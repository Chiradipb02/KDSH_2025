An Analysis of Elo Rating Systems via Markov Chains
Sam Olesker-Taylor
Department of Statistics
University of Warwick
Coventry, CV4 7AL, UK
sam.olesker-taylor@warwick.ac.ukLuca Zanetti
Department of Mathematical Sciences
University of Bath
Bath, BA2 7AY , UK
lz2040@bath.ac.uk
Abstract
We present a theoretical analysis of the Elo rating system, a popular method for
ranking skills of players in an online setting. In particular, we study Elo under the
Bradley–Terry–Luce model and, using techniques from Markov chain theory, show
that Elo learns the model parameters at a rate competitive with the state of the art.
We apply our results to the problem of efficient tournament design and discuss a
connection with the fastest-mixing Markov chain problem.
1 Introduction
The Elo rating system is a popular method for calculating the relative skills of players (or teams) in
sports analytics and particularly chess [ 2,4,1,3]. It is based on a simple zero-sum update rule: if
player ibeats player j, then the rating of player iincreases proportionally to the model probability
thatiwould lose to j, while the rating of jdecreases by the same amount. This amount depends on
the previously estimated difference in skills between iandj.
Despite their widespread popularity, Elo rating systems still lack a rigorous theoretical understand-
ing [6]. Here, we take a probabilistic approach and study Elo under the well-known Bradley–Terry–
Luce model (BTL) [ 11,28]. In this model, the probability pi,jthatiwins against jiswi/(wi+wj),
where wkis the strength of player k. In Elo, this is usually reparametrised via wk= eρk:
pi,j= eρi/(eρi+ eρj) = 1 /(1 + eρj−ρi) =σ(ρi−ρj),
where ρkis the true rating ofkandσ(z):= 1/(1 + exp( −z))forz∈Ris the sigmoid function. In
this setting, after observing ibeatj, the corresponding Elo ratings xiandxjare updated as
xi←xi+ησ(xj−xi)and xj←xj−ησ(xj−xi),
where the step-size η >0is chosen by the modeller. The size of the update depends exponentially on
the difference in ratings: beating a much lower rated opponent does not change the ratings much.
The goal of the Elo rating system is to estimate the true ratings of nplayers by observing results
of matches between pairs of players. It is, therefore, aiming to solve the problem of ranking from
pairwise comparisons. Compared with most algorithms in the area [ 5,20,27,31,37], however, Elo
benefits from three qualities that help explain its popularity in real-world applications: simplicity,
interpretability and the ability to update a ranking of the players in an online fashion.
The knowledgeable reader might have noticed that Elo’s update rule is actually based on the gradient
of the BTL log-likelihood: Elo can be interpreted simply as stochastic gradient descent with fixed
step-size. Rather than studying Elo from a convex optimisation angle, however, we take a more
probabilistic point of view: we assume at each time t, players iandjare selected to play against one
another with probability qi,j. This allows us to interpret Elo as a Markov chain over Rnand deploy
powerful tools to study its behaviour. On the other hand, this approach also presents us with some
challenges: Elo is not a reversible Markov chain and, while it has a unique stationary distribution,
assuming a minor and natural condition on (qi,j)i,j[7], it does not converge to it in total variation [ 6].
38th Conference on Neural Information Processing Systems (NeurIPS 2024).1.1 Our Results
Our main contribution (Theorem 2.5) shows that Elo ratings, averaged over time, well-approximate
the true ratings of the players with high probability. In order to avoid the potential of unbounded
ratings, which are unrealistic in practice, we consider a variant of Elo in which ratings are capped,
whilst maintaining their zero-sum property. We obtain rates of convergence with respect to the number
of observed matches that are competitive against the state of the art in the BTL literature. In contrast
to most other algorithms for the BTL model studied in the literature, Elo learns the parameters of a
BTL model in an online fashion. These rates of convergence is remarkable since Elo was originally
conceived as a simple ranking system for chess players. Furthermore, our approach is very robust,
and also applies to a parallel set-up in which multiple games are played concurrently.
We also discuss the problem of tournament design : we assume we are given a tournament (compari-
son) graph G= ([n], E), and we would like to choose the match-up probabilities (qi,j){i,j}∈Eso
that Elo’s convergence rate is maximised. We highlight a connection between this problem and that of
finding the fastest mixing Markov chain on G[10,39], where the corresponding Markov chain on the
graph is either in discrete or continuous time depending on whether we optimise number of games or
parallel rounds , respectively. As far as we know, this connection has not been made formally before
in the sequential set-up, and both the analysis and optimisation of the parallel set-up are new. In §4,
we also provide experimental results that showcase the usefulness of our strategy.
1.2 Related Work
Despite Elo ratings being the standard ranking system in many sports analytics communities [ 38],
there is a scarcity of work analysing Elo from a probabilistic perspective. In particular, we are aware
only of [ 6], and the unpublished notes [ 7] by the same author, in which Elo is studied as a Markov
process and convergence in distribution to a unique stationary distribution is proved.
If we consider Elo as a technique to estimate the parameters of the BTL model, there is a wealth of
recent literature on the topic by the machine learning community [ 20,37,31,5,27,9]. In contrast to
our setting, however, previous work typically considers an offline scenario, in which the ratings of the
players are computed after all the scheduled matches have taken place. By standard concentration
inequalities, this allows one to obtain a very good approximation of the probability a player wins
against their neighbours in the comparison graph. The goal is then to deduce a global ranking of
the players from such (very good) local information. In our setting, Elo ratings are dynamically
updated before a good local approximation is achieved, which makes the analysis more challenging
and requires the use of powerful, but delicate, concentration inequalities for Markov chains.
A comparison between the rate of convergence for Elo ratings obtained in our work and the rate of
convergence of other algorithms for the BTL model is discussed in §2.
Finally, we mention that the connection between Markov chains and stochastic gradient descent with
fixed step size has been studied before, e.g., in [17].
2 Convergence Rates of Elo Ratings
In this section, we state our main result on the convergence rate of the time-averaged Elo ratings,
discuss related work and outline the most important parts of the proof.
Throughout the paper, “ f≲g” means “ f=O(g)”, “f≪g” means “ f=o(g)” and “whp” means
“with probability 1−O(1/n)”; the notation ˜O(·)hides logarithmic factors; finally, Eπ[·]indicates
thatX0∼π.
2.1 Our Results
We start with the explicit definition of our Markov chain.
Definition 2.1 (Elo Process) .LetM∈Randn≥2. Letρ∈[−M, M ]nwithP
kρk= 0. Letqbe
a distribution on unordered pairs in [n]. Letη∈(0,1
4). A step of EloM(q, ρ;η)proceeds as follows.
0. Suppose that the current vector of ratings is x∈Rn.
21. Choose unordered pair {I, J}to play according to q:
P[{I, J}={i, j}] =q{i,j}for all i, j∈[n].
2.Suppose that Player Ibeats J, which has probability σ(ρI−ρJ). Update ratings xIandxJ:
xI←xI+ησ(xJ−xI);xJ←xJ−ησ(xJ−xI).
3. Orthogonally project the full vector of ratings to [−M, M ]n∩ {x′∈Rn|P
kx′
k= 0}.
LetXt
kdenote the rating of Player kat time t, and πthe equilibrium distribution on Rn. Denote by
At,T
k:=1
tPT+t−1
s=TXs
kfork∈[n]and t, T > 0
thetime-averaged ratings . We typically start from X0= (0, ...,0). The (deterministic) time Tis a
burn-in phase , which allows the Elo ratings to get ‘near’ the true skills, after which we start averaging.
Remark 2.2.The projection step ensures the Elo ratings do not become too large. It is required for
our analysis, but not usually implemented in practice. Indeed, our experiments, discussed in §4,
suggest that, as long as the step-size ηis small enough, Elo ratings remain bounded. Algorithms
which estimate BTL parameters typically require some sort of projection [ 20] or regularisation [ 27].
A simple and efficient algorithm to realise the orthogonal projection is presented in the Appendix.
We show, for a suitable choice of parameters t,Tandη, that the time-averages are concentrated around
the true ratings. In other words, we can use Elo to obtain an MCMC estimate of the true ratings.
Elo ratings in equilibrium are, in general, a biased estimator of the true ratings: i.e., Eπ[X0
k]̸=ρk.
Hence, there will be both a bias and an error term in our MCMC-type estimate of ∥At,T−ρ∥2.
The MCMC convergence rate depends on a spectral gap λq. This parameter quantifies how fast local
information about the relative strengths of two players is propagated to the rest of the ratings. Similar
parameters appear in most of the related literature, e.g., [37, 27].
Definition 2.3 (Spectral Gap) .Letqbe a distribution on unordered pairs in [n]. Define qi,j:=q{i,j},
di,j:=1{i=j}P
kqi,kand∆i,j:=di,j−qi,jfori, j∈[n]. Let λqdenote the spectral gap
(second smallest eigenvalue) of the Laplacian ∆. Always, ∆1=0and∆is positive semi-definite.
Remark 2.4.Equivalently, λqis the spectral gap of the continuous-time Markov chain on [n]with
transition rates qi,j=q{i,j}fori, j∈[n]. Note the scaling:P
i,jqi,j= 2. So, the typical time until
the continuous-time chain jumps is order n, not order 1. This implies λq≤4/n; see Lemma B.2.
We assume λq>0. This holds unless there exists a non-empty subset S⊊[n]withP
i∈S,j̸∈Sqi,j=
0—i.e., players in Snever play those in Sc. This makes estimation of the ratings impossible.
Our main result measures the disparity between the time-averaged Elo ratings and the true ratings.
Theorem 2.5 (Convergence Rate) .LetX∼EloM(q, ρ;η), as in Definition 2.1. Let C1, C2<∞.
Then, there exists a constant C0, depending only on (C1, C2), such that if
min{λq, η,1/t} ≥n−C1and min{t, T} ≥C0t⋆,where t⋆:=e2Mη−1λ−1
qlogn,
then
P
1
n∥At,T−ρ∥2
2≤C0e4M
λqn
η+(logn)2
λqt
≥1−n−C2.
In particular, if η≍(logn)2/(λqt), then
1
n∥At,T−ρ∥2
2≲e4M(logn)2
λqn1
λqtwhp asn→ ∞ .
Remark 2.6.Ideally, λqn=˜Ω(1) ; e.g., if qis uniform over the edges of an expander graph , then
λqn≍1. In this case, we view (logn)2/(λqn) = ˜O(1)as the error’s pre-factor and1/(λqt)
as the (squared) convergence rate . Also, we can then choose η=˜Ω(1) and obtain non-trivial
convergence results. This choice of ηis comparable to that used in practice. Moreover, on average,
only ˜O(1)games per player are need to be observed to guarantee good approximation of the ratings.
Theηterm arises from the average bias1
n∥EX∼π[X]−ρ∥2
2, which is non-zero in general. An estimate
on the average variance1
nP
kVarX∼π[Xk]is necessary to obtain the MCMC convergence rate.
3Theorem 2.7 (Bias and Variance) .Ifπis the equilibrium distribution of EloM(q, ρ;η), then
1
n∥EX∼π[X]−ρ∥2
2≤4e4Mη/(λqn)and1
nP
kVarX∼π[Xk]≤4e2Mη/(λqn).
Despite Elo ratings being biased, the estimated probability a player wins their next match is not:P
j∈[n]qi,jEX∼π[σ(Xi−Xj)] =P
j∈[n]qi,jσ(ρi−ρj)for all i∈[n].
This holds when no projection step is performed as part of the Elo update (equivalently, M:= +∞).
The mixing time is more delicate, as the chain makes deterministic-size discrete jumps, but its
equilibrium distribution is continuous and, therefore, the chain does not converge in total variation.
Instead, we measure convergence in the Wasserstein , also known as transportation , distance.
Theorem 2.8 (Contraction) .IfX, Y∼EloM(q, ρ;η), then there exists a step-by-step coupling with
E(x,y)[∥Xt−Yt∥2
2]≤(1−κ)t∥x−y∥2
2where κ:=1
8e−2Mηλ.
Markov chains satisfying the contraction property (i.e., positively curved ) satisfy powerful concentra-
tion inequalities, developed particularly by Joulin and Ollivier [ 22,23,34,33,24]. The idea is that if
∥X0−Y0∥2=D0, then Dt:=∥Xt−Yt∥2is small when t≍κ−1logD0. For us, D0≤2Mn,
leading to t⋆≍κ−1logn. In the reversible case, this can provide bounds, e.g., on the spectral gap.
The approach is particularly applicable to Markov chains on finite metric spaces, such as graphs. The
set-up of finite graphs was analysed by Bubley and Dyer [ 12] under the name path coupling . In this
case,E[Dt]≤1
2implies P[Xt=Yt]≥1
2, since the minimum graph distance between x̸=yis1.
Our underlying metric space is (Rn,∥ · ∥ 2), however. Inequalities for this more general set-up have
been developed, but they often give weaker bounds. In our case, they lose a factor 1/(ηλq)≳nin the
convergence rate. Morally, though, the exponential convergence at rate κstill implies that 1/κis the
correct timescale for mixing and concentration, perhaps up to some logarithmic factors. Establishing
this rigorously is the most challenging part of our work from a technical point of view.
2.2 Comparison with Related Work
In this section, we compare the convergence rate of Elo given by Theorem 2.5 against the state of
the art for BTL estimation. We highlight, once again, that previous work focusses on the problem of
offline estimation, whilst Elo works in the more challenging online setting. Nevertheless, Elo is able
to match the state-of-the-art algorithms in the offline setting for a wide range of parameters.
Our results imply that Elo provides an estimator ˆρofρwith∥ˆρ−ρ∥2
2≲e4M(logn)2/(λ2
qt)whp.
This matches, up to a log factor, the results by Hajek, Oh and Xu [ 20], who prove that the MLE
constrained on [−M, M ]n∩{x∈Rn|P
kxk= 0},ρMLC, satisfies ∥ρMLC−ρ∥2
2≲e8Mlogn/(λ2
qt).
The dependency on λqhas been improved by Shah, Balakrishnan and Bradley [ 37], who show
∥ρMLC−ρ∥2
2≲ne8Mlogn/(λqt). Since n/λq≥1/4, this is at least as good as our result, and
potentially better for certain choices of q. However, up to log factors, our result matches theirs when
qcorresponds to sampling edges of an expander graph—e.g., a complete graph, or an Erd ˝os–Rényi
graph with parameter p≫(logn)/n. Our result improves the constant in front of M.
More recently, Li, Shrotriya and Rinaldo [ 27] proved a regularised version of the MLE, ρMLR, achieves
∥ρMLR−ρ∥2
2≲e2MEδ/(λ2
qt), where δis the ratio between the maximum and average degree of the
comparison graph G= ([n], E)withE={{i, j} |qi,j>0}andME= max i,j:qi,j>0|ρi−ρj| ≤
2 max k|ρk|. A version of our analysis also applies with ME, instead of M, but we are not able to
prove max i,j:qi,j>0|Xt
i−Xt
j|< M E+ 1holds for polynomially long. Notice that their result is
weaker when the comparison graph is relatively sparse but has a few high degree nodes. Moreover,
they require each player to play the same number of matches; i.e., qi,j= 1/|E|for{i, j} ∈E. Both
limitations are particularly problematic in the context of tournament design discussed in §3. On the
other hand, they obtain ℓ∞error bounds too. We refer to [ 27] for further discussion of previous work.
2.3 Outline of Proof
We now highlight the key steps in estimating the MCMC-type error1
n∥At,T−ρ∥2
2in Theorem 2.5,
where At,Tis the t-step time average of the ratings Xafter a burn-in phase of length T. We use
∥At,T−ρ∥2≤ ∥At,T−Eπ[X0]∥2+∥Eπ[X0]−ρ∥2,
4bounding these error andbias terms separately, via Theorems 2.8 and 2.7, respectively. Their proofs
rely on estimating the change in ℓ2norm a single step, and using the Lipschitz property of the sigmoid
function σ, along with some other careful manipulations. The full proofs are given in the appendix.
The primary challenge is to leverage the positive curvature result of Theorem 2.8 to deduce the
required concentration inequality in Theorem 2.5. As noted at the end of §2.1, positive curvature is
well-suited to this goal, but the specifics of our set-up cause significant difficulties. Particularly, the
aforementioned results reliant only on curvature are not sufficiently strong for our purposes.
A further complication is that Elo is a non-reversible Markov chain. There is a general understanding,
or perhaps belief, in the MCMC community that non-reversibility can improve concentration results.
This has lead to many strategies being proposed, such as non-backtracking, lifting, or zig-zag; see,
e.g., [ 14,16,30,8,25]. Even an alternative definition of the spectral gap has been proposed [ 13];
this gap controls convergence of empirical averages, rather than convergence to equilibrium.
Unfortunately, the majority of general concentration results based on spectral properties [ 19,26,
35,36] are actually worse in the non-reversible set-up: they bound the convergence rates by those
of the multiplicative or additive reversibilisation. These can be hard to estimate, needing detailed
knowledge of the equilibrium distribution, and the resulting bounds are often crude.
Finally, we mention that bounds on the total-variation mixing time can be leveraged to provide
concentration bounds; see, particularly, [ 15,35]. However, Elo does not converge in total variation!
Indeed, Xtis finitely supported, on at most (2n)tstates, given X0, butπis continuous. These (2n)t
states can be used to distinguish Xtandπ. Nevertheless, it is this mixing-time approach that we adapt.
The contraction property implies that two realisations XandYcan be coupled so that their expected
relative distance decreases exponentially, with rate κ. This is ideal for using the coupling approach to
mixing. However, it is not possible to guarantee that Xt=Ytat some point, due to the chain’s finite
support. Instead, we analyse a noisy version : after each update, some (continuous) noise is added to
the ratings. This must be added carefully to preserve the contraction in Theorem 2.8.
Denote the noisy versions UandV. Once UandVare sufficiently close, the additive noise can be
used to couple them exactly, to get Ut=Vt. The size of the noise must be balanced: too small and
this final coupling step is too difficult; too big and Ucan no longer be compared with X.
We delve deeper into this noisy approximation, explaining what noise to add, how it accumulates and
what the resulting mixing time is. The interaction of the noise with the projection step is delicate and
technical; we omit it from the description here, but it should be kept in the back of the mind.
Noisy Version & Error. We consider the following noisy version Uof the Elo process X. Letδ >0.
1.Draw Ut+1/2according to an uncapped Elo step started from Ut—i.e., as if M=∞.
Suppose that Players iandjwere chosen—i.e., {k|Ut+1/2
k̸=Ut
k}={i, j}.
2. Draw ˜Ui,˜Uj∼iidUnif([−√
δ,+√
δ])independently and set ˜Uk:= 0fork /∈ {i, j}. Set
Ut+1
k:=Ut+1/2
k+˜Ukfork∈[n].
This does not preserve the zero-sum property, as the additive noise is independent. The independence
iscrucial later to allow two version to coalesce. We need to control the cumulation until that point.
We control the difference between XandUvia the natural coupling: pick the same pair of players to
play, and observe the same result; sample the noise independently. Careful computation gives
∥Xt+1−Ut+1∥1≤ ∥Xt+1/2−Ut+1/2∥1+ 2√
δ≤ ∥Xt−Ut∥1+ 2√
δ≤...≤2t√
δ.
The second inequality actually says that Elo is non-negatively curved in ℓ1. Iterating this,
1
tPt−1
s=0Xs−1
tPt−1
s=0Us
1≤1
tPt−1
s=0∥Xs−Us∥1≤t√
δdeterministically .△
Curvature. We use the natural coupling between two noisy versions UandV: choose the same
players, observe the same result and add the same noise. Then, there is still rate- κcontraction:
Eu0,v0[∥U1−V1∥2]≤Eu0,v0[∥U1/2−V1/2∥2]≤(1−κ)∥u0−v0∥2. △
5Mixing Time. We bound the total-variation mixing time of the noisy chain via the coupling method:Pu0[Ut∈ ·]−Pv0[Vt∈ ·]
TV≤P(u0,v0)[Ut̸=Vt].
First, we burn-in using the natural coupling, then use a new coupling which exploits the noise.
We start with the natural coupling as given above. Using the rate- κcurvature,
E[∥Ut−Vt∥2]≤(1−κ)t∥U0−V0∥2≤2Mne−κt≤δ2ift≥tδ:=κ−1log(2Mn/δ2).
Hence,
P[∥Ut−Vt∥∞> δ]≤P[∥Ut−Vt∥2> δ]≤δift≥tδ.
Once the absolute difference |Utδ
k−Vtδ
k|are at most δfor all k, the additive noise, which is order√
δ,
dominates the change in difference after a single Elo step, which is order δ. Thus, with complementary
probability order δ/√
δ=√
δ, we can couple the noise so that the rating of a player is the same in
bothUand in Vafter they play a game. Moreover, such a successful step preserves the ℓ∞bound of δ.
Theℓ∞bound implies that all players are chosen within tδsteps with probability at least 1−δ. Hence,
the probability of notsuccessfully matching all ratings after tδsteps is at most order δ+√
δtδ.
Combining these two bounds gives a bound of order δ+√
δtδon the total-variation distance at
time2tδ. The polynomial-growth/decay assumptions in the theorem allow us to choose δto be an
appropriate inverse polynomial (in n) and obtain δ+√
δtδ≪1andtδ≍κ−1logn≍t⋆. △
The above mixing-time bound allows us to establish concentration of time-averages of the noisy Elo
ratings, using results from [ 35]. Particularly, under certain assumptions, if Zis a Markov chain with
equilibrium distribution πand mixing time t⋆, then
−logPπ1
tPt−1
s=0f(Zs)−πf≥ζ
≳σ−2
fζ2t/t⋆,
where πf=Eπ[f]andσ2
f:=Varπ[f]. Notice that this requires Z0∼π, which we do not impose;
this requirement can be circumnavigated by using a burn-in, again comparing with a noisy version.
We want to take f:=fkto be the projection onto the k-th coordinate, which is the k-th player’s
rating, for each k, then do a union bound over the nplayers. This motivates taking
ζ2
k≍σ2
fkt⋆logn
t,which satisfies1
nP
kζ2
k≍η
λqnlogn
λqηlogn
t=1
λqn(logn)2
λqt,
using Theorem 2.7. This is the decay rate required in Theorem 2.5, but for the noisy version.
We need to compare the noisy version with the original. We do this via the estimate established earlier:
1
tPt−1
s=0Xs−1
tPt−1
s=0Us
1≤1
tPt−1
s=0∥Xs−Us∥1≤t√
δdeterministically .
We are taking tto be polynomial in n, and can choose δ−1to be a sufficiently large polynomial so
that this accumulated error is small. Care must be taken to to make all this rigorous, but once it is
done, we are able to deduce the concentration result for the original Elo process.
3 Tournament Design
3.1 Our Results
In this section, we assume we are given a comparison graph G= ([n], E), where edge {i, j} ∈E
indicates that Players iandjare able to play against one another. We want to construct a distribution
qover edges EofGso that Elo can most efficiently approximate the true ratings of the players.
The decay rate in Theorem 2.5 is governed by the spectral gap λq. So, we want to maximise λq. Let
λ⋆
cts:= sup
λqq∈[0,1]E,P
e∈Eqe= 1	
.
This equals the largest spectral gap achievable by a continuous-time Markov chain on [n]with
transitions only across edges of Gand average jump-rate 1/n. It is the fastest-mixing Markov chain
problem, introduced by Sun et al. [ 39], and can be formulated as a semidefinite program. Olesker-
Taylor and Zanetti [32] recently proved that λ⋆
ctsn≳1/(diam G)2.This implies the following.
6Corollary 3.1 (Optimised q).Suppose that the comparison graph G= ([n], E)is given. In the
set-up of Theorem 2.5, there exists a distribution qon the edges Esuch that
1
n∥At,T−ρ∥2
2≲n(diam G)2(logn)2/twhp ifη≲n(diam G)2(logn)2/t.
This choice of probabilities qcan improve drastically over uniform weights—as used by [ 27]. E.g., if
Gconsists of two cliques connected by kedges, then λqn≲k/n2when qe:= 1/|E|is uniform over
E, whilst the optimal λ⋆
ctsn≍1[32]. As a consequence, with the optimal choice of q, only ˜O(n)
total matches need to be played to obtain a good approximation of the true ratings, compared with
˜O(n3/k)for a uniform q. Here, ˜O(·)indicates the asymptotic order up to logarithmic factors. This
demonstrates the power of being able to choose q, given G.
Elo naturally parallelises: if two games consist of disjoint pairs of players, then the Elo update
resulting from one is independent of the result of the other. Hence, if we wish to minimise the number
ofrounds (i.e., sets of games that can be played in parallel), rather than games , we should consider a
distribution ˜qon the set Mofmatchings of the graph G= ([n], E)—i.e., collections of disjoint edges.
Definition 3.2 (Parallel Elo) .Let˜qbe a distribution on M. A single step of ParElo M(˜q, ρ;η)first
selects a matching S⊆Eaccording to ˜qand applies the Elo update (with scale η) to each pair in S.
Then, the resulting vector is orthogonally projected back to zero-sum vectors in [−M,+M]n.
Our analysis is robust enough to handle the parallel case, obtaining convergence rate 1/(λqt), where
nowqeis the marginal probability that edge e∈Eappears in the matching:
qe:=P
S∈M:e∈S˜qS.
Theorem 3.3 (Parallel) .LetX∼ParElo M(˜q, ρ;η). Then, under the conditions of Theorem 2.5,
1
n∥At,T−ρ∥2
2≲e4M(logn)2
λqn/N1
λqtwhp ifη≍(logn)2
λqt,
where N:=P
e∈Eqeis the mean size of the matching. To emphasise, here, tandTcount rounds .
Remark 3.4.It can be shown that this factor Nis needed in the pre-factor via a time-change analysis.
It is natural to optimise λqoverqwhich can arise as the marginals of a distribution ˜qonM. Clearly,
qk:=P
e∈E:k∈eqe≤1for all k∈[n]
for any such q. Thus, the matrix Q= (qi,j)i,j∈Vis substochastic, so λqcorresponds to the spectral
gap of the discrete-time Markov chain on G= ([n], E)with weights qi,j=q{i,j}. Let
λ⋆
disc:= sup{λq|q∈[0,1]E,max k∈[n]qk≤1}.
This is the optimal spectral gap of a discrete-time Markov chain on [n]with transitions allowed
only across edges of Gand uniform stationary distribution. Again, λ⋆
disccan be formulated as a
semidefinite program [ 10] and is related to the vertex conductance via a Cheeger-type inequality [ 32].
We show that a distribution ˜qover matchings with λq≥1
3λ⋆
disccan be found by decomposing the
substochastic Qinto a convex combination of permutation matrices using the Birkhoff–von-Neumann
theorem, followed by decomposing each permutation into disjoint cycles.
Corollary 3.5 (Optimised ˜q).Suppose that the comparison graph G= ([n], E)is given. In the
set-up of Theorem 3.3, there exists a distribution ˜qon matchings Msuch that
1
n∥At,T−ρ∥2
2≲e4M(logn)2
λ⋆
discn/N1
λ⋆
disctwhp ifη≍(logn)2
λ⋆
disct.
In many examples, such as if G= ([n], E)is an expander, but also if Gis a cycle, then λ⋆
disc≍nλ⋆
cts.
In this case, parallel Elo really is as good, up to constants, as nsteps of the original (‘series’) Elo.
(Recall that N=P
eqe= 1is required for λ⋆
cts, but that N≍nis possible for λ⋆
disc.)
Other times, there is already a continuous-time chain, with average jump-rate 1, which has spectral
gap order 1; e.g., two cliques connected by a single edge. In this case, the optimal parallel version
gives no real improvement, even measured by rounds , over the optimally weighted series version.
73.2 Comparison with Related Work
The problem of designing an efficient tournament graph is related to active ranking [21]. Active
ranking, however, allows one to choose which matches to schedule next after observing the results of
some matches. For example, Yan et al. [ 40] propose an algorithm to identify the most informative
pair of players given previous outcomes, and obtain regret bounds between Elo and the true ratings
when matchups are scheduled according to their algorithm. In contrast, we are interested in designing
a probability distribution over matches in an offline manner, without the possibility of changing such
distribution after observing some results.
This problem has been considered by Li, Shrotriya and Rinaldo [ 27]. They discuss a divide-and-
conquer strategy that essentially requires oversampling edges across bottlenecks in the graph. The
drawback of this strategy is that it requires partitioning the graph into well-connected pieces, which is
a non-trivial task itself. Furthermore, [ 27] does not provide explicit bounds on the sample complexity
that can be obtained in this way, besides discussing a few examples where the bottleneck is known.
Nonetheless, our approach shares some similarity with [ 27]: the fastest-mixing Markov chain
implicitly up-weights edges across bottlenecks. The main advantage, however, is that it provides
theoptimal spectral gap allowed by a graph topology, which is related to the diameter of the
graph [ 32]. Moreover, both λ⋆
ctsandλ⋆
disccan be formulated as SDPs, for which fast (polynomial-
time) solvers exist. We remark, however, that this construction might require certain nodes to play an
overwhelmingly large number of matches: this would be problematic for the results of [ 27]. As far as
we know, minimising the number of ‘parallel rounds’ has not been considered before.
4 Experimental Results
We close with discussion of some specific examples and experimental results. Additional experiments
are discussed in the Appendix. We start by considering dumbbell tournament graphs consisting of
two cliques of n/2 = 20 vertices connected by a matching of k∈ {1,20}edges. For each graph,
we perform Elo simulations where the match-ups between players are sampled according to the
following probability distributions.
1. The uniform distribution qUover the edges of the graph.
2.Theoptimal sequential q⋆
seqderived from the fastest-mixing continuous-time Markov chain.
3.The distribution over matchings q⋆
parderived from the fastest mixing discrete-time Markov
chain, where multiple games are played in parallel in each round .
From §3, we know that λqU≍k/n3,λq⋆seq≍1/nandλq⋆par≍k/n.
We sample the true ratings of the players according to independent Gaussians, with mean equal to
1 on one clique, mean 2 on the other, and standard deviation equal to 0.2in both. This difference
in average ratings between cliques simulates a scenario where the two cliques correspond to two
different leagues of slightly different strength on average.
We perform Elo simulations initialising the Elo ratings at zero and setting η= 0.1. For each graph,
we repeat each experiment ten times, each time sampling new true ratings. Experimental results are
displayed in Figures 1 and 2. Simulations are repeated ten times: lines correspond to the average
ℓ2
2-distance between time-averaged Elo ratings and the true ratings, divided by the number of players
(n= 40 ). Shaded regions corresponds to 25–75 percentile over these ten trials. Cyan and blue lines
correspond to the same experiments where we have sampled multiple games in parallel as described
in §3; we display the decay of error wrt the total number of games played in cyan and wrt the number
of parallel rounds in blue. The blue line is solid for the first 2·104games (same number of games
displayed in cyan).
We display the experimental results for k= 1, i.e., two cliques of 20vertices connected by a single
edge, in Figure 1. The experiments align with the theoretical results of §3: when k= 1, the spectral
gapλq⋆
seqof the optimal sequential distribution is of the same order of the spectral gap for our nearly
parallel construction λq⋆par. Indeed, if convergence is measured wrt the number of rounds, the two
corresponding errors seems to decay at a similar same rate, with the parallel version being slightly
better, but requiring more than ten times the total number of games. As predicted by the theory, both
distributions result in much faster convergence than the uniform distribution. If we measure the total
8Figure 1: Elo simulation results for a dumbbell
graph with one edge between two cliques of 20
vertices. Match-ups are sampled from three dif-
ferent probability distributions.
Figure 2: Elo simulation results for a dumbbell
graph with a perfect matching of 20edges be-
tween two cliques of 20vertices.
number of games rather than rounds, the parallel version still results in a faster convergence than the
uniform distribution, but not overwhelmingly so.
We now consider a dumbbell graph with k=n/2, i.e., two cliques connected by a perfect matching.
In this case, the fastest discrete- and continuous-time Markov chains have the same order- 1spectral
gap. However, since the spectral gap for sequential Elo is then rescaled by a factor of 1/n, to achieve
convergence, we expect the number of rounds for the parallel version to be much smaller than the
number of games required by the sequential one; convergence should instead happen at the same
rate when measured in the total number of games. This is clearly shown in Figure 2. The uniform
distribution performs much worse, which we would expect from its order- 1/n2spectral gap. In the
optimal parallel and sequential distributions, the probability to sample an edge from the bottleneck
or from inside the cliques is balanced, while the uniform distribution oversamples edges inside the
cliques. Experiments for the intermediate case of k∈ {5,10}are discussed in the Appendix.
Figure 3: Largest Elo rating in absolute value for
a complete graph of varying size. True ratings
are uniformly distributed in [−1,1].We end this section by discussing experimental
results concerning the maximum rating reached
by Elo. Figure 3 displays the behaviour of the
largest Elo rating in absolute value, where pairs
of players are selected uniformly at random (i.e.,
the underlying graph is a complete graph). The
true ratings are sampled uniformly at random in
[−1,1]. The initial Elo ratings are set equal to
zero. We simulate up to 50000 matches for a
number of players that goes from 100 to 1000.
We observe that the maximum rating is always
below 1.75, corroborating our belief that, in many
scenarios, the maximum Elo rating does not di-
verge for a long time. Further experiments and
discussions are given in the Appendix.
5 Conclusion and Open Problems
Our work is a first step towards establishing the theoretical foundations of the Elo rating system, a
popular ranking method in sports analytics. In particular, our main contribution is an analysis of Elo
under the BTL model, establishing convergence results competitive with the state of the art.
There are several questions prompted by our work. First, from a technical point of view, we would
like to control the maximal Elo rating. This is necessary to understand when we can remove the
projection step in our definition of the Elo Markov chain, and make our theoretical results more
aligned with practice.
9Moreover, we would like to better understand the shape of the stationary distribution of Elo. This
could help us, for example, obtain bounds on the rate of convergence in ℓ∞.
Finally, a touted strength of the Elo rating system in practical applications is its ability to dynamically
update the ratings in response to changes in players’ skills. Can we model these changes in a way
that allows us to prove Elo can keep track of them, and bound the corresponding mean squared error?
Such questions are often studied in the statistics literature; see, e.g., the recent paper [ 18] for details.
References
[1]ATP Elo ratings (tennisabstract.com). https://tennisabstract.com/reports/atp_elo_
ratings.html .
[2] Elo Rating System (chess.com). https://www.chess.com/terms/elo-rating-chess .
[3]Introducing NFL Elo Ratings (fivethirtyeight.com). https://fivethirtyeight.com/
features/introducing-nfl-elo-ratings/ .
[4] World Football Elo Ratings. https://www.eloratings.net/ .
[5]Arpit Agarwal, Prathamesh Patil, and Shivani Agarwal. Accelerated spectral ranking. In
Jennifer Dy and Andreas Krause, editors, Proceedings of the 35th International Conference on
Machine Learning , volume 80 of Proceedings of Machine Learning Research , pages 70–79.
PMLR, 10–15 Jul 2018.
[6]David Aldous. Elo ratings and the sports model: A neglected topic in applied probability?
Statistical Science , 32(4):616–629, 2017.
[7]David Aldous. Mathematical probability foundations of dynamic sports ratings. Draft , January
2017.
[8]Simon Apers, Francesco Ticozzi, and Alain Sarlette. Lifting markov chains to mix faster: Limits
and opportunities. arXiv:1705.08253 [math] , May 2017.
[9]Heejong Bong and Alessandro Rinaldo. Generalized results for the existence and consistency
of the MLE in the bradley-terry-luce model. In Kamalika Chaudhuri, Stefanie Jegelka, Le Song,
Csaba Szepesvári, Gang Niu, and Sivan Sabato, editors, International Conference on Machine
Learning, ICML 2022, 17-23 July 2022, Baltimore, Maryland, USA , volume 162 of Proceedings
of Machine Learning Research , pages 2160–2177. PMLR, 2022.
[10] Stephen Boyd, Persi Diaconis, and Lin Xiao. Fastest mixing markov chain on a graph. SIAM
Review , 46(4):667–689, 2004.
[11] Ralph Allan Bradley and Milton E. Terry. Rank analysis of incomplete block designs. I. The
method of paired comparisons. Biometrika , 39:324–345, 1952.
[12] Ross Bubley and Martin Dyer. Path coupling: A technique for proving rapid mixing in markov
chains. In Proceedings of the 38th Annual Symposium on Foundations of Computer Science ,
FOCS ’97, pages 223–, Washington, DC, USA, 1997. IEEE Computer Society.
[13] Sourav Chatterjee. Spectral gap of nonreversible markov chains. arXiv:2310.10876 [math] ,
October 2023.
[14] Fang Chen, László Lovász, and Igor Pak. Lifting markov chains to speed up mixing. In Annual
ACM Symposium on Theory of Computing (Atlanta, GA, 1999) , page 275–281. ACM, New
York, 1999.
[15] Kai-Min Chung, Henry Lam, Zhenming Liu, and Michael Mitzenmacher. Chernoff–hoeffding
bounds for markov chains: Generalized and simplified. In 29th International Symposium on
Theoretical Aspects of Computer Science , volume 14 of LIPIcs. Leibniz Int. Proc. Inform. , page
124–135. Schloss Dagstuhl. Leibniz-Zent. Inform., Wadern, 2012.
[16] Persi Diaconis, Susan Holmes, and Radford M. Neal. Analysis of a nonreversible markov chain
sampler. Annals of Applied Probability , 10(3):726–752, 2000.
10[17] Aymeric Dieuleveut, Alain Durmus, and Francis Bach. Bridging the gap between constant step
size stochastic gradient descent and Markov chains. Ann. Statist. , 48(3):1348–1382, 2020.
[18] Samuel Duffield, Samuel Power, and Lorenzo Rimella. A State-Space Perspective on Modelling
and Inference for Online Skill Rating, September 2023.
[19] David Gillman. A chernoff bound for random walks on expander graphs. SIAM J. Comput. ,
27(4):1203–1220, 1998.
[20] Bruce Hajek, Sewoong Oh, and Jiaming Xu. Minimax-optimal inference from partial rankings.
In Z. Ghahramani, M. Welling, C. Cortes, N. Lawrence, and K.Q. Weinberger, editors, Advances
in Neural Information Processing Systems , volume 27. Curran Associates, Inc., 2014.
[21] Reinhard Heckel, Nihar B. Shah, Kannan Ramchandran, and Martin J. Wainwright. Active
ranking from pairwise comparisons and when parametric assumptions do not help. Ann. Statist. ,
47(6):3099–3126, 2019.
[22] Aldéric Joulin. Poisson-type deviation inequalities for curved continuous-time markov chains.
Bernoulli. Official Journal of the Bernoulli Society for Mathematical Statistics and Probability ,
13(3):782–798, 2007.
[23] Aldéric Joulin. A new poisson-type deviation inequality for markov jump processes with positive
wasserstein curvature. Bernoulli. Official Journal of the Bernoulli Society for Mathematical
Statistics and Probability , 15(2):532–549, 2009.
[24] Aldéric Joulin and Yann Ollivier. Curvature, concentration and error estimates for markov chain
monte carlo. Annals of Probability , 38(6):2418–2442, 2010.
[25] Jere Koskela. Zig-zag sampling for discrete structures and nonreversible phylogenetic mcmc.
Journal of Computational and Graphical Statistics , 31(3):684–694, 2022.
[26] Pascal Lezaud. Chernoff and berry–esséen inequalities for markov processes. European Series
in Applied and Industrial Mathematics , 5:183–201, 2001.
[27] Wanshan Li, Shamindra Shrotriya, and Alessandro Rinaldo. ℓ∞-bounds of the mle in the
btl model under general comparison graphs. In James Cussens and Kun Zhang, editors,
Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence , volume
180 of Proceedings of Machine Learning Research , page 1178–1187. PMLR, 2022.
[28] R. Duncan Luce. Individual choice behavior: A theoretical analysis . John Wiley & Sons, Inc.,
New York; Chapman & Hall, Ltd., London, 1959.
[29] Math Stack Exchange. Projections Onto Convex Sets Decrease Distances in Hilbert Spaces.
Mathematics Stack Exchange.
[30] Radford M. Neal. Improving asymptotic variance of mcmc estimators: Non-reversible chains
are better. arXiv: 0407281 [math] , July 2004.
[31] Sahand Negahban, Sewoong Oh, and Devavrat Shah. Rank centrality: Ranking from pairwise
comparisons. Operations Research , 65(1):266–287, 2017.
[32] Sam Olesker-Taylor and Luca Zanetti. Geometric bounds on the fastest mixing markov chain.
In Mark Braverman, editor, 13th Innovations in Theoretical Computer Science Conference
(ITCS 2022) , volume 215 of Leibniz International Proceedings in Informatics (LIPIcs) , page
109:1–109:1, Dagstuhl, Germany, January 2022. Schloss Dagstuhl – Leibniz-Zentrum für
Informatik.
[33] Yann Ollivier. Ricci curvature of metric spaces. Comptes Rendus Mathematique. Academie des
Sciences. Paris , 345(11):643–646, 2007.
[34] Yann Ollivier. Ricci curvature of markov chains on metric spaces. Journal of Functional
Analysis , 256(3):810–864, 2009.
[35] Daniel Paulin. Concentration inequalities for markov chains by marton couplings and spectral
methods. Electronic Journal of Probability , 20:no. 79, 32, 2015.
11[36] Daniel Paulin. Mixing and concentration by ricci curvature. Journal of Functional Analysis ,
270(5):1623–1662, 2016.
[37] Nihar Shah, Sivaraman Balakrishnan, Joseph Bradley, Abhay Parekh, Kannan Ramchandran,
and Martin Wainwright. Estimation from Pairwise Comparisons: Sharp Minimax Bounds with
Topology Dependence. In Guy Lebanon and S. V . N. Vishwanathan, editors, Proceedings of
the Eighteenth International Conference on Artificial Intelligence and Statistics , volume 38
ofProceedings of Machine Learning Research , pages 856–865, San Diego, California, USA,
09–12 May 2015. PMLR.
[38] Ray Stefani. The methodology of officially recognized international sports rating systems.
Journal of Quantitative Analysis in Sports , 7(4), 2011.
[39] Jun Sun, Stephen Boyd, Lin Xiao, and Persi Diaconis. The fastest mixing markov process
on a graph and a connection to a maximum variance unfolding problem. SIAM Review ,
48(4):681–699, 2006.
[40] Xue Yan, Yali Du, Binxin Ru, Jun Wang, Haifeng Zhang, and Xu Chen. Learning to identify top
Elo ratings: A dueling bandits approach. In Proceedings of the AAAI Conference on Artificial
Intelligence , volume 36, pages 8797–8805, 2022.
12A Experiments: Further Discussion and Figures
In this appendix we discuss additional experimental results. Code for our experiments is included in
the supplementary material.
In Figure 4 we display further experiments related to dumbbell graphs. In particular, we consider
graphs consisting of two cliques of 20vertices connected by 5(left) and 10(right) edges arranged in a
matching. The experimental setup is the same as the one discussed in §4. Notice how, the more edges
are added to the bottleneck, the better the distribution optimised for parallel rounds performs. The
optimal sequential distribution, instead, performs roughly the same: adding edges in the bottleneck
doesn’t really improve its spectral gap, which depends mainly on the (unchanged) diameter.
Figure 4: Elo simulation results for dumbbell graphs with k= 5 (left) and k= 10 (right) edges
between two cliques of 20vertices.
We also consider a pyramidal graph, which is constructed as follows. We first sample three Erd ˝os–
Rényi random graphs with size, resp., n1= 64 ,n2= 32 andn3= 16 , and density p= 1/2. We then
connect the first graph to the second and the second to the third with two sparse cuts (see Figure 5).
This graph is constructed to loosely resemble the pyramidal structure of, e.g., national sport leagues.
We conduct Elo simulations with the same set-up as for dumbbell graphs discussed earlier. In
particular, we repeat the simulations ten times, resampling each time the players’ true ratings. The
true ratings are sampled as follows: independent normal distributions of standard deviation 0.2 and
mean 0for the Erd ˝os–Rényi at the bottom of the pyramid, mean 1for the Erd ˝os–Rényi in the middle,
Figure 5: Schematic representation of the pyra-
midal graph.
Figure 6: Elo simulation results for the pyramidal
graph.
13and mean 2for the one at the top. This is, again, to loosely simulate the fact that sport leagues are
characterised by stronger players/teams towards the top of the pyramid. Experimental results are
shown in Figure 6. In particular, we observe that the rate of converge for the uniform distribution is
much slower than for the optimal sequential one. This is, again, predicted by the results of §3: the two
bottlenecks slow down the convergence in the uniform case; while the small diameter assures faster
convergence for the optimal distribution by Corollary 3.1. The distribution optimised for parallel Elo,
instead, guarantees very fast convergence when measured according to the number of rounds.
In Figure 7 we display experimental results for a topology corresponding to the giant component of
an Erd ˝os–Rényi random graph of n= 100 vertices and density p= 0.02. True ratings are distributed
as independent standard Gaussians. This graph has reasonably good connectivity, so we expect
the number of games required to converge to be roughly equal for all the sampling distributions
considered, with a good scope for parallelisation. This is confirmed by the error plot. What is perhaps
surprising is that the optimal sequential distribution actually performs slightly worse than the uniform
one. This can be explained by the fact that the spectral gap measures the rate of convergence for
the worst possible vector of ratings: if the ratings do not depend on the topology of the graph, like
in this example, the inverse of the spectral gap is an overtly pessimistic upper bound. Indeed, the
optimal sequential distribution tends to oversample nodes that are in a central position in the graph
and undersample nodes at the periphery. This should make convergence faster because it allows faster
movement of information between distant nodes, but in this specific example is not helpful: since
ratings are sampled in a iid fashion, the faster movement of information globally is not very helpful
and is upset by slower convergence for undersampled nodes.
Figure 7: Left: topology of the giant component of an Erd ˝os–Rényi random graph of n= 100
vertices and density p= 0.02; edges are reweighed according to the distribution corresponding to the
fastest mixing continuous-time Markov chain. Right: Elo simulation results for the same graph.
We now present further experiments about the maximum Elo rating (in absolute value). Again, we
sample true ratings independently and uniformly in [−1,1]. In Figure 8, we present experiments for a
path (left) and star (right) topology of varying size. In both cases, the largest Elo rating in absolute
value remains smaller than twice the largest true rating. Notice that in the star graph the central node
plays all the matches; this means the same player plays in total fifty-thousands matches without its
value becoming particularly large.
Of course, these simulations are far from definitive: there are countless of ways in which to choose
the true ratings and the graph topology. Our belief that these experiments are indicative of a more
general behaviour is due to the peculiarities of the Elo rating systems. In particular, the Elo update
offers diminishing returns: if the rating of iis relatively much larger than the rating of j, ifiwins
against j, the rating of iwon’t increase by much. This is because the sigmoid function σapproaches
zero very fast.
Despite this, proving that the maximum rating cannot increase significantly appears much harder.
This is due to the fact that the maximum rating is not a supermartingale: if all of the neighbours of
the node iwith largest true rating have abnormally large rating, the rating of iis likely to increase,
no matter how large it already was. However, because the zero-sum property of the ratings, the
neighbours of icannot maintain an abnormally large rating for too long. Indeed, it appears very
unlikely that such balanced but “abnormal” configurations are ever reached.
14Figure 8: Behaviour of the largest Elo rating in absolute value for path (left) and star (right) graphs of
varying size.
In the two-player case, the situation is simpler: if player 1has Elo rating x1, then player 2has
x2=−x1, by the zero-sum nature. It is straightforward to check that the Elo ratings are biased
towards the true skills: that is, if player 1has rating x1before a game, then their rating x′
1after the
game has E[|x′
1−ρ1|]<|x1−ρ1|, ifη <1
2.
Suppose that the same argument holds for n >2players: i.e., typically , Elo ratings are biased towards
the true skills. Biased random walks on Rhave exponential tails. So, if η≪1/logn, then it is
super-polynomially unlikely that a given Elo rating will be more than 1away from the corresponding
true skill, in equilibrium. A union bound over the nplayers allows us to deduce that the maximum
Elo rating is at most 1more than the maximum true skill, with probability at least 1−1/n10.
Unfortunately, we weren’t able to make this argument formal for n >2players. We leave proving
that indeed, with high probability, the maximum rating remains small for a large number of steps as
an open problem.
B Convergence Proofs: Preliminaries
There are a few results which we use repeatedly throughout the proofs. We collect them here.
B.1 Dirichlet Characterisation of the Spectral Gap
Recall that λqis the spectral gap of the continuous-time Markov chain on [n]with transition rates
(qi,j)i,j∈[n]. We repeatedly use the standard Dirichlet characterisation of the spectral gap.
Proposition B.1 (Dirichlet Characterisation of the Spectral Gap) .The spectral gap λqsatisfies
λq=1
2min
z∈Rn\{0}:z⊥1P
i,j∈[n]qi,j(zi−zj)2
∥z∥2
2.
In particular, for all z∈RnwithP
kzk= 0,P
i,j∈[n]qi,j(zi−zj)2≥2λq∥z∥2
2.
Lemma B.2. Letqi,j∈[0,1]for all i, j∈[n]withP
i,jqi,j= 2. Letλqdenote the spectral gap of
the continuous-time Markov chain on [n]with transition rates (qi,j)i,j∈[n]. Then,
λq≤2/(n−1)≤4/n.
Proof. We apply the Dirichlet characterisation (Proposition B.1) with zi:=1{i=k} −1
n. Then,
z⊥1,∥z∥2
2= (1−1/n)2+ (n−1)/n2= 1−1/n= (n−1)/n
and
1
2P
i,j∈[n]qi,j(zi−zj)2/∥z∥2
2=1
2P
i,j∈[n]qi,j(1{i=k} −1{j=k})2n
n−1
=1
2n
n−1 P
j:j̸=kqk,j+P
i:i̸=kqi,k
=n
n−1P
ℓqk,ℓ.
Choosing kto minimise this final sum givesP
ℓqk,ℓ≤2
nsince the average1
nP
kP
ℓqk,ℓ=2
n. So,
λq≤n
n−1·2
n= 2/(n−1)≤4/n.
15B.2 Capping the Ratings
Capping at ±Mhas the benefit of restricting the process remains in a compact set. The disadvantage,
though, is that the Elo update is more complicated. It also biases the process compared with the
original. However, as we discuss in Remark C.2 below, the original process is already biased in the
sense that the expected rating in equilibrium is not the true rating: Eπ[X]̸=ρ.
The only property of the projection that we use is the following monotonicity result.
Proposition B.3 (Projection Monotonicity) .LetΩ⊆Rnbe a closed, convex set. Define
ΠΩ(x):= arg min x′∈Ω∥x−x′∥2forx∈Rn;
that is, ΠΩis the orthogonal projection to Ω. Then,
∥ΠΩ(x)−ΠΩ(y)∥2≤ ∥x−y∥2for all x, y∈Rn;
that is, ΠΩ(x)is at least as close to ΠΩ(y)asxis toy, inℓ2.
Versions of this result are well-known. An elementary proof can be found at [ 29]. We apply this
withΩ:={x∈Rn| ∥x∥∞≤M,P
kxk= 0}, which is convex. Our results apply whenever this
monotonicity property holds.
The orthogonal projection ΠΩ(x)can be efficiently computed as follows. We first project xto
{y∈Rn| ∥y∥∞≤M}. This can be done by simply replacing any xi<−Mwith−Mand any
xi> M withM. Let x′be the resulting vector. Notice that x′might not satisfy the constraintP
kx′
k= 0: we need to subtract the displaced massP
kx′
kto the rest of the vector while minimising
ΠΩ(x):= arg min x′′∈Ω∥x−x′′∥2. AssumeP
kx′
k>0(the symmetric case can be handled
similarly). We set x′′
i=−Mfor all the coordinates isuch that x′
i=−Mand call ifrozen . To
minimise ∥x−x′′∥2, we want to distribute −P
kx′
kto the unfrozen coordinates so that x−x′′is as
balanced as possible in each coordinate (this can be imagined as a water-filling procedure). In doing
so, however, we might make x′′
i=−Mfor a new, previously unfrozen, coordinate ibefore we have
subtracted all the displaced mass. If that happens, we simply freeze iand proceed in distributing the
remaining displaced mass to the unfrozen coordinates (until a new coordinate is frozen). We keep
repeating the procedure since all the mass is allocated. Notice that we can allocate all the mass since
we assumedP
kx′
k>0. Moreover, the procedure lasts at most nsteps since at each step we freeze a
new coordinate until we have completed constructing the desired vector.
C Convergence Proofs: Bias and Variance
There is an inherent bias and variance in the Elo ratings. It would be natural to assume that the
expected value of a player’s rating in equilibrium is equal to their real skill. After all, at least in the
two-player case, an individual step is always biased towards the real skill. However, even for two
players, this is not true. In this section, we quantify the bias and the variance in equilibrium.
Throughout this section and the next, we denote
pi,j(z):=σ(zi−zj)forz∈Rnand i, j∈[n].
In particular, pi,j(ρ)is the trueprobability that Player ibeats jandpi,j(x)is the model probability if
the current ratings are x. Additionally, we split up the Elo step into the update and the projection:
• if the current vector is Xt, then let Xt+1/2denote an uncapped step;
• then, Xt+1= Π M(Xt+1/2), where ΠMis the orthogonal projection.
We do not quantify the bias and variance player-by-player, but rather average over all players.
Theorem C.1 (Bias and Variance; Theorem 2.7) .The following bias and variance estimates hold:
∥Eπ[X0]−ρ∥2
2≤Eπ[∥X0−ρ∥2
2]≤4e4Mη/λq;
P
kVarπ[X0
k] =Eπ[∥X0−Eπ[X0]∥2
2]≤4e2Mη/λq.
Proof: Bias. First and foremost, the Cauchy–Schwarz inequality gives
∥Eπ[X0]−ρ∥2
2≤Eπ[∥X0−ρ∥2
2].
16We start the system from equilibrium and use stationarity: X0∼π=⇒X1∼π. Also, we can
ignore the projection step, whilst still assuming that all vectors have ℓ∞norm at most M, due to the
projection monotonicity of Proposition B.3: noting that ∥ρ∥∞≤M, soΠM(ρ) =ρ, we have
∥X1−ρ∥2=∥ΠM(X1/2)−πM(ρ)∥2≤ ∥X1/2−ρ∥2.
WriteEx,{i,j}[·]to indicate that the pair {i, j}is chosen in the first step and X0=x. Then,
Ex,{i,j}
(X1/2
i−ρi)2
=pi,j(ρ) 
xi−ρi+η 
1−pi,j(x)2+ 
1−pi,j(ρ) 
xi−ρi−ηpi,j(x)2
= (xi−ρi)2+η2 
pi,j(ρ) 
1−pi,j(x)2+ 
1−pi,j(ρ)
pi,j(x)2
+ 2η 
pi,j(ρ) 
1−pi,j(x)
− 
1−pi,j(ρ)
pi,j(x)
(xi−ρi)
≤(xi−ρi)2+η2−2η 
pi,j(x)−pi,j(ρ)
(xi−ρi).
An analogous statement holds for X1/2
j−ρj, with iandjswapped:
Ex,{i,j}
(X1/2
j−ρj)2
≤(xj−ρj)2+η2−2η 
pj,i(x)−pj,i(ρ)
(xj−ρj)
= (xj−ρj)2+η2+ 2η 
pi,j(x)−pi,j(ρ)
(xj−ρj),
using the fact that pj,i(·) = 1−pi,j(·). For k /∈ {i, j},
Ex,{i,j}
(X1/2
k−ρk)2
= (xk−ρk)2.
Bringing these three cases (indices k=i,k=jandk∈[n]\ {i, j}) together,
Ex,{i,j}
∥X1/2−ρ∥2
2
≤ ∥x−ρ∥2
2+ 2η2−2η 
pi,j(x)−pi,j(ρ) 
(xi−ρi)−(xj−ρj)
=∥x−ρ∥2
2+ 2η2−2η 
pi,j(x)−pi,j(ρ) 
(xi−xj)−(ρi−ρj)
.
Now, pi,j(x)−pi,j(ρ) =σ(xi−xj)−σ(ρi−ρi)and(xi−xj)−(ρi−ρj)have the same sign. Also,
|pi,j(x)−pi,j(ρ)|=σ 
xi−xj
−σ 
ρi−ρj
≥minz∈[−4M,4M]|σ′(z)| · |(xi−xj)−(ρi−ρj)|
≥1
4e−4M|(xi−xj)−(ρi−ρj)|
since xi, xj, ρi, ρj∈[−M, M ], so|(xi−xj)−(ρi−ρj)| ≤4Mandσ′(z) =σ(z) 
1−σ(z)
.
Hence,
Ex,{i,j}
∥X1/2−ρ∥2
2
≤ ∥x−ρ∥2
2+ 2η2−1
2e−4Mη 
(xi−xj)−(ρi−ρj)2
=∥x−ρ∥2
2+ 2η2−1
2e−4Mη 
(xi−ρi)−(xj−ρj)2.
We now average this over {i, j}:
Ex
∥X1/2−ρ∥2
2
≤ ∥x−ρ∥2
2+ 2η2−1
2e−4MηP
i,jq{i,j}|(xi−ρi)−(xj−ρj)|2.
Now, applying the Dirichlet characterisation of the spectral gap (Proposition B.1) with z:=x−ρ,
Ex
∥X1/2−ρ∥2
2
≤ ∥x−ρ∥2
2+ 2η2−1
2e−4Mηλq∥x−ρ∥2
2= (1−1
2e−4Mηλq)∥x−ρ∥2
2+ 2η2;
again,P
kzk=P
kxk−P
kρk= 0. In particular, stationarity implies that
Eπ
∥X0−ρ∥2
2
=Eπ
∥X1−ρ∥2
2
≤Eπ
∥X1/2−ρ∥2
2
≤4e4Mη/λq.
We perform a very similar calculation when bounding the curvature ; see Definition D.2. This is the
exponential contraction rate between a pair of systems XandY. The (1−1
2e−4Mηλq)-factor above
suggests curvature κ≍e−4Mηλq, which is indeed what we show in Proposition D.4.
We now turn to the variance, for which we use a similar approach. It is a little more technically
challenging, using the slightly cumbersome law of total variance : for random variables AandB,
Var[B] =E[Var[B|A]] +Var[E[B|A]].
17Proof: Variance. The sum of variances is the expectation of an ℓ2distance:P
kVar[Zk] =P
kE
(Zk−E[Zk])2
=EP
k(Zk−E[Zk])2
=E
∥Z−E[Z]∥2
2
,
for any random variable Z∈Rn. Also, for any c∈Rn,
Var[Z] =E[(Z−E[Z])2]≤E[(Z−c)2].
Applying this and the monotonicity of the orthogonal projection from Proposition B.3 givesP
kVar[X1
k] =E
∥X1−E[X1]∥2
2
≤E
∥ΠM(X1/2)−E[X1/2]∥2
2
≤E
∥X1/2−E[X1/2]∥2
2
=P
kVar[X1/2].
Hence, it suffices to prove the bound for X1/2—i.e., for the Elo update without capping.
Use subscript {i, j}to indicate that this pair is chosen in the first game, as before. Let {I, J}be a
pair of (distinct) indices drawn according to q. Then, by the law of total variance,
P
kVar[X1/2
k] =P
kE[Var{I,J}[X1/2
k]] +P
kVar[E{I,J}[X1/2
k]].
We studied the first term (aka the “unexplained variance”) first. First,
P
kE[Var{I,J}[X1/2
k]] =P
kP
i,jq{i,j}Var{i,j}[X1/2
k] =P
i,jq{i,j}P
kVar{i,j}[X1/2
k].
We now bound Var{i,j}[X1/2
k]over three cases: k=i,k=jandk /∈ {i, j}. We have
Var{i,j}[X1/2
i] =Var{i,j}[X0
i−ηpi,j(X0)] +η2Var{i,j}
Bern( pi,j(ρ))
≤Var[X0
i]−2ηCov
X0
i, σ(X0
i−X0
j)
+1
2η2,
since the maximal variance of a [0,1]-valued random variable is1
4. Analogously,
Var{i,j}[X1/2
j]≤Var[X0
j]−2ηCov[X0
j, σ(X0
j−X0
i)] +1
2η2
=Var[X0
j] + 2ηCov
X0
j, σ(X0
i−X0
j)
+1
2η2,
since σ(−z) = 1−σ(z). For k /∈ {i, j},
Var{i,j}[X1/2
k] =Var[X0
k].
Bringing these three cases together,
P
kVar{i,j}[X1/2
k]≤P
kVar[X0
k] +η2−2ηCov
X0
i−X0
j, σ(X0
i−X0
j)
.
Now, σ:R→[0,1]is increasing. So, Cov[Y, σ(Y)]≥0for any random variable Y. Moreover,
|σ(y)−1
2|=|σ(y)−σ(0)| ≥minz∈[−2M,2M]|σ′(z)|·|y| ≥1
4e−2M|y|for all y∈[−2M,2M].
Since X0
i−X0
j∈[−2M,2M], applying this gives
Cov{i,j}
X0
i−X0
j, σ(X0
i−X0
j)
≥1
4e−2MVar{i,j}[X0
i−X0
j].
Plugging this in above,
P
kVar{i,j}[X1/2
k]≤P
kVar[X0
k] +η2−1
2e−2MηVar{i,j}[X0
i−X0
j].
We now average over {i, j}:
P
i,jq{i,j}P
kVar{i,j}[X1/2
k]≤P
kVar[X0
k] +η2−1
2e−2MηP
i,jq{i,j}Var{i,j}[X0
i−X0
j].
Variances are (weighted) sums of squares, which leads to a spectral-gap estimate again:P
i,jq{i,j}Var{i,j}[X0
i−X0
j]
=P
i,jq{i,j}Var{i,j}
(X0
i−E[X0
i])−(X0
j−E[X0
j])
=P
i,jq{i,j}E 
(X0
i−E[X0
i])−(X0
j−E[X0
j])2
=EP
i,jq{i,j} 
(X0
i−E[X0
i])−(X0
j−E[X0
j])2
≥E
λqP
k(X0
k−E[X0
k])2
=λqP
kVar[X0
k],
18by applying the Dirichlet characterisation of the spectral gap with z:=X0−E[X0]. Thus,
P
i,jq{i,j}P
kVar{i,j}[X1/2
k]≤P
kVar[X0
k] +η2−1
2e−2MηλqP
kVar[X0
k]
= (1−1
2e−2Mηλq)P
kVar[X0
k] +η2.
We would like to deduce thatP
kVarπ[X0
k]≤4e2Mη/λqnow, analogously to before. But, we must
remember the second term in the law of total variance (aka the “explained variance”). We have
Var
E{I,J}[X1/2
k]
≤1
2η2qk=1
2η2P
ℓq{k,ℓ}.
Indeed, if Player kis picked—i.e., k∈ {I, J}—then X1/2
kmoves up/down to one of two values
which differ by η; if Player kis not picked, then X1/2
kdoes not move. The maximal variance of such
a random variable is1
2η2qk, where qk=P
ℓq{k,ℓ}is the probability that Player kis picked. Hence,
P
kVar
E{I,J}[X1/2
k]
≤1
2η2P
kqk=η2,
noting the double-counting of edges inP
kqk=P
k,ℓq{k,ℓ}= 2.
Combining the bounds for the unexplained and explained components of the variance,
P
kVar[X1/2
k]≤(1−1
2e−2Mηλq)P
kVar[X0
k] + 2η2.
In particular, stationarity implies thatP
kVarπ[X1/2
k] =P
kVarπ[X0
k],so
P
kVarπ[X0
k] =P
kVarπ[X1
k]≤P
kVarπ[X1/2
k]≤4e2Mη/λq.
We controlled the bias, but did not actually argue that it is non-zero.
Remark C.2 (Bias in Expected Rating) .The uncapped Elo update ( M=∞) implies that
Eπ[Xi] =Eπ
Xi+ηP
jq{i,j} 
pi,j(ρ)−pi,j(X)
=Eπ[Xi] +η P
jq{i,j}Eπ[pi,j(ρ)]−P
jq{i,j}Eπ[pi,j(X)]
.
Therefore,P
jq{i,j}pi,j(ρ) =P
jq{i,j}Eπ[pi,j(X)].
The right-hand side is the expectation of the estimated probability that Player iwins their next game
(not conditioning on their opponent) in equilibrium and the left-hand side is the true probability. The
equality shows that the win-probability estimator for each player is unbiased.
In the two-player case, this actually implies that Eπ[p1,2(X)] =p1,2(ρ).We can deduce from this,
however, that the estimated rating is biased, if ρ̸= (0,0). We do this now, but only informally.
The ratings are zero-sum, so it suffices to consider X1andρ1. Suppose that ρ1>0and that ηis
small—much smaller than ρ1. Then, the rating X1concentrates around ρ1. The win-probability
function σis strictly convex and increasing in (0,∞), which suggests that
p1,2 
Eπ[X1]
<Eπ
p1,2(X1)
=p1,2(ρ),and hence Eπ[X1]̸=ρ.
Of course, Pπ[X1>0]̸= 1. This can be handled using the quantified version of Jensen’s inequality
and large deviation estimates on Pπ[X1<0]. Ifρ1is large, then, very roughly, the latter probability
is like e−ρ2
1, whilst the quantified difference from equality is like e−ρ1; the latter dominates.
Then-player case is more complicated. It is possible that a particular choice of (ρ, q)could lead to
certain players’ having unbiased estimates. However, they will be biased in general.
The ratings are biased, typically, but the win-probabilities at equilibrium are unbiased in the uncapped
setting. Moreover, the real ratings are the only vector ρgiving rise to these win-probabilities.
Proposition C.3. Letx, ρ∈RnwithP
kρk= 0 =P
kxk. Then,
P
jq{i,j}pi,j(x) =P
jq{i,j}pi,j(ρ)for all i∈[k]if and only if x=ρ.
Proof. The “if” direction is obvious. We prove the “only if” direction by constructing a minimisation
problem over zero-sum vectors in Rnwith the following two properties:
191. it has a unique minimum at ρ;
2.xis a minimum if and only if it satisfies the equations in the statement.
Define f:Rn→Rby
f(x):=P
i 1
2P
jq{i,j}log 
1 +exi−xj
−xiP
jq{i,j} 
pi,j(ρ)−1
2
forx∈Rn.
Then, fis strictly convex in {x∈Rn|P
kxk= 0}, and thus has a unique minimiser in that set. We
now take the gradient of fand compare it with 0:
∂f
∂xi(x) =1
2P
jq{i,j} 
2pi,j(x)−1
−P
jq{i,j} 
pi,j(ρ)−1
2
=P
jq{i,j}pi,j(x)−P
jq{i,j}pi,j(ρ).
Hence, xis a minimum if and only ifP
kxk= 0andP
jq{i,j}pi,j(x) =P
jq{i,j}pi,j(ρ).
Notice that if we only desire estimates on the win-probabilities, then the whole Elo framework is
not needed: simply tracking the empirical proportion of games won between each pair of players suf-
fices.
D Convergence Proofs: Curvature and Concentration
Our time-averaged MCMC-type concentration estimates rely crucially on curvature bounds. We start
by introducing curvature, then bounding it in the case of the Elo ratings. We then apply it to obtain
concentration results for time-averaged ratings.
D.1 Curvature Definitions
We introduce the concept of curvature for a Markov chain Pon a general metric space (Ω, d).
Definition D.1 (Transportation Distance) .Letµandπbe probability measures on Ω. The trans-
portation distance W1(µ, π)represents the ‘best’ way to send µtoπso that, on average, points are
moved by the smallest distance:
W1(µ, π):= inf QEQ
d(X, Y)
,
where the infimum is over all couplings Qof(µ, π)—i.e., X∼µandY∼π, marginally, under Q.
Definition D.2 (Curvature of Markov Chains) .The ( Ricci )curvature ofPis
κP:= inf x,y∈Ωκx,y where κx,y:= 1−W1(Px,·, Py,·)/d(x, y)forx, y∈Ω.
A standard application of the triangle inequality and iteration establishing the following result.
Lemma D.3 (Contraction of Distance) .For all measures µandπand all t≥0,
W1(µP, πP )≤(1−κP)W1(µ, π)and W1(µPt, πPt)≤(1−κP)tW1(µ, π).
This reduces to the well-known set-up of path coupling [12] when (Ω, d)is a finite graph endowed
with the usual graph distance. Our set-up, however, is very different: (Ω, d) = (Rn,∥ · ∥ 2).
Exact calculation of the curvature is rarely required. Rather, a particular coupling is analysed, giving
an upper bound on the transportation distance and hence, by extension, an upper bound on the
curvature. The key is finding as close to optimal a coupling as possible.
The next subsection establishes an upper bound on the curvature of the Elo process. The final
subsection of the section develops applies curvature to concentration.
D.2 Curvature Bounds for the Elo Process
We determine the worst-case rate of contraction rate 1−κstarting from ratings (x, y)∈Ω2: we
show that κ≳λqwhere λqis the spectral gap of the auxiliary random walk with rates (qi,j).
Proposition D.4 (Curvature) .Letκdenote the curvature of Elo in ∥ · ∥ 2. Then,
κ≥1
8ηe−2Mλq.
20Proof. Letx= (xk)k∈[n]∈Ωandy= (yk)k∈[n]∈Ωbe two sets of ratings. We want to bound
Ex,y[∥X1−Y1∥2]≤(1−ρ)∥x−y∥2for some ρ≥0under some coupling .
First, we observe that we can ignore the projection step in the Elo update, by Proposition B.3:
∥X1−Y1∥2=∥ΠM(X1/2)−ΠM(Y1/2)∥2≤ ∥X1/2−Y1/2∥2.
Again, this is using the notation X1/2to indicate the uncapped Elo update, and X1= Π M(X1/2).
We thus study (X1/2, Y1/2), under the assumption ∥x∥∞,∥y∥∞≤M. We use the trivial coupling :
• the same pair (I, J)of players is chosen;
• the result of the match is the same—i.e., the same player wins—in both systems.
This is legitimate because neither the choice of players nor the law of the outcome depends on the
current state—the estimated probability that Ibeats Jdepends on the state, but the realprobability
does not. Write E{i,j}[·]for the law conditional on choosing pair {i, j}to play.
Recall that, for z∈Rnandi, j∈[n], we write pi,j(z):=σ(zj−zi)for the estimated probability
thatibeats jusing ratings z. If Player ibeats j, then igains ηpj,ipoints; similarly, iloses ηpj,i
points if Player jbeats i. Observing that pj,i(x)−pj,i(y) =pi,j(y)−pi,j(x), we obtain
E{i,j}
(X1/2
i−Y1/2
i)2
=pi,j(ρ) 
(xi−yi) +η 
pj,i(x)−pj,i(y)2
+ (1−pi,j(ρ)) 
(xi−yi)−η 
pi,j(x)−pi,j(y)2
= 
(xi−yi)−η 
pi,j(x)−pi,j(y)2
= (xi−yi)2+η2 
pi,j(x)−pi,j(y)2−2η(xi−yi) 
pi,j(x)−pi,j(y)
.
Switching the roles of iandjand using the fact that pi,j= 1−pj,iagain, we obtain
E{i,j}
(X1/2
j−Y1/2
j)2
= (xj−yj)2+η2 
pj,i(x)−pj,i(y)2−2η(xj−yj) 
pj,i(x)−pj,i(y)
= (xj−yj)2+η2 
pj,i(x)−pj,i(y)2+ 2η(xj−yj) 
pi,j(x)−pi,j(y)
.
For all other k—i.e., for k /∈ {i, j}—we have X1/2
k=xkandY1/2
k=yk. Hence,
E{i,j}
∥X1/2−Y1/2∥2
2
− ∥x−y∥2
2
≤2η2 
pi,j(x)−pi,j(y)2−2η 
(xi−xj)−(yi−yj) 
pi,j(x)−pi,j(y)
≤ −η(xi−xj)−(yi−yj)σ(xi−xj)−σ(yi−yj),
with the final inequality using the fact that σis1-Lipschitz and η <1
2.
We now bound the difference in probabilities. For ¯x,¯y∈Rwith¯x≥¯y, we have
|σ(¯x)−σ(¯y)| ≥min ¯z∈[¯y,¯x]|σ′(¯z)||¯x−¯y| ≥1
4e−max{|¯x|,|¯y|}|¯x−¯y|.
Combining the previous results,
E{i,j}
∥X1/2−Y1/2∥2
2
− ∥x−y∥2
2≤ −1
4ηe−max{|xi−xj|,|yi−yj|}|(xi−xj)−(yi−yj)|2
≤ −1
4ηe−2M|(xi−xj)−(yi−yj)|2=−1
4ηe−2M|(xi−yi)−(xj−yj)|2,
using the fact that ∥x∥∞,∥y∥∞≤M. Summing over (i, j), weighted by qi,j, gives
E
∥X1/2−Y1/2∥2
2
− ∥x−y∥2
2
=P
i,j∈[n]:i<jq{i,j}E{i,j}
∥X1/2−Y1/2∥2
2− ∥x−y∥2
2
≤ −1
4ηe−2MP
i,j∈[n]:i<jqi,j|(xi−yi)−(xj−yj)|2.
Now, applying the Dirichlet characterisation of the spectral gap (Proposition B.1) with z:=x−y,
E
∥X1/2−Y1/2∥2
2
− ∥x−y∥2
2≤ −1
4ηe−2Mλq∥x−y∥2
2;
note thatP
kxk= 0 =P
kyk, soP
kzk= 0. Jensen’s inequality then gives
E
∥X1/2−Y1/2∥2
≤E
∥X1/2−Y1/2∥2
21/2
≤(1−1
4ηe−2Mλq)1/2∥x−y∥2≤(1−1
8ηe−2Mλq)∥x−y∥2.
Hence, recalling that ∥X1−Y1∥2≤ ∥X1/2−Y1/2∥2,
κx,y≥1
8ηe−2Mλq,and so κ= inf x,y∈Ωκx,y≥1
8ηe−2Mλq.
21D.3 Concentration Statements
Our goal is to establish concentration of time-averaged statistics of the Elo process. General results of
this form as known as “Chernoff-type bounds for Markov chains”. There is a great deal of literature
on such concentration bounds. The version we state here is most-closely related to Theorem 3.4 and
Proposition 3.4 in [35]; see also Theorem 3 in [15], particularly.
Definition D.5 (Mixing Time) .Letµandπbe measures on a state space Ω. Then, the total-variation
(TV) distance between µandπis defined to be
∥µ−π∥TV:= supA|µ(A)−π(A)|,
where the supremum is over measurable subsets of Ω. Let X= (Xt)t≥0be a Markov chain on Ω,
and let πdenote its equilibrium distribution. The (precision- ε)mixing time is
tmix(ε):= inf{t≥0|max x∈Ω∥Px[Xt∈ ·]−π∥TV≤ε}.
By convention, we abbreviate tmix:=tmix(1
4).
Theorem D.6 (Concentration) .LetX= (Xt)t≥0be a uniformly ergodic, irreducible Markov chain
on a state space Ω, started from its equilibrium distribution π. Lettmixdenote its1
4-mixing time.
Letf: Ω→Rbe a bounded function: ∥f∥∞<∞. Let π(f):=Eπ[f] =R
Ωfdπ andσ2
f:=
Varπ[f] =R
Ω(f−π(f))2dπdenote the mean and variance, respectively, of funder π.
Letζ >0andt≥0be an integer. Then,
Pπ1
tPt−1
s=0f(Xs)−π(f)≥ζ
≤2 exp
−ζ2t/tmix
16(1 + 2 tmix/t)σ2
f+ 80ζ∥f∥∞/t
.
In particular, if t≥max{32tmix,40ζσ2
f∥f∥∞}, then
Pπ1
tPt−1
s=0f(Xs)−π(f)≥ζ
≤2 exp 
−1
20σ−2
f·ζ2t/tmix
.
Remark D.7 (Connection to Curvature) .The following description applies to finite state spaces Ω;
we have to be more careful in our Elo application later, since that state space is uncountably infinite.
It is well known that curvature bounds the spectral gap λand relaxation time trel= 1/λin the
reversible case: λ≥κ,and hence trel= 1/λ≤κ−1.However, it also upper-bounds the mixing time
without requiring reversibility, with an additional factor depending on the diameter:
tmix(ε)≤κ−1 
log diam Ω + log(1 /ε)
,
assuming that d(x, y)≥1{x̸=y}. The argument for this is straight-forward: briefly,
P[Xt̸=Yt] =E[1{Xt̸=Yt}]≤E[d(Xt, Yt)]≤(1−κ)td(X0, Y0)≤e−κtdiam Ω ,
then use the standard TV–coupling relation. This can then be plugged into the previous concentration
bound, obtaining exponential decay in κt/log diam Ω .
Applying the theorem to the Elo process has a number of complications, primarily that it does not
have a finite mixing time: given the initial ratings, it is always supported on a certain countable
set; thus, its TV distance to equilibrium, which is continuously-supported, is 1(maximal). We
circumnavigate this by introducing a noisy version in the proof. This is detailed later.
Theorem D.8 (MCMC Convergence of Time Averages) .Letf:Rn→Rbe a1-Lipschitz function
andζ∈(0,1). Letµf:=Eπ[f]andσ2
f:=Varπ[f]denote, respectively, its mean and variance under
π, the unique invariant distribution of X. Fort, T > 0, denote the time average of fin[T, T+t−1]
At,T
f:=1
tPT+t−1
s=Tf(Xs).
Suppose that ∥f∥∞≤1
5t. LetC1, C2<∞. Then, there exists a constant C0<∞, depending only
onC1,C2andf, such that if
min{λq, η,1/t, ζ} ≥n−C1and min{t, T} ≥C0t⋆where t⋆:=e2Mη−1λ−1
qlogn,
then
P0[1
tPT+t−1
s=Tf(Xs)−µf≥C0ζ]≤n−C2+ 2 exp 
−σ−2
fζ2t/t⋆
.
In particular, under these assumptions, taking ζ≍σfp
t⋆logn/t=eMσflogn/p
ηλqt,
PAt,T
f−µf≥C0eMσf√ηlognp
λqt
≤n−C2.
22Remark D.9 (Convergence Rate) .IfX1, X2, ...were iid, then we would have 1/√
tdecay. Chernoff
bounds for reversible Markov chains require tto be replaced by λt, where λis the spectral gap.
The idea is that trel= 1/λsteps of the Markov chain are required to decorrelate terms when near
equilibrium. For non-reversible Markov chains, running for t⋆does the job.
Connecting this to the curvature κ, roughly, t⋆≲κ−1log diam Ω ifκ >0; see Remark D.7. The Elo
process is not reversible and we, in essence, bound t⋆≲κ−1lognandκ≍ηλq.
D.4 Concentration Proofs
Remark D.7 connects curvature and the mixing time for finite Markov chains: in essence, curvature
allows us to bring two copies exactly together. The Elo process, which lives in the continuum Rn,
does not have this property. We can get them extremely close, though. So, morally, the bound of
κ−1log diam Ω ≍λ−1
qlognon ‘mixing’ suggested by curvature feels correct.
We rigorise this idea by adding a small amount of independent noise to the ratings after every step.
This noise is then used to couple the two copies once they are extremely close.
Outline of Proof of Theorem D.8. The proof has multiple steps, which we outline now.
IApproximate the Elo process by a noisy version and control the error.
IICheck that the curvature of the noisy process is at least as good as the original.
IIIControl the mixing time, and hence concentration, of the noisy process.
IVUse a burn-in to get the process quantitatively close to equilibrium.
VCompare the equilibrium distributions for the original and noisy versions.
Finally, we bring all the piece together to conclude the proof, checking a variety of conditions. △
We approximate the Elo process by a noisy version. This circumnavigates issues surrounding the
discrete support of Xtversus the continuous support of its equilibrium distribution.
All the statements consist of generic constants C0, C1, C2<∞. Rather than carry all these depen-
dencies, we make the specific (arbitrary) choice C1:= 5and exhibit a C2for which this works. The
results can easily be extended to the general set-up, albeit with more notation. With this in mind, let
δ:=n−24.
StepI: Noisy Version & Error. We consider the following noisy version Uof the Elo process X.
1.Suppose U0=u0. Draw u1/3according to an uncapped Elo step—i.e., as if M=∞—
started from u0. Suppose Players iandjwere chosen—i.e., {k∈[n]|u1/3
k̸=u0
k}={i, j}.
2.Draw ˜ui,˜uj∼iidUnif([−√
δ,+√
δ])independently of all else and set ˜uk:= 0 fork /∈
{i, j}. Set
u2/3:=u1/3+ ˜u.
3. Define U1:=u1by orthogonally projecting u2/3to[−M, M ]npreserving the sum.
Note that this does not preserve the zero-sum property, as ˜ui̸= ˜uj. We see later, though, that it is
important—crucial, even— for these additive noise terms to be taken independently.
We must control the error between the noisy and original versions. To do this, we use the trivial
coupling, as before: the same players and result is used. The error does not accumulate super-linearly
due to the contractive nature of the Elo update step, as we explain now.
Suppose that (X0, Y0) = (x, y)and generate (X1, Y1) = (x′, y′)from a single step of the trivial
Elo-update coupling. Suppose that Players iandjplay. Let s∈ {0,1}be the indicator that Player i
beats j—the ‘score’. Then,
x′
i=xi+η 
s−pi,j(x)
and y′
i=yi+η 
s−pi,j(y)
.
Subtracting the second from the first gives
x′
i−y′
i=xi−yi−η 
pi,j(x)−pi,j(y)
.
23Analogously,
x′
j−y′
j=xi−yj+η 
pi,j(x)−pi,j(y)
.
Subtracting these,
(x′
i−y′
i)−(x′
j−y′
j) = (xi−yi)−(xj−yj)−2η 
pi,j(x)−pi,j(y)
.
But,pi,j(z) =σ(zi−zj)andσis1-Lipschitz, so
xi−xj≤yi−yjif and only if pi,j(x)≤pi,j(y)
and
|pi,j(x)−pi,j(y)| ≤ |(xi−xj)−(yi−yj)|=|(xi−yi)−(xj−yj)|;
also,η≤1
2. Hence,
|(x′
i−y′
i)−(x′
j−y′
j)| ≤ |(xi−yi)−(xj−yj)| ≤ |xi−yi|+|xj−yj|.
Also, trivially,
|(x′
i−y′
i) + (x′
j−y′
j)|=|(xi−yi) + (xj−yj)| ≤ |xi−yi|+|xj−yj|,
since the Elo update is zero-sum. Combining these bounds,
|x′
i−y′
i|+|x′
j−y′
j|= max
|(x′
i−y′
i)−(x′
j−y′
j)|,|(x′
i−y′
i)+(x′
j−y′
j)|	
≤ |xi−yi|+|xj−yj|.
In other words, an Elo update does not increase the ℓ1distance between the two sets of ratings:
∥x′−y′∥1≤ ∥x−y∥1.
This actually immediately implies that the Elo process is non-negatively curved in ℓ1.
A consequences of this is that that error can only arise from the additive-noise step:
∥Xs−Us∥1≤ ∥Xs−1/2−Us−1/2∥1≤ ∥Xs−1−Us−1∥1+√
δ≤. . .≤s√
δ.
Iterating this completes Step I:
1
tPt−1
s=0∥Xs−Us∥1≤1
2t√
δ≤n−7deterministically . (I)
We can now work with the noisy version U, rather than the original version X. The key statistic for
our analysis is the curvature. This is not hurt by adding noise.
StepII: Curvature. We use the same coupling as before and the same noise in each process.
(i)Suppose that (U0, V0) = ( u0, v0). Draw (u1/3, v1/3)according to a single step of the
trivial Elo coupling started from (u0, v0). Suppose that Players iandjwere chosen.
(ii)Draw a single noise vector n—i.e., ˜ui,˜uj∼iidUnif([−√
δ,+√
δ])and˜uk:= 0 fork /∈
{i, j}. Set
u2/3:=u1/3+ ˜uand v2/3:=v1/3+ ˜u.
(iii) Define U1:=u1andV1:=v1by projecting to [−M, M ]npreserving the respective sums.
We have already shown that the trivial Elo coupling contracts. The added noise does not hurt:
∥u1−v1∥2≤ ∥u2/3−v2/3∥2≤ ∥u1/3−v1/3∥2.
Hence, the two-stage coupling contracts at least as well as the original, completing Step II:
E[∥U1−V1∥2]≤E[∥U1/3−V1/3∥2]≤(1−κ)∥U0−V0∥2. (II)
The reason for adding the noise is to be able to couple two systems UandV, and hence bound the
mixing time. We can then apply the general concentration result of Theorem D.6.
StepIII: Mixing Time. Suppose that (U0, V0) = ( u0, v0)with∥u0−v0∥∞≤δ. From this point,
we proceed via a slightly different coupling, replacing (i, ii, iii) with (i′, ii′, iii′), defined below.
24(i′)Suppose that (U0, V0) = ( u0, v0). Draw (u1/3, v1/3)according to a single step of the
trivial Elo coupling started from (u0, v0)without capping . Suppose that Players iandj
were chosen.
(ii′)Draw ˜uk∼Unif([−√
δ,+√
δ))and set ˜vk:= ˜uk+(u1/3
k−v1/3
k)∈[−√
δ,+√
δ]mod2√
δ
independently for k∈ {i, j}. (Here, “mod 2√
δ” means “adjusting by additive multiples of
2√
δas necessary so that ˜vk∈[−√
δ,+√
δ)”.) Set ˜uk,˜vk:= 0fork /∈ {i, j}. Set
u2/3:=u1/3+ ˜uand v2/3:=v1/3+ ˜v.
(iii′) Set U1:=u1:= Π M(u2/3)andV1:=v1:= Π M(v2/3).
If∥u0−v0∥∞≤δand Players iandjplay, leading to (u1/3, v1/3)under the Elo coupling, then
max{|u1/3
i−v1/3
i|,|u1/3
j−v1/3
j|} ≤3δ,
regardless of which player won. Hence, in the notation of the coupling,
u2/3
k≡u1/3
k+˜uk=v1/3
k+˜vk≡v2/3
kfor both k∈ {i, j}if˜ui,˜uj∈[−√
δ+3δ,+√
δ−3δ].
Say that a step is successful if this holds and fails otherwise. The probability of failure is at most
6√
δ. If it succeeds, then Players iandjare coupled and the bound of δon the ℓ∞norm is preserved.
We now iterate. Suppose that ∥U0−V0∥∞≤δ. and Players itandjtare chosen in step t. Let
τc:= inf
t≥0∪s≤t{it, jt}= [n]	
be the first time that all players have been chosen. If all the first τcsteps are successful, then all
players’ ratings are coupled. Call this event C; then, P[C |τc≤t]≥1−6√
δt.
It remains to analyse two times:
• the ‘burn-in’ time τbto get to ℓ∞norm at most δ, using coupling (i, ii, iii);
• the remaining ‘coupling time’ τcstarted after the burn in, using coupling (i′, ii′, iii′).
The first is easy to handle using curvature:
E[∥Ut−Vt∥∞]≤E[∥Ut−Vt∥2]≤e−κt∥U0−V0∥2≤e−κt·2Mn.
Thus,
P[τb> t]≤P[∥Ut−Vt∥∞> δ]≤E[∥Ut−Vt∥∞]/δ≤δift≥tδ:=κ−1log(2Mn/δ2).
The second is equally easy. Start with (U0, V0)such that |U0
i−V0
i| ≥1for all i. Now, if
∥Ut−Vt∥∞≤δ <1, then all players must have been chosen. Hence,
P[τc> t| C]≤P[∥Ut−Vt∥∞> δ]≤δift≥tδ=κ−1log(2Mn/δ2).
Letτ:= inf{t≥0|Ut=Vt}denote the coalesce time. Putting the above parts together,
P[τ >2tδ]≤P[τb> tδ] +P[τc> tδ] +P[Cc|τc≤tδ]≤2δ+ 6√
δtδ.
We have κ−1= 8e2Mη−1λ−1
q≤n11. So, recalling that δ=n−24, we have
6√
δtδ≤6n−12·n11·72 log n= 432 n−1logn≪1.
Hence, 2δ+ 6√
δtδ≤1
4. Also, δ=n−24andM≤1
2n, so
tδ=κ−1log(2Mn/δ2)≤8e2Mη−1λ−1
q·50 log n= 400 e2Mη−1λ−1
qlogn= 400 t⋆.
This completes Step III:
t⋆(1
4)≤t⋆(2δ+ 6√
δtδ)≤2tδ≤800t⋆= 800 e2Mη−1λ−1
qlogn. (III)
The general concentration result of Theorem D.6 applies only for a Markov chain started from
equilibrium. We start another chain Vfrom equilibrium and use a burn-in to get UandVclose,
quantified by curvature. The error between the time-averaged U- and V-sums is then small.
25StepIV: Burn-In. LetVbe a noisy Elo process, started from its equilibrium distribution—which will
differ from πslightly. Under the above coupling, which has contraction rate 1−κby (II),
PT+t−1
s=TE[∥Us−Vs∥1]≤PT+t−1
s=TE[∥Us−Vs∥2]≤P
s≥Te−κs·2Mn
≤4Mnκ−1e−κT≤δ1/3=n−8ifT≥Tδ:=κ−1log(2Mnκ−1/δ1/3).
Analogously to the previous step, this time using also κ−1≤n5, we have
Tδ=κ−1log(2Mnκ−1/δ)≤8e2Mη−1λ−1
q·31 log n≤250e2Mη−1λ−1
qlogn= 250 t⋆.
Also, t≥κ−1≥n. We can then deduce the estimate desired for Step IV:
E1
tPT+t−1
s=T∥Us−Vs∥1
≤δ1/3/t≤n−9ifT≥250t⋆. (IV)
StepV: Equilibrium Distributions. The original and noisy Elo processes have different equilibrium
distributions; call them πand˜π, respectively. Let YandVbe an original, respectively noisy, Elo
process started from π, respectively ˜π. Then, by the strong law of large numbers,
|π(f)−˜π(f)|= lim
k→∞1
kPL+k−1
ℓ=L(f(Yℓ)−f(Vℓ))almost surely for all L∈N.
In the curvature proof, we showed a ℓ2
2-contraction of 1−2κfor the Elo process; see Proposition D.4.
Adding the noise can increase the ℓ2distance squared by at most 10M√
δ. Hence,
dℓ:=E[∥Yℓ−Vℓ∥2
2]satisfies dℓ≤(1−2κ)dℓ−1+ 10M√
δ.
Iterating this,
dℓ≤ ··· ≤ 2Mn(1−2κ)ℓ+ 5M√
δκ−1≤6M√
δκ−1ifℓ≥L,
for some sufficiently large L. By Cauchy–Schwarz, E[∥Yℓ−Vℓ∥2]≤√dℓ.Hence,
E1
kPL+k−1
ℓ=L∥Yℓ−Vℓ∥2
≤1
kPL+k−1
ℓ=Lp
dℓ≤3δ1/4(M/κ)1/2.
Plugging this in above, for a 1-Lipschitz function f, using ∥ · ∥ 1≤√n∥ · ∥ 2, we obtain
|π(f)−˜π(f)| ≤δ1/4(10Mn/κ )1/2.
Finally, we observe that 10Mn/κ ≤n7, completing Step V:
|π(f)−˜π(f)| ≤n7/2δ1/4=n−5/2. (V)
We bring the previous give steps together to conclude the proof.
Conclusion of Proof of Theorem D.8. We use the following notation, inline with the above:
•Xis the original Elo process, started from an arbitrary initial condition;
•Uis the noisy Elo process, started from the same state as X—i.e., U0=X0;
•Vis the noisy Elo process, started from equilibrium ˜π.
Recall that ∥f∥Lip≤1. This with the triangle inequality allows us to control the steps individually:
1
tPT+t−1
s=Tf(Xs)−π(f)
≤1
tPT+t−1
s=T∥Xs−Us∥1 Step I
+1
tPT+t−1
s=T∥Us−Vs∥1 Step IV
+1
tPT+t−1
s=Tf(Vs)−˜π(f) Step III
+˜π(f)−π(f) Step V
The first term is at most1
2t√
δ≤n−7deterministically by Step Iand the last is at most n7/2δ1/4=
n−5/2byStep V. The second term is at most δ1/3/n=n−9in expectation by Step IV, which we
plug into Markov’s inequality. We assume that ζ≥n−2, so that each of the first two terms is smaller
26thanζ, and n−5/ζ≤n−3. The remaining term is controlled via the general concentration result of
Theorem D.6, using the bound t⋆(1
4)≤800t⋆= 800 e2Mη−1λ−1
qlognfrom Step III. Hence,
P1
tPT+t−1
s=Tf(Xs)−π(f)>9ζ
≤P1
tPT+t−1
s=TUs−1
tPT+t−1
s=TVs
1> ζ
+P1
tPT+t−1
s=Tf(Vs)−π(f)>5ζ
≤n−6+ 2 exp 
−σ−2
fζ2t/t⋆
.
We can apply Theorem D.6 if t≥25600 t⋆= 32·800t⋆due to Step IIIandStep IVifT≥250t⋆.
Finally, we make a specific choice of ζ. There is already a polynomial term in the error probability,
so we want to choose ζas small as possible whilst preserving this. Thus, we take
ζ:= 2σfp
t⋆logn/t= 2eMlogn/p
ηλqt.
D.5 Deduction of Theorem 2.5 from Theorems 2.7 and D.8
We start by recalling Theorem 2.5 for the reader’s convenience, numbered here as Theorem D.10.
Theorem D.10 (MCMC Estimator of Time-Averaged Ratings; Theorem 2.5) .Denote the time-
averaged rating
At,T
k:=1
tPT+t−1
s=TXs
kfork∈[n]and t, T > 0.
LetC1, C2<∞. Then, there exists a constant C0<∞, depending only on C1andC2, such that if
min{λq, η,1/t} ≥n−C1and min{t, T} ≥C0t⋆where t⋆:=e2Mη−1λ−1
qlogn,
then
P
1
n∥At,T−ρ∥2
2≤C0e4M
λqn
η+(logn)2
λqt
≥1−n−C2.
The same result holds for1
n∥At,T−ρ∥1,the average distance in the ℓ1(rather than ℓ2) sense.
Proof of Theorem 2.5/D.10. The two terms inside the probability come from the MCMC-convergence
error and the equilibrium-distribution bias. We use the abbreviations
At
k:=1
tPT+t−1
s=TXs
k, β k:=|π(Πk)−ρk|and σ2
k:=σ2
Πk=Varπ[Πk],
where Πk:Rn→Ris the k-th projector. We separate the MCMC and bias parts:
∥At−ρ∥2
2≤2∥At−π(Π)∥2
2+ 2∥π(Π)−ρ∥2
2.
For the bias part, we simply note for now that
∥π(Π)−ρ∥2
2=P
k|π(Πk)−ρk|2=P
kβ2
k=:n¯β2.
We now turn to the MCMC time-averages. Applying Theorem D.8 with f:= Π k,
PAt,T
k−π(Πk)≥C0eMσklogn/p
ηλqt
≤n−C2,
under the assumptions of that theorem. We perform a union bound over the nplayers:
P1
n∥At,T−π(Π)∥2
2≥C0e2M¯σ2(logn)2/(ηλqt)
≤n−C2+1where ¯σ2:=1
nP
k∈[n]σ2
k.
These bias and (average) variance terms are exactly what we handled in Theorem 2.7:
¯β2≤4e4Mη/(λqn)and ¯σ2≤4e2Mη/(λqn).
The first part of Theorem 2.5 now follows from plugging these in above and some small manipulations.
To obtain the 1/(λqt)decay, we just need to check that t≫t⋆:
t⋆
t=e2Mλ−1
qlogn
ηt≍e2Mλ−1
qlogn
λ−1q(logn)2=e2M
logn≪1.
27E Convergence Proofs: Parallel Matches
Our previous bounds on the bias and the variance included the spectral gap λqobtained from
sequential analysis—namely, we usedP
eqe= 1. These expressions change in the parallel set-up.
This has a knock-on effect on the two terms in Theorem 2.5.
We now state an extended version of Theorem 3.3.
Theorem E.1. Denote the time-averaged rating
At,T
k:=1
tPT+t−1
s=TXs
kfork∈[n]and t, T > 0,
where Xsis the state after s≥0Elorounds . Then, under the conditions of Theorem 2.5,
P
1
n∥At,T−ρ∥2
2≤Ce4M
λqn/N
η+(logn)2
λqt
= 1−o(1),
where N:=P
e∈Eqeis the mean size of the matching; to emphasise, here, tandTcount rounds .
Moreover, there exists a distribution ˜q= (˜qS)S∈Mover matchings whose induced distribution
q= (qe)e∈Eover pairs satisfies λq≥1
3λ⋆
disc. In particular,
∥At,T−ρ∥⋆≲e2Mlognp
λ⋆
discn/N1p
λ⋆
disctwhp ifη≍(logn)2
λ⋆
disct.
We separate the proof of Theorem E.1 into two parts: the convergence and the existence of a
parallelisable qwithλq≥1
3λ⋆
disc. The “in particular” part follows exactly as for Theorem 2.5.
Proof of Theorem E.1: Convergence. Write ¯β2:=1
n∥π(Π)−ρ∥2
2and¯σ2:=1
nP
kVarπ[Πk]for the
average ℓ2-bias and variance of the ratings, respectively, as we did in the deduction of Theorem 2.5.
The analysis of the bias is unchanged until we average over the choice {i, j}of players. Then, we
implicitly usedP
eqe= 1when averaging 2η2over{i, j}. Letting N:=P
eqe=ES∼˜q[|S|]denote
the expected size of the random matching ˜qcorresponding to q, the same analysis gives
Ex
∥X1/2−ρ∥2
2
≤ ∥x−ρ∥2
2+ 2Nη2−1
2e−4MηP
i,jq{i,j}|(xi−ρi)−(xj−ρj)|2.
Inspecting the analysis of the variance to see whereP
eqe= 1is used, we get
P
kVar[X1/2
k]≤P
kVar[X0
k] +3
2Nη2−1
2e−2MηλqP
kVar[X0
k].
The proofs then proceed as before to give the bounds
¯β2≤4e4MηN/(λqn)and ¯σ2≤3e2MηN/(λqn).
The argument for the deduction of Theorem 2.5 gives
P1
n∥At,T−ρ∥2
2≤C0(¯β2+ ¯σ2/(ηλqt)
≥1−n−C2;
now, (t, T)inAt,Tcorrespond to the number of rounds and qmay haveP
eqe>1—and, so, λq
may be larger than 1/n, but not than N/n . Plugging in the new bounds for ¯βand¯σ,
P
1
n∥At,T−ρ∥2
2≤C0e4M
λqn/N
η+(logn)2
λqt
≥1−n−C2.
Proof of Theorem E.1: λq≳λ⋆
disc.Letqbe an optimiser of λ⋆
disc:λq=λ⋆
disc. It can be formulated as
a semidefinite program [ 10], so its solution can be approximated arbitrarily well in polynomial time.
Extending qfrom Eto[n]2byqi,j:=q{i,j}1{{i, j} ∈E}defines a symmetric and substochatic
matrix with the same Dirichlet form. Adjusting the diagonal has no effect on the Dirichlet form, so
we may assume that it is, in fact, stochastic: its row sums are all exactly 1. The spectral gp of this qis
stillλq, by the Dirichlet characterisation (Proposition B.1).
The Birkhoff–von Neumann theorem allows the decomposition of any n×ndoubly stochastic matrix
into a convex combination of (at most) n2permutation matrices in polynomial time:
q=Pn2
ℓ=1αℓPσℓ
28where α∈[0,1]n2withP
ℓαℓ= 1andPσis the permutation matrix for σ∈Symm (n):
(Pσ)i,j=1{j=σ(i)}for all i, j∈[n].
This can be chosen so that each permutation matrix has non-zero entries only over graph edges.
Given a permutation σi, we decompose it into disjoint cycles. These cycles actually correspond to
cycles in the graph; we can discard cycles with only one element. Let v1, v2, ..., v kbe the vertices of
a particular cycle of length k. Then, we can decompose the cycle into three matchings:
• one containing all the edges in the cycle of type {vi, vi+1}with odd i∈ {1, ..., k−1};
• one containing all the edges in the cycle of type {vi, vi+1}with even i∈ {1, ..., k−1};
• one matching containing the single edge {vk, v1}.
This decomposition gives rise to a procedure to sample matchings in the graph.
1.Sample a permutation Σaccording to the convex combination: P[Σ = σℓ] =αℓfor each ℓ.
2.For each cycle in Σ, independently sample one of the three induced matchings listed above,
each with probability 1/3.
The vertices in different cycles in a permutation are distinct. Hence, this procedure does indeed
product a matching. Moreover, the probability that a given edge {i, , j} ∈Ebelongs to the sampled
matching is precisely1
3qi,j=1
3q{i,j}. Hence, we have constructed a matching with associated
spectral gap at least1
3λq. But, by assumption, λq=λ⋆
disc, completing the proof.
29NeurIPS Paper Checklist
1.Claims
Question: Do the main claims made in the abstract and introduction accurately reflect the
paper’s contributions and scope?
Answer: [Yes]
Justification: the abstract and introduction make clear the contributions of our paper.
Guidelines:
•The answer NA means that the abstract and introduction do not include the claims
made in the paper.
•The abstract and/or introduction should clearly state the claims made, including the
contributions made in the paper and important assumptions and limitations. A No or
NA answer to this question will not be perceived well by the reviewers.
•The claims made should match theoretical and experimental results, and reflect how
much the results can be expected to generalize to other settings.
•It is fine to include aspirational goals as motivation as long as it is clear that these goals
are not attained by the paper.
2.Limitations
Question: Does the paper discuss the limitations of the work performed by the authors?
Answer: [Yes]
Justification: We discuss limitations of our work in the introduction and clearly state the
assumptions of our results.
Guidelines:
•The answer NA means that the paper has no limitation while the answer No means that
the paper has limitations, but those are not discussed in the paper.
• The authors are encouraged to create a separate "Limitations" section in their paper.
•The paper should point out any strong assumptions and how robust the results are to
violations of these assumptions (e.g., independence assumptions, noiseless settings,
model well-specification, asymptotic approximations only holding locally). The authors
should reflect on how these assumptions might be violated in practice and what the
implications would be.
•The authors should reflect on the scope of the claims made, e.g., if the approach was
only tested on a few datasets or with a few runs. In general, empirical results often
depend on implicit assumptions, which should be articulated.
•The authors should reflect on the factors that influence the performance of the approach.
For example, a facial recognition algorithm may perform poorly when image resolution
is low or images are taken in low lighting. Or a speech-to-text system might not be
used reliably to provide closed captions for online lectures because it fails to handle
technical jargon.
•The authors should discuss the computational efficiency of the proposed algorithms
and how they scale with dataset size.
•If applicable, the authors should discuss possible limitations of their approach to
address problems of privacy and fairness.
•While the authors might fear that complete honesty about limitations might be used by
reviewers as grounds for rejection, a worse outcome might be that reviewers discover
limitations that aren’t acknowledged in the paper. The authors should use their best
judgment and recognize that individual actions in favor of transparency play an impor-
tant role in developing norms that preserve the integrity of the community. Reviewers
will be specifically instructed to not penalize honesty concerning limitations.
3.Theory Assumptions and Proofs
Question: For each theoretical result, does the paper provide the full set of assumptions and
a complete (and correct) proof?
Answer: [Yes]
Justification: complete proofs are included in the Appendix. An outline of the proof of our
main result is included in the main body of the text.
30Guidelines:
• The answer NA means that the paper does not include theoretical results.
•All the theorems, formulas, and proofs in the paper should be numbered and cross-
referenced.
•All assumptions should be clearly stated or referenced in the statement of any theorems.
•The proofs can either appear in the main paper or the supplemental material, but if
they appear in the supplemental material, the authors are encouraged to provide a short
proof sketch to provide intuition.
•Inversely, any informal proof provided in the core of the paper should be complemented
by formal proofs provided in appendix or supplemental material.
• Theorems and Lemmas that the proof relies upon should be properly referenced.
4.Experimental Result Reproducibility
Question: Does the paper fully disclose all the information needed to reproduce the main ex-
perimental results of the paper to the extent that it affects the main claims and/or conclusions
of the paper (regardless of whether the code and data are provided or not)?
Answer: [Yes]
Justification: in the main body of the paper, we include enough details in order to repro-
duce our experimental results. The supplementary material includes our code so that our
experiments can be reproduced and verified.
Guidelines:
• The answer NA means that the paper does not include experiments.
•If the paper includes experiments, a No answer to this question will not be perceived
well by the reviewers: Making the paper reproducible is important, regardless of
whether the code and data are provided or not.
•If the contribution is a dataset and/or model, the authors should describe the steps taken
to make their results reproducible or verifiable.
•Depending on the contribution, reproducibility can be accomplished in various ways.
For example, if the contribution is a novel architecture, describing the architecture fully
might suffice, or if the contribution is a specific model and empirical evaluation, it may
be necessary to either make it possible for others to replicate the model with the same
dataset, or provide access to the model. In general. releasing code and data is often
one good way to accomplish this, but reproducibility can also be provided via detailed
instructions for how to replicate the results, access to a hosted model (e.g., in the case
of a large language model), releasing of a model checkpoint, or other means that are
appropriate to the research performed.
•While NeurIPS does not require releasing code, the conference does require all submis-
sions to provide some reasonable avenue for reproducibility, which may depend on the
nature of the contribution. For example
(a)If the contribution is primarily a new algorithm, the paper should make it clear how
to reproduce that algorithm.
(b)If the contribution is primarily a new model architecture, the paper should describe
the architecture clearly and fully.
(c)If the contribution is a new model (e.g., a large language model), then there should
either be a way to access this model for reproducing the results or a way to reproduce
the model (e.g., with an open-source dataset or instructions for how to construct
the dataset).
(d)We recognize that reproducibility may be tricky in some cases, in which case
authors are welcome to describe the particular way they provide for reproducibility.
In the case of closed-source models, it may be that access to the model is limited in
some way (e.g., to registered users), but it should be possible for other researchers
to have some path to reproducing or verifying the results.
5.Open access to data and code
Question: Does the paper provide open access to the data and code, with sufficient instruc-
tions to faithfully reproduce the main experimental results, as described in supplemental
material?
31Answer: [Yes]
Justification: code is included in the supplementary material.
Guidelines:
• The answer NA means that paper does not include experiments requiring code.
•Please see the NeurIPS code and data submission guidelines ( https://nips.cc/
public/guides/CodeSubmissionPolicy ) for more details.
•While we encourage the release of code and data, we understand that this might not be
possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not
including code, unless this is central to the contribution (e.g., for a new open-source
benchmark).
•The instructions should contain the exact command and environment needed to run to
reproduce the results. See the NeurIPS code and data submission guidelines ( https:
//nips.cc/public/guides/CodeSubmissionPolicy ) for more details.
•The authors should provide instructions on data access and preparation, including how
to access the raw data, preprocessed data, intermediate data, and generated data, etc.
•The authors should provide scripts to reproduce all experimental results for the new
proposed method and baselines. If only a subset of experiments are reproducible, they
should state which ones are omitted from the script and why.
•At submission time, to preserve anonymity, the authors should release anonymized
versions (if applicable).
•Providing as much information as possible in supplemental material (appended to the
paper) is recommended, but including URLs to data and code is permitted.
6.Experimental Setting/Details
Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
results?
Answer: [Yes]
Justification: we have included our choice of parameters in the paper.
Guidelines:
• The answer NA means that the paper does not include experiments.
•The experimental setting should be presented in the core of the paper to a level of detail
that is necessary to appreciate the results and make sense of them.
•The full details can be provided either with the code, in appendix, or as supplemental
material.
7.Experiment Statistical Significance
Question: Does the paper report error bars suitably and correctly defined or other appropriate
information about the statistical significance of the experiments?
Answer: [Yes]
Justification: we include confidence intervals in the plots of our experiments. Statistical
significance tests are not really relevant for our experimental results.
Guidelines:
• The answer NA means that the paper does not include experiments.
•The authors should answer "Yes" if the results are accompanied by error bars, confi-
dence intervals, or statistical significance tests, at least for the experiments that support
the main claims of the paper.
•The factors of variability that the error bars are capturing should be clearly stated (for
example, train/test split, initialization, random drawing of some parameter, or overall
run with given experimental conditions).
•The method for calculating the error bars should be explained (closed form formula,
call to a library function, bootstrap, etc.)
• The assumptions made should be given (e.g., Normally distributed errors).
•It should be clear whether the error bar is the standard deviation or the standard error
of the mean.
32•It is OK to report 1-sigma error bars, but one should state it. The authors should
preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis
of Normality of errors is not verified.
•For asymmetric distributions, the authors should be careful not to show in tables or
figures symmetric error bars that would yield results that are out of range (e.g. negative
error rates).
•If error bars are reported in tables or plots, The authors should explain in the text how
they were calculated and reference the corresponding figures or tables in the text.
8.Experiments Compute Resources
Question: For each experiment, does the paper provide sufficient information on the com-
puter resources (type of compute workers, memory, time of execution) needed to reproduce
the experiments?
Answer: [No]
Justification: the computer resources are not really relevant for interpreting our experiments.
We include the number of games simulated which is a better way to measure the complexity
of the algorithm analysed.
Guidelines:
• The answer NA means that the paper does not include experiments.
•The paper should indicate the type of compute workers CPU or GPU, internal cluster,
or cloud provider, including relevant memory and storage.
•The paper should provide the amount of compute required for each of the individual
experimental runs as well as estimate the total compute.
•The paper should disclose whether the full research project required more compute
than the experiments reported in the paper (e.g., preliminary or failed experiments that
didn’t make it into the paper).
9.Code Of Ethics
Question: Does the research conducted in the paper conform, in every respect, with the
NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines ?
Answer: [Yes]
Justification: we have read the NeurIPS Code of Ethics and our paper conform to it.
Guidelines:
•The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
•If the authors answer No, they should explain the special circumstances that require a
deviation from the Code of Ethics.
•The authors should make sure to preserve anonymity (e.g., if there is a special consid-
eration due to laws or regulations in their jurisdiction).
10.Broader Impacts
Question: Does the paper discuss both potential positive societal impacts and negative
societal impacts of the work performed?
Answer: [NA]
Justification: we do not foresee any particular societal impact of our paper.
Guidelines:
• The answer NA means that there is no societal impact of the work performed.
•If the authors answer NA or No, they should explain why their work has no societal
impact or why the paper does not address societal impact.
•Examples of negative societal impacts include potential malicious or unintended uses
(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
(e.g., deployment of technologies that could make decisions that unfairly impact specific
groups), privacy considerations, and security considerations.
•The conference expects that many papers will be foundational research and not tied
to particular applications, let alone deployments. However, if there is a direct path to
any negative applications, the authors should point it out. For example, it is legitimate
to point out that an improvement in the quality of generative models could be used to
33generate deepfakes for disinformation. On the other hand, it is not needed to point out
that a generic algorithm for optimizing neural networks could enable people to train
models that generate Deepfakes faster.
•The authors should consider possible harms that could arise when the technology is
being used as intended and functioning correctly, harms that could arise when the
technology is being used as intended but gives incorrect results, and harms following
from (intentional or unintentional) misuse of the technology.
•If there are negative societal impacts, the authors could also discuss possible mitigation
strategies (e.g., gated release of models, providing defenses in addition to attacks,
mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
feedback over time, improving the efficiency and accessibility of ML).
11.Safeguards
Question: Does the paper describe safeguards that have been put in place for responsible
release of data or models that have a high risk for misuse (e.g., pretrained language models,
image generators, or scraped datasets)?
Answer: [NA]
Justification: the paper poses no such risks.
Guidelines:
• The answer NA means that the paper poses no such risks.
•Released models that have a high risk for misuse or dual-use should be released with
necessary safeguards to allow for controlled use of the model, for example by requiring
that users adhere to usage guidelines or restrictions to access the model or implementing
safety filters.
•Datasets that have been scraped from the Internet could pose safety risks. The authors
should describe how they avoided releasing unsafe images.
•We recognize that providing effective safeguards is challenging, and many papers do
not require this, but we encourage authors to take this into account and make a best
faith effort.
12.Licenses for existing assets
Question: Are the creators or original owners of assets (e.g., code, data, models), used in
the paper, properly credited and are the license and terms of use explicitly mentioned and
properly respected?
Answer:[Yes]
Justification: our code uses an existing library to compute a von Neumann-Birkhoff de-
composition of a matrix. We have included the library and its licence in the supplementary
material.
Guidelines:
• The answer NA means that the paper does not use existing assets.
• The authors should cite the original paper that produced the code package or dataset.
•The authors should state which version of the asset is used and, if possible, include a
URL.
• The name of the license (e.g., CC-BY 4.0) should be included for each asset.
•For scraped data from a particular source (e.g., website), the copyright and terms of
service of that source should be provided.
•If assets are released, the license, copyright information, and terms of use in the
package should be provided. For popular datasets, paperswithcode.com/datasets
has curated licenses for some datasets. Their licensing guide can help determine the
license of a dataset.
•For existing datasets that are re-packaged, both the original license and the license of
the derived asset (if it has changed) should be provided.
•If this information is not available online, the authors are encouraged to reach out to
the asset’s creators.
13.New Assets
34Question: Are new assets introduced in the paper well documented and is the documentation
provided alongside the assets?
Answer: [NA]
Justification: no new assets released. Code included for reproducibility has been commented
and include a README file.
Guidelines:
• The answer NA means that the paper does not release new assets.
•Researchers should communicate the details of the dataset/code/model as part of their
submissions via structured templates. This includes details about training, license,
limitations, etc.
•The paper should discuss whether and how consent was obtained from people whose
asset is used.
•At submission time, remember to anonymize your assets (if applicable). You can either
create an anonymized URL or include an anonymized zip file.
14.Crowdsourcing and Research with Human Subjects
Question: For crowdsourcing experiments and research with human subjects, does the paper
include the full text of instructions given to participants and screenshots, if applicable, as
well as details about compensation (if any)?
Answer: [NA]
Justification: the paper does not involve crowdsourcing nor research with human subjects.
Guidelines:
•The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
•Including this information in the supplemental material is fine, but if the main contribu-
tion of the paper involves human subjects, then as much detail as possible should be
included in the main paper.
•According to the NeurIPS Code of Ethics, workers involved in data collection, curation,
or other labor should be paid at least the minimum wage in the country of the data
collector.
15.Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
Subjects
Question: Does the paper describe potential risks incurred by study participants, whether
such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
approvals (or an equivalent approval/review based on the requirements of your country or
institution) were obtained?
Answer: [NA]
Justification: the paper does not involve crowdsourcing nor research with human subjects.
Guidelines:
•The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
•Depending on the country in which research is conducted, IRB approval (or equivalent)
may be required for any human subjects research. If you obtained IRB approval, you
should clearly state this in the paper.
•We recognize that the procedures for this may vary significantly between institutions
and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
guidelines for their institution.
•For initial submissions, do not include any information that would break anonymity (if
applicable), such as the institution conducting the review.
35