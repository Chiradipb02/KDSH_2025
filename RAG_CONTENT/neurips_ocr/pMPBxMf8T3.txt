The Implicit Bias of Heterogeneity towards Invariance:
A Study of Multi-Environment Matrix Sensing
Yang Xu∗
School of Mathematical Sciences
Peking University
xuyang1014@pku.edu.cn
Yihong Gu∗
Department of Operations Research and Financial Engineering
Princeton University
yihongg@princeton.edu
Cong Fang†
School of Intelligence Science and Technology
Peking University
fangcong@pku.edu.cn
Abstract
Models are expected to engage in invariance learning, which involves distinguish-
ing the core relations that remain consistent across varying environments to ensure
the predictions are safe, robust and fair. While existing works consider specific
algorithms to realize invariance learning, we show that model has the potential to
learn invariance through standard training procedures. In other words, this paper
studies the implicit bias of Stochastic Gradient Descent (SGD) over heterogeneous
data and shows that the implicit bias drives the model learning towards an invariant
solution. We call the phenomenon the implicit invariance learning . Specifically,
we theoretically investigate the multi-environment low-rank matrix sensing prob-
lem where in each environment, the signal comprises (i) a lower-rank invariant
part shared across all environments; and (ii) a significantly varying environment-
dependent spurious component. The key insight is, through simply employing
the large step size large-batch SGD sequentially in each environment without any
explicit regularization, the oscillation caused by heterogeneity can provably prevent
model learning spurious signals. The model reaches the invariant solution after
certain iterations. In contrast, model learned using pooled SGD over all data would
simultaneously learn both the invariant and spurious signals. Overall, we unveil
another implicit bias that is a result of the symbiosis between the heterogeneity of
data and modern algorithms, which is, to the best of our knowledge, first in the
literature.
1 Introduction
In real applications, the machine learning models are often heavily over-parameterized, which
means that the number of parameters exceeds the number of data. For over-parameterized models,
∗Equal Contribution.
†Corresponding author.
38th Conference on Neural Information Processing Systems (NeurIPS 2024).Algorithm 1 PooledSGD
Parameter: θ
fort= 1, . . .do
Batch Bfrom entire dataset
Update θ←θ−η∇L(θ;B)
end forAlgorithm 2 HeteroSGD
Parameter: θ
fort= 1, . . .do
Batch Bfrom environment et∼D
Update θ←θ−η∇L(θ;B)
end for
ItersValueCore/uni00A0Signal
Spurious/uni00A0Signal
ItersValueCore/uni00A0Signal
Spurious/uni00A0Signal
Figure 1: An illustration comparing training from aggregated data versus from heterogeneous data.
The left example resembles the case where the model is trained on complete datasets, resulting in a
stable spurious signal that the model tends to fit. The right example simulates a two-environment
case where the spurious signal changes at each step. This oscillation creates a contraction effect,
preventing the model from fitting the spurious signal.
the generalization in the general case becomes ill-posed. One key insight to generalize well is
the implicit preference of the optimization algorithm which plays the role of regularization/bias
[45,22]. Nowadays, there are several kinds of implicit bias discovered from optimization algorithms
under different models and settings. One common feature of the bias is the simplicity which
concludes that (stochastic) gradient-based algorithms perform the incremental learning with the
model complexity gradually increasing. Therefore, benign generalization is possible even when
the number of training data is limited. For example, Li et al. [31], Gunasekar et al. [18] show
that unregularized gradient descent can find the low-rank solution efficiently for matrix sensing
models. Kalimeris et al. [27], Gissin et al. [16], Jiang et al. [24], and Jin et al. [25] further show that
(Stochastic) Gradient Descent ((S)GD) learn models from simple ones to complex ones. Most of the
existing works study the implicit bias of algorithms over a single distributional environment data.
However, data in modern practice are often collected from multiple sources, thus exhibiting certain
heterogeneity. For example, medical data may come from multiple hospitals, and training sets for
large language models consist of numerous corpus from the Internet [ 1]. So what is the impact of
implicit bias for standard training algorithms over heterogeneous data?
This paper initializes the study and shows that implicit bias of SGD on an over-parameterized model
using multi-environment heterogeneous data and shows that the implicit bias can not only save the
number of training data but also, more importantly, drive the model learning the invariant relation
across diverse environments.
Learning the invariant relation that remains consistent across varying environments [ 43] has garnered
significant attention in recent years. Though the association-based standard machine learning pipelines
can achieve a good performance with identical data distributions, a higher requirement is to make
predictions robustly generalize over diverse downstream environments. Learning invariance produces
reliable, fair, robust predictions against strong structural mechanism perturbation. More importantly,
it opens the door to pursue causality blind to any prior knowledge and can unveil direct causes
when the heterogeneity among environments is sufficient [ 17,43]. While existing works consider
specific algorithms to realize invariance learning, this work shows that implicit bias of algorithms over
heterogeneous data has the potential to automatically learn the invaraince. We call the phenomenon the
implicit invariance learning , partially explains why active invariance learning may not be necessary
in practice [42]. Our key insight is:
2The heterogeneity of the data, and the large step size adopted in the optimization
algorithm jointly provide strong multiplicative oscillations in the spurious signal
space, which prevents the model from moving in the direction of unstable and
spurious solutions, thus resulting in an implicit bias to the invariant solution.
We illustrate it rigorously through a simple, canonical but insightful model – multi-environment matrix
sensing, where in each environment the signal consists of two parts: an invariant low-rank matrix
A⋆∈Rd×dand an environment-varying spurious low-rank matrix A(e)∈Rd×dwhere environment
e∈ E, the set of environments. For each environment e∈ E, the joint distribution of (X(e), y(e))
satisfies y(e)=⟨X(e),A⋆⟩+⟨X(e),A(e)⟩with matrix inner product ⟨A,B⟩= Trace( B⊤A). Here
X(e)∈Rd×dis a random linear measurement and y(e)∈Ris the response. We consider the case that
association does not coincide invariance (or causality), where averaging over all the environments,
the best prediction of ygivenXis
f⋆(X) = ⟨X,A⋆⟩|{z}
invariant part+⟨X,Ee[A(e)]⟩|{z}
spurious partwith Ee[A(e)]̸= 0.
In this case, it is not surprising that given enough data, the standard empirical risk minimizer
algorithm, for example, running SGD on pooled data, will return a solution that converges to f⋆,
which diverges from the invariant solution. In this paper, we will show that surprisingly, if each batch
is sampled from data in one environment rather than data in all the environments, the heterogeneity
in the environments together with the implicit regularization effects in the SGD algorithm can drive it
towards the invariant solution. This can be stated informally as follows.
Theorem 1 (Main result, informal) .Under a sufficient heterogeneity condition and some regularity
conditions in matrix sensing, if we adopt an over-parameterized model and runs stochastic gradient
descent where batches are sampled from one environment, i.e., HeteroSGD (Algorithm 3), then
∥ˆθHeteroSGD −A⋆∥F=oP(1).
Instead, the standard approach, i.e., PooledSGD , will return solution ˆθPooledSGD satisfying
∥ˆθPooledSGD −A⋆−As∥F=oP(1) thus ∥ˆθPooledSGD −A⋆∥F= ΩP(1).
An illustration of our result is shown in Figure 1. Our result demonstrates that implicit bias of
commonly used algorithms over heterogeneous data has the potential to drive the model to learn the
invariant relation. Such a result thereby provides an explanation for why models may attain some
robust and even causal prediction after SGD training.
We emphasize that the previous implicit bias studies are restricted to the same data distribution
generalization, under which the population-level minimizer f⋆minimizing the loss with infinite data
is the target in pursuit. However, both the population-level minimizer and those “good” solutions
under previous studies diverge from an invariant solution in general and are no longer benign in this
context, this is termed as “curse of endogeneity” [12, 13].
Notations. We use the conventional notations O(·), o(·),Ω(·)to ignore the absolute constants,
˜O(·),˜o(·),˜Ω(·)to further ignore the polynomial logarithmic factors. Similarly, a≲bmeans that
there exists an absolute constant C > 0such that a≲Cb. We also denote it as a≪b,b≫aif
a=o(b). Unless otherwise specified, we use lowercase bold letters such as vto represent vectors,
and use ∥v∥to denote its Euclidean norm. We use uppercase bold letters such as Xto represent
matrices and use ∥X∥,∥X∥F,∥X∥∗to denote its operator norm, Frobenius norm and nuclear norm,
respectively. We use κ(X)to denote the condition number, which is σmax(X)/σmin(X). We define
Z=oP(1)if the random variable Zsatisfies ZP→0.
2 Related Works
Implicit Regularization. It is believed that implicit bias is a key factor in why over-parameterized
models can generalize well. Through the analysis of certain settings, existing results suggest that
GD/SGD prefers solutions with specific properties [ 45,19,41,38,23], or specific local landscapes
[3,9,32,38]. For the matrix sensing problem, several works [ 18,31,27,16,46,52,24,25] analyze
3the (S)GD dynamics to show how (S)GD recovers the ground truth low-rank matrix. Recently, the
effects of large step size have aroused much attention, particularly the edge-of-stability phenomenon
[8]. Lu et al. [37] investigates the phenomenon “benign oscillation”, which suggests that SGD with
a large learning rate can effectively help neural networks learn weak features thereby benefiting
generalization. Several works [ 20,48,11] show that label noise with large step size has a sparcifying
effect for sparse linear regression. This paper instead studies multi-environment scenarios and fills in
the understanding of the impact of randomness on matrix sensing problems.
Federated Learning. Federated learning [ 39,26] is a machine learning paradigm where data is
stored separately and locally on multiple clients and not exchanged, and clients collaboratively train a
model. Extensive work has focused on designing effective decentralized algorithms (e.g. [ 39,29])
while preserving privacy (e.g. [ 10,7]). The importance of fairness in federated learning has also
garnered attention [ 30,33]. One important issue in federated learning is to handle the heterogeneity
across the data and hardware. Our work shows that by training with certain stochastic gradient descent
methods, the system can automatically remove the bias from the individual environment and thus
learn the invariant features. Our work provides insights into discovering the implicit regularization
effects of standard decentralized algorithms.
Invariance Learning. This research line initiates from causal inference literature [ 43,40,15] since
invariant covariates correspond to direct cause . From theoretic aspects, Fan et al. [13] proposes the
EILLS method that provably achieves invariant variable selections under mild conditions for linear
models. Invariance learning has raised much attention in machine learning since Arjovsky et al. [2]
proposes the structural-agnostic framework IRM. Subsequent works analyze its limitations [ 44,28] or
propose variant methods [ 50,36,34,35,21,51] as regularization and reweighting. About the failure
of classical methods, Wald et al. [49] construct a hard problem and show that interpolation-based
methods fail to learn invariance.
To the best of our knowledge, all the existing works consider specific algorithms to realize invariance
learning or constructing hard cases that classical methods fail. In contrast, this paper studies
commonly used training algorithms and aims to understand how the algorithms can go beyond
learning associations to achieve invariance learning in certain scenarios.
3 Main Results
3.1 Problem Formulation
Data Generating Process. Suppose we observe data from a set of environments Esequentially. Let
Dbe some distribution on E. At each time t= 0,1, . . . , we receive msamples {(X(et)
i, y(et)
i)}m
i=1⊂
Rd×d×Rfrom environment et∼Dsatisfying
y(et)
i=⟨X(et)
i,A⋆⟩+⟨X(et)
i,A(et)⟩, i= 1, . . . m, (1)
where A⋆is an unknown rank r1d×dsymmetric and positive definite matrix that represents the
true signal invariant across different environments, A(et)is an unknown d×dsymmetric matrix
with rank at most r2that represents the spurious signal that may vary. Here ⟨A,B⟩= trace( B⊤A).
We aim to estimate the A⋆using data from heterogeneous environments.
Algorithm. We consider running batch gradient descent on an over-parametrization of the model,
where at each step tone gradient update is performed using the data from environment et. To
be specific, we parameterize our fitted model as y=⟨A,UU⊤⟩with a d×dmatrix Ufor the
sake of simplicity. One can generally use the parameterization X=UU⊤−VV⊤by the same
technique of HaoChen et al. [20], Fan et al. [14]. We initialize UasU0=αIdfor some small
enough α >0. At timestep t, we run a one-step gradient descent on the standard least squares loss
using{(X(et)
i, y(et)
i)}m
i=1:
Lt(U) =1
2mmX
i=1
y(et)
i− ⟨X(et)
i,UU⊤⟩2
. (2)
That is, U0=αIdand
Ut+1=Ut−η∇Lt(Ut) = 
Id−η1
mmX
i=1(⟨X(et)
i,UtUt⊤⟩ −y(et)
i)X(et)
i!
Ut (3)
4Algorithm 3 HeteroSGD
SetU0=αId, where αis a small positive constant to be determined later.
Set large step size η= Θ(1) .
fort= 1, . . . , T −1do
Receive msamples {(X(et)
i, y(et)
i)}m
i=1from current environment et.
Gradient Descent Ut+1=Ut−η
mhPm
i=1
⟨X(et)
i,UtU⊤
t⟩ −y(et)
i
X(et)
ii
Ut.
end for
Output: UT.
fort= 0, . . . , T −1. See a complete presentation in Algorithm 3.
The algorithm adopts a constant level step size ηandlog(α−1)level number of iterations T, i.e.
η= Θ(1) andT= Θ(log( α−1)), and use UTU⊤
Tas our estimate of A⋆.
Standard Method: Pooled Stochastic Gradient Descent. As a comparison, we consider the
standard approach where data in each batch come from different environments and the weights follow
from D. To be specific, the pooled stochastic gradient descent over all environments adopted the
update rule
U←U−η∇¯L(U),where ¯L(U) =1
2mmX
i=1
y(ei)
i− ⟨X(ei)
i,UU⊤⟩2
, e i∼D. (4)
3.2 Assumptions
We first impose some standard assumptions used in matrix sensing. Since we are dealing with learning
true invariant signals from heterogeneous environments, several conditions on the structure of the
invariant signal A⋆and the spurious signals A(e)should be imposed.
Assumption 1 (Invariant and Spurious Space) .There exists U⋆∈Rd×r1andV⋆∈Rd×r2both with
orthogonal columns, i.e., (U⋆)⊤U⋆=Ir1and(V⋆)⊤V⋆=Ir2such that
(a).Clog4(d)≤r1∧r2andd≥(r1+r2)Cfor some large absolute constant C.
(b).A⋆=U⋆(U⋆)⊤.
(c).A(e)=V⋆Σ(e)(V⋆)⊤with some symmetric r2×r2matrix Σ(e)for any e∈ E.
(d).∥(U⋆)⊤V⋆∥ ≤ϵ1for some small quantity ϵ1≥0.
In Condition (b), we assume that the singular values of the true signal A⋆are the same to simplify
the presentation since our main focus is to reduce the spurious signals. It holds for the basic case
when there is only one invariant signal, i.e. r1= 1. The analysis for varying singular values using the
technique of Li et al. [31] is deferred to Section D in Appendix. Other assumptions are usual and easy
to achieve. Condition (a) requires that the total dimension of invariant signals and spurious signals
are small relative to the ambient dimension d. Condition (c) resembles the RIP condition [ 6] in sparse
feature selection [ 5]. Condition (d) says the overlap of invariant subspace and spurious subspace
should be small. Such a condition can be easily satisfied for random projections in high dimensions
where r1+r2≪d, under which we have ϵ1= Θ(p
(r1+r2)/d), see Proposition 1 below.
Proposition 1. LetM1∈Rd×r1andM2∈Rd×r2be two mutually independent random matrix
with i.i.d. N(0,1)entries. Denote their QR decompositions as M1=U⋆
1R1andM2=U⋆
2R2,
respectively. Then there exists a universal constant C1>0such that
(U⋆
1)⊤U⋆
2≤tr
r1+r2
d, (5)
with probability at least 1−4 exp 
−C−1
1d
−2 exp 
−C−1
1(r1+r2)t2
.
5Assumption 2 (Regularity on Spurious Signal Σ(e)).There exists some constant-level quantity
M1, M2such that
sup
e∈E,i∈[r2]|Σ(e)
ii|< M 1 and min
i∈[r2]Vare∼D[Σ(e)
ii]
1 +Ee∼D[Σ(e)
ii]> M 2, (6)
where M1< C 0M2for some universal constant C0>0. Moreover, Σ(e)is strongly diagonal
dominant for any e∈ E, i.e.,
sup
e∈Emax
i∈[r2]r2
2X
j̸=i|Σ(e)
ij| ≤co
M1.5
2(7)
where co>0is some universal constant.
The first inequality in (6)requires that all the spurious signals have a uniform bound, under which a
fixed step size can be adopted. The second inequality in (6)requires that the heterogeneity of the
spurious signals be large compared to the bias of the spurious signals. For example, some variables
receive different interventions in different environments. The condition (7)is imposed to prevent the
explosion of spurious signals during training. When the diagonal and off-diagonal elements are of the
same order, empirical studies and theoretical analyses in some toy examples illustrate the failure of
recovering A⋆. Condition (d) in Assumption 1 and (6) resemble the RIP condition in sparse feature
selection. Example 1 can fulfill all our conditions.
Finally, we impose assumptions on measurements. Recall the RIP condition [6]:
Definition 1 (RIP for Matrices [ 6]).A set of linear measurements X1, . . . ,Xmsatisfy the restricted
isometry property (RIP) with parameter (s, δ)if the following inequality
(1−δ)∥M∥2
F≤1
mmX
i=1⟨Xi,M⟩2≤(1 +δ)∥M∥2
F (8)
holds for any d×dmatrix Mwith rank at most s.
Assumption 3 (RIP Condition for Linear Measurements) .X(et)
1, . . . ,X(et)
msatisfies the RIP with
parameter s= 4(r1+r2)andδ≲1
(M2log(d))1.5r2.5
2√r1+r2for all e∈ E.
It is known from Candès and Plan [6]that for symmetric Gaussian measurements, sample complexity
m=˜Ω(dsδ−2, M2) =dpoly( r,log(d))≪d2suffices.
3.3 Convergence Analysis
The main conceptual challenge in the problem is that any UwithUU⊤=A⋆is no longer a local
minimum since Ee∼D[Σ(e)]is non-zero and could even be comparable to A⋆. This further implies
that running stochastic gradient descent on pooled data will fail to recover A⋆. However, our main
result below shows that simply adopting online gradient descent with “heterogeneous batches” can
successfully recover the true, invariant signal from heterogeneous environments.
Theorem 2 (Main Theorem) .Under Assumption 1-3, suppose further that ϵ1< δ/2. Define δ⋆:=
(cvM2log(d))1.5δr2
2√r1+r2for some absolute constant cv. If we choose η∈(24M−1
2,1
64M−1
1)
andα∈(1/d4,1/d2), then running Algorithm 3 in T= Θ(log( α−1)/η)steps, the algorithm outputs
UTthat satisfies
∥UTU⊤
T−A⋆∥F≤Cmax{δ⋆2√r1M2
1, δ⋆M1}log2d (9)
for some absolute constant C, with probability over 0.99.
Consider the case where r1, r2, M1are sufficiently large but is regarded at constant level, and the
batch size m, ambient dimension dsatisfy dlog2(d)≪m. It follows from the RIP result [ 6]
withδ= Θ(p
d/m)and Theorem 2 that one can adopt α= Θ( d−1),η= Θ(1) , and early stop
T= Θ(log d)such that
Ph
∥UTU⊤
T−A⋆∥F≤C1log(d)p
d/mi
≥1−C1(dlog(d)/m)2/5(10)
6provided ϵ1≤C−1
1p
d/m with some large enough constant C1>0. In this case, it follows from
(10) that one can distinguish the true invariant signals from those spurious heterogeneous ones since
max(U⋆)⊤UTU⊤
TU⋆−Ir1
2,(V⋆)⊤UTU⊤
TV⋆
2	
=oP(1). (11)
The underlying reason why the online gradient descent can recover A⋆is that the heterogeneity of
A(e)and the randomness in the SGD algorithm jointly prevent it from moving in the direction of
spurious signals. At the same time, the standard RIP conditions and the almost orthogonality between
U⋆andV⋆in Condition 1 ensure a steady movement towards the invariant signals.
Conversely, running pooled stochastic gradient descent using all data will result in a biased solution:
Theorem 3 (Negative Result for Pooled SGD) .Under the assumptions of Theorem 2 and some mild
conditions, for the certain case where U⋆⊥V⋆andEe∈DΣ(e)=Ir2, if we perform SGD over all
samples with batch size m= Ω(dpoly( r1+r2, M1M2,log(d)))and ends with T= Θ(log d), then
Utkeeps approaching U⋆U⋆⊤+V⋆V⋆⊤, in the sense that
UTU⊤
T−U⋆U⋆⊤−V⋆V⋆⊤
F≤o(1), (12)
during which for all t= 0,1, . . . , T :
UtU⊤
t−A⋆
F≳√r1∧r2. (13)
The convergence (12) is similar to (9)in derivation. To see this, since each update uses batch from
the whole data, the update in effect degenerates to the case for one environment with no heterogeneity.
Now the one-environment invariant solution A⋆in(9)is exactly equal to U⋆U⋆⊤+V⋆V⋆⊤in(12).
One can also show that for sufficiently large t,UtU⊤
tis sufficiently away from A⋆, indicating that
the biased estimation is not attributed to early stopping.
Our framework can be applied to learning the invariant features for a two-layer neural network with
quadratic activation functions, by recognizing the fact that [31]:
1⊤q(Ux) =
xx⊤,UU⊤
, (14)
where q(·)is the element-wise quadratic function. The following example shows that Theorem 7
implies success of invariant feature learning for 2-layer NN when the ground truth invariant and
variant features are independent random vectors sampled from normal distribution.
Example 1 (Two-Layer NN with Quadratic Activation) .Leta1,···,ar∈Rdbe random vectors
sampled from normal distribution N(0,1
dId). For environment e∈ E, suppose the target function is
determined by r1invariant features and r2variant admits that for each sample (x(e)
i, y(e)
i):
y(e)
i=r1X
j=1q(a⊤
jx(e)
i) +rX
j=r1+1a(e)
jq(a⊤
jx(e)
i) =*
x(e)
ix(e)
i⊤,r1X
j=1aja⊤
j+rX
j=r1+1a(e)
jaja⊤
j+
,(15)
which is equivalent to matrix sensing problem with
A⋆=r1X
j=1aja⊤
j,A(e)=rX
j=r1+1a(e)
jaja⊤
jandX(e)
i=x(e)
ix(e)
i⊤. (16)
And our goal is to train a two-layer NN to capture the invariant features (a1, . . . ,ar1). In this example,
the invariant component and the spurious component have a more intuitive characterization: they are
two disjoint groups of neurons. Moreover, it can be shown that the invariant and variant features are
nearly orthogonal (Proposition 1). Then if {a(e)
j}j,esatisfiessupe,j{|a(e)
j|}·maxj{1+|Eea(e)
j|}
minj{Vare[a(e)
j]}< c0for
some absolute constant c0, the variant version of Algorithm 3 returns a solution that only significantly
selects invariant features with probability over 0.99. See Section C and Theorem 7 for details.
4 Proof Sketch
We define the invariant part Rt∈Rd×r1, spurious part Qt∈Rd×r2inUtas
Rt:=Ut⊤U⋆and Qt:=U⊤
tV⋆(17)
7and let the residual be the error part, that is,
Et:=Ut−
U⋆Rt⊤+V⋆Qt⊤
= (I−U⋆U⋆⊤−V⋆V⋆⊤)Ut. (18)
It is worth noticing that IdU⋆=U⋆U⋆⊤andIdV⋆=V⋆V⋆⊤are both orthogonal projections, and
Idres:=I−IdU⋆−IdV⋆is not.
It follows from the model (1) and the gradient update that
Ut+1=Ut−η1
mmX
i=1⟨X(et)
i,UtU⊤
t−A⋆−A(et)⟩X(et)
iUt. (19)
We use operator Eet◦(M)∈Rd×dto denote the RIP error of the batch at time step tfor some d×d
matrix M, i.e.,
Eet◦(M) :=1
mmX
i=1⟨X(et)
i,M⟩X(et)
i−M. (20)
We also write Et◦(M) :=Eet◦(M)when there is no ambiguity, and we simply denote matrix
Et=Et◦
UtU⊤
t−U⋆U⋆⊤−V⋆ΣtV⋆⊤
withΣt:=Σ(et). Then the gradient update of Ut
can be written as
Ut+1=Ut−η
UtU⊤
t−U⋆U⋆⊤−V⋆ΣtV⋆⊤
Ut−ηEtUt|{z}
RIP Error.(21)
Combining our definition (17) with (21), we obtain
Rt+1=
Ut−η(UtU⊤
t−U⋆U⋆⊤−V⋆ΣtV⋆⊤)Ut−ηEtUt⊤
U⋆
= (I−ηU⊤
tUt+ηI)Rt| {z }
Dominating Dynamics+ηU⊤
tV⋆ΣtV⋆⊤U⋆
| {z }
Interaction Error−ηU⊤
tEtU⋆
|{z}
RIP Error.(22)
Qt+1=
Ut−η(UtU⊤
t−U⋆U⋆⊤−V⋆ΣtV⋆⊤)Ut−ηEtUt⊤
V⋆
=Qt−ηU⊤
tUtQt+ηQtΣt| {z }
Fluctuation Dynamics+ηU⊤
tU⋆U⋆⊤V⋆
|{z }
Interaction Error−ηU⊤
tEtV⋆
|{z}
RIP Error.(23)
For the error part, combining (18) with (21) yields
Et+1= Id res
Ut−η(UtU⊤
t−U⋆U⋆⊤−V⋆ΣtV⋆⊤)Ut−ηEtUt
=Et(I−ηU⊤
tUt)| {z }
Shrinkage Dynamics+ηIdres(U⋆U⋆⊤+V⋆ΣtV⋆⊤)Ut| {z }
Interaction Error−ηIdresEtUt|{z}
RIP Error.(24)
For the invariant part Rt, though different singular values of Rtwill grow at different speeds because
of the randomness from RIP error and et, we claim that all the singular values of Rtare close to Rt
during the training process, where the scalar sequence Rtis defined recursively as
Rt+1= (1−ηR2
t+η)Rt,R0=α. (25)
The dynamics of Qtare very complicated because of the randomness of etand the RIP error. Such a
dynamic will also impact that of RtandEtthrough the complicated dependencies between these
three parts, which will also make it difficult to utilize probability inequalities applicable under
independence. Instead, we claim that such a “fluctuation dynamics” of Qtcan be controlled as
∥Qt∥<poly(log( d), r, M 1)Ltwith Lt=(
α , t < O (1
ηlog(r1+r2))
O(δM1√r1+r2Rt), t≥O(1
ηlog(r1+r2)).
(26)
8025 50 75100
ItersStable/uni00A0Signal
Oscillating/uni00A0Signal
025 50 75100
ItersStable/uni00A0Signal
Oscillating/uni00A0SignalFigure 2: The left figure shows E∥qt∥
and the right figure shows E∥qt∥0.1.We now offer an informal illustration for how oscilla-
tions “shrink” spurious signal. We simply omit error
terms. When matrix Σ(t+1)is diagonal, from (23), the
i-th column qtofQtshould satisfies: ∥qt+1∥ ≤(1 +
ηΣ(t+1)
ii)∥qt∥. Letξdef=Σ(t+1)
ii and assume M≥ |ξ|a.s..
Introduce a concave function [ 20]ϕ(x) =xγ, γ∈(0,1).
When ηM <1
16, do second-order Taylor’s expansion at
ϕ(1)in(a)below:
Eh
ϕ(∥qt+1∥)i
≤Eh
ϕ(1 +ηξ)i
·ϕ(∥qt∥)
(a)≈
1 +ηγE[ξ]−η2γ(1−γ)
2Var[ξ]
ϕ(∥qt∥)<ϕ(∥qt∥),
where E[·]is w.r.t. ξ. So spurious signal keeps small when1
16M> η >4E[ξ]
(1−γ) Var[ ξ]. See the figure
for illustration in Figure 2. While E[∥qt∥](shown in the left figure) increases since the signals have
positive expectations, E[∥qt∥0.1](shown in the right figure) decreases. Note that the above intuition
is informal and the formal argument is deferred in Lemma 6 and Lemma 7 in Appendix.
The entire training process can be divided into two phases. In Phase 1, the invariant signals Rt
increase rapidly while the spurious signals Qtfluctuate but remain at a low level. Phase 1 ends in
O(1
ηlog(1
α))steps when Rtattains Θ(1) -order (see Theorem 4). In Phase 2, the magnitudes of Qt
andEtstay low, while all the singular values of Rtapproach 1(See Theorem 5). We defer the details
to Appendix.
5 Simulations
In this section, we present our simulations. We design three sets of experiments. In the first set of
experiments, we show with the growth of environment heterogeneity, invariance learning is achievable.
For the second set of experiments, we show that given heterogeneous data, invariance learning is
achievable with the growth of step size3. For the third set of experiments, we compare HeteroSGD
(Algorithm 3) and Pooled SGD. In Section B.2 we also perform simulations for Pooled SGD with
small batch size.
In below two sets of experiments, we set the scale of initialization α= 10−3, problem dimension
d= 100 ,r1= 1andr2= 1. Let the true signal be A⋆=uu⊤. Denote the heterogeneity parameter
byM. The environment is generated by A(e)=A⋆+s(e)vv⊤where s(e)∼Unif{1−M,1 +M},
and the default of ηis0.05. The number of linear measurements is set to be m= 8000 with elements
following from i.i.d N(0,1). For the third sets, we set (r1, r2, d,Es(e)) = (3 ,2,40,0.5),m= 2800
forHeteroSGD andm= 5600 without replacement for Pooled SGD. The plots show signal recovery
proportion, 1.0indicates fully recovery.
/uni00000013 /uni00000018/uni00000013 /uni00000014/uni00000013/uni00000013 /uni00000014/uni00000018/uni00000013 /uni00000015/uni00000013/uni00000013
/uni0000002c/uni00000057/uni00000048/uni00000055/uni00000056/uni00000013/uni00000011/uni00000013/uni00000013/uni00000011/uni00000015/uni00000013/uni00000011/uni00000017/uni00000013/uni00000011/uni00000019/uni00000013/uni00000011/uni0000001b/uni00000014/uni00000011/uni00000013/uni00000039/uni00000044/uni0000004f/uni00000058/uni00000048/uni00000037/uni00000055/uni00000058/uni00000048/uni00000003/uni00000036/uni0000004c/uni0000004a/uni00000051/uni00000044/uni0000004f/uni00000003/uni00000030/uni00000020/uni00000019/uni00000011/uni00000013
/uni00000036/uni00000053/uni00000058/uni00000055/uni0000004c/uni00000052/uni00000058/uni00000056/uni00000003/uni00000030/uni00000020/uni00000019/uni00000011/uni00000013
/uni00000028/uni00000055/uni00000055/uni00000052/uni00000055/uni00000003/uni00000030/uni00000020/uni00000019/uni00000011/uni00000013
/uni00000037/uni00000055/uni00000058/uni00000048/uni00000003/uni00000036/uni0000004c/uni0000004a/uni00000051/uni00000044/uni0000004f/uni00000003/uni00000030/uni00000020/uni00000014/uni00000011/uni00000013
/uni00000036/uni00000053/uni00000058/uni00000055/uni0000004c/uni00000052/uni00000058/uni00000056/uni00000003/uni00000030/uni00000020/uni00000014/uni00000011/uni00000013
/uni00000028/uni00000055/uni00000055/uni00000052/uni00000055/uni00000003/uni00000030/uni00000020/uni00000014/uni00000011/uni00000013
/uni00000015 /uni00000017 /uni00000019 /uni0000001b /uni00000014/uni00000013
M/uni00000013/uni00000011/uni00000013/uni00000013/uni00000011/uni00000015/uni00000013/uni00000011/uni00000017/uni00000013/uni00000011/uni00000019/uni00000013/uni00000011/uni0000001b/uni00000014/uni00000011/uni00000013/uni00000036/uni0000004c/uni0000004a/uni00000051/uni00000044/uni0000004f/uni00000003/uni00000039/uni00000044/uni0000004f/uni00000058/uni00000048
 /uni00000037/uni00000055/uni00000058/uni00000048/uni00000003/uni00000036/uni0000004c/uni0000004a/uni00000051/uni00000044/uni0000004f
/uni00000036/uni00000053/uni00000058/uni00000055/uni0000004c/uni00000052/uni00000058/uni00000056/uni00000003/uni00000036/uni0000004c/uni0000004a/uni00000051/uni00000044/uni0000004f
Figure 3: The left figure shows that the heterogeneity facilitates us to eliminate the spurious signal
and learn the invariance. The right figure shows that both true and spurious signals flow up when M
is small, the “phase transition” happens around M= 5.
3A smaller step size can reduce the noise arising from heterogeneity, making the dynamics more similar to
those of Gradient Descent.
9/uni00000013 /uni00000018/uni00000013 /uni00000014/uni00000013/uni00000013 /uni00000014/uni00000018/uni00000013 /uni00000015/uni00000013/uni00000013
/uni0000000bM=5.0/uni0000000c/uni00000013/uni00000011/uni00000013/uni00000013/uni00000011/uni00000015/uni00000013/uni00000011/uni00000017/uni00000013/uni00000011/uni00000019/uni00000013/uni00000011/uni0000001b/uni00000014/uni00000011/uni00000013/uni00000039/uni00000044/uni0000004f/uni00000058/uni00000048/uni00000037/uni00000055/uni00000058/uni00000048/uni00000003/uni00000036/uni0000004c/uni0000004a/uni00000051/uni00000044/uni0000004f/uni00000003=0.05
/uni00000036/uni00000053/uni00000058/uni00000055/uni0000004c/uni00000052/uni00000058/uni00000056/uni00000003=0.05
/uni00000028/uni00000055/uni00000055/uni00000052/uni00000055/uni00000003=0.05
/uni00000037/uni00000055/uni00000058/uni00000048/uni00000003/uni00000036/uni0000004c/uni0000004a/uni00000051/uni00000044/uni0000004f/uni00000003=0.01
/uni00000036/uni00000053/uni00000058/uni00000055/uni0000004c/uni00000052/uni00000058/uni00000056/uni00000003=0.01
/uni00000028/uni00000055/uni00000055/uni00000052/uni00000055/uni00000003=0.01
/uni00000013/uni00000011/uni00000013/uni00000014 /uni00000013/uni00000011/uni00000013/uni00000015 /uni00000013/uni00000011/uni00000013/uni00000016 /uni00000013/uni00000011/uni00000013/uni00000017 /uni00000013/uni00000011/uni00000013/uni00000018 /uni00000013/uni00000011/uni00000013/uni00000019 /uni00000013/uni00000011/uni00000013/uni0000001a /uni00000013/uni00000011/uni00000013/uni0000001b /uni00000013/uni00000011/uni00000013/uni0000001c
/uni00000013/uni00000011/uni00000013/uni00000013/uni00000011/uni00000015/uni00000013/uni00000011/uni00000017/uni00000013/uni00000011/uni00000019/uni00000013/uni00000011/uni0000001b/uni00000014/uni00000011/uni00000013/uni00000014/uni00000011/uni00000015/uni00000014/uni00000011/uni00000017/uni00000036/uni0000004c/uni0000004a/uni00000051/uni00000044/uni0000004f/uni00000003/uni00000039/uni00000044/uni0000004f/uni00000058/uni00000048
/uni00000037/uni00000055/uni00000058/uni00000048/uni00000003/uni00000036/uni0000004c/uni0000004a/uni00000051/uni00000044/uni0000004f
/uni00000036/uni00000053/uni00000058/uni00000055/uni0000004c/uni00000052/uni00000058/uni00000056/uni00000003/uni00000036/uni0000004c/uni0000004a/uni00000051/uni00000044/uni0000004fFigure 4: The left figure shows that the large step size helps eliminate the spurious signal. The right
figure shows that both true and spurious signals flow up when ηis small, and when η≥0.05, the
spurious signal is eliminated.
0 25 50 75 100 125 150 175
Iters0.00.20.40.60.81.0ValueTrue/uni00A0Signal
Spurious
Error
0 25 50 75 100 125 150 175
Iters0.00.20.40.60.81.0ValueTrue/uni00A0Signal
Spurious
Error
Figure 5: The left figure shows that heterogeneity helps eliminate the spurious signal. The right figure
shows that Pooled SGD fits invariant signal and spurious signal simultaneously without distinction.
6 Conclusions
This paper explains that implicit bias of heterogeneity leads the model learning towards invariance
and causality. We show that under heterogeneous environments, online gradient descent with large
step sizes can select out the invariant matrix in the over-parameterized matrix sensing models. We
conjecture that both heterogeneity and stochasticity are indispensable. Over-parameterization may
not be. We leave future studies to understand the necessity of the three factors.
7 Acknowledgement
C. Fang was supported by National Key R&D Program of China (2022ZD0114902), the NSF China
(No.62376008).
10References
[1]Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni
Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. Gpt-4
technical report. arXiv preprint arXiv:2303.08774 , 2023.
[2]Martin Arjovsky, Léon Bottou, Ishaan Gulrajani, and David Lopez-Paz. Invariant risk mini-
mization. arXiv preprint arXiv:1907.02893 , 2019.
[3]Guy Blanc, Neha Gupta, Gregory Valiant, and Paul Valiant. Implicit regularization for deep
neural networks driven by an ornstein-uhlenbeck like process. In Conference on Learning
Theory , pages 483–513. PMLR, 2020.
[4]Emmanuel J Candes. The restricted isometry property and its implications for compressed
sensing. Comptes rendus. Mathematique , 346(9-10):589–592, 2008.
[5]Emmanuel J Candes and Terence Tao. Decoding by linear programming. IEEE transactions on
information theory , 51(12):4203–4215, 2005.
[6]Emmanuel J. Candès and Yaniv Plan. Tight oracle inequalities for low-rank matrix recovery
from a minimal number of noisy random measurements. IEEE Transactions on Information
Theory , 57(4):2342–2359, 2011. doi: 10.1109/TIT.2011.2111771.
[7]Wei-Ting Chang and Ravi Tandon. On the upload versus download cost for secure and private
matrix multiplication. In 2019 IEEE Information Theory Workshop (ITW) , pages 1–5. IEEE,
2019.
[8]Jeremy Cohen, Simran Kaur, Yuanzhi Li, J Zico Kolter, and Ameet Talwalkar. Gradient descent
on neural networks typically occurs at the edge of stability. In International Conference on
Learning Representations , 2020.
[9]Alex Damian, Tengyu Ma, and Jason D Lee. Label noise SGD provably prefers flat global
minimizers. Advances in Neural Information Processing Systems , 34, 2021.
[10] Cynthia Dwork, Krishnaram Kenthapadi, Frank McSherry, Ilya Mironov, and Moni Naor.
Our data, ourselves: Privacy via distributed noise generation. In Advances in Cryptology-
EUROCRYPT 2006: 24th Annual International Conference on the Theory and Applications of
Cryptographic Techniques, St. Petersburg, Russia, May 28-June 1, 2006. Proceedings 25 , pages
486–503. Springer, 2006.
[11] Mathieu Even, Scott Pesme, Suriya Gunasekar, and Nicolas Flammarion. (s) gd over diagonal
linear networks: Implicit bias, large stepsizes and edge of stability. Advances in Neural
Information Processing Systems , 36, 2024.
[12] Jianqing Fan and Yuan Liao. Endogeneity in high dimensions. Annals of Statistics , 42(3):872,
2014.
[13] Jianqing Fan, Cong Fang, Yihong Gu, and Tong Zhang. Environment invariant linear least
squares. arXiv preprint arXiv:2303.03092 , 2023.
[14] Jianqing Fan, Zhuoran Yang, and Mengxin Yu. Understanding implicit regularization in over-
parameterized single index model. Journal of the American Statistical Association , 118(544):
2315–2328, 2023.
[15] AmirEmad Ghassami, Saber Salehkaleybar, Negar Kiyavash, and Kun Zhang. Learning causal
structures using regression invariance. Advances in Neural Information Processing Systems , 30,
2017.
[16] Daniel Gissin, Shai Shalev-Shwartz, and Amit Daniely. The implicit bias of depth: How incre-
mental learning drives generalization. In International Conference on Learning Representations ,
2019.
[17] Yihong Gu, Cong Fang, Peter Bühlmann, and Jianqing Fan. Causality pursuit from heteroge-
neous environments via neural adversarial invariance learning. arXiv preprint arXiv:2405.04715 ,
2024.
11[18] Suriya Gunasekar, Blake E Woodworth, Srinadh Bhojanapalli, Behnam Neyshabur, and Nati
Srebro. Implicit regularization in matrix factorization. Advances in Neural Information
Processing Systems , 30, 2017.
[19] Suriya Gunasekar, Jason D Lee, Daniel Soudry, and Nati Srebro. Implicit bias of gradient
descent on linear convolutional networks. Advances in Neural Information Processing Systems ,
31, 2018.
[20] Jeff Z HaoChen, Colin Wei, Jason Lee, and Tengyu Ma. Shape matters: Understanding the
implicit bias of the noise covariance. In Conference on Learning Theory , pages 2315–2357.
PMLR, 2021.
[21] Badr Youbi Idrissi, Martin Arjovsky, Mohammad Pezeshki, and David Lopez-Paz. Simple data
balancing achieves competitive worst-group-accuracy. In Conference on Causal Learning and
Reasoning , pages 336–351. PMLR, 2022.
[22] Ziwei Ji and Matus Telgarsky. Gradient descent aligns the layers of deep linear networks. In
International Conference on Learning Representations , 2019.
[23] Ziwei Ji and Matus Telgarsky. Directional convergence and alignment in deep learning. Ad-
vances in Neural Information Processing Systems , 33, 2020.
[24] Liwei Jiang, Yudong Chen, and Lijun Ding. Algorithmic regularization in model-free over-
parametrized asymmetric matrix factorization. SIAM Journal on Mathematics of Data Science ,
5(3):723–744, 2023.
[25] Jikai Jin, Zhiyuan Li, Kaifeng Lyu, Simon Shaolei Du, and Jason D Lee. Understanding incre-
mental learning of gradient descent: A fine-grained analysis of matrix sensing. In International
Conference on Machine Learning , pages 15200–15238. PMLR, 2023.
[26] Peter Kairouz, H Brendan McMahan, Brendan Avent, Aurélien Bellet, Mehdi Bennis, Ar-
jun Nitin Bhagoji, Kallista Bonawitz, Zachary Charles, Graham Cormode, Rachel Cummings,
et al. Advances and open problems in federated learning. Foundations and trends ®in machine
learning , 14(1–2):1–210, 2021.
[27] Dimitris Kalimeris, Gal Kaplun, Preetum Nakkiran, Benjamin Edelman, Tristan Yang, Boaz
Barak, and Haofeng Zhang. Sgd on neural networks learns functions of increasing complexity.
Advances in Neural Information Processing Systems , 32, 2019.
[28] Pritish Kamath, Akilesh Tangella, Danica Sutherland, and Nathan Srebro. Does invariant risk
minimization capture invariance? In International Conference on Artificial Intelligence and
Statistics , pages 4069–4077. PMLR, 2021.
[29] Sai Praneeth Karimireddy, Satyen Kale, Mehryar Mohri, Sashank Reddi, Sebastian Stich, and
Ananda Theertha Suresh. Scaffold: Stochastic controlled averaging for federated learning. In
International Conference on Machine Learning , pages 5132–5143. PMLR, 2020.
[30] Tian Li, Shengyuan Hu, Ahmad Beirami, and Virginia Smith. Ditto: Fair and robust federated
learning through personalization. In International Conference on Machine Learning , pages
6357–6368. PMLR, 2021.
[31] Yuanzhi Li, Tengyu Ma, and Hongyang Zhang. Algorithmic regularization in over-parameterized
matrix sensing and neural networks with quadratic activations. In Conference on Learning
Theory , pages 2–47. PMLR, 2018.
[32] Zhiyuan Li, Tianhao Wang, and Sanjeev Arora. What happens after sgd reaches zero loss?–a
mathematical framework. In International Conference on Learning Representations , 2021.
[33] Shiyun Lin, Yuze Han, Xiang Li, and Zhihua Zhang. Personalized federated learning towards
communication efficiency, robustness and fairness. Advances in Neural Information Processing
Systems , 35:30471–30485, 2022.
[34] Yong Lin, Hanze Dong, Hao Wang, and Tong Zhang. Bayesian invariant risk minimization. In
Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages
16021–16030, 2022.
12[35] Yong Lin, Shengyu Zhu, Lu Tan, and Peng Cui. Zin: When and how to learn invariance without
environment partition? Advances in Neural Information Processing Systems , 35, 2022.
[36] Chaochao Lu, Yuhuai Wu, Jo ´se Miguel Hernández-Lobato, and Bernhard Schölkopf. Nonlinear
invariant risk minimization: A causal approach. arXiv preprint arXiv:2102.12353 , 2021.
[37] Miao Lu, Beining Wu, Xiaodong Yang, and Difan Zou. Benign oscillation of stochastic gradient
descent with large learning rate. In International Conference on Learning Representations ,
2023.
[38] Kaifeng Lyu, Zhiyuan Li, and Sanjeev Arora. Understanding the generalization benefit of
normalization layers: Sharpness reduction. Advances in Neural Information Processing Systems ,
35, 2022.
[39] Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas.
Communication-efficient learning of deep networks from decentralized data. In Artificial
intelligence and statistics , pages 1273–1282. PMLR, 2017.
[40] Nicolai Meinshausen, Alain Hauser, Joris M Mooij, Jonas Peters, Philip Versteeg, and Peter
Bühlmann. Methods for causal inference from gene perturbation experiments and validation.
Proceedings of the National Academy of Sciences , 113(27):7361–7368, 2016.
[41] Mor Shpigel Nacson, Jason Lee, Suriya Gunasekar, Pedro Henrique Pamplona Savarese, Nathan
Srebro, and Daniel Soudry. Convergence of gradient descent on separable data. In The 22nd
International Conference on Artificial Intelligence and Statistics , pages 3420–3428. PMLR,
2019.
[42] Vivian Y Nastl and Moritz Hardt. Predictors from causal features do not generalize better to
new domains. arXiv preprint arXiv:2402.09891 , 2024.
[43] Jonas Peters, Peter Bühlmann, and Nicolai Meinshausen. Causal inference by using invariant
prediction: identification and confidence intervals. Journal of the Royal Statistical Society
Series B: Statistical Methodology , 78(5):947–1012, 2016.
[44] Elan Rosenfeld, Pradeep Ravikumar, and Andrej Risteski. The risks of invariant risk minimiza-
tion. In International Conference on Learning Representations , volume 9, 2021.
[45] Daniel Soudry, Elad Hoffer, Mor Shpigel Nacson, Suriya Gunasekar, and Nathan Srebro. The
implicit bias of gradient descent on separable data. Journal of Machine Learning Research , 19
(1):2822–2878, 2018.
[46] Dominik Stöger and Mahdi Soltanolkotabi. Small random initialization is akin to spectral
learning: Optimization and generalization guarantees for overparameterized low-rank matrix
reconstruction. Advances in Neural Information Processing Systems , 34, 2021.
[47] Roman Vershynin. High-dimensional probability: An introduction with applications in data
science , volume 47. Cambridge university press, 2018.
[48] Loucas Pillaud Vivien, Julien Reygner, and Nicolas Flammarion. Label noise (stochastic)
gradient descent implicitly solves the lasso for quadratic parametrisation. In Conference on
Learning Theory , pages 2127–2159. PMLR, 2022.
[49] Yoav Wald, Gal Yona, Uri Shalit, and Yair Carmon. Malign overfitting: Interpolation and
invariance are fundamentally at odds. In International Conference on Learning Representations ,
2023.
[50] Amy Zhang, Clare Lyle, Shagun Sodhani, Angelos Filos, Marta Kwiatkowska, Joelle Pineau,
Yarin Gal, and Doina Precup. Invariant causal prediction for block mdps. In International
Conference on Machine Learning , pages 11214–11224. PMLR, 2020.
[51] Cheng Zhang, Stefan Bauer, Paul Bennett, Jiangfeng Gao, Wenbo Gong, Agrin Hilmkil, Joel
Jennings, Chao Ma, Tom Minka, Nick Pawlowski, et al. Understanding causality with large
language models: Feasibility and opportunities. arXiv preprint arXiv:2304.05524 , 2023.
[52] Jiacheng Zhuo, Jeongyeol Kwon, Nhat Ho, and Constantine Caramanis. On the compu-
tational and statistical complexity of over-parameterized matrix sensing. arXiv preprint
arXiv:2102.02756 , 2021.
13Contents
1 Introduction 1
2 Related Works 3
3 Main Results 4
3.1 Problem Formulation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4
3.2 Assumptions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5
3.3 Convergence Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6
4 Proof Sketch 7
5 Simulations 9
6 Conclusions 10
7 Acknowledgement 10
A Deferred Proofs in Theorem 2 14
A.1 Restricted Isometry Properties . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14
A.2 Additional Auxiliary Sequences . . . . . . . . . . . . . . . . . . . . . . . . . . . 15
A.3 Useful Lemmas . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18
A.4 Bounds of Qt. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20
A.5 Bounds of Et. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20
A.6 Analysis for Phase 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23
A.7 Analysis for Phase 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24
B Deferred Proofs 26
B.1 Proof of Proposition 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26
B.2 The Failure of Pooled Stochastic Gradient Descent . . . . . . . . . . . . . . . . . 28
C Neural Networks with Quadratic Activations 30
D The κ(A⋆)>1Case 32
A Deferred Proofs in Theorem 2
This section is organized as follows: In Section A.1, we state some useful properties from the
definition of RIP. In Section A.2 and A.3, we formally define the auxiliary sequences we use to
control the dynamics and develop several useful lemmas we frequently use. In Section A.4 and A.5,
we bound QtandEtrespectively. In Section A.6 and A.7, we prove Theorem 4 and Theorem 5.
A.1 Restricted Isometry Properties
In this section, we list some useful implications of the definition of RIP property. Below we assume
the set of linear measurements A(et)
1, . . . ,A(et)
m∈Rd×dsatisfy the RIP property with parameter
14(r, δ)and denote Et◦(M) :=1
mPm
i=1⟨X(et)
i,M⟩X(et)
i−Mfor some symmetric d×dmatrix M.
Some lemmas are direct corollaries and some lemmas serve as extensions to rank above rcase. The
proof of these lemmas can be found in Li et al. [31].
Lemma 1. Under the assumption of this subsection, if X,Yared×dmatrices with rank at most r,
then
|⟨Et◦(X),Y⟩| ≤δ∥X∥F∥Y∥F. (27)
Lemma 2. Under the assumption of this subsection, if Xidd×dmatrix with rank at most randZ
is ad×d′matrix, then
∥Et◦(X)Z∥ ≤δ∥X∥F∥Z∥. (28)
Lemma 3. Under the assumption of this subsection, if X,Yared×dmatrices and Yhas rank at
mostr, then
|⟨Et◦(X),Y⟩| ≤δ∥X∥∗∥Y∥F. (29)
Lemma 4. Under the assumption of this subsection, if Xidd×dmatrix and Zis ad×d′matrix,
then
∥Et◦(X)Z∥ ≤δ∥X∥∗∥Z∥. (30)
Lemma 1 is from Candes [4]. The other three lemma can be derived from Lemma 1 through selecting
Zor decomposing Xinto a series of rank-1 matrices [31].
A.2 Additional Auxiliary Sequences
In this section, we additionally define some auxiliary sequences. Some for calibrating the dynamics,
that is, describe how the dynamic progresses without error or randomness and track the trajectories
with the accumulation of error. Some are used for characterizing the impact of randomness on the
dynamic.
The next two deterministic sequences help to track the dynamic of singular values of Rtwhen it
accumulates errors in each step.
Definition 2. We define the following two deterministic sequences:
Rt+1= (1−ηR2
t+η)Rt+η
32log−11
α
Rt, R0=α
Rt+1= (1−ηR2
t+η)Rt−η
32log−11
α
Rt, R0=α.(31)
The next lemma shows that the deviation between RtandRtcan be bounded.
Lemma 5 (Bounded Deviation between RtandRt).Let the sequence Rtbe defined as (25). LetT1
be the first time Rtenters the region (1
3−η,1
3), we have
Rt≤(1 + 1 /6)Rt;
Rt≥(1−1/6)Rt,(32)
for any t= 0, . . . , T 1.
Proof. Fist, for Rthave that
Rt+1
Rt+1=(1−ηR2
t+η)Rt+η
32log−1 1
α
Rt
(1−ηR2
t+η)Rt≤
1 +η
32log−11
αRt
Rt(33)
It takes T1≤4
ηlog 1
α
steps for Rtto reach (1
3−η,1
3). We can conclude that
RT1
RT1≤
1 +η
32log−11
αT1
≤exp(1 /8)<1 +1
6(34)
where we use 1−x≥exp(−2x),1 +x≥exp(x
2)forx∈[0,1/2]. Similarly, For Rt, we have
Rt+1= (1−ηR2
t+η)Rt−η
32log−11
α
Rt≥(1−ηR2
t+η)Rt−η
32·7
6log−11
α
Rt,(35)
15and
Rt+1
Rt+1=(1−ηR2
t+η)Rt−η
32·7
6log−1 1
α
Rt
(1−ηR2
t+η)Rt≥Rt
Rt−η
32·7
6log−11
α
, (36)
which implies
RT1
RT1≥1−7
48>1−1
6. (37)
One can also see that, Rt≤(1 + 1 /6)RtandRt≥(1−1/6)Rtholds for any t≤T, which
completes our proof.
Next, we formally define the calibration line Lt. In later parts, we can show that the norm of each
column of Qtbehaves like a biased random walk with reflecting barrier Lt.
Definition 3. Letα,Rbe defined as above. For t= 0,1, . . ., we define the calibration line:
Lt=α∨40Mδ√r1+r2Rt. (38)
Next, we define a stochastic process qt
ibased on Σt. The reason why we define this sequence is
that though the randomness only directly affects Qt, the dynamic of EtandRtalso shares the
randomness, therefore the dynamics become difficult to reason about since they are deeply coupled.
Therefore, we define this “external” random sequence to dominate them.
Definition 4 (Controller Sequence) .We fix the violation probability p=cv/(M2log(d))for some
small absolute constant cv. For each fixed i, we define a stochastic process qt
ifort= 0,1,2, . . . with
q0
i=α, and
qt+1
i=(
qt
i ,if there exists τ≤tsuch that qτ
i≥p−1.5r1.5
2·Lτ
(1 +ηΣ(t+1)
ii + 2η)qt
i∨Lt+1,otherwise
qt
iis used for providing an upper bound the norm of columns of Qt. Before qt
ihits the upper
absorbing boundary p−1.5r1.5
2·Lt, it can be considered as a “reflection and absorbing” process, with
reflection barrier Ltand absorbing barrier p−1.5r1.5
2·Lt. The following lemma gives an upper bound
for{qt
i}i,t:
Lemma 6 (Upper bound for qt
i).With probability over 0.995over the randomness of the Σ(et), for
alli= 1,2, . . . , r 2andt= 0,1, . . . , T 2, we have
qt
i< p−1.5r1.5
2·Lt. (39)
To prove this, we define a family of random sequences Xi
k,t.
Definition 5. For each i= 1, . . . , r 2, we construct a family of non-negative stochastic processes
{Xi
k,t}T2
t=0fork= 0, . . . , T 2as follows:
Xi
k,t=(
Lt ,0≤t≤k≤T2
(1 +ηΣ(et)
ii+ 2η)Xi
k,t−1,0≤k < t≤T2(40)
(Xi
k,t)k,t∈[T2]can be expressed as the following form:

Xi
k,t
=
L0(1 +ηΣ(e1)
ii+ 2η)L0Q2
s=1(1 +ηΣ(es)
ii+ 2η)
·L0 · · ·QT
s=1(1 +ηΣ(es)
ii+ 2η)
·L0
L1 L1 (1 +ηΣ(e2)
ii+ 2η)L1 · · ·QT
s=2(1 +ηΣ(es)
ii+ 2η)
·L1
L2 L2 L2 · · ·QT
s=3(1 +ηΣ(es)
ii+ 2η)
·L2
............
LT2 LT2 LT2 · · · LT2
.
16It can be noticed that Xi
k,tandqt
ihave close relations. At the beginning we have qt
i=Xi
0,t,
t= 0,1, . . ., progress along the 0-th row. If qt
igets lower than the calibration line Ltat some
timestep t=t0, it switches to the the t0-th row Xi
t0,t, t=t0, . . .until the next time it gets lower than
calibration line Lt, and so on. We can see that qt
ialways progress along a certain row. Thus
P 
∃ksuch that qt
i=Xi
k,t
= 1,∀i∈[r2]andt∈[T2]. (41)
Theerfore, any uniform bound of Xi
k,tcan also be a bound for qt
i. Later in the context, we analyze
Xi
k,tfor each iso we omit the argument iinXi
k,tfor convenient notation.
We define σ-fieldFt=σ(Σ(e0), . . . ,Σ(et−1))fort= 1, . . . T 2andF0=σ(∅). Then we have
F0⊂ F 1⊂ ··· ⊂ F T2form a filtration. The next lemma shows that a certain power of {Xk,t}tis a
non-negative supermartingale w.r.t. Ft.
Lemma 7. For each i= 1, . . . , r 2andk= 0, . . . , T 2, if the learning rate ηsatisfies η∈(24
M2,1
64M1),
then the process {X2/3
k,t}T2
t=0is a non-negative supermartingale with respect to Ft.
Proof. First, its easy to verify the adaptiveness X2/3
k,t∈ FtsinceΣ(t)
ii∈ Ftfor all t= 0,1, . . . T 2.
Next, note that
Eh
X2/3
k,t+1|Fti
=

X2/3
k,t, t+ 1≤k
E
(1 +η(Σ(et)
ii) + 2η)2/3
X2/3
k,t, t≥k(42)
So it suffices to prove that
Ee∼Dh
(1 +ηΣ(et)
ii+ 2η)2/3i
≤1.
For any γ∈(0,1)and|x−1|<1
16, from Taylor’s expansion, we have
x1−γ≤1 + (1 −γ)(x−1)−1
4(1−γ)γ(x−1)2. (43)
Therefore,
Eeth
(1 +ηΣ(et)
ii+ 2η)1−γi
≤1 +η(1−γ)(2 +EΣ(et)
ii)−1
4η2(1−γ)γVaret[Σ(et)
ii].(44)
Hence, it suffices to choose η, γsuch that
(2 +EΣ(et)
ii)≤1
4ηγVar[Σ(et)
ii], η <1
64M1. (45)
When γ=1
3,η∈(24
M2,1
64M1)suffices. Hence we prove Eh
(1 +ηΣ(et)
ii+ 2η)2/3i
≤1and we can
conclude that
0≤Eh
X2/3
k,t+1|Fti
≤X2/3
k,t. (46)
Now we are ready to prove Lemma 6.
Proof of Lemma 6. From the above observations, before qt
ihits the upper absorbing boundary
p−1.5r1.5
2·Lt, there always exists some ksuch that qt
i=Xk,t. Therefore, qt
ihitsp−1.5r1.5
2·Lt
implies there exists some kthatXk,thitsp−1.5r1.5
2·Lt. So it suffices to bound Xk,t.
For any fixed k= 0, ..., T 2, we denote two stopping times:
τ0
kdef=T2∧min
k≤t≤T2{X2/3
k,t<(Lt)2/3};
τ1
kdef=T2∧min
k≤t≤T2{X2/3
k,t≥(p−1.5r1.5
2·Lt)2/3}.(47)
17One gets that
P 
τ1
k< τ0
k(a)
≤1
(p−1.5r1.5
2·Lk)2/3EX2/3
k,τ1
k∧τ0
k(b)
≤1
(p−1.5r1.5
2·Lk)2/3EX2/3
k,0
(c)
≤(Lk)2/3
(p−1.5r1.5
2·Lt)2/3≤(p−1.5r1.5
2)−2/3.(48)
Where the inequality (a)is from Markov’s inequality. Inequality (b)is from the optional stopping
time theorem for supermartingales and inequality (c)is from the fact that Ltis non-decreasing.
Therefore, we can conclude that:
P(∃i≤r2, τ≤T2such that qτ
i≤p−1.5r1.5
2·Lτ)
≤r2P(∃ksuch that τ1
k< τ0
k)
≤r2T2−1X
k=0P 
τ1
k< τ0
k
≤r2T2(p−1.5r1.5
2)−2/3
≤T2p(49)
where the first inequality is simply a union bound over i= 1,2, ..., r 2. Then
T2p≤O(η−1log(d))cv
M2log(d)≤O(M2log(d))cv
M2log(d)≤0.01, (50)
where the constant hidden in O(·)only depends on the choice of α. Since log(1/α)≤4 log( d), the
constant hidden in O(·)is absolute. Therefore, the last inequality holds with sufficiently small cv,
which does not depend on other parameters.
A.3 Useful Lemmas
In this part we bound some quantities that we frequently encounter as the error terms. These lemmas
will simplify our proofs in later parts.
The next lemma helps to bound the “interaction error” arose from the non-orthogonality of V⋆and
U⋆.
Lemma 8. LetRt,Qt,Etandϵ1be defined as above. We have
U⊤
tUt− 
RtR⊤
t+QtQ⊤
t+E⊤
tEt≤6ϵ1∥Ut∥2(51)
Proof. From the definition of Rt,Qt,Et, we have
U⊤
tUt=
U⋆Rt⊤+V⋆Qt⊤+Et⊤
U⋆Rt⊤+V⋆Qt⊤+Et
=RtR⊤
t+QtQ⊤
t+E⊤
tEt+U⊤
t
IdU⋆Idres+ IdV⋆Idres
+ Id resIdU⋆+ Id resIdV⋆+ IdU⋆IdV⋆+ IdV⋆IdU⋆
Ut.(52)
Note that
∥IdU⋆IdV⋆∥=U⋆U⋆⊤V⋆V⋆⊤≤ϵ1 (53)
and
∥IdresIdU⋆∥=∥(I−IdU⋆−IdV⋆) IdU⋆∥=∥−IdU⋆IdV⋆∥ ≤ϵ1. (54)
Similarly, for the other terms, we can prove that all the six terms in the bracket in the last line of 52
have operator norm ≤ϵ1. This completes the proof.
The next lemma helps to bound the RIP error in the dynamic of Ut.
Lemma 9 (Upper Bound for Et).Under the assumption of Theorem 2, if ∥Et∥,∥Qt∥,∥Rt∥<1.1
and∥Et∥2
F<1, we have that:
Ut⊤Et◦
UtUt⊤−U⋆U⋆⊤−V⋆ΣtV⋆⊤≤2M1δ√r1+r2∥Ut∥. (55)
18Proof.
Et◦
UtUt⊤−U⋆U⋆⊤−V⋆ΣtV⋆⊤
(a)
≤Et◦
V⋆ΣtV⋆⊤+Et◦ 
EtE⊤
t+Et◦
UtUt⊤−U⋆U⋆⊤−EtE⊤
t
(b)
≤δ
∥Σt∥F+EtEt⊤
∗
+R⊤
tRt−I
F+Q⊤
tQt
F+ 2∥Et∥(∥Rt∥F+∥Qt∥F) + 2Qt⊤Rt
F
≤δ(√r2M1+ 1 + 3√r1+ 4√r2+ 8(√r1+√r2) + 8√r1)
≤2M1δ√r1+r2,(56)
where in (a)we use the linearity of Et◦(·)and the triangle inequality. In (b)we use Lemma 2 for
the first term, Lemma 4 for the second term, and the expansion:
UtUt⊤−U⋆U⋆⊤−EtE⊤
t=U⋆(Rt⊤Rt−I)U⋆⊤+V⋆Qt⊤QtV⋆⊤
+Et(RtU⋆⊤+QtV⋆⊤) + (V⋆Qt⊤+U⋆Rt⊤)Et⊤
+V⋆Qt⊤RtU⋆⊤+U⋆Rt⊤QtV⋆⊤.(57)
for the third term which shows that UtUt⊤−U⋆U⋆⊤−EtE⊤
thas rank no more than 2(r1+r2).
Hence we can conclude that:
Ut⊤Et◦
UtUt⊤−U⋆U⋆⊤−V⋆ΣtV⋆⊤≤2M1δ√r1+r2· ∥Ut∥. (58)
The following lemma tells how to bound the interaction error and RIP error using the auxiliary
sequences RtandLtwe have already defined:
Lemma 10 (Bound Using calibration Line) .Under the assumptions of Theorem 2, if ∥Et∥ ≤ ∥Rt∥ ≤
min{4Rt,1.1}and∥Qt∥ ≤√r2p−1.5r1.5
2·Lt, we have
 
M1ϵ1+ 2M1δ√r1+r2
∥Ut∥ ≤Lt∧5
576log−11
α
Rt. (59)
Proof. From triangle inequality and the condition of this lemma (2ϵ1≤δ), we have that:
 
M1ϵ1+ 2M1δ√r1+r2
∥Ut∥ ≤5
2M1δ√r1+r2(∥Rt∥+∥Qt∥+∥Et∥)
≤5
2M1δ√r1+r2(8Rt+√r2p−1.5r1.5
2·Lt).(60)
Then it suffices to check:


20M1δ√r1+r2Rt(a)
≤1
2Lt;
2
5M1δ√r2p−1.5r1.5
2√r1+r2Lt(b)
≤1
2Lt;
20M1δ√r1+r2Rt(c)
≤5
1152log−1 1
α
Rt;
2
5M1δ√r2p−1.5r1.5
2√r1+r2Lt(d)
≤5
1152log−1 1
α
Rt,
where (a)is from the definition of Lt,(b)and(c)are from the assumption on δin Theorem 2, and (d)
is from the assumption on δ(the absolute constant cin the condition for δ) and the fact that Lt≤Rt.
Hence the proof is completed.
19A.4 Bounds of Qt
For evaluating the magnitude of ∥Qt∥, we consider its columns. We denote each column of Qtas
q(t)
ifori= 1,2, . . . , r 2. And use qt
iwe defined above to upper bound them. Once we provide a
uniform bound for all q(t)
i, we can also bound ∥Qt∥.
Lemma 11. Under the assumption of Theorem 2, under the event of qt
i< p−1.5r1.5
2·Ltwithp≥ϵ2/3
2
for all i= 1,2, . . . , r 2andt= 0,1, . . . , T , if∥Et∥ ≤ ∥Rt∥ ≤1.1,∥Et∥2
F<1and∥qt
j∥ ≤qt
jfor
allj= 1, . . . , r 2, then we have
∥q(t+1)
i∥ ≤qt+1
i< p−1.5r1.5
2Lt+1 (61)
for all i= 1,2, . . . , r 2.
Proof. From the dynamic of Qt:
Qt+1=Qt−ηU⊤
tUtQt+ηQtΣ−η 
ϵ1+ 2M1δ√r1+r2
∥Ut∥
,
we can see that for each column q(t)
iofQt:
∥q(t+1)
i∥ ≤
I−ηU⊤
tUt+ηΣ(et)
iiI
q(t)
i+ηX
j̸=i|Σ(et)
ji|∥q(t)
j∥+η 
ϵ1+ 2M1δ√r1+r2
∥Ut∥
≤(1 +ηΣ(et)
ii)∥q(t)
i∥2+ηX
j̸=i|Σ(et)
ji|∥q(t)
j∥+ηLt.
where we use Lemma 10. For the second term we have:
ηX
j̸=i|Σ(et)
ji|∥q(t)
j∥(a)
≤ηco
r2M1.5
2p−1.5r1.5
2Lt(b)
≤ηLt(coc−1.5
vr−0.5log1.5d)(c)
≤1, (62)
where in (a)we use Assumption 1 (c) and induction hypothesis that ∥q(t)
j∥< p−1.5r1.5
2·Lt, in(b)
we use the definition of p(Definition 4), and in (c)we use Assumption 1 (a) and Assumption 2 with
sufficiently small co(which depends solely on another universal constant cv). Hence we have
∥q(t+1)
i∥ ≤(1 +ηΣ(et)
ii)∥q(t)
i∥2+ 2ηLt. (63)
There are two probable cases:
(
If∥q(t)
i∥ ≤Lt,then∥q(t+1)
i∥ ≤(1 +ηΣt
ii+ 2η)Lt≤(1 +ηΣt
ii+ 2η)qt
i≤qt+1
i;
If∥q(t)
i∥>Lt,then∥q(t+1)
i∥ ≤(1 +ηΣt
ii+ 2η)∥qt
i∥ ≤(1 +ηΣt
ii+ 2η)qt
i≤qt+1
i.
Both lead to the results we desire.
With the above lemma, we can also give a bound for ∥Qt∥:
Corollary 1. Under the condition of Lemma 11, we have that
∥Qt+1∥ ≤ ∥Qt+1∥F≤vuutr2X
i=1(qt+1
i)2< p−1.5r1.5
2√r2Lt+1. (64)
A.5 Bounds of Et
In this section, we bound the increments of both the operator norm and the Frobenius norm of Et.
The next lemma provide an upper bound for ∥Et∥.
Lemma 12 (Increment of Spectral Norm of Et).Under the assumption of Lemma 11, we have
∥Et+1∥ ≤ ∥Et∥+ηLt. (65)
20Proof. From the dynamic of Et(24), we can derive that
∥Et+1∥ ≤Et 
I−ηU⊤
tUt+ηIdres
U⋆U⋆⊤+V⋆ΣtV⋆⊤+∥IdresEt∥
∥Ut∥
(a)
≤ ∥Et∥+η 
(ϵ1+M1+ 2M1δ√r1+r2
∥Ut∥
(b)
≤ ∥Et∥+η5M1δ√r1+r2(∥Rt∥+∥Qt∥)
(c)
≤ ∥Et∥+ηLt,
where (a)is from Lemma 9 and the fact that ∥IdresUt∥,∥IdresUt∥ ≤ϵ1.(b)and(c)are derived
similarly as Lemma 10.
The next lemma bounds the F-norm of error component Et.
Lemma 13 (Increment of the F-norm of Error Dynamic) .Under the assumption of Lemma 11, and
we further assume that ∥Et∥≲δM1√r1+r2log(1/α), then the Frobenius norm of Et+1can be
bounded by
∥Et+1∥2
F≤(1 +O(ηδM 1√r1+r2))∥Et∥2
F+ηO(δ2M2
1(r1+r2)1.5log(1/α)), (66)
which immediately implies,
∥Et∥2
F≲ 
(1 +O(ηδM 1√r1+r2))t−1
δM1(r1+r2) log(1 /α)
≲tηδ2M2
1(r1+r2)1.5log(1/α).(67)
Proof. We expand ∥Et+1∥2
Ffrom the dynamic of Et(24):
∥Et+1∥2
F=Et 
I−ηU⊤
tUt
+ηIdres
U⋆U⋆⊤+V⋆ΣtV⋆⊤
Ut−ηIdresEtUt2
F
=∥Et(I−ηUt⊤Ut)∥2
F+η2∥IdresEtUt∥2
F
−2ηD
Et(I−ηUt⊤Ut),IdresEtUtE
+ηIdres
U⋆U⋆⊤+V⋆ΣtV⋆⊤
Ut2
F
+D
Et 
I−ηU⊤
tUt
, ηIdres
U⋆U⋆⊤+V⋆ΣtV⋆⊤
UtE
+D
ηIdres
U⋆U⋆⊤+V⋆ΣtV⋆⊤
Ut, ηIdresEtUtE
def= (1) + (2) + (3) + (4) + (5) + (6) .(68)
Now we bound the six parts separately. For the first part, since 0⪯ηU⊤
tUt⪯I, we have
∥Et(I−ηUt⊤Ut)∥2
F≤ ∥Et∥2
F. (69)
For the second part:
(2)≤η2D
Et,Idres2EtUtUt⊤E
(a)
≤η2δ
∥UtUt⊤−U⋆U⋆⊤−EtEt⊤∥F+∥EtEt⊤∥∗+∥V⋆ΣtV⋆⊤∥F
Et(UtUt⊤−EtEt⊤)
F+EtEtEt⊤
∗
≤η2δ
∥UtUt⊤−U⋆U⋆⊤−EtEt⊤∥F+∥EtEt⊤∥∗+∥V⋆ΣtV⋆⊤∥F
∥Et∥UtUt⊤−EtEt⊤
F+EtE⊤
t
∗
(b)
≲η2δM1√r1+r2·δM1√r1+r2· 
O(√r1+r2) +∥Et∥2
F
≲η2δ2M2
1(r1+r2)1.5.(70)
21In(a)we use similar technique as in Lemma 9 to divide UtU⊤
t−U⋆U⋆⊤−V⋆ΣtV⋆⊤into three
parts so that we can use Lemma 1 and Lemma 3. In (b)we use Lemma 9 to bound the first two terms
and (57) to bound the third term with the assumption that ∥Rt∥,∥Qt∥,∥Et∥<2.
For the third part:
(3)(a)=−2ηD
Et,IdresEt(I−ηUt⊤Ut)Ut⊤E
=−2ηD
Et,IdresEt(I−ηUt⊤Ut)(Et⊤+RtU⋆⊤+QtV⋆⊤)E
(b)
≤2ηδ
∥UtUt⊤−U⋆U⋆⊤−EtEt⊤∥F+∥EtEt⊤∥∗+∥Σt∥F
·
∥Et(I−ηUt⊤Ut)Et⊤∥∗+∥Et(I−ηUt⊤Ut)Rt∥F+∥Et(I−ηUt⊤Ut)Qt∥F
(c)
≤2ηδO(M1√r1+r2) 
∥Et∥2
F+∥Et∥∥Rt∥F+∥Et∥∥Qt∥F
≤2ηδO(M1√r1+r2) 
∥Et∥2
F+ (2√r1+ 2√r2)∥Et∥
≲ηδM 1√r1+r2∥Et∥2
F+ηδ2M2
1(r1+r2)1.5log(1/α),
(71)
where in (a)we use the fact that ⟨A,BCD⟩=⟨B⊤AD⊤,C⟩. In(b)we separate Etas in (70). In
(c), for the first term we use the upper bound for Etappeared in Lemma 9, for the second term we
use∥AB∥F≤ ∥A∥∥B∥F(and similarly for nuclear norm) and ∥I−ηU⊤
tUt∥ ≤1.
For the fourth part:
(4)≤2η2ϵ2
1∥Rt∥2
F+ 2η2ϵ2
1∥Qt∥2
F≤8η2ϵ2
1(r1+r2), (72)
where the first inequality is from Cauchy’s inequality and the fact that ∥IdresU⋆∥,∥IdresV⋆∥ ≤ϵ1.
For the fifth part:
(5)≤Et 
I−ηU⊤
tUt·ηIdres
U⋆U⋆⊤+V⋆ΣtV⋆⊤
Ut
∗
≲∥Et∥ηϵ1M1(r1+r2)
≲η 
δM1√r1+r2log(1/α)
ϵ1M1(r1+r2)
≤ηδ2M2
1(r1+r2)1.5log(1/α),(73)
where the first inequality is from the norm inequality ⟨X,Y⟩ ≤ ∥X∥∗∥Y∥and in the last inequality
we use the fact that ϵ1< δ.
For the sixth part:
(6) = η2D
Et,Idres2
U⋆U⋆⊤+V⋆ΣtV⋆⊤
UtU⊤
tE
(a)
≤η2∥Et∥ · ∥Idres2
U⋆U⋆⊤+V⋆ΣtV⋆⊤
UtU⊤
t∥∗
≤η2∥Et∥ · ∥Ut∥2· ∥Idres2
U⋆U⋆⊤+V⋆ΣtV⋆⊤
∥∗
(b)
≲η2δM1√r1+r2· ∥Ut∥2ϵ1(r1+M1r2)
≲η2δM1ϵ1M1(r1+r2)1.5
≲η2δ2M2
1(r1+r2)1.5.(74)
In(a)we use the norm inequality ⟨X,Y⟩ ≤ ∥ X∥∗∥Y∥and in (b)we use ∥Idres∥ ≤ 1and
∥IdresUt∥,∥IdresUt∥ ≤ϵ1.
Now combining Equation (69)-(74), along with the fact that ∥E0∥2
F≤dα2< d−1≪δ2r1.5, we can
derive the result we desire.
22A.6 Analysis for Phase 1
In this section, we give a rigorous analysis for phase 1:
Theorem 4 (Phase 1 analysis) .Under the assumptions of Theorem 2. During the first T1=
O(1
ηlog(1
α))steps, with probability at least 0.995, the following holds for any t∈[0, T1], that
•σj(Rt+1)>(1 +η/3)σj(Rt)for all j∈[r1];
•∥Qt∥F≤p−1.5r1.5
2√r2·Lt≤δ⋆<0.01, where Ltis formally defined in (38).
•∥Et∥≲δ√r1+r2≤ ∥Rt∥and∥Et∥2
F≲δ2M2
1(r1+r2)1.5log(1/α)2.
Finally, we have σ1(RT1), σr1(RT1)∈ 1
4,7
18
.
In the below contexts, unless otherwise specified, we abbreviate the largest and smallest singular
values of Rtasσ(t)
1andσ(t)
r1.
The next lemma tells that, if ∥Qt∥and∥Et∥are both small, then Rtincreases steadily and the
deviation between its singular values is small.
Lemma 14 (Dynamic of Singular Values of Rtin Phase 1) .For some t≤T1−1, under the
assumptions of Lemma 11, if ∥Et∥,∥Qt∥<1
96log−1(1/α)andRt≤σ(t)
r1≤σ(t)
1≤Rt, then
Rt+1≤σ(t+1)
r1≤σ(t+1)
1≤Rt+1. (75)
and
σ(t+1)
1≥(1 +η/3)σ(t)
1
σ(t+1)
r1≥(1 +η/3)σ(t)
r1(76)
Proof. From the dynamic of Rt:
Rt+1= (I−ηU⊤
tUt+ηI)Rt+ηU⊤
tV⋆ΣtV⋆⊤U⋆−ηU⊤
tEtU⋆
= (I−ηRtR⊤
t+ηI)Rt−η(QtQ⊤
t+E⊤
tEt)Rt+ηU⊤
t
(M1ϵ1+ 2M1δ√r+r2)
.
We use σ(t)
1andσ(t)
r1to denote the largest/smallest singular value of Rt. To control the dynamic of
σ(t)
1andσ(t)
r1, we need to bound the magnitude of the error term, that isη(QtQ⊤
t+E⊤
tEt)Rt+ηU⊤
t[2.5δM1√r1+r2]
≤η
∥Qt∥2+∥Et∥2+1
32log−1(1/α)
σ(t)
1
≤η(1
96+1
96+1
96) log−1(1/α)σ(t)
1
≤η
32log−1(1/α)σ(t)
1,(77)
where in the first inequality we use the assumption for ∥Qt∥and∥Et∥andδ. Therefore, from Weyl’s
inequality, we have that(
σ(t+1)
1≤(1−ησ(t)
12+η)σ(t)
1+η
32log (1 /α)−1σ(t)
1;
σ(t+1)
r1≥(1−ησ(t)
r12+η)σ(t)
r1−η
32log (1 /α)−1σ(t)
1.(78)
Using the assumption that
σ(t)
1≤Rt, σ(t)
r1≥Rt, t= 0,1, . . . , T 1. (79)
And Lemma 5, we can conclude that
(1−1/6)Rt+1≤Rt+1≤σ(t+1)
r1≤σ(t+1)
1≤Rt+1≤(1 + 1 /6)Rt+1. (80)
For the increasing speed of σ(t)
r1, note that σ(t)
1<2σ(t)
r1, therefore(
σ(t+1)
1≥(1−1
4η+η−1
32η)σ(t)
1;
σ(t+1)
r1≥(1−1
4η+η−2
32η)σ(t)
r1.(81)
This proves the desired result.
23Now that the supporting lemmas are prepared, we can begin the proof of Theorem 4
Proof of Theorem 4. The initial value of U0implies that
∥U0∥=∥R0∥=∥Q0∥=∥E0∥=α,∥E0∥2
F≤α2d. (82)
Recall that the time T1≤5
ηlog(1/α)is the first time Rtenters the region (1/3−η,1/3). We have
that the event of qt
i< p−1.5r1.5
2·Ltfor all i= 0, . . . , r 2, t= 0, . . . , T 1happens with probability
over0.995. In this event, we can use Lemma 11, 12, 13 and 14 to inductively prove:
• For the operator norm of Et, we have that for all t≤T1:
∥Et∥ ≤α+ηTX
t=0Lt
≤α(1 +η·240
ηlog1
α
)
+ 40M1δ√r1+r2·η
3·
1 + (1 + η/3)−1+ (1 + η/3)−2+···
≤250αlog1
α
+ 40M1δ√r1+r2(1 +η/3)
≤40M1δ√r1+r2
<1
96log−1(1/α).(83)
where in the second inequality we use Lemma 14 that ∥Rt∥increases with rate not less than
(1 + 3 /η).
• For the Frobenius norm of Et:
∥Et∥2
F≤T1ηδ2M2
1(r1+r2)1.5log(1/α)≲δ2M2
1(r1+r2)1.5log2(1/α)<1 (84)
• For∥Qt∥, we use Corollary 1:
p−1.5r1.5
2√r2LT1≲p−1.5r1.5
2√r2δM1√r1+r2<1
96log−1(1/α). (85)
• For Rt, we have for t≤T1:
(1−1/6)Rt≤Rt≤σ(t+1)
r1≤σ(t+1)
1≤Rt≤(1 + 1 /6)Rt. (86)
• For the condition ∥Et∥ ≤ ∥Rt∥:
∥Et+1∥ − ∥Et∥ ≤ηLt≤η
10Rt<η
5∥Rt∥<∥Rt+1∥ − ∥Rt∥. (87)
Hence the proof is completed.
A.7 Analysis for Phase 2
In phase 1, the signal component Rtgrows at a stable speed from αtoO(1)while the spurious
component Qtand the error component Etare kept at low levels. In phase 2, we will characterize
howRtapproach 1 and how to continually keep QtandEt.
Lemma 15 (Stability of Rt).If there exists some real number gsatisfying
0.01> g≥ ∥Qt∥2+∥Et∥2+ 4∥U⊤
tEt∥ (88)
for all t=T1+ 1, . . . , T 1+T−1, then we have
1−5g≤σ(t)
r1≤σ(t)
1≤1 +g, (89)
for all t=T1+O(1
ηlog
1
g
), . . . , T 1+T−1
24Proof. First we consider the upper bound for σ(t)
1. Similar to Equation (78), we have
σ(t+1)
1≤(1−ησ(t)
12+η+ηg)σ(t)
1. (90)
Note that Equation (90) is equivalent to
p
1 +g−σ(t+1)
1≥(p
1 +g−σ(t)
1)
1−η(σ(t)
1+p
1 +g)σ(t)
1
. (91)
With σ(t)
1(T1)<1
2, one can see that σ(t)
1never goes above√1 +g≤1 +g.
Now we consider σ(t)
r1. After phase 1 we have σ(T1)
r≥5
6(1/3−η)>1
4. Ifσ(t)
1≤5σ(t)
r1, similarly
we have:
σ(t+1)
r1≥(1−ησ(t)
12+η−5ηg)σ(t)
r1. (92)
Which implies that, if σ(t)
r1<√1−5g,
p
1−5g−σ(t+1)
r1≤(p
1−5g−σ(t)
r1)(1−η(σ(t)
r1+p
1−5g)σ(t)
r1)
≤(1−1
4η)(p
1−5g−σ(t)
r1)(93)
Therefore, σ(t)
r1will get larger than√1−5g−g2≥1−5gat some time t≤T1+8
ηlog
1
g
. Also
from Equation (92) we can see that, σ(t)
r1keeps increasing before it gets larger than√1−5g. And
once it surpasses√1−5g, it never falls below than√1−5gagain. Therefore, σ(t)
1≤5σ(t)
r1is
satisfied and the proof proceeds.
Now we can state and prove:
Theorem 5 (Phase 2 Analysis) .Under the assumptions of Theorem 2. Let T2=T1+O(1
ηlog((r1+
r2)/δ))≤O(1
ηlog(1
α)). Then with probability at least 0.995, we have
σ1(RT2), σr(RT2)∈
1−O(δ⋆2M2
1∨δM1√r1+r2),1 +O(δ⋆2M2
1∨δM1√r1+r2)
.(94)
And for t=T1+ 1, . . . , T 2, we have
•∥Qt∥F≤p−1.5r1.5
2√r2Lt≤p−1.5r1.5
2√r240M1δ√r1+r2= 40M1δ⋆;
•∥Et∥≲δM1√r1+r2log(1/α))and∥Et∥2
F≲δ2M2
1(r1+r2)1.5log(1/α)2.
Proof of Theorem 5. The error gin Lemma 15 is no less than Ω(δ2M2
1(r1+r2))≫αorder, therefore
T2=T1+1
ηlog (1 /α)suffices for σ(t)
r1to reach 1−5g. Then similar to the induction in the proof of
Theorem 4, we can derive(in the same high probability event):
•∥Et∥ ≤40ηδM 1√r1+r2+ 40ηδM 1√r1+r2(t−T1)≤80δM1√r1+r2log(1/α))<
0.01;
•∥Et∥2
F≲tηδ2M2
1(r1+r2)1.5log(1/α)≲δ2M2
1(r1+r2)1.5log(1/α)2<1;
•∥Qt∥ ≤p−1.5r1.5
2√r2Lt≤p−1.5r1.5
2√r240M1δ√r1+r2=p−1.540M1δ⋆<0.01;
Hence the assumption in Lemma 15 is satisfied, with
g≲p−3δ⋆2M2
1∨δM1√r1+r2 (95)
Therefore,|∥RT2∥ −1∥≲p−3δ⋆2M2
1∨δM1√r1+r2 (96)
25Proof of Theorem 2. Using Theorem 4 and Theorem 5 with T=T2, we have
∥UT2U⊤
T2−A⋆∥F(a)
≤ ∥ET2E⊤
T2∥F+∥R⊤
T2RT2−I∥F+∥Q⊤
T2QT2∥F
+ 2∥ET2QT2∥F+ 2∥EtRt∥F+ 2∥R⊤
T2QT2∥F
(b)
≤ ∥ET2∥2
F+O
δ⋆2M2
1∨δM1√r1+r2√r1+∥QT2∥2
F
+ 2∥ET2∥∥QT2∥F+ 2∥ET2∥∥Rt∥F+ 2∥QT2∥F∥Rt∥
(c)
≲δ2M2
1(r1+r2)1.5log2(1/α) + (δ⋆2M2
1∨δM1√r1+r2)√r1+δ⋆2M2
1
+ (δ⋆M1+ (1 + o(1))√r1)δM1√r1+r2log(1/α) +δ⋆M1(1 +o(1))
≲(δ⋆2M2
1√r1∨δ⋆M1) log2d.
where in (a)we decompose UU t⊤(See (57)) and triangle inequality. In (b)and(c)we use Theorem 5
and repeatedly use the fact ∥AB∥F≤ ∥A∥∥B∥F. This completes the proof.
B Deferred Proofs
B.1 Proof of Proposition 1
In the below contexts, notations such as C, c, C 1, c1always denote some positive absolute constants.
Such notation is widely adopted in the field of non-asymptotic theory.
We first state some useful definitions and lemmas:
Definition 6 (ϵ-Net and Covering Numbers) .Let(T, d)be a metric space. Let ϵ >0. For a subset
K⊂T, a subset M ⊆ Kis called an ϵ-net of Kif every point in Kis within distance ϵof some
point in M. We define the covering number of Kto be the smallest possible cardinality of such M,
denoted as N(K, ϵ).
Lemma 16 (Covering Number of the Euclidean Ball) .LetSn−1denote the unit Euclidean sphere in
Rn. The following result satisfies for any ϵ >0:
N(Sn−1, ϵ)≤2
ϵ+ 1n
. (97)
Lemma 17 (Two-sided Bound on Gaussian Matrices) .LetAbe an d×rmatrix whose elements
Aijare independent N(0,1)random variables. Then for any t≥0we have
√
d−C(√r+t)≤σr(A)≤σ1(A)≤√
d+C(√r+t) (98)
with probability at least 1−2 exp(−t2).
Lemma 18 (Approximating Operator Norm Using ϵ-nets) .LetAbe an m×nmatrix and ϵ∈[0,1/2).
For any ϵ-netM1for the sphere Sn−1and any ϵ-netM2of the sphere Sm−1, we have
sup
x∈M 1,y∈M 2⟨Ax,y⟩ ≤ ∥A∥ ≤1
1−2ϵsup
x∈M 1,y∈M 2⟨Ax,y⟩. (99)
Moreover, if m=n, then we have
sup
x∈M 1⟨Ax,x⟩ ≤ ∥A∥ ≤1
1−2ϵ−ϵ2sup
x∈M 1,y∈M 2|⟨Ax,y⟩|. (100)
Lemma 19 (Concentration Inequality for Product of Gaussian Random Varables) .Suppose Xand
Yare independent N(0,1)random variables. Then ⟨X, Y⟩is a sub-exponential random variable.
Therefore for (X1, . . . , X m, Y1, . . . , Y m)⊤∼N(0,I2m), the following holds for any t≥0:
P 
1
mmX
i=1⟨Xi, Yi⟩> t!
<2 exp 
−cmin(t2, t)·m
. (101)
26Proof. Note that
⟨X, Y⟩=1
21√
2X+1√
2Y2
−1
21√
2X−1√
2Y2
. (102)
The two terms are independent and following Gamma distribution Γ 1
2,1
. Since Gamma distribution
random variables are sub-exponential, ⟨X, Y⟩is sub-exponential too. The concentration inequality
follows from Bernstein’s inequality. (See Theorem 2.8.2 of Vershynin [47]).
Now we prove Proposition 1:
Proof of Proposition 1. First we provide a bound for ∥M⊤
1M2∥. We fix ϵ= 1/4, and we can find
anϵ-netM1of the sphere Sr1−1andϵ-netM2of the sphere Sr2−1with
|M1| ≤9r1,|M2| ≤9r2. (103)
For each x∈ M 1andy∈ M 2, we have for 0< u < 1,
P1
dx⊤M⊤
1M2y> u
=P1
d⟨M1x,M2y⟩> u
≤2 exp(−cdu2),(104)
where we use the fact that M1xandM2yare independent N(0,Id)random vectors and an application
of Lemma 19. We let u=q
r1+r2
d·tfort <q
d
r1+r2, we have:
P 
1
d∥M⊤
1M2∥ ≥r
r1+r2
d·t!
(a)
≤P 
1
dmax
x∈M 1,y∈M 2x⊤M⊤
1M2y≥1
2r
r1+r2
d·t!
(b)
≤9r1+r2·2 exp 
−c2(r1+r2)t2
= 2 exp 
−(r1+r2)(c2t2−log(9))
,
(105)
where in (a)we use Lemma 18, in (b)we apply a union bound over all x∈ M 1andy∈ M 2.
Next, we bound ∥R−1
1∥and∥R−1
2∥. Recall the QR-decompositions of M1andM2:
M1=U⋆
1R1andM2=U⋆
2R2, (106)
which implies M⊤
1M1=R⊤
1R1andM⊤
2M2=R⊤
2R2, and consequently ∥R−1
1∥=σr1(M1)−1
and∥R−1
2∥=σr2(M2)−1. From Lemma 17,
P
∥R−1
1∥ ≥2√
d
=P 
σr1(M1)≤√
d
2!
<2 exp(−c1d). (107)
And similarly for ∥R−1
2∥. Finally, for t <q
d
r1+r2,
P U⋆⊤
1U⋆
2≥4tr
r1+r2
d!
=P 
R−⊤
1M⊤
1M2R−1
1≥4tr
r1+r2
d!
≤P
∥R−1
1∥ ≥2√
d
+P
∥R−1
2∥ ≥2√
d
+P 
1
d∥M⊤
1M2∥ ≥tr
r1+r2
d!
≤4 exp ( −c1d) + 2 exp 
−c2(r1+r2)t2
.(108)
This completes the proof.
27B.2 The Failure of Pooled Stochastic Gradient Descent
From Theorems 2 and 3, for the hard case in Theorem 3, we have a separation that Pooled Gradient
Descent fails to select out the invariant signal, whereas the HeteroSGD can succeed. This isolates the
implicit bias of online algorithms over heterogeneous data towards invariance and causality.
In this section, we give a rigorous proof for Theorem 3. We first demonstrate the failure of PooledGD
Theorem 6 (Negative Result for Pooled Gradient Descent) .Under the assumptions of Theorem 2,
for the certain case where U⋆⊥V⋆andEe∈DΣ(e)=Ir2, if we perform GD over all samples from
all environments and ends with T= Θ(log d), then Utkeeps approaching U⋆U⋆⊤+V⋆V⋆⊤,in
the sense thatUTU⊤
T−U⋆U⋆⊤−V⋆V⋆⊤
F≤˜O(δ∗2M2
1√r1+δ⋆M1) =o(1), (109)
during which for all t= 0,1, . . . , T :
UtU⊤
t−A⋆
F≳√r1∧r2. (110)
Proof of Theorem 6. Firstly, we emphasis that Theorem 2 also applies to the case where there is
only one environment and no spurious signals, the msamples are generated as: (We use underlined
notations to distinguish this setting from others)
yi=⟨Xi,A⋆⟩, i= 1, . . . , m (111)
In such cases, there is no randomness and UTU⊤
Tdeterministically learns A⋆and all the singular
values of Rtgrow at similar speeds.
Under the conditions in Theorem 6, we first construct a single-environment case. Let U⋆andV⋆
be defined as in Theorem 6, we let the invariant signal A⋆=U⋆U⋆⊤+V⋆V⋆⊤and there is no
spurious signal. Then the updating rule is:
Ut+1=Ut−η"
1
mmX
i=1⟨Xi,UtU⊤
t−A⋆⟩Xi#
Ut
=Ut−η
UtU⊤
t−A⋆
Ut−ηE◦
UtU⊤
t−A⋆
Ut.(112)
Using Theorem 2, we can prove that UtUtcontinuously approaches A⋆⊤=U⋆U⋆⊤+V⋆V⋆⊤in
phase 1 & 2, during which:
• In phase 1, ∥Rt∥<1/2therefore ∥UtU⊤
t−U⋆U⋆⊤∥F≳√r1.
•In phase 2, all the singular values of ∥Rt∥get larger than 1/6, from Weyl’s inequality, we
have that the top r2singular values of UtU⊤
t−U⋆U⋆⊤are all larger than 1/6. Hence
∥UtU⊤
t−U⋆U⋆⊤∥F≳√r2.
Therefore, ∥UtU⊤
t−U⋆U⋆⊤∥F≳√r1∧r2for all t= 0, . . . , T .
Now we prove Theorem 6. The updating rule can be written as
Ut+1=Ut−ηEe∼D"
1
mmX
i=1⟨X(e)
i,UtU⊤
t−A⋆−A(e)⟩X(e)
i#
Ut
=Ut−η
UtU⊤
t−A⋆−Ee∼DA(e)
Ut−ηEe∼Dh
Ee◦
UtU⊤
t−A⋆−A(e)i
Ut
=Ut−η
UtU⊤
t−
U⋆U⋆⊤+V⋆V⋆⊤
Ut−ηEe∼Dh
Ee◦
UtU⊤
t−A⋆−A(e)i
Ut.
We compare this updating rule with (112) . The only difference is the RIP error term. However,
the upper bounds for Ee◦ 
UtU⊤
t−A⋆−A(e)
used in the proof also apply for the expectation
Ee∼D
Ee◦ 
UtU⊤
t−A⋆−A(e)
. So we can derive the same conclusion that
UTU⊤
T−A⋆−Ee∼DA(e)
F≤o(1) (113)
28forT= Θ(1
θlog(1/α)), during which we have that for all t= 0,1, . . . , T :
UtU⊤
t−A⋆
F≳√r1∧r2. (114)
Now we are ready to prove Theorem 3. Assume that at each time t= 0, . . . , 1, we receive msamples
{X(t)
i, y(t)
i}m
i=1, each sample is independently sampled from environment et,i∼D, satisfying
y(t)
i=⟨X(t)
i,A⋆+A(et,i)⟩, (115)
and imply the Stochastic Gradient Descent
Ut+1= 
Id−η1
mmX
i=1(⟨X(t)
i,UtU⊤
t⟩ −y(t)
i)X(t)
i!
Ut. (116)
For technical convenience, we assume that Xis the symmetric Gaussian matrix with diagonal
elements from N(0,1)and off-diagonal elements from N(0,1/2). We further assume X(t)
iis
independent of et,i. This corresponds to the cases where each environment has infinitely many
samples and the linear measurements from different environments share the same distribution.
Proof of Theorem 3. Denote ¯A=Ee∈DA(e). Then we have
Ut+1= 
Id−η1
mmX
i=1(⟨X(t)
i,UtU⊤
t−A⋆−¯A⟩)X(t)
i!
Ut
+η 
1
mmX
i=1⟨X(t)
i,A(et,i)−¯A⟩X(t)
i!
Ut.
The first term is the dynamic of single environment matrix sensing problem, and the second term
is a zero-mean noise arising from SGD. Once we can prove that the second term is small with high
probability, then the dynamic will be similar to the dynamic of single environment matrix sensing
problem, thereby we can get a high-probability version of the result of Theorem 3.
Now we control the SGD noise term. Let M3be a1
4-net of the sphere Sd−1with|M3| ≤9d.
Then for any d×dmatrix M, we have ∥M∥ ≤4 max x∈M 3|x⊤Mx|. For any fixed x∈ M 3,
one can see that ⟨X(t)
i,A(et,i)−¯A⟩x⊤Mx has zero mean and is the product of two sub-Gaussian
random variable with sub-Gaussian parameter no more than 2M1(r1+r2)and2. Therefore, it is a
sub-exponential random variable with parameter no more than CM 1(r1+r2)for some universal
constant C >1. Then applying the Bernstein’s Inequality [ 47] and taking the union bound over M3,
we can obtain that
P 
sup
x∈M 3⟨X(t)
i,A(et,i)−¯A⟩x⊤Mx> CM 1(r1+r2)(r
t
m+t
m)!
<2·9dexp(−t).(117)
Setting t= 10dandm=dpoly( r1+r2, M1+M2,logd), we can obtain that with probability over
1−exp(−d),
1
mmX
i=1⟨X(t)
i,A(et,i)−¯A⟩X(t)
i≤1
poly( r1+r2, M1+M2,logd). (118)
Therefore, in this case the SGD error can be upper bounded in the same way as the RIP error at the
level of o(1/poly( r1+r2, M1+M2,logd)). This implies that the SGD error will not significantly
affect the dynamic with probability over 1−Texp(−d). Therefore (113) and(114) hold with
probability over 0.99.
Theorem 3 and Theorem 6 indicate that the failure is because the signal is averaged when calculating
gradients when we perform GD or SGD over pooled datasets. To the best of our knowledge, it is
29intrinsically hard to provide a rigorous statement when the batch size is small. We would like to
leave the theoretical analysis as a future work. In the following simulation, we aim to demonstrate
empirically that Pooled SGD fails to learn invariance with a small batch size. We consider the
|E|= 2 case and the environments are generated by A(1)=U⋆U⋆⊤+ (s+M)V⋆V⋆⊤and
A(2)=U⋆U⋆⊤+ (s−M)V⋆V⋆⊤where (U⋆,V⋆)is column orthonormal. Then the invariant
solution is A⋆=U⋆U⋆⊤and the spurious solution is A⋆+¯A=U⋆U⋆⊤+sV⋆V⋆⊤.We set
(α, d, r 1, r2, s, M, m ) = (10−3,30,5,5,0.5,4,80), use Gaussian measurements as Section 5 and let
Tbe sufficiently large. The following shows the F-norm between UtU⊤
tandA⋆orA⋆+¯A.
0.0 0.2 0.4 0.6 0.8 1.0
t/T1.01.52.02.53.03.54.0UtUtAF
PooledSGD/uni00A0with/uni00A0Batch/uni00A0Size=80
=0.01
=0.05
=0.1
0.0 0.2 0.4 0.6 0.8 1.0
t/T1.01.52.02.53.03.54.0UtUtA AF
PooledSGD/uni00A0with/uni00A0Batch/uni00A0Size=80
=0.01
=0.05
=0.1
Figure 6: These figures shows that when the batch size is small, the trajectory will be far away from
A⋆andA⋆+¯A, suggesting that the algorithm is not stable in this regime.
C Neural Networks with Quadratic Activations
In this section we discuss how to apply our results to nerral networks with quadratic activations. In
particular, Example 1. As discussed above,
y(e)
i=r1X
j=1q(a⊤
jx(e)
i) +rX
j=r1+1a(e)
jq(a⊤
jx(e)
i) =*
x(e)
ix(e)
i⊤,r1X
j=1aja⊤
j+rX
j=r1+1a(e)
jaja⊤
j+
,
(119)
and it is equivalent to matrix sensing problem with
A⋆=r1X
j=1aja⊤
j,A(e)=rX
j=r1+1a(e)
jaja⊤
jandX(e)
i=x(e)
ix(e)
i⊤. (120)
The main difference is that, when the samples xiare i.i.d. N(0,Id), the set of linear measurements
{x1x⊤
1, . . . ,xmx⊤
m}no longer satisfies the RIP property. However, the following lemma tells that,
with proper truncation, the set of measurements enjoys similar properties.
Lemma 20 (Lemma 5.1 of Li et al. [31]).Let(X1, . . . ,Xm) ={x1x1⊤, . . . ,xmx⊤
m}where xi’s
are i.i.d. ∼ N(0,I). LetR= log 1
δ
. Then, for every q, δ∈[0,0.01]andm≳dlog4d
qδ/δ2, with
probability at least 1−q, we have that for every symmetric matrix A:
1
mmX
i=1⟨Xi,A⟩Xi1|⟨Xi,A⟩|≤R−2A−tr(A)I≤δ∥A∥⋆. (121)
IfAhas rank at most rand operator norm at most 1, we have:
1
mmX
i=1⟨Xi,A⟩Xi1|⟨Xi,A⟩|≤R−2A−tr(A)I≤rδ. (122)
To accommodate this difference, we adopt the modified version of loss function and algorithm from
Li et al. [31].
30Algorithm 4 Modified Algorithm For Neural Network with Quadratic Activations
SetU0=αId, where αis a small positive constant.
Set step size η.
fort= 1, . . . , T −1do
Receive msamples (x(et)
i, y(et)
i)from current environment et.
Calculate ˆy(et)
i=1⊤q(Utx(et)
i),i= 1,2, . . . , m .
Calculate modified loss function ˜Lt(Ut) =1
mPm
i=1
ˆy(et)
i−y(et)
i2
1∥U⊤x(et)
i∥2≤R
Gradient Descent ˜Ut=Ut−η∇˜fL(Ut).
Letτt=∥A⋆+A(et)∥.
Shrinkage Ut+1=1
1−η(∥Ut∥2
F−τt)˜Ut
end for
Output: UT.
Remark 1. Here we encounter the same caveat that Algorithm 4 requires our knowledge on τt.
As discussed in Li et al. [31], the algorithm is likely to be robust if τtis replaced by its moment
estimation.
Now we outline the proof sketch of Example 1
Theorem 7 (Two-Layer NN with Quadratic Activation) .Leta1,···,ar∈Rdbe independent
random vectors sampled from normal distribution N(0,1
dId). For environment e∈ E, suppose the
target function is determined by r1invariant features and r2variant admits that for each sample
(x(e)
i, y(e)
i):
y(e)
i=r1X
j=1q(a⊤
jx(e)
i) +rX
j=r1+1a(e)
jq(a⊤
jx(e)
i) =*
x(e)
ix(e)
i⊤,r1X
j=1aja⊤
j+rX
j=r1+1a(e)
jaja⊤
j+
.(123)
Suppose we train the following two-layer NN:
f(x) =dX
j=1q(ujx), (124)
and the initialization of parameters {uj}satisfiesPd
j=1uju⊤
j=αI. If{a(e)
j}j,esatisfies
supe,j{|a(e)
j|}·maxj{1+|Eea(e)
j|}
minj{Vare[a(e)
j]}< c 0for some absolute constant c0, sample complexity m≫
dpoly( r,log(d),supe,j{|a(e)
j|}),α∈(d−4, d−1)andη∼maxj{1+|Eea(e)
j|}
minj{Vare[a(e)
j]}, then Algorithm 4 re-
turns solution that satisfies
∥dX
j=1uju⊤
j−A⋆∥F< o(1) (125)
with probability over 0.99.
Proof. similar to the proof of Theorem 1.2 of Li et al. [31], the modified algorithm is in fact equivalent
to(21) with RIP parameter (r, δ)when m=˜Ω(dr2δ−2). Hence it is fully reduced to the matrix
sensing problem.
Now we verify the conditions for A⋆=Pr1
j=1aja⊤
jandA(e)=Pr
j=r1+1a(e)
jaja⊤
j. Since
ui, i= 1, . . . , r are independently and uniformly sampled from sphere, we have that
•With high probability over the randomness of {ai}i, the eigenvalues of A⋆lie within
1−O(√r1/√
d),1 +O(√r1/√
d)
(See Theorem 4.6.1 of Vershynin [47]).
• The angle between Col(A⋆)andCol(A(e))is ofO(√r1+r2/√
d)order.
31Therefore we can construct two column orthogonal matrix U⋆andV⋆such that U⋆⊤V⋆= 0
andsin(col( U⋆),col(A⋆)),sin(col( V⋆),col(A(e)))≲√r1+r2/√
d. Hence we can apply The-
orem 2 on ˜A⋆:=U⋆U⋆⊤and˜A(e):=V⋆diag( a(e)
i)V⋆⊤. Such approximation only raises
O(√r1+r2/√
d)multiplicative error, which is negligible. And we can easily verify ˜A(e)satisfies
Assumption 2. Then this result follows from the proof of Theorem 9.
D The κ(A⋆)>1Case
In this section we show how to generalize our results to the κ(A⋆)>1case by leveraging the adaptive
subspace technique proposed by Li et al. [31] for single environment setting. This framework mainly
consists of the following steps:
First, instead of using the fixed subspace col(U⋆), we use an adaptive one St, where S0= col( U⋆)
andSt+1= (I−ηMt)Stwhere Mt=1
mPm
i=1⟨Xi,UtU⊤
t−A⋆⟩Xi. And we denote Zt= Id StUt
andHt= (Id−IdSt)Ut. Which makes the updating of Htsubstantially disentangled from Zt.
Second, we reason about the updating rule of Zt. Since the subspace is updated at each step, the
updating rule of Ztbecomes indirect. We introduce ˜Zt= (Id−ηHtZt⊤)Zt(Id−2ηZt+IdStMtHt)
so that Zt+1≈˜Zt−η∇L(˜Zt). It can be shown σmin(Zt)continually increases until it gets larger
than1
2√κ.
During this iteration, we can keep ˜Ztis near Ztfor each tand the principal angle θtbetween Stand
col(U⋆)satisfies sin(θt)≲ηρtwhere ρ=˜Θ(δ√r
κ).
Finally, when σmin(Zt)is sufficiently large and principal angle is small, we can use the local restricted
strongly convex property of Laround A⋆to prove ∥UtUt∥2
Fconverges with rate 1−Θ(η/κ).
For the multi-environment setting, we have the following result under a slightly stronger assumption
on the heterogeneity:
Theorem 8 (General Theorem) .Under Assumption 1 and 2, suppose the heterogeneity parameter
M2≳r2,ϵ1< δ. and the RIP parameter δ≲1
poly( r,log(d),M1+M2,κ). We choose the η∈
(24M−1
2,1
64M−1
1∧1
r2)andα∈(1/d4,1/d3), then running Algorithm 3 in T= Θ(log( α−1)/η)
steps, the algorithm outputs UTthat satisfies
∥UTU⊤
T−A⋆∥F≤o(1) (126)
with probability over 0.99.
Since the full proof of the adaptive subspace technique is involved, for clear representation, we point
out the main differences from the single-environment case. We need to address the following three
issues: (1) How to introduce the spurious component Qtinto the original framework; (2) Whether
the spurious signal A(e)significantly perturbs the dynamic of Zt; and (3) How to give a phase 2
analysis when there is no local restricted strongly convexity around A⋆?
We first cope with (1). With abuse of notation, we adopt the Mt,Zt,Htand additionally define
V(ada)
t = Id V⋆HtandE(ada)
t = (Id−IdV⋆)Ht. We can prove that
V(ada)
t+1=
IdV⋆+ηA(et)+O(ηδ√rM1+ (1 + ηM1) sin(θt))
V(ada)
t +E(ada)
t
≈
IdV⋆+ηA(et)
V(ada)
t +small terms ,
E(ada)
t+1= 
Idres+O(ηδ√rM1+ (1 + ηM1) sin(θt))
V(ada)
t +E(ada)
t
.
≈E(ada)
t +small terms .(127)
If we can ensure sin(θt)≲δpoly( r, M 1+M2,log(d)), we can get similar dynamics as (23) and 24,
then apply similar techniques in Section A.4 and Section A.5 to ensure VtandEtare no more
thanδpoly( r, M 1+M2,log(d)). w.h.p. Moreover, the dynamics in (127) is multiplicative, which
means if we decrease αby comparing to Theorem 2, VtandEtcan be further upper bounded by
d−1δpoly( r, M 1+M2,log(d))in phase 1.
32For issue (2), the spurious signal A(e)brings error about 1+O((δ+ϵ1)√rM1+)multiplicative factor,
which can be absorbed by the inherent RIP error of A⋆. Another difference is that, at the beginning
∥Vt∥or∥Et∥may be substantially larger than Ztdue to the oscillation. We emphasis that such
interference happens in RIP error term or non-orthogonal error term, multiplied by δ,sin(θt)orϵ1. We
can ensure such interference is negligible when δ≲1
poly( r,log(d),M1+M2,κ). Therefore, the dynamic
ofZtis benign, and the principal angle can be bounded by δpoly( r,log(d), M1+M2, κ)≪1.
Finally for issue (3), when σmin(Zt)≥1
2√κandsin(θt) =δpoly( r,log(d), M1+M2, κ)≪1.
We get back to the original subspace col(U⋆)andcol(V⋆). We have Ut=Zt+O(sin(θt)),
Vt=V(ada)
t +O(sin(θt)),Et=E(ada)
t +O(sin(θt))and∥Et−E(ada)
t∥F≲√rsin(θt). Then
we can use the technique from phase 2 analysis (Theorem 5) to complete the proof. We leave the
extension of this theorem for the case where M1, M2are constant level for future studies.
NeurIPS Paper Checklist
1.Claims
Question: Do the main claims made in the abstract and introduction accurately reflect the
paper’s contributions and scope?
Answer: [Yes]
Justification:
Guidelines:
•The answer NA means that the abstract and introduction do not include the claims
made in the paper.
•The abstract and/or introduction should clearly state the claims made, including the
contributions made in the paper and important assumptions and limitations. A No or
NA answer to this question will not be perceived well by the reviewers.
•The claims made should match theoretical and experimental results, and reflect how
much the results can be expected to generalize to other settings.
•It is fine to include aspirational goals as motivation as long as it is clear that these goals
are not attained by the paper.
2.Limitations
Question: Does the paper discuss the limitations of the work performed by the authors?
Answer: [Yes]
Justification: See conclusion for what we leave for future studies.
Guidelines:
•The answer NA means that the paper has no limitation while the answer No means that
the paper has limitations, but those are not discussed in the paper.
• The authors are encouraged to create a separate "Limitations" section in their paper.
•The paper should point out any strong assumptions and how robust the results are to
violations of these assumptions (e.g., independence assumptions, noiseless settings,
model well-specification, asymptotic approximations only holding locally). The authors
should reflect on how these assumptions might be violated in practice and what the
implications would be.
•The authors should reflect on the scope of the claims made, e.g., if the approach was
only tested on a few datasets or with a few runs. In general, empirical results often
depend on implicit assumptions, which should be articulated.
•The authors should reflect on the factors that influence the performance of the approach.
For example, a facial recognition algorithm may perform poorly when image resolution
is low or images are taken in low lighting. Or a speech-to-text system might not be
used reliably to provide closed captions for online lectures because it fails to handle
technical jargon.
•The authors should discuss the computational efficiency of the proposed algorithms
and how they scale with dataset size.
33•If applicable, the authors should discuss possible limitations of their approach to
address problems of privacy and fairness.
•While the authors might fear that complete honesty about limitations might be used by
reviewers as grounds for rejection, a worse outcome might be that reviewers discover
limitations that aren’t acknowledged in the paper. The authors should use their best
judgment and recognize that individual actions in favor of transparency play an impor-
tant role in developing norms that preserve the integrity of the community. Reviewers
will be specifically instructed to not penalize honesty concerning limitations.
3.Theory Assumptions and Proofs
Question: For each theoretical result, does the paper provide the full set of assumptions and
a complete (and correct) proof?
Answer: [Yes]
Justification: We provide assumptions in main text, proof details in appendix, and references
for certain tools.
Guidelines:
• The answer NA means that the paper does not include theoretical results.
•All the theorems, formulas, and proofs in the paper should be numbered and cross-
referenced.
•All assumptions should be clearly stated or referenced in the statement of any theorems.
•The proofs can either appear in the main paper or the supplemental material, but if
they appear in the supplemental material, the authors are encouraged to provide a short
proof sketch to provide intuition.
•Inversely, any informal proof provided in the core of the paper should be complemented
by formal proofs provided in appendix or supplemental material.
• Theorems and Lemmas that the proof relies upon should be properly referenced.
4.Experimental Result Reproducibility
Question: Does the paper fully disclose all the information needed to reproduce the main ex-
perimental results of the paper to the extent that it affects the main claims and/or conclusions
of the paper (regardless of whether the code and data are provided or not)?
Answer: [Yes]
Justification: See simulation section.
Guidelines:
• The answer NA means that the paper does not include experiments.
•If the paper includes experiments, a No answer to this question will not be perceived
well by the reviewers: Making the paper reproducible is important, regardless of
whether the code and data are provided or not.
•If the contribution is a dataset and/or model, the authors should describe the steps taken
to make their results reproducible or verifiable.
•Depending on the contribution, reproducibility can be accomplished in various ways.
For example, if the contribution is a novel architecture, describing the architecture fully
might suffice, or if the contribution is a specific model and empirical evaluation, it may
be necessary to either make it possible for others to replicate the model with the same
dataset, or provide access to the model. In general. releasing code and data is often
one good way to accomplish this, but reproducibility can also be provided via detailed
instructions for how to replicate the results, access to a hosted model (e.g., in the case
of a large language model), releasing of a model checkpoint, or other means that are
appropriate to the research performed.
•While NeurIPS does not require releasing code, the conference does require all submis-
sions to provide some reasonable avenue for reproducibility, which may depend on the
nature of the contribution. For example
(a)If the contribution is primarily a new algorithm, the paper should make it clear how
to reproduce that algorithm.
34(b)If the contribution is primarily a new model architecture, the paper should describe
the architecture clearly and fully.
(c)If the contribution is a new model (e.g., a large language model), then there should
either be a way to access this model for reproducing the results or a way to reproduce
the model (e.g., with an open-source dataset or instructions for how to construct
the dataset).
(d)We recognize that reproducibility may be tricky in some cases, in which case
authors are welcome to describe the particular way they provide for reproducibility.
In the case of closed-source models, it may be that access to the model is limited in
some way (e.g., to registered users), but it should be possible for other researchers
to have some path to reproducing or verifying the results.
5.Open access to data and code
Question: Does the paper provide open access to the data and code, with sufficient instruc-
tions to faithfully reproduce the main experimental results, as described in supplemental
material?
Answer: [No]
Justification: The simulations are a simple validation of our theory.
Guidelines:
• The answer NA means that paper does not include experiments requiring code.
•Please see the NeurIPS code and data submission guidelines ( https://nips.cc/
public/guides/CodeSubmissionPolicy ) for more details.
•While we encourage the release of code and data, we understand that this might not be
possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not
including code, unless this is central to the contribution (e.g., for a new open-source
benchmark).
•The instructions should contain the exact command and environment needed to run to
reproduce the results. See the NeurIPS code and data submission guidelines ( https:
//nips.cc/public/guides/CodeSubmissionPolicy ) for more details.
•The authors should provide instructions on data access and preparation, including how
to access the raw data, preprocessed data, intermediate data, and generated data, etc.
•The authors should provide scripts to reproduce all experimental results for the new
proposed method and baselines. If only a subset of experiments are reproducible, they
should state which ones are omitted from the script and why.
•At submission time, to preserve anonymity, the authors should release anonymized
versions (if applicable).
•Providing as much information as possible in supplemental material (appended to the
paper) is recommended, but including URLs to data and code is permitted.
6.Experimental Setting/Details
Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
results?
Answer: [Yes]
Justification: See simulation section.
Guidelines:
• The answer NA means that the paper does not include experiments.
•The experimental setting should be presented in the core of the paper to a level of detail
that is necessary to appreciate the results and make sense of them.
•The full details can be provided either with the code, in appendix, or as supplemental
material.
7.Experiment Statistical Significance
Question: Does the paper report error bars suitably and correctly defined or other appropriate
information about the statistical significance of the experiments?
35Answer: [No]
Justification: Our theoretical results provide success probability.
Guidelines:
• The answer NA means that the paper does not include experiments.
•The authors should answer "Yes" if the results are accompanied by error bars, confi-
dence intervals, or statistical significance tests, at least for the experiments that support
the main claims of the paper.
•The factors of variability that the error bars are capturing should be clearly stated (for
example, train/test split, initialization, random drawing of some parameter, or overall
run with given experimental conditions).
•The method for calculating the error bars should be explained (closed form formula,
call to a library function, bootstrap, etc.)
• The assumptions made should be given (e.g., Normally distributed errors).
•It should be clear whether the error bar is the standard deviation or the standard error
of the mean.
•It is OK to report 1-sigma error bars, but one should state it. The authors should
preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis
of Normality of errors is not verified.
•For asymmetric distributions, the authors should be careful not to show in tables or
figures symmetric error bars that would yield results that are out of range (e.g. negative
error rates).
•If error bars are reported in tables or plots, The authors should explain in the text how
they were calculated and reference the corresponding figures or tables in the text.
8.Experiments Compute Resources
Question: For each experiment, does the paper provide sufficient information on the com-
puter resources (type of compute workers, memory, time of execution) needed to reproduce
the experiments?
Answer: [No]
Justification: Computing environment is not important for our problem settings.
Guidelines:
• The answer NA means that the paper does not include experiments.
•The paper should indicate the type of compute workers CPU or GPU, internal cluster,
or cloud provider, including relevant memory and storage.
•The paper should provide the amount of compute required for each of the individual
experimental runs as well as estimate the total compute.
•The paper should disclose whether the full research project required more compute
than the experiments reported in the paper (e.g., preliminary or failed experiments that
didn’t make it into the paper).
9.Code Of Ethics
Question: Does the research conducted in the paper conform, in every respect, with the
NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines ?
Answer: [Yes]
Justification: All the authors have reviewed the NeurIPS Code of Ethics.
Guidelines:
•The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
•If the authors answer No, they should explain the special circumstances that require a
deviation from the Code of Ethics.
•The authors should make sure to preserve anonymity (e.g., if there is a special consid-
eration due to laws or regulations in their jurisdiction).
10.Broader Impacts
36Question: Does the paper discuss both potential positive societal impacts and negative
societal impacts of the work performed?
Answer: [NA]
Justification: We investigate theoretical models.
Guidelines:
• The answer NA means that there is no societal impact of the work performed.
•If the authors answer NA or No, they should explain why their work has no societal
impact or why the paper does not address societal impact.
•Examples of negative societal impacts include potential malicious or unintended uses
(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
(e.g., deployment of technologies that could make decisions that unfairly impact specific
groups), privacy considerations, and security considerations.
•The conference expects that many papers will be foundational research and not tied
to particular applications, let alone deployments. However, if there is a direct path to
any negative applications, the authors should point it out. For example, it is legitimate
to point out that an improvement in the quality of generative models could be used to
generate deepfakes for disinformation. On the other hand, it is not needed to point out
that a generic algorithm for optimizing neural networks could enable people to train
models that generate Deepfakes faster.
•The authors should consider possible harms that could arise when the technology is
being used as intended and functioning correctly, harms that could arise when the
technology is being used as intended but gives incorrect results, and harms following
from (intentional or unintentional) misuse of the technology.
•If there are negative societal impacts, the authors could also discuss possible mitigation
strategies (e.g., gated release of models, providing defenses in addition to attacks,
mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
feedback over time, improving the efficiency and accessibility of ML).
11.Safeguards
Question: Does the paper describe safeguards that have been put in place for responsible
release of data or models that have a high risk for misuse (e.g., pretrained language models,
image generators, or scraped datasets)?
Answer: [NA]
Justification: Our paper does not pose such risks.
Guidelines:
• The answer NA means that the paper poses no such risks.
•Released models that have a high risk for misuse or dual-use should be released with
necessary safeguards to allow for controlled use of the model, for example by requiring
that users adhere to usage guidelines or restrictions to access the model or implementing
safety filters.
•Datasets that have been scraped from the Internet could pose safety risks. The authors
should describe how they avoided releasing unsafe images.
•We recognize that providing effective safeguards is challenging, and many papers do
not require this, but we encourage authors to take this into account and make a best
faith effort.
12.Licenses for existing assets
Question: Are the creators or original owners of assets (e.g., code, data, models), used in
the paper, properly credited and are the license and terms of use explicitly mentioned and
properly respected?
Answer: [NA]
Justification: The paper does not use existing assets.
Guidelines:
• The answer NA means that the paper does not use existing assets.
37• The authors should cite the original paper that produced the code package or dataset.
•The authors should state which version of the asset is used and, if possible, include a
URL.
• The name of the license (e.g., CC-BY 4.0) should be included for each asset.
•For scraped data from a particular source (e.g., website), the copyright and terms of
service of that source should be provided.
•If assets are released, the license, copyright information, and terms of use in the
package should be provided. For popular datasets, paperswithcode.com/datasets
has curated licenses for some datasets. Their licensing guide can help determine the
license of a dataset.
•For existing datasets that are re-packaged, both the original license and the license of
the derived asset (if it has changed) should be provided.
•If this information is not available online, the authors are encouraged to reach out to
the asset’s creators.
13.New Assets
Question: Are new assets introduced in the paper well documented and is the documentation
provided alongside the assets?
Answer: [NA]
Justification: The paper does not release new assets.
Guidelines:
• The answer NA means that the paper does not release new assets.
•Researchers should communicate the details of the dataset/code/model as part of their
submissions via structured templates. This includes details about training, license,
limitations, etc.
•The paper should discuss whether and how consent was obtained from people whose
asset is used.
•At submission time, remember to anonymize your assets (if applicable). You can either
create an anonymized URL or include an anonymized zip file.
14.Crowdsourcing and Research with Human Subjects
Question: For crowdsourcing experiments and research with human subjects, does the paper
include the full text of instructions given to participants and screenshots, if applicable, as
well as details about compensation (if any)?
Answer: [NA]
Justification: The paper does not involve crowdsourcing nor research with human subjects.
Guidelines:
•The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
•Including this information in the supplemental material is fine, but if the main contribu-
tion of the paper involves human subjects, then as much detail as possible should be
included in the main paper.
•According to the NeurIPS Code of Ethics, workers involved in data collection, curation,
or other labor should be paid at least the minimum wage in the country of the data
collector.
15.Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
Subjects
Question: Does the paper describe potential risks incurred by study participants, whether
such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
approvals (or an equivalent approval/review based on the requirements of your country or
institution) were obtained?
Answer: [NA]
Justification: The paper does not involve crowdsourcing nor research with human subjects.
38Guidelines:
•The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
•Depending on the country in which research is conducted, IRB approval (or equivalent)
may be required for any human subjects research. If you obtained IRB approval, you
should clearly state this in the paper.
•We recognize that the procedures for this may vary significantly between institutions
and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
guidelines for their institution.
•For initial submissions, do not include any information that would break anonymity (if
applicable), such as the institution conducting the review.
39