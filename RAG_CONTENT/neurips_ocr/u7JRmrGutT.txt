Graph Edit Distance with General Costs
Using Neural Set Divergence
Eeshaan Jain∗†Indradyumna Roy∗‡
Saswat Meher‡Soumen Chakrabarti‡Abir De‡
†EPFL‡IIT Bombay
eeshaan.jain@epfl.ch
{saswatmeher,soumen,indraroy15,abir}@cse.iitb.ac.in
Abstract
Graph Edit Distance (GED) measures the (dis-)similarity between two given graphs,
in terms of the minimum-cost edit sequence that transforms one graph to the
other. However, the exact computation of GED is NP-Hard, which has recently
motivated the design of neural methods for GED estimation. However, they do not
explicitly account for edit operations with different costs. In response, we propose
GRAPH EDX, a neural GED estimator that can work with general costs specified
for the four edit operations, viz., edge deletion, edge addition, node deletion and
node addition. We first present GED as a quadratic assignment problem (QAP)
that incorporates these four costs. Then, we represent each graph as a set of node
and edge embeddings and use them to design a family of neural set divergence
surrogates. We replace the QAP terms corresponding to each operation with their
surrogates. Computing such neural set divergence require aligning nodes and
edges of the two graphs. We learn these alignments using a Gumbel-Sinkhorn
permutation generator, additionally ensuring that the node and edge alignments
are consistent with each other. Moreover, these alignments are cognizant of both
the presence and absence of edges between node-pairs. Experiments on several
datasets, under a variety of edit cost settings, show that GRAPH EDXconsistently
outperforms state-of-the-art methods and heuristics in terms of prediction error.
The code is available at https://github.com/structlearning/GraphEdX .
1 Introduction
The Graph Edit Distance (GED) between a source graph, G, and a target graph, G′, quantifies the
minimum cost required to transform Ginto a graph isomorphic to G′. This transformation involves a
sequence of edit operations, which can include node and edge insertions, deletions and substitutions.
Each type of edit operation may incur a different and distinctive cost, allowing the GED framework
to incorporate domain-specific knowledge. Its flexibility has led to the widespread use of GED for
comparing graphs across diverse applications including graph retrieval [ 5,6], pattern recognition [ 47],
image and video indexing [ 51,49] and chemoinformatics [ 21]. Because costs for addition and deletion
may differ, GED is not necessarily symmetric, i.e.,GED( G, G′)̸= GED( G′, G). This flexibility
allows GED to model a variety of graph comparison scenarios, such as finding the Maximum
Common Subgraph [ 43] and checking for Subgraph Isomorphism [ 13]. In general, it is hard to
even approximate GED [ 32]. Recent work [ 5,6,19,56,39] has leveraged graph neural networks
(GNNs) to build neural models for GED computation, but many of these approaches cannot account
for edit operations with different costs. Moreover, several approaches [ 40,31,56,6] cast GED as
the Euclidean distance between graph embeddings, leading to models that are overly attuned to
cost-invariant edit sequences.
*Equal contribution. Eeshaan Jain did this work while at IIT Bombay.
38th Conference on Neural Information Processing Systems (NeurIPS 2024).1.1 Present work
We propose a novel neural model for computing GED, designed to explicitly incorporate the various
costs of edit operations. Our contributions are detailed as follows.
Neural set divergence surrogates for GED We formulate GED under general (non-uniform) cost
as a quadratic assignment problem (QAP) with four asymmetric distance terms representing edge
deletion, edge addition, node deletion and node addition. The edge-edit operations involve quadratic
dependencies on a node alignment plan — a proposed mapping of nodes from the source graph to
the target graph. To avoid the the complexity of QAP [ 45], we design a family of differentiable set
divergence surrogates, which can replace the QAP objective with a more benign one. In this approach,
each graph is represented as a set of embeddings of nodes and node-pairs (edges or non-edges). We
replace the original QAP distance terms with their corresponding set divergences, and obtain the node
alignment from a differentiable alignment generator modeled using a Gumbel-Sinkhorn network.
This network produces a soft node permutation matrix based on contextual node embeddings from the
graph pairs, enabling the computation of the overall set divergence in a differentiable manner, which
facilitates end-to-end training. Our proposed model relies on late interaction, where the interactions
between the graph pairs occur only at the final layer, rather than during the embedding computation
in the GNN. This supports the indexing of embedding vectors, thereby facilitating efficient retrieval
through LSH [25, 24, 12], inverted index [20], graph based ANN [34, 37] etc.
Learning all node-pair representations The optimal sequence of edits in GED is heavily influenced
by the global structure of the graphs. A perturbation in one part of the graph can have cascading
effects, necessitating edits in distant areas. To capture this sensitivity to structural changes, we
associate both edges as well as non-edges with suitable expressive embeddings that capture the
essence of subgraphs surrounding them. Note that the embeddings for non-edges are never explicitly
computed during GNN message-passing operations. They are computed only once, after the GNN
has completed its usual message-passing through existing edges, thereby minimizing additional
computational overhead.
Node-edge consistent alignment To ensure edge-consistency in the learned node alignment map,
we explicitly compute the node-pair alignment map from the node alignment map and then utilize this
derived map to compute collective edge deletion and addition costs. More precisely, if (u, v)∈G
and(u′, v′)∈G′are matched, then the nodes uandvare constrained to match with u′andv′(or,v′
andu′) respectively. We call our neural framework as G RAPH EDX.
Our experiments across several real datasets show that (1) GRAPH EDXoutperforms several state-of-
the-art methods including those that use early interaction; (2) the performance of current state-of-
the-art methods improves significantly when their proposed distance measures are adjusted to reflect
GED-specific distances, as in our approach.
2 Related work
Heuristics for Graph Edit Distance GED was first introduced in [ 46]. Bunke and Allermann
[14] used it as a tool for non exact graph matching. Later on, [ 13] connected GED with maximum
common subgraph estimation. Blumenthal [7]provide an excellent survey. As they suggest,
combinatorial heuristics to solve GED predominantly follows three approaches: (1) Linear sum
assignment problem with error-correction, which include [ 27,41,53,55] (2) Linear programming,
which predominantly uses standard tools like Gurobi, (3) Local search [ 42]. However, they can be
extremely time consuming, especially for a large number of graph pairs. Among them Zheng et al.
[55] operate in our problem setting, where the cost of edits are different across the edit operations,
but for the same edit operation, the cost is same across node or node pairs.
Optimal Transport In our work, we utilize Graph Neural Networks (GNNs) to represent each graph
as a set of node embeddings. This transforms the inherent Quadratic Assignment Problem (QAP)
of graph matching into a Linear Sum Assignment Problem (LSAP) on the sets of node embeddings.
Essentially, this requires solving an optimal transport problem in the node embedding space. The use
of neural surrogates for optimal transport was first proposed by Cuturi [16], who introduced entropy
regularization to make the optimal transport objective strictly convex and utilized Sinkhorn iterations
[50] to obtain the transport plan. Subsequently, Mena et al. [35] proposed the neural Gumbel Sinkhorn
network as a continuous and differentiable surrogate of a permutation matrix, which we incorporate
into our model.
2In various generative modeling applications, optimal transport costs are used as loss functions, such
as in Wasserstein GANs [ 1,3]. Computing the optimal transport plan is a significant challenge,
with approaches leveraging the primal formulation [ 52,33], the dual formulation with entropy
regularization [17, 48, 22], or Input Convex Neural Networks (ICNNs) [2].
Neural graph similarity computation Most earlier works on neural graph similarity computation
have focused on training with GED values as ground truth [5, 6, 19, 40, 56, 39, 54, 31], while some
have used MCS as the similarity measure [ 6,5]. Current neural models for GED approximation
primarily follow two approaches. The first approach uses a trainable nonlinear function applied to
graph embeddings to compute GED [ 5,39,6,56,54,19]. The second approach calculates GED
based on the Euclidean distance in the embedding space [31, 40].
Among these models, GOTSIM [ 19] focuses solely on node insertion and deletion, and computes
node alignment using a combinatorial routine that is decoupled from end-to-end training. However,
their network struggles with training efficiency due to the operations on discrete values, which
are not amenable to backpropagation. With the exception of GREED [ 40] and Graph Embedding
Network (GEN) [ 31], most methods use early interaction or nonlinear scoring functions, limiting
their adaptability to efficient indexing and retrieval pipelines.
3 Problem setup
Notation The source graph is denoted by G= (V, E)and the target graph by G′= (V′, E′). Both
graphs are undirected and are padded with isolated nodes to equalize the number of nodes to N.
The adjacency matrices for GandG′after padding are A,A′∈ {0,1}N×N. (Note that we will use
M⊤, notM′, for the transpose of matrix M.) The sets of padded nodes in GandG′are denoted by
PaddedNodes GandPaddedNodes G′respectively. We construct η∈ {0,1}N, where η[u] = 0 if
u∈PaddedNodes Gand1otherwise (same for G′). The embedding of a node u∈Vcomputed at
propagation layer kby the GNN, is represented as xk(u). Edit operations, denoted by edit, belong to
one of four types, viz., (i) node deletion, (ii) node addition, (iii) edge deletion, (iv) edge addition. Each
operation edit is assigned a cost cost(edit) . The node and node-pair alignment maps are described
using (hard) permutation matrices P∈ {0,1}N×NandS∈ {0,1}(N
2)×(N
2)respectively. Given
that the graphs are undirected, node-pair alignment need only be specified across at most N
2
pairs.
When a hard permutation matrix is relaxed to a doubly-stochastic matrix, we call it a soft permutation
matrix. We use PandSto refer to both hard and soft permutations, depending on the context. We
denotePNas the set of all hard permutation matrices of dimension N;[N]as{1, . . . , N }and∥A∥1,1
to describeP
u,v|A[u, v]|. For two binary variables c1, c2∈ {0,1}, we denote J(c1, c2)as (c1XOR
c2),i.e.,J(c1, c2) =c1c2+ (1−c1)(1−c2).
Graph edit distance with general cost We define an edit path as a sequence of edit operations
o={edit1,edit2, . . .}; andO(G, G′)as the set of all possible edit paths that transform the source
graph Ginto a graph isomorphic to the target graph G′. Given O(G, G′)and the cost associated with
each operation edit, the GED between GandG′is the minimum collective cost across all edit paths
inO(G, G′). Formally, we write [14, 7]:
GED( G, G′) = min
o={edit 1,edit 2,...}∈O(G,G′)P
i∈[|o|]cost(edit i). (1)
In this work, we assume a fixed cost for each of the four types of edit operations. Specifically, we use
a⊖,a⊕,b⊖andb⊕to represent the costs for edge deletion, edge addition, node deletion, and node
addition, respectively. These costs are not necessarily uniform, in contrast to the assumptions made
in previous works [ 5,31,56,39]. Additional discussion on GED with node substitution in presence
of labels can be found in Appendix B.
Problem statement Our objective is to design a neural architecture for predicting GED under
a general cost framework, where the edit costs a⊖,a⊕,b⊖andb⊕are not necessarily the same.
During the learning stage, these four costs are specified, and remain fixed across all training instances
D={(Gi, G′
i,GED( Gi, G′
i))}i∈[n]. Note that the edit paths are not supervised. Later, given a test
instance G, G′, assuming the same four costs, the trained system has to predict GED( G, G′).
4 Proposed approach
In this section, we first present an alternative formulation of GED as described in Eq. (1), where
the edit paths are induced by node alignment maps. Then, we adapt this formulation to develop
3GRAPH EDX, a neural set distance surrogate, amenable to end-to-end training. Finally, we present the
network architecture of G RAPH EDX.
4.1 GED computation using node alignment map
Given the padded graph pair GandG′, deleting a node u∈Vcan be viewed as aligning node u
with some padded node u′∈PaddedNodes G′. Similarly, adding a new node u′toGcan be seen as
aligning some padded node u∈PaddedNodes Gwith node u′∈V′. Likewise, adding an edge to G
corresponds to aligning a non-edge (u, v)̸∈Ewith an edge (u′, v′)∈G′. Conversely, deleting an
edge in Gcorresponds to aligning an edge (u, v)∈Gwith a non-edge (u′, v′)/∈G′.
Therefore, GED( G, G′)can be defined in terms of a node alignment map. Let ΠNrepresent the set of
all node alignment maps π: [N]→[N]fromVtoV′. Recall that ηG[u] = 0 ifu∈PaddedNodes G
and1otherwise.
min
π∈ΠN1
2X
u,v
a⊖·I[(u, v)∈E∧(π(u), π(v))̸∈E′] +a⊕·I[(u, v)̸∈E∧(π(u), π(v))∈E′]
+X
u
b⊖·ηG[u] (1−ηG′[π(u)]) + b⊕·(1−ηG[u])ηG′[π(u)]
. (2)
In the above expression, the first sum iterates over all pairs of (u, v)∈[N]×[N]and the second
sum iterates over u∈[N]. Because both graphs are undirected, the fraction 1/2accounts for double
counting of the edges. The first and second terms quantify the cost of deleting and adding the edge
(u, v)from and to G, respectively. The third and the fourth terms evaluate the cost of deleting and
adding node ufrom and to G, respectively.
GED as a Quadratic Assignment Problem In its current form, Eq. (2)cannot be immediately
adapted to a differentiable surrogate. To circumvent this problem, we provide an equivalent matricized
form of Eq. (2), using a hard node permutation matrix Pinstead of the alignment map π. We compute
the asymmetric distances between AandPA′P⊤and combine them with weights a⊖anda⊕.
Notably, ReLU 
A−PA′P⊤
[u, v]is non-zero if the edge (u, v)∈Eis mapped to a non-edge
(u′, v′)∈E′withP[u, u′] =P[v, v′] = 1 , indicating deletion of the edge (u, v)fromG. Similarly,
ReLU 
PA′P⊤−A
[u, v]becomes non-zero if an edge (u, v)is added to G. Therefore, for the
edit operations involving edges, we have:
I[(u, v)∈E∧(π(u), π(v))̸∈E′] = ReLU 
A−PA′P⊤
[u, v], (3)
I[(u, v)̸∈E∧(π(u), π(v))∈E′] = ReLU 
PA′P⊤−A
[u, v]. (4)
Similarly, we note that ReLU ( ηG[u]−ηG′[π(u)])>0ifu̸∈PaddedNodes Gandπ(u)∈
PaddedNodes G′, which allows us to compute the cost of deleting the node ufromG. Similarly, we
useReLU ( ηG′[π(u)]−ηG[u])to account for the addition of the node utoG. Formally, we write:
ηG[u] (1−ηG′[π(u)]) = ReLU ( ηG[u]−ηG′[π(u)]), (5)
(1−ηG[u])ηG′[π(u)] = ReLU ( ηG′[π(u)]−ηG[u]). (6)
Using Eqs. (3)–(6), we rewrite Eq. (2) as:
GED( G, G′) = min
P∈PNa⊖
2ReLU 
A−PA′P⊤
1,1+a⊕
2ReLU 
PA′P⊤−A
1,1
+b⊖∥ReLU ( ηG−PηG′)∥1+b⊕∥ReLU ( PηG′−ηG)∥1. (7)
The first and the second term denote the collective costs of deletion and addition of edges, respectively.
The third and the fourth terms present a matricized representation of Eqs. (5)-(6). The above problem
can be viewed as a quadratic assignment problem (QAP) on graphs, given that the hard node
permutation matrix Phas a quadratic involvement in the first two terms. Note that, in general,
GED( G, G′)̸= GED( G′, G). However, the optimal edit paths for these two GED values, encoded
by the respective node permutation matrices, are inverses of each other, as formally stated in the
following proposition (proven in Appendix B).
Proposition 1 Given a fixed set of values of b⊖, b⊕, a⊖, a⊕, letPbe an optimal node permutation
matrix corresponding to GED( G, G′), computed using Eq. (7). Then, P′=P⊤is an optimal node
permutation corresponding to GED( G′, G).
Connection to different notions of graph matching The above expression of GED can be used
to represent various notions of graph matching and similarity measures by modifying the edit costs.
These include graph isomorphism, subgraph isomorphism, and maximum common edge subgraph
4<latexit sha1_base64="OAZimIi/AKMI6fr7wjZbYSSnk0U=">AAAB9HicbVDLSgNBEOyNrxhfUY9eBoPgKeyKosegCB4jmAckS5idnU2GzD6c6Q2GJd/hxYMiXv0Yb/6Nk2QPmljQUFR1093lJVJotO1vq7Cyura+UdwsbW3v7O6V9w+aOk4V4w0Wy1i1Paq5FBFvoEDJ24niNPQkb3nDm6nfGnGlRRw94Djhbkj7kQgEo2gkt4v8CbNbX+Ck5/TKFbtqz0CWiZOTCuSo98pfXT9macgjZJJq3XHsBN2MKhRM8kmpm2qeUDakfd4xNKIh1242O3pCTozikyBWpiIkM/X3REZDrcehZzpDigO96E3F/7xOisGVm4koSZFHbL4oSCXBmEwTIL5QnKEcG0KZEuZWwgZUUYYmp5IJwVl8eZk0z6rORdW+P6/UrvM4inAEx3AKDlxCDe6gDg1g8AjP8Apv1sh6sd6tj3lrwcpnDuEPrM8f6QCSLw==</latexit>Edit1<latexit sha1_base64="4mtWH4io2UzE9nnbV23IqIIIjeM=">AAAB9HicbVBNS8NAEN34WetX1aOXYBE8laQoeiyK4LGC/YA2lM1m0i7dbOLupFhCf4cXD4p49cd489+4bXPQ1gcDj/dmmJnnJ4JrdJxva2V1bX1js7BV3N7Z3dsvHRw2dZwqBg0Wi1i1fapBcAkN5CignSigkS+g5Q9vpn5rBErzWD7gOAEvon3JQ84oGsnrIjxhdhtwnPSqvVLZqTgz2MvEzUmZ5Kj3Sl/dIGZpBBKZoFp3XCdBL6MKORMwKXZTDQllQ9qHjqGSRqC9bHb0xD41SmCHsTIl0Z6pvycyGmk9jnzTGVEc6EVvKv7ndVIMr7yMyyRFkGy+KEyFjbE9TcAOuAKGYmwIZYqbW202oIoyNDkVTQju4svLpFmtuBcV5/68XLvO4yiQY3JCzohLLkmN3JE6aRBGHskzeSVv1sh6sd6tj3nripXPHJE/sD5/AOqEkjA=</latexit>Edit2<latexit sha1_base64="ELlKbAq+6vH1p07eli3L/aBL8UY=">AAAB9HicbVDJSgNBEO2JW4xb1KOXxiB4CjMu6DEogscIZoFkCD09NUmTnsXummAY8h1ePCji1Y/x5t/YSeag0QcFj/eqqKrnJVJotO0vq7C0vLK6VlwvbWxube+Ud/eaOk4VhwaPZazaHtMgRQQNFCihnShgoSeh5Q2vp35rBEqLOLrHcQJuyPqRCARnaCS3i/CI2Y0vcNI77ZUrdtWegf4lTk4qJEe9V/7s+jFPQ4iQS6Z1x7ETdDOmUHAJk1I31ZAwPmR96BgasRC0m82OntAjo/g0iJWpCOlM/TmRsVDrceiZzpDhQC96U/E/r5NicOlmIkpShIjPFwWppBjTaQLUFwo4yrEhjCthbqV8wBTjaHIqmRCcxZf/kuZJ1Tmv2ndnldpVHkeRHJBDckwcckFq5JbUSYNw8kCeyAt5tUbWs/Vmvc9bC1Y+s09+wfr4BuwIkjE=</latexit>Edit3<latexit sha1_base64="5hsmxM/nGHERmoU+Uu5R5EPkmAQ=">AAAB9HicbVBNS8NAEN3Ur1q/qh69BIvgqSSi6LEogscK9gPaUDabSbt0s4m7k2IJ/R1ePCji1R/jzX/jts1BWx8MPN6bYWaenwiu0XG+rcLK6tr6RnGztLW9s7tX3j9o6jhVDBosFrFq+1SD4BIayFFAO1FAI19Ayx/eTP3WCJTmsXzAcQJeRPuSh5xRNJLXRXjC7DbgOOmd98oVp+rMYC8TNycVkqPeK391g5ilEUhkgmrdcZ0EvYwq5EzApNRNNSSUDWkfOoZKGoH2stnRE/vEKIEdxsqURHum/p7IaKT1OPJNZ0RxoBe9qfif10kxvPIyLpMUQbL5ojAVNsb2NAE74AoYirEhlClubrXZgCrK0ORUMiG4iy8vk+ZZ1b2oOvfnldp1HkeRHJFjckpccklq5I7USYMw8kieySt5s0bWi/VufcxbC1Y+c0j+wPr8Ae2MkjI=</latexit>Edit4
<latexit sha1_base64="YglN+fSjpKX/yQOgYD+aNfenZNM=">AAAB7nicdVBNSwMxEJ2tX7V+VT16CRbB05KtWNtb0YvHCtYW2qVks9k2NJtdkqxQSn+EFw+KePX3ePPfmG0rqOiDgcd7M8zMC1LBtcH4wymsrK6tbxQ3S1vbO7t75f2DO51kirI2TUSiugHRTHDJ2oYbwbqpYiQOBOsE46vc79wzpXkib80kZX5MhpJHnBJjpU6LhCGXw0G5gl0P1zDGCLu4XrM8J2cNr1FHnovnqMASrUH5vR8mNIuZNFQQrXseTo0/JcpwKtis1M80SwkdkyHrWSpJzLQ/nZ87QydWCVGUKFvSoLn6fWJKYq0ncWA7Y2JG+reXi395vcxEdX/KZZoZJuliUZQJZBKU/45Crhg1YmIJoYrbWxEdEUWosQmVbAhfn6L/yV3V9c5dfFOtNC+XcRThCI7hFDy4gCZcQwvaQGEMD/AEz07qPDovzuuiteAsZw7hB5y3T4b3j7M=</latexit>Padding<latexit sha1_base64="FCH4xNhZjhLsa7sXorD4cozGmiM=">AAAB/nicdVDJSgNBEO1xjXGLiicvjUHwNPS4xlvQixclglkgCaGnU0ma9Cx014hhCPgrXjwo4tXv8Obf2IkRVPRBweO9Kqrq+bGSBhl7d6amZ2bn5jML2cWl5ZXV3Np6xUSJFlAWkYp0zecGlAyhjBIV1GINPPAVVP3+2civ3oA2MgqvcRBDM+DdUHak4GilVm6TNhBuMb0oXV4OW2kDe4B82MrlmeuxI8YYZS4rHFk+Ivsn3kmBei4bI08mKLVyb412JJIAQhSKG1P3WIzNlGuUQsEw20gMxFz0eRfqloY8ANNMx+cP6Y5V2rQTaVsh0rH6fSLlgTGDwLedAcee+e2NxL+8eoKdQjOVYZwghOJzUSdRFCM6yoK2pQaBamAJF1raW6nocc0F2sSyNoSvT+n/pLLneocuuzrIF08ncWTIFtkmu8Qjx6RIzkmJlIkgKbknj+TJuXMenGfn5bN1ypnMbJAfcF4/AKlUlfY=</latexit>MPNN✓<latexit sha1_base64="Dhjb2J1v/V5/7PclgCwaSuqShS4=">AAACAXicdVDLSgNBEJyNrxhfUS+Cl8EgeFpmfcZb0IsniWBMIAlhdtJJhsw+mOkVwxIv/ooXD4p49S+8+TdOYgQVLWgoqrrp7vJjJQ0y9u5kpqZnZuey87mFxaXllfzq2pWJEi2gIiIV6ZrPDSgZQgUlKqjFGnjgK6j6/dORX70GbWQUXuIghmbAu6HsSMHRSq38Bm0g3KARaRl0cA44bKWNuCeHrXyBuR47ZIxR5rLioeUjsnfsHRep57IxCmSCciv/1mhHIgkgRKG4MXWPxdhMuUYpFAxzjcRAzEWfd6FuacgDMM10/MGQblulTTuRthUiHavfJ1IeGDMIfNsZcOyZ395I/MurJ9gpNlMZxglCKD4XdRJFMaKjOGhbahCoBpZwoaW9lYoe11ygDS1nQ/j6lP5PrnZd78BlF/uF0skkjizZJFtkh3jkiJTIGSmTChHkltyTR/Lk3DkPzrPz8tmacSYz6+QHnNcPgR6Xlw==</latexit>PermNet 
<latexit sha1_base64="qQqkHPzWEl0gb++jqteCueBtEVQ=">AAAB/HicdVDLSgNBEJz1GeMrmqOXwSB4WmZ9xpvoxYNCBGMC2RBmJx0zOPtgplcMS/wVLx4U8eqHePNvnI0RVLSgoajqprsrSJQ0yNi7MzE5NT0zW5grzi8sLi2XVlYvTZxqAXURq1g3A25AyQjqKFFBM9HAw0BBI7g+zv3GDWgj4+gCBwm0Q34VyZ4UHK3UKZV9hFvMzk5rw07mYx+QDzulCnM9tscYo8xl1T3Lc7J94B1UqeeyESpkjFqn9OZ3Y5GGEKFQ3JiWxxJsZ1yjFAqGRT81kHBxza+gZWnEQzDtbHT8kG5YpUt7sbYVIR2p3ycyHhozCAPbGXLsm99eLv7ltVLsVduZjJIUIRKfi3qpohjTPAnalRoEqoElXGhpb6WizzUXaPMq2hC+PqX/k8st19t12flO5fBoHEeBrJF1skk8sk8OyQmpkToRZEDuySN5cu6cB+fZeflsnXDGM2XyA87rB6wKlXI=</latexit>MLP✓<latexit sha1_base64="lmCcKiA2Ypy9wE1QZq3uGpeByHI=">AAACB3icdZDLSgMxFIYzXmu9jboUJFgEN5ZML1p3RTcuK9gLdMaSSdM2NJMZkoxYhu7c+CpuXCji1ldw59uYaSuo6A+Bn++cw8n5/YgzpRH6sObmFxaXljMr2dW19Y1Ne2u7ocJYElonIQ9ly8eKciZoXTPNaSuSFAc+p01/eJ7WmzdUKhaKKz2KqBfgvmA9RrA2qGPv4evEDSMeq7Hrto8ceutlJyhgwrCOnUN5dFwulyowNYUKKqWm6KDiKXTyaKIcmKnWsd/dbkjigApNOFaq7aBIewmWmhFOx1k3VjTCZIj7tG2swAFVXjK5YwwPDOnCXijNExpO6PeJBAdKjQLfdAZYD9TvWgr/qrVj3at4CRNRrKkg00W9mEMdwjQU2GWSEs1HxmAimfkrJAMsMdEmuqwJ4etS+L9pFPJOOY8uS7nq2SyODNgF++AQOOAEVMEFqIE6IOAOPIAn8GzdW4/Wi/U6bZ2zZjM74Iest0+OWZnE</latexit>a a <latexit sha1_base64="BEjXwZsMl/0qYwBZP13BHwF39qY=">AAACB3icdZDLSgMxFIYzXmu9jboUJFgEN5ZML1p3RTcuK9gLdMaSSdM2NJMZkoxYhu7c+CpuXCji1ldw59uYaSuo6A+Bn++cw8n5/YgzpRH6sObmFxaXljMr2dW19Y1Ne2u7ocJYElonIQ9ly8eKciZoXTPNaSuSFAc+p01/eJ7WmzdUKhaKKz2KqBfgvmA9RrA2qGPv+deJG0Y8VmPXbR859NbLTlDAhGEdO4fy6LhcLlVgagoVVEpN0UHFU+jk0UQ5MFOtY7+73ZDEARWacKxU20GR9hIsNSOcjrNurGiEyRD3adtYgQOqvGRyxxgeGNKFvVCaJzSc0O8TCQ6UGgW+6QywHqjftRT+VWvHulfxEiaiWFNBpot6MYc6hGkosMskJZqPjMFEMvNXSAZYYqJNdFkTwtel8H/TKOSdch5dlnLVs1kcGbAL9sEhcMAJqIILUAN1QMAdeABP4Nm6tx6tF+t12jpnzWZ2wA9Zb5+RiJnG</latexit>b b 
<latexit sha1_base64="FIh086jnd2dV1s/cLuLAWnz4HJ4=">AAACB3icdVBNSyNBEO3xYzfGdTfqUZBmg6yChB5NNN6CH8SjC0aFTAg9nYpp7Pmgu0YMQ25e/CtePCji1b/gzX9jT4ygog8KHu9VUVXPj5U0yNizMzY+MfnjZ24qP/1r5vefwuzckYkSLaAhIhXpE58bUDKEBkpUcBJr4IGv4Ng/28n843PQRkbhIfZjaAX8NJRdKThaqV1Y9BAuMK3v7Q7aqYc9QL7qxT05WK6v1v+ttAtFVmIblUq5SjOyVmXljKy7bH2LuiU2RJGMcNAuPHmdSCQBhCgUN6bpshhbKdcohYJB3ksMxFyc8VNoWhryAEwrHf4xoEtW6dBupG2FSIfq+4mUB8b0A992Bhx75rOXiV95zQS71VYqwzhBCMXrom6iKEY0C4V2pAaBqm8JF1raW6nocc0F2ujyNoS3T+n35Git5FZK7H+5WNsexZEjC+QvWSYu2SQ1sk8OSIMIckmuyS25c66cG+feeXhtHXNGM/PkA5zHFxG5mMg=</latexit>GED✓, (G, G0)<latexit sha1_base64="ys/VvPzavRg4ibQpdTAz5Cb3X/4=">AAAB6HicdVDJSgNBEK2JW4xb1KOXxiB4GnqyaLwFPegxAbNAMoSeTk/Spmehu0cIIV/gxYMiXv0kb/6NPUkEFX1Q8Hiviqp6Xiy40hh/WJmV1bX1jexmbmt7Z3cvv3/QUlEiKWvSSESy4xHFBA9ZU3MtWCeWjASeYG1vfJX67XsmFY/CWz2JmRuQYch9Tok2UuO6ny9gG59VKuUqSkmxisspKTm4dIEcG89RgCXq/fx7bxDRJGChpoIo1XVwrN0pkZpTwWa5XqJYTOiYDFnX0JAETLnT+aEzdGKUAfIjaSrUaK5+n5iSQKlJ4JnOgOiR+u2l4l9eN9F+1Z3yME40C+likZ8IpCOUfo0GXDKqxcQQQiU3tyI6IpJQbbLJmRC+PkX/k1bRdio2bpQLtctlHFk4gmM4BQfOoQY3UIcmUGDwAE/wbN1Zj9aL9bpozVjLmUP4AevtE/oojQ8=</latexit>G
<latexit sha1_base64="ys/VvPzavRg4ibQpdTAz5Cb3X/4=">AAAB6HicdVDJSgNBEK2JW4xb1KOXxiB4GnqyaLwFPegxAbNAMoSeTk/Spmehu0cIIV/gxYMiXv0kb/6NPUkEFX1Q8Hiviqp6Xiy40hh/WJmV1bX1jexmbmt7Z3cvv3/QUlEiKWvSSESy4xHFBA9ZU3MtWCeWjASeYG1vfJX67XsmFY/CWz2JmRuQYch9Tok2UuO6ny9gG59VKuUqSkmxisspKTm4dIEcG89RgCXq/fx7bxDRJGChpoIo1XVwrN0pkZpTwWa5XqJYTOiYDFnX0JAETLnT+aEzdGKUAfIjaSrUaK5+n5iSQKlJ4JnOgOiR+u2l4l9eN9F+1Z3yME40C+likZ8IpCOUfo0GXDKqxcQQQiU3tyI6IpJQbbLJmRC+PkX/k1bRdio2bpQLtctlHFk4gmM4BQfOoQY3UIcmUGDwAE/wbN1Zj9aL9bpozVjLmUP4AevtE/oojQ8=</latexit>G<latexit sha1_base64="rOKmAqHfNmVKC5evq5zW/H/w8Xs=">AAAB6XicdVDJSgNBEK2JW4xb1KOXxiB6Cj1ZNN6CHvQYxSyQDKGn05M06Vno7hHCkD/w4kERr/6RN//GniSCij4oeLxXRVU9NxJcaYw/rMzS8srqWnY9t7G5tb2T391rqTCWlDVpKELZcYliggesqbkWrBNJRnxXsLY7vkz99j2TiofBnZ5EzPHJMOAep0Qb6fbquJ8v4CI+rVYrNZSSUg1XUlK2cfkc2UU8QwEWaPTz771BSGOfBZoKolTXxpF2EiI1p4JNc71YsYjQMRmyrqEB8ZlyktmlU3RklAHyQmkq0Gimfp9IiK/UxHdNp0/0SP32UvEvrxtrr+YkPIhizQI6X+TFAukQpW+jAZeMajExhFDJza2IjogkVJtwciaEr0/R/6RVKtrVIr6pFOoXiziycACHcAI2nEEdrqEBTaDgwQM8wbM1th6tF+t13pqxFjP78APW2ydafo1A</latexit>G0<latexit sha1_base64="zAmJutpc6V/29Xw53rFLrw4HHnI=">AAACKXicdZDNShxBFIWrTTQ6iWaSLN0UGQQD0lTPn9O7idm4CgYcFaabobr6zlhY/UPV7ZCh6dfJJq+SjYIhcZsXSfU4ghG9UPBxzr1Vt06UK2mQsT/OyrPnq2sv1jcaL19tbr1uvnl7YrJCCxiJTGX6LOIGlExhhBIVnOUaeBIpOI0uPtX+6VfQRmbpMc5zCBM+S+VUCo5WmjSHAcI3LD/G8ecshmq3DBZ3jvUsCkvm+h2/3/f2mDvwvX67Y4H5+77nV0FUKAVYfZg0W1bs93rdAa2hPWDdGjoe6/jUc9miWmRZR5PmVRBnokggRaG4MWOP5RiWXKMUCqpGUBjIubjgMxhbTHkCJiwXW1V0xyoxnWbanhTpQr0/UfLEmHkS2c6E47l56NXiY964wOkgLGWaFwipuH1oWiiKGa1jo7HUIFDNLXChpd2VinOuuUAbbsOGcPdT+jSctF2v57Iv3dbwYBnHOtkm78ku8cg+GZJDckRGRJDv5Ce5Jr+cH86l89u5uW1dcZYz78h/5fz9B9vlo94=</latexit>AddNode(•)<latexit sha1_base64="LtdIYnL3g8C7+OaWdt87TYavjg4=">AAACWnicdVFda9swFJW9rR/ptmYfb3sRC4MOipHi2LXfuo3BHjtY2kJsgizfpKLyxyS5NBj/yb2Mwf7KYHKSjX0eEBzOPefq6iqrpdCGkC+Oe+fuvZ3dvf3Bwf0HDw+Hjx6f66pRHKa8kpW6zJgGKUqYGmEkXNYKWJFJuMiu3/T1ixtQWlTlB7OqIS3YshQLwZmx0nz4MTFwa9pXef42X0J31CbrnjO1zNKWeLHvE+ofEy+IozCkloQBjcNJl2SNlGC6478C8cYXxTQc90kSn8Q0/hl4OR+OrBgGwSTCPRlHZNITnxI/xtQja4zQFmfz4ackr3hTQGm4ZFrPKKlN2jJlBJfQDZJGQ834NVvCzNKSFaDTdj1Vh19YJceLStlTGrxWf020rNB6VWTWWTBzpf+s9eK/arPGLKK0FWXdGCj55qJFI7GpcL9nnAsF3MiVJYwrYWfF/Iopxo39jYFdwo+X4v+T87FHA4+8n4xOX2/XsYeeoefoCFF0gk7RO3SGpoijz+ibs+PsOl9d1913DzZW19lmnqDf4D79DqDzrlI=</latexit>AddEdge(•,•)<latexit sha1_base64="ZP1Ej+WrEhtHHyC1BQFiJ7Ww2zc=">AAACrHicdVFba9swFJa9W5ddmm2PexELgxaKkWzLtt66jcHe1kHTZjgmyLKcmsoXLHksGP+6/YO97d9MTjLo2u2A4ON8Fx0dpY0slEbol2Xfu//g4aODx5MnT589P5y+eHmh6q7lYs5rWbeLlCkhi0rMdaGlWDStYGUqxWV6/WHkL7+JVhV1da43jUhKtq6KvOBMm9Zq+mOpxXfdv8uyj9laDEf9cpsZt+s06ZFDPQ9h7wQ5hEZBgA0ICKaBP9zRhb4/6iLk0nDUecQl2BuWaSel0MNwcsdBd4ERxYE7WhENKaa3kwkl1KeGDgnxyQiM0w9vJB+vpjPjDgwfwRG4EfJH4GHkUYgdtK0Z2NfZavpzmdW8K0WluWRKxRg1OulZqwsuxTBZdko0jF+ztYgNrFgpVNJvxxrgW9PJYF635lQabrs3HT0rldqUqVGWTF+p29zY/BcXdzqPkr6omk6Liu8uyjsJdQ3Hn4NZ0Qqu5cYAxtvCzAr5FWsZ1+Z/J2YJf14K/w8uXAcTB33xZ6fv9+s4AK/BG3AEMAjBKfgEzsAccOvY+mwtrK+2Y5/bsZ3spLa197wCf5Wd/wb50MWk</latexit>AddEdge(•,•)
<latexit sha1_base64="zAmJutpc6V/29Xw53rFLrw4HHnI=">AAACKXicdZDNShxBFIWrTTQ6iWaSLN0UGQQD0lTPn9O7idm4CgYcFaabobr6zlhY/UPV7ZCh6dfJJq+SjYIhcZsXSfU4ghG9UPBxzr1Vt06UK2mQsT/OyrPnq2sv1jcaL19tbr1uvnl7YrJCCxiJTGX6LOIGlExhhBIVnOUaeBIpOI0uPtX+6VfQRmbpMc5zCBM+S+VUCo5WmjSHAcI3LD/G8ecshmq3DBZ3jvUsCkvm+h2/3/f2mDvwvX67Y4H5+77nV0FUKAVYfZg0W1bs93rdAa2hPWDdGjoe6/jUc9miWmRZR5PmVRBnokggRaG4MWOP5RiWXKMUCqpGUBjIubjgMxhbTHkCJiwXW1V0xyoxnWbanhTpQr0/UfLEmHkS2c6E47l56NXiY964wOkgLGWaFwipuH1oWiiKGa1jo7HUIFDNLXChpd2VinOuuUAbbsOGcPdT+jSctF2v57Iv3dbwYBnHOtkm78ku8cg+GZJDckRGRJDv5Ce5Jr+cH86l89u5uW1dcZYz78h/5fz9B9vlo94=</latexit>AddNode(•)<latexit sha1_base64="LtdIYnL3g8C7+OaWdt87TYavjg4=">AAACWnicdVFda9swFJW9rR/ptmYfb3sRC4MOipHi2LXfuo3BHjtY2kJsgizfpKLyxyS5NBj/yb2Mwf7KYHKSjX0eEBzOPefq6iqrpdCGkC+Oe+fuvZ3dvf3Bwf0HDw+Hjx6f66pRHKa8kpW6zJgGKUqYGmEkXNYKWJFJuMiu3/T1ixtQWlTlB7OqIS3YshQLwZmx0nz4MTFwa9pXef42X0J31CbrnjO1zNKWeLHvE+ofEy+IozCkloQBjcNJl2SNlGC6478C8cYXxTQc90kSn8Q0/hl4OR+OrBgGwSTCPRlHZNITnxI/xtQja4zQFmfz4ackr3hTQGm4ZFrPKKlN2jJlBJfQDZJGQ834NVvCzNKSFaDTdj1Vh19YJceLStlTGrxWf020rNB6VWTWWTBzpf+s9eK/arPGLKK0FWXdGCj55qJFI7GpcL9nnAsF3MiVJYwrYWfF/Iopxo39jYFdwo+X4v+T87FHA4+8n4xOX2/XsYeeoefoCFF0gk7RO3SGpoijz+ibs+PsOl9d1913DzZW19lmnqDf4D79DqDzrlI=</latexit>AddEdge(•,•)
<latexit sha1_base64="IxEk81NuLyVRw9GlvzebCNopzvY=">AAAChnicbVHbahsxENVuenHcS5z2MS+ippBAMNp19+I306TQxxTqJOBdjFYeOyLaC9JsqFn2U/pTfevfVHbc0to9IDicOUcazWSVkgYZ++m4B0+ePnveOey+ePnq9VHv+M21KWstYCJKVerbjBtQsoAJSlRwW2ngeabgJru/WNdvHkAbWRZfcVVBmvNlIRdScLTSrPe9STaXTPUySxs2YBuc75E2QfiGzSWoT/MltG1zuhMcsXgUBdYfePEwXAeDOPJHUZtktVKA7TndSQR+7LHQGiPG4sC3ZOSHw8j/kzhrZ73+7wboPvG2pE+2uJr1fiTzUtQ5FCgUN2bqsQrThmuUQkHbTWoDFRf3fAlTSwueg0mbTVstfW+VOV2U2p4C6Ub9O9Hw3JhVnllnzvHO7NbW4v9q0xoXcdrIoqoRCvH40KJWFEu63gmdSw0C1coSLrS0vVJxxzUXaDfXtUPwdr+8T679gRcOwi8f+uOP23F0yAl5R06JRyIyJp/JFZkQ4Rw4Z47vDN2OO3ADN3q0us4285b8A3f8C3d9uR0=</latexit>DelEdge(•,•)<latexit sha1_base64="rOKmAqHfNmVKC5evq5zW/H/w8Xs=">AAAB6XicdVDJSgNBEK2JW4xb1KOXxiB6Cj1ZNN6CHvQYxSyQDKGn05M06Vno7hHCkD/w4kERr/6RN//GniSCij4oeLxXRVU9NxJcaYw/rMzS8srqWnY9t7G5tb2T391rqTCWlDVpKELZcYliggesqbkWrBNJRnxXsLY7vkz99j2TiofBnZ5EzPHJMOAep0Qb6fbquJ8v4CI+rVYrNZSSUg1XUlK2cfkc2UU8QwEWaPTz771BSGOfBZoKolTXxpF2EiI1p4JNc71YsYjQMRmyrqEB8ZlyktmlU3RklAHyQmkq0Gimfp9IiK/UxHdNp0/0SP32UvEvrxtrr+YkPIhizQI6X+TFAukQpW+jAZeMajExhFDJza2IjogkVJtwciaEr0/R/6RVKtrVIr6pFOoXiziycACHcAI2nEEdrqEBTaDgwQM8wbM1th6tF+t13pqxFjP78APW2ydafo1A</latexit>G0
<latexit sha1_base64="FCH4xNhZjhLsa7sXorD4cozGmiM=">AAAB/nicdVDJSgNBEO1xjXGLiicvjUHwNPS4xlvQixclglkgCaGnU0ma9Cx014hhCPgrXjwo4tXv8Obf2IkRVPRBweO9Kqrq+bGSBhl7d6amZ2bn5jML2cWl5ZXV3Np6xUSJFlAWkYp0zecGlAyhjBIV1GINPPAVVP3+2civ3oA2MgqvcRBDM+DdUHak4GilVm6TNhBuMb0oXV4OW2kDe4B82MrlmeuxI8YYZS4rHFk+Ivsn3kmBei4bI08mKLVyb412JJIAQhSKG1P3WIzNlGuUQsEw20gMxFz0eRfqloY8ANNMx+cP6Y5V2rQTaVsh0rH6fSLlgTGDwLedAcee+e2NxL+8eoKdQjOVYZwghOJzUSdRFCM6yoK2pQaBamAJF1raW6nocc0F2sSyNoSvT+n/pLLneocuuzrIF08ncWTIFtkmu8Qjx6RIzkmJlIkgKbknj+TJuXMenGfn5bN1ypnMbJAfcF4/AKlUlfY=</latexit>MPNN✓<latexit sha1_base64="qQqkHPzWEl0gb++jqteCueBtEVQ=">AAAB/HicdVDLSgNBEJz1GeMrmqOXwSB4WmZ9xpvoxYNCBGMC2RBmJx0zOPtgplcMS/wVLx4U8eqHePNvnI0RVLSgoajqprsrSJQ0yNi7MzE5NT0zW5grzi8sLi2XVlYvTZxqAXURq1g3A25AyQjqKFFBM9HAw0BBI7g+zv3GDWgj4+gCBwm0Q34VyZ4UHK3UKZV9hFvMzk5rw07mYx+QDzulCnM9tscYo8xl1T3Lc7J94B1UqeeyESpkjFqn9OZ3Y5GGEKFQ3JiWxxJsZ1yjFAqGRT81kHBxza+gZWnEQzDtbHT8kG5YpUt7sbYVIR2p3ycyHhozCAPbGXLsm99eLv7ltVLsVduZjJIUIRKfi3qpohjTPAnalRoEqoElXGhpb6WizzUXaPMq2hC+PqX/k8st19t12flO5fBoHEeBrJF1skk8sk8OyQmpkToRZEDuySN5cu6cB+fZeflsnXDGM2XyA87rB6wKlXI=</latexit>MLP✓<latexit sha1_base64="TN2IgwWtLgPmmLqy8GIJ11OU38g=">AAAB/XicbVDLSgMxFL3js9ZX1aWbYBFclRmR6rLoxmUF+4B2KEmaaWOTzJBkhDIUf8Gt7t2JW7/FrV9i2s5CWw9cOJxzL+dySCK4sb7/5a2srq1vbBa2its7u3v7pYPDpolTTVmDxiLWbYINE1yxhuVWsHaiGZZEsBYZ3Uz91iPThsfq3o4TFko8UDziFFsnNbtEZu1Jr1T2K/4MaJkEOSlDjnqv9N3txzSVTFkqsDGdwE9smGFtORVsUuymhiWYjvCAdRxVWDITZrNvJ+jUKX0UxdqNsmim/r7IsDRmLInblNgOzaI3Ff/1iFxIttFVmHGVpJYpOg+OUoFsjKZVoD7XjFoxdgRTzd3viA6xxtS6woqulGCxgmXSPK8E1Ur17qJcu87rKcAxnMAZBHAJNbiFOjSAwgM8wwu8ek/em/fufcxXV7z85gj+wPv8AQ27leI=</latexit>X
<latexit sha1_base64="lWktmyI1ROfmDPxmU7NKAtkD0F8=">AAAB/nicbVDLSgMxFL3xWeur6tJNsIiuyoxIdVl047KCfUA7lEyaaUOTzJBkhDIU/AW3uncnbv0Vt36JaTsLbT1w4XDOvZzLCRPBjfW8L7Syura+sVnYKm7v7O7tlw4OmyZONWUNGotYt0NimOCKNSy3grUTzYgMBWuFo9up33pk2vBYPdhxwgJJBopHnBLrpFY3lFl7ctYrlb2KNwNeJn5OypCj3it9d/sxTSVTlgpiTMf3EhtkRFtOBZsUu6lhCaEjMmAdRxWRzATZ7N0JPnVKH0exdqMsnqm/LzIijRnL0G1KYodm0ZuK/3qhXEi20XWQcZWklik6D45SgW2Mp13gPteMWjF2hFDN3e+YDokm1LrGiq4Uf7GCZdK8qPjVSvX+sly7yespwDGcwDn4cAU1uIM6NIDCCJ7hBV7RE3pD7+hjvrqC8psj+AP0+QNywJYT</latexit>X→<latexit sha1_base64="t19YEyICNfzXCFwgA7yC+c8M+1w=">AAAB/XicbVDLSgMxFL3js9ZX1aWbYBFclRmR6rLoxmUF+4B2KEmaaWOTzJBkhDIUf8Gt7t2JW7/FrV9i2s5CWw9cOJxzL+dySCK4sb7/5a2srq1vbBa2its7u3v7pYPDpolTTVmDxiLWbYINE1yxhuVWsHaiGZZEsBYZ3Uz91iPThsfq3o4TFko8UDziFFsnNbtEZvVJr1T2K/4MaJkEOSlDjnqv9N3txzSVTFkqsDGdwE9smGFtORVsUuymhiWYjvCAdRxVWDITZrNvJ+jUKX0UxdqNsmim/r7IsDRmLInblNgOzaI3Ff/1iFxIttFVmHGVpJYpOg+OUoFsjKZVoD7XjFoxdgRTzd3viA6xxtS6woqulGCxgmXSPK8E1Ur17qJcu87rKcAxnMAZBHAJNbiFOjSAwgM8wwu8ek/em/fufcxXV7z85gj+wPv8AQETldo=</latexit>P<latexit sha1_base64="LHaxoXTPMy3ZJdnoG+R2fzSj0qY=">AAAB/XicbVC7SgNBFL0bXzG+opY2g0GwCrsi0TJoYxnFPCBZwuxkNhkzM7vMzAphCf6CrfZ2Yuu32PolziZbaOKBC4dz7uVcThBzpo3rfjmFldW19Y3iZmlre2d3r7x/0NJRoghtkohHqhNgTTmTtGmY4bQTK4pFwGk7GF9nfvuRKs0ieW8mMfUFHkoWMoKNlVq9QKR303654lbdGdAy8XJSgRyNfvm7N4hIIqg0hGOtu54bGz/FyjDC6bTUSzSNMRnjIe1aKrGg2k9n307RiVUGKIyUHWnQTP19kWKh9UQEdlNgM9KLXib+6wViIdmEl37KZJwYKsk8OEw4MhHKqkADpigxfGIJJorZ3xEZYYWJsYWVbCneYgXLpHVW9WrV2u15pX6V11OEIziGU/DgAupwAw1oAoEHeIYXeHWenDfn3fmYrxac/OYQ/sD5/AEEPZXc</latexit>R<latexit sha1_base64="bhmykqS9gk+49rb/UiWiZSIOO8k=">AAAB/nicbVC7SgNBFL0bXzG+opY2g0G0Crsi0TJoYxnFPCBZwuxkNhkyM7vMzAphCfgLttrbia2/YuuXONlsoYkHLhzOuZdzOUHMmTau++UUVlbX1jeKm6Wt7Z3dvfL+QUtHiSK0SSIeqU6ANeVM0qZhhtNOrCgWAaftYHwz89uPVGkWyQcziakv8FCykBFsrNTuBSK9n572yxW36mZAy8TLSQVyNPrl794gIomg0hCOte56bmz8FCvDCKfTUi/RNMZkjIe0a6nEgmo/zd6dohOrDFAYKTvSoEz9fZFiofVEBHZTYDPSi95M/NcLxEKyCa/8lMk4MVSSeXCYcGQiNOsCDZiixPCJJZgoZn9HZIQVJsY2VrKleIsVLJPWedWrVWt3F5X6dV5PEY7gGM7Ag0uowy00oAkExvAML/DqPDlvzrvzMV8tOPnNIfyB8/kDaTyWDQ==</latexit>R→<latexit sha1_base64="A5jtn/ZxERDMMirdmTqj+8UrXp0=">AAAB/XicbVC7SgNBFL0bXzG+opY2g0GwCrsi0TJoYxnRPCBZwuxkNhkzM7vMzAphCf6CrfZ2Yuu32PolziZbaOKBC4dz7uVcThBzpo3rfjmFldW19Y3iZmlre2d3r7x/0NJRoghtkohHqhNgTTmTtGmY4bQTK4pFwGk7GF9nfvuRKs0ieW8mMfUFHkoWMoKNlVq9QKR303654lbdGdAy8XJSgRyNfvm7N4hIIqg0hGOtu54bGz/FyjDC6bTUSzSNMRnjIe1aKrGg2k9n307RiVUGKIyUHWnQTP19kWKh9UQEdlNgM9KLXib+6wViIdmEl37KZJwYKsk8OEw4MhHKqkADpigxfGIJJorZ3xEZYYWJsYWVbCneYgXLpHVW9WrV2u15pX6V11OEIziGU/DgAupwAw1oAoEHeIYXeHWenDfn3fmYrxac/OYQ/sD5/AEF0pXd</latexit>S<latexit sha1_base64="y/zEcCihUZM4WUyoSJrXcqus8XE=">AAACJHicbZC7TsMwFIYdrqXcAowsFhWiCFQlCBXGChgYy6UXqSmV47qtVduJbAepCnkIXoJXYIWdDTGwMPAkOG0HaDmS5U//f46O/fsho0o7zqc1Mzs3v7CYWcour6yurdsbm1UVRBKTCg5YIOs+UoRRQSqaakbqoSSI+4zU/P556tfuiVQ0ELd6EJImR11BOxQjbaSWfeBdEKbRXewFnIpIJXnP5/F1cgiH914CH1KC8U2y37JzTsEZFpwGdww5MK5yy/722gGOOBEaM6RUw3VC3YyR1BQzkmS9SJEQ4T7qkoZBgThRzXj4qQTuGqUNO4E0R2g4VH9PxIgrNeC+6eRI99Skl4r/ej6f2Kw7p82YijDSRODR4k7EoA5gmhhsU0mwZgMDCEtq3g5xD0mEtck1a0JxJyOYhupRwS0WilfHudLZOJ4M2AY7IA9ccAJK4BKUQQVg8AiewQt4tZ6sN+vd+hi1zljjmS3wp6yvH+RwpJ0=</latexit>!→(R,R→|S)
<latexit sha1_base64="FiwIuewGSYieGWwUdzlgNYgakrg=">AAACI3icbZC7TsMwFIYdrqXcCowsFhWiIFQlCBXGChgYy6UXqSmV4zqtVTuObAepCnkHXoJXYIWdDbEwsPAkuGkHaDmS5U//f46O/Xsho0rb9qc1Mzs3v7CYWcour6yurec2NmtKRBKTKhZMyIaHFGE0IFVNNSONUBLEPUbqXv986NfviVRUBLd6EJIWR92A+hQjbaR27sC9IEyju9gVIYtUUnA9Hl8nhzC99xL4MCQY3yT77VzeLtppwWlwxpAH46q0c99uR+CIk0BjhpRqOnaoWzGSmmJGkqwbKRIi3Edd0jQYIE5UK07/lMBdo3SgL6Q5gYap+nsiRlypAfdMJ0e6pya9ofiv5/GJzdo/bcU0CCNNAjxa7EcMagGHgcEOlQRrNjCAsKTm7RD3kERYm1izJhRnMoJpqB0VnVKxdHWcL5+N48mAbbADCsABJ6AMLkEFVAEGj+AZvIBX68l6s96tj1HrjDWe2QJ/yvr6AQn+pCs=</latexit>!→(R,R→|S)<latexit sha1_base64="oLC7pBqVQy7k/k6IvPuVh34yVcs=">AAACI3icbZC7TsMwFIadcivlFmBksagQBaEqQagwVsDAWCR6kZpQOa5brNpJZDtIVcg78BK8AivsbIiFgYUnwUkzQMuRLH/6/3N07N8LGZXKsj6Nwtz8wuJScbm0srq2vmFubrVkEAlMmjhggeh4SBJGfdJUVDHSCQVB3GOk7Y0uUr99T4SkgX+jxiFxORr6dEAxUlrqmYfOJWEK3cZOELJIJhXH43EnOYLZvZ/Ah5Rg3EgOembZqlpZwVmwcyiDvBo989vpBzjixFeYISm7thUqN0ZCUcxIUnIiSUKER2hIuhp9xIl04+xPCdzTSh8OAqGPr2Cm/p6IEZdyzD3dyZG6k9NeKv7reXxqsxqcuTH1w0gRH08WDyIGVQDTwGCfCoIVG2tAWFD9dojvkEBY6VhLOhR7OoJZaB1X7Vq1dn1Srp/n8RTBDtgFFWCDU1AHV6ABmgCDR/AMXsCr8WS8Ge/Gx6S1YOQz2+BPGV8/GPikNA==</latexit>!→(X,X→|P)
<latexit sha1_base64="EqHJTCbKqwiDh9TNNS7B+/ptRy8=">AAACJHicbZC7TsMwFIadcivlFmBksagQRaAqQagwVsDAWCR6kZpQOa5brNpOZDtIVchD8BK8AivsbIiBhYEnwW0zQMuRLH/6/3N07D+IGFXacT6t3Nz8wuJSfrmwsrq2vmFvbjVUGEtM6jhkoWwFSBFGBalrqhlpRZIgHjDSDAYXI795T6SiobjRw4j4HPUF7VGMtJE69qF3SZhGt4kXcipilZa8gCet9AiO7/0UPowIJrX0oGMXnbIzLjgLbgZFkFWtY3973RDHnAiNGVKq7TqR9hMkNcWMpAUvViRCeID6pG1QIE6Un4w/lcI9o3RhL5TmCA3H6u+JBHGlhjwwnRzpOzXtjcR/vYBPbda9Mz+hIoo1EXiyuBczqEM4Sgx2qSRYs6EBhCU1b4f4DkmEtcm1YEJxpyOYhcZx2a2UK9cnxep5Fk8e7IBdUAIuOAVVcAVqoA4weATP4AW8Wk/Wm/VufUxac1Y2sw3+lPX1A/NqpKY=</latexit>!→(X,X→|P)
<latexit sha1_base64="TN2IgwWtLgPmmLqy8GIJ11OU38g=">AAAB/XicbVDLSgMxFL3js9ZX1aWbYBFclRmR6rLoxmUF+4B2KEmaaWOTzJBkhDIUf8Gt7t2JW7/FrV9i2s5CWw9cOJxzL+dySCK4sb7/5a2srq1vbBa2its7u3v7pYPDpolTTVmDxiLWbYINE1yxhuVWsHaiGZZEsBYZ3Uz91iPThsfq3o4TFko8UDziFFsnNbtEZu1Jr1T2K/4MaJkEOSlDjnqv9N3txzSVTFkqsDGdwE9smGFtORVsUuymhiWYjvCAdRxVWDITZrNvJ+jUKX0UxdqNsmim/r7IsDRmLInblNgOzaI3Ff/1iFxIttFVmHGVpJYpOg+OUoFsjKZVoD7XjFoxdgRTzd3viA6xxtS6woqulGCxgmXSPK8E1Ur17qJcu87rKcAxnMAZBHAJNbiFOjSAwgM8wwu8ek/em/fufcxXV7z85gj+wPv8AQ27leI=</latexit>X<latexit sha1_base64="lWktmyI1ROfmDPxmU7NKAtkD0F8=">AAAB/nicbVDLSgMxFL3xWeur6tJNsIiuyoxIdVl047KCfUA7lEyaaUOTzJBkhDIU/AW3uncnbv0Vt36JaTsLbT1w4XDOvZzLCRPBjfW8L7Syura+sVnYKm7v7O7tlw4OmyZONWUNGotYt0NimOCKNSy3grUTzYgMBWuFo9up33pk2vBYPdhxwgJJBopHnBLrpFY3lFl7ctYrlb2KNwNeJn5OypCj3it9d/sxTSVTlgpiTMf3EhtkRFtOBZsUu6lhCaEjMmAdRxWRzATZ7N0JPnVKH0exdqMsnqm/LzIijRnL0G1KYodm0ZuK/3qhXEi20XWQcZWklik6D45SgW2Mp13gPteMWjF2hFDN3e+YDokm1LrGiq4Uf7GCZdK8qPjVSvX+sly7yespwDGcwDn4cAU1uIM6NIDCCJ7hBV7RE3pD7+hjvrqC8psj+AP0+QNywJYT</latexit>X→<latexit sha1_base64="t19YEyICNfzXCFwgA7yC+c8M+1w=">AAAB/XicbVDLSgMxFL3js9ZX1aWbYBFclRmR6rLoxmUF+4B2KEmaaWOTzJBkhDIUf8Gt7t2JW7/FrV9i2s5CWw9cOJxzL+dySCK4sb7/5a2srq1vbBa2its7u3v7pYPDpolTTVmDxiLWbYINE1yxhuVWsHaiGZZEsBYZ3Uz91iPThsfq3o4TFko8UDziFFsnNbtEZvVJr1T2K/4MaJkEOSlDjnqv9N3txzSVTFkqsDGdwE9smGFtORVsUuymhiWYjvCAdRxVWDITZrNvJ+jUKX0UxdqNsmim/r7IsDRmLInblNgOzaI3Ff/1iFxIttFVmHGVpJYpOg+OUoFsjKZVoD7XjFoxdgRTzd3viA6xxtS6woqulGCxgmXSPK8E1Ur17qJcu87rKcAxnMAZBHAJNbiFOjSAwgM8wwu8ek/em/fufcxXV7z85gj+wPv8AQETldo=</latexit>PFigure 1: Top: Example graphs GandG′are shown with color-coded nodes to indicate alignment
corresponding to the optimal edit path transforming GtoG′.Bottom: GRAPH EDX’s GED prediction
pipeline. GandG′are independently encoded using MPNN θ, and then padded with zero vectors to
equalize sizes, resulting in contextual node representations X,X′∈RN×d. For each node-pair, the
corresponding embeddings and edge presence information are gathered and fed into MLP θto obtain
R,R′∈RN(N−1)/2×D. Simultaneously, X,X′are fed into PERM NETϕto obtain the soft node
alignment P(Eq.(16)) which constructs the node-pair alignment matrix S∈RN(N−1)/2×N(N−1)/2
asS[(u, v),(u′, v′)] =P[u, u′]P[v, v′] +P[u, v′]P[v, u′]. Finally, X,X′,Pare used to approxi-
mate node insertion and deletion costs, while R,R′,Sare used to approximate edge insertion and
deletion costs. The four costs are summed to give the final prediction GED θ,ϕ(G, G′)(Eq.(8)).
detection. For example, by setting all costs to one, GED( G, G′) = min P1
2||A−PA′P⊤||1+
||ηG−PηG′||1, which equals zero only when GandG′are isomorphic. Further discussion on this
topic is provided in Appendix B.
4.2 G RAPH EDX model
Minimizing the objective in Eq. (7)is a challenging problem. In similar problems, recent methods
have approximated the hard node permutation matrix Pwith a soft permutation matrix obtained
using Sinkhorn iterations on a neural cost matrix. However, the binary nature of the adjacency matrix
and the pad indicator ηstill impede the flow of gradients during training. To tackle this problem, we
make relaxations in two key places within each term in Eq. (7), leading to our proposed GRAPH EDX
model.
(1)We replace the binary values in ηG,ηG′,AandA′with real values from node and node-pair
embeddings: X∈RN×dandR∈R(N
2)×D. These embeddings are computed using a GNN
guided neural module EMBED θwith parameter θ. Since the graphs are undirected, Rgathers the
embeddings of the unique node-pairs, resulting in N
2
rows instead of N2.
(2)We substitute the hard node permutation matrix Pwith a soft alignment matrix, generated using
a differentiable alignment planner PERM NETϕwith parameter ϕ. Here, Pis a doubly stochastic
matrix, with P[u, u′]indicating the "score" or "probability" of aligning u7→u′. Additionally,
we also compute the corresponding node-pair alignment matrix S.
Using these relaxations, we approximate the four edit costs in Eq. (7)with four continuous set
distance surrogate functions.ReLU 
A−PA′P⊤
1,1→∆⊖(R,R′|S),ReLU 
PA′P⊤−A
1,1→∆⊕(R,R′|S),
∥ReLU ( ηG−PηG′)∥1→∆⊖(X,X′|P),∥ReLU ( PηG′−ηG)∥1→∆⊕(X,X′|P).
This gives us an approximated GED parameterized by θandϕ.
GED θ,ϕ(G, G′) =a⊖∆⊖(R,R′|S) +a⊕∆⊕(R,R′|S)
+b⊖∆⊖(X,X′|P) +b⊕∆⊕(X,X′|P).(8)
Note that since RandR′contain the embeddings of each node-pair only once, there is no need to
multiply 1/2in the first two terms, unlike Eq. (7). Next, we propose three types of neural surrogates
to approximate each of the four operations.
(1)ALIGN DIFF Given the node-pair embeddings RandR′for the graph pairs GandG′, we
apply the soft node-pair alignment StoR′. We then define the edge edits in terms of asymmetric
5differences between RandSR′, which serves as a replacement for the corresponding terms in
Eq. (7). We write ∆⊖(R,R′|S)and∆⊕(R,R′|S)as:
∆⊖(R,R′|S) =∥ReLU ( R−SR′)∥1,1,∆⊕(R,R′|S) =∥ReLU ( SR′−R)∥1,1.(9)
Similarly, for the node edits, we can compute ∆⊖(X,X′|P)and∆⊕(X,X′|P)as:
∆⊖(X,X′|P) =∥ReLU ( X−PX′)∥1,1,∆⊕(X,X′|P) =∥ReLU ( PX′−X)∥1,1.
(2)DIFFALIGN In Eq. (9), we first aligned R′usingSand then computed the difference from R.
Instead, here we first computed the pairwise differences between R′andRfor all pairs of node-pairs
(e, e′), and then combine these differences with the corresponding alignment scores S[e, e′]. We
compute the edge edit surrogates ∆⊖(R,R′|S)and∆⊕(R,R′|S)as:
∆⊖(R,R′|S) =X
e,e′∥ReLU ( R[e,:]−R′[e′,:])∥1S[e, e′], (10)
∆⊕(R,R′|S) =X
e,e′∥ReLU ( R′[e′,:]−R[e,:])∥1S[e, e′]. (11)
Here, eande′represent node-pairs, which are not necessarily edges. When the node-pair
alignment matrix Sis a hard permutation, ∆⊕and∆⊖remain the same across ALIGN DIFF
and DIFFALIGN (as shown in Appendix B). Similar to Eqs. (10)—(11), we can com-
pute ∆⊖(X,X′|P) =P
u,u′∥ReLU ( X[u,:]−X′[u′,:])∥1P[u, u′]and∆⊕(X,X′|P) =P
u,u′∥ReLU ( X′[u′,:]−X[u,:])∥1P[u, u′].
(3)XOR-D IFFALIGN As indicated by the combinatorial formulation of GED in Eq. (7), the edit
cost of a particular node-pair is non-zero only when an edge is mapped to a non-edge or vice-versa.
However, the surrogates for the edge edits in ALIGN DIFForDIFFALIGN fail to capture this condition
because they can assign non-zero costs to the pairs (e= (u, v), e′= (u′, v′))even when both e
ande′are either edges or non-edges. To address this, we explicitly discard such pairs from the
surrogates defined in Eqs. (10)–(11). This is ensured by applying a XOR operator J 
·,·
between
the corresponding entries in the adjacency matrices, i.e.,A[u, v]andA′[u′, v′], and then multiplying
this result with the underlying term. Hence, we write:
∆⊖(R,R′|S) =X
e=(u,v)
e′=(u′,v′)J 
A[u, v],A′[u′, v′]
∥ReLU ( R[e,:]−R′[e′,:])∥1S[e, e′],(12)
∆⊕(R,R′|S) =X
e=(u,v)
e′=(u′,v′)J 
A[u, v],A′[u′, v′]
∥ReLU ( R′[e′,:]−R[e,:])∥1S[e, e′].(13)
Similarly, the cost contribution for node operations arises from mapping a padded node to a
non-padded node or vice versa. We account for this by multiplying J(ηG[u],ηG′[u′])with
each term of ∆⊖(X,X′|P)and∆⊕(X,X′|P)computed using DIFFALIGN . Hence, we
compute ∆⊖(X,X′|P) =P
u,u′J(ηG[u],ηG′[u′])∥ReLU ( X[u,:]−X′[u′,:])∥1P[u, u′]and
∆⊕(X,X′|P) =P
u,u′J(ηG[u],ηG′[u′])∥ReLU ( X′[u′,:]−X[u,:])∥1P[u, u′].
Comparison between ALIGN DIFF,DIFFALIGN and XOR-D IFFALIGN ALIGN DIFFandDIF-
FALIGN become equivalent when Sis a hard permutation. However, when Sis doubly stochastic,
the above three surrogates, ALIGN DIFF,DIFFALIGN andXOR-D IFFALIGN , are not equivalent. As
we move from ALIGN DIFFtoDIFFALIGN toXOR-D IFFALIGN , we increasingly align the design to
the inherent inductive biases of GED, thereby achieving a better representation of its cost structure.
Suppose we are computing the GED between two isomorphic graphs, GandG′, with uniform costs
for all edit operations. In this scenario, we ideally expect a neural network to consistently output a zero
cost. Now consider a proposed soft alignment Swhich is close to the optimal alignment. Under the
ALIGN DIFFdesign, the aggregated valueP
e′S[e, e′]R′[e′,:]— where eande′represent two edges
matched in the optimal alignment — can accumulate over the large number of N(N−1)/2node-pairs.
This aggregation leads to high values of ||R[e,:]−SR′[e′,:]||1, implying that ALIGN DIFFcaptures
an aggregate measure of the cost incurred by spurious alignments, but cannot disentangle the effect
of individual misalignments, making it difficult for A LIGN DIFFto learn the optimal alignment.
In contrast, the DIFFALIGN approach, which relies on pairwise differences between embeddings to
explicitly guide Stowards the optimal alignment, significantly ameliorates this issue. For example,
in the aforementioned setting of GED with uniform costs, the cost associated with each pairing
6(e, e′)is explicitly encoded using ||R[e,:]−R′[e′,:]||1, and is explicitly set to zero for pairs that are
correctly aligned. Moreover, this representation allows DIFFALIGN to isolate the cost incurred by
each misalignment, making it easier to train the model to reduce the cost of these spurious matches to
zero.
However, DIFFALIGN does not explicitly set edge-to-edge and non-edge-to-non-edge mapping costs
to zero, potentially leading to inaccurate GED estimates. XOR-D IFFALIGN addresses these concerns
by applying a XOR of the adjacency matrices to the cost matrix, ensuring that non-zero cost is
computed only when mapping an edge to a non-edge or vice versa. This resolves the issues in
both ALIGN DIFFandDIFFALIGN by focusing on mismatches between edges and non-edges, while
disregarding redundant alignments that do not contribute to the GED.
Amenability to indexing and approximate nearest neighbor (ANN) search. All of the aforemen-
tioned distance surrogates are based on a late interaction paradigm, where the embeddings of Gand
G′are computed independently of each other before computing the distances ∆. This is particularly
useful in the context of graph retrieval, as it allows for the corpus graph embeddings to be indexed
a-priori, thereby enabling efficient retrieval of relevant graphs for new queries.
When the edit costs are uniform, our predicted GED (8)becomes symmetric with respect to Gand
G′. In such cases, DIFFALIGN andALIGN DIFFyield a structure similar to the Wasserstein distance
induced by L1norm. This allows us to leverage ANN techniques like Quadtree or Flowtree [ 4].
However, while the presence of the XOR operator Jwithin each term in Eq. (12) –(13) ofXOR-
DIFFALIGN enhances the interaction between GandG′, this same feature prevents XOR-D IFFALIGN
from being cast to an ANN-amenable setup, unlike D IFFALIGN and A LIGN DIFF.
4.3 Network architecture of E MBED θand P ERM NETϕ
In this section, we present the network architectures of the two components of GRAPH EDX,viz.,
EMBED θandPERM NETϕ, as introduced in items (1) and (2) in Section 4.2. Notably, in our proposed
graph representation, non-edges and edges alike are embedded as non-zero vectors. In other words,
all node-pairs are endowed with non-trivial embeddings. We then explain the design approach for
edge-consistent node alignment.
Neural architecture of EMBED θ EMBED θconsists of a message passing neural network
MPNN θand a decoupled neural module MLP θ. Given the graphs G, G′,MPNN θwithKprop-
agation layers is used to iteratively compute the node embeddings
xK(u)∈Rd|u∈V	
and
x′
K(u)∈Rd|u∈V′	
, then collect them into XandX′after padding, i.e.,
X:={xK(u)|u∈[N]}= MPNN θ(G),X′:={x′
K(u′)|u′∈[N]}= MPNN θ(G′).(14)
The optimal alignment Sis highly sensitive to the global structure of the graph pairs, i.e.,S[e, e′]
can significantly change when we perturb GorG′in regimes distant from eore′. Conventional
representations mitigate this sensitivity while training models, by setting non-edges to zero, rendering
them invariant to structural changes. To address this limitation, we utilize more expressive graph
representations, where non-edges are also embedded using trainable non-zero vectors. This approach
allows information to be captured from the structure around the nodes through both edges and
non-edges, thereby enhancing the representational capacity of the embedding network. For each
node-pair e= (u, v)∈G(and equivalently (v, u)), and e′= (u′, v′)∈G′, the embeddings of the
corresponding nodes and their connectivity status are concatenated, and then passed through an MLP
to obtain the embedding vectors r(e),r′(e′)∈RD. Fore= (u, v)∈G, we compute r(e)as:
r(e) =MLP θ(xK(u)||xK(v)||A[u, v]) + MLP θ(xK(v)||xK(u)||A[v, u]). (15)
We can compute r′(e)in similar manner. The property r((u, v)) =r((v, u))reflects the undirected
property of graph. Finally, the vectors r(e)andr′(e′)are stacked into matrices RandR′, both with
dimensions R(N
2)×D. We would like to highlight that r((u, v))orr′((u′, v′))are computed only
once for all node-pairs, after the MPNN completes its final Kth layer of execution. The message
passing in the MPNN occurs only over edges. Therefore, this approach does not significantly increase
the time complexity.
Neural architecture of PERM NETϕThe network PERM NETϕprovides Pas a soft node alignment
matrix by taking the node embeddings as input, i.e.,P=PERM NETϕ(X,X′).PERM NETϕis
implemented in two steps. In the first step, we apply a neural network cϕon both xKandx′
K,
and then compute the normed difference between their outputs to construct the matrix C, where
C[u, u′] =∥cϕ(xK(u))−cϕ(x′
K(u′))∥1. Next, we apply iterative Sinkhorn normalizations [ 16,
735] on exp(−C/τ), to obtain a soft node alignment P. Therefore,
P= Sinkhorn
exp 
−∥cϕ(xK(u))−cϕ(x′
K(u′))∥1/τ
(u,u′)∈[N]×[N]
. (16)
Here, τis a temperature hyperparameter. In a general cost setting, GED is typically asymmetric,
so it may be desirable for C[u, u′]to be asymmetric with respect to xandx′. However, as noted
in Proposition 1, when we compute GED( G′, G), the alignment matrix P′=PERM NETϕ(X′,X)
should satisfy the condition that P′=P⊤, where Pis computed from Eq. (16). The current form of
Csupports this condition, whereas an asymmetric form might not, as shown in Appendix B.
We construct S∈R(N
2)×R(N
2)as follows. Each pair of nodes (u, v)inGand(u′, v′)inG′can
be mapped in two ways, regardless of whether they are edges or non-edges: (1) node u7→u′and
v7→v′which is denoted by P[u, u′]P[v, v′]; (2) node u7→v′andv7→u′, which is denoted by
P[u, v′]P[v, u′]Combining these two scenarios, we compute the node-pair alignment matrix Sas:
S[(u, v),(u′, v′)] =P[u, u′]P[v, v′] +P[u, v′]P[v, u′]. This explicit formulation of SfromP
ensures mutually consistent permutation across nodes and node-pairs.
5 Experiments
We conduct extensive experiments on GRAPH EDXto showcase the effectiveness of our method across
several real-world datasets, under both uniform and non-uniform cost settings for GED. Additiional
experimental results can be found in Appendix D.
5.1 Setup
Datasets We experiment with seven real-world datasets: Mutagenicity (Mutag) [ 18], Ogbg-Code2
(Code2) [ 23], Ogbg-Molhiv (Molhiv) [ 23], Ogbg-Molpcba (Molpcba) [ 23], AIDS [ 36], Linux [ 5] and
Yeast [ 36]. For each dataset’s training, test and validation sets Dsplit, we generate |Dsplit|
2
+|Dsplit|
graph pairs, considering combinations between every two graphs, including self-pairing. We calculate
the exact ground truth GED using the F2 solver [ 29], implemented within GEDLIB [ 10]. For GED
with uniform cost setting, we set the cost values to b⊖=b⊕=a⊖=a⊕= 1. For GED with
non-uniform cost setting, we use b⊖= 3, b⊕= 1, a⊖= 2, a⊕= 1. Further details on dataset
generation and statistics are presented in Appendix C. In the main paper, we present results for the
first five datasets under both uniform and non-uniform cost settings for GED. Additional experiments
for Linux and Yeast, as well as GED with node label substitutions, are presented in Appendix D.
Baselines We compare our approach with nine state-of-the-art methods. These include two variants
of GMN [ 31]: (1) GMN-Match and (2) GMN-Embed; (3) ISONET [ 44], (4) GREED [ 40], (5)
ERIC [ 56], (6) SimGNN [ 5], (7) H2MN [ 54], (8) GraphSim [ 6] and (9) EGSC [ 39]. To compute
the GED, GMN-Match, GMN-Embed, and GREED use the Euclidean distance between the vector
representation of two graphs. ISONET uses an asymmetric distance specifically tailored to subgraph
isomorphism. H2MN is an early interaction network that utilizes higher-order node similarity through
hypergraphs. ERIC, SimGNN, and EGSC leverage neural networks to calculate the distance between
two graphs. Furthermore, the last three methods predict a score based on the normalized GED in the
form of exp (−2GED( G, G′)/(|V|+|V′|)). Notably, none of these baseline approaches have been
designed to incorporate non-uniform edit costs into their models. To address this limitation, when
working with GED under non-uniform cost setting, we include the edit costs as initial features in the
graphs for all baseline models. In Appendix D.3, we compare the performance of baselines without
cost features.
Evaluation Given a dataset D={(Gi, G′
i,GED( Gi, G′
i))}i∈[n], we divide it into training, valida-
tion and test folds with a split ratio of 60:20:20. We train the models using the Mean Squared Error
(MSE) between the predicted GED and the ground truth GED as the loss. For model evaluation, we
calculate the Mean Squared Error (MSE) between the actual and predicted GED on the test set. For
ERIC, SimGNN and EGSC, we rescale the predicted score to obtain the true (unscaled) GED as
GED( G, G′) =−(|V|+|V|′) log( s)/2. In Appendix D, we also report Kendall’s Tau (KTau) to
evaluate the rank correlation across different experiments.
5.2 Results
Selection of ∆•(X,X′|P)and∆•(R,R′|S)We start by comparing the performance of the
nine different combinations (three for edge edits, and three for node edits) of our neural distance sur-
8rogates from the cartesian space of Edge- {ALIGN DIFF,DIFFALIGN,XOR-D IFFALIGN}×Node-
{ALIGN DIFF,DIFFALIGN,XOR-D IFFALIGN}. Table 2 summarizes the results. We make the
following observations. (1) The best combinations share the XOR-D IFFALIGN on the edge edit for-
mulation, because, XOR-D IFFALIGN offers more inductive bias, by zeroing the edit cost of aligning
an edge to edge and a non-edge to non-edge, as we discussed in Section 4.2. Consequently, one can
limit the cartesian space to only three surrogates for node edits, while using XOR-D IFFALIGN as the
fixed surrogate for edge edits. (2) There is no clear winner between DIFFALIGN andALIGN DIFF.
GRAPH EDXis chosen from the model which has the lowest validation error, and the numbers in
Table 2 are on the test set. Hence, in datasets such as AIDS under uniform cost, or Molhiv under
non-uniform cost, the model chosen for G RAPH EDX doesn’t have the best test set performance.
Edge edit Node editGED with uniform cost GED with non-uniform cost
Mutag Code2 Molhiv Molpcba AIDS Mutag Code2 Molhiv Molpcba AIDS
DIFFALIGN DIFFALIGN 0.579 0.740 0.820 0.778 0.603 1.205 2.451 1.855 1.825 1.417
DIFFALIGN ALIGN DIFF 0.557 0.742 0.806 0.779 0.597 1.211 2.116 1.887 1.811 1.319
DIFFALIGN XOR 0.538 0.719 0.794 0.777 0.580 1.146 1.896 1.802 1.822 1.381
ALIGN DIFF DIFFALIGN 0.537 0.513 0.815 0.773 0.606 1.185 1.689 1.874 1.758 1.391
ALIGN DIFF ALIGN DIFF 0.578 0.929 0.833 0.773 0.593 1.338 1.488 1.903 1.859 1.326
ALIGN DIFF XOR 0.533 0.826 0.812 0.780 0.575 1.196 1.741 1.870 1.815 1.374
XOR A LIGN DIFF 0.492 0.429 0.788 0.766 0.565 1.134 1.478 1.872 1.742 1.252
XOR D IFFALIGN 0.510 0.634 0.781 0.765 0.574 1.148 1.489 1.804 1.757 1.340
XOR XOR 0.530 1.588 0.807 0.764 0.564 1.195 2.507 1.855 1.677 1.319
GRAPH EDX 0.492 0.429 0.781 0.764 0.565 1.134 1.478 1.804 1.677 1.252
Table 2: Prediction error measured in terms of MSE of the nine combinations of our neural set
distance surrogate across five datasets on test set, for GED with uniform costs and non-uniform costs.
For GED with uniform (non-uniform) costs we have b⊖=b⊕=a⊖=a⊕= 1 (b⊖= 3, b⊕=
1, a⊖= 2, a⊕= 1.) The GRAPH EDXmodel was selected based on the lowest MSE on the validation
set, and we report the results of the MSE on the test set. Green (yellow ) numbers report the best
(second best) performers.
Comparison with baselines We compare the performance of GRAPH EDXagainst all state-of-the-art
baselines for GED with both uniform and non-uniform costs. Table 3 summarizes the results. We
make the following observations. (1) GRAPH EDXoutperforms all the baselines by a significant
margin. For GED with uniform costs, this margin often goes as high as 15%. This advantage becomes
even more pronounced for GED with non-uniform costs, where our method outperforms the baselines
by a margin as high as 30%, as seen in Code2. (2) There is no clear second-best method. Among the
baselines, EGSC and ERIC each outperforms the others in two out of five datasets for both uniform
and non-uniform cost settings. Also, EGSC demonstrates competitive performance in AIDS.
GED with uniform cost GED with non-uniform cost
Mutag Code2 Molhiv Molpcba AIDS Mutag Code2 Molhiv Molpcba AIDS
GMN-Match [31] 0.797 1.677 1.318 1.073 0.821 69.210 13.472 76.923 23.985 31.522
GMN-Embed [31] 1.032 1.358 1.859 1.951 1.044 72.495 13.425 78.254 28.437 33.221
ISONET [44] 1.187 0.879 1.354 1.106 1.640 3.369 3.025 3.451 2.781 5.513
GREED [40] 1.398 1.869 1.708 1.550 1.004 68.732 11.095 78.300 26.057 34.354
ERIC [56] 0.719 1.363 1.165 0.862 0.731 1.981 12.767 3.377 2.057 1.581
SimGNN [5] 1.471 2.667 1.609 1.456 1.455 4.747 5.212 4.145 3.465 4.316
H2MN [54] 1.278 7.240 1.521 1.402 1.114 3.413 9.435 3.782 3.396 3.105
GraphSim [6] 2.005 3.139 2.577 1.656 1.936 5.370 7.405 6.643 3.928 5.266
EGSC [39] 0.765 4.165 1.138 0.938 0.627 1.758 3.957 2.371 2.133 1.693
GRAPH EDX 0.492 0.429 0.781 0.764 0.565 1.134 1.478 1.804 1.677 1.252
Table 3: Prediction error measured in terms of MSE of GRAPH EDXand all the state-of-the-
art baselines across five datasets on test set, for GED with uniform costs and non-uniform
costs. For GED with uniform (non-unfiform) costs we have b⊖=b⊕=a⊖=a⊕= 1
(b⊖= 3, b⊕= 1, a⊖= 2, a⊕= 1.)GRAPH EDXrepresents the best model based on the vali-
dation set from the cartesian space of Edge- {ALIGN DIFF,DIFFALIGN,XOR-D IFFALIGN}×Node-
{ALIGN DIFF,DIFFALIGN,XOR-D IFFALIGN}.Green (yellow ) numbers report the best (second
best) performers.
Impact of cost-guided GED Among the baselines, GMN-Match, GMN-Embed and GREED
compute GED using the euclidean distance between the graph embeddings, i.e.,GED( G, G′) =
∥xG−xG′∥2, whereas we compute it by summing the set distance surrogates between the node
and edge embedding sets. To understand the impact of our cost guided distance, we adapt it
to the graph-level embeddings used by the above three baselines as follows: GED( G, G′) =
b⊖+a⊖
2∥ReLU ( xG−xG′)∥1+b⊕+a⊕
2∥ReLU ( xG′−xG)∥1. Table 4 summarizes the results in
9Uniform cost Non-uniform cost
Mutag Code2 Molhiv Mutag Code2 Molhiv
GMN-Match 0.797 1.677 1.318 69.210 13.472 76.923
GMN-Match * 0.654 0.960 1.008 1.592 2.906 2.162
GMN-Embed 1.032 1.358 1.859 72.495 13.425 78.254
GMN-Embed * 1.011 1.179 1.409 2.368 3.272 3.413
GREED 1.398 1.869 1.708 68.732 11.095 78.300
GREED * 2.133 1.850 1.644 2.456 5.429 3.827
GRAPH EDX 0.492 0.429 0.781 1.134 1.478 1.804
Table 4: Impact of cost guided distance in terms
of MSE; * represents the variant of the baseline
with cost-guided distance. Green (bold ) shows
the best among all methods (only baselines).Mutag Code2 Molhiv Molpcba AIDS
GMN-Match 1.057 5.224 1.388 1.432 0.868
GMN-Embed 2.159 4.070 3.523 4.657 1.818
ISONET 0.876 1.129 1.617 1.332 1.142
GREED 2.876 4.983 2.923 3.902 2.175
ERIC 0.886 6.323 1.537 1.278 1.602
SimGNN 1.160 5.909 1.888 2.172 1.418
H2MN 1.277 6.783 1.891 1.666 1.290
GraphSim 1.043 4.708 1.817 1.748 1.561
EGSC 0.776 8.742 1.273 1.426 1.270
GRAPH EDX 0.441 0.820 0.792 0.846 0.538
Table 5: MSE for different methods with unit
node substitution cost in uniform cost setting.
Green (yellow ) show (second) best method.
terms of MSE, which shows that (1) our set-divergence-based cost guided distance reduces the MSE
by a significant margin in most cases (2) the margin of improvement is more prominent with GED
involving non-uniform costs, where the modeling of specific cost values is crucial (3) GRAPH EDX
outperforms the baselines even after changing their default distance to our cost guided distance.
Performance for GED under node substitution cost The scoring function in Eq. 8 can also be
extended to incorporate node label substitution cost, which has been described in Appendix B. Here,
we compare the performance of our model with the baselines in terms of MSE where we include
node substitution cost b∼, with cost setting as b⊖=b⊕=b∼=a⊖=a⊕= 1. In Table 5, we report
the results across 5 datasets equipped with node labels, passed as one-hot encoded node features. We
observe that (1) our model outperforms all other baselines across all datasets by significant margin;
(2) there is no clear second winner but ERIC, EGSC and ISONET performs better than the others.
Benefits of using all node-pairs representation In Table 6, we compare against
(i) Edge-only (edge → edge): where we only consider the edges that are present,
Mutag Code2 Molhiv
Edge-only (edge→edge) 0.566 0.683 0.858
Edge-only (pair→pair) 0.596 0.760 0.862
GRAPH EDX 0.492 0.429 0.781
Table 6: Comparison of variants of edge represen-
tation under uniform cost setting. Green (yellow )
numbers report the best (second best) performers.resulting in Sbeing an edge-alignment matrix, and
R,R′∈Rmax(|E|,|E′|)×D(ii) Edge-only (pair→
pair): In this variant, the embeddings of the non-
edges in R,R′∈RN(N−1)/2×Dare explicitly set to
zero. in terms of MSE, which show that (1) both these
sparse representations perform significantly worse
compared to our method using non-trivial representa-
tions for both edges and non-edges, and (2) Edge-only (edge→edge)performs better than Edge-only
(pair→pair). This underscores the importance of explicitly modeling trainable non-edge embeddings
to capture the sensitivity of GED to global graph structure.
6 Conclusion
Our work introduces a novel neural model for computing GED that explicitly incorporates general
costs of edit operations. By leveraging graph representations that recognize both edges and non-edges,
together with the design of suitable set distance surrogates, we achieve a more robust neural surrogate
for GED. Our experiments demonstrate that this approach outperforms state-of-the-art methods,
especially in settings with general edit costs, providing a flexible and effective solution for a range of
applications. Future work could focus on extending the GED formulation to richly-attributed graphs
by modeling the structure of edit operations and the similarity of all node-pair features.
Limitations Our neural model for GED showcases significant improvements in accuracy and
flexibility for modeling edit costs. However, there are some limitations to consider. (1) While
computing graph representations over N
2
× N
2
node-pairs does not require additional parameters
due to parameter-sharing, it does demand significant memory resources. This could pose challenges,
especially with larger-sized graphs. (2) The assumption of fixed edit costs across all graph pairs
within a dataset might not reflect real-world scenarios where costs vary based on domain-specific
factors and subjective human relevance judgements. This calls for more specialized approaches to
accurately model the impact of each edit operation, which may differ across node pairs.
Acknowledgements Indradyumna acknowledges Qualcomm Innovation Fellowship, Abir and
Soumen acknowledge grants from Amazon, Google, IBM and SERB.
10References
[1]J. Adler and S. Lunz. Banach wasserstein gan. Advances in neural information processing
systems , 31, 2018.
[2]B. Amos, L. Xu, and J. Z. Kolter. Input convex neural networks. In International Conference
on Machine Learning , pages 146–155. PMLR, 2017.
[3]M. Arjovsky, S. Chintala, and L. Bottou. Wasserstein generative adversarial networks. In
International conference on machine learning , pages 214–223. PMLR, 2017.
[4]A. Backurs, Y . Dong, P. Indyk, I. Razenshteyn, and T. Wagner. Scalable nearest neighbor search
for optimal transport. In International Conference on machine learning , pages 497–506. PMLR,
2020.
[5]Y . Bai, H. Ding, S. Bian, T. Chen, Y . Sun, and W. Wang. Simgnn: A neural network approach to
fast graph similarity computation. In Proceedings of the Twelfth ACM International Conference
on Web Search and Data Mining , pages 384–392, 2019.
[6]Y . Bai, H. Ding, K. Gu, Y . Sun, and W. Wang. Learning-based efficient graph similarity
computation via multi-scale convolutional set matching. In Proceedings of the AAAI Conference
on Artificial Intelligence , volume 34, pages 3219–3226, 2020.
[7]D. B. Blumenthal. New techniques for graph edit distance computation. arXiv preprint
arXiv:1908.00265 , 2019.
[8]D. B. Blumenthal and J. Gamper. Improved lower bounds for graph edit distance. IEEE
Transactions on Knowledge and Data Engineering , 30:503–516, 2018. URL https://api.
semanticscholar.org/CorpusID:3438059 .
[9]D. B. Blumenthal, E. Daller, S. Bougleux, L. Brun, and J. Gamper. Quasimetric graph edit
distance as a compact quadratic assignment problem. In 2018 24th International Conference on
Pattern Recognition (ICPR) , pages 934–939, 2018. doi: 10.1109/ICPR.2018.8546055.
[10] D. B. Blumenthal, S. Bougleux, J. Gamper, and L. Brun. Gedlib: A c++ library for graph
edit distance computation. In D. Conte, J.-Y . Ramel, and P. Foggia, editors, Graph-Based
Representations in Pattern Recognition , pages 14–24, Cham, 2019. Springer International
Publishing. ISBN 978-3-030-20081-7.
[11] S. Bougleux, L. Brun, V . Carletti, P. Foggia, B. Gaüzère, and M. Vento. Graph edit distance as a
quadratic assignment problem. Pattern Recognition Letters , 87:38–46, 2017. ISSN 0167-8655.
doi: https://doi.org/10.1016/j.patrec.2016.10.001. URL https://www.sciencedirect.com/
science/article/pii/S0167865516302665 . Advances in Graph-based Pattern Recogni-
tion.
[12] A. Z. Broder, M. Charikar, A. M. Frieze, and M. Mitzenmacher. Min-wise independent
permutations. In Proceedings of the thirtieth annual ACM symposium on Theory of computing ,
pages 327–336, 1998.
[13] H. Bunke. On a relation between graph edit distance and maximum common subgraph. Pattern
Recognition Letters , 18(8):689–694, 1997.
[14] H. Bunke and G. Allermann. Inexact graph matching for structural pattern recognition. Pattern
Recognition Letters , 1(4):245–253, 1983.
[15] L. Chang, X. Feng, X. Lin, L. Qin, and W. Zhang. Efficient graph edit distance computation and
verification via anchor-aware lower bound estimation. arXiv preprint arXiv:1709.06810 , 2017.
[16] M. Cuturi. Sinkhorn distances: Lightspeed computation of optimal transport. Advances in
neural information processing systems , 26:2292–2300, 2013.
[17] M. Daniels, T. Maunu, and P. Hand. Score-based generative neural networks for large-scale
optimal transport. Advances in neural information processing systems , 34:12955–12965, 2021.
11[18] A. K. Debnath, R. L. Lopez de Compadre, G. Debnath, A. J. Shusterman, and C. Hansch.
Structure-activity relationship of mutagenic aromatic and heteroaromatic nitro compounds.
correlation with molecular orbital energies and hydrophobicity. Journal of Medicinal Chem-
istry, 34(2):786–797, 1991. doi: 10.1021/jm00106a046. URL https://doi.org/10.1021/
jm00106a046 .
[19] K. D. Doan, S. Manchanda, S. Mahapatra, and C. K. Reddy. Interpretable graph similarity
computation via differentiable optimal alignment of node embeddings. In Proceedings of
the 44th International ACM SIGIR Conference on Research and Development in Information
Retrieval , pages 665–674, 2021.
[20] M. Douze, A. Guzhva, C. Deng, J. Johnson, G. Szilvasy, P.-E. Mazaré, M. Lomeli, L. Hosseini,
and H. Jégou. The faiss library. arXiv preprint arXiv:2401.08281 , 2024.
[21] C. Garcia-Hernandez, A. Fernandez, and F. Serratosa. Ligand-based virtual screening using
graph edit distance as molecular similarity measure. Journal of chemical information and
modeling , 59(4):1410–1421, 2019.
[22] A. Genevay, M. Cuturi, G. Peyré, and F. Bach. Stochastic optimization for large-scale optimal
transport. Advances in neural information processing systems , 29, 2016.
[23] W. Hu, M. Fey, M. Zitnik, Y . Dong, H. Ren, B. Liu, M. Catasta, and J. Leskovec. Open
graph benchmark: Datasets for machine learning on graphs. Advances in neural information
processing systems , 33:22118–22133, 2020.
[24] P. Indyk and R. Motwani. Approximate nearest neighbors: towards removing the curse of
dimensionality. In Proceedings of the thirtieth annual ACM symposium on Theory of computing ,
pages 604–613, 1998.
[25] P. Indyk, R. Motwani, P. Raghavan, and S. Vempala. Locality-preserving hashing in multidi-
mensional spaces. In Proceedings of the twenty-ninth annual ACM symposium on Theory of
computing , pages 618–625, 1997.
[26] S. Ivanov, S. Sviridov, and E. Burnaev. Understanding isomorphism bias in graph data sets.
arXiv 1910.12091, 2019. URL https://arxiv.org/abs/1910.12091 .
[27] D. Justice and A. Hero. A binary linear programming formulation of the graph edit distance.
IEEE Transactions on Pattern Analysis and Machine Intelligence , 28(8):1200–1214, 2006.
[28] M. G. Kendall. A new measure of rank correlation. Biometrika , 30(1/2):81–93, 1938.
[29] J. Lerouge, Z. Abu-Aisheh, R. Raveaux, P. Héroux, and S. Adam. New binary linear pro-
gramming formulation to compute the graph edit distance. Pattern Recognition , 72:254–
265, 2017. ISSN 0031-3203. doi: https://doi.org/10.1016/j.patcog.2017.07.029. URL
https://www.sciencedirect.com/science/article/pii/S003132031730300X .
[30] Y . Li, D. Tarlow, M. Brockschmidt, and R. Zemel. Gated graph sequence neural networks.
arXiv preprint arXiv:1511.05493 , 2015.
[31] Y . Li, C. Gu, T. Dullien, O. Vinyals, and P. Kohli. Graph matching networks for learning the
similarity of graph structured objects. In International conference on machine learning , pages
3835–3845. PMLR, 2019.
[32] C.-L. Lin. Hardness of approximating graph transformation problem. In D.-Z. Du and X.-S.
Zhang, editors, Algorithms and Computation , pages 74–82, Berlin, Heidelberg, 1994. Springer
Berlin Heidelberg. ISBN 978-3-540-48653-4.
[33] Z. Lou, J. You, C. Wen, A. Canedo, J. Leskovec, et al. Neural subgraph matching. arXiv
preprint arXiv:2007.03092 , 2020.
[34] Y . A. Malkov and D. A. Yashunin. Efficient and robust approximate nearest neighbor search
using hierarchical navigable small world graphs. IEEE transactions on pattern analysis and
machine intelligence , 42(4):824–836, 2018.
12[35] G. Mena, D. Belanger, S. Linderman, and J. Snoek. Learning latent permutations with gumbel-
sinkhorn networks. arXiv preprint arXiv:1802.08665 , 2018. URL https://arxiv.org/pdf/
1802.08665.pdf .
[36] C. Morris, N. M. Kriege, F. Bause, K. Kersting, P. Mutzel, and M. Neumann. Tudataset: A
collection of benchmark datasets for learning with graphs, 2020.
[37] B. Naidan, L. Boytsov, Y . Malkov, and D. Novak. Non-metric space library manual. arXiv
preprint arXiv:1508.05470 , 2015.
[38] E. Ozdemir and C. Gunduz-Demir. A hybrid classification model for digital pathology using
structural and statistical pattern recognition. IEEE Transactions on Medical Imaging , 32(2):
474–483, 2013. doi: 10.1109/TMI.2012.2230186.
[39] C. Qin, H. Zhao, L. Wang, H. Wang, Y . Zhang, and Y . Fu. Slow learning and fast inference:
Efficient graph similarity computation via knowledge distillation. In Thirty-Fifth Conference on
Neural Information Processing Systems , 2021.
[40] R. Ranjan, S. Grover, S. Medya, V . Chakaravarthy, Y . Sabharwal, and S. Ranu. Greed: A neural
framework for learning graph distance functions. Advances in Neural Information Processing
Systems , 35:22518–22530, 2022.
[41] K. Riesen and H. Bunke. Approximate graph edit distance computation by means of bipartite
graph matching. Image and Vision Computing , 27(7):950–959, 2009. ISSN 0262-8856.
doi: https://doi.org/10.1016/j.imavis.2008.04.004. URL https://www.sciencedirect.com/
science/article/pii/S026288560800084X . 7th IAPR-TC15 Workshop on Graph-based
Representations (GbR 2007).
[42] K. Riesen, A. Fischer, and H. Bunke. Combining bipartite graph matching and beam search for
graph edit distance approximation. In Artificial Neural Networks in Pattern Recognition: 6th
IAPR TC 3 International Workshop, ANNPR 2014, Montreal, QC, Canada, October 6-8, 2014.
Proceedings 6 , pages 117–128. Springer, 2014.
[43] I. Roy, S. Chakrabarti, and A. De. Maximum common subgraph guided graph retrieval: late
and early interaction networks. Advances in Neural Information Processing Systems , 35:
32112–32126, 2022.
[44] I. Roy, V . S. Velugoti, S. Chakrabarti, and A. De. Interpretable Neural Subgraph Matching for
Graph Retrieval. AAAI , 2022.
[45] S. Sahni and T. Gonzalez. P-complete approximation problems. J. ACM , 23(3):555–565, jul
1976. ISSN 0004-5411. doi: 10.1145/321958.321975. URL https://doi.org/10.1145/
321958.321975 .
[46] A. Sanfeliu and K.-S. Fu. A distance measure between attributed relational graphs for pattern
recognition. IEEE transactions on systems, man, and cybernetics , pages 353–362, 1983.
[47] A. Sanfeliu, R. Alquézar, J. Andrade, J. Climent, F. Serratosa, and J. Vergés. Graph-based
representations and techniques for image processing and image analysis. Pattern recognition ,
35(3):639–650, 2002.
[48] V . Seguy, B. B. Damodaran, R. Flamary, N. Courty, A. Rolet, and M. Blondel. Large-scale
optimal transport and mapping estimation. arXiv preprint arXiv:1711.02283 , 2017.
[49] K. Shearer, H. Bunke, and S. Venkatesh. Video indexing and similarity retrieval by largest
common subgraph detection using decision trees. Pattern Recognition , 34(5):1075–1091, 2001.
[50] R. Sinkhorn and P. Knopp. Concerning nonnegative matrices and doubly stochastic matrices.
Pacific Journal of Mathematics , 21(2):343–348, 1967.
[51] S. Tirthapura, D. Sharvit, P. Klein, and B. B. Kimia. Indexing based on edit-distance matching
of shape graphs. In Multimedia storage and archiving systems III , volume 3527, pages 25–36.
SPIE, 1998.
13[52] Y . Xie, M. Chen, H. Jiang, T. Zhao, and H. Zha. On scalable and efficient computation of large
scale optimal transport. In International Conference on Machine Learning , pages 6882–6892.
PMLR, 2019.
[53] Z. Zeng, A. K. Tung, J. Wang, J. Feng, and L. Zhou. Comparing stars: On approximating graph
edit distance. Proceedings of the VLDB Endowment , 2(1):25–36, 2009.
[54] Z. Zhang, J. Bu, M. Ester, Z. Li, C. Yao, Z. Yu, and C. Wang. H2mn: Graph similarity
learning with hierarchical hypergraph matching networks. In Proceedings of the 27th ACM
SIGKDD Conference on Knowledge Discovery & Data Mining , KDD ’21, page 2274–2284,
New York, NY , USA, 2021. Association for Computing Machinery. ISBN 9781450383325. doi:
10.1145/3447548.3467328. URL https://doi.org/10.1145/3447548.3467328 .
[55] W. Zheng, L. Zou, X. Lian, D. Wang, and D. Zhao. Efficient graph similarity search over large
graph databases. IEEE Transactions on Knowledge and Data Engineering , 27(4):964–978,
2014.
[56] W. Zhuo and G. Tan. Efficient graph similarity computation with alignment regularization.
Advances in Neural Information Processing Systems , 35:30181–30193, 2022.
14Graph Edit Distance with General Costs
Using Neural Set Divergence
(Appendix)
Contents
A Broader impact 16
B Discussion on our proposed formulation of GED 17
B.1 Modification of scoring function from label substitution . . . . . . . . . . . . . . . 17
B.2 Proof of Proposition 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17
B.3 Connections with other notions of graph matching . . . . . . . . . . . . . . . . . . 18
B.4 Relation between A LIGN DIFFand D IFFALIGN . . . . . . . . . . . . . . . . . . . 18
B.5 Proof that our design ensures conditions of Proposition 1 . . . . . . . . . . . . . . 19
B.6 Alternative surrogate for GED . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19
C Details about experimental setup 21
C.1 Generation of datasets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21
C.2 Details about state-of-the-art baselines . . . . . . . . . . . . . . . . . . . . . . . . 21
C.3 Details about G RAPH EDX . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23
C.4 Evaluation metrics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23
C.5 Hardware and license . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24
D Additional experiments 25
D.1 Comparison of performance of G RAPH EDX on non-uniform cost Edge-GED . . . 25
D.2 Comparison of G RAPH EDX with baselines on uniform and non-uniform cost setting 26
D.3 Comparison of G RAPH EDX with baselines with and without cost features . . . . . 27
D.4 Comparison of G RAPH EDX with baselines with node substitution cost . . . . . . . 28
D.5 Performance evaluation for edge-only vs. all-node-pair representations . . . . . . . 28
D.6 Effect of using cost-guided scoring function on baselines . . . . . . . . . . . . . . 29
D.7 Results on performance of the alternate surrogates for GED . . . . . . . . . . . . . 29
D.8 Comparison of zero-shot performance on other datasets . . . . . . . . . . . . . . . 29
D.9 Importance of node-edge consistency . . . . . . . . . . . . . . . . . . . . . . . . 30
D.10 Comparison of nine possible combinations our proposed set distances . . . . . . . 31
D.11 Comparison of performance of our model with baselines using scatter plot . . . . . 32
D.12 Comparison of performance of our model with baselines using error distribution . . 32
D.13 Comparison of combinatorial optimisation gadgets for GED prediction . . . . . . . 33
D.14 Prediction timing analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34
D.15 Visualization (optimal edit path) + Pseudocode . . . . . . . . . . . . . . . . . . . 34
15A Broader impact
Graphs serve as powerful representations across diverse domains, capturing complex relationships
and structural notions inherent in various systems. From biological networks to social networks,
transportation networks, and supply chains, graphs provide a versatile framework for modeling
interactions between interconnected entities. In domains where structure-similarity based applications
are prevalent, GED emerges as a valuable and versatile tool.
For example, in bio-informatics, molecular structures can naturally be represented as graphs. GED
computation expedites tasks such as drug discovery, protein-protein interaction modeling, and
molecular similarity analysis by identifying structurally similar molecular compounds. Similarly,
in social network analysis, GED can measure similarities between user interactions, aiding in
friend recommendation systems or community detection tasks. In transportation networks, GED-
based tools assess similarity between road networks for route planning or traffic optimizations.
Further applications include learning to edit scene graphs, analyzing gene regulatory pathways, fraud
detection, and more
Moreover, our proposed variations of GED, particularly those amenable to hashing, find utility in
retrieval based setups. In various information retrieval systems, hashed graph representations can be
used to efficiently index and retrieve relevant items using our GED based scores. Such applications
include image retrieval from image databases where images are represented as scene graphs, retrieval
of relevant molecules from molecular databases, etc.
Furthermore, our ability to effectively model different edit costs in GED opens up new possibilities
in various applications. In recommendation systems, it can model user preferences of varying
importance, tailoring recommendations based on user-specific requirements or constraints. Similarly,
in image or video processing, different types of distortions may have varying impacts on perceptual
quality, and GED with adaptive costs can better assess similarity. In NLP tasks such as text similarity
understanding and document clustering, assigning variable costs to textual edits corresponding to
word insertion, deletions or substitutions, provides a more powerful framework for measuring textual
similarity, improving performance in downstream tasks such as plagiarism detection, summarization,
etc.
Lastly, and most importantly, the design of our model encourages interpretable alignment-driven
justifications, thereby promoting transparency and reliability while minimizing potential risks and
negative impacts, in high stake applications like drug discovery.
16B Discussion on our proposed formulation of GED
B.1 Modification of scoring function from label substitution
To incorporate the effect of node substitution into account when formulating the GED, we first
observe that the effect of node substitution cost b∼only comes into account when a non-padded
node maps to a non-padded node. In all other cases, when a node is deleted or inserted, we do not
additionally incur any substitution costs. Note that, we consider the case when node substitution
cannot be replaced by node addition and deletion, i.e.,b∼≤b⊖+b⊕. Such a constraint on costs
has uses in multiple applications [ 9,38]. LetLdenote the set of node labels, and ℓ(u),ℓ′(u′)∈ L
denote the node label corresponding to nodes uandu′inGandG′respectively. We construct the
node label matrix LforGas follows: L∈ {0,1}N×|L|, such that L[i,:] =one_hot (ℓ(i)),i.e.,Lis
the one-hot indicator matrix for the node labels, which each row corresponding to the one-hot vector
of the label. Similarly, we can construct L′forG′. Then, the distance between labels of two nodes
u∈Vandu′∈V′can be given as ∥L[u,:]−L′[u′,:]∥1. To ensure that only valid node to node
mappings contribute to the cost, we multiply the above with Λ(u, u′) =AND (ηG[u],ηG′[u′]). This
allows us to write the expression for GED with node label substitution cost as
GED( G, G′) = min
P∈PNa⊖
2ReLU 
A−PA′P⊤
1,1+a⊕
2ReLU 
PA′P⊤−A
1,1
+b⊖∥ReLU ( ηG−PηG′)∥1+b⊕∥ReLU ( PηG′−ηG)∥1
+b∼X
u,u′Λ(u, u′)∥L[u,:]−L[u′,:]∥1P[u, u′]
| {z }
∆∼(L,L′|P)
We can design a neural surrogate for above in the same way as done in Section 4.2, and write
GED θ,ϕ(G, G′) =a⊖∆⊖(R,R′|S) +a⊕∆⊕(R,R′|S)
+b⊖∆⊖(X,X′|P) +b⊕∆⊕(X,X′|P)
+b∼∆∼(L,L′|P) (17)
In this case, to account for node substitutions in the proposed permutation, we use L[u,:]andL′[u′,:]
as the features for node uinGand node u′inG′, respectively. We present the comparison of our
method including subsitution cost with state-of-the-art baselines in Appendix D.
B.2 Proof of Proposition 1
Proposition Given a fixed set of values of b⊖, b⊕, a⊖, a⊕, letPbe an optimal node permutation
matrix corresponding to GED( G, G′), computed using Eq. (7). Then, P′=P⊤is an optimal node
permutation corresponding to GED( G′, G).
Proof: Noticing that ReLU ( c−d) = max( c, d)−d, we can write
ReLU 
A−PA′P⊤
1,1=max(A,PA′P⊤)−PA′P⊤
1,1
=max(A,PA′P⊤)
1,1−2|E′|
The last equality follows since max(A,PA′P⊤)≥PA′P⊤element-wise, andPA′P⊤
1,1=
∥A′∥1,1= 2|E′|. Similarly, we can rewriteReLU 
PA′P⊤−A
1,1,∥ReLU ( ηG−PηG′)∥1,
and∥ReLU ( PηG′−ηG)∥1, and finally rewrite Eq. (7) as
GED( G, G′) = min
P∈PNa⊕+a⊖
2max(A,PA′P⊤)
1,1−a⊖|E′| −a⊕|E|
+b⊕+b⊖
2∥max(ηG,PηG′)∥1−b⊖|V′| −b⊕|V|(18)
GED( G′, G) = min
P∈PNa⊕+a⊖
2max(A′,PAP⊤)
1,1−a⊖|E| −a⊕|E′|
+b⊕+b⊖
2∥max(ηG′,PηG)∥1−b⊖|V| −b⊕|V′|(19)
17We can rewrite the max term as follows:
max(A,PA′P⊤)
1,1=X
u,vmax(A,PA′P⊤)[u, v]
=X
u,vmax(PP⊤APP⊤,PA′P⊤)[u, v]
=X
u,vPmax(P⊤AP,A′)P⊤[u, v]
=X
u,vmax(P⊤AP,A′)[u, v]
=max(P⊤AP,A′)
1,1=max(A′,P⊤AP)
1,1
Similarly we can re write ∥max(ηG,PηG′)∥1asmax(ηG′,P⊤ηG)
1. Given a fixed set of cost
function b⊖, b⊕, a⊖, a⊕, the terms containing |E′|,|E|,|V′|,|V|are constant and do not affect
choosing an optimal P. LetC=−a⊖|E′| −a⊕|E| −b⊖|V| −b⊕|V′|, Using the above equations,
we can write:
a⊕+a⊖
2max(A,PA′P⊤)
1,1+b⊕+b⊖
2∥max(ηG,PηG′)∥1
=a⊕+a⊖
2max(A′,P⊤AP)
1,1+b⊕+b⊖
2max(ηG′,P⊤ηG)
1
Let the first term be ρ(G, G′|P). Then second term can be expressed as ρ(G′, G|P⊤)and
ρ(G, G′|P) =ρ(G′, G|P⊤)for allP∈PN. IfPis the optimal solution of minP∈PNρ(G, G′|P)
then, ρ(G′, G|P⊤) = ρ(G, G′|P)≤ρ(G, G′|eP⊤) = ρ(G′, G|eP)for any permutation eP.
Hence, P′=P⊤∈PNis one optimal permutation for GED (G′, G).
B.3 Connections with other notions of graph matching
Graph isomorphism: When we set all costs to zero, we can write that GED( G, G′) =
minP0.5A−PA′P⊤
1,1+∥ηG−PηG′∥1. In such a scenario, GED( G, G′)is symmetric,
i.e.,GED( G′, G) = GED( G, G′)and it becomes zero only when GandG′are isomorphic.
Subgraph isomorphism: Assume b⊖=b⊕= 0. Then, if we set the cost of edge addition
to be arbitrarily small as compared to the cost of edge deletion, i.e.,a⊕≪a⊖. This yields
GED( G, G′) = min P(b⊖P
u,vReLU 
A−PA′P⊤
[u, v]), which can be reduced to zero for
some permutation P,G⊆G′.
Maximum common edge subgraph: From Appendix B.2, we can write that GED( G, G′) =
minP0.5(a⊕+a⊖)max(A,PA′P⊤)
1,1+ 0.5(b⊕+b⊖)∥max{ηG,PηG′}∥1−a⊖|E′| −
a⊕|E| −b⊖|V′| −b⊕|V|. When a⊖=a⊕= 1 andb⊕=b⊖= 0, then GED( G, G′) =max(A,PA′P⊤)
1,1=|E|+|E′| −min(A,PA′P⊤)
1,1. Here, min(A,PA′P⊤)char-
acterizes maximum common edge subgraph andmin(A,PA′P⊤)
1,1provides the number of
edges of it.
B.4 Relation between A LIGN DIFFand D IFFALIGN
Lemma 2 LetZ,Z′∈RN×M, andS∈RN×N
≥0be double stochastic. Then,
∥ReLU ( Z−SZ′)∥1,1≤X
i,j∥ReLU ( Z[i,:]−Z′[j,:])∥1S[i, j]
18Proof: We can write,
∥ReLU ( Z−SZ′)∥1,1=X
i,jReLU
Z[i, j]−X
kS[i, k]Z′[k, j]
(∗)=X
i,jReLUX
kS[i, k]Z[i, j]−S[i, k]Z′[k, j]
(∗∗)
≤X
i,jX
kS[i, k]ReLU ( Z[i, j]−Z′[k, j])
=X
i,k∥ReLU ( Z[i,:]−Z′[k,:])∥1S[i, k] □
where (∗)follows sinceP
kS[i, k] = 1∀i∈[N], and (∗∗)follows due to convexity of ReLU () .
Now, notice that when S∈PN, thenS[i,:]is 1 at one element while 0 at the rest. In that case, we
haveX
i,jReLUX
kS[i, k]Z[i, j]−S[i, k]Z′[k, j]
=X
i,jReLU ( Z[i, j]−Z′[k∗
i, j])
=X
i,jX
kS[i, k]ReLU ( Z[i, j]−Z′[k, j])
where k∗
iis the index where S[i,:]is 1. Hence, we have an equality when Sis a hard permuta-
tion. Replacing (Z,Z′)with(R,R′)and(X,X′), we get that ALIGN DIFFandDIFFALIGN are
equivalent when Sis a hard permutation matrix, and moreover DIFFALIGN is an upper bound on
ALIGN DIFFwhenSis a soft permutation matrix.
B.5 Proof that our design ensures conditions of Proposition 1
Here we show why it is necessary to have a symmetric form for C[u, u′]in P ERM NETϕ.
ForGED( G, G′),
C[u, v] =∥cϕ(xK(u))−cϕ(x′
K(v))∥1
ForGED( G′, G),
C′[v, u] =∥cϕ(x′
K(v))−cϕ(xK(u))∥1
Because the Sinkhorn cost C[u, v]is symmetric, using the above equations we can infer,
C[u, v] =C′[v, u],which implies C′=C⊤
This leads to P′=P⊤. If we use an asymmetric Sinkhorn cost ( C[u, v] =
∥ReLU ( cϕ(xK(u))−cϕ(x′
K(v)))∥1), we cannot ensure C[u, v] =C′[v, u], which fails to sat-
isfyP=P⊤.
B.6 Alternative surrogate for GED
From Appendix B.2, we have
GED( G, G′) = min
P∈PNa⊕+a⊖
2max(A,PA′P⊤)
1,1−a⊖|E′| −a⊕|E|
+b⊕+b⊖
2∥max(ηG,PηG′)∥1−b⊖|V′| −b⊕|V|
Following the relaxations done in Section 4.2, we propose an alternative neural surrogate by replacingmax(A,PA′P⊤)
1,1by∥max(R,SR′)∥1,1and∥max(ηG,PηG′)∥1by∥max(X,PX′)∥1,1,
which gives us the approximated GED parameterized by θandϕas
GED θ,ϕ(G, G′) =a⊕+a⊖
2∥max(R,SR′)∥1,1−a⊖|E′| −a⊕|E|
+b⊕+b⊖
2∥max(X,PX′)∥1,1−b⊖|V′| −b⊕|V|(20)
We call this neural surrogate as MAX. We note that element-wise maximum over AandPA′P⊤,
only allows non-edge to non-edge mapping attribute a value of zero. However, the neural surrogate
described in Equation 20 fails to capture this, due to the presence of the soft alignment matrix S.
To address this, we explicitly discard such pairs from MAX by applying an OR operator over the
edge presence between concerned node pairs, derived from the adjacency matrices AandA′and
19populated in OR(A,A′)∈R(N
2)×(N
2)given by OR(A[u, v],A′[u′, v′]). Similarly, the indication of
node presence can be given be given as OR(ηG,ηG′)[u, u′] =OR(ηG[u],ηG′[u′]). Hence, we write
GED θ,ϕ(G, G′) =a⊕+a⊖
2∥OR(A,A′)⊙max(R,SR′)∥1,1−a⊖|E′| −a⊕|E|
+b⊕+b⊖
2∥OR(ηG,ηG′)⊙max(X,PX′)∥1,1−b⊖|V′| −b⊕|V|
(21)
We call this formulation as MAX-OR. We provide the comparison between MAX, MAX-OR, and
our models in Appendix D.
20C Details about experimental setup
C.1 Generation of datasets
We have evaluated the performance of our methods and baselines on seven real-world datasets:
Mutagenicity (Mutag), Ogbg-Code2 (Code2), Ogbg-Molhiv (Molhiv), Ogbg-Molpcba (Molpcba),
AIDS, Linux and Yeast. We split each dataset into training, validation, and test splits in ratio of
60:20:20. For each split D, we construct (|D|(|D|+ 1)) /2source and target graph instance pairs as
follows: S={(Gi, Gj) :Gi, Gj∈ D ∧ i≤j}. We perform experiment in four GED regimes:
1.GED under uniform cost functions, where b⊖=b⊕=a⊖=a⊕= 1and substitution costs are 0
2.GED under non-uniform cost functions, where b⊖= 3, b⊕= 1, a⊖= 2, a⊕= 1and substitution
costs are 0
3.edge GED under non-uniform cost functions, where b⊖=b⊕= 0,a⊖= 2, a⊕= 1, and
substitution costs are 0
4.GED with node substitution under uniform cost functions, where b⊖=b⊕=a⊖=a⊕= 1, as
well as the node substitution cost b∼= 1.
We emphasize that we generated clean datasets by filtering out isomorphic graphs from the original
datasets before performing the training, validation, and test splits. This step is crucial to prevent
isomorphism bias in the models, which can occur due to leakage between the training and testing
splits, as highlighted by [26].
For each graph, we have limited the maximum number of nodes to twenty, except for Linux, where the
limit is ten. Information about the datasets is summarized in Table 7. Mutag contains nitroaromatic
compounds, with each node having labels representing atom types. Molhiv and Molpcba contain
molecules with node features representing atomic number, chirality, and other atomic properties.
Code2 contains abstract syntax trees generated from Python codes. AIDS contains graphs of chemical
compounds, with node types representing different atoms. For Molhiv, Molpcba and Linux, we have
randomly sampled 1,000 graphs from each original dataset.
#Graphs # Train Pairs # Val Pairs # Test Pairs Avg. |V|Avg.|E|Avg. GED
uniform costAvg. GED
non-uniform
cost Mutag 729 95703 10585 10878 16.01 15.76 11.15 18.57
Code2 128 2926 325 378 18.77 17.77 10.02 16.43
Molhiv 1000 180300 20100 20100 15.01 15.65 11.77 19.86
Molpcba 1000 180300 20100 20100 17.52 18.67 9.58 15.73
AIDS 911 149331 16653 16836 10.97 10.97 7.38 12.07
Yeast 1000 180300 20100 20100 16.59 17.04 10.65 17.74
Linux 89 1431 153 190 8.71 8.35 4.91 7.94
Table 7: Salient characteristics of data sets.
C.2 Details about state-of-the-art baselines
We compared our model against nine state-of-the-art neural baselines and three combinatorial GED
baselines. Below, we provide details of the methodology and hyperparameter settings used for each
baseline. We ensured that the number of model parameters were in a comparable range. Specifically,
we set the number of GNN layers to 5, each with a node embedding dimension of 10, to ensure
consistency and comparability with our model. The following hyperparameters are used for training:
Adam optimiser with a learning rate of 0.001 and weight decay of 0.0005, batch size of 256, early
stopping with patience of 100 epochs, and Sinkhorn temperature set to 0.01. Neural Baselines:
•GMN-Match and GMN-Embed Graph Matching Networks (GMN) use Euclidean distance to
assess the similarity between graph-level embeddings of each graph. GMN is available in two
variants: GMN-Embed, a late interaction model, and GMN-Match, an early interaction model. For
this study, we used the official implementation of GMN to compute Graph Edit Distance (GED).1
•ISONET ISONET utilizes the Gumbel-Sinkhorn operator to learn asymmetric edge alignments
between two graphs for subgraph matching. In our study, we extend ISONET’s approach to predict
the Graph Edit Distance (GED) score. We utilized the official PyTorch implementation provided
by the authors for our experiments.2
1https://github.com/Lin-Yijie/Graph-Matching-Networks/tree/main
2https://github.com/Indradyumna/ISONET
21•GREED GREED utilizes a siamese network architecture to compute graph-level embeddings in
parallel for two graphs. It calculates the Graph Edit Distance (GED) score by computing the norm
of the difference between these embeddings. The official implementation provided by the authors
was used for our experiments.3
•ERIC ERIC utilizes a regularizer to learn node alignment, eliminating the need for an explicit node
alignment module. The similarity score is computed using a Neural Tensor Network (NTN) and a
Multi-Layer Perceptron (MLP) applied to the final graph-level embeddings of both graphs. These
embeddings are derived by concatenating graph-level embeddings from each layer of a Graph
Isomorphism Network (GIN). The model is trained using a combined loss from the regularizer and
the predicted similarity score. For our experiments, we used the official PyTorch implementation
to compute the Graph Edit Distance (GED). The GED scores were inverse normalized from the
model output to predict the absolute GED.4
•SimGNN SimGNN leverages both graph-level and node-level embeddings at each layer of the
GNN. The graph-level embeddings are processed through a Neural Tensor Network to obtain a
pair-level embedding. Concurrently, the node-level embeddings are used to compute a pairwise
similarity matrix between nodes, which is then converted into a histogram feature vector. A
similarity score is calculated by passing the concatenation of these embeddings through a Multi-
Layer Perceptron (MLP). We used the official PyTorch implementation of SimGNN and inverse
normalization of the predicted Graph Edit Distance (GED) score to obtain the absolute GED value.5
•H2MN H2MN presents an early interaction model for graph similarity tasks. Instead of learning
pairwise node relations, this method attempts to find higher-order node similarity using hypergraphs.
At each time step of the hypergraph convolution, a subgraph matching module is employed to learn
cross-graph similarity. After the convolution layers, a readout function is utilized to obtain graph-
level embeddings. These embeddings are then concatenated and passed through a Multi-Layer
Perceptron (MLP) to compute the similarity score. We used the official PyTorch implementation of
H2MN.6
•GraphSim GraphSim uses GNN, where at each layer, a node-to-node similarity matrix is computed
using the node embeddings. These similarity matrices are then processed using Convolutional
Neural Networks (CNNs) and Multi-Layer Perceptrons (MLPs) to calculate a similarity score. We
utilized the official PyTorch implementation.7
•EGSC We used the Teacher model proposed by Efficient Graph Similarity Computation (EGSC),
which leverages an Embedding Fusion Network (EFN) at each layer of the Graph Isomorphism
Network (GIN). The EFN generates a single embedding from a pair of graph embeddings. The
embeddings of the graph pair from each layer are concatenated and subsequently passed through
an additional EFN layer and a Multi-Layer Perceptron (MLP) to obtain the similarity score. To
predict the absolute Graph Edit Distance (GED), we inversely normalized the GED score obtained
from the output of EGSC. We utilized the official PyTorch implementation provided by the authors
for our experiments.8
Combinatorial Baselines: We use the GEDLIB9library for implementation of all combinatorial
baselines.
•Bipartite [41] Bipartite is an approximate algorithm that considers nodes and surrounding edges
of nodes into account try to make a bipartite matching between two graphs. They use linear
assignment algorithms to match nodes and their surroundings in two graphs.
•Branch [ 8], Branch Tight [ 8]improve upon [ 41] by decomposing graphs into branches. Branch
Tight algorithm is another version of Branch that calculates a tighter lower bound but has a higher
time complexity than Branch.
•Anchor Aware GED Chang et al. [15] provides an approximation algorithm that calculates a
tighter lower bound using the anchor aware technique.
3https://github.com/idea-iitd/greed
4https://github.com/JhuoW/ERIC
5https://github.com/benedekrozemberczki/SimGNN
6https://github.com/cszhangzhen/H2MN
7https://github.com/yunshengb/GraphSim
8https://github.com/canqin001/Efficient_Graph_Similarity_Computation
9https://github.com/dbblumenthal/gedlib
22•IPFP [11] is an approximation algorithm which handles node and edge mapping simultaneously
unlike previously discussed methods. This solves a quadratic assignment problem on edges and
nodes.
•F2[29] uses a binary linear programming approach to find a higher lower bound on GED calculation.
This method was used with a very high time limit to generate Ground truth for our experiments.
C.3 Details about G RAPH EDX
At the high level, G RAPH EDX consists of two components E MBED θand P ERM NETϕ.
Neural Parameterization of EMBED θ:EMBED θconsists of two modules: a GNN denoted as
MPNN θand a MLP θ. The MPNN θconsists of K= 5propagation layers used to compute node
embeddings of dimension d= 10 . At each layer k, we compute the updated the node embedding as
follows:
xk+1(u) =UPDATE θ
xk(u),X
v∈nbr(u)LRL θ(xk(u),xk(v))
 (22)
where LRL θis a Linear-ReLU-Linear network, with d= 10 features, and the UPDATE θnetwork
consists of a Gated Recurrent Unit [ 30]. In case of GED setting under uniform cost and GED
setting under non-uniform cost, we set the initial node features x0(u) = 1 , following [ 30]. However,
in case of computation of GED with node substitution costs, we explicitly provide the one-hot
labels as node features. Given the node embeddings and edge-presence indicator obtained from the
adjacency matrices, after 5layer propogations, we compute the edge embeddings r(e)using MLP θ,
which is decoupled from MPNN θ.MLP θconsists of a Linear-ReLU-Linear network that maps
the2d+ 1 = 21 dimensional input consisting of forward (xK(u)||xK(v)||A[u, v])and backward
(xK(v)||xK(u)||A[v, u])signals to D= 20 dimensions.
Neural Parameterization of PERM NETϕ:Given the node embeddings xK(·)andx′
K(·), we first
pass them through a neural network cϕwhich consists of a Linear-ReLU-Linear network transforming
the features from d= 10 toNdimensions, which is the number of nodes after padding. Except
for Linux where N= 10 , all other datasets have N= 20 . We obtain the matrix Csuch that
C[u, u′] =∥cϕ(xK(u))−cϕ(x′
K(u′))∥1. Using temperature τ= 0.01, we perform Sinkhorn
iterations on exp(−C/τ)as follows for T= 20 iterations to get P:
Pk=NORM COL(NORM ROW(Pk−1))
where P0= exp( −C/τ). Here NORM ROW(M)[i, j] =M[i, j]/P
ℓM[ℓ, j]denotes the row
normalization function and NORM COL(M)[i, j] =M[i, j]/P
ℓM[i, ℓ]denotes the column nor-
malization function. We note that the soft alignment Pobtained does not depend on the GED
cost values, as discussed in Appendix B. The soft alignment Pfor nodes is used to construct soft
alignment Sfor as follows: S[(u, v),(u′, v′)] =P[u, u′]P[v, v′] +P[u, v′]P[v, u′].
C.4 Evaluation metrics
Given the dataset Sconsisting of input pairs of graphs (G, G′)along with the ground truth
GED(G, G′)and model prediction [GED(G, G′), we evaluate the performance of the model us-
ing the Root Mean Square Error (RMSE) and Kendall-Tau (KTau) [28] between the predicted GED
scores and actual GED values.
•MSE: It evaluates how far the predicted GED values are from the ground truth. A better performing
model is indicated by a lower MSE value.
MSE =1
|S|X
(G,G′)∈S
GED(G, G′)−[GED(G, G′)2
(23)
•KTau: Selection of relevant corpus graphs via graph similarity scoring is crucial to graph retrieval
setups. In this context, we would like the number of concordant pairs N+(where the ranking of
ground truth GED and model prediction agree) to be high, and the discordant pairs N−(where the
two disagree) to be low. Formally, we write
KTau =N+−N− |S|
2 (24)
23For the methods which compute a similarity score between the pair of graphs through the notion of
normalized GED, we map the similarity score sback to the GED as [GED(G, G′) =−|V|+|V|′
2log(s+
ϵ)where ϵ= 10−7is added for stability of the logarithm.
C.5 Hardware and license
We implement our models using Python 3.11.2 and PyTorch 2.0.0. The training of our models and
the baselines was performed across servers containing Intel Xeon Silver 4216 2.10GHz CPUs, and
Nvidia RTX A6000 GPUs. Running times of all methods are compared on the same GPU.
24D Additional experiments
In this section, we present results from various additional experiments performed to measure the
performance of our model under different cost settings.
D.1 Comparison of performance of G RAPH EDX on non-uniform cost Edge-GED
We consider another cost setting – where the node costs are explicitly set to 0, and a⊕= 1, a⊖= 2.
In such a case, GRAPH EDXonly consists of ∆⊖(R,R′|S)and∆⊕(R,R′|S)terms. To showcase
the importance of aligning edges through edge alignment, we generate an alternate model, where the
alignment happens through the terms ∆⊖(X,X′|P)and∆⊕(X,X′|P), where we set b⊕= 1
andb⊖= 2, and set the edge costs to 0. We call this model NodeSwap (w/o XOR), and the
corresponding XOR variant as NodeSwap + XOR. In Table 8, we compare the performance variants
ofGRAPH EDXwith NodeSwap (w/o XOR) and the rest of the baselines to predict the Edge GED
score in an non-uniform cost setting. From the results, we can infer that the performance of edge-
alignment based model to predict Edge-GED outperforms the corresponding node-alignment version.
MSE±STD KTau
Mutag Molhiv Linux Mutag Molhiv Linux
GMN-Match 11.276 ±0.143 13.586 ±0.171 4.893 ±0.527 0.600 0.562 0.453
GMN-Embed 13.627 ±0.179 16.482 ±0.188 4.363 ±0.420 0.556 0.529 0.484
ISONET 1.468±0.020 2.142 ±0.023 1.930 ±0.186 0.846 0.802 0.659
GREED 11.906 ±0.148 13.723 ±0.136 3.847 ±0.397 0.588 0.558 0.512
ERIC 1.900±0.028 2.154 ±0.024 3.361 ±0.353 0.823 0.805 0.510
SimGNN 3.138±0.052 3.771 ±0.046 5.089 ±0.524 0.784 0.736 0.410
H2MN 3.771±0.062 3.735 ±0.047 5.443 ±0.566 0.748 0.741 0.358
GraphSim 4.696±0.076 5.200 ±0.074 6.597 ±0.697 0.720 0.694 0.316
EGSC 1.871±0.028 2.187 ±0.025 2.803 ±0.260 0.823 0.797 0.608
NodeSwap (w/o XOR) 1.246±0.017 1.858 ±0.019 0.997 ±0.124 0.857 0.814 0.757
NodeSwap + XOR 11.984 ±0.227 11.158 ±0.196 10.959 ±1.116 0.586 0.604 0.321
GRAPH EDX (w/o XOR) 1.174±0.016 1.842±0.019 0.976±0.115 0.863 0.815 0.764
GRAPH EDX + XOR 1.125±0.016 1.855±0.020 0.922±0.108 0.866 0.817 0.780
Table 8: Comparison of edge-alignment based GED scoring function with node-alignment based GED
scoring function and state-of-the-art baselines under the cost setting: a⊖= 2, a⊕= 1, b⊖=b⊕= 0.
In case of NodeSwap (w/o XOR), we swap the edge costs and node costs, and expect the model to
learn the alignments in Edge GED through node alignment only. Green (yellow ) numbers report the
best (second best) performers.
25D.2 Comparison of G RAPH EDX with baselines on uniform and non-uniform cost setting
Tables 9 and 10 report performance in terms of MSE under uniform and non-uniform cost settings,
respectively. Table 11 reports performance in terms of KTau under both uniform and non-uniform
cost settings. The results are similar to those in Table 3, where our model is the clear winner across
all datasets, outperforming the second-best performer by a significant margin. There is no consistent
second-best model, but ERIC, EGSC, and ISONET perform comparably and better than the others.
Mutag Code2 Molhiv Molpcba AIDS Linux Yeast
GMN-Match 0.797±0.013 1.677 ±0.187 1.318 ±0.020 1.073 ±0.011 0.821 ±0.010 0.687±0.088 1.175 ±0.013
GMN-Embed 1.032±0.016 1.358 ±0.104 1.859 ±0.020 1.951 ±0.020 1.044 ±0.013 0.736 ±0.102 1.767 ±0.021
ISONET 1.187±0.021 0.879±0.061 1.354 ±0.015 1.106 ±0.011 1.640 ±0.020 1.185 ±0.115 1.578 ±0.019
GREED 1.398±0.033 1.869 ±0.140 1.708 ±0.019 1.550 ±0.017 1.004 ±0.012 1.331 ±0.169 1.423 ±0.015
ERIC 0.719±0.011 1.363 ±0.110 1.165 ±0.018 0.862±0.009 0.731 ±0.008 1.664 ±0.260 0.969 ±0.010
SimGNN 1.471±0.024 2.667 ±0.215 1.609 ±0.020 1.456 ±0.020 1.455 ±0.020 7.232 ±0.762 1.999 ±0.043
H2MN 1.278±0.021 7.240 ±0.527 1.521 ±0.020 1.402 ±0.020 1.114 ±0.015 2.238 ±0.247 1.353 ±0.018
GraphSim 2.005±0.031 3.139 ±0.206 2.577 ±0.064 1.656 ±0.023 1.936 ±0.026 2.900 ±0.318 2.232 ±0.030
EGSC 0.765±0.011 4.165 ±0.285 1.138±0.016 0.938 ±0.010 0.627±0.007 2.411 ±0.325 0.950±0.010
GRAPH EDX 0.492±0.007 0.429±0.036 0.781±0.008 0.764±0.007 0.565±0.006 0.354±0.043 0.717±0.007
Table 9: Comparison with baselines in terms of MSE including standard error for uniform cost setting
(b⊖=b⊕=a⊖=a⊕= 1).Green (yellow ) numbers report the best (second best) performers.
Mutag Code2 Molhiv Molpcba AIDS Linux Yeast
GMN-Match 69.210 ±0.883 13.472 ±0.970 76.923 ±0.862 23.985 ±0.224 31.522 ±0.513 21.519 ±2.256 63.179 ±1.127
GMN-Embed 72.495 ±0.915 13.425 ±1.035 78.254 ±0.865 28.437 ±0.268 33.221 ±0.523 20.591 ±2.136 60.949 ±0.663
ISONET 3.369±0.062 3.025±0.206 3.451 ±0.039 2.781 ±0.029 5.513 ±0.092 3.031±0.299 4.555 ±0.061
GREED 68.732 ±0.867 11.095 ±0.773 78.300 ±0.795 26.057 ±0.238 34.354 ±0.557 20.667 ±2.140 60.652 ±0.704
ERIC 1.981±0.032 12.767 ±1.177 3.377 ±0.070 2.057±0.020 1.581±0.017 7.809 ±0.911 2.341 ±0.030
SimGNN 4.747±0.079 5.212 ±0.360 4.145 ±0.051 3.465 ±0.047 4.316 ±0.071 5.369 ±0.546 4.496 ±0.060
H2MN 3.413±0.053 9.435 ±0.728 3.782 ±0.046 3.396 ±0.046 3.105 ±0.043 5.848 ±0.611 3.678 ±0.046
GraphSim 5.370±0.092 7.405 ±0.577 6.643 ±0.181 3.928 ±0.053 5.266 ±0.081 6.815 ±0.628 6.907 ±0.137
EGSC 1.758±0.026 3.957 ±0.365 2.371±0.025 2.133 ±0.022 1.693 ±0.023 5.503 ±0.496 2.157±0.027
GRAPH EDX 1.134±0.016 1.478±0.118 1.804±0.019 1.677±0.016 1.252±0.014 0.914±0.110 1.603±0.016
Table 10: Comparison with baselines in terms of MSE including standard error for non-uniform cost
setting ( b⊖= 3, b⊕= 1, a⊖= 2, a⊕= 1).Green (yellow ) numbers report the best (second best)
performers.
GED with uniform cost non-uniform cost
Mutag Code2 Molhiv Molpcba AIDS Linux Yeast Mutag Code2 Molhiv Molpcba AIDS Linux Yeast
GMN-Match 0.901 0.876 0.887 0.797 0.824 0.826 0.852 0.606 0.781 0.619 0.596 0.611 0.438 0.610
GMN-Embed 0.887 0.892 0.856 0.723 0.796 0.815 0.815 0.603 0.790 0.607 0.534 0.601 0.531 0.573
ISONET 0.885 0.918 0.878 0.793 0.756 0.786 0.827 0.887 0.908 0.875 0.817 0.755 0.776 0.834
GREED 0.873 0.878 0.859 0.757 0.807 0.756 0.832 0.614 0.812 0.598 0.547 0.596 0.522 0.582
ERIC 0.909 0.892 0.897 0.820 0.837 0.736 0.868 0.620 0.804 0.895 0.841 0.855 0.633 0.886
SimGNN 0.871 0.856 0.877 0.776 0.775 0.377 0.834 0.862 0.874 0.872 0.804 0.768 0.731 0.843
H2MN 0.878 0.711 0.879 0.781 0.794 0.664 0.848 0.873 0.813 0.875 0.804 0.792 0.681 0.851
GraphSim 0.847 0.839 0.856 0.756 0.730 0.601 0.810 0.851 0.844 0.851 0.784 0.744 0.656 0.824
EGSC 0.906 0.815 0.896 0.809 0.850 0.664 0.868 0.912 0.894 0.900 0.836 0.858 0.696 0.884
GRAPH EDX 0.926 0.937 0.910 0.831 0.857 0.882 0.886 0.929 0.932 0.912 0.858 0.871 0.875 0.898
Table 11: Comparison with baselines in terms of KTau for both uniform and non-uniform cost
settings, where for uniform cost settings costs are b⊖=b⊕=a⊖=a⊕= 1and for non-uniform
cost settings costs are b⊖= 3, b⊕= 1, a⊖= 2, a⊕= 1.Green (yellow ) numbers report the best
(second best) performers.
26D.3 Comparison of G RAPH EDX with baselines with and without cost features
Table 12 reports performance in terms of MSE under non-uniform cost setting, with and without costs
used as features to the baselines. We notice that that in some cases, providing cost features boost
the performance of baselines significantly, and in a few cases, withholding the costs gives a slight
improvement in performance. However, GRAPH EDX, which uses costs in the distance formulation
rather than features, outperforms all baselines by a significant margin.
Cost used as
featuresMutag Code2 Molhiv Molpcba AIDS Linux Yeast
GMN-Match69.210 13.472 76.923 23.985 31.522 21.519 63.179
68.635 12.769 84.113 24.471 31.636 20.255 62.715
GMN-Embed72.495 13.425 78.254 28.437 33.221 20.591 60.949
87.581 18.189 80.797 30.276 34.752 20.227 59.941
ISONET3.369 3.025 3.451 2.781 5.513 3.031 4.555
3.850 1.780 3.507 2.906 5.865 2.771 4.861
GREED68.732 11.095 78.300 26.057 34.354 20.667 60.652
78.878 12.774 78.837 26.188 32.318 23.478 55.985
ERIC1.981 12.767 3.377 2.057 1.581 7.809 2.341
1.912 12.391 2.588 2.220 1.536 11.186 2.161
SimGNN4.747 5.212 4.145 3.465 4.316 5.369 4.496
2.991 8.923 4.062 3.397 3.470 6.623 4.289
H2MN3.413 9.435 3.782 3.396 3.105 5.848 3.678
3.287 14.892 3.611 3.377 3.064 5.576 3.776
GraphSim5.370 7.405 6.643 3.928 5.266 6.815 6.907
4.886 10.257 6.394 3.921 5.538 6.439 6.033
EGSC1.758 3.957 2.371 2.133 1.693 5.503 2.157
1.769 4.395 2.510 2.217 1.432 4.664 2.305
GRAPH EDX 1.134 1.478 1.804 1.677 1.252 0.914 1.603
Table 12: Comparison of performance (MSE) of methods for the non-uniform cost setting when
nodes are initialized with costs as features versus without. For each method, the better performance
between with and without cost-feature initialization is highlighted in bold for both uniform and
non-uniform cost settings. In each column, Green (yellow ) numbers report the best (second best)
performers.
27D.4 Comparison of G RAPH EDX with baselines with node substitution cost
In Tables 13 and 14, we compare the performance of GRAPH EDXwith baselines under a node
substitution cost b∼. The cost setting is b⊖=b⊕=b∼=a⊖=a⊕= 1. This experiment includes
only five datasets where node labels are present. We observe that GRAPH EDXoutperforms all other
baselines. There is no clear second-best model, but ERIC, EGSC, and ISONET perform better than
the others.
Mutag Code2 Molhiv Molpcba AIDS
GMN-Match 1.057±0.011 5.224 ±0.404 1.388 ±0.018 1.432 ±0.017 0.868±0.007
GMN-Embed 2.159±0.026 4.070 ±0.318 3.523 ±0.040 4.657 ±0.054 1.818 ±0.014
ISONET 0.876±0.008 1.129±0.084 1.617 ±0.020 1.332 ±0.014 1.142 ±0.010
GREED 2.876±0.032 4.983 ±0.531 2.923 ±0.033 3.902 ±0.044 2.175 ±0.016
ERIC 0.886±0.009 6.323 ±0.683 1.537 ±0.018 1.278±0.014 1.602 ±0.036
SimGNN 1.160±0.013 5.909 ±0.490 1.888 ±0.031 2.172 ±0.050 1.418 ±0.020
H2MN 1.277±0.014 6.783 ±0.587 1.891 ±0.024 1.666 ±0.021 1.290 ±0.011
GraphSim 1.043±0.010 4.708 ±0.425 1.817 ±0.021 1.748 ±0.021 1.561 ±0.021
EGSC 0.776±0.008 8.742 ±0.831 1.273±0.016 1.426 ±0.018 1.270 ±0.028
GRAPH EDX 0.441±0.004 0.820±0.092 0.792±0.009 0.846±0.009 0.538±0.003
Table 13: Comparison with baselines in terms of MSE including standard error, in presence of the
node substitution cost, which set to one in uniform cost setting: b⊖=b⊕=b∼=a⊖=a⊕= 1.
Green (yellow ) numbers report the best (second best) performers.
Mutag Code2 Molhiv Molpcba AIDS
GMN-Match 0.895 0.811 0.881 0.809 0.839
GMN-Embed 0.847 0.845 0.796 0.684 0.767
ISONET 0.906 0.925 0.868 0.815 0.812
GREED 0.827 0.829 0.822 0.710 0.746
ERIC 0.905 0.847 0.872 0.818 0.815
SimGNN 0.891 0.836 0.864 0.797 0.810
H2MN 0.886 0.818 0.858 0.789 0.802
GraphSim 0.896 0.846 0.860 0.782 0.795
EGSC 0.912 0.802 0.885 0.821 0.832
GRAPH EDX 0.936 0.945 0.913 0.856 0.874
Table 14: Comparison with baselines in terms of KTau, in presence of the node substitution cost,
which set to one in uniform cost setting: b⊖=b⊕=b∼=a⊖=a⊕= 1.Green (yellow ) numbers
report the best (second best) performers.
D.5 Performance evaluation for edge-only vs. all-node-pair representations
In this section, we compare the performance of using graph representation with two variants of our
method. (i) Edge-only (edge→edge): Here, R,R′∈Rmax(|E|,|E′|)×Dare computed using only
the embeddings of node-pairs that are edges, and excluding non-edges. This means that Sbecomes
an edge-to-edge alignment matrix instead of a full node-pair alignment matrix. (ii) Edge-only
(pair→pair): In this variant, Sremains a node-pair alignment matrix, but the embeddings of the
non-edges in R,R′∈RN(N−1)/2×Dare explicitly set to zero. Tables 15 and 16 contain extended
results from Table 6 across seven datasets. The results are similar to those discussed in the main paper:
(1) both these sparse representations perform significantly worse compared to our method using
non-trivial representations for both edges and non-edges, and (2) Edge-only (edge→edge)performs
better than Edge-only (pair→pair). This underscores the importance of explicitly modeling trainable
non-edge embeddings to capture the sensitivity of GED to global graph structure.
Mutag Code2 Molhiv Molpcba AIDS Linux Yeast
Edge-only (edge→edge) 0.566±0.008 0.683±0.051 0.858±0.009 0.791±0.008 0.598±0.006 0.454±0.063 0.749±0.007
Edge-only (pair→pair) 0.596±0.008 0.760 ±0.058 0.862 ±0.009 0.811 ±0.008 0.606 ±0.006 0.474 ±0.056 0.761 ±0.008
GRAPH EDX 0.492±0.007 0.429±0.036 0.781±0.008 0.764±0.007 0.565±0.006 0.354±0.043 0.717±0.007
Table 15: Comparison of using all-node-pairs against edge-only representations using MSE for
uniform cost setting. Green (yellow ) numbers report the best (second best) performers.
28Mutag Code2 Molhiv Molpcba AIDS Linux Yeast
Edge-only (edge→edge) 1.274±0.017 1.817±0.141 1.847±0.019 1.793 ±0.017 1.318±0.014 0.907±0.129 1.649±0.016
Edge-only (pair→pair) 1.276±0.017 1.879 ±0.136 1.865 ±0.020 1.779±0.017 1.422 ±0.015 0.992 ±0.114 1.694 ±0.017
GRAPH EDX 1.134±0.016 1.478±0.118 1.804±0.019 1.677±0.016 1.252±0.014 0.914±0.110 1.603±0.016
Table 16: Comparison of using all-node-pairs against edge-only representations using MSE for
non-uniform cost setting. Green (yellow ) numbers report the best (second best) performers.
D.6 Effect of using cost-guided scoring function on baselines
In Tables 17 and 18, we report the impact of replacing the baselines’ scoring function with our
proposed cost-guided scoring function on three baselines across seven datasets for uniform and
non-uniform cost settings, respectively. We notice that similar to the results reported in Section 5.2,
the cost-guided scoring function helps the baselines perform significantly better in both the cost
settings.
Mutag Code2 Molhiv Molpcba AIDS Linux Yeast
GMN-Match 0.797±0.013 1.677 ±0.187 1.318 ±0.020 1.073 ±0.011 0.821 ±0.010 0.687 ±0.088 1.175 ±0.013
GMN-Match * 0.654±0.011 0.960 ±0.092 1.008 ±0.011 0.858 ±0.009 0.601 ±0.007 0.590 ±0.084 0.849 ±0.009
GMN-Embed 1.032±0.016 1.358 ±0.104 1.859 ±0.020 1.951 ±0.020 1.044 ±0.013 0.736 ±0.102 1.767 ±0.021
GMN-Embed * 1.011±0.017 1.179 ±0.098 1.409 ±0.015 1.881 ±0.019 0.849 ±0.010 0.577 ±0.094 1.600 ±0.017
GREED 1.398±0.033 1.869±0.140 1.708 ±0.019 1.550±0.017 1.004 ±0.012 1.331±0.169 1.423±0.015
GREED * 2.133±0.037 1.850±0.156 1.644 ±0.019 1.623±0.017 1.143 ±0.015 1.297±0.151 1.440±0.016
GRAPH EDX 0.492±0.007 0.429±0.036 0.781±0.008 0.764±0.007 0.565±0.006 0.354±0.043 0.717±0.007
Table 17: Impact of cost-guided distance on MSE in uniform cost setting ( b⊖=b⊕=a⊖=a⊕= 1).
* represents the variant of the baseline with cost-guided distance. Green shows the best performing
model. Bold font indicates the best variant of the baseline.
Mutag Code2 Molhiv Molpcba AIDS Linux Yeast
GMN-Match 69.210 ±0.883 13.472 ±0.970 76.923 ±0.862 23.985 ±0.224 31.522 ±0.513 21.519 ±2.256 63.179 ±1.127
GMN-Match * 1.592±0.027 2.906 ±0.285 2.162 ±0.024 1.986 ±0.021 1.434 ±0.017 1.596 ±0.211 2.036 ±0.022
GMN-Embed 72.495 ±0.915 13.425 ±1.035 78.254 ±0.865 28.437 ±0.268 33.221 ±0.523 20.591 ±2.136 60.949 ±0.663
GMN-Embed * 2.368±0.039 3.272 ±0.289 3.413 ±0.037 4.286 ±0.043 2.046 ±0.025 1.495 ±0.200 3.850 ±0.042
GREED 68.732 ±0.867 11.095 ±0.773 78.300 ±0.795 26.057 ±0.238 34.354 ±0.557 20.667 ±2.140 60.652 ±0.704
GREED * 2.456±0.040 5.429 ±0.517 3.827 ±0.043 3.807 ±0.040 2.282 ±0.028 2.894 ±0.394 3.506 ±0.038
GRAPH EDX 1.134±0.016 1.478±0.118 1.804±0.019 1.677±0.016 1.252±0.014 0.914±0.110 1.603±0.016
Table 18: Impact of cost-guided distance on MSE in non-uniform cost setting ( b⊖= 3, b⊕= 1, a⊖=
2, a⊕= 1). * represents the variant of the baseline with cost-guided distance. Green shows the best
performing model. Bold font indicates the best variant of the baseline.
D.7 Results on performance of the alternate surrogates for GED
In Table 19, we present the performance of the alternate surrogates scoring function for GED
discussed in B under non-uniform cost settings (b⊖= 3, b⊕= 1, a⊖= 2, a⊕= 1) . From the results,
we can infer that the alternate surrogates have comparable performance to GRAPH EDXhowever
GRAPH EDX outperforms it by a small margin on six out of the seven datasets.
Mutag Code2 Molhiv Molpcba AIDS Linux Yeast
MAX-OR 1.194±0.016 1.112±0.084 1.987 ±0.022 1.806 ±0.017 1.347 ±0.014 1.009±0.132 1.686±0.018
MAX 1.351±0.018 1.772 ±0.122 1.972±0.021 1.764±0.017 1.346±0.015 1.435 ±0.169 1.748 ±0.018
GRAPH EDX 1.134±0.016 1.478±0.118 1.804±0.019 1.677±0.016 1.252±0.014 0.914±0.110 1.603±0.016
Table 19: Comparison of MSE between GRAPH EDXMAX-OR, and MAX. Green (yellow ) numbers
report the best (second best) performers.
D.8 Comparison of zero-shot performance on other datasets
In Table 20, we compare all baselines with GRAPH EDXon zero-shot GED prediction on a new
dataset. For each method, we select the best-performing models for {AIDS, Yeast, Mutag, Molhiv },
and test each one on the AIDS dataset under non-uniform cost setting.
Train data GRAPH EDX Match Embed ISONET GREED ERIC SimGNN H2MN GraphSim EGSC
AIDS 1.252 31.522 33.221 5.513 34.354 1.581 4.316 3.105 5.266 1.693
Yeast 1.746 35.24 38.542 7.631 40.838 2.774 4.851 3.805 8.404 2.061
Mutag 2.462 33.918 38.624 7.311 34.936 4.100 5.68 5.117 7.292 4.305
Molhiv 2.127 35.138 38.482 14.806 38.705 2.936 4.525 4.274 6.201 2.444
Table 20: Comparison of MSE between GRAPH EDXand baselines on zero-shot GED prediction
on the AIDS test dataset under non-uniform cost setting. Green (yellow ) numbers report the best
(second best) performers.
29D.9 Importance of node-edge consistency
GRAPH EDXenforces consistency between node and edge alignments by design. However, one might
choose to enforce node-edge consistency through alignment regularization between independently
learnt soft node and edge alignment. However, as shown in Figure 21, we notice that such non-
constrained learning might lead to under-prediction or incorrect alignments. We demonstrate the
importance of constraining the node-pair alignment Swith the node alignment Pby showing the
mapping of nodes and edges between two graphs. The required edit operations for subfigure a) with
the constrained Sare two node additions {e, f}, one edge deletion (d, a), and three edge additions
{(a, f),(e, d),(e, f)}. Assuming that each edit costs one, the true GED is 6. However, in subplot b),
Sis not constrained, and the edit operations with the lowest cost are two node additions {e, f}and
two edge additions {(a, f),(e, f)}. This erroneously results in a GED of 4.
(a) Constrained S
 (b) Unconstrained S
Figure 21: Node and edge alignment with constrained and unconstrained alignment S. A dashed
edge represents the deleted edge. Grey edges represent added edges.
Further, in Table 22, we compare the performance of enforcing node-edge consistency through design
(GRAPH EDX), and through alignment regularization (REG). Following the discussion in Section 4.2,
such a model also exhibits a variant with XOR, called REG-xor. We notice that GRAPH EDXeven
outperforms such the described model in 4 out of 6 cases. We also notice that REG-xor outperforms
GRAPH EDXin the other two cases. However, the above example shows a tendency to learn wrong
alignments which in turn gives wrong optimal edit paths.
GED with uniform cost GED with non-uniform cost
Mutag Code2 Molhiv Mutag Code2 Molhiv
REG 0.536 0.576 0.848 1.162 1.488 1.877
REG-xor 0.513 0.587 0.826 1.309 1.440 1.711
GRAPH EDX 0.492 0.429 0.781 1.134 1.478 1.804
Table 22: Comparison of alignment regularizer usage versus no alignment regularizer usage on
uniform cost GED, Measured by MSE. Green (yellow ) numbers report the best (second best)
performers.
30D.10 Comparison of nine possible combinations our proposed set distances
In Tables 23 and 24, we compare the performance of nine possible combinations our proposed set
distances for uniform and non-uniform cost settings respectively. Results follow the observations in
Table 2, where the variant with XOR-D IFFALIGN outperforms those without it.
Edge edit Node edit Mutag Code2 Molhiv Molpcba AIDS Linux Yeast
DIFFALIGN DIFFALIGN 0.579±0.0078 0.740 ±0.0585 0.820 ±0.0086 0.778 ±0.0075 0.603 ±0.0063 0.494 ±0.0528 0.728 ±0.0071
DIFFALIGN ALIGN DIFF 0.557±0.0073 0.742 ±0.0612 0.806 ±0.0088 0.779 ±0.0076 0.597 ±0.0063 0.452 ±0.0614 0.747 ±0.0078
DIFFALIGN XOR 0.538±0.0072 0.719 ±0.0560 0.794 ±0.0083 0.777 ±0.0075 0.580 ±0.0060 0.356 ±0.0512 0.750 ±0.0075
ALIGN DIFF DIFFALIGN 0.537±0.0072 0.513±0.0367 0.815 ±0.0085 0.773 ±0.0074 0.606 ±0.0064 0.508 ±0.0607 0.731 ±0.0073
ALIGN DIFF ALIGN DIFF 0.578±0.0079 0.929 ±0.0659 0.833 ±0.0086 0.773 ±0.0075 0.593 ±0.0062 0.605 ±0.0678 0.761 ±0.0076
ALIGN DIFF XOR 0.533±0.0074 0.826 ±0.0565 0.812 ±0.0083 0.780 ±0.0074 0.575 ±0.0060 0.507 ±0.0568 0.889 ±0.0138
XOR A LIGN DIFF 0.492±0.0066 0.429±0.0355 0.788±0.0084 0.766 ±0.0074 0.565±0.0062 0.416 ±0.0494 0.730 ±0.0072
XOR D IFFALIGN 0.510±0.0067 0.634 ±0.0522 0.781±0.0084 0.765±0.0073 0.574 ±0.0060 0.332±0.0430 0.717±0.0072
XOR XOR 0.530±0.0074 1.588 ±0.1299 0.807 ±0.0084 0.764±0.0073 0.564±0.0059 0.354±0.0427 0.721±0.0076
GRAPH EDX 0.492±0.0066 0.429 ±0.0355 0.781 ±0.0084 0.764 ±0.0073 0.565 ±0.0062 0.354 ±0.0427 0.717 ±0.0072
Table 23: Comparison of MSE for nine combinations of our neural set distance surrogates under
uniform cost settings. The GRAPH EDXmodel was selected based on the best MSE on the validation
set, while the reported results represent MSE on the test set. Green (yellow ) numbers report the best
(second best) performers.
Edge edit Node edit Mutag Code2 Molhiv Molpcba AIDS Linux Yeast
DIFFALIGN DIFFALIGN 1.205±0.0159 2.451 ±0.2141 1.855 ±0.0197 1.825 ±0.0178 1.417 ±0.0146 0.988 ±0.1269 1.630±0.0161
DIFFALIGN ALIGN DIFF 1.211±0.0164 2.116 ±0.1581 1.887 ±0.0199 1.811 ±0.0174 1.319±0.0140 1.078 ±0.1168 1.791 ±0.0185
DIFFALIGN XOR 1.146±0.0154 1.896 ±0.1487 1.802±0.0188 1.822 ±0.0176 1.381 ±0.0148 1.049 ±0.1182 1.737 ±0.0172
ALIGN DIFF DIFFALIGN 1.185±0.0159 1.689 ±0.1210 1.874 ±0.0202 1.758 ±0.0169 1.391 ±0.0145 0.914±0.1099 1.643 ±0.0163
ALIGN DIFF ALIGN DIFF 1.338±0.0178 1.488±0.1222 1.903 ±0.0204 1.859 ±0.0179 1.326 ±0.0141 1.258 ±0.1335 1.731 ±0.0171
ALIGN DIFF XOR 1.196±0.0164 1.741 ±0.1151 1.870 ±0.0196 1.815 ±0.0174 1.374 ±0.0146 1.128 ±0.1330 1.802 ±0.0194
XOR A LIGN DIFF 1.134±0.0158 1.478±0.1178 1.872 ±0.0202 1.742±0.0168 1.252±0.0136 1.073 ±0.1211 1.639 ±0.0162
XOR D IFFALIGN 1.148±0.0157 1.489 ±0.1220 1.804±0.0192 1.757 ±0.0171 1.340 ±0.0140 0.931±0.1149 1.603±0.0160
XOR XOR 1.195±0.0172 2.507 ±0.1979 1.855 ±0.0195 1.677±0.0161 1.319±0.0141 1.193 ±0.1490 1.638 ±0.0169
GRAPH EDX 1.134±0.0158 1.478 ±0.1178 1.804 ±0.0192 1.677 ±0.0161 1.252 ±0.0136 0.914 ±0.1099 1.603 ±0.0160
Table 24: Comparison of MSE for nine combinations under non-uniform cost settings. The
GRAPH EDXmodel was selected based on the best MSE on the validation set, while the reported re-
sults represent MSE on the test set. Green (yellow ) numbers report the best (second best) performers.
31D.11 Comparison of performance of our model with baselines using scatter plot
In Figure 25, we illustrate the performance of our model compared to the second-best performing
model, under both uniform and non-uniform cost settings, by visualizing the distribution of outputs
of the predicted GEDs by both models. We observe that predictions from our model consistently
align closer to the y=xline across various datasets showcasing lower output variance as compared
to the next best-performing model.
0 10 20 30
Ground Truth→0102030 Predicted→ERIC
GraphEdX
(a) Mutag uniform cost
0 25 50 75
Ground Truth→0255075 Predicted→EGSC
GraphEdX (b) Mutag non-uniform
cost
0 10 20
Ground Truth→01020 Predicted→ISONET
GraphEdX(c) Code2 uniform cost
0 20 40
Ground Truth→02040 Predicted→ISONET
GraphEdX (d) Code2 non-uniform
cost
0 20 40
Ground Truth→02040 Predicted→EGSC
GraphEdX
(e) Molhiv uniform cost
0 50 100
Ground Truth→050100 Predicted→EGSC
GraphEdX (f) Molhiv non-uniform cost
0 10 20
Ground Truth→01020 Predicted→ERIC
GraphEdX (g) Molpcba uniform cost
0 20 40
Ground Truth→0204060 Predicted→ERIC
GraphEdX (h) Molpcba non-uniform
cost
Figure 25: Scatter plot comparing the distribution of the predicted GED of our model with the next
best-performing model across various datasets under both uniform and non-uniform cost settings.
D.12 Comparison of performance of our model with baselines using error distribution
In Figure 26, we plot the distribution of error (MSE) of our model against the second-best performing
model, under both uniform and non-uniform cost settings. We observe that our model performs better,
exhibiting a higher probability density for lower MSE values and a lower probability density for
higher MSE values.
0.00 0.25 0.50 0.75 1.00
Squared Error→0.00.10.20.30.4Probability→ERIC
GraphEdX
(a) Mutag uniform cost
0 2 4
Squared Error→0.00.20.4Probability→EGSC
GraphEdX (b) Mutag non-uniform
cost
0.0 0.5 1.0 1.5 2.0
Squared Error→0.00.20.40.6Probability→ISONET
GraphEdX(c) Code2 uniform cost
0 10 20 30
Squared Error→0.00.20.40.6Probability→ISONET
GraphEdX (d) Code2 non-uniform
cost
0.0 0.5 1.0 1.5 2.0
Squared Error→0.00.10.20.30.4Probability→EGSC
GraphEdX
(e) Molhiv uniform cost
0.0 2.5 5.0 7.5 10.0
Squared Error→0.00.10.20.30.4Probability→EGSC
GraphEdX (f) Molhiv non-uniform
cost
0.0 0.5 1.0 1.5 2.0
Squared Error→0.00.10.20.30.4Probability→ERIC
GraphEdX(g) Molpcba uniform cost
0.0 2.5 5.0 7.5 10.0
Squared Error→0.00.10.20.30.4Probability→ERIC
GraphEdX (h) Molpcba non-uniform
cost
Figure 26: Error distribution of our model compared to the next best-performing model across various
datasets under both uniform and non-uniform cost settings.
32D.13 Comparison of combinatorial optimisation gadgets for GED prediction
10−310−1101 0.00.1IPFP
Anchor-aware GED
Branch-tightF2
BipartiteBranch
GraphEdX
10−410−210−1100101
Time Limit (sec) →0110100 MSE→
(a) Mutag uniform cost
10−410−210−1100101
Time Limit (sec) →0110100 MSE→
 (b) Mutag non-uniform
cost
10−410−210−1100101
Time Limit (sec) →0110100 MSE→
(c) Code2 uniform cost
10−410−210−1100101
Time Limit (sec) →0110100 MSE→
 (d) Code2 non-uniform
cost
10−410−210−1100101
Time Limit (sec) →0110100 MSE→
(e) AIDS uniform cost
10−410−210−1100101
Time Limit (sec) →0110100 MSE→
 (f) AIDS non-uniform cost
10−410−210−1100101
Time Limit (sec) →0110100 MSE→
 (g) Linux uniform cost
10−410−210−1100101
Time Limit (sec) →0110100 MSE→
 (h) Linux non-uniform cost
Figure 27: Performance of combinatorial optimization algorithms on various datasets under both
uniform and non-uniform cost settings is evaluated. We plot MSE against the time limit allocated to
the combinatorial algorithms. Additionally, we include the amortized time of our model and its MSE.
We compare the runtime performance of six combinatorial optimization algorithms described in
Appendix C (ipfp [ 11], anchor-aware GED [ 15], branch tight [ 8], F2 [ 29], bipartite [ 41] and branch
[8]). We note that combinatorial algorithms are slow to approximate the GED between two graphs.
Specifically, GRAPH EDXoften predicts the GED in ∼10−4seconds per graph, however, the
performance of the combinatorial baselines are extremely poor under such a time constraint. Hence,
we execute the combinatorial algorithms with four different time limits per graph: ranging from 10−2
seconds (100x our method) to 10seconds ( 105x our method).
In Figure 27, we depict the MSE versus time limit for the aforementioned combinatorial algorithms
under both uniform and non-uniform cost settings. We also showcase the inference time per graph of
our method in the figure. It is evident that even with a time limit scaled by 105x, most combinatorial
algorithms struggle to achieve a satisfactory approximation for the GED.
33D.14 Prediction timing analysis
In Figure 28 illustrates the inference time per graph of our model versus under uniform cost settings,
averaged over ten runs. From the figure, we observe the following (1) GRAPH EDXoutperforms
four of the baselines in terms of inference time, and is comparable to ISONET’s inference time (2)
GMN-Embed, GREED, ERIC, and EGSC run faster compared to all other methods due to lack of
interaction between graphs, which results in poorer performance at predicting the GED.
GraphEdX GMN-Match GMN-Embed ISONET GREED ERIC H2MN SimGNN GraphSim EGSC10−510−410−3Time (sec)→Mutag
Molhiv
Molpcba
Figure 28: GED inference time comparison between our model and baselines. We notice that
GRAPH EDXis consistently the third-fastest amongst all baselines. Although GMN-Embed and
GREED have the lowest inference time, G RAPH EDX has much lower MSE consistently.
D.15 Visualization (optimal edit path) + Pseudocode
In Algorithm 1, we present the pseudocode to generate the optimal edit path given the learnt node
and edge alignments from GRAPH EDX. Figure 29 demonstrates how the operations in the edit path
can be utilized to convert GtoG′.
Figure 29: An example of the sequence of edit operations performed to convert one graph into
another.
Algorithm 1 Generation of Edit Path
1:function GETEDITPATH(G, G′,ηG,ηG′)
2:P,S←GRAPH EDX(G, G′,ηG,ηG′)
3:P,S←HUNGARIAN (P), HUNGARIAN (S)
4: o=NewList()
5: for(u, v)∈[N]×[N]do
6: ifP[u, v] = 1 andηG[u] = 0 andηG′[v] = 1 then
7: AddItem( o,ADDNODE(u))
8: for(u, v),(u′, v′)∈ {[N]×[N]} × { [N]×[N]}do
9: ifS[(u, v),(u′, v′)] = 1 andA[u, v] = 0 andA′[u′, v′] = 1 then
10: AddItem( o,ADDEDGE((u, v)))
11: ifS[(u, v),(u′, v′)] = 1 andA[u, v] = 1 andA′[u′, v′] = 0 then
12: AddItem( o,DELEDGE((u, v)))
13: for(u, v)∈[N]×[N]do
14: ifP[u, v] = 1 andηG[u] = 1 andηG′[v] = 0 then
15: AddItem( o,DELNODE(u))
16: return o
34NeurIPS Paper Checklist
1.Claims
Question: Do the main claims made in the abstract and introduction accurately reflect the
paper’s contributions and scope?
Answer: [Yes]
Justification: In Section 5, we present experiments and results to support the claims made in
the abstract and introduction.
Guidelines:
•The answer NA means that the abstract and introduction do not include the claims
made in the paper.
•The abstract and/or introduction should clearly state the claims made, including the
contributions made in the paper and important assumptions and limitations. A No or
NA answer to this question will not be perceived well by the reviewers.
•The claims made should match theoretical and experimental results, and reflect how
much the results can be expected to generalize to other settings.
•It is fine to include aspirational goals as motivation as long as it is clear that these goals
are not attained by the paper.
2.Limitations
Question: Does the paper discuss the limitations of the work performed by the authors?
Answer: [Yes]
Justification: In Conclusions, we discuss the limitations of our work.
Guidelines:
•The answer NA means that the paper has no limitation while the answer No means that
the paper has limitations, but those are not discussed in the paper.
• The authors are encouraged to create a separate "Limitations" section in their paper.
•The paper should point out any strong assumptions and how robust the results are to
violations of these assumptions (e.g., independence assumptions, noiseless settings,
model well-specification, asymptotic approximations only holding locally). The authors
should reflect on how these assumptions might be violated in practice and what the
implications would be.
•The authors should reflect on the scope of the claims made, e.g., if the approach was
only tested on a few datasets or with a few runs. In general, empirical results often
depend on implicit assumptions, which should be articulated.
•The authors should reflect on the factors that influence the performance of the approach.
For example, a facial recognition algorithm may perform poorly when image resolution
is low or images are taken in low lighting. Or a speech-to-text system might not be
used reliably to provide closed captions for online lectures because it fails to handle
technical jargon.
•The authors should discuss the computational efficiency of the proposed algorithms
and how they scale with dataset size.
•If applicable, the authors should discuss possible limitations of their approach to
address problems of privacy and fairness.
•While the authors might fear that complete honesty about limitations might be used by
reviewers as grounds for rejection, a worse outcome might be that reviewers discover
limitations that aren’t acknowledged in the paper. The authors should use their best
judgment and recognize that individual actions in favor of transparency play an impor-
tant role in developing norms that preserve the integrity of the community. Reviewers
will be specifically instructed to not penalize honesty concerning limitations.
3.Theory Assumptions and Proofs
Question: For each theoretical result, does the paper provide the full set of assumptions and
a complete (and correct) proof?
Answer: [Yes]
Justification: In Appendix B, we provide proof for the theoretical results mentioned in the
paper.
Guidelines:
• The answer NA means that the paper does not include theoretical results.
•All the theorems, formulas, and proofs in the paper should be numbered and cross-
referenced.
35•All assumptions should be clearly stated or referenced in the statement of any theorems.
•The proofs can either appear in the main paper or the supplemental material, but if
they appear in the supplemental material, the authors are encouraged to provide a short
proof sketch to provide intuition.
•Inversely, any informal proof provided in the core of the paper should be complemented
by formal proofs provided in appendix or supplemental material.
• Theorems and Lemmas that the proof relies upon should be properly referenced.
4.Experimental Result Reproducibility
Question: Does the paper fully disclose all the information needed to reproduce the main ex-
perimental results of the paper to the extent that it affects the main claims and/or conclusions
of the paper (regardless of whether the code and data are provided or not)?
Answer: [Yes]
Justification: We provide code and dataset in the supplementary material with instructions
to reproduce the results.
Guidelines:
• The answer NA means that the paper does not include experiments.
•If the paper includes experiments, a No answer to this question will not be perceived
well by the reviewers: Making the paper reproducible is important, regardless of
whether the code and data are provided or not.
•If the contribution is a dataset and/or model, the authors should describe the steps taken
to make their results reproducible or verifiable.
•Depending on the contribution, reproducibility can be accomplished in various ways.
For example, if the contribution is a novel architecture, describing the architecture fully
might suffice, or if the contribution is a specific model and empirical evaluation, it may
be necessary to either make it possible for others to replicate the model with the same
dataset, or provide access to the model. In general. releasing code and data is often
one good way to accomplish this, but reproducibility can also be provided via detailed
instructions for how to replicate the results, access to a hosted model (e.g., in the case
of a large language model), releasing of a model checkpoint, or other means that are
appropriate to the research performed.
•While NeurIPS does not require releasing code, the conference does require all submis-
sions to provide some reasonable avenue for reproducibility, which may depend on the
nature of the contribution. For example
(a)If the contribution is primarily a new algorithm, the paper should make it clear how
to reproduce that algorithm.
(b)If the contribution is primarily a new model architecture, the paper should describe
the architecture clearly and fully.
(c)If the contribution is a new model (e.g., a large language model), then there should
either be a way to access this model for reproducing the results or a way to reproduce
the model (e.g., with an open-source dataset or instructions for how to construct
the dataset).
(d)We recognize that reproducibility may be tricky in some cases, in which case
authors are welcome to describe the particular way they provide for reproducibility.
In the case of closed-source models, it may be that access to the model is limited in
some way (e.g., to registered users), but it should be possible for other researchers
to have some path to reproducing or verifying the results.
5.Open access to data and code
Question: Does the paper provide open access to the data and code, with sufficient instruc-
tions to faithfully reproduce the main experimental results, as described in supplemental
material?
Answer: [Yes]
Justification: In the supplementary material, we provide code for our model, baselines, and
experimental datasets, as well as instructions for reproducing the results.
Guidelines:
• The answer NA means that paper does not include experiments requiring code.
•Please see the NeurIPS code and data submission guidelines ( https://nips.cc/
public/guides/CodeSubmissionPolicy ) for more details.
•While we encourage the release of code and data, we understand that this might not be
possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not
36including code, unless this is central to the contribution (e.g., for a new open-source
benchmark).
•The instructions should contain the exact command and environment needed to run to
reproduce the results. See the NeurIPS code and data submission guidelines ( https:
//nips.cc/public/guides/CodeSubmissionPolicy ) for more details.
•The authors should provide instructions on data access and preparation, including how
to access the raw data, preprocessed data, intermediate data, and generated data, etc.
•The authors should provide scripts to reproduce all experimental results for the new
proposed method and baselines. If only a subset of experiments are reproducible, they
should state which ones are omitted from the script and why.
•At submission time, to preserve anonymity, the authors should release anonymized
versions (if applicable).
•Providing as much information as possible in supplemental material (appended to the
paper) is recommended, but including URLs to data and code is permitted.
6.Experimental Setting/Details
Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
results?
Answer: [Yes]
Justification: In Appendix C, we provide training details, such as hyperparameters and
optimizer used.
Guidelines:
• The answer NA means that the paper does not include experiments.
•The experimental setting should be presented in the core of the paper to a level of detail
that is necessary to appreciate the results and make sense of them.
•The full details can be provided either with the code, in appendix, or as supplemental
material.
7.Experiment Statistical Significance
Question: Does the paper report error bars suitably and correctly defined or other appropriate
information about the statistical significance of the experiments?
Answer: [Yes]
Justification: Along with Mean Squared Error we also provide Standard deviation to report
the statistical significance of our results.
Guidelines:
• The answer NA means that the paper does not include experiments.
•The authors should answer "Yes" if the results are accompanied by error bars, confi-
dence intervals, or statistical significance tests, at least for the experiments that support
the main claims of the paper.
•The factors of variability that the error bars are capturing should be clearly stated (for
example, train/test split, initialization, random drawing of some parameter, or overall
run with given experimental conditions).
•The method for calculating the error bars should be explained (closed form formula,
call to a library function, bootstrap, etc.)
• The assumptions made should be given (e.g., Normally distributed errors).
•It should be clear whether the error bar is the standard deviation or the standard error
of the mean.
•It is OK to report 1-sigma error bars, but one should state it. The authors should
preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis
of Normality of errors is not verified.
•For asymmetric distributions, the authors should be careful not to show in tables or
figures symmetric error bars that would yield results that are out of range (e.g. negative
error rates).
•If error bars are reported in tables or plots, The authors should explain in the text how
they were calculated and reference the corresponding figures or tables in the text.
8.Experiments Compute Resources
Question: For each experiment, does the paper provide sufficient information on the com-
puter resources (type of compute workers, memory, time of execution) needed to reproduce
the experiments?
Answer: [Yes]
37Justification: In Appendix C we provide information on hardware used for running experi-
ments.
Guidelines:
• The answer NA means that the paper does not include experiments.
•The paper should indicate the type of compute workers CPU or GPU, internal cluster,
or cloud provider, including relevant memory and storage.
•The paper should provide the amount of compute required for each of the individual
experimental runs as well as estimate the total compute.
•The paper should disclose whether the full research project required more compute
than the experiments reported in the paper (e.g., preliminary or failed experiments that
didn’t make it into the paper).
9.Code Of Ethics
Question: Does the research conducted in the paper conform, in every respect, with the
NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines ?
Answer: [Yes]
Justification: Yes, the research conducted in the paper conforms, in every aspect, with
Neurips Code of Ethics.
Guidelines:
•The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
•If the authors answer No, they should explain the special circumstances that require a
deviation from the Code of Ethics.
•The authors should make sure to preserve anonymity (e.g., if there is a special consid-
eration due to laws or regulations in their jurisdiction).
10.Broader Impacts
Question: Does the paper discuss both potential positive societal impacts and negative
societal impacts of the work performed?
Answer: [Yes]
Justification: In Appendix A we have discuss broader impact of our work.
Guidelines:
• The answer NA means that there is no societal impact of the work performed.
•If the authors answer NA or No, they should explain why their work has no societal
impact or why the paper does not address societal impact.
•Examples of negative societal impacts include potential malicious or unintended uses
(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
(e.g., deployment of technologies that could make decisions that unfairly impact specific
groups), privacy considerations, and security considerations.
•The conference expects that many papers will be foundational research and not tied
to particular applications, let alone deployments. However, if there is a direct path to
any negative applications, the authors should point it out. For example, it is legitimate
to point out that an improvement in the quality of generative models could be used to
generate deepfakes for disinformation. On the other hand, it is not needed to point out
that a generic algorithm for optimizing neural networks could enable people to train
models that generate Deepfakes faster.
•The authors should consider possible harms that could arise when the technology is
being used as intended and functioning correctly, harms that could arise when the
technology is being used as intended but gives incorrect results, and harms following
from (intentional or unintentional) misuse of the technology.
•If there are negative societal impacts, the authors could also discuss possible mitigation
strategies (e.g., gated release of models, providing defenses in addition to attacks,
mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
feedback over time, improving the efficiency and accessibility of ML).
11.Safeguards
Question: Does the paper describe safeguards that have been put in place for responsible
release of data or models that have a high risk for misuse (e.g., pretrained language models,
image generators, or scraped datasets)?
Answer: [NA]
Justification: We do not use any such dataset/method.
Guidelines:
• The answer NA means that the paper poses no such risks.
38•Released models that have a high risk for misuse or dual-use should be released with
necessary safeguards to allow for controlled use of the model, for example by requiring
that users adhere to usage guidelines or restrictions to access the model or implementing
safety filters.
•Datasets that have been scraped from the Internet could pose safety risks. The authors
should describe how they avoided releasing unsafe images.
•We recognize that providing effective safeguards is challenging, and many papers do
not require this, but we encourage authors to take this into account and make a best
faith effort.
12.Licenses for existing assets
Question: Are the creators or original owners of assets (e.g., code, data, models), used in
the paper, properly credited and are the license and terms of use explicitly mentioned and
properly respected?
Answer: [Yes]
Justification: We cite and provide URLs for datasets and codes that we use for the experi-
ments.
Guidelines:
• The answer NA means that the paper does not use existing assets.
• The authors should cite the original paper that produced the code package or dataset.
•The authors should state which version of the asset is used and, if possible, include a
URL.
• The name of the license (e.g., CC-BY 4.0) should be included for each asset.
•For scraped data from a particular source (e.g., website), the copyright and terms of
service of that source should be provided.
•If assets are released, the license, copyright information, and terms of use in the
package should be provided. For popular datasets, paperswithcode.com/datasets
has curated licenses for some datasets. Their licensing guide can help determine the
license of a dataset.
•For existing datasets that are re-packaged, both the original license and the license of
the derived asset (if it has changed) should be provided.
•If this information is not available online, the authors are encouraged to reach out to
the asset’s creators.
13.New Assets
Question: Are new assets introduced in the paper well documented and is the documentation
provided alongside the assets?
Answer: [Yes]
Justification: We provide our code and dataset with README file having instructions on
how to run the experiments.
Guidelines:
• The answer NA means that the paper does not release new assets.
•Researchers should communicate the details of the dataset/code/model as part of their
submissions via structured templates. This includes details about training, license,
limitations, etc.
•The paper should discuss whether and how consent was obtained from people whose
asset is used.
•At submission time, remember to anonymize your assets (if applicable). You can either
create an anonymized URL or include an anonymized zip file.
14.Crowdsourcing and Research with Human Subjects
Question: For crowdsourcing experiments and research with human subjects, does the paper
include the full text of instructions given to participants and screenshots, if applicable, as
well as details about compensation (if any)?
Answer: [NA]
Justification: This work does not involve such research.
Guidelines:
•The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
•Including this information in the supplemental material is fine, but if the main contribu-
tion of the paper involves human subjects, then as much detail as possible should be
included in the main paper.
39•According to the NeurIPS Code of Ethics, workers involved in data collection, curation,
or other labor should be paid at least the minimum wage in the country of the data
collector.
15.Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
Subjects
Question: Does the paper describe potential risks incurred by study participants, whether
such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
approvals (or an equivalent approval/review based on the requirements of your country or
institution) were obtained?
Answer: [NA]
Justification: This work does not involve such research.
Guidelines:
•The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
•Depending on the country in which research is conducted, IRB approval (or equivalent)
may be required for any human subjects research. If you obtained IRB approval, you
should clearly state this in the paper.
•We recognize that the procedures for this may vary significantly between institutions
and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
guidelines for their institution.
•For initial submissions, do not include any information that would break anonymity (if
applicable), such as the institution conducting the review.
40