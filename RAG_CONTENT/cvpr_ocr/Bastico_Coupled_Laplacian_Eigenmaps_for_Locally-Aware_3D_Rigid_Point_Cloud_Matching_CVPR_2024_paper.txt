Coupled Laplacian Eigenmaps for Locally-Aware 3D Rigid Point Cloud
Matching
Matteo Bastico1⇤, Etienne Decenci `ere2, Laurent Cort ´e1, Yannick Tillier3, David Ryckelynck1
Mines Paris, Universit ´e PSL
1Centre des Mat ´eriaux (MAT), UMR7633 CNRS, 91003 Evry, France
2Centre de Morphologie Math ´ematique (CMM), 77300 Fontainebleau, France
3Centre de Mise en Forme des Mat ´eriaux (CEMEF), UMR7635 CNRS, 06904 Sophia Antipolis, France
Abstract
Point cloud matching, a crucial technique in computer
vision, medical and robotics ﬁelds, is primarily concerned
with ﬁnding correspondences between pairs of point clouds
or voxels. In some practical scenarios, emphasizing lo-
cal differences is crucial for accurately identifying a cor-
rect match, thereby enhancing the overall robustness and
reliability of the matching process. Commonly used shape
descriptors have several limitations and often fail to pro-
vide meaningful local insights about the paired geome-
tries. In this work, we propose a new technique, based
on graph Laplacian eigenmaps, to match point clouds by
taking into account ﬁne local structures. To deal with the
order and sign ambiguity of Laplacian eigenmaps, we in-
troduce a new operator, called Coupled Laplacian1, that
allows to easily generate aligned eigenspaces for multiple
registered geometries. We show that the similarity between
those aligned high-dimensional spaces provides a locally
meaningful score to match shapes. We ﬁrstly evaluate the
performance of the proposed technique in a point-wise man-
ner, focusing on the task of object anomaly localization on
the MVTec 3D-AD dataset. Additionally, we deﬁne a new
medical task, called automatic Bone Side Estimation (BSE),
which we address through a global similarity score derived
from coupled eigenspaces. In order to test it, we propose a
benchmark collecting bone surface structures from various
public datasets. Our matching technique, based on Cou-
pled Laplacian, outperforms other methods by reaching an
impressive accuracy on both tasks.
1. Introduction
Point cloud matching, or more generally 3D shape match-
ing, is a fundamental task in computer vision. It involves
⇤Corresponding author: matteo.bastico@minesparis.psl.eu
1Code: https://github.com/matteo-bastico/CoupLapﬁnding the closest matching geometry to a target shape
within a set of reference shapes [ 65]. In addition, if the
task involves ﬁnding rigid transformations that best align
the target shape with the reference, it is often part of a reg-
istration process. In particular, point-set rigid registration
determines the relative transformation needed to align two
point clouds without altering their internal structures [ 41].
This problem is essential for many practical computer vi-
sion tasks, such as medical image analysis [ 3,32,48,61],
intelligent vehicles [ 21,34], human pose estimation [ 22]
and objects retrieval and tracking [ 46,64]. Traditional
[8,19,57] and probabilistic registration and matching meth-
ods [ 15,20,30,45], while robust, often struggle to opti-
mally align complex geometries, especially in cases with
intricate local structures or slight deformations.
Over the years, several methods have been proposed
to tackle the challenge of accurate and efﬁcient 3D shape
matching and retrieval [ 5,9,11,51,53,65,73]. Data-driven
3D shape descriptors [ 54], capturing underlying properties
of the shapes under study, are the common denominator of
early shape matching techniques. Global descriptors, such
as volume and areas descriptors [ 78], describe the entirety
of the shape in one compact representation, often failing
to capture local ﬁne details of complex geometries. On the
other hand, local descriptors [ 38,57] aim to tackle this issue
but they generally are sensitive to noise, based on landmarks
and they might not capture semantic information [ 63]. More
recently, deep-learned shape descriptors [ 6,72] and neural
networks for shape matching, based on auto-encoders [ 73]
or transformers [ 59,68], have been proposed. Despite their
good performances, these methods require a huge amount
of annotated data for training, which are hard to collect in
ﬁelds such as medical imaging [ 37]. Furthermore, non-rigid
point cloud matching and retrieval methods [ 35,36,71] are
designed to handle shape deformations and, therefore, they
might be excessively ﬂexible ignoring ﬁne local details that
are not due to deformations, such as anomalies.
This CVPR paper is the Open Access version, provided by the Computer Vision Foundation.
Except for this watermark, it is identical to the accepted version;
the final published version of the proceedings is available on IEEE Xplore.
3447
In this study, we introduce a novel method for rigid 3D
point cloud matching, based on spectral Laplacian eigen-
maps [ 4,23], which focus on local details. This technique
is designed to overcome the limitations of shape descrip-
tors and, although it can be seen as a linear graph neural
network, it does not require training. One of the main rea-
sons that combinatorial and geometric Laplacians are of-
ten considered for spectral graph processing is that their
eigenvectors possess properties like the classical Fourier
basis functions [ 79]. We leverage these characteristics to
perform locally-aware shape comparison of point clouds,
equipped with k-nearest neighbor graph, without relying
on additional descriptors. Nevertheless, eigenspaces align-
ment, including both eigenvalue ordering and sign dis-
ambiguity of the eigendecomposition, is required to cor-
rectly match shapes in the spectral space. Current State-
of-The-Art methods for such alignment are based on Lapla-
cian eigenfunctions matching [ 42,60], i.e. matching the
histograms of the eigenvectors. The latter is not robust
and frequently fails in possible scenarios with highly sym-
metric geometries, such as bones, with small eigenvalue
separation. In this work, we introduce a novel operator,
called Coupled Laplacian , designed to simultaneously pro-
duce aligned eigenspaces for multiple registered geome-
tries. Namely, we show that when two or more shapes, each
with their corresponding graphs, are merged into a single
graph using artiﬁcial cross-edges, the eigendecompositon
of the Laplacian derived from such a combined graph yields
aligned spectral spaces for each individual component. Fur-
thermore, this method is order-invariant, count-agnostic and
landmarks-free, enabling it to handle point clouds without
being inﬂuenced by their speciﬁc arrangement or the num-
ber of points contained. Finally, we utilize the distance
between these aligned higher-dimensional spectral spaces,
which accounts for intricate local structures, as a global
or point-wise score for different applications of 3D shape
matching, as shown in Fig. 1.
One natural application of the proposed technique, is 3D
object anomaly detection thought the identiﬁcation of lo-
cal differences between two shapes. Hence, we tested our
method on the MVTec 3D-AD dataset [ 7], recently pro-
posed for unsupervised point cloud anomaly detection and
localization. Furthermore, in the context of medical imag-
ing, correctly identifying the side of a bone (left or right) is
crucial for diagnosis, treatment planning, or skeletal anal-
ysis [ 12]. We refer to this task as Bone Side Estimation
(BSE). Recent studies on bone landmark detection [ 18] and
statistical shape modeling [ 31] have highlighted the limita-
tions of manual side identiﬁcation for ensuring proper func-
tioning. To the best of our knowledge, manual bone mark-
ings [ 2] are currently the only technique used for this pur-
pose. Consequently, automatic BSE arises as an interesting,
yet challenging, task to assist the development of fully auto-Global SimilarityPoint-Wise Similairty
Matching
Coupled Laplacian
Aligned Eigenmaps
Anomaly Localization
Figure 1. Overview of the proposed technique applied to different
tasks. The global similarity between aligned eigenmaps of multi-
ple geometries, generated from the Coupled Laplacian, is used to
match bones and predict their body side. While local similarity is
exploited for accurate 3D anomaly detection.
mated pipelines for medical image analysis, such as patient-
speciﬁc preoperative planning for Total Knee Arthroplasty
(TKA) [ 33] or Anterior Cruciate Ligament Reconstruction
(ACLR) [ 17,44]. Due to the bilateral symmetry of the an-
imal and human body [ 27,67], i.e. right and left sides are
mirror shapes of one another, the BSE can be deﬁned as
a non-trivial chiral shape matching problem. Then, given
a known reference or source bone, assessing the side of
a target bone involves ﬁnding the best match between the
source-target pair and its mirrored counterpart. The com-
plexity of this task arises from subtle local differences in
mirrored bones, which makes it a suitable application of
the proposed shape matching technique utilizing coupled
Laplacian eigenmaps as local geometry descriptors. We
propose a benchmark for human BSE by extracting sur-
face point clouds of different bones, e.g. femur, hip and
tibia, from public datasets [ 18,31,47]. We also discuss,
in the Supplementary Material, a non-rigid correspondence
application of the proposed matching algorithm, the cross-
species BSE (human to animal), on an internal dataset [ 40].
Our contributions are summarized as follows:
•We propose a new method to preform locally-aware 3D
rigid point cloud matching, considering ﬁne local struc-
tures, based on graph Laplacian eigenmaps.
•We deﬁne the Coupled Laplacian operator for aligned
graphs to tackle the order and sign ambiguity issue of
the eigendecomposition.
•Based on the proposed technique, we introduce a new
method for automatic BSE to assist fully automated med-
ical pipelines and we propose a benchmark to test it.
3448
•We extensively evaluate our method on two tasks:
anomaly detection and BSE, outperforming previously
proposed techniques.
2. Related Works
Early efforts in developing hand-crafted 3D local features
for point cloud matching, registration and retrieval have
typically drawn inspiration from 2D descriptors. Several
methods, such as Signature of Histograms of OrienTations
(SHOT) [ 58,66], Rotational Projection Statistics (RoSP)
[25] and Unique Shape Context (USC) [ 66] rely on the es-
timation of an unique Local Reference Frame (LRF). The
latter is usually based on the eigendecomposition of the
covariance matrix of the neighbours of a point of interest,
which are then projected into the LRF to analyze their ge-
ometric properties. For instance, SHOT [ 58] captures lo-
cal shape and orientation information by computing his-
tograms of surface normals and point distribution around
keypoints. In contrast, LRF-free approaches [ 10,56,57]
try to rely just on features that are intrinsically invariant.
The most common LRF-free features are Fast Point Feature
Hisograms (FPFH) [ 57] which, similarly to SHOT, calcu-
lates histograms of surface normals considering their rela-
tionships in a local region around a keypoint and generat-
ing33-dimensional descriptors. Despite the progress made
with hand-crafted 3D local features, they encounter difﬁ-
culties when it comes to deal with issues like point cloud
resolutions, noisy data, and occlusions [ 26].
On the contrary, spectral-based point cloud descriptors
[1,28,52,55,62,69,70] are a category of feature ex-
traction methods that leverage spectral analysis techniques
from graph theory to capture the underlying structure and
intrinsic geometric properties of point clouds. Among them,
shape-DNA [ 52] is a surface descriptor based on eigenvalue
analysis of the Laplace-Beltrami operator. They propose to
use the sequence of eigenvalues (spectrum) of the Laplace
operator as a ﬁngerprint characterizing the intrinsic geome-
try of 3D shapes represented as point clouds. This method
has been used for shape retrieval, classiﬁcation, and cor-
respondence. Weinmann et al. [70] also proposed to ex-
tract a features set consisting of 8eigenvalues-based indices
for each 3D point of a cloud. Furthermore, Heat Kernel
Signature (HKS) [ 62] and Wave Kernel Signatures (WKS)
[1] are descriptors measuring how heat and wave propagate
across a shape, having the eigendecomposition as leading
element of the computation. Scaled eigenvectors evaluated
at each point are instead directly exploited by the Global
Point Signature (GPS) [ 55] to represent a point cloud as
a set of inﬁnite-dimensional vectors, characterizing each
point within the global context of the surface it belongs.
Nevertheless, the vast majority of these works assumes that
the eigenvalues of a shape are distinct and, therefore, can be
ordered. Indeed, in practice, due to numerical approxima-tions, we cannot guarantee that the eigenvalues of the Lapla-
cian are all distinct and, possible symmetries in the shapes
may cause some of them to have multiplicity grater than
one. As shown by Mateus et al. [42], when dealing with
shape matching, an elegant way to overcome this problem
is to use the Laplacian eigenmaps scheme [ 4], which can
be seen as a reduced GPS, and perform a-posteriori align-
ment of the resulting point cloud embeddings. Matching the
eigenfunctions histograms, i.e. their signatures, is the only
reliable method for such embeddings alignment [ 42,60].
Recently, Ma et. al. [39] proposed a canonization algorithm
for sign and basis invariance, called Maximal Axis Projec-
tion (MAP), that adopts the permutation-invariant axis pro-
jection functions to determine the canonical directions. Un-
fortunately, when the eigenvalues separation is small due to
symmetries in the geometries, these methods becomes un-
stable and sensitive to noise. To overcome this issue, in
this work we propose the Coupled Laplacian operator to
produce a-priori aligned eigenmaps for several registered
shapes, and perform locally-aware shape matching.
Deep-learned point-cloud descriptors [ 6,24,72,77]
arose as an alternative to generate local features for 3D
sufraces. We can distinguish three main categories de-
pending on the backbone architecture employed. Convo-
lutional Neural Networks (CNNs) are often used on point
clouds projected into 2D depth images [ 16,29] or directly
on 3D voxels [ 24,29,77]. Secondly, to work directly on
raw point cloud data, PointNet and PointNet++ have been
proposed aiming to learn rotation and permutation invari-
ant features [ 49,50]. Based on PointNet, several learned
descriptors have been introduced [ 13,14,75,76]. Among
them, PPFNet [ 14] and PPF-FoldNet [ 13] try to improve the
feature representation of PointNet by incorporating global
context and point-pair features. Nevertheless, the lack of
convolutional layers in these models limits the learning of
local geometries. Finally, transformers-based descriptors,
such as Deep Closest Point [ 68], have been recently pro-
posed trying to exploit the attention mechanisms to cap-
ture shapes and surfaces intrinsic characteristics. Arguably,
training a deep-learning model, especially if based on trans-
formers, it is not always feasible in terms of training sam-
ples required to achieve good performances. Furthermore,
in supervised algorithms [ 13,14,24,77], paired 3D patches,
such as in the 3DMatch dataset [ 77], are needed to train the
models. For this reason, the 3D rigid point cloud matching
method we propose does not need training and utilizes only
the similarity among properly aligned spectral embeddings
to relate an unseen target shape to the given references.
3. Method
Graph Laplacian. A 3D point-cloud {xxxi}n
i=1can be
treated as a connected undirected weighted graph G(V,E),
where V={xxxi}n
i=1is the nodes set and E={eeeij}is the
3449
TargetSource 1Source N
Registration
CrossConnections
Registered Target-SourcesCoupled Laplacian
Aligned -dimensional  Embeddings 
12
Figure 2. Proposed workﬂow of the Coupled Laplacian applied to proximal femur shapes. The Nsources are registered to the target
using a rigid or afﬁne registration. After that, cross-connection are added between each target-source pair (for simplicity, in the zoom the
shapes are not overlapping) and the Coupled Laplacian is computed on the global graph. Its eigendecomposition leads to aligned spectral
embeddings of the input geometries that can be used for shape matching.
edge set. The latter is generally obtained though the con-
struction of a nearest neighbors graph [ 4]. To that purpose,
in this work, we consider the k-Nearest Neighbour ( k-NN)
approach, that is, node jis connected to node iifxxxiis
among the knearest neighbours of xxxj. Hence, we can build
a weighted adjacency matrix, WWW={wij}, which stores the
connections between nodes. In particular, in spectral graph
theory, a Radial Basis Function (RBF) is commonly used as
weight function for the edges between xxxiandxxxj, as
wij=e x p✓
 d2(xxxi,xxxj)
 2◆
(1)
where d2(·,·)is the Euclidean distance between two ver-
tices and  2a free parameter which, for simplicity, we
set to the maximum distance between connected nodes,
max ijd2(xxxi,xxxj). The Laplacian matrix ,L2Rn⇥n, of
a graph constructed in such way, is deﬁned as L=D W
where Rn⇥n3DDD=diag([d1,···,dn]) is the degree ma-
trix with diagonal elements di=Pn
j=1wij[43]. The
Laplacian eigenvalues, { i}n
i=0, and eigenvectors, {   i}n
i=0,
can be computed by solving the generalized eigenproblem
L   i= iBBB   i,i=0,···,n . (2)
where BBB2Rn⇥nis generally set as DDD, and  i i+1. Fi-
nally, eigenmaps are simply eigenvectors sub-spaces, gener-
ated by leaving out    0, corresponding to  0=0, and using
the next meigenvectors for embedding graph nodes in an
m-dimensional space, xxxi![   1(i),···,   m(i)]
Coupled Laplacian. The complete pipeline to gener-
ate aligned Laplacian embeddings through graph coupling
is illustrated in Fig. 2. Let GTbe the graph of a target
3D point cloud and GS1,···,GSNthe ones of Ndifferent
sources. We construct a global graph, or coupled graph,
GC, by adding cross-connections separately between thevertices of the source, VT={xxxT
i}nT
i=1, and each of the
reference shapes, VSk={xxxSk
i}nSk
i=1with k=1,···,N.T o
include meaningful cross-connections, we ﬁrst perform a
rigid [ 19,20,45] or afﬁne [ 45] registration of the source ge-
ometries to align to the target. These methods are preferred
to a non-rigid registration because, when dealing with the
identiﬁcation of ﬁne local variations, they do not change the
relative position of the points inside a point-set and, there-
fore, the deformations are kept unchanged. After that, a
sub-set of vertices, FT⇢VT, is stochastically extracted
from the target geometry and their nearest correspondences
are searched in each of the aligned reference point clouds as
FSk={fffSk
j: arg min
xxxSk
i2VSkd2(xxxSk
i,fffT
j)|fffT
j2FT} (3)
with k=1,···,N. In this way, there is no constraint on the
original number points comprising each shape nor on their
initial coordinates systems. Furthermore, the cardinality of
the target sub-set, is chosen as a fraction of its total points,
|FT|=l·nT, where 0<l1. The cross-connection are
therefore added for each pair (fffSk
i,fffT
i),1i|FT|,
between the target and the k-th source. Finally, we ar-
range the vertex indices of the coupled graph such that they
are grouped for each individual geometry, and the whole
weighted adjacency matrix can be computed as in Eq. ( 1).
We deﬁne the Laplacian matrix of a global graph, con-
structed as describe above, as the Coupled Laplacian, LLLC2
Rn⇥n, where n=nT+PN
k=1nSk. Thanks to the vertex or-
dering of the coupled graph, the solution of the generalized
eigenproblem of Eq. ( 2) applied to the Coupled Laplacian,
with BBBC=diag([DDDT,DDDS1,···,DDDSN]), yields to coupled
eigenvectors {   C
i}n
i=0. These eigenvectors can then be split
into each single component of the coupled graph as
   C
i=[   T
i,   S1
i,···,   SN
i]T. (4)
3450
The eigenspaces restricted to the single geometries, ob-
tained thought the Coupled Laplacian, are intrinsically
aligned up to a certain component, depending of the fac-
torl, and the eigenvalues ordering issue is automatically
solved since the split eigenvectors are associated to the same
eigenvalues. The proof of this property for the ideal case of
perfect match and more theoretical aspects of the Coupled
Laplacian are reported in the Supplementary Material.
Shape Matching with Eigenmaps. The Coupled Lapla-
cian allows the generation of m-dimensional embeddings
aligned for the graph vertices of the target and reference
shapes,    T=(    T
1,···,   T
m)2RnT⇥mand   Sk=
(   Sk
1,···,   Skm)2RnSk⇥mfor1kN, respec-
tively. Therefore, a comparison of multiple geometries in
this higher dimensional spectral space yields to a proper
consideration of local structures. We consider in the fol-
lowing two possible applications of the coupled eigenmaps:
(1) a global shape matching score and (2) local similarity
scores. The ﬁrst one can be obtained by measuring the sim-
ilarity between the aligned eigenspaces through the Grass-
mann distance, dG(·,·)[74]. Nevertheless, it cannot be
computed directly, since we consider point clouds of ar-
bitrary size and we do not have point-to-point correspon-
dences. Hence, we restrict the distance computation only
to the set of cross-connected vertices, FTfor the target and
FSkfor the k-th reference. In order to get the reduced basis
restricted only to those coupled points, we perform a QR
decomposition of the restriction of the eigenmodes to the
cross-points. The best matching source is then given by
arg min
kdG(QQQT,QQQSk). (5)
where QQQTandQQQSkare obtained from the QR factorization
of   T(FT,:)and   Sk(FSk,:), respectively. This ﬁrst ap-
proach is used in the following to solve the BSE task by
using two source shapes, i.e. the reference bone of known
side and its contralateral mirrored version.
On the other hand, to obtain point-wise similarity scores
we propose to compare the m-dimensional embeddings of
the cross-connection vertices by using the cosine distance
function. In this case, we interpret the distance value as
the probability of local structural difference, where 0 means
that the two compared points have the same local structure.
4. Experiments
4.1. Experiment settings
Bone Side Estimation. The proposed global shape match-
ing score is used to perform automatic BSE. Assuming gen-
eral unknown initial frames, we used the Principal Com-
ponent Analysis (PCA) to generate a mirrored version of
the reference surface, i.e. a synthetic contralateral bone.
Namely, we identiﬁed that the bilateral symmetry of hu-
man and animal bodies is equivalent to a mirroring aroundTable 1. Summary of the point cloud bone structures collected for
the BSE benchmark. L and R stands for Left and Right, respec-
tively, and Sfor Sheep.
DatasetFemur Hip Tibia Fibula
LR LR LR LRHumanFisher et al. [18]18 19 20 20 -- --
SSM-Tibia [ 31] -- -- - 30 - 30
ICL [ 47] 35 35 -- 35 35 35 35SInternal [ 40] 18 18 -- 18 18 --
Total 71 72 20 20 53 83 35 65
the second principal component on the vast majority of
bones, such as the ones considered in this study. Hence,
given the three point clouds, target, source and mirrored
source, the Coupled Laplacian of Fig. 2can be applied.
More speciﬁcally, we selected the Random Sample Con-
sensus (RANSAC) [ 19], preceded by a spectral scaling, as
rigid registration method to handle varying bone lengths
without altering local structures. The scaling is performed
using only the information carried by the Fiedeler vector,
i.e. the eigenvector    1corresponding to the ﬁrst non-zero
eigenvalue  1. A rough estimation of the bones length, in-
dependently of the Euclidean frame, is given by the dis-
tance between the points corresponding to minimum and
maximum values of the Fiedler vectors. Thanks to that,
one of the two bones can be scaled in order to match the
length of the other and improve the RANSAC registra-
tion. The three aligned m-dimensional embeddings, derived
from the eigendecomposition of the Coupled Laplacian, are
then used as in Eq. ( 5) to retrieve the best matching source
and, consequently, the target side. Note that, the proposed
BSE method is fully independent of the target and reference
frames and therefore can be applied directly on the segmen-
tation obtained from a medical image, without any previous
knowledge, in a fully automated pipeline. In alternative,
one can using two different bone references, one left and
one right, avoiding the mirroring step, or apply the mirror-
ing on the target shape while letting the source unchanged.
Full details of the described algorithm are provided in the
Supplementary Material.
We generated a benchmark to test the BSE task by col-
lecting several bone surface point cloud data from public
datasets [ 18,31,47]. Namely, from Fisher et al. [18] we
extracted Femur and Hip structures, from SSM-Tibia [ 31]
only right Tibia and Fibula, and from the Imperial College
London (ICL) [ 47] we collected Femur, Tibia and Fibula
point clouds. The detailed composition of the benchmark
is reported in Tab. 1. Such a variety of shapes, which
are acquired using different methods, makes the task more
challenging, including some intra-clinic variability. In our
experiments, for a given bone class, we performed cross-
testing by selecting each shape once as source and the others
3451
Table 2. Anomaly localization results. The area under the PRO curve is reported for an integration limit of 0.3for each evaluated method
and dataset category. GAN, AE and VM results are provided by Bergmann et al. [7]. Moreover, we include the results obtained by
restricted GPS [ 55], eigenfunctions (Hist) [ 42,60] and Euclidean matching and MAP [ 39]. All the matching methods are applied after
afﬁne CPD registration, when not speciﬁed, or CMM + CPD Non-Rigid ( NR) registration. The subsctipt on a method indicates the number
of eigenmaps used. The overall best performing methods are highlighted in boldface, while the bests for each category are underlined.
Method BagelCable
GlandCarrot Cookie Dowel Foam Peach Potato Rope Tire Mean "3D RGBVM 0.388 0.321 0.194 0.570 0.408 0.282 0.244 0.349 0.268 0.331 0.335
GAN 0.421 0.422 0.778 0.696 0.494 0.252 0.285 0.362 0.402 0.631 0.474
AE 0.432 0.158 0.808 0.491 0.841 0.406 0.262 0.216 0.716 0.478 0.4813D OnlyGAN 0.111 0.072 0.212 0.174 0.160 0.128 0.003 0.042 0.446 0.075 0.143
AE 0.147 0.069 0.293 0.217 0.207 0.181 0.164 0.066 0.545 0.142 0.203
VM 0.280 0.374 0.243 0.526 0.485 0.314 0.199 0.388 0.543 0.385 0.374
Euclidean ( NR) 0.404 0.623 0.731 0.366 0.771 0.303 0.590 0.772 0.697 0.583 0.584
GPS 100[55] 0.452 0.616 0.695 0.364 0.738 0.471 0.659 0.844 0.647 0.651 0.613
GPS 200[55] 0.465 0.621 0.690 0.363 0.739 0.480 0.672 0.833 0.653 0.670 0.619
Hist 100[60] 0.476 0.629 0.703 0.365 0.744 0.473 0.661 0.840 0.647 0.693 0.623
MAP 200[39] 0.481 0.630 0.694 0.399 0.742 0.497 0.653 0.832 0.649 0.675 0.625
Hist 200[60] 0.491 0.629 0.698 0.351 0.746 0.501 0.663 0.841 0.652 0.695 0.627
Euclidean 0.655 0.631 0.743 0.615 0.803 0.528 0.726 0.875 0.762 0.695 0.703
Ours 100 0.669 0.642 0.808 0.714 0.812 0.582 0.748 0.897 0.750 0.733 0.736
Ours 200 0.702 0.630 0.728 0.735 0.812 0.701 0.780 0.914 0.767 0.713 0.748
Table 3. Accuracy [%] of human BSE. All the matching methods
are applied after RANSAC registration with spectral scaling, when
not speciﬁed, or CMM + CPD Non-Rigid ( NR) registration. The
overall best performing methods are highlighted in boldface.
Method Femur Hip Fibula Tibia Mean "
Chamfer ( NR) 56.58 86.58 57.89 74.74 68.95
Hausdorff ( NR) 57.37 87.63 59.47 73.68 69.54
Hausdorff 73.52 97.95 59.30 72.52 75.82
Chamfer 71.64 98.65 64.62 74.47 77.35
FPFH [ 57] 68.88 96.67 66.69 78.35 77.65
MAP 20[39] 76.05 98.54 71.32 74.21 80.13
Hist 20[60] 77.63 98.42 69.47 77.37 80.72
Ours 20 78.79 98.78 71.28 78.46 81.83
Ours 10 79.68 97.76 73.47 78.66 82.39
as targets on which the side has to be inferred. Therefore,
the average accuracy of all the experiments, achieved when
predicting the correct body side, i.e. binary classiﬁcation,
takes into account the variability of the source shape. The
robustness of the method with respect to the reference is
discussed in the Supplementary Material.
Anomaly Localization. We tested the proposed ap-
proach for the 3D anomaly detection task in the MVTec
3D-AD dataset [ 7]. This recent dataset was designed for
the unsupervised detection of anomalies in point clouds of
industrially manufactured products. It contains over 4000
high-resolution 3D scans of 10 object categories. In our ex-
periments, we chose one anomaly-free training sample for
each class as source and we used the point-wise distances
of the aligned eigenmaps between this shape and each tar-
get in the test set as anomaly scores. We performed the pre-00.10.20.30.40.56065707580Eigenmaps5102030
Fraction of Cross-EdgesAccuracy [%]Figure 3. Average BSE accuracy with respect to the fraction of
cross-edges used to build the Coupled Laplacian and the number
of eigenmaps used for matching.
registration using afﬁne Coherent Point Drift (CPD) [ 45],
which is more suited for objects like the ones included in
the MVTec 3D-AD, e.g. length and thickness variations are
better captured by an afﬁne registration rather than rigid.
In order to speed-up the computation, we pre-processed
the point clouds by removing their ﬂat backgrounds with
a threshold on the z-axis after a 3-dimensional PCA and,
without losing generality, we sub-sampled the number of
foreground points to a maximum of 13000 . Finally, to com-
pare the obtained anomaly scores with the Ground Truth
(GT) image, we projected back the points to the original 2D
plane and, if any sub-sampling was performed, we applied
a dilation with a structuring element of size the inverse of
the sampling factor.
3452
 = 100
 = 200  = 300 
Anomaly (GT) Anomaly Score
Target
Source Anomaly-Free
HoleOpen
Crack
ContaminationFigure 4. Graphical comparison of 3D anomaly localization using different numbers of aligned eigenmaps, m. Tuning the dimension of the
embeddings computed with the Coupled Laplacian, it is possible to decide the extent and size of local surface differences that are detected.
4.2. Experiment results
Bone Side Estimation. In Fig. 3, the average accuracy of
BSE is depicted based on the fraction of artiﬁcial cross-
edges added to create the coupled graph and the dimen-
sion of the spectral embeddings, landm, respectively. We
can observe that the more coupled eigenmaps we aim to
utilize for computing a global similarity score, the greater
the need for additional cross-connections to ensure the re-
liability of the results. This occurs because, when graphs
are weakly coupled with only a few cross-connections, the
Coupled Laplacian captures limited intra-shape characteris-
tics and predominantly emphasizes individual local geome-
tries. In fact, when l=0and therefore the coupled graph is
not fully connected, the eigenmaps obtained using the Cou-
pled Laplacian are equivalent to the ones computed inde-
pendently on each single graph, if the eigenvalues are the
same (proof in the Supplmentary Material). On the other
hand, not too many cross-edges, nor eigenmaps, are needed
to obtain meaningful global matching scores and achieve
good performances in the BSE task. In Tab. 3a quantitative
comparison with other methods of human BSE accuracy is
reported. For a fair comparison, all methods are performed
after RANSAC registration of the sources. Hausdorff and
Chamfer discrepancies are calculated on the Euclidean co-
ordinates of the points, for completeness, also in case of
2-Step non-rigid GMM + CPD registration ( 2000 x slower
than RANSAC). Our method, using 10and20eigenmodes
with l=0.5fraction of cross-connections, outperforms the
other techniques achieving higher accuracy both on the sin-
gle bones and in average. Hence, the description provided
by the aligned eigenmaps, obtained with Coupled Lapla-
cian, is more aware of local details than the other methods.
Anomaly Localization. Tab. 2lists quantitative resultsof each evaluated method for the localization of anoma-
lies. For each category, the normalized area under the Per-
Region Overlap (PRO) curve with an upper integration limit
of0.3[7], as well as, the mean performance, are reported.
Performance of Generative Adversarial Network (GAN),
Autoencoder (AE) and Variation Model (VM) on the same
test set are provided by the dataset authors [ 7]. Further-
more, we tested restricted GPS [ 55], eigenmaps histogram
matching [ 42,60], MAP [ 39] and our method, all with the
same pre-processing and source shapes, using 100and200
eigenmaps. In order to obtain denser and more precise
anomaly localization, the coupled graph is built using the
whole set of points as cross-connections, i.e. l=1. Fur-
thermore, we include the result obtained using as anomaly
score for each target point the normalized Euclidean dis-
tance of the nearest point in the source geometry, both using
rigid and non-rigid registration. Our method, using only 3D
information, outperforms all the other techniques. More-
over, we obtained better results than deep-learning meth-
ods having RGB and Depth in combination as input. Inter-
estingly, the point-wise similarity computed on eigenmaps
not properly aligned (GPS and Hist) is worst than just con-
sidering Euclidean distances between points of registered
shapes, making worthless the computation of spectral em-
beddings. In Fig. 4we compare the qualitative results ob-
tained using different numbers of eigenmaps to score the
point-wise similarities. Using a smaller m, the proposed
technique is prone to individuate only small regions with
highly dissimilar local geometries. By increasing the size
of the spectral embeddings, we can identify larger and more
subtle surface differences, even if they are not necessarily
classiﬁed as anomalies in the GT. For instance, the potato
and bagel surfaces have some natural irregularities, with re-
3453
EuclideanLaplacian
Target
Anomaly (GT)Source  Anomaly-Free 
Anomaly Score
Cut
0CombinedBent
Figure 5. Comparison of the anomaly score obtained using the
Coupled Laplacian technique, with m=2 0 0 andl=1, and
Euclidean distance, both after afﬁne CPD alignment.
spect to the source, that are not highlighted using 100and
200-dimensional embeddings, but are instead detected with
300eigenmaps. This concept is linked to the modal length ,
which we deﬁne in the Supplementary Material. The trade-
off between number of maps and extent of differences de-
tected is interesting to tune the method to other tasks requir-
ing speciﬁc attention to identify surface dissimilarities.
Ablation Study. To further motivate the preference for
Coupled Laplacian spectral space over the Euclidean one,
in Fig. 5, we display comparisons of point-wise distances
(anomaly scores) between source and target in both spaces,
after the same registration. In the ﬁrst and second row the
better resistance to noise and outliers in the spectral space
is highlighted. The bending of the cable gland, i.e. the
anomaly, is barely detected in the Euclidean space because
of noisy points on the back. Instead, with the aligned eigen-
maps comparison, the anomaly, as well as the noise, is cor-
rectly localized. This is because both are local differences,
with respect to the reference, and, therefore, they can be
easily captured with coupled eigenmaps. In addition, in the
third row, we show that our technique provides a sharper
anomaly split of the cookie point cloud, which simpliﬁes
the anomaly detection task. Nevertheless, the usage of the
proposed landmarks-free Coupled Laplacian is limited to
tasks in which a correspondence between target and source
shapes can be deﬁned by mean of a registration process.
Problems including graph isomorphism, such as articulated
shape matching [ 42,60], or non-rigid shape matching, can
be still solved using our method, without relying on the rigid
alignment, if some cross-connection are deﬁned a-priori. In
this case, landmarks and their neighbouring points would be
most likely the easiest option to connect separate graphs and
obtain aligned spectral embeddings for further processing.
Moreover, a wrong registration of the shapes, due to ran-
domness and errors in the selected registration algorithm,
may affect the alignment of the m-dimensional embeddingsderived from the Coupled Laplacian. We report here some
statistics on registration failures in BSE (failure rate [%] /
BSE accuracy on failures [%]), using different references,
for femur 6.84 ±7.82 / 96.67 ±11.30 (high symmetry)
and hip 0.0 ±0.0 (low symmetry). Moreover, to test ro-
bustness, we added white Gaussian rotation and translation
noise, i.i.d. in the 3 axis post-registration, obtaining (Rot.
SD [ ] / Trans. SD [mm] / Acc. Drop [%]): 2.5 / 5 / 8.16
- 5 / 5 / 15.13 - 7.5 / 10 / 18.16. Given the low registration
failure rates and high robustness to noise, we can rely on the
proposed coupling algorithm, making the method indepen-
dent of the acquisition frames. Moreover, the method can
well generalize to any chiral shape matching problem and
to tasks like identiﬁcation of topological noise in graphs and
partial matching (see example in Supplementary Material).
5. Conclusions
We presented a versatile method to perform 3D rigid point
cloud matching, both globally and locally, by using aligned
eigenspaces for two or more similar shapes without prior
knowledge on the local frames or specif markers on them.
The introduction of the Coupled Laplacian operator en-
ables the generation of aligned eigenmaps relying on cross-
connections added between graphs of registered geometries.
We introduced a novel task consisting in the automatic de-
tection of a bone side, i.e. Bone Side Estimation (BSE), and
we proposed a benchmark to test it. Leveraging global sim-
ilarities of eigenmaps derived from the Coupled Laplacian,
we deﬁne a full pipeline to perform BSE on arbitrary bone
surfaces segmented from a generic medical image. More-
over, we tested the ability of the proposed method in captur-
ing local surface differences by performing 3D anomaly de-
tection on the MVTec 3D-AD dataset. The proposed tech-
nique outperforms other methods on the two tasks, therefore
capturing better both global and local similarities, thanks
to the matching performed on correctly aligned spectral
spaces. Beside the applications showcased here, we believe
that our work can help several tasks in many ﬁelds in which
the localization of local difference is crucial for matching,
detection or retrieval. Future extensions could explore gen-
eralizations of the technique, not only for rigid matching
but also to address challenges such as graph isomorphism.
This approach opens new avenues for advancing the State-
of-The-Art in 3D shape analysis and matching techniques.
6. Acknowledgements
This project has received funding from the European
Union’s Horizon 2020 research and innovation programme
under the Marie Skłodowska-Curie grant agreement No
945304-Cofund AI4theSciences hosted by PSL University.
This work was granted access to the HPC/AI resources of
IDRIS under the allocation 2022-AD011013902 made by
GENCI.
3454
References
[1]Mathieu Aubry, Ulrich Schlickewei, and Daniel Cremers.
The wave kernel signature: A quantum mechanical approach
to shape analysis. In 2011 IEEE International Conference
onComputer Vision Workshops (ICCV Workshops), pages
1626–1633, Barcelona, Spain, 2011. IEEE.
[2]Ivan Bandovic, Matthew R. Holme, Asa C. Black, and Ben-
nett Futterman. Anatomy, Bone Markings. In StatPearls.
StatPearls Publishing, Treasure Island (FL), 2023.
[3]Zachary M C Baum, Yipeng Hu, and Dean C Barratt. Real-
time multimodal image registration with partial intraoper-
ative point-set data. Medical Image Analysis, 74:102231,
2021.
[4]Mikhail Belkin and Partha Niyogi. Laplacian Eigenmaps for
Dimensionality Reduction and Data Representation. Neural
Computation, 15(6):1373–1396, 2003.
[5]S. Belongie, J. Malik, and J. Puzicha. Shape matching and
object recognition using shape contexts. IEEE Transactions
onPattern Analysis andMachine Intelligence, 24(4):509–
522, 2002. Conference Name: IEEE Transactions on Pattern
Analysis and Machine Intelligence.
[6]Paul Bergmann and David Sattlegger. Anomaly Detection in
3D Point Clouds using Deep Geometric Descriptors. In 2023
IEEE/CVF Winter Conference onApplications ofComputer
Vision (WACV), pages 2612–2622, Waikoloa, HI, USA,
2023. IEEE.
[7]Paul Bergmann, Xin Jin, David Sattlegger, and Carsten Ste-
ger. The MVTec 3D-AD Dataset for Unsupervised 3D
Anomaly Detection and Localization. In Proceedings of
the17th International Joint Conference onComputer Vision,
Imaging andComputer Graphics Theory andApplications,
pages 202–213, 2022. arXiv:2112.09045 [cs].
[8]P.J. Besl and Neil D. McKay. A method for registration
of 3-D shapes. IEEE Transactions onPattern Analysis and
Machine Intelligence, 14(2):239–256, 1992. Conference
Name: IEEE Transactions on Pattern Analysis and Machine
Intelligence.
[9]S. Bickel, B. Schleich, and S. Wartzack. A Novel Shape
Retrieval Method for 3D Mechanical Components Based on
Object Projection, Pre-Trained Deep Learning Models and
Autoencoder. Computer-Aided Design, 154:103417, 2023.
[10] Tolga Birdal and Slobodan Ilic. Point Pair Features Based
Object Detection and Pose Estimation Revisited. In 2015
International Conference on3DVision, pages 527–535,
2015.
[11] Michael M. Bronstein and Iasonas Kokkinos. Scale-invariant
heat kernel signatures for non-rigid shape recognition. In
2010 IEEE Computer Society Conference onComputer
Vision andPattern Recognition, pages 1704–1711, 2010.
ISSN: 1063-6919.
[12] Michael C. Corballis. Bilaterally Symmetrical: To Be or Not
to Be? Symmetry, 12(3):326, 2020. Number: 3 Publisher:
Multidisciplinary Digital Publishing Institute.
[13] Haowen Deng, Tolga Birdal, and Slobodan Ilic. PPF-
FoldNet: Unsupervised Learning of Rotation Invariant 3D
Local Descriptors, 2018. arXiv:1808.10322 [cs].[14] Haowen Deng, Tolga Birdal, and Slobodan Ilic. PPFNet:
Global Context Aware Local Features for Robust 3D Point
Matching, 2018. arXiv:1802.02669 [cs].
[15] Ben Eckart, Kihwan Kim, and Jan Kautz. Fast and Accurate
Point Cloud Registration using Trees of Gaussian Mixtures,
2018. arXiv:1807.02587 [cs].
[16] Gil Elbaz, Tamar Avraham, and Anath Fischer. 3D Point
Cloud Registration for Localization Using a Deep Neu-
ral Network Auto-Encoder. In 2017 IEEE Conference on
Computer Vision andPattern Recognition (CVPR), pages
2472–2481, Honolulu, HI, 2017. IEEE.
[17] Francisco Figueroa, David Figueroa, Rodrigo Guiloff, Sven
Putnis, Brett Fritsch, and Minerva Itriago. Navigation in
anterior cruciate ligament reconstruction: State of the art.
Journal ofISAKOS, 8(1):47–53, 2023.
[18] Maximilian C. M. Fischer, Sonja A. G. A. Grothues, Ju-
liana Habor, Mat ´ıas de la Fuente, and Klaus Radermacher. A
robust method for automatic identiﬁcation of femoral land-
marks, axes, planes and bone coordinate systems using sur-
face models. Scientiﬁc Reports, 10(1):20859, 2020. Num-
ber: 1 Publisher: Nature Publishing Group.
[19] Martin A. Fischler and Robert C. Bolles. Random sample
consensus: a paradigm for model ﬁtting with applications to
image analysis and automated cartography. Communications
oftheACM, 24(6):381–395, 1981.
[20] Wei Gao and Russ Tedrake. FilterReg: Robust and Ef-
ﬁcient Probabilistic Point-Set Registration using Gaussian
Filter and Twist Parameterization, 2019. arXiv:1811.10136
[cs].
[21] Yang Gao, Honglin Yuan, Tao Ku, Remco C. Veltkamp,
Georgios Zamanakos, Lazaros Tsochatzidis, Angelos Ama-
natiadis, Ioannis Pratikakis, Aliki Panou, Ioannis Romanelis,
Vlassis Fotis, Gerasimos Arvanitis, and Konstantinos Mous-
takas. SHREC 2023: Point cloud change detection for city
scenes. Computers &Graphics, 115:35–42, 2023.
[22] Song Ge and Guoliang Fan. Articulated Non-Rigid Point Set
Registration for Human Pose Estimation from 3D Sensors.
Sensors, 15(7):15218–15245, 2015. Number: 7 Publisher:
Multidisciplinary Digital Publishing Institute.
[23] Benyamin Ghojogh, Ali Ghodsi, Fakhri Karray, and Mark
Crowley. Laplacian-Based Dimensionality Reduction In-
cluding Spectral Clustering, Laplacian Eigenmap, Local-
ity Preserving Projection, Graph Embedding, and Diffusion
Map: Tutorial and Survey, 2022. arXiv:2106.02154 [cs,
stat].
[24] Zan Gojcic, Caifa Zhou, Jan D. Wegner, and Andreas
Wieser. The Perfect Match: 3D Point Cloud Matching With
Smoothed Densities. In 2019 IEEE/CVF Conference on
Computer Vision andPattern Recognition (CVPR), pages
5540–5549, Long Beach, CA, USA, 2019. IEEE.
[25] Yulan Guo, Ferdous Sohel, Mohammed Bennamoun, Min
Lu, and Jianwei Wan. Rotational Projection Statistics
for 3D Local Surface Description and Object Recognition.
International Journal ofComputer Vision, 105(1):63–86,
2013. arXiv:1304.3192 [cs].
[26] Yulan Guo, Mohammed Bennamoun, Ferdous Sohel, Min
Lu, Jianwei Wan, and Ngai Ming Kwok. A Comprehen-
3455
sive Performance Evaluation of 3D Local Feature Descrip-
tors. International Journal ofComputer Vision, 116(1):66–
89, 2016.
[27] G´abor Holl ´o and Mih ´aly Nov ´ak. The manoeuvrability hy-
pothesis to explain the maintenance of bilateral symmetry in
animal evolution. Biology Direct, 7(1):22, 2012.
[28] Jiaxi Hu and Jing Hua. Salient spectral geometric features
for shape matching and retrieval. TheVisual Computer, 25
(5):667–675, 2009.
[29] Haibin Huang, Evangelos Kalogerakis, Siddhartha Chaud-
huri, Duygu Ceylan, Vladimir G. Kim, and Ersin Yumer.
Learning Local Shape Descriptors from Part Correspon-
dences With Multi-view Convolutional Networks, 2017.
arXiv:1706.04496 [cs].
[30] Bing Jian and Baba C. Vemuri. Robust Point Set Registra-
tion Using Gaussian Mixture Models. IEEE Transactions
onPattern Analysis andMachine Intelligence, 33(8):1633–
1645, 2011. Conference Name: IEEE Transactions on Pat-
tern Analysis and Machine Intelligence.
[31] Meghan Keast, Jason Bonacci, and Aaron Fox. Geometric
variation of the human tibia-ﬁbula: a public dataset of tibia-
ﬁbula surface meshes and statistical shape model. PeerJ, 11:
e14708, 2023. Publisher: PeerJ Inc.
[32] Kazuma Kobayashi, Lin Gu, Ryuichiro Hataya, Takaaki
Mizuno, Mototaka Miyake, Hirokazu Watanabe, Masamichi
Takahashi, Yasuyuki Takamizawa, Yukihiro Yoshida,
Satoshi Nakamura, Nobuji Kouno, Amina Bolatkan, Yusuke
Kurose, Tatsuya Harada, and Ryuji Hamamoto. Sketch-
based Medical Image Retrieval, 2023. arXiv:2303.03633
[cs].
[33] Adriaan Lambrechts, Roel Wirix-Speetjens, Frederik Maes,
and Sabine Van Huffel. Artiﬁcial Intelligence Based Patient-
Speciﬁc Preoperative Planning Algorithm for Total Knee
Arthroplasty. Frontiers inrobotics andAI, 9:840282, 2022.
[34] Liang Li, Ming Yang, Chunxiang Wang, and Bing Wang.
Rigid Point Set Registration Based on Cubature Kalman
Filter and Its Application in Intelligent Vehicles. IEEE
Transactions onIntelligent Transportation Systems, 19(6):
1754–1765, 2018. Conference Name: IEEE Transactions
on Intelligent Transportation Systems.
[35] Zhouhui Lian, Afzal Godil, Benjamin Bustos, Mohamed
Daoudi, Jeroen Hermans, Shun Kawamura, Yukinori Kurita,
Guillaume Lavou ´e, Hien Van Nguyen, Ryutarou Ohbuchi,
Yuki Ohkita, Yuya Ohishi, Fatih Porikli, Martin Reuter, Ivan
Sipiran, Dirk Smeets, Paul Suetens, Hedi Tabia, and Dirk
Vandermeulen. A comparison of methods for non-rigid 3D
shape retrieval. Pattern Recognition, 46(1):449–461, 2013.
[36] Z. Lian, J. Zhang, S. Choi, H. ElNaghy, J. El-Sana, T. Fu-
ruya, A. Giachetti, R. A. Guler, L. Lai, C. Li, H. Li, F. A.
Limberger, R. Martin, R. U. Nakanishi, A. P. Neto, L. G.
Nonato, R. Ohbuchi, K. Pevzner, D. Pickup, P. Rosin, A.
Sharf, L. Sun, X. Sun, S. Tari, G. Unal, and R. C. Wilson.
Non-rigid 3D shape retrieval. In Proceedings ofthe2015
Eurographics Workshop on3DObject Retrieval, pages 107–
120, Goslar, DEU, 2015. Eurographics Association.
[37] Eyal Lotan, Charlotte Tschider, Daniel K. Sodickson,
Arthur L. Caplan, Mary Bruno, Ben Zhang, and Yvonne W.Lui. Medical Imaging and Privacy in the Era of Artiﬁcial
Intelligence: Myth, Fallacy, and the Future. Journal ofthe
American College ofRadiology :JACR, 17(9):1159–1162,
2020.
[38] David G. Lowe. Distinctive Image Features from Scale-
Invariant Keypoints. International Journal ofComputer
Vision, 60(2):91–110, 2004.
[39] Jiangyan Ma, Yifei Wang, and Yisen Wang. Laplacian Can-
onization: A Minimalist Approach to Sign and Basis Invari-
ant Spectral Embedding, 2024. arXiv:2310.18716 [cs].
[40] Deyo Maeztu Redin, Julien Caroux, Pierre-Yves Rohan,
H´el`ene Pillet, Alexia Cermolacce, Julien Trnka, Mathieu
Manassero, V ´eronique Viateau, and Laurent Cort ´e. A wear
model to predict damage of reconstructed ACL. Journal
oftheMechanical Behavior ofBiomedical Materials, page
105426, 2022.
[41] Baraka Maiseli, Yanfeng Gu, and Huijun Gao. Recent devel-
opments and trends in point set registration methods. Journal
ofVisual Communication andImage Representation, 46:95–
106, 2017.
[42] Diana Mateus, Radu Horaud, David Knossow, Fabio Cuz-
zolin, and Edmond Boyer. Articulated Shape Matching Us-
ing Laplacian Eigenfunctions and Unsupervised Point Reg-
istration. In 2008 IEEE Conference onComputer Vision and
Pattern Recognition, pages 1–8, 2008. arXiv:2012.07340
[cs].
[43] Russell Merris. Laplacian matrices of graphs: a sur-
vey.Linear Algebra anditsApplications, 197-198:143–176,
1994.
[44] Kento Morita, Syoji Kobashi, Kaori Kashiwa, Hiroshi
Nakayama, Shunichiro Kambara, Masakazu Morimoto,
Shinichi Yoshiya, and Satoru Aikawa. Computer-aided Sur-
gical Planning of Anterior Cruciate Ligament Reconstruc-
tion in MR Images. Procedia Computer Science, 60:1659–
1667, 2015.
[45] Andriy Myronenko and Xubo Song. Point-Set Regis-
tration: Coherent Point Drift. IEEE Transactions on
Pattern Analysis andMachine Intelligence, 32(12):2262–
2275, 2010. arXiv:0905.2635 [cs].
[46] Thao Nguyen, Nakul Gopalan, Roma Patel, Matt Cor-
saro, Ellie Pavlick, and Stefanie Tellex. Robot Object Re-
trieval with Contextual Natural Language Queries, 2020.
arXiv:2006.13253 [cs].
[47] Daniel Nolte, Chui Kit Tsang, Kai Yu Zhang, Ziyun Ding,
Angela E. Kedgley, and Anthony M. J. Bull. Non-linear
scaling of a musculoskeletal model of the lower limb using
statistical shape models. Journal ofBiomechanics, 49(14):
3576–3581, 2016.
[48] Abdol Hamid Pilevar. CBMIR: Content-based Image Re-
trieval Algorithm for Medical Image Databases. Journal of
Medical Signals andSensors, 1(1):12–18, 2011.
[49] Charles R. Qi, Hao Su, Kaichun Mo, and Leonidas J. Guibas.
PointNet: Deep Learning on Point Sets for 3D Classiﬁcation
and Segmentation, 2017. arXiv:1612.00593 [cs].
[50] Charles R. Qi, Li Yi, Hao Su, and Leonidas J. Guibas. Point-
Net++: Deep Hierarchical Feature Learning on Point Sets in
a Metric Space, 2017. arXiv:1706.02413 [cs].
3456
[51] Martin Reuter, Franz-Erich Wolter, and Niklas Peinecke.
Laplace-spectra as ﬁngerprints for shape matching. In
Proceedings ofthe2005 ACM symposium onSolid and
physical modeling, pages 101–106, New York, NY, USA,
2005. Association for Computing Machinery.
[52] Martin Reuter, Franz-Erich Wolter, and Niklas Peinecke.
Laplace–Beltrami spectra as ‘Shape-DNA’ of surfaces and
solids. Computer-Aided Design, 38(4):342–366, 2006.
[53] Martin Reuter, Silvia Biasotti, Daniela Giorgi, Giuseppe
Patan `e, and Michela Spagnuolo. Discrete Laplace–Beltrami
operators for shape analysis and segmentation. Computers
&Graphics, 33(3):381–390, 2009.
[54] R. Rostami, F. S. Bashiri, B. Rostami, and Z. Yu. A Sur-
vey on Data-Driven 3D Shape Descriptors. Computer
Graphics Forum, 38(1):356–393, 2019. eprint:
https://onlinelibrary.wiley.com/doi/pdf/10.1111/cgf.13536.
[55] Raif M. Rustamov. Laplace-Beltrami Eigenfunctions
forDeformation Invariant Shape Representation. The
Eurographics Association, 2007. Accepted: 2014-01-
29T09:43:15Z ISSN: 1727-8384.
[56] Radu Bogdan Rusu, Nico Blodow, Zoltan Csaba Marton,
and Michael Beetz. Aligning point cloud views using per-
sistent feature histograms. In 2008 IEEE/RSJ International
Conference onIntelligent Robots andSystems, pages 3384–
3391, 2008. ISSN: 2153-0866.
[57] Radu Bogdan Rusu, Nico Blodow, and Michael Beetz.
Fast Point Feature Histograms (FPFH) for 3D registration.
In2009 IEEE International Conference onRobotics and
Automation, pages 3212–3217, Kobe, 2009. IEEE.
[58] Samuele Salti, Federico Tombari, and Luigi Di Stefano.
SHOT: Unique signatures of histograms for surface and tex-
ture description. Computer Vision andImage Understanding,
125:251–264, 2014.
[59] Dimple A. Shajahan, Mukund Varma T, and Ramanathan
Muthuganapathy. Point Transformer for Shape Classiﬁca-
tion and Retrieval of 3D and ALS Roof PointClouds, 2021.
arXiv:2011.03921 [cs].
[60] Avinash Sharma, Radu Horaud, and Diana Mateus. 3D
Shape Registration Using Spectral Graph Embedding and
Probabilistic Matching, 2021. arXiv:2106.11166 [cs, stat].
[61] Martin Sinko, Patrik Kamencay, Robert Hudec, and Miroslav
Benco. 3D registration of the point cloud data using ICP
algorithm in medical image analysis. In 2018 ELEKTRO,
pages 1–6, 2018.
[62] Jian Sun, Maks Ovsjanikov, and Leonidas Guibas. A Con-
cise and Provably Informative Multi-Scale Signature Based
on Heat Diffusion. Computer Graphics Forum, 28(5):1383–
1392, 2009.
[63] Sarah Tang and Afzal Godil. An evaluation of local shape
descriptors for 3D shape retrieval. In Three-Dimensional
Image Processing (3DIP) andApplications II, pages 217–
231. SPIE, 2012.
[64] Te Tang and Masayoshi Tomizuka. Track deformable objects
from point clouds with structure preserved registration. The
International Journal ofRobotics Research, 41(6):599–614,
2022. Publisher: SAGE Publications Ltd STM.[65] Johan W. H. Tangelder and Remco C. Veltkamp. A survey of
content based 3D shape retrieval methods. Multimedia Tools
andApplications, 39(3):441–471, 2008.
[66] Federico Tombari, Samuele Salti, and Luigi Di Stefano.
Unique shape context for 3d data description. In Proceedings
oftheACM workshop on3Dobject retrieval, pages 57–62,
New York, NY, USA, 2010. Association for Computing Ma-
chinery.
[67] Søren Toxvaerd. The Emergence of the Bilateral Symmetry
in Animals: A Review and a New Hypothesis. Symmetry,
13(2):261, 2021. Number: 2 Publisher: Multidisciplinary
Digital Publishing Institute.
[68] Yue Wang and Justin M. Solomon. Deep Closest Point:
Learning Representations for Point Cloud Registration,
2019. arXiv:1905.03304 [cs] version: 1.
[69] Yiqun Wang, Jianwei Guo, Dong-Ming Yan, Kai Wang,
and Xiaopeng Zhang. A Robust Local Spectral Descriptor
for Matching Non-Rigid Shapes With Incompatible Shape
Structures. In 2019 IEEE/CVF Conference onComputer
Vision andPattern Recognition (CVPR), pages 6224–6233,
Long Beach, CA, USA, 2019. IEEE.
[70] Martin Weinmann, Boris Jutzi, and Cl ´ement Mallet. Seman-
tic 3D scene interpretation: A framework combining optimal
neighborhood size selection with relevant features. ISPRS
Annals ofthePhotogrammetry, Remote Sensing andSpatial
Information Sciences, II-3:181–188, 2014.
[71] Hao Wu, Lincong Fang, Qian Yu, and Chengzhuan Yang.
Learning Robust Point Representation for 3D Non-Rigid
Shape Retrieval. IEEE Transactions onMultimedia, pages
1–15, 2023. Conference Name: IEEE Transactions on Mul-
timedia.
[72] Jin Xie, Guoxian Dai, Fan Zhu, Edward K. Wong, and Yi
Fang. DeepShape: Deep-Learned Shape Descriptor for 3D
Shape Retrieval. IEEE Transactions onPattern Analysis and
Machine Intelligence, 39(7):1335–1345, 2017. Conference
Name: IEEE Transactions on Pattern Analysis and Machine
Intelligence.
[73] Guoqing Xu and Weiwei Fang. Shape retrieval us-
ing deep autoencoder learning representation. In 2016
13th International Computer Conference onWavelet
Active Media Technology and Information Processing
(ICCWAMTIP), pages 227–230, 2016.
[74] Ke Ye and Lek-Heng Lim. Schubert Varieties and Dis-
tances between Subspaces of Different Dimensions. SIAM
Journal onMatrix Analysis andApplications, 37(3):1176–
1197, 2016.
[75] Zi Jian Yew and Gim Hee Lee. 3DFeat-Net: Weakly Su-
pervised Local 3D Features for Point Cloud Registration.
InComputer Vision –ECCV 2018, pages 630–646, Cham,
2018. Springer International Publishing.
[76] Kwang Moo Yi, Eduard Trulls, Vincent Lepetit, and Pas-
cal Fua. LIFT: Learned Invariant Feature Transform, 2016.
arXiv:1603.09114 [cs].
[77] Andy Zeng, Shuran Song, Matthias Nießner, Matthew
Fisher, Jianxiong Xiao, and Thomas Funkhouser. 3DMatch:
Learning Local Geometric Descriptors from RGB-D Recon-
structions, 2017. arXiv:1603.08182 [cs].
3457
[78] Cha Zhang and Tsuhan Chen. Efﬁcient feature extraction
for 2D/3D objects in mesh representation. In Proceedings
2001 International Conference onImage Processing (Cat.
No.01CH37205), pages 935–938 vol.3, 2001.
[79] H. Zhang, O. Van Kaick, and R. Dyer. Spectral Mesh
Processing. Computer Graphics Forum, 29(6):1865–1894,
2010.
3458
