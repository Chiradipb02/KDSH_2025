Flee the Flaw: Annotating the Underlying Logic of
Fallacious Arguments Through Templates and Slot-filling
Irfan Robbani1Paul Reisert2Naoya Inoue1,3Surawat Pothong1Cam√©lia Guerraoui4,3,5
Wenzhi Wang4,3Shoichi Naito6,4,3Jungmin Choi3Kentaro Inui7,4,3
1JAIST2Beyond Reason3RIKEN4Tohoku University
5INSA Lyon6Ricoh Company, Ltd.7MBZUAI
{robbaniirfan,naoya-i,spothong}@jaist.ac.jp beyond.reason.sp@gmail.com
{guerraoui.camelia.kenza.q4, wang.wenzhi.r7, naito.shoichi.t1}@dc.tohoku.ac.jp
jungmin.choi@riken.jp kentaro.inui@mbzuai.ac.ae
Abstract
Prior research in computational argumentation
has mainly focused on scoring the quality of
arguments, with less attention on explicating
logical errors. In this work, we introduce four
sets of explainable templates for common infor-
mal logical fallacies designed to explicate a fal-
lacy‚Äôs implicit logic. Using our templates, we
conduct an annotation study on top of 400 falla-
cious arguments taken from LOGIC dataset and
achieve a high agreement score (Krippendorf‚Äôs
Œ±of 0.54) and reasonable coverage (0.83). Fi-
nally, we conduct an experiment for detecting
the structure of fallacies and discover that state-
of-the-art language models struggle with de-
tecting fallacy templates (0.47 accuracy). To
facilitate research on fallacies, we make our
dataset and guidelines publicly available.
1 Introduction
Afallacy is an invalid or weak argument supported
by unsound reasoning (Hinton, 2020). The auto-
matic detection of fallacies has important applica-
tions, including providing constructive feedback
to learners in writing. The assessment of argu-
ment quality, including fallacy detection, is con-
sidered an important topic in the fields of com-
putational argumentation and argumentation min-
ing (Wachsmuth et al., 2017; Ke and Ng, 2019).
Previous work on quality assessment has focused
on numerical scoring (Carlile et al., 2018; Ke et al.,
2019) and fallacy type-labeling tasks (Jin et al.,
2022; Sourati et al., 2023a), without aiming to ana-
lyze fallacy logic structures , namely the representa-
tion of how given arguments are weak. In the field
of argumentation theory, a typology of invalid argu-
ments has been long studied and compiled into an
inventory (Walton, 1987; Bennett, 2012). The in-
ventory typically includes semi-formal definitions
and some examples for each type of fallacy. For
example, Faulty Generalization is a widely recog-
nized fallacy type, characterized by ‚ÄúDrawing a
(b) Argumentation Schemes (Walton 2008)Claim: ùë®should not be brought about.ùë®=further advanced coursesPremise: If ùë®is brought about,bad consequences will occur.
Premise ùëÉ‚Ä≤: ùë®‚Ä≤	SUPPRESS ùë™, GOOD(ùë™)ùë®‚Ä≤= NLP class, ùë™= GPAùë®‚Ä≤‚äÜùë®, but ùë®‚Ä≤=ùë®implicitly assumedFaulty Generalization(a) Fallacy Classification(Jin+ 2022; Sourati+ 2023; etc.)(b‚Äô) Argument Templates(Reisert+ 2018)Claim: BAD(ùë®)ùë®= further advanced coursesPremise ùëÉ: ùë®SUPPRESS ùë™, GOOD(ùë™)ùë™= GPASupportSupport(c) Fallacy Logic Structure (Our work)FallaciousSupport
OperationalizedScheme: Argument from Consequence
Template: Argument from Consequence-AT-S3
Template: Faulty Generalization #2Argument: I took an NLP class, an advanced course in Stanford. I suggest not taking further advanced coursesbecause they will hurt your GPA.Figure 1: Overview of our proposed fallacy logic struc-
ture. We extend (b‚Äô) existing argumentative represen-
tation (Reisert et al., 2018) consisting of Claim and
Premise Pby adding (c) Premise P‚Ä≤, which explains
what makes the argument fallacious. The example an-
notation shows: (i) the claim ‚Äú (A‚Ä≤=further advanced
courses ) are BAD‚Äù is supported by ‚Äú P:(A=further
advanced courses )SUPPRESS (C=GPA),aGOOD
thing‚Äù, and (ii) Pis then further supported by ‚Äú P‚Ä≤:
(A‚Ä≤=NLP class )SUPPRESS (C=GPA),aGOOD thing‚Äù,
where A‚Ä≤=NLP class (their own experience) is implicitly
generalized to A=further advanced courses (advanced
courses in general), which makes the overall argument
fallacious.
conclusion based on a small sample size, rather
than looking at statistics that are much more in
line with the typical or average situation.‚Äù (Bennett,
2012). The semi-formal definition is as follows:
‚Äú(i) Sample Sis taken from population P. (ii) Sam-
pleSis a very small part of population P. (iii)
1arXiv:2406.12402v1  [cs.CL]  18 Jun 2024Conclusion Cis drawn from sample Sand applied
to population P‚Äù. Although such inventory pro-
vides insights into how the analysis of fallacy logic
structure can be formulated as an NLP task, several
important questions remain: (i) How should the
annotation scheme for fallacy logic structure identi-
fication be designed? (ii) Can humans consistently
annotate fallacy logic structures? (iii) To what ex-
tent is the automatic identification of fallacy logic
structure a challenging task for machines?
To address this issue, we propose fallacy logic
structure identification , a new task for identifying
the underlying logical structure of fallacies. For
this task, we design an annotation scheme and con-
duct an annotation study to examine its feasibility.
The key idea behind our annotation scheme is to
enrich previous work on the argumentative struc-
ture with a fallacy structure from an inventory of
common fallacy types.
Consider the argument in Fig. 1, where the writer
persuades people notto take advanced courses at
Stanford because they claim it will hurt their GPA.
The claim is further supported by the writer‚Äôs own,
single experience based on their NLP class. This is
a faulty generalization caused by the writer implic-
itlyassuming that their single experience can be
generalized to everyone. Previous work in fallacy
identification (Sourati et al., 2023b; Jin et al., 2022)
would identify this argument as Faulty General-
ization (Fig. 1 (a)), but no additional information
such as logical structure or fallacious reasoning is
provided. Argumentation Schemes (Walton et al.,
2008), a well-known typology for the representa-
tion of arguments, would categorize this argument
asArgument from Consequence (Fig. 1 (b)), and
Reisert et al. (2018)‚Äôs Argument Templates , an oper-
ationalized version of Argumentation Schemes, rep-
resent this argument with a more fine-grained, logi-
cal representation by structured templates (Fig. 1
(b‚Äô)). To represent the committed fallacy structure,
our work further enriches this representation by
adding an additional premise that indicates how the
given argument is fallacious (Fig. 1 (c)).
Our main contributions are as follows:
‚Ä¢We conduct the first study of formulating logi-
cal fallacy structure by creating an inventory
of fallacy templates (¬ß3).
‚Ä¢We create the first dataset of fallacy logi-
cal structures which consists of 400 argu-
ments from LOGIC (Jin et al., 2022) anno-
tated with our templates (¬ß4). We publiclyrelease both the dataset and guidelines1. Our
dataset achieves high inter-annotator agree-
ment (Krippendorf‚Äôs Œ±of 0.54) and coverage
(0.83%).
‚Ä¢We show that the fallacy logic structure identi-
fication task poses a significant challenge for
state-of-the-art language models. (¬ß5).
2 Related Work
Fallacies Annotation Study Several studies ad-
dress creating benchmarks for fallacy identifica-
tion, including (Habernal et al., 2017) for game
facilitation and (Ruiz-Dolz and Lawrence, 2023)
for validating argumentation corpora. Particularly,
Jin et al. (2022) focus on logical fallacies within
climate change discourse, emphasizing the chal-
lenges posed by complex scientific data. They de-
veloped detailed annotation guidelines to aid in
consistent identification of fallacies within climate
arguments. Similarly, Goffredo et al. (2023) ana-
lyzed fallacious reasoning in U.S. presidential de-
bates, highlighting common fallacies. They em-
ployed advanced computational techniques and the
INCEpTION platform for structured annotation,
ensuring reliability through cross-verification and
Krippendorff‚Äôs Œ±. In addition to the current bench-
mark establishment, this research proposes bench-
mark resources aimed at capturing fallacy structure
rather than solely identifying fallacies. This re-
search fills the gap, extending previous work by
focusing on template annotation to capture the un-
derlying structure of fallacious arguments.
Argumentation Structure Argumentation the-
ory examines how arguments, including those
about daily exercise, are constructed and evaluated.
To begin with, (Stab and Gurevych, 2017) estab-
lishes methods for parsing argumentation structure
in persuasive essays by identifying and classify-
ing argument components and their relationships.
(Toulmin, 2003) provides a framework for analyz-
ing arguments by breaking them down into compo-
nents like Claim, Grounds, Warrant, and Rebuttal.
(Walton, 2013) focuses on specific argumentation
schemes, such as Argument from Analogy, which
compares similar situations to infer outcomes but
risks failure with irrelevant similarities (false anal-
ogy). The Argument from Consequence (Walton
1https://github.com/itsanonnymous/
fallacytemplate
2No template can be instantiated#1AA should not be brought about GOOD(C)XSUPPRESSSUPPORTFallacy of CredibilityPROMOTE#2#3#4#5A should not be brought about A should be brought about A should be brought about SUPPORTSUPPORTSUPPORTABAD(C)XSUPPRESSPROMOTEAGOOD(C)XPROMOTEPROMOTEABAD(C)XPROMOTEPROMOTENo template can be instantiated#1AA should not be brought about GOOD(C)SUPPRESSSUPPORTFalse CausalitySUPPORT#2#3#4#5A should be brought about A should not be brought about A should be brought about SUPPORTSUPPORTSUPPORTABAD(C)PROMOTEAGOOD(C)PROMOTEABAD(C)SUPPRESSAGOOD(C)RELATED TOSUPPORTABAD(C)RELATED TOSUPPORTAGOOD(C)RELATED TOSUPPORTABAD(C)RELATED TONo template can be instantiatedAA should be brought about GOOD(C)PROMOTESUPPORTFalse Dilemma#5A should be brought about A should be brought about A should be brought about SUPPORTSUPPORTABAD(C)SUPPRESSABAD(C)PROMOTE#1#2SUPPORTAGOOD(C)SUPPRESS#3#4¬¨AGOOD(C)SUPPRESSSUPPORT¬¨ABAD(C)PROMOTESUPPORT¬¨AGOOD(C)PROMOTESUPPORT¬¨ABAD(C)SUPPRESSSUPPORT
No template can be instantiated#1AA should not be brought about GOOD(C)SUPPRESSSUPPORTFaulty GeneralizationSUPPORT#2#3#4#5A should be brought about A should not be brought about A should be brought about SUPPORTSUPPORTSUPPORTABAD(C)PROMOTEAGOOD(C)PROMOTEABAD(C)SUPPRESSA|A‚ÄôGOOD(C|C‚Äô)SUPPRESSSUPPORTA|A‚ÄôBAD(C|C‚Äô)PROMOTESUPPORTA|A‚ÄôGOOD(C|C‚Äô)PROMOTESUPPORTA|A‚ÄôBAD(C|C‚Äô)SUPPRESSFigure 2: Our templates for annotating fallacious argument logical structure. We extend upon existing work (Walton
et al., 2008; Reisert et al., 2018), consisting of a conclusion (i.e., Ashould (not) be brought about ) and supporting
premise, by adding an additional supporting premise in bold which represents the committed fallacy logical structure.
et al., 2008) emphasizes potential outcomes of ac-
tions, often involving causality and appeals to con-
sequences. Evaluating it requires considering 1) the
connection between action and consequence, 2) the
quality of supporting evidence, and 3) whether op-
posing consequences have been addressed. Build-
ing on prior work on argument structure, particu-
larly the Argument from Consequence scheme (a
frequently used scheme by Walton), this research
addresses a gap by using argument templates, in-
spired by(Reisert et al., 2018) to capture the struc-
ture of fallacies within this scheme. This choice
is motivated by the scheme‚Äôs frequent use and its
potential for revealing fallacious arguments. Build-
ing on this potential, and inspired by (Reisert et al.,
2018) on templates, we address a gap by using tem-
plates to capture the structure of fallacies within the
Argument from the Consequence scheme. Previ-
ous work on Argument from Consequence demon-
strates high coverage in annotation efforts, further
supporting this approach.
3 Fallacy Logic Structure
3.1 Design Principles
To develop an annotation scheme for fallacy logic
structure, we adhere to three key criteria.
First, we require the annotation to be able toexplain the underlying structure of fallacy. We
extend the existing representation of arguments
(Fig. 1 (b‚Äô)) by an additional premise attached with
an explanation as to why it fallaciously supports
the original premise (Fig. 1 (c)).
Second, our annotation scheme must cover a
majority of fallacy types. We focus on the falla-
cies most commonly studied in computational ar-
gumentation, such as those in (Alhindi et al., 2023)
and (Helwe et al., 2023), whose statistics on fal-
lacy types guide our template design to match the
most frequent occurrences. We develop 20 new
templates covering four defective induction fallacy
types‚ÄìFallacy of Credibility, False Causality, False
Dilemma, and Faulty Generalization. An exam-
ple and more detailed explanation regarding four
defective induction fallacy types can be seen in
section A.2.
Third, our annotation scheme must utilise Reis-
ert et al. (2018) template selection and slot-filling
approach further simplifying annotation while re-
maining computationally friendly. As inspired by
the Argument from Consequence and employing
Reisert et al. (2018)‚Äôs work as a base scheme, the
template design captures both positive and negative
consequences within the scheme. This results in
two templates for each consequence type, along
3with a template addressing instances that cannot
be directly covered. This approach aims to pro-
vide rich information about fallacy structures while
simplifying the annotation process.
3.2 Representation of Core Arguments
The underlying structure of arguments has been rep-
resented previously with Walton et al. (2008)‚Äôs Ar-
gumentation Schemes, a set of roughly 60 schemes
which provide structure between argumentative
components such as a conclusion (i.e., claim) and
premise. An example of a common scheme, Argu-
ment from Negative Consequences, is as follows2:
‚Ä¢Premise ( P): If [ A] is brought about, bad
consequences will plausibly occur.
‚Ä¢Conclusion : Therefore, [ A] should not be
brought about.
Here, Ais a placeholder (i.e., slot-filler) represents
anaction andPsupports conclusion. For the ar-
gument in Fig. 1, we represent Argument from
Negative Consequence with [ A]=‚Äúfurther advanced
courses‚Äù.
Towards operationalizing Walton et al. (2008)‚Äôs
Argumentation Schemes into more fine-grained log-
ical representations, Reisert et al. (2018) developed
argument templates , an inventory of annotation-
friendly templates consisting of ingredients such as
placeholders. An example of an argument template
built on top of Argument from Negative Conse-
quences scheme is as follows:
‚Ä¢Premise ( P):[A]SUPPRESS aGOOD [C].
‚Ä¢Conclusion : [A] isBAD .
Both AandCrepresent action andconsequence
placeholders, respectively. GOOD andBAD repre-
sent the sentiment of each placeholder, and SUP-
PRESS represents the relation between AandC,
where SUPPRESS refers to preventing the conse-
quence (Hashimoto et al., 2012). Revisiting the
argument in Fig. 1, we can instantiate the argument
template with A=‚Äúfurther advanced courses‚Äù and
C=‚ÄúGPA‚Äù. Such argument templates are a simple,
efficient way to represent underlying logic.
As shown for Faulty Generalization fallacies in
Figure 2, argument templates were handcrafted
to allow for both Argument from Positive Con-
sequence ( Ashould be brought about ) and Argu-
ment from Negative Consequence ( Ashould not
2For readability, we represent placeholders in brackets.
Figure 3: Examples of template and slot-fillers from FtF
for Faulty Generalization.
be brought about ) with a supporting P‚Ä≤(grey) con-
sisting of positive (e.g., APROMOTE GOOD( C))
and negative (e.g., ASUPPRESS GOOD( C)) con-
sequences, respectively, where PROMOTE refers
to the triggering of the consequence (Hashimoto
et al., 2012). We build on top of this for adding
logical structure for fallacies.
3.3 Our Fallacy Template Inventory
For representing fallacy logical structure, we ex-
tend Walton et al. (2008) and Reisert et al. (2018)
by introducing a new premise P‚Ä≤which supports
premise P. Consider the following representation
for Faulty Generalization:
‚Ä¢Premise ( P):[A]SUPPRESS aGOOD [C].
‚Ä¢Premise (P‚Äô): [A‚Ä≤], a subset of A,SUPPRESS
aGOOD [C]
‚Ä¢Conclusion : [A] isBAD .
Here, on top of the argument template placeholders
AandC,P‚Ä≤includes a new placeholder A‚Ä≤, where
A‚Ä≤is an action and A‚Ä≤‚äÜA. The faulty generaliza-
tion is committed as a result of the argument consid-
ering A‚Ä≤to represent Aas a whole.Revisiting the ar-
gument in Fig. 1, we can instantiate the above with
A=‚Äúfurther advanced courses‚Äù, A‚Ä≤=‚ÄúNLP class‚Äù,
andC=‚ÄúGPA‚Äù.
Fig. 3 shows additional examples of template
instantiation with placeholders for each target fal-
lacy type, with our new premise P‚Ä≤. Using this
figure, we exemplify a complex Faulty General-
ization argument, where two subsets A‚Ä≤andC‚Ä≤
are considered. The main point is symbolized by
4A=‚Äúgarage‚Äù and C=‚Äúovercharged‚Äù, as the narrative
implies that the Ais notorious for C. Hence, it is
implicated that CisBAD and that A]PROMOTE
C. InP‚Ä≤,‚ÄôA‚Ä≤=‚Äúmechanic‚Äù and C‚Ä≤=‚Äúovercharged
her‚Äù are identified, where A‚Ä≤‚äÜAandC‚Ä≤‚äÜCand
A‚Ä≤PROMOTE C‚Ä≤. Therefore, the relation A‚Ä≤PRO-
MOTES C‚Ä≤supports the relation APROMOTE C,
so template #2 is selected.
4 Flee the Flaw (FtF) Dataset
We discuss the creation of our dataset Flee the
Flaw (henceforth, FtF). First, we use an existing
dataset of annotated fallacious arguments for cre-
ating our guidelines and building our inventory of
fallacy templates. We then conduct a full-fledged
annotation on top of 400 arguments.
4.1 Data Collection
To build a dataset of fallacious argument template
instantiations, we require fallacious arguments
which cover our target fallacy types. Therefore,
we use LOGIC (Jin et al., 2022), an English fallacy
dataset consisting of 2,449 fallacious arguments
spanned across multiple fallacy types, including
our four target template types. We sampled 400 ar-
guments (100 per target fallacy type) from LOGIC,
equally split between its development (LOGIC-
DEV 200) and training sets (LOGIC-TRAIN 200),
with 200 arguments each. Missing fallacy instances
in the development set were supplemented from the
training set, ensuring no overlap by segmenting the
training set before distribution.
4.2 Guideline Construction
We employed two expert annotators for guideline
development and annotation: a native English-
speaking postdoctoral researcher specializing in ar-
gument mining (who led guideline creation), and a
non-native English-speaking graduate student spe-
cializing in argumentation.
To create a set of guidelines and test annotation
feasibility, we conduct a multi-round pilot study on
top of LOGIC-DEV 200. Aside from the pilot study
itself, annotators did not go through any training
phase. Given that the LOGIC dataset has limited
fallacious arguments, our pilot study consisted of
200 instances (50 per fallacy type) for creating our
final guidelines, where the study began with an
initial set of guidelines for all fallacy types. For
each of the four fallacy types, annotators focused
on the 50 instances per each fallacy. For each type,we split up the instances to annotate (e.g., 10 out
of 50) using the latest updated set of guidelines,
where results were compared and discussed after
each round. Discussion consisted of findings and
whether annotators agree with each other‚Äôs anno-
tation. If there was a new finding or disagreement,
instances were discussed to reach a consensus and
guidelines were updated accordingly. The process
was repeated until all 200 instances in LOGIC-
DEV 200were annotated and the final annotation
guidelines were created.3
Reducing Annotation Complexities During
guideline construction, annotators found that multi-
ple templates could be instantiated for a single ar-
gument. In order to reduce annotation complexity,
the following conditions were created: i) preser-
vation of argument‚Äôs original, explicit intent , ii)
paraphrase arguments into Argument from Conse-
quences , and iii) preference of entities over events.
We demonstrate such conditions with the False
Dilemma argument: ‚Äú We either have to cut taxes
or leave a huge debt for our children. ‚Äù. Opposed
to selecting the entity A=‚Äútaxes ‚Äù which satisfies
the third condition, annotators were encouraged to
select the event A=‚Äúcut taxes ‚Äù as it maintains the
explicit intention of the argument, satisfying the
first condition. Given that this is a False Dilemma
fallacious argument which follows an either-or ,
the annotators satisfied the second condition by
considering that the argument can be thought of in
terms of argument from consequence, where the
conclusion ‚Äúcut taxes should be brought about‚Äù is
good as it suppresses the premise ‚Äúleave a huge
debt for our children‚Äù, a bad thing.
In addition to the above, it was discovered that
the fallacy type provided by LOGIC could be cat-
egorized into other, non-target fallacy types (e.g.,
Slippery Slope instead of Faulty Generalization ).
In such instances, annotators were instructed to an-
notate the instance considering its given type and
encouraged to apply template #5 if the template
instantiation could not be made.
4.3 Annotation Procedure
Given a fallacious argument, its fallacy type, and
our templates, the procedure for fallacious tem-
plate instantiation is as follows. First, annotators
select the appropriate template from the given set
of 5 templates. Next, annotators write in the nec-
3The final guidelines are made publicly available: https:
//github.com/itsanonnymous/fallacytemplate
5Figure 4: The distribution of fallacy templates in our FtF between one annotator (top row) and the other (bottom
row) for all 400 instances in our train and dev set, where each fallacy type consists of 100 instances. The x-axis
refers to the selected template, and y-axis refers to the frequency.
Fallacy Type GWET AC1 Krippendorff‚Äôs
Œ±
False Dilemma 0.63 0.44
Faulty Generalization 0.40 0.36
False Causality 0.71 0.65
Fallacy of Credibility 0.58 0.49
Average 0.57 0.54
Table 1: Template selection Inter-Annotator Agreement.
essary slot-fillers taken from the input argument.
Afterwards, annotators provide their confidence
level for instances in which they are not 100% con-
fident. Finally, annotators provide any necessary
comments to accompany the annotation. The result-
ing annotation of our fallacious templates on top of
LOGIC-DEV 200and LOGIC-TRAIN 200resulted
in FtF-DEV and FtF-TRAIN, respectively.
4.4 Statistics and Analysis
Inter-Annotator Agreement (IAA) Table 1
shows our IAA scores for template selection. Our
GWET AC1 (Gwet, 2008) scores range from 0.40
to 0.71, indicating moderate to the substantial
agreement. We also calculate Krippendorff‚Äôs al-
pha (Hayes and Krippendorff, 2007) and achieve a
score of 0.54, indicating a high agreement.
Given that Faulty Generalization had the lowest
agreement, we conduct an additional analysis on
all disagreements for Faulty Generalization argu-
ments. We discover that 60% of disagreements
were caused when one annotator labeled ‚Äô#5‚Äô and
the other instantiated a template, where reasons
annotators labeled ‚Äô#5‚Äô were due to complicated
instances and implicitness of the argument. Lastly,Fallacy Type Annotator 1 Annotator 2
False Dilemma 0.90 0.91
Faulty Generalization 0.68 0.76
False Causality 0.95 0.96
Fallacy of Credibility 0.64 0.83
Average 0.80 0.83
Table 2: Coverage of fallacy templates for both annota-
tors.
some instances in LOGIC were found to be other
types of fallacies, namely Slippery Slope .
Distribution of Templates Fig. 4 shows the
distribution of the fallacy templates for both an-
notators. We immediately observe that certain
templates were rarely selected by annotators for
LOGIC, such as template #3 for False Dilemma.
Regardless of this skewed distribution, as reported,
we still achieved a high IAA and coverage for tem-
plate selection.
Coverage Table 2 provides a comparison of an-
notation coverage forannotators, namely the per-
centage of instances where a non-template #5 is
annotated. Overall, our templates achieve a high
coverage for both annotators, with scores of 80%
and 83%. We observe that fallacy types such as
False Dilemma andFalse Causality achieve high
coverage due to their straightforward reasoning.
5 Experiments
To what extent is the automatic identification of
fallacy logic structure challenging for machines?
We evaluate current state-of-the-art LLMs for FtF.
6#Task
Identify the underlying structure of an argument of {fal-
lacy_type}.
Given a list of fallacy templates, your task is to choose a
template that best describes the underlying fallacy struc-
ture...
#List of Templates
Template No.1: \n{template_1}
...
Template No.5: \nThere is either no consequence in the
argument.
#Output Format
Template No.=[No.] \n{slot_fillers}
#Example
{examples} \n#
#Query
{}
Table 3: Generalized prompt used for our 0, 1, and 5-
shot LLM experiments. {fallacy_type} is either Fallacy
of Credibility, False Causality, Faulty Generalization, or
False Dilemma. Depending on the fallacy type, the ap-
propriate templates and slot-filler choices are provided
to the prompt, and for 1 and 5-shot settings, {exam-
ples} are provided. For spacing purposes, we replace
newlines with \nin this prompt and omit templates 2-4.
5.1 Methodology
The fallacy logic identification task comprises two
sub-tasks: (i) template selection and (ii) slot-filling .
As shown in Table 3, the prompt includes this
fallacy-type information, allowing LLM to focus
on two key actions. In template selection, the
model chooses the template that best reflects the
fallacious structure. For slot-filling, the model fills
in the slots of the selected template.
It is commonly known that dataset creation in
argumentation requires significant resources (hu-
man, time, financial), making it difficult to acquire
highly reliable large-scale annotations. Therefore,
we employ LLMs with in-context learning and fine-
tuning to model both sub-tasks jointly. We experi-
ment with three distinct prompts: (i) NL 1, a pure
natural language prompt, (ii) NL 2, simplified ver-
sion of NL 1, and (iii) PL, a semi-structured prompt
with propositional logic and mathematical nota-
tion. Table 3 summarizes a general form of these
prompts; see Appendix A.6 for an example of the
1-shot prompt for False Dilemma.4
5.2 Setup
Models We employed four state-of-the-art LLMs:
GPT-3.5-turbo (Abdullah et al., 2022), GPT-
4Detailed prompts used in our experiments are pub-
licly available at https://github.com/itsanonnymous/
fallacytemplate/tree/main/ftf_prompts4o (Achiam et al., 2023), Llama-3-8B(Meta, 2024),
and Mistral-7B(Jiang et al., 2023). We use a tem-
perature of 0, max tokens of 0.6, top_p of 1.0, and
both frequency and presence penalties of 0. Exper-
iments were conducted using zero-shot, one-shot,
and five-shot prompt settings for GPT-3.5-turbo
and GPT-4o. Few-shot examples were sampled
from FtF-TRAIN, with the number of shots reflect-
ing the number of examples provided in the prompt.
For the fine-tuned model, we split Ftf-TRAIN
into 150 instances as training data and 50 instances
as validation data. We set the learning rate into
2e-4 and optimizer adamw8bit. All models used
Ftf-DEV for testing and evaluating the results.
Evaluation Metrics We use accuracy for the
template section. For the slot-filling, we will
target only instances where the template is cor-
rectly identified by the model. Formally, we de-
fineexact-match slot-filling accuracy as follows:
|X‚à©Y|
|X|, where Xis a set of test instances where
the predicted template is correct, and Yis a set of
test instances where allpredicted slot-fillers must
exactly match the gold-standard slot-fillers.5In ad-
dition, we use partial-match slot-filling accuracy ,
where Yis a set of test instances where allpre-
dicted slot-fillers are required to have over 50%
word overlap with the gold standard.
For evaluating overall performance, we define a
joint accuracy to be a multiplication of template
selection accuracy and slot-filling accuracy.
5.3 Results and Analysis
Tables 4 demonstrate low accuracies across all mod-
els. We choose NL 2prompt for comparing the re-
sult with fine-tuned models based on the highest
accuracy in the template selection between GPT4
and GPT3.5 (appendix A.3). Regarding template
selection, the Mistral-7B model generally outper-
forms every model. Conversely, in slot-filling, the
results show that the GPT4 models with 5-shot
prompting outperform every model. Overall, the
low joint accuracy highlights a significant limita-
tion of state-of-the-art language models in identify-
ing the logical fallacy structure that best captures
the underlying fallacious structure within FtF. Im-
proving LLMs‚Äô ability to handle slot-filling tasks
remains a significant challenge.
5We lowercased all tokens for word matching.
7Model Acc. (TS) Acc. (SF) Acc. (Joint)
GPT4NL 2-0 0.36 0.06 0.02
GPT4NL 2-1 0.42 0.10 0.04
GPT4NL 2-5 0.38 0.24 0.09
GPT3.5NL 2-0 0.21 0.06 0.01
GPT3.5NL 2-1 0.30 0.14 0.04
GPT3.5NL 2-5 0.35 0.17 0.06
Llama3-7b 0.34 0.16 0.05
Mistral-7b 0.47 0.23 0.11
Table 4: Model accuracy for template selection (TS)
and exact-match accuracy for slot-filling (SF).
5.4 Error Analysis
We conducted an error analysis on 40 instances,
aiming to improve the template and prompt. We
focused on the Mistral-7b‚Äôs generated results due
to their highest joint accuracy. We discovered the
following errors: (i)The model predicted template
5 despite the argument being able to be instantiated
(32.5%), (ii)The model predicted a different tem-
plate due to different slot-fillers (32.5%), (iii)The
model predicted a different template despite having
similar slot-fillers as the gold label (17.5%), and
(iv)The model instantiated the template despite no
argument from consequence (17.5%).
We found that template 5 was sometimes pre-
dicted due to noise in the input argument. Among
all the instances that fell into category (i), four in-
stances predicted template 5 because of this noise.6
Although the prompts were built off our guide-
lines, we found that the model occasionally se-
lected different templates due to many possible
terms for slot-filling. Example 2 in table 8, shows
that the model selects a different template due to the
difference in slot-filler A. Upon further analysis,
the model‚Äôs predicted answer was also correct, as
‚Äúban hairspray‚Äù suppress ‚Äúthe world will end‚Äù pos-
sesses the same semantic meaning as ‚Äúhairspray‚Äù
promotes ‚Äúthe world will end‚Äù, but the selected
template and slot-filler were both incorrect.
It still remains a question why such an error that
falls into categories (iii) and (iv) occurred. How-
ever, we believe that the performance drop in the
model was attributed to three main factors: noise
in the dataset, the presence of multiple templates
that could be selected, and the existence of various
possible terms that could fill the slot-filler. Further
details can be seen in section A.5.
6See Example 1 in Appendix Table 8 for an example of
input question noise leading to template 56 Conclusion and Future Work
In this work, we conduct the first study to address
logical fallacy structure by creating an inventory
of fallacy templates. In total, we created 20 novel
templates spanned across 4 fallacy types (Fallacy
of Credibility, False Causality, False Dilemma, and
Faulty Generalization). We created and released
Flee the Flaw, a new dataset consisting of 400 argu-
ments from LOGIC (Jin et al., 2022) annotated with
fallacy logic structure and publicly released both
the corpus and guidelines. Our dataset achieved a
high inter-annotator agreement (Krippendorf‚Äôs Œ±
of 0.54) and coverage (0.83%). We experiment on
top of our new dataset by conducting In-Context
Learning and fine-tuning for fallacy logic structure
identification and discover that it is still a signifi-
cant challenge for state-of-the-art language models.
Our next step involves studying the underlying
patterns and reasoning errors in arguments by an-
alyzing the logical structure of fallacies. Simulta-
neously, we plan to conduct large-scale annotation
on top of lengthier, more natural arguments. Fi-
nally, we plan to explore non-consequential topics,
allowing for more Argumentation Schemes to be
considered.
Limitations
In this research, we mainly focus on the proposed
explainable fallacy template for only 4 fallacy types
which are all mainly informal fallacies. We do not
address the fallacy of logic which is the extension
from the informal fallacy to formal fallacy. To
keep annotation simple, our fallacy templates do
not cover every possible combination of ingredients
(e.g. relations such as NOT PROMOTE ,NOT SUP-
PRESS ) which limits the amount of total instantia-
tions we can acquire. Regardless, we still achieved
a coverage score of roughly 80%. Furthermore, we
extend on argument templates (Reisert et al., 2018)
which were inspired by Walton (2008)‚Äôs Argument
from Consequence scheme which is a common
scheme for every day arguments, but may limit
the full range of fallacy instantiations that we can
produce.
We limit ourselves to four types of fallacies
which only represents a small subset of all known
fallacies. Primarily, we target common informal
logical fallacies as a start for fallacious template
structure instantiation. Given the structure of False
Dilemma fallacy, which follows an either-or struc-
ture, we obtain an unbalanced partition for our
8False Dilemma templates. As shown in Fig. 4, both
annotators mainly annotated with template 2.
Ethical Considerations
Each author of this paper ensured that all ethical
considerations were upheld. All results are reported
as accurately as possible. Given that we conducted
an annotation, we adhere to constructing a high
quality dataset as exemplified by our annotator
agreement results.
References
Malak Abdullah, Alia Madain, and Yaser Jararweh.
2022. Chatgpt: Fundamentals, applications and so-
cial impacts. In 2022 Ninth International Conference
on Social Networks Analysis, Management and Secu-
rity (SNAMS) , pages 1‚Äì8. IEEE.
Josh Achiam, Steven Adler, Sandhini Agarwal, Lama
Ahmad, Ilge Akkaya, Florencia Leoni Aleman,
Diogo Almeida, Janko Altenschmidt, Sam Altman,
Shyamal Anadkat, et al. 2023. Gpt-4 technical report.
arXiv preprint arXiv:2303.08774 .
Tariq Alhindi, Tuhin Chakrabarty, Elena Musi, and
Smaranda Muresan. 2023. Multitask instruction-
based prompting for fallacy recognition. arXiv
preprint arXiv:2301.09992 .
B. Bennett. 2012. Logically Fallacious: The Ul-
timate Collection of Over 300 Logical Fallacies .
Ebookit.com.
Claire Bonial, Austin Blodgett, Taylor Hudson,
Stephanie Lukin, Jeffrey Micher, Douglas Summers-
Stay, Peter Sutor, and Clare V oss. 2022. The search
for agreement on logical fallacy annotation of an in-
fodemic. In Proceedings of the Thirteenth Language
Resources and Evaluation Conference , pages 4430‚Äì
4438.
Winston Carlile, Nishant Gurrapadi, Zixuan Ke, and
Vincent Ng. 2018. Give me more feedback: Anno-
tating argument persuasiveness and related attributes
in student essays. In Proceedings of the 56th Annual
Meeting of the Association for Computational Lin-
guistics (Volume 1: Long Papers) , pages 621‚Äì631,
Melbourne, Australia. Association for Computational
Linguistics.
Pierpaolo Goffredo, Mariana Espinoza, Serena Villata,
and Elena Cabrio. 2023. Argument-based detection
and classification of fallacies in political debates.
InProceedings of the 2023 Conference on Empir-
ical Methods in Natural Language Processing , pages
11101‚Äì11112. Association for Computational Lin-
guistics.
Kilem Li Gwet. 2008. Computing inter-rater reliability
and its variance in the presence of high agreement.
British Journal of Mathematical and Statistical Psy-
chology , 61(1):29‚Äì48.Ivan Habernal, Raffael Hannemann, Christian Pol-
lak, Christopher Klamm, Patrick Pauli, and Iryna
Gurevych. 2017. Argotario: Computational argu-
mentation meets serious games. In Proceedings of
the 2017 Conference on Empirical Methods in Nat-
ural Language Processing: System Demonstrations ,
pages 7‚Äì12, Copenhagen, Denmark. Association for
Computational Linguistics.
Chikara Hashimoto, Kentaro Torisawa, Stijn De Saeger,
Jong-Hoon Oh, et al. 2012. Excitatory or inhibitory:
A new semantic orientation extracts contradiction and
causality from the web. In Proceedings of the 2012
Joint Conference on Empirical Methods in Natural
Language Processing and Computational Natural
Language Learning , pages 619‚Äì630.
Andrew F Hayes and Klaus Krippendorff. 2007. An-
swering the call for a standard reliability measure for
coding data. Communication methods and measures ,
1(1):77‚Äì89.
Chadi Helwe, Tom Calamai, Pierre-Henri Paris, Chlo√©
Clavel, and Fabian Suchanek. 2023. Mafalda:
A benchmark and comprehensive study of fal-
lacy detection and classification. arXiv preprint
arXiv:2311.09761 .
Martin Hinton. 2020. Evaluating the Language of Argu-
ment , 1 edition, volume 37. Springer Cham.
Albert Q Jiang, Alexandre Sablayrolles, Arthur Men-
sch, Chris Bamford, Devendra Singh Chaplot, Diego
de las Casas, Florian Bressand, Gianna Lengyel, Guil-
laume Lample, Lucile Saulnier, et al. 2023. Mistral
7b.arXiv preprint arXiv:2310.06825 .
Zhijing Jin, Abhinav Lalwani, Tejas Vaidhya, Xiaoyu
Shen, Yiwen Ding, Zhiheng Lyu, Mrinmaya Sachan,
Rada Mihalcea, and Bernhard Schoelkopf. 2022.
Logical fallacy detection. In Findings of the Associ-
ation for Computational Linguistics: EMNLP 2022 ,
pages 7180‚Äì7198, Abu Dhabi, United Arab Emirates.
Association for Computational Linguistics.
Zixuan Ke, Hrishikesh Inamdar, Hui Lin, and Vincent
Ng. 2019. Give me more feedback II: Annotating
thesis strength and related attributes in student es-
says. In Proceedings of the 57th Annual Meeting of
the Association for Computational Linguistics , pages
3994‚Äì4004, Florence, Italy. Association for Compu-
tational Linguistics.
Zixuan Ke and Vincent Ng. 2019. Automated essay
scoring: A survey of the state of the art. In Proceed-
ings of the Twenty-Eighth International Joint Con-
ference on Artificial Intelligence, IJCAI-19 , pages
6300‚Äì6308. International Joint Conferences on Arti-
ficial Intelligence Organization.
Meta. 2024. Introducing meta llama 3: The most capa-
ble openly available llm to date.
Paul Reisert, Naoya Inoue, Tatsuki Kuribayashi, and
Kentaro Inui. 2018. Feasible annotation scheme for
capturing policy argument reasoning using argument
9templates. In Proceedings of the 5th Workshop on
Argument Mining , pages 79‚Äì89.
Ramon Ruiz-Dolz and John Lawrence. 2023. Detecting
argumentative fallacies in the wild: Problems and
limitations of large language models. In Proceedings
of the 10th Workshop on Argument Mining . Associa-
tion for Computational Linguistics.
Zhivar Sourati, Filip Ilievski, H√¥ng-√Çn Sandlin, and
Alain Mermoud. 2023a. Case-Based Reasoning with
Language Models for Classification of Logical Falla-
cies.
Zhivar Sourati, Vishnu Priya Prasanna Venkatesh, Dar-
shan Deshpande, Himanshu Rawlani, Filip Ilievski,
H√¥ng-√Çn Sandlin, and Alain Mermoud. 2023b. Ro-
bust and explainable identification of logical fallacies
in natural language arguments. Knowledge-Based
Systems , 266:110418.
Christian Stab and Iryna Gurevych. 2017. Parsing argu-
mentation structures in persuasive essays. Computa-
tional Linguistics , 43(3):619‚Äì659.
Stephen E Toulmin. 2003. The uses of argument . Cam-
bridge university press.
Henning Wachsmuth, Nona Naderi, Yufang Hou,
Yonatan Bilu, Vinodkumar Prabhakaran, Tim Alberd-
ingk Thijm, Graeme Hirst, and Benno Stein. 2017.
Computational argumentation quality assessment in
natural language. In Proceedings of the 15th Con-
ference of the European Chapter of the Association
for Computational Linguistics: Volume 1, Long Pa-
pers, pages 176‚Äì187, Valencia, Spain. Association
for Computational Linguistics.
D.N. Walton. 1987. Informal Fallacies: Towards a
Theory of Argument Criticisms . Companion series. J.
Benjamins Publishing Company.
Douglas Walton. 2008. Informal logic: A pragmatic
approach . Cambridge University Press.
Douglas Walton. 2013. Argumentation schemes for
presumptive reasoning . Routledge.
Douglas Walton, Christopher Reed, and Fabrizio
Macagno. 2008. Argumentation schemes . Cam-
bridge University Press.
10A Appendix
A.1 Template Examples
Figure 5: Examples of template and slot-fillers from FtF
for Fallacy of Credibility.
Shown in Fig. 5 is the example of Fallacy of
Credibility. For the Fallacy of Credibility argument,
the fallacy is committed as the X=‚Äúbest friend‚Äù
is promoting that A=‚Äúpizza‚Äù has C=‚Äúhealth ben-
efits‚Äù, resulting in P‚Ä≤:X=‚Äúbest friend‚Äù promote
thatA=‚Äúpizza‚Äù promote C=‚Äúhealth benefits‚Äù, thus
Conclusion is A=‚Äúpizza‚Äù should be brought about.
However, the friend is not an expert in the field of
nutrition.
Figure 6: Examples of template and slot-fillers from FtF
for False Causality.
For the False Causality argument shown inFig. 6, the argument is stating that A=‚Äúeat yo-
ghurt‚Äù has a correlation with people with healthy
guts, and thus the P:A=‚Äúeat yoghurt‚Äù suppressing
C=‚Äúsick‚Äù. The False Causality is linked, as it‚Äôs
implying that A=‚Äúeating yoghurt‚Äù will definitely
suppress C=‚Äúsick‚Äù. In conclusion, A=‚Äúeating yo-
ghurt‚Äù should be brought about.
Figure 7: Examples of template and slot-fillers from FtF
for False Dilemma.
The example of argument shown in Fig. 7 is con-
sidered as False Dilemma fallacy. The argument
limited the option to A=‚Äúcut taxes‚Äù and negation
ofA=‚Äúcut taxes‚Äù for determine the consequence of
C=‚Äúleave a huge debt for our children‚Äù. It conclude
A=‚Äúcut taxes‚Äù should be brought about without
considering any possible action except P:A=‚Äúcut
taxes‚Äù suppress C=‚Äúleave a huge debt for our chil-
dren‚Äù, and P‚Ä≤: negation of A=‚Äúcut taxes‚Äù promote
C=‚Äúleave a huge debt for our children‚Äù.
A.2 Fallacy Types
False Dilemma occurs due to the restriction of the
choices and ignoring additional potential options.
Faulty Generalization occurs when a belief is ap-
plied to a large population without a sufficient and
unbiased sample. False Causality assumes a cause-
and-effect relationship between two events. Finally,
Fallacy of Credibility involves an appeal to ethics,
authority, or credibility that is not directly rele-
vant to the argument. Table 5 provides a definition,
example, and further explanation of the example
for False Dilemma, Faulty Generalization, False
Causality, and Fallacy of Credibility.
11Fallacy Type Definition Example Explanation
False Dilemma This fallacy is when incorrect
limitations are made on the pos-
sible options in a scenario when
there could be other options.We either have to cut taxes
or leave a huge debt for our
childrenThis argument only limits the
options into ‚Äúcut taxes‚Äù or ‚Äúnot
cut taxes‚Äù for dealing with a
‚Äúdebt‚Äù without considering other
potential options.
Faulty
GeneralizationThis fallacy occurs when an ar-
gument applies a belief to a
large population without having
a large enough sample to do so.I took an NLP class, an ad-
vanced course in Stanford.
I suggest not taking further
advanced courses because
they will hurt your GPA.This argument generalizes ‚Äúfur-
ther advanced courses‚Äù should
not be taken due to hurting the
person‚Äôs "GPA" only because
the took one of the advanced
courses ‚ÄúNLP class.‚Äù
False Causality This fallacy occurs when an ar-
gument assumes that since two
events are correlated,they must
also have a cause and effect re-
lationship.People who eat yoghurt
have healthy guts. If I eat
yoghurt I will never get sickThis argument has a belief that
‚Äúeat yoghurt‚Äù has a strong rela-
tion with ‚Äúnever get sick‚Äù be-
cause of having ‚Äúhealthy guts‚Äù.
Thus, it believes that by eating
yoghurt will ‚Äúnever get sick.‚Äù
Fallacy of
CredibilityThis fallacy is when an appeal
is made to some form of ethics,
authority, or credibility.My Best friend tweeted
about the health benefits of
pizza, and so we‚Äôre going to
out to eat two vegetable piz-
zasThe argument has been pro-
moted by the person‚Äôs best
friend by ‚Äútweet about the health
benefits of pizza‚Äù, but the person
best friend is not an expert in the
field of nutrition which makes
the argument is not credible.
Table 5: Definition and example explanation of four defective induction fallacy types
A.3 Prompt Type for Template Selection and
Exact Match Performance
We report the result of template selection accuracy
and the average accuracy of slot-filling for exact
match for every three prompt types using GPT-4 in
table 6 and GPT3.5 in table 7.
Template selection performs better for 1-shot
prompting for every prompt type in the GPT4
model. However, not for the slot-filling task, 5-
shot prompting outperforms 1-shot prompting for
every prompt type despite not having the highest
accuracy in the template selection task. Different
from GPT3.5 where every task is dominated by
5-shot prompting for every prompt type.
Overall, model performance shows minimal vari-
ation based on prompt type, suggesting that prompt
variation has no significant impact on performance.
A.4 Prompt Type for Template Selection and
Partial Match Performance
We report the average accuracy of slot-filling for
partial match. The results are shown in table 9 for
GPT-4 and table 10 GPT3.5. Despite NL 2zero-
shot prompt on GPT4 model performance of only
0.06 accuracy for an exact match slot-filling task in
table 6, it performs the best with 0.49 accuracy in
the partial match slot-filling task.Pr n Acc. (TS) Acc. (SF) Acc. (Joint)
NL1 0 0.31 0.10 0.03
NL1 1 0.36 0.12 0.04
NL1 5 0.32 0.22 0.07
NL2 0 0.36 0.06 0.02
NL2 1 0.42 0.10 0.04
NL2 5 0.38 0.24 0.09
PL 0 0.32 0.10 0.03
PL 1 0.38 0.10 0.04
PL 5 0.31 0.18 0.06
Table 6: GPT-4 accuracy for template selection (TS) and
exact-match accuracy for slot-filling (SF). ndenotes the
number of few-shot examples, and Prdenotes a prompt
type.
Pr n Acc. (TS) Acc. (SF) Acc. (Joint)
NL1 0 0.21 0.12 0.02
NL1 1 0.31 0.14 0.04
NL1 5 0.37 0.19 0.07
NL2 0 0.21 0.06 0.01
NL2 1 0.30 0.14 0.04
NL2 5 0.35 0.17 0.06
PL 0 0.21 0.13 0.03
PL 1 0.29 0.04 0.01
PL 5 0.37 0.17 0.06
Table 7: GPT-3.5 accuracy for template selection (TS)
and exact-match accuracy for slot-filling (SF).
12Fallacy Type Example Correct Answer Predicted Answer
1 False Dilemma ‚ÄúAmerica: Love it or leave it.
This is an example of which
kind of logical fallacy?‚ÄùTemplate No.=2
[A]=Love it
[C]=leave itTemplate No.=5
[A]=
[C]=
2 False Dilemma We either ban hairspray or the
world will end.Template No.=4
[A]=hairspray
[C]=the world will endTemplate No.=2
[A]=ban hairspray
[C]=the world will end
3 False Causality I√¢C‚Ñ¢ve never had the flu be-
cause I take my vitamins every-
day.Template No.=4
[A]=vitamins
[C]=fluTemplate No.=3
[A]=vitamins
[C]=flu
4 Faulty
GeneralizationThis new test seemed so promis-
ing, but the 3 studies that sup-
ported its validity turned out
to have critical methodological
flaws, so the test is probably not
valid.Template No.=2
[A]=test
[C]=critical methodolical
flaws
[A‚Ä≤]=3 studies that sup-
ported its validity turned out
to have critical methodolog-
ical flaws
[C‚Ä≤]=Template No.=5
[A]=
[C]=
[A‚Ä≤]=
[C‚Ä≤]=
5 Fallacy of
CredibilityAlbert Einstein was extremely
impressed with this theory.Template No.=5
[A]=
[C]=
[X]=Template No.=2
[A]=this theory
[C]=Albert Einstein
[X]=extremely impressed
Table 8: False prediction generated by Mistral-7B model
Pr n Acc. (TS) Acc. (SF) Acc. (Joint)
NL1 0 0.31 0.24 0.07
NL1 1 0.36 0.43 0.16
NL1 5 0.32 0.32 0.10
NL2 0 0.36 0.49 0.17
NL2 1 0.42 0.35 0.15
NL2 5 0.38 0.42 0.16
PL 0 0.32 0.32 0.10
PL 1 0.38 0.21 0.08
PL 5 0.31 0.33 0.10
Table 9: GPT-4 accuracy for template selection (TS)
and partial-match accuracy for slot-filling
Pr n Acc. (TS) Acc. (SF) Acc. (Joint)
NL1 0 0.21 0.12 0.02
NL1 1 0.31 0.33 0.10
NL1 5 0.37 0.37 0.14
NL2 0 0.21 0.19 0.04
NL2 1 0.29 0.36 0.11
NL2 5 0.37 0.36 0.12
PL 0 0.21 0.20 0.04
PL 1 0.30 0.43 0.12
PL 5 0.35 0.38 0.14
Table 10: GPT-3.5 accuracy for template selection (TS)
and partial-match accuracy for slot-filling
A.5 False Template Prediction
Table 8 provides false prediction results using the
Mistral-7B model. As previously mentioned in
the section 5.4, we categorize into 4 types of er-
ror. We found that one of the reasons is the noisethat causes an error in category (i), but such an
error also occurred even for non-noisy input like in
example 4.
In example 3, the model correctly predicts the
slot-filler but chooses different templates. The
template conclusion ‚ÄúVitamins should be brought
about‚Äù is correct, but the model incorrectly as-
signs a good sentiment to ‚Äúflu‚Äù and creates the
premise ‚ÄúVitamins promote flu‚Äù which does not
align with the argument‚Äôs intention. It remains
unclear whether the model struggles to define sen-
timent.
In example 5, we believe the argument cannot
be instantiated as it is not an argument from conse-
quences. However, the model instantiates this argu-
ment into template 2 with the premise ‚ÄúThis theory
suppresses Albert Einstein‚Äù and got promoted by
‚Äúextremely impressed‚Äù which completely different
meaning from the input. This raises the question
of whether the model truly understands arguments
from consequence and the template structure.
A.6 Prompt for LLM Experiments
Table 11, Table 12, Table 13 provides an example of
the 5-shot prompt for False Dilemma used during
our LLM experiments. Instances used for non-
zero-shot settings are randomly selected from FtF-
TRAIN 200.
13A.7 Towards Dataset Expansion
Towards extending FtF with other datasets, using
our templates and guidelines, we conduct a pre-
liminary annotation on top of three existing, pre-
labeled fallacy datasets: LOGICCLIMATE (Jin
et al., 2022), and Argotario (Habernal et al., 2017),
and a Covid dataset (Bonial et al., 2022). We ran-
domly sample 40 arguments, where 20 are labeled
as ‚ÄúHasty Generalization‚Äù and 20 are labeled as
‚ÄúIrrelevant Authority‚Äù.We obtain a total coverage
of 0.50, with Argotario achieving the highest cov-
erage (0.60) and the Covid dataset achieving the
lowest (0.30). Reasons our templates could not
be instantiated included instances that require ev-
idence to function as the target fallacy type (e.g.,
‚ÄúCovid vaccines contain aborted babies.‚Äù as ‚ÄúHasty
Generalization‚Äù), not the target type fallacy (e.g.,
‚ÄúNo, because if you start with same sex marriage,
what is next? Marriage with animals?‚Äù, a Slippery
Slope), of no credible source information provided
(e.g., ‚Äú‚ÄúThe COVID-19 pandemic is not a real med-
ical pandemic‚Äù; ‚ÄúThe COVID-19 vaccine is not
proven safe or effective‚Äù‚Äù).
14# Task
Identify the underlying structure of an argument of False Dilemma.
Given a list of fallacy templates, your task is to choose a template that best describes the underlying fallacy structure, choosing the
template‚Äôs placeholders, [A]and [C], directly from the input text. Additionally, the text must be a consecutive sequence of one or more
terms without any conjugation.
Please follow the output format.
#Definition s
Entity: a noun phrase in the input.
Event: a verb phrase in the input.
Placeholder: A fill-in-the-blank choice within a template. Each placeholder may either be an entity or an event.
Please note! Placeholders can ONLY be either an entity (i.e., noun phrase) or an event (i.e., verb phrase) and may not be any other type
of phrase (e.g., prepositional phrase).
#List of Templates
Template No.1:
Premise 1: An entity/action [A] promotes a good entity/action [C].
Premise 2: The absence of an entity/action [A] suppresses a good entity/action [C].
Conclusion: Therefore, both Premise 1 and Premise 2 support that [A] should be brought about.
Template No.2:
Premise 1: An entity/action [A] suppresses a bad entity/action [C]
Premise 2: The absence of an entity/action [A] promotes a bad entity/action [C].
Conclusion: Therefore, both Premise 1 and Premise 2 support that [A] should be brought about.
Template No.3:
Premise 1: An entity/action [A] suppresses a good entity/action [C]
Premise 2: The absence of an entity/action [A] promotes a good entity/action [C].
Conclusion: Therefore, both Premise 1 and Premise 2 support that [A] should not be brought about.
Template No.4:
Premise 1: An entity/action [A] promotes a bad entity/action [C].
Premise 2: The absence of an entity/action [A] suppresses a bad entity/action [C].
Conclusion: Therefore, both Premise 1 and Premise 2 support that [A] should not be brought about.
Template No.5:
There is either no consequence in the argument, or the argument cannot be instantiated with one of the templates above.
#Output Format
Template No.=[No.]
[A]=
[C]=
#Important Criteria : Prioritizing entities over events for placeholder.
For choosing placeholder, please prioritize entities over events in the case that an entity itself captures the underlying intent of the
argument opposed to the event. However, if the event makes more sense, please choose an event for the placeholder.
#Correct Example
Input: To get better schools, we have to raise taxes. If we don‚Äôt, we can‚Äôt have better schools.
Output:
Template No.=1
[A]=raise taxes
[C]=schools
Explanation:
Here, there are 2 possible options for [C] which are "schools" (i.e., entity) and "can‚Äôt have better schools" (i.e., event). Since the entity is
the top priority and the second option does not work with template 1 because it is a suppressed relation, "schools" is cchosen for [C].
Also, [A] and [C] are taken directly from the input text. For example, "raising taxes" as [A] also sounds correct, but the term "raising" is
not mentioned in the input text. That is why "raise taxes" is chosen for [A]. Because the argument believes that "raise taxes" promote
"schools" while not "raise taxes" suppress "school". he conclusion is implicit that ‚ÄúPremise 1 supports that raise taxes should be brought
about.‚Äù Thus, Template No.=1 is selected.
#Wrong Example
Input: To get better schools, we have to raise taxes. If we don‚Äôt, we can‚Äôt have better schools.
Output:
Template No.=1
[A]=raising taxes
[C]=can‚Äôt have better schools
Explanation:
Here, there are 2 possible options for [C] which are "schools" (i.e., entity) and "can‚Äôt have better schools" (i.e., event). However, "can‚Äôt
have better schools" as [C] is incorrect because it is an event instead of the entity of "schools" which already makes sense.
Also, "raising taxes" as [A] is incorrect because the placeholder is not taken directly from the text. Here "raising taxes" is chosen as [A]
but the word "raising" does not appear in the input text. Therefore the correct choice for [A] is "raise taxes".
# Example1
If you can‚Äôt prove that Ken had an affair with the nanny, then he‚Äôs been faithful to his wife.
Template No.=1
[A]=prove that Ken had an affair with the nanny
[C]=he‚Äôs been faithful to his wife
Again, please only select the placeholders directly from the text!
#Query
{}
Table 11: Natural Language (NL 1): 1-shot False Dilemma prompt for LLM experiment
15#Task
Identify the underlying structure of an argument of False Dilemma.
Given a list of fallacy templates, your task is to choose a template that best describes the underlying fallacy structure, choosing the
template‚Äôs placeholders, [A]and [C], directly from the input text. Additionally, the text must be a consecutive sequence of one or more
terms without any conjugation.
Please follow the output format.
#Definition s
Entity: a noun phrase in the input.
Event: a verb phrase in the input.
Placeholder: A fill-in-the-blank choice within a template. Each placeholder may either be an entity or an event.
Please note! Placeholders can ONLY be either an entity (i.e., noun phrase) or an event (i.e., verb phrase) and may not be any other type
of phrase (e.g., prepositional phrase).
#List of Templates
Template No.1:
Premise 1: An entity/event [A] promotes a good entity/event [C].
Premise 2: An entity/event [¬¨A] suppresses a good entity/event [C].
Conclusion: Therefore, both Premise 1 and Premise 2 support that [A] should be brought about.
Template No.2:
Premise 1: An entity/event [A] suppresses a bad entity/event [C]
Premise 2: An entity/event [¬¨A] promotes a bad entity/event [C].
Conclusion: Therefore, both Premise 1 and Premise 2 support that [A] should be brought about.
Template No.3:
Premise 1: An entity/event [A] suppresses a good entity/event [C]
Premise 2: An entity/event [¬¨A] promotes a good entity/event [C].
Conclusion: Therefore, both Premise 1 and Premise 2 support that [A] should not be brought about.
Template No.4:
Premise 1: An entity/event [A] promotes a bad entity/event [C]
Premise 2: An entity/event [¬¨A] suppresses a bad entity/event [C].
Conclusion: Therefore, both Premise 1 and Premise 2 support that [A] should not be brought about.
Template No.5:
There is either no consequence in the argument, or the argument cannot be instantiated with one of the templates above.
#Output Format
Template No.=[No.]
[A]=
[C]=
#Important Criteria : Prioritizing entities over events for placeholder.
For choosing placeholder, please prioritize entities over events in the case that an entity itself captures the underlying intent of the
argument opposed to the event. However, if the event makes more sense, please choose an event for the placeholder.
#Correct Example
Input: To get better schools, we have to raise taxes. If we don‚Äôt, we can‚Äôt have better schools.
Output:
Template No.=1
[A]=raise taxes
[C]=schools
Explanation:
Here, there are 2 possible options for [C] which are "schools" (i.e., entity) and "can‚Äôt have better schools" (i.e., event). Since the entity is
the top priority and the second option does not work with template 1 because it is a suppressed relation, "schools" is cchosen for [C].
Also, [A] and [C] are taken directly from the input text. For example, "raising taxes" as [A] also sounds correct, but the term "raising" is
not mentioned in the input text. That is why "raise taxes" is chosen for [A]. Because the argument believes that "raise taxes" promote
"schools" while not "raise taxes" suppress "school". he conclusion is implicit that ‚ÄúPremise 1 supports that raise taxes should be brought
about.‚Äù Thus, Template No.=1 is selected.
#Wrong Example
Input: To get better schools, we have to raise taxes. If we don‚Äôt, we can‚Äôt have better schools.
Output:
Template No.=1
[A]=raising taxes
[C]=can‚Äôt have better schools
Explanation:
Here, there are 2 possible options for [C] which are "schools" (i.e., entity) and "can‚Äôt have better schools" (i.e., event). However, "can‚Äôt
have better schools" as [C] is incorrect because it is an event instead of the entity of "schools" which already makes sense.
Also, "raising taxes" as [A] is incorrect because the placeholder is not taken directly from the text. Here "raising taxes" is chosen as [A]
but the word "raising" does not appear in the input text. Therefore the correct choice for [A] is "raise taxes".
# Example1
If you can‚Äôt prove that Ken had an affair with the nanny, then he‚Äôs been faithful to his wife.
Template No.=1
[A]=prove that Ken had an affair with the nanny
[C]=he‚Äôs been faithful to his wife
Again, please only select the placeholders directly from the text!
#Query
{}
Table 12: Propositional Logic (PL): 1-shot False Dilemma prompt for LLM experiments.
16#Task
Identify the underlying structure of an argument of False Dilemma.
Given a list of fallacy templates, your task is to choose a template that best describes the underlying fallacy structure, choosing the
template‚Äôs placeholders, [A]and [C], directly from the input text. Additionally, the text must be a consecutive sequence of one or more
terms without any conjugation.
Please follow the output format.
#Definition s
Entity: a noun phrase in the input.
Event: a verb phrase in the input.
Placeholder: A fill-in-the-blank choice within a template. Each placeholder may either be an entity or an event.
Please note! Placeholders can ONLY be either an entity (i.e., noun phrase) or an event (i.e., verb phrase) and may not be any other type
of phrase (e.g., prepositional phrase).
#List of Templates
Template No.1:
Premise 1: An entity/event [A] promotes a good entity/event [C].
Premise 2: The absence of an entity/event [A] suppresses a good entity/event [C].
Conclusion: Therefore, [A] should be brought about.
Template No.2:
Premise 1: An entity/event [A] suppresses a bad entity/event [C]
Premise 2: The absence of an entity/event [A] promotes a bad entity/event [C].
Conclusion: Therefore, [A] should be brought about.
Template No.3:
Premise 1: An entity/event [A] suppresses a good entity/event [C]
Premise 2: The absence of an entity/event [A] promotes a good entity/event [C].
Conclusion: Therefore, [A] should not be brought about.
Template No.4:
Premise 1: An entity/event [A] promotes a bad entity/event [C]
Premise 2: The absence of an entity/event [A] suppresses a bad entity/event [C].
Conclusion: Therefore, [A] should not be brought about.
Template No.5:
There is either no consequence in the argument, or the argument cannot be instantiated with one of the templates above.
#Output Format
Template No.=[No.]
[A]=
[C]=
#Important Criteria : Prioritizing entities over events for placeholder.
For choosing placeholder, please prioritize entities over events in the case that an entity itself captures the underlying intent of the
argument opposed to the event. However, if the event makes more sense, please choose an event for the placeholder.
#Correct Example
Input: To get better schools, we have to raise taxes. If we don‚Äôt, we can‚Äôt have better schools.
Output:
Template No.=1
[A]=raise taxes
[C]=schools
Explanation:
Here, there are 2 possible options for [C] which are "schools" (i.e., entity) and "can‚Äôt have better schools" (i.e., event). Since the entity is
the top priority and the second option does not work with template 1 because it is a suppressed relation, "schools" is cchosen for [C].
Also, [A] and [C] are taken directly from the input text. For example, "raising taxes" as [A] also sounds correct, but the term "raising" is
not mentioned in the input text. That is why "raise taxes" is chosen for [A]. Because the argument believes that "raise taxes" promote
"schools" while not "raise taxes" suppress "school". he conclusion is implicit that ‚ÄúPremise 1 supports that raise taxes should be brought
about.‚Äù Thus, Template No.=1 is selected.
#Wrong Example
Input: To get better schools, we have to raise taxes. If we don‚Äôt, we can‚Äôt have better schools.
Output:
Template No.=1
[A]=raising taxes
[C]=can‚Äôt have better schools
Explanation:
Here, there are 2 possible options for [C] which are "schools" (i.e., entity) and "can‚Äôt have better schools" (i.e., event). However, "can‚Äôt
have better schools" as [C] is incorrect because it is an event instead of the entity of "schools" which already makes sense.
Also, "raising taxes" as [A] is incorrect because the placeholder is not taken directly from the text. Here "raising taxes" is chosen as [A]
but the word "raising" does not appear in the input text. Therefore the correct choice for [A] is "raise taxes".
#Example1
If you can‚Äôt prove that Ken had an affair with the nanny, then he‚Äôs been faithful to his wife.
Template No.=1
[A]=prove that Ken had an affair with the nanny
[C]=he‚Äôs been faithful to his wife
Again, please only select the placeholders directly from the text!
#Query
{}
Table 13: Natural Language 2(NL 2): 1-shot False Dilemma prompt for LLM experiments.
17