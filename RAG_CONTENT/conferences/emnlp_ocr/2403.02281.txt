Emotion Granularity from Text:
An Aggregate-Level Indicator of Mental Health
Krishnapriya Vishnubhotla1,2Daniela Teodorescu3Mallory J. Feldman4
Kristen A. Lindquist4Saif M. Mohammad5
1Department of Computer Science, University of Toronto
2Vector Institute, Toronto
3Department of Computing Science, University of Alberta
4Department of Psychology and Neuroscience, University of North Carolina at Chapel Hill
5National Research Council Canada
Abstract
We are united in how emotions are central to
shaping our experiences; yet, individuals dif-
fer greatly in how we each identify, categorize,
and express emotions. In psychology, varia-
tion in the ability of individuals to differentiate
between emotion concepts is called emotion
granularity (determined through self-reports
of one’s emotions). High emotion granularity
has been linked with better mental and physical
health; whereas low emotion granularity has
been linked with maladaptive emotion regula-
tion strategies and poor health outcomes. In this
work, we propose computational measures of
emotion granularity derived from temporally-
ordered speaker utterances in social media (in
lieu of self-reports that suffer from various bi-
ases). We then investigate the effectiveness of
such text-derived measures of emotion gran-
ularity in functioning as markers of various
mental health conditions (MHCs). We estab-
lish baseline measures of emotion granularity
derived from textual utterances, and show that,
at an aggregate level, emotion granularities are
significantly lower for people self-reporting as
having an MHC than for the control popula-
tion. This paves the way towards a better un-
derstanding of the MHCs, and specifically the
role emotions play in our well-being.
1 Introduction
Emotions play a central role in how we construct
meaning and communicate with those around us.
Yet, individuals vary in their understanding and
experience of emotions, or “emotional expertise”
(Hoemann et al., 2021b). Some people are able to
recognize, identify, and describe what they feel us-
ing precise, context-specific terms like guilt, anger,
frustration, or helplessness; others tend to use more
broad terms to convey a general sense of feeling
bad or feeling low. Emotion granularity (EG), aka
emotion differentiation , is defined by psychologists
as the ability of an individual to experience andcategorize emotions in very specific terms (Barrett
et al., 2001). Highly granular individuals have a
broad range of highly situated and differentiated
emotion concepts, and can reliably describe these
concepts using language — for example, distin-
guishing between when they are feeling angry vs.
when they are feeling sad, or when they are feeling
elated from when they are feeling content.
Evidence collected in the last two decades pro-
vides consistent support for a link between emo-
tional granularity and mental health (Erbas et al.,
2014, 2018; Starr et al., 2017; Seah et al., 2020),
physical health (Hoemann et al., 2021b; Bonar
et al., 2023), and adaptive health behavior (Dixon-
Gordon et al., 2014; Kashdan et al., 2015). Note
that this is different from other findings that study
how the prevalence of specific emotions varies with
mental health, (for example, people with depres-
sion tend to use more sadness-associated words).
The link between EG and mental health suggests
that there is a fundamental difference in how one
perceives an emotion (broadly or specifically), and
that in turn can impact their mental health.
Typically, granularity is measured across emo-
tions with the same valence; one can therefore have
a measure of negative emotion granularity , mea-
sured as the granularity of negative emotions (such
as anger, sadness, and fear) and positive emotion
granularity , measured as the granularity of positive
emotions (such as joy, excitement, and satisfac-
tion). Some works also look at the co-endorsement
of emotions that express opposite valence, such as
joy and sadness (Lindquist and Barrett, 2008).
In psychology and the affective sciences, emo-
tion granularity is often measured using repeated
measurements, where individuals are asked to rate
the intensity of experiencing certain emotions mul-
tiple times over a period of days (e.g., 2–3 times
each day for 5 days), i.e, with self-reports of emo-
tions felt. An individual’s emotional granularity is
then operationalized as the extent to which multi-arXiv:2403.02281v2  [cs.CL]  25 Nov 2024ple emotions are co-endorsed over time, i.e, how
similarly the emotions are rated across all measure-
ments, using the intraclass correlation coefficient
(ICC) (Shrout and Fleiss, 1979), which measures
the extent to which the emotions co-vary in reports
at the aggregate level. Individuals who tend to fre-
quently rate multiple emotions at the same intensity
levels are defined as low in granularity — the fre-
quent co-endorsement across time indicates that
they are failing to differentiate between these emo-
tions in their reports. In contrast, individuals high
in emotion granularity co-endorse multiple emo-
tions less frequently over time (Tugade et al., 2004;
Hoemann et al., 2021a; Lee et al., 2017; Reitsema
et al., 2022).
While prior work in NLP has studied the link
between emotions and mental health, these have
largely been limited to measuring the prevalence
or intensity of positive and negative emotions. In
this work, we, for the first time, propose a way
to compute emotion granularity from the textual
utterances of an individual . Our method uses the
temporal sequence of the utterances to first con-
struct emotion arcs along multiple emotions, and
computes granularity as the correlation of these
emotion arcs. We hypothesize that this measure is
indicative of the individual consistently expressing
the same set of emotions together over a period of
time, and can therefore act as a proxy measure of
emotional granularity.
We then study the relationship between ag-
gregate, population-level measures of emotion
granularity in text for eight Mental Health
Conditions (MHCs), namely attention-deficit
hyperactivity disorder (ADHD), anxiety, bipolar
disorder, depression, major depressive disorder
(MDD), obsessive-compulsive disorder (OCD),
postpartum depression (PPD), and post-traumatic
stress disorder (PTSD), and compare them to a
control group. We use two social media datasets
where users have chosen to self-disclose their
mental health diagnosis (Suhavi et al., 2022;
Losada et al., 2017, 2018). We compute emotion
granularity metrics for each of these groups to
answer the following questions:
1.Do measures of emotional granularity differ
between the MHCs and the control group?
2.Which measures of emotion granularity are
the most effective at differentiating between
the MHCs and the control group?
3.Which emotion pairs lead to the greatest
difference in granularity between an MHCand the control group?
Exploring this line of questions helps us better un-
derstand how emotion granularity presents itself
in text, whether emotion granularity from text can
be a useful tool to study MHCs, and how an MHC
impacts our perception of emotions (and perhaps
even, how the perception of emotions impacts our
mental health).
Our results establish baseline measures of emo-
tion granularity from text, and show that these
measures function as reliable indicators, at the
aggregate-level, for the presence of many of the
mental health conditions we study. Our work
makes an important contribution to the growing
wealth of research on textual measures of emotional
expression as biosocial markers of MHCs, and has
a broader utility in functioning as an additional
indicator of the mental well-being of populations.1
All our code will be made available through the
project webpage.2
2 Related Work
2.1 Emotions and Mental Health
Measures of emotional experience and their pat-
terns of change over time have been extensively
studied as markers of mental and physical well-
being (Lewis et al., 2010). The Emotion Dynamics
framework in psychology quantifies the patterns
with which emotions change over time, allowing
researchers to better understand emotional experi-
ences and individual variation (Kuppens and Ver-
duyn, 2017). The framework includes several mea-
sures such as the duration, intensity, variability, and
granularity of one’s emotional experiences. Nu-
merous studies in psychology have shown emotion
dynamics correlate with overall well-being, mental
health, and psychopathology (the scientific study of
mental illness or disorders) (Kuppens and Verduyn,
2017; Houben et al., 2015; Silk et al., 2011; Sperry
et al., 2020).
Emotion granularity in particular is positively
associated with adaptive behaviour in adverse con-
ditions — accurately labeling our emotions can
inform us of the right coping strategies to use in
different contexts. Individuals with higher emo-
tion granularity tend to use a broader range of
1The term biosocial marker (Lena, 2021) was coined to
indicate the crucial role social factors (e.g., socioeconomic sta-
tus, years of education, bilingualism, etc.) have on quantitative
features associated with medical conditions (biomarkers).
2https://github.com/Priya22/
emotion-granularity-from-textstrategies to deal with negative emotions, and are
more successful at doing so (Barrett et al., 2001).
Several studies have shown that emotion granu-
larity is lower in individuals with mental health
conditions like bipolar disorder (Suvak et al., 2011;
Dixon-Gordon et al., 2014), manic depressive dis-
order (Demiralp et al., 2012), schizophrenia (Kring
et al., 2003), autism spectrum disorder (Erbas et al.,
2013), and affective disorders like anxiety (Seah
et al., 2020) and depression (Starr et al., 2017;
Willroth et al., 2020). Lower granularity is also
associated with increased tendencies to engage in
maladaptive behaviour, such as alcohol consump-
tion (Kashdan et al., 2015; Emery et al., 2014) and
aggression (Pond Jr et al., 2012).
Researchers in affective science typically mea-
sure emotional granularity through experience sam-
pling methodologies (ESMs), or ecological mo-
mentary assessments (EMAs), where individuals
(participants) are repeatedly asked to report on their
emotional states on several occasions throughout
the day, for several days. For example, participants
may be asked to endorse a series of ten emotion
words (e.g., anger ,fear,happy , etc.) on a Likert
scale across several sampling instances. Emotional
granularity would then be computed as the intra-
class correlation (ICC) of ratings across sampling
instances. A high ICC would suggest that a partic-
ipant experiences all of the emotions in a similar
way across trials (treating them as synonyms for
more general affectual states such as “unpleasant-
ness" or “pleasantness"), whereas a low ICC would
suggest that a participant experienced emotions in
a granular and context-specific way.
While emotion granularity is generally measured
between emotion categories that are close to each
other in the affective space (i.e, express similar
valence), the concept of dialecticism refers to the
co-incidental experience of both negative and pos-
itive emotions (Lindquist and Barrett, 2008). Di-
alecticism can therefore be operationalized as the
co-endorsement of emotion pairs that express posi-
tive and negative valence.
2.2 Language and Mental Health
Given the limitations of self-report surveys (e.g.,
limited data coverage and time spans, biases, etc.
(Kragel et al., 2022)), another approach to measure
well-being indicators is through one’s language
usage. Some well-known linguistic indicators of
mental health include the proportion of pronouns
used for those with depression (Koops et al., 2023),syntax reduction for anorexia nervosa (Cuteri et al.,
2022), certain lexical and syntactic features for
mild cognitive impairment and dementia (Calzà
et al., 2021; Gagliardi and Tamburini, 2021), and
semantic connectedness for schizophrenia (Corco-
ran et al., 2020).
Recently, another linguistic feature that re-
searchers leveraged for insights into overall well-
being, are the emotions expressed in language.
Largely, only sentiment has been explored and
mainly from social media data (a rich source of
language data). For example, more negative sen-
timent was expressed in text by individuals with
depression (De Choudhury et al., 2013; Seabrook
et al., 2018; De Choudhury et al., 2021). Other
work has found that suicide watch, anxiety, and
self-harm subreddits had markedly lower negative
sentiment compared to other mental health subred-
dits such as Autism and Asperger’s (Gkotsis et al.,
2016).
Hipson and Mohammad (2021) and Vishnub-
hotla and Mohammad (2022) introduced Utterance
Emotion Dynamics (UED), a framework to quan-
tify patterns of change of emotional states associ-
ated with utterances along a longitudinal (tempo-
ral) axis (using data from screenplays and tweets).
Teodorescu et al. (2023) found that measures of
emotion dynamics from text correlate with various
mental health diagnoses.
These works overall show that the average emo-
tion expressed in text and also the characteristics
of individual emotion change over time (e.g., vari-
ability) are meaningful indicators of well-being. In
this work, we explore whether the degree of co-
expression of pairs of emotions in text (emotion
granularity) is a meaningful indicator of mental
health.
3 Datasets
We use the Twitter-STMHD dataset (Suhavi et al.,
2022) for our experiments and also verify our re-
sults with a smaller Reddit eRisk (Losada et al.,
2017, 2018) dataset. We describe both of them
below.
Twitter-STMHD dataset : Suhavi et al. (2022)
identified tweeters who self-disclosed as having an
MHC diagnosis using carefully constructed regular
expression patterns and manual verification. We
summarize key details on the dataset creation pro-
cess in Appendix A. The control group consists of
users identified from a random sample of tweets(who posted during approximately the same time
period as the MHC tweets). These tweeters did
not post any tweets meeting the MHC regex de-
scribed above. Additionally, users who had any
posts about mental health discourse were removed
from the control group. Note that this process does
not guarantee that users in the control group did
not have an MHC diagnosis, but rather the group
as a whole may have very few tweeters from these
MHC groups. The number of users in the control
group was selected to match the size of the de-
pression dataset, which had the largest number of
users.
For the final set of users, four years of tweets
were collected for each user: two years before self-
reporting a mental health diagnosis and two years
after. For the control group, tweets were randomly
sampled from between January 2017 and May 2021
(same date range as the other MHC classes).
Reddit eRisk dataset : To further add to our find-
ings, we also included the eRisk 2018 dataset
(Losada et al., 2017, 2018) in our experiments.
It consists of users who self-disclosed as having
depression on Reddit (expressions were manually
checked), and a control group (individuals were
randomly sampled). The dataset includes several
hundred posts per user, over approximately a 500-
day period. We combined users and their instances
from both the training set (which is from the eRisk
2017 task (Losada et al., 2017)) and the test set
(from the eRisk 2018 task (Losada et al., 2018)).
3.1 Preprocessing
We further preprocessed both the Twitter-STMHD
dataset and the eRisk dataset for our experiments
(Section 4), as we are specifically interested in the
relationship between emotion granularity and each
disorder. Several users self-reported as being di-
agnosed with more than one disorder, referred to
ascomorbidity . We found a high comorbidity rate
between users who self-reported as having anxiety
and depression, as is also supported in the literature
(Pollack, 2005; Gorman, 1996; Hirschfeld, 2001;
Cummings et al., 2014). Since we wanted to focus
on each MHC separately (and not on co-morbidity)
we only considered users who self-reported as hav-
ing one MHC. We also performed the following
preprocessing steps:
• We only considered posts in English.
•We filtered out posts that contained URLs (the
text in such posts is often not self-contained).
•We removed retweets (identified throughDataset, Group #people Av. #posts Av. #tokens
per post
Twitter
MHC 19,324 2,590.48 17.59
ADHD 6,356 2,497.43 17.46
Anxiety 3,036 2,921.05 17.46
Bipolar 1,061 2,820.17 17.32
Depression 4,855 2,526.62 16.75
MDD 219 2,640.69 16.40
OCD 1,009 2,388.73 18.38
PPD 179 2,581.19 19.18
PTSD 2,609 2,533.85 19.41
Control 6,001 2,420.50 16.16
Reddit
Depression 112 556.57 47.22
Control 907 665.00 41.09
Table 1: The number of users in each MHC, the aver-
age number of posts per user, and the average number
of tokens per post in the preprocessed version of the
Twitter-STMHD and Reddit eRisk datasets.
tweets containing ‘RT’, ‘rt’). This is to fo-
cus exclusively on texts written by the user.
•To ensure that we did not include users that
post very infrequently or very frequently, we
excluded users based on the number of posts
per individual. We discarded data from those
who either had less than 100 posts (as was
similarly done in Vishnubhotla and Moham-
mad (2022)) and those who had posted more
than 1.5 times the interquartile range above
quartile three (75th percentile) of the control
group.3
Table 1 shows key details of the filtered Twitter-
STMHD and Reddit eRisk datasets.
4 Emotion Granularity from Text
The core metric that we want to capture from
the text utterances of an individual is emotion
granularity—what psychologists term the “co-
endorsement" of pairs of emotions. Analogous
to their operationalization of granularity in terms
of the Intra-Class Correlation (ICC) of repeated
emotion intensity measurements along emotion ad-
jectives, we use textual utterances to derive a tem-
poral sequence of emotion states, referred to as an
emotion arc for the speaker (section 4.1), and op-
erationalize granularity as the correlations of these
arcs. We construct emotion arcs for multiple emo-
tions, for each user in the MHC groups and the
control group.
Emotion Dimensions: A key requirement of our
computational method is that we must be able to
quantify the emotional score of a text along a se-
3The interquartile range is from the 25th to 75th percentile.lected emotion dimension. We are therefore limited
by the resources and models available to compute
such a score for an emotion dimension.
Here, keeping in mind the necessity of includ-
ing multiple emotion dimensions that are similarly-
valenced, we work with the eight emotions rep-
resented in the NRC Emotion Intensity Lexicon:
anger, anticipation, disgust, fear, joy, sadness, sur-
prise, and trust (Mohammad, 2018).
We partition these emotions into three groups
based on the valence association: joy and trust
are in the positive valence group; anger, sadness,
fear, and disgust are in the negative valence group;
and anticipation and surprise are in the variable
valence group. The distinction for surprise and
anticipation is necessary because specific instances
of these emotions can have a positive or a negative
connotation (e.g., a good or a bad surprise).
4.1 Constructing Emotion Arcs
We order the utterances for each user based
on timestamp information in the metadata. We
construct emotion arcs for the temporal sequence
of utterances of each user, along each of the eight
emotions, in two ways pertaining to different
window sizes. This is to make sure that the results
are largely robust even when varying the window
size to some extent.
Utterance-level Window: Emotion scores (for
each emotion category) are computed for each utter-
ance (i.e, tweet or Reddit post). Here, an utterance
is assumed to represent the speaker’s emotion state
at a particular point in time (analogous to sampling
instances). The sequence of utterance emotion
scores for a user forms their temporal emotion arc.4
Word-Count based Window: Here, the emotion
score at a point in time is computed for a window of
words (say, 100 words) that are uttered around that
point, and the window is moved forward by a fixed
step size (say, 1 word at a time) to obtain the emo-
tion score for the next time step. In prior work on
constructing emotion arcs from temporally-ordered
text, such sliding windows are usually employed to
ensure smoother arcs that more accurately capture
the flow of emotions over time.
Teodorescu and Mohammad (2023) conducted
extensive quantitative evaluations of several hy-
perparameters involved in emotion arc construc-
tion, on datasets from diverse domains (including
4The frequency and time of posting often differs between
users, but we ignore that for now.tweets) annotated with emotion scores. We fol-
low many of their recommendations to construct
emotion arcs for the utterances of each of our users.
The texts are tokenized using the twokenizer5
package to obtain a similarly-ordered sequence of
words. Emotion scores are computed with window
sizes of 100 words and 500 words each, and the
window is moved forward by one word at each
timepoint to obtain a series of overlapping emotion
scores.
Emotion scoring method : Keeping in mind the
necessity of an interpretable method of emotion
scoring, we use word–emotion lexicons to compute
the emotion scores of text spans. For each win-
dow, the emotion scores of its constituent words
are averaged to obtain the window-level score for
that emotion. Teodorescu and Mohammad (2023)
showed that emotion arcs constructed with lexicon-
based scoring methods, when used with sliding
window sizes of 100 instances or more, can mimic
the ground-truth emotion arcs with an accuracy of
0.9 or more.
Word–emotion scores are obtained from the
NRC Emotion Intensity Lexicon, which associates
close to 10,000 English words with a real-valued
score between 0 and 1 for each dimension. A score
of 0 indicates that the word has little to no associa-
tion with that particular emotion, and a score of 1
indicates a high association.
Qualitative Checks on Emotion Lexicons :
Lexicon-based methods for constructing emotion
arcs are reliable and interpretable; however, it is
good practice to modify the lexicon to the specific
domain of use, in order to account for terms that
are expected to be used in the target domain in a
sense different from the predominant word sense
(Mohammad, 2023).
We identify and remove words and bigrams
whose usage on Twitter (and sometimes more collo-
quially) is markedly different from the predominant
word sense annotated in the lexicons, such as like
andchaotic evil . We also remove words and bi-
grams that are explicitly associated with mental
health, such as anxious, disorder andpanic attack .
Though our EG metric does not explicitly rely on
the presence of such terms to find associations with
MHCs, we remove them in order to capture more
fundamental differences in emotional expression
between users in the MHC groups and the control
group. The full list of stopwords is in Appendix B.
5https://github.com/myleott/ark-twokenize-pyHyperparameters: We additionally make the fol-
lowing choices of hyperparameters for constructing
and comparing a pair of emotion arcs:
•For a given pair of emotions, we drop all emo-
tion terms that are common to the two lexicons
before constructing their emotion arcs. This
ensures that we are not using words associ-
ated with both emotions, giving us a clearer
indication of co-endorsement.
•An utterance (or window) with no emotion
terms from a particular emotion lexicon is
assigned a score of 0. An alternative is to
assign them a score of nan, in which case they
are not considered a part of the emotion arc.6
A visualization of the emotion arcs obtained us-
ing the utterance-level window for a sampled user
from the Twitter-STMHD dataset is presented in
Appendix E.
4.2 Quantifying Emotion Granularity
We compute the emotion granularity metric as the
negative of the Spearman correlation between each
pair of emotions arcs, for each user.7A high corre-
lation between two arcs indicates that the speaker
is consistently and repeatedly expressing the two
emotions concurrently; we hypothesize that this
is an indicator of a lower ability to differentiate
between the two emotions, and therefore a lower
emotion granularity.8
For each person, we average the correlation
scores between emotion pairs in the different va-
lence groups to obtain the following measures of
emotion granularity (EG):
•EG(pos): The negative of (i.e., −1times)
the average of the correlation scores between
each of the pairs of emotions in the positive
valence group (joy–trust).
•EG(neg): The negative of the average of the
correlation scores between each of the pairs
6We do not observe any major changes to our results based
on these hyperparameter choices.
7We choose Spearman correlation as it is rank-based as
compared to Pearson correlation which utilizes the raw-values.
8We choose to use Spearman correlation over ICC-based
metrics because the emotion scores that we extract from tex-
tual utterances are a relative indicator of the intensity of the
emotion, and not an absolute measure. Further, these scores
cannot be directly compared across different emotions in terms
of absolute intensity (a score of 0.9 for anger may not equate
to the same level of anger as a score of 0.9 would for joy) due
to differences in how overtly different emotions are expressed
via language.of emotions in the negative valence group
(anger–fear, fear–disgust, etc.).
•EG(var): The negative of the average of the
correlation scores between each of the pairs
of emotions in the variable valence group
(surprise–anticipation).
•EG(overall ): Overall emotion granularity,
measured as the negative of the average of
the correlation scores between emotion pairs
whose constituents are in the same group .
Here, the average is taken across all of the
emotion pairs drawn from the positive valence
group, the negative valence group, and the
variable valence group.
•EG(cross ): Emotion granularity of cross-
group emotion pairs. That is, the negative of
the average of the correlation scores between
emotion pairs whose constituents come from
different groups . This measure to some ex-
tent quantifies the amount of dialecticism (ex-
pressing both positive and negative emotions
in a narrow window of time); however, note
that EG(cross) also includes emotions that ex-
press variable valence (surprise and anticipa-
tion), rather than only considering positive–
negative valence emotion pairs.
We consider EG(overall )to be the bottom line
measure of emotion granularity for a user (analo-
gous to that used in psychology studies). Note that
cross-group pairs are not included in this measure.
5 Emotion Granularity and Mental
Health
We now test if there are significant differences
between the emotion granularities of each of the
MHC groups and the control group, using t-tests.
We first limit the users in each group by placing
thresholds on (a) the number of user tweets with
a valid emotion score (set to a minimum of 50),
and (b) the number of unique lexicon terms used in
their tweets (set to a minimum of 25). These thresh-
olds ensure that we are drawing inferences based
on users with valid emotion arcs, with sufficient
lexicon coverage and temporal information.
We performed independent t-tests to compare
emotion granularities between each of the MHCs
and the control group, for each emotion group, us-
ing the SciPy library (Virtanen et al., 2020). To
correct for multiple comparisons (eight tests per-
formed for each MHC per emotion granularity
group), we used the Benjamini–Hochberg proce-Dataset, MHC–Control IC(n)IC(v)EG (pos)EG (neg )EG (var )EG (cross )EG (overall )
Twitter-STMHD
ADHD–control – – lower lower lower lower lower
Anxiety–control – – lower lower lower lower lower
Bipolar–control – – lower lower lower lower lower
MDD–control – – lower – – lower lower
OCD–control – – lower lower lower lower lower
PPD–control – – – lower – – –
PTSD–control – – lower lower lower lower lower
Depression–control – – lower lower lower lower lower
Reddit eRisk
Depression–control – – lower lower – lower lower
Table 2: The difference in emotion granularity between each MHC group and the control. A significant difference is
indicated by the word ‘lower’ or ‘higher’, indicating the direction of the difference in granularity.
dure in the statsmodels library (Seabold and Perk-
told, 2010). Further details on the data assumptions
for t-tests are in Appendix C.
5.1 Term Specificity as a Control
Lower emotion granularity occurs when, for a per-
son, the concepts of the relevant emotions are so
broad (and non-specific) that their meanings over-
lap substantially. This work is testing the hypoth-
esis of whether people who have self-disclosed as
having an MHC have lower emotion granularity
than those that do not. However, another plausi-
ble hypothesis is that people in a particular group
(e.g., MHC or the control) tend to use more spe-
cific words overall. Doing so would imply a higher
specificity (i.e, a higher granularity) in their usage
ofall words , and that the high granularity of emo-
tion words is simply a by-product of their general
style of speaking (or posting online).
To ensure that the level of word specificity does
not differ between MHCs and the control group
and act as a confounder for our measure of emo-
tion granularity, we performed a control experi-
ment. We compute the average information content
of the noun and verb terms in the posts of users
in each group, and use this as a measure of the
specificity of their language. We use the metric
proposed in Resnik (1995), and implemented in the
NLTK WordNet library,9which combines informa-
tion about the depth of the term in the WordNet
tree hierarchy and its frequency of occurrence in
a large corpus (here, the Brown corpus) to com-
pute an information content score (Miller, 1995).
We then compute the following measures of term
specificity for each user:
•IC(n): The information content score for all
nouns is averaged across all posts of each
individual in each group.
9https://github.com/nltk/wordnet•IC(v): The information content score for all
verbs is averaged across all posts of each indi-
vidual in each group.
Statistical tests for significant differences are simi-
larly performed as described above (Section 5).
6 Results
In Table 2 we report the statistical results from the
pairwise comparisons between each MHC and the
control group, for the control experiment on gen-
eral term specificity as well as emotion granularity,
when scores are computed at the utterance-level.
All statistically significant differences between
an MHC and the control group are described as
either ‘higher’ or ‘lower’, and a dash (–) for no
statistical difference. A ‘lower’ value in a cell in-
dicates that the MHC (rows) has lower emotion
granularity (or lower term specificity) than the con-
trol group, i.e., higher correlation between emotion
pairs in that group (columns); ‘higher’ indicates
the MHC has higher emotion granularity (or higher
term specificity) than the control group (i.e., lower
correlation between emotion pairs in that group).
In Table 12 in the Appendix, we also report the ab-
solute Spearman correlation scores for each group.
Below we summarize the results for each column.
6.1 Emotion Granularity as an Indicator of
MHCs
IC(n) and IC(v): We do not see any significant
differences in the information content of noun and
verb terms ( IC(n)andIC(v)) between MHCs and
the control group. This indicates that no group
tends to use more specific or less specific language
in general when posting on these platforms. Details
on the statistical results are shown in Appendix H.
EG(pos): All MHCs except for PPD had signifi-
cantly lower positive emotion granularity than the
control group (which had similar granularity com-pared to the control group). That is, tweeters in
these MHC groups (ADHD, Anxiety, etc.) consis-
tently expressed multiple positive emotions concur-
rently, more so than the control group.
EG(neg): All MHCs except MDD had signifi-
cantly lower negative emotion granularity than the
control group, in both datasets. Thus, tweeters in
these MHCs were generally not differentiating be-
tween the negative emotions of anger, disgust, fear,
and sadness, as well as the control group.
EG(var): Tweeters in the ADHD, Anxiety, Bipolar,
OCD, PTSD, and Depression (Twitter-STMHD)
had significantly lower variable emotion granular-
ity than the control group (i.e., these groups gen-
erally differentiated between surprise and anticipa-
tion less than the control group).
EG(overall): All MHCs except PPD had signifi-
cantly lower emotion granularity for emotion cat-
egories that express the same valence (the mixed
valence emotions of surprise and anticipation are
also included here). Tweeters in these groups are
therefore expressing multiple close emotions fre-
quently with one another – more so than the control
group.
EG(cross): All MHCs except PPD had signifi-
cantly lower granularity between emotion pairs
that come from different valence groups. This in-
dicates that positive and negative emotions are ex-
pressed together more frequently by tweeters in
these groups compared to the control, as well as
emotions like joy (positive valence) and surprise
(variable valence).
Discussion :These results demonstrate that our
measures of emotion granularity from text are con-
sistently lower for users in the MHC groups com-
pared to the control. The term specificity results
also tell us that it is the specificity of emotion word
usage in particular that is differentiating MHCs
from the control group.
Aligning with self-report studies in psychology,
the emotion granularity between negative-valence
emotions is lower for most (7 out of 8) MHCs
in our datasets with utterance-level operationaliza-
tions. Positive emotion granularity is also corre-
lated with many of the MHCs (7 out of 8 disorders).
In general, the granularity of emotional expression
between within-group emotion pairs is lower for
all MHC groups compared to the control in both
datasets, except PPD. This is in line with both the
theoretical and conceptual links established in the
psychology literature on emotion granularity and
mental health: the ability to better differentiatebetween emotion concepts that are close to one
another leads to more adaptive health behaviour.
While emotion pairs from differently-valenced
emotion groups are not usually operationalized in
affective science experiments, we find that this mea-
sure is also significantly lower in many MHCs.
Further investigations into what the concurrent ex-
pression of positive and negative emotions means,
for emotion granularity and emotion dynamics in
general, are interesting research directions.
Variation with hyperparameter choices : We ob-
serve only minor variations from the results re-
ported in Table 2 when the hyperparameters de-
scribed in Section 4.1 for emotion arc construction
were changed – less than 10% of the cells differed
in their values across all variations. We provide a
more detailed report in Appendix F.
6.2 Additional Window Sizes
We also examined how the measures of differences
in emotion granularity between MHCs and the con-
trol change when we compute emotion scores with
larger window sizes.
Many of the utterance-level outcomes are repli-
cated for negative, positive, and overall emotion
granularity with window sizes 100 and 500. Some
measures are no longer significantly different be-
tween certain MHCs and the control. We also find
thatEG(cross )ishigher for certain MHCs (Anxi-
ety, PPD, PTSD, Depression in Twitter-STMHD)
when compared to the control, i.e, users in the
control group are expressing negative and positive
emotions together more frequently than those in
the MHCs.
With larger window sizes, we end up capturing
emotions expressed by the individual over longer
time spans (tweets posted over the span of several
hours or days), rather than co-endorsement at the
same time. We hypothesize that these effects of
dialecticism, where the control group has a higher
co-occurrence of cross-valence group emotions, are
capturing the extent to which users balance neg-
ative emotions with positive emotions (and vice
versa). The consistent effects with 100 and 500-
word windows, and for several MHCs, makes this
a promising area for future work. All emotion gran-
ularity measures with window sized 100 and 500
are reported in Appendix F.1.
6.3 Individual Emotion Pairs
In order to understand which emotion pairs are
expressed together more frequently (resulting inlower emotion granularity), we performed the same
significance tests as before between MHCs and the
control for correlation scores between all individual
emotion pairs. We found that:
•Seven out of the eight MHCs in the Twitter-
STMHD dataset had a lower granularity (a
higher correlation) for anger–disgust (except
PPD) and anger–sadness (except MDD) in the
negative valence group.
•All eight MHCs had a lower emotion granu-
larity (higher correlation) between multiple
cross-group emotion pairs, notably those in-
volving the mixed-valence emotions of antici-
pation and trust.
•Contrary to trends, the Bipolar group had a
higher emotion granularity (i.e, a lower cor-
relation of emotion arcs) for the cross-group
emotion pairs of anger–joy and fear–joy.
Detailed results for each of the emotion pairs and
all MHCs are in Appendix G, Table 10.
Discussion: While lower granularity among cer-
tain emotion pairs consistently function as indica-
tors of all MHCs, we also see a few instances where
MHCs (specifically Bipolar disorder) have a higher
granularity between the emotions when compared
to the control. These findings are of interest to
researchers studying the links between how emo-
tions are expressed in text, and how they vary with
different MHCs.
7 Conclusion
In this work, we operationalized for the first time
a computational measure of emotion granularity
that can be derived from the textual utterances of
individuals. We applied this measure to two so-
cial media datasets of posts from individuals who
have self-disclosed as having an MHC. Our find-
ings showed that our measure of negative emotion
granularity is significantly lower for 7 out of the 8
MHC groups under consideration when compared
to a control group, at an aggregate-level. Also,
all MHCs except for PPD had lower overall emo-
tion granularity (and lower positive emotion gran-
ularity) compared to the control group. Our work
makes an important contribution towards deriving
aggregate-level indicators of emotional health from
the large amounts of utterance data available on
social media platforms. We hope this opens up an
avenue of future work to explore emotional expres-
sion in text and mental health.Limitations
Our work uses the social media utterances of in-
dividuals to derive measures of emotional expres-
sion that, at an aggregate level, are found to corre-
late with multiple mental health conditions. While
we use datasets that were compiled by other re-
searchers in the field, we stress that they may not
be representative of the general population. Our
methods therefore cannot be directly applied to
make inferences on other datasets without a care-
ful experimental validation first. The datasets we
study rely on self-disclosures made on social me-
dia platforms; it is possible that users report only
one such MHC but are diagnosed with others, or
that they misrepresent their diagnoses. Further, the
users in the control groups may include those who
have chosen to simply not self-disclose on these
platforms. This can occur due to many reasons, like
social desirability (Latkin et al., 2017) or impres-
sion management (Tedeschi, 2013). Nonetheless,
since we draw inferences at an aggregate level, the
methods used can overcome some amount of noisy
data.
The set of emotions that we have considered in
our measurement of emotion granularity are also
limited to those for which we can computationally
obtain text-derived emotion scores. These eight
emotions do not represent the wide range of emo-
tion concepts that exist and are experienced and
expressed by us with language, and future research
can attempt to expand our operationalization to
more emotion concepts. It should be noted though,
that past psychology studies on emotion granularity
have also tended to explore small sets of emotions,
largely because it is cumbersome to ask users about
how they feel for a large set of emotions.
The emotion lexicons that we use are some of
the largest that exist with wide coverage and large
number of annotators (thousands of people as op-
posed to just a handful). However, no lexicon can
cover the full range of linguistic and cultural diver-
sity in emotion expression. The lexicons are largely
restricted to words that are most commonly used
in Standard American English and they capture
emotion associations as judged by American native
speakers of English. See Mohammad (2023) for a
discussion of the limitations and best-practises in
the use of emotion lexicons.
Lastly, further work should explore if the
relationships we found hold around various social
factors such as age, region, language, etc. As wefocus on English text, and the region of users is
not known (some information could be extracted
from user profiles in the Twitter-STMHD dataset
however it is fairly noisy), conclusions should be
drawn cautiously across various sociolinguistic
factors.
Ethics Statement
Our approach, as with all data-driven models of
determining indicators of mental health, should
be considered as aggregate-level indicators , rather
than biomarkers for individuals (Guntuku et al.,
2017). We do not attempt to predict the presence
of MHCs for individual users at any stage of the
process. These measures should also not be taken
as standalone indicators of mental health or mental
wellness, even at the population level, but rather as
an additional metric that can be used in conjunction
with other population-level markers, and with the
expertise of clinicians, psychologists, and public
health experts.
Individuals vary considerably in how, and how
well, they express their internal emotional states
using language. Our method of assessing the emo-
tional states of users based on their utterances may
miss several linguistic cues of emotion expression,
and may not account for individual variation or the
extent to which these emotions are expressed on
social media. The emotionality of one’s language
may also be conveying information about the emo-
tions of the speaker, the listener, or something or
someone else mentioned in the utterances. See
further discussions of ethical considerations when
using computational methods for affective science
in Mohammad (2023, 2022).
References
Lisa Feldman Barrett, James Jonathan Gross, Tam-
lin Conner Christensen, and Michael Benvenuto.
2001. Knowing what you’re feeling and knowing
what to do about it: Mapping the relation between
emotion differentiation and emotion regulation. Cog-
nition and Emotion , 15:713 – 724.
Adrienne S Bonar, Jennifer K MacCormack, Mallory J
Feldman, and Kristen A Lindquist. 2023. Examining
the role of emotion differentiation on emotion and
cardiovascular physiological activity during acute
stress. Affective Science , pages 1–15.
Laura Calzà, Gloria Gagliardi, Rema Rossini Favretti,
and Fabio Tamburini. 2021. Linguistic features andautomatic classifiers for identifying mild cognitive
impairment and dementia. Computer Speech & Lan-
guage , 65:101113.
Cheryl M. Corcoran, Vijay A. Mittal, Carrie E. Bear-
den, Raquel E. Gur, Kasia Hitczenko, Zarina Bil-
grami, Aleksandar Savic, Guillermo A. Cecchi, and
Phillip Wolff. 2020. Language as a biomarker for
psychosis: A natural language processing approach.
Schizophrenia Research , 226:158–166. Biomarkers
in the Attenuated Psychosis Syndrome.
Colleen M. Cummings, Nicole E. Caporino, and
Philip C. Kendall. 2014. Comorbidity of anxiety
and depression in children and adolescents: 20 years
after. Psychological Bulletin , 140(3):816–845.
Vittoria Cuteri, Giulia Minori, Gloria Gagliardi, Fabio
Tamburini, Elisabetta Malaspina, Paola Gualandi,
Francesca Rossi, Milena Moscano, Valentina Fran-
cia, and Antonia Parmeggiani. 2022. Linguistic fea-
ture of anorexia nervosa: a prospective case-control
pilot study. Eating and weight disorders : EWD ,
27(4):1367—1375.
Munmun De Choudhury, Scott Counts, and Eric Horvitz.
2013. Social media as a measurement tool of de-
pression in populations. In Proceedings of the 5th
Annual ACM Web Science Conference , WebSci ’13,
page 47–56, New York, NY , USA. Association for
Computing Machinery.
Munmun De Choudhury, Michael Gamon, Scott Counts,
and Eric Horvitz. 2021. Predicting depression via
social media. Proceedings of the International AAAI
Conference on Web and Social Media , 7(1):128–137.
Emre Demiralp, Renee J Thompson, Jutta Mata, Su-
sanne M Jaeggi, Martin Buschkuehl, Lisa Feldman
Barrett, Phoebe C Ellsworth, Metin Demiralp, Luis
Hernandez-Garcia, Patricia J Deldin, et al. 2012.
Feeling blue or turquoise? emotional differentiation
in major depressive disorder. Psychological science ,
23(11):1410–1416.
Katherine L. Dixon-Gordon, Alexander L. Chapman,
Nicole H. Weiss, and M. Zachary Rosenthal. 2014.
A preliminary examination of the role of emotion
differentiation in the relationship between border-
line personality and urges for maladaptive behaviors.
Journal of Psychopathology and Behavioral Assess-
ment , 36:616–625.
Noah N Emery, Jeffrey S Simons, C Joseph Clarke,
and Raluca M Gaher. 2014. Emotion differentiation
and alcohol-related problems: The mediating role of
urgency. Addictive Behaviors , 39(10):1459–1463.
Yasemin Erbas, Eva Ceulemans, Johanna Boonen, Ilse
Noens, and Peter Kuppens. 2013. Emotion differ-
entiation in autism spectrum disorder. Research in
Autism Spectrum Disorders , 7(10):1221–1227.
Yasemin Erbas, Eva Ceulemans, Elise K Kalokerinos,
Marlies Houben, Peter Koval, Madeline L Pe, and
Peter Kuppens. 2018. Why i don’t always knowwhat i’m feeling: The role of stress in within-person
fluctuations in emotion differentiation. Journal of
personality and Social Psychology , 115(2):179.
Yasemin Erbas, Eva Ceulemans, Madeline Lee Pe, Pe-
ter Koval, and Peter Kuppens. 2014. Negative emo-
tion differentiation: Its personality and well-being
correlates and a comparison of different assessment
methods. Cognition and Emotion , 28:1196 – 1213.
Gloria Gagliardi and Fabio Tamburini. 2021. Linguistic
biomarkers for the detection of mild cognitive im-
pairment. Lingue e linguaggio, Rivista semestrale ,
(1/2021):3–31.
George Gkotsis, Anika Oellrich, Tim Hubbard, Richard
Dobson, Maria Liakata, Sumithra Velupillai, and
Rina Dutta. 2016. The language of mental health
problems in social media. In Proceedings of the
Third Workshop on Computational Linguistics and
Clinical Psychology , pages 63–73, San Diego, CA,
USA. Association for Computational Linguistics.
Jack M. Gorman. 1996. Comorbid depression and anx-
iety spectrum disorders. Depression and Anxiety ,
4(4):160–168.
Sharath Chandra Guntuku, David Bryce Yaden, Mar-
garet L. Kern, Lyle H. Ungar, and Johannes C. Eich-
staedt. 2017. Detecting depression and mental illness
on social media: an integrative review. Current Opin-
ion in Behavioral Sciences , 18:43–49.
Will E. Hipson and Saif M. Mohammad. 2021. Emotion
dynamics in movie dialogues. PLOS ONE , 16:1–19.
Robert M. A. Hirschfeld. 2001. The comorbidity of
major depression and anxiety disorders: Recogni-
tion and management in primary care. Primary
care companion to the Journal of clinical psychiatry ,
3(6):244—254.
Katie Hoemann, Lisa Feldman Barrett, and Karen S.
Quigley. 2021a. Emotional granularity increases with
intensive ambulatory assessment: Methodological
and individual factors influence how much. Frontiers
in Psychology , 12.
Katie Hoemann, Cathy Nielson, Ashley Yuen, Jacob
Gurera, Karen S. Quigley, and Lisa Feldman Bar-
rett. 2021b. Expertise in emotion: A scoping review
and unifying framework for individual differences in
the mental representation of emotional experience.
Psychological bulletin , 147 11:1159–1183.
Marlies Houben, Wim Van Den Noortgate, and Peter
Kuppens. 2015. The relation between short-term
emotion dynamics and psychological well-being: A
meta-analysis.
Todd B Kashdan, Lisa Feldman Barrett, and Patrick E
McKnight. 2015. Unpacking emotion differentiation:
Transforming unpleasant experience by perceiving
distinctions in negativity. Current Directions in Psy-
chological Science , 24(1):10–16.Sanne Koops, Sanne G Brederoo, Janna N de Boer,
Femke G Nadema, Alban E V oppel, and Iris E
Sommer. 2023. Speech as a biomarker for depres-
sion. CNS&; neurological disorders drug targets ,
22(2):152—160.
Philip A. Kragel, Ahmad R. Hariri, and Kevin S. LaBar.
2022. The temporal dynamics of spontaneous emo-
tional brain states and their implications for mental
health. Journal of cognitive neuroscience , 34(5):715–
728. May, 2022.
Ann M Kring, Lisa Feldman Barrett, and David E Gard.
2003. On the broad applicability of the affective
circumplex: representations of affective knowledge
among schizophrenia patients. Psychological Sci-
ence, 14(3):207–214.
Peter Kuppens and Philippe Verduyn. 2017. Emotion
dynamics. Current Opinion in Psychology , 17:22–26.
Emotion.
Carl A Latkin, Catie Edwards, Melissa A Davey-
Rothwell, and Karin E Tobin. 2017. The relation-
ship between social desirability bias and self-reports
of health, substance use, and social network factors
among urban substance users in baltimore, maryland.
Addictive behaviors , 73:133–136.
Ja Y . Lee, Kristen A. Lindquist, and Chang S. Nam.
2017. Emotional granularity effects on event-related
brain potentials during affective picture processing.
Frontiers in Human Neuroscience , 11.
Palaniyappan Lena. 2021. More than a biomarker:
could language be a biosocial marker of psy-
chosis? NPJ Schizophrenia , 7(1). Copyright - ©
The Author(s) 2021. This work is published under
http://creativecommons.org/licenses/by/4.0/ (the “Li-
cense”). Notwithstanding the ProQuest Terms and
Conditions, you may use this content in accordance
with the terms of the License; Last updated - 2023-
02-22.
Michael Lewis, Jeannette M Haviland-Jones, and
Lisa Feldman Barrett. 2010. Handbook of emotions .
Guilford Press.
Kristen A Lindquist and Lisa Feldman Barrett. 2008.
Emotional complexity. Handbook of emotions ,
4:513–530.
David E Losada, Fabio Crestani, and Javier Parapar.
2017. Clef 2017 erisk overview: Early risk prediction
on the internet: Experimental foundations. pages
346–360.
David E Losada, Fabio Crestani, and Javier Parapar.
2018. Overview of erisk: early risk prediction on
the internet. In Experimental IR Meets Multilingual-
ity, Multimodality, and Interaction: 9th International
Conference of the CLEF Association, CLEF 2018,
Avignon, France, September 10-14, 2018, Proceed-
ings 9 , pages 343–361. Springer.
George A. Miller. 1995. Wordnet: a lexical database for
english. Commun. ACM , 38(11):39–41.Saif Mohammad. 2023. Best practices in the creation
and use of emotion lexicons. In Findings of the Asso-
ciation for Computational Linguistics: EACL 2023 ,
pages 1825–1836, Dubrovnik, Croatia. Association
for Computational Linguistics.
Saif M. Mohammad. 2018. Word affect intensities. In
Proceedings of the 11th Edition of the Language Re-
sources and Evaluation Conference (LREC-2018) ,
Miyazaki, Japan.
Saif M. Mohammad. 2022. Ethics sheet for automatic
emotion recognition and sentiment analysis. Compu-
tational Linguistics , 48(2):239–278.
Mark H Pollack. 2005. Comorbid anxiety and depres-
sion. Journal of Clinical Psychiatry , 66:22.
Richard S Pond Jr, Todd B Kashdan, C Nathan DeWall,
Antonina Savostyanova, Nathaniel M Lambert, and
Frank D Fincham. 2012. Emotion differentiation
moderates aggressive tendencies in angry people: A
daily diary analysis. Emotion , 12(2):326.
Anne M Reitsema, Bertus F Jeronimus, Marijn van
Dijk, and Peter de Jonge. 2022. Emotion dynamics
in children and adolescents: A meta-analytic and
descriptive review. Emotion , 22(2):374.
Philip Resnik. 1995. Using information content to eval-
uate semantic similarity in a taxonomy. In Interna-
tional Joint Conference on Artificial Intelligence .
Skipper Seabold and Josef Perktold. 2010. statsmodels:
Econometric and statistical modeling with python. In
9th Python in Science Conference .
Elizabeth M Seabrook, Margaret L Kern, Ben D Fulcher,
and Nikki S Rickard. 2018. Predicting depression
from language-based emotion dynamics: Longitudi-
nal analysis of facebook and twitter status updates. J
Med Internet Res , 20(5):e168.
TH Stanley Seah, Pallavi Aurora, and Karin G Coifman.
2020. Emotion differentiation as a protective factor
against the behavioral consequences of rumination:
A conceptual replication and extension in the context
of social anxiety. Behavior Therapy , 51(1):135–148.
Patrick E Shrout and Joseph L Fleiss. 1979. Intraclass
correlations: uses in assessing rater reliability. Psy-
chological bulletin , 86(2):420.
Jennifer S. Silk, Erika E. Forbes, Diana J. Whalen, Jen-
nifer L. Jakubcak, Wesley K. Thompson, Neal D.
Ryan, David A. Axelson, Boris Birmaher, and
Ronald E. Dahl. 2011. Daily emotional dynamics in
depressed youth: A cell phone ecological momentary
assessment study. Journal of Experimental Child
Psychology , 110(2):241–257. Special Issue: Assess-
ment of Emotion in Children and Adolescents.
Sarah H. Sperry, Molly A. Walsh, and Thomas R.
Kwapil. 2020. Emotion dynamics concurrently and
prospectively predict mood psychopathology. Jour-
nal of Affective Disorders , 261:67–75.Lisa R Starr, Rachel Hershenberg, Y Irina Li, and
Zoey A Shaw. 2017. When feelings lack precision:
Low positive and negative emotion differentiation
and depressive symptoms in daily life. Clinical Psy-
chological Science , 5(4):613–631.
Suhavi, Asmit Kumar Singh, Udit Arora, Somyadeep
Shrivastava, Aryaveer Singh, Rajiv Ratn Shah, and
Ponnurangam Kumaraguru. 2022. Twitter-stmhd:
An extensive user-level database of multiple men-
tal health disorders. Proceedings of the Interna-
tional AAAI Conference on Web and Social Media ,
16(1):1182–1191.
Michael K Suvak, Brett T Litz, Denise M Sloan, Mary C
Zanarini, Lisa Feldman Barrett, and Stefan G Hof-
mann. 2011. Emotional granularity and borderline
personality disorder. Journal of abnormal psychol-
ogy, 120(2):414.
James T Tedeschi. 2013. Impression management the-
ory and social psychological research . Academic
Press.
Daniela Teodorescu, Tiffany Cheng, Alona Fyshe, and
Saif Mohammad. 2023. Language and mental health:
Measures of emotion dynamics from text as linguistic
biosocial markers. In Proceedings of the 2023 Con-
ference on Empirical Methods in Natural Language
Processing , pages 3117–3133, Singapore. Associa-
tion for Computational Linguistics.
Daniela Teodorescu and Saif Mohammad. 2023. Eval-
uating emotion arcs across languages: Bridging the
global divide in sentiment analysis. In Findings of the
Association for Computational Linguistics: EMNLP
2023 , pages 4124–4137.
Michele M. Tugade, Barbara L. Fredrickson, and
Lisa Feldman Barrett. 2004. Psychological resilience
and positive emotional granularity: examining the
benefits of positive emotions on coping and health.
Journal of personality , 72 6:1161–90.
Pauli Virtanen, Ralf Gommers, Travis E. Oliphant, Matt
Haberland, Tyler Reddy, David Cournapeau, Ev-
geni Burovski, Pearu Peterson, Warren Weckesser,
Jonathan Bright, Stéfan J. van der Walt, Matthew
Brett, Joshua Wilson, K. Jarrod Millman, Nikolay
Mayorov, Andrew R. J. Nelson, Eric Jones, Robert
Kern, Eric Larson, C J Carey, ˙Ilhan Polat, Yu Feng,
Eric W. Moore, Jake VanderPlas, Denis Laxalde,
Josef Perktold, Robert Cimrman, Ian Henriksen, E. A.
Quintero, Charles R. Harris, Anne M. Archibald, An-
tônio H. Ribeiro, Fabian Pedregosa, Paul van Mul-
bregt, and SciPy 1.0 Contributors. 2020. SciPy 1.0:
Fundamental Algorithms for Scientific Computing in
Python. Nature Methods , 17:261–272.
Krishnapriya Vishnubhotla and Saif M. Mohammad.
2022. Tweet Emotion Dynamics: Emotion word us-
age in tweets from US and Canada. In Proceedings of
the Thirteenth Language Resources and Evaluation
Conference , pages 4162–4176, Marseille, France. Eu-
ropean Language Resources Association.Emily C Willroth, Jayde AM Flett, and Iris B Mauss.
2020. Depressive symptoms and deficits in stress-
reactive negative, positive, and within-emotion-
category differentiation: A daily diary study. Journal
of personality , 88(2):174–184.
A Twitter-STMHD Dataset
Suhavi et al. (2022) created a regular expression
pattern to identify posts which contained a self-
disclosure of a diagnosis and the diagnosis name
(using a lexicon of common synonyms, abbrevi-
ations, etc.) such as ‘diagnosed with X’. They
collected a large set of tweets using the regex. This
resulted in a preliminary dataset of users with po-
tential MHC diagnoses. To handle false positives
(e.g., ‘my family member has been diagnosed with
X’, or ‘I was not diagnosed with X’), the dataset
was split into two non-overlapping parts, one of
which was manually annotated, and the other using
an updated and high-precision regex. In the part
that was annotated by hand, each tweet was anno-
tated by two members of the team. A user was only
included in the dataset if both annotations were
positive as self-disclosing for a particular class. A
licensed clinical psychologist found the 500-tweet
sample to be 99.2% accurate. The manual anno-
tations were used to refine the regular expressions
and diagnosis name lexicon. This updated search
pattern was applied to the other dataset split. To
verify the quality of the updated regex, the authors
applied it to the manually annotated dataset split.
When considering the manual annotations as cor-
rect, the regex was found to be 94% accurate.
B Lexicon Words Removed
We considered the following sets of terms to be
stop-words, which do not contribute to the emotion
score of an utterance, for our analysis:
•Common stopwords: We remove common
English stopwords, such as the,of,for, etc.
We use the list of English stopwords from
the Python NLTK library. The full list
can be found at https://gist.github.com/
sebleier/554280 .
•Domain-specific stopwords: We remove
terms (words and word pairs) whose domi-
nant usage on social media platforms differs
from their annotated sense (e.g, like,chaotic
evil,good morning ). The full list of these
terms is in Table 3.
•MHC-associated terms: Finally, we filter
out terms that are explicitly associated withthe MHCs that we consider, such as anxiety ,
mental health , and panic attack . The full list
of terms is in Table 4.
C Statistical Assumptions
Below we describe in more depth the requirements
for performing an independent t-test, which was
done in our analyses.
•The dependent variable must be measured
using a continuous scale : emotion granular-
ity is measured as the average of Spearman
correlation between emotion arcs in the group,
resulting in continuous values.
•The independent variable must have two
categorical and independent groups : Our
independent variable is diagnosis, which is
either an MHC or the control group.
•Independence of observations : Since the
text stream of utterances come from different
people, we can assume these are independent
observations.10
•Approximately normally distributed depen-
dent variable for each group of indepen-
dent variable : Given the large number of
people and number of utterances per person
in our dataset, we can assume that the means
of the data for each group is approximately
normally distributed according to the law of
large numbers. Further, the t-test is robust to
violations of normality.
•Homogeneity of variance : We performed
Levene’s test for homogeneity of variance to
verify whether this assumption is met. Our
data did not meet this assumption, therefore
we performed t-tests with the unequal variance
setting as True in SciPy .
D Emotion Lexicons
In Table 5, we report statistics on the number of
emotion terms in each lexicon for the eight emo-
tions we consider in this work, and the number of
terms common to and mutually-exclusive between
each emotion pair.
10In reality individuals are largely influenced by one an-
other as we see, interact and engage with content from various
communities, which can influence our emotional state and
therefore utterances. However, for the purposes of our experi-
ments since the utterances come from different people we can
assume they are independent.love flu shot raptor discord
christmas good day good morning good evening
birthday good night good afternoon bloody murder
pretty true crime full time gut punch
vibe wholesome content slur word life time
vote jump scares hot chocolate chaotic evil
trump fever dream chaotic energy chaotic good
like guilty pleasure chaotic neutral hot mess
Table 3: Twitter-specific words and bigrams removed from the emotion lexicons.
disability ptsd
psychosis adhd
suicide depressive
depressed disorder
anxiety mental health
anxious mental illness
disabled panic attack
Table 4: Mental health specific terms removed from the emotion lexicons.
E Visualization of Emotion Arcs
In Figure 1, we plot the emotion arcs for the anger-
fear emotion pair, from the negative valence group,
for a tweeter from an MHC group of the Twitter-
STMHD dataset. Emotion scores are computed
and plotted at the utterance-level, i.e, independently
for each tweet by the user. Note that larger win-
dow sizes and overlapping windows will lead to
smoother arcs.
F Emotion Granularity:
Hyperparameters
We report the results of the statistical analyses of
emotion granularity when emotion arcs were gener-
ated using different choices of the hyperparameters
described in Section 4.1. Table 6 reports the results
when non-lexicon terms (and tweets) are assigned
a score of 0, and only mutually-exclusive emotion
terms are considered, similar to Table 2, but no user
thresholds on number of tweets and unique emo-
tion terms are applied. Table 7 reports the results
when non-lexicon terms (and tweets) are not con-
sidered, and user thresholds are set to 50 and 25,
(similar to Table 2), and only mutually-exclusive
emotion terms are considered (similar to Table 2).
We find that largely the results do not change.
However, when non-lexicon terms and tweets are
ignored, this results in a smaller set of tweets to
compute the emotion arc over, and fewer tweeters
who meet the user thresholds for each group. This
results in signals turning off for certain MHCs.F.1 Various Window Sizes
We report the results of the statistical analyses of
emotion granularity when emotion arcs were gen-
erated using two other window sizes: 100 (Table 8)
and 500 (Table 9). All other hyperparameters are
the same as for Table 2.
We find that largely the results do not change,
however there are some differences in the scenario
when the dataset was smaller (e.g., eRisk dataset
or MHC such as MDD). In such cases, when the
window size is increased, it is possible that sev-
eral emotional experiences occurred, resulting in a
weaker signal of emotion granularity.
G Emotion Granularity: Emotion Pairs
In Table 10 we report the pairwise emotion gran-
ularity results when testing for significant differ-
ences between MHCs and the control group.
H Term Specificity Results
Table 11 shows the results of the term specificity
experiments described in Section 5.1 measuring in-
formation content. For both nouns and verbs, none
of the diagnoses had significantly different term
specificity levels compared to the control group in
both the Twitter-STMHD and eRisk datasets. This
verifies that the significant differences between the
MHCs and the control group for emotion granular-
ity is not due to varying word specificity levels in
these groups.
I Emotion Correlations
Table 12 shows the group-averaged Spearman cor-
relations for emotion pairs in the positive, negative,emo1 emo2 e1-all e2-all e12-comm e1-excl e2-excl
anger anticipation 1157 782 43 1114 739
anger disgust 1157 886 407 750 479
anger fear 1157 1343 551 606 792
anger joy 1157 946 3 1154 943
anger sadness 1157 1014 382 775 632
anger surprise 1157 454 102 1055 352
anger trust 1157 1332 6 1151 1326
anticipation disgust 782 886 19 763 867
anticipation fear 782 1343 82 700 1261
anticipation joy 782 946 283 499 663
anticipation sadness 782 1014 32 750 982
anticipation surprise 782 454 131 651 323
anticipation trust 782 1332 283 499 1049
disgust fear 886 1343 400 486 943
disgust joy 886 946 1 885 945
disgust sadness 886 1014 336 550 678
disgust surprise 886 454 56 830 398
disgust trust 886 1332 2 884 1330
fear joy 1343 946 2 1341 944
fear sadness 1343 1014 545 798 469
fear surprise 1343 454 137 1206 317
fear trust 1343 1332 9 1334 1323
joy sadness 946 1014 0 946 1014
joy surprise 946 454 113 833 341
joy trust 946 1332 308 638 1024
sadness surprise 1014 454 73 941 381
sadness trust 1014 1332 3 1011 1329
surprise trust 454 1332 56 398 1276
Table 5: Emotion Lexicons: For each emotion pair (emo1, emo2), the number of terms in each lexicon (e1-all, e2-
all), the number of emotion terms common to the two lexicons (e12-comm), and the number of mutually-exclusive
emotion terms (e1-excl, e2-excl).
Figure 1: Emotion arcs: Tweet-level emotion arcs for anger and fear, for a sampled user from the Twitter-STMHD
dataset.Dataset, MHC–Control IC(n)IC(v)EG (pos)EG (neg )EG (var )EG (cross )EG (overall )
Twitter-STMHD
ADHD–control – – lower lower lower lower lower
Anxiety–control – – lower lower lower lower lower
Bipolar–control – – – lower lower lower lower
MDD–control – – lower – – lower lower
OCD–control – – lower lower lower lower lower
PPD–control – – – lower lower – lower
PTSD–control – – lower lower lower lower lower
Depression–control – – lower lower lower lower lower
Reddit eRisk
Depression–control – – lower lower lower lower lower
Table 6: Emotion Granularity - hyperparameter variations : The difference in emotion granularity between each
MHC group and the control. A significant difference is indicated by the word ‘lower’ or ‘higher’, indicating the
direction of the difference in granularity. Non-lexicon terms and tweets are assigned a score of zero; user tweet and
unique term thresholds are both set to 0, and only mutually-exclusive emotion terms are considered.
Dataset, MHC–Control IC(n)IC(v)EG (pos)EG (neg )EG (var )EG (cross )EG (overall )
Twitter-STMHD
ADHD–control – – lower lower lower lower lower
Anxiety–control – – – lower lower lower lower
Bipolar–control – – lower lower lower lower lower
MDD–control – – – – – – –
OCD–control – – lower lower lower lower lower
PPD–control – – lower lower lower lower lower
PTSD–control – – lower lower lower lower lower
Depression–control – – higher lower lower lower –
Reddit eRisk
Depression–control – – – lower lower lower lower
Table 7: Emotion Granularity - hyperparameter variations : The difference in emotion granularity between each
MHC group and the control. A significant difference is indicated by the word ‘lower’ or ‘higher’, indicating the
direction of the difference in granularity. Non-lexicon terms and tweets are discarded; user tweet and unique term
thresholds are set to 50 and 25, and only mutually-exclusive emotion terms are considered.
mixed valence groups, and the within-group and
cross-group averages, for the Control groups, and
the delta from these values for each MHC in both
datasets.
Table 13 shows the Spearman correlation be-
tween emotion arcs for all pairs of emotions for
the control group. These results indicate that as
baselines largely emotions in the same group (e.g.,
positive, negative, mixed, overall) co-occur more
often than emotions across groups.Dataset, MHC–Control IC(n)IC(v)EG (pos)EG (neg )EG (var )EG (cross )EG (overall )
Twitter-STMHD
ADHD–control – – lower lower higher lower lower
Anxiety–control – – lower lower lower higher lower
Bipolar–control – – lower lower lower – lower
MDD–control – – lower lower – – lower
OCD–control – – lower lower – – lower
PPD–control – – – – lower higher –
PTSD–control – – – lower – higher lower
Depression–control – – lower lower lower higher lower
Reddit eRisk
Depression–control – – lower – lower – lower
Table 8: Emotion Granularity - using window 100 : The difference in emotion granularity between each MHC
group and the control. A significant difference is indicated by the word ‘lower’ or ‘higher’, indicating the direction
of the difference in granularity.
Dataset, MHC–Control IC(n)IC(v)EG (pos)EG (neg )EG (var )EG (cross )EG (overall )
Twitter-STMHD
ADHD–control – – lower lower – lower lower
Anxiety–control – – lower lower lower higher lower
Bipolar–control – – lower lower lower – lower
MDD–control – – – – – – lower
OCD–control – – lower – – – –
PPD–control – – – – – higher –
PTSD–control – – – lower – higher lower
Depression–control – – lower lower lower higher lower
Reddit eRisk
Depression–control – – lower – – – –
Table 9: Emotion Granularity - using window 500 : The difference in emotion granularity between each MHC
group and the control. A significant difference is indicated by the word ‘lower’ or ‘higher’, indicating the direction
of the difference in granularity.
Emotion Pair, MHC-Control ADHD Anxiety Bipolar Depression MDD OCD PPD PTSD
anger–anticipation lower lower – lower – lower – lower
anger–disgust lower lower lower lower lower lower – lower
anger–fear lower lower lower lower – lower lower lower
anger–joy lower lower higher lower – lower – –
anger–sadness lower lower lower lower – lower lower lower
anger–surprise lower lower – lower – lower – lower
anger–trust lower lower lower lower lower lower – lower
anticipation–disgust lower lower lower lower – lower – lower
anticipation–fear lower lower – lower lower lower lower lower
anticipation–joy lower lower lower lower lower lower lower lower
anticipation–sadness lower lower lower lower – lower – lower
anticipation–surprise lower lower lower lower – lower – lower
anticipation–trust lower lower lower lower lower lower lower lower
disgust–fear lower lower lower lower – lower lower lower
disgust–joy lower lower – lower – lower – lower
disgust–sadness lower lower lower lower – lower lower lower
disgust–surprise lower lower lower lower – lower – lower
disgust–trust lower lower lower lower lower lower lower lower
fear–joy lower lower higher lower – lower – lower
fear–sadness lower lower lower lower – lower lower lower
fear–surprise lower lower lower lower – lower – lower
fear–trust lower lower lower lower lower lower lower lower
joy–sadness lower lower – lower – lower – lower
joy–surprise lower lower – lower – lower – lower
joy–trust lower lower lower lower lower lower – lower
sadness–surprise lower lower lower lower – lower lower lower
sadness–trust lower lower lower lower lower lower lower lower
surprise–trust lower lower – lower – lower lower lower
Table 10: Emotion Granularity - emotion Pairs : The difference in emotion granularity between each emotion pair,
for each MHC group and the control in the Twitter-STMHD dataset. A significant difference is indicated by the
word ‘lower’ or ‘higher’, indicating the direction of the difference.df T-Statistic P-value
POS Dataset MHC–Control
Noun Twitter-STMHD ADHD–control 2368.64 -1.94 0.144
Anxiety–control 2233.36 -0.58 0.718
Bipolar–control 1726.26 -2.40 0.131
MDD–control 226.83 -0.52 0.718
OCD–control 1817.93 1.93 0.144
PPD–control 178.33 -0.49 0.718
PTSD–control 2237.82 -0.54 0.718
Depression–control 2245.64 -0.27 0.787
Reddit eRisk Depression–control 128.95 0.98 0.330
Verb Twitter-STMHD ADHD–control 2248.45 -0.73 0.530
Anxiety–control 2235.85 1.12 0.420
Bipolar–control 1852.44 -2.10 0.096
MDD–control 213.0 1.36 0.354
OCD–control 1645.17 2.28 0.091
PPD–control 169.49 0.98 0.438
PTSD–control 2351.12 2.53 0.091
Depression–control 2274.59 0.54 0.589
Reddit eRisk Depression–control 110.40 1.59 0.116
Table 11: Information Content : The degrees of freedom, t-statistic and p-value for the word specificity experiments
described in Section 5.1.
Dataset, MHC EG (pos)EG (neg )EG (var )EG (cross )EG (overall )
Twitter-STMHD
Control 0.027 0.023 0.012 0.006 0.022
ADHD -0.012* -0.008* -0.005* -0.010* -0.010*
Anxiety -0.012* -0.008* -0.003* -0.008* -0.010*
Bipolar -0.004* -0.008* -0.004* -0.002* -0.006*
MDD -0.011* -0.002 -0.001 -0.005* -0.005*
OCD -0.013* -0.009* -0.006* -0.009* -0.009*
PPD -0.005 -0.009* -0.005 -0.004 -0.003
PTSD -0.013* -0.014* -0.006* -0.008* -0.013*
Depression -0.011* -0.005* -0.003* -0.005* -0.008*
Reddit eRisk
Control 0.114 0.117 0.090 0.094 0.112
Depression -0.016* -0.021* -0.012 -0.022* -0.017*
Table 12: Emotion Granularity - Spearman correlations: Spearman correlation values between utterance-level
emotion arcs for the Control group, and the delta for each MHC when compared to the Control group. Emotion
granularity is defined as the negative of these correlations (i.e, higher correlations imply a lower granularity).
Hyperparameters are the same as in Table 2.
anger anticipation disgust fear joy sadness surprise trust
anger – -0.003 0.020 0.027 -0.010 0.024 0.009 0.007
anticipation – – -0.003 0.007 0.021 0.004 0.012 0.027
disgust – – – 0.023 -0.010 0.021 0.006 0.003
fear – – – – -0.003 0.021 0.012 0.013
joy – – – – – -0.000 0.008 0.027
sadness – – – – – – 0.012 0.008
surprise – – – – – – – 0.023
Table 13: Emotion–Emotion Spearman correlations : Spearman correlation values between pairs of utterance-level
emotion arcs for the all users in the control group of the Twitter-STMHD dataset. Hyperparameters are the same as
in Table 2.