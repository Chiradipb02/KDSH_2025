Decoding Matters: Addressing Amplification Bias and Homogeneity Issue
for LLM-based Recommendation
Keqin Bao1,2*Jizhi Zhang1Yang Zhang3†
Xinyue Huo1Chong Chen3Fuli Feng1†
1University of Science and Technology of China,
2Huawei Inc.3National University of Singapore
{baokq, cdzhangjizhi, xinyueh}@mail.ustc.edu.cn ,
chenchong55@huawei.com ,{zyang1580, fulifeng93}@gmail.com
Abstract
Adapting Large Language Models (LLMs) for
recommendation requires careful consideration
of the decoding process, given the inherent dif-
ferences between generating items and natural
language. Existing approaches often directly
apply LLMs’ original decoding methods. How-
ever, we find these methods encounter signifi-
cant challenges: 1) amplification bias—where
standard length normalization inflates scores
for items containing tokens with generation
probabilities close to 1 (termed ghost tokens),
and 2) homogeneity issue—generating multiple
similar or repetitive items for a user. To tackle
these challenges, we introduce a new decod-
ing approach named Debiasing-Diversifying
Decoding (D3).D3disables length normaliza-
tion for ghost tokens to alleviate amplification
bias, and it incorporates a text-free assistant
model to encourage tokens less frequently gen-
erated by LLMs for counteracting recommen-
dation homogeneity. Extensive experiments on
real-world datasets demonstrate the method’s
effectiveness in enhancing accuracy and diver-
sity. The code is available at https://github.
com/SAI990323/DecodingMatters .
1 Introduction
Researchers have endeavored to adapt Large Lan-
guage Models (LLMs) for recommender systems,
seeking to harness the remarkable abilities of LLMs
to improve recommendation performance (Bao
et al., 2023b; Zhang et al., 2023a; Wei et al., 2024;
Harte et al., 2023). Numerous adaptation solu-
tions have been proposed, with some showcasing
notable success. Among these, using LLMs to per-
form recommendations in a generative manner is
particularly promising (Bao et al., 2023a; Tan et al.,
2024; Zheng et al., 2024). This approach involves
teaching LLMs to directly generate suitable item
*Work is done during internship at Huawei Inc.
†Corresponding Authorrepresentations ( e.g., item titles) as recommenda-
tions based on given instructions. By doing so, this
approach aligns well with the generative nature of
LLMs, potentially enabling a more effective utiliza-
tion of their capabilities for recommendation.
To generate an item, LLMs must produce a se-
quence of tokens representing the item, necessitat-
ing multi-step decoding during generation. Exist-
ing approaches typically adopt original decoding
strategies of the utilized language models, such as
beam search (Bao et al., 2023a; Zheng et al., 2024;
Tan et al., 2024). However, there are distinct dispar-
ities between generating recommended items and
natural language (Bao et al., 2023a; Zheng et al.,
2024). For instance, in terms of the generation
space, items only correspond to a specific, non-
uniformly sampled subset of the entire language
space; in terms of generation results, a set of items
should be recommended, as opposed to only ond
appriopriate language output required in typical
NLP tasks. These distinctions potentially introduce
new challenges for directly applying the heuristic
decoding strategies.
This work delves into studying the decoding pro-
cess of LLMs for generating recommendations. We
identified two potential critical issues for applying
the original decoding strategies of LLMs:
•Amplification Bias: Due to the non-uniform dis-
tribution of items in the language space, some
items may contain tokens with generation prob-
abilities close to 1 under certain conditions (re-
ferred to as ghost tokens). Existing decoding
methods tend to enhance the scores for these
items. Typically, these methods utilize length
normalization to counteract the length bias dur-
ing generation (Wu et al., 2016; Vaswani et al.,
2017) — longer sequences tend to have lower
probabilities than shorter sequences merely due
to the multiplication of probabilities for each to-
ken. However, when ghost tokens appear, mul-
tiplying their generation probabilities (near 1)arXiv:2406.14900v3  [cs.IR]  5 Nov 2024doesn’t significantly decrease the final score, but
length normalization is still applied, resulting in
score amplification.
•Homogeneity Issue: With the original decoding
methods, LLMs often produce items with similar
structures and content when offering multiple rec-
ommendations to a user, as textually similar se-
quences typically receive similar scores. For ex-
ample, when suggesting products, the model may
recommend several items from the same series
or category (e.g., “PlayStation 3” and “PlaySta-
tion 4”). Moreover, the model frequently repeats
item features based on past user interactions, due
to inheriting the match-and-copy mechanism of
LLMs (Olsson et al., 2022; Wang et al., 2022).
Both amplification bias and homogeneity issues
would undeniably exert substantial influences on
recommendation quality, impacting factors such
as accuracy and diversity. Addressing these issues
is crucial. However, this endeavor is undoubtedly
non-trivial. As discussed, the emergence of ampli-
fication bias is intricately linked with the process
of addressing the length bias of LLMs’ generation.
Therefore, it’s crucial to navigate addressing ampli-
fication bias without reintroducing the length bias.
Meanwhile, to address the homogeneity issue, we
must enhance the generation probability of tokens
in LLM that receive less attention. However, there
is a lack of clear guidance on how to balance the
original predictions with enhancing less attention
tokens and which tokens to select.
To this end, we introduce a novel strategy called
Debiasing-Diversifying Decoding (D3). To miti-
gate amplification bias while still addressing length
bias,D3considers selectively applying length nor-
malization to tokens while excluding it for ghost
tokens. When implementing, we find that exclud-
ing ghost tokens results in relatively uniform item
lengths, making the remaining length normaliza-
tion unnecessary. Consequently, D3removes all
length normalization during decoding, facilitating
its implementation. To tackle the homogeneity is-
sue,D3incorporates scores from a text-free assis-
tant model at each decoding step to guide token
generation. This helps avoid generating similar
and repetitive items, as the text-free model is not
influenced by repetitive text and can provide mean-
ingful non-repeated/non-similar token suggestions
based on its recommendation capabilities.
In total, our contribution is as follows:
•We highlight the importance of decoding strate-gies for LLMs’ generation in recommendation
scenarios and identify two critical challenges:
amplification bias towards items with ghost to-
kens and the homogenous issues of generating
similar and repeated items.
•We point out the ghost token and the repetition
phenomenon and propose to mitigate this issue
by removing the length penalty and utilizing a
text-free assistant model.
•Extensive experiments have demonstrated that
our methods can simultaneously enhance the ac-
curacy and diversity of recommendations.
2 Related Work
In this section, we will briefly introduce the devel-
opment and status of the related fields of this article,
mainly including LLMs for recommender systems
and decoding strategies for language models.
2.1 Large Language Models for
Recommender Systems
The remarkable capabilities demonstrated by
LLMs have sparked interest within the recom-
mender systems community, leading to a surge
in research aimed at integrating LLMs into these
systems (Wu et al., 2023; Lin et al., 2023a; Bao
et al., 2024). This research can be broadly di-
vided into two streams. The first stream involves
directly utilizing LLMs as encoders to represent
items, which are then input into conventional rec-
ommendation models (Yuan et al., 2023; Xi et al.,
2023). However, the prevalent LLMs are primar-
ily decoder-only architectures, optimized for next-
token-prediction, which is not conducive to infor-
mation encoding. This limitation potentially con-
strains the full potential of LLMs in recommenda-
tion tasks.
The second stream of research focuses on har-
nessing the generative power of LLMs to pro-
duce recommendations directly (Lin et al., 2023b;
Liao et al., 2024; Wang et al., 2023; Zhang et al.,
2023b, 2024a,b). Despite this approach, it has
been observed that LLMs have limited exposure to
recommendation-specific data during pre-training,
necessitating fine-tuning for effective application
in this domain. While methods of this nature are
on the rise, they often prioritize improving LLMs’
recommendation performance through training en-
hancements, overlooking a crucial aspect: the de-
tailed examination of the models’ recommendation
outputs and the considerations for the decodingphase.
2.2 Decoding in Language Model
In the domain of open-ended text generation, the
issue of diversity has garnered significant atten-
tion, primarily due to the inherent dependency of
language models on maximizing probability dur-
ing the generation process (Welleck et al., 2020;
Holtzman et al., 2020). To address this, a common
approach is to adjust the temperature parameter.
This method modifies the sharpness of the proba-
bility distribution of tokens at each step of genera-
tion, reducing the likelihood of exceedingly similar
outcomes due to overly high probabilities of spe-
cific tokens being chosen. Beyond this, Diverse
Beam Search (DBS) (Vijayakumar et al., 2016)
introduces the concept of beam groups, partition-
ing the generation process to manage similarity
across different groups, thereby increasing the di-
versity of the generated results. Currently, due to
the differences in the decoding space, using LLMs
for recommendations presents unique challenges.
There is a lack of comprehensive discussion on the
decoding stage in this field. In this paper, we con-
duct the first exploratory analysis and optimization
of the decoding process and the recommendations.
The second stream of research focuses on har-
nessing the generative power of LLMs to pro-
duce recommendations directly (Lin et al., 2023b;
Liao et al., 2024; Wang et al., 2023; Zhang et al.,
2023b, 2024b). Despite this approach, it has
been observed that LLMs have limited exposure to
recommendation-specific data during pre-training,
necessitating fine-tuning for effective application
in this domain. While methods of this nature are
on the rise, they often prioritize improving LLMs’
recommendation performance through training en-
hancements, overlooking a crucial aspect: the de-
tailed examination of the models’ recommendation
outputs and the considerations for the decoding
phase.
3 Preliminary
In this section, we will introduce the background
knowledge of the decoding process of current LLM-
based recommender (recLLM) methods.
Considering the decoding process, the model
takes an instruction input and a sequence of user
historical interactions to generate a suitable token
sequence representing a recommended item. Our
input, of length n, is denoted as x=x1···xn,where each xiis a token from the model’s vocab-
ulary V. During decoding, an item is represented
by generating a sequence of tokens having length
m, denoted as y=y1···ym. At decoding time, to-
kens are generated iteratively, one at a time, condi-
tioned on the previous context and expect to select
the output with the highest probability:
p(y|x) =mY
i=1p(yi|x, y<i), (1)
where p(yi|x, y<i)represents the probability dis-
tribution of the next token. However, given the
impracticality of traversing all possible scenarios
to calculate this probability, the greedy search can
apply to select the token xiwith the highest proba-
bility at each step.
Beam Search. Due to the limitations of greedy
decoding methods, which can only generate a sin-
gle item and often fail to find the optimal sequence
of items (Holtzman et al., 2020), researchers cur-
rently using LLMs for recommendation typically
employ beam search methods to generate multi-
ple items simultaneously (Zheng et al., 2024; Tan
et al., 2024). In detail, the formula for calculating
the score for a hypothesis hat step tin beam search
is:
S(h≤t) =S(h≤t−1) + log( p(ht|x, h≤t−1)),(2)
where S(h≤t)is the score of the hypothesis up to
steptused for selecting hypothesis, p(ht|x, h≤t−1)
is the conditional probability of the token htgiven
the previous hypothesis h≤t−1and the input x.
The beam search keeps track of the top Bhy-
potheses at each step based on their scores, where
Bis the beam width. It then expands each of these
hypotheses by considering the kmost likely tokens.
The new hypotheses are scored according to the
above formula, and the top Bhypotheses are re-
tained for the next step. This process continues
until an end-of-sequence token is predicted or the
maximum sequence length is reached. Moreover,
in natural language generation, to avoid repetitive-
ness and overly long outputs, a length normaliza-
tion term is typically added after the generation is
complete.
S(h) =S(h)/hα
L, (3)
where hLis the length of the h,αis the hyper-
parameters to control the length penalty. Once the
beam search is completed, the top Bhypotheses
are selected as the final output [y1, y2, ..., y B].4 Issues for Existing Decoding Method
In this section, we elaborate on the amplification
bias and homogeneity issues of the existing decod-
ing method, clarifying our motivation.
4.1 Amplification Bias
As discussed, due to the non-uniformity of the item
generation space, there are ghost tokens whose gen-
eration becomes deterministic once their preceding
tokens have appeared. The model easily learns this
deterministic characteristic during training and sub-
sequently assigns a near 1-generation probability
to these tokens during the generation phase. For
Eq. (2) and Eq. (3), it is evident that these tokens
minimally impact the value of Sbut increase the
length hL. This means they act like ghosts, occu-
pying a sequence position without changing the
scoreS. Consequently, if the length normalization
in Eq. (3) is still applied, the final score would be
improperly amplified.
4.2 Homogeneity Issue
Next, we illustrate the homogeneity issue in gen-
erated results by analyzing the recommendation
similarity within a recommended list and their rela-
tive repetition compared to historical data.
Recommendation Similarity. We note that the
top-10 recommendations from recLLM often begin
with similar tokens, reducing diversity. To compare,
we examine the first 5 tokens in these recommen-
dations against those from conventional models1.
Furthermore, we also assess the category diversity
of the recommended items. As depicted in Fig-
ure 1a, we utilized BLEU to measure the textual
similarity among recommendation results, and En-
tropy to assess the category diversity. It is evident
that, compared to traditional models, the results
from recLLMs exhibit higher degrees of similari-
ties. This suggests that, despite their impressive
performance, LLMs tend to generate multiple ho-
mogeneous recommendations, given a user. This
homogeneity might be attributed to the excessive
scores given to the first few similar tokens by the
beam search, which makes it challenging for more
diverse outcomes to be included in the final candi-
date generations (Vijayakumar et al., 2016).
Repetition Phenomenon. Looking deeper, we
observe that certain tokens repetitively appear both
1For traditional models, we replaced the item IDs they
produced with their corresponding textual representations.in the recommended items and historically inter-
acted items. Thus, we continue our analysis to
determine the extent of similarity between the rec-
ommended items and the user’s historical inter-
actions. Similarly, we computed the textual and
categorical similarities between the recommenda-
tions generated by LLMs/traditional models and
users’ historical interaction records. As illustrated
in Figure 1c, we observe that similar to the pre-
ceding findings, the recommendations based on
recLLM also exhibit higher similarity to users’ his-
torical interaction sequences. This suggests that
while incorporating textual information offers cer-
tain benefits, it also introduces a new bias: the
model tends to copy from the preceding text (Ols-
son et al., 2022), leading to a prevalence of similar
items in the recommendations.
5 Debiasing-Divesifying Decoding
Next, we introduce Debiasing-Diversifying Decod-
ing, which incorporates two new designs into the
existing method to address the two issues.
Remove Amplification Bias. To address amplifi-
cation bias, according to its source, an intuitive ap-
proach is to exclude ghost tokens when calculating
the sequence length for normalization in Eq. (3). In
essence, apply length normalization only to normal
tokens. However, our analysis reveals that remov-
ing these tokens results in item token sequences
with a much uniform length distribution, making
length normalization for the remaining tokens un-
necessary2. Therefore, we opt to directly eliminate
the length normalization to neutralize the impact of
the ghost token and remove the amplification bias
for the decoding.
Address Homogeneity Issue. In light of the Ho-
mogeneity analysis, we conclude that during beam
search, numerous potential recommendation out-
comes are prematurely pruned due to the domi-
nance of certain tokens with exceptionally high
scores (Vijayakumar et al., 2016). Consequently,
this not only impairs the recommendation quality
but also the recommendation diversity. To address
this issue, it is imperative to refine the model’s scor-
ing mechanism to ensure a more soft distribution
of scores, thereby broadening the range of choices
available during the generation phase. Hence, we
aim to adjust the score of each candidate token at
2The detailed analysis can be seen in Appendix §CIn. Bo. CD.
Dataset103050BLEUSASRec
BIGRec(a)
In. Bo. CD.
Dataset246EntrophySASRec
BIGRec (b)
In. Bo. CD.
Dataset1020BLEUSASRec
BIGRec (c)
In. Bo. CD.
Dataset0.10.30.5RatioSASRec
BIGRec (d)
Figure 1: Homogeneity comparison of recommendation results between recLLM method BIGRec and traditional
method SASRec on three datasets: Instruments (In.),Books (Bo.), and CDs (CD.). (a) and (b) show text similarity
and category diversity (measured by entropy) for the first 5 tokens within the top 10 recommendations, where higher
similarity and lower entropy indicate greater homogeneity. (c) and (d) display text similarity and category repetition
in top-10 recommendations compared to historical interactions.
each step to help recLLM better generate the item
to be recommended.
To achieve this objective, the key is to boost the
scores of tokens that are meaningful but underesti-
mated by recLLM, while avoiding excessive disre-
gard of tokens with higher scores from recLLM to
maintain recommendation performance. Relying
solely on recLLM’s predictions to accomplish this
is challenging. Therefore, we propose leveraging
an additional text-free model to assist. Although
this model has poor recommendation abilities, it
can still provide meaningful recommendation pro-
posals, which are less prone to textual similarity
issues, for recLLM reference.
In detail, we leverage the text-free model to gen-
erate additional scores for tokens at each decoding
step, using these scores to refine the token scores
of recLLM. Let Idenote the set of all items, and
Iidenote the i-th item. We denote the probabil-
ity of the text-free model to recommending Iias
pTF(Ii). At a decoding step, given the hypothesis
h<tthat has already been produced, we need to
generate a new token htbased on it. For which,
only a subset of items is eligible for the generation,
that is, the items matching with h<t, denoted as
Ih<t. Based on this set, we define the token score
STF(h≤t)of the text-free model for a potential
token htas follows:
LTF(ht|h≤t−1) =log P
i∈Ih<t,htpTF(Ii)
P
i∈Ih<tpTF(Ii)!
, (4)
STF(h≤t) =STF(h≤t−1) +LTF(ht|h≤t−1),(5)
pTF(Ii) = 0( Ii/∈ G) (6)
where Ih<t,htdenote the items in Ih<twith ht
coming after h<t,LTF(ht|h≤t−1)denotes the log
probability for the token by the text-free assistant
model, similar to Eq. (2). Then the overall score
function we used to guide the recLLM to generatestep by step is:
˜S(h≤t) =α∗ S(h≤t) + (1 −α)∗ STF(h≤t),(7)
where αis a hyper-parameter to control the assis-
tance level of the text-free model. Notably, S(h≤t)
is computed without the length normalization.
This formulation indicates that during each step
of generation, we do not completely depend on the
knowledge encoded within the recLLM. Instead,
we harness logits from a text-free model, which
is detached from linguistic context, to guide the
recLLM in generating. By infusing text-free model
inferences at every stage, we mitigate the homo-
geneity and redundancy that stem from the model’s
overdependence on language-based attributes.
6 Experiment
6.1 Experimental Settings
6.1.1 Dataset
We conduct experiments on six real-world datasets
from Amazon review data3, including Instruments ,
CDs,Games ,Toys,Sports , and Books . All datasets
contain user review data from May 1996 to Octo-
ber 2018. To preprocess the data, we follow the
strategy outlined in the BIGRec paper to truncate
the dataset based on time information, considering
the high cost of training LLMS. Moreover, we filter
out unpopular users and items with fewer than five
interactions and set the maximum item sequence
length to 10 to meet the baseline requirements. De-
tails of the preprocessing steps and statistics of the
processed datasets can be found in Appendix §A.
3https://cseweb.ucsd.edu/~jmcauley/datasets.
html#amazon_reviews .Table 1: Recommendation accuracy of the compared methods on different-domain datasets.“+Temp” denotes
adjusting the temperature coefficient for BIGRec’s decoding. “+ D3” denotes applying our decoding method to
TIGER/BIGRec. The best results are bolded.
Datasets Metrics Caser GRU4Rec SASRec GRU4Rec* SASRec* TIGER +D3BIGRec +Temp +D3
NDCG@5 0.0550 0.0562 0.0643 0.0712 0.0672 0.0764 0.0785 0.0813 0.0795 0.0816
HR@5 0.0678 0.0681 0.0715 0.0843 0.0798 0.0853 0.0893 0.0929 0.0897 0.0938
NDCG@10 0.0595 0.0614 0.0676 0.0772 0.0731 0.0797 0.0830 0.0856 0.0841 0.0871Instruments
HR@10 0.0817 0.0843 0.0817 0.1030 0.0980 0.0958 0.1032 0.1062 0.1040 0.1110
NDCG@5 0.0161 0.0248 0.0477 0.0435 0.0418 0.0484 0.0620 0.0640 0.0513 0.0823
HR@5 0.0224 0.0342 0.0647 0.0566 0.0561 0.0559 0.0748 0.0786 0.0674 0.1025
NDCG@10 0.0193 0.0288 0.0535 0.0482 0.0478 0.0512 0.0659 0.0694 0.0579 0.0871CDs
HR@10 0.0485 0.0467 0.0824 0.0715 0.0745 0.0646 0.0868 0.0956 0.0879 0.1090
NDCG@5 0.0122 0.0169 0.0237 0.0282 0.0263 0.0367 0.0394 0.0318 0.0279 0.0415
HR@5 0.0187 0.0261 0.0338 0.0407 0.0383 0.0495 0.0521 0.0420 0.0379 0.0565
NDCG@10 0.0164 0.0221 0.0290 0.0352 0.0328 0.0417 0.0453 0.0372 0.0355 0.0480Games
HR@10 0.0321 0.0423 0.0502 0.0624 0.0586 0.0651 0.0706 0.0610 0.0553 0.0767
NDCG@5 0.0228 0.0200 0.0356 0.0367 0.0371 0.0421 0.0487 0.0570 0.0497 0.0652
HR@5 0.0316 0.0275 0.0473 0.0518 0.0531 0.0534 0.0610 0.0739 0.0660 0.0841
NDCG@10 0.0276 0.0238 0.0398 0.0422 0.0433 0.0465 0.0535 0.0643 0.0565 0.0713Toys
HR@10 0.0465 0.0392 0.0745 0.0688 0.0721 0.0668 0.7600 0.0965 0.0871 0.1025
NDCG@5 0.0439 0.0586 0.0695 0.0577 0.0627 0.0846 0.0876 0.0932 0.0870 0.0970
HR@5 0.0541 0.0663 0.0770 0.0760 0.0785 0.0915 0.0964 0.1040 0.0977 0.1083
NDCG@10 0.0469 0.0618 0.0725 0.0624 0.0677 0.0869 0.0901 0.0975 0.0918 0.1013Sports
HR@10 0.0633 0.0761 0.0866 0.0906 0.0939 0.0984 0.1040 0.1171 0.1125 0.1215
NDCG@5 0.0042 0.0060 0.0097 0.0076 0.0103 0.0145 0.0181 0.0182 0.0197 0.0217
HR@5 0.0069 0.0094 0.0146 0.0119 0.0128 0.0183 0.0233 0.0239 0.0253 0.0280
NDCG@10 0.0060 0.0078 0.0123 0.0099 0.0151 0.0157 0.0200 0.0204 0.0218 0.0240Books
HR@10 0.0123 0.0149 0.0226 0.0189 0.0229 0.0220 0.0290 0.0308 0.0317 0.0353
6.1.2 Evaluation Protocal
To evaluate the model’s top-K recommendation per-
formance (accuracy), we use two commonly used
metrics: Hit Ratio (HR@K) and Normalized Dis-
counted Cumulative Gain (NDCG@K) (Bao et al.,
2023a; Rajput et al., 2024), which we compute us-
ing the all-ranking protocol (Krichene and Rendle,
2020). In this paper, we set K as 5 and 10. To better
align with real-world scenarios, we follow previous
work (Bao et al., 2023a) when dividing the dataset,
that is, splitting a dataset into training, validation,
and test sets according to timestamps. This ensures
that there will be no data leakage issues (Ji et al.,
2023) during the training and testing of the model.
6.1.3 Baselines
We adopt the following representative sequential
recommendation models as baselines for our exper-
imental comparison:
- Caser (Tang and Wang, 2018) is a method using
CNN that models user behaviors through hori-
zontal and vertical convolutional.
-GRU4Rec (Hidasi et al., 2016) is an RNN-based
method that uses GRU to model the user behavior
via encoding the item sequence.
-SASRec (Kang and McAuley, 2018) is a methodusing Transformer to model the item sequences.
-GRU4Rec* (Hidasi et al., 2016) is similar to
GRU4Rec but uses the LLM-based embedding
to initialize the item embedding.
-SASRec* (Kang and McAuley, 2018) is similar
to SASRec but uses the LLM-based embedding
to initialize the item embedding.
-TIGER (Rajput et al., 2024) is a generative re-
trieval paradigm for sequential recommendation
and introduces a semantic ID to uniquely identify
items. We extend to LLMs, using the instruction
combined with semantic ID, and generate mul-
tiple semantic ID sequences representing items
during the recommendation process.
-BIGRec (Bao et al., 2023a) is a method that uses
instruction-tuning to directly generate items. We
have made changes to the decoding method of
this approach, ensuring that the produced results
are always within the item list of the dataset.
6.1.4 Implementation Details
For the traditional recommendation models, we op-
timize them using binary cross-entropy loss and the
Adam optimizer with a learning rate searched in
[1e-2,1e-3,1e-4]. We process the data in batches
of size 1024, and we adjust the weight decaywithin the range of [1e-2,1e-3,1e-4,1e-5,1e-6].
For LLM-based methods, for efficiency, we apply
Qwen1.5-1.8B (Bai et al., 2023) as the backbone
LLM. we use the AdamW (Loshchilov and Hut-
ter, 2019) optimizer and adjust the learning rate
within the range of [1e-3,1e-4,5e-5]. During the
training, we applied the cosine learning scheduler
for 3 epochs and set the early stop patience as one
epoch4. In our experiments related to the tempera-
ture coefficient, we adjusted it within the range of
[1.0,1.5,2.0]. All experiments were conducted on
an Ascend 910B with 32GB VRAM.
6.2 Main Results
In this subsection, we study the recommendation
performance of our proposed D3method over six
open-world datasets. As shown in Table 1, it show-
cases our primary experimental results. Notably,
the results can be categorized into the following
groups: traditional models (Caser, GRU4Rec, SAS-
Rec), traditional models enhanced by LLM embed-
dings (GRU4Rec*, SASRec*), TIGER with dif-
ferent decoding methods, recLLM (BIGRec) with
different decoding strategies. Regarding recLLM
decoding, we investigate not only its default strat-
egy and our D3approach but also a temperature
scaling coefficient strategy (denoted as “+temp")
commonly used to adjust generation scores. As
for TIGER, despite not being fully LLM-based, we
still apply our method for it to verify our method’s
wide applicability. From the table, we have the
following observations:
•When compared to the baseline, our decoding
approach with recLLM often gets better perfor-
mance, surpassing all baselines to achieve the
best recommendation performance on all datasets.
This underscores the significance of studying the
decoding strategy for recLLM and demonstrates
the superiority of our decoding method which
removes the amplification bias and alleviates the
homogeneity issue.
•Considering that TIGER also employs beam
search for generation during decoding, it may
face similar challenges to recLLM. We applied
ourD3approach to TIGER. Comparing the re-
sults of the original TIGER and the variant with
D3(columns 8 and 9), we observe improvements
4In our preliminary experiments, we found that for LLMs
trained on the entire dataset, the model generally converges
after only 1 to 2 epochs of training. When we opt to use a
language-agnostic model to assist the recommendation model
based on LLM in inference, we simply employ the SAS-
Rec (Kang and McAuley, 2018)when using our strategy. This demonstrates the
generality of our method, indicating that it is
also suitable for non-linguistic, generation-based
recommendation systems.
•In comparing TIGER (using LLMs but present-
ing items with semantic IDs) with the recLLM
method BIGrec, we find that to leverage LLMs,
it is more suitable to directly represent items with
text. We conjecture that this may be due to the
fact that, while TIGER incorporates information
from LLMs during the training of its encoder,
using LLMs as encoders can result in the loss of
some information. Additionally, using the com-
plete textual representation of items allows for
the full utilization of the knowledge learned by
the LLM.
•We found that simply adjusting the decoding tem-
perature does not improve recommendation per-
formance, although it may enhance recommen-
dation diversity (discussed later in Figure 2).
7 Analysis
This section further explores our decoding ap-
proach in detail and discusses potential extensions.
First, we conduct an ablation analysis to validate
the influence of our two key strategies on recom-
mendation accuracy. We then examine the impact
of the method’s designs on recommendation diver-
sity and investigate an extension of our methods
which can enable easy adjustment of the recom-
mendation type distribution. Finally, we validate
the generalizability of the proposed method using
additional backbones, approaches, and datasets.
7.1 Ablation
To evaluate the influence of different components
of the proposed method D3on accuracy, we con-
ducted ablation studies here. The core elements of
D3include 1) removing length normalization to ad-
dress amplification bias, denoted by “RLN”, and 2)
integrating a text-free assistant model for augment-
ing diversity, denoted as “TFA”. We systematically
deactivated the components one by one to analyze
their effects. The results are summarized in Table 2,
where we draw the following conclusions:
-Disabling the removal of length normalization (“-
RLN”) or the text-free assistant (“-TFA”) model
could both lead to decreased performance com-
pared to the complete version of D3. These re-
sults emphasize the importance of both designs
in addressing their respective issues. Notably,Table 2: Ablation results for “ D3” in terms of accuracy, reporting HR@10. “Baseline” denotes recLLM’s original
decoding, serving as a reference here. “- RLN” denotes deactivating the operation of D3on length normalization,
i.e., deactivating addressing amplification bias. “- TFA” denotes deactivating the use of the text-free model.
Instruments Books CDs Sports Toys Games
Baseline 0.1062 0.0308 0.0956 0.1171 0.0965 0.0610
D30.1111 0.0354 0.1190 0.1215 0.1025 0.0767
- RLN 0.1093 0.0353 0.1000 0.1200 0.0975 0.0659
- TFA 0.1086 0.0309 0.1115 0.1192 0.1006 0.0732
In. Bo. CD. Sp. To. Ga.
Dataset2345EntrophyBIGRec
+TFA+Temp
+Temp+TFA
Figure 2: Recommendation diversity (measured by en-
tropy) of the original BIGRec and the variants with other
decoding strategies. “+TFA” denotes the variant apply-
ing our text-free model assistant decoding, “+Temp”
denotes the variant using the widely-used temperature
scaling to increase diversity, and “+Temp+TFA” denotes
the variant combining “+TFA” and “+Temp”. Smaller
entropy denotes less diversity.
homogeneous recommendations could also limit
recommendation accuracy, so the “-TFA” model
also exhibits decreased performance.
-When applying “-RLN” or “-TFA” to D3, only
one of the D3designs is effective, yet it still out-
performs the Baseline. This indicates the pres-
ence of both the amplification bias and homo-
geneity issue and demonstrates that addressing
them individually can lead to performance im-
provements.
7.2 Diversity
As discussed in our previous work, existing gen-
eration strategies often result in homogeneous rec-
ommendations. In D3, we integrate a text-free
assistant to address the issue. Here, we further
investigate this design by exploring two research
questions: (1) Can the use of a text-free assistant
(TFA) model improve recommendation diversity?
(2) How does the effect of TFA combined with
diversity-enhancing decoding strategy (tempera-
ture adjustment)? As shown in the Figure 2, we
have the following findings:
•Adjusting the temperature improves diversity, but
In. Bo. CD.
Dataset0.10.30.5RatioOrigin
Control
In. Bo. CD.
Dataset0.040.080.120.16HR@10Origin
ControlFigure 3: Effectiveness of employing the proposed TFA
to enhance recommendation ratio (left) and accuracy
(right) for a specified target category of items.
as Table 1 shows, it results in lower performance.
•Using a text-free model for assisted decoding can
not only improve the recommendation accuracy
but also enhance recommendation diversity.
•Utilizing a text-free model for assisted decoding
is a plug-and-play approach. It can be combined
with temperature adjustment to further improve
the diversity of recommendation results.
7.3 Distribution Adjustment
Datasets CID +D3BIGRec +D3
CDs 0.0610 0.0921 0.0869 0.1179
Games 0.0447 0.0598 0.0727 0.0856
Table 3: We report the HR@10 results of our meth-
ods on another approach – CID (Hua et al., 2023) and
another backbone –Llama3.1-8B (Dubey et al., 2024).
“+D3” denotes applying our decoding method. The best
results are bolded.
Taking it one step further, since we can use a text-
free model to assist LLMs in decoding, we can also
use a similar approach to control the distribution
of recommendation results when we have specific
recommendation needs. For instance, we could
recommend more computer-related books to users
in the computer science field. Specifically, this
involves strengthening the logits of certain items
during the assisted decoding process.
To validate this extension attribute, we simulateda scenario where we need to directionally enhance
the recommendation of a specific group of items
and improve recommendation accuracy for that
group. Therefore, when using the text-free model,
we only assist items of that particular group. As
shown in Figure 3, we plotted5the proportion of
recommendations for specific categories before and
after the control, and the recommendation perfor-
mance. We can see that through this approach, we
significantly improved the recommendation propor-
tion and accuracy for specific categories of items.
This verifies the feasibility of the extension of our
method to adjust the recommendation distribution
during the decoding stage.
7.4 Generalizability
To show the generalizability of our methods, we
conduct further experiments using additional back-
bones, approaches, and datasets. In detail, as
shown in Table 3, we present the results of ap-
plying our decoding method to a new backbone
model, Llama3.1-8B (Dubey et al., 2024), and a
new item representation approach, CID (Hua et al.,
2023), on the CDs and Games datasets. The find-
Metrics BIGRec +D3
NDCG@10 0.0277 0.0398
HR@10 0.0563 0.0814
Table 4: We report the NDCG@10 and HR@10 results
of our methods on steam datasets (Kang and McAuley,
2018). “+ D3” denotes applying our decoding method.
The best results are bolded.
ings demonstrate consistent improvements in per-
formance with both the new backbone and the new
method, highlighting the generalizability and effec-
tiveness of our decoding approach. Besides, we
have also applied our approach to the Steam (Kang
and McAuley, 2018) dataset. Given the substantial
size of this dataset, we randomly selected 10% of
the users to expedite the validation process of our
method. The results of our experiments are pre-
sented in Table 4. These findings demonstrate that
our decoding method is not only applicable to other
platforms and datasets but also further validates the
generalizability of our approach.
5Resuls on other three datasets are shown in Figure 5.8 Conclusion
In this paper, we begin by conducting a comprehen-
sive analysis of the decoding strategies currently
used in LLMs for recommendation, highlighting
the critical role of the decoding process. During the
analysis, we identify two major issues in existing
methodologies: (1) amplification bias, i.e.,ampli-
fying scores for items with ghost tokens, and (2)
homogeneity issue, i.e.,generating highly similar
recommendations and easy-to-produce recommen-
dations with textual features similar to historical
interactions This work introduces a novel approach,
D3, to address the issues by eliminating length nor-
malization and incorporating a text-free model to
assist in decoding. Extensive experimental results
demonstrate that D3could significantly enhance
recommendation accuracy and diversity. Further-
more, the method can be generalized to non-text
generative recommendation frameworks, such as
TIGER, indicating its versatility and effectiveness
in improving recommendation systems.
Acknowledgments
This work is supported by the National Natural
Science Foundation of China (62272437), and the
advanced computing resources provided by the Su-
percomputing Center of the USTC.
Limitations
This paper primarily focuses on the issues and chal-
lenges that arise when deploying LLMs in the do-
main of recommendation systems, particularly at
the decoding phase, and offers a viable and effec-
tive solution. However, our study has several limi-
tations: 1) The experiments conducted in this study
are solely based on the Qwen1.5-1.8B model. 2)
The current investigation emphasizes performance
enhancement in sequential recommendation tasks.
Although the method introduced in this paper does
not significantly increase the inference time com-
pared to existing recLLM methods, it encounters
efficiency issues in inference when applied to real-
world recommendation scenarios. A potential so-
lution to address the inference efficiency problem
is to eliminate the generation of ghost tokens. By
integrating existing generation technologies like
vLLM (Kwon et al., 2023), it is possible to signifi-
cantly reduce the number of inference tokens and,
consequently, the inference time. However, due to
the limitations of our experimental setup and thefact that our primary focus was not on this topic, it
was not experimentally tested in this paper.
Ethical Considerations
In this paper, we introduce D3to mitigate am-
plification bias and the problem of homogeneity
in existing LLM-based recommendation decoding
strategies, without introducing new ethical dilem-
mas. We employ publicly available data while care-
fully avoiding sensitive information. Nevertheless,
as recommendations depend on user behavior data,
privacy issues may arise. These concerns can be
managed by securing user consent. Moreover, the
usage of LLMs might perpetuate unseen societal
biases. We recommend comprehensive risk evalu-
ations and caution users about the potential risks
associated with model deployment.
References
Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang,
Xiaodong Deng, Yang Fan, Wenbin Ge, Yu Han, Fei
Huang, et al. 2023. Qwen technical report. arXiv
preprint arXiv:2309.16609.
Keqin Bao, Jizhi Zhang, Xinyu Lin, Yang Zhang, Wen-
jie Wang, and Fuli Feng. 2024. Large language
models for recommendation: Past, present, and fu-
ture. In Proceedings ofthe47th International ACM
SIGIR Conference onResearch andDevelopment in
Information Retrieval, pages 2993–2996.
Keqin Bao, Jizhi Zhang, Wenjie Wang, Yang Zhang,
Zhengyi Yang, Yancheng Luo, Chong Chen, Fuli
Feng, and Qi Tian. 2023a. A bi-step grounding
paradigm for large language models in recommenda-
tion systems. arXiv preprint arXiv:2308.08434.
Keqin Bao et al. 2023b. Tallrec: An effective and effi-
cient tuning framework to align large language model
with recommendation. In RecSys , pages 1007–1014.
ACM.
Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey,
Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman,
Akhil Mathur, Alan Schelten, Amy Yang, Angela
Fan, et al. 2024. The llama 3 herd of models. arXiv
preprint arXiv:2407.21783.
Jesse Harte, Wouter Zorgdrager, Panos Louridas, As-
terios Katsifodimos, Dietmar Jannach, and Marios
Fragkoulis. 2023. Leveraging large language mod-
els for sequential recommendation. In Proceedings
ofthe17th ACM Conference onRecommender
Systems, pages 1096–1102.
Balázs Hidasi, Alexandros Karatzoglou, Linas Bal-
trunas, and Domonkos Tikk. 2016. Session-
based recommendations with recurrent neural net-
works. 4thInternational Conference onLearning
Representations, ICLR 2016.Ari Holtzman, Jan Buys, Li Du, Maxwell Forbes,
and Yejin Choi. 2020. The curious case of neural
text degeneration. 8thInternational Conference on
Learning Representations, ICLR 2020.
Wenyue Hua, Shuyuan Xu, Yingqiang Ge, and
Yongfeng Zhang. 2023. How to index item
ids for recommendation foundation models. In
Proceedings ofthe Annual International ACM
SIGIR Conference onResearch andDevelopment
inInformation Retrieval intheAsia Pacific Region ,
pages 195–204.
Yitong Ji, Aixin Sun, Jie Zhang, and Chenliang Li. 2023.
A critical study on data leakage in recommender
system offline evaluation. ACM Transactions on
Information Systems, 41(3):1–27.
Wang-Cheng Kang and Julian McAuley. 2018. Self-
attentive sequential recommendation. In 2018 IEEE
international conference ondata mining (ICDM) ,
pages 197–206. IEEE.
Walid Krichene and Steffen Rendle. 2020. On sampled
metrics for item recommendation. In Proceedings
ofthe26th ACM SIGKDD international conference
onknowledge discovery &data mining , pages 1748–
1757.
Woosuk Kwon, Zhuohan Li, Siyuan Zhuang, Ying
Sheng, Lianmin Zheng, Cody Hao Yu, Joseph E. Gon-
zalez, Hao Zhang, and Ion Stoica. 2023. Efficient
memory management for large language model serv-
ing with pagedattention. In Proceedings oftheACM
SIGOPS 29th Symposium onOperating Systems
Principles.
Jiayi Liao, Sihang Li, Zhengyi Yang, Jiancan Wu,
Yancheng Yuan, Xiang Wang, and Xiangnan He.
2024. Llara: Large language-recommendation as-
sistant. SIGIR 2024.
Jianghao Lin et al. 2023a. How can recommender sys-
tems benefit from large language models: A survey.
arXiv preprint arXiv:2306.05817.
Xinyu Lin et al. 2023b. A multi-facet paradigm to
bridge large language model and recommendation.
arXiv preprint arXiv:2310.06491.
Ilya Loshchilov and Frank Hutter. 2019. Decou-
pled weight decay regularization. 7thInternational
Conference onLearning Representations, ICLR
2019.
Catherine Olsson, Nelson Elhage, Neel Nanda, Nicholas
Joseph, Nova DasSarma, Tom Henighan, Ben Mann,
Amanda Askell, Yuntao Bai, Anna Chen, Tom Con-
erly, Dawn Drain, Deep Ganguli, Zac Hatfield-Dodds,
Danny Hernandez, Scott Johnston, Andy Jones, Jack-
son Kernion, Liane Lovitt, Kamal Ndousse, Dario
Amodei, Tom Brown, Jack Clark, Jared Kaplan,
Sam McCandlish, and Chris Olah. 2022. In-context
learning and induction heads. Transformer Circuits
Thread . Https://transformer-circuits.pub/2022/in-
context-learning-and-induction-heads/index.html.Shashank Rajput, Nikhil Mehta, Anima Singh, Raghu-
nandan Hulikal Keshavan, Trung Vu, Lukasz Heldt,
Lichan Hong, Yi Tay, Vinh Tran, Jonah Samost, et al.
2024. Recommender systems with generative re-
trieval. Advances inNeural Information Processing
Systems, 36.
Juntao Tan, Shuyuan Xu, Wenyue Hua, Yingqiang Ge,
Zelong Li, and Yongfeng Zhang. 2024. Towards
llm-recsys alignment with textual id learning. SIGIR
2024.
Jiaxi Tang and Ke Wang. 2018. Personalized top-
n sequential recommendation via convolutional se-
quence embedding. In Proceedings oftheeleventh
ACM international conference onweb search and
data mining, pages 565–573.
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob
Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz
Kaiser, and Illia Polosukhin. 2017. Attention is
all you need. Advances inneural information
processing systems, 30.
Ashwin K Vijayakumar, Michael Cogswell, Ram-
prasath R Selvaraju, Qing Sun, Stefan Lee, David
Crandall, and Dhruv Batra. 2016. Diverse beam
search: Decoding diverse solutions from neural se-
quence models. arXiv preprint arXiv:1610.02424.
Kevin Wang, Alexandre Variengien, Arthur Conmy,
Buck Shlegeris, and Jacob Steinhardt. 2022. Inter-
pretability in the wild: a circuit for indirect object
identification in gpt-2 small. ICLR 2023.
Yancheng Wang et al. 2023. Recmind: Large language
model powered agent for recommendation. arXiv
preprint arXiv:2308.14296.
Wei Wei, Xubin Ren, Jiabin Tang, Qinyong Wang, Lixin
Su, Suqi Cheng, Junfeng Wang, Dawei Yin, and Chao
Huang. 2024. Llmrec: Large language models with
graph augmentation for recommendation. In WSDM
2024.
Sean Welleck, Ilia Kulikov, Stephen Roller, Emily
Dinan, Kyunghyun Cho, and Jason Weston. 2020.
Neural text generation with unlikelihood train-
ing. 8thInternational Conference onLearning
Representations, ICLR 2020.
Likang Wu et al. 2023. A survey on large lan-
guage models for recommendation. arXiv preprint
arXiv:2305.19860.
Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V Le,
Mohammad Norouzi, Wolfgang Macherey, Maxim
Krikun, Yuan Cao, Qin Gao, Klaus Macherey, et al.
2016. Google’s neural machine translation system:
Bridging the gap between human and machine trans-
lation. arXiv preprint arXiv:1609.08144.
Yunjia Xi et al. 2023. Towards open-world recommen-
dation with knowledge augmentation from large lan-
guage models. CoRR, abs/2306.10933.Zheng Yuan et al. 2023. Where to go next for rec-
ommender systems? ID- vs. modality-based rec-
ommender models revisited. In SIGIR 2023 , pages
2639–2649. ACM.
Jizhi Zhang, Keqin Bao, Wenjie Wang, Yang Zhang,
Wentao Shi, Wanhong Xu, Fuli Feng, and Tat-Seng
Chua. 2024a. Prospect personalized recommendation
on large language model-based agent platform. arXiv
preprint arXiv:2402.18240.
Junjie Zhang et al. 2023a. Recommendation as in-
struction following: A large language model em-
powered recommendation approach. arXiv preprint
arXiv:2305.07001.
Yang Zhang, Keqin Bao, Ming Yan, Wenjie Wang, Fuli
Feng, and Xiangnan He. 2024b. Text-like encoding
of collaborative information in large language models
for recommendation. ACL 2024.
Yang Zhang, Fuli Feng, Jizhi Zhang, Keqin Bao, Qi-
fan Wang, and Xiangnan He. 2023b. Collm: In-
tegrating collaborative embeddings into large lan-
guage models for recommendation. arXiv preprint
arXiv:2310.19488.
Bowen Zheng et al. 2024. Adapting large language
models by integrating collaborative semantics for
recommendation. ICDE 2024.
A Data Statistic
As shown in Table 5, we outline the condition of
our dataset. During the preprocessing phase, we
took into consideration both the resource impli-
cations of training LLMs and the sparsity issues
associated with randomly sampled datasets. Conse-
quently, starting from October 2017, we processed
the dataset to ensure that each user/item had a
minimum of 5-core interactions post-processing.
Should the number of items post-processing fall
below a threshold (set to 10,000 in our case), we
would extend the timeframe by an additional month
backward and repeat the procedure, ultimately re-
sulting in six distinct datasets. (Note: Even utiliz-
ing the full Instruments data, there are only 9,239
items available).
B Analysis of Amplification Bias
As we have discussed in the main text, due to the
specific, non-uniform of the item space in recom-
mendations, there exists a substantial number of
ghost tokens during the generation of items. These
tokens become determinate following the genera-
tion of preceding tokens. Therefore, their genera-
tion probability is approximately 1, which, under
the default decoding strategy, inadvertently inflates
the score of the item, thereby introducing bias. InInstruments CDs Games Toys Sports Books
Item 9239 14239 11037 11252 16003 41722
Train 140482 148685 201613 112755 181477 682998
Valid 17561 18586 25202 14095 22685 85376
Test 17562 18587 25203 14096 22686 85376
Table 5: The table presents statistical information for six datasets. The first row shows the number of items in our
dataset, and the second, third, and fourth rows display the number of sequences in the training, validation, and test
sets, respectively.
Sp. To. Ga.
Dataset10305070BLEUSASRec
BIGRec
(a)
Sp. To. Ga.
Dataset246EntrophySASRec
BIGRec (b)
Sp. To. Ga.
Dataset1020304050BLEUSASRec
BIGRec (c)
Sp. To. Ga.
Dataset0.10.30.50.7RatioSASRec
BIGRec (d)
Figure 4: The analysis of recommendation results using LLMs on the remaining three datasets (abbreviated
asSp. forSports ,To. forToys, and Ga. forGames ) is presented in these four figures. In Figures (a) and
(b), the text-similarity of the top 5 tokens within the top 10 recommendations and the entropy of the overall
recommendation categories are illustrated, respectively. Higher text similarity and lower entropy indicate a higher
level of homogeneity in recommendations. Figures (c) and (d) depict display text similarity and category repetition
in top-10 recommendations versus historical interactions.
DatasetOrigin Remove
Avg Var Avg Var
Instruments 19.34 55.7 4.31 1.67
CDs 7.64 27.83 3.34 1.15
Games 12.95 35.16 4.6 2.65
Toys 15.8 45.41 4.5 2.19
Sports 18.17 68.54 4.12 1.72
Books 12.27 36.74 3.47 0.84
Table 6: This table presents the average length and its
associated variance of the token lists representing items
in each dataset before and after removing ghost tokens.
Sp. To. Ga.
Dataset0.10.30.5RatioOrigin
Control
(a)
Sp. To. Ga.
Dataset0.040.080.120.16HR@10Origin
Control (b)
Figure 5: These Figures showcase the impact of our
proposed TFA method on modifying recommendation
distributions. In particular, Figure (a) shows the per-
centage of recommended items for a particular category
after adjustments, whereas Figure (b) depicts the perfor-
mance of recommendation within that category.
In.Bo.CD.Sp.To.Ga.
Dataset0.30.50.7RatioTrain
SASRec
LLMFigure 6: This figure displays the ratio of the training
set’s ground truth category, item categories of top-1
recommendations by traditional text-free models and
LLM-based recommender systems appears in the user
historical interactions.
order to mitigate this issue, we begin by analyzing
the length of item representations in terms of to-
kens within each dataset, as well as the length after
removing these tokens, as shown in Table 6. Our
findings indicate that:
•The proportion of ghost tokens significantly
impacts the total length, playing a decisive
role.
•There is considerable variance in the originaltoken lengths, suggesting that length signifi-
cantly influences the scores of items during
the generation process.
•After the removal of ghost tokens, the vari-
ance is reduced, and the lengths of items be-
come relatively uniform. Therefore, it be-
comes feasible to eliminate the length nor-
malization factor directly.
C Analysis of Homogeneity Issue
Figure 4 illustrates the homogeneity issue observed
in the Sports ,Toys, and Games datasets, a phe-
nomenon that is consistent with findings in the
other three datasets. LLM-based recommender sys-
tems demonstrate a significant level of similarity
both in terms of text and category. This confirms
that across all six datasets, while the integration
of textual information enhances performance, it si-
multaneously introduces a text-level bias. This bias
diminishes the diversity of the recommendations,
causing them to converge on specific characteris-
tics. It’s important to clarify that the apparent issue
identified within our study is not inherently detri-
mental. On one side, we note that even text-free
models also recommend items with textual simi-
larities, pointing to a fundamental tendency within
recommender systems. On the other side, as ev-
idenced by Figure 6, where we have mapped out
the proportion of repetitive item categories within
the training set, it’s clear that the practice of sug-
gesting items within similar categories inherently
fulfills the preferences of certain user demograph-
ics. However, when deploying LLM-based recom-
mender systems, their inherent copy mechanisms
tend to exaggerate this feature, which might de-
tract from the experience of a broader user base.
Consequently, our findings advocate for a strate-
gic adjustment to this issue, aiming for moderation
rather than elimination, to balance user satisfaction
across the spectrum optimally.