Statistical Uncertainty in Word Embeddings: GloVe-V
Andrea Vallebueno*
Stanford University
avaimar@stanford.eduCassandra Handan-Nader*
Stanford University
slnader@stanford.edu
Christopher D. Manning
Stanford University
manning@cs.stanford.eduDaniel E. Ho†
Stanford University
deho@stanford.edu
Abstract
Static word embeddings are ubiquitous in com-
putational social science applications and con-
tribute to practical decision-making in a va-
riety of fields including law and healthcare.
However, assessing the statistical uncertainty
in downstream conclusions drawn from word
embedding statistics has remained challenging.
When using only point estimates for embed-
dings, researchers have no streamlined way of
assessing the degree to which their model selec-
tion criteria or scientific conclusions are subject
to noise due to sparsity in the underlying data
used to generate the embeddings. We introduce
a method to obtain approximate, easy-to-use,
and scalable reconstruction error variance es-
timates for GloVe (Pennington et al., 2014),
one of the most widely used word embedding
models, using an analytical approximation to a
multivariate normal model. To demonstrate the
value of embeddings with variance (GloVe-V),
we illustrate how our approach enables princi-
pled hypothesis testing in core word embedding
tasks, such as comparing the similarity between
different word pairs in vector space, assessing
the performance of different models, and ana-
lyzing the relative degree of ethnic or gender
bias in a corpus using different word lists.
1 Introduction
Over the past decade, vector representations of
words, or “word embeddings,” have become stan-
dard ways to quantify word meaning and seman-
tic relationships due to their high performance on
natural language tasks (Mikolov et al., 2013b; Pen-
nington et al., 2014; Levy et al., 2015). Word em-
beddings are now ubiquitous in a wide variety of
downstream computational social science applica-
tions, including charting the semantic evolution of
words over time (Hamilton et al., 2016), generat-
ing simplifications of scientific terminology (Kim
*Equal contribution.
†Corresponding author.et al., 2016), comparing the information density of
languages (Aceves and Evans, 2024), assisting in
legal interpretation (Choi, 2024), and detecting so-
cietal biases in educational texts (Lucy et al., 2020),
historical corpora (Garg et al., 2018; Charlesworth
et al., 2022), legal documents (Matthews et al.,
2022; Sevim et al., 2023), political writing (Knoche
et al., 2019), and annotator judgments (Davani
et al., 2023). Task performance metrics using word
embeddings also factor prominently into the evalu-
ation of more sophisticated, multimodal artificial
intelligence systems, such as brain-computer inter-
faces (Tang et al., 2023) and adversarial text-to-
image generation (Liu et al., 2023).
Though a vast amount of research has relied on
a relatively narrow set of word embedding models,
no unified framework has emerged for represent-
ing statistical uncertainty in how accurately the
word embeddings reconstruct the relationships im-
plied by the sample of word co-occurrences. In-
tuitively, we should be less certain about a word’s
position in vector space the less data we have on
its co-occurrences in the raw text (Ethayarajh et al.,
2019a,b). While it is generally standard practice in
the social and natural sciences to check results for
statistical significance, the vast majority of appli-
cations have relied exclusively on point estimates
of embeddings, ignoring uncertainty even when
training vectors over smaller corpora (e.g., Sevim
et al., 2023; Knoche et al., 2019). In select applica-
tions, approaches have ranged from a bootstrap on
thedocuments in the training corpus (Lucy et al.,
2020), to permutations of the word list or lexicon
(Caliskan et al., 2017; Garg et al., 2018). While
useful, such bootstrap and permutation approaches
are computationally intractable on large datasets.
Moreover, they address uncertainty from document
or lexicon selection, even though embeddings are
parameters of a data generating process on word
co-occurrences, not on collections of documents
or sets of words (Ethayarajh et al., 2019b). Until
1arXiv:2406.12165v1  [cs.CL]  18 Jun 2024Figure 1: Conceptual diagram of the Glove-V method for one word. The top two rows illustrate the structural form
and estimation of the original GloVe model (Pennington et al., 2014), which models each row of a logged, weighted
co-occurrence matrix as the product of a word vector and context vectors, plus constant terms. As shown in the third
row, GloVe-V creates a distribution for the optimal GloVe word vector using the reconstruction error found through
the GloVe minimization procedure. These distributions can be efficiently computed word-by-word by assuming
conditional independence between words given the optimal context vectors and constants.
now, accounting for the fundamental uncertainty
from the data-generating process has eluded the
NLP community.
To fill this gap, we develop GloVe-V , a scalable,
easy-to-use, computationally efficient method for
approximating reconstruction error variances for
the GloVe model (Pennington et al., 2014), one
of the most widely used word embedding models.
Our approach leverages the core insight that if con-
text vectors and constant terms are held fixed at
optimal values, GloVe word embeddings are the
optimal parameters for a multivariate normal prob-
ability model on a weighted log transformation of
the rows of the co-occurrence matrix. If we assume
that the rows of the co-occurrence matrix are inde-
pendent given their context vectors and constant
terms, the word embedding variances according
to this likelihood are computationally tractable on
large vocabularies. This assumption is reasonable
and is also employed in other settings, such as
measuring the influence of particular documents
on downstream embedding statistics (Brunet et al.,
2019). Such variance estimates enable researchers
to conduct rigorous assessments of model perfor-
mance and principled statistical hypothesis tests
on downstream tasks, responding to the need to
account for statistical uncertainty and significance
testing in natural language processing and machine
learning (Card et al., 2020; Dror et al., 2020; Liao
et al., 2021; Bowman and Dahl, 2021; Ulmer et al.,
2022).Our contributions are threefold: (a) we provide
the statistical foundations for a principled notion
of reconstruction error variances for GloVe word
embeddings; (b) we show that incorporating uncer-
tainty can change conclusions about textual similar-
ities, model selection, and textual bias; (c) we pro-
vide a data release including pre-computed word
embeddings and variances for the most frequently
occurring words in the Corpus of American English
(COHA), the largest corpus of historical American
English that is widely used to track the usage and
linguistic evolution of English terms over time (e.g.,
Ng et al., 2015; Newberry et al., 2017; Garg et al.,
2018; Xiao et al., 2023; Charlesworth and Hatzen-
buehler, 2024).1
2 Background on GloVe
We use upper case bold letters for matrices X,
lower case bold letters for vectors x, and regular
non-bolded letters for scalars x, except when in-
dexing into a matrix or vector (i.e., the ijthentry
of the matrix XisXij). Sets are represented by
script letters X.
Word embedding models learn a shared vector
space representation of words in a corpus. The
training data are word co-occurrences in the corpus,
which can be represented by a V×Vco-occurrence
1These data products are intended for academic use. We
also plan to release pre-computed word embeddings and vari-
ances for two larger corpora, Wikipedia & Gigaword and
DSIR Pile, to make our approach more readily accessible to
researchers.
2matrix X, where Xijis the weighted number of
times word jappears in the context of word i,2
andVis the number of words in the vocabulary.
A word embedding is a vector representation of a
given word that emerges from the model.
The GloVe word embedding model (Pennington
et al., 2014) learns two embeddings wk,vk∈RD
for each word k, by minimizing the following cost
function:
J=VX
i=1VX
j=1f(Xij)(wT
ivj+bi+cj−logXij)2
(1)
where f(Xij)is a non-negative weighting function
with properties that ensure that very rare or very
frequent co-occurrences do not receive too much
weight, biandcjare constant terms associated with
word iandjrespectively.3The vectors vkare
called “context” vectors and wkare called “cen-
ter” vectors, representing that word co-occurrences
are defined based on words that appear within a
fixed context window around a center word. The
original implementation computed wk+vkin a
post-processing step to obtain a single embedding
for a word k. In this paper, we focus on the center
vector wkas the embedding of interest for word k.4
3 Variance Derivation for GloVe-V
We now derive the GloVe-V variance estimator by
recasting the optimization problem and recovering
a probabilistic interpretation of GloVe embeddings.
3.1 Reformulating the GloVe optimization
problem
The GloVe optimization problem using the cost in
Equation 1 can be written in matrix form as
min
b,c,W,V∥F⊙R∥F
s.t.R= log X−WTV−b1T−1cT
rank(W),rank(V)≤D(2)
2Co-occurrence terms are usually weighted by the inverse
of their distance from the center word.
3We follow the approach of the original authors and use
f(x) =(
(x/100)3/4if x < 100
1 otherwise
4While summing the context and center vectors can give
useful performance gains, it is not always even a win. See
the extensive discussion in (Assylbekov and Takhanov, 2019;
Levy et al., 2015, secs. 3.3 and 6).where Fij=p
f(Xij),wiandviare the ithand
jthcolumns of matrices WandVrespectively, bi
andcjare the ithandjthelements of vectors band
crespectively, and ⊙is the element-wise product.
Equation 2 is an element-wise weighted low-rank
approximation problem that can be solved in two
steps (e.g., Markovsky, 2012):
min
b∈RV,c∈RV,V∈RV×Dmin
W∈RV×D∥F⊙R∥F(3)
That is, holding the choice of (b,c,V)fixed at
their globally optimal values (b∗,c∗,V∗), the in-
ner minimization to find the optimal Wdecom-
poses to Vweighted least squares projections with
solutions:
w∗
i= (V∗T
KDKV∗
K)−1V∗T
KDK(logxi−b∗
i1−c∗)
(4)
where Kis the set of column indices with non-
zero co-occurrences for word i,V∗
Kis a matrix
whose columns belong to the set {v∗
j:j∈ K} ,
DK=diag({F2
ij:j∈ K} ), andxiis the ithrow
ofX.
3.2 A probabilistic model for an approximate
problem
Recasting the optimization problem in this fashion
allows us to state the natural probabilistic model
for which w∗
iin Equation 4 is optimal. Conditional
on the optimal context vector subspace spanned by
V∗and optimal constant vectors (b∗,c∗), we write
the following weighted multivariate normal model
for the rows of X:
logxi=b∗
i1+c∗+wT
iV∗
K+ei
ei∼ N(0,D−1
Kσ2
i)(5)
where we always have (DK)ii>0due to the
fact the Xij>0forj∈ K , and we assume
that the rows of logXare independent given
the optimal parameters, i.e., logxi|b∗,c∗,V∗
K⊥
logxj|b∗,c∗,V∗
Kfori̸=j.5Then, under standard
assumptions for weighted least squares estimators
(e.g., Romano and Wolf, 2017), the covariance ma-
trix for Wsimplifies into a V D×V D block diag-
onal matrix with the ithD×Dblock given by:
Σi=σ2
i
X
j∈Kf(Xij)v∗
j(v∗
j)T
−1
(6)
5Brunet et al. (2019) rely on the same assumption to make
their method for approximating the influence of a group of
documents on word association statistics computationally
tractable.
3she
largeprices
badlydetermineilluminationrigs
−5.0−2.50.02.55.0
−5.0 −2.5 0.0 2.5 5.0Figure 2: Uncertainty in word embedding locations.
Two-dimensional representations of GloVe word em-
beddings trained on COHA (1900–1999), along with
ellipses drawn around 100 draws from the estimated
multivariate normal distribution from Equation 5 for a
random subset of words. Lower frequency words like
“rigs” and “illumination” have more uncertainty in their
estimated positions in the vector space than high fre-
quency words like “she” and “large.”
We can then estimate σ2
i, the reconstruction error
for word i, with the plug-in estimator:
ˆσ2
i=
1
|K| − DX
j∈Kf(Xij)(logXij−b∗
i−c∗
j−w∗T
iv∗
j)2
(7)
3.3 Estimation
The covariance estimator in Equation 6 is only valid
for words that co-occur with a greater number of
unique context words |K|than the dimensional-
ity of the vectors D. A simple way to increase
the coverage of the variances in smaller corpora
is to reduce the dimensionality of the word vec-
tors. However, when |K| ≈ D, numerical prob-
lems with computing the inverse in Equation 6
are likely to occur even if it is technically pos-
sible to compute an inverse. To address these
numerical issues, for each word whose Hessian
block Hi=P
j∈Kf(Xij)v∗
j(v∗
j)Thas a condi-
tion number that implies numerical error in excess
of 1e-10 in its inverse, we instead compute the
Moore-Penrose pseudo-inverse of HiasVΛ+UT
(Golub and Van Loan, 2013), where Hi=UΛVT
is the singular value decomposition of HiandΛ+
jj= 1/ΛjjifΛjj>1e-3×max jΛjjand0
otherwise. This technique effectively drops dimen-
sions that are predominantly noise in the Hessian
block when computing the inverse.
3.4 Propagating uncertainty
With this derivation in hand, propagating vari-
ance to downstream tasks is straightforward. For
differentiable test statistics, such as the cosine
similarity between two word embeddings, the
most computationally efficient approach is to
use the delta method for asymptotic variances
(van der Vaart, 2000). Using a first-order Taylor
series approximation to the test statistic, the delta
method states that if√n(W−ˆW)converges to
N(0,Σ), then√n(ϕ(W)−ϕ(ˆW))converges to
N(0, ϕ′(W)TΣϕ′(W)), where ϕ(·)is a differen-
tiable function of Wandϕ′(·)is its gradient with
respect to W. If the test statistic only depends on a
subset of words in the vocabulary, the computation
is quite efficient due to the fact that the gradient
will be sparse.
For a broader class of test statistics, researchers
can repeatedly draw from the estimated multivari-
ate normal distribution in Equation 6 and recal-
culate the test statistic of interest (Tanner, 1996),
which is much more computationally efficient than
a bootstrap on the full embedding model. In our
code repository ( github.com/reglab/glove-v ),
we provide a tutorial and starter code to apply the
GloVe-V framework to any downstream test statis-
tic using this method.
4 Results
To build intuition and demonstrate the usefulness
of GloVe-V variances, we now provide empiri-
cal results using the Corpus of Historical Amer-
ican English (COHA) for the 20thcentury, which
contains English-language texts from a balanced
set of genres (fiction, non-fiction, magazines, and
newspapers) from 1900–1999 (Davies, 2012).6For
all examples, we use 300-dimensional GloVe em-
beddings using a symmetric context window of 8
words.7The empirical examples show how GloVe-
V variances can move researchers in NLP towards
emerging best practices for incorporating hypoth-
esis testing in natural language tasks and down-
stream analyses (Card et al., 2020).
6The data were accessed under a standard academic license
in accordance with the data usage restrictions at https://www.
corpusdata.org/restrictions.asp .
7See Appendix A.1 for more details on model training.
4Figure 3: Word-level relationship between GloVe-V
variances and frequency on COHA (1900–1999). L2-
norm of the diagonal of ˆΣfrom Equation 6 ( x-axis, on
alog10scale) plotted against logged word frequencies
(y-axis, on a log10scale) for a subset of 5,000 words
randomly sampled in proportion to word frequency. The
variances for words colored in orange are computed as
discussed in Section 3.3.
4.1 Uncertainty in word embedding locations
We first show that the variances can represent re-
construction error uncertainty in the locations of in-
dividual words in vector space due to data sparsity.
Figure 2 plots a two-dimensional representation of
the word embeddings, with ellipses drawn around
100 draws from the estimated multivariate normal
distribution in Equation 5 for a random subset of
words. The size of the ellipses reflects the fact that,
based on the underlying co-occurrence matrix, we
are more certain about the positions of higher fre-
quency words like “she” and “large” than lower fre-
quency words like “illumination” and “rigs.” The
higher uncertainty for lower frequency words is a
structural feature of the estimated covariance matri-
ces themselves. Figure 3 demonstrates this feature
by plotting the word-level frequency ( x-axis, on a
log10scale) against the L2-norm of the diagonal
of the estimated ˆΣfrom Equation 6 ( y-axis, on a
log10scale) for a random subset of words (sampled
in proportion to their frequency). The magnitude
of the variances for the word embedding param-
eters decreases smoothly as the word frequency
increases. Where |K| ≈ D(highlighted in orange
in Figure 3), the estimation approach described in
Section 3.3 provides a reasonable estimate of the
variance.
4.2 Comparison to document bootstrap
We now provide intuition for why the GloVe-V vari-
ances may in many instances be preferable to the
GloVe−V
Document bootstrap
0.050.100.15
F0
[56−126]F1
[128−292]F2
[294−978]F3
[1006−101960]
Frequency QuartileStd. Error of Cosine SimilarityFigure 4: Comparison between document bootstrap
and GloVe-V standard errors for cosine similarity.
The average standard error of the cosine similarity be-
tween 1,600 randomly sampled word pairs ( y-axis) as a
function of the frequency for the word pair ( x-axis with
word frequency ranges in brackets), using the document
bootstrap approach and Glove-V using the delta method.
The GloVe-V standard errors are more sensitive to word
frequency and are more efficient to compute.
document bootstrap for hypothesis testing on down-
stream test statistics. The document bootstrap is
a computationally intensive approach to capturing
word embedding instability that repeatedly resam-
ples documents from the corpus, recomputes the
word embeddings, and recalculates the test statis-
tic of interest (Antoniak and Mimno, 2018). To
re-purpose this approach in order to conduct a hy-
pothesis test, we must subscribe to the uncertainty
framework that the corpus itself is randomly sam-
pled from a hypothetical population of documents.
However, as described in Section 3, this framework
does not match the statistical micro-foundations
under which the embeddings themselves are es-
timated, causing a mismatch between the notion
of document-level uncertainty and the estimation
target of the embeddings.
Figure 4 shows that document-level uncertainty
can either underestimate or overestimate the vari-
ance of a downstream test statistic compared to the
reconstruction error uncertainty given by GloVe-V ,
depending on the distribution of words across doc-
uments. A word that is used infrequently but in the
same way across many documents may have low
document-level uncertainty because each bootstrap
sample will yield similar (but sparse) co-occurrence
counts for that word, even if the reconstruction er-
ror remains high for each bootstrapped estimate.
Conversely, a word that is extremely common in
only a few documents may have high document-
52
84
5
96
10731
gynecologistneurologistpharmacistpediatricianobstetricianveterinariantherapistpsychiatristdentistsurgeon
0.10.20.30.4
Cosine Similarity with 'doctor'OccupationFigure 5: Nearest neighbors with uncertainty. Health-
care occupations ( y-axis) ranked by their cosine simi-
larity with “doctor” ( x-axis), with the nearest neighbor
ranking based on the point estimate above each point,
and95% GloVe-V uncertainty intervals.
level uncertainty because many bootstrap samples
will drop the majority of documents containing that
word, even if the reconstruction error is low when
all documents are included. Rather than choose one
over the other, researchers can use each method for
different purposes: tools like the document boot-
strap or more computationally efficient analogs
(e.g., Brunet et al., 2019) can be used to assess
sensitivity of results to particular documents, while
GloVe-V can be used to conduct hypothesis tests
under a coherent statistical framework, holding the
corpus fixed.
5GloVe-V enables principled significance
testing
We now show how GloVe-V enables statistical sig-
nificance testing, addressing the increasing recogni-
tion for NLP to move beyond point estimates alone
(Card et al., 2020; Liao et al., 2021). GloVe-V can
also help researchers assess when a corpus is un-
derpowered for specific inferences, as we illustrate
below.
5.1 Uncertainty in knearest neighbors
Word similarity, including knearest neighbor lists,
informs performance evaluation for both embed-
ding models and more sophisticated artificial intel-
ligence systems (e.g. Mikolov et al., 2013a; Levy
and Goldberg, 2014a; Linzen, 2016; Borah et al.,
2021; Tang et al., 2023; Liu et al., 2023). Using
only point estimates to evaluate word similarity,
however, leaves the researcher with no sense of
which word similarities are inherently less certain
because they are based on less co-occurrence datain the underlying corpus. Uncertainty in neigh-
bor rankings is particularly consequential for word
similarity tasks, which depend on the ranking of
different word pairs, and for word analogy tasks,
which are typically solved by finding nearest neigh-
bors in the embedding space.8As an example of
this dilemma, Figure 5 plots the cosine similarity
between “doctor” and a list of healthcare occupa-
tion words along with GloVe-V uncertainty inter-
vals. Based on the point estimates, we can assign a
nearest-neighbor rank to each word by their prox-
imity to “doctor” (printed above the point estimate
in Figure 5). However, for the top three neighbors
(and between neighbours 4 through 10), we cannot
statistically distinguish the ranks (e.g., p= 0.10
for the difference in the cosine similarity of “doc-
tor" and “surgeon" relative to that of “doctor" and
“dentist"). Which neighbor is the “nearest” is there-
fore subject to considerable uncertainty that would
be invisible without incorporation of the GloVe-V
variances.
5.2 Uncertainty in model performance
Performance on analogy tasks is a canonical
approach to word embedding model evaluation
(Mikolov et al., 2013b; Pennington et al., 2014;
Levy et al., 2015). Closed-list relational similarity
tasks such as SemEval-2012 (Jurgens et al., 2012)
are structured so that models can be benchmarked
against random baselines, in which pairs of words
are randomly related to each other to establish a
lower bound on expected performance. Figure 6
presents the performance of GloVe compared to
a random benchmark using two evaluation met-
rics on four relational similarity tasks (see Jurgens
et al., 2012, for details on the tasks and metrics).
While the point estimates for performance suggest
that GloVe outperforms the random baseline on all
tasks, adding uncertainty to both point estimates
reveals that we can only claim significantly higher
performance than random on two of the four rela-
tions ( p= 0.08,p <0.001,p= 0.02,p= 0.08
for relations 1–4, respectively, for the MaxDiff
metric). The GloVe-V intervals also allow us to dis-
tinguish the performance of GloVe across different
relational similarity tasks. While we can say that
GloVe performs better on “Contrast” vs. “Cause-
8In the case of analogy tasks, the solution typically relies
on the nearest neighbor to some linear transformation of the
word embeddings belonging to the words in the analogy (Levy
and Goldberg, 2014a), rather than the nearest neighbor to a
specific word as illustrated in our example.
60.4
 0.2
 0.0 0.2 0.4 0.6
SpearmanPart-Whole -
Event:Feature
Contrast - 
Contrary
Attribute -
Object:Typical Action
Cause-Purpose -
Agent:GoalGloVe-V Random
20 30 40 50 60
MaxDiffFigure 6: Accounting for uncertainty in word embedding performance assessments using the SemEval-2012
Task 2 of Jurgens et al. (2012) on COHA 1900–1999. The task measures the degree of relational similarity of
word pairs using the Spearman correlation and the MaxDiff choice procedure on a taxonomy that comprises 79
types of relations across 10 different classes ( e.g., contrast, part-whole, cause-purpose). We present GloVe-V results
on a subset of relations, along with a Random baseline that randomly rates the word pairs in each relation.
Purpose” ( p= 0.03for the MaxDiff metric), we
cannot claim that it does better on “Cause-Purpose”
than “Part-Whole” ( p= 0.92), even though the
point estimates suggest better performance on the
former task.9
5.3 Uncertainty in word embedding bias
Measurement of societal biases in text is a pop-
ular downstream application using word embed-
dings (e.g., Garg et al., 2018; Lucy et al., 2020;
Charlesworth et al., 2022; Matthews et al., 2022;
Sevim et al., 2023). These types of studies compare
similarity between curated sets of words to test the
prevalence of societal biases in text. For example,
if a set of female-oriented words is closer to a set
of family-oriented words than to career-oriented
words, and this relationship is stronger relative to
the same comparison using male-oriented words,
that is evidence of a gender bias (Bolukbasi et al.,
2016; Caliskan et al., 2017). To represent uncer-
tainty in these comparisons, researchers typically
use a permutation test or bootstrap on the words
included in each set (e.g., Caliskan et al., 2017;
Garg et al., 2018), but others have noted that these
types of uncertainty measures (which account for
uncertainty in word selection) are not designed to
account for the sparsity of word co-occurrences
that form the basis for the comparisons (Ethayarajh
et al., 2019b).
9The relations contain about about 27 to 45 word pairs:
1)Contrast - Contrary : pairs of opposite words (e.g., “dull"
and “bright"); 2) Part-Whole - Event: Feature : pairs in which
one word is a part of the event given by the first word (e.g.,
“carnival" and “rides"); 3) Attribute - Object: Typical Action :
pairs in which one word is a characteristic action of the other
(e.g., “heart" and “beat"); 4) Cause-Purpose - Agent: Goal :
pairs in which one word is a typical objective of the agent
given by the first word (e.g., “painter" and “portrait").It is especially important to account for uncer-
tainty due to sparsity in applications where the anal-
ysis relies on infrequently occurring words such
as surnames, which are often used to measure de-
mographic bias (e.g., Caliskan et al., 2017; Garg
et al., 2018; Swinger et al., 2019). Researchers typ-
ically drop lower frequency surnames altogether
from their analyses (e.g., Garg et al., 2018) be-
cause they have no way of representing the higher
uncertainty in the embedded positions for lower fre-
quency surnames using only point estimates. But
such curation runs the risk of sacrificing the rep-
resentativeness of the word lists involved and the
generalizability of the conclusions (Antoniak and
Mimno, 2021). Using a measure of anti-Asian bias
in the COHA corpus based on Garg et al. (2018),
the left panel of Figure 7 shows how GloVe-V vari-
ances can automatically provide information on
co-occurrence sparsity for researchers.10The bias
measure on the y-axis computes the average cosine
similarity between a set of Asian surnames and a
set of 20 Otherization words,11relative to a set of
White surnames. A more positive bias score indi-
cates that Asian surnames are more closely related
to these negative Otherization words compared to
White surnames.
Figure 7 shows that the anti-Asian bias estimate
in COHA becomes more positive for more fre-
quently appearing surnames, such that relying only
on the most frequent surnames produces an exag-
gerated result relative to the full set of Asian sur-
10Appendix A.2 provides delta method derivations for the
bias statistics used in Figure 7.
11This word list is primarily composed of adjectives used
to describe people as outsiders, such as monstruous ,devious ,
andbizarre .
7Asian
surnames
(Q4)
[764, 17504]Asian
surnames
(Q3)
[256, 762]Asian
surnames
(Q2)
[126, 254]Asian
surnames
(Q1)
[58, 124]0.075
0.050
0.025
0.0000.0250.0500.0750.1000.125Cosine bias scoreAsian surnames (All)
T: Male vs.
Female Names
A: Career vs.
FamilyT: Math vs.
Arts
A: Male vs.
Female T ermsT: Science vs.
Arts
A: Male vs.
Female T erms0.00.20.40.60.81.01.21.41.6WEAT effect size
Figure 7: Ethnicity and gender bias scores. a) Average Asian bias scores with GloVe-V uncertainty using the
cosine bias score of Garg et al. (2018) in COHA 1900–1999 for different Asian surname lists. The gray line and
shaded gray area represent the point estimate and 95% GloVe-V uncertainty interval, respectively, of the bias score
on a master list of Asian surnames. The points and error bars in blue represent the bias score computed on different
subsets of the list, grouped according to the number of times they appear in the corpus. b)Gender bias scores for
three types of bias tests using the WEAT effect size of Caliskan et al. (2017) with GloVe-V uncertainty.
names.12This is likely due to the fact that the most
frequently occurring surnames tend to be from his-
torical figures such as “Ghandi,” “Mao,” and “Mo-
hammed,” which are clearly not representative of
the entire class of Asian surnames. Using GloVe-V ,
low and high frequency words can be seamlessly
combined into a single bias interval that represents
the combined uncertainty in all the estimated word
positions (shown as a gray interval on the plot),
without having to drop any surnames and sacrifice
generalizability.13
GloVe-V intervals can also be useful for studying
high frequency word lists because they allow re-
searchers to make statistical comparisons between
types of bias. The right panel of Figure 7 pro-
vides an example of three gender bias queries with
GloVe-V intervals for the Word Embedding Associ-
ation Test (WEAT) effect size, a cosine-similarity-
based test (Caliskan et al., 2017): (a) male vs. fe-
male names and words related to career vs.family ;
(b) male vs. female terms and words related to math
vs.arts; and (c) male vs. female terms and words
related to science vs.arts. While the point estimate
for type (a) is higher than those for both (b) and
(c), the GloVe-V intervals allow us to reject the
null that (a) is equal to (b) ( p < 0.001), but not
12See Appendix A.3 for details on how we compiled this
surname list.
13GloVe-V intervals can also help researchers determine
when a bias time trend can be supported by the co-occurrence
data. Estimating the anti-Asian bias separately for each decade
of COHA with GloVe-V uncertainty intervals, for example,
reveals no significant trend in the bias score over time, sug-
gesting that time trends such as those reported in Garg et al.
(2018) should also be checked for statistical significance.the null that (a) is equal to (c) ( p= 0.11). In this
case, the GloVe-V intervals guard against making
unsubstantiated claims about which types of bias
are strongest.
6 Conclusion
In this paper, we have derived, computed, and
demonstrated the utility of GloVe-V , a new method
to represent uncertainty in word embedding loca-
tions using the seminal GloVe model. The GloVe-V
variances provide researchers with the ability to eas-
ily propagate uncertainty in the word embeddings
to downstream test statistics of interest, such as
word similarity metrics that are used in both eval-
uation and analyses involving word embeddings.
Unlike methods such as the document and word list
bootstrap, the method is computationally efficient
even on large corpora and represents uncertainty
due to sparsity in the underlying co-occurrence ma-
trix, which is often invisible in downstream analy-
ses that use only the estimated word embeddings.
As we have shown in Section 4, incorporating
uncertainty into downstream analyses can have con-
sequential impacts on the conclusions researchers
draw, and should be a best practice moving forward
for studies that use word embeddings to infer se-
mantic meaning. Finally, while outside the scope
of the current study, we note that the contextual
word and passage representations of transformer
large language models are also point estimates and
similar questions of embedding uncertainty apply
when using such models as well.
8Limitations
While useful in many applications, the GloVe-V
method comes with certain limitations. First, the
variances can only be computed for words whose
number of context words exceeds the embedding
dimensionality. This limitation can easily be mini-
mized by reducing the dimensionality of the vectors
for small corpora; for example, variances can be
computed for 96% of the word embeddings in the
relatively small New York Times Annotated Cor-
pus (NYT) with 50-dimensional vectors, compared
to36% of embeddings with 300-dimensional vec-
tors. Second, researchers need access to the co-
occurrence matrix if they wish to compute the vari-
ances themselves, since it relies on an empirical
estimate of the reconstruction error. Third, the
methodology in this paper applies solely to the
GloVe embedding model because of its statistical
foundations. That said, this model is one of the
most-cited word embedding models in current use
and has been shown to have better stability and
more intuitive geometric properties than competing
models (Mimno and Thompson, 2017; Wendlandt
et al., 2018).
Finally, the uncertainty captured by GloVe-V
intervals is due to sparsity in the underlying co-
occurrence matrix, which is only one of many types
of uncertainty one could consider in embedded lo-
cations for words. Other types of uncertainty that
are held fixed in GloVe-V include instability due
to the documents included in the corpus (e.g., An-
toniak and Mimno, 2018), uncertainty due to the
hyper-parameters of the model (e.g., Borah et al.,
2021), and statistical uncertainty in the estimated
context vector positions and bias terms, which are
treated as constants in the variance computation for
computational tractability. Along with the condi-
tional independence assumption on words, treating
these terms as constants is necessary to reduce the
number of free parameters in the model and al-
low a tractable variance computation. These sorts
of independence assumptions are becoming stan-
dard practice to enable computational efficiency
for models with a large number of parameters –
the same assumption, for example, has been suc-
cessfully employed to develop a computationally
efficient approximation to a document bootstrap
(Brunet et al., 2019).
Despite these limitations, we found by trying
a number of other approaches (detailed in Ap-
pendix A.4) that GloVe-V strikes a desirable bal-ance between maintaining the model’s probabilis-
tic foundations for enhanced statistical rigor, and
preserving computational tractability for practical
purposes.
Acknowledgements
We thank Rishi Bommasani, Matthew Dahl, Neel
Guha, Peter Henderson, Varun Magesh, Joel
Niklaus, Derek Ouyang, Dilara Soylu, Faiz Surani,
Mirac Suzgun, Lucia Zheng, and participants at the
2024 Stanford Data Science Conference for helpful
comments and discussions.
References
Pedro Aceves and James A Evans. 2024. Human lan-
guages with greater information density have higher
communication speed but lower conversation breadth.
Nature Human Behaviour , 8:1–13.
Maria Antoniak and David Mimno. 2018. Evaluating
the stability of embedding-based word similarities.
Transactions of the Association for Computational
Linguistics , 6:107–119.
Maria Antoniak and David Mimno. 2021. Bad seeds:
Evaluating lexical methods for bias measurement.
InProceedings of the 59th Annual Meeting of the
Association for Computational Linguistics and the
11th International Joint Conference on Natural Lan-
guage Processing (Volume 1: Long Papers) , pages
1889–1904.
Zhenisbek Assylbekov and Rustem Takhanov. 2019.
Context vectors are reflections of word vectors in
half the dimensions. Journal of Artificial Intelligence
Research , 66:225–242.
Charles Blundell, Julien Cornebise, Koray
Kavukcuoglu, and Daan Wierstra. 2015. Weight
uncertainty in neural network. In International
conference on machine learning , pages 1613–1622.
PMLR.
Tolga Bolukbasi, Kai-Wei Chang, James Y Zou,
Venkatesh Saligrama, and Adam T Kalai. 2016. Man
is to computer programmer as woman is to home-
maker? debiasing word embeddings. In Advances in
Neural Information Processing Systems , volume 29.
Curran Associates, Inc.
Jonathan W. Book. 2020. Training bayesian neural
networks: A study of improvements to training algo-
rithms. Master thesis.
Angana Borah, Manash Pratim Barman, and Amit
Awekar. 2021. Are word embedding methods sta-
ble and should we care about it? In Proceedings of
the 32nd ACM Conference on Hypertext and social
media , pages 45–55.
9Samuel R. Bowman and George E. Dahl. 2021. What
will it take to fix benchmarking in natural language
understanding? In Proceedings of the 2021 Confer-
ence of the North American Chapter of the Associ-
ation for Computational Linguistics: Human Lan-
guage Technologies , page 4843–4855.
Marc-Etienne Brunet, Colleen Alkalay-Houlihan, Ash-
ton Anderson, and Richard Zemel. 2019. Under-
standing the origins of bias in word embeddings. In
International conference on machine learning , pages
803–811. PMLR.
Elia Bruni, Gemma Boleda, Marco Baroni, and Nam-
Khanh Tran. 2012. Distributional semantics in tech-
nicolor. In Proceedings of the 50th Annual Meeting
of the Association for Computational Linguistics (Vol-
ume 1: Long Papers) , pages 136–145.
Aylin Caliskan, Joanna J Bryson, and Arvind Narayanan.
2017. Semantics derived automatically from lan-
guage corpora contain human-like biases. Science ,
356(6334):183–186.
Dallas Card, Peter Henderson, Urvashi Khandelwal,
Robin Jia, Kyle Mahowald, and Dan Jurafsky. 2020.
With little power comes great responsibility. In
Proceedings of the 2020 Conference on Empirical
Methods in Natural Language Processing (EMNLP) ,
pages 9263–9274.
Tessa ES Charlesworth, Aylin Caliskan, and Mahzarin R
Banaji. 2022. Historical representations of social
groups across 200 years of word embeddings from
google books. Proceedings of the National Academy
of Sciences , 119(28):e2121798119.
Tessa ES Charlesworth and Mark L Hatzenbuehler.
2024. Mechanisms upholding the persistence of
stigma across 100 years of historical text. Scientific
Reports , 14(1):11069.
Jonathan H Choi. 2024. Measuring clarity in legal text.
University of Chicago Law Review , 91:1.
Aida Mostafazadeh Davani, Mohammad Atari, Bren-
dan Kennedy, and Morteza Dehghani. 2023. Hate
speech classifiers learn normative social stereotypes.
Transactions of the Association for Computational
Linguistics , 11:300–319.
Mark Davies. 2012. Expanding horizons in historical
linguistics with the 400-million word corpus of his-
torical american english. Corpora , 7(2):121–157.
Rotem Dror, Lotem Peled-Cohen, Segev Shlomov, and
Roi Reichart. 2020. Statistical Significance Testing
for Natural Language Processing . Number 45 in
Synthesis Lectures on Human Language Technolo-
gies. Springer Nature.
Kawin Ethayarajh, David Duvenaud, and Graeme Hirst.
2019a. Towards understanding linear word analo-
gies. In Proceedings of the 57th Annual Meeting of
the Association for Computational Linguistics , pages
3253–3262, Florence, Italy. Association for Compu-
tational Linguistics.Kawin Ethayarajh, David Duvenaud, and Graeme Hirst.
2019b. Understanding undesirable word embedding
associations. In Proceedings of the 57th Annual
Meeting of the Association for Computational Lin-
guistics , pages 1696–1705, Florence, Italy. Associa-
tion for Computational Linguistics.
Nikhil Garg, Londa Schiebinger, Dan Jurafsky, and
James Zou. 2018. Word embeddings quantify 100
years of gender and ethnic stereotypes. Proceedings
of the National Academy of Sciences , 115(16):E3635–
E3644.
Gene H Golub and Charles F Van Loan. 2013. Matrix
Computations . JHU press.
William L. Hamilton, Jure Leskovec, and Dan Jurafsky.
2016. Diachronic word embeddings reveal statisti-
cal laws of semantic change. In Proceedings of the
54th Annual Meeting of the Association for Compu-
tational Linguistics (Volume 1: Long Papers) , pages
1489–1501, Berlin, Germany. Association for Com-
putational Linguistics.
Rujun Han, Michael Gill, Arthur Spirling, and
Kyunghyun Cho. 2018. Conditional word embed-
ding and hypothesis testing via bayes-by-backprop.
InProceedings of the 2018 Conference on Empiri-
cal Methods in Natural Language Processing , pages
4890–4895. Association for Computational Linguis-
tics.
David Jurgens, Saif Mohammad, Peter Turney, and
Keith Holyoak. 2012. SemEval-2012 task 2: Measur-
ing degrees of relational similarity. In *SEM 2012:
The First Joint Conference on Lexical and Compu-
tational Semantics – Volume 1: Proceedings of the
main conference and the shared task, and Volume
2: Proceedings of the Sixth International Workshop
on Semantic Evaluation (SemEval 2012) , pages 356–
364. Association for Computational Linguistics.
Yea-Seul Kim, Jessica Hullman, Matthew Burgess, and
Eytan Adar. 2016. Simplescience: Lexical simplifica-
tion of scientific terminology. In Proceedings of the
2016 Conference on Empirical Methods in Natural
Language Processing , pages 1066–1071.
Markus Knoche, Radomir Popovi ´c, Florian Lemmerich,
and Markus Strohmaier. 2019. Identifying biases in
politically biased wikis through word embeddings.
InProceedings of the 30th ACM Conference on Hy-
pertext and Social Media , HT ’19, pages 253–257.
Association for Computing Machinery. Event-place:
Hof, Germany.
Omer Levy and Yoav Goldberg. 2014a. Linguistic regu-
larities in sparse and explicit word representations. In
Proceedings of the Eighteenth Conference on Compu-
tational Natural Language Learning , pages 171–180.
Association for Computational Linguistics.
Omer Levy and Yoav Goldberg. 2014b. Neural word
embedding as implicit matrix factorization. Ad-
vances in neural information processing systems , 27.
10Omer Levy, Yoav Goldberg, and Ido Dagan. 2015. Im-
proving distributional similarity with lessons learned
from word embeddings. Transactions of the Associa-
tion for Computational Linguistics , 3:211–225.
Thomas Liao, Rohan Taori, Inioluwa Deborah Raji, and
Ludwig Schmidt. 2021. Are we learning yet? A meta
review of evaluation failures across machine learn-
ing. In Thirty-fifth Conference on Neural Information
Processing Systems Datasets and Benchmarks Track
(Round 2) .
Tal Linzen. 2016. Issues in evaluating semantic spaces
using word analogies. In Proceedings of the 1st Work-
shop on Evaluating Vector-Space Representations for
NLP, pages 13–18. Association for Computational
Linguistics.
Han Liu, Yuhao Wu, Shixuan Zhai, Bo Yuan, and
Ning Zhang. 2023. Riatig: Reliable and impercepti-
ble adversarial text-to-image generation with natural
prompts. In Proceedings of the IEEE/CVF Confer-
ence on Computer Vision and Pattern Recognition ,
pages 20585–20594.
Li Lucy, Dorottya Demszky, Patricia Bromley, and Dan
Jurafsky. 2020. Content analysis of textbooks via nat-
ural language processing: Findings on gender, race,
and ethnicity in texas us history textbooks. AERA
Open , 6(3):2332858420940312.
Ivan Markovsky. 2012. Low rank approximation: Algo-
rithms, implementation, applications , volume 906 of
Communications and Control Engineering . Springer.
Sean Matthews, John Hudzina, and Dawn Sepehr. 2022.
Gender and racial stereotype detection in legal opin-
ion word embeddings. In Proceedings of the AAAI
Conference on Artificial Intelligence , volume 36,
pages 12026–12033.
Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey
Dean. 2013a. Efficient estimation of word represen-
tations in vector space. Arxiv:1301.3781, version
Number: 3.
Tomáš Mikolov, Wen-tau Yih, and Geoffrey Zweig.
2013b. Linguistic regularities in continuous space
word representations. In Proceedings of the 2013
Conference of the North American Chapter of the
Association for Computational Linguistics: Human
Language Technologies , pages 746–751.
David Mimno and Laure Thompson. 2017. The strange
geometry of skip-gram with negative sampling. In
Proceedings of the 2017 Conference on Empirical
Methods in Natural Language Processing , pages
2873–2878, Copenhagen, Denmark. Association for
Computational Linguistics.
National Archives at San Francisco. Case files by birth
country.
Mitchell G Newberry, Christopher A Ahern, Robin
Clark, and Joshua B Plotkin. 2017. Detecting
evolutionary forces in language change. Nature ,
551(7679):223–226.Reuben Ng, Heather G Allore, Mark Trentalange,
Joan K Monin, and Becca R Levy. 2015. Increas-
ing negativity of age stereotypes across 200 years:
Evidence from a database of 400 million words. PloS
one, 10(2):e0117086.
Jeffrey Pennington, Richard Socher, and Christopher D
Manning. 2014. GloVe: Global vectors for word rep-
resentation. In Proceedings of the 2014 conference
on empirical methods in natural language processing
(EMNLP) , pages 1532–1543.
Jeffrey Pennington, Richard Socher, and Christopher D
Manning. 2023. GloVe: Global vectors for word
representation. Github repository: Commit a6f2b94.
Joseph P Romano and Michael Wolf. 2017. Resurrect-
ing weighted least squares. Journal of Econometrics ,
197(1):1–19.
Nurullah Sevim, Furkan ¸ Sahinuç, and Aykut Koç. 2023.
Gender bias in legal corpora and debiasing it. Natural
Language Engineering , 29(2):449–482.
Nathaniel Swinger, Maria De-Arteaga, Neil Thomas
Heffernan IV , Mark DM Leiserson, and Adam Tau-
man Kalai. 2019. What are the biases in my word
embedding? In Proceedings of the 2019 AAAI/ACM
Conference on AI, Ethics, and Society , AIES ’19,
page 305–311, New York, NY , USA. Association for
Computing Machinery.
Jerry Tang, Amanda LeBel, Shailee Jain, and Alexan-
der G Huth. 2023. Semantic reconstruction of con-
tinuous language from non-invasive brain recordings.
Nature Neuroscience , 26(5):858–866.
Martin A. Tanner. 1996. Tools for Statistical Inference:
Methods for the Exploration of Posterior Distribu-
tions and Likelihood Functions , 3 edition. Springer
Series in Statistics. Springer New York.
Dennis Ulmer, Elisa Bassignana, Max Müller-Eberstein,
Daniel Varab, Mike Zhang, Rob van der Goot, Chris-
tian Hardmeier, and Barbara Plank. 2022. Exper-
imental standards for deep learning in natural lan-
guage processing research. In Findings of the Associ-
ation for Computational Linguistics: EMNLP 2022 ,
pages 2673–2692, Abu Dhabi, United Arab Emirates.
Association for Computational Linguistics.
Aad W. van der Vaart. 2000. Asymptotic statistics , vol-
ume 3. Cambridge University Press.
Laura Wendlandt, Jonathan K. Kummerfeld, and Rada
Mihalcea. 2018. Factors influencing the surprising
instability of word embeddings. In Proceedings of
the 2018 Conference of the North American Chap-
ter of the Association for Computational Linguistics:
Human Language Technologies, Volume 1 (Long Pa-
pers) , pages 2092–2102, New Orleans, Louisiana.
Association for Computational Linguistics.
Yu Xiao, Naomi Baes, Ekaterina Vylomova, and Nick
Haslam. 2023. Have the concepts of ‘anxiety’ and
‘depression’ been normalized or pathologized? A
11corpus study of historical semantic change. PLOS
one, 18(6):e0288027.A Appendix
A.1 Training details
We trained multiple GloVe models for the exper-
iments presented in Section 4. First, we trained
a single model on the unaltered COHA (1900-
1999) corpus, which we used for all of the GloVe-
V results. Second, we trained 100 GloVe mod-
els on document-level bootstrap samples of the
COHA (1900-1999) corpus. In both cases, we pre-
processed the corpus to lowercase all tokens and
drop non-alphabetic characters.
We trained each 300-dimensional GloVe model
(132M parameters for a vocabulary size of approxi-
mately 219,000 words) for 80 iterations using the
following default hyperparameters of the official
GloVe model implementation (Pennington et al.,
2023): initial learning rate of 0.05, and α= 0.75
andxmax= 100 for the weighting function. The
training of each model consumed about 40 minutes
on a workstation equipped with an AMD Milan
7543 @ 2.75 GHz processor CPU, using 48 CPU
cores.
A.2 Variance Estimator Derivation for Bias
Measures Using the Delta Method
A.2.1 Cosine Similarity Bias
The cosine similarity bias function of Garg et al.
(2018) is the following:
f(v1, . . . ,vk,MA,MW) =
1
KX
icos(vi,MA)−1
KX
icos(vi,MW)
where viis the word vector for otherization word
i,MAis the mean word vector over all Asian sur-
names (using pre-normalized vectors), and MW
is the mean word vector over all White surnames
(using pre-normalized vectors). There are Kother-
ization words.
In general, the partial derivative of the cosine
similarity between two vectors aandbwith respect
toais:
∂cos(a,b)
∂a=∂aTb/∂a
∥b∥∥a∥−cos(a,b)
∥a∥·∂∥a∥/∂a
If we take ato be an otherization word vi, this
gives us:
∂cos(vi,MA)
∂vi=
MA
∥MA∥∥vi∥−cos(vi,MA)·vi
∥vi∥2
12If we take ato be an Asian surname vector aj,
where MA=1
mP
jaj
||aj||, this gives us:
∂cos(vi,MA)
∂aj=1
mI
||aj||−ajaT
j
||aj||3
vi
||vi||||MA||−cos(vi,MA)·MA
||MA||2
=1
m||aj||||MA||XT
aj(˜ vi−cos(vi,MA)·˜MA)
where Xaj=I−˜ aj˜ aT
j.
So the partial derivatives with respect to each
type of vector are the following:
∂f
∂vi=1
K||vi||
[˜MA−˜MW]−[cos(vi,MA)−cos(vi,MW)]·˜ vi
:=dv
∂f
∂aj=1
Km||MA||I
||aj||−ajaT
j
||aj||3
X
i
˜ vi−cos(vi,MA)·˜MA
=1
Km||aj||||MA||XT
aj
X
i
˜ vi−cos(vi,MA)·˜MA
:=da
∂f
∂wj=−1
Kn||MW||I
||wj||−wjwT
j
||wj||3
X
i
˜ vi−cos(vi,MW)·˜MW
=−1
Kn||wj||||MW||XT
wj
X
i
˜ vi−cos(vi,MW)·˜MW
:=dw
where ˜ ais the normalized version of vector a.
A.2.2 WEAT effect size
For two sets of attributes, VandZ, of equal size
(k) the WEAT effect size of Caliskan et al. (2017)
is the following:
f(v1, . . . ,vk,z1, . . . ,zk,a1, . . . ,aA,w1, . . . ,wW)
=1
|V|P
is(vi,W,A)−1
|Z|P
is(zi,W,A)
std. dev x∈V∪Zs(x, W, A ):=H
Gwhere
H=X
i1
WX
jcos(vi, wj)−1
AX
jcos(vi, aj)
−X
i1
WX
jcos(zi, wj)−1
AX
jcos(zi, aj)
=X
v∈Vs(v, W, A )−X
z∈Zs(z, W, A )
and
G2=1
|V∪Z| −1
X
x∈V∪Z 
s(x, W, A )−1
|Z∪V|X
ys(y, W, A )!2
:=1
|V∪Z| −1X
x∈V∪Z(s(x, W, A )−E)2
Letc′
a(a,b) =∂cos(a,b)
∂a. We first define the
following derivatives:
∂s(vi, W, A )
∂vi=1
WX
jc′
vi(vi,wj)−
1
AX
jc′
vi(vi,aj)
∂s(zi, W, A )
∂zi=1
WX
jc′
zi(zi,wj)−
1
AX
jc′
zi(zi,aj)
∂s(x, W, A )
∂wj=1
Wc′
wj(wj,x), forx∈ {vi,zi}
∂s(x, W, A )
∂aj=−1
Ac′
aj(aj,x), forx∈ {vi,zi}
The partial derivatives with respect to each type
13of vector are the following:
∂f
∂vi=
1
G|V|−H
G5
2·(s(vi, W, A )−E)
|V∪Z|∂s(vi, W, A )
∂vi
∂f
∂zi=
−1
G|Z|−H
G5
2·(s(zi, W, A )−E)
|V∪Z|∂s(zi, W, A )
∂zi
∂f
∂wj=1
G·
 
1
|V|X
v∂s(vi, W, A )
∂wj−1
|Z|X
z∂s(zi, W, A )
∂wj!
−H
G5
21
|V∪Z| −1
P
x∈V∪Z
(s(x, W, A )−E)·
∂s(x,W,A )
∂wj−∂E
∂wj
∂f
∂aj=1
G·
 
1
|V|X
v∂s(vi, W, A )
∂aj−1
|Z|X
z∂s(zi, W, A )
∂aj!
−H
G5
21
|V∪Z| −1
P
x∈V∪Z
(s(x, W, A )−E)·
∂s(x,W,A )
∂aj−∂E
∂aj
where
∂E
∂wj=1
|V∪Z|X
x∈V∪Z∂s(x, W, A )
∂wj
∂E
∂aj=1
|V∪Z|X
x∈V∪Z∂s(x, W, A )
∂aj
A.2.3 Delta Method
Using the derivatives computed in the sections
above, the variance of the bias calculation is:
var(h) =X
i(dt)T
iΣi(dt)i
where h∈[f, g]is the bias function, tis the type of
word i(e.g., t=afor Asian surnames, t=wfor
White surnames, t=vfor Otherization words in
the case of the cosine similarity metric), and Σiis
the variance-covariance matrix for the parameters
of word i(Equation 6).
A.3 Asian Surname List Generation
To explore the behavior of anti-Asian bias scores
on words with varying frequencies in the COHA(1900–1999) corpus (Section 5.3), we compile a
novel Asian surname list with the objective of cap-
turing a broader and more representative set of
surnames that would be present in a historic corpus
such as COHA.
We build on two existing and widely used sur-
name lists for ethnic bias measurement. First, a
list of 20 Asian last names curated by Garg et al.
(2018). This was designed to include the most
common surnames in the United States for this eth-
nicity, as measured by 2000 Census data, as well as
the surnames that had higher average frequencies
in the Google Books and COHA corpora studied
by the authors (largely covering the 1800–1999 pe-
riod). As a result of this curation process, the list is
solely focused on higher frequency last names, and,
by primarily comprising Chinese surnames, may
not be wholly representative of the Asian ethnicity
and of the historic appearances of Asian surnames
in this corpus. Second, a list of 200 Asian Pa-
cific Islander surnames collected by Matthews et al.
(2022) from the 2010 U.S. decennial census, sam-
pled from last names that had a probability of 90%
or larger of belonging to this ethnicity.
We expand the set of 211 unique Asian last
names from the Garg et al. (2018) and Matthews
et al. (2022) lists by collecting surnames in immi-
gration arrival cases from the National Archives at
San Francisco, California, from 1910–1940 (Na-
tional Archives at San Francisco). This data in-
cludes over 65,000 cases detailing the country
of birth, arrival date, first and last name, gender
and date of birth of each person. As ethnicity is
not directly reported, we use the country of birth
to compile the Asian surname list, and find over
1,300 unique last names belonging to immigrants
whose reported birthplace is one the following lo-
cations: China, Japan, Korea, Indo-China, India,
Hong Kong, Burma, Philippine Islands, Thailand,
Malaysia, and Mongolia.14
A.4 Alternative Approaches to Word
Embedding Estimation Uncertainty
We explored several approaches to measuring the
reconstruction error of word embeddings, in addi-
tion to the probabilistic model for GloVe that we
presented in this work.
14We make this surname list available to researchers in our
code repository.
14A.4.1 Implicit matrix factorization in the
skip-gram with negative-sampling
(SGNS) model
Per Levy and Goldberg (2014b), the SGNS word
embedding model implicitly factorizes a matrix
that contains the shifted pointwise mutual infor-
mation (PMI) of word and context vectors. Let
wbe a word vector for word w,cbe a context
vector for word c,VWandVCbe the word and
context vocabularies, respectively, kbe the number
of negative samples, Dbe the collection of word
and context pairs in a corpus, #(i)be the number
of occurrences of word iin the corpus, and #(i, j)
the number of co-occurrences of the words iandj
in the corpus. Then, for sufficiently large dimen-
sionality of the embeddings, the optimal vectors
according to the SGNS objective are such that:
w·c= log#(w, c)· |D|
#(w)·#(c)
−logk
=PMI (w, c)−logk
In this manner, a measure of error in the esti-
mation of the word embedding for word wcould
be obtained by comparing the dot product w·c
andPMI (w, c)across all context words cappear-
ing with word win the corpus. In particular, we
explored a word-level measure of estimation er-
ror for word wcaptured by the median of d(w, c),
the context-level percentage of deviation from the
optimal value, over all contexts:
d(w, c) =w·c−(PMI (w, c)−logk)
PMI (w, c)−logk
By comparing the distribution of this word-level
measure of estimation error over different word
lists, we found that higher frequency word lists,
such as the set of White surnames of Garg et al.
(2018), had much lower estimation errors com-
pared to relatively lower frequency word lists, such
as the set of 20 Asian surnames (see Figure 8).
Though helpful to assess the estimation quality
of word embeddings in a corpus, an important lim-
itation of this method is that it is not a probabilistic
model, and so offers no obvious way to perform
hypothesis testing in downstream applications ac-
counting for this type of error. For this reason,
we sought a different approach that could provide
not only point estimates for the embeddings, but
accompanying uncertainty measures with a proba-
bilistic foundation.
Figure 8: Distribution of word-level estimation error
measures in COHA for different word lists. Using
Levy and Goldberg’s findings for the skip-gram with
negative-sampling (SGNS) model, we compute a word-
level measure of the estimation error in word embed-
dings.
A.4.2 Bayes by Backprop for the SGNS model
In order to obtain distributions over the word em-
beddings, we explored the Bayes-by-Backprop al-
gorithm of Blundell et al. (2015), a variational
inference approach that learns a distribution over
neural network weights. Han et al. (2018) adapt
this method to obtain approximate posterior dis-
tributions for SGNS word embeddings, incorpo-
rating metadata on document covariates in order
to learn conditional distributions for different cor-
pus subsets (e.g., temporal periods or genres) that
share structural information across these partitions.
Using a Gaussian mixture prior for the parame-
ters of the word and context vectors, this method
computes the following conditional posterior dis-
tribution ww|xfor word vectors and unconditional
posterior distribution wcfor the context vectors:
ww|x∼N(f(µw, µx), σw|c)
wc∼N(˜µc,˜σc))
where xis the subcorpus on which the embedding
for word wis estimated, fis an affine transfor-
mation that combines corpus-level word vectors
µwand embeddings for each subcorpora µx, and
σwand˜σcare the diagonal covariance of word
and context vectors, respectively, parameterized as
σw|c= log(1 + eρw)and˜σc= log(1 + e˜ρc). The
Bayes-by-Backprop algorithm initializes parame-
tersµw,µx,˜µc,ρwand˜ρcfor all word and con-
text vectors in the vocabulary, and, given (w, c, x )
triplets, performs sequential updates to these pa-
15Figure 9: Word-level relationship between posterior
standard deviations and frequency in COHA using
the Bayes-by-Backprop approach. Lower-frequency
words displayed poor convergence and their posterior
standard deviations were effectively unchanged during
training.
rameters by computing the gradient of the varia-
tional approximation to the posterior.
Unfortunately, training meaningful embeddings
with Bayes-by-Backprop turned out to be chal-
lenging. On the COHA corpus, our best perfor-
mance was a mean accuracy of 0.11 on the Google
analogy task (Mikolov et al., 2013a) and a mean
Pearson similarity statistic of 0.41 on the MEN
similarity task (Bruni et al., 2012), relative to a
benchmark of 0.24 and 0.51, respectively, using the
pre-trained embeddings of Hamilton et al. (2016)
across COHA decades. We explored numerous
refinements to improve the training of Bayesian
Neural Networks (Book, 2020), including using
different weight initialization schemes for separate
parameter groups (e.g., Uniform Kaiming scheme),
and both uniformly and dynamically re-weighting
the Kullback-Leibler divergence component of the
cost function, to no greater success.
In addition to the lower quality of the embed-
ding posterior means, we encountered an important
scaling issue in the trained parameters. After train-
ing, the posterior means were one to two orders
of magnitude smaller than the posterior standard
deviations, effectively barring us from drawing
meaningful samples from these distributions. An
analysis of the relationship between the posterior
standard deviations and word-level frequency indi-
cated that there was an inverse relationship between
these (similar to what we document in Figure 3
for GloVe-V); however, this relationship only held
for higher frequency words. For lower frequencywords, the posterior standard deviations were all
equivalent and effectively unmodified from their
initialization value (see Figure 9). Convergence di-
agnostics on this model confirmed that these param-
eters ( ρwand˜ρc) were not training correctly. Fur-
ther work would be required to design priors and
parameter-specific weight initialization schemes
that lead to proper training of the parameters for
this subset of words. Our code for these training
runs is made available at the project repository.
16