Uncertainty in Language Models: Assessment through Rank-Calibration
Xinmeng Huang*†Shuo Li∗†Mengxin Yu†Matteo Sesia‡Hamed Hassani†
Insup Lee†Osbert Bastani§†Edgar Dobriban§†
Abstract
Language Models (LMs) have shown promis-
ing performance in natural language genera-
tion. However, as LMs often generate incorrect
or hallucinated responses, it is crucial to cor-
rectly quantify their uncertainty in responding
to given inputs. In addition to verbalized confi-
dence elicited via prompting, many uncertainty
measures ( e.g., semantic entropy and affinity-
graph-based measures) have been proposed.
However, these measures can differ greatly, and
it is unclear how to compare them, partly be-
cause they take values over different ranges
(e.g.,[0,∞)or[0,1]). In this work, we ad-
dress this issue by developing a novel and prac-
tical framework, termed Rank-Calibration , to
assess uncertainty and confidence measures for
LMs. Our key tenet is that higher uncertainty
(or lower confidence) should imply lower gen-
eration quality, on average. Rank-calibration
quantifies deviations from this ideal relation-
ship in a principled manner, without requiring
ad hoc binary thresholding of the correctness
score ( e.g., ROUGE or METEOR). The broad
applicability and the granular interpretability of
our methods are demonstrated empirically. The
code to replicate our experiments is here .
1 Introduction
Language Models (LMs), especially Large Lan-
guage Models (LLMs), have shown promising per-
formance in Natural Language Generation (NLG).
These models, fitted on huge text corpora, can pro-
duce responses resembling those of humans (Tou-
vron et al., 2023b; OpenAI, 2023). However,
since LMs often generate wrong or hallucinated
responses (Weidinger et al., 2021; Xiao and Wang,
2021; Huang et al., 2024), it is crucial to correctly
*The first two authors are listed alphabetically. Correspon-
dence to: Xinmeng Huang <xinmengh@sas.upenn.edu> and
Shuo Li <lishuo1@seas.upenn.edu>.
†University of Pennsylvania, Philadelphia (PA), US
‡University of Southern California, Los Angeles (CA), US
§Collaborative advising.quantify their level of uncertainty in responding to
particular inputs.
0 25 50 75 100
Percentage of UNLL (%)020406080100Percentage of Correctness (%)CDF([A|U])
0 25 50 75 100
Percentage of UEcc (%)020406080100Percentage of Correctness (%)CDF([A|U])
Figure 1: Indication diagrams comparing two uncer-
tainty measures, UNLL (negative log-likelihood) and
UEcc(eccentricity), for the GPT-3.5-turbo model on the
TriviaQA benchmark. The red bars indicate the aver-
age correctness of different outputs, as a function of
the corresponding relative uncertainty levels. The blue
and shallow red areas—deviating from the anti-diagonal
line—indicate where the uncertainty measures are over-
optimistic and pessimistic, respectively. Their sum is
ourrank-miscalibration metric ( i.e., RCE), which here
is lower for UNLL thanUEcc. See Sec. 4.3 for details.
Uncertainty quantification is well-explored in su-
pervised learning, specifically in classification ( e.g.,
Lichtenstein et al., 1977; Gal and Ghahramani,
2016; Lakshminarayanan et al., 2017, etc). In clas-
sification, a confidence measure is an estimate of
the probability that the predicted class bYmatches
the true class label Y(Lichtenstein et al., 1977;
Lee et al., 2023). A confidence measure Cis con-
sidered calibrated if it reflects the probability of
correct prediction, i.e.,P(bY=Y|C) =C, for
all values in C’s range. The Expected Calibration
Error (ECE) measures the miscalibration of a confi-
dence measure (Harrell, 2015; Naeini et al., 2015):
EChP(bY=Y|C)−Ci
. (ECE)
In classification, confidence measures are pre-
dominantly built on model logits (Guo et al., 2017;
Kull et al., 2019). However, these methods are less
suitable for NLG tasks. First, the label space is of-
ten too large to assess correctness via bY=Y, since
1arXiv:2404.03163v2  [cs.CL]  14 Sep 2024LMs produce potentially long textual responses bY
for any given input. Second, for LMs, logits en-
code the likelihood of selecting the next token and
do not necessarily capture linguistic sense (Mielke
et al., 2022). Third, even hand-crafted prompts in-
tended to make LMs express confidence explicitly
may not lead to reliable confidence values because
elicitation is heavily tied to prompt formats (Zhao
et al., 2021; Xiong et al., 2024).
Recent works have studied uncertainty measures
as an alternative to confidence measures. These
capture the “dispersion” of an LMs’ potential out-
puts for a fixed input. Kuhn et al. (2023) introduce
semantic entropy , which incorporates linguistic in-
variances arising from the shared meaning of gen-
erated responses. Lin et al. (2023) extend semantic
entropy by leveraging the affinity matrices induced
by entailment scores of generated outputs. Further,
Chen et al. (2024) characterize differential entropy
in the embedding space with EigenScore, via the
covariance of embeddings of potential responses.
Uncertainty measures are more general and ar-
guably more principled than confidence measures
for LMs, but they lack a universal assessment met-
ric such as ECE. A key issue is that uncertainty
measures are not necessarily commensurate. For
instance, the semantic entropy (Kuhn et al., 2023)
can take arbitrarily large positive values, whereas
the EigV measure of Lin et al. (2023) depends on
the number of responses generated. This makes
it difficult to understand, evaluate, and compare
uncertainty measures via a unified lens.
This paper develops a principled framework to
assess the quality of uncertainty and confidence
measures for LMs. We provide a novel and practi-
cal framework, termed Rank-Calibration . Specifi-
cally, our contributions are as follows.
•We mathematically formalize the assessment
of uncertainty/confidence measures for LMs in
NLG tasks, going beyond binary correctness.
•We demonstrate empirically that existing assess-
ment metrics ( e.g., AUROC, ECE, etc) have sev-
eral limitations, including a heavy dependence
on the LM’s performance, instability caused by
ad hoc binarization of correctness scores, and
incompatibility with diverse uncertainty ranges.
•We address these limitations by starting from a
basic principle: lower uncertainty/higher confi-
dence should indicate higher-quality generation.
We thus propose assessing uncertainty measuresin terms of rank-calibration and introduce a suit-
able metric, the Rank-Calibration Error (RCE).
•To make rank-calibration practical, we intro-
duce the Empirical RCE—an estimate of RCE
based on a finite dataset. Moreover, we intro-
duce novel indication diagrams, previewed in
Fig. 1, that intuitively visualize the deviation
of any uncertainty/confidence measure from the
monotonicity required for rank-calibration.
•We experimentally demonstrate the broader ap-
plicability and granular interpretability of our
proposed methods. Comprehensive ablation
studies are conducted to examine its robustness.
2 Correctness and Uncertainty for LMs
LetVbe the token vocabulary of an LM and
V⋆:=∪ℓ≥1Vℓthe space of sequences of arbitrary
length. Given a query x∈ V⋆, an LM Mcan gen-
erate output by≜(byℓ)ℓ≥1∈V⋆by sequentially sam-
pling from the distribution P(by|x) :=Q
ℓ≥1P(byℓ|
x,by<ℓ). Here, byℓ∈ V is the ℓ-th generated token
andP≜PMis the generative distribution of M.
We work with a deterministic correctness func-
tionA:V⋆×V⋆→Rmapping each pair (x;by)to a
correctness value A(x;by). In practice, correctness
is often not a binary variable in NLG tasks and can
be assessed in at least two different ways. For the
reader’s convenience, the concepts and notations
used in the paper are summarized in Table 1.
•Reference matching. Given certain refer-
ence answers {y(m)}M
m=1associated with x,
a similarity score between the output byand
{y(m)}M
m=1can be interpreted as a correctness
value. Similarity scores commonly utilized for
this purpose include the Rouge score, BLEU
score, and outputs of other discriminative LMs.
•Human evaluation. Correctness or quality may
be evaluated by human experts, possibly inte-
grating multiple opinions ( e.g., averaging). This
approach does not require reference answers
and is as “trustworthy” as the humans involved.
Anuncertainty measure is a (possibly random)
function UM:V⋆×V⋆→R,(x;by)7→UM(x;by)
associated with the LM that maps any pair (x;by)to
an uncertainty value.1We will omit Mand write
U(x;by),P(· |x)when the choice of the LM is
1In special cases, the uncertainty measure may only depend
on the input xand the LM M, not the output by.
2Notation Description
V Token vocabulary
V⋆Space of token sequences
x Input context, x∈ V⋆
by Gen. output by= (byℓ)ℓ≥1∈ V⋆
P≜PMGenerative dist. of LM M
A(·;·) A deterministic correctness function
{y(m)}M
m=1Reference answers for input x
UM(x;by)Uncertainty measure for LM M
CM(x;by)Confidence measure for LM M
reg(u) Regression fn. Ex,by[A|U=u]
Table 1: Summary of notations.
clear. Some examples are reviewed below, while
additional examples and details are in Appendix B.
•NLL. In classification, the softmax of the
last-layer logits determines a model’s predic-
tion (Guo et al., 2017). In NLG tasks, one can
view the Negative Log-Likelihood (NLL),
UNLL(x,by):=−ln(P(by|x)),
as an indicator of uncertainty where by=
(byℓ)ℓ≥1is a generated response. A natural ex-
tension accounting for the length of responses
applies length normalization; this is also known
as the Perplexity measure (Jelinek et al., 1977).
•Entropy. The predictive entropy of the dis-
tribution P(· |x)is large when the same input
may lead to diverse outputs, and it is defined as
UE(x):=−Eby∼P(·|x)[ln(P(by|x))].
Malinin and Gales (2021) propose a variant of
this,UE-LN(x), utilizing the length-normalized
log-likelihood ln(P(by|x))/len(by). Kuhn et al.
(2023) argue that different responses with the
same meaning should be viewed as equals in
this context, regardless of token-level differ-
ences. They propose the semantic entropy,
USE(x):=−Eby∼P(·|x)[ln(P(c(by)|x))],
where c(by)is the semantic concept of by, pro-
vided by another language modeling method.
•Affinity graph. Lin et al. (2023) calculate un-
certainty using a weighted adjacency graph built
upon semantic affinities. Consider an affinity
model e, mapping pairs of responses by,by′to
values in [0,1]. Given Kindependent samples{by(k)}K
k=1fromP(· |x), the model einduces
a symmetric adjacency matrix W=[wi,j]K
i,j=1,
withwi,j=(e(by(i);by(j)) +e(by(j);by(i)))/2for
alli, j. Let D= [1[j=i]PK
k=1wk,j]K
i,j=1be
the corresponding degree matrix and {λk}K
k=1
be the eigenvalues of the Laplacian L=I−
D−1/2WD−1/2. Then, the uncertainty mea-
sures proposed in Lin et al. (2023) include
UEigV(x) :=KX
k=1max{0,1−λk},
UDeg(x) := 1 −trace( D)/K2,
UEcc(x) :=∥[v1,v2, . . . ,vK]∥2,
where {vk}K
k=1are suitable vectors associated
with L, see Lin et al. (2023). Intuitively,
UEigV(x)approximately counts the connected
components in the graph represented by W,
while UDeg(x)andUEcc(x)reflect the diver-
sity of outputs.
The diverse uncertainty measures reviewed
above produce outputs with different ranges. For
instance, UNLL,USE, andUEigV can yield any num-
ber in [0,∞), whereas UDegandUEccare bounded
in[0,1]; see Fig. 3 [bottom] for a visual illustration.
This mismatch in output ranges motivates the need
for a novel unified assessment framework.
As we shall see, our assessment framework can
handle not only any uncertainty measure but also
the closely related concept of confidence measures
(Zhao et al., 2021; Mielke et al., 2022; Xiong et al.,
2024). A confidence measure can be cast as a (pos-
sibly random) function CM:V⋆× V⋆→[0,1],
(x;by)7→CM(x;by)with output taking values in
[0,1]. Intuitively, confidence and uncertainty mea-
sures serve similar purposes, although in a com-
plementary way—high confidence should correlate
with low uncertainty, and vice versa.
With this notation in place, we are now ready to
state our goals and give a more detailed preview
of our proposed framework. Given a benchmark
dataset {(xi,{y(m)
i}Mi
m=1)}n
i=1, where each Mi≥0
denotes the number of reference answers for xi, we
aim to quantify the performance of an uncertainty
measure U(or a confidence measure C) as follows.
First, we obtain the paired values of uncertainty and
correctness {(U(xi,byi), A(xi;byi))}n
i=1by inde-
pendently sampling byi∼P(·|xi)for each 1≤i≤n.
Then, we evaluate E({(U(xi,byi), A(xi;byi))}n
i=1)
3Figure 2: Common workflow for assessing the quality of an LM uncertainty/confidence measure. The key ingredients
are: a base LM M(e.g., Llama-2-7b-chat), a correctness function A(e.g., the Rouge-L score), a benchmark dataset
{xi,{y(m)
i}Mi
m=1}n
i=1(e.g., TriviaQA), an assessment metric E(e.g., AUROC), and the uncertainty measure U
(e.g.,UDeg). The workflow proceeds in five stages: generation, correctness calculation, correctness discretization,
uncertainty quantification, and evaluation. Notably, the threshold τin correctness discretization is usually chosen
heuristically (Kuhn et al., 2023; Xiong et al., 2024; Lin et al., 2023, etc), which can be problematic, as demonstrated
in Sec. 3. Our proposed RCE-based assessment removes this stage by using the correctness values directly.
for each 1≤i≤n, using a suitable metric E.2To ac-
count for the randomness in sampling byi, we may
draw multiple independent responses {by(k)
i}K
k=1iid∼
P(· |xi)and take the average as the final resultPK
k=1E({(U(xi,by(k)
i), A(xi,by(k)
i))}n
i=1)/K.
The closest works have been discussed in Sec. 1
and 2, and more related works are reviewed in
Appendix A.
3 Limitations of Existing Assessments
This section illustrates some limitations of exist-
ing assessments for LM uncertainty measures via a
case study applying the GPT-3.5-turbo (Ouyang
et al., 2022) model on the TriviaQA bench-
mark (Joshi et al., 2017). We use the validation
set of TriviaQA, which contains 11,322question-
answer pairs (after deduplication). We use the same
prompt template as that in Lin et al. (2023). The
template is shown in Appendix E.2.
The uncertainty measures examined here include
the negative log-likelihood UNLL, the semantic en-
tropy USE(Kuhn et al., 2023), the affinity-graph-
based measures UEigV,UEcc, and UDeg(Lin et al.,
2023), with the affinity determined by the NLI
model (He et al., 2021), and the verbalized confi-
dence CVerb (Xiong et al., 2024); see the defini-
tions in Appendix B. These include both white box
and grey box measures,3as well as a diversity of
2A common practice is to map the correctness values to
{0,1}by thresholding at an ad hoc value before feeding them
into the evaluation metric; see Sec. 3 for a discussion of the
limitations of this approach.
3The grey-box oracle refers to the access to model logits,prompt strategies. We use the Rouge-L score as
the correctness function A. We follow a common
assessment pipeline (Kuhn et al., 2023; Lin et al.,
2023; Xiong et al., 2024), as depicted in Fig. 2. The
assessment metrics are detailed in Appendix C.
0.0 0.2 0.4 0.6 0.8 1.0
Threshold0.60.70.8AUROC
Uncertainty/Confidence Measures050100150Output RangesUEigV
UEcc
UDeg
USE
UNLL
CVerb
Figure 3: Top: AUROCs of uncertainty/confidence mea-
sures with various thresholds. Bottom: Output ranges
of uncertainty/confidence measures. Both results are for
GPT-3.5-turbo on the TriviaQA benchmark.
Ad hoc correctness thresholding. Most existing
assessment metrics ( e.g., AUROC, AUPRC, ECE,
etc) are rooted in classification and require binary
labels ( i.e.,A∈ {True orFalse}). Consequently,
an ad hoc threshold τ∈Ris often introduced to
map continuous correctness values to binary labels,
i.e.,¯Aτ(x;by):=1[A(x;by)≥τ](Lin et al., 2023;
Kuhn et al., 2023). Thus, the response is viewed as
correct if the correctness value A(x;by)is at least
τ, and incorrect otherwise.
which is partly feasible for commercial LMs, while the black-
box oracle only relies on generated outputs.
4However, thresholding can lead to inconsisten-
cies. Taking AUROC as an example, we plot the as-
sessed results of uncertainty/confidence measures
under varying thresholds in Fig. 3 [top]. The rela-
tive AUROC results of distinct measures vary dras-
tically with the choice of τ. For example, UNLL
appears inferior to other methods if τ <0.2, but
it becomes the best measure if τ > 0.8. This is
especially concerning given that there seems to be
no principled way to set this threshold. The same
limitation also affects other metrics ( e.g., AUPRC,
AUARC) and configurations; see Appendix E.4.
Diverse output ranges. The second limitation of
existing assessments is rooted in the diverse output
ranges of the uncertainty or confidence measures.
As shown in Fig. 3 [bottom], the output ranges of
different uncertainty measures vary significantly.
For example, the values of USEcan be higher than
100while the values of UEccandUDegare small by
definition. This diversity of output ranges prevents
the direct use of calibration-based metrics such as
ECE, which takes variables with inputs in [0,1].
Strong dependence on LM performance. While
the quality of uncertainty/confidence measures
should be disentangled from the generation per-
formance of the LM, there is often a strong relation
between the two concepts. We argue that many
existing metrics ( e.g., AUROC, AUPRC, AUARC)
can be misleading due to this entanglement. Taking
AUARC as an example, if the base LM is powerful
and all correctness values of its responses are high
(e.g., within [0.9,1.0]), then the evaluated AUARC
will be high for any uncertainty/confidence mea-
sure, regardless of its quality. This is undesirable
because our goal is to provide an overall assess-
ment of the uncertainty measure, which may in the
future need to be applied to different LMs. While
the ECE metric provides a limited “disentangling”
effect, in the sense that it can reflect that highly ac-
curate models may be poorly calibrated ( i.e., with
high ECE values) (Guo et al., 2017), it is not appli-
cable to uncertainty measures in general.
Desiderata of evaluation. The aforementioned
challenges suggest that the evaluation of LM un-
certainty measures should take into account the fol-
lowing key desiderata: (1) avoidance of ad hoc cor-
rectness thresholding, (2) applicability to diverse
output ranges of uncertainty measures, and (3) de-
coupling from the generative performance of the
LM. Moreover, the evaluation framework shouldbe practical. We view these criteria as important,
butnot necessarily exhaustive for an ideal assess-
ment. Future research may identify other requisites
and further improve our framework accordingly.
4 Rank-Calibration
In this section, we introduce a novel assessment
framework satisfying the criteria outlined in Sec. 3.
4.1 Rank-Calibration & RCE
Define the regression function reg(·):R→R, u7→
Ex,by[A(x;by)|U(x;by) =u], representing the
expected correctness level Aconditional on an un-
certainty level U=u. Here, xis a random query
sampled from the distribution associated with a
specific benchmark dataset, while by|x∼P(· |x)
is a random output sampled from the generative
distribution of the LM. We start from the observa-
tion that, ideally, a lower uncertainty level should
correspond to higher generation accuracy. This is
equivalent to saying that the regression function
should ideally be monotone decreasing .
Since Uis a random variable depending on
(x;by),reg(U)is also random. If reg(·)is
monotonically decreasing, then U≤uimplies
reg(U)≥reg(u). Thus, for any value uin the
range of U,
P(U≤u) =P(reg(U)≥reg(u)). (1)
Equation (1)suggests a direct relation between an
uncertainty level uand its corresponding expected
correctness level reg(u). For example, for a value
ofuin the in bottom 10% of the distribution of
U, the expected correctness level reg(u) =E[A|
U=u]is in the top 10% in the distribution of
reg(U)=E[A|U]. We call this desired property
of uncertainty measures Rank-Calibration .
Definition 1 (RANK-CALIBRATION ).We say that
an uncertainty measure Uis rank-calibrated if (1)
holds for any uinU’s range: on average, a lower
uncertainty implies a higher generative quality.
Rank-calibration is related to, yet distinct from,
the usual notion of calibration in the classification
context (Lichtenstein et al., 1977; Guo et al., 2017).
We defer the detailed discussion to Sec. 4.2. We
remark that the principle of rank calibration is also
discussed in a concurrent work (Zhang et al., 2024).
Unlike our work and (Zhang et al., 2024), (Penha
and Hauff, 2021) use the terminology “rank” to
denote the relevance comparison of candidate re-
sponses in the binning of ECE calculation.
5To quantify the distance of a given uncertainty
measure from the ideal rank-calibration, we pro-
pose the following Rank-Calibration Error (RCE) ,
inspired by ECE for calibration.
Definition 2 (RANK-CALIBRATION ERROR ).The
RCE of an uncertainty measure Uis defined as
EUPU′(reg(U′)≥reg(U))−PU′(U′≤U)
,
(RCE)
where U′is an independent copy of U.
Extension to confidence measures. While pri-
marily motivated by uncertainty measures with in-
commensurate ranges, rank-calibration also applies
to confidence measures. Ideally, higher values of a
confidence measure should imply higher generation
accuracy . Thus, defining reg(c) :=E[A|C=c]
for all cin the range of C, we can adapt RCE to
ECPC′(reg(C′)≥reg(C))−PC′(C′≥C)
,
(2)
where C′is an independent copy of C. This gauges
deviations from the equivalence between C≥c
andreg(C)≥reg(c). Since rank-calibration pro-
vides a different perspective from calibration—see
Sec. 4.2— (2)serves as a supplement to ECE in
assessing confidence measures.
4.2 Comparison with Classical Calibration
For a binary correctness value function Ataking
values in {0,1}, rank-calibration relaxes classi-
cal calibration by absorbing all strictly decreasing
transformations.
Theorem 1. Suppose the correctness function A
takes values in {0,1}. If an uncertainty measure
Uis rank-calibrated, i.e., its RCE is zero, then
there exists a unique strictly decreasing transfor-
mation g⋆:R→[0,1]such that Cg⋆:=g⋆(U)is
calibrated, i.e., its ECE is zero. If a confidence
measure Cis calibrated, then for any strictly de-
creasing transformation h:R→R, the induced un-
certainty measure Uh:=h(C)is rank-calibrated.
Proof. IfUis rank-calibrated, the regression func-
tionu7→reg(u) =E[A|U=u]∈[0,1]is
strictly decreasing over all values in U’s range with
positive density (or mass). Moreover, P(A= 1|
reg(U)=reg( u)) =E[A|U=u] = reg( u). There-
fore, reg(U)is a calibrated confidence measure,
andregis strictly decreasing. The uniqueness fol-
lows as P(A= 1|g(U)) =E[A|U] = reg( U)for
any strictly monotone function.On the other hand, if Cis calibrated, then C=
P(A= 1|C) =E[A|C]almost surely. For any
strictly decreasing h, we have E[A|Uh] =E[A|
C] =Calmost surely because his a one-to-one
map. Therefore, for any given cand uncertainty
value uh=h(c), it holds almost surely that
Uh=h(C)≤uh=h(c)⇐⇒ C≥c
⇐⇒E[A|C]≥E[A|C=c]
⇐⇒E[A|Uh]≥E[A|Uh=uh],
which implies Uhis rank-calibrated.
Theorem 1 implies that, for a binary correctness
function, one can construct a calibrated confidence
measure from an uncertainty measure with mono-
tone transformations if and only if the uncertainty
measure is rank-calibrated. However, RCE and
ECE gauge different quantities: ECE captures the
absolute difference between the predicted and true
probabilities, while RCE reflects the deviation from
a monotonic correspondence between uncertainty
and the expected correctness. These two notions
are generally not directly comparable.
For example, consider the special case where a
continuous-valued confidence measure Cis com-
pletely uninformative and the regressed correctness
reg : c7→E[A|C=c]is a constant for all con-
fidence levels c. Then, the RCE defined in (2)
reports a large value of 1/2, reflecting its poor in-
dicativeness. However, the ECE can be large or
small depending on the averaged distance between
C’s output and reg. More generally, we find no
relation in the results of ECE and RCE through the
following result, proved in Appendix D.
Proposition 1. Let the correctness function A∈
{0,1}be binary. For any α, β∈(0,1/2], there
is a confidence measure Csuch that its RCE is α
while the ECE is β.
4.3 Empirical RCE & Indication Diagram
Now, as in Sec. 2, consider a dataset {(ui, ai)}n
i=1
of uncertainty and correctness values computed
over a benchmark dataset where each ui=
U(x;byi),ai=A(xi;byi), andbyiis a response
generated by the LM. The true value of RCE is
unknown, as it refers to an average over the distri-
bution from which the data are drawn.
Empirical RCE. The RCE involves the unknown
probabilities P(U≤u)andP(reg(U)≥reg(u)),
which generally need to be estimated. Estimating
6the latter is challenging as the regression function
is also unknown and needs to be estimated.
To address this, we adopt a piecewise constant
regression or binning strategy, as in non-parametric
statistics (Tsybakov, 2009). First, we group the
uncertainty values {ui}n
i=1intoBequal-mass in-
tervals, each containing ⌈n/B⌉—or, when needed,
⌊n/B⌋—elements. The boundaries of the b-th
(1≤b≤B) bin are the (b−1)/B-th and b/B-th
quantiles of (ui)n
i=1. LetIb⊆ {1, . . . , n }be the
set of indices of the datapoints whose uncertainty
values fall into the b-th bin. The expected correct-
ness level over the b-th bin can be estimated as
crcb:=1
|Ib|X
i∈Ibai,
when|Ib|>0. From now on, we will inter-
pret0/0 := 0 ; and we extend to |Ib|= 0 in
this way. Clearly, crcbis an unbiased estimator
ofE[A|U∈thei-th bin ], which approximates
reg(U)accurately given a narrow bin and abundant
data. We similarly estimate the average uncertainty
within the b-th bin as
uctb=1
|Ib|X
i∈Ibui.
Ascrcbanductbestimate the per-bin averages of
reg(U)andU, for each b, we estimate P(U≤ui)
andP(reg(U)≥reg(ui))fori∈ Ibas follows:
bP(reg(U)≥reg(ui)):=1
B−1X
b′̸=b1[crcb′≥crcb],
bP(U≤ui):=1
B−1X
b′̸=b1[uctb′≤uctb].
A rank-calibrated measure has bP(U≤ui)≈
bP(reg(U)≥reg(ui))for all 1≤i≤n. We thus
compute the empirical Rank-Calibration Error esti-
mator (Empirical RCE) by taking an average of the
per-bin rank differences of correctness and uncer-
tainty values. More precisely,
1
nnX
i=1bP(reg(U)≥reg(ui))−bP(U≤ui).
(Empirical RCE)
The difference between the estimated probabilities
for a given bin represent the ranking gap ( i.e., blue
and shallow red areas in Fig. 1). We use the Empir-
ical RCE as the main metric to assess uncertainty
and confidence measures in the paper.Indication diagram. Similar to reliability dia-
grams representing miscalibration (Lichtenstein
et al., 1977; Niculescu-Mizil and Caruana, 2005),
we can also visualize rank-miscalibration in dia-
grams ( e.g., Fig. 1). In particular, we plot the rela-
tive percentile (between 0%and100% ) of the ex-
pected correctness level ( i.e.,reg(U)) as a function
of the relative percentile of uncertainty ( i.e.,U).
We term these plots indication diagrams . If a mea-
sure is rank-calibrated— i.e., if(1)holds—then the
indication diagram should lie on the anti-diagonal
linepercent(reg( u)) = 1−percent( u). Deviations
from this line represent rank-miscalibration.
Advantages of rank-calibration. We summa-
rize the advantages of the rank-calibration frame-
work by revising the desiderata from Sec. 3. First,
the empirical RCE does not require any thresh-
olding of the correctness values. Second, rank-
calibration assesses the monotonicity of uncertainty
values by leveraging relative ranks, which makes it
independent of the output range. Third, similar to
ECE, the RCE is not directly tied to the generation
performance of the LM. Finally, our assessment is
practical for any uncertainty/confidence measures.
5 Experiments
We provide more comprehensive experiments and
justify the advantages of our assessment.
5.1 Experiment Setup
We consider both open-source and commercial
LMs, including Llama-2-7b ,Llama-2-7b-chat (Tou-
vron et al., 2023b) (an instruction fine-tuned ver-
sion of Llama-2-7b ), and GPT-3.5-turbo (Ouyang
et al., 2022). See Appendix E.1 for more details.
We conduct assessments on the validation sets of
four datasets: TriviaQA (Joshi et al., 2017), Natu-
ral Questions (Kwiatkowski et al., 2019), SQuAD-
1 (Rajpurkar et al., 2016), and Meadow (Wang
et al., 2020). For assessment over the open-ended
and challenging Meadow, we only use the more
advanced model GPT-3.5-turbo. To account for
randomness in the evaluation, we repeat experi-
ments bootstrapping each dataset 20 times. See
more details of datasets in Appendix E.2.
We use multiple correctness functions, including
theRouge-L score, BERT similarity , and ChatGPT
evaluation , all widely applied before (Kuhn et al.,
2023; Xiong et al., 2024). ChatGPT correctness is
only used for GPT-3.5-turbo with temperature 1.0.
See Appendix E.3 for more details.
7Dataset Correctness Temperature UEcc UDeg UEigV UNLL USE CVerb
nq-openbert0.6 0.199 ±0.040 0.046 ±0.008 0.052 ±0.010 0.101 ±0.015 0.062 ±0.010 nan
1.0 0.236 ±0.033 0.035 ±0.008 0.038 ±0.007 0.097 ±0.017 0.055 ±0.012 nan
meteor0.6 0.190 ±0.039 0.062 ±0.008 0.067 ±0.010 0.176 ±0.018 0.072 ±0.009 nan
1.0 0.224 ±0.034 0.044 ±0.006 0.046 ±0.007 0.209 ±0.023 0.074 ±0.015 nan
rougeL0.6 0.198 ±0.039 0.053 ±0.011 0.057 ±0.010 0.167 ±0.013 0.060 ±0.012 nan
1.0 0.227 ±0.035 0.035 ±0.007 0.033 ±0.006 0.211 ±0.021 0.069 ±0.016 nan
rouge10.6 0.199 ±0.039 0.054 ±0.010 0.057 ±0.010 0.167 ±0.014 0.061 ±0.013 nan
1.0 0.227 ±0.035 0.034 ±0.007 0.033 ±0.006 0.212 ±0.021 0.069 ±0.015 nan
squadbert0.6 0.208 ±0.033 0.065 ±0.014 0.075 ±0.017 0.048 ±0.007 0.063 ±0.012 nan
1.0 0.276 ±0.039 0.067 ±0.011 0.063 ±0.010 0.038 ±0.006 0.098 ±0.012 nan
meteor0.6 0.216 ±0.038 0.303 ±0.026 0.265 ±0.022 0.063 ±0.013 0.182 ±0.029 nan
1.0 0.300 ±0.046 0.292 ±0.035 0.250 ±0.027 0.064 ±0.011 0.274 ±0.021 nan
rougeL0.6 0.239 ±0.036 0.177 ±0.026 0.143 ±0.020 0.052 ±0.011 0.127 ±0.020 nan
1.0 0.304 ±0.036 0.179 ±0.033 0.137 ±0.024 0.053 ±0.012 0.210 ±0.027 nan
rouge10.6 0.238 ±0.037 0.183 ±0.027 0.148 ±0.022 0.053 ±0.010 0.129 ±0.021 nan
1.0 0.303 ±0.035 0.185 ±0.033 0.143 ±0.025 0.053 ±0.012 0.213 ±0.026 nan
triviaqabert0.6 0.140 ±0.024 0.062 ±0.016 0.061 ±0.015 0.020 ±0.004 0.027 ±0.007 nan
1.0 0.213 ±0.030 0.025 ±0.006 0.034 ±0.006 0.014 ±0.002 0.036 ±0.006 nan
meteor0.6 0.145 ±0.027 0.067 ±0.017 0.064 ±0.015 0.034 ±0.009 0.075 ±0.016 nan
1.0 0.206 ±0.032 0.035 ±0.007 0.046 ±0.005 0.049 ±0.008 0.084 ±0.007 nan
rougeL0.6 0.141 ±0.021 0.062 ±0.014 0.061 ±0.014 0.024 ±0.005 0.034 ±0.005 nan
1.0 0.204 ±0.035 0.027 ±0.006 0.040 ±0.004 0.022 ±0.002 0.051 ±0.007 nan
rouge10.6 0.141 ±0.021 0.062 ±0.014 0.062 ±0.013 0.024 ±0.005 0.034 ±0.006 nan
1.0 0.203 ±0.035 0.027 ±0.006 0.040 ±0.004 0.022 ±0.002 0.051 ±0.007 nan
Table 2: RCE results for Llama-2-chat with various experimental configurations.
The uncertainty/confidence measures to be as-
sessed are the same as in Sec. 3, ( i.e.,UNLL,USE,
UEcc,UDeg,UEigV, and CVerb). We first illustrate
that our proposed assessment has broad applica-
bility and granular interpretability. Furthermore,
we qualitatively show that uncertainty measures
with lower RCE values reliably indicate correct-
ness. Finally, we study robustness by empirically
checking the impact of temperature and correctness
functions on RCE (Demšar, 2006). More results
for different configurations are given in Table 4.
5.2 Broader Applicability
Previous assessments have some limitations in
open-ended tasks. First, as shown in Fig. 4 [top],
the correctness distribution in open-ended tasks
(e.g., the Meadow dataset) is less concentrated
around zero and one compared to the TriviaQA
correctness distribution. Consequently, if correct-
ness were binarized with thresholding, the assessed
results would be highly impacted by the thresh-
old choice, as illustrated in Fig. 4 [bottom]. As
such, using continuous-valued correctness scores is
common in open-ended tasks (Cohan et al., 2018;
Uppalapati et al., 2023). Since RCE does not re-
quire thresholding, our rank-calibration assessment
does not suffer from the above issue.
5.3 Granular Interpretability
Beyond the rank-calibration error, the indication
diagrams can be instrumental in understanding the
performance of uncertainty measures. We show
0 1
Correctness A050000 Frequency
0 1
Correctness A05001000 Frequency
0.00 0.25 0.50 0.75
Threshold0.60.8AUROCUEigV
UEcc
UDeg
USE
UNLL
CVerbFigure 4: Top: Rouge-L correctness distributions of
GPT-3.5-turbo on the TriviaQA (left) and Meadow
(right) benchmarks. Bottom: AUROCs of assessed
measures for GPT-3.5-turbo on Meadow , with Rouge-L
correctness and various thresholds.
the indication diagrams of UNLLandUSEfor GPT-
3.5-turbo on TriviaQA in Fig. 1. More indication
diagrams can be found in the Appendix.
First, indication diagrams consistently reflect the
effect of rank-miscalibration. The indication di-
agram of UNLL (Fig. 1 [left]) has more overlap
between the red and blue bars, compared to that of
UEcc(Fig. 1 [right]), reflecting a lower RCE level
(0.038 with UNLLv.s. 0.151 with UEcc). The high
overlap suggests that the relative ranks of uncer-
tainty values are more aligned with those of cor-
rectness levels, leading to better rank-calibration.
Second, indication diagrams can shed light onto
8which uncertainty levels may be problematic. For
example, in Fig. 1 [right], we observe that for an
uncertainty in the top 75th percentile, UEcctends to
be overpessimistic: UEccassigns high uncertainty
values to high-quality generations.
5.4 Qualitative Illustration
To illustrate the effectiveness of the RCE as an eval-
uation metric for uncertainty measures, we present
two TriviaQA instances and contrast UNLL (hav-
ing RCE 0.037) with USE(having RCE 0.051) for
GPT-3.5. Here, xis the question input, yis the
answer in the dataset, byis the LM response, and
P(U≤u)signifies the relative magnitudes of LM’s
uncertainty level according to UNLLandUSE.
x: On September 28th,
NASA announced that what
had been detected on Mars?
y: flowing water
by: Possible signs of life
P(USE≤u): 0.813
P(UNLL≤u): 0.930
x: “Feel Like Making
Love” and “The First Time
Ever I Saw Your Face” were
hit singles for which fe-
male artist?
y: roberta flack
by: Roberta Flack
P(USE≤u): 0.864
P(UNLL≤u): 0.046
In the first instance, the generation is factually in-
correct and UNLLassigns a high uncertainty value
to the response, i.e.P(UNLL≤u)≈1. In the sec-
ond scenario, where the generation is correct, UNLL
succeeds in providing a lower uncertainty level,
i.e.P(UNLL≤u)≈0. Yet, USEassigns a lower
uncertainty to a poorer generation and a higher
uncertainty to a better generation ! These instances
showcase that UNLLis more reliable than USEhere,
which is consistent with the RCE-assessed results.
Additional qualitative results are given in Table 5.
5.5 Post-hoc Recalibration
Recalibrating uncertainty/confidence measures
with poor rank-calibration can be of interest;
for ECE, this is sometimes known as Mincer-
Zamowitz regression (Mincer and Zarnowitz,
1969). As discussed in Sec. 4.2, an ECE-calibratedDataset Correctness Temperature USE USE,cal
meadowbert 1.0 0.177 ±0.027 0.083±0.016
meteor 1.0 0.132 ±0.018 0.066±0.015
rougeL 1.0 0.113 ±0.022 0.063±0.014
rouge1 1.0 0.113 ±0.018 0.061±0.012
nq-openbert 1.0 0.050 ±0.007 0.026±0.007
meteor 1.0 0.060 ±0.009 0.033±0.011
rougeL 1.0 0.052 ±0.008 0.030±0.010
rouge1 1.0 0.051 ±0.008 0.029±0.010
squadbert 1.0 0.113 ±0.013 0.050±0.013
meteor 1.0 0.086 ±0.014 0.046±0.010
rougeL 1.0 0.100 ±0.011 0.037±0.008
rouge1 1.0 0.103 ±0.011 0.039±0.007
triviaqabert0.5 0.052 ±0.009 0.030±0.010
1.0 0.052 ±0.012 0.027±0.008
1.5 0.081 ±0.009 0.029±0.007
meteor0.5 0.234 ±0.019 0.058±0.015
1.0 0.209 ±0.012 0.047±0.014
1.5 0.176 ±0.015 0.036±0.012
rougeL0.5 0.050 ±0.008 0.028±0.007
1.0 0.059 ±0.009 0.026±0.007
1.5 0.104 ±0.007 0.028±0.006
rouge10.5 0.050 ±0.008 0.028±0.006
1.0 0.060 ±0.009 0.027±0.006
1.5 0.105 ±0.008 0.028±0.008
Table 3: RCE results of USEandUSE,calafter rank-
calibration for GPT-3.5-turbo with various experimental
configurations.
measure is also RCE-calibrated. However, RCE
is invariant to monotone transformations, which
means that approaches like Platt scaling (Platt,
1999) and isotonic regression (Zadrozny and Elkan,
2002) will not improve rank-calibration. Therefore,
we suggest using histogram binning (or, piecewise
constant regression), which includes non-monotone
transforms (Zadrozny and Elkan, 2001). Table 3
and Fig. 10 and 11 list the RCE results of USEfor
GPT-3.5-turbo before and after calibration. We ob-
serve the calibrated measure is significantly better
rank-calibrated, showing the effectiveness of this
strategy. See the more experimental details and
results in Appendix F.2.
5.6 Robustness Analysis
We conduct ablation studies to analyze the robust-
ness of our assessment to key hyperparameters, in-
cluding temperatures, correctness scores, and sam-
ple sizes. We further propose a method to make
robust comparisons between uncertainty measures
via the Critical Difference (CD) Diagram (Demšar,
2006). Detailed information and results are in Ap-
pendix F.4.
6 Conclusion
This paper investigates the limitations of common
assessments for LM uncertainty/confidence mea-
sures. We develop an alternate framework, termed
rank-calibration, to assess their quality. Our ap-
proach does not require binarizing correctness at ad
hoc thresholds and is compatible with uncertainty
measures taking values in any output range. We ex-
9perimentally show the broad applicability and the
granular interpretability of our method, and provide
a comprehensive robustness analysis. Future direc-
tions include developing uncertainty measures with
guaranteed rank-calibration and enhancing genera-
tive pipelines of LMs ( e.g., the retrieval-augmented
generation) with rank-calibrated measures.
Limitation & Broader Impact
The empirical RCE estimate has not been sub-
jected to a thorough statistical analysis. The per-
formance of assessed uncertainty and confidence
measures ( e.g., the vanilla verbalized confidence
CVerb) have not been optimized, since the paper
focuses on a new assessment approach rather than
benchmarking. Human correctness evaluation is
not performed, due to our limited budget.
This work is designed to unveil the issues in
the existing approaches for evaluating LM uncer-
tainty/confidence measures, and to introduce an
alternate, principled assessment to the LM com-
munity. We believe there are no ethical concerns
associated with our research.
References
Satanjeev Banerjee and Alon Lavie. 2005. METEOR:
An automatic metric for MT evaluation with im-
proved correlation with human judgments. In Pro-
ceedings of the ACL Workshop on Intrinsic and Ex-
trinsic Evaluation Measures for Machine Transla-
tion and/or Summarization , pages 65–72, Ann Arbor,
Michigan. Association for Computational Linguis-
tics.
Steven Bird, Ewan Klein, and Edward Loper. 2009. Nat-
ural language processing with Python: analyzing text
with the natural language toolkit . " O’Reilly Media,
Inc.".
Glenn W Brier. 1950. Verification of forecasts ex-
pressed in terms of probability. Monthly weather
review , 78(1):1–3.
Chao Chen, Kai Liu, Ze Chen, Yi Gu, Yue Wu,
Mingyuan Tao, Zhihang Fu, and Jieping Ye. 2024.
INSIDE: LLMs’ internal states retain the power of
hallucination detection. In The Twelfth International
Conference on Learning Representations .
Jiuhai Chen and Jonas Mueller. 2023. Quantifying un-
certainty in answers from any language model via
intrinsic and extrinsic confidence assessment. arXiv
preprint arXiv:2308.16175 .
Arman Cohan, Franck Dernoncourt, Doo Soon Kim,
Trung Bui, Seokhwan Kim, Walter Chang, and Nazli
Goharian. 2018. A discourse-aware attention model
for abstractive summarization of long documents.Morris H DeGroot and Stephen E Fienberg. 1983. The
comparison and evaluation of forecasters. Journal of
the Royal Statistical Society: Series D (The Statisti-
cian) , 32(1-2):12–22.
Janez Demšar. 2006. Statistical comparisons of classi-
fiers over multiple data sets. The Journal of Machine
learning research , 7:1–30.
Yarin Gal and Zoubin Ghahramani. 2016. Dropout as a
bayesian approximation: Representing model uncer-
tainty in deep learning. In international conference
on machine learning , pages 1050–1059. PMLR.
Tilmann Gneiting and Adrian E Raftery. 2007. Strictly
proper scoring rules, prediction, and estimation.
Journal of the American statistical Association ,
102(477):359–378.
Chuan Guo, Geoff Pleiss, Yu Sun, and Kilian Q Wein-
berger. 2017. On calibration of modern neural net-
works. In International conference on machine learn-
ing, pages 1321–1330. PMLR.
Kartik Gupta, Amir Rahimi, Thalaiyasingam Ajan-
than, Thomas Mensink, Cristian Sminchisescu, and
Richard Hartley. 2021. Calibration of neural net-
works using splines. In International Conference on
Learning Representations .
Frank E Harrell. 2015. Regression modeling strategies
with applications to linear models, logistic and ordi-
nal regression, and survival analysis.
Pengcheng He, Xiaodong Liu, Jianfeng Gao, and
Weizhu Chen. 2021. Deberta: Decoding-enhanced
bert with disentangled attention.
Matthew Honnibal and Ines Montani. 2017. spaCy 2:
Natural language understanding with Bloom embed-
dings, convolutional neural networks and incremental
parsing.
Xinmeng Huang, Shuo Li, Edgar Dobriban, Osbert
Bastani, Hamed Hassani, and Dongsheng Ding.
2024. One-shot safety alignment for large lan-
guage models via optimal dualization. arXiv preprint
arXiv:2405.19544 .
Siddhartha Jain, Ge Liu, Jonas Mueller, and David Gif-
ford. 2020. Maximizing overall diversity for im-
proved uncertainty estimates in deep ensembles. In
Proceedings of the AAAI conference on artificial in-
telligence , volume 34, pages 4264–4271.
Fred Jelinek, Robert L Mercer, Lalit R Bahl, and
James K Baker. 1977. Perplexity—a measure of the
difficulty of speech recognition tasks. The Journal of
the Acoustical Society of America , 62(S1):S63–S63.
Mandar Joshi, Eunsol Choi, Daniel Weld, and Luke
Zettlemoyer. 2017. TriviaQA: A large scale distantly
supervised challenge dataset for reading comprehen-
sion. In Proceedings of the 55th Annual Meeting of
the Association for Computational Linguistics (Vol-
ume 1: Long Papers) , pages 1601–1611, Vancouver,
Canada. Association for Computational Linguistics.
10Saurav Kadavath, Tom Conerly, Amanda Askell, Tom
Henighan, Dawn Drain, Ethan Perez, Nicholas
Schiefer, Zac Hatfield-Dodds, Nova DasSarma, Eli
Tran-Johnson, et al. 2022. Language models
(mostly) know what they know. arXiv preprint
arXiv:2207.05221 .
Lorenz Kuhn, Yarin Gal, and Sebastian Farquhar. 2023.
Semantic uncertainty: Linguistic invariances for un-
certainty estimation in natural language generation.
InThe Eleventh International Conference on Learn-
ing Representations .
Meelis Kull, Miquel Perello Nieto, Markus Kängsepp,
Telmo Silva Filho, Hao Song, and Peter Flach.
2019. Beyond temperature scaling: Obtaining well-
calibrated multi-class probabilities with dirichlet cal-
ibration. Advances in neural information processing
systems , 32.
Ananya Kumar, Percy S Liang, and Tengyu Ma. 2019.
Verified uncertainty calibration. Advances in Neural
Information Processing Systems , 32.
Tom Kwiatkowski, Jennimaria Palomaki, Olivia Red-
field, Michael Collins, Ankur Parikh, Chris Alberti,
Danielle Epstein, Illia Polosukhin, Jacob Devlin, Ken-
ton Lee, Kristina Toutanova, Llion Jones, Matthew
Kelcey, Ming-Wei Chang, Andrew M. Dai, Jakob
Uszkoreit, Quoc Le, and Slav Petrov. 2019. Natu-
ral questions: A benchmark for question answering
research. Transactions of the Association for Compu-
tational Linguistics , 7:452–466.
Balaji Lakshminarayanan, Alexander Pritzel, and
Charles Blundell. 2017. Simple and scalable pre-
dictive uncertainty estimation using deep ensembles.
Advances in neural information processing systems ,
30.
Donghwan Lee, Xinmeng Huang, Hamed Hassani, and
Edgar Dobriban. 2023. T-cal: An optimal test for the
calibration of predictive models. Journal of Machine
Learning Research , 24(335):1–72.
Shiyu Liang, Yixuan Li, and R. Srikant. 2018. Enhanc-
ing the reliability of out-of-distribution image detec-
tion in neural networks. In International Conference
on Learning Representations .
Sarah Lichtenstein, Baruch Fischhoff, and Lawrence D
Phillips. 1977. Calibration of probabilities: The state
of the art. In Decision Making and Change in Human
Affairs: Proceedings of the Fifth Research Confer-
ence on Subjective Probability, Utility, and Decision
Making, Darmstadt, 1–4 September, 1975 , pages 275–
324. Springer.
Chin-Yew Lin. 2004. ROUGE: A package for auto-
matic evaluation of summaries. In Text Summariza-
tion Branches Out , pages 74–81, Barcelona, Spain.
Association for Computational Linguistics.
Stephanie Lin, Jacob Hilton, and Owain Evans. 2022.
Teaching models to express their uncertainty in
words. Transactions on Machine Learning Research .Zhen Lin, Shubhendu Trivedi, and Jimeng Sun. 2023.
Generating with confidence: Uncertainty quantifica-
tion for black-box large language models.
Andrey Malinin and Mark Gales. 2021. Uncertainty
estimation in autoregressive structured prediction. In
International Conference on Learning Representa-
tions .
Potsawee Manakul, Adian Liusie, and Mark JF Gales.
2023. Selfcheckgpt: Zero-resource black-box hal-
lucination detection for generative large language
models. arXiv preprint arXiv:2303.08896 .
Meta. 2023. Llama access request form -
meta ai. https://ai.meta.com/resources/
models-and-libraries/llama-downloads/ .
(Accessed on 12/13/2023).
Sabrina J Mielke, Arthur Szlam, Emily Dinan, and Y-
Lan Boureau. 2022. Reducing conversational agents’
overconfidence through linguistic calibration. Trans-
actions of the Association for Computational Linguis-
tics, 10:857–872.
Jacob A Mincer and Victor Zarnowitz. 1969. The evalu-
ation of economic forecasts. In Economic forecasts
and expectations: Analysis of forecasting behavior
and performance , pages 3–46. NBER.
Mahdi Pakdaman Naeini, Gregory Cooper, and Milos
Hauskrecht. 2015. Obtaining well calibrated proba-
bilities using bayesian binning. In Proceedings of the
AAAI conference on artificial intelligence , volume 29.
Alexandru Niculescu-Mizil and Rich Caruana. 2005.
Predicting good probabilities with supervised learn-
ing. In International Conference on Machine Learn-
ing, pages 625–632.
Jeremy Nixon, Michael W Dusenberry, Linchuan Zhang,
Ghassen Jerfel, and Dustin Tran. 2019. Measuring
calibration in deep learning. In CVPR workshops ,
volume 2.
OpenAI. 2023. Gpt-4 technical report.
Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Car-
roll L. Wainwright, Pamela Mishkin, Chong Zhang,
Sandhini Agarwal, Katarina Slama, Alex Ray, John
Schulman, Jacob Hilton, Fraser Kelton, Luke Miller,
Maddie Simens, Amanda Askell, Peter Welinder,
Paul Christiano, Jan Leike, and Ryan Lowe. 2022.
Training language models to follow instructions with
human feedback.
Georgios Papadopoulos, Peter J Edwards, and Alan F
Murray. 2001. Confidence estimation methods for
neural networks: A practical comparison. IEEE
transactions on neural networks , 12(6):1278–1287.
Nicolas Papernot and Patrick McDaniel. 2018. Deep
k-nearest neighbors: Towards confident, inter-
pretable and robust deep learning. arXiv preprint
arXiv:1803.04765 .
11Adam Paszke, Sam Gross, Francisco Massa, Adam
Lerer, James Bradbury, Gregory Chanan, Trevor
Killeen, Zeming Lin, Natalia Gimelshein, Luca
Antiga, Alban Desmaison, Andreas Kopf, Edward
Yang, Zachary DeVito, Martin Raison, Alykhan Te-
jani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang,
Junjie Bai, and Soumith Chintala. 2019. Pytorch:
An imperative style, high-performance deep learning
library. In Advances in Neural Information Process-
ing Systems 32 , pages 8024–8035. Curran Associates,
Inc.
Gustavo Penha and Claudia Hauff. 2021. On the cal-
ibration and uncertainty of neural learning to rank
models for conversational search. In Proceedings
of the 16th Conference of the European Chapter of
the Association for Computational Linguistics: Main
Volume , pages 160–170.
John Platt. 1999. Probabilistic outputs for support vec-
tor machines and comparisons to regularized likeli-
hood methods. Advances in large margin classifiers ,
10(3):61–74.
Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and
Percy Liang. 2016. Squad: 100,000+ questions for
machine comprehension of text.
Nils Reimers and Iryna Gurevych. 2019. Sentence-bert:
Sentence embeddings using siamese bert-networks.
Carlos Riquelme, George Tucker, and Jasper Snoek.
2018. Deep bayesian bandits showdown: An em-
pirical comparison of bayesian deep networks for
thompson sampling. In International Conference on
Learning Representations .
Leonard J Savage. 1971. Elicitation of personal prob-
abilities and expectations. Journal of the American
Statistical Association , 66(336):783–801.
Chenglei Si, Chen Zhao, Sewon Min, and Jordan
Boyd-Graber. 2022. Re-examining calibration:
The case of question answering. arXiv preprint
arXiv:2205.12507 .
Sree Harsha Tanneru, Chirag Agarwal, and Himabindu
Lakkaraju. 2023. Quantifying uncertainty in natu-
ral language explanations of large language models.
arXiv preprint arXiv:2311.03533 .
Katherine Tian, Eric Mitchell, Allan Zhou, Archit
Sharma, Rafael Rafailov, Huaxiu Yao, Chelsea Finn,
and Christopher Manning. 2023. Just ask for cali-
bration: Strategies for eliciting calibrated confidence
scores from language models fine-tuned with human
feedback. In Proceedings of the 2023 Conference on
Empirical Methods in Natural Language Processing ,
pages 5433–5442.
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier
Martinet, Marie-Anne Lachaux, Timothée Lacroix,
Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal
Azhar, et al. 2023a. Llama: Open and effi-
cient foundation language models. arXiv preprint
arXiv:2302.13971 .Hugo Touvron, Louis Martin, Kevin Stone, Peter Al-
bert, Amjad Almahairi, Yasmine Babaei, Nikolay
Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti
Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton
Ferrer, Moya Chen, Guillem Cucurull, David Esiobu,
Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller,
Cynthia Gao, Vedanuj Goswami, Naman Goyal, An-
thony Hartshorn, Saghar Hosseini, Rui Hou, Hakan
Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa,
Isabel Kloumann, Artem Korenev, Punit Singh Koura,
Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Di-
ana Liskovich, Yinghai Lu, Yuning Mao, Xavier Mar-
tinet, Todor Mihaylov, Pushkar Mishra, Igor Moly-
bog, Yixin Nie, Andrew Poulton, Jeremy Reizen-
stein, Rashi Rungta, Kalyan Saladi, Alan Schelten,
Ruan Silva, Eric Michael Smith, Ranjan Subrama-
nian, Xiaoqing Ellen Tan, Binh Tang, Ross Tay-
lor, Adina Williams, Jian Xiang Kuan, Puxin Xu,
Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan,
Melanie Kambadur, Sharan Narang, Aurelien Ro-
driguez, Robert Stojnic, Sergey Edunov, and Thomas
Scialom. 2023b. Llama 2: Open foundation and
fine-tuned chat models.
Alexandre B Tsybakov. 2009. Introduction to Nonpara-
metric Estimation . Springer.
Padma Jyothi Uppalapati, Madhavi Dabbiru,
·K. Venkata Rao, Omer F. Rana, Rajiv Misra,
Alexander Pfeiffer, Luigi Troiano, Nishtha Kesswani,
and K. Venkata Rao. 2023. A comprehensive survey
on summarization techniques. SN Computer Science ,
4:1–9.
Lucy Lu Wang, Kyle Lo, Yoganand Chandrasekhar,
Russell Reas, Jiangjiang Yang, Doug Burdick, Darrin
Eide, Kathryn Funk, Yannis Katsis, Rodney Michael
Kinney, Yunyao Li, Ziyang Liu, William Merrill,
Paul Mooney, Dewey A. Murdick, Devvret Rishi,
Jerry Sheehan, Zhihong Shen, Brandon Stilson,
Alex D. Wade, Kuansan Wang, Nancy Xin Ru Wang,
Christopher Wilhelm, Boya Xie, Douglas M. Ray-
mond, Daniel S. Weld, Oren Etzioni, and Sebastian
Kohlmeier. 2020. CORD-19: The COVID-19 open
research dataset. In Proceedings of the 1st Work-
shop on NLP for COVID-19 at ACL 2020 , Online.
Association for Computational Linguistics.
Laura Weidinger, John Mellor, Maribeth Rauh, Conor
Griffin, Jonathan Uesato, Po-Sen Huang, Myra
Cheng, Mia Glaese, Borja Balle, Atoosa Kasirzadeh,
et al. 2021. Ethical and social risks of harm from
language models. arXiv preprint arXiv:2112.04359 .
Robert L Winkler, Javier Munoz, José L Cervera,
José M Bernardo, Gail Blattenberger, Joseph B
Kadane, Dennis V Lindley, Allan H Murphy,
Robert M Oliver, and David Ríos-Insua. 1996. Scor-
ing rules and the evaluation of probabilities. Test,
5:1–60.
Thomas Wolf, Lysandre Debut, Victor Sanh, Julien
Chaumond, Clement Delangue, Anthony Moi, Pier-
ric Cistac, Tim Rault, Rémi Louf, Morgan Funtow-
icz, Joe Davison, Sam Shleifer, Patrick von Platen,
12Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu,
Teven Le Scao, Sylvain Gugger, Mariama Drame,
Quentin Lhoest, and Alexander M. Rush. 2020. Hug-
gingface’s transformers: State-of-the-art natural lan-
guage processing.
Yijun Xiao and William Yang Wang. 2021. On halluci-
nation and predictive uncertainty in conditional lan-
guage generation. arXiv preprint arXiv:2103.15025 .
Miao Xiong, Zhiyuan Hu, Xinyang Lu, YIFEI LI, Jie
Fu, Junxian He, and Bryan Hooi. 2024. Can LLMs
express their uncertainty? an empirical evaluation of
confidence elicitation in LLMs. In The Twelfth Inter-
national Conference on Learning Representations .
Bianca Zadrozny and Charles Elkan. 2001. Obtain-
ing calibrated probability estimates from decision
trees and naive bayesian classifiers. In Intertional
Conference on Machine Learning , volume 1, pages
609–616.
Bianca Zadrozny and Charles Elkan. 2002. Transform-
ing classifier scores into accurate multiclass proba-
bility estimates. In Proceedings of the eighth ACM
SIGKDD international conference on Knowledge dis-
covery and data mining , pages 694–699.
Caiqi Zhang, Fangyu Liu, Marco Basaldella, and Nigel
Collier. 2024. Luq: Long-text uncertainty quantifica-
tion for llms. arXiv preprint arXiv:2403.20279 .
Zihao Zhao, Eric Wallace, Shi Feng, Dan Klein, and
Sameer Singh. 2021. Calibrate before use: Improv-
ing few-shot performance of language models. In In-
ternational Conference on Machine Learning , pages
12697–12706. PMLR.
13A Additional Related Work
Uncertainty measures in supervised learning. The quantification of uncertainties in model outputs in
supervised learning has a long history ( e.g., Lichtenstein et al., 1977, etc). Overparametrized models such
as neural networks pose unique challenges to estimate uncertainty and improve model calibration(Guo
et al., 2017; Papadopoulos et al., 2001; Riquelme et al., 2018). Various approaches have been introduced
to mimic Bayesian inference (Gal and Ghahramani, 2016), to utilize simple deep ensembles (Lakshmi-
narayanan et al., 2017; Jain et al., 2020), and to identify training samples that are out-of-distribution (Liang
et al., 2018; Papernot and McDaniel, 2018). Nonetheless, it is not clear how to adapt these strategies to
language modeling, where the output can be text with complex structure.
Uncertainty measures in language modeling. To gauge the uncertainty level associated with the
outputs of LMs, Kuhn et al. (2023) introduces the concept of semantic entropy, which integrates linguistic
consistencies stemming from shared meanings. In a similar vein, Kadavath et al. (2022); Lin et al. (2022);
Xiong et al. (2024) encourage LMs to analyze their own responses and come up with a “probability”
that a response is correct. In related work, Manakul et al. (2023) uses sampling to identify instances of
fabricated information. Recently, Tian et al. (2023) explore methods for deriving confidence measures for
reinforcement-learning-trained LMs. Lin et al. (2023) draw a distinction between estimating uncertainty
and confidence for LMs. Similarly, Chen and Mueller (2023) introduce a method for detecting bad and
speculative responses from a pre-trained LM with a confidence score. Tanneru et al. (2023) propose two
novel measures to quantify the uncertainty of LM-generated explanations. Although considerable research
focuses on developing uncertainty and confidence measures for LMs, the evaluation of their effectiveness
is less studied.
Assessments of uncertainty measures. Early assessment of confidence measures in classification
scenarios leveraged proper scoring rules (Savage, 1971; DeGroot and Fienberg, 1983; Gneiting and
Raftery, 2007), such as the Brier score (Brier, 1950) and the KL divergence (Winkler et al., 1996). Other
assessments include plotting calibration curves, also known as reliability diagrams (estimated probabilities
against predicted ones) (Harrell, 2015). More recently, the ECE metric—or mean absolute calibration
error—has gained popularity in machine learning (Harrell, 2015; Naeini et al., 2015), along with many
variants (Kumar et al., 2019; Nixon et al., 2019; Gupta et al., 2021; Lee et al., 2023; Si et al., 2022).
In the realm of uncertainty quantification for LMs, the assessment based on ECE remains viable.
However, it necessitates the introduction of ad hoc threshold to derive binary labels. Moreover, the
applicability of ECE is limited, as it does not directly apply to LM uncertainty measures that fall outside
the interval [0,1]. Our work introduces an assessment centered around rank-calibration, a critical property
that ideal uncertainty measures should satisfy. This assessment is applicable to both confidence and
uncertainty measures and eliminates the need for thresholding the correctness values.
B Common Uncertainty/Confidence Measures for LMs
In this section, we introduce common measures of uncertainty and confidence in detail.
•NLL & Perplexity. Letby= (byℓ)ℓ≥1be the generated response. Then the Negative Log-Likelihood
(NLL) is
UNLL(x,by) :=−ln(P(by|x)) =−X
ℓ≥1ln(P(byℓ|x,by<ℓ)).
A natural extension accounts for the variable length of responses by applying length normalization.
Suppose that the number of tokens of the response byislen(by), the length-normalized NLL is defined
as
UNLL -LN(x,by) :=−1
len(by)len(by)X
ℓ=1ln(P(byℓ|x,by<ℓ)).
Roughly speaking, this can be viewed as the average nats per token in the generated text; if using log2
instead of ln, it would be the average bits per token. The exponential of the length-normalized NLL is
14known as the Perplexity: UPerp(x;by) := exp( UNLL -LN(x,by))(Jelinek et al., 1977). The perplexity
can also be viewed as the inverse of the geometric mean of the token-wise probabilities.
•Entropy. Entropy is a well-known type of uncertainty measure. The predictive entropy of the
distribution P(· |x)is defined as
UE(x) :=−Eby∼P(·|x)[ln(P(by|x))].
Entropy gauges the information one has about the potential output given the input, and has high
values when outputs are diverse. Malinin and Gales (2021) propose a variant UE-LN(x)using the
length-normalized log-likelihood ln(P(by|x))/Length( by). Kuhn et al. (2023) argues that responses
with an identical meaning should be viewed as equal; even if they differ at the token level. They thus
propose the semantic entropy
USE(x) :=−Eby∼P(·|x)[ln(P(c(by)|x))],
where c(by)is a semantic concept of output by, as determined by another machine learning method. We
can similarly define the length-normalized semantic entropy as
USE-LN(x) :=Eby∼P(·|x)[ln(P(c(by)|x))/len(by)].
•Affinity graph. Recently, Lin et al. (2023) use a weighted adjacency graph built upon semantic
affinities between outputs to reflect uncertainty. Given an entailment-contradiction affinity model e
that maps pairs by,by′of responses to values in [0,1],einduces a symmetric adjacency matrix W=
[wi,j]K
i,j=1with responses {by(k)}K
k=1sampled from P(·|x), where for all i, j,wi,j=(e(by(i);by(j)) +
e(by(j);by(i)))/2. Let D= [1[j=i]PK
k=1wk,j]K
i,j=1be the matrix of degrees and {λk}K
k=1be the
eigenvalues of the Laplacian L=I−D−1/2WD−1/2. Measures proposed in Lin et al. (2023) include
UEigV(x) :=KX
k=1max{0,1−λk},
UDeg(x) := 1 −trace( D)/K2, C Deg(x;by(i)) :=Di,i/K,
UEcc(x) :=∥[v1,v2, . . . ,vK]∥2.
where {vk}K
k=1are certain centralized vectors associated with the spectral decomposition of L. Here,
UEigV(x)is approximates the number of connected components in the graph represented by W, while
UDeg(x)andUEcc(x)reflect the diversity of outputs.
•Verbalized confidence. Verbalized confidence generally refers to the textual confidence output by an
LM. For example, if an LM is highly uncertain about its answer, it may inform the user by saying, e.g.,
“I am only 20% confident in this answer.” This is often implemented by feeding handcrafted prompts
to advanced LMs such as GPT-4 (OpenAI, 2023). Many prompting strategies have been used in the
literature to enhance this procedure (Zhao et al., 2021; Kadavath et al., 2022; Lin et al., 2022; Xiong
et al., 2024). Since optimizing the prompting strategy is not our focus and we do not want confidence
elicitation to interfere with the generation of responses, we adopt a simple post-hoc strategy here by
feeding a query-response pair to an LM and asking it how confident it believes the response correctly
addresses the query. This post-hoc strategy is similar to the one used by Kadavath et al. (2022). We
use the following specific prompt format:
Read the question and answer below.
{question} {generation}
Provide a numeric confidence that indicates your certainty about
this answer.
For instance, if your confidence level is 80%, it means you are 80%
15certain that this answer is correct and there is a 20% chance that
it is incorrect.
Use the following format to provide your confidence: Confidence:
[Your confidence, a numerical number in the range of 0-100]%."
C Common Evaluation Metrics
In this section, we review evaluation metrics that have been commonly used to assess LM uncer-
tainty/confidence measures. These metrics usually require binary correctness values.
•AUROC. AUROC refers to the area under the Receiver-Operating Curve (ROC). The ROC plots
the true positive rate (a.k.a. recall) against the false positive rate (a.k.a. 1−specificity) at various
thresholds of uncertainty levels. The true positive rate is on the y-axis, and the false positive rate is on
thex-axis. An AUROC value of 1may represent a perfect uncertainty measure; a value of 0.5suggests
no discriminative ability (equivalent to random uncertainty levels). The AUROC can be more useful
for evaluation in imbalanced scenarios where correct responses are much more (or less) frequent than
incorrect responses.
•AUPRC. AUPRC refers to the area under the Precision-Recall Curve (PRC), which plots the positive
predictive value (a.k.a. precision) against the true positive rate (a.k.a. recall) at various threshold
settings. Precision is on the y-axis, and recall is on the x-axis. Similar to AUROC, it is valuable in
imbalanced dataset scenarios but focuses more on the performance of the positive (minority) class ( i.e.,
correct responses). Variants of AURPC include AUPRC-Positive and AUPRC-Negative, which focus
on gauging the ability of uncertainty measures to identify correct responses and incorrect responses,
respectively.
•AUARC. AUARC refers to the area under the Accuracy-Rejection Curve (ARC) that plots the accuracy
of generation against a rejection rate (the proportion of generated responses for which the model
abstains from making a prediction). The curve shows how the accuracy of generation improves as
it is allowed to reject uncertain responses. A higher AUARC value means that an LM can generate
more correct responses as it increasingly avoids uncertain (based on the level of specific uncertainty
measures) cases. This metric is useful for evaluating uncertainty measures in scenarios where LMs can
defer responses for which they are not confident.
•ECE. ECE stands for the expected calibration error, a metric used to evaluate the calibration of
confidence measures, particularly in classification tasks. Calibration refers to how well the confidence
levels align with the actual proportion of correct generation. For an ideally calibrated confidence
measure, if the confidence level is 70%, then approximately 70% of generated responses should
be correct. ECE quantifies the difference between the confidence levels and the realized correct
proportion. A lower ECE indicates better calibration, meaning the confidence measure is more
reflective of the actual correct proportion. A confidence measure with an ECE close to zero is
considered well-calibrated.
D Proof of Proposition 1
Case 1. α= 1/2.Consider the continuous case C∼Unif[1 /2−β,1/2 +β]andreg(C)≡1/2 +β
almost surely ( i.e.,A∼Bernoulli(1 /2+β)). Then PC′(reg(C′)≥reg(C))≡1for almost surely. Since
Cis continuous-valued, PC′follows the uniform distribution over [0,1]. We thus have
RCE =Z1
0|1−p|dp=1
2.
On the other hand,
ECE =Z1/2+β
1/2−β|1/2 +β−c|
2βdc=β.
16Case 2. α∈(0,1/2).Consider the case reg(C)≡1/2 +βalmost surely. We construct the marginal
distribution of Cas follows. Let P(C=ck) =pkfor1≤k≤KwithK≥(1−2α)−1. Here
p1=···=pK−1=pwhile pK= 1−(K−1)pwhere pis the non-negative root of (K−1)p2+ (1−
(K−1)p)2= 1−2α. Since K≥(1−2α)−1, such p∈(0,(K−1)−1]exists. Moreover, we let {ck}K
k=1
satisfy 0≤c1<···< cK−1≤1/2 +β,ck+cK−k≡1withck̸= 1/2for all 1≤k < K ,cK= 1/2.
Then, by definition, we can calculate
RCE =KX
k=1pk
1−X
ℓ≥kpℓ
=X
1≤ℓ<k≤Kpkpℓ
=PK
k=1pk2
−PK
k=1p2
k
2=1−PK
k=1p2
k
2=α.
On the other hand, we have
ECE =KX
k=11
2+β−ckpk=β+1
2−KX
k=1ckpk=β.
This finishes the proof.
E Additional Experiment Details
E.1 Model Setup
Following Lin et al. (2023), we set the temperature to 0.6 for the two Llama-2 models and 1.0 for the GPT
model. We quantize the two Llama-2 models to 16 bits. To ablate the influence of temperature, we also
use generated responses of Llama-2-7b-chat with temperature 1.0.
E.2 Datasets
Dataset Descriptions. TriviaQA is a challenging reading comprehension dataset, containing question-
answer pairs whose answers can be found on Wikipedia and the web. Similar to previous works, we use
TriviaQA as an open-domain QA benchmark. Natural Question is a question-answering dataset containing
questions issued to the Google search engine. We use Natural Questions as an open-domain QA benchmark.
SQuAD-1 is a reading comprehension dataset containing questions posed by crowdworkers based on
Wikipedia articles. We include SQuAD-1 as a reading comprehension benchmark, where the annotated
contexts are provided in the prompt. Meadow is created by research groups working on COVID-19
problems. We use this dataset for open-ended generation, where the LM is expected to provide a title for a
paper given the abstract of the paper. The correctness is justified by comparing the generated title to the
true title.
Dataset Setup. TriviaQA contains 11,322 data points, Natural Questions contains 3,600 data points,
SQuAD-1 contains 10,570 data points, and Meadow contains 1,000 data points. The prompt templates
used are similar to those in Kuhn et al. (2023); Lin et al. (2023), and are as follows:
TriviaQA: following from Lin et al. (2023), we use the exact same prompt used in Touvron et al. (2023a):
Answer these questions:
In Scotland, a bothy/bothie is a?
A: House
{question}
A:
Natural Question: Similar to Lin et al. (2023), we use an in-context learning prompt with five demonstra-
tions:
where are the fa cup semi finals played. [SEP] A: the new Wembley
Stadium.[SEP]
who was alf married to in home and away [SEP] A: Ailsa Stewart.[SEP]
17what is the name of the first book in the twilight series [SEP] A:
Twilight.[SEP]
when is tornado season in the united states [SEP] A: March through
June.[SEP]
where did the idea of a messiah come from [SEP] A: Judaism.[SEP]
question [SEP] A:
SQuAD-1: Each data point in SQuAD-1 is a (question, context, reference) triplet, where the context is
annotated to provide useful information to answer the question. We prompt SQuAD-1 using zero-shot
prompting:
Answer the following question based on the context.
{question}
Context: {context}
A:
Meadow: Each data point in Meadow is a (abstract, title) pair. We prompt Meadow using one-shot
prompting:
Abstract: Coronavirus disease 2019 (COVID-19) threatens vulnerable
patient populations, resulting in immense pressures at the local,
regional, national, and international levels to contain the virus.
Laboratory-based studies demonstrate that masks may offer benefits
in reducing the spread of droplet-based illnesses, but few data are
available to assess mask effects via executive order on a popula-
tion basis. We assess the effects of a county-wide mask order on
per-population mortality, intensive care unit (ICU) utilization, and
ventilator utilization in Bexar County, Texas. METHODS: We used pub-
licly reported county-level data to perform a mixed-methods before-
and-after analysis along with other sources of public data for anal-
yses of covariance. We used a least-squares regression analysis to
adjust for confounders. A Texas state-level mask order was issued on
July 3, 2020, followed by a Bexar County–level order on July 15, 2020.
We defined the control period as June 2 to July 2 and the postmask
order period as July 8, 2020–August 12, 2020, with a 5-day gap to ac-
count for the median incubation period for cases; longer periods of
7 and 10 days were used for hospitalization and ICU admission/death,
respectively. Data are reported on a per-100,000 population basis
using respective US Census Bureau–reported populations. RESULTS:
From June 2, 2020 through August 12, 2020, there were 40,771 reported
cases of COVID-19 within Bexar County, with 470 total deaths. The
average number of new cases per day within the county was 565.4 (95%
confidence interval [CI] 394.6–736.2). The average number of posi-
tive hospitalized patients was 754.1 (95% CI 657.2–851.0), in the ICU
was 273.1 (95% CI 238.2–308.0), and on a ventilator was 170.5 (95% CI
146.4–194.6). The average deaths per day was 6.5 (95% CI 4.4–8.6).
All of the measured outcomes were higher on average in the postmask
period as were covariables included in the adjusted model. When ad-
justing for traffic activity, total statewide caseload, public health
complaints, and mean temperature, the daily caseload, hospital bed
occupancy, ICU bed occupancy, ventilator occupancy, and daily mor-
tality remained higher in the postmask period. CONCLUSIONS: There
was no reduction in per-population daily mortality, hospital bed,
ICU bed, or ventilator occupancy of COVID-19-positive patients at-
tributable to the implementation of a mask-wearing mandate. [SEP]
Title: Analysis of the Effects of COVID-19 Mask Mandates on Hospital
18Resource Consumption and Mortality at the County Level [SEP]
Abstract: {abstract} [SEP]
Title:
E.3 Correctness Functions
Rouge score. Recall-Oriented Understudy for Gist Evaluation (Rouge) score has originally been
designed to evaluate machine translation or text summarization tasks. The Rouge score counts the
overlapping n-grams between generated reference texts. Widely used n-grams include unigrams (Rouge-
1), bigrams (Rouge-2), and the longest common subsequence (Rouge-L). Specifically, it is computed
through
ROUGE =|(n-gram ∈Generation )∩(n-gram )∈Reference |
|Reference |.
METEOR score. The Metric for Evaluation of Translation with Explicit Ordering (METEOR) score
has also been originally designed to evaluate machine translation and text summarization. Different from
the Rouge score, the METEOR score considers the accuracy and fluency of the generation, as well as
word order. The calculation of the METEOR score can be found in Banerjee and Lavie (2005).
BERT-similarity. The BERT-similarity is based on sentence-bert (Reimers and Gurevych, 2019).
Specifically, in the first step, reference and generation texts are encoded as 768-dimensional feature
vectors, respectively. Then, the correctness values are computed by calculating the cosine similarity
between reference and generation vectors. In our implementation, we use sentence-Bert with bert-nli-
mean-tokens pre-trained weights as the encoding model.
ChatGPT evaluation. ChatGPT evaluation is calculated by prompting GPT-3.5-turbo with the question,
reference, and generation; and asking it to evaluate the correctness of the generation. The template used
in calculating ChatGPT correctness follows that in Lin et al. (2023):
Rate the level of consistency between the answer to the question and
the reference answer, from 0 to 100.
Question: In Scotland a bothy/bothie is a?
Reference: House
Answer: House
Rating: 100.
Question: Where in England was Dame Judi Dench born?
Reference: York
Answer: London
Rating: 0.
Question: {question}
Reference: {reference}
Answer: {generated}
Rating:
E.4 Inconsistency due to Correctness Thresholding
We provide more evidence to show the inconsistency of AUARC and AUPRC metrics caused by the ad
hoc correctness thresholding. The plots are in Fig 5, 6, 7, 8, and 9.
190.0 0.2 0.4 0.6 0.8 1.0
Threshold0.00.20.40.60.81.0AUARCUEigV
UEcc
UDeg
USE
UNLL
CVerb
0.0 0.2 0.4 0.6 0.8 1.0
Threshold0.00.20.40.60.81.0AUPRCUEigV
UEcc
UDeg
USE
UNLL
CVerbFigure 5: The assessed results for AUARC (left) andAUPRC (right) of uncertainty/confidence measures for GPT-
3.5-turbo on the TriviaQA benchmark using the METEOR correctness score with varying thresholds.
0.0 0.2 0.4 0.6 0.8
Threshold0.450.500.550.600.650.700.750.80AUROCUEigV
UEcc
UDeg
USE
UNLL
CVerb
(a) AUROC
0.00 0.25 0.50 0.75 1.00
Threshold0.00.20.40.60.81.0AUARCUEigV
UEcc
UDeg
USE
UNLL
CVerb (b) AUARC
0.00 0.25 0.50 0.75 1.00
Threshold0.00.20.40.60.81.0AUPRCUEigV
UEcc
UDeg
USE
UNLL
CVerb (c) AUPRC
EigVEccDegSENLLVerb
Uncertainty/Confidence Measure05000100001500020000Output RangesUEigV
UEcc
UDeg
USE
UNLL
CVerb (d) Output ranges
Figure 6: Results for Meadow using GPT-3.5-turbo and the Rouge score.
0.0 0.5 1.0
Threshold0.700.750.800.850.90AUROC
(a) AUROC
0.0 0.5 1.0
Threshold0.750.800.850.900.951.00AUARCUEigV
UEcc
UDeg
USE
UNLL (b) AUARC
0.0 0.5 1.0
Threshold0.800.850.900.951.00AUPRCUEigV
UEcc
UDeg
USE
UNLL (c) AUPRC
EigVEcc DegSENLL
Uncertainty/Confidence Measure12345Output Ranges1e6
UEigV
UEcc
UDeg
USE
UNLL (d) Output ranges
Figure 7: Results for TriviaQA using GPT-3.5-turbo with temperature 1.5 and the bert-similarity metric.
0.0 0.5 1.0
Threshold0.6750.7000.7250.7500.7750.8000.825AUROC
(a) AUROC
0.0 0.5 1.0
Threshold0.650.700.750.800.85AUARCUEigV
UEcc
UDeg
USE
UNLL (b) AUARC
0.0 0.5 1.0
Threshold0.740.760.780.800.82AUPRCUEigV
UEcc
UDeg
USE
UNLL (c) AUPRC
EigVEcc DegSENLL
Uncertainty/Confidence Measure0100200300400500Output RangesUEigV
UEcc
UDeg
USE
UNLL (d) Output ranges
Figure 8: Results for TriviaQA using Llama-2-7b-chat and the Rouge score.
20Model Dataset Correctness Temperature UEcc UDeg UEigV UNLL USE CVerb
Llama-2nq-openbert 0.6 0.302 ±0.044 0.044 ±0.011 0.046 ±0.007 0.121 ±0.016 0.122 ±0.025 nan
meteor 0.6 0.293 ±0.027 0.072 ±0.010 0.077 ±0.015 0.167 ±0.021 0.137 ±0.024 nan
rougeL 0.6 0.297 ±0.039 0.058 ±0.010 0.051 ±0.010 0.147 ±0.021 0.124 ±0.019 nan
rouge1 0.6 0.297 ±0.038 0.057 ±0.011 0.051 ±0.010 0.148 ±0.021 0.124 ±0.020 nan
squadbert 0.6 0.308 ±0.041 0.071 ±0.013 0.064 ±0.013 0.072 ±0.008 0.181 ±0.027 nan
meteor 0.6 0.299 ±0.049 0.252 ±0.027 0.247 ±0.029 0.419 ±0.018 0.407 ±0.024 nan
rougeL 0.6 0.359 ±0.045 0.139 ±0.033 0.150 ±0.027 0.187 ±0.028 0.332 ±0.036 nan
rouge1 0.6 0.360 ±0.044 0.141 ±0.034 0.150 ±0.027 0.195 ±0.032 0.337 ±0.035 nan
triviaqabert 0.6 0.312 ±0.052 0.020 ±0.005 0.028 ±0.007 0.244 ±0.012 0.061 ±0.008 nan
meteor 0.6 0.305 ±0.048 0.041 ±0.007 0.049 ±0.010 0.271 ±0.020 0.052 ±0.007 nan
rougeL 0.6 0.305 ±0.050 0.026 ±0.005 0.033 ±0.006 0.206 ±0.020 0.051 ±0.007 nan
rouge1 0.6 0.307 ±0.049 0.026 ±0.005 0.034 ±0.006 0.209 ±0.019 0.052 ±0.007 nan
Llama-2-chatnq-openbert0.6 0.199 ±0.040 0.046 ±0.008 0.052 ±0.010 0.101 ±0.015 0.062 ±0.010 nan
1.0 0.236 ±0.033 0.035 ±0.008 0.038 ±0.007 0.097 ±0.017 0.055 ±0.012 nan
meteor0.6 0.190 ±0.039 0.062 ±0.008 0.067 ±0.010 0.176 ±0.018 0.072 ±0.009 nan
1.0 0.224 ±0.034 0.044 ±0.006 0.046 ±0.007 0.209 ±0.023 0.074 ±0.015 nan
rougeL0.6 0.198 ±0.039 0.053 ±0.011 0.057 ±0.010 0.167 ±0.013 0.060 ±0.012 nan
1.0 0.227 ±0.035 0.035 ±0.007 0.033 ±0.006 0.211 ±0.021 0.069 ±0.016 nan
rouge10.6 0.199 ±0.039 0.054 ±0.010 0.057 ±0.010 0.167 ±0.014 0.061 ±0.013 nan
1.0 0.227 ±0.035 0.034 ±0.007 0.033 ±0.006 0.212 ±0.021 0.069 ±0.015 nan
squadbert0.6 0.208 ±0.033 0.065 ±0.014 0.075 ±0.017 0.048 ±0.007 0.063 ±0.012 nan
1.0 0.276 ±0.039 0.067 ±0.011 0.063 ±0.010 0.038 ±0.006 0.098 ±0.012 nan
meteor0.6 0.216 ±0.038 0.303 ±0.026 0.265 ±0.022 0.063 ±0.013 0.182 ±0.029 nan
1.0 0.300 ±0.046 0.292 ±0.035 0.250 ±0.027 0.064 ±0.011 0.274 ±0.021 nan
rougeL0.6 0.239 ±0.036 0.177 ±0.026 0.143 ±0.020 0.052 ±0.011 0.127 ±0.020 nan
1.0 0.304 ±0.036 0.179 ±0.033 0.137 ±0.024 0.053 ±0.012 0.210 ±0.027 nan
rouge10.6 0.238 ±0.037 0.183 ±0.027 0.148 ±0.022 0.053 ±0.010 0.129 ±0.021 nan
1.0 0.303 ±0.035 0.185 ±0.033 0.143 ±0.025 0.053 ±0.012 0.213 ±0.026 nan
triviaqabert0.6 0.140 ±0.024 0.062 ±0.016 0.061 ±0.015 0.020 ±0.004 0.027 ±0.007 nan
1.0 0.213 ±0.030 0.025 ±0.006 0.034 ±0.006 0.014 ±0.002 0.036 ±0.006 nan
meteor0.6 0.145 ±0.027 0.067 ±0.017 0.064 ±0.015 0.034 ±0.009 0.075 ±0.016 nan
1.0 0.206 ±0.032 0.035 ±0.007 0.046 ±0.005 0.049 ±0.008 0.084 ±0.007 nan
rougeL0.6 0.141 ±0.021 0.062 ±0.014 0.061 ±0.014 0.024 ±0.005 0.034 ±0.005 nan
1.0 0.204 ±0.035 0.027 ±0.006 0.040 ±0.004 0.022 ±0.002 0.051 ±0.007 nan
rouge10.6 0.141 ±0.021 0.062 ±0.014 0.062 ±0.013 0.024 ±0.005 0.034 ±0.006 nan
1.0 0.203 ±0.035 0.027 ±0.006 0.040 ±0.004 0.022 ±0.002 0.051 ±0.007 nan
GPT-3.5meadowbert 1.0 0.284 ±0.035 0.178 ±0.030 0.174 ±0.025 0.112 ±0.022 0.177 ±0.027 0.288 ±0.033
meteor 1.0 0.292 ±0.045 0.134 ±0.027 0.137 ±0.026 0.074 ±0.012 0.132 ±0.018 0.263 ±0.050
rougeL 1.0 0.278 ±0.045 0.130 ±0.022 0.131 ±0.025 0.056 ±0.010 0.113 ±0.022 0.289 ±0.046
rouge1 1.0 0.290 ±0.047 0.126 ±0.018 0.135 ±0.020 0.059 ±0.013 0.113 ±0.018 0.299 ±0.047
nq-openbert 1.0 0.151 ±0.025 0.050 ±0.012 0.065 ±0.014 0.039 ±0.008 0.050 ±0.007 0.487 ±0.005
meteor 1.0 0.154 ±0.027 0.050 ±0.011 0.063 ±0.011 0.046 ±0.011 0.060 ±0.009 0.452 ±0.018
rougeL 1.0 0.151 ±0.022 0.048 ±0.011 0.062 ±0.012 0.034 ±0.009 0.052 ±0.008 0.487 ±0.006
rouge1 1.0 0.153 ±0.023 0.048 ±0.011 0.063 ±0.012 0.034 ±0.009 0.051 ±0.008 0.487 ±0.006
squadbert 1.0 0.204 ±0.025 0.237 ±0.024 0.240 ±0.019 0.065 ±0.012 0.113 ±0.013 0.181 ±0.029
meteor 1.0 0.181 ±0.012 0.151 ±0.016 0.193 ±0.020 0.054 ±0.017 0.086 ±0.014 0.182 ±0.032
rougeL 1.0 0.222 ±0.025 0.270 ±0.023 0.269 ±0.016 0.037 ±0.010 0.100 ±0.011 0.168 ±0.035
rouge1 1.0 0.226 ±0.024 0.276 ±0.023 0.270 ±0.017 0.039 ±0.010 0.103 ±0.011 0.168 ±0.035
triviaqabert0.5 0.215 ±0.042 0.212 ±0.040 0.212 ±0.041 0.043 ±0.006 0.052 ±0.009 nan
1.0 0.152 ±0.025 0.129 ±0.020 0.133 ±0.020 0.039 ±0.007 0.052 ±0.012 0.182 ±0.025
1.5 0.142 ±0.018 0.053 ±0.011 0.074 ±0.012 0.031 ±0.007 0.081 ±0.009 nan
meteor0.5 0.215 ±0.049 0.211 ±0.045 0.208 ±0.047 0.179 ±0.021 0.234 ±0.019 nan
1.0 0.156 ±0.026 0.131 ±0.024 0.131 ±0.022 0.146 ±0.011 0.209 ±0.012 0.194 ±0.036
1.5 0.137 ±0.024 0.059 ±0.011 0.077 ±0.012 0.119 ±0.010 0.176 ±0.015 nan
rougeL0.5 0.214 ±0.046 0.210 ±0.042 0.207 ±0.041 0.041 ±0.007 0.050 ±0.008 nan
1.0 0.151 ±0.024 0.126 ±0.019 0.129 ±0.019 0.038 ±0.007 0.059 ±0.009 0.181 ±0.026
1.5 0.138 ±0.025 0.059 ±0.012 0.079 ±0.011 0.034 ±0.008 0.104 ±0.007 nan
rouge10.5 0.216 ±0.046 0.212 ±0.043 0.209 ±0.042 0.040 ±0.007 0.050 ±0.008 nan
1.0 0.152 ±0.024 0.126 ±0.018 0.130 ±0.021 0.039 ±0.007 0.060 ±0.009 0.176 ±0.027
1.5 0.137 ±0.023 0.060 ±0.011 0.078 ±0.012 0.034 ±0.008 0.105 ±0.008 nan
Table 4: RCE results for various experimental configurations.
210.0 0.5 1.0
Threshold0.650.700.750.800.85AUROC(a) AUROC
0.0 0.5 1.0
Threshold0.850.900.95AUARCUEigV
UEcc
UDeg
USE
UNLL
CVerb (b) AUARC
0.0 0.5 1.0
Threshold0.6750.7000.7250.7500.7750.8000.825AUPRCUEigV
UEcc
UDeg
USE
UNLL (c) AUPRC
EigVEcc DegSENLL
Uncertainty/Confidence Measure02004006008001000Output RangesUEigV
UEcc
UDeg
USE
UNLL (d) Output ranges
Figure 9: Results for TriviaQA using Llama-2-7b-chat using temperature 1.0 and the Rouge score.
F Additional Experimental Results
Prompt Reference Generation P(UEcc≤u)P(UDeg≤u)P(UEigV≤u)P(USE≤u)P(UNLL≤u)
Q: Who did Dr. Crippen murder? his wife His wife 0.999 0.881 0.822 0.649 0.247
Q: What are the only two musical notes which have no flats? c and f B and F 0.999 0.761 0.769 0.898 0.691
Q: Which Eastenders actor has played the policeman Nick Rowan on TV? nick berry Mark Jordon 0.999 0.972 0.978 0.954 0.918
Q: Which ‘B‘ was the name of the mechanical shark used in the original ‘Jaws‘
film?bruce Bruce 0.999 0.761 0.769 0.337 0.183
Q: Which actor does the interviewing in ’Interview with a Vampire’? christian slater Brad Pitt 0.999 0.858 0.856 0.861 0.893
Q: What did my true love bring to me on the Sixth Day of Christmas? six geese-a-laying Six geese a-laying 0.999 0.761 0.769 0.736 0.688
Q: In January 1957, Russell Endean became the first batsman to be dismissed
from a test cricket match for doing what?handling the ball Handling the ball 0.999 0.761 0.769 0.901 0.368
Q: What are the first names of the two dancing instructors in the UK television
series ‘Hi De Hi’?barry and yvonne Barry and Yvonne 0.999 0.761 0.769 0.846 0.627
Q: Who became the host of the UK television game show Blankety Blank in
1984?les dawson Les Dawson 0.999 0.761 0.769 0.180 0.040
Q: How much, in pounds sterling, does the Best in Show Winner receive at the
annual Crufts Dog Show?100 pounds £100 0.999 0.920 0.908 0.830 0.787
Q: In the Billy Bunter stories, what is the surname of Bunter’s form teacher? quelch Quelch 0.999 0.761 0.769 0.999 0.558
Q: Which play is featured in the film The Producers? springtime for hitler Springtime for Hitler 0.999 0.761 0.769 0.967 0.341
Q: What provoked the war between Honduras and El Salvador in 1969? a football match A soccer match 0.999 0.761 0.769 0.535 0.711
Q: Which character was played by Linda Thorson in The Avengers? tara king Tara King 0.999 0.824 0.885 0.919 0.399
Q: According to a traditional English proverb, what is better than none? half a loaf A bad excuse 0.999 0.972 0.978 0.931 0.908
Q: In which Welsh village is there only one gay, apparently?! llandewi breffi Llanddewi Brefi 0.999 0.926 0.963 0.950 0.906
Q: On September 28th, NASA announced that what had been detected on Mars? flowing water Possible signs of life 0.999 0.965 0.963 0.813 0.930
Q: What are the first four words of the Bible, as recorded in Genesis? in the beginning god In the beginning, God 0.653 0.650 0.651 0.574 0.557
Q: Which national anthem was originally called the ’War Song for the Rhine
Army’?marsellaise German national anthem 0.694 0.858 0.837 0.785 0.888
Q: Name the UK budget holiday company specialising in Turkey and Greece
which went bust in July 2010?goldtrail Goldtrail 0.999 0.920 0.902 0.894 0.655
Q: Who has been President of France twice, but never been elected to the
position?alain poher François Mitterrand 0.999 0.920 0.902 0.854 0.864
Q: What is the name of Madonna’s proposed chain of fitness clubs? hard candy fitness Hard Candy Fitness 0.999 0.761 0.769 0.996 0.183
Q: Elvis Presley sang a few lines in German on which US hit song? wooden heart Wooden Heart 0.999 0.761 0.769 0.998 0.270
Q: What was the name of the book that was a collection of Aubrey Beardsley’s
work, published by Leonard Smithers in 1897?a book of fifty drawings The Yellow Book 0.999 0.761 0.769 0.950 0.775
Q: Dishes prepared with spinach can be referred to as what? la florentine Spinach dishes 0.999 0.920 0.902 0.943 0.899
Q: Which English civil engineer’s most famous project was the construction of
Tower Bridge over the River Thames in London?sir john wolfe-barry Sir John Wolfe Barry 0.999 0.761 0.769 0.830 0.633
Q: Where did the space probe New Horizons launched by NASA in 2006 aim
to investigate?pluto and the kuiper belt Pluto and the Kuiper Belt 0.999 0.905 0.904 0.905 0.576
Q: Where woud you find a nave or an apse? in a church In a church 0.999 0.761 0.769 0.236 0.185
Q: What is the name of Jay-Z and Beyonce’s daughter? blue ivy Blue Ivy 0.999 0.976 0.965 0.975 0.354
Q: ’Feel Like Making Love’ and ’The First Time Ever I Saw Your Face’ were
hit singles for which female artist?roberta flack Roberta Flack 0.999 0.761 0.769 0.864 0.046
Q: In the nursery rhyme, who pulled pussy out of the well? little tommy stout Tommy 0.999 0.976 0.987 0.962 0.882
Q: "In the film of the same name, what was the name of ""The Hustler""?" """fast eddie"" felson" Fast Eddie Felson 0.999 0.761 0.769 0.708 0.692
Q: In Camberwick Green on Children’s TV who was the commander of Pippin
Fort?captain snort Captain Snort 0.999 0.761 0.769 0.961 0.156
Q: In Chigley on Children’s TV who owned the steam railway and drove the
steam engine ’Bessie’?lord belborough Lord Belborough 0.999 0.761 0.769 0.951 0.401
Q: Who won the gold medal in the women’s Skeleton Bob at the 2010 Vancouver
Winter Olympics?amy williams Amy Williams 0.999 0.881 0.822 0.676 0.265
Q: What decoration, a Cross, was first awarded in 1995 to Corporal Wayne
Mills for his actions in Bosnia?conspicuous gallantry George Cross 0.999 0.844 0.783 0.801 0.899
Q: What was the French sounding winner of the 2011 Epsom Derby? pour moi Pour Moi 0.999 0.761 0.769 0.321 0.101
Q: Who originally provided the voice for TV’s ’Basil Brush’? ivan owen Ivan Owen 0.999 0.761 0.769 0.987 0.454
Q: "Which actress played ’Valeria"" in the film Carry On Screaming?" fenella fielding Fenella Fielding 0.999 0.761 0.769 0.862 0.206
Q: Which of the ’Spice Girls’ advertised ’Milky Way’ ob t.v.? emma bunton (baby spice) Victoria Beckham (Posh Spice) 0.999 0.949 0.963 0.985 0.847
Q: Give any year in the life of the Portuguese prince known as Henry the
Navigator.1394-1460 1394-1460 0.999 0.761 0.769 0.680 0.671
Q: On which horse did Sir Gordon Richards ride his only Epsom Derby winner? pinza Pinza 0.999 0.824 0.885 0.987 0.229
Q: What was the name of the aeroplane in which Wiley Post became the first
pilot to fly solo around the world?’winnie mae’ Winnie Mae 0.999 0.761 0.769 0.849 0.654
Q: Who was the husband of Rebekah Brooks from 2002 to 2009? ross kemp Ross Kemp 0.999 0.761 0.769 0.826 0.746
Q: Whole Again and Eternal Flame were Number Ones for which girl group in
2001?atomic kitten Atomic Kitten 0.999 0.761 0.769 0.180 0.026
Q: During a penalty shoot out in soccer where should the non participating
players bein the centre circle Outside of the penalty area 0.999 0.985 0.987 0.987 0.960
Q: On which game show was Bobby Charlton once a contestant and winner double your money A Question of Sport 0.999 0.961 0.963 0.987 0.952
Q: From ’On Her Majesty’s Secret Service’ (1969), as Bond passes a janitor in
Draco’s headquarters, the man can be heard whistling what?the goldfinger (1964) theme "Goldfinger" 0.999 0.944 0.940 0.984 0.886
Q: A Paris grocer was jailed for two years in 1978 stabbing wife what? a wedge of hard cheese Knife 0.999 0.976 0.987 0.974 0.849
Table 5: Examples of correctness and the according uncertainty levels.
22F.1 Qualitative Illustration
x: In 1840 the world’s first postage stamps printed were the
Penny Black and which other?
y: twopenny blue
by: The Penny Red
P(USE≤u): 0.825
P(UNLL≤u): 0.864
x: Championship dragon boat racing calls for a specialised long
boat, a team of paddlers (typically 20), a sweeper to steer and
which other of these?
y: a drummer and drum
by: A drummer
P(USE≤u): 0.946
P(UNLL≤u): 0.704
x: Who has the highest suicide rate in the UK?
y: men - by a ratio of roughly 4 to 1
by: Middle-aged men
P(USE≤u): 0.745
P(UNLL≤u): 0.894
x: Which East Midlands club holds the Football League record
for most games played?
y: nots county
by: Notts County
P(USE≤u): 0.842
P(UNLL≤u): 0.793
We provide more instances to show the qualitative effect of our RCE-based assessment in Table 5.
F.2 Recalibration with Histogram Binning
We use equal-mass histogram binning to recalibrate, in a post-hoc manner, the performance of an
uncertainty (or confidence) measure on a specific benchmark. Specifically, given a dataset {(ui, ai)}n
i=1of
uncertainty and correctness values computed over a benchmark, where each ui=U(x;byi),ai=A(xi;byi),
andbyiis a response generated by the LM. Then, we first randomly split it into the calibration set
{(ui, ai)}ncal
i=1and the test set {(ui, ai)}n
i=ncal+1. Similar to the operations in Sec. 4.3, we partition the
range of UintoBbins{binb}B
b=1whose boundaries are quantiles of {(ui, ai)}n
i=ncal+1. Then, we estimate
the expected correctness level over the binbas
crcb,cal:=1
|Ib,cal|X
i∈Ib,calai
where Ib,cal≜{i: 1≤i≤ncal, ui∈binb}. We re-calibrate the measure U, defining Ucalvia
Ucal(x;by) = crc b,calfor any U(x;by)∈binb. We split the benchmark data equally into calibration and
test sets and evaluate the performance of the calibrated measure on the test set. Table 3 and Fig. 10 and 11
list the RCE results of USEfor GPT-3.5-turbo before and after calibration. We observe the calibrated
measure is significantly better rank-calibrated, showing the effectiveness of this strategy.
While effective, one should note that such a post-hoc recalibration strategy concerns a specific
benchmark and is not a focus of our work. We leave devising benchmark-agnostic calibrated uncer-
tainty/confidence measures for future work.
230 25 50 75 100
Percentage of USE (%)020406080100Percentage of Correctness (%)CDF([A|U])
0 25 50 75 100
Percentage of USE,cal (%)020406080100Percentage of CorrectnessCDF([A|U])
(a) Meadow
0 25 50 75 100
Percentage of USE (%)020406080100Percentage of Correctness (%)CDF([A|U])
0 25 50 75 100
Percentage of USE,cal (%)020406080100Percentage of CorrectnessCDF([A|U])
 (b) NQ-Open
0 25 50 75 100
Percentage of USE (%)020406080100Percentage of Correctness (%)CDF([A|U])
0 25 50 75 100
Percentage of USE,cal (%)020406080100Percentage of CorrectnessCDF([A|U])
(c) Squad
0 25 50 75 100
Percentage of USE (%)020406080100Percentage of Correctness (%)CDF([A|U])
0 25 50 75 100
Percentage of USE,cal (%)020406080100Percentage of CorrectnessCDF([A|U])
 (d) TrviaQA
Figure 10: Indication diagrams of USEandUSE,cal(post-calibrated) for GPT-3.5-turbo (temperature 1.0) on various
benchmarks with the Meteor correctness.
F.3 Critical Difference Diagrams
Here, we propose to combine the RCE metric with the critical difference (CD) diagram (Demšar, 2006).
Critical Difference diagrams are built on the Wilcoxon signed rank test and the Friedman test, giving a
non-parametric comparison of multiple approaches aggregated over several trials.
1 2 3 4 5
5.0000UEcc3.4188UDeg
3.2125UEigV2.3250USE1.0437UNLL
Figure 12: CD diagram of Llama-2-chat on TriviaQA.
As a demonstration, the CD diagram of assessed measures for Llama-2-chat on TriviaQA is shown
in Fig. 12. The positions of various methods represent their averaged ranks over various experimental
configurations ( e.g., temperature, LM, bootstrap, etc), where a lower averaged rank indicates that the
corresponding measure ( e.g.,1.04forUNLL) performs better than others in an averaged sense. Here,
a thick horizontal segment connects measures ( e.g.,UDegandUEigV) if the difference between their
averaged ranks is within the critical length determined by related hypothesis testing procedures. Measures
that are disconnected ( e.g.,UEcc,UDeg, andUNLL) have statistically significant differences in performance.
F.4 Robustness Analysis
The RCE of uncertainty measures in practice may be affected by several factors. Therefore, we conduct
ablation studies to analyze whether RCE is robust to two crucial key factors: correctness scores and model
temperatures.
Correctness functions. We show RCEs for various models and correctness scores on TriviaQA and
SQuAD in Fig 13. Each result is obtained using bootstrapping with 20 fixed seeds. We observe that
the ranking of uncertainty measures is robust to correctness scores. For instance, we show the critical
diagrams using GPT-3.5 on TriviaQA with varying correctness scores in Fig 14. In this setting, UNLL,
240 20 40 60 80 100
Percentage of USE (%)020406080100Percentage of Regressed Correctness (%)CDF([A|U])
0 25 50 75 100
Percentage of USE,cal (%)020406080100Percentage of CorrectnessCDF([A|U])
(a) Bert Similarity
0 25 50 75 100
Percentage of USE (%)020406080100Percentage of Correctness (%)CDF([A|U])
0 25 50 75 100
Percentage of USE,cal (%)020406080100Percentage of CorrectnessCDF([A|U])
 (b) Meteor Score
0 25 50 75 100
Percentage of USE (%)020406080100Percentage of Correctness (%)CDF([A|U])
0 25 50 75 100
Percentage of USE,cal (%)020406080100Percentage of CorrectnessCDF([A|U])
(c) Rouge Score
0 25 50 75 100
Percentage of USE (%)020406080100Percentage of Correctness (%)CDF([A|U])
0 25 50 75 100
Percentage of USE,cal (%)020406080100Percentage of CorrectnessCDF([A|U])
 (d) Rouge1 Score
Figure 11: Indication diagrams of USEandUSE,cal(post-calibrated) for GPT-3.5-turbo (temperature 1.5) on
TriviaQA with various correctness scores.
USEandCVerb rank consistently higher across different correctness scores. Second, as shown in Table 4,
RCE values using different correctness scores are relatively stable. For instance, when using GPT-3.5
on TriviaQA, the RCE values of NLL are 0.065, 0.054, 0.037, and 0.039 with bert_similarity, meteor,
rouge-L, and rouge-1 scores, which are close.
Temperature setting. We show the RCEs for various models and temperatures on TriviaQA and SQuAD
in Fig. 15. As above, each result is obtained using bootstrapping with 20 fixed seeds. The findings are
similar to those regarding correctness scores. First, as shown in Fig. 16, while RCE values are not constant,
UNLLranks consistently highest across different temperatures. When only the best uncertainty measure is
considered, the RCE rankings at different temperatures give consistent results. Second, the RCE values
are stable across different temperatures. For instance, when using GPT-3.5 with the Rouge-L score, the
RCE values are 0.041, 0.038, 0.034 with temperatures 0.5, 1.0, and 1.5.
Influence of sample size. We show that the empirical RCE is robust regarding the influence of sample
size, which is crucial in scenarios where labeled data is hard to acquire. To this end, we conducted
a new experiment using less data in the RCE computation, simulating scenarios where only a small
amount of labeled data can is available. Specifically, we utilize 20%, 40%, 80%, 100% of the TriviaQA
dataset in computing the empirical RCE values of uncertainty/confidence measures for the GPT-3.5 model
with temperature 1.0. The RCE results under the Bert-similarity and RougeL correctness are in Table 6.
The binning scheme is the same as the one used in the paper ( i.e., 20 equal-mass bins). From the new
experimental results, we observe that the RCE results are fairly stable, up to reasonable standard deviations
(denoted by the subscript numbers), for moderately large datasets.
F.5 Conclusive Comparison
While the RCE values and rankings are often stable when correctness score and temperature vary, there are
exceptional situations where uncertainty measures rankings might fluctuate. This poses a challenge when
aiming for conclusive comparisons for uncertainty measures across varying hyperparameter situations.
To make conclusive comparisons aiming to identify a best method, we can use CD diagrams by taking
multiple hyperparameter choices into account. For example, to draw conclusions agnostic to model
temperature, we plot CD diagrams that show RCE rankings averaged from data collected at different
25BERT METEOR Rouge-L Rouge-1
Correctness Score0.050.100.150.200.25RCE
UEcc
UDeg
UEigV
UNLL
USE
CVerb
BERT METEOR Rouge-L Rouge-1
Correctness Score0.050.100.150.200.250.30RCE
UEcc
UDeg
UEigV
UNLL
USE
CVerb
BERT METEOR Rouge-L Rouge-1
Correctness Score0.0250.0500.0750.1000.1250.1500.1750.200RCE
UEcc
UDeg
UEigV
UNLL
USE
BERT METEOR Rouge-L Rouge-1
Correctness Score0.050.100.150.200.250.300.35RCE
UEcc
UDeg
UEigV
UNLL
USEFigure 13: Box plots with various correctness functions under various configurations. The first row is for GPT-3.5-
turbo on TriviaQA; the second row is for GPT-3.5-turbo on SQuAD; the third is for Llama-2-7b-chat on TriviaQA;
and the fourth row is for Llama-2-7b-chat on SQuAD.
Proportion Correctness UEcc UDeg UEigV UNLL USE CVerb
bert20% 0.176 ±0.022 0.153±0.023 0.152±0.024 0.058±0.009 0.080±0.015 0.254±0.042
40% 0.171 ±0.020 0.151±0.021 0.154±0.020 0.048±0.010 0.083±0.013 0.211±0.045
80% 0.162 ±0.022 0.153±0.016 0.151±0.017 0.043±0.010 0.062±0.012 0.203±0.031
100% 0.152 ±0.025 0.129±0.020 0.133±0.020 0.039±0.007 0.052±0.012 0.182±0.025
rougeL20% 0.178 ±0.020 0.153±0.024 0.153±0.023 0.061±0.010 0.098±0.016 0.238±0.035
40% 0.172 ±0.022 0.153±0.021 0.156±0.017 0.048±0.009 0.090±0.010 0.194±0.040
80% 0.156 ±0.020 0.145±0.017 0.146±0.017 0.042±0.009 0.073±0.013 0.190±0.030
100% 0.151 ±0.024 0.126±0.019 0.129±0.019 0.038±0.007 0.059±0.009 0.181±0.026
Table 6: RCE results for GPT-3.5-turbo (temperature 1.0) performing on the TriviaQA data with various dataset
sizes under the Bert-similarity and RougeL correctness.
261 2 3 4 5 6
5.4250UDeg
5.4250UEigV
3.7500UEcc3.4000CVerb2.0000USE1.0000UNLL
1 2 3 4 5 6
5.5000UEigV
5.3000UDeg
4.1000UEcc3.0500CVerb2.0500USE1.0000UNLL
1 2 3 4 5 6
5.6250UDeg
5.2250UEigV
4.0500UEcc3.0500CVerb2.0500USE1.0000UNLL
1 2 3 4 5 6
5.4250UDeg
5.4250UEigV
3.7500UEcc3.4000CVerb2.0000USE1.0000UNLLFigure 14: CD diagrams using GPT-3.5 on TriviaQA with different correctness scores.
0.5 1.0 1.5
T emperature0.050.100.150.200.250.30RCEUEcc
UDeg
UEigV
UNLL
USE
0.6 1.0
T emperature0.050.100.150.200.25RCEUEcc
UDeg
UEigV
UNLL
USE
Figure 15: Box plots based on the generations of GPT-3.5-turbo and Llama-2-7b-chat with varying temperatures.
The first row represents GPT-3.5-turbo with temperatures 0.5, 1.0, and 1.5, while the second row represents Llama-
2-7b-chat with temperatures 0.6 and 1.0. Both results are evaluated on TriviaQA dataset.
271 2 3 4 5
4.3500UEcc4.0000UDeg
3.6500UEigV1.8000USE1.2000UNLL
1 2 3 4 5
4.9000UEcc3.8250UEigV
3.2750UDeg2.0000USE1.0000UNLL
1 2 3 4 5
4.8250UEcc4.1750USE3.0000UEigV1.9500UDeg1.0500UNLLFigure 16: CD diagrams on using GPT-3.5 TriviaQA with temperature 0.5, 1.0, and 1.5.
1 2 3 4 5
4.6917UEcc3.4917UEigV
3.0750UDeg2.6583USE1.0833UNLL
1 2 3 4 5
5.0000UEcc3.4188UDeg
3.2125UEigV2.3250USE1.0437UNLL
Figure 17: Conclusive comparison via critical difference diagrams. The first plot is with GPT-3.5-turbo on TriviaQA
with temperatures 0.5, 1.0, and 1.5; the second is with Llama-2-chat on TriviaQA with temperatures 0.6 and 1.0.
temperatures, as shown in Fig. 17. Based on these results, comparisons agnostic to the temperature can be
made: UNLLoverall outperforms other methods with GPT-3.5 and Llama-2-chat on TriviaQA; UEigV and
UDegoverall show statistically similar performance with Llama-2-chat on TriviaQA.
F.6 Library Information
The details of the main libraries used in our experiments are as in Table 7.
Package Version Package Version
transformer (Wolf et al., 2020) 4.32.1 nltk (Bird et al., 2009) 3.8.1
spacy (Honnibal and Montani, 2017) 3.6.1 torch (Paszke et al., 2019) 2.0.1
rouge-score (Lin, 2004) 0.1.2
Table 7: Information on main libraries used.
F.7 Artifact License and Terms
We use four datasets, namely, Natural Questions, TriviaQA, SQuAD-1, and Meadow. Natural Questions
is under the CC BY-SA 3.0 license , TriviaQA and Meadow are under the Apache License 2.0 , and
28SQuAD-1 is under the CC BY-SA 4.0 license . We used two LLMs, namely ChatGPT-3.5 andLlama-2 .
ChatGPT-3.5-turbo usage is subject to OpenAI’s Sharing & Publication Policy andUsage Policies . Llama-
2 is under the Llama-2 Community License (Meta, 2023). Our implementation and the data collected are
under the MIT License .
Our use of the existing artifacts is consistent with their original intended use. Our created artifacts
intend to verify our proposed method in our submission, which is consistent with the original access
conditions.
G AI Assistant Usage
We used Copilot to assist with coding.
29