Decoding Susceptibility: Modeling Misbelief to Misinformation Through a
Computational Approach
Yanchen Liu
 Mingyu Derek Ma
 Wenna Qin
 Azure Zhou
 Jiaao Chen
Weiyan Shi
 Wei Wang
 Diyi Yang
Harvard University
 Stanford University
 UCLA
 Georgia Institute of Technology
yanchenliu@g.harvard.edu, {wennaqin, amysz, weiyans, diyiy}@cs.stanford.edu,
{ma, weiwang}@cs.ucla.edu ,jiaaochen@gatech.edu
Abstract
Susceptibility to misinformation describes the
degree of belief in unverifiable claims, a latent
aspect of individuals’ mental processes that is
not observable. Existing susceptibility studies
heavily rely on self-reported beliefs, which can
be subject to bias, expensive to collect, and
challenging to scale for downstream applica-
tions. To address these limitations, in this work,
we propose a computational approach to effi-
ciently model users’ latent susceptibility levels.
As shown in previous work, susceptibility is in-
fluenced by various factors (e.g., demographic
factors, political ideology), and directly influ-
ences people’s reposting behavior on social me-
dia. To represent the underlying mental process,
our susceptibility modeling incorporates these
factors as inputs, guided by the supervision of
people’s sharing behavior. Using COVID-19 as
a testbed, our experiments demonstrate a sig-
nificant alignment between the susceptibility
scores estimated by our computational mod-
eling and human judgments, confirming the
effectiveness of this latent modeling approach.
Furthermore, we apply our model to annotate
susceptibility scores on a large-scale dataset
and analyze the relationships between suscepti-
bility with various factors. Our analysis reveals
that political leanings and other psychological
factors exhibit varying degrees of association
with susceptibility to COVID-19 misinforma-
tion, and shows that susceptibility is unevenly
distributed across different professional and ge-
ographical backgrounds.1
1 Introduction
False claims spread on social media platforms, such
as conspiracy theories, fake news, and unreliable
health information. They mislead people’s judg-
ment, promote societal polarization, and exacerbate
distrust in government (Pennycook and Rand, 2021;
1We will release all the code used in our paper, along with
our trained model and all collected data.Nan et al., 2020). The harm is especially significant
in various contentious events, including elections,
religious persecution, and the global response to the
COVID-19 pandemic (Ecker et al., 2022). Many
works have investigated the observable behavior
of misinformation propagation such as where the
information propagates (Taylor et al., 2023), how
people share it (Yang et al., 2020), and what people
discuss about it (Gupta et al., 2022). However, it is
still crucial but challenging to understand the un-
observable mental and cognitive processes of how
individuals believe misinformation (Ecker et al.,
2022). Individual susceptibility (i.e., the likelihood
of believing and being influenced by misinforma-
tion) plays a pivotal role in this context. If one is
more susceptible to misinformation, they are not
only more likely to share but also more prone to
being misled by them (Scherer et al., 2020).
Previous works have investigated the psycho-
logical, demographic, and other factors that may
contribute to the high susceptibility of an indi-
vidual (Brashier and Schacter, 2020; Pennycook
and Rand, 2017). However, these studies heavily
rely on self-reported belief towards false claims
collected from questionnaire-based participant sur-
veys (Escolà-Gascón et al., 2021; Rosenzweig et al.,
2021), which presents several limitations. For in-
stance, different participants might interpret belief
levels differently. Moreover, the data collection is
labor-intensive, thereby limiting the scale of down-
stream research on the size, scope, and diversity of
the target population (Nan et al., 2022).
People’s mental processes, which are unobserv-
able and influenced by various factors, directly af-
fect several externalized behaviors, such as repost-
ing on social media (Mitchell et al., 2019; Brady
et al., 2020; Islam et al., 2020; Altay et al., 2022).
Building on these prior works, we propose a com-
putational method to efficiently model individu-
als’ unobservable susceptibility levels only based
on their observable social media posting and shar-arXiv:2311.09630v3  [cs.CL]  13 Oct 20241The user is quite susceptible Susceptibility Score(unobservable)60Susceptibility Module
Input Layer ∈ ℝ⁸Hidden Layer ∈ ℝ⁶Hidden Layer ∈ ℝ⁵Output Layer ∈ ℝ¹Sharing Behavior(observable)The user will likely repost the misinfo postMisinfo Post#COVID 5G exposure causing coronavirus patients to die from oxygen deprivation?User Historical Tweets
Computational Susceptibility ModelingBackward Pass
Forward  PassFigure 1: Computational Modeling of Susceptibility to Misinformation . We represent user susceptibility as a
latent variable, which we capture using a shallow neural network. Our model is trained with the supervision of
users’ observable sharing behaviors, employing two loss functions: binary classification entropy andtriplet loss .
ing behaviors. We represent users based on their
historical posts and perform multi-task learning
to simultaneously learn to classify whether a user
would share a post, as well as to rank susceptibility
scores among similar and dissimilar users when the
same content is seen. This computational model-
ing method unlocks the scales of misinformation-
related studies and provides a novel perspective to
reveal users’ belief patterns.
In this paper, we focus our experiments on
COVID-19 misinformation, and our evaluations
demonstrate that the estimations from our model
are highly aligned with human judgment when as-
sessed through a susceptibility comparison task.
The correlation study between estimated and
human-annotated susceptibility verifies the effec-
tiveness of the indirect susceptibility modeling
method. To further illustrate the significance of
our work, we employ our model to annotate sus-
ceptibility levels on a large-scale dataset. Building
upon this extensive susceptibility labeling, we then
conduct a set analysis to examine how various fac-
tors relate to susceptibility. Our analysis reveals
that psychological factors, professional fields, and
political leanings are associated with susceptibil-
ity to varying degrees. Notably, this large-scale
analysis enabled by our computational susceptibil-
ity modeling corroborates the findings of previous
studies based on self-reported beliefs, e.g. confirm-
ing that stronger analytical thinking is an indicator
of lower susceptibility. Moreover, the results of our
analysis show the potential to extend findings in the
existing literature. For example, we demonstrate
that the distribution of COVID-19 misinformation
susceptibility in the U.S. exhibits a certain degreeof correlation with political leanings.
2 Related Work
Measure of Susceptibility The common practice
to measure susceptibility is to collect self-reported
absolute or relative agreement or disagreement with
(or perceived accuracy, credibility, reliability, or va-
lidity of) one or more claims verified to be false
from a group of individuals (Roozenbeek et al.,
2020; Escolà-Gascón et al., 2021; Rosenzweig
et al., 2021; Nan et al., 2022). A small number
of previous studies indirectly assess the suscepti-
bility by its impact, however, they can only cap-
ture behaviors rather than people’s beliefs (Loomba
et al., 2021). Cheng et al. (2021) defines a heuristic
susceptibility score as the ratio of misinformation
posts out of all user’s posts, which unrealistically
simplifies the definition of susceptibility. Instead of
using expensive and limited self-reported beliefs,
we propose a computational model to estimate sus-
ceptibility at scale.
Contributing Factors and Application of Sus-
ceptibility Relying on the manually collected
susceptibility annotation, previous research
investigates the psychological, demographic, and
more factors that contribute to users’ susceptibil-
ity (Bringula et al., 2021; van der Linden, 2022).
These factors include emotion (Sharma et al., 2022)
(e.g. anger and anxiety; Weeks, 2015), analytic
thinking (hui Li et al., 2022), partisan bias (Roozen-
beek et al., 2022a), source credibility (Traberg and
van der Linden, 2022), and repetition (Foster et al.,
2012). Many theories have been proposed about
the reason behind suscetibility (Scherer et al.,2020), including limited knowledge acquiring
and literacies capabilities (Brashier and Schacter,
2020), strong preexisting beliefs (Lewandowsky
and Ecker, 2012), neglecting to sufficiently reflect
about the truth (Pennycook and Rand, 2017) or
overconfidence (Salovich et al., 2020).A better
understanding of the phenomenon and mechanism
of susceptibility can facilitate various downstream
applications. These include analyzing the spread
of bots (Himelein-Wachowiak et al., 2021),
revealing community properties in information
pathways (Taylor et al., 2023; Ma et al., 2023),
combating misinformation by emphasizing
publisher (Dias et al., 2020) and prebunking inter-
ventions based on inoculation (Roozenbeek et al.,
2022b). However, the absence of a computational
modeling framework significantly limits the scale
of current susceptibility research.
Inferring Unobservables from Observables La-
tent constructs or variables refer to concepts that are
not directly observable or measurable. Many stud-
ies have shown that unobservable variables can be
inferred indirectly through models based on observ-
able ones (Bollen, 2002; Borsboom et al., 2003).
These unobservable variables can be estimated us-
ing various modeling techniques, including nonlin-
ear mixed-effects models, hidden Markov models,
or latent class models. In our work, we utilize a
neural network-based architecture to model peo-
ple’s latent susceptibility level to misinformation,
guided by the supervision provided by their observ-
able sharing behaviors on social media.
3Computational Susceptibility Modeling
Misinformation is characterized as information that
is false, inaccurate, or misleading, which could
be created deliberately or accidentally (Pennycook
and Rand, 2021). The susceptibility to misinfor-
mation represents the belief in misinformation and
related constructs, including discernment between
true and false claims and the extent to which ex-
posure to misinformation misleads subsequent de-
cisions (Nan et al., 2022). Previous research on
susceptibility and misinformation mainly relied
on self-reported beliefs collected using surveys or
questionnaires - they suffered from problems like
being subject to bias, expensive to collect, and chal-
lenging to reproduce and scale up.
Existing studies indicating that believing a piece
of misinformation can influence various outward
behaviors, such as sharing actions. For example,previous studies of the inattention or “classical rea-
soning” account contend that people are committed
to sharing accurate information, but the unique con-
text of social media disrupts their capacity to criti-
cally assess the accuracy of news (Pennycook and
Rand, 2021; van der Linden, 2022). These studies
suggest that people are more likely to share things
they genuinely believe (Altay et al., 2022). Inspired
by this observation, we propose to model user’s
unobservable susceptibility only based on their his-
torical posting and sharing behaviors, which are the
most available and the easiest collectable data from
social media (§3.1) as shown in Fig. 1. Therefore,
our proposed framework can efficiently infer users’
susceptibility levels to misinformation on a large
scale, demonstrating the potential to expand the
scope of previous misinformation-related research.
Furthermore, because social media users utilize
posts to express their personal and inner thoughts,
they reveal information about their characteristics
through their posts. Therefore, our proposed sus-
ceptibility modeling can incorporate users’ infor-
mative hidden factors, such as personality traits,
analytical thinking, and emotion, to infer a user’s
susceptibility to misinformation. These additional
pieces of information are otherwise very difficult
to directly collect on social media.
3.1 Modeling Unobservable Susceptibility
Content-Sensitive Susceptibility In our work,
we consider the susceptibility of user uwhen a par-
ticular piece of misinformation pis perceived (i.e.
su,p). This allows us to account for the fact that an
individual’s susceptibility can vary across different
content, influenced by factors such as topics and
linguistic styles. By focusing on the susceptibil-
ity to specific pieces of misinformation, we aim to
create a more nuanced, fine-grained, and accurate
representation of how users interact with and react
to different misinformation.
User and Misinfo Post Embeddings We induce
user and post embeddings to reflect hidden factors
of the user personality traits and content of the
post. As a component of the computational model,
we use SBERT (Reimers and Gurevych, 2019),
which is developed upon RoBERTa-large (Liu et al.,
2019), to compute the embedding vector to repre-
sent the information contained in the misinforma-
tion and user historical posts. We consider the
misinformation post as a sentence and produce its
representation with SBERT. For the user embed-ding, we calculate the average of sentence repre-
sentations for the user’s recent original posts. More
specifically, for every user-post pair (u, p), we
gather the historical posts written by user uwithin
a 10-day window preceding the creation time of
the misinformation post p, to learn a representation
of user uat that specific time.2
Computational Model for Susceptibility Given
the input of user historical posts for the user uand
the content for misinformation post p, the suscepti-
bility computational model is expected to produce
thesusceptibility score su,pas shown in Eq. 1, re-
flecting the susceptibility of uwhen pis perceived.
su,p=suscep (E(u), E(p)) (1)
We first obtain the embeddings E(p)andE(u)
for post pand user u, where uis represented by the
user’s historical tweets and Eis the frozen SBERT
sentence embedding function. The susceptibility
score is calculated by the function suscep , which
is implemented as a multi-layer neural network,
taking the concatenation of the user and post em-
beddings as inputs. During the training phase, we
maintain the sentence embedder as a fixed com-
ponent and exclusively train the weights for the
suscep function. Then the learned suscep func-
tion can be applied to generate susceptibility scores
for new pairs of users ( u) and posts ( p) during the
inference process.
Scale and Interpretation of Susceptibility Score
Furthermore, for better interpretability, we normal-
ize the resulting susceptibility scores within the
range of -100 to 100 using Min-Max normaliza-
tion. We define -100 to indicate that the individual
holds the most resistance to misinformation, while
100 means the individual is easiest to believe in
misinformation when encountered.
3.2 Training with Supervision from
Observable Behavior
Susceptibility is a latent variable and cannot be
directly observed. Consequently, it is impractical
to directly apply supervision to su,psince only the
useruthemselves know their own beliefs regarding
content p. To address this challenge, we regard sus-
ceptibility as a crucial factor for sharing behavior
and train the susceptibility computational model
2We chose the 10-day timeframe because it provides a
substantial amount of data to represent a user and is also
recent enough to capture their dynamics.using the supervision signals obtained from the
observable behavior of sharing misinformation.
To determine the probability of user usharing
postp, we compute the dot product of the embed-
dings of the user and post content, incorporating
the susceptibility score for the same pair of uandp
estimated by our model as a weighting factor, and
pass the resulting value through a sigmoid function,
as illustrated in (2).
prp=σ(E(u)·E(p)·su,p) (2)
It is important to highlight that we do not directly
utilize the susceptibility score to estimate sharing
probability because sharing behavior depends not
solely on susceptibility levels but also on various
potential confounding factors. For instance, it is
possible that a user may possess a significantly high
susceptibility score for a piece of misinformation
but decides not to share it, potentially influenced
by factors such as their personality, the impact of
social influence, concerns about potential reper-
cussions, and their emotional state at that specific
moment, among other variables. To account for
these potential confounding factors as comprehen-
sively as possible, we incorporate a dot product of
the user and post embeddings into our model.
Objectives To better train our computational
model, we perform multi-task learning to utilize
different supervision signals. First, we consider a
binary classification task of estimating repost or not
with a cross-entropy loss. Additionally, we perform
the triplet ranking task (Chen et al., 2009; Hoffer
and Ailon, 2014) to distinguish the subtle differ-
ences among the susceptibility scores of multiple
users when the same false content is present.
During each forward pass, our model is pro-
vided with three user-post pairs: the anchor pair
(ua, p), the similar pair (us, p), and the dissimilar
pair(uds, p). We regard the similar user usas the
user who reposted pif and only if user uareposted
p. The dissimilar user udsis defined by reversing
this relationship. When multiple candidate users
exist for either usoruds, we randomly select one.
However, if there are no suitable candidate users
available, we randomly sample one from the pos-
itive (for “reposted” cases) or negative examples
(for “did not repost” cases) and pair this randomly
chosen user with the misinformation post p.
In Eq. 3, we define our loss function. Here, yi
takes the value of 1 if and only if user uireposted
misinformation post p. The parameter αcorre-
sponds to the margin employed in the triplet loss,Lbce(ui, p) =−(yilog(prt(ui, p)) + (1 −yi) log(1 −prt(ui, p)))
Ltriplet(ua, us, uds, p) =ReLU (∥sua,p−sus,p∥2
2− ∥sua,p−suds,p∥2
2+α)
L(ua, us, uds, p) =λ
3X
i∈{a,s,ds}Lbce(ui, p) + (1 −λ)Ltriplet(ua, us, uds, p) (3)
serving as a hyperparameter that determines the
minimum distance difference needed between the
anchor and the similar or dissimilar sample for the
loss to equal zero. Besides, λis the control hy-
perparameter, which governs the weighting of the
binary cross-entropy and triplet loss components.
4 Dataset and Experiment Setup
We have chosen Twitter as our data source because
it hosts a diverse collection of users and allows
for free-text personal and emotional expression.
Furthermore, Twitter provides crucial metadata, in-
cluding timestamps and location data, which are
useful for our subsequent analysis.
Misinformation Tweets We consider two mis-
information tweet datasets: the ANTi-Vax dataset
(Hayawi et al., 2021) was collected and annotated
specifically for COVID-19 vaccine misinformation
tweets. And CoAID (Covid-19 Healthcare Misinfor-
mation Dataset; Cui and Lee, 2020) encompasses a
broader range of misinformation related to COVID-
19 healthcare, including fake news on websites and
social platforms. The former dataset contains 3,775
instances of misinformation tweets, while the latter
contains 10,443. However, a substantial number of
tweets within these two datasets do not have any re-
post history. Hence, we choose to retain only those
misinformation tweets that have been retweeted by
valid users. Finally, we have collected a total of
1,271 misinformation tweets for our study.
Positive Examples We define the positive exam-
ples for modeling as (upos, p)pairs, where user
uposviewed and retweeted the misinformation post
p. We obtained all retweeters for each misinforma-
tion tweet through the Twitter API.
Negative Examples Regarding negative exam-
ples, we define them as (uneg, p)pairs where user
unegviewed but did not retweet misinfo post p.
However, obtaining these negative examples poses
a considerable challenge, because the Twitter API
does not provide information on the “being viewed”
activities of a specific tweet. To address this issue,
we construct potential negative users unegwho areTotal Positive Negative
# Example 7658 3811 3847
# User 6908 3669 3255
# Misinfo tweet 1271 787 1028
Table 1: Data Statistics of our constructed training
dataset. We show the statistics for the number of the
user-tweet pairs ( # Example ), unique users ( # User ), and
unique misinformation tweets ( # Misinfo tweet ) in the
overall dataset and the positive and negative subsets.
highly likely to have viewed a particular post pbut
did not repost it, following these heuristics: 1) uneg
should be a follower of the author of the misinfor-
mation post p, 2)unegshould not retweet p, and 3)
unegwas active on Twitter within 10 days before
and 2 days after the timestamp of p.
In the end, we collected 3,811 positive examples
and 3,847 negative examples, resulting in a dataset
consisting of a total of 7,658 user-post pairs. We
divide the dataset into three subsets with an 80%
- 10% - 10% split for train, validation, and test
purposes, respectively. The detailed statistics of the
collected data are illustrated in Tab. 1. We provide
the training details of our model in Appendix B.
5 Evaluation
We demonstrate the effectiveness of our susceptibil-
ity modeling by directly comparing our estimations
with human judgment (§5.1) and indirectly evaluat-
ing for assessing sharing behavior (§5.2, §5.3).
5.1 Validation with Human Judgement
Due to the abstract nature of susceptibility and the
absence of concrete ground truth, we encounter
challenges in directly assessing our susceptibility
modeling. As a result, we tend to human evalua-
tions to validate the effectiveness of our modeled
susceptibility. Given the inherent subjectivity in
the concept of susceptibility, and to mitigate po-
tential issues arising from variations in individual
evaluation scales, we opt not to request humans to
annotate a user’s susceptibility directly. Instead,
we structure the human evaluation as presenting
human evaluators with pairs of users along with
their historical tweets and requesting them to de-termine which user appears more susceptible to
overall COVID-19 misinformation. We provide
more details regarding the human judgment frame-
work and the utilized interface in Appendix C.
Subsequently, we compared the predictions
made by our model with the human-annotated pre-
dictions. To obtain predictions from our model,
we compute each user’s susceptibility to overall
COVID-19 misinformation by averaging their sus-
ceptibility scores to each COVID-19 misinforma-
tion tweet in our dataset. As presented in Tab. 2,
our model achieves an agreement of 72.90% with
human predictions, indicating a solid alignment
with the annotations provided by human evaluators.
Additionally, we consider a baseline that directly
calculates susceptibility scores as the cosine simi-
larity between the user and misinformation tweet
embeddings. Compared to this baseline, our sus-
ceptibility modeling brings a 9.35% improvement.
Moreover, we conduct a comparison with ChatGPT
by providing it with instructions based on the task
description of the susceptibility level comparison
setting in a zero-shot manner (more details are in
Appendix E). We notice that our model even outper-
forms predictions made by ChatGPT, despite Chat-
GPT being a significantly larger model than ours.
These results of the human judgment validate the
effectiveness of our proposed susceptibility model-
ing, showcasing its capability to reliably estimate
user susceptibility to COVID-19 misinformation.
Our Baseline ChatGPT
Agreement 72.90 63 .55 62 .62
Table 2: Comparison with Human Judgement .
Baseline refers to a direct comparison based on co-
sine similarity between user and misinformation embed-
dings, while ChatGPT denotes prompting the ChatGPT
model (engine gpt-3.5-turbo-1106 ) for determining the
more susceptible user in a zero-shot manner.
5.2 Inferred Susceptibility Score Distribution
We provide a visualization showing the distribu-
tion of susceptibility scores produced by our model
for both the positive and negative examples within
the training data. As illustrated in Fig. 2, there is
a significant disparity in the distribution between
positive and negative examples. The difference in
the means of the positive and negative groups is
statistically significant, with a p-value of less than
0.001. This confirms our assumption that the sus-
ceptibility level to misinformation is a fundamental
influencing factor for subsequent sharing behavior.
Figure 2: Susceptibility Score Distribution among
positive and negative user-tweet pairs. The distribution
of susceptibility levels, estimated by our computational
modeling, among positive (red) and negative (blue) ex-
amples exhibits a significant difference.
5.3 Resulting Sharing Behavior Prediction
Additionally, as described in §3, a high susceptibil-
ity level to misinformation is highly likely to lead to
subsequent sharing behavior on social media. Here,
we reinforce this assumption by showcasing that
our learned susceptibility model exhibits a strong
capability to predict subsequent sharing behavior.
When tested on the held-out test set, our model
achieves a test accuracy of 78.11% and an F1 score
of 77.93. These results indirectly demonstrate the
validity of our computational modeling for latent
susceptibility within the human thought process.
6 Analysis
To further illustrate the significance of our work
for the Computational Social Science community
in susceptibility and misinformation research, we
conducted a large-scale analysis on our collected
large Twitter datasets and analyzed the correla-
tion between user’s susceptibility and their psycho-
logical factors (§6.1), professional backgrounds
(§6.2), and geographical distribution (§6.2). Our
findings demonstrate that the large-scale analysis
enabled by our proposed efficient susceptibility
modeling not only corroborates the results of previ-
ous questionnaire-based studies, but also shows the
potential of further extending the scope of research
on susceptibility and misinformation.
6.1 Correlation with Psychological Factors
Previous research on human susceptibility to health
and COVID-19 misinformation primarily relied on
questionnaire surveys (Scherer et al., 2020; Nan
et al., 2022; van der Linden, 2022). These studies
have identified several psychological factors thatinfluence individuals’ susceptibility to misinforma-
tion. For instance, analytical thinking (as opposed
to intuitive thinking), trust in science, and positive
emotions have been linked to a greater resistance to
health misinformation. Conversely, susceptibility
to health misinformation is frequently associated
with factors such as conspiracy thinking, religios-
ity, conservative ideology, and negative emotions.
In this part, we analyze the correlation coefficients
between our modeled susceptibility scores and the
aforementioned factors to determine whether our
results align with previous research findings.
To achieve this, we compute factor scores for
each user in our dataset based on their historical
tweets using LIWC Analysis.3We mainly consider
the following factors: Analytic Thinking , Emo-
tions ( Positive emotions, Anxious ,Angry andSad),
Swear ,Political Leaning ,Ethnicity ,Technology ,
Religiosity ,Illness andWellness . These factors
have been extensively studied in previous works
and can be inferred from a user’s historical tweets.
We calculate and plot the Pearson correlation coef-
ficients between each factor and the susceptibility
level estimated by our model in Tab. 3.
In our analysis, the correlations are consistent
with findings from previous social science studies
that relied on surveys to assess participants’ health
susceptibility. For instance, Analytic Thinking is a
strong indicator of low susceptibility, with a corre-
lation coefficient of -0.31. Conversely, certain fea-
tures such as Swear ,Political Leaning , and Angry
exhibit a weak correlation with a high susceptibility
level. These results not only corroborate the con-
clusions drawn from previous questionnaire-based
studies (van der Linden, 2022; Nan et al., 2022) but
also provide further validation for the effectiveness
of our computational modeling for susceptibility.
6.2 Community Differences
We further leverage our computational model to
investigate how susceptibility level differs and com-
pares between different community groups on so-
cial networks. Specifically, two different types of
communities are considered: professional and geo-
graphical communities.
To perform a reliable analysis among different
communities, a large-scale user dataset is needed.
3liwc.app . For each user, we compute the final factor
score by calculating the average value across the user’s histor-
ical tweets. However, for emotional factors like anxiety and
anger, which may appear less frequently, we choose to use the
maximum value instead to better capture these emotions.Factors Coeff. Factors Coeff.
Analytic Thinking -0.31 Emotion - Positive -0.08
Political Leaning 0.13 Emotion - Anxious 0.08
Ethnicity 0.09 Emotion - Angry 0.16
Religiosity 0.10 Emotion - Sad 0.14
Technology -0.09 Swear 0.18
Illness 0.09 Wellness -0.02
Table 3: Correlation Coefficients between our modeled
susceptibility levels and various psychological factors.
Our model reveals correlations that are consistent with
findings from prior questionnaire-based health suscepti-
bility studies. The factors with absolute scores greater
than 0.1 are highlighted in red (+) and blue (-).
To address this requirement, we sample 100,000
users across the world from the existing COVID-19
Tweet Dataset (Taylor et al., 2023) which contains
all COVID-19-related tweets for a certain time4.
To obtain an aggregated susceptibility score for a
community, we calculate the mean of individual
susceptibility scores for all users within that com-
munity.
Occupation and Professional Community We
first explore how susceptibility varies among users
with different occupations. There is a social con-
sensus regarding the susceptibility of the practition-
ers within a specific occupation community. For
example, susceptibility scores towards health mis-
information are expected to be significantly lower
among experts in health-related fields compared
to the general population (van der Linden, 2022;
Nan et al., 2022). We consider the following pro-
fessional communities and compare their average
susceptibility scores: Education ( Edu), Society and
Public ( S&P ), Health and Medicine ( H&M ), Fi-
nance and Business ( F&B ), Science and Technol-
ogy ( S&T ), Arts and Media ( A&M ), as well as N/A
for Twitter users who do not specify their occupa-
tion in their user descriptions.
The results are presented in Tab. 4. It is
worth noting that occupations within the A&M area
demonstrate comparatively higher susceptibility,
possibly because of their greater exposure to mis-
information and stronger emotional reactions. In
contrast, professions closely associated with S&T,
F&B ,H&M ,S&P , and Edu tend to exhibit lower
susceptibility to COVID-19 misinformation. These
findings reinforce the previous conclusions that
4Besides, we make sure each sampled user has posted
more than 100 historical tweets between January 2020 and
April 2021. For each user, we utilize the Twitter API to gather
their user descriptions and location information, after which
we extract and categorize their occupations from their self-
reported descriptions with ChatGPT in a zero-shot manner.expertise and knowledge in relevant fields serve
as protective factors against misinformation, espe-
cially for populations in the field of H&M (Nan
et al., 2022). Surprisingly, we notice that the S&T
group is the most susceptible among the unsuscep-
tible groups. For this, we have some speculations
about the underlying reasons; for example, some
people in the S&T community might have a higher
level of skepticism towards traditional institutions
and expertise, partly influenced by the culture that
values disruptive innovation5.
Occupation Suscep. # Users
N/A 4.6201 35145
Arts and Media -0.1504 12635
Science and Technology -2.2076 7170
Finance and Business -5.4192 5844
Health and Medicine -5.4762 6272
Society and Public -6.7747 10973
Education -7.8070 5261
Table 4: Susceptibility Distribution by Professional
Field . We present the average susceptibility scores,
estimated by our computational modeling, for 6 main
professional fields. H&M (highlighted in blue) tends to
have lower susceptibility to COVID-19 misinformation,
consistent with existing studies.
Figure 3: Susceptibility Distribution by U.S. State .
We plot the susceptibility score, estimated by our com-
putational modeling (with Bayesian smoothing), for
each state in the U.S. The average susceptibility score
in the overall U.S. (-2.87) is used as the threshold, with
scores above it displayed in red, and those below it in
blue. Due to insufficient data points, we are only dis-
playing data for 48 contiguous states within the U.S.
Geographical Community We further investi-
gate the geographical distribution of susceptibil-
ity to COVID-19 misinformation, specifically fo-
5We notice that Twitter users who don’t declare their occu-
pation in their user description ( N/A) exhibit a higher suscepti-
bility to COVID misinformation. This may be because those
who are willing to declare their profession are often public
figures who care more about their reputation.cusing on different U.S. states.6This analysis en-
ables us to explore the influence of political ideol-
ogy associated with different U.S. states (Gelman,
2008) on susceptibility to misinformation. Out of
the 100,000 users sampled from around the world,
25,653 users are from U.S. states with more than
200 users for each state. As shown in Fig. 3, the
distribution of susceptibility levels estimated by
our computational modeling is imbalanced across
U.S. states and demonstrates a certain degree of cor-
relation with political leanings. In general, states
known to have a more conservative population tend
to have relatively higher susceptibility scores, while
states that are considered more liberal have lower
scores. The average susceptibility score for users
in blue or red states is -3.66 and -2.82 respectively.7
We observe that 60% of the ten states with the high-
est susceptibility scores are red states, and 90% of
the ten states with the lowest susceptibility scores
are blue states. This trend corresponds with the con-
clusion observed in various previous studies, where
political ideology influences people’s perspectives
on scientific information (McCright et al., 2013;
Baptista et al., 2021; Imhoff et al., 2022). However,
it is important to acknowledge the limitations of
our analysis, as it solely reflects the estimated sus-
ceptibility distribution of the sampled users within
each state. In Appendix F, we present the aver-
age susceptibility scores calculated based on our
sampled users for each U.S. state, along with the
corresponding number of users.
7 Conclusion
In this work, we propose a computational approach
to efficiently model people’s latent susceptibility
to misinformation. While previous research on
susceptibility is heavily relied on self-reported be-
liefs collected from questionnaire-based surveys,
our model trained in a multi-task manner can
estimate user’s susceptibility levels only based
on their posting and sharing behaviors on social
media. When compared with human judgment,
our model shows highly aligned predictions on
a susceptibility comparison evaluation task. To
demonstrate the potential of our proposed compu-
6Given the imbalance in the number of users from different
U.S. states, we calculate average susceptibility scores for each
state with Bayesian smoothing. We use the overall mean and
overall standard deviation as priors, and the more users in the
state, the less the overall mean will affect that state’s score.
7Red and blue states are determined by the 2020 presiden-
tial election results, with red states leaning Republican and
blue states leaning Democratic.tational modeling in extending the scope of pre-
vious misinformation-related studies, we leverage
the susceptibility scores estimated by our model
to analyze factors that influence susceptibility to
COVID-19 misinformation. Our analysis considers
a diverse population from various professional and
geographical backgrounds, and the results obtained
through our computational modeling not only align
with but also support and extend the findings from
previous survey-based social science studies.
Limitations
Besides investigating the underlying mechanism of
misinformation propagation at a large scale, the sus-
ceptibility scores estimated by our model have the
potential to be used to visualize and interpret indi-
vidual and community vulnerability in information
propagation paths, identify users with high risks
of believing in false claims and take preventative
measures, and use as predictors for other human
behaviors. However, while our research represents
a significant step in computational modeling sus-
ceptibility to misinformation, several limitations
should be acknowledged.
First, our model provides insights into suscepti-
bility based on the available data and the features
we have incorporated. However, it’s important to
recognize that various other factors, both individ-
ual and contextual, may influence susceptibility to
misinformation. These factors, such as personal
experiences and offline social interactions, have not
been comprehensively incorporated into our mod-
eling and should be considered in future research.
Moreover, our modeled susceptibility scores rep-
resent an estimation of an individual’s likelihood
to engage with misinformation. These scores may
not always align perfectly with real-world suscep-
tibility levels. Actual susceptibility is a complex
interplay of cognitive, psychological, and social
factors that cannot be entirely captured through
computational modeling. Our modeling should be
viewed as a valuable tool for identifying trends
and patterns, rather than as a means for providing
definitive individual susceptibility assessments.
Additionally, we employ correlational analysis
to investigate the relationships between suscepti-
bility to misinformation and various factors, pro-
fessional and geographical backgrounds (§6). It is
crucial to note, however, that these correlations do
not imply causation. For example, while our find-
ings suggest an association between higher levelsof analytical thinking and reduced susceptibility to
misinformation, we cannot conclude that analyti-
cal thinking directly causes this low susceptibility.
The results suggest potential relationships that are
worth further investigation through causal research
methods to explore the underlying mechanisms of
these associations.
Finally, our study’s findings are based on a spe-
cific dataset and may not be fully generalizable to
all populations, platforms, or types of misinforma-
tion. Especially when examining the geographical
distribution of susceptibility, it’s important to note
that not all U.S. states have a sufficient amount
of Twitter data available for analysis, due to the
high cost of data collection. Furthermore, platform-
specific differences and variations in the types of
misinformation can potentially impact the effec-
tiveness of our modeling and the interpretation of
susceptibility scores.
Ethics Statement
Analyzing and modeling susceptibility to misin-
formation can potentially raise several ethical con-
cerns, particularly when applied at an individual
level. Due to its dual nature, our modeling can not
only be used to identify users with a high risk of
believing in misinformation and taking preventa-
tive measures to reduce harm, but it also holds the
potential for misuse by malicious actors, leading
to privacy violations, stigmatization, and targeted
attacks. To minimize the risk, we refrained from
using any personally identifiable information (PII)
data in our work. Nevertheless, it remains impor-
tant to carefully consider the ethical implications
associated with the deployment of computational
models like ours, enhance regulatory oversight, and
ensure responsible and transparent utilization.
We acknowledge the need for ongoing ethical
scrutiny and are committed to the responsible re-
lease of our trained model, and this includes re-
quiring users to sign a Data Use Agreement that
explicitly prohibits any malicious or harmful use
of our model. Within this agreement, researchers
and practitioners will also be required to acknowl-
edge the limitations (§7), that our modeling may
not fully or accurately represent an individual’s real
susceptibility level.
Acknowledgement
We would like to thank the anonymous re-
viewers and the lab members from StanfordSALT and UCLA for their valuable feed-
back. This work was sponsored by the
Defense Advanced Research Project Agency
(DARPA) grant HR00112290103/HR0011260656
and HR00112490370, the NSF grant IIS-2200274,
IIS-2106859 and IIS-2312501, as well as the NIH
grant U54HG012517 and U24DK097771.
References
Nasser Alsadhan and David Skillicorn. 2017. Estimat-
ing personality from social media posts. In 2017
IEEE international conference on data mining work-
shops (ICDMW) , pages 350–356. IEEE.
Sacha Altay, Anne-Sophie Hacquin, and Hugo Mercier.
2022. Why do so few people share fake news?
it hurts their reputation. New Media & Society ,
24(6):1303–1324.
João Pedro Baptista, Elisete Correia, Anabela Gradim,
and Valeriano Piñeiro-Naval. 2021. The influence
of political ideology on fake news belief: The por-
tuguese case. Publications , 9(2).
Kenneth A. Bollen. 2002. Latent variables in psychol-
ogy and the social sciences. Annual Review of Psy-
chology , 53(1):605–634. PMID: 11752498.
Denny Borsboom, Gideon J. Mellenbergh, and Jaap
van Heerden. 2003. The theoretical status of latent
variables. Psychological Review , 110(2):203–219.
Ryan L Boyd, Ashwini Ashokkumar, Sarah Seraj, and
James W Pennebaker. 2022. The development and
psychometric properties of liwc-22. Austin, TX: Uni-
versity of Texas at Austin , pages 1–47.
William J. Brady, Molly J. Crockett, Jay J. Van Bavel,
and Jay J. Van Bavel. 2020. The mad model of moral
contagion: The role of motivation, attention, and
design in the spread of moralized content online. Per-
spectives on Psychological Science , 15:1010 – 978.
Nadia M. Brashier and Daniel L. Schacter. 2020. Ag-
ing in an era of fake news. Current Directions in
Psychological Science , 29:316 – 323.
Rex Perez Bringula, Annaliza E. Catacutan, Manuel B.
Garcia, John Paul S. Gonzales, and Arlene Mae C.
Valderama. 2021. “who is gullible to political disin-
formation?” : predicting susceptibility of university
students to fake news. Journal of Information Tech-
nology & Politics , 19:165 – 179.
Wei Chen, Tie-Yan Liu, Yanyan Lan, Zhiming Ma, and
Hang Li. 2009. Ranking measures and loss functions
in learning to rank. In Neural Information Processing
Systems .
Lu Cheng, Ruocheng Guo, Kai Shu, and Huan Liu. 2021.
Causal understanding of fake news dissemination
on social media. In Proceedings of the 27th ACMSIGKDD Conference on Knowledge Discovery &
Data Mining , KDD ’21, page 148–157, New York,
NY , USA. Association for Computing Machinery.
Cindy K Chung and James W Pennebaker. 2018. What
do we know when we liwc a person? text analysis as
an assessment tool for traits, personal concerns and
life stories. The Sage handbook of personality and
individual differences , pages 341–360.
Limeng Cui and Dongwon Lee. 2020. Coaid: Covid-19
healthcare misinformation dataset.
Xiang Deng, Yu Gu, Boyuan Zheng, Shijie Chen, Sam
Stevens, Boshi Wang, Huan Sun, and Yu Su. 2024.
Mind2web: Towards a generalist agent for the web.
Advances in Neural Information Processing Systems ,
36.
Nicholas C. Dias, Gordon Pennycook, and David G.
Rand. 2020. Emphasizing publishers does not ef-
fectively reduce susceptibility to misinformation on
social media. Harvard Kennedy School Misinforma-
tion Review .
Ullrich K. H. Ecker, Stephan Lewandowsky, Jonathan
Cook, Philipp Schmid, Lisa K. Fazio, Nadia M.
Brashier, Panayiota Kendeou, Emily K. Vraga, and
Michelle A. Amazeen. 2022. The psychological
drivers of misinformation belief and its resistance
to correction. Nature Reviews Psychology , 1:13 – 29.
Álex Escolà-Gascón, Neil Dagnall, and Josep Gallifa.
2021. Critical thinking predicts reductions in span-
ish physicians’ stress levels and promotes fake news
detection. Thinking Skills and Creativity , 42:100934
– 100934.
Jeffrey L. Foster, Thomas Huthwaite, Julia A. Yesberg,
Maryanne Garry, and Elizabeth F. Loftus. 2012. Rep-
etition, not number of sources, increases both sus-
ceptibility to misinformation and confidence in the
accuracy of eyewitnesses. Acta psychologica , 139
2:320–6.
Andrew Gelman. 2008. Red state, blue state, rich state,
poor state: Why americans vote the way they do.
Jennifer Golbeck, Cristina Robles, Michon Edmondson,
and Karen Turner. 2011. Predicting personality from
twitter. In 2011 IEEE third international conference
on privacy, security, risk and trust and 2011 IEEE
third international conference on social computing ,
pages 149–156. IEEE.
Samrat Gupta, Gaurav Jain, and Amit Anand Tiwari.
2022. Polarised social media discourse during covid-
19 pandemic: evidence from youtube. Behaviour &
Information Technology , 42:227 – 248.
Kadhim Hayawi, Sakib Shahriar, Mohamed Adel Ser-
hani, Ikbal Taleb, and Sujith Samuel Mathew. 2021.
Anti-vax: a novel twitter dataset for covid-19 vaccine
misinformation detection. Public Health , 203:23 –
30.McKenzie Himelein-Wachowiak, Salvatore Giorgi,
Amanda Devoto, Muhammad Rahman, Lyle Ungar,
H. A. Schwartz, David H. Epstein, Lorenzo Leggio,
and Brenda L Curtis. 2021. Bots and misinformation
spread on social media: Implications for covid-19. J
Med Internet Res , 23.
Elad Hoffer and Nir Ailon. 2014. Deep metric learning
using triplet network. In International Workshop on
Similarity-Based Pattern Recognition .
Ming hui Li, Zhiqin Chen, and Li-Lin Rao. 2022. Emo-
tion, analytic thinking and susceptibility to misinfor-
mation during the covid-19 outbreak. Computers in
Human Behavior , 133:107295 – 107295.
Roland Imhoff, Felix Zimmer, Olivier Klein, João H. C.
António, Maria Babinska, Adrian Bangerter, Michal
Bilewicz, Nebojša Blanuša, Kosta Bovan, Rumena
Bužarovska, Aleksandra Cichocka, Sylvain Delou-
vée, Karen M. Douglas, Asbjørn Dyrendal, Tom
Etienne, Biljana Gjoneska, Sylvie Graf, Estrella
Gualda, Gilad Hirschberger, Anna Kende, Yordan
Kutiyski, Peter Krekó, Andre Krouwel, Silvia Mari,
Jasna Miloševi ´c Ðor ¯devi´c, Maria Serena Panasiti,
Myrto Pantazi, Ljupcho Petkovski, Giuseppina Por-
ciello, André Rabelo, Raluca Nicoleta Radu, Florin A.
Sava, Michael Schepisi, Robbie M. Sutton, Viren
Swami, Hulda Thórisdóttir, Vladimir Turja ˇcanin, Pas-
cal Wagner-Egger, Iris Žeželj, and Jan-Willem van
Prooijen. 2022. Conspiracy mentality and political
orientation across 26 countries. Nature Human Be-
haviour , 6(3):392–403.
A.K.M. Najmul Islam, Samuli Laato, Shamim Hayder
Talukder, and Erkki Sutinen. 2020. Misinformation
sharing and social media fatigue during covid-19: An
affordance and cognitive load perspective. Techno-
logical Forecasting and Social Change , 159:120201
– 120201.
Yoav Levine, Noam Wies, Daniel Jannai, Dan Navon,
Yedid Hoshen, and Amnon Shashua. 2022. The in-
ductive bias of in-context learning: Rethinking pre-
training example design. In International Conference
on Learning Representations .
Stephan Lewandowsky and Ullrich K. H. Ecker. 2012.
Psychological science in the public interest , in press
misinformation and its correction : Continued influ-
ence and successful debiasing.
Jiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan,
Lawrence Carin, and Weizhu Chen. 2022. What
makes good in-context examples for GPT-3? In
Proceedings of Deep Learning Inside Out (DeeLIO
2022): The 3rd Workshop on Knowledge Extrac-
tion and Integration for Deep Learning Architectures ,
pages 100–114, Dublin, Ireland and Online. Associa-
tion for Computational Linguistics.
Yanchen Liu, Timo Schick, and Hinrich Schtze. 2023.
Semantic-oriented unlabeled priming for large-scale
language models. In Proceedings of The Fourth
Workshop on Simple and Efficient Natural LanguageProcessing (SustaiNLP) , pages 32–38, Toronto,
Canada (Hybrid). Association for Computational Lin-
guistics.
Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-
dar Joshi, Danqi Chen, Omer Levy, Mike Lewis,
Luke Zettlemoyer, and Veselin Stoyanov. 2019.
Roberta: A robustly optimized bert pretraining ap-
proach. ArXiv , abs/1907.11692.
Sahil Loomba, Alexandre de Figueiredo, Simon J Piatek,
Kristen de Graaf, and Heidi Jane Larson. 2021. Mea-
suring the impact of covid-19 vaccine misinformation
on vaccination intent in the uk and usa. Nature Hu-
man Behaviour , 5:337 – 348.
Mingyu Derek Ma, Alexander K. Taylor, Nuan Wen,
Yanchen Liu, Po-Nien Kung, Wenna Qin, Shicheng
Wen, Azure Zhou, Diyi Yang, Xuezhe Ma, Nanyun
Peng, and Wei Wang. 2023. Middag: Where does
our news go? investigating information diffusion
via community-level information pathways. ArXiv ,
abs/2310.02529.
Aaron M. McCright, Katherine E. Dentzman, Meghan
Charters, and Thomas Dietz. 2013. The influence of
political ideology on trust in science. Environmental
Research Letters , 8.
Amy Mitchell, Jeffrey Gottfried, Galen Stocking, Ma-
son Walker, and Sophia Fedeli. 2019. Many amer-
icans say made-up news is a critical problem that
needs to be fixed. Pew Research Center , 5:2019.
Xiaoli Nan, Yuan Wang, and Kathryn Thier. 2020.
Health misinformation.
Xiaoli Nan, Yuan Wang, and Kathryn Thier. 2022. Why
do people believe health misinformation and who is
at risk? a systematic review of individual differences
in susceptibility to health misinformation. Social
science & medicine , 314:115398.
Gordon Pennycook and David G. Rand. 2017. Who
falls for fake news? the roles of bullshit receptiv-
ity, overclaiming, familiarity, and analytic thinking.
Journal of Personality .
Gordon Pennycook and David G. Rand. 2021. The psy-
chology of fake news. Trends in Cognitive Sciences ,
25:388–402.
Nils Reimers and Iryna Gurevych. 2019. Sentence-
BERT: Sentence embeddings using Siamese BERT-
networks. In Proceedings of the 2019 Conference on
Empirical Methods in Natural Language Processing
and the 9th International Joint Conference on Natu-
ral Language Processing (EMNLP-IJCNLP) , pages
3982–3992, Hong Kong, China. Association for Com-
putational Linguistics.
Jon Roozenbeek, Rakoen Maertens, Stefan M. Herzog,
Michael Geers, Ralf H.J.M. Kurvers, Mubashir Sul-
tan, and Sander van der Linden. 2022a. Susceptibil-
ity to misinformation is consistent across question
framings and response modes and better explained bymyside bias and partisanship than analytical thinking.
Judgment and Decision Making .
Jon Roozenbeek, Claudia R. Schneider, Sarah Dryhurst,
John R. Kerr, Alexandra L. J. Freeman, Gabriel Rec-
chia, Anne Marthe van der Bles, and Sander van der
Linden. 2020. Susceptibility to misinformation about
covid-19 around the world. Royal Society Open Sci-
ence, 7.
Jon Roozenbeek, Sander van der Linden, Beth Goldberg,
Steve Rathje, and Stephan Lewandowsky. 2022b.
Psychological inoculation improves resilience against
misinformation on social media. Science Advances ,
8.
Jon Roozenbeek, Sander van der Linden, and Thomas
Nygren. Prebunking interventions based on “inocula-
tion” theory can cut sensor to misinformation cross
farming.
Leah R. Rosenzweig, Bence Bagó, Adam J. Berinsky,
and David G. Rand. 2021. Happiness and surprise
are associated with worse truth discernment of covid-
19 headlines among social media users in nigeria.
Harvard Kennedy School Misinformation Review .
Nikita A. Salovich, Amalia M. Donovan, Scott R. Hinze,
and David N. Rapp. 2020. Can confidence help ac-
count for and redress the effects of reading inaccurate
information? Memory & Cognition , 49:293–310.
Laura D. Scherer, Jonathon McPhetres, Gordon Penny-
cook, Allison Kempe, Larry A. Allen, Christopher E.
Knoepke, Channing E. Tate, and Daniel D. Matlock.
2020. Who is susceptible to online health misin-
formation? a test of four psychosocial hypotheses.
Health psychology : official journal of the Division
of Health Psychology, American Psychological Asso-
ciation .
Prerika R Sharma, Kimberley A. Wade, and Laura Job-
son. 2022. A systematic review of the relationship
between emotion and susceptibility to misinforma-
tion. Memory , 31:1 – 21.
Louise Sundararajan, Rachel Sing-Kiat Ting, Shu-Kai
Hsieh, and Seong-Hyeon Kim. 2022. Religion, cog-
nition, and emotion: What can automated text analy-
sis tell us about culture? The Humanistic Psycholo-
gist, 50(2):213.
Alexander K. Taylor, Nuan Wen, Po-Nien Kung, Ji-
aao Chen, Violet Peng, and W. Wang. 2023. Where
does your news come from? predicting information
pathways in social media. Proceedings of the 46th
International ACM SIGIR Conference on Research
and Development in Information Retrieval .
Cecilie Steenbuch Traberg and Sander van der Linden.
2022. Birds of a feather are persuaded together: Per-
ceived source credibility mediates the effect of politi-
cal bias on misinformation susceptibility. Personality
and Individual Differences .Sander van der Linden. 2022. Misinformation: suscep-
tibility, spread, and interventions to immunize the
public. Nature Medicine , 28:460 – 467.
Wei Wang, Ivan Hernandez, Daniel A Newman, Jibo
He, and Jiang Bian. 2016. Twitter analysis: Studying
us weekly trends in work stress and emotion. Applied
Psychology , 65(2):355–378.
Brian E. Weeks. 2015. Emotions, partisanship, and
misperceptions: How anger and anxiety moderate the
effect of partisan bias on susceptibility to political
misinformation. Journal of Communication , 65:699–
719.
Yuzhuang Xu, Shuo Wang, Peng Li, Fuwen Luo, Xi-
aolong Wang, Weidong Liu, and Yang Liu. 2023.
Exploring large language models for communica-
tion games: An empirical study on werewolf. arXiv
preprint arXiv:2309.04658 .
Kai-Cheng Yang, Francesco Pierri, Pik-Mai Hui, David
Axelrod, Christopher Torres-Lugo, John Bryden, and
Filippo Menczer. 2020. The covid-19 infodemic:
Twitter versus facebook. Big Data & Society , 8.
Rui Yang, Lin Song, Yanwei Li, Sijie Zhao, Yixiao Ge,
Xiu Li, and Ying Shan. 2024. Gpt4tools: Teaching
large language model to use tools via self-instruction.
Advances in Neural Information Processing Systems ,
36.A Potential Questions
We address here some potential questions readers
might have about our work:
What is the goal of the method design? We
aim to design a framework to estimate users’ sus-
ceptibility to misinformaion efficiently and scal-
ably - indirectly modeling their susceptibility with
a comprehensive representation of their observable
reposting behavior data, rather than training on
their ground-truth susceptibility levels. The sen-
tence embedding model (described in Appendix B)
is selected to create rich representations of users
and posts. Its effectiveness has been shown in ex-
isting works (Levine et al., 2022; Liu et al., 2022,
2023; Xu et al., 2023; Yang et al., 2024; Deng et al.,
2024).
Moreover, the focus of our work is to develop
a concise but reasonable framework for suscepti-
bility modeling and demonstrate its effectiveness,
rather than necessarily striving for the most optimal
model. There is other information that could be
used to model user susceptibility; however, most
of it is not easy to collect and hence goes against
our original motivation. We leave more complex
signals for future work.
Proposed framework lacks novelty? Multi-fold
novelty: Our work contributes to the literature in
multiple dimensions. 1) Proposing a brand new
task without existing data, baselines and evaluation
setup. Modeling user’s susceptibility efficiently
and empirically while no ground-truth suscepti-
bility to train or evaluate is provided; 2) Being
the first to make large-scale susceptibility analysis
possible, while previous works rely on expensive
self-reported human-collected questionnaires; 3)
Being the first large-scale analysis of the relation-
ship between susceptibility and social/psych. fac-
tors, professional backgrounds and geographical
distribution.
Conventional model is a secondary component
under a bigger framework: Even though we use
RoBERTa model trained in previous works to ob-
tain user and post embeddings, we are the first to
design an indirect estimation framework for sus-
ceptibility from users’ history. The off-the-shelf
sentence embedding model is a secondary compo-
nent and it can be replaced with other models, such
as LLMs.
Not just method novelty: The susceptibility mod-
eling framework/method is only one part of ourcontribution, and more importantly, our other im-
portant core contribution is the large-scale analy-
sis enabled by our proposed susceptibility model-
ing method and the interesting findings shown by
this large-scale analysis. These findings not only
corroborate the findings of previous questionnaire-
based studies (which are not possible to scaled-up)
but also showing the potential of extending the
scope of misinfo research.
Reposting behavior not sufficient to provide a
full understanding of believing? We acknowl-
edge that modeling the user’s susceptibility to mis-
information only with the supervision of their shar-
ing behavior on social media is a little bit limited.
However, other information, like “user’s intent be-
hind reposting”, is almost never indicated on any
social media, and intractable to large-scaly collect
and impossible to scale up, which goes against our
original motivation. And actually, only users them-
selves know their sharing intents, whether they are
expressing approval or perhaps irony, which we
believe are rare cases. Therefore, we propose to in-
fer a user’s susceptibility to misinformation based
solely on their historical tweets, because user’s his-
torical posts and reposting behavior are much easier
to collect. This not only enables effective model-
ing of user’s susceptibility and more importantly,
it enables large-scale analysis to help people better
understand the behind mechanism, patterns, influ-
encing factors and distribution of human’s suscep-
tibility to misinformation, which has been shown
in our work. We have also acknowledged the data
unavailability in the Limitations (§7) of this paper.
Why not use user personality features? We do
not explicitly incorporate additional user charac-
teristics into our modeling, because the additional
information is relatively difficult to get on social
media. However, users could display their personal-
ities, etc., user characteristics information through
their posts, thus justifying our design choice that
our modeling solely based on users’ historical posts
could also take these user characteristics into ac-
count. To further confirm our point, there are lots
of previous works proposing to predict/extract a
user’s personality from their posted or liked social
media posts (Golbeck et al., 2011; Alsadhan and
Skillicorn, 2017).
How reliable are LIWC scores used in analysis
in Section 6.1? LIWC is a widely used, well-
established, and convenient tool for analyzing textdata in the field of computational linguistics and
psychology. There are substantial works based on
LIWC analysis and the reliability of LIWC has
also been demonstrated in numerous studies across
various domains (Wang et al., 2016; Chung and
Pennebaker, 2018; Sundararajan et al., 2022; Boyd
et al., 2022).
Why not add more comparing baselines? We
work on a brand new task setting: estimate users’
susceptibility indirectly without any ground-truth
susceptibility labels provided. The only input to
the estimation model is users’ historical posts. The
unique setting prevents us from finding any prior
works that follow this challenging setting, which
makes it impossible for us to conduct a direct com-
parison with existing susceptibility works. Hence,
we come up with two methods: cosine similarity be-
tween embeddings and ChatGPT. We also observe
that cosine similarity is not a weak baseline, and it
yields even better performance than ChatGPT.
Why not include more ablation studies? Our
work mainly focuses on developing a novel frame-
work for susceptibility modeling and demonstrates
its potential to enable large-scale analysis and facil-
itate susceptibility and misinformation-related re-
search. Thus, we prioritize our emphasis on design-
ing a reasonable modeling, rather than necessarily
aiming for the optimal modeling. This is because,
as previously stated, the unobservable nature and
lack of ground truth for susceptibility prevent us
from directly optimizing the modeling for suscep-
tibility itself; instead, we can only do so for the
indirect sharing predictions task. Consequently, ab-
lation studies are of very limited significance in
this context. We believe that including too many
ablation studies could even deviate the audience’s
focus away from our research goals.
How to/what is the performance of adapting the
proposed framework to other domains besides
COVID-19? The advantage of our method is the
capability to estimate susceptibility without the
need for ground-truth user susceptibility labels. Us-
ing users’ historical posts, target posts, and users’
retweet behavior labels is sufficient to train the
model. We will release our code, and people can
try to robustness check it and extend it to more
domains.B Training Details
We use the sentence-transformers/all-roberta-
large-v1 model from sentence-transformers as
our sentence embedder. Through grid search on
learning rates ranging from 1e-5 to 5e-4 and λval-
ues from 0 to 1, we train our model using a learning
rate of 3e-5, set the hyperparameter λto 0.9, and
the margin αto 1 for 100 epochs on the training set,
as detailed in §3. Following the training process,
we select the checkpoint with the lowest validation
loss and proceed to evaluate its performance on the
test set.
C Human Judgement
Here, we provide details about the human judgment
framework utilized in our work.
During human judgment, annotators are tasked
with selecting the more susceptible user based on
five historical tweets for each user. We offer the
user interface used for human judgment in Figure 4.
In the task description, susceptibility is described
as being more likely to believe, be influenced by,
and propagate COVID-19 misinformation. To ac-
count for annotator uncertainty, we provide four
options: Definitely User A ,Probably User A ,Defi-
nitely User B , and Probably User B . Furthermore,
we also request annotators to identify the “most sus-
ceptible tweet” for the selected user, to enhance the
reliability of annotations. This tweet should best
exemplify the user’s susceptibility to COVID-19
misinformation or be the basis for the annotator’s
decision.
Also, it is important to note that even when both
users seem to have low susceptibility to COVID-
19 misinformation, we still ask the annotator to
make a choice. This is because our goal is to rank
users based on their relative susceptibility, offering
a comparative assessment rather than an absolute
determination.
In total, we randomly sampled 110 user pairs
and collected three annotations for each user pair.
We recruited human annotators from Amazon Me-
chanical Turk (AMT) in the U.S. and compensated
each annotator with $0.5 (hourly wage higher than
the federal minimum wage). To determine the gold
label for each user pair, we applied a weighted
majority voting approach, assigning a value of 0.5
toProbably User X and a value of 1 to Definitely
User X . We excluded user pairs with tied annota-
tions, resulting in a final dataset of 107 user pairs.
The kappa score for interrater agreement amongthe annotators is 0.74.
D Examples of User Posts and
Susceptibility Scores
Here we show some examples of users (character-
ized by their historical posts) and the susceptibility
scores estimated by our model for each user when
viewing a specific tweet. Please note that the target
tweets we are showing here are randomly sampled
COVID-19-related tweets, but they are not neces-
sarily misinformation posts. This also suggests that
our trained susceptibility model can be utilized to
estimate a user’s susceptibility to both misinforma-
tion and non-misinformation.
The user KatCapps ’s susceptibility score is esti-
mated as 38.62 when the user sees the tweet:
The coronavirus infection rate is still too
high. There will be a second wave | David
Hunter [Link]
History tweets posted by the user are:
•RT @gregggonsalves: Study estimates 24
states still have uncontrolled coronavirus
spread
•RT @JoeSudbay: OSHA chas not issued en-
forceable guidelines for protecting employees
from covid-19, as it did during the H1N1 out-
break in
•RT @mlipsitch: New Oped with @rickmalley
| Treating Mild Coronavirus Cases Could Help
Save Everyone - The New York Times
•RT @stevesilberman: Texas church that
rushed to reopen cancels masses after priest
dies and others contract #coronavirus.
•RT @carlzimmer: Several cases of coron-
avirus reported after a swim party in Arkansas,
governor says
•RT @GlennKesslerWP: They Survived the
Worst Battles of World War II. And Died of
the Virus.
Another user AmitSin91018424 ’s susceptibility
score is estimated as -12.27 when the user sees
the tweet:Dominic Cummings has broken Covid-
19 policy trust, say top scientists [Link]
History tweets posted by the user are:
•RT @guardian: The pandemic has laid bare
the failings of Britain’s centralised state | John
Harris
•RT @guardian: Coronavirus world map:
which countries have the most cases and
deaths?
E ChatGPT Prompt Template
In Fig. 5, we present the template used to prompt
ChatGPT for the susceptibility comparison task
(§5.1).
F Average Susceptibility Scores and User
Counts by U.S. State
We provide the aggregated susceptibility scores
estimated by our computational modeling for each
U.S. state (§6.2), along with the number of sampled
users in Tab. 5.Figure 4: Human Judgement Interface utilized in our work. Participants are instructed to select the more
susceptible user from a user pair based on five historical tweets for each user.
In this task, you will be presented with 2 Twitter users, each with 5 historical tweets presented in
chronological order. Your task is to determine which of the two users is more susceptible to COVID-
related misinformation, which we define as being more likely to believe, be influenced by, and
propagate such misinformation, e.g. through retweeting.
User A 's Historical Tweets:
{userA_text}
User B 's Historical Tweets:
{userB_text}
It is necessary to make a choice even if both users appear to have low susceptibility to COVID
misinformation.
In such cases, you must select the user who, in your judgment, is relatively more susceptible.
Please answer with one of the following options without any other text: A | B.
Figure 5: ChatGPT Prompt Template for the susceptibility comparison task.State Suscep. # Users State Suscep. # Users
Georgia 0.3935 669 Idaho -3.2296 265
Florida -0.2404 1592 Washington -3.2577 526
Arizona -0.5566 499 Montana -3.2590 543
Louisiana -1.3878 202 Oregon -3.2612 260
Ohio -1.6120 679 Utah -3.3324 206
Texas -1.7478 1627 Vermont -3.3548 556
Missouri -1.9076 308 Indiana -3.3901 270
Nevada -1.9857 294 Delaware -3.4139 359
Michigan -2.0996 575 Arkansas -3.4179 418
Alabama -2.3902 377 North Carolina -3.5324 635
Maryland -2.4763 527 South Dakota -3.6020 351
South Carolina -2.5456 298 Virginia -3.7276 528
Mississippi -2.5886 257 Oklahoma -3.7577 291
Maine -2.6193 208 New Hampshire -4.1011 399
Illinois -2.6294 816 Iowa -4.1603 249
Nebraska -2.6339 324 New York -4.4226 2835
Kansas -2.6541 328 West Virginia -4.8056 285
Kentucky -2.7774 469 Minnesota -4.8423 372
Colorado -2.8109 363 Pennsylvania -4.8700 873
Tennessee -2.8554 397 Rhode Island -5.0661 488
New Mexico -2.9178 518 Wisconsin -5.2446 279
Wyoming -2.9401 319 New Jersey -5.2594 598
North Dakota -2.9789 331 Connecticut -5.6912 242
California -3.2206 2849 Massachusetts -6.3191 761
Table 5: Susceptibility Scores Estimated by Our Computational Model and Number of Sampled Users per
U.S. State . Due to insufficient data points, we only consider 48 contiguous states within the U.S.