What Are the Odds?
Language Models Are Capable of Probabilistic Reasoning
Akshay Paruchuri*, Jake Garrison, Shun Liao, John Hernandez,
Jacob Sunshine, Tim Althoff, Xin Liu, Daniel McDuff
Google
akshay@cs.unc.edu, {althoff, xliucs, dmcduff}@google.com
Abstract
Language models (LM) are capable of remark-
ably complex linguistic tasks; however, numer-
ical reasoning is an area in which they fre-
quently struggle. An important but rarely eval-
uated form of reasoning is understanding prob-
ability distributions. In this paper, we focus
on evaluating the probabilistic reasoning capa-
bilities of LMs using idealized and real-world
statistical distributions. We perform a system-
atic evaluation of state-of-the-art LMs on three
tasks: estimating percentiles, drawing samples,
and calculating probabilities. We evaluate three
ways to provide context to LMs 1) anchoring
examples from within a distribution or fam-
ily of distributions, 2) real-world context, 3)
summary statistics on which to base a Normal
approximation. Models can make inferences
about distributions, and can be further aided
by the incorporation of real-world context, ex-
ample shots and simplified assumptions, even
if these assumptions are incorrect or misspec-
ified. To conduct this work, we developed a
comprehensive benchmark distribution dataset
with associated question-answer pairs that we
have released publicly.
1 Introduction
Language models (LMs) (Workshop et al., 2022;
Touvron et al., 2023; Achiam et al., 2023) are versa-
tile interfaces to knowledge, capable of remarkably
complex linguistic tasks. Summarization of com-
plex documents (Tang et al., 2023; Zhang et al.,
2024b), reasoning over long passages of text (Sha-
ham et al., 2022; Chen et al., 2023; Team et al.,
2023) and zero-shot inference in specialist domains
such as medicine (McDuff et al., 2023) are a few
examples that demonstrate their abilities. While
performance on primarily linguistic problems, can
often be strong, effectiveness on operations that
involve numerical reasoning is a domain that lan-
guage models have struggled with (Kojima et al.,
*Work completed during an internship at Google.
## Consider the following distribution:
  Type: Log-Normal Distribution
  Characteristics: This distribution models values that are the result of 
the multiplicative product of many independent random variables, 
such as income levels, stock prices, or city sizes.
  Log Mean (mu): 3.543
  Log Sigma (sigma): 0.677
  These parameters mean that the natural logarithm of the values 
follows a normal distribution with the speci�ed mean and 
standard deviation.
Your task is to estimate the percentile of a given average exercise 
minutes count value for a population that regularly uses Fitbit devices 
and is active on a daily basis. The data is �ltered for individuals aged 
18-65. The data is age-balanced and gender-balanced, and pe�ains 
to the U.S. population only.
Consider the following parameters that describe a normal distribution:
   Mean: 43.20
  Standard Deviation: 30.50
## Here is your question:
Question:
What is the percentile of the value 35 within the provided distribution?
Idealized Distribution + Real-World Context
+ Real-World Context & Normal Assumption
Predictions:Answer: 50th
Predictions:Answer: 80th
Predictions:Answer: 20th68th
60th
46th
95th
68th
75th
62th
11th
13thWhat is the percentile of 35 exercise minutes?
What is the percentile of $1800 monthly gross rent?
What is the percentile of 294mm precipitation?20000
15000
10000
4000060000
20000
05000Frequency Frequency Frequency0
5000
3000
2000
1000
017.5
15.0Mean Abs. Error (MAE)12.5
10.0
7.5
5.0
2.5
0.0
17.5
15.0Mean Abs. Error (MAE)12.5
10.0
7.5
5.0
2.5
0.0
17.5
15.0Mean Abs. Error (MAE)12.5
10.0
7.5
5.0
2.5
0.0
Exercise (minutes) Health
Monthly Gross Rent ($)
Precipitation (mm) ClimateFinance
Figure 1: LMs & Probabilistic Reasoning. Models can
make inferences about distributions, but can be aided by
the incorporation of real-world context, example shots
and simplified assumptions, even if these assumptions
are incorrect or misspecified.
1arXiv:2406.12830v3  [cs.CL]  30 Sep 20242022). Difficulties handling numbers may be due
to model pretraining formulations (e.g., using au-
toregressive next token prediction pretext tasks) or
numerical token representations not necessarily be-
ing suited to mathematical reasoning (Bachmann
and Nagarajan, 2024), or simply a limited represen-
tation of these types of tasks in the training corpora.
Nevertheless, some work suggests prompting tech-
niques can substantially improve LM performance
on numerical reasoning tasks, indicating that rel-
evant knowledge may already be encoded within
these models (Imani et al., 2023).
A form of numerical reasoning that is impor-
tant for interpreting many different forms of data
is contextualizing an individual measurement or
measurements (a sample or samples) within a pop-
ulation (a distribution). Drawing insights from data
frequently requires comparing and contrasting a
sample from other samples. This is because ab-
solute values in isolation can be hard to interpret,
without the context of how probable they are or
how close they are to the maximum or minimum
values observed across the population. Probabilis-
tic reasoning is something that the human brain
appears to do (Knill and Pouget, 2004) and that
is an important component in cognition (Chater
et al., 2006). Thinking probabilistically is efficient
as one does not have to represent every detail of
every sample that one observes, and instead can
have the data summarized with a small number of
parameters that describe the distribution (Lindskog
et al., 2021). Research has shown that some prob-
abilistic reasoning processes lead to superior per-
formance; for example, people are more accurate
at answering questions about statistical properties
when they estimate the full distribution first (Gold-
stein and Rothschild, 2014). Yet, there are limited
examples evaluating or improving on the proba-
bilistic reasoning by designing LMs that reason
over sets (Ozturkler et al., 2023).
Understanding the distributions is important in
many contexts. In population level data it is impor-
tant when gauging whether an individual behavior
is normative (e.g., Is sleeping 8 hours normal for a
college aged student?). In climatology, inferences
about distributions of temperature or precipitation
data on a given day of the year at a particular lo-
cation are important when determining if observed
events are typical or abnormal. Is a maximum tem-
perature of 35 °C likely to be observed in Seattle
every year?
In this work we propose and define a set of proba-bilistic reasoning tasks and use them to evaluate the
capabilities of LMs - estimating percentiles ,draw-
ing samples , and calculating probabilities . Next we
evaluate the impact of additional real-world context
and parametric assumptions (Normal distribution)
using the task of estimating percentiles (task choice
is motivated in Section 3).
To summarize our research questions:
1.Section 5.1: Provided with an idealized dis-
tribution, are language models able to accu-
rately answer questions about them? Does
this vary by the distribution family? Does
providing prompt examples from different dis-
tributions in the same family or samples from
the same distribution help? Do LMs simply re-
peat the nearest in-context example or is there
evidence of more complex LM behavior?
2.Section 6.2: Can an LM answer questions
about distributions in the world (e.g., income
in the US population)? Are LMs able to re-
trieve statistics and answer questions about
these distributions in a zero-shot manner?
3.Section 6.2: Using simple approximations
such as assuming a Normal distribution, can
we design prompts that lead to more accurate
answers to probabilistic reasoning questions?
To answer these questions we develop a distribu-
tion dataset with associated question-answer pairs
that we will release publicly. The dataset includes
questions about 12 families of standard, idealized
distributions (e.g., Normal or Power-law distribu-
tions) and distributions of real-world data from the
domains of population health, climate, and finance.
Code and additional results for our work can be
found here: https://github.com/yahskapar/
LLMs-and-Probabilistic-Reasoning .
2 Related Work
Language Models and Numerical Reasoning.
Working with numbers is necessary for many ev-
eryday tasks. Yet, while large language models
pretrained on vast numbers of documents exhibit
impressive linguistic capabilities, they often strug-
gle at tasks involving numerical reasoning (Sax-
ton et al., 2019; Kojima et al., 2022) (for a sur-
vey see Lu et al. (2022)). Different approaches to
numerical reasoning have been proposed, many
focusing on logical reasoning of mathematical
tasks (Geva et al., 2020; Imani et al., 2023; Yang
2et al., 2022; Webb et al., 2023). In quantitative
reasoning problems such as those in the domains of
mathematics, science, and engineering, the process
of fine-tuning models has been used to successfully
remedy weaknesses (Lewkowycz et al., 2022). Au-
tomatic generation of data can be used as a way
of obtaining training examples (Geva et al., 2020;
Liu et al., 2022). The fact that specific prompting,
such as providing examples, can improve the per-
formance of LMs on numerical tasks, suggests that
their training data may already include relevant
information to perform these tasks (Imani et al.,
2023; Yang et al., 2022). Benchmark datasets have
helped the research community to develop these
methods (e.g., (He-Yueya et al., 2023; Zhang et al.,
2024a; Liu et al., 2024)) further and automatic eval-
uation of numerical reasoning problems has been
proposed to help in cases where accuracy cannot
be computed mathematically (Cobbe et al., 2021).
Numerical Reasoning Prompt Design. Prompts
designed to handle automatically generated con-
tent (from an LM) were used to improve on nu-
merical and scientific commonsense reasoning
tasks (Liu et al., 2022). Algorithms and code are
useful tools when working with numbers, chain-of-
thought prompts have been designed to leverage
these specifically to improve the performance of
LMs on arithmetic problems (Imani et al., 2023;
Merrill et al., 2024). Retrieval of correlated-
examples (Yang et al., 2022), generating inter-
mediate reasoning steps (Gao et al., 2023) and
expressing reasoning as a program (Chen et al.,
2022) are examples that can also help improve
LM performance on mathematical and logic prob-
lems. Simple approaches such as zero-shot chain-
of-thought (Kojima et al., 2022) exist and are capa-
ble of leveraging multi-step reasoning, but for prob-
abilistic reasoning tasks lead to severely degraded
performance due to generally poor numerical rea-
soning performance.
Probabilistic Reasoning and Cognition. Inspira-
tion for AI systems is often drawn from our under-
standing of human cognition, cognitive science has
revealed insights about how humans can think prob-
abilistically (Cosmides and Tooby, 1996; Oaksford
and Chater, 2001) and can build representations of
relatively complex probability distributions (Lind-
skog et al., 2021), yet our perceptions of means
and variances are subject to biases (Tversky and
Kahneman, 1974). The thought processes people
use when answering questions about distributions
have an impact on their accuracy. Specifically, elic-iting a full distribution before computing summary
or sample statistics can make answers more accu-
rate (Goldstein and Rothschild, 2014).
3 Defining Probabilistic Reasoning Tasks
Our probabilistic reasoning benchmark contains
three distinct tasks that explore a language model’s
(LM’s) context-free (idealized) understanding of
basic, idealized distributions , we describe these
tasks as follows:
Task 1: Estimating Percentiles. Given a dis-
tribution, the model is asked for the percentile
a sample would appear in. A question is
composed of a value (a sample) that is calcu-
lated given the target percentile. The answer
is expected to be a numerical response from
0 to 100. The target percentiles utilized were
nst/th={1,10,20,30,40,50,60,70,80,90,99}.
Language models responses to these questions are
sampled 10 times with a random seed.
Return the percentile of the value {X} within
a normal distribution with mean {Y} and
standard deviation {Z}.
Task 2: Drawing Samples. Given a distribution
the model is asked to draw samples at random from
it. A random seed is used for each sample and
we repeat this 1000 times per distribution. The
language model is explicitly instructed to avoid
generating any code or using additional tools to
perform the sampling. The answer is expected to
be a numerical response.
Sample a number from the normal distribu-
tion with mean {X} and standard deviation
{Y}.
Task 3: Calculating Probabilities. Given a
distribution the model is asked for the probabil-
ity a sample from the distribution will fall be-
tween two given values. The target probabili-
ties and the corresponding target ranges are com-
puted based on a lower and upper quantile to form
examples with different probabilities in the set
P={0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0}.
The answer from the LM is expected to be a numer-
ical response from 0 to 1.
3=
Idealized Distributions Real-World Distributions
Figure 2: Distributions. A visualization of the 12 idealized and 12 real-world distributions across the domains of
health, finance, and climate involved in our evaluation.
Calculate the probability that a value falls
between {W} and {X} in a normal distribu-
tion with mean {Y} and standard dev. {Z}.
In order to evaluate the impact of real-world
context on LM probabilistic reasoning, we explore
distributions in the real-world that have additional
real-world context (e.g., prior knowledge and ex-
pectations about US household incomes). We then
leverage Task 1 of estimating percentiles to evalu-
ate to what degree real-world context impacts per-
formances. Task 1 is particularly well suited for
this exploration, as we later demonstrate that this
Task 1 elicits the highest variation in performance
across distribution families and the number of in-
context examples/shots (further detailed in Sec-
tion 6). In Appendix A we provide full prompt
templates for our three proposed benchmark tasks,
as well as further details regarding template compo-
nents and real-world distribution prompt templates.
4 Curating Data Distributions
We use two distinct datasets for the purpose of un-
derstanding the probabilistic reasoning capabilities
of LMs - a dataset of idealized distributions and a
dataset of real-world distributions . A visualization
of both datasets is shown in Figure 2.Idealized Distributions. We identify 12
families of distributions: Normal, Log-Normal,
Skew-Normal, Exponential, Power Law, Uniform,
Gamma, Gumbel, Poisson, Geometric, Binomial
and Multinomial. These encompass sets of distri-
butions identified (Frank, 2009) and tested in prior
studies (Goldstein and Rothschild, 2014). When an
LM is asked about an idealized distribution, a distri-
bution description is provided with parameters that
can range from simple parameters such as the mean
and standard deviation (e.g., for a Normal distribu-
tion) to less easily interpretable parameters such as
location and scale (e.g., for a Gumbel distribution).
Note that the distribution description does not in-
clude any distrbution probability density function
(PDF) or cumulative distribution function (CDF).
All parameters are captured in a popular, public
Python library for scientific computing - NumPy.
Real-World Distributions. We choose real-world
distributions from the domains of health, finance,
and climate for which there is presumed to be rele-
vant information in the model’s training set.
Health: We sample 100K Fitbit users from the U.S.
population, aged 18-65, and with at least 10 days
of data from the calendar year 2023. The dataset
was gender and age balanced (see Appendix). We
analyze four common wearable metrics (A)step
count, (B)resting heart rate, (C)sleep duration,
4and(D)exercise minutes. We aggregate this data
to obtain averages for each user and ultimately
distributions of daily metrics across 100K users.
In what percentile of the US population
would someone with an average of 6000
steps per day be?
Finance: We use public census data from the Cen-
sus Bureau’s American Community Survey (ACS)
Public Use Microdata Sample (PUMS) (Ruggles
et al., 2020) that contains measures of (E)annual
income, (F)monthly gross rent, (G)annual elec-
tricity costs, and (H)annual water costs ($) for
individuals and households in the US. We select
data from the calendar year 2018.
In what percentile of US households would
someone with a household income of
$70,000 be?
Climate: We use the public Global Historical Cli-
matology Network daily (GHCNd) dataset (Menne
et al., 2012) maintained by the National Oceanic
and Atmospheric Administration (NOAA) that con-
tains average daily measures for variables of (I)
temperature, (J)precipitation, (K)wind speed, and
(L)humidity level for weather stations across the
continental United States. We consider data from
the calendar year 2018 and filter erroneous mea-
sures indicated by measurement quality flags built
into the GHCNd dataset.
In what percentile would an average temper-
ature of 20 degrees Celsius be in the USA?
5 Experimental Setup
5.1 Idealized Distributions
Zero-shot Performance. We evaluate the zero-
shot performance of three LMs ( Gemini 1.0 Ultra ,
GPT4-Turbo , and GPT3.5-Turbo ) across our three
tasks and 12 idealized distributions. LM prompts
are generated as formulated in Section 3.
N-Shot Performance. We propose two types
of shots that might be reasonably employed for
the tasks - within distribution family distribution
shots andwithin distribution shots .Within distribu-
tion family distribution shots are examples from a
different distribution from the same family as the
current distribution in question. The distributionparameters of the variant are randomly sampled
from a specified range of reasonable parameter val-
ues. For example, if we are asking for a percentile
of a value in a normal distribution with a mean
of 100 and a standard deviation of 10, and we are
providing three shots, the randomized shots may be
generated from three variant normal distributions
with means of 108, 118, and 112 and corresponding
standard deviations of 13, 16, and 10. Within distri-
bution shots entail shots from the same distribution
that is being asked about in a question.
To help contextualize the performance in the
N-shot experiments, for the task of estimating per-
centiles we compare both shot types to a baseline
where the answer is picked based on the nearest
corresponding target percentile value in the shot
examples (i.e., the nearest neighbor). This base-
line does not perform any interpolation between
percentiles, which would be required for optimal
performance. If the LM performance exceeds this
baseline performance, it would suggest that the
LMs does perform some form of interpolation, in-
stead of simply reciting in-context examples.
We explicitly avoid using shots that involve
an answer that could be an answer to one of our
proposed questions. Specifically, we use nth
shots=
{5,15,25,35,45,55,65,75,85,95}andPshots =
{0.05,0.15,0.25,0.35,0.45,0.55,0.65,0.75,0.85,
0.95}. For example, if we are asking for a per-
centile of a value in a Normal distribution with
a mean of 100 and a standard deviation of 10,
and we are providing three shots, the mapped
shots will be generated from the same normal
distribution and correspond to 35.0, 55.0, and 75.0.
We sample LM responses 10 times per question
with a random seed. We provide further details,
including examples per shot type and shot count,
in our Section 8.
5.2 Real-World Distributions
Zero-shot Performance. We evaluate the zero-
shot performance of three LMs ( Gemini 1.0 Ultra ,
GPT4-Turbo , and GPT3.5-Turbo ) across the pro-
posed task of estimating percentiles in order to
evaluate an LM’s understanding of probabilistic
reasoning of the real-world distributions in the do-
mains of health, finance, and climate mentioned
in Section 4. We design prompts that contain in-
formation about the corresponding real-world data,
such as where it was sourced from, the year in time
for which the data is relevant, and any relevant fil-
tering that was done, this acts as context that we
5Zero Shot Answer Three Shot Answer Ground-Truth
Zero Shot MAE:
Three Shot MAE:
Zero Shot MAE:
Three Shot MAE:Zero Shot Answer Three Shot Answer Ground-Truth
MAE:
MAE:MAE:
MAE:MAE:
MAE:MAE:
MAE:
MAE:
MAE:MAE:
MAE:MAE:
MAE:MAE:
MAE:Task 1 Task 2 Task 3
Zero Shot 
Three Shot
Figure 3: Results on Idealized Distributions. Model results (top) estimating percentiles, (middle) drawing samples,
(bottom) estimating probabilities, for five common distributions (see Appendix B for results on all distributions).
refer to as “Real-World Context” in the remainder
of the paper. The prompts are built using 11 unique
target values that correspond to ground truth per-
centiles generated from the real-world data. We
sample LM responses 10 times per question with a
random seed.
Performance by Context. To investigate the ef-
fects of context, we compare two conditions: 1)
questions about an idealized distribution with com-
parable shape and parameters of the real-world dis-
tribution but no other context, and 2) questions
about the distribution with Real-World Context (see
examples in Appendix 8). Both conditions involve
a distribution description as mentioned in Section 3.
The prompts are again built using 11 unique target
values that correspond to ground truth percentiles
generated from the real-world data. We sample
Gemini 1.0 Ultra responses 10 times per question
with a random seed.
Simplified Assumptions. Certain real-world dis-
tributions found in Section 4 are Non-Normal. For
example, annual income follows a Power Law dis-
tribution. Despite not all distributions found in Sec-
tion 4 being perfectly Normal distributions, we de-
vise a prompting strategy that involves treating any
distribution in the prompt as a normal distributionwith a specified mean and standard deviation. This
approach can be further justified by the fact that,
despite characteristics such as skewedness being
present in real-world distributions, many distribu-
tions are similar to a Normal distribution. We quan-
titatively reinforce this observation using the Kol-
mogorov–Smirnov test (Chakravarti et al., 1967)
to show that even if the Normal equivalent is not
the best fit for a given real-world distribution, it
can be remarkably close as evidenced by the K-S
statistic. Additionally, we compare our proposed
Normal approximation approach to simply provid-
ing a question involving a real-world distribution
with three within distribution shots.
6 Experimental Results
We organize our results based on the research ques-
tions posed in Section 1. Alongside a concise an-
swer in bold, we provide discussion based on our
analysis of the experimental results.
6.1 Idealized Distributions
Q1: Are LMs able to accurately answer ques-
tions about idealized distributions in a zero-
shot setting? Answer :It varies, performance
on some idealized distributions is better than
6Model Percentiles (%) Sampling (K-S) Probabilities (%)
GPT3.5-Turbo 25.7±3.11 0 .73±0.07 32 .7±2.38
GPT4-Turbo 14.9±2.39 0.59 ±0.08 21.0±2.11
Gemini 1.0 Ultra 16.5±2.67 0 .76±0.09 19.4±2.26
Table 1: Aggregated zero-shot task performance
across different LMs. We evaluate zero-shot perfor-
mance for tasks such as percentiles, sampling, and
probabilities using Gemini 1.0 Ultra, GPT4-Turbo, and
GPT3.5-Turbo. For the tasks of estimating percentiles
and calculating probabilities, results are reported as
Mean Absolute Error (MAE) ±Standard Error ( σM).
For the task of drawing samples, the Mean K-S statistic
±Standard Error ( σM) is reported with all reported val-
ues having p <0.01.
Nearest Shot Within Family Shots Within Distribution Shots0510152025Mean Absolute Error (MAE)# Shots
0
1
3
5
7
9
Figure 4: Language models appear to interpolate
between in-context examples. Comparison of within
family and within distribution shot types to a baseline
where the answer is based on the nearest corresponding
shot to the target percentile value (nearest neighbor),
importantly the baseline does not perform any interpo-
lation between percentiles.
others. Discussion : Language model performance
varied considerably across families of distribution.
Zero-shot performance on the percentile task was
best for the uniform (MAE = 0.54%) and normal
(MAE = 2.29%) distributions (see Figure 3 for
examples and Figure 6 for more detailed results).
Furthermore, the performance of LMs on answer-
ing questions about distributions varied by task.
Estimating percentiles showed rather impressive
zero-shot performance (MAE ¯µ= 16.52, min =
0.54, max = 28.36). Calculating probabilities was
worse on average (MAE µ= 21.48, min = 9.03,
max = 32.53) and sampling performance was gen-
erally poor in the zero-shot case. In all cases,
providing shots (for different percentiles, samples
or probabilities) within a distribution improved the
performance substantially (Percentile ∆0→1shot=
+59.14%, Sampling ∆0→1shot= +55.26% K-S stat.,
Probability ∆0→1shot= +70.13%).
Q2: Does providing prompt examples from dif-
ferent distributions in the same family or sam-
ples from the same distribution help? Answer :
Providing within distribution shots helps morethan within family shots. Discussion : As illus-
trated in Figure 4, providing prompt examples
(shots) from different distributions from the same
family has less impact on the performance than pro-
viding prompt examples from the same distribution
in the question.
Q3: Do LMs simply repeat the nearest in-
context example? Answer :No, they appear to
perform some interpolation that is superior to
a nearest-in-context baseline. Discussion : We
observe that LM performance exceeds that of this
baseline ( Figure 4) which suggests that LMs per-
form some kind of interpolation, instead of simply
reciting in-context examples.
6.2 Real-World Distributions
Q4: What is the zero-shot accuracy of an LM on
distributions in the world (e.g., income in the US
population)? Answer :It varies, performance on
some real-world distributions is better than oth-
ers.Discussion : As shown in Table 2, LMs are ca-
pable of varying degrees of zero-shot performance
given different kinds of context. We consider the
real-world context as the primary baseline in our
investigation of real-world distributions, in contrast
to idealized, context-free versions of the same real-
world distributions and added context that simpli-
fies assumptions (e.g., Normal approximation). On
average with real-world context, Gemini 1.0 Ultra
has superior zero-shot performance on distributions
in the climate domain. In contrast, GPT4-Turbo
has superior zero-shot performance in the health
domain. Both Gemini 1.0 Ultra andGPT4-Turbo
had comparable performance on the finance do-
main while being superior to GPT3.5-Turbo . We
attribute these differences in zero-shot performance
to underlying differences in the large amounts of
training data used to train LMs, especially in the
case Gemini 1.0 Ultra andGPT4-Turbo .
Q5: Does the provided real-world context help
with probabilistic reasoning performance? An-
swer :Yes. Discussion : Figure 5 details both
distribution-wise and domain-wise results using
Gemini 1.0 Ultra with our four context categories
- idealized, real-world context, real-world context
with Normal approximation, and real-world context
with 3 shots. On average, adding real world-context
improves performance and adding real-world con-
text with a Normal approximation improves perfor-
mance still further. This trend is true on aggregate
but not for all individual distributions (e.g., rest-
ing heart rate). This observation appears to be
7Steps
Heart Rate Sleep Mins
Exercise MinsIncome
Gross RentElec CostWater CostTemperature Precipitation Wind SpeedHumidity0102030Mean Absolute Error (MAE)/uni000002ac/uni00000003/uni000002ad/uni00000002/uni00000079/uni000000d8/uni0000012e/uni000000eb/uni00000112/uni0000012e/uni0000010b/uni000000b4/uni0000010c/uni000000ce/uni000000d8/uni00000002/uni000000cd/uni00000158/uni00000002/uni0000007c/uni000000d8/uni000000b4/uni00000106/uni000002b2/uni00000152/uni00000112/uni0000012e/uni00000106/uni000000d4/uni00000002/uni00000024/uni000000f4/uni00000132/uni00000139/uni0000012e/uni000000f4/uni000000cd/uni0000013e/uni00000139/uni000000f4/uni00000112/uni0000010c
Idealized
+ Real-World Context
+ Real-World Context
& Normal Approximation
+ Real-World Context
& 3 Shots
HealthFinance Climate0102030
/uni00000297/uni00000297/uni00000297/uni000002ac/uni0000001d/uni000002ad/uni00000002/uni00000079/uni000000d8/uni0000012e/uni000000eb/uni00000112/uni0000012e/uni0000010b/uni000000b4/uni0000010c/uni000000ce/uni000000d8/uni00000002/uni000000cd/uni00000158/uni00000002/uni00000024/uni00000112/uni0000010b/uni000000b4/uni000000f4/uni0000010cFigure 5: Inferences can be aided by context and simplified assumptions. Mean absolute error in calculating
percentiles for real-world distributions with different prompts, including idealized distributions without real-world
context, added real-world context, and a Normal approximation approach that simplifies parameter content. (*)
designates p <0.05for all possible pairs using the Wilcoxon signed-rank test.
Health Finance Climate
Model Idealized Real-world Con. Norm. Approx. Idealized Real-world Con. Norm. Approx. Idealized Real-world Con. Norm. Approx.
GPT3.5-Turbo 20.5±9.62 20 .3±8.51 6 .81±0.68 17 .7±4.54 20 .4±2.88 7 .55±0.77 22 .7±6.88 25 .7±6.32 7 .90±0.22
GPT4-Turbo 11.0±4.94 4.92 ±3.18 3.15 ±00.76 8.99 ±1.18 10.7±3.24 5.50±0.48 18.5±6.53 15 .2±5.13 4.94±0.58
Gemini 1.0 Pro 25.30±8.41 11 .51±1.06 10 .42±1.32 29 .35±3.72 11 .77±0.92 10 .10±1.01 26 .20±5.44 18 .67±2.01 16 .53±1.94
Gemini 1.0 Ultra 12.8±4.43 10 .3±2.49 5 .89±1.09 14 .0±4.47 10.5±2.75 7.62±1.06 16.9±3.86 10.5 ±0.79 7.43±1.11
Table 2: Zero-shot performance by domain and context category across different LMs. All results are reported
as Mean Absolute Error (MAE) ±Standard Error ( σM) with (%) units.
restricted to distributions that already have a rea-
sonable baseline performance, we suspect that the
saturated performance conflicts with the model’s
ability to leverage real-world context and simpler
assumptions such as the Normal approximation.
Additionally, certain distributions such as house-
hold income show a decrease in performance when
Normal approximation is applied, likely because
the household income distribution follows a Power
Law distribution. It is unhelpful to apply a Normal
approximation on distributions that differ greatly
from a normal distribution. We empirically show
this with the same set of 12 idealized distributions
in Appendix D.3. Lastly, we note that real-world
context with 3 shots has the best performance. This
is unsurprising, and furthermore does not invalidate
the impact of simplified assumptions such as Nor-
mal approximation, which can be more efficient
due to not relying on 3 shots.
Q6: Do parametric assumptions such as a Nor-
mal approximation as a prompt design strategy
improve performance? Answer :Yes. Discussion :
On average across all domains, yes. The simple
assumption of a Normal distribution performs well
and when paired with real-world context, consis-
tently improves performance on real-world distribu-
tions (see Figure 5). This seems reasonable given
the aforementioned internal, potentially incorrect
representations of real-world distributions that LMscan have, and subsequently how stats such as mean
and standard deviation can help correct the LM’s
baseline knowledge. It is perhaps surprising that
performance improves relatively consistently, de-
spite the real-world distributions often differing
from an idealized Normal distribution and there-
fore the LM is being conditioned on a misspecified,
yet still helpful, model.
Q7: How do simpler assumptions such as a
Normal approximation compare to providing
three few-shot examples? Answer :Providing
three few-shot examples is generally better. Dis-
cussion : Generally speaking, providing three few-
shot examples is better and provides superior per-
formance across our proposed domain-specific
datasets of health, finance, and climate.
7 Conclusion
LMs are able to answer questions about idealized
and real-world distributions, with real-world re-
sults suggesting there is some internal representa-
tion that enables modeling or interpolation from
distribution parameters. The probabilistic reason-
ing performance of LMs varies, with certain distri-
butions (e.g., uniform, normal) having much bet-
ter performance in contrast to other distributions
(e.g., log-normal, skew-normal). Within distribu-
tion shots and context can improve probabilistic
8reasoning performance, as can a simplified Normal
approximation.
8 Limitations
Numerical calculation and reasoning remains an
area in which language models, even very large
models, tend to perform poorly. Making approx-
imations based on distributions is effective; how-
ever, it may also be a source of potential biases.
Our experiments have not focused on a deep ex-
ploration of the ability of language models to rep-
resent and answer questions about extreme values,
such as outliers in distributions. Our results do
suggest that language model particularly struggle
with accounting for extreme values in very skewed
(long-tail) distributions. In computing percentiles
the model would often overestimate the percentiles
(and thus underestimate the presence of extreme
values) - see the Power Law family results in Fig. 6
of our appendices. Our work shows that, despite
some promising zero-shot performance and ways
to improve that performance, language models re-
quire more improvements with Non-Uniform and
Non-Normal distributions before they are capable
of being relied on for probabilistic reasoning of
real-world distributions that follow other distribu-
tions (e.g., Power Law). We hope our insights as a
part of this work, as well as our proposed tasks and
datasets critical to probabilistic reasoning and to be
publicly released, prove valuable to the community
at large and their efforts to make language models
more useful, safer, and ultimately more reliable.
9References
Josh Achiam, Steven Adler, Sandhini Agarwal, Lama
Ahmad, Ilge Akkaya, Florencia Leoni Aleman,
Diogo Almeida, Janko Altenschmidt, Sam Altman,
Shyamal Anadkat, et al. 2023. Gpt-4 technical report.
arXiv preprint arXiv:2303.08774 .
Gregor Bachmann and Vaishnavh Nagarajan. 2024. The
pitfalls of next-token prediction. arXiv preprint
arXiv:2403.06963 .
Indra Mohan Chakravarti, Radha Govira Laha, and Jo-
gabrata Roy. 1967. Handbook of methods of applied
statistics. Wiley Series in Probability and Mathemati-
cal Statistics (USA) eng .
Nick Chater, Joshua B Tenenbaum, and Alan Yuille.
2006. Probabilistic models of cognition: Conceptual
foundations. Trends in cognitive sciences , 10(7):287–
291.
Shouyuan Chen, Sherman Wong, Liangjian Chen, and
Yuandong Tian. 2023. Extending context window of
large language models via positional interpolation.
arXiv preprint arXiv:2306.15595 .
Wenhu Chen, Xueguang Ma, Xinyi Wang, and
William W Cohen. 2022. Program of thoughts
prompting: Disentangling computation from reason-
ing for numerical reasoning tasks. arXiv preprint
arXiv:2211.12588 .
Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian,
Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias
Plappert, Jerry Tworek, Jacob Hilton, Reiichiro
Nakano, et al. 2021. Training verifiers to solve math
word problems. arXiv preprint arXiv:2110.14168 .
Leda Cosmides and John Tooby. 1996. Are humans
good intuitive statisticians after all? rethinking some
conclusions from the literature on judgment under
uncertainty. cognition , 58(1):1–73.
Steven A Frank. 2009. The common patterns of nature.
Journal of evolutionary biology , 22(8):1563–1585.
Luyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon,
Pengfei Liu, Yiming Yang, Jamie Callan, and Gra-
ham Neubig. 2023. Pal: Program-aided language
models. In International Conference on Machine
Learning , pages 10764–10799. PMLR.
Mor Geva, Ankit Gupta, and Jonathan Berant. 2020.
Injecting numerical reasoning skills into language
models. In Proceedings of the 58th Annual Meet-
ing of the Association for Computational Linguistics ,
pages 946–958.
Daniel G Goldstein and David Rothschild. 2014. Lay
understanding of probability distributions. Judgment
and Decision making , 9(1):1–14.
Joy He-Yueya, Gabriel Poesia, Rose E Wang, and
Noah D Goodman. 2023. Solving math word prob-
lems by combining language models with symbolic
solvers. arXiv preprint arXiv:2304.09102 .Shima Imani, Liang Du, and Harsh Shrivastava. 2023.
Mathprompter: Mathematical reasoning using large
language models. arXiv preprint arXiv:2303.05398 .
David C Knill and Alexandre Pouget. 2004. The
bayesian brain: the role of uncertainty in neural cod-
ing and computation. TRENDS in Neurosciences ,
27(12):712–719.
Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yu-
taka Matsuo, and Yusuke Iwasawa. 2022. Large lan-
guage models are zero-shot reasoners. Advances in
neural information processing systems , 35:22199–
22213.
Aitor Lewkowycz, Anders Andreassen, David Dohan,
Ethan Dyer, Henryk Michalewski, Vinay Ramasesh,
Ambrose Slone, Cem Anil, Imanol Schlag, Theo
Gutman-Solo, et al. 2022. Solving quantitative rea-
soning problems with language models. Advances
in Neural Information Processing Systems , 35:3843–
3857.
Marcus Lindskog, Pär Nyström, and Gustaf Gredebäck.
2021. Can the brain build probability distributions?
Frontiers in Psychology , 12:596231.
Jiacheng Liu, Alisa Liu, Ximing Lu, Sean Welleck, Pe-
ter West, Ronan Le Bras, Yejin Choi, and Hannaneh
Hajishirzi. 2022. Generated knowledge prompting
for commonsense reasoning. In Proceedings of the
60th Annual Meeting of the Association for Compu-
tational Linguistics (Volume 1: Long Papers) , pages
3154–3169.
Xiao Liu, Zirui Wu, Xueqing Wu, Pan Lu, Kai-Wei
Chang, and Yansong Feng. 2024. Are llms capable
of data-based statistical and causal reasoning? bench-
marking advanced quantitative reasoning with data.
arXiv preprint arXiv:2402.17644 .
Pan Lu, Liang Qiu, Wenhao Yu, Sean Welleck, and
Kai-Wei Chang. 2022. A survey of deep learn-
ing for mathematical reasoning. arXiv preprint
arXiv:2212.10535 .
Daniel McDuff, Mike Schaekermann, Tao Tu, Anil
Palepu, Amy Wang, Jake Garrison, Karan Sing-
hal, Yash Sharma, Shekoofeh Azizi, Kavita Kulka-
rni, et al. 2023. Towards accurate differential diag-
nosis with large language models. arXiv preprint
arXiv:2312.00164 .
Matthew J Menne, Imke Durre, Russell S V ose, Byron E
Gleason, and Tamara G Houston. 2012. An overview
of the global historical climatology network-daily
database. Journal of atmospheric and oceanic tech-
nology , 29(7):897–910.
Mike A. Merrill, Akshay Paruchuri, Naghmeh Rezaei,
Geza Kovacs, Javier Perez, Yun Liu, Erik Schenck,
Nova Hammerquist, Jake Sunshine, Shyam Tai-
lor, Kumar Ayush, Hao-Wei Su, Qian He, Cory Y .
McLean, Mark Malhotra, Shwetak Patel, Jiening
Zhan, Tim Althoff, Daniel McDuff, and Xin Liu.
102024. Transforming wearable data into health in-
sights using large language model agents. Preprint ,
arXiv:2406.06464.
Mike Oaksford and Nick Chater. 2001. The probabilis-
tic approach to human reasoning. Trends in cognitive
sciences , 5(8):349–357.
Batu Ozturkler, Nikolay Malkin, Zhen Wang, and Nebo-
jsa Jojic. 2023. Thinksum: Probabilistic reasoning
over sets using large language models. In Proceed-
ings of the 61st Annual Meeting of the Association for
Computational Linguistics (Volume 1: Long Papers) ,
pages 1216–1239.
Steven Ruggles, Sarah Flood, Ronald Goeken, Josiah
Grover, Erin Meyer, Jose Pacas, and Matthew Sobek.
2020. Ipums usa: version 10.0 [dataset]. Minneapo-
lis, Mn: Ipums , 10:D010.
David Saxton, Edward Grefenstette, Felix Hill, and
Pushmeet Kohli. 2019. Analysing mathematical rea-
soning abilities of neural models. arXiv preprint
arXiv:1904.01557 .
Uri Shaham, Elad Segal, Maor Ivgi, Avia Efrat, Ori
Yoran, Adi Haviv, Ankit Gupta, Wenhan Xiong, Mor
Geva, Jonathan Berant, et al. 2022. Scrolls: Stan-
dardized comparison over long language sequences.
arXiv preprint arXiv:2201.03533 .
Liyan Tang, Zhaoyi Sun, Betina Idnay, Jordan G Nestor,
Ali Soroush, Pierre A Elias, Ziyang Xu, Ying Ding,
Greg Durrett, Justin F Rousseau, et al. 2023. Eval-
uating large language models on medical evidence
summarization. npj Digital Medicine , 6(1):158.
Gemini Team, Rohan Anil, Sebastian Borgeaud,
Yonghui Wu, Jean-Baptiste Alayrac, Jiahui Yu,
Radu Soricut, Johan Schalkwyk, Andrew M Dai,
Anja Hauth, et al. 2023. Gemini: a family of
highly capable multimodal models. arXiv preprint
arXiv:2312.11805 .
Hugo Touvron, Louis Martin, Kevin Stone, Peter Al-
bert, Amjad Almahairi, Yasmine Babaei, Nikolay
Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti
Bhosale, et al. 2023. Llama 2: Open founda-
tion and fine-tuned chat models. arXiv preprint
arXiv:2307.09288 .
Amos Tversky and Daniel Kahneman. 1974. Judgment
under uncertainty: Heuristics and biases: Biases in
judgments reveal some heuristics of thinking under
uncertainty. science , 185(4157):1124–1131.
Taylor Webb, Keith J Holyoak, and Hongjing Lu. 2023.
Emergent analogical reasoning in large language
models. Nature Human Behaviour , 7(9):1526–1541.
BigScience Workshop, Teven Le Scao, Angela Fan,
Christopher Akiki, Ellie Pavlick, Suzana Ili ´c, Daniel
Hesslow, Roman Castagné, Alexandra Sasha Luc-
cioni, François Yvon, et al. 2022. Bloom: A 176b-
parameter open-access multilingual language model.
arXiv preprint arXiv:2211.05100 .Zhicheng Yang, Jinghui Qin, Jiaqi Chen, Liang Lin,
and Xiaodan Liang. 2022. Logicsolver: Towards in-
terpretable math word problem solving with logical
prompt-enhanced learning. In Findings of the Associ-
ation for Computational Linguistics: EMNLP 2022 ,
pages 1–13.
Hugh Zhang, Jeff Da, Dean Lee, Vaughn Robinson,
Catherine Wu, Will Song, Tiffany Zhao, Pranav Raja,
Dylan Slack, Qin Lyu, et al. 2024a. A careful exami-
nation of large language model performance on grade
school arithmetic. arXiv preprint arXiv:2405.00332 .
Tianyi Zhang, Faisal Ladhak, Esin Durmus, Percy Liang,
Kathleen McKeown, and Tatsunori B Hashimoto.
2024b. Benchmarking large language models for
news summarization. Transactions of the Associa-
tion for Computational Linguistics , 12:39–57.
11Overview of Appendices
The appendix is organized as follows:
Appendix A contains additional experimental de-
tails related to the usage of idealized distribu-
tion prompts, examples of idealized distribution
prompts used in Section 5.1, per task, as well as
distribution description examples, and examples of
few-shots.
Appendix B contains 3x4 summary figures corre-
sponding to idealized distribution results described
in Section 6.1.
Appendix C contains examples of real-world dis-
tribution prompts used in Section 5.2.
Appendix D contains additional model-wise ex-
perimental results that extend Table 1 and Table 2,
normal approximation results that show whether
or not invoking the true distribution name makes a
difference, and results for Chain-of-Thought (CoT)
and code tool-use.
Appendix E contains our broader impacts state-
ment.
A Idealized Distribution
A.1 Experimental Details
To systematically investigate performance on ide-
alized distributions using the three proposed tasks
ofestimating percentiles ,drawing samples , and
calculating probabilities , our method involves sets
of questions, or in the case of drawing samples ,
a command, that systematically tests the model’s
knowledge of a given distribution. In addition to
investigating our proposed tasks in a zero-shot set-
ting, we consider two different ways of providing
in-context examples (shots) in the prompt - within
family shots andwithin distribution shots .
Zero-shot Performance. We evaluate the zero-
shot performance of three LMs ( Gemini 1.0 Ultra ,
GPT4-Turbo , and GPT3.5-Turbo ) across our pro-
posed tasks of estimating percentiles ,drawing sam-
ples, and calculating probabilities in order to eval-
uate an LM’s understanding of probabilistic rea-
soning of the 12 idealized distributions described
in Section 4. LM prompts are generated as formu-
lated in Section 3.
Performance by Shot Type. We propose two shot
types used across the aforementioned tasks - within
distribution family distribution shots andwithin dis-
tribution shots .Within distribution family distribu-
tion shots entail randomized shots from a different
variant of the distribution being asked about in a
question. The distribution parameters of the variantare randomly sampled from a specified range of
reasonable parameter values. For example, if we
are asking for a percentile of a value in a normal
distribution with a mean of 100 and a standard de-
viation of 10, and we are providing three shots, the
randomized shots may be generated from three vari-
ant normal distributions with means of 108, 118,
and 112 and corresponding standard deviations of
13, 16, and 10. Within distribution shots entail
shots from the exact same distribution that is being
asked about in a question. The shots are mapped
per shot count to allow for a reasonable spread of
shots throughout the distribution.
Additionally, for the task of estimating per-
centiles , we compare both shot types to a baseline
where the LM is asked to pick from one or more
shots’ answer based on the nearest corresponding
target percentile value. This baseline represents
a nearest neighbor approach using the set of in-
context examples. This baseline makes appropri-
ate use of the information given to the model, but
importantly does not perform any interpolation be-
tween percentiles, which would be required for
strong performance. If LM performance exceeded
baseline performance, this would suggest that LMs
perform some kind of interpolation, instead of sim-
ply reciting in-context examples.
To avoid biasing our results, in the case of the
estimating percentiles andcalculating probabilities
tasks, we explicitly avoid using shots that involve
an answer (percentile or probability respectively)
that could potentially be an answer to one of our
proposed questions. Specifically, we use nth
shots=
{5,15,25,35,45,55,65,75,85,95}andPshots =
{0.05,0.15,0.25,0.35,0.45,0.55,0.65,0.75,0.85,
0.95}. For example, if we are asking for a per-
centile of a value in a normal distribution with a
mean of 100 and a standard deviation of 10, and
we are providing three shots, the mapped shots will
be generated from the same normal distribution
and correspond to 35.0, 55.0, and 75.0. We sample
Gemini 1.0 Ultra responses 10 times per question
with a random seed. Then, we elect to average and
effectively use all answers as a part of our final
evaluation in order to help capture the variability
in language model responses and provide a broader
understanding of their reasoning capabilities.
This effectively is a form of self-consistency. We
provide further details, including examples per
shot type and shot count, in our Section 8.
Key LM Parameters for Reproducibility. Lan-
guage models typically have additional parameters,
12such as temperature and sampling strategies, which
have default settings that can vary from model to
model. For Gemini 1.0 Ultra ,GPT4-Turbo , and
GPT3.5-Turbo , we utilize a default temperature of
0.7 for all of our experiments because we empir-
ically discovered that a temperature of 0.7 to 0.9
with a random seed yielded similar, optimal per-
formance on a hold-out dataset. A temperature of
0.7 also happens to be a default for many language
models, such as various versions of the GPT and
Gemini family models. Unless noted otherwise,
results are obtained using a random seed.
Additional hyperparameters, such as frequency
and brevity penalties, are not utilized in our experi-
ments. We define a frequency penalty as a penalty
that is applied proportional to how many times a to-
ken has appeared in the response and prompt. We
define a brevity penalty as a penalty that targets
responses that are very short, for example transla-
tions that contain only a few words. The nature
of our proposed probabilistic reasoning questions,
where the final answer from the instruction-tuned
language model is always a single, numerical an-
swer that is constrained by the prompt (for example,
percentile answers of 25.3, 55.7, and 82.1) means
that in both cases these penalties are not particu-
larly relevant or effective at producing optimal an-
swers. We utilized the default decoding approach
for each model, with a default top-p (0.95), and
where applicable, top-k (40).
13A.2 Prompt Examples
Percentile Example
## You are an expert on statistics. Your task is to estimate the percentile of a number within a specific distribution.
Answer with just a numerical response from 0 to 100. Make sure your final answer is enclosed by xml tags <answer>
and </answer>.
## Here are some examples to help you understand the task:
{few_shot_examples}
## Consider the following distribution:
{distribution_description}
## Here is your question:
Question:
What is the percentile of the value {target_number} within the provided distribution?
Answer:
Sampling Example
## You are an expert on statistics. Your task is to sample a number from a given distribution. Do not write any code or
use any additional tools to perform the sampling. Answer with just a numerical response. Make sure your final answer
is enclosed by xml tags <answer> and </answer>.
## Here are some examples to help you understand the task:
{few_shot_examples}
## Consider the following distribution:
{distribution_description}
## Instruction: Sample a number from the given distribution and output only the numerical value.
Probability Example
## You are an expert on statistics. Your task is to estimate the probability of being in a range of values within a given
distribution. Answer with just a numerical response from 0 to 1, representing the probability. Make sure your final
answer is enclosed by xml tags <answer> and </answer>.
## Here are some examples to help you understand the task:
{few_shot_examples}
## Consider the following distribution:
{distribution_description}
## Here is your question:
Question:
Considering only values including and between the 1st percentile and the 99th percentile, what is the probability that a
value from the provided distribution is between {lower_target_number} and{upper_target_number} ?
Answer:
14A.2.1 Distribution Description Examples
Normal
Distribution Type: Normal Distribution
Mean: {mean}
Standard Deviation: {std}
Log-Normal
Distribution Type: Log-Normal Distribution
Characteristics: This distribution models values that are the result of the multiplicative product of many independent random variables, such as income levels, stock prices, or city
sizes Log Mean (mu): {mean}
Log Sigma (sigma): {sigma}
These parameters mean that the natural logarithm of the values follows a normal distribution with the specified mean and standard deviation.
Exponential
Distribution Type: Exponential Distribution
Characteristics: Models the time between events in a process where events occur continuously and independently at a constant average rate.
Rate: {rate} (The average number of events per unit time is {1/rate:.2f} .)
Power Law
Distribution Type: Power Law Distribution
Characteristics: Known for its heavy tails suitable for describing phenomena with a high incidence of extreme values.
Alpha: {alpha} (Controls the tail heaviness—the smaller the alpha, the fatter the tail.)
Xmin: {xmin} (Minimum value for which the power law behavior holds.)
Uniform
Distribution Type: Uniform Distribution
Characteristics: All values within the interval have equal probability of occurring.
Min: {a}(Minimum value of the distribution.)
Max: {b}(Maximum value of the distribution.)
Gamma
Distribution Type: Gamma Distribution
Characteristics: Used to model waiting times and life data among other things.
Shape: {shape} (Controls the skewness of the distribution.)
Scale: {scale} (Controls the spread of the distribution.)
Skew-Normal
Distribution Type: Skew-Normal Distribution
Characteristics: A generalization of the normal distribution to accommodate skewness.
Location: {location} (Shifts the distribution along the x-axis.)
Scale: {scale} (Controls the spread of the distribution.)
Skew: {skew} (Determines the direction and degree of skewness.)
Gumbel
Distribution Type: Gumbel Distribution
Characteristics: Often used to model the distribution of extreme values.
Location: {loc} (Centers the distribution.)
Scale: {scale} (Controls the spread of the distribution.)
Poisson
Distribution Type: Poisson Distribution
Characteristics: Suitable for modeling the number of events happening in a fixed interval of time or space.
Lambda: {lam} (Average rate of events per interval.)
Geometric
Distribution Type: Geometric Distribution
Characteristics: Models the number of trials until the first success.
Probability of Success: {p}
15Binomial
Distribution Type: Binomial Distribution
Characteristics: Describes the number of successes in a fixed number of trials with a given probability of success.
Trials: {n}(Total number of trials.)
Probability of Success: {p}(Probability of success in each trial.)
Multinomial
Distribution Type: Multinomial Distribution
Characteristics: Generalizes the binomial distribution for scenarios where each trial can result in more than two outcomes.
Trials: {n}(Total number of trials.)
Probabilities: {probs}
A.2.2 Examples of Few-shots
Within Family Shots
Example 1:
Distribution:
Distribution Type: Normal Distribution
Mean: 80
Standard Deviation: 10
Question:
What is the percentile of 74.722 within the provided distribution?
Answer:
<answer>30.0</answer>
Example 2:
Distribution:
Distribution Type: Normal Distribution
Mean: 108
Standard Deviation: 13
Question:
What is the percentile of 107.903 within the provided distribution?
Answer:
<answer>50.0</answer>
Example 3:
Distribution:
Distribution Type: Normal Distribution
Mean: 82
Standard Deviation: 8
Question:
What is the percentile of 88.708 within the provided distribution?
Answer:
<answer>80.0</answer>
16Within Distribution Shots
Example 1:
Distribution:
Distribution Type: Normal Distribution
Mean: 100
Standard Deviation: 10
Question:
What is the percentile of 96.183 within the provided distribution?
Answer:
<answer>35.0</answer>
Example 2:
Distribution
Distribution Type: Normal Distribution
Mean: 100
Standard Deviation: 10
Question:
What is the percentile of 101.298 within the provided distribution?
Answer:
<answer>55.0</answer>
Example 3:
Distribution:
Distribution Type: Normal Distribution
Mean: 100
Standard Deviation: 10
Question:
What is the percentile of 106.802 within the provided distribution?
Answer:
<answer>75.0</answer>
17B Idealized Distributions Results Summaries
You are an expe� on statistics. Your task is to estimate the percentile of a number within a speci�c distribution.
Answer with just a numerical response from 0 to 100. Make sure your �nal answer is enclosed by xml tags <answer> and </answer>.
Consider the following distribution:
\textbf{\{distribution\_description\}} 
Here is your question:
Question:  What is the percentile of the value \textbf{\{target\_number\}} within the provided distribution?
Answer:
Zero Shot Answer Three Shot Answer Ground-Truth
Figure 6: Percentile Results. Zero and three-shot (within distribution) results for returning percentile estimations
in each of the 12 families of distributions.
18## You are an expe� on statistics. Your task is to sample a number from a given distribution. Do not write any code or use any 
additional tools to pe�orm the sampling. 
Answer with just a numerical response. Make sure your �nal answer is enclosed by xml tags <answer> and </answer>
## Consider the following distribution:
{distribution_description}
## Instruction: Sample a number from the given distribution and output only the numerical value.
Answer:
Zero Shot Answer Three Shot Answer Ground-Truth
Figure 7: Sampling Results. Zero and three-shot (within distribution) results for drawing samples (single repeated
draws) in each of the 12 families of distributions.
19## You are an expe� on statistics. Your task is to estimate the probability of being in a range of values within a given distribution. 
Answer with just a numerical response from 0 to 1, representing the probability. 
Make sure your �nal answer is enclosed by xml tags <answer> and </answer>.
## Consider the following distribution:
{distribution_description}
## Instruction: Considering only values including and between the 1st percentile and the 99th percentile, what is the probability that 
a value from the provided distribution is between {lower_target_number} and {upper_target_number}?
Answer:
Zero Shot Answer Three Shot Answer Ground-TruthFigure 8: Probability Results. Zero and three-shot (within distribution) results for calculating probabilities in each
of the 12 families of distributions.
20C Real-World Distribution Prompts
Health Example
## You are an expert on population health and wearable fitness devices. Your task is to estimate the percentile of a given
average step count value for a population that regularly uses Fitbit devices and is active on a daily basis. The data is
filtered for individuals aged 18-65. The data is age-balanced and gender-balanced, and pertains to the U.S. population
only. Do not use any additional tools such as code generation or search engines. Answer with just a numerical response
from 0 to 100. Make sure your answer is enclosed by xml tags <answer> and </answer>.
## Consider the following parameters that describe a normal distribution of this data:
Mean: 8366.971
Standard Deviation: 3291.940
## Here is your question:
Question:
What is the percentile of the average step count value {target_number} steps for users of Fitbit devices? Do not use
any additional tools such as code generation or search engines. Answer with just a numerical response from 0 to 100.
Make sure your answer is enclosed by xml tags <answer> and </answer>.
Answer:
Finance Example
## You are an expert on finance and statistics. Your task is to estimate the percentile of a given annual household
income within the population using data from the year 2018 in the United States, sourced from the Census Bureau’s
American Community Survey (ACS) Public Use Microdata Sample (PUMS). Do not use any additional tools such as
code generation or search engines. Answer with just a numerical response from 0 to 100. Make sure your answer is
enclosed by xml tags <answer> and </answer>.
## Consider the following parameters that describe a Gumbel distribution of this data:
Mean: 66028.713
Standard Deviation: 53616.018
## Here is your question:
Question:
What is the percentile of an annual household income value of $ {target_number} ? Do not use any additional tools such
as code generation or search engines. Answer with just a numerical response from 0 to 100. Make sure your answer is
enclosed by xml tags <answer> and </answer>.
Answer:
Climate Example
## You are an expert on climate science and statistics. Your task is to estimate the percentile of a given average
temperature value using data from U.S. weather stations in the year 2018, sourced from the National Oceanic and
Atmospheric Administration (NOAA) Global Historical Climatology Network Daily (GHCNd). Do not use any
additional tools such as code generation or search engines. Answer with just a numerical response from 0 to 100. Make
sure your answer is enclosed by xml tags <answer> and </answer>.
## Consider the following parameters that describe a normal distribution of this data:
Mean: 10.643
Standard Deviation: 12.628
## Here is your question:
Question:
What is the percentile of an average temperature of {targe_number} degrees Celsius? Do not use any additional tools
such as code generation or search engines. Answer with just a numerical response from 0 to 100. Make sure your
answer is enclosed by xml tags <answer> and </answer>.
Answer:
21Health Finance Climate
Model Norm. Approx. CoT RWC + Code Norm. Approx. CoT RWC + Code Norm. Approx. CoT RWC + Code
Gemini 1.0 Ultra 5.89±1.09 6.45±4.91 6 .62±1.03 7.62±1.06 9.45±1.26 8 .46±0.94 7.43±1.11 10.48±1.69 8 .56±0.92
Table 3: Zero-shot performance by domain and context category across different LMs. RWC = Real-world
Context. All results are reported as Mean Absolute Error (MAE) ±Standard Error ( σM) with (%) units.
Normal
Log-Normal Exponential Power-LawUniform Gamma
Skew-NormalGumbel Poisson
GeometricBinomial
Multinomial
Distribution Type010203040Mean Absolute Error (MAE)Additional Comparisons to Normal Approximation
Idealized Baseline (RQ1)
Normal Approximation
True Distribution Approximation
Figure 9: Additional Normal Approximation Results. Additional idealized distribution results comparing the
normal approximation approach to the baseline corresponding to idealized or real-world distributions and the true
distribution approach.
D Additional Experimental Results
D.1 Additional Model Results
Additional model results, extending Table 1 and Ta-
ble 2, can be found as a part of our GitHub
repo here: https://github.com/yahskapar/
LLMs-and-Probabilistic-Reasoning .
D.2 CoT and Code Tool-use Results
We provide additional zero-shot Chain-of-Thought
(CoT) (Kojima et al., 2022) and code tool-use re-
sults in Table 3. Though both CoT and code tool-
use show benefits over assuming an idealized dis-
tribution or adding real-world context (Table 2),
neither is convincingly better than the normal ap-
proximation approach. The fact that CoT results
do not exceed normal approximation suggest that
it is non-trivial to instruct a model to improve its
modeling of non-normal distributions. Additional
improvements to CoT-based approaches could be
achieved with further investigation and develop-
ment of techniques useful for numerical reason-
ing tasks. Furthermore, though we chose to use a
cutoff data for corresponding datasets and did not
employ a retrieval approach to retrieve and rank re-
cent information that may be relevant to a proposed
probabilistic reasoning question, we acknowledge
that a retrieval tool can be useful to get more up-
to-date information versus relying on parametric
knowledge.D.3 Additional Normal Approximation
Results
In Figure 9, we additionally present results that
involve a variant of normal approximation where
the true distribution is assumed with a mean and
standard deviation as a part of the prompt. In the
case of idealized distributions, we utilize the same
distribution name with provided mean and standard
deviation. In the case of real-world distributions,
we approximate the distribution based on the K-
S statistic after a matching process across all 12
idealized distributions described in Section 4.
E Broader Impacts
Though we pose more constrained, systematic ques-
tions as a part of our investigation of language
models and their ability to perform probabilistic
reasoning, real-world questions such as "is taking
8000 steps a day normal for an average adult in
the U.S. population using wearable devices?" and
others that we pose as a part of section 4 are com-
pletely reasonable questions for an average user of
LMs to ask. There is a significant practical impact
in improving the probabilistic reasoning capabili-
ties of language models on real-world distributions,
especially when answers to the aforementioned rea-
sonable questions can affect a user’s perception
of real-world distributions and ultimately their per-
spective on potentially critical matters such as those
in the domains of health, finance, and climate.
22