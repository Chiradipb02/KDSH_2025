COMMUNITY -CROSS -INSTRUCT : Unsupervised Instruction Generation for
Aligning Large Language Models to Online Communities
Zihao He, Minh Duc Chu∗, Rebecca Dorn∗, Siyi Guo, Kristina Lerman
USC Information Sciences Institute
{zihaoh, mhchu, rdorn, siyiguo}@usc.edu ,lerman@isi.edu
Abstract
Social scientists use surveys to probe the opin-
ions and beliefs of populations, but these meth-
ods are slow, costly, and prone to biases. Re-
cent advances in large language models (LLMs)
enable the creation of computational represen-
tations or “digital twins” of populations that
generate human-like responses mimicking the
population’s language, styles, and attitudes. We
introduce COMMUNITY -CROSS -INSTRUCT , an
unsupervised framework for aligning LLMs
to online communities to elicit their beliefs.
Given a corpus of a community’s online discus-
sions, COMMUNITY -CROSS -INSTRUCT auto-
matically generates instruction-output pairs by
an advanced LLM to (1) finetune a foundational
LLM to faithfully represent that community,
and (2) evaluate the alignment of the finetuned
model to the community. We demonstrate the
method’s utility in accurately representing po-
litical and diet communities on Reddit. Un-
like prior methods requiring human-authored
instructions, COMMUNITY -CROSS -INSTRUCT
generates instructions in a fully unsupervised
manner, enhancing scalability and generaliza-
tion across domains. This work enables cost-
effective and automated surveying of diverse
online communities1.
1 Introduction
Social scientists use surveys and focus groups to
learn the opinions, needs, and concerns of diverse
populations. However, designing surveys and re-
cruiting participants is a slow and costly process,
limiting the utility of these instruments for prob-
ing public opinion. Surveys are prone to biases,
such as the social desirability bias (Gordon, 1987),
where respondents may alter their responses to sen-
sitive questions to appear more socially accept-
able (Bergen and Labonté, 2020), non-response
*Equal Contribution.
1Code and data are available at https://github.com/
zihaohe123/community-cross-instruct
Multiple Choice
 Predicted Answers
Community Data
Open Ended
Multiple Choice
Open EndedLLM
 Instruction -Response Dataset
(1) Instruction Generation
(2) Fine -Tuning
(3) Evaluation 
or
Llama 3.1 GPT -3.5GPT -4o
Comm -aligned 
LLM
Comm -aligned 
LLMFigure 1: Illustration of COMMUNITY -CROSS -
INSTRUCT to align an LLM to a community. (1) Open-
ended instructions and multi-choice survey questions
are generated by an advanced LLM from the community
data. (2) A foundational LLM is aligned to the com-
munity through instruction-tuning on the open-ended
instructions. (3) The alignment of the finetuned LLM to
the community is measured using the generated survey
questions.
bias (Hill et al., 1997), where participants fail to
answer questions, and self-selection bias due to the
choices participants make to participate in the sur-
vey (Heckman, 1990). In addition, social stigmas
may taint responses (Goel and Salganik, 2010), es-
pecially for hard-to-reach and marginalized groups.
Recent breakthroughs in generative AI and es-
pecially large language models (LLMs) enable
new capabilities for creating computational rep-
resentations of human populations — their digital
twins (El Saddik, 2018) — by ingesting vast tex-
tual data they create, for example, in online dis-
cussion forums. These LLM-based models gener-
ate human-like responses that mimic the language,
communication styles, and attitudes of populations
they are aligned to, allowing us to probe their world-
views, biases, and sentiments in a cost-effective and
automated manner. Previous works have leveraged
such LLM-based representations to mine opinionsarXiv:2406.12074v3  [cs.CL]  22 Oct 2024and learn political attitudes of online communi-
ties (Jiang et al., 2020; He et al., 2024b). However,
these studies typically finetune models like GPT-2
(Radford et al., 2019) directly on raw textual data
from the communities, resulting in models that can
perform text continuation but are limited in their
ability to answer questions in structured formats,
such as multiple choice. Moreover, raw community
data often contains noise, irrelevant information,
or off-topic discussions that can degrade model
performance if not properly handled.
To address these challenges, we aim to align
LLMs to communities by finetuning the models
with high-quality instructions where the commu-
nity perspectives are embedded. However, curat-
ing high-quality instructional data is a non-trivial
process. Existing methods for self-supervised in-
struction generation rely on a seed set of instruc-
tions curated by domain experts (Wang et al., 2022;
Chen et al., 2024b), which is limited by the gener-
alizability to a new domain. In this paper, we in-
troduce COMMUNITY -CROSS -INSTRUCT : a fully
unsupervised framework for aligning LLMs to on-
line communities through instruction-tuning. It in-
corporates the readily available community data
into the instruction generation pipeline, which
no human supervision is needed. COMMUNITY -
CROSS -INSTRUCT uses advanced LLMs to gen-
erate instruction-response pairs that better capture
community perspectives in more structured and use-
ful formats. These instructions-responses pairs are
used to finetune foundational LLMs. The finetuned
LLMs serve as digital twins of communities, which
can be automatically surveyed to elicit their views.
We show a high-level overview of our framework
in Figure 1.
Specifically, given a corpus of comments
and submissions in different forums on Red-
dit,COMMUNITY -CROSS -INSTRUCT uses an ad-
vanced LLM (GPT-4o) to automatically curate two
instructional datasets: (1) COMM INST: a set of
open-ended instructions for comm unity-specific
instruction tuning, and (2) COMM SURVEY , a set
of multi-choice survey questions for comm unity-
specific survey completion. Each instruction in
COMM INST and each survey question in COMM -
SURVEY are paired with responses from different
communities (Figure 2). We finetune foundational
LLMs (GPT-3.5 or Llama-3.1) on COMM INST, in
order to align them to different communities and
evaluate the finetuned LLMs on COMM SURVEY to
measure alignment.Our key contributions can be summarized as
•We introduce COMMUNITY -CROSS -INST-
RUCT , a novel unsupervised framework for
aligning foundational LLMs to online commu-
nities, by finetuning them on the automatically
curated set of open-ended community-specific
instruction-response pairs ( COMM INST). The
models’ alignment to communities is mea-
sured using another set of automatically gen-
erated multiple choice questions and answers
(COMM SURVEY ).
•Using data from Reddit forums, we show
that our method improves the fidelity of
community representation (alignment) in two
domains— politics anddiet—yielding signif-
icant alignment improvement over standard
persona adaptation methods.
Our work highlights the potential of generative
AI to help researchers gain insights from online
communities. By leveraging LLMs to create dig-
ital twins of these communities, researchers can
more accurately and efficiently understand the nu-
ances of public opinion, attitudes, and behaviors.
Our framework not only enhances the fidelity of
community representation but also paves the way
for more effective approaches to studying social
phenomena in the digital age.
Using the term alignment .Inspired by Santurkar
et al. (2023), throughout this paper, we use align-
ment to refer only to the alignment of views and
opinions of LLMs and humans.
2 Problem Definition
A topical domain (e.g., politics ordiet) includes n
communities { C1,C2, ....,Cn} each with different
views and beliefs. Members of each community Ci
collectively author text corpus Di(e.g., discussions
on Reddit forums) expressing views and exhibit-
ing behaviors. Our goal is to align an LLM fto
each community Ciusing its texts Di, such that
the aligned LLM f′
ilearns the complex mindset of
the community and responds to inputs in the com-
munity’s voice. By administering surveys to the
aligned LLMs {f′
1, f′
2, ..., f′
n}, we obtain responses
from different communities, thereby capturing their
ideological differences.
To align an LLM fto a community C, we
finetune it on a set of demonstrations (instruction-
response pairs) (Wang et al., 2023; Ouyang et al.,2022; Chen et al., 2024b) I={(Xj, Yj)}, where
the instructions are open-ended questions probing
the community’s views on different topics, and
the corresponding responses are aligned with each
community’s ideology. Figure 2(a) shows an exam-
ple demonstration in the politics domain. We pro-
pose COMMUNITY -CROSS -INSTRUCT (Figure 3),
a framework to automatically generate community-
specific demonstrations Iwith an advanced LLM
ˆf(GPT-4o) based on the community’s text cor-
pusDand use these demonstrations to instruction-
tune a foundational LLM f(GPT-3.5 or Llama-3.1)
through a process we call “C ROSS -INSTRUCT ”.
Instruction :How should the government handle the taxation 
of legalized marijuana?
Response from r/Liberal : Taxes should fund public services 
and health initiatives. 
Response from r/NeutralPolitics : Balanced taxes to ensure 
regulation without overburdening consumers. 
Response from r/Anarcho_Capitalism : Minimal or no taxes 
to prevent black markets. 
Response from r/Conservative : Avoid high taxes to prevent 
strengthening black markets. 
Response from r/AskThe_Donald : Avoiding high taxes; 
focus on regulation for safety.
Question :What is the key concern  regarding  marijuana  use 
among  youth?
A. Increased  addiction  rates
B. Gateway  to harder  drugs
C. Mental  health  deterioration
D. Loss  of productivity
Answer from r/Liberal : C
Answer from r/NeutralPolitics : C
Answer from r/Anarcho_Capitalism : C
Answer from r/Conservative : B
Answer from r/AskThe_Donald : A(a)
(b)
Figure 2: Example of (a) an instruction from COM-
MINST and (b) a survey question from COMM SURVEY
in the politics domain on the topic of marijuana. The
open-ended instruction and survey question are paired
with answers from different communities.
3 Online Community Corpora Collection
Reddit is a vibrant social media platform hosting
discussion forums (subreddits) on a wide range of
topics (Hofmann et al., 2022; Chen et al., 2024a).
In this paper, we focus on two domains: politics
anddiet, which contain distinctive subreddits, or
communities, with complex social dynamics. Po-
litical subreddits are valuable expressions of di-
verse public opinions and viewpoints. In the age
of rising polarization, LLMs can help researchers
track the complex evolving ideological landscape
and effectively elicit public opinions. Meanwhile,thediet subreddits feature a wealth of sensitive,
health-related conversations, and the latest diet and
diet fads, often discussed using inscrutable insider
jargon. We can track the direction of these dis-
cussions, identifying emerging trends, risks, and
potential health misinformation. This insight al-
lows public health officials to promptly address
harmful health advice and intervene where neces-
sary. Additionally, it provides an early warning
system to detect the spread of dangerous health
practices, ensuring that corrective measures can be
implemented swiftly to protect community health.
We identify a set of representative subreddits for
each domain based on personal knowledge and by
querying ChatGPT. We manually aggregate and
filter results, obtaining the following five political
online communities: r/Liberal ,r/NeutralPolitics ,
r/Anarcho_Capitalism ,r/Conservative , and r/Ask-
The_Donald ; For diet, we investigate three commu-
nities: r/keto ,r/WeightLossAdvice , and r/EDAnony-
mous . More details of these communities are pre-
sented in Appendix A.1.
We collect comments and submissions from Jan-
uary 2019 to December 2022 and remove those
that were deleted by the author or the moderator
through PushShift2. The statistics of the collected
comments and submissions are shown in Appendix
A.1. We do not differentiate between comments
and submissions, and treat each comment and sub-
mission as a separate document. In subsequent
sections of this paper, we use “comment” to refer
to both “comment” and “submission”.
4 Instructional Data Generation
For each domain, we curate a collection of (1) in-
structional datasets COMM INST forcomm unity-
specific instruction tuning, which is used to fine-
tune LLMs to views of different communities, and
(2) survey datasets COMM SURVEY for evaluating
the alignment of the finetuned LLMs’ views to the
comm unities using survey questions. The pipeline
is depicted in Figure 3.
4.1 Topic Modeling
For a domain, denote the combined corpus from all
ncommunities by D=D1∪D2∪....∪Dn. We
use BERTopic (Grootendorst, 2022) on Dto iden-
tify topics T. More details about BERTopic can
be found in Appendix B.1. After topic modeling,
each text dis assigned a topic t(d). For each com-
2https://pushshift.ioGender
IdentityGun 
Control
Comm1
Comm2r/Liberal
r/ConservativeTopic
Modelingt1
t2
Chunk1,1
Chunk1,2Chunk2,1
Chunk2,2
GPT -4oOpen -ended
Instruction1
GPT -4o
R1,1 R2,1
R1,2 R2,2
A1,1
A1,2A2,1
A2,2Multi -choice
Question1
Multi -choice
Question2CommInst1
CommInst2
CommSurvey1
Llama3.1 Comm1-aligned
Llama3.1
Comm2-aligned
Llama3.1Open -ended
Instruction2
CommSurvey2EvaluateFinetune
Evaluate
On a national level guns 
save more than kill, what 
happened in Uvalde was 
still a tragedy .
Rapid onset gender dysphoria is 
being forced down the throats of 
vulnerable, confused children .Q: What are the primary reasons given by users for supporting 
or opposing gun control laws?
r/Liberal :  Gun control laws are essential to reduce mass 
shootings and keep firearms away from dangerous individuals.
r/Conservative : Gun control laws infringe on the Second 
Amendment and do not stop criminals from obtaining guns.
Q: What is the main reason for the increase in 
people identifying as transgender today? 
A.More societal acceptance 
B.Media influence 
C.Biological factors 
D.Political agendas
r/Liberal :  A. r/Conservative : DFinetune
Figure 3: Overview of COMMUNITY -CROSS -INSTRUCT , with an illustrative example of the politics domain. (1)
Data is collected for each community within the desired domain. (2) BERTopic clusters the data and identifies
prominent topics. A chunk is a set of documents from a community on the same topic. Chunk i,jrepresents the
chunk from community ion topic j. (3) For each topic, the advanced LLM is prompted with (i) on-topic chunks
from each community and (ii) task definition of the instructional data generation (see Appendix B.2), which leads
the LLM to generate (a) open-ended instruction-response pairs and (b) multi-choice question-answer pairs. R i,k
represents the response of community ito instruction k; Ai,krepresents the answer of community ito question
k. (4) The open-ended instructions across all topics, along with the corresponding responses of community i, are
added to COMM INSTi, which is used to finetune a foundational LLM, to align the LLM to the community. (5) The
multi-choice questions across all topics, along with the corresponding answers from community i, are added to
COMM SURVEY i, which is used to evaluate the finetuned LLM.
munity Ci, we split the text corpus Diinto smaller
chunks Di={ˆDi
1,ˆDi
2, ....}, where each chunk ˆDi
consists of 50 randomly sampled texts belonging
to a single topic t(ˆDi). A chunk ˆDion topic t(ˆDi)
is considered an occurrence of the topic. To inves-
tigate different views across the communities, we
only keep the topics that are discussed by at least
n−1communities. To balance the occurrences
of different topics, for each topic in a community,
we keep a maximum of 5 chunks. As a result, for
politics anddiet, there are 41 and 148 topics respec-
tively. We present the keywords of 10 topics that
appear 5 times in all communities in Appendix B.1.
Politics topics include COVID vaccines, abortion,
climate, guns. diettopics include body measures,
keto diet, and eating disorder recovery.
4.2 Open-ended Instructions Generation
For a specific domain with ncommunities,
we initialize nempty demonstration pools
{COMM INST i}n
i=1. For a topic tk∈Tthat is dis-
cussed by mcommunities3, from each community
3As we require a topic to appear at least n−1communities,
m=norm=n−1.Ci, we randomly sample without replacement a text
chunk ˆDiontk. We include the msampled text
chunks {ˆD1,ˆD2, ...,ˆDm}on topic tkinto a prompt
and then use the prompt to query the advanced
LLM (GPT-4o) to generate open-ended instructions
and responses on the topic. The prompting tem-
plate is shown in Appendix B.2. In the prompt, we
first specify the topic by the topic keywords, and
then the comments in the sampled chunks from
different communities. Next, we instruct the model
to generate an instruction that can be answered
based on the texts, and that the instruction should
elicit different responses from the communities. In
addition, we instruct the model to not rely on its
pre-knowledge about the community, but solely
focus on the given texts . The generated instruc-
tionXis paired with different responses {Yi}m
i=1
from different communities, as shown in Figure
2(a). Each demonstration {X, Y i}is then added to
the corresponding pool for the i-th community. We
iteratively repeat this process until there are fewer
thann−1communities that have chunks left on
topictk, then we shift to the next topic tk+1. Afterthe iterative generation process, each demonstra-
tion pool COMM INST iis used to finetune a foun-
dational LLM for community Ci. Please refer to
Appendix B.3 for more details about C OMM INST.
4.3 Multi-choice Surveys Generation
To measure the alignment of the finetuned foun-
dational LLM to the community, we administer
a survey of multi-choice questions to the model
and evaluate the agreement between the model’s
responses and the community members’ responses.
However, manually designing surveys and collect-
ing human responses from online communities is
a non-trivial process, which is costly and time-
consuming. Instead, we curate another collection
of datasets called COMM SURVEY for evaluating
the alignment of the finetuned LLMs’ views to the
communities.
We initialize nempty multi-choice question
pools{COMM SURVEY i}n
i=1. Then, following the
open-ended instruction-response pairs generation
process in §4.2, we iteratively generate multi-
choice questions and answers (Figure 2(b)) using
the same advanced LLM (GPT-4o) and add them to
the pools4. The prompting template is shown in Ap-
pendix B.2. Each question pool COMM SURVEY i
is used to evaluate a finetuned foundational LLM
on community Ci. Please refer to Appendix B.3
for more details about C OMM SURVEY .
We assume that the answers generated by the
advanced LLM are the “semi-ground truths”, and
that they faithfully represent the views of the cor-
responding communities. As an empirical eval-
uation, we compute the pairwise agreement be-
tween different communities using their responses
to questions in COMM SURVEY . The results are
presented in Figure 5 in Appendix B.4. We observe
significant polarization between the left-leaning
and right-leaning communities, and strong agree-
ment between the two right-leaning communities
(r/Conservative andr/AskThe_Donald ). However,
in the dietdomain where the communities are more
practical, there is less polarization. For more rigor-
ous evaluation, we verify the “semi-ground truths”
by human annotation, as detailed in Appendix C.
4In practice we use the advanced LLM to generate open-
ended instructions and multi-choice questions at the same time
in a single query. For clarity of presentation, we articulate
them separately.5 Experiments
We align foundational LLMs to Reddit communi-
ties by finetuning them on relevant demonstrations
from COMM INST. After finetuning, we evaluate
the models using surveys from COMM SURVEY ,
comparing their responses to “semi-ground truths”
to assess alignment.
5.1 Experimental Setup
Data Generation. We use OpenAI’s GPT-4o
Batch API to generate the datasets. For each query,
three open-ended instructions and two multi-choice
questions are created, as shown in Appendix B.2.
The API costs approximately $2 for the politics
domain and $5 for the dietdomain.
Data Splitting. Among all the queries used to
prompt the advanced LLM to generate data, we
randomly select 85% of them and use the instruc-
tions generated from these queries as the training
instructions denoted as COMM INST-TRAIN . For
the rest 15% queries, we use the corresponding
multi-choice questions as test questions, denoted
asCOMM SURVEY -TEST . In addition to randomly
splitting the queries, we perform a topic-wise split,
and make sure that the 85% training instructions,
COMM INST-TRAIN -TOPIC , and 15% test ques-
tions, COMM SURVEY -TEST -TOPIC , do not cover
the same topics.
Finetuning. We focus on two strong founda-
tional LLMs – Llama-3.1-8B-Instruct (Dubey et al.,
2024) and GPT-3.5-Turbo (Ouyang et al., 2022).
For each community Ci, we finetune the LLM
onCOMM INST-TRAIN i(§5.3) and COMM INST-
TRAIN -TOPIC i(§5.4). The input and the output are
the instruction and response verbatim. Llama-3.1
is finetuned with LLAMA FACTORY (Zheng et al.,
2024), using both full and LoRA finetuning (Hu
et al., 2022), with batch size 16 for 3 epochs. We
report the results of the model (full or LoRA) that
achieves better loss on the validation set (5% of
the training data). Full finetuning takes around 3
minutes on 4 NVIDIA H100 GPUs, and LoRA
finetuning takes around 30 seconds on 1 GPU. For
GPT-3.5, we use the OpenAI API, which completes
finetuning in around 10 minutes for 1 epoch, where
the batch size is automatically determined.
Measuring Alignment. We administer survey
questions from COMM SURVEY -TEST (§5.3) and
COMM SURVEY -TEST -TOPIC (§5.4) to the fine-
tuned foundational LLMs. Each prompt includesthe question and options verbatim, followed by the
instruction, “Select only one answer by stating ei-
ther A, B, C, or D. Do not provide any additional
explanation or rationale for your choice,” to facili-
tate easier matching of the model’s responses to the
options. We set the temperature to 0.8, generating
20 responses per question, and take the majority
vote. Accuracy is calculated by comparing the
model’s answers to the “semi-ground truths”.
5.2 Baselines
LLM+Context. For each community Ci, we
provide the vanilla (unfinetuned) LLM with the
context about the community by appending 300
most relevant comments from it. For example,
when prompting the LLM to answer a question
inCOMM SURVEY -TEST i, we retrieve the most rel-
evant 300 comments to the question, from the text
chunks that are used to generate COMM SURVEY -
TRAIN i, by calculating the embedding similarity
with sentence-transformers . The prompt is aug-
mented with the instruction “ According to the
following statements, learn the mindset
and select only one most relevant answer
by stating either A, B, C, or D. Do
not provide any additional explanation or
rationale for your choice. [comments] ”.
This baseline is inspired by the idea of in-context
learning, where the LLM learns the community’s
mindset within the context provided in the prompt.
Providing the LLM with context becomes less
efficient when the model is deployed to answer a
large number of survey questions, as each ques-
tion requires processing an extremely long input
sequence due to the added comments. This sig-
nificantly increases computational costs, memory
usage, and processing time, making it inefficient
for large-scale or real-time applications. In con-
trast, our framework, which finetunes the model
on community-specific data, is a one-time effort.
Once the model is finetuned, it can efficiently an-
swer survey questions without requiring additional
long contextual inputs, making it far more scalable
and resource-friendly in practical use cases.
LLM+Steering. When prompting the vanilla
LLM to answer survey questions, we steer it to
mimic the community, by specifying in the prompt
that “ Select only one answer that best
aligns with the opinions of members from
subreddit r/[subreddit] ”. Steering the vanilla
LLMs can nudge them to respond to the commu-nity. For fair comparison to this baseline, we also
steer the finetuned LLM via COMMUNITY -CROSS -
INSTRUCT , where the LLM is aligned to the com-
munity both in the finetuning and steering process.
It is worth noting that steering only applies
to predefined communities that are developed
via a manually specified tag , such as subred-
dits, where we can easily reference community
names in the prompt. While this paper focuses on
forum-based communities, COMMUNITY -CROSS -
INSTRUCT generalizes to other online communi-
ties, including organically formed communities in
the retweet network (Chu et al., 2024) or the news
co-sharing network (Mosleh et al., 2021; He et al.,
2024b), as long as their relevant text data is readily
available. Although it is not always feasible to con-
cisely summarize organically formed communities
in text, COMMUNITY -CROSS -INSTRUCT allows
for LLM alignment to such communities without
requiring explicit textual descriptions.
5.3 Main Results
We compare the finetuned LLMs’ generated an-
swers to multi-choice questions to the “semi-
ground truths” and report the accuracy in Fig-
ure 1 as a measure of alignment with the corre-
sponding community. The LLMs are finetuned on
COMM INST-TRAIN and evaluated on COMM INST-
TEST .
Politics. In the politics domain, CROSS INST
consistently outperforms CONTEXT across both
LLMs, demonstrating the strength of finetuning
on community-specific instructional data. By
aligning LLMs to explicit community instructions,
CROSS INST enables the models to better capture
the nuances of political discourse, where ideologi-
cal divides and subtle differences in language are
critical. This makes the model more adept at accu-
rately reflecting community values without being
overwhelmed by noisy or redundant information,
which is a common issue with CONTEXT . We
observe that the a large portion of generated an-
swers from Llama-3.1 using CONTEXT are texts
irrelevant to the survey questions, indicating that
it struggles in dealing with a lengthy prompt with
300 examples.
An important aspect to consider is that LLMs
come with pre-existing knowledge about various
communities, which is learned during pretraining
on large-scale internet data. During STEERING ,
the model attempts to retrieve and apply this pre-SubredditLlama-3.1-8B GPT-3.5-Turbo
Without Steering With Steering Without Steering With Steering
Context CrossInst Steering Steering+CrossInst Context CrossInst Steering Steering+CrossInst
r/Liberal 8.3 54.2 55.8 58.3 41.7 62.5 45.8 62.5
r/NeutralPol 3.8 50.0 55.0 63.3 55.0 55.0 40.0 50.0
r/Anar_Cap 54.1 76.7 70.0 66.7 50.0 66.7 66.7 73.3
r/Conservative 18.4 63.3 60.5 56.7 50.0 53.3 53.3 53.3
r/AT_Donald 23.7 56.7 66.7 70.0 30.0 56.6 50.0 63.3
avg. politics 21.7 60.2 61.6 63.0 45.3 58.8 51.2 60.5
r/keto 26.0 75.0 67.0 72.0 56.0 68.0 66.0 66.0
r/WLAdvice 27.7 60.6 65.2 61.7 59.6 58.5 66.1 64.8
r/EDAnony 29.1 72.1 65.1 69.8 61.6 72.1 62.7 66.3
avg. diet 27.6 69.2 65.8 67.8 59.1 66.2 64.9 65.7
Table 1: Evaluation results of Llama-3.1-8B and GPT-3.5-Turbo on COMM SURVEY -TEST . The community-aligned
LLMs (C ROSS INST and S TEERING +CROSS INST) are finetuned on C OMM INST-TRAIN , so there is potential topic
overlap between training and evaluation. For each model family, the results are divided into two groups, one without
and one with steering. The best results in each group are highlighted in bold.
SubredditLlama-3.1-8B GPT-3.5-Turbo
Without Steering With Steering Without Steering With Steering
Context CrossInst Steering Steering+CrossInst Context CrossInst Steering Steering+CrossInst
r/Liberal 11.1 50.0 58.3 61.1 41.7 61.1 63.9 65.1
r/NeutralPol 20.8 60.0 54.2 65.0 52.5 65.0 67.5 67.5
r/Anar_Cap 23.9 56.5 52.2 56.5 54.3 58.7 58.7 71.7
r/Conservative 20.0 54.3 52.5 65.2 50.0 67.4 69.6 65.2
r/AT_Donald 25.0 56.5 57.5 56.5 52.2 60.9 61.2 63.0
avg. politics 20.2 55.5 54.9 60.9 50.1 62.6 64.2 66.5
r/keto 29.7 64.4 65.2 63.6 59.3 67.8 61.0 63.5
r/WLAdvice 26.9 63.5 61.5 62.5 58.7 62.5 63.5 62.5
r/EDAnony 25.4 55.9 50.0 54.9 57.8 60.8 58.8 61.8
avg. diet 27.3 61.3 58.9 60.3 58.6 63.7 61.1 62.6
Table 2: Evaluation results of Llama-3.1-8B and GPT-3.5-Turbo on COMM SURVEY -TEST -TOPIC . The community-
aligned LLMs ( CROSS INST andSTEERING +CROSS INST) are finetuned on COMM INST-TRAIN -TOPIC , so there is
no topic overlap between training and evaluation. For each model family, the results are divided into two groups,
one without steering and one with steering. The best results in each group are highlighted in bold.
existing knowledge to align its responses with the
given community. However, this knowledge may
not always be fully accurate or consistent with the
actual values of the community being evaluated.
For example, STEERING might prompt the model
to draw on generalizations or stereotypes that are
present in its pretraining data, which might not
reflect the current or specific views of the subreddit
in question. This inconsistency can explain why
STEERING alone sometimes leads to suboptimal
performance.
When combining STEERING with CROSS INST,
a potential conflict arises between the knowledge
gained from finetuning and the pre-existing commu-
nity knowledge the model tries to retrieve through
steering. The model is essentially being pulled in
two directions: one based on the explicit, finetunedinstructions from CROSS INST and the other based
on its internalized, sometimes outdated, pretrain-
ing knowledge. This conflict can result in STEER -
ING+CROSS INST underperforming compared to
STEERING alone, as observed in certain subreddits,
such as r/Anarcho_Capitalism on Llama-3.1. In
these cases, the inconsistency between the steering
prompts and the finetuned knowledge creates con-
fusion for the model, leading to lower performance.
Diet. In the dietdomain, we observe a similar pat-
tern where CROSS INST significantly outperforms
theCONTEXT baseline. Communities like r/keto
andr/EDAnonymous , which are focused on spe-
cific health and lifestyle goals, benefit greatly from
instructional finetuning. These communities are
characterized by practical and focused discussions,
andCROSS INST allows the model to adapt to thespecific language and norms within these subred-
dits, ensuring a more accurate reflection of their
values and objectives.
Interestingly, in r/WeightLossAdvice ,STEERING
alone performs the best across the four methods
within each LLM. One possible reason for this
is that in certain communities, particularly those
that are well-represented in pretraining data, the
model’s pre-existing knowledge might be more
aligned with the actual community values. In such
communities, where strong ideological markers
may already be embedded in the model’s pretrain-
ing data, steering allows the model to retrieve this
relevant information effectively, leading to stronger
performance. In such cases, STEERING helps am-
plify the model’s pre-learned alignment with the
community, which can be sufficient for capturing
the community’s voice without the need for addi-
tional finetuning.
5.4 Out-of-Topic Generalizability
Our final goal is to create LLMs aligned to differ-
ent communities, which can be used to answer any
survey question from the perspective of the com-
munity. In the real world, the surveys may contain
questions covering topics that do not appear in the
finetuning data COMM INST. In this study, we fine-
tune the LLMs on COMM INST-TRAIN -TOPIC , and
evaluate them on COMM SURVEY -TEST -TOPIC , to
make sure that there is no overlap in topic coverage.
The results are shown in Table 2. CROSS INST
models continue to outperform the CONTEXT base-
lines, demonstrating their strong generalization ca-
pability to new topics, suggesting that CROSS INST
maintains its robustness even when exposed to en-
tirely new topics.
We observe that STEERING alone occasionally
performs the best (e.g., r/AskThe_Donald on both
LLMs, and r/WeightLossAdvice on GPT-3.5). We
argue that this might be because ideologically-
polarized or practical communities are consistent
in their mindsets over time, so the LLM’s pre-
knowledge about them would well predict their
ideologies in the future.
6 Related Works
6.1 Self-Improved Instruction Tuning.
A survey of instruction-tuning approaches (Zhang
et al., 2023) outlines several methods for mod-
els to autonomously self-improve their instruction
set. These include generating instructions for pre-existing texts (Li et al., 2023), eliciting interac-
tion between different model iterations (Chen et al.,
2024c), and bootstrapping from an existing instruc-
tion set to generate new ones (Wang et al., 2022;
Chen et al., 2024b). Additionally, a human-in-the-
loop framework builds upon self-generalization by
iterating between human and machine-generated
instructions (Guo et al., 2024). Despite these ad-
vances, these strategies require manual input. In
this work, we build on self-instruct , a method to
enhance instruction tuning by eliciting synthetic
model instruction generations. We alter the orig-
inal framework by removing the required set of
manually written seed instructions (Wang et al.,
2022). This work significantly contributes to the
field by offering a scalable and fully autonomous
solution to instruction tuning, paving the way for
more adaptive and intelligent models.
6.2 Aligning LLMs to Subgroups
Existing work has aligned LLMs to different hu-
man subgroups to discover their mindset and opin-
ions (Dorn et al., 2023, 2024). Subpopulation rep-
resentative models (SRMs) (Simmons and Hare,
2023) can be used to emulate some characteris-
tics of a particular subpopulation, particularly as
LLMs can provide fine-grained, demographically-
correlated outputs (Argyle et al., 2023a). Argyle
et al. (2023b) find that exposing GPT-3 to thou-
sands of socio-demographic backstories leads the
model to obtain a complex understandings of soci-
ological concepts.
To learn about partisan communities, Jiang et al.
(2022) propose COMMUNITY LM by finetuning
GPT-2 on tweets authored by prominent commu-
nity members, and prompt the finetuned model
to generate opinions about various political enti-
ties. He et al. (2024b) extends COMMUNITY LMto
organically-formed online communities with more
fine-grained ideologies. However, these finetuned
GPT-2 models can only be used for text continua-
tion tasks and cannot answer survey questions. In
our paper, we finetune the foundational instruction-
tuned LLMs to serve as their digital twins. The
resulting LLMs retain the instruction-following ca-
pabilities and are able to complete various tasks
as specified in the instructions, including survey
completion.
6.3 Evaluating LLMs’ Subgroup Alignment
Social scientists use surveys to systematically col-
lect data from populations to characterize their be-liefs, attitudes, opinions, and behaviors (Hill et al.,
1997; Choi and Pak, 2005; Gordon, 1987; Goel
and Salganik, 2010). LLM developers and practi-
tioners focus on measuring LLM’s alignment with
different human subgroups (Santurkar et al., 2023;
Durmus et al., 2023; He et al., 2024a) using use
real-world survey responses as ground truth for
comparing values. However, they often ignore
under-represented groups, as it is difficult to ad-
minister surveys to people from those groups. To
administer surveys, researchers sample individuals
from a target population and ask them to manually
respond to survey questions. This can be costly
and slow, which limits the utility and timeliness
of surveys. Our method addresses this challenge
by using social media data that is easily accessible,
even for those hard-to-reach subgroups. By auto-
matically creating multi-choice survey questions
and answers COMM SURVEY for these groups, our
method enables a more comprehensive and cost-
effective evaluation of LLMs’ alignment with di-
verse groups.
7 Discussions
We aim to align LLMs to online communities
through instruction-tuning so that the aligned
LLMs can be flexibly surveyed to probe the
communities’ views on different topics. To
prepare data for instruction tuning, we propose
COMMUNITY -CROSS -INSTRUCT , and the auto-
matic creation of the open-ended instruction-
response pairs ( COMM INST) is the core contribu-
tion. However, in order to demonstrate that the
finetuned LLMs are indeed aligned to communi-
ties and can be treated as their digital twins, we
propose to automatically generate survey questions
and answers ( COMM SURVEY ) to efficiently eval-
uate LLM alignment. This is a secondary con-
tribution of this paper, and we do not claim that
COMM SURVEY is the best way to measure align-
ment. Therefore, our main goal is to propose a
method to prepare LLMs as a proxy for surveying
different online communities, rather than automati-
cally creating such surveys.
8 Conclusion
In this paper, we introduced and explored
COMMUNITY -CROSS -INSTRUCT , a fully auto-
mated framework to represent online communi-
ties and elicit their views. By automating the
process of surveying diverse online communities,COMMUNITY -CROSS -INSTRUCT offers a cost-
effective and efficient alternative to traditional sur-
vey methods used by social scientists. Through
finetuning LLMs based on community-specific
instructions and answers, COMMUNITY -CROSS -
INSTRUCT enables the generation of accurate re-
sponses that align with the beliefs and perspectives
of different online communities. This innovative
framework has demonstrated its effectiveness in
representing various communities, including po-
litical and diet forums on Reddit. COMMUNITY -
CROSS -INSTRUCT opens up new possibilities for
researchers to gain insights into online communi-
ties’ diverse views and opinions, paving the way
for deeper understanding and analysis of digital
societies.
Moving forward, we will apply the framework to
model organic online communities, such as those in
the retweet network. In addition, we are interested
in aligning LLMs to communities through rein-
forcement learning from human feedback (RLHF).
Limitations
Ignoring Thread Structure in Reddit Data. We
treat each Reddit comment and submission as in-
dependent data points, without taking into account
the thread structure in which they are embedded.
Reddit discussions are inherently hierarchical, with
comments often building upon or responding to
previous comments and submissions. By ignoring
this structure, we may lose important contextual
information that could help capture the nuances
of community interactions and opinions. Future
work could explore leveraging the thread structure
to better model the flow of conversations, capturing
how community members engage with each other’s
ideas and how opinions evolve within discussions.
Identical LLM for Generating both Datasets.
We use GPT-4o for generating both COMM INST
for finetuning LLMs and COMM SURVEY for eval-
uating LLM alignment, as we couldn’t find a dif-
ferent advanced LLM that was able to generate
high-quality data as GPT-4o. This reliance on a sin-
gle LLM introduces a limitation, as it may lead to
a bias where the evaluation dataset (CommSurvey)
is inherently aligned with the model used for in-
struction generation (CommInst), potentially over-
estimating the alignment accuracy of the finetuned
models. To address this limitation, we plan to in-
corporate a diverse set of advanced LLMs as they
become available in future iterations of our frame-work. Additionally, we will include human-in-the-
loop validation to ensure the generated datasets
maintain high quality and representativeness, mit-
igating any biases introduced by the single LLM
dependency. Furthermore, we will explore cross-
validation techniques and third-party evaluations to
benchmark the performance of our finetuned mod-
els, ensuring the robustness and generalizability of
our results beyond the influence of a single LLM.
Group Approximation. To approximate group-
level behavior, community members represented in
the minority might be inherently excluded. Further,
measuring group alignment using a single-answer
multiple choice questionnaire does not account for
a more complex distribution of the various opinions
within the community. We hope to build on this
work by experimenting with survey designs that
account for more diversity in communities.
Hallucination Potential. Adapting models to
communities poses a risk of language models hallu-
cinating or providing misinformation in their com-
munity representation. We hope to build upon this
work with in-depth experiments on model halluci-
nation and misrepresentation in the subgroup rep-
resentation task.
Prompt Perturbations. LLM responses are sen-
sitive to slight changes in prompts (Salinas and
Morstatter, 2024). In this work, we work primarily
with one prompt for instruction generation. We
would be interested to see how the model’s gen-
erated instructions shift with different prompting
schema.
Ethics Statement
Finetuning LLMs towards Bias. Aligning
LLMs with specific communities may result in
models that appear more biased, as they are fine-
tuned to the distinctive views and perspectives of
those communities. However, this process is done
solely for the purpose of accurately reflecting the
values and attitudes prevalent within each commu-
nity, rather than intentionally making the models
more biased. Our goal is not to reinforce or am-
plify harmful biases, but rather to provide a com-
putational tool that can represent the views of a
given community for research purposes. To miti-
gate potential misuse, these models should be used
in controlled environments and in contexts where
understanding specific community perspectives is
essential for social, cultural, or political research.User Privacy and Consent. Users might not be
informed of how their data (reflected in their posts)
are used to produce digital twins that mirror their
voices and the purpose of the survey constructed
based on their data. Furthermore, automatically
surveying communities can reveal unconsented in-
sights of certain individuals or groups of people
online. To address these ethical concerns, we imple-
ment several measures. Firstly, we ensure that all
data used for creating digital twins is anonymized,
stripping any personally identifiable information to
protect user privacy. Secondly, we seek to aggre-
gate data in a manner that focuses on community-
level insights rather than individual-level analysis,
thereby reducing the risk of unconsented personal
exposure. Thirdly, we will obtain explicit consent
from users where possible, clearly communicating
the purpose and scope of our research. Lastly, we
will adhere to ethical guidelines and institutional
review board (IRB) requirements to ensure that
our methods respect the privacy and rights of the
individuals and communities involved.
Acknowledgements
We are grateful to Patrick Gerard, Ashwin Rao,
and DJ Berry for helping review responses to
surveys. This project was funded in part by
the Defense Advanced Research Projects Agency
(DARPA) under Agreement Nos. HR00112290021
and HR001121C0168.
References
Lisa P. Argyle, Ethan C. Busby, Nancy Fulda, Joshua R.
Gubler, Christopher Rytting, and David Wingate.
2023a. Out of one, many: Using language mod-
els to simulate human samples. Political Analysis ,
31(3):337–351.
Lisa P Argyle, Ethan C Busby, Nancy Fulda, Joshua R
Gubler, Christopher Rytting, and David Wingate.
2023b. Out of one, many: Using language mod-
els to simulate human samples. Political Analysis ,
31(3):337–351.
Nicole Bergen and Ronald Labonté. 2020. “everything
is perfect, and we have no problems”: detecting and
limiting social desirability bias in qualitative research.
Qualitative health research , 30(5):783–792.
Kai Chen, Zihao He, Keith Burghardt, Jingxin Zhang,
and Kristina Lerman. 2024a. Isamasred: A public
dataset tracking reddit discussions on israel-hamas
conflict. arXiv preprint arXiv:2401.08202 .
Kai Chen, Zihao He, Jun Yan, Taiwei Shi, and Kristina
Lerman. 2024b. How susceptible are large languagemodels to ideological manipulation? arXiv preprint
arXiv:2402.11725 .
Zixiang Chen, Yihe Deng, Huizhuo Yuan, Kaixuan Ji,
and Quanquan Gu. 2024c. Self-play fine-tuning con-
verts weak language models to strong language mod-
els.arXiv preprint arXiv:2401.01335 .
Bernard CK Choi and Anita WP Pak. 2005. Peer re-
viewed: a catalog of biases in questionnaires. Pre-
venting chronic disease , 2(1).
Minh Duc Chu, Aryan Karnati, Zihao He, and Kristina
Lerman. 2024. Characterizing online eating disor-
der communities with large language models. arXiv
preprint arXiv:2401.09647 .
Rebecca Dorn, Lee Kezar, Fred Morstatter, and Kristina
Lerman. 2024. Harmful speech detection by lan-
guage models exhibits gender-queer dialect bias.
arXiv preprint arXiv:2406.00020 .
Rebecca Dorn, Negar Mokhberian, Julie Jiang, Jeremy
Abramson, Fred Morstatter, and Kristina Lerman.
2023. Non-binary gender expression in online inter-
actions. arXiv preprint arXiv:2303.04837 .
Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey,
Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman,
Akhil Mathur, Alan Schelten, Amy Yang, Angela
Fan, et al. 2024. The llama 3 herd of models. arXiv
preprint arXiv:2407.21783 .
Esin Durmus, Karina Nyugen, Thomas I Liao, Nicholas
Schiefer, Amanda Askell, Anton Bakhtin, Carol
Chen, Zac Hatfield-Dodds, Danny Hernandez,
Nicholas Joseph, et al. 2023. Towards measuring
the representation of subjective global opinions in
language models. arXiv preprint arXiv:2306.16388 .
Abdulmotaleb El Saddik. 2018. Digital twins: The
convergence of multimedia technologies. IEEE mul-
timedia , 25(2):87–92.
Sharad Goel and Matthew J Salganik. 2010. Assess-
ing respondent-driven sampling. Proceedings of the
National Academy of Sciences , 107(15):6743–6747.
Randall A Gordon. 1987. Social desirability bias: A
demonstration and technique for its reduction. Teach-
ing of Psychology , 14(1):40–42.
Maarten Grootendorst. 2022. Bertopic: Neural topic
modeling with a class-based tf-idf procedure. arXiv
preprint arXiv:2203.05794 .
Hongyi Guo, Yuanshun Yao, Wei Shen, Jiaheng Wei,
Xiaoying Zhang, Zhaoran Wang, and Yang Liu. 2024.
Human-instruction-free llm self-alignment with lim-
ited samples. arXiv preprint arXiv:2401.06785 .
Zihao He, Siyi Guo, Ashwin Rao, and Kristina Lerman.
2024a. Whose emotions and moral sentiments do
language models reflect? In Findings of the Associa-
tion for Computational Linguistics ACL 2024 , pages
6611–6631, Bangkok, Thailand and virtual meeting.
Association for Computational Linguistics.Zihao He, Ashwin Rao, Siyi Guo, Negar Mokhberian,
and Kristina Lerman. 2024b. Reading between the
tweets: Deciphering ideological stances of intercon-
nected mixed-ideology communities. arXiv preprint
arXiv:2402.01091 .
James J Heckman. 1990. Selection bias and self-
selection. In Econometrics , pages 201–224. Springer.
Anthony Hill, Julian Roberts, Paul Ewings, and David
Gunnell. 1997. Non-response bias in a lifestyle sur-
vey. Journal of Public Health , 19(2):203–207.
Valentin Hofmann, Hinrich Schütze, and Janet B Pier-
rehumbert. 2022. The reddit politosphere: A large-
scale text and network resource of online political
discourse. In Proceedings of the International AAAI
Conference on Web and Social Media , volume 16,
pages 1259–1267.
Edward J Hu, Phillip Wallis, Zeyuan Allen-Zhu,
Yuanzhi Li, Shean Wang, Lu Wang, Weizhu Chen,
et al. 2022. Lora: Low-rank adaptation of large lan-
guage models. In International Conference on Learn-
ing Representations .
Hang Jiang, Doug Beeferman, Brandon Roy, and Deb
Roy. 2022. Communitylm: Probing partisan world-
views from language models. In Proceedings of the
29th International Conference on Computational Lin-
guistics , pages 6818–6826.
Julie Jiang, Emily Chen, Shen Yan, Kristina Lerman,
and Emilio Ferrara. 2020. Political polarization
drives online conversations about covid-19 in the
united states. Human Behavior and Emerging Tech-
nologies , 2(3):200–211.
Xian Li, Ping Yu, Chunting Zhou, Timo Schick, Luke
Zettlemoyer, Omer Levy, Jason Weston, and Mike
Lewis. 2023. Self-alignment with instruction back-
translation. arXiv preprint arXiv:2308.06259 .
Mohsen Mosleh, Gordon Pennycook, Antonio A
Arechar, and David G Rand. 2021. Cognitive re-
flection correlates with behavior on twitter. Nature
communications , 12(1):921.
Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Car-
roll L Wainwright, Pamela Mishkin, Chong Zhang,
Sandhini Agarwal, Katarina Slama, Alex Ray, et al.
2022. Training language models to follow instruc-
tions with human feedback, 2022. URL https://arxiv.
org/abs/2203.02155 , 13.
Alec Radford, Jeffrey Wu, Rewon Child, David Luan,
Dario Amodei, Ilya Sutskever, et al. 2019. Language
models are unsupervised multitask learners. OpenAI
blog, 1(8):9.
Abel Salinas and Fred Morstatter. 2024. The butterfly
effect of altering prompts: How small changes and
jailbreaks affect large language model performance.
arXiv preprint arXiv:2401.03729 .Shibani Santurkar, Esin Durmus, Faisal Ladhak, Cinoo
Lee, Percy Liang, and Tatsunori Hashimoto. 2023.
Whose opinions do language models reflect? In In-
ternational Conference on Machine Learning , pages
29971–30004. PMLR.
Gabriel Simmons and Christopher Hare. 2023. Large
language models as subpopulation representative
models: A review. arXiv preprint arXiv:2310.17888 .
Kaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, and Tie-
Yan Liu. 2020. Mpnet: Masked and permuted pre-
training for language understanding. Advances in
neural information processing systems , 33:16857–
16867.
Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Al-
isa Liu, Noah A Smith, Daniel Khashabi, and Han-
naneh Hajishirzi. 2022. Self-instruct: Aligning lan-
guage models with self-generated instructions. arXiv
preprint arXiv:2212.10560 .
Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa
Liu, Noah A Smith, Daniel Khashabi, and Hannaneh
Hajishirzi. 2023. Self-instruct: Aligning language
models with self-generated instructions. In Proceed-
ings of the 61st Annual Meeting of the Association for
Computational Linguistics (Volume 1: Long Papers) ,
pages 13484–13508.
Shengyu Zhang, Linfeng Dong, Xiaoya Li, Sen Zhang,
Xiaofei Sun, Shuhe Wang, Jiwei Li, Runyi Hu, Tian-
wei Zhang, Fei Wu, et al. 2023. Instruction tuning
for large language models: A survey. arXiv preprint
arXiv:2308.10792 .
Yaowei Zheng, Richong Zhang, Junhao Zhang, Yanhan
Ye, and Zheyan Luo. 2024. Llamafactory: Unified
efficient fine-tuning of 100+ language models. arXiv
preprint arXiv:2403.13372 .
A Reddit Data
A.1 Subreddits
We briefly introduce each subreddit in Table 3.
Statistics of data from different subreddits are
shown in Table 4.
B Instructional Data Generation
B.1 Topic Modeling with BERTopic
Following the pipeline of BERTopic (Grootendorst,
2022), we first obtain the text embeddings using
all-mpnet-base-v2 (Song et al., 2020). The em-
bedding dimensions are reduced with UMAP, with
n_neighbors 15 and n_components 5. Then the
embeddings are clustered using HDBSCAN, with
min_cluster_size 40. After fitting the model, we
remove texts that are not assigned any topics. Ta-
ble 5 and Table 6 present the top 10 most frequent
topics in politics anddiet.B.2 Prompting Template for C OMM INST
The prompting template for generating the open-
ended instruction-response pairs in COMM INST
and multi-choice question-answer pairs in COMM -
SURVEY is shown in Figure 4.
B.3 Statistics of C OMM INST and
COMM SURVEY
Table 7 describes the number of open-ended
instruction-response pairs in COMM INST and
multi-choice question-answer pairs in COMM SUR-
VEY. The variance is due to their different topic
coverage.
B.4 Community Agreement Analysis
For a pair of communities CiandCj, we identify
their common survey questions in COMM SURVEY i
andCOMM SURVEY j, and compute their agreement
on the questions using Cohen’s Kappa. The agree-
ment matrices for politics anddietare shown in
Figure 5.
In the politics domain, we observe significant
polarization between communities. For example,
the agreement between r/Liberal and both r/Con-
servative (0.01) and r/AskThe_Donald (0.03) is
extremely low, indicating the deep ideological di-
vide between these left-leaning and right-leaning
communities. This low agreement reflects how
vastly different their responses are to the same po-
litical survey questions, aligning with the broader
patterns of political polarization seen across on-
line platforms. On the other hand, r/Conservative
andr/AskThe_Donald exhibit much higher agree-
ment (0.59), highlighting the ideological overlap
between these conservative-leaning communities,
likely reflecting their shared values and viewpoints
on key political issues.
Meanwhile, r/NeutralPolitics shows moderate
agreement with both r/Anarcho_Capitalism (0.24)
andr/Liberal (0.28), suggesting that as a centrist or
neutral forum, it shares certain perspectives with
both libertarian and liberal ideologies. Addition-
ally, r/Anarcho_Capitalism shows higher agree-
ment with conservative-leaning subreddits, such as
r/Conservative (0.36) and r/AskThe_Donald (0.44),
reflecting shared economic or libertarian principles,
despite divergences on other political issues.
In the diet domain, the relationships between
the communities are more practical and less po-
larized compared to politics . Communities like
r/keto andr/WeightLossAdvice exhibit moderateSubreddit Description
r/Liberalr/Liberal is a subreddit dedicated to discussions and news from a liberal political
perspective, focusing on progressive policies, social justice, and left-leaning viewpoints.
r/NeutralPoliticsr/NeutralPolitics is a community dedicated to evenhanded, empirical discussion of
political issues. It is a space to discuss policy and the tone of political debate.
r/Anarcho_Capitalismr/Anarcho_Capitalism is a subreddit dedicated to discussing
free-market capitalist anarchism and related topics, advocating for a society where
voluntary interactions enhance liberty and opportunity for all.
r/Conservativer/Conservative offers the largest space on Reddit for fiscal and social
conservatives to explore and discuss political and cultural issues from a distinctly
conservative perspective.
r/AskThe_Donaldr/AskThe_Donald is a subreddit that serves as a hub for supporters of former President
Donald Trump, fostering discussions around conservative politics, pro-Trump views,
and right-wing ideologies.
r/ketor/keto is a community for sharing experiences and advice about the low-carb Ketogenic
diet, which supports a range of health conditions from diabetes to epilepsy
r/WeightLossAdvicer/WeightLossAdvice is a subreddit where users share tips, strategies, and support for healthy
and sustainable weight loss, with a focus on practical advice and personal experiences.
r/EDAnonymousr/EDAnonymous is a subreddit that provides a supportive, anonymous space for individuals
struggling with eating disorders to share their experiences, seek advice, and offer
encouragement on the path to recovery.
Table 3: Reddit forums used in this study.
r/Lib r/NeutralPol r/Anarcho_Cap r/Conserv r/ATDonald
# of comments 31,233 35,725 670,686 2,243,842 142,543
# of submissions 5,243 2,072 22,551 153,813 15,645
r/keto r/WLAdvice r/EDAnonymous
# of comments 603,466 225,635 347,477
# of submissions 49,571 42,840 99,925
Table 4: Number of comments and submissions in each subreddit.
agreement (0.39), likely reflecting shared goals
related to weight loss and health, even though
they may emphasize different strategies. Similarly,
r/EDAnonymous andr/keto (0.38) show moderate
overlap, suggesting that while their focus areas are
different—one being centered on eating disorders
and the other on ketogenic diets—they share some
common ground in their approaches to health and
diet-related topics.
The strongest alignment within the dietdomain
is between r/WeightLossAdvice andr/EDAnony-
mous (0.41), which likely stems from overlapping
concerns about diet and body image, which are
central to both communities’ discussions.
C Human Annotation
We verify the faithfulness of COMM SURVEY as
the “semi-ground truths” for the communities via
human annotation. We also tried directly posting
the survey questions to the subreddits and having
community members answer them. However, our
posts were immediately removed by moderators
and our accounts were banned from certain subred-
dits. This further indicates the difficulty of directlysurveying online communities.
C.1 Annotator Recruiting
The four annotators for the politics domain closely
follow political news and are knowledgeable about
the platforms of the parties represented in our sam-
ple. The three annotators for the dietdomain are
active members of diet and diet and have substan-
tial knowledge of diet-related topics and trends. To
ensure the annotators were capable of accurately
answering the survey questions for different com-
munities, we implemented a thorough selection and
training process. Annotators were chosen based on
their demonstrated expertise and familiarity with
the relevant domains. Additionally, we conducted
preliminary tests where annotators answered a sub-
set of questions, and their responses were evaluated
for consistency and accuracy.
C.2 Annotation Process
We randomly sampled 20 questions from
COMM SURVEY -POLITICS (Figure 6) and 10
questions from COMM SURVEY -DIET(Figure 7)
for the annotators to answer. When answeringidx Topic Keywords
1vaccine, covid, vaccinated, vaccines, flu, unvaccinated, vaccination, mrna, pandemic, data
2climate, prices, solar, change, co2, emissions, coal, cars, fuels, earth
3ballots, fraud, election, voter, ballot, evidence, voters, machines, audits, rigged
4abortion, abortions, fetus, roe, murder, unborn, conception, choice, womb, cells
5ukraine, russia, putin, nato, war, ukrainians, crimea, invade, conflict, eu
6twitter, facebook, musk, google, social, platforms, companies, users, censorship, ban
7gun, guns, firearms, shootings, firearm, rifles, laws, amendment, ammo, armed
8impeachment, mueller, fbi, impeach, documents, collusion, comey, congress, whistleblower, crimes
9gender, trans, transgender, lgbt, dysphoria, children, sexuality, identity, pronouns, genders
10 capitol, blm, antifa, riots, riot, insurrection, rioters, protesters, terrorism, january
Table 5: Top-10 most frequent topics in politics . Each topic is represented by the topic-10 keywords.
idx Topic Keywords
1 keto, protein, ketosis, started, macros, back, weeks, carbs, diet, calories
2 skinny, thin, girls, like, overweight, body, underweight, weight, hate, myself
3 thank, therapy, relapse, recover, help, life, support, yourself, proud, treatment
4 scale, week, water, lose, weighing, daily, trend, fluctuates, months, plateau
5 potassium, sodium, magnesium, electrolytes, mg, supplement, ketoade, citrate, 5000mg, chloride
6 alcohol, drinking, beer, drink, drinks, liquor, alcoholic, gin, booze, drinker
7 protein, macros, fat, min, kcal, 20g, carbs, bf, lean, need
8 binging, restricting, binges, eating, hunger, control, bingeing, cycle, guilt, feeling
9 ed, eds, recovery, recover, therapist, treatment, me, help, coping, talk
10 coffee, tea, chocolate, brew, creamer, starbucks, latte, unsweetened, flavors, sweetener
Table 6: Top-10 most frequent topics in diet. Each topic is represented by the topic-10 keywords.
each question, the annotators were instructed to
search the relevant posts from the subreddit and
learn their views from the discussions, instead of
solely relying on their pre-assumption about the
community. Each annotator filled out the question
for a different subset of the communities, as shown
in Table 8. If multiple annotators annotated for a
community, they had another round of discussions
to resolve their disagreement. As a result, for
community, the annotators delivered one set of
annotations of the survey questions.
C.3 Annotation Evaluation
For each subreddit, we compare the LLM-
generated “semi-ground truths” to the label from
human annotators, and present the accuracy in
Table 9. In both domains, “semi-ground truths”
achieve strong agreement with human annotations
for most subreddits, which gives confidence that
the advanced LLM-generated survey answers can
be used as “semi-ground truth” to evaluate fine-
tuned foundational LLMs.r/Lib r/NeutralPol r/Anarcho_Cap r/Conserv r/ATDonald
# of instructions 234 234 300 303 303
# of survey questions 156 156 200 202 202
r/keto r/WLAdvice r/EDAnonymous
# of instructions 1,032 885 870
# of survey questions 688 590 580
Table 7: Number of generated open-ended instruction-response pairs in COMM INSTiand multi-choice question-
answer pairs in C OMM SURVEY i, for each community.
r/Lib r/NeutralPol r/Anarcho_Cap r/Conserv r/ATDonald
Annotator 1 x x
Annotator 2 x x x x
Annotator 3 x x
Annotator 4 x x
r/keto r/WLAdvice r/EDAnonymous
Annotator 1 x x x
Annotator 2 x x
Annotator 3 x x
Table 8: Communities that each annotator annotated for.
r/Lib r/NeutralPol r/Anarcho_Cap r/Conserv r/ATDonald
Human-LLM Acc 0.75 NA 0.65 0.55 0.55
r/keto r/WLAdvice r/EDAnonymous
Human-LLM Acc 0.7 0.6 0.5
Table 9: Agreement between human annotators’ survey responses and the advanced LLM (GPT-4o) generated
survey answers, measured by accuracy.Below are comments from 5 different subreddits related to a topic. The topic can be represented using these keywords: ballots, fraud, election, voter, ballot, evidence, voters, machines, audits, rigged. Comments from r/Liberal Comment 1: xxx … Comment 50: xxx Comments from r/Anarcho_Capitalism Comment 1: xxx … Comment 50:xxx Comments from r/NeutralPolitics Comment 1: xxx … Comment 50: xxx Comments from r/Conservative Comment 1: xxx … Comment 50: xxx Comments from r/AskThe_Donald Comment 1: xxx … Comment 50: xxx Write 5 questions (Q1 through Q5) on this topic that can be answered based on these comments. For a subreddit, each question should be answered in a way that the members from the subreddit would do, and the answers should echo the comments shown above. Do NOT rely on your background knowledge about the specific subreddits to answer the questions. The questions should be low-level, detailed, trigger different responses that differentiate between different subreddits. Don’t ask too high-level questions. The questions should not be in the style of reading comprehension ones, and they are intended for members in the subreddits to answer. The questions should not contain “comment” in them. Each question should be paired with answers from all 5 subreddits. For the first 3 questions, they are open-ended. The answers should be concise (fewer than 32 tokens), legible, grammatically correct. For the second 2 questions, they are multi-choice questions and are associated with four options (A through D). Below is the format of generated questions. Q1: [open-ended question] Response from r/Liberal: [answer in clean text] Response from r/Anarcho_Capitalism: [answer in clean text] Response from r/NeutralPolitics: [answer in clean text] Response from r/Conservative: [answer in clean text] Response from r/AskThe_Donald: [answer in clean text] Q2: … Q3: … Q4: [multi-choice question] A.xxx B.xxx C.xxx D.xxx Answer from r/Liberal: A/B/C/D Answer from r/Anarcho_Capitalism: A/B/C/D Answer from r/NeutralPolitics: A/B/C/D Answer from r/Conservative: A/B/C/D Answer from r/AskThe_Donald: A/B/C/D Q5: …Figure 4: Prompting template to generate C OMM INST and C OMM SURVEY in the politics domain.Anar_Cap Liberal NeutralPol Conserv AT_DonaldAnar_Cap Liberal NeutralPol Conserv AT_Donald1.00 0.10 0.24 0.36 0.44
0.10 1.00 0.28 0.01 0.03
0.24 0.28 1.00 0.19 0.13
0.36 0.01 0.19 1.00 0.59
0.44 0.03 0.13 0.59 1.00
0.00.20.40.60.81.0(a) politics
keto WeightLossAdvice EDAnonymousketo WeightLossAdvice EDAnonymous1.00 0.39 0.38
0.39 1.00 0.41
0.38 0.41 1.00
0.00.20.40.60.81.0 (b) diet
Figure 5: Pairwise agreement between different communities, measured by Cohen’s Kappa.1. Which measure do users from these subreddits most commonly support to address school shootings? A. More gun control laws B. Arming teachers and increasing school security C. Mental health interventions D. Stricter penalties for illegal gun possession 2. How should society address the issue of transgender athletes in sports? A. Allow them to compete according to their gender identity B. Create separate categories for transgender athletes C. Require them to compete according to their biological sex D. Ban transgender athletes from competitive sports 3. How do members of your subreddit view the term "echo chamber"? A. As a necessary evil B. As something to avoid C. As a positive thing D. As a misunderstood concept 4. According to the comments, what is the main reason some users believe the US should not get involved in Ukraine? A. It's Europe's problem B. Fear of nuclear escalation C. Financial burden D. Corruption in Ukraine 5. What is a commonly suggested alternative to taking on large student loans for college? A. Community college B. Trade school C. Scholarships and grants D. All of the above 6. How do diGerent groups perceive the involvement of Trump in the January 6th events? A. He incited the violence directly B. His rhetoric contributed to the atmosphere but didn’t incite violence directly C. He had no role; it was spontaneous D. It was a false ﬂag operation 7. Which argument is often used by pro-choice supporters to counter the claim that abortion is murder? A. Fetus viability criteria B. Women's right to bodily autonomy C. Economic impact on unwanted pregnancies D. Historical context of abortion laws 8. How should the government address tax loopholes used by the wealthy? A. Increase audits and enforcement B. Simplify the tax code and eliminate loopholes C. Maintain current practices D. Increase taxes across all brackets 9. What is the stance on abortions in cases of rape from your subreddit? A. Always unacceptable B. Acceptable only if the mother’s life is at risk C. Acceptable in the ﬁrst trimester D. Acceptable in all cases 10. Which policy is believed to most impact gasoline prices? A. Increasing oil drilling B. Subsidizing EVs C. Imposing carbon taxes D. Restricting oil imports  Figure 6: Ten multiple choice survey questions (out of the twenty) in COMM SURVEY for human evaluation in the
politics domain.1. What is a realistic weight loss rate per week? A. 5 pounds B. 0.5 to 2 pounds C. 3 to 4 pounds D. 4 to 6 pounds 2. When experiencing a relapse, what should be your next step? A. Give up and wait for better conditions B. Reﬂect, learn, and try again C. Punish yourself for failing D. Seek immediate professional help 3. What strategy do you use to avoid eating food you don’t want during family meals? A. Politely decline and change the subject B. Take the food and don’t eat it C. Explain your dietary restrictions D. Avoid family meals altogether 4. What is your primary reason for tracking calories? A. Weight loss B. Ensuring proper nutrition C. Managing eating habits D. I don't track calories 5. What role do genetics play in where you store and lose fat ﬁrst? A. No role B. Minor role C. Major role D. Complete control 6. How do community members feel about using protein shakes as meal replacements? A. They are convenient but should not replace whole foods entirely B. They are eSective and can help with quick weight loss C. They cause bowel issues and are not sustainable long-term D. They are great for muscle recovery but should be used sparingly 7. What is one method suggested to help control emotional eating? A. Tracking macros B. Going for a walk C. Drinking more coSee D. Joining a support group 8. How do you handle unsolicited advice or comments about your weight? A. I ignore them and focus on my goals B. I try to educate the person giving advice C. I get upset but don’t confront them D. I change the topic immediately 9. What do members of your subreddit often replace breakfast with? A. Black coSee B. Protein shakes C. Small snacks D. Nothing, they wait until lunch 10. When you have a cheat meal, what is the most important aspect to consider? A. The type of food you are eating B. The timing of the cheat meal C. Balancing it with exercise D. How it ﬁts into your weekly calorie intake Figure 7: Ten multiple choice survey questions C OMM SURVEY for human evaluation in the dietdomain.