Multimodal Clickbait Detection by De-confounding Biases Using Causal
Representation Inference
Jianxing Yu∗†, Shiqi Wang†, Han Yin†, Zhenlong Sun, Ruobing Xie, Bo Zhang, Yanghui Rao
School of Artificial Intelligence, Sun Yat-sen University, Zhuhai, 519082, China
International Campus, Zhejiang University, Haining, 314400, China
Key Laboratory of Sustainable Tourism Smart Assessment Technology, Ministry of Culture and Tourism
WeChat Search Application Department, Tencent, Beijing, 100080
Pazhou Lab, Guangzhou, 510330, China
{yujx26, wangshq25, raoyangh}@mail.sysu.edu.cn, han.22@intl.zju.edu.cn
richardsun@tencent.com, xrbsnowing@163.com, nevinzhang@tencent.com
Abstract
This paper focuses on detecting clickbait posts
on the Web. These posts often use eye-catching
disinformation in mixed modalities to mislead
users to click for profit. That affects the user
experience and thus would be blocked by con-
tent provider. To escape detection, malicious
creators use tricks to add some irrelevant non-
bait content into bait posts, dressing them up as
legal to fool the detector. This content often has
biased relations with non-bait labels, yet tradi-
tional detectors tend to make predictions based
on simple co-occurrence rather than grasping
inherent factors that lead to malicious behavior.
This spurious bias would easily cause misjudg-
ments. To address this problem, we propose a
new debiased method based on causal inference.
We first employ a set of features in multiple
modalities to characterize the posts. Consider-
ing these features are often mixed up with un-
known biases, we then disentangle three kinds
of latent factors from them, including the invari-
ant factor that indicates intrinsic bait intention;
the causal factor which reflects deceptive pat-
terns in a certain scenario, and non-causal noise.
By eliminating the noise that causes bias, we
can use invariant and causal factors to build a
robust model with good generalization ability.
Experiments on three popular datasets show the
effectiveness of our approach.
1 Introduction
With the rapid development of social media, people
share views and advertise products by posting con-
tent on platforms (Liao et al., 2021) like WeChat,
Twitter, Instagram, etc. To increase viewership and
obtain more advertising revenue, unscrupulous cre-
ators misuse these platforms to publish deceptive,
poor-quality posts. Such posts are often described
with a catchy thumbnail or a sensational headline.
For example, the posts have a sexy thumbnail, with
∗Corresponding author.
†These authors have contributed equally to this work.curiosity-inciting phrases like “ You Won’t Believe ”,
and “ X Reasons Why ” in their headlines. That
would bait readers to click on the linked articles.
However, these articles would be unrelated to the
thumbnails and headlines of the posts. Moreover,
they are often full of hoaxes, rumors, and fake news,
which not only degrade users’ experience but also
affect the credibility of the platforms (Zhu et al.,
2023). Thus, the detection of such clickbait posts
has great commercial value for social media.
Due to the large volume of emerging posts, a
manual review of the clickbait is infeasible. Ma-
chine detection has become a hot topic (Comito
et al., 2023). The detective sources can be summa-
rized into two categories (Yadav and Bansal, 2023).
The first is based on social behavior. Since bait
posts are required to spread in social networks to
expand their influence, typical propagation charac-
teristics can be observed. It can be detected based
on social metadata like comments, the number of
views, shares, likes, etc (Agarwal et al., 2023). That
requires a rich collection of user feedback for judg-
ment, but this feedback is often delayed or some
users do not even share it. As a result, malicious
posts can only be found after they have been widely
spread, which is too late for online applications.
Another direction is to analyze the post contents.
The bait posts often have certain linguistic charac-
teristics in terms of deceptive words, syntax, sub-
jectivity, writing style (Zhou et al., 2020), and even
punctuation (Coste and Bufnea, 2021). Besides,
there may be abnormal relations between their sub-
parts in various modalities, such as a rumor article
text with visual thumbnails of an irrelevant actor to
attract clicks. Early works design a set of rules to
detect these features and relations, but the rules are
hand-crafted and non-scalable. Current mainstream
methods turn to the neural model for improving
scalability. They seek correlations between the
post content and labels to make predictions.
However, to escape detection, malicious creatorsarXiv:2410.07673v1  [cs.LG]  10 Oct 2024Conspicuous Clickbait Post 
with easy-to-detect bait content
How difficult studying abroad is!!! Here
are some secrets you must know
Normal Union 2023-05-16 19:00
Posted on Brighton
Are you interested in studying in the UK? 
A top university will change your life!
What are you waiting for? Call us at +44
(20) 3691 5858.
We assembled a team of strong consultants 
with backgrounds in studying abroad at
Oxford, Cambridge, Manchester, and other
top universities. We have helped dozens of 
applicants get their desired offers. Don’t 
miss this opportunity, contact us soon!!!
Normal Union
Share Favorites 5 32Reads 131unrelated
Another heavy defeat for small-town 
swots. Little witch returns to Oxford for 
the master’s degree
Movie Frontline 2023-07-24 11:30
Posted on Melbourne
Emma, who plays Hermione in the “Harry 
Potter” movies, will return to Oxford this
year to study for the master’s degree.
If you also want to choose a British private 
school for your children, please call +44 
(20) 3691 5858 for consultation! Our team 
have personally inspected the top private
schools in the UK, provide real professional
advice, and are 100% guaranteed to offer!
Movie Frontline
Share Favorites 12 17Reads 3071
unrelated
Inconspicuous Clickbait Post 
disguised with valid contentFigure 1: Clickbait samples. The purple arrow indicates
inconsistencies between the headline and its linked ar-
ticle. The simple clickbait post contains conspicuous
bait-indicative words or advertising content (marked
with blue boxes) which is easily detected. The complex
one disguises the bait content with some valid content
(in red boxes) and makes it look inconspicuous, thus
deceiving and escaping the detector.
would use some unrelated content to disguise a
bait post as a valid one. As shown in Fig.(1), in
the left post, some of the conspicuous bait thumb-
nail and text are replaced with unharmful content,
making it look like a legal one on the right. Such
content may co-occur with non-bait label usually,
creating spurious correlations, i.e., the unstable and
confounding patterns in the feature space (Dogra
et al., 2022). That would easily cheat the model
to fail to discover the hidden bait. Respectively,
some valid posts may be misjudged as bait sim-
ply because they contain content that co-occurs
with a bait label. Such biased correlations lead to
high misjudgments. The bias is inadequate to dif-
ferentiate by a naive encoder, which is designed
for generic content understanding tasks such as
text classification. The encoder focuses on general
embedded representations rather than key factors
that cause fraudulent behaviors (Mukherjee et al.,
2022). These behaviors are not static, their top-
ics and types may change over time. The writing
styles would also vary for different authors, but
such disguise tricks commonly follow some styles
and patterns in a particular scenario. On the other
hand, the data-driven neural model relies on scarce
labeled data heavily. To derive a robust model, wehave to collect data on all scenarios for supervised
training. Such uniform data is either unavailable
or costly to acquire. As a result, the statistics on
limited samples are not significant, which is easy to
train the model to remember some inessential spu-
rious correlations. That would harm the model’s
robustness. A simple solution is to customize a
representation that perceives posts’ quality, but that
would face tedious hand-crafted engineering.
Motivated by above observations, we propose a
new debiased approach to detect clickbait posts. In
detail, we first represent the given posts based on
a set of multimodal features, including textual and
visual features, linguistic and cross-modal features,
as well as features of the creators’ profiles. Consid-
ering these mixed representations contain unknown
biases, we resort to causal representation learning,
which is good at eliminating non-causal spurious
noise. The representations are disentangled into
three key latent factors, including (1) invariant fac-
tor that indicates the inherent bait’s intention and
post quality; (2) causal factor in a specific scenario;
and (3) non-causal noise factor. The noise like un-
related words and topics is defined under a specific
scenario, and each is unique. The invariant factor is
obtained by invariant risk minimization, scenarios
are estimated from the data, and the causal factor is
learned by contrastive learning. By removing the
noise and using the remaining invariant and causal
factors, we can build a robust clickbait detector. It
can combat spurious bias and generalize well on
newly formed bait subspecies. To facilitate training,
we further develop a data augmentation technique
to alleviate the labeled data scarcity problem. Ex-
tensive experiments on three real-world datasets
show the effectiveness of our approach.
The main contributions of this paper include,
•We reveal the issue of bait subspecies evolu-
tion via disguise and point out the challenges
of the resulting spurious bias in the field of
multimodal clickbait detection, which is new.
•We propose a new debiased model from a view
of causal inference. It explores a prior causal
structure to elicit latent key factors that reflect
posts’ quality. That can alleviate spurious bias
and achieve better generalization ability.
•We conduct extensive experiments to fully
evaluate the effectiveness of our method.Multimodal Representation 
Separated ScenariosInvariant Mask 
VariantRepresentation  InvariantRepresentation  
ThumbnailsHeadlines and Article bodiesYou won't believe it!Goddess Emma…ProfilesVisual ExtractorTextual ExtractorLinguistic ExtractorStatisticalExtractorMultimodal IntegrationInput Representation(Step-1)
Causal Mask 
<latexit sha1_base64="X6D4f3ALNNwfyeB72BpvpKavV8Q=">AAACAHicbVBNS8NAEN3Ur1q/oh48eFksgqeSiF/HghcPHipYW2hD2Gw37dLNJuxOhBJy8a948aCIV3+GN/+NmzYHbX0w8Hhvhpl5QSK4Bsf5tipLyyura9X12sbm1vaOvbv3oONUUdamsYhVNyCaCS5ZGzgI1k0UI1EgWCcYXxd+55EpzWN5D5OEeREZSh5ySsBIvn3QjwiMKBHZbe5nNJYaFNGQ+3bdaThT4EXilqSOSrR8+6s/iGkaMQlUEK17rpOAlxEFnAqW1/qpZgmhYzJkPUMliZj2sukDOT42ygCHsTIlAU/V3xMZibSeRIHpLM7V814h/uf1UgivvIzLJAUm6WxRmAoMMS7SwAOuGAUxMYRQxc2tmI6IIhRMZjUTgjv/8iJ5OG24F43zu7N6E5dxVNEhOkInyEWXqIluUAu1EUU5ekav6M16sl6sd+tj1lqxypl99AfW5w/qHZcr</latexit>LconstrastScenario-Specific Causal and Non-Causal Factors(Step-3)Non-causal FactorPrediction and Data AugmentationScenario-specific Causal FactorLabeled DataExtraction of Invariant Causal Factors(Step-2)
Contrastive Learning(Step-4)Extraction of FusionNon-clickbaitClickbait  /Projection
Projection
<latexit sha1_base64="cAjsiuPxkQ0Td+PLAyRrlb/x3VQ=">AAACAXicbVDLSsNAFJ3UV62vqBvBzWARXJVEfC0Lbly4qGAf0IYwmU7aoTOTMDMRSogbf8WNC0Xc+hfu/BsnaRbaemDgzDn3cu89Qcyo0o7zbVWWlldW16rrtY3Nre0de3evo6JEYtLGEYtkL0CKMCpIW1PNSC+WBPGAkW4wuc797gORikbiXk9j4nE0EjSkGGkj+fbBgCM9xoilt5mfFp8gTHmW+XbdaTgF4CJxS1IHJVq+/TUYRjjhRGjMkFJ914m1lyKpKWYkqw0SRWKEJ2hE+oYKxIny0uKCDB4bZQjDSJonNCzU3x0p4kpNeWAq8xXVvJeL/3n9RIdXXkpFnGgi8GxQmDCoI5jHAYdUEqzZ1BCEJTW7QjxGEmFtQquZENz5kxdJ57ThXjTO787qTVjGUQWH4AicABdcgia4AS3QBhg8gmfwCt6sJ+vFerc+ZqUVq+zZB39gff4AlCKXhw==</latexit>Lm
<latexit sha1_base64="eJ1rMwH5zm0m8wb5HWd6AxAwrik=">AAAB8nicbVDLSsNAFL3xWeur6tJNsAhdlUSkuiy4cVnBPqANZTKdtEMnM2HmRiihn+HGhSJu/Rp3/o2TNgttPTBwOOde5twTJoIb9LxvZ2Nza3tnt7RX3j84PDqunJx2jEo1ZW2qhNK9kBgmuGRt5ChYL9GMxKFg3XB6l/vdJ6YNV/IRZwkLYjKWPOKUoJX6g5jgJIwyTufDStWrewu468QvSBUKtIaVr8FI0TRmEqkgxvR9L8EgIxo5FWxeHqSGJYROyZj1LZUkZibIFpHn7qVVRm6ktH0S3YX6eyMjsTGzOLSTeUSz6uXif14/xeg2yLhMUmSSLj+KUuGicvP73RHXjKKYWUKo5jarSydEE4q2pbItwV89eZ10rup+o954uK42a0UdJTiHC6iBDzfQhHtoQRsoKHiGV3hz0Hlx3p2P5eiGU+ycwR84nz+hVJFr</latexit>ic<latexit sha1_base64="0YhFS2G3+m2b5e04271kmrM3hpw=">AAAB8nicbVDLSsNAFL3xWeur6tJNsAhdlUSkuiy4cVnBPqANZTKdtEMnM2HmRiihn+HGhSJu/Rp3/o2TNgttPTBwOOde5twTJoIb9LxvZ2Nza3tnt7RX3j84PDqunJx2jEo1ZW2qhNK9kBgmuGRt5ChYL9GMxKFg3XB6l/vdJ6YNV/IRZwkLYjKWPOKUoJX6g5jgJIwyQ+fDStWrewu468QvSBUKtIaVr8FI0TRmEqkgxvR9L8EgIxo5FWxeHqSGJYROyZj1LZUkZibIFpHn7qVVRm6ktH0S3YX6eyMjsTGzOLSTeUSz6uXif14/xeg2yLhMUmSSLj+KUuGicvP73RHXjKKYWUKo5jarSydEE4q2pbItwV89eZ10rup+o954uK42a0UdJTiHC6iBDzfQhHtoQRsoKHiGV3hz0Hlx3p2P5eiGU+ycwR84nz+wkJF1</latexit>scMLP ClassifierManual or Auto AnnotationHistorical dataFigure 2: The overview framework of our causal clickbait detector.
2 Approach
Fig.(2) shows our framework with four steps. We
first extract multimodal features from the posts. By
causal inference, we then disentangle the invariant
factors from them, and separate the remaining parts
into the causal factor and non-causal factor. Finally,
we make the prediction based on the invariant and
causal factors. Next, we define some notations and
elaborate on each component of our approach.
2.1 Notations and Problem Formulation
Clickbait detection . Given a post xi, our task aims
to learn a model F(yi|xi,ΘF)to predict whether
it is clickbait ( yi= 1), where ΘFis the model’s
parameter set, xidenotes the post contents, includ-
ing the textual headline, visual thumbnail and their
linked mixed-modal article. These sub-parts have
some deceptive characteristics and relations, such
as containing malicious rhetoric like exaggeration,
eroticism, bluffing, weirdness, and distortion; the
headline or thumbnail is seductive but unrelated to
the article. In addition, the creators constantly yield
new bait subspecies to avoid being detected and
seized. Thus, our target is to find an optimized ˆΘF
byarg min ˆΘFL(ˆF(yi|xi,ˆΘF)|Dtr)which can be
generalized well to the test set Dtewith a lowest
costL(Dte), where Dtris the training set, L(·)de-
notes a cross-entropy classification loss.
Eliminating spurious correlations . As displayed
in Fig.3.(a), traditional methods often make pre-
dictions based on the co-occurrence between post
features Xand labels Y. Ideally, Xis expected to
reflect the hidden malicious intention of the post.
However, it comes from generic encoders withoutconsidering the fraud behavior. That inevitably in-
troduces some false correlations, such as wrongly
linking some trivial but irrelevant terms or images
with non-bait label. Besides, some bait modes are
stable while some writing styles would change in
various scenarios, such as periods, types, and cre-
ators. It is easy to make erroneous predictions with-
out grasping this distinction. A simple solution is
to dissociate Xinto several factors, i.e., an invari-
ant factor ( IC) that reflects malicious intention, a
causal factor for a certain scenario ( SC), and non-
causal noise ( NF); and then eliminate the effect
of noise NF onY, as Fig.3.(b). However, without
necessary constraints, the spurious correlations in
NF may permeate via ICandSCto harm the pre-
diction of Y. To prevent this effect, we introduce a
causal structure to regularize these latent variables,
as Fig.3.(c). We first use a confounder Cto capture
mixed relations of three factors under the condition
of a certain scenario S. We then isolate the invari-
antICby blocking the influence of ConIC. The
bias in Ccannot affect Ythrough IC. To fully put
away the noise NF, we cut the backdoor paths of
CandSonNF. The SandCcan only impact Y
viaSC. In this way, we can independently elicit
salient unbiased factors without mutual influence,
which can generalize well to new bait subspecies.
2.2 Multimodal Feature Extraction
To fully capture the characteristics of the posts, we
extract five kinds of features in multiple modalities.
More details are exhibited in the Appendix A.
(1) Visual Features : We encode each post image
(e.g. thumbnail and article figure) by transformer-XY(a)(b)XYSCICNFNFSCICXYSC(c)Figure 3: Causal structure for de-confounding biases.
Gray and white nodes represent observable and unob-
served variables, respectively; the bidirectional and uni-
directional arrows denote correlations and causalities,
respectively; purple arrows are key causalities determin-
ing result Y; and orange arrows refer to scenario effects.
based Swin-T (Liu et al., 2021). To grasp the fine-
grained features in the image, we conduct facial
recognition and object detection by DNN andReti-
naNet models (Lin et al., 2017), respectively.
(2) Textual Features : For the text in the post,
such as headline, description, and associated arti-
cle, we first remove hashtag, mention, punctuation,
and URL. We then tokenize each and embed it by
BERT basepre-trained model (Devlin et al., 2019).
Since clickbait posts often contain seductive text in
the thumbnails, we utilize the OCR technique (Li
et al., 2023) to extract the text and encode it.
(3) Cross-modal Features : The clickbait posts of-
ten contain inconsistencies, such as using inviting
thumbnails to lure clicking the unrelated article.
Verifying this cross-modal unmatch between the
post’s sub-parts can help prediction. Due to the het-
erogeneous gap, it is hard to use this inter-modal
complementary benefit directly. To tackle this is-
sue, we employ a CTTransformer (Lu et al., 2019),
which is good at capturing multi-modal relations.
(4) Linguistic Features : To capture the bait pat-
terns and writing styles, we extract six kinds of
features based on thumbnail, headline, and article
body, including article body-thumbnail disparity,
article body-headline disparity, thumbnail-headline
disparity, sentiment of headline, lexical analysis of
headline and baitiness analysis of headline.
(5) Profile Features : The posts’ quality often de-
pends on the creators, i.e., bad creators tend to
write malicious posts. To characterize the quality
of each creator uj, we extract features based on its
profiles, involving the register age, self-description
and screen name of uj, number of followers for uj,
number of users that ujis following, number of cre-
ated posts of uj, time elapsed after uj’s first post,
whether the ujaccount is verified or not, whether
ujallows the geo-spatial positioning, time differ-
ence between the source post time and uj’s share
time, and length of retweet path between ujand asource post. The length is 1 if ujretweets the post.
By concatenating all these features, we can obtain a
d-dimensional vector xias a post’s representation.
2.3 Disentanglement of Invariant Factors
The generic ximay contain spurious correlations,
which are mostly unreliable across various scenar-
ios. For example, the false correlation between an
unrelated actress and the bait label will change in
different contexts of posts. In contrast, it is usu-
ally stable for the bait behavior which is caused
by some common factors, such as underlying lan-
guage patterns and deceptive habits. By seeking
commonalities in various scenarios, we can capture
these inherent factors to achieve better robustness.
Casual Inference : We use an invariance mask
m∈Rdto dissociate the invariant characteristics
of the original representation xiasici=m⊙xi,
where⊙is the element-wise product operator. The
opposite of mis the variance mask, which can ex-
tract the variant representation vci= (1−m)⊙xi.
Ideally, icishould have identical joint distributions
with the unbiased variable across various scenarios.
We pursue it by optimizing mwith an invariant
risk minimization ( IRM) (Arjovsky et al., 2019) ob-
jective. IRM introduces a penalty for the variation
of empirical risks in all scenarios. It tries to mask
some features and calculate their impact on the re-
sults, so as to find out factors that have a stable and
significant impact on the results. That encourages
the mask to suppress spurious features and empha-
size the causally invariant ones. We formulate IRM
loss as a gradient norm penalty over the empirical
riskLsin each training scenario as Eq.(1):
Lm=1
|S|P
s∈S[Ls(m,Fm)+
α||▽FmLs(m,Fm)||2] +β||m||2.(1)
where αandβare trade-off factors, the second
term is the constraint over the variance of scenarios,
and the third one is a regularization term. Ls=
L(Fm(yi|xi,ΘFm)|Dtr
s)is the classified loss on
the training subset Dtr
sunder the specific scenario
s. This objective can enforce the mask mto seek
stable inherent patterns in the context, instead of
learning an average effect of spurious correlations.
Scenario Estimation : The key to optimizing
mlies in the division of scenarios. We thus uti-
lize scenarios to infer the spurious correlations and
determine each with a set of operations. In each sce-
nario, the posts have certain characteristics, such aswriting styles, hot topics, and evolving bait patterns.
Since the scenario is unprovided, we propose to es-
timate it from the data with two iterative phases.
First, we learn a scenario predictive model to fit
the data distribution. We then reassign the samples
into appropriate scenario subsets. To initialize this
iterative process, we randomly assign training sam-
ples to each scenario subset Dtr
s. By alternatively
optimizing the data-fit IRM objective and the esti-
mated scenarios, finally we can learn the invariant
factors across scenarios.
(1) Scenario Division. We observe that the key dif-
ference among various scenarios lie in their char-
acteristics of spurious correlations. We thus ex-
plore such correlations to learn a scenario predic-
tive model Φsfor each s∈ S. In detail, for the ith
sample, Φsevaluates the likelihood that it belongs
to the scenario sbased on its variant representation
vci. Parameterized by θs, the model Φsaims to
minimize the prediction loss on the training subset
Dtr
s, as Eq.(2). Relying on this objective, Φscan
be learned without interference from other scenario
data, which can better handle the spurious bias.
minθsL(Φs(vci|θs)|Dtr
s). (2)
(2) Samples Reallocation. Based on the estimation
in phase 1, we obtain |S|scenario models which in-
dicate different types of spurious biases. Next, we
reallocate all samples to the appropriate scenarios
according to their spurious correlations. In detail,
we feed the variant representation vciinto each
scenario model Φs. Each sample is then assigned
to a scenario with the highest likelihood as Eq.(3).
s(i)←arg maxs∈SΦs(vci|θs). (3)
By running these two phases until convergence, we
obtain stable scenario subsets {Dtr
s|s∈ S} . In turn,
we can optimize the invariance mask m. Finally,
we learn an optimal mto derive a universal causal
factor that is invariant in most situations.
2.4 Dissociation of Causal Factor from Noise
After separating the invariant factor, the remaining
partvciis a mixture of causality and noise in a
specific scenario. We thus further elicit the valu-
able scenario-specific causal factor scifromvci.
We first project it into a latent embedding space,
asξ(vci).ξ(·)is a network with a multi-layer
perceptron, which is parameterized by θξ. When
designing ξ, we do not inject any scenario category
information. That allows us to adapt to some newscenarios without refactoring ξor relearning the pa-
rameters. We then output a causal perception mask
γ=Gumbel −SoftMax (ξ(vci), kd)using the
Gumbel-SoftMax technique. The mask γsets the
values of some dimension to 0and retains kdef-
fective dimensions. By using the mask γ, we can
extract the causal representation as sci=γ⊙vci.
To facilitate the separation of causal factors from
noises, we introduce contrastive constraints based
on the causal interventions. After the causal vector
sciis extracted from vci, we collect the remain-
ing non-causal one nfi= (1−γ)⊙vci.nfican
be used as a contrastive learning signal with the
loss as Eq.(4). For a clickbait sample ( y= 1),
its non-causal feature nfiexactly blocks out the
identifiable clickbait characteristics. When replac-
ing the scenario-specific causal representation sci
withnfi, the prediction is supposed to be the op-
posite, i.e., as non-clickbait. Accordingly, for the
non-clickbait sample ( y= 0), since scidoes not
indicate any clickbait characteristics, using nfifor
detection would not change the prediction.
Lcontrastive =L(Fξ(0|nfi,ΘFξ)|Dtr).(4)
2.5 Prediction and Data Augmentation
By repeating the running flow (i.e., vector mask-
ing→scenario division →mask learning) for T
times till converged, we can obtain the key causal
representations, namely, the invariant causal factor
and scenario-specific causal factor. We concatenate
these two vectors to train a Multilayer Perceptron
classifier, with an objective as Eq.(5).
arg min ˆΘFL(ˆF(yi|[ici;sci],ˆΘF)|Dtr).(5)
To better train the model, we further employ data
augmentation to collect pseudo-labeled data. Since
clickbait posts need to be widely spread to gain
benefits, social behavior is often an effective clue.
We thus design heuristic rules based on social meta-
data, such as share frequency, and viewing time.
This metadata may be lacking in new cases, but
it is sufficient in historical data. That can provide
abundant clickbait cases as training data to reduce
labeled costs. In this way, our model can work well
even if only limited data is provided in some appli-
cations. More details are shown in Appendix D.4.
3 Evaluations
We fully conducted experiments with qualitative
and quantitative analyses to evaluate our approach.3.1 Data and Experimental Settings
We performed evaluations on three popular real-
world datasets, including CLDInst (Ha et al., 2018),
Clickbait17 (Potthast et al., 2018) and FakeNews-
Net(Shu et al., 2020a). By crowd-sourcing, these
datasets were split as bait/non-bait sets with the
size of 4k/3k, 9k/29k, and 5k/17k posts, respec-
tively. For each sample, we crawled the original
post from its URL to collect multimodal data, such
as the thumbnail and creator’s profile.
•CLDInst covers 7,769 fashion-related posts
crawled from Instagram . They are judged by anno-
tators employed from crowdsourcing websites. A
total of 4,260 posts are tagged as clickbait.
•Clickbait17 contains 38,517 Twitter posts as
well as their linked articles from 27 major US news
publishers. To avoid bias, a maximum of 10 posts
per day was sampled for each publisher, with 9,276
posts tagging as clickbait.
•FakeNewsNet is a large-scale multimodal news
dataset that contains over 23k articles with tagged
fake/real labels from the websites of PolitiFact and
GossipCop . It has a rich social context, with 432
fake and 624 real samples from PolitiFact , as well
as 5,323 fake and 16,817 real cases from Gossip-
Cop. Similar to bait posts, fake samples often suf-
fer from issues like irrelevance, inconsistency, etc.
This dataset can be used to evaluate the model’s
ability to recognize bait-like low-quality content.
Each dataset was split into train/validation/test
sets. We tuned the model on a validation set and re-
ported results on the test set. In addition, we further
evaluated the value of data augmentation technique
in Appendix D.4. We employed four typical met-
rics in the field of classification for evaluations,
including accuracy ( ACC ), precision ( PRE), recall
(REC ), and F1-score ( F1). To tackle the class im-
balance problem, we trained all evaluated methods
by using the oversampling technique. To reduce
bias, we repeated running 20times and reported
the average performance. In addition, the config-
urations of all evaluated methods were shown in
Appendix B.
3.2 Comparisons against State-of-the-arts
To verify the effectiveness of our method, we com-
pared it against six typical baselines in the field of
clickbait detection. including (1) dEFEND (Shu
et al., 2019a), a co-attention-based model that pre-
dicted based on both post content and user pro-
files; (2) HPFN (Shu et al., 2020b), which madejudgments based on posts’ propagation on social
network; (3) MCAN (Wu et al., 2021), a multi-
modal model that captured both textual and vi-
sual features by stacked co-attention layers; (4)
CPDM (Mowar et al., 2021), using ensemble clas-
sifier to perceive inconsistencies among content,
headline and thumbnail; (5) CCD (Chen et al.,
2023), a model based on causal intervention and
counterfactual reasoning; (6) VLP (Wang et al.,
2023), a multimodal pre-trained detector.
As displayed in Table 1, our method achieved the
best performance. The outperformance was over
the best baselines (e.g., VLP) on CLDInst ,Click-
bait17 , and FakeNewsNet by 3.78%, 4.66%, and
4.02% in terms of the accuracy metric, respectively.
Methods with multimodal features (i.e., MCAN ,
CPDM ,CCD andVLP) showed better performance,
since these features provided useful discriminant
clues. In addition, our method performed better
than the causal baseline CCD .CCD only tackled
the misalignment among the textual and visual fea-
tures but neglected the spurious bias and disguised
content that are widespread in bait posts. Besides,
we observed on the larger datasets e.g., Clickbait17
andFakeNewsNet , our outperformance was big-
ger. The reason may be that spurious bias in these
datasets was more extensive, and our debiased gain
was greater. To evaluate it, we further selected 500
test samples randomly from each dataset and anno-
tated each post manually. We found that approxi-
mately 23%,26%,27% of the posts were disguised
type, respectively. The datasets Clickbait17 and
FakeNewsNet were more complicated, having a
larger percentage of disguised samples. Moreover,
we provided the precision-recall curves on three
datasets in Fig.(4). Our model achieved the best
precision across all recall levels. That reflected the
effectiveness of our approach in eliminating spu-
rious bias. Ours can obtain a high recall rate and
well identify the bait posts dressed up as valid ones.
3.3 Ablation Studies
To gain insight into the relative contributions of
each component in our approach, we performed
ablation studies on four aspects, including (1) w/o
MFthat discarded the multimodal representation
module and relied solely on text encoders; (2) w/o
EICF that dropped the invariant causal factor by
removing the IRM regularization in Eq.(1); (3) w/o
ENF which threw away the scenario learning mod-
ule, randomly assigned scenarios to samples; (4)
w/o ESCF that removed scenario-specific causalMethodsCLDInst Clickbait17 FakeNewsNet
ACC↑ PRE↑ REC↑ F1↑ ACC↑ PRE↑ REC↑ F1↑ ACC↑ PRE↑ REC↑ F1↑
dEFEND 76.58 ±0.0674.03 ±0.1276.46 ±0.2975.23 ±0.3782.15 ±0.3376.74 ±0.0879.22 ±0.2777.96 ±0.1081.06 ±0.2174.21 ±0.1778.74 ±0.3676.41 ±0.28
HPFN 73.15 ±0.1472.12 ±0.3170.23 ±0.2771.16 ±0.1581.68 ±0.2684.25 ±0.1382.35 ±0.3483.29 ±0.2284.82 ±0.1784.43 ±0.1385.68 ±0.2485.05 ±0.23
MCAN 79.21 ±0.1877.45 ±0.0777.80 ±0.1977.62 ±0.2884.51 ±0.2085.56 ±0.0982.74 ±0.3384.13 ±0.1483.82 ±0.2985.13 ±0.3782.21 ±0.1883.64 ±0.15
CPDM 80.04 ±0.2377.89 ±0.4279.31 ±0.1178.59 ±0.3986.14 ±0.0786.30 ±0.1083.07 ±0.2184.65 ±0.2884.27 ±0.1385.18 ±0.2282.44 ±0.1483.79 ±0.31
CCD 82.77 ±0.1483.13 ±0.1082.91 ±0.1683.02 ±0.2488.36 ±0.2287.61 ±0.1586.46 ±0.0987.03 ±0.2787.72 ±0.1385.96 ±0.2086.46 ±0.1586.21 ±0.14
VLP 85.56 ±0.1684.25 ±0.0783.87 ±0.2084.06 ±0.1288.70 ±0.2687.34 ±0.3786.02 ±0.4186.67 ±0.2488.02 ±0.1087.25 ±0.1686.23 ±0.1986.74 ±0.30
Ours 88.79 ±0.1188.73 ±0.0489.16 ±0.3288.94 ±0.1492.83 ±0.2793.45 ±0.1793.59 ±0.1593.52 ±0.2091.56 ±0.0792.74 ±0.3892.97 ±0.1392.85 ±0.08
Table 1: Comparisons of all methods. The improvements were significant using a statistic t-test with p-value <0.005.
60 65 70 75 80 85 90 95
Recall6065707580859095PrecisionCLDInst
SVM-TS
BiLSTM
dEFEND
HPFN
VLP
Ours
60 65 70 75 80 85 90 95
Recall6065707580859095PrecisionClickbait 1 7
SVM-TS
BiLSTM
dEFEND
HPFN
VLP
Ours
60 65 70 75 80 85 90 95
Recall6065707580859095PrecisionFakeNew sNet
SVM-TS
BiLSTM
dEFEND
HPFN
VLP
Ours
75 80 85 90 95BiLSTM
dEFEND
HPFN
VLP
Ours
60 65 70 75 80 85 90 95
Recall606570758085Precisiond
HPFN
VLP
Ours
60 65 70 75 80 85 90 95
Recall606570758085PrecisionVLP
Ours
65 70 75 80 85 90 95
RecallS
dEFEND
HPFN
VLP
Ours
60 65 70 75 80 85 90 95
Recall6065707580PrecisionOurs
Figure 4: PR curves of all models on three datasets.
factor by deleting the module in Eq.(4).
As shown in Table 2, the ablation on all evalu-
ated components led to a significant performance
drop. This reflected that all four modules were in-
dispensable. Among them, discarding the EICF
module caused the most substantial decrease, i.e.,
more than 6.33% and 6.77% drops in terms of the
accuracy and F1 metrics, respectively. That indi-
cated the usefulness of eliminating spurious bias,
which can improve discriminant and generaliza-
tion ability. The multimodal module was also im-
pactful, with its removal leading to a reduction of
around 4.61% ∼5.63% in terms of accuracy. This
demonstrated the benefits of inter-modal signals to
overcome unimodal one-sidedness. In addition, the
ENF andESCF modules focus on scenario-specific
and non-causal factors, which also led to notice-
able performance drops when they were ablated.
The results validated the rationality of our design.
Ablation studies on other metrics were shown in
Appendix D.5.
DatasetsCLDInst Clickbait17 FakeNewsNet
ACC↓ F1↓ ACC↓ F1↓ ACC↓ F1↓
w/o MF -4.09 ±0.10-4.72 ±0.08 -5.23 ±0.13-5.96 ±0.06 -4.81 ±0.09-5.60 ±0.07
w/o EICF -5.62 ±0.14-6.03 ±0.06 -7.22 ±0.09-8.06 ±0.12 -6.62 ±0.18-7.07 ±0.09
w/o ESCF -2.88 ±0.05-3.70 ±0.08 -3.86 ±0.16-4.27 ±0.11 -3.64 ±0.03-3.87 ±0.14
w/o ENF -3.33 ±0.06-3.92 ±0.10 -4.11 ±0.18-4.73 ±0.09 -3.77 ±0.15-4.31 ±0.05
Table 2: Ablation study with t-test, p-value <0.005.3.4 Study of the Mask Mechanism
Relying on the mask vector m, our model can ex-
tract a causal invariant factor applicable to most
scenarios. We observed that the setting of mcan
be binary ( B) or float ( F), and it can be integrated
into the objective Eq.(1) by the L2norm or a L0
regularizer. To better understand how the mask m
impacted the performance, we tested four mcon-
figurations: ( B+L0), (B+L2), (F+L0) and
(F+L2). As shown in Fig.(5), we found that the
float masks (F) consistently outperformed binary
masks (B). This verified that keeping the contin-
uous mask values provided more representational
power than binary ones. In addition, L2regulariza-
tion worked better than L0. Among all datasets, L2
norm outperformed L0norm by around 1.23% ∼
2.01% on the F1 score. The sparse L0regulariza-
tion might suppress informative dimensions, while
L2allowed more flexibility. More evaluations on
the mask mechanism were shown in Appendix D.1.
CLDInstClickbait17FakeNewsNet
Figure 5: Evaluation the impact of msettings on F1.3.5 Study of the Scenario
Scenario is valuable to learn invariant representa-
tions. These stable features can effectively improve
the robustness of the model and avoid being de-
ceived by disguised content. To study the charac-
teristics of scenarios, we first checked their sepa-
rability. It was estimated from the data based on
alternating optimization. That is, the samples were
grouped to form new scenarios; in turn, after the
scenarios were updated, the samples were moved to
partition again. If most samples no longer changed,
the scenarios can be viewed to be divisible. Thus,
we calculated the ratio of moved samples to infer
the stability of scenarios. If a sample cannot fit the
current scenario and needed to be reassigned to a
new one, we counted it as a moved case. As shown
in Fig.(6), the curves of the moved rate on three
datasets converged after being repeated around 10
rounds. That indicated the scenarios can be sep-
arated and help to capture the spurious bias well.
Moreover, the curve implied the appropriate loop
count for the model optimization. Moreover, we
evaluated the scenario size setting in Appendix D.2.
0 4 8 12 16 20
# Number of Repeats0102030Moved Ratio(%)
CLDInst
Clickbait17
FakeNewsNet
Figure 6: Evaluation on scenario separability based on
the ratio of moved samples.
3.6 Case Studies
Furthermore, we conducted case study to see the ac-
tual effect of our model. Given a dataset like Click-
bait17 , we predicted a score for each test sample.
The highest score indicated the scenario it belonged
to. After classifying all samples, we selected 5 sce-
nario sets with the largest size of samples. We
randomly chose 20 bait and 20 non-bait samples
from each scenario, and visualized their features
by the dimension reduction tool t-SNE . As shown
in Fig.(7), subgraph (a) showed the original fea-
tures cannot differentiate scenarios; (b) presented
the causal invariant features learned by our model.
These features would be helpful for prediction, but
(a) Original space (b) Causal invariant space
(c) Scenario -specific causal space (d) Non -causal space(a) Original space (b) Causal invariant space
(c) Scenario -specific causal space (d) Non -causal spaceNon-clickbait in S#1
Clickbait in S#1Non-clickbait in S#2
Clickbait in S#2Non-clickbait in S#3
Clickbait in S#3Non-clickbait in S#4
Clickbait in S#4Non-clickbait in S#5
Clickbait in S#5Non-clickbait in S#1
Clickbait in S#1Non-clickbait in S#2
Clickbait in S#2Non-clickbait in S#3
Clickbait in S#3Non-clickbait in S#4
Clickbait in S#4Non-clickbait in S#5
Clickbait in S#5
(a) Original space (b) Causal invariant space
(c) Scenario -specific causal space (d) Non -causal spaceNon-clickbait in S#1
Clickbait in S#1Non-clickbait in S#2
Clickbait in S#2Non-clickbait in S#3
Clickbait in S#3Non-clickbait in S#4
Clickbait in S#4Non-clickbait in S#5
Clickbait in S#5
(a) Original space (b) Causal invariant space
(c) Scenario -specific causal space (d) Non -causal space(a) Original space (b) Causal invariant space
(c) Scenario -specific causal space (d) Non -causal spaceNon-clickbait in S#1
Clickbait in S#1Non-clickbait in S#2
Clickbait in S#2Non-clickbait in S#3
Clickbait in S#3Non-clickbait in S#4
Clickbait in S#4Non-clickbait in S#5
Clickbait in S#5Non-clickbait in S#1
Clickbait in S#1Non-clickbait in S#2
Clickbait in S#2Non-clickbait in S#3
Clickbait in S#3Non-clickbait in S#4
Clickbait in S#4Non-clickbait in S#5
Clickbait in S#5
(a) Original space (b) Causal invariant space
(c) Scenario -specific causal space (d) Non -causal spaceNon-clickbait in S#1
Clickbait in S#1Non-clickbait in S#2
Clickbait in S#2Non-clickbait in S#3
Clickbait in S#3Non-clickbait in S#4
Clickbait in S#4Non-clickbait in S#5
Clickbait in S#5Figure 7: Case study with t-SNE visualization on the
distribution of samples in several typical scenarios.
they could not distinguish scenarios. The samples
formed loosely separated clusters but remained dis-
organized within each cluster; (c) visualized the
scenario-specific causal features. Here, scenarios
were separated into distinct clusters well. The fea-
tures can be roughly divided into two groups, but
the inter-class discrimination was insufficient. This
demonstrated the need to combine invariant and
scenario-specific causal factors for robust predic-
tion; (d) depicted a noise factor. Since the noises in
each scenario are unique, they may separate the sce-
narios but it is weak to identify true/false samples.
Overall, these results demonstrated how our model
elicited key causal factors and discarded spurious
correlations, which enabled reliable prediction.
4 Related Work
Clickbait detection is a hot research topic that aims
to predict misleading and sensational social posts.
The predictive sources can be divided into two
categories. The first one is based on social ac-
tivity. Malicious creators keep posting clickbait
and ceaselessly evolve new subspecies to avoid de-
tection. Some researchers propose to examine this
bait behavior based on the creators’ account pro-
files (Yang et al., 2012) and activity metadata (Shu
et al., 2019b). Nevertheless, some valid creators
would produce both high-quality and poor posts,
which easily led to false positive predictions. On
the other hand, clickbait posts often need to be
widely spread on social networks to enhance theirinfluence. These posts should have remarkable
propagation characteristics, such as a unique spread
path, a large number of shares but a short reading
time due to dissatisfaction, etc. The propagation-
based methods had been proposed (Ma et al., 2017),
but they cannot tackle new posts due to lack of user
feedback (Ma et al., 2018). Thus, such methods of-
ten perform high accuracy, but low coverage. Also,
they have an alert delay, which would bring a lot of
losses and could not support online applications.
Another direction is based on the post’s content.
The bait posts often have certain language charac-
teristics, such as delusive words, fallacious phases,
hot topics, raged emotions (Guo et al., 2019), lin-
guistic stylometry (Potthast et al., 2017), etc. To
detect them, early works design rules based on var-
ious features, such as the semantic (Rony et al.,
2017), linguistic (Blom and Hansen, 2015), or
multimodal ones (Chen et al., 2015). However,
these rules are hand-crafted and non-extensible (Yu
et al., 2020). To tackle this issue, current research
turns to data-driven neural networks. Various net-
work architectures have been proposed (Krishneth
et al., 2023), such as RNN (Anand et al., 2017),
CNN (Agrawal, 2016). More advanced techniques
like feature attention (Indurthi et al., 2020) and
graph attention mechanisms (Liu et al., 2022a) have
been developed. To learn representations from rich
unlabeled data (Yu et al., 2023a), some researchers
explore the pre-trained language models ( PLMs ),
likeBERT (Devlin et al., 2019) and RoBERTa (Liu
et al., 2019). They are fine-tuned to fit the classi-
fied tasks (Indurthi et al., 2020), so as to use their
embedded semantic knowledge (Yu et al., 2023b)
to facilitate detection (Yi et al., 2022). Besides,
some works point out that the clickbait was not
only in the unimodal like the text (Ruchansky et al.,
2017) but also in multimodal (Shu et al., 2019a),
such as giving an attractive image with an unrelated
article. They propose to incorporate more features
in multiple modalities (Wang et al., 2018). For
model training, there are other studies on domain
adaptation (López-Sánchez et al., 2018) and data
augmentation (Yang et al., 2019) to solve the data
shortage problem by knowledge transfer.
Differently, we found that traditional represen-
tations have spurious correlations. Malicious cre-
ators would exploit this bug to yield a large number
of new subspecies by rewriting the posts’ content,
such as adding some valid but unrelated terms or
images, and concealing the bait content in a nor-
mal post, etc. In this mixed content environment,the existing model easily misjudges the bait posts
due to spurious bias. We thus propose a debiased
method to tackle this problem by causal inference.
Causality-inspired methods are a hot research
topic in many tasks (Nguyen et al., 2022). To grasp
the causality in the tasks, some works proposed the
causal loss function (Bagi et al., 2023), while others
designed a task-related causal structure (Liu et al.,
2022b) to guide decision-making (Lv et al., 2022).
They pointed out the value of a good representation
for the model’s performance (Bronakowski et al.,
2023). Some studies propose to capture the salient
representations by feature engineering (Yu et al.,
2018) or noise filtering (Wang et al., 2021), but
they ignore spurious correlations. In contrast, we
propose to elicit key factors to eliminate this bias.
5 Conclusion
This paper studied the task of detecting clickbait in
multimodal social media posts. Existing methods
learned shallow features that introduced spurious
correlations, rather than capturing inherent factors
that caused clickbait. Malicious creators used this
spurious bias to form new bait subspecies by rewrit-
ing the posts with tricks, such as disguise with valid
content, leading to misjudgment and poor robust-
ness. To tackle this problem, we proposed a new
debiased framework by causal representation in-
ference. In detail, we first extracted multimodal
features, including textual, visual, linguistic, cross-
modal, and creator profile features. By causal in-
ference with structural constraints, we then disen-
tangle them into three latent factors, including the
invariant factor that indicated inherent bait inten-
tions, a causal factor for a certain scenario, and
noise factor. Based on invariant and causal fac-
tors, we can build a robust model. Moreover, we
propose a data augmentation technique to reduce
training costs. Experimental results on three popu-
lar datasets shown the effectiveness of our model.
Acknowledgments
This work is supported by the National Nat-
ural Science Foundation of China (62276279,
62372483, 62472455, 62102463, U2001211,
U22B2060), Guangdong Basic and Applied Ba-
sic Research Foundation (2024B1515020032), Re-
search Foundation of Science and Technology
Plan Project of Guangzhou City (2023B01J0001,
2024B01W0004), and Tencent WeChat Rhino-Bird
Focused Research Program (WXG-FR-2023-06).Limitations
Detecting clickbait posts on social media is a chal-
lenging task. In real application, this task comes up
against issues such as biases, multimodal content,
evolving bait subspecies, few labeled resources,
etc. Moreover, malicious creators would constantly
disguise the bait posts with tricks such as replac-
ing confusing terms or images pictures to escape
detection. This replaced content is full of spuri-
ous correlations which would make the model mis-
judgment. That would seriously affect the model’s
robustness. We thus propose a debiased model,
which can find the posts with inconsistency on the
thumbnail-article and headline-article pairs, such
as this thumbnail and headline are catchy and sen-
sational, but irrelevant to the article. Although the
current model is effective, there is still room for im-
provement. For example, it does not verify whether
the events described in the post are true or fake.
Also, it does not cover the detection of video bait
posts. Fake content detection is another task and re-
mains an open challenge. A possible solution is to
build a trusted knowledge base. We will investigate
more data modalities in future work.
Ethics Statement
The technology proposed in this paper can be used
to filter the bait posts. That can improve the user ex-
perience and purify the online environment. Unlike
traditional methods based on shallow features, our
model is more robust by eliminating spurious bias.
Excluding the misusage scenarios, there are few or
even no ethical issues with this technology. How-
ever, it is essentially a classification method, and
the classified results may be misused. For example,
it may be abused by malicious persons to filter out
the posts created from certain commercial competi-
tors unfairly. This problem can be addressed by
analyzing the source and publisher of the posts.
References
Basant Agarwal, Ajay Agarwal, Priyanka Harjule, and
Azizur Rahman. 2023. Understanding the intent be-
hind sharing misinformation on social media. In
Journal of Experimental & Theoretical Artificial In-
telligence , 35(4):573–587.
Amol Agrawal. 2016. Clickbait detection using deep
learning. In Proceedings of the 2016 2nd interna-
tional conference on next generation computing tech-
nologies (NGCT) , pages 268–272, Dehradun, India.Cleber Alcântara, Viviane Moreira, and Diego Feijo.
2020. Offensive video detection: dataset and base-
line results. In Proceedings of the Twelfth Language
Resources and Evaluation Conference , pages 4309–
4319, Marseille, France.
Ankesh Anand, Tanmoy Chakraborty, and Noseong
Park. 2017. We used neural networks to detect click-
baits: You won’t believe what happened next! In
Proceedings of the 39th Advances in Information Re-
trieval European Conference on IR Research, ECIR
2017 , pages 541–547, Aberdeen, UK.
Martin Arjovsky, Léon Bottou, Ishaan Gulrajani, and
David Lopez-Paz. 2019. Invariant risk minimization.
arXiv preprint arXiv:1907.02893 .
Shayan Shirahmad Gale Bagi, Zahra Gharaee, Oliver
Schulte, and Mark Crowley. 2023. Generative causal
representation learning for out-of-distribution motion
forecasting. arXiv preprint arXiv:2302.08635 .
Jonas Nygaard Blom and Kenneth Reinecke Hansen.
2015. Click bait: Forward-reference as lure in online
news headlines. In Journal of Pragmatics , 76:87–
100.
Mark Bronakowski, Mahmood Al-khassaweneh, and
Ali Al Bataineh. 2023. Automatic detection of click-
bait headlines using semantic analysis and machine
learning techniques. In Journal of Applied Sciences ,
13(4):2456.
Yimin Chen, Niall J. Conroy, and Victoria L. Rubin.
2015. Misleading online content: Recognizing click-
bait as "false news". In Proceedings of the 2015 ACM
Workshop on Multimodal Deception Detection , pages
15–19, Seattle, Washington, USA.
Ziwei Chen, Linmei Hu, Weixin Li, Yingxia Shao, and
Liqiang Nie. 2023. Causal intervention and counter-
factual reasoning for multi-modal fake news detec-
tion. In Proceedings of the 61st Annual Meeting of
the Association for Computational Linguistics (Vol-
ume 1: Long Papers) , pages 627–638.
Carmela Comito, Luciano Caroprese, and Ester
Zumpano. 2023. Multimodal fake news detection on
social media: a survey of deep learning techniques.
In Journal of Social Network Analysis and Mining ,
13(1):1–22.
Claudia Ioana Coste and Darius Bufnea. 2021. Ad-
vances in clickbait and fake news detection using
new language-independent strategies. In Journal of
Communications Software and Systems , 17(3):270–
280.
J. Devlin, M.W. Chang, K. Lee, and K. Toutanova. 2019.
Bert: Pre-training of deep bidirectional transform-
ers for language understanding. In Proceedings of
the 2019 Conference of of the The North American
Chapter of the Association for Computational Lin-
guistics (NAACL) , pages 4171–4186, Minneapolis,
MN, USA.Varun Dogra, Sahil Verma, NZ Jhanjhi, Uttam Ghosh,
Dac-Nhuong Le, et al. 2022. A comparative analysis
of machine learning models for banking news ex-
traction by multiclass classification with imbalanced
datasets of financial news: Challenges and solutions.
In Journal of International Journal of Interactive
Multimedia & Artificial Intelligence , 7(3).
Chuan Guo, Juan Cao, Xueyao Zhang, Kai Shu, and
Miao Yu. 2019. Exploiting emotions for fake
news detection on social media. arXiv preprint
arXiv:1903.01728 .
Yu-i Ha, Jeongmin Kim, Donghyeon Won, Meeyoung
Cha, and Jungseock Joo. 2018. Characterizing Click-
baits on Instagram. In Proceedings of the Interna-
tional AAAI Conference on Web and Social Media ,
volume 12, pages 92–101, Stanford, CA, USA.
Arafat Hossain, Md Karimuzzaman, Md Moyazzem
Hossain, and Azizur Rahman. 2021. Text mining
and sentiment analysis of newspaper headlines. In
Journal of Information , 12(10):414.
Vijayasaradhi Indurthi, Bakhtiyar Syed, Manish Gupta,
and Vasudeva Varma. 2020. Predicting clickbait
strength in online social media. In Proceedings of
the 28th International Conference on Computational
Linguistics , pages 4835–4846, Barcelona, Spain (On-
line).
A Krishneth, JD Dharaneesh, S Jisnu, and D Sivagane-
san. 2023. Web-plugin to detect clickbait in news
articles using rnn and lstm. In Proceedings of the
2023 5th International Conference on Inventive Re-
search in Computing Applications (ICIRCA) , pages
415–420, Coimbatore, India.
Minghao Li, Tengchao Lv, Jingye Chen, Lei Cui, Yi-
juan Lu, Dinei Florencio, Cha Zhang, Zhoujun Li,
and Furu Wei. 2023. Trocr: Transformer-based op-
tical character recognition with pre-trained models.
InProceedings of the AAAI Conference on Artificial
Intelligence , volume 37, pages 13094–13102, Wash-
ington, DC, USA.
Shu-Hsien Liao, Retno Widowati, and Yu-Chieh Hsieh.
2021. Investigating online social media users’ be-
haviors for social commerce recommendations. In
Journal of Technology in Society , 66:101655.
Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He,
and Piotr Dollár. 2017. Focal loss for dense object
detection. In Proceedings of the IEEE international
conference on computer vision , pages 2980–2988,
Venice, Italy.
Tsung-Yi Lin, Michael Maire, Serge Belongie, James
Hays, Pietro Perona, Deva Ramanan, Piotr Dollár,
and C Lawrence Zitnick. 2014. Microsoft coco:
Common objects in context. In Proceedings of
the Computer Vision–ECCV 2014 , pages 740–755,
Zurich, Switzerland.
Tong Liu, Ke Yu, Lu Wang, Xuanyu Zhang, Hao Zhou,
and Xiaofei Wu. 2022a. Clickbait detection onwechat: A deep model integrating semantic and syn-
tactic information. In Journal of Knowledge-Based
Systems , 245:108605.
Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-
dar Joshi, Danqi Chen, Omer Levy, Mike Lewis,
Luke Zettlemoyer, and Veselin Stoyanov. 2019.
Roberta: A robustly optimized bert pretraining ap-
proach. arXiv preprint arXiv:1907.11692 .
Yuejiang Liu, Riccardo Cadei, Jonas Schweizer, Sher-
win Bahmani, and Alexandre Alahi. 2022b. Towards
robust and adaptive motion forecasting: A causal
representation perspective. In Proceedings of the
IEEE/CVF Conference on Computer Vision and Pat-
tern Recognition , pages 17081–17092, New Orleans,
LA, USA.
Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei,
Zheng Zhang, Stephen Lin, and Baining Guo. 2021.
Swin transformer: Hierarchical vision transformer
using shifted windows. In Proceedings of the
IEEE/CVF international conference on computer vi-
sion, pages 10012–10022, Montreal, QC, Canada.
Daniel López-Sánchez, Jorge Revuelta Herrero,
Angélica González Arrieta, and Juan M Corchado.
2018. Hybridizing metric learning and case-based
reasoning for adaptable clickbait detection. In Jour-
nal of Applied Intelligence , 48:2967–2982.
Jiasen Lu, Dhruv Batra, Devi Parikh, and Stefan Lee.
2019. Vilbert: Pretraining task-agnostic visiolinguis-
tic representations for vision-and-language tasks. In
Journal of Advances in neural information processing
systems , 32.
Fangrui Lv, Jian Liang, Shuang Li, Bin Zang,
Chi Harold Liu, Ziteng Wang, and Di Liu. 2022.
Causality inspired representation learning for domain
generalization. In Proceedings of the IEEE/CVF Con-
ference on Computer Vision and Pattern Recognition ,
pages 8046–8056, New Orleans, LA, USA.
Jing Ma, Wei Gao, and Kam-Fai Wong. 2017. Detect
rumors in microblog posts using propagation struc-
ture via kernel learning. In Proceedings of the 55th
Annual Meeting of the Association for Computational
Linguistics , pages 708–717, Vancouver, Canada.
Jing Ma, Wei Gao, and Kam-Fai Wong. 2018. Rumor
detection on Twitter with tree-structured recursive
neural networks. In Proceedings of the 56th Annual
Meeting of the Association for Computational Lin-
guistics , pages 1980–1989, Melbourne, Australia.
Peya Mowar, Mini Jain, Ruchika Goel, and Dinesh Ku-
mar Vishwakarma. 2021. Clickbait in youtube pre-
vention, detection and analysis of the bait using en-
semble learning. CoRR , abs/2112.08611.
Prithwiraj Mukherjee, Souvik Dutta, and Arnaud
De Bruyn. 2022. Did clickbait crack the code on
virality? In Journal of Academy of Marketing Sci-
ence, 50(3):482–502.Paul Neculoiu, Maarten Versteegh, and Mihai Rotaru.
2016. Learning text similarity with siamese recurrent
networks. In Proceedings of the 1st Workshop on
Representation Learning for NLP , pages 148–157,
Berlin, Germany.
Toan Nguyen, Kien Do, Duc Thanh Nguyen, Bao
Duong, and Thin Nguyen. 2022. Front-door adjust-
ment via style transfer for out-of-distribution gener-
alisation. arXiv preprint arXiv:2212.03063 .
Martin Potthast, Tim Gollub, Kristof Komlossy, Sebas-
tian Schuster, Matti Wiegmann, Erika Patricia Garces
Fernandez, Matthias Hagen, and Benno Stein. 2018.
Crowdsourcing a large corpus of clickbait on twitter.
InProceedings of the 27th international conference
on computational linguistics , pages 1498–1507.
Martin Potthast, Johannes Kiesel, Kevin Reinartz, Janek
Bevendorff, and Benno Stein. 2017. A stylomet-
ric inquiry into hyperpartisan and fake news. arXiv
preprint arXiv:1702.05638 .
Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya
Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sas-
try, Amanda Askell, Pamela Mishkin, Jack Clark,
et al. 2021. Learning transferable visual models from
natural language supervision. In Proceedings of the
International conference on machine learning , pages
8748–8763, Virtual Event.
Md Main Uddin Rony, Naeemul Hassan, and Moham-
mad Yousuf. 2017. Diving deep into clickbaits: Who
use them to what extents in which topics with what
effects? In Proceedings of the 2017 IEEE/ACM
International Conference on Advances in Social Net-
works Analysis and Mining , page 232–239, New
York, USA.
Natali Ruchansky, Sungyong Seo, and Yan Liu. 2017.
CSI: A hybrid deep model for fake news detection.
InProceedings of the 2017 ACM on Conference on
Information and Knowledge Management , pages 797–
806, Singapore.
Kai Shu, Limeng Cui, Suhang Wang, Dongwon Lee,
and Huan Liu. 2019a. defend: Explainable fake news
detection. In Proceedings of the 25th ACM SIGKDD
International Conference on Knowledge Discovery &
Data Mining, KDD 2019 , pages 395–405, New York,
USA.
Kai Shu, Deepak Mahudeswaran, Suhang Wang, Dong-
won Lee, and Huan Liu. 2020a. Fakenewsnet: A data
repository with news content, social context, and spa-
tiotemporal information for studying fake news on
social media. In Journal of Big data , 8(3):171–188.
Kai Shu, Deepak Mahudeswaran, Suhang Wang, and
Huan Liu. 2020b. Hierarchical propagation networks
for fake news detection: Investigation and exploita-
tion. In Proceedings of the international AAAI con-
ference on web and social media , volume 14, pages
626–637.Kai Shu, Xinyi Zhou, Suhang Wang, Reza Zafarani,
and Huan Liu. 2019b. The role of user profiles for
fake news detection. In Proceedings of the 2019
IEEE/ACM international conference on advances in
social networks analysis and mining , pages 436–439,
Vancouver, British Columbia, Canada.
Jinpeng Wang, Yixiao Ge, Rui Yan, Yuying Ge,
Kevin Qinghong Lin, Satoshi Tsutsui, Xudong Lin,
Guanyu Cai, Jianping Wu, Ying Shan, et al. 2023.
All in one: Exploring unified video-language pre-
training. In Proceedings of the IEEE/CVF Confer-
ence on Computer Vision and Pattern Recognition ,
pages 6598–6608.
Wenjie Wang, Fuli Feng, Xiangnan He, Hanwang
Zhang, and Tat-Seng Chua. 2021. Clicks can be
cheating: Counterfactual recommendation for miti-
gating clickbait issue. In Proceedings of the 44th In-
ternational ACM SIGIR Conference on Research and
Development in Information Retrieval, 2021 , pages
1288–1297, Virtual Event, Canada.
Yaqing Wang, Fenglong Ma, Zhiwei Jin, Ye Yuan,
Guangxu Xun, Kishlay Jha, Lu Su, and Jing Gao.
2018. Eann: event adversarial neural networks for
multi-modal fake news detection. In Proceedings of
the 24th ACM SIGKDD International Conference on
Knowledge Discovery & Data Mining, KDD 2018 ,
pages 849–857, London, UK.
Thomas Wolf, Lysandre Debut, Victor Sanh, Julien
Chaumond, Clement Delangue, Anthony Moi, Pier-
ric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz,
Joe Davison, Sam Shleifer, Patrick von Platen, Clara
Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le
Scao, Sylvain Gugger, Mariama Drame, Quentin
Lhoest, and Alexander M. Rush. 2020. Transform-
ers: State-of-the-art natural language processing. In
Proceedings of the 2020 Conference on Empirical
Methods in Natural Language Processing: System
Demonstrations , pages 38–45, Online.
Yang Wu, Pengwei Zhan, Yunjian Zhang, Liming Wang,
and Zhen Xu. 2021. Multimodal fusion with co-
attention networks for fake news detection. In Find-
ings of the association for computational linguistics:
ACL-IJCNLP 2021 , pages 2560–2569.
Kelvin Xu, Jimmy Ba, Ryan Kiros, Kyunghyun Cho,
Aaron C. Courville, Ruslan Salakhutdinov, Richard S.
Zemel, and Yoshua Bengio. 2015. Show, attend and
tell: Neural image caption generation with visual at-
tention. In Proceedings of the 32nd International
Conference on Machine Learning, ICML 2015 , vol-
ume 37, pages 2048–2057, Lille, France.
Kapil Kumar Yadav and Nipun Bansal. 2023. A com-
parative study on clickbait detection using machine
learning based methods. In Proceedings of the 2023
International Conference on Disruptive Technologies
(ICDT) , pages 661–665, Greater Noida, India.
Fan Yang, Yang Liu, Xiaohui Yu, and Min Yang. 2012.
Automatic detection of rumor on sina weibo. In Pro-ceedings of the ACM SIGKDD Workshop on Mining
Data Semantics , New York, USA.
Kai-Chou Yang, Timothy Niven, and Hung-Yu Kao.
2019. Fake news detection as natural language infer-
ence. CoRR , abs/1907.07347.
Xiaoyuan Yi, Jiarui Zhang, Wenhao Li, Xiting Wang,
and Xing Xie. 2022. Clickbait detection via con-
trastive variational modelling of text and label. In
Proceedings of the Thirty-First International Joint
Conference on Artificial Intelligence, IJCAI 2022 ,
pages 4475–4481, Vienna, Austria.
Jianxing Yu, Xiaojun Quan, Qinliang Su, and Jian Yin.
2020. Generating multi-hop reasoning questions to
improve machine reading comprehension. In Pro-
ceedings of the World Wide Web Conference, WWW ,
pages 281–291, Taipei, Taiwan.
Jianxing Yu, Qinliang Su, Xiaojun Quan, and Jian Yin.
2023a. Multi-hop reasoning question generation and
its application. In Journal of IEEE Transactions on
Knowledge and Data Engineering , 35(1):725–740.
Jianxing Yu, Shiqi Wang, Libin Zheng, Qinliang Su,
Wei Liu, Baoquan Zhao, and Jian Yin. 2023b. Gen-
erating deep questions with commonsense reasoning
ability from the text by disentangled adversarial in-
ference. In Findings of the 61st Annual Meeting of
the Association for Computational Linguistics, ACL ,
pages 470–486, Toronto, Canada.
Wenhui Yu, Huidi Zhang, Xiangnan He, Xu Chen,
Li Xiong, and Zheng Qin. 2018. Aesthetic-based
clothing recommendation. In Proceedings of the
2018 World Wide Web Conference on World Wide
Web, pages 649–658, Lyon, France.
Xinyi Zhou, Atishay Jain, Vir V Phoha, and Reza Za-
farani. 2020. Fake news early detection: A theory-
driven model. In Journal of Digital Threats: Re-
search and Practice , 1(2):1–25.
Jie Zhu, Huabin Huang, Banghuai Li, and Leye Wang.
2021. E-crf: Embedded conditional random field for
boundary-caused class weights confusion in semantic
segmentation.
Yi Zhu, Han Wang, Ye Wang, Yun Li, Yunhao Yuan,
and Jipeng Qiang. 2023. Clickbait detection via large
language models. arXiv:2306.09597 .
A Multimodal Feature Extraction
Visual Features :Swin-T (Liu et al., 2021) is a
transformer-based model that is good at capturing
hierarchical features in images based on shifted
window self-attention.
Cross-modal Features : We employ a CTTrans-
former (Lu et al., 2019) to compute the cross-
modal features between the text and image. Given
the textual encoding Tband visual one Vswith
their data type tags, CTcan well encode theirmatching features by a multi-headed attention
network. It outputs a visual-aware text feature
Fvtand a text-aware visual feature Ftv, respec-
tively by Fvt=CT((TbWt),(VsWv)),Ftv=
CT((VsWv),(TbWt)), where Ware weight ma-
trices. These encodings can better reflect bait be-
havior from multiple views.
Linguistic Features : To capture the semantics and
bait patterns of the post, we extract six kinds of fea-
tures based on post content, i.e., thumbnail, head-
line, and article body:
(1)ArticleBody-thumbnail disparity : Creators may
exploit tricks, such as using attractive thumbnails
that are irrelevant to the article body, to mislead
readers into clicking. To calculate this cross-modal
inconsistency, we encode them into a uniform math-
ematical space by a pre-trained CLIP model (Rad-
ford et al., 2021), as [bc, tc] =CLIP (b, t), where b
denotes the body text or figure in the article, trefers
to the thumbnail picture, bcandtcare their encoded
vectors, respectively, where dcis the length. Previ-
ous works (Zhu et al., 2021) show that CLIP has a
good ability to characterize the mutual relations of
various modalities.
(2)ArticleBody-headline disparity : To attract read-
ers, creators often use lure headlines to form a
curiosity gap, regardless of their relevance to the
articles. To compute their relevance, we first em-
bed each textual input via BERT and encode its
context by a bidirectional GRU with an attention
layer. We then feed these two inputs into a Siamese
net (Neculoiu et al., 2016) that is good at learning
similarity, as simbh=Siamese (b, h), where bde-
notes the body text, hrefers to the headline.
(3)Thumbnail-headline disparity : When the head-
line doesn’t match the thumbnail, it will create a
curiosity gap and cause misleading clicks. To un-
derstand the thumbnail, we generate its caption
based on a neural model (Xu et al., 2015) trained
onMS COCO (Lin et al., 2014) dataset. We then
compare the generated caption and headline by co-
sine matching of their BERT embeddings.
(4)Sentiment of headline : The headline often ex-
presses strong feelings to form an emotional curios-
ity gap. To analyze such feelings, we use a senti-
ment classifier (Hossain et al., 2021) which outputs
both polarity (positive/negative/neutral) and inten-
sity (strength). We normalize their values to the
range [0,1]and obtain a feature vector.
(5)Lexical analysis of headline : To grab the
reader’s attention, the headline usually uses provok-
ing clues, such as the overuse of numbers, questionmarks, exclamation marks, and capital letters to
emphasize the shock, or using emojis to indicate
the funny emotion. We thus design a count-based
vector to quantify the features like capitalized let-
ters, question marks, punctuation marks such as
‘∼,!’, emojis, assertive verbs, factive verbs, hedges,
implicative verbs, etc.
(6)Baitness of headline : Another striking pecu-
liarity is the lure verbalism, for example, using
abbreviations like “ OMG ” i.e., oh my god to ex-
press surprise, “ LOL” i.e., laughing out loud to
describe humor, “ ROFL ” i.e., rolling on the floor
laughing . The use of celebrity names or porno-
graphic words (Alcântara et al., 2020) like “ nudes .”
We thus extract features by counting the number
of celebrities, slang words such as “ OMG, WTF ”,
porn words like “ sexy”, captivating phrases like
“you wouldn’t believe ,” “shocking .”
B Experiment Settings
For evaluation, we reimplemented each baseline
with default settings. For fair comparisons, we
conducted ten runs and showed the average results.
Ours: Our model was trained on four 24 GB
Nvidia RTX 3090 GPUs . Based on HuggingFace
PyTorch API (Wolf et al., 2020), we encoded the im-
ages based on the Swin Tiny model pre-trained on
ImageNet with4layers and a hidden dimension of
96. The transformer had a window size of 7×7and
6attention heads. For text encoding, we leveraged
the BERT basemodel with 6transformer layers and
a hidden size of 768. The classifier was a 3-layer
MLP with ReLU activations and a hidden size of
512. The Adam optimizer was used with a learning
rate of 2e−5. We trained for 10epochs, with the
batch size of 64. For contrastive learning, we used
a projection head with 256units and a temperature
of0.1. The mask generator was a 2-layer MLP .
The learning rate for mwas obtained by greedy
search on [0.01,0.001,0.0001] . The trade-off α
andβwere set as 2and0.1forCLDInst ,1and0.1
forClickbait17 and1and0.01forFakeNewsNet ,
respectively. The number of scenarios |S|was set
as10forCLDInst ,15forClickbait17 and15for
FakeNewsNet , respectively. The iteration Twas set
as20initially.
dEFEND: We used pre-trained GloVe embed-
dings of dimension 100 to represent words. We
incorporated both bidirectional GRU layers for
sequential data processing and custom attention
mechanisms to focus on relevant parts of the text.The max sentence length and sentence count were
set to 120 and 50, respectively. We utilized the
RMSprop optimizer with a learning rate of 0.001.
We trained for 10epochs, with the batch size of 20.
HPFN: We extracted the features from the hier-
archical propagation network, and then employed a
series of ensemble classifiers to predict the results,
Gaussian Naive Bayes ,Logistic Regression with
‘lbfgs ’ solver, Decision Tree ,SVM with a linear
kernel. Also, we used Random Forest with 50 esti-
mators for detailed training and 100 estimators for
broader model performance analysis. Data normal-
ization was achieved through StandardScaler . We
used Extra Trees Classifier to build a forest with
100 estimators and computed the feature weighting.
MCAN: Textual features were extracted using
theBERT model, and visual features from images
were obtained through the VGG-19 network. The
model incorporated a novel fusion approach with
multiple co-attention layers to effectively integrate
textual and visual features. Specifically, the model
was designed with ‘ s-fc’, ‘f-fc’, and ‘ t-fc’ layers.
Each had a hidden size of 256, and a ‘ p-fc’ layer
with a hidden size of 35. The dimensions d,m,
anddffwere set to 256, 4, and 512, respectively.
Training was conducted for 100 epochs with early
stopping, utilizing Adam optimizers. The VGG-
19andBERT parameters were frozen to prevent
overfitting. Parameters were optimized by grid
searching, with accuracy as the selection criterion.
CPDM: We embedded the input text by the
BERT model. The dimension of the last hidden
layer was set to 768. For the visual input, we em-
bedded it by the ResNet50 pre-trained model with
the output layer dimension of 2048. We then fused
these multimodal features and trained an ensemble
classifier, i.e., Random Forest . It consisted of six
base classifiers, i.e., K-Nearest Neighbours ,Gaus-
sian Naive Bayes ,Multi-Layer Perceptron ,Support
Vector Machines ,Extreme Gradient Boosting , and
Logistic regression . We used Adam as the optimizer
with a learning rate of 10−4and a batch size of 128.
The training epoch was set to 120.
CCD: We trained the model for 200 epochs.
The initial learning rate for the Adam optimizer
was tuned in [1e-5, 1e-3]. For the confounder dic-
tionary Du∈RN×du,Nis 18 ( Anger, Anxiety,
Assent, Causation, Certainty, Differentiation, Dis-
crepancy, Feel, Hear, Insight, Negative emotion,
Netspeak, Nonfluencies, Positive emotion, Sadness,
See, Swear words, Tentative ), and duwas set to
4. For the scaled dot-product attention, the scalingCLDInstClickbait17FakeNewsNetFigure 8: Evaluation the impact of msettings on ACC.
CLDInstFakeNewsNetClickbait17
Figure 9: Evaluation the impact of msettings on PRE.
factor dmwas set to 256. We followed the original
settings to tune the trade-off hyperparameters α
andβby grid search in {0, 0.1, 0.25, 0.5, 0.75, 1,
2, 3, 4, 5}. And we finally set α= 3andβ= 0.1.
VLP: Due to the storage limitation, we used the
first half of the YT-Temporal 180M. We trained
the model using the AdamW optimizer with a base
learning rate of 1e-4 and weight decay of 1e-2.
The learning rate was warmed up for 10% of the
training steps and was decayed linearly to zero for
the rest of the training. For pre-training, we trained
All-in-one-S andAll-in-one-B for 200K steps with
a batch size of 8 per GPU. For All-in-one-Ti , we
pre-trained for 100K steps with a batch size of 16
per GPU. We adopted mixed precision technique to
speed up the training process. As the domain gap
between pre-train dataset and downstream visual
dataset is large, we used batch size of 512 and
trained with 100 epochs.
C Training Procedure
Our overall training process is summarized in Al-
gorithm 1.
D Additional Evaluations
Due to the page limit, we showed additional exper-
iments as follows, including the evaluations of the
mask and scenario mechanism, case analysis, and
data augmentation technique.
D.1 Additional Study of the Mask Mechanism
The results in terms of accuracy, precision, and re-
call metrics were presented in Fig.(8), Fig.(9), and
Fig.(10), respectively. All the results validated our
design of using a soft float mask regularized by
L2norm, which could perform best. The mask en-
CLDInstClickbait17FakeNewsNetFigure 10: Evaluation the impact of msettings on REC.
Algorithm 1: Our model’s training process.
Data: Training data Dtr
Result: Optimal detector ˆF
1Random assign scenario for each xi∈ Dtr;
2//Trounds of alternating optimization;
3fort←1toTdo
4 while not converged do
5 Optimize Φsvia Eq.(2) for scenario
division;
6 Compute s(i)via Eq.(3) for samples
reallocation;
7 end
8 Learn IRM lossmvia Eq.(1) to elicit an
invariant factor;
9 Optimize the contrastive loss ξvia
Eq.(4) to separate scenario-specific
causal factor and non-causal one;
10end
11Optimize Eq.(5) to learn a clickbait detector
ˆFbased on the elicited invariant and
causal factors, avoiding spurious bias
abled automatic differentiation of feature relevance
for clickbait detection.
To further analyze the mask m, we visualized its
per-dimension values in Fig.(11). For each dataset,
we randomly sampled 100 cases and then analyzed
their learned mask weights. This weight captured
the importance of each kinds of feature. The value
of this weight was between [0,1]. If we plotted
the histogram according to the weights of these
100 samples, where the x ordinate is the value of
the weight and the y ordinate is its corresponding
number of samples. For example, if there was 17
samples had the weight 0.4, then x ordinate was
0.4, the y ordinate was 17. If the weight values of
most samples were high, this kind of feature was
considered to be more important. From the results,
we observed that there were more samples with
high weight for the kinds of cross-modal, linguistic,
and profile features. This reflected their ability
to capture bait behavior more effectively than the
single modal features such as text and visual ones.Clickbait17FakeNewsNet
Mask WeightsCLDInstFrequencyMask WeightsMask WeightsFigure 11: Visualization of the mask mon three datasets. The importance distribution of each kind of feature.
D.2 Study of the Scenario Size Setting
We evaluated the impact of scenario size setting on
the overall performance. Empirically, the small size
was not enough to distinguish complex clickbait
patterns, while a large one may split some relevant
samples into redundant groups. To explore the best
settings, we tuned the scenario size from 1 to 25,
with 1 as an interval. Considering the computa-
tional resources, we tested the size with no larger
than 25. The performance change curves in terms
of accuracy, F1 score, precision, and recall were
displayed in Fig.(12). We observed that with the in-
crement of size, the performance had an ascending
trend, after reaching the peak, it turned to decline.
The optimal sizes for the three datasets were 10,
15, and 15, respectively.
D.3 Qualitative Analysis of Test Cases
Moreover, we analyzed the test cases to infer the
actual running effect of our model. As exhibited in
Table 3, we made the correct prediction for the first
post. This article used a cartoon-style thumbnail.
Our model could judge the authenticity of this arti-
cle through the learned textual features and visual
consistency, without being misled by the attrac-
tiveness of the title or image itself. In the second
example, the headline used exaggerated words like
“Bid Rupert Murdoch farewell by reliving his most
controversial tweets .” It created a curiosity gap
which people expected to reveal the tweets imme-
diately. But the image of the post only contained a
side-sitting photo of “ Rupert Murdoch ”, which had
nothing to do with the headline. The body text actu-
ally simply reviewed some tweets posted by Rupert
Murdoch on Twitter, without delivering the implied
sensational effect as hinted by the headline. For this
clickbait post with inconsistency and irrelevance,
other baselines might rely too much on the surface
word matching between the headline and body text,
without fully understanding their deeper semantics,
leading to the wrong judgment. In contrast, our
model can work well. These results showed the ex-tracted invariant and scenario-specific factors were
effective in distinguishing bait articles.
D.4 Study of Data Augmentation Technique
In real applications, training data is usually insuf-
ficient or even not. To address this problem, we
develop a data augmentation technique which col-
lected pseudo-labeled samples from the historical
data in social media, e.g. WeChat . We found that al-
though the social behavior-based approach needed
extra cold start time, its accuracy was high if suf-
ficient feedback data was accumulated over time.
We thus propose to collect the user behavior of
these posts from historical data over a period of
time, so as to build a batch of pseudo-labeled data.
In detail, we first collected hot posts with more than
µ= 100 ,000forward actions per hour. We then
designed two heuristic rules to identify clickbait,
including those that take less than ν= 10 seconds
viewing duration; and the number of user likes is 0.
The remaining posts were viewed as non-bait. The
statistics on dataset are shown in Table 4. We used
theGoogle Translate API to translate these Chi-
nese posts into English, and got a data-augmented
dataset WeChatCB . To analyze the quality of this
dataset, we randomly selected 500 samples for hu-
man evaluation. The result showed that approxi-
mately 28% of the posts were disguised type. It
indicated that WeChat , like other popular social
platforms, existed serious deceptive issue.
To verify the effectiveness of this augmentation
technique, we simulated a few-shot and zero-shot
environment and trained our model on the aug-
mented data. If the quality of this data is equiva-
lent to the human-tagged one, their performance
should be comparable. In detail, we retained 10%
of the training data from the original dataset and
randomly selected data with a size of 90%∼190%
from the augmented dataset as an additional train-
ing set. The selected data included both positive
and negative samples. The results on the test sets of
CLDInst ,Clickbait17 , and FakeNewsNet , respec-Thumbnails Headlines Body Texts True Label Pred Label
Anderson Cooper hits
Trump with a hard truth
about how he’ll go
down in history“Seven days after choosing to be the first presi-
dent ever to incite insurrection against the coun-
try and the Constitution he took an oath to de-
fend, the president now has another first to his
name,” Cooper said. “The first and only presi-
dent to ever be impeached twice.”0dEFEND : 1
HPFN : 1
MCAN : 1
CPDM : 1
CCD : 0
VLP : 0
Ours : 0
Bid Rupert Murdoch
farewell by reliving
his most controversial
tweetsRupert Murdoch, one of the top media ex-
ecutives in the world, is stepping down
from his perch as CEO of 21st Century
Fox. . . “Independence Day. Immigration is our
history and immigration MUST be our future.
Multi-ethnicities and equality under law for
all.“Making rich poorer won’t do much. Giv-
ing opportunity too poor to become rich is the
only way forward.”1dEFEND : 0
HPFN : 0
MCAN : 0
CPDM : 0
CCD : 1
VLP : 0
Ours : 1
Table 3: Qualitative analysis of test cases for various methods. 0 indicates non-clickbait, while 1 denotes clickbait.
Dataset #Samples #Clickbait #non-Clickbait
WeChatCB 70,785 32,418 38,367
Table 4: The statistics on the pseudo-labeled samples.
DatasetsCLDInst Clickbait17 FakeNewsNet
PRE↓ REC↓ PRE↓ REC↓ PRE↓ REC↓
w/o MF -4.59 ±0.14-4.85 ±0.52 -5.81 ±0.37-6.11 ±0.29 -5.42 ±0.22-5.79 ±0.04
w/o EICF -5.89 ±0.45-6.16 ±0.17 -7.79 ±0.11-8.32 ±0.30 -6.90 ±0.26-7.23 ±0.19
w/o ESCF -3.53 ±0.43-3.87 ±0.55 -4.02 ±0.29-4.52 ±0.06 -3.81 ±0.14-3.93 ±0.11
w/o ENF -3.78 ±0.35-4.06 ±0.12 -4.62 ±0.51-4.85 ±0.43 -4.14 ±0.06-4.49 ±0.40
Table 5: Ablation studies. T-test, p-value <0.005.
tively are shown in Table 6. Moreover, we also
showed the results of using only the augmented
samples (from a size of 100% to200% ), but with
no original training data. Based on 10% human-
tagged data and 150% machine-tagged data, our
model obtained better performance than the one
based on 100% original training data (i.e., human-
tagged data). When in the zero-shot situation, our
model still can obtain good performance based on
180% machine-tagged data. The outperformance
would be larger when feeding more tagged data.
We can infer that the quality of machine tagging
is acceptable and satisfactory. Our data augmenta-
tion technique is useful to alleviate for the shortage
problem of human-tagged resources.
D.5 Ablation Studies on Other Metrics
As demonstrated in Table 5, we plotted the results
in terms of PRE andREC metrics, respectively.Data SettingsCLDInst Clickbait17 FakeNewsNet
ACC PRE REC F1 ACC PRE REC F1 ACC PRE REC F1
H 100% 88.79 ±0.1188.73 ±0.0489.16 ±0.3288.94 ±0.14 92.83 ±0.2793.45 ±0.1793.59 ±0.1593.52 ±0.20 91.56 ±0.0792.74 ±0.3892.97 ±0.1392.85 ±0.08
H 10% + M 90% 83.25 ±0.3185.99 ±0.2284.40 ±0.0585.19 ±0.17 87.95 ±0.5890.16 ±0.0390.56 ±0.7190.36 ±0.24 86.19 ±0.3689.64 ±0.4988.99 ±0.1089.31 ±0.12
H 10% + M 110% 85.53 ±0.0687.37 ±0.4286.66 ±0.3387.01 ±0.50 90.27 ±0.2191.84 ±0.1691.70 ±0.4791.77 ±0.13 88.06 ±0.1191.33 ±0.2790.85 ±0.2491.09 ±0.09
H 10% + M 130% 88.22 ±0.3288.51 ±0.2488.37 ±0.0888.44 ±0.17 92.62 ±0.1493.06 ±0.4992.86 ±0.3692.96 ±0.10 90.21 ±0.2192.28 ±0.4092.53 ±0.2992.41 ±0.16
H 10% + M 150% 89.87 ±0.0389.82 ±0.1389.38 ±0.5189.60 ±0.44 93.80 ±0.2893.33 ±0.2493.72 ±0.3093.52 ±0.15 92.02 ±0.4492.84 ±0.3893.05 ±0.0792.95 ±0.32
H 10% + M 170% 91.85 ±0.2491.28 ±0.3590.51 ±0.5690.89 ±0.17 94.07 ±0.1393.71 ±0.2594.25 ±0.0893.98 ±0.04 93.00 ±0.5293.47 ±0.5593.98 ±0.0993.73 ±0.31
H 10% + M 190% 92.15 ±0.5192.51 ±0.2292.57 ±0.3892.54 ±0.05 94.43 ±0.3494.35 ±0.2794.64 ±0.1894.49 ±0.44 94.07 ±0.0894.37 ±0.2094.48 ±0.5494.42 ±0.42
M 100% 82.90 ±0.5685.29 ±0.3885.42 ±0.2185.35 ±0.60 87.20 ±0.4490.05 ±0.0588.71 ±0.1989.37 ±0.24 87.89 ±0.4389.52 ±0.5186.25 ±0.1187.85 ±0.39
M 120% 84.46 ±0.1886.46 ±0.0586.64 ±0.1486.55 ±0.62 88.30 ±0.3090.91 ±0.1189.66 ±0.2590.28 ±0.32 89.33 ±0.3590.93 ±0.5088.03 ±0.1289.46 ±0.29
M 140% 86.22 ±0.2487.41 ±0.3087.58 ±0.5887.49 ±0.16 90.26 ±0.2991.89 ±0.0890.62 ±0.0391.26 ±0.29 90.82 ±0.5191.51 ±0.4089.15 ±0.0590.32 ±0.14
M 160% 87.76 ±0.6287.92 ±0.4088.30 ±0.1888.11 ±0.09 91.78 ±0.2392.75 ±0.4191.77 ±0.5792.26 ±0.54 91.98 ±0.3492.02 ±0.5091.33 ±0.2191.67 ±0.26
M 180% 89.14 ±0.4389.20 ±0.1688.85 ±0.2289.03 ±0.24 92.54 ±0.1793.36 ±0.6293.91 ±0.0793.63 ±0.35 92.46 ±0.2692.47 ±0.0692.30 ±0.4592.38 ±0.10
M 200% 90.11 ±0.1490.89 ±0.3990.75 ±0.0690.82 ±0.42 94.02 ±0.6493.78 ±0.1993.58 ±0.2093.68 ±0.18 93.31 ±0.1593.08 ±0.5393.88 ±0.3393.48 ±0.07
Table 6: Evaluation of the quality of the augmented data. H and M represent the human-tagged data and machine-
augmented data which are used to train our method, respectively.
151015202588909294151015202584868890151015202588909294CLDInstClickbait17FakeNewsNetF1-Scores85.0785.7488.9488.4988.7587.1188.9691.0593.5188.7592.5692.0492.2491.5092.8588.9390.1390.49CLDInstClickbait17FakeNewsNetAccuracy15101520258688909215101520258486889015101520258890929485.8088.6988.3291.5689.9588.4487.7891.5892.4192.8391.2289.388.8787.6588.1788.3488.7986.06
FakeNewsNetPrecision15101520258486889015101520258890929415101520258890929484.9786.8488.6588.4888.7388.4290.4290.0692.7491.5789.0388.8492.0292.1793.4592.6691.289.14CLDInstClickbait17
FakeNewsNet
# Number of Scenarios# Number of Scenarios# Number of ScenariosRecall15101520258890929415101520258486889015101520258890929485.1790.5690.2192.9791.4388.8488.6792.0892.3393.5992.4790.9088.8787.3988.8788.5289.1686.08CLDInstClickbait17
Figure 12: Evaluation of scenario size settings in terms of accuracy, F1 score, precision and recall, respectively.