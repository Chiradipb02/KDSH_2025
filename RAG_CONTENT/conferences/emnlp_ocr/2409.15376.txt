ControlMath: Controllable Data Generation Promotes Math Generalist
Models
Nuo Chen♠Ning Wu♣Jianhui Chang♢Jia Li♠
♠Hong Kong University of Science and Technology (Guangzhou)
Hong Kong University of Science and Technology
♣Microsoft
♢China Telecom Cloud Computing Research Institute
nchen022@connect.ust.hk ,changjh1@chinatelecom.cn ,jialee@ust.hk
Abstract
Utilizing large language models (LLMs) for
data augmentation has yielded encouraging
results in mathematical reasoning. However,
these approaches face constraints in problem
diversity, potentially restricting them to in-
domain/distribution data generation. To this
end, we propose ControlMath , an iterative
method involving an equation-generator mod-
ule and two LLM-based agents. The module
creates diverse equations, which the Problem-
Crafter agent then transforms into math word
problems. The Reverse-Agent filters and se-
lects high-quality data, adhering to the "less is
more" principle, achieving better results with
fewer data points. This approach enables the
generation of diverse math problems, not lim-
ited to specific domains or distributions. As a
result, we collect ControlMathQA, which in-
volves 190k math word problems. Extensive
results prove that combining our dataset with in-
domain datasets like GSM8K can help improve
the model’s mathematical ability to generalize,
leading to improved performances both within
and beyond specific domains.
1 Introduction
Currently, mathematical reasoning (Cobbe et al.,
2021; Chen et al., 2023d; Zhou et al., 2022; Weng
et al., 2022) is regarded as the one of the most chal-
lenging areas for current Large Language Models
(LLMs). Typically, prompting-based approaches
(Wei et al., 2022b,a; Wang et al., 2022) are com-
mon ways to improve the mathematical abilities of
closed-source LLMs. These methods design differ-
ent prompts for these LLMs to solve multi-step and
complicated math problems, setting a high bench-
mark and demonstrating the potential of LLMs in
tackling sophisticated mathematical problems.
Recently, the focus has shifted towards improv-
ing the capabilities of smaller, open-source LLMs
through instruction-tuning (Yu et al., 2023; Chen
et al., 2024a; Ouyang et al., 2022; Peng et al., 2023;
/uni0000002a/uni00000036/uni00000030/uni0000001b/uni0000002e /uni0000002a/uni00000036/uni00000030/uni0000001b/uni0000002e/uni00000010/uni0000002b/uni00000044/uni00000055/uni00000047 /uni00000036/uni00000039/uni00000024/uni00000030/uni00000033/uni00000010/uni0000002b/uni00000044/uni00000055/uni00000047 /uni00000027/uni00000030/uni00000010/uni00000033/uni00000052/uni0000004f/uni0000005c/uni00000051/uni00000052/uni00000050/uni0000004c/uni00000044/uni0000004f/uni00000056 /uni00000027/uni00000030/uni00000010/uni00000033/uni00000055/uni00000052/uni00000045/uni00000044/uni00000045/uni0000004c/uni0000004f/uni0000004c/uni00000057/uni0000005c
/uni00000037/uni00000048/uni00000056/uni00000057/uni00000003/uni00000027/uni00000044/uni00000057/uni00000044/uni00000056/uni00000048/uni00000057/uni00000056/uni00000013/uni00000015/uni00000013/uni00000017/uni00000013/uni00000019/uni00000013/uni0000001b/uni00000013/uni00000014/uni00000013/uni00000013/uni00000024/uni00000046/uni00000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c/uni00000003/uni0000000b/uni00000008/uni0000000c/uni00000019/uni0000001a/uni00000011/uni00000013
/uni00000015/uni00000013/uni00000011/uni00000015/uni00000015/uni00000017/uni00000011/uni0000001a/uni00000017/uni00000015/uni00000011/uni0000001a/uni0000001c/uni00000013/uni00000011/uni00000016
/uni00000019/uni00000015/uni00000011/uni0000001c
/uni00000014/uni0000001a/uni00000011/uni00000013/uni00000014/uni00000017/uni00000011/uni0000001a
/uni00000014/uni00000014/uni00000011/uni0000001c
/uni0000001b/uni00000011/uni00000014/uni00000017/uni00000015/uni00000011/uni00000014
/uni00000014/uni00000014/uni00000011/uni00000015
/uni0000001a/uni00000011/uni00000017/uni00000018/uni00000011/uni00000018/uni00000015/uni00000014/uni00000011/uni00000013/uni00000032/uni00000058/uni00000055/uni00000056 /uni00000030/uni00000048/uni00000057/uni00000044/uni00000030/uni00000044/uni00000057/uni0000004b /uni0000002a/uni00000036/uni00000030/uni0000001b/uni0000002eFigure 1: We train LLaMA 2-7B model (Touvron et al.,
2023b) with different training corpus and present results
in out-of-domain/distribution datasets: GSM8K-Hard
(Gao et al., 2023), SV AMP-Hard (Chen et al., 2023b),
DM-Polynomials and Probability subdatasets (Saxton
et al., 2018).
Zhang et al., 2023; Longpre et al., 2023; Toshni-
wal et al., 2024). A significant advancement in
this area is the use of data augmentation, using
frontier LLMs like ChatGPT or GPT-4 to increase
the size of available datasets to improve model
performance (Yuan et al., 2023; Yu et al., 2023;
Li et al., 2023a; Tang et al., 2024). For example,
MetaMath (Yu et al., 2023) and MuggleMath (Li
et al., 2023a) employ different augmented meth-
ods, such as question rephrasing, on the GSM8K
(Cobbe et al., 2021) or MATH (Hendrycks et al.,
2021) datasets to generate new problems. However,
these methods depend heavily on seed questions
from the training datasets, resulting in new samples
that closely resemble the original ones. This lack of
diversity can result in models overfitting to specific
domains or data distributions, as the new problems
maintain similar topics, reasoning steps, and nu-
merical operations as the original ones. Thus, the
models are effective within certain domains/dis-
tributions but less capable outside them (Li et al.,
2023a).
Figure 1 showcases the effects of in-domain
data augmentation using MetaMath on the GSM8K
dataset. MetaMath achieves a significant perfor-arXiv:2409.15376v1  [cs.LG]  20 Sep 2024mance boost on GSM8K, increasing accuracy by
over 20%. However, when tested on out-of-domain
datasets like SV AMP-Hard, DM-Polynomials, and
DM-Probability, the model’s performance drops
sharply, sometimes even below the baseline trained
only on GSM8K. Notably, on the GSM8K-Hard
dataset, which only varies the distributions of the
numbers, there is also a substantial decline in ac-
curacy. This highlights that while MetaMath im-
proves in-domain performance, it struggles to gen-
eralize to more diverse or challenging datasets.
Moreover, another critical oversight in previ-
ous approaches is the inclusion of low-quality or
redundant samples in augmented datasets. Al-
though methods like MetaMath have significantly
expanded original datasets from 14k to 400k, con-
cerns remain about the quality and utility of all
generated samples. Some samples may be of low
quality or redundant, failing to contribute meaning-
fully to the model’s learning process and increasing
useless training costs (Chen et al., 2023a). This
highlights the need for an effective strategy to filter
out ineffective training samples, a challenge still
unaddressed in mathematical reasoning.
To address the above challenges, we propose a
simple and iterative approach for controllable math-
ematical data generation, termed ControlMath .
The core concept is from equation to math word
problem and the essence of control lies in two
primary perspectives: (1) Controllable equation
generation: By specifying requirements such as
reasoning steps, designed operators, and numeri-
cal ranges, we generate corresponding equations
through an equation generation module. The fron-
tier LLM-based Problem-Crafter Agent then cre-
ates mathematical word problems based on these
equations, ensuring control over the diversity and
distribution of the final set of problems. (2) Adap-
tively efficient data selection: This is achieved
through a Problem Rewriter-Agent to ensure the
effectiveness of the training samples. This agent
rewrites the generated mathematical problems to
create variations. Both the original and rewritten
problems are fed to the LLM; if the LLM solves
both correctly, it indicates that this generated prob-
lem does not contribute to further learning and can
be discarded. This approach mimics human cog-
nitive learning, where redundant information does
not enhance learning efficiency. Filtering out redun-
dant samples allows us to focus on the most benefi-
cial data, enhancing overall training efficiency. The
overview of our approach is presented in Figure 2.By controlling the generation and selection of
training samples, our method embodies the princi-
ple of "less is more", focusing on quality over quan-
tity to enable stronger models with smaller datasets.
To prove its effectiveness, we curate a dataset-
ControlMathQA-comprising approximately 190k
training samples. By seamlessly integrating this
dataset with established GSM8K and MetaMath
datasets, we embark on training LLMs. Our
empirical results prove the resulting generalist
LLMs clearly show significant performance im-
provements in both in-domain and out-of-domain
datasets, as shown in Figure 1. In general, our
contributions are summarized as follows:
•We propose a new data generation strategy,
named ControlMath, for mathematical reason-
ing, which consists of controllable equation
generation and an adaptively efficient data se-
lection process.
•We collect ControlMathQA, a new training
corpus that involves about 190k samples to
help build math generalist models.
•We further investigate different variants of
ControlMath to show its scaleability and gen-
eralization.
2 Related Works
Mathematical Reasoning with LLMs. In recent
times, large language models (LLMs) (Brown et al.,
2020; Hu et al., 2021; OpenAI, 2023; Touvron
et al., 2023a; Huang et al., 2024; Chen et al., 2023c)
have demonstrated remarkable abilities in handling
complex mathematical reasoning tasks (MR) (Scao
et al., 2022; Cobbe et al., 2021; Zhou et al., 2022;
Weng et al., 2022; Chen et al., 2023e; Imani et al.,
2023a). Two primary approaches are used: (1)
Prompting-based methods (Imani et al., 2023b;
Wang et al., 2022; Gao et al., 2023; Shi et al., 2022;
Chen et al., 2023e), which employ diverse prompts
to aid LLMs in solving mathematical problems. A
notable example is Chain-of-Thought (CoT) (Wei
et al., 2022b), which guides LLMs through step-by-
step prompting. (2) Finetuning-based approaches
(Li et al., 2023b; Yuan et al., 2023), which unlock
the potential of open-source LLMs for mathemat-
ical reasoning through instruction-tuning, relying
on effective downstream training data.
Data Augmentation with LLMs. In the era of
LLMs, data augmentation is regarded as a usefulEquation
37 + 47 = 84, 
84 % 2= 42.0, 
42.+ 18= 60, 
60 / 6 = 10
Ans: 10
Steps : 4, 
Numerical Range : 1-100, 
Operations : +-*%... Question : A group of people went to 
an amusement park. 37 of them were 
children and 47 were adults. They 
split the total number of people into 
two groups and added 18 more people 
to one of the groups. This group was 
then divided equally among six rides. 
How many people rode on each ride?Problem 
Crafter
Rewrite Question : A school organized a 
field trip to a local museum. Initially, 37 
students and 47 teacher s attended. The 
entire group was divided into two, and 
then 18 volunteers joined one of the 
groups. This larger group was evenly 
distributed across six exhibit tours. How 
many people were in each tour group?Problem 
Rewriter
ControlMathQA
Discard
Equation 
Generator
LLMFigure 2: The overview of our ControlMath. Here, we present the example of generating multi-calculation math
word problems.
approach to improve smaller LLMs’ performances
in down-stream tasks. This approach often involves
distilling outputs of stronger LLMs to generate the
SFT datasets (Luo et al., 2023; Mitra et al., 2024;
Yin et al., 2024; Yue et al., 2024; Meng et al., 2022).
When applying data augmentation into math rea-
soning, there are two variants: query augmentation
and response augmentation. Typical works towards
query augmentation include MuggleMath (Li et al.,
2023a), MetaMath (Yu et al., 2023) and MathScale
(Tang et al., 2024), which use different strategies to
obtain the new questions. Meanwhile, RFT (Yuan
et al., 2023) and xRFT (Chen et al., 2023d) con-
centrate on response augmentation, which utilize
rejection sampling to generate diverse reasoning
paths for the same question. However, most of
these approaches rely on seed questions in training
sets, which pose challenges in generating diverse
domain or distribution data.
3 ControlMath
The primary motivation behind ControlMath is
to address the challenges of overfitting and inef-
ficiency in training LLMs for mathematical reason-
ing tasks. To achieve this, ControlMath employs
a three-step approach involving two specialized
agents and one Python function module. In this
section, we present the details of ControlMath.
3.1 Controllable Equation Generation
Our first step is the controllable generation of math-
ematical equations, driven by the need to ensure
diversity in the following generated math word
problems. Specifically, we employ an equation
generation module to allow precise control overthe characteristics of the equations, addressing the
issue of homogeneous training samples that limit
the model’s ability to generalize.
In our implementation, the equation generation
module is a Python function designed to produce
equations based on specified parameters. We fo-
cus on generating three main types of equations:
1)Multi-step Calculation : These include basic
arithmetic operations (addition, subtraction, multi-
plication, division), as well as more complex func-
tions like trigonometric functions, roots, and expo-
nents. For generating such equations, we specify
the input parameters, including steps ,operators
andnumerical ranges , to create diverse equations;
2)Polynomials : These equations involve terms
with variables raised to various powers, often re-
quiring multiple steps to simplify or solve. By
generating polynomials of varying degree of the
polynomial and the coefficients , we ensure that
the model encounters a wide range of polynomial-
related problems; 3) Probability : These equations
involve calculating probabilities, which often re-
quire understanding combinations, permutations,
and probability rules. We follow (Hendrycks et al.,
2021) and set predefined topics: a set of letters or
sequence as templates. These templates serve as the
basis for generating diverse probability problems,
ensuring the LLMs develop a strong foundation in
statistical reasoning.
By customizing different inputs, we generate
a wide variety of formulas that cover a broad
spectrum of mathematical concepts and operations.
This controlled generation ensures the foundation
for creating diverse mathematical word problems.You are a math expert. Given an equation list that con-
tains multi-step mathematical formulas and its final answer.
Your task is to create a math word problem and its refer-
ence solution based on the provided series of mathematical
equations and the final answer.
{few shot examples }
Equation List: { Equation }
Final Answer: { Answer }
You should keep in mind that:
(1) Your produced math problem should be diverse and
avoid using words like “mathematical”, “calculation”, etc.
(2) You should present equations in LaTeX format.
Table 1: Prompt Template for Problem-Crafter Agent.
Problem-Crafter Agent. The second step in-
volves translating the abstract equations into math
word problems. A frointer LLM-based Problem-
Crafter agent is used for this purpose, which gener-
atescontextually rich problems and their reference
solutions from the generated equations. It ensures
that problems vary in context and application while
maintaining a strong connection to the underlying
equations. We present the template for prompts in
Table 1. To guide the agent in question formulation,
we include several examples in the prompts, which
are from manual interactions between Web GPT-4.
3.2 Efficient Data Selection: More data is not
always helpful
Problem-Rewriter Agent. The third step fo-
cuses on selecting effective training data and elimi-
nating redundant or ineffective samples. The mo-
tivation for this step is to enhance training effi-
ciency by ensuring that only useful data is retained,
thereby improving model performance without
overfitting. The Problem-Rewriter agent is crucial
for this step. After generating an initial problem by
the Problem-Crafter, this agent rewrites the prob-
lems to create variations. Note that the rewriter
agent is constrained to maintain the original nu-
merical values of the problems, changing only the
phrasing or topics, as shown in Appendix A.
Efficient Data Selection. Then, both the original
and rewritten math word problems are presented
to the smaller open-sourced LLM; if the LLM can
solve both correctly, it means such problem does
not contribute to further learning and can be dis-
carded because model may have mastered this level
of problems. However, if the model answers incor-
rectly to one of them, it indicates a genuine gap in
understanding, making these problems valuable forfurther training. Such problem will be collected in
ourControlMathQA . This process mimics human
cognitive learning, where exposure to redundant
information does not enhance understanding. By
focusing on non-redundant, effective samples, we
improve the overall quality and efficiency of the
training data. To reduce variance, the temperature
is set to 0 when sampling LLM’s outputs.
Validation. In practice, we observe that some-
times the new problems generated by the Problem-
Crafter Agent might not correctly match the cor-
responding formulas or the generated reference
solutions might be inaccurate. To address these
issues, we introduce a validation step using GPT-4
(gpt-4-turbo ). For validation, we input the for-
mula, the generated problem, and the correspond-
ing solution into GPT-4. If GPT-4 identifies any
mismatches—either the problem does not align
with the formula, or the solution does not correctly
solve the problem—we discard the problematic en-
try. This validation step ensures that only accurate
and relevant problems are included in our dataset,
further enhancing the quality of the training data.
The prompts are presented in Appendix A.
Iterative Process. In theory, our approach can be
iteratively applied indefinitely to continually gen-
erate needed corpus. However, due to resource
constraints, we limit experimentation to three it-
erations . In the first iteration, we use Mistral-7B
which has not undergone any fine-tuning. For the
second and third iterations, we fine-tune the model
using the data generated from the previous itera-
tions. This iterative process allows us to progres-
sively enhance the model’s performance by contin-
ually refining the training data and focusing on the
model’s weaknesses identified in each round.
Why we need to rewrite the problem? The pur-
pose of rewriting the problem is to ensure the ro-
bustness of the model’s understanding. Several
works (Chen et al., 2024c; Yu et al., 2023) have
proved that simply rephrasing or changing the or-
der of the question could confuse LLMs. Thus,
simply testing the model on the original problem
might not fully capture its comprehension, as the
model could be overfitting to specific phrasings or
patterns in the training data. By presenting both the
original and the rewritten problem, we can more
accurately assess whether the model truly under-
stands the underlying concepts. We have also com-
plie a confusion matrix showing the proportionsSpecifications Steps : 4,Operators : [sqrt(), ×, %, +, -], Numerical Range : 1-1000
Generated Equation 4 - 1 = 3, 3 * 16 = 48, sqrt(16) = 4, 30 % 6=5
Math Word ProblemTom sets sail on his ship at 1 PM, traveling at a speed of 10 miles per hour. He reaches his
destination at 4 PM. After spending some time there, he decides to return. However, due
to different weather conditions, he sails back at a slightly slower speed that is the square
root of the original speed. Using this information, can you determine how long it takes
Tom to return to his starting point?
Specifications Degree : 2,Coefficients : -100-100
Generated Equation -41*c - 16*c**2 + 18*c + 25*c
Math Word Problem Express -41*c - 16*c**2 + 18*c + 25*c in the form q*c**2 + p*c + u and give p.
Specifications Templates : A set of letters, Unique characters : 6,Without Replacement
Math Word ProblemWhat is probability of picking 1 k, 1 h, and 1 c when three letters picked without replace-
ment from {c: 1, y: 1, e: 1, n: 1, k: 1, h: 2}?
Table 2: Several generated examples in our ControlMathQA, including input specifications, generated equation and
math word problems. More cases could be seen in Appendix B.
of cases where the model answers both questions
correctly, both incorrectly, or one correctly and one
incorrectly, detailed in the Appendix, Table 6.
Correlation with AdaBoost. Our approach is
theoretically similar to AdaBoost (Freund et al.,
1999), a machine learning algorithm that iteratively
trains weak classifiers on the hardest-to-classify
samples, reweighting data to focus on errors. Sim-
ilarly, ControlMath focuses on generating and se-
lecting the most challenging problems for the LLM,
effectively "reweighting" the training data towards
the areas where the model struggles the most. By
collecting only the problems the model answers
incorrectly, we ensure that subsequent training
rounds address these weaknesses, analogous to how
AdaBoost emphasizes misclassified samples to im-
prove overall model performance. This similarity
to AdaBoost gives ControlMath a theoretical base,
showing that it has the potential to make LLMs
more reliable in general mathematical reasoning.
3.3 Statistics
In each iteration, we generate 160k multi-step cal-
culation formulas, 10k polynomials and 10k prob-
ability problems (See details in following Section
4.1). After data selection and GPT-4 validation
process, we collect 110k math word problems in
total. Inspired by (Yuan et al., 2023), response aug-
mentation also contributes to the benefit of math
reasoning LLMs, we also include this type aug-
mentation in our ContronlMathQA, where we uti-
lizeGPT-3.5-Turbo-0613 to generate answers for
each question three times and remain the correct
ones. As a result, we collect about 190k question-
answer pairs, where 155k for multi-calculation, 15k
for polynomials and 20k for probability problems.
Note, we decide to keep only original problems aswe find including rewritten ones contributes limited
improvements (Results in Appendix, Figure 7).
4 Experiments
In this section, we first present the details of our
implementation, including data generation, training
settings. Then we show the main results of different
backbones with ControlMathQA.
4.1 Implementation
4.1.1 Data Generation
In equation generation (Section 3.1), we introduce
several constraints to ensure the generated equa-
tions are both high in quality and diverse: (1)
Unique equations : To secure robust samples, it
is essential to keep each generated equation dis-
tinct; (2) Diverse Distributions :a) For multi-step
calculation formulas , we set the range for steps
from 2 to 9, covering most multi-step reasoning
scenarios. The numerical range is divided into four
tiers: 1-100, 100-k, 1k-10k, and 10k-1million. Dur-
ing each iteration, these ranges are randomly com-
bined to produce 5,000 unique equation examples
for each combing group, with operators including
basic arithmetic (addition, subtraction, multiplica-
tion, division), square roots, and exponents. b)
Forpolynomials , we set the degree range from 1
to 3 and coefficients from -100 to 100, produc-
ing polynomials of different complexities, ensuring
the LLMs encounter a broad range of polynomial-
related problems. Each iteration randomly samples
5,000 polynomial equations. c) Following Saxton
et al. (2018), we consider two sampling settings:
with or without replacement to generate probability
problems . The sample space templates consist of a
set of characters and a sequential sequence, where
the number of unique characters does not exceedIn-Domain Training Datasets: GSM8K
ModelsIn-Domain Out-Of-DomainAvg.GSM8K GSM8K-Hard SV AMP SV AMP-Hard MATH Polynomials Prob.
LLaMA 2-7B 42.1 11.2 35.8 7.4 4.7 5.5 21.0 18.2
Ours 49.3 18.4 51.6 18.2 9.5 39.0 89.3 39.3
LLaMA 2-13B 49.7 13.5 50.9 14.7 6.0 5.5 22.0 23.2
Ours 57.1 16.6 63.1 20.4 11.2 41.2 90.7 42.9
Mistral-7B 51.5 16.1 37.8 11.3 7.3 4.5 44.9 24.8
Ours 59.1 19.7 55.7 19.1 12.4 42.1 94.9 43.3
In-Domain Training Datasets: MetaMath
ModelsIn-Domain Out-Of-DomainAvg.GSM8K GSM8K-Hard MATH SV AMP SV AMP-Hard Polynomials Prob.
LLaMA 2-7B 62.9 17.0 19.7 60.8 14.7 11.9 8.1 27.9
Ours 67.0 20.2 21.4 68.9 24.7 42.7 90.3 47.9
LLaMA 2-13B 66.9 18.7 22.4 65.7 17.9 14.0 9.3 30.7
Ours 70.0 22.5 24.1 72.4 26.5 43.4 90.1 49.9
Mistral-7B 67.6 21.8 22.7 66.5 19.8 20.8 9.1 32.6
Ours 71.4 24.5 26.1 71.2 28.7 50.9 94.7 52.5
Table 3: Model performances with different training datasets. Prob. refers to Probability. Ours denotes that we
add our ControlMathQA with specific in-domain training datasets. More comprehensive evaluation of the whole
Mathematics and MMLU Datasets can be seen in Appendix, Table 8.
20. In each interaction, we randomly sample 5000
examples. Of note, this setting directly produces
math word problems, eliminating the need for the
problem-crafter agent, as an example in Table 2.
We use math ,sympy ,mathematics_dataset libraries
to generate equations with python.
In Section 3.2, both Problem-Crafter and Rewrit-
ten Agents are based on gpt-4-turbo . Key imple-
mentation details include setting the temperature
to 0.9 to ensure diverse problem generation, max
tokens to 2,000 to accommodate complex problem
formulations, and top-p to 1.
4.1.2 Experimental Settings
Training Settings. The question-answer pairs in
ControlMathQA are formatted in Alpaca-format
(Taori et al., 2023). Experimentally, we select the
LLaMA 2-7B,13B and Mistral-7B (Jiang et al.,
2023) as backbone models. We use a batch size of
128, 512 max token length and train on the Control-
MathQA dataset for 3 epochs using a learning rate
of 2e-5 on NVIDIA A100 GPUs. To better illus-
trate the generalization of our ControlMathQA, we
separately combine it with GSM8K and MetaMath
in-domain training datasets to validate its effective-
ness in in-domain and out-of-domain results.
Evaluation Settings. We evaluate different mod-
els in the following datasets: (1) SV AMP (Patel
et al., 2021), an elementary-level math dataset with
1,000 test examples. (2) SV AMP-Hard (Chen
et al., 2023b), which replaces numbers in SV AMPquestions with values between 100k and 10M. (3)
GSM8K (Cobbe et al., 2021), a dataset of 1,391
linguistically diverse grade school MWPs crafted
by human writers. (4) GSM8K-Hard (Gao et al.,
2023), an advanced version of GSM8K with larger
numerical values to test LLM generalization. (5)
The Polynomials andProbability subsets from
Mathematics Datasets (Saxton et al., 2018), each
containing 2,000 samples. (6) MATH (Hendrycks
et al., 2021), which provides competition-level
challenges across different mathematical domains.
4.2 Results
We evaluate ControlMathQA to answer the fol-
lowing questions: Q1: Can our dataset promote
math generalist LLMs across various domains? Q2:
Does our adaptively efficient data selection strategy
help model achieve better results with less data?
RQ1: ControlMathQA promotes Math Gener-
alist Models. Table 3 presents three backbones’
performances with combining ControlMathQA and
other in-domain training datasets, separately. Ob-
viously, ours could help different LLMs exhibit
exceptional performances across different domains.
A notable example is that when training LLaMA
2-7B with ours and GSM8K, the resulting model
attains impressive improvements of 15.8% and
68.3% on SV AMP and Probability datasets. In-
terestingly, though MetaMath could significantly
boost the model performances in-domain bench-
marks, it downgrades the baseline results in Prob-Figure 3: Here, we present the LLaMA 2-7B performances with different size corpus when we don’t apply our
efficient data selection strategy. Here, we train the model with ControlMathQA and GSM8K.
1 2 3 4 5 6 7
Equations within Question102030405060Accuracy (%)
GSM8K ControlMathQA ControlMathQA-GSM8K
Figure 4: Here, we present the LLaMA 2-7B perfor-
mances with different training corpus in GSM8K.
ability problem solving. This highlights that over-
fitting in-domain helps little or even decreases out-
of-domain mathematical capabilities. These results
underscore the effectiveness of our approach in
enhancing mathematical generalization.
RQ2: More data is not always useful. In this
component, we explore whether our selection strat-
egy can achieve higher training efficiency. Figure 3
shows extensive experiments using GSM8K as the
in-domain training corpus without data selection.
We can draw the several observations: 1) Scal-
ing up the dataset size generally improves model
performance, though the improvement diminishes
with larger size. 2) With our data selection strategy,
the model achieves much better performances vs.
using the same data size without our data selection
strategy. And mostly ours also achieve better per-
formances when the model trained with 500k data
size (except GSM8K). This highlights that moreAugmentation SV AMP SV AMP-H MATH Poly. Prob.
- 35.8 7.4 4.7 5.5 21.0
w. Multi-step 47.5 15.9 6.4 9.3 21.2
w. Poly. 39.1 10.3 7.5 37.8 26.0
w. Prob. 37.5 9.7 7.3 10.1 88.1
Table 4: Ablations for different augmentation prob-
lems. Here, we train LLaMA 2-7B with our datasets
and GSM8K. More results seen in Appendix, Table 7.
data is not always helpful and data quality is more
important than data quantity.
Ablations. Table 4 shows the ablations of differ-
ent augmentation problem types in out-of-domain
datasets. Obviously, each augmentation contributes
to the improvements in different datasets. Multi-
step calculation augmented problems lead to better
results in SV AMP related datasets. Meanwhile,
probability augmentation yields the highest im-
provements in probability-related tasks.
4.3 Discussion 1: Tailor ControlMath for
specific datasets
Our method can focus on both generalization and
adaptation to a targeted dataset. A trivial version
of our method involves adaptively generating data
based on poor performance on a targeted dataset.
Here, we provide an example of how to augment
the GSM8K dataset using our method:
First, we train a base SFT model (LLaMA 2-7B)
using the GSM8K training set. Then, we test this
model on the test set, recording the error rates for/uni0000002a/uni00000036/uni00000030/uni0000001b/uni0000002e /uni0000002a/uni00000036/uni00000030/uni0000001b/uni0000002e/uni00000010/uni0000002b/uni00000044/uni00000055/uni00000047 /uni00000036/uni00000039/uni00000024/uni00000030/uni00000033 /uni00000036/uni00000039/uni00000024/uni00000030/uni00000033/uni00000010/uni0000002b/uni00000044/uni00000055/uni00000047 /uni00000030/uni00000024/uni00000037/uni0000002b
/uni00000037/uni00000048/uni00000056/uni00000057/uni00000003/uni00000027/uni00000044/uni00000057/uni00000044/uni00000056/uni00000048/uni00000057/uni00000056/uni00000013/uni00000014/uni00000013/uni00000015/uni00000013/uni00000016/uni00000013/uni00000017/uni00000013/uni00000018/uni00000013/uni00000019/uni00000013/uni0000001a/uni00000013/uni0000001b/uni00000013/uni00000024/uni00000046/uni00000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c/uni00000003/uni0000000b/uni00000008/uni0000000c/uni00000017/uni0000001c/uni00000011/uni00000016
/uni00000014/uni0000001b/uni00000011/uni00000017/uni00000018/uni00000014/uni00000011/uni00000019
/uni00000014/uni0000001b/uni00000011/uni00000015
/uni0000001c/uni00000011/uni00000018/uni00000017/uni0000001a/uni00000011/uni00000014
/uni00000014/uni00000017/uni00000011/uni0000001a/uni00000017/uni00000019/uni00000011/uni0000001a
/uni00000015/uni00000013/uni00000011/uni00000014
/uni00000019/uni00000011/uni00000014/uni00000017/uni00000015/uni00000011/uni00000014
/uni00000014/uni00000014/uni00000011/uni00000015/uni00000016/uni00000018/uni00000011/uni0000001b
/uni0000001a/uni00000011/uni00000017
/uni00000017/uni00000011/uni0000001a/uni00000026/uni00000052/uni00000051/uni00000057/uni00000055/uni00000052/uni0000004f/uni00000030/uni00000044/uni00000057/uni0000004b/uni00000034/uni00000024 /uni00000026/uni00000052/uni00000051/uni00000057/uni00000055/uni00000052/uni0000004f/uni00000030/uni00000044/uni00000057/uni0000004b/uni00000034/uni00000024/uni00000010/uni00000032/uni00000053/uni00000048/uni00000051 /uni0000002a/uni00000036/uni00000030/uni0000001b/uni0000002eFigure 5: Here, we present the LLaMA 2-7B perfor-
mances with training different corpus.
problems of varying difficulty levels. The difficulty
of a problem is primarily defined by the complexity
of the equations involved. Using our ControlMath
method, we generate new problems matching the
difficulty distribution of the test set problems. We
generate more data for problem types with higher
error rates, proportional to their contribution to the
overall error rate across different difficulty levels.
In each iteration, we generate a total of 15,000
new problems and repeat this process three times
to iteratively generate the final corpus, termed as
ControlMathQA-GSM8K.
Figure 4 presents the accuracy when the model
is trained with different corpus. We can find that
after such tailored data augmentation, the result-
ing model significantly improves in all difficulty
type questions. Moreover, the overall model perfor-
mance increases from 42.1% to 55.3%, a better re-
sult compared with base ControlMathQA (49.3%).
The results indicate that our ControlMath can be
regarded as a plug-and-play module to adaptively
generate training samples for targeted datasets.
4.4 Discussion 2: Cost-Effective ControlMath
Using GPT-4’s API for data generation and val-
idation is costly, resulting in more than 10k dol-
lars. Intuitively, can we use smaller LLMs for
data generation to reduce these costs while main-
taining high quality? To explore this, we col-
lect related 20k training samples from GPT-4 to
train Mistral-7B as the two Problem-Crafter and
Problem-Rewriter Agents. We also apply rejection
sampling to conduct answer augmentation. With
the trained Mistral-7B agents, we conduct data
augmentation over nearly two months on 8xA100
GPUs, resulting in the collection of approximately
1 million training samples. We term the collected
dataset as ControlMathQA-Open .
Interestingly, as shown in Figure 5, although
ControlMathQA-Open consists of more than five
times as much data as the base version, it performs
/uni00000026/uni00000030/uni00000034/uni00000024/uni00000003/uni00000032/uni00000053/uni00000048/uni00000051/uni00000010/uni00000034/uni00000058/uni00000048/uni00000056/uni00000057/uni0000004c/uni00000052/uni00000051 /uni00000026/uni00000030/uni00000034/uni00000024/uni00000010/uni00000034/uni00000058/uni00000048/uni00000056/uni00000057/uni0000004c/uni00000052/uni00000051 /uni00000026/uni00000030/uni00000034/uni00000024/uni00000003/uni00000032/uni00000053/uni00000048/uni00000051/uni00000010/uni00000026/uni00000052/uni00000037 /uni00000026/uni00000030/uni00000034/uni00000024/uni00000010/uni00000026/uni00000052/uni00000037
/uni00000027/uni00000044/uni00000057/uni00000044/uni00000056/uni00000048/uni00000057/uni00000056/uni00000016/uni00000017/uni00000018/uni00000019/uni0000001a/uni0000001b/uni0000001c/uni00000014/uni00000013/uni00000033/uni00000048/uni00000055/uni00000053/uni0000004f/uni00000048/uni0000005b/uni0000004c/uni00000057/uni0000005cFigure 6: The perplexity of questions and CoT an-
swers in different datasets. CMQA is short for Con-
trolMathQA.
Dataset gsm8k MetaMath Ours
Diversity Gain - 0.09 0.41
Table 5: The diversity gain between MetaMath and ours
worse across almost five datasets. This suggests
that the quality of data generated by Mistral-7B is
inferior to that of GPT-4. To investigate the reasons
behind this, we calculate the perplexity (Marion
et al., 2023; Wang et al., 2024; Chen et al., 2024b)
of both datasets using an unfine-tuned Llama 2-
7B model. Figure 6 shows that ControlMathQA
has a significantly lower perplexity compared to
ControlMathQA-Open. This indicates that Control-
MathQA is inherently easier to learn from, which
might better enhance an LLM’s problem-solving
abilities (Yu et al., 2023). Moreover, we hypoth-
esize that data augmentation by LLMs inherently
resembles knowledge distillation, where a superior
teacher model provides more effective problems
and answers, thus better facilitating learning. We
observe a similar phenomenon during answer aug-
mentation: models trained on answer paths gener-
ated by GPT-4 or GPT-3.5 significantly outperform
those trained on data from the LLaMA or Mistral
series.
4.5 Discussion 3: Diversity Gains
we evaluate the diversity of our generated math
word problems using the diversity gain (Bilmes,
2022) metric. This metric measures how much a
new dataset contributes to the diversity of a base
dataset.
Concretely, given a base dataset Dbase: Com-
prises (N) samples, each represented as (qi, ri)where qiis the question, riis the CoT answer.
And given a new dataset, Dnew: Comprises (M)
samples. Then: 1) For each sample ( xi) inDnew,
find the sample ( xj) inDbasethat is most simi-
lar based on feature extraction. 2) Calculate the
squared Euclidean distance in the feature space be-
tween ( xi) and its nearest ( xj) using the formula:
(minxj∈Dbase(∥f(xi)−f(xj)∥2)). 3) Average these
distances over all samples in Dnew.
We use gsm8k as base dataset and OpenAI Em-
bedding API text-embedding-ada-002 to extract
sentence embeddings. The results are presented
in Table 5. ControlMathQA dataset is much more
diverse than gsm8k and MetaMath, covering more
unseen scenarios.
5 Conclusion
In this paper, we propose a new data augmenta-
tion approach for mathematical reasoning, called
ControlMath. The core of this approach lies into
two lines: 1) It first utilizes an equation genera-
tion module to control the distributions of the gen-
erated equations. Then a Probelm-Crafter Agent
generates the math word problems based on these
equations. 2) It introduces a Problem-Rewriter
Agent to help ensure the effectiveness of the gener-
ated samples, filtering out redundant ones. Our ap-
proach could generate diverse problems and focus
on quality over quantity to enable stronger math
generalist models with smaller data. The result-
ing dataset, ControlMathQA, could help LLMs ob-
tain improvements in both in-domain and out-of-
domain datasets. Future works include expanding
the size of ControlMathQA and exploring other
strategies to select more efficient data.
Limitation
In this paper, we focus on using large language
models to generate training samples for mathemati-
cal reasoning, Some issues remain to be explored:
In practice, we observe that gpt-4-turbo may
generate unrelated questions from the given equa-
tions, especially for complex ones involving 7 or 8
steps. We found that the error rate for such cases
can be as high as 25-35%, leading to significant
cost inefficiencies. A more efficient solution needs
to be explored to address this issue.
Another limitation is that we have not yet con-
ducted experiments on larger LLMs like LLaMA
2-30B or 70B models , primarily due to training
resource constraints.Additionally, due to the specificity of our
method, we can generate large amounts of data
tailored to specific datasets, potentially causing
the model to overfit within that domain and thus
achieve better performance. This could lead to
unfair advantages in leaderboard rankings, though
it ultimately depends on the practitioners’ profes-
sional ethics.
References
Jeff Bilmes. 2022. Submodularity in machine
learning and artificial intelligence. Preprint ,
arXiv:2202.00132.
Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie
Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind
Neelakantan, Pranav Shyam, Girish Sastry, Amanda
Askell, Sandhini Agarwal, Ariel Herbert-V oss,
Gretchen Krueger, Tom Henighan, Rewon Child,
Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu,
Clemens Winter, Christopher Hesse, Mark Chen, Eric
Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess,
Jack Clark, Christopher Berner, Sam McCandlish,
Alec Radford, Ilya Sutskever, and Dario Amodei.
2020. Language models are few-shot learners. CoRR ,
abs/2005.14165.
Lichang Chen, Shiyang Li, Jun Yan, Hai Wang, Kalpa
Gunaratna, Vikas Yadav, Zheng Tang, Vijay Srini-
vasan, Tianyi Zhou, Heng Huang, and Hongxia Jin.
2023a. Alpagasus: Training A better alpaca with
fewer data. CoRR , abs/2307.08701.
Nuo Chen, Hongguang Li, Baoyuan Wang, and Jia Li.
2023b. From good to great: Improving math reason-
ing with tool-augmented interleaf prompting. arXiv
preprint arXiv:2401.05384 .
Nuo Chen, Yuhan Li, Jianheng Tang, and Jia Li. 2024a.
Graphwiz: An instruction-following language model
for graph computational problems. In Proceedings
of the 30th ACM SIGKDD Conference on Knowl-
edge Discovery and Data Mining , KDD ’24, page
353–364, New York, NY , USA. Association for Com-
puting Machinery.
Nuo Chen, Yan Wang, Yang Deng, and Jia Li. 2024b.
The oscars of ai theater: A survey on role-playing
with language models. Preprint , arXiv:2407.11484.
Nuo Chen, Yan Wang, Haiyun Jiang, Deng Cai, Yuhan
Li, Ziyang Chen, Longyue Wang, and Jia Li. 2023c.
Large language models meet harry potter: A dataset
for aligning dialogue agents with characters. In Find-
ings of the Association for Computational Linguis-
tics: EMNLP 2023 , pages 8506–8520, Singapore.
Association for Computational Linguistics.
Nuo Chen, Zinan Zheng, Ning Wu, Linjun Shou, Ming
Gong, Yangqiu Song, Dongmei Zhang, and Jia Li.
2023d. Breaking language barriers in multilingualmathematical reasoning: Insights and observations.
arXiv preprint arXiv:2310.20246 .
Xinyun Chen, Ryan A Chi, Xuezhi Wang, and Denny
Zhou. 2024c. Premise order matters in reason-
ing with large language models. arXiv preprint
arXiv:2402.08939 .
Xinyun Chen, Maxwell Lin, Nathanael Schärli, and
Denny Zhou. 2023e. Teaching large language models
to self-debug. arXiv preprint arXiv:2304.05128 .
Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian,
Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias
Plappert, Jerry Tworek, Jacob Hilton, Reiichiro
Nakano, Christopher Hesse, and John Schulman.
2021. Training verifiers to solve math word prob-
lems. CoRR , abs/2110.14168.
Yoav Freund, Robert Schapire, and Naoki Abe. 1999.
A short introduction to boosting. Journal-Japanese
Society For Artificial Intelligence , 14(771-780):1612.
Luyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon,
Pengfei Liu, Yiming Yang, Jamie Callan, and Gra-
ham Neubig. 2023. Pal: Program-aided language
models. In International Conference on Machine
Learning , pages 10764–10799. PMLR.
Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul
Arora, Steven Basart, Eric Tang, Dawn Song, and
Jacob Steinhardt. 2021. Measuring mathematical
problem solving with the math dataset. NeurIPS .
Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan
Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang,
and Weizhu Chen. 2021. Lora: Low-rank adap-
tation of large language models. arXiv preprint
arXiv:2106.09685 .
Jie Huang, Xinyun Chen, Swaroop Mishra,
Huaixiu Steven Zheng, Adams Wei Yu, Xiny-
ing Song, and Denny Zhou. 2024. Large language
models cannot self-correct reasoning yet. In The
Twelfth International Conference on Learning
Representations .
Shima Imani, Liang Du, and Harsh Shrivastava. 2023a.
Mathprompter: Mathematical reasoning using large
language models. arXiv preprint arXiv:2303.05398 .
Shima Imani, Liang Du, and Harsh Shrivastava. 2023b.
Mathprompter: Mathematical reasoning using large
language models. In ACL (industry) , pages 37–42.
Association for Computational Linguistics.
Albert Q. Jiang, Alexandre Sablayrolles, Arthur Men-
sch, Chris Bamford, Devendra Singh Chaplot, Diego
de las Casas, Florian Bressand, Gianna Lengyel, Guil-
laume Lample, Lucile Saulnier, Lélio Renard Lavaud,
Marie-Anne Lachaux, Pierre Stock, Teven Le Scao,
Thibaut Lavril, Thomas Wang, Timothée Lacroix,
and William El Sayed. 2023. Mistral 7b. Preprint ,
arXiv:2310.06825.Chengpeng Li, Zheng Yuan, Guanting Dong, Keming
Lu, Jiancan Wu, Chuanqi Tan, Xiang Wang, and
Chang Zhou. 2023a. Query and response augmenta-
tion cannot help out-of-domain math reasoning gen-
eralization. arXiv preprint arXiv:2310.05506 .
Yifei Li, Zeqi Lin, Shizhuo Zhang, Qiang Fu, Bei Chen,
Jian-Guang Lou, and Weizhu Chen. 2023b. Making
language models better reasoners with step-aware
verifier. In Proceedings of the 61st Annual Meet-
ing of the Association for Computational Linguistics
(Volume 1: Long Papers) , pages 5315–5333.
Shayne Longpre, Le Hou, Tu Vu, Albert Webson,
Hyung Won Chung, Yi Tay, Denny Zhou, Quoc V
Le, Barret Zoph, Jason Wei, et al. 2023. The flan
collection: Designing data and methods for effective
instruction tuning. arXiv preprint arXiv:2301.13688 .
Haipeng Luo, Qingfeng Sun, Can Xu, Pu Zhao, Jian-
guang Lou, Chongyang Tao, Xiubo Geng, Qingwei
Lin, Shifeng Chen, and Dongmei Zhang. 2023. Wiz-
ardmath: Empowering mathematical reasoning for
large language models via reinforced evol-instruct.
arXiv preprint arXiv:2308.09583 .
Max Marion, Ahmet Üstün, Luiza Pozzobon, Alex
Wang, Marzieh Fadaee, and Sara Hooker. 2023.
When less is more: Investigating data pruning for pre-
training llms at scale. Preprint , arXiv:2309.04564.
Yu Meng, Jiaxin Huang, Yu Zhang, and Jiawei Han.
2022. Generating training data with language mod-
els: Towards zero-shot language understanding. Ad-
vances in Neural Information Processing Systems ,
35:462–477.
Arindam Mitra, Hamed Khanpour, Corby Rosset, and
Ahmed Awadallah. 2024. Orca-math: Unlocking
the potential of slms in grade school math. arXiv
preprint arXiv:2402.14830 .
OpenAI. 2023. Gpt-4 technical report. Preprint ,
arXiv:2303.08774.
Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,
Carroll L. Wainwright, Pamela Mishkin, Chong
Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray,
John Schulman, Jacob Hilton, Fraser Kelton, Luke
Miller, Maddie Simens, Amanda Askell, Peter Welin-
der, Paul F. Christiano, Jan Leike, and Ryan Lowe.
2022. Training language models to follow instruc-
tions with human feedback. In NeurIPS .
Arkil Patel, Satwik Bhattamishra, and Navin Goyal.
2021. Are NLP models really able to solve simple
math word problems? In Proceedings of the 2021
Conference of the North American Chapter of the
Association for Computational Linguistics: Human
Language Technologies , pages 2080–2094, Online.
Association for Computational Linguistics.
Baolin Peng, Chunyuan Li, Pengcheng He, Michel Gal-
ley, and Jianfeng Gao. 2023. Instruction tuning with
gpt-4. arXiv preprint arXiv:2304.03277 .David Saxton, Edward Grefenstette, Felix Hill, and
Pushmeet Kohli. 2018. Analysing mathematical rea-
soning abilities of neural models. In International
Conference on Learning Representations .
Teven Le Scao, Angela Fan, Christopher Akiki, El-
lie Pavlick, Suzana Ili ´c, Daniel Hesslow, Roman
Castagné, Alexandra Sasha Luccioni, François Yvon,
Matthias Gallé, et al. 2022. Bloom: A 176b-
parameter open-access multilingual language model.
arXiv preprint arXiv:2211.05100 .
Freda Shi, Mirac Suzgun, Markus Freitag, Xuezhi Wang,
Suraj Srivats, Soroush V osoughi, Hyung Won Chung,
Yi Tay, Sebastian Ruder, Denny Zhou, et al. 2022.
Language models are multilingual chain-of-thought
reasoners. arXiv preprint arXiv:2210.03057 .
Zhengyang Tang, Xingxing Zhang, Benyou Wan, and
Furu Wei. 2024. Mathscale: Scaling instruction
tuning for mathematical reasoning. arXiv preprint
arXiv:2403.02884 .
Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann
Dubois, Xuechen Li, Carlos Guestrin, Percy Liang,
and Tatsunori B. Hashimoto. 2023. Stanford alpaca:
An instruction-following llama model. https://
github.com/tatsu-lab/stanford_alpaca .
Shubham Toshniwal, Ivan Moshkov, Sean Narenthi-
ran, Daria Gitman, Fei Jia, and Igor Gitman. 2024.
Openmathinstruct-1: A 1.8 million math instruction
tuning dataset. arXiv preprint arXiv:2402.10176 .
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier
Martinet, Marie-Anne Lachaux, Timothée Lacroix,
Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal
Azhar, et al. 2023a. Llama: Open and effi-
cient foundation language models. arXiv preprint
arXiv:2302.13971 .
Hugo Touvron, Louis Martin, Kevin Stone, Peter Al-
bert, Amjad Almahairi, Yasmine Babaei, Nikolay
Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti
Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton
Ferrer, Moya Chen, Guillem Cucurull, David Esiobu,
Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller,
Cynthia Gao, Vedanuj Goswami, Naman Goyal, An-
thony Hartshorn, Saghar Hosseini, Rui Hou, Hakan
Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa,
Isabel Kloumann, Artem Korenev, Punit Singh Koura,
Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Di-
ana Liskovich, Yinghai Lu, Yuning Mao, Xavier Mar-
tinet, Todor Mihaylov, Pushkar Mishra, Igor Moly-
bog, Yixin Nie, Andrew Poulton, Jeremy Reizen-
stein, Rashi Rungta, Kalyan Saladi, Alan Schelten,
Ruan Silva, Eric Michael Smith, Ranjan Subrama-
nian, Xiaoqing Ellen Tan, Binh Tang, Ross Tay-
lor, Adina Williams, Jian Xiang Kuan, Puxin Xu,
Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan,
Melanie Kambadur, Sharan Narang, Aurelien Ro-
driguez, Robert Stojnic, Sergey Edunov, and Thomas
Scialom. 2023b. Llama 2: Open foundation and
fine-tuned chat models. Preprint , arXiv:2307.09288.Peiyi Wang, Lei Li, Liang Chen, Feifan Song, Binghuai
Lin, Yunbo Cao, Tianyu Liu, and Zhifang Sui. 2024.
Making large language models better reasoners with
alignment.
Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le,
Ed Chi, Sharan Narang, Aakanksha Chowdhery, and
Denny Zhou. 2022. Self-consistency improves chain
of thought reasoning in language models. arXiv
preprint arXiv:2203.11171 .
Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel,
Barret Zoph, Sebastian Borgeaud, Dani Yogatama,
Maarten Bosma, Denny Zhou, Donald Metzler, Ed H.
Chi, Tatsunori Hashimoto, Oriol Vinyals, Percy
Liang, Jeff Dean, and William Fedus. 2022a. Emer-
gent abilities of large language models. Trans. Mach.
Learn. Res. , 2022.
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten
Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou,
et al. 2022b. Chain-of-thought prompting elicits rea-
soning in large language models. Advances in Neural
Information Processing Systems , 35:24824–24837.
Yixuan Weng, Minjun Zhu, Shizhu He, Kang Liu,
and Jun Zhao. 2022. Large language models are
reasoners with self-verification. arXiv preprint
arXiv:2212.09561 .
Shuo Yin, Weihao You, Zhilong Ji, Guoqiang Zhong,
and Jinfeng Bai. 2024. Mumath-code: Combin-
ing tool-use large language models with multi-
perspective data augmentation for mathematical rea-
soning. Preprint , arXiv:2405.07551.
Longhui Yu, Weisen Jiang, Han Shi, Jincheng Yu,
Zhengying Liu, Yu Zhang, James T. Kwok, Zhenguo
Li, Adrian Weller, and Weiyang Liu. 2023. Meta-
math: Bootstrap your own mathematical questions
for large language models. CoRR , abs/2309.12284.
Zheng Yuan, Hongyi Yuan, Chengpeng Li, Guanting
Dong, Chuanqi Tan, and Chang Zhou. 2023. Scal-
ing relationship on learning mathematical reason-
ing with large language models. arXiv preprint
arXiv:2308.01825 .
Xiang Yue, Xingwei Qu, Ge Zhang, Yao Fu, Wen-
hao Huang, Huan Sun, Yu Su, and Wenhu Chen.
2024. MAmmoTH: Building math generalist models
through hybrid instruction tuning. In The Twelfth In-
ternational Conference on Learning Representations .
Shengyu Zhang, Linfeng Dong, Xiaoya Li, Sen Zhang,
Xiaofei Sun, Shuhe Wang, Jiwei Li, Runyi Hu, Tian-
wei Zhang, Fei Wu, et al. 2023. Instruction tuning
for large language models: A survey. arXiv preprint
arXiv:2308.10792 .
Denny Zhou, Nathanael Schärli, Le Hou, Jason Wei,
Nathan Scales, Xuezhi Wang, Dale Schuurmans,
Claire Cui, Olivier Bousquet, Quoc Le, et al. 2022.
Least-to-most prompting enables complex reason-
ing in large language models. arXiv preprint
arXiv:2205.10625 .A Prompts
In this section, we show the prompts for Problem-
Rewriter agents and training.Prompts A.1: Prompts for Problem-Rewriter Agents
You are a language expert. Your task is to rewrite the given question to make it more diverse by
rephrasing or changing the topic.
The following are several examples:
Question : Sam bought a dozen boxes, each with 30 highlighter pens inside, for $10 each
box. He rearranged five of these boxes into packages of six highlighters each and sold them for $3 per
package. He sold the rest of the highlighters separately at the rate of three pens for $2. How much
profit did he make in total, in dollars?
New Question : Sam purchased 12 boxes, each containing 30 highlighter pens, at $10 per box. He
repackaged five of these boxes into sets of six highlighters and sold them for $3 per set. He sold the
remaining highlighters individually at a rate of three pens for $2. What is the total profit he made in
dollars?
Question : A group of people went to an amusement park. 37 of them were children and 47
were adults. They split the total number of people into two groups and added 18 more people to one of
the groups. This group was then divided equally among six rides. How many people rode on each ride?
New question : A school organized a field trip to a local museum. Initially, 37 students and 47 teachers
attended. The entire group was divided into two, and then 18 volunteers joined one of the groups. This
larger group was evenly distributed across six exhibit tours. How many people were in each tour group?
Question : Express -41*c - 16*c**2 + 18*c + 25*c in the form q*c**2 + p*c + u and give
p
New question : Rewrite the polynomials -41*x - 16*x**2 + 18*x + 25*x in the form a*x**2 + b*x + c
and determine the coefficient b.
Question : What is probability of picking 1 k, 1 h, and 1 c when three letters picked without
replace- ment from {c: 1, y: 1, e: 1, n: 1, k: 1, h: 2}?
New question : What are the odds of drawing one k, one h, and one c from a collection that includes
one each of c, y, e, n, k, and two h, if three letters are chosen sequentially without putting any back?
Question: { Question }
You should keep in mind that you can not change the numbers and operators in the question.
Prompts A.2: Prompts for GPT-4 Evaluation
You are a math expert. Given a question, a reference solution, and an equation, assess whether all
components are logically consistent and correctly matched. Ensure that the question, solution, and
equation are congruent. This means that: 1) The solution should correctly answer the question. 2) The
equation should be applicable and necessary for deriving the solution. 3) All mathematical operations
and logic used in the solution should be supported by the equation.
Question: { Question }
Reference Solution: { Solution }
Equation: { Equation }
If the question, reference solution and equation all align and math correctly, please output True .
Otherwise, output False .20 40 60
Training Size (ten thousands)010203040506070Accuray49.349.9GSM8K
W.o. Rewritten
W. Rewritten
20 40 60
Training Size (ten thousands)Accuray
18.419.3GSM8K-Hard
W.o. Rewritten
W. Rewritten
20 40 60
Training Size (ten thousands)Accuray51.651.0SVAMP
W.o. Rewritten
W. Rewritten
20 40 60
Training Size (ten thousands)Accuray
18.218.9SVAMP-Hard
W.o. Rewritten
W. Rewritten
20 40 60
Training Size (ten thousands)Accuray
9.510.2MATH
W.o. Rewritten
W. Rewritten
20 40 60
Training Size (ten thousands)Accuray39.038.1Polynomials
W.o. Rewritten
W. RewrittenFigure 7: Here, we present the LLaMA 2-7B performances with including rewritten problems vs. without rewritten
problems (Ours). Here, we train the model with ControlMathQA and GSM8K.
Prompts A.3: Prompts for Fine-tuning
Below is an instruction that describes a task. Write a response that appropriately completes the
request.### Instruction: {Query} ### Response:
Problem Typs Original Problem
Rewritten ProblemsPercentage (%) Wrong Correct Total
Wrong 33.1 13.4 46.5
Correct 6.5 47 53.5
Total 39.6 60.4 100
Table 6: Confusion matrix of the proportions between rewritten and original problems in total three iterative
processes.
Augmentation GSM8K GSM8K-Hard SV AMP SV AMP-H MATH Poly. Prob.
- 42.1 11.2 35.8 7.4 4.7 5.5 21.0
w. Multi-step 47.1 16.3 47.5 15.9 6.4 9.3 21.2
w. Poly. 45.1 14.3 39.1 10.3 7.5 37.8 26.0
w. Prob. 44.3 13.7 37.5 9.7 7.3 10.1 88.1
Table 7: Ablations for different augmentation problems. Here, we train LLaMA 2-7B with our datasets and GSM8K.Methods Algebra Arithmetic Calculus Numbers Comparison Polynomials Probability MMLU-Stem Avg.
GSM8K 9.5 46.5 3.3 35.4 70.1 5.5 21.0 29.7 27.6
MetaMath 13.2 61.2 8.8 60.1 77.5 11.9 8.1 42.6 35.5
Ours 74.5 70.6 28.9 87.3 91.4 89.3 39.3 46.3 65.9
Table 8: Evaluation results in Mathematics Dataset and MMLU-Stem. Here, the models are trained on LLaMA2-7B.B Cases
Examples B.1: Several cases of our models solving Probability problems
Question : Three letters picked without replacement from y: 3, a: 1, p: 3, v: 2, c: 2, t: 2. Give prob of
sequence cca.
Answer : To find the probability of picking the sequence “cca” without replacement from the set
{y: 3, a: 1, p: 3, v: 2, c: 2, t: 2}, we calculate the probability step by step: The total number of
letters is 3 + 1 + 3 + 2 + 2 + 2 = 13 . The probability of picking “c” first is2
13since there are 2 “c”s
out of 13 letters. After picking the first “c”, there are now 12 letters left, and the probability of picking
another “c” is1
12. After picking the second “c”, there are now 11 letters left, and the probability of
picking “a” is1
11. The probability of the sequence “cca” is the product of these probabilities:
2
13×1
12×1
11=1
858
Therefore, the probability of picking the sequence “cca” without replacement is1
858. Therefore, the
answer is 1/858. ### 1/858.
Question : Two letters picked without replacement from wdwwwwwrdwrrww. Give prob of sequence dr.
Answer : To find the probability of picking the sequence “dr” without replacement from the string
“wdwwwwwrdwrrww”, we calculate as follows: The total number of letters is 14. There are 2“d”s and
3“r”s in the string. The probability of picking “d” first is2
14since there are 2“d”s out of 14letters.
After picking “d”, there are now 13letters left, and the probability of then picking “r” is3
13, as there
are3“r”s remaining. The probability of the sequence “dr” is the product of these probabilities:
2
14×3
13=3
91
Therefore, the probability of picking the sequence “dr” without replacement is3
91. Therefore, the
answer is 3/91. ### 3/91.
Examples B.2: Several cases of our models solving Polynomial problems
Question : Express -37 - f**3 + 70 + 26 as b + w*f**2 + x*f + y*f**3 and give b.
Answer : Given equation: −37−f3+ 70 + 26 Simplify the constants: −37 + 70 + 26 = 59 Therefore,
the equation can be rewritten as: 59−f3In the form b+wf2+xf+yf3, we have:
b= 59
w= 0(since there is no f2term)
x= 0(since there is no fterm)
y=−1(coefficient of f3)
Therefore, the answer is 59. ### 59.
Question : Frankie, a young scientist, is experimenting with temperature effects on a certain chemical
compound. She measures the change in energy, denoted as E, when a sample is cooled. The energy
change depends on the temperature in Fahrenheit, f, according to the equation:
E=−37−f3+ 70 + 26
Frankie records a temperature of −2Fahrenheit during one of her experiments. Calculate the energy
change for this temperature using the simplified equation.Answer : Substituting f=−2into the simplified equation:
E=−(−2)3+ 59 = −(−8) + 59 = 8 + 59 = 67
The energy change at f=−2Fahrenheit is 67units. Therefore the answer is 67 ###67.
Examples B.3: Several cases of our models solving GSM8K/GSM8K-Hard problems
Question : Susan made 100 cookies for Christmas and was going to equally divide them between her 6
nephews. Before Susan could package them, her husband snuck 4 cookies for himself. How many
cookies will each of Susan’s nephews get?
Answer : Susan made 100 cookies in total.Her husband snuck 4 cookies for himself, so there are «100 -
4 = 96» cookies left.Susan wants to divide these cookies equally between her 6 nephews.To find out
how many cookies each nephew will get, we divide the total number of cookies by the number of
nephews: «96 / 6 = 16». Each of Susan’s nephews will get 16 cookies. Therefore, the answer is 16.
### 16.
Question : Siobhan has 2 fewer jewels than Aaron. Aaron has 5 more jewels than half of Raymond’s
jewels. If Raymond has 973054 jewels, how many jewels does Siobhan have?
Answer : We know that Raymond has 973054 jewels.Half of Raymond’s jewels is «973054/2 = 486527»
jewels.Aaron has 5 more jewels than half of Raymond’s jewels, so Aaron has «486527 + 5 = 486532»
jewels.Siobhan has 2 fewer jewels than Aaron, so Siobhan has «486532 - 2 = 486530» jewels.Therefore,
Siobhan has 486530 jewels. Therefore, the answer is 486530. ###486530.