Voices in a Crowd: Searching for Clusters of Unique Perspectives
Nikolas Vitsakis†
Heriot-Watt University
nv2006@hw.ac.ukAmit Parekh†
Heriot-Watt University
amit.parekh@hw.ac.ukIoannis Konstas
Heriot-Watt University
i.konstas@hw.ac.uk
Abstract
Language models have been shown to repro-
duce underlying biases existing in their train-
ing data, which is the majority perspective by
default. Proposed solutions aim to capture mi-
nority perspectives by either modelling annota-
tor disagreements or grouping annotators based
on shared metadata, both of which face sig-
nificant challenges. We propose a framework
that trains models without encoding annotator
metadata, extracts latent embeddings informed
by annotator behaviour, and creates clusters
of similar opinions, that we refer to as voices .
Resulting clusters are validated post-hoc via in-
ternal and external quantitative metrics, as well
a qualitative analysis to identify the type of
voice that each cluster represents. Our results
demonstrate the strong generalisation capabil-
ity of our framework, indicated by resulting
clusters being adequately robust, while also
capturing minority perspectives based on dif-
ferent demographic factors throughout two dis-
tinct datasets.1
Content Warning: This document contains
and discusses examples of potentially offensive
and toxic language.
1 Introduction
Supervised training is rooted in the presupposi-
tion that every example in a dataset has a single
ground truth, also known as the gold label (Hetti-
achchi et al., 2021). However, disagreement among
dataset annotators challenges the notion that a sin-
gle, per-example, ground truth exists (Uma et al.,
2022, 2021b). While disagreement can be indica-
tive of task difficulty or semantic ambiguity (Jiang
and Marneffe, 2022; Sandri et al., 2023; Wang et al.,
2021), it can also indicate the existence of both
stable andconflicting inter-annotator perspectives
(Abercrombie et al., 2023; Basile et al., 2020).
Nevertheless, capturing minority perspectives
present in the data, which we parallel to voices
†Equal contribution
1All code is made available at https://github.com/
Ni-Vi/Cluster .in a crowd , has proven challenging. Two main
approaches attempt to move beyond gold labels:
i) disagreement-based which leverage annotator
disagreement to provide distributional per-item pre-
diction labels (Leonardelli et al., 2023; Uma et al.,
2022, 2021b), and ii) metadata-based , which en-
code annotator metadata to boost the signal from
voices with the same metadata labels (Beck et al.,
2023; Fleisig et al., 2023; Gupta et al., 2023) (i and
ii respectively in Figure 1).
However, both approaches come with strong vul-
nerabilities. Disagreement-based approaches col-
lapse multiple minority voices into a singular, per-
item, minority-majority distribution (Gordon et al.,
2022), essentially limiting the number of expressed
voices to the number of predicted labels (i.e., two
voices in a binary prediction task). On the other
hand, while metadata-based approaches allow for
multiple minority voices to be expressed (albeit
limited by metadata collected), they are based on
the erroneous assumption that most members that
share metadata labels (e.g., gendered females) will
also exhibit similar patterns of behaviour (Beck
et al., 2023; Dang et al., 2020).
We introduce a framework that addresses both
issues (Figure 1iii): it forms multiple clusters of dis-
tinct voices solely based on annotator behaviours
exhibited during the annotation process in an un-
supervised manner. Our pipeline trains models to
predict each annotation made by each annotator
for a given text input.
The final hidden states form what we refer to as
behavioural embeddings , representing how a given
annotator will behave when shown that text sample,
are then clustered via unsupervised methods. We
define each created cluster as a potential voice —a
group perspective of annotators with similar anno-
tating behaviours.
We apply our framework to two datasets related
to political bias that have been found to contain
multiple heterogeneous and conflicting perspec-
tives (Chen et al., 2019; de Zarate et al., 2020;
Menini and Tonelli, 2016; Németh, 2023). To iden-arXiv:2407.14259v1  [cs.CL]  19 Jul 2024Figure 1: Different approaches for handling annotations: i) disagreement-based create per-example distributional
labels which fail to account for dataset-level effects; ii) metadata-based train models on annotations linked with
annotator metadata, which often groups disagreeing annotators who share metadata labels; iii) the “Voices in a
crowd” approach dynamically creates clusters based on annotation patterns and finally verifies each cluster as a
voice based on post-hoc matched metadata labels.
tify the group whose voice each cluster belongs
to, we match each data point with annotator meta-
data post-hoc while we also conduct an in-depth
qualitative analysis of the clusters themselves. The
resulting clusters show high internal label consis-
tency of either i) dataset majority labels (e.g.,
left-leaning in a left-leaning majority dataset), ii)
dataset minority labels (e.g., right-leaning in a
left-leaning majority dataset), but most importantlytheir intersection resulting in iii) inter-minority
labels (e.g., right-leaning and highly educated, in a
left-leaning, non-highly educated majority dataset).
We are the first to dynamically identify voices of
minority opinions within larger majority/minority
groups, highlighting the significance of providing
an intersectional understanding of annotators that
goes beyond current grouping methodologies.2 Related Work
Disagreement-Based Solutions As an alterna-
tive to gold labels, recent research has introduced
the use of silver labels, i.e., distributional per-item
labels that measure disagreement amongst anno-
tators (Leonardelli et al., 2023; Uma et al., 2022,
2021b). While such approaches allow for the iden-
tification of controversial examples in datasets (For-
naciari et al., 2022), they fail to capture stable inter-
annotator disagreements throughout the dataset that
could provide insight as to why disagreement oc-
curs beyond an item-by-item scale (Abercrombie
et al., 2023; Vitsakis et al., 2023).
To be more specific, disagreement-based solu-
tions essentially limit the number of possible ex-
pressed voices into the number of predicted labels;
the upper bound of possible voices expressed in a
binary task is always two, no matter how diverse
the dataset. Unfortunately, this type of aggregation
leads to the erasure of what we define as inter-
minority voices : stable opinions held by minority
groups that are in conflict with each other as well
as the majority, across examples.
Metadata-Based Solutions A recent trend aim-
ing to capture diverse perspectives has attempted
to group annotators based on their metadata. Such
approaches encode collected annotator metadata,
such as annotator beliefs (Davani et al., 2023;
Röttger et al., 2021) or demographics (Fleisig et al.,
2023; Gupta et al., 2023), into the training pipeline
to allow learning of patterns between annotations
and in-group tendencies. While the incorpora-
tion of such information can seemingly improve
model performance in specific tasks (Welch et al.,
2020), evidence suggests that such results might be
dataset-specific (Lee et al., 2023).
This is due to the assumption that annotators
sharing metadata labels will behave similarly dur-
ing the annotation process. However, demograph-
ics are not necessarily predictive of underlying be-
haviour (Beck et al., 2023; Hwang et al., 2023),
while social sciences have also explained similar
issues with self-reported measures (Dang et al.,
2020; Schwarz, 1999). With the added issue that
annotator metadata is often not collected outright
(Prabhakaran et al., 2021), there is a direct need for
methodologies that identify distinct group voices
based on factors other than a-priori collected labels.
Unsupervised Learning and Clusters of Voices
To circumvent previously mentioned issues, un-supervised learning could be employed along the
lines of how past research identified emergent
themes within corpora via clustering of latent tex-
tual embeddings (Dhillon and Modha, 2001; Meng
et al., 2022; Sevillano et al., 2007). Recently, Meng
et al. (2022) showed promising results in auto-
matic topic discovery by utilising pretrained lan-
guage models to cluster representations in a joint
latent space : formed by combining latent spaces
of multiple modalities during learning, in this case
word and document level embeddings. We aim to
take this work further through our use of joint be-
havioural embeddings, informed by both text and
annotating behaviour, to automatically find voices ,
i.e., clusters of similar opinions.
There are significant challenges to this ap-
proach. Fine-tuning pretrained language model
embeddings produce embeddings that are often
anisotropic and anisometric (Rajaee and Pilehvar,
2021; Xu and Koehn, 2021); when paired with their
high dimensionality nature, clustering via distance-
based metrics is challenging. By using appropriate
dimensionality reductions (Cai et al., 2020; Mu
et al., 2017), the relationships between features
can be analysed and clustered through Euclidean
distance-based metrics (McInnes et al., 2018).
3 Experimental Setup
Our framework comprises a supervised and an
unsupervised component . The former produces
latent embeddings informed by both text and anno-
tating behaviour that the latter uses to cluster into
voices. Being the first such approach, we compared
performance across a variety of transformer-based
architectures, clustering, and dimensionality reduc-
tion techniques to identify optimal combinations.
The supervised component explores several
modelling choices (Section 4) fine-tuned on each
dataset to predict each annotator’s individual an-
notation for a given example without providing
any annotator metadata that could bias the model
(Vitsakis et al., 2023). The unsupervised compo-
nent then performs dimensionality reduction on the
behavioural embeddings —the final hidden states
from the supervised component—and finally cre-
ates clusters via several unsupervised algorithms
(Section 5). Clusters are evaluated through internal
(i.e., intra-cluster similarity) and external metrics
(i.e., consistency of demographic labels in a given
cluster), and via qualitative analysis of the best-
performing combination of components.3.1 Datasets
All datasets used in our experiments contain the fol-
lowing annotator demographics: personal political
leaning, age, and education level.
Media Bias Annotation Dataset (MBIC;
Spinde et al., 2021a,b) comprises sentences from
media articles that may contain political bias from
news outlets across the political spectrum (e.g., Fox
News, MSNBC, etc.) covering 14 potentially di-
visive topics (e.g., gender issues, coronavirus, the
2020 American election). 784 crowd-sourced anno-
tators labelled sentences on whether they consider
them to contain bias. Demographics were slightly
skewed in political ideology (44.3% left-leaning,
26.7% right-leaning, 29.1% center).
Global Warming Stance Dataset (GWSD; Luo
et al., 2020) contains opinions of varying intensities
on the subject of global warming, gathered from
news outlets with different political leanings (e.g.,
The New York Times, Breitbart). 398 annotators
labelled each sentence with whether they agreed,
disagreed, or were neutral. Demographic skew of
this dataset mirrored that of MBIC in self-reported
political affiliation (46% Democrat, 21.2% Repub-
lican, 28.8% Independent, 4% Other).
4 Supervised Component
Each of the following modelling architectures was
trained through a different combination of inputs
(visual representation in Appendix B): given a text
sample in a dataset, x∈X, we predict the indi-
vidual annotation of each annotator pθ(y|x)where
y= (y1, . . . , y K)andKis the total number of
unique annotators within the dataset.
Unpooled Cross Attention uses a pretrained T5
encoder (Raffel et al., 2020) where the encoded
text and the embedded annotator unique identifiers
are fed through a decoder to predict each annota-
tor’s annotation as a sequence. Annotator embed-
dings are directly informed by the text via a cross-
attention layer aiming to capture the influence of
the text in the annotators’ behaviours.
Pooled Cross Attention follows Sullivan et al.
(2023), which showed strong performance in pre-
dicting annotator disagreement in the 2023 Learn-
ing With Disagreements shared task (LeWiDi;
Leonardelli et al., 2023). This model is similar in
structure to Unpooled Cross Attention since it also
uses a T5 encoder as the backbone. However, the
dimension for each encoded text token is downsam-
pled, as previous research has indicated possibleF1 Score ↑ APCS ↓
GWSD Dataset
Unpooled Cross Attention 0.65 0.14± 0.07
Pooled Cross Attention 0.19 0.54± 0.13
Encoder-Encoder 0.63 0.15± 0.11
Classifier Model 0.63 0.81± 0.14
Pretrained Decoder 0.62 0.66± 0.08
Pretrained Encoder-Decoder 0.19 0.95± 0.02
MBIC Dataset
Unpooled Cross Attention 0.72 0.22± 0.05
Pooled Cross Attention 0.43 0.70± 0.06
Encoder-Encoder 0.72 0.21± 0.06
Classifier 0.38 1.00
Pretrained Decoder 0.63 0.75± 0.07
Pretrained Encoder-Decoder 0.71 0.74± 0.25
Table 1: Overall performance (F1 Score) for the su-
pervised component of our framework (6 modelling
architectures) on MBIC and GWSD for the task of indi-
vidual annotator prediction. We also report the Average
Pairwise Cosine Similarity (APCS) across the final hid-
den states; a lower score indicates greater variety in
representation which correlates with better clustering
performance.
benefits in the salience of encoded features (Dhin-
gra et al., 2018; Holzenberger et al., 2018; Schick
and Schütze, 2019). Finally, decoder outputs are
pooled (Reimers and Gurevych, 2019) to predict
an aggregated annotation for each batch.
Encoder-Encoder treats text and annotators as sep-
arate modalities, inspired by vision and language
models (Agarwal et al., 2020; Singh et al., 2022;
Tan and Bansal, 2019). The encoded text (using
T5) and embedded annotator IDs are concatenated
and fed through a bidirectional encoder to predict
the annotation of each annotator, allowing for inter-
action between text and annotator embeddings.
Classifier Model simply concatenates the text with
the unique annotator identifier, before passing to
an encoder (BERT; Devlin et al., 2018 for GWSD,
and RoBERTa; Liu et al., 2019 for MBIC) to pre-
dict each annotation label independently. The in-
dependence between annotators limits interaction
between annotators during training.
Pretrained Decoder is a decoder-only GPT-2
model (Radford et al., 2019) prompted with the con-
catenated text and annotator identifiers in the form
“<text> [SEP] <Ann 1> [SEP] ... <Ann K> ”
and predicts the annotation for each annotator.
Pretrained Encoder-Decoder is similar to Un-
pooled Cross Attention . It uses a pretrained T5encoder-decoder instead; the only difference is
that the unique annotator identifiers are embedded
through the decoder of the T5 model itself—instead
of a decoder trained from scratch—to predict each
annotator’s annotation autoregressively. The de-
coder is unidirectional, forcing casual attention be-
tween annotators in their canonical order. It is
limited compared to the Encoder-Encoder , despite
using cross-attention.
Metrics We compute F1 score to measure the
accuracy of predictions, and Average Pairwise Co-
sine Similarity (APCS) between hidden states of
predicted annotations to illustrate how dense the
latent states are by the end of training; we show
that lower scores generally correlate with better
clustering performance (see Section 5.1).
Results Table 1 summarises the results. For
GWSD, Unpooled Cross Attention achieved the
highest F1 score and lowest APCS, whereas
it shared a similar performance with Encoder-
Encoder for MBIC (albeit the latter has slightly
lower APCS). This could be down to the bidirec-
tional attention mechanism (either through cross-
attention or encoder self-attention) between the
annotator embeddings and the text during training.
These results also showcase the importance of
reporting on the quality of the hidden states. For ex-
ample, while the Pretrained Encoder-Decoder and
Classifier Model have high F1 scores on the MBIC
and GWSD datasets respectively, their low scores
on APCS indicate dense hidden states that would
result in poor clustering outcomes. Overall, our
findings show that the bidirectional attention-based
models that allow interaction between text and an-
notator embeddings are the only consistent archi-
tectures to show high F1 and low APCS scores.
5 Unsupervised Component
Dimensionality Reduction We perform dimen-
sionality reduction on the hidden states before
clustering as follows: a baseline without dimen-
sionality reduction, Principal Component Analysis
(PCA; a linear combination of components) and
Uniform Manifold Approximation and Projection
for Dimension Reduction (UMAP; a non-linear
transformation algorithm; McInnes et al., 2018).
Both PCA (Gupta et al., 2019; Sia et al., 2020)
and UMAP (Ait-Saada and Nadif, 2023; Cai et al.,
2020; George and Sumathy, 2023) improve feature
representation in high-dimensional latent spacesleading to improved clustering.
Clustering Algorithms We used three cluster-
ing techniques: K-means (MacQueen et al., 1967;
Pedregosa et al., 2011), Gaussian Mixture Mod-
els (GMM; Rasmussen, 1999), and HDBSCAN
(McInnes et al., 2017). Each of these techniques
have been used to cluster features when paired with
either PCA (Asyaky and Mandala, 2021; Hosseini
and Varzaneh, 2022; Liu et al., 2021), or UMAP
(Allaoui et al., 2020; Asyaky and Mandala, 2021).
Metrics We use two internal validation met-
rics to assess average similarity scores between
clusters, namely Silhouette (Pedregosa et al.,
2011; Rousseeuw, 1987) and Davies-Bouldin Index
(Davies and Bouldin, 1979; Pedregosa et al., 2011).
Silhouette assesses intra-cluster separation and is
bound between -1 and 1, with 1 being the best pos-
sible score, with a threshold of 0.5 for moderate
clusters (Lengyel and Botta-Dukát, 2019; Shaha-
pure and Nicholas, 2020). The Davies-Bouldin
Index measures intra-cluster dissimilarity, with 0
indicating the lowest possible score (Idrus, 2022;
Kärkkäinen and Fränti, 2000).
We use Purity to assess the external validity
of clusters. Purity measures the internal consis-
tency of assigned labels within a cluster and eval-
uates whether a cluster is prototypical (i.e., repre-
sentative) across provided labels within a dataset
(Christodoulopoulos et al., 2010). In our case,
we report both average purity and the percentage
of prototypical clusters per method. We define a
cluster as prototypical if its metadata label purity
(i.e., political leaning and education level) is signif-
icantly different from the original dataset metadata
label distribution with a threshold of ±10%. These
metrics allow us to automatically assess whether
a cluster emerging from annotator behaviours dur-
ing training is linked to any of the annotator labels
(e.g., a cluster with high right-leaning metadata la-
bel purity) and thus is indicative of a distinct voice.
5.1 Results
Optimal cluster numbers were automatically cal-
culated using hyperparameter sweeps to maximise
the Silhouette score (see Appendix A for more in-
formation). Table 2 shows the clustering of our best
performance combination, K-means with a UMAP
dimensionality reduction on the MBIC dataset as
other configurations performed less optimally as
seen in Appendix C.Purity ↑ Prototypical Cluster % ↑
# Clusters DB Index ↓Silhouette ↑Political Education Political Education
Unpooled Cross Attention
No dim. reduction 19 6.35 0.02 0.71 0.71 15.8 0.0
w/ PCA 10 1.98 0.10 0.36 0.43 20.0 0.0
w/ UMAP 19 0.81 0.47 0.38 0.42 31.6 5.3
Pooled Cross Attention
No dim. reduction 19 3.03 0.06 0.42 0.48 26.0 5.3
w/ PCA 19 1.04 0.28 0.47 0.46 5.5 0.0
w/ UMAP 12 1.13 0.29 0.70 0.50 25.0 8.0
Encoder-Encoder
No dim. reduction 19 6.93 0.01 0.41 0.46 21.1 15.8
w/ PCA 19 0.49 0.54 0.53 0.43 15.0 7.7
w/ UMAP 19 0.49 0.53 0.51 0.48 36.8 21.1
Classifier Model
No dim. reduction 5 1.98 0.06 0.49 0.44 0.0 0.0
w/ PCA 13 0.84 0.36 0.44 0.44 7.4 0.0
w/ UMAP 18 0.55 0.49 0.44 0.49 5.5 5.5
Pretrained Decoder
No dim. reduction 19 2.76 0.06 0.39 0.42 16.0 11.1
w/ PCA 18 1.89 0.12 0.44 0.61 5.6 5.6
w/ UMAP 19 1.01 0.34 0.36 0.42 11.0 11.0
Pretrained Encoder-Decoder
No dim. reduction 5 1.62 0.16 0.44 0.48 0.0 0.0
w/ PCA 8 1.74 0.20 0.37 0.46 0.0 0.0
w/ UMAP 5 0.75 0.44 0.46 0.46 0.0 0.0
Table 2: Internal and external validation metrics for the unsupervised component with the K-Means clustering
algorithm on the MBIC dataset . Internal validation metrics explain intra-cluster separation through higher
Silhouette and lower Davies-Bouldin (DB Index) scores. External validity indicates the potential capturing of a
voice, measured by the average Purity score and % of prototypical clusters.
Internal Validity Metrics Overall, dimensional-
ity reduction significantly impacted the quality of
the resulting clusters; UMAP consistently outper-
formed PCA throughout, while no dimensionality
reduction showed the worst overall results (for av-
erages, see Appendix A.2). The only exception was
Encoder-Encoder, where PCA and UMAP perform
comparably.
Encoder-Encoder performed best overall: be-
ing the only model with Silhouette and Davies-
Boulding Index scores above/below the respec-
tive cutoff points of 0.5, indicating adequate intra-
cluster separation for both metrics (Idrus, 2022;
Lengyel and Botta-Dukát, 2019; Shahapure and
Nicholas, 2020). Interestingly, the Classifier Model
also performed relatively well despite being the
lowest-performing of the supervised component.
External Validity Metrics Average purity scores
are largely inconclusive, as higher scores are notalways linked with better performance as indicated
by any other evaluative metric. For example, Un-
pooled Cross Attention with no dimensionality re-
duction, scores poorly on internal validation met-
rics, while average purity is the highest across both
metadata labels.
Overall, these findings echo those seen in Ta-
ble 1, where models with the lowest APCS scores
also had the best performance in internal and ex-
ternal validation metrics. The best-performing
model was Encoder-Encoder with UMAP outper-
forming PCA, followed by Unpooled Cross Atten-
tion. While UMAP only marginally outperformed
PCA in terms of internal validation scores, the la-
bel distributions in the clusters resulting from PCA
were minimally different when compared to label
distributions present in the original data. Finally,
we found that prototypical clustering percentage
was a strong indicator of capturing representative
clusters of voices.Dataset/Cluster No. Examples Bias Label Distribution
MBIC -1British Olympic swimmer Sharron Davies also slammed the concept of transgender athletes. ✓
BBC Presenter Gabby Logan has said that it is not fair that transgender women can compete in sport
alongside biologically female women.✓
BBC Presenter Gabby Logan has said that it is not fair that transgender women can compete in sport
alongside biologically female women.✗
MBIC -7Trump — who has been criticized for painting an overly rosy picture of the outbreak, often contradicting
his own health officials - insisted on Friday that his administration was “magnificently organized” and
“totally prepared" to address the virus.✓
Google declined to offer details beyond Huntley’s tweets, but the unusually public attribution is a sign
of how sensitive Americans have become to digital espionage efforts aimed at political campaigns.✗
At least 25 transgender or gender-nonconforming people were killed in violent attacks in the United
States last year, according to the Human Rights Campaign, which has been tracking anti-trans violence
since at least 2015.✓
Though conservatives try to demonize Ocasio-Cortez an Omar, their actual policy views are perfectly
mainstream. The New York lawmaker proposed a 70 percent tax on top incomes — a view backed by
public opinion and many well-respected economists.✗
MBIC -8 British Olympic swimmer Sharron Davies also slammed the concept of transgender athletes. ✗
At least 25 transgender or gender-nonconforming people were killed in violent attacks in the United
States last year, according to the Human Rights Campaign, which has been tracking anti-trans violence
since at least 2015.✓
Table 3: Analysis of clusters on the MBIC dataset with the Encoder-Encoder architecture and UMAP dimensionality
reduction. We report the cluster number, representative examples of the cluster, and their paired annotation ( ✓
for perceived bias, ✗for no perceived bias). We also show the distribution of annotator characteristics which is
indicative of the prototypical nature of each cluster.
Manual inspection of PCA-formed clusters in-
dicated that clusters formation was mostly based
around the most salient features discovered during
training, namely the unique annotator tokens or the
inter-sentence similarities. A possible reason for
this phenomenon could be that PCA reduces dimen-
sionalities to the most salient principal components,
which are not conducive to clustering based on con-
textual features in large language models (Cai et al.,
2020). Interestingly, this phenomenon was repro-
duced with UMAP when instructing the model to
focus on finding clusters based on local and not
overarching features (McInnes et al., 2018).2
6 Qualitative case study
While encouraging, our findings cannot be sim-
ply explained through either internal or external
validation metrics; to assess whether a cluster is
truly indicative of a voice, we looked at the content
of the clusters themselves. High label purity of a
cluster should be reflected in the text-annotation
pair content (i.e., high left-leaning purity should
be paired with left-leaning opinions). Given our la-
bels, this can result in three distinct types of voices:
majority, minority and inter-minority.
2A possible solution to this issue is to remove the top
principal components resulting in more salient representations,
and thus improve clustering performance (Mu et al., 2017);
we leave this for future work.Majority voice clusters consist of high purity of a
majority metadata label (e.g., left-leaning opinions
in a left-leaning majority dataset), while minority
voices are the same for dataset minority labels (e.g.,
right-leaning opinions in a left-leaning majority
dataset), and inter-minority voices, which are clus-
ters that consist of high purity across combination
of metadata labels (e.g., high purity in both right-
leaning and highly educated metadata labels in a
dataset with left-leaning and non-highly educated
majority metadata labels.
To extract our clusters, we used the best-
performing combination, i.e., Encoder-Encoder
with UMAP and K-means clustering. We pick three
prototypical clusters out of a single clustering run,
each representing a distinct voice, and discuss them
in Table 3 and Table 4.
6.1 MBIC Dataset
MBIC-1 / Minority Voice This cluster is a proto-
typical example of minority-led consensus amongst
annotators. The cluster’s distribution is more
even, following the original label distribution closer
(44.3%, 29.1%, 26.7% for left, center, and right po-
litical lean). Such clusters often contain different
annotations for the same sentences, while there is
no strong emerging effect from collected labels.
MBIC-7 / Minority voice This is a minority
voice, with the distribution of labels indicatingDataset/Cluster No. Examples Agreement Label Distribution
GWSD -9The early 21st-century drought that afflicted Central Asia is the worst in Mongolia in more than
1,000 years, and made harsher by the higher temperatures consistent with man-made global
warming.✓
Climate change means the end of shopping. ∼
The oil sands are responsible for just 0.001 percent of global greenhouse emissions ∼
GWSD -2There is a connection between human activity and an assumptive change in global climate. ✓
Hiring a White House "climate change czar" would be a good idea. ✓
Scaring young people into believing that climate change is going to kill young people is child
abuse.✗
GWSD -5The oil sands are responsible for just 0.001 percent of global greenhouse emissions ✓
This could mean that current I.P.C.C. model predictions for the next century are wrong, and
there will be no cooling in the North Atlantic to partially offset the effects of global climate
change over North America and Europe.✓
Eco-towns could provide an inspiring blueprint for low-carbon living ✗
Table 4: Analysis of clusters on the GWSD dataset using same parameters as the MBIC dataset, and results are
shown in a similar fashion ( ✓agree with the statement, ✗for disagree and ∼for neutral). Distribution of annotator
characteristics is provided.
that the cluster is primarily formed of right-leaning
opinions. While Item 1 is expectantly labelled as
‘bias’, Item 3 contains no obvious biased words,
despite coming from an obvious place of concern
for a marginalised minority.
MBIC-8 / Majority voice This is an example
of a majority dominant cluster. Such clusters are
populated by the opinion of the original dataset’s
distributional majority label although with a much
heavier skew, indicating a stable and consistent be-
haviour of the group. The labelling distribution
of this cluster is expected to be populated by left-
leaning views and indeed sentences that were previ-
ously labelled as biased in non-left-leaning clusters
(Item 1 of Cluster 1, and Item 3 of Cluster 7), were
consistently found not to be labelled as such.
6.2 GWSD Dataset
GWSD-9 / Minority voice This is an example of
a minority cluster, as indicated by the differences
in the distribution of the minority label between the
cluster and the original data (21% in the original
data, 60% representation in this cluster). While the
expressed opinions within were generally agreeable
about climate-changing effects, there was no agree-
ment with more politically charged statements.
GWSD-2 / Majority voice This is a majority-
dominant cluster. Opinions that could be perceived
as more political were found to be more common
(Item 2), while there was also evidence of general
agreement with some strongly politically charged
examples (Item 3).GWSD-5 / Minority-Minority voice An exam-
ple of a minority within a minority perspective.
Opinions are over-represented by two minority la-
bels, the “republican” in terms of political affilia-
tion, and that of the “higher degree” in terms of
education level (8.4% label representation in the
original dataset). Opinions showed fewer “neutral”
responses and were generally indicative of a well-
informed audience, explicitly agreeing with more
technical items such as Item 2 and especially Item
1, which received mostly “neutral” scores in other
clusters (e.g., Cluster 9).
7 Conclusion
We propose a novel framework to identify underly-
ing minority perspectives in data. We compared six
distinct model architectures trained on a classifi-
cation task, without providing any annotator meta-
data to avoid biasing their training. Subsequently,
final hidden states were passed through various
methods of dimensionality reduction (UMAP and
PCA), with the resulting embeddings used to create
clusters through various unsupervised algorithms
(K-means, GMM, and HDBSCAN).
The resulting clusters were adequately separated
according to internal and external validation met-
rics. Further qualitative analysis of clusters pro-
duced by our best-performing model showcased
the ability of our framework to capture perspectives
as shown by three distinct types: clusters represen-
tative of a minority, a majority, and clusters that
captured multiple minority labels, i.e., a minority
within a minority.Limitations & Ethical Considerations
Internal & External Validity Related As shown
in Table 2 and Appendix C while internal validation
scores canbe indicative of well-defined clusters
of minority perspectives, they are not necessarily
so. We explained in Appendix C, this might be
due to our training on unique annotator tokens,
which might hinder organic clustering based on
behaviour, by providing an alternative and easier
to learn signal in unique annotator tokens.
We aim to expand upon this in future work, by
modifying training of our supervised component to
incorporate aspects more representative of group
behaviours such as inter and intra annotator dis-
agreement (Abercrombie et al., 2023; Leonardelli
et al., 2023; Uma et al., 2021a,b). This would
expand upon limitations of disagreement-bases
approaches described in Section 2, by enabling
group behavioural signals, as indicated by anno-
tator agreement / disagreement, to be captured on
the dataset-level. Furthermore, incorporation of
such methodologies into our framework would fur-
ther expand upon the limitations of disagreement-
based methodologies by allowing for any number
of voices to be expressed.
Automatic Detection of Voices A current limita-
tion of the framework is the ability to automatically
assess the performance of each combination with-
out manual inspection. While necessary at this
step to prove the efficacy of our framework, we
aim to expand this in future work by introducing a
a component that automatically extracts informa-
tion from each cluster to allow for identification of
voice without the need of matching clusters with
metadata labels post hoc.
We aim to employ a similar methodology to
Fleisig et al. (2023), whose pipeline includes a
GPT-2 based component that predicts the demo-
graphic group targeted by a given text. We aim to
include similar components to extrapolate attitudi-
nal and behavioural indicators of formed clusters
via analysing the text-annotation pairs to generate
labels representative of each captured voice simi-
larly to how research in sentiment analysis, has pre-
viously classified opinions on politically charged
data (Ansari et al., 2020; Dorle and Pise, 2018;
Kazienko et al., 2023).
Labels and further marginalisation of minori-
ties Our model uses labels procured during data
gathering to validate emergent clusters. However,the labelling gathering process can potentially be
an erasing process towards minorities in and of
itself (Chandrabose et al., 2021; Hovy and Prabhu-
moye, 2021). For example, the labelling process
can discriminate against socially marginalised mi-
norities by not providing options consistent with
an individual’s identity (Chandrabose et al., 2021;
Jo and Gebru, 2020).
In our case, we encountered this limitation with
the GWSD dataset (Luo et al., 2020), which col-
lected categorical labels about political affiliation
of participants. Beyond the three primary labels
("Democrat", "Independent", "Republican"), the
rest were aggregated into the "other" label. This
resulted in a minority so small that our clustering
methodology could not adequately disentangle it
from the rest. Directions aimed towards future re-
search as explained in Section 7 should address
these concerns for future iterations of our frame-
work.
Dual Use of the Model An unfortunate outcome
of methodologies aim to capture and expressed
more nuanced perspectives can lead to identifi-
cation of marginalised minority perspectives in
datasets, which can lead to concerning practice
of their removal in order to enhance a model’s gen-
eral performance (Sun et al., 2019; Xu et al., 2021).
Nevertheless, Gaci et al. (2023) has also proposed
that methodologies that identify minority perspec-
tives can be used to curate datasets in order to am-
plify voices of specific marginalised groups.
We urge researchers to be transparent in their
indented use of our framework, and to follow eth-
ical frameworks and solutions that have been pre-
viously highlighted by the field in from the data
collection process to model training and intended
use (Blodgett et al., 2020; Hovy and Prabhumoye,
2021; Leidner and Plachouras, 2017; Navigli et al.,
2023; Shmueli et al., 2021).
References
Gavin Abercrombie, Verena Rieser, and Dirk Hovy.
2023. Consistency is key: Disentangling
label variation in natural language processing
with intra-annotator agreement. arXiv preprint
arXiv:2301.10684 .
Shubham Agarwal, Trung Bui, Joon-Young Lee, Ioan-
nis Konstas, and Verena Rieser. 2020. History for
visual dialog: Do we really need it? arXiv preprint
arXiv:2005.07493 .Mira Ait-Saada and Mohamed Nadif. 2023. Is
anisotropy truly harmful? a case study on text cluster-
ing. In Proceedings of the 61st Annual Meeting of the
Association for Computational Linguistics (Volume
2: Short Papers) , pages 1194–1203.
Mebarka Allaoui, Mohammed Lamine Kherfi, and Ab-
delhakim Cheriet. 2020. Considerably improving
clustering algorithms using umap dimensionality re-
duction technique: A comparative study. In Inter-
national conference on image and signal processing ,
pages 317–325. Springer.
Mohd Zeeshan Ansari, Mohd-Bilal Aziz, MO Siddiqui,
H Mehra, and KP Singh. 2020. Analysis of political
sentiment orientations on twitter. Procedia Computer
Science , 167:1821–1828.
Muhammad Sidik Asyaky and Rila Mandala. 2021.
Improving the performance of hdbscan on short
text clustering by using word embedding and umap.
In2021 8th international conference on advanced
informatics: Concepts, theory and applications
(ICAICTA) , pages 1–6. IEEE.
Valerio Basile et al. 2020. It’s the end of the gold stan-
dard as we know it. on the impact of pre-aggregation
on the evaluation of highly subjective tasks. In CEUR
WORKSHOP PROCEEDINGS , volume 2776, pages
31–40. CEUR-WS.
Tilman Beck, Hendrik Schuff, Anne Lauscher, and Iryna
Gurevych. 2023. How (not) to use sociodemographic
information for subjective nlp tasks. arXiv preprint
arXiv:2309.07034 .
Tilman Beck, Hendrik Schuff, Anne Lauscher, and Iryna
Gurevych. 2023. Sensitivity, Performance, Robust-
ness: Deconstructing the Effect of Sociodemographic
Prompting. arXiv e-prints , page arXiv:2309.07034.
Su Lin Blodgett, Solon Barocas, Hal Daumé III, and
Hanna Wallach. 2020. Language (technology) is
power: A critical survey of “bias” in NLP. In Pro-
ceedings of the 58th Annual Meeting of the Asso-
ciation for Computational Linguistics , pages 5454–
5476, Online. Association for Computational Lin-
guistics.
Xingyu Cai, Jiaji Huang, Yuchen Bian, and Kenneth
Church. 2020. Isotropy in the contextual embedding
space: Clusters and manifolds. In International Con-
ference on Learning Representations .
Aravindan Chandrabose, Bharathi Raja Chakravarthi,
et al. 2021. An overview of fairness in data–
illuminating the bias in data pipeline. In Proceedings
of the First Workshop on Language Technology for
Equality, Diversity and Inclusion , pages 34–45.
Sihao Chen, Daniel Khashabi, Wenpeng Yin, Chris
Callison-Burch, and Dan Roth. 2019. Seeing things
from a different angle: Discovering diverse perspec-
tives about claims. arXiv preprint arXiv:1906.03538 .Christos Christodoulopoulos, Sharon Goldwater, and
Mark Steedman. 2010. Two decades of unsupervised
pos induction: How far have we come? In Proceed-
ings of the 2010 Conference on Empirical Methods
in Natural Language Processing , pages 575–584.
Junhua Dang, Kevin M King, and Michael Inzlicht.
2020. Why are self-report and behavioral measures
weakly correlated? Trends in cognitive sciences ,
24(4):267–269.
Aida Mostafazadeh Davani, Mohammad Atari, Bren-
dan Kennedy, and Morteza Dehghani. 2023. Hate
speech classifiers learn normative social stereotypes.
Transactions of the Association for Computational
Linguistics , 11:300–319.
David L Davies and Donald W Bouldin. 1979. A cluster
separation measure. IEEE transactions on pattern
analysis and machine intelligence , (2):224–227.
Juan Manuel Ortiz de Zarate, Marco Di Giovanni, Este-
ban Zindel Feuerstein, and Marco Brambilla. 2020.
Measuring controversy in social networks through
nlp. In International Symposium on String Pro-
cessing and Information Retrieval , pages 194–209.
Springer.
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and
Kristina Toutanova. 2018. BERT: pre-training of
deep bidirectional transformers for language under-
standing. CoRR , abs/1810.04805.
Inderjit S Dhillon and Dharmendra S Modha. 2001.
Concept decompositions for large sparse text data
using clustering. Machine learning , 42:143–175.
Bhuwan Dhingra, Christopher J Shallue, Mohammad
Norouzi, Andrew M Dai, and George E Dahl. 2018.
Embedding text in hyperbolic spaces. arXiv preprint
arXiv:1806.04313 .
Saurabh Dorle and Nitin Pise. 2018. Political sentiment
analysis through social media. In 2018 second in-
ternational conference on computing methodologies
and communication (ICCMC) , pages 869–873. IEEE.
Eve Fleisig, Rediet Abebe, and Dan Klein. 2023. When
the majority is wrong: Modeling annotator disagree-
ment for subjective tasks. In Proceedings of the 2023
Conference on Empirical Methods in Natural Lan-
guage Processing , pages 6715–6726.
Tommaso Fornaciari, Alexandra Uma, Massimo Poesio,
and Dirk Hovy. 2022. Hard and soft evaluation of
NLP models with BOOtSTrap SAmpling - BooStSa.
InProceedings of the 60th Annual Meeting of the
Association for Computational Linguistics: System
Demonstrations , pages 127–134, Dublin, Ireland. As-
sociation for Computational Linguistics.
Yacine Gaci, Boualem Benatallah, Fabio Casati, and
Khalid Benabdeslem. 2023. Targeting the source:
Selective data curation for debiasing nlp models. In
Joint European Conference on Machine Learning and
Knowledge Discovery in Databases , pages 276–294.
Springer.Lijimol George and P Sumathy. 2023. An integrated
clustering and bert framework for improved topic
modeling. International Journal of Information Tech-
nology , pages 1–9.
Mitchell L Gordon, Michelle S Lam, Joon Sung Park,
Kayur Patel, Jeff Hancock, Tatsunori Hashimoto, and
Michael S Bernstein. 2022. Jury learning: Integrat-
ing dissenting voices into machine learning models.
InProceedings of the 2022 CHI Conference on Hu-
man Factors in Computing Systems , pages 1–19.
Soumyajit Gupta, Sooyong Lee, Maria De-Arteaga,
and Matthew Lease. 2023. Same same, but differ-
ent: Conditional multi-task learning for demographic-
specific toxicity detection. In Proceedings of the
ACM Web Conference 2023 , pages 3689–3700.
Vivek Gupta, Ankit Saw, Pegah Nokhiz, Harshit Gupta,
and Partha Talukdar. 2019. Improving document
classification with multi-sense embeddings. arXiv
preprint arXiv:1911.07918 .
Danula Hettiachchi, Mike Schaekermann, Tristan J
McKinney, and Matthew Lease. 2021. The challenge
of variable effort crowdsourcing and how visible
gold can help. Proceedings of the ACM on Human-
Computer Interaction , 5(CSCW2):1–26.
Nils Holzenberger, Mingxing Du, Julien Karadayi,
Rachid Riad, and Emmanuel Dupoux. 2018. Learn-
ing word embeddings: Unsupervised methods for
fixed-size representations of variable-length speech
segments. In Interspeech 2018 . ISCA.
Soodeh Hosseini and Zahra Asghari Varzaneh. 2022.
Deep text clustering using stacked autoencoder. Mul-
timedia Tools and Applications , 81(8):10861–10881.
Dirk Hovy and Shrimai Prabhumoye. 2021. Five
sources of bias in natural language processing. Lan-
guage and Linguistics Compass , 15(8):e12432.
EunJeong Hwang, Bodhisattwa Majumder, and Niket
Tandon. 2023. Aligning language models to user
opinions. In Findings of the Association for Com-
putational Linguistics: EMNLP 2023 , pages 5906–
5919, Singapore. Association for Computational Lin-
guistics.
Ali Idrus. 2022. Distance analysis measuring for clus-
tering using k-means and davies bouldin index algo-
rithm. TEM Journal , 11(4):1871–1876.
Nan-Jiang Jiang and Marie-Catherine de Marneffe.
2022. Investigating reasons for disagreement in natu-
ral language inference. Transactions of the Associa-
tion for Computational Linguistics , 10:1357–1374.
Eun Seo Jo and Timnit Gebru. 2020. Lessons from
archives: Strategies for collecting sociocultural data
in machine learning. In Proceedings of the 2020 con-
ference on fairness, accountability, and transparency ,
pages 306–316.Ismo Kärkkäinen and Pasi Fränti. 2000. Minimiza-
tion of the value of davies-bouldin index. In Pro-
ceedings of the IASTED International Conference on
Signal Processing and Communications (SPC’2000).
IASTED/ACTA Press , pages 426–432.
Przemysław Kazienko, Julita Bielaniewicz, Marcin
Gruza, Kamil Kanclerz, Konrad Karanowski, Piotr
Miłkowski, and Jan Koco ´n. 2023. Human-centered
neural reasoning for subjective content processing:
Hate speech, emotions, and humor. Information Fu-
sion, 94:43–65.
Noah Lee, Na Min An, and James Thorne. 2023. Can
large language models capture dissenting human
voices? In Proceedings of the 2023 Conference
on Empirical Methods in Natural Language Process-
ing, pages 4569–4585, Singapore. Association for
Computational Linguistics.
Jochen L Leidner and Vassilis Plachouras. 2017. Eth-
ical by design: Ethics best practices for natural lan-
guage processing. In Proceedings of the First ACL
Workshop on Ethics in Natural Language Processing ,
pages 30–40.
Attila Lengyel and Zoltán Botta-Dukát. 2019. Sil-
houette width using generalized mean—a flexible
method for assessing clustering efficiency. Ecology
and evolution , 9(23):13231–13243.
Elisa Leonardelli, Alexandra Uma, Gavin Abercrombie,
Dina Almanea, Valerio Basile, Tommaso Fornaciari,
Barbara Plank, Verena Rieser, and Massimo Poesio.
2023. Semeval-2023 task 11: Learning with disagree-
ments (lewidi). arXiv preprint arXiv:2304.14803 .
Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-
dar Joshi, Danqi Chen, Omer Levy, Mike Lewis,
Luke Zettlemoyer, and Veselin Stoyanov. 2019.
Roberta: A robustly optimized BERT pretraining
approach. CoRR , abs/1907.11692.
Ziquan Liu, Lei Yu, Janet H Hsiao, and Antoni B Chan.
2021. Primal-gmm: Parametric manifold learning of
gaussian mixture models. IEEE Transactions on Pat-
tern Analysis and Machine Intelligence , 44(6):3197–
3211.
Ilya Loshchilov and Frank Hutter. 2017. Decou-
pled weight decay regularization. arXiv preprint
arXiv:1711.05101 .
Yiwei Luo, Dallas Card, and Dan Jurafsky. 2020. De-
tecting stance in media on global warming. arXiv
preprint arXiv:2010.15149 .
James MacQueen et al. 1967. Some methods for clas-
sification and analysis of multivariate observations.
InProceedings of the fifth Berkeley symposium on
mathematical statistics and probability , volume 1,
pages 281–297. Oakland, CA, USA.
Leland McInnes, John Healy, Steve Astels, et al. 2017.
hdbscan: Hierarchical density based clustering. J.
Open Source Softw. , 2(11):205.Leland McInnes, John Healy, and James Melville. 2018.
Umap: Uniform manifold approximation and pro-
jection for dimension reduction. arXiv preprint
arXiv:1802.03426 .
Yu Meng, Yunyi Zhang, Jiaxin Huang, Yu Zhang, and
Jiawei Han. 2022. Topic discovery via latent space
clustering of pretrained language model representa-
tions. In Proceedings of the ACM Web Conference
2022 , pages 3143–3152.
Stefano Menini and Sara Tonelli. 2016. Agreement and
disagreement: Comparison of points of view in the
political domain. In Proceedings of COLING 2016,
the 26th International Conference on Computational
Linguistics: Technical Papers , pages 2461–2470.
Jiaqi Mu, Suma Bhat, and Pramod Viswanath. 2017.
All-but-the-top: Simple and effective postprocess-
ing for word representations. arXiv preprint
arXiv:1702.01417 .
Roberto Navigli, Simone Conia, and Björn Ross. 2023.
Biases in large language models: origins, inventory,
and discussion. ACM Journal of Data and Informa-
tion Quality , 15(2):1–21.
Renáta Németh. 2023. A scoping review on the use of
natural language processing in research on political
polarization: trends and research prospects. Journal
of computational social science , 6(1):289–313.
F. Pedregosa, G. Varoquaux, A. Gramfort, V . Michel,
B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer,
R. Weiss, V . Dubourg, J. Vanderplas, A. Passos,
D. Cournapeau, M. Brucher, M. Perrot, and E. Duch-
esnay. 2011. Scikit-learn: Machine learning in
Python. Journal of Machine Learning Research ,
12:2825–2830.
Vinodkumar Prabhakaran, Aida Mostafazadeh Davani,
and Mark Diaz. 2021. On releasing annotator-level
labels and information in datasets. arXiv preprint
arXiv:2110.05699 .
Alec Radford, Jeffrey Wu, Rewon Child, David Luan,
Dario Amodei, Ilya Sutskever, et al. 2019. Language
models are unsupervised multitask learners. OpenAI
blog, 1(8):9.
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine
Lee, Sharan Narang, Michael Matena, Yanqi Zhou,
Wei Li, and Peter J Liu. 2020. Exploring the limits
of transfer learning with a unified text-to-text trans-
former. The Journal of Machine Learning Research ,
21(1):5485–5551.
Sara Rajaee and Mohammad Taher Pilehvar. 2021. How
does fine-tuning affect the geometry of embedding
space: A case study on isotropy. arXiv preprint
arXiv:2109.04740 .
Carl Rasmussen. 1999. The infinite gaussian mixture
model. Advances in neural information processing
systems , 12.Nils Reimers and Iryna Gurevych. 2019. Sentence-bert:
Sentence embeddings using siamese bert-networks.
arXiv preprint arXiv:1908.10084 .
Paul Röttger, Bertie Vidgen, Dirk Hovy, and Janet B
Pierrehumbert. 2021. Two contrasting data anno-
tation paradigms for subjective nlp tasks. arXiv
preprint arXiv:2112.07475 .
Peter J Rousseeuw. 1987. Silhouettes: a graphical aid
to the interpretation and validation of cluster analysis.
Journal of computational and applied mathematics ,
20:53–65.
Marta Sandri, Elisa Leonardelli, Sara Tonelli, and Elis-
abetta Ježek. 2023. Why don’t you do it right?
analysing annotators’ disagreement in subjective
tasks. In Proceedings of the 17th Conference of the
European Chapter of the Association for Computa-
tional Linguistics , pages 2420–2433.
Timo Schick and Hinrich Schütze. 2019. Attentive mim-
icking: Better word embeddings by attending to infor-
mative contexts. arXiv preprint arXiv:1904.01617 .
Norbert Schwarz. 1999. Self-reports: How the ques-
tions shape the answers. American psychologist ,
54(2):93.
Xavier Sevillano, Germán Cobo, Francesc Alías, and
Joan Claudi Socoró. 2007. Text clustering on latent
thematic spaces: Variants, strengths and weaknesses.
InInternational Conference on Independent Compo-
nent Analysis and Signal Separation , pages 794–801.
Springer.
Ketan Rajshekhar Shahapure and Charles Nicholas.
2020. Cluster quality analysis using silhouette score.
In2020 IEEE 7th international conference on data
science and advanced analytics (DSAA) , pages 747–
748. IEEE.
Boaz Shmueli, Jan Fell, Soumya Ray, and Lun-Wei Ku.
2021. Beyond fair pay: Ethical implications of nlp
crowdsourcing. arXiv preprint arXiv:2104.10097 .
Suzanna Sia, Ayush Dalmia, and Sabrina J Mielke. 2020.
Tired of topic models? clusters of pretrained word
embeddings make for fast and good topics too! arXiv
preprint arXiv:2004.14914 .
Amanpreet Singh, Ronghang Hu, Vedanuj Goswami,
Guillaume Couairon, Wojciech Galuba, Marcus
Rohrbach, and Douwe Kiela. 2022. Flava: A founda-
tional language and vision alignment model. In Pro-
ceedings of the IEEE/CVF Conference on Computer
Vision and Pattern Recognition , pages 15638–15650.
Timo Spinde, Lada Rudnitckaia, Jelena Mitrovi ´c, Felix
Hamborg, Michael Granitzer, Bela Gipp, and Karsten
Donnay. 2021a. Automated identification of bias
inducing words in news articles using linguistic and
context-oriented features. Information Processing &
Management , 58(3):102505.Timo Spinde, Lada Rudnitckaia, Kanishka Sinha, Fe-
lix Hamborg, Bela Gipp, and Karsten Donnay.
2021b. Mbic–a media bias annotation dataset in-
cluding annotator characteristics. arXiv preprint
arXiv:2105.11910 .
Michael Sullivan, Mohammed Yasin, and Cassandra L
Jacobs. 2023. University at buffalo at semeval-
2023 task 11: Masda–modelling annotator sensibil-
ities through disaggregation. In Proceedings of the
17th International Workshop on Semantic Evaluation
(SemEval-2023) , pages 978–985.
Tony Sun, Andrew Gaut, Shirlyn Tang, Yuxin Huang,
Mai ElSherief, Jieyu Zhao, Diba Mirza, Elizabeth
Belding, Kai-Wei Chang, and William Yang Wang.
2019. Mitigating gender bias in natural language
processing: Literature review. In Proceedings of the
57th Annual Meeting of the Association for Computa-
tional Linguistics , pages 1630–1640, Florence, Italy.
Association for Computational Linguistics.
Hao Tan and Mohit Bansal. 2019. Lxmert: Learning
cross-modality encoder representations from trans-
formers. arXiv preprint arXiv:1908.07490 .
Alexandra Uma, Dina Almanea, and Massimo Poe-
sio. 2022. Scaling and disagreements: Bias, noise,
and ambiguity. Frontiers in Artificial Intelligence ,
5:818451.
Alexandra Uma, Tommaso Fornaciari, Anca Dumi-
trache, Tristan Miller, Jon Chamberlain, Barbara
Plank, Edwin Simpson, and Massimo Poesio. 2021a.
SemEval-2021 task 12: Learning with disagreements.
InProceedings of the 15th International Workshop
on Semantic Evaluation (SemEval-2021) , pages 338–
347, Online. Association for Computational Linguis-
tics.
Alexandra N Uma, Tommaso Fornaciari, Dirk Hovy, Sil-
viu Paun, Barbara Plank, and Massimo Poesio. 2021b.
Learning from disagreement: A survey. Journal of
Artificial Intelligence Research , 72:1385–1470.
Nikolas Vitsakis, Amit Parekh, Tanvi Dinkar, Gavin
Abercrombie, Ioannis Konstas, and Verena Rieser.
2023. ilab at semeval-2023 task 11 le-wi-di:
Modelling disagreement or modelling perspectives?
arXiv preprint arXiv:2305.06074 .
Dongsheng Wang, Prayag Tiwari, Mohammad Shorfuz-
zaman, and Ingo Schmitt. 2021. Deep neural learn-
ing on weighted datasets utilizing label disagree-
ment from crowdsourcing. Computer Networks ,
196:108227.
Charles Welch, Jonathan K. Kummerfeld, Verónica
Pérez-Rosas, and Rada Mihalcea. 2020. Compo-
sitional demographic word embeddings. In Proceed-
ings of the 2020 Conference on Empirical Methods
in Natural Language Processing (EMNLP) , pages
4076–4089, Online. Association for Computational
Linguistics.Albert Xu, Eshaan Pathak, Eric Wallace, Suchin Guru-
rangan, Maarten Sap, and Dan Klein. 2021. Detoxi-
fying language models risks marginalizing minority
voices. In Proceedings of the 2021 Conference of
the North American Chapter of the Association for
Computational Linguistics: Human Language Tech-
nologies , pages 2390–2397, Online. Association for
Computational Linguistics.
Haoran Xu and Philipp Koehn. 2021. Cross-lingual
bert contextual embedding space mapping with
isotropic and isometric conditions. arXiv preprint
arXiv:2107.09186 .A Training Details
To aid in reproducibility, we report all training de-
tails and any relevant hyperparameters.
A.1 Hyperparameters
All models were trained using a single NVIDIA
A40 GPU. A total of 1080 hours were used during
training of all models. For all models, we used the
AdamW optimizer (Loshchilov and Hutter, 2017)
during training with weight decay 0.01. We re-
port hyperparameters for each model and dataset
in Table 5.From small performance gains during
preliminary experiments, we disable bias across all
linear layers.
Cluster training hyperparameters can be found
in Table 6. Across every model, we found that
when comparing hyperparameters for both PCA
and UMAP converged to the same choices. For
both methods, we found that 2 components yielded
the best results. Additionally, for UMAP, we found
that the optimal number of neighbours were found
to be between 80–100 across all models,with a
minimum distance ranging from 0.8 to 1 to yield
better clustering performance.
A.2 Dimensionality Reduction
We report internal validity evaluation score aver-
ages across dimensionality reduction techniques in
Table 7.
B Visual Representation of Models used
in Training Component
Visual depictions of all model architectures seen in
Figure 2.
C Cluster Metrics
C.1 GWSD Cluster Validity Scores - Kmeans
We report the GWSD internal and external valida-
tion metrics resulting from our clustering using a
k-means algorithm and our various employed di-
mensionality reduction techniques in Table 8.
C.2 GWSD Cluster Validity Scores - GMM
We report the GWSD internal and external vali-
dation metrics resulting from our clustering using
a GMM algorithm and our various employed di-
mensionality reduction techniques in Table 9. This
methodology resulted in cluster metrics which were
not as optimal as those of the K-means solutions.Hyperparameter Value
Unpooled Cross Attention
Model name google/t5-v1_1-large
Downsampling n. of layers 0-3
N. warmup steps 0- 800
Learning rate 0.0001 - 1e-08
Pooled Cross Attention
Model name google/t5-v1_1-large
Ann dim. factor 1-6
Downsampling n. of layers 0-3
N. warmup steps 0- 800
Learning rate 0.0001 - 1e-08
Encoder-Encoder
Model name google/t5-v1_1-large
Downsampling n. of layers 0-3
N. warmup steps 0- 800
Learning rate 0.0001 - 1e-08
Classifier Model
Model name roberta-large
N. warmup steps 0- 800
Learning rate 1e-11 - 1e-3
Pretrained Decoder
Model name gpt2-large
Downsampling n. of layers 0-3
N. warmup steps 0- 800
Learning rate 0.0001 - 1e-08
Pretrained Encoder-Decoder
Model name google/t5-v1_1-large
Downsampling n. of layers 0-3
N. warmup steps 0- 800
Learning rate 0.0001 - 1e-08
Table 5: Hyperparameters for all supervised models
on each of our chosen datasets, obtained from running
running a hyperparameter sweep for 12 hours.
Hyperparameter Value
PCA
Cluster ranges 2 - 19
N components 2-40
GMM
Cluster ranges 2-19
HDBSCAN
Eps 0.0 - 1.0
Min samples 2 - 100
Min cluster size 2 - 100
Table 6: Hyperparameters for all clustering methods
on each of our chosen datasets, obtained from running
running a hyperparameter sweep for 12 hours.Figure 2: Training component: 6 modelling architectures for extracting hidden states (denoted with a yellow circle
asEmb n) used as input for the Clustering component.
Davies-Bouldin Index Silhouette
No dim. reduction 3.655 0.073
w/ PCA 0.491 0.56
w/ UMAP 0.565 0.53
Table 7: Dimensionality reduction effect on internal
validity scores
C.3 GWSD Cluster Validity Scores -
HDBSCAN
We report the GWSD internal and external valida-
tion metrics resulting from our clustering using an
HDBSCAN algorithm and our various employed
dimensionality reduction techniques in Table 10.
Unfortunately, this methodology resulted in either
large cluster numbers too large to be adequately
analysed manually, or with metrics not as optimal
as those of the K-means solutions.C.4 MBIC Cluster Validity Scores- GMM
We report the MBIC internal and external valida-
tion metrics resulting from our clustering using a
GMM algorithm and our various employed dimen-
sionality reduction techniques in Table 11. Unfor-
tunately, this methodology also resulted in cluster
metrics which were not as optimal as those of the
K-means solutions.
C.5 MBIC Cluster Validity Scores-
HDBSCAN
We report the MBIC internal and external valida-
tion metrics resulting from our clustering using a
HDBSCAN algorithm and our various employed
dimensionality reduction techniques in Table 12.
Unfortunately, this methodology also resulted in
either large cluster numbers too large to be ade-
quately analysed manually, or with metrics not as
optimal as those of the K-means solutions.Purity ↑ Prototypical cluster % ↑
# Clusters DB Index ↓Silhouette ↑Political Education Political Education
GWSD - Kmeans
Cross Attention
No dim. reduction 19 1.95 0.17 0.46 0.43 0.00 0.05
w/ PCA 17 0.45 0.61 0.53 0.53 0.00 0.00
w/ UMAP 18 1.05 0.49 0.51 0.44 0.22 0.00
Pooled Cross Attention
No dim. reduction 16 2.76 0.07 0.43 0.44 0.06 0.00
w/ PCA 19 0.79 0.38 0.43 0.47 0.16 0.00
w/ UMAP 19 0.47 0.55 0.49 0.40 0.05 0.11
Encoder-Encoder
No dim. reduction 18 5.77 0.02 0.53 0.34 0.28 0.33
w/ PCA 19 0.84 0.34 0.40 0.60 0.11 0.00
w/ UMAP 15 0.50 0.54 0.69 0.54 0.40 0.20
Classifier Model
No dim. reduction 19 1.95 0.17 0.46 0.43 0.00 0.05
w/ PCA 17 0.45 0.61 0.53 0.53 0.00 0.00
w/ UMAP 18 1.05 0.49 0.51 0.44 0.22 0.00
Pretrained Decoder
No dim. reduction 19 2.83 0.09 0.61 0.47 0.11 0.05
w/ PCA 19 0.47 0.59 0.42 0.44 0.16 0.00
w/ UMAP 17 0.52 0.53 0.51 0.58 0.00 0.00
Pretrained Encoder-Decoder
No dim. reduction 19 2.53 0.06 0.48 0.55 0.05 0.05
w/ PCA 19 0.83 0.34 0.45 0.52 0.11 0.11
w/ UMAP 17 0.84 0.34 0.36 0.57 0.00 0.06
Table 8: Internal and external validation metrics for the K-means clustering technique on the GWSD dataset. Internal
validation metrics explain intra-cluster separation through higher Silhouette and lower Davies-Bouldin (DB Index)
scores. External validity, which indicates the potential of having captured a voice, is measured via the average Purity
score and % of prototypical clusters.Purity ↑ Prototypical cluster % ↑
# Clusters DB Index ↓Silhouette ↑Political Education Political Education
GWSD -GMM
Unpooled Cross Attention
No dim. reduction 5 12.54 0.00 0.44 0.55 0.00 0.00
w/ PCA 5 8.13 0.00 0.44 0.55 0.00 0.00
w/ UMAP 5 8.02 0.01 0.44 0.55 0.00 0.00
Pooled Cross Attention
No dim. reduction 6 3.73 0.04 0.46 0.57 0.00 0.00
w/ PCA 6 2.68 0.05 0.46 0.57 0.00 0.00
w/ UMAP 7 2.31 0.08 0.37 0.46 0.00 0.00
Encoder-Encoder
No dim. reduction 5 9.30 0.01 0.44 0.47 0.00 0.00
w/ PCA 5 4.09 0.03 0.44 0.47 0.00 0.00
w/ UMAP 5 5.57 0.03 0.44 0.47 0.00 0.00
Classifier Model
No dim. reduction 5 1.87 0.19 0.43 0.51 0.00 0.00
w/ PCA 5 1.48 0.33 0.43 0.51 0.00 0.00
w/ UMAP 12 3.02 0.05 0.42 0.50 0.08 0.00
Pretrained Decoder
No dim. reduction 19 3.12 0.05 0.41 0.50 0.05 0.00
w/ PCA 6 1.72 0.18 0.44 0.48 0.00 0.00
w/ UMAP 5 1.75 0.20 0.47 0.53 0.00 0.00
Pretrained Encoder-Decoder
No dim. reduction 5 3.39 0.05 0.47 0.48 0.00 0.00
w/ PCA 6 2.90 0.00 0.44 0.56 0.00 0.00
w/ UMAP 11 2.51 0.06 0.45 0.43 0.09 0.00
Table 9: Internal and external validation metrics for the GMM clustering technique on the GWSD dataset. Internal
validation metrics explain intra-cluster separation through higher Silhouette and lower Davies-Bouldin (DB Index)
scores. External validity, which indicates the potential of having captured a voice, is measured via the average Purity
score and % of prototypical clusters.Purity ↑ Prototypical cluster % ↑
# Clusters DB Index ↓Silhouette ↑Political Education Political Education
GWSD- HDBSCAN
Unpooled Cross Attention
No dim. reduction 407 0.62 0.57 1.00 1.00 0.96 1.00
w/ PCA 4 10.10 0.05 0.50 0.50 0.25 0.50
w/ UMAP 3 17.35 0.01 0.57 0.57 0.33 0.33
Pooled Cross Attention
No dim. reduction 191 1.25 0.30 0.80 0.60 0.59 0.35
w/ PCA 3 2.47 0.01 0.60 0.50 0.33 0.00
w/ UMAP 173 0.23 0.85 0.75 0.38 0.59 0.35
Encoder-Encoder
No dim. reduction 4 9.53 0.01 0.67 0.67 0.50 0.25
w/ PCA 5 6.99 0.03 0.43 0.57 0.00 0.40
w/ UMAP 4 21.22 0.07 0.52 0.92 0.25 0.25
Classifier Model
No dim. reduction 211 0.14 0.95 0.50 0.62 0.59 0.35
w/ PCA 210 0.13 0.95 0.50 0.62 0.59 0.34
w/ UMAP 3 3.20 0.14 0.51 0.42 0.00 0.00
Pretrained Decoder
No dim. reduction 210 1.21 0.62 0.50 0.62 0.60 0.35
w/ PCA 204 1.14 0.52 0.40 0.60 0.57 0.38
w/ UMAP 210 0.78 0.98 0.50 0.62 0.59 0.35
Pretrained Encoder-Decoder
No dim. reduction 3 0.72 0.25 0.50 0.50 0.33 0.33
w/ PCA 3 2.31 0.04 0.50 0.50 0.33 0.33
w/ UMAP — — — — — — —
Table 10: Internal and external validation metrics for the HDBSCAN clustering technique on the GWSD dataset.
Internal validation metrics explain intra-cluster separation through higher Silhouette and lower Davies-Bouldin
(DB Index) scores. External validity, which indicates the potential of having captured a voice, is measured via the
average Purity score and % of prototypical clusters. Missing runs indicate that the cluster number computed was
equal to the amount of text-annotation pairs, proving the solution invalid.Purity ↑ Prototypical cluster % ↑
# Clusters DB Index ↓Silhouette ↑Political Education Political Education
MBIC- GMM
Unpooled Cross Attention
No dim. reduction 19 7.50 0.01 0.66 0.54 0.32 0.05
w/ PCA 5 8.11 0.00 0.41 0.46 0.00 0.00
w/ UMAP 5 8.22 0.00 0.41 0.46 0.00 0.00
Pooled Cross Attention
No dim. reduction 19 4.04 0.02 0.37 0.46 0.32 0.05
w/ PCA 8 4.09 0.00 0.45 0.56 0.12 0.00
w/ UMAP 5 7.83 0.01 0.45 0.51 0.00 0.00
Encoder-Encoder
No dim. reduction 19 8.81 0.00 0.50 0.33 0.21 0.21
w/ PCA 5 9.50 0.00 0.47 0.48 0.20 0.20
w/ UMAP 5 8.87 0.00 0.47 0.48 0.20 0.20
Classifier Model
No dim. reduction — — — — — — —
w/ PCA — — — — — — —
w/ UMAP — — — — — — —
Pretrained Decoder
No dim. reduction 5 3.67 0.03 0.44 0.46 0.00 0.00
w/ PCA 16 2.83 0.01 0.52 0.32 0.00 0.00
w/ UMAP 18 7.50 0.01 0.53 0.50 0.17 0.00
Pretrained Encoder-Decoder
No dim. reduction 6 1.76 0.14 0.47 0.46 0.00 0.00
w/ PCA 5 2.27 0.03 0.49 0.48 0.00 0.00
w/ UMAP 5 0.58 0.43 0.49 0.48 0.00 0.00
Table 11: Internal and external validation metrics for the GMM clustering technique on the GWSD dataset. Internal
validation metrics explain intra-cluster separation through higher Silhouette and lower Davies-Bouldin (DB Index)
scores. External validity, which indicates the potential of having captured a voice, is measured via the average Purity
score and % of prototypical clusters. Rows with missing labels indicate inability of the GMM clustering technique
to create a solution within the allotted train time for the respective configuration’s hyperparameter sweep.Purity ↑ Prototypical cluster % ↑
# Clusters DB Index ↓Silhouette ↑Political Education Political Education
MBIC- HDBSCAN
Unpooled Cross Attention
No dim. reduction 862 1.01 0.71 1.00 1.00 1.00 1.00
w/ PCA 862 0.86 0.72 1.00 1.00 1.00 1.00
w/ UMAP 862 1.30 0.21 1.00 1.00 1.00 1.00
Pooled Cross Attention
No dim. reduction 218 1.30 0.20 1.00 1.00 0.85 0.70
w/ PCA 218 1.26 0.29 1.00 1.00 0.85 0.70
w/ UMAP 218 2.85 0.80 1.00 1.00 0.85 0.70
Encoder-Encoder
No dim. reduction 5 4.18 0.00 1.00 1.00 0.60 0.60
w/ PCA 3 3.59 0.06 1.00 1.00 0.67 0.33
w/ UMAP 5 4.10 0.04 1.00 1.00 0.60 0.60
Classifier Model
No dim. reduction 3 2.70 0.15 0.50 0.58 0.00 0.00
w/ PCA 3 1.81 0.04 0.67 0.67 0.33 0.33
w/ UMAP 3 1.93 0.56 0.46 0.55 0.00 0.00
Pretrained Decoder
No dim. reduction 185 1.22 0.45 0.44 0.56 0.68 0.44
w/ PCA 168 2.45 0.07 0.43 0.57 0.74 0.39
w/ UMAP 168 1.11 0.63 0.43 0.57 0.74 0.39
Pretrained Encoder-Decoder
No dim. reduction 3 1.27 0.19 0.50 0.50 0.33 0.33
w/ PCA 3 2.78 0.04 0.53 0.47 0.33 0.00
w/ UMAP 3 3.29 0.08 0.53 0.49 0.33 0.00
Table 12: Internal and external validation metrics for the HDBSCAN clustering technique on the MBIC dataset.
Internal validation metrics explain intra-cluster separation through higher Silhouette and lower Davies-Bouldin
(DB Index) scores. External validity, which indicates the potential of having captured a voice, is measured via the
average Purity score and % of prototypical clusters.