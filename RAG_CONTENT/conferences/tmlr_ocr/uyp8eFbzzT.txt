Under review as submission to TMLR
Representation Balancing with Decomposed Patterns for
Treatment Eﬀect Estimation
Anonymous authors
Paper under double-blind review
Abstract
Estimating treatment eﬀects from observational data is subject to a covariate shift problem
incurred by selection bias. Recent research has sought to mitigate this problem by balancing
the distribution of representations between the treated and controlled groups. The rationale
behind this is that counterfactual estimation relies on (1) preserving the predictive power
of factual outcomes and (2) learning balanced representations. However, there is a trade-oﬀ
between achieving these two objectives. In this paper, we propose a novel model, DIGNet,
which is designed to capture the patterns that contribute to outcome prediction (task 1)
and representation balancing (task 2) respectively. Speciﬁcally, we derive a theoretical
upper bound that links the concept of propensity confusion to representation balancing,
and further transform the balancing Patterns into Decompositions of Individual propensity
confusion and Group distance minimization (PDIG) to capture more eﬀective balancing
patterns. Moreover, we suggest decomposing proxy features into Patterns of Pre-balancing
and Balancing Representations (PPBR) to preserve patterns that are beneﬁcial for outcome
modeling. Extensive experiments conﬁrm that PDIG and PPBR follow diﬀerent pathways
to achieve the same goal of improving treatment eﬀect estimation. We hope our ﬁndings
can be heuristics for investigating factors inﬂuencing the generalization of representation
balancing models in counterfactual estimation.
1 Introduction
In the context of the ubiquity of personalized decision-making, causal inference has sparked a surge of
research exploring causal machine learning in many disciplines, including economics and statistics (Wager &
Athey, 2018; Athey & Wager, 2019; Farrell, 2015; Chernozhukov et al., 2018; Huang et al., 2021), healthcare
(Qian et al., 2021; Bica et al., 2021a;b), and commercial applications (Guo et al., 2020b;c; Chu et al., 2021).
The core of causal inference is to estimate treatment eﬀects , which can be tied to a fundamental hypothetical
question: What would be the outcome if one received an alternative treatment? Answering this question
requires the knowledge of counterfactual outcomes , which can only be inferred from observational data, but
cannot be obtained directly.
Selection bias presents a major challenge for estimating counterfactual outcomes (Guo et al., 2020a; Zhang
et al., 2020; Yao et al., 2021). This problem is due to the non-random treatment assignment, that is,
treatment (e.g., vaccination) is usually determined by covariates (e.g., age) that also aﬀect the outcome
(e.g., infection rate) (Huang et al., 2022b). The probability of a person receiving treatment is well known
as thepropensity score , and the diﬀerence between each person’s propensity score can inherently lead to a
covariate shift problem, i.e., the distribution of covariates in the treated units is substantially diﬀerent from
that in the controlled ones. The covariate shift issue makes it more diﬃcult to infer counterfactual outcomes
from observational data (Yao et al., 2018; Hassanpour & Greiner, 2019a).
Recently, a line of representation balancing works has sought to alleviate the covariate shift problem by
balancing the distribution between the treated group and the controlled group in the representation space
(Shalit et al., 2017; Johansson et al., 2022). The rational insight behind these works is that the counterfactual
estimation should rest on (1)the accuracy of factual outcome estimation and (2)enforcing minimization
1Under review as submission to TMLR
of distributional discrepancy measured by the Integral Probability Metric (IPM) between the treated and
controlled groups. Wasserstein distance (Cuturi & Doucet, 2014) is the most widely-adopted IPM for the
target (2) (Shalit et al., 2017; Huang et al., 2022a; Zhou et al., 2022), whereas other distance metrics such
asH-divergence have still received little attention in causal representation learning literature though H-
divergence is an important distance metric in other ﬁelds (Ben-David et al., 2006; 2010). Unlike previous
studies focusing on group distance minimization, we emphasize that the propensity score is a natural in-
dicator of whether representations are adequately balanced. Speciﬁcally, when it becomes challenging to
distinguish whether each unit in the representation space is treated or controlled, i.e., propensity confusion ,
the representations are believed to be adequately balanced. Ideally, if propensity confusion is extremely
strong, i.e., representations are perfectly balanced, the propensity scores of each unit in the representation
space would be 0.5. Therefore, propensity confusion provides a logical interpretation for representation
balancing, and achieving propensity confusion is naturally connected to minimizing the H-divergence-based
individual treatment eﬀect (ITE) error bound. More discusses about the theoretical results and empirical
implementations are presented in Section 3.2 and Section 4.1, respectively.
Moreover, a critical issue that remain to be resolved is that enforcing models to learn only balancing patterns
can weaken the predictive power of the outcome function. This is because of the trade-oﬀ between targets (1)
and (2) (Zhang et al., 2020; Assaad et al., 2021; Huang et al., 2022a). We give a motivating example below
to help readers better understand this phenomenon. In addition, we provide another illustrative example
and analytical explanations in Section A.4 as supplementary elaboration on the aforementioned trade-oﬀ.
Motivating Example. Consider two individuals who are identical in every aspect except for their age.
One person is older and is designated as the treatment (T) group, while the other person is younger and
serves as the control (C) group. Age is used as a covariate to distinguish between T and C. If it is known
that the older person is more susceptible to a certain disease, the information age (covariate) can be used
to predict the likelihood of one developing the disease (outcome). However, suppose the information age
of each individual is mapped to some representations such that the representations of T and C are highly-
balanced or even identical. In that case, it may be diﬃcult to diﬀerentiate between T and C based on
these representations. Consequently, these over-balanced representations may lose information to accurately
predict the likelihood of each individual developing the disease.
Theaforementionedissuemotivatesustoexploreapproachesto (i)learningmoreeﬀectivebalancingpatterns
(task 2) without aﬀecting factual outcome prediction (task 1) or (ii)improving factual outcome prediction
(task 1) without aﬀecting learning balancing patterns (task 2). In this paper, we propose a new method,
DIGNet, which learns decomposed patterns to achieve both (i) and (ii). The contributions are threefold:
First, we interpret representation balancing as propensity confusion and derive corresponding theoretical
upper bounds for counterfactual error and ITE error based on H-divergence to ensure its rationality; Sec-
ond, DIGNet transforms the balancing Patterns into Decompositions of Individual propensity confusion and
Group distance minimization ( PDIG) to achieve goal (i), and we empirically ﬁnd that the PDIG structure
learns more eﬀective balancing patterns (task 2) without aﬀecting factual outcome prediction (task 1); Third,
DIGNet decomposes representative features into Patterns of Pre-balancing and Balancing Representations
(PPBR) to achieve goal (ii), and we experimentally conﬁrm that the PPBR approach improves outcome pre-
diction (task 1) without aﬀecting learning balancing patterns (task 2). To better describe our contributions,
we illustrate PPBR, PDIG, and the proposed DIGNet in Figure 1. We also illustrate the model sturecture
of DIGNet with the variants GNet, INet, DGNet, DINet in Figure 2.
1.1 Related Work
The presence of a covariate shift problem stimulates the line of representation balancing works (Johansson
et al., 2016; Shalit et al., 2017; Johansson et al., 2022). These works aim to balance the distributions of
representations between treated and controlled groups and simultaneously try to maintain representations
predictive of factual outcomes. This idea is closely connected with domain adaptation. In particular, the
individual treatment eﬀect (ITE) error bound based on Wasserstein distance is similar to the generalization
bound in Ben-David et al. (2010); Long et al. (2014); Shen et al. (2018). In addition to Wasserstein distance-
based model, our paper derives a new ITE error bound based on H-divergence (Ben-David et al., 2006;
2Under review as submission to TMLR
Φ𝐺𝐺
(b) PPBR (yellow) (c) PDIG (yellow)Φ𝐼𝐼Φ𝐸𝐸
Φ𝐺𝐺
Φ𝐺𝐺
(d) DIGNetΦ𝐸𝐸Φ𝐼𝐼
(a) Classic modelΦ𝐸𝐸
BalancingBalancing BalancingBalancing
BalancingBalancing
Figure1: (a): Theclassicmodel(e.g., CFRNetShalitetal.(2017))extractsandmapstheoriginaldata Dinto
representations ΦEto achieve representation balancing over ΦE, which are referred to as balancing patterns .
These balanced representations are then used for outcome prediction. (b): The PPBR is represented by
the yellow section, where ΦEis used for feature extraction and ΦGis used for representation balancing,
which are termed pre-balancing patterns and balancing patterns, respectively. Note that ΦGalso serves as
decomposed patterns derived from ΦE. Subsequently, ΦEandΦGare concatenated for predicting outcomes.
(c): The PDIG is illustrated as the yellow part, where the balancing patterns consist of two components, ΦG
andΦI, serving for group distance minimization and individual propensity confusion, as detailed in Section
4.2. Afterward, ΦGandΦIare concatenated for predicting outcomes. (d): The proposed model, DIGNet,
incorporates both PPBR and PDIG. In DIGNet, pre-balancing patterns ΦEare decomposed into balancing
patterns ΦGandΦI, which also serve as decomposed patterns. The ﬁnal outcome prediction is obtained by
concatenating ΦE,ΦG, and ΦI.
2010; Ganin et al., 2016). Note that our theoretical results (Section 3.2) and experimental implementations
(Section 4.1) diﬀer greatly from Shalit et al. (2017) due to the distinction between Wasserstein distance and
H-divergence.
Anotherrecent lineof causalrepresentation learning literatureinvestigateseﬃcient neuralnetwork structures
for treatment eﬀect estimation. Kuang et al. (2017); Hassanpour & Greiner (2019b) extract the original co-
variates into treatment-speciﬁc factors, outcome-speciﬁc factors, and confounding factors; X-learner (Künzel
et al., 2019) and R-learner (Nie & Wager, 2021) are developed beyond the classic S-learner and T-learner;
Curth & van der Schaar (2021) leverage structures for end-to-end learners to counteract the inductive bias
towards treatment eﬀect estimation, which is motivated by Makar et al. (2020).
The proposed DIGNet model is built on the PDIG structure and the PPBR approach. The PDIG structure
is motivated by multi-task learning, where we design a framework incorporating two speciﬁc balancing
patterns that share the same pre-balancing patterns. The PPBR approach is motivated by a so-called over-
enforcing problem mentioned by Zhang et al. (2020); Assaad et al. (2021); Huang et al. (2022a), where the
authors argue that improperly balanced representations can be detrimental predictors for outcome modeling,
since such representations can lose the original information that contributes to outcome prediction. Other
representation learning methods relevant to treatment eﬀect estimation include Louizos et al. (2017); Yao
et al. (2018); Yoon et al. (2018); Shi et al. (2019); Du et al. (2021).
2 Preliminaries
Notations. Suppose there are the Ni.i.d. random variables D={(Xi,Ti,Yi)}N
i=1with observed re-
alizations{(xi,ti,yi)}N
i=1, where there are N1treated units and N0controlled units. For each unit i,
Xi∈ X ⊂ Rddenotesd-dimensional covariates and Ti∈ {0,1}denotes the binary treatment, with
e(xi) :=p(Ti= 1|Xi=xi)deﬁned as the propensity score (Rosenbaum & Rubin, 1983). Potential
outcome framework (Rubin, 2005) deﬁnes the potential outcomes Y1,Y0∈Y ⊂ Rfor treatment T= 1
andT= 0, respectively. We let the observed outcome (factual outcome) be Y=T·Y1+ (1−T)·Y0,
and the unobserved outcome (counterfactual outcome) be Y=T·Y0+ (1−T)·Y1. Fort∈{0,1}, let
τt(x) :=E[Yt|X=x]be a function of Ytw.r.t. X, then our goal is to estimate the individual treat-
ment eﬀect (ITE) τ(x) :=E/bracketleftbig
Y1−Y0|X=x/bracketrightbig
=τ1(x)−τ0(x)1, and the average treatment eﬀect (ATE)
1The term E/bracketleftbig
Y1−Y0|X=x/bracketrightbig
is often deﬁned as the Conditional Average Treatment Eﬀect (CATE). In order to maintain
consistency with the notion used in the existing causal representation balancing literature, e.g., Shalit et al. (2017), we refer to
3Under review as submission to TMLR
τATE :=E/bracketleftbig
Y1−Y0/bracketrightbig
=/integraltext
Xτ(x)p(x)dx. We refer to the representations as patterns. The proposed compo-
nents PPBR and PDIG are illustrated in Figure 1, and the necessary representation function ΦE,ΦGand
ΦIare illustrated in Figure 2.
2.1 Problem setup
In causal representation balancing works, we denote representation space by R⊂Rd, and Φ :X →R is
assumed to be a twice-diﬀerentiable, one-to-one and invertible function with its inverse Ψ :R→X such
that Ψ(Φ(x)) =x. The densities of the treated and controlled covariates are denoted by pT=1
x=pT=1(x) :=
p(x|T= 1)andpT=0
x=pT=0(x) :=p(x|T= 0), respectively. Correspondingly, the densities of the treated
and controlled covariates in the representation space are denoted by pT=1
Φ=pT=1
Φ(r) :=pΦ(r|T= 1)and
pT=0
Φ=pT=0
Φ(r) :=pΦ(r|T= 0), respectively.
Our study is based on the potential outcome framework (Rubin, 2005). Assumption 1 states standard
and necessary assumptions to ensure treatment eﬀects are identiﬁable. Before proceeding with theoretical
analysis, we also present some necessary terms and deﬁnitions in Deﬁnition 1.
Assumption 1 (Consistency, Overlap, and Unconfoundedness) .Consistency: If the treatment is t, then
the observed outcome equals Yt. Overlap: The propensity score is bounded away from 0to1:0<e(x)<1.
Unconfoundedness: Yt⊥ ⊥T|X,∀t∈{0,1}.
Deﬁnition 1. Leth:R×{ 0,1}→Ybe an hypothesis deﬁned over the representation space Rsuch that
h(Φ(x),t)estimatesyt, andL:Y×Y→ R+be a loss function (e.g., L(y,y/prime) = (y−y/prime)2). If we deﬁne the
expected loss for (x,t)as/lscripth,Φ(x,t) =/integraltext
YL(yt,h(Φ(x),t))p(yt|x)dyt, we then have factual and counterfactual
losses, as well as them on the treated and controlled:
/epsilon1F(h,Φ) =/integraldisplay
X×{ 0,1}/lscripth,Φ(x,t)p(x,t)dxdt, /epsilon1 CF(h,Φ) =/integraldisplay
X×{ 0,1}/lscripth,Φ(x,t)p(x,1−t)dxdt,
/epsilon1T=1
F(h,Φ) =/integraldisplay
X/lscripth,Φ(x,1)pT=1(x)dx, /epsilon1T=0
F(h,Φ) =/integraldisplay
X/lscripth,Φ(x,0)pT=0(x)dx,
/epsilon1T=1
CF(h,Φ) =/integraldisplay
X/lscripth,Φ(x,1)pT=0(x)dx, /epsilon1T=0
CF(h,Φ) =/integraldisplay
X/lscripth,Φ(x,0)pT=1(x)dx.
If we letf(x,t)beh(Φ(x),t), wheref:X×{ 0,1}→Yis a prediction function for outcome, then the
estimated ITE over fis deﬁned as ˆτf(x) :=f(x,1)−f(x,0). Finally, a better treatment eﬀect estimation
can be reformulated as a smaller error in Precision in the expected Estimation of Heterogeneous Eﬀect
(PEHE):
/epsilon1PEHE (f) =/integraldisplay
XL(ˆτf(x),τ(x))p(x)dx. (1)
Here,/epsilon1PEHE (f)can also be denoted by /epsilon1PEHE (h,Φ)if we letf(x,t)beh(Φ(x),t).
3 Theoretical Results
In this section, we ﬁrst prove /epsilon1PEHEis bounded by /epsilon1Fand/epsilon1CFin Lemma 1. Next, we revisit and extend
the upper bound (Theorem 1) concerning the group distance minimization guided method in Section 3.1.
Section 3.2 further discusses the new concept of propensity confusion and the theoretical results based on
the individual propensity confusion guided method (Theorem 2). Proofs and additional theoretical results
are deferred to Appendix.
Lemma 1. Let functions handΦbe as deﬁned in Deﬁnition 1, and Lbe the squared loss function. Recall that
τt(x) =E[Yt|X=x]. Deﬁning σ2
y= min{σ2
yt(p(x,t)),σ2
yt(p(x,1−t))}∀t∈{0,1}, whereσ2
yt(p(x,t)) =/integraltext
X×{ 0,1}×Y(yt−τt(x))2p(yt|x)p(x,t)dytdxdt, we have
/epsilon1PEHE (h,Φ)≤2(/epsilon1CF(h,Φ) +/epsilon1F(h,Φ)−2σ2
y).
this term as ITE throughout this paper. Note that the original deﬁnition of ITE for the i-th individual is commonly expressed
as the diﬀerence between their potential outcomes, represented as Y1
i−Y0
i.
4Under review as submission to TMLR
Note that similar results will hold as long as Ltakes forms that satisfy the triangle inequality, so Lis not
limited to the squared loss. For instance, we give the result for absolute loss in Lemma 6 in Appendix. This
extends the result shown in Shalit et al. (2017) that Lonly takes the squared loss.
3.1 GNet: Group Distance Minimization Guided Representation Balancing
Previous causal learning models commonly adopt the group distance minimization guided approach to seek
representation balancing via minimizing the distance measured by the Integral Probability Metric (IPM)
deﬁned in Deﬁnition 2.
Deﬁnition 2. LetGbe a function family consisting of functions g:S→R. For a pair of distributions p1,
p2overS, the Integral Probability Metric is deﬁned as
IPMG(p1,p2) := sup
g∈G|/integraldisplay
Sg(s)(p1(s)−p2(s))ds|.
IfGis the family of 1-Lipschitz functions, we can obtain the so-called 1-Wasserstein distance, denoted by
Wass (p1,p2)(Sriperumbudur et al., 2012). Next, we present the bounds for counterfactual error /epsilon1CFand
ITE error/epsilon1PEHEusing Wasserstein distance in Theorem 1.
Theorem 1. LetΦ :X → R be an invertible representation with Ψbeing its inverse. Deﬁne
σ2
y= min{σ2
yt(p(x,t)),σ2
yt(p(x,1−t))}andAy= max{Ayt(p(x,t)),Ayt(p(x,1−t))} ∀t∈ {0,1},
whereσ2
yt(p(x,t)) =/integraltext
X×{ 0,1}×Y(yt−τt(x))2p(yt|x)p(x,t)dytdxdtandAyt(p(x,t)) =/integraltext
X×{ 0,1}×Y|yt−
τt(x)|p(yt|x)p(x,t)dytdxdt∀t∈{0,1}. LetpT=1
Φ(r),pT=0
Φ(r)be as deﬁned before, h:R×{ 0,1}→Y,
u:=Pr(T= 1)andGbe the family of 1-Lipschitz functions. Assume there exists a constant BΦ≥0, such
that fort∈{0,1}, the function gΦ,h(r,t) :=1
BΦ·/lscripth,Φ(Ψ(r),t)∈G. IfLis a loss function that satisﬁes the
triangle inequality, we have
/epsilon1CF(h,Φ)≤(1−u)·/epsilon1T=1
F(h,Φ) +u·/epsilon1T=0
F(h,Φ) +BΦ·Wass (pT=1
Φ,pT=0
Φ). (2)
Let loss function Lbe the squared loss such that L(y1,y2) = (y1−y2)2. Then we have:
/epsilon1PEHE (h,Φ)≤2(/epsilon1T=1
F(h,Φ) +/epsilon1T=0
F(h,Φ) +BΦ·Wass (pT=1
Φ,pT=0
Φ)−2σ2
y). (3)
Let loss function Lbe the absolute loss such that L(y1,y2) =|y1−y2|. Then we have:
/epsilon1PEHE (h,Φ)≤/epsilon1T=1
F(h,Φ) +/epsilon1T=0
F(h,Φ) +BΦ·Wass (pT=1
Φ,pT=0
Φ) + 2Ay. (4)
Our Theorem 1 is a more general result compared to previous literature since it holds for any Lthat takes
forms satisfying the triangle inequality. For instance, Theorem 1 will reduce to the results in Shalit et al.
(2017) ifLis the squared loss as shown in equation 3. We also give the result for absolute loss in Theorem
1 as shown in equation 4. We refer to a model built on Theorem 1 as GNet(aka CFR-Wass in Shalit et al.
(2017)) since it is based on group distance minimization.
3.2 INet: Individual Propensity Confusion Guided Representation Balancing
The propensity score plays a central role to treatment eﬀect estimation because it characterizes the prob-
ability that one receives treatment (Rosenbaum & Rubin, 1983). Unlike previous studies that primarily
employ propensity scores for matching or weighting, we emphasize that the propensity score can also serve
as a natural indicator of whether representations are adequately balanced. Speciﬁcally, when it becomes
challenging to distinguish whether each unit in the representation space is treated or controlled, the repre-
sentations are believed adequately balanced. Consequently, the concept of representation balancing can be
intuitively understood as propensity confusion, which provides a logical interpretation and justiﬁcation for
minimizing theH-divergence-based error bound for ITE. In the following content, we will ﬁrst establish the
upper bounds for counterfactual error and ITE error utilizing the H-divergence, as stated in Theorem 2.
5Under review as submission to TMLR
Deﬁnition 3. Given a pair of distributions p1,p2overS, and a hypothesis binary function class H, the
H-divergence between p1andp2is deﬁned as
dH(p1,p2) := 2 sup
η∈H|Prp1[η(s) = 1]−Prp2[η(s) = 1]|. (5)
Theorem 2. LetΦ :X → R be an invertible representation with Ψbeing its inverse. Deﬁne
σ2
y= min{σ2
yt(p(x,t)),σ2
yt(p(x,1−t))}andAy= max{Ayt(p(x,t)),Ayt(p(x,1−t))} ∀t∈ {0,1},
whereσ2
yt(p(x,t)) =/integraltext
X×{ 0,1}×Y(yt−τt(x))2p(yt|x)p(x,t)dytdxdtandAyt(p(x,t)) =/integraltext
X×{ 0,1}×Y|yt−
τt(x)|p(yt|x)p(x,t)dytdxdt∀t∈{0,1}. LetpT=1
Φ(r),pT=0
Φ(r)be as deﬁned before, h:R×{ 0,1}→Y,
u:=Pr(T= 1)andHbe the family of binary functions. Assume that there exists a constant K≥0such
that/integraltext
YL(y,y/prime)dy≤K∀y/prime∈Y. IfLis a loss function that satisﬁes the triangle inequality, we have
/epsilon1CF(h,Φ)≤(1−u)·/epsilon1T=1
F(h,Φ) +u·/epsilon1T=0
F(h,Φ) +K
2dH(pT=1
Φ,pT=0
Φ). (6)
Let loss function Lbe the squared loss such that L(y1,y2) = (y1−y2)2. Then we have:
/epsilon1PEHE (h,Φ)≤2(/epsilon1T=1
F(h,Φ) +/epsilon1T=0
F(h,Φ) +K
2dH(pT=1
Φ,pT=0
Φ)−2σ2
y). (7)
Let loss function Lbe the absolute loss such that L(y1,y2) =|y1−y2|. Then we have:
/epsilon1PEHE (h,Φ)≤/epsilon1T=1
F(h,Φ) +/epsilon1T=0
F(h,Φ) +K
2dH(pT=1
Φ,pT=0
Φ) + 2Ay. (8)
The details of the proof of Theorem 2 are given in Theorem 2 in Appendix. Theorem 2 holds for forms of
Las long asLtakes forms that satisfy the triangle inequality. For example, we give the result for squared
loss in equation 7, and the result for absolute loss in equation 8. Note that detailed proofs of Theorem 2 in
Appendix suggest that our theoretical derivations are not trivial extensions from other H-divergence related
works (Ben-David et al., 2006; 2010; Ganin et al., 2016) and causal representation balancing works (Shalit
et al., 2017; Johansson et al., 2022), which is also one of our main theoretical contributions. We refer to a
model built on Theorem 2 as INetsince it is based on individual propensity confusion.
4 Method
In the preceding section, we presented theoretical results that guarantee the rationale behind representation
balancingmethodsrelyingonWassersteindistanceand H-divergence. MovingontoSection4.1, wewillbegin
by revisiting GNet, which can be considered as CFRNet Shalit et al. (2017), a Wasserstein distance-based
representation balancing network. Additionally, we will demonstrate how Theorem 2 can be connected with
propensity confusion, leading us to introduce INet, a H-divergence-based representation balancing network.
Subsequently, inSection4.2, we willintroducethePDIGand PPBRcomponentsforrepresentationbalancing
within the scheme of decomposed patterns. Building upon GNet, INet, PPBR, and PDIG, we will design
DIGNet, a novel representation balancing network with decomposed patterns.
4.1 Representation Balancing without decomposed Patterns
In representation balancing models, given the input data tuples (x,t,y) ={(xi,ti,yi)}N
i=1, the original
covariates xare extracted by some representation function Φ(·), and representations Φ(x)are then fed
into the outcome functions h1(·) :=h(·,1)andh0(·) :=h(·,0)that estimate the potential outcome y1and
y0, respectively. Finally, the factual outcome can be predicted by ht(·) =th1(·) + (1−t)h0(·), and the
corresponding outcome loss is
Ly(x,t,y; Φ,ht) =1
NN/summationdisplay
i=1L(ht(Φ(xi)),yi). (9)
If models such as GNet and INet do not have decomposition modes, both outcome prediction and represen-
tation balancing will rely on the extracted features Φ(x). Below we will introduce the objectives of GNet
and INet.
6Under review as submission to TMLR
Objective of GNet. GNet learns the balancing patterns over Φby minimizing the group distance loss
LG(x,t; Φ) =Wass ({Φ(xi)}i:ti=0,{Φ(xi)}i:ti=1). If the original covariates xare extracted by the feature
extractor ΦE(·), then the ﬁnal objective of GNet is
min
ΦE,htLy(x,t,y; ΦE,ht) +α1LG(x,t; ΦE). (10)
For the convenience of the reader, we illustrate the structure of GNet in Figure 2(a).
Objective of INet. Next, we detail how Theorem 2 is related to propensity confusion and give the
objective of INet. Let I(a)be an indicator function that gives 1ifais true, andHbe the family of binary
functions as deﬁned in Theorem 2. The representation balancing seeks to minimize empirical H-divergence
ˆdH(pT=1
Φ,pT=0
Φ)such that
ˆdH(pT=1
Φ,pT=0
Φ) = 2
1−min
η∈H
1
N/summationdisplay
i:η(Φ(xi))=0I[ti= 1] +1
N/summationdisplay
i:η(Φ(xi))=1I[ti= 0]

.(11)
The “min” part in equation 11 indicates that the optimal classiﬁer η∗∈Hminimizes the classiﬁcation
error between the estimated treatment η∗(Φ(xi))and the observed treatment ti, i.e., discriminating whether
Φ(xi)is controlled ( T= 0) or treated ( T= 1). As a result, ˆdH(pT=1
Φ,pT=0
Φ)will be large if η∗can easily
distinguish whether Φ(xi)is treated or controlled, i.e., the optimal classiﬁcation error is small. In contrast,
ˆdH(pT=1
Φ,pT=0
Φ)will be small if it is hard for η∗to determine whether Φ(xi)is treated or controlled, i.e., the
optimal classiﬁcation error is large. Therefore, the prerequisite of a small H-divergence is to ﬁnd a map Φ
such that any classiﬁer η∈Hwill get confused about the probability of Φ(xi)being treated or controlled. To
achieve this goal, we deﬁne a discriminator π(r) :R→ [0,1]that estimates the propensity score of r,which
can be regarded as a surrogate for η(r). The classiﬁcation error for the ithindividual can be empirically
approximated by the cross-entropy loss between π(Φ(xi))andti:
Lt(ti,π(Φ(xi))) =−[tilogπ(Φ(xi)) + (1−ti) log(1−π(Φ(xi)))]. (12)
As a consequence, we aim to ﬁnd an optimal discriminator π∗for equation 11 such that π∗maximizes the
probability that treatment is correctly classiﬁed of the total population:
max
π∈HLI(x,t; Φ,π) = max
π∈H/bracketleftBigg
−1
NN/summationdisplay
i=1Lt(ti,π(Φ(xi)))/bracketrightBigg
. (13)
Given the feature extractor ΦE(·), the objective of INet can be formulated as a min-max game:
min
ΦE,htmax
πLy(x,t,y; ΦE,ht) +α2LI(x,t; ΦE,π). (14)
As stated in equation 14, INet achieves the representation balancing through a min-max formulation, fol-
lowing a strategy of empirical approximation of H-divergence in Ganin et al. (2016). In the maximization,
the discriminator πis trained to maximize the probability that treatment is correctly classiﬁed. This forces
π(ΦE(xi))closer to the true propensity score e(xi). In the minimization, the feature extractor ΦEis trained
to fool the discriminator π. This confuses πsuch thatπ(ΦE(xi))cannot correctly specify the true propensity
scoree(xi). Eventually, the representations are balanced as it is diﬃcult for πto determine the propensity
ofΦ(xi)being treated or controlled. For the convenience of the reader, we illustrate the structure of INet
in Figure 2(b).
4.2 Representation Balancing with Decomposed Patterns
PDIG. Previous demonstrations have shown that GNet is thriving and widely adopted, while INet is
meaningful and interpretable. Nevertheless, they still face the trade-oﬀ between representation balancing
and outcome modeling. To this end, we expect to capture more eﬀective balancing patterns by turning the
7Under review as submission to TMLR
Φ𝐺𝐺
(a) GNet (CFR-Wass) (b) INet (c) DGNet (d) DINet (e) DIGNetΦ𝐸𝐸Φ𝐼𝐼
𝜋𝜋𝜋𝜋𝜋𝜋Φ𝐸𝐸
Φ𝐼𝐼Φ𝐸𝐸 Φ𝐸𝐸Φ𝐸𝐸
Φ𝐺𝐺
Figure 2: Illustrations of the network architecture of the ﬁve models studied in Section 5.
balancing Patterns into Decompositions of Individual propensity confusion and Group distance minimization
(PDIG). More speciﬁcally, the covariates xare extracted by the feature extractor ΦE(·), and then ΦE(x)are
fed into the balancing networks ΦG(·)andΦI(·)for group distance minimization and individual propensity
confusion, respectively. Finally, the losses for the two separate balancing patterns are
min
ΦGLG(x,t; ΦG◦ΦE),
min
ΦImax
πLI(x,t; ΦI◦ΦE,π). (15)
Here,◦denotes the composition of two functions, indicating that Φ(·)inLG(x,t; Φ)andLI(x,t; Φ,π)are
replaced by ΦG(ΦE(·))andΦI(ΦE(·)), respectively.
PPBR. Motivated by the discussion in Section 1, we aim to design a framework that is capable of captur-
ing Patterns of Pre-balancing and Balancing Representations (PPBR) to improve outcome modeling. To this
end, therepresentationbalancingpatterns ΦG(ΦE(x))andΦI(ΦE(x))areﬁrstlearnedover ΦGandΦI, while
ΦEis remained ﬁxed as pre-balancing patterns. Furthermore, we concatenate the balancing representations
ΦG(ΦE(x))andΦI(ΦE(x))with the pre-balancing representations ΦE(x)as attributes for outcome predic-
tion. Asaresult, theproxyfeaturesusedforoutcomepredictionsare ΦE(x)⊕ΦG(ΦE(x))⊕ΦI(ΦE(x)), where
⊕indicates the concatenation by column. For example, if a= [1,2]andb= [3,4], then a⊕b= [1,2,3,4].
ObjectiveofDIGNet. CombiningwithPDIGandPPBR,weproposeanewmodelarchitecture, DIGNet,
as illustrated in Figure 2(e). The objective of DIGNet is separated into four stages:
min
ΦGα1LG(x,t; ΦG◦ΦE), (16)
max
πα2LI(x,t; ΦI◦ΦE,π), (17)
min
ΦIα2LI(x,t; ΦI◦ΦE,π), (18)
min
ΦE,ΦI,ΦG,htLy(x,t,y; ΦE⊕(ΦI◦ΦE)⊕(ΦG◦ΦE),ht). (19)
Within each iteration, DIGNet manages to minimize the group distance via equation 16, and plays an
adversarial game to achieve propensity confusion through equation 17 and equation 18. In equation 19,
DIGNet updates both the pre-balancing and balancing patterns ΦE,ΦI,ΦGalong with the outcome function
htto minimize the outcome prediction loss.
DGNet and DINet. For further ablation studies, we also designed two models, DGNet and DINet. The
twomodelscanbeconsideredaseitherDIGNetwithoutPDIG,orGNetandINetwithPPBR.Thestructures
of DGNet and DINet are shown in Figure 2(c) and Figure 2(d), and the objectives of DGNet and DINet are
deferred to Section A.6 in Appendix.
5 Experiments
In non-randomized observational data, the ground truth regarding treatment eﬀects remains inaccessible
due to the absence of counterfactual information. Therefore, we use simulated data and semi-synthetic
8Under review as submission to TMLR
Figure 3: T-SNE visualizations of the covariates as γvaries. Red represents the treatment group and blue
represents the control group. A larger γindicates a greater imbalance between the two groups.
benchmark data to test the performance of our methods and other baseline models. In this section, our
primary focus revolves around addressing two key questions:
Q1.Is PDIG helpful in ITE estimation by learning more eﬀective balancing patterns without aﬀecting
factual outcome prediction? In other words, can DIGNet which incorporates the PDIG structure achieve
superior ITE estimation performances with more balanced representations compared to DGNet and DINet?
Q2.Is PPBR helpful in ITE estimation by improving factual outcome prediction without aﬀecting learning
balancing patterns? In other words, can DGNet and DINet that involve PPBR enhance ITE estimation
performances with smaller factual outcome errors compared to standard representation balancing models
such as GNet and INet?
5.1 Experimental Settings
Simulation data. Previous causal inference works assess the model eﬀectiveness by varying the distribu-
tion imbalance of covariates in treated and controlled groups at diﬀerent levels Yao et al. (2018); Yoon et al.
(2018); Du et al. (2021). As suggested in Assaad et al. (2021), we draw 1000observational data points from
the following data generating strategy:
Xi∼N(0,σ2·[ρ1p1/prime
p+ (1−ρ)Ip]),
Ti|Xi∼Bernoulli (1/(1 + exp(−γXi))),
Y0
i=β/prime
0Xi+ξi, Y1
i=β/prime
1Xi+ξi, ξi∼N(0,1).
Here, 1pdenotes the p-dimensional all-ones vector and Ipdenotes the identity matrix of size p. We ﬁx
p= 10,ρ= 0.3,σ2= 2,β/prime
0= [0.3,...,0.3],β/prime
1= [1.3,...,1.3]and varyγ∈{0.25,0.5,0.75,1,1.5,2,3}to yield
diﬀerent levels of selection bias. As seen in Figure 3, selection bias becomes more severe with γincreasing.
For eachγ, we repeat the above data generating process to generate 30diﬀerent datasets, with each dataset
split by the ratio of 56%/24%/20%as training/validation/test sets.
Semi-synthetic data. The IHDP dataset is introduced by Hill (2011). This dataset consists of 747
samples with 25-dimensional covariates collected from real-world randomized experiments. Selection bias is
created by removing some of treated samples. The goal is to estimate the eﬀect of special visits (treatment)
on cognitive scores (outcome). The potential outcomes are generated using the NPCI package Dorie (2021).
We use the same 1000datasets as used in Shalit et al. (2017), with each dataset split by the ratio of
63%/27%/10%as training/validation/test sets.
Models and metrics. In simulation experiments, we perform comprehensive comparisons between INet,
GNet, DINet, DGNet, and DIGNet in terms of the mean and standard error for the following metrics:√/epsilon1PEHE,√/epsilon1CF, and√/epsilon1FwithLdeﬁned in Deﬁnition 1 being the squared loss, as well as the empirical
approximations of Wass (pT=1
Φ,pT=0
Φ)anddH(pT=1
Φ,pT=0
Φ)(denoted by Wassand ˆdH, respectively). Note
that as shown in Figure 2, Wassis over ΦEfor GNet while over ΦGfor DGNet and DIGNet; ˆdHis over
ΦEfor INet while over ΦIfor DINet and DIGNet. To analyze the source of gain in simulation studies, we
fairly compare models by ensuring that each model shares the same hyperparameters, e.g., learning rate,
the number of layers and units for (ΦE,ΦG,ΦI,ft), and (α1,α2). Note that we apply an early stopping
9Under review as submission to TMLR
Figure 4: Plots of model performances on test set for diﬀerent metrics as γvaries in
{0.25,0.5,0.75,1,1.5,2,3}. Each graph shows the average of 30runs with standard errors shaded.
Figure 5: Plots of model performances on test set for√/epsilon1F,√/epsilon1CF,ˆdH, andWasswhenγ= 3. Each graph
plots the metric for 30runs. Mean±std of each metric averaged across 30runs are reported on the top.
rule to all models as Shalit et al. (2017) do. In IHDP experiment, we use√/epsilon1PEHE, as well as an additional
metric/epsilon1ATE =|ˆτATE−τATE|to evaluate performances of various causal models (see them in Table 3). More
descriptions of the implementation details, as well as the analysis of training time and training stability, are
detailed in Section A.5 of Appendix.
Device. All the experiments are run on Dell 7920 with one 16-core Intel Xeon Gold 6250 3.90GHz CPU
and three NVIDIA Quadro RTX 6000 GPUs.
5.2 Results and Analysis
Varying selection bias. We ﬁrst make a general comparison between models with the degree of covariate
imbalance increasing, and the relevant results are shown in Figure 4. There are four main observations:
1. DIGNet attains the lowest√/epsilon1PEHEacross all datasets, while GNet have inferior performances than
other models;
2. DINet and DGNet outperform INet and GNet regarding√/epsilon1CFand√/epsilon1PEHE;
3. INet, DINet, and DGNet perform similarly to DIGNet on factual outcome estimations (√/epsilon1F), but
cannot compete with DIGNet in terms of counterfactual estimations (√/epsilon1CF);
4. DIGNet achieves smaller ˆdH(orWass) than DINet and INet (or DGNet and GNet), especially when
the covariate shift problem is severe (e.g., when γ >1).
In conclusion, the above study has produced several noteworthy ﬁndings. Firstly, ﬁnding (1) reveals that
our proposed DIGNet model consistently performs well in ITE estimation. Secondly, as indicated by ﬁnding
(2), implementing the PPBR approach can enhance the predictive accuracy of factual and counterfactual
outcomes. Lastly, ﬁndings (3) and (4) highlight the role of PDIG structure in promoting the simultaneous
reinforcement and complementarity of group distance minimization and individual propensity confusion.
10Under review as submission to TMLR
Figure 6: Plots of model performances on test set for diﬀerent metrics when γ= 3. Each graph plots the
metric for 30runs, with mean±std averaged across 30runs reported on the top.
Table 1: Training- & test- set√/epsilon1PEHE&/epsilon1ATEwhen
γ= 3. Mean±standard error of 30runs.
Training set Test set√/epsilon1PEHE /epsilon1ATE√/epsilon1PEHE /epsilon1ATE
GNet 3.30±0.15 2.58±0.14 3.30±0.16 2.59±0.14
INet 3.24±0.11 2.46±0.09 3.22±0.12 2.47±0.10
DGNet 2.86±0.06 2.15±0.03 2.83±0.07 2.15±0.04
DINet 2.70±0.06 2.12±0.04 2.69±0.08 2.13±0.05
DIGNet 2.66±0.07 2.04±0.05 2.63±0.07 2.03±0.04Table 2: Training- & test- set√/epsilon1PEHE&/epsilon1ATEon
IHDP. Mean±standard error of 100runs.
Training set Test set√/epsilon1PEHE /epsilon1ATE√/epsilon1PEHE /epsilon1ATE
GNet 0.71±0.15 0.12±0.01 0.77±0.18 0.15±0.02
INet 0.66±0.09 0.13±0.01 0.72±0.11 0.15±0.02
DGNet 0.53±0.07 0.11±0.01 0.60±0.09 0.13±0.01
DINet 0.57±0.12 0.13±0.01 0.60±0.11 0.14±0.01
DIGNet 0.42±0.02 0.11±0.01 0.45±0.04 0.12±0.01
Movingforward, oursubsequentanalysiswillstepfurtherintounderstandingtheeﬀectivenessofourproposed
methods, building upon these preliminary conclusions.
Source of gain. To further investigate the above ﬁndings, we choose the case with high selection bias
(γ= 3) to explore the source of gain for PDIG and PPBR. We report model performances (mean ±std)
averaged over 30training and test sets in Table 1 and plot speciﬁc metrics of 30runs on test set in Figure
5 and Figure 6. Below we discuss the source of gain in detail.
(1) Ablation study for PDIG : The PDIG structure is manifest to be eﬀective in capturing more balanced
patterns, without aﬀecting factual outcome predictions. As depicted in Figure 4, DIGNet exhibits more bal-
anced representations, irrespective of whether the discrepancy is measured by ˆdHorWass, while DIGNet,
DINet, and DGNet demonstrate comparable estimates of factual outcomes (√/epsilon1F). In particular, by com-
paring DIGNet with DGNet and DINet in Figure 5, we ﬁnd that the PDIG structure does not aﬀect the
factual outcome estimation (√/epsilon1F). Nevertheless, DIGNet achieves smaller ˆdHwith a|1.94/1.96−1|= 1.0%
reduction (or Wasswith a|0.06/0.10−1|= 40%reduction) compared with DINet (or DGNet). This indi-
cates that PDIG enables group distance minimization and individual propensity confusion to complement
and reinforce each other, thereby learning better balancing patterns. This advantage translates into superior
counterfactualestimation, withDIGNetreduceing√/epsilon1CFby|2.89/2.95−1|= 2.0%and|2.89/3.08−1|= 6.2%
compared to DINet and DGNet, respectively. Consequently, due to the eﬀective capture of balancing pat-
terns by PDIG, DIGNet shows superiority in treatment eﬀect estimation (√/epsilon1PEHEand/epsilon1ATE) compared to
DGNet and DINet, as demonstrated in Table 1.
(2) Ablation study for PPBR : ThePPBRapproachplaysanessentialroleinimprovingoutcomepredictions,
withoutaﬀectinglearningbalancingpatterns. FromFigure6, wegainanimportantinsightthatthediﬀerence
in learned representation balancing patterns, measured by Wass(orˆdH), between DGNet and GNet (or
DINet and INet), is negligible. This implies that PPBR does not impact the representation balancing task.
However, PPBR can improve the predictive power of factual outcomes, resulting in a |1.07/1.12−1|= 4.5%
reduction in√/epsilon1Ffor GNet and a|1.07/1.08−1|= 0.9%reduction for INet. Notably, this improvement is
particularly pronounced in counterfactual estimation, where√/epsilon1CFis reduced by|3.08/3.55−1|= 13.2%for
GNet and|2.95/3.47−1|= 15.0%for INet. Beneﬁting from the advantage of PPBR, the treatment eﬀect
errors (√/epsilon1PEHEand/epsilon1ATE) attained by DINet and DGNet are signiﬁcantly smaller than those attained by
INet and GNet, as shown in Table 1.
11Under review as submission to TMLR
Comparisons on IHDP benchmark. We ﬁrst conduct an ablation study for PDIG and PPBR on 1-100
IHDP datasets and report the results in Table 2. Further, we undergo comparisons between DIGNet and
other causal models on 1-1000 IHDP datasets and report the results in Table 3. Note that “-” indicates either
the result is not reproducible or the original paper does not report relevant values. Table 2 shows that DINet
and DGNet are superior to INet and GNet but inferior to DIGNet concerning treatment eﬀect estimation,
suggesting that each component of PDIG and PPBR is advantageous for treatment eﬀect estimation. For
example, on the test set, DINet reduces√/epsilon1PEHEby|0.60/0.72−1|= 16.7%for INet, and DIGNet achieves
|0.45/0.60−1|= 25%error reduction regarding√/epsilon1PEHEfor DINet. This is consistent with the ﬁndings
before: PPBR and PDIG are beneﬁcial to treatment eﬀect estimation. Table 3 demonstrates that models
that involve either propensity score or representation balancing (e.g., DKLITE, CFR-X, BWCFR-X, and
MBRL) attain√/epsilon1PEHEand/epsilon1ATEof0.57∼0.70and0.13∼0.19, respectively. Compared to the second-
best method, DIGNet improves performance by |0.45/0.57−1|= 21%and|0.12/0.13−1|= 7.7%regarding√/epsilon1PEHEand/epsilon1ATE, respectively, revealingtheprominentoutperformanceoftheproposedmethod. Moreover,
itisnoticeablethatDIGNetachievesthelowesterrorsoverwhelminglyacrossdatasetsandmetrics, indicating
that the proposed method has the most robust performance.
6 Conclusion
Table 3: Training- & test- set√/epsilon1PEHE&/epsilon1ATEon IHDP. Mean ±
standard error of 1000runs.
Training set Test set√/epsilon1PEHE/epsilon1ATE√/epsilon1PEHE/epsilon1ATE
OLS/LR 1(Johansson et al., 2016) 5.8±.3.73±.04 5.8±.3.94±.06
OLS/LR 2(Johansson et al., 2016) 2.4±.1.14±.01 2.5±.1.31±.02
k-NN (Crump et al., 2008) 2.1±.1.14±.01 4.1±.2.79±.05
BART (Chipman et al., 2010) 2.1±.1.23±.01 2.3±.1.34±.02
CF (Wager & Athey, 2018) 3.8±.2.18±.01 3.8±.2.40±.03
CEVAE (Louizos et al., 2017) 2.7±.1.34±.01 2.6±.1.46±.02
SITE (Yao et al., 2018) .69±.0.22±.01.75±.0.24±.01
GANITE (Yoon et al., 2018) 1.9±.4.43±.05 2.4±.4.49±.05
BLR (Johansson et al., 2016) 5.8±.3.72±.04 5.8±.3.93±.05
BNN (Johansson et al., 2016) 2.2±.1.37±.03 2.1±.1.42±.03
TARNet (Shalit et al., 2017) .88±.0.26±.01.95±.0.28±.01
CFR-Wass (GNet) (Shalit et al., 2017) .73±.0.12±.01.81±.0.15±.01
Dragonnet (Shi et al., 2019) 1.3±.4.14±.01 1.3±.5.20±.05
DKLITE (Zhang et al., 2020) .52±.0−.65±.03−
CFR-ISW (Hassanpour & Greiner, 2019a) − − .70±.0.19±.03
BWCFR-OW (Assaad et al., 2021) − − .65±.0.18±.01
BWCFR-MW (Assaad et al., 2021) − − .63±.0.19±.01
BWCFR-TruncIPW (Assaad et al., 2021) − − .63±.0.19±.01
MBRL (Huang et al., 2022a) .52 ±.0 .12±.01 .57±.0 .13±.01
DIGNet (Ours) .42±.0.11±.01.45±.0.12±.01In this paper, we derive a the-
oretical ITE bound based on H-
divergence and connect representa-
tion balancing with the concept of
propensity confusion. More impor-
tantly, we propose the components
of PDIG and PPBR, on which we
construct a decomposition network
structure DIGNet for treatment ef-
fect estimation. Comprehensive ex-
periments verify that PDIG and
PPBR follow diﬀerent pathways to
improve the generalization of coun-
terfactual and ITE estimation, and
such improvements are conﬁrmed
to be very signiﬁcant. In particu-
lar, PDIG helps the model capture
more eﬀective representation bal-
ancing patterns without aﬀecting
outcome prediction, while PPBR
preservespatternspredictiveof out-
comes to enhance the outcome pre-
diction without inﬂuencing learning balancing patterns. We sincerely hope that our ﬁndings can constitute
an important step to inspire more research concerning the generalization of representation balancing models
in counterfactual estimation.
Our paper primarily oﬀers eﬀective empirical solutions to address the trade-oﬀ challenge between domain
invariance and domain discrimination given the absence of a well-established theoretical solution in the
current research ﬁeld. Therefore, it is also important to step beyond these empirical insights into future
theoretical studies aimed at resolving the trade-oﬀ problem. A promising avenue for future theoretical
investigations involves the development of new distributional divergences or theoretical upper bounds that
can robustly handle the trade-oﬀ issue. Exploring the integration of distributionally robust optimization and
nonparametric inference methods in this context would be intriguing. Furthermore, deriving an upper bound
with an analytically optimal solution to the trade-oﬀ problem could be valuable, albeit possibly requiring
additional assumptions. Empirical studies can focus on discouraging the redundancy of shared information
within the PDIG structure and improving the optimization eﬃcacy of DIGNet’s objective.
12Under review as submission to TMLR
References
Serge Assaad, Shuxi Zeng, Chenyang Tao, Shounak Datta, Nikhil Mehta, Ricardo Henao, Fan Li, and
Lawrence Carin. Counterfactual representation learning with balancing weights. In International
Conference onArtiﬁcial Intelligence andStatistics, pp. 1972–1980. PMLR, 2021.
Susan Athey and Stefan Wager. Estimating treatment eﬀects with causal forests: An application.
Observational Studies, 5(2):37–51, 2019.
Shai Ben-David, John Blitzer, Koby Crammer, and Fernando Pereira. Analysis of representations for domain
adaptation. Advances inneuralinformation processing systems, 19, 2006.
Shai Ben-David, John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira, and Jennifer Wortman
Vaughan. A theory of learning from diﬀerent domains. Machine learning, 79(1):151–175, 2010.
Ioana Bica, Ahmed M Alaa, Craig Lambert, and Mihaela Van Der Schaar. From real-world patient data to
individualized treatment eﬀects using machine learning: current and future methods to address underlying
challenges. ClinicalPharmacology &Therapeutics, 109(1):87–100, 2021a.
Ioana Bica, Daniel Jarrett, Alihan Hüyük, and Mihaela van der Schaar. Learning ”what-if” explanations
for sequential decision-making. In International Conference onLearning Representations, 2021b. URL
https://openreview.net/forum?id=h0de3QWtGG .
Victor Chernozhukov, Denis Chetverikov, Mert Demirer, Esther Duﬂo, Christian Hansen, Whitney Newey,
and James Robins. Double/debiased machine learning for treatment and structural parameters. The
Econometrics Journal, 21(1):C1–C68, 2018.
Hugh A Chipman, Edward I George, and Robert E McCulloch. Bart: Bayesian additive regression trees.
TheAnnalsofApplied Statistics, 4(1):266–298, 2010.
Zhixuan Chu, Stephen L. Rathbun, and Sheng Li. Graph infomax adversarial learning for treatment eﬀect
estimation with networked observational data. In KDD, pp. 176–184, 2021. URL https://doi.org/10.
1145/3447548.3467302 .
RichardKCrump, VJosephHotz, GuidoWImbens, andOscarAMitnik. Nonparametrictestsfortreatment
eﬀect heterogeneity. TheReviewofEconomics andStatistics, 90(3):389–405, 2008.
Alicia Curth and Mihaela van der Schaar. On inductive biases for heterogeneous treatment eﬀect estimation.
Advances inNeuralInformation Processing Systems, 34:15883–15894, 2021.
Alicia Curth, David Svensson, Jim Weatherall, and Mihaela van der Schaar. Really doing great at estimating
cate? acriticallookatmlbenchmarkingpracticesintreatmenteﬀectestimation. In Thirty-ﬁfth conference
onneuralinformation processing systemsdatasets andbenchmarks track(round2), 2021.
Marco Cuturi and Arnaud Doucet. Fast computation of wasserstein barycenters. In International conference
onmachine learning, pp. 685–693. PMLR, 2014.
Vincent Dorie. Nonparametric methods for causal inference. https://github.com/vdorie/npci, 2021.
Xin Du, Lei Sun, Wouter Duivesteijn, Alexander Nikolaev, and Mykola Pechenizkiy. Adversarial balancing-
based representation learning for causal eﬀect inference with observational data. DataMiningand
Knowledge Discovery, 35(4):1713–1738, 2021.
MaxHFarrell. Robustinferenceonaveragetreatmenteﬀectswithpossiblymorecovariatesthanobservations.
JournalofEconometrics, 189(1):1–23, 2015.
Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo Larochelle, François Laviolette,
Mario Marchand, and Victor Lempitsky. Domain-adversarial training of neural networks. Thejournalof
machine learning research, 17(1):2096–2030, 2016.
13Under review as submission to TMLR
Ruocheng Guo, Lu Cheng, Jundong Li, P Richard Hahn, and Huan Liu. A survey of learning causality with
data: Problems and methods. ACMComputing Surveys(CSUR), 53(4):1–37, 2020a.
Ruocheng Guo, Jundong Li, Yichuan Li, K Selçuk Candan, Adrienne Raglin, and Huan Liu. Ignite: A
minimax game toward learning individual treatment eﬀects from networked observational data. In IJCAI,
pp. 4534–4540, 2020b.
Ruocheng Guo, Jundong Li, and Huan Liu. Learning individual causal eﬀects from networked observational
data. In Proceedings ofthe13thInternational Conference onWebSearchandDataMining, pp. 232–240,
2020c.
Negar Hassanpour and Russell Greiner. Counterfactual regression with importance sampling weights. In
IJCAI, pp. 5880–5887, 2019a.
Negar Hassanpour and Russell Greiner. Learning disentangled representations for counterfactual regression.
InInternational Conference onLearning Representations, 2019b.
Jennifer L Hill. Bayesian nonparametric modeling for causal inference. Journal ofComputational and
Graphical Statistics, 20(1):217–240, 2011.
Yiyan Huang, Cheuk Hang Leung, Xing Yan, Qi Wu, Nanbo Peng, Dongdong Wang, and Zhixiang Huang.
The causal learning of retail delinquency. In Proceedings oftheAAAIConference onArtiﬁcial Intelligence,
volume 35, pp. 204–212, 2021.
Yiyan Huang, Cheuk Hang Leung, Shumin Ma, Qi Wu, Dongdong Wang, and Zhixiang Huang. Moderately-
balanced representation learning for treatment eﬀects with orthogonality information. In PaciﬁcRim
International Conference onArtiﬁcial Intelligence, pp. 3–16. Springer, 2022a.
YiyanHuang, CheukHangLeung, QiWu, XingYan, ShuminMa, ZhiriYuan, DongdongWang, andZhixiang
Huang. Robust causal learning for the estimation of average treatment eﬀects. In 2022International Joint
Conference onNeuralNetworks (IJCNN 2022). IEEE, 2022b.
GuidoWImbensandJeﬀreyMWooldridge. Recentdevelopmentsintheeconometricsofprogramevaluation.
Journalofeconomic literature, 47(1):5–86, 2009.
Fredrik Johansson, Uri Shalit, and David Sontag. Learning representations for counterfactual inference. In
International conference onmachine learning, pp. 3020–3029. PMLR, 2016.
Fredrik D. Johansson, Uri Shalit, Nathan Kallus, and David Sontag. Generalization bounds and repre-
sentation learning for estimation of potential outcomes and causal eﬀects. JournalofMachine Learning
Research, 23(166):1–50, 2022. URL http://jmlr.org/papers/v23/19-511.html .
Kun Kuang, Peng Cui, Bo Li, Meng Jiang, Shiqiang Yang, and Fei Wang. Treatment eﬀect estimation with
data-driven variable decomposition. In Proceedings oftheAAAIConference onArtiﬁcial Intelligence,
volume 31, 2017.
Sören R Künzel, Jasjeet S Sekhon, Peter J Bickel, and Bin Yu. Metalearners for estimating heterogeneous
treatment eﬀects using machine learning. Proceedings ofthenational academy ofsciences, 116(10):4156–
4165, 2019.
Mingsheng Long, Jianmin Wang, Guiguang Ding, Jiaguang Sun, and Philip S Yu. Transfer joint matching for
unsupervised domain adaptation. In Proceedings oftheIEEEconference oncomputer visionandpattern
recognition, pp. 1410–1417, 2014.
Christos Louizos, Uri Shalit, Joris M Mooij, David Sontag, Richard Zemel, and Max Welling. Causal eﬀect
inference with deep latent-variable models. Advances inneuralinformation processing systems, 30, 2017.
Maggie Makar, Fredrik Johansson, John Guttag, and David Sontag. Estimation of bounds on potential
outcomes for decision making. In International Conference onMachine Learning, pp. 6661–6671. PMLR,
2020.
14Under review as submission to TMLR
Xinkun Nie and Stefan Wager. Quasi-oracle estimation of heterogeneous treatment eﬀects. Biometrika, 108
(2):299–319, 2021.
Zhaozhi Qian, Yao Zhang, Ioana Bica, Angela Wood, and Mihaela van der Schaar. Synctwin: Treatment
eﬀect estimation with longitudinal outcomes. Advances inNeuralInformation Processing Systems, 34:
3178–3190, 2021.
Paul R Rosenbaum and Donald B Rubin. The central role of the propensity score in observational studies
for causal eﬀects. Biometrika, 70(1):41–55, 1983.
Donald B Rubin. Causal inference using potential outcomes: Design, modeling, decisions. Journalofthe
American Statistical Association, 100(469):322–331, 2005.
Shai Shalev-Shwartz and Shai Ben-David. Understanding machine learning: Fromtheorytoalgorithms.
Cambridge university press, 2014.
Uri Shalit, Fredrik D Johansson, and David Sontag. Estimating individual treatment eﬀect: generalization
bounds and algorithms. In International Conference onMachine Learning, pp. 3076–3085. PMLR, 2017.
Jian Shen, Yanru Qu, Weinan Zhang, and Yong Yu. Wasserstein distance guided representation learning for
domain adaptation. In Proceedings oftheAAAIConference onArtiﬁcial Intelligence, volume 32, 2018.
Claudia Shi, David Blei, and Victor Veitch. Adapting neural networks for the estimation of treatment eﬀects.
Advances inneuralinformation processing systems, 32, 2019.
Bharath K Sriperumbudur, Kenji Fukumizu, Arthur Gretton, Bernhard Schölkopf, and Gert RG Lanckriet.
On the empirical estimation of integral probability metrics. Electronic JournalofStatistics, 6:1550–1599,
2012.
Stefan Wager and Susan Athey. Estimation and inference of heterogeneous treatment eﬀects using random
forests.JournaloftheAmerican Statistical Association, 113(523):1228–1242, 2018.
Liuyi Yao, Sheng Li, Yaliang Li, Mengdi Huai, Jing Gao, and Aidong Zhang. Representation learning for
treatment eﬀect estimation from observational data. Advances inNeuralInformation Processing Systems,
31, 2018.
Liuyi Yao, Zhixuan Chu, Sheng Li, Yaliang Li, Jing Gao, and Aidong Zhang. A survey on causal inference.
ACMTransactions onKnowledge Discovery fromData(TKDD), 15(5):1–46, 2021.
Jinsung Yoon, James Jordon, and Mihaela Van Der Schaar. Ganite: Estimation of individualized treatment
eﬀects using generative adversarial nets. In International Conference onLearning Representations, 2018.
Yao Zhang, Alexis Bellot, and Mihaela Schaar. Learning overlapping representations for the estimation of
individualized treatment eﬀects. In International Conference onArtiﬁcial Intelligence andStatistics, pp.
1005–1014. PMLR, 2020.
Guanglin Zhou, Lina Yao, Xiwei Xu, Chen Wang, and Liming Zhu. Cycle-balanced representation learning
for counterfactual inference. In Proceedings ofthe2022SIAMInternational Conference onDataMining
(SDM), pp. 442–450. SIAM, 2022.
A Appendix
A.1 Preliminaries
We start by making some assumptions about the distribution we concern, and give some necessary deﬁnitions
and results. We make the strong ignorability assumption, which assume that there exists a joint distribution
p(X,T,Y0,Y1)such that conditioning on covariate X, the potential outcomes Y0,Y1are independent of T,
i.e.,(Y0,Y1)⊥ ⊥T|X, and the propensity score e(x) :=p(T= 1|X=x)is bounded away from 0 to 1, i.e.
15Under review as submission to TMLR
0<e(x)<1. Recall that we also assume consistency, i.e., if the treatment is t, the observed outcome equals
Yt. These assumptions are crucial conditions that make individual treatment eﬀect identiﬁable (Imbens &
Wooldridge, 2009).
Deﬁnition 1. The individual treatment eﬀect (ITE) for unit xis:
τ(x) =E/bracketleftbig
Y1−Y0|X=x/bracketrightbig
.
Letτt(x) :=E[Yt|X=x], we haveτ(x) =τ1(x)−τ0(x). Letf:X×{ 0,1}→Ybe a prediction function.
Deﬁnition 2. The individual treatment eﬀect estimate can be deﬁned as:
ˆτf(x) :=f(x,1)−f(x,0).
Deﬁnition 3. (Hill, 2011) Let L:Y×Y→ R+be a loss function. The expected Precision in Estimation of
Heterogeneous Eﬀect (PEHE) loss of fis:
/epsilon1PEHE (f) =/integraldisplay
XL(ˆτf(x),τ(x))p(x)dx.
Deﬁnition4. The covariates’ distributions in the treated and controlled groups can be denoted by pT=1(x) :=
p(x|T= 1)andpT=0(x) :=p(x|T= 0), respectively.
In our causal representation balancing approach, we assume that the representation function Φ :X→Ris
a twice-diﬀerentiable, one-to-one function, where R⊂Rdis the representation space. Then, we can denote
Ψ :R→Xby the inverse of Φand the induced distribution of rbypΦ.
Deﬁnition 5. The covariates’ distributions in the treated and controlled groups over Rcan be denoted by
pT=1
Φ(r) :=pΦ(r|T= 1)andpT=0
Φ(r) :=pΦ(r|T= 0), respectively.
Leth:R×{ 0,1}→Ybe an hypothesis deﬁned over the representation space R, such that f(x,t) =
h(Φ(x),t).
Deﬁnition 6. The expected loss for the unit and treatment pair (x,t)is :
/lscripth,Φ(x,t) =/integraldisplay
YL(yt,h(Φ(x),t))p(yt|x)dyt.
Deﬁnition 7. The expected factual loss and counterfactual losses of handΦare, respectively:
/epsilon1F(h,Φ) =/integraldisplay
X×{ 0,1}/lscripth,Φ(x,t)p(x,t)dxdt,
/epsilon1CF(h,Φ) =/integraldisplay
X×{ 0,1}/lscripth,Φ(x,t)p(x,1−t)dxdt.
Deﬁnition 8. The expected treated and control losses are:
/epsilon1T=1
F(h,Φ) =/integraldisplay
X/lscripth,Φ(x,1)pT=1(x)dx,
/epsilon1T=0
F(h,Φ) =/integraldisplay
X/lscripth,Φ(x,0)pT=0(x)dx,
/epsilon1T=1
CF(h,Φ) =/integraldisplay
X/lscripth,Φ(x,1)pT=0(x)dx,
/epsilon1T=0
CF(h,Φ) =/integraldisplay
X/lscripth,Φ(x,0)pT=1(x)dx.
Letu:=Pr(T= 1)be the proportion of treated in the population. We then have the result:
16Under review as submission to TMLR
Lemma 1.
/epsilon1F(h,Φ) =u·/epsilon1T=1
F(h,Φ) + (1−u)·/epsilon1T=0
F(h,Φ),
/epsilon1CF(h,Φ) = (1−u)·/epsilon1T=1
CF(h,Φ) +u·/epsilon1T=0
CF(h,Φ).
Noting that p(x,t) =u·pT=1(x) + (1−u)·pT=0(x), the results can be easily obtained from the Deﬁnitions
7 and 8. This Lemma follows the results in Shalit et al. (2017).
Deﬁnition 9. LetGbe a function family consisting of functions g:S→R. For a pair of distributions p1,
p2overS, deﬁne the Integral Probability Metric:
IPMG(p1,p2) = sup
g∈G|/integraldisplay
Sg(s)(p1(s)−p2(s))ds|.
LetGbe the family of 1-Lipschitz functions, we obtain the so-called 1-Wasserstein distance between distri-
butions, which we denote Wass (p1,p2)(Sriperumbudur et al., 2012).
Deﬁnition 10. Given a pair of distributions p1,p2overS, and a hypothesis binary function class H, the
H-divergence between p1andp2is
dH(p1,p2) = 2supη∈H|Prp1[η(s) = 1]−Prp2[η(s) = 1]|.
Lemma 2. LetGin Deﬁnition 9 be the family of binary functions. Then we obtain
supη∈H/vextendsingle/vextendsingle/integraltext
Sη(s)(p1(s)−p2(s))ds/vextendsingle/vextendsingle=1
2dH(p1,p2).
Proof.LetI(·)denotes an indicator function.
dH(p1,p2)
=2 sup
η∈H/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/integraldisplay
η(s)=1(p1(s)−p2(s))ds/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle
=2 sup
η∈H/vextendsingle/vextendsingle/vextendsingle/vextendsingle/integraldisplay
SI(η(s) = 1)(p1(s)−p2(s))ds/vextendsingle/vextendsingle/vextendsingle/vextendsingle
=2 sup
η∈H/vextendsingle/vextendsingle/vextendsingle/vextendsingle/integraldisplay
Sη(s)(p1(s)−p2(s))ds/vextendsingle/vextendsingle/vextendsingle/vextendsingle(20)
The last equation is because an indicator function is also a binary function.
A.2 Bounds for conterfactual error /epsilon1CF
We ﬁrst derive the counterfactual error bounds when using Wasserstein distance. The following Lemma 3
and corresponding proof is identical to the Lemma 1 in (Shalit et al., 2017).
Lemma 3. LetΦ :X→Rbe an invertible representation with Ψbeing its inverse. Let pT=1
Φ(r),pT=0
Φ(r)
be as deﬁned before. Let h:R×{ 0,1}→Y,u:=Pr(T= 1)andGbe the family of 1-Lipschitz functions.
Assume there exists a constant BΦ≥0, such that for t= 0,1, the function gΦ,h(r,t) :=1
BΦ·/lscripth,Φ(Ψ(r),t)∈G.
Then we have:
/epsilon1CF(h,Φ)≤(1−u)·/epsilon1T=1
F(h,Φ) +u·/epsilon1T=0
F(h,Φ) +BΦ·Wass (pT=1
Φ,pT=0
Φ).
17Under review as submission to TMLR
Proof.
/epsilon1CF(h,Φ)−[(1−u)·/epsilon1T=1
F(h,Φ) +u·/epsilon1T=0
F(h,Φ)]
=[(1−u)·/epsilon1T=1
CF(h,Φ) +u·/epsilon1T=0
CF(h,Φ)]−[(1−u)·/epsilon1T=1
F(h,Φ) +u·/epsilon1T=0
F(h,Φ)]
=(1−u)·[/epsilon1T=1
CF(h,Φ)−/epsilon1T=1
F(h,Φ)] +u·[/epsilon1T=0
CF(h,Φ)−/epsilon1T=0
F(h,Φ)]
=(1−u)/integraldisplay
X/lscripth,Φ(x,1)(pT=0(x)−pT=1(x))dx+u/integraldisplay
X/lscripth,Φ(x,0)(pT=1(x)−pT=0(x))dx (21)
=(1−u)/integraldisplay
R/lscripth,Φ(Ψ(r),1)(pT=0
Φ(r)−pT=1
Φ(r))dr+u/integraldisplay
R/lscripth,Φ(Ψ(r),0)(pT=1
Φ(r)−pT=0
Φ(r))dr(22)
=BΦ·(1−u)/integraldisplay
R1
BΦ/lscripth,Φ(Ψ(r),1)(pT=0
Φ(r)−pT=1
Φ(r))dr
+BΦ·u/integraldisplay
R1
BΦ/lscripth,Φ(Ψ(r),0)(pT=1
Φ(r)−pT=0
Φ(r))dr
≤BΦ·(1−u) sup
g∈G|/integraldisplay
Rg(r)(pT=0
Φ(r)−pT=1
Φ(r))dr|
+BΦ·u·sup
g∈G|/integraldisplay
Rg(r)(pT=1
Φ(r)−pT=0
Φ(r))dr| (23)
=BΦ·Wass (pT=1
Φ,pT=0
Φ) (24)
Equation (21) is by Deﬁnition 8; equation (22) is by the change of formula, pT=0
Φ(r) =pT=0(Ψ(r))JΨ(r),
pT=1
Φ(r) =pT=1(Ψ(r))JΨ(r), whereJΨ(r)is the absolute of the determinant of the Jacobian of Ψ(r); in-
equality (23) is by the premise that1
BΦ·/lscripth,Φ(Ψ(r),t)∈Gfort= 0,1, and (24) is by Deﬁnition 9 of an
IPM.
The crucial condition in Lemma 3 is that gΦ,h(r,t) :=1
BΦ·/lscripth,Φ(Ψ(r),t)∈G. Bounds for BΦcan be given to
evaluate this constant when under more assumptions about the loss function L, the Lipschitz constants of
p(yt|x),h, and the condition number of the Jacobian of Φ. These assumptions and the speciﬁc bounds for
BΦcan be seen in supplement Section A.3 of (Shalit et al., 2017).
Now we turn to derive the counterfactual error bounds for the H-divergence case.
Assumption 1. There exists a constant K > 0such that sup
y2∈Y,x∈X/integraltext
YL(y1,y2)p(y1|x)dy1≤K.
Lemma 4. LetΦ :X→Rbe an invertible representation with Ψbeing its inverse. Let pT=1
Φ(r),pT=0
Φ(r)be
as deﬁned before. Let h:R×{ 0,1}→Y,u:=Pr(T= 1)andHbe the family of binary functions. Assume
loss function Lobeys the Assumption 1. Then we have:
/epsilon1CF(h,Φ)≤(1−u)·/epsilon1T=1
F(h,Φ) +u·/epsilon1T=0
F(h,Φ) +K
2dH(pT=1
Φ,pT=0
Φ).
18Under review as submission to TMLR
Proof.
/epsilon1CF(h,Φ)−[(1−u)·/epsilon1T=1
F(h,Φ) +u·/epsilon1T=0
F(h,Φ)]
=(1−u)/integraldisplay
R/lscripth,Φ(Ψ(r),1)(pT=0
Φ(r)−pT=1
Φ(r))dr+u/integraldisplay
R/lscripth,Φ(Ψ(r),0)(pT=1
Φ(r)−pT=0
Φ(r))dr(25)
≤(1−u)/integraldisplay
pT=0
Φ>pT=1
Φ/lscripth,Φ(Ψ(r),1)(pT=0
Φ(r)−pT=1
Φ(r))dr
+u/integraldisplay
pT=1
Φ>pT=0
Φ/lscripth,Φ(Ψ(r),0)(pT=1
Φ(r)−pT=0
Φ(r))dr (26)
≤(1−u)K/integraldisplay
pT=0
Φ>pT=1
Φ(pT=0
Φ(r)−pT=1
Φ(r))dr+u·K/integraldisplay
pT=1
Φ>pT=0
Φ(pT=1
Φ(r)−pT=0
Φ(r))dr (27)
=(1−u)K/integraldisplay
RI(pt=0
Φ>pT=1
Φ)(pT=0
Φ(r)−pT=1
Φ(r))dr
+u·K/integraldisplay
RI(pT=1
Φ>pT=0
Φ)(pT=1
Φ(r)−pT=0
Φ(r))dr
≤(1−u)Ksup
η∈H|/integraldisplay
Rη(r)(pT=1
Φ(r)−pT=0
Φ(r))dr|
+u·K·sup
η∈H|/integraldisplay
Rη(r)(pT=1
Φ(r)−pT=0
Φ(r))dr| (28)
≤K·sup
η∈H|/integraldisplay
Rη(r)((pT=1
Φ(r)−pT=0
Φ(r)))dr|
=K
2dH(pT=1
Φ,pT=0
Φ) (29)
Equation (25) is same to equation (22); equation (26) is by /lscripth,Φ≥0for all randt; inequality (27) is by
Deﬁnition 6 and Assumption 1; inequality (28) is because an indicator function is also a binary function;
equation (29) is by (20) in Lemma 2.
A.3 Bounds for the PEHE loss /epsilon1PEHE
We ﬁrst state two lemmas for /epsilon1PEHEwith respect to two diﬀerent loss functions: the squared loss and the
absolute loss. In fact, similar lemmas hold for loss functions that satisfy the (relaxed) triangle inequalities.
Deﬁnition 11. The expected variance of ytwith regard to p(x,t)is:
σ2
yt(p(x,t)) =/integraldisplay
X×{ 0,1}×Y(yt−τt(x))2p(yt|x)p(x,t)dytdxdt,
and deﬁne:
σ2
y= min{σ2
yt(p(x,t)),σ2
yt(p(x,1−t))}.
Lemma 5. Let loss function Lbe the squared loss, L(y1,y2) = (y1−y2)2. For any function f:X×{ 0,1}→
Y, and distribution p(x,t)overX×{ 0,1}, we have the same results in Shalit et al. (2017):
/epsilon1PEHE (h,Φ)≤2(/epsilon1CF(h,Φ) +/epsilon1F(h,Φ)−2σ2
y)
19Under review as submission to TMLR
Proof.We denote /epsilon1PEHE (f) =/epsilon1PEHE (h,Φ),/epsilon1F(f) =/epsilon1F(h,Φ),/epsilon1CF(f) =/epsilon1CF(h,Φ)forf(x,t) =h(Φ(x),t).
/epsilon1PEHE (f)
=/integraldisplay
X((f(x,1)−f(x,0))−(τ1(x)−τ0(x)))2p(x)dx
≤2/integraldisplay
X((f(x,1)−τ1(x))2+ (f(x,0)−τ0(x))2)p(x)dx (30)
=2/integraldisplay
X(f(x,1)−τ1(x))2p(x,T= 1)dx+ 2/integraldisplay
X(f(x,0)−τ0(x))2p(x,T= 0)dx
+ 2/integraldisplay
X(f(x,1)−τ1(x))2p(x,T= 0)dx+ 2/integraldisplay
X(f(x,0)−τ0(x))2p(x,T= 1)dx (31)
=2/integraldisplay
X×{ 0,1}(f(x,t)−τt(x))2p(x,t)dxdt+ 2/integraldisplay
X×{ 0,1}(f(x,t)−τt(x))2p(x,1−t)dxdt.
Inequality (30) is because the relaxed triangle inequality, (x+y)2≤2(x2+y2); equation (31) is because
p(x) =p(x,T= 0) +p(x,T= 1).
/epsilon1F(f)
=/integraldisplay
X×{ 0,1}×Y(f(x,t)−yt)2p(yt|x)p(x,t)dytdxdt
=/integraldisplay
X×{ 0,1}×Y(f(x,t)−τt(x))2p(yt|x)p(x,t)dytdxdt
+/integraldisplay
X×{ 0,1}×Y(τt(x)−yt)2p(yt|x)p(x,t)dytdxdt
+ 2/integraldisplay
X×{ 0,1}×Y(f(x,t)−τt(x))(τt(x)−yt)p(yt|x)p(x,t)dytdxdt (32)
=/integraldisplay
X×{ 0,1}(f(x,t)−τt(x))2p(x,t)dxdt+σ2
yt(p(x,t)) (33)
Equation (33) is by Deﬁnition 11 and last term in equation (32) equals to zero, since τt(x) =/integraltext
Yytp(yt|x)dyt.
A similar result can be obtained for /epsilon1CF:
/epsilon1CF(f) =/integraldisplay
X×{ 0,1}(f(x,t)−τt(x))2p(x,1−t)dxdt+σ2
yt(p(x,1−t)).
Combining these results and Deﬁnition 11, we have
/epsilon1PEHE (h,Φ)≤2(/epsilon1F(f)−σ2
yt(p(x,t))) + 2(/epsilon1CF(f)−σ2
yt(p(x,1−t)))
≤2(/epsilon1CF(h,Φ) +/epsilon1F(h,Φ)−2σ2
y).
For the absolute loss L(y1,y2) =|y1−y2|that satisﬁes triangle inequality, the upper bound in Lemma 5 will
replace the standard deviation σ2
yby mean absolute deviation Ay.
Deﬁnition 12. The mean absolute deviation of ytwith regard to p(x,t)is:
Ayt(p(x,t)) =/integraldisplay
X×{ 0,1}×Y|yt−τt(x)|p(yt|x)p(x,t)dytdxdt,
and deﬁne:
Ay= max{Ayt(p(x,t)),Ayt(p(x,1−t))}.
20Under review as submission to TMLR
Lemma 6. Let loss function Lbe the absolute loss, L(y1,y2) =|y1−y2|. For any function f:X×{ 0,1}→Y,
and distribution p(x,t)overX×{ 0,1}:
/epsilon1PEHE (h,Φ)≤/epsilon1CF(h,Φ) +/epsilon1F(h,Φ) + 2Ay.
Proof.Recall that /epsilon1PEHE (f) =/epsilon1PEHE (h,Φ),/epsilon1F(f) =/epsilon1F(h,Φ),/epsilon1CF(f) =/epsilon1CF(h,Φ)forf(x,t) =h(Φ(x),t).
/epsilon1PEHE (f)
=/integraldisplay
X|(f(x,1)−f(x,0))−(τ1(x)−τ0(x))|p(x)dx
≤/integraldisplay
X(|f(x,1)−τ1(x)|+|f(x,0)−τ0(x)|)p(x)dx (34)
=/integraldisplay
X|f(x,1)−τ1(x)|p(x,T= 1)dx+/integraldisplay
X|f(x,0)−τ0(x)|p(x,T= 0)dx
+/integraldisplay
X|f(x,1)−τ1(x)|p(x,T= 0)dx+/integraldisplay
X|f(x,0)−τ0(x)|p(x,T= 1)dx (35)
=/integraldisplay
X×{ 0,1}|f(x,t)−τt(x)|p(x,t)dxdt+/integraldisplay
X×{ 0,1}|f(x,t)−τt(x)|p(x,1−t)dxdt.
Inequality (34) is because triangle inequality, |x+y|≤|x|+|y|; equation (35) is because p(x) =p(x,T=
0) +p(x,T= 1).
/epsilon1F(f)
=/integraldisplay
X×{ 0,1}×Y|f(x,t)−yt|p(yt|x)p(x,t)dytdxdt
≥/integraldisplay
X×{ 0,1}×Y|f(x,t)−τt(x)|p(yt|x)p(x,t)dytdxdt
−/integraldisplay
X×{ 0,1}×Y|τt(x)−yt|p(yt|x)p(x,t)dytdxdt (36)
=/integraldisplay
X×{ 0,1}|f(x,t)−τt(x)|p(x,t)dxdt−Ayt(p(x,t)). (37)
Inequality (36) is also because |x+y|≥|x|−|y|, equation (37) is by Deﬁnition 12. A similar result can be
obtained for /epsilon1CF:
/epsilon1CF(f) =/integraldisplay
X×{ 0,1}|f(x,t)−τt(x)|p(x,1−t)dxdt−Ayt(p(x,1−t)).
Combining these results and Deﬁnition 12, we have
/epsilon1PEHE (h,Φ)≤/epsilon1F(f) +Ayt(p(x,t)) +/epsilon1CF(f) +Ayt(p(x,1−t))
≤/epsilon1CF(h,Φ) +/epsilon1F(h,Φ) + 2Ay.
We summarize the upper bounds of /epsilon1CFand/epsilon1PEHEabove, and give the ﬁnal bounds for these two distance
using the squared and absolute loss, respectively.
Theorem 1. LetΦ :X→Rbe an invertible representation with Ψbeing its inverse. Let pT=1
Φ(r),pT=0
Φ(r)
be as deﬁned before. Let h:R×{ 0,1}→Y,u:=Pr(T= 1)andGbe the family of 1-Lipschitz functions.
Assume there exists a constant BΦ≥0, such that for t= 0,1, the function gΦ,h(r,t) :=1
BΦ·/lscripth,Φ(Ψ(r),t)∈G.
21Under review as submission to TMLR
Let loss function Lbe the squared loss, L(y1,y2) = (y1−y2)2. Then we have (same results in Shalit et al.
(2017)):
/epsilon1PEHE (h,Φ)
≤2(/epsilon1CF(h,Φ) +/epsilon1F(h,Φ)−2σ2
y) (38)
≤2(/epsilon1T=1
F(h,Φ) +/epsilon1T=0
F(h,Φ) +BΦ·Wass (pT=1
Φ,pT=0
Φ)−2σ2
y) (39)
Let loss function Lbe the absolute loss, L(y1,y2) =|y1−y2|. Then we have:
/epsilon1PEHE (h,Φ)
≤/epsilon1CF(h,Φ) +/epsilon1F(h,Φ) + 2Ay (40)
≤/epsilon1T=1
F(h,Φ) +/epsilon1T=0
F(h,Φ) +BΦ·Wass (pT=1
Φ,pT=0
Φ) + 2Ay (41)
Proof.Inequality (38) is by Lemma 5, inequality (39) is by Lemma 1 and Lemma 3; Inequality (40) is by
Lemma 6, inequality (41) is by Lemma 1 and Lemma 3;
Theorem 2. LetΦ :X→Rbe an invertible representation with Ψbeing its inverse. Let pT=1
Φ(r),pT=0
Φ(r)
be as deﬁned before. Let h:R×{ 0,1}→Y,u:=Pr(T= 1)andHbe the family of binary functions.
Let loss function Lbe the squared loss such that L(y1,y2) = (y1−y2)2. Then we have:
/epsilon1PEHE (h,Φ)
≤2(/epsilon1CF(h,Φ) +/epsilon1F(h,Φ)−2σ2
y) (42)
≤2(/epsilon1T=1
F(h,Φ) +/epsilon1T=0
F(h,Φ) +K
2dH(pT=1
Φ,pT=0
Φ)−2σ2
y) (43)
Let loss function Lbe the absolute loss such that L(y1,y2) =|y1−y2|. Then we have:
/epsilon1PEHE (h,Φ)
≤/epsilon1CF(h,Φ) +/epsilon1F(h,Φ) + 2Ay (44)
≤/epsilon1T=1
F(h,Φ) +/epsilon1T=0
F(h,Φ) +K
2dH(pT=1
Φ,pT=0
Φ) + 2Ay (45)
Proof.Inequality (42) is by Lemma 5, inequality (43) is by Lemma 1 and Lemma 4; Inequality (44) is by
Lemma 6, inequality (45) is by Lemma 1 and Lemma 4;
Obviously, when using Wasserstein distance, there are various versions of bounds for diﬀerent loss functions
as long as they satisfy the (relaxed) triangle inequality and assumptions about /lscripth,Φin Theorem 1. Similarly,
when usingH-divergence, there are also various versions of bounds for loss functions that satisfy Assumption
1 and the (relaxed) triangle inequality.
For an empirical sample and a family of representations and hypotheses, we can further upper bound /epsilon1T=0
F
and/epsilon1T=1
Fbytheirrespectiveempiricallossesandamodelcomplexitytermusingstandardarguments(Shalev-
Shwartz & Ben-David, 2014). Both the Wasserstein distance and H-divergence can be consistently estimated
from ﬁnite samples (Sriperumbudur et al., 2012; Ben-David et al., 2006; 2010).
A.4 Illustrative examples
Examples for the motivation for decomposed patterns. To explain the dilemma between repre-
sentation balancing and outcome prediction, we give an intuitive examples and the analytical explanation
below to help readers better understand the motivation and importance of involving decomposed patterns
in representation balancing models.
22Under review as submission to TMLR
Adjust 
covariates 
Figure 7: Example for illustrating the importance of decomposed patterns.
Example 1. Suppose there is a vaccine to prevent some kind of disease. Let Xdenote the covariate (age),
T= 1denote the treatment (getting vaccinated), T= 0denote the control (not getting vaccinated), and Y
denotetheoutcome(probabilityofgettingthedisease). Supposethatthevaccineisassignedaccordingtoage,
and we have found that the older, the higher the probability of getting the disease. The left graph in Figure
7 shows the distribution of pre-balancing covariate Xfor treated and controlled groups, which indicates
that vaccines are more likely to distribute to older people. Technically, the pre-balancing data preserve
the outcome-predictive information: if we want to estimate Yusing the covariate X, we are conﬁdent that
people in the treatment/control group (orange/blue) are susceptible/unsusceptible to the disease since they
are older/younger. The right panel of Figure 7 shows the distribution of the adjusted covariate ˜X, over
which the distributions of treated and controlled groups are highly balanced. In this case, however, the
distribution of ˜Xis too balanced, making it hard to distinguish the treatment samples from the control
samples. Consequently, if we want to estimate Yusing ˜X, we may get confused about which group is
susceptible to the disease because the distributions of ˜Xare almost identical between the treated and
controlled groups. Therefore, only considering balancing patterns can result in a loss of outcome-predictive
information.
Analytical explanation. Recall that, as deﬁned in Deﬁnition 1, Φ :X→Ris a representation function,
andh:R×{ 0,1}→Yisanoutcomefunctionsuchthat h(Φ(x),t)estimatesyt. Fornotationalsimpliﬁcation,
we deﬁneFas a function family consisting f=h◦Φ :X×{ 0,1}→Ysuch thatf(x,t)estimatesyt. Then, as
demonstrated in equation 9, the goal of outcome prediction is to learn the global optimal outcome predictor
f∗such that
f∗=argmin
f∈FL(x,t,y;f).
For models without pre-balancing representations such as GNet (Figure 2a) and INet (Figure 2b), the
outcome is predicted using only balancing patterns. Speciﬁcally, their objectives incorporate the constraint
of distance minimization between treatment and control groups over Φ, i.e., dist (pT=1
Φ,pT=0
Φ)≤Cfor some
small constant C, where “dist” can be “Wass” for GNet or dHfor INet. We deﬁne F/primeas a function family
consistingf=h◦Φ :X×{ 0,1}→Ysuch thatf(x,t)estimatesytwith Φsimultaneously minimizing
dist(pT=1
Φ,pT=0
Φ). It is obvious that F/prime⊆F. The outcome predictor for models without pre-balancing
representations is learned by
f∗∗=argmin
f∈F/primeL(x,t,y;f).
Due toF/prime⊆F, we haveL(x,t,y;f∗)≤L(x,t,y;f∗∗). That is, if the outcome predictor is only learned
by balancing patterns, the learned outcome predictor f∗∗will be suboptimal of f∗. Instead, compared to
f∗∗learned by only balancing patterns, the outcome predictor learned by both pre-balancing and balancing
patterns can give a better estimate, as the corresponding feasible region will be larger than F/prime.
23Under review as submission to TMLR
In summary, on the one hand, involving representation balancing can beneﬁt treatment eﬀect estimation. On
the other hand, if pT=1
ΦandpT=0
Φare too balanced, a model may fail to preserve pre-balancing information
that is useful to outcome predictions. Such a dilemma motivates us to incorporate PPBR and PDIG such
thatPPBRimprovesoutcomepredictionwithoutharmingrepresentationbalancing, andPDIGhelpsamodel
to achieve more balanced representations without harming outcome prediction.
A.5 Additional Experimental details
Additional results on Twins Benchmark. To investigate the applicability of our model DIGNet to
benchmark datasets beyond the commonly used IHDP benchmark, we conducted additional comparisons
with several baseline models, including linear, tree, matching, and representation learning methods, on the
Twins benchmark, as presented in Table 4.
The Twins dataset comprises records of twin births in the USA between 1989 and 1991. After preprocessing,
each unit contains 30 covariates relevant to parents, pregnancy, and birth. The treatment D= 1indicates
the heavier twin, while D= 0indicates the lighter twin. The binary outcome variable Yrepresents 1-year
mortality. For more comprehensive details on this dataset and the limitation of IHDP, refer to Curth et al.
(2021).
Notably, for /epsilon1ATE, the simple linear or matching estimator performs best across diﬀerent methods. On the
other hand, when assessing ITE performance using the AUC of potential outcomes, representation learning
models all demonstrate strong performance, with AUC values exceeding 0.800on both training and test sets.
Among all the models, our DIGNet achieves the highest AUC results. This observation might stem from the
fact that representation balancing models are based on ITE error bounds, rather than ATE error bounds,
thereby optimizing for AUC instead of /epsilon1ATE. This, in turn, inspires us to explore ATE error bounds based
on IPM andH-divergence in future research.
Table 4: Training- & test- set AUC & /epsilon1ATEon Twins. Mean±standard error of 100 runs.
Training set Test set
AUC /epsilon1ATE AUC /epsilon1ATE
OLS/LR 1Johansson et al. (2016) .660±.005.004±.003.500±.028.007±.006
OLS/LR 2Johansson et al. (2016) .660±.004.004±.003.500±.016.007±.006
k-NN Crump et al. (2008) .609±.010.003±.002.492±.012.005±.004
BART Chipman et al. (2010) .506±.014.121±.024.500±.011.127±.024
CEVAE Louizos et al. (2017) .845±.003.022±.002.841±.004.032±.003
SITE Yao et al. (2018) .862±.002.016±.001.853±.006.020±.002
BLR Johansson et al. (2016) .611±.009.006±.004.510±.018.033±.009
BNN Johansson et al. (2016) .690±.008.006±.003.676±.008.020±.007
TARNet Shalit et al. (2017) .849±.002.011±.002.840±.006.015±.002
CFR-Wass (GNet) Shalit et al. (2017) .850±.002.011±.002.842±.005.028±.003
DIGNet (Ours) .874±.001.004±.001.871±.001.008±.001
Hyperparameters. Insimulationstudies, weensureafaircomparisonbyﬁxingallthehyperparametersin
all datasets across diﬀerent models. The relevant details are stated in Table 5. In IHDP studies, to compare
Table 5: Hyperparameters of diﬀerent models in simulation studies.
ΦE ΦG ΦI π h1h0α1α2batchsize iteration learning rate learning rate for π
Gnet (100,100,100,100)− − − (100,100) (100 ,100)0.1−100 300 1e−3−
Inet (100,100,100,100)− − (100,100,100) (100 ,100) (100 ,100)−0.1 100 300 1e−31e−4
DGNet (100,100,100,100) (100 ,100)− − (100,100) (100 ,100)0.1−100 300 1e−3−
DINet (100,100,100,100)− (100,100) (100 ,100,100) (100 ,100) (100 ,100)−0.1 100 300 1e−31e−4
DIGNet (100,100,100,100) (100 ,100) (100 ,100) (100 ,100,100) (100 ,100) (100 ,100)0.1 0.1 100 300 1e−31e−4
24Under review as submission to TMLR
with the baseline model CFR-Wass (GNet), we remain the hyperparameters of INet, DGNet, DINet and the
early stopping rule the same as those used in CFR-Wass Shalit et al. (2017). Since DIGNet is more complex
than other four models, we adjust the hyperparameters of ΦE,ΦG,ΦI,α1, andα2for DIGNet as Shalit
et al. (2017) do. The relevant details are stated in Table 6.
Table 6: Hyperparameters of diﬀerent models in IHDP experiments.
ΦE ΦG ΦI π h1h0α1α2batchsize iteration learning rate learning rate for π
Gnet (100,100,100,100) − − − (100,100,100) (100 ,100,100)1−100 600 1e−3−
Inet (100,100,100,100) − − (200,200,200) (100 ,100,100) (100 ,100,100)−1 100 600 1e−31e−3
DGNet (100,100,100,100) (100 ,100)− − (100,100,100) (100 ,100,100)1−100 600 1e−3−
DINet (100,100,100,100) − (100,100) (200 ,200,200) (100 ,100,100) (100 ,100,100)−1 100 600 1e−31e−3
DIGNet (100,100,100,100,100,100) (100 ,100,100) (100 ,100,100) (200 ,200,200) (100 ,100,100) (100 ,100,100)0.1 1 100 600 1e−31e−3
Analysis of training time and training stability. We record the time it took for diﬀerent models to
run through 100 IHDP datasets, and each model is trained within 600 epochs. Following Shalit et al. (2017),
all models adopt the early stopping rule. We also record the average early stopping epoch on 100 runs
and the actual time on 100 runs, where (actual time) = (total time) ×(average early stopping epoch)/600.
Not surprisingly, GNet took the least amount of time with 3096 seconds since the objective of GNet is the
simplest. However, it is very interesting that the proposed methods, DGNet and DINet, are the ﬁrst two
to early stop. As a result, though DGNet and DINet have multi-objectives, they spent less actual training
time but achieved better ITE estimation compared to GNet and INet. Since GNet and INet are actually
DGNet and DINet with PPBR ablated, we ﬁnd that PPBR component can help a model achieve better ITE
estimates with less time. In addition, we ﬁnd that DIGNet spent the longest time to optimize since it has
the most complex objective. To further study the stability of the model training, we also plot the metrics√/epsilon1F, Wass, ˆdH, and√/epsilon1PEHEfor the ﬁrst 100 epochs of each model on the ﬁrst IHDP dataset. We ﬁnd
that the training process of DIGNet is stable, even steadier than GNet and INet. From this perspective, we
haven’t seen a diﬃculty of optimizing DIGNet.
Table 7: Training time records on 100 IHDP datasets.
Model Time for 600 epochs Avg early stopping Actual time√/epsilon1PEHEon test set
GNet 3096s 240.61 1241s 0.77 ±0.18
INet 4042s 254.19 1712 0.72 ±0.11
DGNet 3775s 169.17 1064s 0.60 ±0.09
DINet 3212s 157.98 846s 0.60 ±0.11
DIGNet 4984s 226.76 1884s 0.45 ±0.04
A.6 Objectives of Diﬀerent Models
Objective of GNet.
min
ΦE,htLy(x,t,y; ΦE,ht) +α1LG(x,t; ΦE).
Objective of INet.
max
πα2LI(x,t; ΦE,π),
min
ΦE,htLy(x,t,y; ΦE,ht) +α2LI(x,t; ΦE,π).
25Under review as submission to TMLR
Figure 8: Training loss plots for the ﬁrst 100 epochs on the ﬁrst IHDP dataset.
Objective of DINet. Note that similar to DIGNet, the pre-balancing patterns are preserved by only
updating ΦIbut ﬁxing ΦEin the second step.
max
πα2LI(x,t; ΦI◦ΦE,π),
min
ΦIα2LI(x,t; ΦI◦ΦE,π),
min
ΦE,ΦI,htLy(x,t,y; ΦE⊕(ΦI◦ΦE),ht).
Objective of DGNet. Note that similar to DIGNet, the pre-balancing patterns are preserved by only
updating ΦGbut ﬁxing ΦEin the ﬁrst step.
min
ΦGα1LG(x,t; ΦG◦ΦE),
min
ΦE,ΦG,htLy(x,t,y; ΦE⊕(ΦG◦ΦE),ht).
Objective of DIGNet.
min
ΦGα1LG(x,t; ΦG◦ΦE),
max
πα2LI(x,t; ΦI◦ΦE,π),
min
ΦIα2LI(x,t; ΦI◦ΦE,π),
min
ΦE,ΦI,ΦG,htLy(x,t,y; ΦE⊕(ΦI◦ΦE)⊕(ΦG◦ΦE),ht).
26