Published in Transactions on Machine Learning Research (02/2023)
Dirichlet Mechanism for Differentially Private KL Divergence
Minimization
Donlapark Ponnoprat donlapark.p@cmu.ac.th
Department of Statistics
Chiang Mai University
Reviewed on OpenReview: https: // openreview. net/ forum? id= lmr2WwlaFc
Abstract
Given an empirical distribution f(x)of sensitive data x, we consider the task of minimizing
F(y) =DKL(f(x)∥y)over a probability simplex, while protecting the privacy of x. We
observe that, if we take the exponential mechanism and use the KL divergence as the loss
function, then the resulting algorithm is the Dirichlet mechanism that outputs a single
draw from a Dirichlet distribution. Motivated by this, we propose a Rényi differentially
private (RDP) algorithm that employs the Dirichlet mechanism to solve the KL divergence
minimization task. In addition, given f(x)as above and ˆyan output of the Dirichlet
mechanism, we prove a probability tail bound on DKL(f(x)∥ˆy), which is then used to derive
a lower bound for the sample complexity of our RDP algorithm. Experiments on real-world
datasets demonstrate advantages of our algorithm over Gaussian and Laplace mechanisms in
supervised classification and maximum likelihood estimation.
1 Introduction
KL divergence is the most commonly used divergence measure in probabilistic and Bayesian modeling. In a
probabilistic model, for example, we estimate the model’s parameters by maximizing the likelihood function
of the parameters, which in turn is equivalent to minimizing the KL divergence between the empirical
distribution and the model’s distribution. In supervised classification, a standard way to fit a classifier is by
minimizing the cross-entropy of the model’s predictive probabilities, which is equivalent to minimizing the
KL divergence between the class-conditional empirical distribution and the model’s predictive distribution.
Such models are widely used in medical fields, social sciences and businesses, where they are used to analyze
sensitive personal information. Without privacy considerations, releasing a model to public might put the
personal data at risk of being exposed to privacy attacks, such as membership inference attacks (Shokri et al.,
2017; Ye et al., 2022). To address the model’s privacy issue, we should focus on its building blocks: the KL
divergences. How can we minimize the KL divergence over the model’s parameters, while keeping the data
private?
DifferentialPrivacy(Dworketal.,2006a;b)providesaframeworkforquantitativeprivacyanalysisofalgorithms
that run on sensitive personal data. Under this framework, one aims to design a task-specific algorithm that
preserves the privacy of the inputs, while keeping the “distance” between the privatized output and the true
output sufficiently small. A simple and well-studied technique is to add a small random noise sampled from a
zero-centered probability distribution, such as the Laplace and Gaussian distributions. Another technique
is to sample an output from a distribution, with greater probabilities of obtaining points that are closer to
the true output, such as the exponential mechanism (McSherry & Talwar, 2007). These techniques have
been deployed in many privacy-preserving tasks, from simple tasks such as private counting and histogram
queries (Dwork et al., 2006a;b) to complex tasks such as deep learning (Abadi et al., 2016).
In this work, we are interested in a setting where our algorithm outputs an empirical distribution f(x)of some
sensitive data x. To protect the privacy of individuals in x, we keepf(x)hidden, and instead release another
discrete distribution that approximates f(x)in KL divergence. This setting may not arise, for example, in
1Published in Transactions on Machine Learning Research (02/2023)
the task of releasing a normalized histogram, as the distance between histograms is often measured in ℓ1
orℓ2. Nonetheless, there are many tasks where KL divergence arises naturally. Prominent examples are
those in probabilistic modeling, where the outputs—the model’s estimated parameters—are obtained from
likelihood maximization. Another examples are those in Bayesian modeling, where models are evaluated
with adjusted negative log-likelihood scores, such as the Akaike information criterion (AIC) and Bayesian
information criterion (BIC). It is also increasingly common in Bayesian practice to evaluate the model with
out-of-sample log-likelihood (Vehtari et al., 2016). Again, minimizing these criteria can be formulated as
minimizing the KL divergence.
A simple approach to privatize a discrete probability distribution is by adding some random noises from a
probability distribution. However, the KL divergence does not behave smoothly with the additive noises, as
the following example illustrates: consider count data of 10 people, interpreted as a normalized histogram:
p= (0.1,0.9). Suppose that we draw two sets of noises z1= (−0.090,0.045)andz2= (−0.099,−0.038)from
Laplace (1/10). Here, the ℓ1-distances between pand its noisy versions are 0.135and0.137, a very small
difference. On the other hand, the KL divergences between between pand its noisy versions are 0.186and
0.499, a2.68times increase. This example illustrates that adding noises to a discrete probability vector, even
at a small scale, could result in a noisy vector that is too far away from the original vector in terms of KL
divergence.
We instead consider the exponential mechanism, a differentially private algorithm that approximately
minimizes user-defined loss functions . It turns out that, by taking the loss function to be the KL divergence,
the exponential mechanism turns into one-time sampling from a Dirichlet distribution; we shall call this the
Dirichlet mechanism .
The Dirichlet mechanism, however, does not inherit the differential privacy guarantee of the exponential
mechanism: the guarantee in (McSherry & Talwar, 2007) requires the loss function to be bounded above, while
the KL divergence can be arbitrarily large. In fact, using the original definition of differential privacy (Dwork
et al., 2006b), the Dirichlet mechanism is not differentially private (see Appendix A). We thus turn to a
relaxation of differential privacy. Specifically, using the notion of the Rényi differential privacy (Mironov,
2017), we study the Dirichlet mechanism and its utility in terms of KL divergence minimization.
1.1 Overview of Our results
Below are summaries of our results.
§3 Privacy. We propose a version of the Dirichlet mechanism (Algorithm 1) that satisfies the Rényi
differential privacy (RDP). In this algorithm, we need to evaluate a polygamma function and find the root of
a strictly increasing function. Our algorithm is easy to implement, as polygamma functions, root-finding
methods and Dirichlet distributions are readily available in many scientific programming languages.
§4 Utility. We derive a probability tail bound for DKL(p∥q)whenqis drawn from a Dirichlet distribution
(Theorem 2). From this, we derive a lower bound for the sample complexity of Algorithm 1 that attains a
target privacy guarantee, both in general case and on categorical data.
§5 Experiments. We compare the Dirichlet mechanism against the Gaussian and Laplace mechanisms for
two learning tasks: naïve Bayes classification and maximum likelihood estimation of Bayesian networks—both
tasks can be done with KL divergence minimization. Experiments on real-world datasets show that the
Dirichlet mechanism provides smaller cross-entropy loss in classification, and larger log-likelihood in parameter
estimation, than the other mechanisms at the same level of privacy guarantee.
1.2 Notations
In this paper, all vectors are d-dimensional, where d≥2. The number of observations is always N. Let
[d]:= [1,...,d ]. For anyu∈Rd, we letuibe thei-th coordinate of u, and for any vector-valued function
f:X →Rd, we letfibe thati-th component of f. LetRd
≥0be the set of d-tuples of non-negative real
numbers, and Rd
>0be the set of d-tuples of positive real numbers. Denote the probability simplex by
Sd−1:=/braceleftig
p∈Rd
≥0:/summationdisplay
ipi= 1/bracerightig
.
2Published in Transactions on Machine Learning Research (02/2023)
For anyu,u′∈Rdand scalarr>0, we writeu+u′:= (u1+u′
1,...,ud+u′
d)andru:= (ru1,...,rud). For
any positive-valued functions f,f′, the notation f(x)∝f′(x)meansf(x) =Cf′(x)for some constant C > 0
andf(x)≈f′(x)meanscf′(x)≤f(x)≤Cf′(x)for somec,C > 0. Lastly,∥u∥2:=/radicalbig
u2
1+...+u2
dis theℓ2
norm ofuand∥u∥∞:= maxi|ui|is theℓ∞norm ofu.
2 Background and related work
2.1 Privacy models
We say that two datasets are neighboring if they differ on a single entry. Here, an entrycan be a row of the
datasets, or a single attribute of a row.
Definition2.1 (PureandApproximatedifferentialprivacy(Dworketal.,2006a;b)) .Arandomizedmechanism
M:Xn→Yis(ε,δ)-differentially private ( (ε,δ)-DP) if for any two neighboring datasets xandx′and all
eventsE⊂Y,
Pr[M(x)∈E]≤eεPr[M(x′)∈E] +δ. (1)
IfMis(ε,0)-DP, then we say that it is ε-differential private ( ε-DP).
The term pure differential privacy (pure DP) refers to ε-differential privacy, while approximate differential
privacy(approximate DP) refers to (ε,δ)-DP whenδ>0.
In this paper, we shall concern ourselves with Rényi differential privacy, a relaxed notion of differential privacy
defined in terms of the Rényi divergence between M(x)andM(x′):
Definition 2.2 (Rényi Divergence (Rényi, 1961)) .LetPandQbe probability distributions. For λ∈(1,∞)
the Rényi divergence of order λbetweenPandQis defined as
Dλ(P∥Q) =1
λ−1log/parenleftbigg
E
y∼P/bracketleftbiggP(y)λ−1
Q(y)λ−1/bracketrightbigg/parenrightbigg
.
and forλ= 1, we define D1(P∥Q) =DKL(P∥Q),
Definition 2.3 (Rényi differential privacy (Mironov, 2017)) .A randomized mechanism M:Xn→Yis
(λ,ε)-Rényi differentially private (( λ,ε)-RDP) if for any two neighboring datasets xandx′,
Dλ(M(x)∥M(x′))≤ε.
Intuitively, εcontrols the moments of the privacy loss random variable: Z:=logP[M(x)=Y]
P[M(x′)=Y], whereYis
distributed as M(x), up to order λ. A smaller εand largerλcorrespond to a stronger privacy guarantee.
The following composition property of RDP mechanisms allow us to track the privacy guarantees of using
multiple Dirichlet mechanisms. This can be helpful when Dirichlet mechanisms is employed in a more complex
algorithms, such as fitting a discrete probabilistic model.
Lemma 1 (Composition of RDP mechanisms (Mironov, 2017)) .LetM1:Xn→Ybe a (λ1,ε1)-RDP
mechanism and M2:Xn→Zbe a (λ2,ε2)-RDP mechanism. Then a mechanism M:Xn→Y×Z defined
byM(x) = (M1(x),M2(x))is(min(λ1,λ2),ε1+ε2)-RDP.
2.2 Exponential mechanism with the KL divergence
The exponential mechanism (McSherry & Talwar, 2007) is a privacy mechanism that releases an element
from a rangeYthat approximately minimizes a given loss function ℓ:XN×Y→ R. Given a base measure
µoverYand a dataset x∈XN, the mechanism outputs y∈Ywith probability density proportional to:
e−βℓ(x,y)µ(y), (2)
whereβis a function of ε, the privacy parameter.
For the first time, we point out the connection between the exponential mechanism and a well-known family
of probability distributions under a specific choice of ℓ(x,y). Letf:XN→Rd
≥0be an arbitrary vector-valued
3Published in Transactions on Machine Learning Research (02/2023)
function on datasets. Let Y=Sd−1. Assuming that Nf:=/summationtext
ifi(x)is known and nonzero, we denote the
normalized vector/tildewidestf(x)=N−1
ff(x)∈Sd−1. In equation 2, let ℓ(x,y) =DKL(/tildewidestf(x)∥y),β=rNf, andµ(y)be
the density of Dirichlet (α), that is,µ(y)∝/producttextd
i=1yα−1
i. Then, the probability density of the output yof the
corresponding exponential mechanism is proportional to:
exp/parenleftig
−rNfDKL(/tildewidestf(x)∥y)/parenrightig/productdisplay
iyα−1
i= exp
r/summationdisplay
i,xi̸=0fi(x) log(yi/]fi(x))
/productdisplay
iyα−1
i
∝/productdisplay
i,xi̸=0yrfi(x)
i/productdisplay
iyα−1
i
=/productdisplay
iyrfi(x)+α−1
i,
which is exactly the non-normalized density function of Dirichlet (rf(x) +α). This specific distribution will
play a major role in the main privacy mechanism introduced in the next section.
From this derivation, we can see that this particular instance of the exponential mechanism can be used to
outputythat approximately minimizes the KL divergence DKL/parenleftig/tildewidestf(x)∥y/parenrightig
while keeping xprivate.
To see how the choices of randαaffect the “distance” between yiand]fi(x), we treatyias an estimator of
]fi(x)and look at the bias of yi:
/vextendsingle/vextendsingle/vextendsingleE[yi]−]fi(x)/vextendsingle/vextendsingle/vextendsingle=/vextendsingle/vextendsingle/vextendsingle/vextendsinglerfi(x) +α
rNf+dα−fi(x)
Nf/vextendsingle/vextendsingle/vextendsingle/vextendsingle=α|Nf−dfi(x)|
Nf(rNf+dα). (3)
The bias is reduced when rincreases and αdecreases. We can also look at the variance of yi:
Var[yi] =(rfi(x) +α)(r(Nf−fi(x)) + (d−1)α)
(rNf+dα)2(rNf+dα+ 1),
which isO(1/r)asr→∞andO(1/α)asα→∞. This implies that draws from Dirichlet (rf(x) +α)are
more concentrated when randαare large.
Applications. The derivation of the Dirichlet mechanism above suggests that the best use of the Dirichlet
mechanism is for privately minimizing KL divergence, which arises in the following scenarios:
1.Maximum likelihood estimation. Consider a problem of parameter estimation in a multinomial
model with dpossible outcomes. Let x∈[d]NbeNobservations, f1(x),...,fd(x)be the frequencies
andy1,...,ydbe the model’s parameters. Then the log-likelihood of xis/summationtext
ifi(x)logyi. Maximizing
the log-likelihood with respect to yis equivalent to minimizing the KL divergence:
arg max
y/summationdisplay
ifi(x) logyi= arg min
yDKL/parenleftbiggf(x)
N/vextenddouble/vextenddouble/vextenddoubley/parenrightbigg
.
Thus, we can use the Dirichlet mechanism to release the parameters of the model while keeping x
private.
2.Cross-entropy minimization. Consider the same multinomial model as above. One might
instead aim to minimize the cross-entropy loss: −1
N/summationtext
ifi(x)logyiovery. This is also equivalent to
minimizing the KL divergence, so we can use the Dirichlet mechanism to privately solve for y.
3.Private estimation of a discrete distribution. If we further assume that xis a sample from an
unknown discrete distribution p∈Sd−1withpi>0for alli, a single draw y∼Dirichlet(rf(x) +α)
can be used to privately estimate pin KL divergence. The KL divergence between pandycan be
bounded as follows:
4Published in Transactions on Machine Learning Research (02/2023)
DKL(p∥y) =DKL(/tildewidestf(x)∥y)−DKL(/tildewidestf(x)∥p) +/summationdisplay
i(pi−]fi(x)) log(pi/yi)
≤DKL(/tildewidestf(x)∥y) + max
i|log(pi/yi)|/summationdisplay
i|]fi(x)−pi|. (4)
Here, we sketch a proof that, with high probability, the bound is small for a sufficiently large
Nf. Due to Theorem 2 below and Agrawal (2020, Theorem I.2), respectively, both DKL(/tildewidestf(x)∥y)
andDKL(/tildewidestf(x)∥p)are small w.h.p. Combining this with Pinsker’s inequality:/summationtext
i|]fi(x)−qi|≤/radicalig
2DKL(/tildewidestf(x)∥q), withq=yandq=p, we obtain yi≈]fi(x)≈pi, and so the second term is also
small w.h.p. Note that we also have a similar bound for DKL(y∥p)by switching yandpin equation 4.
However, if some of the pi’s are really small, it will take a large number of data points to bound
the logarithmic term in equation 4. Finding finite sample bounds for DKL(p∥y)andDKL(y∥p)is an
interesting problem that we leave open for further investigation.
2.3 Polygamma functions
0 1 2 3 4 5x020406080100 ψ/prime(x)
Figure 1: A plot of ψ′(x).In most of this study, we take advantage of several nice properties of
the log-gamma function and its derivatives. The polygamma function
of ordermis the (m+ 1)-th derivative of the logarithm of the gamma
function. Specifically, when m= 0, we have the digamma function ψ(x):=
d
dxlog Γ(x), which is a concave and increasing function.
Our function of interest is the polygamma function of order 1:ψ′(x), which
is a positive, convex, and decreasing function (see Figure 1). It has the
series representation:
ψ′(x) =∞/summationdisplay
k=01
(x+k)2, (5)
which allows for fast approximations of ψ′(x)at any precision. ψ′can also be approximated by the reciprocals:
1
x+1
2x2<ψ′(x)<1
x+1
x2, (6)
which implies that ψ′(x)≈1
x2asx→0andψ′(x)≈1
xasx→∞.
2.4 Related work
There are several studies on the differential privacy of obtaining a single draw from a probability distribution
whose probability density function is of the form y∝⇕⊣√∫⊔≀→1
Zp(x|y)µ(y). Here,xis sensitive data, x∝⇕⊣√∫⊔≀→p(x|y)
is a probability density function for all yin the domain, µis any positive-valued function, and Zis the
normalizing constant. Wang et al. (2015) showed that, when |logp(x|y)|≤Bfor some constant B, then a
single draw is 4B-differentially private. However, the densities that we study are not bounded away from
zero; they have the form/producttext
iyrfi(x)+α
i which becomes small when one of the yi’s is close to zero. Dimitrakakis
et al. (2017) showed that, when pis the density of the binomial distribution and µis the density of the
beta distribution, then a single draw is (0,δ)-DP, and the result cannot be improved unless the parameters
are assumed to be above a positive threshold. As a continuation of their work, we prove in the appendix
that, when the parameters are bounded below by α>0, sampling from the Dirichlet distribution (which is a
generalization of the beta distribution) is (ε,δ)-DP withε>0.
Letxbe a sufficient statistic of an exponential family with finite ℓ1-sensitivity. Foulds et al. (2016) showed
that sampling Y∼p(y|ˆx), where ˆx=x+Laplace noise , is differentially private and as asymptotically
efficient as sampling from p(y|x). However, for a small sample size, the posterior over the noisy statistics
might be too far away from the actual posterior. Bernstein & Sheldon (2018) thus proposed to approximate
the joint distribution p(y,x,ˆx)using Gibbs sampling, which is then integrated over xto obtain a more
accurate posterior over ˆx.
5Published in Transactions on Machine Learning Research (02/2023)
Geumlek et al. (2017) were the first to study sampling from exponential families with Rényi differential privacy
(RDP; Mironov (2017)). Even though they provided a general framework to find (λ,ε)-RDP guarantees for
exponential families, explicit forms of λand the upper bound of λwere not given.
The privacy of data synthesis via sampling from Multinomial (Y), whereYis a discrete distribution drawn
from the Dirichlet posterior, was first studied by Machanavajjhala et al. (2008). They showed that the data
synthesis is ( ε,δ)-DP, where εgrows by the number of draws from Multinomial (Y). In contrast, we show that
a single draw from the Dirichlet posterior is approximate DP, which by the post-processing property allows
us to sample from Multinomial( Y)as many times as we want while retaining the same privacy guarantee.
Gohari et al. (2021) have recently showed that the Dirichlet mechanism is ( ˆε(r,γ,η,η′),δ(r,γ,η,η′))-
DP, where γ,η,η′∈(0,1)are additional parameters. Not only the guarantee has many parame-
ters to optimize, it is also computational intensive. Specifically, for any W⊂[d], define Ωη,η′
W=/braceleftbig
p∈Sd−1:pi>γ,∀i∈W;/summationtext
i∈Wpi≤1−η′/bracerightbig
. Gohari et al. proposed ˆε= Θ(rlog(1/γ))and
δ= 1− min
p∈Ωη,η ′
W,W⊂[d]{Pr[Yi>γ;∀i∈W] :Y∼Dirichlet(rp)}. (7)
0.00000 0.00025 0.00050 0.00075 0.00100 0.00125 0.00150 0.00175 0.00200γ2.22.32.42.52.62.7δ(γ)×10−4
Figure 2: A numerical simulation of δ
(equation 7) as a function of γ.To compute δ, we have to approximate Pr[Y >γ ]with a numerical
integration scheme with high precision, otherwise the integral may be
greater than one. Even then, the integral is highly dependent on the
scheme, and for some choices of the parameters r,η,η′, the value of
δcannot go below a certain threshold. We illustrate this in Figure 2.
Withr= 171.87,η= 0.028andη′= 0.114, the value of δcannot
go below 2.1×10−4. In contrast, our guarantee is much simpler to
compute, as the function ψ′can be easily approximated via its series
representation (equation 5). Moreover, we are the first to provide
the utility of the Dirichlet mechanism in terms of KL divergence
minimization.
3 Main privacy mechanism
3.1 The Dirichlet mechanism
Letf:XN→Rd
≥0be an arbitrary vector-valued function with finite ℓ2- andℓ∞-sensitivities: there exist two
constants ∆2,∆∞>0such that
sup
x,x′neighboring∥f(x)−f(x′)∥2
2≤∆2
2and sup
x,x′neighboring∥f(x)−f(x′)∥∞≤∆∞.
Algorithm 1 below details the Dirichlet mechanism used to privatize x∈XN.
Algorithm 1 (λ,ε)-RDP Dirichlet mechanism
Input:A datasetx∈XN, A vector-valued function f:XN→Rd
≥0withℓ2-sensitivity ∆2andℓ∞-sensitivity
∆∞
Parameters: λ≥1,ε>0
1. Use a root-finding algorithm to find r>0such thatε=1
2λr2∆2
2ψ′(1 + 3(λ−1)r∆∞).
2. Letα= 1 + 4(λ−1)r∆∞.
3. Outputy∼Dirichlet(rf(x) +α).
The following lemma ensures that we can obtain an r>0in Line 1 for any ε>0:
Lemma 2. Withε,∆2>0,∆∞>0andλ≥1held constant, the function r∝⇕⊣√∫⊔≀→1
2λr2∆2
2ψ′(1 + 3(λ−1)r∆∞)
defined on (0,∞)is strictly increasing from 0to∞. Consequently, the equation
ε=1
2λr2∆2
2ψ′(1 + 3(λ−1)r∆∞)
has a unique solution in rfor anyε,∆2,∆∞>0andλ≥1.
The proof of Lemma 2 can be found in Appendix D.
6Published in Transactions on Machine Learning Research (02/2023)
10−310−210−1100101
r10−610−510−410−310−210−1100ελ= 2
Trueε
Algorithm 1
10−310−210−1100101
r10−610−510−410−310−210−1100ελ= 20
Trueε
Algorithm 1
10−310−210−1100101
r10−610−510−410−310−210−1100ελ= 200
Trueε
Algorithm 1
10−210−1100101102
ˆε10−310−210−1100KL divergenceλ= 2
Uniform
Algorithm 1
Gohari et al
10−210−1100101102
ˆε10−1100KL divergenceλ= 20
Uniform
Algorithm 1
Gohari et al
10−210−1100101102
ˆε100
2×10−13×10−14×10−16×10−1KL divergenceλ= 200
Uniform
Algorithm 1
Gohari et al
Figure 3: Top: Plots of the Rényi divergence ( ε) between Dirichlet (rf(x) +α)andDirichlet (rf(x′) +α)using
the direct calculations and Algorithm 1 as a function of rforλ∈{2,20,200}. Here,f(x) = (11,8,65,25,38,1),
f(x′) = (11,7,65,25,38,0)andα= 1 + 4(λ−1)r. Bottom: Plots of DKL(y∥/tildewidestf(x))for multiple instances
ofydrawn from Dirichlet (rf(x) +α), wheref(x) = (119,74,618,272,13,187),α= 1 + 4(λ−1)r, and
λ∈{2,20,200}. For each ˆε, the privacy parameter ris chosen to satisfy ( ˆε,10−5)-DP according to (1) the
results of Gohari et al. (2021), and (2) the conversion from our RDP guarantee to approximate DP.
3.2 Privacy guarantee
Theorem 1. Algorithm 1 is (λ,ε)-RDP.
The proof of Theorem 1 can be found in Appendix E. A few remarks are in order.
Remark 1. In general, we can replace ψ′(1+3(λ−1)r∆∞)in Line 1 by ψ′(1+g(r)), andα= 1+4(λ−1)r∆∞
in Line 2 by α= 1 +g(r) + (λ−1)r∆∞for any function g:R>0→R≥0. In particular, choosing g≡0yields
r=/radicalbig
2ε/(λ∆2
2ψ′(1))which can be computed without a root-finding algorithm. However, this choice of r
makesεgrows asr2, which becomes too large when r>1. Instead, we choose g(r)to be a constant factor of an
existing term (λ−1)r∆∞inα, which allows us to offset the λr2factor inεwithψ′(1 +g(r)) = Θ/parenleftig
1
1+(λ−1)r/parenrightig
.
Remark 2. If one has prior knowledge that fi(x)>bfor someb>0for allx∈XNand alli∈[d], then
the proof of Theorem 1 can be modified so that (λ,ε)-RDP can be obtained by setting rto be the solution
to the equation ε=1
2λr2∆2
2ψ′(1 +rb+ 3(λ−1)r∆∞). Sinceψ′is strictly decreasing, this leads to a larger
value ofrcompared to Algorithm 1.
To demonstrate the tightness of the privacy guarantee of Algorithm 1, we simulate two neighboring histograms:
f(x) = (11,8,65,25,38,1)andf(x′) = (11,7,65,25,38,0). As functions of r, we compare εin Line 1 with
the analytic values of the Rényi divergence between Dirichlet (rf(x) +α)andDirichlet (rf(x′) +α), whereα
is given in Line 2. The plots of εas functions of rin Figure 3 show that our proposed RDP-guarantees are
close to the actual Rényi divergences across different values of λ.
7Published in Transactions on Machine Learning Research (02/2023)
We also perform another simulation in order to compare our privacy guarantees with the ones from Gohari
et al. (2021) in terms of their effects on the KL divergence. In this simulation, we apply the Dirichlet
mechanism with these privacy guarantees to the following count data: f(x) = (119,74,618,272,13,187).
For eachλ∈{2,20,200}, we define α= 1 + 4(λ−1)ras in Algorithm 1. Since the results of Gohari et al.
are stated in terms of approximate DP, we have to convert our result from RDP to approximate DP (see
Appendix B for more details on the conversion). For each ˆεranging from 0.001to100, we use Theorem 1
(with the conversion) and Gohari et al.’s results to choose r>0so that a single draw from Dirichlet (rf(x)+α)
is (ˆε,10−5)-DP. We then draw multiple instances, say y, from the distribution and compute DKL(/tildewidestf(x)∥y).
Finally, we plot the KL divergence as a function of ˆε, as shown in Figure 3. As a baseline, we also plot the
KL divergence between/tildewidestf(x)and the discrete uniform distribution. We can see that our privacy guarantee
generally provides smaller KL divergences than that of Gohari et al.’s. However, as λbecomes very large, the
algorithms output discrete probability distributions that are close to being uniform. The missing points in
theλ= 2andλ= 20plots are related to a precision issue with the Gohari et al.’s method that we pointed
out in Section 2.4: because of insufficient precision in numerical integration, we could not bring the value of δ
down to 10−5.
4 Utility
Let us recap the setting with which we apply the Dirichlet mechanism: we have a sensitive dataset x∈XN
and an arbitrary vector-valued function f:XN→Rd
≥0. LetNf:=/summationtext
ifi(x)and/tildewidestf(x):=N−1
ff(x)∈Sd−1.
We propose the Dirichlet mechanism (Algorithm 1) which aims to output ythat minimizes DKL/parenleftig/tildewidestf(x)∥y/parenrightig
while keeping xprivate. This motivates us to measure the utility of the Dirichlet mechanism in terms of the
KL divergence between/tildewidestf(x)andy. To this end, we can make use of the following bound:
Theorem 2. For anyα >0,p= (p1,...,pd)∈Sd−1andq∼Dirichlet (βp+α), the following inequality
holds for any η>0and anyβ≥dα/(eη/2−1):
Pr[DKL(p∥q)>η]≤e−βη2/(2(2+η)(4+3η)).
The proof can be found in Appendix F. Since the Dirichlet mechanism outputs y∼Dirichlet (rf(x) +α) =
Dirichlet (rNf/tildewidestf(x)+α), we can apply Theorem 2 with p=f(x),q=yandβ=rNf. As long as
Nf≥dα//parenleftbig
r(eη/2−1)/parenrightbig
, we have the bound
Pr/bracketleftig
DKL/parenleftig/tildewidestf(x)∥y/parenrightig
>η/bracketrightig
≤e−rNfη2/(2(2+η)(4+3η)).
We shall assume that η≪1andλ≥2. To obtain DKL/parenleftig/tildewidestf(x)∥y/parenrightig
> ηwith high probability, one needs
Nf= Ω/parenleftig
1
rη2+dα
r(eη/2−1)/parenrightig
. Now, we would like to write randαin terms of εandλusing the following
identities from Algorithm 1.
ε=1
2λr2∆2
2ψ′(1 + 3(λ−1)r∆∞) (8)
α= 1 + 4(λ−1)r∆∞. (9)
We recall from Lemma 2 that the right-hand side of equation 8 is a strictly increasing function of rfrom
0to∞. This implies that, as ε→∞, we haver→∞. Under this limit, it follows from equation 6 that
ψ′(1 + 3(λ−1)r∆∞) = Θ/parenleftig
1
(λ−1)r/parenrightig
. Thus, equation 8 and 9 give r= Θ(ε)andα= Θ((λ−1)ε). On the other
hand, as if ε→0, we haver→0which implies ψ′(1 + 3(λ−1)r∆∞) = Θ (1). Consequently, r= Θ(/radicalbig
ε/λ)
andα= Θ(1). Therefore, to attain the (λ,ε)-RDP guarantee, one needs
Nf=

Ω/parenleftig
1
εη2+d(λ−1)
eη/2−1/parenrightig
ifε≥1
Ω/parenleftbigg/radicalig
λ
ε/bracketleftig
1
η2+d
eη/2−1/bracketrightig/parenrightbigg
ifε<1.
8Published in Transactions on Machine Learning Research (02/2023)
The most common example is when the data is categorical, that is, x∈[d]Nandfi(x)is the number of i’s in
x. ThenNf=/summationtext
ifi(x) =N, and the analysis above implies that the sample complexity for (λ,ε)-RDP and
sub-ηKL divergence, with λandηfixed, isN= Ω/parenleftbig1
ε+ 1/parenrightbig
ifε≥1andN= Ω/parenleftig
1√ε/parenrightig
ifε<1.
5 Experiments and discussions
5.1 Naïve Bayes classification
We consider the Dirichlet mechanism for differentially private multinomial naïve Bayes classification. Given
a datasetD={(x(i),y(i))}N
i=1, we construct a model to classify labels y(i)∈[d]from discrete features
x(i)= (x(i)
1,...,x(i)
K)∈/producttextK
k=1Xk, whereX1,...,XKare finite sets. For j∈[d],k∈[K]andc∈Xk, we
denote the class count by Nj:=/summationtextN
i=1I(y(i)=j). For thek-th feature, we denote the feature-class count
byNk
jc:=/summationtextN
i=1I(y(i)=j,x(i)
k=c). We can use the count data to estimate the class probabilities and the
class-conditional feature probabilities:
Pr[y=j]:= ˆπj=Nj/Nand Pr[xk=c|y=j]:=ˆθk
jc=Nk
jc/Nj. (10)
The naïve Bayes model assumes that, conditioning on the label, the features are independent. As a result,
the probability of y=jconditioned on (x1,...,xK)can be computed as follows:
Pr[y=j|x1,...,xK]∝Pr[y=j]K/productdisplay
k=1Pr[xk=c|y=j]
=Nj
NK/productdisplay
k=1Nk
jxk
Nj
= ˆπjK/productdisplay
k=1ˆθk
jxk.
To modify the model with the Dirichlet mechanism, we sample (˜π1,..., ˜πd)∼Dirichlet(r(N1,...,Nd) +α),
whererandαare chosen according to Algorithm 1 (with ∆2
2= 2and∆∞= 1) to attain (λ,ε/K + 1)-RDP.
Similarly, for each k∈Kandc∈Xk, we sample (˜θk
1c,..., ˜θk
dc)∼Dirichlet/parenleftbig
rk
c(Nk
1c,...,Nk
dc) +αk
c/parenrightbig
, whererk
c
andαk
care chosen to attain (λ,ε/(K+ 1))-RDP as well. We then release ˜πjinstead of ˆπjand˜θk
jcinstead
ofˆθk
jcfor allj,kandc, which leads to (λ,ε)-RDP by the basic composition (Lemma 1) and the parallel
composition of RDP mechanisms
To benchmark the Dirichlet mechanism, we apply the Gaussian mechanism and the Laplace mechanism to
the naïve Bayes model. Specifically, we replace NjandNk
jcin equation 10 by their noisy versions, namely
˜Nj:=Nj+zjand ˜Nk
jc:=Nk
jc+zk
jcwherezj,zk
jc∼N (0,λ(K+ 1)/ε)for the Gaussian mechanism and
zj,zk
jc∼Laplace (0,b), wherebis calculated using Mironov (2017, Corollary 2) to attain (λ,ε/K )-RDP for
the Laplace mechanism.
In this experiment, the naïve Bayes models with differentially private mechanisms are used to classify 8 UCI
datasets (Dua & Graff, 2017) with diverse number of instances/attributes/classes. The details of the datasets
are shown in Table 1. For each dataset, we use a 70-30 train-test split. Before fitting the models, numerical
attributes are transformed into categorical ones using quantile binning, where the number of bins is fixed at
10.
For all privacy mechanisms, we fix λ= 5and study their performances as εincreases from 10−3to10.
We also add the random guessing model, which is a ( λ,0)-RDP model, as the baseline. The classification
performances, measured in cross-entropy (CE) loss and accuracy on the test sets, are shown in Figure 4
and 5. We can see that, on all datasets, the test CE losses of the Dirichlet mechanism are substantially
less than those of the Gaussian mechanism and Laplace mechanism; they are remarkably close to those
of the non-private model on the CreditCard, GermanCredit, Bank and Adult datasets. This result should
not be surprising, as the Dirichlet mechanism is the exponential mechanism that aims to minimize the KL
divergence, and thus the cross-entropy between the normalized counts and the parameters.
9Published in Transactions on Machine Learning Research (02/2023)
Table 1: UCI datasets used in the experiment
Dataset #Instances #Attributes #Classes %Positive Source
CreditCard 30000 23 2 22% Yeh & hui Lien (2009)
Thyroid 7200 21 3 − Quinlan et al. (1986)
Shopper 12330 17 2 15% Sakar et al. (2018)
Digit 5620 64 10 − Garris et al. (1997)
GermanCredit 1000 20 2 30% Grömping (2019)
Bank 41188 20 2 11% Moro et al. (2014)
Spam 4601 57 2 39% Cranor & LaMacchia (1998)
Adult 48842 13 2 24% Kohavi (1996)
-3 -2 -1 0 1
log10(ε)100Test CE lossCreditCard
Random
Non-private
Dirichlet
Gaussian
Laplace
-3 -2 -1 0 1
log10(ε)10−1100Test CE lossThyroid
Random
Non-private
Dirichlet
Gaussian
Laplace
-3 -2 -1 0 1
log10(ε)100Test CE lossShopper
Random
Non-private
Dirichlet
Gaussian
Laplace
-3 -2 -1 0 1
log10(ε)100101Test CE lossDigit
Random
Non-private
Dirichlet
Gaussian
Laplace
-3 -2 -1 0 1
log10(ε)100101Test CE lossGermanCredit
Random
Non-private
Dirichlet
Gaussian
Laplace
-3 -2 -1 0 1
log10(ε)100Test CE lossBank
Random
Non-private
Dirichlet
Gaussian
Laplace
-3 -2 -1 0 1
log10(ε)100101Test CE lossSpam
Random
Non-private
Dirichlet
Gaussian
Laplace
-3 -2 -1 0 1
log10(ε)100Test CE lossAdult
Random
Non-private
Dirichlet
Gaussian
Laplace
Figure 4: Test CE losses of the original and four ( 5,ε)-RDP naïve Bayes models on 8 UCI datasets.
In terms of accuracy, there is no clear winner among the three mechanisms; the Dirichlet mechanism performs
as well as the other mechanisms in most cases. Specifically, it has higher accuracies than the Gaussian
mechanism on the Digit dataset for ε>0.1, on the Adult dataset for ε<0.1, and on the Bank dataset for all
values ofε.
The difference between the two metrics stem from the fact that the cross entropy loss is a continuous function
of the predicted probability, while the accuracy is a result of applying a hard threshold on the probability.
Thus the accuracy does not distinguish between, for example, two instances, x,x′with Pr[y= 1|x] = 0.1
andPr[y= 1|x′] = 0.4, but the CE loss will suffer almost three times as much when the true label of xis1
compared to when the true label of x′is1. Thus a model with high accuracy can have relatively low CE loss
when they are too confident in their incorrect predictions.
All in all, neither metric is an end-all for measuring classification performance, and we should look at more
than one metrics when fitting a model. If one wants to publish a naïve Bayes model under privacy constraint
that performs well in both CE loss and accuracy, then the Dirichlet mechanism is an attractive option.
5.2 Parameter estimations of Bayesian networks
We use the Dirichlet mechanism for differentially private parameter estimations of discrete Bayesian networks.
Consider a dataset D={x(i)}N
i=1, wherex(i)= (x(i)
1,...,x(i)
K)∈/producttextK
k=1XkandX1,...,XKare finite sets. We
10Published in Transactions on Machine Learning Research (02/2023)
-3 -2 -1 0 1
log10(ε)0.750.760.770.780.790.80Test accuracyCreditCard
Non-private
Dirichlet
Gaussian
Laplace
-3 -2 -1 0 1
log10(ε)0.880.900.920.940.96Test accuracyThyroid
Non-private
Dirichlet
Gaussian
Laplace
-3 -2 -1 0 1
log10(ε)0.800.810.820.830.840.850.86Test accuracyShopper
Non-private
Dirichlet
Gaussian
Laplace
-3 -2 -1 0 1
log10(ε)0.20.40.60.8Test accuracyDigit
Random
Non-private
Dirichlet
Gaussian
Laplace
-3 -2 -1 0 1
log10(ε)0.450.500.550.600.650.700.75Test accuracyGermanCredit
Random
Non-private
Dirichlet
Gaussian
Laplace
-3 -2 -1 0 1
log10(ε)0.8600.8650.8700.8750.8800.8850.8900.895Test accuracyBank
Non-private
Dirichlet
Gaussian
Laplace
-3 -2 -1 0 1
log10(ε)0.650.700.750.800.85Test accuracySpam
Non-private
Dirichlet
Gaussian
Laplace
-3 -2 -1 0 1
log10(ε)0.770.780.790.800.810.82Test accuracyAdult
Non-private
Dirichlet
Gaussian
Laplace
Figure 5: Test accuracies of the original and four ( 5,ε)-RDP naïve Bayes models on 8 UCI datasets. Plots of
the random guessing on some datasets are not shown as its accuracies are well below the other models’.
name theKvariables by their index: 1,...,K. Given a Bayesian network and k∈[K], we denote the set of
parents ofk, that is, the set of direct causes of kbyPa(k). Letx(i)
Pa(k):= (x(i)
ℓ)ℓ∈Pa(k)be observed values of
Pa(k)andXPa(j):=/producttext
ℓ∈Pa(j)Xℓbe the product space of Pa(k). Givenj∈Xkandc∈XPa(k), we denote
Nk
c:=/summationtextN
i=1I(x(i)
Pa(k)=c)andNk
jc:=/summationtextN
i=1I(x(i)
k=j,x(i)
Pa(k)=c). The log-likelihood of the parameters
θk
jc:= Pr[xk=j|xPa(k)=c]is given by:
LL(θ):=/summationdisplay
k∈[K]/summationdisplay
j∈Xk
c∈XPa(k)Nk
jclogθk
jc. (11)
Using the first-derivative test, the maximum-likelihood estimators of the Bayesian network are as follow:
ˆθk
jc:=Nk
jc
Nkc. (12)
We can modify the model using the Dirichlet mechanism: assuming that Xk= [d], we replace (ˆθk
1c,..., ˆθk
dc)
by(˜θk
1c,..., ˜θk
dc)∼Dirichlet/parenleftbig
r(Nk
1c,...,Nk
dc) +α/parenrightbig
. Here,randαare chosen according to Algorithm 1 to
attain (λ,ε/K )-RDP. By the basic composition (Lemma 1) and the parallel composition, releasing ˜θk
jcfor all
k∈[K],j∈Xkandc∈XPa(k)is(λ,ε)-RDP.
We will compare the Dirichlet mechanism with the Gaussian and Laplace mechanisms. In equation 12, we
replaceNk
jcby its noisy version: ˜Nk
jc:=Nk
jc+zk
jc, wherezk
jc∼N(0,λK/ε )for the Gaussian mechanism and
zk
jc∼Laplace (0,b), wherebis calculated using Mironov (2017, Corollary 2) to attain (λ,ε/K )-RDP for the
Laplace mechanism. In addition, we replace Nk
cby˜Nk
c:=/summationtext
j˜Nk
jc.
In this experiment, we have prepared Bayesian networks on the Adult, Bank and GermanCredit datasets,
which are parts of full networks provided by Le Quy et al. (2022). The Bayesian networks are shown in
Figure 6. As in the previous experiment, we use a 70-30 train-test split on each dataset, and continuous
attributes are transformed into categorical attributes via quantile binning, with the number of bins fixed at
10.
For all privacy mechanisms, we fix λ= 5and study their performances, in terms of the log-likelihoods of
the privatized parameters on the test sets, as εincreases from 10−3to10. The plot of the log-likelihoods
11Published in Transactions on Machine Learning Research (02/2023)
Adult Bank GermanCredit
age sex
education occupation
capital-gain capital-loss
incomemonth housing
pdays poutcome previous
day-of-week campaign contact
durationyhousing property
age amountother-debtors
num-credits sex-maritalpurpose
installment-rate
credit-hist people-liable duration
other-installment foriegn-worker
Figure 6: Our Bayesian networks on three datasets.
-3 -2 -1 0 1
log10(ε)-300000.-250000.-200000.-150000.-100000.Test log-likelihoodAdult
Non-private
Dirichlet
Gaussian
Laplace
-3 -2 -1 0 1
log10(ε)-250000.-225000.-200000.-175000.-150000.-125000.Test log-likelihoodBank
Non-private
Dirichlet
Gaussian
Laplace
-3 -2 -1 0 1
log10(ε)-12500.-10000.-7500.-5000.-2500.Test log-likelihoodGermanCredit
Non-private
Dirichlet
Gaussian
Laplace
Figure 7: Test log-likelihoods of the parameters obtained from the maximum-likelihood estimation (non-
private) and three ( 5,ε)-RDP mechanisms.
as functions of εare shown in Figure 7. We can see that, on all datasets, the test log-likelihoods of the
Dirichlet mechanism are substantially less than those of the Gaussian mechanism and Laplace mechanism for
ε<1. The results agree with our suggestion to use the Dirichlet mechanism for privacy-aware KL divergence
minimization for discrete parameters, as it is equivalent to likelihood maximization.
6 Conclusion
The Dirichlet mechanism is an instance of the exponential mechanism whose loss function is the discrete
KL divergence—this motivates us to use the Dirichlet mechanism for private estimation of an empirical
distribution in KL divergence. As a consequence, the Dirichlet mechanism can be used for private likelihood
maximization and cross–entropy minimization. This work provides a choice for the multiplicative factor r
and the prior αthat achieves a desired (λ,ε)-RDP guarantee. To demonstrate its efficiency, we compare our
mechanism with the Gaussian and Laplace mechanisms for differentially private naïve Bayes classification,
and as expected, the Dirichlet mechanism provides significantly lower cross-entropy losses on various datasets
compared to the other two mechanisms. We also make a comparison between the mechanisms for maximum
likelihood estimations for Bayesian networks. Our experiment on three datasets shows that the Dirichlet
mechanism provides significantly higher log-likelihoods than the Gaussian and Laplace mechanisms.
As the KL divergence is a fundamental measure in information theory, we envision that the Dirichlet
mechanism would become essential for many privacy-focused information-theoretic models with discrete
parameters.
12Published in Transactions on Machine Learning Research (02/2023)
Broader Impact Statement
The Dirichlet mechanism does not provide privacy protection for free, but with a cost of some accuracy
loss: the higher the privacy guarantee, the lower the accuracy of the privatized model compared to the
original model. Any losses incurred from the inaccuracy must be taken into consideration before deploying
the privatized model.
Acknowledgments
The author would like to thank the reviewers and the action editors for valuable comments and suggestions.
References
Martín Abadi, Andy Chu, Ian J. Goodfellow, H. Brendan McMahan, Ilya Mironov, Kunal Talwar, and
Li Zhang. Deep learning with differential privacy. In Edgar R. Weippl, Stefan Katzenbeisser, Christopher
Kruegel, Andrew C. Myers, and Shai Halevi (eds.), Proceedings of the 2016 ACM SIGSAC Conference on
Computer and Communications Security, Vienna, Austria, October 24-28, 2016 , pp. 308–318. ACM, 2016.
doi: 10.1145/2976749.2978318. URL https://doi.org/10.1145/2976749.2978318 .
Rohit Agrawal. Finite-Sample Concentration of the Multinomial in Relative Entropy. IEEE Transactions on
Information Theory , 66(10):6297–6302, October 2020. ISSN 1557-9654. doi: 10.1109/TIT.2020.2996134.
Necdet Batir. Some new inequalities for gamma and polygamma functions. Research report collection , 7(3),
2004. URL https://vuir.vu.edu.au/17580/ .
Garrett Bernstein and Daniel R. Sheldon. Differentially private bayesian inference for exponential
families. In Samy Bengio, Hanna M. Wallach, Hugo Larochelle, Kristen Grauman, Nicolò Cesa-
Bianchi, and Roman Garnett (eds.), Advances in Neural Information Processing Systems 31: An-
nual Conference on Neural Information Processing Systems 2018, NeurIPS 2018, December 3-8, 2018,
Montréal, Canada , pp. 2924–2934, 2018. URL https://proceedings.neurips.cc/paper/2018/hash/
08040837089cdf46631a10aca5258e16-Abstract.html .
Clément L. Canonne, Gautam Kamath, and Thomas Steinke. The discrete gaussian for differential privacy.
In Hugo Larochelle, Marc’Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin
(eds.),Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information
Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual , 2020. URL https://proceedings.
neurips.cc/paper/2020/hash/b53b3a3d6ab90ce0268229151c9bde11-Abstract.html .
Lorrie Faith Cranor and Brian A. LaMacchia. Spam! Commun. ACM , 41(8):74–83, aug 1998. ISSN 0001-0782.
doi: 10.1145/280324.280336. URL https://doi.org/10.1145/280324.280336 .
Christos Dimitrakakis, Blaine Nelson, Zuhe Zhang, Aikaterini Mitrokotsa, and Benjamin I. P. Rubinstein.
Differential privacy for bayesian inference through posterior sampling. J. Mach. Learn. Res. , 18:11:1–11:39,
2017. URL http://jmlr.org/papers/v18/15-257.html .
Dheeru Dua and Casey Graff. UCI machine learning repository, 2017. URL http://archive.ics.uci.edu/
ml.
Cynthia Dwork and Aaron Roth. The algorithmic foundations of differential privacy. Found. Trends
Theor. Comput. Sci. , 9(3-4):211–407, 2014. doi: 10.1561/0400000042. URL https://doi.org/10.1561/
0400000042 .
Cynthia Dwork, Krishnaram Kenthapadi, Frank McSherry, Ilya Mironov, and Moni Naor. Our data, ourselves:
Privacy via distributed noise generation. In Serge Vaudenay (ed.), Advances in Cryptology - EUROCRYPT
2006, 25th Annual International Conference on the Theory and Applications of Cryptographic Techniques, St.
Petersburg, Russia, May 28 - June 1, 2006, Proceedings , volume 4004 of Lecture Notes in Computer Science ,
pp. 486–503. Springer, 2006a. doi: 10.1007/11761679\_29. URL https://doi.org/10.1007/11761679_29 .
13Published in Transactions on Machine Learning Research (02/2023)
Cynthia Dwork, Frank Mcsherry, Kobbi Nissim, and Adam Smith. Calibrating noise to sensitivity in private
data analysis. In TCC, 2006b.
James R. Foulds, Joseph Geumlek, Max Welling, and Kamalika Chaudhuri. On the theory and practice of
privacy-preserving bayesian data analysis. In Alexander T. Ihler and Dominik Janzing (eds.), Proceedings
of the Thirty-Second Conference on Uncertainty in Artificial Intelligence, UAI 2016, June 25-29, 2016, New
York City, NY, USA . AUAI Press, 2016. URL http://auai.org/uai2016/proceedings/papers/45.pdf .
Michael Garris, J Blue, Gerald Candela, Patrick Grother, Stanley Janet, and Charles Wilson. Nist form-based
handprint recognition system, 1997-01-01 1997.
Joseph Geumlek, Shuang Song, and Kamalika Chaudhuri. Renyi differential privacy mechanisms for
posterior sampling. In Isabelle Guyon, Ulrike von Luxburg, Samy Bengio, Hanna M. Wallach, Rob
Fergus, S. V. N. Vishwanathan, and Roman Garnett (eds.), Advances in Neural Information Processing
Systems 30: Annual Conference on Neural Information Processing Systems 2017, December 4-9, 2017,
Long Beach, CA, USA , pp. 5289–5298, 2017. URL https://proceedings.neurips.cc/paper/2017/
hash/56584778d5a8ab88d6393cc4cd11e090-Abstract.html .
Parham Gohari, Bo Wu, Calvin Hawkins, Matthew T. Hale, and Ufuk Topcu. Differential privacy on the
unit simplex via the dirichlet mechanism. IEEE Trans. Inf. Forensics Secur. , 16:2326–2340, 2021. doi:
10.1109/TIFS.2021.3052356. URL https://doi.org/10.1109/TIFS.2021.3052356 .
Ulrike Grömping. South german credit data: Correcting a widely used data set. Reports in mathematics,
physics and chemistry, Department II, Beuth University of Applied Sciences Berlin, 4 2019.
Abdolhossein Hoorfar and Mehdi Hassani. Inequalities on the lambert w function and hyperpower function.
J. Inequal. Pure and Appl. Math , 9(2):5–9, 2008.
Ron Kohavi. Scaling up the accuracy of naive-bayes classifiers: A decision-tree hybrid. In Proceedings of the
Second International Conference on Knowledge Discovery and Data Mining , KDD’96, pp. 202–207. AAAI
Press, 1996.
Tai Le Quy, Arjun Roy, Vasileios Iosifidis, Wenbin Zhang, and Eirini Ntoutsi. A survey on datasets for
fairness-aware machine learning. WIREs Data Mining and Knowledge Discovery , 12(3):e1452, 2022.
doi: https://doi.org/10.1002/widm.1452. URL https://wires.onlinelibrary.wiley.com/doi/abs/10.
1002/widm.1452 .
Ashwin Machanavajjhala, Daniel Kifer, John M. Abowd, Johannes Gehrke, and Lars Vilhuber. Privacy:
Theory meets practice on the map. In Gustavo Alonso, José A. Blakeley, and Arbee L. P. Chen (eds.),
Proceedings of the 24th International Conference on Data Engineering, ICDE 2008, April 7-12, 2008,
Cancún, Mexico , pp. 277–286. IEEE Computer Society, 2008. doi: 10.1109/ICDE.2008.4497436. URL
https://doi.org/10.1109/ICDE.2008.4497436 .
Frank McSherry and Kunal Talwar. Mechanism design via differential privacy. In 48th Annual IEEE
Symposium on Foundations of Computer Science (FOCS 2007), October 20-23, 2007, Providence, RI,
USA, Proceedings , pp. 94–103. IEEE Computer Society, 2007. doi: 10.1109/FOCS.2007.41. URL https:
//doi.org/10.1109/FOCS.2007.41 .
Ilya Mironov. Rényi differential privacy. In 30th IEEE Computer Security Foundations Symposium, CSF
2017, Santa Barbara, CA, USA, August 21-25, 2017 , pp. 263–275. IEEE Computer Society, 2017. doi:
10.1109/CSF.2017.11. URL https://doi.org/10.1109/CSF.2017.11 .
Sérgio Moro, Paulo Cortez, and Paulo Rita. A data-driven approach to predict the success of bank
telemarketing. Decision Support Systems , 62:22–31, June 2014. doi: 10.1016/j.dss.2014.03.001. URL
https://doi.org/10.1016/j.dss.2014.03.001 .
John Ross Quinlan, Paul J Compton, KA Horn, and Leslie Lazarus. Inductive knowledge acquisition: a
case study. In Proceedings of the second Australian Conference on the Applications of Expert Systems , pp.
183–204, 1986.
14Published in Transactions on Machine Learning Research (02/2023)
Alfréd Rényi. On measures of entropy and information. In Proceedings of the Fourth Berkeley Symposium on
Mathematical Statistics and Probability, Volume 1: Contributions to the Theory of Statistics . The Regents
of the University of California, 1961.
C. Okan Sakar, S. Olcay Polat, Mete Katircioglu, and Yomi Kastro. Real-time prediction of online shoppers’
purchasing intention using multilayer perceptron and LSTM recurrent neural networks. Neural Computing
and Applications , 31(10):6893–6908, May 2018. doi: 10.1007/s00521-018-3523-0. URL https://doi.org/
10.1007/s00521-018-3523-0 .
Reza Shokri, Marco Stronati, Congzheng Song, and Vitaly Shmatikov. Membership inference attacks
against machine learning models. In 2017 IEEE Symposium on Security and Privacy, SP 2017, San Jose,
CA, USA, May 22-26, 2017 , pp. 3–18. IEEE Computer Society, 2017. doi: 10.1109/SP.2017.41. URL
https://doi.org/10.1109/SP.2017.41 .
Aki Vehtari, Andrew Gelman, and Jonah Gabry. Practical bayesian model evaluation using leave-one-out
cross-validation and WAIC. Statistics and Computing , 27(5):1413–1432, August 2016. doi: 10.1007/
s11222-016-9696-4. URL https://doi.org/10.1007/s11222-016-9696-4 .
Yu-Xiang Wang, Stephen E. Fienberg, and Alexander J. Smola. Privacy for free: Posterior sampling
and stochastic gradient monte carlo. In Francis R. Bach and David M. Blei (eds.), Proceedings of
the 32nd International Conference on Machine Learning, ICML 2015, Lille, France, 6-11 July 2015 ,
volume 37 of JMLR Workshop and Conference Proceedings , pp. 2493–2502. JMLR.org, 2015. URL
http://proceedings.mlr.press/v37/wangg15.html .
Jiayuan Ye, Aadyaa Maddi, Sasi Kumar Murakonda, Vincent Bindschaedler, and Reza Shokri. Enhanced
membership inference attacks against machine learning models. In Heng Yin, Angelos Stavrou, Cas
Cremers, and Elaine Shi (eds.), Proceedings of the 2022 ACM SIGSAC Conference on Computer and
Communications Security, CCS 2022, Los Angeles, CA, USA, November 7-11, 2022 , pp. 3093–3106. ACM,
2022. doi: 10.1145/3548606.3560675. URL https://doi.org/10.1145/3548606.3560675 .
I-Cheng Yeh and Che hui Lien. The comparisons of data mining techniques for the predictive accuracy of
probability of default of credit card clients. Expert Systems with Applications , 36(2):2473–2480, March
2009. doi: 10.1016/j.eswa.2007.12.020. URL https://doi.org/10.1016/j.eswa.2007.12.020 .
A Dirichlet posterior sampling is not ε-differentially private
We show that the Dirichlet posterior sampling does not satisfy the original notion of differential privacy—the
pure differential privacy.
Proposition 3. For anyε>0, the mechanism that outputs y∼Dirichlet (rf(x) +α)is notε-differentially
private.
Proof.Without loss of generality, let x= (0,0,..., 0)andx′= (1,0,..., 0). Letα > 0be any positive
number. Let y∼Dirichlet (rf(x) +α)andy′∼Dirichlet (rf(x′) +α). For anyy0= (y1,y2,...,yd)with/summationtext
iyi= 1, we have
Pr[y=y0]
Pr[y′=y0]=B(rf(x′) +α)
B(rf(x) +α)·/producttext
iyrfi(x)+α
i/producttext
iyrfi(x′)+α
i
=B(rf(x′) +α)
B(rf(x) +α)·1
y1.
For anyε>0, we can choose a sufficiently small y1>0so that the right-hand side is larger than eε.
15Published in Transactions on Machine Learning Research (02/2023)
0 2 4 6 8 10r10−1100101ˆε
λ= 2
λ= 10
λ= 50
λ= 200
Figure 8: (ε,δ)-DP guarantees of the Dirichlet mechanism following equation 14 with λ∈{2,10,50,200}and
δ= 10−5.
B Approximate differential privacy
We can convert from RDP to approximate DP with the following conversion formula:
Lemma 3 (From RDP to Approximate DP (Canonne et al., 2020)) .Letε >0. IfMis a (λ,ε)-RDP
mechanism, then it also satisfies (ˆε,δ)-DP with
δ=exp((λ−1)(ε−ˆε))
λ−1/parenleftbigg
1−1
λ/parenrightbiggλ
. (13)
Taking the logarithm of equation 13,
logδ= (λ−1)(ε−ˆε) + (λ−1) log(λ−1)−λlog(λ),
which is equivalent to
ˆε=ε+ log(λ−1)−logδ+λlog(λ)
λ−1.
Plugging in the RDP guarantee in Algorithm 1, we obtain
ˆε=1
2λr2∆2
2ψ′(1 + 3(λ−1)r∆∞) + log(λ−1)−logδ+λlog(λ)
λ−1, (14)
which gives a formula for ˆεin terms of r,λandδ. Figure 8 shows ˆεas a function of rat four different values
ofλ. We can see that, at a fixed δ,ˆεis increased when we increase rand decrease λ.
C Experiments with approximate DP
We perform the same experiments as those in Section 5. But this time, we focus on approximate DP instead
of RDP, and we also include the Dirichlet mechanism with Gohari et al. (2021)’s privacy guarantee in the
experiments. Our ( λ,ε)-RDP guarantee of the Dirichlet mechanism is converted to (ˆε,δ)-DP guarantee,
withδ= 10−5, using the material in Section sec:adp. The results of the naïve Bayes and Bayesian network
experiments are shown in Figure 9 and Figure 10, and those of the Bayesian networks are shown in Figure 11.
Aside from similar results as those in Section 5, We highlight that our Dirichlet mechanism performs better
than Gohari et al.’s in all experiments, and Gohari et al.’s mechanism performs significantly worse for smaller
values of ˆε. We also notice that, in contrast to the results in Section 5 the Laplace mechanism performs
better than the Gaussian mechanism; this is because the composition property for multiple uses of an ˆεDP
mechanism is better than that of an (ˆε,δ)-DP for any δ>0(see Dwork & Roth (2014, Theorem 3.20)).
16Published in Transactions on Machine Learning Research (02/2023)
-2 -1 0 1
log10(ˆε)100101Test CE lossCreditCard
Random
Non-private
Dirichlet
Gohari et al.
Gaussian
Laplace
-2 -1 0 1
log10(ˆε)10−1100101Test CE lossThyroid
Random
Non-private
Dirichlet
Gohari et al.
Gaussian
Laplace
-2 -1 0 1
log10(ˆε)100101Test CE lossShopper
Random
Non-private
Dirichlet
Gohari et al.
Gaussian
Laplace
-2 -1 0 1
log10(ˆε)100101Test CE lossDigit
Random
Non-private
Dirichlet
Gohari et al.
Gaussian
Laplace
-2 -1 0 1
log10(ˆε)100101Test CE lossGermanCredit
Random
Non-private
Dirichlet
Gohari et al.
Gaussian
Laplace
-2 -1 0 1
log10(ˆε)100101Test CE lossBank
Random
Non-private
Dirichlet
Gohari et al.
Gaussian
Laplace
-2 -1 0 1
log10(ˆε)100101Test CE lossSpam
Random
Non-private
Dirichlet
Gohari et al.
Gaussian
Laplace
-2 -1 0 1
log10(ˆε)100101Test CE lossAdult
Random
Non-private
Dirichlet
Gohari et al.
Gaussian
Laplace
Figure 9: Test CE losses of the original and five ( ˆε,10−5)-RDP naïve Bayes models on 8 UCI datasets.
-2 -1 0 1
log10(ˆε)0.450.500.550.600.650.700.750.80Test accuracyCreditCard
Non-private
Dirichlet
Gohari et al.
Gaussian
Laplace
-2 -1 0 1
log10(ˆε)0.20.30.40.50.60.70.80.91.0Test accuracyThyroid
Non-private
Dirichlet
Gohari et al.
Gaussian
Laplace
-2 -1 0 1
log10(ˆε)0.40.50.60.70.8Test accuracyShopper
Non-private
Dirichlet
Gohari et al.
Gaussian
Laplace
-2 -1 0 1
log10(ˆε)0.20.40.60.8Test accuracyDigit
Random
Non-private
Dirichlet
Gohari et al.
Gaussian
Laplace
-2 -1 0 1
log10(ˆε)0.400.450.500.550.600.650.700.75Test accuracyGermanCredit
Random
Non-private
Dirichlet
Gohari et al.
Gaussian
Laplace
-2 -1 0 1
log10(ˆε)0.500.550.600.650.700.750.800.850.90Test accuracyBank
Non-private
Dirichlet
Gohari et al.
Gaussian
Laplace
-2 -1 0 1
log10(ˆε)0.30.40.50.60.70.80.9Test accuracySpam
Non-private
Dirichlet
Gohari et al.
Gaussian
Laplace
-2 -1 0 1
log10(ˆε)0.450.500.550.600.650.700.750.80Test accuracyAdult
Non-private
Dirichlet
Gohari et al.
Gaussian
Laplace
Figure 10: Test accuracies of the original and five ( ˆε,10−5)-DP naïve Bayes models on 8 UCI datasets. Plots
of the random guessing on some datasets are not shown as its accuracies are well below the other models’.
17Published in Transactions on Machine Learning Research (02/2023)
-1 0 1 2
log10(ˆε)-100000.
-500000.Test log-likelihoodAdult
Non-private
Dirichlet
Gohari et al.
Gaussian
Laplace
-1 0 1 2
log10(ˆε)-800000.-600000.-400000.-200000.Test log-likelihoodBank
Non-private
Dirichlet
Gohari et al.
Gaussian
Laplace
-1 0 1 2
log10(ˆε)-10000.Test log-likelihoodGermanCredit
Non-private
Dirichlet
Gohari et al.
Gaussian
Laplace
Figure 11: Test log-likelihoods of the parameters obtained from the maximum-likelihood estimation (non-
private) and four ( ˆε,10−5)-DP mechanisms.
D Proof of Lemma 2
Denotex= 3(λ−1)r∆∞. Withε,λ,∆2and∆∞fixed as constants, we can write the equation as ε=
Cx2ψ′(1 +x)for some constant C > 0. From equation 6, we have ψ′(1 +x) = Θ/parenleftig
1
(1+x)2/parenrightig
asx→0and
ψ′(x) = Θ/parenleftig
1
1+x/parenrightig
asx→∞. Consequently,
lim
x→0x2ψ′(1 +x) = 0and lim
x→∞x2ψ′(1 +x) =∞. (15)
The conclusion will follow if we can show that the function ϕ(x):=x2ψ′(1 +x)is strictly increasing. For this,
first we use ψ′(1 +x)<1
1+x+1
(1+x)2to obtain
[ψ′(1 +x)]2<ψ′(1 +x)
1 +x+ψ′(1 +x)
(1 +x)2≤2ψ′(1 +x)
1 +x<2ψ′(1 +x)
x.
In other words, 2ψ′(1 +x)>x[ψ′(1 +x)]2. Combining this with [ψ′(x)]2+ψ′′(x)>0(see e.g. Batir (2004,
Lemma1.1)), we have
ϕ′(x) = 2xψ′(1 +x) +x2ψ′′(1 +x)>x2[ψ′(1 +x)]2+x2ψ′′(1 +x) =x2/parenleftbig
[ψ′(x)]2+ψ′′(x)/parenrightbig
>0.
Therefore,ϕ(x)is strictly increasing, which, combined with equation 15, implies that the equation ϕ(x) =ε
has a unique solution xεfor anyε>0. We then obtain a solution in rby lettingr=xε/(3(λ−1)∆∞).
E Proof of Theorem 1
Case 1:λ>1.
Letxandx′be neighboring datasets. For notational convenience, let u:=rf(x) +αandu′:=rf(x′) +α.
As usual, we write u= (u1,...,ud),u′= (u′
1,...,u′
d),u0:=/summationtext
iuiandu′
0:=/summationtext
iu′
i. LetP(y)be the density
ofDirichlet (u)andP′(y)be the density of Dirichlet (u′). To compute the Rényi divergence between P(y)and
P′(y), we start with:
Ey∼P(y)/bracketleftbiggP(y)λ−1
P′(y)λ−1/bracketrightbigg
=B(u′)λ−1
B(u)λ−1Ey∼P(y)/bracketleftig
y(λ−1)(u−u′)/bracketrightig
=B(u′)λ−1
B(u)λ−1·B(u+ (λ−1)(u−u′))
B(u), (16)
whereB(u) = Γ(u0)−1/producttext
iΓ(ui)is the multivariate beta function. Thus the ratio can be expressed in terms
of gamma functions:
B(u′)
B(u)=/producttext
iΓ(u′
i)/Γ(/summationtext
iu′
i)/producttext
iΓ(ui)/Γ(/summationtext
iui)=Γ(u0)
Γ(u′
0)/productdisplay
iΓ(u′
i)
Γ(ui),
18Published in Transactions on Machine Learning Research (02/2023)
whereu0:=/summationtext
iuiandu′
0:=/summationtext
iu′
i. Similarly,
B(u+ (λ−1)(u−u′))
B(u)=Γ(/summationtext
iui)
Γ(/summationtext
iui+ (λ−1)/summationtext
i(ui−u′
i))/productdisplay
iΓ(ui+ (λ−1)(ui−u′
i))
Γ(ui).
Taking the logarithm on both side of equation 16, we need to find an upper bound of:
logEy∼P(y)/bracketleftbiggP(y)λ−1
P′(y)λ−1/bracketrightbigg
=/summationdisplay
i(G(ui,u′
i) +H(ui,u′
i))−G(u0,u′
0)−H(u0,u′
0), (17)
where
G(ui,u′
i):= (λ−1)(log Γ(u′
i)−log Γ(ui))
H(ui,u′
i):= log Γ(ui+ (λ−1)(ui−u′
i))−log Γ(ui),
and similarly for G(u0,u′
0)andH(u0,u′
0). Using the second-order Taylor expansion, there exists ξbetween
ui+ (λ−1)(ui−u′
i)andui, andξ′betweenuiandu′
isuch that
G(ui,u′
i) =−(λ−1)(ui−u′
i)ψ(ui) +1
2(λ−1)(ui−u′
i)2ψ′(ξ′)
=−(λ−1)(fi(x)−fi(x′))rψ(ui) +1
2(λ−1)(fi(x)−fi(x′))2r2ψ′(ξ′)
H(ui,u′
i) = (λ−1)(ui−u′
i)ψ(ui) +1
2(λ−1)2(ui−u′
i)2ψ′(ξ)
= (λ−1)(fi(x)−fi(x′))rψ(ui) +1
2(λ−1)2(fi(x)−fi(x′))2r2ψ′(ξ).
We try to find an upper bound of both ψ′(ξ)andψ′(ξ′). Iffi(x)>fi(x′), thenu′
i<ui<ui+ (λ−1)(ui−u′
i).
Thus bothξandξ′are bounded below by u′
i≥α. On the other hand, if fi(x)≤fi(x′), thenui+ (λ−1)(ui−
u′
i)≤ui≤u′
i. In this case, ξandξ′are bounded below by:
ui+ (λ−1)(ui−u′
i) =fi(x) +α−(λ−1)(rfi(x′)−rfi(x))
≥α−(λ−1)r∆∞.
Sinceψ′is decreasing, both ψ′(ξ)andψ′(ξ′)are bounded above by ψ′(α−(λ−1)r∆∞). Consequently,
G(ui,u′
i) +H(ui,u′
i)≤1
2/parenleftbig
(λ−1) + (λ−1)2/parenrightbig
(fi(x)−fi(x′))2r2ψ′(α−(λ−1)r∆∞)
=1
2λ(λ−1)(fi(x)−fi(x′))2r2ψ′(α−(λ−1)r∆∞).
The same argument can be used to show that, there exist ξ0andξ′
0such that:
G(u0,u′
0) +H(u0,u′
0) =1
2(λ−1)(u0−u′
0)2ψ′(ξ′
0) +1
2(λ−1)2(u0−u′
0)2ψ′(ξ0)>0.
Therefore, continuing from equation 17,
Dλ(P(y)∥P′(y)) =1
λ−1/parenleftigg/summationdisplay
i(G(ui,u′
i) +H(ui,u′
i))−G(u0,u′
0)−H(u0,u′
0)/parenrightigg
<1
λ−1/summationdisplay
i(G(ui,u′
i) +H(ui,u′
i))
≤1
2λ/summationdisplay
i(fi(xi)−fi(x′
i))2r2ψ′(α−(λ−1)r∆∞)
≤1
2λ∆2
2r2ψ′(α−(λ−1)r∆∞). (18)
19Published in Transactions on Machine Learning Research (02/2023)
Case 2:λ= 1.
We use the following formula for the KL divergence between two Dirichlet distributions:
DKL(P(y)∥P′(y)) = log Γ(u0)−/summationdisplay
ilog Γ(ui)−log Γ(u′
0)
+/summationdisplay
ilog Γ(u′
i) +/summationdisplay
i(ui−u′
i)(ψ(ui)−ψ(u0)),
From this, we split the right-hand side into two parts and apply the Taylor approximation as before:
−/summationdisplay
ilog Γ(ui) +/summationdisplay
ilog Γ(u′
i) +/summationdisplay
i(ui−u′
i)ψ(ui)≤1
2/summationdisplay
i(ui−u′
i)2ψ′(min{ui,u′
i})
≤1
2/summationdisplay
i(ui−u′
i)2ψ′(1)
=1
2/summationdisplay
i(fi(xi)−fi(x′
i))2r2ψ′(1)
≤1
2∆2
2r2ψ′(1),
and
log Γ(u0)−log Γ(u′
0)−/summationdisplay
i(u0−u′
0)ψ(u0)≤−1
2/summationdisplay
i(ui−u′
i)2ψ′(max{u0,u′
0})
≤0.
Adding these two inequalities yields the same inequality as equation 18 with λ= 1.
Thus, given any λ≥1,ε>0and anyg:R>0→R>0, if we letrbe the solution of1
2λr2∆2
2ψ′(1 +g(r)) =ε
andα= 1 +g(r) + (λ−1)r∆∞, then the inequality above implies Dλ(P(y)∥P′(y))<ε. We conclude that
Algorithm 1 by setting g(r) = 3(λ−1)r∆∞.
F Proof of the Utility bound
We first note a pair of inequalities for the digamma function, which hold for all x>1
2:
log/parenleftbigg
x−1
2/parenrightbigg
<ψ(x)<logx. (19)
We start with the Chernoff bound: for any t≤β,
Pr[DKL(p∥q)>η]≤e−tηE/bracketleftig
etDKL(p∥q)/bracketrightig
=e−tηE/bracketleftigg/productdisplay
i(pi/qi)tpi/bracketrightigg
=e−tη/productdisplay
iptpi
iE/bracketleftigg/productdisplay
iq−tpi
i/bracketrightigg
=e−tη/productdisplay
iptpi
i1
B(βp+α)/integraldisplay/productdisplay
iqβpi−tpi+α−1
i dq
=e−tη/productdisplay
iptpi
iB(βp−tpi+α)
B(βp+α)
=e−tηΓ(β+dα)
Γ(β−t+dα)/productdisplay
iptpi
iΓ(βpi−tpi+α)
Γ(βpi+α). (20)
20Published in Transactions on Machine Learning Research (02/2023)
Using the first-order Taylor approximation, we have the following estimates for log-gamma functions:
log Γ(β+dα)≤log Γ(β−t+dα) +tψ(β+dα)
log Γ(βpi−tpi+α)≤log Γ(βpi+dα)−tpiψ(βpi−tpi+α).
Inserting these inequalities and equation 19 into equation 20, we obtain
Pr[DKL(p∥q)>η]≤e−tηetψ(β+dα)/productdisplay
iptpi
ie−tpiψ(βpi−tpi+α)
<e−tηetlog(β+dα)/productdisplay
iptpi
ie−tpilog(βpi−tpi+α−1/2)
=e−tη(β+dα)t/productdisplay
iptpi
i(βpi−tpi+α−1/2)−tpi
=e−tη(β+dα)t/productdisplay
i/parenleftbig
β−t+p−1
i(α−1/2)/parenrightbig−tpi
=e−tη/productdisplay
i/parenleftbiggβ+dα
β−t+p−1
i(α−1/2)/parenrightbiggtpi
<e−tη/productdisplay
i/parenleftbiggβ+dα
β−t/parenrightbiggtpi
=e−tη/parenleftbiggβ+dα
β−t/parenrightbiggt
= exp/parenleftbigg
−tη+tlogβ+dα
β−t/parenrightbigg
:= exp(f(t)). (21)
The function f(t)is minimized at t∗:=β/parenleftbigg
1−W/parenleftig
βe1+η
β+dα/parenrightig−1/parenrightbigg
, whereWis the Lambert Wfunction. Note
thatWsatisfies the identity log(W(x)/x) =−W(x)for allx≥−e−1. Therefore,
f(t∗) =−t∗η+t∗logβ+dα
β−t∗
=−t∗η+t∗log/braceleftbiggβ+dα
β)W/parenleftbiggβe1+η
β+dα/parenrightbigg/bracerightbigg
=−t∗η+t∗log/braceleftbiggβ+dα
βe1+ηW/parenleftbiggβe1+η
β+dα/parenrightbigg/bracerightbigg
+t∗loge1+η
=−t∗η−t∗W/parenleftbiggβe1+η
β+dα/parenrightbigg
+t∗(1 +η)
=t∗/parenleftbigg
1−W/parenleftbiggβe1+η
β+dα/parenrightbigg/parenrightbigg
=−β/parenleftigg
1−W/parenleftbiggβe1+η
β+dα/parenrightbigg−1/parenrightigg/parenleftbigg
W/parenleftbiggβe1+η
β+dα/parenrightbigg
−1/parenrightbigg
. (22)
21Published in Transactions on Machine Learning Research (02/2023)
The assumption β≥dα/(eη/2−1)impliesβ/(β+dα)≥e−η/2. We use the inequality W(x)≥logx−
log logx+ log logx/(2 logx)forx≥e(Hoorfar & Hassani, 2008, Theorem 2.7) to obtain
W/parenleftbiggβe1+η
β+dα/parenrightbigg
≥W/parenleftig
e1+η/2/parenrightig
≥1 +η
2−log/parenleftig
1 +η
2/parenrightig
+log(1 +η/2)
2(1 +η/2)
= 1 +η
2−/parenleftbigg1 +η
2 +η/parenrightbigg
log/parenleftig
1 +η
2/parenrightig
≥1 +η
2−η
2·1 +η
2 +η
= 1 +η
2(2 +η).
Continuing from equation 22, we have
f(t∗)≤−β/parenleftigg
1−/parenleftbigg
1 +η
2(2 +η)/parenrightbigg−1/parenrightigg/parenleftbigg
1 +η
2(2 +η)−1/parenrightbigg
=−β/parenleftbiggη2
2(2 +η)(4 + 3η)/parenrightbigg
.
Inserting this inequality back into equation 21, we obtain
Pr[DKL(p∥q)>η]≤exp(f(t))≤exp(f(t∗))≤e−βη2/(2(2+η)(4+3η)),
as desired.
22