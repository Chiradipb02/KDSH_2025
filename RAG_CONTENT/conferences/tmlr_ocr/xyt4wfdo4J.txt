Published in Transactions on Machine Learning Research (06/2022)
Iterative State Estimation in Non-linear Dynamical Systems
Using Approximate Expectation Propagation
Sanket Kamthe∗sanketkamthe@gmail.com
Department of Computing, Imperial College London
Chief Technology Office, JP Morgan Chase
So Takao∗so.takao@ucl.ac.uk
UCL Centre for Artificial Intelligence, University College London
Shakir Mohamed†
Department of Computer Science, University College London
Marc Peter Deisenroth
UCL Centre for Artificial Intelligence, University College London
Reviewed on OpenReview: https: // openreview. net/ forum? id= xyt4wfdo4J
Abstract
Bayesian inference in non-linear dynamical systems seeks to find good posterior approxi-
mations of a latent state given a sequence of observations. Gaussian filters and smoothers,
including the (extended/unscented) Kalman filter/smoother, which are commonly used in
engineering applications, yield Gaussian posteriors on the latent state. While they are
computationally efficient, they are often criticised for their crude approximation of the pos-
terior state distribution. In this paper, we address this criticism by proposing a message
passing scheme for iterative state estimation in non-linear dynamical systems, which yields
more informative (Gaussian) posteriors on the latent states. Our message passing scheme
is based on expectation propagation (EP). We prove that classical Rauch–Tung–Striebel
(RTS) smoothers, such as the extended Kalman smoother (EKS) or the unscented Kalman
smoother (UKS), are special cases of our message passing scheme. Running the message
passing scheme more than once can lead to significant improvements of the classical RTS
smoothers, so that more informative state estimates can be obtained. We address potential
convergence issues of EP by generalising our state estimation framework to damped updates
and the consideration of general α-divergences.
1 Introduction
Dynamical systems (state space models) are powerful tools for describing (latent) time-series with noisy
observations. Dynamicalsystemsarecommonlyusedinsignalprocessing, controltheory, andclimatescience.
Given a sequence of noisy observations, estimating the (posterior) distribution of the latent states in a
dynamical system plays an important role, e.g., in optimal control theory (Åström, 2006; Bertsekas, 2005),
data assimilation (Lakshmivarahan & Stensrud, 2009), or robotics (Thrun et al., 2005; Barfoot, 2017).
For linear systems with Gaussian noise, an optimal estimate of posterior distributions of the latent states
conditioned on the observations up to the current time step is given in closed form by the Kalman fil-
ter (Kalman, 1960). The estimate conditioned on all (including future) measurements of a finite time series
is given by the Rauch–Tung–Striebel (RTS) (Rauch et al., 1965) smoother. The efficiency of the Kalman
∗Equal contribution.†Also with DeepMind.
1Published in Transactions on Machine Learning Research (06/2022)
filter and the RTS smoother stems from the closure property of Gaussian densities under linear/affine trans-
formations, conditioning, and marginalisation. These closure properties allow us to derive recursive filtering
and smoothing equations in closed form (Anderson & Moore, 2005).
In non-linear systems, these computationally convenient properties no longer hold; in particular, a non-linear
transformation of a Gaussian density yields a non-Gaussian density. Typically, we tackle this challenge
either by approximating a non-Gaussian density by a Gaussian density (Maybeck, 1979; Julier et al., 2000;
Arasaratnam & Haykin, 2009) or by using sampling-based methods, e.g., the particle filter (Doucet et al.,
2000), to represent non-Gaussian densities by means of particles. In this article, we focus on the former, i.e.,
finding better Gaussian approximations for non-Gaussian densities.
By making a Gaussian approximation to the distribution of the latent states, we are in fact either implicitly
or explicitly linearising the non-linear transformation. The quality of these approximations depends on the
mechanism used for the linearisation. A crude approximation may introduce large errors, which we can
alleviate by iteratively correcting previous estimates (Lefebvre et al., 2004). For example, in the iterative
extended Kalman filter (IEKF) (Corporation, 1974), measurement updates are carried out iteratively until
convergence, where the point around which one linearises the measurement function is refined iteratively.
This is shown to be equivalent to a Gauß–Newton method for MAP estimation (Bell & Cathey, 1993).
An iterative version of the extended Kalman smoother has also been proposed (Bell, 1994), which, again
is equivalent to a Gauß–Newton method for MAP estimation. Recent progress (Raitoharju et al., 2018;
Gultekin & Paisley, 2017) shows that the Bayesian framework and iterative updates can give significant
improvement over standard filtering and smoothing.
All Gaussian filtering systems assume that we can project the true posterior onto a Gaussian (Thrun et al.,
2005) with a reasonable approximation error. More generally, this can be interpreted as an approximate
assumed density filter (ADF) with a Gaussian assumption on densities. In the ADF, the approximate
posterior is obtained by minimising the Kullback–Leibler ( KL) divergence between the true posterior and
the assumed density. For a Gaussian assumed density, this amounts to computing the first two moments
of the true posterior and approximating it with a Gaussian that possesses the same first two moments. In
the Assumed Density Smoother, as well in the iterative Kalman smoothers, there is no mechanism to revisit
previously filtered estimates and correct them based on all the observations.
This shortcoming was addressed by expectation propagation (EP) proposed by Minka (2001a;b); Opper &
Winther (2001). EP extends the ADF by adding a mechanism to iteratively update previous computations
without double-counting observations. For linear Gaussian systems, one full iteration of EP is identical to
the Kalman filter-smoother (Minka, 2001a; Heskes & Zoeter, 2002; Qi & Minka, 2003). Hence, EP is optimal
for linear systems.
One can extend EP to non-linear systems in a manner that is similar to the generalised Gaussian filters.
This extension is motivated by results in (Dehaene & Barthelmé, 2016), who show that EP has an order
of magnitude lower asymptotic error bound compared to a canonical Gaussian approximation for non-
linear systems. Furthermore, applying EP to non-linear systems allows us to perform multiple sweeps
of RTS smoothing, iterating over measurement and transition non-linearities conditioned on all available
observations. We note that the IEKF systems can only iterate over measurement non-linearities and the
IEKS (Bell, 1994), being a MAP estimator, does not properly account for posterior uncertainties. EP can
be implemented as a message passing algorithm. Hence, it can be used as a distributed (and asynchronous)
state estimator and is not limited to the sequential nature of iterative Kalman filters.
One challenge with implementing EP is that its efficacy relies on the ease of computing moments with
respect to the true posterior; for non-linear systems, the exact posterior is often intractable. In this work,
we propose to approximate the true posterior by linearisation methods, such as the unscented transform
(Julier et al., 2000). Hence, we only implement approximate EP when we apply EP to non-linear systems.
We prove that this approximate EP exactly recovers the respective RTS smoothers, e.g., with the unscented
transform approximation we obtain the unscented Kalman smoother (Särkkä, 2008), and if we explicitly
linearise functions, we obtain the extended Kalman smoother. This allows us to extend EP to all non-
linear Gaussian filters/smoothers, and generalise them to a setting where posterior state distributions can
be iteratively refined to yield better Gaussian approximations.
2Published in Transactions on Machine Learning Research (06/2022)
Contribution1
1. We prove that any Gaussian filter for non-linear dynamical systems is equivalent to a single iteration of
approximate EP. This equivalence will allow us to implement (approximate) EP using Kalman-filter-style
updates and without explicitly computing gradients of the log-partition function. Additionally, we can
improve non-linear Gaussian smoothers by iteratively refining the marginal posterior distributions using
approximate EP.
2. Because of approximate EP’s equivalence with Gaussian smoothing, we can further improve estimation
of the marginal posteriors by pre-existing techniques in the EP literature: (1) Damping, which reduces
oscillatory behaviour; (2) Power EP, which allows us to interpolate between EP (mode averaging) and
variational Bayes (mode seeking) for iterative smoothing in non-linear state-space models.
We use a classic non-linear system benchmark, the uniform nonlinear growth model (UNGM) (Doucet et al.,
2000) with a fixed seed as a running example to illustrate properties of the iterative smoothing scheme. The
article is organised as follows. In Section 2, we establish the notation and review classic Kalman filtering
and smoothing, which we then apply to the UNGM benchmark. In Section 3, we introduce EP as a way for
iteratively computing posterior distributions on latent states. Furthermore, we prove that the first iteration
of derivative-based (approximate) EP is equivalent to smoothing with non-linear Kalman filters, which does
not require any derivatives. We demonstrate that EP further improves the standard smoothing results of
the UNGM example. Section 4.2 then addresses potential limit-cycle behaviours of EP by using damped
updates (Heskes & Zoeter, 2003), and then further improves the results by using α-divergence EP (power
EP) (Minka, 2004). In Section 5, we analyse the efficacy of our method and its sensitivity with respect to
α, the damping parameter, and the linearisation technique.
2 Gaussian Filtering and Smoothing
Consider the state-space models of the form
xt=f(xt−1) +wt, (1)
yt=h(xt) +vt, (2)
wherext∈RDis an unobserved/latent state and yt∈REis a measurement at time step t= 1,...,T.
Moreover,fandhare the (non-linear) transition and measurement functions, respectively, and the noise
processeswtandvtare i.i.d. zero-mean Gaussian with diagonal covariances QandR, respectively. The
initial state distribution is given by p(x0) =N(x0|µ0,Σ0,). The purpose of this section is to provide
background details on Gaussian filtering and smoothing algorithms on the state-space model (1)– (2).
2.1 Optimal Filtering and Smoothing
Bayesian filtering corresponds to finding a posterior distribution p(xt|y1:t)on the unobserved latent state
xt, given observations y1:t:= (y1,...,yt)up until the most recent time step t. It proceeds by sequentially
computing a time update and a measurement update (Anderson & Moore, 2005), as we explain below.
Given a filtering distribution p(xt−1|y1:t−1), thetime update
p(xt|y1:t−1) =/integraldisplay
p(xt|xt−1)p(xt−1|y1:t−1) dxt−1 (3)
computes a predictive distribution of the state xtgiven observations up to time step t−1. Here,
p(xt|xt−1) =N(xt|f(xt−1),Q)is the transition probability, which follows from the dynamical system
(1). The measurement update then incorporates the observation ytat timetby computing
p(xt|y1:t) =p(yt|xt)p(xt|y1:t−1)/integraltext
p(yt|xt)p(xt|y1:t−1)dxt∝p(yt|xt)p(xt|y1:t−1), (4)
1Code available at https://github.com/sanket-kamthe/EPyStateEstimator
3Published in Transactions on Machine Learning Research (06/2022)
which yields the filtering distribution. Here, p(yt|xt) =N(yt|h(xt),R)is the observation likelihood, which
follows from (2).
On the other hand, in Bayesian smoothing, the posterior distribution p(xt|y1:T)of the latent state xtgiven
all observations in the time series is computed. Here, we consider the Rauch–Tung–Striebel (RTS) smoother,
which computes this posterior iteratively by applying the smoothing update
p(xt|y1:T) =/integraldisplay
p(xt|xt+1,y1:T)p(xt+1|y1:T)dxt+1=/integraldisplay
p(xt|xt+1,y1:t)p(xt+1|y1:T)dxt+1,(5)
where we used the Markov property p(xt|xt+1,y1:t) =p(xt|xt+1,y1:T).
Equations (3)–(5) are generally intractable for non-linear systems. However, if we focus on Gaussian approx-
imations to the filtering and smoothing distributions, we can derive equations for the time update, measure-
ment update and the smoothing update, provided that we can approximate the densities p(xt−1,xt|y1:t−1),
p(xt,yt|y1:t−1)andp(xt,xt+1|y1:t)respectively by joint Gaussian distributions (Deisenroth, 2010; Särkkä
et al., 2015).
To see this, let us take for example an approximation of p(xt,yt|y1:t−1)as a joint Gaussian
p(xt,yt|y1:t−1) =N/parenleftigg/parenleftbiggxt
yt/parenrightbigg/vextendsingle/vextendsingle/vextendsingle/vextendsingle/parenleftigg
µx
t|t−1
µy
t|t−1/parenrightigg
,/parenleftigg
Σx
t|t−1Σxy
t|t−1
Σyx
t|t−1Σy
t|t−1/parenrightigg/parenrightigg
. (6)
The subscripts t|t−1indicate that the statistics of random variables (e.g., the mean) at time step tare
conditioned on information/observations up to time step t−1and the superscripts indicate whether the
quantity is observed in latent or observed space (for example Σxy
t|1:t−1:= cov[xt,yt|y1,...,yt−1]).
By exploiting the joint Gaussianity in (6), the measurement update equation can be computed by Gaussian
conditioning, leading us to the approximate filter distribution p(xt|y1:t)≈N(xt|µx
t|t,Σx
t|t), where
µx
t|t=µx
t|t−1+Kt(yt−µy
t|t−1), (7)
Σx
t|t=Σx
t|t−1−KtΣyx
t|t−1. (8)
Here, the matrix Kt:=Σxy
t|t−1(Σy
t|t−1)−1corresponds to the Kalman gain in linear systems. Now, to arrive
at the Gaussian approximation (6), we do moment matching, which requires one to compute the means and
covariances of the true distribution p(xt,yt|y1:t−1). This has the following exact expressions
µx
t|t−1=/integraldisplay
f(xt−1)p(xt−1|y1:t−1)dxt−1, (9)
Σx
t|t−1=/integraldisplay
f(xt−1)(f(xt−1))⊤p(xt−1|y1:t−1)dxt−1−µx
t|t−1(µx
t|t−1)⊤+Q, (10)
µy
t|t−1=/integraldisplay
h(xt)p(xt|y1:t−1) dxt, (11)
Σy
t|t−1=/integraldisplay
h(xt)(h(xt))⊤p(xt|y1:t−1) dxt−µy
t|t−1(µy
t|t−1)⊤+R, (12)
Σxy
t|t−1=/integraldisplay
xt(h(xt))⊤p(xt|y1:t−1) dxt−µx
t|t−1(µy
t|t−1)⊤. (13)
Generally, these cannot be computed in closed form when fandhare non-linear. Hence, we resort to
methods that approximate these integrals, such as linearising the non-linear terms or applying the unscented
transform (Deisenroth & Ohlsson, 2011; Särkkä, 2013).
Similar update equations can be obtained for the RTS smoother by approximating the joint distribution
p(xt,xt+1|y1:t)by a joint Gaussian (Deisenroth et al., 2012), which leads to closed-form equations for the
mean and covariance of the smoothing distribution, given by
µx
t|T=µx
t|t+Lt(µx
t+1|T−µx
t+1|t), (14)
Σx
t|T=Σx
t+1|t+1+Lt/parenleftig
Σx
t+1|T−Σx
t+1|t/parenrightig
L⊤
t, (15)
4Published in Transactions on Machine Learning Research (06/2022)
respectively. Here, the matrix Lt=Σx
t,t+1|t(Σx
t+1|t)−1is called the smoothing gain , where Σx
t,t+1|tdenotes
the cross-covariance between xtandxt+1, which has the true expression
Σx
t,t+1|t=/integraldisplay
xt(f(xt))⊤p(xt|y1:t) dxt−µx
t|t(µx
t+1|t)⊤. (16)
Again, for a non-linear transition function f, the integral is intractable. Hence, we approximate it by means
of, for example, linearisation or the unscented transformation.
For the time update, if we similarly approximate the distribution p(xt−1,xt|y1:t−1)by a joint Gaussian, we
can obtain an approximation to the predictive distribution (3) by a simple Gaussian marginalisation.
2.2 Implicit Linearisation in Non-linear Gaussian Filters and Smoothers
Applying moment matching to approximate the true distributions p(xt−1,xt|y1:t−1),p(xt,yt|y1:t−1),
p(xt,xt+1|y1:t)as joint Gaussians in Section 2.1 implicitly linearises the respective transition and mea-
surement functions, as two random variables are jointly Gaussian if and only if they are related by an affine
transformation up to zero-mean Gaussian noise. This is stated more precisely in the following Lemma.
Lemma 1 (Implicit linearisation) .A random variable (x,y)is jointly Gaussian if and only if there exist
matricesM∈RE×D,P∈RE×Eand a vector v∈REsuch thaty=Mx +v+ε, whereε∼N(0,P).
Proof.If(x,y)is jointly Gaussian, we can write
/parenleftbiggx
y/parenrightbigg
∼N/parenleftbigg/parenleftbiggµx
µy/parenrightbigg
,/parenleftbiggΣxΣxy
ΣyxΣy/parenrightbigg/parenrightbigg
, (17)
where Σyx= (Σxy)⊤. On the other hand, if y=Mx +v+εwithε∼N (0,P)were to hold, then for
x∼N(µx,Σx), we have
/parenleftbiggx
y/parenrightbigg
∼N/parenleftbigg/parenleftbiggµx
Mµx+v/parenrightbigg
,/parenleftbiggΣxΣxM⊤
MΣxMΣxM⊤+P/parenrightbigg/parenrightbigg
. (18)
We see that the RHS of expressions (17) and (18) agree if and only if
M=Σyx(Σx)−1, (19)
P=Σy−MΣxM⊤, (20)
v=µy−Mµx. (21)
It is therefore always possible to write y=Mx +v+εfor random variables xandythat are jointly
Gaussian and vice versa. Note that the matrix Pin (20) is guaranteed to be positive semidefinite as it is
exactly the expression for the covariance of the conditional distribution p(y|x).
We illustrate this idea of linearisation that arises as a result of forming joint Gaussians (and vice versa) in the
following two examples. In the first, we look at the case when we use the Taylor approximation to explicitly
linearise the nonlinear transition function and how that results in a joint Gaussian approximation between
two random variables. In the second example, we look at using particle-based methods to approximate a
general joint distribution p(x,y)as joint Gaussians and how that implicitly leads to a linear relationship
betweenxandy.
Example 1 (Taylor approximation) .Letx∼N (µx,Σx)andy|x∼N (g(x),P), wheregis a non-linear
differentiable function. Since the joint distribution p(x,y) =N(x|µx,Σx)N(y|g(x),P)is non-Gaussian,
we approximate it by a Gaussian by means of explicitly linearising garoundµx.
g(x)≈g(µx) +M(x−µx), (22)
whereM:=∇g(µx). Thisgivesusthelinearrelation y=Mx+v+ε,ε∼N(0,P),wherev=g(µx)−Mµx
and the following Gaussian approximation to p(x,y)holds:
/parenleftbiggx
y/parenrightbigg
approx∼ N/parenleftbigg/parenleftbiggµx
g(µx)/parenrightbigg
,/parenleftbiggΣxΣxMT
MΣxMΣxM⊤+P/parenrightbigg/parenrightbigg
. (23)
5Published in Transactions on Machine Learning Research (06/2022)
10 20 30 40 50
EP Iterations45678RMSEEP
UKF
UKS
10 20 30 40 50
EP Iterations2468NLLEP
UKF
UKS
Figure 1: Root mean square error (RMSE) and negative log-likelihood (NLL) performance of estimation
algorithms applied to the UNGM example (single seed). The unscented Kalman filter and the unscented
RTS smoother form the baselines (dashed lines). EP starts from the RTS smoothing baseline, as its first
iteration is identical to the RTS smoother. We can see that the EP estimate improves on the smoothing
baselines with an increasing number of EP iterations. The oscillatory behaviour of EP can be addressed by
damping, which we discuss in Section 4.1.
Example 2 (Monte Carlo and unscented transformation) .Alternatively, we can approximate the joint dis-
tributionp(x,y)in the previous example via a particle-based representation, that is, represent p(x)using
a collection of particles (which can be determined deterministically as in the unscented transformation or
stochastically as in the particle filter) and propagate them forward by gto compute the moments µy,Σy,Σxy
empirically. Wecanthenusethecomputedmomentstodeducetheimplicitlinearisation y=Mx+v+εwith
ε∼N(0,P), whereM,P,vare computed as in (19)–(21). The Monte Carlo and unscented transformation
considered in our experiments in Section 5 follow this framework.
Commonly used Bayesian filters and smoothers for non-linear systems are the extended Kalman filter (EKF),
the unscented Kalman filter (UKF) (Julier et al., 2000), and the cubature Kalman filter (CKF) (Arasaratnam
& Haykin, 2009), all of which compute means and covariances of the unobserved state xt. Since all update
equations of these non-linear filters and smoothers can be expressed as (7), (8), and (14), (15) respectively,
these methods either explicitly (e.g., EKF) or implicitly (e.g., UKF, CKF) linearise the transition and
measurement operators in (1)–(2), which incurs approximation errors.
To account for the approximation errors, we may improve the filtering/smoothing results by iteratively
refining the state estimate. For example, in the iterative extended Kalman filter (IEKF) (Senne, 1972), an
iterative measurement update is used to improve the standard EKF solution. On the other hand, similar
results for smoothing are not well explored. However, we would expect to see similar improvements as
obtained in filtering by iteratively linearising the transition function as well. This is challenging, as, unlike
the measurement function that only depends on the measurement at time step t, the smoothing result
depends on all observations from time steps 1toT.
The approach that we propose here is to apply Expectation Propagation (EP), a general approximate
inference scheme that iteratively refine approximations of the target distribution (Minka, 2001a). Standard
EP is only applicable for linear functions, but it exactly recovers the Kalman and RTS smoother for linear
systems (Minka, 2001a). Similar to Kalman-based iterative filters, we expect the EP updates to iteratively
improve smoothing results in the non-linear case.
2.3 RTS Smoothing Applied to a Non-linear Benchmark
Before describing EP in detail (see Section 3), we motivate the usefulness of its iterative refinement of the
posterior state distribution on an instance of the well-known non-linear benchmark:
6Published in Transactions on Machine Learning Research (06/2022)
xt xt+1p(xt+1|xt) f▷(xt)
f△(xt)f◁(xt+1)
f△(xt+1)
(a) Factor graphxt xt+1f▷(xt)f◁(xt)
f△(xt)f▷(xt+1)f◁(xt+1)
f△(xt+1)
(b) Fully-factored factor graph. Factors between nodes are split.
Figure 2: Factor-graph representations of a dynamical system. (a) Exact factor graph of a dynamical
system. Factors (black squares) correspond to conditional probability distributions, e.g., p(xt+1|xt)for the
factor between xtandxt+1. Circles are random variables. Observations ytare not displayed as they are
deterministic. (b) The fully-factored factor graph illustrates how local messages are being sent to update the
marginal posterior at each time step. The splitted factors are obtained by applying belief propagation on
(a), that is f◁(xt) =/integraltext
p(xt+1|xt)f△(xt+1)f◁(xt+1)dxt+1andf▷(xt+1) =/integraltext
p(xt+1|xt)f▷(xt)f△(xt)dxt.
xt=xt−1
2+25xt−1
1+x2
t−1+ 8 cos(1.2(t−1)) +wt, (24)
yt=x2
t
20+vt, (25)
where we use the same set-up as in (Doucet et al., 2000): wt∼ N (0,1),vt∼ N (0,10)andp(x0) =
N(x0|0,5). We consider trajectories of 100 time steps. This benchmark is challenging for state estimation as
the transition density around x≈0is bimodal and symmetric. The scaled quadratic measurement function
makes these modes indistinguishable.
We compare the results of EP with the unscented Kalman filter and smoother (van der Merwe & Wan
(2004)).2Results are shown in Figure 1, where we plotted the root mean square error (RMSE) and the
negative log-likelihood (NLL) of its predictions, all measured in latent space x(see Appendix A.3 for the
precise expressions of these metrics). While the RMSE only measures the quality of the posterior mean, the
NLL is a measure that allows us to assess the quality of the approximate posterior mean and covariance.
Observe that the results from RTS smoothing and the first iteration of EP are identical, a result we prove
in Section 3.4. We see that EP iterative smoothing generally improves the results obtained by a single pass.
In the next section, we develop the expectation propagation algorithm used to generate the solid red curve
in Figure 1.
3 Expectation Propagation
After this brief motivation, we are now ready to describe expectation propagation (EP) in more detail.
In the context of dynamical systems, EP is typically derived using a factor-graph formulation (Qi, 2005;
Deisenroth & Mohamed, 2012), where the (marginal) distribution over the latent state p(xt|y1:T), i.e., the
smoothing distribution, is represented as a product of factors/messages fi, so thatp(xt|y1:T) =/producttext
ifi(xt);
see Figure 2 for an illustration. There are three types of factors fiin this context: forward, backward, and
measurement messages, which we will denote by the symbols ▷,◁,△, respectively. The forward factor f▷is
a message/information that is carried from all the latent states and observations prior to the current latent
statext. The backwards factor f◁sends information from future states to xt, and the measurement factor
f△incorporates information from the current observation. Thus, each (marginal) state posterior smoothing
distribution can be written as a product of factors/messages
p(xt|y1:T) =f▷(xt)f△(xt)f◁(xt) (26)
= (forward ) (measurement ) (backward ).
2A more thorough comparison across different filters and seeds is discussed in Section 5.
7Published in Transactions on Machine Learning Research (06/2022)
For the non-linear systems we consider here, the exact factors fi(xt)above and therefore the posterior
distributions p(xt|y1:T)are intractable.
EP (Minka, 2001b;a) is a deterministic Bayesian inference algorithm that can be used to approximate the
complex and an often intractable smoothing distribution p(xt|y1:T) =/producttext
ifi(xt)by a distribution of the
formq(xt) =/producttext
iqi(xt), which is a product of simpler and tractable factors qi. The underlying assumption
is that if we can find good approximating factors qi, we may get better estimates of the intractable posterior
distribution p(xt|y1:T). In practice, we restrict the factors qito families of certain distributions, such that
they are closed under multiplication and division (Seeger, 2005), e.g., Gaussians. We get approximatations
in this family by a procedure known as projection .
Definition 1. LetFbe a family of probability distributions. The KLprojection of pontoFis a distribution
inFthat minimises KL (p||q)over all distributions q∈F. We use the shorthand notation projF[·]to define
the operator that projects arbitrary distributions onto the family F:
projF[p] := argmin
q∈FKL (p||q). (27)
In EP, we assume that the approximations q(xt)and the factors qi(xt)come from the exponential family.
This has the useful property that the operation projF[p]simply amounts to finding q∈Fwhose expected
sufficient statistics correspond to those of p(Seeger, 2005). For example, if Fis the family of normal
distributions, then projF[p] =N(µ,Σ)whereµandΣare the mean and covariance of p.
3.1 EP Algorithm
The iterative refinement of each factor qiis carried out as follows in EP (Minka, 2001a). First, we compute
thecavity distribution
q\i(xt)∝q(xt)/qi(xt), (28)
which contains all the information about the distribution of xtexcept for the ithfactor, i.e. the “rest of the
distribution” (Minka, 2004).
Second, we form the (unnormalised) tilted distribution fi(xt)q\i(xt)by combining the “true” factor fi(xt)
with the cavity distribution q\i(xt)and determine an updated factor qi(xt), so thatqi(xt)q\i(xt)approxi-
matesfi(xt)q\i(xt)as close as possible in the KLsense. We achieve this via projection (Definition 1). This
gives us the updated posterior q(xt)newand approximate factor qi(xt)new, which reads
q(xt)new= projF/bracketleftbig
fi(xt)q\i(xt)/bracketrightbig
(29)
qi(xt)new∝q(xt)new
q\i(xt), (30)
respectively. Note that the cavity distribution q\iprovides the “context” within which to find the updated
approximate factor qi; the Gaussian approximation qi≈fineed only hold locally, where the posterior defined
by the remaining factors q\ihas the most concentration of mass.
For linear systems with Gaussian noise, the true factors fi(xt)are also Gaussian, hence the projection step
and the implied Gaussian approximation are exact. This means that in this case, the factors q▷,q◁,q△
are unique and optimal, i.e., qi=fi(Minka, 2001a). The Kalman smoother obtains these results in a
single forward-backward sweep through the factor graph. For non-linear systems, however, computing the
exact factors fiare intractable. Hence, we use approximations to compute these factors (Qi & Minka, 2003),
which requires more than a single iteration of EP to converge. If we iterate multiple times, all factors contain
information from observations at all times. When correctly set up, we can at each iteration improve the
quality of the factors and obtain a closer approximation to the true smoothing distribution p(xt|y1:T).
3.2 EP Updates for Generalised Gaussian Filtering/Smoothing
In the following, we provide explicit computational detail of the EP algorithm when the approximating
familyFis the family of Gaussians. For simplicity, we drop the subscript Ffrom the notation projF[·]
8Published in Transactions on Machine Learning Research (06/2022)
Algorithm 1 Gaussian EP for Dynamical Systems
1:Init:Set all factors qitoN(0,∞I); Setq(x1) =p(x1)and marginals q(xt>1) =N(0,1010I)
2:repeat
3:fort= 1toTdo
4:forall factorsqi(xt), wherei=▷,△,◁do
5: Compute cavity distribution:
q\i(xt)∝q(xt)/qi(xt), (31)
6: Update posterior by projection:
qnew(xt) = proj/bracketleftbig
fi(xt)q\i(xt)/bracketrightbig
(32)
7: Update factor:
qnew
i(xt)∝qnew(xt)/q\i(xt) (33)
8:end for
9:end for
10:untilConvergence or maximum number of iterations exceeded
for the projection in this case. The pseudo-code in Alg. 1 describes the main steps of Gaussian EP. This
iteratively updates the marginal q(xt)and the messages qi(xt),i∈{▷,△,◁}that form this marginal.
•Compute cavity distribution: First, the cavity distribution (28)q\i(xt)is computed (step 5 in Alg. 1)
by removing factor qi(xt)from the marginal q(xt). Sinceq(xt)andqi(xt)are Gaussian, the cavity
distribution is also a (scaled) Gaussian,
q\i(xt)∝q(xt)/qi(xt)∝N(xt|µ\i
t,Σ\i
t). (34)
The termsµ\i
t,Σ\i
tcan be computed via the Gaussian division rule (132)–(134) (Appendix A.2),
Σ\i
t= (Σ−1
t−(Σi
t)−1)−1, (35)
µ\i
t=Σ\i
t(Σ−1
tµt−(Σi
t)−1µi
t). (36)
•Update posterior by projection: Next, the Gaussian projection of the tilted distribution fi(xt)q\i(xt)
is computed (see Def. 1). This requires one to compute the moments of fi(xt)q\i(xt), which can be
deduced from the derivatives of the log-partition function (Minka, 2001a;b; 2008)
logZi(µ\i
t,Σ\i
t) = log/integraldisplay
fi(xt)q\i(xt)dxt. (37)
The moments of the updated (marginal) posterior qnew(xt)can then be computed as
µnew
t=µ\i
t+Σ\i
t∇⊤
µ\i, (38)
Σnew
t=Σ\i
t−Σ\i
t(∇⊤
µ\i∇µ\i−2∇Σ\i)Σ\i
t, (39)
where∇µ\i:= d logZi/dµ\i
t, (40)
and∇Σ\i:= d logZi/dΣ\i
t. (41)
•Update factor: Finally, we obtain the updated factor qnew
i(see (30)) again via the Gaussian division
rule, since both the updated marginal and the cavity distribution are (unnormalised) Gaussians.
9Published in Transactions on Machine Learning Research (06/2022)
Remark1.In some cases, it is easier to compute the updated factor qnew
ifirst; the updated posterior is then
obtained by multiplying the updated factor with the cavity distribution: qnew∝qnew
iq\i.
Remark 2.While the focus of the paper is on smoothing, i.e., the offline inference setting, message passing
in the online setting via a moving window (fixed-lag smoothing) could also be implemented. Here, we would
use the messages of the last ktime steps to find an approximate filtering distribution p(xt|yt−k:t). Iterations
within the considered window would still give improved filtering distributions.
3.3 Implicit Linearisation Requires Explicit Consideration
We now highlight an important detail in the computation of the derivatives ∇µ\i,∇Σ\i, which are required
in the EP update formulas (38)–(39). For nonlinear systems, these cannot be computed in closed-form, hence
we use approximate derivatives in practice, which is obtained by replacing the partition function Ziby its
approximation, denoted ˜Zi, in the computation of (40)–(41). As we shall see more concretely in the next
section, this approximation in general takes a Gaussian form, making it possible to compute derivatives.
As an illustrative example, consider the partition function Z△=/integraltext
f△(xt)q\△(xt)dxtcorresponding to the
measurement message, where f△(xt) =p(yt|xt) =N(yt|h(xt),R). Approximating the tilted distribution
p(yt|xt)q\△(xt)by a joint Gaussian in xtandyt, we get the approximation
˜Z△=/integraldisplay
N/parenleftigg/parenleftbiggxt
yt/parenrightbigg/vextendsingle/vextendsingle/vextendsingle/vextendsingle/parenleftigg
µx\△
t
µy\△
t/parenrightigg
,/parenleftigg
Σx\△
t Σxy\△
t
Σyx\△
t Σy\△
t/parenrightigg/parenrightigg
dxt=N(yt|µy\△
t,Σy\△
t), (42)
which takes the form of a Gaussian. Here, µy\△
t,Σy\△
t,Σxy\△
tcorrespond to approximations of the integrals
Eq\△[h(xt)],covq\△[h(xt)]andcovq\△[xt,h(xt)]respectively, which can be obtained using the same tech-
niques as we saw in the examples in Section 2.2, by applying the unscented transform, linearisation etc. The
termsµx\△
tandΣx\△
tare equivalent to µ\△
tandΣ\△
t; the superscripts were simply added to distinguish
them from moments in the observed space.
Note that ˜Z△in (42) is a Gaussian in the observed space yt, while the derivatives (40)–(41) are taken with
respect to moments in the latent space xt. Using the chain rule, the derivatives thus read
∇µ\△:=d log ˜Zi
dµx\△
t=∂log˜Z△
∂µy\△
t∂µy\△
t
∂µx\△
t+∂log˜Z△
∂Σy\△
t∂Σy\△
t
∂µx\△
t, (43)
∇Σ\△:=d log ˜Z△
dΣx\△
t=∂log˜Z△
∂µy\△
t∂µy\△
t
∂Σx\△
t+∂log˜Z△
∂Σy\△
t∂Σy\△
t
∂Σx\△
t, (44)
which requires knowledge of the derivatives of moments in the observed space with respect to moments in
the latent space (terms highlighted in red). Crucially, these do not necessarily vanish when xtandythave
non-zero correlation—we expect (µy\△
t,Σy\△
t)to change with (µx\△
t,Σx\△
t)if they are correlated.
Computing the terms in red can be achieved if we have an explicit relation between the random variables xt
andyt. Sincextandytare jointly Gaussian in the approximation we made to our partition function (42),
then by Lemma 1, they are related by an affine transformation up to a zero-mean Gaussian noise, that is,
yt=Jtxt+ut+ηtfor some matrix Jt∈RE×D, vectorut∈RE, andηt∼N(0,R). Thus, we have
µy\△
t=Jtµx\△
t+ut, (45)
Σy\△
t=JtΣx\i
tJ⊤
t+R. (46)
We now make an important assumption that the matrix/vectors Jt,ut,Rdo not depend on the mo-
mentsµx\△
t,Σx\△
t, which is equivalent to saying that the approximate conditional distribution ˜p(yt|xt) =
N(yt|Jtxt+ut,R)is independent of the moments µx\△
t,Σx\△
t. This is a reasonable assumption since the
likelihoodp(yt|xt)of our original, unapproximated system is independent of the prior p(xt).
10Published in Transactions on Machine Learning Research (06/2022)
With this assumption, using (45)–(46), we get
∂µy\△
t
∂µx\△
t=Jt∈RE×D,∂µy\△
t
∂Σx\△
t=0∈RE×D×D,∂Σy\△
t
∂µx\△
t=0∈RE×E×D,∂[Σy\△
t]ij
∂[Σx\△
t]kl= [Jt]ik[Jt]jl.
(47)
Thus, from (43)–(44), we obtain the following closed-form formulas for the derivatives in question
∇µ\△= (yt−µy\△
t)⊤(Σy\△
t)−1Jt∈R1×D, (48)
∇Σ\△=1
2/parenleftig
∇⊤
µ\△∇µ\△−J⊤
t(Σy\△
t)−1Jt/parenrightig
∈RD×D, (49)
where we used the identities (126)–(127) in Appendix A.1 to compute the derivatives of a log-Gaussian.
3.4 Derivative-based EP Updates and Kalman Smoothers
Section 2.1 provides generic equations for Bayesian filtering (7)–(8) and RTS smoothing (14)–(15) in non-
linear systems with Gaussian state distributions; the only requirement is to be able to compute means and
covariances of two joint distributions to apply these update equations. In Section 3.2, based on derivatives of
the log-partition function, we derived generic update equations (38)–(39) for computing means and covari-
ances of posterior distributions of the latent states of a non-linear dynamical system, but now formulated
as a message-passing algorithm, which can potentially be iterated and may lead to more refined posterior
distributions than RTS smoothing.
In the following, we will show that these generic update equations are identical for a single iteration of
EP when updates are performed in the following specific order: As in Gaussian filtering, we start with the
time update or “forward factor” ( ▷) update, followed by a measurement update or “up factor” ( △) update
and repeat until we reach t=T. Then we move backwards until we reach t= 0by updating the “back
factor” ( ◁) similar to the backward pass of an RTS smoother. The implication of this statement is that
we can interpret the EP computations in the context of classical Gaussian filtering and RTS smoothing for
non-linear dynamical systems. These equivalences include all classical filters and RTS smoothers for linear
and non-linear systems, including the extended/unscented/cubature Kalman filters/smoothers.
Forward message To compute the mean and covariance for the forward message f▷(xt), we obtain it
directlyinsteadofusingthederivative-basedupdateformulas(38)–(39), asthisturnsouttobemuchsimpler.
Note that the approximate forward message has the expression
f▷(xt) =/integraldisplay
p(xt|xt−1)q\◁(xt−1)dxt−1=/integraldisplay
N(xt|f(xt−1),Q)q\◁(xt−1)dxt−1, (50)
which we can see from the factor graphs in Figure 2. Due to the non-linearity of f, the above integral is
intractable. Hence, we approximate the integrand by a joint Gaussian, denoted q(xt−1,xt), using techniques
such as linearisation and unscented transform (see examples in Section 2.2 for details). By Lemma 1, we
then obtain the Gaussian approximation
q▷(xt) =/integraldisplay
q(xt−1,xt)dxt−1=N(xt|Mt−1µ\◁
t−1+vt−1,Mt−1Σ\◁
t−1M⊤
t−1+Pt−1),(51)
to the true factor f▷(xt)for someMt−1,vt−1,Pt−1, where we used (18) and the Gaussian marginalisation
rule in the last equality. Now, since Pt−1is the covariance of the conditional distribution p(xt|xt−1)(see
proof of Lemma 1), we have Pt−1=Q. This results in the update formulas
µ▷
t=Mt−1µ\◁
t−1+vt−1, (52)
Σ▷
t=Mt−1Σ\◁
t−1M⊤
t−1+Q, (53)
for the forward message. In accordance with Remark 1, we can then also update the approximate marginal
posteriorq(xt)by a simple Gaussian multiplication, i.e., q(xt)∝q▷(xt)q\▷(xt).
11Published in Transactions on Machine Learning Research (06/2022)
Note that the approach that we use here to obtain the forward update formula (i.e., form a joint Gaussian
approximation to the integrand of (50) and marginalise) is identical to how we obtain a general time update
in standard Bayesian filtering (see Section 2.1). The only difference is that in Bayesian filtering, the term
corresponding to the cavity distribution q\◁(xt−1)in (50) is given by the filtering distribution p(xt−1|y1:t−1)
(see (3) in Section 2.1). However, if we refer to Table 1 for the correspondence between EP messages and
filtering distributions, we see that in the very first iteration of EP, the cavity distribution q\◁(xt−1)is exactly
equal top(xt−1|y1:t−1). Hence, we have the following result.
Theorem 1. In the very first iteration of EP, computing the approximate forward message q▷(xt)via the
moments of f▷(xt)in(50)corresponds to the time update in a classical Bayesian filtering algorithm, where
the moments are given by (9)–(10).
Measurement message For the measurement message, we employ the derivative-based update formulas
(38)–(39). We have already explained how to compute the (approximate) derivatives ∇µ\△and∇Σ\△for
this case in Section 3.3, where the resulting expressions are given by (48)–(49). Using this, we can then
obtain the updated posterior qvia (38)–(39) and an updated factor q△by Gaussian division; see (30).
Theorem 2. The moments
µt=µx\△
t+Σx\△
t∇⊤
µ\△, (54)
Σt=Σx\△
t−Σx\△
t/bracketleftig
∇⊤
µ\△∇µ\△−2∇Σ\△/bracketrightig
Σx\△
t (55)
of the update posterior q(xt), which are computed via the derivatives of log˜Z△, are identical to the mo-
ments(7)–(8)of the filtering distribution (measurement update)
µx
t|t=µx
t|t−1+Kt(yt−µy
t|t−1), (56)
Σx
t|t=Σx
t|t−1−KtΣyx
t|t−1(57)
obtained by any Gaussian filter, where
Kt:=Σxy
t/parenleftbig
Σy
t/parenrightbig−1(58)
is the “Kalman gain”.
Proof.Since we are applying the EP forward and measurement updates in sequence and recalling the fact
that we initialised the backward messages q◁(xt)with an uninformative prior, we see that
q\△(xt) =q▷(xt)q◁(xt) =N(xt|µx
t|t−1,Σx
t|t−1)N(xt|0,∞I) =N(xt|µx
t|t−1,Σx
t|t−1),(59)
where we used the relation in Table 1 to identify the forward message q▷(xt)with the predictive distribution
p(xt|y1:t−1)≈N (xt|µx
t|t−1,Σx
t|t−1). This gives us µx\△
t=µx
t|t−1andΣx\△
t=Σx
t|t−1, which allows us to
re-express the standard Kalman update (56)–(57) in terms of EP messages, as
µx
t|t=µx\△
t+Kt(yt−µy\△
t), (60)
Σx
t|t=Σx\△
t−KtΣyx\△
t, (61)
whereKt=Σxy\△
t/parenleftbig
Σy\△
t/parenrightbig−1. We start by showing that the expressions for the means in (54) and (60) are
identical, which is true if
Σx\△
t∇⊤
µ\△=Kt(yt−µy\△
t) (62)
holds. To see this, we use (19) and (48) to re-express the left-hand side of (62) as
Σx\△
t∇⊤
µ\△(48)=Σx\△
tJt⊤(Σy\△
t)−1(yt−µy\△
t)(19)=Σx\△
t(Σx\△
t)−1Σxy\△
t(Σy\△
t)−1(yt−µy\△
t)(63)
=Σx\△
t(Σx\△
t)−1
/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
=IΣxy\△
t(Σy\△
t)−1(yt−µy\△
t) =Σxy\△
t(Σy\△
t)−1
/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
=Kt(yt−µy\△
t), (64)
12Published in Transactions on Machine Learning Research (06/2022)
Filtering/smoothing distributions Corresponding EP messages
Predictive distribution (time update) p(xt|y1:t−1)q▷(xt)
Filtering distribution (measurement update) p(xt|y1:t)q▷(xt)q△(xt) =q\◁(xt)
Smoothing distribution p(xt|y1:T) q▷(xt)q△(xt)q◁(xt) =q(xt)
Table 1: Glossary of filtering/smoothing distributions and corresponding EP messages during the first itera-
tion of EP. These equivalences can be verified inductively by comparing how they are both computed. Note
that all posteriors are only approximate (Gaussian) in the non-linear case.
which verifies identity (62), thus concluding the proof for the mean.
To show the corresponding identity for the covariances in (55) and (61), we need to show that
Σx\△
t/bracketleftig
∇⊤
µ\△∇µ\△−2∇Σ\△/bracketrightig
Σx\△
t=KtΣyx\△
t (65)
holds. Using (19) and (49), the left-hand side of (65) becomes
Σx\△
t/bracketleftig
∇⊤
µ\△∇µ\△−2∇Σ\△/bracketrightig
Σx\△
t(49)=Σx\△
tJ⊤
t(Σy\△
t)−1JtΣx\△
t (66)
(19)=Σx\△
t(Σx\△
t)−1Σxy\△
t(Σy\△
t)−1Σyx\△
t(Σx\△
t)−1Σx\△
t(67)
=Σxy\△
t(Σy\△
t)−1
/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
=KtΣyx\△
t, (68)
concluding the proof of Theorem 2.
Theorems 1–2 state that computing the Gaussian approximate posterior state distributions with derivative-
based updates of the forward and measurement messages is equivalent to the time and measurement updates
in standard Gaussian filtering for non-linear systems.
Backward message For the backward message, we use the partition function
Z◁(µ\◁
t,Σ\◁
t) =/integraldisplay
f◁(xt)q\◁(xt)dxt∝/integraldisplay
f◁(xt)N(xt|µ\◁
t,Σ\◁
t)dxt, (69)
where
f◁(xt)=/integraldisplay
p(xt+1|xt)q\▷(xt+1)dxt+1, (70)
to update the backward message q◁(xt)and the posterior distribution p(xt|y1:T)using the derivative-based
update formulas (38)–(39). The true factor f◁(xt)in (70) accounts for the coupling between xtandxt+1.
Substituting the expression for f◁(xt)in (70) into (69) and reordering the integration yields
Z◁∝/integraldisplay
q\▷(xt+1)/integraldisplay
p(xt+1|xt)q\◁(xt)dxt
/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
=f▷(xt+1)dxt+1. (71)
The inner integral in (71) corresponds to the forward message (50) at time step t+ 1, which can be approxi-
mated byq▷(xt+1)∝N(xt+1|µ▷
t+1,Σ▷
t+1), as discussed earlier. Then, using the identity (131) in Appendix
A.2, the integral in (71) can be computed analytically, giving us the following Gaussian approximation
˜Z◁=N(µ\▷
t+1|µ▷
t+1,Σ▷
t+1+Σ\▷
t+1). (72)
13Published in Transactions on Machine Learning Research (06/2022)
We can now use a similar trick as before to compute the derivatives ∇µ\◁,∇Σ\◁in the backward message
updates. Recall that when obtaining the approximate forward message q▷(xt+1)≈f▷(xt+1), we have
approximated the distribution p(xt+1|xt)q\◁(xt)by a joint Gaussian q(xt,xt+1), giving us the relation
xt+1=Mtxt+vt+εtfor some matrix Mt, vectorvt, andεt∼N(0,Q)by Lemma 1. Then, assuming as
before thatMt,vt,Qare independent of (µ\◁
t,Σ\◁
t)3, we deduce from (52)–(53) that
∂µ▷
t+1
∂µ\◁
t=Mt,∂µ▷
t+1
∂Σ\◁
t=0,∂Σ▷
t+1
∂µ\◁
t=0,∂[Σ▷
t+1]ij
∂[Σ\◁
t]kl= [Mt]ik[Mt]jl, (73)
giving us
∇µ\◁:=d log ˜Z◁
dµ\◁
t=∂log˜Z◁
∂µ▷
t+1∂µ▷
t+1
∂µ\◁
t+∂log˜Z◁
∂Σ▷
t+1∂Σ▷
t+1
∂µ\◁
t= (µ\▷
t+1−µ▷
t+1)⊤(Σ▷
t+1+Σ\▷
t+1)−1Mt,(74)
∇Σ\◁:=d log ˜Z◁
dΣ\◁
t=∂log˜Z◁
∂µ▷
t+1∂µ▷
t+1
∂Σ\◁
t+∂log˜Z◁
∂Σ▷
t+1∂Σ▷
t+1
∂Σ\◁
t=∇⊤
µ\◁∇µ\◁−M⊤
t(Σ▷
t+1+Σ\▷
t+1)−1Mt
2,(75)
where again, we used the identities (126)–(127) in Appendix A.1 to compute the derivatives of log˜Z◁.
Theorem 3. The backward message updates via the derivatives of log˜Z◁
µt=µ\◁
t+Σ\◁
t∇⊤
µ\◁, (76)
Σt=Σ\◁
t−Σ\◁
t/bracketleftig
∇⊤
µ\◁∇µ\◁−2∇Σ\◁/bracketrightig
Σ\◁
t, (77)
are identical to those obtained by the RTS smoothing update
µx
t|T=µx
t|t+Lt(µx
t+1|T−µx
t+1|t), (78)
Σx
t|T=Σx
t|t+Lt/parenleftig
Σx
t+1|T−Σx
t+1|t/parenrightig
L⊤
t, (79)
where
Lt:=Σx
t,t+1|t/parenleftig
Σx
t+1|t/parenrightig−1
. (80)
To prove this, we use the following auxiliary result.
Lemma 2. For anyt, the following identity holds
(Σ\▷
t)−1(µ\▷
t−µ▷
t) =Σ−1
t(µt−µ▷
t), (81)
whereµt,Σtare the moments of the full approximate posterior q(xt) =N(xt|µ▷
t,Σ▷
t)N(xt|µ\▷
t,Σ\▷
t).
Proof.Using identities (129)–(130) in Appendix A.2, we can expand the terms on the right-hand side of (81)
as
Σ−1
tµt= (Σ\▷
t)−1µ\▷
t+ (Σ▷
t)−1µ▷
t (82)
Σ−1
tµ▷
t= ((Σ\▷
t)−1+ (Σ▷
t)−1)µ▷
t. (83)
Subtracting (83) from (82) then gives us
Σ−1
t(µt−µ▷
t) = (Σ\▷
t)−1(µ\▷
t−µ▷
t) (84)
as required.
3Thisisequivalenttosayingthattheapproximatetransitionprobability ˜p(xt+1|xt) =N(xt+1|Mtxt+vt,Q)isindependent
ofµ\◁
t,Σ\◁
t, which again is a reasonable assumption.
14Published in Transactions on Machine Learning Research (06/2022)
Proof of Theorem 3. UsingtherelationsinTable1, wecanre-expresstheright-handsideoftheRTSsmooth-
ing equations (78)–(79) in terms of EP messages as
µt|T=µ\◁
t+Lt(µt+1−µ▷
t+1), (85)
Σt|T=Σ\◁
t+Lt/parenleftbig
Σt+1−Σ▷
t+1/parenrightbig
L⊤
t. (86)
Furthermore, noting the implicit linearisation xt+1=Mtxt+vt+εtand using (52), we have
Σx
t,t+1|t:=/integraldisplay/integraldisplay
(xt−µt|t)(xt+1−µt+1|t)⊤p(xt|y1:t)p(xt+1|y1:t) dxtdxt+1 (87)
Tab.1=/integraldisplay/integraldisplay
(xt−µ\◁
t)(xt+1−µ▷
t+1)⊤q\◁(xt)q▷(xt+1) dxtdxt+1 (88)
(52)=/integraldisplay
(xt−µ\◁
t)(Mtxt−Mtµ\◁
t)⊤q\◁(xt)dxt+Eq\◁[(xt−µ\◁
t)ε⊤
t]/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
=0(89)
=Σ\◁
tM⊤
t, (90)
which gives us
Lt:=Σx
t,t+1|t/parenleftig
Σx
t+1|t/parenrightig−1
=Σ\◁
tM⊤
t(Σ▷
t+1)−1. (91)
We now show the equivalence in the expressions for the means (76) and (85). To prove this, it suffices to
show that
Σx\◁
t∇⊤
µ\◁=Lt(µt+1−µ▷
t+1). (92)
By identity (136) in Appendix A.2, we have that
(Σ▷
t+1+Σ\▷
t+1)−1= (Σ▷
t+1)−1/parenleftbig
(Σ▷
t+1)−1+ (Σ\▷
t+1)−1/parenrightbig−1
/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
=Σt+1(Σ\▷
t+1)−1= (Σ▷
t+1)−1Σt+1(Σ\▷
t+1)−1.(93)
Inserting the expression (74) for ∇µ\◁and invoking Lemma 2, the left-hand side of (92) becomes
Σx\◁
t∇⊤
µ\◁(74)=Σ\◁
tM⊤
t(Σ▷
t+1+Σ\▷
t+1)−1(µ\▷
t+1−µ▷
t+1) (94)
(93)=Σ\◁
tM⊤
t(Σ▷
t+1)−1Σt+1(Σ\▷
t+1)−1(µ\▷
t+1−µ▷
t+1) (95)
Lem. 2=Σ\◁
tM⊤
t(Σ▷
t+1)−1Σt+1Σ−1
t+1/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
=I(µt+1−µ▷
t+1) (96)
=Σ\◁
tM⊤
t(Σ▷
t+1)−1(µt+1−µ▷
t+1)(91)=Lt(µt+1−µ▷
t+1). (97)
This proves the equivalence in the expressions for the mean.
Next, we show the equivalence in the expressions for the covariances (77) and (86). To do this, it suffices to
show that
−Σ\◁
t/bracketleftig
∇⊤
µ\◁∇µ\◁−2∇Σ\◁/bracketrightig
Σ\◁
t=Lt/parenleftbig
Σt+1−Σ▷
t+1/parenrightbig
L⊤
t. (98)
First, we use the matrix identity (137) in Appendix A.2, to get
/parenleftbig
Σ▷
t+1+Σ\▷
t+1/parenrightbig−1= (Σ▷
t+1)−1−(Σ▷
t+1)−1((Σ▷
t+1)−1+ (Σ\▷
t+1)−1)−1
/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
=Σt+1(Σ▷
t+1)−1(99)
= (Σ▷
t+1)−1/parenleftbig
Σ▷
t+1−Σt+1/parenrightbig
(Σ▷
t+1)−1. (100)
15Published in Transactions on Machine Learning Research (06/2022)
In (99), we used the fact that the sum of the precision matrices of all messages gives the precision matrix of
the marginal. Note that the precision of the cavity distribution is the sum of the precisions of all messages
except the forward message. Combining (100) with (75), the left-hand side of (98) yields
−Σ\◁
tM⊤
t/parenleftbig
Σ▷
t+1+Σ\▷
t+1/parenrightbig−1MtΣ\◁
t(100)=Σ\◁
tM⊤
t(Σ▷
t+1)−1
/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
=Lt/parenleftbig
Σt+1−Σ▷
t+1/parenrightbig
(Σ▷
t+1)−1MtΣ\◁
t/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
=L⊤
t,(101)
which concludes the proof.
Theorems 1–3 state that for a single iteration of EP, the Gaussian filtering and smoothing updates and the
derivative-based EP updates with implicit linearisation are identical. This means that the first iteration of
EP can be implemented using derivative-free updates, i.e., the classical update equations for Gaussian filters
and smoothers. For subsequent EP iterations, we can incorporate updated messages by using the following
equations, which very much resemble the general Gaussian filtering/smoothing equations:
•Measurement message
µt=µ\△
t+Kt(yt−µy\△
t), (102)
Σt=Σ\△
t−KtΣyx\△
t, (103)
where forxt∼q\△(xt), we define4
µy\△
t=Eq\△[h(xt)],Σy\△
t= covq\△[h(xt)] +R, (104)
Σxy\△
t = covq\△[xt,h(yt)],Kt=Σxy\△
t(Σy\△
t)−1. (105)
•Backward message
µt=µ\◁
t+Lt(µt+1−µ\◁
t+1) (106)
Σt=Σ\◁
t+Lt(Σt+1−Σ\◁
t+1)L⊤
t (107)
Lt= covq\◁[xt,f(xt)](Σ\◁
t+1)−1. (108)
Here, we identify µ\◁
t=Eq\◁[f(xt)] =µ▷
t(xt+1)andΣ\◁
t= covq\◁[f(xt)] +Q=Σ▷
xt+1.
Remark3.As shown in Algorithm 1, we initialise all approximate factors qi(xt) =N(0,∞I), i∈{▷,△,◁}
with zero mean and infinite variance (zero precision). This implies that the division and multiplication by
these densities corresponds to subtracting/adding zeros to precision matrices, respectively. Therefore, before
updatingqifor the very first time, it holds that q\i(xt) =q(xt), i.e., the cavity computation step leaves the
posterior unchanged as division by a zero-precision Gaussian (subtracting zero) has no effect. Therefore,
in the first EP iteration, the generic derivative-free update equations in (102)–(103) and (106)–(107) are
identical to generic Gaussian filter/smoother updates in (56)–(57) and (78)–(79), respectively.
To summarize, we showed that a single iteration of EP recovers classical Gaussian filters/RTS smoothers as
special cases. We can use this close relationship to implement EP without the explicit use of derivatives,
which is often more numerically stable for non-linear approximations (Seeger, 2005).
Remark4 (ComputationalComplexity) .Thederivative-freeupdates,whicharenearlyidenticaltothegeneric
updates for Gaussian filters/smoothers, tells us that the computational complexity of EP for state estima-
tion isO(KF), whereKis the number of EP iterations, and Fis the computational complexity of the
corresponding Gaussian filter/smoother. This means that EP has the same computational complexity as a
standard Gaussian filter/smoother for each EP iteration.
16Published in Transactions on Machine Learning Research (06/2022)
10 20 30 40 50
EP Iterations345678RMSEEP (=1.0,=1.0)
EP with damping (=1.0,=0.9)
Power EP with damping (=0.9,=0.9)
10 20 30 40 50
EP Iterations2468NLLEP (=1.0,=1.0)
EP with damping (=1.0,=0.9)
Power EP with damping (=0.9,=0.9)
Figure 3: RMSE and NLL for EP (red), damped EP (green), and damped power EP (grey). We extend
on the running example from Figure 1, but omit the filtering/smoothing baseline graphs to focus on the
effects of damping and power. Both damped EP and damped power EP reduce the oscillations seen in EP
substantially. Using power EP, we further improve the performance of EP and damped EP. The power of
EP and damping factor are identical, which improves numerical stability as the power and damping cancel
out in the computations of the updated marginals, see (116) in Algorithm 2.
4 Improving EP by Damping and α-Divergence
RevisitingFigure1, we seethatalthoughEPimproves theresultsoftheRTSsmoother, EPdoes notconverge
to a fixed point but oscillates. In general, it is possible that in the case of non-linear systems, approximate
EP may deteriorate and produce results inferior to ones of the RTS smoother. It may even diverge and fail
to perform the estimation task. One can employ heuristics to determine termination conditions, but there
are no established stopping or convergence criteria. In this section, we introduce damping and minimisation
of theα-divergence as possible remedies to this well-known shortcoming of EP.
4.1 Damped EP
Oscillatory behaviour of EP, as observed in Figure 1, is well-known (Heskes & Zoeter, 2003). Standard EP
has an iteration scheme without termination criteria, and it is not guaranteed to converge (Minka, 2001a).
EP operates on one factor at a time. However, one can establish a convergence criterion based on the
covariance of all the factors in the algorithm. This is called double-loop EP (Heskes & Zoeter, 2003). In a
double-loop EP, the inner loop is a standard EP with damped updates for each factor. The outer loop is
used to pick the optimal damping rate for the inner EP update based on all the factors. However, this outer
loop is prohibitively expensive for most practical applications. Moreover, non-linear systems, as discussed in
this article, use approximate EP, and the approximation would lose any convergence guarantees associated
with the double-loop version.
Instead of computing an optimal damping for each iteration, we can use a fixed damping rate for the EP
updates, which results in the so-called damped EP (Minka, 2004). This damping helps the algorithm to
avoid limit cycles (Heskes & Zoeter, 2003). This changes the EP updates of the marginal and the factor qi
in (29)–(30) to
q′(xt) = proj/bracketleftbig
fi(xt)q\i(xt)/bracketrightbig
(109)
q(xt)new∝q′(xt)γq(xt)1−γ(110)
qi(xt)new∝q(xt)new
q\i(xt), (111)
whereq′corresponds to the undamped update in (29). Damping can be interpreted as a log-opinion pool
between the current estimate and an updated estimate, where the damping factor γ∈(0,1]indicates how
4As usual, the integrals below are only computed approximately, e.g., by using linearisation or the unscented transform.
17Published in Transactions on Machine Learning Research (06/2022)
much weight is given to the current estimate. For γ= 1, we obtain the classical EP updates from (29)–(30),
whereas for γ= 0, we would not update at all.
The damping factor γis a hyper-parameter, which can be tuned depending on the filtering task. In Figure 3,
we plot the effect that damping and α-divergence (this will be explained in the next section) has on EP
performance, where we use the Unscented Transform to implicitly linearise the system (see also Figures 10
and 11 in Appendix C for the equivalent plots using the Monte-Carlo Transform and Taylor Transform to
linearise the system, respectively). We see that a damping factor of 0.9reduces oscillations and stabilises
EP in this particular example. We chose 0.9to illustrate the effect of damping on oscillations; in Section 5,
we provide a more thorough sensitivity analysis for γ.
4.2α-Divergence
In some cases, the damping factor γalone may not improve the results of EP. This is particularly true
for non-linear systems, where the true posteriors are often multi-modal. EP, as discussed so far in this
article, minimizes the KL divergence KL (p||q)between the true posterior and its approximation, so that
the approximate posterior qhas significant probability mass where phas significant probability mass, i.e., it
averages between modes; this direction of the KLdivergence is not mode-seeking (Bishop, 2006). Depending
on the application, one may want to encourage the algorithm to cover most of the probability mass (i.e.,
a mode averaging behaviour), in which case standard EP may be desirable. On the other hand, it may
be desirable in some applications that the algorithm picks one of the modes rather than averaging them,
e.g., in the case of tracking a car moving past a junction. To achieve this flexibility, we can modify the
optimisation objective to encourage the desired behaviour by using power EP instead (Minka, 2004). Power
EP minimises the α-divergence (Amari, 1985) instead of the KL-divergence used by standard EP (Minka,
2004). The α-divergence is a generalisation of the KLdivergence (Zhu & Rohwer, 1995). We follow (Minka,
2005; Zhu & Rohwer, 1995) and define the α-divergence as
Dα(p||q) :=/integraltext
αp(x) + (1−α)q(x)−p(x)αq(x)1−αdx
α(1−α), (112)
whereDα(p||q) = 0if and only if p=qand positive otherwise. For α= 1, we obtain the KL-divergence
KL (p||q)(Zhu & Rohwer, 1995), for α= 0.5, the objective corresponds to the Hellinger distance and for
α= 0, we obtain the KL-divergence KL (q||p)again, except with the arguments reversed. Clearly, the case
α= 1recovers standard EP and the case α= 0recovers variational Bayesian inference. Thus, power EP
can be seen as a bridge between these two commonly used algorithms (Minka, 2005).
To increase the flexibility of our distributed state-estimation algorithm, we propose to use the α-divergence
as ourcost functionto which we findthe approximate Gaussianposterior. That is, wewish to finda Gaussian
q′such thatq′= arg min qDα(p||q)in our projection step, instead of q′= arg min qKL (p||q)as in EP. Here,
the ‘true’ distribution pis given by the tilted distribution p(x) =fi(x)q\i(x)as usual. Typically it would
be difficult to compute or even approximate (112). However, we can work around this challenge by using
the following property of α-divergences (Minka, 2005):
Proposition 1. Any stationary point qofDα(p||q)is also a stationary point of proj/bracketleftbig
p(x)αq(x)1−α/bracketrightbig
.
Algorithm 2 describes EP (with damping) using the α-divergence to find the approximate posterior, instead
of the usual KL divergence minimisation. Setting p(x)∝fi(x)q\i(x), one can check by a straightforward
calculation that proj/bracketleftbig
p(x)αq(x)1−α/bracketrightbig
= proj/bracketleftbig
fi(x)αqα\i(x)/bracketrightbig
,where we defined qα\i(x)∝q(x)/qα
i(x). Thus
the projection step in this modified EP reads
q′= arg min
qDα(p||q)⇔q′(x) = proj/bracketleftbig
fα
i(x)qα\i(x)/bracketrightbig
, (117)
giving us (114) in step 6of the algorithm.
We see from (117) that an interpretation of power EP is that it allows for the fractional inclusion of a
true factor fi, which then yields a partial update to the corresponding approximate fractional factorqα
iin
step 7of the algorithm. In Appendix B, we detail the explicit computations of the projection step (117) for
state-estimation problems, analogous to the computations we did in Section 3.4 for standard EP.
18Published in Transactions on Machine Learning Research (06/2022)
Algorithm 2 Damped Power EP for Dynamical Systems
1:Init:Set all factors qα
itoN(0,∞I); Setq(x1) =p(x1)and marginals q(xt>1) =N(0,1010I)
2:repeat
3:fort= 1toTdo
4:forall factorsqα
i, wherei=▷,△,◁do
5: Compute cavity distribution:
qα\i(xt)∝q(xt)/qα
i(xt) (113)
6: Project:
q′(xt) = proj/bracketleftbig
fα
i(xt)qα\i(xt)/bracketrightbig
(114)
7: Update fractional factor (with damping):
qα
i(xt)new=qα
i(xt)1−γ/parenleftbiggq′(xt)
qα\i(xt)/parenrightbiggγ
∝qα
i(xt)/parenleftbiggq′(xt)
q(xt)/parenrightbiggγ
(115)
8: Update posterior (with damping):
q(xt)new∝q(xt)/parenleftbiggqα
i(xt)new
qα
i(xt)/parenrightbigg1/α
=q(xt)/parenleftbiggq′(xt)
q(xt)/parenrightbiggγ/α
(116)
9:end for
10:end for
11:untilConvergence or maximum number of iterations exceeded
The advantage of applying damped power EP to our running example is demonstrated in Figure 3. We
see that the RMSE/NLL are both lower than that of the damped EP. The same choice of damping γand
αis convenient mathematically, since the power and damping cancel each other out, which simplifies the
posterior update step 8 in Algorithm 2.
5 Results
In the following, we evaluate the proposed iterative state estimator on three benchmark problems. We use
the root mean square error (RMSE) and the negative log-likelihood (NLL) to evaluate its performance, whose
precise expressions can be found in Appendix A.3.
5.1 Non-linear Growth Model
First we consider the non-linear benchmark from Section 2.3. The example shown in Figure 3 uses the
unscented transform for a single seed. We now repeat the same experiment with 10 different random seeds
to evaluate the robustness of different algorithms. Our first goal is to evaluate power EP for different values
of powerαon the non-linear benchmark problem using different transforms.
5.1.1 Effects of Damping, Power and Linearisation Methods
Wetestα-divergenceEPwiththreedifferentlinearisationtechniques, theTaylortransform(TT),the(scaled)
unscented transform (UT) and the Monte Carlo transform (MCT). For the scaled UT we use parameters
(αUT,βUT,κUT) = (1,2,3)for the transition function and (αUT,βUT,κUT) = (1,2,2)for the measurement
function throughout the paper. Similar to the TT (employed by the EKS) and the UT (employed by the
UKS), the MCT computes Gaussian approximations; however, the means and covariances of these Gaussian
approximations are computed by sampling from the (Gaussian) cavity distribution and then using a Monte
Carlo estimate to obtain the desired means and covariances. We refer to this as the Monte-Carlo Kalman
19Published in Transactions on Machine Learning Research (06/2022)
10 20 30 40 502.55.07.510.0RMSEPower: 1.0, Damping: 1.0
TT UT MCT
10 20 30 40 500200400NLLTT
10 20 30 40 50
EP Iterations0510NLLUT MCT
(a) EP, UNGM
10 20 30 40 502.55.07.510.0Power: 1.0, Damping: 0.9
TT UT MCT
10 20 30 40 500200400 TT
10 20 30 40 50
EP Iterations0510UT MCT (b) Damped EP, UNGM
10 20 30 40 502.55.07.510.0Power: 0.9, Damping: 0.9
TT UT MCT
10 20 30 40 500200400 TT
10 20 30 40 50
EP Iterations0510UT MCT (c) Damped power EP, UNGM
Figure 4: RMSE and NLL performance over multiple runs of the experimental set-up corresponding to
Figure 3. Other linearisation methods, namely the Monte Carlo transform (MCT) and the first-order Taylor
transform (TT) are shown alongside the unscented transform (UT). Solid lines show average performance
across 10independent evaluations and shaded regions show one standard deviation away from the mean.
Dashed lines show average performance of the corresponding Gaussian smoother across the same 10seeds.
(a)(γ,α) = (1,1); (b) (γ,α) = (1,0.9); (c) (γ,α) = (0.9,0.9). MCT is the most stable and performs well
for a wide range of damping factors and powers. In contrast, the TT performs poorly on the NLL and is
plotted separately from the UT and the MCT due to the difference in scales.
smoother (abbreviated as MCKS). We used 104samples throughout this paper. The posteriors are updated
according to (102)–(103) and (106)–(107). The MCT determines the exact moments in the limit of infinitely
many samples; that means, in the context of this article, the MCT serves as a ‘best-approximation’ baseline,
which, however, is computationally more demanding than the TT or the UT.
In Figure 4a, we run standard approximate EP ( α= 1.0,γ= 1.0) using all three transforms for approximate
inference (TT, UT, MCT). In this setting, the first iteration is identical to the respective Gaussian smoother.
We see that both the TT and UT based iterations, in terms of RMSE and NLL, oscillate significantly; for
the MCT, the RMSE improves rapidly in the beginning, however, subsequent updates do not improve the
results much further; only slight oscillations occur. Note that the overall higher accuracy and stability of the
MCT is due to the large number of samples ( 104) used for statistical linearisation in this one-dimensional
system.
Changing the damping rate to γ= 0.9(Figure 4b), as used in the running example, we see that there are
fewer oscillations in the RMSE across all transformations (TT, UT, MCT). Further reductions in oscillations
canbeobservedbysetting γtosmallervalues, butatthecostofrequiringmoreEPiterationsforconvergence.
Note that damping does not necessarily improve the RMSE (or the variability of the results) significantly,
comparedwithFigure4a. AnexceptionistheUT,wheredampingdoesimprovetheresultsslightly. However,
the main impact of the damping factor on the RMSE is therefore to reduce oscillations. The same could be
said for the NLL in the UT and MCT examples. However, for the TT, damping appears to impact NLL
negatively, increasing the variability of the results even further across seeds.
In Figure 4c, we use α= 0.9and damping γ= 0.9as in Figure 3. All transforms now show more stable
RMSE curves with visibly more consistent behaviour for TT. The performance, in terms of RMSE, is slightly
20Published in Transactions on Machine Learning Research (06/2022)
improved across all transformations compared to Figure 4b. For the NLL, the same observations hold with
the exception of the TT, where the performance is generally worse compared to the previous two cases, with
high spread across seeds after around iteration 10. Thus, with the exception of the TT, slightly decreasing
the power and damping rate improves the overall results on average, which, for the UT, we found to be
consistent across all random seeds used in this experiment. For the MCT, this is true for nine out of ten
seeds that we tested, and when improvement is observed, it is more pronounced compared to the UT (see,
e.g., Figure 10 in Appendix C).
In Table 2, we display the RMSE and the NLL results of damped power EP after 50 iterations for different
combinations of αandγ. This is compared against the results of the corresponding Kalman-type smoother
for the given type of linearisation (e.g. the EKS when using the Taylor transform for linearisation) and
the IEKS (Bell, 1994), which we take as baseline methods. Note that the IEKS is a MAP estimator (Bell,
1994) and therefore only produces pointwise predictions (st)T
t=1. To evaluate the NLL, we supplement these
predictions with covariance matrices (Pt)T
t=1, obtained by the RTS smoother at every iteration. We see
in general that EP iterations improve predictions in terms of the RMSE and NLL. However, setting the α
parameter too low could result in bad NLL values, which we discuss in more details in the next section. The
IEKS baseline does not produce good predictions in this example; damped power EP overall does better,
although there are some exceptions, e.g. the NLL values when αis small.
Taylor transform Unscented transform Monte-Carlo transform
Baselines RMSE NLL RMSE NLL RMSE NLL
EKS/UKS/MCKS 8.73±1.99 45.8±22.97.60±0.73 9.54±3.28 5.17±0.69 3.35±0.94
IEKS 15.7±4.0 98.8±22.8 – – – –
γ= 1.0 RMSE NLL RMSE NLL RMSE NLL
Power EP ( α= 1.0)7.58±1.37 91.8±52.55.74±0.90 6.63±2.13 4.17±0.65 2.84±0.80
Power EP ( α= 0.8)6.68±1.47 166±190 5.07±0.99 7.58±3.45 3.63±0.80 2.81±0.97
Power EP ( α= 0.6)6.87±1.49 97.8±87.35.69±1.11 9.39±4.77 3.17±0.84 3.52±1.44
Power EP ( α= 0.4)7.26±1.62 200±223 5.92±1.38 43.0±32.8 3.04±0.84 27.5±37.7
Power EP ( α= 0.2)7.28±1.27 136±114 6.01±1.40 197±161 3.81±1.06 189±127
γ= 0.8 RMSE NLL RMSE NLL RMSE NLL
Power EP ( α= 1.0)7.70±1.75 91.8±85.94.90±0.95 5.47±2.55 4.14±0.74 2.72±0.66
Power EP ( α= 0.8)7.31±1.08 86.6±38.05.10±1.17 6.59±3.00 3.33±0.602.41±0.75
Power EP ( α= 0.6)7.65±1.06 93.9±63.95.26±0.98 9.14±4.19 2.94±0.70 4.00±4.66
Power EP ( α= 0.4)7.71±1.23 180±117 4.97±1.03 28.2±20.8 2.86±0.73 31.0±34.5
Power EP ( α= 0.2)8.08±1.29 130±94 6.14±1.80 463±474 3.30±0.47 258±176
γ= 0.6 RMSE NLL RMSE NLL RMSE NLL
Power EP ( α= 1.0)8.29±1.68 104±85.25.05±0.83 5.20±2.25 4.11±0.71 2.68±0.65
Power EP ( α= 0.8)7.53±1.03 109±79.14.70±0.78 5.00±2.11 3.41±0.77 2.58±1.04
Power EP ( α= 0.6)7.80±1.13 125±91.25.25±1.13 7.70±3.73 2.96±0.70 3.67±4.06
Power EP ( α= 0.4)7.89±1.06 140±57.25.14±0.99 21.6±16.02.74±0.55 22.7±35.8
Power EP ( α= 0.2)8.15±1.25 157±66 5.56±0.81 336±272 2.80±0.62 247±183
Table 2: Comparison of RMSE and NLL performance of iterated damped power EP for the UNGM exper-
iment. We compare the results of damped power EP with α∈{0.2,0.4,0.6,0.8,1.0}andγ∈{0.6,0.8,1.0}
against the corresponding Gaussian smoother. We also consider the IEKS as a baseline. The mean and
standard deviation is displayed across 10 different seeds after 50 EP iterations (we also take 50 iterations
for the IEKS), for all transformation types (TT, UT and MCT). We highlight in boldthe best results for
the RMSE and the NLL. In general, iterating EP improves the RMSE and the NLL, provided αis not too
small. An exception is the NLL when using the TT for linearisation, in which case iterating EP gives worse
results. The IEKS performed poorly in this example and power EP yields better results in general.
5.1.2 Sensitivity Analysis
For a more detailed sensitivity analysis, we perform a full sweep across both power α∈[0.1,1.0]and damping
γ∈[0.1,1.0], with a fixed number of 50 EP iterations per experiment. We plot the resulting heat maps of
the mean of both RMSE and NLL across ten different seeds and all three transforms in Figures 6 and 7.
21Published in Transactions on Machine Learning Research (06/2022)
0.1 0.4 0.7 1.051015RMSEIteration: 1, Damping: 0.5
TT UT MCT
0.1 0.4 0.7 1.0
Power02040NLLTT UT MCT
(a) After 1 EP iteration
0.1 0.4 0.7 1.051015Iteration: 10, Damping: 0.5
TT UT MCT
0.1 0.4 0.7 1.0
Power0100200TT UT MCT (b) After 10 EP iterations
0.1 0.4 0.7 1.051015Iteration: 50, Damping: 0.5
TT UT MCT
0.1 0.4 0.7 1.0
Power0250500750 TT UT MCT (c) After 50 EP iterations
Figure 5: Sensitivity analysis of the proposed algorithm across different choices of power α. The damping is
constant for all the experiments and set to γ= 0.5. We average across 10 different seeds with shaded areas
indicating the standard deviation. (a) For the first iteration, we see that the results are largely insensitive
to power, with RMSE slightly preferring lower powers. (b) and (c) show the corresponding 10th and 50th
iteration, respectively. For the UT and the MCT, the RMSE is slightly better at lower powers, whereas the
NLL is much worse (and increasing with iterations). The TT is less sensitive to power overall, except in the
10th iteration, there is a sudden jump in the RMSE and NLL at α= 1.0.
The RMSE in Figure 6a for the Taylor transform shows optimal performance in the top-right corner, for
moderately high values of power and damping α,γ∈[0.8,1.0). Decreasing both parameters leads to increas-
ingly worse performance, especially at very low damping rates of around γ∈[0.1,0.3]. The NLL (Figure 7a)
is less sensitive to the power, but is similarly affected negatively by decreasing damping rates.
The worst performance, in terms of both RMSE and NLL, mutually occurs under the combination of low
damping rates γ∈[0.1,0.3]and high power γ∈[0.9,1.0]. This is due to slow convergence at low damping
rates and can be checked to converge to better values by iterating sufficiently many times. This is shown
in Figure 12 (Appendix C), where we plot the RMSE and NLL values of damped EP after 500 iterations.
The damping factor is set to γ= 0.1and the TT was used for linearisation. It is somewhat surprising
that the RMSE and NLL eventually converge to reasonable values, despite reaching values several orders of
magnitude higher ( O(103)for the RMSE and O(1011)for the NLL!) during the iterations.
The RMSE plot (Figure 6a) also shows that, while it generally prefers high power and damping rates, fixing
α= 1.0can affect the performance negatively. This does not occur for the NLL (Figure 7a), which, on the
other hand, sees sub-optimal performance when the damping rate is set to 1.0. This implies that when using
the TT for this example, the optimal performance can be achieved by setting both αandγclose to, but not
equal to 1.0.
For the UT (Figures 6b and 7b), the optimal performance in terms of RMSE occurs for a wider range of
parameters compared to the TT, at around α,γ∈(0.4,1.0), and the worst performance occurs at the corner
caseα= 0.1,γ= 0.1. Note that the NLL value is still fairly modest in this corner case despite it performing
badly at other values of damping, with fixed α= 0.1. This can be explained by the slow convergence when
the damping factor is small. We see that the NLL is overall insensitive to damping. However, it is sensitive
to power. A low power (around α<0.3) harms the performance substantially. This is due to the fact that
in the low-power region, power EP is mode-seeking and gives over-confident predictions at incorrect modes.
This can be seen for example in Figure 8a, where we plot the outputs of power EP with α= 0.1andγ= 0.4.
In the figure, we see that in the 10th and 50th iterations, the posterior of the latent states does not cover the
ground truth well at several places due to overconfident predictions. Contrast this with Figure 8b, which is
the same plot except with α= 0.9, where much of the ground truth is covered and therefore gives a much
better NLL score.
22Published in Transactions on Machine Learning Research (06/2022)
0.2 0.4 0.6 0.8 1.0
Power0.20.40.60.81.0Damping
468>10
(a) Taylor transform, UNGM
0.2 0.4 0.6 0.8 1.0
Power0.20.40.60.81.0Damping
468>10 (b) Unscented transform, UNGM
0.2 0.4 0.6 0.8 1.0
Power0.20.40.60.81.0Damping
468>10 (c) Monte Carlo transform, UNGM
Figure 6: RMSE heatmap for the Uniform Non-Linear Growth model experiment. We fixed the number of
iterations to 50 and plot the average RMSE over 10 independent runs of the proposed method for varying
powers and damping factors. We vary both power and damping between [0.1,1.0]for different transformation
types. Optimal performance is achieved for mid-to-high damping and power factors. Very low damping rates
yield poor performance due to slow convergence.
0.2 0.4 0.6 0.8 1.0
Power0.20.40.60.81.0Damping
0100200300400>500
(a) Taylor transform, UNGM
0.2 0.4 0.6 0.8 1.0
Power0.20.40.60.81.0Damping
0100200300400>500 (b) Unscented transform, UNGM
0.2 0.4 0.6 0.8 1.0
Power0.20.40.60.81.0Damping
0100200300400>500 (c) Monte Carlo transform, UNGM
Figure 7: Negative Log-Likelihood (NLL) heatmap for the UNGM experiment. Again, we fixed the number
of iterations to 50 and plot the average NLL over 10 independent runs. Similar to the RMSE, the best
performance occurs for mid-to-high power and damping factors. However in contrast to the RMSE, worst
performance in the UT and the MCT occur at very low powers. The poor performance in the bottom-right
corner in the MCT is due to slow convergence.
For the MCT, Figure 7c shows that the NLL results are similar to the ones obtained with the UT, with
low power of around α<0.3being harmful to the performance. In contrast, the result in Figure 6c, while
subtle, indicates that the RMSE slightly prefers mid-to-low power at around α < 0.6. This is indicated
more clearly in Figure 5, where we plotted the RMSE and NLL against the power at different EP iterations.
The significant degradation in NLL due to low power however is clearly not worth the slight gain in RMSE.
Hence, it is optimal to use mid-to-high power of around α > 0.6in this example. We see that both the
RMSE and NLL results in Figures 6c and 7c are less sensitive to damping rates; only the RMSE is affected
negatively by low damping rates of around α<0.2, due to the slower convergence rate in this region.
5.2 Bearings-only Tracking of a Turning Target
We now test our proposed method for a classic bearings-only tracking problem that is commonly encountered
in passive sensor environments. In this problem, we assume that a single target is executing a maneuvering
turn, with four sensors measuring the angles between the target and the sensors, similar to the example
23Published in Transactions on Machine Learning Research (06/2022)
20 40 60 80 10020
020(Iteration 1) RMSE=8.11, NLL=3.47
Prediction Ground truth
20 40 60 80 10020
020(Iteration 10) RMSE=6.08, NLL=38.84
20 40 60 80 100
Time steps20
020(Iteration 50) RMSE=6.17, NLL=681.48
(a)α= 0.1. While the RMSE values generally improve, the
NLL values get progressively worse with iterations as a result
of the mode-seeking behaviour of power EP with α= 0.1.
20 40 60 80 10020
020(Iteration 1) RMSE=7.67, NLL=3.53
Prediction Ground truth
20 40 60 80 10020
020(Iteration 10) RMSE=6.17, NLL=3.74
20 40 60 80 100
Time steps20
020(Iteration 50) RMSE=4.74, NLL=2.65(b)α= 0.9. The RMSE decreases with iterations. However,
in contrast to the results in (a), we see that the NLL decreases
too due to better uncertainty coverage.
Figure 8: Outputs of damped power EP for a single run of the UNGM experiment. The ground-truth
trajectory is shown in red; the shaded blue areas indicate the standard deviation around the mean (solid
blue) of the posterior state estimate using EP with damping factor γ= 0.4. The unscented transform is
used for linearisation. We show the results at EP iterations 1, 10 and 50 for (a) α= 0.1; (b)α= 0.9.
considered in Särkkä & Hartikainen (2010). The dynamical system is given by
xt=A(ωt−1)xt−1+wt−1,wt−1∼N(0,Q),
yt=h(xt) +vt, vt∼N(0,R),(118)
where the state is given by x= (x1,˙x1,x2,˙x2,ω)⊤∈R5, such that the position of the target is z= (x1,x2)⊤,
the corresponding velocities are ˙z= ( ˙x1,˙x2)⊤, respectively, and ωis the time-varying turning rate of the
maneuver. The transition matrix A(ω)takes the form
A(ω) =
1sin(ω∆t)
ω0−1−cos(ω∆t)
ω0
0 cos(ω∆t) 0−sin(ω∆t) 0
01−cos(ω∆t)
ω1sin(ω∆t)
ω0
0 sin(ω∆t) 0 cos( ω∆t) 0
0 0 0 0 1
, (119)
where ∆tis the timestep between two consecutive measurements. The measurement model h(x) =
(h1(x),h2(x),h3(x),h4(x))⊤∈R4is given by
hi(x) = tan−1/parenleftbiggx2−si
2
x1−si
1/parenrightbigg
, i∈{1,2,3,4}, (120)
which measures the angle between the target and the i-th sensorsi= (si
1,si
2)⊤. Following the same setup
as in the target tracking example considered by Arasaratnam & Haykin (2009), we choose the initial state
distribution p(x0) =N(µ0,Σ0), where
µ0= (1000m,300ms−1,1000m,0ms−1,−3◦s−1)⊤, (121)
Σ0= diag(100m2,10m2s−2,100m2,10m2s−2,10−4rad2s−2), (122)
24Published in Transactions on Machine Learning Research (06/2022)
and choose our model error covariance to be of the form Q= diag(q1M,q1M,q2∆t), whereq1= 0.1m2s−3,
q2= 1.75×10−1s−3, and
M=/parenleftigg
∆t3
3∆t2
2
∆t2
2∆t/parenrightigg
. (123)
Since the measurements ytonly depend on the position variables, the cross-correlation in (123) is important
for reconstructing the full latent state. The observation errors for the four sensors are assumed to be
independent and given by Ri=N(0,r2
i), whereri=√
10×10−3rad for all i∈{1,2,3,4}. We consider
trajectories of length 50sand set the sampling frequency to ∆t= 1s. The sensors are placed on the four
corners of the square s1= (−20km,20km),s2= (20km,20km),s3= (−20km,−20km),s4= (20km,−20km)
and assumed to produce measurements at every time step.
Position (z) Velocity ( ˙z) Angular velocity ( ω)
TT RMSE NLL RMSE NLL RMSE (×10−3) NLL
EKS 43.1±5.5 11.0±1.2 11.1±2.4 11.9±2.3 1.44±0.35−2.80±0.27
IEKS 24.8±1.8 8.33±0.267.10±2.33 5.01±0.81 1.26±0.33−3.03±0.10
PEP (α= 1.0)43.1±5.5 11.0±1.2 11.1±2.4 11.9±2.3 1.44±0.35−2.80±0.27
PEP (α= 0.8)36.8±5.8 9.65±0.84 9.82±2.14 11.9±3.1 1.26±0.31−3.00±0.14
PEP (α= 0.6)36.8±5.9 9.62±0.83 9.80±2.13 12.1±3.3 1.26±0.33−2.99±0.16
PEP (α= 0.4)36.7±5.9 9.61±0.83 9.79±2.12 12.1±3.3 1.26±0.33−2.99±0.16
PEP (α= 0.2)36.7±5.9 9.61±0.82 9.78±2.11 12.2±3.3 1.26±0.33−2.99±0.16
UT RMSE NLL RMSE NLL RMSE (×10−3) NLL
UKS 26.5±1.9 8.58±0.49 7.64±1.80 5.66±0.42 1.26±0.28−3.04±0.07
PEP (α= 1.0)26.5±1.9 8.58±0.49 7.64±1.80 5.66±0.42 1.26±0.28−3.04±0.07
PEP (α= 0.8)26.2±2.1 8.51±0.37 7.50±1.87 5.37±0.48 1.26±0.29−3.04±0.08
PEP (α= 0.6)26.2±2.1 8.50±0.36 7.49±1.86 5.33±0.47 1.26±0.29−3.04±0.08
PEP (α= 0.4)26.2±2.1 8.50±0.36 7.48±1.85 5.33±0.46 1.26±0.29−3.04±0.08
PEP (α= 0.2)26.2±2.1 8.50±0.36 7.48±1.85 5.32±0.45 1.26±0.28−3.04±0.08
MCT RMSE NLL RMSE NLL RMSE (×10−3) NLL
MCKS 28.6±3.1 8.70±0.45 9.85±2.17 6.03±0.48 1.66±0.35−2.85±0.12
PEP (α= 1.0)26.4±2.2 8.57±0.58 7.68±1.84 5.69±0.55 1.27±0.29−3.03±0.08
PEP (α= 0.8)26.1±2.0 8.51±0.40 7.58±1.89 5.40±0.57 1.27±0.29−3.03±0.08
PEP (α= 0.6)25.9±2.2 8.50±0.42 7.49±1.89 5.35±0.58 1.27±0.29−3.03±0.08
PEP (α= 0.4)26.0±2.2 8.50±0.41 7.44±1.93 5.34±0.53 1.26±0.30−3.04±0.08
PEP (α= 0.2)26.3±2.1 8.52±0.43 7.55±1.86 5.38±0.55 1.27±0.29−3.03±0.08
Table 3: Comparison of RMSE and NLL performance of iterated power EP (abbreviated as PEP) for the
bearings-only turning target tracking problem. We compare the results for α∈{0.2,0.4,0.6,0.8,1.0}. The
damping factor is fixed at γ= 1.0for all experiments; changing the damping factor did not affect the results
much. We display the mean and standard deviation across 10different seeds after 50EP iterations, for all
transformation types (TT, UT and MCT). As baselines, we also display the results of the corresponding
Gaussian smoother and the IEKS after 50 iterations. For each variable, the best results in terms of the
RMSE and the NLL are highlighted in bold. We observe that when α= 1.0, i.e., standard approximate EP,
iteration does not improve upon the results of the corresponding Kalman-type smoother for the TT and UT
(improvement is seen however for the MCT). Choosing smaller values of αcan improve the result, which
is most signficant in the position variable ( z) when using the TT. However overall, the best performance is
obtained by the IEKS, with power EP performing competitively only in the ωvariable.
We compare the performance of iterated power EP for various values of α, including α= 1.0, which is
equivalent to standard approximate EP. In all the experiments, we take 50EP iterations, which we verified
is enough to ensure convergence, and set the damping factor to γ= 1.0(i.e., no damping). No oscillatory
behaviour was observed during the EP iterations (except for the MCT, where oscillations occurred primarily
due to its stochastic nature; taking larger number of samples helped reduce the oscillations) and therefore
no damping was necessary to aid convergence. For reference, we also compared the results against the
25Published in Transactions on Machine Learning Research (06/2022)
corresponding Kalman-type smoother for the given type of linearisation and the IEKS (Bell, 1994), which
form our baseline methods.
Below are further details on the configurations used in the experiments
•The parameters of the scaled UT were set to (αUT,βUT,κUT) = (1,0,−1)for both the transition and
measurement functions, in accordance with Särkkä & Hartikainen (2010).
•104particles were used in all the MCT experiments.
•We used the values α∈{0.2,0.4,0.6,0.8,1.0}for the power.
The results of the experiments are displayed in Table 3. For this system, we observe that simply iterating the
approximate EP (i.e., power EP with α= 1.0) does not improve the results of the corresponding Kalman-
type smoother when we use the TT and UT for linearisation. This is true for both the RMSE and NLL
performance across all variables (position, velocity, angular velocity). However, by taking smaller values of
α, we see an overall gain in performance. For the TT, significant improvement is obtained in the RMSE for
the position variable when taking α≤0.8, with the best performance occurring at α={0.2,0.4}although
the results are very close when α∈{0.6,0.8}. We also see improvements in the RMSE for the velocity and
angular velocity variables by taking α≤0.8, although they are less pronounced than the former. The NLL
also sees some improvement by taking smaller values of α, except for the velocity variable, where taking
α≤0.6appears to slightly deteriorate the NLL performance. This is likely due to overconfident predictions
owing to the mode-seeking nature of power EP for small α. While similar improvements in the RMSE and
NLL are observed for the UT, the difference is not as significant (in fact, no difference at all in the angular
velocity variable). This is likely due to the UKS already performing very well on this task and therefore has
smaller margins for improvements.
On the other hand, when using the MCT for linearisation, we see that most of the improvements in the
RMSE and the NLL comes from iterating as opposed to taking smaller α, although taking smaller αcan
help squeeze out better performance. This is evident from the fact that the difference in values between
the result from the Kalman smoother and EP after 50iterations are on average greater than the difference
between the results of power EP with different α. Interestingly, we also observed that smaller values for
αcan help to reduce the oscillations during the EP iterations even with moderate number of particles
(in this case, 104). We show this in Figure 13 (Appendix C), where we plotted the average RMSE and
NLL across all variables (position, velocity and angular velocity) against the number of EP iterations for
(α,γ)∈{(1.0,1.0),(1.0,0.8),(0.8,1.0)}. Whenα= 1.0, we see that damping reduces the oscillations slightly
in both the RMSE and NLL, however the oscillations in the NLL is still very large. Taking α= 0.8reduces
this oscillation in the NLL dramatically, even when no damping is applied (although the RMSE becomes
slightly oscillatory again).
While power EP does give better results than the corresponding Gaussian smoother, it does not outperform
the IEKS, which overall gives the best performance in this example. Only in the ωvariable does power EP
yield competitive results.
Overall, we conclude that for this system, the IEKS performs the best, although power EP can give good
results. We see that simply iterating the EP does not alter the smoother results when the TT and UT are
used for linearisation. However, notable improvements can be observed by considering smaller values of α
in power EP. When using the MCT, we see benefits from iterating the approximate EP, even when α= 1.0.
Moreover, further gains in performance can be obtained by taking smaller values of α. The results for the
IEKS however are hard to beat even with these improvements, with power EP only slightly outperforming
the IEKS in the ωvariable.
5.3 Lorenz 96 Model
In our final example, we test our method on the Lorenz 96 model (Lorenz, 1996), another commonly used
benchmark for nonlinear filters/smoothers (Brajard et al., 2020; Fablet et al., 2021; Ott et al., 2004). The
26Published in Transactions on Machine Learning Research (06/2022)
model is defined by a system of ODEs
dxi
dt= (xi+1−xi−2)xi−1−xi+F, i = 1,...,d,
wherex−1=xd−1, x 0=xd, xd+1=x1.(124)
Here,d >4is the dimension of the system and Fis a forcing constant, which we set to F= 8. For our
transition model f, we consider a fourth-order Runge–Kutta discretisation of system (124) with step size
∆t= 0.05. The model error covariance is Q= 0.1I. For the measurement model, we consider the quadratic
operatorh(x) = (x2
1,...,x2
d)⊤∈Rd, with error covariance R=I.
Since we are free to choose the state dimension dof the system, we investigate how our method performs
with increasing dimensions. We evaluate this for systems with dimensions d∈{5,10,20,40,100,200}. Our
initial stateµ0is obtained by spinning-up the model (124) using the fourth-order Runge–Kutta (RK4)
discretisation, starting from the state (0.01,0,0,..., 0)⊤∈Rdand taking 99RK4 timesteps with step size
∆t= 0.05. We set the initial state distribution to p(x0) =N(x0|µ0,I).
The RMSE and NLL results of power EP applied to the Lorenz 96 model across various values of dis
shown in Table 4. We used the values α∈{0.1,0.8,1.0}for the power factor and took 10EP iterations
with no damping for all the experiments. Oscillatory behaviour was not observed during the EP iterations
and adding damping did not change the results by much. For the linearisation methods, we considered the
TT and the UT, with the same UT parameters (αUT,βUT,κUT)that we used for the UNGM experiment
(Section 5.1). We found the MCT with 104particles to be numerically unstable at d≥40for some seed
settings and therefore do not report results for MCT here.5
We see that overall, iterating EP helps to improve both the NLL and RMSE performance over the corre-
sponding Kalman-type smoothers. In contrast, the values of αdo not affect the performance by much. For
the TT, improvements by EP iteration is observed for the RMSE across all values of d, even outperforming
the IEKS. At low dimensions ( d≤10) we see a similar improvement in the NLL. However, for d≥20, EP
iterations appear to affect the NLL results negatively for some values of α. Moreover, the obtained NLL
values are worse by several orders of magnitude compared to those obtained for d≤10. To investigate this
further, we plotted the results for individual seeds in Figure 9 with d= 20and(α,γ) = (1.0,1.0). We see
that in nine out of ten cases, EP iterations actually improve the NLL performance. However, there is a single
outlier case that starts out significantly worse than the rest in the first iteration and becomes worse with
subsequent iterations for the NLL (for the RMSE, iteration appears to always improve the results, which
means that the uncertainty estimates become increasingly overconfident). These outlier scenarios that start
out badly are therefore responsible for the significantly worse NLL values and large spread that we see for
d≥20, even though in most cases, EP iterations actually improve the NLL.
For the UT, we see improvements in the RMSE and NLL with EP iterations for all experiments that
we conducted. Furthermore, we see that the gain in performance due to iterations becomes increasingly
pronounced with increasing d, especially for the NLL. For example, at d= 5, we only see an improvement
in the NLL by a few decimal points upon iterating. However at d= 200, we see a performance gain of
O(102)—much more than what we had anticipated. While less obvious, this trend of increasing performance
gain with increasing dimensions also holds for the RMSE. In Figure 14 (Appendix C), we show Hovmöller
diagrams illustrating the absolute errors for the predictions made by the Unscented Kalman smoother and
the errors made by approximate EP with (α,γ) = (1.0,1.0)after 10 iterations. The state dimension is set
tod= 200. The improvements in predictions due to EP iteration is clear—the errors made by EP after 10
iterations is visibly smaller compared to the errors made after one iteration (i.e., the UKS).
Overall, we conclude that when using the UT for linearisation, EP iterations have the effect of improving
predictions in this system, which becomes more significant at higher dimensions. Thus, our method may
prove to be more beneficial when applied to higher-dimensional systems, but with the downside of increased
computational cost. While the cost of our method only scales linearly in the number of EP iterations, the
cost of running a single iteration is already expensive for higher-dimensional systems. Therefore, it may not
be feasible in practice to run many iterations.
5Experiments with >104many particles would have required unjustified computational resources and time.
27Published in Transactions on Machine Learning Research (06/2022)
Taylor transform Unscented transform
d= 5 RMSE NLL RMSE NLL
EKS/UKS 0.43±0.04−2.47±0.49 0.42±0.05−2.61±0.38
IEKS 0.41±0.04−2.69±0.40 – –
Power EP ( α= 1.0)0.40±0.03−2.77±0.380.40±0.03−2.78±0.36
Power EP ( α= 0.8)0.40±0.03−2.78±0.370.40±0.03−2.80±0.36
Power EP ( α= 0.1)0.41±0.03−2.77±0.370.40±0.03−2.78±0.36
d= 10 RMSE NLL RMSE NLL
EKS/UKS 0.60±0.04−5.19±0.45 0.60±0.02−5.38±0.29
IEKS 0.58±0.03−5.71±0.30 – –
Power EP ( α= 1.0)0.56±0.02−5.86±0.310.56±0.02−5.85±0.29
Power EP ( α= 0.8)0.56±0.02−5.88±0.310.56±0.02−5.88±0.30
Power EP ( α= 0.1)0.57±0.03−5.84±0.350.56±0.02−5.86±0.33
d= 20 RMSE NLL RMSE NLL
EKS/UKS 2.49±4.29 1543±4626 0.95±0.09−9.33±1.19
IEKS 2.37±4.22 1789±5390 – –
Power EP ( α= 1.0)2.25±4.26 1637±4943 0.84±0.05−11.0±0.74
Power EP ( α= 0.8)2.34±4.23 1741±5252 0.82±0.04−11.3±0.5
Power EP ( α= 0.1)2.36±4.23 1792±5400 0.87±0.12−10.5±2.2
d= 40 RMSE NLL RMSE NLL
EKS/UKS 3.27±3.92 1462±3184 1.41±0.09−16.5±1.19
IEKS 3.15±3.85 1540±3388 – –
Power EP ( α= 1.0)3.11±3.86 1424±3146 1.21±0.05−21.6±1.22
Power EP ( α= 0.8)3.11±3.85 1495±3298 1.20±0.05−21.9±1.3
Power EP ( α= 0.1)3.13±3.86 1544±3398 1.28±0.20−18.3±9.5
d= 100 RMSE NLL RMSE NLL
EKS/UKS 3.04±2.01 741±2064 2.54±0.08−22.1±2.31
IEKS 2.90±1.92 850±2410 – –
Power EP ( α= 1.0)2.85±1.94 741±2125 1.98±0.08−49.2±2.35
Power EP ( α= 0.8)2.85±1.93 821±2342 1.97±0.05−51.1±0.9
Power EP ( α= 0.1)2.88±1.93 849±2410 1.97±0.12−50.6±4.2
d= 200 RMSE NLL RMSE NLL
EKS/UKS 5.09±2.93 1399±2374 4.47±0.17 8.72±4.13
IEKS 4.92±2.91 1753±3024 – –
Power EP ( α= 1.0)4.84±2.96 1604±2833 2.95±0.05−89.0±1.67
Power EP ( α= 0.8)4.83±2.96 1698±2968 2.80±0.04−103±1
Power EP ( α= 0.1)4.87±2.93 1752±3027 2.61±0.03−111±1
Table 4: Comparison of RMSE and NLL performance of iterated power EP for the Lorenz 96 experiment
across different dimensions d∈{5,10,20,40,100,200}. We compare the results for α∈{0.1,0.8,1.0}and
consider only the Taylor transform (TT) and the Unscented transform (TT). The Monte Carlo transform is
numerically unstable at high dimensions. We display the mean and standard deviation across 10different
seeds after 10EP iterations with γ= 1.0. As baselines, we also display the results of the corresponding
Gaussian smoother and the IEKS after 10 iterations. For each dimension, we highlight in bold, the best
results in the RMSE and the NLL. We see that in general, iterating EP improves the performance of the
smoother, which can even be quite significant at high dimensions for the UT. An exception is the NLL
performance at moderate-to-high dimensions when using the TT. The poor performance seen here is due to
outlier results. If we exclude these, the result remains overall positive (see Figure 9).
6 Conclusion
Weproposedaniterativestateestimatorfornon-lineardynamicalsystemsbasedonExpectationPropagation
(EP). We show that any Gaussian filter or smoother can be shown as special case of the proposed method.
28Published in Transactions on Machine Learning Research (06/2022)
15.115.215.3
2 4 6 8 10
EP Iterations1.01.5RMSE
1600017000
2 4 6 8 10
EP Iterations050NLL
Figure 9: RMSE and NLL performance of the Lorenz 96 experiment where we used the TT for linearisation
and set (α,γ) = (1.0,1.0). The state dimension is set to d= 20. We display the results for 10 independent
seeds. For most seeds, we observe that EP iterations improve predictions. However, there is one outlier
that starts off badly after the first iteration. In this case, while subsequent iterations improve the RMSE
performance, it deteriorates the NLL performance, leading to the results seen in Table 4, where the NLL
performance becomes worse on average with iterations.
The standard derivative-based EP method is numerically unstable for non-linear systems (Seeger, 2005). We
show that by explicitly accounting for the implicit linearisation typically used in Gaussian smoothers, we can
use derivative-free EP updates, which closely resemble the generic Gaussian smoothing update equations, to
build an iterative state estimator. The proposed method gets the best of both worlds, numerical stability
of Gaussian state estimators and iterative improvements of the EP algorithm. We further improve the
algorithm by using damping and power EP to improve convergence and performance.
Our experiments show the efficacy of EP for state estimation to improve standard (non-iterative) Gaussian
filtering and smoothing methods on three benchmark problems. The iterative EP method still needs the user
to choose the linearisation algorithm, which is identical to choosing the type of Gaussian filter in the standard
setting. In the three examples, we showcase that iterating our approximate EP state-estimation algorithms
(with the help of damping and power EP) generally lead to improved results in terms of the RMSE and
NLL performance compared with their Kalman filter/smoother counterpart. Further improvements are also
observed by (1) applying damping, which aids in convergence when EP is highly oscillatory, as was the case
in the UNGM experiment, and (2) replacing standard EP with power EP, which makes the predictions more
mode seeking. The latter was particularly beneficial in the bearings-only tracking experiment, where simply
taking EP iterations did not result in improved performance (when taking the TT and UT for linearisation).
However, setting αto smaller values lead to improved results. We also saw in the Lorenz 96 experiment that
iterating EP may be particularly effective for higher-dimensional systems as we saw much more significant
improvements at higher dimensions when considering the UT for linearisation. This may be potentially
useful for data assimilation problems in weather forecasting (Carrassi et al., 2018; Evensen, 2009), which
deals with filtering/smoothing in very high dimensions.
We have also compared our algorithm with another iterative smoother, namely the IEKS (Bell, 1994), which
is an extension of the EKS that iteratively refines the linearisation point after every RTS smoother pass.
While this can produce good results, sometimes even better than our EP algorithm as we saw in the bearings-
only tracking example, these are merely MAP estimators and strictly speaking, do not predict uncertainties
(although in our experiments, we have supplemented their outputs with covariance matrices generated by
the RTS smoother at every iteration). EP on the other hand, outputs uncertainty naturally and moreover
refines them iteratively without double counting observations. We have seen that on complex tasks such as
the UNGM and the L96 experiments, power EP generally outperforms the IEKS.
29Published in Transactions on Machine Learning Research (06/2022)
Overall, EP-based state estimation generalises classical Gaussian smoothers (we proved that they are a
special case), but it allows for iterative refinement of the state estimates. Furthermore, the message-passing
formulation lends itself to asynchronous and distributed state estimation; we leave this for future work.
References
Shun-ichi Amari. Differential-Geometrical Methods in Statistics , volume 28 of Lecture Notes in Statistics .
Springer, 1985.
Brian D. O. Anderson and John B. Moore. Optimal Filtering . Dover Publications, 2005.
Ienkaran Arasaratnam and Simon Haykin. Cubature Kalman Filters. IEEE Transactions on Automatic
Control, 54(6):1254–1269, 2009.
Karl J. Åström. Introduction to Stochastic Control Theory . Dover Publications, 2006.
Timothy D. Barfoot. State Estimation for Robotics . Cambridge University Press, 2017.
BradleyMBell. TheiteratedKalmansmootherasaGauss–Newtonmethod. SIAM Journal on Optimization ,
1994.
Bradley M. Bell and Frederick W. Cathey. The Iterated Kalman Filter Update as a Gauss–Newton Method.
IEEE Transactions on Automatic Control , 38(2):294–297, 1993.
Dimitri P. Bertsekas. Dynamic Programming and Optimal Control , volume 1. Athena Scientific, 3rd edition,
2005.
Christopher M. Bishop. Pattern Recognition and Machine Learning . Springer, 2006.
Julien Brajard, Alberto Carrassi, Marc Bocquet, and Laurent Bertino. Combining Data Assimilation and
Machine Learning to Emulate a Dynamical Model from Sparse and Noisy Observations: A Case Study
with the Lorenz 96 Model. Journal of Computational Science , 44:101171, 2020.
Alberto Carrassi, Marc Bocquet, Laurent Bertino, and Geir Evensen. Data assimilation in the geosciences:
An overview of methods, issues, and perspectives. Wiley Interdisciplinary Reviews: Climate Change , 2018.
The Analytic Sciences Corporation. Applied Optimal Estimation . MIT Press, 1974.
Guillaume P. Dehaene and Simon Barthelmé. Bounding Errors of Expectation Propagation. In Advances in
Neural Information Processing Systems , 2016.
Marc P. Deisenroth. Efficient Reinforcement Learning Using Gaussian Processes . KIT Scientific Publishing,
2010.
MarcP.DeisenrothandShakirMohamed. ExpectationPropagationinGaussianProcessDynamicalSystems.
InAdvances in Neural Information Processing Systems , 2012.
Marc P. Deisenroth and Henrik Ohlsson. A General Perspective on Gaussian Filtering and Smoothing:
Explaining Current and Deriving New Algorithms. In Proceedings of the American Control Conference ,
2011.
Marc P. Deisenroth, Ryan D. Turner, Marco F. Huber, Uwe D. Hanebeck, and Carl E. Rasmussen. Robust
Filtering and Smoothing with Gaussian Processes. IEEE Transactions on Automatic Control , 57(7):1865–
1871, 2012.
Arnaud Doucet, Simon J Godsill, and Christophe Andrieu. On Sequential Monte Carlo Sampling Methods
for Bayesian Filtering. Statistics and Computing , 10:197–208, 2000.
Geir Evensen. Data Assimilation: The Ensemble Kalman Filter . Springer, 2009.
30Published in Transactions on Machine Learning Research (06/2022)
Ronan Fablet, Bertrand Chapron, Lucas Drumetz, Etienne Mémin, Olivier Pannekoucke, and François
Rousseau. Learning Variational Data Assimilation Models and Solvers. Journal of Advances in Mod-
eling Earth Systems , 13(10):e2021MS002572, 2021.
San Gultekin and John Paisley. Nonlinear Kalman Filtering With Divergence Minimization. IEEE Trans-
actions on Signal Processing , 65(23):1–13, 2017.
Tom Heskes and Onno Zoeter. Expectation Propagation for Approximate Inference in Dynamic Bayesian
Networks. In Proceedings of the International Conference on Uncertainty in Artificial Intelligence , 2002.
Tom Heskes and Onno Zoeter. Extended Version: Expectation Propagation for Approximate Inference in
Dynamic Bayesian Networks. Technical report, University of Nijmegen, 2003.
Simon J. Julier, Jeffrey K. Uhlmann, and Hugh F. Durrant-Whyte. A New Method for the Nonlinear
Transformation of Means and Covariances in Filters and Estimators. IEEE Transactions on Automatic
Control, 45(3):477–482, 2000.
Rudolf E. Kalman. A New Approach to Linear Filtering and Prediction Problems. Journal of Basic Engi-
neering, 82(1):35–45, 1960.
S. Lakshmivarahan and David J. Stensrud. Ensemble Kalman Filter: Application to Meteorological Data
Assimilation. IEEE Control Systems , 29(3):34–46, 2009.
Tine Lefebvre, Herman Bruyninckx, and Joris De Schutter. Kalman Filters for Non-linear Systems: A
Comparison of Performance. International Journal of Control , 77(7):639–653, 2004.
Edward N. Lorenz. Predictability: A problem Partly Solved. In Seminar on Predictability , 1996.
Peter S. Maybeck. Stochastic Models, Estimation, and Control , volume 141 of Mathematics in Science and
Engineering . Academic Press, 1979.
Thomas P. Minka. A Family of Algorithms for Approximate Bayesian Inference . PhD thesis, Massachusetts
Institute of Technology, Cambridge, MA, USA, 2001a.
Thomas P Minka. Expectation Propagation for Approximate Bayesian Inference. In Proceedings of the
Conference on Uncertainty in Artificial Intelligence , pp. 362–369, 2001b.
Thomas P. Minka. Power EP. Technical Report MSR-TR-2004-149, Microsoft Research, 2004.
Thomas P. Minka. Divergence Measures and Message Passing. Technical report, Microsoft Research, 2005.
Thomas P. Minka. EP: A Quick Reference. Technical report, Microsoft Research, 2008.
Manfred Opper and Ole Winther. Tractable Approximations for Probabilistic Models: The Adaptive TAP
Mean Field Approach. Physical Review Letters , 86(17):5, 2001.
Edward Ott, Brian R. Hunt, Istvan Szunyogh, Aleksey V. Zimin, Eric J. Kostelich, Matteo Corazza, Eu-
genia Kalnay, D. J. Patil, and James A. Yorke. A Local Ensemble Kalman Filter for Atmospheric Data
Assimilation. Tellus A: Dynamic Meteorology and Oceanography , 56(5):415–428, 2004.
Kaare Brandt Petersen and Michael Syskind Pedersen. The Matrix Cookbook, 2012.
Yuan Qi. Extending Expectation Propagation for Graphical Models . PhD thesis, Massachusetts Institute of
Technology, 2005.
Yuan Qi and Thomas Minka. Expectation Propagation for Signal Detection in Flat-Fading Channels. In
Proceedings of the IEEE International Symposium on Information Theory , 2003.
Matti Raitoharju, Lennart Svensson, Ángel F García-Fernández, and Robert Piché. Damped Posterior
Linearization Filter. IEEE Signal Processing Letters , 25(4):536–540, 2018.
31Published in Transactions on Machine Learning Research (06/2022)
H. E. Rauch, F. Tung, and C. T. Striebel. Maximum Likelihood Estimates of Linear Dynamic Systems.
AIAA Journal , 3(8):1445–1450, 1965.
Simo Särkkä. Unscented Rauch-Tung-Striebel Smoother. IEEE Transactions on Automatic Control , 53(3):
845–849, 2008.
Simo Särkkä. Bayesian Filtering and Smoothing . Cambridge University Press, 2013. ISBN 9781139344203.
Simo Särkkä and Jouni Hartikainen. On Gaussian Optimal Smoothing of Non-linear State Space Models.
IEEE Transactions on Automatic Control , 55:1938–1941, 2010.
Simo Särkkä, Jouni Hartikainen, Lennart Svensson, and Fredrik Sandblom. On the Relation Between Gaus-
sian Process Quadratures and Sigma-Point Methods. arXiv:1504.05994 , 2015.
Matthias W. Seeger. Expectation Propagation for Exponential Families. Technical report, University of
California Berkeley, 2005.
Kenneth D. Senne. Stochastic Processes and Filtering Theory. IEEE Transactions on Automatic Control ,
17(5):752–753, 1972.
Sebastian Thrun, Wolfram Burgard, and Dieter Fox. Probabilistic Robotics . MIT Press, 2005.
Rudolph van der Merwe and Eric A. Wan. Sigma-Point Kalman Filters for Integrated Navigation. In
Proceedings of the Annual Meeting of The Institute of Navigation , 2004.
Huaiyu Zhu and Richard Rohwer. Information Geometric Measurements of Generalisation. Technical report,
Aston University, 1995.
32Published in Transactions on Machine Learning Research (06/2022)
A Appendix: Some Useful Mathematical Identities
A.1 Identities for Gaussians
For a random vector x∈RD, we define the Gaussian probability density function as
N(x|µ,Σ) := (2π)−D
2|Σ|−1
2exp/parenleftbig
−1
2(x−µ)⊤Σ−1(x−µ)/parenrightbig
(125)
whereµ∈RDandΣ∈RD×Dare the mean and covariance function, respectively.
Partial derivatives of a log-Gaussian with respect to its mean and covariance are (Petersen & Pedersen,
2012):
∂logN(x|µ,Σ)
∂µ= (x−µ)⊤Σ−1(126)
∂logN(x|µ,Σ)
∂Σ=Σ−1(x−µ)(x−µ)⊤Σ−1−Σ−1
2. (127)
For Gaussian distributions N(x|a,A),N(x|b,B), their multiplication and division results in another
(unnormalised) Gaussian. For multiplication, we obtain
N(x|a,A)N(x|b,B) =cN(x|c,C) (128)
C= (A−1+B−1)−1(129)
c=C(A−1a+B−1b) (130)
c=N(a|b,A+B), (131)
where in (131), cis not a random variable (but a constant); however, we use the Nnotation for the functional
form ofc. The division of two Gaussians is given by
N(x|a,A)
N(x|b,B)∝N(x|c,C) (132)
C= (A−1−B−1)−1(133)
c=C(A−1a−B−1b). (134)
Finally, raising a Gaussian to the power of α>0gives
[N(x|a,A)]α=N(x|a,α−1A). (135)
A.2 Identities for Matrix Inversion
A useful identity for matrix inversion (as a special case of the Woodbury identity) is
(A−1+B−1)−1=A(A+B)−1B (136)
=A−A(A+B)−1A. (137)
A.3 Metrics
Given the ground truth trajectory (xt)and outputs (µt,Σt)of a given state-estimation algorithm for time
stepst= 1,...,T, we evaluate its performance using the root mean square error (RMSE) and the negative
33Published in Transactions on Machine Learning Research (06/2022)
log-likelihood (NLL). For xt∈RD, they are given by
RMSE =/radicaltp/radicalvertex/radicalvertex/radicalbt1
TT/summationdisplay
t=1∥xt−µt∥2, (138)
NLL =−1
TT/summationdisplay
t=1logN(xt|µt,Σt), (139)
logN(xt|µt,Σt) =−D
2log(2π)−1
2log|Σt|−1
2(xt−µt)⊤Σ−1
t(xt−µt), (140)
respectively. While the RMSE only tells us how close our predictive mean is to the ground truth, the NLL
also evaluates the quality of our predictive uncertainties—it penalises heavily when the ground truth does
not lie within some credible region around the predictive mean, or when the uncertainty is much larger than
necessary even if it captures the ground truth.
B Appendix: Projections for Power EP
Here, we derive the expressions for the projections proj/bracketleftbig
fα
i(xt)qα\i(xt)/bracketrightbig
that are necessary in the implemen-
tation of power EP. Recall that we denoted by qα\i(xt) :=q(xt)/qα
i(xt)the cavity distribution with respect
to the fractional factor qα
i(xt). In our implementation of power EP, we keep track of the fractional factors
qα
i(xt)instead of the full factors qi(xt). To make this explicit, we adopt the notation ri(xt) :=qα
i(xt)below.
Forward Projection Recall that the forward factor at time step tis given by
f▷(xt) =/integraldisplay
p(xt|xt−1)q\◁(xt−1)dxt−1. (141)
In practice, we compute the cavity distribution q\◁(xt−1)from the fractional factor r◁(xt−1)by taking
q\◁(xt−1) =q(xt−1)/r1/α
◁(xt−1). (142)
Following the arguments in Section 3.4, the message (141) can be approximated by
q▷(xt) =N(xt|Mt−1µ\◁
t−1+vt−1,Mt−1Σ\◁
t−1M⊤
t−1+Q) =N(xt|µ▷
t,Σ▷
t), (143)
whereMt−1andvt−1are a matrix and a vector respectively, obtained by implicit linearisation (Lemma 1).
Thus, we find the following approximation to the fractional forward factor fα
▷(xt):
r▷(xt) =qα
▷(xt)(135)=N(xt|µ▷
t,α−1Σ▷
t). (144)
Measurement Projection As in standard EP, we derive the measurement projection for power EP via
the partition function, which in this case, reads
Z△=/integraldisplay
fα
△(xt)qα\△(xt)dxt=/integraldisplay
N(yt|h(xt),α−1R)qα\△(xt)dxt. (145)
Letqα\△(xt) =N(xt|µα,x\△
t,Σα,x\△
t ). By following the same procedure as in Section 3.4, we obtain the
following approximation to Z△:
˜Z△=N(yt|Jtµα,x\△
t +ut,JtΣα,x\△
tJ⊤
t+α−1R) =N(yt|µα,y\△
t,Σα,y\△
t ), (146)
where as before, we used the implicit linearisation yt=Jtxt+ut+ε. The gradients of this approximate
log partition function can thus be computed explicitly, which can be checked to be
∇µ\△:=d log ˜Z△
dµα,x\△
t= (yt−µα,y\△
t )⊤(Σα,y\△
t )−1Jt, (147)
∇Σ\△:=d log ˜Z△
dΣα,x\△
t=1
2/parenleftig
∇µ\△∇⊤
µ\△−J⊤
t(Σα,y\△
t )−1Jt/parenrightig
. (148)
34Published in Transactions on Machine Learning Research (06/2022)
This gives us the update formulas (i.e., the moments of proj/bracketleftbig
fα
△(xt)qα\△(xt)/bracketrightbig
=N(xt|µ′
t,Σ′
t))
µ′
t=µα,x\△
t +Σα,x\△
t∇⊤
µ\△ (149)
=µα,x\△
t +Σα,x\△
tJt(Σα,y\△
t )−1(yt−µα,y\△
t ) (150)
=µα,x\△
t +Kα
t(yt−µα,y\△
t ) (151)
Σ′
t=Σα,x\△
t−Σα,x\△
t (∇µ\△∇⊤
µ\△−2∇Σ\△)Σα,x\△
t (152)
=Σα,x\△
t−Σα,x\△
tJ⊤
t(Σα,y\△
t )−1JtΣα,x\△
t (153)
=Σα,x\△
t−Kα
tΣα,yx\△
t, (154)
whereKα
t:=Σα,xy\△
t (Σα,y\△
t )−1is the Kalman gain matrix and Σα,xy\△
t :=Σα,x\△
tJ⊤
t.
BackwardProjection Again, weusethederivativesofthelogpartitionfunctiontocomputethebackward
projection proj/bracketleftbig
fα
◁(xt)qα\◁(xt)/bracketrightbig
. The partition function corresponding to this case reads
Z◁=/integraldisplay
fα
◁(xt)qα\◁(xt)dxt=/integraldisplay/parenleftbigg/integraldisplay
p(xt+1|xt)q\▷(xt+1)dxt+1/parenrightbiggα
qα\◁(xt)dxt. (155)
Using (131), we obtain the following useful identity, which allows us to move the power inside the integral
/parenleftbigg/integraldisplay
p(xt+1|xt)q\▷(xt+1)dxt+1/parenrightbiggα
=/parenleftbigg/integraldisplay
N(xt+1|f(xt),Q)q\▷(xt+1)dxt+1/parenrightbiggα
(156)
(131)=/bracketleftig
N(f(xt)|µ\▷
t+1,Q+Σ\▷
t+1)/bracketrightigα
(157)
(135)=N(f(xt)|µ\▷
t+1,α−1Q+α−1Σ\▷
t+1) (158)
(131)=/integraldisplay
p(xt+1|xt)αqα
\▷(xt+1)dxt+1. (159)
Thus, using Fubini’s theorem to switch the order of integrals, we get
Z◁=/integraldisplay/parenleftbigg/integraldisplay
p(xt+1|xt)q\▷(xt+1)dxt+1/parenrightbiggα
qα\◁(xt)dxt (160)
(159)=/integraldisplay/parenleftbigg/integraldisplay
p(xt+1|xt)αqα
\▷(xt+1)dxt+1/parenrightbigg
qα\◁(xt)dxt (161)
Fubini=/integraldisplay/parenleftbigg/integraldisplay
p(xt+1|xt)αqα\◁(xt)dxt/parenrightbigg
qα
\▷(xt+1)dxt+1. (162)
Now, using the implicit linearisation xt+1=Mtxt+vt+ε, we get the following approximation to Z◁:
˜Z◁=/integraldisplay
N(xt+1|Mtµα\◁
t+vt/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
=:µα,▷
t+1,MtΣα\◁
tM⊤
t+α−1Q/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
=:Σα,▷
t+1)qα
\▷(xt+1)dxt+1 (163)
(131)=N(µ\▷
t+1|µα,▷
t+1,Σα,▷
t+1+α−1Σ\▷
t+1). (164)
This gives us the following expressions for the gradients:
∇µ\◁:=d log ˜Z◁
dµα,x\△
t= (µ\▷
t+1−µα,▷
t+1)⊤(Σα,▷
t+1+α−1Σ\▷
t+1)−1Mt, (165)
∇Σ\◁:=d log ˜Z◁
dΣα,x\△
t=1
2/parenleftig
∇µ\◁∇⊤
µ\◁−M⊤
t(Σα,▷
t+1+α−1Σ\▷
t+1)−1Mt/parenrightig
. (166)
35Published in Transactions on Machine Learning Research (06/2022)
Now setqα,▷(xt+1) :=N(xt+1|µα,▷
t+1,Σα,▷
t+1)and define ˜q(xt+1) :=qα,▷(xt+1)qα
\▷(xt+1), whose mean and
covariance we denote by ˜µt+1and˜Σt+1respectively. In the case α= 1, the distribution ˜qcan be checked to
be equivalent to the marginal q(xt+1). Since we have Mt=Σα,▷
t,t+1(Σα\◁
t)−1(follows from (19)), the update
formulas for backward messages (i.e., moments of proj/bracketleftbig
fα
◁(xt)qα\◁(xt)/bracketrightbig
=N(xt|µ′
t,Σ′
t)) can be checked
to be
µ′
t=µα\◁
t+Σα\◁
tM⊤
t(Σα,▷
t+1+α−1Σ\▷
t+1)−1(µ\▷
t+1−µα,▷
t+1) (167)
=µα\◁
t+Lα
t(˜µt+1−µα,▷
t+1) (168)
Σ′
t=Σα\◁
t−Σα\◁
tM⊤
t(Σα,▷
t+1+α−1Σ\▷
t+1)−1MtΣα\◁
t (169)
=Σα\◁
t+ (Lα
t)⊤(˜Σt+1−Σα,▷
t+1)−1Lα
t, (170)
whereLα
t=Σα,▷
t,t+1(Σα,▷
t+1)−1is the smoother gain. This can be checked in a similar way that we derived the
standard RTS smoother update equations from the derivative-based backward EP updates in Section 3.4.
C Appendix: Additional Figures
10 20 30 40 50
EP Iterations4.04.55.05.56.0RMSEEP (=1.0,=1.0)
EP with damping (=1.0,=0.9)
Power EP with damping (=0.9,=0.9)
10 20 30 40 50
EP Iterations2.53.03.54.04.5NLLEP (=1.0,=1.0)
EP with damping (=1.0,=0.9)
Power EP with damping (=0.9,=0.9)
Figure 10: RMSE and NLL for EP (red), damped EP (green), and damped power EP (grey) for the UNGM
experiment. The Monte Carlo transform (MCT) is used as the linearisation method here. Damping and
power improves the performance significantly and reduces the oscillation seen in the NLL for standard EP.
10 20 30 40 50
EP Iterations89101112RMSEEP (=1.0,=1.0)
EP with damping (=1.0,=0.9)
Power EP with damping (=0.9,=0.9)
10 20 30 40 50
EP Iterations50100150200250300NLLEP (=1.0,=1.0)
EP with damping (=1.0,=0.9)
Power EP with damping (=0.9,=0.9)
Figure 11: RMSE and NLL for EP (red), damped EP (green), and damped power EP (grey) for the UNGM
experiment. The Taylor transform (TT) is used as the linearisation method here. Both damped EP and
damped power EP reduce the oscillations seen in EP for the RMSE, with damped power EP even improving
the performance. However, this is not reflected in the NLL, where power appears to degrade performance.
36Published in Transactions on Machine Learning Research (06/2022)
100 200 300 400 500
EP Iterations0.5
0.00.51.01.52.0RMSE1e3 Power: 1.0, Damping: 0.1
100 200 300 400 500
EP Iterations4
2
02468NLL1e11 Power: 1.0, Damping: 0.1
Figure 12: RMSE and NLL performance over multiple runs of the UNGM experiment, recorded for 500
iterations. We only consider the corner case ( α= 1.0,γ= 0.1) and used the Taylor transform (TT) for
linearisation. The solid lines show the mean across ten different seeds and the shaded areas indicate the
standard deviation. Initially, both the RMSE and NLL increase rapidly for a couple of iterations. However,
they peak at around 25–30 iterations before starting to decrease. Eventually, they converge to good values
after around 200 iterations for the RMSE and 100 iterations for the NLL.
10 20 30 40 50253035RMSEPower: 1.0, Damping: 1.0
MCT
10 20 30 40 50253035Power: 1.0, Damping: 0.8
MCT
10 20 30 40 50253035Power: 0.8, Damping: 1.0
MCT
10 20 30 40 50
EP Iterations1020NLLMCT
10 20 30 40 50
EP Iterations1020MCT
10 20 30 40 50
EP Iterations1020MCT
Figure 13: RMSE and NLL performance of the bearings-only turning target tracking problem, averaged over
allvariables(position, velocity, angularvelocity). TheMCTisusedforlinearisation. Solidlineshowsaverage
performance across 10 random seeds and shaded regions indicate standard deviation. Dashed line shows the
result of the Monte Carlo Kalman smoother. The NLL is highly oscillatory when α= 1.0. Damping does
little to reduce this oscillation, however it is easily controlled by setting α= 0.8.
37Published in Transactions on Machine Learning Research (06/2022)
0 25
Time0
25
50
75
100
125
150
175Components
5
051015
(a) Ground truth (a simulation of the
Lorenz 96 model with d= 200).
0 25
Time0
25
50
75
100
125
150
175
0 25
Time0
25
50
75
100
125
150
175
0.00.51.01.52.02.5(b) Absolute errors for the predictions ( |xGT−xpred|).
The left panel displays the result from the UKS. The right
panel displays the result of EP after 10iterations.
Figure 14: Hovmöller diagram depicting the time-evolution of each component in the Lorenz 96 system with
200dimensions. In (a), we display the ground truth trajectory of a single simulation of the Lorenz 96 model.
In (b), we display the absolute errors for the predictions made by the Unscented Kalman smoother (left) vs
approximate EP after 10iterations (right). We used the UT for the linearisation method in approximate
EP. We see overall improvements in prediction quality by iterating EP.
38