Under review as submission to TMLR
Meta-learning for Positive-unlabeled Classiﬁcation
Anonymous authors
Paper under double-blind review
Abstract
We propose a meta-learning method for positive and unlabeled (PU) classiﬁcation, which
improves the performance of binary classiﬁers obtained from only PU data in unseen target
tasks. PU learning is an important problem since PU data naturally arise in real-world ap-
plications such as outlier detection and information retrieval. Existing PU learning methods
require many PU data, but suﬃcient data are often unavailable in practice. The proposed
method minimizes the test classiﬁcation risk after the model is adapted to PU data by us-
ing related tasks that consist of positive, negative, and unlabeled data. We formulate the
adaptation as an estimation problem of the Bayes optimal classiﬁer, which is an optimal
classiﬁer to minimize the classiﬁcation risk. The proposed method embeds each instance
into a task-speciﬁc space using neural networks. With the embedded PU data, the Bayes
optimal classiﬁer is estimated through density-ratio estimation of PU densities, whose solu-
tion is obtained as a closed-form solution. The closed-form solution enables us to eﬃciently
and eﬀectively minimize the test classiﬁcation risk. We empirically show that the proposed
method outperforms existing methods with one synthetic and three real-world datasets.
1 Introduction
Positive and unlabeled (PU) learning addresses a problem of learning a binary classiﬁer from only PU data
without negative data (Bekker & Davis, 2020; Elkan & Noto, 2008; Liu et al., 2003). It has attracted
attention since PU data naturally arise in many real-world applications. For example, in outlier detection,
only normal (positive) and unlabeled data are often available since anomalous (negative) data are diﬃcult to
collect due to their rarity. In information retrieval for images, a user selects a set of favorite images (positive
data) to automatically discover relevant photos in the user’s photo album (unlabeled data). In addition to
these, PU learning can be applied to many other applications such as medical diagnosis (Zuluaga et al.,
2011), personalized advertising (Hsieh et al., 2015), drug discovery (Liu et al., 2017), text classiﬁcation (Li
& Liu, 2003), and remote sensing (Li et al., 2010).
Although PU learning is attractive, it requires a large amount of PU data to learn accurate classiﬁers.
In some real-world applications, enough data might be unavailable. For example, when we want to build
personalized outlier detectors with user activity data (Hu et al., 2017; Alowais & Soon, 2012), suﬃcient
normal data are unlikely to have been accumulated from new users. In image retrieval, users might select
only a small number of favorite images. To improve performance on target tasks with limited data, meta-
learning has recently been receiving a lot of attention because it learns how to learn from limited data
by using labeled data on diﬀerent but related tasks (source tasks) (Hospedales et al., 2021). In the above
examples, for outlier detection, both normal and anomalous data might be available from other users who
have existed for a long time. In image retrieval, some users might tag unfavorite photos as well as favorite
ones.1By meta-learning, we can quickly adapt to unseen tasks (e.g., users). Although many meta-learning
methods have been proposed and have performed well on various problems (Hospedales et al., 2021), they
are not designed for PU learning from limited PU data.
In this paper, we propose a meta-learning method for PU classiﬁcation, which meta-learns with multiple
source tasks that consist of positive, negative, and unlabeled data, and uses the learned knowledge to obtain
1We discuss other potential applications of the proposed method in Section E of the appendix.
1Under review as submission to TMLR
classiﬁers on unseen target tasks that consist of only PU data. In each meta-learning step, our model is
adapted to given task-speciﬁc PU data, called a support set. Then, common parameters shared across all
tasks are meta-learned to minimize the test classiﬁcation risk (the expected test misclassiﬁcation rate) when
the adapted model is used. This training procedure enables our model to learn how to learn from PU data.
More speciﬁcally, the adaptation to the support set corresponds to estimating a Bayes optimal classiﬁer ,
which is an optimal classiﬁer to minimize the classiﬁcation risk. To estimate this with the support set,
we use the fact that the Bayes optimal classiﬁer can be represented by two components: a density-ratio
between PU densities and a positive class-prior. With the proposed method, the density-ratio is modeled
by using neural networks that have high expressive capabilities. To eﬀectively adapt to a wide variety of
tasks, task-speciﬁc density-ratio models need to be constructed. To this end, the proposed method ﬁrst
calculates task representation vectors of the support set by permutation-invariant neural networks that can
take a set of instances as input (Zaheer et al., 2017). With the task representations, each instance can be
non-linearly embedded into a task-speciﬁc space by other neural networks. The proposed method performs
density-ratio estimation by using the embedded support set, and its solution is obtained as a closed-form
solution. By using the estimated density-ratio, the positive class-prior can also be quickly estimated. As a
result, the proposed method can eﬃciently and eﬀectively estimate the Bayes optimal classiﬁer by using only
the closed-form solution of the density-ratio estimation. This eﬃcient and eﬀective adaptation is a major
strength of our proposed model since meta-learning usually takes high computation costs (Bertinetto et al.,
2018; Lee et al., 2019b).
We meta-learn all the neural networks such that the test classiﬁcation risk, which is directly calculated with
positive and negative data, is minimized when the estimated Bayes optimal classiﬁer is used. All parameters
of the neural networks are common parameters shared among all tasks. Since the closed-form solution of
the density-ratio estimation is diﬀerentiable, we can solve the whole optimization problem by a stochastic
gradient descent method. By minimizing the classiﬁcation risk on various tasks, we can learn accurate
classiﬁers for unseen target tasks from only target PU data.
Our main contributions are summarized as follows:
•To the best of our knowledge, our work is the ﬁrst attempt at meta-learning for positive-unlabeled
classiﬁcation with a few PU data.
•We propose an eﬃcient and eﬀective meta-learning method that estimates the task-speciﬁc Bayes
optimal classiﬁer using only the closed-form solution of the density-ratio estimation.
•We empirically show that the proposed method outperformed existing PU learning methods and
their meta-learning variants when there is insuﬃcient PU data in both synthetic and real-world
datasets.
2 Related Work
Many PU learning methods have been proposed (Bekker & Davis, 2020; Fung et al., 2005; Hou et al., 2018;
Chen et al., 2020a; Luo et al., 2021; Zhao et al., 2022; Wang et al., 2023). Early methods used some heuristics
to identify negative instances in unlabeled data (Li & Liu, 2003; Liu et al., 2003; Yu et al., 2002). However,
the performances of these methods heavily rely on the heuristic strategy and data separability assumption,
i.e., positive and negative distributions are separated (Nakajima & Sugiyama, 2023). Recently, state-of-
the art performances have been achieved by empirical risk minimization-based methods, which rewrite the
classiﬁcation risk with PU data and learn classiﬁers by minimizing the risk (Du Plessis et al., 2015; Kiryo
et al., 2017; Du Plessis et al., 2014). Unlike the heuristic approach, they can build statistically-consistent
classiﬁers (Du Plessis et al., 2015; Kiryo et al., 2017; Du Plessis et al., 2014). A few methods use density-ratio
estimation for obtaining the Bayes optimal classiﬁer, which minimizes the classiﬁcation risk, and have shown
excellent performance (Charoenphakdee & Sugiyama, 2019; Nakajima & Sugiyama, 2023). The proposed
method also uses the density-ratio estimation-based approach for the support set adaptation since it enables
us to obtain the closed-form solution, which is vital for eﬃcient and eﬀective meta-learning as described
2Under review as submission to TMLR
later. Although the empirical risk minimization-based methods are useful, they require the class-prior
probability information. In real-world applications, it is diﬃcult to know the class-prior without negative
data in advance. Thus, the class-prior needs to be estimated from only PU data. However, the class-
prior estimation with PU data is known as an ill-posed problem (Blanchard et al., 2010; Scott, 2015).
To overcome this, the irreducible assumption is commonly used, which states the support of the positive-
conditional distribution is not contained in the support of the negative-conditional distribution (Yao et al.,
2021; Ivanov, 2020; Ramaswamy et al., 2016; Blanchard et al., 2010; Scott, 2015). The proposed method also
uses this assumption and estimates the class-prior on the basis of the estimated density-ratio. Unlike the
proposed method, all these PU learning methods are designed for one task and cannot use data in related
tasks.
PNU learning uses positive, negative, and unlabeled (PNU) data in a task to learn binary classiﬁers (Sakai
et al., 2017; Hsieh et al., 2019; Sakai et al., 2018). Especially, (Sakai et al., 2017) uses the technique of PU
learning to rewrite the classiﬁcation risk with PNU data, which enables us to learn binary classiﬁers without
particular distributional assumptions such as the cluster assumption (Grandvalet & Bengio, 2004). Unlike
the proposed method, these methods cannot use data in source tasks and require negative data in the target
tasks.
Some studies use PU learning for domain adaptation, which learns classiﬁers that ﬁt on a target task by
using data in a source task (Sonntag et al., 2022; Loghmani et al., 2020; Sakai & Shimizu, 2019; Hammoudeh
& Lowd, 2020). These all methods treat only two tasks (source and target tasks) and require both target
and source data in the training phase. In contrast, the proposed method can treat multiple tasks and does
not require any target data in the (meta-)training phase, which is preferable when new target tasks appear
one after another. In addition, these methods are designed for the setting where class labels are the same in
source and target tasks (domains) although the proposed method can treat tasks that have diﬀerent class
labels.
Meta-learning methods train a model such that it generalizes well after adapting to a few data by using data
on multiple tasks (Finn et al., 2017; Snell et al., 2017; Garnelo et al., 2018; Rajeswaran et al., 2019; Iwata
& Kumagai, 2020; Jiang et al., 2022). Although many meta-learning methods have been proposed, to our
knowledge, no meta-leaning methods have been designed for PU learning from a few PU data. Although one
method in (Chen et al., 2020b) uses a technique of the meta-learning for weighting unlabeled data in PU
learning, it cannot treat source tasks and is not designed for learning from a few PU data. A representative
method for meta-learning is model-agnostic meta-learning (MAML) (Finn et al., 2017), which adapts to
support data by using an iterative gradient method. It requires second-order derivatives of the parameters
of whole neural networks and needs to retain all computation graphs of the iterative adaptation during
meta-training, which imposes considerable computational and memory burdens (Bertinetto et al., 2018).
The proposed method is more eﬃcient than MAML since it adapts to support data by using only a closed-
formsolutionofthedensity-ratioestimation. Althoughsomemethodsformulatetheadaptationastheconvex
optimization problem for eﬃcient meta-learning, almost all methods consider ordinary classiﬁcation tasks
(Bertinetto et al., 2018; Lee et al., 2019b). A meta-learning method for the relative density-ratio estimation
has been proposed (Kumagai et al., 2021). Although this method estimates relative density-ratio from a
few data by using multiple unlabeled datasets, it cannot estimate classiﬁers from PU data. In contrast, the
proposed method can estimate the classiﬁer by sequentially estimating the density-ratio of PU data and the
positive class-prior in the support set adaptation.
3 Preliminary
We brieﬂy explain the concept of PU learning based on density-ratio estimation. Let X∈RDandY∈{± 1}
be the input and output random variables, where Dis the dimensionality of the input variable. Let p(x,y)
be the joint density of (X,Y ),pp(x) =p(x|Y= +1)andpn(x) =p(x|Y=−1)be the positive and negative
class-conditional densities, p(x) =πppp(x)+(1−πp)pn(x)be the input marginal density, and πp=p(Y= 1)
be the positive class-prior probability. s:RD→{± 1}is a binary classiﬁer and l01:R×{± 1}→Ris the
zero-one loss, l01(t,y) = (1−sign(ty))/2, where sign(·)is a sign function; sign(U) = 1ifU≥0and
sign(U) =−1otherwise. PU learning aims to learn binary classiﬁer sfrom only PU data, which minimizes
3Under review as submission to TMLR
the classiﬁcation risk:
Rpn(s) =E(X,Y)∼p(x,y)[l01(s(X),Y)] =πpEX∼pp[l01(s(X),+1)] + (1−πp)EX∼pn[l01(s(X),−1)],(1)
where Edenotes an expectation. It is known that the optimal solution for Rpn(s)can be written as
s∗(x) = sign(p(Y= 1|x)−0.5) = sign/parenleftbigg
πppp(x)
p(x)−0.5/parenrightbigg
, (2)
where Bayes’ theorem is used in the second equality (Charoenphakdee & Sugiyama, 2019; Nakajima &
Sugiyama, 2023). This solution is called the Bayes optimal classiﬁer. Since density-ratio r(x) =pp(x)
p(x)
depends on only PU densities, we can estimate s∗(x)with only PU data through the density-ratio estimation
when class-prior πpis known.
4 Proposed Method
In this section, we explain the proposed method. This section is organized as follows: In Section 4.1, we
present our problem formulation. In Section 4.2, we present our model to estimate the Bayes optimal
classiﬁer given PU data. Our model consists of task representation calculation, density-ratio estimation, and
class-prior estimation. In Section 4.3, we explain our meta-learning procedure to train our model. Figure 1
shows the overview of our meta-learning procedure.
4.1 Problem Formulation
LetDp
t:={xp
tn}Np
t
n=1∼pp
tbe a set of positive instances in the t-th task, where xp
tn∈RDis theD-dimensional
feature vector of the n-th positive instance of the t-th task,Np
tis the number of the positive instances in
thet-th task, and pp
tis the positive density of the t-th task. Similarly, let Dn
t:={xn
tn}Nn
t
n=1∼pn
tand
Du
t:={xu
tn}Nu
t
n=1∼pt=πp
tpp
t+ (1−πp
t)pn
tbe negative and unlabeled instances of the t-th task, respectively,
whereπp
tis a positive class-prior of the t-th task. In the meta-training phase, we are given Tsource tasks
D:={Dp
t∪Dn
t∪Du
t}T
t=1. We assume that feature vector size Dis the same across all tasks, and all tasks
are drawn from the same task distribution although joint distribution pt(x,y)can vary across tasks. These
assumptions are common in meta-learning studies (Finn et al., 2017; Snell et al., 2017; Garnelo et al., 2018;
Rajeswaran et al., 2019; Kumagai et al., 2023; Farid & Majumdar, 2021). Since pt(x,y)can diﬀer across
tasks, we cannot directly use labeled data in source tasks to learn classiﬁers in target tasks. In the test
phase, we are given PU data (support set) in a target task S=Sp∪Su={xp
n}Np
n=1∪{xu
n}Nu
n=1, which is
diﬀerent from source tasks. Our aim is to learn a binary classiﬁer that minimizes the test classiﬁcation risk
on the target task to accurately classify any test instance xdrawn from the same distribution as unlabeled
support dataSu.
4.2 Model
In this section, we explain how to estimate the task-speciﬁc Bayes optimal classiﬁer given support set S. We
omit task index tfor simplicity since all procedures are conducted in a task in this section.
4.2.1 Task Representation Calculation
First, we explain how to obtain a vector representation of the given dataset, which is used for obtaining
task-speciﬁc instance embeddings appropriate for the task. Speciﬁcally, the proposed method calculates
M-dimensional task representation vectors, zpandzu, of the support set Susing the following permutation-
invariant neural networks (Zaheer et al., 2017):
zp=g/parenleftBigg
1
NpNp/summationdisplay
n=1f(xp
n)/parenrightBigg
,zu=g/parenleftBigg
1
NuNu/summationdisplay
n=1f(xu
n)/parenrightBigg
, (3)
4Under review as submission to TMLR
Source task 1
Source task t
Source task T……PU data
PN dataNNs
(f,g)zp
zuEmbedded
PU data
Embedded
PN data4) Density-
ratio 
estimation
5) Class-
prior 
estimation6) Classifier 
estimationr*
2) Task rep. calculation3) Instance embedding
*s*
7) Loss 
calculation1) SamplingSupport set
Query setp NN
(h)
Loss
Figure 1: Our meta-learning procedure: (1) For each training iteration, we randomly sample PU data
(support set) and positive and negative (PN) data (query set) from a randomly selected source task. (2)
Task representation vectors, zpandzu, are calculated from positive and unlabeled support data, respectively,
by using the permutation-invariant neural networks (Section 4.2.1). (3) With zpandzu, all instances are
embedded into a task-speciﬁc space by using a neural network. (4) By using the embedded support set,
density-ratio estimation is performed and its closed-form solution ˆr∗is obtained (Section 4.2.2). (5) By
using ˆr∗and the embedded support set, positive class-prior ˆπp
∗is estimated (Section 4.2.3). (6) By using ˆr∗
andˆπp
∗, the estimated Bayes optimal classiﬁer s∗is obtained (Section 4.2.3). (7) Test classiﬁcation risk (loss)
is calculated with the query set and the estimated Bayes optimal classiﬁer, and it can be backpropagated to
update all the neural networks (Section 4.3).
wherefandgare any feed-forward neural network. Since summation is permutation-invariant, the neural
network in Eq. (3) outputs the same vector even when the order of instances varies. In addition, this neural
network can handle diﬀerent numbers of instances. Thus, this neural network can be used as functions for
set inputs. Task representation vectors zpandzucontain information of the PU data. The proposed method
uses the task representation vectors to obtain task-speciﬁc instance embeddings to deal with the diversity of
tasks. The proposed method can use any other permutation-invariant function such as summation (Zaheer
et al., 2017) and set transformer (Lee et al., 2019a) to obtain task representation vectors.
4.2.2 Density-ratio Estimation
Next, we explain how to estimate density-ratio r(x) =pp(x)
p(x)withzpandzu. A naive approach is to estimate
each density and then take the ratio. However, it does not work well since density estimation is known as a
diﬃcult problem and taking the ratio of the two estimations can increase the error (Vapnik, 1999; Sugiyama
et al., 2012). Instead, direct density-ratio estimation without going through density estimation has become
the standard approach (Kanamori et al., 2009; Sugiyama et al., 2012; Yamada et al., 2013). In particular,
neural networks have been recently used for modeling the density-ratio due to their high ﬂexibility and
expressibility (Rhodes et al., 2020; Kato & Teshima, 2021). Following this, our method directly models the
density-ratio r(x) =pp(x)
p(x)by the following neural network,
ˆr(x;S) =w/latticetoph([x,zp,zu]), (4)
where [·,·,·]is a concatenation, h:RD+2K→RM
>0is a feed-forward neural network for instance embedding,
andw∈RM
≥0is linear weights. Since both the outputs of handware non-negative, the estimated density-
ratio is also non-negative. h([x,zp,zu])depends on both zpandzu, and thus, h([x,zp,zu])represents the
task-speciﬁc embedding of instance x. Liner weights wand parameters of all neural networks f,g, and
hare task-speciﬁc and task-shared parameters, respectively. Task-shared parameters are meta-learned to
5Under review as submission to TMLR
improve the expected test performance, which is explained in Section 4.3. Only task-speciﬁc parameters w
are adapted to given support set S, which enables us to estimate the density-ratio as a closed-form solution.
Linear weights ware determined so that the following expected squared error between the true density-ratio
r(x)and estimated density-ratio ˆr(x;S)is minimized:
J(w) =1
2EX∼p/bracketleftBig
(r(X)−ˆr(X;S))2/bracketrightBig
=1
2EX∼p/bracketleftbig
ˆr(X;S)2/bracketrightbig
−EX∼pp[ˆr(X;S)] + Const., (5)
where Const.is a constant term that does not depend on our model. By approximating the expectation
with support set Sand excluding the non-negative constraints of w, we obtain the following optimization
problem:
˜w= arg min
w∈RM/bracketleftbigg1
2w/latticetopKw−k/latticetopw+λ
2w/latticetopw/bracketrightbigg
, (6)
where k=1
Np/summationtextNp
n=1h([xp
n,zp,zu]),K=1
Nu/summationtextNu
n=1h([xu
n,zp,zu])h([xu
n,zp,zu])/latticetop, the third term of r.h.s. of
Eq. (6) is the /lscript2-regularizer to prevent over-ﬁtting, and λ >0is a positive constant. The global optimum
solution for Eq. (6) can be obtained as the following closed-form solution:
˜w= (K+λI)−1k, (7)
where Iis theMdimensional identity matrix. This closed-form solution can be eﬃciently obtained when M
is not large. We note that (K+λI)−1exists since λ>0makes (K+λI)positive-deﬁnite. Since we omitted
the non-negative constraints of win Eq. (6), some learned weights ˜wcan be negative. To compensate
for this, following previous studies (Kanamori et al., 2009), the solution is modiﬁed as ˆw= max( 0,˜w),
where maxoperator is applied in an element-wise manner. By using the learned weights, the density-ratio
estimated with support set Sis obtained as
ˆr∗(x;S) =ˆw/latticetoph([x,zp,zu]). (8)
4.2.3 Class-prior Estimation
We explain how to estimate class-prior πpfromSby using estimated density-ratio ˆr∗(x;S). To view the
relationship between the density-ratio and the class-prior, we ﬁrst consider the following equation as in
(Blanchard et al., 2010; Scott, 2015):
1
r(x)=p(x)
pp(x)=πppp(x) + (1−πp)pn(x)
pp(x)=πp+ (1−πp)pn(x)
pp(x), (9)
where x∈{x/prime|pp(x/prime)>0}. Sincepn(x)
pp(x)is non-negative, this equation implies
inf
x;pp(x)>01
r(x)≥πp. (10)
When we can assume that the support of ppis not contained in the support of pn, i.e.,{x|(pp(x)>0)∧
(pn(x) = 0)}/negationslash=∅, the above equality holds; infx;pp(x)>01
r(x)=πp. This assumption is called the irreducible
assumption and is widely used in PU learning studies (Yao et al., 2021; Ivanov, 2020; Ramaswamy et al.,
2016; Blanchard et al., 2010; Scott, 2015). By using Eqs. (10) and (8), our method estimates class-prior πp
with support set Sas
˜πp
∗(S) = min
x∈S1
ˆr∗(x;S)=1
maxx∈Sˆr∗(x;S). (11)
We used the max operator for Sinstead ofSp. This is because Scontains instances drawn from ppand
even ifpp(x/prime) = 0,x/primedoes not give the maximum value due to r(x/prime) = 0. We note that the max operator is
often used in neural networks such as max pooling (Nagi et al., 2011). Further, since πp≤1, the estimated
6Under review as submission to TMLR
prior is modiﬁed as ˆπp
∗(S) = min(˜πp
∗(S), 1). As a result, by using Eqs. (2), (8), and (11), the Bayes optimal
classiﬁer estimated from support set Sis obtained as
s∗(x;S) = sign (ˆπp
∗(S)ˆr∗(x;S)−0.5). (12)
Our formulation is based on only density-ratio estimation, whose solution is easily obtained as the closed-
form solution. Thus, it can perform fast and eﬀective adaptation. We note that estimating the Bayes
optimal classiﬁer, including the task representation calculation, the density-ratio estimation, and the class-
prior estimation, requires only PU data. Therefore, our model can be applied to target tasks that have only
PU data.
4.3 Meta-training
We explain the training procedure for our model. In this subsection, we use notation Sas a support set in
source tasks. The common parameters to be meta-learned Θare parameters of neural networks f,g, andh,
and regularization parameters λ. In the meta-learning, we want to minimize the test classiﬁcation risk when
the Bayes optimal classiﬁer adapted to support set Sis used:
min
ΘEt∼{1,...,T}E(S,Q)∼Dt[Rpn(Θ,Q;S)], (13)
whereQ=Qp∪Qnis a query set, where Qpis a set of positive instances and Qnis a set of negative instances
drawn from the same task as support set S, and
Rpn(Θ,Q;S) =πp
Q
|Qp|/summationdisplay
x∈Qpl01(s∗(x;S,Θ),+1) +1−πp
Q
|Qn|/summationdisplay
x∈Qnl01(s∗(x;S,Θ),−1), (14)
whereπp
Q=|Qp|
|Qp|+|Qn|, ands∗(x;S,Θ)is the Bayes optimal classiﬁer estimated with support set Sin Eq.
(12). Here, we explicitly describe the dependency of common parameter Θfor clarity. To simulate test
environments, we sample query set Qso that the ratio of positive instances in the query set matches that
of the original dataset, i.e., πp
Q=|Qp|
|Qp|+|Qn|=|Dp
t|
|Dp
t|+|Dn
t|. Since the gradient of the zero-one loss is zero
everywhere except for the origin, gradient descent methods cannot be used. To avoid this, surrogate losses
of the zero-one loss (e.g., the sigmoid function) are usually used (Kiryo et al., 2017; Du Plessis et al., 2015;
Nakajima & Sugiyama, 2023). Following this, we use the following smoothed risk for training:
/tildewidestRpn(Θ,Q;S) =πp
Q
|Qp|/summationdisplay
x∈Qpστ(−u∗(x;S,Θ)) +1−πp
Q
|Qn|/summationdisplay
x∈Qnστ(u∗(x;S,Θ)), (15)
whereu∗(x;S,Θ) = ˆπ∗
p(S)·ˆr∗(x;S)−0.5andστ(U) =1
1+exp(−τ·U)is the sigmoid function with scaling
parameterτ > 0. We can accurately approximate the zero-one loss as τincreases. In our experiments,
we setτ= 10. Sinceu∗(x;S,Θ)is easily obtained on the basis of the closed-form solution of the density-
ratio, the risk in Eq. (13) is eﬃciently calculated. In addition, the risk is diﬀerentiable since u∗(x;S,Θ)
is diﬀerentiable. Thus, we can solve it by a stochastic gradient descent method. Algorithm 1 shows the
pseudocode for our training procedure. For each iteration, we randomly sample task tfrom source tasks
(Line 2). From positive data Dp
tand unlabeled data Du
t, we randomly sample support set S=Sp∪Su
(Lines 3 – 4). We note that even when there are no unlabeled data in a task, we can sample unlabeled data
from labeled data by hiding label information. From labeled data (Dp
t\Sp)∪Dn
t, we randomly sample query
setQ(Line 5) while maintaining the positive ratio|Dp
t|
|Dp
t|+|Dn
t|. We calculate task representations zpandzu
fromS(Line 6). We estimate density-ratio r(x)and positive class-prior πpfrom support set Sto obtain
the Bayes optimal classiﬁer (Lines 7 – 8). By using the estimated Bayes optimal classiﬁer, we calculate the
test classiﬁcation risk on query set Q,/tildewidestRpn(Θ,Q;S)(Line 9). Lastly, the common parameters of our model
Θare updated with the gradient of /tildewidestRpn(Θ,Q;S)(Line 10). After meta-learning, given a few PU data S
in a target task, we can obtain the target task-speciﬁc Bayes optimal classiﬁer by running lines 6 to 8 in
Algorithm 1 with S. Since our model is meta-learned to accurately estimate Bayes optimal classiﬁers from
a few PU data on multiple source tasks, we can expect it to generalize for the target task.
7Under review as submission to TMLR
Algorithm 1 Training procedure of our model.
Require: Datasets in source tasks D, positive support set size Np
S, unlabeled support set size Nu
S, and query
set sizeNQ
Ensure: Common parameters of our model Θ
1:repeat
2:Randomly sample task tfrom{1,...,T}
3:Randomly sample positive support set Spwith sizeNp
SfromDp
t
4:Randomly sample unlabeled support set Suwith sizeNu
SfromDu
t
5:Randomly sample query set Qwith sizeNQfrom (Dp
t\Sp)∪Dn
twhile maintaining the positive ratio
of taskt
6:Calculate task representations zpandzufromSpandSu, respectively by Eq. (3)
7:Calculate linear weights ˜wfromSby (7) to obtain Eq. (8)
8:Calculate positive class-prior ˜πpfromSby (11)
9:Calculate the empirical test classiﬁcation risk /tildewidestRpn(Θ,Q;S)by Eq. (15)
10:Update common parameters Θwith the gradients of /tildewidestRpn(Θ,Q;S)
11:untilEnd condition is satisﬁed;
5 Experiments
5.1 Data
We evaluated the proposed method with one synthetic and three real-world datasets: Mnist-r, Isolet, and
IoT. We used these real-world datasets since they have been commonly used in meta-learning and domain
adaptation studies (Kumagai et al., 2019; 2021; 2023; Ghifary et al., 2015; Mahajan et al., 2021). The
synthetic dataset has 140 tasks, where each task was created on the basis of Gaussian mixture and half
moon data (Wiebe et al., 2015). Gaussian mixture consists of data drawn from a two-dimensional Gaussian
mixture model, in which positive and negative distributions were N(x|(−1.5,0),I2), andN(x|(1.5,0),I2),
respectively. Half moon consists of two crescent-shaped clusters of data with Gaussian noises with 0.4
variance. Each cluster corresponds to a positive or negative class. To create the t-th task, we generated data
from a randomly selected Gaussian mixture or half moon and then rotated the generated data by 2πt−1
180
rad around the origin. The class-prior of each task is described later. We randomly selected 100 source,
20 validation, and 20 target tasks. Mnist-r is created from Mnist dataset by rotating the images (Ghifary
et al., 2015). This dataset has six domains (six rotating angles) with 10class (digit) labels. Each class of
each domain has 100instances and its feature dimension is 256. Isolet consists of 26letters (classes) spoken
by150speakers, and speakers are grouped into ﬁve groups (domains) by speaking similarity (Fanty & Cole,
1990). Each instance is represented as a 617-dimensional vector. IoT is real network traﬃc data for outlier
detection, which are generated from nine IoT devices (domains) infected by malware (Meidan et al., 2018).
Each instance is represented by a 115-dimensional vector. For each domain, we randomly used 2000normal
and2000malicious instances. We normalized each instance by /lscript2normalization.
We explain how to create binary classiﬁcation tasks from each real-world dataset. We used the task construc-
tion procedure similar to the previous meta-learning study (Kumagai et al., 2023). Speciﬁcally, for Mnist-r,
we ﬁrst randomly split all six domains into three groups: four, one, and one domains. Then, we created a
binary classiﬁcation task by regarding one class in a group as positive and the others in the same group as
negative. We used multiple classes for negative data since negative data are often diverse in practice (Hsieh
et al., 2019). By changing positive classes, we created 80 source, 20 validation, and 10 target tasks. We note
that there is no data overlap between source, validation, and target tasks, and creating multiple tasks from
the same dataset is a standard procedure in meta-learning studies (Kumagai et al., 2019; 2021; 2023; Finn
et al., 2017; Snell et al., 2017). For Isolet, we ﬁrst split all ﬁve domains into three, one, and one. Then,
by using the same procedure for Mnist-r, we created 78 source, 26 validation, and 26 target tasks. Since
there are signiﬁcant task diﬀerences in each dataset (e.g., positive data in a task can be negative in other
tasks), task-speciﬁc classiﬁers are required. For IoT, we directly split all nine domains into six source, two
validation, and one target tasks.
8Under review as submission to TMLR
For each source/validation task, the positive class-prior was uniformly randomly selected from
{0.2,0.4,0.6,0.8}. The number of data in each source/validation task of Synthetic, Mnist-r, Isolet, and
IoT were 300, 120, 75, and 625, respectively. For each task, we treated half of the data as labeled data and
the other half as unlabeled data. In each target task, we used 30 support instances (i.e., Np
S+Nu
S= 30). We
randomly created ﬁve diﬀerent source/validation/target task splits for each dataset and evaluated mean test
accuracy (1 - classiﬁcation risk) on target tasks by changing the positive support set size Np
Swithin{1,3,5}
and the positive class-prior within {0.2,0.4,0.6,0.8}of target unlabeled/test data.
5.2 Comparison Methods
Wecomparedtheproposedmethodwiththefollowingninemethods: density-ratio-basedPUlearningmethod
(DRE) (Charoenphakdee & Sugiyama, 2019), non-negative density-ratio-based PU learning method (DRPU)
(Nakajima & Sugiyama, 2023), unbiased PU learning method (uPU) (Du Plessis et al., 2015), non-negative
PU learning method (nnPU) (Kiryo et al., 2017), naive positive and negative learning method (Naive),
three MAML-based PU leaning methods (MDRE, MDRPU, and MnnPU), and neural process-based PU
learning method (NP). All comparison methods except for the proposed method use true positive class-prior
information of target tasks.
DRE, DRPU, uPU, nnPU, and Naive use only target PU data for training. We evaluated these methods to
investigate the eﬀectiveness of using source data. If these methods outperform the proposed method, there
is no need to perform meta-learning in the ﬁrst place. Therefore, it is important to include these methods
in comparison. DRE estimates the Bayes optimal classiﬁer on the basis of a density-ratio estimation like the
proposed method. To estimate the density-ratio, it minimizes the squared error between the true density-
ratio and a RBF kernel model (Kanamori et al., 2009). DRPU is a density-ratio-based PU learning method
with neural networks with a non-negative Bregman divergence estimator. Speciﬁcally, it minimizes the
non-negative squared error, which is a modiﬁed squared error suitable for complex models such as neural
networks. uPU is an unbiased PU learning method based on empirical risk minimization with the RBF kernel
model. nnPU is a neural network-based PU learning method that minimizes the non-negative classiﬁcation
risk. Naive learns a neural network-based binary classiﬁer by regarding unlabeled data as negative data.
MDRE, MDRPU, and MnnPU are neural network-based meta-learning extensions of DRE, DRPU, and
nnPU, respectively. Since there are no existing meta-learning methods for PU classiﬁcation with a few PU
data, we created these baseline methods. For the support set adaptation, MDRE and MDRPU perform
density-ratio estimation with a gradient descent method. Unlike the proposed method, both methods adapt
the whole neural networks for density-ratio estimation. MnnPU minimizes the loss function of nnPU with
a gradient descent method. NP adapts to the support set by feed-forwarding it to neural networks like
neural processes, which are widely used meta-learning methods (Garnelo et al., 2018). Speciﬁcally, NP uses
v([x,zp,zu])as a classiﬁer, where vis a neural network and zpandzuare task representation vectors. All
methods minimize the test classiﬁcation risk in outer problems as in the proposed method. The details of
neural network architectures and how to select hyperparameters are described in Sections B and C of the
appendix.
5.3 Results
Table 1 shows average test accuracy over diﬀerent target class-priors and positive support set sizes. The
proposed method outperformed the other methods. Naive did not work well on all datasets, which indi-
cates that simply treating unlabeled data as negative data introduces a strong bias. PU learning methods
(DRE, DRPU, uPU, and nnPU) outperformed Naive, which indicates the eﬀectiveness of PU learning.
However, since they do not use source data, they performed worse than the proposed method. MDRE,
MDRPU, MnnPU, and NP also utilize information from the source task as in the proposed methods. Since
estimating binary classiﬁers from a few PU data is generally diﬃcult, simply using meta-learning did not
necessarily improve performance (e.g., see the results of MnnPU and nnPU). However, density-ratio-based
meta-learning methods (the proposed method, MDRE, and MDRPU) outperformed their non-meta-learning
variant (DRPU) with all datasets. Some existing studies have reported that density-ratio-based methods
performed well when they used many data (Charoenphakdee & Sugiyama, 2019). Since meta-learning meth-
ods use many data in source tasks, the density-ratio-based meta-learning methods may perform well in our
9Under review as submission to TMLR
Table 1: Average test accuracy [%] over diﬀerent target class-priors within {0.2,0.4,0.6,0.8}and positive
support set sizes within {1,3,5}. Boldface denotes the best and comparable methods according to the paired
t-test (p= 0.05).
Data Ours Naive DRE DRPU uPU nnPU MDRE MDRPU MnnPU NP
Synthetic 82.37 66.05 73.84 73.66 76.98 78.97 79.82 78.96 77.90 80.24
Mnist-r 86.06 55.26 75.83 75.03 75.67 78.37 85.74 86.14 71.64 63.12
Isolet 93.08 54.92 85.80 82.35 84.00 84.73 91.29 92.45 78.33 75.19
IoT 98.70 66.05 76.52 74.10 71.37 76.74 96.40 97.54 97.26 98.38
Average 90.05 60.57 78.00 76.29 77.00 79.70 88.31 88.77 81.28 79.23
1.0 1.5 2.0 2.5 3.0 3.5 4.0 4.5 5.0
# support positive data0.550.600.650.700.750.800.85ACCOurs
Naive
DRE
DRPU
uPU
nnPU
MDRE
MDRPU
MnnPU
NP
(a) Synthetic
1.0 1.5 2.0 2.5 3.0 3.5 4.0 4.5 5.0
# support positive data0.500.550.600.650.700.750.800.85ACCOurs
Naive
DRE
DRPU
uPU
nnPU
MDRE
MDRPU
MnnPU
NP (b) Mnist-r
1.0 1.5 2.0 2.5 3.0 3.5 4.0 4.5 5.0
# support positive data0.50.60.70.80.9ACCOurs
Naive
DRE
DRPU
uPU
nnPU
MDRE
MDRPU
MnnPU
NP (c) Isolet
1.0 1.5 2.0 2.5 3.0 3.5 4.0 4.5 5.0
# support positive data0.60.70.80.91.0ACCOurs
Naive
DRE
DRPU
uPU
nnPU
MDRE
MDRPU
MnnPU
NP (d) IoT
Figure 2: Average test accuracies and their standard errors when changing positive support set sizes.
0.2 0.3 0.4 0.5 0.6 0.7 0.8
T arget positive class-prior0.550.600.650.700.750.800.85ACCOurs
Naive
DRE
DRPU
uPU
nnPU
MDRE
MDRPU
MnnPU
NP
(a) Synthetic
0.2 0.3 0.4 0.5 0.6 0.7 0.8
T arget positive class-prior0.30.40.50.60.70.80.9ACCOurs
Naive
DRE
DRPU
uPU
nnPU
MDRE
MDRPU
MnnPU
NP (b) Mnist-r
0.2 0.3 0.4 0.5 0.6 0.7 0.8
T arget positive class-prior0.30.40.50.60.70.80.9ACCOurs
Naive
DRE
DRPU
uPU
nnPU
MDRE
MDRPU
MnnPU
NP (c) Isolet
0.2 0.3 0.4 0.5 0.6 0.7 0.8
T arget positive class-prior0.50.60.70.80.91.0ACCOurs
Naive
DRE
DRPU
uPU
nnPU
MDRE
MDRPU
MnnPU
NP (d) IoT
Figure 3: Average test accuracies and their standard errors when changing class-priors in target tasks.
experiments. These results suggest that density-ratio-based models are suitable for meta-learning of PU
classiﬁcation with a few PU data.
Figure 2 shows the average test accuracies and their standard errors when changing positive support set
sizesNp
S. All methods tended to improve performance as Np
Sincreased because labeled positive data are
important for PU learning. The proposed method performed the best in almost all values of Np
S. Note that
although it seems that the proposed method and MDRPU yielded similar results due to the poor results of
Naive in Isolet and IoT of Figure 2, the proposed was statistically better than MDRPU as in Table 1.
Figure 3 shows average test accuracies and their standard errors when changing positive class-priors on target
tasks. Naive, which regards all unlabeled data as negative, greatly deteriorated performance as positive class-
prior probability increased. This is because the number of positive data in the unlabeled data became large
when the positive class-prior probability was large. The proposed method consistently performed well in
almost all positive class-prior probabilities. The results of class-prior estimation performance of the proposed
method are described in Section D.1 of the appendix.
Table 2 shows ablation studies of our model. We evaluated three variants of our model: w/o z, w/oπ, and
w/ trueπ. w/o zis our model without task representations zpandzuin Eq. (4). w/o πis our model without
positive class-priors. This model uses s∗(x;S) = sign (ˆr∗(x;S)−0.5)as a binary classiﬁer. w/ true πis our
10Under review as submission to TMLR
Table 2: Ablation studies: Average test accuracy [%] over diﬀerent target class-priors and positive support
set sizes.
Data Ours w/o zw/oπw/ trueπ
Synthetic 82.37 75.92 79.01 84.78
Mnist-r 86.06 84.88 84.36 86.04
Isolet 93.08 92.04 91.51 91.86
IoT 98.70 98.21 98.73 98.36
Table 3: Training and testing time in seconds for meta-learning methods on Mnist-r
Ours MDRE MDRPU MnnPU NP
Train 254.38 485.92 817.23 768.83 168.64
Test 0.018 0.047 0.053 0.050 0.012
model with true positive class-prior information. The proposed method outperformed w/o zand w/oπon
almost all datasets, which indicates the eﬀectiveness of task representations and the estimated class-prior.
Interestingly, the proposed method, which does not use true class-prior information, performed the same
as or better than w/true πin all datasets except for Synthetic. Since the class-prior estimation depends
on the estimated density-ratio in Eq. (11), it might help to improve the performance of the density-ratio
estimation. Since true class-priors are diﬃcult or impossible to obtain without negative data in practice, this
result shows the usefulness of the proposed method. The class-prior estimation performance of the proposed
method was the worst in Synthetic: the average RMSEs of Synthetic, Mnist-r, Isolet, and IoT were 0.205,
0.179, 0.107, and 0.182, respectively. Thus, this might be one cause of the performance degradation in the
ablation study. Since Synthetic has a large overlap in the positive and negative distributions, it may have
been relatively diﬃcult to estimate the class-prior distribution from a few PU data.
Table 3 shows the training and testing time in seconds of meta-learning methods with Mnist-r. We used a
computer with a 2.20 GHz CPU. MAML-based methods (MDRE, MDRPU, and MnnPU) had much longer
computation times than the others because they require costly gradient descent updates for adaptation. In
contrast, since the proposed method can perform adaptation with the closed-form solution of the density-
ratio estimation, it was more eﬃcient than MDRE, MDRPU, and MnnPU. NP had the shortest computation
time because it performs adaptation by simply feed-forwarding the support set to neural networks. However,
the proposed method clearly outperformed NP in terms of accuracy by a large margin in Table 1.
6 Conclusion
In this paper, we proposed a meta-learning method for PU classiﬁcation that can improve performance
of binary classiﬁers obtained from PU data in unseen target tasks. The proposed method adapts to a
few PU data by using only the closed-form solution of density-ratio estimation, leading to eﬃcient and
eﬀective meta-learning. Experiments demonstrated that the proposed method outperforms various existing
PU learning methods and their meta-learning extensions. As future work, we plan to extend our framework
to treat diﬀerent feature spaces across tasks by using techniques in the heterogeneus meta-learning (Iwata
& Kumagai, 2020).
References
Mohammed Ibrahim Alowais and Lay-Ki Soon. Credit card fraud detection: personalized or aggregated
model. In MUSIC, 2012.
Jessa Bekker and Jesse Davis. Learning from positive and unlabeled data: A survey. Machine Learning , 109
(4):719–760, 2020.
Luca Bertinetto, Joao F Henriques, Philip HS Torr, and Andrea Vedaldi. Meta-learning with diﬀerentiable
closed-form solvers. arXiv preprint arXiv:1805.08136 , 2018.
11Under review as submission to TMLR
Gilles Blanchard, Gyemin Lee, and Clayton Scott. Semi-supervised novelty detection. The Journal of
Machine Learning Research , 11:2973–3009, 2010.
Nontawat Charoenphakdee and Masashi Sugiyama. Positive-unlabeled classiﬁcation under class prior shift
and asymmetric error. In SDM, 2019.
Hui Chen, Fangqing Liu, Yin Wang, Liyue Zhao, and Hao Wu. A variational approach for learning from
positive and unlabeled data. NeurIPS , 2020a.
Xuxi Chen, Wuyang Chen, Tianlong Chen, Ye Yuan, Chen Gong, Kewei Chen, and Zhangyang Wang.
Self-pu: self boosted and calibrated positive-unlabeled training. In ICML, 2020b.
Marthinus Du Plessis, Gang Niu, and Masashi Sugiyama. Convex formulation for learning from positive and
unlabeled data. In ICML, 2015.
Marthinus C Du Plessis, Gang Niu, and Masashi Sugiyama. Analysis of learning from positive and unlabeled
data.NeurIPS , 2014.
Charles Elkan and Keith Noto. Learning classiﬁers from only positive and unlabeled data. In SIGKDD ,
2008.
Mark Fanty and Ronald Cole. Spoken letter recognition. In NeurIPS , 1990.
Alec Farid and Anirudha Majumdar. Generalization bounds for meta-learning via pac-bayes and uniform
stability. NeurIPS , 2021.
Chelsea Finn, Pieter Abbeel, and Sergey Levine. Model-agnostic meta-learning for fast adaptation of deep
networks. In ICML, 2017.
Gabriel Pui Cheong Fung, Jeﬀrey Xu Yu, Hongjun Lu, and Philip S Yu. Text classiﬁcation without negative
examples revisit. IEEE transactions on Knowledge and Data Engineering , 18(1):6–20, 2005.
Marta Garnelo, Dan Rosenbaum, Christopher Maddison, Tiago Ramalho, David Saxton, Murray Shanahan,
Yee Whye Teh, Danilo Rezende, and SM Ali Eslami. Conditional neural processes. In ICML, 2018.
Muhammad Ghifary, W Bastiaan Kleijn, Mengjie Zhang, and David Balduzzi. Domain generalization for
object recognition with multi-task autoencoders. In ICCV, 2015.
Yves Grandvalet and Yoshua Bengio. Semi-supervised learning by entropy minimization. 2004.
Zayd Hammoudeh and Daniel Lowd. Learning from positive and unlabeled data with arbitrary positive
shift.NeurIPS , 2020.
Timothy M Hospedales, Antreas Antoniou, Paul Micaelli, and Amos J Storkey. Meta-learning in neural
networks: a survey. IEEE Transactions on Pattern Analysis and Machine Intelligence , 2021.
MingHou, BrahimChaib-Draa, ChaoLi, andQibinZhao. Generativeadversarialpositive-unlabeledlearning.
InIJCAI, 2018.
Cho-Jui Hsieh, Nagarajan Natarajan, and Inderjit Dhillon. Pu learning for matrix completion. In ICML,
2015.
Yu-Guan Hsieh, Gang Niu, and Masashi Sugiyama. Classiﬁcation from positive, unlabeled and biased
negative data. In ICML, 2019.
Qiaona Hu, Baoming Tang, and Derek Lin. Anomalous user activity detection in enterprise multi-source
logs. InICDMW , 2017.
Dmitry Ivanov. Dedpul: Diﬀerence-of-estimated-densities-based positive-unlabeled learning. In ICMLA,
2020.
12Under review as submission to TMLR
Tomoharu Iwata and Atsutoshi Kumagai. Meta-learning from tasks with heterogeneous attribute spaces. In
NeurIPS , 2020.
Weisen Jiang, James Kwok, and Yu Zhang. Subspace learning for eﬀective meta-learning. In ICML, 2022.
Takafumi Kanamori, Shohei Hido, and Masashi Sugiyama. A least-squares approach to direct importance
estimation. The Journal of Machine Learning Research , 10:1391–1445, 2009.
Masahiro Kato and Takeshi Teshima. Non-negative bregman divergence minimization for deep direct density
ratio estimation. In ICML, 2021.
Diederik P Kingma and Jimmy Ba. Adam: a method for stochastic optimization. arXiv preprint
arXiv:1412.6980 , 2014.
Ryuichi Kiryo, Gang Niu, Marthinus C Du Plessis, and Masashi Sugiyama. Positive-unlabeled learning with
non-negative risk estimator. NeurIPS , 2017.
Atsutoshi Kumagai, Tomoharu Iwata, and Yasuhiro Fujiwara. Transfer anomaly detection by inferring latent
domain representations. In NeurIPS , 2019.
Atsutoshi Kumagai, Tomoharu Iwata, and Yasuhiro Fujiwara. Meta-learning for relative density-ratio esti-
mation. In NeurIPS , 2021.
Atsutoshi Kumagai, Tomoharu Iwata, Hiroshi Takahashi, and Yasuhiro Fujiwara. Meta-learning for robust
anomaly detection. In AISTATS , 2023.
Juho Lee, Yoonho Lee, Jungtaek Kim, Adam Kosiorek, Seungjin Choi, and Yee Whye Teh. Set transformer:
A framework for attention-based permutation-invariant neural networks. In ICML, 2019a.
Kwonjoon Lee, Subhransu Maji, Avinash Ravichandran, and Stefano Soatto. Meta-learning with diﬀeren-
tiable convex optimization. In CVPR, 2019b.
Wenkai Li, Qinghua Guo, and Charles Elkan. A positive and unlabeled learning algorithm for one-class
classiﬁcation of remote-sensing data. IEEE transactions on geoscience and remote sensing , 49(2):717–725,
2010.
Xiaoli Li and Bing Liu. Learning to classify texts using positive and unlabeled data. In IJCAI, 2003.
Bing Liu, Yang Dai, Xiaoli Li, Wee Sun Lee, and Philip S Yu. Building text classiﬁers using positive and
unlabeled examples. In ICDM, 2003.
YashuLiu,ShuangQiu,PingZhang,PinghuaGong,FeiWang,GuoliangXue,andJiepingYe. Computational
drug discovery with dyadic positive-unlabeled learning. In ICDM, 2017.
Mohammad Reza Loghmani, Markus Vincze, and Tatiana Tommasi. Positive-unlabeled learning for open
set domain adaptation. Pattern Recognition Letters , 136:198–204, 2020.
Chuan Luo, Pu Zhao, Chen Chen, Bo Qiao, Chao Du, Hongyu Zhang, Wei Wu, Shaowei Cai, Bing He,
SaravanakumarRajmohan, etal. Pulns: positive-unlabeledlearningwitheﬀectivenegativesampleselector.
InAAAI, 2021.
Divyat Mahajan, Shruti Tople, and Amit Sharma. Domain generalization using causal matching. In ICML,
2021.
Kota Matsui, Wataru Kumagai, Kenta Kanamori, Mitsuaki Nishikimi, and Takafumi Kanamori. Variable
selection for nonparametric learning with power series kernels. Neural Computation , 31(8):1718–1750,
2019.
Yair Meidan, Michael Bohadana, Yael Mathov, Yisroel Mirsky, Asaf Shabtai, Dominik Breitenbacher, and
Yuval Elovici. N-baiotâĂŤnetwork-based detection of iot botnet attacks using deep autoencoders. IEEE
Pervasive Computing , 17(3):12–22, 2018.
13Under review as submission to TMLR
Jawad Nagi, Frederick Ducatelle, Gianni A Di Caro, Dan Cireşan, Ueli Meier, Alessandro Giusti, Farrukh
Nagi, Jürgen Schmidhuber, and Luca Maria Gambardella. Max-pooling convolutional neural networks
for vision-based hand gesture recognition. In 2011 IEEE international conference on signal and image
processing applications (ICSIPA) , pp. 342–347. IEEE, 2011.
Shota Nakajima and Masashi Sugiyama. Positive-unlabeled classiﬁcation under class-prior shift: a prior-
invariant approach based on density ratio estimation. Machine Learning , 112(3):889–919, 2023.
Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary DeVito, Zeming Lin,
Alban Desmaison, Luca Antiga, and Adam Lerer. Automatic diﬀerentiation in pytorch. 2017.
Aravind Rajeswaran, Chelsea Finn, Sham M Kakade, and Sergey Levine. Meta-learning with implicit
gradients. In NeurIPS , 2019.
HarishRamaswamy, ClaytonScott, andAmbujTewari. Mixtureproportionestimationviakernelembeddings
of distributions. In ICML, 2016.
Benjamin Rhodes, Kai Xu, and Michael U Gutmann. Telescoping density-ratio estimation. NeurIPS , 2020.
Tomoya Sakai and Nobuyuki Shimizu. Covariate shift adaptation on learning from positive and unlabeled
data. In AAAI, 2019.
Tomoya Sakai, Marthinus Christoﬀel Plessis, Gang Niu, and Masashi Sugiyama. Semi-supervised classiﬁca-
tion based on classiﬁcation from positive and unlabeled data. In ICML, 2017.
Tomoya Sakai, Gang Niu, and Masashi Sugiyama. Semi-supervised auc optimization based on positive-
unlabeled learning. Machine Learning , 107:767–794, 2018.
Bernhard Schölkopf, Alexander J Smola, Francis Bach, et al. Learning with kernels: support vector machines,
regularization, optimization, and beyond . MIT press, 2002.
Clayton Scott. A rate of convergence for mixture proportion estimation, with application to learning from
noisy labels. In AISTATS , 2015.
Jake Snell, Kevin Swersky, and Richard Zemel. Prototypical networks for few-shot learning. In NeurIPS ,
2017.
Jonas Sonntag, Gunnar Behrens, and Lars Schmidt-Thieme. Positive-unlabeled domain adaptation. arXiv
preprint arXiv:2202.05695 , 2022.
Masashi Sugiyama, Taiji Suzuki, and Takafumi Kanamori. Density ratio estimation in machine learning .
Cambridge University Press, 2012.
Vladimir N Vapnik. An overview of statistical learning theory. IEEE transactions on neural networks , 10
(5):988–999, 1999.
Xutao Wang, Hanting Chen, Tianyu Guo, and Yunhe Wang. Pue: biased positive-unlabeled learning en-
hancement by causal inference. NeurIPS , 2023.
Nathan Wiebe, Ashish Kapoor, and Krysta M Svore. Quantum nearest-neighbor algorithms for machine
learning. Quantum information and computation , 15(3-4):318–358, 2015.
Makoto Yamada, Taiji Suzuki, Takafumi Kanamori, Hirotaka Hachiya, and Masashi Sugiyama. Relative
density-ratio estimation for robust distribution comparison. Neural computation , 25(5):1324–1370, 2013.
Yu Yao, Tongliang Liu, Bo Han, Mingming Gong, Gang Niu, Masashi Sugiyama, and Dacheng Tao. Re-
thinking class-prior estimation for positive-unlabeled learning. In ICLR, 2021.
Hwanjo Yu, Jiawei Han, and Kevin Chen-Chuan Chang. Pebl: positive example based learning for web page
classiﬁcation using svm. In SIGKDD , pp. 239–248, 2002.
14Under review as submission to TMLR
Manzil Zaheer, Satwik Kottur, Siamak Ravanbakhsh, Barnabas Poczos, Russ R Salakhutdinov, and Alexan-
der J Smola. Deep sets. In NeurIPS , 2017.
Yunrui Zhao, Qianqian Xu, Yangbangyan Jiang, Peisong Wen, and Qingming Huang. Dist-pu: positive-
unlabeled learning from a label distribution perspective. In CVPR, 2022.
Maria A Zuluaga, Don Hush, Edgar JF Delgado Leyton, Marcela Hernández Hoyos, and Maciej Orkisz.
Learning from only positive and unlabeled data to detect lesions in vascular ct images. In MICCAI , 2011.
A Download Links of Real-world Datasets
We used three real-world datasets for our experiments: Mnist-r2, Isolet3, and IoT4.
B Network Architecture
For the proposed method, a three(two)-layered feed-forward neural network was used for f(g)in Eq. (3).
Forf, the number of hidden and output nodes was 100. For embedding network hin Eq. (4), a four-layered
feed-forward neural network with 100hidden and output nodes was used ( J= 100). The Softplus activation
was used for the output nodes to ensure non-negativeness. For Naive, nnPU, MnnPU, and NP, a ﬁve-layered
feed-forward neural network with 100hidden nodes was used for classiﬁer networks. For DRPU, MDRE,
and MDRPU, a ﬁve-layered feed-forward neural network with 100hidden nodes was used for modeling
the density-ratio. For the task representation vectors in NP, the same neural network architectures as the
proposed method ( fandg) were used. All neural networks used the ReLU function as their activation
functions for the hidden nodes. We implemented all neural network-based methods on the basis of PyTorch
(Paszke et al., 2017). All experiments were conducted on a Linux server with an Intel Xeon CPU and a
NVIDIA A100 GPU.
C Hyperparameters
For meta-learning-based methods (the proposed method, MDRE, MDRPU, MnnPU, and NP), the hyperpa-
rameters were determined on the basis of mean validation accuracy. For non-meta-learning-based methods
(Naive, DRE, DRPU, uPU, and nnPU), the best test results were reported from their hyperparameter
candidates. We describe the hyperparameter candidates for each method below. For DRE and uPU, regu-
larization parameter λwas chosen from{10−3,10−2,..., 10}. Gaussian width of the RBF kernel was set to
the median distance between support instances, which is a useful heuristic (median trick) (Schölkopf et al.,
2002). For DRPU and MDRPU, non-negative correction parameter αwas chosen from {0.1,0.2,0.3}. For
Naive, DRPU, and nnPU, the number of training iterations was selected from {100,500,1000}. For the
proposed method and NP, the dimension of task representations Kwas chosen from {16,32,64,128}. For
MDRE, DRPU, and MnnPU, the iteration number for the support set adaptation was set to three, and the
step size was selected from {10−2,10−1,1}. For density-ratio-based meta-learning methods (the proposed
method, MDRE, and MDRPU), scaling parameter of the sigmoid function τwas set to 10. For all neural
network-based methods, we used the Adam optimizer (Kingma & Ba, 2014) with a learning rate of 10−3.
The mean validation accuracy was also used for early stopping to avoid over-ﬁtting, where the maximum
number of training iterations was 30,000.
D Additional Experimental Results
D.1 Class-prior Estimation Performance
Figure4showsaverageandstandarderrorsofrootmeansquarederrors(RMSEs)betweentrueandestimated
class-priors of the proposed method with diﬀerent positive support set sizes. As Np
Sincreased, the proposed
2https://github.com/ghif/mtae
3http://archive.ics.uci.edu/ml/datasets/ISOLET
4https://archive.ics.uci.edu/ml/datasets/detection_of_IoT_botnet_attacks_N_BaIoT
15Under review as submission to TMLR
1.0 1.5 2.0 2.5 3.0 3.5 4.0 4.5 5.0
# support positive data0.150.200.250.300.35RMSEOurs
(a) Synthetic
1.0 1.5 2.0 2.5 3.0 3.5 4.0 4.5 5.0
# support positive data0.160.170.180.190.20RMSEOurs (b) Mnist-r
1.0 1.5 2.0 2.5 3.0 3.5 4.0 4.5 5.0
# support positive data0.090.100.110.120.130.14RMSEOurs (c) Isolet
1.0 1.5 2.0 2.5 3.0 3.5 4.0 4.5 5.0
# support positive data0.050.100.150.200.250.300.350.40RMSEOurs (d) IoT
Figure 4: Average and standard errors of RMSEs between the true class-prior and estimated class-prior with
the proposed method when changing positive support set size Np
S.
0.2 0.3 0.4 0.5 0.6 0.7 0.8
Target positive class-prior0.140.160.180.200.220.240.260.280.30RMSEOurs
(a) Synthetic
0.2 0.3 0.4 0.5 0.6 0.7 0.8
Target positive class-prior0.140.160.180.200.220.240.260.28RMSEOurs (b) Mnist-r
0.2 0.3 0.4 0.5 0.6 0.7 0.8
Target positive class-prior0.080.090.100.110.120.130.140.15RMSEOurs (c) Isolet
0.2 0.3 0.4 0.5 0.6 0.7 0.8
Target positive class-prior0.050.100.150.200.250.300.350.40RMSEOurs (d) IoT
Figure 5: Average and standard errors of RMSEs between the true class-prior and estimated class-prior with
the proposed method when changing positive class-priors in target tasks.
method tended to improve the estimation performance. This is because the density-ratio estimation used for
class-prior estimation became more accurate as Np
Sincreased. Figure 5 shows average and standard errors of
RMSEs between true and estimated class-priors with diﬀerent positive class-priors on target tasks. Although
the trend of RMSEs varied across datasets, in all cases, the RMSE was kept between 0.05 and 0.3 even with
a few target PU data.
D.2 Impact of Task Representation Vectors
Figure 6 shows average and standard errors of test accuracies when changing the dimension of task repre-
sentation vectors K. The proposed method consistently performed better than DRE over all Kwith all
datasets. Figure 7 shows average and standard errors of RMSEs between truce and estimated class-prior
of the proposed method when changing K. Although the best value of Kwas varied across datasets, the
diﬀerence in RMSE between diﬀerent values of Kwas small. These results demonstrate that the proposed
method is relatively robust against Kvalues.
D.3 Impact of Scaling Parameter τin Sigmoid Function
The proposed method uses the smoothed test classiﬁcation risk in Eq. (15) for meta-learning, which is
obtained by replacing the zero-one loss in Eq. (14) with the sigmoid function with scaling parameter
στ(U) =1
1+exp(−τ·U). We investigated the impact of τ. Table 4 shows the results of the proposed method
withτ= 1andτ= 10. The proposed method with τ= 10outperformed it with τ= 1. This is because our
density-ratio-based score function u∗(x;S,Θ)used in the sigmoid function theoretically only takes values
between−0.5and0.5. In this case, the sigmoid function with small τ(e.g., 1),στ, cannot approximate the
zero-one loss well (e.g., στ=1(u∗(x;S,Θ))takes values between 0.3775and0.6224). By using relatively large
τ(e.g.,10),στcan accurately approximate the zero-one loss (e.g., στ=10(u∗(x;S,Θ))takes values between
0.0067and0.9933). As a result, the proposed method with τ= 10performed well. We note that all
16Under review as submission to TMLR
20 40 60 80 100 120
K0.740.760.780.800.82ACCOurs
DRE
(a) Synthetic
20 40 60 80 100 120
K0.760.780.800.820.840.86ACCOurs
DRE (b) Mnist-r
20 40 60 80 100 120
K0.860.870.880.890.900.910.920.93ACCOurs
DRE (c) Isolet
20 40 60 80 100 120
K0.750.800.850.900.951.00ACCOurs
DRE (d) IoT
Figure 6: Average and standard errors of accuracies with the proposed method when changing the dimension
of task representations K.
20 40 60 80 100 120
K0.2000.2050.2100.215RMSEOurs
(a) Synthetic
20 40 60 80 100 120
K0.1700.1750.1800.1850.1900.1950.2000.2050.210RMSEOurs (b) Mnist-r
20 40 60 80 100 120
K0.1050.1100.1150.1200.125RMSEOurs (c) Isolet
20 40 60 80 100 120
K0.140.150.160.170.180.190.20RMSEOurs (d) IoT
Figure 7: Average and standard errors of RMSEs between the true class-prior and estimated class-prior with
the proposed method when changing the dimension of task representations K.
Table 4: The eﬀect of value τin the proposed method: Average test accuracy [%] over diﬀerent class-priors
and positive support set sizes. Boldface denotes the best and comparable methods according to the paired
t-test and the signiﬁcance level of 5%.
Data Ours ( τ= 10) Ours (τ= 1)
Synthetic 82.37 81.22
Mnist-r 86.06 84.00
Isolet 93.08 91.57
IoT 98.70 98.58
density-ratio-based meta-learning methods (the proposed method, MDRE, and MDRPU) used τ= 10in
our experiments since they performed better than those with τ= 1.
D.4 Experiments with Small Label Ratios in Source Tasks
In the experiments of the main paper, we assume that half of the data in each source task is labeled.
However, the number of labeled data might be smaller in practice. Table 5 shows average test accuracy
when the labeled ratio was small ( 0.1) in each source task on IoT. We used IoT since the number of labeled
data was insuﬃcient to create positive support sets in the other real-world datasets. The proposed method
achieved the best performance. This result shows that the proposed method works well even when the label
ratio in source tasks is small.
D.5 Experiments with a Larger Amount of Support Data
In the experiments in the main paper, we used a relatively small amount of support data. However, more
support data might be available in practice. Table 6 shows average test accuracy with a larger support
set on Synthetic. We used Synthetic since it has suﬃcient data in each task for preparing many support
17Under review as submission to TMLR
Table 5: Results with small label ratio ( = 0.1) in source tasks: Average test accuracy [%] over diﬀerent
class-priors in target tasks within {0.2,0.4,0.6,0.8}and positive support set sizes within {1,3,5}on IoT.
Boldface denotes the best and comparable methods according to the paired t-test and the signiﬁcance level
of5%.
Ours Naive DRE DRPU uPU nnPU MDRE MDRPU MnnPU NP
96.59 66.05 76.52 74.10 71.37 76.74 95.14 95.41 95.88 96.23
Table 6: Results with a larger amount of support data: Average test accuracy [%] over target class-priors
within{0.2,0.4,0.6,0.8}with diﬀerent positive support set sizes Np
Swithin{10,30,50}on Synthetic. We
setNp
S+Nu
S= 100. Boldface denotes the best and comparable methods according to the paired t-test and
the signiﬁcance level of 5%.
Np
SOurs Naive DRE DRPU uPU nnPU MDRE MDRPU MnnPU NP
1085.99 78.15 77.80 77.30 81.21 82.15 81.58 83.76 83.77 85.60
3086.45 81.82 80.32 81.60 84.06 84.45 85.23 85.32 84.87 86.22
5086.77 82.02 80.85 82.64 84.12 84.53 85.52 85.56 85.05 86.13
Table 7: Average test accuracies [%] with diﬀerent numbers of source tasks Tin Synthetic.
TOurs Ours w/ true πnnPU
100 82.37 84.78 78.97
75 81.72 84.61 78.97
50 81.45 83.86 78.97
25 77.13 80.01 78.97
(positive) data. The proposed method performed best even when support set sizes were large. Since positive
support data is vital for PU learning, all methods tended to improve performances as Np
Sincreases. This
result demonstrates the proposed method’s eﬀectiveness with relatively large support data.
D.6 Experiments with Diﬀerent Numbers of Source Tasks
Table 7 shows average test accuracies when changing the number of source tasks Tin Synthetic. We used
Syntheticsinceithassuﬃcientsourcetasks( T= 100). Asthenumberofsourcetasksincreased, theproposed
method (Ours) and it with true target class prior information (Ours w/o true π) performed better. This
result indicates that the proposed method can improve its performance by gaining knowledge from many
tasks. We note that Ours estimates the class priors of target tasks without knowing the true class priors.
WhenTwas small (25), nnPU, which uses target PU data and true target class priors, slightly performed
better than Ours. When using the true class priors, the proposed method (Ours w/ true π) outperformed
nnPU.Thisresultsuggeststhetrueclasspriorinformationisespeciallyusefultoconstructaccurateclassiﬁers
when the number of source data is not large. We note that the proposed method (Ours) worked better than
nnPU in IoT, which has a small number of source tasks (6 tasks) in Table 1 in the main paper.
D.7 Comparison with Task-invariant Classiﬁers
We compared the proposed method with a task-invariant approach, called Invariant, that trains a task-
invariantclassiﬁerwithallthesourcedata. Sincethemeta-learningmethods, includingtheproposedmethod,
learn task-speciﬁc classiﬁers to handle task diﬀerences, this evaluation helps investigating the eﬀectiveness
of the meta-learning methods. Table 8 shows average test accuracy over diﬀerent class-priors and positive
support set sizes. The proposed method performed the best on all datasets. Invariant did not work well on
all datasets except for IoT. This is because Synthetic, Mnist-r, and Isolet have signiﬁcant task diﬀerences in
each dataset (e.g., a positive class in one task can be negative in other tasks, etc.) as described in Section
5.1. Since IoT has small task diﬀerences, Invariant works well.
18Under review as submission to TMLR
Table 8: Comparison with task-invariant classiﬁers: Average test accuracy [%] over diﬀerent class-priors and
positive support set sizes. Boldface denotes the best and comparable methods according to the paired t-test
and the signiﬁcance level of 5%.
Data Ours Invariant
Synthetic 82.37 55.11
Mnist-r 86.06 50.01
Isolet 93.08 49.98
IoT 98.70 98.71
Table 9: Comparison with methods that use larger neural networks: Average test accuracy [%] over diﬀerent
class-priors and positive support set sizes. Boldface denotes the best and comparable methods according to
the paired t-test and the signiﬁcance level of 5%.
Data Ours MnnPU MDRE MDRPU
Synthetic 82.37 73.12 79.47 79.79
Mnist-r 86.06 69.42 81.66 82.47
Isolet 93.08 73.31 83.53 85.22
IoT 98.70 92.11 98.03 97.13
D.8 Comparison with Larger Neural Networks
Inourexperiments,forallneuralnetwork-basedmethodsincludingtheproposedmethod,weusedﬁve-layered
feed-forward neural networks as a function from input xto outputyfor a fair comparison. Here, yis the
density-ratiovaluefordensity-ratio-basedmethodsandistheclassiﬁcationscoreforothermethods. However,
the proposed method and NP use additional neural networks fandgto compute the task representation
z. This diﬀerence in neural networks may aﬀect the results. Therefore, we conducted a new experiment
where the total number of layers of the neural network was matched for each method. Speciﬁcally, we used
eight-layered feed-forward neural networks for meta-learning methods except for the proposed method and
NP. Table 9 shows the average test accuracies with each dataset. The proposed method outperformed the
others that used larger neural networks. These results provide further evidence of the eﬀectiveness of the
proposed method. We note that task-representation is not used for other methods because using itself is
within our proposal.
E Potential Applications of the Proposed Method
We discuss other potential real-world applications of the proposed method other than those described in
Section 1.
We can consider recommendation systems for products to users. In this example, each user is regarded as
a task. The user’s past purchases are treated as positive data (of interest to the user), and unpurchased
products are treated as unlabeled data. Since unpurchased products may contain products of interest to
the user, they cannot be treated as negative data. The aim is to learn a user-speciﬁc classiﬁer that predicts
products of interest to the user that has a few positive data (purchased products). Some users may also
provide information on products they are not interested in (i.e., negative data) as well as positive data. Such
users can be used as source tasks.
We can consider medical diagnosis systems to predict if a patient has a disease in multiple hospitals. Since
distributions of data among hospitals can diﬀer due to the diﬀerences in patients or equipment (Chen et al.,
2020b; Matsui et al., 2019), each hospital is treated as a task. The patients not diagnosed with the disease
are treated as positive data, and others are treated as unlabeled data. Other patients cannot be treated as
negative data because they may simply not have been tested. The aim is to learn a target hospital-speciﬁc
classiﬁer that predicts patients with the disease from a few PU data in a small hospital. Some hospitals may
have patients diagnosed with the disease. These hospitals can be treated as source tasks.
19Under review as submission to TMLR
In social networking services, we consider the problem of automatically discovering a user’s friends. In this
example, each user is regarded as a task. Although the users’ friends (positive data) can be found using the
user’s friendship links, other users cannot be treated as non-friends (negative data) since they might contain
some friends. The aim is to learn a user-speciﬁc classiﬁer that predicts friends of the user that has little
information about he/she friends. Some users may provide information about their non-friends by rejecting
a recommendation of friends or blocking users. Such users can be treated as source tasks.
Although the proposed method assumes that the feature space is the same across tasks, it can be applied
to many real-world applications described in Section 1 and above. For example, when data are images, the
feature dimensions can be made the same by resizing. Thus, the proposed method can be applied to image
retrieval, outlier detection for visual inspection, or medical image diagnosis. When data are text, we can
treat the same feature (word) space across tasks within the same language. Thus, the proposed method can
be applied to textual content-based recommendation systems or social networking services. In addition, even
table data is often recorded in the same format (feature space) within a speciﬁc domain, such as a company
or service. Thus, the proposed method would be applied.
F Limitations
The proposed method has a few limitations to overcome. First, the proposed method uses multiple source
tasks to improve the classiﬁcation performance on unseen target tasks. However, when target and source
tasks are less related, the performance might degrade, which is a common limitation of existing meta-learning
and transfer learning methods.
Second, the proposed method assumes that the feature space is the same across all tasks as in most existing
meta-learning methods (Finn et al., 2017; Snell et al., 2017; Garnelo et al., 2018; Rajeswaran et al., 2019;
Bertinetto et al., 2018; Kumagai et al., 2021). This assumption might be restrictive in practice. However,
there are many real-world applications where the proposed method can be applicable, as described in Sec-
tion 1. For example, when data are images, we can easily make the feature dimension of the task the same
by resizing. When data are text, we can treat the same feature (word) space across tasks within the same
language. As future work, we plan to develop a meta-learning method for PU classiﬁcation that can treat
tasks with diﬀerent feature spaces as in (Iwata & Kumagai, 2020).
Third, the proposed method assumes that source tasks contain some negative data. We also plan to extend
our framework such that it can handle source tasks that do not have negative data by rewriting the test
classiﬁcation risk with query PU data as in (Du Plessis et al., 2015; Kiryo et al., 2017; Du Plessis et al., 2014).
Another idea is that when there is enough PU data for each source task, existing PU learning methods could
be used as pre-processing to create pseudo-PN data on the source tasks for the proposed method.
G Social Negative Impacts
Although we demonstrated that the proposed method outperformed various PU learning methods in our
experiments, it is not perfect; the proposed method has risks of misclassiﬁcation. Thus, when the proposed
method is used for mission critical applications, it should be used to support human decision making. In
addition, since the proposed method uses data from multiple tasks, biased datasets risk being included,
which might result in biased results. We encourage researchers to develop methods to automatically detect
such biases.
20