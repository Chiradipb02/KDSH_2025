Published in Transactions on Machine Learning Research (01/2024)
High-dimensional Bayesian Optimization via
Covariance Matrix Adaptation Strategy
Lam Ngo s3962378@student.rmit.edu.au
RMIT University, Australia
Huong Ha huong.ha@rmit.edu.au
RMIT University, Australia
Jeffrey Chan jeffrey.chan@rmit.edu.au
RMIT University, Australia
Vu Nguyen vutngn@amazon.com
Amazon, Australia
Hongyu Zhang hyzhang@cqu.edu.cn
Chongqing University, China
Reviewed on OpenReview: https: // openreview. net/ forum? id= eTgxr7gPuU
Abstract
Bayesian Optimization (BO) is an effective method for finding the global optimum of expen-
sive black-box functions. However, it is well known that applying BO to high-dimensional
optimization problems is challenging. To address this issue, a promising solution is to use
a local search strategy that partitions the search domain into local regions with high likeli-
hood of containing the global optimum, and then use BO to optimize the objective function
within these regions. In this paper, we propose a novel technique for defining the local
regions using the Covariance Matrix Adaptation (CMA) strategy. Specifically, we use CMA
to learn a search distribution that can estimate the probabilities of data points being the
global optimum of the objective function. Based on this search distribution, we then define
the local regions consisting of data points with high probabilities of being the global op-
timum. Our approach serves as a meta-algorithm as it can incorporate existing black-box
BO optimizers, such as BO,TuRBO(Eriksson et al., 2019), and BAxUS(Papenmeier et al.,
2022), to find the global optimum of the objective function within our derived local regions.
We evaluate our proposed method on various benchmark synthetic and real-world problems.
The results demonstrate that our method outperforms existing state-of-the-art techniques.
1 Introduction
Optimizing expensive black-box functions is an important task that has various applications in machine
learning, data science, and operational research. Bayesian Optimization (BO) (Jones et al., 1998; Brochu
et al., 2010; Shahriari et al., 2016; Binois & Wycoff, 2022; Garnett, 2023) is a powerful approach to tackle this
challenging problem in an efficient manner. It has been successfully applied in a wide range of applications,
including but not limited to hyperparameter tuning of machine learning models (Snoek et al., 2012; Turner
et al., 2020), neural architecture search (Jenatton et al., 2017; Kandasamy et al., 2018b), material design
(Hernández-Lobato et al., 2017), robotics (Calandra et al., 2016), and reinforcement learning (Brochu et al.,
2010; Parker-Holder et al., 2022).
1Published in Transactions on Machine Learning Research (01/2024)
BO operates in an iterative fashion by repeatedly training a surrogate model based on the observed data
and using an acquisition function to suggest promising data points for evaluation (Garnett, 2023). This
method is inspired by Bayes’ theorem, which aims to improve the prior belief about the objective function
byincorporatingobserveddatatoobtainaposteriorwithbetterinformation. Inthisway, BOselectsthenext
data points by considering previous information and maximizes the knowledge gained about the objective
function with new observations, making it sample-efficient in finding the objective function’s global optimum.
Despite being a powerful optimization method, BO still suffers from various problems, including the curse
of dimensionality issue, i.e., it often performs poorly when applied to high-dimensional problems (Rana
et al., 2017; Eriksson et al., 2019; Binois & Wycoff, 2022; Papenmeier et al., 2022). One reason for this is
that, as the search domain grows in dimensionality, more local optima may appear, making it difficult for the
algorithm to find the global optimum. Additionally, a larger search space also implies more regions with high
uncertainty, which can potentially cause the acquisition function to overemphasize exploration and fail to
exploit potential regions within a fixed budget. Moreover, in high-dimensional spaces, the objective function
is typically heterogeneous, making it difficult to fit a global surrogate model across the entire domain.
TherehavebeenvariousworksattemptingtomakeBOworkwellforhigh-dimensionaloptimizationproblems.
One of the most promising approaches, which have demonstrated significant success, is the use of a local
search strategy that partitions the search domain into promising local regions where the optimization process
is performed within (Munos, 2011; Wang et al., 2014; Eriksson et al., 2019; Wang et al., 2020; Wan et al.,
2021). These works, however, have certain limitations. For instance, the works in Munos (2011); Wang
et al. (2014); Eriksson et al. (2019) employ a search space partition technique with fixed parameters that
maybe difficult to optimally specify in advance, and thus, may not provide adequate flexibility for various
problems (Wang et al., 2020). The work in Wang et al. (2020) learns promising local regions by partitioning
the search space into non-linear boundary regions using an unsupervised classification algorithm, but there
is no guarantee that these local regions can be learned accurately with a limited amount of training data.
Inthispaper, wefollowtheaforementionedlocalsearchapproachtotacklethehigh-dimensionaloptimization
problem. We propose to use the Covariance M atrix Adaptation (CMA) strategy to systematically define the
local regions to be used within this local search approach. CMA is a technique developed in the Evolutionary
Algorithm literature (Hansen & Ostermeier, 2001), aiming to estimate the probability distribution of data
points in the search domain being the global optimum of the objective function (i.e., search distribution ).
Typically, CMA is combined with Evolutionary Strategy (ES) techniques like CMA-ES(Hansen & Ostermeier,
2001). These techniques leverage the search distribution derived from CMA to guide the search for the global
optimum toward promising regions in the search domain, i.e., regions that highly likely contain the global
optimum. It has been shown that CMA-based ES techniques, such as CMA-ES, perform very well in finding
the global optima of high-dimensional optimization problems, demonstrating CMA’s effectiveness in identi-
fying promising regions that likely contain the global optima of high-dimensional optimization problems. A
drawbackofthesetechniquesisthattheygenerallyrequirealargenumberoffunctionevaluations(Loshchilov
& Hutter, 2016; Nomura et al., 2021).
Inspired by the effectiveness of CMA in working with high-dimensional optimization problems, we propose
to incorporate CMA into BO methods by using it to define the local regions in the BO local search approach.
In particular, we define the local regions as the regions with the highest probabilities of containing the global
optimum based on CMA’s search distribution. Subsequently, we can use an existing BO optimizer, e.g., BO,
TuRBO(Eriksson et al., 2019), BAxUS(Papenmeier et al., 2022), within these local regions to find the global
optimum of the objective function. By leveraging information from CMA’s search distribution, BO methods
can focus the search within the local regions that have high likelihood of containing the global optimum of the
optimization problem. CMA-based BO methods are therefore expected to work well with high-dimensional
optimization problems, due to CMA’s effectiveness, whilst preserving data-efficiency, a property lacking in
CMA-based ES techniques. We derive the CMA-BO,CMA-TuRBO andCMA-BAxUS algorithms corresponding to
the cases when we incorporate CMA with the optimizers BO,TuRBO,BAxUS, respectively. Our experimental
results on various synthetic and real-world benchmark problems confirm that our proposed approach helps
existing BO methods to work better for high-dimensional optimization problems whilst being data-efficient.
In summary, our contributions are as follows:
2Published in Transactions on Machine Learning Research (01/2024)
•Proposing a novel meta-algorithm using the local search approach and the CMA strategy to enhance
the performance of existing BO methods for high-dimensional optimization problems;
•Deriving the CMA-based BO algorithms corresponding to the cases when we incorporate the pro-
posed meta-algorithm with the state-of-the-art BO methods (e.g., BO,TuRBO,BAxUS);
•Conducting a comprehensive evaluation on various high-dimensional synthetic and real-world bench-
mark problems and demonstrating that our proposed CMA-based meta-algorithm outperforms ex-
isting state-of-the-art methods.
The implementation of our method is available at https://github.com/LamNgo1/cma-meta-algorithm .
2 Background
In this section, we present the fundamental background of BO. Then we revisit two state-of-the-art BO
methods ( TuRBO,BAxUS) that we will incorporate into our CMA-based meta-algorithm.
2.1 Bayesian Optimization
Bayesian optimization (BO) is a powerful optimization method to find the global optimum of an expensive
black-box objective function by sequential queries (Jones et al., 1998; Brochu et al., 2010; Shahriari et al.,
2016; Husain et al., 2023; Garnett, 2023). Let us consider the minimization problem: given an unknown
objective function f:X→RwhereX⊂Rdis a compact space, the goal of BO is to find a global optimum
x∗of the objective function f:
x∗∈arg min x∈Xf(x). (1)
BO solves an optimization problem in an iterative manner. First, the objective function fis approximated
by asurrogate model trained with the current observed dataset D0={xi,yi}t0
i=1withyi=f(xi) +εiand
εi∼N(0,σ2)being the corrupted noise. Then an acquisition function α:X→Ris constructed from the
surrogate model to assign scores to all data points in the domain Xbased on their potential to improve the
optimization process. The next data point to be evaluated, denoted as xnext, is selected as the maximizer of
the acquisition function. Subsequently, the objective function fis evaluated at xnextand the new observed
data (xnext,ynext), withynext=f(xnext) +εandε∼N (0,σ2), is added to the current observed dataset.
The process is conducted iteratively until a pre-defined budget is exhausted, and then BO returns the best
value found from the observed dataset as an estimate of the global optimum x∗.
There are different choices for the surrogate models to be used in BO, including Gaussian Process (GP) (Ras-
mussen & Williams, 2006), Tree-structured Parzen Estimator (TPE) (Bergstra et al., 2011), and neural
networks (Springenberg et al., 2016). In our work, we focus on the GP surrogate model, which is one of
the most popular surrogate models in BO. GP is a probabilistic model that can provide both scalar pre-
dictions for the objective function values and their associated uncertainty. A GP is completely specified by
its mean function µ(x)and covariance function (kernel) k(x,x′)(Rasmussen & Williams, 2006). While the
mean function indicates the most probable values for the objective function values, the covariance function
captures the properties of the objective function, e.g. its smoothness.
There is also a variety of common acquisition functions. Examples include Expected Improvement
(EI) (Mockus et al., 1978), Probability of Improvement (PI) (Kushner, 1964), Upper Confidence Bound
(UCB) (Srinivas et al., 2010), Thompson Sampling (TS) (Thompson, 1933), and Knowledge Gradient
(KG) (Frazier et al., 2009). While each of these acquisition functions has its own strengths and weak-
nesses, they all aim to balance between exploration and exploitation. Exploration encourages the algorithm
to look for promising values in highly uncertain locations, whilst exploitation favors refining the knowledge
around the currently optimal locations. In this work, we use Thompson Sampling (TS) (Thompson, 1933)
as the acquisition function following Eriksson et al. (2019); Papenmeier et al. (2022). In the next section,
we will describe in detail the TS acquisition function which will be later used in our method.
3Published in Transactions on Machine Learning Research (01/2024)
2.2 The Thompson Sampling Acquisition Function
The Thompson Sampling (TS) acquisition function (Thompson, 1933), commonly used in BO research (Kan-
dasamy et al., 2018a; Eriksson et al., 2019; Papenmeier et al., 2022), follows a stochastic policy. The main
idea is to sample a random realization (i.e., sample path ) of the objective function from its posterior distri-
bution, then optimize this sample path to find the next data point to be evaluated. Specifically, at iteration
t, given the observed dataset Dt, the TS acquisition function αTS(x;Dt)can be defined as,
αTS(x;Dt) =f(t)(x)wheref(t)(x)∼p(f|Dt), (2)
andp(f|Dt)denotes the posterior distribution of the objective function fgiven the observed data Dt. If GP
is used as the surrogate model for the objective function, then f(t)(x)∼GP(µ(x),k(x,x′)|Dt).
For a minimization problem as defined in Eq. (1), the TS process is then to minimize the acquisition function
αTS(x;Dt)to find the next data point xt+1to be evaluated,
xt+1= arg min x∈XαTS(x;Dt). (3)
The TS acquisition function selects the data point to be evaluated by drawing a random realization of the
objective function ffrom its posterior distribution, therefore, it encourages exploitation of regions with
higher probabilities of being optimal, while allowing for exploration of other regions, owing to its random
nature. It thus satisfies the desirable property of balancing between exploitation and exploration, which is
a requirement for any acquisition function in BO.
2.3 TurBO
TuRBO(Eriksson et al., 2019) is a state-of-the-art BO method, which proposes to use the local search strategy
to solve the high-dimensional optimization problem. In TuRBO, the global search space is partitioned into
smaller domains, called trust regions (TR) (Yuan, 2000), within which the surrogate model is believed to
accurately model the objective function. TuRBOuses GP as the surrogate model and trains the GP using
all the previous observed data then selects the next observed data point by optimizing the acquisition
function locally within the TR. This local strategy makes TuRBOmore efficient than standard BOmethods
in high-dimensional problems, as it only requires modeling of local surrogate models, abandoning the global
surrogate model used in standard BOmethods. The local surrogate models of TuRBOdo not suffer from the
heterogeneity of the objective function, as they only need to accurately capture the objective function within
the TR.Moreover, asthe TR reduces the regions with largeuncertainty, TuRBOmitigatesthe over-exploration
issue commonly encountered by standard BOmethods when solving high-dimensional optimization problems.
The detailed description of TuRBOcan be found in Appendix Section A.1.
2.4 BAxUS
BAxUS(Papenmeier et al., 2022) is a state-of-the-art BO method that tackles the high-dimensional optimiza-
tion problem using a subspace embedding approach (Wang et al., 2016; Nayebi et al., 2019; Letham et al.,
2020). The main idea is to assume the existence of a low-dimensional subspace ( active subspace )Z⊂Rde
(de≤d), a function g:Z → Rand a projection matrix T∈Rde×dsuch that∀x∈X,g(Tx) =f(x).
This property enables the optimization process to be conducted in the active subspace, which has a lower
dimension compared to the original high-dimensional space. In practice, the effective dimensionality deis
generally unknown, therefore, existing approaches (Wang et al., 2016; Nayebi et al., 2019; Letham et al.,
2020) randomly choose a subspace V⊂RdV(target space ) to project the original space into, and perform
optimization within this chosen subspace. The target dimension dVmust be chosen such that the probability
of the target space containing the global optimum is high. In practice, choosing an appropriate value of the
target dimension dVis challenging as a small value of dVdoes not guarantee that the target space contains
the global optimum whilst a large value of dVcould be subject to the curse of dimensionality issue. BAxUS
proposes an adaptive strategy to gradually increase the target dimension during the optimization process,
guaranteeing a higher probability, compared to existing approaches, that its embedding contains the global
optimum of the objective function. The detailed description of BAxUSis in Appendix Section A.2.
4Published in Transactions on Machine Learning Research (01/2024)
3 Related Work
Various research works have been conducted to address the challenge of applying BO to high-dimensional
optimization problems. One approach is to exploit the additive structure of the objective functions, then
construct and combine a large number of Gaussian Processes (GPs) to approximate the objective func-
tion (Kandasamy et al., 2015; Gardner et al., 2017). Some works suggest replacing GPs with surrogate
models that might scale better with high-dimensional data such as random forests (Hutter et al., 2011), deep
neural networks (Snoek et al., 2015), or Bayesian neural networks (Springenberg et al., 2016). Oh et al.
(2018) propose BOCKwhose main idea is to employ cylindrical transformation to transform the geometry of
the search space, thus mitigating the over-exploration issue of BO in high-dimensional optimization prob-
lems. Other methods, such as the work by Garnett et al. (2014), REMBO(Wang et al., 2016), HeSBO(Nayebi
et al., 2019), ALEBO(Letham et al., 2020), and BAxUS(Papenmeier et al., 2022) propose mapping the orig-
inal high-dimensional space into a low-dimensional space and then conducting optimization within this
low-dimensional space. More recently, Song et al. (2022) propose MCTS-VS, a meta-algorithm that employs
Monte Carlo tree search (MCTS) to construct a low-dimensional subspace and then use a BO optimizer
(e.g., BO,TuRBO) to optimize the objective function within this subspace.
Another approach that has recently attracted a lot of attention is the use of a local search strategy that parti-
tionsthesearchdomainintopromisinglocalregionswheretheoptimizationcanbeperformedwithin(Munos,
2011; Wang et al., 2014; Eriksson et al., 2019; Wang et al., 2020; Turner et al., 2020; Fröhlich et al., 2021;
Wan et al., 2021; 2022). Notable methods in this direction include TuRBO(Eriksson et al., 2019), whose main
idea is to construct local regions as hyper-rectangles centered around the best-found values, and dynami-
cally expand or shrink these regions based on the function values. Wan et al. (2021) extend this idea for
the categorical and mixed search space settings. Another method proposed in Wang et al. (2020), namely
LA-MCTS, is a meta-level algorithm that uses an unsupervised K-mean algorithm to classify the search space
into good and bad local regions, within which a BO optimizer such as BOorTuRBOcan be employed.
Other related works, including the research by Müller et al. (2021); Nguyen et al. (2022), also employ a local
search strategy. However, different compared to the local search approach of partitioning the search space
into local regions, this approach aims to incorporate gradient information into the BO process to enhance
its effectiveness. In particular, the work in Müller et al. (2021) develops a probabilistic model that can
incorporate gradient information, and selects data points for evaluation as those that maximize the gradient.
Building on this work, Nguyen et al. (2022) propose a new acquisition function designed to maximize the
probability of gradient descent, thereby enabling BO to rapidly converge toward the local optimum region.
The local strategies in these methods are different from the space partitioning mechanism used in TuRBOand
LA-MCTS. These methods aim to perform local optimization using the current solution and seek to descend
the objective function values via the gradient information computed from objective function values in nearby
regions. These methods complement our proposed CMA-based meta-algorithm, as they can be used as
optimizers within our approach.
Evolutionary Algorithms (EAs) represent a widely-used family of algorithms for optimizing high-dimensional
black-box functions. Among these, CMA-ES(Hansen & Ostermeier, 2001) is well-known for its impressive
performance in finding global optimum of the objective function. In this paper, we propose a novel meta-
algorithm that leverages the CMA technique of CMA-ESto define the local regions. There are several EA
methods that also combine the CMA technique with the GP surrogate model to enhance the optimization
performance. GPOP(Buche et al., 2005) is an EA method that uses CMA-ESto optimize a merit function
defined by the predicted mean and standard deviation function of a trained GP. DTS-CMAES (Bajer et al.,
2019), another EA method which has been shown to outperform GPOP, constructs a doubly-trained GP inside
CMA-ESto select the data points for forming the mean vector and covariance matrix of CMA. Closely related
to our approach, BADS(Acerbi & Ma, 2017) is a global optimization method that adopts the mesh adaptive
direct search framework (Audet & Dennis, 2006) which uses CMA-ES as the search oracle and a GP-based
method to find the global optimum of the objective function.
In our experiments, we compare the CMA-based BO methods (created by combining our proposed CMA-
based meta-algorithm with the BO optimizers BO,TuRBO,BAxUS) with a comprehensive list of related meth-
ods: the standard BOmethod, TuRBO,BAxUS,LA-MCTS,MCTS-VS,CMA-ES,DTS-CMAES andBADS.
5Published in Transactions on Machine Learning Research (01/2024)
4 High-dimensional Bayesian Optimization via Covariance Matrix Adaptation
In this section, we first discuss the key ideas of the CMA strategy (Section 4.1), then we propose the CMA-
based meta-algorithm (Section 4.2). Finally, we derive the CMA-based BO algorithms ( CMA-BO,CMA-TuRBO ,
CMA-BAxUS ) corresponding to the cases when we integrate the CMA-based meta-algorithm with the BO
optimizer BO,TuRBO, and BAxUS(Sections 4.2.1, 4.2.2, and 4.2.3).
4.1 The Covariance Matrix Adaptation Strategy
The CMA strategy was initially developed in the Evolutionary Algorithm literature, particularly in the
CMA-ESmethod (Hansen & Ostermeier, 2001). Its main idea is based on stochastic search, which maintains
a search distribution, p(x), to estimate the probabilities of data points in the search domain being the global
optimum of the objective function. First, a search distribution p(0)(x)is initialized. Then a population of
data is sampled from p(0)(x), and the search distribution is updated based on the objective function values of
these data points. This process is conducted iteratively until the algorithm converges (Hansen & Ostermeier,
2001; Abdolmaleki et al., 2017). CMA provides well-established formulas (details below) for the updates of
thesearchdistribution, enablingthestochasticsearchalgorithmtoeventuallyallocatethehighestprobability
to the global optimum. It has been shown that CMA-based ES techniques, such as CMA-ES, perform very
well in finding the global optima of high-dimensional optimization problems (Loshchilov & Hutter, 2016;
Eriksson et al., 2019; Letham et al., 2020; Nomura et al., 2021).
In practice, the most popular choice for the search distribution used in CMA is the multivariate normal
distribution (Hansen & Ostermeier, 2001; Hansen, 2016). Consequently, the focus of CMA is on updating
thetwoprincipalmomentsofthisdistribution: themeanvector mandthecovariancematrix Σ. InCMA,the
covariance matrix is normally decomposed as Σ=σ2Cwhereσ>0is the overall standard deviation (step
size) of the search distribution, thus the goal of CMA is then to update m,σ,andC. At iteration t, given
λobserved data points {x(t)
i,y(t)
i}λ
i=1sampled from the search distribution N/parenleftig
m(t−1),(σ(t−1))2C(t−1)/parenrightig
of
the previous iteration t−1, the mean vector m(t), covariance matrix C(t), and step size σ(t)of the search
distribution at iteration tare updated as follows (Hansen & Ostermeier, 2001; Hansen, 2016),
m(t)=m(t−1)+cm/summationdisplayµ
i=1wi/parenleftig
x(t)
i:λ−m(t−1)/parenrightig
,
C(t)= (1−c1−cµ)C(t−1)+cµ
(σ(t−1))2/summationdisplayλ
i=1wi/parenleftig
x(t)
i:λ−m(t−1)/parenrightig/parenleftig
x(t)
i:λ−m(t−1)/parenrightig⊺
+c1p(t)p(t)⊺,
σ(t)=β(t)σ(t−1),(4)
where
•p(t)=/summationtextt
i=0(m(i)−m(i−1))/σ(i)denotes the evolution path which quantifies the overall movement
of the search distribution, i.e., the movement of the mean vector across iterations,
•xi:λdenotes the i-th best candidate out of λdata points{x(t)
i}λ
i=1based on their noisy function
values, i.e., their corresponding noisy function values satisfy: y(t)
1:λ≤y(t)
2:λ≤...≤y(t)
λ:λ,
•µ≤λis a hypeparameter denoting the number of data points selected to update the search distri-
bution; by default, µis usually set as⌊λ/2⌋,
•{wi}λ
i=1denotes the weight coefficients associated with the data points {x(t)
i:λ}λ
i=1such thatw1≥
w2···≥wµ>0>wµ+1≥···≥wλ,/summationtextµ
i=0wi= 1, and/summationtextλ
i=0wi≈0,
•cm,c1andcµdenote the learning rates at which the search distribution changes, where larger rates
result in faster change and smaller rates reduce the adaptation rate of search distribution,
•β(t)denotes a modification rule for the step size, depending on the evolution path p(t).
Detailed information for the suggested settings of these hyperparameters can be found in Appendix Section
A.3. From Eq. (4), it can be seen that in CMA, the mean vector m(t)is updated based on the previous
6Published in Transactions on Machine Learning Research (01/2024)
Figure 1: Illustration of the proposed CMA-based meta-algorithm. In step (1), a hyper-ellipsoid local region
is initialized. In step (2), a BO optimizer (e.g., BO,TuRBO,BAxUS) is used in this local region to collect a
population of candidates (data points to be evaluated). In step (3), the local region is updated using the
CMA technique. The process is conducted iteratively until the evaluation budget is depleted.
mean vector m(t−1)and the highest-ranking observed data points {x(t)
i:λ}µ
i=1. The covariance matrix C(t)
is updated based on the previous covariance matrix C(t−1), all the observed data points {x(t)
i:λ}λ
i=1, and
the evolution path p(t)of the search distribution from previous iterations. The step size σ(t)is updated
based onβ, which depends on the overall movement of the search distribution (the evolution path p(t)). If
the evolution path is short, e.g., when the vectors ∆m(i)=m(i)−m(i−1)in consecutive iterations cancel
each other out, the step size σis decreased, as the search distribution is likely to start converging toward a
solution. On the contrary, when the evolution path is long, e.g., the vectors ∆m(i)are in the same direction,
the step size is increased, as the search distribution is likely to be far away from the true one.
Theoretically, it has been shown that the CMA strategy can be interpreted as a natural gradient learning
method that updates the parameters (mean, covariance matrix, step size) of the search distribution p(x)to
minimize the expected function value E[f(x)]under this distribution (Akimoto et al., 2010; Nomura et al.,
2021). With the updates in Eq. (4), CMA tends to maximize the probability of generating successful data
points{x(t)
i:λ}µ
i=1(e.g., data points with lower function values for a minimization problem) in the subsequent
iterations (Hansen & Auger, 2011). Empirically, as discussed at the beginning of this section, CMA-based
ES techniques like CMA-ESperform very well in finding the global optimum of high-dimensional optimization
problems (Loshchilov & Hutter, 2016; Nomura et al., 2021), demonstrating the effectiveness of CMA in
deriving search distributions that can estimate the probabilities of data points being the global optimum of
the objective function.
4.2 The CMA-based Meta-algorithm
In this section, we present our proposed CMA-based meta-algorithm. We first discuss the overall process
of this meta-algorithm, then we derive three CMA-based BO methods where we integrate the proposed
meta-algorithm with the three state-of-the-art BO optimizers ( BO,TuRBO,BAxUS).
Overall Process. We illustrate the CMA-based meta-algorithm in Fig. 1 and the pseudocode in Algo-
rithm 1. First, an initial search distribution N(m(0),(σ(0))2C(0))is set (line 6), and a local region S(0)is
computed based on this search distribution and the chosen BO optimizer bo_opt(line 9). Then the BO
optimizer bo_optis used within the local region S(0)to suggestλdata points Dλ={xi}λ
i=1to be evaluated
(lines 11-14). The search distribution is then updated based on these λobserved data points Dλ(line 15).
The process is conducted iteratively until the evaluation budget is depleted, and the algorithm terminates.
Note that a restart strategy is also included to restart the algorithm when the current optimization process
is stuck at a local minimum (line 17).
Local Region Formulation. We first define the base local region Sbfor the CMA-based meta-algorithm.
Depending on the employed BO optimizer, we will further derive the local region Scorresponding to that
particular BO optimizer in the later sections (Sections 4.2.1, 4.2.2, and 4.2.3). As discussed in Section
7Published in Transactions on Machine Learning Research (01/2024)
Algorithm 1 The CMA-based meta-algorithm.
1:Input: Objective function f(.), search domain [l,u]d, maximum number of function evaluations N,
number of initial points n0, BO optimizer bo_opt
2:Output: The optimum x∗
3:Sett←0,T←⌊(N−n0)/λ⌋, global dataset D←∅, local dataset Ω←∅, population size λ
4:whilet≤Tdo
5:Samplen0initial data points D0 ▷Latin hypercube
6:Set the initial search distribution N(m(t),(σ(t))2C(t))based onD0 ▷Sec. A.5
7:Update global dataset D←D∪D0. Reset local dataset Ω←D0,restart←False
8:whilet≤Tandnotrestartdo
9: Compute the local region S(t)fromN(m(t),(σ(t))2C(t))depending on bo_opt▷Eqs. (5),(6),(8)
10: Initialize a dataset to collect λobserved data points Dλ←∅
11: fori=1:λdo
12: Apply BO optimizer bo_optto propose an observed data {xi,yi}from a pool of data points
13: UpdateDλ←Dλ∪{xi,yi}
14: end for
15: Update{m(t+1),C(t+1),σ(t+1)}←CMA({m(t),C(t),σ(t)},Dλ) ▷Eq. (4)
16: UpdateD←D∪Dλ,Ω←Ω∪Dλ,t←t+ 1
17: Update restart←Trueifstopping criteria satisfied
18:end while
19:end while
20:Returnx∗= arg min xi∈D{yi}N
i=1from global dataset D={(xi,yi)}N
i=1
4.1, the search distribution by CMA can assign higher probabilities to more promising data points; there-
fore, we can define the local regions as the regions containing data points with high probability values
from this search distribution. As CMA’s search distribution is a multivariate normal distribution, we pro-
pose defining the local region as the α-level confidence hyper-ellipsoid centered at the mean vector of this
search distribution, containing αpercent of the population of data points that follows this search distribu-
tion. Specifically, at iteration t, given the multivariate normal search distribution N(m(t−1),Σ(t−1)), where
Σ(t−1)= (σ(t−1))2C(t−1), obtained in the previous iteration, the base hyper-ellipsoid local region S(t)
bcan
be computed as,
S(t)
b=/braceleftig
x|∆(t−1)(x)≤χ2
1−α,d/bracerightig
, (5)
where ∆(t−1)(x) =/radicalig/parenleftbig
x−m(t−1)/parenrightbig⊺(Σ(t−1))−1/parenleftbig
x−m(t−1)/parenrightbig
is the Mahalanobis distance (Mahalanobis,
1936) fromxto the search distribution N(m(t−1),Σ(t−1))andχ2
1−α,dis the Chi-squared 1−αcritical value
withddegree of freedom. In our proposed CMA-based meta-algorithm, we set αto be 99.73%, corresponding
to the 3-sigma rule that is commonly used in practice. With this setting, the selected observed data in each
iteration will always fall within the three standard deviations of the mean vector of the search distribution.
Local Optimization. In each iteration t, given the multivariate normal search distribution
N(m(t−1),Σ(t−1))obtained in the previous iteration, we first sample a pool of data points that follow
this search distribution and are within the local region S(t). Then, we use the employed BO optimizer,
bo_opt, to selectλdata points from this pool of data points. The rationale behind this step is that in
the CMA strategy, the search distribution N(m(t−1),Σ(t−1))provides estimates of the probabilities of data
points in the search domain being the global optimum of the objective function. By sampling data points
following this search distribution, we can have a pool of data points having high probabilities of being the
global optimum. By using BO to select data points from this pool, we have a higher probability of select-
ing the better data points that are close to the global optimum. Finally, after obtaining λobserved data
points, we update the CMA’s search distribution following Eq. (4). It is worth noting that, in our proposed
approach, in each iteration, we sample and evaluate λdata points rather than just one as in standard BO
methods, i.e., in our algorithm, one iteration is equal to λiterations in standard BO methods.
8Published in Transactions on Machine Learning Research (01/2024)
Restart Strategy. A local search strategy is typically biased toward the starting point, and the optimiza-
tion process can be trapped in local minima (Eriksson et al., 2019). To enable global optimization for the
CMA-based meta-algorithm, we use the CMA’s restart strategy: a new local search will be initialized when
the current one is stuck at a local minimum (Auger & Hansen, 2005; Hansen, 2016). The conditions for a
restart in CMA normally involve checking if the objective function values are flat for a number of iterations
or if some numerical indicators (e.g., condition number) of the search distribution are violated. Further-
more, since some BO optimizers (e.g., TuRBO,BAxUS) have their own restart strategies, we also incorporate
these restart strategies when applying our proposed CMA-based meta-algorithm to the corresponding BO
optimizers (detailed information in the subsequent sections).
4.2.1 CMA-BO: CMA-based Meta-algorithm with Standard BO
In this section, we describe CMA-BO, the corresponding CMA-based BO method obtained when incorporating
the proposed CMA-based meta-algorithm with the standard BOoptimizer. Note that from this section, we
remove the superscript denoting the iteration index for brevity.
Local Region Formulation. ForCMA-BO, we define the local region Sequal to the base local region Sb
described in Eq. (5), i.e., the local region is the α-level confidence hyper-ellipsoid of the search distribution
N(m,Σ). The value αis also set at 99.73%, corresponding to the 3-sigma rule.
Local Optimization. Following the base algorithm described in Section 4.2, in each iteration, we first
sample a pool of data points that (1) follow the previous search distribution N(m,Σ), and, (2) are within
the local regionS. Then we sequentially apply BO with the TS acquisition function to select the best λ
data points from this pool. Note that when training the GP, as in Eriksson et al. (2019), we also use all the
observed data in all the previous iterations. The pseudocode of the local optimization step in CMA-BOis in
Appendix Section A.4, Algorithm 2.
Restart Strategy. CMA-BOhas the same restart strategy with CMA as described in the base algorithm.
4.2.2 CMA-TuRBO: CMA-based Meta-algorithm with TuRBO
We derive CMA-TuRBO , the CMA-based BO method obtained when incorporating our CMA-based meta-
algorithm with the TuRBOoptimizer. The challenge here is that TuRBOhas its own local region adaptation
mechanism to shrink or expand. Furthermore, the shape of the local regions of TuRBOis hyper-rectangle
which is very different from our CMA local regions’ shape which is hyper-ellipsoid.
Local Region Formulation. ForCMA-TuRBO , we incorporate TuRBO’s local region adaptation mechanism,
which is based on the success and failure state of the optimization process, with the local region strategy
defined by CMA. Specifically, with the search distribution N(m,Σ), we define the local region SCMA-TuRBOas
the hyper-ellipsoid with: (1) the center being at the mean vector m, (2) the radii (lengths of the semi-axes
of the hyper-ellipsoid) computed based on the covariance matrix Σand scaled with a factor Lthat is based
on the success and failure state of the optimization, similar to the local region adaptation mechanism in
TuRBO. In particular, Lis initially set as 0.8, and after τsuccconsecutive success, Lis doubled, while it is
halved when the optimization fails to progress after τfailconsecutive times. Therefore, compared to the local
regions defined by CMA-BO, the local regions of CMA-TuRBO are scaled based on the historical optimization
success record as in TuRBO. With a scale factor L, the local regions of CMA-TuRBO are defined as follows,
SCMA-TuRBO =/braceleftbig
x|∆CMA-TuRBO (x)≤χ2
1−α,d/bracerightbig
, (6)
where ∆CMA-TuRBO (x) =/radicalig
(x−m)⊺Σ−1
CMA-TuRBO (x−m)is the Mahalanobis distance from xto the scaled
search distribution N(m,ΣCMA-TuRBO )andΣCMA-TuRBO =L2Σ. The derivation of this scaled covariance matrix
is asfollows. By definition, theradii of thehyper-ellipsoid constructed by Σisr= diag( Λ1/2), where Λis the
diagonal matrix whose diagonal elements are the eigenvalues of Σ. Note that, using the eigendecomposition,
we have that, Σ=UΛU−1withUbeing the eigenvector matrix. Thus, when scaling the radii of this
hyper-ellipsoid by L, i.e.,rCMA-TuRBO =Lr, the covariance matrix ΣCMA-TuRBO becomesU(L2Λ)U−1=L2Σ.
Finally, similar to TuRBO, we also set upper and lower bounds for L, i.e.,Lcannot exceed a threshold Lmax
and whenLbecomes smaller than a threshold Lmin, the algorithm restarts.
9Published in Transactions on Machine Learning Research (01/2024)
Local Optimization. After obtaining the scaled search distribution N(m,ΣCMA-TuRBO )and the local region
SCMA-TuRBO, the optimization process is conducted similarly as in the base algorithm described in Section 4.2.
Specifically, we first sample a pool of data points from the search distribution N(m,ΣCMA-TuRBO ), and then
apply BO with the TS acquisition function to select λdata points from this pool. Besides, when training
the GP, as with Eriksson et al. (2019), we use all the observed data points so far. The pseudocode of the
local optimization step in CMA-TuRBO is in Appendix Section A.4, Algorithm 3.
Restart Strategy. Apart from the restart strategy of CMA, we also employ the restart strategy of TuRBO,
i.e., whenLshrinks below a minimum threshold Lmin, we terminate the CMA local region SCMA-TuRBO and
restart it at a new location randomly.
4.2.3 CMA-BAxUS: CMA-based Meta-algorithm with BAxUS
We present CMA-BAxUS , the method resulted when incorporating our proposed CMA-based meta-algorithm
with the BAxUSoptimizer. The difficulties in deriving CMA-BAxUS are that BAxUSis operated within a series
of search space projections on different dimensionalities and BAxUSalso includes the local search idea from
TuRBOwithin its optimization process.
LocalRegionFormulation. AsdescribedinSection2.4, thecoreideaof BAxUSistoperformoptimization
in the target space Vof dimension dVrather than in the original search space Xof dimension d(d≥dV).
Therefore, to incorporate BAxUSinto our proposed CMA-based meta-algorithm, we need to compute CMA’s
local regions in the target space V. Note that since BAxUSobtains the objective function evaluations in the
original search domain X, thus, using the CMA’s update formula in Eq. (4), we can only compute the search
distribution inX. To compute the CMA’s local regions in the target space V, our main goal is to project the
search distribution NX(mX,ΣX)fromXtoV, and then use the projected search distribution NV(mV,ΣV)
to construct the local regions. When performing function evaluation in X,BAxUSuses a sparse embedding
matrixQ:V →X, so that for any vector v∈V, we can compute the corresponding vector x∈Xas
x=Qv, and thus evaluate the objective function value f(x). Our problem is then to find a projection
matrixPthat mapsXtoV. This is basically a linear regression problem, and the solution can be derived
asP= (Q⊺Q)−1Q⊺(Golub & Van Loan, 2013). Having defined the linear transformation P:X →V,
given the search distribution NX(mX,ΣX), we can compute the projected search distribution NV(mV,ΣV)
as follows (Tong, 1990),
mV=PmX,
ΣV=PΣXP⊺.(7)
Furthermore, note that BAxUSemploys TuRBOas their optimizer, so when defining the local regions for BAxUS,
we also make use of the local region adaptation mechanism in TuRBO, which is to include a scale factor Lto
scale the local region based on the success and failure state of the optimization process. With this, the local
regionSV,CMA-BAxUScan be defined as,
SV,CMA-BAxUS =/braceleftbig
v|∆CMA-BAxUS (v)≤χ2
1−α,d/bracerightbig
, (8)
where ∆CMA-BAxUS (v) =/radicalig
(v−mV)⊺Σ−1
CMA-BAxUS (v−mV)is the Mahalanobis distance from v∈Vto the
scaled search distribution NV(mV,ΣCMA-BAxUS )andΣCMA-BAxUS =L2ΣV.
Local Optimization. After defining the local region SV,CMA-BAxUS in the target space V, we perform the
optimization process similarly to the base algorithm described in Section 4.2, which is to sample a pool of
data points from the search distribution NV(mV,ΣCMA-BAxUS )and use BO with the TS acquisition function to
pickλdata points in the target space V. Note that, to make use of the observed data collected in previous
target spaces, we employ the same splitting strategy as BAxUSto transform the data obtained in previous
target spaces into the current target space, and add them to the observed dataset of the current target
space. Finally, after collecting λobserved data points in the target space V, we then find the corresponding
data points in the original search space Xby using the projection x=Qvand evaluate their objective
function values f(x). From here, we can update the search distribution of CMA, NX(mX,ΣX), using Eq.
(4), and then recompute the local region SV,CMA-BAxUSvia the projected search distribution NV(mV,ΣV). The
pseudocode of the local optimization step in CMA-BAxUS is in Appendix Section A.4, Algorithm 4.
10Published in Transactions on Machine Learning Research (01/2024)
Restart Strategy. Apart from the restart strategy of CMA, we also employ the restart strategy of BAxUS.
Specifically, when the local region of the largest target dimension shrinks smaller than the minimum thresh-
old, i.e., when dV=dandL<L min, we restart the embedding with target dimension dV=dand identity
embedding matrix Q=Id.
5 Experiments
5.1 Experimental Setup and Baselines
We compare our proposed CMA-based meta-algorithm against a comprehensive list of related baselines,
including BO,TuRBO(Eriksson et al., 2019), BAxUS(Papenmeier et al., 2022), LA-MCTS (Wang et al., 2020),
MCTS-VS (Song et al., 2022), CMA-ES(Hansen & Ostermeier, 2001), DTS-CMAES (Bajer et al., 2019), and
BADS(Acerbi & Ma, 2017). Since LA-MCTS andMCTS-VS are also meta-algorithms like our proposed method,
wethereforecompareagainstthecorrespondingmethodsobtainedwhenincorporatingthesemeta-algorithms
with the BOandTuRBOoptimizers, resulting in LAMCTS-TuRBO ,MCTSVS-BO ,MCTSVS-TuRBO . Note that neither
LA-MCTS norMCTS-VS provide guidance on how to incorporate BAxUSas a BO optimizer, so we are unable
to include the BAxUS-based methods with these two meta-algorithms. Besides, we are also unable to include
LAMCTS-BO as its running time is prohibitively slow on the problems used in this paper (each repeat takes
approximately 3 days to run). Details of the experiment setups are in Appendix Sections A.5 and A.6. The
average running time for each method are also reported in Appendix Section A.8.
5.2 Synthetic and Real-world Benchmark Problems
Weconductexperimentsoneightsyntheticandthreereal-worldbenchmarkproblemstoevaluateallmethods.
For synthetic problems, we use Levy-100D, Alpine-100D, Rastrigin-100D, Ellipsoid-100D, Schaffer2-100D,
Branin2-500D, and two modified versions, Shifted-Levy-100D and Shifted-Alpine-100D. For real-world prob-
lems, we use Half-cheetah-102D, LassoDNA-180D and Rover-100D. These are the benchmark BO problems
that used in related works including Wang et al. (2016; 2018); Eriksson et al. (2019); Nguyen et al. (2020);
Wang et al. (2020); Eriksson & Poloczek (2021); Papenmeier et al. (2022); Song et al. (2022); Nguyen et al.
(2022); Ziomek & Ammar (2023). Details of these problems are in Appendix Section A.7.
5.3 Experimental Results
5.3.1 Comparison against State-of-the-art BO Optimizers
In this section, we aim to evaluate whether the proposed CMA-based meta-algorithm enhances the per-
formance of the BO optimizers by comparing the performance of the CMA-based BO methods ( CMA-BO,
CMA-TuRBO ,CMA-BAxUS )withthecorrespondingBOoptimizers( BO,TuRBO,BAxUS).InFig. 2, itcanbeclearly
seenthatourproposedCMA-basedmeta-algorithmsignificantlyenhancestheperformanceofthecorrespond-
ing optimizers. CMA-BOandCMA-TuRBO outperform BOandTuRBOby a very high margin across all 11 bench-
mark problems. CMA-BAxUS outperforms BAxUSsignificantly on 6 problems (Levy-100D, Rastrigin-100D,
Schaffer2-100D, Shifted-Alpine-100D, Rover-100D, LassoDNA-180D) and performs similarly on 5 problems
(Alpine-100D, Ellipsoid-100D, Shifted-Levy-100D, Branin2-500D, Half-cheetah-102D). Besides, it is worth
noting that, in the shifted functions, both the performance of BAxUSand CMA-BAxUS degrade drastically.
This is because the global optimum is not at the center of the search domain and these methods no longer
have the advantageous benefit of the sparse embedding technique. However, CMA-BAxUS still outperforms
BAxUSin Shifted-Alpine-100D and has a similar performance in Shifted-Levy-100D.
5.3.2 Comparison against State-of-the-art Meta-algorithms
Here, we aim to evaluate whether the proposed CMA-based meta-algorithm is better than existing state-of-
the-art meta-algorithms. Specifically, we compare with other methods created by applying existing meta-
algorithmstotheassociatedBOoptimizers( LAMCTS-TuRBO ,MCTSVS-BO ,MCTSVS-TuRBO ).InFig. 3, compared
to existing meta-algorithms ( LA-MCTS andMCTS-VS), our proposed CMA-based meta-algorithm also outper-
forms these state-of-the-art meta-algorithms significantly. It can be clearly seen that CMA-TuRBO outperforms
11Published in Transactions on Machine Learning Research (01/2024)
0 500 1000 1500 2000
Number of evaluations101102RegretAlpine-100D
0 500 1000 1500 2000
Number of evaluations100102Levy-100D
0 500 1000 1500 2000
Number of evaluations102Shifted-Alpine-100D
0 500 1000 1500 2000
Number of evaluations101102103Shifted-Levy-100D
0 250 500 750 1000
Number of evaluations102
101RegretBranin2-500D
0 250 500 750 1000
Number of evaluations106
103
100Schaffer2-100D
0 500 1000 1500 2000
Number of evaluations102104Ellipsoid-100D
0 500 1000 1500 2000
Number of evaluations102103Rastrigin-100D
0 250 500 750 1000
Number of evaluations5
0Best value foundRover-100D
0 500 1000 1500 2000
Number of evaluations2.5
0.02.51e3 Half-cheetah-102D
0 250 500 750 1000
Number of evaluations3.03.21e1
LassoDNA-180D
CMA-BO
CMA-TuRBO
CMA-BAxUS
BO
TuRBO
BAxUS
Figure 2: Comparison between the CMA-based BO methods ( CMA-BO,CMA-TuRBO ,CMA-BAxUS ) against the
original BO optimizers ( BO,TuRBO,BAxUS). Plotting the mean and standard error over 10 repetitions. The
CMA-based BO methods outperform their respective BO optimizers in most cases.
0 500 1000 1500 2000
Number of evaluations101102RegretAlpine-100D
0 500 1000 1500 2000
Number of evaluations100102Levy-100D
0 500 1000 1500 2000
Number of evaluations102Shifted-Alpine-100D
0 500 1000 1500 2000
Number of evaluations101102103Shifted-Levy-100D
0 250 500 750 1000
Number of evaluations102
101RegretBranin2-500D
0 250 500 750 1000
Number of evaluations106
103
100Schaffer2-100D
0 500 1000 1500 2000
Number of evaluations102104Ellipsoid-100D
0 500 1000 1500 2000
Number of evaluations102103Rastrigin-100D
0 250 500 750 1000
Number of evaluations5
0Best value foundRover-100D
0 500 1000 1500 2000
Number of evaluations2.5
0.02.51e3 Half-cheetah-102D
0 250 500 750 1000
Number of evaluations3.03.21e1
LassoDNA-180D
CMA-BO
CMA-TuRBO
CMA-BAxUS
LAMCTS-TuRBO
MCTSVS-BO
MCTSVS-TuRBO
Figure 3: Comparison between the CMA-based BO methods ( CMA-BO,CMA-TuRBO ) against existing meta-
algorithms ( LAMCTS-TuRBO ,MCTSVS-BO ,MCTSVS-TuRBO ). Plotting the mean and standard error over 10 repe-
titions. The CMA-based BO methods outperform the other meta-algorithms given the same BO optimizer.
both LAMCTS-TuRBO andMCTSVS-TuRBO by a very high margin on all of the problems. Similarly, CMA-BOalso
outperforms MCTSVS-BO on all of the problems by a very high margin. Note that, as mentioned in Section
5, we are unable to include LAMCTS-BO due to its prohibitively slow running time (approximately 3 days
per one repeat). Furthermore, these meta-algorithms do not suggest on how to incorporate BAxUSas a BO
optimizer, so we are also unable to compare them with CMA-BAxUS .
12Published in Transactions on Machine Learning Research (01/2024)
5.3.3 Comparison against other Related Baselines
0 500 1000 1500 2000
Number of evaluations101102RegretAlpine-100D
0 500 1000 1500 2000
Number of evaluations100102Levy-100D
0 500 1000 1500 2000
Number of evaluations102Shifted-Alpine-100D
0 500 1000 1500 2000
Number of evaluations101102103Shifted-Levy-100D
0 250 500 750 1000
Number of evaluations102
101RegretBranin2-500D
0 250 500 750 1000
Number of evaluations106
103
100Schaffer2-100D
0 500 1000 1500 2000
Number of evaluations102104Ellipsoid-100D
0 500 1000 1500 2000
Number of evaluations102103Rastrigin-100D
0 250 500 750 1000
Number of evaluations5
0Best value foundRover-100D
0 500 1000 1500 2000
Number of evaluations2.5
0.02.51e3 Half-cheetah-102D
0 250 500 750 1000
Number of evaluations3.03.21e1
LassoDNA-180D
CMA-BO
CMA-TuRBO
CMA-BAxUS
CMAES
DTS-CMAES
BADS
Figure 4: Comparison between the CMA-based BO methods ( CMA-BO,CMA-TuRBO ,CMA-BAxUS ) against the
CMA-based ES methods ( CMA-ES,DTS-CMAES ) and BADS, a global optimization method which combines
BOand CMA-ES. Plotting the mean and standard error over 10 repetitions. The CMA-based BO methods
outperform CMA-ES,DTS-CMAES andBADSconsistently.
We compare the performance of our proposed CMA-based meta-algorithm with other related methods such
as the CMA-based ES methods ( CMA-ES,DTS-CMAES ) and BADS, a global optimization method combining
BOandCMA-ES. Fig. 4 demonstrates that the CMA-based BO methods outperform the related CMA-based
ES methods in the EA literature such as CMA-ESand DTS-CMAES . This improvement could be attributed
to the use of BO optimizers to select data points for the CMA strategy, instead of randomly sampling, as
is the case with these evolutionary algorithms. This approach makes the CMA-based BO methods to be
more data-efficient. BADS’s good performance on the Ellipsoid-100D problem is thanks to the directed search
mechanism based on the mesh points, making BADSperform well on unimodal functions. However, BADS
performance is still similar to CMA-BAxUS within given budget. Apart from that, BADSseem to struggle with
the high-dimensional optimization problems with limited data and perform poorly on most of our problems.
5.4 Analysis of the Effectiveness of the CMA-based Meta-algorithm
5.4.1 The Trajectory of the Local Regions by the CMA-based Meta-algorithm
We conduct a study to understand the trajectories of the local regions defined by the CMA-based meta-
algorithm in various 2D problems. Note that we only plot the local regions for two derived CMA-based
BO methods, CMA-BOand CMA-TuRBO , as the behavior of CMA-BAxUS in 2D problems is similar to that of
CMA-TuRBO . In Fig. 5, we show the local trajectories for the problem Shifted-Alpine-2D. Additional results
for all other synthetic problems can be found in Appendix Section A.9.
We can see that at the beginning (Iteration 0), when the prior information is insufficient for BO, the selected
data points scatter randomly throughout the search domain. In the later iterations, owing to the use of BOor
TuRBOcombining with the local regions defined by the CMA strategy, the selected data points converge closer
to the global optimum. Note that in these plots, both CMA-BOand CMA-TuRBO start with the same CMA’s
search distribution, however, the local regions in CMA-TuRBO are further scaled by a factor of Lcompared to
the base local region due to its local region adaptation mechanism. In the example plotted here, the local
regions of CMA-BOgradually shrink toward the global optimum whilst the local regions of CMA-TuRBO shrink
13Published in Transactions on Machine Learning Research (01/2024)
10
010Iteration 0
 Iteration 2
 Iteration 4
 Iteration 5
 Iteration 8
 Iteration 10
10
 0 1010
010Iteration 0
L=0.8
10
 0 10Iteration 2
L=0.1
10
 0 10Iteration 4
L=0.0125
10
 0 10Iteration 5
L=0.8
10
 0 10Iteration 8
L=0.05
10
 0 10Iteration 10
L=0.05Global minimum
Data proposed
by BO
Ellipse mean 
vector
Local region
Base local 
region
102
101
100101
Figure 5: The local regions’ trajectories defined by the proposed CMA-based meta-algorithm when paired
with BO(upper row) and TuRBO(lower row) for the Shifted-Alpine-2D function. In this case, the local regions
ofCMA-BOgradually move towards the global minimum of the objective function whilst the local regions of
CMA-TuRBO quickly converge to a sub-optimal location, then restart and move toward to the global optimum.
much faster, converge to a local optimum at Iteration 4 (with L= 0.0125), then restart and ultimately
converge to the global optimum.
5.4.2 How the CMA-based Meta-algorithm Approaches the Global Optimum Compared to Baselines
In Section 5.3, we present the performance of our proposed CMA-based BO methods in terms of the best
function values found. In this section, we evaluate how close the selected data points by the CMA-based
BO methods are to the global optimum of the objective function compared to existing baselines. In Fig. 6,
we plot the Euclidean distance between the selected data points in each iteration and the global optimum
of the objective functions for all the methods. Note that we can only evaluate using the synthetic problems
as it is not possible to know the global optima of the real-world problems.
0 1000 2000
Number of evaluations24Log DistanceAlpine-100D
0 1000 2000
Number of evaluations24Levy-100D
0 1000 2000
Number of evaluations34Shifted-Alpine-100D
0 1000 2000
Number of evaluations34Shifted-levy-100D
0 1000 2000
Number of evaluations024Log DistanceEllipsoid-100D
0 1000 2000
Number of evaluations23Rastrigin-100D
CMA-BO
BOCMA-TuRBO
TuRBOCMA-BAxUS
BAxUSMCTSVS-BO
MCTSVS-TuRBOLAMCTS-TuRBO
BADSCMA-ES
DTS-CMAES0 500 1000
Number of evaluations5
05Schaffer2-100D
Figure 6: The Euclidean distances between selected data points in each iteration and the global optimum.
The CMA-based BO methods can guide the search closer to the global optimum than other baselines.
From Fig. 6, we can see that the data points selected by the CMA-based BO methods come closer to
the global optimum than other baselines. Specifically, the data points selected by CMA-BO,CMA-TuRBO , and
CMA-BAxUS are closer to the global optimum than those selected by BO,TuRBO, and BAxUS, respectively in
all the problems except Schaffer2-100D. Compared to other baselines, it is also clear that the CMA-based
BO methods can approach closer to the global optimum in all the problems. It’s worth noting that for
CMA-BAxUS , there are some big jumps in the distance plots which is due to the changes in dimensionality
of the target space, similar to BAxUS. When the target dimension increases, the search is performed in a
higher dimension, so it needs more data to find a good solution than when in a low dimension. However,
14Published in Transactions on Machine Learning Research (01/2024)
BAxUSsuffers this change much more than CMA-BAxUS , i.e., the jumps of BAxUSare more significant than
CMA-BAxUS , asCMA-BAxUS benefits from the guidance of the CMA strategy.
5.4.3 How the CMA-based Meta-algorithm Locates Promising Local Regions Compared to Baselines
0 1000 2000
Number of evaluations2.55.0Log distanceAlpine-100D
0 1000 2000
Number of evaluations2.55.0Levy-100D
0 1000 2000
Number of evaluations345Shifted-Alpine-100D
0 1000 2000
Number of evaluations345Shifted-levy-100D
0 1000 2000
Number of evaluations05Log distanceEllipsoid-100D
0 1000 2000
Number of evaluations24Rastrigin-100D
CMA-BO
CMA-ESCMA-TuRBO
TuRBOCMA-BAxUS
BAxUSLAMCTS-TuRBO
MCTSVS-TuRBO0 500 1000
Number of evaluations5.07.5Schaffer2-100D
Figure 7: The Euclidean distances between centers of local regions and the global optimum. The CMA-based
BO methods can guide the search closer to the global optimum compared to other baselines.
In this section, we investigate the capability of our CMA-based meta-algorithm in guiding the search closer
to the promising regions that have high probabilities of containing the global optimum. We investigate the
movement of the centers of the local regions defined by the methods by plotting their distances to the global
optimum. We conduct this study for BO methods that define a center for their local regions, i.e., CMA-BO,
CMA-TuRBO ,CMA-BAxUS ,TuRBO,BAxUS,LAMCTS-TuRBO ,MCTSVS-TuRBO , and CMA-ES. For CMA-BO,CMA-TuRBO ,
CMA-BAxUS , and CMA-ES, we compute the distance between the mean vectors of the CMA search distributions
at each iteration and the global optimum. For TuRBO,BAxUS,LAMCTS-TuRBO , and MCTSVS-TuRBO , we compute
the distance between the centers of the hyper-rectangular local regions of these methods (defined by TuRBO)
at each iteration and the global optimum. In Fig. 7, we can see that all the CMA-based BO methods
can effectively guide their respective local regions toward the global optimum better than other baselines.
CMA-ES, on the other hand, suffers significantly from the curse of dimensionality issue in the high-dimensional
setting, and steers the search distribution away from the global optimum. This is likely due to the over-
exploration of CMA-ES, which will be discussed in detail in Section 5.4.4. These results further confirm the
capability of our proposed CMA-based meta-algorithm in identifying promising local regions.
5.4.4 The Effectiveness of the CMA-based BO Methods versus CMA-ES
The Bias Issue of the CMA Updates in the CMA-based Meta-algorithm. We investigate a key
difference between the CMA-based BO methods and CMA-ES: the CMA update process in Eq. (4). In
CMA-ES, the CMA search distribution is updated using λdata points randomly sampled from the CMA
multivariate normal search distribution. In our proposed CMA-based meta-algorithm, BO is used to pick
λdata points from a candidate pool of ncdata points sampled from the CMA search distribution. The
use of BO might introduce bias in updating the mean vector m, covariance matrix C, and step-size σin
Eq. (4). One possible issue that can arise is that when ncis large, the λselected data points could be
located near a single point. Even if ncis not so large, the CMA search distribution could be concentrated
around a point, and this could cause premature convergence of the algorithm. However, we argue that in
the high-dimensional setting for BO with a limited budget, this bias issue is not critical. The first reason is
that the search space in a high-dimensional optimization problem is very large and thus, a standard size of
nc(e.g., thousands) is not possible to make the pool of ncdata points very dense, and therefore the scenario
of selected data points located very close to a single point is rare when the evaluation budget is limited.
The second reason is that BO has an exploitation-exploration strategy, so it does not only select data points
with the best-estimated function values (exploitation), but also data points with uncertain function values
15Published in Transactions on Machine Learning Research (01/2024)
0 1000 2000
Number of evaluations101102RegretAlpine-100D
0 1000 2000
Number of evaluations100102RegretLevy-100D
0 1000 2000
Number of evaluations102RegretShifted-Alpine-100D
0 1000 2000
Number of evaluations101102103RegretShifted-Levy-100D
0 500 1000
Number of evaluations102
101RegretBranin2-500D
0 500 1000
Number of evaluations5
0Best value foundRover-100D
0 1000 2000
Number of evaluations2.5
0.02.5Best value found1e3Half-cheetah-102D
0 500 1000
Number of evaluations3.003.25Best value found1e1
LassoDNA-180D
0 500 1000 1500 2000101102Log regretalpine_100D (for important methods)
CMA-BO
CMA-BO (x2)CMA-BO (x3)
 CMA-TuRBO
CMA-TuRBO (x2)CMA-TuRBO (x3)
 CMA-BAxUS
CMA-BAxUS (x2)CMA-BAxUS (x3)
 
Figure 8: Performance of CMA-BO,CMA-TuRBO andCMA-BAxUS when increasing (double and triple) the num-
ber of sampled data points ncwhen optimizing acquisition function Overall, the CMA-based BO methods
maintain the performance, indicating the methods’ robustness w.r.t to nc.
100
 0100100
0100
Iteration: 0
T otal eval: 37
100
 0100
Iteration: 11
T otal eval: 224
100
 0100
Iteration: 22
T otal eval: 411
100
 0100
Iteration: 33
T otal eval: 598
Global minimum CMA-BO CMA-ES
100
 0100
Iteration: 44
T otal eval: 785
100
 0100
Iteration: 55
T otal eval: 972
103
101
Figure 9: The 2D plot for Schaffer2-100D function projecting on the 2 effective dimensions. CMA-ESover-
explores while CMA-BOcan guide the search to focus on the promising region around the global optimum.
(exploration). In the high-dimensional setting, with a limited evaluation budget, the number of observed
data points used to build the GP is even much smaller compared to the search space size, and this results in
a GP with high uncertainty in many areas, making BO to select data points with some levels of randomness.
We conducted some analysis to validate our arguments. First, as discussed in Sections 5.4.2 and 5.4.3,
the results from Figs. 6 and 7 show that the selected data points and the identified local regions by our
CMA-based BO methods can approach the global optimum faster than other baselines. Furthermore, we also
evaluate the robustness of our proposed CMA-based meta-algorithm w.r.t the number of sampled data points
nc. We increase ncto double and triple the value we use in our default setting which is min (100d,5000),
resulting in the values: min (200d,10000)and min (300d,15000). In Fig. 8, we plot the results of our
proposed CMA-based BO methods with different values of nc. We can see that the performance of our
proposed methods remains similar, demonstrating their robustness to the choice of nc, and thus the bias
issue mentioned above is not critical to the high-dimensional setting we use in this paper.
The Over-exploration Issue of CMA-ESin the High-dimensional Setting. It is worth noting that, in
practice, CMA-EStends to over-explore the search space due to its random sampling strategy when selecting
data points to update the search distribution. This behavior can already be seen in Fig. 6 where we can see
that the data points sampled from CMA-ESare very far from the global optimum within our budget, and in
Fig. 7 where it can be observed that the centers of the search distributions by CMA-ESdiverge significantly
from the global optimum within our evaluation budget. We further illustrate this over-exploration issue
ofCMA-ESon the Schaffer2-100D function by displaying the sampled data points of CMA-ESand CMA-BO
across the optimization process. We choose Schaffer2-100D as it has 2effective dimensions and 98dummy
16Published in Transactions on Machine Learning Research (01/2024)
dimensions, so we can project the selected data points to these two effective dimensions and visualize the
selected data points. As we have the results of 10repeats, we present the first one in Fig. 9, and leave
the remaining ones in the Appendix Section A.10. In Fig. 9, we can see that as CMA-ESselects data points
randomly and in the high-dimensional setting, these data points are scattered everywhere in the search
space, causing CMA-ESto over-explore. On the other hand, CMA-BOcan select more meaningful data points,
mitigating the over-exploration issue of CMA-ESin the high-dimensional setting.
6 Conclusion
In this paper, we propose a novel CMA-based meta-algorithm to address the high-dimensional BO problem
by incorporating a local search strategy and the CMA strategy to enhance the performance of existing BO
methods. We further derive the CMA-based BO algorithms for the cases in which our proposed meta-
algorithm is applied to some common state-of-the-art BO optimizers such as BO,TuRBO, and BAxUS. Our
extensive experimental results demonstrate the effectiveness and efficiency of the proposed CMA-based meta-
algorithm, which can significantly improve the BO optimizers and outperform other state-of-the-art meta-
algorithms and related methods.
Acknowledgments
This research is supported by Australian Research Council Discovery Project DP220103044. The first and
second authors (L.N. & H.H.) would like to thank the Google Cloud Research Credits Program for the
computing resources on this project.
References
Abbas Abdolmaleki, Bob Price, Nuno Lau, Luís Paulo Reis, and Gerhard Neumann. Deriving and improv-
ing CMA-ES with information geometric trust regions. In Proceedings of the Genetic and Evolutionary
Computation Conference , pp. 657–664. ACM, 2017. doi: 10.1145/3071178.3071252.
Luigi Acerbi and Wei Ji Ma. Practical bayesian optimization for model fitting with bayesian adaptive direct
search. In Advances in Neural Information Processing Systems (NeurIPS) , volume 30, 2017.
Youhei Akimoto, Yuichi Nagata, Isao Ono, and Shigenobu Kobayashi. Bidirectional Relation between CMA
Evolution Strategies and Natural Evolution Strategies. In Proceedings of the 11th International Conference
on Parallel Problem Solving from Nature: Part I , pp. 154–163, Berlin, Heidelberg, 2010. Springer-Verlag.
ISBN 3642158439.
Charles Audet and J. E. Dennis. Mesh adaptive direct search algorithms for constrained optimization. SIAM
Journal on Optimization , 17(1):188–217, 2006.
Anne Auger and Nikolaus Hansen. A restart cma evolution strategy with increasing population size. In 2005
IEEE congress on evolutionary computation , volume 2, pp. 1769–1776. IEEE, 2005.
Lukáš Bajer, Zbyněk Pitra, Jakub Repický, and Martin Holeňa. Gaussian process surrogate models for the
cma-es. In Proceedings of the Genetic and Evolutionary Computation Conference Companion , pp. 17–18.
Association for Computing Machinery, 2019. ISBN 9781450367486. doi: 10.1145/3319619.3326764.
James Bergstra, Rémi Bardenet, Yoshua Bengio, and Balázs Kégl. Algorithms for hyper-parameter opti-
mization. In Advances in Neural Information Processing Systems 24 , pp. 2546–2554, 2011.
MickaelBinoisandNathanWycoff. Asurveyonhigh-dimensionalgaussianprocessmodelingwithapplication
to bayesian optimization. ACM Transactions on Evolutionary Learning and Optimization , 2(2):1–26, 2022.
Eric Brochu, Vlad M. Cora, and Nando de Freitas. A Tutorial on Bayesian Optimization of Expensive Cost
Functions, with Application to Active User Modeling and Hierarchical Reinforcement Learning, 2010.
17Published in Transactions on Machine Learning Research (01/2024)
Dirk Buche, Nicol N Schraudolph, and Petros Koumoutsakos. Accelerating evolutionary algorithms with
gaussian process fitness function models. IEEE Transactions on Systems, Man, and Cybernetics, Part C
(Applications and Reviews) , 35(2):183–194, 2005.
Roberto Calandra, André Seyfarth, Jan Peters, and Marc Peter Deisenroth. Bayesian optimization for
learning gaits under uncertainty: An experimental comparison on a dynamic bipedal walker. Annals of
Mathematics and Artificial Intelligence , 76:5–23, 2016.
David Eriksson and Matthias Poloczek. Scalable Constrained Bayesian Optimization. In Proceedings of The
24th International Conference on Artificial Intelligence and Statistics , volume 130, pp. 730–738. PMLR,
2021.
David Eriksson, Michael Pearce, Jacob Gardner, Ryan D Turner, and Matthias Poloczek. Scalable Global
Optimization via Local Bayesian Optimization. In Advances in Neural Information Processing Systems ,
pp. 5496–5507, 2019.
Peter I. Frazier, Warren B. Powell, and Savas Dayanik. The Knowledge-Gradient Policy for Correlated
Normal Beliefs. INFORMS J. Comput. , 21(4):599–613, 2009. doi: 10.1287/ijoc.1080.0314.
Lukas P. Fröhlich, Melanie N. Zeilinger, and Edgar D. Klenske. Cautious bayesian optimization for efficient
and scalable policy search. In Proceedings of the 3rd Annual Conference on Learning for Dynamics and
Control, L4DC 2021, 7-8 June 2021, Virtual Event, Switzerland , volume 144 of Proceedings of Machine
Learning Research , pp. 227–240, 2021.
Jacob R. Gardner, Chuan Guo, Kilian Q. Weinberger, Roman Garnett, and Roger B. Grosse. Discovering
and Exploiting Additive Structure for Bayesian Optimization. In Proceedings of the 20th International
Conference on Artificial Intelligence and Statistics , volume 54, pp. 1311–1319. PMLR, 2017.
JacobR.Gardner, GeoffPleiss, KilianQ.Weinberger, DavidBindel, andAndrewGordonWilson. GPyTorch:
Blackbox Matrix-Matrix Gaussian Process Inference with GPU Acceleration. In Advances in Neural
Information Processing Systems 31 , pp. 7587–7597, 2018.
Roman Garnett. Bayesian Optimization . Cambridge University Press, 2023.
Roman Garnett, Michael A. Osborne, and Philipp Hennig. Active learning of linear embeddings for gaussian
processes. In Proceedings of the 30th Conference on Uncertainty in Artificial Intelligence , pp. 230–239.
AUAI Press, 2014.
Gene H Golub and Charles F Van Loan. Matrix computations . JHU press, 2013.
Nikolaus Hansen. The CMA Evolution Strategy: A Tutorial, 2016.
Nikolaus Hansen and Anne Auger. CMA-ES: Evolution Strategies and Covariance Matrix Adaptation. In
Proceedings of the 13th Annual Conference Companion on Genetic and Evolutionary Computation , pp.
991–1010. Association for Computing Machinery, 2011. ISBN 9781450306904. doi: 10.1145/2001858.
2002123.
Nikolaus Hansen and Andreas Ostermeier. Completely Derandomized Self-Adaptation in Evolution Strate-
gies.Evolutionary Computation , 9(2):159–195, 2001. doi: 10.1162/106365601750190398.
JoséMiguelHernández-Lobato, JamesRequeima, EdwardO.Pyzer-Knapp, andAlánAspuru-Guzik. Parallel
and Distributed Thompson Sampling for Large-scale Accelerated Exploration of Chemical Space. In
Proceedings of the 34th International Conference on Machine Learning , volume 70, pp. 1470–1479. PMLR,
2017.
Hisham Husain, Vu Nguyen, and Anton van den Hengel. Distributionally robust bayesian optimization with
φ-divergences. In Thirty-seventh Conference on Neural Information Processing Systems , 2023.
18Published in Transactions on Machine Learning Research (01/2024)
Frank Hutter, Holger H. Hoos, and Kevin Leyton-Brown. Sequential Model-Based Optimization for General
Algorithm Configuration. In Learning and Intelligent Optimization - 5th International Conference , volume
6683, pp. 507–523. Springer, 2011. doi: 10.1007/978-3-642-25566-3_40.
Rodolphe Jenatton, Cedric Archambeau, Javier González, and Matthias Seeger. Bayesian Optimization with
Tree-structured Dependencies. In Proceedings of the 34th International Conference on Machine Learning ,
volume 70, pp. 1655–1664. PMLR, 2017.
Donald R. Jones. A Taxonomy of Global Optimization Methods Based on Response Surfaces. J. Glob.
Optim., 21(4):345–383, 2001. doi: 10.1023/A:1012771025575.
Donald R. Jones, Matthias Schonlau, and William J. Welch. Efficient Global Optimization of Expensive
Black-Box Functions. J. Glob. Optim. , 13(4):455–492, 1998. doi: 10.1023/A:1008306431147.
Kirthevasan Kandasamy, Jeff G. Schneider, and Barnabás Póczos. High Dimensional Bayesian Optimisa-
tion and Bandits via Additive Models. In Proceedings of the 32nd International Conference on Machine
Learning , volume 37, pp. 295–304. JMLR, 2015.
Kirthevasan Kandasamy, Akshay Krishnamurthy, Jeff Schneider, and Barnabas Poczos. Parallelised bayesian
optimisation via thompson sampling. In Proceedings of the Twenty-First International Conference on
Artificial Intelligence and Statistics (AISTATS) , volume 84 of Proceedings of Machine Learning Research ,
pp. 133–142, 2018a.
Kirthevasan Kandasamy, Willie Neiswanger, Jeff Schneider, Barnabás Póczos, and Eric P. Xing. Neural Ar-
chitecture Search with Bayesian Optimisation and Optimal Transport. In Advances in Neural Information
Processing Systems , pp. 2020–2029, 2018b.
H. J. Kushner. A New Method of Locating the Maximum Point of an Arbitrary Multipeak Curve in the
Presence of Noise. Journal of Basic Engineering , 86(1):97–106, 1964. ISSN 0021-9223. doi: 10.1115/1.
3653121.
Ben Letham, Roberto Calandra, Akshara Rai, and Eytan Bakshy. Re-examining linear embeddings for high-
dimensional bayesian optimization. In Advances in Neural Information Processing Systems (NeurIPS) ,
volume 33, pp. 1546–1558, 2020.
Ilya Loshchilov and Frank Hutter. CMA-ES for Hyperparameter Optimization of Deep Neural Networks,
2016.
Prasanta Chandra Mahalanobis. On the generalized distance in statistics. Proceedings of the National
Institute of Sciences (Calcutta) , 2:49–55, 1936.
Jonas Mockus, Vytautas Tiesis, and Antanas Zilinskas. The Application of Bayesian Methods for Seeking
the Extremum. Towards Global Optimization , 2(117-129):2, 1978.
Sarah Müller, Alexander von Rohr, and Sebastian Trimpe. Local policy search with Bayesian optimization.
InAdvances in Neural Information Processing Systems 34 , pp. 20708–20720, 2021.
RémiMunos. OptimisticOptimizationofaDeterministicFunctionwithouttheKnowledgeofitsSmoothness.
InAdvances in Neural Information Processing Systems 24 , pp. 783–791, 2011.
Amin Nayebi, Alexander Munteanu, and Matthias Poloczek. A Framework for Bayesian Optimization in Em-
bedded Subspaces. In Proceedings of the 36th International Conference on Machine Learning , volume 97,
pp. 4752–4761. PMLR, 2019.
QuanNguyen,KaiwenWu,JacobGardner,andRomanGarnett. LocalBayesianoptimizationviamaximizing
probabilityofdescent. In Advances in Neural Information Processing Systems ,volume35,pp.13190–13202.
Curran Associates, Inc., 2022.
Vu Nguyen, Sebastian Schulze, and Michael Osborne. Bayesian optimization for iterative learning. Advances
in Neural Information Processing Systems , 33:9361–9371, 2020.
19Published in Transactions on Machine Learning Research (01/2024)
Masahiro Nomura, Shuhei Watanabe, Youhei Akimoto, Yoshihiko Ozaki, and Masaki Onishi. Warm starting
cma-es for hyperparameter optimization. In Proceedings of the AAAI Conference on Artificial Intelligence ,
volume 35, pp. 9188–9196, 2021.
ChangYong Oh, Efstratios Gavves, and Max Welling. BOCK: Bayesian Optimization with Cylindrical
Kernels. In Proceedings of the 35th International Conference on Machine Learning , volume 80, pp. 3865–
3874. PMLR, 2018.
Leonard Papenmeier, Luigi Nardi, and Matthias Poloczek. Increasing the scope as you learn: Adaptive
bayesian optimization in nested subspaces. In Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and
Kyunghyun Cho (eds.), Advances in Neural Information Processing Systems (NeurIPS) , 2022.
Jack Parker-Holder, Raghu Rajan, Xingyou Song, André Biedenkapp, Yingjie Miao, Theresa Eimer, Baohe
Zhang, Vu Nguyen, Roberto Calandra, Aleksandra Faust, Frank Hutter, and Marius Lindauer. Automated
Reinforcement Learning (AutoRL): A Survey and Open Problems. J. Artif. Intell. Res. , 74:517–568, 2022.
doi: 10.1613/jair.1.13596.
Santu Rana, Cheng Li, Sunil Gupta, Vu Nguyen, and Svetha Venkatesh. High dimensional bayesian opti-
mization with elastic gaussian process. In International conference on machine learning , pp. 2883–2891.
PMLR, 2017.
Carl Edward Rasmussen and Christopher K. I. Williams. Gaussian processes for machine learning . MIT
Press, 2006. ISBN 026218253X.
Kenan Šehić, Alexandre Gramfort, Joseph Salmon, and Luigi Nardi. Lassobench: A high-dimensional hy-
perparameter optimization benchmark suite for lasso. In International Conference on Automated Machine
Learning , pp. 2–1. PMLR, 2022.
Bobak Shahriari, Kevin Swersky, Ziyu Wang, Ryan P. Adams, and Nando de Freitas. Taking the Human
Out of the Loop: A Review of Bayesian Optimization. Proc. IEEE , 104(1):148–175, 2016. doi: 10.1109/
JPROC.2015.2494218.
Jasper Snoek, Hugo Larochelle, and Ryan P Adams. Practical Bayesian Optimization of Machine Learning
Algorithms. In Advances in Neural Information Processing Systems , volume 25. Curran Associates, Inc.,
2012.
Jasper Snoek, Oren Rippel, Kevin Swersky, Ryan Kiros, Nadathur Satish, Narayanan Sundaram, Md.
Mostofa Ali Patwary, Prabhat, and Ryan P. Adams. Scalable Bayesian Optimization Using Deep Neural
Networks. In Proceedings of the 32nd International Conference on Machine Learning , volume 37, pp.
2171–2180. JMLR.org, 2015.
Lei Song, Ke Xue, Xiaobin Huang, and Chao Qian. Monte carlo tree search based variable selection for high
dimensional bayesian optimization. In Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun
Cho (eds.), Advances in Neural Information Processing Systems , 2022. URL https://openreview.net/
forum?id=SUzPos_pUC .
Jost Tobias Springenberg, Aaron Klein, Stefan Falkner, and Frank Hutter. Bayesian Optimization with
Robust Bayesian Neural Networks. In Advances in Neural Information Processing Systems 29 , pp. 4134–
4142, 2016.
Niranjan Srinivas, Andreas Krause, Sham M. Kakade, and Matthias W. Seeger. Gaussian Process Optimiza-
tion in the Bandit Setting: No Regret and Experimental Design. In Proceedings of the 27th International
Conference on Machine Learning , pp. 1015–1022. Omnipress, 2010.
WilliamRThompson. Onthelikelihoodthatonunknownprobabilityexceedsanotherinviewoftheevidence
of two samples. Biometrika , 25(3-4):285–294, 1933. ISSN 0006-3444. doi: 10.1093/biomet/25.3-4.285.
Yung Liang Tong. Fundamental properties and sampling distributions of the multivariate normal distribution .
Springer, 1990.
20Published in Transactions on Machine Learning Research (01/2024)
Ryan Turner, David Eriksson, Michael McCourt, Juha Kiili, Eero Laaksonen, Zhen Xu, and Isabelle Guyon.
Bayesian Optimization is Superior to Random Search for Machine Learning Hyperparameter Tuning:
Analysis of the Black-Box Optimization Challenge 2020. In NeurIPS 2020 Competition and Demonstration
Track, volume 133, pp. 3–26. PMLR, 2020.
Xingchen Wan, Vu Nguyen, Huong Ha, Binxin Ru, Cong Lu, and Michael A Osborne. Think global and
act local: Bayesian optimisation over high-dimensional categorical and mixed search spaces. International
Conference on Machine Learning (ICML) 38 , 2021.
Xingchen Wan, Cong Lu, Jack Parker-Holder, Philip J Ball, Vu Nguyen, Binxin Ru, and Michael Osborne.
Bayesian generational population-based training. In International Conference on Automated Machine
Learning , pp. 14–1. PMLR, 2022.
Linnan Wang, Rodrigo Fonseca, and Yuandong Tian. Learning Search Space Partition for Black-box Op-
timization using Monte Carlo Tree Search. In Advances in Neural Information Processing Systems , vol-
ume 33, pp. 19511–19522. Curran Associates, Inc., 2020.
ZiWang, ClementGehring, PushmeetKohli, andStefanieJegelka. Batchedlarge-scaleBayesianoptimization
in high-dimensional spaces. In International Conference on Artificial Intelligence and Statistics , pp. 745–
754. PMLR, 2018.
Ziyu Wang, Babak Shakibi, Lin Jin, and Nando de Freitas. Bayesian Multi-Scale Optimistic Optimization. In
Proceedings of the Seventeenth International Conference on Artificial Intelligence and Statistics , volume33,
pp. 1005–1014. JMLR.org, 2014.
Ziyu Wang, Frank Hutter, Masrour Zoghi, David Matheson, and Nando De Feitas. Bayesian optimization
in a billion dimensions via random embeddings. Journal of Artificial Intelligence Research , 55:361–387,
2016.
Ya-xiang Yuan. A review of trust region algorithms for optimization. In Iciam, volume 99, pp. 271–282,
2000.
Juliusz Krzysztof Ziomek and Haitham Bou Ammar. Are random decompositions all we need in high
dimensional bayesian optimisation? In International Conference on Machine Learning , pp. 43347–43368.
PMLR, 2023.
A Appendix
A.1 TurBO
InTuRBO, ineach iteration, thetrust region(TR) isconstructed asa hyper-rectanglecentered atthe optimum
data point found so far. Each side length of the TR is initialized with a base side length L, and then scaled
with the GP lengthscales in each dimension, while maintaining the overall hyper-volume. The size of the TR
is critical, as it needs to be large enough to contain potential solutions, while being small enough to ensure
the accuracy of the GP surrogate model. Therefore, TuRBOadopts an adaptation mechanism to expand or
shrink the TR depending on whether the algorithm succeeds or fails to find a better solution. When TuRBO
succeeds in finding better solutions for τsuccconsecutive times, the TR increases its current size, whereas it
decreases its size after τfailconsecutive failures. Furthermore, TuRBOalso defines minimum and maximum
thresholds, denoted as LminandLmaxrespectively, for the TR base side length. The upper bound Lmaxis
to prevent the TR from becoming too large, while the lower bound Lminserves as a restart criterion, such
that when the side length L < L min,TuRBOdiscards the current TR and restarts a new TR from scratch.
These hyperparameters (e.g., τsucc,τfail,Lmin,Lmax) are set as some fixed values in TuRBO.
21Published in Transactions on Machine Learning Research (01/2024)
A.2 BAxUS
BAxUSstarts with a low value of the target dimension dV, and then conducts a BO process to search for
the optimum in this target space within a specific evaluation budget before increasing the target dimension.
Additionally, BAxUSalso employs TuRBOas its BO optimizer to perform optimization for high-dimensional
problems. Therefore, in each iteration, BAxUSalso constructs a TR and applies the TR adaptation mech-
anism, similar to TuRBO, when optimizing within the target space. BAxUSkeeps most of the settings to be
the same with TuRBO(e.g., hyper-rectangle TR, shrinkage factor, success tolerance), but redefines the failure
toleranceτfailto make the search quicker in low-dimensional target spaces.
A.3 Additional Information for the CMA Update Formula
Here, we provide additional information about how to set the hyperparmeters for the CMA formula in Eq.
(4) based on Hansen & Ostermeier (2001). Given the problem dimension as dand the population size
λ= 4 +⌊3 + lnd⌋, let us define some additional terms as,
w′
i= lnλ+ 1
2−lni,fori= 1,...,λ,
µeff=(/summationtextµ
i=1w′
i)2
/summationtextµ
i=1w′
i2,
µ−
eff=(/summationtextλ
i=µ+1w′
i)2
/summationtextλ
i=µ+1w′
i2.(9)
The learning rates coefficient are as follows,
cm= 1,
c1=2
(d+ 1.3)2+µeff,
cµ= min/parenleftbigg
1−c1,2µeff−2 + 1/µeff
(d+ 2)2+µeff/parenrightbigg
.(10)
The weight coefficients wiis set as,
wi=

1/summationtextµ
i=1w′
iw′
i ifw′
i>0,
min/parenleftbigg
1 +c1
cµ,1 +2µ−
eff
2 +µeff,1−c1−cµ
ncµ/parenrightbigg1
/summationtextλ
i=µ+1w′
iw′
iifw′
i<0.(11)
Regarding the the covariance matrix update (second line in Eq. (4)), in practice, the evolution path p(t)=/summationtextt
i=0(m(i)−m(i−1))/σ(i)is computed via exponential smoothing. Initialized with p(0)= 0, the exact
formula of the evolution path is as follows,
p(t)= (1−cc)p(t−1)+/radicalbig
cc(2−cc)µeffm(t)−m(t−1)
σ(t−1), (12)
where
cc=4 +µeff/d
d+ 4 + 2µeff/d. (13)
Regarding the βcoefficient in the step size update (third line in Eq. (4)), the exact formula is as follows,
β(t)= exp/parenleftigg
cσ
dσ/parenleftigg
∥p(t)
σ∥√
d−1/parenrightigg/parenrightigg
, (14)
22Published in Transactions on Machine Learning Research (01/2024)
where
cσ=2 +µeff
d+ 5 + 2µeff,
dσ= 1 + 2 max/parenleftbigg
0,/radicalbiggµeff−1
d+ 1−1/parenrightbigg
+cσ,
p(t)
σ= (1−cc)p(t−1)
σ +/radicalbig
cc(2−cc)µeffC(t−1)−1
2m(t)−m(t−1)
σ(t−1),withp(0)
σ= 0.(15)
A.4 Pseudocode of the CMA-based BO Algorithms
We present the pseudocode for the local optimization steps of CMA-BO,CMA-TuRBO andCMA-BAxUS . These are
the detailed implementation of line 12 in Algorithm 1 depending on the BO optimizer bo_opt. Note that,
as discussed in the base algorithm in Section 4.2, when performing the local optimization step, we first need
to sample a pool of ncdata points following the previous search distribution, then perform BO to select the
data points. In practice, we set nc= min(100dc,5000)wheredc=d, the dimensionality of the problem, for
CMA-BOandCMA-TuRBO ordc=dV, the current target dimensionality, for CMA-BAxUS . This value of ncis the
same as in TuRBOwhen selecting sampling data points for the TS acquisition function.
Algorithm 2 Local Optimization for CMA-BO.
1:Input: Objective function f(.), search distribution N(m,Σ), local regionS, dataset Ω, number of
sampling points nc
2:Output: A new observed data {xnext,ynext}
3:Train a GP from Ω
4:Samplencdata pointsA={xj}nc
j=1fromN(m,Σ)and constrained within S
5:Propose a next observed data xnext= arg minx∈AαTS(x)
6:Evaluate the observed data ynext=f(xnext) +ε
7:Return{xnext,ynext}
Algorithm 3 Local Optimization for CMA-TuRBO .
1:Input:Objective function f(.), search distribution N(m,ΣCMA-TuRBO ), local regionSCMA-TuRBO, dataset Ω,
number of sampling points nc
2:Output: A new observed data {xnext,ynext}
3:Train a GP from Ω
4:Samplencdata pointsA={xj}nc
j=1fromN(m,ΣCMA-TuRBO )and constrained within SCMA-TuRBO
5:Propose a next observed data xnext= arg minx∈AαTS(x)
6:Evaluate the observed data ynext=f(xnext) +ε
7:Return{xnext,ynext}
Algorithm 4 Local Optimization for CMA-BAxUS .
1:Input:Objective function f(.), search distribution NV(mV,ΣCMA-BAxUS ), local regionSV,CMA-BAxUS, dataset
Ω, number of sampling points nc, embedding matrix Q:V→X
2:Output: A new observed data {xnext,vnext,ynext}in bothXandV
3:Train a GP from {vi,yi}|Ω|
i=1∈Ω
4:Samplencdata pointsA={vj}nc
j=1fromN(mV,ΣCMA-BAxUS )and constrained within SV,CMA-BAxUS
5:Propose a next observed data vnext= arg minv∈AαTS(v)andxnext=Qvnext
6:Evaluate the observed data ynext=f(xnext) +ε
7:Return{xnext,vnext,ynext}
23Published in Transactions on Machine Learning Research (01/2024)
A.5 Experimental Setup
We use Matérn 5/2 ARD kernels for the GPs in all methods. The input domains of all problems are scaled
to have equal domain lengths in all dimensions as in Loshchilov & Hutter (2016). The output observations
are normalized following a Normal distribution y∼N(0,1).
For the hyperparameters of the CMA strategy in all CMA-based BO and ES methods, we set them using the
suggested values in Hansen (2016). Specifically, the population size λis set to be 4 +⌊3 + lnd⌋. The initial
mean vector m(0)is selected by minimizing 20initial data points following a Latin hypercube sampling
(Jones, 2001). The covariance matrix C(0)is initialized with an identity matrix Id, and the initial step size
σ(0)is set to 0.3(u−l)whereu,ldenote the upper and lower bounds of the search domain X, i.e.,X= [l,u]d.
To ensure fair comparison between the CMA-based BO methods and the corresponding BO optimizers, we
set the hyperparameters of the CMA-based BO methods to be the same as those of the corresponding BO
optimizers. Specifically, for BOandCMA-BO, the hyperparameter settings of the GP and the TS acquisition
function of these methods are the same. For TuRBOandCMA-TuRBO , we follow the same setting suggested by
TuRBO(Eriksson et al., 2019) to set the initial TR base side length L0, the maximum and minimum TR side
lengthsLmaxandLmin, and the success and failure threshold τsuccandτfail. For BAxUSandCMA-BAxUS , we
alsofollowthesamesettingsuggestedby BAxUS(Papenmeieretal.,2022)tosettheinitialTRbasesidelength
L0, the maximum and minimum TR side lengths LmaxandLmin, the success and failure thresholds τsucc
andτfail, and the bin size b. All the developed CMA-based BO methods ( CMA-BO,CMA-TuRBO ,CMA-BAxUS )
are implemented using GPyTorch (Gardner et al., 2018) as with TuRBOand BAxUS. All the Python-based
methods are run with the same Python package versions.
A.6 Baselines
To evaluate the baseline methods described in Section 5, we use the implementation and hyperparameter
settings provided in the authors’ public source code and their respective papers. Note that for DTS-CMAES
and BADS, the authors’ implementation source code is in Matlab, so to ensure consistency in the objective
function evaluation process with other baselines, we call Python from Matlab to evaluate the objective
function values. All the methods are initialized with 20 initial data points and are run for 10 repeats with
different random seeds. All experimental results are averaged over these 10independent runs. We then
report the mean and the standard error of the simple regret or the best optimal value found. Details of the
implementation for each baseline in the paper are as follows.
BO.This is the standard BOmethod with the TS acquisition function. The GP is constructed with the
Matérn 5/2 ARD kernel and is fitted using the Maximum Likelihood method. The domains of the input
variables in all problems are scaled to have equal domain lengths in all dimensions (Loshchilov & Hutter,
2016). The output observations {yi}are normalized following a Normal distribution N(0,1).
TuRBO (Eriksson et al., 2019). We set all the hyperparameters of TuRBOas suggested in their paper.
This includes the upper and lower bound for TR side length Lmax= 1.6,Lmin= 2−7, batch size b= 1and
the TR adaptation threshold τsucc= 3,τfail=⌈max (4/b,d/b )⌉wheredis the dimension of the problem. We
use their implementation that is made available at https://github.com/uber-research/TuRBO .
BAxUS (Papenmeier et al., 2022). We set all the hyperparameters of BAxUSas suggested in their
paper. This includes the upper and lower bound for TR side length Lmax= 1.6,Lmin= 2−7, the TR
adaptation threshold τsucc= 3and bin size b= 3, budget to input dim mDis set to the maximum budget.
We use their implementation that is made available at https://github.com/LeoIV/BAxUS .
LA-MCTS (Wang et al., 2020). We set all the hyperparameters of LA-MCTS as suggested in their
paper. This includes the exploration factor in UCB Cp= 1, the kernel type of SVM is RBF and the splitting
thresholdθ= 20. For Levy function, we use different settings, which is recommended in the author’s
24Published in Transactions on Machine Learning Research (01/2024)
implementation code1, i.e.,Cp= 10, polynomial kernel, θ= 8. We use their implementation that is made
available at https://github.com/facebookresearch/LaMCTS .
MCTSVS (Song et al., 2022). We set all the hyperparameters of MCTS-VS as suggested in their paper.
This includes the exploration factor in UCB Cp= 1, the fill-in strategy of "best-k" with k= 20, the
feature batch size Nv= 2, the sample batch size Ns= 3, the tree re-initialization threshold Nbad= 5,
the node splitting threshold Nsplit = 3. We use their implementation that is made available at https:
//github.com/lamda-bbo/MCTS-VS .
CMAES (Hansen & Ostermeier, 2001). We use the default settings as suggested in the paper, which
is similar to our settings for CMA-BO. This includes the population size λ= 4 +⌊3 + lnd⌋wheredis the
problem dimension, the random initial mean vector m(0)selected from the minimum of the 20 random initial
points, the identity initial covariance matrix C(0)=Idand the initial step-size σ(0)= 0.3(u−lb)where
the domain is scaled to uniform bound of [l,u]d. We also activate the restart mechanism of CMA-ESso that
the algorithm can restart when it converges to a local minimum. We use their implementation that is made
available at https://github.com/CMA-ES/pycma .
DTS-CMAES (Bajer et al., 2019). We set all the hyperparameters of DTS-CMAES as suggested in their
paper. We use the doubly-trained GP configuration with the population size λ= 8 +⌊6 + lnd⌋wheredis
the problem dimension, initial mean vector m(0)selected from the minimum of the 20 random initial points,
the identity initial covariance matrix C(0)=Idand the initial step-size σ(0)= 0.3(u−lb)where the domain
is scaled to uniform bound of [l,u]dand fixed learning rate β= 0.05. We use their implementation that is
made available at https://github.com/bajeluk/surrogate-cmaes .
BADS (Acerbi & Ma, 2017) We set all the hyperparameters of BADSas suggested in their paper and the
Matlab package. We use their implementation that is made available at https://github.com/acerbilab/
bads.
A.7 Synthetic and Real-world Benchmark Problems
Weconductexperimentsoneightsyntheticandthreereal-worldbenchmarkproblemstoevaluateallmethods.
Synthetic Problems. We use Levy-100D, Alpine-100D, Rastrigin-100D, Ellipsoid-100D, Schaffer2-100D,
Branin2-500D, and two modified versions, Shifted-Levy-100D and Shifted-Alpine-100D. For Branin2-500D,
we use the implementation from Papenmeier et al. (2022); Wang et al. (2016) where the function is created
by adding additional 498 dummy dimensions to the original Branin 2D function, resulting in a function with
the dimension dto be 500. Schaffer2-100D is implemented similarly with 98 dummy dimensions added to the
original Schaffer 2D function. The Levy-100D, Alpine-100D, Rastrigin-100D and Ellipsoid-100D are common
test functions2used in BO research, and we set the dimension dto be 100 for each function. Additionally,
for Levy-100D and Alpine-100D, we create two new versions, namely Shifted-Alpine-100D and Shifted-Levy-
100D, where we shift the global optimum away from the original global optimum by uniformly random
shifting, i.e., we set fshifted (x) =foriginal (x+δ)withδ= [δ1,...,δd]∈[l,u]100andδi∼U(l,u). The search
domains of these two functions, X= [l,u]d, are kept the same as in the original functions. The motivation
behind including these two shifted synthetic problems for evaluation is that, based on our observations, some
sparse embedding methods (e.g., BAxUS) have considerable advantages when the global optimum is at the
center of the search domain, thus, we also evaluate all methods on problems where the global optima are
not at the search domain’s center.
Real-world Problems. We use the following real-world problems: Half-cheetah-102D, LassoDNA-180D
and Rover-100D. For Half-cheetah-102D, we use the same implementation as described in Song et al. (2022),
1https://github.com/facebookresearch/LaMCTS/blob/489bd60886f23b0b76b10aa8602ea6722f334ad6/LA-MCTS/
functions/functions.py
2https://www.sfu.ca/~ssurjano/optimization.html
25Published in Transactions on Machine Learning Research (01/2024)
which parameterizes the Half-cheetah-v4 Mujoco environment from the Gym package3into a 102D rein-
forcement learning (RL) problem. The goal of this problem is to optimize the parameters of a linear policy
designed to solve the RL task. These Mujoco RL tasks have been used in many works, such as Wang et al.
(2020); Nguyen et al. (2020); Song et al. (2022). For LassoDNA-180D, we use the implementation from the
Python LassoBench library (Šehić et al., 2022) as in Papenmeier et al. (2022). The problem LassoDNA-180D
solves the Least Absolute Shrinkage and Selection Operator (LASSO) problem using the DNA dataset from
a microbiology problem. The LassoBench suite has been used in several previous works, such as Papenmeier
et al. (2022); Ziomek & Ammar (2023). For Rover-100D, we use the implementation provided by Wang et al.
(2018). This problem optimizes the locations of 50 points in a 2D-plane trajectory of a rover, resulting in a
100D benchmark function. The goal is to maximize the reward calculated based on the number of collisions
along the rover trajectory. The Rover function has been used in various research works, e.g., Wang et al.
(2018); Eriksson et al. (2019); Eriksson & Poloczek (2021); Nguyen et al. (2022).
A.8 Running time of all methods
We report the average running time per each iteration in Table 1. The results demonstrate that the running
time of our proposed CMA-based BO methods is very similar to the running time of the BO optimizers we
incorporate. This demonstrate the efficacy of our proposed meta-algorithm.
Table 1: Average time (in second) for each iteration run in each method.
Average time
per iteration
(s)Alpine
100DLevy
100DShifted
Alpine
100DShifted
Levy
100DEllipsoid
100DRastrigin
100DSchaffer2
100DBranin2
500D
CMA-BO 3.3 3.28 3.62 3.46 3.21 5.48 3.07 6.8
CMA-TuRBO 3.13 3.17 3.33 3.34 3.24 3.17 2.98 9.19
CMA-BAxUS 8.68 21.27 21.28 21.4 8.27 9.32 5.93 15.19
BO 5.7 5.69 5.63 5.61 5.57 5.6 2.57 1.73
TuRBO 5.32 5.29 5.28 5.53 5.39 5.45 2.46 2.97
BAxUS 9.61 21.79 21.42 20.62 7.56 8.61 7.04 9.36
MCTSVS-BO 0.96 0.36 1.5 1.18 0.48 0.63 0.25 0.43
MCTSVS-TuRBO 0.24 0.27 0.79 0.8 0.27 0.23 0.13 0.21
LAMCTS-TuRBO 3.53 3.51 10.03 8.99 3.46 3.45 1.95 2.39
CMA-ES 4.6E-04 3.2E-03 4.4E-04 2.9E-03 4.4E-04 1.7E-03 4.7E-04 1.0E-03
BADS 1.52 1.74 1.78 1.6 1.18 1.7 0.28 0.29
DTS-CMAES 0.06 0.05 0.05 0.05 0.06 0.05 0.03 0.44
A.9 Additional Trajectory Plots of the Local Regions by the CMA-based Meta-algorithm
Weshowtheremainingtrajectoryplotsofthelocalregionsdefinedby CMA-BOandCMA-TuRBO intheremaining
synthetic functions: Alpine-2D (Fig. 10), Levy-2D (Fig. 11), Shifted-Levy-2D (Fig. 12), Branin-2D (Fig.
13), Ellipsoid-2D (Fig. 14), Schaffer-2D (Fig. 15) and Rastrigin-2D (Fig. 16).
A.10 Additional Results of Schaffer2-100D
As an expansion of Fig. 9, we show in Fig. 17 all the repeats of the 2D plot for Schaffer2-100D functions.
3https://www.gymlibrary.dev/index.html
26Published in Transactions on Machine Learning Research (01/2024)
10
01010
010Iteration 0
10
010Iteration 2
10
010Iteration 4
10
010Iteration 7
10
010Iteration 8
10
010Iteration 10
105
103
101
101
10
01010
010Iteration 0
L=0.4
10
010Iteration 2
L=0.2
10
010Iteration 4
L=0.025
10
010Iteration 7
L=0.4
10
010Iteration 8
L=0.4
10
010Iteration 10
L=0.1
105
103
101
101
10
 0 1010
010Iteration 0
L=0.8
Global minimum
Data proposed by BO
 Ellipse mean vector
Local region
Base local region
10
 0 10Iteration 3
L=0.1
10
 0 10Iteration 6
L=0.0125
10
 0 10Iteration 9
L=0.8
105
103
101
101
Figure 10: Trajectories of the local regions defined by CMA-based BO methods, CMA-BO(upper) and
CMA-TuRBO (lower), for Alpine 2D function. The function global optimum is at [0,0].
10
01010
010Iteration 0
10
010Iteration 2
10
010Iteration 4
10
010Iteration 5
10
010Iteration 8
10
010Iteration 10
105
103
101
101
10
01010
010Iteration 0
L=0.4
10
010Iteration 2
L=0.05
10
010Iteration 4
L=0.025
10
010Iteration 5
L=0.4
10
010Iteration 8
L=0.05
10
010Iteration 10
L=0.0125
105
103
101
101
10
 0 1010
010Iteration 0
L=0.8
Global minimum
Data proposed by BO
 Ellipse mean vector
Local region
Base local region
10
 0 10Iteration 3
L=0.1
10
 0 10Iteration 6
L=0.0125
10
 0 10Iteration 9
L=0.8
105
103
101
101
Figure 11: Trajectories of the local regions defined by CMA-based BO methods, CMA-BO(upper) and
CMA-TuRBO (lower), for Levy 2D function. The function global optimum is at [1,1].
27Published in Transactions on Machine Learning Research (01/2024)
10
01010
010Iteration 0
10
010Iteration 2
10
010Iteration 4
10
010Iteration 7
10
010Iteration 8
10
010Iteration 10
105
103
101
101
10
01010
010Iteration 0
L=0.8
10
010Iteration 2
L=0.4
10
010Iteration 4
L=0.05
10
010Iteration 7
L=0.8
10
010Iteration 8
L=0.4
10
010Iteration 10
L=0.1
105
103
101
101
10
 0 1010
010Iteration 0
L=0.8
Global minimum
Data proposed by BO
 Ellipse mean vector
Local region
Base local region
10
 0 10Iteration 3
L=0.1
10
 0 10Iteration 6
L=0.0125
10
 0 10Iteration 9
L=0.8
105
103
101
101
Figure 12: Trajectories of the local regions defined by CMA-based BO methods, CMA-BO(upper) and
CMA-TuRBO (lower), for Shifted-Levy 2D function. The function global optimum is at [3,−4].
-52.5 1007.515
Iteration 0
-52.5 10
Iteration 2
-52.5 10
Iteration 5
-52.5 10
Iteration 8
-52.5 10
Iteration 10
-52.5 10
Iteration 12
105
103
101
101
-52.5 1007.515
Iteration 0
L=0.8
-52.5 10
Iteration 2
L=0.4
-52.5 10
Iteration 5
L=0.05
-52.5 10
Iteration 8
L=0.8
-52.5 10
Iteration 10
L=0.8
-52.5 10
Iteration 12
L=0.2
105
103
101
101
10
 0 1010
010Iteration 0
L=0.8
Global minimum
Data proposed by BO
 Ellipse mean vector
Local region
Base local region
10
 0 10Iteration 3
L=0.1
10
 0 10Iteration 6
L=0.0125
10
 0 10Iteration 9
L=0.8
105
103
101
101
Figure 13: Trajectories of the local regions defined by CMA-based BO methods, CMA-BO(upper) and
CMA-TuRBO (lower), for Branin 2D function. The function has 3 global optima at [−π,12.275],[π,2.275]
and[9.42478,2.475].
28Published in Transactions on Machine Learning Research (01/2024)
10
01010
010Iteration 0
10
010Iteration 2
10
010Iteration 5
10
010Iteration 6
10
010Iteration 8
10
010Iteration 12
105
103
101
101
10
01010
010Iteration 0
L=0.4
10
010Iteration 2
L=0.2
10
010Iteration 5
L=0.0125
10
010Iteration 6
L=0.8
10
010Iteration 8
L=0.4
10
010Iteration 12
L=0.0125
105
103
101
101
10
 0 1010
010Iteration 0
L=0.8
Global minimum
Data proposed by BO
 Ellipse mean vector
Local region
Base local region
10
 0 10Iteration 3
L=0.1
10
 0 10Iteration 6
L=0.0125
10
 0 10Iteration 9
L=0.8
105
103
101
101
Figure 14: Trajectories of the local regions defined by CMA-based BO methods, CMA-BO(upper) and
CMA-TuRBO (lower), for Ellipsoid 2D function. The function global optimum is at [0,0].
100
0100100
0100Iteration 0
100
0100Iteration 8
100
0100Iteration 20
100
0100Iteration 24
100
0100Iteration 32
100
0100Iteration 40
103
102
101
100
0100100
0100Iteration 0
L=0.4
100
0100Iteration 8
L=0.4
100
0100Iteration 20
L=0.1
100
0100Iteration 24
L=0.4
100
0100Iteration 32
L=0.4
100
0100Iteration 40
L=0.025
103
102
101
10
 0 1010
010Iteration 0
L=0.8
Global minimum
Data proposed by BO
 Ellipse mean vector
Local region
Base local region
10
 0 10Iteration 3
L=0.1
10
 0 10Iteration 6
L=0.0125
10
 0 10Iteration 9
L=0.8
105
103
101
101
Figure 15: Trajectories of the local regions defined by CMA-based BO methods, CMA-BO(upper) and
CMA-TuRBO (lower), for Schaffer 2D function. The function global optimum is at [0,0].
29Published in Transactions on Machine Learning Research (01/2024)
5
0 55
05Iteration 0
5
0 5Iteration 8
5
0 5Iteration 14
5
0 5Iteration 16
5
0 5Iteration 21
5
0 5Iteration 30
105
103
101
101
5
0 55
05Iteration 0
L=0.4
5
0 5Iteration 8
L=0.1
5
0 5Iteration 14
L=0.8
5
0 5Iteration 16
L=0.2
5
0 5Iteration 21
L=0.8
5
0 5Iteration 30
L=0.025
105
103
101
101
10
 0 1010
010Iteration 0
L=0.8
Global minimum
Data proposed by BO
 Ellipse mean vector
Local region
Base local region
10
 0 10Iteration 3
L=0.1
10
 0 10Iteration 6
L=0.0125
10
 0 10Iteration 9
L=0.8
105
103
101
101
Figure 16: Trajectories of the local regions defined by CMA-based BO methods, CMA-BO(upper) and
CMA-TuRBO (lower), for Rastrigin 2D function. The function global optimum is at [0,0].
30Published in Transactions on Machine Learning Research (01/2024)
100
0100
s=0, i=0, n=37
 s=0, i=11, n=224
 s=0, i=22, n=411
 s=0, i=33, n=598
 s=0, i=44, n=785
 s=0, i=55, n=972
100
0100
s=1, i=0, n=37
 s=1, i=11, n=224
 s=1, i=22, n=411
 s=1, i=33, n=598
 s=1, i=44, n=785
 s=1, i=55, n=972
100
0100
s=2, i=0, n=37
 s=2, i=11, n=224
 s=2, i=22, n=411
 s=2, i=33, n=598
 s=2, i=44, n=785
 s=2, i=55, n=972
100
0100
s=3, i=0, n=37
 s=3, i=11, n=224
 s=3, i=22, n=411
 s=3, i=33, n=598
 s=3, i=44, n=785
 s=3, i=55, n=972
100
0100
s=4, i=0, n=37
 s=4, i=11, n=224
 s=4, i=22, n=411
 s=4, i=33, n=598
 s=4, i=44, n=785
 s=4, i=55, n=972
Global minimum
CMA-BO
CMA-ES
100
0100
s=5, i=0, n=37
 s=5, i=11, n=224
 s=5, i=22, n=411
 s=5, i=33, n=598
 s=5, i=44, n=785
 s=5, i=55, n=972
100
0100
s=6, i=0, n=37
 s=6, i=11, n=224
 s=6, i=22, n=411
 s=6, i=33, n=598
 s=6, i=44, n=785
 s=6, i=55, n=972
100
0100
s=7, i=0, n=37
 s=7, i=11, n=224
 s=7, i=22, n=411
 s=7, i=33, n=598
 s=7, i=44, n=785
 s=7, i=55, n=972
100
0100
s=8, i=0, n=37
 s=8, i=11, n=224
 s=8, i=22, n=411
 s=8, i=33, n=598
 s=8, i=44, n=785
 s=8, i=55, n=972
100
 0 100100
0100
s=9, i=0, n=37
100
 0 100
s=9, i=11, n=224
100
 0 100
s=9, i=22, n=411
100
 0 100
s=9, i=33, n=598
100
 0 100
s=9, i=44, n=785
100
 0 100
s=9, i=55, n=972
Figure 17: 2D plots for Schaffer2-100D projecting on the 2 effective dimensions for 10 repeats. CMA-ESalways
tends to over explore whilst CMA-BOgenerally finds more meaningful data points.
31