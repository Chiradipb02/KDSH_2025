Published in Transactions on Machine Learning Research (10/2023)
Straggler-Resilient Personalized Federated Learning
Isidoros Tziotis isidoros_13@utexas.edu
The University of Texas at Austin
Zebang Shen zebang.shen@inf.ethz.ch
ETH Zurich
Ramtin Pedarsani ramtin@ece.ucsb.edu
The University of California, Santa Barbara
Hamed Hassani hassani@seas.upenn.edu
The University of Pennsylvania
Aryan Mokhtari mokhtari@austin.utexas.edu
The University of Texas at Austin
Reviewed on OpenReview: https: // openreview. net/ forum? id= gxEpUFxIgz& referrer= %5BAuthor% 20
Abstract
Federated Learning isanemerginglearningparadigmthatallowstrainingmodelsfromsamples
distributed across a large network of clients while respecting privacy and communication
restrictions. Despite its success, federated learning faces several challenges related to its
decentralized nature. In this work, we develop a novel algorithmic procedure with theoretical
speedup guarantees that simultaneously handles two of these hurdles, namely (i) data
heterogeneity , i.e., data distributions can vary substantially across clients, and (ii) system
heterogeneity , i.e., the computational power of the clients could diﬀer signiﬁcantly. By
leveraging previous works in the realm of representation learning (Collins et al., 2021; Liang
et al., 2020), our method constructs a global common representation utilizing the data from
all clients. Additionally, it learns a user-speciﬁc set of parameters, resulting in a personalized
solution for each individual client. Furthermore, it mitigates the eﬀects of stragglers by
adaptivelyselectingclientsbasedontheircomputationalcharacteristics, thusachievingforthe
ﬁrst time near-optimal sample complexity and provable logarithmic speedup. Experimental
results support our theoretical ﬁndings showing the superiority of our method over alternative
personalized federated schemes in system and data heterogeneous environments.
1 Introduction
Due to growing concerns on data privacy and communication cost, Federated Learning (FL) has become
an emerging learning paradigm as it allows for training machine learning models without collecting local
data from the clients. Due to its decentralized nature, a major challenge in designing eﬃcient solvers for
FL is heterogeneity of local devices which can be categorized into two diﬀerent types: (i) data heterogeneity
where the underlying data distributions of clients vary substantially, and (ii) system heterogeneity where the
computational and storage capabilities of devices diﬀer signiﬁcantly. In fact, it has been observed that the
seminal Federated Averaging ( FedAvg) method suﬀers from slow convergence to a high quality solution when
facing highly heterogeneous datasets (McMahan et al., 2017) as well as heterogeneous systems (Li et al., 2020;
Kairouz et al., 2021).
In this paper, we aim to address these two challenges simultaneously by introducing a generic framework that
includes algorithms with robust performance in the presence of those forms of clients’ heterogeneity. Inspired
by prior works in the literature of FL (Collins et al., 2021; Liang et al., 2020) that utilized representation
1Published in Transactions on Machine Learning Research (10/2023)
learning theory to tackle data heterogeneity, we propose a meta-algorithm that produces personalized
solutions and handles data heterogeneity by leveraging a global representation shared among all clients.
Further, our method circumvents the delays introduced due to the presence of stragglers by carefully selecting
participating nodes based on their computational speeds. In early stages, only a few of the fastest nodes are
chosen to participate and sequentially slower devices are included in the training process until the target
accuracy is achieved. Although the disproportional selection of nodes raises fairness and accuracy concerns,
we highlight that our method achieves speedup without compromising the resulting solution. The most
signiﬁcant contribution of our work is achieving near-optimal sample complexity in regimes with data and
system heterogeneity, alongside a provable logarithmic speedup guarantee in terms of running time. Next we
summarize our contributions:
1.SRPFLAlgorithm . We propose Straggler-Resilient Personalized Federated Learning ( SRPFL), an
adaptive node participation meta-algorithm that builds upon subroutines that fall into the repre-
sentation learning framework (Collins et al., 2021; Liang et al., 2020) enhancing their resilience to
stragglers and performance.
2.Logarithmic Speedup . Assuming that clients’ speeds are drawn from the exponential distribution,
weprovethat SRPFLguaranteeslogarithmicspeedupinthelinearrepresentationsetting, outperforming
established, straggler-prone benchmarks while maintaining the state of the art sample complexity
per clientm=O((d/N +log(N))), wheredandNdenote the feature vector size and number of
active nodes. Our results hold for non-convex loss functions, heterogeneous data and dynamically
changing client’s speeds.
3.Numerical Results . Experiments on various datasets (CIFAR10, CIFAR100, EMNIST, FEMNIST,
Sent140) support our theoretical results showing that: (i) SRPFLsigniﬁcantly boosts the performance
of diﬀerent subroutines designed for personalized FL both in full and partial participation settings
and (ii) SRPFLexhibits superior performance in system and data heterogeneous settings compared to
state-of-the-art baselines.
1.1 Related Work
Data heterogeneity. In data heterogeneous settings, if one aims at minimizing the aggregate loss in
the network using the classic FedAvgmethod or more advanced algorithms, which utilize control-variate
techniques, such as SCAFFOLD (Karimireddy et al., 2019), FEDGATE (Haddadpour et al., 2021), FedDyn(Acar
et al., 2021) or FEDSHUFFLE (Horváth et al., 2022) the resulting solution could perform poorly for some of the
clients. This is an unavoidable hurdle due to the fact that no single model works well for all clients when their
underlying data distributions are diverse. A common technique that addresses this issue is ﬁne-tuning the
derived global model to each local task by following a few steps of SGD updates (Wang et al., 2019; Yu et al.,
2020). Based on this observation, Fallah et al. (2020b) showed that one might need to train models that work
well after ﬁne-tuning and showed its connections to Model-Agnostic Meta-Learning (MAML). In (Cho et al.,
2022; Balakrishnan et al., 2021) novel client-sampling schemes were explored achieving increased eﬃciency
in regimes with data heterogeneity. Another line of work for personalized FL is learning additive mixtures
of local and global models (Deng et al., 2020; Mansour et al., 2020; Hanzely and Richtárik, 2020). These
methods learn local models for clients that are close to each other in some norm, an idea closely related to
multi-task FL (Smith et al., 2017; Hu et al., 2021). The works in (Chen et al., 2022; Lee et al., 2022) studied
the interplay of local and global models utilizing Bayesian hierarchical models and partial participation,
respectively. An alternative approach was presented by Collins et al. (2021), where instead of enforcing local
models to be close, the authors assumed that models across clients share a common representation. Using
this perspective, they presented FedRepa method that provably learns this underlying structure in the linear
representation setting. Building upon the idea of a common representation Zhu et al. (2021) and Jiang and
Lin (2022) proposed federated methods that can handle data heterogeneity while exhibiting robustness to
distribution shifts. Recently, a novel framework was proposed allowing the comparison of personalized FL
methods under various metrics (Wu et al., 2022). In all of the aforementioned methods however, a subset
of clients participate regardless of their computational capabilities. Thus, in the presence of stragglers, the
2Published in Transactions on Machine Learning Research (10/2023)
speed of the training process signiﬁcantly goes down as the server waits, at every communication round, for
the slowest participating node to complete its local updates.
System heterogeneity. Several works have attempted to address the issue of system heterogeneity.
Speciﬁcally, asynchronous methods, which rely on bounded staleness of slow clients, have demonstrated
signiﬁcant gains in distributed data centers (Xie et al., 2019; Stich, 2019; So et al., 2021). In FL frameworks,
however, stragglers could be arbitrarily slow casting these methods ineﬃcient. In an attempt to manually
controlstaleness, deadline-basedcomputationhasbeenproposed(Reisizadehetal.,2019)aswellasaggregation
of a ﬁxed number of models per round (Nguyen et al., 2022). However, in the worst case scenario the
performance of these methods is still determined by the slowest client in the network. Active sampling is
another approach where the server aggregates as many local updates as possible within a predeﬁned time
span (Nishio and Yonetani, 2019). In a diﬀerent line of work the eﬀects of stragglers are mitigated by utilizing
computation/gradient coding schemes (Tandon et al., 2017; Wang et al., 2018; 2020b). In (Cho et al., 2021)
clients use heterogeneous model-architectures to transfer knowledge to nodes with similar data distributions
while Yang et al. (2022) proposed a new framework where clients are free to choose their participation scheme.
More recently, normalized averaging methods were proposed in (Wang et al., 2020a; Horváth et al., 2022)
that rectify the objective inconsistency created by the mismatch in clients’ updates. FedLin(Mitra et al.,
2021) instead utilizes gradient correction and error-feedback mechanisms to circumvent the speed-accuracy
conﬂict. A novel approach to mitigate the eﬀects of stragglers was proposed by Reisizadeh et al. (2022),
where clients are selected to take part in diﬀerent stages of the training according to their computational
characteristics. Alas, all of the above methods yield improvement only in data-homogeneous settings and
they are not applicable in regimes with data heterogeneity.
2 Problem Formulation
In this section, we introduce our setting and deﬁne the data and system heterogeneity model that we
study. Consider the FL framework where Mclients interact with a central server. We focus on a supervised,
data-heterogeneous setting where client idraws samples from distribution Di, potentially with Di/negationslash=Dj.
Further, consider the learning model of the i-th client as qi:Rd− →Ywhich maps inputs xi∈Rdto predicted
labelsqi(xi)∈Y. The objective function of client iis deﬁned as fi(qi) :=E(xi,yi)∼Di[/lscript(qi(xi),yi))], where
the loss/lscript:Y×Y− → Rpenalizes the gap between the predicted label qi(xi)and true label yi. In the most
general setting clients aim to solve
min
(q1,...,qM)∈Q1
MM/summationdisplay
i=1fi(qi), (1)
withQthe space of feasible tuples of mappings (q1,...,qM). Traditionally in FL, methods focus on learning a
single model q=q1=...=qMthat performs well on average across clients (Li et al., 2020; McMahan et al.,
2017). Although such a solution may be satisfactory in data-homogeneous settings, it leads to undesirable local
models when the data distributions are diverse. Indeed, in the presence of data heterogeneity the loss functions
fihave diﬀerent forms and their minimizers could be far from each other. This justiﬁes the formulation in (1)
and necessitates the search for personalized solutions that can be learned in federated fashion.
Low Dimensional Common Representation . There have been numerous examples in image classiﬁcation
and word prediction where tasks with heterogeneous data share a common, low dimensional representation,
despite having diﬀerent labels (Bengio et al., 2013; LeCun et al., 2015; Pillutla et al., 2022). Based on that,
a reasonable choice for Qis a set in which all qishare a common map, coupled with a personalized map
that ﬁts their local data. To formalize this, suppose the ground-truth map can be written for each client i
asqi=hi◦φwhereφ:Rd− →Rkis a shared global representation which maps d-dimensional data points to a
lower dimensional space of size kandhi:Rk− →Y, which maps from the lower dimensional subspace to the
space of labels. Typically k/lessmuchdand thus given any ﬁxed representation φ, the client speciﬁc heads hi:Rk− →Y
are easy to optimize locally. With this common structure into consideration, (1)can be reformulated as
minφ∈Φ1
M/summationtextM
i=1minhi∈Hfi(hi◦φ), where Φis the class of feasible representation and His the class of feasible
heads. This formulation leads to good local solutions, if the underlying data generation models for the clients
share a low dimensional common representation, i.e., yi=h∗
i◦φ∗(xi) +zi, whereziis some additive noise.
3Published in Transactions on Machine Learning Research (10/2023)
Figure 1: Classic FL schemes for solving (2)
Figure 2: SRPFLfor solving (2)
The server and clients collaborate to learn the common representation φ, while locally each client learns
their unique head hi. Since clients often do not have access to their true data distributions, instead of
minimizing their expected loss, they settle for minimizing the empirical loss associated with their local
samples. Speciﬁcally, we assume client ihas access to Sisamples{x1
i,x2
i,...,xSi
i}, and its local empirical loss
isˆfi(hi◦φ) =1
Si/summationtextSi
s=1/lscript(hi◦φ(xs
i),ys
i). Hence, the global problem becomes
min
φ∈Φ1
MM/summationdisplay
i=1min
hi∈H/braceleftBigg
ˆfi(hi◦φ) :=1
SiSi/summationdisplay
s=1/lscript(hi◦φ(xs
i),ys
i)/bracerightBigg
(2)
System Heterogeneity Model . In most FL settings, thousands of clients participate in the training process,
each with diﬀerent computational capabilities. Thus, ﬁxed computational tasks such as gradient computations
or local model updates require diﬀerent processing time, for diﬀerent clients. Formally, for each client i∈[M],
we denote byTithe time required to compute a local model update. When a subset of clients participate in
the learning process, the computational time of each round is determined by the slowest participating node.
Naturally, as the number of nodes in the network grows, we expect the number of stragglers to increase. This
phenomenon calls for the development of straggler-resilient methods in system-heterogeneous settings.
3 Straggler-Resilient Personalized FL
In the shared representation setting, we face the challenge of ﬁnding an algorithm that coordinates server and
clients in order to learn a common representation and a set of personalized parameters in a federated and
straggler-resilient fashion. To this end, we propose a method that tackles problem (2)with limited sample
access and provably superior performance over naive, straggler-prone methods. Speciﬁcally, we propose
the Straggler-Resilient Personalized Federated Learning ( SRPFL) meta-algorithm, designed to mitigate the
eﬀects of system heterogeneity in environments with non-convex loss functions and heterogeneous data while
accommodating a variety of methods as subroutines. In a nutshell, SRPFLiteratively solves problem (2), while
adaptively increasing the set of participating nodes based on their computational capabilities. As a result the
process of learning the common representation across clients’ tasks is accelerated, without compromising the
resulting accuracy.
To simplify the exposition, henceforth we denote by Asome federated algorithm of choice, designed to
solve(2). As depicted in Figure 1, in standard FL frameworks, out of all Mclients in the network, the
server often selects uniformly at random a subset of size N. Subsequently, a few iterations of algorithm A
are performed to approximately solve a version of (2)which corresponds to those Nselected clients i.e.,
minφ∈Φ1
N/summationtextN
i=1minhi∈Hˆfi(hi◦φ). In every following stage, a new subset of Nnodes is sampled and the
same process is repeated. Although such a procedure eventually learns the global representation across all
tasks, it is susceptible to delays caused by stragglers, as the server has to wait for the slowest client (among
theNselected ones) to complete its updates. Hence, when Nis large the training procedure could become
prohibitively slow.
4Published in Transactions on Machine Learning Research (10/2023)
SRPFLtakes a diﬀerent approach in order to mitigate the eﬀects of straggling clients. An overview of the
selecting scheme is provided in Figure 2. At each stage, Nclients are randomly selected, but only a small, fast
subset of them is used to solve their corresponding learning problem. More precisely, suppose that at stage r,
each client iin the sampled subset of size N, is associated with a computational time Tr
i. For simplicity we
assume that the nodes are re-indexed at every stage so that they maintain a decreasing ordering w.r.t. their
times, i.e.Tr
1≤Tr
2≤...≤Tr
N. Initially, only the n0fastest clients,{1,2,...,n 0}, are included in the learning
procedure, with n0much smaller than N. At every communication round, the set of n0nodes perform the
model updates indicated by algorithm A, to solve their version of (2), i.e., minφ∈Φ1
n0/summationtextn0
i=1minhi∈Hˆfi(hi◦φ).
We note that during this stage of the algorithm, the server waits only for the slowest client among the
participating ones, i.e., client n0which is potentially much faster than node N.
Remark 3.1.In practice, the knowledge of clients’ computational power is not required to ﬁgure out the n0
fastest nodes. Instead, the server sends the global representation model to all Nsampled clients and updates
the common representation once the ﬁrst n0new models are received. Indeed, these representations belong
to the fastest n0nodes.
Once the current stage terminates, a new batch of Nclients is sampled and the 2n0fastest nodes are chosen
to participate in the learning process. Since speeds vary across stages, consecutive sets of participating nodes
could have small or no overlap. However, the representations learned in previous stages still operate as good
starting points for subsequent stages which is possible since nodes are homogeneous w.r.t. their representations
(see Section 2). Thus, utilizing the representation model learned from the previous stage, nodes {1,2,...,2n0}
continue the learning process deriving a model of improved accuracy. The procedure of geometrically increasing
the number of participating nodes continues until the target accuracy is achieved. Hence, SRPFLuses the
data of stragglers only at the latest stages of the algorithm when an accurate approximation is required.
Remark 3.2.For simplicity of exposition we assume that the set of Nsampled nodes maintains connectivity
to the server throughout each stage. However, our analysis remains unaﬀected even if a new set of nodes is
sampled at every round.
Weproceedtocharacterizetheclassoffederatedalgorithmsabletoemploy SRPFLtoenhancetheirperformance
in system heterogeneous environments. Any iterative method that solves an instance of (2)can be combined
with our adaptive node participation scheme, however in this paper, we focus on a broad class of alternating
gradient-based update methods, presented in (Collins et al., 2021). As the name suggests, in each round,
clients update their heads and representation models in an alternative fashion. After a certain number of
gradient updates is completed, all clients send their derived representations to the server where the models
are averaged and broadcasted back to the clients. Next, we rigorously illustrate this procedure.
Alternating Update Scheme . At round t, the server communicates a common representation φtto the
clients and a subset of them It, are selected to participate by performing the following updates.
Client Head Update . Each client i∈Itperformsτhlocal gradient-based updates optimizing their head
parameter, given the received representation φt. Concretely, for s= 1,...,τhclientiupdates their head
model as follows
ht,s
i=GRD/parenleftBig
fi/parenleftBig
ht,s−1
i,φt/parenrightBig
,ht,s−1
i,η/parenrightBig
. (3)
Client Representation Update . Once the updated local heads ht,τh
iare obtained, each client iexecutesτφ
local updates on their representation parameters. That is for s= 1,...,τφ
φt,s
i=GRD/parenleftBig
fi/parenleftBig
ht,τh
i,φt,s−1
i/parenrightBig
,φt,s−1
i,η/parenrightBig
. (4)
In the above expressions, GRD (f,h,η )captures the generic notion of an update of variable husing the
gradient of function fwith respect to hand step size η. This notation allows the inclusion of a large class of
algorithms such as Gradient Descent with momentum, SGD, etc.
Server Update . Each client isends their derived representation models φt,τφ
ito the server, where they are
averaged producing the next representation model φt+1.
Coupling SRPFLwith a generic subroutine that falls into the Alternating Update Scheme, gives rise to
Algorithm 1. Every stage ris characterized by a participating set of size 2r·n0, denoted byIr. At the
5Published in Transactions on Machine Learning Research (10/2023)
Algorithm 1 SRPFL
1:Input:Initial number of nodes n0; step sizeη;
number of local updates for head τh; number of local updates for representation τφ.
2:Initialization: n←n0,φ0,h0,τh
1,...,h0,τh
N
3:forr= 0,1,2,..., log(N/n 0)do
4:φ0←φr
5:fort= 1,2,...,τrdo
6:Server sends representation φt−1toNclients sampled from [M].
7:fori∈Irdo
8: Clientiinitializesht,0
i←ht−1,τh
iand runsτhupdatesht
i=ht
i−η∇ht
ifi(ht
i,φt−1).
9: Clientiinitializesφt,0
i←φt−1and runsτφupdatesφt
i=φt
i−η∇φt
ifi(ht
i,φt
i).
10: Clientisendsφt,τφ
ito the server.
11:end for
12:foreach client i /∈Irdo
13:ht,τh
i←ht−1,τh
i
14:end for
15:Server computes φt←1
n/summationtextn
i=1φt,τφ
i.
16:end for
17:Server sets n←min{N,2n}andφr+1←φτr.
18:end for
beginning of each round the server provides a representation model to the participating clients (line 6). The
clients update their models (lines 8and9) and sent their representations back to the server where they are
averaged producing a new global model. The numbers of local updates τh,τφdepend on the subroutine
method of choice and the number of rounds per stage is denoted by τr. At the end of every stage the set of
participating nodes is doubling in size until a set of size Nis reached (line 17).
Remark 3.3 summarizes the technical novelties of our work and highlights crucial beneﬁts enjoyed by SRPFL.
Remark 3.3.Reisizadeh et al. (2022) proposed a similar participation scheme, however their approach diﬀers
from ours and their results apply to signiﬁcantly more restrictive regimes. Speciﬁcally, in (Reisizadeh et al.,
2022) the analysis heavily relies on deriving a connection between the ERM solutions of consecutive stages. In
order to control the statistical accuracy of the corresponding ERM problems (i) data homogeneity across all
clients is necessary and further (ii) clients who participate in early stages are required to remain active and
connected to the server in all subsequent stages, maintaining ﬁxed computational speeds throughout the whole
training process. (iii) The results of their analysis hold only for strongly convex loss functions and (iv) their
stage termination criterion requires the knowledge of the strong convexity parameter. The above restrictions
are detrimental in the FL regime and severely undermine the applicability of the resulting algorithm.
In our work we follow a diﬀerent approach controlling -in terms of principal angle distance - a quantity
analogous to statistical accuracy, therefore directly connecting the common representation (and overall
solution) at every stage to the ground truth representation. This novel approach allows our algorithm to
accommodate (i) data heterogeneity, (ii) clients with dynamically changing speeds or equivalently clients that
are replaced by new ones at every round, and (iii) non-convex loss functions. Additionally, a major part of
our technical contribution focuses on (iv) analytically deriving the optimal number of rounds per stage, thus
producing a simple and eﬃcient doubling scheme.
4 SRPFL in the Linear Representation Case
Our theoretical analysis focuses on a speciﬁc instance of (1), where clients strive to solve a linear representation
learning problem. Concretely we assume that fiis the quadratic loss, φis a projection onto a k-dimensional
subspace of Rd, given by matrix B∈Rd×kand thei-th client’s head hi, is a vector wi∈Rk. We model local
data of client isuch thatyi=w∗/latticetop
iB∗/latticetopxi+zi, for some ground truth representation B∗∈Rd×k, local heads
w∗
i∈Rkandzi∼N(0,σ2)capturing the noise in the measurements. Hence, all clients’ optimal solutions lie
6Published in Transactions on Machine Learning Research (10/2023)
Algorithm 2 FedRep-SRPFL (Linear Representation)
1:Input:Step sizeη; Batch size m; Initial nodes n0;
2:Initialization: Clienti∈[N]sends to server: Pi:=1
m/summationtextm
j=1(y0,j
i)2x0,j
i(x0,j
i)/latticetop, n←n0.
3:Server ﬁnds UDU/latticetop←rank-kSVD(1
N/summationtextN
i=1Pi).
4:forr= 0,1,2,..., log(N/n 0)do
5:Server initializes representation Br,0←U.
6:fort= 1,2,...,τrdo
7:Server sends Br,ttoNclients sampled from [M].
8:fori∈{1,..,n}do
9: Clientisamples a fresh batch of msamples.
10: Clienticomputes wr,t+1
i←arg minwˆft
i(w,Br,t).
11: Clienticomputes Br,t+1
i←Br,t−η∇Bˆft
i(wt+1
i,Br,t)and sends it back to the server.
12:end for
13:Server computes ¯Br,t+1←1
n/summationtext
i∈ItBr,t+1
i.
14:Server computes Br,t+1,Rr,t+1←QR(¯Br,t+1).
15:end for
16:Server sets U←¯Br,t+1andn←min{N,2n}.
17:end for
in the same k-dimensional subspace. Under these assumptions the global expected risk is
min
B,W1
2MM/summationdisplay
i=1E(xi,yi)∼Di/bracketleftBig/parenleftbig
yi−w/latticetop
iB/latticetopxi/parenrightbig2/bracketrightBig
, (5)
where W= [w/latticetop
1,...,w/latticetop
N]∈RN×kis the concatenation of the client-speciﬁc heads. Since the true distributions
Di’s are unknown, algorithms strive to minimize the empirical risk instead. The global empirical risk over all
clients is
1
MM/summationdisplay
i=1ˆfi(wi,B)=1
2MmM/summationdisplay
i=1m/summationdisplay
j=1/parenleftBig
yj
i−wt/latticetop
iB/latticetopxj
i/parenrightBig2
, (6)
wheremis the number of samples at each client. The global loss in (6)is nonconvex and has many global
minima, including all pairs of/parenleftbig
W∗Q−1,B∗Q/latticetop/parenrightbig
, where Q∈Rk×kis some invertible matrix. Thus, the server
aims to retrieve the column space of B∗, instead of the ground truth factors (W∗,B∗). To measure closeness
between column spaces, we adopt the metric of principal angle distance (Jain et al., 2013).
Deﬁnition 4.1. Let matrices B1,B2∈Rd×kandˆB1,⊥,ˆB2orthonormal matrices s.t. span(ˆB1,⊥) =span(B1)⊥
andspan(ˆB2) =span(B2). The principle angle distance between the column spaces of B1andB2is deﬁned
to be dist (B1,B2) :=/bardblˆB/latticetop
1,⊥ˆB2/bardbl2.
Federated Representation Learning ( FedRep) is an alternating minimization-descent algorithm, recently
proposed in (Collins et al., 2021) for the Linear Shared Representation framework. SRPFLcoupled with
FedRepgives rise to Algorithm 2. Below we highlight the main points of interest.
In the initialization phase (lines 2and3) a model of bounded distance from the optimal representation is
obtained, via the Method of Moments (Tripuraneni et al., 2021). Subsequently, at every round t, clienti
samples a fresh batch of samples {xt,j
i,yt,j
i}m
j=1from its local distribution (line 9) and thus the corresponding
loss function becomes ˆfi(wi◦B):=1
2m/summationtextm
j=1(yt,j
i−w/latticetop
iB/latticetopxt,j
i)2. Utilizing the global representation provided
by the server, client icomputes the optimal head wi(line 10). Fixing the newly computed head, client i
proceeds to update its global representation model with one step of gradient descent (line 11) and transmits
it back to the server. As depicted in lines 13and14the parameter server averages the models received and
orthogonalizes the resulting matrix before broadcasting it to the clients, a component of crucial importance
required in our analysis.
Mapping this method back to Algorithm 1 we note that the number of representation model updates τφis
set to 1, whereas the number of head updates τhis suﬃciently large to derive (approximately) the optimal
solutions. This imbalance is designed to take advantage of the inherent structure of our problem where the
7Published in Transactions on Machine Learning Research (10/2023)
size of wi’s is signiﬁcantly smaller than d. Finally, we point out that the number of the communication
rounds per stage τris a small and a priori known to the algorithm constant, speciﬁed by our analysis.
Remark 4.2.Although our proposed method utilizes FedRepas a backbone, our analysis and framework
diﬀer substantially from the ones in (Collins et al., 2021). Speciﬁcally, Collins et al. (2021) assume access to
(i) inﬁnite samples, (ii) without the presence of noise. Additionally, (iii) the number of participating nodes
remains ﬁxed throughout the training and (iv) the focus lies solely on handling heterogeneous data with system
heterogeneity being an orthogonal direction to their work. In contrast, our analysis requires only (i) ﬁnite
and (ii) noisy samples, and our theoretical results (Theorems 4.7 and 4.9) revolve around (iii) participating
subsets of diﬀerent sizes and (iv) regimes where both data and system heterogeneity is prevalent.
4.1 Theoretical Results
In this subsection, we provide rigorous analysis of FedRep-SRPFL in the linear representation setting. First,
we present the notion of Wall Clock Time (WCT) which is the measure of the performance for our algorithm.
Subsequently, we illustrate the contraction inequality that determines the rate at which the distance to the
optimal representation diminishes. We conclude showing that FedRep-SRPFL outperforms its straggler-prone
variant by a factor of O(logN), under the standard assumption that clients’ computational times follow the
exponential distribution. Before we proceed, we introduce the necessary notation and the assumptions.
E0: = 1−dist2/parenleftbig
B0,B∗/parenrightbig
, (7)
¯σmax,∗:= max
I∈[N],|I|=n,n0≤n≤Nσmax/parenleftbigg1√nW∗
I/parenrightbigg
, (8)
¯σmin,∗:= min
I∈[N],|I|=n,n0≤n≤Nσmin/parenleftbigg1√nW∗
I/parenrightbigg
(9)
Assumption 4.3. (Sub-gaussian design). The local samples xi∈Rdare i.i.d. with mean 0, covariance Id
and are Id-sub-gaussian, i.e. E[ev/latticetopxi]≤e/bardblv/bardbl2
2/2for all v∈Rd.
Assumption 4.4. (Client diversity). Let ¯σmin,∗deﬁned in (9), be the minimum singular value of any matrix
that can be obtained by taking nrows of1√nW∗. Then ¯σmin,∗>0.
Speciﬁcally, our theoretical analysis requires Assumption 4.4 to be satisﬁed for every n≥n0. Assumption 4.4
implies that the optimal heads, of the participating clients, span Rk. This is true in many FL regimes as the
number of clients is usually much larger than the dimension of the shared representation.
Remark 4.5.In this work we consider client speeds being independent of the local data available to them.
This is a natural assumption since the computational power of each client crucially depends on their device
characteristics (battery, CPU, etc.), whereas any connection to their local data is unclear. However, in the
presence of strong correlation between data and system heterogeneity, Assumption 4.4 may not hold, which
can be seen as a potential limitation of our work and an interesting future direction to explore.
Assumption 4.6. (Client normalization). The ground-truth client speciﬁc parameters satisfy /bardblw∗
i/bardbl2=√
k
for alli∈[n]andB∗has orthonormal columns.
Assumption 4.6 ensures the ground-truth matrix W∗B∗/latticetopis row-wise incoherent , i.e. its row norms have
similar magnitudes. This is of vital importance since our measurement matrices are row-wise sparse and
incoherence is a common requirement in sensing problems with sparse measurements.
Wall Clock Time. To measure the speedup that our meta-algorithm enjoys we use the concept of real time
or WCT as described below. FedRep-SRPFL runs in communication rounds grouped into stages. Consider such
a roundtat stager, with nodes{1,2,...,nr}participating in the learning process. Here nrdenotes the slowest
participating node. The expected amount of time that the server has to wait for the updates to take place
isE/bracketleftbig
Tr
nr/bracketrightbig
. Put simply, the expected computational time of the slowest node acts as the bottleneck for the
round. Further, at the beginning and at the end of every round, models are exchanged between the server and
the clients. This incurs an additional, ﬁxed communication cost C. Ifτrcommunication rounds take place at
every stage r, then the overall expected WCT for FedRep-SRPFL isE[TSRPFL ]=/summationtextlog(N/n 0)
r=0τr·/parenleftbig
E/bracketleftbig
Tr
nr/bracketrightbig
+C/parenrightbig
.
Similarly, the total expected runtime for FedRepcan be expressed in terms of the total number of rounds, TFR,
asE[TFedRep ]=TFR(E[Tr
N]+C).Taking the ratio of these quantities derives the desired speedup guarantee.
8Published in Transactions on Machine Learning Research (10/2023)
0.00 0.95 1.90 2.85 3.80
T otal Time (C.T.=0)1e220304050607080T esting AccuracyCIFAR10, M=100, Shard=5
FedRep-SRPFL
FedRep
LG-SRPFL
LG-FedAvg
FLANP
FLANP-FT
FedAvg
FedAvg-FT
HFMAML
0.00 0.95 1.90 2.85 3.80
T otal Time (C.T.=0)1e2102030405060T esting AccuracyCIFAR100, N=100, Shard=20
0.00 0.72 1.44 2.16 2.88
T otal Time (C.T.=0)1e22030405060708090T esting AccuracyEMNIST, N=100, Shard=5
0.00 0.72 1.44 2.16 2.88
T otal Time (C.T.=0)1e2102030405060708090T esting AccuracyFEMNIST, N=100, Shard=3
0.00 1.75 3.50 5.25 7.00
T otal Time (C.T.=10)1e220304050607080T esting AccuracyCIFAR10, N=100, Shard=5
0.00 1.65 3.30 4.95 6.60
T otal Time (C.T.=10)1e2102030405060T esting AccuracyCIFAR100, N=100, Shard=20
0.00 1.42 2.84 4.26 5.68
T otal Time (C.T.=10)1e22030405060708090T esting AccuracyEMNIST, N=100, Shard=5
0.00 1.42 2.84 4.26 5.68
T otal Time (C.T.=10)1e2102030405060708090T esting AccuracyFEMNIST, N=100, Shard=3
0.000 0.812 1.624 2.436 3.248
T otal Time (C.T.=100)1e320304050607080T esting AccuracyCIFAR10, N=100, Shard=5
0.000 0.795 1.590 2.385 3.180
T otal Time (C.T.=100)1e3102030405060T esting AccuracyCIFAR100, N=100, Shard=20
0.000 0.772 1.544 2.316 3.088
T otal Time (C.T.=100)1e32030405060708090T esting AccuracyEMNIST, N=100, Shard=5
0.000 0.772 1.544 2.316 3.088
T otal Time (C.T.=100)1e3102030405060708090T esting AccuracyFEMNIST, N=100, Shard=3
Figure 3: Numerical results on CIFAR10, CIFAR100, EMNIST, FEMNIST with full participation ( M=N)
in the ﬁxed computation speeds setting. ‘Shard’ denotes the number of classes per client. ‘C.T.’ denotes the
communication cost per round.
Contraction Inequality. Theorem 4.7 captures the progress made between two consecutive rounds of
FedRep-SRPFL . It follows that the rate of convergence to the optimal representation is exponentially fast,
provided that the number of participating nodes and the batch size are suﬃciently large.
Theorem 4.7. Let Assumptions 4.3-4.6 hold. Further, let the following inequalities hold for the number of
participating nodes and the batch size respectively, n≥n0andm≥c0(1+σ2)k3κ4
E2
0max{log(N),d/n 0}, for
some absolute constant c0. Then FedRep-SRPFL with stepsize η≤1
8¯σ2max,∗, satisﬁes the following contraction
inequality:
dist/parenleftbig
Bt+1,B∗/parenrightbig
≤dist/parenleftbig
Bt,B∗/parenrightbig√
1−a+a/radicalBig
n
n0(1−a), (10)
w.p. at least 1−T·exp/parenleftbig
−90 min/braceleftbig
d,k2log(N)/bracerightbig/parenrightbig
, wherea=1
2ηE0¯σ2
min,∗≤1
4.
HereTdenotes the total number of communication rounds which is logarithmic w.r.t. the target error /epsilon1. The
initial representation computed by the Method of Moments satisﬁes dist/parenleftbig
B0,B∗/parenrightbig
≤1−CM, for some constant
CM. SinceE0is strictly greater than zero inequality (10) ensures contraction.
Remark4.8.Theorem 4.7 suggests that the server can learn the ground-truth representation before some of the
clients update their local heads or participate in the learning process. This might raise concerns about fairness
or accuracy, however it is important to highlight that such concerns are unfounded. This is because, after
obtaining it the server shares the ground-truth representation with all the clients in the system. Thus, even if
a clientiwas not selected in the representation learning process, it can still optimize its low-dimensional head
wi∈Rkusing its local samples through a few local updates (given that kis a small constant). Consequently,
the derivation of the ground-truth model beneﬁts both the clients that already participated in the learning
procedure as well as new clients who opt to join the federated system at a later time.
Logarithmic Speedup. Algorithm 2 sets oﬀ with n0participating clients and follows a doubling scheme so
that at stage ronly the fastest 2rn0nodes contribute to the learning process. Thus at stage r, inequality (10)
can be written as:
dist+≤dist·√
1−α+α/radicalbig
2r(1−α)(11)
9Published in Transactions on Machine Learning Research (10/2023)
0.00 1.09 2.18 3.27 4.36
T otal Time (C.T.=0)1e220304050607080T esting AccuracyCIFAR10, M=100, Shard=5
FedRep-SRPFL
FedRep
LG-SRPFL
LG-FedAvg
FLANP
FLANP-FT
FedAvg
FedAvg-FT
HFMAML
0.00 1.09 2.18 3.27 4.36
T otal Time (C.T.=0)1e2102030405060T esting AccuracyCIFAR100, M=100, Shard=20
0.00 1.09 2.18 3.27 4.36
T otal Time (C.T.=0)1e2405060708090T esting AccuracyEMNIST, M=100, Shard=5
0.00 1.09 2.18 3.27 4.36
T otal Time (C.T.=0)1e2102030405060708090T esting AccuracyFEMNIST, M=100, Shard=3
0.00 1.51 3.02 4.53 6.04
T otal Time (C.T.=10)1e220304050607080T esting AccuracyCIFAR10, M=100, Shard=5
0.00 1.69 3.38 5.07 6.76
T otal Time (C.T.=10)1e2102030405060T esting AccuracyCIFAR100, M=100, Shard=20
0.00 1.51 3.02 4.53 6.04
T otal Time (C.T.=10)1e2405060708090T esting AccuracyEMNIST, M=100, Shard=5
0.00 1.51 3.02 4.53 6.04
T otal Time (C.T.=10)1e2102030405060708090T esting AccuracyFEMNIST, M=100, Shard=3
0.000 0.534 1.068 1.602 2.136
T otal Time (C.T.=100)1e320304050607080T esting AccuracyCIFAR10, M=100, Shard=5
0.000 0.709 1.418 2.127 2.836
T otal Time (C.T.=100)1e3102030405060T esting AccuracyCIFAR100, M=100, Shard=20
0.000 0.534 1.068 1.602 2.136
T otal Time (C.T.=100)1e3405060708090T esting AccuracyEMNIST, M=100, Shard=5
0.000 0.534 1.068 1.602 2.136
T otal Time (C.T.=100)1e3102030405060708090T esting AccuracyFEMNIST, M=100, Shard=3
Figure 4: Numerical results on CIFAR10, CIFAR100, EMNIST, FEMNIST with partial participation
(N=M/5) in the ﬁxed computational speeds setting. ‘Shard’ denotes the number of classes per client.
‘C.T.’ denotes the communication cost per round.
We note that the second term on the r.h.s. is an artifact of the noisy measurements. Utilizing geometric series
properties we can deduce that in the limit, contraction (11)converges to α/√
2r(1−α)(1−√1−α).This implies
that the achievable error of our algorithm is lower bounded by α//radicalbig
N
n0(1−α)(1−√1−α), since the total number
of stages is at most r= log (N/n 0).
To illustrate the theoretical beneﬁts of SRPFLwe compare Algorithm 2 to FedRep. One can distill FedRep
from Algorithm 2 by disregarding the doubling scheme and instead at each round, randomly sampling N
nodes to participate. For fair comparison between the two methods we set the target error small enough so
that the contribution of all Nnodes is necessary. Speciﬁcally, we express the error /epsilon1as
/epsilon1= ˆcα/radicalBig
N
n0(1−α)/parenleftbig
1−√1−α/parenrightbig,with√
2>ˆc>1. (12)
Intuitively, one should expect FedRep-SRPFL to vastly outperform straggler-prone FedRepasˆcapproaches√
2(large error), since in this case the biggest chunk of the workload is completed before FedRep-SRPFL
utilizes the slower half of the clients. In contrast, FedRepexperiences heavy delays throughout the whole
training process due to the inclusion of stragglers at every round. On the contrary, as ˆcapproaches 1(small
error), the amount of rounds spent by FedRep-SRPFL utilizingNclients increases. In this case one should
expect the speedup achieved by FedRep-SRPFL in early stages, to eventually become obsolete. Theorem 4.9
provides a rigorous exposition of these insights.
Theorem 4.9. Suppose that at each stage the client’s computational times are i.i.d. random variables drawn
from the exponential distribution with parameter λ. Further, suppose that the expected communication cost
per round isC=c
λ, for some constant c. Finally, consider the target error /epsilon1given in (12). Then, we have
E[TSRPFL ]
E[TFedRep ]=O/parenleftbigg
log(1
ˆc−1)
log(N)+log(1
ˆc−1)/parenrightbigg
.
10Published in Transactions on Machine Learning Research (10/2023)
0.00 0.71 1.42 2.13 2.84
T otal Time (C.T.=0)1e220304050607080T esting AccuracyCIFAR10, M=100, Shard=5
FedRep-SRPFL
FedRep
LG-SRPFL
LG-FedAvg
FLANP
FLANP-FT
FedAvg
FedAvg-FT
HFMAML
0.00 0.71 1.42 2.13 2.84
T otal Time (C.T.=0)1e2102030405060T esting AccuracyCIFAR100, N=100, Shard=20
0.00 0.55 1.10 1.65 2.20
T otal Time (C.T.=0)1e22030405060708090T esting AccuracyEMNIST, N=100, Shard=5
0.00 0.55 1.10 1.65 2.20
T otal Time (C.T.=0)1e2102030405060708090T esting AccuracyFEMNIST, N=100, Shard=3
0.00 1.51 3.02 4.53 6.04
T otal Time (C.T.=10)1e220304050607080T esting AccuracyCIFAR10, N=100, Shard=5
0.00 1.51 3.02 4.53 6.04
T otal Time (C.T.=10)1e2102030405060T esting AccuracyCIFAR100, N=100, Shard=20
0.00 1.25 2.50 3.75 5.00
T otal Time (C.T.=10)1e22030405060708090T esting AccuracyEMNIST, N=100, Shard=5
0.00 1.25 2.50 3.75 5.00
T otal Time (C.T.=10)1e2102030405060708090T esting AccuracyFEMNIST, N=100, Shard=3
0.000 0.788 1.576 2.364 3.152
T otal Time (C.T.=100)1e320304050607080T esting AccuracyCIFAR10, N=100, Shard=5
0.000 0.788 1.576 2.364 3.152
T otal Time (C.T.=100)1e3102030405060T esting AccuracyCIFAR100, N=100, Shard=20
0.000 0.755 1.510 2.265 3.020
T otal Time (C.T.=100)1e32030405060708090T esting AccuracyEMNIST, N=100, Shard=5
0.000 0.755 1.510 2.265 3.020
T otal Time (C.T.=100)1e3102030405060708090T esting AccuracyFEMNIST, N=100, Shard=3
Figure 5: Numerical results on CIFAR10, CIFAR100, EMNIST, FEMNIST with full participation ( M=N)
in the random (dynamic) computation speeds setting. ‘Shard’ denotes the number of classes per client.
‘C.T.’ denotes the communication cost per round.
Theorem 4.9 establishes O(logN)speedup for our method compared to its straggler prone benchmark. This
result holds when speeds are drawn once at the beginning of the process as well as when new speeds are
drawn at every round thus rendering our method versatile in a broad class of settings.
Remark 4.10.Our analysis is crucially intertwined with the representation learning framework where the
presence of a shared, global representation serves as common ground across data-heterogeneous clients
allowing us to show that intermediate solutions constitute good starting points and substantial progress is
achieved between stages. Despite FedAvgbeing a general-purpose algorithm not designed for representation
learning, it was recently shown to recover the ground-truth representation in the case of multi-task linear
regression (Collins et al., 2022), thus casting FedAvga potential candidate subroutine for our method.
Remark4.11.The initialization phase of Algorithm 2 requires a one-time exchange of information between the
clients and the server. Although this process reveals only the sum of outer products of local samples, it can be
further fortiﬁed using diﬀerential privacy techniques, such as the ones in (Jain et al., 2021; Shen et al., 2022).
5 Experiments
In our empirical study we consider the classiﬁcation tasks for the CIFAR10, CIFAR100, EMNIST, FEMNIST
and Sent140 datasets. We conduct experiments under the full and partial participation scheme with diﬀerent
computation speed distributions comparing the performance of our proposed method against other state-of-
the-art benchmarks. Due to space limitation, in this section we present the results for the image classiﬁcation
tasks in the full and partial participation regime with ﬁxed and dynamic computation speeds. Additional
results and extensive discussion can be found in Appendix C.
Baselines . The ﬁrst benchmarks under consideration are FedRep(Collins et al., 2021) and Local-Global
FedAvg ( LG-FedAvg ) (Liang et al., 2020). These federated methods utilize a mixture of global and local
models to derive personalized solutions with small global loss. Coupling these algorithms with our proposed
doubling scheme gives rise to FedRep-SRPFL andLG-SRPFL , respectively, which are our proposed algorithms
11Published in Transactions on Machine Learning Research (10/2023)
0.000 0.779 1.559 2.338 3.118
T otal Time (C.T.=0)1e420304050607080T esting AccuracyCIFAR10, M=100, Shard=5
FedRep-SRPFL
FedRep
LG-SRPFL
LG-FedAvg
FLANP
FLANP-FT
FedAvg
FedAvg-FT
HFMAML
0.000 0.779 1.559 2.338 3.118
T otal Time (C.T.=0)1e4102030405060T esting AccuracyCIFAR100, M=100, Shard=20
0.00 1.09 2.18 3.27 4.36
T otal Time (C.T.=0)1e2405060708090T esting AccuracyEMNIST, M=100, Shard=5
0.000 0.779 1.559 2.338 3.118
T otal Time (C.T.=0)1e4102030405060708090T esting AccuracyFEMNIST, M=100, Shard=3
0.000 0.784 1.567 2.351 3.135
T otal Time (C.T.=10)1e420304050607080T esting AccuracyCIFAR10, M=100, Shard=5
0.000 0.784 1.567 2.351 3.135
T otal Time (C.T.=10)1e4102030405060T esting AccuracyCIFAR100, M=100, Shard=20
0.000 0.784 1.567 2.351 3.135
T otal Time (C.T.=10)1e45060708090T esting AccuracyEMNIST, M=100, Shard=5
0.000 0.784 1.567 2.351 3.135
T otal Time (C.T.=10)1e4102030405060708090T esting AccuracyFEMNIST, M=100, Shard=3
0.000 0.822 1.644 2.466 3.288
T otal Time (C.T.=100)1e420304050607080T esting AccuracyCIFAR10, M=100, Shard=5
0.000 0.822 1.644 2.466 3.288
T otal Time (C.T.=100)1e4102030405060T esting AccuracyCIFAR100, M=100, Shard=20
0.000 0.822 1.644 2.466 3.288
T otal Time (C.T.=100)1e45060708090T esting AccuracyEMNIST, M=100, Shard=5
0.000 0.822 1.644 2.466 3.288
T otal Time (C.T.=100)1e4102030405060708090T esting AccuracyFEMNIST, M=100, Shard=3
Figure 6: Numerical results on CIFAR10, CIFAR100, EMNIST, FEMNIST with partial participation ( M=N)
in the random (dynamic) computation speeds setting. ‘Shard’ denotes the number of classes per client.
‘C.T.’ denotes the communication cost per round.
for the numerical experiments. We further compare our methods with FLANP(Reisizadeh et al., 2022) and
FedAvg(McMahan et al., 2017) with and without ﬁne-tuning. Note that the ﬁne-tuning variants are also
considered as they often lead to better performance in data-heterogeneous settings (Wang et al., 2019; Yu
et al., 2020). Our ﬁnal baseline is the HF-MAML algorithm from (Fallah et al., 2020a) which is a Model Agnostic
Meta Learning-based method producing high quality personalized solutions in data-heterogeneous settings.
Data allocation. To ensure that our data allocation is heterogeneous we randomly split the data points
among the clients in a way that each client can only observe a speciﬁc subset of classes. For instance, in the
CIFAR10 dataset where there are in total 10diﬀerent classes of data points, each client is only assigned data
from 5diﬀerent classes, which we refer to as Shards; see ﬁrst column of Figure 3. We also make sure that the
test set for each client is consistent with the samples they have access to at training time, e.g., if client ionly
observes samples with labels 1,4,5during training, then at test time they are only asked to classify samples
from the same classes. Further details and diﬀerent allocation schemes are presented in Appendix C.
Simulation of System Heterogeneity. We consider two diﬀerent types of client speed conﬁgurations:
Fixed computation speeds. In this conﬁguration we sample a value for each client from the exponential
distribution with parameter λ, once at the beginning of the training process. These personalized values
capture the computational time of every client and remain ﬁxed throughout the training procedure. In
addition to the computational time, our methods suﬀer a ﬁxed communication cost at every round. In
Figures 3 to 6 each row depicts the eﬀects of diﬀerent values of communication cost on the convergence of the
algorithms under consideration (C.T. = 0,10,1001).
Dynamic computation speeds. In this conﬁguration every client samples at every round their processing times
from a personalized exponential distribution that remains ﬁxed throughout the process. Speciﬁcally, at the
beginning of the training process we sample for each client ia parameter λifrom the uniform distribution
over [1/M,1]. Subsequently, at every round we sample a new computational time for each client ifrom the
exponential distribution with parameter λi. Similarly to the former setting an additional, ﬁxed communication
1For reference the computational times are sampled with λ=1.
12Published in Transactions on Machine Learning Research (10/2023)
cost is incurred at every round contributing to the overall running time. As we illustrate in Figure 5 (full
participation) and 6 (partial participation - %20), the experimental results under this conﬁguration are
qualitatively similar to the ones presented in Figure 3 (full participation) and Figure 4(partial participation -
%20) for ﬁxed computation speeds, with SRPFLproviding substantial speedup over straggler prone variants.
Results and Discussions. From the numerical results in Figures 3 to 6 we distill the following takeaways:
1) Coupling SRPFLwith FedRepexhibits consistently superior performance across diﬀerent datasets and
communication time regimes compared to all proposed baselines. 2) Applying SRPFLto personalized FL
solvers ( FedRepand LG-FedAvg ) signiﬁcantly enhances their eﬃciency. 3) The speedup achieved by our
meta-algorithm is more signiﬁcant for smaller values of communication time. Concretely, we observe that the
gap between FedRep-SRPFL andFedRepas well as LG-SRPFL andLG-FedAvg diminishes as the communication
cost increases (plots in the same column C.T. = 0,10,100). This is unsurprising since our method improves
the computational cost of the training and thus when the communication cost dominates the overall running
time, the beneﬁts of SRPFLare less apparent. 4) FedRep-SRPFL vastly outperforms the ﬁne-tuning variant of
the previously proposed FLANP, especially in regimes with high data heterogeneity (FEMNIST).
6 Conclusion
In this paper, we proposed SRPFL, a straggler resilient FL meta-algorithm with near-optimal sample complexity
and provable logarithmic speedup guarantees in regimes with data and system heterogeneity. Our method
leverages ideas from representation learning theory to compute a global representation model along with local
client heads, thus deriving personalized solutions for all clients. In SRPFLthe participating clients are selected
in an adaptive manner. In early stages fast nodes are prioritized and progressively slower nodes are included
in the training process, therefore mitigating the eﬀects of stragglers without compromising the quality of the
solutions. Our numerical results illustrated the beneﬁts of SRPFLwhen coupled with diﬀerent personalized
FL methods such as FedRepandLG-FedAvg . Furthermore, our experiments support our theoretical ﬁndings
showcasing the superior performance of FedRep-SRPFL compared to state-of-the-art FL methods.
Acknowledgments
The research of I. Tziotis and A. Mokhtari is supported in part by NSF Grants 2019844 and 2112471, ARO
Grant W911NF2110226, the Machine Learning Lab (MLL) at UT Austin, and the Wireless Networking and
Communications Group (WNCG) Industrial Aﬃliates Program. The research of Z. Shen and H. Hassani is
supported by the NSF Institute for CORE Emerging Methods in Data Science (EnCORE) as well as The
Institute for Learning-enabled Optimization at Scale (TILOS). The research of R. Pedarsani is supported by
NSF awards 2003035 and 2236483.
References
Acar, D. A. E., Zhao, Y., Matas, R., Mattina, M., Whatmough, P., and Saligrama, V. (2021). Federated
learning based on dynamic regularization. In International Conference on Learning Representations .
Balakrishnan, R., Li, T., Zhou, T., Himayat, N., Smith, V., and Bilmes, J. (2021). Diverse client selection for
federated learning via submodular maximization. In International Conference on Learning Representations .
Bengio, Y., Courville, A., and Vincent, P. (2013). Representation learning: A review and new perspectives.
IEEE Transactions on Pattern Analysis and Machine Intelligence , 35(8):1798–1828.
Chen, H., Ding, J., Tramel, E. W., Wu, S., Sahu, A. K., Avestimehr, S., and Zhang, T. (2022). Actperﬂ:
Active personalized federated learning. In ACL 2022 Workshop on Federated Learning for Natural Language
Processing .
Cho, Y. J., Wang, J., Chiruvolu, T., and Joshi, G. (2021). Personalized federated learning for heterogeneous
clients with clustered knowledge transfer. arXiv preprint arXiv:2109.08119 .
Cho, Y. J., Wang, J., and Joshi, G. (2022). Towards understanding biased client selection in federated
learning. In International Conference on Artiﬁcial Intelligence and Statistics , pages 10351–10375. PMLR.
13Published in Transactions on Machine Learning Research (10/2023)
Collins, L., Hassani, H., Mokhtari, A., and Shakkottai, S. (2021). Exploiting shared representations for
personalized federated learning. In Proceedings of the 38th International Conference on Machine Learning ,
Proceedings of Machine Learning Research. PMLR.
Collins, L., Hassani, H., Mokhtari, A., and Shakkottai, S. (2022). Fedavg with ﬁne tuning: Local updates
lead to representation learning. Advances in Neural Information Processing Systems , 35:10572–10586.
Deng, Y., Kamani, M. M., and Mahdavi, M. (2020). Adaptive personalized federated learning. arXiv preprint
arXiv:2003.13461 .
Fallah, A., Mokhtari, A., and Ozdaglar, A. (2020a). On the convergence theory of gradient-based model-
agnostic meta-learning algorithms. In International Conference on Artiﬁcial Intelligence and Statistics .
PMLR.
Fallah, A., Mokhtari, A., and Ozdaglar, A. (2020b). Personalized federated learning: A meta-learning
approach. arXiv preprint arXiv:2002.07948 .
Haddadpour, F., Kamani, M. M., Mokhtari, A., and Mahdavi, M. (2021). Federated learning with compression:
Uniﬁed analysis and sharp guarantees. In International Conference on Artiﬁcial Intelligence and Statistics .
PMLR.
Hanzely, F. and Richtárik, P. (2020). Federated learning of a mixture of global and local models. arXiv
preprint arXiv:2002.05516 .
Horváth, S., Sanjabi, M., Xiao, L., Richtárik, P., and Rabbat, M. (2022). Fedshuﬄe: Recipes for better use
of local work in federated learning. arXiv preprint arXiv:2204.13169 .
Hu, S., Wu, Z. S., and Smith, V. (2021). Private multi-task learning: Formulation and applications to
federated learning. arXiv preprint arXiv:2108.12978 .
Jain, P., Netrapalli, P., and Sanghavi, S. (2013). Low-rank matrix completion using alternating minimization.
InProceedings of the Forty-Fifth Annual ACM Symposium on Theory of Computing , STOC ’13, page
665–674, New York, NY, USA. Association for Computing Machinery.
Jain, P., Rush, J., Smith, A., Song, S., and Guha Thakurta, A. (2021). Diﬀerentially private model
personalization. Advances in Neural Information Processing Systems , 34:29723–29735.
Jiang, L. and Lin, T. (2022). Test-time robust personalization for federated learning. arXiv preprint
arXiv:2205.10920 .
Kairouz, P., McMahan, H. B., Avent, B., Bellet, A., Bennis, M., Bhagoji, A. N., Bonawitz, K., Charles, Z.,
Cormode, G., Cummings, R., et al. (2021). Advances and open problems in federated learning. Foundations
and Trends ®in Machine Learning .
Karimireddy, S. P., Kale, S., Mohri, M., Reddi, S. J., Stich, S. U., and Suresh, A. T. (2019). Scaﬀold:
Stochastic controlled averaging for on-device federated learning. arXiv preprint arXiv:1910.06378 .
LeCun, Y., Bengio, Y., and Hinton, G. (2015). Deep learning. Nature, 521:436–44.
Lee, S., Sahu, A. K., He, C., and Avestimehr, S. (2022). Partial model averaging in federated learning:
Performance guarantees and beneﬁts. arXiv preprint arXiv:2201.03789 .
Li, T., Sahu, A. K., Zaheer, M., Sanjabi, M., Talwalkar, A., and Smith, V. (2020). Federated optimization in
heterogeneous networks. Proceedings of Machine Learning and Systems , 2:429–450.
Liang, P. P., Liu, T., Ziyin, L., Allen, N. B., Auerbach, R. P., Brent, D., Salakhutdinov, R., and Morency,
L.-P. (2020). Think locally, act globally: Federated learning with local and global representations. arXiv
preprint arXiv:2001.01523 .
Mansour, Y., Mohri, M., Ro, J., and Suresh, A. T. (2020). Three approaches for personalization with
applications to federated learning. arXiv preprint arXiv:2002.10619 .
14Published in Transactions on Machine Learning Research (10/2023)
McMahan, B., Moore, E., Ramage, D., Hampson, S., and Arcas, B. A. y. (2017). Communication-Eﬃcient
Learning of Deep Networks from Decentralized Data. In Proceedings of the 20th International Conference
on Artiﬁcial Intelligence and Statistics , Proceedings of Machine Learning Research. PMLR.
Mitra, A., Jaafar, R., Pappas, G. J., and Hassani, H. (2021). Linear convergence in federated learning:
Tackling client heterogeneity and sparse gradients. In Ranzato, M., Beygelzimer, A., Dauphin, Y., Liang,
P., and Vaughan, J. W., editors, Advances in Neural Information Processing Systems , volume 34, pages
14606–14619. Curran Associates, Inc.
Nguyen, J., Malik, K., Zhan, H., Yousefpour, A., Rabbat, M., Malek, M., and Huba, D. (2022). Federated
learning with buﬀered asynchronous aggregation. In International Conference on Artiﬁcial Intelligence and
Statistics , pages 3581–3607. PMLR.
Nishio, T. and Yonetani, R. (2019). Client selection for federated learning with heterogeneous resources in
mobile edge. In ICC 2019-2019 IEEE International Conference on Communications (ICC) , pages 1–7.
IEEE.
Pillutla, K., Malik, K., Mohamed, A.-R., Rabbat, M., Sanjabi, M., and Xiao, L. (2022). Federated learning
with partial model personalization. In International Conference on Machine Learning , pages 17716–17758.
PMLR.
Reisizadeh, A., Taheri, H., Mokhtari, A., Hassani, H., and Pedarsani, R. (2019). Robust and communication-
eﬃcient collaborative learning. In Proceedings of the 33rd International Conference on Neural Information
Processing Systems , pages 8388–8399.
Reisizadeh, A., Tziotis, I., Hassani, H., Mokhtari, A., and Pedarsani, R. (2022). Straggler-resilient federated
learning: Leveraging the interplay between statistical accuracy and system heterogeneity. IEEE Journal on
Selected Areas in Information Theory .
Shen, Z., Ye, J., Kang, A., Hassani, H., and Shokri, R. (2022). Share your representation only: Guaranteed
improvement of the privacy-utility tradeoﬀ in federated learning. In The Eleventh International Conference
on Learning Representations .
Smith, V., Chiang, C.-K., Sanjabi, M., and Talwalkar, A. S. (2017). Federated multi-task learning. Advances
in neural information processing systems .
So, J., Ali, R. E., Güler, B., and Avestimehr, A. S. (2021). Secure aggregation for buﬀered asynchronous
federated learning. arXiv preprint arXiv:2110.02177 .
Stich, S. U. (2019). Local sgd converges fast and communicates little. In ICLR 2019 ICLR 2019 International
Conference on Learning Representations .
Tandon, R., Lei, Q., Dimakis, A. G., and Karampatziakis, N. (2017). Gradient coding: Avoiding stragglers
in distributed learning. In Precup, D. and Teh, Y. W., editors, Proceedings of the 34th International
Conference on Machine Learning , Proceedings of Machine Learning Research. PMLR.
Tripuraneni, N., Jin, C., and Jordan, M. (2021). Provable meta-learning of linear representations. In
International Conference on Machine Learning , pages 10434–10443. PMLR.
Vershynin, R. (2018). High-Dimensional Probability: An Introduction with Applications in Data Science .
Cambridge Series in Statistical and Probabilistic Mathematics. Cambridge University Press.
Wang, J., Liu, Q., Liang, H., Joshi, G., and Poor, H. V. (2020a). Tackling the objective inconsistency problem
in heterogeneous federated optimization. Advances in neural information processing systems .
Wang, K., Mathews, R., Kiddon, C., Eichner, H., Beaufays, F., and Ramage, D. (2019). Federated evaluation
of on-device personalization. arXiv preprint arXiv:1910.10252 .
15Published in Transactions on Machine Learning Research (10/2023)
Wang, S., Liu, J., and Shroﬀ, N. (2018). Coded sparse matrix multiplication. In Dy, J. and Krause, A.,
editors,Proceedings of the 35th International Conference on Machine Learning , volume 80 of Proceedings
of Machine Learning Research , pages 5152–5160. PMLR.
Wang, S., Liu, J., and Shroﬀ, N. B. (2020b). Fundamental limits of approximate gradient coding. ACM
SIGMETRICS Performance Evaluation Review , 48:21 – 22.
Wu, S., Li, T., Charles, Z., Xiao, Y., Liu, Z., Xu, Z., and Smith, V. (2022). Motley: Benchmarking
heterogeneity and personalization in federated learning.
Xie, C., Koyejo, S., and Gupta, I. (2019). Asynchronous federated optimization. arXiv preprint
arXiv:1903.03934 .
Yang, H., Zhang, X., Khanduri, P., and Liu, J. (2022). Anarchic federated learning. In International
Conference on Machine Learning , pages 25331–25363. PMLR.
Yu, T., Bagdasaryan, E., and Shmatikov, V. (2020). Salvaging federated learning by local adaptation. arXiv
preprint arXiv:2002.04758 .
Zhu, C., Xu, Z., Chen, M., Konečn` y, J., Hard, A., and Goldstein, T. (2021). Diurnal or nocturnal? federated
learning of multi-branch networks from periodically shifting distributions. In International Conference on
Learning Representations .
16Published in Transactions on Machine Learning Research (10/2023)
A Appendix
Before we dive into the analysis we provide the following useful deﬁnition.
Deﬁnition A.1. For a random vector x∈Rd1and a ﬁxed matrix A∈Rd1×d2, the vector A/latticetopxis called
/bardblA/bardbl2-subgaussian if y/latticetopA/latticetopxis subgaussian with subgaussian norm O(/bardblA2/bardbl/bardbly/bardbl2)for all y∈Rd2, i.e.
E/bracketleftbig
exp/parenleftbig
y/latticetopA/latticetopx/parenrightbig/bracketrightbig
≤exp/parenleftBig
/bardbly/bardbl2
2/bardblA/bardbl2
2/2/parenrightBig
.
We study the performance of SSRFRL with FedRep as the subroutine of choice. The ﬁrst part of our analysis
focuses on a single round tand extends the analysis in Collins et al. (2021). We assume that there are N
clients in the network and at round ta subsetItof them participate in the learning procedure with cardinality
n≥n0:=2d
log(N)·¯σmax,∗. Without loss of generality we assume that the clients are indexed from fastest to
slowest thus the clients that participate in the learning process are all i∈[n]. Each client i, draws a batch of
m≥c0(1+σ2)k3κ4log(N)
E2
0fresh, i.i.d. samples at every round. We denote by Xt
i∈Rd×mandYt
i∈Rmthe
matrix of samples and the labels for client i, such that the rows of Xt
iare samples{x1
i,...,xm
i}. ByZt
i∈Rm
we denote the noise in the measurements of client i, withzi,j∼N(0,σ2). Let ˆB∗∈Rd×kandW∗∈RN×k
stand for the optimal representation and the concatenation of optimal heads respectively. The hat denotes
that a matrix is orthonormal i.e. its columns form an orthonormal set. Similarly, ˆBt∈Rd×kandWt∈RN×k
denote the global representation and the concatenation of the heads at round t.w∗
i’s and wt
i’s denote the
optimal heads and the heads at round twhich constitute the rows of W∗andWtrespectively. Furthermore
we deﬁne ¯σmin,∗:=minI∈[N],|I|=n/prime,n/prime≤Nσmin1√
n/primeW∗
Iand¯σmax,∗:=maxI∈[N],|I|=n/prime,n/prime≤Nσmax1√
n/primeW∗
I, where
WIis formed by taking the rows of Windexed byI. That is ¯σmax,∗and ¯σmin,∗are the maximum and
minimum singular values of any submatrix W∗
Ithat can be obtained throughout the course of our algorithm.
Notice that by assumption 4.6 each row of W∗has norm√
k, so1
n/primeacts as a normalization factor such that/vextenddouble/vextenddouble1
n/primeW∗
I/vextenddouble/vextenddouble
F=√
k. Finally we deﬁne κ=¯σmax,∗/¯σmin,∗. Since we focus on a single round the time index can
be dropped for simplicity. Further, henceforth we drop the subscripts ItonWt.
First we derive the update scheme our algorithm follows. Notice that the empirical objective function given
in (6) can be expressed via matrices XiandYi,
LN(B,W) =1
2mnn/summationdisplay
i=1/parenleftBig
Yi−XiˆBwi/parenrightBig2
(13)
Further, computing the gradients we derive
1
2mnn/summationdisplay
i=1∇ˆB/parenleftBig
Yi−XiˆBwi/parenrightBig2
=1
mnn/summationdisplay
i=1X/latticetop
i/parenleftBig
XiˆBwi−Yi/parenrightBig
w/latticetop
i, (14)
1
2mn∇win/summationdisplay
j=1/parenleftBig
Yj−XjˆBwj/parenrightBig2
=1
mnˆB/latticetopX/latticetop
i/parenleftBig
XiˆBwi−Yi/parenrightBig
(15)
and since/parenleftBig
1
mˆB/latticetopX/latticetop
iXiˆB/parenrightBig
is invertible with high probability by Lemma A.4, solving for the minimizer gives
us
w+
i=/parenleftbigg1
mˆB/latticetopX/latticetop
iXiˆB/parenrightbigg−11
mˆB/latticetopX/latticetop
iYi (16)
Thus our update scheme with stepsize ηis
∀i∈[n]w+
i=/parenleftbigg1
mˆB/latticetopX/latticetop
iXiˆB/parenrightbigg−11
mˆB/latticetopX/latticetop
iYi (17)
B+=ˆB−η
mnn/summationdisplay
i=1X/latticetop
i/parenleftBig
XiˆBw+
i−Yi/parenrightBig
w+/latticetop
i (18)
ˆB+,R+=QR(B+) (19)
whereQRdenotes the QR decomposition and Yi=XiˆB∗w∗
i+Zi.
17Published in Transactions on Machine Learning Research (10/2023)
Lemma A.2. For every client ithe update for wican be expressed as follows :
w+
i=ˆB/latticetopˆB∗w∗
i+Fi+Gi, (20)
where FiandGiare deﬁned in equations (24)and(25), respectively.
Proof.Further expanding (17) we can write
w+
i=/parenleftbigg1
mˆB/latticetopX/latticetop
iXiˆB/parenrightbigg−11
mˆB/latticetopX/latticetop
iXiˆB∗w∗
i+/parenleftbigg1
mˆB/latticetopX/latticetop
iXiˆB/parenrightbigg−11
mˆB/latticetopX/latticetop
iZi (21)
=ˆB/latticetopˆB∗w∗
i+/parenleftbigg1
mˆB/latticetopX/latticetop
iXiˆB/parenrightbigg−1/parenleftbigg1
mˆB/latticetopX/latticetop
iXiˆB∗−1
mˆB/latticetopX/latticetop
iXiˆBˆB/latticetopˆB∗/parenrightbigg
w∗
i
+/parenleftbigg1
mˆB/latticetopX/latticetop
iXiˆB/parenrightbigg−11
mˆB/latticetopX/latticetop
iZi (22)
=ˆB/latticetopˆB∗w∗
i+Fi+Gi (23)
where we deﬁne
Fi:=/parenleftbigg1
mˆB/latticetopX/latticetop
iXiˆB/parenrightbigg−1/parenleftbigg1
mˆB/latticetopX/latticetop
iXiˆB∗−1
mˆB/latticetopX/latticetop
iXiˆBˆB/latticetopˆB∗/parenrightbigg
w∗
i, (24)
Gi:=/parenleftbigg1
mˆB/latticetopX/latticetop
iXiˆB/parenrightbigg−11
mˆB/latticetopX/latticetop
iZi (25)
We further have the following immediate corollary.
Corollary A.3. LetW+,FandGbe the matrices with rows the concatenation of w+
i,FiandGi, respectively.
Then
W+=W∗ˆB∗ˆB+F+G (26)
Our ﬁrst goal is to control the norm of w+
i. In order to achieve that we provide lemmas that bound the
norms of FiandGiextending the analysis in Collins et al. (2021) and Jain et al. (2013).
Lemma A.4. Letδ=ck3/2√
log(N)√mfor some absolute constant c, then with probability at least 1−
exp/parenleftbig
−115k3log(N)/parenrightbig
∀i∈[n], σ min/parenleftbigg1
mˆB/latticetopX/latticetop
iXiˆB/parenrightbigg
≥1−δ (27)
It follows that with the same probability
∀i∈[n], σ max/parenleftbigg1
mˆB/latticetopX/latticetop
iXiˆB/parenrightbigg−1
≤1
1−δ(28)
Proof.First notice that we can rewrite
1
mˆB/latticetopX/latticetop
iXiˆB=m/summationdisplay
j=11√mˆB/latticetopxj
i/parenleftbigg1√mˆB/latticetopxj
i/parenrightbigg/latticetop
(29)
For alli∈[n],j∈[m]we deﬁne vj
i:=1√mˆB/latticetopxj
isuch that each vj
iis an i.i.d./bardbl1√mˆB/bardbl2-subgaussian random
variable (please see the deﬁnition of /bardblA/bardbl2-subgaussian in Deﬁnition A.1) and thus by equation (4.22)(Theorem
4.6.1) in Vershynin (2018) we obtain the following bound for any m≥k,l≥0
σmin/parenleftbigg1
mˆB/latticetopX/latticetop
iXiˆB/parenrightbigg
≥1−c1/parenleftBigg/radicalbigg
k
m+l√m/parenrightBigg
, (30)
18Published in Transactions on Machine Learning Research (10/2023)
with probability at least 1−exp/parenleftbig
−l2/parenrightbig
andc1some absolute constant. We set l= 12k3/2log(N)√
kand
δ1=12c1k3/2√
log(N)√mand the above bound becomes
σmin/parenleftbigg1
mˆB/latticetopX/latticetop
iXiˆB/parenrightbigg
≥1−δ1, (31)
with probability at least 1−exp/parenleftbigg
−k/parenleftBig
12k/radicalbig
log(N)−1/parenrightBig2/parenrightbigg
Further notice that
exp/parenleftbigg
−k/parenleftBig
12k/radicalbig
log(N)−1/parenrightBig2/parenrightbigg
= exp/parenleftbig
k/parenleftbig
−144k2log(N) + 24klog(N)−1/parenrightbig/parenrightbig
(32)
≤exp/parenleftbig
−120k3log(N)/parenrightbig
(33)
Thus taking Union Bound over i∈[n]we have that for all i∈[n]
σmin/parenleftbigg1
mˆB/latticetopX/latticetop
iXiˆB/parenrightbigg
≥1−δ1 (34)
with probability at least
1−nexp/parenleftbig
−120k3log(N)/parenrightbig
≥1−exp/parenleftbig
−115k3log(N)/parenrightbig
(35)
Choosingcsuﬃciently large derives the statement of the lemma.
Lemma A.5. LetHi:=/parenleftBig
1√mˆB/latticetopX/latticetop
i/parenrightBig
1√mXi/parenleftBig
ˆBˆB/latticetop−Id/parenrightBig
ˆB∗andδ:=ck3/2√
log(N)√m, for an absolute con-
stantc. Then with probability at least 1−exp/parenleftbig
−115k2log(N)/parenrightbig
we have
n/summationdisplay
i=1/bardblHiw∗
i/bardbl2
2≤δ2/bardblW∗/bardbl2
2dist2/parenleftBig
ˆB,ˆB∗/parenrightBig
(36)
Proof.In order to argue about the quantity Hi=/parenleftBig
1√mˆB/latticetopX/latticetop
i/parenrightBig
1√mXi/parenleftBig
ˆBˆB/latticetop−Id/parenrightBig
ˆB∗we deﬁne matrix
U:=1√mXi/parenleftBig
ˆBˆB/latticetop−Id/parenrightBig
ˆB∗such that its j-th row, uj=1√mˆB∗/latticetop/parenleftBig
ˆBˆB/latticetop−Id/parenrightBig
xj
iis subgaussian with norm
at most1√mˆB∗/latticetop/parenleftBig
ˆBˆB/latticetop−Id/parenrightBig
. Similarly we deﬁne V=1√mˆB/latticetopX/latticetop
isuch that its j-th row vj=1√mˆBxj
ihas
norm at most1√mˆB. We are now ready to use a concentration argument similar to Proposition (4.4.5)in .
LetSk−1denote the unit sphere in kdimensions andNkthe1/4-net of cardinality 9k. From equation (4.13)
in Vershynin (2018) we have
/vextenddouble/vextenddouble/vextenddouble/parenleftBig
ˆB/latticetopX/latticetop
i/parenrightBig
Xi/parenleftBig
ˆBˆB/latticetop−Id/parenrightBig
ˆB∗/vextenddouble/vextenddouble/vextenddouble
2=/vextenddouble/vextenddoubleU/latticetopV/vextenddouble/vextenddouble
2≤2 max
p,y∈Nkp/latticetop
m/summationdisplay
j=1ujv/latticetop
j
y (37)
= 2 max
p,y∈Nkm/summationdisplay
j=1/angbracketleftp,uj/angbracketright/angbracketleftvj,y/angbracketright (38)
By deﬁnition/angbracketleftp,uj/angbracketrightand/angbracketleftvj,y/angbracketrightare subgaussians with norms1√m/vextenddouble/vextenddouble/vextenddoubleˆB∗/latticetop/parenleftBig
ˆBˆB/latticetop−Id/parenrightBig/vextenddouble/vextenddouble/vextenddouble
2=1√mdist/parenleftBig
ˆB,ˆB∗/parenrightBig
and1√mˆ/bardblB/bardbl2=1√mrespectively and thus for all j∈[m]the product/angbracketleftp,uj/angbracketright/angbracketleftvj,y/angbracketrightis subexponential with
norm at mostC/prime
mdist/parenleftBig
ˆB,ˆB∗/parenrightBig
, for some constant C/prime. Note that
E[/angbracketleftp,uj/angbracketright/angbracketleftv,y/angbracketright] =p/latticetop/parenleftBig
ˆB∗/latticetop/parenleftBig
Id−ˆBˆB/latticetop/parenrightBig
ˆB/parenrightBig
y= 0 (39)
19Published in Transactions on Machine Learning Research (10/2023)
and thus we can use Bernstein’s inequality to bound the sum of mzero mean subexponential random variables,
for any ﬁxed pair p,y∈Nk:
P/parenleftBiggm/summationdisplay
i=1/angbracketleftp,uj/angbracketright/angbracketleftvj,y/angbracketright≥s/parenrightBigg
≤exp
−c2min

s2m2
dist2/parenleftBig
ˆB,ˆB∗/parenrightBig,sm
dist/parenleftBig
ˆB,ˆB∗/parenrightBig


 (40)
≤exp
−c2mmin

s2
dist2/parenleftBig
ˆB,ˆB∗/parenrightBig,s
dist/parenleftBig
ˆB,ˆB∗/parenrightBig


 (41)
for constant c2. Thus taking Union Bound over all the point in the net we derive
P
∀p,y∈Nk,2m/summationdisplay
j=1/angbracketleftp,uj/angbracketright/angbracketleftvj,y/angbracketright≥2s
≤92kexp
−c2mmin

s2
dist2/parenleftBig
ˆB,ˆB∗/parenrightBig,s
dist/parenleftBig
ˆB,ˆB∗/parenrightBig



(42)
Sincem>Ck2log(N), by setting s=dist/parenleftBig
ˆB,ˆB∗/parenrightBig/radicalBig
Ck2log(N)
4mand (38) we obtain
P/parenleftBigg
1
m/vextenddouble/vextenddouble/vextenddouble/parenleftBig
ˆB/latticetopX/latticetop
i/parenrightBig
Xi/parenleftBig
ˆBˆB/latticetop−Id/parenrightBig
ˆB∗/vextenddouble/vextenddouble/vextenddouble
2≥dist/parenleftBig
ˆB,ˆB∗/parenrightBig/radicalbigg
Ck2log(N)
m/parenrightBigg
≤92kexp
−c2ms2
dist2/parenleftBig
ˆB,ˆB∗/parenrightBig

(43)
≤92kexp/parenleftbig
−C·c2mk2log(N)/parenrightbig
(44)
≤exp/parenleftbig
−120k2log(N)/parenrightbig
(45)
for suﬃciently large C. Using Union Bound again over all participating clients we get
P/parenleftBigg
∀i∈[n]/bardblHi/bardbl2≤dist/parenleftBig
ˆB,ˆB∗/parenrightBig/radicalbigg
Ck2log(N)
m/parenrightBigg
≥1−nexp/parenleftbig
−120k2log(N)/parenrightbig
(46)
≥1−exp/parenleftbig
−115k2log(N)/parenrightbig
(47)
The above also implies
P/parenleftBigg
1
nn/summationdisplay
i=1/bardblHi/bardbl2
2≤Cdist2/parenleftBig
ˆB,ˆB∗/parenrightBigk2log(N)
m/parenrightBigg
≥1−exp/parenleftbig
−115k2log(N)/parenrightbig
(48)
P/parenleftBigg
k
n/bardblW∗/bardbl2
2n/summationdisplay
i=1/bardblHi/bardbl2
2≤C/bardblW∗/bardbl2
2dist2/parenleftBig
ˆB,ˆB∗/parenrightBigk3log(N)
m/parenrightBigg
≥1−exp/parenleftbig
−115k2log(N)/parenrightbig
(49)
Finally notice that
n/summationdisplay
i=1/bardblHiw∗
i/bardbl2
2≤n/summationdisplay
i=1/bardblHi/bardbl2
2k≤/bardblW∗/bardbl2
F
nn/summationdisplay
i=1/bardblHi/bardbl2
2≤k
n/bardblW∗/bardbl2
2n/summationdisplay
i=1/bardblHi/bardbl2
2, (50)
where we used Assumption (4.6)and the fact that the rank of W∗isk. Combining this with (49)and
choosing suﬃciently large cwe derive the result.
Building on the previous lemmas we can now bound the norm of Fi.
20Published in Transactions on Machine Learning Research (10/2023)
Lemma A.6. Letδ:=ck3/2√
log(N)√mfor some absolute constant cand for all i∈[n]letFigiven by (24).
Further let matrix F∈Rn×ksuch that its rows are the concatenation of Fi’s. Then with probability at least
1−exp/parenleftbig
−110k2log(N)/parenrightbig
we have
∀i∈[n]/bardblFi/bardbl2≤δ
1−δdist/parenleftBig
ˆB,ˆB∗/parenrightBig
/bardblw∗
i/bardbl2, (51)
/bardblF/bardblF≤δ
1−δdist/parenleftBig
ˆB,ˆB∗/parenrightBig
/bardblW∗/bardbl2(52)
Proof.
/bardblFi/bardbl2
2≤/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble/parenleftbigg1
mˆB/latticetopX/latticetop
iXiˆB/parenrightbigg−1/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
2/bardblHi/bardbl2
2/bardblw∗
i/bardbl2
2 (53)
≤δ2
(1−δ)2·dist2/parenleftBig
ˆB,ˆB∗/parenrightBig
/bardblw∗
i/bardbl2
2(54)
which holds for all i∈[n]with probability at least 1−exp/parenleftbig
−110k2log(N)/parenrightbig
by using Union Bound on the
failure probability of (28) and (47). Similarly, we have
/bardblF/bardbl2
F=n/summationdisplay
i=1/bardblFi/bardbl2
2≤m/summationdisplay
i=1/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble/parenleftbigg1
mˆB/latticetopX/latticetop
iXiˆB/parenrightbigg−1/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
2/bardblHiw∗
i/bardbl2
2(55)
≤1
(1−δ)2m/summationdisplay
i=1/bardblHiw∗
i/bardbl2
2(56)
≤δ2
(1−δ)2·dist2/parenleftBig
ˆB,ˆB∗/parenrightBig
/bardblW∗/bardbl2
2(57)
which holds with probability at least 1−exp/parenleftbig
−110k2log(N)/parenrightbig
taking Union Bound on the failure probability
on (28) and (36).
We now turn our attention on deriving a bound for /bardblGi/bardbl2.
Lemma A.7. Letδ:=ck3/2√
log(N)√mfor some absolute constant cand for all i∈[n]letGigiven by (25).
Further let matrix G∈Rn×ksuch that its rows are the concatenation of Gi’s. Then with probability at least
1−exp/parenleftbig
−110k2log(N)/parenrightbig
we have
∀i∈[n]/bardblGi/bardbl2≤δ
1−δσ2, (58)
/bardblG/bardblF≤δ
1−δ√nσ2(59)
Proof.Notice that we can write
Gi=/parenleftbigg1
mˆB/latticetopX/latticetop
iXiˆB/parenrightbigg−11
mˆB/latticetopX/latticetop
iZi=/parenleftbigg1
mˆB/latticetopX/latticetop
iXiˆB/parenrightbigg−11
mm/summationdisplay
i=1zj
iˆB/latticetopxj
i, (60)
and sincezj
i∼N/parenleftbig
0,σ2/parenrightbig
we can conclude that for all i,j, zj
iˆB/latticetopxj
iis an i.i.d. zero mean subexponential with
norm at most C/prime
2σ2ˆ/bardblB/bardbl2=C/prime
2σ2for some constant C2. Once again we denote by Sk−1the unit sphere in k
dimensions and by Nkthe1/4-net with cardinality 9k. Using Bernstein’s inequality and Union Bound over
all the points on the net we follow the derivations from Lemma A.5 to get
P/parenleftBigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
mm/summationdisplay
i=1zj
iˆB/latticetopxj
i/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble
2≥2s/parenrightBigg
≤9k+1exp/parenleftbigg
−c3mmin/braceleftbiggs2
σ4,s
σ2/bracerightbigg/parenrightbigg
(61)
21Published in Transactions on Machine Learning Research (10/2023)
Sincem>C 2k2log(N), by setting s=σ2/radicalBig
C2k2log(N)
4mwe derive
P/parenleftBigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
mm/summationdisplay
i=1zj
iˆB/latticetopxj
i/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble
2≥σ2/radicalbigg
C2k2log(N)
m/parenrightBigg
≤9k+1exp/parenleftbigg
−c3ms2
σ4/parenrightbigg
(62)
≤9k+1exp/parenleftbig
−C2·c3k2log(N)/parenrightbig
(63)
≤exp/parenleftbig
−115k2log(N)/parenrightbig
(64)
for suﬃciently large C2. Choosing clarge enough and taking Union Bound over all i∈[n]we can obtain
P/parenleftBigg
∀i∈[n]/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
mm/summationdisplay
i=1zj
iˆB/latticetopxj
i/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble
2≤σ2δ/parenrightBigg
≤1−nexp/parenleftbig
−115k2log(N)/parenrightbig
(65)
≤1−exp/parenleftbig
−113k2log(N)/parenrightbig
(66)
(67)
Finally taking Union Bound over the failure probabilities of (28) and (67) we get
∀i∈[n]/bardblGi/bardbl2≤/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble/parenleftbigg1
mˆB/latticetopX/latticetop
iXiˆB/parenrightbigg−1/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble
2/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
mm/summationdisplay
i=1zj
iˆB/latticetopxj
i/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble
2≤δ
1−δσ2(68)
with probability at least 1−nexp/parenleftbig
−110k2log(N)/parenrightbig
. It follows that with the same probability
/bardblG/bardbl2
F=n/summationdisplay
i=1/bardblGi/bardbl2
2≤n/parenleftbiggδ
1−δ/parenrightbigg2
σ4(69)
For alli∈[n]we deﬁne qi:=ˆBw+
i−ˆB∗w∗
i. The following lemma provides upper bounds on the norms of
w+
iandqi
Lemma A.8. Letδ:=ck3/2√
log(N)√mfor some absolute constant candˆδ=δ/(1−δ). Then with probability
at least 1−exp/parenleftbig
−105k2log(N)/parenrightbig
we have
∀i∈[n]/vextenddouble/vextenddoublew+
i/vextenddouble/vextenddouble
2≤2√
k+σ2ˆδ (70)
Further with probability at least 1−exp/parenleftbig
−105k2log(N)/parenrightbig
we have
∀i∈[n]/bardblqi/bardbl2≤2√
k·dist/parenleftBig
ˆB,ˆB∗/parenrightBig
+σ2ˆδ (71)
Proof.
/vextenddouble/vextenddoublew+
i/vextenddouble/vextenddouble
2≤/vextenddouble/vextenddouble/vextenddoubleˆB/latticetop/vextenddouble/vextenddouble/vextenddouble
2/vextenddouble/vextenddouble/vextenddoubleˆB∗/vextenddouble/vextenddouble/vextenddouble
2/bardblw∗
i/bardbl2+/bardblFi/bardbl2+/bardblGi/bardbl2(72)
≤/bardblw∗
i/bardbl2+ˆδ/bardblw∗
i/bardbl2·dist/parenleftBig
ˆB,ˆB∗/parenrightBig
+ˆδσ2(73)
≤2√
k+ˆδσ2(74)
where the ﬁrst inequality comes from (20)and the third from Assumption 4.6. For the second inequality
we take Union Bound over the failure probability of (51)and(58)and thus the above result holds with
probability at least 1−exp/parenleftbig
−107k2log(N)/parenrightbig
. Taking Union Bound for all i∈[n]we get that with probability
at least 1−exp/parenleftbig
−105k2log(N)/parenrightbig
∀i∈[n]/vextenddouble/vextenddoublew+
i/vextenddouble/vextenddouble
2≤2√
k+σ2ˆδ (75)
22Published in Transactions on Machine Learning Research (10/2023)
and the ﬁrst result of the lemma follows. For the second part we have
/bardblqi/bardbl2=/vextenddouble/vextenddouble/vextenddoubleˆBw+
i−ˆB∗w∗
i/vextenddouble/vextenddouble/vextenddouble
2≤/vextenddouble/vextenddouble/vextenddoubleˆBˆB/latticetopˆB∗w∗
i+ˆBFi+ˆBGi−ˆB∗w∗
i/vextenddouble/vextenddouble/vextenddouble
2(76)
≤/vextenddouble/vextenddouble/vextenddouble/parenleftBig
ˆBˆB/latticetop−Id/parenrightBig
ˆB∗w∗
i/vextenddouble/vextenddouble/vextenddouble
2+/vextenddouble/vextenddouble/vextenddoubleˆBFi/vextenddouble/vextenddouble/vextenddouble
2+/vextenddouble/vextenddouble/vextenddoubleˆBGi/vextenddouble/vextenddouble/vextenddouble
2(77)
≤/vextenddouble/vextenddouble/vextenddoubleˆB⊥ˆB∗/vextenddouble/vextenddouble/vextenddouble
2/bardblw∗
i/bardbl2+/bardblFi/bardbl2+/bardblGi/bardbl2 (78)
≤dist/parenleftBig
ˆB,ˆB∗/parenrightBig
/bardblw∗
i/bardbl2+dist/parenleftBig
ˆB,ˆB∗/parenrightBig
ˆδ/bardblw∗
i/bardbl2+σ2ˆδ (79)
≤dist/parenleftBig
ˆB,ˆB∗/parenrightBig
2√
k+σ2ˆδ (80)
where the ﬁrst inequality comes from (20). For the forth inequality we take Union Bound over the failure
probability of (51)and(58)and thus the above result holds with probability at least 1−exp/parenleftbig
−107k2log(N)/parenrightbig
.
Taking Union Bound for all i∈[n]we get that with probability at least 1−exp/parenleftbig
−105k2log(N)/parenrightbig
∀i∈[n]/bardblqi/bardbl2≤2√
k·dist/parenleftBig
ˆB,ˆB∗/parenrightBig
+σ2ˆδ (81)
Lemma A.9. Letδ:=ck3/2√
log(N)√mfor some absolute constant candˆδ=δ/(1−δ). Then with probability
at least 1−exp (−105d)−exp/parenleftbig
−105k2log(N)/parenrightbig
we have
/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
mnn/summationdisplay
i=1X/latticetop
iZiw+/latticetop
i/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble
2≤c·σ2/parenleftBig√
k+ˆδσ2/parenrightBig√
d
√mn(82)
Proof.LetSd−1,Sk−1denote the unit spheres in dandkdimensions andNd,Nkthe1/4-nets of cardinality
9dand9k, respectively. By equation 4.13in Vershynin (2018) we have
/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
mnn/summationdisplay
i=1X/latticetop
iZiw+/latticetop
i/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble
2≤2 max
p∈Nd,y∈Nkp/latticetop/parenleftBiggn/summationdisplay
i=11
mnX/latticetop
iZiw+/latticetop
i/parenrightBigg
y (83)
=≤2 max
p∈Nd,y∈Nkp/latticetop
n/summationdisplay
i=1m/summationdisplay
j=1zj
i
mnxj
iw+/latticetop
i
y (84)
=≤2 max
p∈Nd,y∈Nkn/summationdisplay
i=1m/summationdisplay
j=1/parenleftBigg
zj
i
mn/angbracketleftBig
xj
i,p/angbracketrightBig/angbracketleftbig
w+
i,y/angbracketrightbig/parenrightBigg
(85)
Notice that for any ﬁxed p,yand∀i∈[n],j∈[m]the random variableszj
i
mn/angbracketleftBig
xj
i,p/angbracketrightBig/angbracketleftbig
w+
i,y/angbracketrightbig
are i.i.d. zero
mean subexponentials with norm at mostC/prime
3σ2/bardblw+
i/bardbl2
mn, for some absolute constant C/prime
3. Conditioning on the
event
E1:=n/intersectiondisplay
i=1/braceleftBig/vextenddouble/vextenddoublew+
i/vextenddouble/vextenddouble
2≤2√
k+ˆδσ2/bracerightBig
, (86)
which holds with probability at least 1−exp/parenleftbig
−105k2log(N)/parenrightbig
by Lemma A.8, we can invoke Bernstein’s
inequality to get
P
n/summationdisplay
i=1m/summationdisplay
j=1zj
i
mn/angbracketleftBig
xj
i,p/angbracketrightBig/angbracketleftbig
w+
i,y/angbracketrightbig
≥s/vextendsingle/vextendsingle/vextendsingleE1
≤exp
−c4mnmin

s2
σ4/parenleftBig
2√
k+σ2ˆδ/parenrightBig2,s
σ2/parenleftBig
2√
k+σ2ˆδ/parenrightBig



(87)
23Published in Transactions on Machine Learning Research (10/2023)
Sincem>d·C3
n0≥d·C3
nby settings=σ2(2√
k+ˆδσ2)√d·C3
8√mnthe above quantity simpliﬁes as follows
P
n/summationdisplay
i=1m/summationdisplay
j=1zj
i
mn/angbracketleftBig
xj
i,p/angbracketrightBig/angbracketleftbig
w+
i,y/angbracketrightbig
≥σ2/parenleftBig
2√
k+ˆδσ2/parenrightBig√d·C3
√mn/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingleE1
≤exp
−c4mns2
σ4/parenleftBig
2√
k+σ2ˆδ/parenrightBig2
(88)
≤exp (−C3·c4·d) (89)
≤exp (−110d) (90)
forC3large enough. Taking Union Bound over all points p,yon theNd,Nkand using (85) we derive
P
/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
mnn/summationdisplay
i=1X/latticetop
iZiw+/latticetop
i/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble
2≥/radicalbig
C3σ2/parenleftBig√
k+ˆδσ2/parenrightBig√
d
√mn/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingleE1
≤9d+kexp (−110d) (91)
≤exp (−105d) (92)
and removing the conditioning on E1we get
P
/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
mnn/summationdisplay
i=1X/latticetop
iZiw+/latticetop
i/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble
2≥/radicalbig
C3σ2/parenleftBig√
k+ˆδσ2/parenrightBig√
d
√mn
≤exp (−105d) +P/parenleftbig
EC
1/parenrightbig
(93)
≤exp (−105d) + exp/parenleftbig
−105k2log(N)/parenrightbig
(94)
Choosingclarge enough and taking the complementary event derives the result.
Lemma A.10. Letδ:=ck3/2√
log(N)√mfor some absolute constant candˆδ=δ/(1−δ). Then with probability
at least 1−exp (−100d)−exp/parenleftbig
−100k2log(N)/parenrightbig
we have
/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
nn/summationdisplay
i=1/parenleftbigg1
mX/latticetop
iXi/parenleftBig
ˆBw+
i−ˆB∗w∗
i/parenrightBig
−/parenleftBig
ˆBw+
i−ˆB∗w∗
i/parenrightBig/parenrightbigg
w+/latticetop
i/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble
2≤c·√
d/parenleftbigg
dist/parenleftBig
ˆB,ˆB∗/parenrightBig
k+√
kˆδσ2+/parenleftBig
ˆδσ2/parenrightBig2/parenrightbigg
√mn
(95)
Proof.Let us deﬁne the event
E2:=n/intersectiondisplay
i=1/braceleftBig/vextenddouble/vextenddoublew+
i/vextenddouble/vextenddouble
2≤2√
k+ˆδσ2/intersectiondisplay
/bardblqi/bardbl2≤dist/parenleftBig
ˆB,ˆB∗/parenrightBig
2√
k+ˆδσ2/bracerightBig
, (96)
which happens with probability at least 1−exp/parenleftbig
−100k2log(N)/parenrightbig
by Union Bound and Lemma A.8. For the
rest of this proof we work conditioning on event E2. Recall that qi:=ˆBw+
i−ˆB∗w∗
iand thus we can write
1
nn/summationdisplay
i=1/parenleftbigg1
mX/latticetop
iXi/parenleftBig
ˆBw+
i−ˆB∗w∗
i/parenrightBig
−/parenleftBig
ˆBw+
i−ˆB∗w∗
i/parenrightBig/parenrightbigg
w+/latticetop
i=1
n/parenleftBiggn/summationdisplay
i=1X/latticetop
iXiqiw+/latticetop
i−n/summationdisplay
i=1qiw+/latticetop
i/parenrightBigg
(97)
=1
n
1
mn/summationdisplay
i=1m/summationdisplay
j=1/angbracketleftBig
xj
i,qi/angbracketrightBig
xj
iw+/latticetop
i−n/summationdisplay
i=1qiw+/latticetop
i

(98)
24Published in Transactions on Machine Learning Research (10/2023)
LetSd−1,Sk−1denote the unit spheres in dandkdimensions andNd,Nkthe1/4-nets of cardinality 9dand
9k, respectively. By equation 4.13in Vershynin (2018) we have
/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
nn/summationdisplay
i=1m/summationdisplay
j=11
m/angbracketleftBig
xj
i,qi/angbracketrightBig
xj
iw+/latticetop
i−1
nn/summationdisplay
i=1qiw+/latticetop
i/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble
2≤2 max
p∈Nd,y∈Nk1
np/latticetop
n/summationdisplay
i=1m/summationdisplay
j=11
m/angbracketleftBig
xj
i,qi/angbracketrightBig
xj
iw+/latticetop
i−1
nn/summationdisplay
i=1qiw+/latticetop
i
y
(99)
= 2 max
p∈Nd,y∈Nk1
mnn/summationdisplay
i=1m/summationdisplay
j=1/parenleftBig/angbracketleftBig
xj
i,qi/angbracketrightBig/angbracketleftBig
p,xj
i/angbracketrightBig/angbracketleftbig
w+
i,y/angbracketrightbig
−/angbracketleftp,qi/angbracketright/angbracketleftbig
w+
i,y/angbracketrightbig/parenrightBig
(100)
Notice that for any ﬁxed p,ythe products/angbracketleftBig
xj
i,qi/angbracketrightBig
are i.i.d. subgaussians with norm at most
˜c1/bardblqi/bardbland/angbracketleftBig
p,xj
i/angbracketrightBig
are i.i.d. subgaussians with norm at most ˜c2/bardblp/bardbl2=˜c2. Hence un-
der the eventE2the product1
mn/angbracketleftBig
xj
i,qi/angbracketrightBig/angbracketleftBig
p,xj
i/angbracketrightBig/angbracketleftbig
w+
i,y/angbracketrightbig
are subexponentials with norm at most
C/prime
4
mn/parenleftbigg
dist/parenleftBig
ˆB,ˆB∗/parenrightBig
k+√
kˆδσ2+/parenleftBig
ˆδσ2/parenrightBig2/parenrightbigg
, for some constant C/prime
4. Also note that
E/bracketleftBig/angbracketleftBig
xj
i,qi/angbracketrightBig/angbracketleftBig
p,xj
i/angbracketrightBig/angbracketleftbig
w+
i,y/angbracketrightbig
−/angbracketleftp,qi/angbracketright/angbracketleftbig
w+
i,y/angbracketrightbig/bracketrightBig
= 0 (101)
and thus applying Bernstein’s inequality we get
P
1
mnn/summationdisplay
i=1m/summationdisplay
j=1/angbracketleftBig
xj
i,qi/angbracketrightBig/angbracketleftBig
p,xj
i/angbracketrightBig/angbracketleftbig
w+
i,y/angbracketrightbig
−1
nn/summationdisplay
i=1/angbracketleftp,qi/angbracketright/angbracketleftbig
w+
i,y/angbracketrightbig
≥s/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingleE2

≤exp
−c5·mnmin

s2
/parenleftbigg
dist/parenleftBig
ˆB,ˆB∗/parenrightBig
k+√
kˆδσ2+/parenleftBig
ˆδσ2/parenrightBig2/parenrightbigg2,s/parenleftbigg
dist/parenleftBig
ˆB,ˆB∗/parenrightBig
k+√
kˆδσ2+/parenleftBig
ˆδσ2/parenrightBig2/parenrightbigg



(102)
Sincem >d·C4
n0≥d·C4
nby settings=√C4·d/parenleftbig
dist(ˆB,ˆB∗)k+√
kˆδσ2+(ˆδσ2)2/parenrightbig
2√mnand taking Union Bound over all
p∈Nd,y∈Nkwe derive
P
/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
nn/summationdisplay
i=1/parenleftbigg1
mX/latticetop
iXi/parenleftBig
ˆBw+
i−ˆB∗w∗
i/parenrightBig
−/parenleftBig
ˆBw+
i−ˆB∗w∗
i/parenrightBig/parenrightbigg
w+/latticetop
i/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble
2≥√C4·d/parenleftbigg
dist/parenleftBig
ˆB,ˆB∗/parenrightBig
k+√
kˆδσ2+/parenleftBig
ˆδσ2/parenrightBig2/parenrightbigg
√mn/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingleE2

≤9d+kexp
−c5·mns2
/parenleftbigg
dist/parenleftBig
ˆB,ˆB∗/parenrightBig
k+√
kˆδσ2+/parenleftBig
ˆδσ2/parenrightBig2/parenrightbigg2

≤9d+kexp (−C4·c5·d) (103)
≤9d+kexp (−120d) (104)
≤exp (−100d) (105)
25Published in Transactions on Machine Learning Research (10/2023)
choosing a large enough constant C4. Recall that P/parenleftbig
EC
2/parenrightbig
≤exp/parenleftbig
−100k2log(N)/parenrightbig
. Hence by removing the
conditioning onE2we get that with probability at least 1−exp (−100d)−exp/parenleftbig
−100k2log(N)/parenrightbig
/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
nn/summationdisplay
i=1/parenleftbigg1
mX/latticetop
iXi/parenleftBig
ˆBw+
i−ˆB∗w∗
i/parenrightBig
−/parenleftBig
ˆBw+
i−ˆB∗w∗
i/parenrightBig/parenrightbigg
w+/latticetop
i/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble
2≤c·√
d/parenleftbigg
dist/parenleftBig
ˆB,ˆB∗/parenrightBig
k+√
kˆδσ2+/parenleftBig
ˆδσ2/parenrightBig2/parenrightbigg
√mn
(106)
for suﬃciently large c.
Having set all the building blocks we now proceed to the proof of Theorem 4.7.
Theorem 4.7. Let Assumptions 4.3-4.6 hold. Further, let the following inequalities hold for the number of
participating nodes and the batch size respectively, n≥n0andm≥c0(1+σ2)k3κ4
E2
0max{log(N),d/n 0}, for
some absolute constant c0. Then FedRep-SRPFL with stepsize η≤1
8¯σ2max,∗, satisﬁes the following contraction
inequality:
dist/parenleftbig
Bt+1,B∗/parenrightbig
≤dist/parenleftbig
Bt,B∗/parenrightbig√
1−a+a/radicalBig
n
n0(1−a), (10)
w.p. at least 1−T·exp/parenleftbig
−90 min/braceleftbig
d,k2log(N)/bracerightbig/parenrightbig
, wherea=1
2ηE0¯σ2
min,∗≤1
4.
Proof.First let us recall the deﬁnition of δ:=ck3/2√
log(N)√mfor some absolute constant candˆδ=δ/(1−δ).
Further notice that for our choice of mand suﬃciently large c0we have the following useful inequality
ˆδ=δ
1−δ≤2δ≤E0
20·κ2·1
1 +σ2≤1
20(107)
From the update scheme of our algorithm (18) we have
B+=ˆB−η
mn/parenleftBiggn/summationdisplay
i=1X/latticetop
iXiˆBw+
iw+/latticetop
i−n/summationdisplay
i=1X/latticetop
iXiˆB∗w∗
iw+/latticetop
i−n/summationdisplay
i=1X/latticetop
iZiw+/latticetop
i/parenrightBigg
(108)
=ˆB−η
n/parenleftBiggn/summationdisplay
i=1/parenleftbigg1
mX/latticetop
iXi/parenleftBig
ˆBw+
i−ˆB∗w∗
i/parenrightBig
−/parenleftBig
ˆBw+
i−ˆB∗w∗
i/parenrightBig/parenrightbigg
w+/latticetop
i/parenrightBigg
−η
nn/summationdisplay
i=1/parenleftBig
ˆBw+
i−ˆB∗w∗
i/parenrightBig
w+/latticetop
i+η
nn/summationdisplay
i=11
mX/latticetop
iZiw+/latticetop
i (109)
where we added and subtracted terms. Multiplying both sides by ˆB∗/latticetop
⊥we get
ˆB∗/latticetop
⊥B+=ˆB∗/latticetop
⊥ˆB−η
nˆB∗/latticetop
⊥/parenleftBiggn/summationdisplay
i=1/parenleftbigg1
mX/latticetop
iXi/parenleftBig
ˆBw+
i−ˆB∗w∗
i/parenrightBig
−/parenleftBig
ˆBw+
i−ˆB∗w∗
i/parenrightBig/parenrightbigg
w+/latticetop
i/parenrightBigg
−η
nn/summationdisplay
i=1/parenleftBig
ˆB∗/latticetop
⊥ˆBw+
i−ˆB∗/latticetop
⊥ˆB∗w∗
i/parenrightBig
w+/latticetop
i+η
nˆB∗/latticetop
⊥n/summationdisplay
i=11
mX/latticetop
iZiw+/latticetop
i (110)
=ˆB∗/latticetop
⊥ˆB/parenleftBigg
Ik−η
nn/summationdisplay
i=1w+
iw+/latticetop
i/parenrightBigg
+η
nˆB∗/latticetop
⊥n/summationdisplay
i=11
mX/latticetop
iZiw+/latticetop
i
−η
nˆB∗/latticetop
⊥/parenleftBiggn/summationdisplay
i=1/parenleftbigg1
mX/latticetop
iXi/parenleftBig
ˆBw+
i−ˆB∗w∗
i/parenrightBig
−/parenleftBig
ˆBw+
i−ˆB∗w∗
i/parenrightBig/parenrightbigg
w+/latticetop
i/parenrightBigg
(111)
26Published in Transactions on Machine Learning Research (10/2023)
where the second equality holds since ˆB∗/latticetop
⊥ˆB∗= 0. Recall that from the QRdecomposition of B+we have
B+=ˆB+R+. Hence multiplying by (R+)−1and taking both sides the norm we derive
dist/parenleftBig
ˆB+,ˆB∗/parenrightBig
≤/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddoubleˆB∗/latticetop
⊥ˆB/parenleftBigg
Ik−η
nn/summationdisplay
i=1w+
iw+/latticetop
i/parenrightBigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble
2/vextenddouble/vextenddouble/vextenddouble/parenleftbig
R+/parenrightbig−1/vextenddouble/vextenddouble/vextenddouble
2+/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddoubleη
nˆB∗/latticetop
⊥n/summationdisplay
i=11
mX/latticetop
iZiw+/latticetop
i/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble
2/vextenddouble/vextenddouble/vextenddouble/parenleftbig
R+/parenrightbig−1/vextenddouble/vextenddouble/vextenddouble
2
+/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddoubleη
nˆB∗/latticetop
⊥/parenleftBiggn/summationdisplay
i=1/parenleftbigg1
mX/latticetop
iXi/parenleftBig
ˆBw+
i−ˆB∗w∗
i/parenrightBig
−/parenleftBig
ˆBw+
i−ˆB∗w∗
i/parenrightBig/parenrightbigg
w+/latticetop
i/parenrightBigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble
2/vextenddouble/vextenddouble/vextenddouble/parenleftbig
R+/parenrightbig−1/vextenddouble/vextenddouble/vextenddouble
2
(112)
Let us deﬁne
A1:=dist/parenleftBig
ˆB,ˆB∗/parenrightBig/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddoubleIk−η
nn/summationdisplay
i=1w+
iw+/latticetop
i/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble
2(113)
A2:=/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddoubleη
nˆB∗/latticetop
⊥n/summationdisplay
i=11
mX/latticetop
iZiw+/latticetop
i/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble
2(114)
A3:=/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddoubleη
nˆB∗/latticetop
⊥/parenleftBiggn/summationdisplay
i=1/parenleftbigg1
mX/latticetop
iXi/parenleftBig
ˆBw+
i−ˆB∗w∗
i/parenrightBig
−/parenleftBig
ˆBw+
i−ˆB∗w∗
i/parenrightBig/parenrightbigg
w+/latticetop
i/parenrightBigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble
2(115)
so that the following inequality holds
dist/parenleftBig
ˆB+,ˆB∗/parenrightBig
≤(A1+A2+A3)/vextenddouble/vextenddouble/vextenddouble/parenleftbig
R+/parenrightbig−1/vextenddouble/vextenddouble/vextenddouble
2(116)
For the rest of the proof we will work conditioning on the intersection of the events
E2:=n/intersectiondisplay
i=1/braceleftBig/vextenddouble/vextenddoublew+
i/vextenddouble/vextenddouble
2≤2√
k+ˆδσ2/intersectiondisplay
/bardblqi/bardbl2≤dist/parenleftBig
ˆB,ˆB∗/parenrightBig
2√
k+ˆδσ2/bracerightBig
(117)
E3:=/braceleftBig
/bardblF/bardblF≤dist/parenleftBig
ˆB,ˆB∗/parenrightBig
ˆδ/bardblW∗/bardbl2/intersectiondisplay
/bardblG/bardblF≤ˆδ√nσ2/bracerightBig
(118)
E4:=

/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
mnn/summationdisplay
i=1X/latticetop
iZiw+/latticetop
i/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble
2≤c·σ2/parenleftBig√
k+ˆδσ2/parenrightBig√
d
√mn

(119)
E5:=

/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
nn/summationdisplay
i=1/parenleftbigg1
mX/latticetop
iXi/parenleftBig
ˆBw+
i−ˆB∗w∗
i/parenrightBig
−/parenleftBig
ˆBw+
i−ˆB∗w∗
i/parenrightBig/parenrightbigg
w+/latticetop
i/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble
2≤c√
d/parenleftbigg
dist/parenleftBig
ˆB,ˆB∗/parenrightBig
k+√
kˆδσ2+/parenleftBig
ˆδσ2/parenrightBig2/parenrightbigg
√mn


(120)
which happens with probability at least 1−exp (−90d)−exp/parenleftbig
−90k2log(N)/parenrightbig
by Union Bound on the failure
probability of (52), (59), (82), (95) and (96).
We will now provide bounds for each of the terms of interest in (116), starting from A1. Notice that by (26)
we have
λmax/parenleftbig
W+W+/parenrightbig
=/vextenddouble/vextenddoubleW+/vextenddouble/vextenddouble2
2=/vextenddouble/vextenddouble/vextenddoubleW∗ˆB∗ˆB+F+G/vextenddouble/vextenddouble/vextenddouble2
2(121)
≤2/bardblW∗/bardbl2
2+ 4/bardblF/bardbl2
2+ 4/bardblG/bardbl2
2(122)
≤2/bardblW∗/bardbl2
2+dist/parenleftBig
ˆB,ˆB∗/parenrightBig
4ˆδ2/bardblW∗/bardbl2
2+ 4ˆδ2σ4n (123)
≤4/parenleftBig
/bardblW∗/bardbl2
2+n/parenrightBig
(124)
≤4n/parenleftbig
¯σ2
max,∗+ 1/parenrightbig
(125)
27Published in Transactions on Machine Learning Research (10/2023)
where in the last inequality we use the fact that /bardblW∗/bardbl2=√n·¯σmax,∗. Sinceη</parenleftbig
¯σ2
max,∗+ 1/parenrightbig−1the matrix
Ik−η
nW+/latticetopW+is positive deﬁnite. Thus we have
/vextenddouble/vextenddouble/vextenddoubleIk−η
nW+/latticetopW+/vextenddouble/vextenddouble/vextenddouble
2≤1−η
nλmin/parenleftbig
W+/latticetopW+/parenrightbig
(126)
≤1−η
nλmin/parenleftbigg/parenleftBig
W∗ˆB∗ˆB+F+G/parenrightBig/latticetop/parenleftBig
W∗ˆB∗ˆB+F+G/parenrightBig/parenrightbigg
(127)
≤1−η
n/parenleftBig
σ2
min/parenleftBig
W∗ˆB∗ˆB/parenrightBig
−σ2
min(F)−σ2
min(G)/parenrightBig
+2η
n/parenleftBig
σmax/parenleftBig
F/latticetopW∗ˆB∗/latticetopˆB/parenrightBig
+σmax/parenleftbig
F/latticetopG/parenrightbig
+σmax/parenleftBig
G/latticetopW∗ˆB∗/latticetopˆB/parenrightBig/parenrightBig
(128)
≤1−η
n/parenleftBig
σ2
min(W∗)σ2
min/parenleftBig
ˆB∗/latticetopˆB/parenrightBig
+ 2/vextenddouble/vextenddouble/vextenddoubleˆB∗/latticetopˆB/vextenddouble/vextenddouble/vextenddouble
2/parenleftbig
σmax/parenleftbig
F/latticetopW∗/parenrightbig
+σmax/parenleftbig
G/latticetopW∗/parenrightbig/parenrightbig/parenrightBig
+2η
nσmax(F)σmax(G) (129)
≤1−η·¯σ2
min,∗·σ2
min/parenleftBig
ˆB∗/latticetopˆB/parenrightBig
+2η
n(/bardblF/bardbl2+/bardblG/bardbl2)/bardblW∗/bardbl2+2η
n(/bardblF/bardbl2·/bardblG/bardbl2)(130)
where we used that the norms of ˆB∗andˆBare1since the matrices are orthonormal and ¯σmin,∗≤σmin(W∗).
Recall that we operate under E3and thus we can further write
/vextenddouble/vextenddouble/vextenddoubleIk−η
nW+/latticetopW+/vextenddouble/vextenddouble/vextenddouble
2≤1−η·¯σ2
min,∗·σ2
min/parenleftBig
ˆB∗/latticetopˆB/parenrightBig
+2η
n/parenleftBig
dist/parenleftBig
ˆB,ˆB∗/parenrightBig
ˆδ/bardblW∗/bardbl2+√nˆδσ2/parenrightBig
/bardblW∗/bardbl2
+2η
n/parenleftBig
dist/parenleftBig
ˆB,ˆB∗/parenrightBig
ˆδ2σ2√n/bardblW∗/bardbl2/parenrightBig
(131)
≤1−η·¯σ2
min,∗·σ2
min/parenleftBig
ˆB∗/latticetopˆB/parenrightBig
+ 2η/parenleftBigg
ˆδ/bardblW∗/bardbl2
2
n+ˆδσ2/bardblW∗/bardbl2√n+ˆδ2σ4/bardblW∗/bardbl√n/parenrightBigg
(132)
≤1−η·¯σ2
min,∗·σ2
min/parenleftBig
ˆB∗/latticetopˆB/parenrightBig
+ 3η/parenleftBigg
E0¯σ2
min,∗
20¯σ2max,∗·¯σ2
max,∗/parenrightBigg
(133)
≤1−η·¯σ2
min,∗·σ2
min/parenleftBig
ˆB∗/latticetopˆB/parenrightBig
+1
6ηE0¯σ2
min,∗ (134)
where we upper bound dist/parenleftBig
ˆB,ˆB∗/parenrightBig
by1,ˆδ≤E0
20·κ2·1
1+σ2and use Assumption 4.4 in the third inequality.
Further by the deﬁnition of E0:= 1−dist2/parenleftBig
ˆB0,ˆB∗/parenrightBig
≤σ2
min/parenleftBig
ˆB∗/latticetop,ˆB/parenrightBig
we have
/vextenddouble/vextenddouble/vextenddoubleIk−η
nW+/latticetopW+/vextenddouble/vextenddouble/vextenddouble
2≤1−ηE0¯σ2
min,∗+1
6ηE0¯σ2
min,∗ (135)
and it follows immediately that
A1≤dist/parenleftBig
ˆB,ˆB∗/parenrightBig/parenleftbigg
1−ηE0¯σ2
min,∗+1
6ηE0¯σ2
min,∗/parenrightbigg
(136)
Further since we operate under E4(119) and/vextenddouble/vextenddouble/vextenddoubleˆB∗
⊥/vextenddouble/vextenddouble/vextenddouble
2= 1we have
A2≤ηcσ2/parenleftBig√
k+ 1/parenrightBig√
d√mn(137)
and since we operate under E5(120) we obtain
A3≤ηc/parenleftBig
dist/parenleftBig
ˆB,ˆB∗/parenrightBig
k+√
k+ 1/parenrightBig√
d√mn(138)
28Published in Transactions on Machine Learning Research (10/2023)
Combining (116), (136), (137) and (138) we get
dist/parenleftBig
ˆB+,ˆB∗/parenrightBig
≤dist/parenleftBig
ˆB,ˆB∗/parenrightBig/parenleftBigg
1−5
6ηE0¯σ2
min,∗+ηck√
d√mn/parenrightBigg
·/vextenddouble/vextenddouble/vextenddouble/parenleftbig
R+/parenrightbig−1/vextenddouble/vextenddouble/vextenddouble
2
+ηc/parenleftBig√
k+ 1/parenrightBig/parenleftbig
σ2+ 1/parenrightbig√
d√mn·/vextenddouble/vextenddouble/vextenddouble/parenleftbig
R+/parenrightbig−1/vextenddouble/vextenddouble/vextenddouble
2(139)
The last part of the proof focuses on bounding/vextenddouble/vextenddouble/vextenddouble(R+)−1/vextenddouble/vextenddouble/vextenddouble
2.
Let us deﬁne
S:=n/summationdisplay
i=11
mX/latticetop
iXi/parenleftBig
ˆBw+
i−ˆB∗w∗
i/parenrightBig
w+/latticetop
i (140)
E:=n/summationdisplay
i=11
mX/latticetop
iZiw+/latticetop
i (141)
and hence (108) takes the form
B+=ˆB−η
nS+η
nE (142)
and also
B+/latticetopB+=ˆB/latticetopˆB−η
n/parenleftBig
ˆB/latticetopS+S/latticetopˆB/parenrightBig
+η
n/parenleftBig
ˆB/latticetopE+E/latticetopˆB/parenrightBig
+η2
n2S/latticetopS−η2
n2/parenleftbig
E/latticetopS+S/latticetopE/parenrightbig
+η2
n2E/latticetopE(143)
=Ik−η
n/parenleftBig
ˆB/latticetopS+S/latticetopˆB/parenrightBig
+η
n/parenleftBig
ˆB/latticetopE+E/latticetopˆB/parenrightBig
−η2
n2/parenleftbig
E/latticetopS+S/latticetopE/parenrightbig
+η2
n2E/latticetopE+η2
n2S/latticetopS(144)
By Weyl’s inequality and since R+/latticetopR+=ˆB+/latticetopˆB+we derive
σ2
min/parenleftbig
R+/parenrightbig
≥1−η
nλmax/parenleftBig
ˆB/latticetopS+S/latticetopˆB/parenrightBig
−η
nλmax/parenleftBig
ˆB/latticetopE+E/latticetopˆB/parenrightBig
−η2
n2λmax/parenleftbig
E/latticetopS+S/latticetopE/parenrightbig
(145)
Let us further deﬁne
R1:=η
nλmax/parenleftBig
ˆB/latticetopS+S/latticetopˆB/parenrightBig
(146)
R2:=η2
n2λmax/parenleftbig
E/latticetopS+S/latticetopE/parenrightbig
(147)
R3:=η
nλmax/parenleftBig
ˆB/latticetopE+E/latticetopˆB/parenrightBig
(148)
So that we can succinctly rewrite the above inequality as follows
σ2
min/parenleftbig
R+/parenrightbig
≥1−R1−R2−R3 (149)
We work to bound separately each of the three terms.
R1=2η
nmax
p:/bardblp/bardbl2=1p/latticetopˆB/latticetopSp (150)
= max
p:/bardblp/bardbl2=12η
np/latticetopˆB/latticetop/bracketleftBigg/parenleftBiggn/summationdisplay
i=1/parenleftbigg1
mX/latticetop
iXi/parenleftBig
ˆBw+
i−ˆB∗w∗
i/parenrightBig
−/parenleftBig
ˆBw+
i−ˆB∗w∗
i/parenrightBig/parenrightbigg
w+/latticetop
i/parenrightBigg/bracketrightBigg
p
+ max
p:/bardblp/bardbl2=12η
np/latticetopˆB/latticetop/bracketleftBiggn/summationdisplay
i=1/parenleftBig
ˆBw+
i−ˆB∗w∗
i/parenrightBig
w+/latticetop
i/bracketrightBigg
p (151)
29Published in Transactions on Machine Learning Research (10/2023)
and since we operate under E5(120) the above simpliﬁes to
R1≤2η/vextenddouble/vextenddouble/vextenddoubleˆB/vextenddouble/vextenddouble/vextenddouble
2c/parenleftBig
dist/parenleftBig
ˆB,ˆB∗/parenrightBig
k+√
k+ 1/parenrightBig√
d√mn+ max
p:/bardblp/bardbl2=12η
np/latticetopˆB/latticetop/bracketleftBiggn/summationdisplay
i=1/parenleftBig
ˆBw+
i−ˆB∗w∗
i/parenrightBig
w+/latticetop
i/bracketrightBigg
p(152)
≤3ηc/parenleftBig
dist/parenleftBig
ˆB,ˆB∗/parenrightBig
k+√
k/parenrightBig√
d√mn+ max
p:/bardblp/bardbl2=12η
np/latticetopˆB/latticetop/bracketleftBiggn/summationdisplay
i=1/parenleftBig
ˆBw+
i−ˆB∗w∗
i/parenrightBig
w+/latticetop
i/bracketrightBigg
p (153)
We focus on the second term and using (20) we get
2η
np/latticetopˆB/latticetop/bracketleftBiggn/summationdisplay
i=1/parenleftBig
ˆBw+
i−ˆB∗w∗
i/parenrightBig
w+/latticetop
i/bracketrightBigg
p=2η
n·tr/bracketleftBiggn/summationdisplay
i=1/parenleftBig
ˆBw+
i−ˆB∗w∗
i/parenrightBig
w+/latticetop
ipp/latticetopˆB/latticetop/bracketrightBigg
(154)
=2η
n·tr/bracketleftBiggn/summationdisplay
i=1/parenleftBig
ˆBw+
i−ˆB∗w∗
i/parenrightBig/parenleftBig
ˆB/latticetopˆB∗w∗
i+Fi+Gi/parenrightBig/latticetop
pp/latticetopˆB/latticetop/bracketrightBigg
(155)
We bound each term separately and to this end we deﬁne
T1:=2η
n·tr/bracketleftBiggn/summationdisplay
i=1/parenleftBig
ˆBw+
i−ˆB∗w∗
i/parenrightBig
w∗/latticetop
iˆB∗/latticetopˆBpp/latticetopˆB/latticetop/bracketrightBigg
(156)
T2:=2η
n·tr/bracketleftBiggn/summationdisplay
i=1/parenleftBig
ˆBw+
i−ˆB∗w∗
i/parenrightBig
F/latticetop
ipp/latticetopˆB/latticetop/bracketrightBigg
(157)
T3:=2η
n·tr/bracketleftBiggn/summationdisplay
i=1/parenleftBig
ˆBw+
i−ˆB∗w∗
i/parenrightBig
G/latticetop
ipp/latticetopˆB/latticetop/bracketrightBigg
(158)
such that (155) can be expressed as
2η
np/latticetopˆB/latticetop/bracketleftBiggn/summationdisplay
i=1/parenleftBig
ˆBw+
i−ˆB∗w∗
i/parenrightBig
w+/latticetop
i/bracketrightBigg
p=T1+T2+T3 (159)
Further expanding T1we have
T1=2η
ntr/bracketleftBiggn/summationdisplay
i=1/parenleftBig
ˆBˆB/latticetopˆB∗w∗
iw∗/latticetop
i+ˆBFiw∗/latticetop
i+ˆBGiw∗/latticetop
i−ˆB∗w∗
iw∗/latticetop
i/parenrightBig
ˆB∗/latticetopˆBpp/latticetopˆB/latticetop/bracketrightBigg
(160)
=2η
ntr/bracketleftBigg
ˆB/latticetop/parenleftBig
ˆBˆB/latticetop−Id/parenrightBign/summationdisplay
i=1/parenleftBig
ˆB∗/latticetopw∗
iw∗/latticetop
i/parenrightBig
ˆB∗/latticetopˆBpp/latticetop/bracketrightBigg
+2η
ntr/bracketleftBiggn/summationdisplay
i=1/parenleftBig
ˆBFiw∗/latticetop
i/parenrightBig
ˆB∗/latticetopˆBpp/latticetopˆB/latticetop/bracketrightBigg
+2η
ntr/bracketleftBiggn/summationdisplay
i=1/parenleftBig
ˆBGiw∗/latticetop
i/parenrightBig
ˆB∗/latticetopˆBpp/latticetopˆB/latticetop/bracketrightBigg
(161)
=2η
ntr/bracketleftBig
ˆB/latticetopˆB/parenleftbig
F/latticetop+G/latticetop/parenrightbig
W∗ˆB∗/latticetopˆBpp/latticetop/bracketrightBig
(162)
≤2η
n(/bardblF/bardblF+/bardblG/bardblF)/bardblW∗/bardbl2(163)
where in the ﬁrst equality we expand w+
ivia(20)and in the third equality we use that ˆB/latticetop/parenleftBig
ˆBˆB/latticetop−Id/parenrightBig
= 0
andF/latticetop=n/summationtext
i=1Fiw∗/latticetop
i,G/latticetop=n/summationtext
i=1Giw∗/latticetop
i. The inequality is obtained by noticing that the norms of the
orthonormal ˆB,ˆB∗is one and also/vextenddouble/vextenddoublepp/latticetop/vextenddouble/vextenddouble
2≤1. Conditioning on E3(118)we can further simplify as follows
T1≤2η
n/parenleftBig
dist/parenleftBig
ˆB,ˆB∗/parenrightBig
ˆδ/bardblW∗/bardbl2
2+ˆδσ2√n/bardblW/bardbl2/parenrightBig
(164)
≤1
10ηE0¯σ2
min,∗ (165)
30Published in Transactions on Machine Learning Research (10/2023)
We now turn our attention to T2
T2=2η
n·tr/bracketleftBiggn/summationdisplay
i=1/parenleftBig
ˆBˆB/latticetopˆB∗w∗
i+ˆBFi+ˆBGi−ˆB∗w∗
i/parenrightBig
F/latticetop
ipp/latticetopˆB/latticetop/bracketrightBigg
(166)
=2η
ntr/bracketleftBigg
ˆB/latticetop/parenleftBig
ˆBˆB/latticetop−Id/parenrightBign/summationdisplay
i=1/parenleftBig
ˆB∗w∗
i/parenrightBig
F/latticetop
ipp/latticetop/bracketrightBigg
+2η
ntr/bracketleftBigg
ˆB/latticetopˆBn/summationdisplay
i=1FiF/latticetop
ipp/latticetop/bracketrightBigg
+2η
ntr/bracketleftBigg
ˆB/latticetopˆBn/summationdisplay
i=1GiF/latticetop
ipp/latticetop/bracketrightBigg
(167)
=2η
ntr/bracketleftBig
ˆB/latticetopˆB/parenleftbig
F/latticetopF+G/latticetopF/parenrightbig
pp/latticetop/bracketrightBig
(168)
≤2η
n/parenleftBig
/bardblF/bardbl2
F+/bardblG/bardblF/bardblF/bardblF/parenrightBig
(169)
where in the third equality we used that ˆB/latticetop/parenleftBig
ˆBˆB/latticetop−Id/parenrightBig
= 0and in the forth that the norms of the
orthonormal matrices is 1as well as the norm of pp/latticetop. Following the same calculations for T3we get
T3≤2η
n/parenleftBig
/bardblG/bardbl2
F+/bardblG/bardblF/bardblF/bardblF/parenrightBig
(170)
and thus summing the two terms we get the following
T2+T3≤2η
n(/bardblF/bardblF+/bardblG/bardblF)2(171)
Again conditioning on E3(118) we derive
T2+T3≤2η
n/parenleftBig
ˆδ/parenleftbig
/bardblW∗/bardbl2+√nσ2/parenrightbig/parenrightBig2
(172)
≤2ηˆδ2/parenleftbig
¯σ2
max,∗+σ4/parenrightbig
(173)
≤1
10ηE0¯σ2
min,∗ (174)
Hence combining (153), (165) and (174) we get a bound for R1
R1≤3ηc/parenleftBig
k+√
k/parenrightBig√
d√mn+1
5ηE0¯σ2
min,∗ (175)
≤6η·c·k√
d√mn+1
5ηE0¯σ2
min,∗ (176)
We work in similar fashion to derive the bound on R2
R2=η2
n2λmax/parenleftbig
E/latticetopS+S/latticetopE/parenrightbig
(177)
=2η2
n2max
p:/bardblp/bardbl2=1p/latticetopS/latticetopEp (178)
≤2η2
n2max
p:/bardblp/bardbl2=1p/latticetop/bracketleftBiggn/summationdisplay
i=1/parenleftbigg1
mX/latticetop
iXi/parenleftBig
ˆBw+
i−ˆB∗w∗
i/parenrightBig
−/parenleftBig
ˆBw+
i−ˆB∗w∗
i/parenrightBig/parenrightbigg
w+/latticetop
i/bracketrightBiggn/summationdisplay
i=1/parenleftbigg1
mX/latticetop
iZiw+/latticetop
i/parenrightbigg
p
+2η2
n2max
p:/bardblp/bardbl2=1p/latticetop/bracketleftBiggn/summationdisplay
i=1/parenleftBig
ˆBw+
i−ˆB∗w∗
i/parenrightBig
w+/latticetop
i/bracketrightBiggn/summationdisplay
i=1/parenleftbigg1
mX/latticetop
iZiw+/latticetop
i/parenrightbigg
p (179)
≤2η2/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
nn/summationdisplay
i=1/parenleftbigg1
mX/latticetop
iXi/parenleftBig
ˆBw+
i−ˆB∗w∗
i/parenrightBig
−/parenleftBig
ˆBw+
i−ˆB∗w∗
i/parenrightBig/parenrightbigg
w+/latticetop
i/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble
2·/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
mnn/summationdisplay
i=1/parenleftbig
X/latticetop
iZiw+/latticetop
i/parenrightbig/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble
2
+2η2
n/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddoublen/summationdisplay
i=1/parenleftBig
ˆBw+
i−ˆB∗w∗
i/parenrightBig
w+/latticetop
i/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble
2·/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
mnn/summationdisplay
i=1/parenleftbig
X/latticetop
iZiw+/latticetop
i/parenrightbig/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble
2(180)
(181)
31Published in Transactions on Machine Learning Research (10/2023)
Since we work conditioning on the event E4/intersectiontextE5we further derive
R2≤2η2
c√
d/parenleftbigg
dist/parenleftBig
ˆB,ˆB∗/parenrightBig
k+√
kˆδσ2+/parenleftBig
ˆδσ2/parenrightBig2/parenrightbigg
√mn
·
cσ2/parenleftBig√
k+ˆδσ2/parenrightBig√
d
√mn

+2η2
n/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddoublen/summationdisplay
i=1/parenleftBig
ˆBw+
i−ˆB∗w∗
i/parenrightBig
w+/latticetop
i/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble
2·
cσ2/parenleftBig√
k+ˆδσ2/parenrightBig√
d
√mn
 (182)
≤3η2/parenleftBigg
ck√
d√mn/parenrightBigg/parenleftBigg
c√
kσ2√
d√mn/parenrightBigg
+2η2
nn/summationdisplay
i=1/bardblqi/bardbl2/vextenddouble/vextenddoublew+
i/vextenddouble/vextenddouble
2/parenleftBigg
c√
kσ2√
d√mn/parenrightBigg
(183)
And since we also condition on E2(117) we ﬁnally get
R2≤3η2c2k3
2σ2d
mn+2η2
nn/summationdisplay
i=1/parenleftBig
2√
k+ˆδσ2/parenrightBig2/parenleftBigg
c√
kσ2√
d√mn/parenrightBigg
(184)
≤3η2c2k3
2σ2d
mn+ 9η2/parenleftBigg
ck3
2σ2√
d√mn/parenrightBigg
(185)
The last term we need to bound is R3
R3=η
nλmax/parenleftBig
E/latticetopˆB+ˆB/latticetopE/parenrightBig
(186)
=2η2
n2max
p:/bardblp/bardbl2=1p/latticetopˆB/latticetopEp (187)
≤2η
n/vextenddouble/vextenddouble/vextenddoubleˆB/vextenddouble/vextenddouble/vextenddouble
2/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddoublen/summationdisplay
i=11
mX/latticetop
iZiw+/latticetop
i/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble
2(188)
≤2ηc·σ2/parenleftBig√
k+ˆδσ2/parenrightBig√
d
√mn(189)
≤3ηc√
kσ2√
d√mn(190)
Combining (149) with (176), (185) and (190) we derive
σ2
min/parenleftbig
R+/parenrightbig
≥1−6η·c·k√
d√mn−1
5ηE0¯σ2
min,∗−3η2c2k3
2σ2d
mn−9η2/parenleftBigg
ck3
2σ2√
d√mn/parenrightBigg
−3ηc√
kσ2√
d√mn
(191)
≥1−14ηck3
2σ2√
d√mn−3η2c2k3
2σ2d
mn−1
5ηE0¯σ2
min,∗ (192)
≥1−15ηck3
2σ2√
d√mn−1
5ηE0¯σ2
min,∗ (193)
where the last inequality holds since√mn≥c√
d. We can now combine (139)and(193)to obtain the
contraction inequality
dist/parenleftBig
ˆB+,ˆB∗/parenrightBig
≤dist/parenleftBig
ˆB,ˆB∗/parenrightBig/parenleftBigg
1−5
6ηE0¯σ2
min,∗+ηck√
d√mn/parenrightBigg
·/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble/parenleftBigg
1−15ηck3
2σ2√
d√mn−1
5ηE0¯σ2
min,∗/parenrightBigg−1/2/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble
2
+ηc/parenleftBig√
k+ 1/parenrightBig/parenleftbig
σ2+ 1/parenrightbig√
d√mn·/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble/parenleftBigg
1−15ηck3
2σ2√
d√mn−1
5ηE0¯σ2
min,∗/parenrightBigg−1/2/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble
2(194)
32Published in Transactions on Machine Learning Research (10/2023)
We divide and multiply by n0and using our bounds on mandnthe previous inequality further simpliﬁes,
dist/parenleftBig
ˆB+,ˆB∗/parenrightBig
≤dist/parenleftBig
ˆB,ˆB∗/parenrightBig
1−5
6ηE0¯σ2
min,∗+ηck√
d/radicalBig
mn0·n
n0

1−15ηck3
2σ2√
d/radicalBig
mn0·n
n0−1
5ηE0¯σ2
min,∗
−1/2
+ηc/parenleftBig√
k+ 1/parenrightBig/parenleftbig
σ2+ 1/parenrightbig√
d/radicalBig
mn0·n
n0·
1−15ηck3
2σ2√
d/radicalBig
mn0·n
n0−1
5ηE0¯σ2
min,∗
−1/2
(195)
≤dist/parenleftBig
ˆB,ˆB∗/parenrightBig/parenleftbigg
1−1
2ηE0¯σ2
min,∗/parenrightbigg/parenleftbigg
1−1
2ηE0¯σ2
min,∗/parenrightbigg−1/2
+/parenleftbigg/radicalbiggn0
4nηE0¯σ2
min,∗/parenrightbigg/parenleftbigg
1−1
2ηE0¯σ2
min,∗/parenrightbigg−1/2
(196)
≤dist/parenleftBig
ˆB,ˆB∗/parenrightBig/radicalBigg/parenleftbigg
1−1
2ηE0¯σ2
min,∗/parenrightbigg
+/parenleftbig1
2ηE0¯σ2
min,∗/parenrightbig
/radicalBig
n
n0/parenleftbig
1−1
2ηE0¯σ2
min,∗/parenrightbig (197)
where in the second inequality we used that for our choices of mandnthe following inequality holds
15ηck3
2(1 +σ2)√
d√mn0≤1
10ηE0¯σ2
min,∗. Taking Union Bound over the total number of iterations Twe derive
the result.
Corollary A.11. Recall that our algorithm starts at stage 0withn0participating clients and doubles
the number of participating clients at every subsequent stage. Thus, by slightly abusing notation, we can
reformulate the contraction inequality of Theorem 4.7 at stage ras follows
dist+≤dist√
1−a+a/radicalbig
2r(1−a)witha≤1
4(198)
B Appendix
In the second part of our analysis we compute the expected ‘Wall Clock Time’ of our proposed method
and compare it to the corresponding ‘Wall Clock Time’ of straggler-prone FedRep. We prove that when the
computational speeds are drawn from the exponential distribution with parameter λand the communication
cost is given byC=c1
λ, (for some constant c), then SRPFLguarantees a logarithmic speedup. Recall that in
Corollary A.11 we get the following simpliﬁed version of the contraction inequality
dist+≤dist√
1−a+a/radicalbig
2r(1−a)witha≤1
4. (199)
For the rest of this section w.l.g. we assume that the clients are re-indexed at every stage so that the expected
computation times maintain a decreasing ordering i.e. ∀rE[Tr
1]≤E[Tr
2]≤...,≤E[Tr
N]. For simplicity
henceforth we drop the stage index r. Notice that the decreasing ordering of the computation times in
combination with (199)imply that SRPFLinitially beneﬁts by including only few fast nodes in the training
procedure. However, as the distance diminishes the improvement guaranteed by the contraction inequality
becomes negligible and thus our method beneﬁts by including slower nodes, thus decreasing the second term
of the r.h.s. of (199).
Let us denote by Xithe maximum distance for which the optimal number of participating nodes (for SRPFL)
isn0·2i. This deﬁnition immediately implies that X0= +∞. To compute each Xiwe turn our attention on
measuring the progress per unit of time achieved by SRPFL, when 2r·n0nodes are utilized. This ratio at
stagercan be expressed as
dist+−dist√1−a−a√
2r(1−a)
E[Tn02r] +C. (200)
33Published in Transactions on Machine Learning Research (10/2023)
Notice that by (199)the nominator captures the progress per round while the algorithm incurs E[Tn02r]
computation and Ccommunication cost. Similarly the ration when 2r+1·n0nodes are used is given by
dist+−dist√1−a−a√
2r+1(1−a)
E[Tn02r+1] +C. (201)
Based on the above inequalities we can now compute the optimal doubling points (in terms of distance) and
thus the values of Xi’s. Subsequently, we compute the number of iterations SRPFLspends in every stage.
Lemma B.1. For alliletXidenote the maximum distance for which the optimal number of nodes for SRPFL
isn0·2i. Then the following holds
∀i>0Xi=a/radicalbig
2r(1−a)1−√1−a)
1 +(E[Tn02r] +C)/parenleftBig
1−1√
2/parenrightBig
E[Tn02r+1]−E[Tn02r]
 (202)
X0= +∞
Further SRPFLspends at each stage rat mosttrcommunication rounds such that
tr≥2 log/parenleftbigg√
2(E[Tn02r+1]−E[Tn02r])
E[Tn02r]−E/bracketleftbig
Tn02r−1/bracketrightbig/parenrightbigg
log(1
1−a). (203)
Proof.For each stage rlet us compute the point where the transitioning between 2r·n0and2r+1·n0occurs.
That is the distance at which SRPFLbeneﬁts by doubling the number of participation nodes to 2r+1. Thus
equating the two ratios in (200) and (201) we get
Xr+1−Xr+1√1−a−a√
2r(1−a)
E[Tn02r] +C=Xr+1−Xr+1√1−a−a√
2r+1(1−a)
E[Tn02r+1] +C(204)
Xr+1(E[Tn02r+1]−E[Tn02r]) =a/radicalbig
2r(1−a)(1−√1−a)/parenleftbigg
E[Tn02r+1]−1√
2E[Tn02r] +C/parenleftbigg
1−1√
2/parenrightbigg/parenrightbigg
(205)
Xr+1=a/radicalbig
2r(1−a)(1−√1−a)
1 +(E[Tn02r] +C)/parenleftBig
1−1√
2/parenrightBig
E[Tn02r+1]−E[Tn02r]
 (206)
Let us now compute the number of rounds tr(henceforth denoted by t) required in stage r. That is the
minimum number of iterations that SRPFLneeds to decrease the distance from XrtoXr+1using only the
n02rfastest participating nodes. Thus, starting oﬀ at Xrand following (199) for trounds we have
Xt
r≤Xr(√
1−a)t+t−1/summationdisplay
i=0a/radicalbig
2r(1−a)(√
1−a)i(207)
As stated above we want to ﬁnd the minimum number of rounds such that we reach the next doubling point
i.e. we want tlarge enough such that
Xr+1≥Xr(√
1−a)t+t−1/summationdisplay
i=0a/radicalbig
2r(1−a)(√
1−a)i(208)
≥Xr(√
1−a)t+a/radicalbig
2r(1−a)·1−√1−at
1−√1−a(209)
34Published in Transactions on Machine Learning Research (10/2023)
where in the last inequality we use geometric series properties. We proceed to solve for tby rearranging and
using (202) and the fact that Xr>a√
2r(1−a)(1−√1−a),
(√
1−a)t≤/radicalbig
2r(1−a)(1−√1−a)Xr+1−a/radicalbig
2r(1−a)(1−√1−a)Xr−a(210)
≤(E[Tn02r]+C)/parenleftbig
1−1√
2/parenrightbig
E[Tn02r+1]−E[Tn02r]
√
2/parenleftbigg
(E/bracketleftbig
Tn02r−1/bracketrightbig
+C)/parenleftbig
1−1√
2/parenrightbig
E[Tn02r]−E/bracketleftbig
Tn02r−1/bracketrightbig+ 1−1√
2/parenrightbigg (211)
≤E[Tn02r]−E[Tn02r−1]
E[Tn02r+1]−E[Tn02r](212)
(213)
taking the logarithm on both sides we derive the required amount of rounds
t≥2 log/parenleftbigg√
2(E[Tn02r+1]−E[Tn02r])
E[Tn02r]−E/bracketleftbig
Tn02r−1/bracketrightbig/parenrightbigg
log(1
1−a)(214)
(215)
The following lemmas compute the ‘Wall Clock Time’ that SRPFLand FedReprequire in order to achieve
target accuracy /epsilon1. As discussed in Section 4.1 for fair comparison we consider accuracy of the form
/epsilon1= ˆcα/radicalBig
N
n0(1−α)/parenleftbig
1−√1−α/parenrightbig,with√
2>ˆc>1. (216)
When ˆctakes values close to√
2we expect SRPFLto vastly outperform FedRepand as ˆctakes values close to
1the performance gap diminishes.
Lemma B.2. Suppose at each stage the client’s computational times are i.i.d. random variables drawn from
the exponential distribution with parameter λ. Further, suppose that the expected communication cost per
round isC=c1
λ, for some constant c. Finally, consider target accuracy /epsilon1given in (12). Then the expected
‘Wall Clock Time’ for SRPFLis upper bounded as follows
E[TSRPFL ]≤logN/parenleftBigg
6(c+ 1) + 4 log(1
ˆc−1)
log(1
1−a)/parenrightBigg
1
λ(217)
Proof.First we upper bound the expected cost suﬀered by our method until the distance between the current
representation and the optimal representation becomes smaller than Xlog(N/n0), i.e. the cost corresponding to
the ﬁrst log/parenleftBig
N
2n0/parenrightBig
stages of SRPFL(denoted by E[TSRPFL ]) .
35Published in Transactions on Machine Learning Research (10/2023)
E/bracketleftbig
T1
SRPFL/bracketrightbig
=log(N
2n0)/summationdisplay
i=1ti(E[Tn02i] +C) (218)
≤log(N
2n0)/summationdisplay
i=12 (E[Tn02i] +C)·log/parenleftbigg√
2/parenleftbig
E/bracketleftbig
Tn02i+1/bracketrightbig
−E/bracketleftbig
Tn02i/bracketrightbig/parenrightbig
E/bracketleftbig
Tn02i/bracketrightbig
−E/bracketleftbig
Tn02i−1/bracketrightbig/parenrightbigg
log(1
1−a)(219)
≤log(N
4n0)/summationdisplay
i=12 (E[Tn0·2i] +C)log
√
2(E/bracketleftBig
TN
2/bracketrightBig
−E/bracketleftBig
TN
4/bracketrightBig
)
E/bracketleftBig
TN
4/bracketrightBig
−E/bracketleftBig
TN
8/bracketrightBig

log(1
1−a)
+ 2(E/bracketleftbig
TN/2/bracketrightbig
+C)log
√
2(E[TN]−E/bracketleftBig
TN
2/bracketrightBig
)
E/bracketleftBig
TN
2/bracketrightBig
−E/bracketleftBig
TN
4/bracketrightBig

log(1
1−a), (220)
where we used 214. Since the computational times of the clients come from the exponential distribution it is
straightforward to derive the following bounds
E[TN]−E/bracketleftbig
TN/2/bracketrightbig
=1
λN/2/summationdisplay
i=11
i≤1
λ(ln(N/2) + 1)≤1
λlog(N) (221)
E/bracketleftbig
TN/2/bracketrightbig
−E/bracketleftbig
TN/4/bracketrightbig
=1
λ/parenleftbigg1
N/2+ 1+1
N/2+ 2+...+1
3N/4/parenrightbigg
≥1
λ·N
4·4
3N=1
3λ(222)
E/bracketleftbig
TN/2/bracketrightbig
−E/bracketleftbig
TN/4/bracketrightbig
≤1
λ·N
4·2
N=1
2λ(223)
E/bracketleftbig
TN/4/bracketrightbig
−E/bracketleftbig
TN/8/bracketrightbig
=1
λ/parenleftbigg1
3N/4+ 1+1
3N/4+ 2+...+1
7N/8/parenrightbigg
≥1
λ·N
8·4
3N=1
6λ(224)
Making use of the above bounds the expression in 220 further simpliﬁes to
≤2log/parenleftbig
N
4n0/parenrightbig
/summationdisplay
i=1/bracketleftBigg
(E[Tn0·2i] +C)log(3√
2)
log(1
1−a)/bracketrightBigg
+ 2/parenleftbig
E/bracketleftbig
TN/2/bracketrightbig
+C/parenrightbiglog(3√
2 log(N))
log(1
1−a)(225)
≤5
log(1
1−a)
log/parenleftbig
N
4n0/parenrightbig
/summationdisplay
i=1E[Tn0·2i] + log/parenleftbiggN
2n0/parenrightbigg
·C
+ 2log(3√
2 log(N))
log(1
1−a)(E/bracketleftbig
TN/2/bracketrightbig
+C)(226)
Further, notice that
E/bracketleftbig
TN/2/bracketrightbig
=1
λN/2/summationdisplay
i=11
N/2+i≤1
λ, (227)
and similarly E/bracketleftbig
TN/4/bracketrightbig
≤1
λ·1
3,E/bracketleftbig
TN/8/bracketrightbig
≤1
λ·1
7,E/bracketleftbig
TN/16/bracketrightbig
≤1
λ·1
15and so on. Thus,
log/parenleftbig
N
4n0/parenrightbig
/summationdisplay
i=1E[Tn0·2i] =E[2n0] +E[4n0] +...+E[N/4]≤1
λ∞/summationdisplay
i=11
2i≤1
λ(228)
Combining the bounds from 227 and 228 and substituting C=c1
λin expression 226 we derive the following
bound
E/bracketleftbig
T1
SRPFL/bracketrightbig
≤5
log/parenleftBig
1
1−a/parenrightBig(clog(N/2n0) + 1)1
λ+2 log(3√
2 log(N))
log/parenleftBig
1
1−a/parenrightBig
(c+ 1)1
λ(229)
≤log(N/n0)6(c+ 1)
log/parenleftBig
1
1−a/parenrightBig·1
λ(230)
36Published in Transactions on Machine Learning Research (10/2023)
Having derived an upper bound on the cost suﬀered by SRPFLon the ﬁrst log/parenleftBig
N
2n0/parenrightBig
stages we now turn our
attention on bounding the cost incurred from Xlog(N
n0)until the target accuracy /epsilon1is achieved (denoted by
E/bracketleftbig
T2
SRPFL/bracketrightbig
). Recall that
Xlog(N/n0)=a/radicalBig
N
2n0(1−a)(1−√1−a)/parenleftBigg
1 +(E/bracketleftbig
TN/2/bracketrightbig
+C)(1−1√
2)
E[TN]−E/bracketleftbig
TN/2/bracketrightbig/parenrightBigg
(231)
and further during the last stage of SRPFL,Nclients are utilized deriving the following form in the contractions
inequality from (199)
dist+≤dist√
1−a+a/radicalBig
N
n0(1−a)witha≤1
4. (232)
We ﬁrst compute the number of rounds required in this second phase of the algorithm. Starting with distance
Xlog(N/n0)and following the contraction in (232) for trounds, we derive current distance at most
Xlog/parenleftbig
N
n0/parenrightbig·(√
1−a)t+t−1/summationdisplay
i=0a/radicalBig
N
n0(1−a)(√
1−a)i(233)
=Xlog/parenleftbig
N
n0/parenrightbig·(√
1−a)t+a/radicalBig
N
n0(1−a)1−√1−at
1−√1−a(234)
=a/radicalBig
N
n0(1−a)(1−√1−a)/parenleftBigg
√
2/parenleftBigg
1 +(E/bracketleftbig
TN/2/bracketrightbig
+C)(1−1√
2)
E[TN]−E/bracketleftbig
TN/2/bracketrightbig/parenrightBigg
(√
1−at) + (1−√
1−at)/parenrightBigg
(235)
where in the ﬁrst equality we use geometric series properties and in the second we substitute according to
(231). Using the fact that√
2(E[TN/2]+C)(1−1√
2)≤1
λ(c+ 1)(√
2−1)andE[TN]−E[TN/2]≤1
λlogN
expression (235) is upper bounded by
≤a/radicalBig
N
n0(1−a)(1−√1−a)/parenleftbigg/parenleftbigg√
2 +(c+ 1)(√
2−1)
logN/parenrightbigg
(√
1−at) + (1−√
1−at)/parenrightbigg
(236)
≤a/radicalBig
N
n0(1−a)(1−√1−a)+a/radicalBig
N
n0(1−a)(1−√1−a)·√
1−at(237)
The above implies that the number of rounds in the second phase is the smallest tso that the target accuracy
is achieved, i.e.,
/epsilon1≥a/radicalBig
N
n0(1−a)(1−√1−a)+a/radicalBig
N
n0(1−a)(1−√1−a)·√
1−at(238)
Further recall that from (216) the accuracy can be expressed in terms of
/epsilon1= ˆcα/radicalBig
N
n0(1−α)/parenleftbig
1−√1−α/parenrightbig,with√
2>ˆc>1. (239)
Combining the above and solving for twe derive the required number of rounds for the second phase
t≥2 log(1
ˆc−1)
log(1
1−a)(240)
The expected cost during phase 2can be computed as follows
37Published in Transactions on Machine Learning Research (10/2023)
E/bracketleftbig
T2
SRPFL/bracketrightbig
≤(E[TN] +C)/parenleftBigg
2 log(1
ˆc−1)
log(1
1−a)+ 1/parenrightBigg
(241)
≤(ln(N) + 1 +c)1
λ/parenleftBigg
2 log(1
ˆc−1)
log(1
1−a)+ 1/parenrightBigg
(242)
≤4 log(N)/parenleftBigg
log(1
ˆc−1)
log(1
1−a/parenrightBigg
1
λ(243)
≤log(N)·4
log(1
1−a)log/parenleftbigg1
ˆc−1/parenrightbigg1
λ(244)
Summing the two quantities of interest we can derive the promised upper bound on the ‘Wall Clock Time’ of
SRPFL.
E[TSRPFL ] =E/bracketleftbig
T1
SRPFL/bracketrightbig
+E/bracketleftbig
T2
SRPFL/bracketrightbig
(245)
≤log(N/n0)6(c+ 1)
log/parenleftBig
1
1−a/parenrightBig·1
λ+ log(N)·4
log(1
1−a)log/parenleftbigg1
ˆc−1/parenrightbigg1
λ(246)
≤logN/parenleftBigg
6(c+ 1) + 4 log(1
ˆc−1)
log(1
1−a)/parenrightBigg
1
λ(247)
Having computed an upper bound on the expected ‘Wall Clock Time’ of SRPFLwe proceed to compute an
lower bound on the expected ‘Wall Clock Time’ of FedRep.
Lemma B.3. Suppose at each stage the client’s computational times are i.i.d. random variables drawn from
the exponential distribution with parameter λ. Further, suppose that the expected communication cost per
round isC=c1
λ, for some constant c. Finally, consider target accuracy /epsilon1given in (12). Then the expected
‘Wall Clock Time’ for FedRepis lower bounded as follows
E[TFedRep ]≥logN
logN+ 2 log/parenleftBig
1
ˆc−1/parenrightBig
log/parenleftBig
1
1−a/parenrightBig
1
λ(248)
Proof.First we compute the number of rounds required by FedRepto achieve the target accuracy. Recall
that FedReputilizesNclients at each round deriving the following form of the contractions inequality from
(199)
dist+≤dist√
1−a+a/radicalBig
N
n0(1−a)witha≤1
4. (249)
Starting with distance equal 1and following the contraction in (249)fortrounds, we derive current distance
at most
(√
1−a)t+t−1/summationdisplay
i=0a/radicalBig
N
n0(1−a)(√
1−a)i= (√
1−a)t+a/radicalBig
N
n0(1−a)1−√1−at
1−√1−a, (250)
using the properties of geometric series. Further recall that from (216) the accuracy can be expressed as
/epsilon1= ˆcα/radicalBig
N
n0(1−α)/parenleftbig
1−√1−α/parenrightbig,with√
2>ˆc>1. (251)
38Published in Transactions on Machine Learning Research (10/2023)
The above imply that the number of rounds is going to be the smallest tthat guarantees that the target
accuracy has been achieved that is
ˆcα/radicalBig
N
n0(1−α)/parenleftbig
1−√1−α/parenrightbig≥(√
1−a)t+a/radicalBig
N
n0(1−a)1−√1−at
1−√1−a(252)
We use the fact that/radicalBig
N
n0(1−a)(1−√1−a)−a>0fora≤1/4and all reasonable values of Nto rearrange
and solve for t. Thus, we derive
t≥2 log/parenleftBig
1
ˆc−1/parenrightBig
log/parenleftBig
1
1−a/parenrightBig+logN
log/parenleftBig
1
1−a/parenrightBig (253)
Multiplying the number of rounds with a lower bound on the expected cost incurred per round, results in the
desired lower bound on the expected ‘Wall Clock Time’ suﬀered by FedRep:
E[TFedRep ]≥(E[TN] +C)
2 log/parenleftBig
1
ˆc−1/parenrightBig
log/parenleftBig
1
1−a/parenrightBig
 (254)
≥logN
logN+ 2 log/parenleftBig
1
ˆc−1/parenrightBig
log/parenleftBig
1
1−a/parenrightBig
1
λ(255)
Combining the results of Lemma B.2 and Lemma B.3 we obtain Theorem 4.9.
Theorem 4.9. Suppose that at each stage the client’s computational times are i.i.d. random variables drawn
from the exponential distribution with parameter λ. Further, suppose that the expected communication cost
per round isC=c
λ, for some constant c. Finally, consider the target error /epsilon1given in (12). Then, we have
E[TSRPFL ]
E[TFedRep ]=O/parenleftbigg
log(1
ˆc−1)
log(N)+log(1
ˆc−1)/parenrightbigg
.
Proof.
E[TSRPFL ]
E[TFedRep ]≤6(c+ 1) + 4 log(1
ˆc−1)
logN+ 2 log/parenleftBig
1
ˆc−1/parenrightBig=O
log/parenleftBig
1
ˆc−1/parenrightBig
log(N) + log/parenleftBig
1
ˆc−1/parenrightBig
 (256)
RemarkB.4.The initialization scheme in Algorithm 2 guarantees that dist/parenleftbig
B0,B∗/parenrightbig
≤1−c, with probability
at least 1−O/parenleftbig
(mn)−100/parenrightbig
, eﬀectively without increasing the overall sample complexity. The formal statement
and proof is identical to Theorem 3in (Collins et al., 2021) and is omitted.
C More on Experiments
Hyperparameters and choice of models. We set the hyperparameters following the work of (Collins
et al., 2021). Speciﬁcally, for the implementation of FedRepandFedRep-SRPFL we use SGD with momentum
where the momentum parameter is set to 0.5and the local learning rate to 0.1. Further, similarly to (Collins
et al., 2021) we set the local learning rate to 0.1for all other methods under consideration, which obtains
optimal performance. We ﬁx the batch size to 10for all our implementations. The number of local epochs
is set to 1for CIFAR10 with N= 100and to 5for the rest of the datasets. In terms of the choice of the
neural network model, for CIFAR10, we use LeNet-5 including two convolution layers with (64,64)channels
and three fully connected layers where the numbers of hidden neurons are (120,64). The same structure is
used for CIFAR100, but the numbers of channels in the convolution layers are increased to (64,128)and
the numbers of hidden neurons are increased to (256,128). Additionally, a dropout layer with parameter 0.6
is added after the ﬁrst two fully connected layers, which improves the testing accuracy. For EMNIST and
39Published in Transactions on Machine Learning Research (10/2023)
0.00 1.29 2.58 3.87 5.16
Homogeneous (C.T. = 0)1e23040506070T esting AccuracyCIFAR10, M=100, Shard=10
FedRep-SRPFL
FedRep
LG-SRPFL
LG-FedAvg
FLANP
FLANP-FT
FedAvg
FedAvg-FT
HFMAML
0.00 1.29 2.58 3.87 5.16
Homogeneous (C.T. = 0)1e2405060708090T esting AccuracyEMNIST, M=100, Shard=10
0.00 2.07 4.14 6.21 8.28
Homogeneous (C.T. = 0)1e20.600.650.700.750.80T esting AccuracySENT140, M=83, Shard=2
FedRep-SRPFL
FedRep
LG-SRPFL
LG-FedAvg
FLANP
FLANP-FT
FedAvg
FedAvg-FT
HFMAML
0.00 1.71 3.42 5.13 6.84
Homogeneous (C.T. = 10)1e23040506070T esting AccuracyCIFAR10, M=100, Shard=10
0.00 1.71 3.42 5.13 6.84
Homogeneous (C.T. = 10)1e2405060708090T esting AccuracyEMNIST, M=100, Shard=10
0.000 0.332 0.664 0.996 1.328
Homogeneous (C.T. = 10)1e30.600.650.700.750.80T esting AccuracySENT140, M=83, Shard=2
0.000 0.554 1.108 1.662 2.216
Homogeneous (C.T. = 100)1e33040506070T esting AccuracyCIFAR10, M=100, Shard=10
0.000 0.554 1.108 1.662 2.216
Homogeneous (C.T. = 100)1e3405060708090T esting AccuracyEMNIST, M=100, Shard=10
0.000 1.457 2.914 4.371 5.828
Homogeneous (C.T. = 100)1e30.600.650.700.750.80T esting AccuracySENT140, M=83, Shard=2
Figure 7: Numerical results on CIFAR10, EMNIST, Sent140 with full participation ( M=N) in the ﬁxed
computation speeds setting. ‘Shard’ denotes the number of classes per client. ‘C.T.’ denotes the communication
cost per round.
FEMNIST, we use MLP with three hidden layers with (512,256,64)hidden neurons. For Sent140 we use
two-layer bidirectional LSTM with dimension 256and dropout rate 0.5followed by a fully connected layer of
dimensions 5and a classiﬁcation head. Further, we use the standard glove embedding of dimension 100and
vocabulary of size 10000.
For the needs of SRFRL, we split the neural network model into two parts, the customized head hiand the
common representation φ. In our experiments, we simply take the customized head to be the last hidden
layer and the rest of the parameters are treated as the common representation. Note that LG-FedAvg and
LG-FLANP have a diﬀerent head/representation split scheme and the head is globally shared across all
clients while a local version of the representation is maintained on every client. For all included datasets,
i.e. CIFAR10, CIFAR100, EMNIST, FEMNIST and Sent140 the common head include the last two fully
connected layers and the rest of the layers are treated as the representation part.
Datasets. We include ﬁve datasets in our empirical study: CIFAR10 which consists of 10 classes and a
total number of 50,000 training data points, CIFAR100 which consists of 100 classes and the same amount of
data points as CIFAR10, and EMNIST (balanced) which consists of 47 classes and 131,600 training data
points. Note that in Figures 3-7, we use the ﬁrst 10 classes from EMNIST following (Collins et al., 2021).
For FEMNIST, we use the same setting as (Collins et al., 2021) with the exception that in Figures 3-6 we
allocate to each client 150data points and in Figure 6 we allocate to client i,(100 +ui)samples, with ui
a uniformly distributed random variable in [0,50]. The sentiment140 dataset contains 1,600,000tweets
annotated negative or positive and they can be used to detect sentiment. For this dataset we perform
pre-processing splitting the samples across clients both in a homogeneous as well as a heterogeneous manner.
The number of allocated samples to clients follow the log-normal distribution. During our training procedure,
we perform the data augmentation operations of standard random crop and horizontal ﬂip on the ﬁrst two
datasets and and perform no pre-processing for the last one.
Homogeneous Setting. Apart from providing straggler-resilience beneﬁts our method takes advantage of the
shared representation model to simultaneously address the hurdle of data heterogeneity. In the less challenging
40Published in Transactions on Machine Learning Research (10/2023)
0.00 1.29 2.58 3.87 5.16
T otal Time (C.T. = 0)1e220406080T esting AccuracyFEMNIST, M=100, Shard=3
FedRep-SRPFL
FedRep
LG-SRPFL
LG-FedAvg
FLANP
FLANP-FT
FedAvg
FedAvg-FT
HFMAML
0.00 0.58 1.16 1.74 2.32
Heterogeneous (C.T. = 0)1e20.600.650.700.750.80T esting AccuracySENT140, M=83, Shard=2
FedRep-SRPFL
FedRep
LG-SRPFL
LG-FedAvg
FLANP
FLANP-FT
FedAvg
FedAvg-FT
HFMAML
0.00 2.07 4.14 6.21 8.28
Stragglers % (C.T. = 0)1e20.600.650.700.750.80T esting AccuracySENT140, M=83, Shard=2
FedRep-SRPFL-10%
FedRep-SRPFL-30%
FedRep-10%
FedRep-30%
LG-SRPFL-10%
LG-SRPFL-30%
LG-FedAvg-10%
LG-FedAvg-30%
0.00 1.29 2.58 3.87 5.16
T otal Time (C.T. = 0)1e220304050607080T esting AccuracyCIFAR10, M=100, Shard=5
FedRep-SRPFL
FedRep
LG-SRPFL
LG-FedAvg
FLANP
FLANP-FT
FedAvg
FedAvg-FT
HFMAML
0.00 1.71 3.42 5.13 6.84
T otal Time (C.T. = 10)1e220406080T esting AccuracyFEMNIST, M=100, Shard=3
0.00 1.83 3.66 5.49 7.32
Heterogeneous (C.T. = 10)1e20.600.650.700.750.80T esting AccuracySENT140, M=83, Shard=2
0.000 0.332 0.664 0.996 1.328
Stragglers % (C.T. = 10)1e30.600.650.700.750.80T esting AccuracySENT140, M=83, Shard=2
0.00 1.71 3.42 5.13 6.84
T otal Time (C.T. = 10)1e220304050607080T esting AccuracyCIFAR10, M=100, Shard=5
0.000 0.554 1.108 1.662 2.216
T otal Time (C.T. = 100)1e320406080T esting AccuracyFEMNIST, M=100, Shard=3
0.000 1.308 2.616 3.924 5.232
Heterogeneous (C.T. = 100)1e30.600.650.700.750.80T esting AccuracySENT140, M=83, Shard=2
0.000 1.457 2.914 4.371 5.828
Stragglers % (C.T. = 100)1e30.600.650.700.750.80T esting AccuracySENT140, M=83, Shard=2
0.000 0.554 1.108 1.662 2.216
T otal Time (C.T. = 100)1e320304050607080T esting AccuracyCIFAR10, M=100, Shard=5
Figure 8: Numerical results on FEMNIST, Sent140, CIFAR10 in the ﬁxed computation speeds setting. From
left to right: Imbalanced/Imbalanced/Stragglers%/Correlated Heterogeneity. ‘Shard’ denotes the number of
classes per client.‘C.T.’ denotes the communication cost per round.
homogeneous setting one would expect FedRep-SRPFL to lose some of its competitive advantage. However,
our numerical results in Figure 7 indicate that our method exhibits a stable performance while maintaining
an edge over the other baselines. We note that LG-SRPFL outperforms FedRep-SRPFL in the Sent140 dataset
where LG-FedAvg appears to be better-suited than FedRep. Importantly, our doubling scheme continues to
enhance both subroutines providing clear straggler-resilience beneﬁts even in data homogeneous environments.
Additional Regimes. In Figure 8 we observe the extent at which the beneﬁts of our meta-algorithm
persist in various regimes. Imbalanced Datasets. In the two left columns we explore how the performance of
our doubling scheme degrades for diﬀerent levels of imbalanced local datasets. In the FEMNIST dataset
we allocate to each client i,(100 +ui)local samples where uiis a random variable uniformly distributed in
[0,50]. In this setting the numbers of local samples are suﬃciently close and as a result the beneﬁts of our
scheme are prevalent for all diﬀerent values of communication cost. As we allow the clients to have more
diverse numbers of local samples however, the speedup provided by our doubling scheme diminishes. Indeed
this is the case in the Sent140 dataset where we allocate data to clients in a more dispropotional manner
following the log-normal distribution. We point out that in settings with high diversity simply doubling the
number of clients is not suﬃcient. Instead, to achieve optimal performance one needs to select consecutive
participating sets of clients with cumulative number of samples that double from one stage to the next.
Diﬀerent levels of stragglers. We further consider the setting where clients are split into two categories.
The ﬁrst category consists of typically fast clients whose computational values come from the exponential
distribution with λ= 0.1. The second category consists of clients who are typically straggling, i.e. sampling
their computational cost from the exponential distribution with λ= 10. On the third column of Figure 8 we
compare FedRep,LG-FedAvg and their straggler-resilient variants for diﬀerent percentages of clients coming
from the latter category. Unsurprisingly, the performance of the methods under consideration degrades as
the percentage of stragglers increases however our doubling scheme to some extent mitigates this eﬀect.
Correlated heterogeneity. In this setting we assign data to clients depending on their speeds. More speciﬁcally,
41Published in Transactions on Machine Learning Research (10/2023)
we split clients into 3 groups based on the computational times and respectively we group samples into 3
distinct groups based on their labels. Subsequently, we allocate mutually exclusive (with respect to their
labels) groups of data to speciﬁc groups of clients. The rightmost column of Figure 8 indicates that the
beneﬁts of our doubling scheme persist, although to a lesser degree as the correlation between data and
system heterogeneity grows.
42