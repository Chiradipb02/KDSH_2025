Under review as submission to TMLR
Incorporating Interventional Independence Improves Ro-
bustness against Interventional Distribution Shift
Anonymous authors
Paper under double-blind review
Abstract
We consider learning discriminative representations of variables related to each other via a
causal graph. To learn representations that are robust against interventional distribution
shifts, the training dataset is augmented with interventional data in addition to existing
observational data. However, even when the underlying causal model is known, existing
approaches treat interventional data like observational data, ignoring the independence re-
lations resulting from these interventions. This leads to representations that exhibit large
disparities in predictive performance on observational and interventional data. The perfor-
mance disparity worsens when the quantity of interventional data available for training is
limited. In this paper, (1) we first identify a strong correlation between this performance
disparity and adherence of the representations to the statistical independence conditions
induced by the underlying causal model during interventions. (2) For linear models, we de-
rive sufficient conditions on the proportion of interventional data during training, for which
enforcing statistical independence between representations corresponding to the intervened
node and its non-descendants during interventions can lower the test-time error on interven-
tional data. Following these insights, we propose RepLIn, an algorithm to explicitly enforce
this statistical independence during interventions. We demonstrate the utility of RepLIn
on synthetic and real face image datasets. Our experiments show that RepLIn is scalable
with the number of nodes in the causal graph and is suitable to improve the robustness
of representations against interventional distribution shifts of both continuous and discrete
latent variables compared to the ERM baselines.
1 Introduction
We consider the problem of learning discriminative representations corresponding to latent random variables
for their prediction from their observable data. The relationship between these latent variables can be
modeledusingdirectedacyclicgraphs(DAGs)called causal graphs . Theselatentvariablesusuallycorrespond
to semantic concepts such as the color of an object, the level of glucose in the blood, and a person’s age.
Causal modeling allows manually altering the causal graph and observing its effects on the data, for instance,
by consuming an insulin inhibitor and measuring the glucose level in the blood. This procedure is known
as acausal intervention , and the data collected through this procedure is called interventional data . In
contrast, data collected without intervention is known as observational data . Several types of interventions
are possible on a causal graph, of which we are interested in hard interventions where we manually set the
value of one or more variables. Intervening on a node renders it statistically independent of its parent nodes
in the causal graph1. See (Peters et al., 2017, Chapter 6) and (Pearl, 2009, Chapter 3).
Suppose the latent variables are AandB, such thatA→B(AcausesB) during observations. An attribute-
specific representation FAcorresponding to Alearned by a model from observational training data alone
may contain information about its child node Bdue to the association between AandB. Subsequently,
these models show a performance drop on data collected through intervention on Bduring inference. In
1For ease of use, we refer to “statistical independence” as “independence”, and “hard interventions” as “interventions”. We
will also use “features” to describe the representations a model learns from data.
1Under review as submission to TMLR
other words, these models are not robust against interventional distribution shifts . Interventional data
samples are included in the training data to learn models that are robust to interventional distribution
shifts. For example, in (Sauer & Geiger, 2021; Gao et al., 2023), interventional data was generated using
data augmentations to train image classification models invariant to texture and background. In some works
such as (Arjovsky et al., 2019; Heinze-Deml & Meinshausen, 2021), interventional data is treated merely
as data sourced from different domains or environments , and they do not consider the explicitstatistical
independence relations that arise from interventions2. As we demonstrate, ignoring these independence
relations may result in representations still susceptible to interventional distribution shifts during inference.
Additionally, performing interventions is often challenging, thus limiting the amount of interventional data
available for training. Therefore, causally motivated learning is necessary to improve the robustness of
learned representations against interventional distribution shifts.
We first consider a simple case study in which we observe that models that do not learn independent repre-
sentations during interventions show a performance drop on interventional data. We then derive sufficient
conditions on the proportion of interventional data during training, for which enforcing linear independence
between interventional features of linear models during training can reduce test-time error on interven-
tional data. Following the theoretical assessment, we propose “Rep resentation L earning from In terventional
Data” (RepLIn ), an algorithm to train models with improved robustness against interventional distribution
shifts. We confirm the utility of RepLIn on synthetic (Sec. 5.1) and real face image datasets (Sec. 5.2) and
demonstrate its scalability to the number of nodes (Sec. 6.2).
To summarize our contributions,
•We demonstrate a positive correlation between accuracy drop during interventional distribution shift
and dependence between representations corresponding to the label node and its children. We refer
to this as “interventional feature dependence” (Sec. 3.3).
•We theoretically explain why linear ERM models are susceptible to interventional distribution shifts
in the regime of linear causal models. In the same setting, we theoretically and empirically show that
enforcing linear independence between interventional features improves robustness when sufficient
interventional data is available during training and establish the sufficient condition (Sec. 3.4).
•We propose a novel training algorithm that combines these insights and demonstrates that this
model minimizes the drop in accuracy under interventional distribution shifts by explicitly enforcing
independence between interventional features (Sec. 4).
2 Related Works
Identifiable Causal Representation Learning (ICRL) (Locatello et al., 2019; Schölkopf et al., 2021;
Hyvärinen et al., 2024) seeks to learn representations of the underlying causal model under certain assump-
tions (Hyvärinen et al., 2024), and is, therefore, important to interpretable representation learning. However,
we are interested in a broader class of discriminative representation learning when some underlying causal
relations are known. In contrast to learning the entire causal model, we seek to exploit the known inde-
pendence relations from interventions to learn discriminative representations that are robust against these
interventions. We provide a detailed review of ICRL in App. C.
Interventional data is key in causal discovery (Eberhardt et al., 2005; Yu et al., 2019; Ke et al., 2019; Lippe
et al., 2022a; Wang et al., 2022) as one can only retrieve causal relations up to Markov equivalent graph
without interventions or assumptions on the causal model. For example, known interventional targets have
beenusedforunsupervisedcausaldiscoveryoflinearcausalmodels(Subramanianetal.,2022), interventional
and observational data have been leveraged for training a supervised model for causal discovery (Ke et al.,
2022), and interventions with unknown targets were used for differentiable causal discovery (Brouillard et al.,
2020). Interventional data also find applications in reinforcement learning (Gasse et al., 2021; Ding et al.,
2022) and recommendation systems (Zhang et al., 2021; Krauth et al., 2022; Luo et al., 2024). While this
2Note that distribution shifts due to differing environments is more general than interventional distribution shift. However,
in this work, we argue against an agnostic treatment against interventional distribution shift.
2Under review as submission to TMLR
body of work focuses on discovering causal relations in the data, our work considers how to leverage known
causal relations to learn data representations that are robust to distribution shifts induced by interventions.
Training with group-imbalanced data leads to models that suffer from group-bias during inference.
In such cases, resampling the data according to the inverse sample frequency can improve generalization
and robustness. Studies such as (Gulrajani & Lopez-Paz, 2021; Idrissi et al., 2022) have shown that ERM
with resampling is effective against spurious correlations and is a strong baseline for domain generalization.
Recent work such as dynamic importance reweighting (Fang et al., 2020), SRDO (Shen et al., 2020), and
MAPLE (Zhou et al., 2022) learn to resample using a separate validation set that acts as a proxy for the test
set. However, learning such a resampling requires a large dataset of both observational andinterventional
data, which is often not practically feasible. In contrast, we will exploit known independence relations during
interventions to improve robustness to interventional distributional shifts.
3 The Learning from Interventional Data Problem
Notation: Random variables and random vectors are denoted by regular (e.g., A) and bold (e.g., a) sans-
serif uppercase characters, respectively. The distribution of a random variable Ais denoted by PA.
A1A2 . . .Am U
X BA1A2 . . .Am U
X′ ˜B
During observation During intervention
Figure 1: Causal graph modification due to inter-
vention: Duringobservation, Bistheeffectofitsparent
variablesPaB={A1,...,Am}. When we intervene on
B, it becomes statistically independent of its parents.We now formally define the problem of interest
in this paper, namely learning discriminative rep-
resentations to predict latent variables that are
robust against interventional distribution shifts3,
in general terms, and examine a specific case
study in Sec. 3.1. The learning problem is char-
acterized by a DAG Gthat causally relates our
attributes of interest A1,...,Am, andB. Let
PaB={A1,...,Am}denotetheparentsoftheat-
tributeB. These attributes along with other un-
observed exogenous variables U, generate the ob-
servabledata X, i.e.,X=gX(B,A 1,...,Am,U).
During interventions, the variable Bis set to values drawn from a known distribution independent of PaB.
Therefore, the post-intervention variable B(denoted by ˜B) is statistically independent of its parents, i.e.,
˜B⊥ ⊥PaB, as shown in Fig. 1. Although gXis not affected by this intervention, the distribution of X(now
denoted byX′) will change since it is a function of B. Note that to learn representations that are robust
against distribution shift due to intervention on B, our setting does not provide the knowledge of any node
apart from Band its parents in this causal graph or of any causal relations between A1,...,Am. We also do
not have restrictions on the functional form of causal relations between A1,...,Am,B, andX, or on their
marginal distributions. For training, data samples from both observational and interventional distributions
are available, i.e., Dtrain=Dobs∪DintwhereDobs∼P(X,B,A 1,...,Am)andDint∼P(X′,˜B,A 1,...,Am).
GivenDtrainandG, the goal is to learn attribute-specific discriminative representations FB=hB(X)and
FAi=hAi(X)that are robust against distribution shifts due to intervention on B.
3.1 Does Accuracy Drop during Interventions Correlate with Interventional Feature Dependence?
First, we consider a motivating case study on a synthetic dataset and establish a correlation between the
accuracy drop on interventional data and statistical dependence between the attribute representations under
intervention. We will then estimate the strength of this correlation and theoretically investigate whether
this correlation can be exploited to improve the robustness against interventional distribution shifts.
Problem Setting: Consider the causal graph shown in Fig. 2a. Here, AandBare binary random variables
that generate the observed data X∈R2.Xis also affected by an unobserved noise variable U. Therefore,
functionallyX=gX(A,B,U).Aitself could be a function of unobserved random factors that are of no
predictive interest to us. Therefore, we model A∼Bernoulli (0.6). The distribution of Bis only affected by
3We use “discriminative” to explicitly state that the purpose of these representations is robust prediction and not data
generation. Information loss with improved robustness is therefore acceptable.
3Under review as submission to TMLR
A B
X U
−2 0 2
X1−202X2
(a) Observational graph and data
A ˜B
X′U
−2 0 2
X1−202X2
 (b) Interventional graph and data
Data legend
A=0,B=0
A=0,B=1
A=1,B=0
A=1,B=1
Figure 2: An illustration of Windmill Dataset: AandBare binary random variables that are causally
linked to each other and X, as shown in (a). By intervening on Bas shown in (b), we make A⊥ ⊥˜B.
X=gX(A,B,U)whereUdenotes unobserved noise variables. The true decision boundaries for predicting
AandBfromXare shown in red and blue dashed lines, respectively. See App. F for a detailed description.
A, as denoted by the arrow between them. Analytically, B:=A, where :=indicates the causal assignment
operator, following (Peters et al., 2017). Visually, the observed data looks like a windmill. The value of
Adetermines the windmill’s blade, and Bdetermines the radial distance. We shear the windmill blades
according to a sinusoidal function of the radial distance. To make the data more stochastic, the points’
precise angle and radial distance are sampled from an unobserved distribution independent of AandB. In
Fig. 2b, we intervene on B, modeled as ˜B∼Bernoulli (0.5). This induces a change in the distribution of
Band subsequently that of X. Since the intervention is independent of A,˜Bis also independent of A,
denoted by removing the arrow between Aand ˜B. Note that gXis unaffected by this intervention. The
exact mathematical formulation of the data-generating process is provided in App. F.
Learning task: The task is to accurately predict AandBfromXat test time. We have Nsamples for
training, where βNare interventional and (1−β)Nare observational with 0<β < 1typically being a small
value. Forthisdemonstration, weset N= 40,000,β= 0.01. Therefore, wehave39,600observationaland400
interventional samples. We train a feed-forward network with two hidden layers to learn representations FA
andFBcorresponding to AandB, respectively. We normalize them by dividing each by their corresponding
L2norm. Separate linear classifiers predict AandBfromFAandFBrespectively. By construction, gX
in the data-generating process is a one-to-one mapping. Therefore, predicting AandBfromXaccurately
is possible. However, the true decision boundary for Ais more complex than that of B4. Therefore, the
model may rely on information from Bto predictAdue to their association during observation, similar to
the concept of simplicity bias from (Shah et al., 2020). As a result, FAmay contain information about B
even during interventions when A⊥ ⊥B.
ERM versionAccuracy in predicting A Accuracy in predicting BNHSIC
Observation Intervention Relative drop Observation Intervention Relative drop
Vanilla 99.97 58.56 0.414 100 100 0 0.786
w/ Resampling 93.24 68.65 0.264 100 99.99 10−40.537
Table1: Therelativedropinaccuracyinpredicting Acorrelateswellwithagapinthemeasureofdependence
between the learned representations on interventional data.
Observations: Following the standard ERM framework, the cross entropy errors in predicting Aand
BfromFAandFB, respectively, provide the training signal. The statistical loss function can be writ-
ten asLtotal(f,X) =EPtrain[Lpred(f,X)]. The training distribution is a mixture of observational and
interventional distributions with (1−β)andβacting as the corresponding mixture weights. Thus,
Ltotal(f,X) = (1−β)EPobs/bracketleftbig
Lpred(f,Xobs)/bracketrightbig
+βEPint[Lpred(f,Xint)]. Tab. 1 shows the accuracy of ERM in
predictingAandBon observational and interventional data during validation. Ideally, we expect no drop in
accuracy from observation to intervention if the learned representations are robust against interventional dis-
4We informally define “complexity” as the minimum polynomial degree required to approximate the decision boundary.
4Under review as submission to TMLR
tribution shift. However, we observe that ERM performs only slightly better than random chance in predict-
ingAon interventional data. As a remedy, we consider a stronger version of ERM by sampling observational
and interventional data in separate batches. This is equivalent to sampling interventional data/parenleftig
1−β
β/parenrightig
-times
as observational data. Therefore, we refer to this version as “ERM-Resampled”. The equivalent loss for a
learning function fin ERM-Resampled is Ltotal(f,X) =EPobs/bracketleftbig
Lpred(f,Xobs)/bracketrightbig
+EPint[Lpred(f,Xint)]. Note
thatβdoes not appear in Ltotal(f,X)due to resampling. Although ERM-Resampled performs better than
vanilla ERM, we observe that ERM-Resampled still exhibits a large drop in predictive accuracy between
observational and interventional data during inference. Also, observe the drop in observational accuracy of
ERM-Resampled in predicting Aas it improved interventional accuracy. As we will show in Sec. 3.4, the
reduced observational accuracy is due to the removal of spurious information that had previously improved
its observational accuracy.
3.2 Measuring Statistical Dependence Between Interventional Features
A key characteristic of hard interventions in causal graphs is that the variable being intervened upon be-
comes independent of all its nondescendants. Since the predictive accuracy on the parent node is affected
by intervention, we hypothesize that the representation corresponding to the parent node is dependent on
the child node during intervention . Therefore, to verify our hypothesis, we measure the dependence be-
tween the representations. We measure the dependence between the representations instead of between the
representations and the latent attributes because we aim to learn robust representations for every attribute.
Dependence Measure: To measure dependence between a pair of high-dimensional continuous random
variablesXandY, we use HSIC (Gretton et al., 2005), a non-parametric measure of dependence. Given N
i.i.d. samplesX=/braceleftbig
x(i)/bracerightbigN
i=1andY=/braceleftbig
y(i)/bracerightbigN
i=1fromXandY, empirical HSIC between these samples can
be computed as HSIC (X,Y) =1
(N−1)2Trace [KXHKYH], whereHis theN×Ncentering matrix, and
KX,KY∈RN×NareGrammatriceswhose (i,j)thentriesarekX/parenleftbig
x(i),x(j)/parenrightbig
andkY/parenleftbig
y(i),y(j)/parenrightbig
, respectively.
Here,kXandkYare the kernel functions associated with a universal kernel (e.g., RBF kernel). Since HSIC
is unbounded, we normalize it as NHSIC (X,Y) =HSIC (X,Y)√
HSIC (X,X)HSIC (Y,Y), following (Cortes et al., 2012;
Cristianini et al., 2001).
We use the NHSIC metric to compare the statistical dependence between the features in the Windmill
problem. Tab. 1 shows the difference in NHSIC values between the features FAandFBfrom interventional
data. We observe that ERM-Resampled learns features with less statistical dependence during interventions
than vanilla ERM. A larger interventional feature dependence indicates a larger violation of the underlying
statistical independence relations that result from interventions in the causal graph.
3.3 Strength of Correlation between Drop in Accuracy and Interventional Features Dependence
0.0 0.2 0.4
Rel.∆in accuracy0.00.20.40.60.8NHSIC
r: 0.81, t: 0.61
(a) Rel. ∆against NHSIC
0.0 0.2 0.4
Rel.∆in accuracy0.40.60.81.0KCC
r: 0.75, t: 0.56 (b) Rel. ∆against KCC
Figure 3: Across models with different capacities, a
relative drop in accuracy is always accompanied by
interventional feature dependence, while the corollary
does not hold. Interventional feature dependence is
measured using NHSIC and KCC.How strong is the observed correlation between the
dependence of features and the drop in accuracy?
For a given combination of predictive task and
dataset, does it hold for a variety of hyperparameter
settings? Toanswerthesequestions, wetrainseveral
modelsundertheERM-Resampledsettingdescribed
in Sec. 3.1. To learn representations, we use feed-
forward networks, each with one to six hidden layers
and with 20 to 200 hidden units. We also randomly
set the number of training epochs to use early-
stopping as a regularizer, as described in (Sagawa
et al., 2020). To measure the robustness of a model
to interventional distribution shift, we evaluate the
relative drop in accuracy between observational and
interventional data: Rel. ∆ =Obs acc.−Int acc.
Obs acc..
5Under review as submission to TMLR
In Fig. 3, we plot the relative drop in accuracy
against the interventional feature dependence. In
addition to NHSIC, we also use kernel canonical correlation (KCC) (Bach & Jordan, 2002) to measure the
dependence. We observe that all models with a high relative drop in accuracy also have a large interven-
tional feature dependence (see top-right regions of the plots). However, the corollary is not true – a large
interventional feature dependence does not mean a relative drop in accuracy. Therefore, we conclude that
a relative drop in accuracy is always accompanied by interventional feature dependence . The strength of the
correlation between the relative drop in accuracy and interventional feature dependence is quantitatively
measured using Spearman rank correlation coefficient ( ρ) (Spearman, 1904) and Kendall rank correlation
coefficient ( τ) (Kendall, 1938). In Fig. 3a, ρ= 0.81andτ= 0.61when the dependence is measured using
NHSIC, indicating that the correlation we noted in Sec. 3.2 can be observed for a wide range of models.
When KCC is used for measuring dependence between interventional representations, ρ= 0.75andτ= 0.56
as shown in Fig. 3b. Note that the correlation measures are affected by the choice of measure of dependence.
Both NHSIC and KCC satisfy the postulates for an appropriate measure of dependence in (Rényi, 1959) and
measure dependence from the spectrum of the cross-covariance operator between RKHSs. However, NHSIC
measures the Hilbert-Schmidt norm of the cross-covariance operator while KCC measures its spectral norm.
Therefore, KCC is a “harsher” measure of dependence compared to NHSIC. Asimilarly strongcorrelation
canbeobserved between therelativedropinaccuracy andKCCinFig. 3b.
3.4 Will Minimizing Dependence between Interventional Features Improve Robustness?
Fig. 3 showed that strong interventional feature dependence always accompanies a large relative drop in
accuracy. Based on this correlation, we may ask the following question: will minimizing interventional
feature dependence improve the robustness to interventional distribution shifts? We consider a linear causal
model to answer this question theoretically. The detailed proof of each step is provided in App. B.
Causal Model: We use the causal model shown in Fig. 2a with AandBbeing continuous random variables.
AandBare causally related during observation as B:=wABA. The observed data signal Xis generated
fromAandBasX:=/bracketleftbiggXA
XB/bracketrightbigg
+U, whereXA:=wAAandXB:=wBB.U:=/bracketleftbiggUA
UB/bracketrightbigg
is exogenous noise.
UAandUBare independent of AandBrespectively. We intervene on Bas shown in Fig. 2b, severing the
causal relation between AandB. The intervened variable is denoted as B′andB′⊥ ⊥A.
Learningmodel: Similartothecasestudy, thetaskistopredictthelatentvariables AandBfromobserved
data signalX. The training dataset is sampled from a training distribution Ptrainthat contains observational
and interventional samples. We model Ptrainas a mixture of observation distribution Pobsand interventional
distribution Pintwith (1−β)andβacting as the mixture weights, i.e., Ptrain = (1−β)Pobs+βPint. We
use linear models to learn attribute-specific representations FAandFB, from which predictions ˆAand ˆB,
respectively, are made using the classifiers. The linear models are parameterized by Θ(A)andΘ(B), and the
classifiers are parameterized by c(A)andc(B).
Statistical Risk: The parameter matrix of the linear feature extractor described before can be written in
terms of its constituent parameter vectors as Θ(A)=/bracketleftigg
θ(A)⊤
A
θ(A)⊤
B/bracketrightigg
. Assuming zero mean for all latent variables,
the statistical squared error of an arbitrary model in predicting Afrom an interventional test sample Xis,
EA=/parenleftig
1−wAc(A)⊤θ(A)
A/parenrightig2
ρ2
A+/parenleftig
c(A)⊤θ(A)
A/parenrightig2
ρ2
UA/bracehtipupleft /bracehtipdownright/bracehtipdownleft /bracehtipupright
E(1)
A+/parenleftig
wBc(A)⊤θ(A)
B/parenrightig2
ρ2
B′+/parenleftig
c(A)⊤θ(A)
B/parenrightig2
ρ2
UB/bracehtipupleft /bracehtipdownright/bracehtipdownleft /bracehtipupright
E(2)
A(1)
whereρ2
A=EPint/bracketleftbig
A2/bracketrightbig
,ρ2
B′=EPint/bracketleftbig
B′2/bracketrightbig
,ρ2
UA=EPint/bracketleftbig
U2
A/bracketrightbig
, andρ2
UB=EPint/bracketleftbig
U2
B/bracketrightbig
. The statistical risk can
be split into two components: (1) E(1)
Ain terms of AandUA, and (2)E(2)
Ain terms of BandUB.E(2)
A̸= 0
whenθ(A)
B̸=0. A non-zero θ(A)
Bindicates that the representation FAis a function of XB, i.e., it learns
a spurious correlation with B. Thus the prediction ˆAis susceptible to interventions on B. In contrast, a
robust model will have θ(A)
B=0, and thusE(2)
A= 0. Derivation of Eq. (1) is provided in App. B.1.
6Under review as submission to TMLR
Optimal ERM model: The optimal ERM model can be obtained by minimizing the expected risk in
predicting the latent attributes. Since parameters are not shared between the prediction of aandb, we
can consider their optimization separately. We will consider the optimization of parameters for predicting a
since we are interested in the performance drop in predicting Afrom interventional data.
Θ(A)∗,c(A)∗= argmin
Θ(A),c(A)EPtrain/bracketleftbigg/parenleftig
A−c(A)⊤Θ(A)⊤X/parenrightig2/bracketrightbigg
(2)
For a given training error, there is no unique solution for Θ(A)andc(A). Therefore, we can equivalently
optimize forψA=c(A)⊤Θ(A)⊤. We can write ψA=/bracketleftbiggψ1
ψ2/bracketrightbigg
whereψ1=c(A)⊤θ(A)
Aandψ2=c(A)⊤θ(A)
B. The
learning objective in Eq. (2) then reduces to,
ψ∗
A= argmin
ψAEPtrain/bracketleftig
(A−ψAX)2/bracketrightig
(3)
We can solve Eq. (3) by setting the gradients to zero. To check the robustness of the optimal ERM model,
we can verify whether ψ∗
2= 0or not since a robust model will have θ(A)
B=0. Solving Eq. (3), we get:
ψ∗
2=−(1−β)wBwABσ2
Aσ2
UA
T̸= 0 (4)
whereTis a non-zero scalar. This implies that E(2)
A̸= 0in optimal ERM models. Therefore, optimal ERM
are not robust against interventional distribution shift . Also, note that a robust model is not a minimizer
of prediction loss on the training distribution as the minimizer in Eq. (4) leads to non-zero θ(A)
B. This can
explain the drop in observational accuracy of ERM-Resampled as it improved the interventional accuracy in
predictingAin Sec. 3.1. The detailed derivation is provided in App. B.2.
Minimizing linear dependence: In Sec. 3.3, we showed that dependence between interventional features
correlated positively with the drop in accuracy on interventional data. We will now verify if minimizing
dependence between interventional features can minimize the drop in accuracy. The interventional features
are given byFA=Θ(A)⊤XandF′
B=Θ(B)⊤X.
FA=Θ(A)⊤X=XAθ(A)
A+XBθ(A)
B
F′
B=Θ(B)⊤X=XAθ(B)
A+XBθ(B)
B
For ease of exposition, we will minimize the linear dependence between interventional features instead of
enforcing the full statistical independence we described in Sec. 3.2. Following the definition of HSIC (Gretton
et al., 2005), the linear dependence in interventional features can be defined as follows5,
Dep(FA,F′
B) =/vextenddouble/vextenddoubleEPint/bracketleftbig
FAF′⊤
B/bracketrightbig/vextenddouble/vextenddouble2
F(5)
Leveraging the independence relations during interventions, we can expand Eq. (5) as,
/vextenddouble/vextenddoubleEPint/bracketleftbig
FAF′⊤
B/bracketrightbig/vextenddouble/vextenddouble2
F=/vextenddouble/vextenddouble/vextenddouble(w2
Aρ2
A+ρ2
UA)θ(A)
Aθ(B)⊤
A + (w2
Bρ2
B′+ρ2
UB)θ(A)
Bθ(B)⊤
B/vextenddouble/vextenddouble/vextenddouble2
F(6)
The dependence loss is thus the Frobenius norm of a sum of rank-one matrices. There are three classes of
solutions that minimize Eq. (6): (1) θ(A)
A=θ(A)
B=θ(B)
A=θ(B)
B=0, (2)θ(A)
A=±γθ(A)
Bandγθ(B)
A=∓θ(B)
B
for some scalar γ̸= 0, and (3)θ(A)
A=0orθ(B)
A=0, andθ(A)
B=0orθ(B)
B=0. However, all except two
of these solutions produce trivial features and increase the classification error. The only remaining non-
degenerate solutions are: (S1) θ(A)
A=0,θ(B)
B=0, and (S2)θ(A)
B=0,θ(B)
A=0. Note that (S2) corresponds
to a robust model. Since both (S1) and (S2) minimize Eq. (5), the solution that minimizes the prediction
error on both AandBduring training will prevail.
5For a complete definition of the dependence, refer to App. B.3.
7Under review as submission to TMLR
Proposition 1. The total training error for (S1) is strictly greater than that of (S2) when the following
conditions are satisfied: (1) β≥1−1
|wAB|, (2)β≥min/parenleftbigg
ρ2
A
2ρ2
B′+ρ2
A,ρ2
UA
w2
Aw2
ABρ2
A/parenrightbigg
.
Proposition 1 states that a robust model is guaranteed when a minimum amount of interventional data is
available during training. Note that Proposition 1 describes sufficient conditions for (S1) to have a larger
training error than (S2). In practice, βcould be smaller. Refer to App. B.3 for a detailed derivation and
experimental verification of Proposition 1.
ERM Linear independence
0.4950.5000.505Test error
(a)E(1)
A
0.000.02Test error
 (b)E(2)
A
0.500.520.54Test error
(c)EAFigure 4: Robust models achieve E(2)
A= 0in Eq. (1).
ERM models have a non-zero θ(A)
Bresulting in E(2)
A̸=
0. Minimizing linear independence on interventional
features results in orthogonal interventional feature
spaces where θ(A)
B=θ(B)
A=0. Thus, they result in
robust models with E(2)
A= 0.
Experimental verification: To experimentally verify the theoretical results, we simulate the causal model
by settingwA=wB=wAB= 1. The random variables A,B,UA, andUBare sampled from independent
normal distributions with zero mean and unit variance. We generate N= 50000 data points for training
withβ= 0.5. The classifiers use 2-dimensional features learned by linear feature extractors to predict A
andB. The experiment is repeated with 50 seeds. In Eq. (1), the statistical risk was shown to be composed
ofE(1)
AandE(2)
A, plotted in Figs. 4a and 4b respectively. An ideal robust model will achieve E(2)
A= 0. As
expected, both models have similar E(1)
A. However, linear independence models minimize E(2)
A, resulting in
a lower total error EAshown in Fig. 4c.
4 RepLIn: Enforcing Statistical Independence between Interventional Features
XEncoder A
Encoder BFA
FBClassifier A
Classifier BˆA
ˆBA
BLpred
LpredLdep(only during interventions )Lself
LselfERM
• Uses only Lpredfor training.
• Ignores distribution changes from
causal interventions.
RepLIn (ours)
•Ldep: consistency with interventional
causal model.
•Lself: encourage to learn relevant infor-
mation only.A
BX
A
˜BX′During observations
During interventions
Figure 5: Schematic illustration of RepLIn for a causal graph with two attributes ( A→B)andX=
f(A,B,U). Encoders learn representations FAandFBcorresponding to AandB, which are then used
by their corresponding classifiers to predict ˆAand ˆBrespectively. On interventional samples, we minimize
Ldepbetween the features to ensure their independence. On all samples, we minimize Lselfto encourage the
representations to learn only the relevant information.
As noted in the previous section, there is a strong correlation between the drop in accuracy during interven-
tions and interventional feature dependence. We also showed theoretically that minimizing linear dependence
between interventional features can improve test time error on interventional data for linear models. Based
on this observation, we propose “Rep resentation L earning from In terventional data” (RepLIn) to learn dis-
criminative representations that are robust against interventional distribution shifts.
To enforce independence between interventional features, we propose to use dependence-guided regulariza-
tion denoted asLdepover the prediction loss function (e.g., cross-entropy for classification tasks) used in
ERM. We refer to this regularization as “dependence loss” and is defined for the general case in Sec. 3 as
8Under review as submission to TMLR
Ldep=/summationtextn
i=1NHSIC (Fint
Ai,Fint
B). We minimize the dependence loss onlyfor the interventional samples in
our training set since congruent statistical independence occurs in the data space only during interventions.
However,Ldepalone is insufficient since learning irrelevant features can minimize Ldep. To avoid
such pathological scenarios and encourage the model to learn only relevant information, we intro-
duce another loss that maximizes the dependence between a feature and its corresponding label. We
employ this “self-dependence loss” on both observational and interventional data and define it as
Lself= 1−NHSIC (FB,B)+/summationtextn
i=1NHSIC (FAi,Ai)
2(n+1). However, in contrast to Ldep, we use linear kernels in Lself
to maximize a lower estimate of the dependence between the representations and the labels. Using linear
kernels in HSIC amounts to kP/parenleftbig
x(i),x(j)/parenrightbig
=x(i)⊤x(j)in Sec. 3.2. In summary, RepLIn optimizes the fol-
lowing total loss: Ltotal=Lpred+λdepLdep+λselfLself, whereλdepandλselfare weights that control the
contribution of the respective losses. A pictorial overview of the RepLIn pipeline is shown in Fig. 5.
5 Experimental Evaluation
In this section, we compare the performance of RepLIn to the baselines on synthetic and real face image
datasets. We use the Windmill dataset introduced in Sec. 3.1 to verify the effectiveness of RepLIn and eval-
uate its broader applicability to practical scenarios through the facial attribute prediction task on the CelebA
dataset. Our experiments are designed to validate the following hypothesis: Does explicitly minimizing the
interventional feature dependence improve interventional accuracy?
Training Hyperparameters and Baselines: We consider vanilla ERM and ERM-Resampled (Chawla
et al., 2002; Cateni et al., 2014) as our primary baselines since they are the most commonly used train-
ing algorithms. ERM-Resampled is a strong baseline for group-imbalanced training and domain general-
ization (Idrissi et al., 2022; Gulrajani & Lopez-Paz, 2021). On Windmill dataset, we also consider the
following SOTA algorithms in domain generalization: IRMv1 (Arjovsky et al., 2019), Fish (Shi et al., 2022),
GroupDRO (Sagawa et al., 2020), SAGM (Wang et al., 2023), DiWA (Rame et al., 2022), and TEP (Qiao
& Peng, 2024). The latter two are weight-averaging methods, for which we train 20 independent models per
seed. We study two variants of our method: RepLIn and RepLIn-Resampled . The latter variant uses the
resampling strategy from ERM-Resampled. In each method, attribute-specific representations are extracted
from the input data, which feed into the classifiers to get the final prediction. All baselines share the same
architecture for feature extractors. Linear classifiers are used for all baselines. We note that the values of
λdepandλselfin RepLIn variants are kept fixed across all proportions of interventional data β. A detailed
description of the datasets and the training settings is provided in App. A.
Evaluation Criterion: Our primary interest is in investigating the accuracy drop when predicting the
variables that are unaffected by interventions. Ideally, if the learned features respect causal relations during
interventions, we expect no change in the prediction accuracy of parent variables of the intervened variable
between observational and interventional distributions. To measure the change, we use the relative drop in
accuracy defined in Sec. 3.3: Rel. ∆ =Obs acc.−Int acc.
Obs acc.. Since we optimize NHSIC during training, we use
NKCC from Sec. 3.3 to evaluate the dependence between the features on interventional data during testing.
We repeat each experiment with five different random seeds and report the mean and standard deviation.
5.1 Windmill dataset
We first evaluate our method on the synthetic dataset that helped us identify the relation between the
performance gap in predicting Aon observational and interventional data in Sec. 3.1. As a reminder, the
causal graph consists of two binary random variables AandB, whereA→Bduring observations. We
intervene by setting B∼Bernoulli (0.5), breaking the dependence between AandB. The proportion of
interventional samples in the training data varies from β= 0.01toβ= 0.5.
Tab. 2 compares the interventional accuracy of Afor various amounts of interventional data. We make the
following observations: (1)our model outperforms every baseline in interventional accuracy for all values
ofβ. This clearly demonstrates the advantage of exploiting the underlying causal relations when learning
9Under review as submission to TMLR
Accuracy on interventional data. The relative drop in accuracy is shown in parentheses.
Method β= 0.5 β= 0.3 β= 0.1 β= 0.05 β= 0.01
ERM 76.87±1.08(0.18±0.01)69.86±3.19(0.29±0.04)62.78±1.77(0.37±0.02) 59.52±1.30(0.40±0.01)60.15±3.12(0.40±0.03)
ERM-Res. 73.70±3.19(0.22±0.04)71.19±3.23(0.24±0.03)73.62±1.54(0.22±0.02) 71.03±2.83(0.25±0.03)70.20±3.73(0.26±0.03)
IRMv1 78.24±0.79(0.16±0.01)74.83±1.74(0.20±0.02)78.61±2.24(0.16±0.02) 76.28±1.87(0.18±0.02)71.75±2.03(0.24±0.02)
Fish 77.23±2.24(0.19±0.02)77.23±1.32(0.19±0.01)78.24±2.09(0.18±0.02) 76.42±1.95(0.20±0.02)73.92±2.53(0.23±0.03)
GroupDRO 80.10±1.66(0.02±0.01)80.96±1.33(0.04±0.02)80.35±1.01(0.06±0.02)77.40±1.16(0.08±0.01)71.86±1.60(0.22±0.02)
SAGM 76.43±2.37(0.19±0.02)79.05±2.23(0.17±0.02)76.96±4.36(0.18±0.03) 79.86±1.81(0.16±0.02)72.81±3.10(0.23±0.03)
DiWA 76.61±2.15(0.19±0.02)76.71±0.59(0.19±0.01)76.09±0.69(0.20±0.01) 75.83±1.83(0.20±0.02)73.39±1.31(0.22±0.01)
TEP 58.68±4.72(0.06±0.19)60.42±1.30(0.09±0.06)56.07±3.35(−0.04±0.42)58.52±4.36(0.01±0.25)59.23±1.13(0.18±0.11)
RepLIn 87.94±1.46(0.08±0.02)87.76±2.30(0.10±0.02)83.23±2.67(0.16±0.03) 73.63±2.43(0.25±0.02)67.52±2.30(0.32±0.03)
RepLIn-Res. 88.46±0.96(0.07±0.01)88.05±1.04(0.08±0.01)87.91±1.36(0.08±0.01)86.38±0.85(0.10±0.01)78.41±1.27(0.18±0.02)
Table 2:Results on Windmill dataset: We evaluate the variants of RepLIn (highlighted in gray) against
the baselines on two metrics: interventional accuracy and relative accuracy drop on interventional data com-
pared to observational. As the proportion of interventional data during training ( β) decreases, the problem
becomes more challenging. Compared to the baselines, RepLIn maintains its interventional accuracy. A sim-
ilar trend is observed in the relative accuracy drop, where RepLIn significantly outperforms most baselines.
Thebestand thesecond-best results are shown in different colors. “Res.” stands for “Resampled”.
from interventional data, instead of treating it as a separate domain, and (2)comparing ERM and RepLIn
with their resampling variants, we observe that resampling is a generally useful technique with large gains
whenβis very small (for example, consider results with β≤0.05). We are also interested in the relative
drop in accuracy between observational and interventional data (Rel. ∆). From Tab. 2, we observe that
GroupDRO has the lowest Rel. ∆among the considered methods for β≥0.05, and achieves its best results
when more interventional data is available during training. However, this improvement comes at the cost
of lower interventional accuracy. Meanwhile, the relative drop in accuracy of RepLIn is comparable to
GroupDRO at larger values of βand has the least relative drop in accuracy at lower values of β. DiWA and
TEP were provided with the same pool of models trained with minor variations in their hyperparameters.
We ignore the Rel. ∆of TEP since it has very low accuracy, performing barely above random chance. We
discuss in Sec. 6.1 how the representations learned by RepLIn are less affected by interventional shifts. As
mentioned in Sec. 3.1, interventional robustness may be at odds with observational accuracy as removing
spurious information from representations may hurt performance on observational data. We provide the
results on observational data in App. D.
5.2 Facial Attribute Prediction
WeverifytheutilityofRepLInforpredictingfacialattributesontheCelebAdataset(Liuetal.,2015). Images
in the CelebA dataset are annotated with 40 labeled binary attributes. We consider two of these attributes
–smiling and gender– as random variables affecting each other causally. Since the true underlying
relation between smile and gender is unknown, we adopt the resampling procedure from (Wang & Boddeti,
2022) to induce a desired causal relation between the attributes ( smiling→gender) and obtain samples.
Specifically, to simulate this causal relation, we sample smiling from Bernoulli (0.6)first and then sample
genderaccordingtoaprobabilitydistributionconditionedonthesampled smiling variable. Wethensample
a face image whose attribute labels match the sampled values. We model the diversity in the images due
to unobserved noise variables. Note that, unlike in Windmill , the noise variables in this experiment may
becausally related to the attributes that we wish to predict, adding to the challenges in the dataset. The
causal model for this experiment and some sample images are shown in Fig. 7.
Smiling Gender
(a) Observational causal graph and samples
Smiling Gender
 (b) Interventional causal graph and samples
Figure 7: Causal model for CelebA before and after intervention along with sample images from these models
10Under review as submission to TMLR
Given the face images, we first extract features from ResNet-50 (He et al., 2016) pre-trained on ImageNet
dataset (Deng et al., 2009). Then, similar to the architecture for Windmill experiments, we employ a
shallow MLP to act on these features, followed by a linear classifier to predict the attributes. Our loss
functions act upon the features of the MLP. We use 30,000 samples for training and 15,000 for testing.
We use the relative drop in interventional accuracy as the primary metric and compare RepLIn-Resampled
against ERM-Resampled. We also verify if the correlation between interventional feature dependence and the
relative drop in accuracy observed in Sec. 3.3 on Windmill experiments holds in a more practical scenario.
ERM-Resampled RepLIn-Resampled
10−1
b0.050.100.150.20Rel.∆
(a) Accuracy
10−1
b0.20.40.6KCC
 (b) Dependence
0.1 0.2
Rel.∆0.20.40.6KCCr: 0.86 (c) CorrelationFigure 8: Facial Attribute Prediction:
(a) RepLIn has a lower relative drop in accu-
racy compared to ERM-Resampled. (b) Minimizing
interventional feature dependence during training
generalizes to testing. (c) Interventional feature
dependence correlates positively with the relative
drop in accuracy.
Fig. 8 reports the experimental results on facial attribute prediction for various amounts of interventional
trainingdata. Wemakethefollowingobservations: (1)astheproportionofinterventionaldataincreases, the
relative drop in accuracy in all methods decreases, (2)across all proportions of interventional data, RepLIn
consistently outperforms the baseline by 4%−7%lower relative drop in accuracy despite the potential
challenges due to noise variable being causally related to the attributes of interest, (3)relative drop in
accuracy and interventional feature dependence show strong positive correlation ( ρ= 0.86), and(4)the
interventionalfeaturedependenceofRepLInsteadilydecreasesastheamountofinterventionaldataincreases.
5.3 Toxicity Prediction in Text
We further evaluate RepLIn on a text classification task on the CivilComments dataset (Borkan et al., 2019).
CivilComments consists of comments from online forums, and we use a subset of this dataset labeled with
identity attributes (such as “Male”, “White”, “LGBTQ”, etc.) and toxicity scores by humans. The task is
to classify each comment as toxic or not. Previous works have identified gender bias in toxicity classifier
models (Dixon et al., 2018; Park et al., 2018; Nozza et al., 2019). Therefore, we will simulate a causal model
in the training dataset between the attribute “female” and toxicity, similar to Sec. 5.2. During observation,
both attributes assume the same binary value. During interventions, toxicity takes value independent of
“female”. Input text comments are sampled according to these attributes. Similar to our facial attribute
prediction experiments, we first extract features from the comments using BERT Devlin et al. (2019) and
train the models on these features. Our model architecture consists of a linear layer to learn representations
and a linear layer to predict toxicity.
ERM-Resampled RepLIn-Resampled
10−210−1
b0.060.080.100.12Rel.∆
(a) Accuracy
10−210−1
b0.40.6KCC
 (b) Dependence
0.05 0.10
Rel.∆0.40.60.8KCCr: 0.81 (c) CorrelationFigure9:ToxicityPredictioninText: (a)RepLIn
has lower interventional accuracy drop compared to
ERM-Resampled; (b) Minimizing Ldepduring train-
inggivesusrepresentationsthatareindependentdur-
ing interventions; (c) The strong correlation between
accuracy drop and interventional feature dependence
further corroborates our hypothesis in Sec. 3.2.
Fig. 9 compares the performance of RepLIn against ERM-Resampled. Fig. 9b shows that enforcing inde-
pendence between interventional features minimizes the interventional feature dependence during testing,
although its effectiveness drops as βapproaches 0.01. Yet, RepLIn outperforms the baseline in terms of the
accuracy drop during interventions (Fig. 9a).
11Under review as submission to TMLR
6 Discussion
6.1 How does RepLIn improve robustness against interventional distribution shift?
In Sec. 3.4, we showed theoretically that enforcing linear independence between interventional features can
improve robustness in a linear model. We verified our claims experimentally in non-linear settings in Sec. 5.
In this section, we qualitatively and quantitatively compare the interventional features learned by various
methods to understand how RepLIn improves robustness against interventional distribution shift.
Top row: When A=0, Bottom row: When A=1 B=0 B=1
0 2
Inclination0369Density
−5−2 1 4
Azimuth03Density
0 2
Inclination036Density
−5−2 1 4
Azimuth036Density
(a) ERM
0 2
Inclination036Density
−5−2 1 4
Azimuth02Density
0 2
Inclination036Density
−5−2 1 4
Azimuth01Density (b) ERM-Resampled
0 3
Inclination02Density
−4−1 2
Azimuth0Density
−1 2
Inclination01Density
−4−1 2
Azimuth0Density (c) RepLIn-Resampled
Figure 10: Visualization of interventional features learned by various methods on Windmill dataset.
Method ERM ERM-Resampled IRMv1 Fish GroupDRO RepLIn RepLIn-Resampled
WhenA= 0 0.45±0.058 0.423±0.105 0.333±0.122 0.341±0.111 0.365±0.066 0.15±0.03 0.188±0.032
WhenA= 1 0.499±0.07 0.456±0.11 0.405±0.111 0.37±0.116 0.431±0.048 0.183±0.058 0.168±0.047
Average 0.475±0.063 0.439±0.105 0.369±0.116 0.355±0.113 0.398±0.055 0.166±0.035 0.178±0.036
Table 3: Jensen-Shannon (JS) divergence: The distribution of Fint
Amust be invariant to the value
assumed by BsinceA⊥ ⊥Bduring interventions. Therefore, JS divergence between P(Fint
A|B= 0,A=a)
andP(Fint
A|B= 1,A=a)of a robust model must be zero. We compare the JS divergence between
interventional features of the baselines for β= 0.5. Among the baselines, RepLIn achieves the lowest values
of Jensen-Shannon divergence. The lowest and the second lowest scores are highlighted in color.
Windmill dataset: We consider the distribution of Fint
Afor a fixed value of Aand changing values of
B. Robust representations of Achange with Abut notB. The distribution shift in Fint
Adue to changes
inBcan be quantitatively measured using Jensen-Shannon (JS) divergence. In Tab. 3, we calculate JS
divergence between P(Fint
A|B= 0,A=a)andP(Fint
A|B= 1,A=a)for all methods trained on Windmill
dataset. JS divergence for an ideal robust model must be zero. We observe that Fint
Alearned by RepLIn
achieves the lowest JS divergence. This shows that Fint
Alearned by RepLIn contains the least information
aboutBamong the baselines. In our experiments on Windmill dataset, all baselines learned 3-dimensional
features that lay on a unit radius sphere. Therefore, we can visualize the distributions of their spherical
angles, namely inclination and azimuth. We compare the distributions of inclination and azimuth of Fint
A
learned by RepLIn-Resampled against the ERM baselines in Fig. 10. Each row shows the distribution of the
spherical angles for different values of A. Distributions for different values of Bhave separate colors. These
feature distributions for a robust model must change with Abut notB. We observed from the figure that
the feature distributions of the baselines are affected by Band notAdue to the dependence between Fint
A
andB. However, the feature distributions learned by RepLIn change with Aand overlap significantly when
Btakes different values. Thus, our models perform similarly to a robust model. Visualizations of the feature
distributions of other baselines are provided in App. E.
CelebA dataset: Our learned representations on CelebA are high-dimensional, and therefore we employ
Grad-CAM (Selvaraju et al., 2017) to analyze the features and compare them against those learned by ERM-
Resampled. Since our primary metric is accuracy in predicting smiling during interventions, we visualize
12Under review as submission to TMLR
(a) ERM-Resampled
(b) RepLIn-ResampledFigure 11: Consider these sample face images where
thesubjectsaresmiling. TheERMbaselinemisclassi-
fiedthesesamplesasnotsmiling, whileRepLInclassi-
fied them correctly. We use GradCAM visualizations
to identify the regions in the input images that the
models used to make their predictions. The ERM
model relied on factors such as hair and the presence
of a hat that may correlate with gender to predict
whetherthesubjectsaresmiling. Incontrast, RepLIn
attended to the lip regions to make predictions.
the parts of the input image that the models attend to for predicting a smile. We consider some samples with
smiling = 1 that were misclassified by ERM-Resampled but were correctly classified by RepLIn-Resampled.
Comparing these predictions would help us explain the robustness of RepLIn. Fig. 11 shows the attention
maps from models trained on datasets with 50% interventional data. A robust model would attend to facial
regions surrounding lips to make predictions about smiling. Observe that RepLIn-Resampled tends to focus
more on the region around the lips while ERM-Resampled attends to other regions of the face.
6.2 Scalability with number of nodes
A
B C
D E
(a) Observational
A
B ˜C
D E (b) Intervening on C
A
B C
˜D E(c) Intervening on D
A
B C
D ˜E(d) Intervening on EXA=MLP 6(A)
XB=MLP 4(B)
XC=MLP 1(C)
XD=MLP 1(D)
XE=MLP 1(E)
(e) Generating X
Figure 12: 5-variable causal graph : We construct a 5-variable causal graph to demonstrate the scalability
of our method with the number of nodes. To collect interventional data, we intervene on C,D, andE
separately and measure the performance drop in predicting AandBduring these interventions. Nodes in
the graphs with dashed borders indicate intervened nodes. Note that we do not intervene on multiple targets
at a time. The input data signal Xis constructed as a concatenation of individual input signals, each being
a function of a latent variable, i.e., X=/bracketleftbig
X⊤
AX⊤
BX⊤
CX⊤
DX⊤
E/bracketrightbig⊤Here, MLP lindicates a randomly
initialized MLP with llinear layers, each followed by a ReLU. We also add Gaussian noise sampled from
N(0,0.01)to the output of the MLP.
Consider a causal graph with Nnodes, each with Kparent nodes. To learn robustness against distribution
shifts due to interventions on Mnodes, RepLIn requires only the independence relations between these
Mnodes and their parents and the data resulting from separate interventions on these nodes. Therefore,
RepLIn can scale with MandK. To verify this scalability, we use the causal graph shown in Fig. 12a with
five latent variables. It consists of two binary source nodes AandB, and three binary derived nodes C,D,
andE. During observations, AandBare sampled from independent Bernoulli (0.5)distributions. During
observation, the remaining nodes take the following logical expressions: C:=AorB,D:=AandB, and
E:=notBandC. Like our previous experiments, the training dataset has interventional data samples
collected by intervening on nodes C,D, andEseparately in addition to the observational data. The changes
in the causal graph due to these interventions are shown in Figs. 12b to 12d. Each intervened variable
assumes values from a Bernoulli (0.5)distribution independent of their parents. Each latent variable ∗is
passed through a randomly initialized MLP with noise added to its output to get a corresponding observed
signalX∗. These individual signals are concatenated to obtain the observed input signal X, as shown in
Fig. 12e. The task is to predict the latent variables from the input signal X. Since we are interested in the
13Under review as submission to TMLR
robustness of the model against interventional distribution shift, our primary metrics will be the predictive
accuracy for AandBduring interventions on C,D, andE.
Each batch comprises only observational or interventional data after intervention on a single target. There-
fore, our method only enforces the independence relations from at most one interventional target in each
batch. The validation and test sets consist of samples collected during interventions on C,D, orE. The
predictive performances on the test sets are reported in Table 4. We observe that RepLIn significantly im-
proves over the baseline with sufficient interventional data, β >0.1. When the proportion of interventional
dataβ≤0.1, RepLIn is comparable with the baseline, suggesting that the benefits of enforcing independence
between interventional features extend to larger causal graphs with multiple intervention targets.
Interventional
targetMethodPredictive accuracy on A Predictive accuracy on B
β= 0.5β= 0.3β= 0.1β= 0.05β= 0.5β= 0.3β= 0.1β= 0.05
CERM-Resampled 79.71±0.30 76.22±0.42 73.97±0.39 73.56±0.36 87.60±0.06 85.45±0.23 83.89±0.33 83.71±0.40
RepLIn-Resampled 95.37±0.97 78.77±0.54 72.15±0.31 73.74±0.3696.72±0.81 86.16±0.63 82.35±0.95 82.43±0.65
DERM-Resampled 79.65±0.43 75.47±0.64 71.76±0.35 70.27±0.34 91.05±0.29 90.21±0.27 90.36±0.58 90.55±0.74
RepLIn-Resampled 95.49±1.01 77.76±0.82 71.20±0.82 68.80±0.79 97.87±0.31 92.21±0.48 91.40±0.79 90.88±0.89
EERM-Resampled 86.63±0.33 81.90±0.26 76.20±0.84 73.46±0.37 81.12±0.22 78.00±0.48 74.02±0.38 72.97±0.38
RepLIn-Resampled 96.71±0.49 84.68±0.36 75.01±0.53 71.52±0.87 96.89±0.68 80.88±0.57 72.81±1.13 71.60±0.59
Table 4:Results on 5-variable causal graph: We compare the accuracy of RepLIn in predicting the
sourcenodes AandBduringinterventionsonnon-sourcenodes C,D,andEagainstthatofERM-Resampled.
Our approach outperforms the baselines with sufficient interventional data.
7 Conclusion
This paper considered the problem of learning representations that are robust against interventional dis-
tribution shifts by leveraging the statistical independence induced by interventions in the underlying data-
generating process. First, we established a strong correlation between the drop in accuracy during interven-
tions and statistical dependence between representations on interventional data. We then showed theoreti-
cally that minimizing linear dependence between interventional representations can improve the robustness
of a linear model against interventional distribution shift. Building on this result, we proposed RepLIn
to learn representations that are robust against interventional distribution shift by explicitly enforcing sta-
tistical independence between learned representations on interventional data. Experimental evaluation of
RepLIn across different scenarios corresponding to different causal graphs showed that RepLIn can improve
predictive accuracy during interventions for various proportions of interventional data. RepLIn is also scal-
able to the number of causal attributes and can be used with continuous and discrete latent variables. We
used qualitative and quantitative tools to show that RepLIn is more successful in learning interventional
representations that do not contain information about their child nodes during interventions.
Limitations: We assume access to interventional data and information about the intervened node and
its parent variables. However, this may be challenging to obtain in practice, especially in safety-critical
applications such as drug testing and autonomous driving. In such cases, generative models could generate
synthetic interventional data. Another assumption is that hard interventions may not be possible due to
real-world experimental constraints. Specialized solutions may be required for such cases. For example,
(Bagi et al., 2024) uses a “switch variable” to model soft interventions.
References
Kartik Ahuja, Jason S Hartford, and Yoshua Bengio. Weakly supervised representa-
tion learning with sparse perturbations. In Advances in Neural Information Process-
ing Systems , 2022a. URL https://papers.nips.cc/paper_files/paper/2022/hash/
63d3bae2c1f525745003f679e45bcf7b-Abstract-Conference.html .
Kartik Ahuja, Divyat Mahajan, Vasilis Syrgkanis, and Ioannis Mitliagkas. Towards efficient representation
identification in supervised learning. In Conference on Causal Learning and Reasoning , 2022b.
14Under review as submission to TMLR
Kartik Ahuja, Yixin Wang, Divyat Mahajan, and Yoshua Bengio. Interventional causal representation
learning. In International Conference on Machine Learning , 2023.
Martin Arjovsky, Léon Bottou, Ishaan Gulrajani, and David Lopez-Paz. Invariant risk minimization. arXiv
preprint arXiv:1907.02893 , 2019. URL https://arXiv.org/abs/1907.02893 .
Francis R Bach and Michael I Jordan. Kernel independent component analysis. Journal of Machine Learning
Research , 3(Jul):1–48, 2002.
ShayanShirahmadGaleBagi, ZahraGharaee, OliverSchulte, andMarkCrowley. Disentanglementinimplicit
causal models via switch variable. arXiv preprint arXiv:2402.11124 , 2024.
Daniel Borkan, Lucas Dixon, Jeffrey Sorensen, Nithum Thain, and Lucy Vasserman. Nuanced metrics for
measuring unintended bias with real data for text classification. In ACM Web Conference , 2019.
Johann Brehmer, Pim De Haan, Phillip Lippe, and Taco Cohen. Weakly supervised causal representation
learning. In Advances in Neural Information Processing Systems , 2022.
Philippe Brouillard, Sébastien Lachapelle, Alexandre Lacoste, Simon Lacoste-Julien, and Alexandre Drouin.
Differentiable causal discovery from interventional data. In Advances in Neural Information Processing
Systems, 2020.
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind
Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are few-shot learners.
InAdvances in Neural Information Processing Systems , 2020.
Silvia Cateni, Valentina Colla, and Marco Vannucci. A method for resampling imbalanced datasets in binary
classification tasks for real-world problems. Neurocomputing , 135:32–41, 2014.
Nitesh V Chawla, Kevin W Bowyer, Lawrence O Hall, and W Philip Kegelmeyer. Smote: Synthetic minority
over-sampling technique. Journal of Artificial Intelligence Research , 16:321–357, 2002.
CorinnaCortes, MehryarMohri, andAfshinRostamizadeh. Algorithmsforlearningkernelsbasedoncentered
alignment. Journal of Machine Learning Research , 13:795–828, 2012.
Nello Cristianini, John Shawe-Taylor, Andre Elisseeff, and Jaz Kandola. On kernel-target alignment. In
Advances in Neural Information Processing Systems , 2001.
Mostafa Dehghani, Josip Djolonga, Basil Mustafa, Piotr Padlewski, Jonathan Heek, Justin Gilmer, An-
dreas Peter Steiner, Mathilde Caron, Robert Geirhos, Ibrahim Alabdulmohsin, et al. Scaling vision
transformers to 22 billion parameters. In International Conference on Machine Learning , 2023.
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-scale hierarchical
image database. In IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2009.
JacobDevlin,Ming-WeiChang,KentonLee,andKristinaToutanova. Bert: Pre-trainingofdeepbidirectional
transformers for language understanding. In Conference of the North American Chapter of the Association
for Computational Linguistics: Human Language Technologies , 2019.
Wenhao Ding, Haohong Lin, Bo Li, and Ding Zhao. Generalizing goal-conditioned reinforcement learning
with variational causal reasoning. In Advances in Neural Information Processing Systems , 2022.
Lucas Dixon, John Li, Jeffrey Sorensen, Nithum Thain, and Lucy Vasserman. Measuring and mitigating
unintended bias in text classification. In AAAI/ACM Conference on AI, Ethics, and Society , 2018.
Frederick Eberhardt, Clark Glymour, and Richard Scheines. On the number of experiments sufficient and in
the worst case necessary to identify all causal relations among n variables. In Conference on Uncertainty
in Artificial Intelligence , 2005.
Tongtong Fang, Nan Lu, Gang Niu, and Masashi Sugiyama. Rethinking importance weighting for deep
learning under distribution shift. In Advances in Neural Information Processing Systems , 2020.
15Under review as submission to TMLR
Irena Gao, Shiori Sagawa, Pang Wei Koh, Tatsunori Hashimoto, and Percy Liang. Out-of-domain robustness
via targeted augmentations. In International Conference on Machine Learning , 2023.
Maxime Gasse, Damien Grasset, Guillaume Gaudron, and Pierre-Yves Oudeyer. Causal reinforcement learn-
ing using observational and interventional data. arXiv preprint arXiv:2106.14421 , 2021.
Arthur Gretton, Olivier Bousquet, Alex Smola, and Bernhard Schölkopf. Measuring statistical dependence
with hilbert-schmidt norms. In International Conference on Algorithmic Learning Theory , 2005.
Ishaan Gulrajani and David Lopez-Paz. In search of lost domain generalization. In International Conference
on Learning Representations , 2021. URL https://openreview.net/forum?id=lQdXeXDoWtI .
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In
IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2016.
ChristinaHeinze-DemlandNicolaiMeinshausen. Conditionalvariancepenaltiesanddomainshiftrobustness.
Machine Learning , 110(2):303–348, 2021.
Aapo Hyvarinen and Hiroshi Morioka. Unsupervised feature extraction by time-contrastive learning and
nonlinear ica. In Advances in Neural Information Processing Systems , volume 29, 2016.
Aapo Hyvarinen, Hiroaki Sasaki, and Richard Turner. Nonlinear ica using auxiliary variables and generalized
contrastive learning. In The 22nd International Conference on Artificial Intelligence and Statistics , 2019.
Aapo Hyvärinen, Ilyes Khemakhem, and Ricardo Monti. Identifiability of latent-variable and structural-
equation models: from linear to nonlinear. Annals of the Institute of Statistical Mathematics , 76(1):1–33,
2024.
Badr Youbi Idrissi, Martin Arjovsky, Mohammad Pezeshki, and David Lopez-Paz. Simple data balancing
achieves competitive worst-group-accuracy. In Conference on Causal Learning and Reasoning , 2022. URL
https://proceedings.mlr.press/v177/idrissi22a.html .
Nan Rosemary Ke, Olexa Bilaniuk, Anirudh Goyal, Stefan Bauer, Hugo Larochelle, Bernhard Schölkopf,
Michael C Mozer, Chris Pal, and Yoshua Bengio. Learning neural causal models from unknown interven-
tions.arXiv preprint arXiv:1910.01075 , 2019.
Nan Rosemary Ke, Silvia Chiappa, Jane Wang, Jorg Bornschein, Theophane Weber, Anirudh Goyal,
Matthew Botvinic, Michael Mozer, and Danilo Jimenez Rezende. Learning to induce causal structure.
InInternational Conference on Learning Representattions , 2022.
Maurice G Kendall. A new measure of rank correlation. Biometrika , 30(1/2):81–93, 1938.
Ilyes Khemakhem, Diederik Kingma, Ricardo Monti, and Aapo Hyvarinen. Variational autoencoders and
nonlinear ica: A unifying framework. In International Conference on Artificial Intelligence and Statistics ,
2020.
DiederikPKingmaandJimmyBa. Adam: Amethodforstochasticoptimization. In International Conference
on Learning Representations , 2015.
David Klindt, Lukas Schott, Yash Sharma, Ivan Ustyuzhaninov, Wieland Brendel, Matthias Bethge, and
Dylan Paiton. Towards nonlinear disentanglement in natural data with temporal sparse coding. In
International Conference on Learning Representations , 2021.
Lingjing Kong, Shaoan Xie, Weiran Yao, Yujia Zheng, Guangyi Chen, Petar Stojanov, Victor Akinwande,
and Kun Zhang. Partial identifiability for domain adaptation. In International Conference on Machine
Learning , 2022. URL https://proceedings.mlr.press/v162/kong22a.html .
Karl Krauth, Yixin Wang, and Michael I Jordan. Breaking feedback loops in recommender systems with
causal inference. arXiv preprint arXiv:2207.01616 , 2022.
16Under review as submission to TMLR
Sébastien Lachapelle, Pau Rodriguez, Yash Sharma, Katie E Everett, Rémi Le Priol, Alexandre Lacoste,
and Simon Lacoste-Julien. Disentanglement via mechanism sparsity regularization: A new principle for
nonlinear ica. In Conference on Causal Learning and Reasoning , 2022.
Phillip Lippe, Taco Cohen, and Efstratios Gavves. Efficient neural causal discovery without acyclicity
constraints. In International Conference on Learning Representations , 2022a.
Phillip Lippe, Sara Magliacane, Sindy Löwe, Yuki M Asano, Taco Cohen, and Stratis Gavves. Citris: Causal
identifiability from temporal intervened sequences. In International Conference on Machine Learning ,
2022b.
Phillip Lippe, Sara Magliacane, Sindy Löwe, Yuki M Asano, Taco Cohen, and Efstratios Gavves. Causal
representation learning for instantaneous and temporal effects in interactive systems. In International
Conference on Learning Representations , 2023.
Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang. Deep learning face attributes in the wild. In
IEEE/CVF International Conference on Computer Vision , 2015.
Francesco Locatello, Stefan Bauer, Mario Lucic, Gunnar Raetsch, Sylvain Gelly, Bernhard Schölkopf, and
Olivier Bachem. Challenging common assumptions in the unsupervised learning of disentangled represen-
tations. In International Conference on Machine Learning , 2019.
Chaochao Lu, Yuhuai Wu, José Miguel Hernández-Lobato, and Bernhard Schölkopf. Invariant causal repre-
sentation learning for out-of-distribution generalization. In International Conference on Learning Repre-
sentations , 2021.
Huishi Luo, Fuzhen Zhuang, Ruobing Xie, Hengshu Zhu, Deqing Wang, Zhulin An, and Yongjun Xu. A
survey on causal inference for recommendation. The Innovation , 2024.
Gemma Elyse Moran, Dhanya Sridhar, Yixin Wang, and David Blei. Identifiable deep generative models
via sparse decoding. Transactions on Machine Learning Research , 2022. URL https://openreview.net/
forum?id=vd0onGWZbE .
Debora Nozza, Claudia Volpetti, and Elisabetta Fersini. Unintended bias in misogyny detection. In
IEEE/WIC/ACM International Conference on Web Intelligence , 2019.
JiHoPark, JaminShin, andPascaleFung. Reducinggenderbiasinabusivelanguagedetection. In Conference
on Empirical Methods in Natural Language Processing , 2018.
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen,
Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. Pytorch: An imperative style, high-performance deep
learning library. In Advances in Neural Information Processing Systems , 2019.
Judea Pearl. Causality . Cambridge University Press, 2009.
Jonas Peters, Dominik Janzing, and Bernhard Schölkopf. Elements of Causal Inference: Foundations and
Learning Algorithms . The MIT Press, 2017.
Fengchun Qiao and Xi Peng. Ensemble pruning for out-of-distribution generalization. In International
Conference on Machine Learning , 2024.
Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish
Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al. Learning transferable visual models from
natural language supervision. In International Conference on Machine Learning , 2021.
Alexandre Rame, Matthieu Kirchmeyer, Thibaud Rahier, Alain Rakotomamonjy, Patrick Gallinari, and
Matthieu Cord. Diverse weight averaging for out-of-distribution generalization. In Advances in Neural
Information Processing Systems , 2022.
17Under review as submission to TMLR
Alfréd Rényi. On measures of dependence. Acta Mathematica Academiae Scientiarum Hungarica , 10:441–
451, 1959.
Sorawit Saengkyongam and Ricardo Silva. Learning joint nonlinear effects from single-variable interventions
in the presence of hidden confounders. In Conference on Uncertainty in Artificial Intelligence , 2020.
Sorawit Saengkyongam, Elan Rosenfeld, Pradeep Ravikumar, Niklas Pfister, and Jonas Peters. Identifying
representations for intervention extrapolation. In International Conference on Learning Representations ,
2024.
Shiori Sagawa, Pang Wei Koh, Tatsunori B Hashimoto, and Percy Liang. Distributionally robust neural net-
works for group shifts: On the importance of regularization for worst-case generalization. In International
Conference on Learning Representations , 2020.
Axel Sauer and Andreas Geiger. Counterfactual generative networks. In International Conference on Learn-
ing Representations , 2021.
Bernhard Schölkopf, Francesco Locatello, Stefan Bauer, Nan Rosemary Ke, Nal Kalchbrenner, Anirudh
Goyal, and Yoshua Bengio. Toward causal representation learning. Proceedings of the IEEE , 109(5):
612–634, 2021.
Ramprasaath R Selvaraju, Michael Cogswell, Abhishek Das, Ramakrishna Vedantam, Devi Parikh, and
Dhruv Batra. Grad-cam: Visual explanations from deep networks via gradient-based localization. In
IEEE/CVF International Conference on Computer Vision , 2017.
Harshay Shah, Kaustav Tamuly, Aditi Raghunathan, Prateek Jain, and Praneeth Netrapalli. The pitfalls of
simplicity bias in neural networks. In Advances in Neural Information Processing Systems , 2020.
Ali Sharif Razavian, Hossein Azizpour, Josephine Sullivan, and Stefan Carlsson. Cnn features off-the-shelf:
An astounding baseline for recognition. In IEEE/CVF Conference on Computer Vision and Pattern
Recognition workshops , 2014.
Zheyan Shen, Peng Cui, Tong Zhang, and Kun Kunag. Stable learning via sample reweighting. In AAAI
Conference on Artificial Intelligence , 2020.
Yuge Shi, Jeffrey Seely, Philip HS Torr, N Siddharth, Awni Hannun, Nicolas Usunier, and Gabriel Synnaeve.
Gradient matching for domain generalization. In International Conference on Learning Representations ,
2022.
Xiangchen Song, Weiran Yao, Yewen Fan, Xinshuai Dong, Guangyi Chen, Juan Carlos Niebles, Eric Xing,
and Kun Zhang. Temporally disentangled representation learning under unknown nonstationarity. In
Advances in Neural Information Processing Systems , 2023.
Peter Sorrenson, Carsten Rother, and Ullrich Köthe. Disentanglement by nonlinear ica with general
incompressible-flow networks (gin). In International Conference on Learning Representations , 2020.
Charles Spearman. The proof and measurement of association between two things. The American Journal
of Psychology , 15(1):72–101, 1904.
Jithendaraa Subramanian, Yashas Annadani, Ivaxi Sheth, Stefan Bauer, Derek Nowrouzezahrai, and
Samira Ebrahimi Kahou. Latent variable models for bayesian causal discovery. In International Con-
ference on Machine Learning Workshop on Spurious Correlations, Invariance, and Stability , 2022.
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bash-
lykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. Llama 2: Open foundation and fine-tuned
chat models. arXiv preprint arXiv:2307.09288 , 2023.
Burak Varıcı, Emre Acartürk, Karthikeyan Shanmugam, Abhishek Kumar, and Ali Tajer. Score-based
causal representation learning with interventions. In Advances in Neural Information Processing Systems
Workshop on Causal Representation Learning , 2023.
18Under review as submission to TMLR
BurakVarıcı, EmreAcartürk, KarthikeyanShanmugam, andAliTajer. Generalidentifiabilityandachievabil-
ity for causal representation learning. In International Conference on Artificial Intelligence and Statistics ,
2024.
Julius Von Kügelgen, Yash Sharma, Luigi Gresele, Wieland Brendel, Bernhard Schölkopf, Michel Besserve,
and Francesco Locatello. Self-supervised learning with data augmentations provably isolates content from
style. In Advances in Neural Information Processing Systems , 2021.
Julius von Kügelgen, Michel Besserve, Wendong Liang, Luigi Gresele, Armin Kekić, Elias Bareinboim,
David M Blei, and Bernhard Schölkopf. Nonparametric identifiability of causal representations from
unknown interventions. In Advances in Neural Information Processing Systems , 2023.
Lan Wang and Vishnu Naresh Boddeti. Do learned representations respect causal relationships? In
IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2022.
Pengfei Wang, Zhaoxiang Zhang, Zhen Lei, and Lei Zhang. Sharpness-aware gradient matching for domain
generalization. In IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2023.
Yunxia Wang, Fuyuan Cao, Kui Yu, and Jiye Liang. Efficient causal structure learning from multiple
interventional datasets with unknown targets. In AAAI Conference on Artificial Intelligence , 2022.
XiaojiangYang, YiWang, JiachengSun, XingZhang, ShifengZhang, ZhenguoLi, andJunchiYan. Nonlinear
ica using volume-preserving transformations. In International Conference on Learning Representations ,
2021.
Weiran Yao, Yuewen Sun, Alex Ho, Changyin Sun, and Kun Zhang. Learning temporally causal latent
processes from general temporal data. In International Conference on Learning Representations , 2022.
Kui Yu, Lin Liu, and Jiuyong Li. Learning markov blankets from multiple interventional data sets. IEEE
Transactions on Neural Networks and Learning Systems , 31(6):2005–2019, 2019.
Jiaqi Zhang, Chandler Squires, Kristjan Greenewald, Akash Srivastava, Karthikeyan Shanmugam, and Car-
oline Uhler. Identifiability guarantees for causal disentanglement from soft interventions. In Advances in
Neural Information Processing Systems , 2023.
Yang Zhang, Fuli Feng, Xiangnan He, Tianxin Wei, Chonggang Song, Guohui Ling, and Yongdong Zhang.
Causal intervention for leveraging popularity bias in recommendation. In International ACM SIGIR
Conference on Research and Development in Information Retrieval , 2021.
Yujia Zheng, Ignavier Ng, and Kun Zhang. On the identifiability of nonlinear ica: Sparsity and beyond. In
Advances in Neural Information Processing Systems , 2022.
Xiao Zhou, Yong Lin, Renjie Pi, Weizhong Zhang, Renzhe Xu, Peng Cui, and Tong Zhang. Model agnostic
sample reweighting for out-of-distribution learning. In International Conference on Machine Learning ,
2022.
RolandSZimmermann,YashSharma,SteffenSchneider,MatthiasBethge,andWielandBrendel. Contrastive
learning inverts the data generating process. In International Conference on Machine Learning , 2021.
19Under review as submission to TMLR
Overview of Appendix
App. A: Details of implementation and hyperparameters for all experiments
App. B: Theoretical Motivation for RepLIn
App. C: Review of Identifiable Causal Representation Learning
App. D: Additional results from experiments
App. E: Visualization of Feature Distribution Learned on Windmill dataset
App. F: Generating Windmill dataset
A Implementation details
We implement our models using PyTorch (Paszke et al., 2019) and use Adam (Kingma & Ba, 2015) as our
optimizer with its default settings. Training hyperparameters for each dataset (such as the number of data
points, training epochs, etc.) are shown in Tab. 5. For training stability, we warm up λdepfrom 0 to its set
value between sNandeNepochs where Nis the total number of epochs, and sandeare fractions shown
in Tab. 5.
Table 5: List of hyperparameters used for each dataset.
Dataset #Training samples Epochs Batchsize Initial LR Scheduler λdepλselfStart (s)End (e)
Windmill 40,000 5000 1000 2e-3 MultiStepLR(milestones=[1000], gamma=0.5) 110.66 0.99
CelebA 30,000 2000 1000 1e-3 MultiStepLR(milestones=[1000], gamma=0.1) 2020.01 0.99
Forallmethods,wefirstextractlabel-specificfeaturesfromtheinputsandpassthemthroughacorresponding
classifier to predict the label. The architecture of the feature extractor is the same for all methods on a given
dataset, except on the Windmill dataset. The classification layer is a linear layer mapping from feature
dimensions to the number of classes. The specific details for each dataset are provided below.
Windmill dataset: For ERM baselines, we use an MLP with two layers of size 40 and 1, with a ReLU
activation after each layer (except the last) to extract the features. However, we observed that enforcing in-
dependence using 1-dimensional features was difficult. Therefore, we used 2-dimensional features for RepLIn,
which were then normalized to lie on a sphere.
CelebA dataset: We first extract features from the raw image using a ResNet-50 (He et al., 2016) pre-
trainedonImageNet(Dengetal.,2009). Althoughthesefeaturesarenotoptimalforfaceattributeprediction,
they are useful for face verification (Sharif Razavian et al., 2014). Additionally, it makes the binary attribute
prediction task more challenging. We extract attribute-specific features from this input using a linear layer
that maps it to a 500-dimensional space.
B Theoretical Motivation for RepLIn
In Sec. 3.4, we theoretically motivated RepLIn. This section explains the motivation with detailed proof.
Sketch of proof: First, we estimate the statistical risk in predicting the latent variables from interventional
data from representations learned by arbitrary linear feature extractors and classifiers. In this statistical
risk, we will identify a term that is the source of performance drop during interventions. We will then
show that the optimal ERM models will suffer from this performance drop when trained on a dataset
comprising observational and interventional data. Finally, we show that minimizing linear dependence
between interventional features can lead to robust linear feature extractors.
Setup:We follow the same mathematical notation as the main paper, shown in Tab. 6. The input data X
is generated as a function of two latent variables of interest, AandB. There are noise variables collectively
denoted byUthat participate in the data generation but are not of learning interest. Our task is to predict
AandBfromX.AandBare causally related during observation. For ease of exposition, we will consider
a simple linear relation B:=wABA. This causal relation breaks when we intervene on B. The intervened
20Under review as submission to TMLR
Entity Notation Examples
Scalar Regular lowercase characters a,γ
Random variable Regular sans-serif uppercase characters A
Random vector Bold sans-serif uppercase characters A
Distribution of a random variable A Pwith subscript PA
Table 6: Mathematical notation used in the proof.
variable is denoted with an added apostrophe (i.e., B′). The data generation process can be written in the
form of a structural causal model as follows:
A∼PA XA:=wAA+UA
B′∼PB′ XB:=wBB+UB
B:=wABA(during observations)
X=/bracketleftbiggXA
XB/bracketrightbigg
B:=B′(during interventions)
UA,UB∼PU
Training: The distribution from which training data is sampled is denoted by Ptrain. The training data
consists of both observational and interventional samples, which themselves come from distributions Pobs
andPint. We are interested in the scenario where (1−β)proportion of the training data is observational,
while the remaining βproportion is interventional, where 0< β < 1. The training distribution can be
represented as a mixture of observational and interventional distributions as follows:
Ptrain(X,A,B ) = (1−β)Pobs(X,A,B ) +βPint(X,A,B )
Typically, we assume β≪1. We will also assume that A,B,U, andXhave zero mean, so that we may use
linear models without bias terms to extract representations corresponding to the variables of interest and
train linear classifiers on these representations. The corresponding classifiers are parameterized by c(A)and
c(B). The predictions are made by the classifiers from the learned representations as ˆA=c(A)⊤Θ(A)⊤Xand
ˆB=c(B)⊤Θ(B)⊤X. The models are trained by minimizing the mean squared error on the training data,
LMSE=EPtrain/bracketleftbigg/parenleftbigg/vextenddouble/vextenddouble/vextenddoubleA−ˆA/vextenddouble/vextenddouble/vextenddouble2
2+/vextenddouble/vextenddouble/vextenddoubleB−ˆB/vextenddouble/vextenddouble/vextenddouble2
2/parenrightbigg/bracketrightbigg
.
B.1 Statistical Risk in Predicting Interventional Latent Samples
The model predicts ˆAand ˆBfromXduring inference. The statistical squared error in predicting Afrom
interventional samples can be written as,
EA=EPint/bracketleftbigg/parenleftig
A−ˆA/parenrightig2/bracketrightbigg
=EPint/bracketleftbigg/parenleftig
A−c(A)⊤Θ(A)⊤X/parenrightig2/bracketrightbigg
(7)
The expectation is taken over the interventional distribution over X,A,B,Udenoted by Pint.Θ(A)can be
written in terms of constituent parameter vectors as Θ(A)=/bracketleftigg
θ(A)⊤
A
θ(A)⊤
B/bracketrightigg
. The predicted latent ˆAcan hence be
21Under review as submission to TMLR
written in terms of these vectors as,
ˆA=c(A)⊤Θ(A)⊤X=c(A)⊤/parenleftig
XAθ(A)
A+XB′θ(A)
B+Θ(A)⊤U/parenrightig
=wAAc(A)⊤θ(A)
A+wBB′c(A)⊤θ(A)
B+c(A)⊤Θ(A)⊤U
∴/parenleftig
A−c(A)⊤Θ(A)⊤X/parenrightig2
=/parenleftig/parenleftig
1−wAc(A)⊤θ(A)
A/parenrightig
A+wBB′c(A)⊤θ(A)
B+c(A)⊤Θ(A)⊤U/parenrightig2
=/parenleftig
1−wAc(A)⊤θ(A)
A/parenrightig2
A2+/parenleftig
wBc(A)⊤θ(A)
B/parenrightig2
B′2+˜U2
+ 2/parenleftig
1−wAc(A)⊤θ(A)
A/parenrightig/parenleftig
wBc(A)⊤θ(A)
B/parenrightig
AB′
+ 2/parenleftig
1−wAc(A)⊤θ(A)
A/parenrightig
˜UA+ 2/parenleftig
wBc(A)⊤θ(A)
B/parenrightig
˜UB′(8)
∴EA=EPint/bracketleftbigg/parenleftig
1−wAc(A)⊤θ(A)
A/parenrightig2
A2+/parenleftig
wBc(A)⊤θ(A)
B/parenrightig2
B′2+˜U2/bracketrightbigg
+ 2EPint/bracketleftig/parenleftig
1−wAc(A)⊤θ(A)
A/parenrightig/parenleftig
wBc(A)⊤θ(A)
B/parenrightig
AB′/bracketrightig
+ 2EPint/bracketleftig/parenleftig
1−wAc(A)⊤θ(A)
A/parenrightig
˜UA+ 2/parenleftig
wBc(A)⊤θ(A)
B/parenrightig
˜UB′/bracketrightig
where ˜U=c(A)⊤Θ(A)⊤U=c(A)⊤θ(A)
AUA+c(A)⊤θ(A)
BUB.Udenotes exogenous variables that are indepen-
dent ofAandB. Due to interventions, we also have A⊥ ⊥B. The expectation of AB′will be zero since
they are independent and have zero means marginally. Similarly, the expectation of the products of ˜Uwith
AandBwill be zero. Therefore,
EA=/parenleftig
1−wAc(A)⊤θ(A)
A/parenrightig2
ρ2
A+/parenleftig
c(A)⊤θ(A)
A/parenrightig2
ρ2
UA/bracehtipupleft /bracehtipdownright/bracehtipdownleft /bracehtipupright
E(1)
A+/parenleftig
wBc(A)⊤θ(A)
B/parenrightig2
ρ2
B′+/parenleftig
c(A)⊤θ(A)
B/parenrightig2
ρ2
UB/bracehtipupleft /bracehtipdownright/bracehtipdownleft /bracehtipupright
E(2)
A(9)
whereρ2
A=EPint/bracketleftbig
A2/bracketrightbig
,ρ2
B′=EPint/bracketleftbig
B′2/bracketrightbig
,ρ2
UA=EPint/bracketleftbig
U2
A/bracketrightbig
, andρ2
UB=EPint/bracketleftbig
U2
B/bracketrightbig
.
Statistical risk for a robust model: We are interested in robustness against interventional distribution
shifts. The predictions of Aby a robust model are unaffected by interventions on its child variable B. IfˆA
must not depend on B′, then the corresponding representation FAmust not depend on it either, i.e. θ(A)
B
must be a zero vector. Eq. (9) has two terms: E(1)
AandE(2)
A. Therefore, a robust model will have E(2)
A= 0
sinceθ(A)
B=0. Therefore, showing that an optimal ERM model has a non-zero θ(A)
Bis sufficient to show
that the model is not robust. WewillshowthatanoptimalmodeltrainedusingERMwillhaveanon-zero
θ(A)
B.
B.2 Optimal ERM model
The optimal ERM model can be obtained by minimizing the expected risk in predicting the latent attributes.
Since parameters are not shared between the prediction of aandb, we can consider their optimization
separately. We will consider the optimization of the parameters for predicting asince we are interested in
the performance drop in predicting Afrom interventional data.
Θ(A)∗,c(A)∗= argmin
Θ(A),c(A)EPtrain/bracketleftbigg/parenleftig
A−c(A)⊤Θ(A)⊤X/parenrightig2/bracketrightbigg
wherePtrainis the joint distribution of (X,A,B )during training. As mentioned earlier, Ptrainis a mixture of
observational distribution Pobsand interventional distribution Pint, with (1−β)andβacting as the mixture
weights. Therefore, the training objective can be rewritten as,
Θ(A)∗,c(A)∗= argmin
Θ(A),c(A)J(Θ(A),c(A))
where,J(Θ(A),c(A)) =/parenleftbigg
(1−β)EPobs/bracketleftbigg/parenleftig
A−c(A)⊤Θ(A)⊤X/parenrightig2/bracketrightbigg
+βEPint/bracketleftbigg/parenleftig
A−c(A)⊤Θ(A)⊤X/parenrightig2/bracketrightbigg/parenrightbigg
(10)
22Under review as submission to TMLR
Expanding the error term on observational data, we have,
c(A)⊤Θ(A)⊤X=c(A)⊤/parenleftig
XAθ(A)
A+XBθ(A)
B+Θ(A)⊤U/parenrightig
=wAAc(A)⊤θ(A)
A+wBBc(A)⊤θ(A)
B+c(A)⊤Θ(A)⊤U
=wAAc(A)⊤θ(A)
A+wBwABAc(A)⊤θ(A)
B+c(A)⊤Θ(A)⊤U
∴/parenleftig
A−c(A)⊤Θ(A)⊤X/parenrightig2
=/parenleftig
A−wAAc(A)⊤θ(A)
A−wBwABAc(A)⊤θ(A)
B−c(A)⊤Θ(A)⊤U/parenrightig2
=/parenleftig/parenleftig
1−wAc(A)⊤θ(A)
A−wBwABc(A)⊤θ(A)
B/parenrightig
A−c(A)⊤Θ(A)⊤U/parenrightig2
=/parenleftig
1−wAc(A)⊤θ(A)
A−wBwABc(A)⊤θ(A)
B/parenrightig2
A2+˜U2
−2/parenleftig
1−wAc(A)⊤θ(A)
A−wBwABc(A)⊤θ(A)
B/parenrightig
A˜U
where ˜U=c(A)⊤Θ(A)⊤U=UAc(A)⊤θ(A)
A+UBc(A)⊤θ(A)
Bfrom App. B.1. Since the exogenous variable Uis
independent of AandB, the expectation of their products over the observational distribution becomes zero.
Therefore,
EPobs/bracketleftbigg/parenleftig
A−c(A)⊤Θ(A)⊤X/parenrightig2/bracketrightbigg
=/parenleftig
1−wAc(A)⊤θ(A)
A−wBwABc(A)⊤θ(A)
B/parenrightig2
EPobs/bracketleftbig
A2/bracketrightbig
+EPobs/bracketleftbig˜U2/bracketrightbig
=/parenleftig
1−wAc(A)⊤θ(A)
A−wBwABc(A)⊤θ(A)
B/parenrightig2
ρ2
A+/parenleftig
c(A)⊤θ(A)
A/parenrightig2
ρ2
UA+/parenleftig
c(A)⊤θ(A)
B/parenrightig2
ρ2
UB
(11)
Note that,ρ2
A=EPobs/bracketleftbig
A2/bracketrightbig
,ρ2
UA=EPobs/bracketleftbig
U2
A/bracketrightbig
, andρ2
UB=EPobs/bracketleftbig
U2
B/bracketrightbig
similar to App. B.1 since these values
are unaffected by interventions. The expansion of the error term on interventional data was derived in
Eq. (9). Thus, the overall training objective Eq. (10) can be written as,
J(Θ(A),c(A)) = (1−β)/parenleftbigg/parenleftig
1−wAc(A)⊤θ(A)
A−wBwABc(A)⊤θ(A)
B/parenrightig2
ρ2
A+/parenleftig
c(A)⊤θ(A)
A/parenrightig2
ρ2
UA+/parenleftig
c(A)⊤θ(A)
B/parenrightig2
ρ2
UB/parenrightbigg
+β/parenleftbigg/parenleftig
1−wAc(A)⊤θ(A)
A/parenrightig2
ρ2
A+/parenleftig
wBc(A)⊤θ(A)
B/parenrightig2
ρ2
B′+/parenleftig
c(A)⊤θ(A)
A/parenrightig2
ρ2
UA+/parenleftig
c(A)⊤θ(A)
B/parenrightig2
ρ2
UB/parenrightbigg
We setψ1=c(A)⊤θ(A)
Aandψ2=c(A)⊤θ(A)
B. Since ERM jointly optimizes the feature extractors and the
classifiers, no unique solution minimizes the prediction loss. For example, scaling the feature extractor
parameters by an arbitrary constant scalar γand the classifier parameters by 1/γwill give the same error.
Therefore, we can optimize J(Θ(A),c(A))overψ1andψ2, similar to (Arjovsky et al., 2019).
J(Θ(A),c(A)) = (1−β)/parenleftig
(1−wAψ1−wBwABψ2)2ρ2
A+ψ2
1ρ2
UA+ψ2
2ρ2
UB/parenrightig
+β/parenleftig
(1−wAψ1)2ρ2
A+w2
Bψ2
2ρ2
B′+ψ2
1ρ2
UA+ψ2
2ρ2
UB/parenrightig
(12)
The optimal values of ψ1andψ2are the stationary points of J(Θ(A),c(A))(denoted by Jfor brevity). Thus
the optimal parameter values can be solved for by taking the first-order derivatives of Jw.r.t.ψ1andψ2
and setting them to zero.
∂J
∂ψ1= 2(1−β)/parenleftbig
−(1−wAψ1−wBwABψ2)wAρ2
A+ψ1ρ2
UA/parenrightbig
+ 2β/parenleftbig
−(1−wAψ1)wAρ2
A+ψ1ρ2
UA/parenrightbig
∂J
∂ψ2= 2(1−β)/parenleftbig
−(1−wAψ1−wBwABψ2)wBwABρ2
A+ψ2ρ2
UB/parenrightbig
+ 2β/parenleftbig
w2
Bψ2ρ2
B′+ψ2ρ2
UB/parenrightbig
Setting∂J
∂ψ1=∂J
∂ψ2= 0, we have,
23Under review as submission to TMLR
/parenleftbig
w2
Aρ2
A+ρ2
UA/parenrightbig
ψ1 +(1−β)wAwBwABρ2
Aψ2−wAρ2
A= 0
(1−β)wAwBwABρ2
Aψ1+/parenleftbig
βw2
Bρ2
B′+ (1−β)w2
Bw2
ABρ2
A+ρ2
UB/parenrightbig
ψ2−(1−β)wBwABρ2
A= 0
The equations are of the form u1ψ1+v1ψ2+w1= 0andu2ψ1+v2ψ2+w2= 0. We can solve for ψ2as
ψ2=w2u1−w1u2
v1u2−v2u1. Since we are only interested in probing the robustness of ERM models, we will check if
ψ2is zero instead of fully solving the system of linear equations. E(2)
Ain Eq. (9) is zero if ψ2= 0, i.e. if
w2u1−w1u2= 0.
w2u1−w1u2=−(1−β)wBwAB/parenleftbig
w2
Aρ2
A+ρ2
UA/parenrightbig
ρ2
A+ 4(1−β)w2
AwBwABρ4
A
=−(1−β)wBwABρ2
Aρ2
UA
Unless the training data is entirely composed of interventional data (i.e., β= 1),w2u1−w1u2is not zero.
Thus, the optimal ERM model is not robust against interventional distribution shifts.
B.3 Minimizing Linear Dependence
In Sec. 3.3, we showed that dependence between interventional features correlated positively with the drop
in accuracy on interventional data. We will now verify if minimizing dependence between interventional
features can minimize the drop in accuracy. For ease of exposition, we will minimize the linear dependence
between interventional features instead of enforcing statistical independence. The interventional features are
given byFA=Θ(A)⊤XandF′
B=Θ(B)⊤X.
FA=Θ(A)⊤X=/bracketleftig
θ(A)
Aθ(A)
B/bracketrightig/bracketleftbiggXA
XB/bracketrightbigg
=XAθ(A)
A+XBθ(A)
B
F′
B=Θ(B)⊤X=/bracketleftig
θ(B)
Aθ(B)
B/bracketrightig/bracketleftbiggXA
XB/bracketrightbigg
=XAθ(B)
A+XBθ(B)
B
To define linear independence between interventional features, we use the following definition of cross-
covariance from (Gretton et al., 2005):
Definition 1. Thecross-covariance operator associated with the joint probability pXYis a linear operator
CXY:G→Fdefined as
CXY=EXY[(ϕ(X)−µX)⊗(ψ(Y)−µY)]
whereGandFare reproducing kernel Hilbert spaces (RKHSs) defined by feature maps ϕandψrespectively,
and⊗is the tensor product defined as follows
(f⊗g)h:=f⟨g,h⟩Gfor allh∈G
where⟨·,·⟩is the inner product defined over G.
In our case, instead of RKHS, we have finite-dimensional feature space Rd. Therefore, we have the cross-
covariance matrix as follows,
CXY=EXY[ϕ(X)⊗ψ(Y)] =EXY/bracketleftbig
ϕ(X)ψ(Y)⊤/bracketrightbig
given that the feature maps have zero mean. Following the definition of HSIC (Gretton et al., 2005), linear
dependence in the finite-dimensional case between XandYis defined as the Frobenius norm of the cross-
covariance matrix. Therefore, we define the linear dependence loss between the interventional features as,
Ldep=Dep(FA,F′
B) =/vextenddouble/vextenddoubleEPint/bracketleftbig
FAF′⊤
B/bracketrightbig/vextenddouble/vextenddouble2
F(13)
24Under review as submission to TMLR
Leveraging the independence relations during interventions, we can expand Eq. (13) as,
EPint/bracketleftbig
FAF′⊤
B/bracketrightbig
=EPint/bracketleftbigg/parenleftig
XAθ(A)
A+XBθ(A)
B/parenrightig/parenleftig
XAθ(B)
A+XBθ(B)
B/parenrightig⊤/bracketrightbigg
=EPint/bracketleftig
X2
Aθ(A)
Aθ(B)⊤
A +XAXBθ(A)
Aθ(B)⊤
B +XAXBθ(A)
Bθ(B)⊤
A +X2
Bθ(A)
Bθ(B)⊤
B/bracketrightig
= (w2
Aρ2
A+ρ2
UA)θ(A)
Aθ(B)⊤
A + (w2
Bρ2
B′+ρ2
UB)θ(A)
Bθ(B)⊤
B
∴Ldep=/vextenddouble/vextenddouble/vextenddouble(w2
Aρ2
A+ρ2
UA)θ(A)
Aθ(B)⊤
A + (w2
Bρ2
B′+ρ2
UB)θ(A)
Bθ(B)⊤
B/vextenddouble/vextenddouble/vextenddouble2
F
In the last step, all cross-covariance terms are zero due to the independence of the corresponding random
variables in the causal graph. The dependence loss is the Frobenius norm of a sum of rank-one matrices
θ(A)
Aθ(B)⊤
Aandθ(A)
Bθ(B)⊤
B. Consider the following general form: Z=ab⊤+cd⊤. ThenZij=aibj+cidj.
∥Z∥2
F=/summationdisplay
ij(aibj+cidj)2
∥Z∥2
Fis a sum of squares and thus is zero iff aibj+cidj= 0,∀i,j. Therefore,Ldepis minimized when
θ(A)
Aiθ(B)
Aj+θ(A)
Biθ(B)
Bj= 0,∀i,j. The potential solutions that minimize Ldepare (1)θ(A)
A=θ(A)
B=θ(B)
A=
θ(B)
B=0, (2)θ(A)
A=±γθ(A)
Bandγθ(B)
A=∓θ(B)
Bfor someγ̸= 0, and (3)θ(A)
A=0orθ(B)
A=0, andθ(A)
B=0
orθ(B)
B=0. The former two solutions result in trivial features and will increase the classification error.
The latter solution contains four possible solutions, out of which two solutions result in trivial features.
Solutions resulting in trivial features are unlikely to occur during optimization due to a large classification
error. Therefore, we need to consider only the remaining two solutions.
The possible solutions are: (1) θ(A)
A=0,θ(B)
B=0, and (2)θ(A)
B=0,θ(B)
A=0. Intuitively, in the former
solution,AandBwill be predicted using XBandXArespectively, and the latter solution corresponds to a
robust feature extractor that minimizes the reducible error in Eq. (9). We will compare the predictive error
achieved by these solutions to compare their likelihood during training.
Recall the expression for training error in predicting Afrom Eq. (12).
JA(Θ(A),c(A)) = (1−β)/parenleftig
(1−wAψA1−wBwABψA2)2ρ2
A+ψ2
A1ρ2
UA+ψ2
A2ρ2
UB/parenrightig
+β/parenleftig
(1−wAψA1)2ρ2
A+w2
Bψ2
A2ρ2
B′+ψ2
A1ρ2
UA+ψ2
A2ρ2
UB/parenrightig
= (1−β)/parenleftig
(1−wAψA1−wBwABψA2)2ρ2
A/parenrightig
+β/parenleftig
(1−wAψA1)2ρ2
A+w2
Bψ2
A2ρ2
B′/parenrightig
+ψ2
A1ρ2
UA+ψ2
A2ρ2
UB
We useψA1andψA2instead ofψ1andψ2respectively to denote the parameters for predicting A. A similar
expression can be written for the error in predicting BwithψB1andψB2denoting the parameters for
predictingB.
JB(Θ(B),c(B)) = (1−β)/parenleftig
(1−wAψB1−wBwABψB2)2ρ2
A+ψ2
B1ρ2
UA+ψ2
B2ρ2
UB/parenrightig
+β/parenleftbig
w2
Aψ2
B1ρ2
A+ (1−wBψB2)2ρ2
B′+ψ2
B1ρ2
UA+ψ2
B2ρ2
UB/parenrightbig
= (1−β)/parenleftig
(1−wAψB1−wBwABψB2)2ρ2
A/parenrightig
+β/parenleftbig
w2
Aψ2
B1ρ2
A+ (1−wBψB2)2ρ2
B′/parenrightbig
+ψ2
B1ρ2
UA+ψ2
B2ρ2
UB
Case 1: When θ(A)
A=0,θ(B)
B=0:In this case, ψA1= 0andψB2= 0. Therefore, the predictive error
during training for each latent variable can be written as,
JA= (1−β) (wBwABψA2−1)2ρ2
A+βρ2
A+βw2
Bψ2
A2ρ2
B′+ψ2
A2ρ2
UB
JB= (1−β) (wAψB1−wAB)2ρ2
A+βw2
Aψ2
B1ρ2
A+βρ2
B′+ψ2
B1ρ2
UA
25Under review as submission to TMLR
The optimal values of ψA2andψB1can be obtained by equating the gradients of RAandRBto zero.
∂JA
∂ψA2= 2(1−β)wBwAB(wBwABψA2−1)ρ2
A+ 2βw2
BψA2ρ2
B′+ 2ψA2ρ2
UB= 0
∴ψ∗
A2=(1−β)wBwABρ2
A
(1−β)w2
Bw2
ABρ2
A+βw2
Bρ2
B′+ρ2
UB
J∗
A=(1−β)ρ2
A/parenleftbig
βw2
Bρ2
B′+ρ2
UB/parenrightbig
(1−β)w2
Bw2
ABρ2
A+βw2
Bρ2
B′+ρ2
UB+βρ2
A
∂JB
∂ψB1= 2(1−β)wA(wAψB1−wAB)ρ2
A+ 2βw2
AψB1ρ2
A+ 2ψB1ρ2
UA= 0
∴ψ∗
B1=(1−β)wAwABρ2
A
w2
Aρ2
A+ρ2
UA
J∗
B=(1−β)w2
ABρ2
A(βw2
Aρ2
A+ρ2
UA)
w2
Aρ2
A+ρ2
UA+βρ2
B′
The combined training error for this solution is,
J∗
1=J∗
A+J∗
B
=(1−β)ρ2
A/parenleftbig
βw2
Bρ2
B′+ρ2
UB/parenrightbig
(1−β)w2
Bw2
ABρ2
A+βw2
Bρ2
B′+ρ2
UB+βρ2
A
+(1−β)w2
ABρ2
A(βw2
Aρ2
A+ρ2
UA)
w2
Aρ2
A+ρ2
UA+βρ2
B′ (14)
Case 2: When θ(A)
B=0,θ(B)
A=0:Here,ψA2= 0andψB1= 0. The predictive error during training for
each latent variable can be written as,
JA= (wAψA1−1)2ρ2
A+ψ2
A1ρ2
UA
JB=/parenleftbig
(1−β)w2
ABρ2
A+βρ2
B′/parenrightbig
(wBψB2−1)2+ψ2
B2ρ2
UB
We follow the former procedure to estimate the optimal values of ψA1andψB2.
∂JA
∂ψA1= 2wA(wAψA1−1)ρ2
A+ 2ψA1ρ2
UA= 0
∴ψ∗
A1=wAρ2
A
w2
Aρ2
A+ρ2
UA
J∗
A=ρ2
Aρ2
UA
w2
Aρ2
A+ρ2
UA
∂JB
∂ψB2= 2wB/parenleftbig
(1−β)w2
ABρ2
A+βρ2
B′/parenrightbig
(wBψB2−1) + 2ψB2ρ2
UB
∴ψ∗
B2=(1−β)wBw2
ABρ2
A+βwBρ2
B′
(1−β)w2
Bw2
ABρ2
A+βw2
Bρ2
B′+ρ2
UB
J∗
B=/parenleftbig
(1−β)w2
ABρ2
A+βρ2
B′/parenrightbig
ρ2
UB
(1−β)w2
Bw2
ABρ2
A+βw2
Bρ2
B′+ρ2
UB
The combined training error for this solution is,
J∗
2=J∗
A+J∗
B
=ρ2
Aρ2
UA
w2
Aρ2
A+ρ2
UA+/parenleftbig
(1−β)w2
ABρ2
A+βρ2
B′/parenrightbig
ρ2
UB
(1−β)w2
Bw2
ABρ2
A+βw2
Bρ2
B′+ρ2
UB(15)
26Under review as submission to TMLR
Comparing J∗
1andJ∗
2,
J∗
1−J∗
2=(1−β)βw2
Bρ2
Aρ2
B′+ (1−β)ρ2
Aρ2
UB−(1−β)w2
ABρ2
Aρ2
UB−βρ2
B′ρ2
UB
(1−β)w2
Bw2
ABρ2
A+βw2
Bρ2
B′+ρ2
UB
+(1−β)βw2
Aw2
ABρ4
A+ (1−β)w2
ABρ2
Aρ2
UA−ρ2
Aρ2
UA
w2
Aρ2
A+ρ2
UA+β(ρ2
A+ρ2
B′)
Simplifying the above expression, we get the condition that J∗
1−J∗
2>0ifβsatisfies the following conditions:
(1)β≥1−1
|wAB|, (2)β≥min/parenleftbigg
ρ2
A
2ρ2
B′+ρ2
A,ρ2
UA
w2
Aw2
ABρ2
A/parenrightbigg
. The conditions imply that enforcing linear indepen-
dence results in robust feature extractors when enoughinterventional data is available during training.
However, this is only a sufficient condition that strictly ensures J∗
1−J∗
2>0. In practice, βcould be much
lower, especially when the total loss is of the form Ltotal=λMSELMSE+λdepLdep, whereλMSEandλdep
are positive hyperparameters. We verify this empirically by randomly setting the parameters of the data
generation process and plotting the predictive errors J∗
1andJ∗
2for different values of β. We calculate J∗
1
andJ∗
2for 5000 runs (shown using thin curves) and plot the average error (shown using thick curves) in
Fig. 13. We observe that the average value of J∗
1is always higher than that of J∗
2for all values of β. But,
whenβ→0, their average values get closer to each other.
0.0 0.2 0.4 0.6 0.8 1.0
Proportion of interventional data ( β)02468Training prediction errorJ∗
1 J∗
2
Figure 13: Comparing J∗
1(Eq. (14)) and J∗
2(Eq. (15)) as functions of βfor 5000 runs with randomly sampled
data generation parameters. We show individual runs using thin curves and the average error values using
thick curves. We only show the errors from a few randomly sampled runs for visual clarity. We observe that
the average value of J∗
1(shown using thick red curve) is always higher than that of J∗
2(shown using thick
blue curve), indicating that enforcing linear independence between interventional features is more likely to
obtain robust feature extractors than degenerate solutions.
C Review of identifiable causal representation learning
The primary objective of identifiable causal representation learning (ICRL) is to learn a representation such
that it is possible to identify the latent factors (up to permutation and elementwise transformation) from the
representation. These methods are commonly built upon autoencoder-based approaches and learn generative
representations. The advantage of learning a causal representation is that the decoder then implicitly acts
as the true underlying causal model, facilitating counterfactual evaluation and interpretable representations.
Locatello et al. (2019); Khemakhem et al. (2020) showed that disentangled representation learning was
impossible without additional assumptions on both the model and the data. Some of the inductive biases
that have been proposed since to learn disentangled representations include auxiliary labels (Hyvarinen &
27Under review as submission to TMLR
Morioka, 2016; Hyvarinen et al., 2019; Sorrenson et al., 2020; Khemakhem et al., 2020; Lu et al., 2021; Ahuja
et al., 2022b; Kong et al., 2022), temporal data (Klindt et al., 2021; Yao et al., 2022; Song et al., 2023), and
assumptions on the mixing function (Sorrenson et al., 2020; Yang et al., 2021; Lachapelle et al., 2022; Zheng
et al., 2022; Moran et al., 2022).
Use of interventional data: Some works also use interventional data as weak supervision for identifiable
representation learning (Lippe et al., 2022b; Brehmer et al., 2022; Ahuja et al., 2022a; 2023; Varıcı et al.,
2023; von Kügelgen et al., 2023). Lippe et al. (2022b) learns identifiable representations from temporal
sequences with possible interventions at any time step. Similar to our setting, they assume the knowledge of
the intervention target. They also assume that the intervention on a latent variable at a time step does not
affect other latent variables in the same time step. Lippe et al. (2023) relaxes the latter assumption as long
as perfect interventions with known targets are available. Von Kügelgen et al. (2021); Zimmermann et al.
(2021) showed that self-supervised learning with data augmentations allowed for identifiable representation
learning. Brehmer et al. (2022) use pairs of data samples before and after some unknown intervention to
learn latent causal models. Ahuja et al. (2022a) learns identifiable representations from sparse perturbations,
with identifiability guarantees depending on the sparsity of these perturbations. Sparse perturbations can
be treated as a parent class of interventions where the latent is intervened through an external action such
as in reinforcement learning. Ahuja et al. (2022b) use interventional data for causal learning for polynomial
mixing functions, under some assumptions on the nature of support for non-intervened variables. Varıcı
et al. (2024) relaxes the polynomial assumption on the mixing function and proves identifiability when two
uncoupled hard interventions per node are available along with observational data. Varıcı et al. (2023)
learn identifiable representations from data observed under different interventional distributions with the
help of the score function during interventions. von Kügelgen et al. (2023) uses interventional data to learn
identifiable representations up to nonlinear scaling. In addition to the above uses of interventional data, a
few works (Saengkyongam & Silva, 2020; Saengkyongam et al., 2024; Zhang et al., 2023) have also attempted
to predict the effect of unseen joint interventions with the help of observational and atomic interventions
under various assumptions on the underlying causal model.
Difference from our setting: The general objective in ICRL is to “learn both the true joint distribution
over both observed and latent variables” (Khemakhem et al., 2020). In contrast, the objective of our work is
to learn representations corresponding to latent variables that are robust against interventional distributional
shifts by leveraging knowninterventional independence relations. We pursue this objective in the hope that
as large models such as (Radford et al., 2021), (Brown et al., 2020), (Touvron et al., 2023) and (Dehghani
et al., 2023) become more ubiquitous, efficient methods to improve these models with minimal amounts of
experimentally collected data will be of interest.
D Additional Results from Experiments
As mentioned in the main paper, our objective is to improve the robustness of representations against
interventional distribution shifts. However, this robustness might come at the cost of observational accuracy
since it removes spurious information that gives better performance on observational data. In this section,
we report the results of the baselines and our methods on Windmill , CelebA, and CivilComments datasets.
E Visualization of Feature Distribution Learned on Windmill dataset
In this section, we compare the feature distributions learned by RepLIn on Windmill dataset against all
the baselines from Sec. 5.1. The feature distributions are shown in Fig. 14.
F Generating Windmill Dataset
We provide the exact mathematical formulation of Windmill dataset described in Sec. 3.1. We define the
following constants:
28Under review as submission to TMLR
Method β= 0.5β= 0.3β= 0.1β= 0.05β= 0.01
ERM 93.85±1.84 98.06±1.20 99.70±0.08 99.92±0.02 99.98±0.01
ERM-Resampled 94.53±0.89 94.13±1.19 94.84±0.92 94.56±0.71 94.53±1.14
IRMv1 93.37±0.85 93.59±0.32 93.72±0.73 92.52±0.35 94.04±0.63
Fish 95.54±0.42 95.37±0.36 95.42±0.59 95.83±0.51 96.28±1.12
GroupDRO 82.02±2.00 84.40±2.72 85.35±2.35 84.25±0.91 92.28±1.11
SAGM 94.77±0.62 95.17±0.71 94.13±1.68 95.61±0.69 94.04±1.98
DiWA 94.64±0.96 94.30±0.36 94.57±0.64 94.39±0.99 94.24±0.59
TEP 65.20±14.22 66.94±3.78 61.34±19.35 63.02±15.59 73.77±9.01
RepLIn 95.16±0.53 97.83±0.40 99.24±0.37 98.75±0.43 99.10±0.47
RepLIn-Resampled 95.57±0.62 95.77±0.68 95.59±1.08 95.90±0.35 95.51±1.71
Table 7: Observational accuracy of various methods used in Sec. 5.1.
Method β= 0.5β= 0.3β= 0.1β= 0.05β= 0.01
ERM 76.87±1.08 69.86±3.19 62.78±1.77 59.52±1.30 60.15±3.12
ERM-Resampled 73.70±3.19 71.19±3.23 73.62±1.54 71.03±2.83 70.20±3.73
IRMv1 78.24±0.79 74.83±1.74 78.61±2.24 76.28±1.87 71.75±2.03
Fish 77.23±2.24 77.23±1.32 78.24±2.09 76.42±1.95 73.92±2.53
GroupDRO 80.10±1.66 80.96±1.33 80.35±1.01 77.40±1.16 71.86±1.60
SAGM 76.43±2.37 79.05±2.23 76.96±4.36 79.86±1.81 72.81±3.10
DiWA 76.61±2.15 76.71±0.59 76.09±0.69 75.83±1.83 73.39±1.31
TEP 58.68±4.72 60.42±1.30 56.07±3.35 58.52±4.36 59.23±1.13
RepLIn 87.94±1.46 87.76±2.30 83.23±2.67 73.63±2.43 67.52±2.30
RepLIn-Resampled 88.46±0.96 88.05±1.04 87.91±1.36 86.38±0.85 78.41±1.27
Table 8: Interventional accuracy of various methods used in Sec. 5.1.
Method β= 0.5β= 0.4β= 0.3β= 0.2β= 0.1β= 0.05
ERM-Resampled 91.38±0.09 91.52±0.06 91.39±0.07 90.89±0.10 90.57±0.09 91.82±0.14
RepLIn-Resampled 86.02±0.18 86.35±0.24 86.58±0.11 86.94±0.36 87.67±0.21 89.83±0.11
Table 9: Observational accuracy of various methods used in Sec. 5.2.
Method β= 0.5β= 0.4β= 0.3β= 0.2β= 0.1β= 0.05
ERM-Resampled 81.09±0.17 80.56±0.23 80.06±0.17 79.08±0.16 76.63±0.24 73.42±0.27
RepLIn-Resampled 81.97±0.14 81.94±0.17 81.84±0.18 80.65±0.22 78.56±0.20 75.77±0.05
Table 10: Interventional accuracy of various methods used in Sec. 5.2.
Method β= 0.5β= 0.3β= 0.1β= 0.05β= 0.01
ERM-Resampled 81.26±0.12 81.77±0.14 79.78±0.08 79.97±0.12 79.13±0.09
RepLIn-Resampled 79.27±0.09 80.16±0.12 77.65±0.06 77.84±0.12 78.51±0.16
Table 11: Observational accuracy of various methods used in Sec. 5.3.
RB∼B(1,2.5) (Sample radius)
R=rmax
2(BRB+ (1−B)(2−RB)) (Modify sampled radius based on B)
ΘA∼C/parenleftbigg/braceleftbigg
2πi
narms+ 1:i= 0,...,narms−1/bracerightbigg/parenrightbigg
(Choose an arm)
U∼U(0,1) (To choose a random angle)
Θoff=θmax-off sin/parenleftbigg
πλoffR
rmax/parenrightbigg
(Calculate radial offset for the angle)
Θ =θwid(U−0.5) +A/parenleftbigg
ΘA+π
narms/parenrightbigg
+ (1−A)ΘA+ Θoff
(Angle is decided by Aand the radial offset)
X1=Rcos Θ,X2=Rsin Θ,X=/bracketleftbiggX1
X2/bracketrightbigg
(Convert to Cartesian coordinates)29Under review as submission to TMLR
Method β= 0.5β= 0.3β= 0.1β= 0.05β= 0.01
ERM-Resampled 74.51±0.07 75.29±0.22 72.03±0.18 71.78±0.12 69.80±0.45
RepLIn-Resampled 75.30±0.37 75.81±0.31 72.00±0.23 71.70±0.14 69.99±0.80
Table 12: Interventional accuracy of various methods used in Sec. 5.3.
Top row: When A=0, Bottom row: When A=1 B=0 B=1
0 2
Inclination0369Density
−5−2 1 4
Azimuth03Density
0 2
Inclination036Density
−5−2 1 4
Azimuth036Density
(a) ERM
0 2
Inclination036Density
−5−2 1 4
Azimuth02Density
0 2
Inclination036Density
−5−2 1 4
Azimuth01Density (b) ERM-Resampled
0 2
Inclination036Density
−5−2 1 4
Azimuth02Density
0 2
Inclination03Density
−5−2 1 4
Azimuth03Density (c) IRMv1
0 3
Inclination03Density
−5−2 1 4
Azimuth02Density
0
Inclination03Density
−5−2 1 4
Azimuth01Density
(d) Fish
0 1
Inclination036Density
−5−2 1 4
Azimuth03Density
0 1
Inclination036Density
−5−2 1 4
Azimuth03Density (e) GroupDRO
0
Inclination01Density
−4−1 2
Azimuth01Density
0
Inclination02Density
−5−2 1 4
Azimuth0Density (f) RepLIn
0 3
Inclination02Density
−4−1 2
Azimuth0Density
−1 2
Inclination01Density
−4−1 2
Azimuth0Density
(g) RepLIn-Resampled
Figure 14: Visualization of interventional features learned by various methods on Windmill dataset.
Constants Description Default value
narms Number of “arms” in Windmill dataset 4
rmax Radius of the circular region spanned by the observed data 2
θwid Angular width of each arm0.9π
narms= 0.7068
λoff Offset wavelength. Determines the complexity of the dataset 6
θmax-off Maximum offset for the angle π/6
Table 13: Constants used for generating Windmill dataset, their meaning, and their values.
PyTorch code to generate Windmill dataset is provided in Listing 1.
30Under review as submission to TMLR
Listing 1: Code for Windmill dataset
import math
import torch
# Constants
num_arms = 4 # number of blades in the windmill
max_th_offset = 0.5236 # max offset that can be added to the angle for shearing (= pi/6)
r_max = 2 # length of the blade
num_p = 20000 # number of points to be generated
offset_wavelength = 6 # adjusts the complexity of the blade
# Sample latent variables according to the causal graph.
A = torch.bernoulli(torch.ones(num_points) * 0.6)
if observational_data:
B = A
else:
B = torch.bernoulli(torch.ones(num_points) * 0.5)
# Convert A, B to X.
th_A0 = torch.linspace(0, 2*math.pi, num_arms+1)[:-1]
th_A1 = torch.linspace(0, 2*math.pi, num_arms+1)[:-1] + math.pi/num_arms
# Choose a random arm for A=0 from possible arms. Likewise for A=1.
th_A0 = th_A0[torch.randint(num_arms, (num_p,))]
th_A1 = th_A1[torch.randint(num_arms, (num_p,))]
# beta distribution with alpha=1, beta=3
beta_dist = torch.distributions.beta.Beta(1, 2.5)
# Sample r according to B. If B=0, sample a small r, else sample a large r.
# r ranges from 0 to r_max
B0_r = beta_dist.sample(torch.Size([num_p])) * r_max/2.
B1_r = r_max - beta_dist.sample(torch.Size([num_p])) * r_max/2.
r = B * B0_r + (1-B) * B1_r
# Sample theta according to A.
# Choose the theta arm according to A and then sample from this arm using a uniform distribution.
# First we will have a cartwheel style.
theta = torch.rand(num_p)*th_wid + th_A0*(1-A) + th_A1*A - th_wid/2.
# Add an offset to theta according to r.
th_offset_mod = torch.sin((r/r_max)*offset_wavelength*math.pi)
th_offset = max_th_offset*th_offset_mod
theta += th_offset
x1 = r*torch.cos(theta)
x2 = r*torch.sin(theta)
data = torch.stack([x1, x2], dim=1)
labels = torch.stack([A, B], dim=1).type(torch.long)
31