Under review as submission to TMLR
Threshold-aware Learning to Generate Feasible Solutions for
Mixed Integer Programs
Anonymous authors
Paper under double-blind review
Abstract
Finding a high-quality feasible solution to a combinatorial optimization (CO) problem in a
limited time is challenging due to its discrete nature. Recently, there has been an increasing
numberofmachinelearning(ML)methodsforaddressingCOproblems. Neuraldiving(ND)
is one of the learning-based approaches to generating partial discrete variable assignments
in Mixed Integer Programs (MIP), a framework for modeling CO problems. However, a
major drawback of ND is a large discrepancy between the ML and MIP objectives, i.e.,
misalignment between the variable value classification accuracy and primal bound. Our
study investigates that a specific range of variable assignment rates ( coverage) yields high-
quality feasible solutions, where we suggest optimizing the coverage bridges the gap between
the learning and MIP objectives. Consequently, we introduce a post-hoc method and a
learning-based approach for optimizing the coverage. A key idea of our approach is to jointly
learn to restrict the coverage search space and to predict the coverage in the learned search
space. Experimental results demonstrate that learning a deep neural network to estimate
the coverage for finding high-quality feasible solutions achieves state-of-the-art performance
in NeurIPS ML4CO datasets. In particular, our method shows outstanding performance
in the workload apportionment dataset, achieving the optimality gap of 0.45%, a ten-fold
improvement over SCIP within the one-minute time limit.
1 Introduction
Mixedintegerprogramming(MIP)isamathematicaloptimizationmodeltosolvecombinatorialoptimization
(CO) problems in diverse areas, including transportation (Applegate et al., 2003), finance (Mansini et al.,
2015), communication (Das et al., 2003), manufacturing (Pochet & Wolsey, 2006), retail (Sawik, 2011),
and system design (Maulik et al., 1995). A workhorse of the MIP solver is a group of heuristics involving
primal heuristics (Berthold, 2006; Fischetti et al., 2005) and branching heuristics (Achterberg et al., 2005;
2012). Recently, there has been a growing interest in applying data-driven methods to complement heuristic
components in the MIP solvers: node selection (He et al., 2014), cutting plane (Tang et al., 2020), branching
(Khalil et al., 2017; Balcan et al., 2018; Gasse et al., 2019), and primal heuristics (Nair et al., 2020; Xavier
et al., 2021). In particular, finding a high-quality feasible solution in a shorter time is an essential yet
challenging task due to its discrete nature. Nair et al. (2020) suggests Neural diving (ND) with a variant of
SelectiveNet (Geifman & El-Yaniv, 2019) to jointly learn diving style primal heuristics to generate feasible
solutions and adjust a discrete variable selection rate for assignment, referred to as coverage. ND partially
assignsthediscretevariablevaluesintheoriginalMIPproblemanddelegatestheremainingsub-MIPproblem
to the MIP solver. However, there are two problems in ND. First, the ND model that shows higher variable
value classification accuracy for the collected MIP solution, defined as the ratio of the number of correctly
predicted variable values to the total number of predicted variable values, does not necessarily generate
a higher-quality feasible MIP solution. We refer to this problem as discrepancy between ML and MIP
objectives. Secondly, obtaining the appropriate ND coverage that yields a high quality feasible solution
necessitates the training of multiple models with varying target coverages, a process that is computationally
inefficient.
1Under review as submission to TMLR
In this work, we suggest that the coverage is a surrogate measure to bridge the gap between the ML
and MIP objectives. A key observation is that the MIP solution obtained from the ML model exhibits a
sudden shift in both solution feasibility and quality concerning the coverage. Building on our insight, we
propose a simple variable selection strategy called Confidence Filter (CF) to overcome SelectiveNet’s training
inefficiency problem. While primal heuristics rely on LP-relaxation solution values, CF fixes the variables
whose corresponding neural network output satisfies a specific cutoff value. It follows that CF markedly
reduces the total ND training cost since it only necessitates a single ND model without SelectiveNet. At the
same time, determining the ideal CF cutoff value with regard to the MIP solution quality can be achieved in
linear time in the worst-case scenario concerning the number of discrete variables, given that the MIP model
assessment requires a constant time. To relieve the CF evaluation cost, we devise a learning-based method
called Threshold-aware Learning (TaL) based on threshold function theory (Bollobás, 1981). In TaL, we
propose a new loss function to estimate the coverage search space in which we optimize the coverage. TaL
outperforms other methods in various MIP datasets, including NeurIPS Machine Learning for Combinatorial
Optimization (ML4CO) datasets Gasse et al. (2022).
Our contributions are as follows.
1) To the best of our knowledge, our work is the first attempt to investigate the role of threshold
functions in connection with the importance of coverage optimization in learning to generate MIP
solutions.
2) We devise a new ML framework for data-driven coverage optimization based on threshold function
theory. Our method effectively relieves the gap between the ML and MIP objectives by utilizing the
coverage as a surrogate measure.
3) We empirically demonstrate that our method outperforms the existing methods in various MIP
datasets. In the maritime inventory routing dataset, our method achieves an optimality gap that is
roughly twice as improved as that attained by ND.
2 Preliminaries
2.1 Notations on Mixed Integer Programming
Letnbe the number of variables, mbe the number of linear constraints, x= [x1,...,xn]∈Rnbe the vector
of variable values, c∈Rnbe the vector ofobjective coefficients, A∈Rm×nbe thelinear constraint coefficient
matrix, b∈Rmbe the vector of linear constraint upper bound. Let {ei=e(n)
i∈Rn:i= 1,...,n}be the
Euclidean unit basis vector of Rnand[n] :={1,2,...,n}. Here we can decompose the variable vector as
x=/summationtext
i∈Bxiei.
A Mixed Integer Program (MIP) is a mathematical optimization problem in which the variables are con-
strained by linear and integrality constraints. Let rbe the number of discrete variables. We express an MIP
problemM= (A,b,c)as follows:
min
xc⊤x (1)
subject to Ax≤b
where x= [x1,...,xn]∈Zr×Rn−r. We say x∈Zr×Rn−ris afeasible solution and write x∈R(M)if the
linear and integrality constraints hold. We call x∈RnanLP-relaxation solution and write x∈¯R(M)when
xsatisfies the linear constraints regardless of the integrality constraints.
2.2 Neural diving
Neural diving (ND) (Nair et al., 2020) is a method to learn a generative model that emulates diving-
style heuristics to find a high-quality feasible solution. ND learns to generate a Bernoulli distribution of
a solution’s integer variable values in a supervised manner. For simplicity of notation, we mean integer
2Under review as submission to TMLR
variables’ solution values when we refer to x. The conditional distribution over the solution xgiven an MIP
instanceM= (A,b,c)is defined as
p(x|M) =exp(−E(x;M))
Z(M), (2)
whereZ(M)is the partition function for normalization defined as
Z(M) =/summationdisplay
x′exp (−E(x′;M)), (3)
andE(x;M)is the energy function over the solution xdefined as
E(x;M) =/braceleftigg
c⊤xifxis feasible
∞otherwise(4)
ND aims to model p(x|M)with a generative neural network pθ(x|M)parameterized by θ. Assuming con-
ditional independence between variables, ND defines the conditionally independent distribution over the
solution as
pθ(x|M) =/productdisplay
d∈Ipθ(xd|M), (5)
whereIis the set of dimensions of xthat belongs to discrete variables and xddenotes the d-th dimension of
x. Given that the complete ND output may not always conform to the constraints of the original problem,
ND assigns a subset of the predicted variable values and delegates the off-the-shelf MIP solver to finalize the
solution. In this context, Nair et al. (2020) employs SelectiveNet (Geifman & El-Yaniv, 2019) to regularize
the coverage for the discrete variable assignments in an integrated manner. Here, the coverage is defined as
the number of integer variables that are predicted divided by the number of all integer variables. Regularized
by the predefined coverage, the ND model jointly learns to select variables to assign and predict variable
values for the selected variables.
3 Coverage Optimization
Confidence Filter We propose Confidence Filter (CF) to control the coverage in place of the SelectiveNet
in ND. CF yields a substantial enhancement in the efficiency of model training, since it only necessitates a
single ND model and eliminates the need for SelectiveNet. In CF, we adjust the confidence score cutoff value
of the ND model output pθ(x|M), where the confidence score is defined as max(pθ(xd|M),1−pθ(xd|M))for
the corresponding variable xd. Suppose the target cutoff value is Γ, and the coverage is ρ. Letsdrepresent
the selection of the d-th variable. The value xdis selected to be assigned if sd= 1. It follows that ρ∝1/Γ.
sd=/braceleftigg
1ifmax(pθ(xd|M),1−pθ(xd|M))≥Γ
0otherwise(6)
Our hypothesis is that a higher confidence score associated with each variable corresponds to a higher level
of certainty in predicting the value for that variable with regard to the solution feasiblility and quality.
As depicted in Figure 1, the feasibility and quality of the solution undergo significant changes depending
on the cutoff value of the confidence score. Figure 1a illustrates that a majority of the partial variable
assignments attain feasibility when the confidence score cutoff value falls within the range from 0.95to1.
As depicted in Figure 1b, the solutions obtained from the CF partial variable assignments outperform the
default MIP solver (SCIP) for cutoff values within the range from 0.9to0.98. Therefore, identifying the
appropriate cutoff value is crucial for achieving a high-quality feasible solution within a time limit.
3Under review as submission to TMLR
Cutoff value of confidence scoreFeasible instance ratio ↑
0.000.250.500.751.00
0.0 0.1 0.2 0.3 0.4 0.5Confidence Filter
(a) Feasible instance ratio over the confidence score cutoff
value.
Cutoff value of confidence scoreFinal primal bound ↓
0100000200000300000
0.0 0.1 0.2 0.3 0.4 0.5Confidence Filter Tuned SCIP(b) Final primal bound over the confidence score cutoff
value.
Figure 1: The feasible instance ratio and the final primal bound over the cutoff value of the Confidence
Filter method at the 30-minute time limit. The feasible instance ratio is the number of test instances whose
model-generated partial variable assignments are feasible, divided by the total number of test instances; the
higher, the better. The final primal bound represents the solution quality; the lower, the better. In both (a)
and (b), the feasibility and the solution quality dramatically change at a certain cutoff point. The dotted line
in (b) represents the default MIP solver (SCIP) performance without Neural diving. In (b), the Confidence
Filter outperforms SCIP at the confidence score cutoff value from around 0.4to0.48. The target dataset is
Maritime Inventory Routing problems from (Papageorgiou et al., 2014; Gasse et al., 2022).
Coverage (%)Feasible instance ratio
0.000.250.500.751.00
75 80 85 90 95 100
(a) Feasible instance ratio over the coverage.
Coverage (%)Final primal bound
100200300400500600700
75 80 85 90 95 100 (b) Final primal bound over the coverage rate.
1000 n / 500 m
2000 n / 1000 m
3000 n / 1500 m
4000 n / 2000 m
5000 n / 2500 m
8000 n / 4000 m
Figure 2: The threshold behavior of partial variable assignments with respect to coverage is examined in
terms of the feasibility and final primal bound in set covering instances. We scale up the number of discrete
variablesn, and the number of constraints m, by 1×,2×,3×,4×,5×, and 8×. Each line in the plot
corresponds to each problem size. We use the same model (ND without SelectiveNet) trained on the dataset
of the smallest scale, n= 1000,m= 500. Both (a) and (b) exhibit consistent patterns with respect to the
problem size, concerning the coverage where the threshold behavior occurs.
Threshold coverage Figure 2 shows an abrupt shift in the solution feasibility and quality within a specific
range of coverage. Figure 2a and 2b demonstrate that the threshold coverage, representing the coverage at
which a sudden shift in feasibility and quality occurs, follows a consistent pattern as the test problem sizes
increase. Given the solution generated by the neural network, Figure 2b demonstrates that the optimal
coverage defined as ρ∗= arg min PrimalBound (ρ)is bounded by the feasibility threshold coverage in Figure
2a. We leverage the consistent pattern in the threshold coverage to estimate the optimal coverage.
3.1 Threshold-aware Learning
Overview The main objective of Threshold-aware Learning (TaL) is to learn to predict the optimal cover-
ageρ∗that results in a high-quality feasible solution. We leverage the off-the-shelf MIP solver in TaL to use
4Under review as submission to TMLR
the actual MIP objectives as a criterion to decide the optimal coverage. However, optimizing the coverage
for large-scale MIP problems is costly since we need to find a feasible solution for each coverage rate at each
training step. Therefore, we improve the search complexity for estimating ρ∗by restricting the coverage
search space that leads to high-quality feasible solutions. In TaL, we jointly learn to predict the optimal
coverage and to restrict the coverage search space based on the feasibility and the quality of the partial
variable assignments induced by the coverage. We demonstrate that the coverage is an effective surrogate
measure to reduce discrepancies between the ML and MIP objectives. We also show that TaL reduces the
CF’s evaluation cost from linear to constant time.
Random subset We introduce a random subset S(n,ρ)as a set-valued random variable. Here nrepresents
the index set [n]. For each element in [n],ρ=ρ(n)∈[0,1]is the probability that the element is present.
The selection of each element is statistically independent of the selection of all other elements. We call ρthe
coverage of the subset. Formally, the sample space ΩforS(n,ρ)is a power set of [n], and the probability
measure for each subset B∈Ωassigns probability
P(B) =ρl(1−ρ)n−l, (7)
wherelis the number of elements in B. Given an MIP solution x∈Rn, we refer to S(n,ρ)as a realization
of the random variable that assigns the variable values of the selected dimensions of x.
Learning coverage search space We approximate the optimal coverage ρ∗with a graph neural network
output ˆρπ. Also, ˆρψis a graph neural network output that models the threshold coverage at which the
variable assignments of xswitch from a feasible to an infeasible state. Similarly, ˆρϕis a graph neural
network output that estimates the threshold coverage for computing a criterion value of an LP-relaxation
solution objective, which can be regarded as a lower bound of the solution quality. The LP-relaxation
solution objective criterion pertains to a specific condition where the sub-MIP resulting from partial variable
assignments is feasible and its LP-relaxation solution objective meets certain value. For formal definitions,
see Definition A.3 and A.4.
ˆρψ,ˆρϕ,ˆρπ=GraphNeuralNet( M) (8)
Note that the neural networks ˆρψ,ˆρϕ,andˆρπ, share the same ND model weights. Let ˆρprob
Ψbe a graph neural
network output that predicts the probability of the partial variable assignments induced by the coverage ˆρψ
being feasible. Similarly, ˆρprob
Φis a graph neural network output that predicts the probability of the partial
variable assignments induced by the coverage ˆρπsatisfying the LP-relaxation solution objective criterion.
ˆρprob
Ψandˆρprob
Φshare the same weights of the ND model.
ˆρprob
Ψ,ˆρprob
Φ=GraphNeuralNet( M) (9)
We define the indicator random variable that represents the state of the variable assignments.
Ifeas
S(n,ρ)=/braceleftigg
1,ifS(n,ρ)is feasible
0,otherwiseILP-sat
S(n,ρ)=

1,ifS(n,ρ)satisfies the LP relaxation
solution objective criterion
0,otherwise(10)
Loss function We propose a loss function to find the optimal coverage more efficiently. Let BCE (a,b) =
−(alogb+ (1−a) log(1−b))fora,b∈(0,1)be the binary cross entropy function. We implement the loss
function using the negative log-likelihood function, where the minimization of the negative log-likelihood is
the same as the minimization of binary cross entropy function. Let tbe the iteration step in the optimization
loop. Let x(τ,ρ)be the primal solution at time τwith initial variable assignments of xwith coverage ρ.
In practice, we obtain the optimal coverage as ρ∗= arg min ρ∈[ˆρϕ,ˆρψ]c⊤x(τ,ρ). To approximate the optimal
coverageρ∗using a GNN model ˆρπparameterized by π, we learn the model parameters πby minimizing the
loss functionLcoverage (π)defined as
Lcoverage (π) =∥ˆρπ−ρ∗∥2
2 (11)
5Under review as submission to TMLR
Since the search cost for the optimal coverage is expensive, we restrict the coverage search space by ap-
proximating the threshold coverages induced by the feasibility event Ifeas
S(n,ˆρψ)and the LP-relaxation solution
objective satisfiability event ILP-sat
S(n,ˆρπ). To approximate the threshold coverages using GNN models ˆρψandˆρϕ,
we learn the model parameters ψandϕby minimizing the following loss functions.
Lthreshold (ψ,ϕ) =BCE (ˆρprob(t−1)
Ψ,ˆρ(t)
ψ) +BCE (ˆρprob(t−1)
Φ,ˆρ(t)
ϕ), (12)
Lprob(Ψ,Φ) =BCE (Ifeas
S(n,ˆρψ),ˆρprob
Ψ) +BCE (ILP-sat
S(n,ˆρπ),ˆρprob
Φ) (13)
MinimizingLthresholdandLprobimply that ˆρψandˆρϕconverge to the threshold coverages induced by the
indicator random variables Ifeas
S(n,ˆρψ)andILP-sat
S(n,ˆρπ), respectively. Our final objective is to minimize the total
lossL, which comprises the three components.
L=/summationdisplay
t(Lcoverage +Lthreshold +Lprob)(14)
Note that the loss function in equation (14) is fully differentiable.
Coverage-probability mappings In equation (12) and (13), ˆρprob
Ψis an intermediary between ˆρψand
Ifeas
S(n,ˆρψ). Similarly, ˆρprob
Φbuffers between ˆρϕandILP-sat
S(n,ˆρπ). In practice, ˆρprob
Ψandˆρprob
Φprevent abrupt update
ofˆρψandˆρϕ, depending on Ifeas
S(n,ˆρψ)∈{0,1}andILP-sat
S(n,ˆρπ)∈{0,1}, respectively. Let ρprob
Ψbe a ground-truth
probability that the partial variable assignments S(n,ρψ)is feasible. Let ρprob
Φbe a ground-truth probability
that the partial variable assignments S(n,ρϕ)satisfies the LP-relaxation solution objective criterion. If
Ifeas
S(n,ˆρψ)andILP-sat
S(n,ˆρπ)are non-trivial, there always exist ρψ∈(0,1)andρϕ∈(0,1), such that ρψ=ρprob
Ψ
andρϕ=ρprob
Φ, whereρψandρϕare the threshold coverages. Also, if the value of the indicator random
variablesIfeas
S(n,ρψ)andILP-sat
S(n,ρπ)abrubtly shift based on ρψandρπ, the threshold coverages that correspond
to their corresponding probabilities, such that ρψ=ρprob
Ψandρϕ=ρprob
Φ, are justified.
Algorithm Algorithm 1 describes the overall procedure of TaL. We assume that there is a trained ND
modelpθto predict the discrete variable values. In Algorithm 1, ThresholdAwareGNN at line 6 extends
the model pθto learn ˆρψ,ˆρϕ,ˆρπin equation (8). ThresholdAwareProbGNN at line 7 extends the model
pθto learn ˆρprob
Ψ,ˆρprob
Φin equation (9). ThresholdSolve at line 7 computes the feasibility of the variable
assignments from S(n,ˆρψ), LP-satisfiability induced from S(n,ˆρπ), and the high-quality feasible solution
coverageρ∗, using the MIP solver (See Algorithm 2 in Appendix A.6 for detail). Note that we do not update
the ND weight parameters of pθin ThresholdAwareGNN and ThresholdAwareProbGNN.
3.2 Theoretical Results on Coverage Optimization in Threshold-aware Learning
In this section, we aim to justify our method by formulating the feasibility property P, LP-relaxation
satisfiability property Qκ, and their intersection property Fκ. Specifically, we show that there exist two
local threshold functions of Fκthat restrict the search space for the optimal coverage ρ∗. Finally, we suggest
that finding the optimal coverage shows an improved time complexity at the global optimum of Lthreshold.
Threshold functions in MIP variable assignments We follow the convention in (Bollobás & Thoma-
son, 1987). See Appendix 6 for formal definitions and statements. We leverage Bollobás & Thomason (1987,
Theorem 4), which states that every monotone increasing non-trivial property has a threshold function.
Given an MIP problem M= (A,b,c), we compute xfrom the discrete variable value prediction model pθ.
We denote a≪bora(n)≪b(n)when we refer to lim
n→∞a(n)/b(n) = 0.
Feasibility of partial variable assignments We formulate the feasibility property to show that the
property has a threshold function. The threshold function in the feasibility property is a criterion that
6Under review as submission to TMLR
Algorithm 1 ThresholdAwareLearning
Input: Batch sizeH, the number of iterations T, ND model pθ
1:ThresholdAwareGNN parameterized by ψ,ϕ,π.
2:ThresholdAwareProbGNN parameterized by Ψ,Φ.
3:i←0
4:fori≤Tdo
5:forj≤Hdo
6: x,ˆρψ,ˆρϕ,ˆρπ←ThresholdAwareGNN (M)
7: ˆρprob
Ψ,ˆρprob
Φ←ThresholdAwareProbGNN (M,ˆρψ,ˆρϕ,ˆρπ)
8:MIPOutput←ThresholdSolve (M,x,ˆρψ,ˆρϕ,ˆρπ)
9:Ifeas
S(n,ˆρψ),ILP-sat
S(n,ˆρπ),ρ∗←MIPOutput
10: ifρ∗is Null then
11: break
12: end if
13: ComputeLcoverage,Lthreshold,Lprobby eq. equation 11, equation 12, equation 13
14: g←∇πLcoverage,∇ψ,ϕLthreshold,∇Ψ,ΦLprob
15: gcoverage,gthreshold,gprob←g
16: Updateπ,(ψ,ϕ),(Ψ,Φ)by gradient descent with gcoverage,gthreshold,gprob
17:j←j+ 1
18: end for
19:i←i+ 1
20:end for
21:return ThresholdAwareGNN
dependsonboththelearnedNDmodel pθandtheinputproblem, usedtodetermineacoverageforgenerating
a feasible solution. We assume Mhas a feasible solution and the full solution xgenerated by the ND model
pθis not feasible.
We denote S(n,ρ)∈Pif there exists a feasible solution that contains the corresponding variable values in
S(n,ρ)⊂[n]. IfPis a nontrivial monotone decreasing property, we can define threshold function p0ofPas
P(S(n,ρ)∈P)→/braceleftigg
1ifρ≪p0
0ifρ≫p0(15)
Here,Pis monotone decreasing. Therefore, Phas a threshold function p0by Theorem A.5 and Lemma A.8
in Appendix A.4.
LP-relaxation satisfiability of partial variable assignments We formulate the LP-relaxation satis-
fiability property to show there exists a local threshold function. Given the learned ND model, we set κ
to represent the lower bound of the sub-MIP’s primal bound. The local threshold function is a criterion
depends on the learned ND model and input problem, used to determine a coverage for generating a feasible
solution with an objective value of at least κ.
Letˆx(ρ)be the LP-relaxation solution values after assigning variable values in S(n,ρ). We denote S(n,ρ)∈
Qκifˆx(ρ)is feasible and c⊤ˆx(ρ)is at leastκ. We define the local threshold function q0,κas
P(S(n,ρ)∈Qκ)→/braceleftigg
0ifρ≪q0,κ≪i
1ifi≫ρ≫q0,κ(16)
Here,iis the upper bound of ρ. We assume Mhas a feasible solution, and the full solution xgenerated by
the ND model pθis not feasible. Also, we assume LP-feasible partial variable assignments exist, such that
Qκis nontrivial.
IfPis nontrivial and κis fixed, thenQκis bounded monotone increasing. By the assumption, Pis nontrivial.
Qκhas a local threshold function by Theorem A.7 and Lemma A.9 in Appendix A.4.
7Under review as submission to TMLR
Feasibility and LP-relaxation satisfiability of partial variable assignments We formulate the
propertyFκas an intersection of the property PandQκ. Theorem A.11 in Appendix A.4 states that Fκ
has two local thresholds pa, andpb, such that pa≪ρ≪pbimplies that S(n,ρ)satisfies the MIP feasibility
and the LP-relaxation objective criterion.
Formally, given that Pis nontrivial monotone decreasing and Qκis nontrivial bounded monotone increasing,
Fκ:=P∩Qκ (17)
For some property Hn, a family of subsets Hnis convex if Ba⊆Bb⊆BcandBa,Bc∈HnimplyBb∈Hn.
If we bound the domain of Fκwithp0, such that ρ∈(0,p0)inS(n,ρ)forFκ, thenFκis convex in the
domain, since the intersection of an increasing and a decreasing property is a convex property (Janson et al.,
2011). We define ∆-optimal solution x∆∈Zn, such that c⊤x∆≤c⊤x⋆+ ∆. Let ∆-optimal coverage
ρ∗
∆be the coverage, such that c⊤x(τ,ρ∗
∆)≤c⊤x∆. IfB(n)∈Fκ∗, we assume that the variable values in
B(n)⊂[n]lead to ∆-optimal solution given x. LetAbe the original search space to find the ∆-optimal
coverageρ∗
∆. Lettbe the complexity to find the optimal point as a function of search space size |A|, such
that the complexity to find the optimal coverage is O(t(|A|)). Letκ∗:= maxκsubject to c⊤ˆx(ρ) =κand
P(S(n,ρ)∈Qκ) =ξfor someρ∈(0,1). We assume κ∗is given as ground truth in theory, while we adjust
κalgorithmically in practice. We refer to p1(n)≲p2(n)if there exists a positive constant Cindependent of
n, such that p1(n)≤Cp2(n), forn>1/ϵ. We assume q0,κ≲p0.
We show that TaL reduces the complexity to find the ∆-optimal coverage ρ∗
∆by restricting the search space,
such thatρ∗
∆∈(q0,κ∗,p0), if the test dataset and the training dataset is i.i.d.and the time budget to find
the feasible solution is sufficient in the test phase.
Theorem 3.1. If the variable values in S(n,ρ)∈Fκ∗lead to a ∆-optimal solution, then the complexity of
finding the ∆-optimal coverage is O(t((p0−q0,κ∗)|A|))at the global optimum of Lthreshold.
Proof Sketch. First, we prove the following statement. If the variable values in S(n,ρ)∈Fκ∗lead to ∆-
optimal solution and ρ∗
∆= arg min
ρc⊤x(τ,ρ), then
q0,κ∗≲ρ∗
∆≲p0 (18)
Finally, we show that ˆρψ≈p0andˆρϕ≈q0,κ∗at the global optimum of Lthreshold. See the full proof in the
Appendix A.4.
Connection to the methodology At line 8 in Algorithm 1 (ThresholdSolve procedure; details in Ap-
pendixA.6), wesearchforthe ∆-optimalcoverageusingderivative-freeoptimization(DFO),suchasBayesian
optimization or ternary search in the search space restricted into (ˆρψ,ˆρϕ). Our GNN outputs converge to
the local threshold functions, such that ˆρψ≈p0andˆρϕ≈q0,κ∗, at the global minimum of the loss function
in (12) after iterating over the inner loop of Algorithm 1. It follows that the search space for ρ∗
∆becomes
(q0,κ∗,p0)at the global minimum of the loss function in (12), by Theorem 3.1. By Theorem 3.1 and our as-
sumption, the cardinality of the search space to find ρ∗
∆becomes (p0−q0,κ∗)|A|. Therefore, the post-training
complexity of TaL is O((p0−q0,κ∗)n)in Table 1.
Time complexity We assume that there are ndiscrete variables present in each MIP instance within both
the training and test datasets. For simplicity, we denote that the cost of training or evaluating a single model
isO(1). In the worst-case scenario, ND requires training nmodels and evaluating all ntrained models to
find the optimal coverage. Therefore, the training and evaluation of ND require a time complexity of O(n),
where training is computationally intensive on GPUs, and evaluation is computationally intensive on CPUs.
By excluding the SelectiveNet from ND, CF remarkably improves the training complexity of ND from O(n)
toO(1).
In Table 1, CF still requires O(n)time for evaluation in order to determine the optimal cutoff value for the
confidencescore. TaLutilizesapost-trainingprocessasanintermediatestepbetweentrainingandevaluation,
thereby reducing the evaluation cost to O(1). For simplicity, we denote O(1)for the MIP solution verification
and neural network weight update for each coverage in post-training.
8Under review as submission to TMLR
Table 1: Worst-case computational complexity comparison over the methods
Training (GPU↑) Post-training (CPU ↑, GPU↓) Evaluation (CPU ↑)
ND (Nair et al.) O(n) - O(n)
CF (Ours) O(1) - O(n)
TaL (Ours) O(1) O((p0−q0,κ∗)n) O(1)
4 Other Related Work
There have been SL approaches to accelerate the primal solution process (Xavier et al., 2021; Nair et al.,
2020; Sonnerat et al., 2021; Shen et al., 2021; Ding et al., 2020; Khalil et al., 2022). Empirically, these
methods outperform the conventional solver-tuning approaches. Meanwhile, reinforcement learning (RL) is
one of the mainstream frameworks for solving CO problems (Khalil et al., 2017; Kool et al., 2018; Kwon
et al., 2020; Barrett et al., 2020; Chen & Tian, 2019; Delarue et al., 2020; Lu et al., 2019; Li et al., 2021;
Cunha et al., 2018; Manchanda et al., 2019). RL-based approaches represent the actual task performance
as a reward in the optimization process. However, the RL reward is non-differentiable and the RL sample
complexity hinders dealing with large-scale MIP problems. On the other hand, an unsupervised learning
frameworktosolveCOproblemsongraphsproposedbyKaralias&Loukas(2020)providestheoreticalresults
based on probabilistic methods. However, the framework in Karalias & Loukas (2020) does not leverage or
outperform the MIP solver. Among heuristic algorithms, the RENS (Berthold, 2014) heuristic combines two
types of methods, relaxation and neighborhood search, to efficiently explore the search space of a mixed
integer non-linear programming (MINLP) problem. One potential link between our method and the RENS
heuristic is that our method can determine the coverage that leads to a higher success rate, regardless of
the (N)LP relaxation used in the RENS algorithm. To the best of our knowledge, our work is the first to
leverage the threshold function theory for optimizing the coverage to reduce the discrepancy between the
ML and CO problems objectives.
5 Experiments
5.1 Metrics
We use Primal Integral (PI), as proposed by Berthold (2013) to evaluate the solution quality over the time
dimension. PI measures the area between the primal bound and the optimal solution objective value over
time. Formally,
PI=/integraldisplayT
τ=0c⊤x⋆(τ)dτ−Tc⊤x⋆, (19)
whereTis the time limit, x⋆(τ)is the best feasible solution by time τ, and x⋆is the optimal solution.
PI is a metric representing the solution quality in the time dimension, i.e.,how fast the quality improves.
The optimal instance rate (OR) in Table 2 refers to the average percentage of the test instances solved
to optimality in the given time limit. If the problems are not optimally solved, we use the best available
solution as a reference to the optimal solution. The optimality gap (OG) refers to the average percentage
gap between the optimal solution objective values and the average primal bound values in the given time
limit.
5.2 Data and evaluation settings
We evaluate the methods with the datasets introduced from (Gasse et al., 2022; 2019). We set one minute
to evaluate for relatively hard problems from (Gasse et al., 2022): Workload apportionment and maritime
inventory routing problems. For easier problems from (Gasse et al., 2019), we solve for 1,10, and 5seconds
for the set covering, capacitated facility flow, and maximum independent set problems, respectively. The
optimalityresultsinthelowerpartofTable2areobtainedbysolvingtheproblemsusingSCIPfor 3minutes, 2
9Under review as submission to TMLR
hours, and 10minutes for the set covering, capacitated facility flow, and maximum independent set problems,
respectively. We convert the objective of the capacitated facility flow problem into a minimization problem
by negating the objective coefficients, in which the problems are originally formulated as a maximization
problem in (Gasse et al., 2019). Furthermore, we measure the performance of the model trained on the
maritime inventory routing dataset augmented with MIPLIB 2017 (Gleixner et al., 2021) to verify the
effectiveness of data augmentation. Additional information about the dataset can be found in Appendix
A.7.
5.3 Results
Table 2: Overall results comparing optimality, SCIP, Neural diving, GNNExplainer, Confidence Filter, and
Threshold-aware Learning in five MIP datasets: Workload apportionment, maritime inventory routing, set
covering, capacitated facility flow, and maximum independent set. Given the time limit, we use Primal
Integral (PI) to evaluate the solution quality over time, Primal Bound (PB) to measure the final solution
quality, Optimality Gap (OG) to compare the solution quality with the optimal solution, and Optimal
instance Rate (OR) to show how many problems are solved to optimality.
Workload Maritime Inventory Maritime Inventory
Apportionment Routing (non-augmented) Routing (augmented)
PI↓PB↓OG (%)↓OR (%)↑ PI↓ PB↓OG (%)↓OR (%)↑ PI↓ PB↓OG (%)↓OR (%)↑
SCIP (30 hrs) - 708.31 0.01 98 - 50175.95 0 100 - 50175.95 0 100
SCIP (1 min) 48182.31 738.85 4.36 0 41682758 .55 647961 .18 305.48 30 41682758 .55 647961 .18 305.48 30
Neural diving (Nair et al., 2020) 44926.06 713.10 0.69 2 28357794 .50 372770 .44 143.08 30 30101028 .39 322748 .95 115.88 30
GNNExplainer (Ying et al., 2019) 47165.63 719.96 1.65 0 29343874 .24 369122 .56 141.50 20 39004703 .50 509108 .16 249.95 25
Confidence Filter (Ours) 44862.77 711.43 0.47 2 24581204 .50 202526 .50 83.91 35 24795796 .07 306165.57 136.55 30
Threshold-aware Learning (Ours) 44634.85 711.34 0.45 4 24288490 .56 192074 .00 69.97 30 33639950 .16 287189.69 106.68 35
Set Covering Capacitated Facility Flow Maximum Independent Set
PI↓PB↓OG (%)↓OR (%)↑PI↓ PB↓OG (%)↓OR (%)↑PI↓ PB↓OG (%)↓OR (%)↑
Optimality − 225.79 0 100 − 18049.77 0 100 − − 226.61 0 100
SCIP 788.04 606.68 165.96 2 834198 .50 43172 .72 139.40 0 −1009.56−218.64 3.55 10
Neural diving (Nair et al., 2020) 493.65 246.12 8.99 0 312589.87 18221.34 0.93 34−1062.37−226.51 0.05 95
Confidence Filter (Ours) 431.31 233.06 3.13 5 319075.00 18214 .33 0.91 16 −1081.87−226.44 0.08 87
Threshold-aware Learning (Ours) 411.45 232.99 3.09 3 318984 .36 18147.82 0.54 23−1075.95−226.57 0.02 96
Table 2 shows that TaL outperforms the other methods on all five datasets. Also, CF outperforms ND
in relatively hard problems: Workload apportionment and maritime inventory routing problems. In the
workload apportionment dataset, TaL shows a 0.45%optimality gap at the one-minute time limit, roughly
10×better than SCIP. In the maritime inventory routing non-augmented dataset, TaL achieves a 70%
optimality gap, which is 2×better than ND and 3×better than SCIP. In relatively easy problems, TaL
outperforms ND in the optimality gap by 3×,2×, and 2×in the set covering, capacitated facility flow,
and maximum independent set problems, respectively. On average, TaL takes 10 seconds to show 0.54%
optimality gap while SCIP takes 2 hours to solve capacitated facility flow test problems to optimality. The
best PI value (TaL) in the data-augmented maritime inventory routing dataset is close to the best PI value
(CF) in the non-augmented dataset. Moreover, CF in the data-augmented dataset solves the same number
of instances to the optimality as the TaL in the non-augmented dataset.
6 Conclusion
In this work, we present the CF and TaL methods to enhance the learning-based MIP optimization perfor-
mance. We propose a provably efficient learning algorithm to estimate the search space for coverage opti-
mization. We also provide theoretical justifications for learning to optimize coverage in generating feasible
solutions for MIP, from the perspective of probabilistic combinatorics. Finally, we empirically demonstrate
that the variable assignment coverage is an effective auxiliary measure to fill the gaps between the SL and
MIP objectives, showing competitive results against other methods.
One limitation of our approach is that the neural network model relies on collecting MIP solutions, which
can be computationally expensive. Hence, it would be intriguing to devise a novel self-supervised learning
10Under review as submission to TMLR
approach to train a foundational model for solving MIP problems in combination with TaL. Also, another
direction for future work is to extend TaL to a broader area of machine learning in a high-dimensional setting.
Author Contributions
Acknowledgments
References
Tobias Achterberg, Thorsten Koch, and Alexander Martin. Branching rules revisited. Operations Research
Letters, 33(1):42–54, 2005.
Tobias Achterberg, Timo Berthold, and Gregor Hendel. Rounding and propagation heuristics for mixed
integer programming. In Operations research proceedings 2011 , pp. 71–76. Springer, 2012.
David Applegate, Robert Bixby, Vašek Chvátal, and William Cook. Implementing the dantzig-fulkerson-
johnson algorithm for large traveling salesman problems. Mathematical programming , 97(1):91–153, 2003.
Egon Balas and Andrew Ho. Set covering algorithms using cutting planes, heuristics, and subgradient opti-
mization: a computational study . Springer, 1980.
Maria-Florina Balcan, Travis Dick, Tuomas Sandholm, and Ellen Vitercik. Learning to branch. In Interna-
tional conference on machine learning , pp. 344–353. PMLR, 2018.
Thomas Barrett, William Clements, Jakob Foerster, and Alex Lvovsky. Exploratory combinatorial opti-
mization with reinforcement learning. In Proceedings of the AAAI Conference on Artificial Intelligence ,
volume 34, pp. 3243–3250, 2020.
David Bergman, Andre A Cire, Willem-Jan Van Hoeve, and John Hooker. Decision diagrams for optimiza-
tion, volume 1. Springer, 2016.
Timo Berthold. Primal heuristics for mixed integer programs . PhD thesis, Zuse Institute Berlin (ZIB), 2006.
Timo Berthold. Measuring the impact of primal heuristics. Operations Research Letters , 41(6):611–614,
2013.
Timo Berthold. Rens: the optimal rounding. Mathematical Programming Computation , 6:33–54, 2014.
Béla Bollobás. Threshold functions for small subgraphs. In Mathematical Proceedings of the Cambridge
Philosophical Society , volume 90, pp. 197–206. Cambridge University Press, 1981.
Béla Bollobás and Arthur G Thomason. Threshold functions. Combinatorica , 7(1):35–38, 1987.
Xinyun Chen and Yuandong Tian. Learning to perform local rewriting for combinatorial optimization.
Advances in Neural Information Processing Systems , 32, 2019.
Gérard Cornuéjols, Ranjani Sridharan, and Jean-Michel Thizy. A comparison of heuristics and relaxations
for the capacitated plant location problem. European journal of operational research , 50(3):280–297, 1991.
Bruno Cunha, Ana M Madureira, Benjamim Fonseca, and Duarte Coelho. Deep reinforcement learning as a
job shop scheduling solver: A literature review. In International Conference on Hybrid Intelligent Systems ,
pp. 350–359. Springer, 2018.
Arindam Kumar Das, Robert J Marks, Mohamed El-Sharkawi, Payman Arabshahi, and Andrew Gray.
Minimum power broadcast trees for wireless networks: integer programming formulations. In IEEE IN-
FOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications
Societies (IEEE Cat. No. 03CH37428) , volume 2, pp. 1001–1010. IEEE, 2003.
Arthur Delarue, Ross Anderson, and Christian Tjandraatmadja. Reinforcement learning with combinatorial
actions: An application to vehicle routing. Advances in Neural Information Processing Systems , 33:609–
620, 2020.
11Under review as submission to TMLR
Jian-Ya Ding, Chao Zhang, Lei Shen, Shengyin Li, Bing Wang, Yinghui Xu, and Le Song. Accelerating
primal solution findings for mixed integer programs based on solution prediction. In Proceedings of the
AAAI Conference on Artificial Intelligence , volume 34, pp. 1452–1459, 2020.
Matteo Fischetti, Fred Glover, and Andrea Lodi. The feasibility pump. Mathematical Programming , 104(1):
91–104, 2005.
Maxime Gasse, Didier Chételat, Nicola Ferroni, Laurent Charlin, and Andrea Lodi. Exact combinatorial op-
timization with graph convolutional neural networks. Advances in Neural Information Processing Systems ,
32, 2019.
Maxime Gasse, Quentin Cappart, Jonas Charfreitag, Laurent Charlin, Didier Chételat, Antonia Chmiela,
Justin Dumouchelle, Ambros Gleixner, Aleksandr M Kazachkov, Elias Khalil, et al. The machine
learning for combinatorial optimization competition (ml4co): Results and insights. arXiv preprint
arXiv:2203.02433 , 2022.
Yonatan Geifman and Ran El-Yaniv. Selectivenet: A deep neural network with an integrated reject option.
InInternational conference on machine learning , pp. 2151–2159. PMLR, 2019.
Ambros Gleixner, Gregor Hendel, Gerald Gamrath, Tobias Achterberg, Michael Bastubbe, Timo Berthold,
Philipp Christophel, Kati Jarck, Thorsten Koch, Jeff Linderoth, et al. Miplib 2017: data-driven com-
pilation of the 6th mixed-integer programming library. Mathematical Programming Computation , 13(3):
443–490, 2021.
He He, Hal Daume III, and Jason M Eisner. Learning to search in branch and bound algorithms. Advances
in neural information processing systems , 27, 2014.
Svante Janson, Andrzej Rucinski, and Tomasz Luczak. Random graphs . John Wiley & Sons, 2011.
Nikolaos Karalias and Andreas Loukas. Erdos goes neural: an unsupervised learning framework for com-
binatorial optimization on graphs. Advances in Neural Information Processing Systems , 33:6659–6672,
2020.
Elias B Khalil, Bistra Dilkina, George L Nemhauser, Shabbir Ahmed, and Yufen Shao. Learning to run
heuristics in tree search. In Ijcai, pp. 659–666, 2017.
Elias B Khalil, Christopher Morris, and Andrea Lodi. Mip-gnn: A data-driven framework for guiding
combinatorial solvers. In Proceedings of the AAAI Conference on Artificial Intelligence , 2022.
Wouter Kool, Herke Van Hoof, and Max Welling. Attention, learn to solve routing problems! arXiv preprint
arXiv:1803.08475 , 2018.
Yeong-Dae Kwon, Jinho Choo, Byoungjip Kim, Iljoo Yoon, Youngjune Gwon, and Seungjai Min. Pomo:
Policy optimization with multiple optima for reinforcement learning. Advances in Neural Information
Processing Systems , 33:21188–21198, 2020.
Sirui Li, Zhongxia Yan, and Cathy Wu. Learning to delegate for large-scale vehicle routing. Advances in
Neural Information Processing Systems , 34:26198–26211, 2021.
Hao Lu, Xingwen Zhang, and Shuang Yang. A learning-based iterative method for solving vehicle routing
problems. In International conference on learning representations , 2019.
Sahil Manchanda, Akash Mittal, Anuj Dhawan, Sourav Medya, Sayan Ranu, and Ambuj Singh. Learning
heuristics over large graphs via deep reinforcement learning. arXiv preprint arXiv:1903.03332 , 2019.
Renata Mansini, Lodzimierz Ogryczak, M Grazia Speranza, and EURO: The Association of European Op-
erational Research Societies. Linear and mixed integer programming for portfolio optimization , volume 21.
Springer, 2015.
12Under review as submission to TMLR
Prabir C Maulik, L Richard Carley, and Rob A Rutenbar. Integer programming based topology selection
of cell-level analog circuits. IEEE Transactions on Computer-Aided Design of Integrated Circuits and
Systems, 14(4):401–412, 1995.
Vinod Nair, Sergey Bartunov, Felix Gimeno, Ingrid von Glehn, Pawel Lichocki, Ivan Lobov, Brendan
O’Donoghue, Nicolas Sonnerat, Christian Tjandraatmadja, Pengming Wang, et al. Solving mixed integer
programs using neural networks. arXiv preprint arXiv:2012.13349 , 2020.
Dimitri J Papageorgiou, George L Nemhauser, Joel Sokol, Myun-Seok Cheon, and Ahmet B Keha. Mirplib–
a library of maritime inventory routing problem instances: Survey, core model, and benchmark results.
European Journal of Operational Research , 235(2):350–366, 2014.
Yves Pochet and Laurence A Wolsey. Production planning by mixed integer programming , volume 149.
Springer, 2006.
Tadeusz Sawik. Scheduling in supply chains using mixed integer programming . John Wiley & Sons, 2011.
Yunzhuang Shen, Yuan Sun, Andrew Eberhard, and Xiaodong Li. Learning primal heuristics for mixed
integer programs. In 2021 International Joint Conference on Neural Networks (IJCNN) , pp. 1–8. IEEE,
2021.
Nicolas Sonnerat, Pengming Wang, Ira Ktena, Sergey Bartunov, and Vinod Nair. Learning a large neigh-
borhood search algorithm for mixed integer programs. arXiv preprint arXiv:2107.10201 , 2021.
Yunhao Tang, Shipra Agrawal, and Yuri Faenza. Reinforcement learning for integer programming: Learning
to cut. In International Conference on Machine Learning , pp. 9367–9376. PMLR, 2020.
Álinson S Xavier, Feng Qiu, and Shabbir Ahmed. Learning to solve large-scale security-constrained unit
commitment problems. INFORMS Journal on Computing , 33(2):739–756, 2021.
Rex Ying, Dylan Bourgeois, Jiaxuan You, Marinka Zitnik, and Jure Leskovec. Gnn explainer: A tool for
post-hoc explanation of graph neural networks. arXiv preprint arXiv:1903.03894 , 2019.
13Under review as submission to TMLR
A Appendix
A.1 Notations
•n: the number of variables
•m: the number of linear constraints
•r: the number of discrete variables
•x= [x1,...,xn]∈Rn: the vector of variable values
•xint∈Zr,xcont∈Rn−randx= [xint;xcont]
•x⋆: the vector of optimal solution variable values
•x(τ,ρ): the vector of primal solution at time τwith initial variable assignments of xwith coverage
ρ
•ˆx(ρ): the LP-relaxation solution with initial variable assignments of xwith coverage ρ
•¯x: the vector of LP-relaxation solution variable values
•c∈Rn: the vector of objective coefficients
•A∈Rm×n: the linear constraint coefficient matrix
•b∈Rm: the vector of linear constraint upper bound
•ei=e(n)
i∈Rn,i= 1,...,n: the Euclidean standard basis
•[n] ={1,2,...,n}: the index set
•M= (A,b,c): the MIP problem
•I: the set of dimensions of xthat is discrete
•xd: thed-th dimension of x
•sd: the binary classifier output to decide to fix xd
•pθ: Neural diving model (without SelectiveNet) parameterized by θ
•Γ: the cutoff value for Post hoc Confidence Filter
•R(M): the set of feasible solution(s) x∈Zr×Rn−r
•¯R(M): the set of LP-relaxation solution(s) x∈Rnwhich satisfies Ax≤bregardless the integrality
constraints
•ˆR(M): the set of LP-feasible solution(s) x∈Zr×Rn−rwhich satisfies Ax≤bafter partially fixing
discrete variables of x
•ξ∈(0,1): the probability at which threshold behavior occurs
•P(X): the power set of X
•a≪bora(n)≪b(n) : lim
n→∞a(n)/b(n) = 0
•a≫bora(n)≫b(n) : lim
n→∞a(n)/b(n) =∞
•a≲b:a(n)≲b(n) :there exists C > 0,s. t.a(n)≤Cb(n), wheren∈N, for some setN
•κ: the target objective value of the LP-solution for partial discrete variables fixed
14Under review as submission to TMLR
0 30 60
Time (s)725750775800825850875Primal bound 
ND without SelectiveNet ≈ 85%
≈ 98%Validation Accuracy
ND with SelectiveNet
Figure 3: The variable value classification accuracy and the primal bound comparison in the validation
dataset according to the existence of SelectiveNet. Variable value classification accuracy measures how
many integer variables values match out of the total integer variables between the neural network output
and the solution; the higher, the better. The primal bound represents the MIP solution quality; the lower,
the better. We measure the primal bound over time at the one-minute time limit. The average discrete
variable assignment rate is 20%for both models. We use Confidence Filter for ‘ND without SelectiveNet’.
SelectiveNet improves the classification accuracy by roughly 13percentage points margin, whereas Neural
diving without SelectiveNet outperforms SelectiveNet in the primal bound. The target dataset is the Work-
load Apportionment problem from Gasse et al. (2022).
A.2 Discrepancy between the learning and MIP objectives
The ND learning objective is to minimize the loss function formulated as a negative log likelihood. On the
other hand, MIP aims to optimize the objective function satisfying the constraints. Let’s say the learning
objective is denoted by minimize L. Let’s say the MIP objective is denoted by minimize c⊤x. Assume
that we obtain the solution ˜x, which can be infeasible, from the ND model pθ(x|M)that corresponds to L.
Let˜x(τ,ρ)be a feasible solution at solving time τwith initial variable assignment of ˜xwith coverage rho.
It follows that c⊤˜x(τ,ρ)is not monotone with respect to its corresponding loss L. In Figure 3, ND with
SelectiveNet outperforms ND without SelectiveNet by roughly 13percentage points in validation variable
classificationaccuracy. Incontrast, NDwithoutSelectiveNetoutperformsNDwithSelectiveNetintheprimal
bound.
A.3 Formal Definitions
LetP([n])denotes the power set of [n] ={1,...,n}. Anontrivial property Hnis a nonempty collection
of subsets of [n], where the subsets satisfy the conditions of HnandHn̸=P([n]). We callHnmonotone
increasing ifBss∈HnandBss⊂Bs⊂[n]impliesBs∈Hn. We callHnmonotone decreasing ifBs∈Hn
andBss⊂BsimpliesBss∈Hn. Note that a monotone increasing (decreasing) property Hnis non-trivial
if and only if∅/∈Hnand[n]∈Hn(∅∈Hnand[n]/∈Hn).
Fori= 0,...,n, letBi⊂[n]denote the collection of subsets of [n]withielements, i.e.|Bi|=/parenleftbign
i/parenrightbig
, and
defineHi:=Hn∩Bi. Note that
P(Hn|Bi) =|Hi|
|Bi|=|Hi|/parenleftbign
i/parenrightbig (20)
15Under review as submission to TMLR
where the conditional probability P(Hn|Bi)denotes the probability that a random set of Bihas propertyHn.
If an increasing sequence m=m(n)satisfies that P(Hn|Bm(n))→1asn→∞, then we say that m-subset
ofBm(n)hasHnalmost surely. Similarly, we say that m-subset ofBm(n)fails to haveHnalmost surely if
P(Hn|Bm(n))→0asn→∞.
Definition A.1. A function m∗(n)is a threshold function for a monotone increasing property Hnif for
m/m∗→0asn→∞(we writem≪m∗),m-subset ofBnfails to haveHnalmost surely and for m/m∗→∞
asn→∞(we writem≫m∗),m-subset ofBnhasHnalmost surely:
lim
n→∞P(Hn|Bm(n)) =/braceleftigg
0 :m(n)≪m∗(n)
1 :m(n)≫m∗(n).(21)
Similarly, a function m∗(n)is said to be a threshold function for a monotone decreasing property Hnif for
m/m∗→∞asn→∞,m-subset ofBnfails to haveHnalmost surely and for m/m∗→0asn→∞,
m-subset ofBnhasHnalmost surely:
lim
n→∞P(Hn|Bm(n)) =/braceleftigg
0 :m(n)≫m∗(n)
1 :m(n)≪m∗(n).(22)
We sayHnisbounded monotone decreasing ifBs∈HnandBss⊂Bs∈BiimpliesBss∈Hnfori < n.
We sayHnisbounded monotone increasing ifBss∈HiandBss⊂Bs∈BiimpliesBs∈Hifori<n. We
introduce a local version of a threshold function in the Definition A.1 for a bounded monotone increasing
and decreasing property.
Definition A.2. A function l∗(n)is a local threshold function for a bounded monotone increasing property
Hnif forl/l∗→0,l∗/i→0asn→∞,l-subset ofBnfails to haveHnalmost surely, and for l/l∗→∞,i/l→
∞asn→∞,l-subset ofBnhasHnalmost surely:
lim
n→∞P(Hn|Bl(n)) =/braceleftigg
0 :l(n)≪l∗(n)≪i(n)
1 :i(n)≫l(n)≫l∗(n).(23)
Similarly, a function l∗(n)is said to be a local threshold function for a bounded monotone decreasing
propertyHnif forl/l∗→∞,i/l→∞asn→∞,l-subset ofBnfails to haveHnalmost surely and for
l/l∗→0,l∗/i→0asn→∞,l-subset ofBnhasHnalmost surely:
lim
n→∞P(Hn|Bl(n)) =/braceleftigg
0 :i(n)≫l(n)≫l∗(n)
1 :l(n)≪l∗(n)≪i(n).(24)
From Definition A.2, we have the statement about local threshold functions in bounded monotone properties
in Theorem A.7 in Appendix A.4. Theorem A.7 states that every nontrivial bounded monotone increasing
property has a local threshold function in a bounded domain.
Definition A.3. Given an MIP problem M= (A,b,c),x∈Rn, we define the property Pas
P(x,A,b) :={B(n)⊂[n] :there exists y′∈Zr×Rn−rsubject to A[y+y′]≤b}, (25)
where y=/summationtext
i∈B(n)xiei, and y′=/summationtext
i∈[n]\B(n)yiei.
Definition A.4. Given an MIP problem M= (A,b,c),x∈Rn, andκ∈R, we define the property Qκas
Qκ(x,A,b,c) :={B(n)⊂[n] :there exists z′∈Rn
subject to c⊤[z+z′]≥κandA[z+z′]≤b},(26)
where z=/summationtext
i∈B(n)xieiandz′=/summationtext
i∈[n]\B(n)ziei.
16Under review as submission to TMLR
A.4 Theoretical Statements
Theorem A.5. Letξ∈(0,1). For each n∈N, letHnbe a monotone increasing non-trivial property and
set
m∗(n) := max{m:P(Hn|Bm)≤ξ}. (27)
Ifm≤m∗(n), then
P(Hn|Bm)≤1−ξm
m∗(n) (28)
and, ifm≥m∗(n) + 1, then
P(Hn|Bm)≥1−ξm
m∗(n)+1. (29)
In particular, m∗(n)is a threshold function of Hn.
Proof.We slightly modify the proof in Bollobás & Thomason (1987, Theorem 4) for rigorousness. Let Jn
denote the negation of Hn. Note thatJnis a nontrivial monotone decreasing property.
Ifm≤m∗(n), then
P(Jn|Bm)≥P(Jn|Bm∗(n))≥ξm
m∗(n)
Ifm≥m∗(n) + 1, then
P(Jn|Bm)≤P(Jn|Bm∗(n)+1)≤ξm
m∗(n)+1
Corollary A.6. Letξ∈(0,1). For eachn∈N, letHnbe a monotone decreasing nontrivial property.
m∗(n) := min{m:P(Hn|Bm)≥ξ}. (30)
Ifm≤m∗(n), then
P(Hn|Bm)≥1−ξm
m∗(n) (31)
Ifm≥m∗(n) + 1, then
P(Hn|Bm)≤1−ξm
m∗(n)+1 (32)
In particular, m∗(n)is a threshold function of Hn.
Proof.LetJndenote the negation of Hn. Note thatJnis a nontrivial monotone increasing property.
Ifm≤m∗(n), then
P(Jn|Bm)≤P(Jn|Bm∗(n))≤ξm
m∗(n)
Ifm≥m∗(n) + 1, then
P(Jn|Bm)≥P(Jn|Bm∗(n)+1)≥ξm
m∗(n)+1
Theorem A.7. Letξ∈(0,1). For each n∈N, letHnbe a non-trivial bounded monotone increasing
property, where the bound is i.
l∗(n) := max{l:P(Hn|Bl)≤ξ}. (33)
Ifl≥i+ 1, then it is of limited interest since Hnis non-monotone in such domain. If l≤l∗(n)≤i, then
P(Hn|Bl)≤1−ξl
l∗(n)andP(Hn|Bl∗(n))≤1−ξl∗(n)
i (34)
17Under review as submission to TMLR
Ifi≥l≥l∗(n) + 1, then
P(Hn|Bl)≥1−ξl
l∗(n)+1andP(Hn|Bi)≥1−ξi
l (35)
In particular, l∗is a local threshold function of Hnbounded by i.
Proof.We adapt the proof in Bollobás & Thomason (1987, Theorem 4) for Definition A.2. Let Jndenote
the negation ofHn. Note thatJnis a nontrivial bounded monotone decreasing property.
Ifl≤l∗(n)≤i, then
P(Jn|Bl)≥P(Jn|Bl∗(n))≥ξl
l∗(n)andP(Jn|Bl∗(n))≥P(Jn|Bi)≥ξl∗(n)
i
Ifi≥l≥l∗(n) + 1, then
P(Jn|Bl)≤P(Jn|Bl∗(n)+1)≤ξl
l∗(n)+1andP(Jn|Bi)≤P(Jn|Bl)≤ξi
l
Lemma A.8.Pis monotone decreasing.
Proof.LetBsbe a set, such that Bs⊂B. LetBssbe a set, such that Bss⊂Bs. By definition, if Bs∈P,
then there exists z′
s, such that A[zs+z′
s]≤b, where zs=/summationtext
i∈Bsxiei, and z′
s=/summationtext
i∈[n]\Bsziei, given x. Let
zss=/summationtext
i∈Bssxiei, and z′
ss=/summationtext
i∈[n]\BsszieiforBss⊂Bs. We can choose z′
ss, such that z′
ss=z′
s+/summationtext
i∈Bs\Bssxiei,
where/summationtext
i∈Bs\Bssxiei=zs−/summationtext
i∈Bssxiei. Itfollowsthatthereexists z′
ss, suchthat A[zss+z′
ss] =A[zs+z′
s]≤b.
Hence,Bs∈PimpliesBss∈P.
Lemma A.9. Fixκ. IfPis nontrivial, then Qκis bounded monotone increasing.
Proof.Phas a threshold function p0by Theorem A.5 and Lemma A.8. We choose p0for the bound ofQκ.
Therefore, we inspect only the domain of interest q∈[0,p0]inS(n,q)forQκ. Let up=/summationtext
i∈Bpxiei∈Znfor
Bp=S(n,p0)∈P. GivenBp∈P, there exists u′
p=/summationtext
i∈[n]\Bpuiei∈Rn, such that A[up+u′
p]≤b, since
Zn⊂Rn.
LetBsbe a set, such that Bs⊂Bp. LetBssbe a set, such that Bss⊂Bs. By definition, Bss∈Qκ
implies there exists u′
ss=/summationtext
i∈[n]\Bssuiei∈Rn, such that A[uss+u′
ss]≤b, and c⊤[uss+u′
ss]≥κwhere
uss=/summationtext
i∈Bssxiei∈Zn, given x. Let us=/summationtext
i∈Bsxiei∈Zn, and u′
s=/summationtext
i∈[n]\Bsuiei∈Rn. We show that 1)
Bss∈Qκimplies A[us+u′
s]≤b, and 2)Bss∈Qκimplies c⊤[us+u′
s]≥κ.
1) Let us−ss=/summationtext
i∈Bs\Bssxiei∈Zn. Let u′
p=/summationtext
i∈[n]\Bpuiei∈Rn. For anyBs⊃Bss,Bs\Bss∈P. Also, we
can find u′
s=up−s+u′
p, such that
A[uss+us−ss+up−s+u′
p] =A[us+u′
s] =A[up+u′
p]≤b, (36)
sinceZn⊂Rn. Therefore, A[us+u′
s]≤b.
2) LetR(M)be the set of feasible solutions. Let ˆR(M)be the set of LP-feasible solution ˆu, after fixing the
nontrivial number of discrete variables of M. Let ¯R(M)be the set of LP-feasible solution ¯u, without fixing
variables of M. SinceR(M)⊆ˆR(M)⊆¯R(M),
min
¯u∈¯R(M)c⊤¯u≤min
ˆu∈ˆR(M)c⊤ˆu≤min
u∈R(M)c⊤u (37)
18Under review as submission to TMLR
Therefore, for any Bs,
c⊤[us+u′
s] =c⊤[uss+us−ss+u′
s]≥c⊤[uss+u′
ss]≥κ (38)
By 1) and 2), Bss∈QκimpliesBs∈Qκ. Hence,Qκis bounded monotone increasing, in which the bound
is at mostp0, such that q∈[0,p0]inS(n,q)forQκ.
Lemma A.10. IfPis nontrivial, then q0,κis monotonic increasing with regard to κ, bounded by p0.
Proof.Letx⋆be the vector of optimal solution variable values. Let ¯xbe the vector of LP-relaxation solution
variable values. By Lemma A.9 and Theorem A.7, Qκis bounded monotone increasing and has a local
threshold function q0,κ, whereκis fixed. We choose the constant ξ∈(0,1)as in Theorem A.5, such that
P(S(n,q0,κ)∈Qκ) =ξ. We choose p0as a bound ofQκas in Lemma A.9. Suppose κ1≤κ2, such that
c⊤¯x<κ1≤κ≤κ2<c⊤x⋆. If follows that
P(S(n,q0,κ)∈Qκ1)≥P(S(n,q0,κ)∈Qκ)≥P(S(n,q0,κ)∈Qκ2) (39)
Theorem A.11. Fixκ. Ifq0,κ≪p0, thenFκhas an interval of certainty, such that q0,κ≪ρ≪p0implies
P(S(n,ρ)∈Fκ)→1.
Proof.By Lemma A.8 and A.9, there exist p0andq0such that
P(S(n,ρ)∈P)→/braceleftigg
1ifρ≪p0
0ifρ≫p0
and
P(S(n,ρ)∈Qκ)→/braceleftigg
0ifρ≪q0,κ≪p0
1ifp0≫ρ≫q0,κ
Since
P(S(n,ρ)∈Fκ)≥P(S(n,ρ)∈P) +P(S(n,ρ)∈Qκ)−1 (40)
By equation (40),
q0,κ≪ρ≪p0implies P(S(n,ρ)∈Fκ)→1 (41)
Proposition A.12. Fixˆρϕandˆρprob
Φ. Ifˆρψ∼Uniform (0,1). then the optimal ˆρψinLthresholdisp0.
Proof.By Theorem A.5 and Lemma A.8, Phas a threshold function p0. Suppose there exist Hsamples.
Forˆρϕandˆρprob
Φfixed, the training of Lprobis to maximize
H/summationdisplay
i=1I(i)
S(n,ρ)∈Plog ˆρprob
Ψ+H/summationdisplay
i=1(1−I(i)
S(n,ρ)∈P) log(1−ˆρprob
Φ) (42)
For any (a,b)∈R2\(0,0), letZ:w→alog(w) +blog(1−w). Then arg maxZ(w) =a
a+b. Hence,
arg minLprob=1
HH/summationdisplay
i=1I(i)
S(n,ρ)∈P(43)
19Under review as submission to TMLR
forˆρprob
Φfixed. Similarly, the training of Lthresholdis to maximize
H/summationdisplay
i=1ˆρprob(i)
Ψ log ˆρψ+H/summationdisplay
i=1(1−ˆρprob(i)
Ψ ) log(1−ˆρψ) (44)
, where ˆρprob(i)
Ψcorresponds to ˆρprob
Ψati-th iteration for I(i)
S(n,ρ)∈P. Hence,
arg minLthreshold =1
HH/summationdisplay
i=1ˆρprob(i)
Ψ (45)
At the global minima of Lthreshold, andLprob,
ˆρprob
Ψ=1
HH/summationdisplay
i=1I(i)
S(n,ρ)∈P(46)
and
ˆρψ=1
HH/summationdisplay
i=1ˆρprob(i)
Ψ≈1
HH/summationdisplay
i=1I(i)
S(n,ρ)∈P, (47)
for large enough H. Letξ=P(S(n,ˆρψ)∈P) =1
HH/summationtext
i=1I(i)
S(n,ρ)∈P= arg minLprob. Choosep0=ξ.
Corollary A.13. Fixκ∗,ˆρψandˆρprob
Ψ. Ifˆρϕ∼Uniform (0,1). then the optimal ˆρϕinLthresholdisq0,κ∗.
We relax the result of Theorem A.11 for large enough n.
Remark A.14.q0,κ≲ρ≲p0implies P(S(n,ρ)∈Fκ)≥1−ϵ
Proof of Theorem 3.1. First, we prove the following statement: If the variable values in S(n,ρ)∈Fκ∗lead
to∆-optimal solution and ρ∗
∆= arg min
ρc⊤x(τ,ρ), thenq0,κ∗≲ρ∗
∆≲p0. To obtain a contradiction, suppose
ρ∗
∆= max(arg min
ρc⊤x(τ,ρ)). Suppose also ρ∗
∆≲q0,κ∗orρ∗
∆≳p0.
1)ρ∗
∆≳p0impliesS(n,ρ∗
∆)/∈Pwith high probability. This contradicts ρ∗
∆= max(arg min
ρc⊤x(τ,ρ)).
2)ρ∗
∆≲q0,κ∗impliesS(n,ρ∗
∆)/∈Qκ∗with high probability. Since q0,κ∗≲p0,S(n,ρ∗
∆)∈Pwith high
probability. There exists ρ′, such that S(n,ρ′)∈Qκ∗andc⊤x(τ,ρ′)≤c⊤x(τ,ρ∗
∆), andρ′> ρ∗
∆. This
contradicts ρ∗
∆= max(arg min
ρc⊤x(τ,ρ)).
By Proposition A.12,
arg min
ˆρψLthreshold =p0, for ˆρϕandˆρprob
Φfixed. (48)
By Corollary A.13,
arg min
ˆρϕLthreshold =q0,κ∗,forκ∗,ˆρψandˆρprob
Ψfixed. (49)
By Remark A.14 for large enough n,
q0,κ∗≲ρ≲p0implies P(S(n,ρ)∈Fκ∗)≥1−ϵ (50)
Thus,S(n,ρ∗
∆)∈Fκ∗with high probability, for ρ∗
∆∈[q0,κ∗,p0]. Therefore, we search ρ∗
∆∈[q0,κ∗,p0]at the
global optimum of Lthreshold, such that the cardinality of the search space becomes (p0−q0,κ∗)|A|.
20Under review as submission to TMLR
0 10 20 30 40 50 60
Time (s)725750775800825850875900Primal bound 
SCIP
ND
CF
TAL
GE
(a) Workload apportionment test dataset.
0 10 20 30 40 50 60
Time (s)200000300000400000500000600000700000Primal bound 
SCIP
ND
CF
TAL
GE(b)Maritimeinventoryrouting(non-augmented)test
dataset.
0 10 20 30 40 50 60
Time (s)300000400000500000600000700000Primal bound 
SCIP
ND
CF
TAL
GE
(c) Maritime inventory routing (augmented) test
dataset.
0 20 40 60 80 100
Time (ms)02004006008001000Primal bound 
SCIP
ND
CF
TAL(d) Set covering test dataset.
0 2 4 6 8
Time (s)18000200002200024000260002800030000Primal bound 
SCIP
ND
CF
TAL
(e) Capacitated facility flow test dataset.
0.0 0.5 1.0 1.5 2.0 2.5 3.0 3.5 4.0
Time (s)230
225
220
215
210
205
200
Primal bound 
SCIP
ND
CF
TAL (f) Maximum independent set test dataset.
Figure 4: Average primal bound as a function of running time. ND refers to Neural diving (Nair et al., 2020)
and GE refers to GNNExplainer (Ying et al., 2019).
A.5 Average Primal Bound over Time
Figure 4 shows the average primal bound curves for SCIP, ND, GNNExplainer, CF, and TaL. TaL shows
the best curves in all test datasets except for maximum independent set problems. In Figure 4e, the SCIP
curve is not shown as it is beyond the plotting range. In particular, TaL shows a substantially better curve
for maritime inventory routing problems in Figure 4c and 4b.
A.6 Algorithm Details
21Under review as submission to TMLR
Algorithm 2 ThresholdSolve
Input:M,x,ˆρψ,ˆρϕ,ˆρπ
1:¯x←SolveLP (M,x,0)
2:ˆx(ˆρπ)←SolveLP (M,x,ˆρπ)
3:x(τ,ˆρπ)←SolveMIP (M,x,ˆρπ,τ)
4:Ifeas
S(n,ˆρψ)←1ifS(n,ˆρψ)is feasible else 0
5:x(τ,ˆρψ)←SolveMIP (M,x,ˆρψ,τ)ifS(n,ˆρψ)is feasible else Null
6:x(τ,ˆρϕ)←SolveMIP (M,x,ˆρϕ,τ)ifS(n,ˆρϕ)is feasible else Null
7:κ←ˆρϕ·(c⊤x(τ,ˆρϕ)−c⊤¯x) +c⊤¯x
8:ILP-sat
S(n,ˆρπ)←1ifc⊤ˆx(ˆρπ)≥κelse0
9:ρ∗←arg min
ρ∈[ˆρψ,ˆρϕ]c⊤x(τ,ρ)ifS(n,min(ˆρψ,ˆρϕ))is feasible else Null
10:returnIfeas
S(n,ˆρψ),ILP-sat
S(n,ˆρπ),ρ∗
Algorithm 2 describes the ThresholdSolve procedure at line 8 in Algorithm 7. SolveLP (M,x,0)refers to
the process of solving LP-relaxation of Mto return the objective value of the solution. SolveLP (M,x,ˆρπ)
is the process of solving LP-relaxation of the sub-MIP of Mby fixing variables with coverage ˆρπand values
x. Since the objective term is unbounded, we set κ∈(c⊤¯x,c⊤x(τ,ˆρπ)), and adjust κtoκ∗.
A.7 Experiment Details
Training The base ND GNN models are trained on 4×NVIDIA Tesla V100-32GB GPUs in parallel. The
ND with SelectiveNet models are trained on 4×NVIDIA Tesla A100-80GB GPUs in parallel. The TaL
GNN models are trained on a single NVIDIA Tesla A100-80GB GPU. The training times for each dataset
and method are as follows. Note that the CPU load is higher than the GPU load in TaL. Also, the TaL
column in Table 3 refers to the post-training phase only. It is noticeable that the post-training session does
not exceed 2 hours for all datasets.
Table 3: Training times over the methods for each dataset
ND base ND w/ SelectiveNet TaL
Workload Apportionment ≈5mins ≈3hrs≈1 hr 10 mins
Maritime Inventory Routing (non-augmented) ≈30mins≈2hrs40mins≈10mins
Maritime Inventory Routing (augmented) ≈50hrs≈25mins≈1hr10mins
Set Covering ≈6hrs≈2hrs10mins≈1hr
Capacitated Facility Flow ≈5hrs30mins≈12hrs≈5mins
Maximum Independent Set ≈4hrs50mins≈1hr≈5mins
Evaluation We apply ML-based methods over presolved models from SCIP, potentially with problem
transformations. Throughout the experiments, we are using “aggressive heuristic emphasis” mode in SCIP,
where it tunes the parameters of SCIP to focus on finding feasible solutions.
Adjusting CF cutoff value In Figure 1b, there is a convex-like region between the confidence score 0.4
and 0.5. We manually find such region and conduct binary search over the region.
Dataset The workload apportionment dataset (Gasse et al., 2022) involves problems for distributing work-
loads, such as data streams, among the least number of workers possible, such as servers, while also ensuring
that the distribution can withstand any worker’s potential failure. Each specific problem is represented as a
MILP and employs a formulation of bin-packing with apportionment. The dataset comprises 10,000 training
instances, which have been separated into 9,900 training examples and 100 validation examples.
22Under review as submission to TMLR
The non-augmented maritime inventory routing dataset (Gasse et al., 2022; Papageorgiou et al., 2014)
consists of problems that are crucial in worldwide bulk shipping. The dataset consists of 118 instances for
training, which were split into 98 for training and 20 for validation. Augmented maritime inventory routing
dataset includes additional 599 easy to medium level problems from MIPLIB 2017 (Gleixner et al., 2021) on
top of the non-augmented maritime inventory routing training set.
The set covering instances (Balas & Ho, 1980; Gasse et al., 2019) are formulated as Balas & Ho (1980) and
includes 1,000 columns. The set covering training and testing instances contain 500 rows. The capacitated
facilitylocationproblems(Cornuéjolsetal.,1991;Gasseetal.,2019)aregeneratedasCornuéjolsetal.(1991),
and there are 100 facilities (columns). The capacitated facility location training and testing instances contain
100 customers (rows). The maximum independent set problems (Bergman et al., 2016; Gasse et al., 2019)
are created on Erdos-Rényi random graphs, formulated as Bergman et al. (2016), with an affinity set at 4.
The maximum independent set training and testing instances are composed of graphs with 500 nodes.
23