Published in Transactions on Machine Learning Research (04/2023)
Fast&Fair : Training Acceleration
and Bias Mitigation for GNNs
O. Deniz Kose okose@uci.edu
Department of Electrical Engineering and Computer Science
University of California Irvine
Yanning Shen˚yannings@uci.edu
Department of Electrical Engineering and Computer Science
University of California Irvine
Reviewed on OpenReview: https://openreview.net/forum?id=nOk4XEB7Ke
Abstract
Graph neural networks (GNNs) have been demonstrated to achieve state-of-the-art
performance for a number of graph-based learning tasks, which leads to a rise in their
employment in various domains. However, it has been shown that GNNs may inherit
and even amplify bias within training data, which leads to unfair results towards certain
sensitive groups. Meanwhile, training of GNNs introduces additional challenges, such as
slow convergence and possible instability. Faced with these limitations, this work proposes
FairNorm, a unified normalization-based framework that reduces the bias in GNN-based
learning while also providing provably faster convergence. Specifically, FairNorm presents
individual normalization operators over different sensitive groups and introduces fairness
regularizers on the learnable parameters of normalization layers to reduce the bias in
GNNs. The design of the proposed regularizers is built upon analyses that illuminate the
sources of bias in graph-based learning. Experiments on node classification over real-world
networks demonstrate the efficiency of the proposed scheme in improving fairness in terms of
statistical parity and equal opportunity compared to fairness-aware baselines. In addition,
it is empirically shown that the proposed framework leads to faster convergence compared
to the naive baseline where no normalization is employed.
1 Introduction
Graphs are powerful tools for modeling complex systems and the relations within them. Hence, they are
widely employed to represent various real-world systems, such as gene networks, traffic networks, and social
networks to name a few. Such expressiveness has led to rising attention towards learning over graphs, and it
has been shown that graph neural networks (GNNs) achieve the state-of-the-art for several tasks over graphs
(Gori et al., 2005; Scarselli et al., 2008; Hamilton et al., 2017a; Kipf & Welling, 2017; Veličković et al.,
2018; Xu et al., 2018b). GNNs create node representations by repeatedly aggregating information from the
neighbors, which can be employed on ensuing tasks such as traffic forecasting (Opolka et al., 2019), crime
forecasting (Jin et al., 2020), and recommender systems (Ying et al., 2018).
Machine learning (ML) models have been widely used in various domains to make critical decisions.
Therefore, it is essential to prevent discriminatory behavior in these models towards under-represented
groups. However, it has been demonstrated that ML models propagate the potential bias within the training
data (Dwork et al., 2012; Beutel et al., 2017) and lead to discriminatory results in ensuing applications.
Particular to GNNs, it has been shown that in addition to propagating the already existing bias, GNN-based
˚Corresponding author.
1Published in Transactions on Machine Learning Research (04/2023)
learning may even amplify it due to the utilization of biased graph topologies (Dai & Wang, 2021). This
well-motivates the studies in fairness-aware GNN-based learning.
Normalization operations shift and scale the hidden representations created in deep neural networks (DNNs)
in order to accelerate the optimization process in training (Ioffe & Szegedy, 2015; Ulyanov et al., 2016; Ba
etal.,2016;Salimans&Kingma,2016;Xiongetal.,2020;Miyatoetal.,2018;Wu&He,2018;Santurkaretal.,
2018). While the other aspects of GNN-based learning are theoretically investigated, such as generalization
(Scarselli et al., 2018; Xu et al., 2019b) and expressiveness (Xu et al., 2018a; Loukas, 2020; Ying et al., 2021),
the optimization of GNNs is analytically an under-explored area. Practically, training GNNs generally has
a slow convergence rate and is accompanied by instability issues (Xu et al., 2018a). Inspired by this, Cai
et al. (2021) investigates the effect of a shift operation on a simple GNN-based learning environment and
proposes a normalization framework that is suitable for GNNs. The proposed framework in Cai et al. (2021),
GraphNorm, is demonstrated to be more effective in improving convergence speed over graphs compared to
previously presented normalization strategies in other domains.
It has been shown in Balunovic et al. (2021) that the distributional discrepancy between the representations
among different sensitive groups is one of the leading factors to bias in general ML algorithms. For GNNs,
fairness analyses have also shown that the distributions of the representations of different sensitive groups are
key factors that affect the resulting bias (Li et al., 2020; Kose & Shen, 2022). Note that normalization layers
learn the parameters that manage the sample mean and variance of these hidden representations. Hence,
the normalization can be readily applied to manipulate the related statistics to reduce the bias, while also
improving the convergence. Motivated by this, this study proposes a unified GNN-based learning framework,
FairNorm, that provides a faster convergence through the employment of a normalization layer, while also
mitigating the bias with novel fairness-aware regularizers on the learnable parameters in the introduced
normalization layer. Overall, the contributions of the present work can be summarized as follows:
c1)We propose a framework that can reduce bias while providing a higher convergence speed for a GNN-
based learning environment. To the best of our knowledge, FairNorm is the first attempt to improve fairness
and convergence speed in a unified framework.
c2)The effect of the proposed shift operations on convergence rate is investigated in a simple GNN-based
learning framework. It is analytically shown that the proposed shift operations can improve the convergence
rate for node classification compared to the case where no shift is employed.
c3)Fairness-aware regularizers are introduced on the trainable parameters of the normalization layers. The
design of the regularizers is based on theoretical understanding regarding the sources of bias in GNNs.
c4)Empirical results are obtained over real-world networks in terms of utility and fairness metrics for
node classification. It is demonstrated that compared to fairness-aware baselines, FairNorm leads to an
improvement in fairness metrics while providing comparable utility. Meanwhile, it is empirically shown that
FairNorm enhances the convergence speed with respect to the no-normalization baseline.
2 Related Work
Fairness-aware learning over graphs: Rahman et al. (2019) serves as a seminal work for random walk-
based fairness-aware learning over graphs. In addition, Dai & Wang (2021); Bose & Hamilton (2019); Fisher
et al. (2020) propose to use adversarial regularizors to reduce bias in GNNs. Another approach is to utilize
a Bayesian approach where the sensitive information is modeled in the prior distribution to enhance fairness
over graphs (Buyl & De Bie, 2020). Furthermore, Ma et al. (2021) performs a PAC-Bayesian analysis and
links the notion of subgroup generalization to accuracy disparity, and Zeng et al. (2021) proposes several
strategies including GNN-based ones to reduce bias for the representations of heterogeneous information
networks. Specifically for fairness-aware link prediction, while Buyl & De Bie (2021) introduces a regularizer,
Li et al. (2020); Laclau et al. (2021) propose strategies that alter the adjacency matrix. With a specific
consideration of individual fairness over graphs, Dong et al. (2021b) proposes a ranking-based framework.
Another research direction in fairness-aware graph-based learning is to modify the graph structure to combat
bias resulted from the graph connectivity (Agarwal et al., 2021; Spinelli et al., 2021; Kose & Shen, 2022;
Köse & Shen, 2021). Differing from all previous works, the proposed framework herein proposes a unified
framework that can mitigate bias in GNN-based learning together with an enhanced convergence speed.
2Published in Transactions on Machine Learning Research (04/2023)
Normalization: Batch Normalization (BatchNorm) (Ioffe & Szegedy, 2015) is the pioneering study that
proposes to shift and scale the hidden representations in a batch to accelerate the convergence of training
for DNNs. Following that, several normalization strategies are presented so far for different domains (Huang
et al., 2020; Ioffe & Szegedy, 2015; Ulyanov et al., 2016; Ba et al., 2016; Salimans & Kingma, 2016; Xiong
et al., 2020; Miyato et al., 2018; Wu & He, 2018; Santurkar et al., 2018; Xu et al., 2019a; Dong et al.,
2021a; Huang et al., 2022). Specifically, LayerNorm is presented for natural language processing (Ba et al.,
2016), and InstanceNorm (Ulyanov et al., 2016) seeks to improve the optimization for style transfer tasks,
while Yi et al. (2018); Sun et al. (2020) target at permutation-equivalent data processing. Moreover, Chang
et al. (2019) presents a domain-specific normalization technique for unsupervised domain adaptation, and
Liu et al. (2020); Yu et al. (2020) provide normalization-based solutions for adversarial robustness and image
inpainting, respectively.
For GNNs, Xu et al. (2018a) adapts BatchNorm within the framework of graph isomorphism networks, while
a prior version of Dwivedi et al. (2020) normalizes node features based on the graph size. By taking the
graph structure into account, Chen et al. (2022) proposes two novel normalization techniques, as well as an
attention mechanism that learns a weighted combination of multiple graph-aware normalization strategies.
A size-agnostic normalization for graphs, GraphNorm is proposed in (Cai et al., 2021), which improves
InstanceNorm for graphs with a learnable shift to prevent degradation in expressiveness. Normalization
frameworks are also utilized to combat the over-smoothing issue over GNNs, where Zhou et al. (2020) applies
the normalization independently over clusters that are defined with respect to the class labels, and Zhao &
Akoglu (2020) normalizes the total pairwise feature distances. It is important to note that the cluster-wise
normalization introduced in Zhou et al. (2020) aims to improve the discrimination of the representations
from different classes. However, the cluster definition therein differ significantly from the present work.
Furthermore, none of the aforementioned normalization schemes consider fairness.
3 Preliminaries
This study develops a unified training scheme for GNNs that can improve fairness while at the same time
enhance the convergence speed, given an input graph G:“pV,Eq, where V:“tv1,v2,¨¨¨,vNudenotes the
node set, and EĎVˆVis the edge set. Matrices XPRFˆNandAP t0,1uNˆNare the feature and
adjacency matrices, respectively, where Aij“1if and only ifpvi,vjqPEandFis the dimension of features.
Degree matrix DPRNˆNis defined to be a diagonal matrix with the nth diagonal entry denoting the
degree of node vn. In this study, the sensitive attributes of the nodes are denoted by sP t0,1uN, where
the existence of a single, binary sensitive attribute is considered. Furthermore, S0andS1denote the set of
nodes whose sensitive attributes are 0and1, respectively. Node representations at kth layer are represented
byHpkqPRFˆN, where hjdenotes the representation of node vjandhi,jis theith feature of hj. Vectors
xjPRFandsjP t0,1uwill be used to denote the feature vector and the sensitive attribute of node vj.
Throughout the paper, maxp¨,...,¨qoutputs the element-wise maximum vector of its argument vectors, and
meanp¨,...,¨qdenotes the sample mean operator.
GNNs learn node embeddings by repeatedly aggregating information from neighboring nodes. GNNs with
different aggregation schemes have been developed, see in (Kipf & Welling, 2017; Veličković et al., 2018; Xu
et al., 2018a). A general formulation of GNNs in the matrix form can be written as:
Hpkq“Act´
WpkqHpk´1qQ¯
where Wpkqrepresents the weight matrix of GNN at kth layer and Actdenotes activation function. In
this formulation, Qmatrix specifies the information aggregation process from neighbors, which changes in
different GNN frameworks. For example, Q“ˆD´1
2ˆAˆD´1
2for Graph Convolutional Networks (GCN) (Kipf
& Welling, 2017), where ˆA“A`INwithINPt0,1uNˆNdenoting the identity matrix, and ˆDis the degree
matrix corresponding to ˆA. Finally, the representations created after one aggregation process are denoted
byZpkq“Hpk´1qQ. Note that the superscript pkqfor layer number is dropped in the remaining of the paper,
as the proposed framework is applicable to every layer in the same way.
3.1 Normalization for GNNs
3Published in Transactions on Machine Learning Research (04/2023)
While different normalization schemes have been proposed for different domains, there is not a universal
normalization strategy that suits every domain (Cai et al., 2021). For GNNs, Cai et al. (2021) demonstrates
thatmeannormalizationcandegradetheexpressivenessoftheneuralnetworks, asmeanstatisticsincorporate
graph structural information. Motivated by this, Cai et al. (2021) proposes GraphNorm, which employs a
learnable shift to preserve the mean statistics to a certain extent. The study reports that GraphNorm
consistently achieves superior convergence speed and training stability on graph classification for GNNs
over other normalization strategies. For the input matrix APRFˆN, GraphNorm can be mathematically
described as:
GraphNormpai,jq“γi¨Ai,j´αi¨mi
ˆσi`βi,@i“1,...F (1)
wheremi“řN
j“1ai,j
N,ˆσ2
i“řN
j“1pai,j´αi¨miq2
N, andαi,γi,βiare the learnable parameters.
3.2 Bias in GNNs
ML models can lead to discriminatory results towards certain under-represented groups, as they propagate
the bias within the training data (Dwork et al., 2012; Beutel et al., 2017). It has been demonstrated that
the utilization of graph structure in GNNs amplifies the already existing bias (Dai & Wang, 2021). Thus,
understanding the sources of bias in graph structure is crucial to develop a remedy for it. Motivated by
this, Li et al. (2020) and Kose & Shen (2022) investigate the sources of bias in GNN-based learning. In Li
et al. (2020), the representation discrepancy between different sensitive groups is examined, whereas in Kose
& Shen (2022), the bias analysis is based on the correlation between the aggregated representations Zand
sensitive attributes s. Though through different approaches, both analyses in Li et al. (2020, Theorem 4.1)
and Kose & Shen (2022, Theorem 3.1) demonstrate the parallelism between the terms }µp0q´µp1q},}∆}and
bias in GNN-based learning. Here, µp0qandµp1qare the sample means of node representations respectively
across each sensitive group, where µpnq“meanphj|vjPSnq, and ∆stands for the maximal deviations
of hidden representations, that is ∆pnq
i“maxj|hpnq
i,j´µpnq
i|,@i“1,¨¨¨,Fand∆“maxp∆p0q,∆p1qq. The
superscriptpnqinhpnq
jis utilized to specify the sensitive group index. Specifically, the hidden representation
hpnq
jcorresponds to a node vjPSn.
AstheanalysesinLietal.(2020);Kose&Shen(2022)suggestthatthedistributionsofhiddenrepresentations
corresponding to different sensitive groups influence the resulted bias by GNNs, a tool that can shift these
group-wise distributions can effectively decrease bias-related terms, and hence the overall bias.
4 FairNorm: A Fair and Fast Training Framework for GNNs
This section presents the proposed unified framework that achieves fairness improvement together with faster
convergence speed for GNN-based learning. Herein, we first present a group-wise normalization framework
(M-Norm), upon which we develop FairNorm by incorporating two novel fairness regularizers on M-norm for
fairness-enhancement.
4.1 Group-wise Normalization
It has been demonstrated in Li et al. (2020); Kose & Shen (2022) that decreasing }µp0q´µp1q}and∆can
effectively reduce bias in GNN-based learning. Note that both terms are affected by the distributions of
representations from different sensitive groups. On the other hand, the mean and standard deviation of
the hidden representations, and in turn their distributions, are affected by the learnable parameters of a
normalization layer. Thus, employing such a layer can enable manipulating said distributions, which can be
used to improve fairness. Inspired by this, the proposed framework, FairNorm, first applies normalizations
to different sensitive groups individually, which results in individual learnable parameters affecting µp0q, and
µp1q, as well as their difference. For any input matrix APRFˆN, given that the columns of Acan be divided
into two sensitive groups S0andS1, the corresponding multiple group-wise normalization operations can
4Published in Transactions on Machine Learning Research (04/2023)
be mathematically described as:
M-Norm´
apnq
i,j¯
“γpnq
i¨Apnq
i,j´αpnq
i¨mpnq
i
σpnq
i`βpnq
i, (2)
wherempnq
i“ř|Sn|
j“1apnq
i,j
|Sn|,pσpnq
iq2“ř|Sn|
j“1´
apnq
i,j´mpnq
i¯2
|Sn|, andαpnq
i,γpnq
i,βpnq
iare learnable parameters, @i“
1,...,Fandn“0,1. The superscript pnqinApnq
jspecifies that the representation corresponds to a node
from the sensitive group Sn. Considering that mean normalization can degrade the expressiveness of GNNs
(Cai et al., 2021), the proposed framework employs the learnable parameter αthat manages the amount of
mean normalization.
It is demonstrated in Cai et al. (2021) that applying a shift operation over the whole graph can speed up
the convergence for graph classification. However, as the proposed framework herein applies multiple shift
operations individually over subgraphs corresponding to different sensitive groups and considers the node
classification task, the effect of the proposed strategy on the convergence speed becomes unclear. Hence, the
analysis in Cai et al. (2021) cannot be directly applied to this case. Motivated by this, this study analytically
examines the influence of group-wise shifts on the convergence speed.
Shift operations over different sensitive groups can be applied in matrix forms via the matrices Np0qandNp1q,
where Npnq“IN´1
|Sn|epnqpepnqqJforn“0,1. In this formulation, epnqPRNis created such that epnq
j“1if
vjPSn, andepnq
j“0otherwise. Therefore, for any vector cPRN,cJNpnq“cJ´p1
|Sn|ř
j:vjPSncjqpepnqqJ.
Hence, the group-wise shift operations applied to hidden representations can be written as:
MShiftpWpkqHpk´1qQq“WpkqHpk´1qQNp0qNp1q. (3)
The following lemma demonstrates that Np0qNp1qacts as a preconditioner of Q, whose proof is presented in
Appendix A.
Lemma 1 Letλiandσidenote theith singular values of QandQNp0qNp1q, respectively. It can be shown
thatQNp0qNp1qhas at least two singular values being equal to zero, i.e., γN“γN´1“0. Without loss of
generalization, assume 0ďλ1ď¨¨¨ďλNand0ďγ1ďγ2ď¨¨¨ďγN´2. Then, the following holds:
λ1ďγ1
λ2ďγ2
...
λN´2ďγN´2ďλN, (4)
where the equalities hold, i.e., λi“γiorλN“γN´2, only if Qhas a right singular vector αfor which
pep0qqJα“0andpep1qqJα“0are satisfied.
In other domains, such as DNNs or iterative algorithms, a similar preconditioning is considered to help
the training (Kingma & Ba, 2014; Axelsson, 1985). Such a preconditioning of the aggregation matrix Q
is also demonstrated to accelerate the optimization of GNNs (Cai et al., 2021). In order to theoretically
investigate such an effect in our setting, we considered a basic linear GNN model for node classification that
is optimized via gradient descent, and presented its convergence analysis in Theorem 1. Appendix B presents
all assumptions and considered learning settings employed in Theorem 1 in detail, as well as its proof.
Theorem 1 LetwVanilla
tandwMShift
tdenote the parameters of a linear GNN model at time tfor the cases
where no shift is applied and shift operations Np0qNp1qare applied, respectively. It holds with high probability
that›››wMShift
t´wMShift
˚›››
2“O`
ρt
1˘
and››wVanilla
t´wVanilla
˚››
2“O`
ρt
2˘
,whereρ1ăρ2.(5)
Here, wVanilla
˚andwMShift
˚denote the optimal values for wVanilla
tandwMShift
t, respectively. Thus, it
concludes that the shift operations applied through Np0qNp1qlead to faster convergence with high probability
compared to the scheme where no shift is applied.
5Published in Transactions on Machine Learning Research (04/2023)
Theorem 1 demonstrates that the individual shift operations applied over different sensitive groups indeed
improve the convergence rate compared to the naive baseline. While the result of Theorem 1 seems to be
similar to the result of Cai et al. (2021, Proposition 3.1), the analysis in Cai et al. (2021) cannot be easily
extended to our proof due to the employment of group-wise shifts in this work and the fact that we consider
node classification instead of graph classification.
4.2 Fairness-aware Regularizers
As a complementary step to M-Norm, FairNorm introduces two novel fairness-aware regularizers to mitigate
bias in GNN-based learning. Consider the conventional case where the normalization is applied after linear
transformations (Ioffe & Szegedy, 2015; Xiong et al., 2020; Cai et al., 2021). For this case, the hidden
representations can be expressed in matrix form as:
Hpnq“Act´
M-Normpnq´
pWHQqpnq¯¯
,forn“0,1. (6)
In equation 6, pWHQqpnqdenotes the submatrix consisting the columns of pWHQqwhose corresponding
nodes are in Sn. Furthermore, as the proposed strategy applies normalizations individually over different
sensitive groups, these group-wise normalization layers are differentiated by the superscript n“0,1. Let
¯µpnqPRFdenote the sample mean of representations after normalization for the sensitive group Sn,n“0,1.
In the proposed framework, recalling from Subsection 4.1, individual normalization layers are employed
to create individual learnable parameters for the distributions of different sensitive groups, so that the
bias-related terms derived in Li et al. (2020); Kose & Shen (2022) can be reduced. However, in order to
manipulate ¯µp0qand¯µp1qfor possible bias reduction, the relationship between }µp0q´µp1q}and¯µpnq’s should
be investigated. To this end, we present the following theorem, the proof of which can be found in Appendix
C.
Theorem 2 LetActp.qbe Lipschitz continuous with Lipschitz constant L, and let ¯Hpnqdenote the normalized
representations in group Sn. Then,}µp0q´µp1q}is bounded above by
}µp0q´µp1q}pďL´
}¯µp0q´¯µp1q}p`}¯∆p0q}p`}¯∆p1q}p¯
,@pě1. (7)
Here, ¯∆pnqis the maximal deviation of ¯Hpnqfrom ¯µpnq(i.e.,we have ¯∆pnq
i“maxj|¯hpnq
i,j´¯µpnq
i|,@i“
1,¨¨¨,F).
Theorem 2 demonstrates that decreasing }¯µp0q´¯µp1q}results in a decreased upper bound for }µp0q´µp1q},
which can possibly reduce the actual value of }µp0q´µp1q}. Based on this result, as a second step after
applying group-wise normalization operators, FairNorm proposes the use of a regularizer term Lµ“}¯µp0q´
¯µp1q}2
2to decrease bias for GNN-based learning. We note that many commonly used activation functions
such as ReLU, sigmoid, tanh, etc.have a Lipschitz constant equal to L“1.
Furthermore, Theorem 2 shows that the upper bound for }µp0q´µp1q}can also be decreased by reducing
the norms of maximal deviations ¯∆p0qand ¯∆p1q. Inspired by this finding, L∆“}¯∆p0q}2
2`}¯∆p1q}2
2is also
introduced as a regularizer to reduce the norms of maximal deviations of the normalized representations.
Hence, the overall learning objective for the considered node classification task can be written as:
min
θGNNLc`κLµ`τL∆ (8)
where Lcis the classification loss, Lµ“ } ¯µp0q´¯µp1q}2
2“ }´
γp0qmp0qp1´αp0qq
σp0q`βp0q¯
´´
γp1qmp1qp1´αp1qq
σp1q`βp1q¯
}2
2for M-Norm in equation 2. L∆“ } ¯∆p0q}2
2` }¯∆p1q}2
2, and ¯∆pnq
i“
γpnq
i
σpnq
imaxj|rpnq
i,j´mpnq
i|for M-Norm defined in equation 2 @i“1,¨¨¨,F, where Rpnq“ pWHQqpnq
denotes the representations input to the normalization layer and rpnq
i,jis the element in ith row and jth
column of Rpnqmatrix. GNN parameters are denoted by θGNN, andκandτare hyperparameters specifying
6Published in Transactions on Machine Learning Research (04/2023)
the focus on the fairness regularizers.
Remark 1 (Order of normalization and activation). Although the proposed fairness regularizers
Lµ,L∆are designed for the conventional case where the normalization is used before nonlinear activation,
it can be demonstrated that they can also reduce bias when the normalization is applied after activation,
where
Hpnq“M-Normpnq´
Act´
pWHQqpnq¯¯
,forn“0,1. (9)
In this case, it holds that ¯µpnq“µpnqand}¯∆pnq}“}∆pnq}forn“0,1. Therefore, the employment of the
proposed fairness regularizers can naturally be extended to the case where the normalization is utilized after
activation, as the analyses in Li et al. (2020); Kose & Shen (2022) demonstrate that reducing }µp0q´µp1q}
and}∆}can help mitigate bias in GNN-based learning.
Remark 2 (Applicability to other normalization methods). Note that the proposed FairNorm
framework can be readily utilized together with other normalization techniques where the distribution of the
normalized representations depends on learnable parameters, e.g., BatchNorm (Ioffe & Szegedy, 2015), as
long as group-wise normalization is applied over each sensitive group.
Table 1: Dataset statistics
Dataset|S0| |S1|Inter-edges Intra-edges F
Pokec-z 4851 2808 1140 28336 59
Pokec-n 4040 2145 943 20901 59
Recidivism 9317 9559 298098 325642 17
5 Experiments
In this section, experimental results obtained on real-world datasets for a supervised node classification task
are presented. The performance of the proposed framework, FairNorm, is compared with baseline schemes
in terms of node classification accuracy and fairness metrics. Furthermore, the influence of the proposed
fairness-aware normalization strategy on convergence speed is examined.
5.1 Datasets and Settings
Datasets. In the experiments, three real-world networks are used: Pokec-z, Pokec-n (Dai & Wang, 2021),
and the Recidivism graph (Jordan & Freiburger, 2015). Pokec-z and Pokec-n are created by sampling the
anonymized, 2012 version of Pokec (Takac & Zabovsky, 2012), which is a social network used in Slovakia
(Dai & Wang, 2021). In Pokec networks, the region information is utilized as the sensitive attribute, where
the nodes are the users living in two major regions. Labels to be used in node classification are assigned
to be the binarized working field of the users. The information of defendants (corresponding to nodes) who
got released on bail at the U.S. state courts during 1990-2009 (Jordan & Freiburger, 2015) is utilized to
build the Recidivism graph, where the edges are formed based on the similarity of past criminal records
and demographics. Race is used as the sensitive attribute for this graph, and the node classification task
classifies defendants into bail (i.e., the defendant is not likely to commit a violent crime if released) or no bail
(i.e., the defendant is likely to commit a violent crime if released) (Agarwal et al., 2021). Table 1 presents
further statistical information on the utilized datasets. In the table, |S0|and|S1|are the cardinalities of the
sets of nodes with sensitive attributes 0and1, respectively. ’Inter-edges’ and ’Intra-edges’ correspond to the
number of edges linking nodes from different sensitive groups and the same sensitive group, respectively. F
in Table 1 denotes the dimension of nodal features.
Evaluation Metrics. Accuracy is used as the utility measure for node classification. Two quantitative
measures of group fairness metrics are reported in terms of statistical parity :∆SP“ |Ppˆy“1|s“
0q´Ppˆy“1|s“1q|andequal opportunity :∆EO“|Ppˆy“1|y“1,s“0q´Ppˆy“1|y“1,s“1q|,
whereyis the ground truth label, and ˆydenotes the predicted label. Lower values for ∆SPand∆EOsignify
better fairness performance (Dai & Wang, 2021).
7Published in Transactions on Machine Learning Research (04/2023)
Implementation details. To comparatively evaluate our proposed framework, node classification is
utilized in a supervised setting. A two-layer GCN (Kipf & Welling, 2017) followed by a linear layer is
employed for the classification task, which is identical to the experimental setting used in Dai & Wang
(2021). A normalization layer follows after every GNN layer, where the normalization is applied after linear
transformationsandbeforethenon-linearactivation, assuggestedinIoffe&Szegedy(2015);Caietal.(2021).
For the hyperparameter selection of the GCN model, see Appendix D. This experimental framework is kept
the same for all baselines. Furthermore, training of the model is executed over 50%of the nodes, while the
remaining nodes are equally divided to be used as the validation and test sets. For each experiment, results
for five random data splits are obtained, and the average of them together with standard deviations are
presented. The hyperparameters of the proposed fairness-aware framework and all other baselines are tuned
via a grid search on cross-validation sets, see again Appendix D for the utilized hyperparameter values.
Baselines. This work aims to mitigate bias via employing fairness-aware regularizers, as well as to provide
a faster convergence through its utilized normalization layers. We note that similar to the proposed
regularizers, any other fairness-aware regularizer can be employed together with a normalization layer, for
these same purposes. In order to demonstrate the performance improvement of the proposed regularizers
over said alternatives, we compare the proposed framework with other fairness-aware regularizers. To
this end, the performance of 4different baselines is presented. For improving fairness in a supervised
setting, FairGNN (Dai & Wang, 2021) employs adversarial debiasing and a covariance-based regularizer
(the absolute covariance between the sensitive attribute and estimated label ˆy). The results for these
regularizers are obtained both individually and together, where the framework that utilizes both regularizers
is called FairGNN (Dai & Wang, 2021). Furthermore, hyperbolic tangent relaxation of the difference of
demographic parity ( HTRDDP) that is proposed in Padh et al. (2021) is utilized as another baseline. Note
that, as DDP is not differentiable, its relaxations are used as fairness-aware regularizers for a gradient-based
optimization. It is worth emphasizing that the fairness regularizers proposed in this study are also applicable
to an unsupervised setting, while the covariance-based (also FairGNN) and HTRDDPregularizers can only
be used in a supervised framework.
5.2 Experimental Results
0 200 400 600 800 1000
Epochs0.50.60.70.80.91.0Training Accuracy NoNorm
GraphNorm
FairNorm
(a) Pokec-n (ReLU)
0 200 400 600 800 1000
Epochs0.50.60.70.80.91.0Training Accuracy NoNorm
GraphNorm
FairNorm (b) Pokec-z (ReLU)
0 200 400 600 800 1000
Epochs0.50.60.70.80.91.0Training Accuracy NoNorm
GraphNorm
FairNorm (c) Recidivism (ReLU)
0 200 400 600 800 1000
Epochs0.50.60.70.80.91.0Training Accuracy NoNorm
GraphNorm
FairNorm
(d) Pokec-n (Sigmoid)
0 200 400 600 800 1000
Epochs0.50.60.70.80.91.0Training Accuracy NoNorm
GraphNorm
FairNorm (e) Pokec-z (Sigmoid)
0 200 400 600 800 1000
Epochs0.40.50.60.70.80.9Training Accuracy NoNorm
GraphNorm
FairNorm (f) Recidivism (Sigmoid)
Figure 1: Convergence for different graph data sets when the normalization is not applied (Nonorm) and
applied with/without fairness consideration (FairNorm/GraphNorm).
The results of node classification are presented in Table 2 in terms of fairness and utility metrics for both the
proposed framework and baselines. The results are obtained for two commonly utilized activation functions:
ReLU and sigmoid, in order to demonstrate the efficacy of the proposed framework over different activations.
In Table 2, “NoNorm” denotes the scheme where no normalization layer is employed. “M-Norm” stands for
the proposed framework where only individual normalizations are applied to the nodes belonging to different
8Published in Transactions on Machine Learning Research (04/2023)
Table 2: Comparative Results with Baselines for Different Activation Function Selections
ReLU Sigmoid
Pokec-z Acc ( %) ∆SP(%) ∆EO(%) Acc ( %) ∆SP(%) ∆EOp%q
NoNorm 70.24˘1.0 6.77˘1.8 6.18˘2.570.25˘0.8 7.40˘1.8 6.04˘3.1
M-Norm 70.71˘0.8 5.57˘1.3 5.00˘2.0 69.84˘0.7 6.21˘1.4 4.44˘2.1
Covariance 70.66˘0.8 5.31˘1.4 4.56˘1.9 69.77˘0.6 5.63˘1.9 4.04˘2.1
Adversarial 70.35˘0.9 2.41˘1.0 2.16˘0.6 70.01˘0.9 3.08˘2.8 3.00˘2.4
FairGNN 70.34˘1.1 2.78˘1.5 2.73˘1.0 69.93˘0.7 4.55˘2.2 4.71˘2.7
HTRDDP 70.38˘0.9 2.12˘2.0 3.38˘1.5 69.74˘0.7 1.85˘1.1 2.27˘1.8
FairNorm 70.67˘1.01.35˘1.21.90˘1.8 69.73˘0.91.71˘0.31.48˘1.1
Pokec-n Acc ( %) ∆SP(%) ∆EO(%) Acc ( %) ∆SP(%) ∆EOp%q
NoNorm 69.29˘0.8 1.66˘1.6 2.19˘1.8 68.73˘0.6 2.68˘2.2 2.27˘2.4
M-Norm 69.25˘0.5 2.48˘1.2 2.91˘1.7 68.59˘0.9 1.78˘2.1 2.88˘1.8
Covariance 69.47˘0.6 2.06˘1.3 2.42˘1.5 68.40˘1.1 1.70˘2.2 2.26˘1.8
Adversarial 69.30˘0.4 2.09˘1.9 2.21˘1.9 68.47˘0.7 1.56˘1.8 2.25˘1.5
FairGNN 69.21˘0.4 2.03˘1.9 2.29˘2.1 68.42˘0.7 1.61˘1.71.71˘2.0
HTRDDP 69.51˘0.5 1.85˘1.4 2.03˘1.5 68.37˘0.9 1.64˘1.6 2.53˘1.7
FairNorm 69.38˘0.71.26˘1.21.22˘1.368.88˘1.11.44˘1.21.74˘1.7
Recidivism Acc ( %) ∆SP(%) ∆EO(%) Acc ( %) ∆SP(%) ∆EOp%q
NoNorm 94.32˘0.2 8.89˘0.7 1.17˘0.9 92.69˘0.2 8.29˘0.7 1.31˘0.6
M-Norm 95.00˘0.3 8.87˘1.2 1.71˘0.794.45˘0.3 8.94˘1.2 2.06˘1.0
Covariance 95.07˘0.2 8.82˘1.1 1.43˘0.6 92.87˘1.0 8.44˘0.6 1.64˘1.0
Adversarial 94.14˘0.1 8.58˘1.0 1.26˘0.7 93.82˘0.2 8.72˘0.9 1.59˘1.1
FairGNN 95.14˘0.2 8.73˘1.0 1.33˘0.8 94.11˘0.2 8.68˘1.2 1.51˘0.5
HTRDDP 95.16˘0.2 8.74˘0.8 1.05˘0.4 93.34˘0.4 8.20˘0.9 1.04˘1.0
FairNorm 95.11˘0.28.45˘1.00.90˘0.5 94.32˘0.27.28˘1.10.80˘0.9
sensitive groups, without using the proposed fairness regularizers. Furthermore, “Covariance” is for the
covariance-based regularizer (Dai & Wang, 2021), “Adversarial” stands for the adversarial regularizer (Dai &
Wang, 2021), and “ HTRDDP” denotes hyperbolic tangent relaxation of the difference of demographic parity
(Padh et al., 2021). It should be noted that the results for baselines are obtained with the best performing
normalization layer framework (individual normalizations over different sensitive groups vs. normalization
over all nodes in the graph) in terms of fairness measures.
The results in Table 2 demonstrate that FairNorm achieves superior fairness performance, together with
similar utility, compared to all baselines on all datasets for both of the utilized activations. As M-Norm is
the first step of FairNorm without fairness regularizers, the significant improvements in all fairness measures
compared to M-Norm signify the efficiency of the designed regularizers. Furthermore, on the Recidivism
graph with sigmoid activation, while the improvement in fairness metrics is accompanied by a decrease
in accuracy for the baselines, FairNorm achieves better fairness performance without a deterioration in
utility. Overall, the results in Table 2 show the efficacy of the proposed fairness regularizers in reducing
bias while providing similar utility on different real-world networks. Note that, in addition to their superior
fairness performance, the proposed regularizers of FairNorm can be flexibly applied to both supervised
and unsupervised settings, whereas some of the baselines (“Covariance”, “FairGNN”, “ HTRDDP”) require
predicted labels for their regularizer designs.
The proposed framework herein aims to mitigate bias by also providing a faster convergence speed. The
results in Table 2 confirm that the proposed fairness regularizers within FairNorm do provide said bias
reduction. In order to evaluate the convergence speed of FairNorm’s group-wise normalizations, Figure 1
is presented. The baselines in Figure 1 consist of GraphNorm (Cai et al., 2021), and the framework where
no normalization is applied. We note that in Figure 1, Fairnorm is employed with both its individual
normalizations as well as its fairness regularizers.
The results on both Pokec datasets and the Recidivism network confirm that the employed normalization
can indeed lead to a faster convergence in training compared to NoNorm. Figure 1 also demonstrates that
compared to GraphNorm, the convergence improvement of FairNorm is slightly less on Pokec-z, whereas it
provides approximately the same improvement on Pokec-n and Recidivism.
9Published in Transactions on Machine Learning Research (04/2023)
5.3 Sensitivity Analysis
Table 3: Sensitivity Analysis for Pokec Networks
Pokec-z Pokec-n
ReLU Acc ( %) ∆SP(%) ∆EO(%) Acc ( %) ∆SP(%) ∆EOp%q
M-Norm 70.71˘0.8 5.57˘1.3 5.00˘2.0 69.25˘0.5 2.48˘1.2 2.91˘1.7
τ“10´8,κ“10 70.26˘0.9 1.52˘1.0 2.19˘1.2 69.45˘0.6 2.23˘1.3 2.65˘1.6
τ“10´8,κ“100 70.48˘0.9 1.40˘1.0 2.20˘1.2 69.53˘0.8 2.07˘1.0 1.98˘0.8
τ“10´8,κ“1000 70.37˘1.1 3.20˘0.9 3.18˘2.0 69.38˘0.81.55˘1.41.48˘1.7
κ“100,τ“10´770.67˘1.01.35˘1.21.90˘1.869.56˘0.8 2.10˘0.9 2.09˘0.5
κ“100,τ“10´870.48˘0.9 1.40˘1.0 2.20˘1.7 69.53˘0.8 2.07˘1.0 1.98˘0.8
κ“100,τ“10´970.55˘0.9 1.48˘1.2 1.99˘1.8 69.54˘0.7 2.15˘1.1 1.84˘0.9
Pokec-z Pokec-n
Sigmoid Acc ( %) ∆SP(%) ∆EO(%) Acc ( %) ∆SP(%) ∆EOp%q
M-Norm 69.84˘0.7 6.21˘1.4 4.44˘2.1 68.59˘0.9 1.78˘2.1 2.88˘1.8
τ“10´8,κ“10 69.71˘0.9 1.36˘0.41.72˘1.168.97˘0.8 2.23˘1.3 2.49˘1.8
τ“10´8,κ“100 70.05˘1.2 1.19˘0.8 2.53˘1.0 68.88˘1.11.44˘1.21.74˘1.7
τ“10´8,κ“1000 70.06˘1.11.17˘0.7 2.47˘1.3 68.37˘0.7 2.21˘1.1 3.47˘1.8
κ“100,τ“10´770.06˘1.2 1.28˘0.8 2.39˘1.2 68.87˘1.11.45˘1.2 1.85˘1.6
κ“100,τ“10´870.05˘1.2 1.19˘0.8 2.53˘1.0 68.88˘1.11.44˘1.21.74˘1.7
κ“100,τ“10´970.06˘1.2 1.20˘0.8 2.53˘1.0 68.81˘1.1 1.70˘1.2 1.90˘1.7
Table 4: Sensitivity Analysis for Recidivism Network
ReLU Sigmoid
Recidivism Acc ( %) ∆SP(%) ∆EO(%) Acc ( %) ∆SP(%) ∆EOp%q
M-Norm 95.00˘0.3 8.87˘1.2 1.71˘0.794.45˘0.3 8.94˘1.2 2.06˘1.0
τ“10´10,κ“1 95.01˘0.2 8.76˘1.2 1.66˘0.6 94.38˘0.27.27˘1.0 0.95˘1.0
τ“10´10,κ“0.1 95.02˘0.3 8.62˘1.1 1.43˘0.5 94.27˘0.3 7.29˘1.1 0.89˘1.0
τ“10´10,κ“0.01 95.11˘0.28.45˘1.00.90˘0.5 94.32˘0.27.28˘1.10.80˘0.9
κ“0.1,τ“10´994.99˘0.2 8.59˘1.1 1.17˘0.6 94.33˘0.3 7.39˘1.1 1.12˘1.0
κ“0.1,τ“10´1095.02˘0.3 8.62˘1.1 1.43˘0.5 94.27˘0.3 7.29˘1.1 0.89˘1.0
κ“0.1,τ“10´1194.98˘0.1 8.48˘1.1 1.32˘1.0 94.38˘0.27.27˘1.0 1.14˘1.1
In order to examine the effects of hyperparameter selection, the sensitivity analysis for the proposed
framework is executed. The results for changing κandτvalues are presented in Tables 3 and 4 for Pokec
networks and Recidivism network, respectively. Overall, the results demonstrate that the proposed strategy,
FairNorm, typically leads to better fairness measures compared to the natural baseline (M-Norm) within a
wide range of hyperparameter selection.
5.4 Ablation Study
In order to investigate the influences of different fairness regularizers introduced in this study, we carry over
an ablation study. The results of this study are presented in Table 5. Table 5 demonstrates that while the
employment of Lµseems to have a greater effect in fairness performance improvement, utilization of both Lµ
andL∆(FairNorm) leads to better fairness results compared to the cases where only one of the regularizers
is used with ReLU activation. For the case where sigmoid is used as the nonlinear activation, use of both
regularizers again results in better ∆EOvalues compared to the cases where only one of the regularizers
is employed. However, the same cannot be always claimed for ∆SP, which can be explained by the fact
that sigmoid already limits the maximal deviation to some extend after the first layer reducing the effect
ofL∆. Overall, Table 5 shows that the utilization of both LµandL∆generally achieves the best fairness
performance, while Lµappears to be a more influential component compared to L∆for the bias reduction.
10Published in Transactions on Machine Learning Research (04/2023)
Table 5: Ablation study for the proposed regularizers
ReLU Sigmoid
Pokec-z Accuracy ( %) ∆SP(%) ∆EO(%) Accuracy ( %) ∆SP(%) ∆EOp%q
M-Norm 70.71˘0.8 5.57˘1.3 5.00˘2.0 69.84˘0.7 6.21˘1.4 4.44˘2.1
Lµ 70.65˘0.8 1.50˘1.0 2.19˘1.3 69.71˘0.9 1.36˘0.4 1.72˘1.1
L∆ 70.62˘0.9 5.15˘1.4 4.55˘2.2 69.73˘0.5 5.67˘2.0 4.29˘2.3
FairNorm 70.67˘1.0 1.35˘1.21.90˘1.8 69.73˘0.9 1.71˘0.31.48˘1.1
ReLU Sigmoid
Pokec-n Accuracy ( %) ∆SP(%) ∆EO(%) Accuracy ( %) ∆SP(%) ∆EOp%q
M-Norm 69.25˘0.5 2.48˘1.2 2.91˘1.7 68.59˘0.9 1.78˘2.1 2.88˘1.8
Lµ 69.30˘0.7 1.47˘1.2 1.51˘1.4 68.82˘1.1 1.65˘1.2 1.80˘1.8
L∆ 69.40˘0.5 2.55˘1.1 2.54˘1.6 68.59˘0.9 1.78˘2.1 2.88˘1.8
FairNorm 69.38˘0.7 1.26˘1.21.22˘1.3 68.88˘1.1 1.44˘1.21.74˘1.7
ReLU Sigmoid
Recidivism Accuracy ( %) ∆SP(%) ∆EO(%) Accuracy ( %) ∆SP(%) ∆EOp%q
M-Norm 95.00˘0.3 8.87˘1.2 1.71˘0.7 94.45˘0.3 8.94˘1.2 2.06˘1.0
Lµ 95.08˘0.2 8.67˘1.0 1.35˘0.5 94.33˘0.2 7.18˘1.2 1.05˘1.1
L∆ 95.12˘0.2 8.97˘1.1 1.42˘0.6 94.39˘0.3 8.81˘1.1 1.92˘0.9
FairNorm 95.11˘0.2 8.45˘1.00.90˘0.5 94.32˘0.2 7.28˘1.10.80˘0.9
6 Conclusions and Limitations
This study proposes a unified framework, FairNorm, that mitigates bias in GNN-based learning and provides
faster convergence in training. FairNorm applies group-wise normalizations, and employs two novel fairness
regularizers that manipulate the parameters of these normalizations. The designs of these regularizers are
based on theoretical fairness analyses on GNNs. Experimental results on real-world networks show the
fairness improvement of FairNorm over fairness-aware baselines in terms of statistical parity and equal
opportunity, as well as its similar utility performance in node classification. Furthermore, it is demonstrated
that FairNorm improves the convergence speed of the naive baseline where no normalization is used.
The present framework considers only a single sensitive attribute in its design of normalization layers and
fairness regularizers. One possible future direction of this study is the extension of the design to a case with
multiple sensitive attributes, which may be essential in certain applications.
7 Acknowledgements
We thank the anonymous reviewers for their valuable time in helping us improve our manuscript.
Part of this work is supported by the Google Research Scholar Award and NSF ECCS 2207457.
References
Chirag Agarwal, Himabindu Lakkaraju, and Marinka Zitnik. Towards a unified framework for fair and stable
graph representation learning. In Uncertainty in Artificial Intelligence (UAI) , pp. 2114–2124, August 2021.
Owe Axelsson. A survey of preconditioned iterative methods for linear systems of algebraic equations. BIT
Numerical Mathematics , 25(1):165–187, 1985.
Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton. Layer normalization. arXiv preprint
arXiv:1607.06450 , 2016.
Mislav Balunovic, Anian Ruoss, and Martin Vechev. Fair normalizing flows. In Proc. International
Conference on Learning Representations (ICLR) , April 2021.
Alex Beutel, Jilin Chen, Zhe Zhao, and Ed H Chi. Data decisions and theoretical implications when
adversarially learning fair representations. arXiv preprint arXiv:1707.00075 , June 2017.
11Published in Transactions on Machine Learning Research (04/2023)
Avishek Bose and William Hamilton. Compositional fairness constraints for graph embeddings. In Proc.
International Conference on Machine Learning (ICML) , pp. 715–724, July 2019.
Maarten Buyl and Tijl De Bie. Debayes: a bayesian method for debiasing network embeddings. In Proc.
International Conference on Machine Learning (ICML) , pp. 1220–1229, July 2020.
Maarten Buyl and Tijl De Bie. The kl-divergence between a graph model and its fair i-projection as a fairness
regularizer. arXiv preprint arXiv:2103.01846 , 2021.
Tianle Cai, Shengjie Luo, Keyulu Xu, Di He, Tie-yan Liu, and Liwei Wang. Graphnorm: A principled
approach to accelerating graph neural network training. In Proc. International Conference on Machine
Learning (ICML) , pp. 1204–1215, July 2021.
Woong-Gi Chang, Tackgeun You, Seonguk Seo, Suha Kwak, and Bohyung Han. Domain-specific batch
normalization for unsupervised domain adaptation. In Proceedings of the IEEE/CVF conference on
Computer Vision and Pattern Recognition , pp. 7354–7362, 2019.
Yihao Chen, Xin Tang, Xianbiao Qi, Chun-Guang Li, and Rong Xiao. Learning graph normalization for
graph neural networks. Neurocomputing , 493:613–625, 2022.
WeiCui, XuZhang, andYulongLiu. Covariancematrixestimationfromlinearly-correlatedgaussiansamples.
IEEE Transactions on Signal Processing , 67(8):2187–2195, 2019.
Enyan Dai and Suhang Wang. Say no to the discrimination: Learning fair graph neural networks with
limited sensitive attribute information. In Proc. 14th ACM International Conference on Web Search and
Data Mining (WSDM) , pp. 680–688, March 2021.
Minjing Dong, Yunhe Wang, Xinghao Chen, and Chang Xu. Towards stable and robust addernets. Advances
in Neural Information Processing Systems , 34:13255–13265, 2021a.
Yushun Dong, Jian Kang, Hanghang Tong, and Jundong Li. Individual fairness for graph neural networks: A
ranking based approach. In Proc. ACM Conference on Knowledge Discovery & Data Mining (SIGKDD) ,
pp. 300–310, July 2021b.
Vijay Prakash Dwivedi, Chaitanya K Joshi, Thomas Laurent, Yoshua Bengio, and Xavier Bresson.
Benchmarking graph neural networks. arXiv preprint arXiv:2003.00982 , 2020.
Cynthia Dwork, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Richard Zemel. Fairness through
awareness. In Proc. Innovations in Theoretical Computer Science (ITCS) , pp. 214–226, January 2012.
Joseph Fisher, Arpit Mittal, Dave Palfrey, and Christos Christodoulopoulos. Debiasing knowledge graph
embeddings. In Proc. Conference on Empirical Methods in Natural Language Processing (EMNLP) , pp.
7332–7345, 2020.
Xavier Glorot and Yoshua Bengio. Understanding the difficulty of training deep feedforward neural networks.
InProc. International Conference on Artificial Intelligence and Statistics (AISTATS) , pp. 249–256, May
2010.
Marco Gori, Gabriele Monfardini, and Franco Scarselli. A new model for learning in graph domains. In
Proc. IEEE International Joint Conference on Neural Networks (IJCNN) , volume 2, pp. 729–734, 2005.
Will Hamilton, Zhitao Ying, and Jure Leskovec. Inductive representation learning on large graphs. Advances
in Neural Information Processing Systems (NeurIPS) , 30, December 2017a.
Will Hamilton, Zhitao Ying, and Jure Leskovec. Inductive representation learning on large graphs. Advances
in neural information processing systems , 30, 2017b.
Roger A Horn and Charles R Johnson. Matrix analysis . Cambridge university press, 2012.
Lei Huang, Jie Qin, Yi Zhou, Fan Zhu, Li Liu, and Ling Shao. Normalization techniques in training dnns:
Methodology, analysis and application. arXiv preprint arXiv:2009.12836 , 2020.
12Published in Transactions on Machine Learning Research (04/2023)
Lei Huang, Yi Zhou, Tian Wang, Jie Luo, and Xianglong Liu. Delving into the estimation shift of batch
normalization in a network. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
Recognition , pp. 763–772, 2022.
Sergey Ioffe and Christian Szegedy. Batch normalization: Accelerating deep network training by reducing
internal covariate shift. In Proc. International Conference on Machine Learning (ICML) , pp. 448–456,
July 2015.
Guangyin Jin, Qi Wang, Cunchao Zhu, Yanghe Feng, Jincai Huang, and Jiangping Zhou. Addressing
crime situation forecasting task with temporal graph convolutional neural network approach. In Proc.
International Conference on Measuring Technology and Mechatronics Automation (ICMTMA) , pp. 474–
478, February 2020. doi: 10.1109/ICMTMA50254.2020.00108.
Kareem L Jordan and Tina L Freiburger. The effect of race/ethnicity on sentencing: Examining sentence
type, jail length, and prison length. Journal of Ethnicity in Criminal Justice , 13(3):179–196, 2015.
Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint
arXiv:1412.6980 , 2014.
Thomas N. Kipf and Max Welling. Semi-supervised classification with graph convolutional networks. In
Proc. International Conference on Learning Representations (ICLR) , April 2017.
O Deniz Kose and Yanning Shen. Fair node representation learning via adaptive data augmentation. arXiv
preprint arXiv:2201.08549 , 2022.
Öykü Deniz Köse and Yanning Shen. Fairness-aware node representation learning. arXiv preprint
arXiv:2106.05391 , 2021.
Charlotte Laclau, Ievgen Redko, Manvi Choudhary, and Christine Largeron. All of the fairness for edge
prediction with optimal transport. In Proc. International Conference on Artificial Intelligence and
Statistics (AISTATS) , pp. 1774–1782, April 2021.
Peizhao Li, Yifei Wang, Han Zhao, Pengyu Hong, and Hongfu Liu. On dyadic fairness: Exploring and
mitigating bias in graph connections. In Proc. International Conference on Learning Representations
(ICLR, April 2020.
Aishan Liu, Shiyu Tang, Xianglong Liu, Xinyun Chen, Lei Huang, Zhuozhuo Tu, Dawn Song, and Dacheng
Tao. Towards defending multiple adversarial perturbations via gated batch normalization. arXiv preprint
arXiv:2012.01654 , 2020.
Andreas Loukas. How hard is to distinguish graphs with graph neural networks? Advances in Neural
Information Processing Systems (NeurIPS) , 33:3465–3476, December 2020.
Jiaqi Ma, Junwei Deng, and Qiaozhu Mei. Subgroup generalization and fairness of graph neural networks.
arXiv preprint arXiv:2106.15535 , 2021.
Takeru Miyato, Toshiki Kataoka, Masanori Koyama, and Yuichi Yoshida. Spectral normalization for
generative adversarial networks. In Proc. International Conference on Learning Representations (ICLR) ,
April 2018.
Felix L Opolka, Aaron Solomon, Cătălina Cangea, Petar Veličković, Pietro Liò, and R Devon Hj elm. Spatio-
temporal deep graph infomax. arXiv preprint arXiv:1904.06316 , April 2019.
Kirtan Padh, Diego Antognini, Emma Lejal-Glaude, Boi Faltings, and Claudiu Musat. Addressing fairness
in classification with a model-agnostic multi-objective algorithm. In Uncertainty in Artificial Intelligence
(UAI), pp. 600–609, August 2021.
Tahleen A Rahman, Bartlomiej Surma, Michael Backes, and Yang Zhang. Fairwalk: Towards fair graph
embedding. In Proc. International Joint Conference on Artificial Intelligence (IJCAI) , pp. 3289–3295,
August 2019.
13Published in Transactions on Machine Learning Research (04/2023)
TimSalimansandDurkPKingma. Weightnormalization: Asimplereparameterizationtoacceleratetraining
of deep neural networks. Advances in Neural Information Processing Systems (NeurIPS) , 29, December
2016.
Shibani Santurkar, Dimitris Tsipras, Andrew Ilyas, and Aleksander Madry. How does batch normalization
help optimization? Advances in Neural Information Processing Systems (NeurIPS) , 31, December 2018.
Franco Scarselli, Marco Gori, Ah Chung Tsoi, Markus Hagenbuchner, and Gabriele Monfardini. The graph
neural network model. IEEE Transactions on Neural Networks , 20(1):61–80, 2008.
Franco Scarselli, Ah Chung Tsoi, and Markus Hagenbuchner. The vapnik–chervonenkis dimension of graph
and recursive neural networks. Neural Networks , 108:248–259, 2018.
Indro Spinelli, Simone Scardapane, Amir Hussain, and Aurelio Uncini. Fairdrop: Biased edge dropout for
enhancing fairness in graph representation learning. IEEE Transactions on Artificial Intelligence , 2021.
Weiwei Sun, Wei Jiang, Eduard Trulls, Andrea Tagliasacchi, and Kwang Moo Yi. Acne: Attentive context
normalization for robust permutation-equivariant learning. In Proc. IEEE/CVF Conference on Computer
Vision and Pattern Recognition (CVPR) , pp. 11286–11295, June 2020.
Lubos Takac and Michal Zabovsky. Data analysis in public social networks. In International Scientific
Conference and International Workshop. ’Present Day Trends of Innovations’ , volume 1, May 2012.
Dmitry Ulyanov, Andrea Vedaldi, and Victor Lempitsky. Instance normalization: The missing ingredient
for fast stylization. arXiv preprint arXiv:1607.08022 , 2016.
Petar Veličković, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Liò, and Yoshua Bengio.
Graph attention networks. In Proc. International Conference on Learning Representations (ICLR) , April
2018.
YuxinWuandKaimingHe. Groupnormalization. In Proc. European conference on computer vision (ECCV) ,
pp. 3–19, October 2018.
Ruibin Xiong, Yunchang Yang, Di He, Kai Zheng, Shuxin Zheng, Chen Xing, Huishuai Zhang, Yanyan
Lan, Liwei Wang, and Tieyan Liu. On layer normalization in the transformer architecture. In Proc.
International Conference on Machine Learning (ICML) , pp. 10524–10533, July 2020.
Jingjing Xu, Xu Sun, Zhiyuan Zhang, Guangxiang Zhao, and Junyang Lin. Understanding and improving
layer normalization. Advances in Neural Information Processing Systems , 32, 2019a.
Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka. How powerful are graph neural networks? In
Proc. International Conference on Learning Representations (ICLR) , April 2018a.
Keyulu Xu, Chengtao Li, Yonglong Tian, Tomohiro Sonobe, Ken-ichi Kawarabayashi, and Stefanie Jegelka.
Representation learning on graphs with jumping knowledge networks. In Proc. International Conference
on Machine Learning (ICML) , pp. 5453–5462, July 2018b.
Keyulu Xu, Jingling Li, Mozhi Zhang, Simon S Du, Ken-ichi Kawarabayashi, and Stefanie Jegelka. What can
neural networks reason about? In Proc. International Conference on Learning Representations (ICLR) ,
April 2019b.
Kwang Moo Yi, Eduard Trulls, Yuki Ono, Vincent Lepetit, Mathieu Salzmann, and Pascal Fua. Learning
to find good correspondences. In Proc. IEEE Conference on Computer Vision and Pattern Recognition
(CVPR), pp. 2666–2674, June 2018.
Chengxuan Ying, Tianle Cai, Shengjie Luo, Shuxin Zheng, Guolin Ke, Di He, Yanming Shen, and Tie-Yan
Liu. Do transformers really perform badly for graph representation? Advances in Neural Information
Processing Systems (NeurIPS) , 34, December 2021.
14Published in Transactions on Machine Learning Research (04/2023)
Rex Ying, Ruining He, Kaifeng Chen, Pong Eksombatchai, William L Hamilton, and Jure Leskovec. Graph
convolutionalneuralnetworksforweb-scalerecommendersystems. In Proc. ACM International Conference
on Knowledge Discovery & Data Mining (SIGKDD) , pp. 974–983, July 2018.
Tao Yu, Zongyu Guo, Xin Jin, Shilin Wu, Zhibo Chen, Weiping Li, Zhizheng Zhang, and Sen Liu. Region
normalization for image inpainting. In Proceedings of the AAAI conference on artificial intelligence ,
volume 34, pp. 12733–12740, 2020.
Ziqian Zeng, Rashidul Islam, Kamrun Naher Keya, James Foulds, Yangqiu Song, and Shimei Pan. Fair
representation learning for heterogeneous information networks. arXiv preprint arXiv:2104.08769 , 2021.
Lingxiao Zhao and Leman Akoglu. Pairnorm: Tackling oversmoothing in gnns. In International Conference
on Learning Representations (ICLR) , 2020.
Kaixiong Zhou, Xiao Huang, Yuening Li, Daochen Zha, Rui Chen, and Xia Hu. Towards deeper graph neural
networks with differentiable group normalization. Advances in neural information processing systems , 33:
4917–4928, 2020.
A Proof of Lemma 1
First, we present the following Lemma, as it will be utilized in the proof of Lemma 1.
Lemma 2 (Cauchy Interlace Theorem, (Horn & Johnson, 2012)). Let Abe a Hermitian matrix of order
N, and let Bbe a principal submatrix of Aof orderN´1, such that A“ˆ
B y
yJa˙
PRNˆN. If
λNďλN´1ď¨¨¨ďλ2ďλ1lists the eigenvalues of AandγNďγN´1ď¨¨¨ďγ3ďγ2the eigenvalues of
B, then:
λNďγNďλN´1ďγN´1ď¨¨¨ďλ2ďγ2ďλ1 (10)
whereλi“γionly when there is a nonzero zPRN´1such that Bz“γizandyJz“0; ifλi“γi´1then
there isanonzero zPRN´1such that Bz“γi´1z,yJz“0.
The shift operations over different sensitive groups are defined to be:
MShiftpWpkqHpk´1qQq“WpkqHpk´1qQNp0qNp1q, (11)
where Npnq“IN´1
|Sn|epnqpepnqqJforn“0,1. Let 0ďλ1ď ¨¨¨ ďλNbe the singular values
ofQ. Then, eigenvalues of pQqJQare0ďλ2
1ď ¨¨¨ ďλ2
N. Letγ2
idenote the eigenvalues of
pNp1qqJpNp0qqJpQqJQNp0qNp1q“Np1qNp0qpQqJQNp0qNp1q@i“1,...,N.
pNp0qNp1qqis a projection matrix, for which the following holds:
pNp0qNp1qq2“Np0qNp1qNp0qNp1q“Np0qNp0qNp1qNp1q“Np0qNp1q, (12)
as both Np0qandNp1qare symmetric projection matrices onto the orthogonal complement spaces
of the subspaces spanned by ep0qandep1q, respectively, and pNp0qNp1qqcommutes. Then, the
following decomposition can be written: pNp0qNp1qq “ Udiagp1,1,..., 1,0,0qUJ, where U“„
Usub,1?
|S0|ep0q,1?
|S1|ep1qȷ
. Note that diagpaqcreates a diagonal matrix DPRNˆNwithith diagonal
entry being equal to ai,@aPRN. This decomposition implies that the eigenvalues corresponding to the
15Published in Transactions on Machine Learning Research (04/2023)
eigenvectors1?
|S0|ep0q,1?
|S1|ep1qare zero, which can be shown as:
Np0qNp1qep0q“pIN´1
|S0|ep0qpep0qqJ´1
|S1|ep1qpep1qqJ`1
|S0|1
|S1|ep0qpep0qqJep1qpep1qqJqep0q
“pIN´1
|S0|ep0qpep0qqJ´1
|S1|ep1qpep1qqJqep0q, asep0qandep1qare orthogonal,
“ep0q´1
|S0|ep0qpep0qqJep0q´1
|S1|ep1qpep1qqJep0q
“ep0q´1
|S0||S0|ep0q, aspep0qqJep0q“|S0|by definition,
“0ep0q.(13)
The same analysis also holds for ep1q. Letγ2
Nandγ2
N´1denote zero eigenvalues, and 0ďγ2
1ď¨¨¨ďγ2
N´2
hold. Based on the decomposition of pNp0qNp1qq, the following can be written:
pNp1qqJpNp0qqJpQqJQNp0qNp1q“Np1qNp0qpQqJQNp0qNp1q
“Udiagp1,1,..., 1,0,0qUJpQqJQUdiagp1,1,..., 1,0,0qUJ
„diagp1,1,..., 1,0,0qUJpQqJQUdiagp1,1,..., 1,0,0q,(14)
where A„B, if the eigenvalues of AandBare the same. Furthermore, denote diagp1,1,..., 1,0,0qby
DPRNˆN:
D“„
IN´2r0sN´2ˆ2
r0s2ˆN´2r0s2ˆ2ȷ
, (15)
wherer0siˆjdenotes an all-zeros matrix with dimensions iˆj. Let Cdenote QJQ.
pNp1qqJpNp0qqJCNp0qNp1q
„DUJCUD
“D»
——–UJ
sub
1?
|S0|pep0qqJ
1?
|S1|pep1qqJfi
ffiffiflC”
Usub1?
|S0|pep0qq1?
|S1|pep1qqı
D
“D»
——–UJ
subCUsub1?
|S0|UJ
subCpep0qq1?
|S1|UJ
subCpep1qq
1?
|S0|pep0qqJCUsub1
|S0|pep0qqJCep0q 1?
|S0||S1|pep0qqJCep1q
1?
|S1|pep1qqJCUsub1?
|S0||S1|pep1qqJCep0q 1
|S1|pep1qqJCep1qfi
ffiffiflD
“„
UJ
subCUsubr0sN´2ˆ2
r0s2ˆN´2r0s2ˆ2ȷ
.(16)
As,pNp1qqJpNp0qqJCNp0qNp1qhas the eigenvalues 0ďγ2
1ď¨¨¨ďγ2
N´2, andγ2
N´1“γ2
N“0, equation 16
shows that UJ
subCUsubPRN´2ˆN´2has the eigenvalues 0ďγ2
1ď¨¨¨ďγ2
N´2.
LetRdenote UJCU, then Rhas the eigenvalues 0ďλ2
1ď¨¨¨ďλ2
N, asR„C.
R“»
——–UJ
subCUsub1?
|S0|UJ
subCpep0qq1?
|S1|UJ
subCpep1qq
1?
|S0|pep0qqJCUsub1
|S0|pep0qqJCep0q 1?
|S0||S1|pep0qqJCep1q
1?
|S1|pep1qqJCUsub1?
|S0||S1|pep1qqJCep0q 1
|S1|pep1qqJCep1qfi
ffiffifl(17)
Further, define matrix APRN´1ˆN´1such that:
A“»
–UJ
subCUsub1?
|S0|UJ
subCpep0qq
1?
|S0|pep0qqJCUsub1
|S0|pep0qqJCep0qfi
fl, (18)
16Published in Transactions on Machine Learning Research (04/2023)
together with eigenvalues η1ď¨¨¨ďηN´1. Then, utilizing Lemma 2, equation 17 and equation 18, we can
conclude that
λ2
1ďη1ďλ2
2ďη2¨¨¨ďηN´1ďλ2
N, (19)
whereλ2
i“ηiorλ2
i“ηi´1, if and only if there is a right singular vector αofQsuch thatpep1qqJα“0.
The proof of the condition for λ2
i“ηiorλ2
i“ηi´1is presented below in italic.
Proof: Cauchy interlace theorem states that inequalities in equation 10 become equalities if there is a
nonzero zPRN´1such that Bz“γizandyJz“0or if there is a nonzero zPRN´1such that Bz“γi´1z
andyJz“0. Therefore, for the result in equation 19, inequalities become equalities, if there is a nonzero
zPRN´1such that:
Az“ηzand”1?
|S1|pep1qqJCUsub1?
|S0||S1|pep1qqJCep0qı
z“0. (20)
Note that we dropped the subscript of ηin equation 20, as it is enough to hold these conditions for any of
theηis to turn one of the inequalities into equality in equation 19.
A“«
UJ
sub
1?
|S0|pep0qqJff
C”
Usub1?
|S0|ep0qı
(21)
LetU1:“”
Usub1?
|S0|ep0qı
, where U1forms an orthogonal basis for ep1q. Therefore, A“UJ
1CU 1.
The conditions presented in equation 20 can be rewritten based on this definition:
UJ
1CU 1z“ηzand1a
|S1|pep1qqJCU 1z“0. (22)
The second condition in equation 22 demonstrates that for inequalities in equation 19 become equalities,
CU 1zshould lie in the orthogonal complement space of ep1q, which is spanned by U1. Therefore, if the
second condition in equation 22 is satisfied, there exists a vector bPRN´1such that:
CU 1z“U1b. (23)
In this case, the first condition in equation 22 becomes:
UJ
1CU 1z“UJ
1U1b“IN´1b“b“ηz (24)
Therefore, the following equality should hold to meet both criterion in equation 20:
CU 1z“U1b“ηU1z. (25)
equation 25 demonstrates that the conditions in equation 20 are met, if U1zis the eigenvector of C“QJQ
associated with eigenvalue η. This eigenvector U1zlies in the orthogonal complement space of ep0qand the
eigenvector of C“QJQis the right singular vector of Q. Therefore, inequalities in equation 19 become
equalities, if there is a right singular vector αofQsuch thatpep1qqJα“0, which concludes the proof.
Ais created in the following way:
A“»
–UJ
subCUsub1?
|S0|UJ
subCpep0qq
1?
|S0|pep0qqJCUsub1
|S0|pep0qqJCep0qfi
fl, (26)
together with eigenvalues η1ď¨¨¨ďηN´1. Furthermore, equation 16 shows that UJ
subCUsubPRN´2ˆN´2
has the eigenvalues 0ďγ2
1ď ¨¨¨ ďγ2
N´2. Again, we can apply Cauchy interlace theorem presented in
Lemma 2, which concludes that:
η1ďγ2
1ďη2ďγ2
2¨¨¨ďγ2
N´2ďηN´1, (27)
whereηi“γ2
iorηi“γ2
i´1, if and only if there is a right singular vector αofQsuch thatpep0qqJα“0and
pep1qqJα“0. For these conditions leading to equalities ηi“γ2
iorηi“γ2
i´1, the proof follows in the same
manner as the previous one.
17Published in Transactions on Machine Learning Research (04/2023)
Finally, by unifying the results of equation 19 and equation 27, the Theorem 1 can be proved, such that:
λ1ďγ1 (28)
λ2ďγ2 (29)
...
λN´2ďγN´2ďλN (30)
whereλi“γiorλN“γN´2, only if Qhave a right singular vector αsuch thatpep0qqJα“0and
pep1qqJα“0. Note that λis andγis are defined to be non-negative, thus we can omit the powers of 2in the
final result.
B Learning Environment and Proof for Theorem 1
We first introduce the following Lemma that will be utilized in the proof.
Lemma 3 (Theorem 1, (Cui et al., 2019)) Let x1,...,xN„Np0,Σqbe independent Gaussian vectors,
where Σis anFˆFreal positive definite matrix. Let Bbe a fixed symmetric real NˆNmatrix. Consider
the compound Wishart matrix W“XBXT{NwithX“rx1,...,xNs. Then for any δě0, the following
event
}W´EW}2ě32}B}Fδ`64}B}2δ2
N}Σ}2
holds with probability at most 2 exp`
´2δ2`2Flog 3˘
, where}¨}Fdenotes the Frobenius norm. Specifically,
forδěa
2 lnp3q?
F,
}W´EW}2ě32}B}Fδ`64}B}2δ2
N}Σ}2
holds with probability at most 2 exp`
´δ2˘
.
Model: For the node classification task over a graph G, a linear one-layer GNN-based model is
considered, where the models without and with individual shifts for different sensitive groups are denoted
byfvanillapX,Qq“wJXQandfMShiftpX,Qq“wJXQNp0qNp1q, respectively for wPRFˆ1,XPRFˆN
andQPRNˆN.
Training loss: LetZvanillaPRFˆNandZMShiftPRFˆNdenote XQandXQNp0qNp1q, respectively. The
training loss for both the models without and with individual shifts for different sensitive groups follows as:
Lpwq“1
2}ZJw´y}2
2 (31)
where yPRNdenotes the labels of the nodes. Note that this loss is applicable to both ZvanillaandZMShift,
andZis used interchangeably with Zvanillafor the ease of notation.
Optimization: Gradient descent is utilized for the optimization by initializing w0“0, where an
optimization step can be written as:
wt`1“wt´ηpZZJwt´Zyq
“pIF´ηZZJqwt`ηZy.(32)
Note thatηin Equation equation 32 denotes the learning rate.
In this setting, wtconverges to optimal solution w˚“pZZJq:Zyaccording to the solution of least squares
problem (Horn & Johnson, 2012), where superscript :denotes Moore-Penrose inverse. The residual of wt`1
follows as:
wt`1´w˚“pIF´ηZZJqwt`ηZy´w˚
“pIF´ηZZJqwt`ηpZZJqpZZJq:Zy´w˚
“pIF´ηZZJqwt´pIF´ηZZJqw˚, asw˚“pZZJq:Zy
“pIF´ηZZJqpwt´w˚q.(33)
18Published in Transactions on Machine Learning Research (04/2023)
Assumption 1: w0“0.
Based on Assumption 1 and equation 33, following inequality can be written:
}wt´w˚}ď}p IF´ηZZJq}t}w˚}. (34)
For the learning rate η“1
σmaxpZZJq, the following convergence rate can be guaranteed for this problem:
}wt´w˚}ďˆ
1´σminpZZJq
σmaxpZZJq˙t
}w˚}. (35)
Note thatσminandσmaxoutput the minimum and maximum positive eigenvalues of the input matrix,
respectively. The same result can also be derived for ZMShiftfollowing the same steps, such as:
}wt´w˚}ďˆ
1´σminpZMShiftpZMShiftqJq
σmaxpZMShiftpZMShiftqJq˙t
}w˚}. (36)
Equations equation 35 and equation 36 demonstrate that the convergence rates of the defined node
classification problem for without and with shifts depend on the terms 1´´
σminpZZJq
σmaxpZZJq¯
and 1´´
σminpZMShiftpZMShiftqJq
σmaxpZMShiftpZMShiftqJq¯
, respectively. Therefore, the next step examines these factors together with the
following assumptions.
Assumption 2: xPRFis a centered Gaussian random variable with covariance matrix
Σ“ExrxxJs. The features of nodes x1,...,xNare independent realizations of x, where
X“rx1¨¨¨xNs.Z“XQandZMShift“XQNp0qNp1q.
Assumption 3: ErXQs:“Y.
Assumption 4: OďErpXQ´Yq?
NpXQ´Yq?
NJsďδ1IF
Assumption 5: OďErpXQ´Yq?
NNp0qNp1qpXQ´Yq?
NJsďδ1IF
Assumption 6: Defined Ymatrix is full rank.
We will analyze the eigenvalues of1
NZZJ, as multiplying with a constant does not change the ratio between
the minimum and maximum eigenvalues.
1
NZZJ“1
NNÿ
i“1zizJ
i. (37)
For the analysis of1
NZZJ, we will first focus on E”
ZZ
NJı
, which equals to:
E„ZZJ
Nȷ
“E«
XQ?
NˆXQ?
N˙Jff
“YYJ
N`ErpXQ´Yq?
NpXQ´Yq?
NJ
s(38)
based on the Assumption 3. By utilizing Weyl’s inequality and the provided assumptions, following
inequalities can be written:
σmaxpYYJ
NqďσmaxpE„ZZJ
Nȷ
qďσmaxpYYJ
Nq`δ1
σminpYYJ
NqďσminpE„ZZJ
Nȷ
qďσminpYYJ
Nq`δ1(39)
19Published in Transactions on Machine Learning Research (04/2023)
Similarly:
E„ZMShiftpZMShiftqJ
Nȷ
“E«
XQNp0qNp1q
?
NpXQNp0qNp1qq?
NJff
“E«
XQ?
NpNp0qNp1qq2pXQq?
NJff
, asNp0qNp1qcommutes,
“E«
XQ?
NNp0qNp1qpXQq?
NJff
, asNp0qNp1qis a projection matrix
“YNp0qNp1qYJ
N`E«
pXQ´Yq?
NNp0qNp1qpXQ´Yq?
NJff(40)
Again, by utilizing Weyl’s inequality and the provided assumptions, following inequalities can be written for
the shifted case:
σmaxpYNp0qNp1qYJ
NqďσmaxpE„ZMShiftpZMShiftqJ
Nȷ
qďσmaxpYNp0qNp1qYJ
Nq`δ1
σminpYNp0qNp1qYJ
NqďσminpE„ZMShiftpZMShiftqJ
Nȷ
qďσminpYNp0qNp1qYJ
Nq`δ1(41)
Next step in the proof is bounding the errors }1
NZZJ´E”
ZZ
NJı
}2and}1
NZMShiftpZMShiftqJ´
E”
ZMShiftpZMShiftqJ
Nı
}2. Based on Lemma 3 and assumption 2, the following inequality holds with
probability 1´ϵ, whereϵă2
e, for errors }1
NZZJ´E”
ZZ
NJı
}2and}1
NZMShiftpZMShiftqJ´
E”
ZMShiftpZMShiftqJ
Nı
}2:
›››››1
NZZJ´E«
ZZ
NJff›››››
2ďOˆlogp2{ϵq
N˙
, (42)
where the constants }QQJ}F,}QQJ}2, and}Σ}2are hidden in Op.qnotation for a focus on N, similar to
the approach taken in Cai et al. (2021). Similarly, the following bound holds for }1
NZMShiftpZMShiftqJ´
E”
ZMShiftpZMShiftqJ
Nı
}2with probability 1´ϵ, whereϵă2
e:
››››1
NZMShiftpZMShiftqJ´E„ZMShiftpZMShiftqJ
Nȷ››››
2ďOˆlogp2{ϵq
N˙
. (43)
Based on Lemma 3, Equations equation 42 and equation 43, the inequalities in equation 39 and equation 41
can be re-organized. Following inequalities hold with probability 1´ϵwhereϵă2
e:
σmaxpYYJ
Nq´Oˆlogp2{ϵq
N˙
ďσmaxpZZJ
NqďσmaxpYYJ
Nq`δ1`Oˆlogp2{ϵq
N˙
σminpYYJ
Nq´Oˆlogp2{ϵq
N˙
ďσminpZZJ
NqďσminpYYJ
Nq`δ1`Oˆlogp2{ϵq
N˙ (44)
20Published in Transactions on Machine Learning Research (04/2023)
σmaxpYNp0qNp1qYJ
Nq´Oˆlogp2{ϵq
N˙
ďσmaxp1
NZMShiftpZMShiftqJq
ďσmaxpYNp0qNp1qYJ
Nq`δ1`Oˆlogp2{ϵq
N˙
σminpYNp0qNp1qYJ
Nq´Oˆlogp2{ϵq
N˙
ďσminp1
NZMShiftpZMShiftqJq
ďσminpYNp0qNp1qYJ
Nq`δ1`Oˆlogp2{ϵq
N˙(45)
By the same method that proves Theorem 1 and is presented in Appendix A, it can be shown that positive
eigenvalues of YNp0qNp1qYJare interlaced between the positive eigenvalues of YYJ:
σminpYYJqďσminpYNp0qNp1qYJqďσmaxpYNp0qNp1qYJqďσmaxpYYJq (46)
where inequalities become equalities, only if there is a right singular vector αofYJthat is orthogonal to
bothep0qandep1q.
Assumption 7: None of the right singular vector of YJis orthogonal to both ep0qandep1q
Based on Assumption 7 and result in equation 46, following holds:
σminpYYJ
NqăσminpYNp0qNp1qYJ
NqăσmaxpYNp0qNp1qYJ
NqăσmaxpYYJ
Nq (47)
Finally, for small enough δ1and large enough Nwith probability 1´ϵwithϵă2
e, the following inequalities
can be written:
σminp1
NZZJqďσminpYYJ
Nq`δ1`Oˆlogp2{ϵq
N˙
ăσminpYNp0qNp1qYJ
Nq´Oˆlogp2{ϵq
N˙
ďσminp1
NZMShiftpZMShiftqJq
ďσmaxp1
NZMShiftpZMShiftqJq
ďσmaxpYNp0qNp1qYJ
Nq`δ1`Oˆlogp2{ϵq
N˙
ăσmaxpYYJ
Nq´Oˆlogp2{ϵq
N˙
ďσmaxp1
NZZJq(48)
Therefore, equation 48 proves that 1´´
σminpZZJq
σmaxpZZJq¯
ą1´´
σminpZMShiftpZMShiftqJq
σmaxpZMShiftpZMShiftqJq¯
with probability 1´ϵ.
Unifying this result with Equations equation 35 and equation 36 concludes that shifted model by matrices
Np0qNp1qconverges faster compared to the vanilla model with high probability in the considered learning
environment for node classification.
C Proof of Theorem 2
Define the sample mean after normalization layer by ¯µpnqPRF,n“0,1. Then,
21Published in Transactions on Machine Learning Research (04/2023)
}¯µp0q´¯µp1q}“}1
|S0|ÿ
jPS0¯hp0q
j´1
|S1|ÿ
jPS1¯hp1q
j}
}µp0q´µp1q}“}1
|S0|ÿ
jPS0Actp¯hp0q
jq´1
|S1|ÿ
jPS1Actp¯hp1q
jq}1.(49)
We can write ¯hp0q
j“¯µp0q`¯δp0q
j,@j“1¨¨¨|S0|and ¯hp1q
j“¯µp1q`¯δp1q
j,@j“1¨¨¨|S1|. If the activation
function Actp9qis Lipschitz continuous with Lipschitz constant L(applies to several nonlinear activations,
such as rectified linear unit (ReLU), sigmoid), the following holds:
Actp¯µp0q
iq´L|¯δp0q
i,j|ďActp¯hp0q
i,jq“Actp¯µp0q
i`¯δp0q
i,jq
ďActp¯µp0q
iq`L|¯δp0q
i,j|,@i“1,¨¨¨F
Actp¯µp0qq´L|¯δp0q
j|ďActp¯hp0q
jq“Actp¯µp0q`¯δp0q
jq
ďActp¯µp0qq`L|¯δp0q
j|,@j“1,¨¨¨|S0|(50)
where|.|takes the element-wise absolute value of the input. The same inequalities can also be written for
S1:
Actp¯µp1qq´L|¯δp1q
j|ďActp¯hp1q
jq“Actp¯µp1q`¯δp1q
jqďActp¯µp1qq`L|¯δp1q
j|,
@j“1,¨¨¨|S1|(51)
Based on Equations equation 49, equation 50, and equation 51, following holds:
1
|S0|ÿ
jPS0´
Actp¯µp0qq´L|¯δp0q
j|¯
´1
|S1|ÿ
jPS1´
Actp¯µp1qq`L|¯δp1q
j|¯
ďµp0q´µp1q
ď1
|S0|ÿ
jPS0´
Actp¯µp0qq`L|¯δp0q
j|¯
´1
|S1|ÿ
jPS1´
Actp¯µ1q´L|¯δp1q
j|¯ (52)
Actp¯µp0qq´Actp¯µp1qq´1
|S0|ÿ
jPS0L|¯δp0q
j|´1
|S1|ÿ
jPS1L|¯δp1q
j|ďµp0q´µp1q
ďActp¯µp0qq´Actp¯µp1qq`1
|S0|ÿ
jPS0L|¯δp0q
j|`1
|S1|ÿ
jPS1L|¯δp1q
j|(53)
Define a:“Actp¯µp0qq´Actp¯µp1qq´1
|S0|ř
jPS0L|¯δp0q
j|´1
|S1|ř
jPS1L|¯δp1q
j|andb:“Actp¯µp0qq´Actp¯µp1qq`
1
|S0|ř
jPS0L|¯δp0q
j|`1
|S1|ř
jPS1L|¯δp1q
j|. Equation equation 53 leads to:
|µp0q
i´µp1q
i|ďmaxp|ai|,|bi|q,@i“1,¨¨¨,F. (54)
If we consider the case, |ai|ě|bi|. Then:
|µp0q
i´µp1q
i|ďˇˇˇˇˇˇActp¯µp0q
iq´Actp¯µp1q
iq´1
|S0|ÿ
jPS0L|¯δp0q
j,i|´1
|S1|ÿ
jPS1L|δp1q
j,i|ˇˇˇˇˇˇ
ďˇˇˇActp¯µp0q
iq´Actp¯µp1q
iqˇˇˇ`ˇˇˇˇˇˇ1
|S0|ÿ
jPS0L|¯δp0q
j,i|ˇˇˇˇˇˇ`ˇˇˇˇˇˇ1
|S1|ÿ
jPS1L|¯δp1q
j,i|ˇˇˇˇˇˇ
ďˇˇˇActp¯µp0q
iq´Actp¯µp1q
iqˇˇˇ`Lˇˇˇ¯∆p0q
iˇˇˇ`Lˇˇˇ¯∆p1q
iˇˇˇ,(55)
22Published in Transactions on Machine Learning Research (04/2023)
where ¯∆p0q
i:“maxj|¯δp0q
j,i|and ¯∆p1q
i:“maxj|¯δp1q
j,i|.
Consider the term Actp¯µp0q
iq´Actp¯µp1q
iq:
Actp¯µp0q
iq´Actp¯µp1q
iq“Actp¯µp0q
i`¯µp1q
i´¯µp1q
iq´Actp¯µp1q
iq. (56)
Utilizing Equations equation 50 and equation 51, Actp¯µp0q
i`¯µp1q
i´¯µp1q
iq´Actp¯µp1q
iqcan be bounded by below
and above:
Actp¯µp1q
iq´L|¯µp0q
i´¯µp1q
i|´Actp¯µp1q
iqďActp¯µp0q
i`¯µp1q
i´¯µp1q
iq´Actp¯µp1q
iq
ďActp¯µp1q
iq`L|¯µp0q
i´¯µp1q
i|´Actp¯µp1q
iq(57)
´L|¯µp0q
i´¯µp1q
i|ďActp¯µp0q
i`¯µp1q
i´¯µp1q
iq´Actp¯µp1q
iqďL|¯µp0q
i´¯µp1q
i| (58)
ˇˇˇActp¯µp0q
iq´Actp¯µp1q
iqˇˇˇďL|¯µp0q
i´¯µp1q
i| (59)
Therefore:
|µp0q
i´µp1q
i|ďL|¯µp0q
i´¯µp1q
i|`Lˇˇˇ¯∆p0q
iˇˇˇ`Lˇˇˇ¯∆p1q
iˇˇˇ,@isuch that|ai|ě|bi|. (60)
Next step is to consider the case, |ai|ă|bi|. For this case, following inequalities hold:
|µp0q
i´µp1q
i|ďˇˇˇˇˇˇActp¯µp0q
iq´Actp¯µp1q
iq`1
|S0|ÿ
jPS0L|¯δp0q
j,i|`1
|S1|ÿ
jPS1L|¯δp1q
j,i|ˇˇˇˇˇˇ
ďˇˇˇActp¯µp0q
iq´Actp¯µp1q
iqˇˇˇ`ˇˇˇˇˇˇ1
|S0|ÿ
jPS0L|¯δp0q
j,i|ˇˇˇˇˇˇ`ˇˇˇˇˇˇ1
|S1|ÿ
jPS1L|¯δp1q
j,i|ˇˇˇˇˇˇ
ďˇˇˇActp¯µp0q
iq´Actp¯µp1q
iqˇˇˇ`Lˇˇˇ¯∆p0q
iˇˇˇ`Lˇˇˇ¯∆p1q
iˇˇˇ
ďL|¯µp0q
i´¯µp1q
i|`Lˇˇˇ¯∆p0q
iˇˇˇ`Lˇˇˇ¯∆p1q
iˇˇˇ,@isuch that|ai|ě|bi|.(61)
Combining Equations equation 60 and equation 61, the following inequality can be written:
|µp0q
i´µp1q
i|ďL|¯µp0q
i´¯µp1q
i|`Lˇˇˇ¯∆p0q
iˇˇˇ`Lˇˇˇ¯∆p1q
iˇˇˇ,@i“1,...,F. (62)
which concludes:
}µp0q´µp1q}ďL´
}¯µp0q´¯µp1q}`} ¯∆p0q}`} ¯∆p1q}¯
. (63)
D Hyperparameters
We provide the selected hyperparameter values for the GNN model and the proposed framework for the
reproducibility of the presented results. In the GNN-based classifier, weights are initialized utilizing Glorot
initialization (Glorot & Bengio, 2010). All models are trained for 1000epochs by employing Adam optimizer
(Kingma & Ba, 2014) together with a learning rate of 10´3andℓ2weight decay factor of 10´5. A2-layer
GCN network followed by a linear layer is employed for node classification. Hidden dimension of the node
representations is selected as 64on all datasets.
The results for baseline schemes, covariance, adversarial, HTRDDPregularizers, and FairGNN (Dai & Wang,
2021) are obtained by choosing corresponding hyperparameters (the multiplying factors for these regularizers
in the overall loss) via grid search on cross-validation sets with 5different data splits. Specifically, a grid
search on the values 109,1010,1011is executed for covariance-based regularizer. Furthermore, the values
0.01,0.1,1.10are examined as the multiplier for adversarial regularizer. FairGNN employs both covariance-
based and adversarial regularizers, therefore its parameter selection is the unification of the previous two
23Published in Transactions on Machine Learning Research (04/2023)
hyperparameter selection methods. Finally, the parameters 0.01,0.1,1,10are examined for the HTRDDP
regularizer.
Hyperparameter values for the proposed FairNorm whose results are presented in Section 5.2 can be found in
Table 6. Note that the candidate hyperparameter values for τandκare selected to balance the significance of
Lc,Lµ, andL∆in equation 8 in terms of order of magnitude, so that each component has non-negligible yet
non-dominant effect. These parameters are selected via grid search on cross-validation sets over 5different
data splits. The range of the parameters are selected based on the corresponding loss terms. Specifically,
the values 10,100,1000values are examined for κin Pokec networks, and the values 0.01,0.1,1values are
examined for κin Recidivism network. After the selection of best κvalue, theτis selected together with the
fixed, best κvalue. While the values 10´7,10´8,10´9,10´10values are examined for τin Pokec networks,
the values 10´8,10´9,10´10,10´11values are examined for κin Recidivism network
Table 6: Utilized κandτvalues for the presented results in Table 2
ReLU Pokec-z Pokec-n Recidivism
κ/τ 100{10´71000{10´90.01{10´10
Sigmoid Pokec-z Pokec-n Recidivism
κ/τ 10{10´7100{10´80.01{10´10
E Experimental Results for GraphSAGE
In order to demonstrate the flexibility of the proposed scheme for different GNN models, we provide further
experimental results herein for GraphSAGE operators proposed in Hamilton et al. (2017b) together with
mean aggregation. The obtained results for node classification on Pokec networks and the Recidivism graph
with ReLU activation are presented in Table 7. The results in Table 7 confirm the efficacy of FairNorm also
for the GraphSAGE-based GNN, since FairNorm still achieves better or similar fairness measures compared
to other fairness-aware baselines together with similar utility. Note that the hyperparameters for this set of
experiments are selected in the same way that is described in Appendix D.
Table 7: Comparative Results for GraphSAGE with ReLU activation
Pokec-z Pokec-n Recidivism
Acc ( %) ∆SP(%) ∆EO(%) Acc ( %) ∆SP(%) ∆EOp%q Acc ( %) ∆SP(%) ∆EOp%q
NoNorm 70.16˘0.8 6.37˘1.2 5.32˘1.1 68.73˘0.6 2.69˘1.3 1.76˘1.6 97.93˘0.1 9.37˘0.9 1.42˘0.1
M-Norm 69.94˘0.5 2.82˘1.7 3.52˘1.6 68.96˘0.9 2.45˘1.8 1.82˘1.599.01˘0.1 9.26˘0.70.56˘0.2
Covariance 69.95˘0.7 3.30˘2.0 3.41˘2.269.61˘0.6 3.26˘1.7 2.16˘1.4 98.68˘0.2 9.21˘0.9 0.74˘0.5
Adversarial 68.99˘1.0 1.94˘1.61.97˘1.6 68.94˘1.0 3.24˘1.9 2.43˘2.0 98.88˘0.1 9.13˘0.8 0.73˘0.6
FairGNN 68.92˘1.1 2.79˘1.4 2.42˘1.5 68.99˘0.9 2.96˘2.3 2.12˘1.4 98.82˘0.1 9.36˘0.6 0.66˘0.5
HTRDDP 70.16˘0.5 2.51˘1.7 2.90˘1.8 69.35˘1.9 2.94˘2.0 1.66˘1.2 98.98˘0.1 9.36˘0.70.56˘0.1
FairNorm 69.50˘0.81.37˘1.52.00˘1.9 69.05˘1.12.38˘1.31.30˘0.6 98.98˘0.19.01˘0.80.55˘0.6
F Validation Accuracy Curves
Figure 1 has already shown that FairNorm can achieve faster convergence in training compared to the
framework where no normalization is employed. Figure 2 is provided herein to demonstrate the validation
accuracy over 1000epochs for the case where normalization is not employed, GraphNorm Cai et al. (2021),
and our framework FairNorm. Note that models that achieve the best validation set accuracy are utilized to
obtain the test set performances listed in Table 2. The curves in Figure 2 further signify that FairNorm and
GraphNorm can converge to the model with the best validation set accuracy faster compared to the scheme
that does not use normalization.
24Published in Transactions on Machine Learning Research (04/2023)
0 200 400 600 800 1000
Epochs0.5250.5500.5750.6000.6250.6500.6750.700Validation AccuracyNoNorm
GraphNorm
FairNorm
(a) Pokec-n (ReLU)
0 200 400 600 800 1000
Epochs0.500.550.600.650.70Validation AccuracyNoNorm
GraphNorm
FairNorm (b) Pokec-z (ReLU)
0 200 400 600 800 1000
Epochs0.50.60.70.80.9Validation AccuracyNoNorm
GraphNorm
FairNorm (c) Recidivism (ReLU)
0 200 400 600 800 1000
Epochs0.500.550.600.650.70Validation AccuracyNoNorm
GraphNorm
FairNorm
(d) Pokec-n (Sigmoid)
0 200 400 600 800 1000
Epochs0.500.550.600.650.70Validation AccuracyNoNorm
GraphNorm
FairNorm (e) Pokec-z (Sigmoid)
0 200 400 600 800 1000
Epochs0.40.50.60.70.80.9Validation AccuracyNoNorm
GraphNorm
FairNorm (f) Recidivism (Sigmoid)
Figure 2: Validation curves for different graph data sets when the normalization is not applied (Nonorm)
and applied with/without fairness consideration (FairNorm/GraphNorm).
25