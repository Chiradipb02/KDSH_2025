Under review as submission to TMLR
Calibrated Probabilistic Forecasts for Arbitrary Sequences
Anonymous authors
Paper under double-blind review
Abstract
Real-world data streams can change unpredictably due to distribution shifts, feedback loops
and adversarial actors, which challenges the validity of forecasts. We present a forecasting
framework ensuring valid uncertainty estimates regardless of how data evolves. Leveraging
the concept of Blackwell approachability from game theory, we introduce a forecasting
framework that guarantees calibrated uncertainties for outcomes in any compact space (e.g.,
classification or bounded regression). We extend this framework to recalibrate existing
forecasters, guaranteeing accurate uncertainties without sacrificing predictive performance.
We implement both general-purpose gradient-based algorithms and algorithms optimized for
popular special cases of our framework. Empirically, our algorithms improve calibration and
downstream decision-making for energy systems.
1 Introduction
Machine learning models are often used in settings where data changes unpredictably after deployment. For
example, in medical diagnosis, epidemiological trends can cause distribution shifts that change the prevalence
of ailments in a population. Furthermore, a model’s predictions can impact future observations through
feedback loops –such as in financial forecasting (De Long et al., 1990), adaptive experimentation (Deshpande
and Kuleshov, 2021), preventative medicine (Adam et al., 2020), and predictive policing (Ensign et al.,
2018)–where the model’s deployment induces nonstationarity in future data. Even more challenging, in
settings such as security, regulation, and game playing, data may be chosen adversarially to invalidate
predictions.
Accurate uncertainty estimates are crucial for informed decision-making in dynamic environments. This
work addresses the challenge of maintaining forecast reliability despite adversarial or unpredictable data
shifts. Take for example, an electrical grid operator tasked with using energy generation and load forecasts to
ensure reliable energy supply. Uncertainty estimates are needed to evaluate the risk of different management
decisions, allowing the operator to guard against unfavorable outcomes. Additionally, providing probabilistic
forecasts as opposed to only suggesting decisions allows the operator to incorporate domain knowledge into
the decision process.
To address the need for uncertainty estimation with nonstationary data, we consider a probabilistic forecasting
task for an arbitrary (potentially adversarial) data stream. This raises the question: How can we argue for the
validity of probabilistic forecasts for events that may be unrelated to past observations, or even deterministically
chosen to invalidate predictions? One approach is to appeal to calibration , which says that in the long run,
the observed frequency of an event should match its probability under the forecasts (Dawid, 1982; Foster and
Vohra, 1998; Vovk et al., 2005). In other words, in hindsight the data stream should resemble samples drawn
from the forecasted distributions.
In this work, we study the scope of calibration guarantees that can be provided for forecasts of (potentially)
adversarial data. We consider a stream of outcomes on any compact metric space, encapsulating both
classification tasks and regression for bounded outcomes. Building on a stream of work connecting calibration
to Blackwell approachability (Blackwell, 1956; Foster, 1999; Abernethy et al., 2011; Perchet, 2013), we model
the forecasting task as a zero-sum game played between the Forecaster and Nature. We design the payoff
(i.e., “win condition”) of this game to measure the calibration and predictive performance of the forecasts.
1Under review as submission to TMLR
This allows us to give a general theoretical procedure to enforce any form of calibration that meets mild
regularity conditions. This procedure and its accompanying calibration guarantees serve as a proof that most
popular forms of calibration can be enforced without any assumptions about how the data stream evolves,
with miscalibration decaying in time as O(1/√
T). However, implementing this procedure is in some cases
computationally hard. Thus, we study particular forms of calibration which can be guaranteed by tractable
algorithms, and give gradient-based algorithms that offer greater generality at the cost of worse guarantees.
This allows us to enforce new forms of calibration in online settings, such as decision calibration (Zhao et al.,
2021b) and distribution calibration (Song et al., 2019). Furthermore, we can combine multiple notions of
calibration, for example simultaneously enforcing moment-matching and quantile calibration.
Robustness to adversarial data is valuable since it alleviates the need to make unverifiable assumptions
about the future. However, most real-world data is not truly adversarial: it is unlikely that nature is
conspiring to choose the weather to invalidate weather forecasts. Many forecasters make assumptions that
are approximately valid and, as a result, make more accurate predictions. A good forecasting strategy should
be able to benefit from this domain knowledge. Thus, we also apply our methodology as a post-processing
procedure to achieve no-regret recalibration for existing forecasters; given a set of expert forecasters and a
scoring rule, we construct forecasts that asymptotically match the score of the best forecaster, while also
guaranteeing calibration.
Our main contributions are:
1.We propose a unifying framework for calibration in online learning, describing how many forms of
calibration can be expressed as payoffs in a repeated game.
2.We provide finite-sample calibration guarantees via a theoretical forecasting procedure that applies to any
form of calibration fitting into our framework.
3.We introduce ORCA, a novel gradient-based algorithm to implement the forecasting procedure, and
efficient algorithms optimized for specific forms of calibration.
4.We perform two empirical studies applying ORCA to recalibrate forecasters on regression tasks, demon-
strating its ability to improve both calibration and downstream decisions.
2 Problem Setting
Consider a probabilistic forecasting task, where the goal of the Forecaster is to give a probability distribution
for the next outcome in a sequence (e.g., the weather tomorrow). At each time step t= 1,2,..., Nature
reveals features xt∈X(e.g., today’s temperature and air pressure). Next, Forecaster chooses a forecast ptin
∆(Y), the space of probability distributions over an outcome space Y. Finally, Nature reveals the outcome
yt∈Y. The outcome space Yis assumed to be a compact metric space, such as a finite set of labels in
classification or a bounded interval in regression. We make no assumptions about the feature space X.
Online Learning Forecaster has access to the history and the features when choosing the forecast
pt=Forecaster (ht−1,xt), whereht−1represents the history of all data and forecasts through time t−1.
Nature then observes the forecast before choosing the outcome yt=Nature (ht−1,xt,pt). We allow for the
possibility that Nature acts adversarially, choosing whichever outcome is least favorable for Forecaster. In
this sense, the task can be viewed as a zero-sum repeated game played between Forecaster and Nature. The
generality of the online learning paradigm means our algorithms and theoretical results apply for any sequence
of features and outcomes (xt,yt)overX×Y. In particular, our guarantees hold for nonstationary data
generating processes arising due to distribution shifts, feedback loops, time series, and adversarial actors.
Calibration A notion of calibration represents a property we would expect to observe if each outcome yt
were sampled independently from the forecast pt. For example, suppose yt∈{0,1}is binary and pt∈[0,1]
is a forecasted probability that yt= 1. In the batch setting, where {(xt,yt)}T
t=1are i.i.d. random variables
(e.g., a held-out test dataset), binary distribution calibration says that P(yt= 1|pt≈p)≈pfor all forecasts
p∈∆(Y)that occur sufficiently often. In the online setting, outcomes are an arbitrary sequence and not
necessarily random variables, so the probabilistic definition is not well-defined. Instead, we define calibration
2Under review as submission to TMLR
analogously via empirical frequencies
lim
T→∞/summationtextT
t=11{yt= 1,pt≈p}
/summationtextT
t=11{pt≈p}≈p, (1)
where the indicator variable 1{E}is 1 if the event Eoccurs and 0 otherwise (Vovk et al., 2005). The
indicator 1{pt≈p}is a continuous approximation to the function 1{|pt−p|≤ϵ}for smallϵ(see Section 4
for discussion). In words, Equation 1 says that when the forecast ptis close to any fixed value p, the fraction
of times that yt= 1approaches p. Calibration requires that this holds for all p∈[0,1]such thatpt≈pwith
nonzero frequency in the limit of large T, i.e., lim infT→∞1
T/summationtextT
t=11{pt≈p}>0.
Blackwell Approachability Blackwell’s Approachability Theorem gives sufficient conditions under which
a player in a repeated zero-sum game can control a vector-valued payoff, when averaged over the rounds
of the game. In each round, t= 1,2,..., two players, Forecaster and Nature, sequentially choose actions
at∈Aandbt∈B, respectively, yielding a vector-valued payoff π(at,bt)∈Rm. Forecaster’s goal is to drive
the average payoff πT=1
T/summationtextT
t=1π(at,bt)towards a target set E⊆Rm, while Nature tries to prevent this.
The distance between the average payoff and the target set is defined as d(πT,E) :=infπ∈E∥πT−π∥. A set
Eisapproachable if Forecaster can ensure that d(πT,E)→0asT→∞, regardless of Nature’s strategy. For
our purposes, the target set will be the origin E0={0}. Blackwell (1956) showed that E0is approachable
if Forecaster can ensure the payoff lies in a halfspace defined by the average payoff, regardless of Nature’s
action:
inf
a∈Asup
b∈B⟨π(a,b),π⟩≤0,∀π∈Rm. (2)
3 The Forecasting Game
In this section, we express popular forms of calibration as the average payoff in a zero-sum game played
between Forecaster and Nature. Forecaster’s actions are distributions p∈∆(Y), and Nature’s actions are
outcomesy∈Y. In subsequent sections, we show how to achieve these notions of calibration from a unified
theoretical (Section 4) and algorithmic (Section 5) perspective.
Procedure 1 Probabilistic Forecasting
fort= 1,2,...do
Nature reveals features xt∈X
Forecaster predicts a distribution pt∈∆(Y)
Nature reveals an outcome yt∈Y
Forecaster receives payoff π(xt,pt,yt)∈H
end for
The payoff π(xt,pt,yt)reflects the error of the forecast ptfor features xtand outcome yt, and takes values
in an arbitrary Hilbert space H(e.g., a scalar or a vector). The average payoff up to time Tis denoted
asπT=1
T/summationtextT
t=1π(xt,pt,yt). We are interested in the inner product norm ∥πT∥=/radicalbig
⟨πT,πT⟩H, which for
vector-valued payoffs is the familiar Euclidean norm.
Definition 3.1. Themiscalibration of forecasts p1,p2,...,pTfor features x1,x2,...,xTand outcomes
y1,y2,...,yTwith respect to a payoff πis the norm of the average payoff, ∥πT∥. A sequence of forecasts is
calibrated if the miscalibration vanishes, that is ∥πT∥→0asT→∞.
We now give concrete examples of how calibration can be encoded as a payoff to demonstrate the versatility
of Procedure 1 as an abstraction for calibration.
Binary Calibration As a simple example, consider a binary label indicating whether it rains ( y= 1) or not
(y= 0). Forecaster wants to ensure that on days she predicts rain with probability p, the observed frequency
of rain is also p. We use a vector payoff indexed by a discrete set of probabilities p∈[0,1], with entries
πp(xt,pt,yt) =1{pt≈p}(yt−p). This induces the miscalibration measure ∥πT∥2=/summationtext
p/parenleftbignp,T
T/parenrightbig2(fp,T−p)2,
3Under review as submission to TMLR
wherenp,Tis the number of days pt≈pandfp,Tis the frequency of the event yt= 1whenpt≈p, up to day
T. This closely resembles the Expected Calibration Error (Guo et al., 2017), except using an L2 norm on the
errors instead of an L1 norm.
Quantile Calibration In a regression setting, let ptbe the predicted distribution for the daily high
temperature yt∈R. Quantile calibration requires that for any quantile q∈[0,1](e.g., the median), the
proportion of days ytfalls below the q-quantile of ptisq(e.g., half the time). We use a vector payoff indexed
by a discrete set of quantiles q, given by πq(xt,pt,yt) =1{Fpt(yt)≤q}−q, whereFptis the cdf of pt.
The induced miscalibration measure, known as the Quantile Calibration Error (Kuleshov et al., 2018), is
∥πT∥2=/summationtext
q(fq,T−q)2,wherefq,Tis the frequency of the event Fpt(yt)≤qup to dayT.
Moment Matching Beyond binary and quantile calibration, different notions of faithfulness are relevant
depending on the intended use or interpretation of the forecast. For example, if temperature forecasts are used
to predict the mean or variability of the temperature over a period, it is crucial for the averaged moments of
the forecasts to match those of the data. This can be measured using the payoff πk(xt,pt,yt) =Ey∼pt[yk]−yk
t,
indexed by moments k∈{1,2}. The induced miscalibration metric ∥πT∥2measures the squared error in the
forecasted moments. We can match additional moments of the forecasts and data with k >2, eventually
requiring that the marginal distributions match exactly when kgoes to∞.
Decision Calibration Forecasts directly influence decision-making in areas such as adaptive experimental
design (Deshpande et al., 2024), model predictive control (Garcia et al., 1989), and model-based reinforcement
learning (Malik et al., 2019). In these scenarios, decision-makers must trust that forecasts accurately reflect the
utility of each available action a∈A. For instance, to evaluate whether forecasts systematically undervalue or
overvalue any action, we can use the payoff πa(xt,pt,yt) =Ey∼ptu(a,y,xt)−u(a,yt,xt), indexed by actions
a∈A, whereu(a,y,x )is the utility of action awith outcome yin contextx. A decision-maker should also be
concerned if she experiences swap regret (Blum and Mansour, 2007), wherein when selecting optimal actions
according to the forecasts, she could increase her utility by swapping all occurrences of some action awith
another action a′. This possibility can be measured using the payoff indexed by pairs of actions (a,a′), given
byπa,a′(xt,pt,yt) =1{a′=δ(pt,xt)}(Ey∼pt[u(a,y,xt)]−u(a,yt,xt)), whereδ(pt,xt)is the Bayes optimal
action when yis distributed according to ptwith context xt. By controlling these notions of calibration,
Forecaster can accurately evaluate the average utility of each action and make decisions with vanishing swap
regret.
A General Recipe The above payoffs have a shared structure, which can be abstracted into a general payoff
function of the form π(x,p,y ) =c(x,p)⊗(Ey′∼p[w(y′)]−w(y)), wherecandware vector-valued functions
and⊗is the outer product. Here, wis a “witness function” specifying the quantities that should match
on average between the forecasts and outcomes, and cis a “context function” specifying the conditioning
events under which the quantities should match. Under weak conditions (see Appendix A), calibration can
be achieved online for any payoff of this form.
4 Winning the Forecasting Game with Provable Calibration
In the previous section, we described how calibration can be expressed using payoff functions. In this section,
we use this framework to describe a general forecasting strategy that guarantees miscalibration decreases as
O(1/√
T). Furthermore, we provide a unified approach to enforce arbitrarily many forms of miscalibration
simultaneously. Our strategy includes solving an optimization problem which is computationally hard for
some notions of calibration. In Section 5, we propose an inexact but tractable approach using gradient-based
optimization.
Our work builds on a recent stream of work that leverages Blackwell approachability and related fixed-point
theorems to study calibration in online learning (Perchet, 2013; Vovk et al., 2005; Abernethy et al., 2011;
Lee et al., 2022; Gupta and Ramdas, 2022; Noarov and Roth, 2023). Our primary theoretical contributions
are (1) more general conditions under which calibration can be achieved, allowing for arbitrary compact
outcome spaces and nonconvex calibration metrics, and (2) a framework to simultaneously achieve multiple
4Under review as submission to TMLR
measures of calibration and performance with a unified optimization procedure. These two contributions are
roughly organized into Sections 4.1 and 4.2, respectively. Proofs for all results in this section can be found in
Appendix A.
4.1 An Existence Result for Online Calibration
First, we introduce three mild assumptions about the payoff function that underpin our main results.
Condition 1 (Boundedness) .The norm of the payoff is bounded by B:=supx∈X,p∈∆(Y),y∈Y∥π(x,p,y )∥2<∞.
Condition 2 (Consistency) .The expected payoff is zero when the outcome is drawn from the forecast:
Ey∼p[π(x,p,y )] = 0,∀x∈X,∀p∈∆(Y).
Condition 3 (Continuity) .The payoff is continuous as a function of the forecast p∝⇕⊣√∫⊔≀→π(x,p,y )on∆(Y)
under the Wasserstein metric, ∀x∈X,∀y∈Y.
The first condition ensures that a single bad prediction has bounded impact on the cumulative miscalibration.
The second condition encodes the requirement that a calibration measure is optimized by a perfect forecast.
The third condition requires that the payoff is continuous. For any discontinuous payoff, continuity can be
achieved by smoothing the payoff on an arbitrarily small scale.
Our main result follows from two observations. The first observation is a simple argument that bounds
miscalibration in terms of the inner product between the current and average payoff.
Proposition 4.1. If the payoff is bounded (Condition 1), then
∥πT∥2≤B
T+2
TT/summationdisplay
t=1⟨πt−1,π(xt,pt,yt)⟩. (3)
Proposition 4.1 implies that if we can ensure the inner product in Equation 3 is nonpositive, then miscalibration
will decrease as ∥πT∥2≤B
T. The second observation guarantees that this inner product can be made
nonpositive, regardless of Nature’s play.
Proposition 4.2. If the payoff is consistent (Condition 2) and continuous (Condition 3), then for all π∈H
andx∈X, there exists a forecast p∈∆(Y)such that
max
y∈Y⟨π,π(x,p,y )⟩≤0. (4)
Proposition 4.2 is proven by using continuity to invoke the Ky Fan minimax inequality, and consistency to
ensure that the resulting bound is nonpositive. Together, these results suggest a forecasting strategy which
we formalize in Algorithm 1: play forecasts satisfying the halfspace condition of Equation 4, making the
second term of Equation 3 nonpositive, and guaranteeing that ∥πT∥2≤B
T.
Identifying the specific forecast that satisfies the halfspace inequality Equation 4 can be difficult. For now,
we assume access to an oracle HalfSpaceOracle (π,x)that returns a forecast psatisfying Equation 4. This
oracle is tasked with solving the following minimax optimization problem over p:
min
p∈∆(Y)max
y∈Y⟨π(xt,p,y),πt⟩, (5)
whose optimal solution p∗is guaranteed by Proposition 4.2 to achieve ⟨π(xt,p∗,yt),πt⟩≤0. We defer the
implementation of the oracle to Section 5.
Theorem 4.3. If the payoff satisfies Conditions 1-3, then Algorithm 1 has miscalibration bounded by
∥πT∥2
H≤B/Tfor any sequence {(xt,yt)}∞
t=1.
Theorem 4.3 follows directly from Propositions 4.1 and 4.2, and gives a finite-sample calibration guarantee.
Importantly, we make no convexity assumptions about the payoff, and allow for payoffs in a Hilbert space,
which is useful for infinite dimensional payoffs that arise in regression. Thus, this generalizes existing results
that require discrete outcomes and a bilinear payoff (e.g., Vovk et al., 2005; Kakade and Foster, 2008). In
conclusion, we can achieve general notions of calibration for nonstationary data caused by feedback loops,
distribution shifts, time series, and adversarial environments.
5Under review as submission to TMLR
Algorithm 1 Blackwell Forecasting
Require: Payoffπ,HalfSpaceOracle
π0←0H // Initialize avg payoff as zero
fort= 1,2,...do
Nature reveals features xt∈X
Query HalfSpaceOracle (πt−1,xt)for a distribution ptthat satisfies the inequality
maxy∈Y⟨πt−1,π(xt,pt,y)⟩≤0
Announce forecast pt, observe outcome yt, and receive payoff π(xt,pt,yt)
πt←t−1
tπt+1
tπ(xt,pt,yt) // Update avg payoff
end for
4.2 Multi-Objective and No-Regret Recalibration
Robustness to adversarial data allows us to avoid making assumptions about the data generating process.
However, in practice most forecasting tasks are not truly adversarial; Nature is most likely not conspiring
for the weather to contradict weather forecasts. In this section, we describe how to apply Algorithm 1 as
a post-processing step for another forecaster. This allows us to take advantage of the inductive biases and
valid assumptions of other forecasters, while maintaining guarantees if those assumptions fail. Our work
extends recalibration techniques from the offline setting (e.g., Kuleshov et al., 2018; Marx et al., 2024) to
nonstationary data. A recent stream of work on “calibeating” studies recalibration in the online setting
(Foster and Hart, 2023), and perhaps most relevant to our work is Lee et al. (2022). The most significant
differences between Lee et al. (2022) and our work are that we give deterministic forecasts and do not require
discretization.
Specifically, our goal is to guarantee calibration while simultaneously achieving loss comparable to known
expert forecasters. We begin by defining a standard notion of regret. Let ℓ(p,y)be a bounded and continuous
real-valued proper scoring rule, where smaller values indicate a better forecast. We are given kexpert
forecasters, whose forecasts at each step are provided as features x=(x1,...,xk). Here,xi∈∆(Y)is a
distribution representing the forecast made by expert i. The regret with respect to the best performing expert
is given by
RT:=1
TT/summationdisplay
t=1ℓ(pt,yt)−min
1≤i≤k1
TT/summationdisplay
t=1ℓ(xi,t,yt). (6)
We can bound this regret term in the framework of Blackwell approachability via the k-dimensional payoff
whoseith entry is the excess loss relative to the ith expert,πREG
i(x,p,y ) =ℓ(p,y)−ℓ(xi,y). The norm of
the average payoff then satisfies
/vextenddouble/vextenddoubleπREG(x,p,y )/vextenddouble/vextenddouble2
2≥/vextenddouble/vextenddoubleπREG(x,p,y )/vextenddouble/vextenddouble2
∞=R2
T (7)
Thus, we can treat the regret as simply another payoff that we optimize using Algorithm 1. See Appendix A.1
for the details of this comparison. To achieve calibration with a no-regret guarantee, we note that Forecaster
can control multiple payoffs simultaneously with the same O(1/√
T)time dependency.
Proposition 4.4. Letπ(1),...,π(n)benpayoff functions taking values in Hilbert spaces H1,...,Hn, re-
spectively. Suppose each payoff π(i)satisfies the Conditions 1-3 with bound Bi. Applying Algorithm 1 to
the direct sum payoff π(1)⊕···⊕π(n)ensures/summationtextn
i=1∥π(i)
T∥2
Hi≤1
T/summationtextn
i=1Bi, and using the normalized payoff
π(1)
B1⊕···⊕π(n)
Bnensures∥π(i)
T∥2
Hi≤nBi
Tfor1≤i≤n.
Thus, we can match the performance — up to an O(1/√
T)gap — of any expert forecaster, while guaranteeing
multiple forms of calibration.
5 Algorithms
In the previous section, we gave calibration guarantees for a forecasting strategy that assumed access to an
oracle solution to a minimax optimization problem. In this section we describe algorithms to implement
6Under review as submission to TMLR
this oracle. Since this optimization problem is PPAD-hard in some cases (Hazan and Kakade, 2012), an
efficient algorithm must compromise on either generality or the strength of the guarantees. We consider both
approaches, first giving a general gradient-based optimization strategy without strong guarantees, and then
providing tractable oracles for specialized payoffs.
5.1 Gradient-Based Blackwell Forecasting
Tractable half-space oracles are attractive in that they guarantee calibration. However, there are two
important outstanding limitations: first, some payoff functions do not admit tractable oracles, as indicated
by computational hardness results (Hazan and Kakade, 2012). Second, it is not easy to combine tractable
oracles for individual payoffs into oracles for multiple payoffs; given two payoff functions π1andπ2each with
a tractable oracle, it is not clear how to use the oracles to construct a tractable oracle for π1⊕π2. To mitigate
these issues, we introduce Online Regression Calibration against an Adversary (ORCA), a gradient-based
approach for solving the oracle minimax problem. ORCA iteratively optimizes an upper bound on the
miscalibration (i.e., the minimax inner product). If that upper bound drops below zero, we can control
miscalibration. If the upper bound remains positive because we fail to identify a global optimum of the
nonconvex optimization problem (although we know a solution exists) we play the best identified forecast,
with miscalibration limited by the identified upper bound. Thus, while ORCA does not guarantee calibration,
we know before observing the outcome whether it is possible for the miscalibration to worsen. Additionally,
we can easily combine multiple payoffs by concatenating them, without needing to adjust the optimization
algorithm.
Parameterizing the Forecasts We introduce two parameterized families of distributions over the outcome
space: one for the forecast distributions and one for the adversarial outcome distributions. The forecast
family is given by P={pθ:θ∈Θ}, and should be flexible enough to approximate any distribution over the
outcomes to guarantee the existence of a solution to the half-space oracle problem. For example Pcould
be a neural network that represents the PDF or CDF of the forecast, or a parametric family of mixture
distributions (e.g., θencodes the means, variances, and mixture weights of a Gaussian mixture). Note that
the parameters θdescribe a distribution pθover the outcome space, not model weights mapping inputs to a
distribution.
To enable efficient gradient-based optimization, we give Nature the option to play a randomized outcome,
represented by a distribution q∈∆(Y). Since Nature plays last in each round, this does not affect the optimal
solution to the minimax problem. The adversary family Q={qϕ=/summationtextK
k=1ϕkqk:ϕ∈RK,ϕ≥0,ϕ⊤1= 1}
is chosen to be a mixture distribution with fixed components (q1,...,qK)forqk∈∆(Y), and flexible
mixture weights (ϕ1,...,ϕK). Similarly, the adversary family should be flexible enough to approximate any
distribution over the outcome space, to ensure the oracle does not underestimate the worst-case miscalibration.
Gradient-Based Optimization Each single forecast requires solving an optimization problem over the
forecast family. However, note that this optimization is over a relatively small space—on the order of the 10’s
or 100’s of parameters composing θ. Using the above parameterizations, we write the half-space oracle task
(Equation 5) as
min
p∈∆(Y)max
y∈Y⟨πt−1,π(xt,p,y)⟩= min
p∈∆(Y)max
q∈∆(Y)E
y∼q[⟨πt−1,π(xt,p,y)⟩] (8)
≈min
θ∈Θmax
ϕ∈∆k−1/summationtextK
k=1ϕkE
y∼qk[⟨πt−1,π(xt,pθ,y)⟩] (9)
where ∆k−1={ϕ∈Rk:ϕ≥0,ϕ⊤1 = 1}is the probability simplex. The first equality holds because the
worst-case outcome is equivalent to the worst-case outcome distribution, due to the linearity of the expectation.
The second (approximate) equality replaces the full space of distributions with the parameterized families we
will optimize over. When the components qkare Dirac measures (making qϕa Categorical distribution), we
can compute the expectation analytically. In general, we can also approximate the expectation using Monte
Carlo simulation. Now, the inner maximization problem is a linear program (LP) in the mixture weights ϕ,
which we can solve in O(K3.5)time (Amos and Kolter, 2017). When solving the outer minimization problem,
we differentiate through the LP solution using differentiable convex optimization solvers (Agrawal et al.,
7Under review as submission to TMLR
2019). We now have a minimization task over θwith a differentiable objective, which we can optimize using
standard gradient-based optimizers such as Adam (Kingma and Ba, 2014). The full forecasting strategy for
ORCA is summarized in Algorithm 2.
Algorithm 2 ORCA: Gradient-Based Blackwell Forecasting
Require: Payoffπ, Forecast setP, Adversary setQ
π0←0H // Initialize avg payoff as zero
fort= 1,2,...do
Nature reveals features xt∈X
Initializepθt∈P
whilenot converged do
Computeℓt(θt;Q,π), the worst-case miscalibration for pθtfrom the LP solver. // Equation 9
Updateθtusing gradient-based optimization to minimize ℓt(θt;Q)
end while
Announce forecast pθt, observe outcome yt, and receive payoff π(xt,pt,yt)
πt←t−1
tπt+1
tπ(xt,pθt,yt) // Update avg payoff
end for
5.2 Algorithms for Specialized Notions of Calibration
Algorithm 2 is easy to implement, works with any differentiable payoff, supports no-regret recalibration, and
works well in practice. For many definitions of calibration, we can also design specific half-space oracles that
provably achieve the desired notion of calibration, but they need to be handcrafted for each calibration type
(see Appendix C).
Theorem 5.1. There exist half-space oracles for quantile calibration, distribution calibration, moment-based
calibration, and decision calibration, which provably solve the half-space problem.
The time and space complexity for each algorithm is typically O(1/ϵk)for somek>0(e.g., the number of
moments); see Appendix C. In simple settings (binary calibration and adaptive conformal inference), we
provideO(log(1/ϵk))algorithms. In general, the exponential dependence on kis inevitable, as even for k-class
classification, the optimization problem is PPAD-hard (Hazan and Kakade, 2012).
Recalibration Section 4.2 provides a general way to enforce low-regret relative to baseline forecasters.
Here, we guarantee convergence at the cost of added complexity.
Suppose that a baseline forecaster outputs uncalibrated forecasts xt∈∆(Y); we construct a recalibrator that
outputsptwith low regret relative to xt. We form a partition Cof∆(Y)and associate each cell c∈Cwith
an instance Acof Algorithm 1. When we observe xt, we produce the forecast ptby invoking Acfor the cell
containingxt, then observe yt. We then update Acbased on the data (xt,pt,yt).
Theorem 5.2. Suppose Algorithm 1 approaches a ball of radius ϵ>0centered at the origin and has vanishing
external regret relative any fixed forecast pas measured by a bounded proper loss ℓwith Lipschitz constant
B > 0. Then the above construction yields outputs ptwhose regret relative to xtin terms of ℓis bounded by
2Bϵ+O(1/√
T). The calibration error of the ptis bounded by ϵ+O(1/√
T).
The full construction and the proof of the theorem can be found in Appendix D.
6 Experiments
We perform two experiments to evaluate the ability of ORCA to recalibrate forecasts on regression tasks. In
the first experiment, we test whether ORCA can improve calibration without worsening predictive performance
for four different online learning models on two regression tasks. In the second experiment, we simulate a
decision task for a wind farm operator to test whether ORCA improves downstream decision-making.
8Under review as submission to TMLR
Figure 1: Comparison of the decision loss in-
curred by decisions based on expert forecasts
before and after recalibration with ORCA.
Lower values are better.wind sunspot
Forecaster QCE SMAPE QCE SMAPE
stochastic gradient trees 0.163 0.403 0.1000.505
+ isotonic 0.246 0.554 0.242 1.081
+ ORCA (ours) 0.013 0.4050.045 0.513
neural network 0.142 0.353 0.0480.447
+ isotonic 0.121 0.567 0.147 1.061
+ ORCA (ours) 0.083 0.3970.042 0.453
Hoeffding tree 0.212 0.545 0.072 0.432
+ isotonic 0.186 0.428 0.116 1.061
+ ORCA (ours) 0.016 0.4310.040 0.479
marginal 0.126 0.545 0.046 0.534
+ isotonic 0.094 0.359 0.084 1.016
+ ORCA (ours) 0.017 0.3910.040 0.576
Table 1: Comparison of two recalibration techniques, isotonic
(Kuleshov et al., 2018) and ORCA (ours). The goal is to
reduce miscalibration (QCE), while maintaining predictive
performance (SMAPE). The best value is bolded and values
within 10% of best are underlined.
6.1 Recalibrating Online Learners
Expert Forecasters We recalibrate forecasts from four online learning algorithms implemented in the
River online learning library (Montiel et al., 2021), namely stochastic gradient trees (Gouk et al., 2019), a
neural network, Hoeffding adaptive trees (Bifet and Gavalda, 2009), and a naive forecaster that predicts the
distribution of historical outcomes.
ORCA Implementation We apply ORCA to recalibrate the predictions of each expert forecaster. We
parameterize the action spaces of Forecaster and Nature for the minimax optimization task both as piece-
wise constant densities over 50 evenly-spaced subsets of the outcome space. We find that using similar
parametrizations for Forecaster and Nature is important for preventing them from leveraging limitations
in each other’s expressive capacity. For the payoff function, we use a combined payoff enforcing quantile
calibration, no-regret for the Continuous Ranked Probability Score (CRPS) and Mean Squared Error (MSE)
metrics, and moment-matching for the first two moments. We perform 400 update steps with the Adam
optimizer (Kingma and Ba, 2014) to solve the minimax optimization task.
Datasets We consider two regression tasks. The winddataset consists of hourly wind energy generation
in ERCOT for the year of 2022 (of Texas, 2022). The sunspot dataset (Clette et al., 2014) is a standard
forecasting benchmark where the task is to predict the total monthly sunspots. For each dataset, we forecast
for 1000 time steps, using lag features from the previous 24 steps.
Metrics We evaluate predictive performance using the Symmetric Mean Absolute Percentage Error
(SMAPE), defined as SMAPE =1
T/summationtextT
t=1|yt−ˆyt|
(|yt|+|ˆyt|)/2where ˆytis the mean of the forecast pt. We evaluate
calibration using the Quantile Calibration Error (QCE). For the set of test quantiles Q={0.01,0.02,..., 0.99},
the QCE is defined as QCE =/summationtext
q∈Q(fq,T−q)2,wherefq,Tis the frequency of the event Fpt(yt)≤qup to
dayT. The QCE checks whether ytexceeds each quantile of the forecasts with the expected frequency.
Baseline Comparison We compare ORCA to isotonic recalibration (Kuleshov et al., 2018), a popular
technique for recalibrating predictions in a batch setting. At each time step t, we fit an isotonic recalibrator
based on the data up to time tand apply it to recalibrate the expert forecast at time t+ 1.
9Under review as submission to TMLR
Results The experimental results are displayed in Table 1. We find that ORCA significantly improved
calibration error, while minimally impacting predictive performance. Applying ORCA improved calibration
in all 8 of the settings we tested, decreasing QCE by between 13% and 92% depending on the dataset and
model. ORCA minimally impacted SMAPE, increasing SMAPE by less than 10% in 7 out of 8 cases, and
even decreasing it in 2 cases. ORCA consistently outperformed isotonic recalibration in terms of QCE across
all datasets and models.
6.2 Wind Farm Decision Task
In this experiment, we demonstrate how ORCA can be used to inform downstream decisions with decision
calibration. We design an experiment similar to (Zhao et al., 2021a), in which a wind farm operator submits a
futuregenerationplantoagridoperatoreachday. Oneachday, theoperatorannouncesacommitment a(i)
t∈R
for each hour i= 1,..., 24of the next 24-hour period, and receives a penalty depending on the deviation
between the offered and actual generation, given by ℓ(at,yt) =/summationtext24
i=1(1+λ)(y(i)
t−a(i)
t)++(1−λ)(a(i)
t−y(i)
t)+.
Given a probabilistic forecast for energy generation over each of the next 24 hours, we choose the set of
commitments that minimize the expected loss under the forecasted distributions. We then compare the
decision losses incurred by a bagging trees forecaster to those incurred by forecasts recalibrated using ORCA.
The results of the decision-making experiment are displayed in Figure 1. We observe that applying ORCA
consistently improves the downstream decision loss.
7 Related Work
Calibration has been studied in both online and offline machine learning. In the offline setting, calibration
measures have been designed for a variety of data types and applications, including quantile calibration
(Kuleshov et al., 2018), binary calibration (Song et al., 2019), decision calibration (Zhao et al., 2021b),
threshold calibration (Sahoo et al., 2021), marginal calibration (Gneiting et al., 2007), kernel calibration
(Widmann et al., 2022), and local calibration (Luo et al., 2022). Conversely, existing work in the online
setting focuses on binary calibration, with a few notable exceptions discussed below. Our work can be viewed
as extending the breadth of calibration measures defined in the offline setting to the online setting.
Interest in calibrated online forecasting dates back to the 1980’s (Dawid, 1982). An existing line of work
studies calibration for classification tasks (Abernethy et al., 2011; Gupta and Ramdas, 2022; Okoroafor et al.,
2023; Foster and Vohra, 1998; Kakade and Foster, 2008; Perchet, 2013; Vovk et al., 2005; Kuleshov and Ermon,
2017), where connections between calibration and Blackwell’s approachability theorem (Blackwell, 1956) are
well-known. Furthermore, Okoroafor et al. (2023) give methods for no-regret recalibration in classification.
Foster and Hart (2023) introduce calibeating , a method for improving calibration while maintaining sharpness,
thereforeimprovingperformanceasmeasuredbyaproperscoringrule. Manypreviousanalyses(e.g.,Okoroafor
et al., 2023; Abernethy et al., 2011; Gupta and Ramdas, 2022; Perchet, 2013) leverage the bilinearity of
the payoff function in classification tasks to invoke a fixed point theorem such as von Neumann’s minimax
theorem (Von Neumann and Morgenstern, 1947) or Sion’s minimax theorem (Sion, 1958). In contrast, we
study nonconvex payoffs, such as for quantile calibration in regression, which motivates the new existence
criteria we derive for calibrated forecasting. Furthermore, computational hardness results in this more general
setting motivate our gradient-based calibration methods and efficient oracles for useful special cases.
Noarov and Roth (2023) is also closely related to our work, as they study a general class of calibration
measures that satisfy an elicitability criterion. Two important distinctions between our work and Noarov
and Roth (2023) are that they require randomized forecasts while we give deterministic forecasts, and they
discretize the forecast space while we use a continuous forecast space. Other recent work extends online
calibration to include multicalibration (Gupta et al., 2021; Bastani et al., 2022; Lee et al., 2022; Garg et al.,
2024) and conformal prediction (Gibbs and Candes, 2021; Angelopoulos et al., 2023).
10Under review as submission to TMLR
8 Conclusion
This work presents a novel framework for calibrated probabilistic forecasting for sequences over any compact
outcome space. To implement our framework, we introduce generally-applicable gradient-based algorithms
and provide specialized algorithms for common forecasting scenarios. Empirically, we find that our methods
improve calibration and decision-making when used for recalibration in energy systems. Investigating the
connections between Blackwell forecasting, multicalibration (Gupta et al., 2021; Noarov and Roth, 2023) and
omnicalibration (Garg et al., 2024) is an interesting direction for future work.
9 Broader Impacts
Uncertainty estimates, and particularly those that hold under weak assumptions, support the responsible and
safe deployment of machine learning systems. We hope this work enables broader adoption of uncertainty-
aware decision processes by providing generally applicable calibration methods. Still, calibration is a property
of collections of predictions, and should be used cautiously when considering an individual prediction.
References
Jacob Abernethy, Peter L Bartlett, and Elad Hazan. Blackwell approachability and no-regret learning
are equivalent. In Proceedings of the 24th Annual Conference on Learning Theory , pages 27–46. JMLR
Workshop and Conference Proceedings, 2011.
George Alexandru Adam, Chun-Hao Kingsley Chang, Benjamin Haibe-Kains, and Anna Goldenberg. Hidden
risks of machine learning applied to healthcare: unintended feedback loops between models and future data
causing model degradation. In Machine Learning for Healthcare Conference , pages 710–731. PMLR, 2020.
Akshay Agrawal, Brandon Amos, Shane Barratt, Stephen Boyd, Steven Diamond, and J Zico Kolter.
Differentiable convex optimization layers. Advances in neural information processing systems , 32, 2019.
Brandon Amos and J Zico Kolter. Optnet: Differentiable optimization as a layer in neural networks. In
International Conference on Machine Learning , pages 136–145. PMLR, 2017.
Anastasios N Angelopoulos, Emmanuel J Candes, and Ryan J Tibshirani. Conformal pid control for time
series prediction. arXiv preprint arXiv:2307.16895 , 2023.
Osbert Bastani, Varun Gupta, Christopher Jung, Georgy Noarov, Ramya Ramalingam, and Aaron Roth.
Practical adversarial multivalid conformal prediction. Advances in Neural Information Processing Systems ,
35:29362–29373, 2022.
Albert Bifet and Ricard Gavalda. Adaptive learning from evolving data streams. In Advances in Intelligent
Data Analysis VIII: 8th International Symposium on Intelligent Data Analysis, IDA 2009, Lyon, France,
August 31-September 2, 2009. Proceedings 8 , pages 249–260. Springer, 2009.
Patrick Billingsley. Probability and measure . John Wiley & Sons, 2017.
David Blackwell. An analog of the minimax theorem for vector payoffs. 1956.
Avrim Blum and Yishay Mansour. From external to internal regret. Journal of Machine Learning Research ,
8(6), 2007.
Frédéric Clette, Leif Svalgaard, José M Vaquero, and Edward W Cliver. Revisiting the sunspot number: A
400-year perspective on the solar cycle. Space Science Reviews , 186:35–103, 2014.
A Philip Dawid. The well-calibrated bayesian. Journal of the American Statistical Association , 77(379):
605–610, 1982.
J Bradford De Long, Andrei Shleifer, Lawrence H Summers, and Robert J Waldmann. Positive feedback
investment strategies and destabilizing rational speculation. the Journal of Finance , 45(2):379–395, 1990.
11Under review as submission to TMLR
ShachiDeshpandeandVolodymyrKuleshov. Calibrateduncertaintyestimationimprovesbayesianoptimization.
arXiv preprint arXiv:2112.04620 , 2021.
Shachi Deshpande, Charles Marx, and Volodymyr Kuleshov. Online calibrated and conformal prediction
improves bayesian optimization. In International Conference on Artificial Intelligence and Statistics , pages
1450–1458. PMLR, 2024.
Danielle Ensign, Sorelle A Friedler, Scott Neville, Carlos Scheidegger, and Suresh Venkatasubramanian.
Runaway feedback loops in predictive policing. In Conference on fairness, accountability and transparency ,
pages 160–171. PMLR, 2018.
Ky Fan. A minimax inequality and applications. Inequalities , 3:103–113, 1972.
Dean P Foster. A proof of calibration via blackwell’s approachability theorem. Games and Economic Behavior ,
29(1-2):73–78, 1999.
Dean P Foster and Sergiu Hart. “calibeating”: Beating forecasters at their own game. Theoretical Economics ,
18(4):1441–1474, 2023.
Dean P Foster and Rakesh V Vohra. Asymptotic calibration. Biometrika , 85(2):379–390, 1998.
Carlos E Garcia, David M Prett, and Manfred Morari. Model predictive control: Theory and practice—a
survey.Automatica , 25(3):335–348, 1989.
Sumegha Garg, Christopher Jung, Omer Reingold, and Aaron Roth. Oracle efficient online multicalibration
and omniprediction. In Proceedings of the 2024 Annual ACM-SIAM Symposium on Discrete Algorithms
(SODA), pages 2725–2792. SIAM, 2024.
Isaac Gibbs and Emmanuel Candes. Adaptive conformal inference under distribution shift. Advances in
Neural Information Processing Systems , 34:1660–1672, 2021.
Tilmann Gneiting, Fadoua Balabdaoui, and Adrian E Raftery. Probabilistic forecasts, calibration and
sharpness. Journal of the Royal Statistical Society Series B: Statistical Methodology , 69(2):243–268, 2007.
Henry Gouk, Bernhard Pfahringer, and Eibe Frank. Stochastic gradient trees. In Asian Conference on
Machine Learning , pages 1094–1109. PMLR, 2019.
Chuan Guo, Geoff Pleiss, Yu Sun, and Kilian Q Weinberger. On calibration of modern neural networks. In
International conference on machine learning , pages 1321–1330. PMLR, 2017.
Chirag Gupta and Aaditya Ramdas. Faster online calibration without randomization: interval forecasts and
the power of two choices. In Conference On Learning Theory , pages 4283–4309. PMLR, 2022.
Varun Gupta, Christopher Jung, Georgy Noarov, Mallesh M Pai, and Aaron Roth. Online multivalid learning:
Means, moments, and prediction intervals. arXiv preprint arXiv:2101.01739 , 2021.
Elad Hazan and Sham M Kakade. (weak) calibration is computationally hard. In Conference on Learning
Theory, pages 3–1. JMLR Workshop and Conference Proceedings, 2012.
Sham M Kakade and Dean P Foster. Deterministic calibration and nash equilibrium. Journal of Computer
and System Sciences , 74(1):115–130, 2008.
Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint
arXiv:1412.6980 , 2014.
Volodymyr Kuleshov and Stefano Ermon. Estimating uncertainty online against an adversary. In Thirty-First
AAAI Conference on Artificial Intelligence , 2017.
Volodymyr Kuleshov, Nathan Fenner, and Stefano Ermon. Accurate uncertainties for deep learning using
calibrated regression. In International conference on machine learning , pages 2796–2804. PMLR, 2018.
12Under review as submission to TMLR
Daniel Lee, Georgy Noarov, Mallesh Pai, and Aaron Roth. Online minimax multiobjective optimization:
Multicalibeating and other applications. Advances in Neural Information Processing Systems , 35:29051–
29063, 2022.
Rachel Luo, Aadyot Bhatnagar, Yu Bai, Shengjia Zhao, Huan Wang, Caiming Xiong, Silvio Savarese, Stefano
Ermon, Edward Schmerling, and Marco Pavone. Local calibration: metrics and recalibration. In Uncertainty
in Artificial Intelligence , pages 1286–1295. PMLR, 2022.
Ali Malik, Volodymyr Kuleshov, Jiaming Song, Danny Nemer, Harlan Seymour, and Stefano Ermon.
Calibrated model-based deep reinforcement learning. In International Conference on Machine Learning ,
pages 4314–4323. PMLR, 2019.
Charlie Marx, Sofian Zalouk, and Stefano Ermon. Calibration by distribution matching: Trainable kernel
calibration metrics. Advances in Neural Information Processing Systems , 36, 2024.
Jacob Montiel, Max Halford, Saulo Martiello Mastelini, Geoffrey Bolmier, Raphael Sourty, Robin Vaysse,
Adil Zouitine, Heitor Murilo Gomes, Jesse Read, Talel Abdessalem, et al. River: machine learning for
streaming data in python. 2021.
Georgy Noarov and Aaron Roth. The statistical scope of multicalibration. In International Conference on
Machine Learning , pages 26283–26310. PMLR, 2023.
Electric Reliability Council of Texas. Ercot wind generation data. http://www.ercot.com/gridinfo/generation,
2022.
Princewill Okoroafor, Robert Kleinberg, and Wen Sun. Faster recalibration of an online predictor via
approachability. arXiv preprint arXiv:2310.17002 , 2023.
Vianney Perchet. Approachability, regret and calibration; implications and equivalences. arXiv preprint
arXiv:1301.2663 , 2013.
Roshni Sahoo, Shengjia Zhao, Alyssa Chen, and Stefano Ermon. Reliable decisions with threshold calibration.
Advances in Neural Information Processing Systems , 34:1831–1844, 2021.
Maurice Sion. On general minimax theorems. 1958.
Hao Song, Tom Diethe, Meelis Kull, and Peter Flach. Distribution calibration for regression. In International
Conference on Machine Learning , pages 5897–5906. PMLR, 2019.
Cédric Villani. Optimal transport: Old and new. 2008.
John Von Neumann and Oskar Morgenstern. Theory of games and economic behavior, 2nd rev. 1947.
Vladimir Vovk, Akimichi Takemura, and Glenn Shafer. Defensive forecasting. In International Workshop on
Artificial Intelligence and Statistics , pages 365–372. PMLR, 2005.
Charles Walkden. MATH41112/61112 Lecture Notes: Probability measures on compact metric spaces, May
2016.
David Widmann, Fredrik Lindsten, and Dave Zachariah. Calibration tests beyond classification. arXiv
preprint arXiv:2210.13355 , 2022.
Changfei Zhao, Can Wan, and Yonghua Song. Cost-oriented prediction intervals: On bridging the gap
between forecasting and decision. IEEE Transactions on Power Systems , 37(4):3048–3062, 2021a.
Shengjia Zhao, Tengyu Ma, and Stefano Ermon. Individual calibration with randomized forecasting. In
International Conference on Machine Learning , pages 11387–11397. PMLR, 2020.
Shengjia Zhao, Michael Kim, Roshni Sahoo, Tengyu Ma, and Stefano Ermon. Calibrating predictions to
decisions: A novel approach to multi-class calibration. Advances in Neural Information Processing Systems ,
34:22313–22324, 2021b.
Johanna F Ziegel and Tilmann Gneiting. Copula calibration. 2014.
13Under review as submission to TMLR
A Proofs
We first prove two useful lemmas.
Proposition A.1. If the payoff is bounded (Condition 1), then
∥πT∥2≤B
T+2
TT/summationdisplay
t=1⟨πt−1,π(xt,pt,yt)⟩. (3)
Proof.We proceed by deriving a recursive form for ∥πT∥2
H.
∥πT∥2
H=/vextenddouble/vextenddouble/vextenddouble/vextenddoubleT−1
TπT−1+1
TπT/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
H(10)
=/parenleftbiggT−1
T/parenrightbigg2
∥πT−1∥2
H+1
T2∥πT∥2
H+2(T−1)
T2⟨πT−1,πT⟩H(11)
Multiplying through by T2, we have
T2∥πT∥2
H= (T−1)2∥πT−1∥2
H+∥πT∥2
H+ 2(T−1)⟨πT−1,πT⟩H(12)
Note that this is a recursion over ρT:=T2∥πT∥2
H. Unrolling this recursion gives
T2∥πT∥2
H=T/summationdisplay
t=1∥πt∥2
H+ 2T/summationdisplay
t=1(t−1)⟨πt−1,πt⟩H(13)
Finally, dividing through by T2and using the boundedness of πTgives the desired result:
∥πT∥2
H=1
T2T/summationdisplay
t=1∥πt∥2
H+2
T2T/summationdisplay
t=1(t−1)⟨πt−1,πt⟩H(14)
≤B
T+2
TT/summationdisplay
t=1⟨πt−1,πt⟩H (15)
Proposition A.2. If the payoff is consistent (Condition 2) and continuous (Condition 3), then for all π∈H
andx∈X, there exists a forecast p∈∆(Y)such that
max
y∈Y⟨π,π(x,p,y )⟩≤0. (4)
Proof.Abusing notation, we write the expected payoff for an outcome ydistributed according to a distribution
q∈∆(Y)as
π(x,p,q ) :=Ey∼q[π(x,p,y )]. (16)
The only randomness in Equation equation 16 is due to y. Observe that exchanging the worst-case y∈Yfor
the worst-case distribution q∈∆(Y)does not change the value of the minimax game:
min
p∈∆(Y)max
y∈Y⟨π,π(x,p,y )⟩= min
p∈∆(Y)max
q∈∆(Y)⟨π,π(x,p,q )⟩ (17)
To see that the LHS is not greater than the RHS, note that π(x,p,y )can be represented as π(x,p,δy), where
δyis a Dirac distribution at y. To see that the RHS is not greater than the LHS, note that the objective
value⟨π,π(x,p,q )⟩is linear in q, so the objective value will always be maximized by a Dirac distribution.
Next, we apply the Ky Fan Minimax Inequality Fan (1972) to upper bound the RHS.
14Under review as submission to TMLR
Theorem A.3 (Ky Fan Minimax Inequality Fan (1972)) .Let∆(Y)be a nonempty compact convex subset of
a Hausdorff topological vector space, and let g: ∆(Y)×∆(Y)→Rbe a function such that:
•p∝⇕⊣√∫⊔≀→g(p,q)is lower-semicontinuous for all q∈∆(Y)
•q∝⇕⊣√∫⊔≀→g(p,q)is quasi-concave for all p∈∆(Y)
Then
min
p∈∆(Y)max
q∈∆(Y)g(p,q)≤max
q∈∆(Y)g(q,q) (18)
We apply the Ky Fan Minimax Inequality to the function g(p,q) :=⟨π,π(x,p,q )⟩H. Our assumption that
the payoff is mean-zero implies that π(x,q,q ) = 0, so for all q∈∆(Y)we haveg(q,q) =⟨π,π(x,q,q )⟩H=
⟨π,0⟩H= 0.
Thus, the lemma is proven once we meet the conditions of the Ky Fan Minimax Inequality. Namely, we must
show that ∆(Y)is a nonempty compact convex subset of a Hausdorff topological vector space, and that
g(p,q)is lower-semicontinuous in its first argument and quasi-concave in its second argument.
We first show that ∆(Y)is a nonempty compact convex subset of a Hausdorff topological vector space. The
space of signed measures on Yis a Hausdorff topological vector space when endowed with the weak∗topology.
The set of probability measures ∆(Y)is a subset of the space of signed measures, and it is an elementary result
of probability theory that this set is nonempty and convex (see, e.g., Billingsley, 2017). The compactness of
∆(Y)follows from our assumption that Yis a compact metric space (Walkden, 2016, Theorem 10.2).
All that remains is to show that g(p,q)is lower-semicontinuous in its first argument and quasi-concave in its
second argument. Note that g(p,q)is linear, and therefore quasi-concave, in its second argument due to its
construction as an expectation. Lastly, note that Wasserstein convergence is equivalent to weak∗convergence
on a Polish space (Villani, 2008, Theorem 6.9), so our assumption that g(p,q)is Wasserstein continuous in
its first argument implies lower-semicontinuity in the weak∗topology. Thus, the result follows by application
of the Ky Fan Minimax Inequality.
Theorem 4.3. If the payoff satisfies Conditions 1-3, then Algorithm 1 has miscalibration bounded by
∥πT∥2
H≤B/Tfor any sequence {(xt,yt)}∞
t=1.
Proof.The theorem follows directly from Lemmas 4.1 and 4.2. For each time step t, Lemma 4.2 guarantees
the existence of a forecast ptsuch that maxy∈Y⟨πt,π(xt,pt,qt)⟩≤0. Next, Lemma 4.1 implies that any
forecasting strategy which plays such a forecast ptachieves
∥πT∥2
H≤B
T+2
TT/summationdisplay
t=1⟨πt−1,πt⟩H
≤B
T
Taking the square root of both sides yields the desired result.
Proposition A.4. Letπ(1),...,π(n)benpayoff functions taking values in Hilbert spaces H1,...,Hn,
respectively. Suppose each payoff π(i)satisfies the Conditions 1-3 with bound Bi. Applying Algorithm 1 to
the direct sum payoff π(1)⊕···⊕π(n)ensures/summationtextn
i=1∥π(i)
T∥2
Hi≤1
T/summationtextn
i=1Bi, and using the normalized payoff
π(1)
B1⊕···⊕π(n)
Bnensures∥π(i)
T∥2
Hi≤nBi
Tfor1≤i≤n.
Proof.The proposition includes two inequalities. Define the concatenated payoff π(1:n):= [π(1),...,π(n)]
taking values in the direct sum Hilbert space Hn
1=/circleplustextn
i=1Hi. Note that π(1:n)inherits all the conditions
of Theorem 4.3 from the component payoffs, but with the payoff bound Bn
1=/summationtextn
i=1Bi. Thus, the first
inequality is a direct result of Theorem 4.3. To see the second inequality, we first define a normalized
payoffρ(1:n):= [π(1)/B1,...,π(n)/Bn]where each component payoff has norm at most 1. Applying the first
15Under review as submission to TMLR
inequality, we get that ∥ρ(1:n)
T∥2
Hn
1=/summationtextn
i=1∥π(i)
T∥2
Hi/Bi≤n
T. Since each term of the sum is nonnegative, we
have for all 1≤i≤nthat∥π(i)
T∥2
Hi≤nBi
T.
A.1 An Extension to the Existence Theorem for Semi-Consistent Payoffs
NotethatπREGinSection4.2doesnotsatisfyconsistency(Condition2), whichrequiresthat Ey∼p[π(x,p,y )]=
0,∀x∈X,∀p∈∆(Y). Thus, we introduce a weaker condition (Condition 4), which allows us to control
the positive component of the excess loss, since negative excess loss (i.e., outperforming the experts) is
not problematic. Note that Condition 4 applies to πREGdue to the propriety of the scoring rule; the true
distribution has expected loss no greater than any other forecast.
Condition 4 (Semi-consistency) .A vector-valued payoff π(x,p,y )∈Rmis semi-consistent if
Ey∼p[πi(x,p,y )]≤0, for alli∈{1,...,m},p∈∆(Y), andx∈X.
Proposition A.5. If a vector-valued payoff function satisfies Conditions 1, 3 and 4, then Algorithm
1 achieves∥(πT)+∥2≤B/Tfor any sequence {(xt,yt)}∞
t=1, where (πT)+= ((π1,T)+,..., (πm,T)+)for
(πi,T)+= max(0,πi,T)is the positive part.
The proof of Proposition A.5 is almost identical to the proof of Theorem 4.3, with the average payoff replaced
by its positive part. Applying Proposition A.5 to πREGgives the no-regret guarantee that RT≤√nBℓ√
T, where
Bℓ= supp,yℓ(p,y). Thus, we achieve the same O(1/√
T)regret rate.
B Calibration Payoffs
Below, we introduce an additional payoff for full distribution calibration, and add details to for additional
precision for the quantile calibration payoff.
Distribution Calibration Distribution calibration states that across all time steps twith the same forecast
p, the distribution of outcomes should match the forecast (Song et al., 2019). In the batch setting, where the
outcomeyand forecast pare random variables, distribution calibration can be written as (y|p)∼p. For
example, when forecasting the daily high temperature, on days the forecast is a Gaussian distribution with
mean 20◦C and variance 3◦C, the observed high temperatures should be roughly Gaussian with the same
mean and variance. To define distribution calibration in the online setting using payoffs, we use a vector-based
payoff indexed by a discrete set of distributions p∈∆(Y), given byπp(xt,pt,yt) =1{pt≈p}(Fpt−Fδ(yt)),
whereFptandFδ(yt)are the cdfs for the forecast and a Dirac measure at yt, respectively. Note that a fine
discretization of the space of distributions ∆(Y)will grow exponentially in size as Ygrows, highlighting the
computational hardness of distribution calibration.
Quantile Calibration Since distribution calibration is often too difficult to impose in regression—primarily
due to the need for a conditioning event for each distribution—quantile calibration is a popular weaker
alternative, requiring that the quantiles of forecasts are accurate, on average. That is, the outcome
ytshould be less than or equal to the α-quantile of the forecast with frequency α, for allα∈[0,1]
(e.g.,ytshould exceed the forecasted median half the time). Formally, quantile calibration states that
limT→∞1
T/summationtextT
t=11{yt≤Quantile(pt,α)}=αfor allα∈[0,1]. Quantile calibration enforces the law of
probability that the probability integral transform (PIT) of a continuous random variable follows a uniform
distribution on the unit interval. In a batch setting where the outcomes are i.i.d. random variables and if the
forecasts and ground-truth distributions are continuous, the payoff πα(x,p,y ) =1{yt≤Quantile(pt,α)}−α,
indexed by α∈[0,1], suffices to measure quantile miscalibration. To handle the case where there are
discontinuities in the cdf of the forecast, we allow forecasts over a strict superset of the outcome space and
linearize across discontinuities in the forecasted CDF (see Ziegel and Gneiting (2014) for a similar approach
in the batch setting), yielding the payoff
πα(x,p,y ) =λ1/braceleftbig
Fp(y)≤α−/bracerightbig
+ (1−λ)1/braceleftbig
Fp(y)≤α+/bracerightbig
−α (19)
whereα+=inf{α′∈Range (Fp) :α′≥α},α−=sup{α′∈Range (Fp)∪{0}:α′≤α}, andλ= (α+−
α)/(α+−α−)
16Under review as submission to TMLR
C Oracles
This section introduces half-space oracles designed for specific notions of calibration. Specifically, we focus
on the following: adaptive conformal inference, quantile calibration, distribution calibration, moment-based
distribution calibration, and decision calibration. In each setting, we introduce the definition of calibration,
provide a half-space oracle, prove its correctness, and discuss its computational complexity.
C.1 Quantile-Based Notions of Calibration for Regression Problems
We start with perhaps the simplest setting, which considers forms of calibration defined for regression problems
and in which calibration is defined using quantiles. Specifically we look at two approaches of this form:
adaptive conformal inference—a setting that matches exactly the definition introduced by Gibbs and Candes
(2021)—as well as quantile calibration, an extension to full quantile functions.
Preliminaries We introduce both quasi-randomized and deterministic algorithms. We use the term
quasi-randomized to say that the randomization will be between two forecasts (our outputs) f1,f2that satisfy
||f1−f2||<ϵ, for some small ϵand according to some norm ||·||. Our deterministic algorithms will assume
the existence of a root finding oracle for a function g:X→ Ron some closed and compact set X(e.g., the
interval [0,1]) that is guaranteed to have a point xsuch thatg(x) = 0.
C.1.1 Adaptive Conformal Inference
Setup In the setting of adaptive conformal inference, we are given a target quantile βas well as a quantile
functionQt(a)(that could be different at each time step) that targets a continuous outcome yt∈R. Our
goal is to choose at each time step an αt∈[0,1]such that the Qt(αt)are on average the β-th quantile within
an error tolerance of ϵ>0. In other words, we want
lim
T→∞/parenleftigg
1
TT/summationdisplay
t=11{yt≤Q(αt)}−β/parenrightigg
≤ϵ.
Randomized Algorithm We define our algorithm as follows. First, we define a finite of set of possible
outputs for αtover which we will perform randomization. Specifically, we define our action set as
A={a0,a1,...,aM}whereAis a discretization of [0,1], i.e., 0 =α0≤αi<αi+1≤αM= 1. We will play
distributions p∈∆(A)over the action set. We define our payoffsas follows. Let et(a) =1{yt≤Qt(a)}. Let
the payoff be indexed by actions a∈A, given byπa(pt,yt) =pt(a)(et(a)−β), wherept(a)is the probability
ptassigns to action a. We want the average set of payoffs to approach a ball of size ϵcentered at the origin.
Note that this yields a valid quantile estimate as defined above.
In order to achieve this goal using approachability, we need to devise a half-space oracle that will output at each
time step a distribution ptoverAsuch that for any vector of historical payoffs πt, we have⟨πt,π(pt,y)⟩≤0
for ally.
We construct the following half-space oracle for this goal, given the average payoff πt:
•If for alla,πt,a≥0, outputα0with probability one.
•If for alla,πt,a≤0, outputαMwith probability one.
•Otherwise, there will exist an i∈{1,...,M}such that sign(πt,ai)̸=sign(πt,ai+1). Then choose the
aboveai,ai+1and play with probability pi=|π−1
t,ai|/(|π−1
t,ai|+|πt,ai+1|−1)the valueai, and otherwise
ai+1. Then for all y, we have:
Lemma C.1. Letϵ>1/M. Then the above algorithm is a half-space oracle for a ball of radius ϵ. Furthermore,
the algorithm runs in log(ϵ)time andO(1/ϵ)space.
17Under review as submission to TMLR
Proof.First, we explain the time and space complexity of the algorithm. First, the space complexity is
O(M) =O(ϵ)becauseϵ>1/M. The time complexity is O(log(M)) =O(log(ϵ))because we can find an i
such that sign(πt,ai)̸= sign(πt,ai+1)(or determine that none exists) in O(log(M))time using binary search.
Next, we prove that in each of the three cases above, the property of the half-space oracle is satisfied. Note
that:
⟨πt,π(pt,y)⟩=πt,aipt(ai) (et(ai)−β) +πt,ai+1pt(ai+1) (et(ai+1)−β)
=k·(et(ai)−et(ai+1))for a constant k>0, by choice of pt
note again that et(a1) = 1 =⇒et(a2) = 1ifa1<a2therefore the above expression is ⟨πt,π(pt,y)⟩≤0.
Deterministic Algorithm Our deterministic algorithm is a straight-forward extension of the above
procedure. We now let the action space A= [0,1]be equal to the entire unit interval. The payoffs are the
same as above for each a∈A. The algorithm is defined as follows. Denote the average payoff by c:A→R.
Then we run the zero-finding oracle and output the zero of cif it exists. Otherwise, either c≥0, and we
output 0orc≤0, in which case we output 1.
Lemma C.2. The above algorithm is a deterministic half-space oracle for a ball of radius ϵ. Its runtime is
equal to that of the root-finding oracle.
Proof.First, note that the above three cases in the algorithm are exhaustive for the same reason as in the
previous theorem. The two edge cases are handled as before. In the third case (when the root exists), we put
all the probability on the root a′, and the dot product reduces to:
c·(pt⊙π(y)) =c(a′)pt(a′)π(a′,y) = 0
sincec(a′)is zero (and note that we defined the inner product c·(pt⊙π(y))to generalize to the function
c).
C.1.2 Quantile Calibration
Next, we are interested in a generalization of the above setting, in which the output of the algorithm is an
entire quantile function.
Setup We are given as input a quantile function Qt(a)(that could be different at each time step) that
targets a continuous outcome yt∈Rthat is bounded by values ymin,ymax. Our goal is to choose at each
time step a recalibrator function Rt: [0,1]→[0,1]such that the corrected quantile function Q′
t=Qt◦Rt
represents valid quantiles within an error tolerance of ϵ>0for allβ. In other words, we want
lim
T→∞/parenleftigg
1
TT/summationdisplay
t=1I{yt≤Q′(β)}−β/parenrightigg
≤ϵfor allβ >0.
Deterministic Algorithm Without loss of generality, we can define our action space to consist of quantile
functionsQt. We define our payoffs as follows. Let et(a) =I{yt≤Q(a)}. Letπ(Q,a,y ) =et(a)−a, which
is a vector indexed by a∈[0,1]. We want the average set of payoffs to approach a ball of size ϵcentered at
the origin. Note that this yields a valid quantile estimate as defined above.
In order to achieve this goal using approachability, we need to devise a half-space oracle that will output at
each time step a Qtsuch that for any vector of historical payoffs c∈Rm, we havec·πt(Q,y)≤0for ally,
whereπt(Q,y)is the vector of payoffs indexed by Aand·denotes the inner product.
We construct the following half-space oracle for this goal. Suppose we are given a vector of historical
payoffsc. We run a root finding-algorithm to find at least one root (or the absence of any root).
18Under review as submission to TMLR
•Ifc≥0, letQ(a) =yminfor alla, and output Q.
•Ifc≤0, letQ(a) =ymaxfor alla, and output Q.
•Otherwise, there is a zero a′such thatc(a′) = 0. LetA1be the integral under the curve of cfor
a≤a′and letA2be the integral under the curve for a≥a′.
–IfA2−A1≤0, letQ(a) =yminfora≤a′andQ(a) =ymaxfora≤a′.
–IfA1+A2≤0letQ(a) =ymaxfor alla, and output Q.
–IfA1+A2≥0letQ(a) =yminfor alla, and output Q.
is positive and the area under the curve for a≥a′is negative, let Q(a) =yminfora≤a′and
Q(a) =ymaxfora≤a′.
Lemma C.3. The above algorithm is a deterministic half-space oracle for a ball of radius ϵ. Its runtime is
equal to that of the root-finding oracle.
Proof.First, note that the above three cases in the algorithm are exhaustive. Next, note that when
Q(a) =ymax, thenπ(Q,a,y )≥0for ally. WhenQ(a) =ymin, thenπ(Q,a,y )≤0for ally. Thus, in each of
the first two cases we have c·πt(Q,y)≤0.
In the third setting, first subcase, by construction we have exactly c·πt(Q,y)≤A2−A1≤0. The last
two subcases follow similarly. Note that computationally, we can distinguish among all these subcases, by
performing an inner product with cand observing the result. The computational cost of the algorithm is
that of running the root finding algorithm and the inner product.
Note that this algorithm is not practical, as it produces Q’s that are step functions. It is meant to illustrate
the existence of a polynomial algorithm in our framework. In practice, one would use our optimization-based
solution.
C.2 Variations of Distribution Calibration
Next, we are going to derive half-space oracles for versions of distribution calibration, both the original version
of distribution calibration, as well as more restricted and tractable versions, including decision calibration
and our novel formulation of moment-based calibration.
C.2.1 Distribution Calibration via Discretization
Our overall strategy for constructing half-space oracles will be inspired by Kakade and Foster (2008). We
first provide a summary of their approach that closely follows their exposition.
Specifically, we will define a discretization Vof the space of forecasts. For example, the set V could consist
of probability distributions which are specified to a finite number of digits of precision. Essentially, our
quasi-randomized approach will output a distribution over a small number of similar elements of V, and our
deterministic approach will play a fixed point of this distribution.
More specifically, we will assume that the forecasts live in a compact set ∆(this assumption will have to be
verified for each definition of calibration). We then define a triangulation of ∆, i.e., a partition into a set of
simplices such that any two simplices intersect in either a common face, common vertex, or not at all. Let
Vbe the vertex set of this triangulation. Note that any point plies in some simplex in this triangulation,
and, slightly abusing notation, let V(p)be the set of corners for this simplex. We are going to produce a
randomized output over these corners.
To formalize this, associate a test function wv(p)with eachv∈Vas follows. Each distribution pcan
be uniquely written as a weighted average of its neighboring vertices, V(p). Forv∈V(p), let us define
the test functions wv(p)to be these linear weights, so they are uniquely defined by the linear equation
p=/summationtext
v∈V(p)wv(p)v.
We also define the discretization to be sufficiently small: given a target precision ϵ > 0we define the
discretization such that for all f1,f2in the same simplex we have ||f1−f2||<ϵ.
19Under review as submission to TMLR
Deterministic and Quasi-Deterministic Calibration We use the following results from Kakade and
Foster (2008). Let µT(v) =1
T/summationtextT
t=1wv(ft)(yt−ft). Forv∈V, defineρT(v), a function which updates v
using the calibration error µT(v):ρT(v) =v+µT(v). We extend this function to arbitrary pby interpolating
between the vertices of the cell that contains p:ρT(p) =p+/summationtext
v∈Vwv(p)µT(v).
Consider the following "play the fixed point" algorithm defined by Kakade and Foster (2008). At time T= 1,
we setµ0(v) = 0for allv∈V. Then at each future time T, compute a fixed point of ρT−1and forecast this
fixed point.
We will use the following facts
Lemma C.4. For allT, a fixed point of ρTexists and the forecast fTat timeTsatisfies/summationtext
v∈Vwv(fT)µT−1(v) = 0.
Lemma C.5. The above deterministic algorithm is weakly calibrated in the sense that1
Tlim→
∞/summationtextT
t=1w(ft)(yt−ft)→0in theℓ∞norm for any continuous function w.
Consider now the following quasi-deterministic version of the above algorithm. We start with a forecasting
procedure that is weekly calibrated. At time t, that procedure outputs a forecast ft. We define a quasi-
deterministic forecast by outputting the vertices v∈V(ft)of the simplex containing ft, each with probability
wv(ft). Recall that we have chosen the discretization such that ||f1−f2||<ϵ.
Lemma C.6. The limit of the calibration error of the above algorithm as T→∞is at mostϵ.
Next, we will use these tools to establish half-space oracles for our framework.
C.2.2 Moment-Based Distribution Calibration
Setup In the setting of moment-based calibration, we are trying to forecast at each time step ta continuous
labelyt∈Rand we assume that |yt|≤Bis bounded by B > 0. Our goal is to choose at each step ta
predictionµt,σtsuch that on average, our of all the times when we predicted µt,σtthe mean and the variance
of theytare also approximately equal µt,σt.
Randomized Algorithm We define our action set asA={(µi,σj)}fori,jin a grid with Mticks
along each dimension). The grid represents our set if simplexes and the ticks on the grid are the vertices
V. We will output a probability pover A and sample a forecast ftfromp. We define a set of payoffs as
π(µ,σ,y ) = (µ−y,σ−y2]); thusπhas dimension 2M2. We want the average set of payoffs to approach a ball
of sizeϵcentered at the origin. Note that this yields a valid quantile estimate as defined above.
In order to achieve this goal using approachability, we need to devise a half-space oracle that will output
at each time step a distribution ptoverAsuch that for any vector of historical payoffs c∈Rm, we have
c⊤(pt⊙πt(y))≤0for ally, whereπt(y)is a vector of payoffs indexed by A.
We construct the following half-space oracle for this goal. Suppose we are given a vector of historical payoffs
c. By the above fixed point lemma, there must exist a fixed point ftsuch that/summationtext
v∈Vwv(fT)µT−1(v) = 0.
We can find the cell where ftlives by enumerating the M2cells. Then we set pt, our probability over the A
to be zero everywhere except at V(ft)and equal to wv(ft)everywhere else.
Lemma C.7. Letϵ>1/M. Then the above algorithm is a half-space oracle for a ball of radius ϵ. Furthermore,
the algorithm runs in ϵ2time andO(1/ϵ2)space.
Proof.First, note that our set of possible forecasts is compact, which guarantees that the fixed point exists.
Next, we prove that the property of the half-space oracle is satisfied. If the fixed point is in the interior of a
cell, note that:
c⊤
t(pt⊙π(y)) =/summationdisplay
v∈Vwv(ft)µt−1(v) = 0
becausectis defined to be previous vector of average payoffs, which is precisely µt−1.
20Under review as submission to TMLR
Note that there may be edge cases, where the fixed point is at the edge of the grid. Then we simply have to
enumerate the following edge cases. Suppose that cσ,i,j=0≥0for alli(it’s fully positive on the left edge of
the grid). Then you can find an optimal strategy over µas in a 1d problem over (i,j= 0). Suppose that
cσ,i,j=M≤0for alli(it’s fully positive on the right edge) Then you can find an optimal strategy over µas
in a 1d problem over ( i,j=M). Suppose that cµ,i=0,j≥0for allj(it’s fully positive on the top edge of
the grid) Then you can find an optimal strategy over σas in a 1d problem over (i= 0,j). Suppose that
cµ,i=M,j≤0for allj(it’s fully positive on the bottom edge) Then you can find an optimal strategy over σas
in a 1d problem over (i=M,j).
Next, we explain the above time and space complexity of the algorithm. First, the space complexity is
O(M2) =O(1/ϵ2)becauseϵ>1/M. The time complexity is O(M2) =O(ϵ2)because we simply enumerate
all the cells.
Deterministic Algorithm The above procedure naturally leads to a natural randomized algorithm, where
we simply forecast the fixed point. Computationally, implementing this algorithm requires an oracle for
Brouwer’s fixed-point problem (in general, this is PPAD-hard).
C.2.3 General Distribution Calibration
We can extend the above approach to more general settings, where we want to main a general notion of
distribution calibration. In other words, out of the times when we predict ft, we want the distribution of yto
look likeft.
Setup We are trying to forecast at each time step ta continuous label yt∈Rand we assume that |yt|≤B
is bounded by B > 0. We are going to assume a certain discretization for yinto a partition of Mintervals of
its domain. Our goal is to choose at each step ta forecastftsuch that on average, our of all the times when
we predicted ytwe haveyt≈ft: this can be roughly viewed as matching probability mass functions.
Randomized Algorithm We define our action set Aas a discretization of the set of distributions ft.
This can represent a discretization of the range of ftinto a grid of Npoints. The grid represents our set if
simplexes and the ticks on the grid are the vertices V. We will output a probability pover A and sample a
forecastftfromp. We define a set of payoffs asπ(f,y) =f−y; thusπhas dimension O(MN). We want
the average set of payoffs to approach a ball of size ϵcentered at the origin. Note that this yields a valid
quantile estimate as defined above.
Again, we need to devise a half-space oracle that will output at each time step a distribution ptoverAsuch
that for any vector of historical payoffs c∈Rm, we havec⊤(pt⊙πt(y))≤0for ally, whereπt(y)is a vector
of payoffs indexed by A.
We construct the following half-space oracle for this goal. Suppose we are given a vector of historical payoffs
c. By the above fixed point lemma, there must exist a fixed point ftsuch that/summationtext
v∈Vwv(fT)µT−1(v) = 0.
We can find the cell where ftlives by enumerating the MNcells. Then we set pt, our probability over the A
to be zero everywhere except at V(ft)and equal to wv(ft)everywhere else.
Lemma C.8. The above algorithm is a half-space oracle for a ball of radius ϵ.
Proof.First, note that our set of possible forecasts is compact, which guarantees that the fixed point exists.
Next, we prove that the property of the half-space oracle is satisfied. If the fixed point is in the interior of a
cell, note that:
c⊤
t(pt⊙π(y)) =/summationdisplay
v∈Vwv(ft)µt−1(v) = 0
becausectis defined to be previous vector of average payoffs, which is precisely µt−1. Edge cases would be
handled similarly to the earlier proof.
21Under review as submission to TMLR
Note that in most cases, this algorithm would not be computationally tractable. However, that is expected:
the problem is in general PPAD-hard. This question of computational tractability is what motivated our
previous definition of moment-based calibration.
Deterministic Algorithm The above procedure naturally leads to a natural randomized algorithm, where
we simply forecast the fixed point. Computationally, implementing this algorithm, requires access to an
oracle’s for Brower’s fixed-point problem (in general, this is PPAD-hard).
D Low Regret Relative to Baseline Classifiers
Here, we show that a calibrated forecaster also has small regret relative to any bounded proper loss if we use
a certain construction that combines our algorithm with a baseline forecaster.
D.1 Recalibration Construction
Setup We start with an online forecaster Fthat outputs uncalibrated forecasts pF
tat each step; these
forecasts are fed into a recalibrator such that the resulting forecasts ptare calibrated and have low regret
relative to the baseline forecasts pF
t.
Formally, at every step t= 1,2,...we have:
1:ForecasterFpredictspF
t.
2:A recalibration algorithm produces a calibrated forecast ptbased onpF
t.
3:Nature reveals label yt
4:Based onxt,yt, we update the recalibration algorithm and optionally update H.
Notation We will reuse some of the previously introduced construction based on the work of (Kakade
and Foster, 2008). Specifically, recall that we define a discretization Vof the space of forecasts. We assume
that the forecasts live in a compact set ∆and we define a triangulation of ∆, i.e., a partition into a set of
simplices such that any two simplices intersect in either a common face, common vertex, or not at all. Let V
be the vertex set of this triangulation, and let V(p)be the set of corners for this simplex.
Note that each distribution pcan be uniquely written as a weighted average of its neighboring vertices, V(p).
Forv∈V(p), we define the test functions wv(p)to be these linear weights, so they are uniquely defined
by the linear equation p=/summationtext
v∈V(p)wv(p)v. We also define the discretization to be sufficiently small: given
a target precision ϵ >0we define the discretization such that for all f1,f2in the same simplex we have
||f1−f2||<ϵ.
D.2 Recalibration Algorithm
We are going to define a general meta-algorithm that follows a construction in which we run multiple instances
of our calibrated forecasting algorithms over the inputs of F.
More formally, we take the aforementioned partition of the space of forecasts of ∆ofFand we associate each
simplex with an instance of our calibration algorithm Fcal(using the same ∆and discretization V). In order
to compute pF
t, we invoke the subroutine Fcal
jassociated with simplex Ijcontaining pF
t(with ties broken
arbitrarily). After observing yt, we pass it to Fcal
j.
The resulting procedure produces valid calibrated estimates because each Fcal
jis a calibrated subroutine.
More importantly the new forecasts do not decrease the predictive performance of F, as measured by a proper
lossℓ. In the remainder of this section, we establish these facts formally.
D.3 Theoretical Analysis
Notation Our task is to produce calibrated forecasts. Intuitively, we say that a forecast Ftis calibrated if
for everyy′∈Y, the probability Ft(y′)on average matches the frequency of the event {y=y′}. We formalize
22Under review as submission to TMLR
this by introducing the ratio
ρT(p) =/summationtextT
t=1yt·Ipt=p/summationtextT
t=1Ipt=p(20)
Intuitively, we want ρT(p)→p,a.s. asT→∞for ally. In other words, out of the times when the predicted
probability for ytisp, the average ytlook likep.
The quality of probabilistic forecasts is evaluated using properlossesℓ. Formally, a loss ℓ(y,p)is proper
ifp∈arg minq∈PEy∼(p)ℓ(y,q)∀p∈ P.An example in binary classification is the log-loss ℓlog(y,p) =
ylog(p) + (1−y) log(1−p). We will assume that the loss is bounded by B > 0.
We measure calibration a calibration error CT. Our algorithms will output discretized probabilities; hence we
define the error relative to a set of possible predictions V
CT=/summationdisplay
p∈V|ρT(p)−p|/parenleftigg
1
TT/summationdisplay
t=1I{pt=p}/parenrightigg
. (21)
D.3.1 A Helper Lemma
In order to establish the correctness of our recalibration procedure, we need to start with a helper lemma.
This lemma shows that if forecasts are calibrated, then they have small internal regret.
Lemma D.1. Ifℓis a bounded proper loss, then an (ϵ,ℓ1)-calibrated Fcala.s. has a small internal regret
w.r.t.ℓand satisfies uniformly over time Tthe bound
Rint
T= max
ijT/summationdisplay
t=1Ipt=pi(ℓ(yt,pi)−ℓ(yt,pj))≤2B(RT+ϵ). (22)
Proof.LetTbe fixed for the rest of this proof. Let Iti=Ipt=pibe the indicator of Fcaloutputting prediction
piat timet, letTi=/summationtextT
t=1Itidenote the number of time i/Nwas predicted, and let
Rint
T,ij=T/summationdisplay
t=1Iti(ℓ(yt,pi)−ℓ(yt,pj))
denote the gain (measured using the proper loss ℓ) from retrospectively switching all the plays of action ito
j. This value forms the basis of the definition of internal regret.
LetT(i,y) =/summationtextT
t=1ItiI{yt=y}denote the total number of piforecasts at times when yt=y. Observe that
we have
T(i,y) =T/summationdisplay
t=1ItiI{yt=y}=/summationtextT
t=1ItiI{yt=y}
TiTi=/summationtextT
t=1ItiI{yt=y}
/summationtextT
t=1ItiTi
=q(i,y)Ti+Ti/parenleftigg/summationtextT
t=1ItiI{yt=y}
/summationtextT
t=1Iti−q(i,y)/parenrightigg
=q(i,y)Ti+Ti(ρT(pi)−pi),
whereq(i,y) =pi(y). The last equality follows using some simple algebra after adding and subtracting one
inside the parentheses in the second term.
23Under review as submission to TMLR
We now use this expression to bound Rint
T,ij:
Rint
T,ij=T/summationdisplay
t=1Iti(ℓ(yt,pi)−ℓ(yt,pj))
=/summationdisplay
yT(i,y) (ℓ(y,pi)−ℓ(y,pj))
≤/summationdisplay
yq(i,y)Ti(ℓ(y,pi)−ℓ(y,pj)) +BTi|ρT(pi)−pi|
≤BTi|ρT(pi)−pi|,
where in the first inequality, we used ℓ(y,pi)−ℓ(y,pj)≤ℓ(y,pi)≤B, and in the second inequality we used
the fact that ℓis a proper loss.
Since internal regret equals Rint
T= maxi,jRint
T,ij, we have
Rint
T≤N/summationdisplay
i=1max
jRint
T,ij≤2BN/summationdisplay
i=0Ti|ρ(i/N)−pi|≤2B(RT+ϵ).
D.4 Recalibrated forecasts have low regret relative to uncalibrated forecasts
Next, we use the above result to prove that the forecasts recalibrated using the above construction have low
regret relative to the baseline uncalibrated forecasts.
Lemma D.2 (Recalibration preserves accuracy) .Letℓbe a bounded proper loss such that ℓ(yt,p)≤
ℓ(yt,pj) +Bϵwhenever||p−pj||≤ϵ. Then the recalibrated pta.s. have vanishing ℓ-loss regret relative to pF
t
and we have uniformly:
1
TT/summationdisplay
t=1ℓ(yt,pt)−1
TT/summationdisplay
t=1ℓ(yt,pF
t)<B
ϵM/summationdisplay
j=1Tj
TRTj+ 3Bϵ. (23)
Proof.By the previous lemma, we know that an algorithm whose calibration error is bounded by RT=o(1)
also minimizes internal regret at a rate of 2BRT, and thus external regret at a rate of 2BRT/ϵ.
Next, let us use Ij,tto indicate that Fcal
jwas called at time t. We establish our main claim as follows:
1
TT/summationdisplay
t=1ℓ(yt,pt)−1
TT/summationdisplay
t=1ℓ(yt,pF
t)
=1
TT/summationdisplay
t=1
M/summationdisplay
j=1/parenleftbig
ℓ(yt,pt)−ℓ(yt,pF
t)/parenrightbig
Ij,t

<1
TT/summationdisplay
t=1
M/summationdisplay
j=1(ℓ(yt,pt)−ℓ(yt,pj))Ij,t+Bϵ

≤1
ϵBM/summationdisplay
j=1Tj
TRTj+ 3Bϵ,
whereRTjis a bound on the calibration error of Fcal
jafterTjplays.
In the first two inequality, we use our assumption on the loss ℓ. The last inequality follows because Fcal
j
minimizes external regret w.r.t. the constant action pjat a rate of BRTj/ϵ.
24Under review as submission to TMLR
D.5 Proving that calibration holds under any norm
We want to also give a proof that the recalibration construction described above yields calibrated forecasts.
Lemma D.3. If eachFcal
jis(ϵ,ℓp)-calibrated, then the combined algorithm is also (ϵ,ℓp)-calibrated and the
following bound holds uniformly over T:
CT≤M/summationdisplay
j=1Tj
TRTj+ϵ. (24)
Proof.LetM=|V|. Let I(j)
i=/summationtextT
t=1I(j)
t,iwhere I(j)
t,i=I{pt=pj∩pF
t=pj}and note that/summationtextT
t=1It,i=
/summationtextM
j=1I(j)
i. Let alsoρ(j)
T(pi) =/summationtextT
t=1I(j)
t,iyt/summationtextT
t=1I(j)
t,i. We may write
CT,i=/summationtextT
t=1It,i
T|ρT(pi)−pi|=/summationtextM
j=1I(j)
i
T/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingleM/summationdisplay
j=1/summationtextT
t=1I(j)
t,iyt
/summationtextM
j=1I(j)
i−pi/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle
=/summationtextM
j=1I(j)
i
T/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingleM/summationdisplay
j=1I(j)
iρ(j)
T(pi)
/summationtextM
j=1I(j)
i−pi/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle≤M/summationdisplay
j=1I(j)
i
T/vextendsingle/vextendsingle/vextendsingleρ(j)
T(pi)−pi/vextendsingle/vextendsingle/vextendsingle=M/summationdisplay
j=1Tj
TC(j)
T,i,
whereC(j)
T,i=/vextendsingle/vextendsingle/vextendsingleρ(j)
T(pi)−pi/vextendsingle/vextendsingle/vextendsingle/parenleftig
1
Tj/summationtextT
t=1I(j)
t,i/parenrightig
and in the last line we used Jensen’s inequality. Plugging in this
bound in the definition of CT, we find that
CT=N/summationdisplay
i=1CT,i≤M/summationdisplay
j=1N/summationdisplay
i=1Tj
TC(j)
T,i≤M/summationdisplay
j=1Tj
TRTj+ϵ,
Since eachRTj→0, the full procedure will be ϵ-calibrated.
Recall that RTdenotes the rate of convergence of the calibration error CT. For most online calibration
subroutines Fcal,RT≤f(ϵ)/√
Tfor somef(ϵ). In such cases, we can further bound the calibration error in
the above lemma as
M/summationdisplay
j=1Tj
TRTj≤M/summationdisplay
j=1/radicalbig
Tjf(ϵ)
T≤f(ϵ)√
ϵT.
In the second inequality, we set the Tjto be equal. Thus, our recalibration procedure introduces an overhead
of1√ϵin the convergence rate of the calibration error CTand of the regret relative to a baseline forecaster in
the earlier lemma.
E Applications: Decision-Making
Next, we complement our results with a formal characterization of some benefits of calibration. Consider
a decision-task where we wish to estimate a value function v:Y×A×X→ Rover a set of outcomes Y,
actionsA, and featuresX. Note that the function vcould be a loss ℓ(y,a,x )that quantifies the error of an
actiona∈Ain a statex∈Xgiven outcome y∈Y.
We assume that given x, the agent chooses an action a(x)according to a decision-making process. This could
be an action a(x) =arg minaEy∼H(x)[ℓ(y,a,x )]that minimizes an expected loss according to the probabilities
given by the forecast. The agent then relies on a predictive model Hofyto estimate the future values
v(y,a,x )for the decision a(x):
v(x) =Ey∼H(x)[v(y,a(x),x)]. (25)
We studyv(y,a,x )that are monotonically non-increasing or non-decreasing in y. Examples include linear
utilitiesu(a,x)·y+c(a,x)or their monotone transformations.
25Under review as submission to TMLR
Expectations Under Calibrated Models IfHwas a perfect predictive model, we could estimate expected
values of outcomes perfectly. In practice, inaccurate models can yield imperfect decisions. Surprisingly, our
analysis shows that in many cases, calibration (a much weaker condition that having a perfectly specified
modelH) is sufficient to correctly estimate the value of various outcomes.
Surprisingly, our guarantees can be obtained with a weak condition—quantile calibration. Additional
requirements are the non-negativity and monotonicity of v. Our result is a concentration inequality that
shows that estimates of vare unlikely to exceed the true von average (Zhao et al., 2020).
Theorem E.1. LetMbe a quantile calibrated model as in and let v(y,a,x )be a monotonic value function.
Then for any sequence (xt,yt)T
t=1andr>1, we have:
lim
T→∞1
TT/summationdisplay
t=1I[v(yt,a(xt),xt)≥rv(xt))]≤1/r (26)
Proof.Recall that M(x)is a distribution over Y, with a density px, a quantile function Qx, and a cdf Fx.
Note that for any xands∈(0,1)andy′≤F−1
x(1−s)we have:
v(x) =/integraldisplay
v(x,y,a (x))qx(y)dy
≥/integraldisplay
y≥y′v(x,y,a (x))qx(y)dy
≥v(x,y′,a(x))/integraldisplay
y≥y′qx(y)dy
≥sv(x,y′,a(x))
The above logic implies that whenever v(x)≤sv(x,y,a ), we havey≥F−1
x(1−s)orFx(y)≥(1−s). Thus,
we have for all t,
I{v(xt)≤sv(xt,yt,at)}≤I{Fxt(yt)≥(1−s)}.
Therefore, we can write
1
TT/summationdisplay
t=1I{v(xt)≤sv(xt,yt,at)}≤1
TT/summationdisplay
t=1I{Fxt(yt)≥(1−s)}=s+o(T),
where the last equality follows because Mis calibrated. Therefore, the claim holds in the limit as T→∞
forr= 1/s. The argument is similar if vis monotonically non-increasing. In that case, we can show that
whenevery′>F−1
x(s), we havev(x)≥sv(x,y′,a(x)). Thus, whenever v(x)≤sv(x,y,a ), we havey≤F−1
x(s)
orFx(y)≤s. Because,Fxis calibrated, we again have that
1
TT/summationdisplay
t=1I{v(xt)≤sv(xt,yt,at)}≤T/summationdisplay
t=1I{Fxt(yt)<s}=s+o(T),
and the claim holds with r= 1/s.
Note that this statement represents an extension of Markov inequality. Note also that this implies the same
result for a distribution calibrated model, since distribution calibration implies quantile calibration.
F Additional Experimental Details
Experiments were run on CPU on a MacBook Pro with an M2 chip and 64 GB of memory. The results in
our experiments were generated using 6 hours of compute.
26