Under review as submission to TMLR
Respecting the limit:
Bayesian optimization with a bound on the optimal value
Anonymous authors
Paper under double-blind review
Abstract
In many real-world optimization problems, we have prior information about what objective
function values are achievable. In this paper, we study the scenario that we have either
exact knowledge of the minimum value or a, possibly inexact, lower bound on its value. We
proposebound-aware Bayesian optimization (BABO), a Bayesian optimization method that
uses a new surrogate model and acquisition function to utilize such prior information. We
present SlogGP, a new surrogate model that incorporates bound information and adapts the
Expected Improvement (EI) acquisition function accordingly. Empirical results on a variety
of benchmarks demonstrate the benefit of taking prior information about the optimal value
into account, and that the proposed approach significantly outperforms existing techniques.
Furthermore, we notice that even in the absence of prior information on the bound, the
proposed SlogGP surrogate model still performs better than the standard GP model in
most cases, which we explain by its larger expressiveness.
1 Introduction
For many real-world black-box optimization problems, evaluating a solution can be computationally expen-
sive, and optimization algorithms thus need to be sample efficient. Bayesian optimization (BO) is a global
optimization method suitable for such problems (Brochu et al., 2010; Shahriari et al., 2015; Garnett, 2023).
Due to its data efficiency, it is widely used in many areas, such as protein design (Stanton et al., 2022), chem-
istry (Folch et al., 2022), robotics design (Calandra et al., 2016) and hyperparameter tuning (Cho et al.,
2020).
While BO typically assumes the objective function f(x)to be a black-box, in some real-world applications,
additional information about the achievable optimal value is available. For instance, in hyperparameter tun-
ing, the error rate of a model is always larger than or equal to 0%. In physical experiments, the temperature
must be greater than or equal to −273.16◦C, and the electric resistance must be greater than or equal to
0 Ω.
Intuitively, exploiting such information should be helpful. The first BO paper that takes such information
into account is Hutter et al. (2009), who point out that a log transformation of positive functions is usually
beneficial. Other recent works that may take output bound information into consideration are Nguyen &
Osborne (2020); Wang et al. (2018); Nguyen et al. (2021); Jeong & Kim (2021).
Inthispaper,wefocusonBOforminimizationwithaknownlowerbound fbontheunknownoptimalfunction
valuef∗, i.e.,f∗≥fb. We propose a new algorithm, bound-aware Bayesian optimization (BABO), which
makes use of this lower bound information to improve efficiency in BO. BABO is based on a novel surrogate
model,Shifted Logarithmic Gaussian Process , or SlogGP, which can take into account prior information
on a lower bound of the objective function. SlogGP is defined as f(x) =eg(x)−ζ, whereg(x)is a GP
andζis a learnable parameter. As the resulting predictive distribution is no longer normal, we adapt
the well-known expected improvement (EI) acquisition function to SlogGP, resulting in SlogEI. We then
show how SlogEI can be further modified to also take into account the information on the lower bound
of the objective function. We call this new acquisition function Shifted Logarithmic Truncated Expected
Improvement (SlogTEI). Combining SlogGP and SlogTEI, we obtain BABO.
1Under review as submission to TMLR
WefindthatSlogGPwithSlogEIcanoutperformastandardGPwithEIinBOevenifthereisnoinformation
on the bounds of the objective function, primarily due to its larger expressiveness, where expressiveness refers
to the ability of a model to represent a wide range of functions or patterns in the data. Incorporating lower
bound knowledge into SlogGP and using SlogTEI (BABO) can further enhance its performance. We evaluate
the proposed framework on several synthetic functions as well as two real-world applications. Empirical
results demonstrate that our new method outperforms conventional BO and other algorithms designed for
the case of a known lower bound.
The structure of this paper is as follows. Section 2 gives an introduction to Bayesian optimization and
surveys the literature on BO with lower bound information. In Section 3, we introduce the SlogGP model
and the corresponding acquisition function in the known-bound as well as the unknown-bound case. SlogGP
and SlogTEI together form BABO, our bound aware Bayesian optimization. We also prove that SlogGP is
more flexible than GP, which can explain the superior performance of SlogGP over GP even in the absence
of lower bound information. Section 4 reports on the experimental results, demonstrating the empirical
advantage of using BABO when a lower bound is known. The paper concludes with a summary and some
avenues for future work.
2 Preliminaries
2.1 Bayesian Optimization
Bayesian optimization (BO) is a sequential strategy for global optimization of black-box functions. Given
an objective function f(x)and the feasible set X, the goal of BO is to find an optimal solution x∗∈
argminx∈Xf(x).
BO consists of two main steps. The first step is to build a surrogate model based on historical observations
{(x1,y1),...,(xN,yN)}. A common choice for the surrogate model is a GP, though other models have been
proposed, including random forest (Hutter et al., 2011), deep neural network (Snoek et al., 2015) and
Mondrian trees (Wang et al., 2018). For more information on Gaussian processes, we refer to Rasmussen &
Williams (2006) and Schulz et al. (2018).
The second step involves using the surrogate model for selecting the solution to be evaluated next, balancing
the mean and variance predicted by the surrogate model, which is known as the exploration-exploitation
trade-off. In BO, this balance is achieved by optimizing a so-called acquisition function α. A common choice
is Expected Improvement (EI) (Mockus, 1998). The information from the newly evaluated solution is then
added to the set of observations and the surrogate model is updated before the next iteration.
2.2 Acquisition functions for f∗≥fb
If we have prior information that the global minimum f∗:= minxf(x)is at least fb, then we can try
to adjust the acquisition function to make use of the information. For Max-value Entropy Search (MES)
introduced by Wang & Jegelka (2017) this is straightforward and has already been used as baseline in
Nguyen & Osborne (2020) and Wang et al. (2018). MES selects the next solution to evaluate where it
expects the largest reduction in entropy of the predicted distribution of the optimal objective value. It does
not assume prior knowledge about the optimal value, but uses Gumbel Sampling to sample a realization
off∗from the posterior. However, according to Wang et al. (2018), given a lower bound fbon the minimum
valuef∗, we may calculate MES as αMESb/parenleftbig
x|fb/parenrightbig
=γ(x,fb)ϕ[γ(x,fb)]
2Φ(γ(x,fb))−log Φ/parenleftbig
γ/parenleftbig
x,fb/parenrightbig/parenrightbig
, whereγ/parenleftbig
x,fb/parenrightbig
=
µ(x)−fb
σ(x),ϕ(·)andΦ(·)are the PDF and CDF of the standard normal distribution. Note that this analytical
expressionforMESdoesnotrequireMonteCarlosampling. Inaddition, weshowinAppendixA.1thatMESb
shares the same maximizer with the acquisition function P(f(x)< fb), i.e. argmaxx∈XαMESb/parenleftbig
x|fb/parenrightbig
=
argmaxx∈XP(f(x)<fb).
2Under review as submission to TMLR
2.3 Models for f∗≥fb
Besides in acquisition functions, we can attempt to incorporate the information into surrogate models.
Hutter et al. (2009; 2011) find that employing log-transformation as a preprocessing step for positive-valued
functions, combined with a correspondingly adapted EI acquisition function, can enhance the performance of
BO. When shifting the function to be positive given the information about the lower bound, this is similar to
our SlogGP model with a fixed rather than learnable ζ, and we will later show that it performs significantly
worse than our model. Jeong & Kim (2021) propose the objective bound conditional Gaussian process
(OBCGP). OBCGP introduces a parameter xM, and conducts Gaussian process regression conditioned on
(xM,f(xM))through variational inference. In cases where the lower bound fbis known, we can enforce the
distribution of f(xM)to adhere to this known bound. Nguyen & Osborne (2020) focus on the case when the
exact value of the optimum f∗is known, which can be viewed as a special case of known bound. A parabolic
Gaussian process model1
2g2(x)−f∗(Gunter et al., 2014) is used. To guarantee an analytical form of the
posterior distribution, a linearization is applied, so the final model is −1
2µ2
g(x) +µg(x)g(x)−f∗. It should
be noted that while the range of the parabolic Gaussian process is [fb,∞), after linearization, the model
becomes a GP and samples no longer adhere to the bound. Second, the transformation of the GP inflates the
predictive uncertainty at points with low predicted mean, which causes sampling of EI and UCB to be too
greedy. They therefore propose two new acquisition functions: Confidence Bound Minimization (CBM) and
Expected Regret Minimization (ERM). Finally, the acquisition functions can only be used with tight bound
but not with a more general bound, though the latter is more common. To solve this last issue, Nguyen et al.
(2021) extend the model of Gunter et al. (2014) to a case where only a probability distribution for the lower
bound of the objective function is known, and propose a new acquisition function called Bounded Entropy
Search (BES). However, the other issues of linearly approximating the parabolic Gaussian processes remain.
Another candidate surrogate for the case of a known lower bound fbwould be a non-negativity GP (Pen-
soneault et al., 2020). This method uses a GP as its model but introduces constraints to the hyperparameter
tuning process, enforcing the probability of each f(x)crossing the known bound to be below 5%. However,
this method faces a couple of challenges. First, it is primarily suitable for low-dimensional problems due to
its computational cost. Second, the range of the non-negativity GP remains (−∞,∞), which means that
there is still a mismatch with the desired range [fb,∞)of feasible objective values.
The primary issue of the above-mentioned models is their inability to properly model that the function fis
known to take values in the range [fb,∞). Jensen et al. (2013) proposed regression models using truncated
distribution (GP-TG) or Beta distribution (GP-BE) that have the desired range but lack an analytical form
for posterior inference. They use a Laplace approximation for the surrogate model. Additionally, Monte
Carlo sampling would be needed for the acquisition function if this model were used in a BO framework.
The method presented in this paper has a closed form and thus does not require costly approximations.
3 Bound-aware Bayesian optimization
In this section, we present the Bound-aware Bayesian optimizer (BABO) and its two key components: the
surrogate model, Shifted Logarithmic Gaussian Process (SlogGP) that can leverage a lower bound fbabout
the global minimum f∗if available, and the corresponding acquisition function Shifted Logarithmic Truncated
Expected Improvement (SlogTEI).
3.1 The SlogGP Surrogate Model
The SlogGP model for an objective function f(·)is:
f(x) =eg(x)−ζ,
whereg(x)is a GP and ζis theshift, a parameter that is learned from data during model fitting.
3Under review as submission to TMLR
This model can also be expressed as ln(f(x) +ζ) =g(x). When training the model, we set the mean of
g(x)to be the mean of the warped observed function values, i.e. the mean of g(x)is/summationtextN
i=1ln(yi+ζ)
Nand
y= [y1,....,yN]Tis the observations.
The model can be viewed as a type of warped Gaussian process (Snelson et al., 2003), so we can learn the
hyperparameters and parameters of the model, in particular the hyperparameters of the covariance function
and shiftζby minimizing the negative log likelihood with respect to y= [y1,....,yN]T:
L=1
2ln(det K) +1
2W(y)⊤K−1W(y)−N/summationdisplay
i=1ln/parenleftbiggN−1
N·1
yi+ζ/parenrightbigg
+N
2ln(2π)
where Kis the covariance matrix and W(y) = ln(y+ζ)−/summationtextN
i=1ln(yi+ζ)
N.
The SlogGP model f(x) =eg(x)−ζcan be viewed as combining aspects of a parabolic GP f(x) =1
2g2(x)−ζ
(Gunter et al., 2014; Ru et al., 2018; Nguyen & Osborne, 2020) and a log-transformed GP f(x) =eg(x)
(Hutter et al., 2009; 2011). By integrating these two methods, the SlogGP model offers several advantages.
Specifically, in comparison to log-transformed GPs, SlogGPs can be utilized without requiring any lower
boundinformationandexhibitgreaterexpressivenessduetothelearnableshiftparameter ζ. Whencompared
to parabolic GPs, SlogGPs do not require any approximation and can guarantee an analytical form of the
acquisition function (see Section 3.3). More importantly, as demonstrated in Section 3.2, SlogGPs possess
greater expressiveness than standard GPs, given limited observation, a property that the other two models
lack.
To the best of our knowledge, it is the first time that this model is proposed for handling known lower bound
conditions. Additionally, we find that SlogGP-based BO outperforms GP-based BO even without any bound
information, which we attribute to the enhanced expressiveness of SlogGPs.
3.2 Properties of the SlogGP Model
We begin with the case that we do nothave a lower bound f∗≥fband show that a SlogGP is more general
than a standard GP. In fact, as Theorem 3.1 shows, a SlogGP is reduced to a standard GP under certain
conditions.
Note that a covariance function Kcan be written as K(x1,x2) =σ2
g·k(x1,x2|θg), whereσgis a scaling
hyperparameter called signal variance. θgare other hyperparameters that are independent of σg. For a
noiseless GP, the covariance between x1andx2isCov(x1,x2) =K(x1,x2).
Theorem 3.1. Define a SlogGP f(x) =eg(x)+µg−ζwithg(x)a Gaussian process with zero mean, zero
noise and a covariance function Kwith signal variance σ2
gand other hyperparameters θg.
Then for any GP h(x)with mean ˜µg, signal variance ˜σg, and other hyperparameters ˜θg, we can have the
SlogGPf(x)converge to h(x)in distribution for any x∈Xby setting


µg= ln (ζ+ ˜µg)
θg=˜θg
σg=˜σg
ζ+ ˜µg
and letting ζ→∞, i.e.,
lim
ζ→∞Pf(x)(z) =Ph(x)(z)∀z∈(−ζ,∞),∀x∈X,
whereP(·)denotes the probability density function of a random variable.
The proof for Theorem 3.1 can be found in Appendix A.3.
Hence, in the limit, a GP is a special case of a SlogGP. Under the conditions specified in Theorem 3.1,
asζ→∞, the lower bound −ζtends to negative infinity and the skewness converges to zero, causing
4Under review as submission to TMLR
the distribution to converge to a Gaussian distribution. This relationship is unidirectional: while SlogGP
can approximate a GP by setting its skewness parameter near zero, a symmetric GP inherently lacks the
flexibility to approximate a skewed SlogGP distribution.
Figure 1 illustrates Theorem 3.1 by showing 200 samples from SlogGPs and GPs with three different covari-
ance functions: RBF, Matern32 and Brownian. The left column contains samples from GPs. The middle
column contains samples from SlogGPs whose parameters satisfy Theorem 3.1 (considering ζ→∞cannot
be achieved numerically, we set ζto be a large number ζ:= 100) to approximate the GPs on the left side.
The right column contains SlogGPs with ζ= 0.5. We can see that the posterior distributions of the left and
the middle are very close. If the shift ζis not that large, we find that the distribution is more skewed, as is
shown in the right side.
0.0 0.2 0.4 0.6 0.8 1.01
0123RBF 
 yGP
0.0 0.2 0.4 0.6 0.8 1.01
0123SlogGP (=100)
0.0 0.2 0.4 0.6 0.8 1.01
0123SlogGP (=0.5)
0.0 0.2 0.4 0.6 0.8 1.01
0123Matern32 
 y
0.0 0.2 0.4 0.6 0.8 1.01
0123
0.0 0.2 0.4 0.6 0.8 1.01
0123
0.0 0.2 0.4 0.6 0.8 1.0
x1
0123Brownian 
 y
0.0 0.2 0.4 0.6 0.8 1.0
x1
0123
0.0 0.2 0.4 0.6 0.8 1.0
x1
0123
Figure 1: Example of surrogate models (1D) for (left) a normal GP (center) a SlogGP with the shift ζ:= 100
and parameters set according to Theorem 3.1 to match the normal GP, and (right) a SlogGP with with the
shiftζ:= 0.5.
3.3 An adaptation of EI to the SlogGP Model
Expected improvement (EI) is a popular acquisition function. Recall that for a GP model, the posterior
predictive distribution of function values at any particular location xis Gaussian and thus EI has a simple
analytical form. However, for SlogGP, the posterior predictive distribution is no longer Gaussian and hence
we have to adapt EI.
We derive a closed-form expression for Expected Improvement under the proposed surrogate model, which
we term Shifted Logarithmic Expected Improvement (SlogEI):
αSlogEI(x;fmin) = (fmin+ζ)·Φ/parenleftbiggln(fmin+ζ)−µ(x)
σ(x)/parenrightbigg
−eµ(x)+σ2(x)
2·Φ/parenleftbiggln(fmin+ζ)−µ(x)−σ2(x)
σ(x)/parenrightbigg
.
Note that for ζ:= 0, SlogEI becomes the acquisition function by Hutter et al. (2011). The calculation of
this acquisition function is detailed in Appendix A.2. Furthermore, when the posterior mean and variance
5Under review as submission to TMLR
ofg(x)are differentiable with respect to x, the SlogEI acquisition function inherits this differentiability.
The corresponding gradient calculations are also provided in Appendix A.2, along with an adaptation of the
popular Probability of Improvement acquisition criterion.
In Figure 2, we compare GP+EI and SlogGP+SlogEI empirically on objective functions that are drawn from
a GP model, shown in the left plot, and a SlogGP model as shown in the right one. The hyperparameters
of both methods are fit to data. We observe that both methods perform similarly when the objective
functions are sampled from a GP. When fis sampled from a SlogGP, the performance of GP+EI degrades
substantially. This observation is consistent with the theoretical property shown above that a SlogGP
model can approximate a GP sample, but not vice versa. We also performed a cross-validation test on the
prediction error of the two surrogate models, see Table 1. When the objective function is a GP, SlogGP and
GP are equally good in prediction while when the objective function is a SlogGP, SlogGP achieves a better
cross-validation error. Please see Appendix A.4 for details about the experimental setup.
Table 1: Cross-validation test. The column determines the test function and the row the choice of the
surrogate model. The cells give the prediction error of the surrogate.
GP SlogGP
GP 0.828(±0.0801) 6.21(±1.16)
SlogGP 0.841(±0.0802) 1.414(±0.287)
0 10 20 30 40 50
iteration0.000.250.500.751.001.251.501.752.00simple regretGP 2D
GP+EI
SlogGP+SlogEI
0 10 20 30 40 50
iteration0.000.050.100.150.200.250.300.35SlogGP 2D
GP+EI
SlogGP+SlogEI
Figure 2: Within-model Test. The left panel shows the performance of GP+EI and SlogGP+SlogEI on
GP generated functions, while the right panel compares the two algorithms on SlogGP generated functions.
While both models work equally well on GP generated functions, only the SlogGP model works well on the
SlogGP generated functions.
Next we show how the lower bound information f∗≥fbcan be incorporated into the SlogGP surrogate
model. Then we present a novel acquisition function called SlogTEI that also leverages the lower bound fb.
3.4 Incorporating a lower bound on the minimum into SlogGP
An advantage of the SlogGP model is that it allows to enforce a lower bound through its parameter ζ. On
the other hand, the skewness introduced may not be a very good fit to the observed data, creating a possible
conflict between setting ζto a value that best represents the bound information, and setting ζto a value
that best matches the observed data.
To solve this potential conflict, we use a maximum a posteriori (MAP) estimate for ζand include the bound
information only as prior. Furthermore, we implemented some mechanisms that allow to quickly reduce the
reliance on the prior if the observed mismatch between prior and fit to the data is very large. The details of
how we choose ζare explained in the following.
6Under review as submission to TMLR
When the lower bound fbis known, a straightforward way is to set ζ=−fb. However, this method will
suffer when the prior information is not accurate enough or would otherwise lead to a model mismatch. For
instance, suppose that the known objective function is SlogGP f(x) =eg(x)+ 10, and the prior information
isf(x)>0. In this case, the prior information is correct, but if we enforce ζ= 0, there will be a model
mismatch. Thus, any information about the lower bound should only guide, but not dictate ζ. A natural
way is to use a maximum a posteriori probability (MAP) estimate for the parameter ζ. We choose the prior
distribution to be a shifted log-normal distribution to guarantee that −ζ <fmin, wherefminis the current
best value and−ζis the lower bound of the model, so that the model is well-defined:
ζ∼−fmin+eZ,
whereZ∼N(ln(fmin−fb),2 ln(fmin−fb+δ1)−2 ln(fmin−fb)), andδ1is a positive hyperparameter. We
set the mean and variance of Zsuch that the median of −ζequals the known lower bound fband the mean
of−ζequalsfb−δ1. The selection of δ1is flexible, requiring only a small positive value. In our experiments,
we setδ1= 0.1.
Sometimes, there can be a prior-data conflict, where the prior information is inconsistent with observation
data. Specifically, in SlogGP, prior-data conflict is detected when the estimated lower bound −ˆζis distant
from the known lower bound fb. Note that in this paper, we distinguish ζandˆζ:ζis an unknown parameter
while ˆζis its estimator. To handle a prior-data conflict, we introduce an uncertainty level and variance
threshold.
When we observe the MAP estimator −ˆζis distant from the known bound, we reduce our confidence
through uncertainty level U. Specifically, we use an uncertainty level Uto control the variance of Zto
beU2·2(ln(fmin−fb+δ1)−ln(fmin−fb))so that as the uncertainty level increases, the prior bound
information becomes weaker. Thus, the prior distribution ζpriorbecomes:
ζ∼−fmin+eZ
whereZ∼N(ln(fmin−fb),U2(2 ln(fmin−fb+δ1)−2 ln(fmin−fb))).
Initially, the uncertainty level is set to be U= 1. IfFζprior(ˆζ)< δ2orFζprior(ˆζ)>1−δ2(Fζprioris the
cumulative density function of ζpriorandδ2is a hyperparameter) holds, then we interpret this as indication
of a conflict between the prior information and the observed data. In this event, we re-train the surrogate
model by maximum likelihood estimation (MLE) as the MAP depends on the prior information that we
now consider unreliable. In the next iteration, we increase the uncertainty level Uby multiplying with
|ϕ−1(Pζprior(ζ=ˆζ))|. In terms of choice of δ2, in this paper, we set δ2= 0.01.
Additionally, we will not use the prior information when the estimated signal variance is smaller than a
given threshold. While ideally, we would exclude prior information when the estimated lower bound −˜ζ
significantly deviates from the known lower bound fb(i.e., when|−˜ζ−fb|exceeds a threshold), setting
a universal threshold is challenging due to the varying ranges of objective functions. Instead, we leverage
Theorem 3.1, which establishes that σg= ˜σg/(ζ+ ˜µg)→0asζ→∞. Consequently, we use the estimated
signal variance σ2
gas an indicator for incorporating bound information. Specifically, to prevent prior-data
conflict, we disregard bound information when σ2
g<δ3, where we set δ3= 0.252in our experiments.
Figure 3 illustrates the differences between a GP model and a SlogGP model with the prior knowledge of
f∗.
3.5 Incorporating knowledge of f∗≥fbinto the acquisition criterion
A potential drawback of SlogEI is that the improvement is calculated over the range (−ˆζ,fmin], where
the estimate−ˆζcan be smaller than the known lower bound fb. Thus, the Shifted Logarithmic Trun-
cated Expected Improvement (SlogTEI) acquisition criterion truncates any impossible value below fbwhen
calculating SlogEI:
αSlogTEI(x;fmin,fb) =αSlogEI(x;fmin)−αSlogEI(x;fb).
Notethatiftheestimate ˆζislargerthantheknownlowerbound, i.e −ˆζ >fb,αSlogTEI(x)becomesαSlogEI(x).
Additionally, SlogTEI is differentiable as it is the difference of two differentiable acquisition functions.
7Under review as submission to TMLR
0.0 0.2 0.4 0.6 0.8 1.0
x1
012345y(x)
observation
95% confidence interval
known lower bound
0.0 0.2 0.4 0.6 0.8 1.0
x1
012345
(x)
observation
95% confidence interval
known lower bound
Figure 3: The predictive posterior distribution of the SlogGP model respects the known lower bound. (l)
shows a GP surrogate model; (r) shows a SlogGP surrogate model with known lower bound.
Algorithm 1 BABO (SlogGPb+SlogTEI)
Initial data points D0and uncertainty level U= 1
Known lower bound fb
forn= 0toTdo
Set prior distribution ζprior: Eq. 3.4
Train a surrogate model ˆf(·)by MAP withDnand prior distribution ζprior
ifFζprior(ˆζ)<δ2orFζprior(ˆζ)>1−δ2then
Train a surrogate model ˆf(·)by MLE withDn
U∗=|ϕ−1(Pζprior(ζ=ˆζ))|
end if
ifˆfis trained by MAP and ˆσ2
g<δ3then
Train a surrogate model ˆf(·)by MLE withDn
end if
Findxn+1= arg maxx∈X{αSlogTEI(x)}
Evaluate the objective function yn+1=f(xn+1)
UpdateDn+1=Dn∪{xn+1,yn+1}
end for
We summarize the BABO method that uses the SlogGPbsurrogate and the SlogTEI acquisition criterion in
Algorithm 1, where the superscript bmeans that the SlogGP is trained with lower bound information.
Note that BABO can be straightforwardly extended to batch acquisition by adapting the qEI idea
from Ginsbourger et al. (2008). The acquisition function value αqSlogTEI(X;fmin,fb)for a batch
of solutions X= (x1,...,xq)is calculated by Monte Carlo simulation: αqSlogTEI(X;fmin,fb) =
1
NMC/summationtextN
i=1maxj=1,...,q/braceleftig
(fmin−ξij)+−/parenleftbig
fb−ξij/parenrightbig+/bracerightig
,where (·)+denotes the positive part function, NMCis
the number of samples and ξi∼P(f(X)|D).
Similarly, we propose Truncated Expected Improvement (TEI) for vanilla GPs, an adaptation of Expected
Improvement (EI) that uses a lower bound fbon the global minimum. When we know that the lower bound
isfb, we truncate the distribution of f(x)atfband calculate TEI as
αTEI(x;fmin,fb) =/integraldisplayfmin
fb(fmin−z)·ϕ/parenleftbiggz−µ(x)
σ(x)/parenrightbigg
dz
=E[(fmin−f(x))+]−E[(fb−f(x))+]
TEI will serve as a benchmark algorithm in our experiments.
8Under review as submission to TMLR
4 Experiments
In this section, we compare performance of BABO with other benchmark algorithms across various test
functions. The competing methods are:
•Random (Bergstra et al., 2011): randomly choosing the next solution.
•EI (Mockus, 1998): using Expected Improvement (EI) as the acquisition function
•TEI: using Truncated EI, see Section 3.5
•MESb(Wang et al., 2018): adapted max-entropy search, see Section 2.2
•OBCGP (Jeong & Kim, 2021): OBCGP follows the paper by Jeong & Kim (2021). The origi-
nal implementation of Jeong & Kim (2021) lacks version information and depends on deprecated
packages no longer available through pip. We have updated the codJeong & Kim (2021)ebase to
utilize current package versions and fixed existing bugs. We will release our implementation upon
acceptance of this paper.
•ERM (Nguyen & Osborne, 2020): Our parabolic GP+ERM algorithm follows the method of Nguyen
& Osborne (2020) and the code shared by the authors. Initially, we employ the regular GP+EI
until the lower confidence bound (LCB) reaches the known lower bound. Subsequently, we switch
to the transformed GP+ERM algorithm. This ensures a seamless integration between the two
methods, allowing for an effective exploration-exploitation trade-off during the optimization process.
In addition, following their code, if the next evaluation xn+1is too close to an existing observation
(1-norm distance smaller than 3d·10−4), we will pick a random xinstead. The hyperparameter β
of LCB is set to be/radicalbig
ln(N).
We also fix−ζ=fbin BABO to understand the benefit of learning ζ. Note that when −ζ=fb, SlogTEI
will become equivalent to SlogEI, and BABO with fixed ζcan be viewed as an extension of the method in
Hutter et al. (2011) where in a preprocessing step the function is shifted into the positive region based on
the information of the lower bound. We evaluate the algorithms on eight synthetic functions that are widely
used in BO testing as well as two real-world problems. In addition, we compare qBABO with qEI on two
synthetic functions with different batch sizes and the results are shown in Figure 15 in Appendix A.5. We
will publish the code when the paper is accepted.
Following the experimental setting in Nguyen & Osborne (2020); Jeong & Kim (2021), we assume noise-free
observations in experiments. Additionally, as discussed in Section 3, the hyperparameters of BABO are set
to be (δ1,δ2,δ3) = (0.1,0.01,0.252). Plots show the simple regret (mean ±one standard error) over 100
repetitions for all functions except 50 repetitions for the 10d function. For improved visualization, some
results are presented using logarithmic scales on the y-axis, as indicated by their y-axis scale. Appendix A.4
gives more details of the experimental setup.
4.1 Synthetic Test Functions
We compare the performances on eight synthetic functions with 2 to 10 dimensions where we have an exact
bound on the minimum objective value. The known lower bound is thus set to the minimal value of the
objective function, i.e., fb:=f∗, which is also the setting for which ERM was proposed.
Figure 4 summarizes the performances. Dashed lines indicate algorithms that do not use any information
aboutf∗, whereas solid lines correspond to methods that do leverage bound information. We observe that
BABO (black line) usually achieves substantially better objective values at the same iteration than the other
algorithms. An exception is the Ackley (6D) benchmark where OBCGP achieves better values and BABO
comes in second.
9Under review as submission to TMLR
0 20 40 60 80 100
iteration104
103
102
101
100101simple regretBranin 2D
0 20 40 60 80 100
iteration102
101
100101Beale 2D
0 20 40 60 80 100
iteration103
102
101
100SixHumpCamel 2D
0 20 40 60 80 100
iteration103
102
101
100Hartmann 3D
0 20 40 60 80 100 120 140
iteration100101102simple regretRosenbrock 4D
0 20 40 60 80 100 120 140
iteration2.55.07.510.012.515.017.520.0Ackley 6D
0 20 40 60 80 100 120 140
iteration101102103Powell 8D
0 25 50 75 100 125 150 175 200
iteration406080100120140160StyblinskiT ang 10D
Random EI TEI MESbOBCGP ERM BABO (fixed )
 BABO
Figure 4: Experiment Results (Synthetic Functions): We observe that BABO works best except in Ackley
(6D), where OBCGP works better.
4.2 The Skin Segmentation Task
In the Skin Segmentation benchmark (Nguyen & Osborne, 2020), the goal is to optimize six hyperparameters
of an XGBoost model (Chen & Guestrin, 2016) to accurately identify whether given pixels correspond to
skin. The accuracy achieved by a hyperparameter setting on a hold-out dataset gives the objective value,
hence the objective function has a natural upper bound of 100%. The six hyperparameters are min child
weight, colsample bytree, max depth, subsample, alpha, and gamma.
Figure 5(a) shows that BABO obtains better settings at the same iteration and converges to a near optimal
solution more quickly. The runner-up is BABO with fixed ζ. Interestingly, the standard GP+EI approach
that does not use the prior information about f∗works better than some existing methods that do use it,
i.e. ERM and MESb.
4.3 The Robot Push Problem
The goal of the 4DRobot Push problem (Wang & Jegelka, 2017; De Ath et al., 2021) is to direct a robot
to push a ball towards an unknown target, minimizing the distance between the ball and the target. The
distance is nonnegative and thus implies a lower bound of zero for f∗. The first input variables determine
the initial location of the robot, the third determines the angle of its rectangular hand, and the fourth sets
the number of time-steps that the robot is to move.
Figure 5(b) shows that BABO achieves better solutions at the same iteration and converges more quickly.
The runner-up is TEI that also uses our truncated EI acquisition function but a regular GP surrogate model.
To summarize the experimental results, we ranked the algorithms based on their mean at the final iteration,
as shown in Table 4.3.
5 Investigating the influence of prior information on the optimum
In this section, we study the influence of prior information about f∗. First, we conduct an ablation study
and observe that leveraging prior information about the optimum in model training and acquisition function
is beneficial. Then, we investigate why we need the uncertainty level and variance threshold when using
10Under review as submission to TMLR
0 10 20 30 40 50
iteration98.0098.2598.5098.7599.0099.2599.50accuracy
(a)Skin Segmentation 6D
Random
EI
TEI
MESb
OBCGP
ERM
BABO (fixed )
BABO
0 20 40 60 80 100
iteration101
100distance
(b)Robot Push 4D
Random
EI
TEI
MESb
OBCGP
ERM
BABO (fixed )
BABO
Figure 5: An empirical evaluation of BABO and competitors on two real-world benchmarks. We observe
that BABO achieves significantly better solutions throughout the run.
Table 2: Performance Rank
Branin BealeSixHumpCamel Hartmann Rosenbrock Ackley Powell StyblinskiTang SkinRobert Average
BABO 1 1 1 2 1 2 1 1 1 1 1.2
BABO (fixed ζ)3 2 2 5 5 6 2 2 23 3.2
TEI 6 8 5 3 4 4 3 3 52 4.3
EI 4 4 4 4 3 5 7 4 36 4.4
MESb5 7 6 1 2 7 4 5 45 4.6
ERM 2 3 3 6 6 3 5 6 67 4.7
OBCGP 7 5 7 7 7 1 6 7 84 5.9
Random 8 6 8 8 8 8 8 8 88 7.8
bound information in model training. Finally, we investigate how SlogGPbis influenced by its estimated
lower bound−˜ζand lower bound information.
5.1 The Contributions of Different Components
To better understand how different components of BABO contribute to its success, we compare the following
settings:
•SlogGP+SlogEI: Removing the bound information usage in both SlogGP and acquisition function.
This will tell us how helpful the lower bound information really is.
•SlogGPb+SlogEI: Removing bound information from the acquisition function only. This will show
therelativeimportanceofusingboundinformationintheSlogGPmodelandtheacquisitionfunction.
•SlogGP+SlogTEI: Removing bound information from the model only. This will show the relative
importance of using bound information in the SlogGP model and the acquisition function.
Looking at the results on the eight synthetic test functions in Figure 6 and two real-life problems in Figure
8, the full BABO performs best, often followed closely by the version using the bound information only in
the SlogGP model or the version using the bound information only in the acquisition function, and then
the version not using bound information at all. The standard GP+EI usually did quite poorly, except
for the Hartmann 3D function where all methods share similar performance. An additional observation is
that SlogGP+SlogEI (not using bound information) works better than GP+EI, which can be explained by
SlogGP’s larger expressive power, as shown in Theorem 3.1.
We now analyze the estimated shift parameter −˜ζ, with its median values shown in Figure 7 and 9. The
estimated lower bounds corroborate our ablation study findings, as demonstrated in two real-world bench-
marks. For the Skin Segmentation task (Figure 8(a)), SlogGP+SlogEI outperforms GP+EI. This aligns with
our expectations since the estimated lower bound of 0.1%(rather than a highly negative value) indicates
11Under review as submission to TMLR
function skewness, favoring SlogGP over GP. The proximity between this estimate and our known lower
bound (fb:= 0%) enables rapid convergence to the optimal lower bound, enhancing BO performance. In
the Robot Push problem (Figure 8(b)), bound information similarly proves advantageous. Figure 9(b) shows
convergence of−˜ζto approximately −0.5, close to the known bound fb. This proximity accelerates ˜ζlearn-
ing and improves overall BO performance. The synthetic functions exhibit similar patterns. In the Beale
function, for example, the known lower bound fb= 0approximates the convergence value of 3, enabling
rapid SlogGP model learning and consequently enhancing BO performance.
0 20 40 60 80 100
iteration104
103
102
101
100101simple regretBranin 2D
0 20 40 60 80 100
iteration102
101
100101Beale 2D
0 20 40 60 80 100
iteration104
103
102
101
100SixHumpCamel 2D
0 20 40 60 80 100
iteration103
102
101
100Hartmann 3D
0 20 40 60 80 100 120 140
iteration100101102simple regretRosenbrock 4D
0 20 40 60 80 100 120 140
iteration468101214161820Ackley 6D
0 20 40 60 80 100 120 140
iteration101102103Powell 8D
0 25 50 75 100 125 150 175 200
iteration406080100120140160StyblinskiT ang 10D
GP+EI GP+TEI SlogGP+SlogEI SlogGPb+SlogEI SlogGP+SlogTEI BABO
Figure6: DifferentComponentsComparison(SyntheticFunctions): Generally, thecompleteBABOapproach
demonstrates superior performance, suggesting that incorporating bound information in both the modeling
and acquisition function stages is beneficial.
5.2 Using bound information in model training
When the bound information is available, we use MAP to allow use of this information, and uncertainty level
and variance threshold to allow BAO to ignore the bound information if it would lead to a model mismatch.
A possible question is whether it is necessary to handle the prior-data conflict explicitly. To answer this
question, we compare the following settings with SlogTEI:
•Using MAP only
•Using MAP and the uncertainty level
We do experiments on two objective functions: Branin 2D and Ackley 6D. The results are shown in Figure 10.
On the Branin function, their performance is almost identical at the beginning while MAP-only is slightly
worse later on. This is because when we have enough data, we can estimate the underlying lower bound
accurately even if the prior information can be slightly misleading. For the Ackley function, MAP is worse
than MAP+uncertainty level which in turn is worse than BABO. This is because the best fitting −ˆζof
SlogGP is very negative (as shown in Figure 7), so fb= 0conflicts with observation data and not using the
bound information is a better choice.
5.3 The influence of lower bound information in SlogGP-based BO
We first test how different known lower bound information fbinfluences BABO performance. We test on
three objective functions: Branin, Beale and Hartmann. Our experimental results in Figure 11 demonstrate
12Under review as submission to TMLR
0 20 40 60 80 100
iteration25
20
15
10
5
05lower boundBranin 2D
no bound information
bound information
0 20 40 60 80 100
iteration4
2
024lower boundBeale 2D
no bound information
bound information
0 20 40 60 80 100
iteration3.5
3.0
2.5
2.0
1.5
1.0
0.5
0.0lower boundSixHumpCamel 2D
no bound information
bound information
0 20 40 60 80 100
iteration140
120
100
80
60
40
20
0lower boundHartmann 3D
no bound information
bound information
0 20 40 60 80 100 120 140
iteration400
300
200
100
0lower boundRosenbrock 4D
no bound information
bound information
0 20 40 60 80 100 120 140
iteration300
275
250
225
200
175
150
125
100
lower boundAckley 6D
no bound information
bound information
0 20 40 60 80 100 120 140
iteration1000
800
600
400
200
0lower boundPowell 8D
no bound information
bound information
0 25 50 75 100 125 150 175 200
iteration2500
2000
1500
1000
500
lower boundStyblinskiT ang 10D
no bound information
bound information
Figure 7: Estimated Lower Bound (Synthetic Functions): The estimated lower bound plots align with
performance across functions. For functions like Ackley and Hartman, where bounds are highly negative
relativetotheobjectiverange, SlogGPbehavessimilarlytoGPsincethelowerboundprovideslittleguidance.
However,forfunctionslikeBealewheretheestimatedboundconvergesnearthetrueminimum,thisadditional
bound information proves more beneficial.
0 10 20 30 40 50
iteration98.0098.2598.5098.7599.0099.2599.50accuracy
(a)Skin Segmentation 6D
GP+EI
GP+TEI
SlogGP+SlogEI
SlogGPb+SlogEI
SlogGP+SlogTEI
BABO
0 20 40 60 80 100
iteration101
100distance
(b)Robot Push 4D
GP+EI
GP+TEI
SlogGP+SlogEI
SlogGPb+SlogEI
SlogGP+SlogTEI
BABO
Figure 8: Different Components Comparison (Real-world Benchmarks): Generally, the complete BABO
approach demonstrates superior performance, suggesting that incorporating bound information in both the
modeling and acquisition function stages is beneficial.
that BABO’s performance consistently improves as the known lower bound fbconverges toward the true
minimum value f∗.
13Under review as submission to TMLR
0 10 20 30 40 50
iteration5
4
3
2
1
0123estimated lower bound (median)
(a)Skin Segmentation 6D
no bound information
bound information
0 20 40 60 80 100
iteration2.0
1.5
1.0
0.5
0.0
(b)Robot Push 4D
no bound information
bound information
Figure 9: Estimated Lower Bound (Real-world Benchmarks): Prior information helps to reduce the gap
between−ˆζand its convergence value in both Skin Segmentation problem and Robot Push problem.
0 20 40 60 80 100
iteration104
103
102
101
100101simple regret
(a)Branin 2D
fixed C
MAP
MAP+Uncertainty Level
BABO
0 20 40 60 80 100 120 140
iteration101
4×1006×1002×101
(b)Ackley 6D
fixed C
MAP
MAP+Uncertainty Level
BABO
Figure 10: Ablation Study on How to Use Prior Information: For the Branin function, where the known
lowerboundisquiteaccurate, allmethods(MAP,MAP+UncertaintyLevel, BABO)demonstratecomparable
performance. In contrast, for the Ackley function, the optimal fitted value of −˜ζis substantially negative,
creating a significant prior-data conflict with the known lower bound fb= 0. In this case, disregarding the
prior bound information in the surrogate model leads to superior performance.
0 20 40 60 80 100
iteration104
103
102
101
100101simple regret
(a)Branin 2D
fb=f*
fb=f*12
fb=f*100
0 20 40 60 80 100
iteration102
101
100101
(b)Beale 2D
fb=f*
fb=f*3
fb=f*100
0 20 40 60 80 100
iteration103
102
101
100
(c)Hartmann 3D
fb=f*
fb=f*20
fb=f*100
Figure 11: BABO with different fb: BABO’s performance improves as the known lower bound fbapproaches
the minimum value f∗.14Under review as submission to TMLR
BABO consists of two parts: SlogGPband SlogTEI. Although it is clear that the closer fbandf∗, SlogTEI
should be better, it is not that obvious how the prior information influences the surrogate model. The
influence of a given lower bound in SlogGP on BABO performance is clear when there is no model mismatch:
whenfbis close to the underlying −ζ, the prior information of the lower bound can help to learn the model
lower bound quickly. On the other hand, when fbis far away from the best fitting −ζ, this information can
be misleading, which is why we reduce the impact of the prior information if a large gap is found.
If there is model mismatch (which is common in practice), the influence of lower bound information on the
surrogate model is less clear. However, we found that the estimated parameter −ˆζinfluences the balance
between exploitation and exploration. Specifically, a higher value of −ˆζcorresponds to a greater emphasis
on exploitation, as the current best value in the underlying GP model gmin= ln(fmin+ˆζ)will be more
negative as−ˆζincreases. Hence, BO is more likely to search in close proximity to xmin, focusing more on
exploitation. Conversely, if ˆζis lower and far away from fmin, then BO will do more exploration.
In order to demonstrate this effect, we study the relationship between −ˆζand the properties of the next
sample chosen. Our base model is SlogGPbwith−ˆζ=fmin−1.
Figures 12(a)-(c) show that the gap between the mean of the next evaluation value and fmin, i.e.
E[fbase(xn+1)]−fminincreases as−ˆζis lowered. Similarly, Figures 12(d)-(f) show that the predicted
variance of fbase(xn+1)increases as−ˆζis lowered.
Finally, Figures 12(g)-(i) present the relationship between Euclidean distance ||xn+1−xmin||and−ˆζ. A
more local search near xminin case of larger−ˆζis an indication of more exploitation in BO.
15Under review as submission to TMLR
fmin  
 0.001
fmin 
 0.1
fmin 
 1
fmin 
 2
fmin 
 5
fmin 
 10
fmin 
 50
fmin 
 100
fmin 
 200
02468101214[fbase(xn+1)]fmin
(a)Branin 2D
fmin  
 0.001
fmin 
 0.1
fmin 
 1
fmin 
 2
fmin 
 5
fmin 
 10
fmin 
 50
fmin 
 100
fmin 
 200
020406080100
(b)Beale 2D
fmin  
 0.001
fmin 
 0.1
fmin 
 1
fmin 
 2
fmin 
 5
fmin 
 10
fmin 
 50
fmin 
 100
fmin 
 200
0.4
0.2
0.00.20.40.60.8
(c)Hartmann 3D
fmin  
 0.001
fmin 
 0.1
fmin 
 1
fmin 
 2
fmin 
 5
fmin 
 10
fmin 
 50
fmin 
 100
fmin 
 200
0510152025variance of fbase(xn+1)
(d)Branin 2D
fmin  
 0.001
fmin 
 0.1
fmin 
 1
fmin 
 2
fmin 
 5
fmin 
 10
fmin 
 50
fmin 
 100
fmin 
 200
0100200300400500
(e)Beale 2D
fmin  
 0.001
fmin 
 0.1
fmin 
 1
fmin 
 2
fmin 
 5
fmin 
 10
fmin 
 50
fmin 
 100
fmin 
 200
0.00.10.20.30.40.50.60.70.8
(f)Hartmann 3D
fmin  
 0.001
fmin 
 0.1
fmin 
 1
fmin 
 2
fmin 
 5
fmin 
 10
fmin 
 50
fmin 
 100
fmin 
 200
0.20.40.60.81.0||xn+1 xmin||
(g)Branin 2D
fmin  
 0.001
fmin 
 0.1
fmin 
 1
fmin 
 2
fmin 
 5
fmin 
 10
fmin 
 50
fmin 
 100
fmin 
 200
0.00.20.40.60.8
(h)Beale 2D
fmin  
 0.001
fmin 
 0.1
fmin 
 1
fmin 
 2
fmin 
 5
fmin 
 10
fmin 
 50
fmin 
 100
fmin 
 200
0.10.20.30.40.50.60.70.80.9
(i)Hartmann 3D
Figure 12: Exploitation and Exploration Analysis: When −ˆζis higher (towards the left of each figure),
BABO prefers more exploitation; When −ˆζis lower, BABO prefers more exploration. Top row shows
E[fbase(xn+1)]−fmin, middle row shows variance at next sample location, and bottom row shows distance
of new sample location from current best.
6 Conclusion
We proposed BABO, a Bayesian Optimization algorithm that is able to leverage prior information about
the optimal value f∗to achieve better solutions and a higher sample-efficiency. BABO uses the tailored
surrogate model SlogGP and the acquisition criterion Shifted Logarithmic Truncated Expected Improvement
(SlogTEI), which is an extension of Expected Improvement that takes the prior information into account.
Experimental results demonstrate that BABO benefits from the prior information and outperforms previous
approaches. Moreover, we find that even without prior information about f∗, the SlogGP model often
16Under review as submission to TMLR
performs better than the commonly used GP model when combined with EI. For future work, we will
investigate the potential of the SlogGP model further for a wider range of scenarios.
We observe that BABO sometimes chooses a large absolute value for the parameter ζof the SlogGP model,
which means that the modeled function is ‘pushed away’ from the known lower bound on the optimal value.
Thisisbecausetheparameterfittingtradesoffmodelfitwithusingthepriorinformationabout f∗. Although
this effect is mitigated by incorporating the information about f∗also in the acquisition criterion SlogTEI,
we wonder if there is a more suitable way of jointly modeling the unknown objective and the bound on its
optimal value.
References
James Bergstra, Rémi Bardenet, Yoshua Bengio, and Balázs Kégl. Algorithms for hyper-parameter opti-
mization. Advances in Neural Information Processing Systems , 24, 2011.
Eric Brochu, Vlad M Cora, and Nando De Freitas. A tutorial on Bayesian optimization of expensive cost
functions, with application to active user modeling and hierarchical reinforcement learning. arXiv preprint
arXiv:1012.2599 , 2010.
Roberto Calandra, André Seyfarth, Jan Peters, and Marc Peter Deisenroth. Bayesian optimization for
learning gaits under uncertainty: An experimental comparison on a dynamic bipedal walker. Annals of
Mathematics and Artificial Intelligence , 76:5–23, 2016.
TianqiChenandCarlosGuestrin. Xgboost: Ascalabletreeboostingsystem. In ACM SIGKDD International
Conference on Knowledge Discovery and Data Mining , pp. 785–794, 2016.
Hyunghun Cho, Yongjin Kim, Eunjung Lee, Daeyoung Choi, Yongjae Lee, and Wonjong Rhee. Basic
enhancement strategies when using Bayesian optimization for hyperparameter tuning of deep neural net-
works.IEEE Access , 8:52588–52608, 2020.
GeorgeDeAth, RichardMEverson, AlmaAMRahat, andJonathanEFieldsend. Greedisgood: Exploration
and exploitation trade-offs in Bayesian optimisation. ACM Transactions on Evolutionary Learning and
Optimization , 1(1):1–22, 2021.
Jose Pablo Folch, Shiqiang Zhang, Robert Lee, Behrang Shafei, David Walz, Calvin Tsay, Mark van der
Wilk, and Ruth Misener. Snake: Bayesian optimization with pathwise exploration. Advances in Neural
Information Processing Systems , 35:35226–35239, 2022.
Roman Garnett. Bayesian optimization . Cambridge University Press, 2023.
David Ginsbourger, Rodolphe Le Riche, and Laurent Carraro. A multi-points criterion for deterministic
parallel global optimization based on Gaussian processes. hal-00260579 , 2008.
Tom Gunter, Michael A Osborne, Roman Garnett, Philipp Hennig, and Stephen J Roberts. Sampling for
inferenceinprobabilisticmodelswithfastBayesianquadrature. Advances in Neural Information Processing
Systems, 27, 2014.
Frank Hutter, Holger H Hoos, Kevin Leyton-Brown, and Kevin P Murphy. An experimental investigation
of model-based parameter optimisation: Spo and beyond. In Genetic and Evolutionary Computation
Conference , pp. 271–278, 2009.
Frank Hutter, Holger H Hoos, and Kevin Leyton-Brown. Sequential model-based optimization for general
algorithm configuration. In International Conference on Learning and Intelligent Optimization , pp. 507–
523. Springer, 2011.
Bjørn Sand Jensen, Jens Brehm Nielsen, and Jan Larsen. Bounded Gaussian process regression. In 2013
IEEE International Workshop on Machine Learning for Signal Processing (MLSP) , pp. 1–6. IEEE, 2013.
Taewon Jeong and Heeyoung Kim. Objective bound conditional gaussian process for bayesian optimization.
InInternational Conference on Machine Learning , pp. 4819–4828. PMLR, 2021.
17Under review as submission to TMLR
Jonas Mockus. The application of Bayesian methods for seeking the extremum. In L.C.W. Dixon and G.P.
Szegö (eds.), Towards Global Optimisation , volume 2, pp. 117–129. North-Holland, 1998.
Vu Nguyen and Michael A Osborne. Knowing the what but not the where in Bayesian optimization. In
International Conference on Machine Learning , pp. 7317–7326. PMLR, 2020.
Vu Nguyen, Marc Peter Deisenroth, and Michael A Osborne. Gaussian process sampling and optimization
with approximate upper and lower bounds. arXiv preprint arXiv:2110.12087 , 2021.
Andrew Pensoneault, Xiu Yang, and Xueyu Zhu. Nonnegativity-enforced Gaussian process regression. The-
oretical and Applied Mechanics Letters , 10(3):182–187, 2020.
Carl Edward Rasmussen and Christopher KI Williams. Gaussian processes for machine learning . Springer,
2006.
Binxin Ru, Michael A Osborne, Mark McLeod, and Diego Granziol. Fast information-theoretic Bayesian
optimisation. In International Conference on Machine Learning , pp. 4384–4392. PMLR, 2018.
Eric Schulz, Maarten Speekenbrink, and Andreas Krause. A tutorial on Gaussian process regression: Mod-
elling, exploring, and exploiting functions. Journal of Mathematical Psychology , 85:1–16, 2018.
Bobak Shahriari, Kevin Swersky, Ziyu Wang, Ryan P Adams, and Nando De Freitas. Taking the human out
of the loop: A review of Bayesian optimization. Proceedings of the IEEE , 104(1):148–175, 2015.
Edward Snelson, Zoubin Ghahramani, and Carl Rasmussen. Warped Gaussian processes. Advances in Neural
Information Processing Systems , 16, 2003.
Jasper Snoek, Oren Rippel, Kevin Swersky, Ryan Kiros, Nadathur Satish, Narayanan Sundaram, Mostofa
Patwary, Mr Prabhat, and Ryan Adams. Scalable Bayesian optimization using deep neural networks. In
International Conference on Machine Learning , pp. 2171–2180. PMLR, 2015.
Samuel Stanton, Wesley Maddox, Nate Gruver, Phillip Maffettone, Emily Delaney, Peyton Greenside, and
Andrew Gordon Wilson. Accelerating Bayesian optimization for biological sequence design with denoising
autoencoders. In International Conference on Machine Learning , pp. 20459–20478. PMLR, 2022.
Zi Wang and Stefanie Jegelka. Max-value entropy search for efficient Bayesian optimization. In International
Conference on Machine Learning , pp. 3627–3635. PMLR, 2017.
ZiWang, ClementGehring, PushmeetKohli, andStefanieJegelka. Batchedlarge-scaleBayesianoptimization
in high-dimensional spaces. In International Conference on Artificial Intelligence and Statistics , pp. 745–
754. PMLR, 2018.
18Under review as submission to TMLR
A Appendix
A.1αMESb/parenleftbig
x|fb/parenrightbig
shares the same maximizer with P(f(x)<fb)
MESbshares the same maximizer with the acquisition function P(f(x)< fb), i.e.
argmaxx∈XαMESb/parenleftbig
x|fb/parenrightbig
=argmaxx∈XP(f(x)<fb). See examples in Figure 13.
0.0 0.2 0.4 0.6 0.8 1.0
x0.0000.0010.0020.0030.0040.0050.0060.007acquisition function valueMESb
(f(x)<fb)
0.0 0.2 0.4 0.6 0.8 1.0
x0.000.020.040.060.080.10 MESb
(f(x)<fb)
0.0 0.2 0.4 0.6 0.8 1.0
x0.000.050.100.150.200.25MESb
(f(x)<fb)
Figure 13: MESbandP(f(x)<fb)
Proof.For simplicity, we use γto represent γ/parenleftbig
x,fb/parenrightbig
=µ(x)−fb
σ(x)for the following analysis.
Firstly, P(f(x)<fb) = Φ(fb−µ(x)
σ(x)) = 1−Φ(γ), so it is monotonically decreasing with γ.
ThenextstepistoprovethatMESbisalsodecreasingwith γ. Welookat αMESb/parenleftbig
x|fb/parenrightbig
=γϕ(γ)
2Φ(γ)−log (Φ (γ)).
For simplicity, we denote it by M(γ). The derivative of M(γ)is:
M′(γ) =1
2·/parenleftbiggϕ(γ)
Φ(γ)+γ·ϕ′(γ)
Φ(γ)−γ·ϕ(γ)2
Φ(γ)2/parenrightbigg
−ϕ(γ)
Φ(γ)
=1
2·/parenleftbigg
−ϕ(γ)
Φ(γ)+γ·ϕ′(γ)
Φ(γ)−γ·ϕ(γ)2
Φ(γ)2/parenrightbigg
=1
2·/parenleftbigg
−ϕ(γ)
Φ(γ)+γ·−γϕ(γ)
Φ(γ)−γ·ϕ(γ)2
Φ(γ)2/parenrightbigg
=1
2·/parenleftbigg
−ϕ(γ)
Φ(γ)−γ2·ϕ(γ)
Φ(γ)−γ·ϕ(γ)2
Φ(γ)2/parenrightbigg
=−ϕ(γ)
2·/parenleftbigg1
Φ(γ)+γ2
Φ(γ)+γ·ϕ(γ)
Φ(γ)2/parenrightbigg
=−ϕ(γ)
2Φ(γ)2·(Φ(γ)(1 +γ2) +γ·ϕ(γ))
To determine the monotonicity of M(γ), we need to determine whether D(γ) = (Φ(γ)(1 +γ2) +γ·ϕ(γ))is
positive or negative. It is easy to calculate D′(γ) = 2ϕ(γ) + 2γΦ(γ). GivenD′′(γ) = 2Φ(γ)>0,D′(γ)is an
increasing function in (−∞,∞)and the minimal value is achieved when γ→−∞:
lim
γ→−∞D′(γ) = lim
γ→−∞2(ϕ(γ) +γΦ(γ))
= 2·lim
γ→−∞γΦ(γ)
= 2·lim
γ→−∞Φ′(γ)
(1
γ)′
= 2·lim
γ→−∞−ϕ(γ)γ2
= 0
19Under review as submission to TMLR
Hence,D′(γ)>0forγ∈(−∞,∞), soD(γ)is an increasing function. Similarly, D(γ)→0whenγ→−∞,
soD(γ)>0forγ∈(−∞,∞). Hence, the derivative of M(γ)is negative, i.e. M(γ)is a decreasing function
ofγ.
Considering γis a function of x,P(f(x)<fb)andαMESb/parenleftbig
x|fb/parenrightbig
share the same monotonicity with respect
tox, they share the same maximizer.
Figure 14 shows the decreasing relationship between γand MESb. Consider MESbandP(f(x)< fb)are
both decreasing with γ, they share the same maximizer γ∗.
20
 15
 10
 5
 0 5 10 15 20
0.00.51.01.52.02.53.03.5MESb
Figure 14: MESbis decreasing with γ. As MESbandP(f(x)<fb)are both decreasing with γ, they share
the same maximizer γ∗
A.2 Adapting the acquisition functions EI and PI for the SlogGP model
In the following section, we propose two adaptations of popular acquisition functions to the SlogGP model,
Shifted Logarithmic Probability of Improvement (SlogPI) and Shifted Logarithmic Expected Improvement
(SlogEI). If the current best value is denoted by fmin, SlogPI is
αSlogPI(x;fmin) =P(f(x)≤fmin)
= Φ/parenleftbiggln(fmin+ζ)−µ(x))
σ(x)/parenrightbigg
.
The calculation process is shown as follows.
For a solution xand the current minimal observation fmin, we denote the predicted mean of g(x)asµand
variance of g(x)asσ2. Due to the normal distribution of g(x),eg(x)(denoted by Z) follows a log-normal
distribution. Hence, SlogPI can be calculated as follows:
αSlogPI(x;fmin) = P(f(x)≤fmin)
=P(Z−ζ≤fmin)
=P(Z≤fmin+ζ)
= Φ(ln(fmin+ζ)−µ(x)
σ(x))
20Under review as submission to TMLR
In terms of SlogEI, we firstly calculate E[(η−Z)+]using the definition of the log-normal distribution, where
ηis a constant and (·)+denotes the positive part function:
E[(η−Z)+] =/integraldisplay∞
0(η−Z)+·1
zσ(x)√
2πe−(ln(z)−µ(x))2
2σ(x)2dz
=/integraldisplayη
0(η−z)·1
zσ(x)√
2πe−(ln(z)−µ(x))2
2σ(x)2dz+/integraldisplay∞
η0·1
zσ(x)√
2πe−(ln(z)−µ(x))2
2σ(x)2dz
=/integraldisplayη
0(η−z)·1
zσ(x)√
2πe−(ln(z)−µ(x))2
2σ2(x)dz
=η·/integraldisplayη
01
zσ(x)√
2πe−(ln(z)−µ(x))2
2σ(x)2dz−/integraldisplayη
0z·1
zσ(x)√
2πe−(ln(z)−µ(x))2
2σ(x)2dz
=ηΦ/parenleftbiggln(η)−µ(x)
σ(x)/parenrightbigg
−/integraldisplayη
0z·1
zσ(x)√
2πe−(ln(z)−µ(x))2
2σ(x)2dz
The last equality simply uses the definition of the CDF of the lognormal distribution. The second term is
the partial expectation, so
/integraldisplayη
0z·1
zσ(x)√
2πe−(ln(z)−µ(x))2
2σ2dz
=eµ(x)+σ(x)2
2·Φ/parenleftbiggln(η)−µ(x)−σ(x)2
σ(x)/parenrightbigg
Hence,
E[(η−Z)+] =ηΦ/parenleftbiggln(η)−µ(x)
σ(x)/parenrightbigg
−eµ(x)+σ(x)2
2·Φ/parenleftbiggln(η)−µ(x)−σ(x)2
σ(x)/parenrightbigg
Settingη=fmin+ζ, we obtain the formula of E[(fmin−(Z−ζ))+}], i.e. SlogEI:
αSlogEI(x;fmin) = (fmin+ζ)·Φ/parenleftbiggln(fmin+ζ)−µ(x)
σ(x)/parenrightbigg
−eµ(x)+σ2(x)
2·Φ/parenleftbiggln(fmin+ζ)−µ(x)−σ2(x)
σ(x)/parenrightbigg
.
SlogEI is differentiable with xif∂µ
xiand∂σ
xiexist. The partial derivative is
∂αSlogEI
∂xi=∂αSlogEI
∂µ·∂µ
∂xi+∂αSlogEI
∂σ·∂σ
∂xi.
where
∂αSlogEI
∂µ=−(fmin+ζ)
σ(x)·ϕ/parenleftbiggln(fmin+ζ)−µ(x)
σ(x)/parenrightbigg
+eµ(x)+σ2(x)
2
σ(x)·ϕ/parenleftbiggln(fmin+ζ)−µ(x)−σ2(x)
σ(x)/parenrightbigg
−eµ(x)+σ2(x)
2·Φ/parenleftbiggln(fmin+ζ)−µ(x)−σ2(x)
σ(x)/parenrightbigg
and
∂αSlogEI
∂σ=−(fmin+ζ)
σ2(x)·ϕ/parenleftbiggln(fmin+ζ)−µ(x)
σ(x)/parenrightbigg
·(ln(fmin+ζ)−µ(x))
+eµ(x)+σ2(x)
2·ϕ/parenleftbiggln(fmin+ζ)−µ(x)−σ2(x)
σ(x)/parenrightbigg
·(ln(fmin+ζ)−µ(x)
σ2(x)+ 1)
−σ(x)eµ(x)+σ2(x)
2·Φ/parenleftbiggln(fmin+ζ)−µ(x)−σ2(x)
σ(x)/parenrightbigg
.
21Under review as submission to TMLR
A.3 Proof of Theorem 3.1
For convenience, we repeat Theorem 3.1 first before stating the proof.
Theorem 3.1. Define a SlogGP f(x) =eg(x)+µg−ζwithg(x)a Gaussian process with zero mean, zero
noise and a covariance function Kwith signal variance σ2
gand other hyperparameters θg.
Then for any GP h(x)with mean ˜µg, signal variance ˜σg, and other hyperparameters ˜θg, we can have the
SlogGPf(x)converge to h(x)in distribution for any x∈Xby setting


µg= ln (ζ+ ˜µg)
θg=˜θg
σg=˜σg
ζ+ ˜µg
and letting ζ→∞, i.e.,
lim
ζ→∞Pf(x)(z) =Ph(x)(z)∀z∈(−ζ,∞),∀x∈X,
whereP(·)denotes the probability density function of a random variable.
Proof.Given a SlogGP f(x) =eg(x)+µg−ζwithg(x)a Gaussian process with zero mean, zero noise and
a covariance function Kwith signal variance σ2
gand other hyperparameters θg. We setσg,θg,µgsuch that
the following equations:

µg= ln (ζ+ ˜µg)
θg=˜θg
σg=˜σg
ζ+ ˜µg
are satisfied for some constants (˜σg,˜µg,˜θg)∈Θ.
According to the definition ex=/summationtext∞
k=0xk
k!, we have
f(x) =eµgeg(x)−ζ
=eµg·(1 +g(x) +1
2g2(x) +1
6g3(x)) +...)−ζ
=eµgg(x) +eµg−ζ+eµg(1
2g2(x) +1
6g3(x)) +...).
In the formula, we distinguish three different parts: eµgg(x),eµg−ζandeµg(1
2g2(x) +1
6g3(x) +...).
In terms of the first part, g(x)is a Gaussian process with zero noise, zero mean and kernel with signal
varianceσ2
gand other hyperparameters θg. Hence,eµgg(x)is a Gaussian process with zero noise, zero mean
and kernel with signal variance e2µgσ2
gand other hyperparameters θg.
The second part eµg−ζis the constant ˜µgas we setµg= ln (ζ+ ˜µg).
For the third part, we first look at eµgg2(x). We haveeµgg2(x) = (eµg
2g(x))2, soeµgg2(x)is the square of a
Gaussian process with signal variance eµgσ2
gand mean 0. When ζ→∞, we haveeµgσ2
g→0, so∀x
lim
ζ→∞P/parenleftbig/vextendsingle/vextendsingleeµgg2(x)−0/vextendsingle/vextendsingle>ε/parenrightbig
= 0.
For other terms eµggk(x)in the third part, we can view them as (eµg
kg(x))k, so similarly, we have
limζ→∞P/parenleftbig/vextendsingle/vextendsingleeµggk(x)−0/vextendsingle/vextendsingle>ε/parenrightbig
= 0fork≥3,∀xand∀ε.
Therefore, for∀xand∀ε,
lim
ζ→∞P(|f(x)−˜g(x)|>ε) = 0,
22Under review as submission to TMLR
where ˜g(x) =eµgg(x) +eµg−ζis a Gaussian process with mean ˜µg, zero noise and covariance function K
with signal variance ˜σ2
gand other hyperparameters ˜θg.
Therefore, we have
lim
ζ→∞Pf(x)(z) =P˜g(x)(z)∀z∈(−ζ,∞),∀x∈X,
whereP(·)denotes the probability density function of a random variable.
Given that ˜gandhshare the same parameters, they share the same posterior distribution, i.e.
P˜g(x)(z) =Ph(x)(z)∀z∈(−ζ,∞),∀x∈X,
Hence, we have
lim
ζ→∞Pf(x)(z) =Ph(x)(z)∀z∈(−ζ,∞),∀x∈X,
A.4 Experimental Settings (Within-model Test, Synthetic Function Test and Real-world Benchmark
Test)
The experimental setting is as follows. For each d-dimensional test function, we sample 4dinitial points from
a Latin hypercube design. The input domain is scaled to [0,1]d. For GP-based methods, function values
are standardized (scaled and centralized) and for SlogGP-based methods, function values are scaled and
the centralizing is done in model training. As kernel we use the squared exponential kernel: K(xa,xb) =
σ2exp/parenleftig
−∥xa−xb∥2
2ℓ2/parenrightig
. For acquisition function optimization, we use restart L-BFGS-B in scipy. The restart
time and initial samples (restart number 3dand initial sample 30d) and L-BFGS-B options are the same for
all acquisition functions. We compare the performance of BABO with other benchmark algorithms across
various test functions. The benchmark algorithms we consider are Random, EI, TEI, MESb, OBCGP and
ERM.
We consider a noiseless setting in our theoretical analysis. In practice, a small positive noise variance is
typically introduced to ensure numerical stability. Since the estimated signal variance ˆσ2
gin SlogGP can vary
substantially, ranging from near-zero to several hundred, we adopt an adaptive noise variance proportional
to the estimated signal variance: σ2
noise = 10−5·ˆσ2
g,n−1The initial noise variance is set to 6·10−6. We
maintain these noise parameter settings across all comparative methods to ensure fair comparison.
Details of test functions are shown in the table below.
Table 3: Test Function Information
Test Function Optimal Value Search Space
GP-generated functions (2D) - [0.,1.]2
SlogGP-generated functions (2D) - [0.,1.]2
Beale (2D) 0 [−4.5,4.5]2
Branin (2D) 0.397887 [[−5.,10.],[0.,15.]]
SixHumpCaml (2D) -1.0316 [[−3.,3.],[−2.,2.]]
Levy (2D) 0 [[−10.,10.],[−10.,10.]]
Hartmann (3D) -3.86278 [0.,1.]d
DixonPrice (4D) 0 [−10.,10.]d
Rosenbrock (4D) 0 [−2.048,2.048]d
Ackley (6D) 0 [−32.768,32.768]d
Powell (8D) 0 [−4.,5.]d
StyblinskiTang (10D) -391.6599 [−5.,5.]d
Robot Push (4D) 0 [[−5.,5.],[−5.,5.],[0.,2π],[0.,300.]]
Skin Segmentation (6D) 99.7 [[0.,10.],[0.,10.],[5.,15.],[1.,20.],[0.5,1.],[0.1,1.]]
23Under review as submission to TMLR
In addition, in terms of within-model in Section 3.4, for GP-generated functions, signal variance σ2
g= 2,
lengthscale l= 0.1and mean 0. For SlogGP-generated functions, signal variance σ2
g= 1.2, lengthscale
l= 0.1, shiftζ= 30and mean 0.5.
We also had a cross-validation test for GP and SlogGP. The repetition number is 50. In each experiment, 40
initial training points are sampled randomly. We test the gap between model prediction mean at a random
xand its value f(x).
A.5 More experiments: batched BABO
0 20 40 60 80 100
number of solutions0.00.51.01.52.0simple regretLevy 2D
qEI (q=1)
qEI (q=5)
qEI (q=10)
qBABO (q=1)
qBABO (q=5)
qBABO (q=10)
0 20 40 60 80 100 120 140
number of solutions101102103DixonPrice 4D
qEI (q=1)
qEI (q=5)
qEI (q=10)
qBABO (q=1)
qBABO (q=5)
qBABO (q=10)
Figure 15: Batched BO: We evaluated the performance across varying batch sizes (q = 1, 5, and 10) for both
test problems. The experimental results demonstrate that qBABO consistently outperforms qEI across all
batch size configurations.
24