Published in Transactions on Machine Learning Research (03/2023)
Cheap and Deterministic Inference for Deep State-Space
Models of Interacting Dynamical Systems
Andreas Look andreas.look@bosch.com
Bosch Center for Artificial Intelligence
Melih Kandemir kandemir@imada.sdu.dk
University of Southern Denmark
Barbara Rakitsch barbara.rakitsch@bosch.com
Bosch Center for Artificial Intelligence
Jan Peters peters@ias.informatik.tu-darmstadt.de
Technical University Darmstadt
Reviewed on OpenReview: https: // openreview. net/ forum? id= dqgdBy4Uv5
Abstract
Graph neural networks are often used to model interacting dynamical systems since they
gracefully scale to systems with a varying and high number of agents. While there has been
much progress made for deterministic interacting systems, modeling is much more challeng-
ing for stochastic systems in which one is interested in obtaining a predictive distribution
over future trajectories. Existing methods are either computationally slow since they rely
on Monte Carlo sampling or make simplifying assumptions such that the predictive distri-
bution is unimodal. In this work, we present a deep state-space model which employs graph
neural networks in order to model the underlying interacting dynamical system. The pre-
dictive distribution is multimodal and has the form of a Gaussian mixture model, where the
moments of the Gaussian components can be computed via deterministic moment matching
rules. Our moment matching scheme can be exploited for sample-free inference, leading to
more efficient and stable training compared to Monte Carlo alternatives. Furthermore, we
propose structured approximations to the covariance matrices of the Gaussian components
in order to scale up to systems with many agents. We benchmark our novel framework
on two challenging autonomous driving datasets. Both confirm the benefits of our method
compared to state-of-the-art methods. We further demonstrate the usefulness of our indi-
vidual contributions in a carefully designed ablation study and provide a detailed runtime
analysis of our proposed covariance approximations. Finally, we empirically demonstrate
the generalization ability of our method by evaluating its performance on unseen scenarios.
1 Introduction
Many dynamical systems, such as traffic flow (Li et al., 2018; Yu et al., 2018), fluid dynamics (Ummenhofer
etal.,2019)orhumanmotion(Jainetal.,2016), involveinteractionsbetweenagents. Graph Neural Networks
(GNN) (Battaglia et al., 2018) have recently emerged as a powerful tool in these settings, since they allow
learning the dynamics of interacting systems from data only. Recent research has made great advances for
modeling deterministic complex systems by being able to extrapolate from systems with a small number
of agents and short time horizons to systems with a high number of agents and long time horizons. These
methods have been successfully applied to a number of physical systems covering fluids, rigid solids and
deformable materials (Sanchez-Gonzalez et al., 2020). However, for many real-world applications, predicting
a single future trajectory for each agent is not enough, since the stochasticity in the dynamical system
1Published in Transactions on Machine Learning Research (03/2023)
has significant consequences. For instance, in autonomous driving, the driver’s intention (e.g. overtaking,
turning, lane changing) is a hidden factor that may induce different modes of driving trajectories.
Ground Truth
Prediction: Mode 1
Weight: 0.12
Prediction: Mode 2
Weight: 0.74
Prediction: Mode 3
Weight: 0.14
Figure 1: We approximate the predictive distribution of a latent Graph Deep State-Space Model (GDSSM)
as a Gaussian mixture distribution via deterministic moment matching rules. Given historical information
in the form of observed trajectories (dashed lines), our proposed GDSSM architecture predicts the future
dynamics while taking interactions between traffic participants into account. We present the true future
trajectories (left-most plot) as solid lines. For each mode and traffic participant, we show the predicted 95%
confidence interval of our model (three right-most plots). Our model accounts for interactions, for example,
the brown vehicle is only entering the roundabout if the blue vehicle is staying in the roundabout (Mode 1).
If the blue vehicle is leaving the roundabout, the entering lane for the brown vehicle is blocked by the blue
vehicle (Mode 2, Mode 3) and the brown car has to wait. The ground truth data and the map come from
the rounD dataset (Krajewski et al., 2020).
In the deep learning literature, multiple architectures have been successfully applied to time-series data with
two prominent classes being a) recurrent methods that apply a fixed transition model repeatedly at each time
step (e.g. Hochreiter (1991), Chung et al. (2014)), b) history-based methods that aggregate information from
the past using either convolutional filters (e.g. Bai et al. (2018), Oord et al. (2016)) or attention modules
(e.g. Vaswani et al. (2017), Li et al. (2019)). Recurrent methods capture the internal state of the system
at each time point tin a latent state xt. Predicting the output in this manner respects the causal order
of the dynamical system, i.e. the latent state xtof time point tis needed in order to compute the latent
statext+1at the next time point t+ 1. State-space models (e.g. Särkkä (2013)) belong to the class of
recurrent methods. They are defined by two probability distributions: the transition model, p(xt+1|xt), that
propagates the latent state forward in time and the emission model, p(yt|xt), that maps the latent state into
the observational space. Obtaining multistep-ahead predictions for state-space models requires propagating
distributions in the latent space. For general transition models, this operation cannot be done in closed-form
and existing methods either use numerical integration schemes (e.g. Solin et al. (2021), Look et al. (2022)) or
Monte Carlo methods (e.g. Krishnan et al. (2017), Bayer et al. (2021)). For interacting systems, the latent
space grows linearly with the number of agents, requiring a high number of MC samples, which can make
these methods prohibitively slow. To the best of our knowledge, numerical integration schemes have not
been explored for multi-agent dynamical systems. In contrast, probabilistic history-based methods directly
predict the distribution over future trajectories, mitigating the sampling overhead. However, this approach
make the learning problem hard as the model needs to learn the future distribution for multiple time steps
ahead. To account for this, complex models (e.g. large neural networks) are often necessary. This can
prevent their usage in embedded systems with limited memory capacity.
In this work, we present a novel approach for modeling stochastic dynamical systems with interacting agents
that is able to generate expressive multi-modal predictive distributions over future trajectories in a runtime
and memory efficient manner. We model the unknown stochastic dynamical system as a Deep State-Space
Model(DSSM) in which the shared dynamics of all agents are modeled in a joint latent space using GNNs.
Our model belongs to the family of recurrent neural networks and we replace the expensive MC operations
during training and testing by introducing a novel deterministic moment matching scheme. Prior work
(Look et al., 2022) on moment matching for dynamical systems does not consider interacting systems and
is restricted to unimodal processes. We overcome the first limitation by applying GNNs in the transition
model and the second limitation by placing a Gaussian Mixture Model (GMM) over the initial latent state.
2Published in Transactions on Machine Learning Research (03/2023)
For each mixture component, we independently apply our moment matching rules in order to arrive at
multimodal predictive distributions over future trajectories. In autonomous driving, the initial latent state
is often estimated from historical information and can provide information about the drivers’ intentions
(Tang & Salakhutdinov, 2019). Conditioned on the initial latent state, the predictive distribution can often
be accurately modeled with an unimodal distribution (Cui et al., 2019; Chai et al., 2019). Finally, as there
exists a wide variety of dense traffic scenarios, the high number of agents can result in prohibitively large
GMM covariance matrices as their size grows quadratically with the number of traffic participants. We
address this problem by proposing structured covariance approximations.
We summarize our contribution as follows:
•We derive output moments for GNN layers, which makes GNNs applicable to moment matching
algorithms. This leads to the first deterministic inference scheme for deep state-space models for
interacting systems.
•We introduce a GMM distribution over the initial latent states that results in multimodal predictive
distributions over future trajectories.
•We propose structured approximations to the GMM covariance matrices that can reduce the com-
putational complexity of our approach from O(M3)toO(M2), whereMis the number of agents.
In our experiments, we benchmark our proposed model on two challenging autonomous driving datasets.
Our results demonstrate that our deterministic model has strong empirical performance compared to state-
of-the-art alternatives. We visualize the predictive output distribution for a real-world traffic scenario on
a roundabout with multiple agents in Fig. 1. The future distribution is highly multi-modal, as traffic
participants can leave the roundabout from several exits. Our model is capable of predicting multiple
modes, which we efficiently approximate as a GMM, and takes interactions into account using GNNs.
To gain further insights into our model and inference scheme, we carefully examine the impact of the
individual contributions of our work in an ablation study. Next, we provide an empirical runtime study
of our covariance approximations. Our findings indicate that sparse covariance approximations reduce the
computationalcomplexitybyafactorofupto100, whichmakesthemfavourableforapplicationswithlimited
computational resources. We conclude our experiments by studying the generalization capabilities of our
model on out-of-distribution data, e.g. traffic environments that have not been observed during training.
2 Background
In this chapter, we first provide background on (deep) state-space models for single-agent systems. We
proceed by giving a small recap on moment matching rules that allow us to propagate the latent dynamics
forward in time in a deterministic manner. Next, we review graph neural networks for interaction modeling.
State-space models and graph neural networks form the basis for our new model for stochastic dynamical
interacting systems, which we introduce in Sec. 3. The deterministic moment matching rules build the
foundation of our training and testing routines that we describe in Sec. 4.
2.1 Deep State-Space Models
State-Space Models (SSM) are a model class for dynamical systems (e.g. Schön et al. (2011), Särkkä (2013))
that assume that each Dy-dimensional observed variable yt∈RDyis emitted by a latent Dx-dimensional
latent variable xt∈RDx. The latents are coupled via first-order Markovian dynamics, e.g. the state at time
pointxtonly depends on the state of the previous time point xt−1. Typically the observed state yt−1does
not contain all necessary information in order to reliably predict the next observed state yt. Consider the
case of traffic forecasting in which the observed state ytcontains the position of a vehicle but not its velocity
or acceleration data. We can then supply the latent state xtwith the missing information in order to allow
for accurate forecasts about the next time point. Consequently, SSMs are a flexible model class that allows
us to make reliable forecasts about complex systems.
3Published in Transactions on Machine Learning Research (03/2023)
ADeep State-Space Model (DSSM) is a non-linear SSM in which the transition model, that maps the latent
state from the current to the next time point, and the emission model, that maps the latent state to the
outputs, are realized by neural networks. They come in handy for applications in which the true underlying
dynamics have an unknown non-linear functional form and must be estimated from data. Assuming additive
Gaussian noise (e.g. Krishnan et al. (2017)), their generative model can be written down as follows
x0∼p(x0|I), (1)
xt∼N (xt|xt−1+f(xt−1,I),diag(L(xt−1,I))), t = 1,...,T (2)
yt∼N (yt|g(xt),diag(Γ(xt))), t = 1,...,T (3)
whereI∈RDIis the context variable that encodes auxiliary information, such as historical or relational
information. The mean update f(xt,I) :RDx×RDI→RDx, governing the deterministic component of the
transition model, is parameterized by a neural net with an arbitrary architecture. Similarly, the variance
updateL(xt,I) :RDx×RDI→RDx
+is parameterized by another neural net, which models the stochasticity
of the system. Both fandLare neural networks, which are parameterized by θfandθL. The emission
model follows a Gaussian distribution with mean g(xt) :RDx→RDyand variance Γ(xt) :RDx→RDy
+,
wheregandΓare both neural networks with arbitrary architecture and parameters θgandθΓ.
Assuming additive Gaussian noise allows us to interpret the transition model [Eq. (2)] as a discretized neural
stochastic differential equation (Tzen & Raginsky, 2019; Look et al., 2022). While we do not pursue this line
ofworkanyfurther, wenotethatthisconnectionallowsforstraight-forwardextensionstoirregularlysampled
time series. Finally, there exists work that couples state-space models with recurrent neural networks (Chung
et al., 2015; Fraccaro et al., 2016) whose gating mechanism can help in learning long-term effects.
2.2 Transition Kernel
In this section, we provide background on how to compute the t-step transition kernel, p(xt|x0,I)witht>1,
which allows us to propagate the latent state forward in time for general state-space models. It is defined
by the following recurrence
p(xt|x0,I) =/integraldisplay
p(xt|xt−1,I)p(xt−1|x0,I)dxt−1, (4)
wherep(x0|I)follows Eq. (1). It is worth noting that Eq. (4) cannot be computed in closed-form since the
distribution p(xt−1|x0,I)has to be propagated through the non-linear transition model p(xt|xt−1,I)[Eq. 2].
2.2.1 Overview
Various approximations to the transition kernel [Eq. (4)] have been proposed that can be roughly split into
two groups: (a) MC sampling based approaches (Brandt & Santa-Clara, 2002; Pedersen, 1995; Elerian et al.,
2001) and (b) deterministic approximations based on assumed densities (Särkkä et al., 2015). While MC
based approaches can, in the limit of infinitely many samples, approximate arbitrarily complex distribu-
tions, they are often slow in practice and their convergence is difficult to assess. In contrast, deterministic
approachesoftenbuildontheassumptionthatthe t-steptransitionkernelcanbeapproximatedbyaGaussian
distribution. This assumption can be justified if the transition model can be locally linearly approximated
and the observations are sufficiently densely sampled. The transition kernel is then computed in an iterative
manner by applying a Gaussian approximation at each time step and propagating the moments along the
time direction using a numerical integration scheme (Särkkä & Sarmavuori, 2013; Särkkä et al., 2015).
Prior work in the context of neural SDEs (Look et al., 2022) proposes to first discretize the differential
equations and afterwards apply moment matching through the neural network layers as numerical integration
scheme. Since the resulting algorithm propagates moments through time and neural network layers, it is
termedBidimensional Moment Matching (BMM). This approach was shown to be superior over standard
numerical integration schemes in terms of compute and accuracy. Since the transition model in SSMs can
be interpreted as discretized SDEs (Särkkä et al., 2015), we build our work on their approach. Moment
propagation through neural network layers has also been applied previously in the context of expectation
4Published in Transactions on Machine Learning Research (03/2023)
propagation (Hernandez-Lobato & Adams, 2015; Ghosh et al., 2016), deterministic variational inference (Wu
et al., 2019), and evidential deep learning (Haussmann et al., 2020).
2.2.2 Bidimensional Moment Matching
In this section, we recapitulate the original Bidimensional Moment Matching (BMM) algorithm of Look
et al. (2022) and its use for propagating the latent state forward in time [Eq. (2)]. BMM approximates the
transition kernel p(xt|x0,I)by combining horizontal moment matching along the time axis with vertical
moment matching across the neural network layers.
Horizontal Moment Matching In order to facilitate the computation of the transition kernel, we replace
p(xt|x0,I)for all time steps t= 1,...,Twith a Gaussian distribution
p(xt|x0,I) =/integraldisplay
p(xt|xt−1,I)p(xt−1|x0,I)dxt−1 (5)
≈N(xt|µt(I),Σt(I)),
with meanµt(I)and covariance Σt(I). This approximation simplifies the problem to calculating the first two
moments of the transition kernel and is assumed to work well if the dynamics can be locally approximated
by a linear model, which is the case for many applications. Assuming that the one-step transition kernel
p(xt|xt−1,I)follows Eq. (2), the mean µt(I)and covariance Σt(I)can be computed as a function of prior
momentsµt−1(I)andΣt−1(I)(Look et al., 2022)
µt(I) =µt−1(I) +E[f(xt−1,I)], (6)
Σt(I) = Σt−1(I) + Cov[f(xt−1,I)] + Cov[xt−1,f(xt−1,I),] + Cov[xt−1,f(xt−1,I)]T+diag(E[L(xt−1,I)]),
where Cov[xt−1,f(xt−1,I)]denotes the cross-covariance between the random vectors in the arguments.
Vertical Moment Matching The mean E[f(xt−1,I)]and covariance Cov[fθ(xt−1,I)]of the transition
function, as well as the expected variance update E[L(xt−1,I)], can be computed as a result of moment
propagation through neural network layers. For many common layers, including affine transformations and
ReLU activation functions, the corresponding output moments can be either computed in closed-form or
good approximations are available in the literature (Wu et al., 2019). In contrast, approximating the cross-
covariance Cov[xt,fθ(xt,I)]cannot be achieved using moment matching rules since we cannot decompose
the cross-covariance term into layerwise operations. Instead, we resort to Stein’s Lemma using
Cov[xt,f(xt,I)] = Cov[xt]E[∇xtf(xt,I)], (7)
where the expected Jacobian can be approximated as (Look et al., 2022)
E[∇xtf(xt,I)]≈L/productdisplay
l=1E[Jl
t]. (8)
Above,Jl
tdenotes the Jacobian of layer lat time step t. The expectation of the Jacobian is analytically
available or can be closely approximated for common layer types.
2.3 Graph Neural Networks
Graph neural networks (GNNs) have emerged as a powerful method for interaction modeling (Battaglia
et al., 2018; Hamilton et al., 2017; Gilmer et al., 2017). Given a set of agents and relational information in
form of a graph, each agent corresponds to one node in the graph that is equipped with a set of features.
The relation between the agents is encoded via the edges and information exchange between the agents takes
place by sending messages along the edges. By performing multiple rounds of message-passing, information
can flow along the graph. This allows for interactions between non-adjacent agents, provided that a path
between the agents exists.
5Published in Transactions on Machine Learning Research (03/2023)
More formally, we define the structure of our GNN as follows. For Magents, a GNN receives as inputs a
set of node features x={xm}M
m=1, wherex∈RMDxandxm∈RDx, and a set of edges E={em,m′}M
m,m′=1
which is part of the context variable I ∈RDI. The edge attribute em,m′has a binary encoding, where
em,m′= 1if agentmand agentm′are related. The GNN output is an update of the node features, i.e.
z=GNN (x,I)withz∈RMDz, and consists of the following two steps that may be repeated multiple times:
1. For each agent m, receive message xNm∈RDxby aggregrating information from neighboring agents:
xNm=AGG/parenleftig
{xm′|em,m′= 1}/parenrightig
∈RDx, (9)
where{xm′|em,m′= 1}denotes the set of all neighbours of node m. The aggregation operation
AGG is permutation invariant, i.e. it does not change when the ordering of the inputs is swapped
and generalizes to a varying number of inputs. A commonly used aggregation operation that we
also apply in our work is the mean function.
2. For each agent m, update the node information:
zm=UPDATE (xm,xNm,I), (10)
where UPDATE (xm,xNm,I) :RDx×RDx×RDI→RDzis typically implemented by a neural
network.
A simple form of an interacting dynamical system takes the features of each agent at its current position and
connects agents that are within a pre-defined radius with edges. The GNN operation updates the position
and velocity information of each agent by taking information of the adjacent traffic participants into account.
3 Graph Deep State-Space Models
We aim to model stochastic dynamical interactions between agents following complex behavioural patterns,
such as road traffic interactions. We extend deep state-space models to interacting systems by proposing
Graph Deep State-Space Models (GDSSM), which use graph neural networks in the transition model to
capture interactions between agents. We define our probabilistic model in this section and then introduce a
novel scheme for efficient and deterministic training and predictions in the subsequent section.
We are interested in modeling the dynamics of Minteracting agents with deep state-space models by using
a coupled latent space. In other words, instead of using a Dx-dimensional latent space for each agent, we
assume that the agents share a latent space of size MDx. Since (i) the number of agents can vary between
scenes, (ii) the transition model should be agnostic to the order of the agents and (iii) it is challenging to
parameterize high-dimensional latent spaces, we use GNNs in the transition model.
More formally, we denote the state of agent mat time step tasxm
t∈RDxand the set of all state variables as
xt={xm
t}M
m=1. The dynamics of xtfollow Eq. (2), where the mean update f(xt,I) :RMDx×RDI→RMDx
and the variance update L(xt,I) :RMDx×RDI→RMDxare implemented with the help of graph neural
networks
f(xt,I) =
˜f(x1
t,xN1
t,I)
...
˜f(xM
t,xNM
t,I)
, L (xt,I) =
˜L(x1
t,xN1
t,I)
...
˜L(xM
t,xNM
t,I)
. (11)
The agent-specific mean update is denoted by ˜f(xm
t,xNm
t,I) :RDx×RDx×RDI→RDxand the variance
by˜L(xm
t,xNm
t,I) :RDx×RDx×RDI→RDx
+. Both implement the update function in general graph neural
networks [Eq. (10)], whereas ,xNm
tcontains aggregated information of the states from all neighboring agents
[Eq.(9)]. A deterministic variant of our model, e.g. setting L(xt,I) = 0, has been successfully used for
6Published in Transactions on Machine Learning Research (03/2023)
learning surrogate models for complex physical systems (Sanchez-Gonzalez et al., 2020). We further assume
that it is sufficient to couple the latent dynamics across the agents and keep the emission model [Eq. (3)]
independent across agents. Note that our transition model consists of a single aggregation and update
step which is sufficient if the data is densely sampled such that the information flow between agents is fast
compared to the evolution of the state dynamics. However, it is also straight-forward to extend the model
to multiple message-passing steps per time point by stacking multiple GNN layers in the mean and variance
update function.
Furthermore, we note that although the transition noise factorizes across agents, correlations between agents
emerge since the mean and the variance depend not only on the state of the m-th agent, but also on the
states of all neighboring agents. After aaggregation steps, our GNN model accounts for correlations between
agentmand agentm′provided that they are connected by a path that is at most asteps long. In contrast,
methods, that only take the state of the m-th agent into account, do not lead to any correlations, while
methods, that take the state of all other agents into account, lead to a fully correlated covariance matrix
after one time step.
In order to complete the probabilistic description of our model, we further specify the distribution of the
initial latent state x0∈RMDxwith aGaussian Mixture Model (GMM)
v∼Cat([π1(I),...,πV(I)]), (12)
x0∼N(x0|µ0,v(I),diag(Σ0,v(I))),
where Cat ([π1(I),...,πV(I)])is a categorical distribution with Vmixture components. Each component
is specified by its weight πv(I) :RDI→R+, meanµ0,v(I) :RDI→RMDx, and diagonal covariance
Σ0,v(I) :RDI→RMDx
+. The weights π1:Vform a standard V-simplex. We use a GNN, which we refer to as
the embedding function h (I) :RDI→RV+2VMDx, in order to model the initial state distribution
h(I) =
π1:V(I)
µ0,1:V(I)
Σ0,1:V(I)
. (13)
We assume that the context variable Icontains relational information as a set of edges as well as historical
information for each agent in the form of an observed trajectory. In a sense, the embedding function acts
hereby as a filter, which learns a distribution over the initial latent state from past observations.
In autonomous driving, the initial latent state can be connected to the drivers’ intention (Tang & Salakhut-
dinov, 2019). The context information Iis often not sufficient to rule out different hypotheses about the
future, e.g. does the car behind us want to overtake in the next five seconds or not. Using a mixture model
allows us to incorporate different hypotheses into the model in a principled manner, which will ultimately
lead to highly multimodal predictive distributions.
State-space models and graph neural networks have been previously combined for multi-agent trajectory
forecasting by Yang et al. (2020). In contrast to our work, the authors (i) use a different model definition
by applying recurrent neural networks and a non-Gaussian density in the transition model and (ii) perform
Monte Carlo sampling during inference which can lead to slow convergence. In the next chapter, we show
that our model definition allows for more efficient training by performing deterministic moment matching
rules. We compare against Monte Carlo alternatives in our experiments.
4 Deterministic Approximations for GDSSMs
In this chapter, we present our novel inference scheme for GDSSMs that enables efficient and determinis-
tic training and predictions. In Sec. 4.1, we first give a short overview over existing inference techniques
and compare it to our scheme which aims at directly maximizing the predictive log-likelihood of future
trajectories. The predictive log-likelihood cannot be computed in closed-form. We propose an efficient and
deterministic approximation to it in Sec. 4.2 that relies on bidimensional moment matching. Our moment
matching rules necessitate the computation of output moments and expected Jacobians of graph neural
7Published in Transactions on Machine Learning Research (03/2023)
network layers. We present ouput moments for commonly used layers in Sec. 4.3. As our algorithm approx-
imates the output distribution at each time step with a Gaussian mixture distribution over all agents, the
resulting covariance matrix for each mixture component can become computationally intractable for a large
number of traffic participants. We address this pain point in Sec. 4.4 by proposing sparse approximations
to the covariance.
4.1 Parameter Inference
Classical inference methods for state-space models aim at directly maximizing the log-likelihood of the data
logp(y1,...,yT|I) = log/integraldisplay
p(x0|I)T/productdisplay
t=1p(xt|xt−1,I)p(yt|xt)dx0...dxT, (14)
wherep(xt|xt−1,I)is defined in Eq. (2) and p(yt|xt)in Eq. (3). This quantity can only be computed in
closed-form if the emission and transition model are linear Gaussians. In our case, the transition model
is parameterized by a graph neural network and the emission model by a standard neural network. Both
functions are highly non-linear and render an analytical solution to Eq. (14) infeasible.
Therefore, most existing methods apply either a particle filter (Schön et al., 2015), variational inference
(Krishnan et al., 2017; Bayer et al., 2021) or a combination of both (Naesseth et al., 2018; Maddison et al.,
2017; Le et al., 2018) in order to approximate the log-likelihood. All of these approaches have in common
that they require learning a proposal distribution q(x0,...,xT|y1,...,yT): In particle filtering, the proposal
distribution is recursively defined by the importance function q(xt|x0,...,xt−1,y1,...,yt)and is optimal
in terms of variance by setting q(xt|x0,...,xt−1,y1,...,yt) =p(xt|xt−1,yt)(e.g. Doucet et al. (2000).
Variational inference aims to find the best approximation to the true posterior within the chosen variational
family by minimizing the Kullback-Leibler (KL) divergence between the true and approximate posterior (Blei
et al., 2017), while variational sequential Monte Carlo seeks to minimize the KL divergence on an extended
sampling space (Le et al., 2018).
However, the proposal distribution is only used as an auxiliary tool during inference. For many prediction
tasks (Djuric et al., 2020; Jain et al., 2019; Chai et al., 2019), the quantity of interest is the predictive
log-likelihood (PLL)
PLL(y1,...,yT|I) =T/summationdisplay
t=1logp(yt|I) (15)
=T/summationdisplay
t=1log/integraldisplay
p(x0|I)p(xt|x0,I)p(yt|xt)dx0dxt,
where the transition kernel p(xt|x0,I)is defined in Eq. (4).
In contrast to the standard training objective, the predictive log-likelihood propagates the latent state
forward in time without receiving any feedback from the observations; mimicking the behavior during test
time. Since we want to use the same objective during training and test time, we opt for directly maximizing
the predictive log-likelihood during training. The observation that using one-step ahead predictions in
training is not sufficient in order to obtain reliable multi-step ahead predictions during testing has also been
made in Bengio et al. (2015) where the authors propose a scheduled sampling strategy in order to gradually
switch from single to multi-step ahead predictions during training. Multi-step ahead training has also been
successfully applied for spatio-temporal forecasting(Pal et al., 2021) and model-based planning (Hafner et al.,
2019).
The PLL aims at optimizing the average marginal log-likelihood logp(yt|I), while the standard objective
aims at optimizing the joint likelihood logp(y1,...,yT|I). We deem the choice between the two objectives
application dependent: The PLL is most useful for tasks that can be solved by assessing the marginal
distributions only. An important and large application class that falls into this category is in the context of
autonomous driving in which the marginal distributions of neighboring traffic participants at a given time
8Published in Transactions on Machine Learning Research (03/2023)
horizon are often sufficient in order to control the car (e.g. Herman et al. (2022)). As a consequence, many
papers in the autonomous driving literature report as evaluation metrics the performance of their method
at fixed time intervals which matches our PLL objective (e.g. Djuric et al. (2020); Jain et al. (2019); Chai
et al. (2019)). In contrast, optimizing the joint log-likelihood is preferred for tasks that require sampling
realistic looking trajectories, as it is done for instance in sentence generation (Vaswani et al., 2017).
4.2 Approximating the Predictive Log-Likelihood using Bidimensional Moment Matching
We are interested in the predictive log-likelihood PLL (y1,...,yT|I), which describes the predictive log-
likelihood of all traffic participants up to time step T. In order to calculate it, we need to solve the nested
set of integrals given in Eq. (15). The BMM algorithm allows us to approximate the transition kernel
p(xt|I) =/integraltext
p(xt|x0,I)p(x0|I)dx0in case that the initial state x0has a Gaussian distribution. However,
in our model formulation the initial latent state x0follows a GMM to allow for multimodality. In order to
account for that, we approximate the marginal latent distribution p(xt|I)as
p(xt|I)≈V/summationdisplay
v=1πv(I)p(xt,v|I), (16)
where each mixture component p(xt,v|I)is approximated with the BMM algorithm as p(xt,v|I)≈
N(µt,v(I),Σt,v(I)). Assuming a GMM at the initial state allows us to efficiently obtain multimodal predic-
tions while being computationally efficient: We obtain multimodal distributions by explicitly marginalizing
over the mixture components and we compute each component efficiently by applying the BMM algorithm.
Finally, we approximate the marginal distribution p(yt|I)as a GMM by another round of moment matching
p(yt|I) =/integraldisplay
p(yt|g(xt),diag(Γ(xt)))p(xt|I)dxt (17)
≈V/summationdisplay
v=1πv(I)N(at,v(I),Bt,v(I)),
whereat,v(I)andBt,v(I)are the mean and covariance of the v-th mixture component at the t-th time step.
These two moments are available as
at,v(I) =E[g(xt,v)], B t,v(I) = Cov[g(xt,v)] +diag(E[Γ(xt)]), (18)
whichisadirectoutcomeofthelawoftheunconsciousstatistician. Wepresentthepseudocodeforcomputing
p(yt|I)using our method in Algorithm 1. Algorithm 2 further shows how we can optimize our model
parameters employing the PLL [Eq. (15)] as a training objective.
Inourmethod, weapproximate p(xt,v|I)andp(yt|I)byapplyingmomentmatchingtoeachGaussianmixture
component independently. We note that this approximation becomes exact for locally linear transition and
emission functions as stated in Thm. 1.
Theorem 1. The marginal distribution p(yt|I)is analytically computed as
p(yt|I) =V/summationdisplay
v=1πv(I)N(at,v(I),Bt,v(I)),
for a GDSSM with the below generative model
v∼Cat([π1(I),...,πV(I)]),
x0∼N(µ0,v(I),diag(Σ0,v(I))),
xt∼N (xt|xt−1+f(t,v,I)xt−1,diag(L(t,v,I))), t = 1,...,T
yt∼N (yt|g(t,v,I)xt,diag(Γ(t,v,I))), t = 1,...,T
wheref(t,v,I),L(t,v,I),g(t,v,I),Γ(t,v,I)are timet, component v, and contextIdepending matrices with
appropriate dimensionality.
9Published in Transactions on Machine Learning Research (03/2023)
Proof.The proof is straightforward as the output moments of the transition and emission function are
analytically tractable. We provide details in App. A.
Algorithm 1 Bidimensional Moment Matching in Latent Space ( BMMLS)
Inputs:T ▷Prediction horizon
I ▷Context variable
f(xt,I;θf) ▷Mean update
L(xt,I;θL) ▷Covariance update
g(xt;θg) ▷Mean emission
Γ(xt;θΓ) ▷Covariance emission
h(I;θh) ▷Embedding function
Outputs: Approximate marginal distribution p(yT|I)
µ0,1:V(I),Σ0,1:V(I),πv(I) =h(I;θh) ▷GMM at initial step, Eq. 13
formixture component v∈{1,···,V}do
fortime stept∈{0,···,T−1}do ▷Horizontal Moment Matching
µt+1,v←µt(I) +E[f(xt,I;θf)] ▷Eq. 6
Σt+1,v←Σt(I) + Cov[f(xt,I;θf)] + Cov[xt,f(xt,I;θf),] + Cov[xt,f(xt,I;θf)]T+diag(E[L(xt,I;θL)]) ▷Eq. 6
end for
aT,v(I)←E[g(xT,v;θg)] ▷Eq. 18
BT,v(I)←Cov[g(xT,v;θg)] +diag(E[Γ(xT;θΓ)]) ▷Eq. 18
end for
return/summationtextV
v=1πv(I)N(aT,v(I),BT,v(I))
Algorithm 2 Deterministic Training of a GDSSM
Inputs:D ▷Dataset
f(xt,I;θf) ▷Mean update
L(xt,I;θL) ▷Covariance update
g(xt;θg) ▷Mean emission
Γ(xt;θΓ) ▷Covariance emission
h(I;θh) ▷Embedding function
Outputs: Optimized weights θ={θf,θL,θg,θΓ,θh}
while not converged do
I,y1:T∼D ▷SampleIandy1:Tfrom dataset
foryt∈y1:Tdo
p(yt|I) =BMMLS (t,I,f,L,g, Γ,h) ▷Approximate marginal distribution p(yt|I)via algorithm 1
end for
PLL(y1,...,yT|I) =/summationtextT
t=1logp(yt|I) ▷Calculate predictive log-likelihood 15
θ←θ+∂PLL (y1:T|I)
∂θ▷Update weights θ
end while
returnθ
For general non-linear transition and emission functions, the quality of this scheme depends on two factors:
(a) how well the transition and emission function can be approximated in a locally linear fashion and (b) if
the covariance matrix Σt,vis small enough over the time horizon t. We observe in our experiments that the
approximation works well and further illustrate its behavior on a small toy dataset in Fig. 2. Finally, we note
that Gaussian mixture models have also been successfully used for filtering problems (Alspach & Sorenson,
1972) where, similar as in our work, moment matching is performed for each component individually in the
predict step.
4.3 Output Moments of Graph Neural Network Layers
In order to use the the BMM framework, we need to be able to calculate the first two output moments as well
as the expected Jacobian of graph neural network layers. In the following, we derive the analytic expression
of the output moments and expected Jacobian for the common graph neural net layers: (i) node-wise affine
transformation, and (ii) mean aggregation. Output moments for the ReLU activation are provided in Wu
et al. (2019). For completeness, we also provide the output moments for the ReLU activation in App. B.
Letxl,m
t∈RDx,lbe the node features at layer lof nodemat time step tandxl
t={xl,m
t}M
m=1the set of
all node features with xl
t∈RMDx,l. For the sake of brevity, we have omitted here the index of the mixture
10Published in Transactions on Machine Learning Research (03/2023)
0 1 2 3 4 5
Time in seconds2
1
0123Value1.00
0 1 2 3 4 5
Time in secondsValue0.31 0.69
0 1 2 3 4 5
Time in secondsValue0.34 0.33 0.33
0 1 2 3 4 5
Time in secondsValue0.34 0.33 0.00 0.33
Figure 2: Predictions of our model after training on an one-dimensional, multi-modal toy problem. Solid
black lines represent the ground truth dynamics with three different modes of equal probability. For our
model, we report for each predicted mode the mean, 95% confidence interval and mixture weight. We set the
dimension of the latent space to Dx= 3and vary (from left to right) the number of modes Vin the model
from 1 to 4. For V < 3, the number of modes is set too small, and we observe mode covering behavior. For
V≥3, our model can recover the ground truth dynamics. If the number of components is too high (V=4),
the mixture weights of redundant components are set to zero.
component v. We denote mean and covariance of a graph with Mnodes at layer land time step tas
E[xl
t] =
E[xl,1
t]
...
E[xl,M
t]
, Cov[xl
t] =
Cov[xl,1
t,xl,1
t]... Cov[xl,1
t,xl,M
t]
.........
Cov[xl,M
t,xl,1
t]... Cov[xl,M
t,xl,M
t].
, (19)
where E[xl,m
t]∈RDx,landCov[xl,m
t,xl,m′
t]∈RDx,l×Dx,l. A typical GNN architecture (see Sec. 2.3) consists
of alternating aggregation steps, in which information of all neighbors is collected, and update steps, in
which the features of the node are updated. For the aggregation step, we derive the output moments for
the commonly used mean aggregation operation in Sec. 4.3.3. For the update step, we assume that the
neural network is built as a sequence of affine transformations and nonlinearities. The output moments of
nonlinear activations are applied independently across agents. As a consequence, their rules do not change
when used in the GNN setting and we can use the derivations from Wu et al. (2019). Hence it remains open
to derive the output moments for affine transformations, as they are used in GNN context, which we tackle
in Sec. 4.3.2. The mean aggregation operation and the node-wise affine operation used in the update step
are special cases of a standard affine layer, which we review in Sec. 4.3.1.
4.3.1 Standard Affine Transformation
Suppose we apply an affine transformation to node mat layerlwith statexl,m
t
xl+1,m
t =Wlxl,m
t+bl, (20)
with weight matrix Wland biasbl. The output moments are analytically tractable as
E[xl+1,m
t ] =WlE[xl,m
t] +bl, Cov[xl+1,m
t ] =WlCov[xl,m
t](Wl)T.
The expected Jacobian of the affine transformation reads as Jl
t=Wl.
4.3.2 Node-Wise Affine Transformation
Thenode-wiseaffinetransformationappliestoeachnode matlayerlwithstatexl,m
tthesametransformation
simultaneously with weight matrix Wland biasbl. The node-wise affine transformation can be interpreted
11Published in Transactions on Machine Learning Research (03/2023)
as a standard affine transformation acting on the set of all nodes xl
tas

Wlxl,1
t+bl
Wlxl,2
t+bl
...
Wlxl,M
t+bl
=
Wl0... 0
0Wl... 0
............
0 0... Wl

xl,1
t
xl,2
t
...
xl,M
t
+
bl
bl
...
bl
= (IM⊗Wl)/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
ˆWlxl
t+ (1M⊗bl)/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
ˆbl,(21)
whereIMis the identity matrix with shape M×M,1Mis a vector of ones with shape M×1, and⊗is the
Kronecker product. The output moments of node-wise affine transformation are
E[xl+1
t] =ˆWlE[xl
t] +ˆbl, Cov[xl+1
t] =ˆWlCov[xl
t](ˆWl)T.
Similarly as for the standard affine transformation, the expected Jacobian of node-wise affine transformation
is analytically available as Jl
t=ˆWl.
4.3.3 Mean Aggregation
A commonly used aggregation operation is the mean aggregator, which calculates the message xl,Nm
tto node
mat time step tat layerlas
xl,Nm
t =1
|Nm|/summationdisplay
m′∈Nmxl,m′
t. (22)
Letxl,N
tbe the set of all messages, i.e. xl,N
t={xl,Nm
t}M
m=1. The mean aggregation can be equivalently
written as a linear transformation
xl,N
t= (A⊗IDx,l)/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
ˆAxl
t. (23)
Above,A∈RM×Mdenotes the row normalized adjacency matrix, which summarizes the edge information
Ein matrix format and IDx,ldenotes the identity matrix with dimensionality Dx,l×Dx,l. The Kronecker
product expands the adjacency matrix accordingly to the Dx,l-dimensional node features. Hence, the mean
aggregation corresponds to a linear transformation with a weight matrix consisting of M×Mblocks, where
each block is a diagonal matrix of shape Dx×Dx. Its moments are analytically available as
E[xl,N
t] =ˆAE[xl
t], Cov[xl,N
t] =ˆACov[xl
t]ˆAT. (24)
The expected Jacobian is available as Jl
t=ˆA.
4.4 Sparse Covariance Approximation
For settings with a large number of agents Mor with a high-dimensional state xl,m
t, the application of
the BMM algorithm can become computationally expensive. In the following, we review the computational
complexity of the BMM algorithm. We assume that the GNN model consists of a mean aggregation step
followed by multiple node-wise affine transformations and nonlinearities, which is the same architecture that
we employ later on in our experiments. The mean aggregation is done for each of the Dxlatent states
independently, and we denote the maximum hidden layer width with H.
Computing the nonlinearities is cheap as the operation acts elementwise and their effect on the runtime can
be neglected during this analysis. The other two operations (see Sec. 4.3.2 and Sec. 4.3.3) can be described by
affine operations for which the weight matrices are heavily structured; the mean aggregation step corresponds
to a weight matrix consisting of M×Mdiagonal blocks, the node-wise affine transformation to a block-
diagonal weight matrix with Mblocks of shape H×H. Propagation of the full covariance matrix through a
neuralnetwork(forwardcost)hasthecomputationalcomplexityof O(M2H3+M2H2Dx+M2HD2
x+M3D2
x),
where the first term is due to the cost of the H×H-dimensional node-wise affine transformations in the
hidden layers, the second and third term are due to the cost of the H×D-dimensional node-wise affine
transformation after the aggregation operation, and the fourth term is due to the aggregation operation.
12Published in Transactions on Machine Learning Research (03/2023)
Figure 3: Groupings of the covariance matrix for graph structured data. Consider the example graph with
M= 5agents, which is depicted in the left panel. Each agent has dimensionality Dx. In the middle panel,
we show the covariance matrix between all agents, which consists of 5×5blocks, where each block has
dimensionality Dx×Dx.
The computational cost of the expected Jacobian is O(MH3+MH2Dx+M2D2
x)and we give its derivation
in the following. Let the expected Jacobian of the aggregation operation be E[J1
t]and the product of the
expected Jacobians of the subsequent neural net layers E[Jnet
t] =/producttextL
l=2E[Jl
t]. The expected Jacobian of
the neural net layers E[Jnet
t]is block-diagonal with Mblocks of shape Dx×Dxand its computation takes
O(MH3+MH2Dx)time. Multiplying E[J1
t]withE[Jnet
t]results in a fully populated matrix where each
entry can be computed by a single dot product, due to the structure of its factors, and its computation
contributes withO(M2D2
x)to the runtime.
Consequently, thetotalcostisdominatedbytheforwardcost, O(M2H3+M2H2Dx+M2HD2
x+M3D2
x),when
using the full covariance matrix.1Since the computational cost quickly becomes intractable due to the
cubic dependence with respect to the number of agents in the forward pass, we next propose different sparse
approximations to the covariance matrix. Independent of the chosen approximation, the cost of the expected
Jacobian remains unchanged, as it does not depend on the covariance matrix.
•Full: Model the full covariance matrix.
Forward cost:O(M2H3+M2H2Dx+M2HD2
x+M3D2
x).
Total cost:O(M2H3+M2H2Dx+M2HD2
x+M3D2
x).
•Main Diagonal : Keep the diagonal entries in the covariance blocks, which corresponds to the blue
line in Fig. 3.
Forward cost:O(MH2+MHDx+M2Dx).
Total cost:O(MH3+MH2Dx+M2D2
x).
•Main Blocks : Keep the block-diagonal blocks in the covariance matrix, which corresponds to the
orange blocks and blue lines in Fig. 3.
Forward cost:O(MH3+MH2Dx+MHD2
x+M2D2
x).
Total cost:O(MH3+MH2Dx+MHD2
x+M2D2
x).
•All Diagonals : Structure the covariance matrix in blocks of shape M×Mand keep the diagonal
entries in each block, which corresponds to the blue and red lines in Fig. 3.
Forward cost:O(M2H2+M2HDx+M3Dx).
Total cost:O(M2H2+M2HDx+M3Dx+MH3+MH2Dx+M2D2
x).
Note that setting the off-diagonal blocks to zero, as done in Main Blocks and Main Diagonal, corresponds to
an independence assumption between the agents and leads to a runtime reduction from O(M3)toO(M2). In
contrast, assuming a diagonal structure within each block, as performed in Main Diagonal and All Diagonals,
corresponds to an independence assumption between the features and leads to runtime reduction from O(H3)
toO(H2)in the forward pass.
1For reference, taking a Monte Carlo approach has the computational complexity O(SMH2+SMHD x+SM2Dx)where
Sis the number of Monte Carlo samples.
13Published in Transactions on Machine Learning Research (03/2023)
Vehicle 1
Vehicle 2
Vehicle 3
Vehicle 4
Vehicle 5
Vehicle 6
(a) Example Scene.
123456
Vehicle1
2
3
4
5
6Vehicle
8
6
4
2
0Log Covariance (b) Covariance at 1 second.
123456
Vehicle1
2
3
4
5
6Vehicle
8
6
4
2
0Log Covariance (c) Covariance at 3 seconds.
123456
Vehicle1
2
3
4
5
6Vehicle
8
6
4
2
0Log Covariance (d) Covariance at 5 seconds.
Figure 4: We visualize an example scene from the rounD dataset (Krajewski et al., 2020) and the covariance
matrix in the latent space at different time steps for the case of a unimodal initial distribution. In the left
plot, dashed lines represent the observed history and solid lines represent the true future trajectories.
Finally, it is important to note that the covariance matrix only has the same structure as the graph after
the first time step. Agents that are not connected via an edge can still have a non-zero cross-covariance at
time stept, provided that they are connected by a path that is at most tsteps long. In our applications,
this leads to non-sparse covariances after a few time steps, since the number of agents is small compared to
the time horizon. We present the covariance matrix at three different time steps for an exemplary scene in
Fig. 4. For a short prediction horizon of one second, the covariance matrix has an approximately diagonal
shape. As the prediction horizon increases, the covariance matrix becomes more complex and is no longer
dominated by its diagonal entries. We remark that the we could further increase the information spread
across agents by using an architecture with multiple aggregation steps within the GNN module if required.
5 Experiments
We provide experiments on two challenging autonomous driving datasets. The first experiment (Sec. 5.1)
conducts an ablation study, while the second experiment (Sec. 5.2) benchmarks our model against state-
of-the-art methods. We provide a runtime analysis and a benchmark of our proposed sparse covariance
approximations in Sec. 5.3. In Sec. 5.4, we analyse the generalization capabilities of our model by bench-
marking it on novel unseen traffic environments.
We provide details about the training procedure in App. C, and the architecture for the embedding, tran-
sition, and emission functions in App. H. Accompanying code is available under https://github.com/
boschresearch/Deterministic-Graph-Deep-State-Space-Models .
Asevaluationmetrics, weusetheRoot-Mean-SquareError(RMSE)andthepredictivenegativelog-likelihood
(NLL) at fixed time intervals (1s, 2s, 3s, 4s, 5s). For more details about the evaluation, we refer to App. D.
5.1 rounD
The rounD dataset (Krajewski et al., 2020) consists of vehicle trajectories recorded at different roundabouts
in Germany. As the roundabouts involve many interactions among vehicles, we expect the predictive distri-
butions to be multimodal and highly complex. We use the recordings from the roundabout in Neuweiler near
Aachen for training and testing purposes. The dataset consists of 13,129 tracked objects recorded at 25Hz
in 22 sessions, amounting to a total recording time of 6.6hours. We remove pedestrians, bicycles, as well as
parked vehicles from the dataset, as their influence on the vehicle behaviour patterns in the roundabouts is
negligible. After dataset curation, we are left with 12,715 tracked objects. We downsample the recordings by
a factor of five and construct a dataset consisting of eight-second-long segments with 50% overlap, resulting
in 5405 snippets. We use the first three seconds as the track history, which is part of the context variable
I, and the following five seconds as the prediction horizon. The first 18 recording sessions, corresponding
to 4,314 snippets, are used for training and validation. The final four recording sessions, corresponding to
1,091 snippets, are used for testing.
14Published in Transactions on Machine Learning Research (03/2023)
We build the connection graph by connecting vehicles with an Euclidean distance of less than 30meters.
The dataset has been recorded with drones and we keep the original global coordinate system.
5.1.1 Baselines
We compare our method with multiple baselines models. For each baseline, we remove one key assumption of
our model. We cite papers that employ similar ideas as appropriate. We did not reimplement these works but
performed an ablation study in which we replaced specific components of our model in the interest of a fair
comparison. Furthermore, we compare against different training strategies as an alternative to maximizing
the PLL and analyze the multimodality of our model.
(i) Model :
(i.i) GDSSM : Our model as proposed in Sec. 4.
(i.ii) Non Recurrent GNN (e.g. Casas et al. (2020); Herman et al. (2022)): This architecture receives the
context variableI, performs one round of message passing, and subsequently outputs one normal
distribution for each of the next five seconds without using a recurrent architecture.
(i.iii) No Latent Noise (e.g. Sanchez-Gonzalezetal.(2020)): Weremovethenoisefromthelatentdynamics
[Eq. (2)] while keeping the emission model unchanged. The uncertainty can no longer be propagated
forward in time as the emission model acts independently for each time point.
(i.iv) Linearity (e.g. Li et al. (2020)): We remove all non-linearities from the latent dynamics. Note that
we keep the non-linear emission model in order to map the dynamics into a latent space in which
the system can be linearly approximated.
(i.v) No Interactions (e.g. Krishnan et al. (2017)): Our model with a diagonal adjacency matrix, i.e. we
remove all edges from the graphs. This model neglects interactions between traffic participants.
(ii) Modes :
(ii.i)VModes: We vary the number of mixture components Vin the GMM prior [Eq.(12)] in order to
test the effect of multimodality.
(ii.ii)∞Modes: This alternative does not follow an assumed density approach, i.e. the marginal latent
distribution p(xt|I)is not approximated as a GMM with a bounded number of modes. Instead
p(xt|I)is approximated by simulating a large number of trajectories, where each trajectory can
follow a different mode (Brandt & Santa-Clara, 2002). We set the number of particles to 100.
(iii) Objectives :
(iii.i) PLL/Det. : We train the model on the predictive log-likelihood [Eq.(15)] and use our deterministic
approximations for GDSSM as proposed in Sec. 4.2 and Sec. 4.3.
(iii.ii) PLL/MC : We train the model on the predictive log-likelihood [Eq.(15)] and take an assumed density
approach by approximating the marginal distribution [Eq.(17)] as a GMM. The intractable integrals
are solved via Monte Carlo (MC) integration. One forward pass through our model amounts ap-
proximately to the computational cost of 12 Monte Carlo simulations. For a fair comparison, we use
during training 16 particles, which is more costly than training with our proposed moment propaga-
tion algorithm, and test with 100 particles. We use the same amount of particles for all MC based
methods.
(iii.iii) ELBO/MC (e.g. (Krishnan et al., 2017)): The model is trained by maximizing the Evidence Lower
Bound(ELBO). We give a description of this loss function in App. E. The approximate posterior
is a filtering distribution that models the latent state as a normal distribution. We propagate the
latent state forward in time direction via Monte Carlo sampling.
15Published in Transactions on Machine Learning Research (03/2023)
(iii.iv) MCO/MC (e.g. (Maddison et al., 2017)): The model is trained by maximizing the Monte Carlo
Objective (MCO), which combines particle filters with variational inference. We give a description of
this loss function in App. E. The proposal distribution is a filtering distribution and we propagate
the particles in time direction via Monte Carlo sampling.
5.1.2 Results
We provide benchmark results of all methods in Tab. 1. First, we compare our deterministic training
and testing scheme (GDSSM PLL/Det.) against its Monte Carlo alternative (GDSSM PLL/MC). Though
Monte Carlo based training is more costly than training with BMM, the Monte Carlo results are significantly
outperformed by our method. Our results indicate that our deterministic approach leads to more effective
approximations compared to Monte Carlo sampling despite the approximation error we obtain by our de-
terministic moment matching scheme. One potential explanation for our finding is that the Monte Carlo
approaches suffer under a high variance since the latent space for multi-agent space grows linearly with the
number of agents.
When changing the training objective from the PLL to ELBO/MC or MCO/MC, we observe that the
performance is comparable to PLL/MC for the prediction horizon of 1second. For longer prediction horizons,
the performance of the models that are trained on ELBO/MC or MCO/MC degrade quicker compared to
the model trained on PLL. We believe that this behavior can be explained by the mismatch between training
and testing objectives. When training on MCO/MC or ELBO/MC, the model obtains feedback from the
observationsviatheproposaldistribution, whileduringtestingithastoproducemulti-stepaheadpredictions
without receiving any feedback from the observations.
Next, we study if our method can capture multimodality by increasing the number of components in the
GMM prior. It is worth noting that GMMs can approximate arbitrarily complex distributions when the
number of components is chosen high enough. In our experiments, we observe that an increase of components
significantly decreases the NLL, making the GMM prior a vital ingredient of our method and suggesting
that the true predictive distribution is highly multi-modal. If the number of components is chosen too small,
our model adjusts its uncertainty predictions accordingly. For example, we observe in Fig. 1 the uncertainty
of the orange agent to increase as the vehicle is close to the exit of the roundabout. The high predictive
uncertainty can be explained by two potential future outcomes: the orange vehicle can leave the roundabout
or stay inside. Consequently, our model learns to compensate if the number of components is picked too low,
which in turn allows us to trade accuracy for computational runtime. When using tailored implementations,
one can easily scale up to a larger number of components, since their computations can be parallelized
without any hurdles. We further note that the RMSE is less affected by the choice of the number of modes
and stays within two standard errors. Since the RMSE value measures the error between the true value and
the expected value of the predictive distribution, this result suggests that the expected value can already
be modeled well by predictive distributions with very few modes (actually, one mode seems to suffice for
this). We further provide the minRMSE values in App.F that decrease with increasing number of modes,
indicating that the different modes correspond to a diverse set of plausible trajectories.
Next, we compare our model to a simpler alternative in which the dynamics are assumed to be linear, which
allows calculating the moments of the transition model exactly and in closed form (Särkkä & Solin, 2019).
In contrast, our approach, GDSSM, approximates the non-linear dynamics in a local linear way by using
deterministic moment matching results. We find that our approach achieves lower RMSE and NLL, which
can most likely be attributed to the higher modeling flexibility of our proposed model class.
Our ablation study further shows that discarding latent noise and removing interactions between traffic
participants results in higher RMSE and NLL. Compared to modeling the dynamics in a non-recurrent
manner, our model achieves a similar RMSE and outperforms its competitor in terms of NLL.
5.2 NGSIM
TheNext Generation Simulation (NGSIM) dataset (Halkias & Colyar, 2007) consists of vehicle trajectories
recorded at 10Hz at two different highways, US-101 and I-80, in the United States. The dataset is commonly
16Published in Transactions on Machine Learning Research (03/2023)
Table 1: RounD results. We provide RMSE and NLL (mean ±standard error over 10 runs).
Non Recur. GDSSM GDSSM GDSSM GDSSM GDSSM GDSSM GDSSM GDSSM GDSSM GDSSM
GNN No Lat. Noise Linear No Interaction
1 Mode∞Modes∞Modes 1 Mode 1 Mode 1 Mode 1 Mode 1 Mode 2 Modes 3 Modes 4 Modes
PLL/Det. ELBO/MC MCO/MC PLL/Det. PLL/Det. PLL/Det. PLL/MC PLL/Det. PLL/Det. PLL/Det. PLL/Det.RMSE1s0.72±0.021.53±0.040.95±0.04 1.22±0.080.88±0.020.91±0.030.90±0.020.79±0.020.75±0.020.74±0.030.73±0.03
2s1.90±0.023.42±0.092.43±0.09 2.33±0.082.12±0.032.10±0.042.09±0.021.87±0.031.84±0.031.82±0.031.80±0.04
3s3.54±0.035.99±0.144.55±0.16 3.88±0.073.88±0.053.69±0.063.60±0.043.36±0.033.35±0.033.35±0.033.33±0.04
4s5.26±0.049.24±0.267.62±0.27 5.58±0.086.13±0.095.39±0.135.37±0.055.08±0.045.15±0.095.14±0.085.06±0.04
5s7.20±0.0511.59±0.4111.24±0.417.65±0.108.83±0.137.56±0.237.65±0.067.24±0.057.34±0.127.35±0.197.29±0.09NLL1s1.90±0.012.62±0.042.79±0.06 2.96±0.081.95±0.081.67±0.072.82±0.031.48±0.051.34±0.081.36±0.041.21±0.05
2s3.25±0.024.45±0.074.21±0.03 3.85±0.103.93±0.133.37±0.084.11±0.022.91±0.032.93±0.072.93±0.062.79±0.09
3s4.40±0.025.64±0.095.21±0.03 5.05±0.135.11±0.194.34±0.084.67±0.093.87±0.024.01±0.073.77±0.103.83±0.08
4s5.13±0.026.59±0.136.01±0.03 6.17±0.166.01±0.224.93±0.095.01±0.074.46±0.034.52±0.114.21±0.154.34±0.18
5s5.71±0.026.98±0.146.73±0.04 7.24±0.206.80±0.225.51±0.105.41±0.055.05±0.044.82±0.244.59±0.154.27±0.23
used for benchmarking traffic forecasting methods and allows us to compare our method against prior art.
We adopt the experimental setup of Deo & Trivedi (2018) and use both highway scenarios. As provided
in the original publication, we employ a local coordinate system that is centered around an ego-vehicle.We
split the scenarios into three 15 minute long time spans resembling mild, moderate, and congested traffic
conditions and downsample each trajectory by a factor of two. The test set consists of a fourth of all
trajectories randomly sampled from both locations. As in the rounD experiment, we split each trajectory
into eight-second-long segments, where the first three seconds are used as the track history and the following
five seconds as the prediction horizon.
Similarly as in Diehl et al. (2019); Lenz et al. (2017); Wheeler & Kochenderfer (2016), we introduce a
connection graph based on the lane position of each vehicle. Each vehicle has at most six connections to
other vehicles, which are the nearest vehicles in front/behind on the same/left/right lane. The vehicles on
the outermost lanes have a maximum of four neighbours, as there are no neighbours to the left or right.
5.2.1 Baselines
We compare our approach with the following methods:
(i) Constant Velocity (Mercat et al., 2019): This method uses a linear state-space model together with a
Kalman filter in order to make predictions. It does not take interactions between agents into account.
(ii) Convolutional Social (CS)-LSTM (Deo & Trivedi, 2018): Interactions between vehicles are modeled by
introducing a grid and applying a convolutional layer on top. Dynamics are modeled by a deterministic
LSTM, which predicts the mean and the variance of a normal distribution at each time step.
(iv) Spatio-Temporal (ST)-LSTM (Chen et al., 2020): Interactions are modeled with a spatio-temporal
graph structure, i.e. a graph with a position and time depending component. Dynamics are modeled by a
deterministic LSTM that predicts the mean and the variance of a normal distribution at each time step. To
the best of our knowledge, this is the only GNN based method that also reports NLL.
(iv) Multiple Futures Prediction (MFP) (Tang & Salakhutdinov, 2019): A recurrent model with deterministic
transition dynamics. Stochasticity is introduced via the initial state and noisy observations that are fed back
into the dynamical model. Interactions are modeled by an attention module.
5.2.2 Results
We provide benchmark results of our proposed model in Tab. 2. Similar to the experiments on the rounD
dataset in Sec. 5.1, we observe that (i) deterministic training and testing is more efficient than its Monte
Carlo based alternative and (ii) increasing the number of modes improves the performance.
Next, we compare our method, using one component in the GMM prior only, with all other unimodal
prediction methods. We can observe that our approach outperforms its competitors in terms of NLL.
Furthermore, our method gives similar RMSE as other methods and is only outperformed by MFP. However,
and in contrast to the other methods in the benchmark, MFP reports the best RMSE over 5 Monte Carlo
samples, which makes it difficult to draw a fair conclusion.
17Published in Transactions on Machine Learning Research (03/2023)
We subsequently increase the number of modes for our model and for MFP. In terms of NLL, our method
achieves superior results when it comes to long-term predictions (3s, 4s, 5s), while MFP performs better for
short-term predictions (1s, 2s). Accurate long-term prediction of the agents in a driving scene is crucial for
high-level autonomous driving, as an accurate environment model is a prerequisite for precise planning of
driving controls. For instance, advanced driver-assistance systems usually use time horizons between 3s and
5s for driver warnings and emergency brakes, while autonomous cars aim for a time horizon for 5s or longer
in order to ensure safe and comfortable rides (Philipp & Goehring, 2019). We provide minRMSE values for
different number of modes as a measure of predictive diversity in App. F.
Table 2: NGSIM results. We provide RMSE and NLL averages and standard errors over 10 runs. For MFP,
we report the best RMSE values over 5 Monte Carlo samples.
Const. Vel. CS-LSTM ST-LSTM MFP MFP GDSSM GDSSM GDSSM GDSSM GDSSM
1 Mode 1 Mode 1 Mode 1 Mode 4 Modes 1 Mode 1 Mode 2 Modes 3 Modes 4 Modes
PLL/MC PLL/Det. PLL/Det. PLL/Det. PLL/Det.RMSE1s 0.75 0.61 0.51 0.54 0.54 0.56±0.000.53±0.010.55±0.000.55±0.010.57±0.02
2s 1.81 1.27 1.21 1.16 1.17 1.27±0.021.18±0.011.22±0.011.23±0.021.24±0.04
3s 3.16 2.09 2.01 1.90 1.91 2.11±0.031.98±0.022.02±0.022.05±0.032.06±0.04
4s 4.80 3.10 3.01 2.78 2.75 3.16±0.042.99±0.033.03±0.043.06±0.053.05±0.06
5s 6.70 4.37 4.31 3.83 3.78 4.47±0.054.29±0.044.33±0.074.33±0.074.35±0.08NLL1s 0.80 0.58 0.90 0.73 -0.65 0.64±0.040.19±0.02-0.12±0.02-0.15±0.03-0.16±0.03
2s 2.30 2.14 2.41 2.33 1.19 2.10±0.101.61±0.021.37±0.021.35±0.021.32±0.02
3s 3.21 3.03 3.25 3.17 2.28 2.92±0.112.42±0.022.23±0.022.23±0.022.19±0.02
4s 3.89 3.68 3.61 3.77 3.06 3.54±0.103.02±0.022.88±0.022.88±0.022.82±0.02
5s 4.44 4.22 4.36 4.26 3.69 4.04±0.103.50±0.023.42±0.023.41±0.023.36±0.02
5.3 Covariance Approximations
We provide a detailed runtime analysis for different covariance approximations in Sec. 5.3.1 and study their
impact on the predictive performance in Sec. 5.3.2.
5.3.1 Runtime
We visualize the runtime of different covariance approximations, as well as the runtime of the Monte Carlo
alternative in Fig. 5 as a function of input dimensionality and number of agents. We use the same NSDE
architecture as in our experiments on the rounD and NGSIM dataset. For the Monte Carlo alternative, we
visualize the runtime for 16 particles, as we use the same number of particles for training in Sec. 5.1 and
5.2.
We first confirm that propagation of the full covariance matrix is more costly than any of the proposed
approximations. In fact, our sparse covariance approximations can reduce the runtime up to a factor of 100
for systems with a large number of agents and a high input dimensionality. As we derived in Sec. 4.4, when
usingtheBMMalgorithmwithafullcovariancematrixorthealldiagonalsapproximation, thecomputational
cost shows a cubic dependence on the number of agents. In contrast, the main diagonal approximation, the
main blocks approximation, as well as MC based predictions have a quadratic dependence on the number
of agents. This makes these two approximations an attractive alternative to MC based predictions, when
systems with a high number of agents need to be modeled with a limited computational budget.
For systems with a moderate input dimensionality ( ≈8) and number of agents ( ≈16), all of our proposed
approximations require only up to 5ms in order to compute the distribution at the next time point, which
corresponds to the cost of 5-10 Monte Carlo simulations.
5.3.2 Benchmark
Next, we study the effect of different covariance approximations on the performance. We report the results
for the case of a unimodal GDSSM. The results are depicted in Tab. 3. We report here our main findings.
First, modeling the full covariance matrix results in the best performance in terms of lowest RMSE and NLL.
Second, the all diagonals covariance approximation performs the best among the covariance approximations.
18Published in Transactions on Machine Learning Research (03/2023)
21232527
Input Dimensionality104
103
102
101
100101102Time in sFull
21232527
Input Dimensionality Time in sMain Diagonal
21232527
Input Dimensionality Time in sMain Blocks
21232527
Input Dimensionality Time in sAll Diagonals
21232527
Input Dimensionality Time in sMonte Carlo
21 Agents
22 Agents
23 Agents
24 Agents
25 Agents
Figure 5: Wallclock time for output moment calculation for the latent dynamics using GNNs with three
hidden layers of size 24 for different covariance approximations (from left to right). For each approximation,
we plot the runtime as a function of the input dimensionality Dxand number of agents M. The GNNs are
initialized at random and we report the average runtime over 100 repetitions.
It achieves comparable RMSE as the full solution, but falls slightly behind in NLL when the system is highly
interactive (see rounD dataset). In this setting, it outperforms the other two sparse approximations with
respect to NLL. This behavior might be explained by the assumptions made in the covariance approxima-
tion: it is the only approximation that allows for correlations between agents as its structure only neglects
dependencies between latent features.
Third, thedifferencesinperformancesbetweenthefullsolutionandthedifferentapproximationswithrespect
to RMSE lie between one and two standard errors. Modeling the main diagonal only can thus be sufficient
for applications with low computational resources and a high demand in accuracy by accepting a slight loss
in calibration. For these applications, the runtime can be reduced from O(M3)toO(M2).
Table 3: Test performance for different covariance approximations on the rounD and NGSIM dataset for the
unimodal case. We provide average and standard error over 10 runs.
rounD NGSIM
Full Main Diagonal Main Blocks All Diagonals Full Main Diagonal Main Blocks All DiagonalsRMSE1s0.79±0.020.82±0.02 0.83±0.040.78±0.020.53±0.010.54±0.01 0.55±0.010.53±0.01
2s1.87±0.021.88±0.02 1.89±0.051.87±0.021.18±0.011.18±0.02 1.19±0.021.19±0.02
3s3.36±0.033.40±0.02 3.38±0.063.34±0.021.98±0.021.99±0.03 2.05±0.031.99±0.02
4s5.08±0.045.07±0.04 5.09±0.075.05±0.032.99±0.032.98±0.04 3.07±0.042.97±0.03
5s7.24±0.057.25±0.06 7.30±0.087.25±0.054.29±0.044.34±0.05 4.54±0.064.32±0.04NLL1s1.48±0.051.77±0.06 1.79±0.051.69±0.030.19±0.020.24±0.04 0.22±0.030.18±0.03
2s2.91±0.033.34±0.04 3.35±0.063.25±0.021.61±0.021.63±0.03 1.64±0.031.59±0.03
3s3.87±0.024.27±0.03 4.28±0.054.18±0.022.42±0.022.44±0.02 2.46±0.032.43±0.02
4s4.46±0.035.00±0.02 5.01±0.054.92±0.023.02±0.023.04±0.02 3.06±0.043.01±0.02
5s5.05±0.045.69±0.02 5.68±0.065.64±0.053.50±0.023.59±0.02 3.62±0.033.57±0.02
5.4 Out-of-Distribution Testing
We analyze the generalization capabilities of our model by testing it on out-of-distribution data, e.g. traffic
environments that have not been observed during training.
For this experiment, we reuse the rounD dataset (Krajewski et al., 2020) since it consists of record-
ings at three different roundabouts. Here, each roundabout corresponds to a separate traffic environment.
We select one recording from each roundabout (Kackerstraße in Aachen, Thiergarten in Alsdorf and
19Published in Transactions on Machine Learning Research (03/2023)
Neuweiler near Aachen) and apply the same data curation steps as in Sec. 5.1. In order to generalize
between different traffic environements, we change the experimental setup as follows:
•Local coordinate system: Wetransformthedataintoalocalcoordinatesystem, whichiscentered
at the ego-vehicle and is oriented to the heading direction of the ego-vehicle.
•Include map information to the context variable I.We extract a local map around the ego-
vehicle, which spans a rectangle with a length of 74meters and a width of 44meters. Afterwards, we
apply a binary masking to the map which divides the image into drivable and non-drivable areas.
Our task is to jointly model all vehicles, which lie within this rectangle.
More details on the preprocessing can be found in App. G.
5.4.1 Results
Next, we analyze the generalization capabilities of our model by comparing the following strategies: (1)
training on two traffic environments and testing on a third distinct traffic environment, (2) directly training
the model on the test traffic environment and (3) training on all traffic environments. In order to enable a
fair comparison, the data for each traffic environment is split into non-overlapping training and test sets.
We present the results for different traffic environments in Tab. 4. The first column in Tab. 4 de-
scribes the RMSE and NLL when we train our model on the traffic environments Thiergarten (T) and
Neuweiler (N) and test it on the traffic environment Kackertstraße (K). The second column describes the
predictive performance by using scenes from the same traffic environment (K) for training and testing. The
third column describes the predictive performance by training on all three traffic environments (KNT) and
testing on the traffic environment K. The remaining columns benchmark the generalization capabilities of
our model on the traffic environments T and N and are set up in an analogous fashion.
In all experiments, we observe that the performance increases from (1) using different training envi-
ronments for training and testing, to (2) using the same environment for training and testing and (3)
using all environments for training. The difference in performance between (1) and (2) is moderate for the
locations K and T demonstrating that our model is capable of generalizing to unseen traffic environments
during testing. For the location N, the performance difference is increased which can be explained by
studying the locations in more detail: N is a multi-lane roundabout with congested traffic, the roundabouts
K and T are single-lane with moderate traffic. In consequence, the out-of-domain test on the traffic
environment N is more challenging. We visualize exemplary predictions of our model GDSSM in Fig. 6.
Table 4: Test performance on different traffic environments on the rounD dataset using our method GDSSM
(1 mode). We vary for each test traffic environment the training traffic environments. We provide averages
and standard errors over 10 runs. Kackertstraße=K, Thiergarten=T, Neuweiler=N.
Test K T N
Train TN K KTN KN T KTN KT N KTNRMSE1s2.12±0.091.88±0.051.55±0.041.42±0.041.49±0.051.21±0.042.98±0.122.02±0.071.55±0.04
2s4.56±0.133.73±0.053.34±0.092.82±0.052.53±0.092.27±0.045.82±0.193.38±0.063.02±0.09
3s7.51±0.246.05±0.175.62±0.204.42±0.123.67±0.123.35±0.078.96±0.244.89±0.134.91±0.18
4s10.57±0.348.65±0.267.99±0.176.75±0.185.33±0.155.00±0.1612.44±0.336.81±0.146.91±0.18
5s13.00±0.3112.02±0.4310.73±0.279.97±0.407.59±0.297.41±0.2714.86±0.428.77±0.198.69±0.31NLL1s4.11±0.074.02±0.043.13±0.063.35±0.063.16±0.062.88±0.064.75±0.073.84±0.043.21±0.08
2s5.36±0.104.84±0.034.66±0.094.22±0.043.99±0.073.65±0.045.82±0.094.60±0.054.42±0.09
3s6.55±0.175.97±0.076.42±0.175.49±0.104.98±0.114.50±0.057.32±0.175.55±0.045.68±0.09
4s7.71±0.207.07±0.147.57±0.217.20±0.096.38±0.195.89±0.138.65±0.186.79±0.116.71±0.08
5s8.63±0.188.14±0.188.08±0.158.54±0.127.45±0.216.84±0.119.11±0.187.54±0.227.04±0.14
20Published in Transactions on Machine Learning Research (03/2023)
Prediction: Mode 1
Weight: 0.40
Prediction: Mode 2
Weight: 0.60
(a) Kackertstraße (K)
Prediction: Mode 1
Weight: 0.57
Prediction: Mode 2
Weight: 0.43 (b) Thiergarten (T)
Figure6: PredictionsofourmodelGDSSM(2modes)onout-of-domaintrafficenvironments, i.e. thetraining
and testing traffic environments are distinct. Given the history of each traffic participant (dashed lines), we
visualize the predicted 95% confidence interval. Solid lines represent the true future trajectory.
6 Conclusion
In this work, we have proposed GDSSMs in which the latent dynamics of the agents are coupled via GNNs in
order to capture interactions among multiple agents. We derived moment matching rules for GNN layers that
allow for deterministic inference and introduced a GMM prior over the initial latent states in order to allow
for multimodal predictions. Both together lead to an efficient and stable algorithm that is able to produce
complex and nonlinear predictive distributions. We confirmed that our novel method shows strong empirical
performance on two challenging autonomous driving datasets. Finally, we proposed sparse approximations
to the covariance matrix considering the computational limits of real-world vehicle control units. Depending
on the required calibration, our approximations can lead to a significant reduction of the runtime without
impeding accuracy.
In future work, we seek to increase the robustness of our proposed model towards novel and unseen traffic
scenarios. One way could be to incorporate epistemic uncertainty into our model formulation by placing a
prior over the weights of the GNN. To achieve this, we could combine our model with recent advances in
variational inference in order to find an approximation to the intractable weight posterior. Another research
direction of interest is modeling of irregular and partially observed dynamical systems. Prior work uses
continuous time encoder networks as well as a continuous time transition model in latent space (Rubanova
et al., 2019; Brouwer et al., 2019). Following this vein of work, an extension of our model towards continuous
time networks seems a promising direction for modeling interactive systems.
References
Daniel Alspach and Harold Sorenson. Nonlinear Bayesian estimation using Gaussian sum approximations.
IEEE transactions on automatic control , 17(4), 1972.
Shaojie Bai, J Zico Kolter, and Vladlen Koltun. An Empirical Evaluation of Generic Convolutional and
Recurrent Networks for Sequence Modeling. arXiv, abs/1803.01271, 2018.
Mayank Bansal, Alex Krizhevsky, and Abhijit S. Ogale. ChauffeurNet: Learning to Drive by Imitating the
Best and Synthesizing the Worst. arXiv, abs/1812.03079, 2018.
Peter W. Battaglia, Jessica B. Hamrick, Victor Bapst, Alvaro Sanchez-Gonzalez, Vinícius Flores Zambaldi,
Mateusz Malinowski, Andrea Tacchetti, David Raposo, Adam Santoro, Ryan Faulkner, Çaglar Gülçehre,
H. Francis Song, Andrew J. Ballard, Justin Gilmer, George E. Dahl, Ashish Vaswani, Kelsey R. Allen,
Charles Nash, Victoria Langston, Chris Dyer, Nicolas Heess, Daan Wierstra, Pushmeet Kohli, Matthew
Botvinick, Oriol Vinyals, Yujia Li, and Razvan Pascanu. Relational inductive biases, deep learning, and
graph networks. arXiv, abs/1806.01261, 2018.
Justin Bayer, Maximilian Soelch, Atanas Mirchev, Baris Kayalibay, and Patrick van der Smagt. Mind the
Gap when Conditioning Amortised Inference in Sequential Latent-Variable Models. In ICLR, 2021.
21Published in Transactions on Machine Learning Research (03/2023)
SamyBengio, OriolVinyals, NavdeepJaitly, andNoamShazeer. ScheduledSamplingforSequencePrediction
with Recurrent Neural Networks. In NeurIPS , 2015.
David M. Blei, Alp Kucukelbir, and Jon D. McAuliffe. Variational Inference: A Review for Statisticians.
Journal of the American Statistical Association , 112(518), 2017.
Michael W. Brandt and Pedro Santa-Clara. Simulated Likelihood Estimation of Diffusions with an Appli-
cation to Exchange Rate Dynamics in Incomplete Markets. Journal of Financial Economics , 63(274),
2002.
Edward De Brouwer, Jaak Simm, Adam Arany, and Yves Moreau. GRU-ODE-Bayes: Continuous Modeling
of Sporadically-Observed Time Series. In NeurIPS , 2019.
Yuri Burda, Roger Baker Grosse, and Ruslan Salakhutdinov. Importance Weighted Autoencoders. In ICLR,
2016.
Sergio Casas, Cole Gulino, Simon Suo, Katie Luo, Renjie Liao, and Raquel Urtasun. Implicit Latent Variable
Model for Scene-Consistent Motion Forecasting. In ECCV, 2020.
Yuning Chai, Benjamin Sapp, Mayank Bansal, and Dragomir Anguelov. MultiPath: Multiple Probabilistic
Anchor Trajectory Hypotheses for Behavior Prediction. arXiv, abs/1910.05449, 2019.
Guangxi Chen, Ling Hu, Qieshi Zhang, Ziliang Ren, Xiangyang Gao, and Jun Cheng. ST-LSTM: Spatio-
Temporal Graph Based Long Short-Term Memory Network For Vehicle Trajectory Prediction. In IEEE
ICIP, 2020.
Junyoung Chung, Caglar Gulcehre, KyungHyun Cho, and Yoshua Bengio. Empirical Evaluation of Gated
Recurrent Neural Networks on Sequence Modeling. arXiv, abs/1412.3555, 2014.
Junyoung Chung, Kyle Kastner, Laurent Dinh, Kratarth Goel, Aaron C Courville, and Yoshua Bengio. A
Recurrent Latent Variable Model for Sequential Data. In NeurIPS , 2015.
Henggang Cui, Vladan Radosavljevic, Fang-Chieh Chou, Tsung-Han Lin, Thi Nguyen, Tzu-Kuo Huang, Jeff
Schneider, and Nemanja Djuric. Multimodal Trajectory Predictions for Autonomous Driving using Deep
Convolutional Networks. In ICRA, 2019.
Nachiket Deo and M. Trivedi. Convolutional Social Pooling for Vehicle Trajectory Prediction. In CVPR
Workshop , 2018.
Frederik Diehl, Thomas Brunner, Michael Le, and Alois Knoll. Graph Neural Networks for Modelling Traffic
Participant Interaction. In IEEE Intelligent Vehicles Symposium , 2019.
Nemanja Djuric, Vladan Radosavljevic, Henggang Cui, Thi Nguyen, Fang-Chieh Chou, Tsung-Han Lin,
Nitin Singh, and Jeff Schneider. Uncertainty-aware Short-term Motion Prediction of Traffic Actors for
Autonomous Driving. In IEEE WACV , 2020.
Arnaud Doucet, Simon Godsill, and Christophe Andrieu. On sequential Monte Carlo sampling methods for
Bayesian filtering. Statistics and computing , 10(3), 2000.
Ola Elerian, Siddhartha Chib, and Neil Shephard. Likelihood Inference for Discretely Observed Nonlinear
Diffusions. Econometrica , 69(4), 2001.
Marco Fraccaro, Søren Kaae Sønderby, Ulrich Paquet, and Ole Winther. Sequential Neural Models with
Stochastic Layers. In NeurIPS , 2016.
Yarin Gal and Zoubin Ghahramani. Dropout as a Bayesian Approximation: Representing Model Uncertainty
in Deep Learning. In ICML, 2016.
Pascal Germain, Francis Bach, Alexandre Lacoste, and Simon Lacoste-Julien. PAC-Bayesian Theory Meets
Bayesian Inference. In NeurIPS , 2016.
22Published in Transactions on Machine Learning Research (03/2023)
Soumya Ghosh, Francesco Delle Fave, and Jonathan Yedidia. Assumed Density Filtering Methods for Learn-
ing Bayesian Neural Networks. In AAAI, 2016.
Justin Gilmer, Samuel S. Schoenholz, Patrick F. Riley, Oriol Vinyals, and George E. Dahl. Neural Message
Passing for Quantum Chemistry. In ICML, 2017.
Tilmann Gneiting and Adrian E Raftery. Strictly proper scoring rules, prediction, and estimation. Journal
of the American statistical Association , 102(477):359–378, 2007.
Danijar Hafner, Timothy P. Lillicrap, Ian Fischer, Ruben Villegas, David Ha, Honglak Lee, and James
Davidson. Learning Latent Dynamics for Planning from Pixels. In ICML, 2019.
John Halkias and James Colyar. Us highway 101 dataset. Technical report, Federal Highway Administration,
2007. URL https://rosap.ntl.bts.gov/view/dot/38724/Print .
William L. Hamilton, Rex Ying, and Jure Leskovec. Inductive Representation Learning on Large Graphs.
InNeurIPS , 2017.
Trevor Hastie, Robert Tibshirani, Jerome H Friedman, and Jerome H Friedman. The elements of statistical
learning: data mining, inference, and prediction , volume 2. Springer, 2009.
Manuel Haussmann, Sebastian Gerwinn, and Melih Kandemir. Bayesian Evidential Deep Learning with
PAC Regularization. arXiv, abs/1906.00816, 2020.
Michael Herman, Jörg Wagner, Vishnu Prabhakaran, Nicolas Möser, Hanna Ziesche, Waleed Ahmed, Lutz
Bürkle, Ernst Kloppenburg, and Claudius Gläser. Pedestrian Behavior Prediction for Automated Driving:
Requirements, Metrics, and Relevant Features. IEEE Transactions on Intelligent Transportation Systems ,
23(9), 2022.
Jose Miguel Hernandez-Lobato and Ryan Adams. Probabilistic Backpropagation for Scalable Learning of
Bayesian Neural Networks. In ICML, 2015.
Sepp Hochreiter. Untersuchungen zu dynamischen neuronalen Netzen. Diploma, Technische Universität
München , 91(1), 1991.
Ajay Jain, Sergio Casas, Renjie Liao, Yuwen Xiong, Song Feng, Sean Segal, and Raquel Urtasun. Discrete
Residual Flow for Probabilistic Pedestrian Behavior Prediction. In CoRL, 2019.
Ashesh Jain, Amir Roshan Zamir, Silvio Savarese, and Ashutosh Saxena. Structural-RNN: Deep Learning
on Spatio-Temporal Graphs. In CVPR, 2016.
Robert Krajewski, Tobias Moers, Julian Bock, Lennart Vater, and Lutz Eckstein. The rounD Dataset: A
Drone Dataset of Road User Trajectories at Roundabouts in Germany. In ITSC, 2020.
Rahul G. Krishnan, Uri Shalit, and David Sontag. Structured Inference Networks for Nonlinear State Space
Models. In AAAI, 2017.
Tuan Anh Le, Maximilian Igl, Tom Rainforth, Tom Jin, and Frank Wood. Auto-Encoding Sequential Monte
Carlo. In ICLR, 2018.
David Lenz, Frederik Diehl, Michael Truong-Le, and Alois C. Knoll. Deep Neural Networks for Markovian
Interactive Scene Prediction in Highway Scenarios. In IEEE Intelligent Vehicles Symposium , 2017.
ShiyangLi, XiaoyongJin, YaoXuan, XiyouZhou, WenhuChen, Yu-XiangWang, andXifengYan. Enhancing
the Locality and Breaking the Memory Bottleneck of Transformer on Time Series Forecasting. In NeurIPS ,
2019.
Yaguang Li, Rose Yu, Cyrus Shahabi, and Yan Liu. Diffusion Convolutional Recurrent Neural Network:
Data-Driven Traffic Forecasting. In ICLR, 2018.
23Published in Transactions on Machine Learning Research (03/2023)
Yunzhu Li, Hao He, Jiajun Wu, Dina Katabi, and Antonio Torralba. Learning Compositional Koopman
Operators for Model-Based Control. In ICLR, 2020.
Andreas Look, Melih Kandemir, Barbara Rakitsch, and Jan Peters. A Deterministic Approximation to
Neural SDEs. IEEE TPAMI , 2022.
Chris J Maddison, John Lawson, George Tucker, Nicolas Heess, Mohammad Norouzi, Andriy Mnih, Arnaud
Doucet, and Yee Teh. Filtering Variational Objectives. In NeurIPS , 2017.
Jean Mercat, Nicole Zoghby, Guillaume Sandou, Dominique Beauvois, and Guillermo Gil. Inertial Single
VehicleTrajectoryPredictionBaselinesandApplicationswiththeNGSIMDataset. arXiv, abs/1908.11472,
2019.
Christian Naesseth, Scott Linderman, Rajesh Ranganath, and David Blei. Variational Sequential Monte
Carlo. In AISTATS , 2018.
Aaron van den Oord, Sander Dieleman, Heiga Zen, Karen Simonyan, Oriol Vinyals, Alex Graves, Nal
Kalchbrenner, Andrew Senior, and Koray Kavukcuoglu. WaveNet: A Generative Model for Raw Audio.
arXiv, abs/1609.03499, 2016.
Soumyasundar Pal, Liheng Ma, Yingxue Zhang, and Mark Coates. RNN with Particle Flow for Probabilistic
Spatio-temporal Forecasting. In ICML, 2021.
Asger Roer Pedersen. A New Approach to Maximum Likelihood Estimation for Stochastic Differential
Equations Based on Discrete Observations. Scandinavian Journal of Statistics , 22(1), 1995.
Andreas Philipp and Daniel Goehring. Analytic Collision Risk Calculation for Autonomous Vehicle Naviga-
tion. InICRA, 2019.
Yulia Rubanova, Ricky T. Q. Chen, and David K Duvenaud. Latent Ordinary Differential Equations for
Irregularly-Sampled Time Series. In NeurIPS , 2019.
Alvaro Sanchez-Gonzalez, Jonathan Godwin, Tobias Pfaff, Rex Ying, Jure Leskovec, and Peter Battaglia.
Learning to Simulate Complex Physics with Graph Networks. In ICML, 2020.
Simo Särkkä. Bayesian Filtering and Smoothing . Cambridge University Press, 2013.
Simo Särkkä and Juha Sarmavuori. Gaussian Filtering and Smoothing for Continuous-Discrete Dynamic
Systems. Signal Processing , 93(2), 2013.
Simo Särkkä and Arnold Solin. Applied Stochastic Differential Equations . Cambridge University Press.,
2019.
Simo Särkkä, Jouni Hartikainen, Isambi Sailon Mbalawata, and Heikki Haario. Posterior Inference on
Parameters of Stochastic Differential Equations via Non-Linear Gaussian Filtering and Adaptive MCMC.
Statistics and Computing , 25(2), 2015.
Thomas B Schön, Adrian Wills, and Brett Ninness. System Identification of Nonlinear State-Space Models.
Automatica , 47(1), 2011.
ThomasBSchön, FredrikLindsten, JohanDahlin, JohanWågberg, ChristianANaesseth, AndreasSvensson,
and Liang Dai. Sequential Monte Carlo Methods for System Identification. IFAC, 48(28), 2015.
Arno Solin, Ella Tamir, and Prakhar Verma. Scalable Inference in SDEs by Direct Matching of the Fokker-
Planck-Kolmogorov Equation. In NeurIPS , 2021.
Charlie Tang and Russ R Salakhutdinov. Multiple Futures Prediction. In NeurIPS , 2019.
Belinda Tzen and Maxim Raginsky. Neural Stochastic Differential Equations: Deep Latent Gaussian Models
in the Diffusion Limit. arXiv, abs/1905.09883, 2019.
24Published in Transactions on Machine Learning Research (03/2023)
Benjamin Ummenhofer, Lukas Prantl, Nils Thuerey, and Vladlen Koltun. Lagrangian Fluid Simulation with
Continuous Convolutions . In ICLR, 2019.
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser,
and Illia Polosukhin. Attention Is All You Need. In NeurIPS , 2017.
Tim A. Wheeler and Mykel J. Kochenderfer. Factor Graph Scene Distributions for Automotive Safety
Analysis. In ITSC, 2016.
Anqi Wu, Sebastian Nowozin, Edward Meeds, Richard E. Turner, Jose Miguel Hernandez-Lobato, and
Alexander L. Gaunt. Deterministic Variational Inference for Robust Bayesian Neural Networks. In ICLR,
2019.
Fan Yang, Ling Chen, Fan Zhou, Yusong Gao, and Wei Cao. Relational State-Space Model for Stochastic
Multi-Object Systems. In ICLR, 2020.
Bing Yu, Haoteng Yin, and Zhanxing Zhu. Spatio-Temporal Graph Convolutional Networks: A Deep Learn-
ing Framework for Traffic Forecasting. In IJCAI, 2018.
25Published in Transactions on Machine Learning Research (03/2023)
A Proof of Theorem 1
Theorem 1. The marginal distribution p(yt|I)is analytically computed as
p(yt|I) =V/summationdisplay
v=1πv(I)N(yt|at,v(I),Bt,v(I)),
for a GDSSM with the below generative model
v∼Cat([π1(I),...,πV(I)]),
x0∼N(µ0,v(I),diag(Σ0,v(I))),
xt∼N (xt|xt−1+f(t,v,I)xt−1,diag(L(t,v,I))), t = 1,...,T
yt∼N (yt|g(t,v,I)xt,diag(Γ(t,v,I))), t = 1,...,T
wheref(t,v,I),L(t,v,I),g(t,v,I),Γ(t,v,I)are timet, component v, and contextIdepending matrices with
appropriate dimensionality.
Proof.The proof is straightforward as the output moment of the transition and emission function are ana-
lytically available
p(yt|I) =/integraldisplay
p(yt|v,xt,I)p(xt|v,x0,I)p(v,x0|I)dvdx 0dxt
=V/summationdisplay
v=1πv(I)/integraldisplay
p(yt|v,xt,I)p(xt|v,x0,I)N(x0|µ0,v(I),diag(Σ0,v(I)))dx0dxt
=V/summationdisplay
v=1/integraldisplay
p(yt|v,xt,I)N(xt|µt,v(I),Σt,v(I))dxt
=V/summationdisplay
v=1πv(I)N(yt|at,v(I),Bt,v(I)).
The moments at time step tof a linear time depending dynamical system are available as (Särkkä, 2013)
µt,v(I) =t/productdisplay
t′=1(I+f(t′,v,I))µ0,v(I),
Σt,v(I) =/bracketleftiggt/productdisplay
t′=1(I+f(t′,v,I))/bracketrightigg
diag(Σ0,v(I))/bracketleftiggt/productdisplay
t′=1(I+f(t′,v,I))T/bracketrightigg
+t−1/summationdisplay
t′=1/bracketleftiggt/productdisplay
t′′=t′+1(I+f(t′′,v,I))/bracketrightigg
diag(L(t′,v,I))/bracketleftiggt/productdisplay
t′′=t′+1(I+f(t′′,v,I))T/bracketrightigg
+diag(L(t,v,I))
We obtain the same expression via the BMM algorithm, which is easy to prove by inserting the locally linear
system into Eq. 6. Finally, mean at,v(I)and covariance Bt,v(I)of the output at time step tare available as
(Särkkä, 2013)
at,v(I) =E[g(t,v,I)xt] =g(t,v,I)µt,v(I),
Bt,v(I) =Cov[g(t,v,I)xt] +diag(E[Γ(t)]) =g(t,v,I)Σt,v(I)g(t,v,I)T+diag(Γ(t,v,I)).
26Published in Transactions on Machine Learning Research (03/2023)
B Output Moments for the ReLU Activation Function
Suppose, we apply the ReLU activation function at layer land time step tto the input xl
t
xl+1
t= max(0,xl
t).
Output Moments We can approximate the output moments of xl+1
tas a function of the input moments
(Wu et al., 2019)
E[max(0,xl
t)]≈/radicalig
diag(Cov[xl
t])SR/parenleftbigg
E[xl
t]//radicalig
diag(Cov[xl
t])/parenrightbigg
,
Cov[max(0,xl
t)]≈/radicalig
diag(Cov[xl
t])diag(Cov[xl
t])TF/parenleftbig
E[xl
t],Cov[xl
t]/parenrightbig
,
where SR (x) =ϕ(x) +xΦ(x)withϕandΦrepresenting the PDF and CDF of a standard Gaussian variable.
The function F(E[xl
t],Cov[xl
t])is a shorthand notation for
F(E[xl
t],Cov[xl
t]) =A/parenleftbig
E[xl
t],Cov[xl
t]/parenrightbig
+ exp/bracketleftbig
−Q/parenleftbig
E[xl
t],Cov[xl
t]/parenrightbig/bracketrightbig
.
The function A(E[xl
t],Cov[xl
t])can be estimated as
A(E[xl
t],Cov[xl
t])) =SR(ϵl
k)SR(ϵl
k)T+ρl
kΦ(ϵl
k)Φ(ϵl
k)T,
whereρl
k= Cov[xl
t]//parenleftig/radicalbig
diag(Cov[xl
t])/radicalbig
diag(Cov[xl
t])T/parenrightig
is a dimensionless matrix and ϵl
k=
E[xl
t]//radicalbig
diag(Cov[xl
t])is a dimensionless vector.
Thei,j-th element of Q(E[xl
t],Cov[xl
t])can be estimated as:
Q/parenleftbig
E[xl
t],Cov[xl
t])/parenrightbig
i,j=ρl
ki,j
2gl
ki,j(1 + ¯ρki,j)/parenleftig
(ϵl
ki)2+ (ϵl
kj)2/parenrightig
−arcsin(ρl
ki,j)−ρl
ki,j
ρki,jgl
ki,jϵl
kiϵl
kj−log/parenleftigg
gl
ki,j
2π/parenrightigg
,
wheregl
k= arcsin(ρl
k) +ρl
k⊘/parenleftbigg
1 +/radicalig
1−ρl
k⊙ρl
k/parenrightbigg
. The operator⊘denotes the elementwise disivision and
⊙denotes the elementwise multiplication.
Expected Jacobian Sinceactivationfunctionsareappliedelement-wise, off-diagonalentriesoftheexpected
gradient are zero. The diagonal of the Jacobian of the ReLU function is the expected Heaviside step function
Wu et al. (2019)
diag/parenleftig
E/bracketleftig
∇xl
tmax(0,xl
t)/bracketrightig/parenrightig
≈Φ/parenleftbigg
E[xl
t]//radicalig
diag(Cov[xl
t]))/parenrightbigg
.
For a more detailed derivation, we refer to the work of Wu et al. (2019).
C Training Details
We train all models with the ADAM optimizer and stochastic mini-batches. We use a batch size of 4 and a
learning rate of 0.0001. In order to accelerate training of multi-modal GDSSMs we initialize the transition
and observation neural nets with the pretrained versions of the uni-modal GDSSMs.
C.1 rounD
We train deterministic models (GDSSM Det. and Non Recur. GNN) for 50k weight updates. For the MC
based models (GDSSM MC) we use 100k weight updates. The dataset contains 4,314 training and 1,091
testing snippets. We do not use a separate validation dataset as we observed no overfitting.
27Published in Transactions on Machine Learning Research (03/2023)
C.2 NGSIM
We train all models for 1000k updates on the NGSIM dataset. The dataset contains 5,922k/860k/1,505k
train/validation/testsnippets. Wevalidatethemodelson1krandomminibatchesfromthevalidationdataset
after every 10k weight updates.
C.3 Out-of-Distribution Testing
We train all models for 50k weight updates. The dataset consists of three sub-datasets with 254/ 251/ 137
snippets, where 80% of each sub-dataset are used for training and the remaining 20% for testing. Due to
the small size of the sub-datasets we observed overfitting. We address this by using the last 20% of each
training sub-dataset for validation. We validate the model after every 1k weight updates.
D Evaluation Metrics
In the following, we give a brief overview on different evaluation metrics. We provide the negative log-
likelihood (NLL) and the Root-Mean-Square Error (RMSE) in the main of the paper, and minRMSE in
App. F.
Root-Mean-Square Error The (root) mean-square error at time point tis defined as
MSE Base(t) =1
NN/summationdisplay
nM(n)/summationdisplay
m(ym
t,n−ˆym
t,n)T(ym
t,n−ˆym
t,n)
M(n),RMSE Base(t) =/radicalbig
MSE Base(t),(25)
whereNis the number of snippets in the dataset, M(n)is the number of agents in the n-th snippet, ym
t,nis
the true location of the m-th agent at time point tof then-th snippet, and ˆym
t,nthe corresponding predicted
location.
Unfortunately, it is not straight-forward to extend RMSE baseto probabilistic forecasts. To the best of our
knowledge, none of the existing variants is a strictly proper scoring rule (Gneiting & Raftery, 2007) where
the latter is optimal if and only if the predictive distribution matches the true distribution. An example of
a strictly proper scoring rule that we also provide in the paper is the predictive NLL:
NLL(t) =−1
NN/summationdisplay
nM(n)/summationdisplay
mlogp(ym
t,n|I)
M(n). (26)
For deterministic GDSSMs, we approximate p(ym
t,n|I)directly with our method that we introduced in Sec.
4.2. For GDSSMs that do not follow an assumed density approach, we approximate p(ym
t,n|I)via Monte
Carlo integration.
In the following, we discuss different RMSE variants in more detail.
Bayes Predictor: A common evaluation metric used in the ML community (e.g. Gal & Ghahramani
(2016)) is to compute
RMSE (t) =/radicaltp/radicalvertex/radicalvertex/radicalbt1
NN/summationdisplay
nM(n)/summationdisplay
m(ym
t,n−E[ˆym
t,n])T(ym
t,n−E[ˆym
t,n])
M(n), (27)
where we assume that the probabilistic predictor will perform model averaging before making its final
prediction. This score only evaluates the goodness of the first moment and does not take any information of
higher moments into account. We provide its values in the main part of the paper.
Gibbs Predictor: An alternative way for extending deterministic loss functions to the probabilistic sce-
nario can be found in the PAC-Bayes setting (e.g. Germain et al. (2016)) by considering the average loss in
28Published in Transactions on Machine Learning Research (03/2023)
the risk function. In our case, this would lead to
RMSE Gibbs (t) =/radicaltp/radicalvertex/radicalvertex/radicalvertex/radicalbtE
1
NN/summationdisplay
nM(n)/summationdisplay
m(ym
t,n−ˆym
t,n)T(ym
t,n−ˆym
t,n)
M(n)
, (28)
where we take expectation with respect to the predictions ˆym
t,n. However, we discourage to take this for-
mulation as evaluation metric since it penalizes any form of variance in the predictor and favors a Dirac
distribution around the expected value of the true distribution. Note that this result can be tightly linked
to the bias-variance trade-off in statistical learning theory (e.g. Hastie et al. (2009)).
Min Predictor: A popular alternative in the traffic forecasting literature (e.g. Tang & Salakhutdinov
(2019)) is to compute the minimal error over a set of Spotential predictions
minRMSE (t) =/radicaltp/radicalvertex/radicalvertex/radicalbt1
NN/summationdisplay
nM(n)/summationdisplay
mmin
s=1,...,S(ym
t,n−ˆym
t,n,s)T(ym
t,n−ˆym
t,n,s)
M(n), (29)
where (ˆym
t,n,s)S
s=1is the set of Spotential predictions. This score favors models that produce a set of
diverse predictions where at least one candidate is close to the true outcome but ignores the goodness of the
remainingS−1predictors. While it gives some useful information about the model capacity, it does not
give a complete representation of the test-time performance when the best mode is unknown. We provide
its values in App. F.
E Alternative Parameter Inference Methods
One commonly used inference method in the context of machine learning circumvents maximizing the log-
likelihood and instead maximizes the Evidence Lower Bound (ELBO)
ELBO (y1,...,yT|I) =Eq(x0,...,xT)/bracketleftbigg
logp(y1,...,yT,x0,...,xT|I)
q(x0,...,xT)/bracketrightbigg
, (30)
that involves learning an approximation q(x0,...,xT)to the intractable smoothing distribution
p(x0,...,xT|y1,...,yT,I)(Krishnan et al., 2017).
A tighter bound to the log-likelihood logp(y1,...,yT|I)can be obtained by calculating the impor-
tance weighted log-likelihood, which we refer to as the Monte Carlo Objective (MCO) (Maddison et al.,
2017; Burda et al., 2016)
MCO (y1,...,yT|I) =Eq(x0,...,xT)/bracketleftigg
log1
KK/summationdisplay
k=1p(y1,...,yT,x0,k,...,xT,|I)
q(x0,k...,xT,k)/bracketrightigg
, (31)
whereKis the number of Monte Carlo samples and xt,kis thek-th sample at time step t. For state-space
models, recent work combined the MCO with particle filters (Naesseth et al., 2018; Maddison et al., 2017;
Le et al., 2018).
F Extended Results
We provide minRMSE values for the rounD and NGSIM dataset. We set the proposal predictions to the
mean values of each mode and the min operator selects for each agent the proposal that produces the lowest
error per snippet over the complete prediction horizon. This score favors models in which the proposal
predictions are diverse as long as at least one candidate is close to the true outcome. As shown in Tab.
5, the minRMSE decreases as we increase the number of modes, which indicates that the different modes
correspond to a diverse set of plausible trajectories.
29Published in Transactions on Machine Learning Research (03/2023)
Table 5: minRMSE values as a function of the number of modes on the rounD and NGSIM dataset. We
provide average and standard error over 10 runs. For RMSE and NLL results, please refer to Tab. 1 and
Tab. 2.
rounD NGSIM
1 Mode 2 Modes 3 Modes 4 Modes 1 Mode 2 Modes 3 Modes 4 ModesminRMSE1s0.79±0.020.75±0.040.76±0.030.69±0.020.53±0.010.46±0.010.35±0.010.32±0.01
2s1.87±0.021.85±0.061.83±0.071.68±0.051.18±0.011.05±0.010.80±0.010.71±0.01
3s3.36±0.033.46±0.113.05±0.162.75±0.121.98±0.021.73±0.021.33±0.021.18±0.03
4s5.08±0.045.07±0.134.55±0.284.04±0.452.99±0.032.60±0.042.02±0.041.75±0.04
5s7.24±0.056.29±0.235.95±0.474.43±0.534.29±0.043.69±0.062.88±0.052.46±0.05
G Experimental Setup for Out-of-Distribution Testing
G.1 Dataset Construction
We construct a dataset, which consists of three different traffic environments. We select one recording
from the roundabout in Kackertstraße (K) in Aachen, one recording from the roundabout in Thiergarten
(T) in Alsdorf, and one recording from the roundabout in Neuweiler (N) near Aachen. We use the same
preprocessing procedure as in Sec. 5.1. We remove pedestrians, bicycles, and parked vehicles from each
traffic environment. There remain 319/ 264/ 389 tracked objects over a time span of 0.3/ 0.3/ 0.15hours
at the traffic environments K/ T/ N. We downsample the recordings by a factor of 5 and then construct
for each traffic environment a dataset which consists of 8s long snippets with 50% overlap. The first three
seconds are used as the track history and the following five seconds as the prediction horizon. We obtain
254/ 251/ 137 snippets for the traffic environments K/ T/ N. For each traffic environment we use the first
80% snippets for training and the remaining 20% snippets for testing.
G.2 Map Processing
The map processing follows existing work in the domain of traffic forecasting Bansal et al. (2018); Herman
et al. (2022). Given an ego-vehicle and its history, we first calculate the heading of the vehicle. The heading
is calculated as the average heading direction over the last 0.2 observed seconds. The position and the
heading direction jointly define the Region-of-Interest (ROI) on the map. The ROI is a rectangle with a
length of 74 meters and a width of 44 meters, which is centered at the ego-vehicle and oriented according to
the heading of the ego-vehicle. We further convert the RGB-image into a binary road image. We visualize
the processed map information in Fig. 7b
Ego Vehicle
Heading
Relevant Map Information
(a) Full map with ego-vehicle.
Ego Vehicle
Heading (b) Rotated, cropped, and masked map information.
Figure 7: Processing of map information.
30Published in Transactions on Machine Learning Research (03/2023)
H Network Architectures
H.1 Network Architectures without World Models
Below we present the neural network architectures for the experiments in Sec. 5.1, 5.2, 5.3.
State
M×4Adjacency
M×M
Mean Aggregator
FC-24 + ReLU
FC-24 + ReLU
FC
State
M×4
(a) Mean update functionState
M×4Adjacency
M×M
Mean Aggregator
FC-24 + ReLU
FC + ReLU
State
M×4
(b) Variance update functionState
M×4
FC-24 + ReLU
FC
State
M×2
(c) Observation mean function
History
M×30Adjacency
M×M
FC-30 + Tanh
Mean Aggregator
FC-64 + Tanh
FC FC+ Exp
Mean
M×V×4Covariance
M×V×4
(d) Embedding functionState
M×4Observation
M×2Adjacency
M×M
FC-30 + Tanh
Mean Aggregator
FC-64 + Tanh
FC FC+ Exp
Mean
M×4Covariance
M×4
(e) Approximate posterior
Figure 8: Architectures without map information. For fully connected layers we give the number of output
neurons.
The embedding function receives the history of all Magents. This history is 3seconds long with a time
step of 0.2seconds and consists of two dimensional coordinates. After flattening, the input is a vector of
size 30. The output of the embedding function is a GMM with Vmixture components. We use the mean
aggregator in the embedding, mean and variance update function. The mean aggregator calculates the
message to agent maccordingly to Eq. 22. After the message xNm
tis calculated, it is concatenated with the
statexm
t. Mean and variance update functions are neural networks, which conduct at each prediction step
one round of message passing and then calculate the output. Our emissions model uses a neural network
for the mean function g(xt)and a constant vector for Q(xt). The emission model maps the state of each
agent back to the observed space and does not depend on interactions. The approximate posterior is used
31Published in Transactions on Machine Learning Research (03/2023)
in Sec. 5.1 for the baselines that are trained on the ELBO or MCO. In contrast maximizing the PLL does
not necessitate an approximate posterior. The approximate posterior network takes the previous state and
the current observation in order to approximate the latent distribution at the current time step.
H.2 Network Architectures with Map Information
These neural net architectures have been used in our experiments in Sec. 5.4. It closely follows the archi-
tectures in Sec. H.1. We add an additional neural net, which encodes the masked map of size 500x300 into
a flattened 256-dimensional vector. This map embedding is used as an additional input to the embedding
function.
State
M×16Adjacency
M×M
Mean Aggregator
FC-50 + ReLU
FC-50 + ReLU
FC
State
M×16
(a) Mean update functionState
M×16Adjacency
M×M
Mean Aggregator
FC-50 + ReLU
FC + ReLU
State
M×16
(b) Variance update functionState
M×16
FC-50 + ReLU
FC
State
M×2
(c) Observation mean function
History+Encoded Map
M×30+256Adjacency
M×M
FC-512 + Tanh
FC-512 + Tanh
Mean Aggregator
FC-512 + Tanh
FC FC+ Exp
Mean
M×V×16Covariance
M×V×16
(d) Embedding functionMasked Map
500×300
Conv-1-6+ReLU+MaxPool
Conv-6-12+ReLU+MaxPool
Conv-12-24+ReLU+MaxPool
FC
Encoded Map
256
(e) Map encoder
Figure 9: Architectures with map information. For fully connected layers we give the number of output
neurons. For convolutional layers we give the number of input channels and output channels. We use a
kernel size of 3 and stride 2. For MaxPool layers we use a kernel size of 2 and stride 2.
32