Published in Transactions on Machine Learning Research (10/2023)
Sharper Rates and Flexible Framework for
Nonconvex SGD with Client and Data Sampling
Alexander Tyurin alexandertiurin@gmail.com
KAUST, Saudi Arabia
Lukang Sun lukang.sun@kaust.edu.sa
KAUST, Saudi Arabia
Konstantin Burlachenko burlachenkok@gmail.com
KAUST, Saudi Arabia
Peter Richtárik richtarik@gmail.com
KAUST, Saudi Arabia
Reviewed on OpenReview: https: // openreview. net/ forum? id= zKgJ6TWAFE
Abstract
We revisit the classical problem of finding an approximately stationary point of the average
ofnsmooth and possibly nonconvex functions. The optimal complexity of stochastic first-
order methods in terms of the number of gradient evaluations of individual functions is
O/parenleftbig
n+n1/2ε−1/parenrightbig
, attained by the optimal SGD methods SPIDER(Fang et al., 2018) and PAGE
(Li et al., 2021), for example, where εis the error tolerance. However, i) the big- Onotation
hides crucial dependencies on the smoothness constants associated with the functions, and
ii) the rates and theory in these methods assume simplistic sampling mechanisms that
do not offer any flexibility. In this work we remedy the situation. First, we generalize
thePAGEalgorithm so that it can provably work with virtually any (unbiased) sampling
mechanism. This is particularly useful in federated learning, as it allows us to construct and
better understand the impact of various combinations of client and data sampling strategies.
Second, our analysis is sharper as we make explicit use of certain novel inequalities that
capture the intricate interplay between the smoothness constants and the sampling procedure.
Indeed, our analysis is better even for the simple sampling procedure analyzed in the PAGE
paper. However, this already improved bound can be further sharpened by a different
sampling scheme which we propose. In summary, we provide the most general and most
accurate analysis of optimal SGD in the smooth nonconvex regime. Finally, our theoretical
findings are supported by carefully designed experiments.
1 Introduction
In this paper, we consider the minimization of the average of nsmooth functions (1)in the nonconvex setting
in the regime when the number of functions nis very large. In this regime, calculation of the exact gradient
can be infeasible and the classical gradient descent method ( GD) (Nesterov, 2018) can not be applied. The
structure of the problem is generic, and such problems arise in many applications, including machine learning
(Bishop & Nasrabadi, 2006) and computer vision (Goodfellow et al., 2016). Problems of this form are the
basis of empirical risk minimization (ERM), which is the prevalent paradigm for training supervised machine
learning models.
1Published in Transactions on Machine Learning Research (10/2023)
1.1 Finite-sum optimization in the smooth nonconvex regime
We consider the finite-sum optimization problem
min
x∈Rd/braceleftbigg
f(x) :=1
nn/summationtext
i=1fi(x)/bracerightbigg
, (1)
wherefi:Rd→Ris a smooth (and possibly nonconvex) function for all i∈[n] :={1,...,n}.We are
interested in randomized algorithms that find an ε-stationary point of (1)by returning a random point /hatwidex
such that E/bracketleftig
∥∇f(/hatwidex)∥2/bracketrightig
≤ε.The main efficiency metric of gradient-based algorithms for finding such a point
is the (expected) number of gradient evaluations ∇fi; we will refer to it as the complexity of an algorithm.
1.2 Related work
The area of algorithmic research devoted to designing methods for solving the ERM problem (1)in the
smooth nonconvex regime is one of the most highly developed and most competitive in optimization.
The path to optimality. Let us provide a lightning-speed overview of recent progress. The complexity of
GDfor solving (1)isO/parenleftbig
nε−1/parenrightbig
, but this was subsequently improved by more elaborate stochastic methods,
including SAGA,SVRGand SCSG(Defazio et al., 2014; Johnson & Zhang, 2013; Lei et al., 2017; Horváth
& Richtárik, 2019), which enjoy the better complexity O/parenleftbig
n+n2/3ε−1/parenrightbig
. Further progress was obtained by
methods such as SNVRGand Geom-SARAH (Zhou et al., 2018; Horváth et al., 2020), improving the complexity
to/tildewideO/parenleftbig
n+n1/2ε−1/parenrightbig
. Finally, the methods SPIDER,SpiderBoost ,SARAHand PAGE(Fang et al., 2018; Wang
et al., 2019; Nguyen et al., 2017; Li et al., 2021), among others, shaved-off certain logarithmic factors and
obtained the optimalcomplexityO/parenleftbig
n+n1/2ε−1/parenrightbig
, matching lower bounds (Li et al., 2021).
Optimal, but hiding a secret. While it may look that this is the end of the road, the starting point of
our work is the observation that the big-Onotation in the above results hides important and typically very
large data-dependent constants. For instance, it is rarely noted that the more precise complexity of GDis
O/parenleftbig
L−nε−1/parenrightbig
,while the complexity of the optimal methods, for instance PAGE, isO/parenleftbig
n+L+n1/2ε−1/parenrightbig
,where
L−≤L+aredifferent and often very large smoothness constants. Moreover, it is easy to generate examples
of problems (see Example 1) in which the ratio L+/L−isas large as one desires .
Client and data sampling in federated learning. Furthermore, several modern applications, notably
federated learning (Konečný et al., 2016; McMahan et al., 2017), depend on elaborate clientanddata
sampling mechanisms, which are not properly understood. However, optimal SGDmethods were considered
in combination with very simple mechanisms only, such as sampling a random function fiseveral times
independently with replacement (Li et al., 2021). We thus believe that an in-depth study of sampling
mechanisms for optimal methods will be of interest to the federated learning community. There exists prior
work on analyzing non-optimal SGDvariants with flexible mechanisms For example, using the “arbitrary
sampling” paradigm, originally proposed by Richtárik & Takáč (2016) in the study of randomized coordinate
descent methods, Horváth & Richtárik (2019) and Qian et al. (2021) analyzed SVRG,SAGA, and SARAH
methods, and showed that it is possible to improve the dependence of these methods on the smoothness
constants via carefully crafted sampling strategies. Further, Zhao & Zhang (2014) investigated the stratified
sampling, but only provided the analysis for vanilla SGD, and in the convex case.
1.3 Summary of contributions
•Specifically, in the original paper (Li et al., 2021), the optimal (w.r.t. nandε) optimization method PAGE
was analyzed with a simple uniform mini-batch sampling with replacement. We analyze PAGEwith virtually
any (unbiased) sampling mechanism using a novel Definition 1. Moreover, we show that some samplings can
improve the convergence rate O/parenleftbig
n+L+n1/2ε−1/parenrightbig
ofPAGE.We obtain the new state-of-the-art convergence
rates in the considered setting (see Table 2).
•We improve the analysis of PAGEusing a new quantity, the weighted Hessian Variance L±(orL±,w),
that is well-defined if the functions fiareLi–smooth. It is important that we get strictly better theoretical
guarantees without any additional assumptions on the structure of (1). We show that, when the functions
2Published in Transactions on Machine Learning Research (10/2023)
Table 1: The constants A,B, wiand|S|that characterize the samplings in Definition 1.
Sampling scheme A w iB|S|Reference
Uniform With Replacement 1/τ 1/n 1/τ≤τSec. E.3
Importance 1/τ qi1/τ≤τSec. E.3
Nice(=Uniform Without Replacement )n−τ
τ(n−1)1/nn−τ
τ(n−1)τSec. E.1
Independent1/summationtextn
i=1pi
1−pipi
1−pi/summationtextn
i=1pi
1−pi0/summationtextn
i=1piSec. E.2
Extended Nicen−τ
τ(n−1)li/summationtextn
i=1lin−τ
τ(n−1)≤τSec. E.4
We now provide a brief explanation of the samplings (more mathematically rigorous explanations are provided in the
corresponding sections from “Reference”): 1) Uniform With Replacement is a sampling, where we take exactly τ
elements from a set with replacement. 2) Importance is a sampling, where we take exactly τelements from a set
with replacement, and a new sampled element is taken non-uniformly. 3) Niceis a sampling, where we take exactly τ
elements from a set without replacement. 4) Independent is a sampling, where we take each element independently with
a predefined probability. 5) Extended Nice is a sampling, where we repeat each ithelementlitimes before applying the
Nicesampling.
Notation:n= #of data points; τ=batch size;qi=probability to sample ithdata point in the multinomial distribution;
pi=probability to sample ithdata point in the bernoulli distribution; li= #of times to repeat ithdata point before
apply the Nicesampling.
fiare “similar” in the sense of the weighted Hessian Variance, PAGEenjoys faster convergence rates (see
Table 2). Also, unlike (Szlendak et al., 2022), we introduce weights withat can play a crucial role in some
samplings. Moreover, the experiments in Sec 5 agree with our theoretical results.
•Our framework is flexible and can be generalized to the composition of samplings . These samplings naturally
emerge in federated learning (Konečný et al., 2016; McMahan et al., 2017), and we show that our framework
can be helpful in the analysis of problems from federated learning.
2 Assumptions
We need the following standard assumptions from nonconvex optimization.
Assumption 1. There exists f∗∈Rsuch thatf(x)≥f∗for allx∈Rd.
Assumption 2. There exists L−≥0such that∥∇f(x)−∇f(y)∥≤L−∥x−y∥for allx,y∈Rd.
Assumption 3. For alli∈[n],there exists a constant Li>0such that∥∇fi(x)−∇fi(y)∥≤Li∥x−y∥for
allx,y∈Rd.
Note that Assumption 2 follows from Assumption 3 with L−≤1
n/summationtextn
i=1Li.
2.1 Tight variance control of general sampling estimators
In Algorithm 1 (a generalization of PAGE), we form an estimator of the gradient ∇fvia subsampling. In our
search for achieving the combined goal of providing a general(in terms of the range of sampling techniques
we cater for) and refined(in terms of the sharpness of our results, even when compared to known results
using the samesampling technique) analysis of PAGE, we have identified several powerful tools, the first of
which is Definition 1. Let
Sn:=/braceleftigg
(w1,...,wn)∈Rn/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsinglew1,...,wn≥0,n/summationdisplay
i=1wi= 1/bracerightigg
be thestandard simplex and(Ω,F,P)a probability space.
Definition 1 (S(A,B,{wi}n
i=1)and Weighted ABInequality) .Consider any random mapping S:Rd×
···× Rd×Ω→Rd, which we will call “sampling”, such that E[S(a1,...,an;ω)]=1
n/summationtextn
i=1aifor all
3Published in Transactions on Machine Learning Research (10/2023)
a1,...,an∈Rd,and there exist A,B≥0and weights (w1,...,wn)∈Snsuch that
E/bracketleftigg/vextenddouble/vextenddouble/vextenddouble/vextenddoubleS(a1,...,an;ω)−1
nn/summationtext
i=1ai/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightigg
≤A
nn/summationtext
i=11
nwi∥ai∥2−B/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
nn/summationtext
i=1ai/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
, (2)
for alla1,...,an∈Rd.The collection of such samplings will denote as S(A,B,{wi}n
i=1).
For simplicity, we denote S({ai}n
i=1):=S(a1,...,an) :=S(a1,...,an;ω).The main purpose of a sampling
S∈S(A,B,{wi}n
i=1)is to estimate the mean1
n/summationtextn
i=1aiusing some random subsets (possibly containing
some elements more than once) of the set {a1,...,an}.We refer to Table 1, where we provide examples of
samplings that satisfy this definition. One of the simplest examples is the sampling
S(a1,...,an;ω) =aχ, (3)
whereχ∈[n]is uniformly sampled from the set [n](theUniform With Replacement sampling with τ= 1
from Table 1).
We now define the cardinality |S|of a sampling S∈S(A,B,{wi}n
i=1).
Definition 2 (Cardinality of a Sampling) .Let us take S∈S(A,B,{wi}n
i=1),and define the function
Sω(a1,...,an) :Rd×···× Rd→Rdsuch that Sω(a1,...,an) := S(a1,...,an;ω).If the function
Sω(a1,...,an)depends only on a subset A(ω)of the arguments (a1,...,an),whereA(ω) : Ω→2{a1,...,a n},
we define|S|:= E [|A(ω)|].
In terms of our problem (1), the cardinality of a sampling represents the number of the gradients ∇fithat a
sampling calculates in each draw. Note that it can be easily calculated (see Table 1 for details). In the case
of (3), one can see that |S|= 1.
Definition 1 is most closely related to two independent works: (Horváth & Richtárik, 2019) and (Szlendak
et al., 2022). Horváth & Richtárik (2019) analyzed several non-optimal SGDmethods for “arbitrary samplings”;
these are random set-valued mappings Swith values being the subsets of [n]. The distribution of a such a
sampling is uniquely determined by assigning probabilities to all 2nsubsets of [n]. In particular, they consider
the samplings S(a1,...,an) =1
n/summationtext
i∈Sai
pi, pi:=Prob (i∈S),|S|=|S|,someA≥0,w1,...,wn≥0and
B= 0.Our new set S(A,B,{wi}n
i=1)includes these samplings. Recently, Szlendak et al. (2022) studied a
similar inequality, but in the context of communication-efficient distributed training with randomized gradient
compression operators. They explicitly set out to study correlated compressors, and for this reason introduced
the second term in the right hand side; i.e., they considered the possibility of Bbeing nonzero, as in this way
they obtain a tighter inequality, which they can use in their analysis. However, their inequality only involves
uniform weights{wi}. See Table 1 for an overview of several samplings and the values A,Band{wi}that
belong to S(A,B,{wi}n
i=1)from Definition 1. Our Definition 1 offers the tightest known way to control of the
variance of the sampling estimator, and our analysis can take advantage of it.
2.2 Sampling-dependent smoothness constants
We now define two smoothness constants that depend on the weights {wi}n
i=1of a sampling Sand on the
functionsfi.
Definition 3. Given a sampling S∈S(A,B,{wi}n
i=1), letL+,wbe a constant for which
1
nn/summationtext
i=11
nwi∥∇fi(x)−∇fi(y)∥2≤L2
+,w∥x−y∥2, (4)
for allx,y∈Rd.For(w1,...,wn) = ( 1/n,..., 1/n),we defineL+:=L+,w.
Definition 4. Given a sampling S∈S(A,B,{wi}n
i=1), letL±,wbe a constant for which
1
nn/summationtext
i=11
nwi∥∇fi(x)−∇fi(y)∥2−∥∇f(x)−∇f(y)∥2≤L2
±,w∥x−y∥2,∀x,y∈Rd. (5)
For(w1,...,wn) = ( 1/n,..., 1/n),we defineL±:=L±,w.
4Published in Transactions on Machine Learning Research (10/2023)
Table 2: The complexity of methods and samplings from Table 1 and Sec 4.
Sampling scheme Complexity Comment
Independent (Horváth & Richtárik, 2019) Θ/parenleftbigg
n+n2/3/parenleftbig
1
n/summationtextn
i=1Li/parenrightbig
ε/parenrightbiggSVRGmethod
pi∝Li
Uniform With Replacement (Li et al., 2021) Θ/parenleftig
n+√nL+
ε/parenrightig
—
Uniform With Replacement (new) Θ/parenleftig
n+max{√nL±,L−}
ε/parenrightig
—
Importance Θ/parenleftbigg
n+√n/parenleftbig
1
n/summationtextn
i=1Li/parenrightbig
ε/parenrightbigg
qi=Li/summationtext
i=1Li
Stratified Θ/parenleftbigg
n+max/braceleftbig√n/radicalbig
1
g/summationtextg
i=1L2
i,±,gL−/bracerightbig
ε/parenrightbiggThe functions fi
are splitted into ggroups
Notation:n= #of data points; ε=error tolerance; L−,Li,L±,L+andLi,±are smoothness constants such that
L−≤1
n/summationtextn
i=1Li, L−≤L+andL±≤L+;g= #of groups in the Stratified sampling.
One can interpret Definition 3 as weighted mean-squared smoothness property (Arjevani et al., 2019), and
Definition 4 as weighted Hessian variance (Szlendak et al., 2022) that captures the similarity between the
functionsfi. The constants L+,wandL±,whelp us better understand the structure of the optimization
problem (1)in connection with a particular choice of a sampling scheme. Note that Definitions 3, 4 and
Definition 1 are connected with the weights {wi}n
i=1.
The next result states that L2
+,wandL2
±,ware well-defined and finite provided the functions fiareLi–smooth
for alli∈[n].
Theorem 5. If Assumption 3 holds, then L2
+,w=L2
±,w=1
n/summationtextn
i=11
nwiL2
isatisfy Def. 3 and 4.
Indeed, from Assumption 3 and the inequality ∥∇f(x)−∇f(y)∥2≥0we get
1
nn/summationtext
i=11
nwi∥∇fi(x)−∇fi(y)∥2−∥∇f(x)−∇f(y)∥2≤/parenleftbigg
1
nn/summationtext
i=11
nwiL2
i/parenrightbigg
∥x−y∥2,
thus we can take L2
±,w=1
n/summationtextn
i=11
nwiL2
i.The proof for L2
+,wis the same.
From the proof, one can see that we ignore ∥∇f(x)−∇f(y)∥2when estimating L2
±,w.However, by doing
that, the obtained result is not tight.
2.3 Clarifications and Discussion
In the literature, including (Li et al., 2021), it is usually considered that one of the following inequalities
holds. For all i∈[n],
∥∇fi(x)−∇fi(y)∥≤Li∥x−y∥,∀x,y∈Rd,
for someLi<∞(see Assumption 3). The inequality
1
nn/summationtext
i=1∥∇fi(x)−∇fi(y)∥2≤L2
+∥x−y∥2,∀x,y∈Rd,
holds for some L+<∞.These inequalities are standard smoothness assumptions (the latter follows from
the former for some L2
+≤1
n/summationtextn
i=1L2
i). Under the last inequality, Li et al. (2021) get the theoretical bound
O/parenleftbig
n+L+n1/2ε−1/parenrightbig
that depend on L+.
i) We want to emphasize that we also only consider Assumption 3. However, further we show that our
theoretical bounds depend on L±,w(andL+,w) instead of L+,and we provide the examples when L±,w(and
L+,w) are much smaller than L+(see Table 2). We get this improvement without additional assumptions on
the problem (1).
5Published in Transactions on Machine Learning Research (10/2023)
ii) The weights widepend only on a choice of a sampling, and play an essential role in the Importance
sampling, for instance. In Sec 3.3, we show that if we take the Importance sampling with qi=Li//summationtextn
i=1Li
for alli∈[n],thenwi=Li//summationtextn
i=1Lifor alli∈[n],and it leads to the fact that L±,w≤L+,w≤1
n/summationtextn
i=1Li.
One can see that a good choice of a sampling can lead to good weights wisuch that the inequalities in
Definitions 3 and 4 are satisfied with small L±,wandL+,w.It holds without additional assumptions about
our problem.
3 A General and Refined Theoretical Analysis of PAGE
In the Algorithm 1, we provide the description of the PAGEmethod. The description of the method can be
found in (Li et al., 2021, Sec. 2.1) The choice of PAGEas the base method is driven by the simplicity of the
proof in the original paper. However, we believe that other methods, including SPIDERand SARAH, can also
admit samplings from Definition 1.
Algorithm 1 PAGE
1:Input:initial point x0∈Rd, stepsizeγ >0, probability p∈(0,1]
2:g0=∇f(x0)
3:fort= 0,1,...,Tdo
4:xt+1=xt−γgt
5:Generate a random sampling function St
6:gt+1=/braceleftigg
∇f(xt+1) with probability p
gt+St/parenleftbig
{∇fi(xt+1)−∇fi(xt)}n
i=1/parenrightbig
with probability 1−p
7:end for
In this section, we provide theoretical results for Algorithm 1. Let us define ∆0:=f(x0)−f∗.
Theorem 6. Suppose that Assumptions 1, 2, 3 hold and the samplings St∈S(A,B,{wi}n
i=1).
Then Algorithm 1 (PAGE) has the convergence rate E/bracketleftig/vextenddouble/vextenddouble∇f(/hatwidexT)/vextenddouble/vextenddouble2/bracketrightig
≤2∆0
γT,whereγ≤
/parenleftig
L−+/radicalig
1−p
p/parenleftbig
(A−B)L2
+,w+BL2
±,w/parenrightbig/parenrightig−1
.
To reach an ε-stationary point, it is enough to do
T:=2∆0
ε/parenleftig
L−+/radicalig
1−p
p/parenleftbig
(A−B)L2
+,w+BL2
±,w/parenrightbig/parenrightig
(6)
iterations of Algorithm 1. To deduce the gradient complexity, we provide the following corollary.
Corollary 1. Suppose that the assumptions of Thm 6 hold. Let us take p=|S|
|S|+n.Then the complexity (the
expected number of gradient calculations ∇fi) of Algorithm 1 equals
N:= Θ (n+|S|T) = Θ/parenleftig
n+∆0
ε|S|/parenleftig
L−+/radicalig
n
|S|/parenleftbig
(A−B)L2
+,w+BL2
±,w/parenrightbig/parenrightig/parenrightig
.
Proof.At each iteration, the expected # gradient calculations equals pn+ (1−p)|S|≤2|S|.Thus the total
expected number of gradient calculations equals n+ 2|S|Tto get anε-stationary point.
The original result from (Li et al., 2021) states that the complexity of PAGEwith batch size τis
Norig:= Θ/parenleftbigg
n+∆0
ετ/parenleftbigg
L−+√n
τL+/parenrightbigg/parenrightbigg
≥Θ/parenleftbigg
n+∆0√nL+
ε/parenrightbigg
(7)
for allτ∈{1,2,...,n}.
In the following examples, we will see that Cor 1 can guarantee better complexities than (7). These
improvements we get using a refined and tighter analysis of the gradient estimator gt+1in Sec D. In particular,
we provide a better upper bound to the variance E/bracketleftig/vextenddouble/vextenddoublegt+1−∇f(xt+1)/vextenddouble/vextenddouble2/bracketrightig
,which makes our dependencies on
smoothness constants tighter.
6Published in Transactions on Machine Learning Research (10/2023)
3.1Uniform With Replacement sampling
Let us do a sanity check and substitute the parameters of the sampling that the original paper uses. We take
theUniform With Replacement sampling (see Sec E.3) with batch size τ(note thatτ≥|S|),A=B=1/τand
wi=1/nfor alli∈[n](see Table 1) and get the complexity Nuniform = Θ/parenleftig
n+∆0
ετ/parenleftig
L−+√n
τL±/parenrightig/parenrightig
for allτ∈ {1,2,...,n}.Next, let us fix τ≤max/braceleftig√nL±
L−,1/bracerightig
,and, finally, obtain that Nuniform =
Θ/parenleftig
n+∆0max{√nL±,L−}
ε/parenrightig
.Let us compare it with (7). With the same sampling , our analysis provides
better complexity; indeed, note that max{√nL±,L−}≤√nL+(see Lemma 2 in Szlendak et al. (2022)).
Moreover, Szlendak et al. (2022) provides examples of the optimization problems when L±is small and L+is
large, so the difference can be arbitrary large.
Note that the original analysis of PAGE(Li et al., 2021) is also based on Assumptions 1, 2 and 3, and we do
not have additional assumptions on the structure of the problem (1). We have better theoretical guarantees
in the same setting.
3.2Nicesampling (= Uniform Without Replacement ) sampling
Next, we consider the Nicesampling (see Sec E.1) and get that the complexity Nnice =
Θ/parenleftig
n+∆0
ετ/parenleftig
L−+1
τ/radicalig
n(n−τ)
(n−1)L±/parenrightig/parenrightig
.Unlike the Uniform With Replacement sampling, for εsmall enough,
theNicesampling recovers the complexity of GDforτ=n, which is equal to Θ/parenleftig
∆0nL−
ε/parenrightig
.
3.3Importance sampling
Let us consider the Importance sampling (see Sec E.3) that justifies the introduction of the weights wi.We
can get the complexity
Nimportance = Θ/parenleftbigg
n+∆0
ετ/parenleftbigg
L−+√n
τL±,w/parenrightbigg/parenrightbigg
≤Θ/parenleftbigg
n+∆0max{√nL±,w,L−}
ε/parenrightbigg
forτ≤max/braceleftig√nL±,w
L−,1/bracerightig
.Now, we take qi=wi=Li/summationtext
i=1Liand use the results from Sec F to obtain
Nimportance = Θ/parenleftbigg
n+∆0√n(1
n/summationtextn
i=1Li)
ε/parenrightbigg
(See Sec G). In Example 2, we consider the optimization task where
1
n/summationtextn
i=1Liis√ntimes smaller than L+.Thus the complexity Nimportance can be at least√ntimes smaller
that the complexity Norig.However, we do not guarantee that Nimportance≤Norigin general.
3.4 The power of B > 0
This is the first analysis of optimal SGD, which uses B > 0.In all previous examples, the constant A=B > 0.
IfA=B,then the complexity
N= Θ/parenleftbigg
n+∆0
ε|S|/parenleftbigg
L−+/radicalbiggn
|S|BL2
±,w/parenrightbigg/parenrightbigg
,
thus the complexity Ndoes not depend on L2
+,w,which greater of equal to L2
±,w.It can even be possible
thatL2
±,wis close or equal to zero, while L2
+,wis arbitrary large. Unlike Definition 3 of L2
+,w,, Definition 4 of
L2
±,wcaptures the variance of gradient differences . Imagine that (w1,...,wn) = ( 1/n,..., 1/n)andfi=ffor
alli∈[n],then the the left-hand side of (5)equals zero, and we can take L2
±,w= 0.In general, we can not
takeL2
+,w= 0in (4) iffi=ffor alli∈[n].
3.5 Analysis under PŁCondition
The previous results can be extended to the optimization problems that satisfy the Polyak-Łojasiewicz
condition. Under this assumption, Algorithm 1 enjoys a linear convergence rate.
7Published in Transactions on Machine Learning Research (10/2023)
Assumption 4. There exists µ>0such that the function fsatisfy (Polyak-Łojasiewicz) PŁ-condition:
∥∇f(x)∥2≥2µ(f(x)−f∗)∀x∈R,
wheref∗= infx∈Rdf(x)>−∞.
Using Assumption 4, we can improve the convergence rate of PAGE.
Theorem 7. Suppose that Assumptions 1, 2, 3, 4 and the samplings St∈S(A,B,{wi}n
i=1).
Then Algorithm 1 (PAGE)has the convergence rate E/bracketleftbig
f(xT)/bracketrightbig
−f∗≤(1−γµ)T∆0,whereγ≤
min/braceleftbigg/parenleftig
L−+/radicalig
2(1−p)
p/parenleftbig
(A−B)L2
+,w+BL2
±,w/parenrightbig/parenrightig−1
,p
2µ/bracerightbigg
.
Algorithm 2 PAGEwith composition of samplings
1:Input:initial point x0∈Rd, stepsizeγ >0, probability p∈(0,1],g0=∇f(x0)
2:fort= 0,1,...,Tdo
3:xt+1=xt−γgt
4:ct+1=/braceleftigg
1with probability p
0with probability 1−p
5:ifct+1= 1then
6:gt+1=∇f(xt+1)
/*FL Interpretation: With the small probability, calculate the full gradients ∇fion the nodes and
collect them */
7:else
8:Generate samplings St
ifor alli∈[n]
9:ht+1
i=St
i/parenleftbig
{∇fij(xt+1)−∇fij(xt)}mi
j=1/parenrightbig
for alli∈[n]
/*FL Interpretation: Calculate the mini-batches ht+1
ion the nodes */
10:Generate a sampling Stand setgt+1=gt+St/parenleftbig
{ht+1
i}n
i=1/parenrightbig
/*FL Interpretation: Collect ht+1
ionly from the sampled nodes */
11:end if
12:end for
4 Composition of Samplings: Application to Federated Learning
In Sec 3, we analyze the PAGEmethod with samplings that belong to Definition 1. Now, let us assume that
the functions fihave the finite-sum form, i.e., fi(x) :=1
mi/summationtextmi
j=1fij(x),thus we an optimization problem
min
x∈Rd/braceleftigg
f(x) :=1
nn/summationtext
i=11
mimi/summationtext
j=1fij(x)/bracerightigg
, (8)
Another way to get the problem is to assume that we split the functions fiinto groups of sizes mi.Let us
consider (8) instead of (1).
The problem (8)occurs in many applications, including distributed optimization and federated learning
(Konečný et al., 2016; McMahan et al., 2017). In federated learning, many devices and machines (nodes)
store local datasets that they do not share with other nodes. The local datasets are represented by functions
fi,and all nodes solve the common optimization problem (8). Due to privacy reasons and communication
bottlenecks (Kairouz et al., 2021), it is infeasible to store and compute the functions filocally in one machine.
In general, when we solve (1)in one machine, we have the freedom of choosing a sampling Sfor the functions
fi,which we have shown in Sec 3. However, in federated learning, a sampling of nodes or the functions fiis
dictated by hardware limits or network quality (Kairouz et al., 2021). Still, each ithnode can choose sampling
Sito sample the functions fij.As a result, we have a composition of the sampling Sand the samplings Si
(see Algorithm 2).
8Published in Transactions on Machine Learning Research (10/2023)
Assumption5. For allj∈[mi],i∈[n],there exists a Lipschitz constant Lijsuch that∥∇fij(x)−∇fij(y)∥≤
Lij∥x−y∥for allx,y∈Rd.
We now introduce the counterpart of Definitions 3 and 4.
Definition 8. For alli∈[n]and any sampling Si∈S(Ai,Bi,{wij}mi
j=1), define constant Li,+,wisuch that
1
mimi/summationtext
j=11
miwij∥∇fij(x)−∇fij(y)∥2≤L2
i,+,wi∥x−y∥2
for allx,y∈Rd.
Definition 9. For alli∈[n]and any sampling Si∈S(Ai,Bi,{wij}mi
j=1), define constant Li,±,wisuch that
1
mimi/summationdisplay
j=11
miwij∥∇fij(x)−∇fij(y)∥2−∥∇fi(x)−∇fi(y)∥2≤L2
i,±,wi∥x−y∥2
for allx,y∈Rd.
Let us provide the counterpart of Thm 6 for Algorithm 2.
Theorem 10. Suppose that Assumptions 1, 2, 3, 5 hold and the samplings St∈S(A,B,{wi}n
i=1)and the
samplings St
i∈S(Ai,Bi,{wij}mi
j=1)for alli∈[n].Moreover,B≤1.Then Algorithm 2 has the convergence
rateE/bracketleftig/vextenddouble/vextenddouble∇f(/hatwidexT)/vextenddouble/vextenddouble2/bracketrightig
≤2∆0
γT,whereγ≤/parenleftig
L−+/radicalig
1−p
p(Ll+Lg)/parenrightig−1
,
Ll:=1
nn/summationdisplay
i=1/parenleftbigg
A
nwi+(1−B)
n/parenrightbigg
((Ai−Bi)L2
i,+,wi+BiL2
i,±,wi),
and
Lg:= (A−B)L2
+,w+BL2
±,w.
Theobtainedtheoremprovidesageneralframeworkthathelpsanalyzetheconvergenceratesofthecomposition
of samplings that belong to Definition 1. We discuss the obtained result in different contexts.
4.1 Federated Learning
For simplicity, let us assume that the samplings StandSt
iareUniform With Replacement samplings with
batch sizes τandτifor alli∈n, accordingly, then to get ε-stationary point, it is enough to do
T:= Θ/parenleftbigg
∆0
ε/parenleftbigg
L−+/radicalbigg
1−p
pτ/parenleftig
1
n/summationtextn
i=11
τiL2
i,±+L2
±/parenrightig/parenrightbigg/parenrightbigg
iterations. Note that T≥Θ/parenleftig
∆0
ε/parenleftig
L−+/radicalig
1−p
pτL2
±/parenrightig/parenrightig
for allτi≥1for alli∈[n].It means that after some
point, there is no benefit in increasing batch sizes τi.In order to balance1
n/summationtextn
i=11
τiL2
i,±andL2
±,one can
takeτi= Θ/parenleftbig
L2
i,±/L2
±/parenrightbig
.The constant L2
i,±captures the intra-variance insideithnode, while L2
±captures the
inter-variance between nodes. If the intra-variance is small with respect to the inter-variance , then our
theory suggests taking small batch sizes and vice versa.
4.2Stratified sampling
Let us provide another example that is closely related to (Zhao & Zhang, 2014). Let us consider (1)and use a
variation of the Stratified sampling (Zhao & Zhang, 2014): we split the functions fiintog=n/mgroups, where
mis the number of functions in each group. Thus we get the problem (8)withf(x) =1
g/summationtextg
i=11
m/summationtextm
j=1fij(x).
Let us assume that we always sample allgroups, thus A=B= 0,and the sampling St
iareNicesamplings
with batch sizes τ1for alli∈[n].Applying Thm 10, we get the convergence rate
Tgroup := Θ/parenleftbigg
∆0
ε/parenleftbigg
L−+/radicalbigg
1−p
pgτ1/parenleftig
1
g/summationtextg
i=1L2
i,±/parenrightig/parenrightbigg/parenrightbigg
.
9Published in Transactions on Machine Learning Research (10/2023)
At each iteration, the algorithm calculates gτ1gradients, thus we should take p=gτ1
gτ1+nto get
the complexity Ngroup := Θ (n+gτ1T)= Θ/parenleftig
n+∆0
ε/parenleftig
gτ1L−+√n/radicalig
1
g/summationtextg
i=1L2
i,±/parenrightig/parenrightig
.Let us take τ1≤
max/braceleftbigg√n/radicalbig
1
g/summationtextg
i=1L2
i,±
gL−,1/bracerightbigg
to obtain the complexity Ngroup = Θ/parenleftbigg
n+∆0max/braceleftbig√n/radicalbig
1
g/summationtextg
i=1L2
i,±,gL−/bracerightbig
ε/parenrightbigg
.Com-
paring the complexity Ngroupwith the complexity Nuniformfrom Sec 3, one can see that if split the functions
fiin a “right way”, such that Li,±is small for i∈[n](see Example 3), then we can get at least√n/√gtimes
improvement with the Stratified sampling. However, we can be “unlucky” with a splitting of the functions;
thus, we do not guarantee improvement in general.
5 Experiments
0 5000 10000 15000 20000 25000 30000 35000
# of gradient calculations109
108
107
106
105
104
103
102
||f(xk)||2
L± = 0.0; L = 0.96; L+ = 0.96
Number of functions: 1000Vanilla PAGE, Batch: 1 Step: 0.03
Uniform With Replacement, Batch: 1 Step: 0.97
Importance, Batch: 1 Step: 0.97
0 5000 10000 15000 20000 25000 30000
# of gradient calculations109
108
107
106
105
104
103
102
||f(xk)||2
L± = 0.1; L = 0.96; L+ = 0.97
Vanilla PAGE, Batch: 1 Step: 0.03
Uniform With Replacement, Batch: 1 Step: 0.24
Importance, Batch: 1 Step: 0.98
0 5000 10000 15000 20000 25000 30000
# of gradient calculations105
104
103
102
||f(xk)||2
L± = 0.5; L = 0.96; L+ = 1.08
Vanilla PAGE, Batch: 1 Step: 0.03
Uniform With Replacement, Batch: 1 Step: 0.06
Importance, Batch: 1 Step: 0.17
0 5000 10000 15000 20000 25000 30000
# of gradient calculations104
103
102
||f(xk)||2
L± = 0.97; L = 0.98; L+ = 1.38
Vanilla PAGE, Batch: 1 Step: 0.02
Uniform With Replacement, Batch: 1 Step: 0.03
Importance, Batch: 1 Step: 0.05
Figure 1: Comparison of samplings and methods on quadratic optimization tasks with various L±.
We now provide experiments1with synthetic quadratic optimization tasks, where the functions fi, in general,
are nonconvex quadratic functions. Note that our goal here is to check whether the dependencies that our
theory predicts are correct for the problem (1). The procedures that generate synthetic quadratic optimization
tasks give us control over the choice of smoothness constants. All parameters, including the step sizes, are
chosen as suggested by the corresponding theory. In the plots, we represent the relation between the norm of
gradients and the number of gradient calculations ∇fi.
5.1 Quadratic optimization tasks with various Hessian Variances L±
UsingAlgorithm3(seeAppendix), wegeneratedvariousquadraticoptimizationtaskswithdifferentsmoothness
constantsL±∈[0,1.0]and fixedL−≈1.0(see Fig. 1). We choose d= 10,n= 1000,regularization λ= 0.001,
and the noise scale s∈{0,0.1,0.5,1}.According to Sec 3 and Table 2, the gradient complexity of original
PAGEmethod (“Vanilla PAGE” in Fig. 1) is proportional to L+.While the gradient complexity of the
new analysis with the Uniform With Replacement sampling (“Uniform With Replacement” in Fig. 1) is
proportional to L±,which is always less or equal L+.In Fig. 1, one can see that the smaller L±with respect
toL+,the better the performance of “Uniform With Replacement.” Moreover, we provide experiments with
theImportance sampling (“Importance” in Fig. 1) with qi=Li/summationtextn
i=1Lifor alli∈[n].This sampling has the
best performance in all regimes.
5.2 Quadratic optimization tasks with various local Lipschitz constatns Li
Using Algorithm 4 (see Appendix), we synthesized various quadratic optimization tasks with different
smoothness constants Li(see Fig. 2). We choose d= 10, n= 1000,the regularization λ= 0.001,and the
noise scale s∈{0,0.1,0.5,10.0}.We generated tasks in such way that the difference between maxiLiand
miniLiincreases. First, one can see that the Uniform With Replacement sampling with the new analysis
(“Uniform With Replacement” in Fig. 2) has better performance even in the cases of significant variations
ofLi. Next, we see the stability of the Importance sampling (“Importance” in Fig. 2) with respect to this
variations.
1Our code: https://github.com/mysteryresearcher/sampling-in-optimal-sgd
10Published in Transactions on Machine Learning Research (10/2023)
0 5000 10000 15000 20000 25000 30000
# of gradient calculations109
108
107
106
105
104
103
102
||f(xk)||2
minLi = 0.98; maxLi = 0.98Number of functions: 1000Vanilla PAGE, Batch: 1 Step: 0.03
Uniform With Replacement, Batch: 1 Step: 1.01
Importance, Batch: 1 Step: 1.01
0 5000 10000 15000 20000 25000 30000
# of gradient calculations109
108
107
106
105
104
103
102
||f(xk)||2
minLi = 0.98; maxLi = 1.62
Vanilla PAGE, Batch: 1 Step: 0.03
Uniform With Replacement, Batch: 1 Step: 0.24
Importance, Batch: 1 Step: 0.9
0 5000 10000 15000 20000 25000 30000
# of gradient calculations109
108
107
106
105
104
103
102
||f(xk)||2
minLi = 0.98; maxLi = 4.34
Vanilla PAGE, Batch: 1 Step: 0.02
Uniform With Replacement, Batch: 1 Step: 0.06
Importance, Batch: 1 Step: 0.65
0 5000 10000 15000 20000 25000 30000
# of gradient calculations109
108
107
106
105
104
103
102
||f(xk)||2
minLi = 0.98; maxLi = 64.47
Vanilla PAGE, Batch: 1 Step: 0.0
Uniform With Replacement, Batch: 1 Step: 0.0
Importance, Batch: 1 Step: 0.09
Figure 2: Comparison of samplings and methods on quadratic optimization tasks with various Li.
0.0 0.2 0.4 0.6 0.8 1.0
# of gradient calculations 1e6106
105
104
103
102
101
100||f(xk)||2
minLi = 0.25; maxLi = 28.75n = 49749Uniform With Replacement
Importance
w8adataset
0.0 0.2 0.4 0.6 0.8 1.0
# of gradient calculations 1e6101
100101102103104105106||f(xk)||2
minLi = 88.12; maxLi = 2500100864.0n = 690Uniform With Replacement
Importance australian dataset
Figure 3: Comparison of samplings on nonconvex machine learning tasks with LIBSVM datasets.
5.3 Nonconvex classification problem with LIBSVM datasets
We now solve nonconvex machine learning tasks and compare samplings on LIBSVM datasets (Chang & Lin,
2011) (see details in Sec A.2). As in previous sections, PAGEwith the Importance sampling performs better
in Fig. 3, especially in the australian dataset where the variation of Liis large.
References
Yossi Arjevani, Yair Carmon, John C Duchi, Dylan J Foster, Nathan Srebro, and Blake Woodworth. Lower
bounds for non-convex stochastic optimization. arXiv preprint arXiv:1912.02365 , 2019.
Christopher M Bishop and Nasser M Nasrabadi. Pattern recognition and machine learning , volume 4. Springer,
2006.
Konstantin Burlachenko, Samuel Horváth, and Peter Richtárik. Fl_pytorch: optimization research simulator
for federated learning. In Proceedings of the 2nd ACM International Workshop on Distributed Machine
Learning , pp. 1–7, 2021.
Chih-Chung Chang and Chih-Jen Lin. LIBSVM: a library for support vector machines. ACM Transactions
on Intelligent Systems and Technology (TIST) , 2(3):1–27, 2011.
Aaron Defazio, Francis Bach, and Simon Lacoste-Julien. SAGA: A fast incremental gradient method with
support for non-strongly convex composite objectives. Advances in Neural Information Processing Systems ,
27, 2014.
Cong Fang, Chris Junchi Li, Zhouchen Lin, and Tong Zhang. SPIDER: Near-optimal non-convex optimization
via stochastic path integrated differential estimator. In NeurIPS Information Processing Systems , 2018.
Ian Goodfellow, Yoshua Bengio, Aaron Courville, and Yoshua Bengio. Deep learning , volume 1. MIT Press,
2016.
Samuel Horváth and Peter Richtárik. Nonconvex variance reduced optimization with arbitrary sampling. In
International Conference on Machine Learning , pp. 2781–2789. PMLR, 2019.
11Published in Transactions on Machine Learning Research (10/2023)
Samuel Horváth, Lihua Lei, Peter Richtárik, and Michael I Jordan. Adaptivity of stochastic gradient methods
for nonconvex optimization. arXiv preprint arXiv:2002.05359 , 2020.
Rie Johnson and Tong Zhang. Accelerating stochastic gradient descent using predictive variance reduction.
Advances in Neural Information Processing Systems , 26, 2013.
Peter Kairouz, H Brendan McMahan, Brendan Avent, Aurélien Bellet, Mehdi Bennis, Arjun Nitin Bhagoji,
Kallista Bonawitz, Zachary Charles, Graham Cormode, Rachel Cummings, et al. Advances and open
problems in federated learning. Foundations and Trends ®in Machine Learning , 14(1–2):1–210, 2021.
Jakub Konečný, H Brendan McMahan, Felix X Yu, Peter Richtárik, Ananda Theertha Suresh, and Dave Bacon.
Federated learning: Strategies for improving communication efficiency. arXiv preprint arXiv:1610.05492 ,
2016.
Lihua Lei, Cheng Ju, Jianbo Chen, and Michael I Jordan. Non-convex finite-sum optimization via SCSG
methods. Advances in Neural Information Processing Systems , 30, 2017.
Zhize Li, Hongyan Bao, Xiangliang Zhang, and Peter Richtárik. PAGE: A simple and optimal probabilistic
gradient estimator for nonconvex optimization. In International Conference on Machine Learning , pp.
6286–6295. PMLR, 2021.
Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas. Communication-
efficient learning of deep networks from decentralized data. In Artificial Intelligence and Statistics , pp.
1273–1282. PMLR, 2017.
Yurii Nesterov. Lectures on Convex Optimization , volume 137. Springer, 2018.
Lam Nguyen, Jie Liu, Katya Scheinberg, and Martin Takáč. SARAH: A novel method for machine learning
problems using stochastic recursive gradient. In The 34th International Conference on Machine Learning ,
2017.
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen,
Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. Pytorch: An imperative style, high-performance deep
learning library. In Advances in Neural Information Processing Systems (NeurIPS) , 2019.
Xun Qian, Zheng Qu, and Peter Richtárik. L-SVRG and L-Katyusha with arbitrary sampling. Journal of
Machine Learning Research , 22:1–49, 2021.
PeterRichtárikandMartinTakáč. Parallelcoordinatedescentmethodsforbigdataoptimization. Mathematical
Programming , 156(1):433–484, 2016.
Rafał Szlendak, Alexander Tyurin, and Peter Richtárik. Permutation compressors for provably faster
distributed nonconvex optimization. International Conference on Learning Representations (ICLR) , 2022.
Zhe Wang, Kaiyi Ji, Yi Zhou, Yingbin Liang, and Vahid Tarokh. SpiderBoost and momentum: Faster
variance reduction algorithms. Advances in Neural Information Processing Systems , 32, 2019.
Peilin Zhao and Tong Zhang. Accelerating minibatch stochastic gradient descent using stratified sampling.
arXiv preprint arXiv:1405.3080 , 2014.
Dongruo Zhou, Pan Xu, and Quanquan Gu. Stochastic nested variance reduction for nonconvex optimization.
Advances in Neural Information Processing Systems , 31, 2018.
12Published in Transactions on Machine Learning Research (10/2023)
Contents
1 Introduction 1
1.1 Finite-sum optimization in the smooth nonconvex regime . . . . . . . . . . . . . . . . . . . . 2
1.2 Related work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2
1.3 Summary of contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2
2 Assumptions 3
2.1 Tight variance control of general sampling estimators . . . . . . . . . . . . . . . . . . . . . . . 3
2.2 Sampling-dependent smoothness constants . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4
2.3 Clarifications and Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5
3 A General and Refined Theoretical Analysis of PAGE 6
3.1Uniform With Replacement sampling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7
3.2Nicesampling (= Uniform Without Replacement ) sampling . . . . . . . . . . . . . . . . . . . 7
3.3Importance sampling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7
3.4 The power of B > 0. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7
3.5 Analysis under PŁCondition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7
4 Composition of Samplings: Application to Federated Learning 8
4.1 Federated Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9
4.2Stratified sampling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9
5 Experiments 10
5.1 Quadratic optimization tasks with various Hessian Variances L±. . . . . . . . . . . . . . . . 10
5.2 Quadratic optimization tasks with various local Lipschitz constatns Li. . . . . . . . . . . . . 10
5.3 Nonconvex classification problem with LIBSVM datasets . . . . . . . . . . . . . . . . . . . . . 11
A Extra Experiments and Details 15
A.1 Quadratic optimization tasks with various batch sizes. . . . . . . . . . . . . . . . . . . . . . . 15
A.2 Details on experiments with LIBSVM datasets . . . . . . . . . . . . . . . . . . . . . . . . . . 15
A.3 Federated learning experiments with LIBSVM dataset . . . . . . . . . . . . . . . . . . . . . . 16
A.4 Computing environment . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17
B Auxiliary fact: Variance Decomposition 18
C Examples of Optimization Problems 18
D Missing Proofs 19
E Derivations of the Parameters for the Samplings 21
13Published in Transactions on Machine Learning Research (10/2023)
E.1Nicesampling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21
E.2Independent sampling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22
E.3Importance andUniform With Replacement sampling . . . . . . . . . . . . . . . . . . . . . . . 23
E.4Extended Nice sampling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24
F The Optimal Choice of wi 25
G The Complexity of Algorithm 1 with the Importance sampling 25
H Missing Proofs: The Composition of Samplings 25
I Artificial Quadratic Optimization Tasks 29
14Published in Transactions on Machine Learning Research (10/2023)
A Extra Experiments and Details
A.1 Quadratic optimization tasks with various batch sizes.
In this section, we consider the same setup as in Sec 5.1. In Figure 4, we fix L±,and show that the Importance
sampling has better convergence rates with different batch sizes. Note that with large batches, the competitors
reduce to the GDmethod, and the difference is not significant.
103104105106107
# of gradient calculations (log scale)109
108
107
106
105
104
103
102
||f(xk)||2
L± = 0.1; L = 0.96; L+ = 0.97
Number of functions: 1000Vanilla PAGE, Batch: 1 Step: 0.03
Vanilla PAGE, Batch: 25 Step: 0.46
Vanilla PAGE, Batch: 100 Step: 0.79
Vanilla PAGE, Batch: 1000 Step: 1.01
Importance, Batch: 1 Step: 0.97
Importance, Batch: 25 Step: 1.04
Importance, Batch: 100 Step: 1.04
Importance, Batch: 1000 Step: 1.04
Figure 4: Comparison of samplings and methods with various batch sizes.
A.2 Details on experiments with LIBSVM datasets
We compare the samplings on practical machine learnings with LIBSVM datasets (Chang & Lin, 2011) (under
the 3-clause BSD license). Parameters of Algorithm 1 are chosen as suggested in Thm 6 and Cor 1. We take
the parameters for Uniform With Replacement andImportance samplings from Table 1 with qi=Li/summationtextn
i=1Li.
We consider the logistic regression task with a nonconvex regularization (Wang et al., 2019)
f(x1,x2) :=1
nn/summationdisplay
i=1
−log/parenleftigg
exp/parenleftbig
a⊤
ixyi/parenrightbig
/summationtext
y∈{1,2}exp/parenleftbig
a⊤
ixy/parenrightbig/parenrightigg
+λ/summationdisplay
y∈{1,2}d/summationdisplay
k=1{xy}2
k
1 +{xy}2
k
→ min
x1,x2∈Rd,
where{·}kis an indexing operation, ai∈Rdis the feature of a ithsample,yi∈{1,2}is the label of a ith
sample, constant λ= 0.001.We fix batch size τ= 1and take w8adataset (dimension d= 300, number of
samplesn= 49,749) andaustralian dataset (dimension d= 14, number of samples n= 690) from LIBSVM.
102103104105106107108109
Li01020304050607080Number of Datapointsaustralian
100101
Li05001000150020002500300035004000Number of Datapointsw8a
Figure 5: The distribution of Lipschitz constants Li
15Published in Transactions on Machine Learning Research (10/2023)
0.0 0.2 0.4 0.6 0.8 1.0
# of gradient calculations 1e6100101102103104105||f(xk)||2
Uniform With Replacement [points=1]
Uniform With Replacement [points=7]
Uniform With Replacement [points=21]
Uniform With Replacement [points=35]
Uniform With Replacement [points=56]
Importance [points=1]
Importance [points=7]
Importance [points=21]
Importance [points=35]
Importance [points=56]
(a)τclients = 1, #clientsn= 10
0.0 0.2 0.4 0.6 0.8 1.0
# of gradient calculations 1e6100101102103104105||f(xk)||2
Uniform With Replacement [points=1]
Uniform With Replacement [points=7]
Uniform With Replacement [points=21]
Uniform With Replacement [points=35]
Uniform With Replacement [points=56]
Importance [points=1]
Importance [points=7]
Importance [points=21]
Importance [points=35]
Importance [points=56]
 (b)τclients = 3, #clientsn= 10
0.0 0.2 0.4 0.6 0.8 1.0
# of gradient calculations 1e6100101102103104105||f(xk)||2
Uniform With Replacement [points=1]
Uniform With Replacement [points=7]
Uniform With Replacement [points=21]
Uniform With Replacement [points=35]
Uniform With Replacement [points=56]
Importance [points=1]
Importance [points=7]
Importance [points=21]
Importance [points=35]
Importance [points=56]
(c)τclients = 6, #clientsn= 10
0.0 0.2 0.4 0.6 0.8 1.0
# of gradient calculations 1e6100101102103104105||f(xk)||2
Uniform With Replacement [points=1]
Uniform With Replacement [points=7]
Uniform With Replacement [points=21]
Uniform With Replacement [points=35]
Uniform With Replacement [points=56]
Importance [points=1]
Importance [points=7]
Importance [points=21]
Importance [points=35]
Importance [points=56]
 (d)τclients = 9, #clientsn= 10
Figure 6: Comparison of methods on australian dataset from LIBSVM
For the logistic regression, the Lipschitz constants Lican be estimated. The distribution of Lipschitz constants
Liacross datapoints for that two datasets is presented in Fig. 5. We use Thm 5 to obtain L2
+,wandL2
±,w.
A.3 Federated learning experiments with LIBSVM dataset
In this experiment2, we compare the Uniform With Replacement sampling and the Importance sampling on
the logistic regression task from Sec. A.2 in a distributed environment. The training of the models is carried
onaustralian dataset from LIBSVM. The dataset is reshuffled with uniform distribution, and then it is split
acrossn= 10clients. In all experiments, we use Algorithm 2 with theoretical stepsizes according to Theorem
10. We take the parameters of the Uniform With Replacement andImportance samplings from Table 1 with
qi=Li/summationtextn
i=1Li.
According to Algorithm 2, we have the samplings Stthat sample clients, and the samplings St
ithat sample
data from the local datasets of clients. Algorithm 2 allows mixed sampling strategies that satisfy Assumption 1.
For simplicity, we consider that the samplings StandSt
iare of the same type.
For the logistic regression, the Lipschitz constants LiandLijof the gradients of functions fi(x)andfij(x)
can be estimated. As in Sec A.2, we use Thm 5 to obtain the constants L2
i,+,w, L2
i,±,w, L2
+,wandL2
±,w.The
results of experiments are provided in Fig. 6. We denote by τpointsthe batch size of the samplings St
ifor all
i∈[n],and byτclientsthe batch size of the sampling St.The number of gradient calculations in Fig. 6 stands
for the total number of gradient calculations in all clients.
We demonstrate results for different values of the batch sizes τclientsandτpoints. As in previous experiments,
theImportance sampling has better empirical performance than the Uniform With Replacement sampling. In
addition to it, we observe that plots with small batch sizes τpointsconverge faster.
2Our code: https://github.com/mysteryresearcher/page_ab_fl_experiment_a3
16Published in Transactions on Machine Learning Research (10/2023)
A.4 Computing environment
The code was written in Python 3.6.8 using PyTorch 1.9 (Paszke et al., 2019) and optimization research
simulator FL_PyTorch (Burlachenko et al., 2021). The distributed environment was emulated on a machine
with Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz and 64 cores.
17Published in Transactions on Machine Learning Research (10/2023)
B Auxiliary fact: Variance Decomposition
We use the following auxiliary fact in our proofs: Let us take a random vector ξ∈Rd, then
E/bracketleftig
∥ξ∥2/bracketrightig
= E/bracketleftig
∥ξ−E [ξ]∥2/bracketrightig
+∥E [ξ]∥2. (9)
C Examples of Optimization Problems
Example 1. For simplicity, let us assume that nis even. Let us consider the optimization problem (1)with
fi(x) =a
2x2+b
2x2fori∈{1,···,n/2}andfi(x) =−a
2x2+b
2x2fori∈{n/2 + 1,···,n},wherex∈Rand
b≥0.Thenf(x) =b
2x2and
L2
−= sup
x̸=y∥∇f(x)−∇f(y)∥2
∥x−y∥2=b2.
Moreover,
L2
+= sup
x̸=y1
n/summationtextn
i=1∥∇fi(x)−∇fi(y)∥2
∥x−y∥2=1
2/parenleftbig
(a+b)2+ (a−b)2/parenrightbig
,
and we can take aarbitrary large.
Example 2. Let us assume that n≥2and consider the optimization problem (1)withf1(x) =b
2x2and
fi(x) = 0fori∈{2,···,n},wherex∈Randb≥0.Thenf(x) =b
2nx2,
L−= sup
x̸=y∥∇f(x)−∇f(y)∥
∥x−y∥=b
n,
1
nn/summationdisplay
i=1Li=1
nsup
x̸=y∥∇f1(x)−∇f1(y)∥2
∥x−y∥2=b
n,
and
L+=/radicaligg
sup
x̸=y1
n/summationtextn
i=1∥∇fi(x)−∇fi(y)∥2
∥x−y∥2=b√n.
Example 3. Let us consider the optimization problem (8)withf(x) =1
g/summationtextg
i=11
m/summationtextm
j=1fij(x)andfij(x) =
bi
2x2for alli∈[g]andj∈[m], wherex∈Randb1≥0andbi= 0for alli∈{2,...,g}.Thenf(x) =b1
2gx2,
L−= sup
x̸=y∥∇f(x)−∇f(y)∥
∥x−y∥=b1
g,
L2
±= sup
x̸=y1
gm/summationtextg
i=1/summationtextm
j=1∥∇fij(x)−∇fij(y)∥2−∥∇f(x)−∇f(y)∥2
∥x−y∥2=/parenleftbigg1
g−1
g2/parenrightbigg
b2
1,
and
L2
i,±= sup
x̸=y1
m/summationtextn
j=m∥∇fij(x)−∇fij(y)∥2−∥∇fi(x)−∇fi(y)∥2
∥x−y∥2= 0∀i∈[n].
Substituting the smoothness constants to the complexity Nuniformfrom Sec 3 and Nuniformfrom Sec 4, one
can show that
Nuniform = Θ/parenleftbigg
n+∆0max{√nL±,L−}
ε/parenrightbigg
= Θ/parenleftbigg
n+∆0√nb1
ε√g/parenrightbigg
and
Ngroup = Θ
n+∆0max/braceleftig√n/radicalig
1
g/summationtextg
i=1L2
i,±,gL−/bracerightig
ε
= Θ/parenleftbigg
n+∆0b1
ε/parenrightbigg
.
The complexity Ngroupis√n/√gtimes better than the complexity Nuniform.
18Published in Transactions on Machine Learning Research (10/2023)
D Missing Proofs
Lemma 1. Suppose that Assumption 2 holds and let xt+1=xt−γgt.Then for any gt∈Rdandγ >0, we
have
f(xt+1)≤f(xt)−γ
2/vextenddouble/vextenddouble∇f(xt)/vextenddouble/vextenddouble2−/parenleftbigg1
2γ−L−
2/parenrightbigg/vextenddouble/vextenddoublext+1−xt/vextenddouble/vextenddouble2+γ
2/vextenddouble/vextenddoublegt−∇f(xt)/vextenddouble/vextenddouble2. (10)
Proof.Using Assumption 2, we have
f(xt+1)≤f(xt) +/angbracketleftbig
∇f(xt),xt+1−xt/angbracketrightbig
+L−
2/vextenddouble/vextenddoublext+1−xt/vextenddouble/vextenddouble2
=f(xt)−γ/angbracketleftbig
∇f(xt),gt/angbracketrightbig
+L−
2/vextenddouble/vextenddoublext+1−xt/vextenddouble/vextenddouble2.
Next, due to−⟨x,y⟩=1
2∥x−y∥2−1
2∥x∥2−1
2∥y∥2,we obtain
f(xt+1)≤f(xt)−γ
2/vextenddouble/vextenddouble∇f(xt)/vextenddouble/vextenddouble2−/parenleftbigg1
2γ−L−
2/parenrightbigg/vextenddouble/vextenddoublext+1−xt/vextenddouble/vextenddouble2+γ
2/vextenddouble/vextenddoublegt−∇f(xt)/vextenddouble/vextenddouble2.
Theorem 6. Suppose that Assumptions 1, 2, 3 hold and the samplings St∈S(A,B,{wi}n
i=1).
Then Algorithm 1 (PAGE) has the convergence rate E/bracketleftig/vextenddouble/vextenddouble∇f(/hatwidexT)/vextenddouble/vextenddouble2/bracketrightig
≤2∆0
γT,whereγ≤
/parenleftig
L−+/radicalig
1−p
p/parenleftbig
(A−B)L2
+,w+BL2
±,w/parenrightbig/parenrightig−1
.
Proof.We start with the estimation of the variance of the noise:
E/bracketleftig/vextenddouble/vextenddoublegt+1−∇f(xt+1)/vextenddouble/vextenddouble2/bracketrightig
= (1−p)E/bracketleftig/vextenddouble/vextenddoublegt+St/parenleftbig
{∇fi(xt+1)−∇fi(xt)}n
i=1/parenrightbig
−∇f(xt+1)/vextenddouble/vextenddouble2/bracketrightig
= (1−p)/vextenddouble/vextenddoubleSt/parenleftbig
{∇fi(xt+1)−∇fi(xt)}n
i=1/parenrightbig
−/parenleftbig
∇f(xt+1)−∇f(xt)/parenrightbig/vextenddouble/vextenddouble2+ (1−p)/vextenddouble/vextenddoublegt−∇f(xt)/vextenddouble/vextenddouble2,
where we used the unbiasedness of the sampling. Using Definition 1, we have
E/bracketleftig/vextenddouble/vextenddoublegt+1−∇f(xt+1)/vextenddouble/vextenddouble2/bracketrightig
≤(1−p)/parenleftigg
An/summationdisplay
i=11
n2wi/vextenddouble/vextenddouble∇fi(xt+1)−∇fi(xt)/vextenddouble/vextenddouble2−B/vextenddouble/vextenddouble∇f(xt+1)−∇f(xt)/vextenddouble/vextenddouble2/parenrightigg
+ (1−p)/vextenddouble/vextenddoublegt−∇f(xt)/vextenddouble/vextenddouble2.
Using the definition of L+,wandL±,w, we get
E/bracketleftig/vextenddouble/vextenddoublegt+1−∇f(xt+1)/vextenddouble/vextenddouble2/bracketrightig
≤(1−p)/parenleftigg
An/summationdisplay
i=11
n2wi/vextenddouble/vextenddouble∇fi(xt+1)−∇fi(xt)/vextenddouble/vextenddouble2−B/vextenddouble/vextenddouble∇f(xt+1)−∇f(xt)/vextenddouble/vextenddouble2/parenrightigg
+ (1−p)/vextenddouble/vextenddoublegt−∇f(xt)/vextenddouble/vextenddouble2
= (1−p)/parenleftigg
(A−B)/parenleftiggn/summationdisplay
i=11
n2wi/vextenddouble/vextenddouble∇fi(xt+1)−∇fi(xt)/vextenddouble/vextenddouble2/parenrightigg
+B/parenleftiggn/summationdisplay
i=11
n2wi/vextenddouble/vextenddouble∇fi(xt+1)−∇fi(xt)/vextenddouble/vextenddouble2−/vextenddouble/vextenddouble∇f(xt+1)−∇f(xt)/vextenddouble/vextenddouble2/parenrightigg/parenrightigg
+ (1−p)/vextenddouble/vextenddoublegt−∇f(xt)/vextenddouble/vextenddouble2
≤(1−p)/parenleftbig
(A−B)L2
+,w+BL2
±,w/parenrightbig/vextenddouble/vextenddoublext+1−xt/vextenddouble/vextenddouble2+ (1−p)/vextenddouble/vextenddoublegt−∇f(xt)/vextenddouble/vextenddouble2.(11)
19Published in Transactions on Machine Learning Research (10/2023)
We now continue the proof using Lemma 1. We add (10) withγ
2p×(11), and take expectation to get
E/bracketleftbigg
f(xt+1)−f∗+γ
2p/vextenddouble/vextenddoublegt+1−∇f(xt+1)/vextenddouble/vextenddouble2/bracketrightbigg
≤E/bracketleftbigg
f/parenleftbig
xt/parenrightbig
−f∗−γ
2/vextenddouble/vextenddouble∇f/parenleftbig
xt/parenrightbig/vextenddouble/vextenddouble2−/parenleftbigg1
2γ−L−
2/parenrightbigg/vextenddouble/vextenddoublext+1−xt/vextenddouble/vextenddouble2+γ
2/vextenddouble/vextenddoublegt−∇f/parenleftbig
xt/parenrightbig/vextenddouble/vextenddouble2/bracketrightbigg
+γ
2pE/bracketleftig
(1−p)/vextenddouble/vextenddoublegt−∇f/parenleftbig
xt/parenrightbig/vextenddouble/vextenddouble2+ (1−p)/parenleftbig
(A−B)L2
+,w+BL2
±,w/parenrightbig/vextenddouble/vextenddoublext+1−xt/vextenddouble/vextenddouble2/bracketrightig
= E/bracketleftbigg
f/parenleftbig
xt/parenrightbig
−f∗+γ
2p/vextenddouble/vextenddoublegt−∇f/parenleftbig
xt/parenrightbig/vextenddouble/vextenddouble2−γ
2/vextenddouble/vextenddouble∇f/parenleftbig
xt/parenrightbig/vextenddouble/vextenddouble2
−/parenleftbigg1
2γ−L−
2−(1−p)γ
2p/parenleftbig
(A−B)L2
+,w+BL2
±,w/parenrightbig/parenrightbigg/vextenddouble/vextenddoublext+1−xt/vextenddouble/vextenddouble2/bracketrightbigg
≤E/bracketleftbigg
f/parenleftbig
xt/parenrightbig
−f∗+γ
2p/vextenddouble/vextenddoublegt−∇f/parenleftbig
xt/parenrightbig/vextenddouble/vextenddouble2−γ
2/vextenddouble/vextenddouble∇f/parenleftbig
xt/parenrightbig/vextenddouble/vextenddouble2/bracketrightbigg
,(12)
where the last inequality holds due to1
2γ−L−
2−(1−p)γ
2p/parenleftbig
(A−B)L2
+,w+BL2
±,w/parenrightbig
≥0by choosing stepsize
γ≤/parenleftbigg
L−+/radicalbigg1−p
p/parenleftbig
(A−B)L2
+,w+BL2
±,w/parenrightbig/parenrightbigg−1
.
Now, if we define Φt:=f(xt)−f∗+γ
2p∥gt−∇f(xt)∥2, then (12) can be written in the form
E [Φt+1]≤E [Φt]−γ
2E/bracketleftig/vextenddouble/vextenddouble∇f/parenleftbig
xt/parenrightbig/vextenddouble/vextenddouble2/bracketrightig
.
Summing up from t= 0toT−1, we get
E [ΦT]≤E [Φ 0]−γ
2T−1/summationdisplay
t=0E/bracketleftig/vextenddouble/vextenddouble∇f/parenleftbig
xt/parenrightbig/vextenddouble/vextenddouble2/bracketrightig
.
Then according to the output of the algorithm, i.e., /hatwidexTis randomly chosen from {xt}t∈[T]and Φ0=
f/parenleftbig
x0/parenrightbig
−f∗+γ
2p∥g0−∇f/parenleftbig
x0/parenrightbig
∥2=f/parenleftbig
x0/parenrightbig
−f∗def= ∆ 0, we have
E/bracketleftig
∥∇f(/hatwidexT)∥2/bracketrightig
≤2∆0
γT.
Theorem 7. Suppose that Assumptions 1, 2, 3, 4 and the samplings St∈S(A,B,{wi}n
i=1).
Then Algorithm 1 (PAGE)has the convergence rate E/bracketleftbig
f(xT)/bracketrightbig
−f∗≤(1−γµ)T∆0,whereγ≤
min/braceleftbigg/parenleftig
L−+/radicalig
2(1−p)
p/parenleftbig
(A−B)L2
+,w+BL2
±,w/parenrightbig/parenrightig−1
,p
2µ/bracerightbigg
.
Proof.From the proof of Thm 6, we know that
E/bracketleftig/vextenddouble/vextenddoublegt+1−∇f(xt+1)/vextenddouble/vextenddouble2/bracketrightig
≤(1−p)/parenleftbig
(A−B)L2
+,w+BL2
±,w/parenrightbig/vextenddouble/vextenddoublext+1−xt/vextenddouble/vextenddouble2+ (1−p)/vextenddouble/vextenddoublegt−∇f(xt)/vextenddouble/vextenddouble2. (13)
20Published in Transactions on Machine Learning Research (10/2023)
Using Lemma 1, we add (10) withγ
p×(13), and take expectation to get
E/bracketleftbigg
f(xt+1)−f∗+γ
p/vextenddouble/vextenddoublegt+1−∇f(xt+1)/vextenddouble/vextenddouble2/bracketrightbigg
≤E/bracketleftbigg
f/parenleftbig
xt/parenrightbig
−f∗−γ
2/vextenddouble/vextenddouble∇f/parenleftbig
xt/parenrightbig/vextenddouble/vextenddouble2−/parenleftbigg1
2γ−L−
2/parenrightbigg/vextenddouble/vextenddoublext+1−xt/vextenddouble/vextenddouble2+γ
2/vextenddouble/vextenddoublegt−∇f/parenleftbig
xt/parenrightbig/vextenddouble/vextenddouble2/bracketrightbigg
+γ
pE/bracketleftig
(1−p)/vextenddouble/vextenddoublegt−∇f/parenleftbig
xt/parenrightbig/vextenddouble/vextenddouble2+ (1−p)/parenleftbig
(A−B)L2
+,w+BL2
±,w/parenrightbig/vextenddouble/vextenddoublext+1−xt/vextenddouble/vextenddouble2/bracketrightig
= E/bracketleftbigg
f/parenleftbig
xt/parenrightbig
−f∗+/parenleftig
1−p
2/parenrightigγ
p/vextenddouble/vextenddoublegt−∇f/parenleftbig
xt/parenrightbig/vextenddouble/vextenddouble2−γ
2/vextenddouble/vextenddouble∇f/parenleftbig
xt/parenrightbig/vextenddouble/vextenddouble2
−/parenleftbigg1
2γ−L−
2−(1−p)γ
p/parenleftbig
(A−B)L2
+,w+BL2
±,w/parenrightbig/parenrightbigg/vextenddouble/vextenddoublext+1−xt/vextenddouble/vextenddouble2/bracketrightbigg
≤E/bracketleftbigg
f/parenleftbig
xt/parenrightbig
−f∗+/parenleftig
1−p
2/parenrightigγ
p/vextenddouble/vextenddoublegt−∇f/parenleftbig
xt/parenrightbig/vextenddouble/vextenddouble2−γ
2/vextenddouble/vextenddouble∇f/parenleftbig
xt/parenrightbig/vextenddouble/vextenddouble2/bracketrightbigg
,
where the last inequality holds due to1
2γ−L−
2−(1−p)γ
p/parenleftbig
(A−B)L2
+,w+BL2
±,w/parenrightbig
≥0by choosing stepsize
γ≤/parenleftigg
L−+/radicaligg
2(1−p)
p/parenleftbig
(A−B)L2
+,w+BL2
±,w/parenrightbig/parenrightigg−1
.
Next, using Assumption 4 and γ≤p
2µ, we have
E/bracketleftbigg
f(xt+1)−f∗+γ
p/vextenddouble/vextenddoublegt+1−∇f(xt+1)/vextenddouble/vextenddouble2/bracketrightbigg
≤(1−γµ) E/bracketleftbigg
f/parenleftbig
xt/parenrightbig
−f∗+γ
p/vextenddouble/vextenddoublegt−∇f/parenleftbig
xt/parenrightbig/vextenddouble/vextenddouble2/bracketrightbigg
.
Unrolling the recursion and considering that g0=∇f(x0),we can complete the proof of theorem.
E Derivations of the Parameters for the Samplings
E.1Nicesampling
LetSbe a random subset uniformly chosen from [n]with a fixed cardinality τ. Let us fix a1,...,an∈Rd.A
sampling S(a1,...,an) :=1
n/summationtext
i∈Sai
piis called the Nicesampling, where pi:=Prob (i∈S).
Let us bound E/bracketleftig/vextenddouble/vextenddoubleS(a1,...,an)−1
n/summationtextn
i=1ai/vextenddouble/vextenddouble2/bracketrightig
and find parameters from Definition 1. Note that |S|=|S|=
τ.We introduce auxiliary random variables
χi:=/braceleftigg
1i∈S
0otherwise..
21Published in Transactions on Machine Learning Research (10/2023)
Due topi=Prob (i∈S) =τ
n,we have
E
/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
n/summationdisplay
i∈Sai
pi/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
= E
/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
τn/summationdisplay
i=1χiai/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2

=1
τ2n/summationdisplay
i=1E/bracketleftig
∥χiai∥2/bracketrightig
+1
τ2/summationdisplay
i̸=jE [⟨χiai,χjaj⟩]
=1
τ2n/summationdisplay
i=1E [χi]∥ai∥2+1
τ2/summationdisplay
i̸=jE [⟨χi,χj⟩]⟨ai,aj⟩
=1
nτn/summationdisplay
i=1∥ai∥2+τ−1
n(n−1)τ/summationdisplay
i̸=j⟨ai,aj⟩
=1
nτn/summationdisplay
i=1∥ai∥2+τ−1
n(n−1)τ
/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddoublen/summationdisplay
i=1ai/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
−n/summationdisplay
i=1∥ai∥2

=n−τ
τ(n−1)1
nn/summationdisplay
i=1∥ai∥2+τ−1
n(n−1)τ/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddoublen/summationdisplay
i=1ai/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
,
where we use E/bracketleftbig
χ2
i/bracketrightbig
= E [χi] =τ
nandE [χiχj] =τ(τ−1)
n(n−1),wheni̸=j.
Finally, we have
E
/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
n/summationdisplay
i∈Sai
pi−1
nn/summationdisplay
i=1ai/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
= E
/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
n/summationdisplay
i∈Sai
pi/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
−/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
nn/summationdisplay
i=1ai/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
=n−τ
τ(n−1)1
nn/summationdisplay
i=1∥ai∥2+τ−1
n(n−1)τ/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddoublen/summationdisplay
i=1ai/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
−/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
nn/summationdisplay
i=1ai/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
=n−τ
τ(n−1)
1
nn/summationdisplay
i=1∥ai∥2−/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
nn/summationdisplay
i=1ai/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
.
Thus we have A=B=n−τ
τ(n−1)andwi=1
nfor alli∈[n].
E.2Independent sampling
Let us define i.i.d. random variables
χi=/braceleftigg
1with probability pi
0with probability 1−pi,.
for alli∈[n]and takeS:={i∈[n]|χi= 1}.We now fix a1,...,an∈Rd.A sampling S(a1,...,an) :=
1
n/summationtext
i∈Sai
piis called the Independent sampling, where pi:=Prob (i∈S).
22Published in Transactions on Machine Learning Research (10/2023)
We get
E
/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
n/summationdisplay
i∈Sai
pi−1
nn/summationdisplay
i=1ai/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
= E
/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
nn/summationdisplay
i=11
piχiai/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
−/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
nn/summationdisplay
i=1ai/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
=n/summationdisplay
i=1E [χi]
n2p2
i∥ai∥2+/summationdisplay
i̸=jE [χi] E [χj]
n2pipj⟨ai,aj⟩−/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
nn/summationdisplay
i=1ai/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
=n/summationdisplay
i=11
n2pi∥ai∥2+1
n2
/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddoublen/summationdisplay
i=1ai/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
−n/summationdisplay
i=1∥ai∥2
−/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
nn/summationdisplay
i=1ai/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
=1
n2n/summationdisplay
i=1/parenleftbigg1
pi−1/parenrightbigg
∥ai∥2.
Thus we have A=1/summationtextn
i=1pi
1−pi, B= 0andwi=pi
1−pi/summationtextn
i=1pi
1−pifor alli∈[n].
E.3Importance andUniform With Replacement sampling
Let us fixτ >0.For allk∈[τ],we define i.i.d. random variables
χk=

1with probability q1
2with probability q2
...
nwith probability qn,
where (q1,...,qn)∈Sn(simple simplex). A sampling
S(a1,...,an) :=1
ττ/summationdisplay
k=1aχk
nqχk
is called the Importance sampling. The Importance sampling reduces to the Uniform With Replacement
sampling when qi=1/nfor alli∈[n].Note that|S|≤τ.
Let us bound the variance
E
/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
ττ/summationdisplay
k=1aχk
nqχk−1
nn/summationdisplay
i=1ai/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2

=1
τ2τ/summationdisplay
k=1E
/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddoubleaχk
nqχk−1
nn/summationdisplay
i=1ai/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
+1
τ2/summationdisplay
k̸=k′E/bracketleftigg/angbracketleftigg
aχk
nqχk−1
nn/summationdisplay
i=1ai,aχk′
nqχk′−1
nn/summationdisplay
i=1ai/angbracketrightigg/bracketrightigg
.
Using the independents and unbiasedness of the random variables, the last term vanishes and we get
E
/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
ττ/summationdisplay
k=1aχk
nqχk−1
nn/summationdisplay
i=1ai/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
=1
τ2τ/summationdisplay
k=1E
/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddoubleaχk
nqχk−1
nn/summationdisplay
i=1ai/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2

(9)=1
τ2τ/summationdisplay
k=1E/bracketleftigg/vextenddouble/vextenddouble/vextenddouble/vextenddoubleaχk
nqχk/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightigg
−1
τ/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
nn/summationdisplay
i=1ai/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
=1
τn/summationdisplay
i=1qi/vextenddouble/vextenddouble/vextenddouble/vextenddoubleai
nqi/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
−1
τ/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
nn/summationdisplay
i=1ai/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
23Published in Transactions on Machine Learning Research (10/2023)
=1
τ
1
nn/summationdisplay
i=11
nqi∥ai∥2−/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
nn/summationdisplay
i=1ai/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
.
Thus we have A=B=1
τ,andwi=qifor alli∈[n].
E.4Extended Nice sampling
In this section, we analyze the extension of Nicesampling. First, we litimes repeat each vector ai, then we
use theNicesampling. We define
˜ai:=

/summationtextn
j=1lj
nl1a11≤i≤l1 /summationtextn
j=1lj
nl2a2l1+ 1≤i≤l1+l2
.../summationtextn
j=1lj
nlnan/summationtextn−1
j=1lj≤i≤/summationtextn
j=1lj,,
whereai∈Rdandli≥1for alli∈[n].Then we have
1
nn/summationdisplay
i=1ai(x) =1
NN/summationdisplay
i=1˜ai(x),
whereN:=/summationtextn
j=1lj. Also, we denote Nk:=/summationtextk
j=1lj.
For someτ >0,we apply the Nicesampling method:
S(a1,...,an) :=1
N/summationdisplay
i∈S˜ai
pi=N/summationdisplay
i=11
τχi˜ai,
where
χi=/braceleftigg
1i∈S
0otherwise, pi=Prob (i∈S),
andSis a random set with cardinality τfrom [N]. The sampling S(a1,...,an)is called the Extended Nice
sampling.
We now ready to bound the variance. Using the results for the Nicesampling, we obtain
E
/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddoubleS(a1,...,an)−1
nn/summationdisplay
i=1ai(x)/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2

= E
/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddoubleS(a1,...,an)−1
NN/summationdisplay
i=1˜ai(x)/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2

=n−τ
τ(n−1)1
NN/summationdisplay
i=1∥˜ai∥2−n−τ
τ(n−1)/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
NN/summationdisplay
i=1˜ai/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
=n−τ
τ(n−1)/parenleftigg
1
N/parenleftbiggN
nl1/parenrightbigg2N1/summationdisplay
i=1∥a1∥2+1
N/parenleftbiggN
nl2/parenrightbigg2N2/summationdisplay
i=N1+1∥a2∥2
+···+1
N/parenleftbiggN
nln/parenrightbigg2N/summationdisplay
i=Nn−1+1∥an∥2
−n−τ
τ(n−1)/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
nn/summationdisplay
i=1ai/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
24Published in Transactions on Machine Learning Research (10/2023)
=n−τ
τ(n−1)/parenleftbiggN
nl11
n∥a1∥2+N
nl21
n∥a2∥2+···+N
nln1
n∥an∥2/parenrightbigg
−n−τ
τ(n−1)/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
nn/summationdisplay
i=1ai/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
=n−τ
τ(n−1)/parenleftiggn/summationdisplay
i=11
n2wi∥ai∥2/parenrightigg
−n−τ
τ(n−1)/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
nn/summationdisplay
i=1ai/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
wherewi=li
N. Thus we have A=B=n−τ
τ(n−1)andwi=li
Nfori∈[n].
F The Optimal Choice of wi
Let us consider L2
+,wandL2
±,w.In Sec 2, we show that one can take L2
+,w=L2
±,w=1
n/summationtextn
i=11
nwiL2
i.Let us
minimize1
n/summationtextn
i=11
nwiL2
iwith respect to the weights wisuch thatw1,...,wn≥0and/summationtextn
i=1wi= 1. Using
the method of Lagrange multipliers, we can construct a Lagrangian
L(w,λ) :=1
nn/summationdisplay
i=11
nwiL2
i−λ/parenleftiggn/summationdisplay
i=1wi−1/parenrightigg
.
Next, we calculate partial derivatives
∂L
∂wi=−1
n2w2
iL2
i−λ= 0∀i∈[n]
and get
w2
i=−L2
i
n2λ.
Using/summationtextn
i=1wi= 1,we can show that the weights w∗
i=Li/summationtextn
i=1Liare the solutions of the minimization
problem. Moreover,
L2
±,w∗=1
nn/summationdisplay
i=11
nw∗
iL2
i=/parenleftigg
1
nn/summationdisplay
i=1Li/parenrightigg2
.
G The Complexity of Algorithm 1 with the Importance sampling
The expected number of gradient calculations ∇fiof Algorithm 1 with the Importance sampling, the optimal
wi∗from Sec. F, and τ≤max/braceleftig√nL±,w
L−,1/bracerightig
equals
Nimportance =O
n+∆0
ετ
L−+√n
τ/radicaltp/radicalvertex/radicalvertex/radicalbt1
nn/summationdisplay
i=11
nwi∗L2
i


=O/parenleftigg
n+∆0
ετ/parenleftigg
L−+√n
τ1
nn/summationdisplay
i=1Li/parenrightigg/parenrightigg
=O/parenleftigg
n+∆0
ε√nL±,w∗+∆0√n/parenleftbig1
n/summationtextn
i=1Li/parenrightbig
ε/parenrightigg
=O/parenleftigg
n+∆0√n/parenleftbig1
n/summationtextn
i=1Li/parenrightbig
ε/parenrightigg
.
H Missing Proofs: The Composition of Samplings
Lemma 2. Let us assume that a random sampling function Sbelongs to Definition 1 with some A,Band
weightswi,and a random sampling function Sibelongs to Definition 1 with some Ai,Biand weights wijfor
25Published in Transactions on Machine Learning Research (10/2023)
alli∈[n].Moreover,B≤1.Then
E
/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddoubleS(S1(a11,...,a 1m1),...,Sn(an1,...,anmn))−1
nn/summationdisplay
i=1
1
mimi/summationdisplay
j=1aij
/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2

≤1
nn/summationdisplay
i=1/parenleftbiggA
nwi+(1−B)
n/parenrightbigg
Ai
mimi/summationdisplay
j=11
miwij∥aij∥2−Bi/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
mimi/summationdisplay
j=1aij/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2

+A
nn/summationdisplay
i=11
nwi/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
mimi/summationdisplay
j=1aij/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
−B/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
nn/summationdisplay
i=1
1
mimi/summationdisplay
j=1aij
/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
,
whereaij∈Rdfor allj∈[mi]andi∈[n].
Proof.We denote/hatwideai:=Si(ai1,...,aimi)andai:=1
mi/summationtextmi
j=1aij.Using (9), we have
E
/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddoubleS(/hatwidea1,...,/hatwidean)−1
nn/summationdisplay
i=1ai/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2

= E
ES
/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddoubleS(/hatwidea1,...,/hatwidean)−1
nn/summationdisplay
i=1ai/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2


= E
ES
/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddoubleS(/hatwidea1,...,/hatwidean)−1
nn/summationdisplay
i=1/hatwideai/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2

+ E
/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
nn/summationdisplay
i=1/hatwideai−1
nn/summationdisplay
i=1ai/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
.
Next, using Definition 1 for the sampling S,we get
E
/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddoubleS(/hatwidea1,...,/hatwidean)−1
nn/summationdisplay
i=1ai/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2

≤A1
nn/summationdisplay
i=11
nwiE/bracketleftig
∥/hatwideai∥2/bracketrightig
−BE
/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
nn/summationdisplay
i=1/hatwideai/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2

+ E
/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
nn/summationdisplay
i=1/hatwideai−1
nn/summationdisplay
i=1ai/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
.
Due to (9), we obtain
E
/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddoubleS(/hatwidea1,...,/hatwidean)−1
nn/summationdisplay
i=1ai/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2

≤A1
nn/summationdisplay
i=11
nwiE/bracketleftig
∥/hatwideai−ai∥2/bracketrightig
+A1
nn/summationdisplay
i=11
nwi∥ai∥2
−BE
/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
nn/summationdisplay
i=1/hatwideai−1
nn/summationdisplay
i=1ai/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
−B/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
nn/summationdisplay
i=1ai/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
+ E
/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
nn/summationdisplay
i=1/hatwideai−1
nn/summationdisplay
i=1ai/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2

26Published in Transactions on Machine Learning Research (10/2023)
=A1
nn/summationdisplay
i=11
nwiE/bracketleftig
∥/hatwideai−ai∥2/bracketrightig
+A1
nn/summationdisplay
i=11
nwi∥ai∥2
+ (1−B)E
/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
nn/summationdisplay
i=1/hatwideai−1
nn/summationdisplay
i=1ai/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
−B/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
nn/summationdisplay
i=1ai/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
=A1
nn/summationdisplay
i=11
nwiE/bracketleftig
∥/hatwideai−ai∥2/bracketrightig
+A1
nn/summationdisplay
i=11
nwi∥ai∥2
+(1−B)
n2n/summationdisplay
i=1E/bracketleftig
∥/hatwideai−ai∥2/bracketrightig
−B/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
nn/summationdisplay
i=1ai/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
=1
nn/summationdisplay
i=1/parenleftbiggA
nwi+(1−B)
n/parenrightbigg
E/bracketleftig
∥/hatwideai−ai∥2/bracketrightig
+A1
nn/summationdisplay
i=11
nwi∥ai∥2−B/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
nn/summationdisplay
i=1ai/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
.
Using Definition 1 for the samplings Si,we have
E
/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddoubleS(/hatwidea1,...,/hatwidean)−1
nn/summationdisplay
i=1ai/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2

≤1
nn/summationdisplay
i=1/parenleftbiggA
nwi+(1−B)
n/parenrightbigg
Ai1
mimi/summationdisplay
j=11
miwij∥aij∥2−Bi∥ai∥2

+A1
nn/summationdisplay
i=11
nwi∥ai∥2−B/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
nn/summationdisplay
i=1ai/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
.
Theorem 10. Suppose that Assumptions 1, 2, 3, 5 hold and the samplings St∈S(A,B,{wi}n
i=1)and the
samplings St
i∈S(Ai,Bi,{wij}mi
j=1)for alli∈[n].Moreover,B≤1.Then Algorithm 2 has the convergence
rateE/bracketleftig/vextenddouble/vextenddouble∇f(/hatwidexT)/vextenddouble/vextenddouble2/bracketrightig
≤2∆0
γT,whereγ≤/parenleftig
L−+/radicalig
1−p
p(Ll+Lg)/parenrightig−1
,
Ll:=1
nn/summationdisplay
i=1/parenleftbigg
A
nwi+(1−B)
n/parenrightbigg
((Ai−Bi)L2
i,+,wi+BiL2
i,±,wi),
and
Lg:= (A−B)L2
+,w+BL2
±,w.
Proof.We start with the estimation of the variance of the noise:
E/bracketleftig/vextenddouble/vextenddoublegt+1−∇f(xt+1)/vextenddouble/vextenddouble2/bracketrightig
= (1−p)E/bracketleftbigg/vextenddouble/vextenddouble/vextenddoublegt+S/parenleftig/braceleftbig
Si/parenleftbig
{∇fij(xt+1)−∇fij(xt)}mi
j=1/parenrightbig/bracerightbign
i=1/parenrightig
−∇f(xt+1)/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
= (1−p)/vextenddouble/vextenddouble/vextenddoubleS/parenleftig/braceleftbig
Si/parenleftbig
{∇fij(xt+1)−∇fij(xt)}mi
j=1/parenrightbig/bracerightbign
i=1/parenrightig
−/parenleftbig
∇f(xt+1)−∇f(xt)/parenrightbig/vextenddouble/vextenddouble/vextenddouble2
+ (1−p)/vextenddouble/vextenddoublegt−∇f(xt)/vextenddouble/vextenddouble2,
where we used the unbiasedness of the composition of samplings. Using Lemma 2, we have
E/bracketleftig/vextenddouble/vextenddoublegt+1−∇f(xt+1)/vextenddouble/vextenddouble2/bracketrightig
≤(1−p)
1
nn/summationdisplay
i=1/parenleftbiggA
nwi+(1−B)
n/parenrightbigg
Ai
mimi/summationdisplay
j=11
miwij/vextenddouble/vextenddouble∇fij(xt+1)−∇fij(xt)/vextenddouble/vextenddouble2−Bi/vextenddouble/vextenddouble∇fi(xt+1)−∇fi(xt)/vextenddouble/vextenddouble2

27Published in Transactions on Machine Learning Research (10/2023)
+A
nn/summationdisplay
i=11
nwi/vextenddouble/vextenddouble∇fi(xt+1)−∇fi(xt)/vextenddouble/vextenddouble2−B/vextenddouble/vextenddouble∇f(xt+1)−∇f(xt)/vextenddouble/vextenddouble2/parenrightigg
+ (1−p)/vextenddouble/vextenddoublegt−∇f(xt)/vextenddouble/vextenddouble2.
Using Definitions 3, 4, 8 and 9, we get
E/bracketleftig/vextenddouble/vextenddoublegt+1−∇f(xt+1)/vextenddouble/vextenddouble2/bracketrightig
≤(1−p)
1
nn/summationdisplay
i=1/parenleftbiggA
nwi+(1−B)
n/parenrightbigg
Ai−Bi
mimi/summationdisplay
j=11
miwij/vextenddouble/vextenddouble∇fij(xt+1)−∇fij(xt)/vextenddouble/vextenddouble2
+Bi
1
mimi/summationdisplay
j=11
miwij/vextenddouble/vextenddouble∇fij(xt+1)−∇fij(xt)/vextenddouble/vextenddouble2−/vextenddouble/vextenddouble∇fi(xt+1)−∇fi(xt)/vextenddouble/vextenddouble2


+A−B
nn/summationdisplay
i=11
nwi/vextenddouble/vextenddouble∇fi(xt+1)−∇fi(xt)/vextenddouble/vextenddouble2
+B/parenleftigg
1
nn/summationdisplay
i=11
nwi/vextenddouble/vextenddouble∇fi(xt+1)−∇fi(xt)/vextenddouble/vextenddouble2−/vextenddouble/vextenddouble∇f(xt+1)−∇f(xt)/vextenddouble/vextenddouble2/parenrightigg/parenrightigg
+ (1−p)/vextenddouble/vextenddoublegt−∇f(xt)/vextenddouble/vextenddouble2
≤(1−p)/parenleftigg
1
nn/summationdisplay
i=1/parenleftbiggA
nwi+(1−B)
n/parenrightbigg/parenleftbig
(Ai−Bi)L2
i,+,wi+BiL2
i,±,wi/parenrightbig
+ (A−B)L2
+,w+BL2
±,w/parenrightigg
/vextenddouble/vextenddoublext+1−xt/vextenddouble/vextenddouble2
+ (1−p)/vextenddouble/vextenddoublegt−∇f(xt)/vextenddouble/vextenddouble2.
From this point the proof of theorem repeats the proof of Thm 6 with
1
nn/summationdisplay
i=1/parenleftbiggA
nwi+(1−B)
n/parenrightbigg/parenleftbig
(Ai−Bi)L2
i,+,wi+BiL2
i,±,wi/parenrightbig
+ (A−B)L2
+,w+BL2
±,w
instead of
(A−B)L2
+,w+BL2
±,w.
28Published in Transactions on Machine Learning Research (10/2023)
I Artificial Quadratic Optimization Tasks
In this section, we provide algorithms that we use to generate artificial optimization tasks for experiments.
Algorithm 3 and Algorithm 4 allow us to control the smoothness constants L±andLi,accordingly, via the
noise scales.
Algorithm 3 Generate quadratic optimization task with controlled L±(homogeneity)
1:Parameters: number nodes n, dimension d, regularizer λ, and noise scale s.
2:fori= 1,...,ndo
3:Generate random noises νs
i= 1 +sξs
iandνb
i=sξb
i,i.i.d.ξs
i,ξb
i∼NormalDistribution (0,1)
4:Take vector bi=νs
i
4(−1 +νb
i,0,···,0)∈Rd
5:Take the initial tridiagonal matrix
Ai=νs
i
4
2−1 0
−1......
......−1
0−1 2
∈Rd×d
6:end for
7:Take the mean of matrices A=1
n/summationtextn
i=1Ai
8:Find the minimum eigenvalue λmin(A)
9:fori= 1,...,ndo
10:Update matrix Ai=Ai+ (λ−λmin(A))I
11:end for
12:Take starting point x0= (√
d,0,···,0)
13:Output: matrices A1,···,An, vectorsb1,···,bn, starting point x0
Algorithm 4 Generate quadratic optimization task with controlled Li
1:Parameters: number nodes n, dimension d, regularizer λ, and noise scale s.
2:fori= 1,...,ndo
3:Generate random noises νs
i= 1 +sξs
i,where i.i.d. ξs
i∼ExponentialfDistribution (1.0)
4:Generate random noises νb
i=sξb
i,i.i.d.ξb
i∼NormalDistribution (0,1)
5:Take vector bi= (−1
4+νb
i,0,···,0)∈Rd
6:Take the initial tridiagonal matrix
Ai=νs
i
4
2−1 0
−1......
......−1
0−1 2
∈Rd×d
7:end for
8:Take starting point x0= (√
d,0,···,0)
9:Output: matrices A1,···,An, vectorsb1,···,bn, starting point x0
29