Published in Transactions on Machine Learning Research (06/2023)
Neural Networks beyond explainability:
Selective inference for sequence motifs
Antoine Villié antoine.villie@univ-lyon1.fr
Université de Lyon, Université Lyon 1, CNRS, VetAgro Sup, Laboratoire de Biométrie et Biologie Evolutive,
UMR5558, Villeurbanne, France
Philippe Veber philippe.veber@univ-lyon1.fr
Université de Lyon, Université Lyon 1, CNRS, VetAgro Sup, Laboratoire de Biométrie et Biologie Evolutive,
UMR5558, Villeurbanne, France
Yohann De Castro yohann.de-castro@ec-lyon.fr
Institut Camille Jordan, École Centrale Lyon, CNRS UMR 5208
Institut universitaire de France (IUF)
Laurent Jacob laurent.jacob@cnrs.fr
Sorbonne Université, CNRS, IBPS, Laboratory of Computational and Quantitative Biology (LCQB), UMR 7238,
Paris 75005, France
Reviewed on OpenReview: https: // openreview. net/ forum? id= nddEHTSnqg
Abstract
Over the past decade, neural networks have been successful at making predictions from
biological sequences. As in other fields of deep learning, tools have been devised to extract
features such as sequence motifs that can explain the predictions made by a trained net-
work. Here we intend to go beyond explainable machine learning and introduce SEISM, a
selective inference procedure to test the association between these extracted features and
the predicted phenotype. In particular, we discuss how training a one-layer convolutional
network is formally equivalent to selecting motifs maximizing some association score. We
adapt existing sampling-based selective inference procedures by quantizing this selection
over an infinite set to a large but finite grid. Finally, we show that sampling under a specific
choice of parameters is sufficient to characterize the composite null hypothesis typically used
for selective inference—a result that goes well beyond our particular framework. We illus-
trate the behavior of our method in terms of calibration, power and speed and discuss its
power/speed trade-off with a simpler data-split strategy. SEISM paves the way to an easier
analysis of neural networks used in regulatory genomics, and to more powerful methods for
genome wide association studies (GWAS).
1 Introduction
In the recent years, neural networks have been successfully used for making predictions from biological se-
quences. In particular, they have brought significant improvements in regulatory genomics, e.g.to predict
cell-type specific transcription factor binding, gene expression, chromatin accessibility or histone modifica-
tions from a DNA sequence (Zhou & Troyanskaya, 2015; Kelley et al., 2018; Avsec et al., 2021a;b). These
tasks are expected to be a good proxy for predicting the functional effect of non-coding variants, and help
us in turn make better sense of the observed human genetic variation and its effect on various phenotypical
traits including diseases. Most successful models have used convolutional neural networks (CNNs, LeCun &
Bengio, 1998) and more recent approaches have explored self-attention mechanisms (Vaswani et al., 2017).
These models have been trained from experimental data obtained from ChIP-seq, ATAC-seq, DNase-seq, or
CAGE assays, that provide examples where both the DNA sequence and the outcome of interest are known.
1Published in Transactions on Machine Learning Research (06/2023)
A commonly outlined limitation of neural networks is their lack of explainability or black box aspect, i.e.,
the contrast between their excellent prediction accuracy and the possibility to explain these in intuitive or
mechanistic terms (Ras et al., 2022; Molnar, 2022). Elementary one-layer CNNs don’t face this issue, as
their trained filters have a straightforward interpretation as position weight matrices (PWMs, Harr et al.,
1983; Schneider & Stephens, 1990), a historical and basic element of regulatory genomics. Nonetheless, these
simple models are notoriously too simple to capture the complexity of the regulatory code which requires
to account not only for individual motif presence but for their long range sequence context and mutual
interactions (Avsec et al., 2021b). Multi-layer CNNs and self-attention mechanisms model this additional
complexity but are less straightforward to interpret. Tools inspired from the explainable deep learning
literature have been adapted to extract features beyond PWMs and one-layer CNNs to explain the predicted
regulatory behavior (Novakovsky et al., 2022). It is therefore often possible to explain the predictions of a
trainedneuralnetworkforbiologicalsequences, eitherdirectlythroughestimatesofitsparametersorthrough
features extracted post hoc.
Unfortunately, finding features somewhat associated to an outcome is often not enough, as an observed non-
zero association can be spurious. In experimental science, it is actually common to quantify the significance
of this association, e.g., by testing the hypothesis that it is zero. Genome wide association studies (GWAS,
Visscher et al., 2017) for example find genetic variants correlated with a trait by building a linear model
explaining this trait by each variant and testing the hypothesis that the weight is zero. Statistical significance
has its own limitations (Wasserstein & Lazar, 2016), but often provides an intuitive scale for identifying
relevant features. Quantifying the significance of associations between interpretable features and predicted
outcome is equally important in the context of neural networks but has received little attention to our
knowledge.
Figure 1: Overview of our SEISM procedure. (a) The input is a set of sequences and corresponding pheno-
types in some space Y(b) It trains a convolutional neural networks to predict a phenotype from sequences,
which leads to the selection of sequence motifs. (c) Then SEISM partitions the space of motifs to quantize
the selection. The selection event is the set of phenotype vectors that would lead to selecting an element
in the same mesh. (d) Using a sampling strategy, SEISM builds a null distribution for the test statistic,
conditional to the selection event. The p-values associated with a selected motif is the quantile of its score
under this distribution.
Here, we set out to go beyond explainable machine learning by introducing SElective Inference for Sequence
Motifs (SEISM), depicted in Figure 1, a valid statistical inference procedure for these features. In order to do
so, we cast commonly used CNNs in a feature selection framework, and show that it achieves similar selection
performances as existing bioinformatics algorithms on de novomotifs discovery tasks. This selection needs to
be accounted for when testing the association of the features with the predicted trait. This problem has been
discussed and addressed in the growing literature on post-selection inference over the past few years, using
e.g.data-split (Wasserman & Roeder, 2009) or selective inference strategies (Taylor & Tibshirani, 2015;
Reid et al., 2018; Slim et al., 2019). The former split the data into two parts, performing selection on one
and inference on the other. They produce valid inference but necessarily result in a reduction of the sample
2Published in Transactions on Machine Learning Research (06/2023)
size, which is unsatisfying when the original sample size is limited. By contrast, the latter condition the null
distribution on the selecting event, which generally provides more power but can prove more computationally
intensive.
Our contributions are as follows:
•We formally cast one-layer CNNs into a motif discovery tool, reaching similar performances as
de-novomotifs discovery tools from the bio-informatics literature (Section 3).
•We define a post-selection inference framework for the features selected by the neural network, using
either data-split or selective inference (Section 4), each being more appropriate in a given sample
size regime.
•Both strategies require sampling under a normal null hypothesis which is composite—several mean
vectorsdefinethesamenull—anddependsonanunknownparameters. Weprovideinvarianceresults
suggesting a practical procedure that works around these issues (Section 4.6). To our knowledge,
they were a blind spot in sampling-based post-selection inference approaches beyond our specific
context.
•Existing selective inference methods are only defined for selections over a finite set. We work around
this issue by quantizing our selection to a very large but finite space, making it amenable to existing
sampling strategies. We show that the resulting procedure is well calibrated.
•We provide a PyTorch implementation of SEISM at:
https://gitlab.in2p3.fr/antoine.villie1/seism .
In this paper, we restrict our presentation to simple one-layer CNNs and sequence motifs. The procedure
we introduce here, however, is not limited to this framework. It can be applied to more expressive features
proposed in the explainable machine learning literature, but may require some further work depending on
the feature considered.
2 A short overview of our SEISM procedure
SEISM aims to detect sequence motifs associated with a biological outcome, and to test the statistical
significance of this association. Here we briefly describe the selective inference version of SEISM in order
to give the reader an overview of the procedure. It is summarized in Algorithm 1, and more details will be
given in the following sections.
(i) SEISM takes as input biological sequences Xassociated with a phenotype y. The user must also
specify the number of motifs to find, as well as a parameter controlling the meshing of the motif space,
that is the precision with which the found motifs will be tested.
(ii) The motif selection step corresponds to the maximisation of a so-called association score s(·,·), which
depends on the phenotype and on the motifs zthrough their activation patterns in the biological
sequencesφz,X. This step is formally equivalent to training a one hidden layer CNN. We implement
a greedy procedure, optimizing each new filter over the residuals of the previously entered ones, using
a gradient descent method initialized at the k-mer with the best score. To that end, we enumerates
thek-mers contained in Xusing the DSK software (Rizk et al., 2013) and compute their scores s(·,·).
(iii) SEISM splits the set of sequence motifs into meshes according to the input parameter. This step leads
to the definition of a set of null hypotheses and of a selection event E,i.e.the set of outcomes y′that
would have led to the selection of motifs within the same meshes as the ones selected in (ii), namely
the sequence of meshes (Mi1,...,Miq). Formally, the selection event reads
E:=/braceleftig
y′∈Y :∀j∈[q],arg max
z∈Zs(z,Pjy′)∈Mij/bracerightig
, (1)
for some projection matrix Pj, to be defined later.
3Published in Transactions on Machine Learning Research (06/2023)
(iv) Itapproximatestheconditionalnulldistributionoftheteststatisticsbysamplingbiologicaloutcomes y′
under the null, conditionally to the selection event. This sampling is performed using a hit-and-run
strategy (according to Algorithm 2), by building a discrete time Markov chain on Ewhose distribution
converges to the uniform one.
(v) SEISM finally computes the p-values for the null hypotheses defined in (iii), associated with the selected
motifs in ii, using the empirical distribution of the test statistics, and returns the motifs with their
association p-values. Given these p-values, one can adjust the number of selected motifs discarding the
ones with non-significant p-values. This multiple-testing issue has not been investigated in this paper,
but the practitioner can use for instance a Bonferroni bound to select the number of motifs.
The data-split version of SEISM applies the same (i)-(ii) steps on a fraction of the data , and simply compares
the scores of the selected motifs on the remaining data to the distribution of scores for the same motif with
data sampled under the null distribution—as opposed to the selective null generated by (iii)-(v). Sampling
is much faster under the null than under the selective null, because it does not involve a rejection step. Both
samplings will need our results in Section 4.6 to avoid depending on a particular value of the mean and
variance parameters.
Algorithm 1 SEISM algorithm (general formulation)
# Description: SEISMselects a set of sequence motifs (z1,...,zq)based on an association score s(·,·), and
evaluate their p-values based on a partition Z=/unionsqtextMi.
Inputs: Responsey∈Y⊆ Rn, sequence samples X, feature function z∈Z∝⇕⊣√∫⊔≀→φz,X∈Rn, association
scores:Z×Y→ R, number of selected motifs q≥1, meshesZ=/unionsqtext
i=1Mi, sampling algorithm HR.
Result: ((p1,z1),..., (pq,zq)), sequence of p-values and sequence motifs.
# Selection step: Selection of the sequence motifs (z1,...,zq)and the sequence of meshes (Mi1,...,Miq).
1forj= 1,...,q do
2zj←arg max
z∈Zs(z,Pjy); //Pkorthogonal projection onto Span
ℓ<j/braceleftbig
φzℓ,X/bracerightbig⊥
3ij←is.t.zj∈Mi; // the mesh Mijis selected
4end
# Inference step: SEISMprovides ap-valuepkon the statistical influence of the selected sequence motifs zk
conditional on the selection event (1)of observations y′that would have led to same selection of the sequence
of meshes (Mi1,...,Miq).
5y′(1),...,y′(N)←HR (y,/parenleftbig
Mi1,...,Miq/parenrightbig
); // Sampling outcomes under the selected null
6forj= 1,...,q do
7 ˜Fj(·;y′(1),...,y′(N))←empirical cumulative distribution function of s(rMij,Πjy′)under the selected
null ; //rMijis a motif representing MijandΠjthe orthogonal projection onto
Span
ℓ̸=j/braceleftbig
φzℓ,X/bracerightbig⊥
8pj←˜Fj(s(rMij) ;y′(1),...,y′(N)); // output the jthp-value
9end
3 One hidden layer CNNs select sequence motifs maximizing an association score
One-layer CNNs have been at the core of the rising popularity of deep learning over the past decade, by
enabling major improvements in computer vision tasks (Krizhevsky et al., 2012). Although they are formally
a specialized fully connected feedforward networks with additional constraints on the weights, CNNs are
equivalent to, and more often thought of as, a set of convolutions of the vectorial input with some smaller
vectors referred to as filters. When applying the network, dot products are taken between each of them and
4Published in Transactions on Machine Learning Research (06/2023)
successive windows of the vectorial input followed by some non-linear operation, producing an activation
profile for each filter. In one-layer networks, these activations are pooled across the windows into a single
scalar for each filter and these scalars are combined—typically through a linear or regular fully connected
network—to provide a prediction for the input. Because convolution filters are homogeneous to the input,
they easily lend themselves to interpretation: as small image patches for image inputs, and as sequence
motifs for appropriately encoded biological sequence inputs. Accordingly, activation profiles reflect how
much each piece of the input is similar to the filter—in the sense of the dot product—and applying a one-
layer CNN amounts to applying a predictive function to a modified representation of the original data by
these similarity profiles. Because convolution filters are jointly optimized with the parameterization of the
predictive function, CNNs are often described as a strategy to jointly learn a data representation and a
function acting on this representation, both being optimized for a prediction objective. In computer vision,
the optimized filters of the first layer typically learn to detect edges with different orientations. In biological
sequences, they learn short sequences whose presence anywhere in the input is predictive of the output
phenotype used for training.
Figure 2: A motif represented by its position weight matrix and corresponding sequence logo. The total
height of the letters indicates the information content of the position (in bits), closely related to the Shannon
entropy.
Unlike input sequences that are formed by a discrete succession of letters in some alphabet, trained filters
are continuous and therefore account for possible variation in the predictive short sequence, e.g., a T mostly
followed by a C but sometimes an A or a G and so on (Figure 2). These probabilistic objects have also been
used for a long time in the bioinformatics literature and referred to as position weight matrices (PWMs).
Inferring PWMs either according to their frequency in a set of sequences (Bailey et al., 2006) or their
discriminating power between two sets (Bailey, 2021) has been a major theme over the past thirty years.
Here we formalize the training a one-layer CNN as equivalent to the selection of a set of sequence motifs
that are optimal for some association score. This formalization will be instrumental in the definition of our
hypothesis testing procedure in Section 4.
Notations LetXrepresent a data set of none-hot encoded sequence samples {x1,x2,...,xn}, in a setX
of biological sequences assumed to be over an alphabet A—for DNA sequences, A={A,C,T,G}. One-hot
encoding maps each letter in Ato a vector in{0,1}|A|, with all-zero entries except for a single 1at the
coordinate corresponding to the order of the letter in A—for DNA sequences, Ais encoded as (1,0,0,0).
Everyxiis therefore encoded as a matrix in {0,1}|A|×|xi|—although in practice, encoded sequences are often
padded with dummy columns to have the same lengths. We denote yi∈Ythe measurement of a biological
property associated with sequence xi, andy∈Ynthe corresponding vector of outcomes. We consider one-
layer CNNs with a Gaussian non-linearity with scale ω, a max global pooling and a linear prediction function.
These CNNs parameterize a function f:X →Ybyqfilters of length k, namelyZ:={z1,...,zq}∈Zq,
whereZis a subset of R|A|×k, given by the simplex in this paper:
Z=/braceleftbigg
z∈R|A|×k
+ :∀j∈[k],|A|/summationdisplay
i=1zi,j= 1/bracerightbigg
, (2)
andqweightsβ∈Rq.
5Published in Transactions on Machine Learning Research (06/2023)
More precisely, we define f(xi) :=/parenleftbig
φZ,Xβ/parenrightbig
i, withφZ,X∈Rn×qdefined asφZ,X=Cn˜φZ,X, where
Cn=In−n−11n1⊤
nis the centering operator, Inthe identity matrix, 1nthe all-one vector in Rn, and
˜φZ,X
i,j:= max
u∈[xi]ℓ/braceleftbigg
exp/parenleftbigg
−||zj−u||2
2ω2/parenrightbigg/bracerightbigg
, (3)
where [xi]ℓdenotes the set of ℓconsecutive entries of the vector xi(and of its reverse-complement coun-
terpart), and ωis a bandwidth hyperparameter whose impact and tuning is studied in Appendix A. This
model differs with a typical CNN in two ways. First, it uses a Gaussian activation function instead of an
exponential one; second the use of the centering operator that sets the average of the activation to zero.
These adjustments were made to improve the SEISM algorithm’s selection performances.
3.1 From empirical risk minimization to association scores
The function fis learned in a classical penalized empirical risk minimization framework, using the
data{X,y}:
min
(Z,β)∈(Z×Rq)n−1/vextenddouble/vextenddoubley−φZ,Xβ/vextenddouble/vextenddouble2+λ||β||2, (4)
for someλ > 0. Equation (4) formalizes the idea that learning a one-layer CNN on one-hot encoded
sequences amounts to learning a data-representation φZ,Xof the sequences parameterized by a set Zof
filters—corresponding to PWMs—and a linear function with weights βacting on this representation. Noting
that there exists a unique explicit optimal βfor Eq. (4), it follows immediately that:
arg min
Z/braceleftig
min
β/braceleftbig
n−1||y−φZ,Xβ||2+λ||β||2/bracerightbig/bracerightig
= arg max
Z/braceleftig
sridge
λ(Z,y)/bracerightig
, (5)
wheresridgedefines a particular quadratic association score between an outcome yand a set of filters Z:
sridge
λ(Z,y) :=yTφZ,X/bracketleftbig
(φZ,X)TφZ,X+λnIq/bracketrightbig−1(φZ,X)Ty. (6)
It formalizes the training of a CNN as the selection of a set of filters whose association with yin the sense
ofsridge
λis maximal. Of note, one has
lim
λ→∞λn×sridge
λ(Z,y) =yTφZ,X(φZ,X)Ty=:sHSIC(Z,y),
so for large values of the regularization hyperparameter, selecting filters by learning a CNN is equivalent
to selecting filters with the classical HSIC score (Song et al., 2012), because φalready includes a centering
operator. In addition to connecting sridgewithsHSIC, we observed that the centering in the definition
ofφZ,Xled to the selection of better sequence motifs in our experiments. Observe that the centering matrix
is an orthogonal projection matrix onto E:= Range(Cn), the orthogonal of the vector line generated by the
vector 1, and it holds/vextenddouble/vextenddoubley−φZ,Xβ/vextenddouble/vextenddouble2
n=/vextenddouble/vextenddoubleCny−φZ,Xβ/vextenddouble/vextenddouble2
n+/vextenddouble/vextenddoubley−Cny∥2
n. (7)
The solution of (4) is unchanged if yis replaced by Cny, and so we can assume that y∈Ewithout any
generality loss. Furthermore, this shows that we can work with skewed data in a classification context, since
imbalanced classes will have no effect on the result.
3.2 Greedy optimization
It is common to solve (4) by stochastic gradient descent (SGD) jointly over the qfilters. More generally, this
approach for training a neural network with a single, large hidden layer is known to find a global optimizer at
the largeqlimit under some assumptions (Soltanolkotabi et al., 2019). Our objective here is slightly different:
we do not necessarily aim at approximating a continuous measure with a large number of particules, but we
aim at selecting a small number of particules lending themselves to a biological interpretation. Furthermore,
thenumberofrelevantmotifsonagivendatasetisgenerallyunknown. Inthiscontext, itisknownthatjointly
optimizing the convolution filters leads to irrelevant PWMs, with some actual motif split across several filters
6Published in Transactions on Machine Learning Research (06/2023)
and other duplicated (Koo & Eddy, 2019). A possible strategy is to forego filter-level interpretation, train an
overparameterized network—with a much larger qthan the expected number of motifs—and use attribution
methods to extract relevant motifs or other interpretable features from the trained network (Shrikumar et al.,
2018). Here we adopt a different strategy using a forward stepwise procedure, where we iteratively optimize
each of the convolution filters over the residual error left by the previous ones.
More precisely at each of the qsteps, we select zjsuch that:
zj= arg max
z∈Zsridge(z,Pjy), (8)
wherePjis the projection operator onto the orthogonal of the subspace Span
ℓ<j/braceleftbig
1,φzℓ,X/bracerightbig
, see line 2 of
Algorithm 1. This is how zjis optimized over the residuals of the previous filters. The vector 1enforces that
we project on a subspace of E, in particular P1=Cn. Without this projection, iterating (8) would return
the samez. Of note, joint optimization procedures of the qfilters don’t face this issue, and forward selection
procedures over finite sets of features work around the problem by iteratively removing the selected elements
from the set over which selection if performed (Slim et al., 2019). This sequential strategy combined with
the testing procedure introduces in Section 4 provides a data-driven mean to choose the number qof relevant
motifs.
In practice, we solve (8) with a standard gradient descent algorithm, initialized at the k-mer with the best
association score. The k-mer list is obtained using the DSK software (Rizk et al., 2013). The length k
first varies according to a user-defined range, and the optimal value is chosen by SEISM, as described in
Appendix A. We work on a less constrained set than Z(2) and don’t enforce the positivity constraint during
optimization. We project the optimized motifs onto the full Zat the end of the process. Our procedure also
requires to choose a motif length k. We proceed adaptively by choosing the length leading to the highest
score, within a user-specified range.
With the one-layer CNNs training formally cast as the successive selection of qsequence motifs optimizing
an association score, we now turn to the problem of testing the significance of these associations. Of note,
what follows is only based on the definition of an association score and could be applied to perform inference
on other features coming from the training step of any algorithm, as long as one can define an association
score between the feature and the outcome.
4 Post-selection testing of the association between the outcome and trained
convolution filters
We now turn to the problem of testing the association between the selected motifs zand the trait y. In order
to do so, we need to solve three interrelated problems. First, the motifs were specifically selected for their
association with the trait, which leads to the well known post-selection inference problem. Any inference
procedure that disregards that the hypothesis was constructed using the same data used for testing is likely
invalid and produces deflated p-values. Second, we deal with a continuous selection event, because (8)
is performed over a continuous set Z. By contrast, existing solutions for post-selection inference address
selections over finite sets. Third, the null hypothesis commonly used for similar post-selection inference
problems is composite, i.e., it corresponds to several values of the parameters. Existing methods work
around this issue by fixing theses parameters to arbitrary values, thereby limiting the scope under which
they are calibrated. Here we present our solutions to these three problems.
Consider the Gaussian model:
y=µ+σϵ (9)
whereµ∈Eis the target deterministic signal, and ϵ∼N(0,Cn)the standard Gaussian distribution on E.
4.1 Selective null hypothesis
We follow Yamada et al. (2018) and test the association of a motif zthrough the following null hypothesis:
H0: “s(z,µ) = 0”, (10)
7Published in Transactions on Machine Learning Research (06/2023)
for some association score s. For azchosen independently of the data, H0could be tested by sampling y′
under the corresponding distribution, and using the quantile of the s(z,y′)scores corresponding to s(z,y)as
ap-value—i.e., the probability when sampling under H0to observe a score as extreme as s(z,y). In our case,
however, the motifs zin the trained convolution filters were specifically selected for their strong association
withy, and this procedure would not produce calibrated p-values. This problem is known as post-selection
inference, and has been discussed and addressed in a growing literature over the past few years. Data-split
strategies lead to valid inference but necessarily result in a reduction of the sample size, which is unsatisfying
when the original sample size is limited. Alternatively, selective inference frameworks were developed in the
recent years to address these issues. We refer to (Hastie et al., 2015, Chapter 6) and references therein for a
general presentation. Taylor et al. (2014) and Lee et al. (2016) address scenarios where the selection event,
i.e.the set of data outputs that would result in the selection of the same set of features, is polyhedral—
determined by the finite intersection of linear constraints. Reid & Tibshirani (2013), and later Reid et al.
(2015) extend this selection to clusters or groups of features, still in the linear framework. Yamada et al.
(2018) extended post-selection inference to the non-linear framework, by proposing a kernel-based approach,
where the selection is performed through the HSIC criterion. Slim et al. (2019) generalize this work, by
allowing the selection to be carried out with a wider range of tools, making use of quadratic association
scores.
To our knowledge, the selective inference literature only addresses the problem of selecting features from a
discrete collection and does not provide a solution for selections from a continuous set like our Z. Hence,
testing (10) directly is not feasible and we resort to the quantization of the motif space to address this
problem.
In addition to that, we push the analysis of the statistical model further, in order to be able to apply it with
weaker assumptions on the data distribution.
4.2 Selective inference over a continuous set of features
Formally, our selection event Econt.is the set of outcomes y′that would have led to the selection of the same
set of motifs Z={z1,...,zq}than the one selected using yfrom the real dataset, when applying the same
selection procedure:
Econt.:=/braceleftbig
y′∈E :∀j∈{1,...,q}arg max
z∈Zs(z,Pjy′) =zj/bracerightbig
, (11)
wherePjis the orthogonal projection onto Span
ℓ<j/braceleftbig
1,φzℓ,X/bracerightbig⊥.
A simple rejection approach to sample from the null (10) conditioned to Econt.would be to sample yinE
under (9, 10) and only retain those in Econt.. Unfortunately, Econt.belongs to a strictly lower-dimensional
vector space of Rnand is therefore a null set for the Lebesgue measure on Rn. ForsHSICandsridge, and
noting that a maximum is also a critical point, we indeed obtain:
y′∈Econt.=⇒ ∀j∈{1,...,q}Pjy′∈Span/braceleftbig
∇zφzj,X/bracerightbig⊥.
Forq= 1and assuming that the different directions of the gradient are independent, this spans is a
vector subspace with dimension n−4×k. We empirically observed that sampling from this subspace
produced a non-zero proportion of y′inEcont.. Nonetheless, choosing a sampling distribution that leads to
the correct conditional distribution is not straightforward—and may not even be possible—as discussed in
Supplementary Material B. Moreover, relying on conditional probability with respect to a null set is not well
definedandmayleadtotheBorel-Kolmogorovparadox(Bungert&Wacker,2022), whichfurthercomplicates
its use.
We choose to circumvent this issue using a partition of the space Zof motifs spaces, over which our selec-
tion (8) operates, into a very large but finite set of meshes: Z=/unionsqtextMi. As depicted in Figure 3, we consider
a regular partition of each coordinates into mbins:
8Published in Transactions on Machine Learning Research (06/2023)
1
0:75
0:5
0:25
0
1 0 :75 0 :5 0 :25 00
0:25
0:5
0:75
1A C
G
Figure 3: Discretization of the 3-letters alphabet simplex {A,C,G}, with a binning parameter for the meshes
m= 4.
Based on this partition into meshes, we define a quantized selection event Eas follows. First, given an
outcomeywe define the sequence of the qselected meshes (Mi1,...,Miq)as
∀j∈{1,...,q},arg max
z∈Zs(z,Pjy)∈Mij,
Second, the selection event is given by:
E(i1,...,iq) :=/braceleftig
y′∈Y :∀j∈{1,...,q},arg max
z∈Zs(z,Pjy′)∈Mij/bracerightig
, (12)
the set of outcomes y′that would have led to the selection of motifs within the same meshes as the selected
ones (Mi1,...,Miq).
We now show how quantization (12) of the selection problem make enables the definition of a valid inference
procedure. We start with the simplest case where we select a single motif ( q= 1).
4.3 Test with only one motif q= 1,µandσfixed
In this section, considering the motif z1was chosen by the SEISM selection procedure, selection event (12)
boils down to:
E(i1) :=/braceleftbigg
y′∈Y : arg max
z∈Zs(z,y′)∈Mi1/bracerightbigg
(13)
We use this simplified case to introduce our null hypotheses and test statistics attached to this selection
event, and consider two options:
•A first option consists in representing the mesh Mi1by its center c1. Then the corresponding null
hypothesis is the following:
H′
0,1: “s(c1,µ) = 0”, (14)
It can be tested using statistic V′
1=s(c1,y).
•A second possibility is to represent Mi1by the motif with the highest association score within. In
this case, the null hypothesis becomes:
H′′
0,1: “∀z∈Mi1, s(z,µ) = 0”, (15)
We test it using statistic V′′
1= max
z∈Mi1s(z,y).
9Published in Transactions on Machine Learning Research (06/2023)
Algorithm 2 Hypersphere Directions hit-and-run sampler
/*Description: The Hypersphere Directions hit-and-run sampler creates a discrete-time
Markov chain on an open and bounded region and is used to approximate a uniform
distribution on the selection event E. */
Inputs: Responsey∈E⊆Rn,BandRthe numbers of burn-in iterations and replicates.
Result:y′(B+1),...,y′(B+R)∈E⊆Rnthe replicates sampled under the conditional null distribution
10˜y′(0)←L(y);/*Lis the cumulative distribution function of N(µ,σ2Cn) */
11fort= 1,...,B +Rdo
12Sample uniformly θ(t)from{θ∈Rn,∥θ∥= 1};
13a(t)←max/braceleftigg
max
θ(i)
t>0−˜y′(t−1)
θt; max
θ(i)
t<01−˜y′(t−1)
θt/bracerightigg
;
14b(t)←max/braceleftigg
min
θ(i)
t<0−˜y′(t−1)
θt; min
θ(i)
t>01−˜y′(t−1)
θt/bracerightigg
;/* Sampling λ(t)from/bracketrightbig
a(t),b(t)/bracketleftbig
ensures that
˜y′(t−1)+λ(t)θ(t)∈]0,1[n*/
15 whiley′(t)/∈Edo
/* This loop is parallelized on several cores until one of them discovers a
replicates in the selection event. */
16 Sample uniformly λ(t)from/bracketrightbig
a(t),b(t)/bracketleftbig
;
17 ˜y′(t)←˜y′(t−1)+λ(t)θ(t);
18y′(t)←L−1(˜y′(t));
19 end
20end
In both cases, we reject the null hypothesis if the test statistics are greater than a threshold, determined
by their cumulative distributions under the nulls (14), (15) conditionally to E(i1):F′
1,(i1)andF′′
1,(i1). In
practice, there is no closed form for these conditional cumulative distributions, and we rely on an empirical
version that we build using a hit-and-run sampler algorithm, as described in Section 4.4.
Hypotheses (14) and (15) lead to very similar results when the meshes are small enough, which is easily the
case in practice. (14) gives us insights on one specific motif of the mesh — the center, but (15) tells us about
whether there exists a motif within Mi1associated with the phenotype. To illustrate the difference, let us
consider a meshing with only one bin per coordinate, that is the meshing with only one mesh, containing all
the motifs:
•Testing the center-based null hypothesis (14) boils down to testing the association of µwith the
motifc1with the same probabilities for each letter of Aat every position, and produces a p-value
of1, regardless of the data, since for any k-meru,∥c−u∥2=k×(0.752+ 3×0.252), which leads to
∀X∈X,φc,X=0according to the centering step, and to a zero score for any y′∈E.
•By contrast, one can obtain a strictly less than 1 p-value for (15), because different y′∈Ecan lead
to different scores, which means that there may exist a motif in Zassociated with y— but does not
inform us on which motif it is.
4.4 Sampling from the conditional null distribution with the Hit-and-Run algorithm
Even after reducing our selection to a finite set (Section 4.2), a rejection sampling strategy that would
drawy′from either (9, 16) or (9, 17) and only retain those leading to the selection of the same mesh as y
is not tractable as the rejection rate is empirically too low. Following Slim et al. (2019), we resort to a
Hypersphere Direction strategy (Algorithm 2).
10Published in Transactions on Machine Learning Research (06/2023)
The hit-and-run algorithm produces uniform samples from an open and bounded acceptance region—
corresponding, in our case, to the selection event. It starts from any point in the acceptance region, draws a
random direction from this point and samples along this direction until it finds one elements that also falls
in the acceptance region. It then follows the same procedure from this new starting point. The hit-and-run
sampler therefore also relies on rejection but it does so along a single dimension rather than from Rn. It
explores the selection event step by step, starting from a point that belongs to this event, which guarantees
a higher acceptance rate. To speed up the procedure, we parallelize the rejection step across several cores.
Because each point sampled by the hit-and-run procedure depends on the previous one, it is impossible to
parallelize the whole sampling process. By contrast, the rejection step used for computing a single replicate,
once a sampling direction has been fixed, can be parallelized. We draw several distances to the initial point
independently, optimizing new independent points, until one of them belongs to the selection event. This
parallelization provides a significant time saving, as discussed in Section 5.3. Algorithm 2 produces uniform
samples from an open and bounded acceptance region. The boundedness assumption does not hold in our
case as the arg max overZof the score only depends on the direction of yand not on its norm. The
openness requirement is ensured by the definition of the meshes. Following Slim et al. (2019) again, we use
the reparameterization ˜y=L(y), where L:Rn→]0,1[nis defined as L(y)i=Lµ,σ2(yi)fori= 1,...,n
andLµ,σ2denotes the cumulative distribution function of N(µ,σ2Cn). Sampling uniform ˜yfrom the open
bounded space ]0,1[nindirectly provides normal samples from N(µ,σ2Cn).
Combining this sampling strategy with the quantization of the selection event introduced in Section 4.2 and
the selective null hypotheses attached to this event introduced in Section 4.3 provides a selective inference
procedure for one selected motif z1(q= 1) and a null defined by a given pair (µ,σ)of parameters. Our
next two steps are to handle the selection of multiple motifs, and the general case where several µdescribe
the same null hypothesis and σis not specified.
4.5 Dealing with the selection of several motifs ( q>1)
We now consider that we selected q > 1motifs with the SEISM procedure, leading to the general (12)
selection event E(i1,...,iq). Generalizing our single-motif strategy of Section 4.3, we propose two options
for defining null hypotheses (and test statistics) related to this selection event:
•The first one relies on the centers of the selected meshes:
H0,j: “s(cj,Π′
jµ) = 0”, (16)
where Π′
jis the orthogonal projector onto Spanℓ̸=j/braceleftbig
φcℓ,X/bracerightbig⊥. In other words, it expresses that the
center of the mesh Mijis associated with µafter removing its component carried by the span of the
centers of the meshes corresponding the the q−1other motifs.
•And the second one takes advantages of the best motifs in each mesh:
H0,j: “∀(z∗
iℓ)ℓ̸=j∈(Miℓ)ℓ̸=j,∀z∈Mij, s(z,Π′′/parenleftig/parenleftbig
z∗
iℓ/parenrightbig
ℓ̸=j/parenrightig
µ) = 0”, (17)
withΠ′′/parenleftig/parenleftbig
z∗
iℓ/parenrightbig
ℓ̸=j/parenrightig
being the projection onto Spanℓ̸=j/braceleftbig
φz∗
iℓ,X/bracerightbig⊥.
Generalizing what we introduced for q= 1(Section 4.3), we test those hypotheses using V′
j=s(cj,Π′
jy)and
V′′
j= maxz∈Mijs(z,Π′′
jy). To that end, we rely on their cumulative distributions under the nulls (16), (17)
conditionally to E(i1,...,iq): respectively F′
1,...,q(i1,...,iq)andF′′
1,...,q, (i1,...,iq), empirically approximated with
Algorithm 2.
Following the work of Loftus & Taylor (2015) in the finite case, both versions of our null hypothesis are
joint across the qmotifs: each of them considers the association between the j-th selected motif and µafter
projecting onto the span of all others, not just the ones that were selected before — using Π′andΠ′′. This
is to be contrasted to our sequential selection process, which adjusts at each steps for the previously selected
motifs usingP.
In order to give more insights on these null hypotheses, we derive the following proposition:
11Published in Transactions on Machine Learning Research (06/2023)
Proposition 4.1 (Description of the selective nulls) .LetZ={z1,...,zq}beqsequence motifs. Let s(·,·)
be a score such that "nullity implies orthogonality" (for instance sHSICorsridge):
(A1)Nullity implies orthogonality: If{s(z,y) = 0}then{⟨φz,X,y⟩= 0}, for every (y,z)∈E×Z,
and for some function z→φz,X∈E.
Letµ∈Eand decompose µas
µ=q/summationdisplay
j=1αjφzj,X+µ (18)
withµ∈Eorthogonal to Span(φZ,X).
It holds that “s(zj,Πjµ) = 0”is equivalent to “αj= 0”for some decomposition (18).
IfRank(φZ,X) =qthen the decomposition (18) is unique, and the greedy selection procedure described
in Section 3 enforces this situation. We interpret this as follows: we look at a motif zℓand would like to
test its significance; in view of property (A1), we can eliminate the effects that are captured by the other
motifs by using the orthogonal projection onto the orthogonal of Span(φzj,X), given by Πj(using Πj=Π′
j
orΠj=Π′′/parenleftig/parenleftbig
z∗
iℓ/parenrightbig
ℓ̸=j/parenrightig
), and consider Πjyto test the association “s(zj,Πjµ) = 0”; equivalent to testing
“αj= 0”by the above proposition.
4.6 Sampling under selective multiple hypotheses with known σ
The sampling strategy described in Section 4.4 builds a conditional null distribution—therefore offering a
selective inference procedure—for a given µandσ. In practice, σis not known, and several values of µ
can describe the selective null hypotheses (16) or (17) for a given motif selection. Of note, this issue is
not specific to our selective inference procedure. It will arise in any sampling-based post-selection inference
strategy including data-split: even if the latter samples from a non-selective null hypothesis, it still needs
specific values for µandσ. Forµ, the issue is that any fixed value can not represent the whole set of possible
values, which would modify the null hypothesis actually tested. For the variance parameter, it may be fixed
by the user, but this may lead to a non-valid procedure if the chosen value is different from the real one.
We leave aside the choice of σfor now, and describe how we can sample from any null distribution (16)
or (17) using µ= 0for a given σ. Our results holds for scores verifying the following assumption—this
includes both sHSICandsridge:
(A2)Nullity implies translation-invariant: Ifs(z,y) = 0then∀y′∈E, s(z,y′) =s(z,y+y′), for
every (y,z)∈E×Z;
Under this assumption, the following proposition ensures that using the quantile of the empirical distribution
of scores sampled under µ= 0leads to a calibrated test procedure:
Proposition 4.2. Letsbe an association score such that (A2)holds. Let V′
j=s(cj,Π′
jy)andV′′
j=
maxz∈Mijs(z,Π′′
jy), formed from ysampled from (9)with any mean µsuch thats(z′,µ) = 0, any known
varianceσ > 0, and such that z′= arg maxz∈Zs(z,y). The conditional null distributions F′
j,(i1,...,iq)and
F′′
j,(i1,...,iq), with mean 0and variance σverify:
F′
j,(i1,...,iq)(V′
j)∼Unif (0,1)andF′′
j,(i1,...,iq)(V′′
j)∼Unif (0,1)
Proof.Assumption (A2)under the Gaussian model (9) implies the following property:
∀(z,A,y)∈Z×A×Esuch thaty=µ+σϵ,
“s(z,Aµ) = 0” =⇒“s(z,Ay) =s(z,σAε)”,(19)
12Published in Transactions on Machine Learning Research (06/2023)
which implies that, for a composite null hypothesis of the form H0: “s(z,Aµ) = 0”, the distribution
ofs(z,Ay)does not depend on the mean µthat satisfies H0. Hence, even if the hypothesis H0corresponds
to a set of probability distributions of ythat may depend on µ, the distribution of the statistic s(z,Ay)
does not depend on µunder this hypothesis. We can then conclude that if σis known, as it is assumed
to be the case in this section, then a test statistic of the form V=s(z,Πy)has the same distribution
ass(z,σΠϵ).
4.7 Sampling under selective multiple hypotheses with unknown σ
In practice, σis often unknown. To address this issue, we rely on the normalized versions of the test
statisticsV′andV′′introduced in Section 4.3, defined by
T′
j:=s(cj,Π′
jy)
∥y∥2andT′′
j:= max
z∈Mijs/parenleftig
z,Π′′/parenleftbig
(zℓ)ℓ̸=j/parenrightbig
y/parenrightig
∥y∥2(20)
wherezℓ= arg maxz∈Zs(z,Pℓy). We will denote G′
j,(i1,...,iq)andG′′
j,(i1,...,iq)their cumulative distribution
functions under the null, conditionally to E(i1,...,iq).
We will also make use of a third assumption, here again fulfilled by sHSICandsridge:
(A3)Two-homogeneity: It holds that s(z,ty) =t2s(z,y)for all (y,z)∈E×Z and allt>0.
Of note, normalizing the association score with respect to the labels does not affect the selection:
∀y∈Y,arg max
z∈Zs(z,y) = arg max
z∈Zs(z,y)
∥y∥2(21)
Ifµ=0, the distribution of the normalized statistics does not depend on σ, and the empirical cumulative
distribution functions of normalized scores obtained by sampling under µ=0and anyσstill provide a valid
inference procedure :
Proposition 4.3. Letsbe an association score such that (A2)and(A3)hold. LetT′
j=s(cj,Π′
jy)/∥y∥2
andT′′
j= maxz∈Mijs(z,Π′′
jy)/∥y∥2, formed from ysampled from (9)with meanµ=0, and any variance
σ >0. Then for all σ′>0, their conditional null distributions G′
j,(i1,...,iq)andG′′
j,(i1,...,iq)with mean 0and
varianceσ′verify:
G′
j,(i1,...,iq)(T′
j)∼Unif (0,1)andG′′
j,(i1,...,iq)(T′′
j)∼Unif (0,1)
Proof.Let us consider two different normal models as defined in (9) under the global null hypothesis “µ=0”
and given by
y(1)=σ(1)ε(1)andy(2)=σ(2)ε(2)
Then
s(cj,Π′
jy(1))
∥y(1)∥2∼s(cj,Π′
jy(2))
∥y(2)∥2ands(z,Π′′/parenleftig
(zℓ)ℓ̸=j/parenrightig
y(1))
∥y(1)∥2∼s(z,Π′′/parenleftig
(zℓ)ℓ̸=j/parenrightig
y(2))
∥y(2)∥2.
The proof directly follows assumption (A3)applied with t=∥y(·)∥2. Proposition 4.3 is complementary
to Proposition 4.2 and provides a selective inference procedure when σis unknown, under the special null
hypothesisµ= 0.
Our final result investigates the testing procedures for the general null hypotheses (16) and (17)—not re-
stricted toµ= 0—with an unknown σ. Recall that the decision rule is to reject the null hypothesis if the
observed value of the statistic is greater than a given threshold t. We show that choosing tto be a quantile
for the global null hypothesis ( µ= 0) leads to a calibrated (for the type I error) non-selective procedure,
see (22).
13Published in Transactions on Machine Learning Research (06/2023)
Proposition 4.4 (Global null achieves lowest observed significance) .LetZ={z1,...,zq}beqsequence
motifs. Let s(·,·)be a score such that (A1)and(A2)hold. Letµ∈Ebe such that
H0: “s(Z,µ) = 0”
Then
∀t>0,sup
µ∈H0P/bracketleftbiggs(Z,µ+σϵ)
∥µ+σϵ∥2≥t/bracketrightbigg
=P/bracketleftbiggs(Z,ϵ)
∥ϵ∥2≥t/bracketrightbigg
(22)
We provide a proof in Appendix C. This proof makes an ad-hoc use of Anderson’s theorem on a symmetric
convex cone (whereas it is usually devoted to symmetric convex bodies).
Proposition 4.4 shows that data-split produces a calibrated procedure for testing the general null hypothe-
ses (16) and (17) when sampling under the global null ( µ= 0) the test statistics (20). We could not prove
an equivalent statement for conditional null hypotheses, and Proposition 4.4 therefore does not guarantee
the validity of a selective inference procedure sampling under the global null ( µ= 0). Yet, we used it as
a heuristic justification of SEISM and we observed that it leads to empirically calibrated procedures, see
Section 5.2.
In view of Proposition 4.4 and its proof, one can see that the alternatives µsuch that∥Pqµ∥/∥µ∥is large
have small power. As the selection procedure described in Section 3 achieves good results (Section 5.1),
the chosen motifs Zshould capture the principal components of µ, and therefore are such that ∥Pqµ∥/∥µ∥
should be small.
5 Results
5.1 SEISM performs as well as state-of-the-art de novomotif discovery methods
In order to compare the accuracy of our selection step with existing motif discovery algorithms, we use the 40
ENCODE Transcription Factors ChIP-seq datasets from K562 cells (ENCODE Project Consortium, 2004),
each of which contains a known TF motif, denoted m∗, derived using completely independent assays (Jolma
et al., 2013). STREME (Bailey, 2021) and MEME (Bailey et al., 2006) are state-of-art bioinformatics
methods for de-novo motifs discovery tasks. STREME identifies motifs that maximize a Fisher score of
association between the presence of the motif and the binary class of sequences. By looking for maximum
likelihood estimates of the parameters of a mixture model - made up of a background distribution and a
model for generating k-mers at some positions - that may have produced a particular dataset using an
expectation maximisation technique, MEME finds enriched motifs in this dataset. Finally CKN-seq (Chen
et al., 2017) is a one-layer CNN tailored to small scale datasets. We set up STREME, MEME and SEISM to
select 5 sequence motifs. SEISM is run with a regularization parameter λ= 0.01. CKN-seq jointly optimizes
its filters, which notoriously leads to poor performances when few filters are used. We train it consequently
over 128 filters. We measure these accuracy of all methods by comparing the motifs they discover with
the known motif corresponding to the transcription factor m∗. We rely on the Tomtom method (Gupta
et al., 2007), which quantifies the probability that the euclidean distance between a random motif and m∗
is lower than the distance between the discovered motif and m∗. More precisely for each method we use the
lowest Tomtom p-value between the known TF motif m∗and any of those discovered by the method. The
Tomtom score is then defined as −log10of the Tomtom p-value. We define the accuracy of the method as
the proportion of experiments where the Tomtom score between its best match and the true TF motif was
higher than some threshold.
Figure 4 (left panel) demonstrates that SEISM is just as good as, if not superior to, state-of-the-art bioinfor-
matics algorithms at detecting sequence motifs when thresholding Tomtom p-values at 0.01. The one-layer
CNNwithjointlyoptimizedfiltersperformspoorlyinthisexperiments, emphasisingtheimportanceofgreedy
optimization for selecting the right motif.
Figure 4 (right panel) shows that SEISM performs slightly worse than STREME and MEME for high
thresholds on the Tomtom scores. This suggests that the matrix zthat SEISM identifies is close enough to
the PWM matrix of the true motif, but farther away than the matrices identified by STREME or MEME.
14Published in Transactions on Machine Learning Research (06/2023)
SEISM STREME MEME CKN020406080100Succes Rate (%) for a TOMTOM score >= 2
2 3 4 5 6 7 8 9 10
Motif  accuracy score (-log10 TOMTOM p-values)020406080100Succes Rate ( %)SEISM
STREME
MEME
CKN
Figure 4: Left: Proportion of datasets where the true motif was detected by the designated algorithm. A
true motif is said to be detected if its highest Tomtom score with the discovered motifs is greater than 2.
Right: Accuracy of motif discovery algorithms on ENCODE TF ChIP-seq datasets. The curves display the
proportion of ChIP-seq datasets were the best motif identified by the designated algorithm has a Tomtom
score greater than x.
This discrepancy reflects a different usage of zto parameterize a distribution of k-mers. In practice, we
observe that on a given dataset, the p-values of the best motifs discovered by SEISM and STREME are not
separated by more than 2 orders of magnitude, which leads to minor differences in the motifs, as illustrated
in Table 1.
Reference motif SEISM motif STREME motif
(ATF4_DBD) p-value = 10−6p-value = 3×10−8
012 bits
1ACGT
2CGA
3T
4GT
5TAG
6C
7GA
8AT
9TC
10A
11CGT
12TAC
13ATC
012 bits
1GA
2T
3GT
4AG
5C
6GA
7AT
8AC
9GTA
012 bits
1 2CGA
3T
4CGT
5TAG
6TC
7GA
8CT
9TAC
10TA
11GCT
Table 1: Comparison between two discovered sequence motifs by SEISM or STREME, and the true motif
(ATF4_DBD)
Both SEISM and MEME/STREME exploit a distribution of k-mers at the transcription factor binding site.
MEME and STREME maximize the likelihood of a categorical model , whereby the matrix zdirectly defines
the probability to observe each letter at each of the ksites:
∀/parenleftbig
u,z∈Z/parenrightbig
,Lcat(u;z) =k/productdisplay
i=1uT
izi (23)
SEISM on the other hand is based on a Gaussian model . Through representation (3), zis meant to maximize
the Gaussian likelihood of a set of k-mers,i.e.
∀/parenleftbig
u,z∈Z/parenrightbig
,Lgaus(u;z) =Ck/productdisplay
i=1e−∥ui−zi∥2
2ω2 (24)
whereCis a constant such that the sum of probabilities over R4×kequals 1. If we consider a binary yto
matchthesettingofMEME/STREME,thissetismadeofone k-merforeachpositivesequence. Importantly,
15Published in Transactions on Machine Learning Research (06/2023)
thetrueTFmotifsfrom(Jolmaetal.,2013)thatweusetoassessselectionaccuraciesarealsodefinedthrough
themaximumlikelihoodinacategoricalmodel, whichcanexplainwhythe zobtainedwithMEME/STREME
are closer to the true PWM than the one obtained with SEISM.
We now illustrate on a simple example how the same distribution of k-mers is parameterized by different
matrices under the two models. To build an easy example, we focus on k-mers of length 1, with
P(A) = 0.3, P(C) = 0.4, P(G) = 0.1, P(T) = 0.2 (25)
The matrixz1= (0.3,0.4,0.1,0.2)Tused with the categorical model trivially constructs such a distribution.
But using the same matrix in a Gaussian model with a parameter ωfixed as described in Appendix A leads
to a slightly different distribution:
P(A) = 0.28, P(C) = 0.43, P(G) = 0.11, P(T) = 0.18 (26)
A distribution closer to Equation (25) can be constructed with a Gaussian model parameterized by z2=
(0.315,0.38,0.08,0.225)T.
To clarify the relationships between those two motifs, we will rewrite (23) considering uis one hot encoded.
That is, for each position i, it has only one 1for letterj(i)and 0’s elsewhere:
∀/parenleftbig
u,z∈Z/parenrightbig
,Lcat(u;z) =k/productdisplay
i=1zi,j(i) (27)
Assuming that the columns of zare normalized and ω= 1, we can modify (24):
∀/parenleftbig
u,z∈Z/parenrightbig
,Lgaus(u;z) =Ck/productdisplay
i=1e−∥ui−zi∥2
2ω2=C2k/productdisplay
i=1euT
izi=C2k/productdisplay
i=1ezi,j(i) (28)
With the Gaussian model and a few assumptions, the motifs can the be seen as defining the log probability
to observe each letter at each of the ksites. This gives us a new interpretation for the filters learned by
CNNs and suggests that in this framework it might be interesting to constrain ezrather thanzto be inZ.
We used a Gaussian activation function since it is closer to typical CNNs approaches. Our framework
is generic enough to allow other activation functions based on the categorical model, or more realistic
variants (Ruan & Stormo, 2017).
5.2 Statistical validity and performances
InordertoassessthestatisticalvalidityandoftheSEISMprocedurewiththedifferentstrategies, wesimulate
datasets under the null hypothesis. To that end, we draw one sequence motif ˜zwith length k= 8for each
simulated dataset using a uniform distribution on Zrestricted to motifs with an information level fixed at
10bits. Then, we draw a set of n= 30biological sequences Xas follows: all sites are generated according
to a uniform distribution over A, C, T, G for all sequences, and for half of the sequences one k-mer is drawn
according to the categorical model parameterized by ˜z. The phenotypes yare drawn fromN(0,σ2Cn)to
generate data under the null hypothesis for calibration experiments, and from N(φ˜z,X,σ2Cn)to generate
data under the alternative for experiments on statistical power, with σ= 0.1in both cases. We then run
the SEISM procedure to select and test two sequence motifs. For both the data-split strategy and the
hypersphere direction sampling one, the distribution from which the replicates are drawn uses the empirical
variance from yas variance parameter. Although any choice for this parameter leads to a valid procedure,
as described in Section 4.6, we make this choice for numerical stability considerations. For the data-split
strategy, we sample 1000 replicates under the null hypothesis to compute the p-value. For SEISM, we sample
50,000replicates under the conditional null hypothesis using the hypersphere direction sampler, after 10,000
burn-in iterations.
Figure 5 (top) shows the Q-Q plot of the distribution of quantiles of the uniform distribution against the
p-values obtained across 1000 datasets under the null hypothesis for the data-split strategy and 100 datasets
16Published in Transactions on Machine Learning Research (06/2023)
for the hypersphere direction sampling one. All the data points are well-aligned with the diagonal, which
confirms the correct calibration of both the data-split and hypersphere direction sampling strategies, either
considering the best motif or the center of the mesh and regardless of the size parameter.
Figure 5 (bottom) shows the same Q-Q plot on data generated under the alternative hypothesis. From
this figure, we observe that on small datasets, the post-selection strategy is more powerful than the data-
split one, regardless of the size of the mesh considered or the choice concerning the definition of the null
hypothesis. The variance observed on the curves associated with the selective inference procedure is due to
the presence of a weak residual signal after the first motif as a result of an imperfect selection step. Testing
it with the best motif in the mesh captures this signal, resulting in curves under the diagonal. By contrast,
focusing on the center of the meshes leads to testing motifs that do not capture this signal, placing us in the
conservative situation, described at the end of Section 4.7. The residual signal is not well explained by the
mesh’s centers, and thus its component on the orthogonal of the span of the activation vector of the second
motif is important. The larger the mesh, the farther its center is to the selected motif and thus the less
signal it captures, which explains the differences between the two curves.
0.0 0.2 0.4 0.6 0.8 1.00.00.20.40.60.81.0
data-split
PSI best motif m=0.25
PSI center motif m=0.25
PSI best motif m=0.5
PSI center motif m=0.5
0.0 0.2 0.4 0.6 0.8 1.00.00.20.40.60.81.0
0.0 0.2 0.4 0.6 0.8 1.00.00.20.40.60.81.0
0.0 0.2 0.4 0.6 0.8 1.00.00.20.40.60.81.0
Empirical quantilesp-valuesCalibration PowerMotif 1 Motif 2
Figure 5: Q-Q plots obtained by applying data-split and different hit-and-run sampling strategies to select
two motifs and test their association with an outcome. Top: data simulated under the null hypothesis. The
proximity between the quantiles of the obtained p-values and those of the uniform distribution confirms that
all SEISM strategies presented in this article are correctly calibrated. Bottom : data simulated under an
alternative hypothesis, where the outcome depends on the activation φ˜z,Xof a single motif in the sequence.
The distributions of the p-values computed with the post-selection inference (PSI) strategies have a larger
deviation to the uniform distribution than the distributions of the p-values computed with the data-split
strategy (purple).
17Published in Transactions on Machine Learning Research (06/2023)
5.3 Computation costs
The section serves as an overview of how various user-specified parameters impact the computation time
required by the post-selection inference procedure.
As discussed in 4.6, the hit-and-run algorithm is actually a rejection sampler. Its overall computation cost
depends mainly on two characteristics: the cost of the selection step, that is the cost of selecting qmotifs
for a given phenotype y, and the acceptance rate. Although some parameters affect the selection cost, the
acceptance rate is primarily responsible for determining if a user-specified combination of parameters results
in a tractable configuration for the post-selection method in a reasonable amount of time. This rate is high
compared with a naive rejection sampler over E, as the hit-and-run strategy reduces the dimension over
which the rejection step is performed: from nwith a naive sampler to 1. Nonetheless some parameters may
have a major impact on the rejection rate. To clarify it, we studied in Figure 6 the impact of several user-
specified parameters — the number of motifs to be discovered, the precision of the meshes, the regularization
parameter of the ridge score and the number of computation cores allowed during the rejection step of the
hit-and-run sampler.
Although the number of motifs to be found by SEISM undoubtedly affects the selection cost, we can roughly
consider that this relationship is linear. The upper left figure in Figure 6, however, demonstrates that the
influence on the overall computing cost is superlinear, in line with the exponential growth of the number
of distinct selection events one may describe with a fixed mesh size. As a result, the post-selection process
quickly becomes intractable for discovering and test more than a few motifs.
We make a similar observation for mesh precision: computation time grows exponentially with the number of
bins used to define the meshing. This can be explained by the exponential relationship between the number
of bins and the number of different meshes (and thus the rejection rate). Of note, mesh precision has no
impact on the selection time, and therefore the computation time is entirely explained by the acceptance
rate.
We observe that the greater the regularization parameter λ, the lower the computation time. This can be
explained by detailing its impact on the rejection rate. To understand it, it is necessary to note that the
motifs are not selected over Z, but over a less constrained set as described in 3. They are only projected
ontoZat the end of the whole procedure, to ease their interpretation. The meshes are then defined over a
vectorial space, leading to an infinite number of meshes. Compared to a small regularization parameter, a
higherλfavors motifs resulting in a φz,Xwith a higher norm. With regard to the activation function, such
motifs are located closer from the k-mers, and thus from Z.λhas then no effect on the number of existing
meshes, but impacts the number of acceptable ones, in the sense that they have a reasonable probability to
be selected. A lower λleads to better selection performances, but to a higher number of acceptable meshes,
and thus to a lower acceptance rate. We empirically set λ= 0.01to provide a good trade-off.
Finally, the rejection sampling step can be parallelized over several computation cores, which accelerates the
whole procedure, as described in Section 4.4. As long as the acceptance rate is small enough, using jcores
to parallelize the rejection step should roughly divide the computation time by j.
We can clearly identify limitations inherent to the use of the selective inference procedure. Although it is
more powerful than the data-split approach, it can not be used in every situation. This latter approach does
indeed not include any rejection step, and the only factor influencing its overall computation time is the
selection time, only marginally influenced by the aforementioned parameters.
5.4 Using SEISM on empirical data
The experiments on simulated data that we present in Sections 5.2 and 5.3 are useful to analyse the cali-
bration, power and computational behavior of SEISM in a controlled environment where the ground truth
is known. Here we use an empirical dataset to evaluate two other critical aspects: the robustness of SEISM
to the Gaussian assumption, and its ability to select the correct number of filters. We rely on the ChIP-seq
dataset from Chatagnon et al. (2015). As part of this study, the authors investigate the mechanisms under-
lying cell differentiation and are particularly interested in the retinoic acid receptor (RAR), a transcription
18Published in Transactions on Machine Learning Research (06/2023)
1 2 3
Number of motifs to be selected025050075010001250150017502000time (s)
2 4 8
Number of bins for the meshing0500100015002000250030003500time (s)
0.01 0.1 1
Ridge regularization parameter lambda20304050time (s)
1 2 3 4
Number of threads102103time (s)
Figure 6: Impact of different parameters on the computation time for 100 replicates for the post-selection
inference procedure. Upper left: Impact of the number of motifs to be discovered Upper right: Impact
of the number of bins defining the meshes. Bottom left: Impact of the ridge regularization parameter.
Bottom right: (Log scale) Impact of the number of threads over which the hit-and-run sampling is paral-
lelized.
19Published in Transactions on Machine Learning Research (06/2023)
factor. They perform a ChIP-seq experiment, which leads to a dataset containing 131,895 sequences of length
500 and their associated phenotypes: the −log10ofp-values resulting from a test to determine whether the
sequence is associated with a high number of bindings with RAR. We then derive a smaller dataset contain-
ing only 1,000 sequences, enriched with sequences significantly associated with RAR, in order to increase
the signal to noise ratio and speed up the computations.
The Gaussian assumption is strongly challenged on classification labels, but can also be questioned for
continuous phenotypes. Although this problem is not limited to SEISM, we propose here an approach to
assess whether the Gaussian assumption is valid for a given dataset (X,y)for the SEISM procedure. This
method follows 3 steps:
1. CreateNdatasets (X,y(i))derived from the original one. The sequences are unchanged, but the
labels are randomly permuted versions of y. This permutation ensures that these new datasets are
under the null hypothesis, while maintaining the original probability distribution of y.
2. Run the whole SEISM procedure on each of those permuted datasets, and collect the p-values.
3. Draw a Q-Q plot: if the distribution is close to the uniform, then it validates the use of the Gaussian
model for this dataset.
Our analysis in Section 5.3 suggests that the selective inference version of SEISM would be too computa-
tionally intensive and would bring little improvement compared to the data-split version on this dataset,
and we therefore apply the above procedure with data-split. We use the ridge association score with a
penlaty paramter λ= 0.1. The resulting empirical distribution of the labels is far from a Gaussian one
(see Figure 7), but the p-values obtained on the permuted datasets with the aforementioned methodology
are uniformly distributed between 0 and 1, as shown in Figure 8, which validates the use of SEISM on this
particular dataset.
Phenotypes
Figure 7: Empirical probability density of the phenotypes in Chatagnon et al. (2015).
We then select and test four motifs using the same data-split version of SEISM on the non-permuted dataset.
The resulting motifs are represented in Table 2 with their respective p-values.
The first motif found— the one with the lowest p-value—recovers a known motif for RAR (Balmer &
Blomhoff, 2005), see Figure 9. On the other hand, only the first discovered motif is associated with a
significantp-value, aligning with the current literature for RAR. This confirms the capability of SEISM to
infer a posterior the right number of feature in the model.
20Published in Transactions on Machine Learning Research (06/2023)
0.0 0.2 0.4 0.6 0.8 1.0
empirical quantiles0.00.20.40.60.81.0pvaluesdata-split
Figure 8: Q-Q plot obtained by applying the SEISM procedure to permuted versions of Chatagnon et al.
(2015).
Motif 1p= 10−3Motif 2p= 0.013
Motif 3p= 0.47 Motif 4p= 0.23
Table 2: Motifs and p-values obtained with SEISM on the dataset from Chatagnon et al. (2015).
6 Discussion and future works
We have introduced a procedure to test the association between features learned by a neural network and
the outcome predicted by this network. We did so by relying on the post-selection inference framework and
formalizing the network training as a feature selection step. Along the way, we addressed general problems
related to selective inference over composite hypotheses, which has implications beyond testing of features
extracted by trained neural networks. In particular to our knowledge, all previous procedures had to work
under the assumption that the variance was known. Our strategy to normalize the statistic to make it
scale-free could easily be transferred to kernelPSI for testing the association of kernels with a trait, or to
previous selective inference frameworks for testing groups of variables using sampling strategies (Slim et al.,
2019; Reid et al., 2018).
From a neural network perspective, SEISM provides a principled way to select the number of filters of
a CNN, with a different objective—significance—than the usual prediction-oriented cross-validation pro-
1 2 3 4 5 6012bits
Figure 9: Known binding motif for RAR (Balmer & Blomhoff, 2005).
21Published in Transactions on Machine Learning Research (06/2023)
cedures. Through the SEISM procedure, we are also drawing connections between neural networks for
biological sequences and two related fields: sequence motif detection, and GWAS.
Sequence motif detection has been a major theme in bioinformatics for the past 30 years and many methods
have been proposed to identify motifs that are over-represented in a set of sequence compared to some control
class or background distribution. The earliest CNNs for regulatory genomics Alipanahi et al. (2015); Zhou
& Troyanskaya (2015) already exploited the fact that trained convolution filters of the first layer could be
interpreted as PWMs, and more recent work have sought to extract PWMs from entire multi-layer trained
networks through attribution methods. The selection step of our procedure merely formalizes that training
a one-layer CNN is equivalent to selecting a finite set of PWMs that have a maximal association to the
outcome for some particular score. This formalization also highlights the specific way by which CNNs with
exponential activation functions parameterize the distribution of k-mers at a binding site. Although the
PWM returned by most bioinformatics models represents a categorical distribution—probability to draw
each letter at each site, trained convolution matrices parameterize a Gaussian distribution. In practice, this
difference leads to discrepancies between the trained convolution filters and PWMs learned using categorical
likelihoods—including those offered by databases and often used as ground truth. This observation also
suggests alternative sets of constraints for convolution filters— e.g., each column of the pointwise exponential
of the filter should belong to the simplex.
By providing an inference procedure for features extracted by the trained model, our work also connects
neural networks for genomic sequences to GWAS. The good predictive performances of these neural networks
is often explained by their ability to jointly learn an appropriate data representation and a regular prediction
function acting on this representation. Nonetheless, the space from which these representations are learned is
seldom formalized and to our knowledge the association of the extracted features with the predicted outcome
is never tested. GWAS on the other hand relies on hypothesis testing, but commonly relies on relatively
simple genomic variants such as single nucleotide polymorphisms (SNPs) or k-mer presence (Jaillard et al.,
2018; Roux de Bézieux et al., 2022). Our framework paves the way to GWAS over richer sets of variants, e.g.
capturing the presence of entire polymorphic genes through large convolution filters, or the interaction of
simpler variants through multilayer or self-attention networks (Avsec et al., 2021a). This will require scaling
to entire genomes as inputs, and making more complex networks, such as multi-layer CNNs and networks
using attention mechanisms, amenable to inference. The most important step in achieving this goal is to
formulate the training of these networks as a feature selection problem and formalize the association between
these features and the phenotype. The inference framework might then be directly derived from this present
work. For instance, we may test motif interactions derived from convolutional-attention networks (Ullah &
Ben-Hur, 2021), or a (motif, position) couple as selected in (Ditz et al., 2022). Regarding multi-layer CNNs,
several strategies are conceivable. One solution would be to build on TFModISco, that aims at extracting
motifssummarizingthefeaturescapturedbyatrainedmulti-layerCNN(inparticular, accountingforpossible
interactions). These extracted motifs could be tested using the SEISM framework: the selection event is the
set of simulated phenotypes that would lead to the construction of TFModISco motifs (Shrikumar et al.,
2018) within the same meshes. Of note in this strategy, the motifs would not be selected using the same
score used as a statistic for testing, but this is not an issue. A second, more integrated possibility would
be to test the filters of the first layer within a deeper network. Deeper layers indeed model interactions
between the motifs, and with such an architecture the filters of the first layer would then be optimized
while taking into account those interactions. The selection procedure would still be a greedy one, and the
architecture of the network would vary from step to step: the first layer would contain more and more filters,
but the previously entered filters would be fixed. This selection procedure could then be translated into a
selection event, and the inference framework could then be applied accordingly. Finally, we could test the
deeper features themselves, but this would only make sense for an appropriate architecture that makes these
features interpretable. A simple option would be, for example, to apply a global (or large enough) pooling
over a first layer with few filters, and test filters of the second layer that would represent motif combinations.
Alternatively, the second layer could be an even simpler set of pairwise interactions between motifs ( i.e.,
special filters with only two non-zero entries). In practice, this could be done by optimizing the residual
errors for the successive filters of this second layer. Admittedly, a few practical problems may arise. First,
the hit-and-run sampler requires the selection method to be stable, that is, running the selection method
twice on the same input will lead to the same selection on features. This property is required to guarantee the
22Published in Transactions on Machine Learning Research (06/2023)
theoretical convergence of the the algorithm but may not be necessary in practice. Second, some attention
may be required to avoid the that computational cost become prohibitive, in particular depending on the
regularity properties of the selection event leading to a higher rejection probability or to a higher number
of replicates required. Granted that these technical challenges can be addressed, we are confident that
extending SEISM to more general networks and corresponding features will benefit both the fields currently
using these networks—such as regulatory genomics—and GWAS.
23Published in Transactions on Machine Learning Research (06/2023)
7 Acknowledgements
This work has been supported by ANR grants (FAST-BIG project ANR-17-CE23-0011-01 and PIECES
project ANR-20-CE45-0017) and was performed using the computation facilities of the LBBE/PRABI.
We thank François Gindraud, Jean-Philippe Rasigade, Lotfi Slim and Dexiong Chen for the insightful dis-
cussions and support.
References
Babak Alipanahi, Andrew Delong, Matthew T. Weirauch, and Brendan J. Frey. Predicting the sequence
specificities of DNA- and RNA-binding proteins by deep learning. Nature Biotechnology , 33(8):831–838,
July 2015. ISSN 1087-0156. doi: 10.1038/nbt.3300. URL http://dx.doi.org/10.1038/nbt.3300 .
Luigi Ambrosio, Nicola Gigli, and Giuseppe Savaré. Gradient flows: in metric spaces and in the space of
probability measures . Springer Science & Business Media, 2005.
Žiga Avsec, Vikram Agarwal, Daniel Visentin, Joseph R. Ledsam, Agnieszka Grabska-Barwinska, Kyle R.
Taylor, Yannis Assael, John Jumper, Pushmeet Kohli, and David R. Kelley. Effective gene expres-
sion prediction from sequence by integrating long-range interactions. Nature Methods , 18(10):1196–
1203, Oct 2021a. ISSN 1548-7105. doi: 10.1038/s41592-021-01252-x. URL https://doi.org/10.1038/
s41592-021-01252-x .
Žiga Avsec, Melanie Weilert, Avanti Shrikumar, Sabrina Krueger, Amr Alexandari, Khyati Dalal, Robin
Fropf, Charles McAnany, Julien Gagneur, Anshul Kundaje, and Julia Zeitlinger. Base-resolution models
of transcription-factor binding reveal soft motif syntax. Nat Genet , 53(3):354–366, February 2021b.
Timothy L Bailey. STREME: accurate and versatile sequence motif discovery. 37(18):2834–2840, 2021.
ISSN 1367-4803, 1460-2059. doi: 10.1093/bioinformatics/btab203. URL https://academic.oup.com/
bioinformatics/article/37/18/2834/6184861 .
Timothy L. Bailey, Nadya Williams, Chris Misleh, and Wilfred W. Li. MEME: discovering and analyzing
DNA and protein sequence motifs. 34:W369–W373, 2006. ISSN 0305-1048. doi: 10.1093/nar/gkl198. URL
https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1538909/ .
J. E. Balmer and R. Blomhoff. A robust characterization of retinoic acid response elements based on a
comparison of sites in three species. The Journal of Steroid Biochemistry and Molecular Biology , 96(5):
347–354, September 2005. ISSN 0960-0760. doi: 10.1016/j.jsbmb.2005.05.005.
Leon Bungert and Philipp Wacker. The lion in the attic – a resolution of the borel–kolmogorov paradox,
2022. URL http://arxiv.org/abs/2009.04778 .
Amandine Chatagnon, Philippe Veber, Valérie Morin, Justin Bedo, Gérard Triqueneaux, Marie Sémon,
Vincent Laudet, Florence d’Alché Buc, and Gérard Benoit. RAR/RXR binding dynamics distinguish
pluripotency from differentiation associated cis-regulatory elements. Nucleic Acids Research , 43(10):4833–
4854, May 2015. ISSN 1362-4962. doi: 10.1093/nar/gkv370.
Dexiong Chen, Laurent Jacob, and Julien Mairal. Biological sequence modeling with convolutional kernel
networks. 2017. doi: 10.1101/217257. URL http://biorxiv.org/lookup/doi/10.1101/217257 .
Jonas C. Ditz, Bernhard Reuter, and Nico Pfeifer. Convolutional motif kernel networks, 2022. URL http:
//arxiv.org/abs/2111.02272 .
ENCODE Project Consortium. The ENCODE (ENCyclopedia of DNA elements) project. 306(5696):636–
640, 2004. ISSN 1095-9203. doi: 10.1126/science.1105136.
Shobhit Gupta, John A. Stamatoyannopoulos, Timothy L. Bailey, and William Stafford Noble. Quantifying
similarity between motifs. 8(2):R24, 2007. ISSN 1474-760X. doi: 10.1186/gb-2007-8-2-r24. URL https:
//doi.org/10.1186/gb-2007-8-2-r24 .
24Published in Transactions on Machine Learning Research (06/2023)
R Harr, M Häggström, and P Gustafsson. Search algorithm for pattern match analysis of nucleic acid
sequences. Nucleic Acids Res , 11(9):2943–2957, May 1983.
Trevor Hastie, Robert Tibshirani, and Martin Wainwright. Statistical learning with sparsity. Monographs
on statistics and applied probability , 143:143, 2015.
Magali Jaillard, Leandro Lima, Maud Tournoud, Pierre Mahé, Alex van Belkum, Vincent Lacroix, and
Laurent Jacob. A fast and agnostic method for bacterial genome-wide association studies: Bridging the
gap between k-mers and genetic events. PLOS Genetics , 14(11):1–28, 11 2018. doi: 10.1371/journal.pgen.
1007758. URL https://doi.org/10.1371/journal.pgen.1007758 .
Arttu Jolma, Jian Yan, Thomas Whitington, Jarkko Toivonen, Kazuhiro R. Nitta, Pasi Rastas, Ekaterina
Morgunova, Martin Enge, Mikko Taipale, Gonghong Wei, Kimmo Palin, Juan M. Vaquerizas, Renaud
Vincentelli, Nicholas M. Luscombe, Timothy R. Hughes, Patrick Lemaire, Esko Ukkonen, Teemu Kivioja,
and Jussi Taipale. DNA-binding specificities of human transcription factors. 152(1):327–339, 2013. ISSN
00928674. doi: 10.1016/j.cell.2012.12.009. URL https://linkinghub.elsevier.com/retrieve/pii/
S0092867412014961 .
David R Kelley, Yakir A Reshef, Maxwell Bileschi, David Belanger, Cory Y McLean, and Jasper Snoek.
Sequential regulatory activity prediction across chromosomes with convolutional neural networks. Genome
Res, 28(5):739–750, March 2018.
Peter K. Koo and Sean R. Eddy. Representation learning of genomic sequence motifs with convolutional
neural networks. 15(12):e1007560, 2019. ISSN 1553-7358. doi: 10.1371/journal.pcbi.1007560. URL
https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1007560 . Publisher:
Public Library of Science.
Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classification with deep convolutional
neural networks. In F. Pereira, C.J. Burges, L. Bottou, and K.Q. Weinberger (eds.), Advances in Neural
Information Processing Systems , volume 25. Curran Associates, Inc., 2012. URL https://proceedings.
neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf .
Yann LeCun and Yoshua Bengio. Convolutional Networks for Images, Speech, and Time Series , pp. 255–258.
MIT Press, Cambridge, MA, USA, 1998. ISBN 0262511029.
Jason D. Lee, Dennis L. Sun, Yuekai Sun, and Jonathan E. Taylor. Exact post-selection inference, with
application to the lasso. 44(3):907–927, 2016. ISSN 0090-5364. doi: 10.1214/15-AOS1371. URL http:
//arxiv.org/abs/1311.6238 .
M.A. Lifshits. On the absolute continuity of distributions of functionals of random processes. Theory of
Probability & Its Applications , 27(3):600–607, 1983.
Joshua R. Loftus and Jonathan E. Taylor. Selective inference in regression models with groups of variables.
arXiv e-prints , art. arXiv:1511.01478, November 2015.
Christoph Molnar. Interpretable Machine Learning . 2 edition, 2022. URL https://christophm.github.
io/interpretable-ml-book .
Gherman Novakovsky, Nick Dexter, Maxwell W. Libbrecht, Wyeth W. Wasserman, and Sara Mostafavi.
Obtaining genetics insights from deep learning via explainable artificial intelligence. Nature Reviews
Genetics , Oct 2022. ISSN 1471-0064. doi: 10.1038/s41576-022-00532-2. URL https://doi.org/10.
1038/s41576-022-00532-2 .
Gabrielle Ras, Ning Xie, Marcel van Gerven, and Derek Doran. Explainable deep learning: A field guide
for the uninitiated. J. Artif. Int. Res. , 73, may 2022. ISSN 1076-9757. doi: 10.1613/jair.1.13200. URL
https://doi.org/10.1613/jair.1.13200 .
Stephen Reid and Robert Tibshirani. Sparse regression and marginal testing using cluster prototypes. 2013.
URL http://arxiv.org/abs/1503.00334 .
25Published in Transactions on Machine Learning Research (06/2023)
Stephen Reid, Jonathan Taylor, and Robert Tibshirani. A general framework for estimation and inference
from clusters of features. 2015. URL http://arxiv.org/abs/1511.07839 .
Stephen Reid, Jonathan Taylor, and Robert Tibshirani. A general framework for estimation and inference
from clusters of features. Journal of the American Statistical Association , 113(521):280–293, 2018. doi:
10.1080/01621459.2016.1246368. URL https://doi.org/10.1080/01621459.2016.1246368 .
Guillaume Rizk, Dominique Lavenier, and Rayan Chikhi. DSK: k-mer counting with very low memory usage.
29(5):652–653, 2013. ISSN 1367-4811. doi: 10.1093/bioinformatics/btt020.
Hector Roux de Bézieux, Leandro Lima, Fanny Perraudeau, Arnaud Mary, Sandrine Dudoit, and Laurent
Jacob. CALDERA: finding all significant de Bruijn subgraphs for bacterial GWAS. Bioinformatics , 38:
i36–i44, 06 2022. ISSN 1367-4803. doi: 10.1093/bioinformatics/btac238. URL https://doi.org/10.
1093/bioinformatics/btac238 .
Shuxiang Ruan and Gary D. Stormo. Inherent limitations of probabilistic models for protein-DNA binding
specificity. 13(7):e1005638, 2017. ISSN 1553-7358. doi: 10.1371/journal.pcbi.1005638. URL https:
//journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005638 . Publisher: Public
Library of Science.
T D Schneider and R M Stephens. Sequence logos: a new way to display consensus sequences. Nucleic Acids
Res, 18(20):6097–6100, October 1990.
Avanti Shrikumar, Katherine Tian, Žiga Avsec, Anna Shcherbina, Abhimanyu Banerjee, Mahfuza Sharmin,
Surag Nair, and Anshul Kundaje. Technical note on transcription factor motif discovery from importance
scores (tf-modisco) version 0.5.6.5, 2018. URL https://arxiv.org/abs/1811.00416 .
Lotfi Slim, Clément Chatelain, Chloe-Agathe Azencott, and Jean-Philippe Vert. kernelPSI: a post-selection
inference framework for nonlinear variable selection. In Kamalika Chaudhuri and Ruslan Salakhutdinov
(eds.),Proceedings of the 36th International Conference on Machine Learning , volume 97 of Proceedings of
Machine Learning Research , pp. 5857–5865. PMLR, 09–15 Jun 2019. URL https://proceedings.mlr.
press/v97/slim19a.html .
Mahdi Soltanolkotabi, Adel Javanmard, and Jason D. Lee. Theoretical insights into the optimization land-
scape of over-parameterized shallow neural networks. IEEE Transactions on Information Theory , 65(2):
742–769, 2019. doi: 10.1109/TIT.2018.2854560.
LeSong, AlexSmola, ArthurGretton, JustinBedo, andKarstenBorgwardt. Featureselectionviadependence
maximization. Journal of Machine Learning Research , 13(47):1393–1434, 2012. URL http://jmlr.org/
papers/v13/song12a.html .
Jonathan Taylor and Robert J. Tibshirani. Statistical learning and selective inference. Proceedings of the
National Academy of Sciences , 112(25):7629–7634, 2015. doi: 10.1073/pnas.1507583112. URL https:
//www.pnas.org/doi/abs/10.1073/pnas.1507583112 .
JonathanTaylor,RichardLockhart,RobertTibshirani,andRyanJTibshirani. Exactpost-selectioninference
for forward stepwise and least angle regression. pp. 32, 2014.
V.S. Tsirelson. The density of the distribution of the maximum of a gaussian process. Theory of Probability
& Its Applications , 20(4):847–856, 1976.
FahadUllahandAsaBen-Hur. Aself-attentionmodelforinferringcooperativitybetweenregulatoryfeatures.
49(13):e77, 2021. ISSN 0305-1048. doi: 10.1093/nar/gkab349. URL https://doi.org/10.1093/nar/
gkab349.
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser,
and Illia Polosukhin. Attention is all you need. Advances in neural information processing systems , 30,
2017.
26Published in Transactions on Machine Learning Research (06/2023)
P M Visscher, N R Wray, Q Zhang, P Sklar, M I McCarthy, M A Brown, and J Yang. 10 years of
GWAS discovery: Biology, function, and translation. Am J Hum Genet , 101(1):5–22, July 2017. doi:
10.1016/j.ajhg.2017.06.005. URL https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5501872/ .
Larry Wasserman and Kathryn Roeder. High-dimensional variable selection. 37(5):2178–2201, 2009. ISSN
0090-5364, 2168-8966. doi: 10.1214/08-AOS646. Publisher: Institute of Mathematical Statistics.
Ronald L. Wasserstein and Nicole A. Lazar. The ASA statement on p-values: Context, process, and purpose.
The American Statistician ,70(2):129–133,2016. doi: 10.1080/00031305.2016.1154108. URL https://doi.
org/10.1080/00031305.2016.1154108 .
Makoto Yamada, Yuta Umezu, Kenji Fukumizu, and Ichiro Takeuchi. Post selection inference with kernels.
2018.
Jian Zhou and Olga G Troyanskaya. Predicting effects of noncoding variants with deep learning-based
sequence model. Nat Methods , 12:931–4, 2015 Oct 2015. ISSN 1548-7105. doi: 10.1038/nmeth.3547.
27Published in Transactions on Machine Learning Research (06/2023)
Supplemental Materials of “Neural Networks beyond explainability: Selective
inference for sequence motifs"
A Tuning the activation bandwidth hyperparameter
The data representation φZ,Xdepends on a hyperparameter ωcontrolling the bandwidth of the gaussian
non-linearity (Equation 3): exp/parenleftig
−||zj−u||2
2ω2/parenrightig
. Assuming that the positions are independant, we know that
the expected value of the distance between a motif zand ak-meruwith length kis proportional to k.
In order to get an activation that does not depend on the length of the motifs, we simply set ωto be
proportional to√
k. From empirical tests, we set ω=√
0.9∗k
2to achieve good selection results by choosing
the motif that maximizes the association score among a set of possible lengths.
B Disintegration of the selection event given by sequence motifs
In this section we consider the selection event:
Econt.(Z) :=/braceleftig
y′∈E,∀i∈{1,...,q}arg max
z∈Zs(z,Piy′) =zi/bracerightig
, (S1)
given by the sequence of selected motifs Z= (z1,...,zq). We denote by µthe law ofyas given by Eq. (9),
a Gaussian distribution on E.
A first remark on the uniqueness of the selection
Consider the mapping π:E→Zqgiven byπ(y′) =ZwhereZ= (z1,...,zq)is the sequence of motifs
such thaty′∈Econt.(Z). It is not clear that πis well defined as a same y′may lead to the selection of at
least two different motifs sequences ZandZ′. As a first remark, we can see that the set of problematic y′
is exactly
P:=/uniondisplay
Z̸=Z′Econt.(Z)∩Econt.(Z′).
When one assumes that Z= (z1,...,zq)is unique, one implicitly assumes that µ(P) = 0. For sufficiently
regular scores, this is however the case. For sake of readability, we will not comprehensively study this issue
but we will present an argument for the scores sHSICandsridge. In this case, we can circumvent this difficulty
considering the Gaussian random field
z∝⇕⊣√∫⊔≀→⟨φz,X,y⟩for (HSIC) and z∝⇕⊣√∫⊔≀→⟨/parenleftbig
∥φz,X∥2+λn/parenrightbig−1/2φz,X,y⟩for (Ridge)
indexed byZwhereyis distributed with respect to a multivariate Gaussian distribution Eq. (9). Its
autocovariance function is given by (z,z′)∝⇕⊣√∫⊔≀→σ2⟨φz,X,φz′,X⟩from Eq. (9) (one has to multiply by/parenleftbig
∥φz,X∥2+λn/parenrightbig−1/2/parenleftbig
∥φz′,X∥2+λn/parenrightbig−1/2for the Ridge). The score is just the largest norm of this Gaussian
random field. It is well established in theory of Gaussian random fields that the law of this maximum is
regular and the argument maximum is unique. The interested reader may consult the pioneering work of
Tsirelson (Tsirelson, 1976) and Lifshits (Lifshits, 1983). In Tsirelson’s theorem, the parameter set is count-
able. This says that the same result holds true for separable bounded Gaussian processes, since in this case,
the distribution of the supremum coincides a.s. with the one of the supremum on some countable nonrandom
set. To avoid a cumbersome presentation, we will assume that almost surely the selected sequence motifs
Z= (z1,...,zq)is uniquely defined, hence πis well defined.
1Published in Transactions on Machine Learning Research (06/2023)
The disintegration steps
To sample conditionally on (S1), one need to consider the conditional law with respect to this event. We will
denote this law by µZ, it depends only on µ,Zandπ. This law is described by the theorem of disintegration,
see for instance (Ambrosio et al., 2005, Theorem 5.3.1). Denote νthe pushforward measure of µbyπ,
denoted by ν=π#µ, a probability measure on the set ZqofZ. By the disintegration theorem, there
exists aν-almost everywhere uniquely determined Borel family of probability measures µZ(the though-after
conditional distributions) such that
•Supported by Econt.(Z):µZ/braceleftbig
E\π−1(Z)/bracerightbig
= 0forν-almost every Z;
•Expectation of the conditional expectation is the expectation: It holds that, for every Borel
test mapf:E→ [0,+∞],/integraldisplay
Efdµ=/integraldisplay
Zq/parenleftig/integraldisplay
π−1(Z)fdµZ/parenrightig
dν(Z), (S2)
where one can remark that π−1(Z) =Econt.(Z)by definition of π. Let us comment on this result regarding
our purposes. First, we have mentioned that we known that the support Econt.(Z)is included in some
subspace, sayS, defined by the first order conditions. Second, although one can use a rejection sampling
strategy on the subspace Sto draw points on the support Econt.(Z)(viewed as a subset of the same Hausdorff
dimension as the subspace S), it is not clear at all what should be the density of µZ. Indeed, the family of
probability measures µZis the unique family that satisfies Eq. (S2). It implies that a measure µZdepends
on the others measures µZ′and this dependency is geometrically given by the (piece-wise) topological sub-
manifold given by the function z∝⇕⊣√∫⊔≀→φz,XfromZtoE.
From a practical view point, we tried various law for µZsuch as the uniform, or a rejection sampling based
on the Gaussian distribution (9), but none of them matched the condition (S2). In the next subsection, we
recall a toy example: the disintegration of the uniform measure on the sphere is not the uniform measure.
Even in this simple geometrical example, the calculus of the conditional law might be seen as tedious. We
believe that the calculus of µZis somehow out of reach for our purposes and our analysis with selection
events defined by meshes more suited.
A toy example on the sphere
LetSbe the 2-sphere embedded in the 3-Euclidean space. Let µbe the uniform measure on the sphere S. Let
{Sθ:θ∈[0,π)}be a family of sub-spaces of co-dimension 1(hyper-planes) sharing Span{(0,0,1)}(say the
north pole) as a revolution axis parameterized by θ. The parameter θcan be interpreted as the longitude.
Figure S1: For θ= 0,Sθis the light red plan, the conditional measure dµ0(ϕ)is depicted with a red area
and is proportional to |sin(ϕ)|, which is not the uniform measure.
2Published in Transactions on Machine Learning Research (06/2023)
Let¯πbe the function that maps a point to its longitude modulo π. By spherical symmetries, the pushforward
measureν= ¯π#µis the uniform measure on [0,π), so that dν(θ) = (1/π)dθ. Condition (S2) (the lhs of the
equality below) is given by the coordinate integration system (the rhs) in:
/integraldisplay
Sfdµ=/integraldisplayπ
0/parenleftig/integraldisplay
¯π−1(θ)fdµθ/parenrightig
dν(θ) =/integraldisplayπ
0/parenleftig/integraldisplay2π
0f(θ,ϕ)|sinϕ|
4πdϕ/parenrightig
dθ,
whereϕis the latitude. Note that ¯π−1(θ) =S∩Sθand it is in bijection with [0,2π)using the mapping that to
a point maps its latitude. Using this representation, it is not hard to see that the uniform measure on ¯π−1(θ)
is given by (1/2π)1[0,2π)(ϕ)while the above equality shows that the conditional measure µθof the uniform
measure on the sphere has density (1/4)|sinϕ|1[0,2π)(ϕ), see Figure S1. It proves that the disintegration of
the uniform measure on the sphere is not the uniform measure, but rather a distribution that will put few
mass around the poles and large mass around the equator.
C Proof of Proposition 4.4
Consider the orthogonal decompositon
E=R⊕S⊕T
whereRis the span of φZ,X,Tis the span of µ(orthogonal toRby Proposition 4.1), and Ssuch that the
equality holds. Consider y∈Eand its othogonal decomposition y=r+s+tewheree=µ/∥µ∥2is a unit
norm vector that spans T. Letτ >0and note that it is enough to prove that
Pµ/braceleftigs(Z,Y)
∥Y∥2≤τ/bracerightig
≥P0/braceleftigs(Z,Y)
∥Y∥2≤τ/bracerightig
,
whereYis a random variable with the same distribution as µ+σϵ(resp.σϵ) on the probability space
defined by Pµ(resp. P0). Not that the event decomposed as
/braceleftig
y:s(Z,y)
∥y∥2≤τ/bracerightig
=/braceleftig
(t,r,s) :s(Z,r)≤τ(t2∥µ∥2+∥r∥2+∥s∥2)/bracerightig
By othogonality, note that Lµ(r,s) =L0(r,s)and this law is a centered Gaussian multivariate law. We
deduce that the aforementioned probabilities are of the form
Pµ/braceleftigs(Z,Y)
∥Y∥2≤τ/bracerightig
=/integraldisplay∞
0w0(t)φµ(t)dt
where
w0(t) =P0/braceleftig
s(Z,r)≤τ(t2∥µ∥2+∥r∥2+∥s∥2)/bracerightig
φµ(t) = exp/parenleftbig
−(t−µe)2/2/parenrightbig
+ exp/parenleftbig
−(t+µe)2/2/parenrightbig
withµe=⟨e,µ⟩=∥µ∥2. Note that w0: (0,∞)→(0,1)is an increasing continuous function. It is an
increasing homeomorphism and the Fubini’s equality yields
Pµ/braceleftigs(Z,Y)
∥Y∥2≤τ/bracerightig
=/integraldisplay∞
0w0(t)φµ(t)dt
=/integraldisplay∞
0/integraldisplay1
01{u≤w0(t)}duφµ(t)dt
=/integraldisplay∞
0/integraldisplay1
01{w−1
0(u)≤t}duφµ(t)dt
=/integraldisplay1
0/integraldisplay∞
w−1
0(u)φµ(t)dtdu
3Published in Transactions on Machine Learning Research (06/2023)
By Anderson’s theorem, the measure of the interval [−w−1
0(u),w−1
0(u)]for the centered Gaussian density is
greater than the one for a non-centered Gaussian density with the same variance. As a result, we deduce
that /integraldisplay∞
w−1
0(u)φµ(t)dt≥/integraldisplay∞
w−1
0(u)φ0(t)dt,
which achieves the proof.
4