Published in Transactions on Machine Learning Research (02/2024)
Multitask Learning Can Improve Worst-Group Outcomes
Atharva Kulkarni∗atharvak@cs.cmu.edu
Language Technologies Institute, School of Computer Science
Carnegie Mellon University
Lucio M. Dery∗ldery@cs.cmu.edu
Computer Science Department, School of Computer Science
Carnegie Mellon University
Amrith Setlur asetlur@cs.cmu.edu
Machine Learning Department, School of Computer Science
Carnegie Mellon University
Aditi Raghunathan raditi@cs.cmu.edu
Computer Science Department, School of Computer Science
Carnegie Mellon University
Ameet Talwalkar atalwalk@cs.cmu.edu
Machine Learning Department, School of Computer Science
Carnegie Mellon University
Graham Neubig gneubig@cs.cmu.edu
Language Technologies Institute, School of Computer Science
Carnegie Mellon University
Reviewed on OpenReview: https: // openreview. net/ forum? id= sPlhAIp6mk
Abstract
In order to create machine learning systems that serve a variety of users well, it is vital
to not only achieve high average performance but also ensure equitable outcomes across
diverse groups. However, most machine learning methods are designed to improve a model’s
average performance on a chosen end task without consideration for their impact on worst
group error. Multitask learning (MTL) is one such widely used technique. In this paper,
we seek not only to understand the impact of MTL on worst-group accuracy but also to
explore its potential as a tool to address the challenge of group-wise fairness. We primarily
consider the standard setting of fine-tuning a pre-trained model, where, following recent
work (Gururangan et al., 2020; Dery et al., 2023), we multitask the end task with the pre-
training objective constructed from the end task data itself. In settings with few or no
group annotations, we find that multitasking often, but not consistently, achieves better
worst-group accuracy than Just-Train-Twice (JTT; Liu et al. (2021)) – a representative
distributionally robust optimization (DRO) method. Leveraging insights from synthetic
data experiments, we propose to modify standard MTL by regularizing the joint multitask
representation space. We run a large number of fine-tuning experiments across computer
visionand naturallanguage processing datasetsand findthat ourregularizedMTL approach
consistently outperforms JTT on both average and worst-group outcomes. Our official code
can be found here: https://github.com/atharvajk98/MTL-group-robustness .
*Equal contribution.
1Published in Transactions on Machine Learning Research (02/2024)
1 Introduction
As machine learning systems exert ever-increasing influence on the real world, it is paramount that they not
only perform well on aggregate but also exhibit equitable outcomes across diverse subgroups characterized
by attributes like race (Buolamwini & Gebru, 2018; Liang et al., 2021), gender (Buolamwini & Gebru, 2018;
Srinivasan & Bisk, 2022) and geographic location (Jurgens et al., 2017; De Vries et al., 2019; Ayush et al.,
2021). Therefore, it is important to understand the impact of widely-used machine learning techniques with
respecttothesedesiderata. Multitasklearning(MTL)(Caruana,1997;Baxter,2000;Ruderetal.,2019;Dery
et al., 2021a) is one example of such a technique that features prominently in machine learning practitioners’
toolbox for improving a model’s aggregate performance. However, the effect of multitask learning on worst
group outcomes is underexplored. In this paper, we both study the impact of MTL, as is, on worst group
error and also consider whether modifications can be made to improve its effect on worst group outcomes.
Traditionally, the problem of worst-group generalization has been tackled explicitly via methods such as
distributionallyrobustoptimization(DRO)(Ben-Taletal.,2013;Duchi&Namkoong,2018;Hashimotoetal.,
2018; Sagawa et al., 2020a). In contrast to traditional empirical risk minimization, DRO aims to minimize
the worst-case risk over a predefined set of distributions (the uncertainty set ). Defining the uncertainty set
usually (but not always) requires access to group annotations. Since average performance based approaches
like MTL are typically designed without consideration of group annotations, our focus will be on settings
with limited-to-no group annotations. In these settings, there exist a number of generalized Reweighting
(GRW)algorithms for distributional robustness (Nam et al., 2020; Liu et al., 2021; Zhang et al., 2022; Nam
et al., 2022; Qiu et al., 2023; Zhai et al., 2023; Izmailov et al., 2022). These approaches minimize the weighted
average risk based on the weight assigned to each example. One such widely used method is the Just-Train-
Twice (JTT) algorithm (Liu et al., 2021), which performs two model training runs: one to identify poorly
performing examples and another run that upweights these examples. For our empirical explorations, we
take JTT as a representative DRO method and use it to provide reference performance to situate our study
of multitask learning.
Table 1: Standard multitasking improves worst
group outcomes over ERM and JTT but not
consistently . Experimental details can be found
in Section A.1.
Dataset MethodNo Group Labels Val Group Labels
Worst-Group Acc Worst-Group Acc
WaterbirdsERM 80.14.6 85.41.4
JTT 82.11.2 85.92.5
(MTL) ERM+MIM 80.14.6 85.32.4
Civil-SmallERM 51.65.6 67.42.1
JTT 52.55.2 68.01.8
(MTL) ERM+MLM 58.36.6 68.50.4We focus our investigations of multitask learning on the
ubiquitous setting of fine-tuning a pre-trained model.
Here, a common way to improve end task average
performance is to multitask the end task with the pre-
training objective constructed over the task data itself
(Gururangan et al., 2020; Dery et al., 2021b). We
intuit that this multitasking approach could improve
robustness to worst group outcomes since previous work
like Hendrycks et al. (2019; 2020); Mao et al. (2020)
has established a favorable connection between pre-
training and robustness (both adversarial and out-of-
distribution). We test our intuition by conducting
preliminaryexperimentsacrossapairofcomputervisionandnaturallanguagetasksintwosettings: onewith
limited group annotations and the other with none. Initial results (Table 1) reveal that multitasking shows
promise in that it can improve worst group outcomes over ERM and JTT/ However, these improvements
are not consistent. Therefore, we are spurred to consider modifications to make it a more competitive tool
against worst group outcomes.
In order to build intuition about how to adapt MTL to target the worst group error, we conduct controlled
experiments on two-layer linear models trained from scratch on synthetic data. We borrow the synthetic
data setup introduced by Sagawa et al. (2020b) in which training data consists of two majority groups, where
spurious features (features that are not required to robustly solve the end task) are predictive of the end task
output, and two minority groups, where spurious features are uncorrelated with the output. Sagawa et al.
(2020b) demonstrated that under certain conditions on the generative distribution of the input features,
linear models trained on such data would probably rely on spurious features and thus, have poor worst
group error. Working with this simplified setup where worst-group outcomes are easily inducible allows us
to study MTL’s effects more incisively. We instantiate reconstruction from noised input as our auxiliary
2Published in Transactions on Machine Learning Research (02/2024)
task to perform multitask learning in the synthetic setup. This choice is partially*informed by the fact that
many pre-training objectives like masked language modeling (MLM) (Devlin et al., 2018) and masked image
modeling (He et al., 2022; Tong et al., 2022) are based on input reconstruction. When training solely on this
auxiliary task, we uncover that regularizing the pre-output layer of the model is critical for ensuring that
the model upweights the core features (features required to robustly solve the end task) over the spurious
ones. This leads us to the following recipe for improving worst-group error: regularized multitask learning
of the end task with the (appropriately chosen) auxiliary objective.
Through a battery of experiments across natural language processing (NLP) and computer vision (CV)
datasets, we demonstrate that multitasking the end task with the pre-training objective along with ℓ1
regularization on the shared, pre-prediction layer activations is competitive when pitted against state-
of-the-art DRO approaches like JTT (Liu et al., 2021) and Bitrate-Constrained DRO (Setlur et al.,
2023). Specifically, in settings where only validation group annotations are available, regularized MTL
outperforms JTT and BR-DRO on 3/3and2/3datasets, respectively. Our approach improves worst-group
accuracy over ERM (by as much as ∼4%) and JTT (by∼1%) in settings where group annotations
are completely unavailable. Moreover, regularized MTL consistently outperforms both ERM and JTT
on average performance, regardless of whether group annotations are available or not. Thus, within the
prevailing framework of utilizing pre-trained models for downstream fine-tuning, our results demonstrate
that regularized multitask learning can be a simple yet versatile and robust tool for improving both average
and worst-group outcomes.
2 Informal motivation for our regularized MTL method
Problem Setup / Preliminaries: Let each input example x∈Xhave a classification label y∈Yand
a demographic attribute s∈S. Each group g= (s,y)∈Gis defined by the label yand the attribute s,
such thatsspuriously correlates with y. Thus, the sample space of Gis the Cartesian product of Yand
S. Our goal is to learn a model that minimizes the worst-group error. We evaluate the models based on
their worst group accuracy (WGA), i.e., the minimum predictive accuracies of our model across all groups.
We are interested in the setting where the spurious attribute s, and consequently, the group identity gare
unavailable (or available to a very limited degree) at training time, as annotating spurious attributes is
typically expensive.
Why would we expect multitask learning to help mitigate worst group outcomes? It would be
naive to assume that multitasking the end task with anyauxiliary task would prevent poor group outcomes.
In order to better understand intuitively which auxiliary tasks may be helpful, we first provide an example
using the data generation process and linear model setup presented in Sagawa et al. (2020b)’s work on the
effect of spurious and core features on worst-group accuracy.
When do models incur high worst group error? Sagawa et al. (2020b) describe a simple data-
generating distribution that defines, for each example, a label y∈{− 1,1}, a spurious attribute s∈{− 1,1},
and features x. The features are described as either core features xcoreif they are associated with the label
y, or spurious features xspurif they are associated with the spurious attribute s:
xcore|y∼N/parenleftbig
y1, σ2
coreIdc/parenrightbig
xspur|s∼N/parenleftbig
s1, σ2
spurIds/parenrightbig (1)
x= [xcore;xspur]∈Rdandd= (dc+ds)
We can then define a linear model, parameterized by ˆw, that predicts the label given the features.
ˆy(i)=ˆw·x(i). (2)
Note that because the core features xcoreare the ones associated with the label to be predicted, they are the
ones that the model shoulduse in order to attain high predictive accuracy.
*We will delve deeper into other motivations in Section 2
3Published in Transactions on Machine Learning Research (02/2024)
The cross-product of the space of possible labels y=±1and spurious attributes s=±1divides the samples
generated from this distribution into four groups. When some groups are more frequent than others in the
training data, a correlation between {y,s}is created. Further still, in the presence of the above correlation,
if the spurious features have lower variance with respect to the data generating process (Equation 1), i.e.,
σ2
spur≤σ2
core, linear models will tend to rely more on (assign a higher weight to) the spurious features over
the core ones (Sagawa et al., 2020b). This learned reliance on the spurious features – instead of the core
features that are truly predictive of the label – results in poor worst-group error.
Why does reconstruction help? Considering the above, for an auxiliary task to be helpful, it should
discourage the model from using spurious features by showing a stronger preference for core features in
exactly the case when σ2
spur≤σ2
core. In this paper, we argue that one class of tasks that fulfills this criterion
arereconstruction tasks , where we predict original input features from noised versions.
For instance, in the example above, if we add noise with a constant variance of σ2
noiseover each dimension,
it results in noised inputs that have variances ˜σ2
spur=/parenleftbig
σ2
spur+σ2
noise/parenrightbig
≤˜σ2
core=/parenleftbig
σ2
core+σ2
noise/parenrightbig
per spurious
and core feature dimension, respectively. Under the assumption that both true labels y= 1andy=−1are
equally probable, and in the simplest case where we are reconstructing features independently of each other
with a linear predictor ˆxi=wi˜xi(where ˜xis the noised input), the Bayes optimal weight on a feature i
would be (see Appendix A.3 for the full proof):
wbayes
i =σ2
i+ 0.5/parenleftig
µ2
i|y=1+µ2
i|y=−1/parenrightig
σ2
i+ 0.5/parenleftig
µ2
i|y=1+µ2
i|y=−1/parenrightig
+σ2
noise(3)
whereµ2
i|y=±1are the per-dimension means from Eqn 1
Note that wbayes
iis larger for dimensions with higher variances σ2
i, assuming µ2
i|y=±1are symmetric across
core and spurious features (i.e all i). Thus, this reconstruction task places more weight on the core features
in exactly the setting where a linear predictor for the end task would prefer to use the spurious features.
Note that for this preference of the core features to be effectively realized, the auxiliary task needs to be
sufficiently up-weighted, but not so much so that the end task is not learned at all.
Why is regularization necessary? Given an auxiliary task with the above property of preferring core
to spurious features (under σ2
spur≤σ2
core), a model with sufficient capacity can still rely on spurious features
for solving the end task. We can incentivize the model to mostly use core features by applying sufficient
regularization to the parts of the model that are shared between the two tasks (such as shared feature
extractors). The restricted capacity encourages the model to rely on features that would cause it to do well
onbothtasks, which would be the core features.
Based on the intuition established in this section, we propose a simple yet effective method for improving
worst-group outcomes: Multitasking the end task with the pre-training objective – which tends to be
reconstruction tasks – while regularizing the shared (pre-prediction) layer . In Section 3, we will test this
intuition through synthetic data experiments, and in Sections 4 and 5, we demonstrate its empirical efficacy
through natural data experiments.
3 Synthetic Data Experiments
We initiate our investigation with an empirical study in a simplified context, involving the training of a
two-layer linear model on synthetic data. This exploration is designed to substantiate the informal intuition
introduced in Section 2 through concrete empirical findings.
3.1 Data Generating Distribution
We base our experiment on the data generation distribution from Equation 1, where features are divided
into core and spurious ones.
4Published in Transactions on Machine Learning Research (02/2024)
3
 2
 1
 0 1 2 3
Core Feature1.0
0.5
0.00.51.0Spurious FeatureTraining Data
[Majority Group] Class = 1
[Majority Group] Class = 0
[Minority Group] Class = 1
[Minority Group] Class = 0
Figure 1: Visualization of synthetic
training data ( 1000points).As an instantiation, we consider end the task data defined by
Tend={(xi,yi)}i∈Nwhere we have Ntotal samples. Here
dc= 1;ds= 1 =⇒d= 2. The data is dominated
by samples where {s=y}and thus, we have two majority
groups Gs=y=1andGs=y=−1, each withnmaj
2samples. The
two minority groups are when {s=−y}each withnmin
2:
Gs=−y=1,Gs=−y=−1. Due to the fact that nmaj> n min, the
attributesis highly correlated with the label yin the training
data and thus, is a spurious feature when considering the true
data generation distribution. The end task is to predict the
true labelyifrom the given input data xi.
Figure 1 shows data sampled from the generative process
described in Equation 1. We produce 1000samples in R2with
σ2
core= 0.6andσ2
spur= 0.1.nmin= 100andnmax= 900,
making the spurious feature highly correlated with the true label.
3.2 Training on the end task only
3
 2
 1
 0 1 2 3
Core Feature1.5
1.0
0.5
0.00.51.01.5Spurious FeatureEnd-Task Only
|a|1=0.10 
  Acc(Worst) = 64.15% | Acc(Avg) = 83.16%
[Majority Group] Class = 1
[Majority Group] Class = 0
[Minority Group] Class = 1
[Minority Group] Class = 0
3
 2
 1
 0 1 2 3
Core Feature1.5
1.0
0.5
0.00.51.01.5Spurious FeatureEnd-Task Only
|a|1=10.00 
  Acc(Worst) = 48.30% | Acc(Avg) = 75.21%
[Majority Group] Class = 1
[Majority Group] Class = 0
[Minority Group] Class = 1
[Minority Group] Class = 0
Figure 2: Predictors learned when we train on the end task only. Examples visualized are the balanced test
samples created from Equation 1.
We train on Tendonly to confirm that the resulting model has poor worst-group outcomes. Since we will
eventually be do multitasking, we use a two layer linear model where the first layer is a linear featurizer
– that will eventually be shared between all tasks being multitasked – and the second layer is a prediction
head dedicated to the end task. This shared featurizer but separate head architecture is common in modern
multitask learning (Yu et al., 2020; Michel et al., 2021; Dery et al., 2021a).
For simplicity, the featurizer layer f(·)is a diagonal linear function parameterized by a*:
f:Rd→Rd|f(a)(x) = (diag (a))x (4)
And the final output prediction layer is given by
yend
pred=/parenleftbig
wend/parenrightbigTf(x) = (wend)T/parenleftbigg
diag (a)/parenrightbigg
x=/parenleftbig
ˆwend/parenrightbigTx
Note that we have effectively parameterized a linear model with decomposed formulation which will be
helpful once we proceed to multitasking. The end task loss is binary cross-entropy with ℓ2regularization on
*the diagonal parameterization allows us to easily read off how much weight is assigned to core features versus spurious ones
5Published in Transactions on Machine Learning Research (02/2024)
0.1 10
|a|14
2
0246log(|aspur
acore|)Auxiliary Task only
 Distribution of shared feature weights
Median
Mean
Figure 3: The ratio log(aspur
acore)for 2 (extreme)
choices of|a|1across 4 hyperparameter settings
(learning rate×batch size).
Figure 4: Multitask learning architecture used in
Section 3.4. We use a shared intermediate layer and
two separate prediction heads for TauxandTend
wendis given by the following equation where σbe the sigmoid function:
Lend/parenleftbig
wend,a/parenrightbig
=1
N/summationdisplay
(xi,yi)∈Tend/bracketleftbigg
yi·log/parenleftbig
σ/parenleftbig
yend
pred/parenrightbig/parenrightbig
+ (1−yi)·log/parenleftbig
1−σ/parenleftbig
yend
pred/parenrightbig/parenrightbig/bracketrightbigg
+λ
2∥wend∥2(5)
We fit the model solely to the end task by running batched stochastic gradient descent on Lend. We use a
batch size of 64, learning rate of 10−3,λ= 1, and 500epochs. We use 100generated points as validation
data for model selection. As can be seen in Figure 2, training on the end task only can result in a predictor
that achieves poor worst group error. This occurs even with varying the norm of the featurizer parameter a.
3.3 Training on auxiliary data only
As motivated in Section 2, we proceed to introduce a reconstruction based auxiliary task. The auxiliary
task data is defined by Taux={(˜xi,xi}i∈Mwhere we have Mtotal samples. Munlabelled points (with
respect to the end task) are taken from the distribution described by Equation 1. Noise of the form
ϵnoise∼N/parenleftbig
0, σ2
noiseId/parenrightbig
|˜x=x+ε (6)
is applied to each point. The task is to reconstruct xifrom ˜xi. Reusing the featurizer from Equation 4, we
define the following prediction model:
xaux
pred=/parenleftbig
Waux/parenrightbigTf(a)(˜x)
Wauxparameterizes the auxiliary prediction head which we regularize to {Waux∈Rd×d|∥Waux∥2
F= 1}.
Finally, our reconstruction loss is given by:
Lrecon (Waux,a) =1
2M/summationdisplay
(˜xi,xi)∈Taux∥xi−/parenleftbig
Waux/parenrightbigTf(˜x)∥2(7)
Using the synthetic data instantiation in Figure 1, we apply noise from N(0, I2), i.e.,σ2
noise = 1on each
of the 1000training points to get the training data for the auxiliary task*. We fit the model solely to the
auxiliary task by running batched stochastic gradient descent on Lrecon. We use learning rates in the set
{10−2,10−3}and batch sizes in the set {64,256}.
We consider two cases when the intermediate layer ahas low versus high capacity, as reflected in ℓ1-norm.
Lowℓ1-norm –∥a∥1=|aspur|+|acore|= 0.1means restricted capacity since this constraint (along with
∥Waux∥F= 1) results in models that cannot fit the training data perfectly. High ℓ1-norm (∥a∥1= 10)
*Note that while we could generate more points for the auxiliary task, we would like to mimic the setting where we refrain
from introducing external data (data beyond end task training data) since methods like JTT and BR-DRO do not utilize them.
6Published in Transactions on Machine Learning Research (02/2024)
means that the model is expressive enough to perfectly fit the training data. Figure 3 provides insight into
the learned intermediate layer in either case. When the model has enough capacity, there is no competition
between the core and spurious features. This means solutions where the spurious feature is weighted more
than the core feature are feasible as long as the core feature weight is enough to reconstruct the the noised
core features well.
However, under restricted capacity where the learned weight of the core and spurious features are in direct
competition, the model has to put more weight on the core features in order to achieve a lower auxiliary
loss (as motivated in Section 2). This can be seen in Figure 3. Thus, for the auxiliary task to be effective at
forcing a model to use core features over spurious ones, the model’s capacity must be reasonably restricted.
3.4 Multitasking with regularization
Given the findings from Section 3.3, we proceed to multitask LendandLreconalong with regularization on
the shared layer a. Let A(τ) ={a∈Rd||a|1=τ}be a set of ℓ1-norm constrained vectors, we solve the
following multitask optimization problem:
˜Waux,˜ wend,˜ a= argmin∥Waux∥2
F=1,a∈A(τ)α·Lrecon (Waux,a) +Lend/parenleftbig
wend,a/parenrightbig
(8)
Table 2: Summary of results from Sections
3.3 and 3.4. Regularized multitasking leads to
improved worst-group outcomes.
Method∥a∥1= 0.1∥a∥1= 10
Worst-Group Acc Worst-Group Acc
End task only 64.15 48 .30
Regularized MTL 94.02 0.0We implement the multitask model illustrated in Figure 4.
We use the same set of hyper-parameters as used in Section
3.3 and perform joint stochastic gradient descent on both
TendandTaux. Whenτis chosen to be small enough,
model capacity is restricted, and the model is forced to rely
chiefly on the core features to do well on both the end and
auxiliary tasks. Figure 5 evinces this. When the norm of
the shared layer is high ∥a∥1= 10, the end task can still
predominantly rely on the spurious features leading to poor
worst group error. On the other hand, when model capacity is reasonably restricted by setting ∥a∥1= 0.1,
we see from Figure 5 (left) that we can achieve improved worst group accuracy. Thus, we can effectively
leverage the reconstruction auxiliary task in this simplified setting by applying sufficient regularization to
ensure improved worst-group outcomes.
3
 2
 1
 0 1 2 3
Core Feature1.5
1.0
0.5
0.00.51.01.5Spurious FeatureRegularized MTL 
|a|1=0.10 =10.00 
 Acc(Worst) = 94.02% | Acc(Avg) = 95.00%
[Majority Group] Class = 1
[Majority Group] Class = 0
[Minority Group] Class = 1
[Minority Group] Class = 0
3
 2
 1
 0 1 2 3
Core Feature1.5
1.0
0.5
0.00.51.01.5Spurious FeatureRegularized MTL 
|a|1=10.00 =10.00 
 Acc(Worst) = 0.00% | Acc(Avg) = 50.00%
[Majority Group] Class = 1
[Majority Group] Class = 0
[Minority Group] Class = 1
[Minority Group] Class = 0
Figure 5: Depicted are the learned half-spaces for the multitask model under τ={0.1,10}andα= 10.
Restricting the capacity of the shared feature space is critical for multitasking to be effective for improving
worst group error. Examples visualized are 1000balanced test examples sampled from Equation 1
7Published in Transactions on Machine Learning Research (02/2024)
4 Details For Natural Data Experiments
We have made a case for using regularized multitask learning to combat poor worst-group performance
through empirical explorations in a simplified, synthetic setting. In this section, we review the experimental
details for our investigations of tasks of more practical interest.
4.1 Datasets
We conduct experiments across three datasets. To relieve the burden of compute, we introduce a fourth
dataset, a smaller, sub-sampled version of one of the original datasets for ablations.
1.Waterbirds: This image classification dataset was introduced by Sagawa et al. (2020a). The task is to
distinguish between species of land and water birds. It consists of bird images sourced from the CUB
dataset Wah et al. (2011) and superimposed on land or water backgrounds from the Places dataset Zhou
et al. (2018). The label (type of bird) is spuriously correlated with the background, resulting in 4 groups.
Since this is a small dataset ( 4795train examples), we also use it for ablations.
2.MultiNLI: This is a natural language inference dataset. The task is to classify whether the second
sentence is entailed by, contradicts, or is neutral with respect to the first sentence (Williams et al., 2018).
Following Sagawa et al. (2020a), we utilize the presence of negation words as a spurious attribute, leading
to the creation of a total of 6groups.
3.Civilcomments: The Civilcomments dataset is a toxicity classification dataset that contains comments
from online forums Borkan et al. (2019); Koh et al. (2021). Along with the toxicity label, each text
is annotated with additional overlapping sub-group labels of 8 demographic identities: male, female,
LGBTQ, Christian, Muslim, other religions, Black, and White. As per Koh et al. (2021) and Sagawa
et al. (2020a), we defines 16overlapping groups by taking the Cartesian product of the binary toxicity
label and each of the above 8demographic identities.
4.Civilcomments-small: As Civilcomments is a large dataset of about 448000datapoints, we create a
sub-group stratified subset of 5%for conducting ablations and other detailed experiments. Our subset
contains 13770,2039, and 4866datapoints in our train, validation, and test split, respectively.
4.2 Multitask Model and Training Details
We follow the parameter sharing paradigm (Ruder, 2017; Sener & Koltun, 2018) where both TendandTaux
share the same model body, parameterized by θbase. We instantiate task-specific heads, parameterized by
θendandθaux, respectively. We introduce ℓ1regularization to the last layer activations immediately before
the per-task prediction heads*. Specifically, let hend,haux∈Rdbe the output representations generated by
the base model, which are fed into their respective task-specific heads. Our final multitask learning objective
is expressed as follows:
Lfinal=Lend+αaux·Laux+αreg/parenleftbig
∥hend∥1+∥haux∥1/parenrightbig
(9)
We cross-validate optimizing Lfinalwith different weighting schemes. We choose αauxandαregfrom the
set{e−1,e0,e1}. Note that whilst we optimize Lfinalwe care only about improving worst-group error on
Taux. We use the pretrained BERT base(Devlin et al., 2018) and ViT base(Dosovitskiy et al., 2020) as the
shared base models for NLP and CV tasks, respectively. We leverage the base models’ self-supervised pre-
training objectives, namely, masked language modeling (MLM) and masked image modeling (MIM) for our
auxiliary transfer task Tauxas in Dery et al. (2021a). These auxiliary objectives are based on end-task data
itself (unless specified otherwise). We do this to maintain an apples-to-apples comparison with our chosen
baselines, which do not use external data. As Section 5 will show, we obtain performance improvements even
in this setting. In Section 5.4, we show that our improvements when using task-only data are predicated on
sufficient prior pre-training. More details on the multitask model and batching scheme are presented in A.1.
*Incontrasttosyntheticdataexperiments, wherethenormconstraintisappliedtopre-predictionlayerweights, inthissection
we directly apply the norm constraint to the features, indirectly constraining model weights. In the synthetic experiment, core
and spurious features have a one-to-one mapping to model weights, enabling direct regularization of the features, but that is
no longer possible in more complex models.
8Published in Transactions on Machine Learning Research (02/2024)
For training, we vary the fine-tuning learning rate within the ranges of {10−3,10−4}for Waterbirds, and
{10−4,10−5}for the text datasets. We experiment with batch sizes in the set {4,8,16,32}. We use the
same batch sizes for TendandTaux. We train for 50epoch for the NLP datasets and 200epochs for
Waterbirds, with an early stopping patience of 10, as per the check-pointing scheme explained in section
4.2. We use the Adam optimizer for NLP datasets with decoupled weight decay regularization of 10−2
(Loshchilov & Hutter, 2017). Consistent with the recent studies on ViT (Dosovitskiy et al., 2020; Steiner
et al., 2022), we use SGD with a momentum of 0.9(Sutskever et al., 2013) to fine-tune Waterbirds. We run
each hyperparameter configuration across 5seeds and report the averaged results. We report the ERM, JTT,
and groupDRO results for Civilcomments and MultiNLI from Idrissi et al. (2022) as the authors conducted
extensive hyperparameter tuning across all these methods. However, since Idrissi et al. (2022) report results
on Waterbirds using a ResNet-50 model (He et al., 2016) and our experiments employ ViT, we re-run all
baselines using ViT with a consistent set of hyperparameters, as mentioned above.
Evaluation Details We assess all methods and datasets using two model selection strategies:
1.Val-GP: This strategy requires group annotations in the validation data during training. Here, we select
the model based on the maximum worst-group accuracy on the validation data.
2.No-GP: This strategy requires no access to any group annotations during training. We select the model
based on the average validation accuracy.
Baseline Methods Since we evaluate our method based on its ability to generalize to worst performing
groups, we benchmark it against three popular methods found in group generalization literature. These
methods either directly or indirectly optimize for worst-group improvements.
1.Empirical Risk Minimization (ERM): This is the standard approach of minimizing the average loss
over all the training data. No group information is used during training except when the Val-GP strategy
is used for model selection.
2.Just Train Twice (JTT): It presents a two step approach for worst group generalization Liu et al.
(2021). JTT first trains a standard ERM model for Tepochs to identify misclassified datapoints. Then,
a second model is trained on a reweighted dataset constructed by upweighting the misclassified examples
byαup. It does not use group information during training except for the Val-GP strategy.
3.Bit-rate Constrained DRO (BR-DRO): Traditionally, in the two-player formulation of DRO, the
adversary can use complex reweighting functions, resulting in overly pessimistic solutions. In contrast,
BR-DRO Setlur et al. (2023) constrains the adversary’s complexity based on information theory under
a data-independent prior. While BR-DRO offers weaker robustness without performance guarantees for
arbitrary reweighting, it is less pessimistic and suitable for simpler distribution shifts, characterized by a
reweighting function contained in a simpler complexity class. BR-DRO does not use group information
during training except for the Val-GP setting.
4.Group-DRO: Group distributionally robust optimization minimizes the maximum loss across all the
sub-groups Sagawa et al. (2020a). This optimization method incorporates group annotations during
training. Similar to prior works Liu et al. (2021); Idrissi et al. (2022); Setlur et al. (2023), we treat it as
an oracle, as this is the only method that uses group annotations.
5 Results And Discussion
In this section, we provide empirical evidence demonstrating the effectiveness of our regularized MTL
approach in mitigating worst-group error while maintaining average performance across different scenarios.
5.1 Multitasking is Competitive with Bespoke DRO Methods
We first compare our approach with previously proposed methods for tackling worst-group accuracy. Table 3
details the performance of various methods across the tasks of interest for the Val-GP setting. As expected,
groupDRO yields the highest worst-group accuracy as it directly optimizes for it. Our MTL approach
outperforms JTT and BR-DRO on two datasets (MNLI and Waterbirds) while performing comparatively
9Published in Transactions on Machine Learning Research (02/2024)
Table 3: Mean and standard deviations of the test worst-group accuracies across all the methods
under consideration. Regularized MTL consistently reduces the gap between ERM and groupDRO when
considering worst-group accuracy.
Method Group Labels Civilcomments MNLI Waterbirds
ERM Val Only 61.32.0 67.61.2 85.41.4
JTT Val Only 67.81.6 67.51.9 85.92.5
BR-DRO Val Only 68.90.7 68.50.8 86.71.3
ERM + MT + L1 Val Only 68.23.2 69.71.5 87.52.7
groupDRO (Upper Bound) Train and Val 69.91.2 78.00.7 93.90.7
with BR-DRO on the CivilComments dataset. Given the competitive results in Table 3, we argue that our
regularized MTL formulation is an attractive option over JTT and BR-DRO. Multitasking already features
prominently in many ML code bases. Thus, introducing our simple regularization modification to existing
MTL implementations represents a smaller technical overhead compared to introducing JTT or BR-DRO
to target worst-group error. Also, as we will see in Section 5.2 below, regularized MTL is a single approach
capable of improving both worst-group and average accuracy.
5.2 Multitasking Improves both Average and worst-group Performance Even in the Absence Group
Annotations
72.575.077.580.082.585.087.590.0Worst Group AccuracyWaterbirds 
 (no validation group annotations)
72.575.077.580.082.585.087.590.0Waterbirds 
 (with validation group annotations)
Median
Mean
ERM JTT ERM_MLM_L1
Methods45.050.055.060.065.070.0Worst Group AccuracyCivilcomments-small 
 (no validation group annotations)
ERM JTT ERM_MLM_L1
Methods45.050.055.060.065.070.0Civilcomments-small 
 (with validation group annotations)
Median
Mean
93.094.095.096.097.098.0Average AccuracyWaterbirds 
 (no validation group annotations)
93.094.095.096.097.098.0
Waterbirds 
 (with validation group annotations)
Median
Mean
ERM JTT ERM_MLM_L1
Methods80.081.082.083.084.085.0Average AccuracyCivilcomments-small 
 (no validation group annotations)
ERM JTT ERM_MLM_L1
Methods80.081.082.083.084.085.0Civilcomments-small 
 (with validation group annotations)
Median
Mean
Figure 6: Comparison of the performance of different approaches with respect to average and worst-group
accuracy on the Waterbirds dataset under val-GP and no-GP settings. Regularized MTL improves both
average and worst-group accuracy even without group annotations. All methods enjoy lift in when validation
group annotations are available.
Though previous works typically assume that practitioners have access to the group annotations on the
validationset(Liuetal.,2021;Kirichenkoetal.,2022),weareinterestedinsettingswherenosuchannotations
are available. This covers many tasks of practical interest since, in some cases, it may be prohibitively
cost-intensive (financially and in terms of human labor) to acquire group annotations even for the smaller
validation set (Paranjape et al., 2023). Consequently, we present a comparative performance analysis in
Figure 6, encompassing settings with and without access to group annotations. With respect to worst-group
accuracy, our regularized MTL approach outperforms JTT and achieves ≈2%lift over ERM when group
10Published in Transactions on Machine Learning Research (02/2024)
annotations are absent, a trend consistent across both Waterbirds and Civilcomments-small datasets. While
this lift of≈2%remains when validation group annotations are introduced, the benefit from group-labeled
dataismorepronounced( ≈5%−15%). Thisboostcanbeworthwhiletopractitionerswhohavetheresources
to obtain some group annotations. Moreover, it becomes evident from Figure 6 that our method not only
yields superior worst-group performance but also improves in average performance.
5.3 Are both Regularization and Multitasking Jointly necessary?
Table 4: Disentangling the impact of L1 regularization and SSL objective on wost-group accuracy. We see
that regularized multitasking is necessary for gains in both average and worst-group performance.
Dataset MethodNo Group Annotations Val Group Annotations
Avg Acc WG Acc Avg Acc WG Acc
WaterbirdsJTT 95.60.3 82.11.2 94.00.5 85.92.5
ERM 95.50.2 80.14.6 94.10.7 85.41.4
+ L1 95.60.3 82.05.4 94.70.9 86.41.4
+ MIM 95.30.4 80.14.6 95.00.6 85.32.4
+ MIM + L1 95.80.3 83.33.4 95.40.4 87.52.7
Civilcomments-SmallJTT 83.30.2 52.55.2 81.30.8 68.01.8
ERM 83.90.4 51.65.6 81.41.0 67.42.1
+ L1 83.70.4 51.64.0 80.30.7 66.31.6
+ MLM 83.91.2 58.36.6 80.30.7 68.50.4
+ MLM + L1 84.40.4 53.74.3 82.00.5 69.41.7
Inthissection, weconductanablationtoverifyif bothmultitasklearningandregularizingthefinallayerjoint
embedding space are necessary to improve average and worst-group performance. Our results are captured in
Table4. Whenassessingtheworst-groupaccuracy, wefindthatregularizingthefinalembeddingspaceduring
ERMcan, attimes, resultinworseperformancecomparedtotrainingviastandardERM( 66.31.6vs67.42.1on
CivilComments-small with validation group labels). On the other hand, multitasking without regularization
can fail to improve over ERM, as evinced by the lack of improvement on Waterbirds. The regularized MTL
approach is the only setting consistently improving on both datasets with and without validation group
annotations. In line with these findings, we observe that joint L1 regularization and multitask learning setup
yields the highest average accuracy in most cases.
5.4 Impact of Pre-Training
Table 5: Waterbirds: Impact of pre-training on average and worst-group accuracy.
Pretrianed MethodNo Group Annotations Val Group Annotations
Avg Acc WG Acc Avg Acc WG Acc
NoERM 65.10.5 4.51.6 53.30.7 10.12.9
JTT 67.05.3 10.812.2 56.22.1 49.94.0
ERM + MIM + L1 67.02.3 1.650.7 53.52.7 12.03.2
yesERM 95.50.2 80.14.6 94.10.7 85.41.4
JTT 95.60.3 82.11.2 94.00.5 85.92.5
ERM + MIM + L1 95.80.3 83.33.4 95.40.4 87.52.7
Fine-tuning pre-trained models is arguably the de-facto paradigm in machine learning (Devlin et al., 2018;
Dosovitskiy etal.,2020; Deryet al.,2021b). Consequently, our experiments sofar haveexclusively focused on
pre-trained models. In this section, we wish to understand the effect of deviating from this paradigm on our
MTL approach. Thus, we compare against JTT and ERM when the model is trained from scratch instead
of starting with a pre-trained model. Tables 5 and 6 depict our results on Waterbirds and Civilcomments-
small, respectively. Our results show that pre-training is critical for setting up regularized MTL as a viable
11Published in Transactions on Machine Learning Research (02/2024)
Table 6: Civilcomments-small : Impact of pre-training on average and worst-group accuracy.
Pretrianed MethodNo Group Annotations Val Group Annotations
Avg Acc WG Acc Avg Acc WG Acc
NoERM 80.70.8 31.17.2 74.40.9 54.03.7
JTT 79.60.6 34.98.9 74.31.2 58.71.3
ERM+MLM+L1 80.70.6 31.37.6 74.20.3 56.20.9
YesERM 83.90.4 51.65.6 81.41.0 67.42.1
JTT 83.30.2 52.55.2 81.30.8 68.01.8
ERM+MLM+L1 84.40.4 53.74.3 82.00.6 69.41.7
remedy against poor worst-group outcomes. We posit the following explanation for this outcome. Note
that our informal motivation in Section 2 presupposes an ability to solve the auxiliary task to a reasonable
degree. Solving the MLM and MIM tasks effectively from scratch with only the inputs of the relatively
small supervised dataset is difficult. This poor performance on the auxiliary task translates to an inability
to constrain the use of the spurious features on the end-task. Consistent with prior works (Tu et al., 2020;
Wiles et al., 2022), our recommendation to practitioners is to use our approach during the fine-tuning of
pre-trained models to be maximally effective.
Another consequence of our findings is that caution is warranted in interpreting the results of previous work
on DRO in light of the new paradigm of mostly using pre-trained models. Most previous results on DRO have
examined the setting of training from scratch, and as Tables 6 and 5, DRO methods significantly outperform
competitors in that setting. However, the originally outsized gains in worst-group error significantly shrink
when we move to pre-trained models whilst our method shows superior performance.
6 Related Work
•Multitask Learning. Multitask learning is a common stratergy for ML practitioners to improve the
average performance of their models (Ruder, 2017; Ruder et al., 2019; Liu et al., 2019). While work like
Hendrycks et al. (2019; 2020); Mao et al. (2020) have shown that multitasking can improve the adversarial
andout-of-distributionrobustnessofmodels,theimpactofmultitaskingonworst-groupoutcomeshasbeen
relatively unexplored. Makino et al. (2022) propose generative multitask learning (GMTL), a method that
bolsters robustness to target shift by conditioning the input on all available targets, thereby addressing
challenges associated with target-causing confounders and spurious dependencies between input and
targets. However, it is important to note that their approach necessitates all target annotations during
training, a requirement we do not assume in our scenario. Our work is inspired by Gururangan et al.
(2020), who introduce constructing auxiliary objectives directly from end-task data for continued pre-
training (they dub this Task Adaptive Pre-training – TAPT). Following Dery et al. (2021b; 2023), we
multitask this auxiliary task with the end-task. However, unlike these studies, our focus is on improving
the worst-case group accuracy of the final model. The work by Michel et al. (2021) explores the balancing
of worst and average performance in multitask learning. In their study, they focus on a set of equally
important end tasks, striving for proficient model performance across all of them. In contrast, our work
delves into the asymmetrical multitask setting, where the presence of the auxiliary task is determined by
its contribution to enhancing our target metric in the end task.
•Robustness using group demographics. Our multitask learning approach is primarily designed for
settings with limited-to-no group annotations. However, many DRO approaches assume the presence of
group annotations for all training points. Among the approaches that leverage group information, Group
Distributionally Robust Optimization Sagawa et al. (2020a) is the most popular technique that tries to
minimize the maximum loss over the sub-groups. Goel et al. (2021) presented Model Patching , a data
augmentation method designed to enhance the representation of minority groups. FISH, proposed by Shi
et al. (2022), focuses on domain generalization via inter-domain gradient matching. In the settings where
group annotations are expensive (financially or in terms of human resources) to procure, these methods
are not viable options.
12Published in Transactions on Machine Learning Research (02/2024)
•Robustness without group demographics. Extensive research has been dedicated to addressing the
challenges of worst-group generalization in the more realistic scenario where access to group annotations
during training is unavailable. GEORGE Sohoni et al. (2020) adopts a clustering-based methodology to
unveil latent groups within the dataset and subsequently employs groupDRO for improved robustness.
Learning from Failure (LfF) Nam et al. (2020) introduces a two-stage strategy. In the first stage, an
intentionally biased model aims to identify minority instances where spurious correlations do not apply. In
the second stage, the identified examples are given increased weight during the training of a second model.
Just Train Twice (JTT) method Liu et al. (2021) follows a similar principle by training a model that
minimizes loss over a reweighted dataset. This dataset is constructed by up-weighting training examples
misclassified during the initial few epochs. Our regularized MTL approach has several advantages over
these methods, even though they are all deployed in the same limited-to-no group annotations settings.
As we have demonstrated, our approach can improve both worst-group and average performance, unlike
the other approaches targeted against worst-group error only. Secondly, due to the widespread usage of
multitasklearningbymanyMLpractitioners, implementingourmodificationrepresentsminimaloverhead
instead of introducing one of the above bespoke approaches.
7 Conclusion
In this work, we presented an empirical investigation of the impact of multitasking on worst-group outcomes.
We found that deploying multitasking, as is, does not consistently improve upon worst performing groups.
We have shown that while DRO methods, like JTT, display superior performance when models are trained
from scratch, this is not the case in the currently more widespread setting of fine-tuning a pre-trained model.
Specifically, when fine-tuning, our method – regularized multitasking of the end-task with the pre-training
objective constructed over end-task data – leads to improvements in worst-case group accuracy over JTT.
Our work has demonstrated that it is possible to design a single, simple method that improves both worst-
case group accuracy average accuracy regardless of the availability of group annotations. Since multitask
learning is already a standard part of many practitioner’s toolbox, and our modification to adapt it against
worst-group accuracy is simple, our approach requires minimal overhead to integrate into existing systems
compared to bespoke DRO approaches. We thus encourage practitioners to introduce our modification to
their MTL pipelines as an essentially free way of improving worst-group performance without sacrificing
gains in average performance.
In order to keep an apples-to-apples comparison with DRO approaches, we have primarily focused on
multitasking with auxiliary objectives based on end-task data only. For future work, it would be interesting
to explore the impact of multitasking with auxiliary objectives based on external data more deeply. It would
also be interesting to leverage meta-learning to dynamically adapt the auxiliary tasks towards improving
worst-case group outcomes (Dery et al., 2021b; 2023). Additionally, we leave the study on the generalizability
of our method to adversarial robustness, domain shift, and label shift to future work.
8 Acknowledgements
This work was also supported in part by the Tang AI Innovation Fund, Defence Science and Technology
Agency Singapore, National Science Foundation grants IIS1705121, IIS1838017, IIS2046613, IIS2112471, and
funding from Meta, Morgan Stanley, Amazon, Google, Schmidt Early Career Fellowship and Apple. Any
opinions, findings, conclusions, or recommendations expressed in this material are those of the author(s) and
do not necessarily reflect the views of any of these funding agencies.
13Published in Transactions on Machine Learning Research (02/2024)
References
Armen Aghajanyan, Anchit Gupta, Akshat Shrivastava, Xilun Chen, Luke Zettlemoyer, and Sonal Gupta.
Muppet: Massive multi-task representations with pre-finetuning. In Proceedings of the 2021 Conference on
Empirical Methods in Natural Language Processing , pp. 5799–5811, Online and Punta Cana, Dominican
Republic, November 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.emnlp-main.
468. URL https://aclanthology.org/2021.emnlp-main.468 .
Kumar Ayush, Burak Uzkent, Chenlin Meng, Kumar Tanmay, Marshall Burke, David Lobell, and Stefano
Ermon. Geography-aware self-supervised learning. In Proceedings of the IEEE/CVF International
Conference on Computer Vision , pp. 10181–10190, 2021.
Jonathan Baxter. A model of inductive bias learning. Journal of artificial intelligence research , 12:149–198,
2000.
Aharon Ben-Tal, Dick Den Hertog, Anja De Waegenaere, Bertrand Melenberg, and Gijs Rennen. Robust
solutions of optimization problems affected by uncertain probabilities. Management Science , 59(2):341–
357, 2013.
Daniel Borkan, Lucas Dixon, Jeffrey Sorensen, Nithum Thain, and Lucy Vasserman. Nuanced metrics
for measuring unintended bias with real data for text classification. In Companion Proceedings of The
2019 World Wide Web Conference , WWW ’19, pp. 491–500, New York, NY, USA, 2019. Association for
Computing Machinery. ISBN 9781450366755. doi: 10.1145/3308560.3317593. URL https://doi.org/
10.1145/3308560.3317593 .
Joy Buolamwini and Timnit Gebru. Gender shades: Intersectional accuracy disparities in commercial gender
classification. In Conference on fairness, accountability and transparency , pp. 77–91. PMLR, 2018.
Rich Caruana. Multitask learning. Machine learning , 28:41–75, 1997.
Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton. A simple framework for contrastive
learning of visual representations. In International conference on machine learning , pp. 1597–1607. PMLR,
2020.
Terrance De Vries, Ishan Misra, Changhan Wang, and Laurens Van der Maaten. Does object recognition
workforeveryone? In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition
workshops , pp. 52–59, 2019.
Lucio M Dery, Yann Dauphin, and David Grangier. Auxiliary task update decomposition: The good, the
bad and the neutral. arXiv preprint arXiv:2108.11346 , 2021a.
Lucio M Dery, Paul Michel, Ameet Talwalkar, and Graham Neubig. Should we be pre-training? an argument
for end-task aware training as an alternative. arXiv preprint arXiv:2109.07437 , 2021b.
Lucio M. Dery, Paul Michel, Mikhail Khodak, Graham Neubig, and Ameet Talwalkar. AANG : Automating
auxiliary learning. In The Eleventh International Conference on Learning Representations , 2023. URL
https://openreview.net/forum?id=vtVDI3w_BLL .
JacobDevlin,Ming-WeiChang,KentonLee,andKristinaToutanova. Bert: Pre-trainingofdeepbidirectional
transformers for language understanding. arXiv preprint arXiv:1810.04805 , 2018.
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas
Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, et al. An image is
worth 16x16 words: Transformers for image recognition at scale. arXiv preprint arXiv:2010.11929 , 2020.
John Duchi and Hongseok Namkoong. Learning models with uniform performance via distributionally robust
optimization. arXiv preprint arXiv:1810.08750 , 2018.
Karan Goel, Albert Gu, Yixuan Li, and Christopher Re. Model patching: Closing the subgroup performance
gap with data augmentation. In International Conference on Learning Representations , 2021. URL
https://openreview.net/forum?id=9YlaeLfuhJF .
14Published in Transactions on Machine Learning Research (02/2024)
Sachin Goyal, Ananya Kumar, Sankalp Garg, Zico Kolter, and Aditi Raghunathan. Finetune like you
pretrain: Improved finetuning of zero-shot vision models. In Proceedings of the IEEE/CVF Conference
on Computer Vision and Pattern Recognition , pp. 19338–19347, 2023.
Suchin Gururangan, Ana Marasović, Swabha Swayamdipta, Kyle Lo, Iz Beltagy, Doug Downey, and
Noah A Smith. Don’t stop pretraining: Adapt language models to domains and tasks. arXiv preprint
arXiv:2004.10964 , 2020.
Tatsunori Hashimoto, Megha Srivastava, Hongseok Namkoong, and Percy Liang. Fairness without
demographics in repeated loss minimization. In Jennifer Dy and Andreas Krause (eds.), Proceedings
of the 35th International Conference on Machine Learning , volume 80 of Proceedings of Machine
Learning Research , pp. 1929–1938. PMLR, 10–15 Jul 2018. URL https://proceedings.mlr.press/
v80/hashimoto18a.html .
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In
Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , June 2016.
Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Dollár, and Ross Girshick. Masked autoencoders
are scalable vision learners. In Proceedings of the IEEE/CVF conference on computer vision and pattern
recognition , pp. 16000–16009, 2022.
Dan Hendrycks, Kimin Lee, and Mantas Mazeika. Using pre-training can improve model robustness and
uncertainty. In International conference on machine learning , pp. 2712–2721. PMLR, 2019.
Dan Hendrycks, Xiaoyuan Liu, Eric Wallace, Adam Dziedzic, Rishabh Krishnan, and Dawn Song. Pretrained
transformers improve out-of-distribution robustness. arXiv preprint arXiv:2004.06100 , 2020.
Badr Youbi Idrissi, Martin Arjovsky, Mohammad Pezeshki, and David Lopez-Paz. Simple data balancing
achieves competitive worst-group-accuracy. In Bernhard Schölkopf, Caroline Uhler, and Kun Zhang (eds.),
Proceedings of the First Conference on Causal Learning and Reasoning , volume 177 of Proceedings of
Machine Learning Research , pp. 336–351. PMLR, 11–13 Apr 2022. URL https://proceedings.mlr.
press/v177/idrissi22a.html .
Pavel Izmailov, Polina Kirichenko, Nate Gruver, and Andrew G Wilson. On feature learning in the presence
of spurious correlations. Advances in Neural Information Processing Systems , 35:38516–38532, 2022.
David Jurgens, Yulia Tsvetkov, and Dan Jurafsky. Incorporating dialectal variability for socially equitable
language identification. In Regina Barzilay and Min-Yen Kan (eds.), Proceedings of the 55th Annual
Meeting of the Association for Computational Linguistics (Volume 2: Short Papers) , pp.51–57, Vancouver,
Canada, July 2017. Association for Computational Linguistics. doi: 10.18653/v1/P17-2009. URL https:
//aclanthology.org/P17-2009 .
Maurice G Kendall. A new measure of rank correlation. Biometrika , 30(1/2):81–93, 1938.
Polina Kirichenko, Pavel Izmailov, and Andrew Gordon Wilson. Last layer re-training is sufficient for
robustness to spurious correlations. arXiv preprint arXiv:2204.02937 , 2022.
Pang Wei Koh, Shiori Sagawa, Henrik Marklund, Sang Michael Xie, Marvin Zhang, Akshay Balsubramani,
Weihua Hu, Michihiro Yasunaga, Richard Lanas Phillips, Irena Gao, Tony Lee, Etienne David, Ian
Stavness, WeiGuo, BertonEarnshaw, ImranHaque, SaraMBeery, JureLeskovec, AnshulKundaje, Emma
Pierson, Sergey Levine, Chelsea Finn, and Percy Liang. Wilds: A benchmark of in-the-wild distribution
shifts. In Marina Meila and Tong Zhang (eds.), Proceedings of the 38th International Conference on
Machine Learning , volume 139 of Proceedings of Machine Learning Research , pp. 5637–5664. PMLR,
18–24 Jul 2021. URL https://proceedings.mlr.press/v139/koh21a.html .
Paul Pu Liang, Chiyu Wu, Louis-Philippe Morency, and Ruslan Salakhutdinov. Towards understanding
and mitigating social biases in language models. In International Conference on Machine Learning , pp.
6565–6576. PMLR, 2021.
15Published in Transactions on Machine Learning Research (02/2024)
Evan Z Liu, Behzad Haghgoo, Annie S Chen, Aditi Raghunathan, Pang Wei Koh, Shiori Sagawa, Percy
Liang, andChelseaFinn. Justtraintwice: Improvinggrouprobustnesswithouttraininggroupinformation.
In Marina Meila and Tong Zhang (eds.), Proceedings of the 38th International Conference on Machine
Learning , volume 139 of Proceedings of Machine Learning Research , pp. 6781–6792. PMLR, 18–24 Jul
2021. URL https://proceedings.mlr.press/v139/liu21f.html .
Xiaodong Liu, Pengcheng He, Weizhu Chen, and Jianfeng Gao. Multi-task deep neural networks for natural
language understanding. In Proceedings of the 57th Annual Meeting of the Association for Computational
Linguistics , pp. 4487–4496, Florence, Italy, July 2019. Association for Computational Linguistics. doi:
10.18653/v1/P19-1441. URL https://aclanthology.org/P19-1441 .
Ilya Loshchilov and Frank Hutter. Decoupled weight decay regularization. arXiv preprint arXiv:1711.05101 ,
2017.
Taro Makino, Krzysztof Geras, and Kyunghyun Cho. Generative multitask learning mitigates target-
causing confounding. In S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh
(eds.),Advances in Neural Information Processing Systems , volume 35, pp. 36546–36558. Curran
Associates, Inc., 2022. URL https://proceedings.neurips.cc/paper_files/paper/2022/file/
ece182f93af26c64187ba3f7dfd4309a-Paper-Conference.pdf .
ChengzhiMao, AmoghGupta, VikramNitin, BaishakhiRay, ShuranSong, JunfengYang, andCarlVondrick.
Multitask learning strengthens adversarial robustness. In Computer Vision–ECCV 2020: 16th European
Conference, Glasgow, UK, August 23–28, 2020, Proceedings, Part II 16 , pp. 158–174. Springer, 2020.
Paul Michel, Sebastian Ruder, and Dani Yogatama. Balancing average and worst-case accuracy in multitask
learning. arXiv preprint arXiv:2110.05838 , 2021.
Junhyun Nam, Hyuntak Cha, Sungsoo Ahn, Jaeho Lee, and Jinwoo Shin. Learning from failure: De-
biasing classifier from biased classifier. In H. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan,
and H. Lin (eds.), Advances in Neural Information Processing Systems , volume 33, pp. 20673–20684.
Curran Associates, Inc., 2020. URL https://proceedings.neurips.cc/paper_files/paper/2020/
file/eddc3427c5d77843c2253f1e799fe933-Paper.pdf .
Junhyun Nam, Jaehyung Kim, Jaeho Lee, and Jinwoo Shin. Spread spurious attribute: Improving
worst-group accuracy with spurious attribute estimation. In International Conference on Learning
Representations , 2022. URL https://openreview.net/forum?id=_F9xpOrqyX9 .
Bhargavi Paranjape, Pradeep Dasigi, Vivek Srikumar, Luke Zettlemoyer, and Hannaneh Hajishirzi. AGRO:
Adversarial discovery of error-prone groups for robust optimization. In The Eleventh International
Conference on Learning Representations , 2023. URL https://openreview.net/forum?id=IrzkT99fDJH .
Shikai Qiu, Andres Potapczynski, Pavel Izmailov, and Andrew Gordon Wilson. Simple and fast group
robustness by automatic feature reweighting. In Andreas Krause, Emma Brunskill, Kyunghyun Cho,
Barbara Engelhardt, Sivan Sabato, and Jonathan Scarlett (eds.), Proceedings of the 40th International
Conference on Machine Learning , volume 202 of Proceedings of Machine Learning Research , pp. 28448–
28467. PMLR, 23–29 Jul 2023. URL https://proceedings.mlr.press/v202/qiu23c.html .
Sebastian Ruder. An overview of multi-task learning in deep neural networks. arXiv preprint
arXiv:1706.05098 , 2017.
Sebastian Ruder, Matthew E Peters, Swabha Swayamdipta, and Thomas Wolf. Transfer learning in natural
languageprocessing. In Proceedings of the 2019 conference of the North American chapter of the association
for computational linguistics: Tutorials , pp. 15–18, 2019.
Shiori Sagawa, Pang Wei Koh, Tatsunori B. Hashimoto, and Percy Liang. Distributionally robust neural
networks. In International Conference on Learning Representations , 2020a. URL https://openreview.
net/forum?id=ryxGuJrFvS .
16Published in Transactions on Machine Learning Research (02/2024)
Shiori Sagawa, Aditi Raghunathan, Pang Wei Koh, and Percy Liang. An investigation of why
overparameterization exacerbates spurious correlations. In Hal Daumé III and Aarti Singh (eds.),
Proceedings of the 37th International Conference on Machine Learning , volume 119 of Proceedings of
Machine Learning Research , pp. 8346–8356. PMLR, 13–18 Jul 2020b. URL https://proceedings.mlr.
press/v119/sagawa20a.html .
Ozan Sener and Vladlen Koltun. Multi-task learning as multi-objective optimization. In S. Bengio,
H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett (eds.), Advances in Neural
Information Processing Systems , volume 31. Curran Associates, Inc., 2018. URL https://proceedings.
neurips.cc/paper_files/paper/2018/file/432aca3a1e345e339f35a30c8f65edce-Paper.pdf .
Amrith Setlur, Don Dennis, Benjamin Eysenbach, Aditi Raghunathan, Chelsea Finn, Virginia Smith, and
Sergey Levine. Bitrate-constrained DRO: Beyond worst case robustness to unknown group shifts. In The
Eleventh International Conference on Learning Representations , 2023. URL https://openreview.net/
forum?id=2QzNuaRHn4Z .
Yuge Shi, Jeffrey Seely, Philip Torr, Siddharth N, Awni Hannun, Nicolas Usunier, and Gabriel Synnaeve.
Gradient matching for domain generalization. In International Conference on Learning Representations ,
2022. URL https://openreview.net/forum?id=vDwBW49HmO .
Nimit Sohoni, Jared Dunnmon, Geoffrey Angus, Albert Gu, and Christopher Ré. No subclass left behind:
Fine-grainedrobustnessincoarse-grainedclassificationproblems. InH.Larochelle, M.Ranzato, R.Hadsell,
M.F. Balcan, and H. Lin (eds.), Advances in Neural Information Processing Systems , volume 33, pp.
19339–19352. Curran Associates, Inc., 2020. URL https://proceedings.neurips.cc/paper/2020/
file/e0688d13958a19e087e123148555e4b4-Paper.pdf .
Kaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, and Tie-Yan Liu. MASS: Masked sequence to sequence pre-
training for language generation. In Kamalika Chaudhuri and Ruslan Salakhutdinov (eds.), Proceedings
of the 36th International Conference on Machine Learning , volume 97 of Proceedings of Machine Learning
Research , pp.5926–5936.PMLR,09–15Jun2019. URL https://proceedings.mlr.press/v97/song19d.
html.
Tejas Srinivasan and Yonatan Bisk. Worst of both worlds: Biases compound in pre-trained vision-and-
language models. In Proceedings of the 4th Workshop on Gender Bias in Natural Language Processing
(GeBNLP) , pp. 77–85, Seattle, Washington, July 2022. Association for Computational Linguistics. doi:
10.18653/v1/2022.gebnlp-1.10. URL https://aclanthology.org/2022.gebnlp-1.10 .
Andreas Peter Steiner, Alexander Kolesnikov, Xiaohua Zhai, Ross Wightman, Jakob Uszkoreit, and Lucas
Beyer. How to train your vit? data, augmentation, and regularization in vision transformers. Transactions
on Machine Learning Research , 2022. ISSN 2835-8856. URL https://openreview.net/forum?id=
4nPswr1KcP .
Ilya Sutskever, James Martens, George Dahl, and Geoffrey Hinton. On the importance of initialization and
momentum in deep learning. In Sanjoy Dasgupta and David McAllester (eds.), Proceedings of the 30th
International Conference on Machine Learning , volume 28 of Proceedings of Machine Learning Research ,
pp. 1139–1147, Atlanta, Georgia, USA, 17–19 Jun 2013. PMLR. URL https://proceedings.mlr.press/
v28/sutskever13.html .
Zhan Tong, Yibing Song, Jue Wang, and Limin Wang. Videomae: Masked autoencoders are data-efficient
learners for self-supervised video pre-training. Advances in neural information processing systems , 35:
10078–10093, 2022.
Lifu Tu, Garima Lalwani, Spandana Gella, and He He. An empirical study on robustness to spurious
correlations using pre-trained language models. Transactions of the Association for Computational
Linguistics , 8:621–633, 2020. doi: 10.1162/tacl_a_00335. URL https://aclanthology.org/2020.
tacl-1.40 .
17Published in Transactions on Machine Learning Research (02/2024)
Catherine Wah, Steve Branson, Peter Welinder, Pietro Perona, and Serge Belongie. The caltech-ucsd birds-
200-2011 dataset. 2011.
Olivia Wiles, Sven Gowal, Florian Stimberg, Sylvestre-Alvise Rebuffi, Ira Ktena, Krishnamurthy Dj
Dvijotham, and Ali Taylan Cemgil. A fine-grained analysis on distribution shift. In International
Conference on Learning Representations , 2022. URL https://openreview.net/forum?id=Dl4LetuLdyK .
Adina Williams, Nikita Nangia, and Samuel Bowman. A broad-coverage challenge corpus for sentence
understanding through inference. In Proceedings of the 2018 Conference of the North American Chapter
of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers) ,
pp. 1112–1122, New Orleans, Louisiana, June 2018. Association for Computational Linguistics. doi: 10.
18653/v1/N18-1101. URL https://aclanthology.org/N18-1101 .
Tianhe Yu, Saurabh Kumar, Abhishek Gupta, Sergey Levine, Karol Hausman, and Chelsea Finn. Gradient
surgery for multi-task learning. Advances in Neural Information Processing Systems , 33:5824–5836, 2020.
Runtian Zhai, Chen Dan, J Zico Kolter, and Pradeep Kumar Ravikumar. Understanding why generalized
reweighting does not improve over ERM. In The Eleventh International Conference on Learning
Representations , 2023. URL https://openreview.net/forum?id=ashPce_W8F- .
Michael Zhang, Nimit S Sohoni, Hongyang R Zhang, Chelsea Finn, and Christopher Re. Correct-n-
contrast: acontrastiveapproachforimprovingrobustnesstospuriouscorrelations. InKamalikaChaudhuri,
Stefanie Jegelka, Le Song, Csaba Szepesvari, Gang Niu, and Sivan Sabato (eds.), Proceedings of the 39th
International Conference on Machine Learning , volume 162 of Proceedings of Machine Learning Research ,
pp. 26484–26516. PMLR, 17–23 Jul 2022. URL https://proceedings.mlr.press/v162/zhang22z.html .
Bolei Zhou, Agata Lapedriza, Aditya Khosla, Aude Oliva, and Antonio Torralba. Places: A 10 million image
database for scene recognition. IEEE Transactions on Pattern Analysis and Machine Intelligence , 40(6):
1452–1464, 2018. doi: 10.1109/TPAMI.2017.2723009.
18Published in Transactions on Machine Learning Research (02/2024)
A Appendix
A.1 Training Details
ForTprim, we employ a task-specific classification head of a single-layer multi-layer perceptron (MLP). For
Taux, we leverage the pre-trained MLM and MIM heads from BERT and ViT, respectively. We utilize the
embedding of the [CLS] token from the base model through this MLP for classification. To facilitate effective
multitask training, we adopt a task-heterogeneous batching scheme Aghajanyan et al. (2021). This facilitates
the accumulation of gradients across tasks prior to each parameter update, contributing to improved training
efficiency and convergence. Lastly, to ensure proper scaling, the L1 loss is normalized by the number of
parameters in the shared representation.
A.2 Going Beyond the Pre-training Objective
Table 7: Impact of different pre-training objectives on average and worst-group accuracy. Not all auxiliary
tasks can help improve worst-group performance.
Dataset MethodNo Group Annotations Val Group Annotations
Avg Acc WG Acc Avg Acc WG Acc
WaterbirdsERM 95.50.2 80.14.6 94.10.7 85.41.4
+ MIM + L1 95.80.3 83.33.4 95.40.4 87.52.7
+ SimCLR + L1 96.10.3 84.03.4 95.50.7 87.21.6
Civilcomments-SmallERM 83.90.4 51.65.6 81.41.0 67.42.1
+ MLM + L1 84.40.4 53.74.3 82.00.5 69.41.7
+ CLM + L1 83.30.7 50.94.9 81.10.9 67.31.4
Previous works in multitasking with self-supervised objectives suggest that different auxiliary objectives
have disparate impacts on end task performance (Dery et al., 2023). Out of curiosity about the impact of
the choice of auxiliary objective, we explore the impact of going beyond the model’s original pre-training
objective. For the Waterbirds dataset, we experiment with SimCLR – a constrastive prediction task based on
determining whether two distinct augmented images originate from the same base image (Chen et al., 2020).
For BERT experiments on Civilcomments-small, we substitute the standard masked language modeling
(MLM) task with causal language modeling (CLM) as the auxiliary task. From the results in Table 7,
we observe that SimCLR’s performance closely resembles that of the MIM pre-training objective, whereas
CLM shows relatively inferior results compared to MLM. We hypothesize that BERT’s intrinsic bidirectional
attentionmechanismandnon-autoregressivenatureare notideallysuitedforcausallanguagemodeling (Song
et al., 2019), resulting in the model underperforming in our multitask setup. Given the model performance’s
sensitivity to the replacement objective’s choice, we proffer a practical recommendation to practitioners: use
the pre-training objective as the auxiliary task. This aligns with recent work on best practices for fine-tuning
pre-trained models (Goyal et al., 2023).
A.3 Bayes optimal model for dimension-independent reconstruction under noised inputs
ℓ(wi) =1
2E/bracketleftbig
(xi−wi˜xi)2/bracketrightbig
=1
2E/bracketleftig
(xi)2−2wixi˜xi+ (wi˜xi)2/bracketrightig
∂ℓ(wi)
∂wi=−E[xi˜xi] +wiE/bracketleftig
(˜xi)2/bracketrightig
19Published in Transactions on Machine Learning Research (02/2024)
The optimal weighting w∗
iis achieved when∂ℓ(wi)
∂wi= 0.
w∗
i=E[xi˜xi]
E/bracketleftig
(˜xi)2/bracketrightig
=E[xi(xi+ϵi)]
E/bracketleftig
(xi+ϵi)2/bracketrightig
=E/bracketleftbig
(xi)2/bracketrightbig
+E[xi]E[ϵi]
E[(xi)2] + 2E[xi]E[ϵi] +E[(ϵi)2]
noteE[ϵi] = 0,E/bracketleftbig
(xi)2/bracketrightbig
=σ2
i+ 0.5/parenleftig
µ2
i|y=1+µ2
i|y=−1/parenrightig
=σ2
i+ 0.5/parenleftig
µ2
i|y=1+µ2
i|y=−1/parenrightig
σ2
i+ 0.5/parenleftig
µ2
i|y=1+µ2
i|y=−1/parenrightig
+σ2
noise
B Broader Impact Statement
In terms of broader impact, our work has beneficial implications for group fairness and mitigating
demographic-basedbiasinmachinelearningsystems. Specifically, wepresenta simple approachtoimproving
worst-case group error. This means that our work contributes positively to certain groups that would
otherwise be impacted by the poor performance of ML models. We have also provided a new lens from
which to view the problem of the impacts of multitasking, resulting in showing that it is tool able against
poor group-based outcomes. However, our method introduces compute overhead due to the optimization
of multiple objectives. This results in increased power consumption and, thus, greenhouse emissions during
the training of models. Nevertheless, introducing our simple regularization modification to existing MTL
implementations represents a negligible technical overhead than introducing JTT or BR-DRO to target
worst-group error.
Table 8: Sensitivity analysis of all the methods to different hyperparameters wrt worst-group accuracy.
Dataset Method Seed Learning Rate Batch Size Up T λauxλreg
WaterbirdsERM 0.0734 0 .5717−0.4384− − − −
JTT 0.0573− − 0.380 0.0246 0.1862− −
ERM + MT + L1 −0.0314− 0.0142− − 0.0943 0.4114
groupDRO −.1688 0 .196−0.1384− − − −
Civilcomments-SmallERM 0.0617−0.8 0 .1029− − − −
JTT−0.0315− 0.2104−0.0047 0.1111− −
ERM + MT + L1 0.0677− 0.0453− − 0.0601−0.2955
groupDRO −0.0392−0.7352−0.1726− − − −
Sensitivity to Hyperparameters: For evaluating the sensitivity of worst group accuracy to various
hyperparameters across different methods, we employ Kendall’s rank coefficient τKendall (1938). To
adhere to our computation budget, we opt for the optimal learning rate utilized in ERM for both JTT
and ERM+MT+L1. Our sensitivity analysis from Table 8 reveals distinct preferences in learning rates. The
ViT model applied to waterbirds, demonstrating a preference for higher learning rates. Conversely, when
trained on the civilomments-small dataset, BERT exhibits a preference for lower learning rates. The epoch
at upsampling is also a sensitive hyperparameter for JTT. The sensitivity to different seed values is negligible
across all the methods. Notably, our method displays the most minor sensitivity to changes in batch size.
However, it is noteworthy that our method is most responsive to variations in the regularization parameter
(λreg), with lower values resulting in higher worst group accuracy.
20