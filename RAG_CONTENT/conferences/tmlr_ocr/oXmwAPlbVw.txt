Published in Transactions on Machine Learning Research (02/2023)
U-Statistics for Importance-Weighted Variational Inference
Javier Burroni jburroni@cs.umass.edu
University of Massachusetts Amherst
Kenta Takatsu‡ktakatsu@andrew.cmu.edu
Carnegie Mellon University
Justin Domke domke@cs.umass.edu
University of Massachusetts Amherst
Daniel Sheldon sheldon@cs.umass.edu
University of Massachusetts Amherst
Reviewed on OpenReview: https: // openreview. net/ forum? id= oXmwAPlbVw
Abstract
We propose the use of U-statistics to reduce variance for gradient estimation in importance-
weighted variational inference. The key observation is that, given a base gradient estimator
that requires m > 1samples and a total of n > msamples to be used for estimation,
lower variance is achieved by averaging the base estimator on overlapping batches of size m
than disjoint batches, as currently done. We use classical U-statistic theory to analyze the
variance reduction, and propose novel approximations with theoretical guarantees to ensure
computational eﬃciency. We ﬁnd empirically that U-statistic variance reduction can lead
to modest to signiﬁcant improvements in inference performance on a range of models, with
little computational cost.
1 Introduction
An important recent development in variational inference (VI) is the use of ideas from Monte Carlo sampling
to obtain tighter variational bounds (Burda et al., 2016; Maddison et al., 2017; Le et al., 2018; Naesseth et al.,
2018; Domke & Sheldon, 2019). Burda et al. (2016) ﬁrst introduced the importance-weighted autoencoder
(IWAE), a deep generative model that uses the importance-weighted evidence lower bound (IW-ELBO) as its
variationalobjective. TheIW-ELBOuses msamplesfromaproposaldistributiontoboundthelog-likelihood
more tightly than the conventional evidence lower bound (ELBO), which uses only 1sample. Later, the
IW-ELBO was also connected to obtaining better approximate posterior distributions for pure inference
applications of VI (Cremer et al., 2017; Domke & Sheldon, 2018), or “IWVI”. Similar connections were made
for other variational bounds (Naesseth et al., 2018; Domke & Sheldon, 2019).
The IW-ELBO is attractive because, under certain assumptions [see Burda et al. (2016); Domke & Sheldon
(2018)], it gives a tunable knob to make VI more accurate with more computation. The most obvious
downside is the increased computational cost (up to a factor of m) to form a single estimate of the bound
anditsgradients. Amoresubtletradeoﬀisthatthesignal-to-noiseratioofsomegradientestimatorsdegrades
withm(Rainforth et al., 2018), which makes stochastic optimization of the bound harder and might hurt
overall inference performance.
To take advantage of the tighter bound while controlling variance, one can average over rindependent
replicates of a base gradient estimator (Rainforth et al., 2018). This idea is often used in practice and
requires a total of n=rmsamples from the proposal distribution.
‡Work done while at UMass.
1Published in Transactions on Machine Learning Research (02/2023)
Our main contribution is the observation that, whenever using r > 1replicates, it is possible to reduce
variance with little computational overhead using ideas from the theory of U-statistics. Speciﬁcally, instead
of running the base estimator on rindependent batches of msamples from the proposal distribution and
averaging the result, using the same n=rmsamples we can run the estimator on k>roverlapping batches
ofmsamples and average the result. In practice, the extra computation from using more batches is a small
fraction of the time for model computations that are already required to be done for each of the nsamples.
Speciﬁcally:
•We describe how to take an m-sample base estimator for the IW-ELBO or its gradient and reduce
variance compared to averaging over rreplicates by forming a complete U-statistic , which averages the
base estimator applied to every distinct batch of size m. This estimator has the lowest variance possible
among estimators that average the base estimator over diﬀerent batches, but it is usually not tractable
in practice due to the very large number of distinct batches.
•We then show how to achieve most of the variance reduction with much less computation by using
incomplete U-statistics , which average over a smaller number of overlapping batches. We introduce a
novel way of selecting batches and prove that it attains a (1−1//lscript)fraction of the possible variance
reduction with k=/lscriptrbatches.
•As an alternative to incomplete U-statistics, we introduce novel and fast approximations for IW-ELBO
complete U-statistics. The extra computational step compared to the standard estimator is a single sort
of theninput samples, which is very fast. We prove accuracy bounds and show the approximations
perform very well, especially in earlier iterations of stochastic optimization.
•We demonstrate on a diverse set of inference problems that U-statistic-based variance reduction for the
IW-ELBO either does not change, or leads to modest to signiﬁcant gains in black-box VI performance,
with no substantive downsides. We recommend always applying these techniques for black-box IWVI
withr>1.
•WeempiricallyshowthatU-statistic-basedestimatorsalsoreducevarianceduringIWAEtrainingandlead
to models with higher training objective values when used with either the standard gradient estimator or
the doubly-reparameterized gradient (DReG) estimator (Tucker et al., 2018).
2 Importance-Weighted Variational Inference
Assume a target distribution p(z,x)wherex∈RdXis observed and z∈RdZis latent. VI uses the following
evidencelowerbound(ELBO),givenapproximatingdistribution qφwithparameters φ∈Rdφ, toapproximate
lnp(x)(Saul et al., 1996; Blei et al., 2017):
L=E/bracketleftbigg
lnp(Z,x)
qφ(Z)/bracketrightbigg
≤lnp(x), Z∼qφ.
The inequality follows from Jensen’s inequality and the fact that E/bracketleftBig
p(Z,x)
qφ(Z)/bracketrightBig
=p(x), that is, the importance
weightp(Z,x)
qφ(Z)is an unbiased estimate of p(x).
Burda et al. (2016) ﬁrst showed that a tighter bound can be obtained by using the average of mimportance
weights within the logarithm. The importance-weighted ELBO ( IW-ELBO ) is
Lm=E/bracketleftBig
ln1
mm/summationdisplay
i=1p(Zi,x)
qφ(Zi)/bracketrightBig
≤lnp(x), Ziiid∼qφ. (1)
This bound again follows from Jensen’s inequality and the fact that1
m/summationtextm
i=1p(Zi,x)
qφ(Zi), which is the sample
average of munbiased estimates, remains unbiased for p(x). Moreover, we expect Jensen’s inequality to
provide a tighter bound because the distribution of this sample average is more concentrated around p(x)
than the distribution of one estimate. Indeed, Lm≥Lm/primeform>m/primeandLm→lnp(x)asm→∞(Burda
et al., 2016).
2Published in Transactions on Machine Learning Research (02/2023)
In importance-weighted VI (IWVI), the IW-ELBO Lmis maximized with respect to the variational param-
etersφto obtain the tightest possible lower bound to lnp(x), which simultaneously ﬁnds an approximating
distribution that is close in KL divergence to p(z|x)(Domke & Sheldon, 2018). In practice, the IW-ELBO
and its gradients are estimated by sampling within a stochastic optimization routine. It is convenient to
deﬁne the log-weight random variables Vi= lnp(Zi,x)−lnqφ(Zi)forZi∼qφand rewrite the IW-ELBO as
Lm=E[h(V1:m)], h (v1:m) = ln1
mm/summationdisplay
i=1evi. (2)
Then, an unbiased IW-ELBO estimate with rreplicates, using n=rmi.i.d. log-weights (Vj,i)r,m
j=1,i=1is
ˆLn,m=1
rr/summationdisplay
j=1h(Vj,1,...,Vj,m). (3)
InˆLn,m, we use the subscript nto denote the total number of input samples used for estimation and mfor
the number of arguments of h, which determines the IW-ELBO objective to be optimized.
For gradient estimation, an unbiased estimate for the IW-ELBO gradient ∇φLmis:
ˆGn,m=1
rr/summationdisplay
j=1g(Zj,1,...,Zj,m), Zj,iiid∼qφ, (4)
whereg(z1:m)is any one of several unbiased “base” gradient estimators that operates on a batch of msamples
fromqφ, includingthereparameterizationgradientestimator(Kingma&Welling,2013;Rezendeetal.,2014),
the doubly-reparameterized gradient (DReG) estimator (Tucker et al., 2018), or the score function estimator
(Fu, 2006; Kleijnen & Rubinstein, 1996).
2.1 IWVI Tradeoﬀs: Bias, Variance, and Computation
Past research has shown that by using a tighter variational bound, IWVI can improve both learning and
inference performance, but also introduce tradeoﬀs such as those pointed out by Rainforth et al. (2018). In
fact, there are several knobs to consider when using IWVI that control its bias, variance, and amount of
computation. These tradeoﬀs can be complex so it is helpful to review the key elements as they relate to
our setting, with the goal of understanding when and how IWVI can be helpful and providing self-contained
evidence that the setting where U-statistics are beneﬁcial can and does arise in practice.
Consider the task of maximizing an IW-ELBO objective Lmto obtain the tightest ﬁnal bound on the log-
likelihood. This requires estimating Lmand its gradient with respect to the variational parameters in each
iteration of a stochastic optimization procedure. Assume there is a ﬁxed budget of nindependent samples
per iteration, where, for convenience, n=rmfor an integer r≥1, as above. The parameters mandrcan
be adjusted to control the estimation bias and variance at the cost of increased computation. Speciﬁcally:
•For a ﬁxed m, by setting r/prime>r, we can reduce the variance of the estimator in Equation (4) by increasing
the computational cost to r/primem>rm samples per iteration.
•For a ﬁxed r, by setting m/prime>mwe can reduce the bias of the objective — that is, the gap in the bound
Lm/prime≤lnp(x)— by increasing the computational cost to rm/prime>rmsamples per iteration.
However, Rainforth et al. (2018) observed that increasing mmay also have the negative eﬀect of worsening
the signal-to-noise (SNR) ratio of gradient estimation (but also that this could be counterbalanced by
increasingr). Later, Tucker et al. (2018) showed that, for the DReG gradient estimator, increasing m
canincrease SNR; see also the paper by (Finke & Thiery, 2019) for a detailed discussion of these issues.
Overall, while the eﬀect of increasing the number of replicates rto reduce variance is quite clear, the eﬀects
of increasing mare suﬃciently complex that it is diﬃcult to predict in advance when it will be beneﬁcial.
3Published in Transactions on Machine Learning Research (02/2023)
2 8 32 128
m2.002.252.502.753.003.253.503.754.00error1e5
n
16
32
64
128
256
Figure 1: Distribution of the distance (error) between
the distribution’s covariance and that of the approx-
imating distribution as a function of mfor diﬀerent
numbersofsampledpoints n, aftertraininganapprox-
imating distribution using the standard IW-ELBO es-
timator. As we increase n, the optimal malso in-
creases, but at a slow rate. [See Section 6 for details.]However, an important premise of our work is that
the optimal setting of mis often strictly between
1andn, since this is the setting where U-statistics
can be used to reduce variance. To understand this,
we can ﬁrst reason from the perspective of a user
that is willing to spend more computation to get
a better model. Assuming the variational bound is
not already tight, this user can increase mas much
as desired to tighten the bound, and then, increase
ras needed to control the gradient variance. This
argument predicts that, for a suﬃciently large com-
putational budget and complex enough model (so
that the bound is not already tight with m= 1), a
valuem> 1will often be optimal.
From the perspective of a user with ﬁxed computa-
tional budget, in which the number of optimization
iterations is also being ﬁxed, we could instead ask:
“for a ﬁxed n, what are the optimal choices of m
andr=n/m”? This question can be addressed em-
pirically. Rainforth et al. (2018) reported in their
Figure 6 that the extreme values, i.e., m= 1or
m=n, were never the best values. We found empirically that for some models, this result also holds for
black box VI, i.e., the optimal choice of mis strictly greater than 1and less than n, as shown in Figure 1.
See also Figure 5, which shows that similar observations apply when using the DReG estimator. In our
analysis of 17 real Stan and UCI models, with n= 16, around half of them achieved the best performance
for an intermediate value of m, depending on the approximating distribution and base gradient estimator
[see Table 8 and 9 in Appendix G]. And we further conjecture that the fraction of real-world models with
this property will increase as nincreases.
For the rest of this work we focus on methods that can reduce variance for the case when 1<m<n .
3 U-Statistic Estimators
We now introduce estimators for the IW-ELBO and its gradients based on U-statistics, and apply the theory
of U-statistics to relate their variances. The theory of U-statistics was developed in a seminal work by
Hoeﬀding (1948) and extends the theory of unbiased estimation introduced by Halmos (1946). For detailed
background, see the original works or the books by Lee (1990) and van der Vaart (2000).
The standard estimators in Eqs. (3) and (4) average the base estimators h(v1:m)andg(z1:m)on disjoint
batches of the input samples. The key insight of U-statistics is that variance can be reduced by averaging
the base estimators on a larger number of overlapping sets of samples.
We will consider general IW-ELBO estimators of the form
ˆLS(v1:n) =1
|S|/summationdisplay
s∈Sh(vs1,...,vsm), (5)
whereSis any non-empty collection of size- msubsets of the indices JnK:={1,...,n}, andsiis theith
smallest index in the set s∈ S. Since Eh(V1:m) =Lm, it is clear (by symmetry and linearity) that
EˆLS(V1:n) =Lm, that is, the estimator is unbiased. For now, we will call this a “U-statistic with kernel h”,
as it is clear the same construction can be generalized by replacing hby any other symmetric function of
mvariables1, or “kernel”, while preserving the expected value. Later, we will distinguish between diﬀerent
types of U-statistics based on the collection S.
1Recall that a symmetric function is a function invariant under all permutations of its arguments.
4Published in Transactions on Machine Learning Research (02/2023)
We can form U-statistics for gradient estimators by using base gradient estimators as kernels. Let g(z1:m)
be any symmetric base estimator such that Eg(Z1:m) =∇φLm. The corresponding U-statistic is
ˆGS(Z1:n) =1
|S|/summationdisplay
s∈Sg(Zs1,...,Zsm) (6)
and satisﬁes EˆGS(Z1:n) =∇φLm.
3.1 Variance Comparison
How much variance reduction is possible for IWVI by using U-statistics? In this section, we ﬁrst deﬁne the
standard IW-ELBO estimator andcomplete U-statistic IW-ELBO estimator , and then relate their variances.
For concreteness, we restrict our attention to IW-ELBO objective estimators, but analagous results hold for
gradients by using a base gradient estimator as the kernel of the U-statistic.
We ﬁrst express the standard IW-ELBO estimator ˆLn,min the terminology of Eq. (5):
Estimator 1. Thestandard IW-ELBO estimator ˆLn,mof Eq. (3) is the U-statistic ˆLSformed by taking S
to be a partition of JnKinto disjoint sets, i.e., S=/braceleftbig
{1,...,m},{m+1,..., 2m},...,{(r−1)m+1,...,rm}/bracerightbig
.
Estimator 2. Thecomplete U-statistic IW-ELBO estimator ˆLU
n,mis the U-statistic ˆLSwithS=/parenleftbigJnK
m/parenrightbig
, the
set of all distinct subsets of JnKwith exactly melements.
We will show that the variance of the ˆLU
n,mis never more than that of ˆLn,m, and is strictly less under certain
conditions (that occur in practice), using classical bounds on U-statistic variance due to Hoeﬀding (1948).
Since ˆLU
n,mis an average of terms, one for each s∈/parenleftbigJnK
m/parenrightbig
, its variance depends on the covariances between
pairs of terms for index sets sands/prime, which in turn depend on how many indices are shared by sands/prime.
This motivates the following deﬁnition:
Deﬁnition 3.1. LetV1,...,V 2mbei.i.d.log-weights. For 0≤c≤m, take s,s/prime∈/parenleftbigJ2mK
m/parenrightbig
with|s∩s/prime|=c.
UsinghfromEq. (2), deﬁne
ζc= Cov/bracketleftBig
h(Vs1,...,Vsm), h(Vs/prime
1,...,Vs/primem)/bracketrightBig
,
which depends only on cand not the particular sands/prime.
Inwords, thisisthecovariancebetweentwoIW-ELBOestimates, eachusingonebatchof mi.i.d.log-weights,
and where the two batches share clog-weights in common. For example, when m= 2we have
ζ0= 0, ζ 1= Cov[ln(1
2eV1+1
2eV2),ln(1
2eV1+1
2eV3)],and, ζ 2= Var[ln(1
2eV1+1
2eV2)].
Then, due to Hoeﬀding’s classical result,
Proposition 3.2. Withζ1, andζmdeﬁned as above, the standard IW-ELBO estimator ˆLn,m(Estimator 1)
and complete U-statistic estimator (Estimator 2) withn=rmandr∈Nsatisfy
m2
nζ1≤Var[ˆLU
n,m]≤m
nζm= Var[ ˆLn,m].
Moreover, for a ﬁxed m, the quantity nVar[ˆLU
n,m]tends to its lower bound m2ζ1asnincreases.
Proof.The inequalities and asymptotic statement follow directly from Theorem 5.2 of Hoeﬀding (1948). The
equality follows from the deﬁnition of ζm.
Hoeﬀding proved that mζ1≤ζm. We observe in practice that there is a gap between the two variances that
leads to practical gains for the complete U-statistic estimator in real VI problems.
A classical result of Halmos (1946) also shows that complete U-statistics are optimal in a certain sense: we
describe how this result applies to estimator ˆLU
n,min Appendix B.
5Published in Transactions on Machine Learning Research (02/2023)
Finally, we conclude this discussion by stating the main analogue of Proposition 3.2 for gradient estimation.
The result, also following from Theorem 5.2 of Hoeﬀding (1948), states that the complete U-statistic gradient
estimator has total variance and expected squared norm no larger than that of the standard estimator:
Proposition 3.3. LetˆGn,mand ˆGU
n,mbe the standard and complete-U-statistic gradient estimators formed
using a symmetric base gradient estimator g(z1:m)that is unbiased for ∇φLmand the same index sets as
ˆLn,mand ˆLU
n,m, respectively. Then tr(Var[ ˆGU
n,m])≤tr(Var[ ˆGn,m])andE/bardblˆGU
n,m/bardbl2
2≤E/bardblˆGn,m/bardbl2
2.
We provide a proof in Appendix B.1.
3.2 Computational Complexity
There are two main factors to consider for the computational complexity of an IW-ELBO estimator:
1) The cost to compute nlog-weights Vi= lnp(Zi,x)−lnq(Zi)fori∈JnK, and
2) the cost to compute the estimator given the log-weights.
A problem with the complete U-statistics ˆLU
n,mand ˆGU
n,mis that they use/vextendsingle/vextendsingle/parenleftbigJnK
m/parenrightbig/vextendsingle/vextendsingle=/parenleftbign
m/parenrightbig
distinct subsets
of indices in Step 2), which is expensive. It should be noted that these log-weight manipulations are very
simple, while, for many probabilistic models, computing each log-weight is expensive, so, for modest mand
n, the computation may still be dominated by Step 1). However, for large enough mandn, Step 2) is
impractical.
4 Incomplete U-Statistic Estimators
In practice, we can achieve most of the variance reduction of the complete U-statistic with only modest
computational cost by averaging over only k/lessmuch/parenleftbign
m/parenrightbig
subsets of indices selected in some way. Such an
estimator is called an incomplete U-statistic . Incomplete U-statistics were introduced and studied by Blom
(1976).
A general incomplete U-statistic for the IW-ELBO has the form in Eq. (5) where S(/parenleftbigJnK
m/parenrightbig
is a collection
of size-msubsets of JnKthat does not include every possible subset. We will also allow Sto be a multi-set,
so that the same subset may appear more than once. Note that the standard IW-ELBO estimator ˆLn,mis
itself an incomplete U-statistic, where the k=r=n
mindex sets are disjoint. We can improve on this by
selectingk>rsets.
Estimator 3 (Random subsets) .Therandom-subset incomplete-U-statistic estimator for the IW-ELBO is
the estimator ˆLSkwhereSkis a set ofksubsets (si)k
i=1drawn uniformly at random (with replacement) from/parenleftbigJnK
m/parenrightbig
.
We next introduce a novel incomplete U-statistic, which is both very simple and enjoys strong theoretical
properties.
Estimator 4 (Permuted block) .The permuted block estimator is computed by repeating the standard
IW-ELBO estimator /lscripttimes with randomly permuted log-weights and averaging the results. Formally, the
permuted-block incomplete-U-statistic estimator for the IW-ELBO is the estimator ˆLS/lscript
Πwith the collection
S/lscript
Πdeﬁned as follows. Let πdenote a permutation of JnK. DeﬁneSπas the collection obtained by permuting
indices according to πand then dividing them into rdisjoint sets of size m. That is,
Sπ=/braceleftBig/braceleftbig
π(1),π(2),...,π (m)/bracerightbig
,/braceleftbig
π(m+ 1),...,π (2m)/bracerightbig
,...,/braceleftbig
π/parenleftbig
(r−1)m+ 1/parenrightbig
,...,π (rm)/bracerightbig/bracerightBig
.
Now, letS/lscript
Π=/unionmultitext
π∈ΠSπwhere Πis a collection of /lscriptrandom permutations and/unionmultitextdenotes union as a multiset.
The total number of sets in S/lscript
Πisk=r/lscript.
Both incomplete-U-statistic estimators can achieve variance reduction in practice for a large enough number
of setsk, but the permuted block estimator has an advantage: its variance with ksubsets is never more
than that of the random subset estimator with ksubsets, and never more than the variance of the standard
6Published in Transactions on Machine Learning Research (02/2023)
IW-ELBO estimator (and usually smaller). On the other hand, the variance of the random subset estimator
is more than that of the standard estimator unless k≥k0for some threshold k0>r.
Proposition 4.1. Givenmandn=rm, the variances of these estimators satisfy the following partial
ordering:
Var[ˆLU
n,m]
/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
complete(a)
≤Var[ˆLS/lscript
Π]
/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
permuted block(b)
≤standard/bracehtipdownleft/bracehtipupright/bracehtipupleft/bracehtipdownright
Var[ˆLn,m]
≤
(c)Var[ˆLSr/lscript]/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
random subset.(7)
Moreover, if the number of permutations /lscript>1andVar[ˆLU
n,m]<Var[ˆLn,m], then(b)is strict; if r=n
m>1,
then(c)is strict. (Note that the permuted and random subset estimators both use k=r/lscriptsubsets.)
Proof.By Def. 3.1, if sands/primeare uniformly drawn from/parenleftbigJnK
m/parenrightbig
andκ=/vextendsingle/vextendsingle/parenleftbigJnK
m/parenrightbig/vextendsingle/vextendsingle, we have
E[ζ|s∩s/prime|] =/summationdisplay
s,s/prime∈(JnK
m)ζ|s∩s/prime|
κ2=/summationdisplay
s,s/prime∈(JnK
m)E[h(Vs1,...,Vsm)h(Vs/prime
1,...,Vs/primem)]
κ2−E[ˆLU
n,m]2= Var[ ˆLU
n,m].(8)
Letπ1,...,π/lscriptbe the random permutations. Observe that for s,s/prime∈Sπidistinct, i.e., two distinct sets within
theith block, sands/primeare disjoint and then h(Vs1,...,Vsm)is independent of h(Vs/prime
1,...,Vs/primem). Hence, all
dependencies between diﬀerent sets are due to relations between permutations, i.e., each of the /lscriptrterms will
have a dependency with the (/lscript−1)rterms not in the same permutation. Therefore, it follows from (8) that
the total variance of ˆLS/lscript
Πis
Var[ˆLS/lscript
Π] =1
/lscriptrζm+ (1−1
/lscript) Var[ ˆLU
n,m], (9)
i.e., a convex combination of1
rζm= Var[ ˆLn,m]andVar[ˆLU
n,m]. Hence, using Proposition 3.2, (a) and (b)
holds.
By a similar argument, the total variance of ˆLSr/lscriptis
Var[ˆLSr/lscript] =1
/lscriptrζm+ (1−1
r/lscript) Var[ ˆLU
n,m].
Then, (c) holds because
Var[ˆLS/lscript
Π]−Var[ˆLSr/lscript] =1
/lscript(1
r−1) Var[ ˆLU
n,m]≤0.
A remarkable property of the permuted-block estimator is that we can choose the number of permutations /lscript
to guarantee what fraction of the variance reduction of the complete estimator we want to achieve. Say we
would like to achieve 90%of the variance reduction; then it suﬃces to set /lscript= 10. The following Proposition
formalizes this result.
Proposition 4.2. Givenmandn=rm, for/lscript∈Nthe permuted-block estimator achieves a (1−1//lscript)fraction
of the variance reduction provided by the complete U-statistic IW-ELBO estimator, i.e.,
Var[ˆLn,m]
/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
standard−Var[ˆLS/lscript
Π]
/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
permuted block= (1−1
/lscript)( Var[ ˆLn,m]
/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
standard−Var[ˆLU
n,m]
/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
complete).
Proof.This follows directly from Eq. (9).
The conclusions of Propositions 4.1 and 4.2 do not depend on the kernel. This means they provide strong
guarantees for our novel and simple permuted-block incomplete U-statistic with anykernel, which may be
of general interest, and also imply the following result for gradients:
Proposition 4.3. The conclusion of Proposition 4.2 holds with Var[ˆL]replaced by either E[/bardblˆG/bardbl2
2]or
tr([Var[ ˆG]), for each pair (ˆL,ˆG)of objective estimator and gradient estimator that use the same collection S
of index sets, and for any base gradient estimator g(v1:m).
7Published in Transactions on Machine Learning Research (02/2023)
5 Eﬃcient Lower Bounds
In the last section, we approximated the complete U-statistic by averaging over k/lessmuch/parenleftbign
m/parenrightbig
subsets. For
example, by Proposition 4.2, we could achieve 90% of the variance reduction with 10 ×more batches than
the standard estimator, and the extra running-time cost is often very small in practice. An even faster
alternative is to approximate the kernel in such a way that we can compute the complete U-statistic without
iterating over subsets. In this section, we introduce such an approximation for the IW-ELBO objective,
where the extra running-time cost is a single sort of the nlog-weights, which is extremely fast. Furthermore,
Proposition 5.2 below will show that it is always a lower bound to ˆLU
n,mand has bounded approximation
error, so its expectation lower bounds Lmandlnp(x); thus, it can be used as a surrogate objective within
VI that behaves well under maximization. We then introduce a “second-order” lower bound, which has
provably lower error. Unlike the last two sections, these approximations do not have analogues for arbitrary
gradient estimators such as DReG or score function estimators. For optimization, we use reparameterization
gradients of the surrogate objective.
Estimator 5. Theapproximate complete U-statistic IW-ELBO estimator is
ˆLA
n,m(V1:n) =/parenleftbiggn
m/parenrightbigg−1/summationdisplay
s∈(JnK
m)max(Vs1,...,Vsm)−lnm.
Thisestimatorusestheapproximation ln/summationtextm
i=1evi≈max{v1,...,vm}forlog-sum-exp. ThefollowingPropo-
sition shows that we can compute ˆLA
n,mexactlywithout going over the/parenleftbign
m/parenrightbig
subsets but instead taking only
O(nlnn)time. The intuition is that each of the nlog-weights will be a maximum element of some number
of size-msubsets, and each such term in the summation for ˆLA
n,mwill be the same. Moreover, we can reason
in advance how many times each log-weight will be a maximum.
Proposition 5.1. For anyv1:n∈Rn, it holds that
ˆLA
n,m(v1:n)≡/parenleftbiggn
m/parenrightbigg−1n/summationdisplay
i=1biv[i]−lnm,
wherebi=/parenleftbign−i
m−1/parenrightbig
, ifi∈Jn−(m−1)K(and 0otherwise), and [·]:JnK→JnKis a permutation s.t., the
sequence of log-weights v[1],...,v [n]is non-increasing.
Proof.Fors∈/parenleftbigJnK
m/parenrightbig
, let vs= (vs1,...,vsm). We can see that max vs=v[i]whereiis the smallest index in
s. Thus,
/summationdisplay
s∈(JnK
m)max vs=n/summationdisplay
i=1biv[i],
wherebiis the number of sets s∈/parenleftbigJnK
m/parenrightbig
with minimum index equal to i. The conclusion follows because
there aren−iindices larger than i, but we can take m−1of them only when i∈Jn−(m−1)K.
To further understand both the computational simpliﬁcation and the quality of this approximation, con-
sider this real example of computing the (non-approximate) complete U-statistic IW-ELBO estimator ˆLU
4,2.
Suppose that the sampled log-weights are
v= (−6034.091,−4351.335,−4157.236,−5419.201).
Given the/parenleftbig4
2/parenrightbig
sets, we can evaluate the kernel h(vi,vj) = ln(evi+evj)−ln 2on each of them to generate the
following table:
8Published in Transactions on Machine Learning Research (02/2023)
(vi,vj) h(vi,vj)
(−6034.091,−4351.335)−4352.028
(−6034.091,−4157.236)−4157.930
(−6034.091,−5419.201)−5419.895
(−4351.335,−4157.236)−4157.930
(−4351.335,−5419.201)−4352.028
(−4157.236,−5419.201)−4157.930
Mean −4432.956
At three decimal points of precision, we see that h(vi,vj) = max(vi,vj) + ln 2and therefore−4157.930,
−4352.028, and−5419.895each appear/parenleftbig3
1/parenrightbig
times,/parenleftbig2
1/parenrightbig
times, and once, respectively.
0 2000 4000 6000 8000 10000
iterations−600−500−400−300−200objective standard IW
permuted
mean diﬀerence
0 500 1000 1500 2000
iterations−60−50−40−30objective
−32−30
0 1000 2000 3000 4000 5000
iterations−1300−1250−1200−1150objective
−1160−1150
Figure 2: Median envelope of the objective using the permuted-block and standard IW-ELBO estimators
for the mushrooms (left), mesquite (center) and electric-one-pred (right) models. In all cases we used
n= 16andm= 8. For reference there is a line segment of length similar to the average objective diﬀerence,
respectively, 202.08,0.97, and−3.91.
5.1 Accuracy and Properties of the Approximation
It is straightforward to derive both upper and lower bounds of the complete U-statistic IW-ELBO estimator
ˆLU
n,mfrom this approximation.
Proposition 5.2. For any set of log-weights v1:n∈Rn, it holds that
ˆLA
n,m(v1:n)≤ˆLU
n,m(v1:n)≤ˆLA
n,m(v1:n) + lnm. (10)
Moreover, the ﬁrst inequality is strict unless m= 1. On the other hand, the second inequality is an equality
when all log-weights are equal.
Proof.Thisisadirectapplicationofwell-knowninequalitiesforlog-sum-exp. Let h(v1,...,vm) = ln/summationtextM
i=1evi
andf(v1,...,vm) = max{v1,...,vm}. Then, for all v1:m∈Rm,
f(v1:m)≤h(v1:m)≤f(v1:m) + lnm. (11)
To see this, write ˆv= max{v1,...,vm}. Then,
1
meˆv≤1
mm/summationdisplay
j=1evj≤eˆv. (12)
Eq. (11) follows from applying lnto (12). Eq. (10) then follows from (11) and the deﬁnitions of ˆLA
n,mand
ˆLU
n,m.
One comment about the approximation quality is in order: in the limit as the variance of the log-weights de-
creases, the second inequality in the bounds above becomes tight, and the approximation error of ˆLA
n,m(v1:n)
approaches its maximum lnm. This can be seen during optimization when maximizing the IW-ELBO, which
tends to reduce log-weight variance [cf. Figure 4].
9Published in Transactions on Machine Learning Research (02/2023)
5.2 Second-Order Approximation
Based on our understanding of the approximation properties of ˆLA
n,m, we can add a correction term to obtain
a second-order approximation.
Estimator 6. For2≤m≤n, thesecond-order approximate complete-U-statistic IW-ELBO estimator is
ˆLA,2
n,m(V1:n) =ˆLA
n,m(V1:n) +/parenleftbign
m/parenrightbig−1n−(m−1)/summationdisplay
i=1˜biln(1 +e∆V[i]), (13)
where ∆V[i]=V[i+1]−V[i]and˜bi=/parenleftbign−1−i
m−2/parenrightbig
.
This can still be computed in O(nlnn)time and gives a tighter approximation than ˆLA
n,m.
Proposition 5.3. For allv1:n∈Rn,
ˆLA
n,m(v1:n)<ˆLA,2
n,m(v1:n)≤ˆLU
n,m(v1:n).
Moreover, the second inequality is an equality exactly when m=n= 2.
Proof.The ﬁrst inequality follows directly because the terms in the summation of (13) are positive reals.
For the second inequality, take s∈/parenleftbigJnK
m/parenrightbig
and letibe the smallest index in s. Ifsis one of the/parenleftbign−1−i
m−2/parenrightbig
sets
on whichiis the smallest index and i+ 1∈s, then
1
mev[i](1 +ev[i+1]−v[i]) =ev[i]+ev[i+1]
m≤1
m/summationdisplay
s∈sevs.
Ifi+ 1/negationslash∈s, we know that1
mev[i]≤1
m/summationtextm
j=1evsj. We ﬁnish by applying logarithm to both inequalities and
the deﬁnition of ˆLA
n,mand ˆLU
n,m.
In contrast to ˆLA
n,m, the second-order approximation is not a U-statistic. However, it is a tighter lower-bound
ofˆLU
n,m.
Note 5.4. To use the approximations as an objective, we need them to be diﬀerentiable. If the distribution
ofWis absolutely continuous, then the approximations are almost surely diﬀerentiable because sortis
almost surely diﬀerentiable, with Jacobian given by the permutation matrix it represents [cf. Blondel et al.
(2020)].
6 Experiments
In this section, we empirically analyze the methods proposed in this paper. We do so in three parts: we ﬁrst
study the gradient variance, VI performance, and running time for IWVI in the “black-box” setting2; we
then focus on a case where the posterior has a closed-form solution, using random Dirichlet distributions;
and ﬁnally, we study the performance of the estimators for Importance-Weighted Autoencoders.
For black-box IWVI, we experiment with two kinds of models: Bayesian logistic regression with 5 diﬀerent
UCIdatasets(Dua&Graﬀ,2017)usingbothdiagonalandfullcovarianceGaussianvariationaldistributions,3
and a suite of 12 statistical models from the Stan example models (Stan Development Team, 2021; Carpenter
et al., 2017), with both diagonal (all models) and full covariance Gaussian (10 models4) approximating
2That is, VI that uses only black-box access to lnp(z,x)and its gradients.
3Thatis,p(y|θ) =/producttextN
i=1Bernoulli/parenleftbig
yi; logistic(θTxi)/parenrightbig
forﬁxedxi∈Rdandp(θ) =N(θ;0,σ2Id), andV= lnp(θ,y)−lnq(θ)
forθ∼q(θ)with either q(θ) =N(θ;µ,diag(w))orq(θ) =N(θ;µ,LLT); we optimize over (µ,w)or(µ,L), withwconstrained
to be positive (via exponential transformation) and Lconstrained to be lower triangular with positive diagonal (via softplus
transformation). Parameters were randomly initialized prior to transformations from iid standard Gaussians.
4The irt-multilevel model diverged for all conﬁgurations using a full covariance Gaussian.
10Published in Transactions on Machine Learning Research (02/2023)
distributions. We provide additional information regarding the models in Appendix C. For each model,
the variational parameters were optimized using stochastic gradient descent with ﬁxed learning rate for
15diﬀerent logarithmically spaced learning rates. We used n= 16samples per iteration except for the
running time analysis, and experimented with m∈{2,4,8}. Since this is a stochastic optimization problem,
we ran every combination of model, learning rate, n, andm, using 50diﬀerent random seeds to assess
typical performance. We used the reparameterization gradient estimator as the base gradient estimator, and
also provide in Appendix D and G (very similar) results for the doubly-reparameterized (DReG) gradient
estimator.
complete-U approx.approx. 2nd random subs. permuted0.40.50.60.70.8ratio of grads’ total variance
(a) Ratio of gradient’s total variance.
complete-U approx.approx. 2nd random subs. permuted0.50.60.70.80.91.0ratio of objective’s variance
 (b) Ratio of the objective’s variances.
Figure 3: Ratios of the trace of the variance (i.e., the total variance) of diﬀerent proposed gradient estimators
to that of the standard gradient estimator, and objective’s variances (b) for the mushrooms dataset (d= 96).
All ratios are below 1, which indicates variance reduction. The estimators can be ordered by variance:
the complete-U-statistic estimator and second-order approximation are lowest, followed by the permuted-
block and ﬁrst-order approximation, and ﬁnally the random subsets estimator. Since /lscript= 20, we expect
the permuted-block estimator to achieve 1−1
20= 0.95of the variance reduction; the estimated variance
reduction is 91.24%and95.72%for the objective.
Gradient Variance We ﬁrst conﬁrm empirically that U-statistics reduce the variance of gradients within
IWVI. For each random seed, we performed IWVI using the complete U-statistic ˆLU
n,mfor 10,000 iterations.
Every 200iterations, we computed the gradients, given the values of the parameters at that time, for
each of the alternative gradient estimators: the standard estimator, the complete U-statistic estimator, its
approximations, the permuted-block estimator with /lscript= 20, and the random subsets estimator with k= 20n
m
(a number of sets equal to the permuted version). In all cases we used n= 16andm= 8. For each gradient
estimator ˆG, we estimate the total variance tr(Var[ ˆG])using 200independent gradient samples.
Figure 3–(a) shows the total variance of each estimator as a fraction of that of the standard estimator
(that is, the ratio tr(Var[ ˆG])/tr(Var[ ˆGn,m])) for Bayesian logistic regression with the mushrooms dataset.
The ratios are between 60%and 70%for all methods, with the random subsets estimator showing the
highest variance and the complete U-statistic the lowest. This conﬁrms it is possible to reduce gradient
variance with U-statistics. Moreover, the estimators can be ordered by their gradients’ total variance. The
complete U-statistic estimator and the 2nd order approximation have the smallest variance, the permuted-
block estimator has slightly higher variance, and the random subsets estimator has the highest variance (but
still less than that of the standard estimator). Recall that, according to Prop. 4.2, /lscript= 20implies that the
permuted estimator achieves 95%of the variance reduction provided by the complete-U-statistic IW-ELBO.
In this case, we estimated the variance reduction of the permuted-block estimator to be 91.24%of that
of the complete-U-statistic estimator. We also show the ratio of the objective’s variances in Figure 3–(b).
Most estimators have a ratio of around 80%, but the permuted-block estimator achieves a 95.72%variance
reduction provided by the complete U-statistic estimator.
11Published in Transactions on Machine Learning Research (02/2023)
Table 1: For Bayesian logistic regression (a) and Stan models (b), diﬀerence in nats of the average objective
(higher is better) when trained using the permuted estimator vs. the standard IW-ELBO estimator. The
variational distribution is a Gaussian distribution using either a full rank covariance matrix (ﬁrst column)
or a diagonal one (second column). The entry is “—” when the model diverged for all conﬁgurations, and
NaN when it diverged for the speciﬁc conﬁguration (other conﬁgurations are found in the Appendix).
(a) Bayesian logistic regression models.
Datasetpermuted−standard IW-ELBO
m= 8
Full Covariance Diagonal
a1a 112.42 4.48
australian 3.36 1.38
ionosphere 16.58 0.06
mushrooms 202.56 8.69
sonar 50.62 0.19(b) Stan models.
Datasetpermuted−standard IW-ELBO
m= 8
Full Covariance Diagonal
congress 19.80 7.33
election88 1133.70 6.94
election88Exp NaN 32.76
electric 80.46 4.32
electric-one-pred -3.45 -3.91
hepatitis NaN 0.65
hiv-chr 283.19 15.84
irt 16077.03 1.00
irt-multilevel — 62.32
mesquite 1.41 2.00
radon 268.98 14.83
wells -0.03 -0.11
VI Performance Ultimately, our goal is to provide a more eﬃcient optimization method. To measure typ-
ical stochastic optimization performance, we ﬁrst took the maximum objective value across learning rates in
each iteration to construct the optimization envelope for each method and random seed [cf. Geﬀner & Domke
(2018)]. The purpose of the envelope is to eliminate the learning rate as a nuisance parameter since stochastic
optimization methods are very sensitive to learning rate, and one common beneﬁt of variance reduction is to
allow a larger learning rate. Then, for each method we used the median envelope across the 50 random seeds
as a measure of its typical optimization behavior over iterations. Examples can be seen in Figure 2. As a ﬁnal
metric for each method we computed the average objective value (of the median envelope)across iterations up
to 10,000 iterations,5excluding the ﬁrst 50 iterations, which were highly noisy and sensitive to initialization.
This is a useful summary metric to measure the tendency of one method to “stay ahead” of another (see
the examples in Figure 2). Agrawal et al. (2020) found a similar metric eﬀective for learning rate selection.
Table 2: Times for 1000iterations of optimiza-
tion with diﬀerent estimators on the mushrooms
dataset with n= 24,m= 12, averaged over 100
trials.
MethodTime (s)
Mean Std
ˆL24,12standard IW-ELBO 5.47 0.04
ˆLU
24,12complete U 1573.27 2.12
ˆLS2024
12random subsets 6.49 0.09
ˆL20
SΠpermuted block 6.45 0.09
ˆLA
24,12approx. 5.25 0.02
ˆLA,2
24,12approx. 2nd order 5.54 0.04Table 1 shows the average objective diﬀerence between
the permuted-block and standard IW-ELBO estimators
form= 8, with positive numbers indicating better per-
formance for permuted-block. We focus on permuted-
block here because it consistently achieves an excellent
tradeoﬀ between variance reduction and running time.
In Appendix D we present similar results for two addi-
tional methods—the 2nd order approximation and the
permuted-block estimator with DReG as the base gra-
dient estimator—and for diﬀerent values of m; in Ap-
pendix G we show the median envelopes themselves for
many combinations of models, methods, and m. The ex-
amples in Figure 2 were selected to show cases where the
diﬀerenceisbig(left), small(center),andnegative(right);
to contextualize our summary metric, we also added a ref-
erence vertical bar showing an iteration where the diﬀerence between the two envelopes is approximately
5For some datasets, such as sonar, we observed early convergence by visual inspection and computed the metric only up to
that point. See Figures in Appendix G.
12Published in Transactions on Machine Learning Research (02/2023)
equal to the average objective diﬀerence. These results make it clear that the permuted-block estima-
tor improves the convergence of stochastic optimization for VI across a range of models and settings. In
electric-one-pred , permuted-block was consistently worse, but we veriﬁed that it still had lower-variance
gradients; we speculate this is an unstable model where higher variance gradients help escape local optima.
Running Time Table 2 shows the times required to complete 1000iterations of optimization with diﬀerent
estimators for Bayesian logistic regression with the mushrooms data set, averaged over 100trials. Here we
usedn= 24andm= 12, which makes it a challenging setting for the complete U-statistic estimator,
because there are/parenleftbig24
12/parenrightbig
=2,704,156 sets. As expected, the complete U-statistic is orders of magnitude slower.
The approximations are faster than the standard estimator because the smallest m−1log-weights do not
contribute to the objective, and thus their gradients are not needed. The permuted-block estimator incurs
an extra cost of less than 1 ms per iteration compared to the standard IW-ELBO estimator for this model
(a 18% increase). However, the increased time only depends on m,n, and/lscript, and not on the model. Even for
a very complex model, we would expect the extra time for these settings to be on the order of order of 1 ms
per iteration, and be negligible compared to other costs. For example, for the irt, the standard estimator
took 16.62s(0.11), while the permuted-block estimator took 17.54s(0.12), i.e., a 5% increase.
Incomplete U-Statistics and Approximations Previously, we analyzed the methods by com-
paring them to the standard IW-ELBO estimator. In this part we will use the complete U-
statistics as a baseline: given a realization of log-weights v1,...,vn, we measure the diﬀer-
ence between the objective value assigned by the complete U-statistic and the alternatives. For
this experiment, we will use n= 16,m= 8and the Bayesian logistic regression dataset
mushrooms . In Figure 4 we plot the diﬀerence measured in nats as a function of the iteration
step. From that plot (especially the inset), it is clear that the approximations are underestimators.
0 2000 4000 6000 8000 10000
iterations−20−100102030405060nats−0.50−0.250.000.250.50standard IW
approx.
approx. 2nd
random subsets
permuted
Figure 4: Diﬀerence between estimated value using
any of the methods and that of the complete U-
statistic, in nats, for the mushrooms dataset. (25th
and 75th percentiles shown with dashed lines.) As op-
timization progresses, the error of the incomplete U-
statistics decreases, but the error of the approximation
increases. The inset shows the permuted and both ap-
proximations in a region that is 0.5nats of the target
value.It is also interesting to see the approximations and
the incomplete U-statistic being complementary: as
the optimization progresses, the error of the approx-
imations increases, but the error made by the in-
complete U-statistics decreases. We expected this
result because the variance of the log-weights de-
creases with the optimization. (The upper-bound of
Eq. (10) is achieved when all viare equal; but this is
exactly the case when all the incomplete U-statistics
coincide.)
Dirichlet Experiments We conducted experi-
ments with random Dirichlet distributions as de-
scribed in (Domke & Sheldon, 2018). The goal was
twofold. First, thisisasettingwhereexactinference
is possible, so we can evaluate IWVI with diﬀerent
estimators on the accuracy of posterior inference di-
rectly, instead of using the IW-ELBO as a proxy.
Secondly, this is a simple setting to demonstrate
that the optimal value of mis often strictly between
1andn, which is the regime in which our variance
reduction methods are useful (all but the approxi-
mations coincide when m∈{1,n}). We again used
SGD with 15 diﬀerent learning rates and selected,
for each conﬁguration, the learning rate that achieved the best mean objective after 10k iterations. We
optimized each conﬁguration using, for this experiment, 100 diﬀerent random seeds. We estimated the accu-
racy of the approximation by computing the distance (error) between the distribution’s covariance and the
estimated covariance of the learned approximation. Figure 1 shows the error as a function of mfor diﬀerent
values ofnwhen using the standard IW-ELBO estimator for a random Dirichlet with 50 parameters. The
ﬁgure shows that the optimal mincreases with n, but slowly. Figure 5 shows similar results for other esti-
13Published in Transactions on Machine Learning Research (02/2023)
mators: permuted, DReG, and permuted-DReG. In all cases, we conﬁrm that, for this model, the optimal
mlies strictly between 1andn. We provide in Appendix E additional details.
2 8 32 128
m2.02.53.03.54.04.55.0error1e5
permuted
2 8 32 128
m1.92.02.12.22.32.42.5error1e5
DReG
2 8 32 128
m1.92.02.12.22.32.42.5error1e5
permuted-DReG
n
16
32
64
128
256
Figure 5: Distance between the covariance of a random Dirichlet distribution with 50 parameters and the
covariance of its approximation as a function of mfor diﬀerent values of nafter training using the permuted
(left), DReG (center) or permuted-DReG (right) estimators.
6.1 Importance-Weighted Autoencoders
To evaluate the performance of the proposed methods on IWAEs, we trained IWAEs on 4 diﬀerent datasets:
MNIST,KMNIST,FMNIST,and Omniglot . WecomparethestandardIW-ELBOestimatorandDReGestimators
to their permuted versions, i.e., the permuted and permuted-DReG estimators. We also evaluate the second-
order approximation to the complete-U-statistic estimator. We trained each combination of dataset, method,
and value of musing ﬁve diﬀerent random seeds, and the optimization was run for 100 epochs using Adam
(Kingma & Ba, 2015).
In Figure 6, we present the ﬁnal testing objective for diﬀerent values of m(usingn= 50in all cases) for
theKMNISTdataset, and we show results for the rest of the datasets in Figure 8 in the Appendix F along
with further details on the experiments. The ﬁgure shows that the permuted versions consistently improved
over the base versions, i.e., the permuted estimator improves over the standard-IW estimator in the same
way as the permuted-DReG estimator improves over the DReG estimator. Additionally, we can see that
the second-order approximation outperforms the permuted estimator for small values of m. However, as
mincreases, the permuted estimator takes the lead, which is expected since the approximation error grows
withm.
method−204.0−203.5−203.0−202.5−202.0−201.5IW objectivekmnist — m = 5
methodkmnist — m = 10
methodkmnist — m = 25
standard IW
permuted
approx. 2nd
DReG
permuted-DReG
Figure 6: Objective’s distribution for KMNISTwithn= 50and diﬀerent combinations of methods and m.
We also compared the total wall-clock time required to complete the optimization with diﬀerent estimators
in Figure 9 in the Appendix. It can be seen that there is not a signiﬁcant time increase for using our proposed
methods.
14Published in Transactions on Machine Learning Research (02/2023)
7 Related and Future Work
Gradient variance reduction is an active topic in VI because of its impact on stochastic optimization. Our
complete- and incomplete-U-statistic methods are complementary to other variance reduction techniques:
they are compatible with diﬀerent base estimators, including the Doubly Reparameterized Gradient Estima-
tor (DReG) of Tucker et al. (2018) and the generalization of Bauer & Mnih (2021). Another broad approach
to variance reduction is the use of control variates (Miller et al., 2017; Mnih & Gregor, 2014; Ranganath
et al., 2014; Geﬀner & Domke, 2018; 2020). In the case of IWVI, the control variates of Mnih & Rezende
(2016) and Liévin et al. (2020), which are designed for the score function estimator, could work as a base
estimator from which a U-statistic can be built. We leave its empirical evaluation for future work.
Importance-weighted estimators are also being used for the Reweighted Wake-Sleep (RWS) procedure (Born-
schein & Bengio, 2015; Le et al., 2020) and its variations (Dieng & Paisley, 2019; Kim et al., 2020). Given
the connection between the gradient estimators of RWS and that of the IW-ELBO [see Kim et al. (2020)],
these estimators could be potentially improved by using the ideas of the complete- and incomplete-U-statistic
methods.
The numerical approximations of Section 5 follow a diﬀerent principle of approximating the objective; it is an
open question if such an approximation can be used in conjunction with other variance reduction methods.
Interestingly, the ﬁrst-order approximation expresses the objective as a convex combination of the ordered
log-weights (minus a constant), which has a form similar to the objective presented in Wang et al. (2018),
albeit with diﬀerent coeﬃcients.
It would be an interesting future line of work to extend the order of Proposition 4.1 to a partial order of
random variables in the sense of Mattei & Frellsen (2022).
Nowozin (2018) introduced Jackknife-VI (JVI), which uses complete-U statistics to reduce bias instead of
variance. In Appendix A we brieﬂy discuss possible applications of our methods to JVI.
8 Conclusion
We introduced novel methods based on U-statistics to reduce gradient and objective variance for importance-
weighted variational inference, and found empirically that the methods improve black-box VI performance
and IWAEs training. We recommend using the permuted-block estimator in any situation with r > 1
replicates: it never increases variance, and can be tuned based on computational budget to achieve any
desired fraction of the possible variance reduction. In practice, a 95% fraction of possible variance reduction
canbeachievedataverylowcost. TheapproximationsofSection5areextremelyfastandprovidesubstantial
variance reduction, but are not universally better than the standard estimator because they introduce some
bias that can hurt performance, especially in easier models near the end of optimization.
Acknowledgments
This material is based upon work supported by the National Science Foundation under Grant Nos. 1749854
and 1908577. JB would like to thank Tomás Geﬀner and Miguel Fuentes for their helpful discussions.
15Published in Transactions on Machine Learning Research (02/2023)
References
Abhinav Agrawal, Justin Domke, and Daniel Sheldon. Advances in black-box VI: Normalizing ﬂows, im-
portance weighting, and optimization. In Advances in Neural Information Processing Systems (NeurIPS) ,
pp. 1–8, 2020.
Matthias Bauer and Andriy Mnih. Generalized doubly reparameterized gradient estimators. In International
Conference on Machine Learning , pp. 738–747. PMLR, 2021.
EliBingham, JonathanP.Chen, MartinJankowiak, FritzObermeyer, NeerajPradhan, TheofanisKaraletsos,
Rohit Singh, Paul Szerlip, Paul Horsfall, and Noah D. Goodman. Pyro: Deep Universal Probabilistic
Programming. Journal of Machine Learning Research , 2018.
David M Blei, Alp Kucukelbir, and Jon D McAuliﬀe. Variational inference: A review for statisticians.
Journal of the American statistical Association , 112(518):859–877, 2017.
Gunnar Blom. Some properties of incomplete U-statistics. Biometrika , 63(3):573–580, 1976.
Mathieu Blondel, Olivier Teboul, Quentin Berthet, and Josip Djolonga. Fast diﬀerentiable sorting and
ranking. In Hal Daumé III and Aarti Singh (eds.), Proceedings of the 37th International Conference on
Machine Learning , volume 119 of Proceedings of Machine Learning Research , pp. 950–959. PMLR, 13–18
Jul 2020. URL https://proceedings.mlr.press/v119/blondel20a.html .
Jörg Bornschein and Yoshua Bengio. Reweighted wake-sleep. In ICLR, 2015.
Yuri Burda, Roger Grosse, and Ruslan Salakhutdinov. Importance Weighted Autoencoders. In ICLR, 2016.
Bob Carpenter, Andrew Gelman, Matthew D Hoﬀman, Daniel Lee, Ben Goodrich, Michael Betancourt,
Marcus Brubaker, Jiqiang Guo, Peter Li, and Allen Riddell. Stan: A probabilistic programming language.
Journal of statistical software , 76(1), 2017.
Chih-Chung Chang and Chih-Jen Lin. Libsvm: a library for support vector machines. ACM transactions
on intelligent systems and technology (TIST) , 2(3):1–27, 2011.
Tarin Clanuwat, Mikel Bober-Irizar, Asanobu Kitamoto, Alex Lamb, Kazuaki Yamamoto, and David Ha.
Deep learning for classical japanese literature, 2018.
ChrisCremer, QuaidMorris, andDavidDuvenaud. Reinterpretingimportance-weightedautoencoders. arXiv
preprint arXiv:1704.02916 , 2017.
Adji B Dieng and John Paisley. Reweighted expectation maximization. arXiv preprint arXiv:1906.05850 ,
2019.
Justin Domke and Daniel Sheldon. Importance weighting and variational inference. In Proceedings of the
32nd International Conference on Neural Information Processing Systems , pp. 4475–4484, 2018.
Justin Domke and Daniel R. Sheldon. Divide and couple: Using Monte Carlo variational objectives for
posterior approximation. In Advances in Neural Information Processing Systems 32: Annual Conference
on Neural Information Processing Systems 2019, NeurIPS 2019, December 8-14, 2019, Vancouver, BC,
Canada, pp. 338–347, 2019.
Dheeru Dua and Casey Graﬀ. UCI machine learning repository, 2017. URL http://archive.ics.uci.edu/
ml.
Axel Finke and Alexandre H Thiery. On importance-weighted autoencoders. arXiv preprint
arXiv:1907.10477 , 2019.
Michael C Fu. Gradient estimation. Handbooks in operations research and management science , 13:575–616,
2006.
16Published in Transactions on Machine Learning Research (02/2023)
Tomas Geﬀner and Justin Domke. Using large ensembles of control variates for variational inference. In
Proceedings of the 32nd International Conference on Neural Information Processing Systems , pp. 9982–
9992, 2018.
Tomas Geﬀner and Justin Domke. Approximation based variance reduction for reparameterization gradients.
Advances in Neural Information Processing Systems , 33, 2020.
Andrew Gelman and Jennifer Hill. Data analysis using regression and multilevel/hierarchical models . Cam-
bridge university press, 2006.
Paul R Halmos. The theory of unbiased estimation. The Annals of Mathematical Statistics , 17(1):34–43,
1946.
Wassily Hoeﬀding. A class of statistics with asymptotically normal distribution. Annals of Mathematical
Statistics , 19:273–325, 1948.
Dongha Kim, Jaesung Hwang, and Yongdai Kim. On casting importance weighted autoencoder to an em
algorithm to learn deep generative models. In Silvia Chiappa and Roberto Calandra (eds.), Proceedings
of the Twenty Third International Conference on Artiﬁcial Intelligence and Statistics , volume 108 of
Proceedings of Machine Learning Research , pp. 2153–2163. PMLR, 26–28 Aug 2020. URL https://
proceedings.mlr.press/v108/kim20b.html .
Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In ICLR (Poster) , 2015.
Diederik P Kingma and Max Welling. Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114 ,
2013.
Jack PC Kleijnen and Reuven Y Rubinstein. Optimization and sensitivity analysis of computer simulation
models by the score function method. European Journal of Operational Research , 88(3):413–427, 1996.
Brenden M Lake, Ruslan Salakhutdinov, and Joshua B Tenenbaum. Human-level concept learning through
probabilistic program induction. Science, 350(6266):1332–1338, 2015.
Tuan Anh Le, Maximilian Igl, Tom Rainforth, Tom Jin, and Frank Wood. Auto-encoding sequential Monte
Carlo. In 6th International Conference on Learning Representations, ICLR 2018, Vancouver, BC, Canada,
April 30 - May 3, 2018, Conference Track Proceedings , 2018.
TuanAnhLe,AdamR.Kosiorek,N.Siddharth,YeeWhyeTeh,andFrankWood. Revisitingreweightedwake-
sleep for models with stochastic control ﬂow. In Ryan P. Adams and Vibhav Gogate (eds.), Proceedings of
The 35th Uncertainty in Artiﬁcial Intelligence Conference , volume 115 of Proceedings of Machine Learning
Research , pp. 1039–1049. PMLR, 22–25 Jul 2020. URL https://proceedings.mlr.press/v115/le20a.
html.
Yann LeCun, Corinna Cortes, and CJ Burges. Mnist handwritten digit database. ATT Labs [Online].
Available: http://yann.lecun.com/exdb/mnist , 2, 2010.
Laurence Lock Lee. U-statistics. Theory and Practice . CRC Press, 1990. ISBN 9781351405867.
ValentinLiévin,AndreaDittadi,AndersChristensen,andOleWinther. Optimalvariancecontrolofthescore-
function gradient estimator for importance-weighted bounds. Advances in Neural Information Processing
Systems, 33:16591–16602, 2020.
David J Lunn, Andrew Thomas, Nicky Best, and David Spiegelhalter. Winbugs — a bayesian modelling
framework: concepts, structure, and extensibility. Statistics and computing , 10(4):325–337, 2000.
Chris J. Maddison, Dieterich Lawson, George Tucker, Nicolas Heess, Mohammad Norouzi, Andriy Mnih,
Arnaud Doucet, and Yee Whye Teh. Filtering variational objectives. In Advances in Neural Information
Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017, December
4-9, 2017, Long Beach, CA, USA , pp. 6573–6583, 2017.
17Published in Transactions on Machine Learning Research (02/2023)
Nathan Mantel. 232. note: Assumption-free estimators using U statistics and a relationship to the Jackknife
method. Biometrics , pp. 567–571, 1967.
Pierre-Alexandre Mattei and Jes Frellsen. Uphill roads to variational tightness: Monotonicity and monte
carlo objectives. arXiv preprint arXiv:2201.10989 , 2022.
AC Miller, NJ Foti, A D Amour, and Ryan P Adams. Reducing reparameterization gradient variance.
Advances in Neural Information Processing Systems , 2017.
Andriy Mnih and Karol Gregor. Neural variational inference and learning in belief networks. In International
Conference on Machine Learning , pp. 1791–1799. PMLR, 2014.
Andriy Mnih and Danilo Rezende. Variational inference for monte carlo objectives. In International Con-
ference on Machine Learning , pp. 2188–2196. PMLR, 2016.
Christian A. Naesseth, Scott W. Linderman, Rajesh Ranganath, and David M. Blei. Variational sequential
Monte Carlo. In International Conference on Artiﬁcial Intelligence and Statistics, AISTATS 2018, 9-
11 April 2018, Playa Blanca, Lanzarote, Canary Islands, Spain , volume 84 of Proceedings of Machine
Learning Research , pp. 968–977. PMLR, 2018.
Sebastian Nowozin. Debiasing evidence approximations: On importance-weighted autoencoders and Jack-
knife variational inference. In International Conference on Learning Representations , 2018.
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen,
Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Kopf, Edward Yang, Zachary
DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, and
Soumith Chintala. Pytorch: An imperative style, high-performance deep learning library. In H. Wallach,
H.Larochelle, A.Beygelzimer, F.d /quotesingle.ts1Alché-Buc, E.Fox, andR.Garnett(eds.), Advances in Neural Informa-
tion Processing Systems 32 , pp. 8024–8035. Curran Associates, Inc., 2019. URL http://papers.neurips.
cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf .
John C Platt. Sequential minimal optimization: A fast algorithm for training support vector machines. In
Advances in Kernel Methods-Support Vector Learning , 1999.
Tom Rainforth, Adam Kosiorek, Tuan Anh Le, Chris Maddison, Maximilian Igl, Frank Wood, and Yee Whye
Teh. Tighter variational bounds are not necessarily better. In International Conference on Machine
Learning , pp. 4277–4285. PMLR, 2018.
Rajesh Ranganath, Sean Gerrish, and David Blei. Black box variational inference. In Artiﬁcial intelligence
and statistics , pp. 814–822. PMLR, 2014.
DaniloJimenezRezende,ShakirMohamed,andDaanWierstra. Stochasticbackpropagationandapproximate
inference in deep generative models. In International conference on machine learning , pp. 1278–1286.
PMLR, 2014.
Lawrence K Saul, Tommi Jaakkola, and Michael I Jordan. Mean ﬁeld theory for sigmoid belief networks.
Journal of Artiﬁcial Intelligence Research , 4:61–76, 1996.
Stan Development Team. Stan Example models, 2021. URL https://github.com/stan-dev/
example-models .
George Tucker, Dieterich Lawson, Shixiang Gu, and Chris J Maddison. Doubly reparameterized gradient
estimators for Monte Carlo objectives. In International Conference on Learning Representations , 2018.
Aad W van der Vaart. Asymptotic statistics , volume 3. Cambridge University Press, 2000.
Dilin Wang, Hao Liu, and Qiang Liu. Variational inference with tail-adaptive f-divergence. Advances in
Neural Information Processing Systems , 31, 2018.
Han Xiao, Kashif Rasul, and Roland Vollgraf. Fashion-mnist: a novel image dataset for benchmarking
machine learning algorithms, 2017.
18Published in Transactions on Machine Learning Research (02/2023)
A Experiments with Jackknife
The relation between the jackknife estimator and complete U-statistics was made explicit early on by Mantel
(1967). Recently, Nowozin (2018) used the jackknife estimator as a way to diminish the bias in IW-VI,
proposing jackknife VI (JVI). Using the notation of Section 3, the jackknife estimator is
ˆLJ,r
n(V1:n) =r/summationdisplay
j=0c(n,r,j )ˆLU
n,n−j(V1:n), (14)
where ˆLU
n,n−jis the complete U-statistic IW-ELBO estimator, and the c(n,r,j )are the Sharot coeﬃcients
[cf. Nowozin (2018)].
In the original version (14), it evaluates a collection of rcomplete U-statistics with mranging from nto
n−r. However, there is no need to constrain min that way, i.e., we can instead compute the following
estimator
ˆLJ,r
n,m(V1:n) =r/summationdisplay
j=0c(m,r,j )ˆLU
n,m−j(V1:n),forr<m≤n,
because the bias is a function of m. This means that once mis ﬁxed, we can pick the number of independent
samplesn≥mto reduce the variance of the estimation.
complete-U approx. 2nd permuted ( /lscript= 20) permuted ( /lscript= 100)
method−210−200−190−180−170−160LJ,1
24,8
method
complete-U
approx. 2nd
permuted ( /lscript= 20)
permuted ( /lscript= 100)
Figure7: DistributionsoftheobjectiveusingtheJack-
knife estimator ˆLJ,1
24,8on an approximation of the pos-
terior of the mushrooms dataset, using diﬀerent esti-
mators.For our experiment, we optimized a variational
approximation to the posterior of the mushrooms
dataset as in Section 6. We used the complete-U-
statistic IW-ELBO estimator for optimization ( n/prime=
16andm= 8), andwechoosetheconﬁgurationwith
the highest ﬁnal bound.
We evaluated the trained model using the Jackknife
estimator with n= 24,r= 1andm= 8. For
the inner estimator we used the complete-U-statistic
IW-ELBO estimator, a variation of the permuted-
block IW-ELBO estimator6with/lscript= 20and with
/lscript= 100, and the second order approximation. Fig-
ure 7 shows that, when using the permuted estima-
tor with/lscript= 20, the increased variance gets trans-
lated into an increased variance in the ﬁnal estima-
tion. However, it can be reduced by increasing the
number of permutations to /lscript= 100. In the follow-
ing table, we show the time taken to compute the
Jackknife estimator without accounting for the time
of building the index set.7
Method Mean time (ms) Std
complete-U 23.98 2.28
approx. 2nd 0.71 0.05
permuted ( /lscript= 20) 0.69 0.02
permuted ( /lscript= 100) 0.86 0.03
In this case, we observed that the alternatives are approximately 30times faster than using the complete-
U-statistic.
6Sincenis not an integer multiple of m−1, we reduced the total number of sets to /lscriptm⌊n
m⌋.
7We pre-computed the index set for the complete-U-statistic, which in this case requires 735471 + 346104 = 1081575 sets,
taking 1.34seconds.
19Published in Transactions on Machine Learning Research (02/2023)
B Additional Theoretical results
In this section, we apply a result of Halmos (1946) to the estimation of the IW-ELBO. Subject to certain
conditions, the estimator ˆLU
n,mhas the smallest variance of any unbiased estimator of the IW-ELBO. The
technical conditions are needed to deﬁne the class of “unbiased estimators” as ones that are unbiased for all
log-weight distributions in a non-trivial class.
Proposition B.1. LetEF[·]and VarF[·]denote expectation and variance with respect to log-weights
V1,...,Vndrawn independently from distribution F, and letLm(F) =EF/bracketleftbig
ln1
m/parenleftbig/summationtextm
i=1eVi/parenrightbig/bracketrightbig
be the IW-
ELBO with log-weight distribution F. Let ˜Fdenote the set of distributions supported on a ﬁnite subset of
R. Suppose Φis any estimator such that E˜F[Φ(V1:n)] =Lm(˜F)for all ˜F∈˜F. Then,
VarF[ˆLU
n,m(V1:n)]≤VarF[Φ(V1:n)]
whenever the latter quantity is deﬁned, for anydistribution Fon the real numbers (up to conditions of
measurability and integrability).
Proof.The result is a direct application of Theorem 5 of Halmos (1946).
For IW-ELBO estimation, the conditions are rather mild: we expect an IW-ELBO estimator to work for
generic log-weight distributions. For gradient estimation, we take the conclusion lightly, because gradient
estimators often use speciﬁc properties of the underlying distributions, such as having a reparameterization.
B.1 Additional Proofs
In this section, we provide a proof of Proposition 3.3. We ﬁrst need to deﬁne a quantity similar to Def-
inition 3.1. Recall, from the statement of the Proposition, that g:RdZ→Rdφ, and letgidenote itsith
component.
Deﬁnition B.2. LetZ1,...,Z 2mbei.i.d.drawn from qφ, and 1≤i≤dφ. For 0≤c≤m, take s,s/prime∈/parenleftbigJ2mK
m/parenrightbig
with|s∩s/prime|=c. UsinggfromProposition 3.3 , deﬁne
ς(i)
c= Cov/bracketleftBig
gi(Zs1,...,Zsm), gi(Zs/prime
1,...,Zs/primem)/bracketrightBig
,
which depends only on cand not the particular sands/prime.
We can now proceed with the proof.
Proof of Proposition 3.3 .For1≤i≤dφ, using Eq. (4) and (6), it follows from Theorem 5.2 of Hoeﬀding
(1948) that
Var[( ˆGU
n,m)i]≤m
nς(i)
m= Var[( ˆGn,m)i].
From the deﬁnition of the covariance matrix, we get
tr(Var[ ˆGU
n,m]) =dθ/summationdisplay
i=1Var[( ˆGU
n,m)i]≤dθ/summationdisplay
i=1Var[( ˆGn,m)i] = tr(Var[ ˆGn,m]).
Using again that ˆGU
n,mand ˆGn,mare unbiased, that is, E[ˆGU
n,m] =E[ˆGn,m], then
E/bardblˆGU
n,m/bardbl2
2=dθ/summationdisplay
i=1(Var[( ˆGU
n,m)i] +E[(ˆGU
n,m)i]2)≤dθ/summationdisplay
i=1(Var[( ˆGn,m)i] +E[(ˆGn,m)i]2) =E/bardblˆGn,m/bardbl2
2.
20Published in Transactions on Machine Learning Research (02/2023)
C Dataset description
We provide a brief description of the datasets and models used for the experiments. The models used for
Bayesian logistic regressions were taken from the UCI Machine Learning Repository Dua & Graﬀ (2017).
The rest of the models are part of the Stan Example models Stan Development Team (2021); Carpenter
et al. (2017).
For the dataset used for Bayesian logistic regression, whenever there was a categorical variable with k
categories, we dummiﬁed itbycreating k−1dummiesvariables. Additionally, forthe a1adataset, continuous
variables were discretized into quintiles following the work of Platt (1999). However, since we were unable
to ﬁnd the ﬁle describing the actual process used for the discretization, some discrepancies remained.
Table 3: Description of datasets/models.
NameNum. of
variablesNum. of
recordsComments
a1a 105 1605First 1605 instances of the Adult Data Set,
following LIBSVM Chang & Lin (2011),
+ discretized continous and dummiﬁed.
australian 35 690 From UCI + dummiﬁed.
ionosphere 35 351 From UCI
mushrooms 96 8124 From UCI + dummiﬁed.
sonar 61 208 From UCI
congress 4 343 Gelman & Hill (2006) Ch. 7
election88 95 2015 Gelman & Hill (2006) Ch. 19
election88Exp 96 2015 Gelman & Hill (2006) Ch. 19
electric 100 192 Gelman & Hill (2006) Ch. 23
electric-one-pred 3 192 Gelman & Hill (2006) Ch. 23
hepatitis 218 288 WinBUGS Lunn et al. (2000) examples
hiv-chr 173 369 Gelman & Hill (2006) Ch. 7
irt 501 30105 Gelman & Hill (2006) Ch. 14
irt-multilevel 604 30015 Gelman & Hill (2006) Ch. 14
mesquite 3 46 Gelman & Hill (2006) Ch. 4
radon 88 919 radon-chr from Gelman & Hill (2006) Ch. 19
wells 2 3020 Gelman & Hill (2006) Ch. 7
MNIST 784 60000 + 10000 LeCun et al. (2010)
FMNIST 784 60000 + 10000 Fashion-MNIST, Xiao et al. (2017)
KMNIST 784 60000 + 10000 Kuzushiji-MNIST Clanuwat et al. (2018)
Omniglot 784 24345 + 8070 Lake et al. (2015) from Burda et al. (2016)
D Pairwise comparison
In this section we present the mean diﬀerence of the medians of the envelopes as described in Section 6. We
comparethemethodsthatusedthereparameterizedgradientsasbasedgradientestimator, i.e., thepermuted-
block estimator and the 2nd order approximation, to the standard IW-ELBO estimator. Additionally, we
compare the standard IW using DReG as a based gradient estimator with a version of the permuted-block
that uses the DReG as a base gradient estimator, namely, the permuted DReG.
Interestingly, in the settings presented in Table 7, only the proposed methods, i.e., the complete-U statistic
with its two approximations, the permuted-block, and the random subsets, converged at some point. All the
other methods diverged, which explains why we cannot compute the diﬀerence.
21Published in Transactions on Machine Learning Research (02/2023)
Table 4: Bayesian logistic regression models using a Gaussian approximation with a covariance matrix of
full rank. Diﬀerence in nats of the average objective (higher values are better).
Datasetpermuted - standard IW approx. 2nd - standard IW permuted DReG - DReG
m
2 4 82 4 82 4 8
a1a 45.36100.56 112.42 47.53105.30 122.34 27.30111.74 119.51
australian 1.31 2.61 3.361.07 2.37 3.221.45 1.87 3.94
ionosphere 3.8913.17 16.58 4.1113.55 17.55 4.3415.74 17.91
mushrooms 64.46145.85 202.56 67.28153.58 214.31 93.45186.01 179.02
sonar 30.15 61.09 50.6232.94 63.34 54.1427.99 69.54 90.86
Table 5: Bayesian logistic regression models using a diagonal Gaussian approximation. Diﬀerence in nats of
the average objective (higher values are better).
Datasetpermuted - standard IW approx. 2nd - standard IW permuted DReG - DReG
m
24 824 824 8
a1a 1.544.01 4.481.494.08 4.451.4012.67 12.86
australian 0.021.00 1.380.050.96 1.28-0.07 0.06 1.43
ionosphere -0.10-0.10 0.06-0.12-0.21 0.00-0.12-0.08 0.31
mushrooms 1.882.76 8.691.743.30 9.161.944.69 8.50
sonar 0.03-0.15 0.19-0.02-0.18 0.150.03-0.28 0.21
Table 6: Stan models using a diagonal Gaussian approximation. Diﬀerence in nats of the average objective
(higher values are better).
Datasetpermuted - standard IW approx. 2nd - standard IW permuted DReG - DReG
m
24 82 4 82 4 8
congress 2.504.61 7.332.89 4.76 7.632.37 4.68 7.02
election88 0.122.66 6.940.12 2.84 7.060.10 2.67 6.83
election88Exp 0.8298.52 32.76 4.73117.78 55.27-1.89100.09 32.53
electric 0.261.53 4.320.16 1.54 4.520.24 1.56 4.63
electric-one-pred 0.66-0.77 -3.91 0.74-0.76 -4.38 0.69-0.77 -3.93
hepatitis 0.90-0.06 0.652.06156.53 1.86-0.30 0.92 0.69
hiv-chr 0.162.03 15.84 0.34 2.12 21.74-0.08 1.45 12.91
irt 0.190.80 1.000.15 0.72 0.930.11 0.61 1.40
irt-multilevel 35.6943.79 62.3229.74 48.20 53.6434.66 50.26 55.22
mesquite 0.200.58 2.00-0.06 0.28 1.74-0.29 0.39 1.99
radon 7.885.79 14.83 7.85 8.91 65.49 8.16 7.56 60.92
wells -0.02 0.01 -0.11-0.20 -0.30 -0.35-0.02 -0.04 -0.14
22Published in Transactions on Machine Learning Research (02/2023)
Table 7: Stan models using a full covariance Gaussian approximation. Diﬀerence in nats of the average
objective (higher values are better).
Datasetpermuted - standard IW approx. 2nd - standard IW permuted DReG - DReG
m
2 4 82 4 82 4 8
congress 11.62 12.02 19.8012.33 12.57 20.4613.55 13.11 20.96
election88 NaN 1785 1133NaN 2494 2170NaN 1776 1116
election88Exp NaN NaN NaNNaN NaN NaNNaN NaN NaN
electric NaN-38.02 80.46 NaN-77.53 89.06 NaN-43.16 34.91
electric-one-pred -1.81 -4.73 -3.45-3.18 -4.77 -4.37-1.79 -4.72 -3.46
hepatitis NaN NaN NaNNaN NaN NaNNaN NaN NaN
hiv-chr NaN NaN283.19 NaN NaN 325.79 NaN NaN NaN
irt 17793 20064 1607719399 22000 17686 NaN NaN NaN
mesquite 2.57 1.20 1.412.43 0.95 1.192.67 0.53 0.74
radon NaN 1150268.98 NaN 1316 303.83 NaN11675 269.26
wells 0.02 0.07 -0.03-0.29 -0.31 -0.29 0.04 0.02 -0.02
E Random Dirichlet experiment
We follow Domke & Sheldon (2018) for the Random Dirichlet experiment. For a randomly-sampled Dirichlet
Distribution with 50 parameters, we approximate it using a ( 50−1)-dimensional Gaussian distribution
parameterized with a full rank covariance matrix, with its domain constrained to the simplex using PyTorch’s
distributions (Paszke et al., 2019).
We optimize each conﬁguration using 100 diﬀerent random seeds. We select the learning rate that achieved
the highest objective among all learning rates that converged for all seeds. For each seed, we compute
the Frobenius norm between the empirical covariance of the approximating distribution and that of the
theoretical distribution (the error). The distribution of this error is shown in Figure 1 and 5. We had to
exclude eight outliers with errors greater than 10−4and up to 0.5. Interestingly, those outliers used either
the DReG or permuted-DReG estimators.
F VAE details.
For the variational autoencoders, we used, for all datasets, the architecture used by Burda et al. (2016).
We trained each conﬁguration for a ﬁxed number of epochs (100) using Adam (Kingma & Ba, 2015) with a
learning rate of 10−4. In all cases, we used a batch size of 500, and a latent variable of dimension 50, while
takingn= 50samples. Datasets were taken from PyTorch, except for the Omniglot , for which we used
the construction provided by Burda et al. (2016). We evaluated using the standard IW-ELBO estimator,
regardless of the estimator used for the optimization.
To get consistent wall-clock time measurements, we trained only using CPU on dedicated servers, with
disabled hyper-threading and a single task per core. Additionally, we used set_flush_denormal to avoid
creating denormal numbers because some estimators create many of such numbers (especially DReG-like
estimators), having a substantial negative impact on performance. Our implementation of DReG is based
on Pyro’s (Bingham et al., 2018) not-yet-integrated implementation. We are not aware of a PyTorch imple-
mentation without the extra time penalty.
In the following plots, we provide the objective distribution for all dataset/method/ mconﬁgurations and
the distribution of the wall-clock time.
23Published in Transactions on Machine Learning Research (02/2023)
−204.0−203.5−203.0−202.5−202.0−201.5IW objectivekmnist — m = 5 kmnist — m = 10 kmnist — m = 25
−245.50−245.25−245.00−244.75−244.50−244.25IW objectivefmnist — m = 5 fmnist — m = 10 fmnist — m = 25
−156−154−152−150−148IW objectiveomniglot — m = 5 omniglot — m = 10 omniglot — m = 25
method−108.25−108.00−107.75−107.50−107.25−107.00−106.75−106.50IW objectivemnist — m = 5
methodmnist — m = 10
methodmnist — m = 25standard IW
permuted
approx. 2nd
DReG
permuted-DReG
Figure 8: Distribution of the objective for diﬀerent combinations of datasets, methods and m, usingn= 50
samples.
24Published in Transactions on Machine Learning Research (02/2023)
2750030000325003500037500400004250045000total time (s)kmnist — m = 5 kmnist — m = 10 kmnist — m = 25
2750030000325003500037500400004250045000total time (s)fmnist — m = 5 fmnist — m = 10 fmnist — m = 25
1100012000130001400015000160001700018000total time (s)omniglot — m = 5 omniglot — m = 10 omniglot — m = 25
method2750030000325003500037500400004250045000total time (s)mnist — m = 5
methodmnist — m = 10
methodmnist — m = 25standard IW
permuted
approx. 2nd
DReG
permuted-DReG
Figure 9: Distribution of the time taken to run 100 epochs for diﬀerent combinations of datasets, methods
andm, usingn= 50samples.
25Published in Transactions on Machine Learning Research (02/2023)
G Figures of median envelope
Forsomeofthemethodspresentedinthepaper, wecomputethemedianenvelopeduringtrainingasdescribed
in Section 6.
0 250 500 750 1000−800−780−760−740−720−700−680−660−640objectivea1a — m = 2
method
standard IW
complete-U
permuted
0 250 500 750 1000−800−780−760−740−720−700−680−660−640a1a — m = 4
0 250 500 750 1000−800−780−760−740−720−700−680−660−640a1a — m = 8
0 250 500 750 1000−800−780−760−740−720−700−680−660−640a1a — m = 16
0 250 500 750 1000−320−310−300−290−280−270−260objectiveaustralian — m = 2
0 250 500 750 1000−320−310−300−290−280−270−260australian — m = 4
0 250 500 750 1000−320−310−300−290−280−270−260australian — m = 8
0 250 500 750 1000−320−310−300−290−280−270−260australian — m = 16
0 5000 1000050100150200250300350400450objectivecongress — m = 2
0 5000 1000050100150200250300350400450congress — m = 4
0 5000 1000050100150200250300350400450congress — m = 8
0 5000 1000050100150200250300350400450congress — m = 16
0 5000 10000−1800−1750−1700−1650−1600−1550−1500objectiveelection88 — m = 2
0 5000 10000−1800−1750−1700−1650−1600−1550−1500election88 — m = 4
0 5000 10000−1800−1750−1700−1650−1600−1550−1500election88 — m = 8
0 5000 10000−1800−1750−1700−1650−1600−1550−1500election88 — m = 16
0 5000 10000−2400−2200−2000−1800−1600−1400objectiveelection88Exp — m = 2
0 5000 10000−2400−2200−2000−1800−1600−1400election88Exp — m = 4
0 5000 10000−2400−2200−2000−1800−1600−1400election88Exp — m = 8
0 5000 10000−2400−2200−2000−1800−1600−1400election88Exp — m = 16
0 5000 10000−940−920−900−880−860−840−820−800objectiveelectric — m = 2
0 5000 10000−940−920−900−880−860−840−820−800electric — m = 4
0 5000 10000−940−920−900−880−860−840−820−800electric — m = 8
0 5000 10000−940−920−900−880−860−840−820−800electric — m = 16
0 2000 4000−1300−1275−1250−1225−1200−1175−1150objectiveelectric-one-pred — m = 2
0 2000 4000−1300−1275−1250−1225−1200−1175−1150electric-one-pred — m = 4
0 2000 4000−1300−1275−1250−1225−1200−1175−1150electric-one-pred — m = 8
0 2000 4000−1300−1275−1250−1225−1200−1175−1150electric-one-pred — m = 16
0 5000 10000−1400−1200−1000−800−600objectivehepatitis — m = 2
0 5000 10000−1400−1200−1000−800−600hepatitis — m = 4
0 5000 10000−1400−1200−1000−800−600hepatitis — m = 8
0 5000 10000−1400−1200−1000−800−600hepatitis — m = 16
0 5000 10000
iterations−800−750−700−650−600objectivehiv-chr — m = 2
0 5000 10000
iterations−800−750−700−650−600hiv-chr — m = 4
0 5000 10000
iterations−800−750−700−650−600hiv-chr — m = 8
0 5000 10000
iterations−800−750−700−650−600hiv-chr — m = 16
0250 500 750 1000−150−145−140−135−130−125objectiveionosphere — m = 2
method
standard IW
complete-U
permuted
0250 500 750 1000−150−145−140−135−130−125ionosphere — m = 4
0250 500 750 1000−150−145−140−135−130−125ionosphere — m = 8
0250 500 750 1000−150−145−140−135−130−125ionosphere — m = 16
0 2000 4000−15940−15930−15920−15910−15900−15890−15880objectiveirt — m = 2
0 2000 4000−15940−15930−15920−15910−15900−15890−15880irt — m = 4
0 2000 4000−15940−15930−15920−15910−15900−15890−15880irt — m = 8
0 2000 4000−15940−15930−15920−15910−15900−15890−15880irt — m = 16
0 5000 10000−17000−16750−16500−16250−16000−15750−15500−15250−15000objectiveirt-multilevel — m = 2
0 5000 10000−17000−16750−16500−16250−16000−15750−15500−15250−15000irt-multilevel — m = 4
0 5000 10000−17000−16750−16500−16250−16000−15750−15500−15250−15000irt-multilevel — m = 8
0 5000 10000−17000−16750−16500−16250−16000−15750−15500−15250−15000irt-multilevel — m = 16
0250 500 750 1000−60−55−50−45−40−35−30objectivemesquite — m = 2
0250 500 750 1000−60−55−50−45−40−35−30mesquite — m = 4
0250 500 750 1000−60−55−50−45−40−35−30mesquite — m = 8
0250 500 750 1000−60−55−50−45−40−35−30mesquite — m = 16
0250 500 750 1000−400−350−300−250−200objectivemushrooms — m = 2
0250 500 750 1000−400−350−300−250−200mushrooms — m = 4
0250 500 750 1000−400−350−300−250−200mushrooms — m = 8
0250 500 750 1000−400−350−300−250−200mushrooms — m = 16
0500 1000 1500 2000−2000−1800−1600−1400−1200objectiveradon — m = 2
0500 1000 1500 2000−2000−1800−1600−1400−1200radon — m = 4
0500 1000 1500 2000−2000−1800−1600−1400−1200radon — m = 8
0500 1000 1500 2000−2000−1800−1600−1400−1200radon — m = 16
0250 500 750 1000−200−180−160−140−120objectivesonar — m = 2
0250 500 750 1000−200−180−160−140−120sonar — m = 4
0250 500 750 1000−200−180−160−140−120sonar — m = 8
0250 500 750 1000−200−180−160−140−120sonar — m = 16
0250 500 750 1000
iterations−2046−2045−2044−2043−2042−2041−2040objectivewells — m = 2
0250 500 750 1000
iterations−2046−2045−2044−2043−2042−2041−2040wells — m = 4
0250 500 750 1000
iterations−2046−2045−2044−2043−2042−2041−2040wells — m = 8
0250 500 750 1000
iterations−2046−2045−2044−2043−2042−2041−2040wells — m = 16
Figure 10: Median envelope for models when using a diagonal Gaussian as approximating distribution for
the estimators complete-U, permuted and the standard IW.
26Published in Transactions on Machine Learning Research (02/2023)
0 250 500 750 1000−800−780−760−740−720−700−680−660−640objectivea1a — m = 2
method
DReG
complete-U-DReG
permuted-DReG
0 250 500 750 1000−800−780−760−740−720−700−680−660−640a1a — m = 4
0 250 500 750 1000−800−780−760−740−720−700−680−660−640a1a — m = 8
0 250 500 750 1000−800−780−760−740−720−700−680−660−640a1a — m = 16
0 250 500 750 1000−320−310−300−290−280−270−260objectiveaustralian — m = 2
0 250 500 750 1000−320−310−300−290−280−270−260australian — m = 4
0 250 500 750 1000−320−310−300−290−280−270−260australian — m = 8
0 250 500 750 1000−320−310−300−290−280−270−260australian — m = 16
0 5000 1000050100150200250300350400450objectivecongress — m = 2
0 5000 1000050100150200250300350400450congress — m = 4
0 5000 1000050100150200250300350400450congress — m = 8
0 5000 1000050100150200250300350400450congress — m = 16
0 5000 10000−1800−1750−1700−1650−1600−1550−1500objectiveelection88 — m = 2
0 5000 10000−1800−1750−1700−1650−1600−1550−1500election88 — m = 4
0 5000 10000−1800−1750−1700−1650−1600−1550−1500election88 — m = 8
0 5000 10000−1800−1750−1700−1650−1600−1550−1500election88 — m = 16
0 5000 10000−2400−2200−2000−1800−1600−1400objectiveelection88Exp — m = 2
0 5000 10000−2400−2200−2000−1800−1600−1400election88Exp — m = 4
0 5000 10000−2400−2200−2000−1800−1600−1400election88Exp — m = 8
0 5000 10000−2400−2200−2000−1800−1600−1400election88Exp — m = 16
0 5000 10000−940−920−900−880−860−840−820−800objectiveelectric — m = 2
0 5000 10000−940−920−900−880−860−840−820−800electric — m = 4
0 5000 10000−940−920−900−880−860−840−820−800electric — m = 8
0 5000 10000−940−920−900−880−860−840−820−800electric — m = 16
0 2000 4000−1300−1275−1250−1225−1200−1175−1150objectiveelectric-one-pred — m = 2
0 2000 4000−1300−1275−1250−1225−1200−1175−1150electric-one-pred — m = 4
0 2000 4000−1300−1275−1250−1225−1200−1175−1150electric-one-pred — m = 8
0 2000 4000−1300−1275−1250−1225−1200−1175−1150electric-one-pred — m = 16
0 5000 10000−1400−1200−1000−800−600objectivehepatitis — m = 2
0 5000 10000−1400−1200−1000−800−600hepatitis — m = 4
0 5000 10000−1400−1200−1000−800−600hepatitis — m = 8
0 5000 10000−1400−1200−1000−800−600hepatitis — m = 16
0 5000 10000
iterations−800−750−700−650−600objectivehiv-chr — m = 2
0 5000 10000
iterations−800−750−700−650−600hiv-chr — m = 4
0 5000 10000
iterations−800−750−700−650−600hiv-chr — m = 8
0 5000 10000
iterations−800−750−700−650−600hiv-chr — m = 16
0250 500 750 1000−150−145−140−135−130−125objectiveionosphere — m = 2
method
DReG
complete-U-DReG
permuted-DReG
0250 500 750 1000−150−145−140−135−130−125ionosphere — m = 4
0250 500 750 1000−150−145−140−135−130−125ionosphere — m = 8
0250 500 750 1000−150−145−140−135−130−125ionosphere — m = 16
0 2000 4000−15940−15930−15920−15910−15900−15890−15880objectiveirt — m = 2
0 2000 4000−15940−15930−15920−15910−15900−15890−15880irt — m = 4
0 2000 4000−15940−15930−15920−15910−15900−15890−15880irt — m = 8
0 2000 4000−15940−15930−15920−15910−15900−15890−15880irt — m = 16
0 5000 10000−17000−16750−16500−16250−16000−15750−15500−15250−15000objectiveirt-multilevel — m = 2
0 5000 10000−17000−16750−16500−16250−16000−15750−15500−15250−15000irt-multilevel — m = 4
0 5000 10000−17000−16750−16500−16250−16000−15750−15500−15250−15000irt-multilevel — m = 8
0 5000 10000−17000−16750−16500−16250−16000−15750−15500−15250−15000irt-multilevel — m = 16
0250 500 750 1000−60−55−50−45−40−35−30objectivemesquite — m = 2
0250 500 750 1000−60−55−50−45−40−35−30mesquite — m = 4
0250 500 750 1000−60−55−50−45−40−35−30mesquite — m = 8
0250 500 750 1000−60−55−50−45−40−35−30mesquite — m = 16
0250 500 750 1000−400−350−300−250−200objectivemushrooms — m = 2
0250 500 750 1000−400−350−300−250−200mushrooms — m = 4
0250 500 750 1000−400−350−300−250−200mushrooms — m = 8
0250 500 750 1000−400−350−300−250−200mushrooms — m = 16
0500 1000 1500 2000−2000−1800−1600−1400−1200objectiveradon — m = 2
0500 1000 1500 2000−2000−1800−1600−1400−1200radon — m = 4
0500 1000 1500 2000−2000−1800−1600−1400−1200radon — m = 8
0500 1000 1500 2000−2000−1800−1600−1400−1200radon — m = 16
0250 500 750 1000−200−180−160−140−120objectivesonar — m = 2
0250 500 750 1000−200−180−160−140−120sonar — m = 4
0250 500 750 1000−200−180−160−140−120sonar — m = 8
0250 500 750 1000−200−180−160−140−120sonar — m = 16
0250 500 750 1000
iterations−2046−2045−2044−2043−2042−2041−2040objectivewells — m = 2
0250 500 750 1000
iterations−2046−2045−2044−2043−2042−2041−2040wells — m = 4
0250 500 750 1000
iterations−2046−2045−2044−2043−2042−2041−2040wells — m = 8
0250 500 750 1000
iterations−2046−2045−2044−2043−2042−2041−2040wells — m = 16
Figure 11: Median envelope for models when using a diagonal Gaussian as approximating distribution using
the complete-U DReG, permuted DReG and the standard DReG gradient estimators.
27Published in Transactions on Machine Learning Research (02/2023)
0 5000 10000−1200−1100−1000−900−800−700−600objectivea1a — m = 2
method
standard IW
complete-U
permuted
0 5000 10000−1200−1100−1000−900−800−700−600a1a — m = 4
0 5000 10000−1200−1100−1000−900−800−700−600a1a — m = 8
0 5000 10000−1200−1100−1000−900−800−700−600a1a — m = 16
0 5000 10000−450−400−350−300−250objectiveaustralian — m = 2
0 5000 10000−450−400−350−300−250australian — m = 4
0 5000 10000−450−400−350−300−250australian — m = 8
0 5000 10000−450−400−350−300−250australian — m = 16
0 5000 1000050100150200250300350400450objectivecongress — m = 2
0 5000 1000050100150200250300350400450congress — m = 4
0 5000 1000050100150200250300350400450congress — m = 8
0 5000 1000050100150200250300350400450congress — m = 16
0.000.250.500.751.000.00.20.40.60.81.0objectiveelection88 — m = 2
0 5000 10000−10000−9000−8000−7000−6000−5000−4000−3000election88 — m = 4
0 5000 10000−10000−9000−8000−7000−6000−5000−4000−3000election88 — m = 8
0.000.250.500.751.000.00.20.40.60.81.0election88 — m = 16
0.000.250.500.751.000.00.20.40.60.81.0objectiveelection88Exp — m = 2
0.000.250.500.751.000.00.20.40.60.81.0election88Exp — m = 4
0 5000 10000−10000−9000−8000−7000−6000−5000−4000−3000−2000election88Exp — m = 8
0.000.250.500.751.000.00.20.40.60.81.0election88Exp — m = 16
0.000.250.500.751.000.00.20.40.60.81.0objectiveelectric — m = 2
0 5000 10000−1800−1700−1600−1500−1400−1300−1200−1100−1000electric — m = 4
0 5000 10000−1800−1700−1600−1500−1400−1300−1200−1100−1000electric — m = 8
0 5000 10000−1800−1700−1600−1500−1400−1300−1200−1100−1000electric — m = 16
0 2000 4000−1300−1275−1250−1225−1200−1175−1150objectiveelectric-one-pred — m = 2
0 2000 4000−1300−1275−1250−1225−1200−1175−1150electric-one-pred — m = 4
0 2000 4000−1300−1275−1250−1225−1200−1175−1150electric-one-pred — m = 8
0 2000 4000−1300−1275−1250−1225−1200−1175−1150electric-one-pred — m = 16
0.000.250.500.751.000.00.20.40.60.81.0objectivehepatitis — m = 2
0 5000 10000−5000−4500−4000−3500−3000−2500−2000−1500hepatitis — m = 4
0 5000 10000−5000−4500−4000−3500−3000−2500−2000−1500hepatitis — m = 8
0 5000 10000−5000−4500−4000−3500−3000−2500−2000−1500hepatitis — m = 16
0.000.250.500.751.00
iterations0.00.20.40.60.81.0objectivehiv-chr — m = 2
0 5000 10000
iterations−3500−3000−2500−2000−1500hiv-chr — m = 4
0 5000 10000
iterations−3500−3000−2500−2000−1500hiv-chr — m = 8
0 5000 10000
iterations−3500−3000−2500−2000−1500hiv-chr — m = 16
0250 500 750 1000−300−250−200−150objectiveionosphere — m = 2
method
standard IW
complete-U
permuted
0250 500 750 1000−300−250−200−150ionosphere — m = 4
0250 500 750 1000−300−250−200−150ionosphere — m = 8
0250 500 750 1000−300−250−200−150ionosphere — m = 16
0 5000 10000−120000−100000−80000−60000−40000−20000objectiveirt — m = 2
0 5000 10000−120000−100000−80000−60000−40000−20000irt — m = 4
0 5000 10000−120000−100000−80000−60000−40000−20000irt — m = 8
0.000.250.500.751.000.00.20.40.60.81.0irt — m = 16
0500 1000 1500 2000−60−55−50−45−40−35−30objectivemesquite — m = 2
0500 1000 1500 2000−60−55−50−45−40−35−30mesquite — m = 4
0500 1000 1500 2000−60−55−50−45−40−35−30mesquite — m = 8
0500 1000 1500 2000−60−55−50−45−40−35−30mesquite — m = 16
0 5000 10000−600−500−400−300−200objectivemushrooms — m = 2
0 5000 10000−600−500−400−300−200mushrooms — m = 4
0 5000 10000−600−500−400−300−200mushrooms — m = 8
0 5000 10000−600−500−400−300−200mushrooms — m = 16
0.000.250.500.751.000.00.20.40.60.81.0objectiveradon — m = 2
0 5000 10000−5000−4000−3000−2000radon — m = 4
0 5000 10000−5000−4000−3000−2000radon — m = 8
0 5000 10000−5000−4000−3000−2000radon — m = 16
0250 500 750 1000−600−500−400−300−200objectivesonar — m = 2
0250 500 750 1000−600−500−400−300−200sonar — m = 4
0250 500 750 1000−600−500−400−300−200sonar — m = 8
0250 500 750 1000−600−500−400−300−200sonar — m = 16
0500 1000 1500 2000
iterations−2048−2046−2044−2042−2040objectivewells — m = 2
0500 1000 1500 2000
iterations−2048−2046−2044−2042−2040wells — m = 4
0500 1000 1500 2000
iterations−2048−2046−2044−2042−2040wells — m = 8
0500 1000 1500 2000
iterations−2048−2046−2044−2042−2040wells — m = 16
Figure 12: Median envelope for models when using a Gaussian distribution with full-rank covariance as
approximating distribution for the estimators complete-U, permuted and the standard IW.
28Published in Transactions on Machine Learning Research (02/2023)
0 5000 10000−1200−1100−1000−900−800−700−600objectivea1a — m = 2
method
DReG
complete-U-DReG
permuted-DReG
0 5000 10000−1200−1100−1000−900−800−700−600a1a — m = 4
0 5000 10000−1200−1100−1000−900−800−700−600a1a — m = 8
0 5000 10000−1200−1100−1000−900−800−700−600a1a — m = 16
0 5000 10000−450−400−350−300−250objectiveaustralian — m = 2
0 5000 10000−450−400−350−300−250australian — m = 4
0 5000 10000−450−400−350−300−250australian — m = 8
0 5000 10000−450−400−350−300−250australian — m = 16
0 5000 10000100200300400objectivecongress — m = 2
0 5000 10000100200300400congress — m = 4
0 5000 10000100200300400congress — m = 8
0 5000 10000100200300400congress — m = 16
0.000.250.500.751.000.00.20.40.60.81.0objectiveelection88 — m = 2
0 5000 10000−10000−8000−6000−4000election88 — m = 4
0 5000 10000−10000−8000−6000−4000election88 — m = 8
0.000.250.500.751.000.00.20.40.60.81.0election88 — m = 16
0.000.250.500.751.000.00.20.40.60.81.0objectiveelection88Exp — m = 2
0.000.250.500.751.000.00.20.40.60.81.0election88Exp — m = 4
0 5000 10000−10000−8000−6000−4000−2000election88Exp — m = 8
0.000.250.500.751.000.00.20.40.60.81.0election88Exp — m = 16
0.000.250.500.751.000.00.20.40.60.81.0objectiveelectric — m = 2
0 5000 10000−1800−1600−1400−1200−1000electric — m = 4
0 5000 10000−1800−1600−1400−1200−1000electric — m = 8
0 5000 10000−1800−1600−1400−1200−1000electric — m = 16
0 2000 4000
iterations−1300−1275−1250−1225−1200−1175−1150objectiveelectric-one-pred — m = 2
0 2000 4000
iterations−1300−1275−1250−1225−1200−1175−1150electric-one-pred — m = 4
0 2000 4000
iterations−1300−1275−1250−1225−1200−1175−1150electric-one-pred — m = 8
0 2000 4000
iterations−1300−1275−1250−1225−1200−1175−1150electric-one-pred — m = 16
0 250 500 750 1000−300−250−200−150objectiveionosphere — m = 2
method
DReG
complete-U-DReG
permuted-DReG
0 250 500 750 1000−300−250−200−150ionosphere — m = 4
0 250 500 750 1000−300−250−200−150ionosphere — m = 8
0 250 500 750 1000−300−250−200−150ionosphere — m = 16
0 500 1000 1500 2000−60−55−50−45−40−35−30objectivemesquite — m = 2
0 500 1000 1500 2000−60−55−50−45−40−35−30mesquite — m = 4
0 500 1000 1500 2000−60−55−50−45−40−35−30mesquite — m = 8
0 500 1000 1500 2000−60−55−50−45−40−35−30mesquite — m = 16
0 5000 10000−600−500−400−300−200objectivemushrooms — m = 2
0 5000 10000−600−500−400−300−200mushrooms — m = 4
0 5000 10000−600−500−400−300−200mushrooms — m = 8
0 5000 10000−600−500−400−300−200mushrooms — m = 16
0.000.250.500.751.000.00.20.40.60.81.0objectiveradon — m = 2
0 5000 10000−5000−4000−3000−2000radon — m = 4
0 5000 10000−5000−4000−3000−2000radon — m = 8
0 5000 10000−5000−4000−3000−2000radon — m = 16
0 250 500 750 1000−600−500−400−300−200objectivesonar — m = 2
0 250 500 750 1000−600−500−400−300−200sonar — m = 4
0 250 500 750 1000−600−500−400−300−200sonar — m = 8
0 250 500 750 1000−600−500−400−300−200sonar — m = 16
0 500 1000 1500 2000
iterations−2048−2046−2044−2042−2040objectivewells — m = 2
0 500 1000 1500 2000
iterations−2048−2046−2044−2042−2040wells — m = 4
0 500 1000 1500 2000
iterations−2048−2046−2044−2042−2040wells — m = 8
0 500 1000 1500 2000
iterations−2048−2046−2044−2042−2040wells — m = 16
Figure 13: Median envelope for models when using a Gaussian distribution with full-rank covariance as
approximating distribution using the complete-U DReG, permuted DReG and the standard DReG gradient
estimators.
29Published in Transactions on Machine Learning Research (02/2023)
Table 8: Median objective averaged over the last 200 iterations when using the estimators complete-U,
permuted and the standard IW. It can be seen that for at least 10 models out of 17, using either the di-
agonal Gaussian or the full rank covariance Gaussian approximation, the best objective is achieved with
an intermediate value of m, and it is at least 1 nat larger than the objective with m= 16. These mod-
els are: congress ,election88 ,election88Exp ,electric ,electric-one-pred ,hepatitis ,hiv-chr,
irt-multilevel ,mushrooms andradon. Optimizations using m= 1are not shown.
model methodDiagonal Gaussian Full Rank Covariance Gaussian
m
2 4 8 16 2 4 8 16
a1a standard IW -652.8 -649.7 -648.0 -647.6 -639.0 -660.7 -738.1 -772.1
complete-U -652.6 -648.9 -646.7 -647.6 -637.8 -639.0 -663.9 -772.1
permuted -652.6 -649.0 -647.0 -647.7 -637.8 -639.2 -664.1 -771.2
australian standard IW -264.4 -261.2 -259.1 -258.0 -256.8 -256.8 -256.8 -257.2
complete-U -264.8 -261.5 -259.1 -258.0 -256.8 -256.8 -256.8 -257.2
permuted -264.7 -261.4 -259.0 -257.9 -256.8 -256.8 -256.8 -257.1
congress standard IW 417.1 419.5 419.5 417.6 416.9 417.2 412.4 403.9
complete-U 418.8 420.3 420.3 417.6 419.4 420.3 419.2 403.9
permuted 418.5 420.2 420.4 417.1 419.4 420.2 418.9 402.9
election88 standard IW -1529.5 -1523.3 -1525.0 -1535.6 NaN -5964.2 -4383.2 NaN
complete-U -1529.7 -1521.5 -1519.8 -1535.6 NaN -4943.1 -2046.2 NaN
permuted -1529.4 -1520.6 -1520.5 -1535.5 NaN -5443.7 -3000.9 NaN
election88Exp standard IW -1755.7 -1570.8 -1502.7 -1461.2 NaN NaN NaN NaN
complete-U -1760.0 -1496.5 -1467.0 -1461.2 NaN NaN -3748.2 NaN
permuted -1766.6 -1512.3 -1482.7 -1461.9 NaN NaN NaN NaN
electric standard IW -830.5 -827.7 -826.1 -830.9 NaN -1421.1 -1166.2 -1207.2
complete-U -830.6 -827.0 -823.0 -830.9 NaN -1459.2 -1090.3 -1207.2
permuted -830.6 -827.1 -823.5 -830.9 NaN -1413.6 -1098.1 -1203.4
electric-one-pred standard IW -1148.6 -1147.5 -1146.4 -1144.6 -1153.0 -1145.8 -1141.5 -1141.2
complete-U -1148.3 -1145.2 -1146.8 -1144.6 -1150.7 -1144.1 -1140.3 -1141.2
permuted -1148.3 -1146.6 -1146.5 -1144.6 -1151.0 -1144.5 -1140.0 -1141.2
hepatitis standard IW -561.3 -774.9 -775.4 -774.4 NaN NaN NaN -1693.7
complete-U -561.2 -564.3 -773.1 -774.4 NaN -1664.4 -1592.8 -1693.7
permuted -561.2 -773.8 -775.2 -774.4 NaN -1779.6 -1715.7 -1682.1
hiv-chr standard IW -606.4 -604.4 -607.5 -603.8 NaN NaN -1879.9 -1945.0
complete-U -606.2 -604.0 -602.6 -603.8 NaN -3395.8 -1450.6 -1945.0
permuted -606.2 -604.0 -603.1 -603.7 NaN NaN -1486.9 -1960.9
ionosphere standard IW -133.1 -129.2 -127.2 -125.6 -125.3 -126.6 -132.5 -142.3
complete-U -133.2 -129.6 -127.3 -125.6 -124.9 -125.2 -127.2 -142.3
permuted -133.3 -129.6 -127.3 -125.7 -124.9 -125.2 -127.3 -142.2
irt standard IW -15887.5 -15887.1 -15886.8 -15886.7 -36563 -64934 -68447 NaN
complete-U -15887.4 -15887.0 -15886.8 -15886.7 -33230 -37383 -50316 NaN
permuted -15887.4 -15887.0 -15886.8 -15886.6 -35620 -37547 -54763 NaN
irt-multilevel standard IW -15204.7 -15194.1 -15191.3 -15196.8 NaN NaN NaN NaN
complete-U -15198.7 -15164.0 -15185.8 -15196.8 NaN NaN NaN NaN
permuted -15200.3 -15173.0 -15186.2 -15197.0 NaN NaN NaN NaN
mesquite standard IW -29.9 -29.7 -29.6 -29.3 -29.8 -29.7 -29.6 -29.2
complete-U -29.9 -29.8 -29.6 -29.3 -29.8 -29.7 -29.6 -29.2
permuted -29.9 -29.7 -29.6 -29.2 -29.8 -29.7 -29.6 -29.2
mushrooms standard IW -211.6 -206.5 -204.3 -215.5 -180.8 -194.2 -215.8 -339.0
complete-U -210.6 -204.3 -200.8 -215.5 -180.2 -180.7 -185.6 -339.0
permuted -210.8 -204.5 -201.4 -215.4 -180.2 -180.7 -187.6 -337.3
radon standard IW -1210.5 -1210.4 -1213.3 -1210.4 NaN -2422.9 -1595.8 -1636.5
complete-U -1210.5 -1210.2 -1210.2 -1210.4 NaN -1548.0 -1445.9 -1636.5
permuted -1210.5 -1210.2 -1211.8 -1210.4 NaN -1600.6 -1454.7 -1645.2
sonar standard IW -136.2 -126.3 -121.3 -117.9 -138.0 -154.9 -200.9 -226.7
complete-U -136.5 -127.4 -121.5 -117.9 -116.6 -120.9 -156.3 -226.7
permuted -136.5 -127.3 -121.5 -117.9 -116.7 -121.5 -158.2 -228.5
wells standard IW -2042.1 -2041.9 -2041.7 -2041.2 -2041.9 -2041.8 -2041.7 -2041.1
complete-U -2042.2 -2042.0 -2041.7 -2041.2 -2041.9 -2041.9 -2041.8 -2041.1
permuted -2042.2 -2041.9 -2041.7 -2041.2 -2041.9 -2041.8 -2041.8 -2041.1
30Published in Transactions on Machine Learning Research (02/2023)
Table 9: Median objective averaged over the last 200 iterations when using the complete-U DReG, permuted
DReG and the standard DReG gradient estimators. It can be seen that for at least 8 models out of 17,
using either the diagonal Gaussian or the full rank covariance Gaussian approximation, the best objective is
achievedwithanintermediatevalueof m, anditisatleast1natlargerthantheobjectivewith m= 16. These
models are: congress ,election88 ,election88Exp ,electric ,electric-one-pred ,irt-multilevel ,
mushrooms andradon. Optimizations using m= 1are not shown.
model methodDiagonal Gaussian Full Rank Covariance Gaussian
m
2 4 8 16 2 4 8 16
a1a DReG -652.7 -649.9 -648.0 -647.0 -659.7 -770.3 -936.6 -1205.4
comp.-DReG -652.5 -648.6 -646.5 -647.0 -655.7 -667.4 -894.2 -1205.4
perm.-DReG -652.5 -648.7 -646.4 -647.1 -655.3 -725.2 -874.7 -1209.8
australian DReG -264.4 -261.2 -259.0 -257.8 -256.7 -256.7 -256.7 -256.9
comp.-DReG -264.7 -261.6 -259.0 -257.8 -256.7 -256.7 -256.6 -256.9
perm.-DReG -264.7 -261.5 -258.9 -257.8 -256.7 -256.7 -256.6 -256.9
congress DReG 417.9 419.7 419.9 418.2 418.5 418.9 413.2 404.5
comp.-DReG 419.6 420.5 420.7 418.2 420.5 420.8 419.8 404.5
perm.-DReG 419.4 420.5 420.7 417.9 420.4 420.7 419.8 404.6
election88 DReG -1529.2 -1522.3 -1524.2 -1534.9 NaN -5964.4 -4349.2 NaN
comp.-DReG -1529.1 -1520.7 -1518.4 -1534.9 NaN -4950.7 -2079.0 NaN
perm.-DReG -1529.1 -1520.7 -1518.4 -1534.3 NaN -5439.8 -3041.2 NaN
election88Exp DReG -1755.8 -1571.9 -1502.0 -1461.9 NaN NaN NaN NaN
comp.-DReG -1733.2 -1495.9 -1468.8 -1461.9 NaN NaN -3664.0 NaN
perm.-DReG -1766.8 -1512.3 -1483.3 -1460.1 NaN NaN -3947.5 NaN
electric DReG -830.0 -827.2 -824.8 -826.2 NaN -1417.4 -1291.3 -1314.0
comp.-DReG -830.2 -826.1 -822.0 -826.2 NaN -1459.2 -1219.0 -1314.0
perm.-DReG -829.9 -826.3 -822.6 -826.3 NaN -1427.2 -1239.1 -1326.1
electric-one-pred DReG -1148.8 -1147.5 -1146.4 -1144.6 -1153.0 -1145.8 -1141.4 -1141.2
comp.-DReG -1148.5 -1146.0 -1146.8 -1144.6 -1150.7 -1144.1 -1140.3 -1141.2
perm.-DReG -1148.3 -1146.7 -1146.5 -1144.6 -1151.0 -1144.5 -1140.0 -1141.2
hepatitis DReG -561.3 -776.3 -775.1 -774.0 NaN NaN NaN NaN
comp.-DReG -561.1 -772.0 -772.6 -774.0 NaN NaN NaN NaN
perm.-DReG -561.3 -773.5 -774.8 -774.0 NaN NaN NaN NaN
hiv-chr DReG -606.2 -604.1 -605.4 -602.7 NaN NaN NaN NaN
comp.-DReG -606.1 -603.7 -602.2 -602.7 NaN NaN NaN NaN
perm.-DReG -606.1 -603.6 -602.9 -602.7 NaN NaN NaN NaN
ionosphere DReG -133.1 -129.3 -127.1 -125.6 -124.3 -125.8 -130.7 -142.1
comp.-DReG -133.2 -129.6 -127.2 -125.6 -124.2 -124.2 -124.7 -142.1
perm.-DReG -133.3 -129.6 -127.2 -125.6 -124.2 -124.3 -125.7 -142.0
irt DReG -15887.3 -15886.9 -15886.6 -15886.3 NaN NaN NaN NaN
comp.-DReG -15887.3 -15886.9 -15886.5 -15886.3 NaN NaN NaN NaN
perm.-DReG -15887.3 -15886.9 -15886.5 -15886.3 NaN NaN NaN NaN
irt-multilevel DReG -15226.1 -15199.4 -15195.8 -15224.4 NaN NaN NaN NaN
comp.-DReG -15206.9 -15188.6 -15188.0 -15224.4 NaN NaN NaN NaN
perm.-DReG -15214.0 -15191.6 -15188.4 -15222.2 NaN NaN NaN NaN
mesquite DReG -29.9 -29.8 -29.6 -29.4 -29.8 -29.7 -29.7 -29.3
comp.-DReG -29.9 -29.8 -29.6 -29.4 -29.8 -29.7 -29.7 -29.3
perm.-DReG -29.9 -29.8 -29.6 -29.4 -29.8 -29.7 -29.7 -29.3
mushrooms DReG -211.6 -206.6 -204.7 -215.9 -192.2 -251.2 -305.6 -405.3
comp.-DReG -210.6 -204.3 -201.1 -215.9 -180.3 -193.6 -253.5 -405.3
perm.-DReG -210.7 -204.4 -201.5 -215.4 -180.4 -194.3 -250.9 -400.8
radon DReG -1210.5 -1210.3 -1219.9 -1210.3 NaN -2410.8 -1624.9 -1650.9
comp.-DReG -1210.4 -1210.1 -1210.2 -1210.3 NaN -1538.0 -1445.7 -1650.9
perm.-DReG -1210.4 -1210.2 -1212.5 -1210.2 NaN -1593.3 -1466.2 -1642.4
sonar DReG -136.2 -126.2 -121.1 -117.6 -135.4 -152.5 -226.3 -259.6
comp.-DReG -136.5 -127.2 -121.5 -117.6 -115.2 -118.4 -155.6 -259.6
perm.-DReG -136.5 -127.3 -121.3 -117.6 -115.3 -118.9 -156.4 -260.5
wells DReG -2042.2 -2041.9 -2041.8 -2041.2 -2041.9 -2041.9 -2041.8 -2041.2
comp.-DReG -2042.2 -2042.0 -2041.9 -2041.2 -2041.9 -2041.9 -2041.9 -2041.2
perm.-DReG -2042.2 -2042.0 -2041.8 -2041.2 -2041.9 -2041.9 -2041.9 -2041.2
31