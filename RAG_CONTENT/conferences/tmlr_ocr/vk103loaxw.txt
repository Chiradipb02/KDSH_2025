Under review as submission to TMLR
TAMUNA: Doubly Accelerated Federated Learning with
Local Training, Compression, and Partial Participation
Anonymous authors
Paper under double-blind review
Abstract
Infederatedlearning, alargenumberofuserscollaboratetolearnaglobalmodel. Theyalter-
nate local computations and communication with a distant server. Communication, which
can be slow and costly, is the main bottleneck in this setting. In addition to communication-
efficiency, arobustalgorithmshouldallowforpartialparticipation, thedesirablefeaturethat
not all clients need to participate to every round of the training process. To reduce the com-
munication load and therefore accelerate distributed gradient descent, two strategies are
popular: 1) communicate less frequently; that is, perform several iterations of localcompu-
tations between the communication rounds; and 2) communicate compressed information
insteadoffull-dimensionalvectors. WeproposeTAMUNA,thefirstalgorithmfordistributed
optimization and federated learning, which harnesses these two strategies jointly and allows
for partial participation. TAMUNA converges linearly to an exact solution in the strongly
convex setting, with a doubly accelerated rate: it provably benefits from the two accelera-
tion mechanisms provided by local training and compression, namely a better dependency
on the condition number of the functions and on the model dimension, respectively.
1 Introduction
Federated Learning (FL) is a novel paradigm for training supervised machine learning models. Initiated
a few years ago (Konečný et al., 2016a;b; McMahan et al., 2017; Bonawitz et al., 2017), it has become a
rapidly growing interdisciplinary field. The key idea is to exploit the wealth of information stored on edge
devices, such as mobile phones, sensors and hospital workstations, to train global models, in a collaborative
way, while handling a multitude of challenges, like data privacy (Kairouz et al., 2021; Li et al., 2020a; Wang
et al., 2021). In contrast to centralized learning in a datacenter, in FL, the parallel computing units have
private data stored on each of them and communicate with a distant orchestrating server, which aggregates
the information and synchronizes the computations, so that the process reaches a consensus and converges
to a globally optimal model. In this framework, communication between the parallel workers and the server,
which can take place over the internet or cell phone network, can be slow, costly, and unreliable. Thus,
communication dominates the overall duration and cost of the process and is the main bottleneck to be
addressed by the community, before FL can be widely adopted and applied in our daily lives.
The baseline algorithm of distributed Gradient Descent ( GD) alternates between two steps: one round
of parallel computation of the local function gradients at the current model estimate, and one round of
communication of these gradient vectors to the server, which averages them to form the new estimate for
the next iteration. To decrease the communication load, two strategies can be used: 1) communicate less
frequently, or equivalently do more local computations between successive communication rounds; or 2)
compress the communicated vectors. We detail these two strategies in Section 1.3. Moreover, in practical
applications where FL is deployed, it is unrealistic to assume that all clients are available 100%of the time to
perform the required computation and communication operations. Thus, partial participation is an essential
feature in practice, whereby only part of the clients need to participate in any given round of the process,
while maintaining the overall convergence guarantees.
1Under review as submission to TMLR
In this paper, we propose a new randomized algorithm named TAMUNA , which combines local training and
compression for communication-efficient FL. It is variance-reduced (Hanzely & Richtárik, 2019; Gorbunov
etal.,2020a;Goweretal.,2020), sothatitconvergestoanexactsolution(withexactgradients), andprovably
benefits from the two mechanisms: the convergence rate is doubly accelerated, with a better dependency
on the condition number of the functions and on the dimension of the model, in comparison with GD. In
addition, TAMUNA handles partial participation of the clients. In the remainder of this section, we formulate
the setup, we propose a new model to characterize the communication complexity, we present the state of
the art, and we summarize our contributions.
1.1 Formalism
We consider a distributed client-server setting, in which n≥2clients perform computations in parallel and
communicate back and forth with a server. We study the convex optimization problem:
minimize
x∈Rdf(x):=1
nn/summationdisplay
i=1fi(x), (1)
where each function fi:Rd→Rmodels the individual cost of client i∈[n]:={1,...,n}, based on its
underlying private data. The number nof clients, as well as the dimension d≥1of the model, are typically
large. This problem is of key importance as it is an abstraction of empirical risk minimization, the dominant
framework in supervised machine learning.
For everyi∈[n], the function fiis supposed L-smooth and µ-strongly convex,1for someL≥µ > 0(a
sublinear convergence result is derived in the Appendix for the merely convex case, i.e. µ= 0). Thus,
the sought solution x⋆of (1) exists and is unique. We define κ:=L
µ. We focus on the strongly convex
case, because the analysis of linear convergence rates in this setting gives clear insights and allows us to
deepen our theoretical understanding of the algorithmic mechanisms under study; in our case, local training,
communication compression, and partial participation. The analysis of algorithms converging to a point with
zero gradient in (1) with nonconvex functions relies on significantly different proof techniques (Karimireddy
et al., 2021; Das et al., 2022), so the nonconvex setting is out of the scope of this paper.
To solve the problem (1), the baseline algorithm of Gradient Descent ( GD) consists in the simple iteration,
fort= 0,1,...,
xt+1:=xt−γ
nn/summationdisplay
i=1∇fi(xt),
for some stepsize γ∈(0,2
L). That is, at iteration t,xtis first broadcast by the server to all clients, which
compute the gradients ∇fi(xt)in parallel. These vectors are then sent to the server, which averages them
and performs the gradient descent step. It is well known that for γ= Θ(1
L),GDconverges linearly, with
iterationcomplexity O(κlogϵ−1)toreachϵ-accuracy. Since d-dimensionalvectorsarecommunicatedatevery
iteration, the communication complexity of GDin number of reals is O(dκlogϵ−1). Our goal is a twofold
acceleration of GD, with a better dependency to both κanddin this complexity. We want to achieve this
goal by leveraging the best of the two popular mechanisms of local training and communication compression.
1.2 Asymmetric communication regime
Uplink and downlink communication . We call uplink communication (UpCom) the parallel transmis-
sion of data from the clients to the server and downlink communication (DownCom) the broadcast of the
same message from the server to all clients. UpCom is usually significantly slower than DownCom, just like
uploading is slower than downloading on the internet or cell phone network. This can be due to the asymme-
try of the service provider’s systems or protocols used on the communication network, or cache memory and
1A function f:Rd→Ris said to be L-smooth if it is differentiable and its gradient is Lipschitz continuous with constant
L; that is, for every x∈Rdandy∈Rd,∥∇f(x)−∇f(y)∥≤L∥x−y∥, where, here and throughout the paper, the norm is the
Euclidean norm. fis said to be µ-strongly convex if f−µ
2∥·∥2is convex. We refer to Bauschke & Combettes (2017) for such
standard notions of convex analysis.
2Under review as submission to TMLR
aggregation speed constraints of the server, which has to decode and average the large number nof vectors
received at the same time during UpCom.
Communication complexity . We measure the UpCom or DownCom complexity as the expected num-
ber of communication rounds needed to estimate a solution with ϵ-accuracy, multiplied by the number of
real values sent during a communication round between the server and any client. Thus, the UpCom or
DownCom complexity of GDisO(dκlogϵ−1)). We leave it for future work to refine this model of counting
real numbers, to take into account how sequences of real numbers are quantized into bitstreams, achieving
further compression (Horváth et al., 2022; Albasyoni et al., 2020).
A model for the overall communication complexity . Since UpCom is usually slower than DownCom,
we proposeto measure the total communication (TotalCom)complexity as a weighted sumof the two UpCom
andDownComcomplexities: weassumethattheUpComcostis1(unitoftimepertransmittedrealnumber),
whereas the downCom cost is α∈[0,1]. Therefore,
TotalCom =UpCom +α.DownCom. (2)
A symmetric but unrealistic communication regime corresponds to α= 1, whereas ignoring downCom and
focusing on UpCom, which is usually the limiting factor, corresponds to α= 0. We will provide explicit
expressions of the parameters of our algorithm to minimize the TotalCom complexity for any given α∈[0,1],
keeping in mind that realistic settings correspond to small values of α. Thus, our model of communication
complexity is richer than only considering α= 0, as is usually the case.
1.3 Communication efficiency in FL: state of the art
Two approaches come naturally to mind to decrease the communication load: Local Training (LT), which
consists in communicating less frequently than at every iteration, and Communication Compression (CC),
which consists in sending less than dfloats during every communication round. In this section, we review
existing work related to these two strategies and to Partial Participation (PP).
1.3.1 Local Training (LT)
LT is a conceptually simple and surprisingly powerful communication-acceleration technique. It consists
in the clients performing multiple local GD steps instead of only one, between successive communication
rounds. This intuitively results in “better” information being communicated, so that less communication
rounds are needed to reach a given accuracy. As shown by ample empirical evidence, LT is very efficient
in practice. It was popularized by the FedAvgalgorithm of McMahan et al. (2017), in which LT is a core
component. However, LTwasheuristicandnotheorywasprovidedintheirpaper. LTwasanalyzedinseveral
works, in the homogeneous, or i.i.d. data, regime (Haddadpour & Mahdavi, 2019), and in the heterogeneous
regime, which is more representative in FL (Khaled et al., 2019; Stich, 2019; Khaled et al., 2020; Li et al.,
2020b; Woodworth et al., 2020; Gorbunov et al., 2021; Glasgow et al., 2022). It stands out that LT suffers
from so-called client drift, which is the fact that the local model obtained by client iafter several local GD
steps approaches the minimizer of its local cost function fi. The discrepancy between the exact solution
x⋆of (1) and the approximate solution obtained at convergence of LT was characterized in Malinovsky
et al. (2020). This deficiency of LT was corrected in the Scaffoldalgorithm of Karimireddy et al. (2020) by
introducing control variates, which correct for the client drift, so that the algorithm converges linearly to
the exact solution. S-Local-GD (Gorbunov et al., 2021) and FedLin(Mitra et al., 2021) were later proposed,
with similar convergence properties. Yet, despite the empirical superiority of these recent algorithms relying
on LT, their communication complexity remains the same as vanilla GD, i.e.O(dκlogϵ−1).
Most recently, a breakthrough was made with the appearance of accelerated LT methods. Scaffnew, proposed
by Mishchenko et al. (2022), is the first LT-based algorithm achieving O(d√κlogϵ−1)accelerated commu-
nication complexity. In Scaffnew, communication is triggered randomly with a small probability pat every
iteration. Thus, the expected number of local GD steps between two communication rounds is 1/p. By
choosingp= 1/√κ, the optimal dependency on√κinstead ofκ(Scaman et al., 2019) is obtained. In this
paper, we propose to go even further and tackle the multiplicative factor din the complexity of Scaffnew.
3Under review as submission to TMLR
Scaffnew has been extended in Malinovsky et al. (2022), using calls to variance-reduced (Gorbunov et al.,
2020a; Gower et al., 2020) stochastic gradient estimates instead of exact gradients. It has also been analyzed
in Condat & Richtárik (2023) as a particular case of RandProx , a primal-dual algorithm with a general ran-
domized and variance-reduced dual update. Conceptually, TAMUNA is inspired by RandProx , with the dual
update corresponding to the intermittent update of the control variates of the participating clients. TAMUNA
is not a particular case of RandProx , though, because the primal update of the model and the dual update of
the control variates are decoupled. Without compression and in case of full participation, TAMUNA reverts
toScaffnew.
A different approach was developed by Sadiev et al. (2022a) with the APDA-Inexact algorithm, and then by
Grudzień et al. (2023) with the 5GCSalgorithm: in both algorithms, the local steps correspond to an inner
loop to compute a proximity operator inexactly.
1.3.2 Partial Participation (PP)
PP, a.k.a. client sampling, is the property that not all clients need to participate in a given round, consisting
of a series of local steps followed by communication with the server. This is an important feature for a
FL method, since in practice, there are many reasons for which a client might be idle and unable to do
any computation and communication for a certain period of time. PP in SGD-type methods is now well
understood (Gower et al., 2019; Condat & Richtárik, 2022), but its combination with LT has remained
unconvincing so far. Scaffoldallows for LT and PP, but its communication complexity does not benefit
from LT. The variance-reduced FedVARP algorithm with LT and PP has been proposed Jhunjhunwala et al.
(2022), for nonconvex problems and with a bounded global variance assumption that does not hold in our
setting. Scaffnew does not allow for PP. This was the motivation for Grudzień et al. (2023) to develop 5GCS,
which is, to the best of our knowledge, the first and only algorithm enabling LT and PP, and enjoying
accelerated communication. We refer to Grudzień et al. (2023) for a detailed discussion of the literature of
LT and PP. 5GCSis completely different from Scaffnew and based on Point-SAGA (Defazio, 2016) instead of
GD. Thus, it is an indirect, or two-level, combination of LT and PP: PP comes from the random selection
of the activated proximity operators, whereas LT corresponds to an inner loop to compute these proximity
operators inexactly. TAMUNA is a direct combination of LT and PP as two intertwined stochastic processes.
TAMUNA reverts to Scaffnew in case of full participation (and no compression); in other words, TAMUNA
is the first generalization of Scaffnew to PP, and it fully retains its LT-based communication acceleration
benefits.
Throughoutthepaper, wedenoteby c∈{2,...,n}thecohortsize, ornumberofactiveclientsparticipatingin
every round. We report in Table 1 the communication complexity of the two known algorithms converging
linearly to the exact solution, while allowing for LT and PP, namely Scaffoldand5GCS.Scaffoldis not
accelerated, with a complexity depending on κ, and5GCSis accelerated with respect to κbut notd. Also,
in5GCSthe number of local steps in each communication round is fixed of order at least/parenleftbig/radicalbigcκ
n+ 1/parenrightbig
logκ,
whereas in TAMUNA it is random and typically much smaller, of order/radicalbigsκ
n+ 1, wherescan be as small as
2, see (14).
1.3.3 Communication Compression (CC)
To decrease the communication complexity, a widely used strategy is to make use of (lossy) compression; that
is, a possibly randomized mapping C:Rd→Rdis applied to the vector xthat needs to be communicated,
with the property that it is much faster to transfer C(x)than the full d-dimensional vector x. A popular
sparsifying compressor is rand-k, for somek∈[d]:={1,...,d}, which multiplies kelements of x, chosen
uniformly at random, by d/k, and sets the other ones to zero. If the receiver knows which coordinates have
been selected, e.g. by running the same pseudo-random generator, only these kelements of xare actually
communicated, so that the communication complexity is divided by the compression factor d/k. Another
sparsifying compressor is top-k, which keeps the kelements of xwith largest absolute values unchanged
and sets the other ones to zero. Some compressors, like rand-k, are unbiased; that is, E[C(x)] =xfor
everyx∈Rd, where E[·]denotes the expectation. On the other hand, compressors like top-kare biased
(Beznosikov et al., 2020).
4Under review as submission to TMLR
Table 1: UpCom complexity ( α= 0) of linearly converging algorithms with LT or CC and allowing for
PP (with exact gradients). The /tildewideOnotation hides the logϵ−1factor (and other log factors for Scaffold).
c∈{2,...,n}is the number of participating clients and the other notations are recalled in Table 3.
Algorithm LT CC UpCom
DIANA-PP(a)✗ ✓ /tildewideO/parenleftbig
(1 +d
c)κ+dn
c/parenrightbig
Scaffold ✓ ✗ /tildewideO(dκ+dn
c)
5GCS ✓ ✗ /tildewideO/parenleftbig
d√κ/radicalbign
c+dn
c/parenrightbig
TAMUNA ✓✓/tildewideO/parenleftig√
d√κ/radicalbign
c+d√κ√n
c+dn
c/parenrightig
(a)using independent rand-1 compressors, for instance. Note that O(√
d√κ/radicalbign
c+dn
c)is better than O(κ+dn
c)
andO(d√κ√n
c+dn
c)is better than O(d
cκ+dn
c), so that TAMUNA has a better complexity than DIANA-PP .
Table 2: TotalCom complexity of linearly converging algorithms using Local Training (LT), Communication
Compression (CC), or both, in case of full participation and exact gradients. The /tildewideOnotation hides the
logϵ−1factor. The notations are recalled in Table 3.
Algorithm LT CC TotalCom TotalCom=UpCom when α= 0
DIANA(a)✗ ✓/tildewideO/parenleftig
(1 +αd+d+αd2
n)κ+d+αd2/parenrightig
/tildewideO/parenleftbig
(1 +d
n)κ+d/parenrightbig
EF21(b)✗ ✓ /tildewideO(dκ) /tildewideO(dκ)
Scaffold ✓ ✗ /tildewideO(dκ) /tildewideO(dκ)
FedLin ✓ ✗ /tildewideO(dκ) /tildewideO(dκ)
S-Local-GD ✓ ✗ /tildewideO(dκ) /tildewideO(dκ)
Scaffnew ✓ ✗ /tildewideO(d√κ) /tildewideO(d√κ)
5GCS ✓ ✗ /tildewideO(d√κ) /tildewideO(d√κ)
FedCOMGATE ✓ ✓ /tildewideO(dκ) /tildewideO(dκ)
TAMUNA ✓✓/tildewideO/parenleftig√
d√κ+d√κ√n+d+√αd√κ/parenrightig
/tildewideO/parenleftig√
d√κ+d√κ√n+d/parenrightig
(a)using independent rand-1 compressors, for instance. Note that O(√
d√κ+d)is better than O(κ+d)and
O(d√κ√n+d)is better than O(d
nκ+d), so that TAMUNA has a better complexity than DIANA .
(b)using top-kcompressors with any k, for instance.
The variance-reduced algorithm DIANA(Mishchenko et al., 2019) is a major contribution to the field, as it
converges linearly with a large class of unbiased compressors. For instance, when the clients use independent
rand-1compressors for UpCom, the UpCom complexity of DIANAisO/parenleftbig
(κ(1 +d
n) +d) logϵ−1/parenrightbig
. Ifnis large,
this is much better than with GD.DIANAwas later extended in several ways (Horváth et al., 2022; Gorbunov
et al., 2020a); in particular, DIANA-PP is a generalized version allowing for PP (Condat & Richtárik, 2022).
Algorithms converging linearly with biased compressors have been proposed recently, like EF21(Richtárik
et al., 2021; Fatkhullin et al., 2021; Condat et al., 2022b), but the theory is less mature and the acceleration
potentialnotasclearaswithunbiasedcompressors. WesummarizeexistingresultsinTable2. Ouralgorithm
TAMUNA benefits from CC with specific unbiased compressors, with even more acceleration than DIANA.
Also, the focus in DIANAis on UpCom and its DownCom step is the same as in GD, with the full model
broadcast at every iteration, so that its TotalCom complexity can be worsethan the one of GD. Extensions
ofDIANAwith bidirectional CC, i.e. compression in both UpCom and DownCom, have been proposed
(Gorbunov et al., 2020b; Philippenko & Dieuleveut, 2020; Liu et al., 2020; Condat & Richtárik, 2022), but
this does not improve its TotalCom complexity; see also Philippenko & Dieuleveut (2021) and references
therein on bidirectional CC. We note that if LT is disabled ( L(r)≡1),TAMUNA is still new and does not
revert to a known algorithm with CC.
5Under review as submission to TMLR
Algorithm 1 TAMUNA
1:input: stepsizesγ > 0,η > 0; number of participating clients c∈ {2,...,n}; sparsity index for
compression s∈{2,...,c}; initial model estimate ¯x(0)∈Rdat the server and initial control variates
h(0)
1,...,h(0)
n∈Rdat the clients, such that/summationtextn
i=1h(0)
i= 0.
2:forr= 0,1,...(rounds) do
3:choose a subset Ω(r)⊂[n]of sizecuniformly at random
4:choose the number of local steps L(r)≥1
5:forclientsi∈Ω(r), in parallel, do
6:x(r,0)
i:= ¯x(r)(initialization received from the server)
7: forℓ= 0,...,L(r)−1(local steps) do
8:x(r,ℓ+1)
i:=x(r,ℓ)
i−γg(r,ℓ)
i+γh(r)
i, whereg(r,ℓ)
iis an unbiased stochastic estimate of ∇fi/parenleftbig
x(r,ℓ)
i/parenrightbig
of
varianceσ2
i
9: end for
10: end for
11:UpCom: the server and active clients agree on a random binary mask q(r)=/parenleftbig
q(r)
i/parenrightbig
i∈Ω(r)∈Rd×c
generatedasexplainedinFigure1, andeveryclient i∈Ω(r)sendsthecompressedvector C(r)
i/parenleftig
x(r,L(r))
i/parenrightig
to the server, where C(r)
i(v)denotesvmultiplied elementwise by q(r)
i.
12: ¯x(r+1):=1
s/summationtext
i∈Ω(r)C(r)
i/parenleftig
x(r,L(r))
i/parenrightig
(aggregation by the server)
13: forclientsi∈Ω(r), in parallel, do
14:h(r+1)
i:=h(r)
i+η
γ/parenleftig
C(r)
i/parenleftbig
¯x(r+1)/parenrightbig
−C(r)
i/parenleftig
x(r,L(r))
i/parenrightig/parenrightig/parenleftbig
¯x(r+1)is received from the server/parenrightbig
15: end for
16: forclientsi /∈Ω(r), in parallel, do
17:h(r+1)
i:=h(r)
i(the client is idle)
18: end for
19:end for
1.4 Challenges and contributions
Our new algorithm TAMUNA builds upon the LT mechanism of Scaffnew and enables PP and CC, which are
essential features for applicability to real-world FL setups. In short,
TAMUNA = (S)GD+LT/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
Scaffnew+PP+CC.
We focus on the strongly convex setting but we also prove sublinear convergence of TAMUNA in the merely
convex case in the Appendix. We emphasize that the problem can be arbitrarily heterogeneous: we do
not make any assumption on the functions fibeyond smoothness and strong convexity, and there is no
notion of data similarity whatsoever. We also stress that our goal is to deepen our theoretical understanding
of LT, CC and PP, and to make these 3 intuitive and effective mechanisms, which are widely used in
practice, work in the best possible way when harnessed to (stochastic) GD. Thus, we establish convergence of
TAMUNA in Theorem 1 with stochastic GD steps of bounded variance, which is more general than exact GD
steps, but only to illustrate the robustness of our framework. A thorough analysis would need to consider
the general setting of possibly variance-reduced (Gorbunov et al., 2020a; Gower et al., 2020) SGD local
steps, as was done for Scaffnew in Malinovsky et al. (2022). We leave it for future work, since we focus
on thecommunication complexity, and stochastic gradients can only worsenit. Reducing the computation
complexity using accelerated (Nesterov, 2004) or stochastic GD steps is somewhat orthogonal to our present
study.
Let us elaborate on the double challenge of combining LT with PP and CC. Our notations are summarized
in Table 3 for convenience.
6Under review as submission to TMLR
Table 3: Summary of the main notations used in the paper.
LT local training
CC communication compression
PP partial participation (a.k.a. client sampling)
L smoothness constant
µ strong convexity constant
κ=L/µ condition number of the functions
d dimension of the model
n,i number and index of clients
[n] ={1,...,n}
α weight on downlink communication (DownCom), see (2)
σ2
i,σ2:=/summationtext
iσ2
ivariance of the stochastic gradients, see (3)
c∈{2,...,n}number of active clients (a.k.a. cohort size). Full participation if c=n
Ω⊂[n]index set of active clients
s∈{2,...,c}sparsity index for compression. No compression if s=c
q= (qi)c
i=1random binary mask for compression, as detailed in Figure 1
r index of rounds
L,ℓ number and index of local steps in a round
p inverse of the expected number of local steps per round
t,T indexes of iterations
γ,η,χ stepsizes
xi local model estimate at client i
hi local control variate tracking ∇fi
¯x(r)model estimate at the server at round r
τ convergence rate
1.4.1 Combining LT and PP
With the recent breakthrough of Scaffnew (Mishchenko et al., 2022), we now understand that LT is not
only efficient in practice, but also grounded in theory, and yields communication acceleration if the number
of local steps is chosen appropriately. However, Scaffnew does not allow for PP. It has been an open and
challenging question to know whether its powerful randomized mechanism would be compatible with PP. In
fact, according to Grudzień et al. (2023), the authors of Scaffnew“have tried—very hard in their own words—
but their efforts did not bear any fruit.” In this paper, we break this lock: TAMUNA handles LT and PP,
and fully benefits from the acceleration of LT, whatever the participation level; that is, its communication
complexity depends on√κ, notκ.
Combining LT and PP is difficult: we want PP not only during communication whenever it occurs, but
also with respect to all computations before. The simple idea of allowing at every round some clients to be
active and to proceed normally, and other clients to be idle with unchanged local variables, does not work.
A key property of TAMUNA is that only the clients which participated in a given round make use of the
updated model broadcast by the server to update their control variates (step 14). From a mathematical
point of view, our approach relies on combining the two stochastic processes of probabilistic communication
and random client selection in two different ways , for updating after communication the model estimates xi
on one hand, and the control variates hion the other hand. Indeed, a crucial property is that the sum of
the control variates over all clients always remains zero. This separate treatment was the key to the success
of our design.
1.4.2 Combining LT and CC
It is very challenging to combine LT and CC. In the strongly convex and heterogeneous case considered
here, the methods Qsparse-local-SGD (Basu et al., 2020) and FedPAQ(Reisizadeh et al., 2020) do not converge
linearly. The only linearly converging LT + CC algorithm we are aware of is FedCOMGATE (Haddadpour
et al., 2021). But its rate is O(dκlogϵ−1), which does not show any acceleration. We note that random
7Under review as submission to TMLR
(a) (b) (c) (d)
Figure 1: The random sampling pattern q(r)= (q(r)
i)c
i=1∈Rd×cused for communication is generated by a
random permutation of the columns of a fixed binary template pattern, which has the prescribed number
s≥2of ones in every row. In (a) with (d,c,s ) = (5,6,2)and (b) with (d,c,s ) = (5,7,2), with ones in blue
and zeros in white, examples of the template pattern used when d≥c
s: for every row k∈[d], there are s
ones at columns i= mod(s(k−1),c) + 1,..., mod(sk−1,c) + 1. Thus, there are ⌊sd
c⌋or⌈sd
c⌉ones in every
column vector qi. In (c), an example of sampling pattern obtained after a permutation of the columns of
the template pattern in (a). In (d) with (d,c,s ) = (3,10,2), an example of the template pattern used when
c
s≥d: for every column i= 1,...,ds, there is 1 one at row k= mod(i−1,d) + 1. Thus, there is 0 or 1 one
in every column vector qi. We can note that when d=c
s, the two different rules for d≥c
sandc
s≥dfor
constructing the template pattern are equivalent, since they give exactly the same set of sampling patterns
when permuting their columns. These two rules make it possible to generate easily the columns q(r)
iofq(r)
on the fly, without having to generate the whole mask q(r)explicitly.
reshuffling, which can be seen as a kind of LT, has been combined with CC in Sadiev et al. (2022b);
Malinovsky & Richtárik (2022).
Like for PP, the program of combining LT and CC looks simple, as it seems we just have to “plug” com-
pressors into Scaffnew. Again, this simple approach does not work and the key is to have separate stochastic
mechanisms to update the local model estimates and the control variates. In Condat et al. (2022a), a
specific compression mechanism compatible with LT was designed and CompressedScaffnew , which combines
the LT mechanism of Scaffnew and this new CC mechanism, was proposed. CompressedScaffnew is the first
algorithm, to the best of our knowledge, to exhibit a doubly-accelerated linear rate, by leveraging LT and
CC. However, like Scaffnew,CompressedScaffnew only works in case of full participation. We stress that this
successful combination of LT and CC does not help in combining LT and PP: a non-participating client
does not participate to communication whenever it occurs, but it also does not perform any computation
before. Therefore, there is no way to enable PP in loopless algorithms like Scaffnew andCompressedScaffnew ,
where communication can be triggered at any time. Whether a client participates or not must be decided
in advance, at the beginning of a round consisting of a sequence of local steps followed by communication.
Our new algorithm TAMUNA is the first to solve this challenge. It works with any level of PP, with as few
as two clients participating in every round. TAMUNA relies on the same dedicated design of the compressors
asCompressedScaffnew , explained in Figure 1 and such that the messages sent by the different clients com-
plement each other, to keep a tight control of the variance after aggregation. We currently do not know how
to use any other type of compressors in TAMUNA .
Thus, by combining LT and CC, TAMUNA establishes the new state of the art in communication efficiency.
For instance, with exact gradients, if αis small and nis large, its TotalCom complexity in case of full
participation is
O/parenleftig/parenleftig√
d√κ+d/parenrightig
logϵ−1/parenrightig
;
our general result is in Theorem 2. Thus, TAMUNA enjoys twofold acceleration, with√κinstead ofκthanks
to LT and√
dinstead ofdthanks to CC.
8Under review as submission to TMLR
2 Proposed algorithm TAMUNA
The proposed algorithm TAMUNA is shown as Algorithm 1. Its main loop is over the rounds, indexed by
r. A round consists of a sequence, written as an inner loop, of local steps indexed by ℓand performed in
parallel by the active clients, followed by compressed communication with the server and update of the local
control variates hi. Thecactive, or participating, clients are selected randomly at the beginning of the
round. During UpCom, every client sends a compressed version of its local model xi: it sends only a few of
its elements, selected randomly according to the rule explained in Figure 1 and known by both the clients
and the server (for decoding).
At the end of the round, the aggregated model estimate ¯x(r+1)formed by the server is sent only to the
active clients, which use it to update their control variates hi. This update consists in overwriting only the
coordinates of hiwhich have been involved in the communication process; that is, for which the mask q(r)
i
has a one. Indeed, the received vector ¯x(r+1)does not contain relevant information to update hiat the other
coordinates.
The update of the local model estimates xiat the clients takes place at the beginning of the round, when
the active clients download the current model estimate ¯x(r)to initialize their local steps. So, it seems that
there are two DownCom steps from the server to the clients per round (steps 6 and 14), but the algorithm
can be written with only one: ¯x(r+1)can be broadcast by the server at the end of round rnot only to the
active clients of round r, but also to the active clients of the next round r+ 1, at the same time. We keep
the algorithm written in this way for simplicity.
Thus, the clients of index i /∈Ω(r), which do not participate in round r, are completely idle: they do not
compute and do not communicate at all. Their local control variates hiremain unchanged, and they do not
even need to store a local model estimate: they only need to receive the latest model estimate x(r)from the
server when they participate in the process.
InTAMUNA , unbiased stochastic gradient estimates of bounded variance σ2
ican be used: for every i∈[n],
E/bracketleftig
g(r,ℓ)
i|x(r,ℓ)
i/bracketrightig
=∇fi/parenleftbig
x(r,ℓ)
i/parenrightbig
,E/bracketleftbigg/vextenddouble/vextenddouble/vextenddoubleg(r,ℓ)
i−∇fi/parenleftbig
x(r,ℓ)
i/parenrightbig/vextenddouble/vextenddouble/vextenddouble2
|x(r,ℓ)
i/bracketrightbigg
≤σ2
i, (3)
for someσi≥0. We have g(r,ℓ)
i=∇fi/parenleftbig
x(r,ℓ)
i/parenrightbig
ifσi= 0. We define the total variance σ2:=/summationtextn
i=1σ2
i. Our
main result, stating linear convergence of TAMUNA to the exact solution x⋆of (1), or to a neighborhood if
σ>0, is the following:
Theorem 1 (fast linear convergence to a σ2-neighborhood) .Letp∈(0,1]. InTAMUNA , suppose that at
every round r≥0,L(r)is chosen randomly and independently according to a geometric law of mean p−1;
that is, for every L≥1,Prob(L(r)=L) = (1−p)L−1p. Also, suppose that
0<γ <2
L(4)
andη:=pχ, where
0<χ≤n(s−1)
s(n−1)∈/parenleftbigg1
2,1/bracketrightbigg
. (5)
For every total number t≥0of local steps made so far, define the Lyapunov function
Ψt:=n
γ/vextenddouble/vextenddouble¯xt−x⋆/vextenddouble/vextenddouble2+γ
p2χn−1
s−1n/summationdisplay
i=1/vextenddouble/vextenddouble/vextenddoubleh(r)
i−h⋆
i/vextenddouble/vextenddouble/vextenddouble2
, (6)
wherex⋆is the unique solution to (1),h⋆
i=∇fi(x⋆),r≥0andℓ∈{0,...,L(r)−1}are such that
t=r−1/summationdisplay
ˆr=0L(ˆr)+ℓ, (7)
9Under review as submission to TMLR
and
¯xt:=1
s/summationdisplay
i∈Ω(r)C(r)
i/parenleftig
x(r,ℓ)
i/parenrightig
. (8)
Then, for every t≥0,
E/bracketleftig
Ψt/bracketrightig
≤τtΨ0+γσ2
1−τ, (9)
where
τ:= max/parenleftbigg
(1−γµ)2,(γL−1)2,1−p2χs−1
n−1/parenrightbigg
<1. (10)
Also, ifσ= 0,(¯x(r))r∈Nconverges to x⋆and(h(r)
i)r∈Nconverges to h⋆
i, almost surely.
The complete proof is in the Appendix. We give a brief sketch here. The analysis is made for a single-loop
version of the algorithm, shown as Algorithm 2, with a loop over the iterations, indexed by t, and one local
step per iteration. Thus, communication does not happen at every iteration but is only triggered randomly
with probability p. Its convergence is proved in Theorem 3. Indeed, the contraction of the Lyapunov function
happens at every iteration and not at every round, whose size is random. That is why we have to reindex
the local steps to obtain a rate depending on the number of iterations tso far. We detail in the Appendix
how Theorem 3 on Algorithm 2 yields Theorem 1 on TAMUNA .
We note that in (8), ¯xtis actually computed only if ℓ= 0, in which case ¯xt= ¯x(r). We also note that the
theorem depends on sbut not onc. The dependence on cis hidden in the fact that sis upper bounded by c.
Remark 1 (settingη).In the conditions of Theorem 1, one can simply set η=p
2inTAMUNA , which is
independent of nands. However, the larger η, the better, so it is recommended to set
η=pn(s−1)
s(n−1). (11)
Also, as a rule of thumb, if the average number of local steps per round is L, one can replace pbyL−1.
We can comment on the difference between TAMUNA andScaffold, when CC is disabled ( s=c). InTAMUNA ,
hiis updated by adding ¯x(r+1)−x(r,L(r))
i, the difference between the latest global estimate ¯x(r+1)and the
latest local estimate x(r,L(r))
i. By contrast, in Scaffold,¯x(r)−x(r,L(r))
iis used instead, which involves the “old”
global estimate ¯x(r). Moreover, this difference is scaled by the number of local steps, which makes it small.
That is why no acceleration from LT can be obtained in Scaffold, whatever the number of local steps. This
is not a weakness of the analysis in Karimireddy et al. (2020) but an intrinsic limitation of Scaffold.
We can also note that the neighborhood size in (9) does not show so-called linear speedup; that is, it does
not decrease when nincreases. The properties of performing LT with SGD steps remain little understood
(Woodworth et al., 2020), and we believe this should be studied within the general framework of variance
reduction (Malinovsky et al., 2022). Again, this goes far beyond the scope of this paper, which focuses on
communication.
3 Iteration and communication complexities
We consider in this section that exact gradients are used ( σ= 0),2since our aim is to establish a new state of
the art for the communication complexity, regardless of the type of local computations. We place ourselves
in the conditions of Theorem 1.
We first remark that TAMUNA has the same iteration complexity as GD, with rateτ♯:= max(1−γµ,γL−1)2,
as long aspandsare large enough to have 1−χp2s−1
n−1≤τ♯. This is remarkable: LT, CC and PP do not
harm convergence at all, until some threshold.
2Ifσ > 0, it is possible to derive sublinear rates to reach ϵ-accuracy for the communication complexity, by setting γ
proportional to ϵ, as was done for Scaffnew in Mishchenko et al. (2022, Corollary 5.6).
10Under review as submission to TMLR
Let us consider the number of iterations (= total number of local steps) to reach ϵ-accuracy, i.e. E/bracketleftig
Ψt/bracketrightig
≤ϵ.
For anys≥2,p∈(0,1],γ= Θ(1
L), andχ= Θ(1), the iteration complexity of TAMUNA is
O/parenleftbigg/parenleftbigg
κ+n
sp2/parenrightbigg
logϵ−1/parenrightbigg
.
Thus, by choosing
p= min/parenleftbigg
Θ/parenleftbigg/radicalbiggn
sκ/parenrightbigg
,1/parenrightbigg
, (12)
which means that the average number of local steps per round is
E/bracketleftig
L(r)/bracketrightig
= max/parenleftbigg
Θ/parenleftbigg/radicalbiggsκ
n/parenrightbigg
,1/parenrightbigg
, (13)
the iteration complexity becomes
O/parenleftig/parenleftig
κ+n
s/parenrightig
logϵ−1/parenrightig
.
We now consider the communication complexity. Communication occurs at every iteration with probability
p, and during every communication round, DownCom consists in broadcasting the full d-dimensional vector
¯x(r), whereas in UpCom, compression is effective and the number of real values sent in parallel by the
clients is equal to the number of ones per column in the sampling pattern q, which is⌈sd
c⌉≥1. Hence, the
communication complexities are:
DownCom:O/parenleftbigg
pd/parenleftbigg
κ+n
sp2/parenrightbigg
logϵ−1/parenrightbigg
,
UpCom:O/parenleftbigg
p/parenleftbiggsd
c+ 1/parenrightbigg/parenleftbigg
κ+n
sp2/parenrightbigg
logϵ−1/parenrightbigg
.
TotalCom:O/parenleftbigg
p/parenleftbiggsd
c+ 1 +αd/parenrightbigg/parenleftbigg
κ+n
sp2/parenrightbigg
logϵ−1/parenrightbigg
.
For a given s, the best choice for p, for both DownCom and UpCom, is given in (12), for which
O/parenleftbigg
p/parenleftbigg
κ+n
sp2/parenrightbigg/parenrightbigg
=O/parenleftbigg/radicalbiggnκ
s+n
s/parenrightbigg
and the TotalCom complexity is
TotalCom:O/parenleftbigg/parenleftbigg/radicalbiggnκ
s+n
s/parenrightbigg/parenleftbiggsd
c+ 1 +αd/parenrightbigg
logϵ−1/parenrightbigg
.
We see the first acceleration effect due to LT: with a suitable p <1, the communication complexity only
depends on√κ, notκ, whatever the participation level cand compression level s.
Without compression, i.e. s=c, whatever α, the TotalCom complexity becomes
O/parenleftbigg
d/parenleftbigg/radicalbiggnκ
c+n
c/parenrightbigg
logϵ−1/parenrightbigg
.
We can now set sto further accelerate the algorithm, by minimizing the TotalCom complexity:
Theorem 2 (doubly accelerated communication) .In the conditions of Theorem 1, suppose that σ= 0,
γ= Θ(1
L),χ= Θ(1), and
p= min/parenleftbigg
Θ/parenleftbigg/radicalbiggn
sκ/parenrightbigg
,1/parenrightbigg
, s = max/parenleftig
2,/floorleftigc
d/floorrightig
,⌊αc⌋/parenrightig
. (14)
Then the TotalCom complexity of TAMUNA is
O/parenleftbigg/parenleftbigg√
d√κ/radicalbiggn
c+d√κ√n
c+dn
c+√αd√κ/radicalbiggn
c/parenrightbigg
logϵ−1/parenrightbigg
. (15)
11Under review as submission to TMLR
As reported in Tables 1 and 2, TAMUNA improves upon all known algorithms using either LT or CC on top
ofGD, even those working only with full participation.
Corollary 1 (dependence on α).As long as α≤max(2
c,1
d,n
κc), there is no difference with the case α= 0,
in which we only focus on UpCom, and the TotalCom complexity is
O/parenleftbigg/parenleftbigg√
d√κ/radicalbiggn
c+d√κ√n
c+dn
c/parenrightbigg
logϵ−1/parenrightbigg
. (16)
On the other hand, if α≥max(2
c,1
d,n
κc), the complexity increases and becomes
O/parenleftbigg√αd√κ/radicalbiggn
clogϵ−1/parenrightbigg
, (17)
but compression remains operational and effective with the√αfactor. It is only when α= 1thats=c, i.e.
there is no compression, and that the Upcom, DownCom and TotalCom complexities all become
O/parenleftbigg
d√κ/radicalbiggn
clogϵ−1/parenrightbigg
. (18)
Thus, in case of full participation ( c=n),TAMUNA is faster than Scaffnew for everyα∈[0,1].
Corollary 2 (full participation) .In case of full participation ( c=n), the TotalCom complexity of TAMUNA
is
O/parenleftbigg/parenleftbigg√
d√κ+d√κ√n+d+√αd√κ/parenrightbigg
logϵ−1/parenrightbigg
. (19)
4 Experiments
Our work is theoretical and studies the foundational properties of a class of algorithms. Nonetheless, we
carry experiments to illustrate our results using a practical logistic regression problem.
The global loss function is defined as
f(x) =1
MM/summationdisplay
m=1/parenleftig
log/parenleftbig
1 + exp/parenleftbig
−bma⊤
mx/parenrightbig/parenrightbig
+µ
2∥x∥2/parenrightig
, (20)
where the variables am∈Rdandbm∈{− 1,1}represent the data samples, and Mdenotes the total number
of samples. The function fin (20) is divided into nseparate functions fi, with any remainder from dividing
Mbyndiscarded.
We select the strong convexity constant µso thatκ= 104.
For our analysis, we choose n= 1000and examine two scenarios: in the first one, we have d > nusing
the ‘real-sim’ dataset with d= 20958, and in the second one, we have n > dusing the ‘w8a’ dataset with
d= 300, from the widely-used LIBSVM library (Chang & Lin, 2011). Additionally, we consider two cases
for each scenario: α= 0andα= 0.1, whereαis the weight on DownCom defined in (2).
We measure the convergence error f(x)−f(x⋆)with respect to TotalCom, i.e. the total number of com-
municated reals, as defined in Section (1.2). Here, xdenotes the model known by the server; for TAMUNA ,
this is ¯x(r). This error serves as a natural basis for comparing algorithms, and since fisL-smooth, we have
f(x)−f(x⋆)≤L
2∥x−x⋆∥2for anyx. Consequently, the error converges linearly at the same rate as Ψin
Theorem 1..
We compare the performance of three algorithms allowing for PP, namely Scaffold,5GCS, andTAMUNA , for
two participation scenarios: c=nandc= 0.1n(10% participation). In the full participation case, we add
Scaffnew to the comparison.
In order to ensure theoretical conditions that guarantee linear convergence, we set γandηforTAMUNA as
γ=2
L+µ, η =pn(s−1)
s(n−1),
12Under review as submission to TMLR
(a) w8a,n= 1000,α= 0,c=n (b) w8a,n= 1000,α= 0.1,c=n
(c) w8a,n= 1000,α= 0,c= 0.1n (d) w8a,n= 1000,α= 0.1,c= 0.1n
Figure 2: Logistic regression experiment in the case n > d. The dataset w8a has d= 300features and
n= 1000, son≈3d. The first row shows a comparison in the full participation regime, while the second
row shows a comparison in the partial participation regime with 10% of clients. On the left, α= 0, while on
the right,α= 0.1.
where the remaining parameters sandpare fine-tuned to achieve the best communication complexity. In
our experimental setup, we found that using s= 40andp= 0.01resulted in excellent performance. The
conditions of Theorem 1 are met with these values, so linear convergence of TAMUNA is guaranteed. We
adopt the same values of γandpforScaffnew. ForScaffold, we usep−1local steps, which is the same, on
average, as for TAMUNA andScaffnew; the behavior of Scaffoldchanged marginally with other values. We
also setγto its highest value that ensures convergence. In the case of 5GCS, we tuneγ,τ, and the number
of local steps to achieve the best communication complexity.
The models in all algorithms, as well as the control variates in TAMUNA ,Scaffnew andScaffold, are initialized
with zero vectors.
The results are shown in Figures 2 and 3. Each algorithm is run multiple times with different random seeds,
depending on its variance (7 times for TAMUNA , 5 times for Scaffnew, and 3 times for Scaffoldand5GCS).
The shaded area in the plots shows the difference between the maximum and minimum convergence error
achieved over these runs. Additionally, the progress of the first run for each algorithm is depicted with a
thicker line and markers.
As can be seen, our proposed algorithm TAMUNA outperforms all other methods. In case of full partici-
pation,Scaffnew outperforms Scaffoldand5GCS, which shows the efficiency of its LT mechanism. TAMUNA
embeds the same mechanism and also benefits from it, but it outperforms Scaffnew thanks to CC, its second
13Under review as submission to TMLR
(a) real-sim, n= 1000,α= 0,c=n (b) real-sim, n= 1000,α= 0.1,c=n
(c) real-sim, n= 1000,α= 0,c= 0.1n (d) real-sim, n= 1000,α= 0.1,c= 0.1n
Figure 3: Logistic regression experiment in the case d > n. The dataset real-sim has d= 20,958features
andn= 1000, son≈d/20. The first row shows a comparison in the full participation regime, while the
second row shows a comparison in the partial participation regime with 10% of clients. On the left, α= 0,
while on the right, α= 0.1.
communication-acceleration mechanism. The difference between TAMUNA andScaffnew is larger for α= 0
than forα= 0.1, as explained by our theory; the difference would vanish if αtends to 1.TAMUNA is ap-
plicable and proved to converge with any level of PP, whereas Scaffnew only applies to the full participation
case.
5 Conclusion
We have proposed TAMUNA , the first communication-efficient algorithm that allows for partial participation
(PP) and provably benefits from the two combined acceleration mechanisms of Local Training (LT) and
Communication Compression (CC), in the convex setting. Moreover, this is achieved not only for uplink
communication, but for our more comprehensive model of total communication. These theoretical guaran-
tees are confirmed in practice and TAMUNA communicates less than existing algorithms to reach the same
accuracy. An important venue for future work will be to generalize our specific compression mechanism to
a broad class of compressors including quantization (Horváth et al., 2022). Another venue consists in imple-
menting internal variance reduction for the stochastic gradients, as was done for Scaffnew in Malinovsky et al.
(2022). Analyzing the properties of TAMUNA on nonconvex problems should also be studied (Karimireddy
et al., 2021; Das et al., 2022).
14Under review as submission to TMLR
References
A. Albasyoni, M. Safaryan, L. Condat, and P. Richtárik. Optimal gradient compression for distributed and
federated learning. preprint arXiv:2010.03246, 2020.
D. Basu, D. Data, C. Karakus, and S. N. Diggavi. Qsparse-Local-SGD: Distributed SGD With Quantization,
Sparsification, and Local Computations. IEEE Journal on Selected Areas in Information Theory , 1(1):
217–226, 2020.
H. H. Bauschke and P. L. Combettes. Convex Analysis and Monotone Operator Theory in Hilbert Spaces .
Springer, New York, 2nd edition, 2017.
D. P. Bertsekas. Convex optimization algorithms . Athena Scientific, Belmont, MA, USA, 2015.
A. Beznosikov, S. Horváth, P. Richtárik, and M. Safaryan. On biased compression for distributed learning.
preprint arXiv:2002.12410, 2020.
K. Bonawitz, V. Ivanov, B. Kreuter, A. Marcedone, H. B. McMahan, S. Patel, D. Ramage, A. Segal, and
K. Seth. Practical secure aggregation for privacy-preserving machine learning. In Proc. of the 2017 ACM
SIGSAC Conference on Computer and Communications Security , pp. 1175–1191, 2017.
C.-C. Chang and C.-J. Lin. LIBSVM: A library for support vector machines. ACM Trans-
actions on Intelligent Systems and Technology , 2:27:1–27:27, 2011. Software available at
http://www.csie.ntu.edu.tw/%7Ecjlin/libsvm.
L. Condat and P. Richtárik. MURANA: A generic framework for stochastic variance-reduced optimization.
InProc. of the conference Mathematical and Scientific Machine Learning (MSML), PMLR 190 , pp. 81–96,
2022.
L. Condat and P. Richtárik. RandProx: Primal-dual optimization algorithms with randomized proximal
updates. In Proc. of Int. Conf. Learning Representations (ICLR) , 2023.
L. Condat, I. Agarský, and P. Richtárik. Provably doubly accelerated federated learning: The first theoreti-
cally successful combination of local training and compressed communication. preprint arXiv:2210.13277,
2022a.
L. Condat, K. Li, and P. Richtárik. EF-BV: A unified theory of error feedback and variance reduction
mechanisms for biased and unbiased compression in distributed optimization. In Proc. of Conf. Neural
Information Processing Systems (NeurIPS) , 2022b.
R. Das, A. Acharya, A. Hashemi, S. Sanghavi, I. S. Dhillon, and U. Topcu. Faster non-convex federated
learning via global and local momentum. In Proc. of Conf. on Uncertainty in Artificial Intelligence (UAI) ,
2022.
A. Defazio. A simple practical accelerated method for finite sums. In Proc. of 30st Conf. Neural Information
Processing Systems (NIPS) , volume 29, pp. 676–684, 2016.
I. Fatkhullin, I. Sokolov, E. Gorbunov, Z. Li, and P. Richtárik. EF21 with bells & whistles: Practical
algorithmic extensions of modern error feedback. preprint arXiv:2110.03294, 2021.
M. R. Glasgow, H. Yuan, and T. Ma. Sharp bounds for federated averaging (Local SGD) and continuous
perspective. In Proc. of Int. Conf. Artificial Intelligence and Statistics (AISTATS), PMLR 151 , pp.
9050–9090, 2022.
E. Gorbunov, F. Hanzely, and P. Richtárik. A unified theory of SGD: Variance reduction, sampling, quanti-
zation and coordinate descent. In Proc. of 23rd Int. Conf. Artificial Intelligence and Statistics (AISTATS),
PMLR 108 , 2020a.
E. Gorbunov, D. Kovalev, D. Makarenko, and P. Richtárik. Linearly converging error compensated SGD.
InProc. of Conf. Neural Information Processing Systems (NeurIPS) , 2020b.
15Under review as submission to TMLR
E. Gorbunov, F. Hanzely, and P. Richtárik. Local SGD: Unified theory and new efficient methods. In Proc.
of 24th Int. Conf. Artificial Intelligence and Statistics (AISTATS), PMLR 130 , pp. 3556–3564, 2021.
R. M. Gower, N. Loizou, X. Qian, A. Sailanbayev, E. Shulgin, and P. Richtárik. SGD: General analysis and
improved rates. In Proc. of 36th Int. Conf. Machine Learning (ICML) , volume PMLR 97, pp. 5200–5209,
2019.
R. M. Gower, M. Schmidt, F. Bach, and P. Richtárik. Variance-reduced methods for machine learning. Proc.
of the IEEE , 108(11):1968–1983, November 2020.
M. Grudzień, G. Malinovsky, and P. Richtárik. Can 5th Generation Local Training Methods Support Client
Sampling? Yes! In Proc. of Int. Conf. Artificial Intelligence and Statistics (AISTATS) , April 2023.
F. Haddadpour and M. Mahdavi. On the Convergence of Local Descent Methods in Federated Learning.
preprint arXiv:1910.14425, 2019.
Farzin Haddadpour, Mohammad Mahdi Kamani, Aryan Mokhtari, and Mehrdad Mahdavi. Federated learn-
ing with compression: Unified analysis and sharp guarantees. In Proc. of Int. Conf. Artificial Intelligence
and Statistics (AISTATS), PMLR 130 , pp. 2350–2358, 2021.
F. Hanzely and P. Richtárik. One method to rule them all: Variance reduction for data, parameters and
many new methods. preprint arXiv:1905.11266, 2019.
S. Horváth, C.-Y. Ho, L. Horváth, A. N. Sahu, M. Canini, and P. Richtárik. Natural compression for dis-
tributed deep learning. In Proc. of the conference Mathematical and Scientific Machine Learning (MSML),
PMLR 190 , 2022.
S. Horváth, D. Kovalev, K. Mishchenko, S. Stich, and P. Richtárik. Stochastic distributed learning with
gradient quantization and variance reduction. Optimization Methods and Software , 2022.
D. Jhunjhunwala, P. Sharma, A. Nagarkatti, and G. Joshi. FedVARP: Tackling the variance due to partial
client participation in federated learning. In Proc. of 38th Conf. Uncertainty in Artificial Intelligence
(UAI), volume PMLR 180, pp. 906–916, 2022.
P. Kairouz et al. Advances and open problems in federated learning. Foundations and Trends in Machine
Learning , 14(1–2), 2021.
S. P. Karimireddy, S. Kale, M. Mohri, S. Reddi, S. U. Stich, and A. T. Suresh. SCAFFOLD: Stochastic
controlled averaging for federated learning. In Proc. of 37th Int. Conf. Machine Learning (ICML) , pp.
5132–5143, 2020.
S. P. Karimireddy, M. Jaggi, S. Kale, M. Mohri, S. Reddi, S. U. Stich, and A. T. Suresh. Breaking the
centralized barrier for cross-device federated learning. In Proc. of Conf. Neural Information Processing
Systems (NeurIPS) , 2021.
A. Khaled, K. Mishchenko, and P. Richtárik. Better communication complexity for local SGD. In NeurIPS
Workshop on Federated Learning for Data Privacy and Confidentiality , 2019.
A. Khaled, K. Mishchenko, and P. Richtárik. Tighter theory for local SGD on identical and heterogeneous
data. In Proc. of 23rd Int. Conf. Artificial Intelligence and Statistics (AISTATS), PMLR 108 , 2020.
J. Konečný, H. B. McMahan, D. Ramage, and P. Richtárik. Federated optimization: distributed machine
learning for on-device intelligence. arXiv:1610.02527, 2016a.
J. Konečný, H. B. McMahan, F. X. Yu, P. Richtárik, A. T. Suresh, and D. Bacon. Federated learning: Strate-
gies for improving communication efficiency. In NIPS Private Multi-Party Machine Learning Workshop ,
2016b. arXiv:1610.05492.
T. Li, A. K. Sahu, A. Talwalkar, and V. Smith. Federated learning: Challenges, methods, and future
directions. IEEE Signal Processing Magazine , 3(37):50–60, 2020a.
16Under review as submission to TMLR
X. Li, K. Huang, W. Yang, S. Wang, and Z. Zhang. On the convergence of FedAvg on non-iid data. In Proc.
of Int. Conf. Learning Representations (ICLR) , 2020b.
Xiaorui Liu, Yao Li, Jiliang Tang, and Ming Yan. A double residual compression algorithm for efficient
distributed learning. In Proc. of Int. Conf. Artificial Intelligence and Statistics (AISTATS), PMLR 108 ,
pp. 133–143, 2020.
G. Malinovsky, D. Kovalev, E. Gasanov, L. Condat, and P. Richtárik. From local SGD to local fixed point
methods for federated learning. In Proc. of 37th Int. Conf. Machine Learning (ICML) , volume PMLR
119, pp. 6692–6701, 2020.
G. Malinovsky, K. Yi, and P. Richtárik. Variance reduced ProxSkip: Algorithm, theory and application to
federated learning. In Proc. of Conf. Neural Information Processing Systems (NeurIPS) , 2022.
Grigory Malinovsky and Peter Richtárik. Federated random reshuffling with compression and variance
reduction. preprint arXiv:arXiv:2205.03914, 2022.
H. B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. Agüera y Arcas. Communication-efficient
learning of deep networks from decentralized data. In Proc. of Int. Conf. Artificial Intelligence and
Statistics (AISTATS), PMLR 54 , 2017.
K. Mishchenko, E. Gorbunov, M. Takáč, and P. Richtárik. Distributed learning with compressed gradient
differences. arXiv:1901.09269, 2019.
K. Mishchenko, G. Malinovsky, S. Stich, and P. Richtárik. ProxSkip: Yes! Local Gradient Steps Provably
Lead to Communication Acceleration! Finally! In Proc. of the 39th International Conference on Machine
Learning (ICML) , July 2022.
A. Mitra, R. Jaafar, G. Pappas, and H. Hassani. Linear convergence in federated learning: Tackling client
heterogeneity and sparse gradients. In Proc. of Conf. Neural Information Processing Systems (NeurIPS) ,
2021.
Y. Nesterov. Introductory lectures on convex optimization: a basic course . Kluwer Academic Publishers,
2004.
Constantin Philippenko and Aymeric Dieuleveut. Artemis: tight convergence guarantees for bidirectional
compression in federated learning. preprint arXiv:2006.14591, 2020.
ConstantinPhilippenkoandAymericDieuleveut. Preservedcentralmodelforfasterbidirectionalcompression
in distributed settings. In Proc. of Conf. Neural Information Processing Systems (NeurIPS) , 2021.
A. Reisizadeh, A. Mokhtari, H. Hassani, A. Jadbabaie, and R. Pedarsani. FedPAQ: A communication-
efficient federated learning method with periodic averaging and quantization. In Proc. of Int. Conf.
Artificial Intelligence and Statistics (AISTATS) , pp. 2021–2031, 2020.
P. Richtárik, I. Sokolov, and I. Fatkhullin. EF21: A new, simpler, theoretically better, and practically faster
error feedback. In Proc. of 35th Conf. Neural Information Processing Systems (NeurIPS) , 2021.
A. Sadiev, D. Kovalev, and P. Richtárik. Communication acceleration of local gradient methods via an
accelerated primal-dual algorithm with an inexact prox. In Proc. of Conf. Neural Information Processing
Systems (NeurIPS) , 2022a.
A. Sadiev, G. Malinovsky, E. Gorbunov, I. Sokolov, A. Khaled, K. Burlachenko, and P. Richtárik. Federated
optimization algorithms with random reshuffling and gradient compression. preprint arXiv:2206.07021,
2022b.
K. Scaman, F. Bach, S. Bubeck, Y. T. Lee, and L. Massoulié. Optimal convergence rates for convex
distributed optimization in networks. Journal of Machine Learning Research , 20:1–31, 2019.
17Under review as submission to TMLR
S. U. Stich. Local SGD converges fast and communicates little. In Proc. of International Conference on
Learning Representations (ICLR) , 2019.
J. Wang et al. A field guide to federated optimization. preprint arXiv:2107.06917, 2021.
B. E. Woodworth, K. K. Patel, and N. Srebro. Minibatch vs Local SGD for heterogeneous distributed
learning. In Proc. of Conf. Neural Information Processing Systems (NeurIPS) , 2020.
18Under review as submission to TMLR
Algorithm 2
1:input:stepsizesγ > 0,χ > 0; probability p∈(0,1]; number of participating clients c∈{2,...,n};
compression index s∈ {2,...,c}; initial estimates x0
1,...,x0
n∈Rdandh0
1,...,h0
n∈Rdsuch that/summationtextn
i=1h0
i= 0, sequence of independent coin flips θ0,θ1,...with Prob(θt= 1) =p, and for every t
withθt= 1, a subset Ωt⊂[n]of sizecchosen uniformly at random and a random binary mask
qt= (qt
i)i∈Ωt∈Rd×cgenerated as explained in Figure 1. The compressed vector Ct
i(v)isvmultiplied
elementwise by qt
i.
2:fort= 0,1,...do
3:fori= 1,...,n, at clients in parallel, do
4: ˆxt
i:=xt
i−γgt
i+γht
i, wheregt
iis an unbiased stochastic estimate of ∇fi(xt
i)of variance σ2
i
5: ifθt= 1then
6: ifi∈Ωtthen
7: send ˆxt
ito the server, which aggregates ¯xt:=1
s/summationtext
j∈ΩtCt
j(ˆxt
j)and broadcasts it to all clients
8: ht+1
i:=ht
i+pχ
γ/parenleftbig
Ct
i(¯xt)−Ct
i(ˆxt
i)/parenrightbig
9: else
10: ht+1
i:=ht
i
11: end if
12:xt+1
i:= ¯xt
13: else
14:xt+1
i:= ˆxt
i
15:ht+1
i:=ht
i
16: end if
17: end for
18:end for
Appendix
A Proof of Theorem 1
We first prove convergence of Algorithm 2, which is a single-loop version of TAMUNA ; that is, there is a
unique loop over the iterations and there is one local step per iteration. In Section A.2, we show that this
yields a proof of Theorem 1 for TAMUNA . We can note that in case of full participation ( c=n,Ωt≡[n]),
Algorithm 2 reverts to CompressedScaffnew (Condat et al., 2022a).
To simplify the analysis of Algorithm 2, we introduce vector notations: the problem (1) can be written as
findx⋆= arg min
x∈Xf(x)s.t.Wx= 0, (21)
whereX:=Rd×n, an element x= (xi)n
i=1∈Xis a collection of vectors xi∈Rd,f:x∈X∝⇕⊣√∫⊔≀→/summationtextn
i=1fi(xi)is
L-smooth and µ-strongly convex, the linear operator W:X→Xmaps x= (xi)n
i=1to(xi−1
n/summationtextn
j=1xj)n
i=1.
The constraint Wx= 0means that xminus its average is zero; that is, xhas identical components x1=
···=xn. Thus, (21) is indeed equivalent to (1). We have W=W∗=W2.
We also rewrite Algorithm 2 using vector notations as Algorithm 3. It converges linearly:
Theorem 3 (fast linear convergence) .In Algorithm 3, suppose that 0< γ <2
L,0< χ≤n(s−1)
s(n−1),ω=
n−1
p(s−1)−1. For every t≥0, define the Lyapunov function
Ψt:=1
γ/vextenddouble/vextenddoublext−x⋆/vextenddouble/vextenddouble2+γ(1 +ω)
pχ/vextenddouble/vextenddoubleht−h⋆/vextenddouble/vextenddouble2, (22)
where x⋆is the unique solution to (21)andh⋆:=∇f(x⋆). Then Algorithm 3 converges linearly: for every
t≥0,
E/bracketleftbig
Ψt/bracketrightbig
≤τtΨ0+γσ2
1−τ, (23)
19Under review as submission to TMLR
Algorithm 3
input:stepsizesγ >0,χ>0; probability p∈(0,1], parameter ω≥0; number of participating clients c∈
{2,...,n}; compression index s∈{2,...,c}; initial estimates x0∈Xandh0∈Xsuch that/summationtextn
i=1h0
i= 0;
sequence of independent coin flips θ0,θ1,...with Prob(θt= 1) =p, and for every twithθt= 1, a subset
Ωt⊂[n]of sizecchosen uniformly at random and a random binary mask qt= (qt
i)i∈Ωt∈Rd×cgenerated
as explained in Figure 1. The compressed vector Ct
i(v)isvmultiplied elementwise by qt
i.
fort= 0,1,...do
ˆ xt:=xt−γgt+γht, where gt= (gt
i)n
i=1≈∇f(xt)
ifθt= 1then
¯ xt:= (¯xt)n
i=1, where ¯xt:=1
s/summationtext
j∈ΩtCt
j(ˆxt
j)
xt+1:=¯ xt
dt:= (dt
i)n
i=1withdt
i=/braceleftbigg(1 +ω) (Ct
i(ˆxt
i)−Ct
i(¯xt))ifi∈Ωt,
0otherwise
else
xt+1:=ˆ xt
dt:= 0
end if
ht+1:=ht−pχ
γ(1+ω)dt
end for
where
τ:= max/parenleftbigg
(1−γµ)2,(γL−1)2,1−p2χs−1
n−1/parenrightbigg
<1. (24)
Also, ifσ= 0,(xt)t∈Nand(ˆ xt)t∈Nboth converge to x⋆and(ht)t∈Nconverges to h⋆, almost surely.
Proof.We consider the variables of Algorithm 3. For every t≥0, we denote byFt
0theσ-algebra generated
by the collection of X-valued random variables x0,h0,...,xt,ht, and byFttheσ-algebra generated by these
variables, as well as the stochastic gradients gt.dtis a random variable; as proved in Section A.1, it satisfies
the 3 following properties, on which the convergence analysis of Algorithm 3 relies: for every t≥0,
1.E[dt|Ft] =Wˆ xt.
2.E/bracketleftig/vextenddouble/vextenddoubledt−Wˆ xt/vextenddouble/vextenddouble2|Ft/bracketrightig
≤ω/vextenddouble/vextenddoubleWˆ xt/vextenddouble/vextenddouble2.
3.dtbelongs to the range of W; that is,/summationtextn
i=1dt
i= 0.
We suppose that/summationtextn
i=1h0
i= 0. Then, it follows from the third property of dtthat, for every t≥0,/summationtextn
i=1ht
i= 0; that is,Wht=ht.
For everyt≥0, we define ˆht+1:=ht−pχ
γWˆ xt,wt:=xt−γgtandw⋆:=x⋆−γ∇f(x⋆). We also define
¯ xt♯:= (¯xt♯)n
i=1, with ¯xt♯:=1
n/summationtextn
i=1ˆxt
i; that is, ¯xt♯is the exact average of the ˆxt
i, of which ¯xtis an unbiased
random estimate.
Lett≥0. We have
E/bracketleftig/vextenddouble/vextenddoublext+1−x⋆/vextenddouble/vextenddouble2|Ft/bracketrightig
=pE/bracketleftig/vextenddouble/vextenddouble¯ xt−x⋆/vextenddouble/vextenddouble2|Ft,θt= 1/bracketrightig
+ (1−p)/vextenddouble/vextenddoubleˆ xt−x⋆/vextenddouble/vextenddouble2,
Since E[¯ xt|Ft,θt= 1] = ¯ xt♯,
E/bracketleftig/vextenddouble/vextenddouble¯ xt−x⋆/vextenddouble/vextenddouble2|Ft,θt= 1/bracketrightig
=/vextenddouble/vextenddouble¯ xt♯−x⋆/vextenddouble/vextenddouble2+E/bracketleftig/vextenddouble/vextenddouble¯ xt−¯ xt♯/vextenddouble/vextenddouble2|Ft,θ= 1/bracketrightig
,
with/vextenddouble/vextenddouble¯ xt♯−x⋆/vextenddouble/vextenddouble2=/vextenddouble/vextenddoubleˆ xt−x⋆/vextenddouble/vextenddouble2−/vextenddouble/vextenddoubleWˆ xt/vextenddouble/vextenddouble2.
20Under review as submission to TMLR
To analyze E/bracketleftig
∥¯ xt−x⋆∥2|Ft,θt= 1/bracketrightig
, where the expectation is with respect to the active subset Ωtand the
mask qt, we can remark that the expectation and the squared Euclidean norm are separable with respect to
the coordinates of the d-dimensional vectors. So, we can reason on the coordinates independently on each
other, even if the the coordinates, or rows, of qtare mutually dependent. Also, for a given coordinate k∈[d],
choosingselements at random among the celements ˆxt
i,kwithi∈Ωt, with Ωtchosen uniformly at random
too, is equivalent to selecting selements ˆxt
i,kamong alli∈[n]uniformly at random in the first place. Thus,
for every coordinate k∈[d], it is like a subset /tildewideΩt
k⊂[n]of sizes, which corresponds to the location of the
ones in the k-th row of qt, is chosen uniformly at random and
¯xt
k=1
s/summationdisplay
i∈/tildewideΩt
kˆxt
i,k.
Then, as proved in Condat & Richtárik (2022, Proposition 1),
E/bracketleftig/vextenddouble/vextenddouble¯ xt−¯ xt♯/vextenddouble/vextenddouble2|Ft,θt= 1/bracketrightig
=nd/summationdisplay
k=1E/tildewideΩt
k

1
s/summationdisplay
i∈/tildewideΩt
kˆxt
i,k−1
nn/summationdisplay
j=1ˆxt
j,k
2
|Ft
=ν/vextenddouble/vextenddoubleWˆ xt/vextenddouble/vextenddouble2,
where
ν:=n−s
s(n−1)∈/bracketleftbigg
0,1
2/parenrightbigg
. (25)
Moreover,
/vextenddouble/vextenddoubleˆ xt−x⋆/vextenddouble/vextenddouble2=/vextenddouble/vextenddoublewt−w⋆/vextenddouble/vextenddouble2+γ2/vextenddouble/vextenddoubleht−h⋆/vextenddouble/vextenddouble2+ 2γ⟨wt−w⋆,ht−h⋆⟩
=/vextenddouble/vextenddoublewt−w⋆/vextenddouble/vextenddouble2−γ2/vextenddouble/vextenddoubleht−h⋆/vextenddouble/vextenddouble2+ 2γ⟨ˆ xt−x⋆,ht−h⋆⟩
=/vextenddouble/vextenddoublewt−w⋆/vextenddouble/vextenddouble2−γ2/vextenddouble/vextenddoubleht−h⋆/vextenddouble/vextenddouble2+ 2γ⟨ˆ xt−x⋆,ˆht+1−h⋆⟩−2γ⟨ˆ xt−x⋆,ˆht+1−ht⟩
=/vextenddouble/vextenddoublewt−w⋆/vextenddouble/vextenddouble2−γ2/vextenddouble/vextenddoubleht−h⋆/vextenddouble/vextenddouble2+ 2γ⟨ˆ xt−x⋆,ˆht+1−h⋆⟩+ 2pχ⟨ˆ xt−x⋆,Wˆ xt⟩
=/vextenddouble/vextenddoublewt−w⋆/vextenddouble/vextenddouble2−γ2/vextenddouble/vextenddoubleht−h⋆/vextenddouble/vextenddouble2+ 2γ⟨ˆ xt−x⋆,ˆht+1−h⋆⟩+ 2pχ/vextenddouble/vextenddoubleWˆ xt/vextenddouble/vextenddouble2.
Hence,
E/bracketleftig/vextenddouble/vextenddoublext+1−x⋆/vextenddouble/vextenddouble2|Ft/bracketrightig
=p/vextenddouble/vextenddoubleˆ xt−x⋆/vextenddouble/vextenddouble2−p/vextenddouble/vextenddoubleWˆ xt/vextenddouble/vextenddouble2+pν/vextenddouble/vextenddoubleWˆ xt/vextenddouble/vextenddouble2+ (1−p)/vextenddouble/vextenddoubleˆ xt−x⋆/vextenddouble/vextenddouble2
=/vextenddouble/vextenddoubleˆ xt−x⋆/vextenddouble/vextenddouble2−p(1−ν)/vextenddouble/vextenddoubleWˆ xt/vextenddouble/vextenddouble2
=/vextenddouble/vextenddoublewt−w⋆/vextenddouble/vextenddouble2−γ2/vextenddouble/vextenddoubleht−h⋆/vextenddouble/vextenddouble2+ 2γ⟨ˆ xt−x⋆,ˆht+1−h⋆⟩
+/parenleftbig
2pχ−p(1−ν)/parenrightbig/vextenddouble/vextenddoubleWˆ xt/vextenddouble/vextenddouble2.
21Under review as submission to TMLR
On the other hand, using the 3 properties of dtstated above, we have
E/bracketleftig/vextenddouble/vextenddoubleht+1−h⋆/vextenddouble/vextenddouble2|Ft/bracketrightig
≤/vextenddouble/vextenddouble/vextenddouble/vextenddoubleht−h⋆−pχ
γ(1 +ω)Wˆ xt/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
+ωp2χ2
γ2(1 +ω)2/vextenddouble/vextenddoubleWˆ xt/vextenddouble/vextenddouble2
=/vextenddouble/vextenddouble/vextenddouble/vextenddoubleht−h⋆+1
1 +ω/parenleftbigˆht+1−ht/parenrightbig/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
+ω
(1 +ω)2/vextenddouble/vextenddouble/vextenddoubleˆht+1−ht/vextenddouble/vextenddouble/vextenddouble2
=/vextenddouble/vextenddouble/vextenddouble/vextenddoubleω
1 +ω/parenleftbig
ht−h⋆/parenrightbig
+1
1 +ω/parenleftbigˆht+1−h⋆/parenrightbig/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
+ω
(1 +ω)2/vextenddouble/vextenddouble/vextenddoubleˆht+1−ht/vextenddouble/vextenddouble/vextenddouble2
=ω2
(1 +ω)2/vextenddouble/vextenddoubleht−h⋆/vextenddouble/vextenddouble2+1
(1 +ω)2/vextenddouble/vextenddouble/vextenddoubleˆht+1−h⋆/vextenddouble/vextenddouble/vextenddouble2
+2ω
(1 +ω)2⟨ht−h⋆,ˆht+1−h⋆⟩+ω
(1 +ω)2/vextenddouble/vextenddouble/vextenddoubleˆht+1−h⋆/vextenddouble/vextenddouble/vextenddouble2
+ω
(1 +ω)2/vextenddouble/vextenddoubleht−h⋆/vextenddouble/vextenddouble2−2ω
(1 +ω)2⟨ht−h⋆,ˆht+1−h⋆⟩
=1
1 +ω/vextenddouble/vextenddouble/vextenddoubleˆht+1−h⋆/vextenddouble/vextenddouble/vextenddouble2
+ω
1 +ω/vextenddouble/vextenddoubleht−h⋆/vextenddouble/vextenddouble2.
Moreover,
/vextenddouble/vextenddouble/vextenddoubleˆht+1−h⋆/vextenddouble/vextenddouble/vextenddouble2
=/vextenddouble/vextenddouble/vextenddouble(ht−h⋆) + (ˆht+1−ht)/vextenddouble/vextenddouble/vextenddouble2
=/vextenddouble/vextenddoubleht−h⋆/vextenddouble/vextenddouble2+/vextenddouble/vextenddouble/vextenddoubleˆht+1−ht/vextenddouble/vextenddouble/vextenddouble2
+ 2⟨ht−h⋆,ˆht+1−ht⟩
=/vextenddouble/vextenddoubleht−h⋆/vextenddouble/vextenddouble2+ 2⟨ˆht+1−h⋆,ˆht+1−ht⟩−/vextenddouble/vextenddouble/vextenddoubleˆht+1−ht/vextenddouble/vextenddouble/vextenddouble2
=/vextenddouble/vextenddoubleht−h⋆/vextenddouble/vextenddouble2−/vextenddouble/vextenddouble/vextenddoubleˆht+1−ht/vextenddouble/vextenddouble/vextenddouble2
−2pχ
γ⟨ˆht+1−h⋆,W(ˆ xt−x⋆)⟩
=/vextenddouble/vextenddoubleht−h⋆/vextenddouble/vextenddouble2−p2χ2
γ2/vextenddouble/vextenddoubleWˆ xt/vextenddouble/vextenddouble2−2pχ
γ⟨W(ˆht+1−h⋆),ˆ xt−x⋆⟩
=/vextenddouble/vextenddoubleht−h⋆/vextenddouble/vextenddouble2−p2χ2
γ2/vextenddouble/vextenddoubleWˆ xt/vextenddouble/vextenddouble2−2pχ
γ⟨ˆht+1−h⋆,ˆ xt−x⋆⟩.
Hence,
1
γE/bracketleftig/vextenddouble/vextenddoublext+1−x⋆/vextenddouble/vextenddouble2|Ft/bracketrightig
+γ(1 +ω)
pχE/bracketleftig/vextenddouble/vextenddoubleht+1−h⋆/vextenddouble/vextenddouble2|Ft/bracketrightig
≤1
γ/vextenddouble/vextenddoublewt−w⋆/vextenddouble/vextenddouble2−γ/vextenddouble/vextenddoubleht−h⋆/vextenddouble/vextenddouble2+/parenleftbigg
2pχ
γ−p
γ(1−ν)/parenrightbigg/vextenddouble/vextenddoubleWˆ xt/vextenddouble/vextenddouble2
+ 2⟨ˆ xt−x⋆,ˆht+1−h⋆⟩+γ
pχ/vextenddouble/vextenddoubleht−h⋆/vextenddouble/vextenddouble2
−pχ
γ/vextenddouble/vextenddoubleWˆ xt/vextenddouble/vextenddouble2−2⟨ˆht+1−h⋆,ˆ xt−x⋆⟩+γω
pχ/vextenddouble/vextenddoubleht−h⋆/vextenddouble/vextenddouble2
=1
γ/vextenddouble/vextenddoublewt−w⋆/vextenddouble/vextenddouble2+/parenleftbiggγ(1 +ω)
pχ−γ/parenrightbigg/vextenddouble/vextenddoubleht−h⋆/vextenddouble/vextenddouble2
+/parenleftbiggpχ
γ−p(1−ν)
γ/parenrightbigg/vextenddouble/vextenddoubleWˆ xt/vextenddouble/vextenddouble2. (26)
Since we have supposed
0<χ≤1−ν=n(s−1)
s(n−1)∈/parenleftbigg1
2,1/bracketrightbigg
,
22Under review as submission to TMLR
we have
1
γE/bracketleftig/vextenddouble/vextenddoublext+1−x⋆/vextenddouble/vextenddouble2|Ft/bracketrightig
+γ(1 +ω)
pχE/bracketleftig/vextenddouble/vextenddoubleht+1−h⋆/vextenddouble/vextenddouble2|Ft/bracketrightig
≤1
γ/vextenddouble/vextenddoublewt−w⋆/vextenddouble/vextenddouble2+γ(1 +ω)
pχ/parenleftbigg
1−pχ
1 +ω/parenrightbigg/vextenddouble/vextenddoubleht−h⋆/vextenddouble/vextenddouble2.
Finally,
E/bracketleftig/vextenddouble/vextenddoublewt−w⋆/vextenddouble/vextenddouble2|Ft
0/bracketrightig
≤/vextenddouble/vextenddouble(Id−γ∇f)xt−(Id−γ∇f)x⋆/vextenddouble/vextenddouble2+γ2σ2,
and according to Condat & Richtárik (2023, Lemma 1),
/vextenddouble/vextenddouble(Id−γ∇f)xt−(Id−γ∇f)x⋆/vextenddouble/vextenddouble2≤max(1−γµ,γL−1)2/vextenddouble/vextenddoublext−x⋆/vextenddouble/vextenddouble2.
Therefore,
E/bracketleftbig
Ψt+1|Ft
0/bracketrightbig
≤max/parenleftbigg
(1−γµ)2,(γL−1)2,1−pχ
1 +ω/parenrightbigg
Ψt+γσ2
= max/parenleftbigg
(1−γµ)2,(γL−1)2,1−p2χs−1
n−1/parenrightbigg
Ψt+γσ2. (27)
Using the tower rule, we can unroll the recursion in (27) to obtain the unconditional expectation of Ψt+1.
Ifσ= 0, using classical results on supermartingale convergence (Bertsekas, 2015, Proposition A.4.5), it
follows from (27) that Ψt→0almost surely. Almost sure convergence of xtandhtfollows. Finally, by
Lipschitz continuity of ∇f, we can upper bound ∥ˆ xt−x⋆∥2by a linear combination of ∥xt−x⋆∥2and
∥ht−h⋆∥2. It follows that E/bracketleftig
∥ˆ xt−x⋆∥2/bracketrightig
→0linearly with the same rate τand that ˆ xt→x⋆almost surely,
as well.
A.1 The random variable dt
We study the random variable dtused in Algorithm 3. If θt= 0,dt= 0. If, on the other hand, θt= 1, for
every coordinate k∈[d], a subset/tildewideΩt
k⊂[n]of sizesis chosen uniformly at random. These sets (/tildewideΩt
k)d
k=1are
mutually dependent, but this does not matter for the derivations, since we can reason on the coordinates
separately. Then, for every k∈[d]andi∈[n],
dt
i,k:=/braceleftigg
a/parenleftig
ˆxt
i,k−1
s/summationtext
j∈/tildewideΩt
kˆxt
j,k/parenrightig
ifi∈/tildewideΩt
k,
0otherwise,(28)
for some value a>0to determine. We can check that/summationtextn
i=1dt
i= 0. We can also note that dtdepends only on
Wˆ xtand not on ˆ xt; in particular, if ˆxt
1=···= ˆxt
n,dt
i= 0. We have to set aso that E[dt
i] = ˆxt
i−1
n/summationtextn
j=1ˆxt
j,
where the expectation is with respect to θtand the/tildewideΩt
k(all expectations in this section are conditional to
ˆ xt). So, let us calculate this expectation.
Letk∈[d]. For every i∈[n],
E/bracketleftbig
dt
i,k/bracketrightbig
=ps
n
aˆxt
i,k−a
sEΩ:i∈Ω
/summationdisplay
j∈Ωˆxt
j,k

,
where EΩ:i∈Ωdenotes the expectation with respect to a subset Ω⊂[n]of sizescontaining iand chosen
uniformly at random. We have
EΩ:i∈Ω
/summationdisplay
j∈Ωˆxt
j,k
= ˆxt
i,k+s−1
n−1/summationdisplay
j∈[n]\{i}ˆxt
j,k=n−s
n−1ˆxt
i,k+s−1
n−1n/summationdisplay
j=1ˆxt
j,k.
23Under review as submission to TMLR
Hence, for every i∈[n],
E/bracketleftbig
dt
i,k/bracketrightbig
=ps
n/parenleftbigg
a−a
sn−s
n−1/parenrightbigg
ˆxi,k−ps
na
ss−1
n−1n/summationdisplay
j=1ˆxj,k.
Therefore, by setting
a:=n−1
p(s−1), (29)
we have, for every i∈[n],
E/bracketleftbig
dt
i,k/bracketrightbig
=ps
n/parenleftbigg1
pn−1
s−1−1
pn−s
s(s−1)/parenrightbigg
ˆxi,k−1
nn/summationdisplay
j=1ˆxj,k
= ˆxi,k−1
nn/summationdisplay
j=1ˆxj,k,
as desired.
Now, we want to find the value of ωsuch that
E/bracketleftig/vextenddouble/vextenddoubledt−Wˆ xt/vextenddouble/vextenddouble2/bracketrightig
≤ω/vextenddouble/vextenddoubleWˆ xt/vextenddouble/vextenddouble2(30)
or, equivalently,
E/bracketleftiggn/summationdisplay
i=1/vextenddouble/vextenddoubledt
i/vextenddouble/vextenddouble2/bracketrightigg
≤(1 +ω)n/summationdisplay
i=1/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddoubleˆxt
i−1
nn/summationdisplay
j=1ˆxt
j/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
.
We can reason on the coordinates separately, or all at once to ease the notations. We have
E/bracketleftiggn/summationdisplay
i=1/vextenddouble/vextenddoubledt
i/vextenddouble/vextenddouble2/bracketrightigg
=ps
nn/summationdisplay
i=1EΩ:i∈Ω/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddoubleaˆxt
i−a
s/summationdisplay
j∈Ωˆxt
j/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
.
For everyi∈[n],
EΩ:i∈Ω/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddoubleaˆxt
i−a
s/summationdisplay
j∈Ωˆxt
j/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
=EΩ:i∈Ω/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble/parenleftig
a−a
s/parenrightig
ˆxt
i−a
s/summationdisplay
j∈Ω\{i}ˆxt
j/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
=/vextenddouble/vextenddouble/vextenddouble/parenleftig
a−a
s/parenrightig
ˆxt
i/vextenddouble/vextenddouble/vextenddouble2
+EΩ:i∈Ω/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddoublea
s/summationdisplay
j∈Ω\{i}ˆxt
j/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
−2/angbracketleftigg/parenleftig
a−a
s/parenrightig
ˆxt
i,a
sEΩ:i∈Ω/summationdisplay
j∈Ω\{i}ˆxt
j/angbracketrightigg
.
We have
EΩ:i∈Ω/summationdisplay
j∈Ω\{i}ˆxt
j=s−1
n−1/summationdisplay
j∈[n]\{i}ˆxt
j=s−1
n−1
n/summationdisplay
j=1ˆxt
j−ˆxt
i

24Under review as submission to TMLR
and
EΩ:i∈Ω/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble/summationdisplay
j∈Ω\{i}ˆxt
j/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
=EΩ:i∈Ω/summationdisplay
j∈Ω\{i}/vextenddouble/vextenddoubleˆxt
j/vextenddouble/vextenddouble2+EΩ:i∈Ω/summationdisplay
j∈Ω\{i}/summationdisplay
j′∈Ω\{i,j}/angbracketleftbig
ˆxt
j,ˆxt
j′/angbracketrightbig
=s−1
n−1/summationdisplay
j∈[n]\{i}/vextenddouble/vextenddoubleˆxt
j/vextenddouble/vextenddouble2+s−1
n−1s−2
n−2/summationdisplay
j∈[n]\{i}/summationdisplay
j′∈[n]\{i,j}/angbracketleftbig
ˆxt
j,ˆxt
j′/angbracketrightbig
=s−1
n−1/parenleftbigg
1−s−2
n−2/parenrightbigg/summationdisplay
j∈[n]\{i}/vextenddouble/vextenddoubleˆxt
j/vextenddouble/vextenddouble2+s−1
n−1s−2
n−2/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble/summationdisplay
j∈[n]\{i}ˆxt
j/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
=s−1
n−1n−s
n−2
n/summationdisplay
j=1/vextenddouble/vextenddoubleˆxt
j/vextenddouble/vextenddouble2−/vextenddouble/vextenddoubleˆxt
i/vextenddouble/vextenddouble2
+s−1
n−1s−2
n−2/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddoublen/summationdisplay
j=1ˆxt
j−ˆxt
i/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
.
Hence,
E/bracketleftiggn/summationdisplay
i=1/vextenddouble/vextenddoubledt
i/vextenddouble/vextenddouble2/bracketrightigg
=ps
nn/summationdisplay
i=1/vextenddouble/vextenddouble/vextenddouble/parenleftig
a−a
s/parenrightig
ˆxt
i/vextenddouble/vextenddouble/vextenddouble2
+psa2
(s)2s−1
n−1n−s
n−2n/summationdisplay
j=1/vextenddouble/vextenddoubleˆxt
j/vextenddouble/vextenddouble2
−ps
na2
(s)2s−1
n−1n−s
n−2n/summationdisplay
i=1/vextenddouble/vextenddoubleˆxt
i/vextenddouble/vextenddouble2+ps
na2
(s)2s−1
n−1s−2
n−2n/summationdisplay
i=1/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddoublen/summationdisplay
j=1ˆxt
j−ˆxt
i/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
−2ps
na
ss−1
n−1/parenleftig
a−a
s/parenrightign/summationdisplay
i=1/angbracketleftigg
ˆxt
i,n/summationdisplay
j=1ˆxt
j−ˆxt
i/angbracketrightigg
=(n−1)2
psnn/summationdisplay
i=1/vextenddouble/vextenddoubleˆxt
i/vextenddouble/vextenddouble2+(n−1)2
ps(s−1)nn−s
n−2n/summationdisplay
i=1/vextenddouble/vextenddoubleˆxt
i/vextenddouble/vextenddouble2
+1
pss−2
s−1n−1
n−2/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddoublen/summationdisplay
i=1ˆxt
i/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
−21
psns−2
s−1n−1
n−2/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddoublen/summationdisplay
i=1ˆxt
i/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
+1
psns−2
s−1n−1
n−2n/summationdisplay
i=1/vextenddouble/vextenddoubleˆxt
i/vextenddouble/vextenddouble2+ 2n−1
psnn/summationdisplay
i=1/vextenddouble/vextenddoubleˆxt
i/vextenddouble/vextenddouble2−2n−1
psn/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddoublen/summationdisplay
i=1ˆxt
i/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
=(n−1)(n+ 1)
psnn/summationdisplay
i=1/vextenddouble/vextenddoubleˆxt
i/vextenddouble/vextenddouble2+(n−1)2
ps(s−1)nn−s
n−2n/summationdisplay
i=1/vextenddouble/vextenddoubleˆxt
i/vextenddouble/vextenddouble2
−n−1
psns
s−1/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddoublen/summationdisplay
i=1ˆxt
i/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
+1
psns−2
s−1n−1
n−2n/summationdisplay
i=1/vextenddouble/vextenddoubleˆxt
i/vextenddouble/vextenddouble2
=(n2−1)(s−1)(n−2) + (n−1)2(n−s) + (s−2)(n−1)
ps(s−1)n(n−2)n/summationdisplay
i=1/vextenddouble/vextenddoubleˆxt
i/vextenddouble/vextenddouble2
−n−1
p(s−1)n/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddoublen/summationdisplay
i=1ˆxt
i/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
=n−1
p(s−1)n/summationdisplay
i=1/vextenddouble/vextenddoubleˆxt
i/vextenddouble/vextenddouble2−n−1
p(s−1)n/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddoublen/summationdisplay
i=1ˆxt
i/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
=n−1
p(s−1)n/summationdisplay
i=1/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddoubleˆxt
i−1
nn/summationdisplay
j=1ˆxt
j/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
.
25Under review as submission to TMLR
Therefore, (30) holds with
ω=n−1
p(s−1)−1 (31)
and we have a= 1 +ω.
A.2 From Algorithm 2 to TAMUNA
TAMUNA is a two-loop version of Algorithm 2, where every sequence of local steps followed by a commu-
nication step is grouped into a round. One crucial observation about Algorithm 2 is the following: for a
clienti /∈Ωt, which does not participate in communication at iteration twithθt= 1, its variable xigets
overwritten by ¯xtanyway (step 12 of Algorithm 2). Therefore, all local steps it performed since its last
participation are useless and can be omitted. But at iteration twithθt= 0, it is still undecided whether or
not a given client will participate in the next communication step at iteration t′> t, since Ωt′has not yet
been generated. That is why TAMUNA is written with two loops, so that it is decided at the beginning of
the round which clients will communicate at the end of the round. Accordingly, at the beginning of round
r, a client downloads the current model estimate (step 6 of TAMUNA ) only if it participates ( i∈Ω(r)), to
initialize its sequence of local steps. Otherwise ( i /∈Ω(r)), the client is completely idle: neither computation
nor downlink or uplink communication is performed in round r. Finally, a round consists of a sequence of
successive iterations with θt= 0and a last iteration with θt= 1followed by communication. Thus, the
number of iterations, or local steps, in a round can be determined directly at the beginning of the round,
according to a geometric law. Given these considerations, Algorithm 2 and TAMUNA are equivalent. In
TAMUNA , the round and local step indexing is denoted by parentheses, e.g. (r,ℓ), to differentiate it clearly
from the iteration indexing.
ToobtainTheorem1fromTheorem3, wefirsthavetoreindexthelocalstepstomaketheequivalentiteration
indextin Algorithm 2 appear, since the rate is with respect to the number of iterations, not rounds, whose
size is random. The almost sure convergence statement follows directly from the one in Theorem 3.
Importantly, we want a result related to the variables which are actually computed in TAMUNA , without
including virtual variables by the idle clients, which are computed in Algorithm 2 but not in TAMUNA . That
is why we express the convergence result with respect to ¯xt, which relates only to the variables of active
clients; also, ¯xtis the model estimate known by the server whenever communication occurs, which matters
at the end. Note the bar in Ψin (6) to differentiate it from Ψin (22). Thus, we continue the analysis of
Algorithms 2 and 3 in Section A, with same definitions and notations. Let t≥0. Ifθt= 0, we choose
Ωt⊂[n]of sizecuniformly at random and a random binary mask qt= (qt
i)i∈Ωt∈Rd×c, and we define
¯xt:=1
s/summationtext
j∈ΩtCt
j(ˆxt
j)(in Theorem 1, for simplicity, Ωtandqtare the ones that will be used at the end of the
round; this choice is valid as it does not depend on the past). Ωt,qtand¯xtare already defined if θt= 1. We
want to study E/bracketleftig
∥¯xt−x⋆∥2|Ft/bracketrightig
, where the expectation is with respect to Ωtandqt, whatever θt. Using
the derivations already obtained,
nE/bracketleftig/vextenddouble/vextenddouble¯xt−x⋆/vextenddouble/vextenddouble2|Ft/bracketrightig
=/vextenddouble/vextenddoubleˆ xt−x⋆/vextenddouble/vextenddouble2−/vextenddouble/vextenddoubleWˆ xt/vextenddouble/vextenddouble2+ν/vextenddouble/vextenddoubleWˆ xt/vextenddouble/vextenddouble2
=/vextenddouble/vextenddoublewt−w⋆/vextenddouble/vextenddouble2−γ2/vextenddouble/vextenddoubleht−h⋆/vextenddouble/vextenddouble2+ 2γ⟨ˆ xt−x⋆,ˆht+1−h⋆⟩
+ (2pχ+ν−1)/vextenddouble/vextenddoubleWˆ xt/vextenddouble/vextenddouble2
≤/vextenddouble/vextenddoublewt−w⋆/vextenddouble/vextenddouble2−γ2/vextenddouble/vextenddoubleht−h⋆/vextenddouble/vextenddouble2+ 2γ⟨ˆ xt−x⋆,ˆht+1−h⋆⟩
+/parenleftbig
2pχ−p(1−ν)/parenrightbig/vextenddouble/vextenddoubleWˆ xt/vextenddouble/vextenddouble2.
Hence,
n
γE/bracketleftig/vextenddouble/vextenddouble¯xt−x⋆/vextenddouble/vextenddouble2|Ft/bracketrightig
+γ(1 +ω)
pχE/bracketleftig/vextenddouble/vextenddoubleht+1−h⋆/vextenddouble/vextenddouble2|Ft/bracketrightig
≤1
γ/vextenddouble/vextenddoublewt−w⋆/vextenddouble/vextenddouble2+γ(1 +ω)
pχ/parenleftbigg
1−pχ
1 +ω/parenrightbigg/vextenddouble/vextenddoubleht−h⋆/vextenddouble/vextenddouble2
26Under review as submission to TMLR
and
n
γE/bracketleftig/vextenddouble/vextenddouble¯xt−x⋆/vextenddouble/vextenddouble2|Ft
0/bracketrightig
+γ(1 +ω)
pχE/bracketleftig/vextenddouble/vextenddoubleht+1−h⋆/vextenddouble/vextenddouble2|Ft
0/bracketrightig
≤max/parenleftbigg
(1−γµ)2,(γL−1)2,1−p2χs−1
n−1/parenrightbigg
Ψt+γσ2.
Using the tower rule,
n
γE/bracketleftig/vextenddouble/vextenddouble¯xt−x⋆/vextenddouble/vextenddouble2/bracketrightig
+γ(1 +ω)
pχE/bracketleftig/vextenddouble/vextenddoubleht+1−h⋆/vextenddouble/vextenddouble2/bracketrightig
≤τtΨ0+γσ2
1−τ.
Since in TAMUNA ,x0
1=···=x0
n= ¯x0= ¯x(0),Ψ0= Ψ0. This concludes the proof of Theorem 1.
B Proof of Theorem 2
We suppose that the assumptions in Theorem 2 hold. sis set as the maximum of three values. Let us
consider these three cases.
1) Suppose that s= 2. Since 2 =s≥⌊αc⌋and2 =s≥⌊c
d⌋, we haveα≤3
cand1≤3d
c. Hence,
O/parenleftbigg/radicalbiggnκ
s+n
s/parenrightbigg/parenleftbiggsd
c+ 1 +αd/parenrightbigg
=O/parenleftbig√nκ+n/parenrightbig/parenleftbiggd
c+d
c+d
c/parenrightbigg
=O/parenleftbigg
d√nκ
c+dn
c/parenrightbigg
. (32)
2) Suppose that s=⌊c
d⌋. Thensd
c≤1. Sinces≥⌊αc⌋and⌊c
d⌋=s≥2, we haveαc≤s+ 1≤c
d+ 1and
d
c≤1
2, so thatαd≤1 +d
c≤2. Hence,
O/parenleftbigg/radicalbiggnκ
s+n
s/parenrightbigg/parenleftbiggsd
c+ 1 +αd/parenrightbigg
=O/parenleftbigg/radicalbiggnκ
s+n
s/parenrightbigg
.
Since 2s≥c
d, we have1
s≤2d
cand
O/parenleftbigg/radicalbiggnκ
s+n
s/parenrightbigg/parenleftbiggsd
c+ 1 +αd/parenrightbigg
=O/parenleftbigg√
d/radicalbiggnκ
c+dn
c/parenrightbigg
. (33)
3) Suppose that s=⌊αc⌋. This implies α > 0. Thens≤αc. Also, 2s≥αcand1
s≤2
αc. Since
s=⌊αc⌋≥⌊c
d⌋, we haveαc+ 1≥c
dand1≤αd+d
c. Sinces=⌊αc⌋≥2, we have1
c≤α
2and1≤2αd.
Hence,
O/parenleftbigg/radicalbiggnκ
s+n
s/parenrightbigg/parenleftbiggsd
c+ 1 +αd/parenrightbigg
=O/parenleftbigg/radicalbiggnκ
αc+n
αc/parenrightbigg
(αd+αd+αd)
=O/parenleftbigg√αd/radicalbiggnκ
c+dn
c/parenrightbigg
. (34)
By adding up the three upper bounds (32), (33), (34), we obtain the upper bound in (15).
27Under review as submission to TMLR
C Sublinear convergence in the convex case
In this section only, we remove the hypothesis of strong convexity: the functions fiare only assumed to be
convex and L-smooth, and we suppose that a solution x⋆∈Rdto (1) exists. Also, for simplicity, we only
consider the case of exact gradients ( σ= 0). Then we have sublinear ergodic convergence:
Theorem 4 (sublinear convergence) .In Algorithm 2 suppose that σ= 0and that
0<γ <2
Land 0<χ<n(s−1)
s(n−1)∈/parenleftbigg1
2,1/bracketrightbigg
. (35)
For everyi= 1,...,nandT≥0, let
˜xT
i:=1
T+ 1T/summationdisplay
t=0xt
i. (36)
Then
E/bracketleftig/vextenddouble/vextenddouble∇f(˜xT
i)/vextenddouble/vextenddouble2/bracketrightig
=O/parenleftbigg1
T/parenrightbigg
. (37)
Proof.A solution x⋆∈Rdto (1), which is supposed to exist, satisfies ∇f(x⋆) =1
n/summationtextn
i=1∇fi(x⋆) = 0.x⋆is
not necessarily unique but h⋆
i:=∇fi(x⋆)is unique.
We define the Bregman divergence of a L-smooth convex function gat pointsx,x′∈RdasDg(x,x′):=
g(x)−g(x′)−⟨∇g(x′),x−x′⟩≥0. We have Dg(x,x′)≥1
2L∥∇g(x)−∇g(x′)∥2. We note that for every
x∈Rdandi= 1,...,n,Dfi(x,x⋆)is the same whatever the solution x⋆.
For everyt≥0, we define the Lyapunov function
Ψt:=1
γn/summationdisplay
i=1/vextenddouble/vextenddoublext
i−x⋆/vextenddouble/vextenddouble2+γ
p2χn−1
s−1n/summationdisplay
i=1/vextenddouble/vextenddoubleht
i−h⋆
i/vextenddouble/vextenddouble2, (38)
Starting from (26), we have, for every t≥0,
E/bracketleftbig
Ψt+1|Ft/bracketrightbig
=1
γn/summationdisplay
i=1E/bracketleftig/vextenddouble/vextenddoublext+1
i−x⋆/vextenddouble/vextenddouble2|Ft/bracketrightig
+γ
p2χn−1
s−1n/summationdisplay
i=1E/bracketleftig/vextenddouble/vextenddoubleht+1
i−h⋆
i/vextenddouble/vextenddouble2|Ft/bracketrightig
≤1
γn/summationdisplay
i=1/vextenddouble/vextenddouble/parenleftbig
xt
i−γ∇fi(xt
i)/parenrightbig
−/parenleftbig
x⋆−γ∇fi(x⋆)/parenrightbig/vextenddouble/vextenddouble2
+/parenleftbiggγ
p2χn−1
s−1−γ/parenrightbiggn/summationdisplay
i=1/vextenddouble/vextenddoubleht
i−h⋆
i/vextenddouble/vextenddouble2+p
γ(χ−1 +ν)n/summationdisplay
i=1/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddoubleˆxt
i−1
nn/summationdisplay
j=1ˆxt
j/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
,
with
/vextenddouble/vextenddouble/parenleftbig
xt
i−γ∇fi(xt
i)/parenrightbig
−/parenleftbig
x⋆−γ∇fi(x⋆)/parenrightbig/vextenddouble/vextenddouble2=/vextenddouble/vextenddoublext
i−x⋆/vextenddouble/vextenddouble2−2γ⟨∇fi(xt
i)−∇fi(x⋆),xt
i−x⋆⟩
+γ2/vextenddouble/vextenddouble∇fi(xt
i)−∇fi(x⋆)/vextenddouble/vextenddouble2
≤/vextenddouble/vextenddoublext
i−x⋆/vextenddouble/vextenddouble2−(2γ−γ2L)⟨∇fi(xt
i)−∇fi(x⋆),xt
i−x⋆⟩,
where the second inequality follows from cocoercivity of the gradient. Moreover, for every x,x′,Dfi(x,x′)≤
⟨∇fi(x)−∇fi(x′),x−x′⟩. Therefore,
E/bracketleftbig
Ψt+1|Ft/bracketrightbig
≤Ψt−(2−γL)n/summationdisplay
i=1Dfi(xt
i,x⋆)
−γn/summationdisplay
i=1/vextenddouble/vextenddoubleht
i−h⋆
i/vextenddouble/vextenddouble2+p
γ(χ−1 +ν)n/summationdisplay
i=1/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddoubleˆxt
i−1
nn/summationdisplay
j=1ˆxt
j/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
.
28Under review as submission to TMLR
Telescoping the sum and using the tower rule of expectations, we get summability over tof the three negative
terms above: for every T≥0, we have
(2−γL)n/summationdisplay
i=1T/summationdisplay
t=0E/bracketleftbig
Dfi(xt
i,x⋆)/bracketrightbig
≤Ψ0−E/bracketleftbig
ΨT+1/bracketrightbig
≤Ψ0, (39)
γn/summationdisplay
i=1T/summationdisplay
t=0E/bracketleftig/vextenddouble/vextenddoubleht
i−h⋆
i/vextenddouble/vextenddouble2/bracketrightig
≤Ψ0−E/bracketleftbig
ΨT+1/bracketrightbig
≤Ψ0, (40)
p
γ(1−ν−χ)n/summationdisplay
i=1T/summationdisplay
t=0E
/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddoubleˆxt
i−1
nn/summationdisplay
j=1ˆxt
j/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
≤Ψ0−E/bracketleftbig
ΨT+1/bracketrightbig
≤Ψ0. (41)
Taking ergodic averages and using convexity of the squared norm and of the Bregman divergence, we can
now getO(1/T)rates. We use a tilde to denote averages over the iterations so far. That is, for every
i= 1,...,nandT≥0, we define
˜xT
i:=1
T+ 1T/summationdisplay
t=0xt
i
and
˜xT:=1
nn/summationdisplay
i=1˜xT
i.
The Bregman divergence is convex in its first argument, so that, for every T≥0,
n/summationdisplay
i=1Dfi(˜xT
i,x⋆)≤n/summationdisplay
i=11
T+ 1T/summationdisplay
t=0Dfi(xt
i,x⋆).
Combining this inequality with (39) yields, for every T≥0,
(2−γL)n/summationdisplay
i=1E/bracketleftbig
Dfi(˜xT
i,x⋆)/bracketrightbig
≤Ψ0
T+ 1. (42)
Similarly, for every i= 1,...,nandT≥0, we define
˜hT
i:=1
T+ 1T/summationdisplay
t=0ht
i
and we have, for every T≥0,
n/summationdisplay
i=1/vextenddouble/vextenddouble˜hT
i−h⋆
i/vextenddouble/vextenddouble2≤n/summationdisplay
i=11
T+ 1T/summationdisplay
t=0/vextenddouble/vextenddoubleht
i−h⋆
i/vextenddouble/vextenddouble2.
Combining this inequality with (40) yields, for every T≥0,
γn/summationdisplay
i=1E/bracketleftig/vextenddouble/vextenddouble˜hT
i−h⋆
i/vextenddouble/vextenddouble2/bracketrightig
≤Ψ0
T+ 1. (43)
Finally, for every i= 1,...,nandT≥0, we define
˜ˆxT
i:=1
T+ 1T/summationdisplay
t=0ˆxt
i
29Under review as submission to TMLR
and
˜ˆxT:=1
nn/summationdisplay
i=1˜ˆxT
i,
and we have, for every T≥0,
n/summationdisplay
i=1/vextenddouble/vextenddouble˜ˆxT
i−˜ˆxT/vextenddouble/vextenddouble2≤n/summationdisplay
i=11
T+ 1T/summationdisplay
t=0/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddoubleˆxt
i−1
nn/summationdisplay
j=1ˆxt
j/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
.
Combining this inequality with (41) yields, for every T≥0,
p
γ(1−ν−χ)n/summationdisplay
i=1E/bracketleftig/vextenddouble/vextenddouble˜ˆxT
i−˜ˆxT/vextenddouble/vextenddouble2/bracketrightig
≤Ψ0
T+ 1. (44)
Next, we have, for every i= 1,...,nandT≥0,
/vextenddouble/vextenddouble∇f(˜xT
i)/vextenddouble/vextenddouble2≤2/vextenddouble/vextenddouble∇f(˜xT
i)−∇f(˜xT)/vextenddouble/vextenddouble2+ 2/vextenddouble/vextenddouble∇f(˜xT)/vextenddouble/vextenddouble2
≤2L2/vextenddouble/vextenddouble˜xT
i−˜xT/vextenddouble/vextenddouble2+ 2/vextenddouble/vextenddouble∇f(˜xT)/vextenddouble/vextenddouble2. (45)
Moreover, for every T≥0and solution x⋆to (1),
/vextenddouble/vextenddouble∇f(˜xT)/vextenddouble/vextenddouble2=/vextenddouble/vextenddouble∇f(˜xT)−∇f(x⋆)/vextenddouble/vextenddouble2
≤1
nn/summationdisplay
i=1/vextenddouble/vextenddouble∇fi(˜xT)−∇fi(x⋆)/vextenddouble/vextenddouble2
≤2
nn/summationdisplay
i=1/vextenddouble/vextenddouble∇fi(˜xT)−∇fi(˜xT
i)/vextenddouble/vextenddouble2+2
nn/summationdisplay
i=1/vextenddouble/vextenddouble∇fi(˜xT
i)−∇fi(x⋆)/vextenddouble/vextenddouble2
≤2L2
nn/summationdisplay
i=1/vextenddouble/vextenddouble˜xT
i−˜xT/vextenddouble/vextenddouble2+4L
nn/summationdisplay
i=1Dfi(˜xT
i,x⋆). (46)
There remains to control the terms/vextenddouble/vextenddouble˜xT
i−˜xT/vextenddouble/vextenddouble2: we have, for every T≥0,
n/summationdisplay
i=1/vextenddouble/vextenddouble˜xT
i−˜xT/vextenddouble/vextenddouble2≤2n/summationdisplay
i=1/vextenddouble/vextenddouble(˜xT
i−˜xT)−(˜ˆxT
i−˜ˆxT)/vextenddouble/vextenddouble2+ 2n/summationdisplay
i=1/vextenddouble/vextenddouble˜ˆxT
i−˜ˆxT/vextenddouble/vextenddouble2
≤2n/summationdisplay
i=1/vextenddouble/vextenddouble˜xT
i−˜ˆxT
i/vextenddouble/vextenddouble2+ 2n/summationdisplay
i=1/vextenddouble/vextenddouble˜ˆxT
i−˜ˆxT/vextenddouble/vextenddouble2. (47)
For everyi= 1,...,nandt≥0,
ˆxt
i=xt
i−γ/parenleftbig
∇fi(xt
i)−ht
i/parenrightbig
so that, for every i= 1,...,nandT≥0,
˜xT
i−˜ˆxT
i=γ1
T+ 1T/summationdisplay
t=0∇fi(xt
i)−γ˜hT
i
and
/vextenddouble/vextenddouble˜xT
i−˜ˆxT
i/vextenddouble/vextenddouble2=γ2/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
T+ 1T/summationdisplay
t=0∇fi(xt
i)−˜hT
i/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
≤2γ21
T+ 1T/summationdisplay
t=0/vextenddouble/vextenddouble∇fi(xt
i)−∇fi(x⋆)/vextenddouble/vextenddouble2+ 2γ2/vextenddouble/vextenddouble˜hT
i−h⋆
i/vextenddouble/vextenddouble2
≤4Lγ21
T+ 1T/summationdisplay
t=0Dfi(xt
i,x⋆) + 2γ2/vextenddouble/vextenddouble˜hT
i−h⋆
i/vextenddouble/vextenddouble2. (48)
30Under review as submission to TMLR
Combining (45), (46), (47), (48), we get, for every T≥0,
n/summationdisplay
i=1/vextenddouble/vextenddouble∇f(˜xT
i)/vextenddouble/vextenddouble2≤2L2n/summationdisplay
i=1/vextenddouble/vextenddouble˜xT
i−˜xT/vextenddouble/vextenddouble2+ 2n/vextenddouble/vextenddouble∇f(˜xT)/vextenddouble/vextenddouble2
≤2L2n/summationdisplay
i=1/vextenddouble/vextenddouble˜xT
i−˜xT/vextenddouble/vextenddouble2+ 2L2n/summationdisplay
i=1/vextenddouble/vextenddouble˜xT
i−˜xT/vextenddouble/vextenddouble2+ 4Ln/summationdisplay
i=1Dfi(˜xT
i,x⋆)
= 4L2n/summationdisplay
i=1/vextenddouble/vextenddouble˜xT
i−˜xT/vextenddouble/vextenddouble2+ 4Ln/summationdisplay
i=1Dfi(˜xT
i,x⋆)
≤8L2n/summationdisplay
i=1/vextenddouble/vextenddouble˜xT
i−˜ˆxT
i/vextenddouble/vextenddouble2+ 8L2n/summationdisplay
i=1/vextenddouble/vextenddouble˜ˆxT
i−˜ˆxT/vextenddouble/vextenddouble2+ 4Ln/summationdisplay
i=1Dfi(˜xT
i,x⋆)
≤32L3γ21
T+ 1n/summationdisplay
i=1T/summationdisplay
t=0Dfi(xt
i,x⋆) + 16L2γ2n/summationdisplay
i=1/vextenddouble/vextenddouble˜hT
i−h⋆
i/vextenddouble/vextenddouble2
+ 8L2n/summationdisplay
i=1/vextenddouble/vextenddouble˜ˆxT
i−˜ˆxT/vextenddouble/vextenddouble2+ 4Ln/summationdisplay
i=1Dfi(˜xT
i,x⋆).
Taking the expectation and using (39), (43), (44) and (42), we get, for every T≥0,
n/summationdisplay
i=1E/bracketleftig/vextenddouble/vextenddouble∇f(˜xT
i)/vextenddouble/vextenddouble2/bracketrightig
≤32L3γ21
T+ 1n/summationdisplay
i=1T/summationdisplay
t=0E/bracketleftbig
Dfi(xt
i,x⋆)/bracketrightbig
+ 16L2γ2n/summationdisplay
i=1E/bracketleftig/vextenddouble/vextenddouble˜hT
i−h⋆
i/vextenddouble/vextenddouble2/bracketrightig
+ 8L2n/summationdisplay
i=1E/bracketleftig/vextenddouble/vextenddouble˜ˆxT
i−˜ˆxT/vextenddouble/vextenddouble2/bracketrightig
+ 4Ln/summationdisplay
i=1E/bracketleftbig
Dfi(˜xT
i,x⋆)/bracketrightbig
.
≤32L3γ2
2−γLΨ0
T+ 1+ 16L2γΨ0
T+ 1+8L2γ
p(1−ν−χ)Ψ0
T+ 1+4L
2−γLΨ0
T+ 1
=/bracketleftbigg32L3γ2+ 4L
2−γL+ 16L2γ+8L2γ
p(1−ν−χ)/bracketrightbiggΨ0
T+ 1.
Hence, with γ= Θ/parenleftbigp
L/radicalbigc
n/parenrightbig
,χsatisfyingδ≤χ≤1−ν−δfor someδ >0, andh0
i=∇fi(x0), for every
i∈[n], then for every ϵ>0, we have
n/summationdisplay
i=1E/bracketleftig/vextenddouble/vextenddouble∇f(˜xT
i)/vextenddouble/vextenddouble2/bracketrightig
≤ϵ (49)
after
O/parenleftigg
L2
p/radicalbiggn
c/vextenddouble/vextenddoublex0−x⋆/vextenddouble/vextenddouble2
ϵ/parenrightigg
(50)
iterations and
O/parenleftigg
L2/radicalbiggn
c/vextenddouble/vextenddoublex0−x⋆/vextenddouble/vextenddouble2
ϵ/parenrightigg
(51)
communication rounds.
We note that LT does not yield any acceleration: the communication complexity is the same whatever p.
CC is effective, however, since we communicate much less than dfloats during every communication round.
This convergence result applies to Algorithm 2. ˜xT
iin (36) is an average of all xt
i, including the ones for
clients not participating in the next communication round. The result still applies to TAMUNA , with, for
31Under review as submission to TMLR
everyi∈[n],˜xT
idefined as the average of the x(r,ℓ)
iwhich are actually computed, since this is a random
subsequence of all xt
i.
32