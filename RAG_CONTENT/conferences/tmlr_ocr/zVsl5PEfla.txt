Under review as submission to TMLR
Sampling from the latent space in Autoencoders:
A simple way towards generative models?
Anonymous authors
Paper under double-blind review
Abstract
By sampling from the latent space of an autoencoder and decoding the latent space samples
to the original data space, any autoencoder can simply be turned into a generative model.
For this to work, it is necessary to model the autoencoder’s latent space with a distribution
from which samples can be obtained. Several simple possibilities (kernel density estimates,
Gaussian distribution) and more sophisticated ones (Gaussian mixture models, copula models,
normalization ﬂows) can be thought of and have been tried recently. This study aims to
discuss, assess, and compare various techniques that can be used to capture the latent space
so that an autoencoder can become a generative model while striving for simplicity. Among
them, a new copula-based method, the Empirical Beta Copula Autoencoder , is considered.
Furthermore, we provide insights into further aspects of these methods, such as targeted
sampling or synthesizing new data with speciﬁc features.
1 Introduction
Generating realistic sample points of various data formats has been of growing interest in recent years.
Thus, new algorithms such as Autoencoders (AEs) andGenerative Adversarial Networks (GANs) Goodfellow
et al. (2014) have emerged. GANs use a discriminant model, penalizing the creation of unrealistic data
from a generator and learning from this feedback. On the other hand, AEs try to ﬁnd a low-dimensional
representation of the high-dimensional input data and reconstruct from it the original data. To turn an AE
into a generative model, the low-dimensional distribution is modeled, samples are drawn, and thereupon new
data points in the original space are constructed with the decoder. We call this low dimensional representation
of the data in the autoencoder the latent space in the following. Based on that, Variational Autoencoders
(VAEs)have evolved, optimizing for a Gaussian distribution in the latent space Kingma & Welling (2014).
Adversarial autoencoders (AAEs) utilize elements of both types of generative models, where a discriminant
model penalizes the distance of the encoded data from a prior (Gaussian) distribution (Makhzani et al., 2016).
However, such strong (and simplifying) distributional assumptions as in the VAE or AAE can have a negative
impact on performance, leading to a rich literature coping with the challenge of reducing the gap between
approximate and true posterior distributions (e.g., Rezende & Mohamed 2015; Tomczak & Welling 2018;
Kingma et al. 2016; Gregor et al. 2015; Cremer et al. 2018; Marino et al. 2018; Takahashi et al. 2019). In this
paper we discuss more ﬂexible approaches modeling the latent space without imposing restrictions on the
underlying distribution.
Recently, Tagasovska et al. 2019 presented the Vine Copula Autoencoder (VCAE) . Their approach comprises
two building blocks, an autoencoder and a vine copula which models the dependence structure in latent
space. By that, they were able to create realistic, new images with samples from the ﬁtted vine copula
model in the latent space. In this work, we want to elaborate on this idea and compare various methods
to model the latent space of an autoencoder to turn it into a generative model. To this end, we analyze,
amongst others, the usage of Gaussian mixture models (GMM) as done by Ghosh et al. 2020, the vine copula
approach by Tagasovska et al. 2019, and simple multivariate Kernel Density Estimates . Additionally, we
introduce a new, non-parametric copula approach, the Empirical Beta Copula Autoencoder (EBCAE) . To get
a deeper understanding of how this can turn a standard autoencoder into a generative model, we inspect
resulting images, check the models for their ability to generalize and compare additional features. In this
1Under review as submission to TMLR
Figure 1: Function scheme of simple generative autoencoders. 1. An encoder fencodes the data Xto a low
dimensional representation Y. 2.1Yis modeled by Y/prime, 2.2 Generate new synthetic samples of the latent
space by sampling from Y/prime. 3. Decode the new samples with the decoder g.
study we do not aim to beat the latest SOTA generative models but want to shed light on diﬀerent modeling
techniques in the latent space and their characteristics in a rather straightforward autoencoder setting, which
may be applied in more sophisticated models as well. Thus, we strive for simplicity and take an alternative
route to more and more complex models. We believe that such an analysis in a straightforward setting is
essential for understanding the eﬀects from diﬀerent sampling methods, which may then be applied in more
advanced generative models. We also check whether the methods may be a simple alternative to more complex
models, such as normalization ﬂows Rezende & Mohamed (2015) or diﬀusion models (see, e.g., Rombach
et al. 2022; Vahdat et al. 2021). More speciﬁcally, we use the well-known Real NVP (Dinh et al., 2017) as an
example from these more sophisticated machine learning models in the latent space but do not elaborate on
these in detail. Note that in contrast to other methods (e.g., as proposed by Oring et al. 2021, Berthelot
et al. 2019 or van den Oord et al. 2017), the investigated overall approach does not restrict or change the
training of the autoencoder in any form. All models considered in this work are constructed in three steps,
visualized in Figure 1. First, an autoencoder, consisting of an encoder fand a decoder g, is trained to ﬁnd a
low-dimensional representation of the data X. Second, the data in the latent space Yis used to learn the best
ﬁtting representation Y/primeof it. This is where the examined models diﬀer from each other by using diﬀerent
methods to model the latent space. Finally, we sample from the learned representation of the latent space
and feed the samples into the decoder part of the autoencoder, creating new synthetic data samples.
Generative models are a vivid part of the machine learning literature. For example, new GAN developments
Varshney et al. (2021); Karras et al. (2021); Lee et al. (2021); Hudson & Zitnick (2021), developments in
the ﬁeld of autoencoders, Larsen et al. (2016); Yoon et al. (2021); Zhang et al. (2020); Shen et al. (2020) or
developments in variational autoencoders Sohn et al. (2015); Havtorn et al. (2021); Masrani et al. (2019);
Xu et al. (2019) are emerging. We again want to emphasize that for the models we consider, no prior is
needed, nor the optimization approach is changed, i.e., the latent space is modeled after the training of
the autoencoder post-hoc. Thus, the presented approach could be transferred to other, more sophisticated,
state-of-the-art autoencoders, as hinted in Ghosh et al. 2020. The general idea of creating new data by
sampling in the latent space of a generative model has already been used by, e.g., Tagasovska et al. 2019;
Dai & Wipf 2019; Brehmer & Cranmer 2020 or Ghosh et al. 2020, but to the best of our knowledge, no
analysis and comparison of such methods have been made so far. Closely related, more and more researchers
speciﬁcally address the latent space of generative models Mishne et al. (2019); Fajtl et al. (2020); Moor et al.
(2020); Oring et al. (2021); Hofert et al. (2021) in their work. There, especially hierarchical methods as
suggested by Maaløe et al. (2019) seem to be promising. Further, Autoencoders based on the Wasserstein
Distance lately achieved excellent results by changing the regularization term of a VAE and using or learning
a Gaussian Mixture Prior Tolstikhin et al. (2019); Mondal et al. (2021), analogously to our use of Gaussian
Mixtures ﬁtting the latent space distribution.
2Under review as submission to TMLR
This work does not propose a new ’black-box algorithm’ for generating data (although we present the new
EBCAE) but analyses challenges and possible answers on how autoencoders can be turned into generative
models by using well-understood tools of data modeling. One of our main ﬁndings is, that is hard to ﬁnd
a trade-oﬀ between out-of-bound sampling and creating new pictures. We conclude that besides a pure
numerical perspective and looking at new random samples of a generative model with a latent space, the
resulting image of the nearest neighbor in the latent space from the training data should be inspected. We
demonstrate in our experiments that copula-based approaches may be promising alternatives to traditional
modeling methods since they allow for the recombination of marginal distributions from one class with the
dependence structure of another class leading to new possibilities in synthesizing images and discuss targeted
sampling. Our conclusion is intended to point out relevant aspects to the user and discusses the advantages
and disadvantages of the models examined.
The remainder of the paper is structured as follows. Section 2 introduces various methods for modeling the
latent space. Besides traditional approaches, copula-based methods are introduced. Section 3 describes the
implementation, evaluation, and results of the experiments carried out. In Section 4 we discuss the results
and conclude the paper. Last, we provide additional experiments and insides for interested readers in the
appendix.
2 Modeling the latent space
In this section, we want to introduce and reﬂect on diﬀerent methods to model the latent space in an
autoencoder (Step 2 in Figure 1). All methods aim to ﬁt the low-dimensional data Yas best as possible to
be able to create new sample points in the latent space, which leads to new realistic images after passing the
decoder. We ﬁrst recap more ’traditional’ statistical tools, followed by copulas as an intuitive and ﬂexible
tool for modeling high-dimensional data. We brieﬂy explain how each approach can be used to model data in
the latent space and how to obtain samples thereof. Note that we do not introduce our benchmark models,
namely the standard plain vanilla VAEand theReal NVP , and refer to the original papers instead (Kingma
& Welling, 2014; Dinh et al., 2017). Pseudocode of the overall sampling approach is given in the Appendix
(Algorithm 2).
2.1 Traditional modeling methods
We classify the multivariate Gaussian distribution , aKernel Density Estimation (KDE) , and aGaussian
Mixture Model (GMM) as traditional modeling methods and give a rather short treatment of each below.
They are well known and can be studied in various statistics textbooks such as Hastie et al. 2001 or Bishop
2006.
Multivariate Gaussian
The probably simplest method is to assume the data in the latent space to follow a multivariate Gaussian
distribution. Thus, we estimate the covariance matrix ˆΣand mean vector ˆµof the date Y. In the second step,
we draw samples thereof and pass them through the decoder to generate new images. Note that this is similar
to the sampling procedure in a VAE, but without forcing the latent space to be Gaussian during training.
GMM
TheGaussian Mixture Model (GMM) aims to model the density of the latent space by mixing Mmultivariate
Gaussian distributions. Thus, the Gaussian mixture model has the form
f(x) =M/summationdisplay
m=1αmφ(x;µm,Σm) (1)
whereαmdenotes the mixing parameter and φthe density of the multivariate normal distribution with
mean vector µmand covariance matrix Σm. The model is usually ﬁt by maximum likelihood using the EM
algorithm. By combining several Gaussian distributions, it is more ﬂexible than estimating only one Gaussian
3Under review as submission to TMLR
distribution as above. A GMM can be seen as some kind of kernel method (Hastie et al., 2001), having a
rather wide kernel. In the extreme case, i.e., where mequals the number of points the density is estimated
on, a Gaussian distribution with zero variance is centered over each point. Kernel density estimation is
introduced in the following.
KDE
Kernel Density Estimation is a well-known non-parametric tool for density estimation. Put simply, a KDE
places a density around each data point. The total resulting estimated density is constructed by
f(x) =1
NλN/summationdisplay
i=1Kλ(x0,xi) (2)
withNbeing the total number of data points, λthe bandwidth, and Kthe used kernel. Note that the choice
of bandwidth and kernel can aﬀect the resulting estimated density. The kernel density estimation can be
performed in univariate data as well as in multivariate data. In this work, we rely on the most commonly
used kernel, the Gaussian Kernel, and a bandwidth ﬁtted via Silverman’s rule of thumb (Silverman, 1986) for
the univariate KDEs (i.e. for estimating the marginal distributions of the latent space), while we use a grid
search with 10-fold cross-validation in the multivariate case.
We use kernel density estimation in multiple manners throughout this work. First, we use a multivariate
KDE to model the density of the data in the latent space itself. In the case of a Gaussian kernel, it can be
written by
f(x) =1
N√
Σ2πN/summationdisplay
i=1e−1/2(x−xi)/primeΣ−1(x−xi)(3)
where Σrepresents the covariance matrix of the kernel, i.e., the matrix of bandwidths. Second, we ignore
the dependence structure between margins and estimate the univariate densities of each dimension in the
latent space by a KDE for each marginal distribution. In this way, we are able to ﬁnd out whether explicitly
modeling the dependence structure is necessary or not. We call that approach the Independent modeling
approach also denoted short by Independent in the following. Last, we use univariate KDEs for modeling the
marginal distributions of each dimension in the latent space and use them in the copula models described
below.
2.2 Copula based models
Besides the traditional modeling methods introduced above, we apply copula based models. In the following,
we ﬁrst introduce copulas as a tool for high-dimensional data, which allows us to model the latent space
in our application. Then, we focus on the two copula-based methods to model the latent space of the
autoencoder: the vine copula and theempirical beta copula approach. For detailed introductions to copulas,
we refer the reader to Nelsen 2006; Joe 2014; Durante & Sempi 2015.
Copulas have been subject to an increasing interest in the Machine Learning community over the last
decades, see, e.g., Dimitriev & Zhou 2021; Janke et al. 2021; Messoudi et al. 2021; Ma et al. 2021; Letizia
& Tonello 2020; Liu 2019; Kulkarni et al. 2018; Tran et al. 2015. In a nutshell, copula theory enables us
to decompose any d-variate distribution function into dmarginal univariate distributions and their joint
dependence structure, given by the copula function. Thus, copulas "couple" multiple univariate distributions
into one joint multivariate distribution. More formally, a d-variate copula C: [0,1]d− →[0,1]is ad-dimensional
joint distribution function whose margins are uniformly distributed on the unit interval. Decomposing and
coupling distributions with copulas is formalized in Theorem 2.1 going back to Sklar 1959.
Theorem 2.1 (Sklar 1959) .Consider a d-dimensional vector of random variables Yi= (Yi,1,...,Yi,d)with
joint distribution function FY(yi) =P(Y1≤yi,1,...,Yd≤yi,d)fori= 1,...,n. The marginal distribution
4Under review as submission to TMLR
functionsFjare deﬁned by Fj(yi,j) =P(Yj≤yi,j)foryi,j∈R,i= 1,...,nandj= 1,...,d. Then, there
exists a copula C, such that
FY(y1,..,yd) =C(F1(y1),...,Fd(yd))
for(y1,...,yd)∈Rd. Vice versa, using any copula ˜C,it follows that ˜FY(y1,..,yd) := ˜C(F1(y1),...,Fd(yd))
is a proper multivariate distribution function.
This allows us to construct multivariate distributions with the same dependence structure but diﬀerent
margins or multivariate distributions with the same margins but diﬀerent couplings/pairings, i.e., dependence
structures. The simplest estimator is given by the empirical copula. It can be estimated directly on the ranks
of each marginal distribution by
ˆC(u) =1
nn/summationdisplay
i=1d/productdisplay
j=11/braceleftbiggr(n)
i,j
n≤uj/bracerightbigg
(4)
withu= (u1,...,ud)∈[0,1]dandr(n)
i,jdenoting the rank of each yi,jwithin (y1,j,...,yn,j), i.e.,
r(n)
i,j=n/summationdisplay
k=11{yk,j≤yi,j}. (5)
Note that u= (u1,...,ud)represents a quantile level, hence a scaled rank. Simultaneously, the univariate
margins can be estimated using a KDE so that the full distribution latent space is governed for. Note
that it is not possible to draw new samples from the empirical copula directly as no random process is
involved. In our applications, the latent space is typically equipped with dimensions ≥2.Although a variety
of two-dimensional copula models exist, the amount of multivariate (parametric) copula models is somewhat
limited. We present two solutions to this problem in the following, namely vine copulas and theempirical
beta copula .
Vine Copula Autoencoder
Vine copulas decompose the multivariate density as a cascade of bivariate building blocks organized in a
hierarchical structure. This decomposition is not unique, and it inﬂuences the estimation procedure of
the model. Here, we use regular-vine (r-vine) models Czado (2019); Joe (2014) to model the 10, 20 and
100 dimensional latent space of the autoencoders at hand. An r-vine is built of a sequence of linked trees
Ti= (Vi,Ei), with nodes Viand edgesEifori= 1,...,d−1and follows distinct construction rules which we
present in Appendix B.
Thed-dimensional copula density can then be written as the product of its bivariate building blocks:
c(u1,...,ud) =d−1/productdisplay
i=1/productdisplay
e∈Eicaebe;De(uae|De,ube|De) (6)
with conditioning set Deand conditional probabilities, e.g., uae|De=P(Uae≤uae|De). The conditioning set
Deincludes all variables conditioned on at the respective position in the vine structure (see Appendix B).
For each resulting two-dimensional copula of conditional variables, any parametric or non-parametric copula
model (as done by Tagasovska et al. 2019) can be chosen. However, the construction and estimation of vine
copulas is rather complicated. Hence, assuming independence for seemingly unimportant building blocks,
so-called truncation, is regularly applied. Because of this, truncated vine copula models do not capture the
complete dependence structure of the data, and their usage is not underpinned by asymptotic theory. We
refer to Czado (2019); Czado & Nagler (2022); Aas (2016) for reviews of vine copula models.
Empirical Beta Copula Autoencoder
Theempirical beta copula (Segers et al., 2017) avoids the problem of choosing a single, parametric multivariate
copula model due to its non-parametric nature. Further, and in contrast to the presented vine copula
5Under review as submission to TMLR
approach, it oﬀers an easy way to model the full, non-truncated multivariate distribution based on the
univariate ranks of the joint distribution and, thus, seems to be a reasonable choice to model the latent space.
The empirical beta copula is closely related to the empirical copula (see Formula 5) and is a crucial element
of the Empirical-Beta-Copula Autoencoder. It is solely based on the ranks r(n)
i,jof the original data Yand
can be interpreted as a continuous counterpart of the empirical copula. It is deﬁned by
Cβ=1
nn/summationdisplay
i=1d/productdisplay
j=1Fn,r(n)
i,j(uj) (7)
foru= (u1,...,ud)∈[0,1]d, where
Fn,r(n)
i,j(uj) =P(U(r(n)
i,j)≤uj) (8)
=n/summationdisplay
p=r(n)
i,j/parenleftbiggn
p/parenrightbigg
up
j(1−uj)(n−p)(9)
is the cumulative distribution function of a beta distribution , i.e.,B(r(n)
i,j,r(n)
i,j+n−1). Asri,jis the rank of
theithelement in dimension j,U(ri,j)represents the ri,jthorder statistic of ni.i.d. uniformly distributed
random variables on [0,1]. For example, if the rank of the ithelement in dimension jis 5,U(ri,j)=U(5)
denotes the 5thorder statistic on ni.i.d. uniformly distributed random variables.
The intuition behind the empirical beta copula is as follows: Recall that the marginal distributions of a copula
are uniformly distributed on [0,1]and, hence, the kthsmallest value of scaled ranks r(n)
i,j/ncorresponds to the
kthorder statistic U(k). Such order statistics are known to follow a beta distribution B(k,k+n−1)(David
& Nagaraja, 2003). Consequently, the mathematical idea of the empirical beta copula is to replace each
indicator function of the empirical copula with the cumulative distribution function of the corresponding
rankr(n)
i,j.
We argue that the empirical beta copula can be seen as the naturally extended version of the empirical copula,
thus, it seems to be a good choice for dependence modeling. Segers et al. 2017 further demonstrates that
the empirical beta copula outperforms the empirical copula both in terms of bias and variance. A theorem
stating the asymptotic behavior of the empirical copula is given in Appendix C.
Synthetic samples in the latent space y/primeare created by reversing the modeling path. First, random samples
from the copula model u= (u1,...,ud)are drawn. Then, the copula samples are transformed back to the
natural scale of the data by the inverse probability integral transform of the marginal distributions, i.e.,
y/prime
j=ˆFj(uj), where ˆFjis the estimated marginal distribution and ujthejth element of the copula sample for
j∈{1,...,d}. Algorithm 1 summarizes the procedure.
Algorithm 1: Sampling from Empirical Beta Copula
Input:Sample Y⊂Rn×d, new sample size m
begin
Compute rank matrix Rn×dout of Y
Estimate marginals of Ywith KDE,/hatwidef1(y1), . . . ,/hatwidefd(yd).
fori≤mdo
Draw random from I∈[1, . . . , n ]
forj≤ddo
Draw uI,j∼B(RIj, n+ 1−RIj)
Setui= (uI1, . . . , u Id)
Rescale margins by Yi=/hatwideF−1
1(ui1), . . . ,/hatwideF−1
d(uid).
Output: New sample Y/primeof size m
We now present the experiments and results of a comparative study including all mentioned methodologies to
model the latent space in the next section.
6Under review as submission to TMLR
3 Experiments
In this section, we present the results of our experiments. We use the same architecture for the autoencoder
in all experiments for one dataset but replace the modeling technique for the latent space for all algorithms.
The architecture, as well as implementation details, are given in Appendix D. We further include a standard
VAE and the Real NVP normalization ﬂow approach modeling the latent space in our experiments to serve
as a benchmark.
Gaussian Distribution
Independent
Multivariate KDE
GMM
Vine Copula
EBC
VAE
Real NVP
Original
Figure 2: Comparison of random, synthetic samples of diﬀerent Autoencoder models row by row for MNIST
(left) and CelebA (right). Original input samples are given in the last row.
3.1 Setup
We ﬁrst describe the overall methodology and the usage of the methods proposed in Section 2. We then
introduce the used data sets and evaluation framework.
Methodology
We train an autoencoder consisting of two neural nets, an encoderf, and adecoderg. The encoder f
maps data Xfrom the original space to a lower-dimensional space, while the decoder greconstructs this
low-dimensional data Yfrom the low-dimensional latent space to the original space (see Fig. 1). We train both
neural nets in a way that the reconstruction loss is minimized, i.e., that the reconstructed data X/prime=g(f(X))
is as similar to the original data Xas possible. In the second step, we model the latent space Ydata with a
multivariate Gaussian distribution, a Gaussian mixture model, Kernel density estimates, the two presented
copula methods and the Real NVP. Thus, we ﬁt models with diﬀerent ﬂexibility and complexity while keeping
the training process of the autoencoder untouched. Last, new samples are generated by decoding random
samples from the learned model in the latent space. Note that such an approach is only reasonable when the
underlying autoencoder has learned a relevant and interesting representation of the data and the latent space
is smooth. We demonstrate this in Appendix E.
Datasets
We conduct experiments on one small-scale, one medium, and one large-scale dataset. The small-scale MNIST
dataset (LeCun et al., 2010) includes binary images of digits, while the medium-scale SVHNdataset (Netzer
et al., 2011) contains images of house numbers in Google Street View pictures. The large-scale CelebAdataset
(Liu et al., 2015) consists of celebrity images covering 40 diﬀerent face attributes. We split data into a train
set and a test set of 2000 samples which is a commonly used size for evaluation (Tagasovska et al., 2019;
7Under review as submission to TMLR
Xu et al., 2018). Note that the data sets cover diﬀerent dimensionalities in the latent space, allowing for a
throughout assessment of the methods under investigation.
Evaluation
Evaluation of results is performed in several ways. First, we visually compare random pictures generated
by the models. Second, we evaluate the results with the framework proposed by Xu et al. 2018, since a
log-likelihood evaluation is known to be incapable of assessing the quality (Theis et al., 2016) and unsuitable
for non-parametric models. Based on their results, we choose ﬁve metrics in our experiments: The earth
mover distance (EMD) , also known as Wasserstein distance (Vallender, 1974); the mean maximum discrepancy
(MMD) (Gretton et al., 2007); the 1-nearest neighbor-based two-sample test (1NN) , a special case of the
classiﬁer two-sample test (Lopez-Paz & Oquab, 2017); the Inception Score (Salimans et al., 2016); and the
Frêchet inception distance (Heusel et al., 2017) (the latter two over ResNet-34 softmax probabilities). In
line with Tagasovska et al. 2019 and as proposed by Xu et al. 2018, we further apply the EMD, MMD, and
1NN over feature mappings in the convolution space over ResNet-34 features. For all metrics except the
Inception Score, lower values are preferred. For more details on the metrics, we refer to Xu et al. 2018. Next,
we evaluate the ability to generate new, realistic pictures by the diﬀerent latent space modeling techniques.
Therefore, we compare new samples with their nearest neighbor in the latent space stemming from the original
data. This shows us whether the learned distribution covers the whole latent space, or stays too close to
known examples, i.e., the model does not generalize enough. Finally, we compare other features of the tested
models, such as their ability of targeted sampling and of recombining attributes.
3.2 Results
In the following, we show results for our various experiments. First, we present visual results for each of
the methods investigated to gain a qualitative understanding of their diﬀerences. Second, we compare the
methods in terms of performance metrics. Third, we evaluate the latent space and nearest neighbots in the
latent space. Finally, we address computing times and discuss targeted sampling and recombination of image
features.
Visual Results
Figure 2 shows images generated from each method for MNIST and CelebA. The GMM model is composed
of 10 elements, and the KDE is constructed using a Gaussian kernel with a bandwidth ﬁtted via a grid search
and 10-fold cross-validation. The speciﬁcation of the Real NVPs are given in the Appendix.
For the MNIST dataset, we observe the best results for the EBCAE (row 6) and KDE (row 3), while the
other methods seem to struggle a bit. For the CelebA, our visual observations are slightly diﬀerent. All
methods produce images that are clearly recognizable as faces. However, the Gaussian samples in row 1 and
independent margins in row 2 create pictures with some unrealistic artefacts, blurry backgrounds, or odd
colors. This is also the case for the GMM in row 4 and VCAE in row 5, but less severe. We believe that this
comes from samples of an empty area in the latent space, i.e., where none of the original input pictures were
projected to. In contrast to that, the samples in the latent space of the KDE, EBCAE, and Real NVP stay
within these natural bounds, producing good results after passing the decoder (rows 3, 6, 8). Recall that
all methods use the same autoencoder and only diﬀer by means of sampling in the latent space. From our
observations, we also conclude that the autoencoder for the CelebA dataset is less sensitive toward modeling
errors in the latent space since all pictures are clearly recognizable as faces. In contrast, for the MNIST
dataset, not all images clearly show numbers. Similar results for SVHN are presented in the Appendix.
Numerical Results
The numerical results computed from 2000 random samples displayed in Figure 3 prove that dependence
truly matters within the latent space. Simultaneously, the KDE, GMM, and EBCAE perform consistently
well over all metrics, delivering comparable results to the more complex Real NVP. Especially the EBCAE
outperforms the other methods, whereas the VCAE, Gauss model, and VAE usually cluster in the middle.
8Under review as submission to TMLR
Figure 3: Performance metrics of generative models on CelebA, reported over epochs computed from 2000
random samples. Note that they only diﬀer in the latent space sampling and share the same autoencoder.
We further report results over the number of samples in the latent space in Figure 9 in the Appendix. This,
at ﬁrst sight, unusual perspective visualizes the capability to reach good performance even for small sample
sizes in latent space. In a small-sample regime, it is crucial to assess how fast a method adapts to data in
the latent space and models it correctly. We see that all methods perform well for small sample sizes, i.e.,
n= 200.Similar experiments for MNIST and SVHN can be found in Appendix F.
Nearest Neighbour and Latent Space Evaluation
Next, we evaluate the diﬀerent modeling techniques in their ability to generate new, realistic images. For
this, we focus on pictures from the CelebA dataset in Figure 4. First, we create new, random samples with
the respective method (top row) and then compare these with their decoded nearest neighbor in the latent
space (middle row). The bottom row displays the latent space nearest neighbor in the original data space
before applying the autoencoder. By doing so, we are able to disentangle two eﬀects. First, the eﬀect from
purely encoding-decoding an image and, second, the eﬀect of modeling the latent space. Thus, we can check
whether new images are signiﬁcantly diﬀerent from the input, i.e., whether the distribution modeling the
latent space merely reproduces images or generalizes to some extent.
We observe that the samples from GMM, VCAE and the Real NVP substantially diﬀer from their nearest
neighbors. However, again they sometimes exhibit unrealistic colors and blurry backgrounds. The samples
created from KDE and EBCAE look much more similar to their nearest neighbors in the latent space,
indicating that these methods do not generalize to the extent of the other methods. However, their samples
do not include unrealistic colors or features and seem to avoid sampling from areas where no data point
of the original data is present. Thus, they stay in ’natural bounds’. Note that this eﬀect apparently is not
reﬂected in the numerical evaluation metrics. We, therefore, recommend that, in addition to a quantitative
evaluation, a qualitative evaluation of the resulting images should always be performed.
To further underpin this point, Figure 5 shows 2-dimensional TSNE-Embeddings (see, e.g.,van der Maaten
& Hinton 2008) of the latent space for all six versions of the autoencoder (MNIST). Black points indicate
original input data, and colored points are synthetic samples from the corresponding method. We see that
the KDE, as well as the EBCAE, stay close to the original space. The samples from the GMM and Real
NVP also seem to closely mimic the original data, whereas the other methods fail to do so. This visualization
conﬁrms our previous conjecture that some algorithms tend to sample from ’empty’ areas in the latent space,
leading to unrealistic results.
9Under review as submission to TMLR
(a) Gaussian
 (b) Independent
 (c) KDE
 (d) Real NVP
(e) GMM
 (f) VCAE
 (g) EBCAE
Figure 4: Nearest neighbor evaluation of the six investigated modeling methods after decoding. Top row:
Newly generated images. Middle row: Nearest neighbor of new image in the latent space of training samples
after decoding. Bottom row: Original input training picture of nearest neighbor in latent space.
Figure 5: TSNE embeddings of samples in the latent space of the MNIST dataset. Points from the original
input training data Yare given in black, whereas new, synthetic samples Y/primein the latent space stemming
from the diﬀerent modeling methods are colored.
Computing Times, Targeted Sampling and Recombination
We also report computing times for learning and sampling of the diﬀerent models for MNIST and CelebA in
Table 1. Unsurprisingly, the more straightforward methods such as Gauss, Independence, KDE, and GMM,
exhibit the lowest sampling times. The Real NVP shows the highest learning time as a neural network is
ﬁtted. However, we expect the diﬀerence to be much smaller once trained on an appropriate GPU. The times
also reﬂect the complexities of the methods in the latent space dimensions.
Table 1: Modeling and sampling time in the CelebA andMNIST dataset of 2000 artiﬁcial samples based
on a latent space of size n= 2000in [s].
CelebA CelebA MNIST MNIST
Method Learn Sample Learn Sample
Gauss <0.01 0.01 0.002 0.002
Indep. 4.10 0.07 0.393 0.003
KDE 75.25 0.01 13.958 0.001
GMM 1.35 0.03 0.115 0.004
VCAE 306.97 148.48 10.345 4.590
EBCAE 3.41 59.36 0.328 5.738
Real NVP 2541.19 3.69 341.608 0.477
10Under review as submission to TMLR
Last, we discuss other features of the tested methods, such as targeted sampling and recombination. In
contrast to the other techniques, the KDE and EBCAE allow for targeted sampling. Thus, we can generate
new images with any desired characteristic directly, e.g., only ones in a data set of images of numbers. In the
case of the KDE, this simply works by sampling from the estimated density of the corresponding sub-group.
In the case of the EBCAE, we randomly choose among rows in the rank matrix of original samples that
share the desired speciﬁc attribute, i.e., we sample Iin the ﬁrst for-loop in Algorithm 1 conditional on the
sub-group. Thus, newly generated samples stay close to the original input and therefore share the same main
characteristics. Other approaches are also possible, however, they need further tweaks to the model, training,
or sampling as the conditional variational autoencoder (Sohn et al., 2015).
The second feature we discuss is recombination. By using copula-based models (VCAE and EBCAE), we
can facilitate the decomposition idea and split the latent space in its dependence structure and margins, i.e.,
we combine the dependence structure of images with a speciﬁc attribute with the marginal distributions of
images with diﬀerent attributes. Therefore, copula-based methods allow controlling the attributes of created
samples to some extent. Our experiments suggest that the dependence structure provides the basic properties
of an image, while the marginal distributions are responsible for details (see, e.g., Figure 6). However, we
want to point out that it is not generally clear what information is embedded in the dependence structure and
what information is in the marginal distributions of latent space. This might also depend on the autoencoder
and the dataset at hand. Thad said, using such a decomposition enables higher ﬂexibility and hopefully fuels
new methodological developments in this ﬁeld.
Figure 6: Samples from recombination experiment with the EBCAE. Glasses are removed by using the
marginal distribution of the training data without glasses in the latent space. Top row: Samples created
with the dependence structure in latent space from samples with glasses and marginal distributions in latent
space from samples without glasses. Middle row: Nearest neighbor of newly created sample in the training
data after decoding. Bottom row: Original input picture of nearest neighbor in latent space.
4 Discussion
In this section, we want to discuss the results of our experiments and want to express some further thoughts.
So, is sampling from the latent space a simple way towards generative models? We observed that sampling
from the latent space via the investigated methods is indeed a viable approach to turn an autoencoder into
a generative model and may be promising for application in more advanced autoencoders. However, each
modeling approach in this setting comes with its own restrictions, advantages, and problems.
We witness a trade-oﬀ between the ability to generalize, i.e., to create genuinely new pictures, and sample
quality, i.e., to avoid unrealistic colors or artefacts. In cases where new data points are sampled in the
neighborhood to existing points (as in the KDE or EBCAE), the newly generated data stays in somehow
natural bounds and provides realistic, but not completely new, decoded samples. On the other hand, modeling
the latent space too generically leads to bad-quality images. We believe this is similar to leaving the feasible
set of an optimization problem or sampling from a wrong prior. While being close to actual points of the
original latent space, new samples stay within the feasible set. By moving away from these points, the risk
11Under review as submission to TMLR
of sampling from an unfeasible region and thus creating unrealistic new samples increases. Recombination
via a copula-based approach of marginal distributions and dependence structures oﬀers the possibility to
detect new feasible regions in the latent space for the creation of realistic images. Also, interpolating by
building convex combinations of two points in the latent space seems reasonable. However, without further
restrictions during training (see, e.g., discussion in Ghosh et al. 2020), we cannot principally guarantee proper
interpolation results. Further, we observe that the mentioned trade-oﬀ is not reﬂected by the performance
metrics. Therefore, we strongly recommend not only checking quantitative results but also ﬁnding and
analyzing the nearest neighbor in the original data to detect the pure reproduction of pictures. This also
reveals that the development of further evaluation metrics could be beneﬁcial.
A closely related issue is the choice of a parametric vs. a non-parametric modeling method in the latent
space. Parametric methods can place probability mass in the latent space, where no data point of the original
input data was observed. Thus, parametric methods are able to generate (truly) new data, subject to their
assumption. However, if the parametric assumption is wrong, the model creates samples from ’forbidden’
areas in the latent space leading to unrealistic images. In spite of this, carefully chosen parametric models
can be beneﬁcial, and even a log-likelihood is computable and traceable (although we do not use it for
training). Non-parametric methods avoid this human decision and possible source of error completely but are
closely bound to the empirical distribution of the given input data. Consequently, such methods can miss
important areas of the latent space but create more realistic images. Furthermore, adjusting parameters of
the non-parametric models, such as increasing bandwidths or lowering truncation levels, oﬀer possibilities to
slowly overcome these limitations.
Besides the major points above, the EBCAE and KDE oﬀer an easy way of targeted sampling without
additional training eﬀort. This can be beneﬁcial for various applications and is not as straightforward with
other methods. Lastly, the investigated methods diﬀer in their runtime. While vine copula learning and
sampling is very time-intensive for high dimensions, the EBCAE is much faster but still outperformed by the
competitors. For the non-copula methods, the GMM is really fast in both datasets while still capturing the
dependence structure to some extent. In contrast to that, the Real NVP needs more time for training but is
rather quick in generating new samples.
To sum up, we can conﬁrm that there are indeed simple methods to turn a plain autoencoder into a generative
model, which may then also be beneﬁcial in more complex generative models. We conclude that the optimal
method to do so depends on the goals of the user. Besides runtime considerations, the speciﬁc application of
the autoencoder matters. For example, if one is interested in targeted sampling, EBCAE or KDE should
be applied. Recombination experiments call for a copula-based approach, whereas in all cases, the trade-oﬀ
between generalization and out-of-bound sampling should be considered.
References
Kjersti Aas. Pair-copula constructions for ﬁnancial applications: A review. Econometrics , 4(4), 2016. ISSN
2225-1146.
Tim Bedford and Roger M. Cooke. Vines: A new graphical model for dependent random variables. The
Annals of Statistics , 30(4):1031–1068, 2002. ISSN 00905364.
David Berthelot, Colin Raﬀel, Aurko Roy, and Ian Goodfellow. Understanding and improving interpolation
in autoencoders via an adversarial regularizer. In International Conference on Learning Representations ,
2019.
Christopher M. Bishop. Pattern Recognition and Machine Learning (Information Science and Statistics) .
Springer-Verlag, Berlin, Heidelberg, 2006. ISBN 0387310738.
Johann Brehmer and Kyle Cranmer. Flows for simultaneous manifold learning and density estimation. In
H. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, and H. Lin (eds.), Advances in Neural Information
Processing Systems , volume 33, pp. 442–453. Curran Associates, Inc., 2020.
Chris Cremer, Xuechen Li, and David Duvenaud. Inference suboptimality in variational autoencoders, 2018.
URLhttps://arxiv.org/abs/1801.03558 .
12Under review as submission to TMLR
Claudia Czado. Analyzing Dependent Data with Vine Copulas: A Practical Guide With R . Springer
International Publishing, 2019.
Claudia Czado and Thomas Nagler. Vine copula based modeling. Annual Review of Statistics and Its
Application , 9(1):453–477, 2022. doi: 10.1146/annurev-statistics-040220-101153.
Bin Dai and David Wipf. Diagnosing and enhancing vae models, 2019. URL https://arxiv.org/abs/1903.
05789.
H. A. David and H. N. Nagaraja. Order Statistics . John Wiley and Sons, 08 2003. doi: http://dx.doi.org/10.
1002/0471722162.
Alek Dimitriev and Mingyuan Zhou. CARMS: Categorical-antithetic-REINFORCE multi-sample gradient
estimator. In A. Beygelzimer, Y. Dauphin, P. Liang, and J. Wortman Vaughan (eds.), Advances in Neural
Information Processing Systems , 2021.
Laurent Dinh, Jascha Sohl-Dickstein, and Samy Bengio. Density estimation using real NVP. In 5th
International Conference on Learning Representations, ICLR 2017, Toulon, France, April 24-26, 2017,
Conference Track Proceedings . OpenReview.net, 2017.
Fabrizio Durante and Carlo Sempi. Principles of copula theory . CRC Press LLC, 01 2015. doi: 10.1201/b18674.
Jiri Fajtl, Vasileios Argyriou, Dorothy Monekosso, and Paolo Remagnino. Latent bernoulli autoencoder.
In Hal Daumé III and Aarti Singh (eds.), Proceedings of the 37th International Conference on Machine
Learning , volume 119 of Proceedings of Machine Learning Research , pp. 2964–2974. PMLR, 13–18 Jul 2020.
Partha Ghosh, Mehdi S. M. Sajjadi, Antonio Vergari, Michael Black, and Bernhard Scholkopf. From variational
to deterministic autoencoders. In International Conference on Learning Representations , 2020.
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron
Courville, and Yoshua Bengio. Generative adversarial nets. In Z. Ghahramani, M. Welling, C. Cortes,
N. Lawrence, and K. Q. Weinberger (eds.), Advances in Neural Information Processing Systems , volume 27.
Curran Associates, Inc., 2014.
Karol Gregor, Ivo Danihelka, Alex Graves, Danilo Rezende, and Daan Wierstra. Draw: A recurrent neural
network for image generation. In Francis Bach and David Blei (eds.), Proceedings of the 32nd International
Conference on Machine Learning , volume 37 of Proceedings of Machine Learning Research , pp. 1462–1471,
Lille, France, 07–09 Jul 2015. PMLR.
Arthur Gretton, Karsten Borgwardt, Malte Rasch, Bernhard Schölkopf, and Alex Smola. A kernel method for
the two-sample-problem. In B. Schölkopf, J. Platt, and T. Hoﬀman (eds.), Advances in Neural Information
Processing Systems , volume 19. MIT Press, 2007.
Charles R. Harris, K. Jarrod Millman, Stéfan J van der Walt, Ralf Gommers, Pauli Virtanen, David
Cournapeau, Eric Wieser, Julian Taylor, Sebastian Berg, Nathaniel J. Smith, Robert Kern, Matti Picus,
Stephan Hoyer, Marten H. van Kerkwijk, Matthew Brett, Allan Haldane, Jaime Fernández del Río, Mark
Wiebe, Pearu Peterson, Pierre Gérard-Marchant, Kevin Sheppard, Tyler Reddy, Warren Weckesser, Hameer
Abbasi, Christoph Gohlke, and Travis E. Oliphant. Array programming with NumPy. Nature, 585:357–362,
2020. doi: 10.1038/s41586-020-2649-2.
Trevor Hastie, Robert Tibshirani, and Jerome Friedman. The Elements of Statistical Learning . Springer
Series in Statistics. Springer New York Inc., New York, NY, USA, 2001.
Jakob D. Drachmann Havtorn, Jes Frellsen, Soren Hauberg, and Lars Maaløe. Hierarchical vaes know what
they don’t know. In Marina Meila and Tong Zhang (eds.), Proceedings of the 38th International Conference
on Machine Learning , volume 139 of Proceedings of Machine Learning Research , pp. 4117–4128. PMLR,
18–24 Jul 2021.
13Under review as submission to TMLR
Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter. Gans trained
by a two time-scale update rule converge to a local nash equilibrium. In I. Guyon, U. V. Luxburg, S. Bengio,
H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett (eds.), Advances in Neural Information Processing
Systems, volume 30. Curran Associates, Inc., 2017.
Marius Hofert, Avinash Prasad, and Mu Zhu. Quasi-random sampling for multivariate distributions via
generative neural networks. Journal of Computational and Graphical Statistics , 30(3):647–670, 2021. doi:
10.1080/10618600.2020.1868302.
Drew A Hudson and Larry Zitnick. Generative adversarial transformers. In Marina Meila and Tong Zhang
(eds.),Proceedings of the 38th International Conference on Machine Learning , volume 139 of Proceedings
of Machine Learning Research , pp. 4487–4499. PMLR, 18–24 Jul 2021.
Tim Janke, Mohamed Ghanmi, and Florian Steinke. Implicit generative copulas. In Thirty-Fifth Conference
on Neural Information Processing Systems , 2021.
H. Joe.Dependence modeling with copulas . Chapman & Hall/CRC, 01 2014. doi: 10.1201/b17116.
Tero Karras, Miika Aittala, Samuli Laine, Erik Härkönen, Janne Hellsten, Jaakko Lehtinen, and Timo Aila.
Alias-free generative adversarial networks. In Thirty-Fifth Conference on Neural Information Processing
Systems, 2021.
Diederik P. Kingma and Max Welling. Auto-Encoding Variational Bayes. In 2nd International Conference
on Learning Representations, ICLR 2014, Banﬀ, AB, Canada, April 14-16, 2014, Conference Track
Proceedings , 2014.
Durk P Kingma, Tim Salimans, Rafal Jozefowicz, Xi Chen, Ilya Sutskever, and Max Welling. Improved
variational inference with inverse autoregressive ﬂow. In D. Lee, M. Sugiyama, U. Luxburg, I. Guyon, and
R. Garnett (eds.), Advances in Neural Information Processing Systems , volume 29. Curran Associates, Inc.,
2016.
Vaibhav Kulkarni, Natasa Tagasovska, Thibault Vatter, and Benoit Garbinato. Generative models for
simulating mobility trajectories. ArXiv, 2018.
Anders Boesen Lindbo Larsen, Søren Kaae Sønderby, Hugo Larochelle, and Ole Winther. Autoencoding
beyond pixels using a learned similarity metric. In Maria Florina Balcan and Kilian Q. Weinberger (eds.),
Proceedings of The 33rd International Conference on Machine Learning , volume 48 of Proceedings of
Machine Learning Research , pp. 1558–1566, New York, New York, USA, 20–22 Jun 2016. PMLR.
Yann LeCun, Corinna Cortes, and CJ Burges. Mnist handwritten digit database. ATT Labs [Online].
Available: http://yann.lecun.com/exdb/mnist , 2, 2010.
Jinhee Lee, Haeri Kim, Youngkyu Hong, and Hye Won Chung. Self-diagnosing GAN: Diagnosing underrep-
resented samples in generative adversarial networks. In Thirty-Fifth Conference on Neural Information
Processing Systems , 2021.
Nunzio A. Letizia and Andrea M. Tonello. Segmented generative networks: Data generation in the uniform
probability space. IEEE Transactions on Neural Networks and Learning Systems , pp. 1–10, 2020. doi:
10.1109/TNNLS.2020.3042380.
Weiwei Liu. Copula multi-label learning. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d /quotesingle.ts1Alché-Buc,
E. Fox, and R. Garnett (eds.), Advances in Neural Information Processing Systems , volume 32. Curran
Associates, Inc., 2019.
Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang. Deep learning face attributes in the wild. In
Proceedings of International Conference on Computer Vision (ICCV) , December 2015.
David Lopez-Paz and Maxime Oquab. Revisiting classiﬁer two-sample tests. In 5th International Conference
on Learning Representations, ICLR 2017, Toulon, France, April 24-26, 2017, Conference Track Proceedings .
OpenReview.net, 2017.
14Under review as submission to TMLR
Jiaqi Ma, Bo Chang, Xuefei Zhang, and Qiaozhu Mei. CopulaGNN: Towards integrating representational
and correlational roles of graphs in graph neural networks. In International Conference on Learning
Representations , 2021.
Lars Maaløe, Marco Fraccaro, Valentin Liévin, and Ole Winther. Biva: A very deep hierarchy of latent
variables for generative modeling, 2019.
Alireza Makhzani, Jonathon Shlens, Navdeep Jaitly, Ian Goodfellow, and Brendan Frey. Adversarial
autoencoders, 2016.
Joe Marino, Yisong Yue, and Stephan Mandt. Iterative amortized inference. In Jennifer Dy and Andreas
Krause (eds.), Proceedings of the 35th International Conference on Machine Learning , volume 80 of
Proceedings of Machine Learning Research , pp. 3403–3412. PMLR, 10–15 Jul 2018.
Vaden Masrani, Tuan Anh Le, and Frank Wood. The thermodynamic variational objective. In H. Wallach,
H. Larochelle, A. Beygelzimer, F. d /quotesingle.ts1Alché-Buc, E. Fox, and R. Garnett (eds.), Advances in Neural
Information Processing Systems , volume 32. Curran Associates, Inc., 2019.
Soundouss Messoudi, Sébastien Destercke, and Sylvain Rousseau. Copula-based conformal prediction for
multi-target regression. Pattern Recognit. , 120:108101, 2021.
Gal Mishne, Uri Shaham, Alexander Cloninger, and Israel Cohen. Diﬀusion nets. Applied and Computational
Harmonic Analysis , 47(2):259–285, 2019. ISSN 1063-5203. doi: https://doi.org/10.1016/j.acha.2017.08.007.
Arnab Kumar Mondal, Himanshu Asnani, Parag Singla, and AP Prathosh. Flexae: ﬂexibly learning latent
priors for wasserstein auto-encoders. In Cassio de Campos and Marloes H. Maathuis (eds.), Proceedings
of the Thirty-Seventh Conference on Uncertainty in Artiﬁcial Intelligence , volume 161 of Proceedings of
Machine Learning Research , pp. 525–535. PMLR, 27–30 Jul 2021.
Michael Moor, Max Horn, Bastian Rieck, and Karsten Borgwardt. Topological autoencoders. In Hal Daumé
III and Aarti Singh (eds.), Proceedings of the 37th International Conference on Machine Learning , volume
119 ofProceedings of Machine Learning Research , pp. 7045–7054. PMLR, 13–18 Jul 2020.
Roger B. Nelsen. An Introduction to Copulas . Springer Science+Business Media, Inc., 2006. ISBN 0-387-
28659-4.
Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, and Andrew Y. Ng. Reading
digits in natural images with unsupervised feature learning. In NIPS Workshop on Deep Learning and
Unsupervised Feature Learning 2011 , 2011. URL http://ufldl.stanford.edu/housenumbers/nips2011_
housenumbers.pdf .
Alon Oring, Zohar Yakhini, and Yacov Hel-Or. Autoencoder image interpolation by shaping the latent space.
In Marina Meila and Tong Zhang (eds.), Proceedings of the 38th International Conference on Machine
Learning , volume 139 of Proceedings of Machine Learning Research , pp. 8281–8290. PMLR, 18–24 Jul 2021.
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen,
Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Kopf, Edward Yang, Zachary
DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, and
Soumith Chintala. Pytorch: An imperative style, high-performance deep learning library. In H. Wallach,
H. Larochelle, A. Beygelzimer, F. d /quotesingle.ts1Alché-Buc, E. Fox, and R. Garnett (eds.), Advances in Neural
Information Processing Systems , volume 32. Curran Associates, Inc., 2019.
F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer,
R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay.
Scikit-learn: Machine learning in Python. Journal of Machine Learning Research , 12:2825–2830, 2011.
Danilo Rezende and Shakir Mohamed. Variational inference with normalizing ﬂows. In Francis Bach and
David Blei (eds.), Proceedings of the 32nd International Conference on Machine Learning , volume 37 of
Proceedings of Machine Learning Research , pp. 1530–1538, Lille, France, 07–09 Jul 2015. PMLR.
15Under review as submission to TMLR
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and BjÃ ¶rn Ommer. High-resolution
image synthesis with latent diﬀusion models. In Proceedings of the IEEE Conference on Computer Vision
and Pattern Recognition (CVPR) , 2022.
Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, Xi Chen, and Xi Chen.
Improved techniques for training gans. In D. Lee, M. Sugiyama, U. Luxburg, I. Guyon, and R. Garnett
(eds.),Advances in Neural Information Processing Systems , volume 29. Curran Associates, Inc., 2016.
Johan Segers, Masaaki Sibuya, and Hideatsu Tsukahara. The empirical beta copula. Journal of Multivariate
Analysis, 155:35–51, 2017. ISSN 0047-259X. doi: doi.org/10.1016/j.jmva.2016.11.010.
Tianxiao Shen, Jonas Mueller, Regina Barzilay, and Tommi S. Jaakkola. Educating text autoencoders: Latent
representation guidance via denoising. In Proceedings of The thirty-seventh International Conference on
Machine Learning , pp. 8719–8729, 2020.
B. W. Silverman. Density estimation for statistics and data analysis / B.W. Silverman . Chapman and Hall
London ; New York, 1986. ISBN 0412246201.
Abe Sklar. Fonctions de répartition à n dimensions et leurs marges. Publications de l’Institut de Statistique
de l’Université de Paris , 8:229–231, 1959.
Kihyuk Sohn, Honglak Lee, and Xinchen Yan. Learning structured output representation using deep
conditional generative models. In C. Cortes, N. Lawrence, D. Lee, M. Sugiyama, and R. Garnett (eds.),
Advances in Neural Information Processing Systems , volume 28. Curran Associates, Inc., 2015.
Natasa Tagasovska, Damien Ackerer, and Thibault Vatter. Copulas as high-dimensional generative models:
Vine copula autoencoders. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d /quotesingle.ts1Alché-Buc, E. Fox, and
R. Garnett (eds.), Advances in Neural Information Processing Systems , volume 32. Curran Associates, Inc.,
2019.
Hiroshi Takahashi, Tomoharu Iwata, Yuki Yamanaka, Masanori Yamada, and Satoshi Yagi. Variational
autoencoder with implicit optimal priors. AAAI’19/IAAI’19/EAAI’19. AAAI Press, 2019. ISBN 978-1-
57735-809-1. doi: 10.1609/aaai.v33i01.33015066.
L. Theis, A. van den Oord, and M. Bethge. A note on the evaluation of generative models. In International
Conference on Learning Representations , Apr 2016.
Ilya Tolstikhin, Olivier Bousquet, Sylvain Gelly, and Bernhard Schoelkopf. Wasserstein auto-encoders, 2019.
Jakub Tomczak and Max Welling. Vae with a vampprior. In Amos Storkey and Fernando Perez-Cruz (eds.),
Proceedings of the Twenty-First International Conference on Artiﬁcial Intelligence and Statistics , volume 84
ofProceedings of Machine Learning Research , pp. 1214–1223. PMLR, 09–11 Apr 2018.
Dustin Tran, David Blei, and Edo M Airoldi. Copula variational inference. In C. Cortes, N. Lawrence, D. Lee,
M. Sugiyama, and R. Garnett (eds.), Advances in Neural Information Processing Systems , volume 28.
Curran Associates, Inc., 2015.
Arash Vahdat, Karsten Kreis, and Jan Kautz. Score-based generative modeling in latent space. In Neural
Information Processing Systems (NeurIPS) , 2021.
S. S. Vallender. Calculation of the wasserstein distance between probability distributions on the line. Theory
of Probability and Its Applications , 18:435–435, 1974.
Aaron van den Oord, Oriol Vinyals, and Koray Kavukcuoglu. Neural discrete representation learning. In
Proceedings of the 31st International Conference on Neural Information Processing Systems , NIPS’17, pp.
6309–6318, Red Hook, NY, USA, 2017. Curran Associates Inc. ISBN 9781510860964.
Laurens van der Maaten and Geoﬀrey Hinton. Visualizing data using t-sne. Journal of Machine Learning
Research , 9(86):2579–2605, 2008.
16Under review as submission to TMLR
Guido Van Rossum and Fred L Drake Jr. Python reference manual . Centrum voor Wiskunde en Informatica
Amsterdam, 1995.
Sakshi Varshney, Vinay Kumar Verma, Srijith P K, Lawrence Carin, and Piyush Rai. CAM-GAN: Continual
adaptation modules for generative adversarial networks. In Thirty-Fifth Conference on Neural Information
Processing Systems , 2021.
Pauli Virtanen, Ralf Gommers, Travis E. Oliphant, Matt Haberland, Tyler Reddy, David Cournapeau, Evgeni
Burovski, Pearu Peterson, Warren Weckesser, Jonathan Bright, Stéfan J. van der Walt, Matthew Brett,
Joshua Wilson, K. Jarrod Millman, Nikolay Mayorov, Andrew R. J. Nelson, Eric Jones, Robert Kern, Eric
Larson, C J Carey, İlhan Polat, Yu Feng, Eric W. Moore, Jake VanderPlas, Denis Laxalde, Josef Perktold,
Robert Cimrman, Ian Henriksen, E. A. Quintero, Charles R. Harris, Anne M. Archibald, Antônio H. Ribeiro,
Fabian Pedregosa, Paul van Mulbregt, and SciPy 1.0 Contributors. SciPy 1.0: Fundamental Algorithms for
Scientiﬁc Computing in Python. Nature Methods , 17:261–272, 2020. doi: 10.1038/s41592-019-0686-2.
Haowen Xu, Wenxiao Chen, Jinlin Lai, Zhihan Li, Youjian Zhao, and Dan Pei. On the necessity and
eﬀectiveness of learning the prior of variational auto-encoder, 2019. URL https://arxiv.org/abs/1905.
13452.
Qiantong Xu, Gao Huang, Yang Yuan, Chuan Guo, Yu Sun, Felix Wu, and Kilian Q. Weinberger. An
empirical study on evaluation metrics of generative adversarial networks. ArXiv, abs/1806.07755, 2018.
Sangwoong Yoon, Yung-Kyun Noh, and Frank Park. Autoencoding under normalization constraints. In
Marina Meila and Tong Zhang (eds.), Proceedings of the 38th International Conference on Machine Learning ,
volume 139 of Proceedings of Machine Learning Research , pp. 12087–12097. PMLR, 18–24 Jul 2021.
Zijun Zhang, Ruixiang Zhang, Zongpeng Li, Yoshua Bengio, and Liam Paull. Perceptual generative autoen-
coders. In Hal Daumé III and Aarti Singh (eds.), Proceedings of the 37th International Conference on
Machine Learning , volume 119 of Proceedings of Machine Learning Research , pp. 11298–11306. PMLR,
13–18 Jul 2020.
Appendix
A Pseudocode: Overall sampling approach
Algorithm 2: Overall sampling approach
Input:Autoencoder with Encoder fand Decoder g
begin
Compute latent space Yby passing training samples through encoder f
for each method do
Model the latent space by ﬁtting the respective method
Create new samples from the latent space Y/primeby drawing (randomly) from the ﬁtted method
for each element Y/prime
iinY/primedo
Decode Y/prime
iby passing it through the decoder g
Output: New sample X/prime
B Details on the Vine Copula
In the vine copula autoencoder Tagasovska et al. (2019) use regular-vine (r-vines) . A r-vine is built of a
sequence of linked trees Ti= (Vi,Ei), with nodes Viand edgesEifori= 1,...,d−1. Ad−dimensional vine
tree structure V= (T1,...,Td−1)is a sequence of T−1trees if (see Czado 2019):
1.Each treeTj= (Ni,Ei)is connected, i.e. for all nodes a,b∈Ti,i= 1,...,d−1,there exists a path
n1,...,nk⊂Njwitha=n1,b=nk.
17Under review as submission to TMLR
2.T1is a tree with node set N1={1,...,d}and edge set E1.
3. Fori≥2,Tjis a tree with node set Ni=Ei−1and edge set Ei.
4. Fori= 2,...,d−1and{a,b}∈Eiit must hold that |a∩b|= 1.
An example of a ﬁve-dimensional vine tree structure is given below in Figure 7. Note that the structure has
to be estimated and multiple structures are possible. For details on vine copula estimation, see Czado (2019);
Joe (2014); Bedford & Cooke (2002).
Figure 7: Example of a vine copula tree structure T1−T4for ﬁve dimensions.
C Asymptotics of the Empirical Beta Copula
Theorem C.1 gives the asymptotic behavior of the empirical beta copula.
Theorem C.1 (Asymptotics of the empirical beta copula) .Let the copula Chave continuous ﬁrst-order
partial derivatives ˙Cj=δC(u)/δujfor eachj∈{1,...,d}on the setIj={u∈[0,1]d: 0<uj<1}. The
corresponding empirical copula is denoted as Cn, with empirical copula process Gn=√n/parenleftbigg
Cn(u)−C(u)/parenrightbigg
and empirical beta copula Cβ
nwith empirical beta copula process Gβ
n=√n/parenleftbigg
Cβ
n(u)−C(u)/parenrightbigg
. Suppose Gn G
forn− →∞toGinl∞([0,1]d), where Gis a limiting process having continuous trajectories almost surely.
Then, inl∞([0,1]d)
Gβ
n=Gn+op(1),n−→∞.
Proof.See Segers et al. 2017 Section 3.
In short, Theorem C.1 states that the empirical beta copula has the same large-sample distribution as the
empirical copula and, thus, converges to the true copula. However, the empirical beta copula performs better
for small samples. Segers et al. 2017 demonstrate that the empirical beta copula outperforms the empirical
copula both in terms of bias and variance.
18Under review as submission to TMLR
D Implementation
D.1 Implementation of the Autoencoder
We implemented the experiments in Python 3.8 Van Rossum & Drake Jr (1995) using numpy 1.22.0, scipy
1.7.1„ scikit-learn 1.1.0 and pytorch 1.10.1 Harris et al. (2020); Virtanen et al. (2020); Pedregosa
et al. (2011); Paszke et al. (2019). The AEs were trained using the Adam optimizer with learning rate 0.001
for MNIST and 0.0005for SVHN and CelebA. A weight decay of 0.001was used in all cases. Batch sizes
were ﬁxed to 128 (MNIST), 32 (SVHN) and 100 (CelebA) samples for training, while the size of the latent
space was set to 10 (MNIST), 20 (SVHN) and 100 (CelebA) according to the data sets size and complexity.
Training was executed on a separate train set and evaluated on a hold-out test set of 2000 samples, similar
to Tagasovska et al. 2019. For comparison with the VCAE and performance metrics, we have resorted to
the implementation from Tagasovska et al. 2019 and Xu et al. 2018. The architectures for all networks are
described in Appendix D.2. We trained the autoencoders on an NVIDIA Tesla V100 GPU with 10 Intel Xeon
Gold 6248 CPUs. The experiments are executed afterward on a PC with an Intel i7-6600U CPU and 20GB
RAM.
D.2 Architectures of Autoencoders and VAE
We use the same architecture for EBCAE, VCAE, and VAE as described below. All models were trained by
minimizing the Binary Cross Entropy loss.
MNIST
Encoder:
x∈R32×32→Conv 32 →BN→ReLu
→Conv 64 →BN→ReLu
→Conv 128 →BN→ReLu
→FC10
Decoder:
y∈R10→FC100→ConvT 128 →BN→ReLu
→ConvT 64 →BN→ReLu
→ConvT 32 →BN→ReLu
→FC1
For all (de)convolutional layers, we used 4 ×4 ﬁlters, a stride of 2, and a padding of 1. BNdenotes
batch normalization, ReLUrectiﬁed linear units, and FCfully connected layers. Last, Convkdenotes the
convolution with kﬁlters.
SVHN
In contrast to the MNIST dataset, images in SVHN are colored. We do not use any preprocessing in this
dataset.
Encoder:
x∈R3×32×32→Conv 64 →BN→ReLu
→Conv 128 →BN→ReLu
→Conv 256 →BN→ReLu
→FC100→FC20
19Under review as submission to TMLR
Decoder:
y∈R20→FC100→ConvT 256 →BN→ReLu
→ConvT 128 →BN→ReLu
→ConvT 64 →BN→ReLu
→ConvT 32 →BN→ReLu
→FC1
Notations are the same as described above.
CelebA
In contrast to the MNIST dataset, images in CelebA are colored. Further, we ﬁrst took central crops of
140×140 and resize the images to a resolution 64 ×64.
Encoder:
x∈R3×64×64→Conv 64 →BN→LeakyReLu
→Conv 128 →BN→LeakyReLu
→Conv 256 →BN→LeakyReLu
→Conv 512 →BN→LeakyReLu
→FC100→FC100
Decoder:
y∈R100→FC100→Conv 512 →BN→ReLu
→ConvT 256 →BN→ReLu
→ConvT 128 →BN→ReLu
→ConvT 64 →BN→ReLu
→ConvT 32 →BN→ReLu
→FC1
LeakyReLU uses a negative slope of 0.2, and padding was set to 0 for the last convolutional layer of the
encoder and the ﬁrst of the decoder. All other notations are the same as described above.
D.3 Implementation of Real NVP
In our study, we used a Real NVP (see Dinh et al. 2017) to model the latent space of the autoencoder and
serve as a benchmark. For all data sets, we use spatial checkerboard masking, where the mask has a value of
1 if the sum of coordinates is odd, and 0 otherwise. For the MNIST data set, we use 4 coupling layers with 2
hidden layers each and 256 features per hidden layer. Similarly, for the SVHN data set, we also use four
coupling layers with two hidden layers each and 256 hidden layer features. Lastly, for the CelebA data set,
we use four coupling layers with two hidden layers each and 1024 hidden layer features. For all data sets, we
applied a learning rate of 0.0001 and learn for 2000 epochs.
E Image Interpolation of the Autoencoder
We show that our used autoencoder learned a relevant and smooth representation of the data by interpolation
in the latent space and, thus, modeling the latent space for generating new images is reasonable. For example,
consider two images A and B with latent variables yA,1,...,xA,100andyB,1,...,yB,100. We now interpolate
linearly in each dimension between these two values and feed the resulting interpolation to the decoder to get
20Under review as submission to TMLR
Figure 8: Interpolation in the latent space of samples of the autoencoder.
the interpolated images. Each row in Figure 8 shows a clear linear progression in ten steps from the ﬁrst face
on the left to the ﬁnal face on the right. For example, in the last row, we see a female with blonde hair slowly
transforming into a male with a beard. The transition is smooth, and no sharp changes or random images
occur in-between.
21Under review as submission to TMLR
F Additional Experiments
F.1 Numerical Assessment of Methods on CelebA
Figure 9: Performance metrics of generative models on CelebA , reported over latent space sample size. Note
that they only diﬀer in the latent space sampling and share the same autoencoder.
22Under review as submission to TMLR
F.2 Numerical Assessment of Methods on MNIST
Figure 10: Performance metrics of generative models on MNIST , reported over epochs computed from 2000
random samples. Note that they only diﬀer in the latent space sampling and share the same autoencoder.
Figure 11: Performance metrics of generative models on MNIST , reported over latent space sample size.
Note that they only diﬀer in the latent space sampling and share the same autoencoder.
23Under review as submission to TMLR
F.3 Numerical Assessment of Methods on SVHN
Figure 12: Performance metrics of generative models on SVHN, reported over epochs computed from 2000
random samples. Note that they only diﬀer in the latent space sampling and share the same autoencoder.
Figure 13: Performance metrics of generative models on SVHN, reported over latent space sample size. Note
that they only diﬀer in the latent space sampling and share the same autoencoder.
24Under review as submission to TMLR
F.4 Generated Images from SVHN
Figure 14: Comparison of synthetic samples of diﬀerent Autoencoder models. 1strow:Fitted normal
distribution, 2ndrow:Independent margins, 3rdrow:KDE-AE, 4throw:GMM, 5throw:VCAE, 6th
row:EBCAE, 7throw:VAE, 8throw:Real NVP, Last row: original pictures.
G Code
Code will be provided here. [link to the repository will be inserted]
25