Under review as submission to TMLR
Compressive Recovery of Signals Defined on Perturbed
Graphs
Anonymous authors
Paper under double-blind review
Abstract
Recovery of signals with elements defined on the nodes of a graph, from compressive mea-
surements is an important problem, which can arise in various domains such as sensor
networks, image reconstruction and group testing. In some scenarios, the graph may not
be accurately known, and there may exist a few edge additions or deletions relative to a
ground truth graph. Such perturbations, even if small in number, significantly affect the
Graph Fourier Transform (GFT). This impedes recovery of signals which may have sparse
representations in the GFT bases of the ground truth graph. We present an algorithm
which simultaneously recovers the signal from the compressive measurements and also cor-
rects the graph perturbations. We analyze some important theoretical properties of the
algorithm. Our approach to correction for graph perturbations is based on model selection
techniques such as cross-validation in compressed sensing. We validate our algorithm on sig-
nals which have a sparse representation in the GFT bases of many commonly used graphs in
the network science literature. An application to compressive image reconstruction is also
presented, where graph perturbations are modeled as undesirable graph edges linking pixels
with significant intensity difference. In all experiments, our algorithm clearly outperforms
baseline techniques which either ignore the perturbations or use first order approximations
to the perturbations in the GFT bases.
1 Introduction
Efficient acquisition of data arranged on the nodes of a graph (i.e. a graph signal) may be performed via
the technique of Compressed Sensing (CS) Candes & Wakin (2008). Instead of recording the data at each
node of the graph separately, a small number of random linear measurements of the graph signal may be
acquired in a domain-specific manner. CS techniques allow accurate recovery of a high-dimensional vector
from a small number of linear measurements, given sufficient conditions such as sparsity/compressibility of
the signal representation in a known orthonormal basis, and measurement matrix characteristics such as the
restricted isometry property (RIP) Candes & Wakin (2008). In some applications, graph signals defined on
the nodes of an undirected, unweighted graph, possess a sparse representation in terms of the eigenvectors
of the Laplacian matrix of the graph, which are also known as a Graph Fourier Transform (GFT) basis for
such graphs in the Graph Signal Processing (GSP) literature Ortega et al. (2018). Given the sparsity of
this representation, such graph signals may be recovered from the compressive linear measurements using
CS decoding algorithms. Compressive graph signal measurements naturally arise in sensor networks Zhu &
Rabbat (2012), group testing with side information such as contact tracing graphs Goenka et al. (2021), or
in image acquisition if the image is regarded as a graph.
In this work, we consider the case when a graph signal has been compressively acquired, but there is some
uncertainty in the knowledge of the graph on which the signal was defined. A nominal graph is known,
which has the same nodes as the actual(unknown) graph, but has a small number of edge perturbations
(edge additions and/or deletions) relative to the actual graph. Due to this, significant uncertainty is induced
in the GFT basis of the graph, since the perturbation of a few edges of the graph will perturb its Laplacian
matrix, and correspondingly its eigenvectors. Hence the graph signal will not be recovered accurately by
a CS decoding algorithm if the GFT basis of the nominal graph is used, and some alternative approach is
1Under review as submission to TMLR
needed for recovery of the graph signal. In some applications, it may be desirable to recover the actual graph
as well. We refer to the problem of recovery of the actual graph and the graph signal from compressive
measurements as the Compressive Perturbed Graph Recovery (CPGR) problem.
We present a method called Greedy Edge Selection ( Ges), which solves this problem by refining the nominal
graph one edge at a time, based on the cross-validation (CV) errors of the signals recovered using these
graphs on a held-out set of measurements. The algorithm keeps proceeding as long as the CV errors of the
successive graphs keep decreasing. Finally, the algorithm outputs the refined graph and the graph signal
defined using the GFT basis of the refined graph. To summarize, our main contributions in this work are:
1. We present the novel (to our best knowledge) problem of Compressive Perturbed Graph Recovery
(CPGR), in which there is uncertainty in the orthonormal basis used for CS recovery, due to edge
perturbations in the underlying graph.
2. We present the Greedy Edge Selection ( Ges) method (Sec. 3.2) for solving the CPGR problem,
using an approach based on CV errors.
3. Weframetheproblemofedge-awarerecoveryofpatch-wisecompressivelyacquiredimages(suchasin
Kulkarni et al. (2016)) as a CPGR problem. As an extension of Gesto this special case, we propose
Inferred Linear-Edge Compressive Image Recovery ( Ilecir, Sec. 4), an algorithm which recovers
images simultaneously with linear image edges in the patches of the image via structured/coupled
perturbation of the edges of a 2D lattice graph (unlike unstructured edge perturbations performed
inGes).
4. Using CV theory for compressed sensing Zhang et al. (2014), we prove high-probability signal and
graph recovery guarantees for a brute-force version of our algorithms (called ‘Brute Force Graph
Selection’ or Bfgs). We also provide similar guarantees for solution improvement at each step of
Ges, and also in the Ileciralgorithm.
5. We empirically validate the Gesalgorithm on signals on a variety of graphs commonly used in the
NetworkScienceliteraturenet(2024). Wealsoperformsimulationsoninterpolationofsignalsdefined
on perturbed graphs. Likewise, we validate the Ileciralgorithm on 40images of various kinds –
natural images, synthetically generated piece-wise smooth images, cartoon images, and depth-maps
of indoor scenes (Sec. 5). Our algorithms outperform the baseline method of using the GFT basis
of the nominal graph or the GFT basis produced by first-order perturbations, in a standard CS
decoding algorithm.
1.1 Applications of CPGR
The CPGR problem is motivated by the following applications (see also Sec. 2 after equation 1):
1.Compressive Image Recovery: 2D Images can be regarded as signals defined on the nodes of
a grid graph. The 2D DCT is one of the possible GFT bases for such a graph. However, GSP
principles allow this to be generalized to compressive reconstruction of images defined on any other
type of pixel grid, such as hexagonal Middleton & Sivaswamy (2005), or on the vertices of a 3D mesh
Lalos et al. (2016), for which the 2D DCT is no longer the appropriate GFT basis. In all such cases,
the nominal graph is regarded as the perturbed version of the actual graph which allows sparser
image representation. The graph edges (in the nominal graph) to be dropped correspond to edges
between graph nodes that lie on two different sides of an image edge or object-object boundary. See
Sec. 4 for more details.
2.Graph Signal Interpolation: A second motivating example is the case where the data values at
only a subset of mout ofngraph nodes ( m<n) are available, and the remaining are missing and
need to be inferred. This situation comes up in mass testing in a pandemic, where it is impossible
to test each person, and contact tracing information is useful for inferring the health status of
individuals who have not been tested. In this case, note that the sensing matrix is a randomly
2Under review as submission to TMLR
chosen row-subset of the identity matrix (depending on the particular nodes for which signal values
were observed). Each person (or a group of individuals such as a family) is regarded as a node
of the CT graph. The infection status at the node is the signal value, and CT graph edges are
created between different persons who are in contact with each other or between different groups of
people which regularly intermingle. If we assume a diffusion model for the spread of the infection
levels across people who come in contact, we can model the vector of infection levels as being sparse
or compressible in the GFT of the CT graph. But CT graphs are known to contain errors due
to various limitations of Bluetooth or other modalities for acquiring CT information Kleinman &
Merkel (2020). See Sec. 5.1 under ‘Signal Interpolation on Perturbed Graphs’ for more details.
3.Pooled Testing using Contact Tracing Graphs: Consider the case of pooled testing in a
pandemic situation Ghosh et al. (2021), using CT graphs Goenka et al. (2021). Pooled testing
involves replacing individual tests on ndifferent individuals by tests on m≪npools, where each
pool is creating by mixing small, fixed-volume portions of the samples of a subset (containing r<n
individuals) of the nindividuals. The participation of the different individuals in different pools is
encoded by a binary ‘pooling matrix’. The aim is to infer the infection levels of the nindividuals
given knowledge of the pooling matrix and the results on the mpools. This can be framed as a CS
problem as in Ghosh et al. (2021). Successful estimation of infection levels requires the n-element
vector of individual infection levels to be sparse, and also requires the pooling matrix to obey certain
properties Ghosh et al. (2021). However additional information is available in CT graphs, which can
be used to improve the inference for the same m, assuming a diffusion model for infection spread.
But CT graphs can contain errors as mentioned previously, and hence this is another important
application of our theory.
Organization of the paper: The remainder of this paper is organised as follows: Sec. 2 defines the CPGR
problem formally and gives an overview of the literature tackling similar problems. Sec. 3 and 4 describe
the methods presented in this paper in detail. Several numerical results for our methods are presented in
Sec. 5. Finally, conclusions and future work are discussed in Sec. 6. A glossary containing various symbols
(variables and algorithm names) used in the main paper is presented in Table S.V of the supplemental
material.
2 Problem Statement
Consider that we are given linear, and possibly noisy, compressive measurements y∈Rmof an unknown
graph signal defined on the vertices of an undirected, unweighted graph Gactual := (V,Eactual )where the set
of the nodes is denoted by V≜{1,...,n}(and thus|V|=n), and the set of edges is denoted by Eactual.
The graph signal is given by a vector x∗∈Rnwith each entry representing the value on the corresponding
graph node. Hence we have
y=Φx∗+η, (1)
where Φis am×n‘measurement/sensing matrix’ with m≪n(since we are in the compressive regime),
andηis a noise vector, each of whose entries is assumed to be i.i.d. Gaussian with mean 0and variance
σ2. In our setting, the graph Gactualis not known with full accuracy. Instead, we have access to the graph
Gnominal = (V,Enominal ), which has the same nodes as Gactual, but the set of edges Enominalcontains a few
edge perturbations (additions or deletions) relative to Eactual. We now give a few examples of actual and
nominal graphs in practical applications, referring to Sec. 1.1. In compressive image recovery, the nominal
graph is the grid graph in which each node is a pixel and is connected by graph edges to its four neighbors,
whereas the actual (unknown) graph is the one in which certain graph edges (corresponding to image edges)
are dropped. In graph signal interpolation or pooled testing, the nominal graph is the available CT graph
obtained via Bluetooth, whereas the actual graph is the CT graph in which each graph edge represents an
actual contact between two individuals (irrespective of whether or not it was recorded by Bluetooth).
We assume that an upper bound d0on the number of perturbations is known, i.e. |Eactual−Enominal|+
|Enominal−Eactual|≤d0. For any undirected graph with adjacency matrix W, its Laplacian matrix is given
byL=D−W, whereDis the diagonal matrix whose ithdiagonal entry contains the degree of the ithnode.
3Under review as submission to TMLR
For simplicity, we assume unweighted graphs. For undirected graphs, the Laplacian matrix is positive semi-
definite and has real-valued eigenvectors and eigenvalues. Let Lactualbe the (unknown) Laplacian matrix
ofGactual, and letLactual =VactualΛactualVT
actualbe its eigen-decomposition. From the GSP literature, we
know that the eigenvectors Vactualform a GFT basis, with each eigenvector having an associated ‘frequency’
– the eigenvalue – which is a measure of its variation across the neighbouring nodes of the graph Gactual
(Ortega et al., 2018, Sec. II.E). We assume that x∗issparse-spectrum , i.e. its GFT (Ortega et al., 2018,
Eqn. 14) given by θ∗=VT
actualx∗has very few non-zero entries. We also assume that GnominalandGactual
have distinct eigenvalues. The case of repeated eigenvalues is discussed later in this section. The goal is
to recover the original signal x∗, as well as the actual graph Gactualgiven justy,ΦandGnominal. This is
formally defined as follows: [Compressive Perturbed Graph Recovery (CPGR) Problem] Given y,Φ,Enominal
andd0, findx∗andEactual. To our best knowledge, this is a novel computational problem, and has not been
explored in the literature. While we are mainly concerned with sparse-spectrum signals as defined earlier,
the model of band-limited signals – a subset of sparse-spectrum signals – has been widely considered in the
literature (albeit not in conjunction with incorrectly defined graphs) Zhu & Rabbat (2012); Ortega et al.
(2018). In the band-limited model, the signals are linear combinations of the first seigenvectors with the
smallest frequencies, with sbeing the band limit. In the following section, we present a literature review of
closely related work.
2.1 Related Work
Graph Spectral Compressed Sensing: Recovery of graph signals from compressive measurements while
making use of the graph structure via their GFT is sometimes called graph spectral compressed sensing Zhu
& Rabbat (2012); Jung et al. (2018). While these and other works in GSP (e.g. see references in Ortega
et al. (2018)) focus on band-limited signals, we mainly focus on the recovery of sparse-spectrum signals, i.e.
signals with arbitrary sparse support in the GFT domain. In Zhu & Rabbat (2012); Jung et al. (2018); Zou
et al. (2020), the measurements are the values of the graph signals on a subset of the nodes, and the purpose
of compressive recovery is to interpolate the missing data at other nodes. Our work focuses on compressive
measurements which are random linear combinations of the values at the different nodes, more in line with
traditional CS or group testing Goenka et al. (2021), although we also consider graph signal interpolation.
More importantly, we consider perturbed graphs.
Signals over Graphs with Partly Erroneous Topology: Our work is different as compared to a
large body of work in graph learning ( eg, Segarra et al. (2017) or the references in Dong et al. (2019)),
which typically assumes noknowledge of the graph, but an availability of many graph signals defined over
the nodes. Instead, we assume that the graph is known up to a few edge perturbations, and that only
a single graph signal is indirectly observed via compressive measurements. The approach of correcting
a small number of edges has been followed in a small number of papers, albeit in the non-compressive
regime given a single signal vector – Ceci & Barbarossa (2020); Ceci et al. (2020). The work in Ceci &
Barbarossa (2020) gives an approximate formula to compute eigenvectors of a perturbed graph from those
of the original graph, and uses it in a brute-force algorithm which performs corrections to a graph topology
given a band-limited graph signal with known band limit. A total least squares approach to robust graph
signal recovery given structural equation models is presented in Ceci et al. (2020). The work in Miettinen
et al. (2021) develops models for perturbations to edges in a graph and examines their effect on graph signal
filtering and independent components analysis. As opposed to this, in our work, we present a method for
robust graph signal recovery from compressive measurements given a small number of perturbations in the
graph topology, and assuming the signal has a sparse, but not necessarily band-limited, representation in
the underlying GFT basis. The work in Mahmood et al. (2018) performs joint recovery of an undirected,
weighted, data-dependent graph with nodes representing overlapping patches of a 2-D image along with the
image itself (i.e.,the graph signal) from compressive measurements. This is done by alternately re-computing
the graph from the image, and then invoking graph total variation (GTV) and wavelet-sparsity prior for
tomographic reconstruction. We note that their method is not applicable to our setting, where the graph
is unweighted, and not data-dependent - i.e., it cannot be computed directly from the graph signal. Also,
our technique focuses on recovery of a small number graph perturbations and not the full graph, and is not
restricted to just graphs associated with images. In our setting, the signal is a linear combination of a small
number of arbitrary GFT basis vectors, and hence the signals need not be smooth over the graph, whereas in
4Under review as submission to TMLR
Mahmood et al. (2018), the GTV prior assumes piece-wise smoothness of the graph signal. Unlike Mahmood
et al. (2018), we also provide sufficient conditions for successful signal and graph recovery using one of our
methods in Sec. 3.3.
Compressed Sensing with Perturbed Models: We now give an overview of techniques in general CS
that deal with model mismatches. Referring to Eqn. 1, we could have perturbations in either the sensing
matrix Φor the representation matrix Ψor both. The former problem has been explored in terms of
perturbations to specified Fourier frequencies in Fourier sensing matrices in magnetic resonance imaging in
work such as Pandotra et al. (2019); Ianni & Grissom (2016). More unstructured and dense perturbations
toΦare considered in Zhu et al. (2011); Parker et al. (2011); Fosson et al. (2020). The focus of the work in
this paper, however, is related to perturbations in Ψ, because perturbations to the graph topology induces
changes in the GFT matrix, which is the signal representation matrix (and not the sensing matrix which is
completely independent). The problem of perturbations in Ψhas been extensively explored in the context
of off-the-grid signal representation in sinusoidal bases such as the Fourier or discrete cosine transform in
Chi et al. (2011); Nichols et al. (2014); Tan et al. (2014), using approaches such as alternating minimization
Nichols et al. (2014), modified greedy algorithms like orthogonal matching pursuit (OMP) Teke et al. (2013),
or structured sparsity Zhu et al. (2011); Tan et al. (2014). Applications to problems such as direction of
arrival estimation have been explored. In contrast to this, we explore perturbations in the representation
matrix in an indirectmanner. That is, we explore methods to correct for perturbations in edge specifications
in the adjacency matrix within our optimization framework. Given changes to the adjacency matrix, the
Laplacianmatrixanditseigenvectorsarerecomputed. WealsonotethatsmallperturbationsintheLaplacian
matrix may lead to large perturbations of some of its eigenvectors – especially in those with high frequency.
Hence the methods which make the assumption of small perturbation in ΨZhu et al. (2011) are not directly
applicable to the problem considered in our work.
3 Method
3.1 Recovery using standard CS decoding algorithms
It is well known that a signal x∗acquired compressively as in Eqn. 1 and sparse in some known orthonormal
basis Ψmay be recovered via Lasso(Least Absolute Shrinkage and Selection Operator) Hastie et al. (2015)
as:
Lasso: ˆxlasso= arg min
x∥y−Φx∥2
2+µ∥ΨTx∥1, (2)
whereµ > 0is a regularization parameter. Suitable choices of matrix Φ, such as those whose entries are
drawn independently from a zero-mean Gaussian, satisfy with high probability the Restricted Eigenvalue
Condition (Hastie et al., 2015, Sec. 11.2.2) if m=O(slogn)or other similar properties sufficient for recovery
ofx∗using Lasso(Hastie et al., 2015, Thm. 11.1) or other CS decoding algorithms. The regularization
parameterµis typically chosen via cross-validation (CV) Zhang et al. (2014), by holding out some mcv<m
measurements, performing recovery using only the remaining mr=m−mcvmeasurements, and choosing the
value ofµfor which the CV error ϵµ
cv(defined below) is minimized. As shown in (Zhang et al., 2014, Thm.
1), the CV error acts as a data-driven proxy for the (unobservable) mean-squared error. This estimator is
represented as shown below:
CVE(y,Φ,Ψ,mcv,µ) :ˆxµ
r=argmin
x∥yr−Φrx∥2
2+µ∥ΨTx∥1,
ϵµ
cv=∥ycv−Φcvˆxµ
r∥2
2, (3)
Lasso-Cv(y,Φ,Ψ,Γ,mcv) : ˆµ= arg min
µ∈Γϵµ
cv,
ˆxlasso-cv =argmin
x∥y−Φx∥2
2+ ˆµ∥ΨTx∥1. (4)
Here CVEis the CV error computation routine, and Lasso-Cv isLassowith cross-validation. Also, ycv
andΦcvare the held out measurements and the corresponding rows of Φ, andyrandΦrare the remaining
measurements or rows used for signal recovery. Furthermore, ˆxµ
ris the signal recovered using the parameter
5Under review as submission to TMLR
valueµ,ϵµ
cvis the cross-validation error of ˆxµ
r,Γis the set of possible values of µwhich are tried, ˆµis
the value of µ∈Γwhich gives the smallest CV error, and ˆxlasso-cvis the final estimate of x∗output by
Lasso-Cv . Note that the cross-validation approach does notrequire knowledge of the underlying signal, or
knowledge of the underlying actual graph or its eigenvectors, in any manner.
Henceanestimateof x∗couldberecoveredvia Lasso(Eqn.2)or Lasso-Cv (Eqn.4)byputting Ψ=Vactual,
with recovery guarantees from compressed sensing theory. A naive method of estimating x∗whenEactualis
not known is to use the GFT matrix of the nominal graph, Vnominalas the orthonormal basis ΨinLasso
orLasso-Cv from Eqn. 4. Thus we have the following estimates:
ˆxactual =Lasso-Cv (y,Φ,Vactual,Γ,mcv), (5)
ˆxnominal =Lasso-Cv (y,Φ,Vnominal,Γ,mcv). (6)
We refer to the technique of using the GFT basis in LassoasGft-Lasso . If the actual graph is used, we
call it Agft-Lasso , and if the nominal graph is used, it is called Ngft-Lasso . If cross-validation is used to
determinethevalueoftheparameter µ, thenthesetechniquesaretermed Gft-Lasso-Cv ,Agft-Lasso-Cv ,
andNgft-Lasso-Cv , respectively.
Since the set of edges Enominaldiffers slightly from Eactual, the GFT matrix of the nominal graph, Vnominalwill
be a perturbed version of the actual GFT matrix Vactual. Indeed,x∗may not even be sparse in Vnominalif the
perturbation is significant. In the following subsections, we present methods which use the CV error of Gft-
Lasso-Cv to select from potential refinements of the nominal graph. Note that even small perturbations to
the adjacency matrix can lead to large differences between VactualandVnominal, and so we cannot exploit
any sparsity property of Vactual−Vnominalfor derivingVactual.
3.2 Greedy Edge Selection
We present the Greedy Edge Selection ( Ges) algorithm (Alg. 1) to solve the CPGR problem. The main
idea is to keep refining the edges of a candidate graph – initialized with the edges of the nominal graph – by
perturbing one edge at a time, as long as the cross-validation error of the retrieved signal on a held-out set
of measurements keeps decreasing. The hope is that each greedy refinement of the candidate graph brings
it closer to the actual graph, such that eventually the actual graph as well as the original graph signal are
recovered. The algorithm performs at most d0greedy refinement steps where d0is an upper bound on the
number of edge perturbations. The edges of the candidate graph after greedy refinement step tare referred
to asE(t)
candidate, withE(0)
candidate =Enominal. In the greedy step tof the algorithm, all graphs which can be
obtained by adding or removing one edge to or from the edge set of the candidate graph E(t−1)
candidate (except
those which have already been perturbed in greedy steps 1,..., (t−1)) are considered. There are/parenleftbign
2/parenrightbig
−(t−1)
such graphs. GFT matrices of each of these graphs are computed via eigendecomposition of their Laplacian
matrices. Gft-Lasso-Cv (Sec. 3.1) is performed to find the smallest CV error and the ideal value of µusing
each GFT matrix. The edge e(t)
bestwhich gives the smallest value for CV error is chosen and the candidate
graph is updated, provided the CV error decreases by more than a factor τ∈(0,1]relative to the CV error
for the current candidate graph. Otherwise, the algorithm stops, and an estimate of the signal is returned
by performing Lassousing the GFT matrix and µobtained fromE(t−1)
candidate.
Noise-based stopping criterion: From Eqn. 3 and Eqn. 1, we see that the CV error for the ground truth
signalx∗is a sum of squares of mcvi.i.d. Gaussian random variables with mean 0and variance σ2, and thus
has mean equal to mcvσ2and standard deviation√2mcvσ2. Hence, before a greedy step begins, the Ges
algorithm checks whether the CV error is within a high confidence interval of mcvσ2and stops if that is the
case, in order to prevent fitting to the measurement noise.
Brute-forcealgorithm: A brute-forceversion of Ges(referred toas Brute-Force GraphSelection or Bfgs)
is also possible, wherein all graphs which are at most d0perturbations from Gnominalare considered, signals
are recovered using their GFT matrices on mrmeasurements, and the graph which gives the minimum CV
error on the remaining mcvmeasurements is chosen for final signal recovery. As there are/parenleftbign
2/parenrightbig
possible edges,
the total number of graphs enumerated via brute-force is/parenleftbig(n
2)
0/parenrightbig
+/parenleftbig(n
2)
1/parenrightbig
+···+/parenleftbig(n
2)
d0/parenrightbig
=O(n2d0).
6Under review as submission to TMLR
Algorithm 1 Greedy Edge Selection ( Ges)
Input:y: Compressive measurements, Φ: measurement matrix, Enominal: nominal graph edge set, σ2:
variance of measurement noise, Γ: values of µfor grid search, τ∈(0,1]: CV error improvement factor,
mcv: Number of CV measurements, d0: maximum number of edge perturbations, g: CV error confidence
interval factor
Output: Estimated graph signal ˆxgreedy
1:Initialize:E(0)
candidate←E nominal,V(0)←Vnominal,{ϵ(0)
cv,µ(0)}←{ min,argmin
µ∈Γ}CVE(V(0),µ|y,Φ, mcv),
P(0)=∅, andtest←0
2:fortin1,...,d 0do
3:ifϵ(t−1)
cv≤(mcvσ2+g√2mcvσ2)then
4:break, to prevent fitting on noise
5:foreach possible edge ewhich is not inP(t−1)do
6: Obtain perturbed graph edge set:
E(t)
e←(E(t−1)
candidate−{e})∪({e}−E(t−1)
candidate )
7: Compute Laplacian matrix L(t)
efromE(t)
eand GFT matrix V(t)
evia eigendecomposition of L(t)
e
8: Compute best CV error and µusingV(t)
e:
ϵ(e,t)
cv←min
µ∈ΓCVE(V(t)
e,µ|y,Φ,mcv)
µ(t)
e←argmin
µ∈ΓCVE(V(t)
e,µ|y,Φ,mcv)
9:ifmin
eϵ(e,t)
cv<τϵ(t−1)
cvthen
10: Select edge: e(t)
best←arg min
eϵ(e,t)
cv
11: Perform updates: P(t)←P(t−1)∪{e(t)
best},
ϵ(t)
cv←min
eϵ(e,t)
cv,E(t)
candidate←E(t)
e(t)
best,V(t)←V(t)
e(t)
best,µ(t)←µ(t)
e(t)
best, andtest←t
12:else
13: break; insignificant improvement.
14:Estimate ˆxgreedyviaLassofromy,Φ,V(test), andµ(test)using all the measurements:
ˆxgreedy←arg min
x∈Rn∥y−Φx∥2
2+µ(test)∥V(test)Tx∥1
15:return ˆxgreedy
Running time: The algorithm performs a maximum of d0greedy steps. In each greedy step, Gft-Lasso
is performed for a maximum of/parenleftbign
2/parenrightbig
graphs. Grid search for µis performed over |Γ|values. Hence the total
number of Gft-Lasso optimizations performed is O(|Γ|d0n2), which is a significant improvement over the
O(|Γ|n2d0)Gft-Lasso optimizations performed by Bfgs.
Signal recovery accuracy: While the greedy algorithm is not guaranteed to recover the original graph
and the signal, we find empirically (Sec. 5.1) that the mean error in the recovered signal is much lower than
that using the nominal graph, and in many cases, the original graph is recovered. In Theorem 3.3, we present
conditions under which the solution is guaranteed to improve at any step of the Gesalgorithm.
3.3 Recovery Guarantees and Bounds
LetˆxGdenotethesignalrecoveredusing Gft-Lasso-Cv withtheGFTofgraph G. Wemaketheassumption
that each entry of Φis independently drawn from a sub-Gaussian distribution of mean 0 and variance 1.
We present the following recovery guarantee for the Bfgsalgorithm from Sec. 3.2: [Brute-Force Algorithm
Recovery Guarantee] If in the Bfgsalgorithm in Sec. 3.2, the number of CV measurements mcvobeys
mcv≥4/parenleftig
1 +2c
(c−1)2/parenrightig/braceleftig
ln|Γ|+ ln (d0+ 1) + 2d0lnn+ ln1
δ/bracerightig
(7)
7Under review as submission to TMLR
for arbitrary constants c∈(1,∞)andδ∈(0,1), then its recovery error is bounded as
∥ˆxbf−x∗∥2
2< c∥ˆxactual−x∗∥2
2+ (c−1)σ2(8)
with probability more than 1−δ. As a consequence, if
∥ˆxG−x∗∥2
2≥c∥ˆxactual−x∗∥2
2+ (c−1)σ2, (9)
for all graphsG̸=Gactualwhich are upto d0edge perturbations from Gnominal, then with probability more
than 1−δ,ˆxbf=ˆxactual, and the actual graph is recovered. The proof is provided in the supplemental
material (Sec. ??). It is based on a theorem from Zhang et al. (2014) regarding how well the CV error
predicts the recovery error for compressed sensing with Gaussian random matrices1. We use this theorem
and the union bound to lower bound the probability that the CV error of the signal recovered using Gft-
Lasso-Cv with the actual graph is lower than the CV errors for all signals having a recovery error satisfying
the condition in Eqn. 9.
Discussion on Theorem 3.3:
1. Given compressive measurements for signals defined on an incorrectly defined graph, it is not a
prioriclear whether the problem of signal recovery and graph recovery are solvable at all. The
main contribution of Theorem 3.3 is to outline conditions where successful recovery of the signal
is possible (Eqns. 7 and 8), and where successful recovery of the graph is possible (Eqn. 9). The
result shows that the number of additional measurements needed for cross-validation depends scales
asO(d0logn). Therefore mcv≪nfor appropriate choices of the other parameters, and signal and
graph recovery from compressive measurements is possible under appropriate conditions without too
many additional measurements.
2. There is a tradeoff between the number of CV measurements used and the quality of recovery,
encapsulated by the parameter c. Ifcis close to 1, the recovery error is close to or equal to that
achieved using Gft-Lasso-Cv on the actual graph. However in such a case, mcvwill be large. On
the other hand, a large value of cwill allow for a smaller value of mcv– however in that case, the
recovered signal may have error higher than if the actual graph was known. In practice, our method
attains significant reduction in signal error compared to the baseline method of using the GFT of
the nominal graph (Sec. 5.1).
3. Dependence of the bound on d0in Eqn. 7 shows that the method works well if the nominal graph
and the actual graph are only a few perturbations away from each other. In particular, if a nominal
graph were not known at all, then the brute-force algorithm must enumerate all graphs, making
d0=/parenleftbign
2/parenrightbig
. In this case, mcv= Ω(n2lnn), and we are no longer in the regime of CS.
4. The upper bound on ∥ˆxactual−x∗∥2
2scales asO(slog(n)/m)(Hastie et al., 2015, Thm. 11.1,
Eqn. 11.15) where the sparsity level s:=∥VT
actualx∗∥0. For successful compressive recovery, we
typically require O(slogn)measurements. Thus as sincreases, the upper bound on ∥ˆxactual−x∗∥2
2
and the number of measurements needed for successful recovery, both increase. As ∥ˆxbf−x∗∥2
2is
upper bounded by ∥ˆxactual−x∗∥2
2, the former is also indirectly affected by s.
5. The dependence of the bound in Eqn. 7 on |Γ|seems to be an artifact of our proof technique. Our
proof does not exploit the fact that there may be many ‘bad’ graphs in the search space, for which
the recovery error (and the CV error) will be high regardless of the value of µ∈Γused. Instead, the
proof proceeds by assuming that the CV errors for a ‘bad’ graph with different values of µare not
correlated, leading to an overestimation of the bound for mcv. Perhaps some other proof technique
might be used which removes or weakens the dependence of the bound on |Γ|.
1The theorems in Zhang et al. (2014) can however be easily extended to handle any sub-Gaussian matrix by using an
appropriate formula for the variance of the particular sub-Gaussian distribution used in Eqn. 50 in Zhang et al. (2014), which
will reflect accordingly in the bounds in Theorem 3.3.
8Under review as submission to TMLR
6.Remark on Graph Recovery: While the brute-force method is guaranteed to recover the signal
to good accuracy as per Theorem 3.3, we do not know if it always recovers the actual graph, even in
the absence of measurement noise. For example, there might be cases wherein a graph signal has a
sparser or equally-sparse representation in the GFT basis of a graph which is not the actual graph,
which might get chosen by the algorithm. In particular, it is known that the eigenvectors of the
Laplacian matrix of a graph and its complement graph2are the same. In general, an edge perturbs
an eigenvector only if the entries of the eigenvector on the two nodes of the edge are not equal (see
Eqn. 13). The first eigenvector of the graph Laplacian never gets perturbed, since it has the same
value on all nodes. Another example is the case of a graph with more than one connected component,
in which the eigenvectors have non-zero entries in only one component each. Perturbation of an edge
in one component will not affect the eigenvectors which have only zero entries in nodes belonging
to that component. Thus this perturbed edge will not be recoverable if the graph signal was a
linear combination of eigenvectors which only had zero entries in the corresponding component. The
authors do not know if there exist connected graphs which are a small number of perturbations
from each other and share some eigenvectors or have eigenvectors which are the linear combination
of a small number of the eigenvectors of the other graph. Consider another example consisting of
two complete graphs which are joined to each other via a few connecting edges to create a larger
combined graph. Consider a signal created by a linear combination of a few low frequency GFT
basis vectors of the larger graph. The deletion of an edge belonging to one of the smaller complete
graphs will not have much of an effect on the GFT of the perturbed graph. For such perturbations,
the sufficient condition in Eqn. 9 will be violated (because the error ∥x∗−ˆxG∥2for many candidate
graphsGwill be very close to ∥x∗−ˆxactual∥2), even more so under high noise, and hence the actual
graph will not be recoverable. In this way, the structure of Gactualaffects graph recovery even though
it may not affect signal recovery. Interestingly, the signal recovery bound in Eqn. 8 does not depend
on the structure of the graph – it only depends on mcv,σand (indirectly) on s,mr.
7. We have also derived a result analogous to Theorem 1 but using CV errors instead of MSEs. This
result produces a testablecondition for signal and graph recovery. It is presented as Theorem S.5 of
the supplemental.
Analogous to Theorem 3.3, we present a theorem for solution improvement using the greedy Gesmethod
(Algorithm 1). Let ˆx(t)be the estimate by the greedy edge selection algorithm after tsteps, and let ˆx(t)
best
be the estimate with the lowest recovery error amongst the signals recovered at step t.
[Greedy Edge Selection Solution Improvement Guarantee] If in the greedy edge selection algorithm (Algo-
rithm 1) with τ= 1the number of CV measurements mcvobeys
mcv≥4/parenleftig
1 +2c
(c−1)2/parenrightig/braceleftig
ln|Γ|+ lnn(n+ 1)
2+ ln1
δ/bracerightig
(10)
for arbitrary constants c∈(1,∞)andδ∈(0,1), then the recovery error after step tis bounded as
∥ˆx(t)−x∗∥2
2< c∥ˆx(t)
best−x∗∥2
2+ (c−1)σ2(11)
with probability more than 1−δ. As a consequence, if
∥ˆx(t−1)−x∗∥2
2≥c∥ˆx(t)
best−x∗∥2
2+ (c−1)σ2, (12)
then the solution is guaranteed to improve at step twith probability more than 1−δ. The proof for
Theorem 3.3 is similar to that for Theorem 3.3, and is provided in the supplemental material. The main
difference is in the lower bound for mcv, which is due to the different number of perturbed graphs considered
in each algorithm. Theorem 3.3 outlines conditions under which the solution at the end of each iteration of
Geshas a sensibly bounded error, and under which the solution improves from iteration to iteration (where
an iteration consists of perturbing one extra edge over and above the previous iteration). The condition in
2The complement of a graph is a graph in which every edge present in the original graph is absent in the complement graph
and every edge which is absent in the original graph is present in the complement graph.
9Under review as submission to TMLR
the theorem states a requirement of only a logarithmic number of additional compressive measurements for
CV.
Case of Non-distinct eigenvalues: We have so far assumed that the eigenvalues of the Laplacian of the
nominal and actual graphs are distinct. In cases where eigenvalues of the Laplacian are not distinct, there
will be no adverse effect on signal reconstruction if the (randomly generated and sparse) signal support
does not cover eigenvectors associated with eigenvalues having multiplicity greater than one. In case the
signal support does include eigenvectors associated with eigenvalues having multiplicity greater than one,
the compressive reconstruction will still not be affected if the multiplicity is not too much larger than 1. This
is because the effective increase in signal ℓ0norm will be upper bounded by the total eigenvalue multiplicity.
3.4 Alternatives to Eigendecomposition for GFT basis computation
TheGesalgorithm requires computing the eigen-decomposition (step 16 in Alg. 1) of the Laplacian matrix
L(t)
eof the graph obtained by perturbing the candidate edge set E(t−1)
candidatewith edgee, for each possible edge
e, at each time step t. This step may take a long time for large graphs. It may be made more efficient by
using an approximate formula given in Ceci & Barbarossa (2020), to obtain the eigenvectors of L(t)
efrom the
eigenvectors of Lnominal, and the set of perturbations P(t−1)∪{e}, instead of performing eigendecomposition
ofL(t)
e. If an original Laplacian matrix Lis perturbed by a set of edges Pto obtain a perturbed Laplacian
matrix ˜L, and their eigenvectors are v1...vnand˜v1...˜vnrespectively, then from (Ceci & Barbarossa, 2020,
Eqn. 7 and 11) we have the approximation:
˜vk≃vk+/summationdisplay
{i,j}∈Pσi,j(vk(i)−vk(j))n/summationdisplay
l=2
l̸=kvl(i)−vl(j)
λk−λlvl, (13)
whereσi,j= 1for edge addition, and σi,j=−1for edge deletion. The approximation for ˜vkis valid only
under the condition that
λk−1−λk≪/summationdisplay
{i,j}∈Pσi,j(vk(i)−vk(j))2≪λk+1−λk. (14)
We discuss some intuition behind this approximation from Ceci & Barbarossa (2020) and the condition under
which it is valid. First, note that each new edge {i,j}inPintroduces a rank-one perturbation of Lwith
the matrix σi,jai,jaT
i,j, whereai,jis a vector with ai,j(i) = 1,ai,j(j) =−1, and the remaining entries of ai,j
are equal to zero. That is, ˜L=L+∆L, where the perturbing matrix ∆L=/summationtext
{i,j}∈Pσi,jai,jaT
i,j. Note that
aT
i,jvk= (vk(i)−vk(j))and hencevT
k∆Lvk=/summationtext
{i,j}∈Pσi,jvT
kai,jaT
i,jvk=/summationtext
{i,j}∈Pσi,j(vk(i)−vk(j))2. It is
easily verified that if aT
i,jvk= 0(i.e. (vk(i)−vk(j)) = 0) for all the perturbing edges {i,j}∈P, thenvkis
also an eigenvector of ˜L. Recall that the normalized eigenvectors of a matrix Lare the critical points of the
Rayleigh quotient xTLxon the unit sphere xTx= 1, with the eigenvalue being the value of the Rayleigh
quotient at the corresponding eigenvector. Eqn. 14 means that the perturbation of the Rayleigh quotient at
vkmust be much smaller than the difference in values of the Rayleigh quotient at the closest critical points.
In Eqn. 13, the perturbation of vkby edge{i,j}is negligible if|aT
i,jvk|is small. Similarly, if |aT
i,jvl|is small,
then the perturbation of other eigenvectors in the direction of vldue to the edge{i,j}is small. Finally,
a small eigen-gap λk−λk−1orλk+1−λkmeans that the Rayleigh quotient is relatively flat between the
two critical points, and hence the critical point may be changed easily via a perturbation. We evaluate the
suitability of this approximation to our method in Sec. 5.1.
4 Application: Inferred Linear-Edge Compressive Image Recovery
We now present an application of the Compressive Perturbed Graph Recovery framework, in the domain of
compressive image recovery. In this section, we use the term ‘edge’ as an element of a graph connecting a
pair of vertices, and use the term ‘image edge’ to refer to the entity which separates two regions in an image.
10Under review as submission to TMLR
(a)
 (b)
 (c)
 (d)
 (e)
Figure 1: (a) A 5×52-D lattice graph whose nodes represent pixels of a 5×5patch and whose edges represent
connections between a pixels and its four neighbors. This forms the nominal graph for the problem of compressive
image patch recovery. (b) The lattice graph partitioned by an image edge (orange line). The graph edges going
across the image edge are removed (dotted purple lines). Since the image edge is unknown before reconstruction,
the image-edge partitioned graph is the (unknown) actual graph for the problem of recovery of an image patch from
compressive measurements. (c) All 64 2-D DCT basis vectors of an 8×8patch. (d) An 8×8patch with a sharp
edge. (e) Segmentation-aware basis vectors for this patch, obtained by computing the eigenvectors of the Laplacian
matrix of the graph created by dropping the edges of the 8×8lattice graph whose endpoints lie in different segments
of the patch.
TheGesmethod presented in Sec. 3.2 is a generally applicable technique on any graph. However, if the
graph has some well-known structure to it, it may be possible to select the edges for perturbation in a more
structured manner, instead of greedily one at a time. We present such a method for image reconstruction
from compressive measurements taken using a block-based version Kulkarni et al. (2016) of the Rice Single-
Pixel Camera Duarte et al. (2008). That is, for each h×wpatchx∗of an image, compressive measurements
yobtained via a noisy version of Φx∗as in Eqn. 1, are assumed to be available, with Φhaving dimensions
m×nwithn=hwandm≪n, and the task is to reconstruct each patch of the image.
Any 2-D (two-dimensional) grayscale raster image can be considered to be a graph signal, with each pixel
being a node and horizontal and vertical neighbours connected to each other via an edge, with each pixel
node mapped to its value in the image. Such a graph is called a ‘lattice graph’ (Fig. 1(a)). The 2-D Discrete
Cosine Transform (DCT) basis (Fig. 1(c)) is known to form an eigenbasis of the Laplacian matrix of a 2-D
lattice graph (Fracastoro et al., 2016, Proposition 1), and thus is a GFT basis for this graph. Piece-wise
smooth images, depth-maps, and natural images have a sparse or compressible representation in the DCT
basis, because the low-frequency basis vectors in DCT model the correlation between neighbouring pixels
well. This fact is heavily exploited in the well known JPEG standard for image compression. Thus, it is
natural to employ Lasso(Eqn. 2) with the DCT basis in order to reconstruct the image patches.
However, neighbouring pixels on either side of a sharp image-edge will not have correlated values, due to
which DCT-based recovery will not be accurate near an image-edge. In such cases, it may be better to
use some other transform basis whose vectors maintain no correlation in their values across the image edge.
Since the DCT basis is a GFT basis of the 2-D lattice graph, one possible basis is the GFT basis of the graph
obtained by dropping those edges of the 2-D lattice graph which link nodes that are located on two different
sides of an image-edge – see Fig. 1(d) and Fig. 1(e) for an example of such a ‘segmentation-aware’ basis.
We may call this graph the ‘image-edge partitioned graph’ (see Fig. 1(b)) if it is constructed using the true
image edges. However, since the image is acquired compressively, it is not straightforward to know the exact
location of the image-edges, and hence the image-edge partitioned graph is unknown. Hence, the problem of
decoding of the compressively acquired image using the GFT of the unknown image-edge-partitioned graph
while knowing only the 2D lattice graph may be formulated as CPGR, i.e. Problem 2. The 2D lattice graph
is the nominal graph, the image-edge partitioned graph is the actual graph, and the set of pixel values is
the unknown graph signal which is sparse/compressible in the GFT of the actualgraph. In this application,
we may consider the notion that the ‘actual’ graph that we seek to determine, is simply one that yields a
sparser representation for the image patch, thereby allowing possibly better image reconstruction.
11Under review as submission to TMLR
Algorithm 2 Inferred Linear-Edge Compressive Image Recovery ( Ilecir)
Input:y: vector of mmeasurements of an h×wpatch, Φ:m×nmeasurement matrix with n=hw,
VDCT: 2-D DCT basis vectors of an h×wpatch,ϕ: set of linear image-edges connecting boundary pixels
of anh×wpatch,Vh,w: GFT matrices of the partitioned graphs formed by the image-edges in ϕ,σ2:
measurement noise variance, Γ: values ofµfor grid search, mcv: number of CV measurements, τ∈(0,1]:
CV error improvement factor, g: CV error confidence interval factor.
Output: ˆP: estimated image patch of size h×w
1:Compute CV error and µusing DCT:
{ϵDCT
cv,µDCT}←{ min,argmin}
µ∈ΓCVE(VDCT,µ|y,Φ,mcv)
2:ifϵDCT
cv≤(mcvσ2+g√2mcvσ2)i.e. close to noise then
3:Vest←VDCT,µest←µDCT
4:else
5:forEach linear image edge i∈ϕdo
6: Retrieve corresponding GFT matrix Vi∈Vh,w
7: Compute best CV error and µusingi:
{ϵ(i)
cv,µi}←{ min,argmin}
µ∈ΓCVE(Vi,µ|y,Φ,mcv)
8:ifmin
iϵ(i)
cv<τϵDCT
cvthen
9:Vest←Vi,µest←µi
10:Estimate the vectorized patch using LASSO: ˆxilecir←arg min
x∈Rn∥y−Φx∥2
2+µest∥VT
estx∥1
11:Convert ˆxilecirtoh×wpatch ˆP, assuming row-major order
12:return ˆP
Rather than directly applying the Gesalgorithm from Sec. 3.2 to solve this problem, it is better to exploit
the inherent structure in image-edges to drop graph edges in a systematic way. With this in mind, we
present a variant of Gescalled Inferred Linear-Edge Compressive Image Recovery ( Ilecir) in Algorithm 2.
Each image patch is assumed to either contain no image-edge or at most a single linearimage-edge, i.e.,
a straight line with its endpoints at two boundary pixels of the patch. Reconstruction of the patch from
a reconstruction subset of measurements is performed using the GFTs corresponding to each image-edge
partitioned graph as well as DCT, and CV errors on a held-out subset of measurements are computed. The
GFT corresponding to the estimated signal with the lowest cross-validation error is selected, and the final
estimate of the patch is reconstructed using all the measurements. The noise-based stopping criterion from
Sec. 3.2 is employed here.
We now present a theorem (proved in the supplemental material) showing how the Ilecir(Algorithm 2)
solutionimprovesuponthe Dct-basedrecovery( Dct-Lasso-Cv )solution. Let ˆxbest-edgedenotethe(vector-
ized) patch estimate with the lowest recovery error amongst all the patch estimates in the Ileciralgorithm
for a single patch, and let ˆxdctdenote the estimate using Dct-based recovery. Note that ˆxbest-edgeis un-
observable. [ IlecirSolution Improvement Guarantee] If in the Ileciralgorithm (Algorithm 1) with τ= 1
the number of CV measurements mcvobeys
mcv≥4/parenleftig
1 +2c
(c−1)2/parenrightig/braceleftig
ln|Γ|+ ln(|ϕ|+ 1) + ln1
δ/bracerightig
(15)
for arbitrary constants c∈(1,∞)andδ∈(0,1)and whereϕis the set of all possible linear image edges in
anh×wpatch with endpoints at the boundary, then the recovery error is bounded as
∥ˆxilecir−x∗∥2
2< c∥ˆxbest-edge−x∗∥2
2+ (c−1)σ2(16)
with probability more than 1−δ. As a consequence, if
∥ˆxdct−x∗∥2
2≥c∥ˆxbest-edge−x∗∥2
2+ (c−1)σ2, (17)
12Under review as submission to TMLR
then the solution is guaranteed to improve over Dct-Lasso-Cv with probability more than 1−δ. For the
case of compressive image recovery, Ileciris faster than Ges(see Sec. S.V of the supplemental for more
details) and also exploits the continuous/linear nature of the image edges unlike Ges.
5 Empirical Evaluation
We perform an empirical evaluation of our GesandIlecirmethods, the details of which are discussed in
Sec. 5.1 and 5.2 respectively.
5.1 Greedy Edge Selection on synthetic graphs
Experiment Setup: We test Geson the following graphs commonly used in the network science litera-
ture: Planted Partition Model (PPM), Stochastic Block Model (SBM), Erdős–Rényi (ER) Graph, Random
Geometric Graph (RGG), Barabasi-Albert (BA) Graph and Karate Club (KC) graph. All these are random
graph models, other than the KC graph, which is a two-community social network having n= 34nodes.
More details regarding the random graph models can be found in the supplemental material in Sec. ??. The
actual graphs used in our experiments are instantiated with n= 100nodes for the random graph models.
The PPMs have l= 5communities, each of size r= 20, withp= 0.9andq= 0.01(intra-cluster and
inter-cluster edge probabilities, respectively), with the expected number of edges being 895. The SBMs have
l= 5communities with sizes {r1,...,r 5}={5,10,20,25,40}, and the probabilities p,qare set to be the
same as the PPM. The ER Graphs have p=895
4950. The RGGs have r= 0.27. The BA graphs have r= 10.
The graph parameters are chosen so that the expected number of edges of the graphs are roughly equal,
except the SBM, for which the edge probabilities are matched with the PPM.
Nominal graphs are generated by perturbing d∈{1,2,5,10}edges of the actual graph. The set of edges
to be perturbed – known as the perturbation set ω, with|ω|=d– is chosen to be a subset of a prior set
Ωof100“potentially faulty edges” decided at the time of data generation. For each graph, all/parenleftbign
2/parenrightbig
possible
edges are assigned to different categories, and an approximately equal number of edges from each of these
categories are sampled to form Ω. The edge categories are based on presence/absence of an edge in the actual
graph, whether the edge is inter-cluster or intra-cluster for community-structured graphs, and whether the
endpoints of the edge are both low-degree or both high-degree or one low-degree and one high-degree node
for the BA graph. This makes a total of 2categories for ER graphs and RGGs, 4for PPMs, SBMs and KC,
and6for the BA graph.
We generate 10instances of each graph type described above, with 10sparse-spectrum graph signals for
each graph, making it a total of N= 100sparse-spectrum signals for each graph type. The signals are
linear combinations of s= 5(s= 2for KC) eigenvectors (chosen randomly for each signal) of the Laplacian
matrices of the graphs. We use a measurement matrix of size 50×100or17×34, whose entries are
i.i.d.N(0,1). Furthermore, i.i.d. N(0,σ2)noise is added to each measurement, with σ=β∥Φx∗∥1
m, with
β∈{0,0.01,0.02,0.05}. Corresponding to each signal, a nominal graph is generated as described above.
The algorithm Gesis compared with the baseline algorithm NGft-Lasso-Cv (Eqn. 6) and the ideal al-
gorithm AGft-Lasso-CV (Eqn. 5) using the RRMSE (Relative Root Mean-Square Error) metric, defined
asRRMSE (ˆx) =∥ˆx−x∗∥2
∥x∗∥2, where ˆxis the estimated signal, and x∗is the ground-truth signal. The set
Γ :={10−3+6
19t:t∈{0,1,2,..., 19}}(i.e. 20 values between 0.001and1000, evenly spaced in logarithm)
for all algorithms. For Ges, the loss improvement factor is set to τ= 0.99, and the maximum number of
iterations to d0= 2d, for eachd∈{1,2,5,10}. In practice, the algorithm stops much earlier than the max
number of iterations due to the CV error either increasing in an iteration or being close to the noise variance.
This is also evidenced by the fact that the total number of edge perturbations reported by Ges(Table 2,
sum of correctly detected and spuriously reported edge perturbations) is mostly close to dand much smaller
thand0.
TheGesalgorithm is run with the following practical modifications: (1) grid search over Γto estimate
theLassoregularization parameter µis performed only for the candidate graph at the end of a step and
is re-used for the perturbed graphs in the next step in order to speed up the experiments; (2) K-fold (or
13Under review as submission to TMLR
Graph # Edges Perturbed AGft-Lasso-Cv NGft-Lasso-Cv Ges
PPM1
0.00000.1111 0.0003
2 0.2125 0.0156
5 0.3410 0.1618
10 0.4631 0.3856
SBM1
0.00000.0372 0.0001
2 0.0685 0.0009
5 0.1529 0.0273
10 0.2259 0.1277
ERG1
0.00000.0843 0.0000
2 0.1304 0.0024
5 0.2343 0.1082
10 0.3218 0.2634
RGG1
0.00000.0357 0.0000
2 0.0855 0.0000
5 0.1508 0.0248
10 0.2580 0.1589
BAG1
0.00000.0472 0.0000
2 0.1066 0.0003
5 0.1788 0.0246
10 0.2657 0.1772
KCG1
0.00010.0982 0.0001
2 0.1627 0.0197
5 0.2865 0.1379
10 0.4266 0.3390
Table 1: RRMSE of signal recovered from noiseless measurements ( m= 50,n= 100except for KCG where
m= 17,n= 34) via Greedy Edge Selection ( Ges),Lassowith the nominal graph ( Ngft-Lasso-Cv ), and Lasso
with the actual graph ( Agft-Lasso-Cv ), for various number of perturbed edges.
multi-fold) cross-validation (with K= 5) is used instead of single-fold CV to improve accuracy since the
total number of available measurements is small – in K-fold cross-validation, the CV error is computed K
times, each time with a different subset of the mmeasurements, each subset of size ⌊m
K⌋(with reconstruction
done on the remaining m−⌊m
K⌋measurements), and the sum of the KCV errors is returned; and (3) the
prior set of possible faulty edges Ω(of size|Ω|= 100as specified earlier) is provided to the Gesso that
only these edge perturbations are tried, which speeds up the experiments. The latter is justified since in
real-world applications, such prior information may be available. For example, in a CT graph, we could
conclude that two individuals may have come in contact if their phones use the same WiFi access points,
even though Bluetooth-based contact tracing may suggest otherwise (e.g. by being located in the same office
room at a far-enough distance).
Results: The RRMSE of the Greedy Edge Selection ( Ges) algorithm for recovery of sparse-spectrum signals
from noiseless measurements ( σ=β= 0) is presented in Table. 1, for each graph model mentioned earlier,
withd={1,2,5,10}edges perturbed to create the nominal graph. We see that for each graph type, Ges
outperforms the baseline method of recovery using the nominal graph, i.e. Ngft-Lasso . As expected, the
RRMSE increases as the number of perturbations are increased. For one or two edge perturbations, the
RRMSE is close to zero or very small, whereas for upto five perturbations, the RRMSE is at most half of
that obtained using Ngft-Lasso , and often much lower than that. Even for ten edge perturbations, the
RRMSE of Gesis significantly lower than that of Ngft-Lasso .
Table 2 presents the fraction of cases in which Gessuccessfully recovers (i.e. recovers with zeroerror) the
actual graph from the nominal graph. We see that for most graph types, the actual graph is recovered in
close to 100%cases when up to two edges are perturbed. Despite being a greedy algorithm, the actual
14Under review as submission to TMLR
Graph # Edges
PerturbedFrac. Actual Graph
RecoveredMean # Edges
DetectedMean # Spurious
Edges
PPM1 1.00 1.00 0.00
2 0.93 1.89 0.07
5 0.37 2.60 1.58
10 0.00 1.03 3.06
SBM1 0.90 0.90 0.00
2 0.78 1.75 0.05
5 0.43 3.62 1.36
10 0.02 3.47 3.54
ERG1 1.00 1.00 0.00
2 0.98 1.96 0.02
5 0.43 2.93 1.41
10 0.01 1.52 2.99
RGG1 0.98 0.98 0.00
2 0.96 1.96 0.00
5 0.62 3.94 0.95
10 0.03 2.55 3.80
BAG1 0.97 0.97 0.00
2 0.92 1.91 0.02
5 0.52 3.92 1.06
10 0.04 2.78 3.93
KCG1 0.89 0.91 0.14
2 0.66 1.42 1.00
5 0.04 0.94 3.26
10 0.00 0.95 4.19
Table 2: Fraction of actual graphs successfully recovered, mean number of edge perturbations correctly detected,
and mean number of spurious edge perturbations reported by Ges, for various number of perturbed edges on different
graph models ( m= 50,n= 100except for KCG where m= 17,n= 34).
graph gets recovered in a significant fraction of cases even when five edges perturbations were performed.
In some cases the actual graph is recoverable via Geseven if ten edge perturbations were induced. Table 2
also shows the average number of edge perturbations correctly detected by Ges, and the average number
of spurious edge perturbations reported by it. Close to 100%of edge perturbations are correctly detected
for upto two edge perturbations made to the actual graph, and around 50%to80%for most graphs when
five edge perturbations are made. The number of spurious edge perturbations reported by Gesis close to
zero for upto two edge perturbations, and small for five edge perturbations. With ten edge perturbations,
the number of edge perturbations correctly detected drops and the number of spurious edge perturbations
reported increases. But it is worth noting that the problem of edge perturbation recovery from compressive
measurements of a graph signal is quite challenging due to the eigenvectors of the nominal graph being
significantly perturbed for even a small number of edge perturbations. For example, note that even a small
number of edge perturbations (as low as 1-3) can seriously affect signal recovery – see Table 1 for the PPM
graph when 2and5edges are perturbed, where Ngft-Lasso-Cv produces very high errors of 0.21and0.34,
butGesreduces them to 0.016and0.16, respectively. Algorithms such as Gesprovide efficient ways of
signal recovery in compressive settings in the face of adverse conditions brought in by (even a small number
of) edge perturbations. For comparison, the work in Ceci & Barbarossa (2020) considers recovery of upto
four edge perturbations from a known, uncompressed graph signal with Gaussian priors. For analysis of edge
recovery by category (intra- or inter-cluster), see Sec. S.IV of the supplemental material.
The performance of Geswith noisy measurements is shown in Table 3, for the PPM. We find that the
Gesalgorithm performs well even in the presence of noise. Its RRMSE is significantly less than that of
NGft-Lasso-Cv for upto 5edge perturbations, and is comparable to that of AGft-Lasso-Cv when the
15Under review as submission to TMLR
Signal Model Noise Level ( β)# Edges Perturbed AGft-Lasso-Cv NGft-Lasso-Cv Ges
Sparse-
Spectrum0.011
0.01170.1125 0.0082
2 0.2113 0.0145
5 0.3439 0.1772
10 0.4931 0.4355
0.021
0.02230.1192 0.0156
2 0.2137 0.0247
5 0.3457 0.1792
10 0.4940 0.4441
0.051
0.05390.1412 0.0396
2 0.2351 0.0579
5 0.3555 0.2180
10 0.4987 0.4464
Band-
Limited0.011
0.01140.0131 0.0092
2 0.0141 0.0096
5 0.0185 0.0137
10 0.0238 0.0191
0.021
0.02270.0243 0.0179
2 0.0248 0.0191
5 0.0278 0.0233
10 0.0320 0.0266
0.051
0.05600.0559 0.0438
2 0.0551 0.0446
5 0.0586 0.0484
10 0.0598 0.0497
Table 3: Performance of Geswith measurement noise of different levels given by β∈{0.01,0.02,0.05}(m= 50,n=
100).
number of edge perturbations is 1or2. Occasionally, we find that Gesis able to do slightly better than
Agft-Lasso-Cv . We suspect that this is because only 20different values were tried during grid search for
theLassoregularization parameter µ, due to which Gescould find a better graph than the actual graph
for the given values of µfor the purpose of signal recovery. A more fine-grained grid search would lead to
the expected behaviour of AGft-Lasso-Cv performing better than Ges.
Comparison between Bfgs and Ges: In Table 4, we now present comparative performance statistics for
Gesversus Bfgsfor 3 perturbations induced on the KC graph of n= 34nodes with m= 17compressive
measurements. We used an 8-fold CV, 20 values of µused for each graph, and a prior list of 10 possibly faulty
edges provided to the algorithms (to make the brute force search more manageable). In total, we perturbed
3 edges from the set of the faulty edges, and nominal graphs were created by adding inter-cluster edges to
the actual graph. Average RRMSE results were computed for 100 signals. We also report the fraction of
times that graph recovery was successful (all edge perturbations correctly recovered). The last two rows of
Table 4 present additional results for the same settings as above, but for different methods of choosing µ:
(1) For Bfgs, a singleµfor the Lassoestimator was chosen using CV on the nominal graph, and Bfgswas
performed using only that chosen value of µ. (2) For Ges, the value of µwas chosen at the beginning of each
tthiteration using CV with the GFT basis of the current graph, i.e. G(t−1):= (V,E(t−1)), and then used
for all candidate perturbations in the tthiteration. From Table 4, we see the superior performance of Bfgs
overGesfor both settings as expected (albeit for greater computational cost). Both algorithms significantly
lower the RRMSE compared to the baseline of using the nominal graph GFT for recovery ( 0.0196and0.0287
forGesand0.0006and0.0028forBfgs, compared to 0.1874forNgft-Lasso-Cv ).
Case of repeated eigenvalues: On randomly generated PPM graphs, we observed that around 96% of
the eigenvectors had eigenvalues with multiplicity of 1. About 0.8% had a multiplicity of 2, and about 0.7%
had a multiplicity of 3 and the remaining had a multiplicity greater than or equal to 4 (Table 5). All these
16Under review as submission to TMLR
Method RRMSE Frac. Graphs Recovered
Agft-Lasso-Cv 0.0001 -
Ngft-Lasso-Cv 0.1874 0
Ges 0.0196 0.79
Bfgs 0.0006 0.99
Ges,µchosen on current candidate graph 0.0287 0.75
Bfgs,µchosen on nominal graph 0.0028 0.94
Table 4: Comparison of reconstruction performance of GesandBfgson the KC Graph with n= 34nodes and
usingm= 17compressive measurements, given d0= 3inter-cluster edge perturbations. RRMSE results are avg.
over 100 signals.
Graph type Multiplicity % of eigenvectors with this multiplicity
PPM with
100 nodes1 95.998
2 0.790
3 0.696
≥4 2.516
Table 5: Eigenvalue multiplicities for planted partition model graphs with n= 100nodes, computed over 1000
graphs.
percentages were computed across 1000 instances each of different types of synthetic graphs with n= 100
nodes. Two eigenvalues were considered equal if the absolute difference between them was less than or equal
toϵ= 10−8. For the same experiments on the SBM and RGG graphs, very similar results were obtained and
are hence not shown separately – more than 98%and97%of the eigenvectors, respectively, had eigenvalue
multiplicities equal to 1 for these graphs. For the BA and ER graphs, all eigenvectors had a eigenvalue
multiplicity of 1. The good reconstruction results shown in Tables 1 and 2 confirm the hypothesis that signal
reconstruction is not adversely affected if the (randomly generated and sparse) signal support does not cover
eigenvectors associated with eigenvalues having multiplicity greater than one, or if the multiplicity is not
too much larger than 1. Furthermore, we also computed the effective sparsity of the signals in the GFT
bases, i.e. the sum of multiplicities of the eigenvector groups which form the signal support. We observed
empirically that the effective sparsity was equal to the true sparsity (i.e. ℓ0norm of the coefficient vector)
in majority of the test cases, and very rarely greater than the true sparsity by more than 5. Further details
are now included in the supplemental material in Sec. S.VIII.
Using closed-form approximations for eigenvector perturbation: Table 6 shows the RRMSE ob-
tained using the Ges-Ae algorithm, in which the eigenvector perturbation approximation Ceci & Barbarossa
(2020) (Eqn. 13) is used in place of eigendecomposition in Ges(see Sec. 3.4), for compressive recovery of
sparse-spectrum and band-limited signals on PPMs with a few edge perturbations. We find that for both
Signal Model # Edges Perturbed AGft-Lasso-Cv NGft-Lasso-Cv Ges Ges-Ae
Sparse-
Spectrum1
0.00000.1142 0.0000 0.1109
2 0.2175 0.0061 0.2306
5 0.3492 0.1821 0.3335
10 0.5006 0.4368 0.5139
Band-
Limited1
0.00000.0042 0.0001 0.0033
2 0.0059 0.0003 0.0054
5 0.0130 0.0024 0.0135
10 0.0195 0.0104 0.0202
Table 6: Performance of Greedy Edge Selection with approximated eigenvectors ( Ges-Ae) compared to that of
Ges,Agft-Lasso-Cv , and Ngft-Lasso-Cv for sparse-spectrum and bandlimited signals, all with m= 50,n= 100.
sparse-spectrum and band-limited signals, the RRMSE of Ges-Ae is significantly higher than that for Ges,
across a range of edge perturbations. Moreover, the RRMSE of Ges-Ae is close to that obtained with the
17Under review as submission to TMLR
Method dRRMSE Frac. of Graphs Recovered
Agft-Lasso-Cv 10.0292 -
Ngft-Lasso-Cv 10.2126 0
Ges 10.0688 0.83
Agft-Lasso-Cv 20.0292 -
Ngft-Lasso-Cv 20.2956 0
Ges 20.0860 0.74
Agft-Lasso-Cv 50.0292 -
Ngft-Lasso-Cv 50.4719 0
Ges 50.3384 0.22
Agft-Lasso 100.0292 -
Ngft-Lasso 100.5631 0
Ges 100.5403 0.02
Table 7: RRMSE results for signal interpolation over PPM graph perturbed by dedges, for signals with a sparse
representation in the actual GFT, using Gesalgorithm.
nominal graph, and sometimes slightly worse. Hence we do not find the eigenvector perturbation approxima-
tion (a first order approximation) to be useful when applied to greedy edge selection with cross-validation.
Perhaps a better approximation with higher order terms in it might be more useful. A major reason for the
performance of Ges-Ae could be that the condition under which the approximation is applicable – given by
Eqn. 14 – gets violated often. We deem the condition to be violated for an edge {i,j}and thektheigenvector
vkif(vk(i)−vk(j))2>4(λk+1−λk))for edge addition or (vk(i)−vk(j))2>4(λk−λk−1)in case of edge
deletion. In our experiments, the fraction of times this condition was violated for at least one eigenvector out
of the first five (i.e. the band-limited eigenvectors) for a PPM graph with n= 100,l= 5,p= 0.9,q= 0.01
was87.7%, if an inter-cluster edge is perturbed. Similarly, we found that the condition in Eqn. 14 was
violated 74.7%of the times for at least one eigenvector out of five for a random choice of five eigenvectors
and any kind of edge. While this condition does not get violated for intra-cluster edges in the band-limited
case, the amount of perturbation in the low-frequency eigenvectors by such edges is very small, such that the
RRMSE for these cases is close to zero even for NGft-Lasso-Cv , and hence these cases do not contribute
much to the average RRMSE.
Signal Interpolation on Perturbed Graphs: We now present results for interpolation of signals defined
on the nodes of a perturbed graph, assuming that the signal is sparse in the GFT basis of the actual graph.
In our experiments, we use signal values defined at only m= 50nodes out of a total of n= 100nodes.
The signal coefficient vectors contain only 5 non-zero elements. The nominal graph contains d∈{1,2,5,10}
edge perturbations w.r.t. the actual graph. The values at the remaining nodes are obtained via the Ges
algorithm. Numerical results for this experiment are presented in Table 7 for a PPM graph, with results
averaged over 100 instances. The results show substantially improved performance with Gesford∈{1,2}
and some improvement for d= 5.
5.2 Inferred Linear-Edge Compressive Image Recovery
Experiment Setup: For evaluation of Ilecir, we simulate the patch-wise compressive acquisition of 10
images each from the following datasets: (1) A synthetic dataset we created, containing piece-wise smooth
images in the form of a union of regions individually containing intensity values expressed by polynomials of
x,y; (2) The Berkeley segmentation dataset3, a set of natural images used in image segmentation tasks; (3)
The Tom and Jerry dataset4, a dataset of still frames from the popular Tom and Jerry cartoon; and (4) The
NYU Depth dataset5, a dataset of depth-map images of indoor scenes. While ground-truth segmentation
is available for the synthetic dataset, the available segmentations for the other datasets are either human-
3https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/bsds/
4https://www.kaggle.com/datasets/balabaskar/tom-and-jerry-image-classification
5https://cs.nyu.edu/~silberman/datasets/nyu_depth_v2.html
18Under review as submission to TMLR
labelled or machine-generated. In each dataset, the segmentation information is used to construct the actual
graph, by dropping the edges of the lattice graph which connect pixels in two different segments of a patch.
Patch-wise compressive image acquisition is simulated for an image in the following manner. The image is
divided into non-overlapping patches of size 8×8. Each patch is arranged in row-major order to produce
a vector of n= 64dimensions, which forms the signal x∗. Measurements are generated using Eqn. 1, with
am×nmeasurement matrix whose entries are i.i.d. N(0,1), withm∈{20,30,40}. Furthermore, i.i.d.
N(0,σ2)noise is added to each measurement, with σ=β∥Φx∗∥1
m, withβ∈{0,0.01,0.02,0.05}. These
measurements are then decoded using the Ileciralgorithm, and the 8×8patch is estimated. For gray-scale
images, the estimated values are clipped to be between 0and255and rounded to the nearest integer. For
depth maps, negative values are set to 0. The recovered patches are stitched together to reconstruct the
image. The results of Ilecirare compared to those with DCT-based recovery ( Dct-Lasso-Cv ), and using
the GFT of the ground-truth segmentation ( SegGFT-Lasso-Cv ) in terms of the RRMSE and Structural
Similarity Index Measure (SSIM)6of the recovered images relative to the ground truth. For the algorithms,
Γ≜{10−3+6
19t:t∈{0,1,2,..., 19}},K= 5folds are used for cross-validation, and the loss improvement
factorτis set to 0.99. To speed up Ilecir, grid search over Γis performed only for DCT-based recovery,
and the same value of µis re-used for recovery with the image-edge partitioned graphs. However, after an
image-edge is chosen, µis re-computed using CV to yield the final patch estimate.
Quantitative comparison in the noiseless setting: Fig. 2 shows the RRMSE and SSIM of images recov-
ered using Ilecir,Dct-Lasso-Cv andSegGft-Lasso-Cv fromm∈{20,30,40}linear measurements, for
10 images each from the aforementioned datasets. Also see Tables S.VI-S.XVII of the supplemental for the
numerical values. We note that Ilecirsubstantially improves over Dct-Lasso-Cv in terms of the RRMSE
and SSIM of the recovered images on the Synthetic and the NYU Depth datasets. It also shows some im-
provement for the images in the Tom and Jerry dataset. For Tom and Jerry and the NYU Depth datasets,
the improvement is most pronounced when m= 20linear measurements are used. Such improvement is
expected since these are piece-wise smooth images – while the smooth regions are accurately recovered by
Dct-Lasso-Cv , the patches containing sharp edges are not recovered very accurately. Ilecirperforms
better on such patches, while maintaining the accuracy afforded by Dct-Lasso-Cv on smooth patches.
TheSegGft-Lasso-Cv method has near-perfect recovery for the Synthetic dataset. This substantiates
the rationale behind using the GFT basis of the 2-D lattice graph partitioned according to the segments
of a patch for recovery. Since Ilecironly models linear image edges and does not model more than one
image edge in a patch, recovery using it is not perfect. Notably, Ileciroften performs better than the
SegGft-Lasso-Cv method for the Tom and Jerry and NYU Depth Datasets. This means that it is able
to perform edge detection slightly better than the algorithm used to perform edge detection for the images
from the Tom and Jerry dataset. For the NYU Depth Dataset, we found that the provided segmentation
maps were not properly aligned with the depth map images (see Fig. 3 for an example of an incorrectly
labelled segmentation map of a patch from this dataset). Due to this, the SegGft-Lasso-Cv method per-
formsworsethanDct-Lasso-Cv for the NYU Depth dataset. This demonstrates a strength of the Ilecir
method – since the underlying segmentation is automatically inferred, it circumvents possible errors in the
segmentation map if it were available.
RRMSE and SSIM of images recovered using Ilecirare higher than those recovered using Dct-Lasso-Cv
for some images of the Berkeley dataset. Since natural imagescontain vastregions of detailed texture and not
just gradient of intensity, it is hard to improve upon the baseline Dct-Lasso-Cv method by modelling just
a single linear edge. This is also substantiated by the performance of the SegGft-Lasso-Cv method, which
is similar to Dct-Lasso-Cv andIlecir. However, a visual inspection of the images recovered by Ilecir,
SegGft-Lasso-Cv andDct-Lasso-Cv would reveal that IlecirandSegGft-Lasso-Cv perform better
along the edges in these images (see later in this section).
Qualitative Comparison in the noiseless setting: The results of image recovery via SegGft-Lasso-
Cv,Dct-Lasso-Cv , and Ilecirfor one image of each dataset are shown in Fig. 4, along with the original
image in each case. A careful inspection of the images reveals that in each case, the images recovered by
Ilecirhave higher fidelity than the corresponding image recovered by Dct-Lasso-Cv along sharp edges
6https://en.wikipedia.org/wiki/Structural_similarity
19Under review as submission to TMLR
in the image. The quality of the recovered images remains the same in regions where there are no sharp
edges. In Fig. 4 (Row 1), for the image from the Synthetic dataset, we clearly see that Ilecirhas good
recovery in regions where there is only a single edge which is close to linear. In contrast, Dct-Lasso-Cv
produces many artifacts along the edges. The image recovered by Ileciralso possesses some artifacts along
the edges, but much fewer than the one recovered by Dct-Lasso-Cv . These artifacts may appear for Ilecir
whenever the ground-truth image edge in the patch does not exactly match any of the image edges that
Ilecirtests for. Ilecirdoes not do well around corners, due to the presence of more than one image edge
in the patch. However, a careful inspection reveals that for some patches, the recovery quality for Ilecir
seems to be better than Dct-Lasso-Cv even in the presence of two edges, and there does not appear to be
a case where Ilecirhas worse recovery quality than Dct-Lasso-Cv . This is due to the high-probability
RMSE improvement guarantee of Ilecir(due to cross-validation) as established by Theorem 3.3.
In Fig. 4 (Row 2), there are much fewer artifacts around the face of the polar bear in the image recovered
byIleciras compared to the one recovered by Dct-Lasso-Cv . In the same region, we also see that while
there are fewer artifacts for SegGft-Lasso-Cv compared to Dct-Lasso-Cv , the recovery by Ileciris
much better than for SegGft-Lasso-Cv . This once again highlights the strength of Ilecircompared
to using human-labelled segmentation (which may contain errors) for recovery and is not available during
compressive recovery. In Fig. 4 (Row 3), there are much fewer artifacts for Ileciraround the ears and
the head of Tom (the cat), compared to for Dct-Lasso-Cv . However, there are many artifacts on the
face of Tom for both IlecirandDct-Lasso-Cv . This highlights the inability of Ilecirto improve upon
Dct-Lasso-Cv in regions containing many edges. In Fig. 4 (Row 4), we observe the same pattern – Ilecir
performs better than Dct-Lasso-Cv and even SegGft-Lasso-Cv around the edges in the depth map.
The reconstruction by each algorithm on an individual patch of an image from the NYU Depth dataset is
also shown in Fig. 3, which clearly demonstrates the recovery of the ground-truth segmentation and the
original patch using Ilecir.
Edgemap Recovered by Ilecir: Since the Ileciralgorithm discovers the best linear image edge for each
patch, an edge-map of the original image may be recovered by stitching together the edge-maps of each
patch. Fig 5 shows an image from the synthetic dataset (col 1), and its edge-map (col 2) recovered by the
Ileciralgorithm. The original edges are correctly detected for most patches.
Performance of Greedy Edge Selection on Compressive Image Recovery: We test the effectiveness
ofGeson the problem of patch-wise compressive image recovery on an image from the Synthetic dataset.
Fig. 6 and Table 8 show the RRMSE and SSIM of the recovered images when Gesis used for recovery, with
a maximum of d0∈{1,2,5,10}edges of the 2-D lattice graph of a patch being allowed to be perturbed by
the algorithm. We see that using Ges(especially when d0= 10graph edges are allowed to be perturbed)
is marginally better than using Dct-Lasso-Cv – however, it is much better to use Ilecir. This is evident
in Fig. 6, as well – a careful inspection reveals that the image recovered by Ges-10 (d0= 10) has slightly
fewer artifacts than the one recovered by Dct-Lasso-Cv , but recovery via Ilecir(see Fig. 4) is much
better. Fig. 5 shows the edgemap recovered by various algorithms, including Ges-5 and Ges-10 (cols 3
and 4). An edgemap for Gesis recovered in the following manner – whenever the Gesalgorithm drops
a (2-D lattice graph) edge between two pixels, the right pixel or the bottom pixel of the graph edge is
marked with white color (denoting a pixel belonging to an image edge), and remaining pixels are marked
with black color (denoting background pixels). We see that the edgemap recovered by Gesfollows the image
edges very coarsely. It consists of many isolated dots, instead of groups of pixels connected as an edge. In
comparison, the edgemap recovered by Ilecirconsists of linear edges in each patch. The Ileciralgorithm
takes advantage of the structure in perturbations of the graph edges, and is able to outperform Ges, which
perturbs graph edges in an unstructured manner.
Effect of Noise on Ilecir recovery performance: Table 9 shows the RRMSE and SSIM of images
recovered using Ilecirfrom noisy measurements of an image of the Synthetic dataset, with different noise
levelsβ∈{0,0.01,0.02,0.05}. Wefindthat Ilecirperformssignificantlybetterthan Dct-Lasso-Cv evenin
the presence of noise. In fact Ileciron measurements with β= 0.02has better RRMSE and approximately
the same SSIM as Dct-Lasso-Cv with noiseless measurements. We also find that the RRMSE and SSIM
ofSegGft-Lasso-Cv worsens significantly with measurement noise. Fig. 7 shows the images recovered
using Dct-Lasso-Cv andIlecirfor different noise levels. We note that the images recovered by Ilecir
20Under review as submission to TMLR
# Measure-
ments (m)Method RRMSE SSIM
40Dct-Lasso-Cv 0.0335 0.9598
SegGft-Lasso-Cv 0.0005 1.0000
Ilecir 0.0161 0.9938
Ges-1 0.0335 0.9606
Ges-2 0.0327 0.9633
Ges-5 0.0317 0.9657
Ges-10 0.0317 0.9658
30Dct-Lasso-Cv 0.0433 0.9406
SegGft-Lasso-Cv 0.0011 1.0000
Ilecir 0.0253 0.9856
Ges-1 0.0440 0.9395
Ges-2 0.0430 0.9425
Ges-5 0.0421 0.9450
Ges-10 0.0419 0.9454
20Dct-Lasso-Cv 0.0656 0.8914
SegGft-Lasso-Cv 0.0057 0.9993
Ilecir 0.0353 0.9744
Ges-1 0.0685 0.8845
Ges-2 0.0682 0.8860
Ges-5 0.0679 0.8868
Ges-10 0.0682 0.8863
Table 8: Performance of Geswith various perturbation budgets on Synthetic Image ID 0.
Noise Level Method RMSE SSIM
0Dct-Lasso-Cv 0.0335 0.9598
SegGft-Lasso-Cv 0.0005 1.0000
Ilecir 0.0161 0.9938
0.01Dct-Lasso-Cv 0.0343 0.9531
SegGft-Lasso-Cv 0.0079 0.9929
Ilecir 0.0187 0.9850
0.02Dct-Lasso-Cv 0.0375 0.9336
SegGft-Lasso-Cv 0.0156 0.9730
Ilecir 0.0240 0.9620
0.05Dct-Lasso-Cv 0.0520 0.8349
SegGft-Lasso-Cv 0.0368 0.8739
Ilecir 0.0468 0.8457
Table 9: RRMSE and SSIM of Ilecir,Dct-Lasso-Cv andSegGft-Lasso-Cv for Image ID 0 of the Synthetic
dataset for different noise levels ( β∈{0,0.01,0.02,0.05},m= 40,n= 64).
21Under review as submission to TMLR
are of better quality than the corresponding images recovered by Dct-Lasso-Cv , across all noise levels.
The image recovered by Ilecirwith noise level β= 0.02looks better near the edges in the image than the
one recovered by DCT from noiseless measurements.
Dealing with repeated eigenvalues: ForIlecir, the nominal graph is always a connected grid graph.
However,thegraphsthatsubsequentlyevolveinthe Ilecircontaintwo(disconnected)componentsseparated
by an image edge. For each such segmentation, an adjacency matrix is created by dropping the edges of
the 2-D lattice graph whose two endpoints lie in two different segments. We computed the eigenvectors
of Laplacian matrices of the two segments in each patch separately. Note that the eigenvectors of the
Laplacian matrix of a graph with more than one connected component are the same as the eigenvectors of
each component, with the entries corresponding to nodes of the remaining components set to zero. This fact
helped us obtain the eigenvectors of the Laplacian matrix of the complete segmented patch. This procedure
is helpful to avoid introducing correlations between the two segments, which may happen in case there are
repeated eigenvalues. Notably, the eigenvalue of 0 gets repeated ktimes if there are kconnected components
in a graph. These computed GFTs are used in the Ileciralgorithm.
22Under review as submission to TMLR
RRMSE SSIMSynthetic
0 1 2 3 4 5 6 7 8 900.050.100.050.100.050.1DCT-LASSO-CVm=20 m=30 m=40
0 1 2 3 4 5 6 7 8 90.850.90.9510.850.90.9510.850.90.951SegGFT-LASSO-CV ILECIRm=20 m=30 m=40 Berkeley
100007118072164046209021230063246009290303650724100645000 00.10.200.10.200.10.2m=20 m=30 m=40
1000071180721640462090212300632460092903036507241006450000.60.70.80.910.60.70.80.910.60.70.80.9m=20 m=30 m=40 Tom and Jerry
1780390891746612275642535818629261520 00.050.10.1500.050.10.1500.050.1m=20 m=30 m=40
17803908917466122756425358186292615200.80.850.90.9510.80.850.90.9510.80.850.90.95m=20 m=30 m=40 NYU Depth
103140277419493543603108912441433 00.010.020.0300.010.020.0300.010.020.03
Image IDm=20 m=30 m=40
1031402774194935436031089124414330.920.940.960.9810.920.940.960.9810.920.940.960.98
Image IDm=20 m=30 m=40
Figure 2: RRMSE and SSIM using Ilecir,Dct-Lasso-Cv andSegGft-Lasso-Cv (Segmentation-aware recovery)
in the noiseless regime, with n= 64for8×8patches. Also see Tables S.VI to S.XVII of the supplemental.
23Under review as submission to TMLR
Figure 3: Left to right: An 8×8patch from an image in the NYU depth dataset (leftmost), its incorrectly
labelled segmentation (second from left), signal recovery by SegGFT-Lasso-Cv (poor quality), recovery of correction
segmentation by Ilecir, recovery of patch by Ilecir, patch recovered via Dct-Lasso-Cv . Note: the two regions of
the segmentation maps are colored arbitrarily.
Original SegGFT Dct IlecirSynthetic
Synthetic, Image ID: 0, Original
Synthetic, Image ID: 0, Noiseless, m: 40, SegGFT-LASSO
Synthetic, Image ID: 0, Noiseless, m: 40, DCT-LASSO
Synthetic, Image ID: 0, Noiseless, m: 40, ILECIR
 Berkeley
Berkeley, Image ID: 100007, Original
Berkeley, Image ID: 100007, Noiseless, m: 40, SegGFT-LASSO
Berkeley, Image ID: 100007, Noiseless, m: 40, DCT-LASSO
Berkeley, Image ID: 100007, Noiseless, m: 40, ILECIR
 Tom and Jerry
T om and Jerry, Image ID: 4661, Original
T om and Jerry, Image ID: 4661, Noiseless, m: 40, SegGFT-LASSO
T om and Jerry, Image ID: 4661, Noiseless, m: 40, DCT-LASSO
T om and Jerry, Image ID: 4661, Noiseless, m: 40, ILECIR
 NYU Depth
NYU Depth, Image ID: 103, Original
NYU Depth, Image ID: 103, Noiseless, m: 40, SegGFT-LASSO
NYU Depth, Image ID: 103, Noiseless, m: 40, DCT-LASSO
NYU Depth, Image ID: 103, Noiseless, m: 40, ILECIR
Figure 4: Zoomed view of images from the Synthetic (top row), Berkeley (second row), Tom and Jerry (third row),
and NYU Depth (bottom row) datasets, recovered patch-wise from m= 40compressive measurements per 8×8
patch via various algorithms in the noiseless setting. The columns denote, from left to right: Col 1 – the original
image, images recovered via SegGft-Lasso-Cv (Col 2), via Dct-Lasso-Cv (Col 3), via Ilecir(Col 4). Note that
Ilecirproduces significantly smoother reconstruction of the edges (the polar bear’s face against the snow, Tom’s
finger against the wall, the object against the background in the depth map) than Dct-Lasso-Cv . Zoom into PDF
for a clearer view. Enlarged images are provided in the supplementary materials (Figs. S.3 to S.6).
24Under review as submission to TMLR
Figure 5: Asyntheticimage(col1),anditsedgemapasrecoveredpatch-wisefrom m= 30compressivemeasurements
per8×8patch via the Ilecir(col 2), Ges-1(col 3), and Ges-10(col 4) algorithms.
Synthetic, Image ID: 0, Noiseless, m: 40, ILECIR
Synthetic, Image ID: 0, Noiseless, m: 40, DCT-LASSO
Synthetic, Image ID: 0, Noiseless, m: 40, GES-10
Figure 6: Comparison of images recovered using (from left to right) Ilecir,Dct-Lasso-Cv , and Ges-10.Ges
shows only very minor improvement over Dct, such as in the top-right corner of the zoomed portion, whereas Ilecir
performsbetterreconstructioninareaswithasingleimageedge. Hence Ilecirispreferredforedge-awarecompressive
image recovery.
β= 0 β= 0.01 β= 0.02 β= 0.05Dct-Lasso-Cv
Synthetic, Image ID: 0, Noiseless, m: 40, DCT-LASSO
Synthetic, Image ID: 0, Noise Level : 0.01, m: 40, DCT-LASSO
Synthetic, Image ID: 0, Noise Level : 0.02, m: 40, DCT-LASSO
Synthetic, Image ID: 0, Noise Level : 0.05, m: 40, DCT-LASSO
 Ilecir
Synthetic, Image ID: 0, Noiseless, m: 40, ILECIR
Synthetic, Image ID: 0, Noise Level : 0.01, m: 40, ILECIR
Synthetic, Image ID: 0, Noise Level : 0.02, m: 40, ILECIR
Synthetic, Image ID: 0, Noise Level : 0.05, m: 40, ILECIR
Figure 7: Zoomed view of Image ID 0of the Synthetic dataset, recovered patch-wise from m= 40compressive
measurements per 8×8patch using the Dct-Lasso-Cv (top row) and the Ilecir(bottom row) algorithms for various
noise levels ( β∈{0,0.01,0.02,0.05}). Note the significantly smoother edge reconstruction and edge artifact reduction
in case of Ileciras compared to Dct-Lasso-Cv .
25Under review as submission to TMLR
6 Conclusion and Future Work
This work proposes a new technique of compressive graph signal recovery in cases where the graph topology
is partly incorrectly specified. This is a novel computational problem (to our best knowledge), with no
existing literature that targets this specific problem. At the core of the technique to correct for errors in
graph topology, lies the concept of cross validation in compressed sensing. A novel algorithm is proposed and
supportive theoretical results are stated and proved. A large number of computer simulations are presented,
including results on compressive image recovery where images or image patches are modeled as lattice
graphs. Since intensity values at pixels/nodes that lie on opposite sides of an image edge are uncorrelated,
the presence of a graph edge that links such nodes is regarded as a perturbation that needs to be corrected.
Thus edge-preserving compressive recovery is cast quite interestingly as a graph perturbation problem. This
specific idea has been used in image compression before Hu et al. (2014), where the application innately has
access to the complete graph as well as the underlying image. However its application to compressive image
reconstruction (as in our work) is quite novel – in our case, the underlying image as well as the underlying
image graph are both unknown, and both these are estimated from just the compressive measurements.
Moreover, our technique is naturally applicable to image data that are defined on arbitrary non-Cartesian
domains, for examples on the vertices of a 3D model. In such cases, our perturbed GFT technique fits
in very naturally, even though the eigenvectors of the Laplacian of the actual graph may not be the DCT .
Furthermore, our technique can be easily extended to handle dropping of edges even in weighted graphs.
We also note that the idea of signal sparsity in the GFT for compressive recovery has not been extensively
explored in the literature, with most papers focusing on band-limited approximations Zhu & Rabbat (2012)
unlike our approach. Finally, we show in the supplemental material (Sections 6 and 7) that our method
may be used to recover signals which admit some other structure than sparsity in the GFT, such as being
piece-wise constant, by using a different regularizer than the ℓ1-norm of GFT, such as Graph Total Variation.
There are a few major avenues for future work listed below: (1) Research towards a more computationally
efficientstrategytouncoverallgraphperturbations, overandaboveourgreedyalgorithms, andextendingthe
strategy to handle weighted graphs, such as by using gradient descent of the Lassoobjective over Laplacian
matrices, parameterized in terms of eigenvectors and eigenvalues. One potential direction for designing
computationally more efficient algorithms would be to incorporate ideas from Jayawant & Ortega (2022) to
avoid repeated eigen-decompositions. (2) Improving the performance of compressive image recovery possibly
using steerable bases such as those in Fracastoro et al. (2016), particularly in the presence of eigenvalues
with multiplicity greater than 1, or using notions of image edge smoothness or continuity.
References
Network science. https://en.wikipedia.org/wiki/Network_science , 2024.
E. Candes and M. Wakin. An introduction to compressive sampling. IEEE SPM , 25(2):21–30, 2008.
Elena Ceci and Sergio Barbarossa. Graph signal processing in the presence of topology uncertainties. IEEE
TSP, 68:1558–1573, 2020. doi: 10.1109/TSP.2020.2976583.
Elena Ceci, Yanning Shen, Georgios B Giannakis, and Sergio Barbarossa. Graph-based learning under
perturbations via total least-squares. IEEE TSP , 68:2870–2882, 2020.
Yuejie Chi, Louis L. Scharf, Ali Pezeshki, and A. Robert Calderbank. Sensitivity to basis mismatch in
compressed sensing. IEEE TSP , 59(5):2182–2195, 2011.
Xiaowen Dong, Dorina Thanou, Michael Rabbat, and Pascal Frossard. Learning graphs from data: A signal
representation perspective. IEEE SPM , 36(3):44–63, 2019.
Marco F Duarte et al. Single-pixel imaging via compressive sampling. IEEE SPM , 25(2):83–91, 2008.
S. Fosson, V. Cerone, and D. Regruto. Sparse linear regression from perturbed data. Automatica , 122, 2020.
Giulia Fracastoro, Sophie M Fosson, and Enrico Magli. Steerable discrete cosine transform. IEEE TIP , 26
(1):303–314, 2016.
26Under review as submission to TMLR
S. Ghosh, R. Agarwal, M. A. Rehan, S. Pathak, P. Agarwal, Y. Gupta, S. Consul, N. Gupta, Ritika,
R. Goenka, A. Rajwade, and M. Gopalkrishnan. A compressed sensing approach to pooled RT-PCR
testing for COVID-19 detection. IEEE Open Journal of Signal Processing , 2:248–264, 2021. doi: 10.1109/
OJSP.2021.3075913.
Ritesh Goenka, Shu-Jie Cao, Chau-Wai Wong, Ajit Rajwade, and Dror Baron. Contact tracing enhances
the efficiency of COVID-19 group testing. In ICASSP, pp. 8168–8172, 2021.
T. Hastie, R. Tibshirani, and M. Wainwright. Statistical Learning with Sparsity: The LASSO and General-
izations. CRC Press, 2015.
Wei Hu, Gene Cheung, Antonio Ortega, and Oscar C Au. Multiresolution graph fourier transform for
compression of piecewise smooth images. IEEE TIP , 24(1):419–433, 2014.
J.D. Ianni and W.A. Grissom. Trajectory auto-corrected image reconstruction. Magnetic Resonance in
Medicine , 76(3), 2016.
Ajinkya Jayawant and Antonio Ortega. Practical graph signal sampling with log-linear size scaling. Signal
Processing , 194:108436, 2022.
Alexander Jung, Nguyen Tran, and Alexandru Mara. When is network LASSO accurate? Frontiers in
Applied Mathematics and Statistics , 3:28, 2018.
Robert A Kleinman and Colin Merkel. Digital contact tracing for covid-19. Cmaj, 192(24):E653–E656, 2020.
Kuldeep Kulkarni et al. Reconnet: Non-iterative reconstruction of images from compressively sensed mea-
surements. In CVPR, pp. 449–458, 2016.
ArisSLalos,IasonNikolas,EvangelosVlachos,andKonstantinosMoustakas. Compressedsensingforefficient
encoding of dense 3d meshes using model-based bayesian learning. IEEE Transactions on Multimedia , 19
(1):41–53, 2016.
Faisal Mahmood, Nauman Shahid, Ulf Skoglund, and Pierre Vandergheynst. Adaptive graph-based total
variation for tomographic reconstructions. IEEE SPL , 25(5):700–704, 2018.
Lee Middleton and Jayanthi Sivaswamy. Hexagonal Image Processing: A Practical Approach (Advances in
Pattern Recognition) . Springer-Verlag, Berlin, Heidelberg, 2005. ISBN 1852339144.
Jari Miettinen, Sergiy A Vorobyov, and Esa Ollila. Modelling and studying the effect of graph errors in
graph signal processing. Signal Processing , 189:108256, 2021.
Jonathan M. Nichols, Albert K. Oh, and Rebecca M. Willett. Reducing basis mismatch in harmonic signal
recovery via alternating convex search. IEEE SPL , 21(8):1007–1011, 2014.
Antonio Ortega, Pascal Frossard, Jelena Kovačević, José MF Moura, and Pierre Vandergheynst. Graph
signal processing: Overview, challenges, and applications. Proceedings of the IEEE , 106(5):808–828, 2018.
H. Pandotra, E. Malhotra, A. Rajwade, and K. S. Gurumoorthy. Dealing with frequency perturbations in
compressive reconstructions with Fourier sensing matrices. Signal Process. , 165:57–71, 2019.
J. Parker, V. Cevher, and P. Schniter. Compressive sensing under matrix uncertainties: An approximate
message passing approach. In ACSSC, pp. 804–808, 2011.
Santiago Segarra, Antonio G Marques, Gonzalo Mateos, and Alejandro Ribeiro. Network topology inference
from spectral templates. IEEE TSIPN , 3(3):467–483, 2017.
Z. Tan, Y Peng, and A Nehorai. Joint sparse recovery method for compressed sensing with structured
dictionary mismatches. IEEE TSP , 62(19):4997–5008, 2014.
O. Teke, A. C. Gurbuz, and O. Arikan. Perturbed orthogonal matching pursuit. IEEE TSP , 61(24):6220–
6231, 2013.
27Under review as submission to TMLR
J. Zhang, L. Chen, P. T. Boufounos, and Y. Gu. On the theoretical analysis of cross validation in compressive
sensing. In ICASSP, pp. 3370–3374, 2014.
H. Zhu, G. Leus, and G. Giannakis. Sparsity-cognizant total least-squares for perturbed compressive sam-
pling.IEEE Trans. Signal Process. , 59(11), 2011.
Xiaofan Zhu and Michael Rabbat. Graph spectral compressed sensing for sensor networks. In ICASSP, pp.
2865–2868, 2012.
Xiuming Zou, Lei Feng, and Huaijiang Sun. Compressive sensing of multichannel EEG signals based on
graph fourier transform and cosparsity. Neural Processing Letters , 51:1227–1236, 2020.
A Appendix
Please see the supplemental material for proofs of the theorems, and many additional empirical results.
28