Published in Transactions on Machine Learning Research (12/2023)
Local Function Complexity for Active Learning
via Mixture of Gaussian Processes
Danny Panknin danny.panknin@tu-berlin.de
Uncertainty, Inverse Modeling and Machine Learning Group, Berlin Institute of Technology, 10587 Berlin, Germany
Physikalisch-Technische Bundesanstalt, 10587 Berlin, Germany
Stefan Chmiela stefan@chmiela.com
Machine Learning Department, Berlin Institute of Technology, 10587 Berlin, Germany
BIFOLD-Berlin Institute for the Foundations of Learning and Data, Germany
Klaus-Robert Müller klaus-robert.mueller@tu-berlin.de
Machine Learning Department, Berlin Institute of Technology, 10587 Berlin, Germany
BIFOLD-Berlin Institute for the Foundations of Learning and Data, Germany
Department of Artificial Intelligence, Korea University, Seoul 136-713, South Korea
Max Planck Institute for Informatics, 66123 Saarbrücken, Germany
Shinichi Nakajima nakajima@tu-berlin.de
Machine Learning Department, Berlin Institute of Technology, 10587 Berlin, Germany
BIFOLD-Berlin Institute for the Foundations of Learning and Data, Germany
RIKEN AIP, 1-4-1 Nihonbashi, Chuo-ku, Tokyo, Japan
Reviewed on OpenReview: https: // openreview. net/ forum? id= w4MoQ39zmc
Abstract
Inhomogeneities in real-world data, e.g., due to changes in the observation noise level or
variations in the structural complexity of the source function, pose a unique set of challenges
for statistical inference. Accounting for them can greatly improve predictive power when
physical resources or computation time is limited. In this paper, we draw on recent theoretical
results on the estimation of local function complexity (LFC), derived from the domain of
local polynomial smoothing (LPS), to establish a notion of local structural complexity, which
is used to develop a model-agnostic active learning (AL) framework. Due to its reliance on
pointwise estimates, the LPSmodel class is not robust and scalable concerning large input
space dimensions that typically come along with real-world problems. Here, we derive and
estimate the Gaussian process regression (GPR)-based analog of the LPS-basedLFCand
use it as a substitute in the above framework to make it robust and scalable. We assess the
effectiveness of our LFCestimate in an ALapplication on a prototypical low-dimensional
synthetic dataset, before taking on the challenging real-world task of reconstructing a
quantum chemical force field for a small organic molecule and demonstrating state-of-the-art
performance with a significantly reduced training demand.
1 Introduction
Inference problems from real-world data often exhibit inhomogeneities, e.g., the noise level, the density of the
data distribution, or the complexity of the target function may change over the input space. There exist
different approaches from various domains that treat specific kinds of inhomogeneities. For example, Kersting
et al. (2007); Cawley et al. (2006) deal with heteroscedasticity by reconstructing a local noise variance
function that is used to adapt the regularization of the model locally. Some approaches adjust bandwidths
locally with respect to the input density (Wang & Wang, 2007; Mackenzie & Tieu, 2004; Moody & Darken,
1989; Benoudjit et al., 2002). Inhomogeneous complexity can also be captured using a combination of several
1Published in Transactions on Machine Learning Research (12/2023)
kernel-linear models with different bandwidths, either learned jointly (Zheng et al., 2006; Guigue et al., 2005)
or hierarchically (Ferrari et al., 2010; Bellocchio et al., 2012). The most widely applicable models treat all
types of aforementioned inhomogeneities in a unified way (Tresp, 2001; Panknin et al., 2021). Namely, they
locally adapt bandwidths or regularization according to the inhomogeneities in noise, complexity, and data
density. While this is the path we will pursue, the focus in this work will be on inhomogeneous complexity
under the assumption of homoscedastic noise. In addition, we will investigate our proposed estimates in a
heteroscedastic setting to demonstrate negligible practical limitations.
Exposing inhomogeneities sheds light on the informativeness of certain locations of the input space, which
subsequently can be used to guide the sampling process during training—also known as active learning (AL).
AL(Kiefer, 1959; MacKay, 1992; Seung et al., 1992; Seo et al., 2000) is a powerful tool to enhance the
training process of a model when the acquisition of labeled training data is expensive. It has been successfully
implemented in various regression applications like reinforcement learning (Teytaud et al., 2007), wind speed
forecasting (Douak et al., 2013), and optimal control (Wu et al., 2020).
Nowadays, machine learning (ML) methods are increasingly deployed in physical modeling applications across
various disciplines. In that setting, the labels that are necessary for model training are typically expensive
as they stem, e.g., from computationally expensive first-principles calculations (Chmiela et al., 2017) or
even laboratory experiments. Due to the need for effective training datasets, ALhas become an integral
part of ever-growing importance in real-world applications, e.g., in the domains of pharmaceutics (Warmuth
et al., 2003) and quantum chemistry (Gubaev et al., 2018; Tang & de Jong, 2019; Huang & von Lilienfeld,
2020)—which raises the demand for AL solutions and the importance of AL research in general.
Through the advance of MLin scientific fields that hold the potential for significant impact, new regression
problems emerge, for which there is initially only scarce domain knowledge while they simultaneously require
thousands to tens of thousands of training samples for MLmodels to operate at an acceptable performance
level. Regarding AL, these two characteristics of regression problems are hard to reconcile:
Due to insufficient domain knowledge on the one hand, a suitable ALapproach shall be robust, since unjustified
assumptions may result in a training performance that is even worse than random test sampling . Byrandom
test sampling , we refer to the naive training data construction that draws samples i.i.d. according to the test
distribution. Additionally, the ALapproach shall be model-agnostic since the state-of-the-art is ever-evolving
for this particular kind of regression problem. For these reasons, practitioners prefer model-free ALapproaches
for regression (Wu, 2019) over sophisticated, model-based ALapproaches with strong assumptions as the
former are inherently robust and model-agnostic by ignoring label information.
On the other hand, it is preferable that an ALapproach outperforms random test sampling even at large
training sizes. In the following, we will measure the ALperformance by the relative required sample size
ϱ>0, which asymptotically equates the performance of n·ϱactive training samples to nrandom test samples
(seeDefinition 2). Accordingly, we call an ALapproach asymptotically superior to random test sampling , if
ϱ<1. Unfortunately, the performance gain of model-free ALapproaches that we observe at small training
sizes over random test sampling eventually diminishes completely ( ϱ= 1) with growing training size.
For the described learning task, we therefore require an ALapproach that is model-based but comes with
mild regularity assumptions at the same time to feature robustness and model-agnosticity to a certain extent.
Recently, Panknin et al. (2021) addressed the outlined ALscenario, where the fundamental idea is to analyze
the distribution of the optimal training set of a model in the asymptotic limit of the sample size.
Assumingthatthislimitingdistributionexists, theythenproposetosampletrainingdataina top-down manner
from this very distribution, knowing that with growing sample size the training set will eventually become
optimal. By a top-down ALapproach, we mean an (infinite) training data refinement process x′
1,x′
2,...such
that—when optimizing an ALcriterion with respect to {x1,...,xn}—{x′
1,...,x′
n}asymptotically becomes
a respective optimizer as n→∞. They have shown for the local polynomial smoothing (LPS) model class
(Cleveland & Devlin, 1988) that the asymptotically optimal distribution exists, whose density furthermore
factorizes into contributions of the test density, heteroscedastic noise, and local function complexity (LFC)—a
measure of the local structural complexity of the regression function. Intuitively, LFCscales with the local
amount of variation of the regression function. It is essentially estimated as the reciprocal determinant of the
2Published in Transactions on Machine Learning Research (12/2023)
locally optimal kernel bandwidth (LOB) of theLPSmodel, calibrated for the local effects of the training input
density and noise level. Given a small but sufficient training set, these factors can be estimated, allowing the
construction of the optimal training density and subsequently enabling the refinement of the training data
towards asymptotic optimality.
While the previous work by Panknin et al. (2021) provides a theoretically sound solution to our considered
ALscenario, the required pointwise estimates that are inherent to the LPSmodel class prevent scalability
with regard to the input space dimension d. The goal of our work is to extend the above approach in a
scalable way. The key idea is to build the required estimate of LFCbased on the LOBof the related Gaussian
process(GP) model class that can naturally deal with high input space dimensions. Subsequently, we plug
our scalable LFCestimate into the ALframework of the existing method, whose functioning is justified by
the method’s model-agnostic nature.
It is particularly the almost assumption-free nature of LPSthat made the results of Panknin et al. (2021)
model-agnostic. To that effect, we base our results on the nonparametric, adaptive bandwidth Gaussian
process regression (GPR) model to preserve this property. While we lose the strict asymptotic sampling
optimality this way, we expect it to be reasonably close due to the model-agnosticity nevertheless. We refer
to the resulting training density as the superior training density forlocally adaptive models , by which we
refer to models that adapt to the considered inhomogeneities, namely heteroscedasticity and inhomogeneous
complexity. Note that it is first and foremost superior for our adaptive bandwidth GPR model.
Fig.1 summarizes all steps of our contribution and shows how they are interlinked and in which sections
they will be discussed. Specifically, we contribute in two ways:
Theoretical contribution Assuming homoscedastic data, we propose a GPR-basedLFCestimate which is
inspired by the design of the LPS-basedLFCestimate. Here, we need to respect the scaling behavior of LOB
ofGPRthat differs from the LPScase, where we use asymptotic results on the scaling of optimal bandwidths
forGPR, as described in Sec.3.3. Making use of the model-agnosticity of the optimal training density of
LPS, we replace the herein contained LPS-basedLFCestimate for our GPR-basedLFCestimate to obtain a
superior training density forlocally adaptive models . From this point, we can implement the AL framework
by Panknin et al. (2021), for which we propose a novel pool-based formulation. Both, our LFCand density
estimate will inherit the scalability of the deployed GPR-based LOB estimate.
Methodological contribution We propose a scalable LOBestimate for GPRas the weighted average of
bandwidth candidates, where the weights are given by the gate function of a sparse mixture of GPs model—a
special case of a mixture of experts (MoE) model (Jacobs et al., 1991; Jordan & Jacobs, 1994; Pawelzik et al.,
1996). Here, each expert of the MoEis aGPRmodel that holds an individual, fixed bandwidth candidate.
We construct the MoEinPyTorch (Paszke et al., 2019) out of well-established components from the related
work and design a training objective that is regularized with respect to small bandwidth choices to obtain a
robust and reasonable LOBestimate in the end. In addition, we provide an implementation1of both, the
ALframework and our model. Finally, we propose a novel model-agnostic way of choosing inducing points
(IPs) of sparse GPRmodels: Respecting LFC, we place additional basis functions of a kernel method in more
complex regions while removing basis functions in simpler regions of the input space.
Sec. 4.3 Sec. 4.1
Sec. 4.2
Figure 1: An overview of the steps of our contribution and how they are interlinked. We will elaborate on
the main steps in the specified sections.
1https://github.com/DPanknin/modelagnostic_superior_training
3Published in Transactions on Machine Learning Research (12/2023)
To show the capabilities of our approach, we consider two inhomogeneously complex regression problems:
The Doppler function In a controlled setting of 1-dimensional synthetic data, we will first analyze our
MoEmodel and the proposed estimates of LFCand thesuperior training density , where we will demonstrate
the asymptotic superior performance of our superior sampling scheme and compare to related work. By the
superior sampling scheme , we refer to i.i.d. sampling from the superior training density .
Forcefieldreconstruction Quantuminteractionsexhibitmulti-scalebehaviorduetothecomplexelectronic
interactions that give rise to any observable property of interest, like the total energy or atomic forces of a
system (Bereau et al., 2018; Yao et al., 2018; Grisafi & Ceriotti, 2019; Ko et al., 2021; Unke et al., 2021a). To
demonstrate the scalability of our approach, we consider a force field reconstruction problem of a molecule
with 27 dimensions, where the application of the LPS-basedALframework by Panknin et al. (2021) is
intractable. Besides the asymptotic superior ALperformance, we gain insights into the local structural
complexity of this high-dimensional molecular configuration space through visualizations of the scalar-valued
LFC function.
We begin by discussing our work in the context of related work in Sec.2. Next, we give a formal definition of
the considered regression problem and the asymptotic ALtask, and review asymptotic results for LPSand
GPRinSec.3. InSec.4, we describe our MoEmodel and derive the GPR-basedLFCandsuperior training
densityestimates. In Sec.5, we then describe our experiments and results, which will be further discussed in
Sec. 6. We finally conclude in Sec. 7.
2 Related work
Choice of MoE, experts and the gate The common assumption of MoEapproaches is that the overall
problem to infer is too complex for a single, comparably simple expert. This is the case, for example in
regression of nonstationary or piecewise continuous data, and naturally in classification where each cluster
shape may follow its own pattern. In such a scenario each expert of the MoEmodel can specialize in modeling
an individual, (through the lens of a single expert) incompatible subset of the data, where the gate learns a
soft assignment of data to the experts. Under these assumptions, the hyperparameters of each expert can be
tuned individually on the respective assigned data subset. In the light of this paradigm, there exist several
instances of mixture of GPs, for example, Tresp (2001); Meeds & Osindero (2006); Yuan & Neubauer (2009);
Yang & Ma (2011); Chen et al. (2014).
Inourwork, weaimtoinferasingleregressionproblem, wherethereisnosuchsegmentationasdescribedabove:
Each individual (reasonably specified) expert of our mixture model is eventually capable of modeling the whole
problem on its own. Yet, if the problem possesses an inhomogeneous structure, the prediction performance
can be increased by allowing for a local individual bandwidth choice. Therefore, we deviate from the common
MoEparadigm, sharing all those parameters across the experts that describe the regression function. This
less common assumption was also made by Pawelzik et al. (1996), where—locally dependent—some experts
are expected to perform superior compared to the others.
For the expert and gate components of our MoEmodel, we focus on the sparse, variational GPRmodel (see,
e.g., Hensman et al. (2015)) trained by stochastic gradient descent. However, there exist other (sparse) GPR
approaches that could be considered for the gate or the experts of our MoEmodel. Some are computationally
appealing as they solve for the inducing value distribution analytically (Seeger et al., 2003; Snelson &
Ghahramani, 2005; Titsias, 2009) or do not require inducing points in the first place in the case of a full
GPR model (see, e.g. Williams & Rasmussen (1996)).
Particularly the expert models of our MoEmodel can be exchanged for arbitrary sparse and full formulations
ofGPR, as long as we can access the posterior predictive distribution. We give a short summary of these
model alternatives in Appendix B.1 and B.2, which are also included in our provided implementation.
For the gate, however, analytic approaches come with complications as they require labels. Such labels do
not exist for the gate, and so we would need to train the MoEin anexpectation maximization loop, where
the likelihood of an expert to have produced a training label functions as a pseudo-label to the gate.
4Published in Transactions on Machine Learning Research (12/2023)
Alternative nonstationary GPs As opposed to a standard GP that features a stationary covariance
structure, our MoE model with GP experts of individual bandwidths can be interpreted as a nonstationary
GP. Apart from MoE model architectures, there exist other approaches to construct a nonstationary GP:
Closely related to the MoEmodel, (Rullière et al., 2018) proposed to aggregate individual expert model
outputs through a nested GP. Note that this approach is not well-suited for our purpose as the aggregation
weights lack the interpretation of a hidden classifier, leaving the subsequent LOBestimation (as in (24))
open. (Gramacy & Lee, 2008) deploy individual stationary GPs on local patches of the input space that are
given by an input space partitioning of a tree.
(Gramacy & Apley, 2015) identify subsets of the training data that are necessary to resemble the GP
covariance structure at each individual evaluation point. Careful bandwidth choice for each subset then yields
a nonstationary GP as well as local bandwidths. Roininen et al. (2019) obtain local bandwidths by imposing
a hyperprior on the bandwidth of a GP. Note that our work intends to elaborate the estimation of LFCand
model-agnostic superior training, given any estimate of LOBofGPR. We deployed an MoEapproach as
a simple means to obtain these estimates. The MoEcomponent in our LFCand superior training density
estimates may be readily replaced by the approaches of Gramacy & Apley (2015) or Roininen et al. (2019).
Indeep Gaussian process (DGP) regression (Damianou & Lawrence, 2013), the inputs are mapped through
one or more hidden (stationary) GPs. This warping of the input space yields a nonstationary covariance
structure of DGP. An approximate DGPmodel through random feature expansions was exercised by Roininen
et al. (2019). Sauer et al. (2023b) discuss active learning for DGPregression. We will implement the DGP
model as well as the ALscheme of Sauer et al. (2023b) and compare the ALperformance of our superior AL
scheme on this very model to demonstrate the model-agnosticity of our work in Sec. 5.1.
IP selection In our work (see Sec.4.5), we choose the IP locations of the gate and the experts of our MoE
model in a diverse and representative way but also in alignment with the structural complexity of the target
function, interpreting this choice as a nested ALproblem. There are a variety of IP selection approaches in
the literature. Zhang et al. (2008) interpreted the choice of IP locations from a geometric view that is similar
to ours: They derived a bound on the reconstruction error of a full kernel matrix by a Nyström low-rank
approximation in terms of the sum of distances of all training points to their nearest IP. This exposes a
local minimum by letting the IP locations be the result of k-Means clustering . This choice of IP locations
is representative and diverse, while it solely considers input space information. In this sense, our approach
extends their work by additionally considering label information. This and our approach draw a fixed number
of IPs at once. There are also a lot of Nyström method based IP selection approaches that select columns
of the full kernel matrix according to a fixed distribution (Drineas et al., 2005) or one-by-one in a greedy,
adaptive way (Smola & Schölkopf, 2000; Fine & Scheinberg, 2001; Seeger et al., 2003). An intensive overview
of Nyström method based IP selection methods was given by Kumar et al. (2012), where they also analyzed
ensembles of low-rank approximations. We compare our proposed IP choice (29) to the greedy fast forward
IP selection approach by Seeger et al. (2003) in Sec. 5.1.
Moss et al. (2023) incorporate a quality function into a diverse IP selection process that can be specified flexibly.
They consider Bayesian optimization rather than regression, they exercise a quality function proportional to
the label. However, other measures of informativeness that are better suited for regression could be deployed.
Note that LFC would be a possible candidate for this purpose.
TheALscenario In this work, we consider model-agnostic ALwith persistent performance at large (or
even asymptotic) training size as opposed to the common ALparadigm that is concerned with small sample
sizes. In this sense, we delimit ourselves from ALapproaches that are tied to a model, e.g., when they are
based on a parametric model (Kiefer, 1959; MacKay, 1992; He, 2010; Sugiyama & Nakajima, 2009; Gubaev
et al., 2018), or which refine training data bottom-up in a greedy way to maximize its information content at
small sample size, where the information is either based on the inputs only (Seo et al., 2000; Teytaud et al.,
2007; Yu & Kim, 2010; Wu, 2019; Liu et al., 2021) or also incorporates the labels (Burbidge et al., 2007; Cai
et al., 2013). By a bottom-up AL approach, we mean a training data refinement process that is constructed
by choosing the nthinputxnas the optimizer of an ALcriterion with respect to {x1,...,xn}, when keeping
the previously drawn inputs {x1,...,xn−1}(with labels{y1,...,yn−1}) fixed.
5Published in Transactions on Machine Learning Research (12/2023)
Our work is therefore complementary to the latter kind of approaches which can be better suited in another
ALscenario. For example, if there is enough domain knowledge such that we can deduce a reasonable
parametric model without the need for a model change in hindsight, an active sampling scheme based on this
model will be best. Our category of interest is for the other case, when domain knowledge is scarce, where we
have no idea about the regularity or structure of the problem to decide on a terminal model. Here, for small
training sizes (and particularly from scratch), input space geometric arguments (Teytaud et al., 2007; Yu &
Kim, 2010; Wu, 2019; Liu et al., 2021) are applied in practice. However, as already noted in the introduction,
their benefit is limited to this small sample size regime, which we will demonstrate on our synthetic dataset.
They serve reasonably for the initialization of supervised AL approaches, including ours, nevertheless.
Regarding our considered ALscenario, Panknin et al. (2021) have recently proposed an ALframework based
on theLPSmodel class, where training samples are added so as to minimize the mean integrated squared
error(MISE) in the asymptotic limit. This approach is therefore provably asymptotically superior to random
test sampling . Additionally, it is robust since the LPSmodel is almost free of regularity assumptions. Finally,
theirLPS-based solution then showed to be model-agnostic: On the one hand, this is indicated theoretically
by the fact that the LPSmodel has only indirect influence on the asymptotic form of LFCand the optimal
training density since the predictor is asymptotically not involved (see, e.g., Eq. (8)); On the other hand,
this is validated empirically by assessing the performance of their LPS-based training dataset construction
underreasonable model change in hindsight. This model change is restricted to locally adaptive models . Here,
Panknin et al. (2021) observed a consistent performance superior to random test sampling when training
a random forest model and a radial basis function (RBF)-network (Moody & Darken, 1989), using their
proposed training dataset.
AL for classification Note that the outlined AL scenario can be solved more easily for classification:
Here,ALis intuitively about the identification and rendering of the decision boundaries, which is inherently
a model-agnostic task. In addition, since the decision boundaries are a submanifold of the input space X, a
substantial part of Xcan be spared when selecting training samples. Therefore, ALfor classification leverages
the decay of the generalization error from a polynomial to an exponential law (Seung et al., 1992) over
random test sampling . For the above reasons, ALfor classification has been applied successfully in practice
(Lewis & Gale, 1994; Roy & McCallum, 2001; Goudjil et al., 2018; Warmuth et al., 2003; Pasolli & Melgani,
2010; Saito et al., 2015; Bressan et al., 2019; Sener & Savarese, 2018; Beluch et al., 2018; Haut et al., 2018;
Tong & Chang, 2001; He, 2010). In contrast, the performance gain of ALfor regression is more limited in the
sense that, under weak assumptions, we are tied to the decay law of the generalization error of random test
sampling (Györfi et al., 2002; Willett et al., 2005).
GP uncertainty sampling There exists a lot of research on ALforGPR(Seo et al., 2000; Pasolli &
Melgani, 2011; Schreiter et al., 2015; Yue et al., 2020), which is typically based on minimizing prediction
uncertainties of the model. With our proposed ALapproach being based on GPRmodels, this research area
is the most related competitor to our work.
For a standard GPRmodel, the prediction uncertainty is the higher the farther away we move from
training inputs. In this way, GP uncertainty sampling samples (pseudo -)uniformly from the input space
which makes up for a low-dispersion sequence (Niederreiter, 1988) (see Definition 5). Note that standard
GP uncertainty sampling is an input space geometric argument since it does not depend on the regression
function to infer. As already indicated in the introduction and as we will show in Sec.5.1, input space
geometric arguments feature no benefit regarding asymptotic AL performance.
Since our model is a mixture of GPRexperts, it is straightforward to derive its uncertainty as a mixture of
Gaussian process uncertainties (MoGPU) by simply weighting the predictive variances of all experts with
respect to the gate output (see (32)for a definition). As opposed to GP uncertainty sampling ,MoGPU can
cope with structural inhomogeneities. Therefore, we consider MoGPU as a fair baseline competitor to our
superior sampling scheme and compare both in Sec. 5.1.
6Published in Transactions on Machine Learning Research (12/2023)
3 Preliminaries
We will now give a formal definition of the regression task, the ALobjective and LOB, and a short review
of the asymptotic results on LFCand the optimal training distribution of the LPSmodel in Sec.3.1 and
3.2. Then we recap asymptotic results on the optimal bandwidth of GPRinSec.3.3 and known models in
Sec. 3.4 that will serve as building blocks of our proposed adaptive bandwidth MoE model later on.
In the following, we denote by diag (z)∈Rd×dthe diagonal matrix with the entries of the vector z∈Rdon
its diagonal and by Id=diag ( 1d)the identity matrix, where 1dis the vector of ones in Rd.
3.1 Formal definition of the regression task and AL objective
Letfbe the target regression function defined on an input space X⊂Rdthat we want to infer from noisy
observations yi=f(xi) +εi, wherexi∈Xare the training inputs and εiis independently drawn noise
from a distribution with mean E[εi] = 0and local noise variance V[εi] =v(xi). We denote a training set
by(Xn,Yn), whereXn= (x1,...,xn)∈XnandYn= (y1,...,yn)∈Rn. For a given model class /hatwidefthat
returns a predictor /hatwidefXn,Ynfor a training set (Xn,Yn), we can define the pointwise conditional mean squared
errorof/hatwidefinx∈X, givenXn, by
MSE/parenleftig
x,/hatwidef|Xn/parenrightig
=EYn/bracketleftig
(/hatwidefXn,Yn(x)−f(x))2/bracketrightig
=Eεn/bracketleftig
(/hatwidefXn,f(Xn)+εn(x)−f(x))2/bracketrightig
. (1)
Note that via marginalization the conditional mean squared error is no function of the training labels Yn.
Given a test probability density q∈C0/parenleftbig
X,R+/parenrightbig
such that/integraldisplay
Xq(x)dx= 1, theconditional mean integrated
squared error of the model under the given training set is then defined as
MISE/parenleftig
q,/hatwidef|Xn/parenrightig
=/integraldisplay
XMSE/parenleftig
x,/hatwidef|Xn/parenrightig
q(x)dx. (2)
With these preparations, the AL task is to construct a training dataset (X′
n,Y′
n)such that
X′
n≈argminXn∈XnMISE/parenleftig
q,/hatwidef|Xn/parenrightig
. (3)
3.2 Locally optimal bandwidths, function complexity, and optimal training
Let/hatwidefΣbe a family of kernel machines which is characterized by a positive definite bandwidth matrix
parameter Σ∈Sd
++of an RBF kernel kΣ(x,x′) :=|Σ|−1ϕ(∥Σ−1(x−x′)∥)for a monotonically decreasing
functionϕ:R+→R+. The well known Gaussian kernel is for example implemented by ϕ(z) = exp{−1
2z2}.
Given a bandwidth space S⊆Sd
++we define the LOB function of /hatwidefby
Σn
/hatwidef(x) =argminΣ∈SMSE/parenleftig
x,/hatwidefΣ|Xn/parenrightig
, (4)
assuming that this minimizer uniquely exists for all x∈X.
Denote by mΣ
Qthe predictor of the LPSmodel of order Qunder bandwidth Σand by Σn
Q:= Σn
mQthe
LOBfunction (4)ofLPS, if it is well-defined. This is the case, e.g., for the isotropic bandwidths space
S={σId|σ>0}under mild assumptions2, where we particularly can write Σn
Q(x) =σn
Q(x)Id. We refer to
Appendix A for details on the LPS model and asymptotic results. For the optimal predictor
/hatwidefQ
LPS:=mΣn
Q(x)
Q (x) (5)
2ForLOBbeing well-defined in the isotropic case, we generally require a non-vanishing bias and variance in terms of a
bias-variance-decomposition of the MSEof the predictor in x, for all x∈X. See, e.g., Eq. (36)for theLPSpredictormQ, or
Silverman (1986); Wand & Jones (1994) in more general.
7Published in Transactions on Machine Learning Research (12/2023)
ofLPS, letting/hatwidef=/hatwidefQ
LPSin Eq.(3), Panknin et al. (2021) have shown that there exists an optimal training
densitypQ,n
Optthat allows the optimal training inputs in Eq. (3)to be asymptotically obtained by independently
and identically sampling X′
n∼pQ,n
Opt. They have also shown that this density exhibits a closed-form
pQ,n
Opt(x)∝/bracketleftbig
Cn
Q(x)q(x)/bracketrightbig2(Q+1)+d
4(Q+1)+dv(x)2(Q+1)
4(Q+1)+d(1 +o(1)), (6)
where for an arbitrary training dataset (Xn,Yn)withXn∼p, the LFC of LPS is defined by
Cn
Q(x) :=/bracketleftbiggv(x)
p(x)n/bracketrightbiggd
2(Q+1)+d/vextendsingle/vextendsingleΣn
Q(x)/vextendsingle/vextendsingle−1=/bracketleftbiggv(x)
p(x)n/bracketrightbiggd
2(Q+1)+d
σn
Q(x)−d. (7)
TheLFCin(7)asymptotically solely depends on the behavior of fas opposed to p,v, andn: It scales with
the local variation of fin the vicinity of x. For example,
Cn
1(x)∝trace (D2
f(x))2d
2(Q+1)+d(1 +o(1)) (8)
is a function of the trace of the Hessian of f(Fan et al., 1997).
The optimal density pQ,n
Optin(6)implies that we require more training data where the problem is locally
more complex (large Cn
Q) or noisy (large v), or where test instances are more likely (large q). As already
noted in the introduction, the results to LFCand the optimal training density of LPSindicate their problem
intrinsic nature, as they reflect no direct dependence on the LPSmodel except for the order Q. Note that
forf∈Cα(X,R), there is a canonical choice Q=⌈α⌉−1of theLPSmodel order. When deriving LFC
under this canonical-order model, we consider the dependence of the associated LFCand the optimal training
density onQnegligible, as its choice is driven by the problem intrinsic regularity.
In practice, we obtain X′
n∼pQ,n
Optby estimating Eq. (6)and(7)from (Xn′,Yn′)withXn′∼pfor an arbitrary
training density p, wheren′<n, followed by adding the remaining n−n′inputs appropriately (see Sec.4.2).
The construction of pQ,n
Optcrucially depends on reliable estimates of LOBas the key ingredient for the estimation
ofLFC. While Panknin et al. (2021) provide such an estimate based on Lepski’s method (Lepski, 1991;
Lepski & Spokoiny, 1997), it does not scale well with increasing input space dimension d. This is because
pointwise estimates suffer from the curse of dimensionality regarding robustness and computational feasibility.
The goal of this work is to implement the above ALframework but based on a functional LOBestimate in
the domain of GPRinstead of LPS, since the GPRmodel class can naturally deal with high input space
dimensions (Williams & Rasmussen, 1996). Relying on the model-agnosticity, we expect that LOBestimates
based on LPScan be exchanged for LOBestimates based on GPRin the formulation of LFCandpQ,n
Optwhen
matching the degree Qto the smoothness of the regression function appropriately.
3.3 On the scaling of GPR bandwidths
The major difference between LPSandGPRis that we keep a fixed model complexity—in the sense of the
number of basis functions—in the former while there is varying model complexity in the latter as we add
further training instances. E.g., under the Gaussian kernel the model complexity of GPRgrows infinitely.
When the regularity of the kernel and the target function fmatch, then, as soon as the training size n
becomes large enough, there is no need for further shrinkage of the bandwidth to reproduce fwithGPRin
the asymptotic limit. In particular, given enough samples, there is no need for local bandwidth adaption.
However, there is a mismatch if f∈Cα(X,R)isα-times continuously differentiable since the Gaussian kernel
is infinitely often continuously differentiable. As shown by Van der Vaart et al. (2007; 2009), in order to
obtain optimal minimax -convergence of the predictor (except for logarithmic factors), the associated (global)
bandwidth has to follow the asymptotic law
Σn
GPR∝n−1
2α+d. (9)
Note that for f∈Cα(X,R), where the theoretical results of LPSapply, the scaling factor n−1
2α+dofLOB
in sample size matches exactly for both classes, LPSandGPR. In our work, we will use (9)to deduce a
GPR-based LFC estimate in analogy to the LPS-based LFC estimate (7) by Panknin et al. (2021).
8Published in Transactions on Machine Learning Research (12/2023)
3.4 Preliminaries on the applied models
We will now introduce the models that we implement in this work. For the RBF-kernelk, we define the kernel
matrix between X∈XnandX′∈XmasKΣ(X,X′) =/bracketleftbig
kΣ(x,x′)/bracketrightbig
x∈X,x′∈X′. As a shorthand notation we
furthermore define KΣ(X) :=KΣ(X,X ).
3.4.1 Sparse variational Gaussian processes
We define the sparse GPRmodel/hatwidey∼SVGP (θ)(see, e.g. Williams & Rasmussen (1996); Hensman et al.
(2015)) as follows: The sparse GP is described by the (hyper-) parameters θ= (µ,λ,/hatwidev,Σ,X†,µ†,S†), which
are the global constant prior mean µ, the regularization parameter λ, the label noise variance function /hatwidev, the
bandwidth matrix Σof the kernel and the prior distribution, given by the IP locations X†∈Xmas well as
their inducing value distribution, characterized by the moments µ†andS†. That is, for the inducing values
Y†ofX†we assumeY†=/hatwidey(X†)∼N(·;µ†,S†). Here, the degree of sparsity is described by mIPs: This
number can be fixed in advance or gradually increased with training size n, where the increase mn=o[n]is
typically much slower than n. If we can assume homoscedastic noise, we let /hatwidev(x)≡σ2
ε.
The sparse GP then outputs
/hatwidey(X∗)∼N(·;µ∗(X∗),C∗(X∗)|θe) (10)
for the mean function
µ∗(X∗) =K∗†K−1/2
†(/tildewideµ†−K−1/2
†µ(X†)) +µ(X∗), (11)
and the covariance function
C∗(X∗) =λ/bracketleftig
K∗+K∗†K−1/2
†(/tildewideS†−Im)K−1/2
†K⊤
∗†/bracketrightig
+diag (/hatwidev(X∗)), (12)
where/tildewideµ†=K−1/2
†µ†and/tildewideS†=K−1/2
†S†K−1/2
†are the whitened moments of the inducing value distribution
(Pleiss et al. (2020), Sec. 5.1), and we have defined K∗=KΣ(X∗),K†=KΣ(X†)andK∗†=KΣ(X∗,X†).
We chooseµto be the constant mean function, i.e., µ(X) =µ 1nforX∈Xn, noting that other mean
functions are possible. Note that test predictions /hatwidefGP(x) =µ∗(x)are given by Eq. (11).
The training objective LetPdenote the prior distribution of the inducing function values Y†of the
IPsX†and letQdenote a tractable variational distribution intended to approximate P(·)≈Q(·|Xn,Yn).
Invariational inference , we want to minimize the Kullback-Leibler divergence KL[Q∥P]betweenQandP,
which is equivalent to maximizing the data log-evidence log(P(Xn,Yn)). As a tractable approximation, we
maximize the evidence lower bound (ELBO), given by
Eu∼Q(·|Xn,Yn)log(P(Xn,Yn|u))−KL [Q(·|Xn,Yn)∥P]
≈1
n/summationdisplayn
b=1Pb−KL [Q(·|Xn,Yn)∥P], (13)
wherePbis the predictive log-likelihood in xb, marginalized over the variational distribution Q, that is,
Pb:=Eu∼Q(·|Xn,Yn)log/integraldisplay
P(yb|f)P(f|u,xb)df. (14)
3.4.2 Sparse mixture of experts
Given a finite set of expert models /hatwideylthat are parameterized by θel, the MoE model is given by
/hatwidefMoE(x) =/summationdisplayL
l=1G(x)l/hatwideyl(x), (15)
where the gateG:X → [0,1]Lis a probability assignment of an input xto the experts. In particular, it
holds/summationdisplayL
l=1G(x)l≡1andG(x)i≥0,∀x∈Xand1≤i≤L.
9Published in Transactions on Machine Learning Research (12/2023)
We implement the approach of Shazeer et al. (2017) to model the gate Gas follows: For the softmaxfunction
softmax (a)i:= exp{ai}/slashig/summationdisplayL
l=1exp{al}, (16)
wherea∈RL, Shazeer et al. (2017) propose to set
G(x) =softmax (/tildewideh1(x),...,/tildewidehL(x)),where/tildewidehil(x) =/braceleftigg
hil(x),l<κ
−∞,l≥κ+ 1(17)
for an adequate permutation (i1,...,iL)of{1,...,L}such thathil(x)>hil+1(x)are ordered decreasingly.
Here,hl(x) =gl(x) +N(0,s2
l)is a noisy version of single-channel gating models glwith parameters θgl. Note
that these models can be chosen freely and may also deviate from the choice of expert models /hatwideyl.
The cutoff value 1≤κ≤Lcontrols the sparsity of the MoE, as it enforces the minor mixture weights to
strictly equal zero. For stability reasons, during the training, we give each expert a chance to become an
element of the top- κcomponents by adding independent Gaussian noise N(0,s2
l)before thresholding, where
s∈RL
++is another hyperparameter to set or learn. This noisy gating prevents a premature discarding of
initially underperforming experts.
The overall MoE hyperparameter set is thus given by
Θ = ({θel}L
l=1,{θgl}L
l=1,κ,s). (18)
4 Estimating locally optimal bandwidths via mixture of Gaussian processes
In this section, we derive our main contribution, namely the GPR-basedALframework, which we summarized
inFig.2. We first derive our GPR-based estimates of LFCand thesuperior training density inSec.4.1
(Fig.2, B). Combining this estimate with the ALframework from Panknin et al. (2021), we obtain a GPR-
based, model-agnostic superior sampling scheme inSec.4.2 (Fig.2, C). Next, we describe our GPR-based
MoEmodel in Sec.4.3 (Fig.2, A) of which we obtain the required LOBestimate of GPRfor the estimation
ofsuperior training density . The scalability of this estimate enables the application of our superior sampling
schemeto problems of high input space dimensions. We then give details on the training of the MoEin
Sec.4.4 and finally propose an LFC-based IP selection method in Sec.4.5. We summarize the pseudo-code of
oursuperior sampling scheme in Algorithm 1.
4.1 GPR-based LFC and the superior training density
LetΣn
GPR(x)denote the LOBfunction (4)ofGPR. Inspired by the results to LFCand thesuperior training
densityofLPSin Eq.(7)and(6), we are able to deduce their GPR-based analog. Here, we need to take
into account that GPRadapts universally3to functions f∈Cα(X,R), as opposed to LPS, whose decay
rate is determined by the specified polynomial order Q. The idea of the LFCestimate was to adjust LOB
appropriately so that it becomes invariant under the influence of the training density, heteroscedasticity, and
its global decay with respect to the training size n.
Combining the local effective sample size p(x)nwith the scaling result of the global Σn
GPRin(9)fromSec.3.3,
we propose an LFC estimate for GPR as follows (see Appendix C for proof details).
Theorem 1 (LFCofGPR).Forf∈Cα(X,R),Xn∼pand homoscedastic noise, the GPR-basedLFC
estimate of finx∈Xis asymptotically given by
Cn
GPR(x) :=/bracketleftbigg1
p(x)n/bracketrightbiggd
2α+d
|Σn
GPR(x)|−1. (19)
In analogy to Eq. (7),Cn
GPRmeasures the structural complexity of f, as it asymptotically does not depend
onp,vandn. Note that the LPSmodel provides no explicit way to adapt to the local noise variance v(x),
3That is, the MISE decays at the minimax-rate n−2α
2α+dof nonparametric models.
10Published in Transactions on Machine Learning Research (12/2023)
Experts
GateMoE
query label    of
A
B C
Figure 2: The proposed AL framework.
such that the LOBofLPSscales with respect to vto address heteroscedasticity (see (36)inAppendix A).
ForGPR, we have made the restriction of homoscedastic noise in the definition of Cn
GPRinTheorem 1,
since we are not aware of a theory on the scaling of GPR-basedLOBwith respect to heteroscedasticity.
However, as opposed to LPS, a heteroscedastic GPRmodel provides an explicit way to adapt to the local
noise variance v(x)via regularization. As a result, we observe only very little influence of heteroscedasticity
onLOBfunction, which we will demonstrate in Sec.5.1. Thus, Cn
GPRwill be sufficiently calibrated in a
heteroscedastic scenario, making it a reasonable estimate of LFC in practice without further restrictions.
Now, when putting Cn
GPRinto Eq. (6) with Q=α−1, we obtain the superior training density
pGPR,n
Sup (x)∝[Cn
GPR(x)q(x)]2α+d
4α+dv(x)2α
4α+d(1 +o(1)). (20)
For evenα∈NwithQ=α−1andCn
GPR≡Cn
Q,pGPR,n
SupandpQ,n
Optcoincide, which proved to be optimal for
LPS. In this sense, (20)generalizes (6)to the general case of α∈R+, where we expect that the true optimal
training density for f∈Cα(X)will not deviate by a lot from pGPR,n
Sup. SinceLPSandGPRare related models,
we furthermore expect Cn
GPRto be similar to Cn
Qfor the appropriate order Q.
Note that for f∈C∞(X), we letα→∞in Eq. (19) and (20) to obtain
Cn
GPR(x) =|Σn
GPR(x)|−1andpGPR,n
Sup (x)∝[Cn
GPR(x)q(x)v(x)]1
2. (21)
WhileXn∼pGPR,n
Supwill not be optimal for our model, we expect it to be asymptotically superior to the
naiverandom test sampling , i.e.,Xn∼q, due to the model-agnosticity of the LPS-based result. To assess
the asymptotic performance of a training density p(such aspGPR,n
Sup), let us first observe the following:
For regression problems and under weak assumptions the law of the MISEdoes not change with respect
top, except for a constant multiple (Györfi et al., 2002; Willett et al., 2005). Accordingly, the number of
actively selected training samples ( ∼p) that are required to achieve the same level of accuracy of random
test sampling is given by a constant ϱ>0. Formally, we can define ϱas follows.
11Published in Transactions on Machine Learning Research (12/2023)
Algorithm 1: Superior training data process (Xn,Yn)n∈Nwith labelsYnof training inputs Xnd→pGPR,n
Sup
Input
1: Intermediate training sizes (nk)k∈N0withnk<nk+1,∀k∈N0for reestimation
2: A labeled validation set Xval,Yval
3: An input generating process Xpool∈XNwithXpool∼pX
4: The label oracle y:X →R
5: (optional) The test density q
6: (optional) The intrinsic dimension δ≤dof the input space X
7: (optional) The regularity αof the target function f∈Cα(X,R)
Output
8: (Infinite) training data process (Xn,Yn)with labelsYnof training inputs Xn∼pGPR,n
Sup
Procedure
9:▷Initialization
10: Estimate pool density /hatwidepXbased onXpool▷e.g., using kernel density estimation
11:ifqis not specified then
12: Set q←/hatwidepX
13:ifδis not specified then
14: Estimate δbased onXpool▷e.g., following the work of Facco et al. (2017)
15:ifαis not specified then
16: Set α←∞ ▷as discussed in Sec. 6
17: Setp0←q
18: Draw initial training inputs Xn0∼p0
19: Query labels Yn0←y(Xn0)from the oracle
20: Set (ΘH,ΣE)←hyper_init (Xn0,Yn0,p0,Xval,Yval) ▷see Algorithm 2 in Appendix D
21:▷Sample Process
22:fork∈N0do
23: ifk>0then
24: Update IP locations XE
†,XG
†∈ΘH, whereXE
†,XG
†∼/radicalig
pk·/hatwideCnk−1
GPR▷see (29) in Sec. 4.5
25: ifk== 1 then
26: Gradually decrease mE=/vextendsingle/vextendsingleXE
†/vextendsingle/vextendsingleandmG=/vextendsingle/vextendsingleXG
†/vextendsingle/vextendsingleas long as the validation performance of /hatwidefMoEdoes not degrade
as discussed in Sec. 4.4.3
27: Train the model /hatwidefMoEfrom Sec. 4.3 with hyperparameters ΘHon(Xnk,Ynk)as described in Sec. 4.4
28: Estimate the LOB /hatwideΣnk
GPRof GPR according to (24)
29: Estimate the LFC /hatwideCnk
GPR←/bracketleftbig
1/slashbig
pk(x)/bracketrightbig 1
2α+d/vextendsingle/vextendsingle/hatwideΣnk
GPR(x)/vextendsingle/vextendsingle−1according to (22)
30: Estimate the superior training density /hatwidepGPR,nk
Sup←/bracketleftbig/hatwideCnk
GPR(x)q(x)/bracketrightbig2α+d
4α+d/hatwidev(x)2α
4α+daccording to (23)
31: Set γ1= maxx∈Xpk(x)/slashig
/hatwidepGPR,nk
Sup (x)andγ2= max/braceleftbig
0,(0.5−γ−1
1)/slashbig
(1−γ−1
1)/bracerightbig
▷see Sec. 4.2
32: Set pk+1←γ2pk+ (1−γ2)/hatwidepGPR,nk
Sup
33: Set/tildewidepk+1←2pk+1−pk ▷see Sec. 4.2
34: Draw Xnk+1,...,Xnk+1∼/tildewidepk+1via importance sampling from Xpoolas described in Sec. 4.2
35: Query labels ynk+1,...,ynk+1←y(Xnk+1,...,Xnk+1)from the oracle
36: SetXnk+1←Xnk∪{Xnk+1,...,Xnk+1}andYnk+1←Ynk∪{ynk+1,...,ynk+1} ▷ThenXnk+1∼pk+1
Definition 2. Over the space of square-integrable functions f∈L2(X), for a nonparametric regression
model/hatwidefand a training density p, we define by ϱ(/hatwidef,p)>0the relative required sample size such that for
n′=ϱ(/hatwidef,p)n,X′
n′∼pandXn∼qit holds that
MISE/parenleftig
q,/hatwidef|Xn/parenrightig
=MISE/parenleftig
q,/hatwidef|X′
n′/parenrightig
(1 +o(1)).
Thus, a training density pis asymptotically superior to random test sampling , ifϱ(/hatwidef,p)<1, since we achieve
the same performance as random test sampling with only a fraction of the number of training samples. In
Sec. 5 we will demonstrate the superiority of the training density pGPR,n
Supfor our GPR-based MoE model.
Respecting the intrinsic dimension in high-dimensional input spaces In Eq.(19),(20)and(21)we
assume the input space Xto have full degrees of freedom d, which in practice is particularly not the case
12Published in Transactions on Machine Learning Research (12/2023)
in high-dimensional feature spaces. For an intrinsic dimension δ < dofX, we adjust as follows: For the
spaceS={σΣ|σ>0}of bandwidth candidates that are essentially isotropic up to a fixed, shared positive
definite factor Σ∈Sd
++that is, e.g., calculated in a pre-processing step, let Σn
GPR(x) =σn
GPR(x)Σbe theLOB
function of GPRwith respect toS. Then we replace all occurrences of dforδand|Σn
GPR(x)|forσn
GPR(x)δ
in Eq. (19), (20) and (21).
Besides being an ingredient to AL,LFCcan also be used to reduce the required model complexity. For
example, in an RBF-network or a sparse GPRmodel, we can coarsen or refine the model resolution by placing
an adequate amount of basis functions or IPs, respecting LFC. We will discuss this choice in Sec.4.5 and
demonstrate its ability to reduce the overall model complexity in Sec.5.1. Finally, LFCcan be inspected
to obtain deeper insights into the research field of the regression problem, which is particularly hard for
high-dimensional data (see Sec. 5.2).
4.2 The active learning framework
Starting with an initial training set Xn0,Yn0of sizen0withXn0∼p0for some initial training distribution
such asp0≡q, we implement the online sampling procedure as described in Panknin et al. (2021), such that
Xn∼pGPR,n
Supasn→∞. We grow the training set as follows:
Given the current training set Xnk,Ynkwe estimate/hatwideΣnk
GPRas described in Sec. 4.3. Using (19), (20), it is
/hatwideCnk
GPR(x)∝/bracketleftbig
1/slashbig
pk(x)/bracketrightbig 1
2α+d/vextendsingle/vextendsingle/vextendsingle/hatwideΣnk
GPR(x)/vextendsingle/vextendsingle/vextendsingle−1
,and (22)
/hatwidepGPR,nk
Sup (x)∝/bracketleftig
/hatwideCnk
GPR(x)q(x)/bracketrightig2α+d
4α+d/hatwidev(x)2α
4α+d. (23)
Letting the next sample size be nk+1= 2nk, we have already drawn half the samples of nk+1according to a
potentially different distribution pkthan the new proposed /hatwidepGPR,nk
Sup. The closest we can get in distribution to
/hatwidepGPR,nk
SupisgivenbyXnk+1∼pk+1, wherepk+1:=γ2pk+(1−γ2)/hatwidepGPR,nk
Sup, forγ2=max/braceleftbigg
0,0.5−γ−1
1
1−γ−1
1/bracerightbigg
∈[0,0.5)
andγ1=max
x∈Xpk(x)
/hatwidepGPR,nk
Sup (x). This is achieved by sampling xnk+1,...,xnk+1∼/tildewidepk+1for/tildewidepk+1= 2pk+1−pk,
which is a valid probability density (Panknin et al., 2021).
Adaptions in the pool-based active learning scenario In theALframework described above, we
deal with properly normalized probability densities. But in the pool-based ALscenario such normalization
is usually impossible since our information about the input space Xis restricted to a large, unlabeled pool
of samplesXpool∈XN. This pool follows a distribution Xpool∼pX, for which it is common to assume an
(unnormalized) density estimate /hatwidepXto be given: Unlabeled inputs are considered cheaply accessible, whereas
querying labels is expensive.
For ourALframework to be applicable, it suffices to keep all considered densities such as /hatwidepGPR,nk
Supat equal
norm, which we can enforce via normalizing a density pby¯p=p/norm (p), where
norm (p) =/vextendsingle/vextendsingleXpool/vextendsingle/vextendsingle−1/summationdisplay
x∈Xpoolp(x)//hatwidepX(x).
To see this, note that first of all /hatwidepXis an unnormalized estimate of pXsuch that we can write /hatwidepX≈c·pXfor
some unknown constant c>0. On the one hand, it is/integraldisplay
X/hatwidepX(x)dx=cby definition. On the other hand, it is
norm (p)≈/integraldisplay
Xp(x)
/hatwidepX(x)pX(x)dx=1
c/integraldisplay
Xp(x)dx,
such that also/integraldisplay
X¯p(x)dx=1
norm (p)/integraldisplay
Xp(x)dx≈cholds for any unnormalized density p.
Subsequently, the required samples xnk+1,...,xnk+1∼/tildewidepk+1are obtained via importance sampling from the
pool with importance weights P(xi=x)∝/tildewidepk+1(x)/[norm (/tildewidepk+1)/hatwidepX(x)]forx∈Xpoolandnk+ 1≤i≤nk+1.
13Published in Transactions on Machine Learning Research (12/2023)
4.3 Sparse mixture of Gaussian processes
Recall the sparse MoE model (15) from Sec. 3.4.2, given by
/hatwidefMoE(x) =/summationdisplayL
l=1G(x)l/hatwideyl(x),
where the gate G:X → [0,1]Lis a probability assignment of an input xto the expert models /hatwideyl. In particular,
it holds/summationdisplayL
l=1G(x)l≡1andG(x)i≥0,∀x∈Xand1≤i≤L. According to (18), besides the expert and
gate model parameters {θel}L
l=1and{θgl}L
l=1, thisMoEapproach has two hyperparameters, κands, for
controlling the sparsity of the gate and adding noise to the gate responses during the training to escape local
optima.
We choose the expert models as well as the single channel gating models to be sparse variational GPs
(Williams & Rasmussen, 1996; Hensman et al., 2015), that is, /hatwideyl∼SVGP (θel)andgl∼SVGP (θgl), which
are parameterized by θelandθgl, as described in Sec.3.4.1. The overall MoEhyperparameter set is thus
given by Θ = ({θel}L
l=1,{θgl}L
l=1,κ,s).
We will keep certain hyperparameters of Θconstant after initialization, and share some hyperparameters
across experts and the channels of the gate: While the covariances of the inducing value distributions
S†∈θ,θ∈Θcould be full positive definite matrices, we apply S†= 0throughout, giving favorable stability
and computational efficiency. For the same reasons, we fix the inducing point (IP) locations X†∈θ,θ∈Θ
after initialization. Furthermore, we share the IP locations among the experts, respectively the gate channels,
such that for X†∈θelwe applyX†=XE
†and forX†∈θglwe applyX†=XG
†, for all 1≤l≤L.
In this work, our goal is to fit a single, coherent regression problem by a MoEapproach. Therefore, we
propose to share all the parameters across the experts that characterize the regression function rather than
the expert model. That is, we share the mean µE, the regularization parameter λE, and the noise variance
function/hatwidev, respectively the global noise variance σ2
εwith/hatwidev(x)≡σ2
εin case of homoscedasticity. Furthermore,
we apply a fixed, logarithmically spaced set of individual expert bandwidth scaling factors σ1<...<σ L
that are multiplied by a fixed, shared bandwidth matrix ΣE. Our expert parameters therefore reduce to
θel= (µE,λE,/hatwidev,σlΣE,XE
†,µel
†,0).
Remark 3. Recall from Sec.2 that it is possible to replace the variational GPRexpert models for full as
well as sparse analytic GPRformulations (see Appendix B). With slight abuse of notation, these cases are
subsumed by setting µel
†=∅orXE
†=µel
†=∅for sparse, respectively full analytic GPR.
Since our objective does not incorporate any likelihood about the gate’s output, there is no noise function to
fit for the gate, such that we set /hatwidev≡0for/hatwidev∈θgland all 1≤l≤L. Each output channel of the gate poses
its own classification problem, which is why we do not share the means. Yet, we share the regularization
parameter and the bandwidth, as the individual channels should be structurally similar. Our gate parameters
therefore reduce to
θgl= (µgl,λG,0,σGId,XG
†,µgl
†,0).
After training as described in Sec.4.4, this MoEcan cope with a varying structural complexity through
the individual bandwidth scaling factors σlof the experts and heteroscedastic noise through the adaptive
regularization. Additionally, we can now use the gate of our MoE to propose an LOB estimate of GPR.
AGPR-basedLOBestimate After training of the MoE, we use the learned gate Gfrom(15)to predict
Σn
GPR(x)as
/hatwideΣn
GPR(x) =/hatwideσn
GPR(x)ΣE,where/hatwideσn
GPR(x) = exp/braceleftbigg/summationdisplayL
l=1G(x)llog(σl)/bracerightbigg
. (24)
Due to the finite candidate set σ1,...,σLwe are limited to measure a quantization of Σn
GPR(x)through
G(x)l=P(Σn
GPR(x) =σlΣE). If, in fact, Σn
GPR∈{σ1ΣE,...,σLΣE}holds true, then there exists an index
functionj(x)∈{1,...,L}such that Σn
GPR(x) =σj(x)ΣE. In this case, we are able to exactly recover LOB
14Published in Transactions on Machine Learning Research (12/2023)
withG(x)l=/braceleftigg
1, l=j(x)
0,else. In any other case, the estimate (24)ofLOBis a reasonable interpolation, which
deviation from Σn
GPRcan be controlled by the number of bandwidth candidates of the MoE.
4.4 Model training
This section is devoted to the training of the model described in Sec.4.3. We first set up the training objective
inSec.4.4.1 and describe the training procedure of our model in Sec.4.4.2, where we identify hyperparameters
of the approach. Then, we discuss how to choose the essential hyperparameters systematically on the initial
training dataset in Sec. 4.4.3.
4.4.1 The training objective
First, we will set up the objective function for training our MoE model in batch mode .
The main objective Denote by ∅ ⊊B⊆{ 1,...,n}the indices of a batch, and let wB=/summationdisplay
b∈Bw(xb)for
the training importance weight function w∝q/p. LetPlbe the prior distribution of the inducing function
values of the l-th expert and Qlthe corresponding variational distribution as defined in Sec.3.4.1. We choose
the (through the gate G) weighted sum of the individual expert negative ELBO objectives (13), denoted by
Obj(Xn,Yn,B,w,Θ) =−/summationdisplayL
l=1/bracketleftig
w−1
B/summationdisplay
b∈Bvl(xb)Pb,l−1
nlKL[Ql(·|Xn,Yn)∥Pl]/bracketrightig
,
as our main objective, where nl=nwB/νB,lforνB,l=/summationdisplay
b∈Bvl(xb)withvl(x) =G(x)lw(x)and
Pb,l=Eu∼Ql(·|Xn,Yn)log/integraldisplay
Pl(yb|f)Pl(f|u,xb)df
is the predictive log-likelihood (14)of the l-th expert in xb, marginalized over its variational distribution Ql.
A penalty on small bandwidth choices In the spirit of Lepski’s method (Lepski, 1991; Lepski &
Spokoiny, 1997), we prefer the largest choice of bandwidth out of all candidates that perform comparably
well. In order to enforce this, we penalize smaller bandwidth choices by adding the following term:
penσ(Xn,Yn,B,w,Θ) =2
(L−1)/summationdisplayL
l=1νB,l(L−l)/slashbig/summationdisplayL
l=1νB,l. (25)
Note that penσ(Xn,Yn,B,w,Θ) = 1ifνB,1=...=νB,L. Our total objective then amounts to
Obj(Xn,Yn,B,w,Θ) =Obj(Xn,Yn,B,w,Θ) +ϑσpenσ(Xn,Yn,B,w,Θ). (26)
Remark 4. If we assume our problem to be (almost) noise-free, we replace the Objin our objective (26)for
themean squared error
MSE (Xn,Yn,B,w,Θ) =w−1
B/summationdisplay
b∈Bw(xb)∥yb−/hatwidey(xb)∥2.
4.4.2 Training procedure
We implement our model in PyTorch (Paszke et al., 2019), using the GPyTorch -package (Gardner et al., 2018).
Given the training set (Xn,Yn), we minimize the objective described in Sec.4.4.1 via ADAM-optimization
(Kingma & Ba, 2015). It remains to identify those variables of the MoEthat will be adapted as parameters
during the training. Then, the remaining variables are hyperparameters that need to be specified or tuned
through an external validation step.
Recall from Sec.4.3 that the MoEhas two further hyperparameters, κfor enforcing sparse gate responses
and a noise term on the gate responses during the training, which is controlled by s. Instead of learning sas
a parameter during the training—like proposed by Shazeer et al. (2017)—we propose to shrink s←sηsafter
15Published in Transactions on Machine Learning Research (12/2023)
each training epoch, for a multiplicative factor ηs<1and an initial value s:=s0as hyperparameters. We
discuss this heuristic choice in Appendix F.
We require appropriate learning rates for the optimization of the parameters and tunable hyperparameters of
the model. Generally, we suggest applying an adaptive base learning rate η, where we shrink η←ηi:=1
2ηi−1
for an initial base learning rate η0during the training as soon as the validation performance gets stuck until
ηicrosses a lower threshold, e.g., ηi<η0/1000. Note that, relative to the base learning rate, good learning
rates for the individual types of tunable parameters should be deployed: Within a GP component SVGP (θ)
withθ= (µ,λ,/hatwidev,Σ,X†,µ†,S†), the hyperparameters (µ,λ,/hatwidev)must be updated on a smaller scale than the
inducing value distribution, given by (µ†,S†). In this regard, let ηH≤1be the factor such that, if we update
µ†at rateη, then we update (µ,λ,/hatwidev)at rateηHη.
Similarly, we need to update the gate parameters θglon a smaller scale than the expert parameters θel. In
this regard, let ηG≤1be the factor such that, if we update θelat rateη, then we update θglat rateηGη.
The set of hyperparameters that require off-training selection (e.g., via cross-validation) is thus given by
ΘH= (B,κ,{σl}L
l=1,σG,λG,XE
†,XG
†,s0,ηs,ϑσ,η0,ηH,ηG), (27)
whereas the overall set of parameters that get tuned while training is given by
ΘT= (µE,λE,/hatwidev,ΣE,µE
†,µG,µG
†). (28)
We provide further details on the design choices for our MoE model in Appendix F.
4.4.3 Choosing the hyperparameters
Since our MoEapproach is based on known building blocks (Williams & Rasmussen, 1996; Hensman et al.,
2015; Shazeer et al., 2017) we can train our model using well-established software libraries (Kingma & Ba,
2015; Paszke et al., 2019; Gardner et al., 2018), with the hyperparameters chosen by following best practice.
While the set of hyperparameters (27)appears to be large, most of them can be tuned in advance on the
initial training dataset of moderate size and held fixed in the subsequent training data refinement process.
Note that some hyperparameters impact the computational complexity rather than the model performance.
Thus, as long as they are not underestimated, their tuning is optional and will therefore be postponed:
•Since our MoEis robust concerning unnecessarily large choices of the gate output sparsity κ, we
initializeκ≡Lwhile choosing the remaining hyperparameters, followed by tuning κas the last
hyperparameter, where we successively reduce κuntil we observe a significant loss of performance of
the MoE.
•The numbers mE=/vextendsingle/vextendsingle/vextendsingleXE
†/vextendsingle/vextendsingle/vextendsingle,mG=/vextendsingle/vextendsingle/vextendsingleXG
†/vextendsingle/vextendsingle/vextendsingleof IPs of the expert and the gate are the main driver of the
computational complexity of our MoE. While unnecessarily large numbers will not hurt the model
performance, they should therefore be set to the smallest value that leads to no significant loss of
performance to keep the computational complexity of the model moderate at larger training sizes. In
the initial iteration, we use mE=n0for the experts and mG=n0
4, where the locations of the IPs
XE
†,XG
†∼pare chosen diverseas described in Appendix E. In the second iteration, where we have
first estimates of LFC,XE
†andXG
†are drawn as discussed in Sec.4.5. Here, we gradually decrease
mEandmGuntil we observe a significant loss of validation performance of the MoE. We holdmE
andmGfixed in subsequent iterations. Note that the IP locations are not subject to optimization.
The initial base learning rate and the expert’s internal hyperparameters learning rate ( η0,ηH) and the batch
sizeBthat are related to a single GPR expert rather than the whole MoE model:
•First, we hold ηH= 0.2,B=n0fixed at reasonable initial values and perform line search over η0
according to the resulting validation performance of a single, isotropic, sparse GPRexpert. Here, too
small values of η0result in slow convergence of the objective, in which case we interrupt the training
immediately and increase η0as long as the first objective updates are consistently decreasing.
16Published in Transactions on Machine Learning Research (12/2023)
•Next, we choose ηHaccording to the resulting validation performance of a single, isotropic, sparse
GPRexpert, where we gradually decrease ηH, starting from ηH= 1. Again, we interrupt the training
for too large choices of ηH, where the training objective will diverge.
•Finally, we choose Baccording to the resulting validation performance of a single, isotropic, sparse
GPR expert, where we gradually decrease B, starting from B=n0.
Next, we have to deal with the remaining hyperparameters that are related to the MoEmodel. For this,
we first initialize the less crucial hyperparameters at reasonable values, tuning them afterward: We apply
a set of experts with {σl}L
l=1, whereL= 7, andσl= 2l−4
δ, which are logarithmically spaced around
the global bandwidth estimate ΣEof the best-performing model that we obtained from the above tuning
of the hyperparameters related to a single GPRexpert. The noise added to the gate ( s0,ηs) as well as
the regularization ϑσof the bandwidth function are about fine-tuning of the model. We set them to
s0= 0.1,ηs= 1/√
2andϑσ= 0.01. We suggest to keep ηs= 1/√
2throughout without further tuning.
•Via grid search, we choose σG,λGaccording to the resulting validation performance of the MoE
model, where we gradually decrease the gate learning rate from ηG= 1.
As a last step, we choose the hyperparameters for fine-tuning of the MoE model:
•First, we perform line search over ϑσaccording to the resulting validation performance of the MoE.
•Next, we tune{σl}L
l=1: We observe that unreasonable bandwidths will be automatically dropped
during the training. Therefore, if the minimal or maximal candidate associated with σ1,σLis not
chosen during the training, we remove the respective expert and retrain the MoE. Vice versa, we
expand the bandwidth candidate range beyond σ1,σLwith a factor of 2∓1
δas long as the boundary
candidates are not dropped during the training.
•Finally, we perform line search over s0according to the resulting validation performance of the MoE.
4.5 Initializing the IP locations
Since the numbers of IPs of the gate XG
†, as well as the experts XE
†are the computational bottleneck of
our model, they should be chosen advisedly. We can interpret the choice of IPs as a nested ALtask at
small sample size. In the small sample size regime, input space geometric arguments have proven to be
robust and superior in comparison to naive approaches like random sub-sampling from the training inputs
(Teytaud et al., 2007; Yu & Kim, 2010; Wu, 2019; Liu et al., 2021). They are representative, respecting the
training distribution, and diverse (with low-dispersion ) so that they achieve an acceptable representation of
the dataset at the smallest possible number of IPs. By low-dispersion, we resort to the following definition:
Definition 5. Thedispersion , given by supx∈Xmin1≤i≤n∥x−xi∥(Niederreiter, 1988) is a measure of how
well spread out the training sample is. We say that a sequence has low-dispersion if its dispersion is lower
than the dispersion of random uniform sampling.
Indeed, by sampling the IPs in this manner, we can reduce the distance of an evaluation point xto its
closest neighbor in XE
†, which is known to reduce the reconstruction error of a full kernel matrix by a sparse
representation (Zhang et al., 2008).
In addition, recall that our derived LFCmeasure of local structural complexity quantifies the local variation
of the target function. Intuitively, we require more IPs to sense and reconstruct the target function where
this local variation is higher. In summary, we therefore propose to choose the IPs
XE
†,XG
†∼/radicalbig
p·Cn
GPR (29)
as thegeometric mean ofLFCand the training density Xn∼pin a diverse way. Here, we ensure diversity
by implementing distribution preserving clustering or particle repulsion as described in Appendix E.
17Published in Transactions on Machine Learning Research (12/2023)
5 Experiments
In this section, we will first analyze our approach on toy-data, regarding the MoEmodel,LFC, and the
superior training density . Then, we apply our approach to a high-dimensional MD simulation dataset from
quantum chemistry, by which we can deduce deeper insights into this regression problem.
We denote the root mean squared error (RMSE) and the maximum absolute error (maxAE) of a model/hatwideffor
a test setXT∈XNwithXT∼qby
RMSE (/hatwidef,Xn,Yn) =
1
N/summationdisplay
x∈XT/vextendsingle/vextendsingle/vextendsinglef(x)−/hatwidefXn,Yn(x)/vextendsingle/vextendsingle/vextendsingle2
1
2
and maxAE (/hatwidef,Xn,Yn) = max
x∈XT/vextendsingle/vextendsingle/vextendsinglef(x)−/hatwidefXn,Yn(x)/vextendsingle/vextendsingle/vextendsingle.
As already discussed in Sec.4.1, the learning rate is invariant under change of the training density Xn∼pin
the considered scenario. For our MoE model and f∈Cα(X,R)we, thus, can write
RMSE (/hatwidefMoE,Xn,Yn) =Cpn−τ(1 +o(1)), withτ=/braceleftigg
α
2α+d, α<∞
1/2, α =∞, (30)
whereCp>0is a constant depending on the training density p. Note that we can theoretically bound the
asymptotic RMSEfrom below by C∗n−τ, where we have defined C∗:=Cp∗withX′
n∼p∗being the optimal
training set from (3). Unfortunately, since p∗is unknown—even when given the ground truth—we are not
able to estimate C∗and, thus, provide a lower bound of the RMSE beyond the known learning rate n−τ.
As anALperformance measure, we use the relative required sample size from Definition 2 which can be
estimated for a GPR-based model such as our MoE and f∈Cα(X,R)according to
ϱ(/hatwidefMoE,p)≈/bracketleftbigg
RMSE (/hatwidefMoE,X′
n,Y′
n)
RMSE (/hatwidefMoE,Xn,Yn)/bracketrightbigg1
τ
(31)
where it isX′
n∼pandXn∼qwith respective labels Y′
nandYn. Using(31), we can compare the asymptotic
ALperformance of different ALsampling schemes in the following experiments. For example, we can quantify
the AL performance of our proposed AL framework by sampling X′
n∼/hatwidepGPR,n
Sup.
5.1 Doppler function
We will first demonstrate our approach on the Doppler function (see, for example, Donoho & Johnstone
(1994)), which was also discussed in related work that deals with inhomogeneous complexity (Panknin et al.,
2021; Bull et al., 2013). For x∈X= [0,1], let
P(y|x) =N(y;f(x),1), f(x) =C/radicalbig
x(1−x) sin (2π(1 +ϵ)/(x+ϵ)),
whereϵ= 0.05,Cis chosen such that ∥f∥2= 7andN(·;µ,σ2)denotes the Gaussian distribution with mean
µand variance σ2. We assume a uniform test distribution q∼U(X)in all Doppler function experiments.
This one-dimensional, homoscedastic toy-example allows for an easy and intuitive visualization. Fig.3 shows
an example dataset as blue dots and the true function fto infer in black. Due to the strong variation
of structural complexity, a single-scale GPRmodel does not cope well with the Doppler function (see
Appendix G.1 for a comparison of single-scale to multi-scale GPR).
We implement our proposed MoEmodel as described in Sec.4.3 with sparse GPs as the expert and gate
models and using the Gaussian kernel k. We apply 512, respectively 128IPs for the experts and the gate,
which are chosen via SVGD (see Appendix E). Furthermore we apply σj= 10(j−10)/3,1≤j≤7, as the
expert bandwidths, λE= 20as the initial expert regularization, and σG= 0.05andλG= 10for the gate. For
the training, we apply a batch size of B= 512, a terminal expert sparsity κ= 2, a penalty factor of ϑσ= 0.5
for small bandwidth choices, gate noise parameters s0= 0.1andηs= 1/√
2, and learning rate parameters
η= 0.01,ηH= 0.2,ηG= 1.
18Published in Transactions on Machine Learning Research (12/2023)
Figure 3: The Doppler experiment: An exemplary dataset and the locations of 128IPs, once sampled most
naively—that is, random according to the test distribution—and once optimized regarding diversity as well
as structural complexity and representativeness as described in Sec.4.5, shown on natural x-scale (left) and
on logarithmic x-scale (right).
Figure 4: The Doppler experiment: The gate function (left) and the associated estimates of LOB,LFCand
superior training density (right) trained on the dataset from Fig. 3 and shown on a logarithmic x-scale.
Fig.4 shows the gate function after training of the MoEmodel, as described in Sec.4.4.1, and the associated
estimates of LOB, LFC and the superior training density , calculated according to (24) and (21).
Comparing the active learning framework in the LPSandGPRdomain Sincef∈C∞(X,R),
our deduced superior training density estimate is given by Eq. (21). InFig.5 we plot our estimates of LOB
and thesuperior training density in comparison to the LPS-based results for polynomial degrees of order
Q= 1,3, and with implementation and hyperparameters as described in Panknin et al. (2021). Here, we can
observe the qualitative similarity of the LPS- and GPR-based estimates of LOB.
When conducting the proposed GPR-based active sampling scheme as described in Sec.4.2, we additionally
observe quantitative benefits in Fig.6 overrandom test sampling —quite similar to the LPS-based result
forQ= 3: When estimating the relative sample size (31)we require to achieve the same RMSEvia active
sampling compared to random test sampling , we obtain ϱ(/hatwidefMoE,/hatwidepGPR,n
Sup ) = 0.58±0.04. This means that we
save about 42% of samples via our active sampling scheme.
This provides evidence for the effectiveness of our superior sampling scheme , combining the theoretical
foundation of the LPS domain with the efficient access to LOB estimates in the GPR domain.
Comparing random test sampling toequidistant sampling In the introduction, we indicated that
the advantage of the robust and model-agnostic input space geometric arguments (Teytaud et al., 2007; Yu &
Kim, 2010; Wu, 2019; Liu et al., 2021) diminishes as the training size grows. We can substantiate this claim
by comparing random test sampling toequidistant sampling on the Doppler dataset. By equidistant sampling
overX= [0,1]we mean the deterministic construction of the training inputs, where for ngiven training
samples the subsequent ntraining inputs get placed halfway between all nearest neighbors of the former n
19Published in Transactions on Machine Learning Research (12/2023)
Figure 5: The Doppler experiment: The LOB estimates (left) and the resulting superior training density of
our proposed GPR-based approach in comparison to the LPS-based approach of order Q= 1,3(right). The
results are averaged over 20repetitions.
Figure 6: The Doppler experiment: The RMSE(left) and the maxAE (right) of our proposed GPR-based
approach in comparison to the LPS-based approach of order Q= 3(see Eq. (5)and(6)), once using the
respective ALscheme and once, applying random test sampling . The results are averaged over 20repetitions.
The long-dashed, gray line is for illustration of the optimal learning rate τfrom(30), where the offset C∗is
imaginary. It shall therefore not be confused with a true lower bound.
samples. In this way, the training input inter-distances are halved exactly with each iteration. We regard this
construction as the optimal input space geometric choice, which result will subsume all ALcompetitors of
this type. We now observe in Fig.7 that, indeed, equidistant sampling is superior to random test sampling at
small training sizes. As claimed, however, with growing training size, this advantage gradually diminishes
until it has vanished completely at n= 215training samples.
On Gaussian process uncertainty InSec.2 we mentioned that GP uncertainty sampling is the most
related approach to our superior sampling scheme since both build on GPRmodels. As also discussed therein,
we can regard standard GP uncertainty sampling as an input space geometric argument, whose performance
we can subsume by equidistant sampling in the Doppler experiment. Particularly this implies that standard
GP uncertainty sampling provides no benefits regarding asymptotic AL performance.
Instead—given the gate function of our MoEfrom the previous part of this experiment, which was obtained for
215training samples and which we now keep fixed—we define the uncertainty estimate of our model MoGPU
as a straightforward extension of GP uncertainty sampling which takes the inhomogeneous complexity of
data into account: By simply weighting the predictive variances of all experts in some input xwith respect
to the gate values G(x)from (15), we derive
MoGPU (x) =/summationdisplayL
l=1G(x)lC∗
θl(x), (32)
20Published in Transactions on Machine Learning Research (12/2023)
Figure 7: The Doppler experiment: The RMSE(left) and the maxAE (right) of our proposed MoEmodel
when comparing random test sampling toequidistant sampling . The results are averaged over 20repetitions.
Figure 8: A comparison of the mixture of Gaussian process uncertainty and the equidistant sampling baselines
to our proposed active sampling scheme for the Doppler experiment: (Top) The training data histograms
after 213samples, contrasted with functions of σn
GPR, and the RMSE(bottom left) and the maxAE (bottom
right) at several training sizes of the compared schemes. The results are averaged over 20repetitions. The
long-dashed, gray line is for illustration of the optimal learning rate τfrom(30), where the offset C∗is
imaginary. It shall therefore not be confused with a true lower bound.
whereC∗
θlis the predictive variance of the l-th expert (see (12)). Note that we consider MoGPU as a baseline
competitor to our superior sampling scheme .
Intuitively, the uncertainty estimate in x∈Xincreases as the applied bandwidth σn
GPR(x)decreases. Now,
in order to equalize uncertainty over the input space, MoGPU will sample more in regions where σn
GPRis
smaller. ForXndrawn according to MoGPU, we expectXn∼[σn
GPR]−d. This expectation holds as can be
seen at the top in Fig. 8.
21Published in Transactions on Machine Learning Research (12/2023)
Figure 9: A comparison of the DGPmodel performance, using the ALC criterion for DGP, therandom test
sampling baseline, and our proposed active sampling scheme for the Doppler experiment: (Top) The training
data histograms after 512samples, and the RMSE(bottom left) and the maxAE (bottom right) at several
training sizes of the compared schemes. The results are averaged over 5repetitions.
For evaluation, we combine the fixed gate function with full GPRexperts and compare our proposed sampling
scheme with MoGPU (both determined through the gate). In all error measures the beneficial effect of the
low-dispersion property of Xndrawn according to MoGPU has already vanished for about 512training
samples, from where the asymptotic law dominates. As expected, our approach is superior to MoGPU when
comparing RMSE. Interestingly, MoGPU is superior to our approach regarding the maxAE, suggesting that
Xn∼[σn
GPR]−dis the preferable training distribution under the supremum-norm.
ALPerformance on deep Gaussian processes To demonstrate the model-agnosticity of our AL
approach, we deploy the DGPmodel of Sauer et al. (2023b) using the CRAN package deepgp4. This package
also implements an aggregate variance-based ALcriterion (Cohn, 1994), which they named active learning
Cohn(ALC) after the originator. We deploy a 3-layer DGPmodel, using the Gaussian kernel. For test
evaluation, We train the model using Vecchia-approximation (Sauer et al., 2023a) with a total of 10,000
Gibbs-sampling steps, burning the initial 8000, and thinning the remaining steps to 1,000.
Beginning with 128 equidistant samples, we refine the training data of the DGPmodel using the ALC
criterion, random test sampling , and our proposed superior training scheme. The resulting training data
distributions and the performance of the DGPmodel are plotted in Fig.9. As expected, our superior training
scheme performs superior to random test sampling . While the ALC criterion that is particularly designed
for theDGPmodel performs best, we observe only very little difference at 512 training samples. Note that
sampling according to the ALC criterion becomes computationally challenging already at this point since
theDGPmodel has to be re-trained after each new sample. In contrast, sampling Xn∼pGPR,n
Supcan be
performed in batch mode. This result emphasizes the complementary nature of our asymptotic work to the
classicbottom-up AL literature.
4Seehttps://cran.r-project.org/web/packages/deepgp/index.html
22Published in Transactions on Machine Learning Research (12/2023)
Figure 10: The Doppler experiment: The curves show the RMSEat training size n= 215for a varying number
of expert IPs m. The colors correspond to different IP distributions, whereas the line styles correspond to
the underlying training distribution. The results are averaged over 20repetitions.
Necessity of the small bandwidth penalty We impose a penalty on small bandwidth choices through
the factorϑσ= 0.5to regularize the bandwidth function and prevent overfitting, as described in Appendix F.
We demonstrate this overfitting issue in Appendix G.2 that results from applying no regularization ( ϑσ= 0).
Parsimonious modeling using LFCInSec.4.1 we mentioned that LFCcan also be used to coarsen or
refine the model resolution adequately to reduce the overall complexity of the model. While we fixed the IPs
to reasonable numbers in the other parts of the Doppler experiment, that is, m= 512andm= 1024IPs
under active, respectively random test sampling , we here investigate the influence of the number of IPs and
their distribution on the capability to resemble the Doppler function. Recall from Sec.4.5 that we interpret
the choice of the IPs as a nested ALtask at small sample size (m≪n), where it is reasonable for them to be
sampled in a diverse way, respecting the training distribution but also the structural complexity of the target
function. In Fig. 3, we show a naive choice and our optimized choice of IPs.
InFig.10, we compare the RMSEfor the fixed training size n= 215for both settings, active and passive,
when sampling the IPs according to the training density p, theLFCand their geometric mean (29). First of
all, we observe that we generally require less IPs with active sampling compared to random test sampling ,
which originates from the fact that the superior training density /hatwidepGPR,n
Supalready respects LFCto some degree.
Next, we observe that the geometric mean of the training density and LFCperforms best, provided that the
number of IPs mis large enough. Finally, we observe that, non-surprisingly, we can shrink mthe most under
the LFC distribution, namely to m= 128, before the performance of the model degrades substantially.
In summary, we are able to shrink the model complexity up to a factor of 8for the Doppler function without
a significant loss of performance, when respecting LFC in the model design.
Comparing our proposed IP selection method to a greedy fast forward selection InSec.2, we
discussed other IP selection approaches. For comparison, we have implemented the greedy fast forward (GFF)
IP selection method of Seeger et al. (2003), in which, beginning from scratch, the most informative training
inputs are gradually added to the set of IPs as a means to approximate the full GP(θ)distribution. Here, the
information of an IP candidate xi∈Xn\X†is measures by
J(xi) =KL/bracketleftig
QX†∪{xi}∥QX†/bracketrightig
,
which is the Kullback-Leibler divergence between the posterior distributions based on the IPs X†∪{xi}and
X†. Accordingly, the updated set of IPs is given by X†←X†∪{x∗
i}, where
x∗
i=argmaxxi∈Xn\X†J(xi).
The procedure converges, when the remaining IP candidates carry no further information, that is, J(x∗
i)<εJ,
up to a specified threshold εJ≥0.
At a given threshold εJ, we observe that the number of selected IPs is very small for the experts with a large
bandwidth, while it increases drastically ( ∝σ−1
i) for experts with a small bandwidth. Now that the overall
23Published in Transactions on Machine Learning Research (12/2023)
Figure 11: The Doppler experiment: The curves show the RMSEat training size n= 215at a varying number
of expert IPs m, where the IPs are either chosen at random, according to our proposed selection method, and
via GFF. The results are averaged over 20repetitions.
Figure 12: The Doppler experiment under heteroscedastic noise: (Top left) An exemplary dataset; (Top
right) The LOBestimates, when comparing the homoscedastic to the heteroscedastic Doppler experiment;
(Bottom left) The training densities of random test sampling ,pGPR,n
SupandpGPR,n
Supwhen wrongly assuming
homoscedasticity; (Bottom right) The RMSEat several training sizes of the compared sampling schemes.
The results are averaged over 20repetitions.
complexity of the MoEis dominated by the expert with the most IPs, it is fair to compare the number of IPs
of the expert at bandwidth σ1with our statically specified number mof IPs in Fig.10. Here, we will vary the
thresholdεJto obtain a curve that maps the associated number of IPs to the achieved RMSE. The results
inFig.11 show that with GFFalmost no IPs can be saved for this inhomogeneously complex problem, as
opposed to our proposed IP selection method.
In any case, even under training according to pGPR,n
Sup, the selected IPs by Seeger et al. (2003) are uniformly
distributed. In particular, the need for less IPs of the experts at smaller bandwidths to the right of Xis not
recognized and, thus, we observe no IP savings at an acceptable performance over a random IP selection at
all for this inhomogeneously complex problem.
24Published in Transactions on Machine Learning Research (12/2023)
Heteroscedastic noise treatment While the treatment of heteroscedastic noise is not the main focus of
this work, we will now demonstrate our approach on a heteroscedastic version of the Doppler experiment. For
this, we let v(x) = (3−4|x−0.5|))2∈[1,9], which we plot in Fig.12 (top left) together with the resulting
dataset. Here, we assume the local noise variance (or an estimate of it) to be provided externally, again, since
its estimation is out of the scope of this work. However, note that the estimation of vis well-studied in the
literature, especially for GPs (Kersting et al., 2007; Cawley et al., 2006; Tresp, 2001).
InFig.12 (top right) we compare the LOBestimates obtained from the homoscedastic dataset and the
heteroscedastic version. As we have suggested in Sec.4.1, the influence of von theLOBestimates obtained
from heteroscedastic GPRexperts is relatively small. Likewise, we proceed with the evaluation of our proposed
ALscheme under heteroscedasticity. Here, we compare to random test sampling but also to pGPR,n
Supunder
the wrong assumption of homoscedastic noise. Note that we use the heteroscedastic MoEin all cases since
the wrong assumption of homoscedastic noise in the experts makes the MoEvery volatile. The respective
training densities and RMSElearning curves can be seen in the bottom row in Fig.12. Due to the stronger
noise (compared to the homoscedastic experiment), the asymptotic behavior begins to materialize later from
n= 213training samples. Until this point, sampling only with respect to the structural complexity looks
also promising. However, as soon as the training size becomes large enough to roughly resemble the target
function, respecting the inhomogeneity in the noise level becomes crucial to achieve a homogeneous pointwise
convergence and, thus, maintaining asymptotic superiority.
5.2 Force field reconstruction
We now turn our attention to a real-world example in which we predict the potential energy surface (PES)
and corresponding force field (FF) of a molecule from first-principles calculations. The PES function links the
geometryx= [R1,...,R a]∈R3×aof a molecule to its potential energy E∈R, whereRiare the Cartesian
positions of the aatoms of the molecule. In ab initio computations, this mapping is achieved by solving
the time-independent Schrödinger equation. The PES encodes essential information on the properties of
a molecule. Due to thermal and quantum effects, molecules are never perfectly rigid but assume different
configurations. The distribution of these configurations is determined by the shape of the PES. For example,
the minima of the PES will be sampled more frequently than other regions and correspond to stable structures.
This has practical implications since many experimental techniques measure an expectation value over
molecular distributions. In order to achieve a meaningful comparison, sampling needs to be taken into account
in theoretical simulations as well. One of the most successful approaches to sample molecular distributions is
MD simulation. They model the time evolution of the atomic positions, sampling the PES by integrating
Newton’s equations of motion. To this end, energy-conserving forces acting on each atom are required. These
forces are the negative derivative of the PES with respect to the atomic positions F∈R3×a.
This type of proxy for the prohibitively expensive ab initio quantum mechanical calculations is commonly used
to enable long-timescale MD simulations that consist of millions of steps, each requiring the evaluation of the
PES and FF for a new geometry. Converged MD trajectories give unique insights into the dynamic behavior
and structure-function relationships of physical systems at atomic scale. They are widely used in molecular
biology research and play a crucial role in applications such as protein folding and drug discovery. MLhas
the potential to profoundly advance this field, as it bears the promise of offering a unique cost-accuracy
trade-off that is not achievable with traditional methods (Noé et al., 2020; von Lilienfeld et al., 2020; Unke
et al., 2021b; Keith et al., 2021). However, some commonly deployed ML-based FFs rely on rather naive
exhaustive sampling schemes to gather training data, which stands in the way of scaling to larger system
sizes, both, from a data acquisition cost and training perspective. Here, we demonstrate how our method can
be used to construct smaller, yet more effective training datasets.
In this experiment, we reconstruct a FF for the molecule malonaldehyde, which has a= 9atoms and the
chemical formula C3H4O2(seeFig.13 (A)). Formally, we try to infer the high-dimensional target function
f:X → Y,R∝⇕⊣√∫⊔≀→[E,F], whereX=R3aandY=R1+3a. For visualization purposes, we only show a
two-dimensional subspace of the PES, which is characterized by the two main features of this molecule, its
two rotors (aldehyde groups) (Chmiela et al., 2018; Sauceda et al., 2020). Their relative orientation is the
dominant driver of the potential energy in this case and therefore most descriptive. Each point on the surface
depicted in Fig.13 (B) is generated by fixing the rotor pair at a particular angle and relaxing all remaining
25Published in Transactions on Machine Learning Research (12/2023)
LFC Estimate
Test densityOptimized data distribution Geometry
samplingEnergies &
Forcese.g. 500K
Superior training
       density
A B C D E
Figure 13: Reconstructing ML-based FFs using our MoEapproach: (A-B) The inputs and outputs of the
regression task are the geometries and energies (including forces, i.e., energy gradients) of malonaldehyde. As
an example, we highlight the geometries of the two energetically stable states found in the local minima of the
energy surface. (C) The density estimate of the true MD geometry distribution. (E) The superior training
densityestimate (21)based on our approach. All properties are evaluated at the relaxed malonaldehyde
configurations and plotted with respect to the angles of the two aldehyde rotors of malonaldehyde (see
Chmiela et al. (2018); Sauceda et al. (2020)).
degrees of freedom to obtain a minimal energy configuration. We will refer to these geometries as the relaxed
configurations in the following.
To reconstruct the FF, we consider the broadly adopted symmetric gradient-domain machine learning
(sGDML) method (Chmiela et al., 2018; 2019), which is a GPRmodel that takes energy and force labels
and also roto-translational and permutational invariances of the geometries into account (see Appendix H.1
for details). We anticipate that sGDML will benefit from our MoEapproach, where we deploy sGDML as
the expert model, since the transition paths along the PES vary in complexity, due to the interplay between
distinct atom types with different characteristic interaction length scales. Our ALapproach can only improve
training efficiency if there are inhomogeneities in the data. Using our LFCestimate, we therefore first verify
our intuition that the PES of malonaldehyde varies in complexity. Based on this, we derive the superior
training density , which we finally input into our ALframework to refine the training dataset in a superior
way.
Experimental setup All experiments use an extensive pre-computed reference trajectory (almost a million
data points (Xpool,Ypool)) as ground truth, as opposed to generating new data points on demand. This test
setup allows a post-hoc verification of the training distribution generated by our ALapproach, while still
providing ample redundancy and therefore sampling freedom.
Recall from Sec.4.2 that we require an unnormalized density estimate of the trajectory Xpool∼pXsince
we are dealing with a pool-based ALscenario. We estimate /hatwidepXby standard kernel density estimation ,
based on the energy-to-energy entry of the sGDML kernel/tildewidekfrom(46)atσ= 0.03.Fig.13 (C) shows the
density estimate of the relaxed configurations, where we observe that pXis very unbalanced, with a strong
concentration of mass near the stable configurations.
We implement our MoEapproach, using the sGDML kernel/tildewidekfrom(46)with a Gaussian base kernel function
k. While we sample the training data randomly (with appropriate weights) from the pool, we will draw
sub-samples (i.e., for choosing the IPs of sparse expert and gate models) via symmetrized distributional
clustering (DC) with distributional k-means ++initialization (see Appendix E).
Since this dataset comes with practically noise-free labels (we consider the first principle calculations as
ground truth), we tune the experts (and MoEmodel) with respect to MSErather than the Objobjective.
For stability, we will apply /hatwidev(x) = 10−9even though we assume no noise.
Anisotropic bandwidths sGDML operates ond=a(a−1)/2 = 36features that are based on the
interatomic distances of the molecule. In contrast to the work of Chmiela et al. who restrict themselves to an
isotropic bandwidth ΣE=σEId, our implementation of sGDML in GPyTorch naturally enables us to tune
an anisotropic bandwidth ΣE=diag (σ1,...,σ d)in the preprocessing step.
26Published in Transactions on Machine Learning Research (12/2023)
Figure 14: A visualization of the individual
feature importance of malonaldehyde in the
anisotropic case: The structural formula of
the molecule is plotted in black. The im-
portance of the individual interatomic dis-
tances is reciprocal to ΣE, which is the
bandwidth estimate obtained by training the
anisotropic sGDML model. Hence, we ex-
press the importance of each interatomic dis-
tance of the molecule in red, where the im-
portance corresponds to the line saturation
γ=/bracketleftig
−log(ΣE)−min(−log(ΣE))
max(−log(ΣE))−min(−log(ΣE))/bracketrightig2
∈[0,1].
We partially offset the increased memory footprint of the model due to the tunable ΣEby implementing the
sparseGPRmodel from Sec.3.4.1 under the sGDML kernel/tildewidekfrom(46)and limiting the number of IPs to
m= 128configurations. Since all our features are of the same type—pairwise interatomic distances—they
are inherently calibrated in terms of scale. Hence, the reciprocal entries of ΣEdirectly translate into the
importance of the features, which we display in Fig. 14.
We observe, that the importance assigned to some pairs of atoms agrees with chemical intuition, e.g.,
interactions with light hydrogen atoms are generally weaker. Furthermore, the important role of the opposing
aldehydegroupsinmalonaldehydeemergesintheformofaheavilyweightedpaththatconnectsthe O-C-C-C-O
backbone of the molecule.
InFig.15 we see that our anisotropic variant of sGDML performs consistently better than the original
isotropic sGDML model. Similar to the calculation of the relative sample size in (31)we can compare two
models of equal asymptotic MSElaw. When comparing anisotropic to isotropic sGDML, both under random
test sampling , we can save about 10% of samples.
Setting up the MoEmodel After having trained ΣE, we apply dense sGDML experts with Σj=σjΣE,
whereσj= 2−5/4+j/2,1≤j≤8as the individual expert bandwidths, λE= 1as the initial expert
regularization, and σG= 0.1andλG= 104for the sparse gate with 1024IPs. For the training, we apply a
batch size of B= 1024, a terminal expert sparsity κ= 8, a penalty factor of ϑσ= 0.01for small bandwidth
choices, gate noise parameters s0= 0.01andηs= 1/√
2, and learning rate parameters η= 0.005,ηH= 0.05,
ηG= 0.1. As we discuss in Appendix F, for tuning the MoEwith dense ( sGDML) experts, we either require
an additional gate training set, which is independent of the training set for the experts, or we could provide
leave-one-out ( LOO) responses of the experts for the training of the gate. In our experiment, we use an
additional gate training set XG
nGof fixed size nG= 214. The anisotropic MoEmodel performs consistently
better than anisotropic sGDML, as can be seen in Fig. 15. When comparing the anisotropic MoE model to
isotropic sGDML, both under random test sampling , we can save about 21% of samples.
Active learning We assume an intrinsic dimension of δ= 2(the two aldehyde rotor angles, the most
salient features of malonaldehyde) and a smooth target function f∈C∞(X,Y). The test distribution is
given by the MD trajectory such that q=pX. Prior to the ALprocedure, we separate the validation samples
Xvaland test samples XTat random from the pool Xpool. We apply an initial expert training size of
n0= 29, doubling the sample size with each iteration of the ALprocedure. The initial expert training set
Xn0and the gate training set XG
nGare drawn via importance sampling from the remaining pool with weights
/hatwidep−1/2
X(Xpool\(Xval∪XT)). By this it is Xn0∼q1/2, which is more in alignment with the superior training
density(21) than sampling Xn0∼q.
27Published in Transactions on Machine Learning Research (12/2023)
Figure 15: The RMSEunder the true MD trajectory test distribution for different variants of sGDML and
training distribution at varying training size: The performance is given for passive sampling, using the original
isotropic sGDML (dotted), anisotropic sGDML (dash-dotted) and our MoEmodel with anisotropic sGDML
experts (dashed), and for the MoEmodel, applying the proposed superior sampling scheme (solid). The
results are averaged over 5repetitions.
InFig.13 (D, E) we show the estimates of LFCand the superior training density under the pool test
distribution, evaluated on the relaxed configurations of malonaldehyde. The LFCestimates confirm our
expectation that the transition areas are more complex to model than the regions near the stable configurations.
Subsequently, our active sampling scheme shifts sample mass away from the stable regimes in favor of the
transition areas.
We have plotted the error curves of passive and active sampling schemes in Fig.15. When estimating the
relative sample size (31)that we require to achieve the same RMSEvia active sampling compared to random
test sampling , we obtain ϱ(/hatwidefMoE,/hatwidepGPR,n
Sup ) = 0.920±0.013. This means that we save about 8% of samples
under the MoEmodel with our active sampling scheme compared to random test sampling . In total, when
comparing our actively trained MoEapproach to the passively trained, original sGDML model, we can save
about 31% of samples. Notably, DFT level calculations (Perdew et al., 1996; Blum et al., 2009; Tkatchenko
& Scheffler, 2009) for the studied system require minutes to hours of computation per sample , CCSD(T) level
computations even require days of computation per sample. So in the field of quantum chemistry saving
roughly a third of computing power is of practical importance.
6 Discussion
Active learning Recall that in this work we have restricted ourselves to the scenario of model-agnostic AL
with persistent performance at large training size. This scenario is complementary to the more common small
sample size regime. And while both cases are important, a lot of ALrelated work (as discussed in Sec.2)
does not apply to our ALscenario. We also discussed and demonstrated in our experiments that input space
geometric arguments which are model-free asymptotically come with no benefit over random test sampling .
Since our proposed model is GPR-based, we also analyzed uncertainty sampling ( MoGPU) for our MoEmodel
to show that our proposed superior sampling scheme differs from uncertainty sampling. Moreover, our superior
sampling scheme showed to be superior to uncertainty sampling. Finally, in the regime of our ALscenario,
the approach by Panknin et al. (2021) recently has demonstrated state-of-the-art performance to recent,
sophisticated, model-agnostic ALapproaches. This was done by training different models on the actively
constructed training sets of their and other ALapproaches and assessing their performance. In particular,
they compared favorably to Goetz et al. (2018)—a random tree-based ALapproach—in a heteroscedastic
setting, using a regression forest model and to Bull et al. (2013)—a wavelet-based ALapproach—in a setting
of inhomogeneous complexity, using an RBF-network. This demonstrates the flexibility of this ALapproach
in terms of learning problem specifications as well as model choices. Now that our work builds on the previous
work of Panknin et al. (2021), state-of-the-art performance of our work is implied.
28Published in Transactions on Machine Learning Research (12/2023)
Interpretability of LFCDue to model-agnosticity, we consider LFCto be an intrinsic, interpretable
property of the regression problem, which can be used as an analysis tool by domain experts:
When looking at a single point in a high-dimensional input space, a visual assessment of the local structural
complexity (e.g., a human can visually detect more complexity to the left of the Doppler function) is
challenging. Here, the scalar LFCvalue gives a human assessable, quantitative description. The LFC(as
a scalar-valued function) then even allows for an easy visualization of the local structural complexity in
high-dimensional input spaces, if the input space features a reasonable low-dimensional projection. This
benefit was demonstrated in the high-dimensional FF reconstruction experiment, where the two-dimensional
visualization of LFC provides new insights into the regression problem. Note that the LFC function cannot
be visualized in the absence of a low-dimensional projection.
Parsimonious modeling We proposed a novel, model-agnostic approach to select the IPs of GPR, sampling
them in a diverse way from a distribution that is representative for the training data and respects the LFC.
In the experiments, we have seen that for problems of inhomogeneous complexity, our approach sustains the
expressive power of the model at a considerably smaller number of IPs, compared to the GFFIP selection
method of Seeger et al. (2003).
Heteroscedasticity While inhomogeneities in noise are not the focus of our work, note that both, our model
as well as the original ALframework upon which we built our approach naturally deal with heteroscedasticity.
It, therefore, suffices to complement our work with an estimate of the noise variance function vas, e.g., given
in Kersting et al. (2007); Cawley et al. (2006). The only aspect left open is to elaborate on the impact of v
on theLOBofGPRand, thus, the adequate adjustment with respect to vin the derivation of the LFC. As
we argued, GPRalready treats heteroscedasticity through local adaptions of the regularization. Hence, we
assume the influence of von theLOBto be negligible to not existent. This is opposed to the LOBofLPS
whose only way to deal with heteroscedasticity is through adaption of its LOB.
Intrinsic dimension and smoothness of the problem In our derivation of LFCand the superior
training density , we assumed the intrinsic dimension δ≤dand the smoothness α∈(0,∞]off∈Cα(X,R)
to be given through domain knowledge.
Ifδis unknown, we can estimate it from unlabeled input instances, such as Xpoolin a pre-processing step.
However, this is beyond the scope of our work and we refer to the approach of Facco et al. (2017)5for an
estimate of the δfor unbalanced input distributions in high-dimensional input spaces X.
If we have no ground truth knowledge about the smoothness αof the target function f∈Cα(X,R), we
resort to/hatwideα=∞as default in practice. This assumption is justified, as long as fhappens to be rougher in at
most finitely many locations of the input space. Since, asymptotically, the violation of α=∞affects only
a set of measure zero, the influence on our ALsetting that addresses large training sizes is marginal. We
consider the restriction to target functions that are at most rough on a finite set of input space locations a
weak assumption which, thus, comes with no practical limitations.
One way to deal with an unknown smoothness αis to deploy the Matérnkernel
kν(x,x′) :=21−ν
Γ(ν)/parenleftbig
∥x−x′∥/σ/parenrightbigν/tildewidekν/parenleftbig
∥x−x′∥/σ/parenrightbig
,
where Γis thegamma function and/tildewidekνis the modified Bessel function of the second kind or order ν. After
finding the best fitting ν∗, we obtain by /hatwideα:=⌈ν∗⌉−1a reasonable estimate to α. We defer this idea to
future work as it is beyond the scope of this work.
Dimensional scaling As opposed to nonstationary GP approaches (e.g., the tree-based or local GP by
Gramacy & Lee (2008); Gramacy & Apley (2015) that suffer from the curse of dimensionality through input
space localization, we segment the input space into a fixed number Lof patches, given by the Lexperts of our
MoE. Thus, if we were to instantiate our MoEwith dense GPRmodels, our approach scales well concerning
the input space dimension d. However, in real-world applications, we typically deal with training sizes that
are too large for dense modeling. In this regime, sparse GPRrepresentations scale poorly in das their IPs
5For an implementation in Python see https://scikit-dimension.readthedocs.io/en/latest/index.html
29Published in Transactions on Machine Learning Research (12/2023)
must be space-filling (Binois & Wycoff, 2022). Likewise, our density-based ALapproach encounters decaying
power for large d. A low intrinsic dimension ( δ <d) of the regression problem is therefore crucial for our
work to apply.
LFCand the superior sampling scheme as aMLconcept Recall that we consider LFCto be a
problem intrinsic property. Here, the problem is characterized by features x∈Xwith labels f(x)∈R, a
hypothesis space of locally adaptive models , and the MISEas the loss function (or rather the pointwise MSE
from(1)due to the localization of LFC). In this sense, LFCis formally a property of the combination of
model and loss according to the characterization of (Jung (2022), Chapter 2). Similarly, the superior training
densityis a property of the combination of model and loss with respect to the same hypothesis space and
MISE instead of the pointwise MSE as loss function.
On a realistic implementation in ab initio FF reconstruction In our FF reconstruction experiment,
we assumed a large unlabeled reference trajectory Xpoolto be given that already follows the true molecular
distribution. This will not be given in practice, since building the input trajectory already requires the
computationally expensive estimation of the respective labels. At this point, the actual task behind the
regression problem would already be solved. We outline a realistic ab initio FF reconstruction scenario in
Appendix H.3.
7 Conclusion
Standard MLtasks implicitly assume a certain homogeneity in the data scales. However, in practice this
structural property of the learning problem may not be fulfilled, e.g., in multiscale problems from the sciences
such as turbulence (Brunton et al., 2020) or quantum chemistry (Noé et al., 2020; von Lilienfeld et al., 2020;
Unke et al., 2021b; Keith et al., 2021).
In this work, we aimed to identify local inhomogeneities in regression tasks, which can be used to construct
better models and training datasets and for domain interpretation. To this end, we combined recent results on
model-agnostic LFCestimates and asymptotically optimal sampling, which are founded in the domain of LPS,
with estimates of LOB, which are derived in the GPRdomain. By this, we benefit from both sides, having a
theoretically sound superior sampling scheme on the one hand, and having access to the required estimates
from a model that naturally can cope with high input space dimensions on the other hand. Furthermore, we
have shown how respecting LFC in the selection of IPs contributes to parsimonious modeling.
On synthetic data, we showcased and validated our approach, where we analyzed similarities with the
LPS-based analog but also compared to the most related GP uncertainty sampling concepts for AL. To
show the full potential of our approach, we studied a real-world, high-dimensional force field reconstruction
task. Our approach not only gave access to an interpretable visualization of the inhomogeneous structural
complexity but also guided the sampling process in a way that takes the structural changes into account,
enhancing the quality of the training data. Here, we additionally identified the multi-scale structure of the
individual atomic interactions, whose treatment also results in a substantial performance gain of the broadly
adopted method sGDML.
Future work InSec.4.1 we conjecture that the LOBof heteroscedastic GPRis invariant or scales at most
weakly with respect to the local noise level v(x). This claim should be supported by further theoretical
investigation. While we deployed our estimates of LFCand the superior training density, using /hatwideα=∞,
if the smoothness of the target function f∈Cα(X,R)is unknown, it is possible to (re-)estimate /hatwideα, e.g.,
by tuning the regularity of the Matérn kernel of a GPRmodel after the acquisition of each new training
data batch. While we have compared to baseline IP selection methods, a thorough comparison to more
sophisticated approaches remains open. A promising idea is also to combine our LFCestimate with the IP
selection approach by Moss et al. (2023) to obtain informative and diverse IPs in GPR. Finally, we will focus
on the application of our approach to real-world problems from chemistry, physics, and further domains also
applying techniques from explainable AI (e.g. Samek et al. (2021); Letzgus et al. (2022)). In particular,
recent advances on sGDML regarding the scalability by Chmiela et al. (2023) will enable the application of
our approach to large molecular systems.
30Published in Transactions on Machine Learning Research (12/2023)
Acknowledgments
D. Panknin ,S. Chmiela ,S. Nakajima , andK.-R. Müller were funded by the German Ministry for Education
and Research as BIFOLD - Berlin Institute for the Foundations of Learning and Data (ref. BIFOLD23B).
D. Panknin was also supported by the BMBF project ALICE III, Autonomous Learning in Complex Environ-
ments (01IS18049B). K.-R. Müller was also supported by the BMBF Grants 01GQ1115 and 01GQ0850, under
the Grants 01IS14013A-E, 031L0207A-D; DFG under Grant Math+, EXC 2046/1, Project ID 390685689 and
by the Institute of Information & Communications Technology Planning & Evaluation (IITP) grants funded
by the Korea Government (No. 2017-0-00451, Development of BCI based Brain and Cognitive Computing
Technology for Recognizing User’s Intentions using Deep Learning) and funded by the Korea Government
(No. 2019-0-00079, Artificial Intelligence Graduate School Program, Korea University).
All funding sources were not involved in the process of writing and submitting this work.
References
David Arthur and Sergei Vassilvitskii. K-means++: The advantages of careful seeding. In Proceedings of the
Eighteenth Annual ACM-SIAM Symposium on Discrete Algorithms , SODA ’07, pp. 1027–1035. Society for
Industrial and Applied Mathematics, 2007.
Francesco Bellocchio, Stefano Ferrari, Vincenzo Piuri, and Nunzio Alberto Borghese. Hierarchical approach
for multiscale support vector regression. IEEE Transactions on Neural Networks and Learning Systems , 23
(9), 2012.
William H Beluch, Tim Genewein, Andreas Nürnberger, and Jan M Köhler. The power of ensembles for
active learning in image classification. In Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition , pp. 9368–9377, 2018.
Nabil Benoudjit, Cédric Archambeau, Amaury Lendasse, John Aldo Lee, Michel Verleysen, et al. Width
optimization of the gaussian kernels in radial basis function networks. In ESANN, volume 2, pp. 425–432,
2002.
Tristan Bereau, Robert A DiStasio Jr, Alexandre Tkatchenko, and O Anatole Von Lilienfeld. Non-covalent
interactions across organic and biological subsets of chemical space: Physics-based potentials parametrized
from machine learning. J. Chem. Phys. , 148(24):241706, 2018.
Mickael Binois and Nathan Wycoff. A survey on high-dimensional gaussian process modeling with application
to bayesian optimization. ACM Transactions on Evolutionary Learning and Optimization , 2(2):1–26, 2022.
Volker Blum, Ralf Gehrke, Felix Hanke, Paula Havu, Ville Havu, Xinguo Ren, Karsten Reuter, and Matthias
Scheffler. Ab initio molecular simulations with numeric atom-centered orbitals. Computer Physics
Communications , 180(11):2175–2196, 2009.
Rafael S Bressan, Pedro H Bugatti, and Priscila TM Saito. Breast cancer diagnosis through active learning
in content-based image retrieval. Neurocomputing , 357:1–10, 2019.
Steven L Brunton, Bernd R Noack, and Petros Koumoutsakos. Machine learning for fluid mechanics. Annual
review of fluid mechanics , 52:477–508, 2020.
Adam D Bull et al. Spatially-adaptive sensing in nonparametric regression. The Annals of Statistics , 41(1):
41–62, 2013.
Robert Burbidge, Jem J Rowland, and Ross D King. Active learning for regression based on query by
committee. In International conference on intelligent data engineering and automated learning , pp. 209–218.
Springer, 2007.
Wenbin Cai, Ya Zhang, and Jun Zhou. Maximizing expected model change for active learning in regression.
In2013 IEEE 13th international conference on data mining , pp. 51–60. IEEE, 2013.
31Published in Transactions on Machine Learning Research (12/2023)
Gavin C. Cawley, Nicola L. C. Talbot, and Olivier Chapelle. Estimating predictive variances with kernel ridge
regression. In Machine Learning Challenges. Evaluating Predictive Uncertainty, Visual Object Classification,
and Recognising Tectual Entailment , pp. 56–77, Berlin, Heidelberg, 2006. Springer Berlin Heidelberg. ISBN
978-3-540-33428-6.
Ziyi Chen, Jinwen Ma, and Yatong Zhou. A precise hard-cut em algorithm for mixtures of gaussian processes.
InInternational Conference on Intelligent Computing , pp. 68–75. Springer, 2014.
Stefan Chmiela, Alexandre Tkatchenko, Huziel E. Sauceda, Igor Poltavsky, Kristof T. Schütt, and Klaus-
Robert Müller. Machine learning of accurate energy-conserving molecular force fields. Science Advances , 3
(5):e1603015, 2017.
Stefan Chmiela, Huziel E. Sauceda, Klaus-Robert Müller, and Alexandre Tkatchenko. Towards exact molecular
dynamics simulations with machine-learned force fields. Nature Communications , 9(1):3887, 2018. doi:
10.1038/s41467-018-06169-2.
Stefan Chmiela, Huziel E. Sauceda, Igor Poltavsky, Klaus-Robert Müller, and Alexandre Tkatchenko. sgdml:
Constructing accurate and data efficient molecular force fields using machine learning. Computer Physics
Communications , 240:38–45, 2019. doi: 10.1016/j.cpc.2019.02.007.
Stefan Chmiela, Valentin Vassilev-Galindo, Oliver T. Unke, Adil Kabylda, Huziel E. Sauceda, Alexandre
Tkatchenko, and Klaus-Robert Müller. Accurate global machine learning force fields for molecules with
hundreds of atoms. Science Advances , 9:eadf0873, 2023. doi: 10.1126/sciadv.adf0873.
William S Cleveland and Susan J Devlin. Locally weighted regression: an approach to regression analysis by
local fitting. Journal of the American statistical association , 83(403):596–610, 1988.
David Cohn. Neural network exploration using optimal experiment design. Advances in Neural Information
Processing Systems , 6:679–686, 1994.
Andreas Damianou and Neil D Lawrence. Deep gaussian processes. In Artificial intelligence and statistics ,
pp. 207–215. PMLR, 2013.
David L Donoho and Jain M Johnstone. Ideal spatial adaptation by wavelet shrinkage. biometrika , 81(3):
425–455, 1994.
Fouzi Douak, Farid Melgani, and Nabil Benoudjit. Kernel ridge regression with active learning for wind speed
prediction. Applied Energy , 103(0):328 – 340, 2013.
Petros Drineas, Michael W Mahoney, and Nello Cristianini. On the nyström method for approximating a
gram matrix for improved kernel-based learning. journal of machine learning research , 6(12), 2005.
Elena Facco, Maria d’Errico, Alex Rodriguez, and Alessandro Laio. Estimating the intrinsic dimension of
datasets by a minimal neighborhood information. Scientific reports , 7(1):12140, 2017.
Jianqing Fan, Theo Gasser, Irène Gijbels, Michael Brockmann, and Joachim Engel. Local polynomial
regression: optimal kernels and asymptotic minimax efficiency. Annals of the Institute of Statistical
Mathematics , 49(1):79–99, 1997.
Stefano Ferrari, Francesco Bellocchio, Vincenzo Piuri, and N Alberto Borghese. Multi-scale support vector
regression. In Neural Networks (IJCNN), The 2010 International Joint Conference on , pp. 1–7. IEEE,
2010.
Shai Fine and Katya Scheinberg. Efficient svm training using low-rank kernel representations. Journal of
Machine Learning Research , 2(Dec):243–264, 2001.
Guojun Gan, Chaoqun Ma, and Jianhong Wu. Data clustering: theory, algorithms, and applications . SIAM,
2020.
32Published in Transactions on Machine Learning Research (12/2023)
Jacob R Gardner, Geoff Pleiss, David Bindel, Kilian Q Weinberger, and Andrew Gordon Wilson. Gpytorch:
Blackbox matrix-matrix gaussian process inference with gpu acceleration. In Advances in neural information
processing systems , pp. 7576–7586, 2018.
Jack Goetz, Ambuj Tewari, and Paul Zimmerman. Active learning for non-parametric regression using purely
random trees. In Advances in Neural Information Processing Systems , pp. 2537–2546, 2018.
Mohamed Goudjil, Mouloud Koudil, Mouldi Bedda, and Noureddine Ghoggali. A novel active learning
method using svm for text classification. International Journal of Automation and Computing , 15(3):
290–298, 2018.
Siegfried Graf and Harald Luschgy. Foundations of quantization for probability distributions . Springer, 2007.
Robert B Gramacy and Daniel W Apley. Local gaussian process approximation for large computer experiments.
Journal of Computational and Graphical Statistics , 24(2):561–578, 2015.
Robert B Gramacy and Herbert K H Lee. Bayesian treed gaussian process models with an application to
computer modeling. Journal of the American Statistical Association , 103(483):1119–1130, 2008.
Andrea Grisafi and Michele Ceriotti. Incorporating long-range physics in atomic-scale machine learning. J.
Chem. Phys. , 151(20):204105, 2019.
Konstantin Gubaev, Evgeny V Podryabinkin, and Alexander V Shapeev. Machine learning of molecular
properties: Locality and active learning. The Journal of chemical physics , 148(24):241727, 2018.
Vincent Guigue, Alain Rakotomamonjy, and Stéphane Canu. Kernel basis pursuit. In European Conference
on Machine Learning , pp. 146–157. Springer, 2005.
László Györfi, Michael Kohler, Adam Krzyżak, and Harro Walk. A distribution-free theory of nonparametric
regression , volume 1. Springer, 2002.
Jun Han and Qiang Liu. Stein variational gradient descent without gradient. In International Conference on
Machine Learning , pp. 1900–1908. PMLR, 2018.
Juan Mario Haut, Mercedes E Paoletti, Javier Plaza, Jun Li, and Antonio Plaza. Active learning with
convolutional neural networks for hyperspectral image classification using a new bayesian approach. IEEE
Transactions on Geoscience and Remote Sensing , 56(11):6440–6461, 2018.
Xiaofei He. Laplacian regularized d-optimal design for active learning and its application to image retrieval.
Image Processing, IEEE Transactions on , 19(1):254–263, 2010.
James Hensman, Alexander Matthews, and Zoubin Ghahramani. Scalable variational gaussian process
classification. In Artificial Intelligence and Statistics , pp. 351–360. PMLR, 2015.
Bing Huang and O Anatole von Lilienfeld. Quantum machine learning using atom-in-molecule-based fragments
selected on the fly. Nature Chemistry , 12(10):945–951, 2020.
Robert A Jacobs, Michael I Jordan, Steven J Nowlan, Geoffrey E Hinton, et al. Adaptive mixtures of local
experts. Neural computation , 3(1):79–87, 1991.
Michael I Jordan and Robert A Jacobs. Hierarchical mixtures of experts and the em algorithm. Neural
computation , 6(2):181–214, 1994.
Alexander Jung. Machine learning: The basics. In Machine Learning: Foundations, Methodologies, and
Applications . Springer, 2022.
John A Keith, Valentin Vassilev-Galindo, Bingqing Cheng, Stefan Chmiela, Michael Gastegger, Klaus-Robert
Müller, and Alexandre Tkatchenko. Combining machine learning and computational chemistry for predictive
insights into chemical systems. Chem. Rev. , 121(16):9816–9872, 2021.
33Published in Transactions on Machine Learning Research (12/2023)
Kristian Kersting, Christian Plagemann, Patrick Pfaff, and Wolfram Burgard. Most likely heteroscedastic
gaussian process regression. In International Conference on Machine Learning , 2007.
Jack Kiefer. Optimum experimental designs. Journal of the Royal Statistical Society. Series B (Methodological) ,
pp. 272–319, 1959.
Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In 3rd International
Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference
Track Proceedings , 2015. URL http://arxiv.org/abs/1412.6980 .
Tsz Wai Ko, Jonas A Finkler, Stefan Goedecker, and Jörg Behler. A fourth-generation high-dimensional
neural network potential with accurate electrostatics including non-local charge transfer. Nat. Commun. ,
12(1):398, 2021.
Arvind Krishna, Simon Mak, and Roshan Joseph. Distributional clustering: A distribution-preserving
clustering method. arXiv preprint arXiv:1911.05940 , 2019.
Sanjiv Kumar, Mehryar Mohri, and Ameet Talwalkar. Sampling methods for the nyström method. The
Journal of Machine Learning Research , 13(1):981–1006, 2012.
Oleg V Lepski. On a problem of adaptive estimation in gaussian white noise. Theory of Probability & Its
Applications , 35(3):454–466, 1991.
Oleg V Lepski and Vladimir G Spokoiny. Optimal pointwise adaptive methods in nonparametric estimation.
The Annals of Statistics , pp. 2512–2546, 1997.
Simon Letzgus, Patrick Wagner, Jonas Lederer, Wojciech Samek, Klaus-Robert Müller, and Gregoire
Montavon. Toward explainable artificial intelligence for regression models: A methodological perspective.
IEEE Signal Processing Magazine , 39(4):40–58, 2022.
David D. Lewis and William A. Gale. A sequential algorithm for training text classifiers. In Proceedings
of the 17th annual international ACM SIGIR conference on Research and development in information
retrieval, pp. 3–12. Springer-Verlag New York, Inc., 1994.
Qiang Liu and Dilin Wang. Stein variational gradient descent: A general purpose bayesian inference algorithm.
In D. Lee, M. Sugiyama, U. Luxburg, I. Guyon, and R. Garnett (eds.), Advances in Neural Information
Processing Systems , volume 29. Curran Associates, Inc., 2016. URL https://proceedings.neurips.cc/
paper/2016/file/b3ba8f1bee1238a2f37603d90b58898d-Paper.pdf .
Ziang Liu, Xue Jiang, Hanbin Luo, Weili Fang, Jiajing Liu, and Dongrui Wu. Pool-based unsupervised
active learning for regression using iterative representativeness-diversity maximization (irdm). Pattern
Recognition Letters , 142:11–19, 2021.
David J. C. MacKay. Information-based objective functions for active data selection. Neural computation , 4
(4):590–604, 1992.
Mark Mackenzie and A Kiet Tieu. Asymmetric kernel regression. IEEE transactions on neural networks , 15
(2):276–282, 2004.
Elias Masry. Multivariate local polynomial regression for time series: uniform strong consistency and rates.
Journal of Time Series Analysis , 17(6):571–599, 1996.
Elias Masry. Multivariate regression estimation: local polynomial fitting for time series. Nonlinear Analysis:
Theory, Methods & Applications , 30(6):3575–3581, 1997.
Edward Meeds and Simon Osindero. An alternative infinite mixture of gaussian process experts. In Advances
in Neural Information Processing Systems , pp. 883–890, 2006.
John Moody and Christian J Darken. Fast learning in networks of locally-tuned processing units. Neural
computation , 1(2):281–294, 1989.
34Published in Transactions on Machine Learning Research (12/2023)
Henry B Moss, Sebastian W Ober, and Victor Picheny. Inducing point allocation for sparse gaussian processes
in high-throughput bayesian optimisation. In International Conference on Artificial Intelligence and
Statistics , pp. 5213–5230. PMLR, 2023.
Harald Niederreiter. Low-discrepancy and low-dispersion sequences. Journal of number theory , 30(1):51–70,
1988.
Frank Noé, Alexandre Tkatchenko, Klaus-Robert Müller, and Cecilia Clementi. Machine learning for molecular
simulation. Annual review of physical chemistry , 71:361–390, 2020.
Danny Panknin, Klaus-Robert Müller, and Shinichi Nakajima. Optimal sampling density for nonparametric
regression. arXiv preprint arXiv:2105.11990 , 2021.
E. Pasolli and F. Melgani. Active learning methods for electrocardiographic signal classification. Information
Technology in Biomedicine, IEEE Transactions on , 14(6):1405–1416, 11 2010. ISSN 1089-7771. doi:
10.1109/TITB.2010.2048922.
Edoardo Pasolli and Farid Melgani. Gaussian process regression within an active learning scheme. In 2011
IEEE International Geoscience and Remote Sensing Symposium , pp. 3574–3577. IEEE, 2011.
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen,
Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Kopf, Edward Yang, Zachary
DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, and
Soumith Chintala. Pytorch: An imperative style, high-performance deep learning library. In Advances in
neural information processing systems , pp. 8026–8037, 2019.
Klaus Pawelzik, Jens Kohlmorgen, and Klaus-Robert Müller. Annealed competition of experts for a
segmentation and classification of switching dynamics. Neural Computation , 8(2):340–356, 1996.
John P Perdew, Kieron Burke, and Matthias Ernzerhof. Generalized gradient approximation made simple.
Physical review letters , 77(18):3865–3868, 1996.
Geoff Pleiss, Martin Jankowiak, David Eriksson, Anil Damle, and Jacob R Gardner. Fast matrix square roots
with applications to gaussian processes and bayesian optimization. arXiv preprint arXiv:2006.11267 , 2020.
Lassi Roininen, Mark Girolami, Sari Lasanen, and Markku Markkanen. Hyperpriors for matérn fields
with applications in bayesian inversion. Inverse Problems and Imaging , 13(1):1–29, 2019. ISSN 1930-
8337. doi: 10.3934/ipi.2019001. URL https://www.aimsciences.org/article/id/d17bde6b-3e5f-
438d-af0a-b712cf433748 .
Nicholas Roy and Andrew McCallum. Toward optimal active learning through sampling estimation of error
reduction. In Proceedings of the 18th International Conference on Machine Learning , pp. 441–448. Morgan
Kaufmann Publishers Inc., 2001.
Didier Rullière, Nicolas Durrande, François Bachoc, and Clément Chevalier. Nested kriging predictions for
datasets with a large number of observations. Statistics and Computing , 28:849–867, 2018.
Priscila TM Saito, Celso TN Suzuki, Jancarlo F Gomes, Pedro J de Rezende, and Alexandre X Falcao.
Robust active learning for the diagnosis of parasites. Pattern Recognition , 48(11):3572–3583, 2015.
Wojciech Samek, Grégoire Montavon, Sebastian Lapuschkin, Christopher J Anders, and Klaus-Robert Müller.
Explaining deep neural networks and beyond: A review of methods and applications. Proceedings of the
IEEE, 109(3):247–278, 2021.
Huziel E Sauceda, Stefan Chmiela, Igor Poltavsky, Klaus-Robert Müller, and Alexandre Tkatchenko. Con-
struction of machine learned force fields with quantum chemical accuracy: Applications and chemical
insights. In Machine Learning Meets Quantum Physics , pp. 277–307. Springer, 2020.
Annie Sauer, Andrew Cooper, and Robert B Gramacy. Vecchia-approximated deep gaussian processes for
computer experiments. Journal of Computational and Graphical Statistics , 32(3):824–837, 2023a.
35Published in Transactions on Machine Learning Research (12/2023)
Annie Sauer, Robert B Gramacy, and David Higdon. Active learning for deep gaussian process surrogates.
Technometrics , 65(1):4–18, 2023b.
Jens Schreiter, Duy Nguyen-Tuong, Mona Eberts, Bastian Bischoff, Heiner Markert, and Marc Toussaint.
Safe exploration for active learning with gaussian processes. In Joint European conference on machine
learning and knowledge discovery in databases , pp. 133–149. Springer, 2015.
Matthias W Seeger, Christopher KI Williams, and Neil D Lawrence. Fast forward selection to speed up
sparse gaussian process regression. In International Workshop on Artificial Intelligence and Statistics , pp.
254–261. PMLR, 2003.
Ozan Sener and Silvio Savarese. Active learning for convolutional neural networks: A core-set approach. In
International Conference on Learning Representations , 2018.
Sambu Seo, Marko Wallat, Thore Graepel, and Klaus Obermayer. Gaussian process regression: Active data
selection and test point rejection. In Mustererkennung 2000 , pp. 27–34. Springer, 2000.
H. Sebastian Seung, Manfred Opper, and Haim Sompolinsky. Query by committee. In Proceedings of the fifth
annual workshop on Computational learning theory , pp. 287–294. ACM, 1992.
Noam Shazeer, Azalia Mirhoseini, Krzysztof Maziarz, Andy Davis, Quoc Le, Geoffrey Hinton, and Jeff
Dean. Outrageously large neural networks: The sparsely-gated mixture-of-experts layer. arXiv preprint
arXiv:1701.06538 , 2017.
Bernard W Silverman. Density estimation for statistics and data analysis , volume 26 of Monographs on
Statistics & Applied Probability . Chapman & Hall/CRC Press, 1986.
AJ. Smola and B. Schölkopf. Sparse greedy matrix approximation for machine learning. In Proceedings
of the 17th International Conference on Machine Learning , pp. 911–918, San Fransisco, CA, USA, 2000.
Max-Planck-Gesellschaft, Morgan Kaufman.
Edward Snelson and Zoubin Ghahramani. Sparse gaussian processes using pseudo-inputs. Advances in neural
information processing systems , 18, 2005.
Masashi Sugiyama and Shinichi Nakajima. Pool-based active learning in approximate linear regression.
Machine Learning , 75(3):249–274, 2009.
Yu-Hang Tang and Wibe A de Jong. Prediction of atomization energy using graph kernel and active learning.
The Journal of chemical physics , 150(4):044107, 2019.
Olivier Teytaud, Sylvain Gelly, Jérémie Mary, et al. Active learning in regression, with an application to
stochastic dynamic programming. In ICINCO 2007 , 2007.
Michalis Titsias. Variational learning of inducing variables in sparse gaussian processes. In Artificial
intelligence and statistics , pp. 567–574. PMLR, 2009.
AlexandreTkatchenkoandMatthiasScheffler. Accuratemolecularvanderwaalsinteractionsfromground-state
electron density and free-atom reference data. Physical review letters , 102(7):073005, 2009.
Simon Tong and Edward Chang. Support vector machine active learning for image retrieval. In Proceedings
of the ninth ACM international conference on Multimedia , pp. 107–118. ACM, 2001.
Volker Tresp. Mixtures of gaussian processes. In Advances in neural information processing systems , pp.
654–660, 2001.
Oliver T Unke, Stefan Chmiela, Michael Gastegger, Kristof T Schütt, Huziel E Sauceda, and Klaus-Robert
Müller. SpookyNet: Learning force fields with electronic degrees of freedom and nonlocal effects. Nat.
Commun. , 12:7273, 2021a.
36Published in Transactions on Machine Learning Research (12/2023)
Oliver T. Unke, Stefan Chmiela, Huziel E. Sauceda, Michael Gastegger, Igor Poltavsky, Kristof T. Schütt,
Alexandre Tkatchenko, and Klaus-Robert Müller. Machine learning force fields. Chem. Rev. , 121(16):
10142–10186, 2021b.
Aad W Van der Vaart, J Harry Van Zanten, et al. Bayesian inference with rescaled gaussian process priors.
Electronic Journal of Statistics , 1:433–448, 2007.
Aad W Van der Vaart, J Harry Van Zanten, et al. Adaptive bayesian estimation using a gaussian random
field with inverse gamma bandwidth. The Annals of Statistics , 37(5B):2655–2675, 2009.
O Anatole von Lilienfeld, Klaus-Robert Müller, and Alexandre Tkatchenko. Exploring chemical compound
space with quantum-based machine learning. Nat. Rev. Chem. , 4:347–358, 2020.
Matthew P. Wand and M Chris Jones. Kernel Smoothing , volume 60 of Monographs on Statistics & Applied
Probability . Chapman & Hall/CRC Press, 1994.
Bin Wang and Xiaofeng Wang. Bandwidth Selection for Weighted Kernel Density Estimation. arXiv e-prints ,
art. arXiv:0709.1616, 09 2007.
Manfred K Warmuth, Jun Liao, Gunnar Rätsch, Michael Mathieson, Santosh Putta, and Christian Lemmen.
Active learning with support vector machines in the drug discovery process. Journal of chemical information
and computer sciences , 43(2):667–673, 2003.
Rebecca Willett, Robert Nowak, and Rui M. Castro. Faster rates in regression via active learning. Advances
in Neural Information Processing Systems , 18, 2005.
Christopher KI Williams and Carl Edward Rasmussen. Gaussian processes for regression. In Advances in
neural information processing systems , pp. 514–520, 1996.
Dongrui Wu. Pool-based sequential active learning for regression. IEEE transactions on neural networks and
learning systems , 30(5):1348–1359, 2019.
Yadong Wu, Zengming Meng, Kai Wen, Chengdong Mi, Jing Zhang, and Hui Zhai. Active learning approach
to optimization of experimental control. Chinese Physics Letters , 37(10):103201, 2020.
Yan Yang and Jinwen Ma. An efficient em approach to parameter learning of the mixture of gaussian
processes. In International Symposium on Neural Networks , pp. 165–174. Springer, 2011.
Kun Yao, John E Herr, David W Toth, Ryker Mckintyre, and John Parkhill. The TensorMol-0.1 model
chemistry: a neural network augmented with long-range physics. Chem. Sci. , 9(8):2261–2269, 2018.
Hwanjo Yu and Sungchul Kim. Passive sampling for regression. In 2010 IEEE International Conference on
Data Mining , pp. 1151–1156. IEEE, 2010.
Chao Yuan and Claus Neubauer. Variational mixture of gaussian process experts. In Advances in Neural
Information Processing Systems , pp. 1897–1904, 2009.
Xiaowei Yue, Yuchen Wen, Jeffrey H Hunt, and Jianjun Shi. Active learning for gaussian process considering
uncertainties with application to shape control of composite fuselage. IEEE Transactions on Automation
Science and Engineering , 18(1):36–46, 2020.
Kai Zhang, Ivor W Tsang, and James T Kwok. Improved nyström low-rank approximation and error analysis.
InProceedings of the 25th international conference on Machine learning , pp. 1232–1239, 2008.
Danian Zheng, Jiaxin Wang, and Yannan Zhao. Non-flat function estimation with a multi-scale support
vector regression. Neurocomputing , 70(1):420–429, 2006.
37Published in Transactions on Machine Learning Research (12/2023)
A Asymptotic results for local polynomial smoothing
In this section, we will review the theory of Panknin et al. (2021).
The prediction of the LPSmodel of order Qunder the bandwidth Σ∈Sd
++inx∈Xcan be understood as
follows: First, the regression problem is localized around xaccording to weights kΣ(·,x)that decrease with
growing distance to x. Then we search for the polynomial up to order Qthat fits the localized regression
problem best. Finally, the evaluation of this polynomial in xis returned as the prediction. Formally, it is
mΣ
Q(x) =p∗
Q,Σ,x(0),where (33)
p∗
Q,Σ,x=argmin
p∈PQ(Rd)/summationdisplayn
i=1kΣ(xi,x) (yi−p(xi−x))2,
andPQ(Rd)is the space of the real polynomial mappings p:Rd→Rup to order Q.
The localization is controlled by Σthrough the kernel weights KΣ(x,xi)forxi∈Xn: For an RBF-kernel,
kΣ(x,x′)decays monotonically with growing distance of x′tox. This decay is dampened or amplified as Σ
increases or decreases, respectively (in the sense of the Loewner order).
For readability, since Σwill be replaced by terms with more involved notation, we redefine (1) by
MSE/parenleftig
x,/hatwidef,Σ|Xn/parenrightig
:=MSE/parenleftig
x,/hatwidefΣ|Xn/parenrightig
. (34)
For a bandwidth space S⊆Sd
++, Panknin et al. (2021) proposed to minimize the AL objective
MISE/parenleftig
q,/hatwidef|Xn/parenrightig
=/integraldisplay
XinfΣ∈SMSE/parenleftig
x,/hatwidef,Σ|Xn/parenrightig
q(x)dx, (35)
which is the optimal MISE, obtained by predictions that are based on locally optimal chosen bandwidths. If
these locally optimal bandwidth choices are well-defined, that is, if for all x∈Xthere exists a unique Σ′∈S
such that
MSE/parenleftig
x,/hatwidef,Σ′|Xn/parenrightig
= inf Σ∈SMSE/parenleftig
x,/hatwidef,Σ|Xn/parenrightig
,
we are able to define the LOB function
Σn(x) =argminΣ∈SMSE/parenleftig
x,/hatwidef,Σ|Xn/parenrightig
.
This function exists, for example, in the isotropic caseS={σId|σ>0}forLPSunder mild conditions,
where we denote Σn(x) =σn(x)Id(see, e.g., Masry (1996; 1997); Fan et al. (1997) or Panknin et al. (2021)
for an overview).
Assuming the isotropic bandwidths candidate space S={σId|σ>0}, theLOBas in Eq. (4)is an
asymptotically well-defined function under mild assumptions6: Denoting the LOBofLPSof orderQby
Σn
Q(x) =σn
Q(x)Idsuch that
σn
Q(x) =argminσ>0MSE/parenleftbig
x,mQ,σId|Xn/parenrightbig
, (36)
asymptotically it holds
σn
Q(x) =CQ/bracketleftig
v(x)
p(x)n/bracketrightig 1
2(Q+1)+dbQ[x,Id]−2
2(Q+1)+d+op/bracketleftig
n−1
2(Q+1)+d/bracketrightig
, (37)
whereCQis a constant, and bQ[x,Id]is a function of xtaken from the asymptotic conditional bias
f(x)−E/bracketleftig
mhnId
Q(x)/vextendsingle/vextendsingle/vextendsingleXn/bracketrightig
ofLPS(Masry, 1996; 1997). That is, for a sequence hn→0asn→∞we can
write the conditional bias, which is of order Q+ 1, as
f(x)−E/bracketleftig
mhnId
Q(x)/vextendsingle/vextendsingle/vextendsingleXn/bracketrightig
=hQ+1
nbQ[x,Id] +op/bracketleftbig
hQ+1
n/bracketrightbig
. (38)
6We require non-vanishing leading bias- and variance-terms of mQ(x), which is guaranteed if ∀x∈Xit holds that bQ[x,Id]̸= 0
from Eq. (38) and v(x)>0.
38Published in Transactions on Machine Learning Research (12/2023)
Eq.(37)shows how LOBscales asymptotically with respect to the training size n, the local noise level
functionv(x)and the training density p(x). The remaining bias component depends on the local structural
complexity, which can be characterized by the derivatives of fin a non-trivial way. Therefore it encodes the
local structural complexity of f. Given all other properties and LOBitself, we are able to formulate LFCin
a closed form.
Definition 6 (Panknin et al. (2021)) .ForLPSof orderQ, theLFCoffinx∈Xis asymptotically given by
Cn
Q(x) =/bracketleftbiggv(x)
p(x)n/bracketrightbiggd
2(Q+1)+d/vextendsingle/vextendsingleΣn
Q(x)/vextendsingle/vextendsingle−1=/bracketleftbiggv(x)
p(x)n/bracketrightbiggd
2(Q+1)+d
σn
Q(x)−d.
As already mentioned in Eq. (35), given a test density q, theALtask is to minimize MISE/parenleftbig
q,mQ|Xn/parenrightbig
. Now,
if LOB is well-defined, we can rewrite
MISE/parenleftbig
q,mQ|Xn/parenrightbig
=/integraldisplay
XinfΣ∈SMSE/parenleftbig
x,mQ,Σ|Xn/parenrightbig
q(x)dx
=/integraldisplay
XMSE/parenleftbig
x,mQ,Σn
Q(x)|Xn/parenrightbig
q(x)dx.
Finally, when solving for the optimal training dataset
X′
n≈argminXn∈XnMISE/parenleftbig
q,mQ|Xn/parenrightbig
,
as in Eq. (3), the optimal training inputs X′
ncan be written asymptotically as an independent and identically
distributed sample from the optimal training distribution, whose density pQ,n
Optpossesses an asymptotic closed
form.
Theorem 7 (Panknin et al. (2021)) .Letv,q∈C0/parenleftbig
X,R+/parenrightbig
for a compact input space X, whereqis a test
probability density. Additionally, assume that vandqare bounded away from zero. I.e., v,q≥ϵfor some
ϵ >0. Letkbe aRBF-kernel with bandwidth parameter space S={σId|σ>0}. LetQ∈Nbe odd and
f∈CQ+1(X)such that the bias of order Q+ 1does not vanish almost everywhere. Then the optimal training
density for LPS of order Qis asymptotically given by
pQ,n
Opt(x)∝/bracketleftbig
Cn
Q(x)q(x)/bracketrightbig2(Q+1)+d
4(Q+1)+dv(x)2(Q+1)
4(Q+1)+d(1 +o(1)).
We will use this optimal distribution to sample X′
n∼pQ,n
Optwith a proposed estimator for Cn
Qthat is scalable
with respect to the input space dimension.
ForLPSwithX′
n∼pandXn∼q, we can asymptotically calculate the relative required sample size from
Definition 2 in Sec. 4.1 by
ϱ(mQ,p) =/bracketleftbigg
MISE(q,mQ|X′
n)
MISE(q,mQ|Xn)/bracketrightbigg2(Q+1)+d
2(Q+1)
. (39)
B Analytic GPR formulations
B.1 Classical Gaussian process regression
TheGPRmodel/hatwidey∼GP (θ)(see, e.g. Williams & Rasmussen (1996)) is defined as follows: The GP is described
by the hyperparameters θ= (µ,λ,/hatwidev,Σ), which are the global constant prior mean µ, the regularization
parameterλ, the label noise variance function /hatwidevand the bandwidth matrix Σof the kernel. If we can assume
homoscedastic noise, we let /hatwidev(x)≡σ2
ε.
The GP prior then assumes the labels YnofXnto be distributed according to Yn=/hatwidey(Xn)∼
N(·;µ(Xn),C(Xn)|θ), for the constant mean function µ(Xn) =µ 1n, and the covariance function
C(Xn) =λKn+diag (/hatwidev(Xn)),
39Published in Transactions on Machine Learning Research (12/2023)
whereKn=KΣ(Xn)is the kernel matrix of Xn.
For test inputs X∗, the posterior predictive distribution of Y∗is then given by
/hatwidey(X∗)∼N(·;µ∗(X∗),C∗(X∗)|θ),
where the predictive mean and covariance are given by
µ∗(X∗) =µ(X∗) +C∗nC−1
n(Yn−µ(Xn)), (40)
C∗(X∗) =C∗−C∗nC−1
nC⊤
∗n, (41)
and we have defined
C(Xn∪X∗) =/bracketleftbigg
CnC⊤
∗n
C∗nC∗/bracketrightbigg
.
B.2 Analytic sparse Gaussian processes
We define the sparse GPRmodel/hatwidey∼SGP (θ)as follows, following Snelson & Ghahramani (2005): The sparse
GP is described by the (hyper-) parameters θ= (µ,λ,/hatwidev,Σ,X†), which are the global constant prior mean µ,
the regularization parameter λ, the label noise variance function /hatwidev, the bandwidth matrix Σof the kernel and
the prior distribution, given by the IP locations X†∈Xm.
Here, the degree of sparsity is described by mIPs: This number can be fixed in advance or gradually
increased with training size n, where the increase mn=o[n]is typically much slower than n. If we can
assume homoscedastic noise, we let /hatwidev(x)≡σ2
ε.
The sparse GP then outputs
/hatwidey(X∗)∼N(·;µ∗(X∗),C∗(X∗)|θe)
for the mean function
µ∗(X∗) =K∗†Q−1
†K⊤
n†(Λ + diag (/hatwidev(Xn)))−1(Yn−µ(Xn))
and the covariance function
C∗(X∗) =K∗−K∗†(K−1
†−Q−1
†)K⊤
∗†+diag (/hatwidev(X∗))
where we have defined K†=KΣ(X†),Kn=KΣ(Xn),K∗†=KΣ(X∗,X†),Kn†=KΣ(Xn,X†),
Q†=K†+K⊤
n†(Λ + diag (/hatwidev(Xn)))−1Kn†,andΛ =diag (λ)withλ=diag (Kn+Kn†K−1
†K⊤
n†).
We chooseµto be the constant mean function, i.e., µ(X) =µ 1nforX∈Xn, noting that other mean
functions are possible.
C LFC of GPR
Theorem 1 (LFCofGPR).Forf∈Cα(X,R),Xn∼pand homoscedastic noise, the GPR-basedLFC
estimate of finx∈Xis asymptotically given by
Cn
GPR(x) :=/bracketleftbigg1
p(x)n/bracketrightbiggd
2α+d
|Σn
GPR(x)|−1. (19)
Proof.LetX=/unionmultidisplayk
i=1Xk
ibeasegmentationoftheinputspacewithnon-emptyinteriors (Xk
1)◦,..., (Xk
k)◦̸=∅,
over which we can define the restricted bandwidth function search space
Sk=/braceleftbigg
Σ(x) =/summationdisplayk
i=1 1Xk
i(x)Σi/vextendsingle/vextendsingle/vextendsingle/vextendsingleΣ1,..., Σk∈S/bracerightbigg
.
40Published in Transactions on Machine Learning Research (12/2023)
Here, 1A(z)is the indicator function, returning 1forz∈Aand0, else. Furthermore let Σk,n∈Skbe the
minimizer of the MISE over Skwith Σk,n(x) =/summationdisplayk
i=1 1Xk
i(x)Σk,n
isuch that
/integraldisplay
XMSE/parenleftig
x,/hatwidefΣk,n(x)|Xn/parenrightig
q(x)dx= min Σ∈Sk/integraldisplay
XMSE/parenleftig
x,/hatwidefΣ(x)|Xn/parenrightig
q(x)dx.
Recall from (9)that Σn
GPR∝n−1
2α+dgenerally holds for arbitrary input spaces. Due to this, asymptotically,
/hatwidef|Xk
idoes not depend on training samples outside Xk
i. Hence, letting Xi,n:=/braceleftbig
x∈Xn/vextendsingle/vextendsinglexi∈Xk
i/bracerightbig
, the
individual Σk,n
iare asymptotically found by solving the isolated segments of the objective
/integraldisplay
Xk
iMSE/parenleftig
x,/hatwidefΣk,n
i|Xi,n/parenrightig
q(x)dx= min Σ∈S/integraldisplay
Xk
iMSE/parenleftig
x,/hatwidefΣ|Xi,n/parenrightig
q(x)dx.
First of all, it is EXi,n=p(Xk
i)n, wherep(A) :=/integraldisplay
Ap(x)dxis the probability for a training sample to fall
intoA⊂X. In addition, we need to account for the expanse of Xkn
i, which we measure by Vol(Xkn
i). Here,
Vol(A) :=/integraldisplay
Adxis the volume of A⊂X. Again with (9), it is therefore
Σk,n
i∝/bracketleftig
p(Xkn
i)/Vol(Xkn
i)n/bracketrightig−1
2α+d.
Subsequently, we can slowly refine the segmentation X=/unionmultidisplaykn
i=1Xkn
i, where max 1≤i≤knVol(Xkn
i)→0for
kn→∞slow enough (with kn=o(n)). Then, for almost every x∈X, there exists a sequence (ik,x)k∈Nwith
x∈Xk
ik,xfor allk∈Nsuch that
Σkn,n
ikn,x=p(x)n(1 +op[1]).
By construction, it is Σkn,n
ikn,x= Σn
GPR(x)(1 +op[1]). It follows Σn
GPR(x) =p(x)n(1 +op[1])such that
|Σn
GPR(x)|=[p(x)n]d
2α+d(1 +op[1]). Therefore, asymptotically, Cn
GPR(x) :=/bracketleftig
1
p(x)n/bracketrightigd
2α+d|Σn
GPR(x)|−1does
not depend on nandp. Under homoscedasticity, asymptotically, Cn
GPRis necessarily a function that only
depends on f, which justifies its use as a measure of LFC. ■
41Published in Transactions on Machine Learning Research (12/2023)
D Algorithmic summary of the proposed AL framework
Algorithm 2: (ΘH,ΣE)←hyper_init (Xn0,Yn0,p0,Xval,Yval)
Input
1: Initial training data (Xn0,Yn0)
2: Training data density p0
3: A labeled validation set (Xval,Yval)
Output
4: Initial hyperparameters ΘH= (B,κ,{σl}L
l=1,σG,λG,XE
†,XG
†,s0,ηs,ϑσ,η0,ηH,ηG)
5: Global (anisotropic) expert bandwidth ΣE∈ΘT
Procedure
6:▷Initialize secondary hyperparameters related to computational complexity
7: Identify κ≡L
8: SetmE←n0andmG←n0
4▷RecallmE=/vextendsingle/vextendsingleXE
†/vextendsingle/vextendsingle,mG=/vextendsingle/vextendsingleXG
†/vextendsingle/vextendsingleare the number of IPs
9: Draw IP locations XE
†,XG
†∼p0as described in Appendix E
10:▷Tune expert-related hyperparameters
11:Choose (B,η 0,ηH) as described in Sec.4.4.3 according to the validation performance of SVGP (θ), whereµ,λ,/hatwidev,ΣE,µ†∈θ
are learned with respect to (Xn0,Yn0)and (B,η 0,ηH)
12: Set ΣE∈ΘT, where we choose ΣE∈θfrom the best performing SVGP (θ)of the previous step
13:▷Initialize secondary hyperparameters related to fine-tuning
14: SetL←7andσl←2l−4
δfor1≤l≤Las described in Sec. 4.4.3
15: Set s0←0.1,ηs←1/√
2andϑσ←0.01as described in Sec. 4.4.3
16:▷Tune MoE related hyperparameters
17:Choose (σG,λG,ηG) as described in Sec.4.4.3 according to the validation performance of /hatwidefMoEfrom(15), where the model
parameters ΘT\{ΣE}from(28)are learned with respect to (Xn0,Yn0)and the model hyperparameters ΘH\{σG,λG,ηG}
from (27) are fixed
18:Choose (ϑσ,s0,L,{σl}L
l=1) as described in Sec.4.4.3 according to the validation performance of /hatwidefMoE, where the model
parameters ΘT\{ΣE}from(28)arelearnedwithrespectto (Xn0,Yn0)andthemodelhyperparameters ΘH\{ϑσ,s0,{σl}L
l=1}
from (27) are fixed
19: Decrease κ∈ΘH(beginning from κ=L) as long as the validation performance of /hatwidefMoEdoes not degrade
E Finding diverse IP locations
In order to obtain diverse IP locations with a certain distribution, we consider two approaches, Stein
variational gradient descent (SVGD) (Liu & Wang, 2016; Han & Liu, 2018) and distributional clustering (DC)
(Krishna et al., 2019).
Stein Variational Gradient Descent SVGD takes a particle swarm and tries to align the empirical
distribution of the particles with a target distribution, of which we require the density, as well as its derivative
(Liu & Wang, 2016). In addition, the individual particles repel each other, such that we have both diversity
and representativeness. In our scenario we have no access to this derivative, such that we resort to the work
of Han & Liu (2018) that is solely based on the density. Since the particles move freely in the input space
and we have to evaluate the target density a considerable number of times, we suggest applying SVGD, when
we deal with well-behaved input spaces and target densities that are easy to evaluate. If the input space is
only given through high-dimensional features from a finite set of samples, SVGD might move particles into
regions far apart from the data manifold.
Distributional Clustering DC is similar to the known k-means clustering (Gan et al., 2020) but solves
a different inertiaobjective, that is modified such that asymptotically, as the number of cluster centers /vextendsingle/vextendsingle/vextendsingleX†/vextendsingle/vextendsingle/vextendsingle→∞, the distribution of the training data is preserved (Krishna et al., 2019). Under the standard
k-means clustering objective, we would observe X†∼pd
2+d(Graf & Luschgy, 2007), where it was Xn∼p.
Since we intend to use clustering for sub-sampling rather than identifying a fixed number of true cluster
centers, we deal with a comparably large number of cluster centers, here. Thus, we will use DC so as to
obtain a representative set of IPs. Due to very mild assumptions on the problem, DC is specifically easy to
perform in higher dimensions.
42Published in Transactions on Machine Learning Research (12/2023)
Dealing with local optima of DC The inertia objective of DC is given by
inertia DC[c|Xn] =/summationdisplay
c∈c/summationdisplay
x∈Ic 1x̸=clog∥x−c∥, (42)
where
Ic=/braceleftbig
x∈Xn/vextendsingle/vextendsingle∥x−c∥≤∥x−c′∥,∀c′∈c/bracerightbig
(43)
are those elements in Xnthat are closest to the center c.
In the classical Lloyd-step the centers are updated so as to minimize the intra-cluster inertia, which is given
in the case of DC by
c∗=argminz∈Ic/summationdisplay
x∈Ic 1x̸=zlog∥x−z∥. (44)
It is a known problem that k-means-related inertia objectives suffer from local optima (Arthur & Vassilvitskii,
2007): The converged solution of cluster centers will typically lie close to their initialization. One way to
tackle this issue in practice is to run multiple repetitions of the procedure, followed by choosing the solution
with minimal inertia. Unfortunately, the amount of local optima increases with the number of cluster centers.
In our case, where we use DC for sub-sampling rather than clustering in its usual sense, we deal with a large
number of clusters such that this strategy becomes computationally tedious.
Complementary to running multiple repetitions of k-means, we will extend the state-of-the-art method
k-means ++for choosing the initial set of clusters in a more sophisticated way, where we additionally account
for the training distribution. Given the inertia objective
inertia [c|Xn] =/summationdisplayn
i=1minc∈c∥xi−c∥2
of the cluster centers c, thek-means ++procedure builds the set of initial cluster centers as follows: Draw the
first center c1randomly from Xn. Then keep track of the current closest squared distance
dm
i= min
j∈{1,...,m}∥xi−cj∥2(45)
of each element xi∈Xnto the so far drawn centers c1,...,cmand sample the next center cm+1with
probability∝(dm
i)n
i=1fromXn. This procedure is repeated until the desired number of cluster centers is
reached.
The advantage of k-means ++is that the initial centers are more diverse than if they were sampled at random
fromXn. However, in its standard form, the centers initialized by k-means ++are themselves distributed
flatter thanXn. And so, in the case of DC, we propose the following adjustment for a distributional
k-means ++:
We sample with probability ∝/parenleftbig
dm
ip(xi)2/d/parenrightbign
i=1fromXn, whereXn∼p.
Symmetrized DC for molecules Since any symmetric molecule has multiple equivalent representations,
care must be taken when measuring distances in DC. The key idea is to always compare the two configurations
in its closest representation. Using the notation from Appendix H.1, let
d(z,z′) = min 1≤s≤s∥Φ(z)−Φ(πsz′)∥
be the symmetrized distance between two molecule representations. The symmetrized DC algorithm is then
obtained by replacing all occurrences of ∥z−z′∥withd(z,z′)in the cluster assignments Ic, the objective
inertia DC[c|Xn], the cluster updates c∗and closest distances dm
ifrom Equations 43, 42, 44 and 45.
F Design choices of the sparse MoE model
InSec.4.3 we have made several design choices with computational feasibility in mind. We will discuss these
summarized in this section.
43Published in Transactions on Machine Learning Research (12/2023)
The gate model While in Sec.4.3 we have chosen the gate gl∼SVGP (θgl)to be aGPRmodel, note that
any choice of model with sufficient flexibility would have been possible. GPRfeatures universal approximation
properties, which makes it a favorable choice.
Furthermore, the gate should come with a small degree of freedom to prevent compared to the experts to
prevent those from overfitting during the training of the MoE. For this reason, and the fact that we have no
ground truth labels for the training of the gate anyhow, we choose our GPR-based gate to be sparse.
Finally, note that we share the set of gate IP locations XG
†across all gate channels. While this is not
necessary, it simplifies our method without costs as the MoEis rather insensitive concerning the gate IP
locations, as long as these are well-spread.
The expert models While we made clear why we use GPRexperts in our work, we left open in Sec.4.3,
whether these experts should be sparse or dense. Here, the deciding factor is the amount of ntraining samples
that we have to deal with: When ngoes beyond a few thousand, we suggest switching to sparse GPRexperts
for computational reasons. Note that after training of the MoE, it is also possible to switch back to full GPR
experts, if one aims for a high accuracy predictor. For the purpose of AL, this is not necessary.
Similar to the gate, we share the IP locations XE
†across all experts, which simplifies our model. In contrast
to the gate situation, the MoEis sensitive to the choice of expert IP locations. Now, if we were to allow
individual IP locations for each expert, an elsewise locally underperforming expert might work better than the
remaining experts due to a lucky choice of its individual IPs. Subsequently, this would result in a sub-optimal
gate and, hence, ultimately in a wrong superior training density estimate.
For better generalization, if our MoEmodel comprises dense GPRexperts, we will either have to rely on
individual training sets for the experts and the gate, or we use leave-one-out expert responses on a shared
training set.
In the sparse expert case, it is necessary to learn reasonable inducing values µ†prior to the actual learning
procedure of the MoEto not get stuck in a spurious solution. Therefore, there should be a short pre-training
phase for each individual expert.
In addition—whether or not the experts are sparse—the shared expert parameters µE,λE,/hatwidev,ΣEshould be
initialized reasonably. In this regard, we suggest training a single, global expert model before the (pre-)training
of the actual experts to obtain those initial parameter estimates for which we have no prior knowledge. If
we assume isotropic bandwidths to be sufficient, we can simply set ΣE=σEIdand learn the scalar σE>0
instead. Note that, from practice, the training of the MoEsuffers tremendously from online changes of the
expert bandwidths. Thus, we suggest to keep ΣEfixed after initialization.
Finally, note that, if we stick with sparse experts after training of the MoE, it can be beneficial for the
prediction accuracy to re-train the MoE, where we keep the gate fixed. In this post-processing step, we would
like to apply larger learning rates on the experts to escape local optima. However, larger learning rates also
lead to underperforming intermediate steps, in which an actively trained gate might reject the best fitting
expert at random—therefore pushing the gate towards a local optimum. Keeping the pre-trained gate fixed
at this point prevents this undesired behavior.
The IPs Recall that we have set the covariance S†= 0of the inducing value distribution to zero, whereas
it could have also been a diagonal or positive definite matrix. Playing around with this parameter, we have
seen no significant improvement that would justify the considerable amount of additional model parameters
from a computational point-of-view.
In our approach we suggest keeping the IP locations fixed, which is also for reasons of computational
feasibility, but, more importantly, adaptive IP locations come along with heavy prediction instabilities during
the training.
We found it necessary and sufficient to initialize the IP locations by state-of-the-art methods, as described in
Appendix E.
TheMoEobjective For the training of our MoEinSec.4.4.1, we added a penalty on small bandwidth
choices. As described in (Lepski, 1991; Lepski & Spokoiny, 1997), the optimal bandwidth choice is the largest
44Published in Transactions on Machine Learning Research (12/2023)
one that is capable of modeling the function. Now that we are able to model a comparably flat function by
small bandwidths, as long as we have got enough training support, it can occur that, with no regularization,
we choose a too-small bandwidth for such a flat region. A too-small bandwidth choice might cause overfitting.
But even worse, in the subsequent ALloop the flat region is falsely identified as complex, leading to more
training queries in this location, which then allow for even smaller bandwidths to model this flat region. We
will demonstrate this pathological behavior for the unregularized case on toy-data in Sec. 5.1.
The gate noise sLike already mentioned in Sec. 4.4.1, it is possible to tune sin the training process:
Remark 8. Shazeer et al. (2017) proposed to learn the sparameter by adding a penalty term to the main
objective that penalizes the imbalance of how likely training inputs are assigned to each expert: Let πb∈[0,1]L
be the expert assignment probabilities of xband defineπB=/summationdisplay
b∈Bπb. Then they add a penalty V[πB]/slashbig
[EπB]2
to the objective, which is the squared coefficient of variation —a coefficient that accounts for the non-uniformity
of a set of positive variables.
We justify our simple heuristic to shrink sin a static way as follows: Recall from Sec.4.3 that sprevents
premature commitment to a spurious solution. When treating sas a trainable parameter, it does not decay
towards zero. Maintaining the noise then prevents the locally best-performing experts from converging by
randomly withholding training samples. For this reason, we find that sbehaves best when decaying towards
zero as the training progresses.
G Supplemental results on the Doppler experiment
G.1 The single-scale GPR model
When training a single-scale GPRmodel on the Doppler dataset, the tuned bandwidth parameter will
typically take an intermediate value, trying to compromise between more complex and simpler regions. This
is reflected in the predictions in Fig.16, where the single-scale GPRmodel suffers from the inhomogeneous
structure, underfitting the complex region to the left while simultaneously overfitting the simple region to the
right.
InFig.17 we compare the performance of our multi-scale MoEapproach to the single-scale GPRmodel. The
consistently inferior performance of the single-scale GPRmodel shows that the issue above persists even for
large training sizes.
G.2 Necessity of the small bandwidth penalty
InAppendix F we discuss overfitting issues with too small local bandwidth estimates as a consequence of
inadequate regularization of LOB. To address this issue, we have proposed to penalize such small bandwidth
choices byϑσpenσ(Xn,Yn,B,w,Θ)with the penalty term penσfrom (25) and a scaling factor ϑσ≥0.
Figure 16: The Doppler experiment: An exemplary dataset and the predictions of a global GPRmodel,
shown on natural x-scale (left) and on logarithmic x-scale (right).
45Published in Transactions on Machine Learning Research (12/2023)
Figure 17: The Doppler experiment: The maxAE (left) and the RMSE(right) of our proposed MoEmodel
in comparison to a single-scale GPR model. The results are averaged over 20repetitions.
Figure 18: The Doppler experiment: An actively sampled dataset (top) with our MoEfit atn= 212training
samples without small bandwidth penalty ( ϑσ= 0), and the associated LOB estimate (bottom).
Now, while the LOBestimate with ϑσ= 0.5(seeFig.4) consistently behaves as expected, we show for
comparison a typical LOBestimate in Fig.18 that results from applying no regularization ( ϑσ= 0).
By chance—here, the flat region of the Doppler function to the right—the trained model suffers from
massive overfitting by too small LOBestimates. These falsely obtained small LOBestimates then lead to
overestimation of LFC, which subsequently results in a detrimental oversampling of these locations by the
AL procedure.
H Supplemental on the malonaldehyde MD simulation experiment
H.1 The sGDML model
The GDML model by Chmiela et al. (2017) represents the geometry x=[R1,...,R a]∈R3×aof each molecule
in terms of the reciprocal distances Φ(x)kl=∥Rk−Rl∥−1of all atom-pairings to achieve roto-translational
invariance of the input. This representation gives us a total d=a(a−1)/2input features. The similarity of
46Published in Transactions on Machine Learning Research (12/2023)
Figure 19: The RMSEunder the uniform test distribution for different variants of sGDML and training
distribution at varying training size: The performance is given for passive sampling, using the original
isotropic sGDML (dotted), anisotropic sGDML (dash-dotted) and our MoEmodel with anisotropic sGDML
experts (dashed), and for the MoEmodel, applying the proposed superior sampling scheme (solid). The
results are averaged over 2repetitions.
a pair of configurations (z,E,F )and(z′,E′,F′)is then given by the extended covariance function
Cov(E,E′) =k(Φ(z),Φ(z′)),
Cov(E,F′) =dk(Φ(z),Φ(z′))
dΦ′dΦ(z′)
dx,
Cov(F,F′) =/bracketleftbiggdΦ(z)
dx/bracketrightbigg⊤dk(Φ(z),Φ(z′))
dΦdΦ′dΦ(z′)
dx.
Hence, we denote the overall kernel function of two configurations by
k(z,z′) =Cov((E,F),(E′,F′))∈R(3a+1)×(3a+1).
Atoms of the same type are physically identical and therefore exchangeable, albeit only a small subset of
such symmetries is exercised at a given (low) MD simulation temperature. Full permutational invariance is
only needed when enough energy is put into the system for all bonds to break and all atoms to disassociate.
The symmetric extension sGDML (Chmiela et al., 2018; 2019) automatically identifies all accessed atom
permutations from the training set and adds this symmetric prior to the covariance function. Formally, let
(πs)s
s=1be atomic permutations that lead to an equivalent molecular representation. Then, the extended
symmetric kernel of sGDML is given by
/tildewidek(z,z′) =/summationdisplays
s=1/summationdisplays
t=1k(πsz,πtz′). (46)
Malonaldehyde possesses s= 4such permutations.
Remark 9. The identified set of permutations is transitively closed to form a group. Under isotropy, it
suffices to permute only one of the two configurations given to the kernel: Permuting both entries (as in (46))
equals permuting one entry and multiplying by the constant s. However, if the applied bandwidth is not of the
form Σ =σId, this property does not hold.
H.2 The malonaldehyde MD simulation experiment under a uniform test distribution
In this scenario, we assume a uniform test density q=U(X). Accordingly, we weight the validation and test
MSEby the importance weights 1//hatwidepX(Xval)and1//hatwidepX(XT). We draw the initial expert training set Xnof
sizen= 29and the gate training set XG
nGvia importance sampling from the remaining pool with weights
1//hatwidepX(Xpool\(Xval∪XT)). By this it is Xn∼U(X).
InFig.20 we show the estimates of LOB,LFC, and the superior training density under the pool test
distribution, evaluated on the relaxed configurations of malonaldehyde. The LFCestimates in Fig.20 confirm
47Published in Transactions on Machine Learning Research (12/2023)
Figure 20: Estimates of LOB(left),LFC(middle) and the superior training density (right) under the pool
test distribution q=U(X), evaluated at the relaxed malonaldehyde configurations, plotted with respect to
the angles of the two aldehyde rotors of malonaldehyde.
our expectation that the transition areas are more complex to model than the regions near the stable
configurations. Subsequently, our active sampling scheme shifts sample mass away from the stable regimes in
favor of the transition areas.
We have plotted the error curves of passive and active sampling schemes in Fig.19. When estimating the
relative sample size (31)that we require to achieve the same RMSEvia active sampling compared to random
test sampling , we obtain ϱ(/hatwidefMoE,/hatwidepGPR,n
Sup ) = 0.965±0.009. This means that we save about 3.5% of samples
with our active sampling scheme. With similar calculations, we save about 27%, when comparing the original
sGDML approach with passive sampling to our MoE model with active sampling.
H.3 A realistic MD simulation AL scenario
In the realistic ab initio FF reconstruction ALscenario, we begin by sampling the initial training set ( Xn0,Yn0)
as well as the validation set ( Xval,Yval) by simulating the true MD trajectory solving the computationally
expensive Schrödinger equation. Estimate the initial MD density pX,0based on (Xn0∪Xval).
Fork∈N0:
•Setqk←p1−1
k+1
X,kto encourage exploration in early iterations and exploitation in later iterations
•Estimate the model /hatwidefk:=/hatwidefMoEbased on (Xnk,Ynk)
•EstimatepGPR,nk
Supbased onqkand/hatwidefk
•Sample a large pool ( Xpool,k +1,/hatwideYpool,k +1) of, e.g., 100,000 candidates by simulating the approximate
MD trajectory using the computationally cheap model /hatwidefk. While simulation, avoid unreliable out-
of-distribution predictions, e.g., by resetting the trajectory in some xwheneverpX,k(x)<ϵdrops
below a reasonable threshold.
•Estimate the trajectory density pX,k+1ofXpool,k +1
•Update the training set ( Xnk+1,Ynk+1) by selecting input candidates from the pool Xpool,k +1with
distribution pGPR,nk
Supand estimating the respective labels solving the Schrödinger equation
48