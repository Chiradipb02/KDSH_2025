Under review as submission to TMLR
Federated Learning with Heterogeneous Diﬀerential Privacy
Anonymous authors
Paper under double-blind review
Abstract
Federated learning (FL) takes a ﬁrst step towards preserving privacy by training s tatistical
models while keeping client data local. Models trained using FL may still indirectly leak
private client information through model updates during training. Diﬀerential privacy (DP)
can be employed on model updates to provide privacy guarantees within FL, typicall y at
the cost of degraded accuracy of the ﬁnal trained model. Both non-private FL and DP-
FL can be solved using variants of the federated averaging ( FedAvg ) algorithm. In this
work, we consider a heterogeneous DP setup where clients may require varying degrees of
privacy guarantees. First, we analyze the optimal solution to a simpliﬁed l inear problem
with (heterogeneous) DP in a Bayesian setup. We ﬁnd that unlike the non-private setup,
where the optimal solution for homogeneous data amounts to a single global so lution for all
clients learned through FedAvg , the optimal solution for each client in this setup would
be a personalized one even when data is homogeneous. We also analyze the privacy-utility
tradeoﬀ for this problem, where we characterize the gains obtained from the heterogeneo us
privacy where some clients opt for less stringent privacy guarantees. We propo se a new
algorithm for federated learning with heterogeneous DP, referred to as FedHDP , which
employs personalization and weighted averaging at the server using privacy choi ces by clients,
to achieve the Bayes optimal solution on a class of linear problems for all cl ients. Through
numerical experiments we show that FedHDP provides up to 9 .27% performance gain
compared to the baseline DP-FL for the considered datasets where 5% of clients opt out o f
DP. Additionally, we show a gap in the average performance of local models b etween non-
private and private clients of up to 3 .49%, empirically illustrating that the baseline DP-FL
might incur a large utility cost when not all clients require the stricter priva cy guarantees.
1 Introduction
The abundance of data and advances in computation infrastructure have enabled the training o f high-quality
machine learning models. On the other hand, the data is distributed over many devices that a re typically
power-constrained and have limited computational capabilities. To reduce the amount of data transmission
over networks and maintain the privacy of raw data, (McMahan et al., 2017) proposed the federated learning
(FL) framework for training a central server-side model using decentralized data a t clients. See the recent
surveys (Kairouz et al., 2019; Li et al., 2020; Wang et al., 2021) for mo re.
Federated learning frameworks aim to train a global model iteratively and col laboratively using clients’
data. During each round, the server has access to a select number of clients, each of whom has a local
dataset. The server broadcasts the current model to such clients, who train the model by taking gradient
steps using their local data on the model and return the gradient-based update back to the server. The
server then aggregates the updates and produces the new global model for the next round. Several pr ior
works on federated learning algorithms have been proposed in the literature to overcome various issues that
arise in realistic federated learning setups, e.g., data heterogeneity (Konečn` y et a l., 2016; Zhao et al., 2018;
Corinzia et al., 2019; Hsu et al., 2019; Karimireddy et al., 2020; Reddi et al ., 2020), and device dropout and
communication cost (Li et al., 2018; Zhu & Jin, 2019; Wang et al., 2020; Al-Shedivat et al., 2020).
Despite the clients’ data being kept on device in federated learning, the deployed model at t he central server
is still vulnerable to various privacy attacks, such as membership inference a ttacks (Shokri et al., 2017) and
model inversion attacks (Fredrikson et al., 2015), among others. In or der to mitigate such a critical issue,
privacy-preserving variations of federated learning algorithms are proposed i n the literature. One promising
1Under review as submission to TMLR
approach to privacy-preserving FL utilizes diﬀerential privacy in order to provide the privacy guarantees.
Diﬀerential privacy is a widely studied and accepted mathematical notion that describ es privacy-preserving
algorithms where the information leakage of private data is bounded. Diﬀeren tial privacy is deﬁned as follows
Deﬁnition 1 (diﬀerential privacy (DP) (Dwork et al., 2014)) .A randomized algorithm A(·), whose image
is denoted as O, is said to be (ǫ,δ)-DP if for any two adjacent inputs Dand D′that diﬀer in just one entry,
and all subsets O⊆Othe following relationship holds
Pr(A(D)∈O)≤eǫPr(A(D′)∈O) +δ. (1)
The diﬀerence in the two adjacent inputs in the DP deﬁnition can be a single sample, a sing le client, or a single
set of clients depending on the application, keeping in mind that the condition must hold fo r all adjacent
inputs. In federated learning, instead of targeting privacy guarantees for individual sam ples of each client, it is
common to consider a diﬀerent diﬀerential privacy guarantee by having the adjacent da tasets describe the case
where we seek to provide privacy at the client-level data (McMahan et al., 2018), i .e., global DP. Moreover,
heterogeneous diﬀerential privacy has been a topic of interest in the literature and ha s been considered in
various works such as (Alaggan et al., 2016; Jorgensen et al., 2015) t hat aim at examining the problem from
a theoretical point of view , and (Zhou et al., 2020; Ferrando et al., 2021; Liu et al., 2021; Amid et a l., 2022)
that study combining public and private datasets to improve the utility of the model . It is worth noting
that using diﬀerential privacy in federated learning causes unavoidable degradation in performance. Several
prior works utilized diﬀerential privacy to provide privacy guarantees for feder ated learning algorithms. For
example, (Truex et al., 2020; Sun et al., 2020; Kim et al., 2021; Song et al., 20 15) apply DP mechanisms
at clients to ensure local DP guarantees, where clients have complete control over the amount of privacy
they desire. On the other hand, (Geyer et al., 2017; McMahan et al., 2018; Andrew et al., 2019; Wei et al.,
2020; Bietti et al., 2022) apply DP mechanisms at the server to ensure global D P guarantees for all clients.
Applying DP typically causes some degradation in utility, i.e., the model’s per formance degrades as the
privacy budget gets smaller (Alvim et al., 2011; Sankar et al., 2013; Makhdoum i et al., 2014; Calmon et al.,
2015). These approaches to privacy-preserving federated learning use ﬁxed privacy budgets f or all clients,
an approach that can be overly strict and cause unnecessary degradation in perform ance. A variation of DP
setups is proposed in the literature, for scenarios with clients and a server, wher e a hybrid model is used
by combining local DP with global DP and giving clients the option to opt in eit her (Avent et al., 2017;
Beimel et al., 2019). Ablender process is considered by Avent et al. (2017) for computing heavy hitters
where some clients opt in local DP while the remaining opt in global DP. Some dra wbacks of these works
include their assumption of clients’ data to be IID, as well as applying local DP which requires a large
number of samples at clients. These two assumptions make applying such an approa ch in FL setups diﬃcult
due to the non-IID nature of clients’ data in FL, and the relatively small number o f samples generated by
clients in FL which requires either increasing the variance of the added noise or relax ing the privacy leakage
budget leading to either large degradation in performance or higher privacy leakage budg ets.
Heterogeneity is a fundamental feature of federated learning, e.g., clients’ dataset s can no longer be considered
IID in FL (Li et al., 2020). This introduces a challenging and critical problem t hat needs to be resolved
to realize the full potential of privacy-preserving FL in realistic environm ents. One possible solution is
based on model personalization, where clients learn personalized local models that performs better on their
local data compared to the global model when heterogeneity exists. There are diﬀerent a pproaches to
personalization in the literature by introducing diﬀerent modiﬁcations to FL a lgorithms, e.g., (Smith et al.,
2017; Wang et al., 2019; Arivazhagan et al., 2019; Khodak et al., 2019; M ansour et al., 2020; Fallah et al.,
2020; Deng et al., 2020; Dinh et al., 2020; Li et al., 2021). Another type of heterogeneity include systems
heterogeneity where diﬀerent devices have diﬀerent capabilities, in terms of various cha racteristics such as
connection, computational, and power capabilities (Li et al., 2018). Solutions to system heterogeneity include
designing algorithms that can tolerate device dropout, reduce communication cost, o r reduce computations
cost (Caldas et al., 2018; Gu et al., 2021; Horvath et al., 2021; Li et al., 2018). In this work, we study
heterogeneity along the privacy axis. We ﬁnd that, similar to other notions of heter ogeneity, addressing this
problem in an optimal fashion requires curating personalized solutions for each client, which is diﬀerent from
the homogeneous non-private setup where one global model can be used to serve all clients .
2Under review as submission to TMLR
Organization & Our Contributions
In this work, we develop a framework to study heterogeneity in privacy requirement s in federated learning
setups. More speciﬁcally, we consider a new setup for privacy-preserving federated learning where privacy
parameters are no longer ﬁxed across all clients. We show that existence of non-private clients who may
choose to relax their privacy choices, even if they represent a small percentage of t he overall population, can
be leveraged to improve the performance of the global model as well as the perso nalized local models for all
clients .Our contributions and the organization of the paper are as follows:
•In Section 2, we propose a heterogeneous setup for privacy in federated learning frameworks. The
proposed setup considers heterogeneity in privacy choices of clients in FL. Instead of granting the
same level of privacy for all clients, each client is given the option to choo se their desired level of
privacy. Moreover, we formally pose an optimization objective for solving the problem from a client’s
point of view.
•In Section 3 , wetheoretically study heterogeneous diﬀerential privacy in the simpliﬁed Bayesian setup
of federated point estimation, introduced by Li et al. (2021) ,where clients are either private or non-
private (i.e., two levels of privacy). We show that unlike the case of non-private FL with homogeneous
data1, where the Bayes optimal solution is a single global model that could be learn t via vanilla
federated averaging, the optimal Bayes solution in diﬀerentially private FL requires personalization,
even in the case of homogeneous DP . We also characterize the optimal degree of personalization based
on the privacy requirements, degree of data heterogeneity, and other parameters (See Theor em 3).
Further, we characterize theprivacy-utility tradeoﬀ observed at clients. Finally, we discuss extension
to federated linear regression and with more than two privacy levels.
•In Section 4, we propose the federated learning with heterogeneous diﬀerential privacy algorithm ,
referred to as FedHDP , for the heterogeneous privacy setup. The FedHDP algorithm extends the
Bayes optimal solution for federated point estimation to be applicable to more realistic scenarios.
•In Section 5 , we provide experimental results of the FedHDP algorithm using various synthetic
and realistic federated datasets from TensorFlow Federated (TFF) (Google, 2019) using reasonable
privacy parameters, where the privacy choices presented to clients are either private or non-pri vate.
Although the design guarantees of FedHDP don’t apply in these complex settings, we experimen-
tally show that it provides signiﬁcant gains compared to DP-FedAvg algorithm (Andrew et al.,
2019), and other stronger variants of it .
2 Privacy Guarantees within Federated Learning
In this section, we brieﬂy describe the federated learning (FL) setup together with existing privacy guarantees .
FLconsists of a central server, who wishes to learn a model, and a set of clients, who cooperate with the
server to learn a model while keeping their data on device. In particular, the central ser ver coordinates the
training of the model using the clients over multiple training rounds. The set of all clients, denoted by C,
contains all clients that wish to cooperate in training the model. Each clien tcj∈Chas a local loss fj(·) and
a local dataset denoted by Dj={dj1,dj2,...,djnj}, where djiis thei-th sample at the j-th client.
During communication round t, the server sends the current model state, i.e., θt, to the set of available
clients in that round, denoted by Ct, who take multiple gradient steps on the model using their own local
datasets to minimize their local loss functions fj(·). The clients then return the updated model to the
server who aggregates them, e.g., by taking the average, to produce the next model sta teθt+1. This
general procedure describes a large class of learning global models with federated lear ning, such as federated
averaging ( FedAvg ) (McMahan et al., 2017).
To design privacy-preserving federated learning algorithms using diﬀerential priva cy, certain modiﬁcations
to the baseline federated averaging algorithm are required. In particular, the fo llowing modiﬁcations are
introduced: clipping and noising. Considering client-level privacy, the averaging opera tion at the server is
the target of such modiﬁcations. Suppose that clients are selected at each round fro m the population of all
clients of size N, with a certain probability denoted by q. First, each client update is clipped to have a norm
1Homogeneous data refers to the case where the data for all cli ents is independent and identically distributed (IID).
3Under review as submission to TMLR
at mostS, then the average is computed followed by adding a Gaussian noise with mean zero a nd co-variance
σ2I=z2(S
qN)2I. The variable zis referred to as the noise multiplier, which dictates the achievable values of
(ǫ,δ)-DP. Training the model through multiple rounds increases the amount of leaked infor mation. Luckily,
the moment accountant method in (Abadi et al., 2016) can be used to provide a tig hter estimate of the
resulting DP parameters ( ǫ,δ). This method achieves client-level diﬀerential privacy deﬁned in Deﬁnition 1.
It is worth noting that the noise can be added at the client side but needs to achieve the des ired resulting
noise variance in the output of the aggregator at the server, which is still t he desired client-level DP.
Selecting the clipping threshold as well as the noise multiplier is essential to obtai ning useful models with
meaningful privacy guarantees. During training, the norm of updates can either increase or decrease; if the
norm increases or decreases signiﬁcantly compared to the clipping norm, the algorithm m ay slow down or
diverge. Andrew et al. (2019) presented a solution to privately and adaptively update the clipping norm
during each round of communication in federated learning based on the feedback from client s on whether or
not their update norm exceeded the clipping norm. We consider this as the baseline for privacy-pr eserving
federated learning algorithm and refer to it in the rest of the paper as DP-FedAvg (Andrew et al., 2019).
The case where no noise is added is the baseline for non-private federated learning algor ithm, which is
referred to simply as Non-Private .
One fundamental aspect of DP-FedAvg is that it provides an equal level of privacy to allclients. This
naturally arises given the assumption that all clients have similar behavi or towards their own privacy in the
federated learning setup. In other words, DP-FedAvg implicitly assumes a homogeneity of the privacy level
is required by all clients. This is in contrast to the heterogeneity feature of f ederated learning setups, where
diﬀerent clients have diﬀerent data, capabilities, and objectives. Next we describe our proposed setup for
federated learning with heterogeneous diﬀerential privacy.
Proposed Setup: Heterogeneous Privacy within Federated Learning
The proposed setup for federated learning with heterogeneous diﬀerential privacy is as follows. Prior to train-
ing, the server presents each client with a set of diﬀerent privacy parameters P={(ǫ1,δ1),(ǫ2,δ2),...,(ǫl,δl)}.
Each client ci∈Cthen makes their choice from the set of privacy parameters based on their desired level o f
privacy. The server then creates lsubsets of clients who share the same choice of privacy parameters, i.e.,
C1,C2,...,Cl, each with their corresponding privacy parameters. The server then coordinates the tr aining of
a global model through updates from clients while ensuring the privacy of each group of clients according to
their privacy parameters is met.
We further examine what the server and clients agree upon at the beginning of training a federated learning
model in terms of privacy to formally deﬁne the considered privacy measures. Each cli entcj, whose dataset is
denoted as Djthat is disjoint from all other clients, requires the server to apply some rando mized algorithm
Aj(·), whose image is denoted as Oj, such that the following holds
Pr(Aj(Dj)∈Oj)≤eǫjPr(Aj(De)∈Oj) +δj, (2)
where Deis the empty dataset, and the relationship holds for all subsets Oj⊆Oj. This achieves client-level
privacy with parameters ( ǫj,δj) from client cj’s point of view. Let us assume we have Nclients, each has
their own privacy requirements for the server ( ǫj,δj) forj∈[N], which should hold regardless the choices
made by any other client. Now, let us have a randomized algorithm A(·), which denotes the composition of
allAj(·)’s; then, the parallel composition property of diﬀerential privacy states t hat the algorithm A(·) is
(ǫc,δc)-DP, which satisﬁes the following:
Pr(A(D)∈O)≤eǫcPr(A(D′)∈O) +δc, (3)
where Dcontains all datasets from all clients and D′contains datasets from all clients but one, Ois the image
ofA(·), and the relationship holds for all neighboring datasets Dand D′that diﬀer by only one client and
allO⊆O. The parallel composition property of diﬀerential privacy states that the r esultingǫc= max iǫi,
andδc= max iδi. Next, considering our setup, let us have lsets of private clients Ci’s. Each client in the
i-th set of clients requires ( ǫpi,δpi)-DP, and without loss of generality, assume that ǫpi≥ǫplandδpi≥δpl
∀i < l . This is the case we consider in this paper, where we apply a randomized algorithm Api(·), whose
image is denoted as Opi, to the dataset that includes all clients in the set Ciand the following holds
Pr(Api(Dpi)∈Opi)≤eǫpiPr(Api(D′
pi)∈Opi) +δpi, (4)
4Under review as submission to TMLR
where Dpicontains all datasets from all clients in Ciand D′
picontains datasets from all clients in that subset
except one, and the relationship holds for all neighboring datasets Dpiand D′
pithat diﬀer by only one client
and allOpi⊆Opi.
Now, let us assume in the proposed heterogeneous diﬀerential privacy setup that each cl ient inCirequires
(ǫpi,δpi)-DP in the sense of (2). As a result, we can see that the only way for DP-FedAvg toguarantee
meeting the privacy requirement for the clients in Clwith (ǫpl,δpl) is to enforce ( ǫpl,δpl)-DP for allclients.
In other words, DP-FedAvg needs to be ( ǫpl,δpl)-DP, i.e., it needs to apply the strictest privacy parameters
to all clients in the sense of (3). On the other hand, in our setup we can guarantee meeting the privacy
requirements for each set of clients by ensuring an ( ǫpi,δpi)-DP for clients in Ci, respectively, in the sense of
(4). In other words, we need to only apply the appropriate DP algorithm with it s appropriate metrics for
each subset of clients to ensure the privacy metrics are met. This in turn results in our setup satisfying the
corresponding privacy requirements needed by each set of clients, which are the main t argets that need to
be achieved in both algorithms from the clients’ point of view in terms o f their desired privacy levels.
Next, in terms of objectives in federated learning setups, the server’s goal is to utilize the clients updates
by averaging them to produce the next model state, and in our case, these updates are subject to speciﬁc
diﬀerential privacy conditions. On the other hand, clients have a diﬀerent objective when it comes to their
performance measures. The clients’ goal is to minimize their loss function giv en all other clients datasets
including their own. However, since clients do not have access to other clients’ raw data, a client desires to
use the information from the diﬀerentially-private updates computed using the datasets by other clients as
well as its own local update in order to reach a solution. Assume that the clien tcjobserves all other clients
DP-statistics of the datasets {ψi:i∈[N]\j}, which are the outputs of a randomized function that satisﬁes
the privacy condition in (2), as well as its own non-DP dataset Dj. Then the client’s Bayes optimal solution
is
θ∗
j= arg min
/hatwideθj/braceleftBig
EDj/bracketleftBig
ℓj(/hatwideθj)/vextendsingle/vextendsingle{ψi:i∈[N]\j},Dj/bracketrightBig/bracerightBig
. (Local Bayes objective)
whereℓj(·) is the loss function used to train a model for clientcj, andDjis the true distribution of the dataset
at clientcj. Notice that clientcjhas access to their own dataset Djand DP-statistics of the other datasets
{/tildewideDi:i∈[N]\j}. From the point of view of client cj, this objective is the Bayes optimal solution when
observing all DP-statistics from other clients that are subject to their priva cy constraints. It is important
to note that (Local Bayes objective) is not suited to a federated optimization framework due to the fact
that even individual updates from other clients are not available to the client to ut ilize, but rather their
aggregation through a global model at the server. In practice , each client utilizes the global model state /hatwideθ
tooptimize the following:
/hatwideθ∗
j= arg min
/hatwideθj/braceleftBig
EDj/bracketleftBig
ℓj(/hatwideθj)/vextendsingle/vextendsingle/hatwideθ,Dj/bracketrightBig/bracerightBig
. (Local personalized federated objective)
We notice that this solution is a form of personalization in federated learni ng, where clients no longer deploy
the global model locally by default, but rather utilize it to derive better local mo dels that perform well on
their own local dataset. In the remainder of this paper we will demonstrate this a pproach’s ability to learn
good (even optimal as we shall see in the next section) personalized local models co mpared to baseline private
federated learning. Next, we will consider the proposed setup for a simpliﬁed federated problem known as
the federated point estimation.
3 Analyzing Heterogeneous Diﬀerential Privacy in Simpliﬁed Settings
In this section, we provide some insights into the heterogeneous diﬀerential privacy problem in a sim-
pliﬁed setup inspired by the one proposed by Li et al. (2021). Recall that in the federated learning
setup, clients are interested in learning good models that perform best on their l ocal datasets. Speciﬁ-
cally, in the federated point estimation setup, clients are interested in lear ning Bayes optimal models in
the sense of (Local Bayes objective) .We show that in this simpliﬁed setup , the solution could be cast
asa bi-level optimization problem, which can be solved as a personalized federated lea rning problem
(Local personalized federated objective) . We ﬁrst start by considering the global estimation on the server and
5Under review as submission to TMLR
show the proposed solution is Bayes optimal for the other clients’ data . Then we consider local estimations
for all sets of clients and show that the proposed solution is Bayes optimal for all clients when using appropri-
ate values of the the respective hyperparameters. We further characterize the privacy-utility tradeoﬀ gains in
theBayes optimal solution compared to variants of diﬀerentially private federated averaging (Andrew et al.,
2019) .
3.1 Analyzing Heterogeneous Diﬀerential Privacy in Federated Point Estimation
We consider a setting consisting of Nclients, each with nsdata points, where the goal of each client is to
estimate the mean of their data. Let us denote the quantity to be estimated at client cjas
φj=φ+pj, (5)
whereφisa global parameter ,andpj∼N(0,τ2) isan inherent Gaussian-distributed hyperparameter that
encompasses the non-IID nature in federated learning setups we are interested in. Increasing τ2makes the
data more uncorrelated at diﬀerent clients, i.e., leading to increase in data heterogeneity .Note that at the
extremeτ2→∞ the clients’ data points are independent of each other. On the other hand, settingτ2= 0
denotes the case of IID clients, i.e., data homogeneity. In other words, in this case, all client data are generated
from the same distribution . The observed samples at client cjare denoted by xj={xj,1,xj,2,...,xj,n s}, and
xj,i=φj+vj,i, (6)
wherevj,i∼N(0,nsα2) is the additive noise in the observations. The loss function at the client cjis
fj(φ) =1
2/parenleftBigg
φ−1
nsns/summationdisplay
i=1xj,i/parenrightBigg2
. (7)
Then minimizing fj(φ) leads the client to have the estimate ˆφj=1
ns/summationtextns
i=1xj,iwhose variance is α2+τ2.
For the sake of simplicity and clarity of analysis, we model the additive no ise only as an addition at the
server side rather than the client side. This way, when the server aggregates the priv ate clients’ updates,
the resulting noise variance for privacy is equivalent to the desired value by the server. It is worth that the
notion of privacy here remains a client-level privacy despite the location of noise addition. We denote the
updates sent to the server by client cjas
ψj=ˆφj+lj, (8)
wherelj∼N(0,γ2
j) for clientcj.Note thatγ2
jis related to the value of the noise multiplier z2at the server.
We will refer to our solution and algorithm as FedHDP in the remainder of the paper. The algorithm’s
pseudocode for federated point estimation is described in Algorithm 1 in Appendix B . In this setup, the
server and clients goals are to minimize the Bayes risk (i.e., test error), deﬁned as follows
θ∗:= arg min
/hatwideθ/braceleftbigg
E/bracketleftbigg1
2/parenleftBig
φ−/hatwideθ/parenrightBig2/vextendsingle/vextendsingle/vextendsingle/vextendsingleψ1,...,ψN/bracketrightbigg/bracerightbigg
. (9)
θ∗
j:= arg min
/hatwideθ/braceleftbigg
E/bracketleftbigg1
2/parenleftBig
φj−/hatwideθ/parenrightBig2/vextendsingle/vextendsingle/vextendsingle/vextendsingle{ψi:i∈[N]\j},ˆφj/bracketrightbigg/bracerightbigg
, (10)
where the ﬁrst corresponds to the server’s Bayes objective, given all clients updat es, while the second is the
client’s Bayes objective, given its non-private estimation as well as other cl ients’ private updates.
In the case of federated point estimation considered here, and more generally for federated linear r egression
considered in Appendix A , the server’s goal is to ﬁnd the following:
/hatwideθ∗:= arg min
/hatwideθ

1
2/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble/summationdisplay
i∈[N]wiψi−/hatwideθ/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
2

, (11)
6Under review as submission to TMLR
wherewi’s are the weights assigned to clients’ updates in the averaging process, while each client has a goal
to ﬁnd the minimizer of their local objective function, i.e.,
/hatwideθ∗
j:= arg min
/hatwideθ/braceleftbigg1
2/bardbl/hatwideθ−/hatwideφj/bardbl2
2+λj
2/bardbl/hatwideθ−/hatwideθ∗/bardbl2
2/bracerightbigg
, (Local FedHDP objective)
whereλjis a regularization parameter that controls the closeness of the personalized mo del towards the global
model. Higher values of λjsteers the personalized model to the global model, while smaller values of λj
steers the personalized model towards the local model at the client. Notice that (L ocalFedHDP objective)
is a special case of the (Local personalized federated objective) where personali zation is performed through
a bi-level regularization . Next, we will discuss why we chose this case and show that the proposed FedHDP
solution converges to the Bayes optimal solution for the server as well as t he clients.
3.1.1 Federated Point Estimation with Private and Non-Private Clients
In our discussion so far, we assumed that clients have multiple privacy levels t o choose from. In realistic
setups, clients are expected to be individuals who may not have complete awareness abo ut what each
parameter means in terms of their privacy. It is worth noting that interpreting the meaning of ǫin diﬀerential
privacy is hard in general (Dwork et al., 2019), and thus it is unrealistic t o assume the average client can
make their choice precisely. Therefore, the server needs to make a choice on how these parameters are
presented to clients. A special case we consider extensively in this paper is the case w ithtwo classes of
private andnon-private clients. Clients who choose to be private are guaranteed a ﬁxed ( ǫ,δ)-DP, while
clients who choose otherwise are not private. In fact ,the approach to privacy from the server’s point of view
is to enable privacy by default for all clients and give each client the option to opt out of privacy if they
desire to do so, which is a more practical solution because clients can make inf ormed decisions about their
privacy , and those who are not as familiar with privacy choices are kept private by def ault. The non-private
choice can be suitable for diﬀerent types of clients such as enthusiasts, beta testers, volunteers, and company
employees, among others. Before we present our proposed solution, we will discuss two major baselines tha t
we consider in this setup:
DP-FedAvg uses the diﬀerentially private federated averaging (Andrew et al., 2019) as the g lobal model,
where all clients are guaranteed the same level of privacy regardless of their pref erence.
HDP-FedAvg ensures privacy for the set of private clients similar to DP-FedAvg , however, no noise is
added to the non-private clients’ updates. By design, HDP-FedAvg is a stronger variant of DP-FedAvg
for a more fair comparison in a heterogeneous privacy setting.
We present our algorithm, FedHDP :federated learning with heterogeneous diﬀerential privac y, specialized
tofederated point estimation with private and non-private clients in Algorithm 1. There are three important
parameters introduced in the algorithm: r(the ratio of the weight assigned to private clients to that of the
non-private ones), γ2(the variance of the noise added for diﬀerential privacy), and λj(a hyperparameter
that controls the degree of personalization at client cj). We shall see that for diﬀerent choices of these
parameters, Algorithm 1 recovers HDP-FedAvg as well as Ditto (Li et al., 2021), and strictly generalizes
them. In the remainder of Section 3.1, we analyze Algorithm 1, and derive the optim al values for randλj
in order to achieve the Bayes optimal solution for the federated point estima tion problem.
Algorithm 1 FedHDP: Federated Learning with Heterogeneous Diﬀerential Privacy (Point Estimatio n)
Inputs:θ0,α2,τ2,γ2,η= 1,{λj}j∈[N],r,ρnp,N.
Outputs:θ∗,{θ∗
j}j∈[N]
At server:
forclientcjinCtin parallel do
ψj←ClientUpdate (θt,cj)
end for
θ∗←1
ρnpN+r(1−ρnp)N/summationtext
ci∈Cnpψi
+r
ρnpN+r(1−ρnp)N/summationtext
ci∈CpψiAt clientcj:
ClientUpdate (θ0,cj):
θ←θ0
θj←θ0
θ←θ−η(θ−1
ns/summationtextns
i=1xj,i)
θ∗
j←θj−ηj/parenleftbig
(θj−1
ns/summationtextns
i=1xj,i) +λj(θj−θ)/parenrightbig
ψ←θ+ /BDcj∈CpN(0,(1−ρnp)Nγ2)
returnψto server
7Under review as submission to TMLR
Symbol Notation
N Number of clients
ρnp Fraction of non-private clients
C Set of clients
Cnp Subset of non-private clients
Cp Subset of private clients
ns Number of samples at each client
nsα2Observation noise variance at a client
τ2Degree of data heterogeneity (non-IIDness) at clients
γ2Privacy noise variance at the server
λj Regularization parameter at client cj
r Ratio of private weights to non-private weights on the server
Table 1: Summary of notation for federated point estima-
tion setup.Figure 1: Server noise variance σ2
svs the
ratio hyperparameter r. (left) Trade-oﬀ for
diﬀerentγ2, (right) trade-oﬀ for diﬀerent
σ2
c:=α2+τ2.
3.1.2 Optimal Global Estimate on the Server
The server’s goal is to combine the updates received from clients such that the result ing noise variance is
minimized, while ensuring the privacy of the set of private clients. Let us denote the sets of private and non-
private clients as CpandCnprespectively, and the fraction of clients with no privacy constraint (non-priva te
clients) asρnp. Also, let γ2
j= 0 for the non-private clients and γ2
j= (1−ρnp)Nγ2for the private clients.
To this end, we use Mahdavifar et al. (2017, Lemma 11) to ﬁnd the optimal aggregator at the server. The
server ﬁrst computes the two intermediate average values for non-private and priva te clients as
θnp=1
ρnpN/summationdisplay
i∈Cnpψi, θ p=1
(1−ρnp)N/summationdisplay
i∈Cpψi. (12)
whereθnp∼N(φ,1
ρnpN(α2+τ2)), andθp∼N(φ,1
(1−ρnp)N(α2+τ2) +γ2). Now, the server aims to combine
such values to compute its estimation θof the value of φwith the goal of minimizing the resulting estimation
noise variance σ2
s.If the resulting weighted average is expanded, it can be expressed as/summationtext
i=[N]wiψi.In this
case, considering the weights used in the weighted average, let us denote the ratio of w eightswi’s dedicated
for private clients to weights for non-private clients by r=wp
wnp.
Lemma 1 (Global estimate optimality) .FedHDP from the server’s point of view, with ratio r∗=
α2+τ2
α2+τ2+(1−ρnp)Nγ2, is Bayes optimal (i.e., θconverges to θ∗) in the considered federated point estimation
problem. Furthermore, the resulting variance is
σ2
s,opt=1
N/bracketleftbigg(α2+τ2)(α2+τ2+ (1−ρnp)Nγ2)
α2+τ2+ρnp(1−ρnp)Nγ2/bracketrightbigg
. (13)
The proof is relegated to the appendix to conserve space. Next, we show some simulat ion results for the
server noise σ2
sagainst the ratio rfor diﬀerent values of α2+τ2andγ2in the federated point estimation
setup with Nclients and ρnp,fraction of non-private clients. The results are shown in Figure 1, and we can
see that the optimal ratio r∗in Lemma 1 minimizes the server variance as expected.
8Under review as submission to TMLR
Lemma 2 (Global model performance gap) .The server-side estimation mean-square error gap between
FedHDP (optimal) and the baselines, HDP-FedAvg andDP-FedAvg , is as follows:
σ2
s,hdp-fedavg−σ2
s,opt=ρnp(1−ρnp)3γ4N
α2+τ2+ρnp(1−ρnp)γ2N≥0, (14)
σ2
s,dp-fedavg−σ2
s,opt=ρnp(1−ρnp)(α2+τ2)γ2+ρnp(1−ρnp)2γ4N
α2+τ2+ρnp(1−ρnp)γ2N≥0, (15)
σ2
s,dp-fedavg−σ2
s,hdp-fedavg =ρnp(1−ρnp)(α2+τ2)γ2+ρ2
np(1−ρnp)2γ4N
α2+τ2+ρnp(1−ρnp)γ2N≥0. (16)
Notice that if ρnp→0(homogeneous private clients) orρnp→1(no private clients) , the gap vanishes
as expected. In other words, the beneﬁt of FedHDP on the server side is only applicable in the case of
heterogeneous diﬀerential privacy. It can be observed that if the number of clients is large ( N→∞ ),
the gap approaches (1 −ρnp)2γ2and (1−ρnp)γ2in (14) and (15), respectively. Notice that having this
constant gap is in contrast to σ2
s,optvanishing as N→∞ .This is expected since the noise in the observation
itself decreases as the number of clients increases and, hence, having the non-private clients alone would be
suﬃcient to (perfectly) learn the optimal global model .Finally , if the noise γ2added for the privacy is large
(γ2→∞ ),which corresponds to a small ǫ,then the gap with optimality grows unbounded .In contrast, in
this case,σ2
s,opt remains bounded, again because the optimal aggregation strategy would be to di scard the
private clients and to only aggregate the non-private updates.
3.1.3 Optimal Local Estimates on Clients
Now that we have characterized the optimal server-side aggregation, we consider o ptimal learning
strategies at the client side. In particular, we show that FedHDP achieves the Bayes optimal solu-
tion (Local Bayes objective) for local estimates at both the private as well as the non-private clients.
Theorem 3 (Personalized local estimate optimality) .Assuming using FedHDP with ratior∗in Lemma 1,
and using the values λ∗
npfor non-private clients and λ∗
pfor private clients stated below, FedHDP is Bayes
optimal (i.e., θjconverges to θ∗
jfor each client j∈[N])
λ∗
np=α2
τ2, (17)
λ∗
p=α2(τ2+α2) +ρnp(1−ρnp)α2γ2N
τ2(τ2+α2) + (1−ρnp)(α2+τ2)γ2+ (1−ρnp)ρnpτ2γ2N. (18)
The proof follows from the properties of Gaussian random variables, (Mahdavifar et al., 2017, Lemma 11),
together with algebraic derivations, which is relegated to the appendix. This result shows that FedHDP
recovers the (Local Bayes objective), which is the best one could hope for even if the client had access to
diﬀerentially private versions of all other clients’ updates without any const raints that arise in federated
learning, such as just having access to the global model.
We also notice that the values of λ∗arediﬀerent for private and non-private clients. We recall that the derived
expression for the personalization parameters for all clients consider the presence of data heterogeneity as
well as privacy heterogeneity. In Table 2 we provide a few important special cases for both λ∗
pandλ∗
npfor
the considered federated point estimation problem.
Table 2: Special cases of FedHDP in the federated point estimation.
No privacy ( ρnp= 1) Homogeneous privacy ( ρnp= 0)
Homogeneous data ( τ2= 0) FedAvg λ∗
np=∞ DP-FedAvg+Ditto λ∗
p=1
γ2
Heterogeneous data ( τ2>0)FedAvg+Ditto λ∗
np=α2
τ2 DP-FedAvg+Ditto λ∗
p=Nα2
Nτ2+(1−ρnp)Nγ2
Homogeneous data & No privacy: In this case, the optimal FedHDP algorithm recovers Fe-
dAvg (McMahan et al., 2017) with no personalization ( λ∗
np=∞). This is not surprising as this is exactly
the setup for which the vanilla federated averaging was originally introduced.
9Under review as submission to TMLR
Heterogeneous data & No privacy: In this case, the optimal FedHDP algorithm recovers
Ditto (Li et al., 2021). Again, this is not surprising as this is exactly t he setup for which Ditto has been
shown to be Bayes optimal.
Homogeneous data & Homogeneous privacy: In this case, the optimal FedHDP algorithm recovers
DP-FedAvg (Andrew et al., 2019), however, with additional personalization using Ditto (Li et al., 2021).
At ﬁrst, this might be surprising as there is no data heterogeneity in this case, whi ch is where Ditto would
be needed. However, a closer look at this case reveals that the noise added due to diﬀerenti al privacy creates
artiﬁcial data heterogeneity that needs to be dealt with using Ditto . In fact, as ǫ→0, or equivalently, as
γ2→∞,for the added noise for privacy, we observe that λ∗
p→0 implying that the local learning becomes
optimal. This is expected since, in this case, the data from other (private) clients is, roughly speaking, so
noisy that it is best to rely solely on the personal data.
Heterogeneous data & Homogeneous privacy: In this case, the optimal FedHDP algorithm again
recovers DP-FedAvg+Ditto . Similar to the homogeneous data case, with γ2→ ∞,we observe that
λ∗
p→0,i.e., the local learning becomes optimal.
Remark: Although the heterogeneous diﬀerential privacy problem is fundamentally diﬀerent from robust-
ness to data-poisoning attack (Li et al., 2021) , its solution bears resemblance to a recently-proposed person-
alization scheme known as Ditto (Li et al., 2021). FedHDP ,in its general form, diﬀers from Ditto in a
number of major ways, and recovers it as a special case . First, theserver-side aggregation in Ditto is the
vanilla FedAvg ; however, in the proposed solution the server-side aggregation is no longer FedAvg , but
rather a new aggregation rule which utilizes the privacy choices made by clients. Seco nd,Ditto , where the
setup includes two sets of clients, i.e., benign and malicious, is designed for robustness against malicious
clients; hence, the performance on malicious clients is not considered. On the other hand, the sets of clients
in our proposed setup are the sets of clients with diﬀerent levels of privacy ; hence, measuring the performance
across allsetsof clients, i.e., clients with diﬀerent privacy levels, is needed, and improving their performance
is desired across all sets of clients. Third, the server in Ditto is unaware of the status of the clients, i.e.,
whether or not they are malicious; while in the proposed setup the server is aware o f the privacy choices
made by clients, and hence can give diﬀerent weights to updates from private and non-private clients .
3.1.4 Privacy-Utility Tradeoﬀ
Thus far , we have shown that for the problem of federated point estimation, the global es timate beneﬁted
greatly from the introduced setup of heterogeneous diﬀerential privacy. A better glo bal estimate would enable
better performance on clients’ devices in the federated point estimation setup, even when no personalization
is utilized. However, a question may arise on whether clients have a utility cost if they choose to remain
private compared to the case where they opt out and become non-private .
Figure 2: The eﬀect of opting out on
the personalized local model estimate as a
function of λwhen employing (left) HDP-
FedAvg+Ditto and (right) FedHDP .To answer this question, we argue that opting out helps the
server to produce a better global estimate, in addition to help-
ing clients to produce better personalized local estimates. In
other words, clients that opt out can produce better personal-
ized local estimates compared to the ones that remain private.
To illustrate the motivation of opting out for clients, we perform
an experiment where we conduct the federated point estimation
experiment for two scenarios. The ﬁrst is the case where client
ckremains private, and the second is the case where ckopts
out of privacy and becomes non-private. For comparison, we
provide the results of the experiments of FedHDP with the
optimal value r∗, as well as HDP-FedAvg+Ditto . The re-
sults of these experiments are shown in Figure 2. We can see
that if the client is non-private, they exhibit improvements in
their estimates using the optimal value λ∗for both algorithms,
but the proposed FedHDP with the optimal value r∗greatly
outperforms the one with vanilla FedAvg . Additionally, in
this problem, we can see that the optimal value of λ∗
npfor non-
private clients is always greater than or equal to the value λ∗
p
10Under review as submission to TMLR
for private clients, which is due to the value of rbeing less than or equal to 1. In other words, non-private
clients have more inﬂuence on the global estimate, and hence, encouraging the local estimat e to get closer to
the global estimate in (Local FedHDP objective) is more meaningful compared to private clients. Further-
more, this experiment illustrates an important trade-oﬀ between privacy and ut ility for each client, where
opting out of privacy improves performance, while maintaining privacy incurs degra ded performance.
3.2 Extension to Federated Linear Regression with Multiple Priva cy Levels
We consider the analysis for the federated point estimation with two privacy levels as a ﬁrst step towards
demonstrating the eﬀectiveness of FedHDP . We extend the analysis to the following setups in Appendix A:
•Federated linear regression with two privacy levels: In this extended setup, we have two
subsets of clients C1andC2, each having its own privacy requirements γ2
1andγ2
2, respectively. We
perform an analysis of the new setup, derive the expressions for the optimal hyper parameters under
a diagonal covariance matrix assumption, which was also made by Li et al. ( 2021).
•Federated linear regression beyond two privacy levels: We also consider the case with more
than two privacy levels in federated linear regression, provide an analysis of t his setup, and show
the solution to the optimal aggregator as well as the optimal regularizat ion parameters for each set
of clients. The solution would still be achieved by FedHDP algorithm, however, now with diﬀerent
values ofλjfor each set of client, and a server-side weighted averaging that depends on the indivi dual
values of noise variance γ2
iof each set of clients.
4 FedHDP: Federated Learning with Heterogeneous Diﬀerenti al Privacy
Now that we have been able to ﬁnd a Bayes optimal solution in the simpliﬁed federat ed point estimation
setup (and some extensions of it) , we build upon the ingredients we used to build a general solution for
federated learning with heterogeneous diﬀerential privacy. We formally present the FedHDP algorithm
and elaborate on its hyperparameters. The FedHDP algorithm that is designed to take advantage of the
aforementioned heterogeneous privacy setup is described in Algorithm 2. Similarly to the simpliﬁed setting,
FedHDP utilizes diﬀerential privacy with adaptive clipping, upweighting of less privat e clients on the server
side, and a simple form of personalization.
Algorithm 2 FedHDP : Federated learning with heterogeneous DP (General Algorithm)
Inputs: model parameters θ0, sensitivity S0, learning
rate η, personalized learning rate ηp, noise multipliers
z, zb, quantile κ, and factor ηb.
Outputs:θT,{θj}j∈[N]
At server:
forround t= 0,1,2, ..., T−1do
Ct←Sample Ntclients from C
forclient cjinCtin parallel do
△θt
j, bt
j←ClientUpdate (θt, cj, St)
end for
forj∈[l]in parallel do
Nt
j←|Ct
j|,zt
j←zjSt
Nt
j
△˜θt
j←1
Nt
j/summationtext
ci∈Ct
j△θt
i+N(0,(zt
j)2I)
end for
△θt←/summationtext
i∈[l]wt
i△˜θt
i
θt+1←θt+△θt
St+1←Ste−ηb/parenleftbig
(1
Nt/summationtext
i∈Ctbt
i+N(0,z2
b1
Nt2))−κ/parenrightbig
end forAt client cj:
ClientUpdate (θ0, cj, S):
θ←θ0
θj←θ0(if not initialized)
B←batch the client’s data Dj
forepoch e= 1,2, ..., E do
forBinBdo
θ←θ−η∇fj(θ, B)
θj←θj−ηp(∇fj(θj, B) +λj(θj−θ0))
end for
end for
△θ←θ−θ0
b← /BD/bardbl△θ/bardbl2≤S
return Clip(△θ, S), bto server
Clip(θ, S):
returnθ×S
max( /bardblθ/bardbl2,S)to client
11Under review as submission to TMLR
First, the notations for the variables used in the algorithm are introduced. T he set ofNclientsCis split
into subsets containing clients grouped according to their desired privacy levels, denot ed byC1,C2,...,Cl. Let
the number of clients in the subset Cibe denoted by Ni=|Ci|. The rest of the hyperparameters in the
algorithm are as follows: the noise multipliers z,zb, the clipping sensitivity S, the learning rate at clients η,
the personalized learning rate at clients ηp, quantileκ, and factor ηb. Also, the superscript ( ·)tis used to
denote a parameter during the t-th training round.
During round tof training, no additional steps are required for the clients during the global model training.
Clients train the received model using their local data followed by sending back their clipped updates ∆ θt
j
along with their clipping indicator bt
jto the server. The server collects the updates from clients and performs
atwo-step aggregation process . During the ﬁrst step, the updates from the clients in each subset Ciare
passed through a ( ǫi,δi) diﬀerentially private averaging function to produce △˜θt
i. In the second step of the
aggregation the outputs of the previous averaging functions are combined to produce the next iteration of
the model. In this step, the server performs a weighted average of the outputs. The weights for this step
are chosen based on the number of clients in each subset in that round, the privacy level s, as well as other
parameters. This part resembles the weighted averaging considered in the aforementi oned federated point
estimation problem in Section 3.1.2. In general, the goal is to give more w eight for updates from clients with
less strict privacy requirement compared to the ones with stricter privacy requirem ents. The output of this
step is△θt, which is then added to the previous model state to produce the next model state.
To further elaborate on the averaging weights, let us reconsider the simple setup w here we have only two
subsets of clients, i.e., C1andC2, with DP parameters ( ǫ1,δ1) and (ǫ2,δ2), respectively. Also suppose that
the second subset has stricter privacy requirements, i.e., ǫ1≥ǫ2andδ1≥δ2The weights wt
1andwt
2during
roundtcan be expressed as follows wt
1=Nt
1
Nt
1+rNt
2andwt
2=rNt
2
Nt
1+rNt
2. In general, we desire the value of the
ratiorbe bounded as 0 ≤r≤1 in FedHDP to use the less-private clients’ updates more meaningfully.
The ﬁrst factor to consider when choosing ris related to the desired privacy budget, lower privacy budgets
requires more noise to be added, leading to a lower value of r. This intuition was veriﬁed in the simpliﬁed
setting in the previous section. Another factor that is more diﬃcult to quantify i s the heterogeneity between
the less-private set of clients and the private set of clients. To illustrate this intuition we give the following
example. Suppose that the model is being trained on the MNIST dataset where each client ha s samples of
only one digit. Consider two diﬀerent scenarios: the ﬁrst is when each of the less-pri vate clients have a digit
drawn uniformly from all digits, and the second is when all of the less-private clients have the same digit.
It can be argued that the ratio r, when every other hyperparameter is ﬁxed, should be higher in the second
scenario compared to the ﬁrst; since contributions from the more-private clients a re more signiﬁcant to the
overall model in the second scenario than the ﬁrst. This will be experimentally v eriﬁed in the experiments
section presented later.
Then, clients need to train personalized models to be used locally. In the personalization process , each
client simultaneously continues learning a local model when participating in a trai ning round using the local
dataset and the most recent version of the global model received during training and the appropriate value
ofλ. It is worth noting that the personalization step is similar in spirit t o the personalized solution to the
federated point estimation problem in Section 3.1.3. Furthermore, the server keeps track of the privacy loss
due to the clients’ participation in each round by utilizing the moment accountant method (Abadi et al.,
2016) for each set of clients to provide them with tighter bounds on their priva cy loss.
5 Experimental Evaluation
Thus far, we showed that FedHDP achieves Bayes optimal performance on a class of linear problems. In
this section, we present the results of a number of more realistic experiments t o show the utility gain of
the proposed FedHDP algorithm with ﬁne-tuned hyperparameters compared to the baseline DP-FedAvg
algorithm, where we additionally apply personalization on this baseline at clients using Di tto (Li et al.,
2021) and refer to it as DP-FedAvg+Ditto .Additionally, we compare the performance against another
stronger baseline, HDP-FedAvg+Ditto , which is a personalized variant of HDP-FedAvg . Note that
HDP-FedAvg+Ditto can be viewed as a special case of FedHDP with uniform averaging, i.e., r= 1,
instead of a weighted averaging at the server. Note that the hyperparameters for the models, such as learning
rate and others, are ﬁrst tuned using the baseline Non-Private algorithm, then the same values of such
12Under review as submission to TMLR
hyperparameters are applied in all the private algorithms. The experiments consider the case where two
privacy levels are presented to each client to choose from, to be private or no n-private. The experiments
show that FedHDP outperforms the baseline algorithms with the right choice of the hyperpara metersr,λ
in terms of the global model accuracy, as well as in terms of the average persona lized local model accuracy.
5.1 Setup
The experiments are conducted on multiple federated datasets, synthetic and realist ic. The synthetic datasets
are manually created to simulate extreme cases of data heterogeneity often exhibit ed in federated learning
scenarios. The realistic federated datasets are from TFF (Google, 2019) , where such datasets are assigned
to clients according to some criteria. The synthetic dataset is referred to as t he non-IID MNIST dataset,
and the number of samples at a client is ﬁxed across all clients. Each client is a ssigned samples randomly
from the subsets of samples each with a single digit between 0 −9. A skewed version of the synthetic dataset
is one where non-private clients are sampled from the clients who have the digit 7 i n their data. In the
non-IID MNIST dataset, we have 2 ,000 clients and we randomly sample 5% of them for training each round.
The realistic federated datasets are the FMNIST and FEMNIST from TFF dataset s. The FMNIST and
FEMNIST datasets contain 3 ,383 and 3,400 clients, respectively, and we sample ∼3% of them for training
each round. TensorFlow Privacy (TFP) (Google, 2018) is used to compute the pr ivacy loss, i.e., the values
of (ǫ,δ), incurred during the training phase. Refer to the appendix for an extended description of the us ed
models and their parameters, as well as an extended version of the results.
Remark: It is worth noting that computing the optimal values of r,λnp, andλpfor non-convex models
such as neural networks is not an easy task. To resolve this issue in this secti on, we treat them as hyperpa-
rameters to be tuned. In practice, we cannot compute these parameters analytically, and hence we choose
these parameters via grid search on the validation set. Note that tuning the regularization parameters λnp
andλpis done locally at clients and, hence, does not lead to any privacy loss. On the other hand, t he
ratio hyperparameter, r, needs tuning by the server, which results in some privacy loss. The recent work by
Papernot & Steinke (2022) shows that tuning hyperparameters from non-private tr aining runs incur signiﬁ-
cant privacy loss while such a hyperparameter tuning based on private runs may lea d to negligible privacy
loss. We leave a comprehensive investigation of this issue to future work.
5.2 Results
In this part, we provide the outcomes of the experiments on the datasets mentioned above. In these exper-
iments, we provide results when 5% of the total client population is non-private . Clients that opt out are
picked randomly from the set of all clients but ﬁxed for a fair comparison acros s all experiments. The excep-
tion for this assumption is for the skewed non-IID MNIST dataset, where clients that opt out are sampled
from the clients who have the digit 7. All other hyperparameters are ﬁxed. To eval uate the performance of
each algorithm, we measure the following quantities for each dataset:
1.Acc g: the average test accuracy on the server test dataset using the global model.
2.Acc g,p,Acc g,np: the average test accuracy of all private andnon-private clients using the global
model on their local test datasets, respectively.
3.Acc l,p,Acc l,np: the average test accuracy of all private andnon-private clients using their personal-
ized local models on their local test datasets, respectively.
4.△g,△l: the gain in the average performance of non-private clients over the private ones using the
global model and the personalized local models on their local test datasets, respect ively; computed
as△g=Acc g,np−Acc g,pand△l=Acc l,np−Acc l,p.
A summary of the results, shown in Table 3 and Table 4, provides the best perfor mance for each experiment
along with their corresponding hyperparameters. More detailed results are show n in the appendix. If diﬀerent
values of the hyperparameters in FedHDP yield two competing results, such as one with better global model
performance at the server and one with better personalized models at the clients, w e show both.
We can see from Tables 3 and 4 that FedHDP allows the server to learn better global models while allowing
clients to learn better personalized local models compared to the other baselines, i. e.,DP-FedAvg+Ditto
13Under review as submission to TMLR
Table 3: Summary of the results of experiments on synthetic datasets : We compare the performance of the
baseline algorithms against FedHDP with tuned hyperparameters. The variance of the performance metric
across clients is between parenthesis.
nonIID MNIST dataset, (3 .6,10−4)-DP
Setup Global model Personalized local models
Algorithm hyperparameters Acc g%Acc g,p%Acc g,np%△g%Acc l,p%Acc l,np%△l%
Non-Private Ditto λnp=0.005 93.8 - 93.75(0.13) - - 99.98(0.001) -
DP-FedAvg+Ditto λp=0.005 88.75 88.64(0.39) - - 99.97(0.002) - -
HDP-FedAvg+Ditto λp=λnp=0.005 87.71 87.55(0.42) 88.35(0.34) 0.8 99.97(0.001) 99.93(0.001)−0.04
FedHDPr=0.01,
λp=λnp=0.00592.48 92.43(0.30) 93.30(0.21) 0.88 99.94(0.001) 99.94(0.001) 0.0
Skewed nonIID MNIST dataset, (3 .6,10−4)-DP
Non-Private Ditto λnp=0.005 93.67 - 93.62(0.15) - - 99.98(0.001) -
DP-FedAvg+Ditto λp=0.005 88.93 88.87(0.35) - - 99.98(0.001) - -
HDP-FedAvg+Ditto λp=λnp=0.005 88.25 88.05(0.39) 89.98(0.05) 1.93 99.97(0.001) 99.85(0.001)−0.11
FedHDPr=0.1,
λp=λnp=0.00590.36 89.96(0.37) 97.45(0.01) 7.49 99.97(0.001) 99.76(0.003)−0.21
FedHDPr=0.9,
λp=λnp=0.00587.96 87.69(0.56) 92.97(0.04) 5.28 99.98(0.001) 99.96(0.001)−0.02
Table 4: Summarized results of experiments on realistic federated datasets : We compare the performance of
the baseline algorithms against FedHDP with the hyperparameters that perform best. The variance of the
performance metric across clients is between parenthesis.
FMNIST dataset, (0 .6,10−4)-DP
Setup Global model Personalized local models
Algorithm hyperparameters Acc g%Acc g,p%Acc g,np%△g%Acc l,p%Acc l,np%△l%
Non-Private Ditto λnp=0.05 89.65 - 89.35(1.68) - - 94.53(0.59) -
DP-FedAvg+Ditto λp=0.05 77.61 77.62(2.55) - - 90.04(1.04) - -
HDP-FedAvg+Ditto λp=λnp=0.005 75.87 75.77(2.84) 74.41(2.8)−1.36 90.45(1.02) 92.32(0.8) 1.87
FedHDPr=0.01,
λp= 0.05,λnp= 0.00586.88 85.36(1.89) 90.02(1.28) 4.66 93.76(0.68) 95.94(0.41) 2.18
FEMNIST dataset, (4 .1,10−4)-DP
Non-Private Ditto λnp=0.25 81.66 - 81.79(1.38) - - 84.46(0.89) -
DP-FedAvg+Ditto λp=0.05 75.42 75.86(1.82) - - 74.69(1.29) - -
HDP-FedAvg+Ditto λp=λnp=0.05 75.12 75.87(1.65) 78.59(1.58) 2.72 74.67(1.34) 75.95(1.12) 1.28
FedHDPr=0.1,
λp=λnp= 0.0576.52 77.91(1.67) 83.9(1.27) 5.99 77.9(1.22) 79.15(0.99) 1.25
FedHDPr=0.01,
λp=λnp= 0.2574.86 77.31(2.18) 86.73(0.98) 9.42 81.19(1.02) 84.68(0.78) 3.49
as well as the FedHDP withr= 1. For example, the gain due to FedHDP compared to the DP-
FedAvg+Ditto in terms of global model performance is up to 9 .27%. For personalized local models,
the gain for clients due to FedHDP compared to DP-FedAvg+Ditto is up to 9.99%. Additionally, we
can also see the cost in the average performance in personalized local models bet ween clients who choose
to opt out of privacy and clients who choose to remain private. This demonstrates the advantage of opting
out, which provides clients with an incentive to opt out of diﬀerential privacy t o improve their personalized
local models, for example, non-private clients can gain up to 3 .49% on average in terms of personalized local
model performance compared to private clients. It is worth mentioning that opt ing out can also improve the
global model’s performance on clients’ local data. We observe that there is up t o 12.4% gain in the average
performance of non-private clients in terms of the accuracy of the global model on t he local data compared
to the one of baseline DP-FedAvg+Ditto . Similar trends can be observed for the other baseline.
6 Conclusion
In this paper, we considered a new aspect of heterogeneity in federated learning setups, namely, heterogeneous
diﬀerential privacy . We proposed a new setup for privacy heterogeneity between clients where privacy levels
are no longer ﬁxed for all clients. In this setup, the clients choose their desired pri vacy levels according to
their preferences and inform the server about the choice. We provided a formal treatment for the federated
14Under review as submission to TMLR
point estimation problem and showed the optimality of the proposed solutio n on the central server as well
as the personalized local models in such setup. Moreover, we have observed that pers onalization becomes
necessary whenever data heterogeneity is present, or privacy is required, or both. We propo sed a new
algorithm called FedHDP for the considered setup. In FedHDP , the aim is to employ diﬀerential privacy
to ensure the privacy level desired by each clients are met, and we proposed a two-st ep aggregation scheme
at the server to improve the utility of the model. We also utilize personaliza tion to improve the performance
at clients. Finally, we provided a set of experiments on synthetic and realis tic federated datasets considering
a heterogeneous diﬀerential privacy setup. We showed that FedHDP outperforms the baseline private FL
algorithm in terms of the global model as well as the personalized local models performance, and showed
an the cost of requiring stricter privacy parameters in such scenarios in terms o f the gap in the average
performance at clients.
Acknowledgement
We are grateful to the anonymous TMLR reviewers whose thoughtful comments help ed signiﬁcantly with
clarity of the presentation of this paper.
Broader Impact & Limitations
In this paper, we investigated a heterogeneous privacy setup where diﬀerent clients ma y have diﬀerent levels
of privacy protection guarantees, and in particular explored an extreme setup where some clients may opt
out of privacy guarantees, to gain improvements in performance. However, the c hoice to loosen privacy
requirements is heavily dependent on the client, the setting, and their valuation of t heir data. Moreover,
since the algorithm orients the model towards the less private clients, it ma y introduce unfairness for the
more private clients. Additionally, the server may have its own requirement s during training, for example, a
lower limit to the fraction of less private clients or vice versa, where the privacy choices may be overridden
by the server. Overall, we believe that the interplay between all of these diﬀerent societal aspects need to
be carefully studied before the proposed mechanisms in this paper can be practicall y used.
We acknowledge that some of the assumptions inthetheoretical study of the federated linear regression
and federated point estimation setup are unrealistic, but similar assumptions have been made in prior work
of (Li et al., 2021). For example, we neglected the eﬀect of clipping, weassumed that all clients have the
same number of samples , and assumed the covariance matrix is diagonal . On the other hand, for more
complex models such as the ones used in the experiments, ﬁnding the best values of weights to be used in
the aggregator at the server as well as the personalization parameters for ea ch client is not straightforward,
as some of the theoretical constructs in this paper are not estimable from data. Nevertheless, we believe
that the theoretical studies in this paper can be used to build intuition about heterog eneous privacy setups
and can be used as guiding principles for designing new algorithms.
Finally, the FedHDP algorithm comes with two additional hyperparameters compared with DP-FedAvg :
r(the weight ratio of private and non-private clients at the server), and λj(the degree of personalization at
clientcj). In this paper, we chose rbased on grid search, however that will naturally incur a loss of privacy
that we did not carefully study. Having said that, recent work by Papernot & Steink e (2022) suggests that
the privacy loss due to such hyperparameter tuning based on private training runs mi ght be manageable but
the exact interplay remains to be studied in future work.
References
Martin Abadi, Andy Chu, Ian Goodfellow, H Brendan McMahan, Ilya Mironov, Kunal T alwar, and Li Zhang.
Deep learning with diﬀerential privacy. In Proceedings of the 2016 ACM SIGSAC conference on computer
and communications security , pp. 308–318, 2016.
Maruan Al-Shedivat, Jennifer Gillenwater, Eric Xing, and Afshin Rostamizadeh. F ederated learning via
posterior averaging: A new perspective and practical algorithms. arXiv preprint arXiv:2010.05273 , 2020.
Mohammad Alaggan, Sébastien Gambs, and Anne-Marie Kermarrec. Heterogeneous diﬀerenti al privacy.
Journal of Privacy and Conﬁdentiality , 7(2):127–158, 2016.
15Under review as submission to TMLR
Mário S Alvim, Miguel E Andrés, Konstantinos Chatzikokolakis, Pierpaol o Degano, and Catuscia
Palamidessi. Diﬀerential privacy: on the trade-oﬀ between utility and inform ation leakage. In Inter-
national Workshop on Formal Aspects in Security and Trust , pp. 39–54. Springer, 2011.
Ehsan Amid, Arun Ganesh, Rajiv Mathews, Swaroop Ramaswamy, Shuang Song, Thom as Steinke, Vinith M
Suriyakumar, Om Thakkar, and Abhradeep Thakurta. Public data-assisted mirror des cent for private
model training. In International Conference on Machine Learning , pp. 517–535. PMLR, 2022.
Galen Andrew, Om Thakkar, H Brendan McMahan, and Swaroop Ramaswamy. Diﬀerenti ally private learn-
ing with adaptive clipping. arXiv preprint arXiv:1905.03871 , 2019.
Manoj Ghuhan Arivazhagan, Vinay Aggarwal, Aaditya Kumar Singh, and Sunav Choudhary . Federated
learning with personalization layers. arXiv preprint arXiv:1912.00818 , 2019.
Brendan Avent, Aleksandra Korolova, David Zeber, Torgeir Hovden, and Benjami n Livshits. BLENDER:
Enabling local search with a hybrid diﬀerential privacy model. In 26th{USENIX}Security Symposium
({USENIX}Security 17) , pp. 747–764, 2017.
Amos Beimel, Aleksandra Korolova, Kobbi Nissim, Or Sheﬀet, and Uri Stemmer. The power of synergy in
diﬀerential privacy: Combining a small curator with local randomizers. arXiv preprint arXiv:1912.08951 ,
2019.
Alberto Bietti, Chen-Yu Wei, Miroslav Dudik, John Langford, and Steven Wu. Perso nalization improves
privacy-accuracy tradeoﬀs in federated learning. In International Conference on Machine Learning , pp.
1945–1962. PMLR, 2022.
Sebastian Caldas, Jakub Konečny, H Brendan McMahan, and Ameet Talwalkar. Expanding the reach of
federated learning by reducing client resource requirements. arXiv preprint arXiv:1812.07210 , 2018.
Flavio P Calmon, Ali Makhdoumi, and Muriel Médard. Fundamental limits of perf ect privacy. In 2015 IEEE
International Symposium on Information Theory (ISIT) , pp. 1796–1800. IEEE, 2015.
Luca Corinzia, Ami Beuret, and Joachim M Buhmann. Variational federated multi-tas k learning. arXiv
preprint arXiv:1906.06268 , 2019.
Yuyang Deng, Mohammad Mahdi Kamani, and Mehrdad Mahdavi. Adaptive personalized federa ted learning.
arXiv preprint arXiv:2003.13461 , 2020.
Canh T Dinh, Nguyen H Tran, and Tuan Dung Nguyen. Personalized federated learning with mo reau
envelopes. arXiv preprint arXiv:2006.08848 , 2020.
Cynthia Dwork, Aaron Roth, et al. The algorithmic foundations of diﬀerent ial privacy. Foundations and
Trends in Theoretical Computer Science , 9(3-4):211–407, 2014.
Cynthia Dwork, Nitin Kohli, and Deirdre Mulligan. Diﬀerential privacy i n practice: Expose your epsilons!
Journal of Privacy and Conﬁdentiality , 9(2), 2019.
Alireza Fallah, Aryan Mokhtari, and Asuman Ozdaglar. Personalized federated learning: A meta-learning
approach. arXiv preprint arXiv:2002.07948 , 2020.
Cecilia Ferrando, Jennifer Gillenwater, and Alex Kulesza. Combining public and private data. arXiv preprint
arXiv:2111.00115 , 2021.
Matt Fredrikson, Somesh Jha, and Thomas Ristenpart. Model inversion attack s that exploit conﬁdence
information and basic countermeasures. In Proceedings of the 22nd ACM SIGSAC conference on computer
and communications security , pp. 1322–1333, 2015.
Robin C Geyer, Tassilo Klein, and Moin Nabi. Diﬀerentially private federated learning: A client level
perspective. arXiv preprint arXiv:1712.07557 , 2017.
Google. TensorFlow Privacy, 2018. URL http://tensorflow.org/privacy .
16Under review as submission to TMLR
Google. TensorFlow Federated, 2019. URL http://tensorflow.org/federated .
Xinran Gu, Kaixuan Huang, Jingzhao Zhang, and Longbo Huang. Fast federated learning i n the presence
of arbitrary device unavailability. Advances in Neural Information Processing Systems , 34:12052–12064,
2021.
Samuel Horvath, Stefanos Laskaridis, Mario Almeida, Ilias Leontiadis, St ylianos Venieris, and Nicholas Lane.
FjORD: Fair and accurate federated learning under heterogeneous targets with ordered dropo ut.Advances
in Neural Information Processing Systems , 34:12876–12889, 2021.
Tzu-Ming Harry Hsu, Hang Qi, and Matthew Brown. Measuring the eﬀects of non-identical dat a distribution
for federated visual classiﬁcation. arXiv preprint arXiv:1909.06335 , 2019.
Zach Jorgensen, Ting Yu, and Graham Cormode. Conservative or liberal? perso nalized diﬀerential privacy.
In2015 IEEE 31St international conference on data engineerin g, pp. 1023–1034. IEEE, 2015.
Peter Kairouz, H Brendan McMahan, Brendan Avent, Aurélien Bellet, Mehdi Bennis, Arjun Niti n Bhagoji,
Keith Bonawitz, Zachary Charles, Graham Cormode, Rachel Cummings, et al. Adva nces and open prob-
lems in federated learning. arXiv preprint arXiv:1912.04977 , 2019.
Sai Praneeth Karimireddy, Satyen Kale, Mehryar Mohri, Sashank Reddi, Sebastian Stich, and
Ananda Theertha Suresh. Scaﬀold: Stochastic controlled averaging for federated learning . In Interna-
tional Conference on Machine Learning , pp. 5132–5143. PMLR, 2020.
Mikhail Khodak, Maria-Florina Balcan, and Ameet Talwalkar. Adaptive gradi ent-based meta-learning meth-
ods. arXiv preprint arXiv:1906.02717 , 2019.
Muah Kim, Onur Günlü, and Rafael F Schaefer. Federated learning with local diﬀerential pr ivacy: Trade-oﬀs
between privacy, utility, and communication. In ICASSP 2021-2021 IEEE International Conference on
Acoustics, Speech and Signal Processing (ICASSP) , pp. 2650–2654. IEEE, 2021.
Jakub Konečn` y, H Brendan McMahan, Daniel Ramage, and Peter Richtárik. Federated o ptimization: Dis-
tributed machine learning for on-device intelligence. arXiv preprint arXiv:1610.02527 , 2016.
Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and Vi rginia Smith. Federated
optimization in heterogeneous networks. arXiv preprint arXiv:1812.06127 , 2018.
Tian Li, Anit Kumar Sahu, Ameet Talwalkar, and Virginia Smith. Federated learni ng: Challenges, methods,
and future directions. IEEE Signal Processing Magazine , 37(3):50–60, 2020.
Tian Li, Shengyuan Hu, Ahmad Beirami, and Virginia Smith. Ditto: Fair and ro bust federated learning
through personalization. International Conference on Machine Learning , 2021.
Junxu Liu, Jian Lou, Li Xiong, Jinfei Liu, and Xiaofeng Meng. Projected federated av eraging with hetero-
geneous diﬀerential privacy. Proceedings of the VLDB Endowment , 15(4):828–840, 2021.
Hessam Mahdavifar, Ahmad Beirami, Behrouz Touri, and Jeﬀ S Shamma. Global ga mes with noisy infor-
mation sharing. IEEE Transactions on Signal and Information Processing ove r Networks , 4(3):497–509,
2017.
Ali Makhdoumi, Salman Salamatian, Nadia Fawaz, and Muriel Médard. From the inf ormation bottleneck to
the privacy funnel. In 2014 IEEE Information Theory Workshop (ITW 2014) , pp. 501–505. IEEE, 2014.
Yishay Mansour, Mehryar Mohri, Jae Ro, and Ananda Theertha Suresh. Three approaches for personaliza-
tion with applications to federated learning. arXiv preprint arXiv:2002.10619 , 2020.
Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arca s.
Communication-eﬃcient learning of deep networks from decentralized data. In Artiﬁcial Intelligence and
Statistics , pp. 1273–1282. PMLR, 2017.
17Under review as submission to TMLR
H Brendan McMahan, Daniel Ramage, Kunal Talwar, and Li Zhang. Learning diﬀerentiall y private recurrent
language models. In International Conference on Learning Representations , 2018.
Nicolas Papernot and Thomas Steinke. Hyperparameter tuning with Rényi diﬀerentia l privacy. International
Conference on Learning Representations (ICLR) , 2022.
Sashank Reddi, Zachary Charles, Manzil Zaheer, Zachary Garrett, Keith Rush, Jakub K onečn` y, Sanjiv
Kumar, and H Brendan McMahan. Adaptive federated optimization. arXiv preprint arXiv:2003.00295 ,
2020.
Lalitha Sankar, S Raj Rajagopalan, and H Vincent Poor. Utility-privacy tr adeoﬀs in databases: An
information-theoretic approach. IEEE Transactions on Information Forensics and Security , 8(6):838–852,
2013.
Reza Shokri, Marco Stronati, Congzheng Song, and Vitaly Shmatikov. Membership infer ence attacks against
machine learning models. In 2017 IEEE Symposium on Security and Privacy (SP) , pp. 3–18. IEEE, 2017.
Virginia Smith, Chao-Kai Chiang, Maziar Sanjabi, and Ameet Talwalkar. Federated multi-task learning.
arXiv preprint arXiv:1705.10467 , 2017.
Shuang Song, Kamalika Chaudhuri, and Anand Sarwate. Learning from data with heterogeneo us noise using
SGD. In Artiﬁcial Intelligence and Statistics , pp. 894–902. PMLR, 2015.
Lichao Sun, Jianwei Qian, Xun Chen, and Philip S Yu. LDP-FL: Practical private agg regation in federated
learning with local diﬀerential privacy. arXiv preprint arXiv:2007.15789 , 2020.
Stacey Truex, Ling Liu, Ka-Ho Chow, Mehmet Emre Gursoy, and Wenqi Wei. LDP-Fed: Federated learning
with local diﬀerential privacy. In Proceedings of the Third ACM International Workshop on Edge Systems,
Analytics and Networking , pp. 61–66, 2020.
Hongyi Wang, Mikhail Yurochkin, Yuekai Sun, Dimitris Papailiopoulos, and Y asaman Khazaeni. Federated
learning with matched averaging. arXiv preprint arXiv:2002.06440 , 2020.
Jianyu Wang, Zachary Charles, Zheng Xu, Gauri Joshi, H Brendan McMahan, Maruan A l-Shedivat, Galen
Andrew, Salman Avestimehr, Katharine Daly, Deepesh Data, et al. A ﬁeld guide to feder ated optimization.
arXiv preprint arXiv:2107.06917 , 2021.
Kangkang Wang, Rajiv Mathews, Chloé Kiddon, Hubert Eichner, Françoise Beaufays, a nd Daniel Ramage.
Federated evaluation of on-device personalization. arXiv preprint arXiv:1910.10252 , 2019.
Kang Wei, Jun Li, Ming Ding, Chuan Ma, Howard H Yang, Farhad Farokhi, Shi Jin, Tony QS Quek, and
H Vincent Poor. Federated learning with diﬀerential privacy: Algorithms and per formance analysis. IEEE
Transactions on Information Forensics and Security , 15:3454–3469, 2020.
Yue Zhao, Meng Li, Liangzhen Lai, Naveen Suda, Damon Civin, and Vikas Chandra. Federa ted learning
with non-iid data. arXiv preprint arXiv:1806.00582 , 2018.
Yingxue Zhou, Zhiwei Steven Wu, and Arindam Banerjee. Bypassing the ambient dimension: Pr ivate sgd
with gradient subspace identiﬁcation. arXiv preprint arXiv:2007.03813 , 2020.
Hangyu Zhu and Yaochu Jin. Multi-objective evolutionary federated learning. IEEE transactions on neural
networks and learning systems , 31(4):1310–1322, 2019.
18Under review as submission to TMLR
Appendix: Organization & Contents
We include additional discussions and results complementing the main paper in the appendix .
• Appendix A includes a discussion on federated linear regression and the optimality of FedHDP
along with some related simulation results.
• Appendix B includes proofs and additional results for the federated point estimatio n considered in
the paper.
• Finally, we include additional information about the experimental setup alo ng with extended versions
of the results of each experiment in Appendix C.
19Under review as submission to TMLR
ATheoretical Derivations for Federated Linear Regression
In this section, we consider applying the proposed algorithm FedHDP on the simpliﬁed setup of federated
linear regression problem, ﬁrst introduced by Li et al. (2021). We utilize a si milar setup as the federated
point estimation problem, solve the optimization problem, and show the Bay es optimality of FedHDP on
the global model on the server, as well as the optimality of local models on cli ents.
A.1 Federated Linear Regression Setup
Assume the number of samples per client is ﬁxed and the the eﬀect of clipping is negligible. Let us denote
the total number of clients as N, of whomN1=ρ1Nare private with privacy level p1andN2= (1−ρ1)N
are private with privacy level p2, wherep2is stricter than p1, i.e., more private. The subset of clients with
privacy level p1is denoted by C1, while the subset of clients with privacy level p2is denoted by C2. Denote
the number of samples held by each client as ms, the samples at client cjas{Fj,xj}, where Fjis the data
features matrix, and xjis the response vector. Let us assume that the features matrix Fjhas the property
of diagonal covariate covariance, i.e., FT
jFj=nsId.Let us denote the relationship between xjand Fjas
xj=Fjφj+vj (19)
where elements of the observations noise vector vjare drawn independently from N(0,β2), andφjis the
vector of length dto be estimated. The vector φjis described as
φj=φ+pj (20)
where pj∼N(0,τ2Id), andφis the vector to be estimated at the server. It is worth noting that τ2is
a measure of relatedness, as speciﬁed by Li et al. (2021), where larger values of τ2reﬂect increasing data
heterogeneity and vice versa. The local loss function at client cjis as follows
fj(φ) =1
ms/bardblFjφ−xj/bardbl2
2 (21)
Local estimate of φjat clientcjthat minimizes the loss function given Fjand xjis denoted by /hatwideφjand is
computed as
/hatwideφj=/parenleftbig
FT
jFj/parenrightbig−1FT
jxj, (22)
which is distributed as /hatwideφj∼N/parenleftbig
φj,β2(FT
jFj)−1/parenrightbig
. As assumed earlier, let FT
jFj=nsId, then the loss function
can be translated to
fj(φ) =1
2/vextenddouble/vextenddoubleφ−1
nsns/summationdisplay
i=1xj,i/vextenddouble/vextenddouble2
2, (23)
where xj,i’s are the noisy observations of the vector φjat clientcj, which holds due to the assumption of
the diagonal covariate covariance matrix . The updates sent to the server by client cjare as follows
ψj=/hatwideφj+lj (24)
where lj∼N(0,N1γ2
1Id) for private clients cj∈C1orlj∼N(0,N2γ2
2Id) for private clients cj∈C2. Note
that as we mentioned in the paper, we still consider client-level privacy; however, w e move the noise addition
process from the server side to the client side. This is done such that when the server ag gregates the private
clients’ updates in each subset the resulting privacy noise variance is equivalent t o the desired value by the
server, i.e., γ2
1andγ2
2. This is done for simplicity and clarity of the discussion and proofs.
In this setup, the problem becomes a vector estimation problem and the goal at the serv er is to estimate the
vectorφgiven the updates from all clients, denoted by {ψi:i∈[N]}as
θ∗:= arg min
/hatwideθ/braceleftbigg
E/bracketleftbigg1
2/bardbl/hatwideθ−φ/bardbl2
2/vextendsingle/vextendsingle/vextendsingle/vextendsingleψ1,...,ψN/bracketrightbigg/bracerightbigg
. (25)
20Under review as submission to TMLR
On the other hand, client cj’s goal is to estimate the vector φjgiven their local estimate /hatwideφjas well as the
updates from all other clients {ψi:i∈[N]\j}as
θ∗
j:= arg min
/hatwideθ/braceleftbigg
E/bracketleftbigg1
2/bardbl/hatwideθ−φj/bardbl2
2/vextendsingle/vextendsingle/vextendsingle/vextendsingle{ψi:i∈[N]\j},ˆφj/bracketrightbigg/bracerightbigg
.(Local Bayes objective)
Now, considering the value of φ, the covariance matrix of client cj’s update is denoted by Σ j. The value of
the covariance matrix can be expressed as follows
Σj=/braceleftbiggβ2(FT
jFj)−1+ (τ2+N1γ2
1)Id,ifcj∈C1
β2(FT
jFj)−1+ (τ2+N2γ2
2)Id,ifcj∈C2(26)
We have FT
jFj=nsId, and letβ2
ns=α2,σ2
c=α2+τ2,σ2
p1=σ2
c+N1γ2
1, andσ2
p2=σ2
c+N2γ2
2, then we have
Σj=/braceleftbigg
(α2+τ2+N1γ2
1)Id,ifcj∈C1
(α2+τ2+N2γ2
2)Id,ifcj∈C2(27)
=/braceleftbiggσ2
p1Id,ifcj∈C1
σ2
p2Id,ifcj∈C2(28)
Next, we discuss the optimality of FedHDP for the speciﬁed federated linear regression problem for the
server’s global model as well as the clients personalized local models.
A.2 Global Estimate on The Server
In the considered federated setup, the server aims to ﬁnd /hatwideθ∗described as follows
/hatwideθ∗:= arg min
/hatwideθ

1
2/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble/summationdisplay
i∈[N]wiψi−/hatwideθ/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
2

. (29)
The server’s goal , in general, is to combine the client updates such that the estimation error of φin (25)
is minimized , i.e., the server aims to ﬁnd the Bayes optimal solution described in (25). For the considered
setup, the server aims to utilize the updates sent by clients, i.e., {ψi:i∈[N]}, to estimate the vector φ.
The estimate at the server is denoted by θ.Our goal in this part is to show that the solution to (29), which
is the solution in FedHDP algorithm converges to the Bayes optimal solution in (25) . First, we state an
important lemma that will be used throughout this section.
Lemma 4 (Lemma 2 in Li et al. (2021)) .Letφbe drawn from the non-informative uniform prior on Rd.
Also, let{ψi:i∈[N]}denote noisy observations of φwith independent additive zero-mean independent
Gaussian noise and corresponding covariance matrices {Σi:i∈[N]}. Let
Σφ=/parenleftBig/summationdisplay
i∈[N]Σ−1
i/parenrightBig−1
. (30)
Then, conditioned on {ψi:i∈[N]}, we have
φ= Σ φ/summationdisplay
i∈[N]Σ−1
iψi+pφ, (31)
where pφ∼N(0,Σφ), which is independent of {ψi:i∈[N]}.
Next, we state the Bayes optimality of the solution at the server.
Lemma 5 (Global estimate optimality) .The proposed solution, from the server’s point of view, with weights
wj’s chosen below, is Bayes optimal in the considered federate d linear regression problem.
wj=/braceleftbigg1
N1+N2r∗,ifcj∈C1
r∗
N1+N2r∗,ifcj∈C2(32)
21Under review as submission to TMLR
where
r∗=σ2
c+N1γ2
1
σ2c+N2γ2
2. (33)
Furthermore, the covariance of the estimation error is:
Σs,opt=1
N/bracketleftbigg(σ2
c+N1γ2
1)(σ2
c+N2γ2
2)
σ2c+ (1−ρ1)N1γ2
1+ρ1N2γ2
2/bracketrightbigg
Id. (34)
Proof. First, for the considered setup, Lemma 4 states that the optimal aggregator at the server is the
weighted average of the client updates. The server observes the updates {ψi:i∈[N]}, which are noisy
observations of φwith zero-mean Gaussian noise with corresponding covariance matrices {Σi:i∈[N]}.
Then, the server computes its estimate θofφas
θ= Σ θ/summationdisplay
i∈[N]Σ−1
iψi+pθ, (35)
where pθ∼N(0,Σθ) and
Σθ=/parenleftBig/summationdisplay
i∈[N]Σ−1
i/parenrightBig−1
=/parenleftBig
N1(σ2
c+N1γ2
1)−1Id+N2(σ2
c+N2γ2
2)−1Id/parenrightBig−1
(36)
=1
N/bracketleftbigg(σ2
c+N1γ2
1)(σ2
c+N2γ2
2)
σ2c+ (1−ρ1)N1γ2
1+ρ1N2γ2
2/bracketrightbigg
Id. (37)
InFedHDP with only two subsets of clients, we only have a single hyperparameter to mani pulate server-side,
which is the ratio rthat is the ratio of the weight dedicated for clients with higher privacy level to t he one
for clients with the lower privacy level. To achieve the same noise variance a s in (37) we need to choose
the ratiorcarefully. To this end, setting r=σ2
c+N1γ2
1
σ2
c+N2γ2
2inFedHDP results in additive noise variance in the
estimate with zero mean and covariance matrix as follows
Σs,opt=1
N/bracketleftbigg(σ2
c+N1γ2
1)(σ2
c+N2γ2
2)
σ2c+ (1−ρ1)N1γ2
1+ρ1N2γ2
2/bracketrightbigg
Id. (38)
Therefore, the weighted average of the updates using above weights, results in t he solution being Bayes
optimal, i.e., produces θ∗.
A.3 Personalized Local Estimates on Clients
As mentioned in Section 3, FedHDP diﬀers from Ditto in many ways. First, the global model aggregation
is diﬀerent, i.e., FedAvg was employed in Ditto compared to the 2-step aggregator in FedHDP . Second,
inDitto measuring the performance only considers benign clients, while in FedHDP it is important to
measure the performance of all subsets of clients, and enhancing it across all client s is desired. In this
part, we focus on the personalization part for both sets of clients. The goa l at clients is to ﬁnd the Bayes
optimal solution to the (Local Bayes objective). However, in the considered f ederated setup, clients don’t
have access to individual updates from other clients, but rather have the global estima te/hatwideθ∗. So, we have
the local FedHDP objective as
/hatwideθ∗
j:= arg min
/hatwideθ/braceleftbigg1
2/bardbl/hatwideθ−/hatwideφj/bardbl2
2+λ
2/bardbl/hatwideθ−/hatwideθ∗/bardbl2
2/bracerightbigg
. (Local FedHDP objective)
First, we compute the Bayes optimal local estimate θ∗
jofφjfor the local objective at client cj. We consider
clientcj, which can be either in C1orC2, and compute their minimizer of (Local Bayes objective). In this
case, the client is given all other clients’ estimates {ψi:i∈[N]\j}and has their own local estimate ˆφj.
To this end, we utilize Lemma 4 to ﬁnd the optimal estimate θ∗
j. Given the updates by all other clients
{ψi:i∈[N]\j}, the client can compute the estimate φ\jof the value of φas
φ\j= Σφ\j/parenleftBig/summationdisplay
i=[N]\jΣ−1
iψi/parenrightBig
+pφ\j, (39)
22Under review as submission to TMLR
where pφ\j∼N(0,Σφ\j) and
Σφ\j=/parenleftBig/summationdisplay
i=[N]\jΣ−1
i/parenrightBig−1
, (40)
=/parenleftBig
m1
σ2p1Id+n1
σ2p2Id/parenrightBig−1
, (41)
=σ2
p1σ2
p2
nσ2p1+mσ2p2Id, (42)
wheren=N2−1,m=N1ifcj∈C2, orn=N2,m=N1−1 ifcj∈C1. Then, the client uses Σφ\jand ˆφj
to estimateθ∗
jas
θ∗
j= Σ θ∗
j/parenleftBig
(Σφ\j+τ2Id)−1φ\j+ (σ2
c−τ2)−1ˆφj/parenrightBig
+pθ∗
j, (43)
= Σ θ∗
j/parenleftbigg/parenleftBignσ2
p1+mσ2
p2
σ2p1σ2p2+τ2(nσ2p1+mσ2p2)/parenrightBig
φ\j+1
σ2c−τ2ˆφ∗
j/parenrightbigg
+pθj, (44)
where pθ∗
j∼N(0,Σθ∗
j) and
Σθ∗
j=/parenleftbigg/parenleftBigσ2
p1σ2
p2+τ2(nσ2
p1+mσ2
p2)
nσ2p1+mσ2p2Id/parenrightBig−1
+ ((σ2
c−τ2)Id)−1/parenrightbigg−1
, (45)
=(σ2
c−τ2)/parenleftbig
σ2
p1σ2
p2+τ2(nσ2
p1+mσ2
p2)/parenrightbig
σ2c/parenleftbig
nσ2p1+mσ2p2/parenrightbig
+σ2p1σ2p2Id. (46)
We expand (44) as
θ∗
j=σ2
p1σ2
p2+τ2(nσ2
p1+mσ2
p2)
σ2c(nσ2p1+mσ2p2) +σ2p1σ2p2ˆφj+σ2
p2(σ2
c−τ2)
σ2c(nσ2p1+mσ2p2) +σ2p1σ2p2/summationdisplay
ci∈C1
i/\egatio\slash=jψi
+σ2
p1(σ2
c−τ2)
σ2c(nσ2p1+mσ2p2) +σ2p1σ2p2/summationdisplay
ci∈C2
i/\egatio\slash=jψi+pθ∗
j. (47)
This is the Bayes optimal solution to the local Bayes objective optimizati on problem for client cjin
(Local Bayes objective). Now, recall that in FedHDP , the clients do not have access to individual
client updates, but rather the global model. Therefore, the clients solve the FedHDP local objective
in (Local FedHDP objective). Given a value of λjand the global estimate ˆθ∗, the minimizer ˆθj(λj) of
(Local FedHDP objective) is
ˆθj(λj) =1
1 +λj/parenleftBig
ˆφj+λjˆθ∗/parenrightBig
(48)
=1
1 +λj/parenleftbigg(N1+N2r) +λjij
(N1+N2r)ˆφj+λj
(N1+N2r)/summationdisplay
ci∈C1
i/\egatio\slash=jψi+λjr
(N1+N2r)/summationdisplay
ci∈C2
i/\egatio\slash=jψi/parenrightbigg
, (49)
whereij= 1 ifcj∈C1orij=rifcj∈C2. Now, we are ready to state the Bayes optimality of the local
FedHDP objective for optimal values λ∗
jfor all clients.
Lemma 6 (Local estimates optimality) .The solution to the local FedHDP objective from the clients’ point
of view using λ∗
jchosen below, under the assumption of global estimate optim ality stated in Lemma 5, is
Bayes optimal in the considered federated linear regressio n problem.
λ∗
j=

N(1+Υ2)+N1Γ2
2+N2Γ2
1
NΥ2(1+Υ2)+Υ2((N2+1)Γ2
1+N1Γ2
2)+Γ2
1(1+Γ2
2),ifcj∈C1
N(1+Υ2)+N1Γ2
2+N2Γ2
1
NΥ2(1+Υ2)+Υ2(N2Γ2
1+(N1+1)Γ2
2)+Γ2
2(1+Γ2
1),ifcj∈C2(50)
where Υ2=τ2
α2,Γ2
1=N1γ2
1
α2, and Γ2
2=N2γ2
2
α2.
23Under review as submission to TMLR
Proof. To prove this lemma, as shown in (Li et al., 2021), we only need to ﬁnd the optim al values of λ∗
jthat
minimize the following
λ∗
j= arg min
λE/parenleftbig
/bardblθ∗
j−ˆθj(λ)/bardbl2
2/vextendsingle/vextendsingleφ\j,ˆφj/parenrightbig
(51)
for private and non-private clients. To compute the values of λ∗
j, we plug in the values of θ∗
jfrom (47) and
θj(λ)in (49), which gives us the following
λ1=(N1+N2r)/parenleftbig
σ2
c(nσ2
p1+mσ2
p2)−τ2(nσ2
p1+mσ2
p2)/parenrightbig
(N1+N2r)/parenleftbig
τ2(nσ2p1+mσ2p2) +σ2p1σ2p2/parenrightbig
−ij/parenleftbig
σ2c(nσ2c+mσ2p) +σ2p1σ2p2/parenrightbig, (52)
λ2=(N1+N2r)(σ2
c−τ2)σ2
p2
σ2c(nσ2p1+mσ2p2) +σ2p1σ2p2−(N1+N2r)(σ2c−τ2)σ2p2, (53)
λ3=(N1+N2r)(σ2
c−τ2)σ2
p2
σ2c(nσ2p1+mσ2p2) +σ2p1σ2p2−(N1+N2r)(σ2c−τ2)σ2p2, (54)
andλ∗
j=1
3(λ1+λ2+λ3) (55)
wherer=σ2
p1
σ2
p2. For client cj∈C1, we haveij= 1,n=N2andm=N1−1. Setting Υ2=τ2
α2,Γ2
1=N1γ2
1
α2,
andΓ2
2=N2γ2
2
α2and substituting in (55) gives the desired result in (50). For client cj∈C2, we have
ij=r,n=N2−1andm=N1. Setting Υ2=τ2
α2,Γ2
1=N1γ2
1
α2, and Γ2
2=N2γ2
2
α2and substituting in (55) gives
the desired results in (50). As a result, the resulting ˆθj(λ∗
j)is Bayes optimal.
Next, we provide a few examples of corner cases for both λ∗
pandλ∗
npfor the considered linear regression
setup:
•r→1, i.e., noise added for privacy is similar for both sets of clients Γ2
1→Γ2
2,λ∗
1→
N(1+Υ2)+NΓ2
2
NΥ2(1+Υ2)+(N+1)Υ2Γ2
2+(1+Γ2
2)Γ2
2andλ∗
2→N(1+Υ2)+NΓ2
2
NΥ2(1+Υ2)+(N+1)Υ2Γ2
2+(1+Γ2
2)Γ2
2. If Γ2
1= Γ2
2= 0, then
we haveλ∗
1=λ∗
2→1
Υ2as in Ditto with FedAvg and no malicious clients.
•N2→N, i.e., all clients have the same privacy level, as in DP-FedAvg ,λ∗
2→N
Υ2N+Γ2
2.
•α2→0,λ∗
2→0andλ∗
1→0. The optimal estimator for all clients approaches the local estimator,
i.e.,ˆθj(λ∗
j)→ˆφj.
•τ2→0, i.e., all clients have IID samples, λ∗
1→N+N2Γ2
1+N1Γ2
2
Γ2
1(1+Γ2
2)andλ∗
2→N+N2Γ2
1+N1Γ2
2
Γ2
2(1+Γ2
1).
A.4 Optimality of FedHDP
Next, we show the convergence of the FedHDP algorithm to the FedHDP global and local objectives for
the linear regression problem described above as follows
Lemma 7 (FedHDP convergence) .FedHDP, with learning rate η= 1andηp=1
1+λjconverges to the global
FedHDP objective and the local FedHDP objective.
Proof. In the considered setup, we denote ˆφj=1
ns/summationtextns
i=1xj,iat clientcj. The client updates the global
estimationθby minimizing the loss function in (23). The global estimation update at the client follows
θ←θ−η(θ−ˆφj). (56)
Updating the estimation once with η= 1results in the global estimation update being ˆφj, adding the noise
results in the same ψj, and hence the global estimate in the next iteration is unchanged. As for the local
FedHDP estimation, when the client receives the global estimate θafter the ﬁrst round, the client updates
its estimateθjas
θj←θj−ηp/parenleftbig
(θj−ˆφj) +λj(θj−θ)/parenrightbig
. (57)
24Under review as submission to TMLR
Figure 3: The eﬀect of opting out on the personalized local model estimate for a li near regression problem
as a function of λwhen employing (left) HDP-FedAvg and (right) FedHDP .
Updating the estimate once with ηp=1
1+λjgivesθj=1
1+λj(ˆφj+λjθ), which is the solution to the local
FedHDP objective in (48). Hence, FedHDP converges to the global and local FedHDP ob jectives.
Next, we state the optimality theorem of FedHDP algorithm for the considered setup described above.
Theorem 8 (FedHDP optimality) .FedHDP from the server’s point of view with ratio r∗chosen below, is
Bayes optimal (i.e., θconverges toθ∗) in the considered federated linear regression problem.
r∗=σ2
c+N1γ2
1
σ2c+N2γ2
2. (58)
Furthermore, FedHDP from the clients point of view, with λ∗
jchosen below, is Bayes optimal (i.e., θjcon-
verges toθ∗
jfor each client j∈[N]) in the considered federated linear regression problem.
λ∗
j=

N(1+Υ2)+N1Γ2
2+N2Γ2
1
NΥ2(1+Υ2)+Υ2((N2+1)Γ2
1+N1Γ2
2)+Γ2
1(1+Γ2
2),ifcj∈C1
N(1+Υ2)+N1Γ2
2+N2Γ2
1
NΥ2(1+Υ2)+Υ2(N2Γ2
1+(N1+1)Γ2
2)+Γ2
2(1+Γ2
1),ifcj∈C2(59)
Proof. Follows by observing Lemma 7, which states that the algorithm converges to the global and local
FedHDP objectives, then by Lemma 5 and Lemma 6, which state that the solution t o the FedHDP objective
is the Bayes optimal solution for both global and local objectives.
A.5 Privacy-Utility Tradeoﬀ
Let us consider the special case of opt-out of privacy in this simpliﬁed linear regressi on setup, i.e., γ2
1= 0
andγ2
2=γ2. As discussed in the paper for federated point estimation, we would like to obs erve the eﬀect of
opting out of privacy on the client’s personalized local model, compared to the one w here the client remains
private. We show an experiment comparing FedHDP usingr∗against HDP-FedAvg for two scenarios.
The ﬁrst is when the client chooses to opt out of privacy, and the second is when the client chooses to remain
private. See Figure 3 for the results of such experiment. We can see that FedHDP outperforms the one
with HDP-FedAvg , and the cost of remaining private is evident in terms of higher loss at the client .
A.6 Extension Beyond Two Privacy Levels
The setup for federated learning with two privacy levels was presented to show the st eps and the explicit
expressions for the values of the ratio and the regularization hyperparameters . Next, we show brieﬂy that
25Under review as submission to TMLR
the same derivation can be extended to ﬁnd the explicit expressions for the hyperparam eters in a general
case of federated linear regression with clients choosing one of lprivacy levels. To start, assume that we have
lprivacy levels where clients can be split into lsubsets denoted by Cifori= 1,2,...,l, each hasNi>1clients,
respectively, while other notations are still the same. Notice that this setup contains the most general case
wherel=|C|and each client has their own privacy level.
Similar to the setup with two privacy levels, each client sends their update to the s erver after adding the
appropriate amount of Gaussian noise, i.e., N(0,Niγ2
iId)for clientcj∈Ci, for privacy. Let us denote the
updates sent to the server by {ψ:i∈[N]}which are estimates of φwith zero-mean Gaussian noise with
corresponding covariance matrices {Σi:i∈[N]}, where Σjfor clientcj∈Ciis expressed as
Σj= (α2+τ2+Niγ2
i)Id=σ2
jId=σ2
piId. (60)
Then, the server computes its estimate θofφas
θ= Σ θ/summationdisplay
i∈[N]Σ−1
iψi+pθ, (61)
where pθ∼N(0,Σθ)and
Σθ=/parenleftBig/summationdisplay
i∈[N]Σ−1
i/parenrightBig−1
=/parenleftBig/producttext
i∈[l]σ2
pi/summationtext
i∈[l]Ni/producttext
k∈[l]\iσ2pk/parenrightBig
Id. (62)
InFedHDP , the server applies a weighted averaging to the clients’ updates ψi’s of this form
θ=/summationdisplay
i∈[N]wiψi. (63)
To achieve the optimal covariance of the estimation at the server, the resulti ng weights used for client cjin
Ciat the server as follows
wj=ri/summationtext
k=[l]Nkrk. (64)
In this case, we have lratio hyperparameters ri’s to tune. Similar to the approach followed for the 2-level
privacy heterogeneity, we can ﬁnd the optimal values of the ratio hyperparameters t hat achieve the optimal
covariance of the estimation at the server. The optimal values of r∗
iare
r∗
i=σ2
p1
σ2pi. (65)
Next, we compute the Bayes optimal local estimate θ∗
jofφjfor the local objective at client cj. We consider
clientcj, which can be in any private set of clients Ci, and compute their minimizer of (Local Bayes objective).
In this case, the client has access to all other clients’ private estimates {ψi:i∈[N]\j}and has their own
local non-private estimate ˆφj. Similar to the approach before, we utilize Lemma 4 to ﬁnd the optimal
estimateθ∗
j. Given the updates by all other clients {ψi:i∈[N]\j}, the client can compute the estimate
φ\jof the value of φas
φ\j= Σφ\j/parenleftBig/summationdisplay
i=[N]\jΣ−1
iψi/parenrightBig
+pφ\j, (66)
where pφ\j∼N(0,Σφ\j)and
Σφ\j=/parenleftBig/summationdisplay
i=[N]\jΣ−1
i/parenrightBig−1
, (67)
=/parenleftBig
M11
σ2p1Id+M21
σ2p2Id+...+Ml1
σ2plId/parenrightBig−1
, (68)
=/producttext
i∈[l]σ2
pi/summationtext
i∈[l]Mi/producttext
k∈[l]\iσ2pkId, (69)
26Under review as submission to TMLR
where
Mi=/braceleftbiggNi ifcj/∈Ci
Ni−1,ifcj∈Ci. (70)
Therefore, we have the following
φ\j=1/summationtext
i∈[l]Mi/producttext
k∈[l]\iσ2pk/parenleftBig/summationdisplay
i=[l]/productdisplay
k1∈[l]\iσ2
pk1/summationdisplay
ck2∈Ci
k2/\egatio\slash=jψi/parenrightBig
+pφ\j. (71)
Then, the client uses Σφ\jand ˆφjto estimateθ∗
jas
θ∗
j= Σ θ∗
j/parenleftBig/parenleftbig
(/producttext
i∈[l]σ2
pi/summationtext
i∈[l]Mi/producttext
k∈[l]\iσ2pk+τ2)Id/parenrightbig−1φ\j+ (σ2
c−τ2)−1ˆφj/parenrightBig
+pθ∗
j, (72)
where pθ∗
j∼N(0,Σθ∗
j)and
Σθ∗
j=/parenleftbigg/parenleftBig/producttext
i∈[l]σ2
pi+τ2/summationtext
i∈[l]Mi/producttext
k∈[l]\iσ2
pk/summationtext
i∈[l]Mi/producttext
k∈[l]\iσ2pk/parenrightBig−1
+ (σ2
c−τ2)−1/parenrightbigg−1
Id. (73)
We expand (72) as
θ∗
j= Σ θ∗
j(σ2
c−τ2)−1ˆφj+ Σ θ∗
j/parenleftBig1/producttext
i∈[l]σ2pi+τ2/summationtext
i∈[l]Mi/producttext
k∈[l]\iσ2pk/summationdisplay
i=[l]/productdisplay
k1∈[l]\iσ2
pk1/summationdisplay
ck2∈Ci
k2/\egatio\slash=jψi/parenrightBig
+pθ∗
j.(74)
This is the Bayes optimal solution to the local Bayes objective optimizati on problem for client cjin
(Local Bayes objective). Next, we know in FedHDP the clients do not have access to individual client
updates, but rather the global model. As a result, the clients solve the FedHDP local objective in
(Local FedHDP objective). Given a value of λjand the global estimate ˆθ∗, the minimizer ˆθj(λj)of
(Local FedHDP objective) is
ˆθj(λj) =1
1 +λj/parenleftBig
ˆφj+λjˆθ∗/parenrightBig
(75)
=1
1 +λj/parenleftbigg/summationtext
i=[l]Niri+λjij/summationtext
i=[l]Niriˆφj+1/summationtext
i=[l]Niri/summationdisplay
i∈[l]λjri/summationdisplay
ck∈Ci
k/\egatio\slash=jψk/parenrightbigg
, (76)
whereij=rifor clientcj∈Ci. Note that we have l+ 1terms in both (76) and (74), which we can use to
compute the value of λ∗
jas done in the previous section, and results similar to the ones in the prior parts
of this appendix then follow from such ﬁndings. Note that computing the expressions of the optimal λ∗
jin
closed form for each one of the lsets of private clients in the considered setup is involved; hence, our brief
presentation of the sketch of the solution.
27Under review as submission to TMLR
B Federated Point Estimation
In this section, we continue the discussion started in Section 3, and make use of the results stated in Appendix
A. In the federated point estimation problem, Fj= [1,1,...,1]Tof lengthnsat clientcj. The results in the
previous section can be used for federated point estimation by using d= 1. In the remainder of this section,
we assume the opt-out of privacy scenario where clients choose to be either private or non-private in the
setup. First, we restate Lemma 1 and show its proof.
Lemma 9 (Global estimate optimality (Lemma 1 restated)) .FedHDP from the server’s point of view, with
ratior∗chosen below, is Bayes optimal (i.e., θconverges to θ∗) in the considered federated point estimation
problem given by r∗=σ2
c
σ2
c+Npγ2.Furthermore, the resulting variance is:
σ2
s,opt=1
N/bracketleftbiggσ2
c(σ2
c+Npγ2)
σ2c+ρnpNpγ2/bracketrightbigg
. (77)
Proof. Follows directly by setting d= 1,γ2
1= 0,γ2
2=γ2,N1=Nnp, andN2=Npin Theorem 8.
Next, we restate Theorem 3 and show its proof.
Theorem 10 (Local estimate optimality (Theorem 3 restated)) .Assuming using FedHDP with ratior∗in
Lemma 1, and using the values λ∗
npfor non-private clients and λ∗
pfor private clients stated below, FedHDP
is Bayes optimal (i.e., θjconverges to θ∗
jfor each client j∈[N])
λ∗
np=1
Υ2, (78)
λ∗
p=N+NΥ2+ (N−Np)Γ2
NΥ2(Υ2+ 1) + (N−Np+ 1)Υ2Γ2+ Γ2. (79)
where Υ2=τ2
α2andΓ2=Npγ2
α2.
Proof. Follows directly by setting d= 1,Γ2
1= 0,Γ2
2= Γ2,N1=Nnp, andN2=Npin Theorem 8.
Finally, we show one additional simulation result for the federated point est imation problem. The resulting
server noise σ2
sversus the fraction of non-private clients ρnpis plotted for two scenarios. The ﬁrst is the
baseline FedAvg , and the second is the optimal FedHDP . We can see in Figure 4 that FedHDP provides
better noise variance at the server compared to FedAvg , and the gain can be signiﬁcant for some values of
ρnp, even if small percentage of clients opt out.
Figure 4: Server noise variance σ2
svs non-private client fraction ρnpfor the baseline FedAvg aggregator and
optimal FedHDP aggregator.
28Under review as submission to TMLR
C Experiments: Extended Experimental Results
In this section, we provide an extended version of the results of experiments conducted o n the considered
datasets. We describe the datasets along with the associated tasks in Tables 5, the models used in Table 6,
and the hyperparameters used in Table 7.
Table 5: Experiments setup: Number of clients is N, approximate fraction of clients per round is q.
Dataset N q Task Model
non-IID MNIST 2,000 5% 10-label classiﬁcation FC NN
FMNIST 3,383 3% 10-label classiﬁcation FC NN
FEMNIST 3,400 3% 62-label classiﬁcation CNN
Table 6: Models used for experiments.
non-IID MNIST, and FMNIST Datasets
Layer Size Activation
Input image 28×28 -
Flatten 784 -
Fully connected 50 ReLU
Fully connected 10 Softmax
FEMNIST Dataset
Input image 28×28 -
Convolutional (2D) 28×28×16 ReLU
Max pooling (2D) 14×14×16 -
Convolutional (2D) 14×14×32 ReLU
Max pooling (2D) 7×7×32 -
Dropout (25%) - -
Flatten 1568 -
Fully connected 128 ReLU
Dropout (50%) - -
Fully connected 62 Softmax
Table 7: Hyperparameters used for each experiment.
Hyperparameter non-IID MNIST FMNIST FEMNIST
Batch size 20
Epochs 25 50 25
η, ηp 0.5 0.01 0.02
η, ηpdecaying factor 0.9 every 50 rounds N/A
S00.5 0.5 2.0
ηb 0.2
κ 0.5
Eﬀective noise multiplier 1.5 4.0 1.0
For each experiment, we presented the results of each dataset for the two baselines , i.e., Non-Private ,DP-
FedAvg , and HDP-FedAvg , as well as the proposed FedHDP algorithm along with the best parameters
that produce the best results in the main body of the paper. In this appendix, we show t he extended
version of the experiments. For all experiments, training is stopped after 500communication rounds for
each experiment. The server’s test dataset is the test MNIST dataset in the non-IID MNIST experiments,
or the collection of the test datasets of all clients in the FMNIST and FEMNIST datasets. Note that
the experiment of FedHDP withr= 0 denotes the case where the server only communicates with non-
private clients during training and ignores all private clients. For the baseline algorithms, we note that the
personalization scheme that is used on clients is Ditto .We vary the ratio hyperparameter ras well as the
regularization hyperparameters λpandλnpat the clients and observe the results. In the following tables,
we list the entirety of the results of all experiments conducted on each dataset fo r various values of the
29Under review as submission to TMLR
hyperparameters. For readability, we highlight the rows that contain the b est values of performance metrics
in the proposed algorithm FedHDP .
Table 8: Experiment results on non-IID MNIST ,(ǫ,δ) = (3.6,10−4). The variance of the performance metric
across clients is between parenthesis.
λp=λnp= 0.005
Setup Global model Personalized local models
Algorithm hyperparam. Acc g%Acc g,p%Acc g,np%△g%Acc l,p%Acc l,np%△l%
Non-Private+Ditto - 93.8 - 93.75(0.13) - - 99.98(0.001) -
DP-FedAvg+Ditto - 88.75 88.64(0.39) - - 99.97(0.002) - -
HDP-FedAvg+Ditto - 87.71 87.55(0.42) 88.35(0.34) 0.8 99.97(0.001) 99.93(0.001)−0.04
FedHDP r=0 90.7 90.64(0.68) 91.72(0.5) 1.08 90.64(0.68) 99.94(0.001) 9.2964
FedHDP r=0.001 91.74 91.65(0.39) 92.61(0.27) 0.94 99.94(0.001) 99.95(0.001) 0.01
FedHDP r=0.01 92.48 92.43(0.30) 93.30(0.21) 0.88 99.94(0.001) 99.94(0.001) 0
FedHDP r=0.025 92.36 92.28(0.27) 92.96(0.19) 0.68 99.95(0.001) 99.91(0.001)−0.04
FedHDP r=0.1 90.7 90.59(0.34) 91.31(0.26) 0.73 99.97(0.001) 99.95(0.001)−0.02
λp=λnp= 0.05
Non-Private+Ditto - 93.81 - 93.76(0.13) - - 99.93(0.001) -
DP-FedAvg+Ditto - 87.98 87.97(0.39) - - 99.84(0.002) - -
HDP-FedAvg+Ditto - 89.64 89.50(0.32) 90.55(0.24) 1.05 99.83(0.002) 99.84(0.002) 0.01
FedHDP r=0 91 91.12(0.48) 92.08(0.41) 0.96 91.12(0.48) 99.76(0.002) 8.65
FedHDP r=0.001 92.15 92.10(0.33) 92.88(0.25) 0.78 99.81(0.002) 99.78(0.002)−0.03
FedHDP r=0.01 92.45 92.39(0.33) 93.26(0.25) 0.87 99.81(0.002) 99.78(0.003)−0.03
FedHDP r=0.025 92.14 92.09(0.35) 93.01(0.26) 0.92 99.85(0.002) 99.8(0.002)−0.05
FedHDP r=0.1 90.7 90.82(0.29) 91.55(0.21) 0.73 99.87(0.002) 99.80(0.003)−0.06
λp=λnp= 0.25
Non-Private+Ditto - 93.79 - 93.75(0.13) - - 99.10(0.007) -
DP-FedAvg+Ditto - 88.26 88.23(0.41) - - 98.23(0.017) - -
HDP-FedAvg+Ditto - 88.27 88.09(0.49) 89.08(0.4) 0.99 98.14(0.017) 98.13(0.017)−0.01
FedHDP r=0 90.42 90.41(0.69) 91.41(0.58) 1.0 90.41(0.69) 98.06(0.023) 7.65
FedHDP r=0.001 92.18 92.12(0.34) 92.85(0.26) 0.73 98.47(0.015) 98.08(0.024)−0.39
FedHDP r=0.01 92.41 92.35(0.29) 93.19(0.21) 0.83 98.62(0.015) 98.33(0.019)−0.28
FedHDP r=0.025 92.5 92.42(0.28) 93.19(0.19) 0.77 98.71(0.011) 98.41(0.017)−0.3
FedHDP r=0.1 91.17 91.10(0.32) 91.94(0.24) 0.84 98.71(0.012) 98.60(0.013)−0.11
30Under review as submission to TMLR
Table 9: Experiment results on Skewed non-IID MNIST ,(ǫ,δ) = (3.6,10−4). The variance of the performance
metric across clients is between parenthesis.
λp=λnp= 0.005
Setup Global model Personalized local models
Algorithm hyperparam. Acc g%Acc g,p%Acc g,np%△g%Acc l,p%Acc l,np%△l%
Non-Private+Ditto - 93.67 - 93.62(0.15) - - 99.98(0.001) -
DP-FedAvg+Ditto - 88.93 88.87(0.35) - - 99.98(0.001) - -
HDP-FedAvg+Ditto - 88.25 88.05(0.39) 89.98(0.05) 1.93 99.97(0.001) 99.85(0.001)−0.11
FedHDP r=0 10.27 7.1(6.5) 100(0) 92.9 7.1(6.5) 100(0) 92.9
FedHDP r=0.025 87.11 86.61(1.10) 98.16(0.01) 11.55 99.99(0.001) 99.91(0.001)−0.08
FedHDP r=0.1 90.36 89.96(0.37) 97.45(0.01) 7.49 99.97(0.001) 99.76(0.003)−0.21
FedHDP r=0.5 88.44 88.14(0.36) 93.36(0.03) 5.2 99.98(0.001) 99.93(0.001)−0.05
FedHDP r=0.75 89.14 88.92(0.37) 92.43(0.06) 3.5 99.97(0.001) 99.93(0.001)−0.04
FedHDP r=0.9 87.96 87.69(0.56) 92.97(0.04) 5.28 99.98(0.001) 99.96(0.001)−0.02
λp=λnp= 0.05
Non-Private+Ditto - 93.67 - 93.62(0.15) - - 99.93(0.001) -
DP-FedAvg+Ditto - 88.78 88.70(0.53) - - 99.83(0.002) - -
HDP-FedAvg+Ditto - 88.33 88.11(0.46) 91.67(0.04) 3.56 99.87(0.001) 99.61(0.001)−0.26
FedHDP r=0 10.28 7.1(6.5) 100(0) 92.9 7.1(6.5) 100(0) 92.9
FedHDP r=0.025 87.92 87.45(0.99) 98.1(0.01) 10.65 99.95(0.001) 99.75(0.003)−0.2
FedHDP r=0.1 88.98 88.64(0.52) 96.18(0.02) 7.54 99.9(0.001) 99.47(0.005)−0.43
FedHDP r=0.5 88.22 87.9(0.38) 93.43(0.03) 5.33 99.85(0.002) 99.42(0.008)−0.42
FedHDP r=0.75 88.56 88.37(0.35) 91.33(0.04) 2.94 99.84(0.002) 99.52(0.004)−0.33
FedHDP r=0.9 89.19 88.97(0.4) 92.24(0.03) 3.27 99.88(0.001) 99.58(0.005)−0.3
λp=λnp= 0.25
Non-Private+Ditto - 93.67 - 93.62(0.15) - - 99.09(0.007) -
DP-FedAvg+Ditto - 87.78 87.71(0.53) - - 98.15(0.02) - -
HDP-FedAvg+Ditto - 89.4 89.22(0.26) 92.01(0.03) 2.79 98.27(0.02) 97.62(0.03)−0.64
FedHDP r=0 10.27 7.1(6.5) 100(0) 92.9 7.1(6.5) 100(0) 92.9
FedHDP r=0.025 87.51 87.01(0.9) 98.49(0.01) 11.48 98.69(0.01) 99.09(0.006)−0.4
FedHDP r=0.1 89.05 88.66(0.54) 96.8(0.02) 8.14 98.69(0.012) 98.55(0.008)−0.13
FedHDP r=0.5 88.18 88.11(0.55) 93.43(0.03) 5.32 98.32(0.014) 97.80(0.01)−0.52
FedHDP r=0.75 87.96 87.8(0.33) 92.58(0.03) 4.78 98.25(0.017) 97.5(0.02)−0.75
FedHDP r=0.9 88.26 87.93(0.41) 91.67(0.03) 3.74 98.25(0.02) 97.68(0.02)−0.57
31Under review as submission to TMLR
Table 10: Experiment results on FMNIST ,(ǫ,δ) = (0.6,10−4). The variance of the performance metric
across clients is between parenthesis.
λp=λnp= 0.005
Setup Global model Personalized local models
Algorithm hyperparam. Acc g%Acc g,p%Acc g,np%△g%Acc l,p%Acc l,np%△l%
Non-Private+Ditto - 89.65 - 89.35(1.68) - - 93.95(0.67) -
DP-FedAvg+Ditto - 71.76 71.42(2.79) - - 91.01(0.94) - -
HDP-FedAvg+Ditto - 75.87 75.77(2.84) 74.41(2.8)−1.36 90.45(1.02) 92.32(0.8) 1.87
FedHDP r=0 81.78 80.73(2.45) 89.35(1.5) 8.62 80.73(2.4) 95.80(0.39) 15.06
FedHDP r=0.01 85.38 84.61(2.05) 89.3(1.26) 4.69 93.26(0.74) 95.94(0.41) 2.67
FedHDP r=0.025 85.7 84.93(1.97) 89.58(1.29) 4.65 93.04(0.76) 95.22(0.54) 2.18
FedHDP r=0.05 85.21 84.68(1.99) 86.22(1.76) 1.54 92.87(0.74) 95.40(0.51) 2.53
FedHDP r=0.1 81.76 81.45(2.45) 81.96(1.84) 0.51 92.47(0.78) 94.83(0.52) 2.36
FedHDP r=0.5 78.19 78.02(2.59) 76.48(3.02)−1.53 91.08(0.94) 92.59(0.83) 1.51
λp=λnp= 0.05
Non-Private+Ditto - 89.65 - 89.35(1.68) - - 94.53(0.59) -
DP-FedAvg+Ditto - 77.61 77.62(2.55) - - 90.04(1.04) - -
HDP-FedAvg+Ditto - 72.42 77.14(2.72) 76.28(2.76)−0.86 89.12(1.15) 90.92(0.91) 1.8
FedHDP r=0 82.61 80.72(2.45) 89.45(1.51) 8.73 80.72(2.45) 95.57(0.38) 14.84
FedHDP r=0.01 86.88 85.36(1.89) 90.02(1.28) 4.66 93.76(0.68) 95.78(0.36) 2.02
FedHDP r=0.025 86.03 84.22(1.98) 88.40(1.68) 4.18 93.53(0.68) 95.11(0.54) 0.52
FedHDP r=0.05 84.65 82.68(2.16) 86.68(1.67) 4.00 92.92(0.76) 95.02(0.55) 2.1
FedHDP r=0.1 82.89 81.72(2.28) 83.68(2.18) 1.96 92.38(0.83) 94.25(0.61) 1.87
FedHDP r=0.5 76.59 78.05(2.60) 78.04(2.66)−0.0041 89.63(1.10) 91.67(0.84) 2.04
λp=λnp= 0.25
Non-Private+Ditto - 89.66 - 89.36(1.69) - - 94.32(0.64) -
DP-FedAvg+Ditto - 70.1 70.40(2.91) - - 88.38(1.25) - -
HDP-FedAvg+Ditto - 72.67 72.05(2.83) 74.31(2.42) 2.26 87.54(1.34) 87.39(1.23)−0.15
FedHDP r=0 81.93 80.85(2.39) 89.71(1.39) 8.86 80.85(2.39) 94.56(0.50) 13.71
FedHDP r=0.01 85.31 84.55(1.98) 89.27(1.54) 4.72 92.76(0.78) 94.77(0.5) 2.01
FedHDP r=0.025 86.17 85.52(1.92) 89.25(1.31) 3.73 92.46(0.85) 94.35(0.57) 1.89
FedHDP r=0.05 83.97 83.5(2.19) 85.4(1.88) 1.9 91.69(0.91) 93.9(0.53) 2.21
FedHDP r=0.1 83.78 83.22(2.11) 84.94(2.12) 1.72 90.9(1.02) 92.62(0.73) 1.72
FedHDP r=0.5 74.64 74.63(3.23) 72.54(2.93)−2.09 88.12(1.34) 88.69(1.28) 0.57
32Under review as submission to TMLR
Table 11: Experiment results on FEMNIST ,(ǫ,δ) = (4.1,10−4). The variance of the performance metric
across clients is between parenthesis.
λp=λnp= 0.005
Setup Global model Personalized local models
Algorithm hyperparam. Acc g%Acc g,p%Acc g,np%△g%Acc l,p%Acc l,np%△l%
Non-Private+Ditto - 81.56 - 81.72(1.37) - - 73.86(1.5) -
DP-FedAvg+Ditto - 75.39 76.1(1.73) - - 71.3(1.47) - -
HDP-FedAvg+Ditto - 74.96 75.6(1.69) 77.84(1.47) 2.24 71.44(1.5) 70.03(1.18)−1.4
FedHDP r=0 72.77 75.34(2.6) 85.7(1.14) 10.36 75.34(2.6) 72.2(1.22)−3.14
FedHDP r=0.001 73.66 76.22(2.44) 86.04(1.2) 9.82 72.78(1.51) 71.74(1.34)−1.04
FedHDP r=0.01 74.75 77.16(2.26) 86.4(1.07) 9.24 73.24(1.52) 71.49(1.29)−1.76
FedHDP r=0.025 75.37 77.66(2.06) 86.56(1) 8.9 73.11(1.55) 71.62(1.18)−1.49
FedHDP r=0.1 76.47 77.99(1.68) 84.36(1.31) 6.37 72.3(1.5) 69.93(1.15)−2.37
FedHDP r=0.5 76.11 76.69(1.62) 80.82(1.3) 4.13 71.32(1.56) 70.11(1.26)−1.2
λp=λnp= 0.05
Non-Private+Ditto - 81.95 - 82.09(1.38) - - 82.89(1.13) -
DP-FedAvg+Ditto - 75.42 75.86(1.82) - - 74.69(1.29) - -
HDP-FedAvg+Ditto - 75.12 75.87(1.65) 78.59(1.58) 2.72 74.67(1.34) 75.95(1.12) 1.28
FedHDP r=0 72.65 75.9(2.5) 86.19(1.27) 10.29 80.59(1.13) 81.97(0.88) 1.38
FedHDP r=0.001 73.31 75.9(2.5) 86.19(1.27) 10.29 80.59(1.13) 81.97(0.88) 1.38
FedHDP r=0.01 74.68 77.16(2.27) 86.25(1.05) 9.09 80.74(1.06) 82.13(0.98) 1.38
FedHDP r=0.025 75.22 77.43(2.09) 85.95(1.12) 8.52 80(1.16) 80.99(0.92) 1.01
FedHDP r=0.1 76.52 77.91(1.67) 83.9(1.27) 5.99 77.9(1.22) 79.15(0.99) 1.25
FedHDP r=0.5 76.15 76.55(1.68) 80.04(1.62) 3.49 75.43(1.25) 77.13(1.17) 1.7
λp=λnp= 0.25
Non-Private+Ditto - 81.66 - 81.79(1.38) - - 84.46(0.89) -
DP-FedAvg+Ditto - 75.99 76.56(1.6) - - 73.06(1.46) - -
HDP-FedAvg+Ditto - 75.31 75.67(1.71) 78.88(1.59) 3.21 72.58(1.45) 74.98(1.43) 2.4
FedHDP r=0 72.89 75.5(2.56) 86.09(1.28) 10.6 75.5(2.56) 84.77(0.8) 9.28
FedHDP r=0.001 73.41 76.01(2.51) 85.99(1.13) 9.97 80.98(1.06) 84.71(0.83) 3.73
FedHDP r=0.01 74.86 77.31(2.18) 86.73(0.98) 9.42 81.19(1.02) 84.68(0.78) 3.49
FedHDP r=0.025 75.41 77.68(2.1) 86.23(1.03) 8.55 80.01(1.1) 83.2(0.8) 3.19
FedHDP r=0.1 76.62 77.82(1.68) 83.35(1.27) 5.52 76.99(1.24) 78.96(1.04) 1.97
FedHDP r=0.5 75.89 76.71(1.65) 80.01(1.4) 3.3 73.48(1.37) 75.49(1.57) 2.01
33