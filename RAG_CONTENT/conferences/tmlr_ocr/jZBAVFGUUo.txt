Under review as submission to TMLR
Towards Measuring Predictability: To which extent data-
driven approaches can extract deterministic relations from
data exemplified with time series prediction and classifica-
tion
Anonymous authors
Paper under double-blind review
Abstract
Minimizing loss functions is one important ingredient for machine learning to fit parameters
such that the machine learning models extract relations hidden in the data. The smaller the
loss function value on various splittings of a dataset, the better the machine learning model
is assumed to perform. However, datasets are usually generated by dynamics consisting of
deterministic components where relations are clearly defined and consequently learnable as
well as stochastic parts where outcomes are random and thus not predictable. Depending
on the amplitude of the deterministic and stochastic processes, the best achievable loss
functionvaluevariesandisusuallynotknowninrealdatasciencescenarios. Inthisresearch,
a statistical framework is developed that provides measures to address predictability of a
target given the available input data and, after training an machine learning model, how
much of the deterministic relations have been missed by the model. Consequently, the
presented framework allows to differentiate model errors into unpredictable parts regarding
the given input and a systematic miss of deterministic relations. The work extends the
definition of model success or failure as well as convergence of a training process. Moreover,
it is demonstrated how such measures can enrich the procedure of model training and guide
the combination of different models. The framework is showcased with time series data on
different synthetic and real world datasets. The implementation of the used models and
measures for quantifying the deterministic relations are provided via the git repository ....
(the repository will be published and the link will be provided in case of acceptance, but for
the review process it is provided as a supplementary zip-file)
1 Introduction
Data analysis and the application of the corresponding insights work if there are reliable and stable relations
between the measured quantities and their model. However, due to the fact that any measurement may
not be error free or the dynamics that determine the values of the considered quantities may be inherently
noisy to a certain extent, measurement values do not only purely reflect the relations to be investigated.
Furthermore, the input data could miss relevant information, e.g., relevant features are not provided or even
measured, to model the output data such that regarding the given input data some parts of the output are
unpredictable due to the lack of information. Usually, real world datasets are not binary in terms of being
predictable, meaning that there are some deterministic patterns plus patterns which can’t be inferred from
the provided historic data, like financial markets solely based on its history, and therefore there is no chance
for any model to predict them totally accurate. Depending on the relative magnitude of these elements, the
prediction error can vary even for a successful model. We extend the term for model success by its ability
to extract or learn, respectively, all the available deterministic relations. Consequently, we argue that the
magnitude of prediction errors alone does not unequivocally signify the model success or failure.
1Under review as submission to TMLR
One key issue before any data analysis, machine learning (ML) model training or information extraction
from a dataset is testing if there are such reliable relations between the quantities in the dataset of interest.
Such tests deliver valuable insights to evaluate efforts for further analysis, and if reasonable at all. A
second key aspect after an iteration of data analysis or information extraction, such as the training of an
ML model, is testing if there is information left to extract or all the reliable information is extracted in
terms of deterministic relations between input and output data. If all relations are extracted or learned,
respectively, the deviations between the predictions given the input data and the target (ground truth) are
supposed to be stochastically independent of the input data. Thus, given that input, additional analysis on
this input-target relation might not reveal further insights or improve accuracy in terms of extracting more
deterministic relations. Consequently, further training might not improve a model in terms of learning these
deterministic relations.
Following the outline above, in the presented work, we provide a framework to address the following, which
is illustrated in Figure 1:
•We utilize measures to evaluate the stochastic dependence and information content between random
variables modeling the data to evaluate to what extent the data is interconnected and to quantify
extractable information based on defined input and output (target) variables assembled from the
dataset.
•After fitting a model, we use these measures to estimate if there is still information left to extract.
This evaluation is done by testing the stochastic independence and information content between the
input and the deviations of the model output and the ground truth. For this purpose, we investigate
the relation of random variables that model corresponding quantities.
Investigate the dataIs the target predictable from the input?Train ML modelReﬁne data setorSTOPNoYes
Determine the deviation between model prediction and targetAre the deviations predictable from the input?Done!Model extracts all informationNoAdapt modelYes
Figure 1: Graphical abstract representing the main concept of the presented work to analyze for information
content and information extracted or learned, respectively, by a model.
These bullet points provide the foundation of the framework that we endeavor to establish for characterizing
failure cases in prediction modeling. A failure case is herein defined as a scenario in which a prediction model
fails to capture the essential, meaning deterministic, dynamics of the target variable(s), given the input
information. This definition of failure allows us to decide on whether there is potential for improvement or
the prediction model has already achieved the best possible scenario given the data where inaccuracies are
not further predictable and thus improvable. Our mathematical framework provides an additional insight
for model evaluation and extends the current performance measures of ML models considering not only
the ground truth and the model output but also the input and thus to what degree the ground truth is
2Under review as submission to TMLR
predictable given the input. This extension aligns with the perception in the area of generative models such
as GAN Yoon et al. (2019); Jeha et al. (2022) or diffusion models Kollovieh et al. (2024); Tashiro et al.
(2021); Li et al. (2022); Yuan & Qiao (2024) the discriminative score, the generative score, the Frechet
Inception Distance (FID), the Maximum Mean Discrepency (MMD), the Negative Log Likelihood (NLL) or
theContinuousRankedProbabilityScore(CRPS)isalsoreportedbesidesthestandardevaluationframework
of mean squared or absolute error (MSE/MAE) to have a more probabilistic view by taking distributions of
predictions into account. Our framework extends such metrics in a sense that we assess the model accuracy
not only based on its output and ground truth but also by taking the predictability of the deviation between
modeloutputandgroundtruthintoaccountgiventheinputandthusdetermineifthedeviationisimprovable
at all given the input data.
Furthermore, our framework can consequently provide an explanation in case there is a bad model accuracy
by analyzing the deviations if there is information left or deviations consist only of unpredictable parts from
the perspective of the input data. The ability to differentiate what data points are predictable and what are
not given the input data is not provided by accuracy measures or loss functions that only consider the model
output and ground truth, for instance mean squared or absolute errors, instead we additionally consider
the information the model deviations share with the input data. The framework is not limited to a specific
model architecture and thus is model-agnostic since we only inspect the dependence of input and the model
errors, which does not require the knowledge of the inner function of the model.
The implementation of this general framework provided with this work is the mutual information, the chi-
square test of independence and the Pearson correlation to investigate the existence of relations between
random variables. One variable could be an input feature and one variable could be an output feature
to be predicted by an ML method. In case of several input or output variables, the sum of all pairwise
considerations between input and output variables can serve as a measure for information to extract. This
approach is entirely data-driven and needs no prior knowledge about the data and its distribution. Our
framework is not limited to these tests and we provide pros and potential cons of the pairwise approach in the
DiscussionaswellasotherimplementationsofmutualinformationestimatorsthatcanbefoundintheRelated
Works section. Consequently, other methods that test for information content or stochastic dependence can
be used and easily included into our modularized git repository that is provided with this work. One of
the main intention of this work is to apply such measures to demonstrate how to evaluate potential model
success. Further, to differentiate model inaccuracies into systematic failures and unpredictable parts with
respect to the input data. The choice of the measures and their implementations themselves are not the
focus of this work.
In analogy to the idea of using information and stochastic dependence measures for feature selection, we
apply the same methods to the input and the deviations between the model prediction and the ground
truth. Our approach for measuring the predictability of output based on input variables is similar to feature
selection methods, such as the minimize redundancy maximize relevance (mRMR) method Peng et al. (2005),
which is based on mutual information. If input and these deviations take their values totally independent of
each other, it means that there is nothing left to learn for an ML method, regardless of the loss value which
might be high or low depending on the magnitude of the unpredictable component.
Evaluating the deviations for dependence on the input has several benefits for model training:
•Further convergence criterion: Apart from utilizing the loss function for convergence, we can stop
training whenever there is no information or dependence left between the input and the deviation
of a model prediction from the ground truth.
•Hyperparametertuning: Wecanstopagridsearchwheneverwehaveidentifiedahyperparameterset
with which the corresponding model has extracted all the information on the training or validation
test set.
•Distributionshiftdetection: Adatasplittingintotrainingandvalidationsetorhistoricalandpresent,
can be investigated for different stochastic properties which results in less stochastic independent
input and model deviations compared to the ones obtained on the training set as learned relations
do not hold on other data sets than the training set due to the shift.
3Under review as submission to TMLR
•Dataefficiency: Incaseofaclosedsystemwheredistributionshiftcanbeexcluded, e.g., thedynamics
are known and fixed, the total amount of training data can be used for fitting model parameters
since no data is required to be utilized as an additional set for early stopping since overfitting can
be detected directly on the training data with our framework by an independent input and model
deviation.
•Recognize best possible loss function value: We can decide if an inaccuracy measured by a loss
function value is due to unpredictable parts given the input data or reflects a systematic failure
of the model not capturing relevant information. Thus, we can decide if a loss function value is
a corresponding lower bound for the given dataset since no further deterministic relations remain
within the dataset.
•Success criterion: We provide a loss function agnostic framework to evaluate performance of ML
accuracy defined by the quantity of extracted deterministic relations, which can be used as a model
selection criterion.
Firstly, we showcase our general framework with an application to time series forecasting. The basic proce-
dure including our framework is the following. After quantifying the level of predictability by inspecting the
input and ground truth target, we can perform an exactly similar test on the input and the residuals, which
define the deviations as ground truth minus prediction, to see whether they are still predictable given the
input. We use supervised ML techniques to predict future parts of the time series. Secondly, we showcase
the application for time series classification similarly where there is nominal target data and the deviation
between ground truth and model output is defined accordingly in Section 2.3 and Section 4.4.
Among different data modalities such as text, image, and timeseries, our insight is that in timeseries data,
the existence of a clear relationship between input and output is often not directly noticeable. Therefore, in
this work, we focus specifically on timeseries analysis. For instance, in natural language processing (NLP),
we typically do not encounter a sequence of random words or tokens. Similarly, in image datasets, depending
on the task (e.g., classification, segmentation), the relationship between input and output usually exists a
priori, and one would not typically spend time proving such existence, instead would directly train a model
to solve the task at hand. However, in timeseries analysis, the underlying dynamics of a process need to be
learned from the measurements. Sometimes, the history of measurements provides little to no information
about its future, leading to future samples being mainly or at least partially independent of past samples
and therefore being unpredictable. For example, consider the prediction of stock prices using timeseries
data. Past stock prices may not always provide a clear indication of future prices due to the complexity
of market dynamics and the influence of external factors such as economic events and investor sentiment.
Therefore, accurately predicting future stock prices requires understanding and modeling the underlying
patterns and dynamics in the timeseries data, which may not be directly evident from historical observations
alone. Without having a stopping criterion for improvement of the model in such scenarios, one could spend
a huge amount of time on learning dynamics which either don’t exist (such as a pure noise) or it is impossible
to learn because the given history is sharing no or low information in that regard. Therefore, in such cases,
we should know the upper bound of the model’s performance to avoid trying to improve it while further
improvement is not possible. One example is prediction of workloads, mainly network traffic in datacenters:
“measurement studies found two key results with implications for the network design. First, the traffic
patterns inside a data center are highly divergent..., and they change rapidly and unpredictably.” Greenberg
et al. (2009). A more recent manifesto Buyya et al. (2018) re-iterated the brittleness of existing “demand
estimation and workload prediction methods” , leaving it as an open question if “Machine Learning (ML) and
Artificial Intelligence(AI) methods could fully address this shortcoming” . Our framework is intended to be
used to study if there are corresponding relations regarding the available input data and how successful a
model is in learning the input-target relation.
Therefore in this work we would like to find a quantifiable answer to this question: To what extent data-
driven approaches can extract deterministic relations from data. Our solution is simple yet intuitive and
effective. By checking the independence of model deviations from the given input, we are able to judge if
further improvement of models and results is still possible.
4Under review as submission to TMLR
Paperoutline Theworkisorganizedasfollows: Themaintheoreticalconceptsthatareusedintheproposed
framework are in detail described in Section 2. This includes a precise definition of the measure of mutual
information and the chi-square test of independence, as well as an equinumeric discretization scheme for
features with a continuous co-domain. Furthermore, a stacking architecture how models may be combined
to extract iteratively all the information is defined.
A section of related methods follows Section 2 and addresses how our work extends related works using
mutual information, ensemble learning and time series prediction.
Applications of the information extraction evaluation of a model is showcased in Section 4 with different
experiments in the area of time series prediction and classification. These experiments include a basic proof
of concept, an analysis of the influence of the loss function on the information extracting depending on the
structure of the noise, suggest additional convergence criteria based on the presented framework, stacking of
models as well as detecting distribution shifts of the data.
In the Discussion, we provide assumptions and limitations of our current approach. Furthermore, we sketch
furtherapplicationofourframeworkintheareaofunstructureddata. Moreover,efficientmodelsizereduction
is also discussed by ranking subparts of a model with stochastic measures since the presented framework is
general and can be applied to any function generating output from input data.
2 Theoretical background and Methods
In this section, we provide the necessary background and mathematically establish our framework.
2.1 Basic concept for unpredictability in a nutshell
Definition of unpredictabilty
The random variable Yis deemed unpredictable with respect to an information set given by the random
variableXif the conditional distribution P(Y=y|X=x)aligns with the unconditional distribution
P(Y=y)according to
P(Y=y|X=x) =P(Y=y) (1)
for allxandy. Specifically when Xcomprises the past realization of Y, the equation (1) suggest that having
knowledge about these past realizations does not enhance the predictive accuracy of Y. It is important to
note that this form of unpredictability in Yis an inherent attribute, unrelated to any prediction algorithm
Bezbochina et al. (2023). One famous example of unpredictable time series is white noise where samples
are identically but independently distributed (iid), where the independence of future samples from the past
samples makes it essentially unpredictable and therefore training an ML model is pointless. In this case,
the best predictor in terms of L2-loss is a mean predictor, suggesting further investing on improving the
prediction model is fruitless. Please note that while unpredictable data and noisy data are related, they are
not equivalent. Noise represents a specific subset of unpredictability.
On the other hand, if (1) doesn’t hold true, it suggests that given X, it is reasonable to train an ML model
to predictY. The more the distributions of the two sides of (1) deviate from each other, the more chance
we have to train a model with a high accuracy to predict Ybased onX. In the scope of this work, we call
Xthe context/input variable and Ythe target/output that we want to predict. In this work, we use the
terms input and context interchangeably, analogously the terms output and target. In the following part,
we explain how to measure and quantify the concept we have introduced so far.
Measuring predictability
Assuming (1) is satisfied, we can derive the joint distribution by
P(Y=y,X =x) =P(Y=y)P(X=x) (2)
for allxandyby utilizing the definition of conditional probability. However, in practical data science
scenarios (2) barely holds entirely true even in case of independence of XandYdue to noise or numerical
errors. Therefore it is crucial to quantify the degree to which the independence assumption is met and to
5Under review as submission to TMLR
introduce statistical concepts to decide based on a level of significance if the hypothesis of independence
cannot be rejected.
Ourapproachtoquantifyingtheindependenceoftheserandomvariablesisgroundedin(2),wherewemeasure
the deviation between its left and right-hand side. Although in general any measure of deviation can be
used, in this work, we mainly focus on Kullback–Leibler divergence and chi-square test of independence
as a measure of this deviation. In the former case, such deviation can be calculated based on the mutual
information formula given by
I(X;Y) =DKL(P(X,Y)∥PX⊗PY)
whereDKLis the Kullback–Leibler divergence, PX⊗PYdenotes the outer product distribution, and P(X,Y)
is the joint distribution (see Murphy (2022) Section 2.2.4 Figure 2.3). A higher value of mutual information
represents higher predictability of Ybased onXwhich aligns with the definition of mutual information,
measuring the information gained about Ythrough observation of X.
Quantifying measure of success
Wedefineasuccessfulpredictionwhenthedeviationsbetweenmodeloutputandgroundtruth, e.g., theresid-
ual defined as the ground truth minus the prediction, are stochastically independent of the context/input
information. In case of independence, the deviations contain no information shared with the context, ren-
dering them effectively unpredictable based on the the provided context information. Consequently, no
further improvements are possible, marking the prediction as successful. It is crucial to note that as long as
some mutual information remains, there is potential for enhancements, whether through selecting a different
model, loss function, or adjusting various parameters. For the sake of assessment, lower values of mutual
information suggest better prediction quality.
Weremarkthatthescopeofthisworkdoesnotincludethedevelopmentofnewmethodstocalculate,estimate
or approximate mutual information but the application of such methods to improve ML training. In the
Related Work section, we provide references to such methods. For the demonstration of the application, we
provide one implementation that worked for our experiments. However, our framework does not rely on a
specific implementation of mutual information or any other stochastic measure to quantify the stochastic
independence of variables and thus any method to calculate the corresponding measure, such as mutual
information, can be taken. Furthermore, our provided git repository is modularized, ensuring that it can
be easily extended by further functions calculating mutual information (or any other measure calculating
stochastic dependence or information content).
A rigorous mathematical formulation, including details about the provided implementation of the framework,
is given in the following.
2.2 Foundations and implementation details for the predictability framework
In this section, we explain our framework in detail.
Measures for stochastic independence and information content
We are given n∈Ninput features in the format x∈Rnandm∈Noutput features in the format y∈Rm.
Each feature is modeled as a random variable taking values upon measurement. Consequently, the set of
input random variable is given by X= (x1,...,xn),xi:R→Zxi,t∝⇕⊣√∫⊔≀→xi(t),i∈{1,...,n}wheretis a
time point of measurement and Zxi:=/braceleftbig
zk
xi/bracerightbig
k=1,...,lxi,lxi∈N, is a set of discrete events. In our case, such
an event is defined through the random variable xitaking a value at time point tbetween two predefined
boundaries (see Figure 11 and 12 in the Appendix). In this work, these boundaries are calculated by an
adaptive scheme presented in Algorithm 1.
Analogously, the set of output random variables is defined by Y={y1,...,ym},yj:R→Zyj,t∝⇕⊣√∫⊔≀→yj(t),
j∈{1,...,m}andZyj:=/braceleftig
zk
yj/bracerightig
k=1,...,lyj,lyj∈N, is a set of discrete events. Our framework not only
6Under review as submission to TMLR
holds for random variables with a discrete co-domain but also for random variables with a continuous co-
domain. In our case, we choose to discretize continuous domains and we will later explain Algorithm 1
that discretizes random variables with a continuous co-domain equinumerically. Furthermore, independent
of the topology of the co-domain, we define an information or a dependence measure by Φ :X×Y→
R,(x1,...,xn,y1,...,ym)∝⇕⊣√∫⊔≀→Φ (x1,...,xn,y1,...,ym)that describes how much information, resp., stochastic
dependence exists between the input and the output variables. An example for such a measure can be the
stochastic independence of multiple real valued random variables, see, e.g., (Gallager, 2013, 1.3.4) or mutual
information as outlined in Subsection 2.1.
In this work, we focus on a specific structure of Φ, which is a pairwise test between input and output
random variables providing corresponding information or stochastic dependence summing up each value of
the pairwise measure. The measure Φis given by
Φ (x1,...,xn,y1,...,ym):=n/summationdisplay
i=1m/summationdisplay
j=1ϕ(xi,yj)
whereϕ:X×Y→R,(xi,yj)∝⇕⊣√∫⊔≀→ϕ(xi,yj)for eachi∈{1,...,n}andj∈{1,...,m}.
We are aware that a pairwise test might be an approximation of the actual value of the measure for the
deterministic relations, e.g., as in the case of the stochastic independence of multiple real valued random
variables. However, this approximation provides the advantage of much less computational costs, in partic-
ular for large nandmas provided in the discussion section of Breitenbach et al. (2022). It is one outcome
of this work that this approximation is a useful measure to estimate the deterministic connections between
input and output as well as model deviations between predictions and ground truth, moreover to estimate
the learning success of a model which is the reduction of deterministic relations between the input dataset
and the model deviations from the ground truth. A similar consideration holds for the mutual information
where a precise calculation of the joint probability can be very costly in case of many input and output
variables and where other mutual information estimators exist as well to circumvent this issue, please see
the related work and the discussion section for references and further details about this issue.
In the present work, we focus on the mutual information and the chi-square test of independence between
two random variables as measures, which are both explained later in detail. However, the presented work
is generic and can also be executed with different measures for independence, like Pearson’s correlation
coefficient as defined in, e.g., Breitenbach et al. (2023) for random variables. We remark that in terms of
testing a hypothesis if input and model deviations are independent of each other, it is beneficial to rely
on several tests to be sure about the consistency of the results and not having a wrong decision because
requirements of a test are not fulfilled, which is often challenging to verify.
In the following part, we explain the main ingredients of the present framework to analyze for deterministic
relations. Although these concepts might be well-known, we repeat them here for the convenience of the
reader since they are central for this work and a precise definition consistent with this work facilitates its
understanding.
Mutual information
The probability P/parenleftbig
xi=zk1xi/parenrightbig
describes the likelihood that the outcome of xiequals the event zk1xifor anyi∈
{1,...,n}and anyk1∈{1,...,lxi}. Analogously for P/parenleftig
yj=zk2yj/parenrightig
for anyj∈{1,...,m}andk2∈/braceleftbig
1,...,lyj/bracerightbig
.
The probability P/parenleftig
xi=zk1xi∧yj=zk2yj/parenrightig
describes the likelihood that the outcome of xiequals the event
zk1xiand the outcome of yjequals the event zk2yjfor anyi∈{1,...,n},j∈{1,...,m},k1∈{1,...,lxi}and
k2∈/braceleftbig
1,...,lyj/bracerightbig
. Based on this definition, we can define the mutual information for a pair of random variables
xiandyjas one example for ϕas follows
I(xi,yj):=lxi/summationdisplay
k1=1lyj/summationdisplay
k2=1P/parenleftig
xi=zk1
xi∧yj=zk2
yj/parenrightig
loga
P/parenleftig
xi=zk1xi∧yj=zk2yj/parenrightig
P/parenleftig
xi=zk1xi/parenrightig
P/parenleftig
yj=zk2yj/parenrightig
 (3)
7Under review as submission to TMLR
for anyi∈{1,...,n}andj∈{1,...,m}with the basis a∈N\{1}of the logarithm. The mutual information
describes how much information we gain about the outcome of yjgiven the outcome of xi. If the outcome
ofxiis independent of yj, namely
P/parenleftbig
xi=zk1
xi/parenrightbig
=P/parenleftig
xi=zk1
xi|yj=zk2
j/parenrightig
:=P/parenleftig
xi=zk1xi∧yj=zk2yj/parenrightig
P/parenleftig
yj=zk2yj/parenrightig,
for allk1∈{1,...,lxi}andk2∈/braceleftbig
1,...,lyj/bracerightbig
, whereP/parenleftig
xi=zk1xi|yj=zk2
j/parenrightig
is the conditional probability that
xi=zk1xiunder the condition that yj=zk2
j, we expect zero mutual information since loga1 = 0.
The mutual information is bounded from below by 0. The upper bound depends on the number of events
ofyj. In order to normalize the mutual information such that it is bounded from above by 1 for any yj, we
define the corresponding log base a=lyj. We remark that in case where yjis replaced by the corresponding
model deviation, the basis is defined accordingly to the number of different events of the model deviation
from the ground truth. The normalization is in particular important to compare the information content
betweenxiandyjwith the left information content between xiand the corresponding deviation between
model output and ground truth after the training of the ML model to estimate the information extraction
of the model from the dataset.
As a next example, we introduce the chi-square test of independence of two random variables.
Chi-square test of independence
In case the chi-square test of independence is taken as the measure for stochastic independence, then we
define in this work that ϕreturns 1 if the corresponding random variables of the pair are not independent
of each other, else 0.
Let us have N∈Nmeasurements where at each measurement the values of all random variables are deter-
mined. For any fixed i∈{1,...,n}andj∈{1,...,m}, we define
P/parenleftig
xi=zk1
xi∧yj=zk2
yj/parenrightig
:=Ok1k2
N
whereOk1k2∈Nis the number of observed measurements where xi=zk1xiandyj=zk2yjfor the corresponding
k1∈{1,...,lxi}andk2∈/braceleftbig
1,...,lyj/bracerightbig
. Then, we have
P/parenleftbig
xi=zk1
xi/parenrightbig
=lyj/summationdisplay
k2=1Ok1k2
NandP/parenleftig
yj=zk2
yj/parenrightig
=lxi/summationdisplay
k1=1Ok1k2
N
withN=/summationtextlyj
k2=1/summationtextlxi
k1=1Ok1k2. Under the hypothesis that the random variables xiandyj,i∈{1,...,lxi}
andj∈/braceleftbig
1,...,lyj/bracerightbig
, are stochastically independent, the number of expected measurements Ek1k2∈Rwhere
xi=zk1xiandyj=zk2yjis given by
Ek1k2:=P/parenleftbig
xi=zk1
xi/parenrightbig
P/parenleftig
yj=zk2
yj/parenrightig
N
for the corresponding k1∈{1,...,lxi}andk2∈/braceleftbig
1,...,lyj/bracerightbig
as we can take the corresponding proportions from
Nindependent of the outcome of the other random variable. Consequently, if xiandyjare independent,
it is necessary that the observed and the expected number of measurements for all k1∈{1,...,lxi}and
k2∈/braceleftbig
1,...,lyj/bracerightbig
are each equal. The chi-square statistic given by
χ2:=lxi/summationdisplay
k1=1lyj/summationdisplay
k2=1(Ok1k2−Ek1k2)2
Ek1k1, (4)
equals zero if Ok1k2andEk1k2equal each other for all k1∈{1,...,lxi}andk2∈/braceleftbig
1,...,lyj/bracerightbig
and quantifies the
deviation from not being equal. However, due to the presence of noise, even under independence of xiandyj,
8Under review as submission to TMLR
it might hold that (Ok1k2−Ek1k2)2>0for somek1∈{1,...,lxi}andk2∈/braceleftbig
1,...,lyj/bracerightbig
. Consequently, we need
toestimatefromadistributionhowlikelytheobservedchi-squarevalueunderthehypothesisofindependence
is. If the observed value is too unlikely, we rather assume that the opposite of our hypothesis of independence
is the case, meaning the variables depend on each other and there exists a dependence between the random
variables in taking their values. It can be proven that χ2is chi-square distributed with (lxi−1)/parenleftbig
lyj−1/parenrightbig
degrees of freedom, see, e.g., (Rao, 1973, 6d.2) or (Georgii, 2015, 11.3). One important assumption is that the
termOk1k2−Ek1k2√
Ek1k1is approximately normally distributed, which is usually sufficiently the case if Ek1k2≥5
for allk1∈{1,...,lxi}andk2∈/braceleftbig
1,...,lyj/bracerightbig
, see, e.g., McHugh (2013) or (Greenwood & Nikulin, 1996, page
21). Based on the distribution, we can calculate a p-value for the observed χ2value. The p-value is the
probability to get a higher chi-square value than the observed one under the hypothesis of independence. If
the p-value is too small, e.g., for this work we use lower than the level of significance of 0.01, we reject the
hypothesis of independence and assume that the random variables take their values not independent of each
other. Our measure of dependence is the number of chi-square tests that indicate dependence of the tested
pairs for the input and output variables (xi,yj)for eachi∈{1,...,n}andj∈{1,...,m}. However, since the
number of chi-square tests is given by nm, which can scale to large numbers, we use an adapted p-value to
lower the risk of wrongly rejected hypothesis, which would result in assuming too often dependence. We use
the Bonferroni-correction dividing our level of significance 0.01by the number of chi-square tests mn.
Discretization scheme for co-domains of random variables
In the next part, we describe how to discretize real valued continuous random variables, meaning that the co-
domain is continuous. We take Algorithm 4 from Breitenbach et al. (2022). We remark that our algorithm
also works for real valued discrete random variables without any change. Consequently, no separation
between discretized and continuous random variables is necessary. The algorithm provides an adaptive
discretization scheme for each random variable, meaning that boundaries of the bins, in which the co-
domain of a random variable is divided and define the events denoted with zk1xiorzk2yj, are not set equidistant
but rather equinumeric. With equinumeric, we mean that each bin has - if possible - the same number of
data points which balances the likelihood of each event.
Algorithm 1 Discretize the co-domain of random variables
1. Setρ∈Nnumber of minimum data points per bin.
2. For any random variable v:
(a) Determine the minimum value mand the maximum value Mof all measured values of v.
(b) IfM≤m: Skipv
(c) IfM >m:
i. Sort the measured data points of vin ascending order.
ii. Go through the data points in ascending order. Determine the range of a bin such that there
are at least ρdata points within the current bin and that the value of the last data point of
the current bin is smaller than the first one of the next bin.
iii. If there are less than ρdata points left: Join these data points with the last bin that has at
leastρdata points.
iv. Output: Upper and lower bound of each bin defining the events zk
vfork∈{1,...,lv}.
Algorithm 1 works as follows. The parameter ρ∈Ndetermines the minimum number of data points
per bin in which the co-domain of a random variable, such as xioryj, is discretized. These upper and
lower bounds of each bin define the event zk
ximeaning that the random variable xitakes a value within
the corresponding kthbin. Analogously, it holds for the events zk
yjof the random variable yj. Thus,
the parameter ρinfluences the marginal probability P/parenleftbig
xi=zk1xi/parenrightbig
andP/parenleftig
yj=zk2yj/parenrightig
of the joint distribution
P/parenleftig
xi=zk1xi∧yj=zk2yj/parenrightig
and consequently the corresponding expected frequency Ek1k2as well as the number
of bins for each random variable. Increasing ρwill increase the quantity Ek1k1, which might be useful if
9Under review as submission to TMLR
Ek1k1<5for onek1∈{1,...,lxi}and onek2∈/braceleftbig
1,...,lyj/bracerightbig
. Consequently, this discretization scheme is
beneficial for the implemented chi-square test and can be used without any restriction for the calculation
of the mutual information as well. We need to keep in mind that a too big ρmight lead to a too coarse
discretization deleting information from the continuous random variable. In case of the chi-square test, one
strategy might be to start with a small ρwhereEk1k1<5for onek1∈{1,...,lxi}and onek2∈/braceleftbig
1,...,lyj/bracerightbig
and increase ρuntilEk1k1≥5for allk1∈{1,...,lxi}and allk2∈/braceleftbig
1,...,lyj/bracerightbig
. A further advantage of
that scheme is that by ensuring always a minimum number of data points in each bin of each marginal
distribution, the denominator in the mutual information and chi-square formula is never zero which could
happen with an equidistant discretization strategy.
In step 2 a), we determine the minimum and the maximum of the available data points of the corresponding
random variable vto filter out constant random variables in 2 b). Without any variation, constant random
variables do not provide any information for predicting something for what at least two different kind of
events are necessary. For non-constant random variables, we sort the data points of the random variable
in ascending order. Once this is done, we can go through the points in ascending order and determine the
boundaries of the bins such that at least ρdata points are included in a bin. If there are several data points
with equal values, we include all these points into the current bin such that the first data point in the next
bin is larger than all data points in the bin before. If the remaining data points, which have not yet been
associated to a bin, are less than ρdata points, we include them into the bin with the largest upper bound.
The binning generated by Algorithm 1 can be used for the chi-square test and the mutual information
to calculate corresponding marginal and joint probabilities as we do in our implementation provided with
this work. The marginal and joint probabilities of (3) and (4) are calculated as follows. We take the
frequency of each event zk1xi,zk2yjandzk1xi∧zk2yjand divide it by Nto obtain the corresponding probabilities
P/parenleftbig
xi=zk1xi/parenrightbig
,P/parenleftig
yj=zk2yj/parenrightig
andP/parenleftig
xi=zk1xi∧yj=zk2yj/parenrightig
forallk1∈{1,...,lxi},k2∈/braceleftbig
1,...,lyj/bracerightbig
,i∈{1,...,n}
andj∈{1,...,m}. In Appendix A, the process is illustrated with regard to our time series data.
Stochastic independence as a hypothesis test
We conclude this section with a remark about the distribution of test statistics. Even under the hypothesis
of independent data/random variables, there are some variations by coincident that lead to a distribution of
the test statistic. Consequently, we need a probability how likely it is under the assumption of independent
random variables (no deterministic relation between input and output) to get a test statistic value bigger
than the observed one, and thus exclude that the relation in the measured data is just by coincidence. Then,
we can decide if a certain observed test statistic is too unlikely under the assumption of independent random
variables and we should rather assume that the opposite is true, meaning that there are some deterministic
relations by whose effect random variables do not take their values independent of each other. Based on
such a statistical view, all models where it cannot be rejected that their deviations from the ground truth
are independent of the input are equally good in terms of extracting the deterministic relations.
The chi-square value χ2is chi-square distributed with corresponding degrees of freedom under certain as-
sumptions. Consequently, we can evaluate the likelihood for the observed chi-square value of being generated
by two independent random variables. This likelihood can be calculated for each pair of random variable
separately as in (4), which results in mndecisions. However, when considering each term of (4) as a random
variable where (lxi−1)/parenleftbig
lyj−1/parenrightbig
take there value freely for each i∈{1,...,n}andj∈{1,...,,m}, resulting
in the corresponding degree of freedom under which we evaluate the likelihood of the observed χ2, we can
add the chi-square value of all random variables together as follows
χ2:=n/summationdisplay
i=1m/summationdisplay
j=1lxi/summationdisplay
k1=1lyj/summationdisplay
k2=1(Ok1k2−Ek1k2)2
Ek1k1. (5)
The likelihood of χ2defined in (5) under the hypothesis of independent input and output variables can be
evaluated as sum of/summationtextn
i=1/summationtextm
j=1(lxi−1)/parenleftbig
lyj−1/parenrightbig
freely varying normalized random variables, defining the
degree of freedom for the corresponding chi-square distribution. The value of χ2defined in (5) can be used as
a measure for stochastic independence between input and output, as alternative to the number of stochastic
10Under review as submission to TMLR
independent input and output pairs as described in the context of (4). The difference is in defining the
functionϕ.
We are not aware of a theoretic distribution for the mutual information under the hypothesis for the mutual
informationdefinedin(3). However, togetathresholdformutualinformation, suchthatwecandecidebased
on a level of significance if an observed mutual information value is too unlikely under the assumption of
independent input and output variables, we can numerically determine a distribution of mutual information
with the following permutation procedure. The idea is to shuffle the association of value pairs between
input and output based on the available data according to (xi(t),yj(π(t)))for alli∈{1,...,n}andj∈
{1,...,,m}whereπ:T→T,t∝⇕⊣√∫⊔≀→π(t)is a bijective map, called permutation, and Tis the set of all time
points of measurements of the data points. The random association of pairs from different measurements is
assumed to provide us a distribution of mutual information when input and output variables take their values
independently to evaluate how likely the observed mutual information is assuming random input-output
associations. Even in case there is a strong deterministic relation, the shuffling is supposed to ensure that the
corresponding dependence in taking the values is randomized. If the observed or higher mutual information
values are unlikely according to the distribution of mutual information values numerically determined based
on the dataset, we should rather assume that the reason for the observed mutual information value is
the non-random (deterministic) mechanisms relating input and output values or corresponding random
variables, respectively. The argumentation holds for both model output and model deviations from the
ground truth. The observed mutual information value is determined as unlikely under the hypothesis of
independent input and output variables if less than a predefined percentage of mutual information values
(level of significance; in this work 5%) generated with the randomly shuffled data is bigger than the observed
mutual information value. The distribution is generated by calculating the mutual information value for
several random permutations as described above. In this work, we calculate the mutual information 100
times with shuffled data. The same procedure holds to calculate a distribution for the chi-square value
defined in (4) or (5) in case assumptions are violated to justify the application of the chi-square distribution
forχ2. However, we remark that the theoretically available distributions for the test statistic defined in (4)
and (5) are an advantage in terms of computation time as the above described permutation method requires
repeated computations to generate the distribution under the assumption of independent input and output
variables. Finally, with such a stochastic framework in place, we are able to make concrete decisions if further
improvement is possible given the data or if all the learnable relations are already extracted, meaning that
the left deterministic relations cause deviations that are at most in the magnitude of order that unpredictable
influences can do.
2.3 Stacking architecture
Different properties of a model may influence its capability of extracting deterministic relations. Conse-
quently, in this part, we provide an architecture to combine different models with different properties to
systematically extract deterministic relations. Roughly, models are stacked together where all models get
the same input, however, try to learn only what the models in the stack of models so far have not extracted
regarding deterministic relations.
We need to differentiate two cases. The first case is where the target is ordinal data. Here the random
variables modeling the deviations of the model output from the ground truth are defined by the difference
between the model output and the ground truth. In this case the model deviations are termed as residuals.
In case where the target is nominal data, the random variables that model the deviations of the model are
defined as follows. In case the prediction of the model is not correct, the random variable modeling the
deviation of the model from the ground truth takes the value of the class label that would have been correct.
In case the model is right, the corresponding random variable takes a value that does not represent a model
class, e.g., a negative integer.
Next, we explain the stacking procedure in detail for both cases. We are given the data {(xi,yi),i∈I}
wherexiis the vector-valued input, yithe corresponding vector-valued output and Iis a finite subset of the
natural numbers N. Withxandy, we denote the corresponding vectors of random variables that take the
corresponding values for a given i. First, we check if xandyare stochastically dependent on each other. If
11Under review as submission to TMLR
Model 1 Model 2 Model 3 
Input 
Figure 2: Stacking architecture for problems with ordinal target data.
yes, we train the first model/part of the model stack to best fit the prediction ¯ytoygivenx. With ¯y, we
denote a (vector-valued) random variable taking the values ¯yifor the corresponding i∈I.
For ordinal target data, the procedure looks as follows. If ∆y1:=y−¯yis not independent of x, there is still
some information left that can be extracted. Consequently, we fit a model that may have properties different
to the current model to learn these relations between xand the residuals ∆y1. In other words, the purpose
of the second model on top of first model is to correct the prediction of the first model. The output of the
two models is then the prediction of the first model ¯yplus the correction ∆y1. In the next iteration, we test
the residuals ∆y2:=y−¯y−∆y1for stochastic dependence on x. This procedure can be repeated until the
corresponding residuals are stochastically independent of x. We call this procedure stacking of models and
can be generalized as follows such that a new model on top of a stack learns to correct the prediction of the
previous stack. The procedure is illustrated in Figure 2.
To generalize, we define
∆yj:=y−j−1/summationdisplay
k=0∆yk
where ∆y0:= ¯yfor anyj∈N. In a purely deterministic scenario, we would extend the stacking until
∆yj= 0. In a real scenario where there are unpredictable parts in the data, our definition of no further
improvement possible is that ∆yjis stochastically independent of xbased on a statistical test or measure.
The random variable representing the output of the total stack is denoted with
˜y:=j−1/summationdisplay
k=0∆yk,
taking the corresponding values ˜yiupon the input xifori∈I, wherejis the smallest number such that
∆yjis stochastically independent of x. Consequently, the stacking stops if y−˜yis independent of x. This
definition also works for discrete ordinal data, where the differences, resp., residuals take only discrete values.
We remark that this architecture does not require more inference time since each model of the stack does
not depend on the output of other layers but all perform their inference on the same input data and thus
can be run in parallel.
For nominal target data (the difference between class labels has no meaning), the stacking architecture works
analogously except the definition of the deviation of the model from the ground truth is different, please
compare with Figure 3. The deviation of the model output from the ground truth is defined by a random
variableθj,j∈Nthat take the value of the correct class in case of a wrong prediction from the model/stack
below and a value that does not represent a discrete class of the ground truth in case the prediction of the
model/stack below is correct. If θjis independent of the input xfor onej, we can stop the stacking of more
12Under review as submission to TMLR
Model 1 Model 2 Model 3 
Input Decision 
module Decision 
module 
Figure 3: Stacking architecture for problems with nominal target data.
models. As long as θjis dependent on the input x, whereθ1is based on the predictions of the first model,
there is a deterministic relation that another model can learn to predict θj, which models a correction to the
prediction of the model/stack below. In such a case, the stack is extended by another model predicting θj.
Based on the prediction ¯yjof the model/stack below and the prediction for the corresponding θj, we can
decide during inference which prediction to take. In case of θjequaling a class label, we take the value of θj
predicted by the corresponding model subsequent upstream in the stacking architecture as the value for ¯yj+1.
Otherwise, i.e. θjequals a number not representing a class label, the value of ¯yj+1equals the one of ¯yj. The
final prediction of the stack is denoted with ¯y, which represents a the vector-valued case as well. We remark
that the co-domain of the random variable θjis not one-hot encoded but the models output ¯yjshould be
due to the nominal character. However, in terms of the random variable θ, since there is a bijection between
the co-domain of this random variable and the corresponding one-hot encoding, the information content or
statistical independence between the random variable θjwith its one-dimensional co-domain consisting of
integer numbers and the input also exists and is supposed to be equal to the one-hot encoded version of θj.
One greedy implementation of both stacking concepts above is to combine models randomly and check that
after each new model ∆yjorθjhas less information with the input than ∆yj−1orθjhas with the input
to ensure benefits of the new model on top of the stack. This is a test that the new model successfully
extracts remaining information and doesn’t do guessing rather than really filling in what is missing in terms
of deterministic relations and thus provides a well-working correction.
3 Related Work
Mutual information estimation and applications
Besides classical methods to estimate mutual information such as Darbellay & Vajda (1999); Kraskov et al.
(2004); Gretton et al. (2005); Moon et al. (1995); Kozachenko & Leonenko (1987); Gao et al. (2017), a
more recent neural network based estimation of mutual information Belghazi et al. (2018); Oord et al.
(2018); Song & Ermon (2020); Franzese et al. (2023) is proposed. Such methods provide an alternative
to Algorithm 1 for the calculation of mutual information. However, since it is the focus of this work to
use such implementations to test model convergence in terms of independent input and output, we used a
framework in which we could directly implement further stochastic measures such as the chi-square test,
not being just specific for mutual information estimation. Our work may further motivate the development
of such methods as we give another application of such measures and estimators for model evaluation.
Furthermore, in different scenarios it may be that different requirements of certain estimation methods are
more or less fulfilled, which justifies considering several stochastic measures and their implementations which
is facilitated by our modularized approach. Moreover, by using different statistical tests, we can demonstrate
how to include hypotheses testing to decide for independent input and output, like the target data, residuals
13Under review as submission to TMLR
or model deviations, which allows us to make a stochastic decision for model convergence based on the given
data. Nevertheless, in Czyż et al. (2023) several mutual information estimators are benchmarked regarding
their accuracy. This work provides evidence that in low-dimensional settings, such as the pairwise case,
histogram based methods, e.g., Algorithm 1, can provide accurate results. Under model convergence with
independent input and model deviations, it is required that the pairwise test confirms independent input
and model deviations as well, which represents a necessary condition for convergence. On the other hand,
if we have to calculate the full mutual information according to Czyż et al. (2023), neural estimators may
better handle high dimensional settings, making it suitable to compute the joint mutual information.
The work Xu et al. (2019) introduces an information-theoretic measure called Determinant-based Mutual
Information (DMI) to train deep networks that are robust to label noise. However, the key conceptual differ-
ence from our approach is that they do not account for the input in the same way we do. Specifically, once
the prediction and the ground truth are available, their method does not consider the input that generated
the prediction anymore. In contrast, our approach consistently evaluates whether a given prediction can be
improved based on the provided input, taking into account the entire triple of input, prediction, and ground
truth, whereas Xu et al. (2019) focus solely on a tuple consisting of the prediction and ground truth.
DeepInfoMax (DIM) Hjelm et al. (2019) as well as contrastive predictive coding (CPC) Oord et al. (2018)
maximizes mutual information between raw data and its compressed representation to find a better repre-
sentation of raw images. Furthermore, Chen et al. (2016) employs mutual information to find a disentangled
and interpretable representation of images. The work of Brakel & Bengio (2017) also focused on finding
a disentangled/independent representation/features of images and uses mutual information as a measure
of independence between these features and thus the degree of disentanglement. Our framework can be
directly applied to the corresponding generated representations to test if the model accuracy is only caused
by unpredictable parts like noise. For more details, please see the Discussion about the case of unstructured
input data.
Innovation method
In time series analysis and signal processing, the Innovation method Reid & Term (2001); Houts et al. (2013)
is a widely recognized metric and is often used as an indirect measure of the consistency of the prediction
model’s (typically Kalman Filter) parameters when the true (ground truth) latent states of a dynamical
system are inaccessible. It works by comparing the observed data with the model’s predictions with the goal
that the differences —known as innovations or residuals— have a zero mean and a specific covariance where
residuals from different time points are uncorrelated. For Kalman Filters, this covariance can be determined
in closed form. A range of tests Reid & Term (2001) can be conducted to ensure these criteria are met,
thereby confirming the filter is consistent and reliable. While the Innovation method uses stochastic means
to investigate properties of the residuals to evaluate the model performance, our framework additionally
includes the input data to evaluate the stochastic independence of input and residuals to evaluate the
potential of a model to be improved due to remaining deterministic relations between input and residuals.
Due to computational challenges the calculation of stochastic measures might have and thus due to the
usage of approximations, the Innovation and our presented framework can be used as necessary tests that a
successful model has to pass. Furthermore, our framework also suggests an option how to extend to nominal
ground truth data where it is not possible to define differences and thus residuals.
Ensemble learning
Our proposed stacking procedure can be considered as an extension of ensemble learning methods such as
Wortsman et al. (2022). However, our approach extends it in two key facets. Firstly, we refrain from the
indiscriminate combination of multiple models. Our framework triggers a combination only if it confirms
the presence of potential for further improvement in terms of further learnable/extractable deterministic
relations. Secondly, our approach is characterized by progressiveness: We don’t assign each model the task
of learning the ground truth but rather focus on capturing what remains unlearned by the stack of previous
models. This progressiveness not only contributes to the efficacy of our stacking strategy but also enables
each model to concentrate on specific tasks that are not covered by other models. For this purpose, we stack
models in a way that the input is given to all models in a stack, and each model attempts to correct the
errors left by the preceding models in the stack. In order to enable models to extract different information
14Under review as submission to TMLR
that the preceding models could not so far, it could be helpful that the models vary in their properties, like
the model parameters, the loss function they are trained with or the architecture itself.
Information bottleneck
Another application of our framework is to extend the information bottleneck concept Saxe et al. (2019);
Kawaguchi et al. (2023). The basic framework of the information bottleneck is to maximize the mutual
information between a data representation sought and the corresponding output data and at the same time
to minimize the mutual information between this representation and the input data. There is a parameter
to balance both contradicting requirements. With our framework, we can extend the information bottleneck
method by providing a procedure how to choose this balance parameter to find a lossless compression of
the input data. Starting with a configuration where the model extracts all the information between input
and output data, we tune the balance parameter such that the compression is weighted higher until the
model cannot extract all the information between input and output assessed by having dependent input and
residuals or model deviations. With that procedure, we find the threshold of the balance parameter for a
lossless compression.
Time series prediction
Besides the above related methods, the showcase of this work is in particular associated with time series
prediction. In the past few years many of time series prediction models have been developed to improve the
prediction performance, such as RNN, LSTM Memory (2010), GRU Cho et al. (2014), transformer and its
variants Vaswani et al. (2017); Kitaev et al. (2019); Zhou et al. (2021); Liu et al. (2022); Zhang & Yan (2022);
Wu et al. (2021); Zhang et al. (2022) and state space models such as RKN Becker et al. (2019), S4 Gu et al.
(2021), MTS3 Shaj et al. (2023) as well as simple yet effective linear models such as Zeng et al. (2023). The
improvement is measured in terms of corresponding loss function values of the best weight configuration of
a model. We would like to extend these evaluation by our framework where we introduce another quantity
that evaluates how much information is left to extract from the time series given the input length of the
historic data. Furthermore, our approach would like to establish a level before model training, that allows for
evaluation if a time series is predictable given historic data. This is in particular important for challenging
time series. Additionally, there is a discussion that a simple linear layer has a superior performance in certain
time series prediction scenarios Zeng et al. (2023), notably periodic time series Li et al. (2023). Nevertheless,
there is a question in all scenarios: How can we make sure that the current method has already achieved the
lowest possible bound of the error for each time series or can it still be improved by fitting a better model
for each case?
4 Applications|Numerical experiments
Inthis section, weshowcaseourframeworktoanalyze timeseriesfor theirpredictability, measuredependence
between input/context and output/target data. Furthermore, we demonstrate how to measure learning
successofmodelswithourframeworkandusetheseinsightstobuildmodelstackstoextractmoreinformation
from data than single models can do. Moreover, we show how we extend the performance evaluation of a
model with our framework and derive further criteria for convergence of the training of a model.
Apart from several real world datasets, we use a synthetic dataset to purely demonstrate some of the effects
from above where we can control properties of the noise, such as the ratio between information and noise,
which we do not know in a real dataset. The synthetic dataset consists of the time series that is composed
of the sinus function, sin :R→R, t∝⇕⊣√∫⊔≀→sin(t)and the random variable θ:R→R, t∝⇕⊣√∫⊔≀→θ(t), which generates
noise by random values according to y(t):= sin(t) +aθ(t)wherea>0scales the amplitude of the noise. In
order to evaluate performance in an already established metric, we use the normalized root mean squared
error (RMSE) defined by1
σ/radicalig/summationtextN
i=1(˜yi−yi)2whereN∈Nis the number of measurement points, ˜yiis the
model prediction at the discrete time point i∈N,yiis the corresponding actual output data and σis the
standard deviation/radicalig/summationtextN
i=1(¯y−yi)2calculated on the training dataset where ¯yis the mean of the values yi
of the training dataset.
The parameter ρof Algorithm 1 is set to 5%of the number of measurement points of the corresponding
dataset on which the algorithm is performed, unless otherwise stated.
15Under review as submission to TMLR
We remark that the term residuals is usually used instead of model deviations to name the difference between
model output and the ground truth in case of ordered target data. In the nominal case, we further use the
term model deviation. The model deviation in the nominal case is defined as the class that would have
been correct in case the model predicts the wrong class. If the model is correct, the model deviation equals
a number that does not represent a class, e.g., the number -1. We will show for both definitions that the
stochastic dependence and the mutual information with the input decays over training epochs on training
and validation datasets.
We provide a short overview about the intention of each subsection in this section and what it is supposed
to demonstrate:
•Subsection 4.1: The noise-independent evaluation of model performance.
•Subsection 4.2: The loss-function agnostic evaluation of model convergence.
•Subsection 4.3: The differentiation of model inaccuracies into a systematic model failure or due
unpredictability and thus show stochastic independence of input and residuals or model deviation
as a stopping criterion.
•Subsection 4.4: The application of our framework to nominal data.
•Subsection 4.5: The stacking procedure and the evidence that stochastic dependence between in-
put and residuals or model deviations can be used to correct former predictions that left these
deterministic relations over.
•Subsection 4.6: The detection of distribution shift in the sense that relations learned by a model do
not hold on a data set different from the training data set.
4.1 Splitting noise off from model inaccuracy
In practical scenarios where data is obscured by noise or cases that some components of the future samples
are not predictable based on the history, evaluating prediction models becomes challenging. Traditional
metrics such as L2-loss on validation set may not suffice due to the uncertainty surrounding the ratio of
unpredictable to predictable parts. This uncertainty complicates determining the lower bound of prediction
errorbeforehand. Therefore, solelyrelyingonlossmetricsformodelassessmentisinsufficient, asthesourceof
error could be either model inadequacy/failure or inherent data unpredictability. Therefore it is important to
be able to distinguish between these two cases, because in the former case we have the chance to improve the
prediction, however, in the latter case we cannot. For example, when the power of noise (as an unpredictable
component) equals to half of the data power, the lowest possible normalized mean squared error (MSE)
on validation is 0.5. However, by employing our framework that identifies when the model has learned the
primary data component effectively, we can stop training and attribute the remaining residual to initial
data noise, although the L2error is still high. Motivated by the this discussion, we start our experiments
with such a data where the first component is fully predictable such as the sinusoid function plus some
independent, identical distributed Gaussian noise that is completely unpredictable.
In the following, we demonstrate how our framework can be used to distinguish if the model inaccuracy
results from noise rather than a relation between input and residuals that the current model has not learned
yet. Since we need to vary the amplitude of noise compared to the deterministic relation, which is modeled
by the sinus function in this case, we choose to work on our synthetic data described above.
For the numerical implementation, we consider a window of size 50 and the first 49 samples are considered as
context/input to the model and the 50thsample as the target/output. To generate the dataset, the window
is slid over the time series that was split into training and test/validation set before the experiment according
to a ratio of 0.75/0.25.
For the experiments depicted in Table 1, the random variable θadds Gaussian noise. According to the
table, chi-square test and the mutual information (at least in some cases) indicate that the MLP model,
16Under review as submission to TMLR
Exp. Err Chi-square Analysis Mutual Information Analysis
Rel. noise std RMSE Actual Err Init. dep. var Res. dep. var Init. MI Init. Perm Res. MI Res. Perm pv
0 2.2×10−52.2×10−549 49* 27.497 0.7385±0.027227.2781 0.4039±0.2360
0.2715 0.2731 0.0616 49 0 8.3351 0.7076±0.01360.7301 0.7096±0.01140.05
0.4927 0.4914 0.1073 49 0 4.193 0.7337±0.01190.7643 0.7332±0.0108 0
0.6465 0.6568 0.1476 47 0 2.5647 0.7024±0.01040.7472 0.7049±0.0095 0
0.7482 0.7461 0.1682 38 0 1.6659 0.7325±0.00920.7503 0.7054±0.0089 0
0.8166 0.8184 0.1789 37 0 1.2591 0.7293±0.00950.7862 0.7296±0.0085 0
0.8611 0.8595 0.1831 30 0 1.053 0.711±0.0077 0.7562 0.7102±0.0069 0
0.8921 0.9068 0.1893 28 1 0.9725 0.7275±0.00860.7931 0.7278±0.0075 0
0.9148 0.9134 0.1846 19 0 0.8825 0.7109±0.00790.7605 0.7384±0.00820.01
0.9306 0.9415 0.1934 11 0 0.8751 0.7341±0.00750.7521 0.7070±0.0073 0
0.9425 0.9410 0.1952 5 0 0.8153 0.7053±0.0070.7652 0.7042±0.0085 0
Table 1: Impact of varying amplitudes of white noise on a sinusoidal signal and assessing its influence on
the performance of a simple MLP. The relative power of the noise component, which is the root of the
variance of noise divided by the variance of the total time series, is shown in the first column, which is the
theoretical lower bound of test RMSE. In the second column, the normalized RMSE on the test data is
shown. The third columns shows the L2-loss between the prediction and actual clean sinusoid. The fourth
column illustrates the dependency of the target on the history evaluated by chi-square test, which is initially
complete until almost half of the power is taken by noise and decreases to small numbers when noise becomes
the dominant (94 percent) part of the time series. The fifth column evaluates the dependency of residual
target on the corresponding context to show how successful the model is to reduce this dependencies. The
last five columnsshowthe same concept interms of mutual information. Similar to chi-square, we have initial
and residual values as well as two more columns to report their corresponding lower bound which is obtained
by random permutation tests. The last column shows the p-value of the observed mutual information under
the hypothesis that residuals are independent of the input given the dataset. Note:* Initially might seem
counter-intuitive, more plots are given in Figure 13. Due to some numerical error, some periodic patterns
(only visible when multiplies by 10000 see top left plot in Figure 13) are present in the residuals which
are correctly detected as dependency by the chi-square test. Such cases can be handled by introducing a
threshold indicating a very close fit between model output and data in some norm. An alternative could be
to impose a minimal bin width in Algorithm 1 which might impact the equinumeric property.
trained with L2-loss, has extracted the sinus function. We see that all essential information are extracted
because the chi-square test indicates that all residuals are independent of the input. In the case of mutual
information, the p-values are greater than 0.01 indicating that based on that level of significance, we cannot
reject the hypothesis that the input and the residual are independent of each other and thus the input is
unlikely to carry information about the outcome of the residual. Therefore in these cases, even a much
more sophisticated model is not able to decrease the error further and might lead to overfitting to the noise.
While the RMSE increases with the amplitude of the noise, indicating that the model performance would
become worse, our stochastic measures indicate that the model has extracted the sinus function as the main
deterministic driver of the time series. This can be seen since the L2-norm between model prediction and
the pure sinus value, shown as Actual Err in 1, is (almost) independent of the noise amplitude. Furthermore,
the fact that the normalized test RSME is always close to the relative noise standard deviation indicates
that the deviation between model and data results from the noise and not from a systematic deviation from
the sinus function. We remark that the first and third column can only be presented because we exactly
know the signal and the noise component separately. In real world data, these numbers usually cannot be
computed, however, our method can provide the valuable insight if there is some relation left to extract or
the deviation between model and data is rather due to errors coming from unpredictable relations given the
input data.
4.2 Information extraction influenced by loss function and noise properties
In this part, we show that depending on the noise properties, the loss function is an important key factor
to extract the deterministic relations from the data. For this purpose, we use our synthetic dataset where
the random variable θis defined by θ(t):=1
10θ1(t) + 10θ2(t),θ1is Gaussian distributed with mean zero and
17Under review as submission to TMLR
-# dep-test + L2 # dep-test+ L1 Initial MI Residual MI + L2 Residual MI + L1
Trial 0 38 0 13.37 1.053 0.7524
Trial 1 28 1 13.567 0.9331 0.8099
Trial 2 49 0 13.394 1.217 0.7683
Trial 3 24 1 13.436 0.8886 0.7912
Trial 4 41 0 13.494 1.067 0.7451
Table 2: The effect of the choice of the loss function in mitigating asymmetric noise effects. All values are
reported on the validation data. Initial number of dependent variables is 49 on the test set, i.e, the target
depends on all past time series steps. The first two columns (dep-test L2and dep-test L1) represent the
dependence measured by the chi-square test of independence between input and residuals on the test set of
a model trained with L1- andL2-loss function. The model trained with L1-loss could better reduce these
dependencies. The mutual information (MI) analysis confirm the chi-square results since the remaining MI
in the model trained within L1is lower. The p-values of MI are zero, however, as shown in Figure 4 further
investigation shows that the p-value rises up to 10 %for theL1model (orange curve) on validation set,
although it always remains zero for the L2model. That means that the p-value could serve as a convergence
criterion, since we cannot reject the hypothesis that the L1model with the corresponding weights doesn’t
extract all the deterministic relations.
-actual-Test-rmse-model-trained-with-L2 actual-Test-rmse-model-trained-with-L1
Trial 0 0.1114 0.04958
Trial 1 0.1221 0.04567
Trial 2 0.1154 0.04189
Trial 3 0.1039 0.0499
Trial 4 0.1117 0.04799
Table 3: Best actual RMSE for a model trained on L2- andL1-loss function. Lower bound on the error is
0 here since we compare the prediction with the pure sinus-function. It is worth nothing to remind that all
models are trained on the noisy data. The term ’actual’ refers to the fact that we report the errors here by
comparing the prediction with the actual/pure signal.
standard deviation 1 and θ2is a Poisson distributed random variable over the number of peaks (high values
of the time series) within a time interval. If at a time point tthere is such a random peak, the variable
θ2(t) = 1and0otherwise. In this numerical experiment, the rate of arrivals of a peak is1
200peaks per
sample (or expected time between two data points), meaning that we expect one peak after 200 data points
on average.
Since peaks only increase the values of the time series randomly, the mean of the noise is greater than zero,
indicating asymmetry. In this case, we see in Table 2 that the initial dependence between input and output is
totally reduced only by the MLP that is trained with the L1-loss function while it does not extract the total
deterministic relations when using an L2-loss function. In this case, by saying "we extract the deterministic
relations", we mean to learn/approximate the sinus-function with the model. This extraction has taken place
when only noise is left that is independent of the input, as shown with Table 3 where we see that in the
L2-norm the model output trained on L1-loss function is much closer to the corresponding sinus-function,
evaluated on the test set. In other words, the results of Table 3 depict that the model trained with an L2-loss
function is prone to irregular peaks. For illustration, plots of predictions and residuals for L1- andL2-loss
functions are given in Figure 14. We remark that also here the synthetic set is useful since we know the exact
functional formula that generates the data apart from noise. However, this example provides evidence that
once a stochastic measure reports independence between residuals and input that the model has extracted
the deterministic relations excluding noise from the learning.
Another conclusion that we draw from this experiment, in particular from Table 3, is that the minimization
of a loss function under the constraints from the model does not necessarily coincide with extracting the
real dynamic that underlies a dataset or extracting the most information from the dataset, respectively. For
18Under review as submission to TMLR
example, the minimum of the L2-loss function subject to the constraints of the model is more distracted
from the real dynamics (sinus-function) by the specific noise than the L1-correspondence. However, with our
framework, we provide a way to measure if there is something left to extract, e.g., since a used loss function
is not suitable for the noise of a dataset.
We conclude this section with the following remark: We see the L1-loss function is less prone to the asym-
metric noise than the L2-loss function. Since L0-loss function weights all deviations from the real data with
the same penalty, we formulate the hypothesis that L0-loss function might perform even better than L1-loss
function. However, since the L0-loss function is discontinuous and thus not differentiable at all, a lack of a
numerical efficient optimization algorithm capable to deal with the discontinuity of the loss function might
hinder its broader application. Consequently, a starting point for further research might be to analyze the
performance of loss functions with regard to information extraction that consist of parts cutting off bigger
deviations with, e.g., min(max(˜y−y,−τ),τ),τ > 0, which can be solved with semi-smooth methods, see, e.g.,
Ulbrich (2011) or as shown in Breitenbach (2022) by transforming the corresponding optimization problem
into a higher dimensional one to resolve the min- and max-function to differentiable functions. Such a loss
function, e.g., taking the absolute value or the square of the projection min(max(˜y−y,−τ),τ), could be a
tradeoff between numerical efficiency and robustness against asymmetric noise or outliers parameterized by
the parameter τ. Starting the learning with a big τand restarting the optimization with a smaller τwith the
result from the last optimization procedure or decreasing τwithin one optimization run could also accelerate
the convergence speed. This procedure could make the prediction more precise with regard to extracting the
deterministic relations assuming that bigger determinations come (mostly) from noise given the input data.
Our framework can monitor the effect of τwith regard to extracting the deterministic relations.
4.3 Stochastic measures as convergence criteria
Next, weshowhowthemutualinformationandthechi-squaretestevolveduringthetrainingaftereachepoch
todemonstrateitscapabilitytoworkasconvergencecriteria. Theprocedureisasfollows. Ifinputandoutput
are not independent of each other, training of a model is started. If after an epoch, input and residuals or
model deviations, respectively, are independent on the training or validation set, more detailed if we cannot
reject the hypothesis that input and residuals, resp., model deviations are stochastically independent, then
there is no information left to extract and we can stop the training. The value of the stochastic measure
as proposed in this work is that we can evaluate if flattening of the loss function after some epochs is due
to the training is done in terms of information extraction or if the convergence speed meanwhile has just
slowed down. In the case of slowed down convergence, it is worth further patience since it could be that (now
more slowly) further information is extracted or in later epochs the convergence speed increases again when
having found the right updates for the weights. The advantage of a stochastic measure taking the relation
between input and model deviations into account is that there is a lower bound of dependence known in
advance that is theoretically always achievable by a model, namely when all the deterministic relations are
extracted, which is by definition independent of the unpredictable parts given the input data. In contrast,
for loss functions that do not take this relation into account, there is in advance no lower bound known that
is achievable on the concrete dataset.
In this experiment, we use the data from Section 4.2 and plot relevant metrics in Figure 4. We see that when
the loss function doesn’t improve any more, the corresponding chi-square test is zero and the p-value of the
mutual information becomes non-zero in a magnitude of order such that we cannot reject the independence
of input and residuals. Although we only check pairwise, this experiment shows that our framework provides
valuable convergence criteria as a stagnating loss function also indicates that the model has extracted all
the deterministic relations between input and output. The rationale is that if input and residuals or model
deviations are independent of each other, it is necessary that also a pairwise test indicates independence.
Furthermore, the turning point when stochastic measures increase marks a condition for early stopping
without considering a validation set. The increasing stochastic measures, while the loss function further
decreases, shows that training after the turning point adapts the model weights to relations that overfit the
data defined in the sense of deterministic relations, like spurious correlations. The reason is that the loss
function minimum does not necessarily coincide with the minimum regarding the stochastic measures. The
19Under review as submission to TMLR
overfitted relations do not seem to be relevant for the validation set as here the stochastic measures stay
pretty constant after some epochs.
We provide a further example based on the dataset ETTh2 Zhou et al. (2021) with a similar result depicted
in Figure 5. We see based on the chi-square test that, after some epochs, there is already a set of weights
based on which the residuals are clearly stochastically independent of the input. Similarly, we see that
the mutual information is close to the value generated by the permutation test, supporting the chi-square
results. Furthermore, the increase of the chi-square and the mutual information on the validation set for
later epochs might indicate an overfitting since the minimum based on the L1-loss function, which further
decreases over epochs, does not necessarily coincide with the maximum of extracted deterministic relations
defined by a stochastic measure, see also Section 4.2. A reason for the difference of the loss functions in
taking optima might be that the L1-loss weights any deviation between model and ground truth equally
regardless if the corresponding data point is predictable given the input while mutual information, like any
other measure based on stochastic independence, takes only predictable data points into account. Depending
on the properties of the unpredictable data part, this difference might lead to different optima regarding the
model’s parameter values.
4.4 Time series classification
In this section, we apply our framework on time series classification (TSC) problems. We remark that
for ordered classes, we can apply the framework where the differences between the discrete output values
and the ground truth models the residuals. In order to define model deviations from the ground truth in
the nominal case, we use the definition for the nominal case as described in the Methods section 2.3. In
this case, the random variable θmodeling the deviation of the model classification from the ground truth
takes the value of the correct class in case the output of the model is not correct and -1 otherwise. We
apply our framework on a subset of the well-known UCR dataset Dau et al. (2019). More specifically, the
dataset DistalPhalanxOutlineCorrect for Figure 6 is a binary classification problem from time series data.
Furthermore, the dataset ElectricDevices for Figure 7 consists of seven classes where we relabeled the classes
always starting from 0 until all classes are labeled accordingly.
In this case, the parameter ρof Algorithm 1 is set to 10 to cope with the high imbalance of the classes
and the fact that over epochs this imbalance increases since most of the cases are classified correctly and
thus the class labeled with -1 for θincreases. Results including cross-entropy loss, accuracy and the mutual
information per epoch are shown in Figure 6 and Figure 7. In Figure 6 and Figure 7, we see that while
the accuracy is increasing, the dependence of the variable θwith the input xdecreases over epochs as it is
supposed to, since less and less cases are not predicted correctly. In other words, the random variable θtends
to a constant function where information gain is small/zero taking any other input variable into account.
The difference in both cases is the following. From the results of Figure 6, we can say that over training
epochs we approach a parameter configuration where we cannot reject the hypothesis based on a level of
significance of 1% that the input and the model deviations are independent based on our mutual information
measure. In this case, we do not expect a further improvement regarding the model performance since it
captured potentially all deterministic relations. In contrast to the experiment depicted in Figure 7, where
according to our mutual information test, we reject this hypothesis and thus there are deterministic relations
to extract which may improve the model performance.
4.5 Stacking of models systematically extracts information and improves prediction
After we have seen in the previous sections that the loss function has an influence on the information
extraction depending on the noise, see in particular Section 4.2, we further investigate in this section how
different model properties, like the architecture or hyperparameters, contribute to capturing different kind of
information and how such differences could be systematically combined to extract all available deterministic
relations in a dataset. For this purpose, we present a general architecture that is not limited to only varying
lossfunctionsandthusissupposedtocombinethecapabilitiesofdifferentmodelsasdescribedintheMethods
section 2.3. Further this section showcasing the function of the stacking architecture provides evidence that
dependent input and model deviations indeed contain information to correct the output of the former model.
20Under review as submission to TMLR
Figure 4: Curves showing values of stochastic measures of independence between input and residuals as well
as the loss function history.
21Under review as submission to TMLR
Figure 5: Curves showing values of stochastic measures of independence between input and residuals as well
as the loss function history based on the ETTh2 dataset.
22Under review as submission to TMLR
Figure 6: Results on a classification problem showcasing our framework, in particular the definition of the
model deviation for nominal target data. Numbers in the parentheses show the number of parameters of the
model in million. Although validation accuracy remains below 0.8, mutual information (MI) analysis shows
the model deviations are already independent of the input.
23Under review as submission to TMLR
Figure 7: Results on a classification problem showcasing our framework, in particular the definition of the
model deviation for nominal target data. Numbers in the parentheses shows the number of parameters of
the model in million. The p-value always remains zero in this experiment for both train and validation set
for the mutual information (MI).
24Under review as submission to TMLR
Metrics Init MI Init Perm Init diff Res MI Res Perm pvRes diff Init Chi-square Res Chi-sauare
MLP L1-0.5 23.038 4.167 18.871 5.256 4.617 00.6392 60 2
MLP L2-0.5 23.038 4.167 18.871 5.347 4.579 00.7679 60 8
stacked-0.5 23.038 4.167 18.871 4.843 4.564 0.060.2798 60 0
2nd stacked model-0.5 5.256 4.617 0.6392 4.483 4.564 0.060.2798 2 0
MLP L1 23.038 4.167 18.871 5.262 4.586 00.6758 60 4
MLP L2 23.038 4.167 18.871 5.414 4.533 00.8814 60 5
Stacked MLP 23.038 4.167 18.871 4.955 4.579 0.010.3765 60 0
2nd stacked model 5.262 4.543 0.7182 4.955 4.579 0.010.3765 4 0
NST L1 23.038 4.167 18.871 5.267 4.577 00.6901 60 1
NST L2 23.038 4.167 18.871 5.468 4.564 00.9038 60 8
Table 4: Comparison of performance metrics for various standalone and stacked models. Initial mutual
information (MI), permutation analysis values, and their differences are presented, providing insights into the
starting states. Residual metrics, including mutual information, permutation values, and the corresponding
p-values in the mutual information framework assessing the independence of input and residual output, are
also reported. Additionally, chi-square values for both initial and residual states are included indicating the
number of correlated input lags of the time series.
We showcase the efficacy of our framework with a real-world time-series datasets. The dataset is a Nasdaq
datasets taken from the UCI repository and the M4 competition dataset Makridakis et al. (2020). More
specifically, we take the variable DE1. We train models according to MLP and Nonstationary Transformer
(NSTs) Liu et al. (2022) architecture on the dataset that is split according to the ratio of 0.7/0.3 into a
training and test set. The input of the models are the past 60 time lags and the output is the next value
in the time series (singlestep prediction). To this end, an MLP model trained with L1-loss is chosen as the
first model and another MLP trained with L2-loss is chosen as a second model in the stack. The weights of
the last layer of the models in the stack, except the first model, are initially set such that the output of each
model is close the zero. The rationale is that if the prediction from the stack below is correct, only minor
corrections are necessary building on the previous predictions. Furthermore, the last layers in models are
chosen for weight rescaling since the first layers are usually intended for feature extraction. Aditionaly, the
layer norm operation (dividing by standard deviation) would cancel the scaling to small values, for details
about this part please see the Appendix, Section F.4.
As illustrated in Table 4, none of the individual models successfully render the residuals independent of the
input. Remarkably, it was only through the combination in stacked models that an increase of p-values
was observed, enhancing the overall performance. To provide a more comprehensive comparison, results
for NST are also included. We see that in this case, the MLP stack not only extracts more information
as the NST but is computationally even cheaper. In order to exclude that the effect is a result of more
free parameters, we have included MLPs with about the half of free parameters each indicated by the "0.5".
Moreover, we see that only the stacked models provide a non-zero p-value such that only in this case, we
cannot reject the hypothesis that input and residuals are independent based on a level of significance of 1%.
Beyond mutual information and chi-square test, considerations such as L2-loss and learning curves in Figure
8 further support the empirical evidence that stacking models outperforms their individual counterparts by
having a smaller L2-loss function (comparison only valid if the last layer of the stack is trained with the
same loss functions, which is in this case L2-loss function, as the corresponding single model). This evidence
showcases the capacity of multiple models to learn diverse aspects. However, we remark that a comparison
in terms of loss functions and information extraction is tricky as shown in Section 4.2.
Further examples demonstrating the stacking procedure for a 1-step ahead prediction as well as a multi-step
ahead prediction are provided in the Appendix in Section D. The results are in line with the ones reported
in this section. We remark that the multi-step ahead prediction showcases the application of our framework
for a multi-dimensional model output.
We remark that a linear combination of loss functions according to λ1∥·∥2
L2+λ2∥·∥L1with the hyperparam-
etersλ1,λ2>0could be an alternative approach to stacking in terms of loss functions. However, the success
of that formulation might depend on the right choice of the hyperparameters λ1andλ2. Our framework
25Under review as submission to TMLR
Figure 8: The L2loss comparison for stacked models and single models.
provides an option to choose the hyperparameters accordingly such that most information is extracted from
the data, e.g., the mutual information is minimized between the input and the residuals. Please note that
finding the best combination or any hyperparameter optimization is not the focus of this work. In the present
work, the focus is on showcasing our framework in terms of its potential for applications in various ML use
cases.
To conclude this section, we show that our stacking framework also works for classification problems. For
architectural details, please see the Methods section 2.3 and Section 4.4. In Table 5, we provide numbers
based on the ElectricDevices dataset. To further improve the effect of stacking, we see potential when
including a corresponding loss function into the training process for optimizing parameters such that the
corresponding ML architecture extracts most deterministic relations possible. Regarding this topic, please
see the Conclusion and Future Work section in combination with the Discussion part "Alternative of model
deviation for nominal data".
Metrics Init MI Init Perm Init diff Res MI Res Perm Res diff
SVM-rbf kernel 41.65 16.00 25.65 23.72 15.50 8.22
SVM-sigmoid kernel 41.65 16.00 25.65 34.13 16.62 17.51
SVM-sigmoid + SVM-rbf 41.65 (23.72) 16.00 (15.50) 25.65 (8.22) 23.23 14.41 7.82
Table 5: Numbers in parentheses show the starting point of the last stacked model. The abbreviation
SVM refers to the standard Python sklearn implementation of a support vector machine. The p-values
assessing the independence of the input and the model deviation from ground truth alsways remains zero in
all experiments. For a description of the meaning of the columns, please refer to Table 6.
26Under review as submission to TMLR
4.6 Detecting distribution shifts
One prevalent issue hindering the advancement of machine learning models towards higher accuracies is
distribution shift, meaning that relations that hold within the training set do not hold on the validation
set. A reason could be that the validation set contains newer data and that the underlying dynamics have
changed or change over time. Especially several existing works such as (Zeng et al., 2023, Figure 5) and Kim
et al. (2021), in particular (Kim et al., 2021, Figure 3) have confirmed this phenomenon, e.g., on ETT1 and
ETT2 data sets. This section presents a novel insight into this phenomenon, enlightening how our proposed
framework can detect and distinguish such cases from mere overfitting to noise. In a typical training scenario,
after some epochs while training loss continues to decrease, validation loss may gradually start to increase.
Without prior assurance of the absence of distribution shift, a pure loss function based approach without
including stochastic measures struggles to differentiate between overfitting to the noise in training data and
(partial) distribution shift due to different deterministic relations between the training and the validation
set, as both can lead to similar observations of an increasing loss function on the validation set.
Our framework provides a concise solution. Instead of solely monitoring the loss function, tracking mutual
information enables us to determine the types of relationships the model is learning. A decrease in mutual
informationacrossepochsindicatessuccessfulextractionofinformation, suggestingthatthemodelislearning
deterministic relationships within the training set, and not already overfitting to noise. If it does so as well
on the validation set until input and deviations between model and ground truth are independent, then we
can stop the training process since the model might have learned all deterministic relations on the training
set that hold true for the validation set, too. In that case further training might cause an overfitting to noise.
Similarly, if there is no significant reduction in mutual information despite decreasing training loss, it may
indicate overfitting to the noise in the training data, as the model is fitting to the unpredictable elements of
the ground truth which shares no mutual information with the input.
On our synthetic dataset, the deterministic relations are identical on training and test set by construction. In
Figure 4, we see for the training based on L2-loss function that the mutual information increases on training
and validation set after reaching their minimum upon a few epochs simultaneously. After that, the model
fits noise rather than the actual sinus function since the norm of the difference between model prediction
and sinus function increases simultaneously while the loss on the training set further decreases.
In case the deterministic relations in the training data may (partially) not hold true for the validation set, it
may lead to an increase in loss and potentially mutual information over epochs on the validation set, while
mutual information on the training set decreases, as we see in Figure 9. In this figure, the deterministic
relations learned on the training data do not cause a fitting output of the model on the validation set.
In contrast, please see Figure 5 where mutual information between input and residuals on training and
validation set from ETTh2 simultaneously decreases over epochs. Results in Figure 9 show the learning
curves when fitting an MLP with L1 as a loss function on the residuals of PatchTST Nie et al. (2022) with
the best setting they proposed on the ETTh1 data set where the input length is 336 lags and we predict
a target length of 96 lags. We remark that this experiment also showcases the application of our proposed
framework to multi-dimensional output.
5 Discussion
In this section, we discuss our assumptions and limitations of our implemented approach before we sketch
further potential applications of our approach.
Assumptions and Limitations: The implemented approach tests pairwise the relation between input
and output features. We are aware that there is a difference, e.g., in pairwise stochastic independence and
(mutual) stochastic independence in case of more than two random variables (Gallager, 2013, Section 1.3.4).
Thatmeansthattheremightbemoreinformationconsidering, e.g., twoinputfeaturesatonceandtestitwith
the output instead of testing for pairwise relations with one input feature and an output feature. However,
the full consideration, instead of a pairwise testing, scales exponentially in terms of the computational costs.
Consequently, we are aware that the current pairwise approach, which is computationally cheap compared
to the full approach, cannot provide in general a full statement like, there is no information left to learn,
27Under review as submission to TMLR
Figure 9: Distribution shift experiment on ETTh1 Dataset. Experiment is repeated for six different random
seeds. Shaded aread depicts the minimum and maximum over seeds and the solid line shows the average.
in case of pairwise independent input features and residuals/model deviations. In this regard, the current
approach can only be used as an additional metric to evaluate if training is done and further iterations
might not provide a further improvement. This could be the case if a low pairwise measure of the relation
between input and output coincides with a small/no loss function improvement. Pairwise test is a specific
case of a full consideration. Consequently, the opposite direction is true that a pairwise test indicating
deterministic relations between input and residuals/model deviations implies that there is information left a
model can learn. An analogous framework is using the gradient as a convergence criterion within the context
of optimization where the gradient provides only necessary conditions for convergence to a global minimum.
Only under some conditions, the gradient can be used as a sufficient condition to characterize a global
minimum. However, even in this case, using only necessary conditions, provides useful optimization results
while keeping the computational costs manageable, which might be analogous to our pairwise definition of
the used stochastic measures. In this regard, if all deterministic relations are learned, it is necessary that
the measures for independence based on a pairwise test indicate independence of the input and the residuals
or the model deviations.
It is left to investigate under which conditions a pairwise consideration is sufficient to test for a total
stochastic independence of input and output. Furthermore, we remark that our framework is not limited to
a specific choice of stochastic dependence/information measures and also our git repository is designed that
new measures can be quickly included in a modularized manner.
Due to the fact that any approximation or estimation of a measure, like mutual information, may not work
sufficiently accurate Czyż et al. (2023), it is appropriate not only to rely on one estimator for one measure
but use different ones. We do so by considering an approximation for mutual information and the chi-square
test. The generality of our framework allows us to utilize different measures for independence where we can
also consider other features like computational runtime apart from accuracy. For example, the test statistic
of the chi-square test of independence provides a theoretically known distribution which allows us a quick
hypotheses testing if based on the data corresponding variables are independent.
For time series, we would like to remark that, even under a method that considers (full) mutual independence
between the input (history of the time series) and output (prediction target), a result of total independence
of input and output does not imply that the time series is not predictable. It just says with the given input,
28Under review as submission to TMLR
the time series is not predictable autoregressively. Maybe with other features that are related to the quantity
measured as a time series, there is a deterministic relation that can be used for predicting the time series.
Alternative of model deviation for nominal data: One further option to model deviations of a model
from the ground truth in the case of nominal target data could be a multi-dimensional random variable that
models the difference between the actual probability distribution (e.g., 1 for the correct class, 0 otherwise)
and the predicted distribution from the model for the classification. If the input variables and the difference
distribution, which serves as the correction to the prediction to get the correct distribution, are determinis-
tically related, then the correction (difference distribution) could be learned by another model and added to
the distribution from the previous stage. After adding, which is all done in the decision module, see Figure
3, the new distribution can be processed with the softmax-function for normalization and the classification
may correspond to, e.g., the most likely class. In other words, the classification problem could be seen as a
multi-dimensional ordinal data scenario.
Extension to unstructured data: For models that extract information from an input like videos, images,
sound, ortext, theinputdataneedstobetransformedintoanumericalrepresentationthatsharesinformation
with the ground truth. An example are the pixels in a figure where a small object of interest moves within a
big blank picture or tokenized text, where the position of a word can vary while not changing the meaning.
We could optimize first layer(s) to have the highest mutual information with the ground truth that is to be
predicted analogously to Chen et al. (2016) or Brakel & Bengio (2017) focusing on finding (mutually, not
only pairwise) disentangled representations. This procedure could also foster the application of a pairwise
test between each node in such a representation and the output features since the disentangled representation
extracts potential mutual information considering several original input features at once such that each node
of the representation is independent of each other. In such a case, the necessary condition of a pairwise
test for model convergence might be already sufficient. It is the task of an encoder to find a numerical
representation (vector embedding) from an input signal that maximizes information content, in the form of,
e.g., mutual information or stochastic dependence, with the ground truth to be predicted. Thus, the encoder
issupposedtoextracttherelevantinformationfromthe(unstructured)inputregardingthepredictiontarget.
This extraction can be seen as a definition for "relevant information". In that sense, a training of a model
can be two-staged. First, we could train an encoder part to maximize the mutual information or stochastic
dependence between the vector embedding (output of an encoder) and the ground truth. To use a gradient
method for this purpose, differentiable estimators of mutual information, like Franzese et al. (2023), or
any other definition of stochastic independence need to be available. To consider the example above, the
encoder’s part may be to extract the moving object from the figure independent of its position. In the second
stage, we train the decoder part, which is supposed to make the prediction based on the vector embedding,
with some loss function to minimize errors between model output and ground truth. Another option is to
optimize the decoder for minimizing mutual information or the stochastic dependence between the model
deviation (decoder’s output and ground truth) and the vector embedding (encoder’s output). However, this
suggestion also requires a differentiable function defining stochastic independence or mutual information,
respectively. We remark that separating the training of the encoder from the decoder’s training might be
important in case we use a loss function based on reducing stochastic dependence between the encoder’s
output and the decoder’s deviation from the ground truth because if the encoder’s representation does not
contain much information about the ground truth, the decoder’s deviation from the ground truth is not
predictable given the encoder’s representation and would thus indicate training success. Given the fixed
dimension of the vector embedding, we can compare different encoder architectures and define the best
with, e.g., the highest (normalized) mutual information between vector embedding and prediction target.
Analogously, the best decoder can be defined as the one having the lowest (normalized) mutual information
between the encoder’s vector embedding and the model deviation of the decoder’s output and the ground
truth. We remark that the mutual information can be replaced by any measure for stochastic dependence.
The corresponding encoder-decoder architecture is illustrated in Figure 10.
A specific issue with the output of large language models, and in general for unstructured output data,
is that there is sometimes more than one correct class (e.g., tokens associated with synonyms), but only
one word is taken by a large language model. In such a case, a solution might be another large language
model to tell synonyms to evaluate if a model is right. Thus, this definition of the model correctness
29Under review as submission to TMLR
Input x (unstructured data)EncoderVector embedding zDecoderModel output yFirst training process (Encoder training):Optimize parameters of the Encoder such that given x the information content between z and G is maximized, measured in mutual information or any smooth approximation of it or any other loss function maximizing stochastic dependence.Ground truth data G for model output
Second training process (Decoder training):Optimize parameters of the Decoder such that given z the deviation between y and G is minimized.
Figure 10: Encoder-Decoder architecture for a separated training of the encoder and the decoder based on
stochastic dependence.
transforms the unstructured output to a structured one that can be investigated for dependence with other
layers/representations. One possible implementation can be like the corresponding random variable taking
the value for a correct prediction, which could be in this case several classes defined by the other model. If
the model is not correct, this variable could take a number of a correct class, where in terms of synonyms one
correctoption, accordingtotheevaluatingmodel, isenough. Alsointhisunstructureddatacase, thestacking
concept works since the random variable θjin Figure 3 is defined with the help of a second large language
model instead of a simple rule based definition from the known tabular data. Such an investigation can help
to answer the question how small a model can be and where most information is learned/extracted to make
large language or even multimodal models more efficient. For more details, see the next paragraph about
cutting down models. As distributions over classes represent the probability for corresponding outputs, like
synonyms, it might also be an option to work on distributions directly as described above under "Alternative
of model deviation for nominal data", though the dimensionality of the problem increases accordingly.
Another advantage of calculating stochastic measures between representations of a (pre-)trained model and
the ground truth belonging to a specific task, like classification, is to find out which representations of which
model have the highest dependence (information content) to the corresponding task, which could efficiently
enrich the way how (pre-)trained models are selected from a pool of available models.
Cutting down models to structures extracting most information: If we perform a training with
usual loss functions without any additional optimization for mutual information in specific layers, we could
also identify the best structures within a trained model that extract most information and which subparts
only contribute in a minor way to, e.g., an embedding. While in this work so far the idea of stacking
models has been discussed, zooming more in a model’s architecture would help us analyzing the model itself
regarding its subunits (e.g. layers, embeddings, attention mechanisms, etc.). The approach is to apply
mutual information like in the scenario of multi-dimensional input and output. The output can be filled
with the data to predict or the output of other subunits, like an embedding, upstream towards the output
of the total model. If there is no contribution or only a minor one, we could cut the corresponding subunit
out.
By ranking subunits with such measures, we have a clear procedure what subunits to exclude, instead of
randomly selecting some for cutting out before retraining the model. The training could start from the
current model parameters to just fine-tune the remaining layers. Training from the scratch is also possible
but could delete a lot of parameter values that are still valid. The procedure can be iteratively repeated
and even to that point where model size is balanced against a (small) drop of accuracy. Our framework
can in additional help to find a lossless pruning similar to the Related Work section about the information
30Under review as submission to TMLR
bottleneck by testing if the stochastic measures between input or any representation of it and the model
deviations get worse after a cutoff. Such investigations might facilitate an understanding about the problem-
specific relevant structures and keeping model sizes efficient without lowering their accuracy. As an example,
we could test how large, e.g., large language or multimodal models need to be and which structures extract
the most information, similar to Liu et al. (2024). Further, we remark, that with a measure for self-similarity,
like the Pearson correlation, we could probably identify identities, resp., structures that behave similarly,
e.g., in a sequential arrangement of layers that have the same output behavior, which should be lowly ranked
since they only direct information through. A similar work is done in Gromov et al. (2024) to identify layers
with a similar behavior that can be cut off. However, with mutual information, we can also investigate
structures that do not behave similarly, but how much single parts of a branch structure contribute to the
part where these branches come together.
If a training fails, we could also use such methods to test which structures fail. An example is a cascade
of layers with one layer where input and output do not share any information anymore. The disruption
of routing information could mean that this layer is like a constant function, which may delete important
information.
Stacking software pipeline: Apart from finding relevant properties of a model to vary, like size, deepness,
loss function etc., another aspect is that we assume the stack to be constant once trained and parameters
are kept constant while only the new model on top of the stack is trained. It is to investigate in future
research if, e.g., training all the parameters of the whole stack after training the new model on top of the
stack might benefit the accuracy before testing if another model for the top of the stack is needed. One
important application of a pipeline is to facilitate a precise time series prediction related to a concrete single
time series and provide this capabilities to a broad audience even outside the ML community that apply
the predictions of time series, like weather forecasts. Another use case is improving therapies where their
effect depends on time-varying patient-specific parameters. Thus, by taking, e.g., the daily rhythm of gene
expression of humans into account, as argued in the concept of chronotherapy Zhang et al. (2014), a precise
prediction of the expression levels may improve the effect of therapies and can be one brick for personalized
medicine.
6 Conclusion and Future Work
In this work, a framework for measuring predictability of input-output relation was developed. Furthermore,
it was shown how the information extraction of an ML model from this input-output-relation can be mea-
sured. Based on this framework, a stacking architecture was presented, which is able to extract information
systematically in case a single model fails to do so. Moreover, it was demonstrated how the corresponding
stochastic measures for predictability can be used to extend the current definition of model convergence
and training success. The total framework was showcased with time series prediction and classification on
synthetic and real world datasets.
The presented framework provides measures to evaluate the existence of deterministic relations that a model
can extract and how successful a model has been with extracting them. All these measures are supposed
to consider the triple of input, model output and ground truth to calculate if the model deviations from
the ground truth are independent of the input. Promising further research might be the development of a
differentiable loss function based on such a stochastic measure to fit the model to the deterministic relations
directly, sorting out unpredictable parts like noise. In contrast, there are loss functions that only consider
a tuple of ground truth and model output, like L1,L2, cross entropy or KL-Divergence that fit the model’s
output distribution to the data distribution without differentiating if a data point is mainly influenced by,
e.g., noise or the deterministic relations. Such a loss function might benefit the stacking procedure as each
component can be optimized in terms of extracting only deterministic relations from the data.
According to the presented framework the mutual information between input and the model deviations
might serve as such a loss function sought. However, for the implementation, there are some challenges left
that need further research to overcome them. One challenge might be that the current implementation is
not differentiable since minor changes regarding the size of a residual can cause a change in the belonging
to the corresponding bin that are generated during the calculation of the mutual information. A suitable
31Under review as submission to TMLR
smoothing might facilitate the application of a corresponding loss function within a numerically efficient
algorithm that requires a smooth loss function. These challenge of the non-smoothness is already described
in (Oord et al., 2018, Section 2.1). There are smooth approximations of mutual information, like Belghazi
et al. (2018) or Franzese et al. (2023), however, these approximations could become computationally too
costly since an ML model needs to be trained in any epoch approximating the mutual information between
input and model deviations. A further challenge could be that there might be instabilities in estimating the
mutual information, as reported in Choi & Lee (2022). Such an inaccuracy in the estimation of the mutual
information for a loss function could cause divergence of the optimization procedure and thus not improve
the model’s capability to extract more deterministic relations differentiating them from unpredictable parts
like noise given the input data. Further research for a smooth and computational cheap approximation of
mutual information is promising to focus the ML training on the deterministic relations encoded in the data
to the degree the corresponding architecture is able to extract.
Such a framework can also benefit applications outside machine learning in the field of optimization and data
driven modeling, like best parameter fit Raue et al. (2015); Crouch et al. (2024) since such a loss function
might improve the parameter finding with regard to making their value choice more robust against noise. In
this regard, the input variable is the time tin case the modeling is done with ordinary differential equations
(ODEs) or space xand optionally time if the modeling is done with partial differential equations (PDEs).
Additionally, we could have some external stimuli u, like the effect of drugs in biology or the heating of a
work piece, which are input variables. The output are the corresponding quantities ythat are to be described
by the model. Thus, we ideally have that, e.g., f(t,x,u )approximates yas well as possible where fsolves
the underlying system of differential equations. With such an approach, we can test if yis predictable given
the input data at all. After that, we can see if the underlying model (consisting of, e.g., ODEs or PDEs)
fits the data, meaning the model is able to capture all the deterministic relations within the data or if the
model should be extended to capture the information hidden in the data well since we have to reject the
hypothesis that the input variables and the residuals are independent.
References
Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton. Layer normalization. arXiv preprint
arXiv:1607.06450 , 2016.
Philipp Becker, Harit Pandya, Gregor Gebhardt, Cheng Zhao, C. James Taylor, and Gerhard Neumann.
Recurrent kalman networks: Factorized inference in high-dimensional deep feature spaces. In Kamalika
Chaudhuri and Ruslan Salakhutdinov (eds.), Proceedings of the 36th International Conference on Machine
Learning , volume 97 of Proceedings of Machine Learning Research , pp. 544–552. PMLR, 09–15 Jun 2019.
URL https://proceedings.mlr.press/v97/becker19a.html .
Mohamed Ishmael Belghazi, Aristide Baratin, Sai Rajeshwar, Sherjil Ozair, Yoshua Bengio, Aaron Courville,
and Devon Hjelm. Mutual information neural estimation. In International conference on machine learning ,
pp. 531–540. PMLR, 2018.
Alexandra Bezbochina, Elizaveta Stavinova, Anton Kovantsev, and Petr Chunaev. Enhancing predictability
assessment: Anoverviewandanalysisofpredictabilitymeasuresfortimeseriesandnetworklinks. Entropy,
25(11):1542, 2023.
Philemon Brakel and Yoshua Bengio. Learning independent features with adversarial nets for non-linear ica.
arXiv preprint arXiv:1710.05050 , 2017.
Tim Breitenbach. On the SQH method for solving optimal control problems with non-smooth state cost
functionals or constraints. Journal of Computational and Applied Mathematics , 415:114515, 2022.
Tim Breitenbach, Lauritz Rasbach, Chunguang Liang, and Patrick Jahnke. A principal feature analysis.
Journal of Computational Science , 58:101502, 2022.
Tim Breitenbach, Bartosz Wilkusz, Lauritz Rasbach, and Patrick Jahnke. On a method for detecting periods
and repeating patterns in time series data with autocorrelation and function approximation. Pattern
Recognition , 138:109355, 2023.
32Under review as submission to TMLR
Rajkumar Buyya, Satish Narayana Srirama, Giuliano Casale, Rodrigo Calheiros, Yogesh Simmhan, Blesson
Varghese, Erol Gelenbe, Bahman Javadi, Luis Miguel Vaquero, Marco A. S. Netto, Adel Nadjaran Toosi,
Maria Alejandra Rodriguez, Ignacio M. Llorente, Sabrina De Capitani Di Vimercati, Pierangela Samarati,
Dejan Milojicic, Carlos Varela, Rami Bahsoon, Marcos Dias De Assuncao, Omer Rana, Wanlei Zhou, Hai
Jin, Wolfgang Gentzsch, Albert Y. Zomaya, and Haiying Shen. A manifesto for future generation cloud
computing: Research directions for the next decade. ACM Comput. Surv. , 51(5):105:1–105:38, November
2018. ISSN 0360-0300. doi: 10.1145/3241737. URL http://doi.acm.org/10.1145/3241737 .
Xi Chen, Yan Duan, Rein Houthooft, John Schulman, Ilya Sutskever, and Pieter Abbeel. Infogan: In-
terpretable representation learning by information maximizing generative adversarial nets. Advances in
neural information processing systems , 29, 2016.
Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Holger
Schwenk, and Yoshua Bengio. Learning phrase representations using rnn encoder–decoder for statistical
machine translation. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language
Processing (EMNLP) , pp. 1724. Association for Computational Linguistics, 2014.
Kwanghee Choi and Siyeong Lee. Combating the instability of mutual information-based losses via regular-
ization. In Uncertainty in Artificial Intelligence , pp. 411–421. PMLR, 2022.
Samantha AW Crouch, Jan Krause, Thomas Dandekar, and Tim Breitenbach. Dataxflow: Synergizing data-
driven modeling with best parameter fit and optimal control–an efficient data analysis for cancer research.
Computational and Structural Biotechnology Journal , 23:1755–1772, 2024.
Paweł Czyż, Frederic Grabowski, Julia E Vogt, Niko Beerenwinkel, and Alexander Marx. Beyond normal:
On the evaluation of mutual information estimators. In Thirty-seventh Conference on Neural Information
Processing Systems , 2023. URL https://openreview.net/forum?id=25vRtG56YH .
Georges A Darbellay and Igor Vajda. Estimation of the information by an adaptive partitioning of the
observation space. IEEE Transactions on Information Theory , 45(4):1315–1321, 1999.
Hoang Anh Dau, Anthony Bagnall, Kaveh Kamgar, Chin-Chia Michael Yeh, Yan Zhu, Shaghayegh
Gharghabi, Chotirat Ann Ratanamahatana, and Eamonn Keogh. The ucr time series archive. IEEE/CAA
Journal of Automatica Sinica , 6(6):1293–1305, 2019.
Giulio Franzese, Mustapha Bounoua, and Pietro Michiardi. Minde: Mutual information neural diffusion
estimation. arXiv preprint arXiv:2310.09031 , 2023.
Robert G. Gallager. Stochastic Processes: Theory for Applications . Cambridge University Press, 2013. doi:
10.1017/CBO9781139626514.
Weihao Gao, Sewoong Oh, and Pramod Viswanath. Density functional estimators with k-nearest neighbor
bandwidths. In 2017 IEEE International Symposium on Information Theory (ISIT) , pp. 1351–1355. IEEE,
2017.
Hans-Otto Georgii. Stochastik: Einführung in die Wahrscheinlichkeitstheorie und Statistik . Walter de
Gruyter GmbH & Co KG, 2015.
Albert Greenberg, James R Hamilton, Navendu Jain, Srikanth Kandula, Changhoon Kim, Parantap Lahiri,
David A Maltz, Parveen Patel, and Sudipta Sengupta. Vl2: a scalable and flexible data center network.
InProceedings of the ACM SIGCOMM 2009 conference on Data communication , pp. 51–62, 2009.
Priscilla E Greenwood and Michael S Nikulin. A guide to chi-squared testing , volume 280. John Wiley &
Sons, 1996.
Arthur Gretton, Ralf Herbrich, Alexander Smola, Olivier Bousquet, Bernhard Schölkopf, et al. Kernel
methods for measuring independence. 2005.
Andrey Gromov, Kushal Tirumala, Hassan Shapourian, Paolo Glorioso, and Daniel A Roberts. The unrea-
sonable ineffectiveness of the deeper layers. arXiv preprint arXiv:2403.17887 , 2024.
33Under review as submission to TMLR
Albert Gu, Karan Goel, and Christopher Re. Efficiently modeling long sequences with structured state
spaces. In International Conference on Learning Representations , 2021.
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In
Proceedings of the IEEE conference on computer vision and pattern recognition , pp. 770–778, 2016.
R Devon Hjelm, Alex Fedorov, Samuel Lavoie-Marchildon, Karan Grewal, Phil Bachman, Adam Trischler,
and Yoshua Bengio. Learning deep representations by mutual information estimation and maximization.
InInternational Conference on Learning Representations , 2019. URL https://openreview.net/forum?
id=Bklr3j0cKX .
Sarah E Houts, Shandor G Dektor, and Stephen M Rock. A robust framework for failure detection and
recovery for terrain-relative navigation. Unmanned Untethered Submersible Technology , 2013.
Paul Jeha, Michael Bohlke-Schneider, Pedro Mercado, Shubham Kapoor, Rajbir Singh Nirwan, Valentin
Flunkert, Jan Gasthaus, and Tim Januschowski. Psa-gan: Progressive self attention gans for synthetic
time series. In The Tenth International Conference on Learning Representations , 2022.
Kenji Kawaguchi, Zhun Deng, Xu Ji, and Jiaoyang Huang. How does information bottleneck help deep
learning? In International Conference on Machine Learning , pp. 16049–16096. PMLR, 2023.
Taesung Kim, Jinhee Kim, Yunwon Tae, Cheonbok Park, Jang-Ho Choi, and Jaegul Choo. Reversible
instance normalization for accurate time-series forecasting against distribution shift. In International
Conference on Learning Representations , 2021.
Nikita Kitaev, Lukasz Kaiser, and Anselm Levskaya. Reformer: The efficient transformer. In International
Conference on Learning Representations , 2019.
Marcel Kollovieh, Abdul Fatir Ansari, Michael Bohlke-Schneider, Jasper Zschiegner, Hao Wang, and
Yuyang Bernie Wang. Predict, refine, synthesize: Self-guiding diffusion models for probabilistic time
series forecasting. Advances in Neural Information Processing Systems , 36, 2024.
Lyudmyla F Kozachenko and Nikolai N Leonenko. Sample estimate of the entropy of a random vector.
Problemy Peredachi Informatsii , 23(2):9–16, 1987.
Alexander Kraskov, Harald Stögbauer, and Peter Grassberger. Estimating mutual information. Physical
review E , 69(6):066138, 2004.
Yan Li, Xinjiang Lu, Yaqing Wang, and Dejing Dou. Generative time series forecasting with diffusion,
denoise, and disentanglement. Advances in Neural Information Processing Systems , 35:23009–23022, 2022.
Zhe Li, Shiyi Qi, Yiduo Li, and Zenglin Xu. Revisiting long-term time series forecasting: An investigation
on linear mapping. arXiv preprint arXiv:2305.10721 , 2023.
Yong Liu, Haixu Wu, Jianmin Wang, and Mingsheng Long. Non-stationary transformers: Exploring the
stationarity in time series forecasting. Advances in Neural Information Processing Systems , 35:9881–9893,
2022.
Zechun Liu, Changsheng Zhao, Forrest Iandola, Chen Lai, Yuandong Tian, Igor Fedorov, Yunyang Xiong,
Ernie Chang, Yangyang Shi, Raghuraman Krishnamoorthi, et al. Mobilellm: Optimizing sub-billion
parameter language models for on-device use cases. arXiv preprint arXiv:2402.14905 , 2024.
Spyros Makridakis, Evangelos Spiliotis, and Vassilios Assimakopoulos. The m4 competition: 100,000 time
series and 61 forecasting methods. International Journal of Forecasting , 36(1):54–74, 2020.
Mary L McHugh. The chi-square test of independence. Biochemia medica , 23(2):143–149, 2013.
Long Short-Term Memory. Long short-term memory. Neural computation , 9(8):1735–1780, 2010.
Young-Il Moon, Balaji Rajagopalan, and Upmanu Lall. Estimation of mutual information using kernel
density estimators. Physical Review E , 52(3):2318, 1995.
34Under review as submission to TMLR
Kevin P Murphy. Probabilistic machine learning: an introduction . MIT Press, 2022. Available at https:
//github.com/probml/pml-book/releases/latest/download/book1.pdf .
Yuqi Nie, Nam H Nguyen, Phanwadee Sinthong, and Jayant Kalagnanam. A time series is worth 64 words:
Long-term forecasting with transformers. In The Eleventh International Conference on Learning Repre-
sentations , 2022.
Aaron van den Oord, Yazhe Li, and Oriol Vinyals. Representation learning with contrastive predictive
coding.arXiv preprint arXiv:1807.03748 , 2018.
Hanchuan Peng, Fuhui Long, and Chris Ding. Feature selection based on mutual information criteria of max-
dependency, max-relevance, and min-redundancy. IEEE Transactions on pattern analysis and machine
intelligence , 27(8):1226–1238, 2005.
Calyampudi Radhakrishna Rao. Linear statistical inference and its applications , volume 2. Wiley New York,
1973.
Andreas Raue, Bernhard Steiert, Max Schelker, Clemens Kreutz, Tim Maiwald, Helge Hass, Joep Vanlier,
Christian Tönsing, Lorenz Adlung, Raphael Engesser, et al. Data2dynamics: a modeling environment
tailored to parameter estimation in dynamical systems. Bioinformatics , 31(21):3558–3560, 2015.
Ian Reid and Hilary Term. Estimation ii. University of Oxford, Lecture Notes , 2001.
Andrew M Saxe, Yamini Bansal, Joel Dapello, Madhu Advani, Artemy Kolchinsky, Brendan D Tracey, and
David D Cox. On the information bottleneck theory of deep learning. Journal of Statistical Mechanics:
Theory and Experiment , 2019(12):124020, 2019.
Vaisakh Shaj, Saleh GHOLAM ZADEH, Ozan Demir, Luiz Ricardo Douat, and Gerhard Neumann. Multi
time scale world models. In Thirty-seventh Conference on Neural Information Processing Systems , 2023.
URL https://openreview.net/forum?id=fY7dShbtmo .
Jiaming Song and Stefano Ermon. Understanding the limitations of variational mutual information estima-
tors. In International Conference on Learning Representations , 2020. URL https://openreview.net/
forum?id=B1x62TNtDS .
Yusuke Tashiro, Jiaming Song, Yang Song, and Stefano Ermon. Csdi: Conditional score-based diffusion
models for probabilistic time series imputation. Advances in Neural Information Processing Systems , 34:
24804–24816, 2021.
Michael Ulbrich. Semismooth Newton methods for variational inequalities and constrained optimization
problems in function spaces . SIAM, 2011.
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser,
and Illia Polosukhin. Attention is all you need. Advances in neural information processing systems , 30,
2017.
Mitchell Wortsman, Gabriel Ilharco, Samir Ya Gadre, Rebecca Roelofs, Raphael Gontijo-Lopes, Ari S Mor-
cos, Hongseok Namkoong, Ali Farhadi, Yair Carmon, Simon Kornblith, et al. Model soups: averaging
weights of multiple fine-tuned models improves accuracy without increasing inference time. In Interna-
tional Conference on Machine Learning , pp. 23965–23998. PMLR, 2022.
Haixu Wu, Jiehui Xu, Jianmin Wang, and Mingsheng Long. Autoformer: Decomposition transformers with
auto-correlation for long-term series forecasting. Advances in Neural Information Processing Systems , 34:
22419–22430, 2021.
Yilun Xu, Peng Cao, Yuqing Kong, and Yizhou Wang. L_dmi: A novel information-theoretic loss function
for training deep nets robust to label noise. Advances in neural information processing systems , 32, 2019.
Jinsung Yoon, Daniel Jarrett, and Mihaela Van der Schaar. Time-series generative adversarial networks.
Advances in neural information processing systems , 32, 2019.
35Under review as submission to TMLR
Xinyu Yuan and Yan Qiao. Diffusion-TS: Interpretable diffusion for general time series generation. In The
Twelfth International Conference on Learning Representations , 2024. URL https://openreview.net/
forum?id=4h1apFjO99 .
Ailing Zeng, Muxi Chen, Lei Zhang, and Qiang Xu. Are transformers effective for time series forecasting?
InProceedings of the AAAI conference on artificial intelligence , volume 37, pp. 11121–11128, 2023.
Ray Zhang, Nicholas F Lahens, Heather I Ballance, Michael E Hughes, and John B Hogenesch. A circadian
gene expression atlas in mammals: implications for biology and medicine. Proceedings of the National
Academy of Sciences , 111(45):16219–16224, 2014.
Xiyuan Zhang, Xiaoyong Jin, Karthick Gopalswamy, Gaurav Gupta, Youngsuk Park, Xingjian Shi, Hao
Wang, Danielle C. Maddix, and Bernie Wang. First de-trend then attend: Rethinking attention for time-
series forecasting. In NeurIPS ’22 Workshop on All Things Attention: Bridging Different Perspectives on
Attention , 2022. URL https://openreview.net/forum?id=GLc8Rhney0e .
Yunhao Zhang and Junchi Yan. Crossformer: Transformer utilizing cross-dimension dependency for mul-
tivariate time series forecasting. In The Eleventh International Conference on Learning Representations ,
2022.
Haoyi Zhou, Shanghang Zhang, Jieqi Peng, Shuai Zhang, Jianxin Li, Hui Xiong, and Wancai Zhang. In-
former: Beyond efficient transformer for long sequence time-series forecasting. In Proceedings of the AAAI
conference on artificial intelligence , volume 35, pp. 11106–11115, 2021.
36Under review as submission to TMLR
A Further explanation on discretization and empirical probability estimation
This section aims at providing further explanation on the discretization schema and the details of the
calculation of the empirical marginal and joint probability functions. We exemplify the procedure how we
compute these entities based on Algorithm 1 with our time series data.
We first consider a sufficient number of input-output windows as depicted in Figure 11a, each having the
same total length, which is the sum of the input length and the output length. In each window, the ith
point in the input is considered as the random variable xi, while the jthpoint in the output is treated as
the random variable yj. This is illustrated in Figure 11b. For each window, we get one realization of each
random variable xiandyj.
(a) Several input-output windows randomly selected from a dataset.
Input | Context Output | Target
(b) Details of a selected window including input and output modeled as random variables.
Figure 11: Preparation of the data for the statistical tests.
Once we have a sufficient number of realizations for each of the random variables, we apply Algorithm 1 to
discretize the co-domain of each random variable. Each bin of the discretized co-domain of a random variable
defines the event that the value of this random variable is between the boundaries of that bin. Algorithm 1
can be viewed as performing adaptive binning and histogram construction for each of the random variables.
In this context, each event zk
virepresents the random variable vitaking a value within the interval defined by
the upper and lower bounds of the kthbin after discretization. Consequently, the output of this algorithm
includes the upper and lower bounds of the bins as well as the frequency with which the random variable vi
falls into each bin.
To compute the joint probability distribution of random variables, modeling the input of a model, the output
of a model, the residuals or the model deviations, we calculate the frequency of the joint events where each
random variable is within a bin. For this purpose, each joint realization is placed into the corresponding
2D cell (or cuboids in higher dimensions where more than pairwise combinations of random variables are
considered), whose bin boundaries are predetermined by the outer product of the marginal bins. This process
37Under review as submission to TMLR
is illustrated in Figure 12. The probability for marginal and joint distributions is obtain by dividing the
corresponding frequency by the number of realizations (in this case the number of windows).
Boundries of event/interval  or lessRange of variable Range of V ariable Boundries of event/interval 
or less
Figure 12: Computation of the joint histogram for pairs of random variables. Each joint realization of
xiandyjobserved across all input-output windows is represented by a green square and is placed in the
corresponding 2D bin. The boundaries of the 2D bins are determined by the outer product of the boundaries
for each random variable. Discretization of each random variable follows the procedure outlined in Algorithm
1. Note that the marginal distributions are discretized to have equal numbers of data points per bin (where
there might be an exception for the last bin according to our realization or if there are many points with the
same value), the joint distribution can deviate arbitrarily much from a uniform distribution. In this figure,
ρ1andρ2are illustrated with different values ( ρ1= 10,ρ2= 15) for the sake of generality. Consequently,
each bin of the marginals here contains 10 or 15 green squares, respectively. However, in our experiments,
these values are set to be equal.
B Convergence and bounds on estimation of mutual information
In this section, we discuss the convergence property of our approximation of mutual information based on
Algorithm 1. For this purpose, we focus on Darbellay & Vajda (1999) which describes a convergence result
for mutual information based on an adaptive discretization scheme of the co-domains of random variables.
We show that our method fulfills the same conditions as used in Darbellay & Vajda (1999). These conditions
are that the discretization scheme decouples the process of decreasing bin width and approximation of the
true density with the empirical one by increasing the samples in each bin. Once we have shown that our
approach fulfills the same conditions, we can follow the reasoning in Darbellay & Vajda (1999) to prove
convergence of the mutual information based on our framework to the true mutual information between
random variables. For this rigorous analysis, we have to equip our algorithm by a further threshold keeping
a bin at a minimal width. In this case of reaching the minimum bin width, the condition of the minimum
number of points per bin is suspended for this bin. These two further items are used for the theoretical
38Under review as submission to TMLR
consideration to apply it several times for the convergence process, however, do not come into action for its
application.
First, we show how we can ensure the decreasing bin width by including more samples. The data, prediction
and therefore residuals/model deviations from the data are finite. The reason for the boundedness is that the
model is a continuous function and thus bounded input is mapped to a bounded output. Consequently, as
these entities constitute our random variables, the marginal and joint distributions are of bounded support.
Therefore adding more data points would lead to an arbitrarily smaller bin width when a fixed amount of
data points per bin is considered, unless the marginal probability is exactly zero. However, in this case the
joint probability is also zero resulting in the fact that these events do not contribute to the total mutual
information. Consequently, we can discard these bins and without loss of generality, we require non-zero
probability density within the domain. By iteratively including more data points, our discretization scheme
provides decreasing bin width until the minimum bin width is reached.
The next requirement for applying the reasoning of Darbellay & Vajda (1999) is to show that putting more
samples increases the data points per bin to approximate the true probabilities by the empirical ones to
any arbitrarily small error. Due to the action of the minimum bin width, putting more data points solely
increases the number of data points per bin since we have a non-zero probability. Consequently, the minimum
bin width ensures a decoupling of the limit process of getting a finer discretization of the domains of the
probability functions and more data points per bin to make empirical distributions converge to the true ones.
We remark that the main focus of our work is to show that measures quantifying the stochastic independence
between input and output, and thus residuals or model deviations, are useful to monitor model convergence.
Examples are the chi-square test of independence or the mutual information. In particular, for the mutual
information there are many different implementations that have their pros and cons. For some overview,
please have a look into (Czyż et al., 2023, Appendix), including convergence results for the estimators.
C Models’ settings for numerical experiments
This section of the appendix is allocated to the architecture of the utilized neural networks (NNs) in the
experiments. Through this appendix we show the architecture of the MLPs with the number of nodes per
each layer inside a list. The number of layers is the same as the length of the list. Unless specified differently,
all activation functions are Relu and initial learning rates are 1e-4.
Section 4.1 :
All NNs are MLPs with Relu activation functions.
MLP Layers: [49,490,980,1]
Activation functions: Relu
Initial learning rate: 1e-4
0.506M parameters
Section 4.2 :
All NNs are MLPs with Relu activation functions. Number of nodes in each layer is written in the list.
MLP Layers: [49,490,700,490,1]
Activation function: Relu
Initial learning rate: 1e-4
0.712M parameters
Figure 6 : Timesreise Classification
MLP CrossEntropy (0.84M)
MLP Layers: [80, 720, 720, 360, 2]
39Under review as submission to TMLR
Figure 7 : Timesreise Classification
NST CrossEntropy (0.69M)
Number of encoder layers: 2
Number of decoder layers: 1
Number of heads: 8
d_model: 128
Dropout: 0.1
MLP CrossEntropy (0.85M)
MLP Layers: [96, 720, 720, 360, 7]
Table 4:
MLPL1-0.5 (0.025M) & MLPL2-0.5 (0.025M):
Layers ob both models: [60,80,120,80,1]
Activation function: Relu
InitiaL learning rate: 1e-4
MLPL1(0.05M) & MLPL2(0.05M) :
Layers for both models: [120,80,180,1]
NSTL1 (0.05M) & NSTL2 (0.05M)
Number of encoder layers: 1
Number of decoder layers: 1
Number of heads: 2
d_model: 40
Dropout: 0.1
Table 6:
Here is the details of the pool of the used models -MLPs and Transformers- in one step ahead prediction
experiment on weather dataset. For all non-stationary transformers (NSTs) dropout is set to 0.1.
The initial learning_rate for all models as the first stack is 1e-4 and for the second and the third stack is
1e-5.
The dropout for NSTs is 0.1 and for PatchTsT is 0.2, and there is no dropout for MLPs.
The size of subsequent hidden layer after the attention head (d_ff) in transformers are set to the provided
default numbers, i.e. 4*d_model for NSTs and for 2*d_model for PatchTST.
Please note that PatchTST uses the vanilla Transformer encoder as its core architecture Nie et al. (2022)
and therefore the number of decoder layer is zero.
PatchTST L2(0.41M)
PatchTST L2 architecture
Number of encoder layers: 3
Number of decoder layers: 0
Number of heads: 16
d_model: 128
Dropout: 0.2
MLP L1(0.59M)
MLP Layers: [96, 720, 720, 1]
NST L1(3.88M)
NST L1 architecture
Number of encoder layers: 2
40Under review as submission to TMLR
Number of decoder layers: 2
Number of heads: 8
d_model: 256
Dropout: 0.1
NST L1(1.05M)
NST architecture
Number of encoder layers: 2
Number of decoder layers: 2
Number of heads: 8
d_model: 128
Dropout: 0.1
NST L1(0.86M) on PatchTST L2(0.41M)
NST architecture
Number of encoder layers: 2
Number of decoder layers: 1
Number of heads: 8
d_model: 128
Dropout: 0.1
PatchTST architecture
Number of encoder layers: 3
Number of decoder layers: 0
Number of heads: 16
d_model: 128
Dropout: 0.2
NST L1(1.13M) on PatchTST L2(0.41M)
NST architecture
Number of encoder layers: 2
Number of decoder layers: 2
Number of heads: 8
d_model: 128
Dropout: 0.1
PatchTST architecture
Number of encoder layers: 3
Number of decoder layers: 0
Number of heads: 16
d_model: 128
Dropout: 0.2
NST L2(0.53M) on MLP L1(0.59M)
MLP Layers: [96, 720, 720, 1]
NST architecture:
Number of encoder layers: 2
Number of decoder layers: 1
Number of heads: 6
d_model: 96
Dropout: 0.1
41Under review as submission to TMLR
NST L1(0.86M) on MLP L1(0.59M)
MLP Layers: [96, 720, 720, 1]
NST architecture:
Number of encoder layers: 2
Number of decoder layers: 1
Number of heads: 8
d_model: 128
Dropout: 0.1
NST L1(2.05M) on MLP L1(0.59M)
MLP Layers: [96, 720, 720, 1]
NST architecture:
Number of encoder layers: 4
Number of decoder layers: 4
Number of heads: 8
d_model: 128
Dropout: 0.1
MLP L1(0.59M) on NST L1(1.13M) on PatchTST L2(0.41M)
MLP Layers: [96, 720, 720, 1]
NST architecture
Number of encoder layers: 2
Number of decoder layers: 2
Number of heads: 8
d_model: 128
Dropout: 0.1
PatchTST architecture
Number of encoder layers: 3
Number of decoder layers: 0
Number of heads: 16
d_model: 128
Dropout: 0.2
Table 5:
In this experiment, two simple SVM models are used:
SVM with rbf kernel
SVM with with sigmoid kernel
Table 7:
Here is the details of the pool of the used models -MLPs and Transformers- in multistep ahead prediction
experiment on NASDAQ-DE1 dataset.
MLP L1 (2.09M):
MLP Layers: [60,360,3440,240,30]
MLP L2 (3.77M):
MLP Layers: [60,720,3440,360,30]
42Under review as submission to TMLR
MLP L2 (4.61M):
MLP Layers: [60,900,3440,420,30]
NST L1 & NST L2 (2.67M):
Number of encoder layers: 2
Number of decoder layers: 1
Number of heads: 8
d_model: 256
Dropout: 0.1
MLP L2 (0.67M) on MLPL1 (2.09M)
MLP L2 Layers: [60,360,1080,240,30])
MLP L1 Layers: [60,360,3440,240,30]
MLP L2 (0.64M) on NSTL1 (2.67M):
MLP L2 layers: [60,360,1020,240,30]
NST L1 architecture:
Number of encoder layers: 2
Number of decoder layers: 1
Number of heads: 8
d_model: 256
Dropout: 0.1
MLP L2 (0.09M) on MLP L2 (0.64M) on NST L2 (2.67M)
NST L2 architecture:
Number of encoder layers: 2
Number of decoder layers: 1
Number of heads: 8
d_model: 256
Dropout: 0.1
MLP L2 (0.64M) layers: [60,360,1020,240,30]
MLP L2 (0.09M) layers: [60,720,60,30]
C.1 Data description
Datasets Here is a description of the datasets used in our experiments:
(1)ETTZhou et al. (2021) contains seven features including the oil temperature and six power load feature.
ETTh indicates the ETT data with a granularity of 1-hour-level and ETTm indicates the ETT data with a
granularity of 15-minutes-level.
(2)Weather1is recorded every 10 minutes for 202 whole year, and contains 21 meteorological indicators such
as humidity and air temperature.
(3)Nasdaqdataset consists of 82 variables, including important indices of markets around the world, the
price of major companies in the U.S. market, treasury bill rates, etc. It is measured daily, having a total
of 1984 data samples for each variable. We set the corresponding input length as 60 similar to Kim et al.
(2021). In this work, we conduct our experiments on DE1 variable.
(4)ElectricDevice is a subset of the UCR time series classification dataset. It consists of seven different
classes, each representing a specific type of electric device which is to be predicted from the time series.
1https://www.bgc-jena.mpg.de/wetter/
43Under review as submission to TMLR
(5)DistalPhalanxOutlineCorrect is a subset of the UCR time series classification dataset. This dataset
focuses on the classification of outlines of distal phalanx bones from time series.
D Further experiments showcasing the stacking of models
The results of this experiment demonstrating 1-step ahead prediction with the stacking procedure is provided
in Table 6 for the Weather dataset, see Subsection C.1. The split setting is matched with Nie et al. (2022).
Except the prediction length, we use the same training parameters and architecture for PatchTST as used
in Nie et al. (2022).
Metrics Init MI Init Perm Init diff Res MI Res Perm Res diff
PatchTSTL2 (0.41M) 3213 153 3060 659 177 482
MLPL1 (0.59M) 3213 153 3060 514 174 340
NSTL1 (3.88M ) 3213 153 3060 608 182 426
NSTL1(1.05M ) 3213 153 3060 641 183 458
NSTL2(0.426M) 3213 153 3060 700 182 518
NSTL1(0.86M)+PatchTSTL2(0.41M) 3213(659) 153(177) 3060(482) 506 181 325
NSTL1(1.13M)+PatchTSTL2(0.41M) 3213(659) 153(177) 3060(482) 516 183 333
NSTL2(0.53M)+MLPL1(0.59M) 3213(514) 153(171) 3060(343) 400 181 219
NSTL1(0.86M)+MLPL1(0.59M) 3213(514) 153(171) 3060(343) 441 182 259
NSTL1(0.53M)+MLPL1(0.59M) 3213(514) 153(171) 3060(343) 442 182 260
NSTL1(2.05M)+MLPL1(0.59M) 3213(514) 153(171) 3060(343) 448 182 266
MLPL1(0.59)+NSTL1(1.13M) + PatchTSTL2 (0.41M) 3213(516) 183(153) 3060(363) 499 182 317
Table 6: Comparison of performance metrics for various standalone and stacked models on weather dataset.
Initial mutual information (MI), permutation analysis values, and their differences are presented, providing
insightsintothestartingstates. Residualmetrics, includingmutualinformation, valuesfromthepermutation
test of mutual information are also reported.The corresponding p-values assessing the independence of input
and residual output is always 0 in all experiments. Additionally, in the first column, number of parameters
for the models is shown in parentheses in millions. In the other columns, the values of the metrics only for
the last model of the stack is depicted in the parentheses. In the first column, the model on the left is the
first one and the one on the right is the last model in the stack.
In the next experiment, we demonstrate our framework for a multistep prediction. We take the NASDAQ
dataset from Kim et al. (2021) analogously to Section 4.5. We choose the input of length 60 to predict a
target length of 30. The result is provided in Table 7 and shows that also in this case, with stacking of
models, we can systematically extract the information and gradually make the input independent of the
residuals in contrast to the single models. The evidence is provided by the fact that a stack of MLP and
NST models provides the smallest mutual information between input and residuals when subtracting the
mutual information generated by randomly shuffling the data (column "Res diff" of Table 7).
44Under review as submission to TMLR
Metrics Init MI Init Perm Init diff Res MI Res Perm Res diff Init Chi-square Res Chi-sauare
MLP L1(2.09M) 617.48 123.29 494.19 169.45 135.11 34.34 1800 332
MLP L2 (3.77M) 617.48 123.29 494.19 163.53 135.36 28.17 1800 182
MLP L2 (4.61M) 617.48 123.29 494.19 162.82 135.47 27.35 1800 177
NST L1(2.67M) 617.48 123.29 494.19 183.23 135.15 48.08 1800 811
NST L2(2.67M) 617.48 123.29 494.19 179.47 135.28 44.19 1800 729
MLP L2(0.67M) + MLP L1(2.09M) 617.48(169.45) 123.287(135.11) 494.19(34.35) 157.91 135.28 22.63 1800(332) 55
MLPL2(0.64M)+NSTL1(2.67M) 617.48(183.23) 123.287(135.15) 494.19(48.08) 156.84 135.22 21.62 1800(811) 35
MLP L2(0.64M)+NSTL2(2.67M) 617.48(179.47) 123.287(135.28) 494.19(44.19) 153.15 135.25 17.90 1800(729) 30
MLPL2(0.09M)+MLPL2(0.64M)+NSTL2(2.67M) 617.48(153.17) 123.287(135.28) 494.19(17.89) 151.80 135.27 16.53 1800(30) 20
Avg Ensemble (3.4M) 617.48 123.29 494.19 170.95 135.36 35.59 1800 387
Table 7: Comparison of performance metrics for various standalone and stacked models. Initial mutual
information (MI), permutation analysis values, and their differences are presented, providing insights into
the starting states. Residual metrics, including mutual information, values from the permutation test of
mutual information. Additionally, the number of dependent input lags tested by the chi-square test of
independence for both initial and residual states are included. In the first column, the number of parameters
for the models is shown in parentheses in millions. In the other columns, the values of the metrics only
for the last model of the stack is depicted in the parentheses. In the first column, the model on the left is
the first one and the one on the right is the last model in the stack. In the last row, we take the average
prediction of the three models of the penultimate row when each of those models is separately trained to
predict the original ground truth. The p-values assessing the independence of input and residual output
based on mutual information remains always zero in all experiments in this table.
45Under review as submission to TMLR
E Further tables and figures
Without Noise: residuals are magnified by 10000
 Amplitude of Noise = 0.2
Amplitude of Noise = 0.6
 Amplitude of Noise = 0.8
Figure 13: Plots of model outputs (prediction), residuals and the data (ground truth) of the experiments of
Section 4.1.
46Under review as submission to TMLR
MLP-L1
 MLP-L2
Figure 14: Plots of model outputs (prediction), residuals and the data (ground truth) of the experiments of
Section 4.2.
Figure 15: Plots of model outputs (prediction), residuals and the data (ground truth) of the ETTh2 dataset.
47Under review as submission to TMLR
Theoretical bound Experimental Error Pearsonr Analysis
Relative noise std Normalized Test RMSE Initial R Residual R
0 0.000023 30.764 0
0.2715 0.2737 28.538 0
0.4919 0.5043 23.129 0
0.6465 0.6687 17.494 0.9446
0.7499 0.7683 13.197 0
0.8161 0.8287 10.455 0
0.8614 0.8718 7.868 0
0.8923 0.901 5.561 1
0.9149 0.9206 4.664 0
0.9308 0.9427 3.723 0
0.9429 0.9373 2.882 0
Table 8: Pearson correlation results for Section 4.1. The test consists of the sum of the absolute value
of the Pearson correlation between each input and output features. However, the correlation measure is
only considered if the p-value is smaller than 0.01. Otherwise, the corresponding input and output pair is
considered as uncorrelated. In the first column, there is the relative noise, which is the root of the variance
of the noise divided by the total signal. The second column provides the normalized RMSE as defined in
Section 4. The third column is the sum of the absolute value of the Pearson correlation between input and
the single step forecast as output and the forth column is analogous to the third column where the single step
forecast is replaced by the corresponding residual (model prediction minus data). Since the residuals are less
correlated or even decorrelated with the input, the model extracted the deterministic relations measured in
the Pearson correlation test.
-Initial pearsonr Residual Pearsonr + L2 Residual Pearsonr + L1
Trial 0 15.33 0 0
Trial 1 16.925 0 0
Trial 2 15.25 0 0
Trial 3 17.104 0 0
Trial 4 15.449 0 0
Table 9: The effect of the choice of the loss function in mitigating asymmetric noise effect in terms of
distracting a model from extracting/learning the deterministic relations. The experiments are conducted in
Section 4.2. The Pearson test is described in Table 8. While the chi-square test and the mutual information
test depicted in Table 2 reflect the better fitting of the model trained with L1-loss function to the real data,
see Table 3, the Pearson test does not, which could be traced back to the limitation of testing only linear
correlations where chi-square and mutual information are generalizations in terms of measuring stochastic
independence.
F Transformer architecture explanation
In this section, we explain the transformer architecture in more detail. Specifically, we explain the building
blocks as depicted in (Vaswani et al., 2017, Figure 1).
F.1 Token embedding
In the transformer model, each token of the input sequence is first represented as a dense vector called a
token embedding. This embedding captures the semantic meaning of the token in the context of the task
being performed.
48Under review as submission to TMLR
Each token is encoded by a vector z∈Rdzone-hot encoding the corresponding token where dz∈Nis the
number of different tokens generated from the vocabulary. The token embedding is obtained by applying
a linear transformation A∈RC×dzto the one-hot encoded representation of tokens zwhereC∈Nis the
number of dimensions of the transformer’s internal representation of the embeddings ( Csometimes also
denoted with embedding _size). The entries of Aare learnable weights and optimized during the training
process. The mapping A:Rdz→RC,z∝⇕⊣√∫⊔≀→Azcan be implemented as:
token_embedding =nn.Linear (config.vocab_size ,config.n_embed )
where config.vocab_size =dzis the size of the vocabulary (number of unique tokens), and config.n_embed is
the desired embedding dimension C. Consequently, this mapping turns the input shape (B,T,dz)to the out-
put shape of the token embedding (B,T,C ), whereBrepresents the batch size and Trepresents the sequence
length of the input (number of tokens). The transformation Ais applied to each token and element of a
batch byz(b,:,:)∝⇕⊣√∫⊔≀→z(b,:,:)Afor eachb∈{1,...,B}wherez∈RB×T×dz,z(b,:,:):= (zbik)i∈{1,...,T},k∈{1,...,d z}
provides the one-hot encoded representation for each token and each element of the batch. By using batches,
several inputs can be considered at once.
For the specific case of time series modeling, the token embedding is replaced by the following. A convolu-
tional neural network (CNN) is used for generating the embedding. The input channels of the CNN equal 1
in an autoregressive scenario (only historic parts of the time series itself are use to predict future parts of the
time series) but can be set to any feature number F∈N, which is measured at each time point, in case, e.g.,
an output is predicted from several input time series. Each time window for each channel, which cuts out
each part of the Ftime series of length Tand which is used as the input for the prediction, is represented by
a vector of size T. These vectors from the sliding window are transformed by a one-dimensional CNN into the
spaceRC. The padding is set such that the input length Tequals the output length of the CNN. We remark
that the shift one by one time points is not necessary and can be increased such that the token number
in the embedding is smaller than the number of time points used as the input for the transformer. In our
case, each filter (convolution) of the CNN is applied to each output, controlled by the parameter groups=1
and a common choice for the kernel size of 3. To achieve this transformation, we employ a one-dimensional
convolutional layer in our implementation. Specifically, a 1D convolutional layer with an input channel size
ofFand an output channel size of C(the embedding dimension of the transformer) can be utilized:
nn.Conv1d (In_channels =F,out_channels =C)
This convolutional layer applies a set of learnable filters across the temporal dimension Tof the in-
put data, extracting relevant patterns and features. It’s important to note that the kernel size,
padding, and stride parameters of the convolutional layer can be adjusted to ensure that the out-
put length matches the input length T. For more details, see the PyTorch documentation, e.g.,
https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html.
In general, the transformation (token embedding by a CNN) is applied as follows CNN :RT×F→
RT×C,z(b,:,:)∝⇕⊣√∫⊔≀→CNN (z(b,:,:))to each each element of a batch z(b,:,:)∈RB×T×F,z(b,:,:):=
(zbik)i∈{1,...,T},k∈{1,...,F}, numerated by b∈{1,...,B}with the batch size B∈N, (in parallel) generating a
tensor of dimension (B,T,C ).
For more details about the general framework of token embedding, see, e.g., Zhou et al. (2021).
F.2 Positional embedding
The purpose of a positional embedding is to include information about the position of a token relative to
other tokens from the input into the total embedding of each token. The positional embedding is a vector
of dimension Cand is added to the token embeddings to provide information about the relative positions of
tokens.
There are several methods available to code for positional information, see, e.g., Vaswani et al. (2017).
49Under review as submission to TMLR
F.3 Attention head operation
The attention head is the essential building block of a transformer. Each attention head forms one layer
where the output of one layer is processed by a subsequent layer until the output of the final layer is processed
by a linear layer to obtain a corresponding output, see, e.g., (Vaswani et al., 2017, Figure 1).
Let’s consider a single attention head operation in a transformer model. In this operation, we have the
input tensor x∈RB×T×C. The tensor xcan be the one after the token embedding (inclusive positional
encoding) or the output of a previous layer. We remark that each layer in this presentation preserves the
format (B,T,C ).
The input tensor xis next transformed into different representations via linear transformation matrices.
These matrices contain the learnable weights and are given by WK∈RC×C,WQ∈RC×CandWV∈RC×C.
We define a tensor for key ( K), query (Q), and value ( V) by the linear mappings
K(b,·,·):=x(b,·,·)WK∈RT×C, Q (b,·,·):=x(b,·,·)WQ∈RT×C, V (b,·,·):=x(b,·,·)WV∈RT×C
for eachb∈{1,...,B}wherex(b,·,·)∈RT×Csuch thatx(b,i,k ) =xbikfor allb∈{1,...,B},i∈{1,...,T}
andk∈{1,...,C}. Each of the matrices WK,WQandWVis an instance of a linear layer and can be
implemented with PyTorch as follows:
nn.Linear (C,C,bias =False ).
We remark that Cmay be called embedding _size.
In order to quantify the attention of token i∈{1,...,T}represented in its key representation (K)with regard
to tokenj∈{1,...,T}of the input represented in its query representation (Q), the dot product is calculated
for eachb∈{1,...,B}between the query ( Q) and key (K) tensors over the vector embedding for each token
pairi,j∈{1,...,T}. This operation can be represented as
Θ :{1,...,B}×{ 1,...,T}×{ 1,...,T}→R,(b,i,j )∝⇕⊣√∫⊔≀→Θ(b,i,j ):=1√
CC/summationdisplay
k=1Qb,i,k·Kb,j,k (6)
wherebrepresents the batch index, iandjrepresent the positions in the sequence (input), and krepresents
the embedding dimension. The sum is scaled by C−0.5. One reason behind dividing the sum by the square
root of the embedding dimension is given in the section about the Softmax function below, see Section F.3.1.
We implement the mapping Θusing the key ( K) and query ( Q) tensors and the Einstein summation con-
vention as follows:
Θ(b,i,j ) =1√
Ctorch.einsum (bij,bkj−>bik,Q,K )
F.3.1 Softmax
After calculating the similarities between keys and queries, the purpose of the Softmax function is to nor-
malize the scores of similarity. A high similarity between the key of token iand the query of token jis a
proxy for a high association or attention the token ihas to token j, meaning the connection is important for
predicting the corresponding output. Due to the monotonicity of the Softmax function, a bigger similarity
score between the corresponding key and query will result in a bigger value, called attention between the
corresponding tokens, compared to smaller ones.
The Softmax function in our case is defined by
Softmax :{1,...,B}×{ 1,...,T}×{ 1,...,T}→R,(b,i,j )∝⇕⊣√∫⊔≀→Softmax(b,i,j ):=eΘ(b,i,j)
/summationtextT
l=1eΘ(b,i,l).
50Under review as submission to TMLR
Here, the Softmax function is applied along the last dimension, ensuring that the attention weights sum
up to 1 along this dimension. This normalization means, fixing a batch number band a token number
iof the input provides us a normalized attention score about all the other token numbers j∈{1,...,T}.
The implementation is done by applying the corresponding Softmax function along dim= −1to the tensor
Θb,i,j:= Θ(b,i,j )for allb∈{1,...,B}andi,j∈{1,...,T}.
Next, weexplainthenormalizationby C−0.5of(6). Forlargenumbers, theSoftmaxfunctionisapproximately
aconstantfunctionandchangesintheweightsofthetransformermodeldonotresultinasignificantchangeof
the attention. Depending on the embedding dimension C, the corresponding sum scales. For an illustration,
see, e.g., (Vaswani et al., 2017, footnote 4). The scaling of the sum by C−0.5ensures to stay in a range
where the Softmax is in an area of larger steepness and changes in the weights of the transformer result in
significant changes of the attention values. Similarly, see (Vaswani et al., 2017, Section 3.2.1).
F.3.2 Weighted aggregation
We apply the attention scores to the value tensor ( V) to obtain a weighted sum. The attention tensor is
defined by
Ab,i,j:= Softmax( b,i,j )
for allb∈{1,...,B}andi,j∈{1,...,T}such thatA∈RB×T×T. The weighted sum of attention scores is
given by
A(b,·,·)V(b,·,·)∈RT×C
for eachb∈{1,...,B}and turns the output of an attention head into the tensor format (B,T,C ). The
output tensor of attention head H∈RB×T×Cis defined by
Hb,i,k:=T/summationdisplay
l=1Ab,i,lVb,l,k
for allb∈{1,...,B},i∈{1,...,T}andk∈{1,...,C}.
F.3.3 Multi-head attention
Optionally, in order to calculate attention on different subspaces of keys and queries for the same input in
each layer, there is a multi-head attention taking only projected parts of keys and queries.
In the multi-head attention formalism, the output of each head is concatenated along the last dimension,
which is the embedding dimension
Concat ((B,T,C/n _heads ),...,(B,T,C/n _heads )) = (B,T,C )
wheren_headsis the number of attention heads. Specifically, the output of each head is calculated with
the following weight matrices WK
h∈RC×C/n_heads,WQ
h∈RC×C/n_heads,WV
h∈RC×C/n_headsand
WO∈RC×Cwhereh∈{1,...,n_heads}. Furthermore, n_headsandCare chosen such that the quotient
C/n_headsis an integer. The matrices calculate the corresponding projections of keys, queries and values as
followsKh(b,·,·):=K(b,·,·)WK
h∈RT×C/n_heads,Qh(b,·,·):=Q(b,·,·)WQ
h∈RT×C/n_heads,Vh(b,·,·):=
V(b,·,·)WV
h∈RT×C/n_headsfor allb∈{1,...,B}.
The weight matrices WK
h,WQ
handWV
hare each implemented with a linear layer according to
nn.Linear (C,head_size,bias =False )
andhead_sizeis calculated as
head_size=/floorleftbiggembedding _size
n_heads/floorrightbigg
where forWOthe number head_sizeis replaced by C.
51Under review as submission to TMLR
Applying the procedure for the single-head attention for each h∈{1,...,n_heads}by replacing each Kby
the corresponding Kh, eachQby the corresponding Qhand eachVby the corresponding Vhprovides us
the tensor of each attention head Hh∈RB,T,C/n _headswhere in (6) the index in the sum is only over 1to
C/n_headseach.
After processing all attention heads, the outputs are concatenated along the last dimension, resulting in a
tensor of shape (B,T,C ). The output of the multi-head attention is given by
H(b,·,·):= Concat(H1(b,·,·),...,Hn_heads(b,·,·))WO∈RT×C
for eachb∈{1,...,B}.
F.4 Adding and layer normalization
After the attention head operation, residual connections and layer normalization are applied.
Theaddingoftheinputandtheoutputofalayer(residuallearningHeetal.(2016))iscrucialformaintaining
an information flow and is easing the training of deep networks. The residual connection involves adding the
input tensor xto the output of the multi-head attention operation Haccording to x+Hwhere +denotes
an element-wise addition. The addition helps to loop through the original information from the input to all
the layers in a sequential layer architecture while also incorporating the information learned by the attention
mechanism. A prerequisite is that the attention head preserves the input format.
Following the residual learning operation, layer normalization is applied to stabilize the learning process Ba
et al. (2016) according to
LayerNorm :=z−E(z)/radicalbig
Var(z) +ϵ
wherezis the output of the previous layer, E(z)is the mean value of all the values of the output of the
previous layer (mean over the elements of z) andVar(z)is the corresponding variance. Since the square root
is not differentiable at 0, a small constant ϵ>0keeps the numerical implementation stable in case of a small
variance of z. Moreover, the constant ϵavoids division by zero errors. More details about the implementation
can be found under https://pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html . Due to
its construction, the normalization is done for each element of the batch.
We remark that for our implementation, the normalization is applied over the embedding dimension ( C)
separately for each token of the input ( Tdimension), meaning that z∈RC. This is reasonable since the
feed forward networks (explained in Subsection F.5) are applied over the d_model ( C) on each element of
the batch (B) and input length ( T).
F.5 Feed forward network (FFN)
After the normalization step of the attention head’s residual learning, each token’s representation is passed
through a feed-forward neural network (FFN). Such an FFN consists of two linear transformations separated
by a non-linear activation function g:Rm×n→Rm×n,m,n∈N,z∝⇕⊣√∫⊔≀→g(z), such as ReLU (Rectified Linear
Unit;g= max) according to
FFN (x(b,t,·)) =g(x(b,t,·)W1+b1)W2+b2∈RC
for eachb∈{1,...,B}andt∈{1,...,T}wherex∈RB×T×Cis the output from the previous operation in
the architecture, W1∈RC×dff,dff∈N, in our implementation dff= 4C,W2∈Rdff×Candb1∈Rdff.
Furthermore, x(b,t,·)W1∈Rdff, which is the same bias for each tin contrast to b1∈RT×dffwhere
52Under review as submission to TMLR
for eachtthere is another bias, and b2∈RCare learnable parameters. These operations are applied
by Pytorch’s linear layer https://pytorch.org/docs/stable/generated/torch.nn.Linear.html . The
activation function gintroduces non-linearity to the model, enabling it to learn non-linear patterns from the
data. In the transformer architecture, an FFN is also followed by residual learning and layer normalization
as described above in Subsection F.4.
F.6 Masking
Looking at (Vaswani et al., 2017, Figure 1), the masking is one of the essential building blocks located within
the decoder (explained in Subsection F.7).
Themaskingofvaluesoftheattentionweights Θhasthepurposesofforcingattentionbetweentokenstozero,
meaning not allowing them to interact or to extract information from the interaction. Due to the iterative
application of the transformer for text generation, we would like to force the attention mechanism that a
token only considers tokens backwards in time (that come earlier in a sentence). This backward orientation
helps to generate representations of tokens that collect information from tokens that are already there and
prevents generating representations that make use of tokens that come after that token in a sentence. By
the procedure of masking, the representations of tokens are more unified independent of the input length.
As an example: "I am hungry and thus I go to a restaurant." Although probably "hungry" should get a
lot of attention with "restaurant" without masking, in an iterative application of the transformer, the word
"hungry" in "I am hungry and thus I go" would not be useful since its most attention was on restaurant that is
not there yet. However, with masking we force the transformer to find embeddings and representations such
that the word "hungry" gets a useful representation to predict the next token during learning, independent
if the input is "I am hungry and thus I go to a restaurant." or "I am hungry and thus I go".
A different interpretation of the masking can be causality in a use case where the sequence of events is of
importance forcing attention only to historic events.
We implement the masking effecting only backwards interaction by a lower triangular mask M∈RT×T. This
matrix is applied to the attention weights Θgenerating masked attention weights. The tokens of the input
are counted in the second dimension of the tensor Θwhere the third dimension accounts for the dimension of
the current vector representation ( TorCdepending on the current representation). Consequently, the lower
triangular matrix (1 on the diagonal and below and 0 above), allows token 1 to have a non-zero attention
only with token 1, token 2 can interact with token 2 and token 1 and so on until token T.
Subsequently, for each b∈{1,...,B}, the entries of the attention weight tensor Θ(b,:,:)are replaced by−∞
whereMequals zero. The attention tensor Θis thus transformed into the masked attention weight tensor
ΘM. The−∞forces the corresponding Softmax calculation to zero in the corresponding positions, meaning
that the corresponding token does not pay attention to the corresponding other tokens.
F.7 Encoder and decoder
In a transformer architecture, there are typically two main components. This is the encoder and the decoder.
Next, we explain both components according to (Vaswani et al., 2017, Figure 1).
Usually each layer in the encoder consists of an attention head followed by a residual learning and normaliza-
tion, which is the input into a two linear transformation separated by a non-linear activation function, also
followed by a residual learning and normalization. For the decoder, a layer consists of a masked attention
unit (self-attention), followed by residual learning and layer normalization, followed by an attention unit
where key and values are calculated from the corresponding encoder layer (cross-attention). The rest of the
layer is according to an encoder layer. The repetition of layers of encoder and decoder is the main building
block for the transformer.
The encoder processes the input sequence. These are the text input or for time series prediction the historic
time series (the time series itself or other time series of features) generating a vector representation that
53Under review as submission to TMLR
captures the contextual information of each token, which is meant also for the time series case as discussed
in Subsection F.1.
The decoder, on the other hand, takes the encoded representations and generates an output sequence. It
also consists of multiple layers, each containing self-attention mechanisms and cross-attention mechanisms.
The self-attention mechanisms help the decoder focus on different parts of its input sequence, while the
cross-attention mechanisms allow it to incorporate information from the encoder’s output.
For the case of generating iteratively the next token for text generation, the prediction target is typically
the next token in a sequence. Since for the text generation, several predicted tokens are required, the input
of the decoder grows by the predicted token after each iteration. For inference the next token is predicted.
Also during the training, the model is trained to predict the next token given the previous tokens in the
input sequence. The number of input tokens for the decoder is given by L∈N. The input to the encoder
can be passed to the input of the decoder. If tokens are iteratively generated, the number Lis supposed
to be bigger than Tin such cases, where Tis the input length of the encoder. If the iterative output of
the decoder becomes longer than a maximum size ˜L∈Nfor the decoder’s input, which can exist due to
limitation on the hardware to calculate attention for such an input length between each token, then only
the latest ˜Ltokens are used as an input for the decoder. If the sequence is shorter, corresponding positions
are masked out as explained in Subsection F.6. For translating, input language of the encoder’s input can
be different to the language of the decoder’s output/input. In such a case, the encoder’s input may not be
passed to the decoder’s input and the input of the decoder is iteratively generated by several applications of
the transformer.
In any case, the output of the decoder x∈RB×L×Cis transformed by a linear map ¯W:C→Rdzwith bias
¯b∈Rdzsuch that the last dimension fits the number of available tokens from a dictionary according to
¯x(b,i,:):=x(b,i,:)¯W+¯b∈Rdz
for eachb∈{1,...,B}andi∈{1,...,L}. Then, the Softmax function is applied to the last slice Lof the
tensor ¯xaccording to
Softmax :{1,...,B}×{ 1,...,dz}→R,(b,s)∝⇕⊣√∫⊔≀→Softmax(b,s):=e¯xb,L,s
/summationtextdz
l=1e¯xb,L,l
to obtain a probability over all possible tokens to choose the most likely token as the following token for each
b∈{1,...,B}. To include some variety on choosing the next token, we can disturb this distribution for the
next token (e.g., introducing a temperature parameter) a bit such that also tokens become the most likely
one that are close to the most likely token according to the undisturbed distribution over the tokens.
For time series forecasting tasks, the prediction target may vary depending on the application. It could be
the next value in the time series sequence, multiple future values, or even a binary classification indicating
whether certain conditions will be met in the future. The basic concept is that a linear transformation
˜W:C→E,E∈N, with a bias ˜b∈REtransforms the output of the decoder to the output format that
corresponds to what is to predict, like the number of features or the numbers of classes that is then turned
into a probability over classes by a corresponding Softmax function.
In this work, we focus on time series prediction. As discussed in Zhou et al. (2021), it is advantageous to
generate a multistep prediction (which includes a singlestep prediction) not by an iterative application of the
transformer, like explained above, but provide the prediction at once, meaning to provide the prediction of
lengthL∈Nwithasingleapplicationofthetransformer. Asaconsequence, thetrainingisdonewithadirect
multistep loss. The rationale behind generating the prediction at once is to avoid error accumulation within
the multistep ahead time series prediction task. Considering (Liu et al., 2022, Algorithm 4), we define the
input for the decoder by x∈RB×T
2+L×FwhereL∈Nis the number of steps within the multistep prediction
or prediction length, respectively, and F∈Nthe number of features, analogously to the token embedding for
time series prediction tasks described in Subsection F.1. While for the encoder the initialization is the input
sequence, the initialization values for the decoder are as follows. The firstT
2slices of the decoder input x
are filled with the lastT
2slices of the input of the encoder ˜x∈RB×T×Faccording to xb,i,f= ˜xb,T
2+i,ffor all
54Under review as submission to TMLR
b∈{1,...,B},i∈{1,...,T
2},f∈{1,...,F}. The last slices of the decoder are initialized with zeros according
toxb,i,f= 0for allb∈{1,...,B},i∈{T
2+ 1,...,T
2+L},f∈{1,...,F}. This representation is embedded,
see Subsection F.1, and processed as shown in (Vaswani et al., 2017, Figure 1) by a number of layers within
the transformer. The output of the decoder, again denoted with x∈RB×T
2+L×C, is transformed by a linear
mapping according to
P(b,i,:):=x(b,i,:)˜W+˜b∈RE
for eachb∈{1,...,B}andi∈{1,...,T
2+L}where ˜W∈RC×E,˜b∈REandP∈RB×T
2+L×E. In our
application, where we predict the time series from its history, F=E= 1. The output after the linear
transformation represents the L-step prediction and is given by
P(b,i,e ) for alli∈{T
2+ 1,...,T
2+L}
for each element of the batch b∈{1,...,B}and dimension e∈{1,...,E}. Based on the output, loss functions
are calculated with respect to the corresponding ground truth.
G Architecture for multilayer perceptrons for time series prediction
In this section, we describe the multilayer perceptron (MLP) architecture that we use for the time series
prediction in this work. There is evidence that also MLPs are a very powerful model to predict time series
Zeng et al. (2023).
Iteratively, an input tensor x∈RB×F×TwithB∈Nas the batch size, T∈Nas the length of the historic
input of the time series for the prediction and F∈Nas the number of features is transformed to the
output tensor y∈RB×F×LwhereL∈Nis the length of the multistep prediction, which includes singlestep
prediction where L= 1. In between there can be several hidden layers. All layers have the following
structure taking an input tensor zd−1∈RB×F×Ndwith a certain number of nodes ("neurons") Nd∈Nwhere
d∈{1,...,n},n∈Nis the number of layers, N1=T,Nn+1=Landz0:=x. The layer dis defined by the
function given as follows
Md:RNd→RNd+1, zd−1(b,f,:)∝⇕⊣√∫⊔≀→Md(zd−1(b,f,:)):=gd(zd−1(b,f,:)Wd+bd)
for eachb∈{1,...,B}andf∈{1,...,F}wheregd:RF×Nd+1is a pointwise applied non-linear activation
function for each d∈{1,...,n}, like the ReLu function where gd= max,zd−1∈RB×F×Ndis the output from
layerd−1and the input for layer d,Wd∈RNd×Nd+1andbd∈RNd+1. The operation zd−1(b,f,:)Wdis the
common matrix-vector multiplication for any d∈{1,...,n},b∈{1,...,B},f∈{1,...,F}. We remark that gd
can be but does not have to be a different function for each layer. For each b∈{1,...,B}andf∈{1,...,F},
we have that y(b,f,:):=Mn(zn−1(b,f,:). In this formulation, all weights in each layer dare the same for all
features. This is the implementation we provide and is used in Zeng et al. (2023). However, in the examples
within the present work, we have F= 1.
To implement a version that has different weights for each feature in each layer d, we just need to reformulate
the input of the layers by zd−1,f(b,:) =zd−1(b,f,:)∈RNdfor allf∈{1,...,F}. Accordingly, the definition
of the layers looks like
Md,f:RNd→RNd+1, zd−1,f(b,:)∝⇕⊣√∫⊔≀→Md,f(zd−1,f(b,:)):=g(zd−1,f(b,:)Wd,f+bd,f)
whereapplyingthedefinitionsseparatelytoeachfeatureleadsto FdifferentMLPswheretheweightmatrices
and bias can differ per feature.
In order to introduce cross learning where information from one feature can influence the prediction of other
features, we need to reshape the three dimensional tensor (B,F,Nd)to(B,FNd)for some layers where a
corresponding weight matrix W∗
d:FNd→FNd+1can mix information from different features.
In a multi layer architecture, we can combine cross learning and learning per feature in different layers
assemblingtheminonemodelbyreshapingoutputsinthecorrespondingformatsfrom (B,F,Nd)to(B,FNd)
or(B,FNd)to(B,F,Nd)after a layer before the next one depending on the learning type to change.
55Under review as submission to TMLR
With Pytorch such layers are implemented with
nn.Linear (n,m,bias =True )
wheren∈Nis the dimension of the input and m∈Nis the dimension of the output. The biasparameter
Trueadds a bias with non-zero values and the parameter Falsefixes the values of the bias to zero.
56