Published in Transactions on Machine Learning Research (07/2024)
Multi-Fidelity Active Learning with GFlowNets
Alex Hernandez-Garcia∗alex.hernandez-garcia@mila.quebec
Mila, Université de Montréal
Nikita Saxena*†nikitasaxena0209@gmail.com
Birla Institute of Technology and Science, Pilani
Moksh Jain moksh.jain@mila.quebec
Mila, Université de Montréal
Cheng-Hao Liu chenghao.liu@mail.mcgill.ca
Mila, McGill University
Yoshua Bengio yoshua.bengio@mila.quebec
Mila, Université de Montréal, CIFAR Fellow, IVADO
Reviewed on OpenReview: https: // openreview. net/ forum? id= dLaazW9zuF
Abstract
In the last decades, the capacity to generate large amounts of data in science and engineer-
ing applications has been growing steadily. Meanwhile, machine learning has progressed to
become a suitable tool to process and utilise the available data. Nonetheless, many rele-
vant scientific and engineering problems present challenges where current machine learning
methods cannot yet efficiently leverage the available data and resources. For example, in sci-
entific discovery, we are often faced with the problem of exploring very large, structured and
high-dimensional spaces. Moreover, the high fidelity, black-box objective function is often
very expensive to evaluate. Progress in machine learning methods that can efficiently tackle
such challenges would help accelerate currently crucial areas such as drug and materials dis-
covery. In this paper, we propose a multi-fidelity active learning algorithm with GFlowNets
as a sampler, to efficiently discover diverse, high-scoring candidates where multiple approx-
imations of the black-box function are available at lower fidelity and cost. Our evaluation
on molecular discovery tasks shows that multi-fidelity active learning with GFlowNets can
discover high-scoring candidates at a fraction of the budget of its single-fidelity counterpart
while maintaining diversity, unlike RL-based alternatives. These results open new avenues
for multi-fidelity active learning to accelerate scientific discovery and engineering design.
1 Introduction
To tackle the most pressing challenges for humanity, such as the climate crisis and the threat of pandemics
or antibiotic resistance, there is a growing need for new scientific discoveries. By way of illustration, new
materials can play an important role in improving the efficiency of energy production and storage; and
reducing the costs and duration of drug discovery cycles has the potential to effectively and rapidly mitigate
∗Equivalent Contribution
†Work done during an internship at Mila
1Published in Transactions on Machine Learning Research (07/2024)
fM
λM
fM−1
λM−1
Oracles
λm: cost
f2
λ2
f1
λ1
DataD=D ∪ { (xi,fmi(xi),mi)}1≤i≤B
{(xi,mi)}1≤i≤B Queries
Multi-fid. surrogate
p(fm|x,m,D)
GFlowNet
train
(x,m)α(x,m ) RewardAcquisition function
SampleNTopB
Figure1: Illustrationofmulti-fidelityactivelearningwithGFlowNets(Algorithm1). Givenasetof Moracles
f1,...,fM(center left) with varying fidelities and costs λ<...<λ M, respectively, we can construct a data
setD(top left) with annotations from the oracles. With this data, we fit a multi-fidelity surrogate (center),
modelling the posterior p(fm(x)|x,m,D). The surrogate is used to evaluate a multi-fidelity acquisition
function—max-value entropy search in our experiments— which makes the reward to train a GFlowNet
(right). The GFlowNet is trained to sample both an object xand the fidelity mproportionally to this
reward. Once the GFlowNet is trained, we sample Ntuples (x,m)and select the top Baccording to the
acquisition function (bottom left). Finally, we annotate each new candidate with the selected oracle, add
them to the data set and repeat the process until the budget is exhausted.
the consequences of new diseases. In recent years, researchers in materials science, biochemistry and other
fields have increasingly adopted machine learning as a tool since it holds the promise to drastically accelerate
scientific discovery (Butler et al., 2018; Zitnick et al., 2020; Bashir et al., 2021; Das et al., 2021).
Although machine learning has already made a positive impact in scientific discovery applications (Stokes
et al., 2020; Jumper et al., 2021), unleashing its full potential demands improving the current algorithms
(Agrawal & Choudhary, 2016). For example, typical tasks in potentially impactful applications in materials
and drug discovery require exploring combinatorially large, structured and high-dimensional spaces (Bohacek
et al., 1996; Polishchuk et al., 2013), where only small, noisy data sets are available. Furthermore, obtaining
new annotations computationally or experimentally is often very expensive. Such scenarios present serious
challenges even for the most advanced machine learning methods currently available.
In the search for a useful discovery, we typically define a quantitative proxy for usefulness, which we can
view as a black-box function. One promising avenue for improvement is developing methods that more
efficiently leverage the availability of multiple approximations of the target black-box function at lower
fidelity but much lower cost than the highest fidelity oracle (Chen et al., 2021; Fare et al., 2022). For
example, a standard tool to characterise the properties of materials and molecules is quantum mechanics
simulations such as Density Functional Theory (DFT) (Parr, 1980; Sholl & Steckel, 2022). However, DFT
is computationally too expensive for high-throughput exploration of large search spaces. Thus, large-scale
exploration can only be achieved through cheaper but less accurate oracles. Nonetheless, solely relying on
low-fidelity approximations is clearly suboptimal. Ideally, such “needle-in-a-haystack” problems would be
best tackled by methods that can efficiently and adaptively distribute the available computational budget
between the multiple oracles depending on the already acquired information.
Another challenge is that even the highest fidelity oracles are often underspecified with respect to the
actual, relevant, downstream applications. This underspecification problem can be mitigated by finding
multiple candidate solutions (Jain et al., 2023a). However, most current machine learning methods used
2Published in Transactions on Machine Learning Research (07/2024)
in scientific discovery problems, such as Bayesian optimisation (BO, Song et al., 2018; Garnett, 2023) and
reinforcement learning (RL, Angermueller et al., 2020), are designed for global optimisation of the target
function. Therefore, it is imperative to develop methods that not only find the global optimum, but also
discover sets of diverse, high-scoring candidates.
Recently, generativeflownetworks(GFlowNetsorGFN,Bengioetal.,2021a)havedemonstratedtheirability
to find diverse candidates through discrete probabilistic modelling, with particularly promising results when
used in an active learning loop (Jain et al., 2022). In this paper, we propose a multi-fidelity active learning
algorithm enhanced with these capabilities of GFlowNets. Our contributions can be summarized as follows:
•We introduce a multi-fidelity active learning algorithm designed for combinatorially large, structured
and high-dimensional spaces.
•We propose an extension of GFlowNets for this multi-fidelity setting, to sample both candidates and
oracle indices, proportionally to a given acquisition function.
•We conduct a comprehensive empirical evaluation across four scientific discovery tasks and demon-
strate that multi-fidelity active learning with GFlowNets
–discovers high-scoring samples with reduced computational costs compared to its single-fidelity
counterpart, and
–identifiesmultiplemodesofthetargetfunction,unlikemethodsrelyingonreinforcementlearning
or standard Bayesian optimisation, thereby facilitating diverse sampling.
2 Related Work
Our work can be framed within the broad field of active learning (AL), a class of machine learning methods
whose goal is to learn an efficient data sampling scheme to accelerate training (Settles, 2009). For the bulk
of the literature in AL, the goal is to train an accurate model h(x)of an unknown target function f(x),
as in classical supervised learning. However, in certain scientific discovery problems, which motivate our
work, a desirable goal is often instead to discover multiple, diverse candidates xwith high values of f(x), as
discussed in Section 1.
Our work is also closely connected to Bayesian optimisation (BO, Garnett, 2023; Snoek et al., 2015), which
aims at optimising a black-box objective function f(x)that is expensive to evaluate. In contrast to the
problems we address in this paper, standard BO typically considers continuous domains and works best
in relatively low-dimensional spaces (Frazier, 2018). Nonetheless, in recent years, approaches for BO with
structured data (Deshwal & Doppa, 2021; Papenmeier et al., 2023) and high-dimensional domains (Grosnit
et al., 2021) have been proposed in the literature. The main difference between standard BO and the problem
we tackle in this paper is that we are interested in finding multiple, diverse samples with high value of fand
not only the optimum. Recent work by Maus et al. (2022) has proposed a variant of traditional BO to find
diverse solutions.
This goal, as well as the discrete nature of the search space, is shared with active search (Garnett et al.,
2012), a variant of active learning in which the task is to efficiently find multiple samples of a valuable
(binary) class from a discrete domain X. This objective was already considered in the early 2000s by
Warmuth et al. (2001) for drug discovery, and more formally analysed in later work (Jiang et al., 2017;
2019). Another recent research area in stochastic optimisation that considers diversity is so-called Quality-
Diversity (Chatzilygeroudis et al., 2021), which typically uses evolutionary algorithms that search in a latent
space. These and other problems such as multi-armed bandits (Robbins, 1952) and the general framework
of experimental design (Chaloner & Verdinelli, 1995) all share the objective of optimising or exploring an
expensive black-box function. Formal connections between some of these areas have been established in the
literature (Srinivas et al., 2010; Foster, 2021; Jain et al., 2023a; Fiore et al., 2023).
Multi-fidelity methods have been proposed in most of these areas of research. An early survey on multi-
fidelity methods for Bayesian optimisation was compiled by Peherstorfer et al. (2018), and research on the
subject has continued since with the proposal of specific acquisition functions (Takeno et al., 2020) and the
3Published in Transactions on Machine Learning Research (07/2024)
use of deep neural networks to improve the modelling (Li et al., 2020). Recently, works on multi-fidelity
active search have also appeared in the literature (Nguyen et al., 2021), but interestingly, the literature on
multi-fidelity active learning (Li et al., 2022a) is scarcer. Finally, while multi-fidelity methods have started to
be applied in scientific discovery problems (Chen et al., 2021; Fare et al., 2022) the literature is still limited
probably because most approaches cannot tackle the specifics of scientific discovery, such as the need for
diverse samples. Here, we aim at addressing this need with the use of GFlowNets (Bengio et al., 2021a; Jain
et al., 2023b) for multi-fidelity active learning.
3 Method
In this section, we first briefly introduce the necessary background on GFlowNets and active learning. Then,
we describe the proposed algorithm for multi-fidelity active learning with GFlowNets.
3.1 Background
GFlowNets Generative flow networks (GFN; Bengio et al., 2021a;b) are amortised samplers originally
designed for sampling from discrete high-dimensional distributions. Given a space of compositional objects
Xand a non-negative reward function R(x), GFlowNets are designed to learn a stochastic policy π(x)that
generatesx∈Xwith aprobability proportional to the reward, that is π(x)∝R(x). This distinctive property
induces sampling of diverse, high-reward objects, which is a desirable property for scientific discovery, among
other applications (Jain et al., 2023a).
A key property of GFlowNets is that objects x∈Xare constructed sequentially by sampling transitions
st→st+1∈Abetween partially constructed objects (states) s∈S, which includes a unique empty state s0.
The stochastic forward policy is typically parameterised by a neural network PF(st+1|st;θ), whereθdenotes
the learnable parameters, which models the distribution over transitions from the current state stto the
next statest+1. The backward transitions are parameterised too and denoted PB(st|st+1;θ). Objectsxare
generated by the sequential application of PF, forming trajectories τ= (s0→s1...→x). To learn the
parameters θsuch thatπ(x)∝R(x)we use the trajectory balance learning objective (Malkin et al., 2022)
LTB(τ;θ) =/parenleftbigg
logZθ/producttextn
t=0PF(st+1|st;θ)
R(x)/producttextn
t=1PB(st|st+1;θ)/parenrightbigg2
, (1)
whereZθisatrainableapproximationofthepartitionfunction/summationtext
x∈XR(x). TheGFlowNetlearningobjective
supports training from off-policy trajectories, so during training the trajectories are typically sampled from
a mixture of the current policy with a uniform random policy. The reward can also be tempered to make
the policy focus on the modes (see Appendix C.3).
Active Learning In its simplest formulation, the (single fidelity) active learning problem that we consider
is as follows: we start with an initial data set D={(xi,f(xi))}of samplesx∈Xand their evaluations by an
expensive, black-box objective function (oracle) f:X→R, which we use to train a surrogate model h(x).
A GFlowNet can then be trained to learn a generative policy πθ(x)usingh(x)as reward function, that is
R(x) =h(x). After training, the policy πθ(x)can be used to generate a batch of samples to be evaluated by
the oraclef, add them to the data set and repeat the process a number of active learning rounds.
As an alternative, instead of directly using the surrogate output as the reward, we can instead train a
probabilistic surrogate p(f|D)and use as reward the output of an acquisition function α(x,p(f|D))that
considers the epistemic uncertainty of the surrogate model, as typically done in Bayesian optimisation. This
istheapproachbyJainetal.(2022)withGFlowNet-AL.AnimportantdifferencebetweentraditionalBOand
active learning with GFlowNets is that the latter samples from the acquisition function instead of optimising
it (Jain et al., 2023a). This difference accounts for the capability of active learning with GFlowNets to
discover diverse candidates: if multiple, diverse candidates have high values of the acquisition function,
GFlowNet has the potential to generate them with high probability, whereas standard BO seeks to find the
optimum only.
4Published in Transactions on Machine Learning Research (07/2024)
Whilemuchoftheactivelearningliterature(Settles,2009)hasfocusedonso-called pool-based activelearning,
where the learner selects samples from a pool of unlabelled data, we here consider the scenario of de novo
query synthesis , where samples are selected from the entire object space X. This scenario is particularly
suited for scientific discovery (King et al., 2004; Xue et al., 2016; Yuan et al., 2018; Kusne et al., 2020). The
ultimate goal pursued in active learning applications is also heterogeneous. Often, the goal is the same as
in classical supervised machine learning: to train an accurate (surrogate) model h(x)of the unknown target
functionf(x). In many scientific discovery problems, we are not interested in the surrogate’s accuracy
across the entire input space X, but rather in discovering new, diverse objects with high values of f. We
have reviewed the literature that is connected to our work in Section 2.
3.2 Multi-Fidelity Active Learning
We now consider the following active learning problem with multiple oracles of different fidelities. Our
ultimate goal is to generate a batch of Ksamples{xi}K
i=1∈Xaccording to the following desiderata:
•The samples obtain a high value when evaluated by the objective function f:X→R+.
•The samples are diverse, covering distinct, high-valued regions of f.
Furthermore, we are constrained by a computational budget Λthat limits our capacity to evaluate f. While
fis extremely expensive to evaluate, we have access to a discrete set of approximate functions (oracles)
{fm}1≤m≤M:X →R+, wheremrepresents the fidelity index and each oracle has an associated cost λm
and level of confidence ℓm∈(0,1]. We assume, without loss of generality, that the larger m, the higher the
fidelity or confidence, that λ1< λ 2< ... < λ M<Λand thatℓM= 1. We also assume fM=fbecause,
even though there may exist more accurate oracles, we do not have access to them. This scenario resembles
many practically relevant problems in scientific discovery and motivates our approach: because the objective
functionfMis not a perfect proxy of the true usefulness of objects x, we seek diversity; and because fM
may be expensive to evaluate, we make use of approximate models.
In multi-fidelity active learning—as well as in multi-fidelity Bayesian optimisation—the iterative sampling
scheme consists of not only selecting the next object x(or batch of objects) to evaluate, but also the level
of fidelitym, such that the procedure is cost-effective. Namely, after each active learning round we acquire
triplets (xi,fmi(xi),mi).
Briefly, our algorithm, MF-GFN follows these iterative steps: at each iteration j, we use the currently
available dataDjto train a probabilistic multi-fidelity surrogate model h(x,m). We can use the surrogate to
compute the worth of annotating a candidate xwith the oracle fmvia an acquisition function α(x,m). Next,
we train a GFlowNet with the acquisition function as a reward. Once trained, we sample Ntuples (x,m)and
select the top B, as per the acquisition function. Finally, we annotate each candidate xwith the selected
oraclemand start over with the extended data set. Figure 1 contains a visual illustration of MF-GFN
and more detailed descriptions are provided in Algorithm 1 and in Appendices A and B. Below, we further
describe the surrogate model and the acquisition function, and in Section 3.3 we introduce multi-fidelity
GFlowNets.
SurrogateModel GivenadatasetD, acandidate xandanoracleindex m, wewanttomodeltheposterior
distributionovertheoutputoftheoracle, p(fm(x)|x,m,D). AnaturalmodellingchoiceisGaussianProcesses
(GP, Rasmussen & Williams, 2005), commonly used in Bayesian optimisation. However, in order to better
model structured, high-dimensional data, we use deep kernel learning (Wilson et al., 2016): First, a non-
linear embedding of the inputs z=gω(x)is learnt by a deep neural network with parameters ω. Then, we
use the following multi-fidelity GP kernel:
KMF((x,m),(x′,m′)) =KX(gω(x),gω(x′)) +KM(m,m′)×KXM(gω(x),gω(x′)), (2)
where both KX(z,z′)andKXM(z,z′)are Matérn kernels (with a different lengthscale each) applied to the
latent representations of the inputs from the network and
KM(m,m′) = (1−ℓm)(1−ℓm′)(1 +ℓmℓm′)p
5Published in Transactions on Machine Learning Research (07/2024)
Algorithm 1: MF-GFN: Multi-fidelity active learning with GFlowNets. A graphical summary of this
algorithm is shown in Fig. 1.
Input:{(fm,λm,ℓm)}:Moracles and their corresponding cost and confidence;
D0={(xi,fmi(xi),mi)}: Initial data set;
h(x,m): Multi-fidelity Gaussian Process surrogate model;
α(x,m): Multi-fidelity acquisition function;
R(α(x,m),β): reward function with temperature parameter βto train the GFlowNet;
N: Number of candidates sampled from the GFlowNet;
B: Acquisition batch size of oracles queries;
Λ: Maximum available budget;
K: Number of top-scoring candidates to be evaluated at termination;
Initialisation:D←D 0,Λj←0,j←0
while Λj<Λdo
•Fit surrogate hon data setD;
•Train GFlowNet with reward R(α(x,m),β)to obtain policy πθ(x);
•SampleN≫Btuples (xi,mi)∼πθ;
•Score each tuple using α(x,m)and select the top Btuples with the highest scores;
•Evaluate each tuple with the corresponding oracle to form batch
B←{ (x1,fm1(x1),m1),..., (xB,fmB(xB),mB)};
•Update data setD←D∪B , budget Λj←Λj+/summationtextB
i=1λmiand indexj←j+ 1;
end
Result: Top-K(D), set of K candidates with largest values of the highest-fidelity oracle fM.
is applied over the fidelity confidences, which we set equal to the normalised costs ℓm=λm
λM∈(0,1]for
simplicity. The kernel KMFis known as linear truncated kernel, is implemented in BoTorch (Balandat
et al., 2020) and has been used before in multi-fidelity Bayesian optimisation works, for example by Mikkola
et al. (2023). Additional details are provided in Appendix B. Finally, we would like to note that our multi-
fidelity active learning algorithm is independent of the specific choice of surrogate model.
Acqusition Function Multi-fidelity methods proposed in the Bayesian optimisation literature have
adapted information theory-based acquisition functions (Li et al., 2022a; Wu et al., 2023; Li et al., 2022b).
In our work, we use the multi-fidelity version (Takeno et al., 2020) of max-value entropy search (MES, Wang
& Jegelka, 2017). MES captures the mutual information between the value of candidate xand the maximum
value attained by the objective function, f⋆. The multi-fidelity variant, MF-MES, is designed to select the
candidatexand the fidelity mthat maximise the mutual information between f⋆
Mand the oracle at fidelity
m,fm, weighted by the cost of the oracle λm:
α(x,m) =1
λmI(f⋆
M;fm(x)|Dj). (3)
We chose MES as the acquisition function for our approach because it has been shown to be more efficient
than plain entropy search (Wang & Jegelka, 2017). However, the algorithm is independent of the choice of
acquisition function. Additionally, for efficiency, we adopt the GIBBON approximation of MF-MES, which
has demonstrated good performance in the context of multi-fidelity optimisation (Moss et al., 2021). We
provide further details about the acquisition function and the GIBBON approximation in Appendix B.
3.3 Multi-Fidelity GFlowNets
A multi-fidelity acquisition function can be regarded as a cost-adjusted utility function. Therefore, in order
to carry out a cost-aware search, we seek to sample diverse objects with high value of the acquisition function.
To this purpose, we propose to use a GFlowNet as a generative model by training it to sample the fidelity
min addition to the candidate xitself. In other words, it learns a sampling policy πθ(x,m). Formally, given
a GFlowNet with state and transition spaces SandA, we augment the state space with a new dimension
6Published in Transactions on Machine Learning Research (07/2024)
for the fidelityM′={0,1,2,...,M}(includingm= 0, which corresponds to unset fidelity), such that the
augmented, multi-fidelity state space is SM=S×M′. The set of allowed transitions AMis augmented
such that a fidelity m> 0of a trajectory must be selected once, and only once, from any intermediate state.
Intuitively, allowing the selection of the fidelity at any step in the trajectory should give flexibility for better
generalisation. At the end, complete trajectories are the concatenation of an object xand the fidelity m> 0,
that is (x,m)∈XM=X×M.
In summary, the proposed approach learns a policy that jointly samples objects in a possibly very large,
structured and high-dimensional space, together with the level of fidelity. Since we use a multi-fidelity
acquisition function as reward function to train the multi-fidelity GFlowNet, the learnt sampling policy will
be approximately proportional to the acquisition function, hence providing diversity. As in the single-fidelity
case, if multiple, diverse tuples (x,m)obtain high values of the acquisition function α, the GFlowNet can
potentially sample them with high probability. In practice, we rescale the acquisition function so as to
further increase the relative rewards of high values of α, as detailed in Appendix C.3.
4 Empirical Evaluation
In this section, we present empirical evaluations of multi-fidelity active learning with GFlowNets. Through
our experiments, we aim to answer the following questions:
•Can our multi-fidelity active learning approach find high-scoring, diverse samples at lower cost than
with a single-fidelity oracle?
•Does MF-GFN, which samples objects and fidelities (x,m), provide any advantage over sampling
onlyxand selecting mrandomly?
4.1 Metrics
As discussed in Section 3.2, our goal is to sample diverse objects with high scores according to a reward
function. Following Gao et al. (2022) and Jain et al. (2022), we here consider a pair of metrics that capture
both the scores and the diversity of the final batch of candidates. These metrics are computed from the set
of bestKcandidates, obtained out of the full data set Djat iteration j. We refer to this set as top- K(Dj),
which consists of the Kcandidates with the largest values of the objective function (highest-fidelity oracle)
fM. The two metrics we consider in this section are:
•Mean top-K score : mean score, per the highest fidelity oracle fM, of the top- Ksamples.
•Top-K diversity : mean pairwise distance within the top- Ksamples.
Additional details and formal definitions are provided in Appendix D. We report the metrics averaged over 3
experiments with different random seeds, as well as the 95 % confidence intervals of the mean top- Kscores
estimated via bootstrapping.
Since here we are interested in the cost effectiveness of the active learning process, we evaluate the above
metrics as a function of the cost accumulated in querying the oracles. It is important to note that multi-
fidelity approaches are notaimed at achieving bettermean top-Kscores than a single-fidelity active learning
counterpart, but rather the same mean top-Kscores but with a smaller budget .
4.2 Baselines
In order to evaluate our approach, and to shed light on the questions stated above, we consider the following
baselines:
GFlowNetwithhighestfidelity(SF-GFN) GFlowNet-basedactivelearning(GFlowNet-AL)asinJain
et al. (2022) with the highest fidelity oracle, to establish a benchmark for performance without considering
the cost-accuracy trade-offs.
7Published in Transactions on Machine Learning Research (07/2024)
0.2 0.4 0.6 0.8 1.0
Fraction of total SF-GFN budget46810121416Mean Top-100 energySF-GFN
Random
Rand. fid. GFNMF-PPO
MF-GFN
0.20 0.25 0.30 0.35 0.40 0.45 0.50Diversity
(a) DNA aptamers task
103
102
101
100
Fraction of total SF-GFN budget (log)0.50.60.70.8Mean Top-100 energy
0.2 0.3 0.4 0.5 0.6 0.7 0.8Diversity (b) Anti-microbial peptides (AMP) task
Figure 2: Results on the DNA aptamers and AMP tasks. The curves indicate the mean energy fMwithin the
top-100 samples computed at the end of each active learning round and plotted as a function of the budget
used. The colour of the round markers indicates the diversity within the batch (darker colour indicating
higher diversity), computed as the average pairwise sequence identity distance (see Appendix D). In both
the DNA and the AMP tasks, MF-GFN outperforms all baselines in terms of cost efficiency, while obtaining
great diversity in the final batch of top- Kcandidates.
GFlowNet with random fidelities (Random fid. GFN) Variant of SF-GFN where the candidates are
generated with the GFlowNet but the multi-fidelity acquisition function is evaluated with random fidelities
sampled from a uniform distribution. This allows us to investigate the contribution of learning to sample
the fidelity for each object with GFlowNets.
Random candidates and fidelities ranked by the acquisition function (Random) Quasi-random
approach where both candidates and fidelities are randomly sampled from a uniform distribution. We first
sampleNrandom (x,m)pairs, then select the top Baccording to the acquisition function. This baseline is
typically competitive due to the value provided by the acquisition.
Multi-fidelity PPO (MF-PPO) Instantiation of multi-fidelity Bayesian optimisation where the acquisi-
tion function is optimised using proximal policy optimisation (PPO, Schulman et al., 2017). Unlike with the
other baselines, we include an initialisation of n/3steps where nis the maximum number of steps allowed.
This is to help exploration and diversity, since without it PPO tends to collapse to generation of very similar
candidates.
4.3 Benchmark Tasks
As a proof of concept, we perform experiments on two low-dimensional synthetic functions: Branin and
Hartmann, widely used in the multi-fidelity Bayesian optimisation literature (Perdikaris et al., 2017; Song
etal.,2018;Kandasamyetal.,2019;Lietal.,2020;Folchetal.,2023). ThesetasksshowthatMF-GFNisable
to obtain results comparable to other multi-fidelity BO methods. We provide these results in Appendix C.4.
Nonetheless, the motivation of our work is the challenges posed by large, structured and high-dimensional
problems common in scientific discovery. Therefore, in order to assess the performance of MF-GFN on such
scenarios, we evaluate it on more complex tasks of practical scientific relevance. We present results on a
variety of discovery domains: DNA aptamers (Section 4.3.1), anti-microbial peptides (Section 4.3.2) and
small molecules (Section 4.3.3).
8Published in Transactions on Machine Learning Research (07/2024)
4.3.1 DNA Aptamers
DNA aptamers are single-stranded nucleotide sequences of nucleobases A, C, T and G, with multiple applica-
tions in polymer design due to their specificity and affinity as sensors in crowded biochemical environments
(Zhou et al., 2017; Corey et al., 2022; Yesselman et al., 2019; Kilgour et al., 2021). The objective is to
maximize the (negative) free energy of the secondary structure of DNA sequences. This free energy can be
seen as a proxy of the stability of the sequences. We compute the diversity as one minus the mean pairwise
sequence identity among a set of DNA sequences (see Appendix D for the details).
Setting In our experiments, we consider fixed-length sequences of 30 bases and design a GFlowNet envi-
ronment where the action space Aconsists of the choice of base to append to the sequence, starting from an
empty sequence. This yields a design space of size |X|= 430(ignoring the selection of fidelity in MF-GFN).
Further details about the task are discussed in Appendix C.5.1.
Oracles NUPACK (Zadeh et al., 2011), a nucleic acid structure analysis software, is used as the highest
fidelity oracle, fM. As a low fidelity oracle, we trained a transformer model on 1 million randomly sampled
sequences annotated with fM, and assigned it a cost 100×smaller than the highest-fidelity oracle. The cost
difference is selected to simulate practical scenarios where wet lab experiments take hours for evaluation,
while cheap online simulations take a few minutes.
Results As presented in Fig. 2a, MF-GFN reaches the best mean top- Kenergy achieved by its single-
fidelity counterpart with just about 25 %of the budget. It is also more efficient than GFlowNet with random
fidelities and MF-PPO. Crucially, we also see that MF-GFN maintains a high level of diversity (0.32), even
after converging to the top-K scores. On the contrary, MF-PPO (0.20) is not able to discover diverse samples,
as is expected based on prior work (Jain et al., 2022).
4.3.2 Antimicrobial Peptides
Antimicrobial peptides are short protein sequences which possess antimicrobial properties. As proteins, these
are sequences of amino-acids—a vocabulary of size 20 along with a special stop token. The aim is to identify
sequences with a high antimicrobial activity, as measured by a model trained on DBAASP (Pirtskhalava
et al., 2021). The diversity calculation is equivalent to that of DNA.
Setting We consider variable-length protein sequences with up to 50 residues. Analogous to DNA, if we
ignore the fidelity, this yields a design space of size |X|>2050.
Oracles We construct a three-oracle setup by training deep learning models with different capacities on
exclusive subsets of data points. We simulated a setup wherein the two lower fidelity oracles are trained on
specific subgroups of the peptides. Similar to the DNA experiment, the lower-fidelity oracles had both a cost
100×less than the highest fidelity oracle. Additional details can be found in Appendix C.5.2.
Results Fig. 2b indicates that in this task MF-GFN obtains even greater advantage over all other baselines
in terms of cost-efficiency. It reaches the same maximum mean top- Kscore as the random baselines with 10×
less budget and almost 100×less budget than SF-GFN. In this task, MF-PPO did not achieve comparable
results. Crucially, the diversity of the final batch found by MF-GFN stayed high (0.87).
4.3.3 Small Molecules
Molecules are clouds of interacting atoms described by a set of quantum mechanical properties. These
properties dictate their chemical behaviours and applications. To demonstrate the capability of MF-GFN in
the setting of quantum chemistry, we consider two tasks in molecular electronic potentials: maximisation of
the (negative) adiabatic ionisation potential (IP) and of the adiabatic electron affinity (EA). These electronic
potentials dictate the molecular redox chemistry, and are crucial in organic semiconductors, photoredox
catalysis and organometallic synthesis. In this task, the diversity measure is the average pairwise Tanimoto
distance among the top- Kscoring molecules (Bajusz et al., 2015), as detailed in Appendix D.
9Published in Transactions on Machine Learning Research (07/2024)
0.2 0.4 0.6 0.8 1.0
Fraction of total SF-GFN budget9
8
7
6
5
4
Mean Top-100 energy [eV]SF-GFN
Random
Rand. fid. GFNMF-PPO
MF-GFN
0.70 0.75 0.80 0.85 0.90 0.95Diversity
(a) Molecules ionisation potential (IP) task
0.2 0.4 0.6 0.8 1.0
Fraction of total SF-GFN budget2345Mean Top-100 energy [eV]SF-GFN
Random
Rand. fid. GFNMF-PPO
MF-GFN
0.75 0.80 0.85 0.90 0.95Diversity (b) Molecules electron affinity (EA) task
Figure 3: Results on the molecular discovery tasks: (a) ionisation potential (IP), (b) electron affinity (EA).
These visualisations are analogous to those in Fig. 2. The diversity of molecules is computed as the average
pairwise Tanimoto distance (see Appendix D). Results generally show MF-GFN’s faster convergence in
discovering diverse molecules with desirable properties.
Setting We designed the GFlowNet state space by considering variable length sequences of SELFIES
tokens (Krenn et al., 2020) to represent molecules, with a vocabulary size of 26. The maximum length was
64, resulting in a design space of |X|>2664.
Oracles Numerous approximations of these quantum mechanical properties have been developed with dif-
ferent methods at different fidelities, with the famous example of Jacob’s ladder in density functional theory
(Perdew & Schmidt, 2001). We employed three oracles that correlate with experimental results as approxi-
mations of the scoring function, by using various levels of geometry optimisation to obtain approximations
to the adiabatic geometries. The calculation of IP or EA was carried out with the semi-empirical quantum
chemistry method XTB (Neugebauer et al., 2020). These three oracles had costs of 1, 3 and 7 (respectively),
proportional to their computational running demands. See Appendix C.5.3 for further details.
Results The realistic configuration and practical relevance of these tasks allow us to draw stronger conclu-
sionsabouttheusefulnessofmulti-fidelityactivelearningwithGFlowNetsinscientificdiscoveryapplications.
As in the other tasks evaluated, we here also found MF-GFN to achieve better cost efficiency at finding high-
score top-Kmolecules (Fig. 3), especially for ionisation potentials (Fig. 3a). By clustering the generated
molecules, we find that MF-GFN captures as many modes as random generation, far exceeding that of MF-
PPO. Indeed, while MF-PPO is able to quickly optimise the target function in the task of electron affinity
(Fig. 3b), all generated molecules were from a few clusters (low diversity), which is of much less utility for
chemists.
4.4 Ablation studies and additional results
Besides the main experiments presented above, we carried out additional experiments to gain further insights
aboutMF-GFNandstudytheinfluenceofitsvariouscomponents. WeprovidedetailedresultsinAppendixE
and summarise the main conclusions here:
•Analysing the results in terms of the top- Kdiversesamples confirms that the GFlowNet-based
approaches are able to jointly optimize scores and diversity, while RL approaches trade diversity for
high scores (Appendix E.1).
10Published in Transactions on Machine Learning Research (07/2024)
•As is expected, the advantage of MF-GFN over its single-fidelity counterpart decreases as the cost
of the lower fidelity oracles increases. Nonetheless, even with a cost ratio of 1 : 2in the DNA task,
MF-GFN still outperforms all other methods (Appendix E.2).
•The same conclusions hold for various values of the final candidate set size, K∈{50,100,200}
(Appendix E.3).
•Similar results to the ones presented above were obtained on proof-of-concept experiments with
the synthetic functions Branin and Hartmann, common in the multi-fidelity Bayesian optimisation
literature (Appendix C.4).
•We expect MF-GFN to query cheap oracles to prune the input space and costly oracles for high-
reward candidates. We validate this through a visualisation using the two-dimensional Branin func-
tion (Appendix E.5).
•A slightly variation of the baseline Rand. fid. GFN where the fidelities are sampled from a distribu-
tion proportional to the cost indicates that learning the fidelity with MF-GFN is still advantageous
(Appendix E.6).
5 Conclusions, Limitations and Future Work
In this paper, we have presented MF-GFN, a multi-fidelity active learning algorithm that leverages
GFlowNets to achieve exploration with diversity for scientific discovery applications. MF-GFN samples
candidates as well as the fidelity at which the candidate is to be evaluated, when multiple oracles are avail-
able with varying fidelities and costs. We evaluated MF-GFN on benchmark tasks of practical relevance,
such as DNA aptamer generation, antimicrobial peptide and small molecule design. Through comparisons
with previously proposed methods as well as with variants of our method designed to understand the con-
tributions of different components, we conclude that multi-fidelity active learning with GFlowNets not only
outperforms its single-fidelity active learning counterpart in terms of cost effectiveness and diversity of sam-
pled candidates, but it also offers an advantage over other multi-fidelity methods due to its ability to learn
a stochastic policy to jointly sample objects and the fidelity of the oracle.
Limitations and Future Work Aside from the molecular modelling tasks, our empirical evaluations in
this paper involved simulated oracles with manually selected costs. Future work should evaluate MF-GFN
with more practical oracles and costs that reflect their computational or financial demands. As a first
approach to multi-fidelity active learning with GFlowNets, the proposed algorithm may be improved and
adapted to specific applications in different ways. For example, instead of selecting the top- Bcandidates
at the end of each active learning round, one could adopt stochastic batch acquisition strategies (Kirsch
et al., 2023). If the oracle costs reflect run-time, as is the case in many scientific discovery problems, then it
would be interesting to consider strategies that would not block the exploration while waiting for the most
expensive oracle. Furthermore, a promising avenue that we do not study in this paper is the application
of MF-GFN in more complex, structured design spaces, such as hybrid (discrete and continuous) domains
(Lahlou et al., 2023; AI4Science et al., 2023), as well as both multi-fidelity and multi-objective problems
(Jain et al., 2023b).
Finally, given the complexity of multi-fidelity active learning algorithms, consisting of multiple components,
we have barely optimised the many hyperparameters and design choices. In fact, we have opted for conser-
vative, simple choices in several cases. For example, as oracle confidence we have simply used the inverse of
the cost instead of a more accurate estimate of the oracle fidelity. Therefore, we expect significant room for
improvement from simple hyperparameter optimisation.
Statement of Broader Impact
Ourworkismotivatedbypressingchallengestosustainabilityandpublichealth, andweenvisionapplications
of our approach to drug discovery and materials discovery. However, as with all work on these topics, there
11Published in Transactions on Machine Learning Research (07/2024)
is a potential risk of dual use of the technology by nefarious actors (Urbina et al., 2022). The authors
strongly oppose any uses or derivations of this work intended to cause harm to humans or the environment
and explicitly request the careful consideration of potential harms.
Reproducibility Statement
Wehavemadeanefforttoincludethemostrelevantdetailsofourproposedalgorithminthemainbodyofthe
paper. For example, a detailed procedure of the steps of the algorithm is presented in Algorithm 1. Besides
this, we have included additional details about the algorithm in Appendices A and B. We have also provided
the most relevant information about the experiments in Section 4, for instance including a description of
the data representation and the oracles for each of the benchmark tasks. The rest of the details about the
experiments are provided in Appendix C for the sake of better clarity, transparency and reproducibility.
Finally, the implementation of MF-GFN and the code to reproduce the experiments is publicly available in
a GitHub repository:
https://github.com/nikita-0209/mf-al-gfn
References
RDKit: Open-source cheminformatics. https://www.rdkit.org , 2023. URL https://zenodo.org/
record/8254217 .
Ankit Agrawal and Alok Choudhary. Perspective: Materials informatics and big data: Realization of the
“fourth paradigm” of science in materials science. APL Materials , 4(5):053208, 2016.
Mila AI4Science, Alex Hernandez-Garcia, Alexandre Duval, Alexandra Volokhova, Yoshua Bengio, Divya
Sharma, Pierre Luc Carrier, Yasmine Benabed, Michał Koziarski, and Victor Schmidt. Crystal-GFN:
sampling crystals with desirable properties and constraints. arXiv preprint arXiv:2310.04925 , 2023.
Christof Angermueller, David Dohan, David Belanger, Ramya Deshpande, Kevin Murphy, and Lucy Col-
well. Model-based reinforcement learning for biological sequence design. In International Conference on
Learning Representations (ICLR) , 2020.
DávidBajusz, AnitaRácz, andKárolyHéberger. Whyistanimotoindexanappropriatechoiceforfingerprint-
based similarity calculations? Journal of Cheminformatics , 7, 05 2015.
Maximilian Balandat, Brian Karrer, Daniel R. Jiang, Samuel Daulton, Benjamin Letham, Andrew Gordon
Wilson, and Eytan Bakshy. BoTorch: A Framework for Efficient Monte-Carlo Bayesian Optimization. In
Advances in Neural Information Processing Systems (NeurIPS) , volume 33, 2020.
Christoph Bannwarth, Sebastian Ehlert, and Stefan Grimme. GFN2-xTB—an accurate and broadly
parametrized self-consistent tight-binding quantum chemical method with multipole electrostatics and
density-dependent dispersion contributions. Journal of Chemical Theory and Computation , 15(3):1652–
1671, 2019.
Ali Bashir, Qin Yang, Jinpeng Wang, Stephan Hoyer, Wenchuan Chou, Cory McLean, Geoff Davis, Qiang
Gong, Zan Armstrong, Junghoon Jang, et al. Machine learning guided aptamer refinement and discovery.
Nature Communications , 12(1):2366, 2021.
Emmanuel Bengio, Moksh Jain, Maksym Korablyov, Doina Precup, and Yoshua Bengio. Flow network
based generative models for non-iterative diverse candidate generation. In Advances in Neural Information
Processing Systems (NeurIPS) , volume 34, 2021a.
Yoshua Bengio, Salem Lahlou, Tristan Deleu, Edward J. Hu, Mo Tiwari, and Emmanuel Bengio. GFlowNet
foundations. arXiv preprint arXiv:2111.09266 , 2021b.
Regine S Bohacek, Colin McMartin, and Wayne C Guida. The art and practice of structure-based drug
design: a molecular modeling perspective. Medicinal Research Reviews , 16(1):3–50, 1996.
12Published in Transactions on Machine Learning Research (07/2024)
Keith T Butler, Daniel W Davies, Hugh Cartwright, Olexandr Isayev, and Aron Walsh. Machine learning
for molecular and materials science. Nature, 559(7715):547–555, 2018.
Kathryn Chaloner and Isabella Verdinelli. Bayesian experimental design: A review. Statistical Science , pp.
273–304, 1995.
Konstantinos Chatzilygeroudis, Antoine Cully, Vassilis Vassiliades, and Jean-Baptiste Mouret. Quality-
diversity optimization: a novel branch of stochastic optimization. In Black Box Optimization, Machine
Learning, and No-Free Lunch Theorems , pp. 109–135. Springer, 2021.
Chi Chen, Yunxing Zuo, Weike Ye, Xiangguo Li, and Shyue Ping Ong. Learning properties of ordered and
disordered materials from multi-fidelity data. Nature Computational Science , 1(1):46–53, 2021.
Laming Chen, Guoxin Zhang, and Hanning Zhou. Fast greedy map inference for determinantal point process
to improve recommendation diversity. arXiv preprint arXiv:1709.05135 , 2018.
David R Corey, Masad J Damha, and Muthiah Manoharan. Challenges and opportunities for nucleic acid
therapeutics. Nucleic Acid Therapeutics , 32(1):8–13, 2022.
Payel Das, Tom Sercu, Kahini Wadhawan, Inkit Padhi, Sebastian Gehrmann, Flaviu Cipcigan, Vijil Chen-
thamarakshan, Hendrik Strobelt, Cicero Dos Santos, Pin-Yu Chen, et al. Accelerated antimicrobial dis-
covery via deep generative models and molecular dynamics simulations. Nature Biomedical Engineering ,
5(6):613–623, 2021.
Aryan Deshwal and Janardhan Rao Doppa. Combining latent space and structured kernels for Bayesian
optimizationovercombinatorialspaces. In Advances in Neural Information Processing Systems (NeurIPS) ,
volume 34, 2021.
Clyde Fare, Peter Fenner, Matthew Benatan, Alessandro Varsi, and Edward O Pyzer-Knapp. A multi-fidelity
machine learning approach to high throughput materials screening. npj computational materials , 8(1):257,
2022.
Francesco Di Fiore, Michela Nardelli, and Laura Mainini. Active learning and Bayesian optimization: a
unified perspective to learn with a goal. arXiv preprint arXiv:2303.01560 , 2023.
Jose Pablo Folch, Robert M Lee, Behrang Shafei, David Walz, Calvin Tsay, Mark van der Wilk, and Ruth
Misener. Combining multi-fidelity modelling and asynchronous batch Bayesian optimization. Computers
& Chemical Engineering , 172:108194, 2023.
Adam Evan Foster. Variational, Monte Carlo and policy-based approaches to Bayesian experimental design .
PhD thesis, University of Oxford, 2021.
Peter I. Frazier. A tutorial on Bayesian optimization. arXiv preprint arXiv:1807.02811 , 2018.
Wenhao Gao, Tianfan Fu, Jimeng Sun, and Connor W. Coley. Sample efficiency matters: A benchmark for
practical molecular optimization. arXiv preprint arXiv:2206.12411 , 2022.
Jacob R. Gardner, Geoff Pleiss, David Bindel, Kilian Q. Weinberger, and Andrew Gordon Wilson. GPy-
Torch: Blackbox matrix-matrix gaussian process inference with GPU acceleration. arXiv preprint
arXiv:1809.11165 , 2021.
Roman Garnett. Bayesian optimization . Cambridge University Press, 2023.
Roman Garnett, Yamuna Krishnamurthy, Xuehan Xiong, Jeff Schneider, and Richard Mann. Bayesian
optimal active search and surveying. arXiv preprint arXiv:1206.6406 , 2012.
Antoine Grosnit, Rasul Tutunov, Alexandre Max Maraval, Ryan-Rhys Griffiths, Alexander I. Cowen-Rivers,
Lin Yang, Lin Zhu, Wenlong Lyu, Zhitang Chen, Jun Wang, Jan Peters, and Haitham Bou-Ammar. High-
dimensional Bayesian optimisation with variational autoencoders and deep metric learning. arXiv preprint
arXiv:2106.03609 , 2021.
13Published in Transactions on Machine Learning Research (07/2024)
Thomas A Halgren. Merck molecular force field. I. Basis, form, scope, parameterization, and performance
of MMFF94. Journal of Computational Chemistry , 17(5-6):490–519, 1996.
Moksh Jain, Emmanuel Bengio, Alex Hernandez-Garcia, Jarrid Rector-Brooks, Bonaventure FP Dossou,
Chanakya Ajit Ekbote, Jie Fu, Tianyu Zhang, Michael Kilgour, Dinghuai Zhang, et al. Biological sequence
design with GFlowNets. In International Conference on Machine Learning (ICML) , volume 162. PMLR,
2022.
Moksh Jain, Tristan Deleu, Jason Hartford, Cheng-Hao Liu, Alex Hernandez-Garcia, and Yoshua Bengio.
GFlowNets for AI-driven scientific discovery. Digital Discovery , 2023a.
Moksh Jain, Sharath Chandra Raparthy, Alex Hernandez-Garcia, Jarrid Rector-Brooks, Yoshua Bengio,
Santiago Miret, and Emmanuel Bengio. Multi-objective GFlowNets. In International Conference on
Machine Learning (ICML) , 2023b.
Shali Jiang, Gustavo Malkomes, Geoff Converse, Alyssa Shofner, Benjamin Moseley, and Roman Garnett.
Efficient nonmyopic active search. In International Conference on Machine Learning (ICML) , volume 70.
PMLR, 2017.
Shali Jiang, Roman Garnett, and Benjamin Moseley. Cost effective active search. In Advances in Neural
Information Processing Systems (NeurIPS) , volume 32, 2019.
John Jumper, Richard Evans, Alexander Pritzel, Tim Green, Michael Figurnov, Olaf Ronneberger, Kathryn
Tunyasuvunakool, Russ Bates, Augustin Žídek, Anna Potapenko, et al. Highly accurate protein structure
prediction with AlphaFold. Nature, 596(7873):583–589, 2021.
Kirthevasan Kandasamy, Gautam Dasarathy, Junier B. Oliva, Jeff Schneider, and Barnabas Poczos. Multi-
fidelity gaussian process bandit optimisation. Journal of Artificial Intelligence Research (JAIR) , 66:151–
196, 2019.
Michael Kilgour, Tao Liu, Brandon D Walker, Pengyu Ren, and Lena Simine. E2EDNA: Simulation protocol
for DNA aptamers with ligands. Journal of Chemical Information and Modeling , 61(9):4139–4144, 2021.
Ross D King, Kenneth E Whelan, Ffion M Jones, Philip GK Reiser, Christopher H Bryant, Stephen H
Muggleton, Douglas B Kell, and Stephen G Oliver. Functional genomic hypothesis generation and exper-
imentation by a robot scientist. Nature, 427(6971):247–252, 2004.
Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In International Confer-
ence on Learning Representations (ICLR) , 2015.
Andreas Kirsch, Sebastian Farquhar, Parmida Atighehchian, Andrew Jesson, Frédéric Branchaud-Charron,
and Yarin Gal. Stochastic batch acquisition: A simple baseline for deep active learning. Transactions on
Machine Learning Research (TMLR) , 2023. ISSN 2835-8856.
Mario Krenn, Florian Häse, AkshatKumar Nigam, Pascal Friederich, and Alan Aspuru-Guzik. Self-
referencing embedded strings (SELFIES): A 100% robust molecular string representation. Machine Learn-
ing: Science and Technology , 1(4):045024, 2020.
Patrick Kunzmann and Kay Hamacher. Biotite: a unifying open source computational biology framework
in Python. BMC Bioinformatics , 19:1–8, 2018.
A Gilad Kusne, Heshan Yu, Changming Wu, Huairuo Zhang, Jason Hattrick-Simpers, Brian DeCost, Suchis-
mita Sarker, Corey Oses, Cormac Toher, Stefano Curtarolo, et al. On-the-fly closed-loop materials dis-
covery via Bayesian active learning. Nature Communications , 11(1):5966, 2020.
Salem Lahlou, Tristan Deleu, Pablo Lemos, Dinghuai Zhang, Alexandra Volokhova, Alex Hernández-García,
Léna Néhale Ezzine, Yoshua Bengio, and Nikolay Malkin. A theory of continuous generative flow networks.
InInternational Conference on Machine Learning (ICML) , 2023.
14Published in Transactions on Machine Learning Research (07/2024)
Shibo Li, Wei Xing, Mike Kirby, and Shandian Zhe. Multi-fidelity Bayesian optimization via deep neural
networks. In Advances in Neural Information Processing Systems (NeurIPS) , volume 33, 2020.
Shibo Li, Robert M Kirby, and Shandian Zhe. Deep multi-fidelity active learning of high-dimensional
outputs. In International Conference on Artificial Intelligence and Statistics (AISTATS) , volume 151, pp.
1694–1711. PMLR, 2022a.
Shibo Li, Jeff M. Phillips, Xin Yu, Robert M. Kirby, and Shandian Zhe. Batch multi-fidelity active learning
with budget constraints. arXiv preprint arXiv:2210.12704 , 2022b.
Wesley J. Maddox, Samuel Stanton, and Andrew Gordon Wilson. Conditioning sparse variational gaussian
processes for online decision-making. CoRR, abs/2110.15172, 2021.
Nikolay Malkin, Moksh Jain, Emmanuel Bengio, Chen Sun, and Yoshua Bengio. Trajectory balance: Im-
provedcreditassignmentinGFlowNets. In Advances in Neural Information Processing Systems (NeurIPS) ,
volume 35, 2022.
Natalie Maus, Kaiwen Wu, David Eriksson, and Jacob Gardner. Discovering many diverse solutions with
Bayesian optimization. arXiv preprint arXiv:2210.10953 , 2022.
P. Mikkola, Julien Martinelli, Louis Filstroff, and Samuel Kaski. Multi-fidelity Bayesian optimization with
unreliable information sources. In International Conference on Artificial Intelligence and Statistics (AIS-
TATS), 2023.
Henry B. Moss, David S. Leslie, Javier Gonzalez, and Paul Rayson. GIBBON: General-purpose information-
based Bayesian optimisation. Journal of Machine Learning Research (JMLR) , 22(235):1–49, 2021.
Hagen Neugebauer, Fabian Bohle, Markus Bursch, Andreas Hansen, and Stefan Grimme. Benchmark study
ofelectrochemicalredoxpotentialscalculatedwithsemiempiricalanddftmethods. The Journal of Physical
Chemistry A , 124(35):7166–7176, 2020.
Quan Nguyen, Arghavan Modiri, and Roman Garnett. Nonmyopic multifidelity active search. In Interna-
tional Conference on Machine Learning (ICML) , volume 139. PMLR, 2021.
Leonard Papenmeier, Luigi Nardi, and Matthias Poloczek. Bounce: Reliable high-dimensional Bayesian
optimization for combinatorial and mixed spaces. In Advances in Neural Information Processing Systems
(NeurIPS) , volume 36, 2023.
Robert G Parr. Density functional theory of atoms and molecules. In Horizons of Quantum Chemistry:
Proceedings of the Third International Congress of Quantum Chemistry Held at Kyoto, Japan, October
29-November 3, 1979 , pp. 5–15. Springer, 1980.
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen,
Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Köpf, Edward Yang, Zach
DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, and
Soumith Chintala. PyTorch: An imperative style, high-performance deep learning library. In Advances in
Neural Information Processing Systems (NeurIPS) , volume 32, 2019.
Benjamin Peherstorfer, Karen Willcox, and Max Gunzburger. Survey of multifidelity methods in uncertainty
propagation, inference, and optimization. SIAM Review , 60(3):550–591, 2018.
John P Perdew and Karla Schmidt. Jacob’s ladder of density functional approximations for the exchange-
correlation energy. AIP Conference Proceedings , 577(1):1–20, 2001.
Paris Perdikaris, M. Raissi, Andreas C. Damianou, ND Lawrence, and George Em Karniadakis. Nonlinear
information fusion algorithms for data-efficient multi-fidelity modelling. Proceedings of the Royal Society
A: Mathematical, Physical and Engineering Sciences , 473(2198), 2017.
15Published in Transactions on Machine Learning Research (07/2024)
Malak Pirtskhalava, Anthony A Amstrong, Maia Grigolava, Mindia Chubinidze, Evgenia Alimbarashvili,
Boris Vishnepolsky, Andrei Gabrielian, Alex Rosenthal, Darrell E Hurt, and Michael Tartakovsky.
DBAASP v3: database of antimicrobial/cytotoxic activity and structure of peptides as a resource for
development of new therapeutics. Nucleic Acids Research , 49(D1):D288–D297, 2021.
Pavel G Polishchuk, Timur I Madzhidov, and Alexandre Varnek. Estimation of the size of drug-like chemical
space based on GDB-17 data. Journal of Computer-Aided Molecular Design , 27:675–679, 2013.
Carl Edward Rasmussen and Christopher K. I. Williams. Gaussian Processes for Machine Learning . The
MIT Press, 11 2005.
Herbert E. Robbins. Some aspects of the sequential design of experiments. Bulletin of the American
Mathematical Society , 58:527–535, 1952.
John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov. Proximal policy optimiza-
tion algorithms. arXiv preprint arXiv:1707.06347 , 2017.
Burr Settles. Active learning literature survey. Independent Technical Report , 2009.
David S Sholl and Janice A Steckel. Density functional theory: a practical introduction . John Wiley & Sons,
2022.
Jasper Snoek, Oren Rippel, Kevin Swersky, Ryan Kiros, Nadathur Satish, Narayanan Sundaram, Mostofa
Patwary, Mr Prabhat, and Ryan Adams. Scalable Bayesian optimization using deep neural networks. In
International Conference on Machine Learning (ICML) . PMLR, 2015.
András Sobester, Alexander Forrester, and Andy Keane. Engineering Design via Surrogate Modelling. Ap-
pendix: Example Problems , pp. 195–203. John Wiley & Sons, Ltd, 2008.
Jialin Song, Yuxin Chen, and Yisong Yue. A general framework for multi-fidelity Bayesian optimization
with Gaussian processes. In International Conference on Artificial Intelligence and Statistics , volume 89.
PMLR, 2018.
Niranjan Srinivas, Andreas Krause, Sham M Kakade, and Matthias Seeger. Gaussian process optimization in
the bandit setting: No regret and experimental design. In International Conference on Machine Learning
(ICML), 2010.
Samuel Stanton, Wesley Maddox, Nate Gruver, Phillip Maffettone, Emily Delaney, Peyton Greenside, and
Andrew Gordon Wilson. Accelerating Bayesian optimization for biological sequence design with denoising
autoencoders. In International Conference on Machine Learning (ICML) , volume 162. PMLR, 2022.
Jonathan M Stokes, Kevin Yang, Kyle Swanson, Wengong Jin, Andres Cubillos-Ruiz, Nina M Donghia,
Craig R MacNair, Shawn French, Lindsey A Carfrae, Zohar Bloom-Ackermann, et al. A deep learning
approach to antibiotic discovery. Cell, 180(4):688–702, 2020.
Shion Takeno, Hitoshi Fukuoka, Yuhki Tsukada, Toshiyuki Koyama, Motoki Shiga, Ichiro Takeuchi, and
Masayuki Karasuyama. Multi-fidelity Bayesian optimization with max-value entropy search and its par-
allelization. In International Conference on Machine Learning (ICML) , volume 119. PMLR, 2020.
Fabio Urbina, Filippa Lentzos, Cédric Invernizzi, and Sean Ekins. Dual use of artificial-intelligence-powered
drug discovery. Nature Machine Intelligence , 4(3):189–191, 2022.
Zi Wang and Stefanie Jegelka. Max-value entropy search for efficient Bayesian optimization. In International
Conference on Machine Learning (ICML) , volume 70. PMLR, 2017.
Manfred KK Warmuth, Gunnar Rätsch, Michael Mathieson, Jun Liao, and Christian Lemmen. Active
learning in the drug discovery process. In Advances in Neural Information Processing Systems (NeurIPS) ,
volume 14, 2001.
16Published in Transactions on Machine Learning Research (07/2024)
Andrew Gordon Wilson, Zhiting Hu, Ruslan Salakhutdinov, and Eric P Xing. Deep kernel learning. In
International Conference on Artificial Intelligence and Statistics (AISTATS) , pp. 370–378. PMLR, 2016.
Dongxia Wu, Ruijia Niu, Matteo Chinazzi, Yian Ma, and Rose Yu. Disentangled multi-fidelity deep Bayesian
active learning. arXiv preprint arXiv:2305.04392 , 2023.
Dezhen Xue, Prasanna V Balachandran, John Hogden, James Theiler, Deqing Xue, and Turab Lookman.
Accelerated search for materials with targeted properties by adaptive design. Nature Communications , 7
(1):1–9, 2016.
Joseph D Yesselman, Daniel Eiler, Erik D Carlson, Michael R Gotrik, Anne E d’Aquino, Alexandra N Ooms,
Wipapat Kladwang, Paul D Carlson, Xuesong Shi, David A Costantino, et al. Computational design of
three-dimensional RNA structure and function. Nature Nanotechnology , 14(9):866–873, 2019.
Ruihao Yuan, Zhen Liu, Prasanna V Balachandran, Deqing Xue, Yumei Zhou, Xiangdong Ding, Jun Sun,
Dezhen Xue, and Turab Lookman. Accelerated discovery of large electrostrains in BaTiO3-based piezo-
electrics using active learning. Advanced Materials , 30(7):1702884, 2018.
Joseph N Zadeh, Conrad D Steenberg, Justin S Bois, Brian R Wolfe, Marshall B Pierce, Asif R Khan,
Robert M Dirks, and Niles A Pierce. NUPACK: Analysis and design of nucleic acid systems. Journal of
Computational Chemistry , 32(1):170–173, 2011.
Wenhu Zhou, Runjhun Saran, and Juewen Liu. Metal sensing by DNA. Chemical Reviews , 117(12):8272–
8325, 2017.
C Lawrence Zitnick, Lowik Chanussot, Abhishek Das, Siddharth Goyal, Javier Heras-Domingo, Caleb Ho,
Weihua Hu, Thibaut Lavril, Aini Palizhati, Morgane Riviere, et al. An introduction to electrocatalyst
design using machine learning for renewable energy storage. arXiv preprint arXiv:2010.09435 , 2020.
17Published in Transactions on Machine Learning Research (07/2024)
A MF-GFN Algorithm
Our algorithm, MF-GFN, detailed in Algorithm 1, proceeds as follows: An active learning round jstarts
with a data set of annotated samples Dj={(xi,fmi(xi),mi)}1≤m≤M. If no initial data set is available,
a set of data points could be sampled randomly. The data set is used to fit a probabilistic multi-fidelity
surrogate model h(x,m)of the posterior p(fm(x)|x,m,D). The output of the surrogate model is then used
to compute the value of a multi-fidelity acquisition function α(x,m). In our experiments, we use the multi-
fidelity version (Takeno et al., 2020) of max-value entropy search (MES, Wang & Jegelka, 2017), which is
an information-theoretic acquisition function widely used in Bayesian optimisation. Additional details about
the surrogate and the acquisition function are provided Section 3 and Appendix B.
The acquisition function is used to derive the reward to train a multi-fidelity GFlowNet (see details in
Appendix C.3. The GFlowNet is trained to sample tuples (x,m)proportionally to the reward. An active
learningroundterminatesbygenerating Ntuplesfromthesampler(heretheGFlowNetpolicy π)andforming
a batch with the best Bobjects, according to α. Note that N≫B, since sampling from a GFlowNet is
relatively inexpensive. The selected objects are annotated by the corresponding oracles and incorporated
into the data set, such that Dj+1=Dj∪{(x1,fm1(x1),m1),..., (xB,fmB(xB),mB)}. This procedure is
repeated, progressively acquiring new data, until the budget is exhausted.
B Surrogate Models and Acquisition Function
In this section, we discuss additional details about the surrogate model and acquisition function used in our
experiments.
B.1 Gaussian Processes
Following the Bayesian optimisation literature, we assume a Gaussian Process (GP) prior on the joint
distribution over the function values at different fidelities. The posterior distribution over the oracles
p(fm(x)|x,m,D)is a also a GP. Concretely, consider a set of n points {(x1,m1),(x2,m2),..., (xn,mn)}
with observed values {fm1(x1),...fmn(xn)}. LetD={(x1,fm1(x1),m1),..., (xn,fmn(xn),mn)}. A key
decision for modelling with GPs is the choice of the kernel. As discussed in Section 3.2, we use the linear
truncated multi-fidelity kernel previously used by Mikkola et al. (2023). Assuming a GP prior with mean
functionµ, kernelKMF(Eq. (2)) and an additive Gaussian noise observation model with variance σ, the
posterior distribution conditioned on Dis also a GP with the following mean and covariance:
µn(x,m) =µ(x1:n,m1:n) +KMF((x,m),(x1:n,m1:n))(KMF((x1:n,m1:n),(x1:n,m1:n))
+σ2I)−1(fm(x1:n)−µ(x1:n,m1:n)).
Kn((xi,mi),(xj,mj)) =KMF((xi,mi),(xj,mj))
−KMF((xi,mi),(x1:n,m1:n))(KMF((x1:n,m1:n),(x1:n,m1:n))
+σ2I)−1KMF((x1:n,m1:n),(xj,mj)).
B.2 Deep Kernel Learning
For synthetic tasks, we use an exact GP for the surrogate. However, for larger, higher dimensional tasks,
having a kernel which captures the structure in the space becomes critical as standard kernels such as RBF
and Matérn have difficulty to accurately capture a useful notion of similarity. Thus, for the larger benchmark
tasks we use deep kernel learning (DKL; Wilson et al., 2016) to alleviate the challenges of defining a kernel.
DKL involves using a deep neural network gω, whereωare the parameters, to learn a low-dimensional
embedding zfor an input x,z=gω(x)and applying the kernel on these low-dimensional embeddings.
KX(xi,xj)→KX(gω(xi),gω(xj)),
18Published in Transactions on Machine Learning Research (07/2024)
wheregωis a transformer for our experiments. Additionally, to scale the GP to large datasets, we implement
the stochastic variational GP based on the greedy inducing point method (Chen et al., 2018). Training
surrogatemodelswithDKLcanleadtosomeinstabilities, soforourexperimentswerelyonrecommendations
from Stanton et al. (2022) to ensure stable training of the surrogate model.
B.3 Acquisition Function
In our experiments, we use the max-value entropy search (MES, Wang & Jegelka, 2017) acquisition function.
Specifically, we use the multi-fidelity MF-MES variant proposed by Takeno et al. (2020), which for a given
candidate (x,m)measures the mutual information between the value of fm(x)and the maximum value of
the highest fidelity oracle f∗
M.
α(x,m) =I(f⋆
M;fm(x)|Dj) =H(fm(x)|Dj)−Ef⋆[H(fm(x)|f⋆
M,Dj)|Dj].
The acquisition function can also be interpreted as the expected information gain about f∗
Mobtained by
queryingfm(x), where information gain is defined as the reduction in entropy over f∗
Minduced by observing
fm(x).
The mutual information can be expensive to compute and is typically approximated using Monte Carlo
samples (Wang & Jegelka, 2017). For our experiments, we use the GIBBON approximation (Moss et al.,
2021). Moss et al. (2021) proposed an approximation to the MES acquisition function that is tractable and
efficient to compute. Concretely, it takes the following form:
α(x,m)≈1
λm1
|F|/summationdisplay
F∈FIGApprox(fm(x),F|Dn),with
IGApprox=1
2log|R|−1
2|F|/summationdisplay
F∈Flog/parenleftbigg
1−ρ2ϕ(γ(F))
Φ(γ(F))/bracketleftbigg
γ(F) +ϕ(γ(F))
Φ(γ(F))/bracketrightbigg/parenrightbigg
,
whereϕandΦare the standard normal cumulative distribution and probability density functions (arising
from the expression for the differential entropy of a truncated Gaussian), γ(F) =F−µn(x,m)
σn(x,m),Ris the
correlation matrix with elements Ri,j=Σi,j
Σi,iΣj,j,ρ=Corr(fm(x),fM(x)), andF={Fi}|F|
i=1, F∼p(f∗
M|D).
µn(x,m)is the predictive mean, σn(x,m)is the predictive standard deviation and Σi,jis the predictive
covariance of the surrogate model for fidelities i,jatx.
Note that our algorithm is not bound to a particular acquisition function (or surrogate model) and therefore
these components may be adapted to the specific needs of the application.
C Experimental Details
This section presents the details about the experiments discussed in Section 4. First, we provide general
details about all tasks and then present details specific to each task in separate sections.
C.1 Initial data set and budget
We define a budget ( Λ0) for the initial data set. Let λmbe the cost of evaluating xwith oracle fm, and
nSF,nMFbe the number of initial training points in the single- and multi-fidelity experiments respectively.
Also letnmbe the number of training points evaluated against fmin the multi-fidelity experiment such that
nMF=/summationtextM
m=1nm. Then,
Λ0=nSF×λM=m=M/summationdisplay
m=1nm×λm.
The initial data set is split into train and validation in the ratio of 9:1 for all tasks. Task-specific information
is summarized in Table 1.
19Published in Transactions on Machine Learning Research (07/2024)
For each task, we assign a total active learning budget Λ =γ×λM(Table 2).γwas selected based on the
rate of convergence of the algorithms to the modes. Note that during an active learning round, only the
oracle evaluations of the sampled batch contribute to Λ. The cost of sampling from a trained GFlowNet is
nearly negligible compared to the oracle evaluations. This is why we can afford to sample a large number of
samples (N= 5×B) to then select the best B, according to the acquisition function (Algorithm 1).
C.2 DKL Implementation Details
Here, we describe our implementation of DKL, which is inspired by Stanton et al. (2022).
Neural Network Architecture For all experiments, the same base architecture was used, featuring
transformer encoder layers with position masking for padding tokens. Standard pre-activation residual
blocks were included, comprising two convolutional layers, layer normalisation, and swish activations. The
encoder embeds input sequences with standard vocabulary and sinusoidal position embeddings. The encoder
is trained with the Masked Language Modeling (MLM) objective which is calculated by randomly masking
input tokens and subsequently computing the empirical cross-entropy between the original sequence and the
predictive distribution generated by the MLM head for the masked positions.
Optimiser Hyperparameters The running estimates of the first two moments in the Adam opti-
miser (Kingma & Ba, 2015) were disabled by setting β1= 0.0andβ2= 0.01.
Kernel Hyperparameters In order to force the encoder to learn features appropriate for the initial
lengthscale, we place a tight Gaussian prior with σ= 0.01around the intial lengthscale value. The reinitial-
isation procedure for inducing point locations and variational parameters outlined by Maddox et al. (2021)
was followed.
C.3 Reward Function and Policy Models Details
Neural Network Architecture For all tasks, the architecture of the GFlowNet forward policy ( PF)
model is a multi-layer perceptron with 2 hidden layers and 2048 units per layer. The backward policy ( PB)
model was set to share all but the last layer parameters with PF. We use LeakyReLU as our activation
function as in Bengio et al. (2021a). All models are trained with the Adam optimiser (Kingma & Ba, 2015).
Reward Function As detailed in Algorithm 1, the GFlowNet is trained to generate samples with a higher
value of the MES acquisition function and its multi-fidelity variant in single- and multi-fidelity experiments,
respectively. In order to increase the relative reward of higher values of the acquisition function, we scale
the MES value α(x,m)by1
β, with 0< β≤1. On an additional note, MES exhibits increased sparsity as
more samples are discovered. Hence, in order to facilitate optimisation, we introduce another scaling factor
denoted by ρj−1, which depends on the active learning round j. Altogether, our GFlowNet reward function
is the following:
R(α(x,m),β,ρ,j ) =α(x,m)×ρj−1
β,
Note that within an active learning round, the GFlowNet samples (approximately) from this fixed reward
function and thus the policy need not be conditioned on j. The hyperparameter values for all tasks are
detailed in Table 2.
Our models are implemented in PyTorch (Paszke et al., 2019), and rely on BoTorch (Balandat et al., 2020)
and GPyTorch (Gardner et al., 2021).
C.4 Synthetic Tasks
This section describes the experiments and results obtained on the synthetic tasks Branin and Hartmann,
included for completeness, to allow a comparison with the traditional Bayesian optimisation literature.
20Published in Transactions on Machine Learning Research (07/2024)
Table 1: Oracle costs (indexed by increasing level of fidelity) and initial data set details.
Task Oracle Costs Initial Data Set
Λ0nSF nMF
λ1λ2λM n1n2nM
Branin 0.01 0.1 1 4 4 20 20 2
Hartmann 6D 0.125 0.25 1 25 25 80 40 5
DNA – 0.2 20 1600 80 – 3000 50
AMP 0.5 0.5 50 2500 50 2000 2000 10
Molecules 1 3 7 1050 150 700 68 16
Table 2: Hyperparameters concerning the active learning setting and the policy reward function.
Task Surrogate Model Active-learning Policy reward function
γ B β ρ
Branin Exact GP 300 30 1 1
Hartmann 6D Exact GP 100 10 1e-2 1
DNA DKL 256 512 1e-5 2
Antimicrobial Peptides DKL 20 32 1e-5 1
Molecules DKL 180 128 1e-6 1.5
C.4.1 Branin
We consider an active learning problem in a two-dimensional space (x1,x2)where the target function fM
is the Branin function, as modified by Sobester et al. (2008) and implemented in BoTorch (Balandat et al.,
2020). In the standard domain [−5,10]×[0,15], the Branin function has three modes and is evaluated using
the following expression:
f(x) = (x2−−1.25x2
1
π2+5x1
π−6)2+ (10−5
4π) cos(x1) + 10.
This corresponds to the modification introduced by Sobester et al. (2008). As lower fidelity functions, we
used the expressions from Perdikaris et al. (2017), which involve non-linear transformations of the true
function as well as shifts and non-uniform scalings. The functions, indexed by increasing level of fidelity, are
the following:
f1(x) =f2(1.2(x+ 2))−3x2+ 1,
f2(x) = 10/radicalbig
f(x−2) + 2(x1−0.5)−3(3x2−1)−1.
This amounts to three levels of fidelity, including the true function. The lower-fidelity oracles, the costs of
the oracles (0.01,0.1,1.0)as well as the number of points queried in the initial training set were adopted
from Li et al. (2020).
In order to consider a discrete design space, we interpolate the domain into a discrete 100×100grid. We
model this grid with a GFlowNet as in (Bengio et al., 2021a; Malkin et al., 2022): starting from the origin
(0,0), for any state s= (x1,x2), the action space consists of the choice between the exit action or the
dimension to increment by 1, provided the next state is in the limits of the grid.
We use the BoTorch implementation of an exact multi-fidelity Gaussian process as described in Appendix B.1
for regression. The active learning acquisition batch size Bis30in the Branin task.
Fig. 4a illustrates the results for this task. We observe that MF-GFN is able to reach the minimum of the
Branin function with a smaller budget than the single-fidelity counterpart and the baselines.
21Published in Transactions on Machine Learning Research (07/2024)
102
101
100
Fraction of total SF-GFN budget (log)50
40
30
20
10
0Mean Top-50 scoreSF-GFN
Rand. fid. GFN
MF-GFN
(a) Branin task
102
101
100
Fraction of total SF-GFN budget (log)1.52.02.53.0Mean Top-10 scoreSF-GFN
Rand. fid. GFN
MF-PPO
MF-GFN (b) Hartmann task
Figure 4: Results on the synthetic tasks—Branin and Hartmann functions. The curves indicate the mean
scorefMwithin the top-50 and top-10 samples (for Branin and Hartmann, respectively) computed at the end
of each active learning round and plotted as a function of the budget used. The random baseline is omitted
from this plot to facilitate the visualisation since the results were significantly worse in these tasks. We
observe that MF-GFN clearly outperforms the single-fidelity counterpart (SF-GFN) and slightly improves
upon the GFlowNet baseline that samples random fidelities. On Hartmann, MF-PPO initially outperforms
the other methods.
C.4.2 Hartmann 6D
We consider the 6-dimensional Hartmann function as objective fMon a hyper-grid domain. It is typically
evaluated on the hyper-cube xi∈[0,1]6and consists of six local maxima. The expression of the true
Hartmann function is given by
f(x) =4/summationdisplay
i=1ηiexp(−3/summationdisplay
j=1Aij(xj−Pij)2),
whereη= [1.0,1.2,3.0,3.2]andA,P∈R4×6are the following fixed matrices:
A=
10 3 17 3 .5 1.7 8
0.05 10 17 0 .1 8 1
3 3.5 1.7 10 17 8
17 8 0 .05 10 0.1 1
,
P= 10−4×
3689 1170 267
4699 4387 7470
1091 8732 5547
381 5743 8828
.
To simulate the lower fidelities, we modify ηtoη(m)whereη(m) =η+δ(M−m)whereδ=
[0.01,−0.01,−0.1,0.1]andM= 3. The domain is X= [0,1]6. This implementation was adopted from
Kandasamy et al. (2019). As with Branin, we consider three oracles, adopting the lower-fidelity oracles and
the set of costs (0.125,0.25,1.0)from Song et al. (2018).
We discretise the domain into a six-dimensional hyper-grid of length 10, yielding 106possible candidate
points. For the surrogate, we use the same exact multi-fidelity GP implementation as of Branin. The active
learning acquisition batch size Bis10.
The results for the task are illustrated in Fig. 4b, which indicate that multi-fidelity active learning with
GFlowNets (MF-GFN) offers an advantage over single-fidelity active learning (SF-GFN) as well as some of
22Published in Transactions on Machine Learning Research (07/2024)
the other baselines in this higher-dimensional synthetic problem as well. The better performance on MF-
PPO can be attributed to the fact that while the GFN initiates its exploration from the origin point, the
PPO commences from a random starting point within a bounded range, allowing at most three units of
displacement (maximum possible displacement is 10 units) along each of the six axes. We hypothesise that
this aids the PPO algorithm in expediting the discovery of modes within the optimisation process. While
MF-PPO performs better in this task, as shown in the benchmark experiments, it tends to collapse to single
modes of the function in complex high-dimensional scenarios.
C.5 Benchmark Tasks
C.5.1 DNA
We conduct experiments using a two-oracle setup ( fM,f1) with costs λM= 20andλ1= 0.2for the high
and low fidelity oracles, respectively. As fM, we use the free energy of the secondary structure of DNA
sequences obtained via the software NUPACK (Zadeh et al., 2011), setting the temperature at 310K.f1is
a transformer (with 8encoder layers, 1024hidden units per layer and 16heads) trained on 1 million random
sequences annotated by fM. To evaluate the performance of f1(with respect to fM), we construct a test
set by sampling sequences from a uniform distribution of the free energy. On this test set, the explained
variance of the f1is calculated to be 0.8. For the probabilistic surrogate model, we implement deep kernel
learning, the hyperparameters of which are provided in Table 4. The active learning acquisition batch size
Bis512.
C.5.2 Antimicrobial Peptides
We use data from DBAASP (Pirtskhalava et al., 2021), containing antimicrobial activity labels, which is
originally split into three sets: D1for training the oracle, D2as the initial data set in the active learning
loop andD3as the test set (Jain et al., 2022).
Table 3: Oracles for the antimicrobial peptides task.
Oracle Training points Model Layers Hidden units Training Epochs
f1 3447 MLP 2 512 51
f2 3348 MLP 2 512 51
fM 6795 MLP 2 1024 101
We design a three-oracle setup ( fM,f2,f1) where each oracle is a different neural network model. The
configurations of the oracle models are presented in Table 3. Biologically, each antimicrobial peptide can
be classified into an antimicrobial group. fMis trained on the entire dataset D1. However, for f1andf2,
we divideD1into two approximately equally-sized disjoint subsets. This simulated a setup wherein each
lower fidelity oracle specialised in different sub-regions of the entire sample space. We set costs λM= 50and
λ1=λ2= 0.5asf1andf2have similar configurations. The explained variance of f1andf2(with respect
tofM) on a uniform test set, D3was0.1435and0.099respectively. For the surrogate, we implement deep
kernel learning with the hyperparameters detailed in Table 4. The active learning acquisition batch size B
is32.
Table 4: Deep kernel hyperparameters for the DNA and antimicrobial tasks.
Architecture hyperparameter Value
Number of layers 8
Number of heads 8
Latent dimension 64
GP likelihood variance init. 0.25
GP length scale prior N(0.7, 0.01)
Number of SGVP inducing points 64Optimisation hyperparameter Value
Batch size 128
Learning rate 1e-3
Adam EMA parameters (β1,β2)(0.0, 1e-2)
Maximum number of epochs 512
Early stopping patience 15
Early stopping holdout ratio 0.1
23Published in Transactions on Machine Learning Research (07/2024)
C.5.3 Small Molecules
For the experiments with small molecules, we construct a three oracle setup ( fM,f2,f1) with costs rep-
resenting the actual compute time. We implement the oracles using RDKit 2023.03 (rdk, 2023) and the
semi-empirical quantum chemistry package xTB. We use GFN2-xTB (Bannwarth et al., 2019) method for
the single point calculation of ionisation potential (IP) and electron affinity (EA) with empirical correction
terms.
Inf1, we consider one conformer obtained by RDKit with its geometry optimised via the force-field MMFF94
(Halgren, 1996). This geometry is used to calculate (vertical) IP/EA. In f2, we consider two conformers
obtained by RDKit, and take the lowest energy conformer after optimisation by MMFF94, and further
optimiseit viaGFN2-xTBto obtaintheground state geometry; thisremains averticalIP/EA calculation. In
fM, we consider four conformers obtained by RDKit, and take the lowest energy conformer after optimisation
by MMFF94, and further optimise it via GFN2-xTB; the corresponding ion is then optimised by GFN2-
xTB, and the adiabatic energy difference is obtained via total electronic energy. The fidelities are based
on the fact that vertical IP/EA approximates that of adiabatic ones (to varying degrees, depending on the
molecule). On a uniform test set of 1400 molecules, the explained variance of f1andf2(with respect to fM)
is0.1359,0.279and0.79,0.86for the EA and IP tasks respectively.
The surrogate model is a deep kernel with the hyperparameters are provided in Table 5. The active learning
acquisition batch size Bis128. In the environment for GFN, we consider a set of SELFIES vocabularies
containing aliphatic and aromatic carbon, boron, nitrogen, oxygen, fluorine, sulfur, phosphorous, chlorine,
and bromine, subject to standard valency rules.
Table 5: Deep Kernel hyperparameters for the molecular tasks
Architecture hyperparameter Value
Number of layers 8
Number of heads 8
Latent dimension 32
GP likelihood variance init. 0.25
GP length scale prior N(0.7, 0.01)
Number of SGVP inducing points 64Optimisation hyperparameter Value
Batch size 128
Learning rate 1e-3
Adam EMA parameters (β1,β2)(0.0, 1e-2)
Maximum number of epochs 512
Early stopping patience 15
Early stopping holdout ratio 0.1
We note that this is proof-of-concept and hence neither do we conduct a full search of conformers, nor do
we perform Density Functional Theory calculations. Nonetheless, we observe that the highest fidelity oracle
has a good correlation with experiments (Neugebauer et al., 2020). We do not consider synthesisability in
this study and we note it may negatively impact GFN as unphysical molecules could produce false results
for the semi-empirical oracle.
D Metrics
In this section, we provide additional details about the metrics used for the evaluation of the proposed
MF-GFN as well as the baselines.
Since we are interested in discovering multiple objects with high scores, instead of only one, in order to
compute our evaluation metrics, we consider the set of top- Kcandidates in the data set D. Formally, let
Dj1be the data set after active learning round j:
Dj={x1,x2,...,xn},
such thatfM(xi)≥fM(xj),∀i<j. Then, we define the set of top- Kcandidates as
1Rigorously, the data set consists of triplets (xi, fmi(xi), mi), as defined in Section 3. Here, for better readability, we simplify
the notation and define the data set in terms of the candidates xionly.
24Published in Transactions on Machine Learning Research (07/2024)
top-K(Dj) ={xi|xi∈Dj,fM(xi)≥fM(xK),1≤i≤K}.
Note that, for evaluation purposes, the top- Kset is selected according to the highest-fidelity oracle fM(xi)
and not the oracle selected by the algorithm for the candidate, fmi(xi).
Meantop- KscoreWeadaptthismetricfromBengioetal.(2021a), whichismeanttoreflecttheabilityof
the algorithm to discover multiple high-scoring samples. This metric is the mean value of the highest-fidelity
oracle across the top- Kset:
mean (top-K(Dj)) =1
KK/summationdisplay
i=1fM(xi). (4)
Top-Kdiversity This metric is meant to reflect the ability of the algorithm to discover diverse samples.
In order to measure the diversity of the top- Kset of candidates for each of the tasks, we use use one minus
the similarity index, which is equal to one if all sequences/molecules in a batch are identical, and zero if all
sequences/molecules are maximally different. Specifically,
diversity (top-K(Dj)) = 1−1/parenleftbigK
2/parenrightbig/summationdisplay
xi,xk∈Dj
xi̸=xks(xi,xk), (5)
wheres(xi,xj)is a similarity measure between elements xi, andxk.
•DNA aptamers : The similarity measure is calculated by the mean pairwise sequence identity
within a set of DNA sequences. The higher the sequence identity, the more similar the sequences
are. We utilize global alignment with the Needleman-Wunsch algorithm and standard nucleotide
substitution matrix, as calculated by the Biotite package (Kunzmann & Hamacher, 2018). Here,
s(xi,xk) =Number of matching nucleotides
Total number of nucleotides in the alignment.
•Antimicrobial peptides : The similarity measure is calculated by the mean pairwise sequence
identity within a set of peptide sequences. The higher the sequence identity, the more similar the
sequences are. We utilize global alignment with the Needleman-Wunsch algorithm and BLOSUM62
substitution matrix, as calculated by the Biotite package (Kunzmann & Hamacher, 2018). Here,
s(xi,xk) =Number of matching aminoacids
Total number of aminoacids in the alignment.
•Molecules : The similarity measure is calculated by the mean pairwise Tanimoto similarity within a
set of molecules. The higher the Tanimoto similarity, the more similar the molecules are. Tanimoto
metrics are calculated from Morgan Fingerprints (radius of two, size of 2048 bits) as implemented
in the RDKit package (rdk, 2023). Here, s(xi,xk) =|F(xi)∩F(xk)|
|F(xi)∪F(xk)|.
Mean diverse top- KscoreThis is an alternative version to the mean top- Kscore metric by which
we restrict the selection of the Kcandidates to data points that are diverse between each other. We use
similarity measures ( vide infra ) such that we sample the top- Kcandidates where each candidate is at most
similar to each other by a certain threshold. For antimicrobial peptides, the sequence identity threshold
is 0.35; for DNA aptamers, the sequence identity threshold is 0.60; for molecules, the Tanimoto similarity
distance threshold is 0.35. The results using this metric are reported in Appendix E.
E Additional Results
This section includes additional results and ablation studies to complement the analysis presented in the
main body of the paper.
25Published in Transactions on Machine Learning Research (07/2024)
E.1 Energy of Diverse Top- K
In this section, we complement the results presented in Section 4 with the mean diverse top- Kscores, as
defined in Appendix D. This metric combines that mean top- Kscore and the measure of diversity. Figure 5
shows the results on the DNA, AMP and the molecular tasks.
102
101
100
Fraction of total SF-GFN budget (log)02468Mean Top-100 energySF-GFN
Random
Rand. fid. GFNMF-PPO
MF-GFN
(a) DNA task
103
102
101
100
Fraction of total SF-GFN budget (log)0.00.20.40.60.8Mean Top-50 energy (b) Anti-microbial peptides (AMP) task
101
100
Fraction of total SF-GFN budget (log)9
8
7
6
5
Mean Top-100 energy [eV]SF-GFN
Random
Rand. fid. GFNMF-PPO
MF-GFN
(c) Molecules ionisation potential (IP) task
101
100
Fraction of total SF-GFN budget (log)12345Mean Top-100 energy [eV]SF-GFN
Random
Rand. fid. GFN
MF-GFN (d) Molecules electron affinity (EA) task
Figure 5: Mean scores (energy) of diverse top- Kcandidates on the DNA (top left), AMP (top right) and
molecular (bottom) tasks. The mean energy is computed across the top- Kcandidates at each active learning
round that also satisfy the criteria of diversity. Consistent with the diversity metrics observed in Fig. 2,
we here see that GFlowNet-based methods, and especially MF-GFN, obtain good results according to this
metric, while MF-PPO achieves comparatively much lower mean energy.
The results with this metric allow us to further confirm that multi-fidelity active learning with GFlowNets
is able to discover sets of diverse candidates with high mean scores, as is sought in many scientific discovery
applications. In contrast, methods that do not encourage diversity such as RL-based algorithms (MF-PPO)
obtain comparatively much lower results with this metric.
E.2 Impact of Oracle Costs
As discussed in Appendix B.3, a multi-fidelity acquisition function like the one we use—defined in Eq. (3)—is
a cost-adjusted utility function. Consequently, the cost of each oracle plays a crucial role in the utility of
acquiring each candidate. In our tasks with small molecules (Section 4.3.3), for instance, we used oracles with
costs proportional to their computational demands and observed that multi-fidelity active learning largely
outperforms single-fidelity active learning. However, depending on the costs of the oracles, the advantage of
multi-fidelity methods can significantly diminish.
26Published in Transactions on Machine Learning Research (07/2024)
In order to analyse the impact of the oracle costs on the performance of MF-GFN, we run several experiments
on the DNA task (Section 4.3.1), which consists of two oracles, with additional sets of oracle costs. In
particular, besides the costs used in the experiments presented in Section 4.3.1, (0.2,20)for the lowest and
highest fidelity oracles, we run experiments with costs (1,20)and(10,20). Additionally, we perform similar
experiments on the Hartmann task with 5 sets of oracle costs.
The results on the DNA task, presented in Fig. 6a, indeed confirm that the advantage of MF-GFN over SF-
GFN decreases as the cost of the lowest-fidelity oracle becomes closer to the cost of the highest-fidelity oracle.
However, it is remarkable that even with a ratio of costs as small as 1 : 2, MF-GFN still outperforms not
only SF-GFN but also MF-PPO in terms of cost effectiveness, without diversity being negatively impacted.
It is important to note that in practical scenarios of scientific discovery, the cost of lower fidelity oracles
is typically orders of magnitude smaller than the cost of the most accurate oracles, since the latter may
correspond to wet-lab experiments or expensive computer simulations. The results on the Hartmann task
(Fig. 6b) further confirm the above conclusions.
0.2 0.4 0.6 0.8 1.0
Fraction of total SF-GFN budget46810121416Mean Top-100 energySF-GFN
MF-PPO
MF-GFN (0.2, 20)
MF-GFN (1, 20)
MF-GFN (10, 20)
0.50 0.55 0.60 0.65 0.70 0.75 0.80 0.85Diversity
(a) DNA
0.2 0.4 0.6 0.8 1.0
Fraction of total SF-GFN budget1.01.52.02.53.0Mean Top-10 scoreMF-GFN orig. (0.125, 0.25, 1.0)
MF-GFN (0.25, 0.5, 1)
MF-GFN (0.5, 0.5, 1)
MF-GFN (0.5, 0.75, 1)
MF-GFN (0.8, 0.8, 1)
SF-GFN (b) Hartmann
Figure 6: Analysis of the impact of the oracle costs on the performance of MF-GFN on the DNA task and
the synthetic Hartmann task. On the DNA task, we observe that the advantage over SF-GFN and MF-PPO
(0.2, 20) decreases as the cost of the lower fidelity oracle becomes closer to the cost of the highest fidelity
oracle. Nonetheless, even with a cost ratio of 1 : 2MF-GFN displays remarkable performance with respect
to other methods. Similar conclusions can be drawn from the analysis on the Hartmann task.
E.3 Impact of the Acquisition Batch Size
We evaluate the impact of the active learning acquisition batch size Bon the performance of MF-GFN and
its comparison with the baselines for the small molecules IP task with different acquisition batch sizes. From
the results in Fig. 7, we notice that the reward curve becomes slightly steeper with larger batch sizes.
E.4 Impact of the Choice of the Final Candidate Set Size
For the set of results presented in the main paper, we computed the mean top- Kenergy and diversity on the
final batch of candidates of size K= 100. While the choice of Kis not arbitrary as it is related to the active
learning acquisition size and in turn to reasonable numbers in the domains of application, it is interesting to
study whether our conclusions are robust to other choices of K. In Fig. 8, we provide the equivalent set of
results for all the tasks with K= 50and in Fig. 9 with K= 200, half and double the size, respectively.
In view of these results, we can conclude that the results are robust to the choice of this parameter, since
we can derive the same conclusions for all values of K∈{50,100,200}: MF-GFN obtains the best trade-off
between mean energies and diversity, all other GFlowNet-based methods are able to discover diverse samples
and using PPO as the sampler discovers high-scoring samples but strongly lacks diversity.
27Published in Transactions on Machine Learning Research (07/2024)
101
100
Fraction of total SF-GFN budget (log)10
9
8
7
6
5
4
Mean Top-100 energy [eV]MF-GFN 64
SF-GFN 64
MF-GFN 128 (orig.)
SF-GFN 128 (orig.)
MF-GFN 256
SF-GFN 256
0.035 0.040 0.045 0.050 0.055Diversity
Figure 7: Impact of the acquisition size (64/128/256) on the small molecules (IP) task.
0.2 0.4 0.6 0.8 1.0
Fraction of total SF-GFN budget4681012141618Mean Top-50 energySF-GFN
Random
Rand. fid. GFNMF-PPO
MF-GFN
0.50 0.55 0.60 0.65 0.70 0.75 0.80 0.85Diversity
(a) DNA aptamers task
103
102
101
100
Fraction of total SF-GFN budget (log)0.50.60.70.8Mean Top-50 energy
0.2 0.3 0.4 0.5 0.6 0.7 0.8Diversity (b) AMP task
0.2 0.4 0.6 0.8 1.0
Fraction of total SF-GFN budget8
7
6
5
4
Mean Top-50 energy [eV]SF-GFN
Random
Rand. fid. GFNMF-PPO
MF-GFN
0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.45Diversity
(c) Molecules IP task
0.2 0.4 0.6 0.8 1.0
Fraction of total SF-GFN budget2.02.53.03.54.04.55.05.5Mean Top-50 energy [eV]SF-GFN
Random
Rand. fid. GFNMF-PPO
MF-GFN
0.1 0.2 0.3 0.4 0.5 0.6 0.7Diversity (d) Molecules EA task
Figure 8: Results as in the original figures, but with K= 50, instead of K= 100.
E.5 Visualisation of Sampled Candidates
Given that MF-GFN conducts a cost-aware search with the help of the multi-fidelity acquisition function,
our expectation is that the algorithm will selectively query the less costly oracles for input space exploration
and will query the more expensive oracles on high-reward candidates. To substantiate this hypothesis, we
28Published in Transactions on Machine Learning Research (07/2024)
0.2 0.4 0.6 0.8 1.0
Fraction of total SF-GFN budget246810121416Mean Top-200 energySF-GFN
Random
Rand. fid. GFNMF-PPO
MF-GFN
0.50 0.55 0.60 0.65 0.70 0.75 0.80 0.85Diversity
(a) DNA aptamers task
103
102
101
100
Fraction of total SF-GFN budget (log)0.500.550.600.650.700.750.80Mean Top-200 energy
0.2 0.3 0.4 0.5 0.6 0.7 0.8Diversity (b) AMP task
0.2 0.4 0.6 0.8 1.0
Fraction of total SF-GFN budget10
9
8
7
6
5
Mean Top-200 energy [eV]SF-GFN
Random
Rand. fid. GFNMF-PPO
MF-GFN
0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.45Diversity
(c) Molecules IP task
0.2 0.4 0.6 0.8 1.0
Fraction of total SF-GFN budget1234Mean Top-200 energy [eV]SF-GFN
Random
Rand. fid. GFNMF-PPO
MF-GFN
0.1 0.2 0.3 0.4 0.5 0.6 0.7Diversity (d) Molecules EA task
Figure 9: Results as in the original figures, but with K= 200, instead of K= 100.
provide a two-dimensional visualisation (Fig. 10) of the sampled candidates after expending the allocated
budget in the synthetic Branin task (Appendix C.4.1).
Overall, we observe that the lower-fidelity oracles are queried extensively for exploration of a relatively large
portion of the sample space, while the highest-fidelity oracle tends to be queried near the modes of the
objective function.
E.6 GFlowNet with random fidelities proportional to inverse of cost
In Section 4.2, we describe the baselines used as comparisons against MF-GFN. The set of baselines includes
a slight but relevant modification of MF-GFN, where the policy to select the fidelity of each candidate is
not learnt by the GFlowNet but sampled randomly from a uniform distribution (Random fid. GFN). This
comparison has allowed us to conclude that the GFlowNet variant that we have introduced, which learns to
sample tuples of candidate and fidelity, obtains better results.
A reasonable alternative to sampling the fidelity from a uniform distribution is to sample the fidelity from a
distribution proportional to the inverse of the cost, that is p(m|x)∝1
λm. In order to verify whether this is
a significantly stronger baseline than Random fid. GFN, the experiments in Fig. 11 show a comparison on
the Hartmann task. As a main conclusion, the two baselines with random fidelities perform very similarly
and not better than MF-GFN. A limitation of this analysis is that the simplicity of the Hartmann task does
not allow MF-GFN to obtain a large advantage with respect to these baselines.
29Published in Transactions on Machine Learning Research (07/2024)
5
 4
 3
 2
 1
 0 1 2 3 4 5 6 7 8 9 10
X-Axis0123456789101112131415Y-AxisCost: 0.01
Cost: 0.1
Cost: 1
Mode
Training Point
Figure 10: We present a visualisation of the sampled candidates (x,m)in the synthetic Branin task (Ap-
pendix C.4.1). The domain of Branin is defined in [−5,10]×[0,15]. Each round marker, identified by
grid-specific coordinates, represents a sampled candidate, x. The markers are colour-coded based on the
oracle the candidate is to be evaluated with, m. Our observation reveals that the lower fidelity oracles (with
costs of 0.01and0.1) are primarily used for exploration across the input domain, while evaluations using the
high-fidelity oracle (cost= 1) are predominantly concentrated near the modes (denoted by the star marker).
Note that the training points were intentionally chosen to exclude the modes.
A closer analysis of the results indicates that sampling the fidelities proportionally to1
λmis strongly biased
towards selecting the lowest fidelity. This may result in the stagnation of the improvement as the active
learning algorithm progresses, since most often the lowest fidelity is selected, preventing the algorithm to
get closer to the modes of the objective function. Given the positive results of MF-GFN in the rest of the
experiments and its nearly negligible overhead with respect to these baselines, we conclude that learning the
fidelity rather than selecting it at random is a favourable choice.
0.2 0.4 0.6 0.8 1.0
Fraction of total SF-GFN budget2.953.003.053.103.153.20Mean Top-10 scoreMF-GFN
MF-GFN Cost-based fidelities
MF-GFN Uniform fidelities
Figure 11: Evaluation of the performance of the MF-GFN baseline which samples the fidelity mfrom a
distribution proportional to the inverse of the oracle cost1
λm. These experiments are on the Hartmann task.
We observe that this alternative baseline performs similarly to the one included in the main results section.
30