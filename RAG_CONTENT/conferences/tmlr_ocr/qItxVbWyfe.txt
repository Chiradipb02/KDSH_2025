Published in Transactions on Machine Learning Research (05/2024)
Federated Learning with Convex Global and Local Con-
straints
Chuan He he000233@umn.edu
Department of Computer Science and Engineering, University of Minnesota
Le Peng peng0347@umn.edu
Department of Computer Science and Engineering, University of Minnesota
Ju Sun jusun@umn.edu
Department of Computer Science and Engineering, University of Minnesota
Reviewed on OpenReview: https: // openreview. net/ forum? id= qItxVbWyfe
Abstract
In practice, many machine learning (ML) problems come with constraints, and their applied
domains involve distributed sensitive data that cannot be shared with others, e.g., in health-
care. Collaborative learning in such practical scenarios entails federated learning (FL) for
ML problems with constraints, or FL with constraints for short. Despite the extensive de-
velopments of FL techniques in recent years, these techniques only deal with unconstrained
FL problems or FL problems with simple constraints that are amenable to easy projections.
There is little work dealing with FL problems with general constraints. To fill this gap,
we take the first step toward building an algorithmic framework for solving FL problems
with general constraints. In particular, we propose a new FL algorithm for constrained ML
problems based on the proximal augmented Lagrangian (AL) method. Assuming convex
objective and convex constraints plus other mild conditions, we establish the worst-case
complexity of the proposed algorithm. Our numerical experiments show the effectiveness
of our algorithm in performing Neyman-Pearson classification and fairness-aware learning
with nonconvex constraints, in an FL setting.
1 Introduction
Federated learning (FL) has emerged as a prominent distributed machine learning (ML) paradigm that
respects data privacy by design and has found extensive applications in diverse domains (Kairouz et al.,
2021). In FL, ML models are trained without centralized training data: local clients hold their local data
and never directly share them with other clients or the central server. Given a global ML model to train,
typical FL strategies consist of repeated local computation and central aggregation: in each round, each
local client performs local computation of quantities of interest (e.g., local model parameters or derivatives)
based on the local data, and then the central server collects and aggregates the local results and updates the
parameters of the global ML model. Since the shared local results are usually highly nonlinear functions of
local data, making reverse engineering of local data unlikely, data privacy is naturally protected.
1.1 Federated learning for constrained machine learning problems
However, existing FL techniques are developed almost exclusively for unconstrained ML problems or, at best,
for ML problems with simple constraints that are amenable to easy projections, despite the growing list of
ML problems with general constraints—where constraints typically encode prior knowledge and desired
properties, e.g., robustness evaluation (Goodfellow et al., 2014), fairness-aware learning (Agarwal et al.,
2018), learning with imbalanced data (Saito & Rehmsmeier, 2015), neural architecture search (Zoph et al.,
1Published in Transactions on Machine Learning Research (05/2024)
2018), topologyoptimization(Christensen&Klarbring,2008), physics-informedmachinelearning(McClenny
& Braga-Neto, 2020). Here, we sketch two quick examples.
Neyman-Pearson classification, or optimizing the false-positive rate with a controlled false-
negative rate Conventional binary classification assumes equal importance in both classes, so predictive
errors in both classes are counted equally. In numerous applications, such as medical diagnosis, misclassifying
one class (i.e., the priority class) is much more costly than misclassifying the other. The Neyman-Pearson
classification framework addresses this asymmetry in misclassification cost by explicitly controlling the error
rate in the priority class while optimizing that in the other (Tong et al., 2016; Scott, 2007; Rigollet & Tong,
2011; Tong et al., 2018):
min
θ1
n0n0/summationdisplay
i=1φ(fθ,zi,0) s.t.1
n1n1/summationdisplay
i=1φ(fθ,zi,1)≤r, (1)
wherefθis the trainable binary classifier parameterized by θ,φis the loss function serving as a proxy to
classification error, and {zi,0}n0
i=1and{zi,1}n1
i=1are the training data from class 0and1, respectively. The
constraint imposes an upper bound on the error rate for class 1.
Fairness-aware learning Typical ML models are known to have biases toward the majority subgroups
of the input space (Agarwal et al., 2018; Celis et al., 2019; Mehrabi et al., 2021). For example, a disease
diagnostic model that is trained on a male-dominant dataset tends to predict much more accurately on
the male subgroup than on the female subgroup. To counteract such potential model biases, a natural
way is to enforce fairness constraints to ensure that the performance of the model on different subgroups
is comparable (Agarwal et al., 2018; Celis et al., 2019; Mehrabi et al., 2021). A possible formulation for
two-subgroup problems is
min
θ1
n′n′/summationdisplay
i=1φ(fθ,zi) s.t.−δ≤1
|S0|/summationdisplay
i∈S0φ(fθ,zi)−1
|S1|/summationdisplay
i∈S1φ(fθ,zi)≤δ, (2)
wherefθis the ML model parameterized by θ,{zi}is the training set, and φis the proxy loss function,
similar to the setup in Eq. (1). With S0andS1denoting the two subgroups of interest, the constraint
imposes that the performance disparity of fθonS0andS1should not be larger than δ>0, which is usually
set close to 0.
Both examples are particularly relevant to biomedical problems, where class imbalance and subgroup imbal-
ance are prevalent. Moreover, there are strict regulations on the distribution and centralization of biomedical
data for research, e.g., the famous Health Insurance Portability and Accountability Act (HIPAA) protection
of patient privacy (OCR, 2023). Together, these underscore the importance of developing FL techniques
for constrained ML problems, which is largely lacking: FL problems with only simple constraints that are
amenable to easy projections have been considered in Yuan et al. (2021); Tran Dinh et al. (2021), and a small
number of papers have tried to mitigate class imbalance (Shen et al., 2021) and improve model fairness (Du
et al., 2021; Chu et al., 2021; Gálvez et al., 2021) through constrained optimization in FL settings. However,
these developments are specialized to their particular use cases and lack computational guarantees for the
feasibility and optimality of their solutions.
In this paper, we take the first step toward a general and rigorous FL framework for general constrained ML
problems . Consider the constrained ML problems in Eqs. (1) and (2) in an FL setting with nlocal clients,
where theithclient holds local data Ziand so the whole training set is the union Z1∪···∪Zn. Since the
objectives and constraints in Eqs. (1) and (2) are in the finite-sum form, both examples are special cases of
the following finite-sum constrained optimization problem:
min
θ/braceleftiggn/summationdisplay
i=1fi(θ;Zi) +h(θ)/bracerightigg
s.t.n/summationdisplay
i=1˜ci(θ;Zi)≤0.
/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
local data coupled(3)
2Published in Transactions on Machine Learning Research (05/2024)
Note that inside the constraint, the local data are coupled which necessarily lead to communication between
thelocalclientsandthecentralservertoallowtheevaluationoftheconstraintfunction. Totrytoreducesuch
communication so that we can have more flexibility in algorithm design, we introduce decoupling variables
{si}, leading to an equivalent formulation:
min
θ,si/braceleftiggn/summationdisplay
i=1fi(θ;Zi) +h(θ)/bracerightigg
s.t.n/summationdisplay
i=1si≤0,
/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
no local data˜ci(θ;Zi)≤si,1≤i≤n/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
local data decoupled, (4)
which decouples the local data into nlocal constraints.
In this paper, we consider the following setup for FL with global and local constraints, a strict generalization
of Eq. (4):
min
w/braceleftiggn/summationdisplay
i=1fi(w;Zi) +h(w)/bracerightigg
s.t. c 0(w;Z0)≤0/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
global constraint, ci(w;Zi)≤0,1≤i≤n/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
local constraints. (5)
In contrast to unconstrained FL or FL with simple constraints amenable to easy projections studied in
existing literature, our focus lies on general convex constraints, where projections may or may not be easy to
compute. Here, we assume nlocal clients, each with a local objective fi(w;Zi)and a set of local constraints
ci(w;Zi)≤0(i.e., scalar constraints are vectorized) for i= 1,...,n. To stress the FL setting, we spell out
the dependency of these local objectives and local constraints on the local data Zi’s:theseZi’s are only
accessible to their respective local clients and should never be shared with other local clients or the central
server. Henceforth, we omit Zi’s in local objectives and constraints when no confusion arises. To allow
flexibility in modeling, we also include the global constraint c0(w;Z0)≤0, with central data Z0that is only
accessiblebythecentralserver. Tofacilitatethetheoreticalstudyofthealgorithmthatwedevelop,wefurther
assume that all objectiveand scalarconstraint functionsare convex, butwealso verify theapplicability ofour
FL algorithm to classification problems with nonconvex fairness constraints in Section 5.2. To summarize,
our standing assumptions on top of Eq. (5) include
Assumption 0. We make the following assumption throughout this paper:
(a) The objective functions fi:Rd→R,1≤i≤n, and themiscalar constraint functions inside ci:Rd→
Rmi,0≤i≤n, are convex and continuously differentiable, and h:Rd→(−∞,∞]is a simple closed
convex function.
(b) For each 1≤i≤n, only the local objective fiand local constraint cihave access to the local data Zi,
which are never shared with other local clients and the central server. Only the central server has access
to the global data Z0,
1.2 Our contributions
ThispapertacklesEq.(5)byadoptingthesequentialpenalizationapproach,whichinvolvessolvingasequence
of unconstrained subproblems that combine the objective function with penalization of constraint violations.
In particular, we propose an FL algorithm based on the proximal augmented Lagrangian (AL) method
developed in Lu & Zhou (2023). In each iteration, the unconstrained subproblem is solved by an inexact
solver based on the alternating direction method of multipliers (ADMM) in a federated manner. We study
the worst-case complexity of the proposed algorithm assuming locallyLipschitz continuous gradients. Our
main contributions are highlighted below.
•We propose an FL algorithm (Algorithm 1) for solving Eq. (5) based on the proximal AL method. To the
best of our knowledge, the proposed algorithm is the first in solving general constrained ML problems in
an FL setting. Assuming locallyLipschitz continuous gradients and other mild conditions, we establish
its worst-case complexity to find an approximate optimal solution of Eq. (5). The complexity results are
entirely new in the literature.
•We propose an ADMM-based inexact solver in Algorithm 2 to solve the unconstrained subproblems arising
in Algorithm 1. We equip this inexact solver with a newly introduced verifiable termination criterion and
3Published in Transactions on Machine Learning Research (05/2024)
establish its global linear convergence for solving the subproblems of Algorithm 1; these subproblems are
strongly convex and have locally Lipschitz continuous gradients.
•We perform numerical experiments to compare our proposed FL algorithm (Algorithm 1) with the central-
ized proximal AL method (Algorithm 3) on binary Neyman-Pearson classification and classification with
nonconvex fairness constraints using real-world datasets (Section 5). Our numerical results demonstrate
that our FL algorithm can achieve solution quality comparable to that of the centralized proximal AL
method.
1.3 Related work
FL algorithmsfor unconstrained optimization FL has emerged as a cornerstone for privacy-preserved
learning since Google’s seminal work (McMahan et al., 2017), and has found applications in numerous
domains where the protection of data privacy precludes centralized learning, including healthcare (Rieke
et al., 2020; Peng et al., 2023a;b), finance (Long et al., 2020), Internet of things (Mills et al., 2019), and
transportation Liu et al. (2020). FedAvg (McMahan et al., 2017) is the first and also the most popular FL
algorithm to date. After FedAvg, numerous FL algorithms have been proposed to improve performance and
address practical issues, such as data heterogeneity (Karimireddy et al., 2020; Li et al., 2021c; Zhang et al.,
2021), system heterogeneity (Li et al., 2020; Wang et al., 2020; Gong et al., 2022), fairness (Li et al., 2021b),
communication efficiency (Sattler et al., 2019; Konečn` y et al., 2016; Mishchenko et al., 2022), convergence
(Pathak & Wainwright, 2020), handling simple constraints (Yuan et al., 2021; Tran Dinh et al., 2021),
incentives (Travadi et al., 2023), and hyperparameter tuning (Yao et al., 2024). Since our FL algorithm
relies on applying an inexact ADMM (Algorithm 2) to solve subproblems, it is also worth mentioning that
ADMM-based algorithms have been proposed to handle FL problems (Zhou & Li, 2023; Gong et al., 2022;
Zhang et al., 2021) and optimization problems with many constraints in a distributed manner (Giesen &
Laue, 2019). More FL algorithms and their applications can be found in the survey (Li et al., 2021a).
Despite the intensive research on FL, existing algorithms focus primarily on unconstrained ML problems,
versus constrained ML problems considered in this paper.
Centralized algorithms for constrained optimization Recent decades have seen fruitful algorithm
developments for centralized constrained optimization in numerical optimization. In particular, there has
beenarichliteratureonALmethodsforsolvingconvexconstrainedoptimizationproblems(Aybat&Iyengar,
2013; Necoara et al., 2019; Patrascu et al., 2017; Xu, 2021; Lan & Monteiro, 2016; Lu & Zhou, 2023; Lu
& Mei, 2023). In addition, variants of AL methods have been developed to solve nonconvex constrained
optimization problems (Hong et al., 2017; Grapiglia & Yuan, 2021; Birgin & Martínez, 2020; Kong et al.,
2023; Li et al., 2021d; He et al., 2023a;b; Lu, 2022). Besides AL methods and their variants, sequential
quadratic programming methods (Boggs & Tolle, 1995; Curtis & Overton, 2012), trust-region methods
(Byrd et al., 1987; Powell & Yuan, 1991), interior point methods (Wächter & Biegler, 2006), and extra-point
methods Huang et al. (2022) have been proposed to solve centralized constrained optimization problems.
Distributed algorithms for constrained optimization Developing distributed algorithms for con-
strained optimization has started relatively recently. To handle simple local constraints in distributed opti-
mization, Nedic et al. (2010); Lin et al. (2016); Wang et al. (2017) study distributed projected subgradient
methods. For complicated conic local constraints, Aybat & Hamedani (2016; 2019) develop distributed
primal-dual algorithms. For distributed optimization with global and local constraints, Zhu & Martínez
(2011); Yuan et al. (2011) develop primal-dual projected subgradient algorithms. For an overview of dis-
tributed constrained optimization, see Yang et al. (2019). Notice that FL is a special distributed optimiza-
tion/learning framework that protects data privacy by prohibiting the transfer of raw data from one client
to another or to a central server. These distributed algorithms for constrained optimization do not violate
the FL restriction and hence can be considered as FL algorithms, but they can only handle problems with
simple global or local constraints that are amenable to easy projection. Therefore, they cannot be applied
directly to our setup Eq. (5) with general global and local constraints.
FL algorithms for constrained ML applications A small number of papers have developed FL algo-
rithms for particular constrained ML applications, such as learning with class imbalance and fairness-aware
4Published in Transactions on Machine Learning Research (05/2024)
ML. For example, Shen et al. (2021); Chu et al. (2021) propose FL algorithms to address class imbalance and
subgroup imbalance, respectively, by optimizing the Lagrangian function. Du et al. (2021) applies quadratic
penalty method to deal with the constraint in fairness-aware ML. In addition, Gálvez et al. (2021) pro-
poses an FL algorithm to tackle fairness-aware ML based on optimizing the AL function. However, these
developments are tailored to specific applications and lack rigorous computational guarantees regarding the
feasibility and optimality of their solutions. In contrast, this paper focuses on developing algorithms with
theoretical guarantees for FL with convex global and local constraints. To the best of our knowledge, this
work provides the first general FL framework for constrained ML problems.
2 Notation and preliminaries
Throughout this paper, we let RdandRd
+denote the d-dimensional Euclidean space and its nonnegative
orthant, respectively. We use ⟨·,·⟩to denote the standard inner product, ∥·∥to denote the Euclidean norm
of a vector or the spectral norm of a matrix, and ∥·∥∞to denote the ℓ∞-norm of a vector. For any vector
v∈Rd,[v]+∈Rdis its nonnegative part (i.e., with all negative values set to zero). We adopt the standard
big-O notationO(·)to present complexity results; /tildewideO(·)representsO(·)with logarithmic terms omitted.
Given a closed convex function h:Rd→(−∞,∞],∂handdom(h)denote the subdifferential and domain
ofh, respectively. The proximal operator associated with his denoted by proxh, that is, proxh(u) =
arg minw{∥w−u∥2/2 +h(w)}for allu∈Rd. Given a continuously differentiable mapping ϕ:Rd→Rp,
we write the transpose of its Jacobian as ∇ϕ(w) = [∇ϕ1(w)··· ∇ϕp(w)]∈Rd×p. We say that∇ϕisL-
Lipschitz continuous on a set Ωfor someL>0if∥∇ϕ(u)−∇ϕ(v)∥≤L∥u−v∥for allu,v∈Ω. In addition,
we say that∇ϕis locally Lipschitz continuous on Ωif for anyw∈Ω, there exist Lw>0and an open set
Uwcontainingwsuch that∇ϕisLw-Lipschitz continuous on Uw.
Given a nonempty closed convex set C⊆Rdand any point u∈Rd,dist(u,C)anddist∞(u,C)stand for the
Euclideandistanceand theChebyshevdistance from utoC, respectively. Thatis, dist(u,C) = minv∈C∥u−v∥
anddist∞(u,C) = minv∈C∥u−v∥∞. The normal cone of Catu∈Cis denoted byNC(u). The Minkowski
sum of two setsBandCis defined asB+C:={b+c:b∈B,c∈C}.
For ease of presentation, we let m:=/summationtextn
i=0miand adopt the following notations throughout this paper:
f(w) =n/summationdisplay
i=1fi(w), c (w) =/bracketleftiggc0(w)
...
cn(w)/bracketrightigg
∈Rm, µ =/bracketleftiggµ0
...
µn/bracketrightigg
∈Rm. (6)
Assumption 1. Throughout this paper, we assume that the strong duality holds for Eq. (5)and its dual
problem
sup
µ≥0inf
w{f(w) +h(w) +⟨µ,c(w)⟩}. (7)
That is, both problems have optimal solutions and, moreover, their optimal values coincide.
Under Assumption 1, it is known that (w,µ)∈dom(h)×Rm
+is a pair of optimal solutions of Eq. (5) and
Eq. (7) if and only if it satisfies (see, e.g., Lu & Zhou (2023))
0∈/parenleftbigg∇f(w) +∂h(w) +∇c(w)µ
c(w)−N Rm
+(µ)/parenrightbigg
. (8)
In general, it is hard to find an exact optimal solution of Eq. (5) and Eq. (7). Thus, we are instead interested
in seeking an approximate optimal solution of Eq. (5) and Eq. (7) defined as follows.
Definition 1. Given anyϵ1,ϵ2>0, we say (w,µ)∈dom(h)×Rm
+is an (ϵ1,ϵ2)-optimal solution of Eq. (5)
and Eq.(7)ifdist∞(0,∇f(w) +∂h(w) +∇c(w)µ)≤ϵ1anddist∞(c(w),NRm
+(µ))≤ϵ2.1
1For unconstrained convex problems with differentiable objective minwf(w), a natural measure of convergence is ∥∇f(w)∥,
i.e., the distance between 0and∇f(w), as the optimality condition is ∇f(w) = 0. If the objective is nondifferentiable, we need
to use the notation of subdifferential, ∂f(w), which is a set for each win general. In this case, the optimality condition reads
0∈∂f(w), and the measure of convergence is the distance between 0and the subdifferent set dist(0 , ∂f(w)) := min u∈∂f(w)∥u∥.
5Published in Transactions on Machine Learning Research (05/2024)
Here, the two different tolerances ϵ1,ϵ2are used for measuring stationarity and feasibility violation, respec-
tively. This definition is consistent with the ϵ-KKT solution considered in Lu & Zhou (2023) except that
Definition 1 uses the Chebyshev distance rather than the Euclidean distance.
3 A proximal AL based FL algorithm for solving Eq. (5)
Inthissection, weproposeanFLalgorithmforsolvingEq.(5)basedontheproximalALmethod. Specifically,
we describe this algorithm in Section 3.1, and then analyze its complexity results in Section 3.2.
Assumption 2. Throughout this section, we assume that
(a) The proximal operator for hcan be exactly evaluated.
(b) The gradients ∇fi,1≤i≤n, and the transposed Jocobians ∇ci,0≤i≤n, are locally Lipschitz
continuous on Rd.
Assumption 2(b) clearly holds if all ∇fi’s and∇ci’s are globally Lipschitz continuous on Rd, but this
assumption holds for a broad class of problems without global Lipschitz continuity on ∇fi’s and∇ci’s.
For example, the quadratic penalty function of c(w)≤0, namely∥[c(w)]+∥2, only has a locally Lipschitz
continuous gradient even if ∇cis globally Lipschitz continuous on Rd(see Remark 4.1). In addition, the
gradient of a convex high-degree polynomial, such as ∥w∥4withw∈Rd, is locally Lipschitz continuous but
not globally Lipschitz continuous on Rd.
3.1 Algorithm description
In this subsection, we describe a proximal AL-based FL algorithm (Algorithm 1) for finding an (ϵ1,ϵ2)-
optimal solution of Eq. (5) for prescribed ϵ1,ϵ2∈(0,1). This algorithm follows a framework similar to a
centralized proximal AL method described in Appendix D; see Section 11.K in Rockafellar & Wets (2009)
or Lu & Zhou (2023) for more details of proximal AL. At each iteration, it applies an inexact ADMM solver
(Algorithm 2) to find an approximate solution wk+1to the proximal AL subproblem associated with Eq. (5):
min
w/braceleftigg
ℓk(w) :=n/summationdisplay
i=1fi(w) +h(w) +1
2βn/summationdisplay
i=0/parenleftbig
∥[µk
i+βci(w)]+∥2−∥µk
i∥2/parenrightbig
/bracehtipupleft /bracehtipdownright/bracehtipdownleft /bracehtipupright
augmented Lagrangian function+1
2β∥w−wk∥2
/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
proximal term/bracerightigg
.(9)
Then, the multiplier estimates are updated according to the classical scheme:
µk+1
i= [µk
i+βci(wk+1)]+,0≤i≤n.
Notice that the subproblem in Eq. (9) can be rewritten as
min
w/braceleftigg
ℓk(w) :=n/summationdisplay
i=0Pi,k(w) +h(w)/bracerightigg
, (12)
wherePi,k,0≤i≤n, are defined as
P0,k(w) :=1
2β/parenleftbig
∥[µk
0+βc0(w)]+∥2−∥µk
0∥2/parenrightbig
+1
2(n+ 1)β∥w−wk∥2, (13)
Pi,k(w) :=fi(w) +1
2β/parenleftbig
∥[µk
i+βci(w)]+∥2−∥µk
i∥2/parenrightbig
+1
2(n+ 1)β∥w−wk∥2,∀1≤i≤n.(14)
When Algorithm 2 (see Section 4) is applied to solve Eq. (12), the local merit function Pi,k, constructed
from the local objective fiand local constraint ci, is handled by the respective local client i, while the merit
functionP0,kis handled by the central server. We observe that Algorithm 1 with the subproblem in Eq. (12)
solved by Algorithm 2 meets the basic FL requirement: since local objective fi’s and local constraint ci’s are
handled by their respective local clients and the central server only performs aggregation and handles the
global constraint c0, no raw data are shared between local clients and the central server, i.e., Assumption 0(b)
is obeyed.
6Published in Transactions on Machine Learning Research (05/2024)
Algorithm 1 A proximal AL based FL algorithm for solving Eq. (5)
Input: tolerances ϵ1,ϵ2∈(0,1),w0∈dom(h),µ0
i≥0for0≤i≤n,¯s>0, andβ >0.
1:fork= 0,1,2,...do
2:Setτk= ¯s/(k+ 1)2.
3:Call Algorithm 2 (see Section 4 below) with (τ,˜w0) = (τk,wk)to find an approximate solution wk+1
4:to Eq. (12) in a federated manner such that
dist∞(0,∂ℓk(wk+1))≤τk. (10)
5:Server update: The central server updates µk+1
0= [µk
0+βc0(wk+1)]+.
6:Communication (broadcast): Each local client i,1≤i≤n, receiveswk+1from the central server.
7:Client update (local): Each local client i,1≤i≤n, updatesµk+1
i= [µk
i+βci(wk+1)]+.
8:Communication: Each local client i,1≤i≤n, sends∥µk+1
i−µk
i∥∞to the central server.
9:Termination (server side): Output (wk+1,µk+1)and terminate the algorithm if
∥wk+1−wk∥∞+βτk≤βϵ1, max
0≤i≤n{∥µk+1
i−µk
i∥∞}≤βϵ2. (11)
10:end for
Remark 3.1. We now make the following remarks on Algorithm 1.
(a) For hyperparameters of Algorithm 1,
•ϵ1,ϵ2∈(0,1)only depend on the numerical accuracy that the user aims to achieve;
•the initial iterates w0andµ0
i,1≤i≤n, are usually randomly generated or set as a constant vector;
•¯s > 0controls the tolerance sequence {τk}k≥0for the subproblems in Algorithm 1. These finite,
non-zero tolerances allow us to solve the subproblems inexactly but can still guarantee convergence,
hence saving computational costs. In particular, setting {τk}k≥0to diminish rapidly towards zero on
the order ofO(1/k2)can guarantee convergence of Algorithm 1. In practice, ¯sonly needs to be set
asO(1).
(b) Compared to the centralized proximal AL developed in Lu & Zhou (2023), we have made the following
major changes to arrive at Algorithm 1.
•add communication steps to allow dual updates in an FL manner;
•to solve the subproblem, we cannot directly apply the accelerated gradient method (AGM) as in Lu
& Zhou (2023). It is possible to develop an FL version of AGM by eagerly aggregating gradients
from local clients, but that induces heavy communication between clients and the central server. To
address this, we first reformulate the subproblem as a finite-sum problem and then propose an inexact
ADMM solver to solve it. The inexact ADMM solver allows multiple steps of local updates before
aggregation of model weights at the central server, hence it is communication friendly. We also
propose a new stopping criterion for the inexact ADMM (Algorithm 2). Detailed explanations can
be found in Remark 4.2.
For ease of later reference, we refer to the update from wktowk+1as one outer iteration of Algorithm 1,
and call one iteration of Algorithm 2 for solving Eq. (9) one inner iteration of Algorithm 1. In the rest of
this section, we study the following measures of complexity for Algorithm 1.
•Outer iteration complexity , which measures the number of outer iterations of Algorithm 1 ( one outer
iteration refers to one execution from Line 2 to Line 9 in Algorithm 1);
•Total inner iteration complexity , which measures the total number of iterations of Algorithm 2 that
are performed in Algorithm 1 ( one inner iteration refers to one execution from Line 3 to Line 10 in
Algorithm 2).
The following theorem concerns the output of Algorithm 1, whose proof is deferred to Appendix A.1.
Theorem 3.1 (output of Algorithm 1 ).If Algorithm 1 successfully terminates, its output (wk+1,µk+1)
is an (ϵ1,ϵ2)-optimal solution of Eq. (5).
7Published in Transactions on Machine Learning Research (05/2024)
3.2 Complexity analysis
In this subsection, we establish the outer and total inner iteration complexity for Algorithm 1. To proceed,
we let (w∗,µ∗)be any pair of optimal solutions of Eq. (5) and Eq. (7). First, we establish a lemma to show
that all iterates generated by Algorithm 1 are bounded. Its proof can be found in Appendix A.2.
Lemma 3.1 (bounded iterates of Algorithm 1 ).Suppose that Assumptions 0 to 2 hold. Let {wk}k≥0
be all the iterates generated by Algorithm 1. Then we have wk∈Q 1for allk≥0, where
Q1:={w∈Rd:∥w−w∗∥≤r0+ 2√n¯sβ}withr0:=∥(w0,µ0)−(w∗,µ∗)∥, (15)
andw0,µ0,¯s, andβare inputs of Algorithm 1.
This boundedness result allows us to utilize the Lipschitz continuity on a bounded set to establish the conver-
gence rate for Algorithm 1. The following theorem states the worst-case complexity results of Algorithm 1,
whose proof is relegated to Appendix A.3.
Theorem 3.2 (complexity results of Algorithm 1 ).Suppose that Assumptions 0 to 2 hold. Then,
(a) the number of outer iteration of Algorithm 1 is at most O(max{ϵ−2
1,ϵ−2
2}); and
(b) the total number of inner iterations of Algorithm 1 is at most /tildewideO(max{ϵ−2
1,ϵ−2
2}).
Remark 3.2. (a) To the best of our knowledge, Theorem 3.2 provides the first worst-case complexity results
for finding an approximate optimal solution of Eq. (5)in an FL framework; (b) The number of outer and
inner iterations of Algorithm 1 with detailed dependencies on the algorithm hyperparameters can be found in
Eqs.(48)and(84)in the proofs, respectively.
3.3 Communication overheads
In the outer loop of Algorithm 1, a single communication round occurs after solving a proximal AL sub-
problem. During this round, the central server sends the current weights wk+1to all local clients, and each
client sends back the maximum change in their respective multipliers, measured by ∥µk+1
i−µk
i∥∞, to the
central server. The communication overheads of the inner solver Algorithm 2 are discussed in Section 4.3.
The communication complexity of Algorithm 1 is /tildewideO(max{ϵ−2
1,ϵ−2
2}).
4 An inexact ADMM for FL
In this section, we propose an inexact ADMM-based FL algorithm to solve the subproblem in Eq. (12) (the
same as Eq. (9)) for Algorithm 1. Before proceeding, we show that ∇Pi,k,0≤i≤n, are locally Lipschitz
continuous on Rd, whose proof is deferred to Appendix B.1.
Lemma 4.1 (local Lipschitz continuity of ∇Pi,k).Suppose that Assumptions 0 to 2 hold. Then the
gradients∇Pi,k,0≤i≤n, are locally Lipschitz continuous on Rd.
Remark 4.1. It is worth noting that ∇Pi,k,0≤i≤n, are typically not globally Lipschitz continuous on Rd
even if∇fi,1≤i≤n, and∇ci,0≤i≤n, are globally Lipschitz continuous on Rd. For example, consider
c0(w) =∥w∥2−1. By Eq. (13), one has that
∇P0,k(w) = 2[µk
0+β(∥w∥2−1)]+w+1
(n+ 1)β(w−wk).
In this case, it is not hard to verify that ∇c0is globally Lipschitz continuous on Rd, but∇P0,kis not. Thus,
analyzing the complexity results for solving the subproblems in Eq. (12)using local Lipschitz conditions of
∇Pi,k,0≤i≤n, is reasonable.
Moreover, it is easy to see that Pi,kare strongly convex with the modulus 1/[(n+ 1)β]for all 0≤i≤nand
allk≥0.
Since both the local Lipschitz and the strong convexity (including its modulus) properties hold for all k≥0,
and we need to solve the subproblem of the same form each k, below we drop kand focus on solving the
8Published in Transactions on Machine Learning Research (05/2024)
following model problem in an FL manner:
min
w/braceleftigg
ℓ(w) :=n/summationdisplay
i=0Pi(w;Zi) +h(w)/bracerightigg
, (16)
where the data Zi’s are only accessible to their corresponding local/global functions Pi’s, necessitating FL.
We will drop Zi’s henceforth for simplicity. The model problem in Eq. (16) satisfies:
1. The functions Pi,0≤i≤n, are continuously differentiable, and moreover, ∇Pi,0≤i≤n, are locally
Lipschitz continuous on Rd;
2. The functions Pi,0≤i≤n, are strongly convex with a modulus σ>0onRd, that is,
⟨∇Pi(u)−∇Pi(v),u−v⟩≥σ∥u−v∥2,∀u,v∈Rd,0≤i≤n. (17)
4.1 Algorithm description
Algorithm 2 An inexact ADMM based FL algorithm for solving Eq. (16)
Input: tolerance τ∈(0,1],q∈(0,1),˜w0∈dom(h), andρi>0for1≤i≤n;
1:Setw0= ˜w0, and (u0
i,λ0
i,˜u0
i) = ( ˜w0,−∇Pi( ˜w0),˜w0−∇Pi( ˜w0)/ρi)for1≤i≤n.
2:fort= 0,1,2,...do
3:Setεt+1=qt;
4:Server update: The central server finds an approximate solution wt+1to
min
w/braceleftigg
φ0,t(w) :=P0(w) +h(w) +n/summationdisplay
i=1/bracketleftigρi
2∥˜ut
i−w∥2/bracketrightig/bracerightigg
(18)
5:such that dist∞(0,∂φ 0,t(wt+1))≤εt+1.
6:Communication (broadcast): Each local client i,1≤i≤n, receiveswt+1from the server.
7:Client update (local): Each local client i,1≤i≤n, finds an approximate solution ut+1
ito
min
ui/braceleftig
φi,t(ui) :=Pi(ui) +⟨λt
i,ui−wt+1⟩+ρi
2∥ui−wt+1∥2/bracerightig
(19)
8:such that∥∇φi,t(ut+1
i)∥∞≤εt+1, and then updates
λt+1
i=λt
i+ρi(ut+1
i−wt+1), (20)
˜ut+1
i=ut+1
i+λt+1
i/ρi, (21)
˜εi,t+1=∥∇φi,t(wt+1)−ρi(wt+1−ut
i)∥∞. (22)
9:Communication: Each local client i,1≤i≤n, sends (˜ut+1
i,˜εi,t+1)back to the central server.
10:Termination (server side): Outputwt+1and terminate this algorithm if
εt+1+n/summationdisplay
i=1˜εi,t+1≤τ. (23)
11:end for
In this subsection, we propose an inexact ADMM-based FL algorithm (Algorithm 2) for solving Eq. (16). To
make each participating client ihandle their local objective Piindependently (see Section 3.1), we introduce
decoupling variables ui’s and obtain the following equivalent consensus reformulation for Eq. (16):
min
w,ui/braceleftiggn/summationdisplay
i=1Pi(ui) +P0(w) +h(w)/bracerightigg
s.t. ui=w, 1≤i≤n, (24)
9Published in Transactions on Machine Learning Research (05/2024)
which allows each local client ito handle the local variable uiand the local objective function Piwhile
imposing consensus constraints that force clients’ local parameters uiequal to the global parameter w. This
reformulation enables the applicability of an inexact ADMM that solves Eq. (24) in a federated manner. At
each iteration, an ADMM solver optimizes the AL function associated with Eq. (24):
LP(w,u,λ ) :=n/summationdisplay
i=1/bracketleftig
Pi(ui) +⟨λi,ui−w⟩+ρi
2∥ui−w∥2/bracketrightig
+P0(w) +h(w) (25)
with respect to the variables w,u, andλalternately, where u= [uT
1,...,uT
n]Tand[λT
1,...,λT
n]Tcollect all
the local parameters and the multipliers associated with the consensus constraints, respectively. Specifically,
in iteration t, one performs
wt+1≈arg min
wLP(w,ut,λt), (26)
ut+1≈arg min
uLP(wt+1,u,λt), (27)
λt+1
i=λt
i+ρi(ut+1
i−wt+1),∀1≤i≤n. (28)
By the definition of LPin Eq. (25), one can verify that the step in Eq. (26) is equivalent to Eq. (18), and
also the step in Eq. (27) can be computed in parallel, which corresponds to Eq. (19). Therefore, the ADMM
updates naturally suit the FL framework, as the separable structure in Eq. (25) over the pairs {(ui,λi)}
enables the local update of (ui,λi)at each client iwhilewis updated by the central server.
Since the subproblems in Eq. (18) and Eq. (19) are strongly convex, their approximate solutions wt+1
andut+1
i,1≤i≤n, can be found using a gradient-based algorithm with a global linear convergence
rate (Nesterov et al., 2018). Furthermore, the value ˜εi,t+1in Eq. (22) serves as a measure of local optimality
and consensus for client i. By summing up ˜εi,t+1for1≤i≤nand including εt+1, one can obtain a
stationarity measure for the current iterate (see (Eq. (23))), as presented in the following theorem. Its proof
can be found in Appendix B.2.
Remark 4.2. We now make the following remarks on Algorithm 2.
(a) On hyperparameters of Algorithm 2,
•(τ,˜w0)is specified as (τk,wk)at thekth iteration of Algorithm 1.
•From Eq. (18),ρi,1≤i≤ncan be viewed as weighting parameters for aggregation. Therefore, it
is natural to set ρi=amifor1≤i≤n, wheremiis the number of samples in client iandais a
global constant. We follow this rule when setting ρi’s.
•q∈(0,1)determines the tolerance sequence {εt+1}t≥0for the subproblems in Eq. (18). These tol-
erances in solving subproblems reduce computational costs. Setting {εt+1}t≥0to rapidly diminish
toward zero rapidly at a geometric rate ensures the convergence of Algorithm 1. In practice, we
suggest setting qasO(1).
(b) The main innovations we have here compared to the existing literature on ADMM-based FL algorithms
(e.g, Zhou & Li (2023); Gong et al. (2022); Zhang et al. (2021)) include:
•We establish the complexity results of an inexact ADMM-based FL algorithm under local Lipschitz
conditions, vs. global Lipschitz conditions in other work. Our complexity results can be found in
Theorem 4.2.
•We propose a novel and rigorous stopping criterion (Eq. (23)) that is easily verifiable, communication-
light, and compatible with the outer iterations (as our inexact ADMM FL algorithm serves as a
subproblem solver in our overall algorithm framework).
Theorem 4.1 (output of Algorithm 2 ).If Algorithm 2 terminates at some iteration T≥0, then its
outputwT+1satisfies dist∞(0,∂ℓ(wT+1))≤τ.
Theorem 4.1 states that Algorithm 2 outputs a point that approximately satisfies the first-order optimality
condition of Eq. (5). In addition, it follows from Theorem 4.1 that Algorithm 2 with (τ,˜w0) = (τk,wk)finds
an approximate solution wk+1to Eq. (12) such that Eq. (10) holds.
10Published in Transactions on Machine Learning Research (05/2024)
4.2 Complexity analysis
In this subsection, we establish the iteration complexity for the inexact ADMM, namely, Algorithm 2. Recall
from Eq. (17) that Eq. (16) is strongly convex and thus has a unique optimal solution. We refer to this
optimal solution of Eq. (16) as ˜w∗throughout this section. The following lemma shows that all the iterates
generated by Algorithm 2 lie in a compact set. Its proof can be found in Appendix B.3.
Lemma 4.2 (bounded iterates of Algorithm 2 ).Suppose that Assumptions 0 to 2 hold and let
{ut+1
i}1≤i≤n,t≥0and{wt+1}t≥0be all the iterates generated by Algorithm 2. Then it holds that all these
iterates stay in a compact set Q, where
Q:=/braceleftigg
v:∥v−˜w∗∥2≤n+ 1
σ2(1−q2)+1
σn/summationdisplay
i=1/parenleftbigg
ρi∥˜w∗−˜w0∥2+1
ρi∥∇Pi( ˜w∗)−∇Pi( ˜w0)∥2/parenrightbigg/bracerightigg
.(29)
The iteration complexity of Algorithm 2 is established in the following theorem, whose proof is relegated to
Appendix B.4.
Theorem 4.2 (iteration complexity of Algorithm 2 ).Suppose that Assumptions 0 to 2 hold. Then
Algorithm 2 terminates in at most O(|logτ|)iterations.
Remark 4.3. We now make the following remarks on the complexity results in Theorem 4.2.
(a) Algorithm 2 enjoys a global linear convergence rate when solving the problem in Eq. (16). The result
generalizes classical convergence results for ADMM in the literature, which typically require a strongly
convex objective with globally Lipschitz continuous gradient (e.g., see Lin et al. (2015)). In contrast,
our result is the first to establish a global linear convergence of an inexact ADMM assuming a strongly
convex objective with only a locally Lipschitz continuous gradient.
(b) The number of iterations of Algorithm 2 with dependencies on all the algorithm hyperparameters can be
found in Eq. (74)in the proofs.
(c) The general research on complexity analysis for optimization algorithms under local Lipschitz assump-
tions is relatively new. For example, Lu & Mei (2023) proposes accelerated gradient methods for convex
optimization problems with locally Lipschitz continuous gradients, and Zhang & Hong (2024) proposes
accelerated gradient methods for nonconvex optimization problems with locally Lipschitz continuous gra-
dients.
4.3 Communication overheads
In each iteration of Algorithm 2, a single communication round happens between the clients and the central
server. During this round, the central server transmits the global weight wt+1to all clients, and subsequently
each local client performs multiple local updates to solve a local subproblem and then sends the updated
local weights ˜ut+1
iand a local stationarity measure ˜εi,t+1back to the central server. The communication
complexity of each call of Algorithm 2 is O(|logτ|).
5 Numerical experiments
Here, we conduct numerical experiments to evaluate the performance of our proposed FL algorithm (Algo-
rithm 1). Specifically, we benchmark our algorithm against a centralized proximal AL method (cProx-AL,
described in Algorithm 3) on a convex Neyman-Pearson classification problem (Section 5.1) and a fair-
aware learning problem (Section 5.2) with real-world datasets, and further on linear-equality-constrained
quadratic programming problems with simulated data (Appendix E.2). All experiments are carried out
on a Windows system with an AMD EPYC 7763 64-core processor, and all algorithms are implemented
in Python. The code to implement the proposed algorithm on these numerical examples is available at
https://github.com/PL97/Constr_FL .
11Published in Transactions on Machine Learning Research (05/2024)
Table1: NumericalresultsforsolvingEq.(30)usingouralgorithmvs. usingcProx-AL.Insidetheparentheses
are the respective standard deviations over 10 random trials. For feasibility, we include the mean and
maximum losses for class 1 among all local clients.
dataset nobjective value (loss for class 0) feasibility (loss for class 1 ( ≤0.2))
Algorithm 1 cProx-AL relative difference Algorithm 1 cProx-AL
mean max mean max
breast-cancer-wisc10.27 (1.52e-04) 0.27 (3.02e-05) 7.09e-04 (2.02e-04) 0.20 (1.80e-07) 0.20 (1.80e-07) 0.20 (1.84e-08) 0.20 (1.84e-08)
50.34 (4.50e-02) 0.33 (4.55e-02) 1.15e-02 (5.17e-03) 0.19 (7.33e-06) 0.20 (1.08e-06) 0.19 (1.13e-04) 0.20 (1.72e-05)
100.37 (1.08e-01) 0.37 (1.08e-01) 3.92e-04 (2.76e-04) 0.17 (1.15e-05) 0.20 (6.05e-09) 0.17 (1.14e-05) 0.20 (2.95e-08)
200.46 (2.12e-01) 0.45 (2.12e-01) 3.43e-02 (2.91e-02) 0.16 (3.52e-05) 0.20 (3.76e-06) 0.16 (7.03e-06) 0.20 (7.70e-08)
adult-a10.73 (2.19e-04) 0.73 (1.25e-04) 2.24e-04 (3.46e-04) 0.20 (6.30e-07) 0.20 (6.30e-07) 0.20 (1.73e-06) 0.20 (1.73e-06)
50.74 (1.03e-02) 0.74 (1.03e-02) 4.25e-03 (7.44e-04) 0.20 (2.14e-04) 0.20 (2.80e-04) 0.20 (1.21e-05) 0.20 (2.28e-06)
100.77 (1.98e-02) 0.77 (1.98e-02) 2.69e-03 (3.24e-03) 0.19 (6.41e-05) 0.20 (9.76e-05) 0.19 (2.00e-05) 0.20 (1.23e-05)
200.78 (2.86e-02) 0.79 (2.81e-02) 1.13e-02 (4.11e-03) 0.18 (6.40e-04) 0.20 (6.59e-05) 0.18 (1.96e-05) 0.20 (3.19e-06)
monks-111.58 (7.61e-05) 1.58 (7.50e-05) 1.39e-05 (1.09e-05) 0.20 (1.09e-07) 0.20 (1.09e-07) 0.20 (3.01e-07) 0.20 (3.01e-07)
51.65 (8.39e-02) 1.65 (8.41e-02) 2.08e-04 (1.84e-04) 0.19 (6.39e-05) 0.20 (5.39e-05) 0.19 (5.04e-06) 0.20 (5.60e-07)
101.71 (1.18e-01) 1.71 (1.18e-01) 4.59e-04 (3.32e-04) 0.18 (3.98e-05) 0.20 (4.46e-05) 0.18 (6.44e-06) 0.20 (1.60e-06)
201.81 (1.49e-01) 1.79 (1.60e-01) 1.78e-02 (1.38e-02) 0.17 (1.68e-04) 0.20 (2.24e-04) 0.17 (4.60e-06) 0.20 (1.62e-06)
Figure 1: Convergence behavior of local objective and local feasibility in one random trial over the outer
iterations of Algorithm 1 on three real-world datasets. The solid blue and brown lines indicate the mean
local objective and the mean local feasibility over all clients, respectively. The blue and the brown areas
indicate the cross-client variations of local objectives and local feasibility, respectively. The dashed black
line indicates the feasibility threshold.
5.1 Neyman-Pearson classification
In this subsection, we consider the Neyman-Pearson classification problem:
min
w1
nn/summationdisplay
i=11
mi0mi0/summationdisplay
j=1ϕ(w; (x(i0)
j,0)) s.t.1
mi1mi1/summationdisplay
j=1ϕ(w; (x(i1)
j,1))≤ri,1≤i≤n, (30)
where{x(i0)
j}1≤j≤mi0and{x(i1)
j}1≤j≤mi1are the sets of samples at client iassociated with labels 0and1,
respectively, and ϕis the binary logistic loss (Hastie et al., 2009)
ϕ(w; (x,y)) =−ywTx+ log(1 +ewTx), y∈{0,1}. (31)
Then, both the objective and the constraints in Eq. (30) are convex. We consider three real-world datasets,
namely ‘breast-cancer-wisc’, ‘adult-a’, and ‘monks-1’, from the UCI repository2and described in Ap-
pendix E.1. For each dataset, we perform the Neyman-Pearson classification that minimizes the loss of
classification for class 0 (majority) while ensuring that the loss for class 1 (minority) is less than a threshold
ri= 0.2. To simulate the FL setting, we divide each dataset into nfolds, mimicking local clients, each
holding the same amount of data with equal ratios of the two classes.
We apply Algorithm 1 and cProx-AL (Algorithm 3) to find a (10−3,10−3)-optimal solution of Eq. (30). We
run 10 trials of Algorithm 1 and cProx-AL. For each run, both algorithms have the same initial point w0,
2seehttps://archive.ics.uci.edu/datasets
12Published in Transactions on Machine Learning Research (05/2024)
randomly chosen from the unit Euclidean sphere. We set the other parameters for Algorithm 1 and cProx-AL
asµ0
i= (0,..., 0)T∀0≤i≤n,¯s= 0.001andβ= 300. We also set ρi= 0.01∀1≤i≤nfor Algorithm 2.
Comparing the objective value and feasibility of solutions achieved by Algorithm 1 and cProx-AL in Table 1,
we see that both algorithms can yield solutions of similar quality. Given the small standard deviations, we
observe that the convergence behavior of Algorithm 1 remains stable across 10 trial runs. These observations
demonstrate the ability of Algorithm 1 to reliably solve Eq. (30) in the FL setting without compromising
solution quality. From Fig. 1, we observe that Algorithm 1 consistently achieves feasibility for all local
constraints while also minimizing all the local objectives.
5.2 Classification with fairness constraints
In this subsection, we consider fairness-aware learning with global and local fairness constraints:
min
w1
nn/summationdisplay
i=11
mimi/summationdisplay
j=1ϕ(w;z(i)
j) s.t.−ri≤1
˜mi˜mi/summationdisplay
j=1ϕ(w; ˜z(i)
j)−1
ˆmiˆmi/summationdisplay
j=1ϕ(w; ˆz(i)
j)≤ri,0≤i≤n.(32)
Here,{z(i)
j= (x(i)
j,y(i)
j)∈Rd×{0,1}:i= 0,...,n,j = 1,...,mi}is the training set, where iindexes
the central server/local clients. For each i= 0,...,n, the dataset{z(i)
j}1≤j≤miis further divided into
two subgroups{˜z(i)
j}1≤j≤˜miand{ˆz(i)
j}1≤j≤ˆmibased on certain subgroup attributes. The constraints with
i= 1,...,nrefer to local constraints at client i, while the constraints with i= 0refer to global constraints
at the central server.
We chooseϕas the binary logistic loss defined in Eq. (31), leading to nonconvex constraints in Eq. (32). For
the real-world dataset, we consider ‘adult-b’3: each sample in this dataset has 39features and one binary
label. To simulate the FL setting, we divide the 22,654training samples from the ‘adult-b’ dataset into n
folds and distribute them to nlocal clients. The central server holds the 5,659test samples from the ‘adult-
b’ dataset. Note that although we have taken both the “training” and “test” samples from the ‘adult-b’
dataset here, these samples are used to simulate our local samples and central samples, respectively. The
focus here is to test optimization performance, not generalization—we do not have a test step, unlike in
typical supervised learning.
We apply Algorithm 1 and cProx-AL (Algorithm 3) to find a (10−3,10−3)-optimal solution of Eq. (32). We
run 10 trials of Algorithm 1 and cProx-AL. For each run, both algorithms have the same initial point w0,
randomly chosen from the unit Euclidean sphere. We set the other parameters for Algorithm 1 and cProx-AL
asµ0
i= (0,..., 0)T∀0≤i≤n,¯s= 0.001andβ= 10. We also set ρi= 108∀1≤i≤nfor Algorithm 2.
Comparing the objective value and feasibility of solutions achieved by Algorithm 1 and cProx-AL in Table 2
reveals that Algorithm 1 and cProx-AL can produce solutions of similar quality. Given the small standard
deviations, we observe that the convergence behavior of Algorithm 1 remains stable across 10 trial runs.
These observations demonstrate the ability of Algorithm 1 to reliably solve Eq. (32) in the FL setting without
compromising solution quality. It also suggests the potential of our algorithm in solving FL problems with
nonconvex constraints. From Fig. 2, we see that our proposed method consistently achieves feasibility for
all local and global constraints while also minimizing all the local objectives.
6 Concluding remarks
Inthispaper, weproposeanFLalgorithmforsolvinggeneralconstrainedMLproblemsbasedontheproximal
AL method. We analyze the worst-case iteration complexity of the proposed algorithm, assuming convex
objective and convex constraints with locally Lipschitz continuous gradients. Finally, we perform numerical
experiments to assess the performance of the proposed algorithm for constrained classification problems,
using real-world datasets. The numerical results clearly demonstrate the practical efficacy of our proposed
algorithm. Since our work is the first of its kind, there are numerous possible future directions. For example,
3This dataset can be found in https://github.com/heyaudace/ml-bias-fairness/tree/master/data/adult .
13Published in Transactions on Machine Learning Research (05/2024)
Table 2: Numerical results for Eq. (32) using our algorithm vs. using cProx-AL. Inside the parentheses are
the respective standard deviations over 10 random trials. For feasibility, we include the mean and maximum
loss disparities (absolute difference between losses for two subgroups) among all clients and the central server.
nobjective value feasibility (loss disparity ( ≤0.1))
Algorithm 1 cProx-AL relative difference Algorithm 1 cProx-AL
mean max mean max
10.37 (9.83e-05) 0.37 (4.14e-05) 1.97e-03 (2.53e-04) 0.10 (1.14e-04) 0.10 (1.36e-04) 0.10 (3.69e-06) 0.10 (5.38e-06)
50.37 (3.99e-03) 0.37 (4.05e-03) 1.86e-03 (4.69e-04) 0.09 (5.34e-05) 0.10 (7.51e-05) 0.09 (3.68e-05) 0.10 (4.36e-06)
100.37 (6.39e-03) 0.37 (6.52e-03) 2.39e-03 (8.40e-04) 0.08 (1.68e-04) 0.10 (2.15e-05) 0.08 (1.52e-04) 0.10 (6.56e-06)
200.38 (9.46e-03) 0.37 (9.86e-03) 4.61e-03 (2.43e-03) 0.08 (9.75e-05) 0.10 (1.01e-04) 0.08 (4.90e-05) 0.10 (6.06e-06)
Figure 2: Convergence of local objective, local feasibility, and the feasibility for global constraints in one
random trial over the outer iterations of Algorithm 1. The solid blue and brown lines indicate the mean local
objective and the mean local feasibility over all clients, respectively. The blue and brown areas indicate the
cross-client variations of local objectives and local feasibility, respectively. The dashdot blue line indicates
the feasibility for global constraints. The dashed black line indicates the feasibility threshold.
one could try to extend our FL algorithms to allow partial client participation and stochastic solvers at local
clients. In addition, developing FL algorithms for general constrained ML with convergence guarantees in
nonconvex settings remains largely open. Lastly, constrained FL with a fixed iteration and communication
budget, especially stringent ones, is a very useful but challenging future research topic.
Acknowledgments
C. He is partially supported by the NIH fund R01CA287413 and the UMN Research Computing Seed Grant.
L.PengispartiallysupportedbytheCISCOResearchfund1085646POUSA000EP390223. J.Sunispartially
supported by the NIH fund R01CA287413 and the CISCO Research fund 1085646 PO USA000EP390223.
The authors acknowledge the Minnesota Supercomputing Institute (MSI) at the University of Minnesota for
providing resources that contributed to the research results reported in this article. The content is solely the
responsibility of the authors and does not necessarily represent the official views of the National Institutes
of Health.
14Published in Transactions on Machine Learning Research (05/2024)
References
Alekh Agarwal, Alina Beygelzimer, Miroslav Dudík, John Langford, and Hanna Wallach. A reductions
approach to fair classification. In International Conference on Machine Learning , pp. 60–69. PMLR, 2018.
NecdetSAybatandErfanYHamedani. Aprimal-dualmethodforconicconstraineddistributedoptimization
problems. Advances in Neural Information Processing Systems , 29, 2016.
Necdet S Aybat and Erfan Y Hamedani. A distributed ADMM-like method for resource sharing over time-
varying networks. SIAM Journal on Optimization , 29(4):3036–3068, 2019.
Necdet S Aybat and Garud Iyengar. An augmented Lagrangian method for conic convex programming.
arXiv preprint arXiv:1302.6322 , 2013.
Heinz H Bauschke and Patrick L Combettes. Convex Analysis and Monotone Operator Theory in Hilbert
Spaces. Springer, 2nd edition, 2017.
ErnestoGBirginandJoséMMartínez. ComplexityandperformanceofanaugmentedLagrangianalgorithm.
Optimization Methods and Software , 35(5):885–920, 2020.
Paul T Boggs and Jon W Tolle. Sequential quadratic programming. Acta Numerica , 4:1–51, 1995.
Richard H Byrd, Robert B Schnabel, and Gerald A Shultz. A trust region algorithm for nonlinearly con-
strained optimization. SIAM Journal on Numerical Analysis , 24(5):1152–1170, 1987.
Elisa Celis, Lingxiao Huang, Vijay Keswani, and Nisheeth K Vishnoi. Classification with fairness constraints:
A meta-algorithm with provable guarantees. In Proceedings of the Conference on Fairness, Accountability,
and Transparency , pp. 319–328, 2019.
Peter W Christensen and Anders Klarbring. An Introduction to Structural Optimization , volume 153.
Springer Science & Business Media, 2008.
Lingyang Chu, Lanjun Wang, Yanjie Dong, Jian Pei, Zirui Zhou, and Yong Zhang. FedFair: Training fair
models in cross-silo federated learning. arXiv preprint arXiv:2109.05662 , 2021.
Frank E Curtis and Michael L Overton. A sequential quadratic programming algorithm for nonconvex,
nonsmooth constrained optimization. SIAM Journal on Optimization , 22(2):474–500, 2012.
Wei Du, Depeng Xu, Xintao Wu, and Hanghang Tong. Fairness-aware agnostic federated learning. In
Proceedings of the 2021 SIAM International Conference on Data Mining (SDM) , pp. 181–189. SIAM,
2021.
Borja R Gálvez, Filip Granqvist, Rogier van Dalen, and Matt Seigel. Enforcing fairness in private federated
learningviathemodifiedmethodofdifferentialmultipliers. In NeurIPS 2021 Workshop Privacy in Machine
Learning , 2021.
Joachim Giesen and Sören Laue. Combining ADMM and the augmented Lagrangian method for efficiently
handling many constraints. In International Joint Conference on Artificial Intelligence , pp. 4525–4531,
2019.
Yonghai Gong, Yichuan Li, and Nikolaos M Freris. FedADMM: A robust federated deep learning framework
withadaptivitytosystemheterogeneity. In 2022 IEEE 38th International Conference on Data Engineering
(ICDE), pp. 2575–2587. IEEE, 2022.
Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial examples.
arXiv preprint arXiv:1412.6572 , 2014.
Geovani N Grapiglia and Ya-xiang Yuan. On the complexity of an augmented Lagrangian method for
nonconvex optimization. IMA Journal of Numerical Analysis , 41(2):1546–1568, 2021.
15Published in Transactions on Machine Learning Research (05/2024)
Trevor Hastie, Robert Tibshirani, and Jerome H Friedman. The Elements of Statistical Learning: Data
Mining, Inference, and Prediction . Springer, New York, 2nd edition, 2009.
Chuan He, Heng Huang, and Zhaosong Lu. A Newton-CG based barrier-augmented Lagrangian method for
general nonconvex conic optimization. arXiv preprint arXiv:2301.04204 , 2023a.
Chuan He, Zhaosong Lu, and Ting Kei Pong. A Newton-CG based augmented Lagrangian method for
finding a second-order stationary point of nonconvex equality constrained optimization with complexity
guarantees. SIAM Journal on Optimization , 33(3):1734–1766, 2023b.
Mingyi Hong, Davood Hajinezhad, and Ming-Min Zhao. Prox-PDA: The proximal primal-dual algorithm
for fast distributed nonconvex optimization and learning over networks. In International Conference on
Machine Learning , pp. 1529–1538. PMLR, 2017.
Kevin Huang, Nuozhou Wang, and Shuzhong Zhang. An accelerated variance reduced extra-point approach
to finite-sum VI and optimization. arXiv preprint arXiv:2211.03269 , 2022.
Peter Kairouz, H Brendan McMahan, Brendan Avent, Aurélien Bellet, Mehdi Bennis, Arjun Nitin Bhagoji,
Kallista Bonawitz, Zachary Charles, Graham Cormode, Rachel Cummings, et al. Advances and open
problems in federated learning. Foundations and Trends ®in Machine Learning , 14(1–2):1–210, 2021.
Sai P Karimireddy, Satyen Kale, Mehryar Mohri, Sashank Reddi, Sebastian Stich, and Ananda T Suresh.
Scaffold: Stochastic controlled averaging for federated learning. In International Conference on Machine
Learning , pp. 5132–5143. PMLR, 2020.
Jakub Konečn` y, H Brendan McMahan, Felix X Yu, Peter Richtárik, Ananda T Suresh, and Dave Bacon.
Federated learning: Strategies for improving communication efficiency. arXiv preprint arXiv:1610.05492 ,
2016.
Weiwei Kong, Jefferson G Melo, and Renato DC Monteiro. Iteration complexity of an inner accelerated
inexactproximalaugmentedLagrangianmethodbasedontheclassicalLagrangianfunction. SIAM Journal
on Optimization , 33(1):181–210, 2023.
Guanghui Lan and Renato DC Monteiro. Iteration-complexity of first-order augmented Lagrangian methods
for convex programming. Mathematical Programming , 155(1-2):511–547, 2016.
Qinbin Li, Zeyi Wen, Zhaomin Wu, Sixu Hu, Naibo Wang, Yuan Li, Xu Liu, and Bingsheng He. A survey on
federated learning systems: Vision, hype and reality for data privacy and protection. IEEE Transactions
on Knowledge and Data Engineering , 2021a.
Tian Li, Anit K Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and Virginia Smith. Federated
optimization in heterogeneous networks. Proceedings of Machine Learning and Systems , 2:429–450, 2020.
Tian Li, Shengyuan Hu, Ahmad Beirami, and Virginia Smith. Ditto: Fair and robust federated learning
through personalization. In International Conference on Machine Learning , pp. 6357–6368. PMLR, 2021b.
Xiaoxiao Li, Meirui Jiang, Xiaofei Zhang, Michael Kamp, and Qi Dou. FedBN: Federated learning on non-iid
features via local batch normalization. arXiv preprint arXiv:2102.07623 , 2021c.
Zichong Li, Pin-Yu Chen, Sijia Liu, Songtao Lu, and Yangyang Xu. Rate-improved inexact augmented
Lagrangian method for constrained nonconvex optimization. In International Conference on Artificial
Intelligence and Statistics , pp. 2170–2178. PMLR, 2021d.
Peng Lin, Wei Ren, and Yongduan Song. Distributed multi-agent optimization subject to nonidentical
constraints and communication delays. Automatica , 65:120–131, 2016.
Tianyi Lin, Shiqian Ma, and Shuzhong Zhang. On the global linear convergence of the ADMM with multi-
block variables. SIAM Journal on Optimization , 25(3):1478–1497, 2015.
16Published in Transactions on Machine Learning Research (05/2024)
Yi Liu, JQ James, Jiawen Kang, Dusit Niyato, and Shuyu Zhang. Privacy-preserving traffic flow prediction:
A federated learning approach. IEEE Internet of Things Journal , 7(8):7751–7763, 2020.
Guodong Long, Yue Tan, Jing Jiang, and Chengqi Zhang. Federated learning for open banking. In Federated
Learning: Privacy and Incentive , pp. 240–254. Springer, 2020.
Songtao Lu. A single-loop gradient descent and perturbed ascent algorithm for nonconvex functional con-
strained optimization. In International Conference on Machine Learning , pp. 14315–14357. PMLR, 2022.
Zhaosong Lu and Sanyou Mei. Accelerated first-order methods for convex optimization with locally Lipschitz
continuous gradient. SIAM Journal on Optimization , 33(3):2275–2310, 2023.
Zhaosong Lu and Zirui Zhou. Iteration-complexity of first-order augmented Lagrangian methods for convex
conic programming. SIAM Journal on Optimization , 33(2):1159–1190, 2023.
LeviMcClennyandUlissesBraga-Neto. Self-adaptivephysics-informedneuralnetworksusingasoftattention
mechanism. arXiv preprint arXiv:2009.04544 , 2020.
Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Agüera y Arcas.
Communication-efficient learning of deep networks from decentralized data. In Artificial Intelligence and
Statistics , pp. 1273–1282. PMLR, 2017.
Ninareh Mehrabi, Fred Morstatter, Nripsuta Saxena, Kristina Lerman, and Aram Galstyan. A survey on
bias and fairness in machine learning. ACM Computing Surveys (CSUR) , 54(6):1–35, 2021.
Jed Mills, Jia Hu, and Geyong Min. Communication-efficient federated learning for wireless edge intelligence
in IoT.IEEE Internet of Things Journal , 7(7):5986–5994, 2019.
Konstantin Mishchenko, Grigory Malinovsky, Sebastian Stich, and Peter Richtárik. Proxskip: Yes! local
gradient steps provably lead to communication acceleration! finally! In International Conference on
Machine Learning , pp. 15750–15769. PMLR, 2022.
Ion Necoara, Andrei Patrascu, and Francois Glineur. Complexity of first-order inexact Lagrangian and
penalty methods for conic convex programming. Optimization Methods and Software , 34(2):305–335,
2019.
Angelia Nedic, Asuman Ozdaglar, and Pablo A Parrilo. Constrained consensus and optimization in multi-
agent networks. IEEE Transactions on Automatic Control , 55(4):922–938, 2010.
Yurii Nesterov et al. Lectures on convex optimization , volume 137. Springer, 2018.
OCR. Hipaa Home. HHS.gov , Aug 2023. URL https://www.hhs.gov/hipaa/index.html .
Reese Pathak and Martin J Wainwright. FedSplit: An algorithmic framework for fast federated optimization.
InAdvances in neural information processing systems , volume 33, pp. 7057–7066, 2020.
Andrei Patrascu, Ion Necoara, and Quoc Tran-Dinh. Adaptive inexact fast augmented Lagrangian methods
for constrained convex optimization. Optimization Letters , 11:609–626, 2017.
Le Peng, Gaoxiang Luo, Andrew Walker, Zachary Zaiman, Emma K Jones, Hemant Gupta, Kristopher
Kersten, John L Burns, Christopher A Harle, Tanja Magoc, Benjamin Shickel, Scott D Steenburg, Tyler
Loftus, Genevieve B Melton, Judy W Gichoya, Ju Sun, and Christopher J Tignanelli. Evaluation of
federated learning variations for COVID-19 diagnosis using chest radiographs from 42 US and European
hospitals. Journal of the American Medical Informatics Association , 30(1):54–63, 2023a.
Le Peng, Sicheng Zhou, Jiandong Chen, Rui Zhang, Ziyue Xu, and Ju Sun. A systematic evaluation of
federated learning on biomedical natural language processing. In International Workshop on Federated
Learning for Distributed Data Mining , 2023b. URL https://openreview.net/forum?id=pLEQFXACNA .
MJD Powell and Ya-xiang Yuan. A trust region algorithm for equality constrained optimization. Mathemat-
ical Programming , 49(1):189–211, 1991.
17Published in Transactions on Machine Learning Research (05/2024)
Nicola Rieke, Jonny Hancox, Wenqi Li, Fausto Milletari, Holger R Roth, Shadi Albarqouni, Spyridon Bakas,
Mathieu N Galtier, Bennett A Landman, Klaus Maier-Hein, Sébastien Ourselin, Micah Sheller, Ronald M
Summers, Andrew Trask, Daguang Xu, Maximilian Baust, and M Jorge Cardoso. The future of digital
health with federated learning. NPJ Digital Medicine , 3(1):119, 2020.
PhilippeRigolletandXinTong. Neyman-Pearsonclassification, convexityandstochasticconstraints. Journal
of Machine Learning Research , 2011.
R Tyrrell Rockafellar. Augmented Lagrangians and applications of the proximal point algorithm in convex
programming. Mathematics of Operations Research , 1(2):97–116, 1976.
R Tyrrell Rockafellar and Roger J-B Wets. Variational Analysis , volume 317. Springer Science & Business
Media, 2009.
Takaya Saito and Marc Rehmsmeier. The precision-recall plot is more informative than the ROC plot when
evaluating binary classifiers on imbalanced datasets. PloS one , 10(3):e0118432, 2015.
Felix Sattler, Simon Wiedemann, Klaus-Robert Müller, and Wojciech Samek. Robust and communication-
efficient federated learning from non-IID data. IEEE Transactions on Neural Networks and Learning
Systems, 31(9):3400–3413, 2019.
Clayton Scott. Performance measures for Neyman-Pearson classification. IEEE Transactions on Information
Theory, 53(8):2852–2863, 2007.
Zebang Shen, Juan Cervino, Hamed Hassani, and Alejandro Ribeiro. An agnostic approach to federated
learning with class imbalance. In International Conference on Learning Representations , 2021.
Xin Tong, Yang Feng, and Anqi Zhao. A survey on Neyman-Pearson classification and suggestions for future
research. Wiley Interdisciplinary Reviews: Computational Statistics , 8(2):64–81, 2016.
Xin Tong, Yang Feng, and Jingyi Jessica Li. Neyman-Pearson classification algorithms and NP receiver
operating characteristics. Science Advances , 4(2):eaao1659, 2018.
Quoc Tran Dinh, Nhan H Pham, Dzung Phan, and Lam Nguyen. FedDR–randomized Douglas-Rachford
splitting algorithms for nonconvex federated composite optimization. In Advances in Neural Information
Processing Systems , volume 34, pp. 30326–30338, 2021.
Yash Travadi, Le Peng, Xuan Bi, Ju Sun, and Mochen Yang. Welfare and fairness dynamics in federated
learning: A client selection perspective. Statistics and Its Interface , 2023.
Andreas Wächter and Lorenz T Biegler. On the implementation of an interior-point filter line-search algo-
rithm for large-scale nonlinear programming. Mathematical Programming , 106:25–57, 2006.
JianyuWang,QinghuaLiu,HaoLiang,GauriJoshi,andHVincentPoor. Tacklingtheobjectiveinconsistency
problem in heterogeneous federated optimization. Advances in Neural Information Processing Systems ,
33:7611–7623, 2020.
PengWang, PengLin, WeiRen, andYongduanSong. Distributedsubgradient-basedmultiagentoptimization
with more general step sizes. IEEE Transactions on Automatic Control , 63(7):2295–2302, 2017.
Yangyang Xu. Iteration complexity of inexact augmented Lagrangian methods for constrained convex pro-
gramming. Mathematical Programming , 185:199–244, 2021.
Tao Yang, Xinlei Yi, Junfeng Wu, Ye Yuan, Di Wu, Ziyang Meng, Yiguang Hong, Hong Wang, Zongli Lin,
and Karl H Johansson. A survey of distributed optimization. Annual Reviews in Control , 47:278–305,
2019.
Wei Yao, Chengming Yu, Shangzhi Zeng, and Jin Zhang. Constrained bi-level optimization: Proximal
Lagrangian value function approach and Hessian-free algorithm. In International Conference on Machine
Learning , 2024.
18Published in Transactions on Machine Learning Research (05/2024)
DemingYuan, ShengyuanXu, andHuanyuZhao. Distributedprimal-dualsubgradientmethodformultiagent
optimization via consensus algorithms. IEEE Transactions on Systems, Man, and Cybernetics, Part B
(Cybernetics) , 41(6):1715–1724, 2011.
Honglin Yuan, Manzil Zaheer, and Sashank Reddi. Federated composite optimization. In International
Conference on Machine Learning , pp. 12253–12266. PMLR, 2021.
Junyu Zhang and Mingyi Hong. First-order algorithms without Lipschitz gradient: A sequential local
optimization approach. INFORMS Journal on Optimization , 2024.
Xinwei Zhang, Mingyi Hong, Sairaj Dhople, Wotao Yin, and Yang Liu. FedPD: A federated learning
framework with adaptivity to non-iid data. IEEE Transactions on Signal Processing , 69:6055–6070, 2021.
Shenglong Zhou and Geoffrey Ye Li. Federated learning via inexact ADMM. IEEE Transactions on Pattern
Analysis and Machine Intelligence , 2023.
Minghui Zhu and Sonia Martínez. On distributed convex optimization under inequality and equality con-
straints. IEEE Transactions on Automatic Control , 57(1):151–164, 2011.
Barret Zoph, Vijay Vasudevan, Jonathon Shlens, and Quoc V Le. Learning transferable architectures for
scalable image recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern
Recognition , pp. 8697–8710, 2018.
19Published in Transactions on Machine Learning Research (05/2024)
Appendix
In Appendices A to C, we provide proofs of the main results in Sections 3 and 4. Appendix D presents
a proximal AL method for centralized constrained optimization. In Appendix E, we include some extra
numerical results.
A Proofs of Theorem 3.1, Lemma 3.1, and Theorem 3.2(a)
First, we set up the technical tools necessary for the proof, following Lu & Zhou (2023). With the abbrevi-
ations in Eq. (6), we define the Lagrangian function associated with Eqs. (5) and (7) as
l(w,µ) =

f(w) +h(w) +⟨µ,c(w)⟩ifw∈dom(h)andµ≥0,
−∞ ifw∈dom(h)andµ̸≥0,
∞ ifw̸∈dom(h),
Then, one can verify that
∂l(w,µ) =

/parenleftbigg∇f(w) +∂h(w) +∇c(w)µ
c(w)−N Rm
+(µ)/parenrightbigg
ifw∈dom(h)andµ≥0,
∅ otherwise.(33)
We also define a set-valued operator Tassociated with Eqs. (5) and (7):
T: (w,µ)→{(u,ν)∈Rd×Rm: (u,−ν)∈∂l(w,µ)},∀(w,µ)∈Rd×Rm, (34)
which is maximally monotone (see, e.g., Section 2 of Rockafellar (1976)). Finding a KKT solution of Eq. (5)
can be viewed as solving the monotone inclusion problem (Rockafellar, 1976):
Find (w,µ)∈Rd×Rmsuch that (0,0)∈T(w,µ). (35)
Furthermore, applying the proximal AL method to solve Eq. (5) is equivalent to applying the proximal point
algorithm (PPA) to solve this monotone inclusion problem (Rockafellar, 1976; Bauschke & Combettes, 2017),
that is,
wk+1= arg min
wℓk(w), µk+1= [µk+βc(wk+1)]+,⇐⇒ (wk+1,µk+1) =J(wk,µk),∀k≥0,(36)
where (w0,µ0)∈dom(h)×Rm
+andJis the resolvent of Tdefined as
J:= (I+βT)−1(37)
withIbeing the identity operator. When the arg minwℓk(w)subproblem is only solved up to approximate
stationarity, that is, dist∞(0,∂ℓk(wk+1))≤τkas in our Algorithm 1, the error τkwill propagate to the next
iterate that we obtain. This is quantitatively captured by the following result.
Lemma A.1 (adaptation of Lemma 5 of Lu & Zhou (2023) ).Suppose that Assumptions 0 to 2 hold.
Let{(wk,µk)}k≥0be generated by Algorithm 1. Then for any k≥0, we have
∥(wk+1,µk+1)−J(wk,µk)∥≤β√nτk,
whereJis the resolvent of Tdefined in Eq. (37).
Proof.Notice from Eq. (10) that dist(0,∂ℓk(wk+1))≤√ndist∞(0,∂ℓk(wk+1))≤√nτk. By this and
Lemma 5 of Lu & Zhou (2023), the conclusion of this lemma holds.
20Published in Transactions on Machine Learning Research (05/2024)
A.1 Proof of Theorem 3.1
Proof of Theorem 3.1. Notice from Eqs. (6) and (9) that
ℓk(w) =f(w) +h(w) +1
2β/parenleftbig
∥[µk+βc(w)]+∥2−∥µk∥2/parenrightbig
+1
2β∥w−wk∥2.
By this, Eq. (33), and the fact that µk+1= [µk+βc(wk+1)]+, one has
∂ℓk(wk+1)−1
β(wk+1−wk) =∇f(wk+1) +∂h(wk+1) +∇c(wk+1)[µk+βc(wk+1)]+
=∇f(wk+1) +∂h(wk+1) +∇c(wk+1)µk+1=∂wl(wk+1,µk+1).(38)
Notice that
µk+1= [µk+βc(wk+1)]+= arg min
µ∈Rm
+1
2∥µ−(µk+βc(wk+1))∥2.
By the optimality condition of this projection, we have
0∈µk+1−(µk+βc(wk+1)) +NRm
+(µk+1),
which together with Eq. (33) implies that
1
β(µk+1−µk)∈∂µl(wk+1,µk+1). (39)
In view of this, Eqs. (10), (11) and (38), we can see that
dist∞(0,∂wl(wk+1,µk+1))Eq.(38)
≤ dist∞(0,∂ℓk(wk+1)) +1
β∥wk+1−wk∥∞
Eq.(10)
≤τk+1
β∥wk+1−wk∥∞Eq.(11)
≤ϵ1,
dist∞(0,∂µl(wk+1,µk+1))Eq.(39)
≤1
β∥µk+1−µk∥∞Eq.(11)
≤ϵ2.
These along with Eq. (33) and Definition 1 imply that (wk+1,µk+1)is an (ϵ1,ϵ2)-KKT solution of Eq. (5),
which proves this theorem as desired.
A.2 Proof of Lemma 3.1
Define
wk
∗:= arg min
wℓk(w), µk
∗:= [µk+βc(wk
∗)]+,∀k≥0, (40)
which, by Eq. (36), is equivalent to
(wk
∗,µk
∗) =J(wk,µk). (41)
Recall that (w∗,µ∗)is assumed to be any pair of optimal solutions to Eq. (5) and Eq. (7). Toward the proof,
we first present an intermediate result, which mostly follows the fact that Jis firmly nonexpansive.
Lemma A.2. Suppose that Assumptions 0 to 2 hold. Let {(wk,µk)}k≥0be generated by Algorithm 1. Let
(wk
∗,µk
∗)be defined in Eq. (40)for allk≥0. Then the following relations hold.
∥(wk,µk)−(wk
∗,µk
∗)∥2+∥(wk
∗,µk
∗)−(w∗,µ∗)∥2≤∥(wk,µk)−(w∗,µ∗)∥2,∀k≥0, (42)
∥(wk,µk)−(w∗,µ∗)∥≤∥ (w0,µ0)−(w∗,µ∗)∥+β√nk−1/summationdisplay
j=0τj,∀k≥0. (43)
21Published in Transactions on Machine Learning Research (05/2024)
Proof.Since (w∗,µ∗)is a solution to the monotone inclusion problem Eq. (35), we have
(0,0)∈T(w∗,µ∗),and (w∗,µ∗) =J(w∗,µ∗). (44)
Moreover, sinceTis maximally monotone, its resolvent Jis firmly nonexpansive (see, e.g., Corollary 23.9
of Bauschke & Combettes (2017)), that is, ∥J(w,µ)−J(w′,µ′)∥2+∥(I−J )(w,µ)−(I−J )(w′,µ′)∥2≤
∥(w,µ)−(w′,µ′)∥2for any feasible pairs (w,µ)and(w′,µ′). Using Eqs. (41) and (44), we obtain that
∥(wk,µk)−(wk
∗,µk
∗)∥2+∥(wk
∗,µk
∗)−(w∗,µ∗)∥2
Eqs. (41)and (44)=∥(I−J )(wk,µk)−(I−J )(w∗,µ∗)∥2+∥J(wk,µk)−J(w∗,µ∗)∥2
≤∥(wk,µk)−(w∗,µ∗)∥2.(firm nonexpansiveness of J)
Hence, Eq. (42) holds as desired.
Now we prove Eq. (43). It suffices to consider the case where k≥1. We have
∥(wk,µk)−(w∗,µ∗)∥≤∥ (wk,µk)−J(wk−1,µk−1)∥+∥J(wk−1,µk−1)−J(w∗,µ∗)∥
≤β√nτk−1+∥(wk−1,µk−1)−(w∗,µ∗)∥, (45)
where we have invoked Lemma A.1 and the nonexpansiveness of Jto obtain the final upper bound. Re-
peatedly applying Eq. (45) for iterates (w1,µ1)through (wk−1,µk−1), we have
β√nτk−1+∥(wk−1,µk−1)−(w∗,µ∗)∥≤β√nk−1/summationdisplay
j=0τj+∥(w0,µ0)−(w∗,µ∗)∥, (46)
completing the proof.
Proof of Lemma 3.1. Notice from Algorithm 1 that τk= ¯s/(k+ 1)2for allk≥0. Therefore, one has/summationtext∞
j=0τj≤2¯s. In view of this, Eq. (15), and Lemma A.2, we observe that
max{∥wk−w∗∥,∥µk−µ∗∥,∥wk−wk
∗∥,∥wk
∗−w∗∥}≤r0+ 2√n¯sβ,∀k≥0. (47)
wherer0is defined in Eq. (15), and βand¯sare inputs of Algorithm 1. Eq. (47) implies that wk∈Q 1for
allk≥0, completing the proof.
A.3 Proof of Theorem 3.2(a)
To prove Theorem 3.2(a), we first present a general technical lemma on the convergence rate of an inexact
PPA applied to monotone inclusion problems.
Lemma A.3 (restatement of Lemma 3 of Lu & Zhou (2023) ).Let/tildewideT:Rp⇒Rqbe a maximally
monotone operator and z∗∈Rpsuch that 0∈/tildewideT(z∗). Let{zk}be a sequence generated by an inexact PPA,
starting with z0and obtaining zk+1by approximately evaluating /tildewideJ(zk)such that
∥zk+1−/tildewideJ(zk)∥≤ek
for someβ >0andek≥0, where/tildewideJ:= (I+β/tildewideT)−1andIis the identity operator. Then, for any K≥1,
we have
min
K≤k≤2K∥zk+1−zk∥≤√
2/parenleftig
∥z0−z∗∥+ 2/summationtext2K
k=0ek/parenrightig
√
K+ 1.
Proof of Theorem 3.2(a). Observe that Algorithm 1 terminates when two consecutive iterates (wk+1,µk+1)
and(wk,µk)are close. We use this observation and Lemmas A.1 and A.3 to derive the maximum number
of outer iterations of Algorithm 1.
22Published in Transactions on Machine Learning Research (05/2024)
Recall that/summationtext∞
j=0τj≤2¯s. It follows from Lemmas A.1 and A.3 that
min
K≤k≤2K1
β∥(wk+1,µk+1)−(wk,µk)∥≤√
2/parenleftig
∥(w0,µ0)−(w∗,µ∗)∥+ 2√nβ/summationtext∞
j=0τj/parenrightig
β√
K+ 1
≤√
2/parenleftbig
∥(w0,µ0)−(w∗,µ∗)∥+ 4√n¯sβ/parenrightbig
β√
K+ 1=√
2 (r0+ 4√n¯sβ)
β√
K+ 1,
which then implies that
min
K≤k≤2K/braceleftbigg
τk+1
β∥wk+1−wk∥∞/bracerightbigg
≤¯s
(K+ 1)2+√
2 (r0+ 4√n¯sβ)
β√
K+ 1≤/bracketleftbigg
¯s+√
2 (r0+ 4√n¯sβ)
β/bracketrightbigg1√
K+ 1,
min
K≤k≤2K1
β∥µk+1−µk∥∞≤√
2 (r0+ 4√n¯sβ)
β√
K+ 1.
WeseefromtheseandtheterminationcriterioninEq.(11)thatthenumberofouteriterationsofAlgorithm1
is at most
Kϵ1,ϵ2:=/bracketleftbigg
¯s+√
2(r0+ 4√n¯sβ)
β/bracketrightbigg2
max{ϵ−2
1,ϵ−2
2}=O(max{ϵ−2
1,ϵ−2
2}). (48)
Hence, Theorem 3.2(a) holds as desired.
B Proofs of the main results in Section 4
Throughout this section, we let ( ˜w∗,u∗)be the optimal solution of Eq. (24), and λ∗be the associated
Lagrangian multiplier. Recall from the definition of ˜u0
iin Algorithm 2 and Eq. (21) that
˜ut
i=ut
i+λt
i/ρi,∀1≤i≤n,t≥0. (49)
B.1 Proof of Lemma 4.1
For notational convenience, write f0(w)≡0. Then, by Eqs. (13) and (14), one can verify that
∇Pi,k(w) =∇fi(w) +∇ci(w)[µk
i+βci(w)]++1
(n+ 1)β(w−wk),∀0≤i≤n. (50)
Proof of Lemma 4.1. Fix an arbitrary w∈Rdand a bounded open set Uwcontainingw. We suppose that
∇fiisLw,1-Lipschitz continuous on Uw, and∇ciisLw,2-Lipschitz continuous on Uw. Also, let Uw,1=
supw∈Uw∥ci(w)∥andUw,2= supw∈Uw∥∇ci(w)∥. By Eqs. (13), (14) and (50)) one has for each 0≤i≤n
andu,v∈Uwthat
∥∇Pi,k(u)−∇Pi,k(v)∥Eq.(50)
≤ ∥∇fi(u)−∇fi(v)∥+∥∇ci(u)−∇ci(v)∥∥[µk
i+βci(u)]+∥
+∥[µk
i+βci(u)]+−[µk
i+βci(v)]+∥∥∇ci(v)∥+1
(n+ 1)β∥u−v∥
≤Lw,1∥u−v∥+ (∥µk
i∥+βUw,1)Lw,2∥u−v∥
+β∥ci(u)−ci(v)∥∥∇ci(v)∥+1
(n+ 1)β∥u−v∥
≤/bracketleftbigg
Lw,1+ (∥µk
i∥+βUw,1)Lw,2+βU2
w,2+1
(n+ 1)β/bracketrightbigg
∥u−v∥.
Therefore,∇Pi,k(u)is locally Lipschitz continuous on Rd, and the conclusion holds as desired.
23Published in Transactions on Machine Learning Research (05/2024)
B.2 Proof of Theorem 4.1
Proof of Theorem 4.1. In view of the termination criterion Eq. (23), it suffices to show that
dist∞(0,∂ℓ(wT+1))≤εT+1+n/summationdisplay
i=1˜εi,T+1.
By the definition of ℓin Eq. (16), one has that
∂ℓ(wT+1) =n/summationdisplay
i=0∇Pi(wT+1) +∂h(wT+1). (51)
In addition, notice from Eqs. (18), (19) and (49) that
∂φ0,T(wT+1) =∇P0(wT+1) +n/summationdisplay
i=1ρi(wT+1−˜uT
i) +∂h(wt+1)
=∇P0(wT+1) +n/summationdisplay
i=1[ρi(wT+1−uT
i)−λT
i] +∂h(wT+1),
∇φi,T(wT+1) =∇Pi(wT+1) +λT
i,∀1≤i≤n.
Combining these with Eq. (51), we obtain that
∂ℓ(wT+1) =∂φ0,T(wT+1) +n/summationdisplay
i=1[∇φi,T(wT+1)−ρi(wT+1−uT
i)],
which together with dist∞(0,∂φ 0,T(wT+1))≤εT+1(see Algorithm 2 and Eq. (22)) implies that
dist∞(0,∂ℓ(wT+1))≤dist∞(0,∂φ 0,T(wT+1)) +n/summationdisplay
i=1∥∇φi,T(wT+1)−ρi(wT+1−uT
i)∥∞
≤εT+1+n/summationdisplay
i=1˜εi,T+1,
as desired.
B.3 Proof of Lemma 4.2
To prove Lemma 4.2, we use convergence analysis techniques for ADMM to show that the distances between
iterates{uk
i}1≤i≤nandwkand the optimal solution ˜w∗are controlled by the distance between the initial
iterate ˜w0and˜w∗. To the best of our knowledge, such boundedness results without assuming global Lipschitz
continuity are entirely new in the literature on ADMM.
Proof of Lemma 4.2. From the optimality conditions and stopping criteria for Eq. (18) and Eq. (19), there
existet+1
i’s for 0≤i≤nwith∥et+1
i∥∞≤εt+1andht+1∈∂h(wt+1)so that:
et+1
0=∇P0(wt+1) +ht+1+n/summationdisplay
i=1ρi(wt+1−˜ut
i)Eq.(49)=∇P0(wt+1) +ht+1+n/summationdisplay
i=1[ρi(wt+1−ut
i)−λt
i]
Eq.(20)=∇P0(wt+1) +ht+1+n/summationdisplay
i=1[ρi(ut+1
i−ut
i)−λt+1
i] (52)
and
et+1
i=∇φi,t(ut+1
i)Eq.(19)=∇Pi(ut+1
i) +λt
i+ρi(ut+1
i−wt+1)Eq.(20)=∇Pi(ut+1
i) +λt+1
i,∀1≤i≤n.(53)
24Published in Transactions on Machine Learning Research (05/2024)
Moreover, since ˜w∗andu∗are the optimal solution of Eq. (24) with the associated Lagrangian multiplier
λ∗∈Rm, we have by the optimality condition that there exists h∗∈∂h( ˜w∗)such that
∇Pi(u∗
i) +λ∗
i= 0,∇P0( ˜w∗) +h∗−n/summationdisplay
i=1λ∗
i= 0, u∗
i= ˜w∗,∀1≤i≤n. (54)
Recall that Pi,0≤i≤n, are strongly convex with the modulus σ>0, we have
σ∥ut+1
i−˜w∗∥2≤⟨ut+1
i−˜w∗,∇Pi(ut+1
i)−∇Pi( ˜w∗)⟩ (strong convexity of Pi)
=⟨ut+1
i−˜w∗,−λt+1
i+λ∗
i+et+1
i⟩ ( ˜w∗=u∗
i,∇Pi(u∗
i) =λ∗
i, and Eq. (53) )
≤⟨ut+1
i−˜w∗,−λt+1
i+λ∗
i⟩+σ
2∥ut+1
i−˜w∗∥2+1
2σ∥et+1
i∥2,
(⟨a,b⟩≤t/2∥a∥2+ 1/(2t)∥b∥2for alla,b∈Rdandt>0),
and
σ∥wt+1−˜w∗∥2≤⟨wt+1−˜w∗,∇P0(wt+1) +ht+1−∇P0( ˜w∗)−h∗⟩(strong convexity of P0+h)
=⟨wt+1−˜w∗,n/summationdisplay
i=1[λt+1
i−λ∗
i−ρi(ut+1
i−ut
i)] +et+1
0⟩,(Eq. (52) and Eq. (54) )
≤⟨wt+1−˜w∗,n/summationdisplay
i=1[λt+1
i−λ∗
i−ρi(ut+1
i−ut
i)]⟩+σ
2∥wt+1−˜w∗∥2+1
2σ∥et+1
0∥2,
(⟨a,b⟩≤t/2∥a∥2+ 1/(2t)∥b∥2for alla,b∈Rdandt>0).
Summing up these inequalities and rearranging the terms, we obtain that
σ
2(∥wt+1−˜w∗∥2+n/summationdisplay
i=1∥ut+1
i−˜w∗∥2)
≤n/summationdisplay
i=1⟨wt+1−˜w∗,λt+1
i−λ∗
i−ρi(ut+1
i−ut
i)⟩+1
2σ∥et+1
0∥2+n/summationdisplay
i=1(⟨ut+1
i−˜w∗,−λt+1
i+λ∗
i⟩+1
2σ∥et+1
i∥2)
≤n/summationdisplay
i=1⟨wt+1−ut+1
i,λt+1
i−λ∗
i⟩+n/summationdisplay
i=1ρi⟨wt+1−˜w∗,ut
i−ut+1
i⟩+n+ 1
2σε2
t+1
(∥et+1
i∥≤εt+1for all 0≤i≤nandt≥0)
Eq.(20)=n/summationdisplay
i=11
ρi⟨λt
i−λt+1
i,λt+1
i−λ∗
i⟩+n/summationdisplay
i=1ρi⟨wt+1−˜w∗,ut
i−ut+1
i⟩+n+ 1
2σε2
t+1, (55)
Notice that the following well-known identities hold:
⟨wt+1−˜w∗,ut
i−ut+1
i⟩=1
2(∥wt+1−ut+1
i∥2−∥wt+1−ut
i∥2+∥˜w∗−ut
i∥2−∥˜w∗−ut+1
i∥2),(56)
⟨λt
i−λt+1
i,λt+1
i−λ∗
i⟩=1
2(∥λ∗
i−λt
i∥2−∥λ∗
i−λt+1
i∥2−∥λt
i−λt+1
i∥2). (57)
These along with Eqs. (20) and (55) imply that
σ
2(∥wt+1−˜w∗∥2+n/summationdisplay
i=1∥ut+1
i−˜w∗∥2) +n/summationdisplay
i=1ρi
2∥wt+1−ut
i∥2−n+ 1
2σε2
t+1
Eq.(55))
≤n/summationdisplay
i=11
ρi⟨λt
i−λt+1
i,λt+1
i−λ∗
i⟩+n/summationdisplay
i=1ρi⟨wt+1−˜w∗,ut
i−ut+1
i⟩+n/summationdisplay
i=1ρi
2∥wt+1−ut
i∥2
Eq.(56)
≤n/summationdisplay
i=11
ρi⟨λt
i−λt+1
i,λt+1
i−λ∗
i⟩+n/summationdisplay
i=1ρi
2(∥˜w∗−ut
i∥2−∥˜w∗−ut+1
i∥2+∥wt+1−ut+1
i∥2)
25Published in Transactions on Machine Learning Research (05/2024)
Eq.(20)=n/summationdisplay
i=11
ρi⟨λt
i−λt+1
i,λt+1
i−λ∗
i⟩+n/summationdisplay
i=11
2ρi∥λt+1
i−λt
i∥2+n/summationdisplay
i=1ρi
2(∥˜w∗−ut
i∥2−∥˜w∗−ut+1
i∥2)
Eq.(57)=n/summationdisplay
i=11
2ρi(∥λ∗
i−λt
i∥2−∥λ∗
i−λt+1
i∥2) +n/summationdisplay
i=1ρi
2(∥˜w∗−ut
i∥2−∥˜w∗−ut+1
i∥2)
=n/summationdisplay
i=1[(ρi
2∥˜w∗−ut
i∥2+1
2ρi∥λ∗
i−λt
i∥2)−(ρi
2∥˜w∗−ut+1
i∥2+1
2ρi∥λ∗
i−λt+1
i∥2)]. (58)
Summing up this inequality over t= 0,...,Tfor anyT≥0, we obtain that
T/summationdisplay
t=0/bracketleftigg
σ
2/parenleftigg
∥wt+1−˜w∗∥2+n/summationdisplay
i=1∥ut+1
i−˜w∗∥2/parenrightigg
+n/summationdisplay
i=1ρi
2∥wt+1−ut
i∥2−n+ 1
2σε2
t+1/bracketrightigg
≤n/summationdisplay
i=1/bracketleftbigg/parenleftbiggρi
2∥˜w∗−u0
i∥2+1
2ρi∥λ∗
i−λ0
i∥2/parenrightbigg
−/parenleftbiggρi
2∥˜w∗−uT+1
i∥2+1
2ρi∥λ∗
i−λT+1
i∥2/parenrightbigg/bracketrightbigg
.(59)
Recall from Algorithm 2 that εt+1=qt,u0
i= ˜w0, andλ0
i=−∇Pi( ˜w0). Notice from Eq. (54) that ˜w∗=u∗
i
andλ∗
i=−∇Pi(u∗
i). By these and Eq. (59), one can deduce that
σ
2(∥wt+1−˜w∗∥2+n/summationdisplay
i=1∥ut+1
i−˜w∗∥2)≤n+ 1
2σ∞/summationdisplay
t=0q2t+n/summationdisplay
i=1/parenleftbiggρi
2∥˜w∗−u0
i∥2+1
2ρi∥λ∗
i−λ0
i∥2/parenrightbigg
≤n+ 1
2σ(1−q2)+n/summationdisplay
i=1/parenleftbiggρi
2∥˜w∗−u0
i∥2+1
2ρi∥λ∗
i−λ0
i∥2/parenrightbigg
=n+ 1
2σ(1−q2)+n/summationdisplay
i=1/parenleftbiggρi
2∥˜w∗−˜w0∥2+1
2ρi∥∇Pi( ˜w∗)−∇Pi( ˜w0)∥2/parenrightbigg
.
In view of this and the definition of Qin Eq. (29), we can observe that wt+1∈Qandut+1
i∈Qfor allt≥0
and1≤i≤n. Hence, the conclusion of this lemma holds as desired.
B.4 Proof of Theorem 4.2
We first prove an auxiliary recurrence result that will be used later.
Lemma B.1. Assume that r,c> 0andq∈(0,1). Let{at}t≥0be a sequence satisfying
(1 +r)at+1≤at+cq2t,∀t≥0. (60)
Then we have
at+1≤max/braceleftbigg
q,1
1 +r/bracerightbiggt+1/parenleftbigg
a0+c
1−q/parenrightbigg
,∀t≥0. (61)
Proof.It follows Eq. (60) that
at+1≤1
1 +rat+1
1 +rcq2t≤1
(1 +r)2at−1+cq2(t−1)
(1 +r)2+cq2t
1 +r
≤···≤1
(1 +r)t+1a0+t/summationdisplay
i=0cq2i
(1 +r)t+1−i=1
(1 +r)t+1a0+ct/summationdisplay
i=0qi
(1 +r)t+1−iqi
≤1
(1 +r)t+1a0+cmax/braceleftbigg
q,1
1 +r/bracerightbiggt+1t/summationdisplay
i=0qi
(qi≤max{q,1/(1 +r)}iand1/(1 +r)t+1−i≤max{q,1/(1 +r)}t+1−i)
26Published in Transactions on Machine Learning Research (05/2024)
≤1
(1 +r)t+1a0+c
1−qmax/braceleftbigg
q,1
1 +r/bracerightbiggt+1
≤max/braceleftbigg
q,1
1 +r/bracerightbiggt+1/parenleftbigg
a0+c
1−q/parenrightbigg
.
Hence, Eq. (61) holds as desired.
The following lemma proves the Lipschitz continuity of ∇PionQ.
Lemma B.2. LetQbe defined in Eq. (29). Then there exists some L∇P>0such that
∥∇Pi(u)−∇Pi(v)∥≤L∇P∥u−v∥,∀u,v∈Q,0≤i≤n. (62)
Proof.Notice from Eq. (29) that the set Qis convex and compact. By this and the local Lipschitz continuity
of∇PionRd, one can verify that there exists some constant L∇P>0such that Eq. (62) holds (see also
Lemma 1 in Lu & Mei (2023)).
We introduce a potential function Stto measure the convergence of Algorithm 2:
St:=n/summationdisplay
i=1/parenleftbiggρi
2∥˜w∗−ut
i∥2+1
2ρi∥λ∗
i−λt
i∥2/parenrightbigg
,∀t≥0. (63)
The following lemma gives a recursive result of St, which will play a key role on establishing the global
convergence rate for Algorithm 2 in Theorem 4.2.
Lemma B.3. Suppose that Assumptions 0 to 2 hold. Let {wt+1}t≥0and{ut+1
i}1≤i≤n,t≥0be all the iterates
generated by Algorithm 2. Then we have
St≤qt
r/bracketleftigg
S0+1
1−q/parenleftigg
n+ 1
2σ+n/summationdisplay
i=1σ
ρ2
i+ 2L2
∇P/parenrightigg/bracketrightigg
,∀t≥0, (64)
whereσandL∇Pare given in Eq. (17)and Lemma B.2, respectively, qandρi,1≤i≤n, are inputs of
Algorithm 2, and
qr:= max/braceleftbigg
q,1
1 +r/bracerightbigg
, r := min
1≤i≤n/braceleftbiggσρi
ρ2
i+ 2L2
∇P/bracerightbigg
. (65)
Proof.Recall from Eq. (58) that
St=n/summationdisplay
i=1/parenleftbiggρi
2∥˜w∗−ut
i∥2+1
2ρi∥λ∗
i−λt
i∥2/parenrightbigg
≥n/summationdisplay
i=1/parenleftbiggρi+σ
2∥˜w∗−ut+1
i∥2+1
2ρi∥λ∗
i−λt+1
i∥2+ρi
2∥wt+1−ut
i∥2/parenrightbigg
+σ
2∥wt+1−˜w∗∥2−n+ 1
2σε2
t+1
≥n/summationdisplay
i=1/parenleftbiggρi+σ
2∥˜w∗−ut+1
i∥2+1
2ρi∥λ∗
i−λt+1
i∥2/parenrightbigg
−n+ 1
2σε2
t+1. (66)
Also, notice from Eqs. (53), (54) and (62) that
∥λ∗
i−λt+1
i∥2Eqs. (53)and (54)
≤ (∥∇Pi( ˜w∗)−∇Pi(ut+1
i)∥+∥et+1
i∥)2Eq.(62)
≤ 2L2
∇P∥˜w∗−ut+1
i∥2+ 2ε2
t+1,
which implies that
∥˜w∗−ut+1
i∥2≥2ρi
ρ2
i+ 2L2
∇P/parenleftbiggρi
2∥˜w∗−ut+1
i∥2+1
2ρi∥λ∗
i−λt+1
i∥2/parenrightbigg
−2ε2
t+1
ρ2
i+ 2L2
∇P. (67)
27Published in Transactions on Machine Learning Research (05/2024)
Plugging this into Eq. (66), we have
StEq.(67)
≥n/summationdisplay
i=1/parenleftbigg
1 +σρi
ρ2
i+ 2L2
∇P/parenrightbigg/parenleftbiggρi
2∥˜w∗−ut+1
i∥2+1
2ρi∥λ∗
i−λt+1
i∥2/parenrightbigg
−n+ 1
2σq2t−n/summationdisplay
i=1σ
ρ2
i+ 2L2
∇Pq2t
= (1 +r)St+1−/parenleftigg
n+ 1
2σ+n/summationdisplay
i=1σ
ρ2
i+ 2L2
∇P/parenrightigg
q2t(r:= min
1≤i≤nσρi/(ρ2
i+ 2L2
∇P)).
Whent= 0, Eq. (64) holds clearly. When t≥1, by the above inequality, Eq. (65), and Lemma B.1 with
(at,c) = (St,n+1
2σ+/summationtextn
i=1σ
ρ2
i+2L2
∇P), we obtain that
St≤max/braceleftbigg
q,1
1 +r/bracerightbiggt/bracketleftigg
S0+1
1−q/parenleftigg
n+ 1
2σ+n/summationdisplay
i=1σ
ρ2
i+ 2L2
∇P/parenrightigg/bracketrightigg
=qt
r/bracketleftigg
S0+1
1−q/parenleftigg
n+ 1
2σ+n/summationdisplay
i=1σ
ρ2
i+ 2L2
∇P/parenrightigg/bracketrightigg
.
Therefore, the conclusion of this lemma is true as desired.
Proof of Theorem 4.2. Notice that Algorithm 2 terminates when εt+1+/summationtextn
i=1˜εi,t+1is small. Next, we show
that this quantity is bounded by Stdefined in Eq. (63) plus other small quantities, and then use Lemma B.3
to bound the maximum number of iterations of Algorithm 2.
By Eq. (22), and the fact that ∥∇φi,t(ut+1
i)∥∞≤εt+1(see Algorithm 2), one can obtain that
εt+1+n/summationdisplay
i=1˜εi,t+1Eq.(22)=εt+1+n/summationdisplay
i=1∥[∇φi,t(wt+1)−ρi(wt+1−ut
i)]∥∞
≤εt+1+n/summationdisplay
i=1∥∇φi,t(ut+1
i)∥∞+n/summationdisplay
i=1∥∇φi,t(wt+1)−∇φi,t(ut+1
i)∥+n/summationdisplay
i=1ρi∥wt+1−ut
i∥
(∥u∥∞≤∥u∥for allu∈Rdand the triangle inequality )
≤(n+ 1)εt+1+n/summationdisplay
i=1(L∇P+ρi)∥wt+1−ut+1
i∥+n/summationdisplay
i=1ρi∥wt+1−ut
i∥, (68)
where the second inequality follows from
∥∇φi,t(wt+1)−∇φi,t(ut+1
i)∥Eq.(19)
≤ ∥∇Pi(wt+1)−∇Pi(ut+1
i)∥+ρi∥wt+1−ut+1
i∥
Eq.(62)
≤(L∇P+ρi)∥wt+1−ut+1
i∥,∀1≤i≤n.
Next, we derive upper bounds for ∥wt+1−ut+1
i∥andρi∥wt+1−ut
i∥, respectively. First, by Eqs. (58), (63)
and (64), we have
σ
4∥wt+1−ut+1
i∥2≤σ
2∥wt+1−˜w∗∥2+σ
2∥ut+1
i−˜w∗∥2
Eq.(58)
≤n/summationdisplay
i=1(ρi
2∥˜w∗−ut
i∥2+1
2ρi∥λ∗
i−λt
i∥2) +n+ 1
2σε2
t+1 (69)
=St+n+ 1
2σq2t(the definition of Stin Eq. (63) and εt+1=qtfor allt≥0)
Eq.(64)
≤qt
r/bracketleftigg
S0+1
1−q/parenleftigg
n+ 1
2σ+n/summationdisplay
i=1σ
ρ2
i+ 2L2
∇P/parenrightigg/bracketrightigg
+n+ 1
2σq2t
28Published in Transactions on Machine Learning Research (05/2024)
≤

qt/2
r/bracketleftigg
S0+1
1−q/parenleftigg
n+ 1
2σ+n/summationdisplay
i=1σ
ρ2
i+ 2L2
∇P/parenrightigg/bracketrightigg1/2
+/radicalbigg
n+ 1
2σqt

2
(a2+b2≤(a+b)2for alla,b≥0).(70)
Using again Eqs. (58), (63) and (64), we obtain that
1
2(n/summationdisplay
i=1ρi∥wt+1−ut
i∥)2≤(n/summationdisplay
i=1ρi)(n/summationdisplay
i=1ρi
2∥wt+1−ut
i∥2) ( Cauchy-Schwarz inequality )
Eq.(58)
≤ (n/summationdisplay
i=1ρi)n/summationdisplay
i=1(ρi
2∥˜w∗−ut
i∥2+1
2ρi∥λ∗
i−λt
i∥2) + (n/summationdisplay
i=1ρi)n+ 1
2σε2
t+1
= (n/summationdisplay
i=1ρi)/parenleftbigg
St+n+ 1
2σq2t/parenrightbigg
(the definition of Stin Eq. (63) and εt+1=qtfor allt≥0)
Eq.(64)
≤ (n/summationdisplay
i=1ρi)/braceleftigg/bracketleftigg
S0+1
1−q/parenleftigg
n+ 1
2σ+n/summationdisplay
i=1σ
ρ2
i+ 2L2
∇P/parenrightigg/bracketrightigg
qt
r+n+ 1
2σq2t/bracerightigg
≤(n/summationdisplay
i=1ρi)

qt/2
r/bracketleftigg
S0+1
1−q/parenleftigg
n+ 1
2σ+n/summationdisplay
i=1σ
ρ2
i+ 2L2
∇P/parenrightigg/bracketrightigg1/2
+/radicalbigg
n+ 1
2σqt

2
(a2+b2≤(a+b)2for alla,b≥0).(71)
Combining Eqs. (68), (70) and (71), we obtain that
εt+1+n/summationdisplay
i=1˜εi,t+1≤(n+ 1)qt+
2√σn/summationdisplay
i=1(L∇P+ρi) +/radicaltp/radicalvertex/radicalvertex/radicalbt2n/summationdisplay
i=1ρi

·

/bracketleftigg
S0+1
1−q/parenleftigg
n+ 1
2σ+n/summationdisplay
i=1σ
ρ2
i+ 2L2
∇P/parenrightigg/bracketrightigg1/2
qt/2
r+/radicalbigg
n+ 1
2σqt


≤(n+ 1)qt/2
r+
2√σn/summationdisplay
i=1(L∇P+ρi) +/radicaltp/radicalvertex/radicalvertex/radicalbt2n/summationdisplay
i=1ρi

·/braceleftigg/bracketleftigg
S0+1
1−q/parenleftigg
n+ 1
2σ+n/summationdisplay
i=1σ
ρ2
i+ 2L2
∇P/parenrightigg/bracketrightigg1/2
+/radicalbigg
n+ 1
2σ/bracerightigg
qt/2
r
(q≤qr≤q1/2
r<1). (72)
Recall from Algorithm 2 and Eq. (54) that (u0
i,λ0
i) = ( ˜w0,−∇Pi( ˜w0))andλ∗
i=−∇Pi( ˜w∗). By these and
Eq. (63), one has
S0=n/summationdisplay
i=1/parenleftbiggρi
2∥˜w∗−˜w0∥2+1
2ρi∥∇Pi( ˜w∗)−∇Pi( ˜w0)∥2/parenrightbigg
. (73)
For convenience, denote
b:=
2√σn/summationdisplay
i=1(L∇P+ρi) +/radicaltp/radicalvertex/radicalvertex/radicalbt2n/summationdisplay
i=1ρi

·/braceleftigg/bracketleftiggn/summationdisplay
i=1/parenleftbiggρi
2∥˜w∗−˜w0∥2+1
2ρi∥∇Pi( ˜w∗)−∇Pi( ˜w0)∥2/parenrightbigg
+1
1−q/parenleftigg
n+ 1
2σ+n/summationdisplay
i=1σ
ρ2
i+ 2L2
∇P/parenrightigg/bracketrightigg1/2
+/radicalbigg
n+ 1
2σ/bracerightigg
.
29Published in Transactions on Machine Learning Research (05/2024)
Using this, Eqs. (72) and (73), we obtain that
εt+1+n/summationdisplay
i=1˜εi,t+1≤(n+ 1 +b)qt/2
r.
This along with the termination criterion in Eq. (23) implies that the number of iterations of Algorithm 2 is
bounded above by/ceilingleftbigg2 log(τ/(n+ 1 +b))
logqr/ceilingrightbigg
+ 1 =O(|logτ|). (74)
Hence, the conclusion of this theorem holds as desired.
We observe from the proof of Theorem 4.2 that under Assumptions 0 to 2, the number of iterations of
Algorithm 2 is bounded by the quantity in Eq. (74).
C Proof of Theorem 3.2(b)
To establish the total inner-iteration complexity, we first show that all the inner iterates produced by
Algorithm 2 for solving all the subproblems of form Eq. (12) within Algorithm 1 are in a compact set
(i.e.,Q2later), and then estimate the Lipschitz modulus of ∇Pi,kfor all 0≤i≤nand allkoverQ2. Then
we can bound the inner-iteration complexity based on the size of Q2and the Lipschitz modulus.
Boundedness of all inner iterates Recall from Eq. (15) that Q1is a compact set. Let
U∇f:= sup
w∈Q 1max
1≤i≤n∥∇fi(w)∥, U∇c:= sup
w∈Q 1max
0≤i≤n∥∇ci(w)∥, Uc:= sup
w∈Q 1max
0≤i≤n∥ci(w)∥.(75)
Since∇fifor all 1≤i≤nare locally Lipschitz, they are Lipschitz on Q1with someL∇f>0. Similarly,
∇cifor all 0≤i≤nare Lispchitz onQ1with some modulus L∇c>0. Hence,∇Pi,kfor all 0≤i≤nand
allkare Lipschitz continuous on Q1:
∥∇Pi,k(u)−∇Pi,k(v)∥Eq.(50)
≤ ∥∇fi(u)−∇fi(v)∥+∥[µk
i+βci(u)]+∥∥∇ci(u)−∇ci(v)∥
+∥[µk
i+βci(u)]+−[µk
i+βci(v)]+∥∥∇ci(v)∥+1
(n+ 1)β∥u−v∥
Eq.(81)
≤L∇f∥u−v∥+ (∥µ∗
i∥+∥µk
i−µ∗
i∥+βUc)L∇c∥u−v∥
+βU2
∇c∥u−v∥+1
(n+ 1)β∥u−v∥
Eq.(47)
≤L∇P,1∥u−v∥ (76)
where
L∇P,1:=L∇f+ (∥µ∗∥+r0+ 2√n¯sβ+βUc)L∇c+βU2
∇c+1
(n+ 1)β. (77)
The next lemma says that all the inner iterates generated by Algorithm 2 stay in a compact set.
Lemma C.1. Suppose that Assumptions 0 to 2 hold and let {wk,t+1}t≥0and{uk,t+1
i}1≤i≤n,t≥0be all the
inner iterates generated by Algorithm 2 for solving the subproblems of form Eq. (12)in Algorithm 1. Then
it holds that all these iterates stay in a compact set Q2, where
Q2:=/braceleftigg
v:∥v−u∥2≤(n+ 1)3β2
(1−q2)+ (n+ 1)βn/summationdisplay
i=1/bracketleftigg/parenleftigg
ρi+L2
∇P,1
ρi/parenrightigg
(r0+ 2√n¯sβ)2/bracketrightigg
,u∈Q 1/bracerightigg
,(78)
andL∇P,1andQ1are as defined in Eq. (77)and Eq.(15), respectively.
30Published in Transactions on Machine Learning Research (05/2024)
Proof.Recall that for any k≥0, the subproblem in Eq. (12) has an optimal solution wk
∗(see Eq. (40)), the
initial iterate of Algorithm 2 for solving Eq. (12) is wk, andPi,k,0≤i≤n, are strongly convex with modulus
1/[(n+ 1)β]. By Lemma 4.2 with (Pi,˜w∗,˜w0,σ) = (Pi,k,wk
∗,wk,1/[(n+ 1)β]), we obtain that{wk,t+1}t≥0
and{uk,t+1
i}t≥0,1≤i≤nstay in a set/tildewideQdefined as
/tildewideQ:=/braceleftigg
v:∥v−wk
∗∥2≤(n+ 1)3β2
(1−q2)+ (n+ 1)βn/summationdisplay
i=1/parenleftbigg
ρi∥wk
∗−wk∥2+1
ρi∥∇Pi,k(wk
∗)−∇Pi,k(wk)∥2/parenrightbigg/bracerightigg
.
Thus, to show the boundedness of all the inner iterates, it suffices to derive upper bounds for ∥wk
∗−wk∥
and∥∇Pi,k(wk
∗)−∇Pi,k(wk)∥that are independent of k. Sincewk,wk
∗∈Q 1, we have
∥∇Pi,k(wk
∗)−∇Pi,k(wk)∥≤L∇P,1∥wk
∗−wk∥ (79)
due to Eq. (76), where we note that L∇P,1is independent of k. Moreover,∥wk
∗−wk∥≤r0+ 2√n¯sβfrom
Eq. (47) provides a k-independent upper bound for ∥wk
∗−wk∥. Thus, we have
n/summationdisplay
i=1/parenleftbigg
ρi∥wk
∗−wk∥2+1
ρi∥∇Pi,k(wk
∗)−∇Pi,k(wk)∥2/parenrightbigg
≤n/summationdisplay
i=1/bracketleftigg/parenleftigg
ρi+L2
∇P,1
ρi/parenrightigg
(r0+ 2√n¯sβ)2/bracketrightigg
.(80)
Finally, combining the above results and noting that wk
∗∈Q 1completes the proof.
Lipschitz modulus of ∇Pi,kfor all 0≤i≤nand allkoverQ2LetL∇f,2be the Lipschitz constant
of∇fi,1≤i≤n, onQ2, andL∇c,2be the Lipschitz constant of ∇ci,0≤i≤n, onQ2. Also, define
U∇c,2:= sup
w∈Q 2max
0≤i≤n∥∇ci(w)∥, Uc,2:= sup
w∈Q 2max
0≤i≤n∥ci(w)∥. (81)
Using similar arguments as for deriving L∇P,1in Eq. (77), we can see that ∇Pi,k,0≤i≤n, are Lipschitz
continuous onQ2with modulus L∇P,2defined as
L∇P,2:=L∇f,2+ (∥µ∗∥+r0+ 2√n¯sβ+βUc,2)L∇c,2+βU2
∇c,2+1
(n+ 1)β. (82)
Proof of Theorem 3.2(b) Recall that Theorem 4.2 has established the number of iterations of Algo-
rithm 2 for solving each subproblem of Algorithm 1. In the rest of this proof, we derive an upper bound for
the total number of inner iterations for solving all subproblems of Algorithm 1.
We see from Lemma C.1 that all iterates generated by Algorithm 2 for solving Eq. (12) lie in Q2. Also,∇Pi,k,
1≤i≤n, areL∇P,2-Lipschitz continuous on Q2. Therefore, by Theorem 4.2 with (τ,Pi,σ,L∇P,˜w∗,˜w0) =
(τk,Pi,k,1/[(n+1)β],L∇P,2,wk
∗,wk)and the discussion at the end of Appendix B.4, one has that the number
of iterations of Algorithm 2 for solving Eq. (12) during the k-th outer loop is no more than
Tk:=/ceilingleftbigg2 log(τk/(n+ 1 +bk))
log ˜qr/ceilingrightbigg
+ 1 (83)
where
˜qr:= max/braceleftbigg
q,1
1 + ˜r/bracerightbigg
,˜r:= min
1≤i≤n/braceleftigg
ρi
(n+ 1)β(ρ2
i+ 2L2
∇P,2)/bracerightigg
,
bk:=
2/radicalbig
(n+ 1)βn/summationdisplay
i=1(L∇P,2+ρi) +/radicaltp/radicalvertex/radicalvertex/radicalbt2(n/summationdisplay
i=1ρi)

·/braceleftigg/bracketleftiggn/summationdisplay
i=1/parenleftbiggρi
2∥wk
∗−wk∥2+1
2ρi∥∇Pi,k(wk
∗)−∇Pi,k(wk)∥2/parenrightbigg
31Published in Transactions on Machine Learning Research (05/2024)
+1
1−q/parenleftigg
(n+ 1)2β
2+1
(n+ 1)βn/summationdisplay
i=11
ρ2
i+ 2L2
∇P,2/parenrightigg/bracketrightigg1/2
+ (n+ 1)/radicalbigg
β
2/bracerightigg
.
Plugging Eq. (80) into ¯b, we have that bk≤¯b, where
¯b:=
2/radicalbig
(n+ 1)βn/summationdisplay
i=1(L∇P,2+ρi) +/radicaltp/radicalvertex/radicalvertex/radicalbt2(n/summationdisplay
i=1ρi)

·

/bracketleftiggn/summationdisplay
i=1ρ2
i+L2
∇P,1
2ρi(r0+ 2√n¯sβ)2+1
1−q/parenleftigg
(n+ 1)2β
2+1
(n+ 1)βn/summationdisplay
i=11
ρ2
i+ 2L2
∇P,2/parenrightigg/bracketrightigg1/2
+ (n+ 1)/radicalbigg
β
2

,
which is independent of k. Bybk≤¯b,τk= ¯s/(k+ 1)2,k≤Kϵ1,ϵ2whereKϵ1,ϵ2is the upper bound for the
number of outer iterations as defined in Appendix A.3, and Eq. (83), one has that
Tk≤/ceilingleftbigg2 log((n+ 1 + ¯b)(Kϵ1,ϵ2+ 1)2/¯s)
log(˜q−1r)/ceilingrightbigg
+ 1.
Therefore, by Kϵ1,ϵ2=O(max{ϵ−2
1,ϵ−2
2}), onecanseethatthetotalnumberofinneriterationsofAlgorithm1
is at most
Kϵ1,ϵ2/summationdisplay
k=0Tk≤(Kϵ1,ϵ2+ 1)/parenleftbigg/ceilingleftbigg2 log((n+ 1 + ¯b)(Kϵ1,ϵ2+ 1)2/¯s)
log(˜q−1r)/ceilingrightbigg
+ 1/parenrightbigg
=/tildewideO(max{ϵ−2
1,ϵ−2
2}).(84)
Hence, Theorem 3.2(b) holds as desired.
Algorithm 3 A centralized proximal AL method for solving Eq. (85)
Input: tolerances ϵ1,ϵ2∈(0,1),w0∈dom(h),µ0≥0, nondecreasing positive {τk}k≥0, andβ >0.
fork= 0,1,2,...do
Apply a centralized solver to find an approximate solution wk+1to:
min
w/braceleftbigg
ℓk(w) =f(w) +h(w) +1
2β/parenleftbig
∥[µk+βc(w)]+∥2−∥µk∥2/parenrightbig
+1
2β∥w−wk∥2/bracerightbigg
such that
dist∞(0,∂ℓk(wk+1))≤τk.
Update the Lagrangian multiplier:
µk+1= [µk+βc(wk+1)]+.
Output (wk+1,µk+1)and terminate the algorithm if
∥wk+1−wk∥∞+βτk≤βϵ1,∥µk+1−µk∥∞≤βϵ2.
end for
D A centralized proximal AL method
In this part, we present a centralized proximal AL method (adapted from Algorithm 2 of Lu & Zhou (2023))
for solving the convex constrained optimization problem:
min
wf(w) +h(w) s.t. c(w)≤0, (85)
where the function f:Rd→Rand the mapping c:Rd→Rmare continuous differentiable and convex, and
his closed convex.
32Published in Transactions on Machine Learning Research (05/2024)
E Extra Numerical Results
E.1 Dataset description for Neyman-Pearson classification
In this part, we describe the datasets for Neyman-Pearson classification in Section 5.1. ‘breast-cancer-wisc’,
‘adult-a’, and ‘monks-1’ are three binary classification datasets. We present the total number of samples for
class 0 and class 1 and the number of features.
Table 3: Datasets for Neyman-Pearson classification
dataset class 0/class 1 feature dimension
breast-cancer-wisc 455/240 20
adult-a 24715/7840 21
monks-1 275/275 21
E.2 Linear equality constrained quadratic programming
In this subsection, we consider the linear equality constrained quadratic programming:
min
wn/summationdisplay
i=1/parenleftbigg1
2wTAiw+bT
iw/parenrightbigg
s.t. Ciw+di= 0,0≤i≤n, (86)
whereAi∈Rd×d,1≤i≤n, are positive semidefinite, bi∈Rd,1≤i≤n,Ci∈R˜m×d,0≤i≤n, and
di∈R˜m,0≤i≤n.
For each (d,n, ˜m), we randomly generate an instance of Eq. (86). In particular, for each 1≤i≤n, we first
generate a random matrix Aiby lettingAi=UiDiUT
i, whereDi∈Rd×dis a diagonal matrix. The diagonal
entries ofDiare generated randomly from a uniform distribution over [0.5,1], andUi∈Rd×dis a randomly
generated orthogonal matrix. We then randomly generate Ci,0≤i≤n, with all entries drawn from a
normal distribution with mean zero and a standard deviation of 1/√
d. Finally, we generate bi,1≤i≤n
anddi,0≤i≤nas random vectors uniformly selected from the unit Euclidean sphere.
We apply Algorithm 1 and cProx-AL (Algorithm 3) to find a (10−3,10−3)-optimal solution of Eq. (86), and
compare their solution quality. In particular, when implementing Algorithm 1, we exactly solve the quadratic
subproblems in Eqs. (18) and (19). We run 10 trials of Algorithm 1 and cProx-AL, where for each run, both
algorithms share the same initial point w0, randomly chosen from the unit Euclidean sphere. We set the
other parameters for Algorithm 1 and cProx-AL as µ0
i= (0,..., 0)T∀0≤i≤n,¯s= 0.1andβ= 10. We
also setρi= 1for each 1≤i≤nfor Algorithm 2.
Table 4: Numerical results for Eq. (86) using our algorithm vs. using cProx-AL. Inside the parentheses are
the respective standard deviations over 10 random trials.
objective value feasibility violation
n d ˜mAlgorithm 1 cProx-AL relative difference Algorithm 1 cProx-AL
1100 1 -0.23 (4.65e-6) -0.23 (2.38e-5) 1.63e-3 (1.01e-4) 3.33e-4 (1.14e-5) 5.68e-4 (2.82e-5)
300 3 -0.37 (2.74e-6) -0.37 (1.32e-6) 1.01e-3 (3.51e-5) 3.52e-4 (1.44e-5) 4.45e-4 (1.70e-5)
500 5 -0.30 (1.36e-5) -0.30 (7.54e-6) 1.34e-3 (4.62e-5) 4.38e-4 (5.36e-5) 3.85e-4 (1.05e-5)
5100 1 9.81 (7.18e-5) 9.80 (1.46e-5) 1.09e-3 (7.96e-6) 1.34e-4 (9.02e-6) 8.03e-4 (1.57e-6)
300 3 8.47 (8.12e-5) 8.45 (1.30e-5) 1.36e-3 (9.62e-6) 1.09e-4 (1.31e-5) 8.28e-4 (1.98e-6)
500 5 9.92 (4.43e-5) 9.91 (4.87e-6) 8.26e-4 (4.27e-6) 1.33e-4 (9.68e-6) 3.73e-4 (2.43e-7)
10100 1 49.40 (9.02e-5) 49.37 (5.82e-6) 5.59e-4 (1.67e-5) 7.31e-5 (7.54e-6) 5.88e-4 (1.34e-7)
300 3 41.49 (7.04e-5) 41.44 (5.48e-6) 1.14e-3 (1.77e-6) 8.56e-5 (2.27e-7) 8.73e-4 (7.26e-6)
500 5 41.45 (2.25e-5) 41.41 (5.30e-6) 9.39e-4 (4.94e-7) 9.29e-4 (2.55e-6) 7.66e-4 (1.37e-7)
33Published in Transactions on Machine Learning Research (05/2024)
We observe that Algorithm 1 and cProx-AL are capable of finding nearly feasible solutions, and achieve
similar objective value. In view of the small standard deviations, we observe that the convergence behavior
of Algorithm 1 remains stable across 10 trial runs.
34