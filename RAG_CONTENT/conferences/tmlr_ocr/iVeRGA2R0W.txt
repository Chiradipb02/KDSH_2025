Under review as submission to TMLR
Robust Pareto Set Identification With Contaminated Bandit
Feedback
Anonymous authors
Paper under double-blind review
Abstract
We consider the Pareto set identification (PSI) problem in multi-objective multi-armed
bandits (MO-MAB) with contaminated reward observations. At each arm pull, with some
fixed probability, the true reward samples are replaced with the samples from an arbitrary
contaminationdistributionchosenbyanadversary. Weconsider (α,δ)-PACPSIandpropose
asamplemedian-basedmulti-objectiveadaptiveeliminationalgorithmthatreturnsan (α,δ)-
PAC Pareto set upon termination with a sample complexity bound that depends on the
contamination probability. As the contamination probability decreases, we recover the well-
known sample complexity results in MO-MAB. We compare the proposed algorithm with
a mean-based method from MO-MAB literature, as well as an extended version that uses
median estimators, on several PSI problems under adversarial corruptions, including review
bombing and diabetes management. Our numerical results support our theoretical findings
anddemonstratethatrobustalgorithmdesigniscrucialforaccuratePSIundercontaminated
reward observations.
1 Introduction
Multi-armed bandit (MAB) problem involves decision making under uncertainty in which a finite amount of
resources are allocated between a limited number of options (arms) in order to optimize gain over time (or
equally minimize regret). In the classical setting, each arm is associated with a reward distribution that is
unknown or only partially known at the time of allocation and the information on distributions increase as
more observations are made over time (Thompson, 1933; Robbins, 1952; Lai & Robbins, 1985).
Over the last decades, MAB algorithms have been used in a broad range of applications such as medical
treatment allocation (Villar et al., 2015), financial portfolio design (Shen et al., 2015), adaptive routing
(Awerbuch & Kleinberg, 2004), cellular coverage optimization (Shen et al., 2018), news article recommen-
dation (Li et al., 2010), and online advertising (Pandey et al., 2007). Due to the security concerns in these
applications, adversarial MABs have attracted considerable attention. A variety of adversary models are
considered that come with different restrictions on the adversary. One of the widely studied attack model
is the attack that has a bounded attack value. Auer et al. (2002b) consider adversarial attacks bounded in
value and propose the famous Exp3 algorithm for robust learning, and derive both upper and lower bounds
on the regret. However, the asymptotic behaviour of the regret bound approaches to that of a linear bound
and hence becomes trivial, as the hardness of the competitor sequence increases. This type of adversarial at-
tack is further studied in Stoltz (2005); Audibert & Bubeck (2009); Bubeck & Cesa-Bianchi (2012). Another
popular attack model considered in the literature is the attack model that has a limited budget of attack
value. In this model, the total amount of corruption injected in reward samples over all rounds is limited by
a certain amount. Two notable works that study this kind of attack are Lykouris et al. (2018) and Gupta
et al. (2019). Another adversarial attack model is the bounded probability attack model. In this model,
an attack can occur at every round with fixed probability. Unlike the attack models mentioned before, this
model does not put any restrictions on the attack value. This attack model is considered in Kapoor et al.
(2019); Altschuler et al. (2019); Guan et al. (2020); Mathieu et al. (2024); Mukherjee et al. (2021); Wu et al.
(2023), and also in this study. Adversarial attacks are also studied within the context of stochastic linear
MAB (Bogunovic et al., 2021) and Gaussian process MAB (Han & Scarlett, 2022).
1Under review as submission to TMLR
Table 1: Comparison with the related work.
Work Setting Goal Adversary Bound
Auer et al. (2016) MO-MAB PSI Adv. free Samp. com.
Altschuler et al. (2019) MAB Best arm id. Obl.,Presc.,Mal. Samp. com.
Auer et al. (2002b) MAB Regret min. Bounded attack Cum. reg.
Drugan & Nowe (2013) MO-MAB Regret min. Adv. free Cum. reg.
Nika et al. (2020) MO GP PSI Adv. free Samp. com.
Zuluaga et al. (2016) MO GP PSI Adv. free Samp. com.
Kapoor et al. (2019) MAB Regret min. Oblivious Cum. reg.
Guan et al. (2020) MAB Regret min. Prescient like Cum. reg.
Lykouris et al. (2018) MAB Regret min. Prescient like Cum. reg.
Ours MO-MAB PSI Obl.,Presc.,Mal. Samp. com.
Multi-objective MABs (MO-MABs) are another significant extension of the MAB setting where multiple,
possibly conflicting objectives are optimized simultaneously. Unlike the single objective optimization, in
multi-objective optimization (MOO) problems, it is not possible to identify a single optimal arm in most of
the cases. Therefore, in MOO, the aim is to identify the set of Pareto optimal arms which are not dominated
by any other arm (see Section 3 for definition of Pareto optimality).
MO-MABs are extensively studied in the non-adversarial, stochastic settings for regret minimization and
Pareto set identification (PSI) problems. Auer et al. (2016) propose an elimination-based adaptive arm sam-
pling algorithm, and derive upper and lower bounds on the sample complexity of successful PSI (Theorems 4
and 17 therein). These bounds are/summationtext
i4320
(∆ϵ0
i)2log/parenleftig
12KD
δ∆ϵ0
i/parenrightig
andΩ/parenleftbigg/summationtextK
i=11
(˜∆ϵ0
i)2log/parenleftbig1
δ/parenrightbig/parenrightbigg
respectively, where
˜∆ϵ0
iand∆ϵ0
iare their gaps defined with mean differences of arms as well as their accuracy parameter ϵ0. In
their bounds, Kis the number of arms, Dis the number of objectives and δis the confidence parameter.
Drugan & Nowe (2013) investigate MO-MAB from the regret minimization perspective using scalarization
based methods. These methods turn the multi-objective problem into a single-objective problem, which can
be solved efficiently via well-known single-objective bandit algorithms such as UCB (Auer et al., 2002a).
Multi-objective variants of Thompson Sampling and Knowledge Gradient algorithms are investigated in
Yahyaa & Manderick (2015) and Yahyaa et al. (2014). Regret minimization in multi-objective contextual
bandit problems is studied in Tekin & Turgay (2018) and Turgay et al. (2018).
Another line of work (Zuluaga et al., 2016; Hernández-Lobato et al., 2014; Shah & Ghahramani, 2016; Nika
et al., 2020; Campigotto et al., 2014) focuses on PSI with Gaussian process priors and propose acquisition
strategies to utilize prior induced dependencies between mean arm rewards.
1.1 Contribution and Comparison with Related Works
In the literature, single objective MAB problem is studied under various attack models. In most of the MAB
literature, the goal is to identify the arm that corresponds to the reward distribution with the highest first
order statistic (mean) (Even-Dar et al., 2002). This is only justified when the attack model is assumed to
be bounded in value since mean cannot be estimated from samples contaminated with an attack that has
unbounded value. However in many applications, it is more plausible to restrict the probability of occurrence
of an attack instead of the attack value. For instance, consider review bombing, an internet phenomenon
where some accounts post negative reviews or ratings for a product, service, or content as a form of protest or
manipulation. In this case, the bounded attack probability represents the fraction of adversarial users in the
system. As shown in the single objective adversarial MAB studies that consider bounded probability attack
model, the median is a robust measure against the unbounded attacks (Altschuler et al., 2019). Altschuler
et al. (2019) work on this setting and provide upper and lower bounds as O/parenleftig/summationtext
i̸=i∗1
˜∆2
ilog/parenleftig
k
δ˜∆i/parenrightig/parenrightig
and
Ω/parenleftbigg/summationtext
i∈[k]\{i∗}1
max(˜∆i,α)2log1
δ/parenrightbigg
respectively (Theorems 3 and 18 therein), where ˜∆iis the gap of arm iin
the contaminated case, [k]is the set of of arms, δandαare the confidence and accuracy parameters, and
2Under review as submission to TMLR
i∗is the optimal arm. The methods introduced for the contaminated best arm identification problem in
Altschuler et al. (2019) operate on the principle of elimination, where designs that are not the best arm are
progressively removed until one arm remains. However, this termination criterion, and hence the methods of
Altschuler et al. (2019), cannot be trivially extended to the multi-objective setting, as the number of Pareto
optimal arms is unknown. To address these challenges, we establish the median statistic as a robust measure
in the multi-objective case and propose a method to solve PSI in the adversarial setting. The detailed
comparison of our work with the prior work from the literature is provided in Table 1. Our contributions
are summarized as follows:
•We propose a robust algorithm that returns an (α,δ)-PAC Pareto set of arms under adversarial
contamination, including oblivious, prescient and malicious adversarial attacks (see Section 3.1 for
precise definitions).
•We provide a tight sample complexity bound for our algorithm depending on the contamination
probability. In particular, when the reward distributions are subgaussian, our sample complexity
bound has the same dependence on αas Algorithm 1 of Auer et al. (2016) that works in the
contamination-free setting, scaling as O/parenleftbigK
α2log/parenleftbigMK
δα/parenrightbig/parenrightbig
.
•We conduct extensive experiments on real world data that verify the robustness of our algorithm to
adversarial corruptions.
1.2 Organization
In Section 2, we introduce the necessary notation. In Section 3, we formulate the adversarial MO-MAB
problem. In Section 4, we describe our median-based Pareto elimination algorithm. In Section 5, we prove
that the proposed algorithm satisfies the accuracy and coverage requirements defined in Section 3.4 and prove
a sample complexity bound. In Section 6, we give the experimental results. Conclusions of the research and
future directions are highlighted in Section 7.
2 Notation
We denote the Bernoulli distribution with parameter ρ∈[0,1]by Ber (ρ). We denote the set of positive
integers by N+and the set{1,...,n}by[n]forn∈N+. We use the short hand notation [a±b]to denote
the interval [a−b,a+b]. We use the abbreviation w.h.p.to denote with high probability andcdfto denote
cumulative distribution function .
LetFrepresent a cdf and Xbe a random variable such that X∼F. We denote the right and left quantile
functions of XbyQR,F(p):= inf{x∈R:F(x)> p}andQL,F(p):= inf{x∈R:F(x)≥p}forp∈[0,1]
respectively. The following notations are borrowed from Altschuler et al. (2019). The set of medians is
denoted by m1(F):= [QL,F(1
2),QR,F(1
2)]. We also use the shorthand m1(X)to denotem1(F). In the case
where median is unique, we use m1(F)to denote the median instead of the singleton set containing this
value. Note that m1(F)can be considered to be the robust analogue to mean. We denote the empirical
median of a sequence of samples x1,...,xn∈Rasˆm1(x1,...,xn). Ifnis odd, this corresponds to the middle
value in the sequence. If nis even, it corresponds to the average of two middle values. Given that Fhas a
unique median, we define the median absolute deviation of Fasm2(F) :=m1(|X−m1(F)|).
Supposexis anM-dimensional vector. We denote the ith element of xbyxi. Consider another M-
dimensional vector y. We use the notation x⪯yto denote that vector xis weakly dominated by vector y,
or equivalently, for all i∈[M] :xi≤yi. Also we use the notation x⪯̸yto denote that xis not weakly
dominated by y, or equivalently, there exists i∈[M] :xi> yi. We say that xis dominated by y, denoted
byx≺y, ifx⪯yand there exists i∈[M] :xi<yi.
Supposeais a scalar and xis a vector. We use the notation x+aandx−ato denote the summation of each
element ofxwithaand the subtraction of each element of xbyarespectively. We also define the ordering
relations between scalars and vectors similar to the ones defined between the vectors above: x⪯adenotes
that for all i,xi≤a;a⪯xdenotes that for all i,a≤xi;a⪯̸xdenotes that there exists isuch thata>xi
andx⪯̸adenotes that there exists isuch thatxi>a.
3Under review as submission to TMLR
3 Problem Formulation
We consider a multi-objective pure exploration problem with Mobjectives indexed by d∈[M]andKarms
indexed by i∈[K]. The learner sequentially samples arms over rounds n∈N+. When selected in round n,
armigenerates a random reward (outcome) vector Yi,n:= (Yd
i,n)d∈[M], whereYd
i,nrepresents the reward in
objectived. Arm reward distributions do not depend on n. The cdf of Yd
i,nis denoted by Fd
i. The random
variablesYa
i,nandYb
j,ncan be correlated for all i,j∈[K]anda,b∈[M]. When an arm is selected, its random
reward vector is not directly observed by the learner. Instead, the learner observes the contaminated random
reward vector denoted by ˜Yi,n:= (˜Yd
i,n)d∈[M], where ˜Yd
i,nrepresents the contaminated reward in objective d.
Next, we describe the contamination model. The contamination probability is fixed across all arms and
objectives and is denoted by ϵ∈(0,1
2). Bernoulli random variable corresponding to arm iand objective d
that determines whether a contamination occurs at round nis denoted by Bd
i,n∼Ber(ϵ). If a contamination
occurs at arm iand objective din roundn, then the observed reward is sampled from the contamination
distribution instead of the true reward distribution. Formally,
˜Yd
i,n=/braceleftigg
Yd
i,nifBd
i,n= 0
Zd
i,nifBd
i,n= 1
whereZd
i,nrepresents the contaminated reward. Equivalently, ˜Yd
i,n= (1−Bd
i,n)Yd
i,n+Bd
i,nZd
i,n. The cdf of
Zd
i,nis denoted by Gd
i,n. We allow the contamination distributions depend on round n. The cdf of ˜Yd
i,nis
denoted by ˜Fd
i,n.
We define median of interest md
i, corresponding to cdf Fd
i, as the mean of right and left (1/2)-quantiles of
Fd
i, i.e.,
md
i:=QR,Fd
i(1
2) +QL,Fd
i(1
2)
2.
Note that if Fd
ihas a unique median, md
iis equivalent to this median. We also define median of interest
vectorof armi, which we denote by mi, as theM-dimensional vector whose elements are the medians of
interests that are associated with arm i. Next, we define the Pareto optimal set of arms according to median
of interest.
Definition 1. P∗:={i∈[K]|∄j∈[K] :mi≺mj}.
The learner’s goal is to (approximately) identify P∗by sampling as few arms as possible. A PSI algorithm
stops after conducting a series of sequential evaluations of arms in [K]with the aim of returning a predicted
Pareto setPthat approximates P∗up to a given level of accuracy (formally defined in Section 3.3).
3.1 Adversarial Contamination Models
We consider three contamination models, which we give in the order from the weakest to the strongest below
in terms of the adversarial power. Our contamination models are extensions of the contamination models
in Altschuler et al. (2019) to MO-MAB. Specifically, we extend their contamination models to hold for any
dimensiond∈[M].
Oblivious adversary: Chooses all the contamination distributions a priori without the knowledge of the arm
rewards or the rounds in which the samples are corrupted. Formally, for any given i∈[K]and alld∈[M],
{(Yd
i,n,Zd
i,n,Bd
i,n)}n≥1triples are independent. Furthermore, for any given n,Yd
i,nandBd
i,nare independent
for alliandd. Therefore, ˜Fd
i,nis equivalent to (1−ϵ)Fd
i+ϵGd
i,nin this model. A motivating example for
oblivious adversary is sensing errors in sensor networks. An arm corresponds to a sensor, and once activated
the sensor collects Mmeasurements. Oblivious adversary models randomly occurring measurement errors
due to the environmental effects or sensor defects.
Prescient adversary: Can choose contamination distributions based on all the past and future true arm
rewards and the outcome of Bernoulli random variable that determines if a contamination occurs. For-
mally, for any given i∈[K]andd∈[M], the pairs{(Yd
i,n,Bd
i,n)}n≥1are independent. Furthermore, for
4Under review as submission to TMLR
any givenn,Yd
i,nandBd
i,nare independent for all ianddandZd
i,nmay depend on all the realizations
{Yd
j,s,Bd
j,s,Zd
j,s}j∈[K],d∈[M],s≥1. This can model randomly occurring sensing errors where the observed (cor-
rupted) value depends on the true rewards. The prescient adversary model can also be a good fit for review
bombing. For instance, a protesting user can give lowest scores to Pareto optimal arms.
Malicious adversary: In the malicious adversary, not only can the adversary choose the contamination
distributions based on both past and future true arm rewards (as in the prescient model), but they also have
the additional ability to manipulate the occurrence of contaminations based on the true rewards.
Formally, in the case of prescient adversary, for any arm i∈[K]and objective d∈[M], the pairs
{(Yd
i,n,Bd
i,n)}n≥1remain independent over time. However, unlike the prescient adversary, the malicious
adversary can couple the contamination indicator Bd
i,n(which determines whether a reward is contami-
nated) with the true reward Yd
i,n. This means that the adversary can condition both the choice of whether
to contaminate and the contaminated value Zd
i,non all previous and future observed outcomes.
For example, in a cybersecurity setting, an attacker can perform a man-in-the-middle attack, where they
intercept and modify communications between two parties. By selectively corrupting rewards from certain
arms, the attacker can manipulate the algorithm’s choices.
3.2 Unavoidable Bias and Median Concentration
Becauseouradversarialcontaminationmodelsallowforanarbitrarycontaminationdistribution, meanstatis-
tics cannot be predicted from the contaminated samples. Furthermore, median statistic is subject to an
unavoidable bias which makes the median identifiable only up to a certain interval. Below we will review
results from Altschuler et al. (2019), which quantifies the amount of unavoidable bias and the concentration
of sample median. The results presented in this subsection are related to the concentration of the median
in a single objective. Later on, we will utilize them for our multi-objective PSI identification and sample
complexity analysis.
Definition2. (Altschuler et al., 2019, Definition 5). For any ¯t∈(0,1
2)and positive, non-decreasing function
Rdefined on domain [0,¯t], defineCR,¯tto be the family of all distributions Fthat satisfy the following:
R(t)≥max/braceleftbigg
QR,F/parenleftbigg1
2+t/parenrightbigg
−m,m−QL,F/parenleftbigg1
2−t/parenrightbigg/bracerightbigg
for allt∈[0,¯t]andm∈m1(F).
Rbounds the maximum quantile deviation that can occur from the median. It will play a key role in our
sample complexity analysis. We will choose a common Rfor all{Fd
i}i,din order to facilitate our analysis.
Below, westateresultsonconcentrationoftheempiricalmedian. Thesewillbeusedinoursamplecomplexity
analysis.
Lemma 1. (Upper bound on empirical median deviation for prescient and oblivious adversaries) (Altschuler
et al., 2019, Lemma 7). Let ¯t∈(0,1
2),ϵ∈(0,2¯t
1+2¯t),δ∈(0,1)andF∈CR,¯t, whereRis a non-decreasing
function defined on domain [0,¯t]. LetYi∼FandBi∼Ber(ϵ)all be independently drawn for i∈[n]. Let
{Zi}i∈[n]be arbitrary random variables possibly depending on {Yi,Bi}i∈[n], and ˜Yi= (1−Bi)Yi+BiZi. Then
forn≥2(¯t−ϵ
2(1−ϵ))−2log(2
δ):
P/parenleftig
sup
m∈m1(F)|ˆm(˜Y1,...,˜Yn)−m|≤R/parenleftigϵ
2(1−ϵ)+/radicalbigg
2 log(2/δ)
n/parenrightig/parenrightig
≥1−δ .
Lemma 2. (Upper bound on empirical median deviation for malicious adversary) (Altschuler et al., 2019,
Lemma 8). Let ¯t∈(0,1
2),ϵ∈(0,¯t),δ∈(0,1)andF∈CR,¯t, whereRis a non-decreasing function defined on
domain [0,¯t]. Let (Yi,Bi)pairs be independently drawn for i∈[n]with marginals Yi∼FandBi∼Ber(ϵ).
Let{Zi}i∈[n]be arbitrary random variables possibly depending on {Yi,Bi}i∈[n], and ˜Yi= (1−Bi)Yi+BiZi.
Then forn≥2(¯t−ϵ)−2log(3
δ):
P/parenleftig
sup
m∈m1(F)|ˆm(˜Y1,...,˜Yn)−m|≤R/parenleftig
ϵ+/radicalbigg
2 log(3/δ)
n/parenrightig/parenrightig
≥1−δ .
5Under review as submission to TMLR
In the expressions above, we observe that in the limiting case as n→∞, the difference between sample me-
dian and median is upper bounded by D:=R(ϵ
2(1−ϵ))for oblivious and prescient adversaries and D:=R(ϵ)
for malicious adversary. An intriguing question is whether these bounds can be improved. The answer is
negative, as (Altschuler et al., 2019, Corollary 6 & Lemma 9) shows that there exists reward and contam-
ination distributions for which Dis unavoidable. Therefore, as in Altschuler et al. (2019), we call Dthe
unavoidable bias term.
Note that the above lemmas can be used for bounding the deviation of empirical median from the median
of interest since median of interest is also a median of the given distribution. In the rest of the paper, we
will simply refer to median of interest as themedianand themedian of interest vector as themedian vector .
The results presented above are very general. In the examples below, we show how Rcan be defined for
specific families of distributions. Below, we provide a suitable Rfor subgaussian distributions, which are
commonly used in bandit problems.
Example 1. Allσ-subgaussian distributions are members of the family CR,¯t, where ¯t∈(0,1/2)and
R(t) =σ√
2/parenleftbigg/radicaligg
log/parenleftbigg1
1/2−t/parenrightbigg
+/radicalbig
log(2)/parenrightbigg
. (1)
Derivation of equation 1 can be found in Appendix A.1.
Another interesting case, which allows sharper bounds is the family of distributions whose cdfs increase
linearly around the median (not too flat around the median).
Definition 3. (Altschuler et al., 2019, Definition 10) Given ¯t∈(0,1/2)andB > 0, defineFB,¯tas the
family of distributions Fwith a unique median such that for all x1,x2∈[QL,F(1/2−¯t),QR,F(1/2 +¯t)]
|F(x1)−F(x2)|≥1
Bm2(F)|x1−x2|.
As noted in Altschuler et al. (2019), (i) any univariate Gaussian distribution is in FB,¯tfor any ¯t∈(0,1/2)
andB≥q3/4/ϕ(q1/2+¯t), whereϕis the standard Gaussian density and qαis itsαquantile, (ii) any uniform
distribution defined on an interval is in FB,¯tfor any ¯t∈(0,1/2)andB≥4. Moreover, all distributions F
inCR,¯tgiven in Definition 3 satisfy Definition 2 with R(t) =Bm2(F)t.
3.3 Multi-objective Suboptimality Gap
The number of samples required to distinguish an arm i /∈P∗from an arm j∈P∗depends on distance
between arms iandj. We quantify this distance by the notion of suboptimality gap.
Definition 4. We define ∆i,j:= max/braceleftbig
0,mind(md
j−md
i)/bracerightbig
as the suboptimality gap of an arm iwith respect
to armjand∆i:= maxj∈P∗∆i,jas the suboptimality gap of arm i.
∆imeasures how much arm iis dominated by the Pareto set. Given a positive real number α, we call an
armi α-optimal if ∆i≤α, andα-suboptimal if ∆i> α. All Pareto optimal arms are α-optimal for any
positive real number αsince ∆j= 0for a Pareto optimal arm j.
Due to the unavoidable bias, in general, it is not possible to detect Pareto optimal arms with more than 2D
accuracy, as proven in the following remark, whose details can be found in Appendix A.2.
Lemma 3. Suppose that an adversary can alter a reward sample as much as Dso that either
limn→∞ˆm(˜Yd
i,1,···,˜Yd
i,n) =m+Dorlimn→∞ˆm(˜Yd
i,1,···,˜Yd
i,n) =m−Dholds fori∈[K]. Then, given any
ζ >0, there are bandit environments in which it is impossible to distinguish (2D−ζ)-optimal arms from the
Pareto optimal arms.
3.4 Pareto Accuracy
In the following, we define the class of algorithms that is of interest to us in the adversarial MO-MAB setting.
6Under review as submission to TMLR
f1f2
ˆm12D+ 2U1
2U1ˆm2ˆm3
ˆm4S←S\ {4}
oo
f1f2
ˆm1ˆm2ααoˆm3ααoO1← {2,3}
f1f2
ˆm1αα αˆm2ˆm3
ooO2← {3}
Figure 1: Visualization of R-PSI algorithm in two dimensional objective space. The red circles mark points
used in comparisons. The blue squares are the confidence regions of arms given in Lemma 4, whereas shaded
squares are the smaller regions used in identification phase. The left figure visualizes the elimination phase,
where arm 3eliminates arm 4. The middle and right figures visualize the Pareto identification phase of
the algorithm. Both arm 2and arm 3are added to O1, as shown in the middle figure. However, arm 2is
suspected to be useful in elimination of the arm 1in the future rounds, thus it is not added to O2as depicted
in the right figure. As a result, only arm 3is added to the estimated Pareto set P.
Definition 5. (Pareto accurate algorithm) Suppose that the reward distributions belong to CR,¯tgiven in
Definition 2 for some ¯t∈(0,1
2). Then, given the accuracy parameter α≥0, the confidence probability
0< δ < 1and the adversarial attack probability 0≤ϵ <2¯t
1+2¯tfor oblivious and prescient adversaries,
0≤ϵ < ¯tfor malicious adversaries, we call an algorithm Pareto accurate in the adversarial MO-MAB
setting, if the set of arms Pthat the algorithm returns at termination satisfies the following conditions:
1. Accuracy: All the returned arms are (2D+α)-optimal:
∀i∈P,∆i≤2D+α .
2. Coverage: If a Pareto optimal arm jis not inP, then, there exists at least one arm in Pthat
(2D)-covers arm j:
∀j∈P∗,∃i∈P:mj−mi⪯2D .
The Pareto accuracy can be considered as the generalization of the probably approximately correct (PAC)
learning concept from the single objective MAB setting to the adversarial MO-MAB setting. However, in
the adversarial MO-MAB setting, since the Pareto optimal arms cannot be distinguished from other 2D-
optimal arms as shown in Lemma 3, it is not possible to approximate the optimal solution arbitrarily well.
This reflects itself in the accuracy and the coverage conditions defined above. We also note that, from
the algorithms that are in the class defined above, the ones that have smaller sample complexity would be
favorable since in many practical settings, taking samples induce some type of cost, e.g., monetary and time,
that we would want to minimize.
4 A Robust Learning Algorithm
We propose a Pareto accurate algorithm called Robust Pareto Set Identification (R-PSI) whose pseudocode
is given in Algorithm 1. The algorithm sequentially operates over sampling phases indexed by t≥0. It
keeps two sets of arms: the undecided set Sand thepredicted Pareto set P, whereS∪P= [K]for allt. A
visualization of the R-PSI algorithm is provided in Figure 1.
7Under review as submission to TMLR
At the beginning ( t= 0), all the arms are assigned to the undecided set S. Then each arm is sampled n0
times, which is defined as:
n0:=/ceilingleftbigg
2β¯t,ϵlog/parenleftigπ2MK
6˜δ/parenrightig/ceilingrightbigg
(2)
where
β¯t,ϵ:=/parenleftbigg
¯t−ϵ
2(1−ϵ)/parenrightbigg−2
,˜δ:=δ
2(3)
for prescient and oblivious adversaries, and
β¯t,ϵ:= (¯t−ϵ)−2,˜δ:=δ
3(4)
for malicious adversary.
For sampling phase t≥1, letτirepresent the number of sampling phases so far in which arm iis sampled.
At each sampling phase t≥1, the algorithm selects the arm with the largest statistical bias which we denote
byi∗. Computation of i∗is closely linked with Lemmas 1 and 2. In particular, given R, the statistical bias
of any arm after τsampling rounds represents the uncertainty in the median estimate attributed to sample
size, and is computed as
Uτ=R/parenleftig
hϵ+ 1//radicalig
β¯t,ϵτ/parenrightig
−R(hϵ),
wherehϵ:=ϵ
2(1−ϵ)for oblivious and prescient adversary and hϵ:=ϵfor malicious adversary. Thus, we set
Ui=Uτi, (5)
andi∗= arg maxk∈[K]Uk,τk.
Remark 1. The difference between the sampling round numbers of any two arms in Scannot be larger than
1since the algorithm selects the arm with the largest statistical bias at each sampling phase.
∀i,j∈S,|τi−τj|≤1.
After armi∗is selected, it is successively sampled nτi∗times where
nτi∗:= 1 +/ceilingleftig
4τi∗β¯t,ϵlog/parenleftigτi∗
τi∗−1/parenrightig
+ 2β¯t,ϵlog/parenleftig(τi∗−1)2MKπ2
6˜δ/parenrightig/ceilingrightig
.
As will be proven in Lemma 4, nτi∗is chosen in such a way that the sample complexity requirements of
Lemma 1 and Lemma 2 are met and the resulting empirical median deviation bound of Lemma 1 and Lemma
2 depends on τi∗through the expression R/parenleftbigg
hϵ+1√
β¯t,ϵτi∗/parenrightbigg
.
After each sampling phase, algorithm enters the elimination step where the arms that are guaranteed to
be(2D+α)-suboptimal are eliminated. As shown in Lemma 5, none of the Pareto optimal arms can be
eliminated at this step which is crucial for our theoretical analysis to hold since the additive property of
suboptimality is not satisfied in the adversarial setting as shown in Remark 4 of Altschuler et al. (2019).
After the elimination step, algorithm enters the identification step where the arms that are guaranteed to
satisfy the accuracy requirements are collected in O1. Among these arms in O1, the ones that can potentially
eliminate an arm in Sat future rounds are dropped back to S. If these arms were to remain in O1, the
(2D+α)-suboptimal arms to be eliminated by these arms will never be eliminated and might be returned
inPby the algorithm. This prevents arms that are (2D+α)-suboptimal to potentially end up in P. The
rest of the arms in O1are collected in O2.
Note that we have an if statement in the identification step that checks whether Uk> α/ 4and when
Uk≤α/4, the algorithm terminates by moving all the arms in O1toP. This is to guarantee the termination
8Under review as submission to TMLR
Algorithm 1 R-PSI
1:Input:α,δ,ϵ,¯t,R(·)
2:Initialize: S= [K],P=∅,τi= 0∀i∈[K],
t= 0.
3:τi←τi+ 1∀i∈[K]
4:Sample each arm n0times as in (2)
5:UpdateUiaccording to (5) ∀i∈S
6:Update ˆmi∀i∈S
7:whileS̸=∅do
8:ift>0then
9:Sampling:
10: Choose arm i∗= arg maxk∈[K]Uk,τk
11:τi∗←τi∗+ 1
12: Samplei∗successively nτi∗times.
13: UpdateUi∗according to (5)
14: Update ˆm∗
i
15:end if
16:Elimination:
17:S←S\{i∈S|∃j∈S\{i}: ˆmi+D+Ui≺18: ˆmj−D−Uj}
19:Identification:
20:O1←{i∈S|∄j∈S\{i}: ˆmi−Ui+α⪯
21: ˆmj+Uj}
22:if∃k∈S:Uk>α/ 4then
23:O2←{i∈O1|∄j∈S\{i}: ˆmj−Uj+α⪯
24: ˆmi+Ui}
25:S←S\O2
26:P←P∪O2
27:else:
28:P←P∪O1
29: returnP
30:end if
31:t←t+ 1
32:end while
33:returnP
of the algorithm as there might be some arms left in Swith suboptimality gaps between (4D+α)and
(2D+α)that might cause algorithm to stuck in an infinite loop in the absence of this step. By Lemma 9,
arms that are (4D+α)-suboptimal are eliminated by the R-PSI algorithm in the earlier rounds. To align
with this guarantee, we define ¯∆i:= ∆i−4Das the adjusted suboptimality gap of arm i, indicating that
arms with ¯∆i>αare eliminated earlier due to their significant suboptimality.
5 Accuracy and Sample Complexity Analysis
In this section, we provide accuracy and sample complexity analysis for R-PSI.
5.1 Good Event
We start by showing that the good event in which the sample median concentrates sufficiently around the
true median occurs with high probability. The rest of our analysis is based on this good event . The details
of this result can be found in Appendix A.3.
Lemma 4. DefineEas the event in which for all i∈[K],d∈[M]andτi≥1, the following is satisfied:
md
i+D+Uτi≥ˆmd
i≥md
i−D−Uτi,
or equivalently,|ˆmd
i−md
i|≤D+Uτi. Then:
P(E)≥1−δ .
5.2 Main Results
In this section, we present the theoretical analysis of R-PSI for the Pareto set identification problem in MO-
MAB with contaminated reward observations. A key algorithmic innovation of R-PSI lies in its intricate set
operations, which allow it to overcome termination condition issues that hinder previous methods. Through
rigorous analysis tailored for the set operations of R-PSI, we prove that, using these set operations, R-
PSI returns an ( α,δ)-PAC Pareto set, providing strong accuracy guarantees (see Lemmata 5–8). We then
establish upper bounds on the sample complexity of R-PSI (see Theorem 1 and Corollaries 1 and 2). These
9Under review as submission to TMLR
sample complexity upper bounds rely on the novel termination condition of R-PSI (line 22 of Algorithm 1),
which introduces a new approach to determining when the algorithm should stop. This termination criterion
leverages a statistical bias term, Uk, to ensure that sufficient information has been gathered about the arms
before halting. In the proof of Lemmata 5–8, we demonstrate that this termination condition is sufficient to
guarantee that R-PSI is a Pareto accurate method. For the sample complexity upper bounds of subgaussian
reward distributions (Corollary 1), we use the newly introduced R(·)established in Example 1 in Section
3.2. We also discuss the tightness of the upper bounds in Remark 2.
Next, we state our first main result, which provides an accuracy guarantee for R-PSI and establishes a
high-probability upper bound on its sample complexity.
Theorem 1. Assume that the reward distributions belong to CR,¯tgiven in Definition 2 and the event E
defined in Lemma 4 holds. Then, given any α∈R+, andϵ≤2¯t
1+2¯tfor the oblivious and prescient adversary
(ϵ≤¯tin the case of the malicious adversary), R-PSI is Pareto accurate with sample complexity Nbounded
by:
N≤/summationdisplay
i: ∆i>4D+α2τ(¯∆i)/parenleftigg
β¯t,ϵlog/parenleftiggτ2
(¯∆i)MKπ2
6˜δ/parenrightigg
+ 1/parenrightigg
+/summationdisplay
i: ∆i≤4D+α2τ(α)/parenleftigg
β¯t,ϵlog/parenleftigg
τ2
(α)MKπ2
6˜δ/parenrightigg
+ 1/parenrightigg
(6)
≤Kτ(α)/parenleftigg
2β¯t,ϵlog/parenleftigg
τ2
(α)MKπ2
6˜δ/parenrightigg
+ 2/parenrightigg
, (7)
where ¯∆i:= ∆i−4D, andτ(a):= inf{τ:Uτ≤a/5}fora∈R+.
The above theorem gives the most general expression for the sample complexity without making any further
assumptions on the reward distributions. If a suitable Rcan be determined, for the given reward distribu-
tions, then it is possible to derive an explicit gap-dependent bound on the sample complexity. Below, we
provide such a result for subgaussian reward distributions.
Corollary 1. Suppose that the reward distributions are subgaussian with parameter σ. Then, the asymptotic
sample complexity (as α→0) is given by:
O
σ2Kβ¯t,ϵ
α2log/parenleftig
1
1/2−hϵ/parenrightiglog
σ2MK
α2log/parenleftig
1
1/2−hϵ/parenrightig
˜δ

. (8)
Thesamplecomplexityboundderivedforsubgaussiandistributionsinequation8hasaworstcaseasymptotic
matching to the bounds derived in Theorem 4 of Auer et al. (2016) and Theorem 3 of Altschuler et al. (2019)
in terms of α-dependence. Also, this bound nearly matches, in the worst case, the adversary-free lower
bound in Theorem 17 of Auer et al. (2016). We also note that unlike these studies, our bound contains an
ϵ-dependent factor that comes from the adversarial attack. Details about Theorem 1 and Corollary 1 can
be found in Appendices A.4 and A.5, respectively.
Based on Definitions 2 and 3, if F∈FB,¯t, thenF∈CR,¯t, whereR(t) =Bm2(F)t(Altschuler et al., 2019).
In the next Corollary, we provide sample complexity analysis for reward distributions in F∈FB,¯t.
Corollary 2. Suppose that the reward distributions are from the family F∈FB,¯t. Let ¯m2≥maxi∈[K]m2(F)
forF∈FB,¯tbe a known upper bound. When R(t) =B¯m2tis used, R-PSI is Pareto accurate with sample
complexity Nbounded by
N≤K/summationdisplay
i2/parenleftigg
β¯t,ϵ+25 ¯m2
2B2
(∆α
i)2/parenrightigg
log
/parenleftbigg
1 +25 ¯m2
2B2
β¯t,ϵ(∆α
i)2/parenrightbigg2
MKπ2
6˜δ
+ 1
,
where ∆α
i:= max(α,¯∆i). Notice that as hϵapproaches ¯t, the bound increases towards infinity. This is
expected as ¯tis the threshold for hϵ. Whenhϵ>¯t, by Definition 2, R(t)no longer bounds the maximum
10Under review as submission to TMLR
possible deviation from medians ((Altschuler et al., 2019), Lemma 1). Hence distinguishing between the
contaminatedmedianandthetruemedianbecomesuncontrollable. Thisisreflectedbythesamplecomplexity
requirements of Lemmata 1 and 2. When B,¯m2,¯tare taken as non-negative constants and ϵ= 0, the sample
complexity bound takes the form O/parenleftig
K
α2log/parenleftig
MK
˜δα/parenrightig/parenrightig
which recovers the worst case bound from Theorem 4 of
Auer et al. (2016) for adversary free Pareto set identification in MO-MAB setting. Details about Corollary
2 can be found in Appendix A.6.
Remark 2. To analyze the tightness of the upper bounds, we consider a specific problem instance where
M= 1. In this case, P∗= arg max imiand∆i= maxjmj−mi. Thus, the accuracy condition for Pareto
accurate algorithms given in Definition 5 reduces to ∀i∈P,mi≥maxjmj−2D−α. The coverage condition
reduces to∀j∈P∗,∃i∈P:mj−mi≤2D. Success conditions considered in Altschuler et al. (2019) require
that any successful algorithm, for any α≥0, should return a single arm Isuch thatmi∗−mI−Ui∗−UI≤α,
wherei∗= arg max imi. In terms of our notation, this condition is mI≥maxjmj−2D−α, which
is equivalent to our accuracy condition. Thus, we can say that Altschuler et al. (2019) studies a success
condition that is weaker than ours. Any lower bound for the success condition of Altschuler et al. (2019)
also holds in our case. In particular, the lower bound stated in Theorem 18 of Altschuler et al. (2019) holds,
which is given by Ω/parenleftig/summationtext
i∈[K]\{i∗}1
max{∆i−2D,α}2log(1
δ)/parenrightig
. In terms of dependence on α, both Corollary 1 and
2 match this lower bound up to logarithmic terms.
6 Numerical Results
We compare our algorithm with Algorithm 1 from Auer et al. (2016) which considers Pareto set identification
problem for the adversary free MO-MAB. We name this algorithm Auer-A1. Auer-A1 is a Pareto accurate
algorithm in the adversary free setting ( D= 0) and its ranking of the arms is based on the mean of the
distributions instead of the median. We conduct experiments on MovieLens dataset (Harper & Konstan,
2015), SW-LLVM dataset Zuluaga et al. (2013), and data obtained from UVA/PADOVA Type 1 Diabetes
Simulator (Man et al., 2014). For the algorithms to be comparable, except MovieLens dataset, we consider
Gaussian rewards so that the median and the mean are the same. However, the experiments on MovieLens
dataset are an exception, as its reward distribution is categorical, meaning the mean and median values may
differ. This discrepancy between the mean and median values might affect the performance of Auer-A1. To
mitigate this effect, we choose as the arm set a subset of movies in MovieLens dataset such that the Pareto
set in terms of median rewards are the same as the Pareto set in terms of mean rewards. We also compare
our algorithm with a modification of Auer-A1 algorithm that uses median values instead of mean values and
thus returns a median-based Pareto set. We call this median based method Auer-A1-M .
Note that in Auer et al. (2016), the success condition differs from the accuracy and coverage requirements we
use to define the Pareto accuracy in the adversarial MO-MAB setting. In particular, their success condition
requires the predicted arms to be at least α-accurate and all the Pareto optimal arms to be returned in
the predicted set. In terms of our accuracy and coverage arguments, this success condition is equivalent to
anα-accuracy and 0margin coverage requirement. For a fair comparison, while evaluating Auer-A1 and
Auer-A1-M, we relax this success condition to (2D+α)accuracy and (2D)coverage requirement, which
are equivalent to the requirements set for R-PSI. In real-world applications, the reward distributions of the
arms may not be available. To maintain realism in our experiments, in all experiments, we use the Rfrom
Example 1. This is because the subgaussian assumption covers the largest set of cases for which we have
derived explicit theoretical results, making it more suitable when dealing with an unknown reward function.
Robust PSI can be viewed as a classification task where the true positives are accurate arms and false
negatives are uncovered arms. To align with existing research on classification tasks and to provide a metric
that is appropriate for the accuracy and coverage conditions as defined in Definition 5, we define the robust
analogue of F1 score and denote it by r-F1 score. Our definition is inspired by the ϵ-F1 score introduced
by Karagözlü et al. (2024), which is designed for approximate arm identification in the context of vector
optimization.
r-F1 :=2|Πr∩P|
2|Πr∩P|+/vextendsingle/vextendsingleΠr\P/vextendsingle/vextendsingle+|P\Πr|,
11Under review as submission to TMLR
where Πris the set of 2D+αoptimal arms and Πr\Pis the set of Pareto optimal arms that is not covered by
P. Note that r-F1 = 1if and only if the algorithm is Pareto accurate (see Definition 5). The experiments
also utilize other metrics: SC (average sample complexity), RSR (ratio of successful runs), and RO (ratio of
optimal arms). RSR measures the ratio of experiments where the Pareto set is accurately identified under
the adversarial success conditions defined in Definition 5. A higher RSR score indicates that the algorithm
achieves this task consistently. This metric is crucial in scenarios where robust performance across multiple
trials is essential, since a high RSR score corresponds to achieving the success condition in most of the
experiments. SC is the average number of samples required by the algorithm to return the estimated Pareto
set. A lower SC indicates greater efficiency, as it means the algorithm achieves its result with fewer arm pulls.
Comparing SC across different algorithms provides an understanding of the trade-offs between accuracy and
efficiency. For example, an algorithm might achieve high accuracy but require significantly more samples.
RO is the ratio of the number of Pareto optimal arms returned by the method to the total number of true
Paretooptimalarms, i.e., |P∗∩P|/|P∗|. ThismetrictellsushowmuchofthetrueParetoarmswerereturned.
A high RO metric means that the algorithm is returning most of the arms in the true Pareto set. However,
this metric alone cannot capture how accurate an algorithm is since an algorithm might achieve a perfect
RO score, while returning too many arms that are not true Pareto arms. RO metric might seem redundant
since r-F1 metric also considers the recall of the algorithm, but it is still crucial while comparing algorithm
performances. For example, in a setting where there are only a few arms in the true Pareto optimal set,
an algorithm which returns all ( 2D+α)-optimal arms except the true Pareto arms will achieve a high r-F1
score, but RO will be 0since none of the true Pareto arms were returned.
6.1 Experiments on MovieLens Dataset
Review bombing is an internet phenomenon where a large group of accounts post negative reviews or ratings
for a product, service, or content as a form of protest or manipulation. This practice can significantly skew
public perception and has prompted many review platforms to develop methods to mitigate its effects. We
consider the movie reviews on MovieLens, a movie recommendation service. We select 24 movies and assign
each of them to an arm. When an arm is pulled, a randomly selected review of that arm is observed.
The objective of the optimization is to find the Pareto arms in terms of the review scores across five age
demographics: 0−18,19−25,26−35,36−45,46+. (i.e.M= 5). To simulate the task of Pareto identification
under an event of review bombing, we choose a prescient adversary that replaces the scores of the Pareto
optimal arms with the lowest review score (i.e., 1) in contaminated objectives and leaves the non-Pareto
arms as is. We choose σ= 0.2in equation 1, δ= 0.1, andα= 0.2. We use ¯t= 0.49and maximum ϵvalue
of0.4. We report the average results over 100runs in Table 2. The results indicate that Auer-A1’s success
rate declines as adversaries get stronger, whereas R-PSI consistently makes accurate predictions with fewer
samples. Though Auer-A1-M returns an accurate and covering Pareto set, it misses out some of the true
Pareto designs indicated by the low RO score.
6.2 Experiments on SW-LLVM Dataset
We use SW-LLVM dataset from Zuluaga et al. (2013) which consists of 1023 compiler settings characterized
by 11 binary features. The objectives are performance and memory footprint of some software when compiled
with these settings. Similar to Auer et al. (2016), to obtain a stochastic-like data for our algorithm, we use
the combinations of 4 of the binary features to form 16 arms. By ignoring all the other features we end up
with 64 data points for each arm. When an arm is pulled, one of the 64 data points pertaining to that arm is
randomly selected and the corresponding objectives are returned as reward. We normalize the data to obtain
a similar range for both objectives. We assume that the reward distributions are Gaussian. Note that this
assumption is for the purpose of determining the parameters of the algorithm and does not affect the rewards
obtained from arm pulls in any way. We take the mean of 64 data points assigned to an arm and use this
as the mean (median) of the corresponding Gaussian reward distribution. We select a malicious adversary
that is 25% more likely to contaminate Pareto arms compared to non-Pareto arms, while also preserving the
marginal distribution Ber(ϵ). The contamination has a value of ±10. The choice for the parameters σ,δ,
and¯tare the same as in the previous setting, while αwas chosen to be 0.1. We report the average results
over 100 runs in Table 2. It can be seen that contaminations as low as ϵ= 0.05prevent Auer-A1 from
12Under review as submission to TMLR
Table 2: Experiments on real world datasets. From left to right: MovieLens, SW-LLVM dataset and
UVA/PADOVA simulator experiment results.
MovieLens SW-LLVM UVA/PADOVA
ϵ RSR SC RO r-F1 RSR SC RO r-F1 RSR SC RO r-F1
R-PSI0.0 1.0 18674.7 1.0 1.0 1.0 1540.9 1.0 1.0 1.0 3951.8 1.0 1.0
0.05 1.0 20425.0 1.0 1.0 1.0 54935.1 1.0 1.0 1.0 4432.0 1.0 1.0
0.1 1.0 20914.1 1.0 1.0 1.0 57822.5 1.0 1.0 1.0 5067.2 1.0 1.0
0.2 1.0 33753.2 1.0 1.0 1.0 72969.3 1.0 1.0 1.0 7232.8 1.0 1.0
0.3 1.0 49212.2 1.0 1.0 1.0 98714.7 1.0 1.0 1.0 12683.8 1.0 1.0
0.4 1.0 105847.2 1.0 1.0 1.0 222906.8 0.92 1.0 1.0 39647.0 1.0 1.0
Auer-A10.0 1.0 33779.0 1.0 1.0 1.0 7175.7 1.0 1.0 1.0 642344.1 1.0 1.0
0.05 0.0 59092.6 0.0 0.92 0.97 250885.9 0.0 0.98 1.0 900844.7 1.0 1.0
0.1 0.0 59428.8 0.0 0.92 0.92 174599.9 0.0 0.97 1.0 1089962.2 0.93 1.0
0.2 0.0 58917.8 0.0 0.92 0.78 80767.7 0.0 0.90 0.8 1450304.8 0.71 0.99
0.3 0.0 57953.3 0.0 0.92 0.91 41946.3 0.0 0.96 0.0 1946291.2 0.71 0.75
0.4 0.0 57765.6 0.0 0.92 0.91 37811.9 0.0 0.97 0.0 1696773.8 0.41 0.75
Auer-A1-M0.0 1.0 33320.7 1.0 1.0 1.0 9896.7 1.0 1.0 1.0 637868.3 1.0 1.0
0.05 1.0 35075.4 1.0 1.0 0.99 19033.2 0.94 1.0 1.0 642238.1 1.0 1.0
0.1 1.0 36231.0 1.0 1.0 0.96 31614.2 0.76 0.99 1.0 646958.6 1.0 1.0
0.2 1.0 43351.1 0.98 1.0 0.74 47045.5 0.22 0.87 1.0 658259.9 1.0 1.0
0.3 1.0 43722.6 0.95 1.0 0.50 23726.7 0.03 0.71 1.0 680222.4 1.0 1.0
0.4 1.0 45058.0 0.83 1.0 0.20 6526.8 0.0 0.59 1.0 739778.4 1.0 1.0
being a Pareto accurate algorithm. Although the Auer-A1-M method achieves higher scores compared to its
mean-based counterpart, these scores remain low, indicating that Auer-A1-M exhibits significant limitations
under adversarial conditions.
6.3 Experiments on UVA/PADOVA Diabetes Simulator
Managing type 1 diabetes requires adjusting insulin doses based on carbohydrate intake to maintain blood
glucose levels within a safe range. Because this method demands specialized training and knowledge, it
is prone to errors among patients (Roversi et al., 2020). To simulate this problem, we conduct in silico
experiments using the University of Virginia (UVa)/PADOVA T1DM simulator (Man et al., 2014) which
simulates the blood glucose levels of type 1 diabetes patients for a given meal event, i.e., carbohydrate
content of the meal, and an administered external insulin dose. We select 36 combinations of bolus insulin
doses and meal events as potential treatment scenarios for a selected patient and assign each of them to an
arm. We aim at identifying the combinations that most effectively reduce the duration of time during which
blood glucose levels fall below or exceed the safe range under occasional inaccurate carbohydrate counting.
We define the safe range as 100-140 mg/dL. When an arm is pulled, the time above the safe range and below
the safe range are observed with a small Gaussian noise with σ= 0.025, which is also used in equation 1.
To simulate real-world cases where patients inaccurately count carbohydrates, resulting in the consumption
of meals with incorrect carbohydrate content, we deploy an oblivious contamination that changes the meal
event of an arm without changing the bolus insulin dose. We standardize the reward distribution so that
it has a mean of zero and a variance of one. The choice for the parameters α,δ, and ¯tare the same as
the SW-LLVM experiment. We report the average results over 100 runs in Table 2. The results indicate
that the Auer-A1 exhibits significant limitations under adversarial conditions, in contrast to our algorithm,
which aligns with our theoretical predictions and consistently meets the success criteria across various attack
probabilities. Specifically, though it takes excessive amounts of samples, it fails to return an accurate and
covering Pareto set. Auer-A1-M method manages to return such a Pareto set, but not without requiring
almost 2 orders of magnitude more samples than R-PSI.
13Under review as submission to TMLR
7 Conclusion
We investigated the Pareto set identification problem under adversarial attacks. We proposed a sample-
efficient algorithm that returns a predicted set that abides by the accuracy and coverage requirements. We
also proved a sample complexity upper bound that matches the adversary-free case lower bound proved in
previous studies in terms of accuracy parameter dependence. We further proved a tighter gap-dependent
sample complexity bound. The experimental results support our theoretical predictions, demonstrating
robustness in adversarial settings. In contrast, multi-objective methods developed for adversary-free envi-
ronments showed reduced effectiveness against strong adversaries. Even when these methods were extended
with median estimators instead of mean estimators—which provided some improvement—they still struggled
to maintain effectiveness against strong adversarial conditions. To the best of our knowledge, this is the
first study to propose an algorithm with theoretical guarantees that is capable of approximating the Pareto
set when the reward samples are corrupted by adversarial attacks with arbitrary contamination values. An
interesting future research direction is to investigate the success and the sample complexity of the Pareto
set identification for large-scale MO-MAB problems with correlated arms. Employing skewed stochastic
processes with separate mean and median parameters could increase the practicality of robust Pareto set
identification methods for large-scale MO-MAB problems, as these processes reduce sample complexity by
effectively capturing the correlations between the arms.
References
Jason Altschuler, Victor-Emmanuel Brunel, and Alan Malek. Best arm identification for contaminated
bandits. J. Mach. Learn. Res. , 20(91):1–39, 2019.
Jean-Yves Audibert and Sébastien Bubeck. Minimax policies for adversarial and stochastic bandits. In Proc.
22nd Annu. ACM Symp. Theory Comput. (COLT) , volume 7, January 2009.
Peter Auer, Nicolo Cesa-Bianchi, and Paul Fischer. Finite-time analysis of the multiarmed bandit problem.
Mach. Learn. , 47(2):235–256, 2002a.
Peter Auer, Nicolò Cesa-Bianchi, Yoav Freund, and Robert E. Schapire. The nonstochastic multiarmed
bandit problem. SIAM J. Comput. , 32(1):48–77, 2002b.
Peter Auer, Chao-Kai Chiang, Ronald Ortner, and Madalina Drugan. Pareto front identification from
stochastic bandit feedback. In Proc. 19th Int. Conf. Artif. Intell. Stat. , volume 51, pp. 939–947, 2016.
BaruchAwerbuchandRobertD.Kleinberg. Adaptiveroutingwithend-to-endfeedback: Distributedlearning
and geometric approaches. In Proc. 36th Annu. ACM Symp. Theory Comput. , pp. 45–53, 2004.
Ilija Bogunovic, Arpan Losalka, Andreas Krause, and Jonathan Scarlett. Stochastic linear bandits robust to
adversarial attacks. In Proc. 24th Int. Conf. Artif. Intell. Stat. , pp. 991–999, 2021.
Sébastien Bubeck and Nicolò Cesa-Bianchi. Regret analysis of stochastic and nonstochastic multi-armed
bandit problems. Foundations and Trends ®in Machine Learning , 5(1):1–122, 2012.
Paolo Campigotto, Andrea Passerini, and Roberto Battiti. Active learning of Pareto fronts. IEEE Trans.
Neural Netw. Learn. Syst. , 25(3):506–519, 2014. doi: 10.1109/TNNLS.2013.2275918.
Madalina M. Drugan and Ann Nowe. Designing multi-objective multi-armed bandits algorithms: A study.
InProc. Int. Jt. Conf. Neural Netw. , pp. 1–8, 2013.
EyalEven-Dar, ShieMannor, andYishayMansour. PACboundsformulti-armedbanditandMarkovdecision
processes. In COLT 2002 , pp. 255–270, 2002.
Ziwei Guan, Kaiyi Ji, Donald J. Bucci Jr., Timothy Y. Hu, Joseph Palombo, Michael Liston, and Yingbin
Liang. Robust stochastic bandit algorithms under probabilistic unbounded adversarial attack. AAAI
Conf. Artif. Intell. , 34(04):4036–4043, Apr. 2020.
14Under review as submission to TMLR
Anupam Gupta, Tomer Koren, and Kunal Talwar. Better algorithms for stochastic bandits with adversarial
corruptions. In Alina Beygelzimer and Daniel Hsu (eds.), Proc. 32nd Conf. on Learn. Theory (COLT) ,
volume 99 of Proc. Mach. Learn. Res. , pp. 1562–1578. PMLR, 25–28 Jun 2019.
Eric Han and Jonathan Scarlett. Adversarial attacks on Gaussian process bandits. In Proc. 39th Int. Conf.
Mach. Learn. , pp. 8304–8329, 2022.
F Maxwell Harper and Joseph A Konstan. The movielens datasets: History and context. ACM Transactions
on Interactive Intelligent Systems , 5(4):1–19, 2015.
José Miguel Hernández-Lobato, Matthew W Hoffman, and Zoubin Ghahramani. Predictive entropy search
for efficient global optimization of black-box functions. In Adv. Neural Inf. Process. Syst. , volume 27,
2014.
Sayash Kapoor, Kumar Kshitij Patel, and Purushottam Kar. Corruption-tolerant bandit learning. Mach.
Learn., 108(4):687–715, 2019.
Efe Mert Karagözlü, Yaşar Cahit Yıldırım, Çağın Ararat, and Cem Tekin. Learning the Pareto set under
incomplete preferences: pure exploration in vector bandits. In Proceedings of The 27th International
Conference on Artificial Intelligence and Statistics , volume 238, pp. 3070–3078, 2024.
Tze Leung Lai and Herbert Robbins. Asymptotically efficient adaptive allocation rules. Advances in Applied
Mathematics , 6(1):4–22, 1985.
Lihong Li, Wei Chu, John Langford, and Robert E. Schapire. A contextual-bandit approach to personalized
news article recommendation. In Proc. 19th World Wide Web Conf. , pp. 661–670, 2010.
Thodoris Lykouris, Vahab Mirrokni, and Renato Paes Leme. Stochastic bandits robust to adversarial cor-
ruptions. In Proc. 50th Annu. ACM Symp. Theory Comput. , pp. 114–122, New York, 2018. Association
for Computing Machinery.
Chiara Dalla Man, Francesco Micheletto, Dayu Lv, Marc Breton, Boris Kovatchev, and Claudio Cobelli.
The UVA/PADOVA type 1 diabetes simulator: new features. J. Diabetes Sci. Technol. , 8(1):26–34, 2014.
Timothée Mathieu, Debabrota Basu, and Odalric-Ambrym Maillard. Bandits corrupted by nature: Lower
bounds on regret and robust optimistic algorithms. Transactions on Machine Learning Research , 2024.
Arpan Mukherjee, Ali Tajer, Pin-Yu Chen, and Payel Das. Mean-based best arm identification in stochastic
bandits under reward contamination. In Advances in Neural Information Processing Systems , volume 34,
pp. 9651–9662, 2021.
AndiNika, KeremBozgan, SepehrElahi, ÇağınArarat, andCemTekin. ParetoactivelearningwithGaussian
processes and adaptive discretization, 2020. URL https://arxiv.org/abs/2006.14061 .
Sandeep Pandey, Deepak Agarwal, Deepayan Chakrabarti, and Vanja Josifovski. Bandits for taxonomies: A
model-based approach. In Proc. 2007 SIAM Int. Conf. Data Min. , pp. 216–227, 2007.
Herbert Robbins. Some aspects of the sequential design of experiments. Bulletin of the American Mathe-
matical Society , 58(5):527–535, 1952.
Chiara Roversi, Martina Vettoretti, Simone Del Favero, Andrea Facchinetti, and Giovanni Sparacino. Mod-
eling carbohydrate counting error in type 1 diabetes management. Diabetes Technology & Therapeutics ,
22(10):749–759, 2020.
Amar Shah and Zoubin Ghahramani. Pareto frontier learning with expensive correlated objectives. In Proc.
33rd Int. Conf. Mach. Learn. , volume 48, pp. 1919–1927, 2016.
Cong Shen, Ruida Zhou, Cem Tekin, and Mihaela van der Schaar. Generalized global bandit and its
application in cellular coverage optimization. IEEE J. Sel. Topics Signal Process. , 12(1):218–232, 2018.
15Under review as submission to TMLR
Weiwei Shen, Jun Wang, Yu-Gang Jiang, and Hongyuan Zha. Portfolio choices with orthogonal bandit
learning. In 24th IJCAI Int. Jt. Conf. Artif. Intell. , pp. 974–980, 2015.
Gilles Stoltz. Incomplete information and internal regret in prediction of individual sequences . PhD thesis,
Université Paris Sud - Paris XI, May 2005.
Cem Tekin and Eralp Turgay. Multi-objective contextual multi-armed bandit with a dominant objective.
IEEE Trans. on Signal Process. , 66(14):3799–3813, 2018.
William R Thompson. On the likelihood that one unknown probability exceeds another in view of the
evidence of two samples. Biometrika , 25(3-4):285–294, 1933.
Eralp Turgay, Doruk Oner, and Cem Tekin. Multi-objective contextual bandit problem with similarity
information. In Proc. 21st Int. Conf. Artif. Intell. Statist. , pp. 1673–1681, 2018.
Sofía S Villar, Jack Bowden, and James Wason. Multi-armed bandit models for the optimal design of clinical
trials: benefits and challenges. Stat. Sci. , 30(2):199, 2015.
Yulian Wu, Xingyu Zhou, Youming Tao, and Di Wang. On private and robust bandits. In Advances in
Neural Information Processing Systems , volume 36, pp. 34778–34790, 2023.
Saba Yahyaa, Madalina Drugan, and Bernard Manderick. Knowledge gradient for multi-objective multi-
armed bandit algorithms. In Proc. 6th Int. Conf. Agents Artif. Intell. (ICAART) , volume 1, pp. 74–83,
2014.
Saba Q. Yahyaa and Bernard Manderick. Thompson sampling for multi-objective multi-armed bandits
problem. In Proc. Eur. Symp. Artif. Neural Netw. Comput. Intell. Mach. Learn. , pp. 47–52, 2015.
Marcela Zuluaga, Guillaume Sergent, Andreas Krause, and Markus Püschel. Active learning for multi-
objective optimization. In Proc. 30th Int. Conf. Mach. Learn. , pp. 462–470, 2013.
Marcela Zuluaga, Andreas Krause, and Markus Püschel. ϵ-PAL: An active learning approach to the multi-
objective optimization problem. J. Mach. Learn. Res. , 17(104):1–32, 2016.
A Appendix
A.1 Derivation of equation 1
Let anyXsuch thatX−E[X]isσ-subgaussian distributed, be called a σ-subgaussian variable. Then, for
anyq>0, we have :
P/parenleftbig
X−E[X]≥q/parenrightbig
≤e−q2
2σ2, (9)
P/parenleftbig
X−E[X]≤−q/parenrightbig
≤e−q2
2σ2. (10)
By definition:
P(X <QR,F(1/2 +t))≤1/2 +t,∀t∈/parenleftbigg
0,1
2/parenrightbigg
. (11)
Next, we will bound QR,F(1/2 +t)−mfor the three cases given below. Let qt:=QR,F(1/2 +t).Case 1:
E[X]≤m≤qt.Case 2:m≤E[X]≤qt.Case 3:m≤qt≤E[X].
Case 1:Sinceqt−E[X]>0, then, by equation 9 and equation 11:
1−(1/2 +t)≤P/parenleftbig
X≥qt/parenrightbig
=P/parenleftbig
X−E[X]≥qt−E[X]/parenrightbig
≤e−(qt−E[X])2
2σ2.
16Under review as submission to TMLR
Simplifying above gives:
qt≤E[X] +/radicaligg
2σ2log/parenleftbigg1
1/2−t/parenrightbigg
. (12)
Sincem≥E[X]:
qt−m≤qt−E[X]≤/radicaligg
2σ2log/parenleftbigg1
1/2−t/parenrightbigg
.
Case 2:In this case, equation 12 is valid since qt≥E[X]. Also, by equation 10, we can bound E[X]−m:
1/2≤P(X≤m) =P(X−E[X]≤m−E[X])≤e−(E[X]−m)2
2σ2.
Therefore, we have:
E[X]−m≤/radicalbig
2σ2log 2. (13)
Combining equation 13 with equation 12, we obtain:
qt−m= (qt−E[X]) + (E[X]−m)≤/radicaligg
2σ2log/parenleftbigg1
1/2−t/parenrightbigg
+/radicalbig
2σ2log 2.
Case 3:By equation 13 and by the fact that qt≤E(X):
qt−m≤E[X]−m≤/radicalbig
2σ2log 2.
Combining the results for all three cases, we obtain:
qt−m≤/radicaligg
2σ2log/parenleftbigg1
1/2−t/parenrightbigg
+/radicalbig
2σ2log 2.
Following a similar argument, one can obtain the same bound on m−qt, from which the result follows.
A.2 Proof of Lemma 3
Consider a simple environment with only 2 arms. Suppose that arm 1is Pareto optimal and arm 2is such
that
∀d∈[M] :md
1−md
2= 2D−ζ .
Adversary can manipulate the experiment so that ∀d∈[M],limn→∞ˆm(˜Yd
1,1,···,˜Yd
1,n) =md
1−Dand
limn→∞ˆm(˜Yd
2,1,···,˜Yd
2,n) =md
2+D .This implies that: ∃N0:∀N > N 0,∀d∈[M], md
1−D−ζ/4≤
ˆm(˜Yd
1,1,···,˜Yd
1,N)≤md
1−D+ζ/4andmd
2+D−ζ/4≤ˆm(˜Yd
2,1,···,˜Yd
2,N)≤md
2+D+ζ/4.Therefore,
∀N >N 0:
ˆm(˜Yd
2,1,···,˜Yd
2,N)−ˆm(˜Yd
1,1,···,˜Yd
1,N)≥ζ/2>0.
Hence, we conclude that, even if infinitely many samples are collected from both arms, it is not possible to
decide on their optimality based on the empirical medians.
A.3 Proof of Lemma 4
The total number of samples Nτitaken from arm iat the end of the sampling phase τiis given by:
Nτi=τi/summationdisplay
τ=1nτ
17Under review as submission to TMLR
=⌈2β¯t,ϵlog(π2MK
6˜δ)⌉+τi/summationdisplay
τ=2/parenleftbigg
1 +⌈4τβ¯t,ϵlog(τ
τ−1) + 2β¯t,ϵlog(τ−1)2MKπ2
6˜δ⌉/parenrightbigg
≥2β¯t,ϵlog(π2MK
6˜δ) +τi/summationdisplay
τ=2/parenleftbigg
4τβ¯t,ϵlog(τ
τ−1) + 2β¯t,ϵlog(τ−1)2MKπ2
6˜δ/parenrightbigg
After simplifying the r.h.s. of the above display, we obtain:
Nτi≥2τiβ¯t,ϵlog/parenleftbiggτ2
iMKπ2
6˜δ/parenrightbigg
= 2τiβ¯t,ϵlog/parenleftbiggδ
˜δδτi/parenrightbigg
= 2τiβ¯t,ϵlog/parenleftbigg1
˜δτi/parenrightbigg
,
whereδτi=6δ
τ2
iMKπ2,˜δτi= (δτi˜δ)/δand˜δis given in equations 3 and 4.
SinceNτi≥2τiβ¯t,ϵlog(1
˜δτi)andRis a non-decreasing function, we have
R/parenleftigg
hϵ+/radicaligg
1
β¯t,ϵτi/parenrightigg
≥R
hϵ+/radicaligg
2 log(1/˜δτi)
Nτi
.
Next, note that ˜δτi=δτi/2for oblivious and prescient adversary and ˜δτi=δτi/3for malicious adversary.
The inequality above, and Lemmas 1 and 2 imply that ∀i∈[K]and∀d∈[M]:
P/parenleftbigg
sup
md
i|ˆmd
i−md
i|≥R/parenleftigg
hϵ+/radicaligg
1
β¯t,ϵτi/parenrightigg/parenrightbigg
≤P/parenleftbigg
sup
md
i|ˆmd
i−md
i|≥R
hϵ+/radicaligg
2 log(1/˜δτi)
Nτi
/parenrightbigg
≤δτi.
InsertingUτiandDin the left hand side of the inequality above we obtain:
P/parenleftbigg
sup
md
i|ˆmd
i−md
i|≥Uτi+D/parenrightbigg
≤δτi.
The result follows by the union bound:
P(E)≥1−/summationdisplay
i∈[K]/summationdisplay
j∈[M]/summationdisplay
τi≥1δτi= 1−/summationdisplay
i∈[K]/summationdisplay
j∈[M]/summationdisplay
τi≥16δ
τ2
iMKπ2
= 1−MK6
MKπ2δ/summationdisplay
τi≥11
τ2
i= 1−δ .
A.4 Proof of Theorem 1
In the proof, we assume that event Eholds. First, we prove that the Pareto optimal arms are not eliminated
in the ‘Elimination’ step.
Lemma 5. R-PSI does not eliminate Pareto optimal arms in the ‘Elimination’ step.
Proof.At elimination step, an arm iis eliminated if∃j∈S\{i}: ˆmi+D+Ui≺ˆmj−D−Uj. By Lemma
4, this implies that mi= (mi−D−Ui) +D+Ui⪯ˆmi+D+Ui≺ˆmj−D−Uj⪯(mj+D+Uj)−D−Uj.
Hence,mi≺mj. By definition of Pareto optimality, this is not possible if iis a Pareto optimal arm. Hence,
Pareto optimal arms cannot be discarded at the elimination step of R-PSI.
Next, we prove that R-PSI has an optimality guarantee of (2D+α), i.e., any arm in Pis(2D+α)-optimal.
Before proving this, we state a technical result that will be used in the proof.
18Under review as submission to TMLR
Lemma 6. Suppose an arm iis moved to O2at some sampling phase t1. Then, the following is satisfied
for allt≥t1:
∀j∈S,∃dj∈[M] :mdj
j+D+α>mdj
i−D .
Proof.Sinceiis moved to O2at sampling phase t1, the condition for O2requires:
∄j∈S\{i}: ˆmj−Uj+α⪯ˆmi+Ui.
This implies:
∀j∈S\{i},∃dj∈[M] : ˆmdj
j−Uj+α> ˆmdj
i+Ui.
Applying Lemma 4 gives:
∀j∈S\{i},∃dj∈[M] : (mdj
j+D+Uj)−Uj+α≥ˆmdj
j−Uj+α> ˆmdj
i+Ui≥(mdj
i−D−Ui) +Ui.
Hence:
∀j∈S,∃dj∈[M] :mdj
j+D+α>mdj
i−D .
The result follows by noting that Sdoes not admit any new arms over time.
We are now ready to prove the optimality guarantee for the predicted arms.
Lemma 7. Pcan only contain arms that are (2D+α)-optimal.
Proof.Denote the Pareto optimal arms in Sat the beginning of sampling phase t2byS(p)and the Pareto
optimal arms in Pat the beginning of sampling phase t2byP(p). We haveP∗=S(p)∪P(p).
Considerj∈Sthat is moved to Pat sampling phase t2. Note that an arm in Sneeds to be first moved to
O1to end up in P. AssumeS(p)̸=∅orS(p)̸={j}. Then,j∈Smoved toO1implies that:
∄i∈S(p)\{j}: ˆmj−Uj+α⪯ˆmi+Ui,
or equivalently:
∀i∈S(p)\{j},∃di∈[M] : ˆmdi
j−Uj+α> ˆmdi
i+Ui.
By Lemma 4:
∀i∈S(p)\{j},∃di∈[M] : (mdi
j+D+Uj)−Uj+α≥ˆmdi
j−Uj+α> ˆmdi
i+Ui≥(mdi
i−D−Ui) +Ui.
Hence:
∀i∈S(p)\{j},∃di∈[M] :mdi
j+D+α>mdi
i−D . (14)
By Definition 4, this implies that ∆j,i<2D+αfor alli∈S(p).
Assume that P(p)̸=∅. We know each arm i∈P(p)must have visited O2in some sampling phase t < t 2
since algorithm did not terminate for any t<t 2. Sincejis inSat sampling phase t, Lemma 6 implies that
∃di∈[M] :mdi
j+D+α>mdi
i−D. Noting that this holds for all i∈P(p), we obtain
∀i∈P(p),∃di∈[M] :mdi
j+D+α>mdi
i−D . (15)
By Definition 4, this implies that ∆j,i<2D+αfor alli∈P(p). This together with the result after
equation 14 implies that ∆j<2D+α. Hence, we conclude that if arm jis moved to P, it needs to be
(2D+α)-optimal.
19Under review as submission to TMLR
Next, we show that for any Pareto optimal arm that is not returned in P, there exists an arm returned in
Pwhich is not worse than the Pareto optimal arm more than 2Din any objective.
Lemma 8. If a Pareto optimal arm p∗is not returned in Pwhen R-PSI terminates, then there exists an
armjreturned in Psuch thatmp∗−mj⪯2D.
Proof.Lemma 5 guarantees that p∗is not eliminated in the ‘Elimination’ step of the algorithm given in line
17 of Algorithm 1. Therefore, p∗/∈Pcan happen only if Algorithm 1 enters the ‘else’ statement in line 28
of its ‘Identification’ step (happens when ∀i∈S, Ui≤α/4) andp∗/∈O1when this happens. The algorithm
terminates and returns Pafter this.
p∗/∈O1in the final sampling phase before termination implies that there exists l1∈S\{p}such that:
ˆmp∗−Uτp∗+α⪯ˆml1+Uτl1. (16)
Letp∗⪯·l1denote the above relation. Also, considering that Uτl1,Uτp∗≤α/4, the above inequality implies:
ˆmp∗+Uτp∗≺ˆml1−Uτl1+α .
Hence:
ˆml1−Uτl1+α̸⪯ˆmp∗+Uτp∗. (17)
We use the notation l1̸⪯·p∗to denote the expression above.
Case 1:Assume that l1∈O1, thus it will be returned in P. Applying Lemma 4, we get:
mp∗−D−2Uτp∗+α⪯ˆmp∗−Uτp∗+α⪯ˆml1+Uτl1⪯ml1+D+ 2Uτl1,
which implies that mp∗−ml1⪯2D+ 2Uτp∗+ 2Uτl1−α⪯2Dsinceα≥2Uτp∗+ 2Uτl1.
Case 2:Assume that l1/∈O1. In this case, there exists l2∈S\{l1}such that:
ˆml1−Uτl1+α⪯ˆml2+Uτl2. (18)
Observe that l2̸=p∗. To see this assume that l2=p∗. This will imply
ˆml1−Uτl1+α⪯ˆmp∗+Uτp∗.
This is a contradiction since equation 16 implies that
ˆmp∗−Uτp∗−2Uτl1+ 2α⪯ˆml1−Uτl1+α⪯ˆmp∗+Uτp∗⇒2α⪯2Uτl1+ 2Uτp∗,
which does not hold. Thus, we conclude that l2̸=p∗. Chaining equation 18 with equation 16, we obtain
ˆmp∗−Uτp∗+α⪯ˆmp∗−Uτp∗+α+ (α−2Uτl1)⪯ˆml1−Uτl1+α⪯ˆml2+Uτl2,
which implies that mp∗−ml2⪯2D+ 2Uτp∗+ 2Uτl2−α⪯2Dsinceα≥2Uτp∗+ 2Uτl2. Ifl2∈O1, we are
done. If not, we prove by induction that there is some j∈O1for whichmp∗−mj⪯2D.
Now, let [li]n
i=1denote a set of arms in Sthat satisfies the following:
1.p∗⪯·l1⪯····⪯·ln.
2. There are no repeating arms in the set.
Now, we will prove by induction that
∀z∈{p∗}∪[li]k−1
i=1, lk̸⪯·z (19)
20Under review as submission to TMLR
for anyk∈[n].We have already proven in equation 17 that when k= 1, equation 19 holds. Now, assuming
that equation 19 holds for k−1, we show that it also holds for k. First, observe that, since lk−1⪯·lkand
sinceα>2Uτlk−1andα>2Uτlk:
ˆmlk−1+Uτlk−1≺ˆmlk−1+Uτlk−1+ (α−2Uτlk−1) = ˆmlk−1−Uτlk−1+α⪯ˆmlk+Uτlk
≺ˆmlk+Uτlk+ (α−2Uτlk) = ˆmlk−Uτlk+α . (20)
Therefore, ˆmlk−1+Uτlk−1≺ˆmlk−Uτlk+α,which implies that ˆmlk−Uτlk+α⪯̸ˆmlk−1+Uτlk−1, orlk̸⪯·lk−1.
Also, by assumption, lk−1̸⪯·z,∀z∈{p∗}∪[li]k−2
i=1, or equivalently:
ˆmlk−1−Uτlk−1+α̸⪯ˆmz+Uτz,∀z∈{p∗}∪[li]k−2
i=1. (21)
Also it is shown in equation 20 that:
ˆmlk−1−Uτlk−1+α≺ˆmlk−Uτlk+α . (22)
Hence, by equation 21, and equation 22:
ˆmlk−Uτlk+α̸⪯ˆmz+Uτz,∀z∈{p∗}∪[li]k−2
i=1.
Also, we had proved above that lk̸⪯·lk−1.From this and above, we conclude:
∀z∈{p∗}∪[li]k−2
i=1∪{lk−1}, lk̸⪯·z
which proves the induction. Now, suppose that we can find another arm ln+1that we can add to this set.
Since the induction proven above applies to this arm as well, we can deduce that ln+1is not prevented by
any other arm in this set to enter O1. Now, suppose that we sequentially keep adding other arms to this set.
Considering that we have a finite amount of arms in S, we will eventually reach a point where we will not
be able to add any more arms. Denote by La set that is constructed through such a procedure and denote
the last element of this set by j. Then,jsatisfies the following:
p∗⪯·l1···⪯·j .
Also, since we cannot keep adding any more arms to this set, we must have:
∀k∈S\(L∪{p∗}) :j̸⪯·k .
Considering that jsatisfies the above proven induction:
∀k∈L∪{p∗}:j̸⪯·k .
Hence, combining two inequalities above yields:
∀k∈S:j̸⪯·k .
The above inequality means that arm jis returned in P. Next, we prove by another induction that p∗⪯·lk
for anylk∈L .This is already given for the first element, i.e., p∗⪯·l1.Now assume that this is true for
armlk−1.Then,p∗⪯·lk−1or equivalently ˆmp∗−Uτp∗+α⪯ˆmlk−1+Uτlk−1. As shown in equation 20, we
also have that:
ˆmlk−1+Uτlk−1≺ˆmlk+Uτlk.
Hence:
ˆmp∗−Uτp∗+α⪯ˆmlk+Uτlk
orp∗⪯·lkandtheinductionisproven. Sincearm jdescribedaboveispartofthisset, p∗⪯·jorequivalently:
ˆmp∗−Uτp∗+α⪯ˆmj+Uτj.
Applying Lemma 4 above, we get:
mp∗−D−2Uτp∗+α⪯ˆmp∗−Uτp∗+α⪯ˆmj+Uτj⪯mj+D+ 2Uτj.
Hence,mp∗−D−2Uτp∗+α⪯mj+D+2Uτj.Sinceα≥2Uτp∗+2Uτj, thisimpliesthat mp∗−D⪯mj+D.
21Under review as submission to TMLR
Next, we state the termination condition for R-PSI in the remark below. We obtain this condition based on
the observation that if the algorithm enters the “else" statement inside the identification step at some round
t, then it terminates after performing the operation inside this “else".
Remark 3. R-PSI terminates at the latest when ∀i∈S,Ui≤α/4.
Next, we give a relaxed elimination condition for the arms that are (4D+α)-suboptimal in the lemma below.
The proof technique of this lemma is similar to the previous lemmas and can be found in Appendix A.7.
Lemma 9. An armithat is (4D+α)-suboptimal is guaranteed to be eliminated at the latest when ∀k∈
S,Uk<¯∆i/4where ¯∆i= ∆i−4D.
With this, we are ready to complete the proof of Theorem 1.
Final Steps in the Proof of Theorem 1 : By Remark 1 and 3, ∀i∈[K], we have:
τi≤inf{τ:Uτ≤α/4}≤inf{τ:Uτ≤α/5}. (23)
By Lemma 9, we can obtain tighter bounds on the number of sampling rounds of arms that are (4D+α)-
suboptimal:
τi≤inf{τ:Uτ<¯∆i/4}≤inf{τ:Uτ≤¯∆i/5}. (24)
The total number of samples taken from an arm that has been selected for τsampling phases can be bounded
by:
Nτ=n0+τ/summationdisplay
˜τ=2n˜τ
=⌈2β¯t,ϵlog(π2MK
6˜δ)⌉+τ/summationdisplay
˜τ=21 +⌈4˜τβ¯t,ϵlog(˜τ
˜τ−1) + 2β¯t,ϵlog(˜τ−1)2MKπ2
6˜δ⌉
≤1 + 2β¯t,ϵlog(π2MK
6˜δ) +τ/summationdisplay
˜τ=2/parenleftbigg
2 + 4˜τβ¯t,ϵlog(˜τ
˜τ−1) + 2β¯t,ϵlog(˜τ−1)2MKπ2
6˜δ/parenrightbigg
.
Simplifying r.h.s. of the above display, we obtain:
Nτ≤2τ(β¯t,ϵlog(τ2MKπ2
6˜δ) + 1).
Now, we can bound the sample complexity as follows.
N=K/summationdisplay
i=1Nτi
=/summationdisplay
i: ∆i>4D+αNτi+/summationdisplay
i: ∆i≤4D+αNτi
≤/summationdisplay
i: ∆i>4D+α2τ(¯∆i)/parenleftigg
β¯t,ϵlog/parenleftiggτ2
(¯∆i)MKπ2
6˜δ/parenrightigg
+ 1/parenrightigg
+/summationdisplay
i: ∆i≤4D+α2τ(α)/parenleftigg
β¯t,ϵlog/parenleftigg
τ2
(α)MKπ2
6˜δ/parenrightigg
+ 1/parenrightigg
=K/summationdisplay
i=12τ(∆α
i)/parenleftigg
β¯t,ϵlog/parenleftiggτ2
(∆α
i)MKπ2
6˜δ/parenrightigg
+ 1/parenrightigg
(25)
≤Kτ(α)/parenleftigg
2β¯t,ϵlog/parenleftigg
τ2
(α)MKπ2
6˜δ/parenrightigg
+ 2/parenrightigg
,
where ∆α
i:= max(α,¯∆i).
Lastly, the Pareto accuracy of R-PSI follows from Lemma 7 and 8.
22Under review as submission to TMLR
A.5 Proof of Corollary 1
Letτ−:=τ(α)−1.By definition of τ(α), we have:
Uτα−1=Uτ−=R/parenleftig
hϵ+ 1//radicalig
β¯t,ϵτ−/parenrightig
−R(hϵ)>α/ 5.
UsingR(t)from Example 1, we have:
σ√
2/parenleftbigg/radicaltp/radicalvertex/radicalvertex/radicalbtlog/parenleftbigg1
1/2−hϵ−/radicalig
1
β¯t,ϵτ−/parenrightbigg
−/radicaligg
log/parenleftbig 1
1/2−hϵ/parenrightbig/parenrightbigg
>α/ 5
⇔2σ2log
1
1/2−hϵ−/radicalig
1
β¯t,ϵτ−
>α2
25+ 2σ2log/parenleftbigg1
1/2−hϵ/parenrightbigg
+2ασ√
2
5/radicaligg
log/parenleftbigg1
1/2−hϵ/parenrightbigg
⇔log/parenleftbigg1
1/2−hϵ−/radicalig
1
β¯t,ϵτ−/parenrightbigg
>α2
50σ2+ log/parenleftbigg1
1/2−hϵ/parenrightbigg
+α√
2
5σ/radicaligg
log/parenleftbigg1
1/2−hϵ/parenrightbigg
.
Letc1=1
50σ2andc2=√
2
5σ/radicalbigg
log/parenleftig
1
1/2−hϵ/parenrightig
. Continuing from the above display,
log/parenleftbigg1
1/2−hϵ−/radicalig
1
β¯t,ϵτ−/parenrightbigg
>α2c1+ log/parenleftbigg1
1/2−hϵ/parenrightbigg
+αc2
⇔1
1/2−hϵ−/radicalig
1
β¯t,ϵτ−>exp/parenleftbigg
α2c1+ log/parenleftbigg1
1/2−hϵ/parenrightbigg
+αc2/parenrightbigg
⇔1
exp/parenleftig
α2c1+ log/parenleftig
1
1/2−hϵ/parenrightig
+αc2/parenrightig>1/2−hϵ−/radicaligg
1
β¯t,ϵτ−
⇔/radicaligg
1
β¯t,ϵτ−>1/2−hϵ−exp/parenleftbigg
−α2c1−log/parenleftbigg1
1/2−hϵ/parenrightbigg
−αc2/parenrightbigg
⇔/radicaligg
1
β¯t,ϵτ−>(1/2−hϵ)(1−exp(−α2c1−αc2))
⇔τ−<1
(1/2−hϵ)2β¯t,ϵ/parenleftbigg1
1−exp(−α2c1−αc2)/parenrightbigg2
.
Continuing from the above display, using1
1−e−x= 1 +1
ex−1≤1 +1
xwe get:
τ−<1
(1/2−hϵ)2β¯t,ϵ/parenleftbigg
1 +1
α2c1+αc2/parenrightbigg2
.
Recall that τ−:=τ(α)−1:
τ(α)<1 +1
(1/2−hϵ)2β¯t,ϵ/parenleftbigg
1 +1
α2c1+αc2/parenrightbigg2
= 1 +(¯t−hϵ)2
(1/2−hϵ)2/parenleftbigg
1 +1
α2c1+αc2/parenrightbigg2
23Under review as submission to TMLR
<1 +/parenleftbigg
1 +1
α2c1+αc2/parenrightbigg2
(26)
≤1 +/parenleftbigg
1 +1
αc2/parenrightbigg2
≤/parenleftbigg√
2 +1
αc2/parenrightbigg2
≤/parenleftbigg2
αc2/parenrightbigg2
(27)
=4
α2c2
2
=50σ2
α2log/parenleftig
1
1/2−hϵ/parenrightig, (28)
where equation 27 holds when αc2≤1/√
2, which is valid when α→0andϵis fixed. Equation 26 holds due
to(¯t−hϵ)2<(1/2−hϵ)2which follows from
(¯t−hϵ)2−(1/2−hϵ)2= (¯t−1/2)(¯t−2hϵ+ 1/2)<0.
The last line holds due to hϵ≤¯t < 1/2. For oblivious and prescient adversaries, Theorem 1 has the
assumption ϵ≤2¯t
1+2¯twhich is equivalent toϵ
2(1−ϵ)≤¯t. For malicious adversary, Theorem 1 has the
assumption ϵ≤¯t. Hence,hϵ≤¯tfor all adversaries. By Definition 2, ¯t∈(0,1/2). Hence,hϵ≤¯t<1/2.
Starting from equation 7:
N≤Kτ(α)/parenleftigg
2β¯t,ϵlog/parenleftigg
τ2
(α)MKπ2
6˜δ/parenrightigg
+ 2/parenrightigg
≤4Kτ(α)β¯t,ϵlog/parenleftigg
τ2
(α)MKπ2
6˜δ/parenrightigg
(29)
= 4Kτ(α)β¯t,ϵ/parenleftigg
log/parenleftigg
τ2
(α)MK
˜δ/parenrightigg
+ log/parenleftbiggπ2
6/parenrightbigg/parenrightigg
≤8Kτ(α)β¯t,ϵlog/parenleftigg
τ2
(α)MK
˜δ/parenrightigg
(30)
≤8Kτ(α)β¯t,ϵlog/parenleftigg
τ2
(α)M2K2
˜δ2/parenrightigg
= 16Kτ(α)β¯t,ϵlog/parenleftbiggτ(α)MK
˜δ/parenrightbigg
.
Equations 29 and 30 hold for large M,Kand small ˜δvalues. Plugging in equation 28, we have
N≤16K50σ2
α2log/parenleftig
1
1/2−hϵ/parenrightigβ¯t,ϵlog
50σ2
α2log/parenleftbig
1
1/2−hϵ/parenrightbigMK
˜δ

= 800Kσ2
α2log/parenleftig
1
1/2−hϵ/parenrightigβ¯t,ϵlog
50σ2MK
α2log/parenleftig
1
1/2−hϵ/parenrightig
˜δ
 (31)
24Under review as submission to TMLR
=O
σ2Kβ¯t,ϵ
α2log/parenleftig
1
1/2−hϵ/parenrightiglog
σ2MK
α2log/parenleftig
1
1/2−hϵ/parenrightig
˜δ

.
Let us analyze the bound under the assumption ϵ= 0and¯tis a constant. We have log/parenleftig
1
1/2−hϵ/parenrightig
= log(2),
β¯t,ϵ=1
¯t2. Starting from equation 31, we have
N≤800σ2Kβ¯t,ϵ
α2log/parenleftig
1
1/2−hϵ/parenrightiglog
50σ2MK
α2log/parenleftig
1
1/2−hϵ/parenrightig
˜δ

=800σ2
¯t2log(2)K
α2/parenleftbigg
log/parenleftbigg50σ2MK
α2˜δlog(2)/parenrightbigg/parenrightbigg
=O/parenleftbiggKσ2
α2log/parenleftbiggσ2MK
α˜δ/parenrightbigg/parenrightbigg
.
A.6 Proof of Corollary 2
Letτ−:=τ(∆α
i)−1. By definition of τ(∆α
i), we have:
Uτ−=R/parenleftig
hϵ+ 1//radicalig
β¯t,ϵ(τ−)/parenrightig
−R(hϵ)>(∆α
i)/5.
Let us define z:=B¯m2for brevity. Notice that z > 0sinceB > 0by Definition 3 and ¯m2>0as it is
the maximum over the median of non-negative values. Also, β¯t,ϵ>0for oblivious, prescient and malicious
adversaries. Using R(t) =B¯m2t, we have
z/parenleftig
hϵ+ (β¯t,ϵτ−)−1
2/parenrightig
−zhϵ>(∆α
i)
5⇔(β¯t,ϵτ−)−1
2z>(∆α
i)
5⇔(β¯t,ϵτ−)−1
2>(∆α
i)
5z⇔(β¯t,ϵτ−)−1>(∆α
i)2
25z2
⇔β¯t,ϵτ−<25z2
(∆α
i)2⇔τ−<25z2
β¯t,ϵ(∆α
i)2⇔τ(∆α
i)<1 +25z2
β¯t,ϵ(∆α
i)2.
Recall equation 25:
N≤K/summationdisplay
i=12τ(∆α
i)/parenleftigg
β¯t,ϵlog/parenleftiggτ2
(∆α
i)MKπ2
6˜δ/parenrightigg
+ 1/parenrightigg
.
Putting them together,
N≤K/summationdisplay
i2/parenleftigg
β¯t,ϵ+25 ¯m2
2B2
(∆α
i)2/parenrightigg
log
/parenleftbigg
1 +25 ¯m2
2B2
β¯t,ϵ(∆α
i)2/parenrightbigg2
MKπ2
6˜δ
+ 1
.
A.7 Proof of Lemma 9
First, we give the following lemma needed in the proof.
Lemma 10. Consider an arm ithat is (2D+α)-suboptimal and suppose that the Pareto optimal arm
j= arg maxz∈P∗∆i,zis moved to Patt0before the termination round. Then iis eliminated at t≤t0.
25Under review as submission to TMLR
Proof.Assume that i∈Sat the beginning of ‘Identification’ step at sampling phase t0. By Lemma 6,
∃di∈[M] :mdi
i+ (2D+α)> mdi
j, implying ∆i<2D+α, hence arm icannot be (2D+α)-suboptimal.
Therefore, it is not possible for arm ito be inSafter the ‘Elimination’ step at t0. Similarly, icannot be in
Patt0because of Lemma 7. These together imply that it was eliminated at a round t≤t0.
Next we proceed proving Lemma 9. By Lemma 7, if i̸∈S, theniis already eliminated since icannot be in P.
Now, suppose that i∈S. Consider the optimal arm j= arg maxk∈P∗∆i,k. Note that ∆i,j= ∆i>4D+α
and
∀d∈[M], md
j≥md
i+ ∆i. (32)
Now, suppose that j∈Sso thatUj≤¯∆i/4. Then, by Lemma 4 and by equation 32:
ˆmd
j−D−Uj≥md
j−2D−2Uj≥md
i+ ∆i−2D−2Uj
≥ˆmd
i+ ∆i−3D−2Uj−Ui. (33)
Considering that ∆i>4DandUi,Uj<¯∆i/4:
ˆmd
i+ ∆i−3D−2Uj−Ui= ˆmd
i+ ∆i−4D−2Uj−2Ui+D+Ui>ˆmd
i+D+Ui.(34)
We conclude from equation 33 and equation 34:
ˆmd
j−D−Uj>ˆmd
i+D+Ui,∀d∈[M].
Hence, by the elimination rule of R-PSI, when j∈S,iis eliminated. Now suppose that j /∈S. Sincej
cannot be eliminated by Lemma 5, j∈P. By Lemma 10, iis eliminated.
Lastly, suppose that at the earliest round where ∀k∈S ,Uk≤¯∆i/4, the algorithm enters the else statement
in the ‘Identification’ step. Then, the algorithm terminates by Remark 3 and iis not included in Pby
Lemma 7. To summarize, in all possible scenarios, we showed that iis guaranteed to be eliminated (if it is
not already eliminated) as soon as ∀k∈S, Uk≤¯∆i/4.
26