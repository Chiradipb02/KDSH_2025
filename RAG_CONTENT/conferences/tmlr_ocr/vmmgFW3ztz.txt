Under review as submission to TMLR
Leveraging a Simulator for Learning Causal Represen-
tations from Post-Treatment Covariates for CATE
Anonymous authors
Paper under double-blind review
Abstract
Treatmenteffectestimationinvolvesassessingtheimpactofdifferenttreatmentsonin-
dividual outcomes. Current methods estimate Conditional Average Treatment Effect
(CATE) using observational datasets where covariates are collected before treatment
assignment and outcomes are observed afterward, under assumptions like positivity
and unconfoundedness. In this paper, we address a scenario where both covariates
and outcomes are gathered after treatment. We show that post-treatment covariates
render CATE unidentifiable, and recovering CATE requires learning treatment-
independent causal representations. Prior work shows that such representations can
belearnedthroughcontrastivelearningifcounterfactualsupervisionisavailableinob-
servational data. However, since counterfactuals are rare, other works have explored
usingsimulatorsthatoffersyntheticcounterfactualsupervision. Ourgoalinthispaper
istosystematicallyanalyzetheroleofsimulatorsinestimatingCATE.Weanalyzethe
CATE error of several baselines and highlight their limitations. We then establish a
generalization bound that characterizes the CATE error from jointly training on real
andsimulateddistributions, asafunctionofthereal-simulatormismatch. Finally, we
introduceSimPONet,anovelmethodwhoselossfunctionisinspiredfromourgeneral-
ization bound. We further show how SimPONet adjusts the simulator’s influence on
thelearningobjectivebasedonthesimulator’srelevancetotheCATEtask. Weexper-
iment with various DGPs, by systematically varying the real-simulator distribution
gap to evaluate SimPONet ’s efficacy against state-of-the-art CATE baselines.
1 Introduction
In Conditional Average Treatment Effect (CATE) task, the goal is to estimate the difference in an
outcomeY, as an individual Zis subject to different treatments T. The gold standard to estimating
such effects is Randomized Control Trials, which are often expensive, and with the easy availability of
observationaldata,thereisextensiveinterestinharnessingthemforderivingtheseestimates. Thefirst
step in estimating treatment effects from observational datasets is to determine the set of covariates
that,whenconditionedupon,makethetreatmenteffectsidentifiable. Priorworks (Künzeletal.,2019;
Nie&Wager,2021;Curth&vanderSchaar,2023;Shalitetal.,2017;Nieetal.,2021;Shalitetal.,2016;
Chauhan et al., 2023; Curth & van der Schaar, 2021; Zhang et al., 2020; Shi et al., 2019; Stuart, 2010),
assume that such covariates are observed, and gathered prior to treatment, with outcomes Yobserved
after the treatment is given. However, collecting such datasets is challenging as it requires tracking
1Under review as submission to TMLR
thesameindividualsovertwodistincttimepoints. Asaresult, readilyavailableobservationaldatasets
can sometimes contain both covariates Xand the outcomes Yrecorded together post-treatment. X,
Yare observed for individuals characterized by a latent representation Z. For example, in economics,
policymakers implement different taxation policies Taimed at improving an outcomes Ylike Gross
Domestic Expenditure of the individuals Z. To identify effective policies, they may rely on domain
expertise or conduct small-scale RCTs where collecting pre-treatment covariates is feasible. However,
the true effectiveness of a policy is only revealed through large-scale testing on the population after
its implementation. Collecting such datasets typically involves obtaining post-treatment covariates X
and their associated outcomes Ytogether (Ashenfelter, 1978; Angrist, 1995). Even in other domains
such as voluntary healthcare surveys, only post-treatment data about patients might be accessible. In
medical imaging, an image taken under a specific instrument setting (treatment) may be evaluated to
determine whether switching to a different setting would improve a subsequent diagnosis (outcome).
We present our setup in the top panel of Fig. 1 marked RealDGP (Data Generating Process for the
real distribution), where the latent variables Zcausally produce the observed treatment T, outcome
Y, and covariates X. We begin this paper by presenting an impossibility result in this context.
Lemma 1. The causal effect of TonYis not identifiable given i.i.d. samples of the observed nodes
from the real DGP shown in top panel of Fig. 1.
ZT
Y(T) X(T)
XS(0)XS(1)YS(0)YS(1)gt
gS
0gS
1ft=g−1
tReal DGP
Z∼PZN(µT(Z),σ2
y)PT(•|Z)
δ(X−gT(Z))
δ(XS−gS
T(Z))N(µS
T(Z),σ2
yS)
Simulator DGP
Figure 1: The Data Generating pro-
cess for Real and Simulator.proof.SinceXisacollider,conditioningonitopensthebackdoor
pathT→X←Z→Y. Furthermore,as Zislatent,thisbackdoor
path remains open, making CATE unidentifiable from X,T,
andYalone (Pearl, 2015).
The main takeaway from the lemma is that certain additional
assumptions are unavoidable for achieving identifiability. The
lemma further emphasizes that the key to identifiability lies in
extracting treatment-independent causal representations from
the post-treatment Xthat affectY. One such assumption that
allowsfortherecoveryofcausalrepresentationsiscounterfactual
supervision in real data. Prior work (Von Kügelgen et al., 2021)
demonstratesthat, undersuchanassumption,contrastivelosses
can be applied to pairs of covariates that differ by treatment to
extractZfromXandT. While some works (Nagalapatti et al.,
2022; Bachman et al., 2019) assume direct access to such coun-
terfactualsupervisioninrealdata,othersrelyonsimulatorsthat
generate high-quality synthetic counterfactuals (Von Kügelgen
et al., 2021; Zimmermann et al., 2021). However, these are strong assumptions since counterfactuals
are rarely available in real-world scenarios, and while simulators are more feasible, assessing their
quality or relevance to the downstream task during training is challenging. Therefore, our goal in this
paper is to leverage simulators only to the extent they remain relevant to the CATE task. We conduct
a theoretical analysis to derive generalization bounds that show how CATE error worsens as the
mismatch between real and simulated distributions increases. These insights motivate our proposed
algorithm, SimPONet , which uses simulated data to apply regularizers inspired by our generalization
bound.SimPONet ’s aim is to enhance CATE estimates beyond what is achievable with observational
data alone. Through experiments, we systematically vary the distributional gap between real and
2Under review as submission to TMLR
synthetic data across various DGPs, demonstrating that SimPONet consistently outperforms multiple
baselines in estimating CATE.
Contributions: 1) We address Treatment Effect Estimation with post-treatment covariates —- a
non-identifiable challenge – by leveraging a simulator that offers synthetic counterfactual supervision.
2) We assess the CATE errors for three baselines that can be trained on real/simulated data, and
highlighttheirlimitations. 3)Next,weconsiderajointtrainingframework,andderiveageneralization
bound that characterizes the CATE error as a function of real-simulator distributional mismatch.
4) This analysis motivates our method, SimPONet , a novel algorithm that uses simulated samples
to improve CATE estimates beyond what can be achieved from observational data alone. 5) To
our knowledge, this is the firstsystematic study on the role of simulators in CATE estimation. 6)
Experiments across various DGPs confirm SimPONet ’s effectiveness.
2 Related Work
2.1 CATE with Pre-Treatment Covariates
The primary challenge addressed here is handling confounding that arises out of biased treatment
assignment in observational datasets. The main ideas explored include: estimating pseudo-outcomes
for missing treatments in the training dataset and then using these to train effect predictors (Gao
& Han, 2020; Curth & van der Schaar, 2021; Nie & Wager, 2021; Kennedy, 2020; Yoon et al., 2018;
Zhang et al., 2020; Nagalapatti et al., 2024a); adding targeted regularizers to ensure consistent ITE
estimates (Shi et al., 2019; Nie et al., 2021; Zhang et al., 2022); learning balanced representation of
covariates across treatment groups (Shalit et al., 2016; 2017; Yao et al., 2018; Chauhan et al., 2023;
Wangetal.,2024;Wuetal.,2023); matchingtonear-bycovariates(Stuart,2010;Rosenbaum&Rubin,
1983; Iacus et al., 2012; Schwab et al., 2018; Kallus, 2020; Nagalapatti et al., 2024b); and weighing
losses to mitigate confounding (Hassanpour & Greiner, 2019a;b; Jung et al., 2020; Ozery-Flato et al.,
2018).
2.2 CATE with Post-Treatment Covariates
Thisisoursetting,andismorechallengingbecauseitfallsintothethirdrung(counterfactual)ofPearl’s
causal ladder (Pearl & Press, 2000). Please refer (Pearl, 2015) to for a formal proof. In economics,
post-treatment variables in trials are known to exacerbate estimated causal effects (Coppock, 2019;
HOMOLA et al., 2024; King, 2010). Post-treatment variables have been used to estimate selection
biasP(T|Z)in observational data (Bareinboim & Pearl, 2012; Bareinboim & Tian, 2015; Correa
et al., 2018). A closely related work is (Huang et al., 2023) that leverages post-treatment variables for
estimating treatment effects but differs from us since they assume: (1) covariates Xcausally affect
Y, and (2) an entangled version of X,Zis observed; they simply focus on disentangling Zthrough
representation learning.
2.3 Real-World Applications of using Simulators for Estimating CATE
We provide two examples from medicine and electrochemistry to show how simulators aid CATE
estimation in practice:
Medicine. Simulators play a crucial role in pharmacology, particularly for assessing drug efficacies.
For instance, the SimBiology toolbox1in MATLAB is commonly used to predict the effects of SGLT2
1https://in.mathworks.com/videos/series/simbiology-tutorials-for-qsp-pbpk-and-pk-pd-modeling-and-analysis.html
3Under review as submission to TMLR
inhibitors (T) on type-2 diabetes ( Y) while considering post-treatment covariates ( X) such as plasma
glucoselevels,gutglucoselevels,urinaryglucoseexcretion,andliverinsulinlevels. SimBiologyenables
modeling these effects using differential and algebraic equations that are often calibrated on target
populations to minimize the real-simulator mismatch. Despite not perfectly replicating reality, such
simulators are invaluable for early-stage clinical trial decisions and have demonstrated utility in
modeling short-term treatment effects (Dalla Man et al., 2007).
Electrochemistry. Another application involves recommending optimal electrode materials to
maximize battery capacity ( Y). By observing Yunder various electrode materials ( T) and post-
treatment variables like charge/discharge rate, internal resistance, and temperature distribution
(X), the Ansys Battery Cell and Electrode Simulator2provides electrochemical simulations. This
tool has been used by Volkswagen Motorsport for comprehensive multiphysics simulations to design
and validate battery models. Such simulators are highly relevant for practical decision-making in
industries.
These examples illustrate the practical relevance of simulators across different fields. While simulators
cannot fully replace real data or randomized controlled trials (RCTs), they offer valuable insights
that can reduce the number of RCTs needed for optimal treatment identification. Our paper aims to
characterize the CATE error when using imperfect simulators in conjunction with real observational
data. Additionally, SimPONet maximizes the utility of simulators by leveraging the highly correlated
simulator’s treatment effects with real-world effects, without relying on the exact correlation of
individual potential outcomes.
3 Problem Formulation
Weuserandomvariables X,T,Ytodenotepost-treatmentcovariates,binarytreatments,andoutcomes
respectively. The observational dataset has nsamples:Dtrn={(xi,ti,yi)}n
i=1whereti∈T={0,1}
denotes treatment, xi∈X⊂ Rnxdenotes covariates observed after tiis applied, and yithe resulting
outcome. We use the Neyman-Rubin potential outcomes framework to denote Yi(t),Xi(t)as the
potential outcome and covariate for unit iunder a treatment t. The main challenge is the absence
of counterfactuals in Dtrn, i.e., for each unit i, we observe covariates and outcomes under only one
treatmentti.
We use the random variable Z∈Z⊂ Rnzto denote the causal representations of covariates X.Z
generatesXvia treatment-specific covariate generating functions gt:Z∝⇕⊣√∫⊔≀→Xfort∈{0,1}. We assume
thatgtis diffeomorphic (Locatello et al., 2019a;b; Von Kügelgen et al., 2021); i.e., it is smooth,
invertible, and has a smooth inverse. The assumption that gtis diffeomorphic is required to establish
the theoretical identifiability of τ. A non-invertible transformation risks losing information when
mappingZ,TtoX. If this lost information includes features necessary for identifiability, then τ
becomes unidentifiable from the observed X,T,Y. Diffeomorphism ensures that all factors involved
in generating Xare preserved within Xso that there exists inverse functions ft:X∝⇕⊣√∫⊔≀→Z,∀t∈{0,1}
that could recover the causal representations Zback. In Sec. 5.6, we experiment with non-invertible
transformations and find that both the baselines and SimPONet maintain robust performance, even
when these assumptions are violated in practice.
A sample is obtained from the real DGP as follows: (1) zi∼PZ, (2)ti∼P(T|zi), (3)xi∼P(X|zi,ti)=
δ(X−gti(zi)), whereδdenotes the dirac-delta distribution, (4) yi∼P(Y|zi,ti) =N(µti(zi),σ2
y)is
2https://www.ansys.com/applications/battery/battery-cell-and-electrode
4Under review as submission to TMLR
sampled from a Gaussian with mean µti(zi)and constant variance σ2
y. Here,µt:Z∝⇕⊣√∫⊔≀→Y∀tgenerates
responses for individuals with latent representations zunder treatment t. We express the factual
observed outcome for iasYi(ti)=µti(fti(xi)), and the missing counterfactual (CF) outcome under
1−tiasYi(1−ti)=µ1−ti(fti(xi)).
OurGoal isConditionalAverageTreatmentEffect(CATE)estimationwhichquantifiesthedifference
inoutcomesduetoachangeintreatment. Givenatestunit (xj,tj),itsCATEisgivenby τj=E[Yj(T=
1)−Yj(T=0)|xj,tj]. As argued earlier, estimating τfrom post-treatment data involves the sub goal of
learning causal representations of observed covariates Xusing a function ft:X∝⇕⊣√∫⊔≀→Z. We useτ:Z∝⇕⊣√∫⊔≀→Y
to express the treatment effect using the latent zjasτ(zj)=µ1(zj)−µ0(zj). SinceftinvertsXto give
Z, the same effect can also be expressed for (xj,tj)usingτXasτX(xj,tj)=µ1(ftj(xj))−µ0(ftj(xj))
whereτX:X×T∝⇕⊣√∫⊔≀→Y . Notice that τX(•,t) =τ◦ft(•). When estimating τX, the factual outcome is
easy, all we need to do is fit a regression model on the observation data. The main challenge lies in
estimating the counterfactual outcome under treatment 1−tj.
Theorem 1 in (Locatello et al., 2019a) presents an impossibility result stating that ftwhich maps
covariatesXto their treatment-independent causal representations Zisnotidentifiable solely using
Dtrn. ThemainhurdleisthatmultipleDGPscanyieldthesamemarginaldistribution P(X,T),making
itimpossibletoisolatethetrueDGP.However,priorworkhasshownhowtolearn ftwithcounterfactuals ,
requiring that Dtrnincludes both covariates Xi(ti)andXi(1−ti). Theorem 4.4 of (Von Kügelgen
et al., 2021) shows that such counterfactual supervision allows for recovery of Zup to a diffeomorphic
transformation husingcontrastivelearning. Proposition2in(Zimmermannetal.,2021)furthershows
thathis, in particular, a rotation in an nzdimensional unit-normalized hypersphere. While some
prior works assume direct access to counterfactual supervision in real data (Nagalapatti et al., 2022;
Bachman et al., 2019), others rely on high-quality synthetic counterfactuals from simulators (Xie,
2018; Kaur et al., 2021). In contrast, our approach seeks to leverage simulators only to the extent that
they improve the downstream CATE task. We next formally define the simulator’s data generating
process.
Simulator DGP The simulator generates paired instances giving rise to a counterfactual dataset
Dsyn={xS
i(0),xS
i(1),yS
i(0),yS
i(1)}generated using the DGP as shown in the lower panel in Figure 1.
The simulated instances are obtained as follows: (1) zi∼PZ; i.e.,Zis sampled from the same
distribution as real, (2) post-treatment covariates xS
i(t)∼P(XS|Z=zi,T=t)=δ(XS−gS
t(zi))under
bothtreatments t={0,1}.gS
t:Z∝⇕⊣√∫⊔≀→X∀tare diffeomorphic functions, and (3) corresponding outcomes
yS
i(0),yS
i(1)are sampled from P(YS|Z=zi,T=t)=N(µS
t(zi),σ2
yS), whereµS
t:Z∝⇕⊣√∫⊔≀→Y,∀t. Note that
ziremains hidden even in Dsyn. We use “S” in the superscript to indicate a simulator component.
Now we describe some metrics that assess the distance between real and simulator DGP.
Definition1 [dx|t(ft,fS
t)]Weassessthedistancebetweentherealandsyntheticcausalrepresentation
extractorsftandfS
tusingthefollowingexpecteddistance: dx|t(ft,fS
t)=Ex∼P(X|t)/bracketleftbig
||ft(x)−fS
t(x)||2
2/bracketrightbig
.
Definition 2 [dz(τ,τS)] We assess the distance between the real and simulator CATE functions on
thePZdistribution as: dz(τ,τS)=Ez∼PZ/bracketleftbig
(τ(z)−τS(z))2/bracketrightbig
. Under composition with a diffeomorphic
functionh, we writedh(τ,τS)=Ez∼PZ/bracketleftbig
(τ(h(z))−τS(h(z)))2/bracketrightbig
.
Assumptions for Identifying CATE τX.We summarise the assumptions that are needed on
the real dataset Dtrnand simulated counterfactual dataset Dsynto identify the CATE function τX:
(A1)Positivity: P(T=t|Z=z)>0,∀t∈T,z∈Z. (A2)Diffeomorphic Covariate Generation:
Covariatesinbothrealandsyntheticdistributionsareobtainedthroughdiffeomorphictransformations
5Under review as submission to TMLR
ofZunder any treatment T. (A3)Identifiability of τgivenZ:The causal factors Zthat generate X
formasufficientadjustmentset, blockingbackdoorpathsbetween TandY, thusmaking τidentifiable
fromZ. NotethatA2andA3togetherensurethat Xcontainsinformationaboutalltherelevantlatent
factors that affect the outcome Yand is a weaker notion of the commonly used unconfoundedness
assumption.
CATE Error (ECATE).Given a test dataset Dtst={(xj,tj,yj(0),yj(1))}m
j=1, with each xjrendered
undertj, we compute the empirical error incurred in estimating CATE using mean squared error as
ECATE =1
m/summationtext
j∈Dtst[τj−/hatwideτj]2whereτj=yj(1)−yj(0)is the true effect and /hatwideτjis the predicted effect for
the instance (xj,tj).
The CATE error in general can be decomposed across treatment Tas
ECATE =/summationdisplay
t∈TP(T=t)Et
CATEwhereEt
CATE =/integraldisplay
x∈X[τX(x,t)−/hatwiderτX(x,t)]2P(x|t)dx
Definition 3. Let us define factualerrorEt
Fandcounterfactual errorEt
CFon samples with observed
treatmenttand missing treatment 1−tas follows:
Et
F=/integraldisplay
x∈X[µt(ft(x))−/hatwideµt(/hatwideft(x))]2P(x|t)dxandEt
CF=/integraldisplay
x∈X[µ1−t(ft(x))−/hatwideµ1−t(/hatwideft(x))]2P(x|t)dx
Lemma 2. The CATE error is related to the factual and counterfactual error as: Et
CATE≤2Et
F+2Et
CF
[Proof in Appendix A.5.1]
4 Learning Causal Representations for CATE
Our task involves learning four functions: /hatwideftthat extracts the causal representations from X(t)and/hatwideµt
that estimates the outcomes Y(t)fort∈{0,1}. With access to counterfactual simulated dataDsynand
observational real dataDtrn, one can come up with the following approaches for estimating CATE: 1)
SimOnly, which only uses Dsyn, and 2) RealOnly which only uses Dtrnto estimate µt,(3)RealµSimf,
which uses Dsynto estimate ftand subsequently, Dtrnto estimate µt. We now discuss the training
approach for each of these methods, delve into their shortcomings, and then present our proposed
methodSimPONet .
Toillustratetheshortcomings,weconsideratestinstance x⋆generatedundertreatment T=1(without
loss of generality) and derive the CATE error expression for it in the population setting, as |Dtrn|→∞
and|Dsyn|→∞.
4.1 The SimOnly Estimator
SimOnly solely uses Dsyn. It leverages the counterfactual supervision provided by the simulator and
identifies the simulator’s DGP as follows:
(Step 1) Estimate the synthetic causal representation extractor fSfrom covariate pairs {xS
i(0),xS
i(1)}
using contrastive learning Von Kügelgen et al. (2021):
{/tildewidefS
0,/tildewidefS
1}=argmin
{/hatwidefS
0,/hatwidefS
1}|Dsyn|/summationdisplay
i=1/bracketleftigg
−logexp(sim(ˆzi(1),ˆzi(0))/summationtext
j̸=i/summationtext
t,t′exp(sim(ˆzi(t),ˆzj(t′)))/bracketrightigg
where ˆzi(t)=/hatwidefS
t(xS
i(t))(1)
6Under review as submission to TMLR
wheresim(•,•)is cosine similarity, (xS
i(t),xS
i(1−t))denotes a positive pair with the same underlying
latentzi. A negative pair (xS
i(t),xS
j(t′))has different (zi,zj). Contrastive learning increases similarity
of representations of positive pairs (ˆzi(0),ˆzi(1))while pushing apart the negative pairs (ˆzi(t),ˆzj̸=i(t′)).
Lemma 3. As|Dsyn|→∞, contrastive training with paired counterfactual covariates as shown in
Eq. 1 recovers /tildewidefS
t=h◦fS
twherehis a diffeomorphic transformation. Moreover, when the latent
spaceZ⊂S(nz−1)(unit-norm hypersphere in Rnz),his a rotation transform by Extended Mazur-Ulam
Theorem as shown in (Zimmermann et al., 2021) (Proposition 2).
[Refer Appendix A.5.2 for more details.]
The main insight from the above lemma is that, given counterfactual supervision, it is possible to
recover causal representations Zfrom post-treatment covariates Xup to a rotation h, making CATE
identifiable in the simulated distribution, as we demonstrate below.
(Step 2) Estimate /tildewideτS(z)=/tildewideµS
1(z)−/tildewideµS
0(z)with supervision on difference of outcomes τS(fS
t(xS
i(t)))=
yS
i(1)−yS
i(0)as
/tildewideτS=argmin
/hatwideτS/summationdisplay
xS∈Dsyn/bracketleftig
τS(fS
t(xS(t)))−/hatwiderτS(/tildewidefS
t(xS(t)))/bracketrightig2
(2)
The SimOnly method uses these estimates as-is on real data, i.e. /hatwideτ=/tildewideτSand/hatwideft=/tildewidefS
t,∀t∈T. We
analyze below the error incurred with such estimates on real data.
CATE error: In the population setting, since /tildewidefS
t=h◦fS
t, we see that the optimization problem in
Eq. 2 yields/tildewideτS=τS◦h−1as its solution. Thus, for an instance x⋆from the real distribution under
treatment 1, the true CATE is τ(f1(x⋆)). The CATE error using SimOnly becomes:
/bracketleftbig
τ(f1(x⋆))−τS◦h−1(h◦fS
1(x⋆))/bracketrightbig2=/bracketleftbig
τ(f1(x⋆))−τS(fS
1(x⋆))/bracketrightbig2.
This shows that for SimOnly to provide accurate CATE estimates, the simulator must perfectly align
with the real world; i.e., τS=τandft=fS
tfor allt. However, designing such simulators is highly
challenging in practice, making this method unsuitable for CATE.
4.2 The RealOnly Estimator
RealOnly solely uses real observational data Dtrn. SinceDtrnlacks counterfactual covariates, this
modelcannotapplycontrastivetrainingandthereforecannotexplicitlysupervisetherecoveryofcausal
representations. Instead, it focuses on regressing the factual outcomes yi(ti)from post-treatment
covariates xi(ti). In terms of the four learning parameters, its learning objective is:
argmin
{/hatwideµ0,/hatwideµ1,/hatwidef0,/hatwidef1}|Dtrn|/summationdisplay
i=1(yi−/hatwideµti(/hatwidefti(xi)))2
However,since /hatwideµt,/hatwideftarenotindividuallysupervised,wemightaswellcollapsethemintoacomposition
µF
t=µt◦ft; yieldingµF
ti(xi)=yi, and thereby CATE as /hatwiderτX(x,t)=/hatwideµF
1(x)−/hatwideµF
0(x).
RealOnly is consistent in estimating the factual outcomes, because as |Dtrn|→∞, we have
/hatwideµF
t=argmin/hatwideµF
tEx∼P(x|t)/bracketleftig/parenleftbig
/hatwideµF
t(x)−µF
t(x)/parenrightbig2/bracketrightig
=µF
tand therefore, the factual error Et
F= 0. How-
7Under review as submission to TMLR
ever, RealOnly incurs a significant error when estimating the counterfactual outcome, which in turn
contributes to the CATE error, as shown below.
CATE error: The true CATE for x⋆obtained using treatment 1can be written as τ(f1(x⋆)) =
µ1(f1(x⋆))−µ0(f1(x⋆)). Then, the CATE error for RealOnly is computed as:
/bracketleftbig/parenleftbig
µ1(f1(x⋆))−µ0(f1(x⋆))/parenrightbig
−/parenleftbig
/hatwideµF
1(x⋆)−/hatwideµF
0(x⋆)/parenrightbig/bracketrightbig2=/bracketleftbig/parenleftbig
µ1(f1(x⋆))−/hatwideµF
1(x⋆)/parenrightbig
−/parenleftbig
µ0(f1(x⋆))−/hatwideµF
0(x⋆)/parenrightbig/bracketrightbig2
In the population setting, using the consistency of factual estimates, the CATE error reduces to/bracketleftbig
µ0(f1(x⋆))−µF
0(x⋆)/bracketrightbig2. This error is zero when f1(x⋆) =f0(x⋆). Thus, for RealOnly to provide
accurate CATE estimates, the treatment must not affect the post-treatment covariates, i.e., g0(z)=
g1(z)∀zin which case their inverse are equal f0=f1. However, this assumption is often unrealistic.
For instance, in pharmacology, different drugs typically induce distinct effects on patient covariates,
limiting the applicability of this model in such settings.
Remark: The post-treatment covariates Xcan be viewed as a special case of the pre-treatment
covariatesZwhen the covariate-generating functions g0=g1. In such cases, our proposed SimPONet
algorithm offers no distinct advantage, and existing CATE methods designed for pre-treatment
covariates suffice and should be used instead.
4.3 The Real µSimfEstimator
Unlike SimOnly, which uses Dsynto learn both /hatwideftand/hatwideµt, this approach leverages Dsynsolely to
learn the representation extractor /hatwideft. Specifically, it assumes that /hatwideft=/tildewidefS
t, as obtained from Eq. 1.
Thereafter, it learns the /hatwideµtparameters by applying a factual loss on Dtrnto estimate
/hatwideµ0,/hatwideµ1=argmin
{/hatwideµ0,/hatwideµ1}/summationdisplay
Dtrn(yi−/hatwideµti(/tildewidefS
ti(xi)))2
We call this method RealµSimfsince it learns the outcome parameters µfrom real samples while
learning representation extractor ftfrom the simulator.
CATE error: One condition under which the RealµSimfmodel achieves zero CATE error is when
/tildewidefS
t=ftfor each treatment t. This requires that the simulator aligns with real-world covariates,
specifically xt=gt(z)=gS
t(z)=xS
t. This limitation arises because the model learns the representation
extractor solely from Dsyn, without making adjustments for real covariates.
In summary, we described three possible CATE estimators and showed that each method would
provide accurate CATE estimates under certain strong assumptions about the real and simulator
DGPs. Given that none of these assumptions would hold in practice, we now turn to exploring a joint
training framework that learns simultaneously from both real and simulated samples.
4.4 The SimPONet Estimator
We first conduct a theoretical analysis to derive a generalization bound that characterizes the CATE
error as a function of the mismatch between the real and simulator distributions. This analysis forms
the basis for our proposed method, SimPONet , whose loss function is inspired by the bound.
Lemma 4. AssumeτisKτ-Lipschitz, and /tildewidefSand/tildewideτSare estimates from the simulator DGP obtained
fromtheoptimizationinEq. 1,2. Then,theCATEerrorontheestimates /hatwideftand/hatwideτadmitsthefollowing
bound:
Et
CATE (/hatwideft,/hatwideτ)≤[8Et
F+12dh(/hatwideτ,/tildewideτS)+12K2
τdx|t(/hatwideft,/tildewidefS
t)]+[12dz(τ,τS)+12K2
τdx|t(ft,fS
t)]
8Under review as submission to TMLR
wheredx|t,dz,dh(z)aredistancefunctionsinSec.3and Et
Fisthefactualloss. [ProofinAppendixA.5.2.]
The expressions in blue are constants that capture the discrepancy between real and simulated
distributionsandcannotbeminimized. Incontrast, theremainingtermscanbeminimizedbytraining
onDtrnandDsyn. As|Dtrn|approaches infinity, the factual error Et
Fcan be made to approach zero,
while the other minimizable distance terms act as regularizers. The term dh(/hatwideτ,/tildewideτS)can assist in
regularizing the outcome parameters /hatwideµt, whereasdx|t(/hatwideft,/tildewidefS
t)can aid in regularizing the parameters
of the causal representation extractor functions /hatwideft. This analysis leads to our proposed approach
SimPONet whose overall loss is as follows:
min
{/hatwideµt,/hatwideft}/summationdisplay
Dtrn/parenleftig
yi−/hatwideµti(/hatwidefti(xi))/parenrightig2
/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
Factual Loss on Dtrn+λf/summationdisplay
Dtrn∥/tildewidefS
ti(xi)−/hatwidefti(xi)∥2
2
/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
d(/tildewidefS
t,/hatwideft)regularizer+λτ/summationdisplay
Dsyn/summationdisplay
t∈{0,1}/parenleftig
τS
i−/hatwideτ(/tildewidefS
t(xS
i(t)))/parenrightig2
/bracehtipupleft /bracehtipdownright/bracehtipdownleft /bracehtipupright
τSregularizer on Dsyn
(3)
whereτS
i=yS
i(1)−yS
i(0)andλτ,λf>0are loss weights. /hatwideτ(•)=/hatwideµ1(•)−/hatwideµ0(•)denotes the estimated
CATE.
SimPONet relaxes the strict equality /hatwideft=/tildewidefS
tused byRealµSimf, and instead uses /tildewidefS
tas a regularizer,
while ensuring that /hatwideµtaccurately predicts the factual outcomes for instances in Dtrn. It also imposes
theτSloss on simulated instances to leverage any potential similarity between the true treatment
effect,τ, and the simulated treatment effect, τS. Furthermore, the τSloss is essential to prevent
degenerate solutions that would cause SimPONet to collapse to the RealµSimfestimator. This is
becauseapplyingregularizationsolelyon /hatwideftcandrivetheregularizer ||/hatwideft(x)−/tildewidefS
t(x)||2
2tozero, leading
to/hatwideft=/tildewidefS
t, while still minimizing the factual error Et
Fby updating/hatwideµtaccordingly. Consequently,
SimPONet would collapse into the RealµSimfestimator, making the τSloss critical in avoiding such
degeneracies.
Adjusting Loss Weights. SimPONet adjusts the loss weight λffor learning/hatwideftby comparing the
factual errors of the RealOnly model, which trains on X, with those of the RealµSimfmodel, trained
using simulated causal representations /tildewidefS
t(x). If RealOnly consistently outperforms RealµSimfin
factualerror,weinferthatthesimulatedrepresentationsmaynotgeneralizewelltotherealdistribution,
prompting SimPONet to reduceλf. By default, λfis set to 1; however, if RealµSimfexhibits a
notably higher factual error, SimPONet lowersλfto10−4.
In contrast, tuning λτrequiresτsupervision on real data, which is unavailable. Prior work (Curth
& van der Schaar, 2021; Nagalapatti et al., 2024b; Künzel et al., 2019) argue that while outcome
functionsµtcan be complex, the difference function τ=µ1−µ0is often simpler. For instance, if we
considerµS
t=µt+c(withc>0), we can make the factual outcomes to diverge arbitrarily while their
corresponding τandτSremain equal. Therefore, while comparing the factual errors between SimOnly
and RealOnly models to set λτis appealing, it maybe a poor choice in practice. So, SimPONet always
setsλτto its default 1.
We present the SimPONet ’s pseudocode in Appendix A.4.
9Under review as submission to TMLR
5 Experiments
We conduct experiments that are designed to address the following research questions:
RQ1How do different methods compare with varying discrepancies between real and simulator in
settings with closed form estimates; i.e., without errors due to finite-sample training?
RQ2 How does SimPONet compare to other SOTA baselines that assume pre-treatment covariates?
RQ3 What are the contributions of individual loss terms in SimPONet ?
RQ4 How does SimPONet fare against the baselines when µtexhibits complex non-linear behavior?
RQ5How do CATE methods perform when trained directly on (a) post-treatment covariates X, or
(b) pre-treatment Z, or (c) simulated causal representations /tildewidefSfrom Eq. 1?
5.1 Neural Architecture and Hyperparameters
For the Linear experiments in RQ1, we omit shared layers in Fig. 5, and set /hatwidef0and/hatwidef1asnx×nx
matrices, and /hatwideµ0and/hatwideµ1asnx×1vectors. For the real-world experiments in RQ2, with both ft,µtas
non-linear functions, we set /hatwideµ0and/hatwideµ1as 2-layer MLPs with hidden layers of 100 and 50 neurons. The
shared layers have 2 hidden layers with 50 and nxneurons, respectively. We impose the d(/hatwideft,/tildewidefS
t)loss
forSimPONet on outputs of the shared layers. For experiments in RQ4, we omit the shared layers
while setting /hatwideftas linear layer. But since µis non-linear, we use an MLP with one hidden layer of 50
neurons and ReLU activations for each /hatwideµt.
Hyperparameters: Weimplementedallbaselinesand SimPONet using jaxwithinCATENets(Curth
etal.,2021),astandardlibraryforbenchmarkingstate-of-the-artCATEestimationmethods. Toensure
consistency,weusedthesameMLParchitecture,learningrates,optimizers,andotherhyperparameters
as the default settings in CATENets for baseline approaches. The unique hyperparameters for
SimPONet arethelossweights λfandλτ. AsdescribedinSec. 4.4, SimPONet tunesλfbycomparing
the factual errors of the RealOnly and RealµSimfmodels, while λτis always set to 1. CATENets
applies early stopping based on factual error in the validation dataset, a common practice in CATE
training. To ensure a fair comparison, we maintained consistent training and validation splits across
all methods.
Assessing Statistical Significance: For CATE experiments, standard deviation is sometimes
misleading to comment on the statistical significance of empirical results as noted in (Curth et al.,
2021). So, for all experiments, we conduct a one-sided paired t-test with SimPONet as the baseline
and enclose p-values in brackets to indicate statistical significance. Lower p-values favor SimPONet .
5.2 RQ1: Assessing Baselines Under Settings Without Finite Training Sample Errors
To address RQ1, we consider a setting where both the real and simulator DGPs as shown in Fig. 1 are
linear. In particular, we generate the training datasets DtrnandDsynas follows: (1) Latent variables
z∈Rnzare sampled from distribution PZ. (2) Real and simulated covariates for a treatment tare
computed as gt(z)=zRtandgS
t(z)=zSt, where RtandStare invertible matrices. (3) Outcomes are
generated as µt(z)=z⊤wtandµS
t(z)=z⊤wS
t, wherewtandwS
tare vectors in Rnz. We consider two
datasets for RQ1: (1) Synthetic-Gaussian and (2) Real World-IHDP, differing in how Zis obtained.
In setting (1), z∈R10is sampled from a standard Gaussian N(0,1), while for (2), Zis taken from the
real-world IHDP dataset (Appendix A.7) as-is.
10Under review as submission to TMLR
Table 1: RQ1: In a linear DGP setting, we vary the gaps using γRford(f0,f1)in the first column, γRSfor
d(ft,fS
t), andγτford(τ,τS). “low” refers to 0.1 that simulates small distance, while “high” refers to 0.4. We
runallexperimentswithfivedifferentseedsandreport p-valuesofcomparingthemeanperformanceinbracket.
Synthetic-Gaussian Real World-IHDP
d(f0,f1)d(ft,fS
t)d(τ,τS)SimOnly RealOnly RealµSimfSimPONet SimOnly RealOnly RealµSimfSimPONet
0.00 high high 2.82 (0.27) 0.00 (1.00) 15.75 (0.01) 2.58 (0.00) 3.57 (0.11) 0.00 (1.00) 48.76 (0.05) 3.20 (0.00)
low low low 0.63 (0.00) 2.47 (0.02) 1.19 (0.01) 0.54 (0.00) 1.00 (0.44) 3.43 (0.02) 2.73 (0.00) 0.97 (0.00)
low low high 1.57 (0.16) 2.47 (0.08) 1.19 (0.83) 1.39 (0.00) 1.62 (0.26) 3.43 (0.04) 2.73 (0.02) 1.49 (0.00)
low high low 2.14 (0.22) 2.47 (0.00) 15.75 (0.01) 1.85 (0.00) 3.67 (0.31) 3.43 (0.48) 48.76 (0.05) 3.37 (0.00)
low high high 2.82 (0.26) 2.47 (0.56) 15.75 (0.01) 2.57 (0.00) 3.57 (0.11) 3.43 (0.39) 48.76 (0.05) 3.19 (0.00)
high low low 0.63 (0.00) 13.86 (0.02) 1.19 (0.01) 0.54 (0.00) 1.00 (0.47) 47.78 (0.06) 2.73 (0.00) 0.98 (0.00)
high low high 1.57 (0.16) 13.86 (0.03) 1.19 (0.83) 1.39 (0.00) 1.62 (0.27) 47.78 (0.06) 2.73 (0.02) 1.50 (0.00)
high high low 2.14 (0.21) 13.86 (0.03) 15.75 (0.01) 1.85 (0.00) 3.67 (0.31) 47.78 (0.06) 48.76 (0.05) 3.38 (0.00)
high high high 2.82 (0.26) 13.86 (0.04) 15.75 (0.01) 2.57 (0.00) 3.57 (0.11) 47.78 (0.06) 48.76 (0.05) 3.19 (0.00)
Now, to systematically control the real-simulator mismatch, we need means to vary the following
distances:d(R−1
0,R−1
1),d(R−1
t,S−1
t),andd(τ,τS). Weachievethisasfollows: (1)Initialize R−1
0,w0∼
N(0,1). (2)Toinjectadistance γR∈(0,0.5)between R−1
0andR−1
1,setR−1
1=(1−γR)R−1
0+γRN(0,1).
(3) Setw1∼γw0+(1−γ)N(0,1). We useγ=0.4in all experiments. (4) Similarly, inject a γRSgap
between R−1
tandS−1
t. (5) For treatment effect parameters wτ=w1−w0in the real DGP, we sample
its simulator counterpart with a gap γτaswS
τ=(1−γτ)wτ+γτN(0,1)and setwS
taccordingly.
In linear settings, the optimization problems for the CATE estimators SimOnly, RealOnly, and
RealµSimfadmitclosed-formsolutions. Weshowtheclosed-formsolutionsinTable7intheAppendix,
and a detailed derivation in Appendix A.6.
ForSimPONet ,aclosed-formsolutionisnotpossible,sowesolveittoalocaloptimumusingalternating
minimization over /hatwideµtand/hatwideft, with each alternating update in closed-form. We show the SimPONet ’s
update equations in Appendix A.6.4. In summary, the setting of RQ1 allows study of the impact of
varying discrepancies between the real and simulator distributions without approximation errors due
to finite training samples.
We show the results comparing SimPONet with the three baselines in Table 13where we observe:
(a) Across both synthetic and real-world settings, SimPONet achieves either the best or second-best
performance. The CATE error for SimPONet remains controlled primarily due to its ability to bound
errorsinthecounterfactualdistribution. (b)Incontrast,theRealOnlyand RealµSimfmodelsperform
well only under certain restrictive conditions favorable to them, providing zero error on the factual
distribution but very high counterfactual error, leading to poor CATE estimates.
5.3 RQ2: Comparing SimPONet with State-of-the-art CATE Baselines
We conduct experiments using semi-synthetic observational datasets commonly used to assess efficacy
of treatment effect estimation methods in the literature: the Infant Health Development Program
3Each entry in the table reports the CATE Error alongside its corresponding p-value as CATE Error ( p-value).
The p-value denotes the statistical significance of the hypothesis that SimPONet outperforms the baseline. We use a
one-sided paired t-test for this assessment. Smaller p-values indicate stronger evidence in favor of SimPONet . We show
thebest performing method in green, and the second best method in yellow across all our tables.
11Under review as submission to TMLR
(IHDP) and the Atlantic Causal Inference Conference (ACIC) datasets. These datasets contain
real-world pre-treatment covariates (Z). Please refer Appendix A.7 for more details on these datasets.
To align these datasets with our study, we apply RealNVP Normalizing Flows (Dinh et al., 2016)
to transform pre-treatment covariates Zinto post-treatment X. Flows are non-linear deep neural
networks that ensure invertibility of the covariate generating functions gt,gS
t. We consider randomly
initialized flows with two coupling layers. We used the flows g0,g1on real data, and two other distinct
flowsgS
0,gS
1to obtain covariates in synthetic data from Z. We borrow the real outcomes as-is from
the ground truth dataset. However, we synthesize simulator outcomes with a gap of γτas follows:
(1) sample wS
τ∈Rnz∼N(0,1)(2) setτS(z) =τ(z)+(σ(τ)·γτ·z⊤wS
τ), whereσ(τ)is the standard
deviation of CATE labels in the real dataset. Scaling by σ(τ)ensured comparability between τand
τS. Thus, when γτ=0,τ=τS; whenγτ=1,τis disparate from τS.
We evaluated SimPONet against various baselines from the well-known CATENets (Curth et al.,
2021), a benchmarking library for CATE estimation. Since the baseline methods are not designed to
extract the causal representations, we provided them with representations extracted by simulated
causal representation extractor /tildewidefS
t(x)as input for a fair comparison. Running these baselines with
post-treatment covariates Xdirectly as input yielded much poorer results as shown in Fig. 3. We also
compared SimPONet with SimOnly, RealOnly, and RealµSimfbaselines that we developed in our
theoretical analysis. We present the results in Table 2 for γτ=0.1, and defer the results for larger γτ
to Appendix 5.7. We make the following key observations:
IHDP ACIC-2 ACIC-7 ACIC-26
Dataset0123456Factual Errorsp=0.00p=0.19p=0.47p=0.08Comparing Factual Errors on Validation Data
RealOnly
RealSimf
Figure 2: Factual errors with p-values
shownabovebars. ForIHDP,RealOnly
consistently outperforms Real µSimf.(a)IHDP: This dataset contains 25 pre-treatment covariates,
19ofwhicharebinary. Contrastivetrainingstruggledtocapture
these binary features, causing RealµSimf, which uses/tildewidefS
t(x)as
input, to consistently underperform RealOnly, which directly
usesx. As shown in Fig 2, the p-value is zero for the IHDP
dataset,butsignificantlylargerfortheothers. Asaresult,weset
the weight of the regularizer d(/hatwideft,/tildewidefS
t), controlled by λf, to 1e-4
for IHDP, while keeping λfat its default value of 1 for ACIC.
Overall,SimPONet achieved the best performance.
(b)ACIC-2: This dataset is unique in that the true CATE,
τ, is constant across all individuals in the observational data, implying that its standard deviation
σ(τ)=0for real samples. As a result, our approach to synthesizing the simulated CATE, τS, given by
τS(z)=τ(z)+/parenleftbig
σ(τ)·γτ·z⊤wS
τ/parenrightbig
, yieldsτS(z)=τ(z)for allz. This leads to perfect alignment between
the synthetic and true CATE, causing SimOnly to outperform all other methods on this dataset.
Although SimPONet could have improved by assigning a higher weight to the τSregularizer, tuning
this weight would typically require supervision on τ, which we avoid.
(c)ACIC-7 and ACIC-26: The CATENets baselines significantly outperform the RealOnly model,
because of high-quality causal representations extracted by /tildewidefS
t. This is demonstrated by RealµSimf
outperforming RealOnly on factual error (see Fig. 2). In ACIC-7 and ACIC-26, SimPONet achieves
the best results by leveraging the closeness between τandτS. FlexTENet (Curth & van der Schaar,
2021), which shares parameters between /hatwideµ0and/hatwideµ1, and PairNet (Nagalapatti et al., 2024b), which
applies losses on pairs of close-by samples are strong contenders to SimPONet .
ACIC-All: The last column in the table presents results across all 77 seeds of the ACIC dataset.
SimPONet achieves the lowest mean CATE error overall. However, for certain seeds, SimPONet ’s
12Under review as submission to TMLR
Table 2: RQ2: Comparison of SimPONet with several pre-treatment baselines and post-treatment proposals.
p-values for paired t-tests against SimPONet are in brackets. Lower p-values indicate statistical significance.
SimPONet outperforms others overall, while SimOnly performs best on ACIC-2 since τ=τS.
Method IHDP ACIC-2 ACIC-7 ACIC-26 ACIC-All
RNet (Nie & Wager, 2021) 1.54 (0.00) 3.30 (0.00) 5.91 (0.04) 6.06 (0.18) 5.78 (0.03)
XNet (Künzel et al., 2019) 1.0 (0.00) 0.43 (0.15) 5.49 (0.17) 5.1 (0.38) 4.45 (0.41)
DRNet (Schwab et al., 2020) 0.96 (0.00) 0.24 (0.59) 5.53 (0.15) 5.08 (0.39) 4.45 (0.40)
CFRNet (Shalit et al., 2017) 0.96 (0.00) 0.36 (0.26) 5.55 (0.15) 5.09 (0.38) 4.67 (0.32)
FlexTENet (Curth & van der Schaar, 2021) 0.96 (0.00) 0.32 (0.32) 5.46 (0.19) 5.04 (0.40) 4.85 (0.37)
DragonNet (Shi et al., 2019) 0.96 (0.00) 0.29 (0.41) 5.57 (0.14) 5.09 (0.38) 4.60 (0.40)
IPW (Robins et al., 1994) 0.96 (0.00) 0.36 (0.24) 5.56 (0.15) 5.09 (0.38) 4.45 (0.40)
k-NN (Stuart, 2010) 0.96 (0.00) 0.33 (0.33) 5.48 (0.18) 5.13 (0.37) 4.44 (0.40)
PerfectMatch (Schwab et al., 2018) 0.98 (0.00) 0.56 (0.11) 5.75 (0.08) 5.13 (0.37) 4.56 (0.28)
StableCFR (Wu et al., 2023) 1.01 (0.00) 1.09 (0.03) 5.56 (0.15) 5.08 (0.43) 4.82 (0.14)
ESCFR (Wang et al., 2024) 0.96 (0.00) 0.27 (0.47) 5.55 (0.15) 5.79 (0.21) 4.73 (0.18)
PairNet (Nagalapatti et al., 2024b) 0.97 (0.00) 0.12 (0.85) 5.46 (0.23) 5.05 (0.37) 4.44 (0.41)
SimOnly 0.94 (0.00) 0.00 (0.98) 6.65 (0.00) 6.60 (0.12) 6.45 (0.02)
RealOnly 0.83 (0.13) 11.23 (0.01) 14.81 (0.05) 8.18 (0.01) 9.82 (0.00)
RealµSimf 0.96 (0.00) 0.17 (0.76) 5.57 (0.14) 5.09 (0.38) 4.52 (0.38)
SimPONet 0.79 (0.00) 0.26 (0.00) 5.04 (0.00) 4.67 (0.00) 4.36 (0.00)
Table 3: RQ3: Impact of regularizers. Here, −d(/hatwideft,/tildewidefS
t)represents our loss 3 with λf= 0, and−τSmeans
λτ=0. Anegativevalueimplies SimPONet withallregularizersoutperformstheablationwhereoneregularizer
is disabled.
IHDP - Linear ft, LinearµtGP - Linear ft, Non-Linear µt
d(f0,f1)d(ft,fS
t)d(τ,τS)−d(/hatwideft,/tildewidefS)−τS−d(/hatwideft,/tildewidefS)−τS
0.00 high high +1.29 (1.00) -1.07 (0.18) -0.55 (0.31) -0.62 (0.26)
high low low -0.64 (0.04) +0.01 (0.51) -0.29 (0.24) -0.04 (0.47)
high low high -0.40 (0.11) +0.00 (0.50) -0.42 (0.10) -0.19 (0.34)
high high low +1.74 (0.99) -0.03 (0.48) -0.66 (0.27) -0.71 (0.25)
high high high +1.30 (1.00) -0.03 (0.45) -0.72 (0.21) -0.97 (0.18)
CATE error remains comparable to baselines such as PairNet, k-NN, as indicated by them having
p-values close to 0.4. The RealOnly model consistently performs worse across all seeds due to the
covariate functions g0andg1producing disparate post-treatment covariates X0andX1when applied
toZ. Similarly, the SimOnly model suffers due to the distributional mismatch between the real and
simulator data.
5.4 RQ3: Ablation of SimPONet Losses
Weevaluatetheimpactofthe d(/hatwideft,/tildewidefS
t)andτSregularizersin SimPONet ’sobjective3. Weexperiment
with the Linear IHDP dataset (Sec. 5.2) and the Non-Linear Gaussian process dataset (Sec. 5.5).
For the Linear IHDP dataset, in the −τScase, we added an L2penalty on wtfor the alternating
minimization to work. Table 3 presents the difference in CATE errors of SimPONet and the ablation,
averaged over five seeds with p-values. A negative entry means SimPONet does better than the
ablation. We observe that τSloss is very effective since SimPONet outperforms the−τSin both
datasets. ForIHDP,removing d(/hatwideft,/tildewidefS
t)losshelps. Wecouldnotset λfweighttobesmallbecauseboth
RealOnly and RealµSimfachieved zero factual error. Despite this, SimPONet with both regularizers
comfortably outperformed the other proposals demonstrating it as a better candidate for our task.
13Under review as submission to TMLR
Table4: RQ4: ResultsforlinearcovariateandGP-basednonlinearoutcomefunctions. Weruneachexperiment
5timesandshowthe p-values. SimPONet outperformsothersinmanysettings. RealOnlyisastrongcontender.
d(f0,f1)d(ft,fS
t)d(τ,τS)SimOnly RealOnly RealµSimfSimPONet
0.00 high high 5.30 (0.09) 2.99 (0.11) 3.17 (0.09) 1.94 (0.00)
low low low 1.77 (0.15) 1.06 (0.73) 1.05 (0.77) 1.26 (0.00)
low low high 1.56 (0.08) 0.98 (0.65) 1.07 (0.44) 1.05 (0.00)
low high low 4.60 (0.04) 2.87 (0.07) 3.12 (0.04) 1.88 (0.00)
low high high 4.15 (0.04) 2.96 (0.02) 3.11 (0.01) 1.60 (0.00)
high low low 2.39 (0.14) 1.19 (0.68) 1.12 (0.77) 1.37 (0.00)
high low high 1.94 (0.11) 0.98 (0.83) 1.16 (0.58) 1.21 (0.00)
high high low 7.42 (0.09) 2.65 (0.38) 2.95 (0.25) 2.37 (0.00)
high high high 5.70 (0.07) 2.80 (0.17) 3.16 (0.09) 2.10 (0.00)
5.5 RQ4: Linear covariate function gand non-linear outcome function µ
Now, we consider a more complex setup where the covariate functions gtandgS
tremain linear, but
the outcome functions µtandµS
tare nonlinear in Z. In particular, we sample the outcomes yandyS
using Gaussian Processes (GPs) (Rasmussen & Williams, 2005). Let GP(0,Kγ)denote a GP with an
RBF kernel of width γ, so a higher γresults in a more complex function. To sample the µ0,µ1such
that their difference τhas a gapγ, we follow: (1) Sample τusing a GP: τ∼GP(0,Kγ). (2) Sample
µ0∼GP(0,K1). (3) Setµ1∼µ0+τ. As before, we set γ= 0.4. Now, to sample µS
0,µS
1such that
d(τ,τS)=γτ: (1) SetτS∼τ+GP(0,Kγτ). (2) Sample yS
0∼GP(0,K1). (3) SetyS
1=yS
0+τS.
We estimate/tildewidefSin Eq. 1 in closed-form, whereas we learn other parameters using gradient descent.
We show the results in Table 4 where we observe: (a) SimPONet outperforms the other baselines in
five out of nine settings (b) In alignment with our theory, RealµSimfperforms better than others
only whend(ft,fS
t)is small. In summary, when the properties of the underlying DGP are unclear,
SimPONet proves to be an effective approach for learning τ.
5.6 RQ5: Comparing CATE methods when trained on ZvsXvs/tildewidefS(X)
To address RQ5, we use the IHDP dataset to evaluate the baseline models when trained on post-
treatment covariates Xdirectly, and we compare these results with those from Table 2, where the
baselines were trained on simulated causal representations, /tildewidefS
t(x). We also evaluate the baselines
trained on pre-treatment Zto explicitly show the detrimental impact of post-treatment covariates on
the CATE error.
In addition, we extend Table 2 by considering non-invertible, non-linear transformations with Multi-
Layer Perceptrons (MLPs) on the IHDP dataset to assess the robustness of SimPONet and baselines
when the diffeomorphism assumption is violated. To this end, we used two-layer MLPs for gtandgS
t
to generate covariates from Z. We present the results in Fig. 3, and make the following observations:
In the pre-treatment setting, causal representation extraction is unnecessary, making simulator
supervision inconsequential; thus, we omit the four post-treatment CATE methods introduced in this
paper. For other baselines, Fig. 3 shows that they perform significantly worse with post-treatment X
thanwithpre-treatment Z,underscoringtheimportanceofcausalrepresentationrecovery. DragonNet
achieved the best performance with pre-treatment covariates.
14Under review as submission to TMLR
For Normalizing Flow-generated covariates, CATE error consistently decreased when baselines used
simulator-based causal representations, ˜St(X), rather than X, validating the utility of simulators in
extracting causal representations. However, the CATE error remains significantly higher compared
to using pre-treatment covariates Z, highlighting that simulators, while helpful, are not ideal and
exhibit a distributional gap between real and simulator distributions. This gap impacts all CATE
methods. Notably, SimPONet , specifically designed to leverage simulator supervision and incorporate
regularizers using simulator-generated data, achieves the best results.
In the MLP-based covariate experiments with non-invertible covariate functions g0,g1,SimPONet
consistently outperformed all baselines, exhibiting trends similar to those observed with Normalizing
Flow-generated covariates. This suggests that the diffeomorphism assumption, while necessary for our
theoretical results, may be inconsequential in practice.
RNet XNetDRNetCFRNet
FlexTENet DragonNetIPWk-NN
PerfectMatchPairNetSimOnly RealOnly
Real Simf
SimPONet0.250.500.751.001.251.501.752.00CATE ErrorInput Pre-T Z
Input  NF X
Input  NF fS
t(X)
Input MLP fS
t(X)
Figure 3: Comparing CATE errors under pre-treatment Z, and MLP, Normalizing flow generated
post-treatment covariates X.
5.7 Varying γτin Arbitrary DGP Experiment
The results of the varying γτexperiment are presented in Fig. 4, where we compare two approaches
that leverage simulator data during training: SimOnly and SimPONet . Across all γτgaps, we
observe that SimPONet consistently outperforms SimOnly in three out of four datasets, with ACIC-2
being the exception. This is expected, as ACIC-2 satisfies the condition τs=τ. The performance
gains ofSimPONet are particularly notable in the ACIC-7 and ACIC-26 datasets, where the CATE
error for SimOnly escalates significantly at larger γτvalues. The exact error values for these cases
are shown in the inset subplot at the top-right. These findings underscore our argument: while
SimOnlycanperformwellonsimulatorscloselyalignedwiththerealworld,itstruggleswithreal-world
simulators that diverge from reality. In contrast, SimPONet ’s adjustment strategies—enabled by
theoretically grounded regularizers derived from the CATE error analysis—yield much more reliable
CATE estimates.
5.8 On the Quality of ZExtracted by SimPONet
In this experiment, we evaluate the quality of representations learned by SimPONet . IfSimPONet ’s
regularizersinthelossesenabletherecoveryofrepresentationsidentifiableforCATE,thenaRealOnly
model trained on these representations should outperform the RealµSimfmodel trained on representa-
tions extracted using contrastive training on the simulator dataset. We focus on the Linear IHDP and
non-linear GP datasets, as they provide closed-form solutions for Objective 1, and and gives us a fine
15Under review as submission to TMLR
0.0 0.2 0.4 0.6 0.8 1.0
0246810CATE Error
Varying  that controls d(S,)
IHDP - Simonly
IHDP - SimPONet
ACIC-2 - Simonly
ACIC-2 - SimPONet
ACIC-7 - Simonly
ACIC-7 - SimPONet
ACIC-26 - Simonly
ACIC-26 - SimPONet01020304050
Figure 4: We varyγτ, which controls the gap between the synthetic CATE, τS, and the real CATE, τ. Each
dataset is represented by a distinct color, where the pale version of the color indicates SimOnly and the darker
version denotes SimPONet . For ACIC-7 and ACIC-26, as γτincreases, the CATE error grows significantly.
Therefore, we present these results as an inset figure in the top-right corner.
Table 5: RQ5: Evaluating RealµSimfperformance with Zfrom SimPONet ’s/hatwideftvs./tildewidefS
tobtained from Dsyn.
RealµSimfwith SimPONet ’s/hatwideftsignificantly outperforms in many settings indicating SimPONet extracts
betterZ.
IHDP - Linear ft, Linearµt GP - Linear ft, Non-Linear µt
d(f0,f1)d(ft,fS
t)d(τ,τS)RealµSimfRealµSimPONet fRealµSimfRealµSimPONet f
0.00 high high 48.76 (0.05) 3.28 (0.00) 3.17 (0.32) 2.67 (0.00)
low low low 2.73 (0.00) 0.97 (0.00) 1.05 (0.81) 1.55 (0.00)
low low high 2.73 (0.02) 1.49 (0.00) 1.07 (0.78) 1.55 (0.00)
low high low 48.76 (0.05) 3.48 (0.00) 3.12 (0.23) 2.53 (0.00)
low high high 48.76 (0.05) 3.21 (0.00) 3.11 (0.34) 2.73 (0.00)
high low low 2.73 (0.00) 0.98 (0.00) 1.12 (0.72) 1.29 (0.00)
high low high 2.73 (0.02) 1.49 (0.00) 1.16 (0.76) 1.42 (0.00)
high high low 48.76 (0.05) 3.37 (0.00) 2.95 (0.57) 3.11 (0.00)
high high high 48.76 (0.05) 3.23 (0.00) 3.16 (0.42) 2.97 (0.00)
grained control to set the gaps between real and simulated datasets and assess the performance across
many settings of these gaps. Specifically, we train the RealOnly model using Zextracted from /hatwideftvia
SimPONet , and call it as RealµSimPONet f, and compare it to RealµSimftrained from/tildewidefS. Results
in Table 5 show that RealµSimPONet fsignificantly outperforms the baseline RealµSimfacross many
DGP settings, with particularly strong results in the Linear IHDP case where p-values are consistently
small. This demonstrates that SimPONet effectively learns high-quality representations Z.
5.9 Sensitivity to Loss Weights
In this experiment, we analyze the sensitivity of SimPONet ’s performance to the loss weights λfand
λτin its objective function. Using the IHDP covariates, we conduct this analysis across the three
variants used in our study. For the Synthetic datasets, we set the real simulator gaps, as specified
in Tables 1 and ??, tohigh. In the Semi-Synthetic IHDP setting, we evaluate performance on five
randomly selected dataset versions. The results, summarized in Table 6, report the mean CATE
error along with its standard deviation across dataset seeds. All methods consistently performed
16Under review as submission to TMLR
Table 6: This table assesses the sensitivity of the loss weights on all three versions of the IHDP dataset
considered in our work – Synthetic Linear Sec. 5.2, Synthetic Non-Linear Sec. 5.5, and Semi-synthetic Sec. 5.3.
We consider nine different settings of the loss weights in SimPONet ’s objective 3. The table shows mean ±
standard deviation of the CATE Error.
λµλϕSynthetic Linear Synthetic Non-Linear Semi-Synthetic
0.10.1 3.46±0.91 4.23±2.21 0.72±0.19
0.10.5 3.42±0.84 3.55±1.21 0.70±0.19
0.11.0 3.43±0.78 3.40±1.15 0.71±0.20
0.50.1 3.41±0.90 4.06±2.21 0.74±0.19
0.50.5 3.38±0.88 3.32±1.06 0.73±0.19
0.51.0 3.37±0.82 3.23±1.00 0.71±0.20
1.00.1 3.38±0.86 3.99±2.17 0.71±0.20
1.00.5 3.39±0.87 3.24±1.02 0.72±0.19
1.01.0 3.38±0.85 3.14±0.93 0.71±0.21
poorly when the loss weights are small. This indicates tht the regularizers are important to impose on
post-treatment covariates. Across other settings, overall, we observe that SimPONet is sensitive to
the choice of hyperparameter settings in non-linear and semi-synthetic versions, and remains fairly
robust in the linear setting. However, tuning these hyperparameters is challenging in practice due to
the absence of counterfactual data in real observational datasets. Despite this sensitivity, SimPONet
outperforms achieves either comparable performance or manages to surpass the baseline methods
across different loss weight configurations.
6 Conclusion
This paper addressed the challenge of estimating treatment effects from post-treatment covariates a
setting not identifiable from observational data alone. We proposed to tackle this task using off-the-
shelf simulators that synthesize counterfactuals, in contrast to prior work that relied on real-world
counterfactuals, which limited their practical applicability. Our theoretical analysis established a
bound on the CATE error based on the distributional mismatch between real and simulated data.
Notable,oursisthefirstworktosystematicallyanalyzetheroleofsimulatorsinCATEestimation. We
introduced SimPONet , a framework that jointly learns from real and simulated samples to enhance
CATEestimatesbeyondwhatcouldbeachievedfromobservationaldataalone. Extensiveexperiments
across various DGPs demonstrated that SimPONet is a robust and effective method for estimating
CATE from post-treatment data.
References
Joshua Angrist. Estimating the labor market impact of voluntary military service using social security
data on military applicants, 1995.
Orley Ashenfelter. Estimating the effect of training programs on earnings. The Review of Economics
and Statistics , pp. 47–57, 1978.
17Under review as submission to TMLR
Philip Bachman, R Devon Hjelm, and William Buchwalter. Learning representations by maximizing
mutual information across views. Advances in neural information processing systems , 32, 2019.
Elias Bareinboim and Judea Pearl. Controlling selection bias in causal inference. In Artificial
Intelligence and Statistics , pp. 100–108. PMLR, 2012.
Elias Bareinboim and Jin Tian. Recovering causal effects from selection bias. In Proceedings of the
AAAI Conference on Artificial Intelligence , volume 29, 2015.
Nitay Calderon, Eyal Ben-David, Amir Feder, and Roi Reichart. DoCoGen: Domain counterfactual
generation for low resource domain adaptation. In Smaranda Muresan, Preslav Nakov, and Aline
Villavicencio (eds.), Proceedings of the 60th Annual Meeting of the Association for Computational
Linguistics (Volume 1: Long Papers) , pp. 7727–7746, Dublin, Ireland, May 2022. Association for
Computational Linguistics. doi: 10.18653/v1/2022.acl-long.533. URL https://aclanthology.
org/2022.acl-long.533 .
Vinod K Chauhan, Soheila Molaei, Marzia Hoque Tania, Anshul Thakur, Tingting Zhu, and David A
Clifton. Adversarial de-confounding in individualised treatment effects estimation. In International
Conference on Artificial Intelligence and Statistics , pp. 837–849. PMLR, 2023.
Zeming Chen, Qiyue Gao, Antoine Bosselut, Ashish Sabharwal, and Kyle Richardson. DISCO:
Distilling counterfactuals with large language models. In Anna Rogers, Jordan Boyd-Graber, and
NaoakiOkazaki(eds.), Proceedings of the 61st Annual Meeting of the Association for Computational
Linguistics (Volume 1: Long Papers) , pp. 5514–5528, Toronto, Canada, July 2023. Association for
Computational Linguistics. doi: 10.18653/v1/2023.acl-long.302. URL https://aclanthology.
org/2023.acl-long.302 .
Alexander Coppock. Avoiding post-treatment bias in audit experiments. Journal of Experimental
Political Science , 6(1):1–4, 2019.
JuanCorrea,JinTian,andEliasBareinboim. Generalizedadjustmentunderconfoundingandselection
biases. In Proceedings of the AAAI Conference on Artificial Intelligence , volume 32, 2018.
Alicia Curth and Mihaela van der Schaar. On inductive biases for heterogeneous treatment effect
estimation. Advances in Neural Information Processing Systems , 34:15883–15894, 2021.
Alicia Curth and Mihaela van der Schaar. In search of insights, not magic bullets: Towards demystifi-
cationofthemodelselectiondilemmainheterogeneoustreatmenteffectestimation. In International
Conference on Machine Learning, ICML 2023, 23-29 July 2023, Honolulu, Hawaii, USA , 2023.
Alicia Curth, David Svensson, Jim Weatherall, and Mihaela van der Schaar. Really doing great at
estimating cate? a critical look at ml benchmarking practices in treatment effect estimation. In
Thirty-fifth conference on neural information processing systems datasets and benchmarks track
(round 2) , 2021.
Chiara Dalla Man, Robert A Rizza, and Claudio Cobelli. Meal simulation model of the glucose-insulin
system.IEEE Transactions on biomedical engineering , 54(10):1740–1749, 2007.
Nikhil J Dhinagar, Sophia I Thomopoulos, Emily Laltoo, and Paul M Thompson. Counterfactual mri
generation with denoising diffusion models for interpretable alzheimer’s disease effect detection.
bioRxiv, pp. 2024–02, 2024.
18Under review as submission to TMLR
Laurent Dinh, Jascha Sohl-Dickstein, and Samy Bengio. Density estimation using real nvp. arXiv
preprint arXiv:1605.08803 , 2016.
Tanay Dixit, Bhargavi Paranjape, Hannaneh Hajishirzi, and Luke Zettlemoyer. CORE: A retrieve-
then-edit framework for counterfactual data generation. In Yoav Goldberg, Zornitsa Kozareva, and
Yue Zhang (eds.), Findings of the Association for Computational Linguistics: EMNLP 2022 , pp.
2964–2984, Abu Dhabi, United Arab Emirates, December 2022. Association for Computational
Linguistics. doi: 10.18653/v1/2022.findings-emnlp.216. URL https://aclanthology.org/2022.
findings-emnlp.216 .
Zijun Gao and Yanjun Han. Minimax optimal nonparametric estimation of heterogeneous treat-
ment e ffects. In H. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, and H. L in (eds.), Ad-
vances in Neural Information Processing Systems , volume 33, pp. 21751–21762. Curran Asso-
ciates, Inc., 2020. URL https://proceedings.neurips.cc/paper_files/paper/2020/file/
f75b757d3459\c3e93e98ddab7b903938-Paper.pdf .
Muhammad Waleed Gondal, Manuel Wuthrich, Djordje Miladinovic, Francesco Locatello, Martin
Breidt, Valentin Volchkov, Joel Akpo, Olivier Bachem, Bernhard Schölkopf, and Stefan Bauer. On
the transfer of inductive bias from simulation to the real world: a new disentanglement dataset.
Advances in Neural Information Processing Systems , 32, 2019.
YuGu,JianweiYang,NaotoUsuyama,ChunyuanLi,ShengZhang,MatthewPLungren,JianfengGao,
and Hoifung Poon. Medjourney: Counterfactual medical image generation by instruction-learning
from multimodal patient journeys. 2023.
Negar Hassanpour and Russell Greiner. Counterfactual regression with importance sampling weights.
InIJCAI, pp. 5880–5887, 2019a.
Negar Hassanpour and Russell Greiner. Learning disentangled representations for counterfactual
regression. In International Conference on Learning Representations , 2019b.
JONATHAN HOMOLA, MIGUEL M. PEREIRA, and MARGIT TAVITS. Fixed effects and post-
treatment bias in legacy studies. American Political Science Review , 118(1):537–544, 2024. doi:
10.1017/S0003055423001351.
Qiang Huang, Defu Cao, Yi Chang, and Yan Liu. Extracting post-treatment covariates for heteroge-
neous treatment effect estimation. 2023.
Stefano M Iacus, Gary King, and Giuseppe Porro. Causal inference without balance checking:
Coarsened exact matching. Political analysis , 20(1):1–24, 2012.
GuillaumeJeanneret,LoïcSimon,andFrédéricJurie. Diffusionmodelsforcounterfactualexplanations.
InProceedings of the Asian Conference on Computer Vision , pp. 858–876, 2022.
Yonghan Jung, Jin Tian, and Elias Bareinboim. Learning causal effects via weighted empirical risk
minimization. Advances in neural information processing systems , 33:12697–12709, 2020.
Nathan Kallus. Deepmatch: Balancing deep covariate representations for causal inference using
adversarial training. In International Conference on Machine Learning , pp. 5067–5077. PMLR,
2020.
19Under review as submission to TMLR
Prabhjot Kaur, Samira Taghavi, Zhaofeng Tian, and Weisong Shi. A survey on simulators for testing
self-driving cars. In 2021 Fourth International Conference on Connected and Autonomous Driving
(MetroCAD) , pp. 62–70. IEEE, 2021.
Edward H Kennedy. Towards optimal doubly robust estimation of heterogeneous causal effects. arXiv
preprint arXiv:2004.14497 , 2020.
Gary King. A hard unsolved problem? post-treatment bias in big social science questions. In Hard
Problems in Social Science” Symposium, April , volume 10, 2010.
Sören R Künzel, Jasjeet S Sekhon, Peter J Bickel, and Bin Yu. Metalearners for estimating heteroge-
neous treatment effects using machine learning. Proceedings of the national academy of sciences ,
116(10):4156–4165, 2019.
Oran Lang, Ilana Traynis, and Yun Liu. Explaining counterfactual images. Nature Biomedical
Engineering , 2023. URL https://rdcu.be/dwVKK .
Francesco Locatello, Stefan Bauer, Mario Lucic, Gunnar Raetsch, Sylvain Gelly, Bernhard Schölkopf,
andOlivierBachem. Challengingcommonassumptionsintheunsupervisedlearningofdisentangled
representations. In international conference on machine learning , pp. 4114–4124. PMLR, 2019a.
Francesco Locatello, Michael Tschannen, Stefan Bauer, Gunnar R ¨¨ätsch, Bernhard Schölkopf,
and Olivier Bachem. Disentangling factors of variations using few labels, 2019b. URL https:
//openreview.net/forum?id=SkGy6hjvPE .
Nishtha Madaan, Inkit Padhi, Naveen Panwar, and Diptikalyan Saha. Generate your counterfactuals:
Towardscontrolledcounterfactualgenerationfortext. In AAAIConferenceonArtificialIntelligence ,
2020. URL https://api.semanticscholar.org/CorpusID:228063841 .
Lokesh Nagalapatti, Guntakanti Sai Koushik, Abir De, and Sunita Sarawagi. Learning recourse on
instanceenvironmenttoenhancepredictionaccuracy. In AdvancesinNeuralInformationProcessing
Systems, 2022.
Lokesh Nagalapatti, Akshay Iyer, Abir De, and Sunita Sarawagi. Continuous treatment effect
estimation using gradient interpolation and kernel smoothing. Proceedings of the AAAI Conference
on Artificial Intelligence , 38(13):14397–14404, Mar. 2024a. doi: 10.1609/aaai.v38i13.29353. URL
https://ojs.aaai.org/index.php/AAAI/article/view/29353 .
Lokesh Nagalapatti, Pranava Singhal, Avishek Ghosh, and Sunita Sarawagi. Pairnet: Training with
observed pairs to estimate individual treatment effect. In Forty-first International Conference on
Machine Learning, ICML 2024, Vienna, Austria, July 21-27, 2024 . OpenReview.net, 2024b. URL
https://openreview.net/forum?id=o5SVr80Rgg .
Lizhen Nie, Mao Ye, Qiang Liu, and Dan Nicolae. Vcnet and functional targeted regularization for
learning causal effects of continuous treatments. arXiv preprint arXiv:2103.07861 , 2021.
XinkunNieandStefanWager. Quasi-oracleestimationofheterogeneoustreatmenteffects. Biometrika ,
108(2):299–319, 2021.
Michal Ozery-Flato, Pierre Thodoroff, and Tal El-Hay. Adversarial balancing for causal inference.
ArXiv, abs/1810.07406, 2018.
20Under review as submission to TMLR
Yushu Pan and Elias Bareinboim. Counterfactual image editing. arXiv preprint arXiv:2403.09683 ,
2024.
Nick Pawlowski, Daniel Coelho de Castro, and Ben Glocker. Deep structural causal models for
tractable counterfactual inference. Advances in neural information processing systems , 33:857–869,
2020.
J. Pearl and Cambridge University Press. Causality: Models, Reasoning, and Inference . Cambridge
University Press, 2000. ISBN 9780521773621. URL https://books.google.co.in/books?id=
wnGU_TsW3BQC .
Judea Pearl. Conditioning on post-treatment variables. Journal of Causal Inference , 3(1):131–137,
2015.
Carl Edward Rasmussen and Christopher K. I. Williams. Gaussian Processes for Machine Learning
(Adaptive Computation and Machine Learning) . The MIT Press, 2005. ISBN 026218253X.
Marcel Robeer, Floris Bex, and Ad Feelders. Generating realistic natural language counterfactuals. In
Marie-Francine Moens, Xuanjing Huang, Lucia Specia, and Scott Wen-tau Yih (eds.), Findings
of the Association for Computational Linguistics: EMNLP 2021 , pp. 3611–3625, Punta Cana,
Dominican Republic, November 2021. Association for Computational Linguistics. doi: 10.18653/
v1/2021.findings-emnlp.306. URL https://aclanthology.org/2021.findings-emnlp.306 .
James M Robins, Andrea Rotnitzky, and Lue Ping Zhao. Estimation of regression coefficients when
some regressors are not always observed. Journal of the American statistical Association , 89(427):
846–866, 1994.
Paul R Rosenbaum and Donald B Rubin. The central role of the propensity score in observational
studies for causal effects. Biometrika , 70(1):41–55, 1983.
Axel Sauer and Andreas Geiger. Counterfactual generative networks. In International Conference on
Learning Representations , 2021. URL https://openreview.net/forum?id=BXewfAYMmJw .
Patrick Schwab, Lorenz Linhardt, and Walter Karlen. Perfect match: A simple method for learning
representations for counterfactual inference with neural networks. arXiv preprint arXiv:1810.00656 ,
2018.
Patrick Schwab, Lorenz Linhardt, Stefan Bauer, Joachim M Buhmann, and Walter Karlen. Learning
counterfactual representations for estimating individual dose-response curves. In Proceedings of the
AAAI Conference on Artificial Intelligence , volume 34, pp. 5612–5619, 2020.
Uri Shalit, Fredrik D. Johansson, and David Sontag. Estimating individual treatment effect: general-
ization bounds and algorithms, 2016. URL https://arxiv.org/abs/1606.03976 .
Uri Shalit, Fredrik D Johansson, and David Sontag. Estimating individual treatment effect: general-
ization bounds and algorithms. In International Conference on Machine Learning , pp. 3076–3085.
PMLR, 2017.
Claudia Shi, David Blei, and Victor Veitch. Adapting neural networks for the estimation of treatment
effects.Advances in neural information processing systems , 32, 2019.
21Under review as submission to TMLR
Elizabeth A Stuart. Matching methods for causal inference: A review and a look forward. Statistical
science: a review journal of the Institute of Mathematical Statistics , 25(1):1, 2010.
Jayaraman Thiagarajan, Vivek Sivaraman Narayanaswamy, Deepta Rajan, Jia Liang, Akshay Chaud-
hari, and Andreas Spanias. Designing counterfactual generators using deep model inversion.
Advances in Neural Information Processing Systems , 34:16873–16884, 2021.
Julius Von Kügelgen, Yash Sharma, Luigi Gresele, Wieland Brendel, Bernhard Schölkopf, Michel
Besserve, and Francesco Locatello. Self-supervised learning with data augmentations provably
isolates content from style. Advances in neural information processing systems , 34:16451–16467,
2021.
Clinton J. Wang, Natalia S. Rost, and Polina Golland. Spatial-intensity transform gans for high
fidelity medical image-to-image translation. In Anne L. Martel, Purang Abolmaesumi, Danail
Stoyanov, Diana Mateus, Maria A. Zuluaga, S. Kevin Zhou, Daniel Racoceanu, and Leo Joskowicz
(eds.),Medical Image Computing and Computer Assisted Intervention – MICCAI 2020 , pp.749–759,
Cham, 2020. Springer International Publishing. ISBN 978-3-030-59713-9.
Hao Wang, Jiajun Fan, Zhichao Chen, Haoxuan Li, Weiming Liu, Tianqiao Liu, Quanyu Dai, Yichao
Wang, Zhenhua Dong, and Ruiming Tang. Optimal transport for treatment effect estimation.
Advances in Neural Information Processing Systems , 36, 2024.
Anpeng Wu, Kun Kuang, Ruoxuan Xiong, Bo Li, and Fei Wu. Stable estimation of heterogeneous
treatment effects. In International Conference on Machine Learning , pp. 37496–37510. PMLR,
2023.
JinyuXie. Simglucosev0.2.1(2018)[Online],2018. URL https://github.com/jxx123/simglucose .
Accessed on September 25, 2023.
Liuyi Yao, Sheng Li, Yaliang Li, Mengdi Huai, Jing Gao, and Aidong Zhang. Representation learning
for treatment effect estimation from observational data. Advances in Neural Information Processing
Systems, 31, 2018.
Jinsung Yoon, James Jordon, and Mihaela Van Der Schaar. Ganite: Estimation of individualized
treatment effects using generative adversarial nets. In International Conference on Learning
Representations , 2018.
YaoZhang,AlexisBellot,andMihaelaSchaar. Learningoverlappingrepresentationsfortheestimation
of individualized treatment effects. In International Conference on Artificial Intelligence and
Statistics , pp. 1005–1014. PMLR, 2020.
Yi-FanZhang,HanlinZhang,ZacharyC.Lipton,LiErranLi,andEricP.Xing. Exploringtransformer
backbones for heterogeneous treatment effect estimation, 2022. URL https://arxiv.org/abs/
2202.01336 .
Roland S. Zimmermann, Yash Sharma, Steffen Schneider, Matthias Bethge, and Wieland Brendel.
Contrastive learning inverts the data generating process. 139:12979–12990, 2021. URL http:
//proceedings.mlr.press/v139/zimmermann21a.html .
22Under review as submission to TMLR
A Appendix / supplemental material
A.1 Code
We have released the code in the anonynous URL https://anonymous.4open.science/r/
catenets-simponet/README.md . We have also uploaded the code along with our submission.
A.2 Learning Counterfactual Simulators
Herewediscusspriorworksthattraingenerativemodelsforsynthesizingcounterfactuals. Ingeneral,to
obtaincounterfactualsintherealdistribution,weneedtofollowthreesteps(Pawlowskietal.,2020): (a)
abduction ,invertingXtoobtainZ,(b)action,applyinganewtreatment,and(c) prediction generating
a newXunder the new treatment. These steps require prior knowledge of the DGP specifications,
which are often difficult to define and cannot be learned from observational data alone (Pawlowski
et al., 2020). Consequently, many methods bypass the principled approach and use pre-trained models
like Diffusion models and Large Language models to generate pseudo counterfactuals from a related
syntheticdomain. Suchsimulatorsareproposedacrossvariousmodalities,includingimages(Pawlowski
et al., 2020; Gu et al., 2023; Thiagarajan et al., 2021; Pan & Bareinboim, 2024; Sauer & Geiger, 2021;
Jeanneret et al., 2022), text (Madaan et al., 2020; Calderon et al., 2022; Chen et al., 2023; Dixit et al.,
2022; Robeer et al., 2021), and healthcare (Lang et al., 2023; Wang et al., 2020; Dhinagar et al., 2024).
Prior research (Gondal et al., 2019) shows that while such simulated data is not directly usable for
downstream tasks, they provide strong inductive biases that transfer well to the real distribution. Our
method can incorporate any such counterfactual generators as simulators, provided they contribute to
learning causal representations that are predictive of CATE.
A.3 SimPONet Architecture
Shared
Layers
Figure 5: SimPONet ’s model architecture.We present an overview of the Sim-
PONetmodel architecture in Figure
5. Our model has four primary pa-
rameters:/hatwidef0and/hatwidef1for extracting
causal representations, and /hatwideµ0and/hatwideµ1
forpredictingoutcomes. Sharedlayers
project/hatwidef0and/hatwidef1intoacommonspace.
A.4 SimPONet Pseudocode
Here, we present the SimPONet pseudocode. The steps involved in our algorithm are:
line 1First we use the simulator dataset Dsynto apply contrastive losses on the counterfactual
covariatesusingEq. 1. Thisoptimizationgivesusa Zextractorinthesimulatordistribution,
which we denote as /tildewidefS
t.
line 2We partition the training dataset into train, validation dataset using stratified split based
onT. We then initialize the loss weigts λf,λτto their defaults.
lines 4,5 Wenowdecideuponthelossweight λf. Todoso, wetrainRealOnlyand RealµSimfmodels.
We then assess the factual prediction errors of these models on the validation split of the
training dataset. If RealOnly model performs much better than the RealµSimfmodel, it
means that the /tildewidefS
tobtained from line2 above is of inferior quality. Therefore, we scale λf
that regularizes the SimPONet ’s/hatwideftbased on/tildewidefS
tto a very small value, 1e-4.
23Under review as submission to TMLR
line 6We can now apply gradient descent algorithm on the SimPONet ’s objective in Eq. 3 to train
the/hatwideµt,/hatwideftparameters of the model.
Algorithm 1 SimPONet Algorithm
Require: Observational Data Dtrn:{(xi,ti,yi)}, Simulator Data Dsyn:{(xS
i(0),xS
i(1),yS
i(0),yS
i(1))}
1:Let{/hatwidef(•,t)}←Zextraction functions, and {/hatwideµ(•,t)}←outcome functions for t=0,1.
2:Let/tildewidefS
t←Eq. 1 (Minimize Contrastive loss on Dsyn)
3:SetDtrn,Dval←split(Dtrn,pc=0.3, stratify=T), and init default hyperparameters λf,λτ←1,1
4:RealOnly←min{/hatwideµ,/hatwidef}/summationtext
Dtrn(yi−/hatwideµti(/hatwidefti(xi)))2; RealµSimf←min/hatwideµ/summationtext
Dtrn(yi−/hatwideµti(/tildewidefS
ti(xi)))2
5:Setλf←1e-4 if FactualErr (RealOnly,Dval)>>FactualErr (RealµSimf,Dval)
6:{/hatwideft,/hatwideµt}←Eq. 3 (perform gradient descent on SimPONet ’s objective using Dtrn,Dsynwhile early stopping
using Factual Error on Dval)
7:Return{/hatwideft,/hatwideµt}fort=0,1
We present the pseudocode for SimPONet in Alg. 1.
A.5 Theoretical Analysis
In this section, we present the proofs for our theoretical results.
A.5.1 Proof of Lemma 2
The CATE error is related to the factual and counterfactual error as: Et
CATE≤2Et
F+2Et
CF
Proof. We decompose the CATE error into factual and counterfactual estimation error as follows:
Et
CATE =/integraldisplay
x∈X[τX(x,t)−/hatwiderτX(x,t)]2P(x|t)dx=/integraldisplay
x∈X[τ(ft(x))−/hatwideτ(/hatwideft(x))]2P(x|t)dx
=/integraldisplay
x∈X[(µ1(ft(x))−µ0(ft(x)))−(/hatwideµ1(/hatwideft(x))−/hatwideµ0(/hatwideft(x)))]2P(x|t)dx
=/integraldisplay
x∈X[(µ1(ft(x))−/hatwideµ1(/hatwideft(x)))−(µ0(ft(x))−/hatwideµ0(/hatwideft(x)))]2P(x|t)dx
Lett′=1−tdenote the counterfactual treatment. We can then rewrite the above expression as:
Et
CATE =/integraldisplay
x∈X[(µt(ft(x))−/hatwideµt(/hatwideft(x)))−(µt′(ft(x))−/hatwideµt′(/hatwideft(x)))]2P(x|t)dx
Now using the inequality (a−b)2≤2a2+2b2, we can separate the factualandcounterfactual terms:
Et
CATE≤2/integraldisplay
x∈X[µt(ft(x))−/hatwideµt(/hatwideft(x))]2P(x|t)dx+2/integraldisplay
x∈X[µt′(ft(x))−/hatwideµt′(/hatwideft(x))]2P(x|t)dx
=2Et
F+2Et
CF
24Under review as submission to TMLR
A.5.2 Recovery of fSupto a diffeomorphic transformation
Lemma5. As|Dsyn|→∞, contrastivetrainingwithpairedcovariatesrecovers /tildewidefS
t=h◦fS
twhilepaired
outcome supervision recovers /tildewideτS=τS◦h−1wherehis a diffeomorphic transformation. Moreover, when
the latent spaceZ⊂S(nz−1)(unit-norm hypersphere in Rnz),his a rotation transform by Extended
Mazur-Ulam Theorem as shown in (Zimmermann et al., 2021) (Proposition 2).
Proof.Theorem 4.4 of (Von Kügelgen et al., 2021) shows that contrastive training with covariate
pairs{xS
i(0),xS
i(1)}recoversZupto a diffeomorphic transformation h, i.e. for the simulator DGP
our estimate ˆzi=/tildewidefS(xS
i(t),t) =h(zi) =h(fS(xS
i(t),t),∀t∈T. Moreover for unit-norm latent
representations,Z⊂Sdz−1, (Zimmermann et al., 2021) show that his an isometric (norm-preserving)
function and therefore, a rotation transform by an extension of Mazur-Ulam Theorem. Mazur-Ulam
Theorem states that any smooth, invertible and isometric function is necessarily affine. Moreover, in
our setting, the norm of zas well as ˆzis always one and thus, his necessarily a rotation. Therefore, we
recover/tildewidefS=h◦fSupto a rotation of the true inverse map fSwith sufficient paired samples from the
simulator.
Next, we recover /tildewideτSfrom the following minimisation:
/tildewideτS=argmin
/hatwideτSExS/bracketleftig
/hatwideτS(/tildewidefS(xS(t),t))−τS(fS(xS(t),t))/bracketrightig2
=argmin
/hatwideτSEz/bracketleftbig
/hatwideτS(h(z))−τS(z)/bracketrightbig2
The above optimization gives /tildewideτS=τS◦h−1and hence we recover the CATE function τSfor the
simulator DGP composed with h−1.
Proof of Lemma 4.
AssumeτisKτ-Lipschitz, and /tildewidefSand/tildewideτSare estimates from the simulator DGP obtained from the
optimization in Eq. 1, 2. Then, the CATE error on the estimates /hatwideftand/hatwideτadmits the following bound:
Et
CATE (/hatwideft,/hatwideτ)≤[8Et
F+12dh(/hatwideτ,/tildewideτS)+12K2
τdx|t(/hatwideft,/tildewidefS
t)]+[12dz(τ,τS)+12K2
τdx|t(ft,fS
t)]
wheredx|t,dz,dh(z)are distance functions in Sec. 3 and Et
Fis the factual loss.
Proof.Wenowconstructatupperboundon counterfactual errorEt
CFthatreliesonbothobservational
data and simulator estimates to motivate the SimPONet objective:
Et
CF=/integraldisplay
x∈X[µt′(ft(x))−/hatwideµt′(/hatwideft(x))]2P(x|t)dx
=/integraldisplay
x∈X[(µt′(ft(x))−µt(ft(x)))−(/hatwideµt′(/hatwideft(x))−/hatwideµt(/hatwideft(x)))+µt(ft(x))−/hatwideµt(/hatwideft(x))]2P(x|t)dx
=/integraldisplay
x∈X[(21t=0−1)·(τ(ft(x))−/hatwideτ(/hatwideft(x)))+µt(ft(x))−/hatwideµt(/hatwideft(x))]2P(x|t)dx
25Under review as submission to TMLR
Where 1t=0=1whent=0and zero otherwise, and thus, (21t=0−1)=±1adjusting the sign of CATE
terms. Now we utilise the inequality (a+b+c)2≤3(a2+b2+c2)to obtain:
Et
CF=/integraldisplay
x∈X[(21t=0−1)·(τ(ft(x))−/hatwideτ(h◦ft(x))+/hatwideτ(h◦ft(x))−/hatwideτ(/hatwideft(x)))+µt(ft(x))−/hatwideµt(/hatwideft(x))]2P(x|t)dx
≤3/integraldisplay
x∈X[τ(ft(x))−/hatwideτ(h◦ft(x))]2P(x|t)dx+3/integraldisplay
x∈X[/hatwideτ(h◦ft(x))−/hatwideτ(/hatwideft(x))]2P(x|t)dx
+3/integraldisplay
x∈X[µt(ft(x))−/hatwideµt(/hatwideft(x))]2P(x|t)dx
=3/integraldisplay
z∈Z[τ(z)−/hatwideτ(h(z))]2P(z|t)dz+3/integraldisplay
x∈X[/hatwideτ(h(ft(x)))−/hatwideτ(/hatwideft(x))]2P(x|t)dx+3Et
F
Herehdenotes the unknown rotation transformation that relates the estimated simulator functions
(/tildewidefS,/tildewideτS)with the ground-truth simulator functions (fS,τS)as shown in Lemma 5. Let Kτbe the
Lipschitz constant for /hatwideτ. We can bound the second term in the above expression as follows:
Et
CF≤3/integraldisplay
z∈Z[τ(z)−/hatwideτ(h(z))]2P(z|t)dz+3K2
τ/integraldisplay
x∈X||h(ft(x))−/hatwideft(x)||2P(x|t)dx+3Et
F
=3dz(τ,/hatwideτ◦h)+3K2
τdx|t(h◦ft,/hatwideft)+3Et
F
Now we can add and subtract simulator function estimates to bound the two distance terms as follows:
Et
CF≤3/integraldisplay
z∈Z[τ(z)−τS(z)+τS(z)−/hatwideτ(h(z))]2P(z|t)dz
+3K2
τ/integraldisplay
x∈X||h(ft(x))−h(fS
t(x))+h(fS
t(x))−/hatwideft(x)||2P(x|t)dx+3Et
F
≤6/integraldisplay
z∈Z[τ(z)−τS(z)]2P(z|t)dz+6/integraldisplay
z∈Z[τS(z)−/hatwideτ(h(z))]2P(z|t)dz
+6K2
τ/integraldisplay
x∈X||h(ft(x))−h(fS
t(x)||2P(x|t)dx+6K2
τ/integraldisplay
x∈X||h(fS
t(x))−/hatwideft(x)||2P(x|t)dx+3Et
F
=6dz(τ,τS)+6dz(/hatwideτ◦h,τS)+6K2
τdx|t(h◦ft,h◦fS
t)+6K2
τdx|t(/hatwideft,h◦fS
t)+3Et
F
Now,usingLemma5,wecanrewrite τS=/tildewideτS◦hinthesecondterm. Thus, dz(/hatwideτ◦h,τS)=dz(/hatwideτ◦h,/tildewideτS◦h).
Now making use of Definition 2, we can rewrite this as dh(z)(/hatwideτ,/tildewideτS)which is a distance function defined
on the space of rotated latents h(z). We also rewrite h◦fSas/tildewidefSin the fourth term.
Moreover,dx|t(h◦ft,h◦fS
t)=dx|t(ft,fS
t)sincehis a rotation transform and preserves the distance
between any two vectors. Thus, ||ft(x)−fS
t(x)||2=||h◦ft(x)−h◦fS
t(x)||2. Combining these results,
we can evaluate the above bound to the following:
26Under review as submission to TMLR
Et
CF≤[6dh(z)(/hatwideτ,/tildewideτS)+6K2
τdx|t(/hatwideft,/tildewidefS
t)+3Et
F]+[6dz(τ,τS)+6K2
τdx|t(ft,fS
t)]
A.6 Linear DGP Derivation
WederiveexpressionsforCATEestimates /hatwiderτX(x,t)aswellasEt
CATEforeachofourproposedestimators
in the linear setting below. Note that ground truth CATE τX(x,t) =xR−1
t(w1−w0). We consider
factual treatment t=1to illustrate the errors.
A.6.1 SimOnly
For SimOnly, we use ˆR−1
t=S−1
tand ˆwt=wS
twhich are obtained by training on simulator data. Thus,
the CATE estimate /hatwiderτX(x∗,t)=x∗S−1
t(wS
1−wS
0). The CATE error on a sample x∗, with treatment
t=1is given by [/hatwiderτX(x∗,1)−τX(x∗,1)]2=[(x∗(S−1
1(wS
1−wS
0)−R−1
1(w1−w0))]2
A.6.2 RealOnly
For RealOnly, the factual objective Et
F=||xˆR−1
tˆwt−y||2
2=||xˆR−1
tˆwt−xR−1
twt||2
2. Thus, the closed
form solution of the estimator ˆR−1
tˆwt=R−1
twt,∀t∈T. Since we can’t decouple the terms ˆR−1
tand ˆwt,
the CATE estimate is given by /hatwiderτX(x∗,t)=x∗ˆR−1
1ˆw1−x∗ˆR−1
0ˆw0=x∗R−1
1w1−x∗R−1
0w0.
CATE error on sample x∗with treatment t= 1is given by [/hatwiderτX(x∗,1)−τX(x∗,1)]2= [(x∗R−1
1w1−
x∗R−1
0w0)−xR−1
1(w1−w0)]2=[x(R−1
1−R−1
0)w0]2
A.6.3 Real µSimf
ForRealµSimf, we first set ˆR−1
t=S−1
twhich is obtained by training on simulator data. Next,
we train ˆwton the factual objective: ||xˆR−1
tˆwt−xR−1
twt||2
2=||xS−1
tˆwt−xR−1
twt||2
2. This, gives
us a closed form solution for the minimising ˆwt=StR−1
twt. The CATE estimate /hatwiderτX(x∗,t) =
x∗S−1
t(ˆw1−ˆw0) =x∗S−1
t(S1R−1
1w1−S0R−1
0w0). Fixing treatment t= 1, this simplifies further:
/hatwiderτX(x∗,1) =x∗S−1
1(S1R−1
1w1−S0R−1
0w0) =x∗(R−1
1w1−S−1
1S0R−1
0w0). CATE Error is given
by[/hatwiderτX(x∗,1)−τX(x∗,1)]2= [x∗(R−1
1w1−S−1
1S0R−1
0w0)−x∗R−1
1(w1−w0)]2= [x∗R−1
1w0−
x∗S−1
1S0R−1
0w0]2=[x∗(R−1
1−S−1
1S0R−1
0)w0]2
Table 7: This table presents the predicted CATE and the corresponding CATE errors obtained from the three
CATE proposals computed analytically for a test instance x⋆observed under treatment 1.
Method Estimate for CATE /hatwiderτX(x⋆,1)CATE Error [/hatwiderτX(x⋆,1)−τ(x⋆,1)]2
SimOnly x⋆S−1
1wS
τ/bracketleftbig
x⋆/parenleftbig
R−1
1wτ−S−1
1wS
τ/parenrightbig/bracketrightbig2
RealOnly x⋆/parenleftbig
R−1
1w1−R−1
0w0/parenrightbig /bracketleftbig
x⋆(R−1
0−R−1
1)w0/bracketrightbig2
RealµSimfx⋆S−1
1S1R−1
1w1−x⋆S−1
1S0R−1
0w0/bracketleftbig
x⋆(R−1
1−S−1
1S0R−1
0)w0/bracketrightbig2
A.6.4 SimPONet
We train both ˆR−1
t,ˆwton the following objective jointly:
L({ˆR−1
t,ˆwt}t=0,1)=/bracketleftigg/summationdisplay
t=0,1||xˆR−1
tˆwt−xR−1
twt||2
2+λf/summationdisplay
t=0,1||xˆR−1
t−xS−1
t||2
F+λτ||z( ˆw1−ˆw0)−z(w1−w0)||2
2/bracketrightigg
27Under review as submission to TMLR
Here, z=xS
t′S−1
t′arethelatentsforsimulatedcovariates xS
t′(whichareidentifiablefrom Dsyn). Dueto
the joint nature of this optimisation, it is not possible to derive closed form solutions for the optimum.
However, one can compuet gradients of the objective with respect to ˆR−1
tand ˆwtseparately. This,
gives us an alternating minimisation algorithm with closed form updates.
∂L
∂ˆR−1
t=∂
∂ˆR−1
t/bracketleftig
||xˆR−1
tˆwt−y||2
2+λf||xˆR−1
t−xS−1
t||2
F/bracketrightig
=2xTxˆR−1
t( ˆwtˆwtT+λfI)−2xTyˆwt+−2λfxTxS−1
t
Setting the derivative to zero, we obtain the following update rule:
ˆR−1
t←(x†yˆwt+λfS−1
t)·( ˆwtˆwtT+λfI)−1
where x†=(xTx)−1xTis the pseudoinverse of x.
∂L
∂ˆwt=∂
∂ˆwt/bracketleftig
||xˆR−1
tˆwt−y||2
2+λτ||z( ˆwt−ˆwt′)−(yS
1−yS
0)||2
2/bracketrightig
=2(ˆzTˆz) ˆwt−2ˆzTy+2λτ(zTzˆwt−zT(zˆwt′+(yS
1−yS
0)))
=2[(ˆzTˆz)+λτ(zTz)] ˆwt−2(ˆzTy+λτzT(zˆwt′+(yS
1−yS
0)))
Where ˆz=xˆR−1
t. Setting the derivative to zero, we obtain the following update rule:
ˆwt←((ˆzTˆz)+λτ(zTz))−1·(ˆzTy+λτzT(zˆwt′+(yS
1−yS
0)))
ForSimPONet , we perform alternating updates of ˆwtand ˆR−1
tfixing the other estimate.
A.7 Summary of Datasets
IHDP.TheInfantHealthandDevelopmentProgram(IHDP)isarandomizedcontrolledtrialdesigned
to assess the impact of physician home visits on the cognitive test performance of premature infants.
The dataset exhibits selection bias due to the deliberate removal of non-random subsets of treated
individuals from the training data. Since outcomes are observed for only one treatment, we generate
both observed and counterfactual outcomes using a synthetic outcome generation function based on
the original covariates for both treatments, making the dataset suitable for causal inference.
The IHDP dataset includes 747 subjects and 25 variables. While the original dataset discussed
in (Shalit et al., 2017) had 1000 versions, our work uses a smaller version with 100 iterations, aligning
with the CATENets benchmark. Each version varies in the complexity of the assumed outcome
generation function, treatment effect heterogeneity, etc. As outlined in (Curth et al., 2021), reporting
the standard deviation of performance across the 100 different seeds is inappropriate. Therefore, we
calculatep-valuesthroughpairedt-testsbetweenourmethod( SimPONet )andotherbaselinemethods,
usingSimPONet as the baseline for all experiments. We follow setting D of the IHDP dataset as
mentioned in (Curth & van der Schaar, 2021) where response surfaces are modified to suppress the
extremely high variance of potential outcomes in certain versions of the IHDP dataset.
ACIC.The Atlantic Causal Inference Conference (ACIC) competition dataset (2016)4consists of 77
datasets, all containing the same 58 covariates derived from the Collaborative Perinatal Project. Each
4https://jenniferhill7.wixsite.com/acic-2016/competition
28Under review as submission to TMLR
Table 8: Effect of varying training sizes on CATE using the IHDP dataset. We experiment with training
proportions of 10%, 25%, 50%, and 75% of the full training set. Results demonstrate how the performance of
SimPONet and baseline methods evolves with varying amounts of training data.
Training Percentage 0.10 0.25 0.50 0.75
RNet 3.08 (0.08) 2.52 (0.07) 2.30 (0.12) 2.30 (0.14)
XNet 2.43 (0.09) 1.90 (0.12) 1.16 (0.19) 1.10 (0.35)
DRNet 3.28 (0.04) 2.01 (0.03) 1.05 (0.40) 1.05 (0.44)
CFRNet 1.41 (0.03) 1.06 (0.21) 0.95 (0.59) 1.02 (0.50)
FlexTENet 2.97 (0.08) 2.33 (0.07) 1.04 (0.40) 1.03 (0.49)
DragonNet 3.48 (0.04) 2.02 (0.04) 0.97 (0.53) 1.02 (0.50)
IPW 3.44 (0.03) 1.74 (0.06) 0.94 (0.60) 1.03 (0.49)
NearNeighbor 2.10 (0.19) 1.65 (0.05) 2.65 (0.11) 1.07 (0.47)
PerfectMatch 3.44 (0.03) 2.54 (0.03) 3.32 (0.01) 1.05 (0.45)
PairNet 1.64 (0.13) 1.18 (0.11) 1.09 (0.30) 1.09 (0.36)
SimOnly 1.45 (0.23) 1.45 (0.07) 1.45 (0.15) 1.45 (0.04)
RealOnly 2.28 (0.13) 2.92 (0.07) 0.97 (0.54) 0.86 (0.75)
RealµSimf 3.35 (0.03) 2.01 (0.04) 1.07 (0.31) 1.02 (0.25)
SimPONet 1.01 (0.00) 0.93 (0.00) 0.95 (0.00) 0.87 (0.00)
dataset simulates binary treatment assignments and continuous outcome variables, with variations in
the complexity of the treatment assignment mechanism, treatment effect heterogeneity, the ratio of
treated to control observations, overlap between treatment and control groups, dimensionality of the
confounder space, and the magnitude of the treatment effect.
Alldatasetssharecommoncharacteristics,suchasindependentandidenticallydistributedobservations
conditional on covariates, adherence to the ignorability assumption (selection on observables with
all confounders measured and no hidden bias), and the presence of non-true confounding covariates.
Of the 77 datasets, we selected a subset of three: versions 2, 7, and 26, aligning with the CATENets
benchmark. These versions present non-linear covariate-to-outcome relationships and maximum
variabilityintreatmenteffectheterogeneity. Version2,notably,exhibitsnoheterogeneity,meaningthe
treatment effect is constant across all individuals. However, accurately estimating outcome differences
even for this version is challenging due to the inherent noise in potential outcome realizations in the
dataset.
A.8 Experiments with Limited Training Data
In this experiment, we evaluate the performance of CATE methods with varying training sizes. We
use 10 randomly selected dataset versions of the IHDP dataset. For each version, the methods are
trained using 10%, 25%, 50%, and 75% of the training data. Importantly, the simulator dataset is
not subsampled, so the SimOnly model maintains the same CATE error across all training sizes. The
results are presented in Table 8. At extremely low training sizes (10%), SimPONet achieves the lowest
CATE error with a significant margin over all baselines. With 25% of the training data, the baseline
methods improve, but SimPONet continues to deliver the best CATE error. At 50% training size, the
baselines further improve and perform comparably to SimPONet . WhileSimPONet ’s CATE error
29Under review as submission to TMLR
increases slightly in this setting, it remains close, trailing the best-performing baseline by only 0.01.
Finally, at 75% training size, SimPONet ’s CATE error decreases significantly, while many baselines
plateauinperformance. Overall, SimPONet demonstratesexceptionalrobustnessinestimatingCATE,
particularly in limited training data scenarios.
30Under review as submission to TMLR
A.9 Table of Symbols
Symbol Definition
XReal post-treatment covariates: Random Variable
YReal outcomes: Random Variable
XSSimulator post-treatment covariates: Random Variable
YSSimulator outcomes: Random Variable
TTreatment: Random Variable
ZLatent (unobserved) pre-treatment representations: Random Variable
DtrnObservational training dataset from Real DGP
DsynCounterfactual dataset from Simulator DGP
DtstTest dataset from Real DGP
x,xS,z,t,y,ySRealisations of random variables X,XS,Z,T,Y,YSrespectively
XSpace of post-treatment covariate values: Set
TSpace of treatment values: Set ={0,1}
ZSpace of latents: Set
YSpace of outcomes: Set
nz,nxDimensions of vector spaces in which Z,Xlie
Yi(t)Potential outcome for ithunit under treatment t
Xi(t)Potential post-treatment covariate for ithunit under treatment t
gtMapping fromZ∝⇕⊣√∫⊔≀→X, transforms latents to real post-treatment covariates under t
gS
tMapping fromZ∝⇕⊣√∫⊔≀→X, transforms latents to simulated post-treatment covariates under t
ftMapping fromX∝⇕⊣√∫⊔≀→Z, transforms real post-treatment covariates under tto latents
fS
tMappingX∝⇕⊣√∫⊔≀→Z, transforms simulated post-treatment covariates under tto latents
PZProbability distribution of latents Z
µtOutcome function for real data under t
µS
tOutcome function for simulated data under t
τConditional Average Treatment Effect for real data, µ1−µ0, MappingZ∝⇕⊣√∫⊔≀→Y
τSConditional Average Treatment Effect for simulated data, µS
1−µS
0, MappingZ∝⇕⊣√∫⊔≀→Y
◦Composition of functions
τX(x,t)Conditional Average Treatment Effect for real data, τ◦ft(x), MappingX×T∝⇕⊣√∫⊔≀→Y
τS
X(xS,t)Conditional Average Treatment Effect for simulated data, τS◦fS
t(xS), MappingX×T∝⇕⊣√∫⊔≀→Y
hDiffeomorphic transformation, arises due to contrastive learning
SdUnit-norm hypersphere of dimension d, Subset of R(d+1)
dx|tExpected squared-distance between two functions on P(X|T), see Section 3 for definition
dzExpected squared-distance between two functions on PZ, see Section 3 for definition
dh(z)dzunder transformation honz, see Section 3 for definition
sim(•,•)Cosine similarity
/hatwideftEstimate for ft
/hatwidefS
tEstimate for fS
t
/hatwideµtEstimate for µt
/hatwideµS
tEstimate for µS
t
/tildewidefS
tEstimate for fS
trecovered from contrastive learning
/tildewideµS
tEstimate for µS
ton recovering Simulator DGP
ECATECATE estimation error
Et
CATECATE estimation error on covariates xunder treatment t
Et
FFactual error on treatment tsamples
Et
CFCounterfactual error on treatment tsamples
KµLipschitz constant for µt,/hatwideµt
KτLipschitz constant for τ,/hatwideτ
KµSLipschitz constant for µS
t,/hatwideµS
t,/tildewideµS
t
KτSLipschitz constant for τS,/hatwideτS,/tildewideτS
Rtgtfor linear DGP: Matrix
StgS
tfor linear DGP: Matrix
wtµtfor linear DGP: Vector
wS
tµS
tfor linear DGP: Vector
wττfor linear DGP: Vector
wS
ττSfor linear DGP: Vector
31