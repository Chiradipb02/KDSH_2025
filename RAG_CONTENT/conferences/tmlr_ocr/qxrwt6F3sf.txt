Published in Transactions on Machine Learning Research (04/2023)
PAC-Bayes Generalisation Bounds for Heavy-Tailed Losses
through Supermartingales
Maxime Haddouche maxime.haddouche@inria.fr
Inria, University College London and Université de Lille
Benjamin Guedj benjamin.guedj@inria.fr
Inria and University College London
Reviewed on OpenReview: https: // openreview. net/ forum? id= qxrwt6F3sf
Abstract
While PAC-Bayes is now an established learning framework for light-tailed losses ( e.g., sub-
gaussian or subexponential), its extension to the case of heavy-tailed losses remains largely
uncharted and has attracted a growing interest in recent years. We contribute PAC-Bayes
generalisation bounds for heavy-tailed losses under the sole assumption of bounded variance
of the loss function. Under that assumption, we extend previous results from Kuzborskij and
Szepesvári (2019). Our key technical contribution is exploiting an extention of Markov’s
inequality for supermartingales. Our proof technique uniﬁes and extends diﬀerent PAC-
Bayesian frameworks by providing bounds for unbounded martingales as well as bounds for
batch and online learning with heavy-tailed losses.
1 Introduction
PAC-Bayes learning is a branch of statistical learning theory aiming to produce (tight) generalisation guar-
antees for learning algorithms, and as a byproduct leads to designing new eﬃcient learning procedures by
minimising such guarantees. Generalisation bounds are helpful for understanding how a learning algorithm
may perform on future similar batches of data. Since its emergence in the late 1990s, PAC-Bayes theory (see
the seminal works of Shawe-Taylor and Williamson, 1997; McAllester, 1998; 1999; 2003; Catoni, 2003; 2007)
has revealed powerful enough to explain the generalisation abilities of learning algorithms which output
distributions over the predictors space (a particular case being when the output is a Dirac mass on a single
predictor) from which our predictors of interest are designed. We refer to the recent surveys from Guedj
(2019); Alquier (2021) for an overview on PAC-Bayes.
At ﬁrst, PAC-Bayes theory was mainly focused on classiﬁcation tasks (see Seeger, 2002; Langford and
Schapire, 2005; Catoni, 2007) but has quickly been generalised to any bounded loss function in regression
(seee.g., Maurer,2004;Germainetal.,2009;2016). PAC-Bayeslearningcoversabroadscopeofdomainsand
tools,frominformationtheory(Kakadeetal.,2008;WuandSeldin,2022)tostatisticallearning(Catoni,2003;
2007), convexoptimisation(Thiemannetal.,2017), Bernstein-typeconcentrationinequalities(Tolstikhinand
Seldin, 2013; Mhammedi et al., 2019), margins (Biggs and Guedj, 2022a; Biggs et al., 2022) and martingales
(Seldin et al., 2011; 2012a;b), to name but a few.
From a practical perspective, the above led to generalisations guarantees for PAC-Bayes-inspired neural
networks (NN): a promising line of work initiated by Dziugaite and Roy (2017) and pursued further by
Letarte et al. (2019); Rivasplata et al. (2019); Pérez-Ortiz et al. (2021); Biggs and Guedj (2021); Perez-
Ortiz et al. (2021a;b); Biggs and Guedj (2022b), among others, established NN architectures enjoying tight
generalisation guarantees, turning PAC-Bayes into a powerful tool to handle complex neural structures ( e.g.,
Chérief-Abdellatif et al., 2022).
1Published in Transactions on Machine Learning Research (04/2023)
These encouraging breakthroughs gave rise to several initiatives to extend PAC-Bayes beyond the bounded
losses assumption which is limiting in practice. Indeed, the goal is to make PAC-Bayes able to provide
eﬃciency guarantees to any learning algorithm attached to a loss function. For instance, consider a NN
trained to solve regression problems without constraints on the training domain. Several works already
proposed routes to overcome the boundedness constraint: Catoni (2004, Chapter 5) already proposed PAC-
Bayes bounds for the classiﬁcation tasks and regressions ones with quadratic loss under a subexponential
assumption. This technique has later been exploited in Alquier and Biau (2013) for the single-index model,
and by Guedj and Alquier (2013) for nonparametric sparse additive regression, both under the assumption
that the noise is subexponential. However all these works are dealing with light-tailed losses. Alquier
and Guedj (2018); Holland (2019); Kuzborskij and Szepesvári (2019); Haddouche et al. (2021) proposed
extensions beyond light-tailed losses. Our work stands in the continuation of this spirit while developing and
exploiting a novel technical toolbox. To better highlight the novelty of our approach, we ﬁrst present the
two classical building blocks of PAC-Bayes.
1.1 Understanding PAC-Bayes: a celebrated route of proof
1.1.1 Two essential building blocks for a preliminary bound
In PAC-Bayes, we typically assume access to a non-negative loss function /lscript(h,z)taking as argument a
predictorh∈Handdataz∈Z(thinkofzasapairinput-output (x,y)forsupervisedlearningproblems,oras
a single datum xin unsupervised learning). We also assume access to a m-sized sample S= (z1,...,zm)∈Zm
of data on which we will learn a meaningful posterior distribution QonH, from a prior P(or reference
measure–see e.g., Guedj,2019foradiscussionontheterminologyofprobabilitydistributionsinPAC-Bayes).
To do so, PAC-Bayesian proofs are built upon two cornerstones. The ﬁrst one is the change of measure
inequality (Csiszár, 1975; Donsker and Varadhan, 1975; Dupuis and Ellis, 2011 – see also Banerjee, 2006;
Guedj, 2019 for a proof).
Lemma 1.1 (Change of measure inequality) .For any measurable function ψ:H→Rand any distributions
Q,PonH:
Eh∼Q[ψ(h)]≤KL(Q,P) + log ( Eh∼P[exp(ψ(h))]),
with KLdenoting the Kullback-Leibler divergence.
The change of measure inequality is then applied to a certain function fm:Zm×H→Rof the data and a
candidate predictor: for all posteriors Q,
Eh∼Q[fm(S,h)]≤KL(Q,P) + log ( Eh∼P[exp(fm(S,h))]). (1)
To deal with the random variable X(S) :=Eh∼P[exp(fm(S,h))], our second building block is Markov’s
inequality/parenleftBig
P(X >a )≤E[X]
a/parenrightBig
which we apply for a ﬁxed δ∈]0,1[onX(S)witha=ES[X(S)]/δ. Taking
the complementary event gives that for any m, with probability at least 1−δover the sample S,X(S)≤
ES[X(S)]/δ, thus:
Eh∼Q[fm(S,h)]≤KL(Q,P) + log(1/δ) + log ( Eh∼PES[exp(fm(S,h))]). (2)
1.1.2 From preliminary to complete bounds
From the preliminary result of Eq. (2), there exists several ways to obtain PAC-Bayesian generalisation
bounds, all being tied to speciﬁc choices of fand the assumptions on the dataset S. However they all
rely on the control of an exponential moment implied by Markov’s inequality: this is a strong constraint
which has been at the heart of the classical assumption appearing in PAC-Bayes learning. For instance,
the celebrated result of McAllester (1999), tightened by Maurer (2004), exploits in particular, a data-free
prior, an iid assumption on Sand a light-tailed loss function. Most of the existing results stand with those
assumptions (see e.g., Catoni, 2007; Germain et al., 2009; Guedj and Alquier, 2013; Tolstikhin and Seldin,
2Published in Transactions on Machine Learning Research (04/2023)
2013; Guedj and Robbiano, 2018; Mhammedi et al., 2019; Wu and Seldin, 2022). Indeed, in many of these
works, a boundedness assumption on the loss is used but in many cases, it can be relaxed to subgaussiannity
without loss of generality. Catoni (2004) extended PAC-Bayes learning to the subexponential case. Many
works tried to mitigate at least one of the following three assumptions.
•Data-free priors. With an alternative set of techniques, Catoni (2007) obtained bounds with
localised ( i.e., data-dependent) priors. More recently, Lever et al. (2010); Parrado-Hernández et al.
(2012); Lever et al. (2013); Oneto et al. (2016); Dziugaite and Roy (2017); Mhammedi et al. (2019)
also obtained PAC-Bayes bound with data-dependent priors.
•The iid assumption on S.The work of Fard and Pineau (2010) established links between rein-
forcement learning and PAC-Bayes theory. This naturally led to the study of PAC-Bayesian bound
for martingales instead of iid data (Seldin et al., 2011; 2012a;b).
•Light-tailed loss. PAC-Bayes bounds for heavy-tailed losses ( i.e., without subgaussian or subex-
ponential assumptions) have been studied. Audibert and Catoni (2011) provide PAC-Bayes bounds
for least square estimators with heavy-tailed random variables. Their results was suboptimal with
respect to the intrinsic dimension and was followed by further works from Catoni and Giulini (2017)
and Catoni (2018). More recently, this question has been adressed in the works of Alquier and Guedj
(2018); Holland (2019); Kuzborskij and Szepesvári (2019); Haddouche et al. (2021), extending PAC-
Bayes to heavy-tailed losses under additional technical assumptions.
Several questions then legitimately arise.
Can we avoid these three assumptions simultaneously? The answer is yes: for instance the work of
Rivasplata et al. (2020) proposed a preliminary PAC-Bayes bound holding with none of the three assump-
tions listed above. Building on their theorem, Haddouche and Guedj (2022) only exploited a bounded loss
assumption to derive a PAC-Bayesian framework for online learning, requiring no assumption on data and
allowing data (history in their context)-dependent priors.
Can we obtain PAC-Bayes bounds without the change of measure inequality? Yes, for instance
Alquier and Guedj (2018) proposed PAC-Bayes bounds involving f-divergences and exploiting Holder’s
inequality instead of Lemma 1.1. More recently, Picard-Weibel and Guedj (2022) developed a broader
discussion about generalising the change of measure inequality for a wide range of f-divergences. We note
also that Germain et al. (2009) proposed a version of the classical route of proof stated above avoiding the
use of the change of measure inequality. This comes at the cost of additional technical assumptions (see
Haddouche et al., 2021, Theorem 1 for a statement of the theorem in a proper measure-theoretic framework).
Can we avoid Markov’s inequality? We mentioned above that several works avoided the change of
measure inequality to obtain PAC-Bayesian bounds, but can we do the same with Markov’s inequality? This
point is interesting as avoiding Markov allow us to avoid assumptions such as sub-gaussiannity to provide
PAC-Bayes bound. The answer is yes but this is a rare breed. To the best of our knowledge, only two
papers are explicitly not using Markov’s inequality: Kakade et al. (2008) obtained a PAC-Bayes bound
using results on Rademacher complexity based on the McDiarmid concentration inequality, and Kuzborskij
and Szepesvári (2019) exploited a concentration inequality from De la Peña et al. (2009), up to a technical
assumptions to obtain results for unbounded losses. Both of this works did not required a bound on an
exponential moment to hold.
1.2 Originality of our approach
Avoiding Markov’s inequality appears challenging in PAC-Bayes but leads to fruitful results as those in
Kuzborskij and Szepesvári (2019).
In this work, we exploit a generalisation of Markov’s inequality for supermartingales: Ville’s inequality (as
noticed by Doob 1939). This result has, to our knowledge, never been used in PAC-Bayes before.
3Published in Transactions on Machine Learning Research (04/2023)
Lemma 1.2 (Ville’s maximal inequality for supermartingales) .Let(Ft)be a ﬁltration and (Zt)a non-
negative super-martingale satisfying Z0= 1a.s. IfZtis adapted to FtandE[Zt|Ft−1]≤Zt−1a.s.,t≥1,
then, for any 0<δ< 1, it holds
P/parenleftbig
∃T≥1 :ZT>δ−1/parenrightbig
≤δ.
Proof.We apply the optional stopping theorem (Durrett, 2019, Thm 4.8.4) with Markov’s inequality deﬁning
the stopping time i= inf{t>1:Zt>δ−1/bracerightbig
so that
P/parenleftbig
∃t≥1 :Zt>δ−1/parenrightbig
=P/parenleftbig
Zi>δ−1/parenrightbig
≤E[Zi]δ≤E[Z0]δ≤δ.
A major interest of Ville’s result is that it holds for a countable sequence of random variables simultaneously.
This point is new in PAC-Bayes as it will allow us to obtain bounds holding for a countable (not necessarily
ﬁnite) dataset S= (zi)i≥1.
On which supermartingale do we apply Ville’s bound ? To fully exploit Lemma 1.2, we now take a
countable dataset S= (zi)i≥1∈Zm. Recall that, because we use the change of measure inequality, we have
to deal with the following exponential random variable appearing in Eq. (1) for any m≥1:
Zm:=Eh∼P[exp(fm(S,h))].
Our goal is to choose a sequence of functions fmsuch that (Zm)mis a supermartingale. A way to do so
comes from Bercu and Touati (2008).
Lemma 1.3. Let(Mm)be a locally square-integrable martingale with respect to the ﬁltration (Fm). For all
η∈Randm≥0, one has:
E/bracketleftbigg
exp/parenleftbigg
η∆Mm−η2
2(∆[M]m+ ∆/angbracketleftM/angbracketrightm)/parenrightbigg
|Fm−1/bracketrightbigg
≤1,
where ∆Mm=Mm−Mm−1,∆[M]m= ∆M2
mand∆/angbracketleftM/angbracketrightm=E/bracketleftbig
∆M2
m|Fm−1/bracketrightbig
.
We deﬁne Vm(η) = exp/parenleftBig
ηMm−η2
2([M]m+/angbracketleftM/angbracketrightm)/parenrightBig
.Then, for all η∈R,(Vm(η))is a positive super-
martingale with E[Vm(η)]≤1where [M]m(h) :=/summationtextm
i=1∆[M]m,/angbracketleftM/angbracketrightm(h) :=/summationtextm
i=1∆/angbracketleftM/angbracketrightm.
In the sequel, this lemma will be helpful to design a supermartingale ( i.e., to choose a relevant fmfor any
m) without further assumption.
1.3 Contributions and outline
By avoiding Markov, a key message of (Kuzborskij and Szepesvári, 2019) is that, for learning problems
with independent data, PAC-Bayes learning only requires the control of order 2 moment on losses to be
used with convergence guarantees. This is strictly less restrictive than the classical subgaussian/subgamma
assumptions appearing in the major part of the literature.
We successfully prove this fact remains even for non-independent data: we only need to control order 2 (con-
ditional) moments to perform PAC-Bayes learning. Furthermore, our proof technique is general enough to
encompass two diﬀerent PAC-Bayesian framework: PAC-Bayes for martingales (Seldin et al., 2011; 2012a;b)
and Online PAC-Bayes learning (Haddouche and Guedj, 2022). Thus, our main contributions are twofold.
•We provide a novel PAC-Bayesian bound holding for data-free priors and unbounded martingales.
From this, we recover in PAC-Bayes bounds for unbounded losses and iid data as a signiﬁcant
particular case.
•We extend the Online PAC-Bayes framework of Haddouche and Guedj (2022) to the case of un-
bounded losses.
4Published in Transactions on Machine Learning Research (04/2023)
More precisely, Sec. 2.1 contains our novel PAC-Bayes bound for unbounded martingales and Sec. 2.3 con-
tains an immediate corollary for learning theory with iid data. Our second contribution lies in Sec. 3 and
extend Online PAC-Bayes theory to the case of unbounded losses. We eventually apply our main result for
martingales in Sec. 4 to the setting of multi-armed bandit. Doing so, we provably extend a result of Seldin
et al. (2012a) to the case of unbounded rewards.
Appendix A gathers more details on PAC-Bayes, we draw in Appendix B a detailed comparison between our
new results and a few classical ones. We show that adapting our bounds to the assumptions made in those
papers allows to recover similar or improved bounds. We defer to Appendix C the proofs of Secs. 2.3 and 4.
2 A PAC-Bayesian bound for unbounded martingales
2.1 Main result
A line of work led by Seldin et al. (2011; 2012a;b) provided PAC-Bayes bounds for almost surely bounded
martingales. We provably extend the remits of their result to the case of unbounded martingales.
Framework Our framework is close to the one of Seldin et al. (2012a): we assume having access to a
countable dataset S= (zi)i≥1∈with no restriction on the distribution of S(in particular the zican depend
on each others). We denote for any m,Sm:= (zi)i=1..mthe restriction of Sto itsmﬁrst points. (Fi)i≥0is
a ﬁltration adapted to S. We denote for any i∈N Ei−1[.] :=E[.|Fi−1]. We also precise the space Hto be
an index (or a hypothesis) space, possibly uncountably inﬁnite. Let {X1(S1,h),X2(S2,h),···:h∈H}be
martingale diﬀerence sequences, meaning that for any m≥1,h∈H,Em−1[Xm(Sm,h)] = 0.
For anyh∈H, letMm(h) =/summationtextm
i=1Xi(Si,h)be martingales corresponding to the martingale diﬀerence
sequences and we deﬁne, as in Bercu and Touati (2008), the following
[M]m(h) :=m/summationdisplay
i=1Xi(Si,h)2,
/angbracketleftM/angbracketrightm(h) =m/summationdisplay
i=1Ei−1/bracketleftbig
Xi(Si,h)2/bracketrightbig
.
For a distribution QoverHdeﬁne weighted averages of the martingales with respect to QasMm(Q) =
Eh∼Q[Mm(h)](similar deﬁnitions hold for [M]m(Q),/angbracketleftM/angbracketrightm(Q)).
Main result. We now present the main result of this section where we succesfully avoid the boundedness
assumption on martingales. This relaxation comes at the cost of additional variance terms [M]m,/angbracketleftM/angbracketrightm.
Theorem 2.1. For any data-free prior P∈M+
1(H), anyλ>0, any collection of martingales (Mm(h))m≥1
indexed byh∈H, the following holds with probability 1−δover the sample S= (zi)i∈N, for allm∈N/{0},
Q∈M+
1(H):
|Mm(Q)|≤KL(Q,P) + log(2/δ)
λ+λ
2([M]m(Q) +/angbracketleftM/angbracketrightm(Q)).
Proof lies in Sec. 2.2.
Analysis of the bound. This theorem involves several terms. The change of measure inequality introduces
the KL divergence term, the approximation term log(2/δ)comes from Ville’s inequality (instead of Markov
in classical PAC-Bayes). Finally, the terms [M]m(Q),/angbracketleftM/angbracketrightm(Q)come from our choice of supermartingale
as suggested by Bercu and Touati (2008). The term [M]m(Q)can be interpreted as an empirical variance
term while/angbracketleftM/angbracketrightm(Q)is its theoretical counterpart. Note that /angbracketleftM/angbracketrightm(Q)also appears in Seldin et al. (2012a,
Theorem 1).
We recall that this general result stands with no assumption on the martingale diﬀerence sequence (Xi)i≥1
and holds uniformly on all m≥1. Those two points are, to the best of our knowledge, new within the
PAC-Bayes literature. We discuss in Sec. 2.3 and Appendix B more concrete instantiations.
5Published in Transactions on Machine Learning Research (04/2023)
Comparison with literature. The closest result from Thm. 2.1 is the PAC-Bayes Bernstein inequality of
Seldin et al. (2012a). Our bound is a natural extension of theirs as their result only involves the variance
term (not the empirical one), but requires two additional assumptions:
1. Bounded variations of the martingale diﬀerence sequence: ∀m,∃Cm∈R2such that a.s. for all h
|Xm(Sm,h)|≤Cm.
2. Restriction on the range of the λ:∀m,λm≤1/Cm.
Seldin et al. (2012a) need those assumptions to ensure the Bernstein assumption which states that for
anyh,E[exp(λMm(h)−λ2
2/angbracketleftM/angbracketrightm(h))]≤1. Our proof technique do not require the Bernstein assump-
tion (and so none of the two conditions described above, which allow us to deal with unbounded martin-
gales) as we exploit the supermartingale structure to obtain our results. More precisely, the price to pay
to avoid the Bernstein assumption is to consider the empirical variance term [M]m(h)and to prove that/parenleftBig
exp/parenleftBig
λMm−λ2
2([M]m+/angbracketleftM/angbracketrightm)/parenrightBig/parenrightBig
m≥1is a supermartingale using Lemma 1.2 and Lemma 1.3 (see Sec. 2.2
for the complete proof). A broader discussion is detailed in Appendix B.
2.2 Proof of Thm. 2.1
Proof.We ﬁxη∈Rand we consider the function fmto be for all (S,h):
fm(S,h) :=ηMm(h)−η2
2([M]m(h) +/angbracketleftM/angbracketrightm(h))
=m/summationdisplay
i=1η∆Mi(h)−η2
2(∆[M]i(h) + ∆/angbracketleftM/angbracketrighti(h)),
where ∆Mi(h) =Xi(Si,h),∆[M]i(h) =Xi(Si,h)2,∆/angbracketleftM/angbracketrighti(h) =Ei−1/bracketleftbig
Xi(Si,h)2/bracketrightbig
. For the sake of
clarity, we dropped the dependency in SofMm. Note that, given the deﬁnition of Mm,Mm(h)isFm
measurable for any ﬁxed h.
LetPaﬁxeddata-freeprior, weﬁrstapplythechangeofmeasureinequalitytoobtain ∀m∈N,∀Q∈M+
1(H):
Eh∼Q[fm(S,h)]≤KL(Q,P) + log
Eh∼P[exp(fm(S,h))]/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
:=Zm
,
with the convention f0= 0. We now have to show that (Zm)mis a supermartingale with Z0= 1. To do so
remark that for any m, becausePis data free one has the following result.
Lemma 2.2. For any data-free prior P, anyσ-algebra Fbelonging to the ﬁltration (Fi)i≥0, any nonnegative
functionftaking as argument the sample Sand a predictor h, one has almost surely:
E[Eh∼P[f(S,h)]|F] =Eh∼P[E[f(S,h)|F]].
Proof.LetAbe aF-measurable event. We want to show that
E[Eh∼P[f(S,h)]1A] =E[Eh∼P[E[f(S,h)|F]]1A],
where the ﬁrst expectation in each term is taken over S. Note that it is possible to take this expectation
thanks to the Kolomogorov’s extension theorem (see e.g.Tao, 2011, Thm 2.4.4) which ensure the existence
of a probability space for the discrete-time stochastic process S= (zi)i≥1.
Thus, this is enough to conclude that
E[Eh∼P[f(S,h)]|F] =Eh∼P[E[f(S,h)|F]],
6Published in Transactions on Machine Learning Research (04/2023)
by deﬁnition of the conditional expectation. To do so, notice that because f(S,h)1Ais a nonnegative
function, and that Pis data-free, we can apply the classical Fubini-Tonelli theorem.
E[Eh∼P[f(S,h)]1A] =Eh∼P[E[f(S,h)1A]].
One now conditions by Fand use the fact that 1AisF-measurable:
=Eh∼P[E[E[f(S,h)|F]1A]].
We ﬁnally re-apply Fubini-Tonelli to re-intervert the expectations:
=E[Eh∼P[E[f(S,h)|F]1A]].
This concludes the proof of Lemma 2.2.
We then use Lemma 2.2 with f= exp(fm)andF=Fm−1to obtain:
Em−1[Zm] =Eh∼P[Em−1[(exp(fm(S,h))]]
=Eh∼P/bracketleftbigg
exp(fm−1(S,h))Em−1/bracketleftbigg
exp(η∆Mm(h)−η2
2(∆[M]m(h) + ∆/angbracketleftM/angbracketrightm(h))/bracketrightbigg/bracketrightbigg
,
withfm−1(S,h) =/summationtextm−1
i=1η(∆Mi(h))−η2
2(∆[M]i(h) + ∆/angbracketleftM/angbracketrighti(h)). Using Lemma 1.3 ensures that for any h,
Em−1[exp(η∆Mm(h)−η2
2(∆[M]m(h) + ∆/angbracketleftM/angbracketrightm(h))]≤1,
thus we have
Em−1[Zm]≤Eh∼P[exp(fm−1(S,h))] =Zm−1.
Thus (Zm)mis a nonnegative supermartingale with Z0= 1. We can use Ville’s inequality (Lemma 1.2)
which states that
PS/parenleftbig
∃m≥1 :Zm>δ−1/parenrightbig
≤δ.
Thus, with probability 1−δoverS, for allm∈N,Zm≤1/δ. We then have the following intermediary
result. For all Pa data-free prior, η∈R, with probability 1−δoverS, for allm> 0,Q∈M+
1(H)
ηMm(Q)≤KL(Q,P) + log(1/δ) +η2
2([M]m(Q) +/angbracketleftM/angbracketrightm(Q))], (3)
recalling that Mm(Q) =Eh∼Q[Mm(h)], and that similar deﬁnitons hold for [M]m(Q),/angbracketleftM/angbracketrightm(Q). Thus,
applying the bound with η=±λ(λ >0) and taking an union bound gives, with probability 1−δoverS,
for anym∈N,Q∈M+
1(H)
λ|Mm(Q)|≤KL(Q,P) + log(2/δ) +λ2
2([M]m(Q) +/angbracketleftM/angbracketrightm(Q))].
Dividing by λconcludes the proof.
2.3 A corollary: Batch learning with iid data and unbounded losses
In this section, we instantiate Thm. 2.1 onto a learning theory framework with iid data. We show that our
bound encompasses several results of literature as particular cases.
Framework Weconsidera learning problem speciﬁedbyatuple (H,Z,/lscript)consistingofaset Hofpredictors,
the data space Z, and a loss function /lscript:H×Z→R+. We consider a countable dataset S= (zi)i≥1∈ZNand
assume that sequence is iid following the distribution µ. We also denote by M+
1(H)is the set of probabilities
onH.
7Published in Transactions on Machine Learning Research (04/2023)
Deﬁnitions Thegeneralisation error Rof a predictor h∈His∀h,R(h) =Ez∼µ[/lscript(h,z)], theempir-
ical error ofhis∀h,Rm(h) =1
m/summationtextm
i=1/lscript(h,zi)]and ﬁnally the quadratic generalisation error Vofhis
∀h,Quad (h) =Ez∼µ[/lscript(h,z)2]. We also denote by generalisation gap for anyhthe quantity|R(h)−Rm(h)|.
Main result. We now state the main result of this section. This bound is a corollary of Thm. 2.1 and ﬁlls
the gap with learning theory.
Theorem 2.3. For any data-free prior P∈M+
1(H), anyλ >0the following holds with probability 1−δ
over the sample S= (zi)i∈N, for allm∈N/{0},Q∈M+
1(H)
Eh∼Q[R(h)]≤Eh∼Q/bracketleftBigg
Rm(h) +λ
2mm/summationdisplay
i=1/lscript(h,zi)2/bracketrightBigg
+KL(Q,P) + log(2/δ)
λm+λ
2Eh∼Q[Quad(h)].
Proof is furnished in Appendix C.
About the choice of λ.A novelty in this theorem is that the bound holds simultaneously on all m> 0
– this is due to the use of Ville’s inequality. This sheds a new light on the choice of λ. Indeed, taking a
localisedλdepending on a given sample size (e.g. λm= 1/√m) ensures convergence guarantees for the
expected generalisation gap. Doing so, our bound matches the usual PAC-Bayes literature (i.e. a bound
holding with high probability for a single m). However the novelty brought by Thm. 2.3 is that our bound
holds for unbounded losses for all times simultaneously. This suggests that taking a sample size-dependent
λmay not be the best answer. We detail an instance of this fact below when one thinks of λas a parameter
of an optimisation objective. Indeed, our bound suggests a new optimisation objective for unbounded losses
which is for any m> 0:
argmin QEh∼Q/bracketleftBigg
1
mm/summationdisplay
i=1/parenleftbigg
/lscript(h,zi) +λ
2/lscript(h,zi)2/parenrightbigg/bracketrightBigg
+KL(Q,P)
λm. (4)
Eq. (4) diﬀers from the classical objective of Catoni (2007, Thm 1.2.6) on the additional quadratic term
λ
2/lscript(h,zi)2. Note that this objective implies a bound on the theoretical order 2 moment to be meaningful
as we do not include it in our objective. Note that this constraint is less restrictive than Catoni’s objective
which requires a bounded loss. This objective stresses the role of the parameter λas being involved in a new
explicit tradeoﬀ between the KL term and the eﬃciency on training data.
Also, this optimisation objective is valid for any sample size m, this means that our λshould not depend on
certain dataset size but should be ﬁxed in order to ensure a learning algorithm with generalisation guarantees
at all time. This draws a parallel with Stochastic Gradient Descent with ﬁxed learning step.
About the underlying assumptions in this bound. Our result is empirical (all terms can be computer
or approximated) at the exception of the term Eh∼Q[Quad(h)]. This invites to choose carefully the class
of posteriors, in order to bound this second-order moment with minimal assumptions. For instance, if we
consider the particular case of the quadratic loss /lscript(h,z) = (h−z)2, then we only need to assume that our data
haveaﬁnitevarianceifwerestrictourposteriorstohavebothboundedmeansandvariance. Thisassumption
is striclty less restrictive than the classical subgaussian/subgamma assumption classically appearing in the
literature.
Comparison with literature. Back to the bounded case, we note that instantiating the boundedness
assumption in Thm. 2.3 make us recover the result of Alquier et al. (2016, Theorem 4.1) for the subgaussian
case. We also remark that instantiating the HYPE condition conditioning Haddouche et al. (2021, Theorem
3) allow us to improve their result as we transformed the control of an exponential moment into one on a
second-order moment. More details are gathered in Appendix B. We also compare Thm. 2.3 to Kuzborskij
and Szepesvári (2019, Theorem 3) which is a PAC-Bayes bound for unbounded losses obtained through
a concentration inequality from De la Peña et al. (2009). They arrived to what they denote as semi-
empirical inequalities which also involve empirical and theoretical variance terms (and not an exponential
moment).Their bound holds for independent data and a single posterior. First of all, note that Thm. 2.3
holds for any posterior, which is strictly more general. Note also that our bound is a straightforward corollary
8Published in Transactions on Machine Learning Research (04/2023)
of Thm. 2.1 which holds for any martingale (thus for any data distribution in a learning theory framework)
and so, exploits a diﬀerent toolbox than Kuzborskij and Szepesvári (2019) (control of a supermartingale vs.
concentration bounds for independent data). We insist that a fundamental novelty in our work is to extend
the conclusion of Kuzborskij and Szepesvári (2019) to the case of non-independent data: it is possible to
perform PAC-Bayes learning for unbounded losses at the expense of the control of second-order moments.
Note also that their bound is slightly tighter than ours as their result is Thm. 2.3 being optimised in λ
(which is something we cannot do as the resulting λwould be data-dependent).
3 Online PAC-Bayes learning with unbounded losses
Recently, an online learning framework has been designed in Haddouche and Guedj (2022). This allowed the
design of Online PAC-Bayes (OPB) algorithms which involved the use of history-dependent priors evolving
at each time step of the learning procedure. The main contribution of this section is an OPB bound valid
for unbounded losses.
Framework We consider the same framework as in Sec. 2.3 except we do not make any assumption on
the data distribution. Our goal is now to deﬁne a posterior sequence (Qi)i≥1from a prior sequence (Pi)i≥1.
We also deﬁne a ﬁltration (Fi)i≥1adapted to (zi)i≥1. We reuse the following deﬁnitions extracted from
Haddouche and Guedj (2022).
Deﬁnitions For alli, we denote by Ei[.]the conditional expectation E[.|Fi].
Astochastic kernel from∪∞
m=1ZmtoHis deﬁned as a mapping Q:∪∞
m=1Zm×ΣH→[0,1]where (i) For any
B∈ΣH, the function S/mapsto→Q(S,B)is measurable, (ii) For any S, the function B/mapsto→Q(S,B)is a probability
measure over H.
We also say that a sequence of stochastic kernels (Pi)i≥1is anonline predictive sequence if (i) for all
i≥1,S∈∪∞
m=1Zm,Pi(S,.)isFi−1measurable and (ii) for all i≥2,Pi(S,.)/greatermuchP1(S,.).
Main result. We now state the main theorem of this section, which extends the remits of the Online
PAC-Bayes framework to the case of unbounded losses.
Theorem 3.1. For any distribution over the (countable) dataset S, anyλ > 0and any online predictive
sequence (used as priors) (Pi)i≥1, we have with probability at least 1−δover the sample S∼µ, the following,
holding for the data-dependent measures Pi,S:=Pi(S,.)any posterior sequence (Qi)i≥1and anym≥1:
m/summationdisplay
i=1Ehi∼Qi[E[/lscript(hi,zi)|Fi−1]]≤m/summationdisplay
i=1Ehi∼Qi[/lscript(hi,zi)] +λ
2m/summationdisplay
i=1Ehi∼Qi/bracketleftBig
ˆVi(hi,zi) +Vi(hi)/bracketrightBig
+m/summationdisplay
i=1KL(Qi/bardblPi,S)
λ+log(1/δ)
λ.
With for all i,ˆVi(hi,zi) = (/lscript(hi,zi)−Ei−1[/lscript(hi,zi)])2is the empirical variance at time iandVi(hi) =
Ei−1[ˆV(hi,zi)]is the true conditional variance.
Proof lies in Sec. 3.1.
Analysis of the bound. This bound is, to our knowledge, the ﬁrst Online PAC-Bayes bound in literature
holding for unbounded losses. It is semi-empirical as the variance and empirical variance terms have theo-
retical components. However, these terms can be controlled with assumptions on conditional second-order
moments and not on exponential ones (as made in Haddouche and Guedj, 2022 where the bounded loss as-
sumption was used to obtain conditional subgaussianity). To emphasise our point, we consider as in Sec. 2.3
the case of the quadratic loss /lscript(h,z) = (h−z)2. Here, we only need to assume that our data have a ﬁnite
variance if we restrict our posteriors to have both bounded means and variance. Also the meaning of the
online predictive sequence Piis that we must be able to design properly a sequence of priors before drawing
9Published in Transactions on Machine Learning Research (04/2023)
our data, this can be for instance an online algorithm whihc generate a prior distribution from past data at
each time step.
Finally, we note that if we assume being able to bound simultaneaously all condtional means and variance
(which is strictly less restrictive than bounding the loss),then Thm. 3.1 suggests a new online learning
objective which is an online counterpart to Eq. (4).
∀i≥1ˆQi+1= argmin
Q∈M+
1(H)Ehi∼Q/bracketleftbigg
/lscript(hi,zi) +λ
2/lscript(hi,zi)2/bracketrightbigg
+KL(Q/bardblPi,S)
λ(5)
Comparison with literature. Our most natural comparison point is Theorem 2.3 of Haddouche and
Guedj (2022) (re-stated in Appendix A). We claim that Thm. 3.1 is a strict improvement of their result on
various sides described below.
•If we assume our loss to be bounded, then we can upper bound our empirical/theoretical variance
terms to recover exactly Haddouche and Guedj (2022, Theorem 2.3). Our bound can then be seen
as a strict extension of theirs and shows that bounding order two moments is a suﬃcient condition
to perform online PAC-Bayes: subgaussianity induced by boundedness is not necessary even when
our data are non iid.
•Another crucial point lies on the range of our result which holds with high probability for any
countable posterior sequence (Qi)i≥1, any timemand the priors (Pi,S)i≥1. This is far much general
thanHaddoucheandGuedj(2022, Theorem2.3)whichholdsonlyforasingle mandasingleposterior
sequence (Qi,S)i=1..m. This happens because in Haddouche and Guedj (2022), the change of measure
inequality has not been exploited: they used a preliminary theorem from Rivasplata et al. (2020)
which holds for a single (data-dependent) prior/posterior couple. This preliminary theorem already
involved Markov’s inequality which forced the authors to assume conditionnal subgaussianity to
deal with an exponential moment. On the contrary, we exploited the fact that our online predictive
sequence was history-dependent to use the change of measure inequality at any time step and control
an exponential supermartingale through Ville’s inequality.
•InHaddoucheandGuedj(2022, Eq. 1), anOPBalgorithmisgivenbytheirupperbound. Thisworks
because their associated learning objective admits a close form (Gibbs posterior) which matches the
fact their bound hold for a single posterior sequence. Because our bound holds uniformly on all
posteriors, it is now legitimate to restrict their algorithms to any parametric class of distributions
and perform any optimisation algorithm to obtain a surrogate of the best candidate.
Online PAC-Bayes as presented in Haddouche and Guedj (2022) relies on a conditional subgaussiannity
assumption to control an exponential moment. They did not exploit a martingale-type structure to do so.
Our supermartingale approach has proven to be well suited to Online PAC-Bayes as we provided atheorem
valid for unbounded losses holding simultaneously on all posteriors: two points which have not been reached
in Haddouche and Guedj (2022).
3.1 Proof of Thm. 3.1
Proof.We ﬁxm≥1,Sa countable dataset and (Pi)i≥1an online predictive sequence. We aim to design a
m-tuple of probabilities. Thus, our predictor set of interest is Hm:=H⊗mand then, our predictor his a
tuple (h1,..,hm)∈H.
Our goal is to apply the change of measure inequality on Hmto a speciﬁc function fminspired from Lemma
1.3. We deﬁne this function below, for any sample Sand any predictor hm= (h1,...,hm)
fm(S,hm) :=m/summationdisplay
i=1λXi(hi,zi)−λ2
2m/summationdisplay
i=1(ˆVi(hi,zi) +Vi(hi)),
10Published in Transactions on Machine Learning Research (04/2023)
whereXi(hi,zi) =Ei−1[/lscript(hi,zi)]−/lscript(hi,zi). Notice that for ﬁxed h, the sequence (fm(S,h))m≥1is a super-
martingale according to Lemma 1.3.
Now for a given posterior tuple Q1,...Qmwe deﬁneQ=Q1⊗...⊗Qmand alsoPm
S=P1,S⊗...⊗Pm,S. We
can now properly apply the change of measure inequality for any m:
m/summationdisplay
i=1Ehi∼Qi[λXi(hi,zi)−λ2
2(ˆVi(hi,zi) +Vi(hi))] =Ehm∼Q[fm(S,hm)]
≤KL(Q,Pm
S) + log/parenleftbig
Ehm∼Pm
Sexp(fm(S,hm))/parenrightbig
.
Noticing that KL(Q,Pm
S) =/summationtextm
i=1KL(Qi,Pi,S), the only remaining term to deal with is the exponential rv.
To do so we prove the following lemma:
Lemma 3.2. The sequence (Mm:=Ehm∼Pm
Sexp(fm(S,hm))m≥1is a non-negative supermartingale.
Proof.Weﬁxm≥1andwerecallthatforany i,Pi,SisFi−1-measurable. Weshowthat Em−1[Mm]≤Mm−1.
We ﬁrst recover Mm−1fromEm−1[Mm].
Em−1[Mm] =Em−1/bracketleftbig
Ehm∼Pm
Sexp(fm(S,hm)/bracketrightbig
=Em−1/bracketleftbig
Eh1,..,hm∼P1,S⊗...⊗Pm,Sexp(fm(S,hm)/bracketrightbig
=Em−1/bracketleftbigg
Eh1,..,hm∼P1,S⊗...⊗Pm,S/bracketleftbigg
Πm
i=1exp/parenleftbigg
λXi(hi,zi)−λ2
2(ˆVi(hi,zi) +Vi(hi))/parenrightbigg/bracketrightbigg/bracketrightbigg
=Mm−1Em−1/bracketleftbigg
Ehm∼Pm,S/bracketleftbigg
exp/parenleftbigg
λXm(hm,zm)−λ2
2(ˆVm(hm,zm) +Vm(hm))/parenrightbigg/bracketrightbigg/bracketrightbigg
.
The last line holding because Pm−1
S =P1,S⊗...⊗Pm−1,SisFm−1measurable.
Now we exploit the fact that Pm,SisFm−1measurable to apply a conditional Fubini lemma stated in
Haddouche and Guedj (2022, Lemma D.3). We have:
Em−1/bracketleftbigg
Ehm∼Pm,S/bracketleftbigg
exp/parenleftbigg
λXm(hm,zm)−λ2
2(ˆVm(hm,zm) +Vm(hm))/parenrightbigg/bracketrightbigg/bracketrightbigg
=Ehm∼Pm,S/bracketleftbigg
Em−1/bracketleftbigg
exp/parenleftbigg
λXm(hm,zm)−λ2
2(ˆVm(hm,zm) +Vm(hm))/parenrightbigg/bracketrightbigg/bracketrightbigg
.
Now we can apply Lemma 1.3 for any hm∈Hwith ∆Mm=Xm(hm,zm),∆[M]m=ˆV(hm,zm)and
∆/angbracketleftM/angbracketrightm=Vm(hm). We then have for all hm∈H:
Em−1/bracketleftbigg
exp/parenleftbigg
λXm(hm,zm)−λ2
2(ˆVm(hm,zm) +Vm(hm))/parenrightbigg/bracketrightbigg
≤1.
ThusEm−1[Mm]≤Mm−1, this concludes the lemma’s proof.
Now we can apply Ville’s inequality which implies that with probability at least 1−δ, for anym≥1:
Ehm∼Pm
Sexp(fm(S,hm))≤1
δ.
Thus we have with probability at least 1−δ, for any posterior sequence (Qi)i≥1, the data-dependent measures
P1,S,...,Pm,Sand anym≥1:
11Published in Transactions on Machine Learning Research (04/2023)
m/summationdisplay
i=1Ehi∼Qi/bracketleftbigg
λXi(hi,zi)−λ2
2(ˆVi(hi,zi) +Vi(hi))/bracketrightbigg
≤m/summationdisplay
i=1KL(Qi,Pi,S) + log/parenleftbigg1
δ/parenrightbigg
.
Re-organising the terms in this bound and dividing by λconcludes the proof.
4 Application to the multi-armed bandit problem
We exploit our main result in the context of the multi-armed bandit problem – we adopt the framework of
Seldin et al. (2012a).
Framework. LetAbe a set of actions of size |A|=K < +∞anda∈Abe an action. At each round
i, the environment furnishes a reward function Ri:A→Rwhich associate a reward Ri(a)to the arm a.
Assuming the Ris are iid, we denote for any a, theexpected reward for action ato beR(a) =ER1[R1(a)].
At each round i, the player executes an action Aiaccording to a policy πi. We then set the ﬁltration (Fi)i≥1
to beFi=σ({πj,Aj,Rj|1≤j≤m}).
Assumptions. We suppose here that (Ri)i≥1is an iid sequence and that at each time i,AiandRiare
independent and that πiisFi−1measurable. This means that the player is not aware of the rewards each
round and performs its current move with regards to the past.
We also add two technical assumptions. First, the order two moment of the expected reward is uniformly
bounded: supa∈AER1[R1(a)2]≤C. This assumption is strictly less restrictive than the boundedness as-
sumption made in Seldin et al. (2012a). Similarly to this work, we also assume that there exists a sequence
(εi)i≥1such that infa∈Aπi(a)≥εi. We say that (πi)i≥1isbounded from below by (εi)i≥1.
Deﬁnitions. Fori≥1anda∈{1,...,K}, deﬁne a set of random variables (Ra
i)i≥1(the importance
weighted samples , Sutton and Barto, 2018)
Ra
i:=/braceleftbigg1
πi(a)Ri,ifAi=a,
0,otherwise.
We deﬁne for any time m:ˆRm(a) =1
m/summationtextt
i=1Ra
i.Observe that for all i,E[Ra
i|Fi−1] =R(a)andE[ˆRm(a)] =
R(a). Leta∗be the "best" action (the action with the highest expected reward, if there are multiple "best"
actions pick any of them). Deﬁne the expected and empirical per-round regrets as
∆(a) =R(a∗)−R(a),ˆ∆m(a) =ˆRm(a∗)−ˆRm(a).
Observe that m/parenleftBig
ˆ∆m(a)−∆(a)/parenrightBig
forms a martingale. Let
Vm(a) =m/summationdisplay
i=1E/bracketleftbigg/parenleftBig
Ra∗
i−Ra
i−[R(a∗)−R(a)]/parenrightBig2
|Fi−1/bracketrightbigg
be the cumulative variance of this martingale and
ˆVm(a) =m/summationdisplay
i=1/parenleftBig
Ra∗
i−Ra
i−[R(a∗)−R(a)]/parenrightBig2
its empirical counterpart. We denote for any distribution QoverA,∆(Q) =Ea∼Q[∆(a)],Vm(Q) =
Ea∼Q[Vm(a)], similar deﬁnitions hold for ˆ∆m(Q),ˆVm(Q). We can now state the main result of this sec-
tion – its proof is deferred to Appendix C.
12Published in Transactions on Machine Learning Research (04/2023)
Theorem 4.1. For anym≥1, any history-dependent policy sequence (πi)i≥1bounded from below by (εi)i≥1,
we have with probability 1−δ, for all posterior Q
/vextendsingle/vextendsingle/vextendsingle∆(Q)−ˆ∆m(Q)/vextendsingle/vextendsingle/vextendsingle≤2/radicalBigg/parenleftbig
1 +2K
δ/parenrightbig
(log(K) + log(4/δ))
mεm.
To the best of our knowledge, this result is the ﬁrst PAC-Bayesian guarantees for multi-armed bandits with
unbounded rewards. The proposed bound is as tight as Theorem 2.3 of Seldin et al. (2012a), up to a factor
(e−2)transformed into/parenleftbig
1 +2K
δ/parenrightbig
(which is a huge dependency in K) within the square root. Note that our
result comes at the price of the localisation: Theorem 2.3 of Seldin et al. (2012a) proposes a bound holding
uniformly for all time mwhile our approach only holds for a single time m.
We believe there is room for improvement in Thm. 4.1. Indeed, the current approach is naive as it consists
in bounding crudely with high probability the empirical variance. Such a naive trick impeach us to consider
all times simultaneously. Indeed, in its current form, taking an union bound on Thm. 4.1 is costful as we
have a dependency in 1/δin our result (instead of log(1/δ)in Seldin et al., 2012a): this would destroy the
convergence rate. The question of dealing more subtly with the empirical variance term is left as an open
question.
5 Conclusion
We showed that it is possible to generalise the PAC-Bayes toolbox to unbounded martingales and heavy-
tailed losses (resp. learning problem with unbounded losses for batch/online learning), the solely implicit
assumption being the existence of second order moments on the martingale diﬀerence sequence (resp. on the
loss function) which is reasonable as many PAC-Bayes bound lies on assumptions on exponential moments
(e.g.the subgaussian assumption) to work. We also proved that our main theorem can be seen as a general
basis allowing to recover several PAC-Bayesian bounds. This shows that the supermartingale framework is
a fruitful approach to unify several branches of PAC-Bayes and could lead to new promising developement
such as the work of Jang et al. (2023).
References
P. Alquier. User-friendly introduction to PAC-Bayes bounds, 2021. URL https://arxiv.org/abs/2110.
11216.
P. Alquier and G. Biau. Sparse single-index model. J. Mach. Learn. Res. , 14(1):243–280, 2013. doi:
10.5555/2567709.2502589. URL https://dl.acm.org/doi/10.5555/2567709.2502589 .
P. Alquier and B. Guedj. Simpler PAC-Bayesian bounds for hostile data. Machine Learning , 107(5):887–902,
2018. ISSN 1573-0565. URL http://dx.doi.org/10.1007/s10994-017-5690-0 .
P. Alquier, J. Ridgway, and N. Chopin. On the properties of variational approximations of gibbs posteriors.
Journal of Machine Learning Research , 17(236):1–41, 2016. URL http://jmlr.org/papers/v17/15-290.
html.
J.-Y. Audibert and O. Catoni. Robust linear least squares regression. The Annals of Statistics , 39(5):2766
– 2794, 2011. doi: 10.1214/11-AOS918. URL https://doi.org/10.1214/11-AOS918 .
A. Banerjee. On Bayesian Bounds. In Proceedings of the 23rd international conference on Machine learning ,
pages 81–88, 2006.
B. Bercu and A. Touati. Exponential inequalities for self-normalized martingales with applications. The
Annals of Applied Probability , 18(5):1848–1869, 2008.
F. Biggs and B. Guedj. Diﬀerentiable PAC-Bayes objectives with partially aggregated neural networks.
Entropy, 23(10):1280, 2021.
13Published in Transactions on Machine Learning Research (04/2023)
F. Biggs and B. Guedj. On margins and derandomisation in PAC-Bayes. In G. Camps-Valls, F. J. R. Ruiz,
and I. Valera, editors, Proceedings of The 25th International Conference on Artiﬁcial Intelligence and
Statistics [AISTATS] , volume 151 of Proceedings of Machine Learning Research , pages 3709–3731. PMLR,
28–30 Mar 2022a. URL https://proceedings.mlr.press/v151/biggs22a.html .
F. Biggs and B. Guedj. Non-vacuous Generalisation Bounds for shallow neural networks. In ICML, 2022b.
F. Biggs, V. Zantedeschi, and B. Guedj. On margins and generalisation for voting classi-
ﬁers. In S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh, edi-
tors,Advances in Neural Information Processing Systems , volume 35, pages 9713–9726. Curran
Associates, Inc., 2022. URL https://proceedings.neurips.cc/paper_files/paper/2022/file/
3f8675af3da6da231c9e75b889b7f047-Paper-Conference.pdf .
O. Catoni. A PAC-Bayesian approach to adaptive classiﬁcation. preprint, 840, 2003.
O. Catoni. Statistical learning theory and stochastic optimization: Ecole d’Eté de Probabilités de Saint-Flour,
XXXI-2001 , volume 1851. Springer Science & Business Media, 2004.
O. Catoni. PAC-Bayesian Supervised Classiﬁcation: The Thermodynamics of Statistical Learning. Institute
of Mathematical Statistics Lecture Notes—Monograph Series 56. IMS, Beachwood, OH. MR2483528 ,
5544465, 2007.
O. Catoni. PAC-Bayesian bounds for the Gram matrix and least squares regression with a random design.
arXiv preprint arXiv:1603.05229 , 2018.
O. Catoni and I. Giulini. Dimension-free PAC-Bayesian bounds for matrices, vectors, and linear least squares
regression. arXiv preprint arXiv:1712.02747 , 2017.
B.-E. Chérief-Abdellatif, Y. Shi, A. Doucet, and B. Guedj. On PAC-Bayesian reconstruction guarantees for
VAEs. In G. Camps-Valls, F. J. R. Ruiz, and I. Valera, editors, Proceedings of The 25th International
Conference on Artiﬁcial Intelligence and Statistics [AISTATS] , volume 151 of Proceedings of Machine
Learning Research , pages 3066–3079. PMLR, 28–30 Mar 2022. URL https://proceedings.mlr.press/
v151/cherief-abdellatif22a.html .
I. Csiszár. I-divergence geometry of probability distributions and minimization problems. The annals of
probability , pages 146–158, 1975.
V. H. De la Peña, T. L. Lai, and Q.-M. Shao. Self-normalized processes: Limit theory and Statistical
Applications , volume 204. Springer, 2009.
M. D. Donsker and S. S. Varadhan. Asymptotic evaluation of certain Markov process expectations for large
time, I.Communications on Pure and Applied Mathematics , 28(1):1–47, 1975.
J. Doob. Jean Ville, Étude Critique de la Notion de Collectif. Bulletin of the American mathematical society ,
45(11):824–824, 1939.
P. Dupuis and R. S. Ellis. A Weak Convergence Approach to the Theory of Large Deviations . Wiley-
Interscience, 2011.
R. Durrett. Probability: theory and examples , volume 49. Cambridge university press, 2019.
G. K. Dziugaite and D. M. Roy. Computing Nonvacuous Generalization Bounds for Deep (stochastic) Neural
Networks with many more parameters than training data. arXiv preprint arXiv:1703.11008 , 2017.
M. Fard and J. Pineau. PAC-Bayesian Model Selection for Reinforcement Learning. Advances in Neural
Information Processing Systems (NeurIPS) , 23, 2010.
P. Germain, A. Lacasse, F. Laviolette, and M. Marchand. PAC-Bayesian Learning of Linear Classiﬁers. In
Proceedings of the 26th Annual International Conference on Machine Learning , ICML ’09, page 353–360,
New York, NY, USA, 2009. Association for Computing Machinery. ISBN 9781605585161. URL https:
//doi.org/10.1145/1553374.1553419 .
14Published in Transactions on Machine Learning Research (04/2023)
P. Germain, F. Bach, A. Lacoste, and S. Lacoste-Julien. PAC-Bayesian theory meets Bayesian inference.
Advances in Neural Information Processing Systems (NeurIPS) , 29, 2016.
B. Guedj. A Primer on PAC-Bayesian Learning. In Proceedings of the second congress of the French
Mathematical Society , 2019.
B. Guedj and P. Alquier. PAC-Bayesian estimation and prediction in sparse additive models. Electron. J.
Statist., 7:264–291, 2013. doi: 10.1214/13-EJS771. URL https://doi.org/10.1214/13-EJS771 .
B. Guedj and S. Robbiano. PAC-Bayesian high dimensional bipartite ranking. Journal of Statistical Planning
and Inference , 196:70 – 86, 2018. ISSN 0378-3758. doi: https://doi.org/10.1016/j.jspi.2017.10.010. URL
http://www.sciencedirect.com/science/article/pii/S0378375817301945 .
M. Haddouche and B. Guedj. Online PAC-Bayes Learning. In S. Koyejo, S. Mohamed, A. Agarwal, D. Bel-
grave, K. Cho, and A. Oh, editors, Advances in Neural Information Processing Systems , volume 35, pages
25725–25738. Curran Associates, Inc., 2022. URL https://proceedings.neurips.cc/paper_files/
paper/2022/file/a4d991d581accd2955a1e1928f4e6965-Paper-Conference.pdf .
M. Haddouche, B. Guedj, O. Rivasplata, and J. Shawe-Taylor. PAC-Bayes unleashed: generalisation bounds
with unbounded losses. Entropy, 23(10):1330, 2021.
M. Holland. PAC-Bayes under potentially heavy tails. In H. Wallach, H. Larochelle, A. Beygelzimer,
F. d Alché-Buc, E. Fox, and R. Garnett, editors, Advances in Neural Information Processing Systems
(NeurIPS) 32 , pages 2715–2724. Curran Associates, Inc., 2019. URL http://papers.nips.cc/paper/
8539-pac-bayes-under-potentially-heavy-tails.pdf .
K. Jang, K.-S. Jun, I. Kuzborskij, and F. Orabona. Tighter PAC-Bayes Bounds Through Coin-Betting,
2023. URL https://arxiv.org/abs/2302.05829 .
S. M. Kakade, K. Sridharan, and A. Tewari. On the complexity of linear prediction: Risk bounds, margin
bounds, and regularization. Advances in Neural Information Processing Systems (NeurIPS) , 21, 2008.
I. Kuzborskij and C. Szepesvári. Efron-Stein PAC-Bayesian Inequalities. arXiv preprint arXiv:1909.01931 ,
2019.
J. Langford and R. Schapire. Tutorial on practical prediction theory for classiﬁcation. Journal of machine
learning research , 6(3), 2005.
G. Letarte, P. Germain, B. Guedj, and F. Laviolette. Dichotomize and generalize: PAC-Bayesian binary
activated deep neural networks. Advances in Neural Information Processing Systems (NeurIPS) , 32, 2019.
G. Lever, F. Laviolette, and J. Shawe-Taylor. Distribution-dependent PAC-Bayes priors. In International
Conference on Algorithmic Learning Theory , pages 119–133. Springer, 2010.
G. Lever, F. Laviolette, and J. Shawe-Taylor. Tighter PAC-Bayes bounds through distribution-dependent
priors.Theoretical Computer Science , 473:4–28, 2013.
A. Maurer. A note on the PAC Bayesian theorem. arXiv preprint cs/0411099 , 2004.
D. A. McAllester. Some PAC-Bayesian theorems. In Proceedings of the eleventh annual conference on
Computational Learning Theory , pages 230–234. ACM, 1998.
D. A. McAllester. PAC-Bayesian model averaging. In Proceedings of the twelfth annual conference on
Computational Learning Theory , pages 164–170. ACM, 1999.
D. A. McAllester. PAC-Bayesian stochastic model selection. Machine Learning , 51(1):5–21, 2003.
Z. Mhammedi, P. Grünwald, and B. Guedj. PAC-Bayes Un-Expected Bernstein Inequality. In H. Wallach,
H. Larochelle, A. Beygelzimer, F. d Alché-Buc, E. Fox, and R. Garnett, editors, Advances in Neural
Information Processing Systems (NeurIPS) 32 , pages 12202–12213. Curran Associates, Inc., 2019. URL
http://papers.nips.cc/paper/9387-pac-bayes-un-expected-bernstein-inequality.pdf .
15Published in Transactions on Machine Learning Research (04/2023)
L. Oneto, D. Anguita, and S. Ridella. PAC-Bayesian analysis of distribution dependent priors: Tighter risk
bounds and stability analysis. Pattern Recognition Letters , 80:200–207, 2016.
E. Parrado-Hernández, A. Ambroladze, J. Shawe-Taylor, and S. Sun. PAC-Bayes bounds with data depen-
dent priors. The Journal of Machine Learning Research , 13(1):3507–3531, 2012.
M. Perez-Ortiz, O. Rivasplata, B. Guedj, M. Gleeson, J. Zhang, J. Shawe-Taylor, M. Bober, and J. Kittler.
Learning PAC-Bayes Priors for Probabilistic Neural Networks. 2021a. URL https://arxiv.org/abs/
2109.10304 .
M. Perez-Ortiz, O. Rivasplata, E. Parrado-Hernandez, B. Guedj, and J. Shawe-Taylor. Progress in self-
certiﬁed neural networks. In NeurIPS 2021 workshop Bayesian Deep Learning [BDL] , 2021b. URL http:
//bayesiandeeplearning.org/2021/papers/38.pdf .
M. Pérez-Ortiz, O. Rivasplata, J. Shawe-Taylor, and C. Szepesvári. Tighter Risk Certiﬁcates for Neural
Networks. Journal of Machine Learning Research , 22, 2021.
A. Picard-Weibel and B. Guedj. On change of measure inequalities for f-divergences. arXiv preprint
arXiv:2202.05568 , 2022.
O. Rivasplata, V. M. Tankasali, and C. Szepesvári. PAC-Bayes with Backprop. CoRR, abs/1908.07380,
2019. URL http://arxiv.org/abs/1908.07380 .
O. Rivasplata, I. Kuzborskij, C. Szepesvári, and J. Shawe-Taylor. PAC-Bayes analysis beyond the usual
bounds. Advances in Neural Information Processing Systems (NeurIPS) , 33:16833–16845, 2020.
M. Seeger. PAC-Bayesian Generalization Error Bounds for Gaussian Process Classiﬁcation. Journal of
Machine Learning Research , 3, 08 2002.
Y. Seldin, F. Laviolette, J. Shawe-Taylor, J. Peters, and P. Auer. PAC-Bayesian Analysis of Martingales
and Multiarmed Bandits. arXiv preprint arXiv:1105.2416 , 2011.
Y. Seldin, N. Cesa-Bianchi, P. Auer, F. Laviolette, and J. Shawe-Taylor. PAC-Bayes-Bernstein Inequality for
Martingales and its Application to Multiarmed Bandits. In D. Glowacka, L. Dorard, and J. Shawe-Taylor,
editors,Proceedings of the Workshop on Online Trading of Exploration and Exploitation 2 , volume 26
ofProceedings of Machine Learning Research , pages 98–111, Bellevue, Washington, USA, 02 Jul 2012a.
PMLR. URL https://proceedings.mlr.press/v26/seldin12a.html .
Y. Seldin, F. Laviolette, N. Cesa-Bianchi, J. Shawe-Taylor, and P. Auer. PAC-Bayesian Inequalities for
Martingales. IEEE Transactions on Information Theory , 58(12):7086–7093, 2012b.
J. Shawe-Taylor and R. C. Williamson. A PAC analysis of a Bayes estimator. In Proceedings of the 10th
annual conference on Computational Learning Theory , pages 2–9. ACM, 1997.
R. S. Sutton and A. G. Barto. Reinforcement Learning: An introduction . MIT press, 2018.
T. Tao.An introduction to measure theory , volume 126. American Mathematical Society Providence, 2011.
N. Thiemann, C. Igel, O. Wintenberger, and Y. Seldin. A strongly quasiconvex PAC-Bayesian bound. In
International Conference on Algorithmic Learning Theory , pages 466–492. PMLR, 2017.
I. O. Tolstikhin and Y. Seldin. PAC-Bayes-Empirical-Bernstein Inequality. In C. Burges, L. Bottou,
M. Welling, Z. Ghahramani, and K. Weinberger, editors, Advances in Neural Information Processing
Systems (NeurIPS) , volume 26. Curran Associates, Inc., 2013. URL https://proceedings.neurips.cc/
paper/2013/file/a97da629b098b75c294dffdc3e463904-Paper.pdf .
Y.-S. Wu and Y. Seldin. Split-kl and pac-bayes-split-kl inequalities for ternary random vari-
ables. In S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh, edi-
tors,Advances in Neural Information Processing Systems , volume 35, pages 11369–11381. Cur-
ran Associates, Inc., 2022. URL https://proceedings.neurips.cc/paper_files/paper/2022/file/
49ffa271264808cf500ea528ed8ec9b3-Paper-Conference.pdf .
16Published in Transactions on Machine Learning Research (04/2023)
A Some PAC-Bayesian background
We present below an immediate corollary of Seldin et al. (2012a, Thm 2.1) where we upper bounded the
cumulative by an empirical quantity (the sum of squared upper bound of the martingale diﬀerence sequence).
TheoremA.1 (Seldinetal.,2012a, Theorem2.1) .Let{C1,C2,...}be an increasing sequence set in advance,
such that|Xi(Si,h)|≤Cifor allSi,hwith probability 1. Let {P1,P2,...}be a sequence of data-free prior
distributions over H. Let (λi)i≥1be a sequence of positive numbers such that
λm≤1
Cm.
Then with probability 1−δoverS= (zi)i≥1, for allm≥1, any posterior QoverH,
|Mm(Q)|≤KL(Q/bardblPm) + 2 log(m+ 1) + log2
δ
λm+ (e−2)λmVm(Q),
whereVm(Q)is deﬁned in Appendix B.1.
Furthermore, if we bound the variance term, we would have:
|Mm(Q)|≤KL(Q/bardblPm) + 2 log(m+ 1) + log2
δ
λm+ (e−2)λmm/summationdisplay
i=1C2
i.
Below, we use the deﬁnitions introduced in Sec. 2.3. We study here a particular case of Alquier et al. (2016)
for bounded losses which are especially subgaussian thanks to Hoeﬀding’s lemma.
TheoremA.2 (AdaptedfromAlquieretal.,2016, Theorem4.1) .Letm> 0,S= (z1,...,zm)be an iid sample
from the same law µ. For any data-free prior P, for any loss function /lscriptbounded by K, anyλ>0,δ∈]0; 1[,
one has with probability 1−δfor any posterior Q∈M1(H)
Eh∼Q[R(h)]≤Eh∼Q[Rm(h)] +KL(Q/bardblP) + log(1/δ)
λ+λK2
2m.
Theorem A.3 (Haddouche et al., 2021, Theorem 3) .Let the loss /lscriptbeHYPE(K)compliant. For any
P∈M+
1(H)with no data dependency, for any α∈Rand for any δ∈[0,1], we have with probability at least
1−δover size-msamples S, for any Q
Eh∼Q[R(h)]≤Eh∼Q[Rm(h)] +KL(Q||P) + log/parenleftbig1
δ/parenrightbig
mα+1
mαlog/parenleftbigg
Eh∼P/bracketleftbigg
exp/parenleftbiggK(h)2
2m1−2α/parenrightbigg/bracketrightbigg/parenrightbigg
.
Theorem A.4 (Theorem 2.3 of Haddouche and Guedj, 2022) .For any distribution µoverZm, anyλ>0
and any online predictive sequence (used as priors) (Pi), for any sequence of stochastic kernels (Qi)we
have with probability 1−δover the sample S∼µ, the following, holding for the data-dependent measures
Qi,S:=Qi(S,.),Pi,S:=Pi(S,.):
m/summationdisplay
i=1Ehi∼Qi,S[E[/lscript(hi,zi)|Fi−1]]≤m/summationdisplay
i=1Ehi∼Qi,S[/lscript(hi,zi)] +KL(Qi,S/bardblPi,S)
λ+λmK2
2+log(1/δ)
λ.
B Extensions of previous results
Here we gather several corollaries of our main result in order to show how our Thm. 2.1 extends the validity
of some classical results in the literature. More precisely we show that our result extends (up to numerical
factors) the PAC-Bayes Bernstein inequality of Seldin et al. (2012a). Then, going back to the bounded case,
we generalise a result from Catoni (2007) reformulated in Alquier et al. (2016) and we also show how our
work strictly improves on the bound of Haddouche et al. (2021).
17Published in Transactions on Machine Learning Research (04/2023)
B.1 Extension of the PAC-Bayes Bernstein inequality
Here we rename two terms for consistency with Theorem 2.1 of Seldin et al. (2012a) (see Thm. A.1). For a
martingale Mm(h) =/summationtextm
i=1Xi(Si,h), we deﬁne, at time m,empirical cumulative variance to be ˆVm(h) =
[M]m(h) =/summationtextm
i=1Xi(Si,h)2and thecumulative variance asVm(h) =/angbracketleftM/angbracketrightm(h) =/summationtextm
i=1Ei−1[Xi(Si,h)2].
We provide below a corollary containing two bounds: the ﬁrst one being a straightforward corollary of
Thm. 2.1, the second being valid for bounded martingales and formally close to Theorem 2.1 of Seldin et al.
(2012a).
Corollary B.1. Let{P1,P2,...}be a sequence of data-free prior distributions over H. Let (λi)i≥1be a
sequence of positive numbers. Then the following holds with probability 1−δoverS= (zi)i≥1: for any tuple
(m,λk,Pk)withm,k≥1, any posterior QoverH,
|Mm(Q)|≤KL(Q,Pk) + 2 log(k+ 1) + log(2 /δ)
λk+λk
2/parenleftBig
ˆVm(Q) +Vm(Q)/parenrightBig
, (6)
with ˆVm(Q) =Eh∼Q[ˆVm(h)],Vm(Q) =Eh∼Q[Vm(h)]. Furthermore, if we assume that for any i, there exists
Ci>0such that|Xi(Si,h)|≤Cifor allSi,hthen we have the following corollary: with probability 1−δ
overS, for any tuple (m,λm,Pm)m≥1, any posterior Q,
|Mm(Q)|≤KL(Q,Pm) + 2 log(m+ 1) + log(2 /δ)
λm+λmm/summationdisplay
i=1C2
i. (7)
The proof is deferred to Appendix C. Note that Eq. (6) holds uniformly on all tuples {(λk,Pk,m)|k≥
1,m≥1}while Eq. (7), as well as Theorem 2.1 of Seldin et al. (2012a) holds uniformly on the tuples
{(λm,Pm,m)|m≥1}which is a strictly smaller collection. Hence our approach gives guarantees for a
larger event with the same conﬁdence level.
Furthermore, Theorem 2.1 of Seldin et al. (2012a) involves the cumulative variance Vm(Q)(and not its
empirical counterpart). Because this term is theoretical, we bound it in Thm. A.1 by/summationtextm
i=1C2
iwhich is
supposedly empirical. In this context, Eq. (7), recovers nearly exactly the bound of Seldin et al. (2012a)
with the transformation of a factor (e−2)into1. Notice also that Eq. (7) stands with no assumption on
the range of the λi, which is not the case in Thm. A.1.
Finally, we stress two fundamental diﬀerences between our work and the one of Seldin et al. (2012a). First,
we replace Markov’s inequality by Ville’s inequality; second, we exploited the exponential inequality of
Lemma 1.3 instead of the Bernstein inequality. These allow for results for unbounded martingales for all m
simultaneously.
B.2 Extensions of learning theory results
B.2.1 A general result for bounded losses
We use deﬁnitions from Sec. 2.3 and provide a corollary of our main result when the loss is bounded by a
positive constant K > 0. We assume our data are iid.
Corollary B.2. For any data-free prior P∈M+
1(H), anyλ>0the following holds with probability 1−δ
over the sample S= (zi)i∈N, for allm∈N/{0},Q∈M+
1(H)
|Eh∼Q[R(h)]−Eh∼Q[Rm(h)]|≤KL(Q,P) + log(2/δ)
λm+λK2.
We also have the local bound: for any m≥1, with probability 1−δoverS, for allQ∈M+
1(H)
Eh∼Q[R(h)]≤Eh∼Q[Rm(h)] +KL(Q,P) + log(2/δ)
λ+λK2
m.
18Published in Transactions on Machine Learning Research (04/2023)
The proof is deferred to Appendix C. Remark that the second bound of Corollary B.2 is exactly the Catoni
bound stated in Alquier et al. (2016) (see Thm. A.2 in Appendix A) up to a numerical factor of 2.
The ﬁrst bound is, to our knowledge, the ﬁrst PAC-Bayesian bound for bounded losses holding uniformly
(for a given parameter λ) on the choice of Q,mand thus extends the scope of Catoni’s bound which holds
for a single mwith high probability. Indeed, if we want for instance Thm. A.2 to hold for any i∈{1..m}, we
then have to take an union bound on mevents which turns the term log(1/δ)intolog(m/δ)(but with the
beneﬁt of holding for mparameters λ1,...,λm). This point is common to the most classical PAC-Bayesian
bounds (as those of McAllester, 1998; 1999; Maurer, 2004; Catoni, 2007; Tolstikhin and Seldin, 2013) and
impeach us to have a bound uniformly on all m∈N/{0}aslog(m)goes to inﬁnity asymptotically.
B.2.2 An extension of Haddouche et al. (2021)
We now focus on the work of Haddouche et al. (2021) which provides general PAC-Bayesian bounds for
unbounded losses. Their theorems hold for iid data and under the so-called HYPE(for HYPothesis-
dependent rangE) condition. It states that a loss function /lscriptisHYPE (K)compliant if there exists a function
K:H→R+(supposedly accessible) such that ∀z∈Z,/lscript(h,z)≤K(h). We provide Cor. B.3 to compare
ourselves with their main result (stated in Thm. A.3 for convenience).
Corollary B.3. For any data-free prior P∈M+
1(H), any loss function /lscriptbeingHYPE (K)compliant, any
α∈[0,1],m≥1, the following holds with probability 1−δover the sample S= (zi)i∈N, for allQ∈M+
1(H)
Eh∼Q[R(h)]≤Eh∼Q/bracketleftBigg
1
mm/summationdisplay
i=1/parenleftbigg
/lscript(h,zi) +1
2m1−α/lscript(h,zi)2/parenrightbigg/bracketrightBigg
+KL(Q,P) + log(1/δ)
mα+1
2m1−αEh∼Q[K2(h)].
Proof.The proof is a straightforward application of Thm. 2.3 by ﬁxing m≥1choosingλ=mα−1(thus we
localise Thm. 2.3 to a single m), and bounding Quad(h)byK2(h).
The main improvement of our bound over Thm. A.3 is that we do not have to assume the convergence of
an exponential moment to obtain a non-trivial bound. Indeed, we transformed the (implicit) assumption
Eh∼P/bracketleftBig
exp/parenleftBig
K(h)2
2m1−2α/parenrightBig/bracketrightBig
<+∞ontoEh∼Q[K(h)2]<+∞, which is signiﬁcantly less restrictive. Furthermore,
Thm. A.3 holds for a single choice of mwhile ours still holds uniformly over all integers m> 0.
Cor. B.3 also sheds new light on the HYPEcondition. Indeed, in Haddouche et al. (2021), Konly intervenes
in an exponential moment involving the prior P, while ours considers a second-order moment on Kimplying
the posterior Q. The diﬀerence is major as Eh∼Q[K(h)2]can be controlled by a wise choice of posterior.
Thus it can be incorporated in our optimisation route, acting now as an optimisation constraint instead of
an environment constraint.
C Proofs
C.1 Proof of Thm. 2.3
Proof.LetPa ﬁxed data-free prior, set (Fi)i≥0such that for all i,ziisFimeasurable. We also set for any
ﬁxedh∈H,Mm(h) :=/summationtextm
i=1/lscript(h,zi)−R(h). Note that because data are iid, for any ﬁxed h, the sequence
(Mm(h))mis indeed a martingale. We set for any m≥1,h∈H
[M]m(h) =m/summationdisplay
i=1(/lscript(h,zi)−R(h))2
and
/angbracketleftM/angbracketrightm(h) =m/summationdisplay
i=1Ei−1[(/lscript(h,zi)−R(h))2] =m/summationdisplay
i=1Ez∼µ[(/lscript(h,z)−R(h))2].
19Published in Transactions on Machine Learning Research (04/2023)
The last equality holds because data is assumed iid. Thus, we can apply Thm. 2.1 to obtain with probability
1−δ
|Mm(Q)|≤KL(Q,P) + log(2/δ)
λ+λ
2/parenleftbig
[M]m(Q)2+/angbracketleftM/angbracketrightm(Q)2/parenrightbig
.
Now, we notice that |Mm(Q)|=m|Eh∼Q[R(h)−Rm(h)]|and that for any m,h, because/lscriptis nonnegative
[M]m(h) +/angbracketleftM/angbracketrightm(h) =m/summationdisplay
i=1(/lscript(h,zi)−R(h))2+Ez∼µ[(/lscript(h,z)−R(h))2]
≤m/summationdisplay
i=1/lscript(h,zi)2+R(h)2+Ez∼µ[/lscript(h,z)2]−R(h)2.
Thus integrating over hgives:
[M]m(Q) +/angbracketleftM/angbracketrightm(Q)≤m/summationdisplay
i=1Eh∼Q[/lscript(h,zi)2] +mEh∼Q[Quad(h)].
Then dividing by mand applying the last inequality gives
Eh∼Q[R(h)]≤Eh∼Q/bracketleftBigg
1
mm/summationdisplay
i=1/parenleftbigg
/lscript(h,zi) +λ
2/lscript(h,zi)2/parenrightbigg/bracketrightBigg
+KL(Q,P) + log(2/δ)
λm+λ
2Eh∼Q[Quad(h)].
This concludes the proof.
C.2 Proof of Thm. 4.1
Proof.Let (λm)i≥1be a countable sequence of positive scalars. As precised earlier Mm(a) :=
m/parenleftBig
ˆ∆m(a)−∆(a)/parenrightBig
is a martingale. We then apply Thm. 2.1 with the uniform prior ( ∀a,P(a) =1
K)
andλ=λm(depending possibly on m): with probability 1−δ/2, for any tuple (m,λm)withm≥1, any
posteriorQ,
|Mm(Q)|≤KL (Q,P) + 2 + log(4 /δ)
λm+λm
2/parenleftBig
ˆVm(Q) +Vm(Q)/parenrightBig
.
Notice that for any Q,KL(Q,P)≤log(K)by concavity of the log. We now ﬁx an horizon M > 0, we then
have in particular, with probability 1−δ/2: for any posterior Q,
|Mm(Q)|≤log(K) + 2 log(k+ 1) + log(4 /δ)
λk+λm
2/parenleftBig
ˆVm(Q) +Vm(Q)/parenrightBig
.
We now have to deal with Vk(Q),ˆVk(Q)for allk≤m. To do so, we propose the two following lemmas.
Lemma C.1. For allm≥1,a∈A,Vm(a)≤2Cm
εm. Then, we have for any m,Q,Vm(Q)≤2Cm
εm.
Proof.We have
Vt(a) =m/summationdisplay
i=1E/bracketleftbigg/parenleftBig/bracketleftBig
Ra∗
i−Ra
i/bracketrightBig
−∆(a)/parenrightBig2
|Fi−1/bracketrightbigg
=m/summationdisplay
i=1E/bracketleftbigg/parenleftBig
Ra∗
i−Ra
i/parenrightBig2
|Fi−1/bracketrightbigg
−m∆(a)2
≤m/summationdisplay
i=1E/bracketleftbigg/parenleftBig
Ra∗
i−Ra
i/parenrightBig2
|Fi−1/bracketrightbigg
=m/summationdisplay
i=1E/bracketleftbigg
EAi∼πiERi/bracketleftbigg1
πi(a∗)2Ri(a∗)21(Ai=a∗) +1
πi(a)2Ri(a)21(Ai=a)/bracketrightbigg
|Fi−1/bracketrightbigg
.
20Published in Transactions on Machine Learning Research (04/2023)
The last line holding because Riis independent of Fi−1,Aiis independent of RiandπisFi−1measurable.
We now use that for all i,a,ERi[Ri(a)2]≤C
=m/summationdisplay
i=1E/bracketleftbigg
EAi∼πi/bracketleftbigg1
πi(a∗)2C1(Ai=a∗) +1
πi(a)2C1(Ai=a)/bracketrightbigg
|Fi−1/bracketrightbigg
=m/summationdisplay
i=1C/parenleftBigg
πi(a)
πi(a)2+πi(a∗)
πi(a∗)2/parenrightBigg
=m/summationdisplay
i=1C/parenleftbigg1
πi(a)+1
πi(a∗)/parenrightbigg
≤2Cm
εm.
Lemma C.2. Letm≥1, with probability 1−δ/2, for any posterior Q, we have
ˆVm(Q)≤4CKm
εmδ.
Proof.LetQa distribution over A. Recall that
ˆVm(Q) =m/summationdisplay
i=1/parenleftBig
Ra∗
i−Ra
i−[R(a∗)−R(a)]/parenrightBig2
=/summationdisplay
a∈AQ(a)ˆVm(a).
Notice that for any a,(ˆSMa
m)mis a nonnegative random variable. We then apply Markov’s inequality for
anya, with probability 1−δ/2K
ˆVm(a)≤2KE[ˆVm(a)]
δ.
Noticing that E[ˆVm(a)] =E[Vm(a)], we can apply Lemma C.1 to conclude that
E[ˆVm(a)]≤2Cm
εm.
Finally, taking an union bound on thoser events for all a∈Agives us, with probability 1−δ/2, for any
posteriorQ
Vm(Q)≤/summationdisplay
a∈AQ(a)ˆVm(a)
≤/summationdisplay
a∈AQ(a)4CKm
εmδ
=4CKm
εmδ.
This concludes the proof.
To conclude, we apply Lemmas C.1 and C.2 to get that with probability 1−δ, for any posterior Q
|Mm(Q)|≤KL (Q,P) + log(4/δ)
λm+Cmλm
εm/parenleftbigg
1 +2K
δ/parenrightbigg
.
21Published in Transactions on Machine Learning Research (04/2023)
Dividing by mand taking
λm=/radicalBigg
(log(K) + log(4/δ))εm
Cm/parenleftbig
1 +2K
δ/parenrightbig
concludes the proof.
C.3 Proof of Cor. B.1
Proof.Fixδ>0. For any pair (λk,Pk),k≥1, we apply Thm. 2.1 with
δk:=δ
k(k+ 1)≥δ
(k+ 1)2.
Notice that we have/summationtext+∞
k=1δk=δ. We then have with probability 1−δkoverS, for anym≥1, any posterior
Q,
|Mm(Q)|≤KL(Q,Pk) + 2 log(k+ 1) + log(2 /δ)
λk+λk
2/parenleftBig
ˆVm(Q) +Vm(Q)/parenrightBig
.
Taking an union bound on all those event, gives the ﬁnal result, valid with probability 1−δover the sample
S, for any any tuple (m,λk,Pk)withm,k≥1, any posterior QoverH. This gives Eq. (6).
To obtain Eq. (7), we restrict the range of Eq. (6) to the tuples (m,λm,Pm),m≥1(the restricted set of
tuples where k=m) and we bound both ˆVm(Q),Vm(Q)by/summationtextm
i=1C2
ito conclude.
C.4 Proof of Cor. B.2
Proof.For the ﬁrst bound we start from the intermediary result Eq. (3) of Thm. 2.1. Using the same
marrtingale as in Thm. 2.3 gives, for any η∈R, holding with probability 1−δfor anym> 0,Q∈M+
1(H)
η/parenleftBiggm/summationdisplay
i=1Eh∼Q[/lscript(h,zi)]−mEh∼Q[R(h)]/parenrightBigg
≤KL(Q,P) + log(1/δ) +η2
2m/summationdisplay
i=1Eh∼Q[∆[M]i(h) + ∆/angbracketleftM/angbracketrighti(h)].
Takingη=±λwithλ>0gives
λm|Eh∼Q[R(h)−Rm(h)]|≤KL(Q,P) + log(1/δ) +λ2
2m/summationdisplay
i=1Eh∼Q[∆[M]i(h) + ∆/angbracketleftM/angbracketrighti(h)].(8)
Finally, divide by λmand bound ∆[M]i(h) + ∆/angbracketleftM/angbracketrighti(h)by2K2to conclude.
For the second bound, we start from Eq. (8) again and for a ﬁxed m, we now apply our result with λ/prime=λ/m.
We then have for any m, with probability 1−δ, for anyQ
λ|Eh∼Q[R(h)−Rm(h)]|≤KL(Q,P) + log(1/δ) +λ2
2m2m/summationdisplay
i=1Eh∼Q[∆[M]i(h) + ∆/angbracketleftM/angbracketrighti(h)].
Finally, dividing by λ, bounding ∆[M]i(h) + ∆/angbracketleftM/angbracketrighti(h)by2K2and rearranging the terms concludes the
proof.
22