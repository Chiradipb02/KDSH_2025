Under review as submission to TMLR
Group Fair Federated Learning via Stochastic Kernel Regu-
larization
Anonymous authors
Paper under double-blind review
Abstract
Ensuringgroup fairness in federated learning (FL) presents unique challenges due to data
heterogeneity and communication constraints. We propose Kernel Fair Federated Learning
(KFFL), a novel framework that incorporates group fairness into FL models using the Ker-
nel Hilbert-Schmidt Independence Criterion (KHSIC) as a fairness regularizer. To address
scalability, KFFLapproximates KHSIC with Random Feature Maps (RFMs), significantly
reducing computational and communication overhead while achieving group fairness .
To address the resulting non-convex optimization problem, we propose FedProxGrad , a fed-
erated proximal gradient algorithm that guarantees convergence. Through experiments on
standard benchmark datasets across both IID and Non-IID settings for regression and clas-
sification tasks, KFFLdemonstrates its ability to balance accuracy and fairness effectively,
outperforming existing methods by comprehensively exploring the Pareto Frontier. Further-
more, we introduce KFFL-TD, a time-delayed variant that further reduces communication
rounds, enhancing efficiency in decentralized environments.
1 Introduction
Unintended unfairness in machine learning models poses significant challenges, particularly in decision-
making processes that impact specific population groups Dwork et al. (2012a); Agarwal et al. (2019b); Jalal
et al. (2021). For instance, the COMPAS software, used in judicial decision-making for criminal offenses, has
beenshowntoyieldunjustoutcomesdisproportionatelyaffectingtheAfricanAmericancommunityDressel&
Farid (2018); Barenstein (2019). Such findings underscore the need for model outputs to be fair with respect
to protected demographic attributes like gender and race. Ensuring demographic fairness has therefore
emerged as a critical challenge in machine learning, driving efforts to develop robust solutions for mitigating
bias and ensuring equitable model deployment.
Recent advances in bias mitigation algorithms Jalal et al. (2021); Correa et al. (2021); Agarwal et al. (2019b);
Memarrastetal.(2023)largelydependonfairnessregularizersincorporatedintothetrainingobjective, which
typically requires centralized access to data. However, in federated learning (FL) Li et al. (2020), where
data is distributed across clients, privacy regulations and bandwidth constraints often prohibit raw data
sharing, making centralized approaches to group fairness impractical. Furthermore, implementing fairness
regularizers in the distributed FL setting presents additional challenges, including communication overhead,
computational costs, and data heterogeneity, all of which complicate training a globally fair model.
Consequently, prior efforts to achieve group fairness in federated settings have primarily focused on aligning
local and global fairness metrics Ezzeldin et al. (2023); Papadaki et al. (2022), often avoiding the direct in-
corporation of regularizer terms to ensure statistical group fairness. However, this approach faces theoretical
challenges, as no universally consistent evaluation metric exists to enforce group fairness across all clients.
Additionally, applying local debiasing mechanisms at individual clients alone is inadequate to ensure group
fairness in the globally trained model.
In the literature, fair federated learning often uses the terms client fairness andgroup fairness inter-
changeably. However, these concepts address distinct objectives. Works such as Chaudhury et al. (2022);
1Under review as submission to TMLR
Figure 1: FedAvgcan result in models whose predictions are biased with respect to sensitive attributes such
as race or gender. KFFLis a principled approach designed specifically to mitigate demographic bias when
training a model in a distributed setting.
Li et al. (2019); Donahue & Kleinberg (2021); Cui et al. (2021); Du et al. (2021) focus on client fairness
in federated learning, aiming to ensure that the model performs equitably across clients’ data Mohri et al.
(2019), thereby mitigating disparities arising from data heterogeneity among clients. In contrast, group
fairness Ezzeldin et al. (2023); Papadaki et al. (2022) seeks to achieve fairness across different demographic
groups. This involves establishing performance guarantees to ensure the global model is fair with respect to
sensitive attributes, such as race or gender. More discussion on the related works is available in the Appendix
A.1. This work aims to address the latter objective ie: group fairness in the trained global model.
Particularly, we propose a novel approach that integrates the Kernel Hilbert-Schmidt Independence Criterion
(KHSIC) Gretton et al. (2005b) as a fairness regularizer into FL. KHSIC is a powerful measure of statistical
dependence capable of capturing complex, non-linear relationships between variables, making it well-suited
for enforcing group fairness
Why Choose KHSIC? The Hilbert-Schmidt Independence Criterion (HSIC) has been effectively used as a
fairness regularizer in centralized regression models, as demonstrated in Pérez-Suay et al. (2017). KHSIC, a
kernelized version of HSIC, stands out due to its ability to capture complex, nonlinear dependencies among
random variables through the use of kernel functions. Additionally, KHSIC provides a theoretical guarantee:
a low KHSIC value between model outputs and sensitive attributes ensures approximate statistical parity
Kim & Gittens (2021).Compared to the closely related Rényi correlation Baharlouei et al. (2019b), KHSIC
is more practical for measuring dependence because its empirical computation reduces to straightforward
linear algebra operations. This makes KHSIC not only theoretically robust but also computationally efficient
in practical applications.
However, directly applying KHSIC in a federated learning (FL) setup presents challenges, as it is compu-
tationally expensive and communication-intensive due to the necessity of computing and exchanging large
kernel matrices. To address these limitations, we leverage Random Feature Maps (RFMs) Rahimi & Recht
(2007) to approximate kernel functions. This approximation significantly reduces both computational and
communication costs, making the integration of KHSIC as a fairness regularizer more feasible and efficient
in federated learning setting.
Furthermore, to efficiently solve the distributed optimization problem incorporating the fairness regularizer,
we propose FedProxGrad , a federated proximal gradient algorithm. This method ensures convergence for
non-convex composite optimization problems that arise from the integration of the fairness term.
Our main contributions are as follows:
•We propose KFFL, a novel federated learning algorithm that incorporates group fairness using KHSIC
as a fairness regularizer. To the best of our knowledge, this is the first work to adapt KHSIC for use
in federated learning, addressing the unique challenges of the federated setting.
2Under review as submission to TMLR
•We develop a communication-efficient approximation using Random Feature Maps to reduce the
computational and communication overhead associated with KHSIC. This allows us to avoid trans-
mitting large kernel matrices, reducing communication costs by orders of magnitude.
•We introduce FedProxGrad , a federated proximal gradient algorithm that provides convergence
guarantees for non-convex composite optimization problems. FedProxGrad allows both terms of the
compositeobjectivetobenon-convex, asopposedtopriorworksonfederatedcompositeoptimization
Wang & Li (2023); Bao et al. (2022); Yuan et al. (2021); Tran Dinh et al. (2021).
•We conduct extensive experiments on standard benchmark datasets under both IID and Non-IID
data distributions on both classification and regression tasks. Our results demonstrate that KFFL
effectively balances the trade-off between accuracy and fairness, outperforming existing baselines
and exploring the Pareto frontier more comprehensively.
•We analyze the communication overhead of KFFLand introduce a time-delayed variant, KFFL-TD,
which further reduces communication rounds while maintaining performance. This makes our
method more practical for real-world FL applications where communication resources are limited.
2 Preliminaries
The goal of fair learning is to ensure that the model’s output exhibits no dependencies on sensitive attributes.
We assume the observations are sampled i.i.d. from a joint distribution P(X,S,Y )to obtain training data
{xi,si,yi}n
i=1. Here, xicontains the non-sensitive covariates, sicontains sensitive covariates (which may be
a binary scalar sior multi-dimensional vector si), andyiis the ground truth label for the i-th sample. This
dataset is employed to train a classifier f(x;ω), whereωdenotes the model parameters.1
As an example, consider the task of training a binary classifier for making hiring decisions. Here xconsists
of features that are ethically and legally allowable for use in making hiring decisions, srepresents binary
sensitive features such as the individual’s sex or marital status, and the ground truth decisions are yi∈{0,1}.
The classifier makes predictions ˆyi=f(xi;ω)∈{0,1}, where 1signifies a decision to hire.
2.1 Metrics for Group Fairness
The two most widely used definitions of group fairness for evaluating classifier fairness Ezzeldin et al. (2023)
are statistical parity and equalized odds Dwork et al. (2012a). These measures aim to assess equitable
treatment across protected groups in trained models.
•Statistical Parity Difference (SPD) : A model achieves statistical parity when the probability
of a positive outcome is independent of the sensitive variable Dwork et al. (2012b), i.e., ˆy⊥ ⊥s. In
the context of binary sensitive variables, a measure of statistical parity is given by
SPD = Pr(ˆy= 1|s= 1)−Pr(ˆy= 1|s= 0). (1)
•Equalized Odds (EOD) : A model satisfies equalized odds when the true positive rates do not
depend on the sensitive variable Romano et al. (2020). In the context of binary sensitive variables,
a measure of equalized odds is given by
EOD = Pr(ˆy= 1|y= 1,s= 1)−Pr(ˆy= 1|y= 1,s= 0). (2)
Equalizedoddsandstatisticalparityvaluesclosertozeroindicatethatthemodelisfair(withrespecttothose
particular definitions). We develop our framework in the context of SPD but, as is common in the literature,
1We follow the notation convention where boldface lowercase letters (e.g., v) denote vectors, non-bold lowercase letters (e.g.,
v) represent scalars, and boldface uppercase letters (e.g., M) signify matrices. For example, in the equation v=Mu +b,vand
uare vectors, Mis a matrix, and bis a scalar.
3Under review as submission to TMLR
utilize both these notions in measuring its performance empirically in Section 5 when the underlying model
is a classifier.
Fairregressionhasbeenextensivelystudiedincentralizedsettings, withnotablecontributionssuchasChzhen
et al. (2020a); Agarwal et al. (2019a); Chzhen et al. (2020b). However, training regression models in dis-
tributed settings, where the target variable ˆyis continuous, remains an underexplored area. Traditional
fairness metrics like Equalized Odds (EOD) andStatistical Parity Difference (SPD) are not directly
applicable in this context. Instead, the Kolmogorov-Smirnov (KS) distance is commonly employed to
evaluate fairness. This metric captures the maximum disparity between the distributions of model predic-
tions for different sensitive groups, providing a robust measure for regression tasks (see Appendix F for more
details).
•Kolmogorov-Smirnov (KS) Distance Chzhen et al. (2020a):
Foreachsensitivegroup s∈S, letthesetofindicesofsamplesbelongingtothatgroupberepresented
as:
Is={i∈{1,2,...,n}:si=s}.
The empirical cumulative distribution function (CDF) of the model predictions for group sis defined
as:
Fs(t;ω) =1
|Is|/summationdisplay
i∈Is1{f(xi;ω)≤t}, (3)
wheref(xi;ω)is the model’s prediction for input xiparameterized by ω.
The KS distance between the predictions for any two sensitive groups sands′is given by:
KS(ω) = max
s,s′∈Ssup
t∈R/vextendsingle/vextendsingle/vextendsingleFs(t;ω)−Fs′(t;ω)/vextendsingle/vextendsingle/vextendsingle. (4)
TheKSdistancemeasuresthelargestdifferencebetweentheCDFsofpredictionsforanytwosensitive
groupssands′. A smaller KS value indicates lower disparity between groups, supporting fairness
objectives in regression tasks.
2.2 Kernel Hilbert-Schmidt Independence Criterion (KHSIC)
The Kernel Hilbert-Schmidt Independence Criterion ( KHSIC) of Gretton et al. (2005a) is key to our ap-
proach to ensuring statistical parity. The KHSIC is predicated on the observation that ˆyandsare indepen-
dent if and only if everyfunction of ˆyis uncorrelated with everyfunction of s.
Given two Reproducing Kernel Hilbert Spaces FandG, the KHSIC quantifies the dependence of these
random variables by measuring the correlation of every function of ˆyinFwith every function of sinG:
ψpop(ˆy,s) = sup
h∈F,g∈G
∥h∥2
F≤1,∥g∥2
G≤1Cov(h(ˆy),g(s)). (5)
Under some regularity conditions on FandG(universality), this population KHSIC is zero if and only if ˆy
andsare independent. More generally, the population KHSIC gives an upper bound on the total variation
distance between the joint distribution Pˆy,sand the product of the marginals Pˆy⊗Ps, and thus quantifies
the dependence of ˆyandsKim & Gittens (2021).
The KHSIC is more practically useful as a measure of dependence than the closely related Rényi correlation:
the latter is defined in terms of the probability density functions (PDFs) of ˆyands. This approach does not
scale to high-dimensional inputs because accurately estimating the PDFs of ˆyandsrequires an exponential
number of observations relative to their dimensionality. By comparison, empirical estimation of the KHSIC
reduces to simple and scalable linear algebraic computations. The empirical KHSIC is given by Gretton
et al. (2005a)
ψemp(ˆy,s) =1
(n−1)2Tr/parenleftbig
HKsH2KˆyH/parenrightbig
, (6)
4Under review as submission to TMLR
where
Kˆy= [κˆy(ˆyi,ˆyj)]n
i,j=1,Ks= [κs(si,sj)]n
i,j=1,H=I−1
n11⊤.
The matrices KˆyandKsaren×nkernel matrices evaluated on the training data corresponding to the
kernels.2Gretton et al. (2005a) show that ψemp(ˆy,s)is a1√n-consistent estimator of ψpop(ˆy,s).
We propose to measure the fairness (in the sense of statistical parity) of models by using the KHSIC:
ψ(ω;X,S) =1
(n−1)2Tr (HKsHK ˆyH). (7)
The notation ψ(ω;X,S)emphasizes that the fairness measure depends on ωthrough the predictions ˆy=
f(X;ω).
2.3 Fair Learning Objective
Consequently, we propose to learn fair models by using ψ(ω;X,S)as a regularizer:
ω⋆=argminω1
nn/summationdisplay
i=1ℓ(yi,f(xi;ω)) +λψ(ω;X,S). (8)
The first term in the objective function represents the loss ℓ(yi,f(xi;ω)), which quantifies the discrepancy
between the model’s predictions and the ground truth labels. This loss function can be instantiated as the
cross-entropy loss for classification tasks or the mean squared error (MSE) for regression tasks. The second
term acts as a fairness regularizer by measuring the dependence between the model’s predictions and the
sensitive attributes using the KHSIC criterion. The regularization parameter λcontrols the trade-off between
optimizing predictive performance and enforcing fairness, thereby balancing the two objectives.
Solving Equation (8) in a centralized setting is conceptually straightforward but computationally challenging
because, at each iteration, it involves computing matrices Kˆy(ω)of sizen×nand computing gradients
through them. The computational burden is compounded in the federated learning setting by the additional
communicationburden: clientsneedtocommunicatethese n×nmatricestocomputetheirlocalcontributions
to the gradients. Hence, a straightforward adaptation of this centralized approach to a distributed setting is
prohibitive from the perspectives of both computation and communication. In the next section (Section 3),
we introduce a novel method FedProxGrad to overcome these challenges in the federated setting.
3 Composite Optimization in the Federated Setting
Employing the fair ML formulation of equation (8) in a federated setting requires solving a federated com-
posite optimization (FCO) problem that can be written in the standard form
argminωm/summationdisplay
i=1ℓi(ω) +ψ(ω),
where theℓiare data-fitting terms local to each client, and ψis the global fairness regularizer. For brevity,
we have absorbed the regularization constant λintoψ. We denote the sum of local-data fitting terms
withℓ(ω) =/summationtextm
i=1ℓi(ω)and the composite objective with F(ω) =ℓ(ω) +ψ(ω). In Equation (8) the fairness
termψis non-convex and the data fitting term, ℓ, may also be non-convex. The next section (Section 4)
shows how to reduce the communication complexity involved in using a kernel-based fairness regularizer for
ψ. This section provides an algorithm for solving the resulting non-convex FCO problem.
Several existing works provide algorithms for the FCO problem–Wang & Li (2023); Bao et al. (2022); Yuan
et al. (2021) develop algorithms that require the ℓiandψto be convex, while the algorithm of Tran Dinh
2For notational brevity, we use the notation κto refer to two potentially different kernel functions on the features and the
sensitive variables.
5Under review as submission to TMLR
Algorithm 1 Federated Proximal Gradient Descent ( FedProxGrad )
1:Input:ω0,T,α
2:fort= 0,···,T−1do
3: Server computes gt, a stochastic gradient estimator for ∇ψ(ωt), and computes ωt+1/2=ωt−αgt
4: Server sends ωt+1/2to clients
5: Each client for i∈{1,...,m}computes
ωi
t+1=argminωℓi(ω) +1
2α∥ω−ωt+1/2∥2
2
6: Each client returns ωi
t+1back to the server
7: Server aggregates the device models to form
ωt+1=1
mm/summationdisplay
i=1ωi
t+1.
8:end for
et al. (2021) requires only ψto be convex—but, to our knowledge, no extant optimization algorithms for
FCO guarantees convergence for problems where the ℓiandψare both non-convex. To fill this gap, we
introduce FedProxGrad , a federated proximal gradient descent algorithm.
The FedProxGrad algorithm, described in Algorithm 1, extends the stochastic proximal gradient algorithm in
astraightforwardmannerfromthecentralizedsettingtothefederatedsetting. Theanalysisofitsconvergence
follows closely that of FedProx, so we introduce the same notions used in its convergence Li et al. (2020).
Definition 1 (γ-suboptimality) .Letℓi
t(ω) =ℓi(ω)+1
2α∥ω−ωt+1/2∥2(see Algorithm 1 for the definition of
ωt+1/2). Givenγ∈[0,1], a point/hatwideωis aγ-suboptimal solution of argminωℓi
t(ω)if∥∇ℓi
t(/hatwideω)∥≤γ∥∇ℓi
t(ωt)∥.
Smallerγcorrespond to higher accuracy.
This condition on the local solvers ensures that the local solution for the (t+ 1)th iterate is a factor of γless
suboptimal than the tth iterate. This condition is agnostic to the particular solvers employed, and can be
achieved using an deterministic or randomized solvers that use full gradients or stochastic gradients.
Definition 2 ((G,B)-Bounded Dissimilarity) .The local functions ℓiare(G,B)-boundedly dissimilar at ω
ifEi∥∇ℓi(ω) +∇ψ(ω)∥2≤B2∥∇F(w)∥2+G2.
This condition is standard Li et al. (2020); Karimireddy et al. (2020), and ensures that local progress on the
individual clients can be translated to global progress.
The definition of γ-suboptimality and the bounded dissimilarity condition have been modified from those
used in Li et al. (2020) to facilitate the analysis of a composite objective
Theorem 1. Assume that the functions ℓi,ψ, andFareL-smooth; the functions ℓiareL−-weakly convex;
Fis bounded below by a constant F⋆; the bounded dissimilarity condition (Definition 2) holds with G= 0;
and that the stochastic gradient estimate for the fairness regularizer satisfies E[gt|ωt] =∇ψ(ωt)and
E[∥gt−∇ψ(ω)∥2
2|ω]≤σ2
for allω. If the local solvers on each client ensure γsuboptimal solutions (Definition 1) with parameter
γ≤1
8(B+1)and the global stepsize is chosen to satisfy
α<min/braceleftbigg1
20,1
2L−,1
120L(B+ 1),1
5LB2/bracerightbigg
,
then the sequence of iterates generated by FedProxGrad satisfies
1
TT−1/summationdisplay
t=0E/bracketleftbig
∥∇F(ωt)∥2
2/bracketrightbig
≤F(ω0)−F⋆
αT+ 4σ2.
6Under review as submission to TMLR
This result shows that, for an appropriate choice of hyperparameters, the FedProxGrad algorithm converges
at a rate of1
Tup to the noise level of the stochastic gradient. A proof is provided in the Appendix A.2
4 Communication-Efficient Kernel Regularized Fair Learning
Random Feature Maps for Kernel Approximation:
In the centralized setting, kernel methods pose a computational challenge due to their inherent complexity,
requiring optimization with a kernel matrix incurring a computational cost of up to O(n3). One line of
research for reducing this burden, starting with the seminal work of Rahimi & Recht (2007), uses random
feature maps (RFMs). A random feature map for a shift-invariant kernel function κis a random function
ϕ:Rp→RDthat is constructed to satisfy κ(x,y) =E⟨ϕ(x),ϕ(y)⟩for any two vectors xandy, where the
expectation is taken over the randomness in ϕ. RFMs enable the efficient formation of randomized low-rank
approximations to kernel matrices. In particular, if the rows of ZS∈Rn×Dconsist of the application of an
RFMϕto the si, and the rows of Zf(ω)∈Rn×Dlikewise consist of the application an RFM to the observed
xi, then
KS=E[ZSZT
S]and Kf(ω)=E[Zf(ω)ZT
f(ω)], (9)
and the variance goes down as the number of random features Dincreases, so ZSZT
SandZf(ω)ZT
f(ω)are
principled randomized low-rank approximations to the corresponding kernel matrices. A substantial body of
work has demonstrated that these approximations exhibit theoretically and empirically similar performance
to full kernel matrices (Hamid et al., 2014; Rahimi & Recht, 2007; Yu et al., 2016).More discussion on the
construction and drawing of these feature maps is also made in Appendix G
Approximation of the Fairness Regularizer: We utilize these randomized low-rank approximations to
efficiently compute principled approximations to the regularizer ψ(ω)in Equation 8. Note that Zf(ω)and
ZShave dimensions n×Dand thatD≪nin size. Specifically, we utilize the Orthogonal Random Feature
Maps (ORFM) of (Yu et al., 2016).
The first crucial observation is that by using RFMs, one need only communicate a D×Dmatrix to approx-
imateψ(ω)(see Theoram 2) and its gradient g(ω)(see Corollary 1) , rather than communicating two n×n
kernel matrices. For proof refer to the Appendix A.3 and A.5 respectively.
Theorem 2. LetZfandZsben×Dmatrices constructed using RFMs. Then ψ(ω) =E/bracketleftbig
∥G(ω)∥2
F/bracketrightbig
where
G(ω) =Z⊤
sZf(ω)−nµsµ⊤
f(ω)∈RD×D. Here,µsis the mean over the rows of Zsandµfis the mean over
the rows of Zf(ω).
Corollary 1. g(ω) =∇∥G(ω)∥2
Fis an unbiased stochastic estimate of ∇ψ(ω).
Distributed Computation in Federated Settings:
In a distributed setup the RFM matrices can be partitioned over the mworkers as follows:
Zf(X)=
Zf(X),1
...
Zf(X),m
and ZS=
ZS,1
...
ZS,m
, (10)
where Zf(X),i,ZS,i∈Rni×D. Hereniis the number of data points on worker i, son=/summationtextm
i=1ni. This
observation allows each worker to efficiently compute its contribution to the feature interaction matrix
G(ω).
Lemma 1. The global feature interaction matrix can be partitioned into local interactions as G(ω) =/summationtextm
i=1Z⊤
s,iZf,i−n/parenleftbig1
n/summationtextm
i=1niµs,i/parenrightbig/parenleftbig1
n/summationtextm
i=1niµf,i/parenrightbig⊤
Therefore, using Lemma 1 (see Proof in A.4), to compute the global interaction term G(ω), each worker only
needs to transmit the local feature interaction matrix Z⊤
s,iZf,i∈RDs×Df, along with its local average feature
vectorsµs,i∈RDsandµf,i∈RDfto the server. Since empirically we use the same size of DsandDfwe
7Under review as submission to TMLR
drop the subscript in our discussion. This approach facilitates the computation of G(ω)and, consequently,
g(ω)using Lemma 2 (see Proof in A.6).
Lemma 2. An unbiased estimate of the gradient of fairness regularizer ψcan be partitioned into local
interactions as g(ω) =/summationtextm
i=1JΩi(ω)TG(ω), where Ωi(ω) =Z⊤
sZf,i(ω)−niµsµ⊤
fandJΩi(ω)is the Jacobian
ofΩiwith respect to the model parameters ω.
Communication Efficiency using RFMs : Therefore, instead of transmitting n×nmatrices, only D×D
matrices need be sent to compute unbiased approximations to ψand∇ψ. This results in a substantial
reduction in communication costs. For instance, consider training a fair model on the ADULT dataset
(n= 32K). Choosing D= 1024( numbers based on our experimental evaluations) with equal partitioning
of data points, computing ψexactly requires communicating 32K×32Kmatrices, compared to 1024×1024
matrices when RFMs are employed, so the communication costs are reduced by three orders of magnitude!
Table 1: Table that explains the notations used in KFFLAlgorithm
Symbol Description
x Data parameter vector
ω Model parameter vector
Mi(ω)Interaction matrix for client i
µs Global mean sensitivity vector
µf Global mean function vector
µs,i Local mean sensitivity vector for client i
µf,i Local mean function vector for client i
Ωi(ωt)Local interaction matrix for client i
fi(ωt)Local data fitting term for client i
γt Parameter for regularization
Z Random Feature Map Matrix
Ds Dimensions of the protected attribute feature map matrix
Df Dimensions of the logits feature map matrix
JΩi(ω)Jacobian of Ωiatω
G(ω)Gradient vector at ω
G(ω) =Z⊤
sZf(ω)−nµsµ⊤
f(ω)
Mi(ω) =Z⊤
sZf,i(ω)
µs=/parenleftigg
1
nm/summationdisplay
i=1niµs,i/parenrightigg
µf=/parenleftigg
1
nm/summationdisplay
i=1niµf,i/parenrightigg⊤
µ⊤
s,i=1
ni1⊤Zs,i
µ⊤
f,i=1
ni1⊤Zf,i
ωt+1=argminω/bracketleftbigg
fi(ωt) +1
2αt∥ω−ωt∥2
2/bracketrightbigg
Ωi(ω) =Mi(ω)−niµsµ⊤
f
gi(ω) =JΩi(ω)TG(ω)Equations used in KFFL/KFFL-TD
(11)
(12)
(13)
(14)
(15)
(16)
(17)
(18)
(19)
8Under review as submission to TMLR
DATA FAIR1 FAIR2Legend
Figure 2: The communication pattern for KFFL. Different colors correspond to the FAIR1,FAIR2 and
DATAsub-rounds of KFFL. The direction of the arrows indicate an uplink or downlink communication and
the width of each arrowhead highlights the communication cost in each sub-round. Thicker lines indicate
(large) communication costs on the order of the size of ω, while thinner lines represent communication costs
on the order of D2.
Kernel Regularized Fair Federated Learning KFFL
We now introduce the KFFLalgorithm, which uses the FedProxGrad method to implement kernel-regularized
fair learning using the approximation to ψintroduced in the previous section. A time-delayed variant that
uses stale fairness gradient information to incur one less round of communication per iteration, KFFL-TD, is
presented in Appendix C.
Algorithm 2 KFFL– Client Side
Input :(ROUND,..)
1:if ROUND =FAIR1 then
2: Clients compute Mi(ωt)(see Equation 12) using shared random seed ζto generate their RFM, µf,i(t)using
Equation 16 and µs,i(t)using Equation 15.
3: Combine terms Φi(ωt) ={Mi(ωt),µs,i,µf,i}
4:Return :Φi(ωt)
5:else if ROUND =FAIR2 then
6: Client compute local interaction for gradients using Equation 18 to get Ωi(ωt)
7: The clients then compute the local gradient gi(ωt)using Equation 19 from Λ(ωt)
8:Return :gi(ωt)
9:else if ROUND =DATA then
10: Clients do a local update on ωt+1/2following Equation 17 to get ωi
t+1
11: Return :ωi
t+1
12:end if
The KFFLalgorithm is detailed in Algorithm 2, which gives the client-side procedure, and Algorithm 3, which
gives the server-side process. Equations 11 till 19 are used in these algorithms. At a high level, KFFLuses
federated composite optimization to fit a fair model in three rounds:
FAIR1 At the start of the t+ 1-th iteration, the clients use the RFMs to compute the local terms Φi(ωt)
needed to compute the interaction matrix G(ωt)for the current global model ωt, and communicate
them to the server. Clients also store the local interaction term for next round Mi(ωt). The server
combines the local terms to compute the interaction matrix G(ωt)on the current global model, and
returns these to the workers.
9Under review as submission to TMLR
Algorithm 3 KFFL– Server Side
1:ω=ω0{This is the initial model}
2:t←0
3:whileωnot converged do
4:for alli= 1,...,m in parallel do
5: Generation of random seed ζ
6: Φi(ωt) =Client Update (FAIR1,ωt,ζ)
7:end for
8: Φ(ωt) ={Φi(ωt)}m
i=1
9: From Φ(ωt)compute G(ωt)using Equation 11 ; µs(t)using Equation 13 and µf(t)using Equation 14
10: for alli= 1,...,m in parallel do
11: Λ(ωt) ={FAIR2,G(ωt),µs(t)µf(t)⊤}
12: gi(ωt) =Client Update (Λ(ωt))
13: end for
14:ωt+1/2←ωt−/summationtextm
i=1gi(ωt)
15: for alli= 1,...,m in parallel do
16:ωi
t+1=Client Update (DATA,ωt+1/2)
17: end for
18:ωt+1←average/parenleftbig
ωi
t+1/parenrightbig
19:end while
FAIR2 Theworkersuse G(ωt),µs(t)µf(t)⊤fromtheserverandthelocalinteractionterm Mi(ωt)previously
computed to compute their contribution to the stochastic estimate of the fairness gradient and
communicate these to the server.
DATAThe rest of the iteration implements FedProxGrad : the server computes the gradient estimate for ψ
and sendsωt+1/2=ωt−gtto the clients, which locally update their models ωi
t+1and send them
back to the server, which then computes the next global model ωt+1.
For brevity, the time-delay variant KFFL-TD and its associated algorithms (Algorithms 4 and 5) are detailed
in Appendix C. The following section (5) evaluates the empirical performance of KFFLandKFFL-TD against
baseline federated learning algorithms designed to mitigate demographic bias, utilizing the fairness metrics
introduced in the Preliminaries. Furthermore, we examine the communication costs of KFFLand KFFL-TD
relative to these baselines.
5 Experimental Section
In this section, we evaluate the performance of our methods, KFFLand KFFL-TD, in achieving statistical
group fairness in a federated setting. Fairness is assessed using statistical parity and equalized odds for
classification models (see Equation 1 2 and the Kolmogorov-Smirnov (KS) 4 distance for regression models.
While most of the work in fair federated learning has explored fairness algorithms that aim to achieve client
parity / client fairness (i.e., consistent performance across clients) , such as in Cui et al. (2021) and Du
et al. (2021), it is essential to highlight that client parity algorithms do not directly target statistical
groupfairness reduction . Instead, they often achieve statistical groupfairness as a byproduct rather
Table 2: Communication measured in terms of the number of rounds required for one global update using
KFFL,KFFL-TD,FedAvg, and FairFed. Algorithms that incorporate fairness, such as FairFed, require a
similar number of communication rounds as our methods KFFLandKFFL-TD
Method Rounds of Communication
KFFL 3
KFFL-TD (Time Delay Variant) 2
Fair Fed Ezzeldin et al. (2023) 3
FedAvg 1
10Under review as submission to TMLR
0.00 0.05 0.10 0.15 0.20 0.25 0.30 0.35
Demographic Parity0.00.20.40.60.81.0AccuracyLow SPD Region High SPD Region
"Completely Fair" "Completely Unfair"Client data distribution: IID 
KFFL
KFFL_TD
FairFed
FedAvg
MinMax
FairFed_Kernel
0.00 0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40
Demographic Parity0.00.20.40.60.81.0AccuracyLow SPD Region High SPD Region
"Completely Fair" "Completely Unfair"Client data distribution: Non-IID 
KFFL
KFFL_TD
FairFed
FedAvg
MinMax
FairFed_Kernel
0.00 0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40
Demographic Parity0.00.20.40.60.81.0Accuracy
Centralized: Accuracy vs. Demographic Parity
0.0 0.1 0.2 0.3 0.4
Equalized Odds0.00.20.40.60.81.0AccuracyLow EOD Region High EOD Region
"Completely Fair" "Completely Unfair"Client data distribution: IID 
KFFL
KFFL_TD
FairFed
FedAvg
MinMax
FairFed_Kernel
0.0 0.1 0.2 0.3 0.4
Equalized Odds0.00.20.40.60.81.0AccuracyLow EOD Region High EOD Region
"Completely Fair" "Completely Unfair"Client data distribution: Non-IID 
KFFL
KFFL_TD
FairFed
FedAvg
MinMax
FairFed_Kernel
0.00 0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40
Equalized Odds0.00.20.40.60.81.0Accuracy
Centralized: Accuracy vs. Equalized Odds
Figure 3: Accuracy versus Demographic Parity (DP) and Equalized Odds (EOD) for KFFLand its baselines
under IID and Non-IID conditions on the COMPAStest dataset. Each point represents a different fairness
weightλranging 0.01 to 123.16 for both KFFLandKFFL-TD. The blue region denotes higher levels of group
fairness (low SPD and EOD), while the gray region indicates lower levels of group fairness (high SPD
and EOD)
0.00 0.05 0.10 0.15 0.20 0.25
Demographic Parity0.00.20.40.60.81.0AccuracyLow SPD Region High SPD Region
"Completely Fair""Completely Unfair"Client data distribution: IID 
KFFL
KFFL_TD
FairFed
FedAvg
MinMax
FairFed_Kernel
0.00 0.05 0.10 0.15 0.20 0.25 0.30
Demographic Parity0.00.20.40.60.81.0AccuracyLow SPD Region High SPD Region
"Completely Fair""Completely Unfair"Client data distribution: Non-IID 
KFFL
KFFL_TD
FairFed
FedAvg
MinMax
FairFed_Kernel
0.04 0.06 0.08 0.10 0.12
Demographic Parity0.00.20.40.60.81.0Accuracy
Centralized: Accuracy vs. Demographic Parity
0.00 0.05 0.10 0.15 0.20 0.25
Equalized Odds0.00.20.40.60.81.0AccuracyLow EOD Region High EOD Region
"Completely Fair""Completely Unfair"Client data distribution: IID 
KFFL
KFFL_TD
FairFed
FedAvg
MinMax
FairFed_Kernel
0.00 0.05 0.10 0.15 0.20 0.25
Equalized Odds0.00.20.40.60.81.0AccuracyLow EOD Region High EOD Region
"Completely Fair""Completely Unfair"Client data distribution: Non-IID 
KFFL
KFFL_TD
FairFed
FedAvg
MinMax
FairFed_Kernel
0.00 0.02 0.04 0.06 0.08 0.10 0.12
Equalized Odds0.00.20.40.60.81.0Accuracy
Centralized: Accuracy vs. Equalized Odds
Figure 4: Accuracy versus Demographic Parity (DP) and Equalized Odds (EOD) for KFFLand its baselines
under IID and Non-IID conditions on the ADULTtest dataset. Each point represents a different fairness
weightλranging from 20.00 to 1000.00 for both KFFLandKFFL-TD. The blue region denotes higher levels
of group fairness (low SPD and EOD), while the gray region indicates lower levels of group fairness
(high SPD and EOD).
11Under review as submission to TMLR
than a primary objective. Thus, these algorithms are not suitable benchmarks for our approach, as we focus
explicitly on addressing statistical group fairness in federated learning.
We compare KFFLagainst five baseline methods: FedAvgLi et al. (2020); the MinMaxalgorithm of Papadaki
et al. (2022), which aims to optimize model performance for the worst-performing demographic; FairFed
Ezzeldin et al. (2023), where clients convey localized fairness metrics and the server optimizes weighting
coefficients by minimizing the contribution of the poorest-performing client for a chosen fairness metric (eg:
Equalized Odds). The framework of FairFed allows for different local bias mitigation algorithms. We use
FairFed with the best performing local bias mitigation algorithm, FairBatch Roh et al. (2020). The latter
two baselines were chosen as these methods are explicitly designed to mitigate demographic bias in
federated learning .To highlight the importance of global communication of fairness information, we also
consider Local-Kernel orFairFed-Kernel , which uses FedAvgwith each local client implementing a local
bias mitigation algorithm (similar to Equation 8). Finally, KFFLis compared against its time delay variant
KFFL-TD. The selection of various hyperparameters for KFFLand its variants is discussed in Appendix B.1.
This section includes a discussion of both common hyperparameters (e.g., batch size, learning rate, local
epochs, global rounds) and algorithm-specific hyperparameters, such as the feature map size Dused in KFFL
andKFFL-TD.
We evaluate the performance in two different federated learning settings: IID(Independent and Identically
Distributed) and Non-IID (Non-Independent and Non-Identically Distributed).In the IID setting, each
client is provided with an equal number of samples and a consistent data distribution for local training Li
et al. (2020). In the Non-IID setting, each client has a different distribution of the protected attribute.
Specifically, since the protected group Ais binary with attributes A0andA1, half of the clients have 90 %
ofA0and 10% ofA1, while the other half has 90% of A1and 10% ofA0Li et al. (2020).
For the classification task, we used five datasets commonly applied in group fairness research Han et al.
(2023): Adult,COMPAS,Bank,ACS, and German. The client models for evaluation include Logistic Regression
Han et al. (2023) and Neural Networks. Additional results and details can be found in Appendix D.
When the underlying task is regression, we incorporate additional datasets into our evaluation. Beyond the
Adultdataset, we also consider the Law School and Communities and Crime datasets, as utilized in the
work Agarwal et al. (2019a). For more details on the dataset refer to B.2.
Note on Privacy: While privacy-preserving techniques like Secure Aggregation Bonawitz et al. (2017), as
discussedinEzzeldinet al. (2023), canbeincorporatedintoourapproach—enablingclientstosendencrypted
gradients through such protocols—our primary focus in this work is the development and evaluation of
our novel algorithm. Specifically, we aim to explore the Pareto frontier of fairness-performance trade-offs.
Integration of privacy-preserving protocols, such as DP-SGD Chua et al. (2024) and Secure Aggregation, is
left as future work, as the current evaluation emphasizes statistical fairness over privacy concerns.Similar to
prior works in federated learning that do not impose privacy constraints Crawshaw & Liu (2024); Cho et al.
(2023); Gu et al. (2021); Malinovsky et al. (2023); Eichner et al. (2019), we assume no privacy-preserving
mechanisms in this study.
Note on Full Participation: Furthermore, we consider full client participation , consistent with ap-
proaches such as FairFed Ezzeldin et al. (2023), the MinMaxalgorithm proposed by Papadaki et al. (2022),
Table 3: Communication Costs of KFFLandKFFL-TD, relative to FedAvg. Here,ε≜D2/|ω|.. One limitation
ofKFFLandKFFL-TD is the additional cost incurred by the exchange of model parameters.However, the use
of Random Fourier Features see Algorithms 2 and 3 in our approach ensures that the cost of the additional
matrices is effectively mitigated for large model sizes
Method Uplink Downlink
KFFL 2 +ε 2 +ε
KFFL-TD (Time Delay Variant) 2 +ε 2 +ε
Fair Fed Ezzeldin et al. (2023) 1 1
FedAvg 1 1
12Under review as submission to TMLR
Fairness weight λRMSE↓ KS Difference↓
0.0 0.320332±0.024803 0.604128±0.166035
5.0 0.320936±0.024753 0.618280±0.186275
10.0 0.321824±0.024351 0.551812±0.179296
50.0 0.314788±0.026521 0.391712±0.157367
100.0 0.318976±0.023506 0.290872±0.099638
Table 4: RMSE and KS Difference with standard deviations for 5 runs with KFFLwithIIDfor the Commu-
nities and Crime Dataset.Optimal points are those with lower RMSE (for accuracy) and KS (for fairness)
Fairness weight λRMSE↓ KS Difference↓
0.00 0.810188±0.002067 0.439208±0.175972
0.01 0.810068±0.002152 0.424060±0.164314
0.10 0.809940±0.002189 0.487244±0.139673
1.00 0.810052±0.002201 0.200248±0.170934
5.00 0.810100±0.002022 0.212672±0.065094
Table 5: RMSE and KS Difference with standard deviations for 5 runs KFFL with Non-IID for the Law
School Dataset.Optimal points are those with lower RMSE (for accuracy) and KS (for fairness)
and other works in federated learning Zhang et al. (2023); Li et al. (2023a;b); Zakerinia et al. (2023); Huang
et al. (2022).
6 Performance Evaluation of KFFL
Existing fair classifiers and regressors that balance fairness and accuracy typically optimize for a single point
on the trade-off curve (see Figure 3 and Figure 4), whereas methods such as KFFLand KFFL-TD explore
the Pareto frontier more comprehensively to provide a better trade-off between accuracy and statistical
fairness. Thisnarrowfocusrestrictstheexplorationofalternativesolutions, potentiallyleadingtosuboptimal
outcomes that fail to reflect diverse stakeholder preferences for fairness and performance. The KFFLand
KFFL-TD methods proposed in the previous sections overcome this limitation by systematically exploring
multiple points along the Pareto front, offering a broader spectrum of optimal trade-offs between fairness
and accuracy tailored to specific needs for various stakeholders.
6.1 KFFL offers better Pareto Frontier
For the classification task, we evaluate the models’ test accuracy and fairness metrics, focusing on Demo-
graphic Parity (SPD) 1 and Equalized Odds (EOD) 2, across five datasets: BANK,ACS,COMPAS,ADULT, and
GERMAN. Each dataset considers a single protected binary sensitive attribute. For example, in COMPAS, the
protected attribute is race (black/white), while in ADULT, it is sex (male/female). This subsection presents
results for the Logistic Regression model, with the Appendix D covering the performance of the Neural
Network model.
KFFLand its baselines are compared under both IID and Non-IID conditions on the COMPAStestdataset
in Figure 3. The blue region, referred to as the ’Low SPD Region’ and ’Low EOD Region,’ represents
low statistical parity discrepancy (SPD) (see Equation 1) and low equalized odds discrepancy (EOD) (see
Equation 2). These regions correspond to higher levels of group fairness . In contrast, the grayregion,
labeled as the ’High SPD Region’ and ’High EOD Region,’ indicates lower levels of group fairness .
Points labeled ’completely fair’ indicate trade off points where the model achieves no statistical parity or
equalized odds discrepancies, as defined in Equations 1 and 2. In contrast, points labeled ’completely unfair’
represent the performance of the standard FedAvgmodel, which is trained without any fairness objective
(i.e.,λ= 0in the distributed setting of Equation 8). Each point reflects a different fairness weight λ, ranging
from 20.00 to 1000.00 for both KFFLandKFFL-TD using the ADULTdataset and from 0.01 to 123.16 for COMPAS
13Under review as submission to TMLR
Method COMPAS BANK ACS GERMAN
Acc.(↑)FedAvg 61.13 ±1.25 91.21±1.10 81.14±1.20 72.50±1.15
KFFL 60.30±1.3090.23±1.2579.12±1.3572.50±1.10
KFFL-TD 59.51±1.4590.78±1.2081.12±1.0572.50±1.40
FairFed/FairBatch 55.47 ±1.50 88.05±1.30 58.77±1.20 30.00±1.25
KHSIC-Local 44.13 ±1.55 88.77±1.15 58.77±1.05 70.00±1.35
MinMax 56.68 ±1.40 64.93±1.20 58.77±1.25 70.00±1.10
SPD(↓)FedAvg 0.16 ±0.02 0.23±0.01 0.08±0.04 0.19±0.03
KFFL 0.06±0.010.05±0.030.04±0.020.00±0.04
KFFL-TD 0.05±0.020.06±0.010.00±0.030.00±0.02
FairFed/FairBatch 0.05 ±0.03 0.00±0.02 0.00±0.01 0.00±0.03
KHSIC-Local 0.08 ±0.02 0.00±0.03 0.00±0.02 0.00±0.01
MinMax 0.03 ±0.01 0.21±0.02 0.00±0.03 0.00±0.02
EOD(↓)FedAvg 0.23 ±0.02 0.16±0.01 0.04±0.02 0.02±0.03
KFFL 0.07±0.010.04±0.020.02±0.030.00±0.02
KFFL-TD 0.08±0.020.05±0.010.03±0.020.00±0.03
FairFed/FairBatch 0.09 ±0.02 0.16±0.03 0.00±0.01 0.00±0.02
KHSIC-Local 0.05 ±0.03 0.00±0.02 0.00±0.01 0.00±0.03
MinMax 0.03 ±0.02 0.02±0.01 0.00±0.03 0.00±0.02
Table 6: Trade-off points for datasets BANK,ACS, and GERMAN, alongside the previously analyzed COMPAS,
under Non-IID client distributions. Models are trained and evaluated on test datasets after three runs.
KFFL andKFFL-TD are showcased, demonstrating Pareto optimality across accuracy and fairness
metrics. Lower SPD and EOD values indicate higher fairness; it is observed that KFFLandKFFL-TD provide
better trade-off points, achieving a balance between accuracy and fairness with reduced group disparity.
dataset. More details on the choice of λfor other datasets is given in section Appendix B.5. As λincreases
beyond this range, we observe non-optimal points to the right of the ’completely unfair’ point.
It can be seen that other baselines, such as FairFed and MinMax, are not designed to produce a smooth
Pareto Frontier between accuracy and fairness. For FairFed Ezzeldin et al. (2023), the tradeoff is controlled
by a parameter called the "fairness budget" β, which varies from 0.1 to 5, based on the recommendations
in Ezzeldin et al. (2023). However, optimal performance of the FairFed baseline requires a local debiasing
mechanism, for which we use the FairBatch algorithm Roh et al. (2020) for comparison.
ForMinMax, a "global adversary rate" Papadaki et al. (2022) is used to control the reduction of expected loss
for the worst-performing demographic. To explore the accuracy-fairness tradeoff, we varied this parameter
from 0.001 to 0.1 based on the setting in that paper.
In the right column, the ’Centralized’ method refers to a non-distributed data setting, corresponding to
Equation 8, where the full kernel is used as a regularizer. Similarly, Figure 4 provides an evaluation for the
ADULTtestdataset. Each point represents a different fairness weight λ, ranging from 0 to 0.01 for both KFFL
andKFFL-TD.
The "Centralized" version for each dataset illustrates that using the full kernel allows for a clear tradeoff
between accuracy and fairness. Our distributed KHSIC approach KFFLpreserves this tradeoff in
Figure 3 and 4. Specifically, KFFLandKFFL-TD maintain competitive accuracy (approximately 0.85 to 0.78)
on the ADULTdataset and between 0.6 to 0.7 on the COMPASdataset,across different fairness regions .
In contrast, methods like FairFed andMinMaxperform similarly to our methods in lower levels of group
fairness but significantly underperform in regions with higher levels of group fairness often failing to
provide any tradeoff points in the areas identified as high fairness regions .
A key drawback of FairFed andMinMaxis that their hyperparameter choices limit the smooth exploration
of the Pareto frontier. In contrast, KFFLand KFFL-TD provide a more effective accuracy-fairness tradeoff,
achieving a smoother and more optimal Pareto frontier across various fairness regions, consistently main-
taining or surpassing the performance of these baselines. Notably, FairFed and MinMaxfail to produce
tradeoff points in the higher Equalized Odds (EOD) regions, with their performance consistently falling
below Pareto-optimal levels across both evaluation metrics and distributions.
Moreover, the smooth exploration of the Pareto frontier by KFFLand KFFL-TD persists even under more
challenging federated learning conditions, such as when the data distribution is Non-IID. Unlike FairFed
14Under review as submission to TMLR
andMinMax, which require extensive tuning for specific evaluation metrics, KFFLandKFFL-TDperform well
without metric-specific hyperparameter optimization .
However, the choice of the fairness weight hyperparameter λis crucial for effectively utilizing KFFLand
KFFL-TD. Increasing the fairness weight λbeyond a certain threshold can push the model’s performance
towards lower levels of group fairness Figure 3 and 4. While a tradeoff between accuracy and fairness
is inevitable in group fairness problems, KFFLand KFFL-TD consistently offer a superior balance between
accuracy and fairness.
Figures 4 and 3 illustrate the tradeoff achieved when KHSIC is applied as a local fairness regularizer in the
methods Local-Kernel andFairFed-Kernel . In these methods, each client independently solves Equation
8 without global communication of fairness gradients. The results clearly show that local debiasing methods
failtoachieveatradeoffcomparabletothecentralizedapproach, wherealldataisconsolidatedandoptimized
by a single entity using Equation 8. These findings underscore the importance of the principled strategies
employed by KFFLandKFFL-TD.
6.2 KFFL has better Tradeoff Points
Table 6 highlights key trade-off points for additional datasets, including BANK,ACS, and GERMAN, alongside
the previously analyzed COMPASdataset. The models were trained under Non-IID client distribution, and
the trade-off points were computed based on test dataset performance after three runs.
To showcase the benefits of our approach, we selected specific trade-off points. For the COMPASdataset, if
the desired accuracy is around 60%, similar to the performance of FedAvg, KFFLand KFFL-TD achieve a
small SPD of 0.06. In contrast, other baselines achieve similar SPD but with an approximately 5% drop in
accuracy. A similar trend becomes evident with the ACSdataset, where KFFL-TD provides a trade-off point
of relatively high 80% accuracy for low SPD value. For the baselines, a comparable fairness point results in
a 22% drop in accuracy.
Additionally, KFFLis robust across different evaluation metrics,In the BANKdataset, KFFLandKFFL-TD offer
a trade-off point of 90% accuracy with SPD values of 0.05 and 0.04, respectively. In comparison, FairFed
achieves 0.00 SPD with 88% accuracy but exhibits a high EOD of 0.16, as it was optimized for reducing
SPD in our experiments. This underscores the importance of carefully selecting an evaluation metric in the
FairFed approach. Additionally, MinMaxshows a high SPD but low EOD, indicating that one evaluation
metric may be favored over the other, depending on the dataset with this approach. In contrast, KFFLand
KFFL-TD provide a trade-off point that reduces unfairness across both evaluation metrics for this dataset.
6.3 KFFL offers reduced Communication Overhead
Table 2 compares the communication rounds required by our proposed methods, KFFLand its time-delay
variant KFFL-TD see (C), with baseline methods such as FedAvgandFairFed Ezzeldin et al. (2023). While
KFFLrequires a similar number of communication rounds as FairFed,KFFL-TD reduces the number of rounds
needed for a global model update by using stale fairness gradients, thereby lowering the total communication
rounds needed per update
One limitation of KFFLand KFFL-TD is the additional communication overhead caused by the exchange of
extra model parameters. Table 3 compares the relative communication costs (per client, per iteration) for the
FedAvgandKFFLalgorithms. Let|ω|denote the size of the model. For each iteration, FedAvgincurs uplink
(client-to-server) and downlink (server-to-client) communication costs of |ω|. In contrast, KFFLrequires the
client to transmit ωi
t,Φi(ωt),gi(ωt)(see Algorithm 2), resulting in an uplink cost of 2|ω|+D2, and the server
to transmitωt,Λ(ωt),ωt+1/2, incurring a similar downlink cost of 2|ω|+D2(see Algorithm 3). Notably,
D2is often smaller than |ω|, particularly for large models. KFFL-TD (Appendix C) incurs comparable
communication costs but reduces the number of communication rounds per iteration (see Figure 5).
To quantify this overhead, Table 3 defines ϵ≡D2
|ω|, whereDis the data dimensionality. This results in total
uplink and downlink communication costs of approximately 2 +ϵper iteration for KFFL, compared to 1for
standard methods like FedAvg. Although FairFed also exchanges local and global accuracy and fairness
15Under review as submission to TMLR
metrics during each global update, we exclude these scalar quantities from the comparison for simplicity in
Table 3.
To mitigate the overhead from these additional matrices, we leveraged Random Fourier Features (RFF).
RFF approximates kernel functions with finite-dimensional feature mappings, keeping the size of the extra
matrices proportional to ϵ. Sinceϵis relatively small when D2≪|ω|, the additional communication cost
becomes negligible in practice. This ensures that the overall communication costs of KFFLand KFFL-TD
remains only one order of magnitude higher due to the additional exchange of model parameters, while
providing the benefits of ensuring learning a model that is fair with respect to different demographic groups.
6.4 KFFL provides better tradeoff points for Regression Tasks
Weconductexperimentsusingalinearregressionmodeltoevaluateitsperformanceintermsofbothaccuracy
and group fairness. Accuracy for regression tasks is measured using Root Mean Square Error (RMSE), which
quantifies the average magnitude of errors between predicted and actual values; a lower RMSE indicates
higher accuracy. Group fairness is assessed using the Kolmogorov-Smirnov (KS) distance (Equation 4),
where a lower KS distance signifies greater statistical fairness.
Table 4 presents the performance of KFFLunder varying fairness weights ( λ) in theIIDsetting using
theCommunities and Crime dataset. Increasing λemphasizes the fairness term in KFFL. Across different
λvalues, the model achieves solutions with significantly reduced KS distance while maintaining RMSE
comparable to standard distributed regression tasks (e.g., λ= 0). Notably, the KS distance is reduced by
half with minimal impact on RMSE, demonstrating a balanced trade-off between accuracy and fairness. A
similar pattern emerges under Non-IID settings with the Law School dataset, as detailed in Table 5.
Additional results in the Appendix, including Tables 15, 13, 11, 12, 14, and 10, extend these findings to the
Law School ,Communities and Crime , and Adultdatasets. These results underscore the effectiveness of
KFFLin balancing accuracy and fairness by appropriately tuning the fairness weight λin the regularization
term for regression tasks.
7 Conclusions
This work introduces a systematic approach for training group-fair machine learning models in a federated
setting. Our method leverages KHSIC as a fairness regularizer to capture complex, non-linear dependencies
between model outputs and sensitive attributes, ensuring approximate statistical parity without requiring
access to sensitive attributes during training. The proposed method, KFFL, significantly reduces the commu-
nication and computation costs of a naive implementation by employing Random Feature Maps and a novel
federated proximal gradient algorithm, FedProxGrad , which accommodates the non-convexity of both the
data-fitting term and the fairness regularizer.
Experimental results demonstrate that KFFLperforms robustly across diverse client data distributions and
standard datasets commonly used to evaluate fair learning methods. It achieves strong performance in both
regression and classification tasks by thoroughly exploring the Pareto frontier, providing a smoother and
more optimal trade-off between accuracy and fairness.
Limitations and Future Work
KFFLeffectively enforces statistical parity but is specifically designed for this particular fairness definition.
Expanding the method to include other notions of group fairness, such as conditional variants of KHSIC,
could significantly enhance its versatility. Also, the current framework assumes full client participation,
making it less suitable for scenarios with partial participation or privacy constraints. To address these
challenges, future work could incorporate differentially private gradient estimation techniques and develop
more advanced stochastic analyses to support partial participation. Additionally, the convergence rate of
FedProxGrad is influenced by the variance σ2of the stochastic gradient estimate for the fairness regularizer,
which imposes a variance-dependent floor on the efficiency of the method. Future work will aim to overcome
these challenges by exploring variance reduction techniques or alternative strategies to mitigate the impact
ofσ2on convergence rates.
16Under review as submission to TMLR
References
pyrfm: A library for random feature maps in python. URL https://neonnnnn.github.io/pyrfm/random_
feature.html .
Alekh Agarwal, Miroslav Dudík, and Zhiwei Steven Wu. Fair regression: Quantitative definitions and
reduction-based algorithms. In International Conference on Machine Learning , pp. 120–129. PMLR,
2019a.
Alekh Agarwal, Miroslav Dudík, and Zhiwei Steven Wu. Fair regression: Quantitative definitions and
reduction-based algorithms. In International Conference on Machine Learning , pp. 120–129. PMLR,
2019b.
Sina Baharlouei, Maher Nouiehed, Ahmad Beirami, and Meisam Razaviyayn. R \’enyi fair inference. arXiv
preprint arXiv:1906.12005 , 2019a.
Sina Baharlouei, Maher Nouiehed, Ahmad Beirami, and Meisam Razaviyayn. R \’enyi fair inference. arXiv
preprint arXiv:1906.12005 , 2019b.
Yajie Bao, Michael Crawshaw, Shan Luo, and Mingrui Liu. Fast composite optimization and statistical
recovery in federated learning. In Proceedings of the 39th International Conference on Machine Learning ,
volume 162, pp. 1508–1536. PMLR, 2022.
Matias Barenstein. Propublica’s compas data revisited. arXiv preprint arXiv:1906.04711 , 2019.
Barry Becker and Ronny Kohavi. Adult. UCI Machine Learning Repository, 1996. DOI:
https://doi.org/10.24432/C5XW20.
Keith Bonawitz, Vladimir Ivanov, Ben Kreuter, Antonio Marcedone, H Brendan McMahan, Sarvar Patel,
Daniel Ramage, Aaron Segal, and Karn Seth. Practical secure aggregation for privacy-preserving machine
learning. In proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security ,
pp. 1175–1191, 2017.
Hongyan Chang and Reza Shokri. Bias propagation in federated learning. In The Eleventh International
Conference on Learning Representations , 2023. URL https://openreview.net/forum?id=V7CYzdruWdm .
Bhaskar Ray Chaudhury, Linyi Li, Mintong Kang, Bo Li, and Ruta Mehta. Fairness in federated learning
via core-stability. arXiv preprint arXiv:2211.02091 , 2022.
Yae Jee Cho, Pranay Sharma, Gauri Joshi, Zheng Xu, Satyen Kale, and Tong Zhang. On the convergence of
federated averaging with cyclic client participation. In International Conference on Artificial Intelligence
and Statistics , pp. 10351–10375, 2023. URL https://arxiv.org/abs/2302.03109 .
Lynn Chua, Badih Ghazi, Pritish Kamath, Ravi Kumar, Pasin Manurangsi, Amer Sinha, and Chiyuan
Zhang. How private is dp-sgd? arXiv preprint arXiv:2403.17673 , 2024.
Evgenii Chzhen, Christophe Denis, Mohamed Hebiri, Luca Oneto, and Massimiliano Pontil. Fair regression
with wasserstein barycenters. Advances in Neural Information Processing Systems , 33:7321–7331, 2020a.
Evgenii Chzhen, Christophe Denis, Mohamed Hebiri, Luca Oneto, and Massimiliano Pontil. Fair regres-
sion via plug-in estimator and recalibration with statistical guarantees. Advances in Neural Information
Processing Systems , 33:19137–19148, 2020b.
Jose Correa, Andres Cristi, Paul Duetting, and Ashkan Norouzi-Fard. Fairness and bias in online selection.
InInternational conference on machine learning , pp. 2112–2121. PMLR, 2021.
MichaelCrawshawandMingruiLiu. Federatedlearningunderperiodicclientparticipationandheterogeneous
data: A new communication-efficient algorithm and analysis. arXiv preprint arXiv:2410.23131 , 2024. URL
https://arxiv.org/abs/2410.23131 .
17Under review as submission to TMLR
Sen Cui, Weishen Pan, Jian Liang, Changshui Zhang, and Fei Wang. Addressing algorithmic disparity and
performance inconsistency in federated learning. Advances in Neural Information Processing Systems , 34:
26091–26102, 2021.
Kate Donahue and Jon Kleinberg. Models of fairness in federated learning. arXiv preprint arXiv:2112.00818 ,
2021.
Julia Dressel and Hany Farid. The accuracy, fairness, and limits of predicting recidivism. Science advances ,
4(1):eaao5580, 2018.
Wei Du, Depeng Xu, Xintao Wu, and Hanghang Tong. Fairness-aware agnostic federated learning. In
Proceedings of the 2021 SIAM International Conference on Data Mining (SDM) , pp. 181–189. SIAM,
2021.
Cynthia Dwork, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Richard Zemel. Fairness through
awareness. In Proceedings of the 3rd innovations in theoretical computer science conference , pp. 214–226,
2012a.
Cynthia Dwork, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Richard Zemel. Fairness through
awareness. In Proceedings of the 3rd innovations in theoretical computer science conference , pp. 214–226,
2012b.
HubertEichner, TomerKoren, BrendanMcMahan, NathanSrebro, andKunalTalwar. Semi-cyclicstochastic
gradient descent. In International Conference on Machine Learning , pp. 1764–1773, 2019. URL https:
//arxiv.org/abs/1904.10120 .
Yahya H Ezzeldin, Shen Yan, Chaoyang He, Emilio Ferrara, and A Salman Avestimehr. Fairfed: Enabling
group fairness in federated learning. In Proceedings of the AAAI Conference on Artificial Intelligence ,
volume 37, pp. 7494–7502, 2023.
Arthur Gretton, Olivier Bousquet, Alex Smola, and Bernhard Schölkopf. Measuring statistical depen-
dence with hilbert-schmidt norms. In International conference on algorithmic learning theory , pp. 63–77.
Springer, 2005a.
Arthur Gretton, Ralf Herbrich, Alexander Smola, Olivier Bousquet, Bernhard Schölkopf, et al. Kernel
methods for measuring independence. 2005b.
Xinran Gu, Kaixuan Huang, Jingzhao Zhang, and Longbo Huang. Fast federated learning in the presence
of arbitrary device unavailability. Advances in Neural Information Processing Systems , 34:12052–12064,
2021. URL https://arxiv.org/abs/2106.07070 .
Raffay Hamid, Ying Xiao, Alex Gittens, and Dennis DeCoste. Compact random feature maps. In Interna-
tional conference on machine learning , pp. 19–27. PMLR, 2014.
Xiaotian Han, Jianfeng Chi, Yu Chen, Qifan Wang, Han Zhao, Na Zou, and Xia Hu. Ffb: A fair fairness
benchmark for in-processing group fairness methods. arXiv preprint arXiv:2306.09468 , 2023.
Shengyuan Hu, Steven Wu, and Virginia Smith. Fair federated learning via bounded group loss.
Kaixuan Huang, Xinran Gu, Jingzhao Zhang, and Longbo Huang. Federated stochastic primal-dual learning
with differential privacy. arXiv preprint arXiv:2204.12284 , 2022. URL https://arxiv.org/abs/2204.
12284.
AjilJalal, SushrutKarmalkar, JessicaHoffmann, AlexDimakis, andEricPrice. Fairnessforimagegeneration
with uncertain sensitive attributes. In International Conference on Machine Learning , pp. 4721–4732.
PMLR, 2021.
Sai Praneeth Karimireddy, Satyen Kale, Mehryar Mohri, Sashank Reddi, Sebastian Stich, and
Ananda Theertha Suresh. Scaffold: Stochastic controlled averaging for federated learning. In International
conference on machine learning , pp. 5132–5143. PMLR, 2020.
18Under review as submission to TMLR
Kevin Kim and Alex Gittens. Learning fair canonical polyadical decompositions using a kernel independence
criterion. arXiv preprint arXiv:2104.13504 , 2021.
Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint
arXiv:1412.6980 , 2014.
Tian Li, Maziar Sanjabi, Ahmad Beirami, and Virginia Smith. Fair resource allocation in federated learning.
arXiv preprint arXiv:1905.10497 , 2019.
Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and Virginia Smith. Federated
optimization in heterogeneous networks. Proceedings of Machine learning and systems , 2:429–450, 2020.
Wei Li, Jian Wang, Xiaoyang Zhang, Yifan Zhang, and Yanfeng Wang. Privacy protection bottom-up
hierarchical federated learning. In International Conference on Artificial Intelligence and Security , pp.
25–36, 2023a. URL https://link.springer.com/chapter/10.1007/978-981-97-5562-2_3 .
Wei Li, Jian Wang, Xiaoyang Zhang, Yifan Zhang, and Yanfeng Wang. Anofel: Supporting anonymity for
privacy-preserving federated learning. arXiv preprint arXiv:2306.06825 , 2023b. URL https://arxiv.
org/abs/2306.06825 .
Grigory Malinovsky, Samuel Horváth, Konstantin Burlachenko, and Peter Richtárik. Improving accelerated
federated learning with compression and importance sampling. Federated Learning and Analytics in Prac-
tice: Algorithms, Systems, Applications, and Opportunities , 2023. URL https://arxiv.org/abs/2302.
03662.
Ninareh Mehrabi, Fred Morstatter, Nripsuta Saxena, Kristina Lerman, and Aram Galstyan. A survey on
bias and fairness in machine learning. ACM computing surveys (CSUR) , 54(6):1–35, 2021.
Ninareh Mehrabi, Cyprien de Lichy, John McKay, Cynthia He, and William Campbell. Towards multi-
objective statistically fair federated learning. arXiv preprint arXiv:2201.09917 , 2022.
Omid Memarrast, Linh Vu, and Brian D Ziebart. Superhuman fairness. In International Conference on
Machine Learning , pp. 24420–24435. PMLR, 2023.
Mehryar Mohri, Gary Sivek, and Ananda Theertha Suresh. Agnostic federated learning. In International
Conference on Machine Learning , pp. 4615–4625. PMLR, 2019.
Afroditi Papadaki, Natalia Martinez, Martin Bertran, Guillermo Sapiro, and Miguel Rodrigues. Minimax
demographic group fairness in federated learning. In 2022 ACM Conference on Fairness, Accountability,
and Transparency , pp. 142–159, 2022.
Sikha Pentyala, Nicola Neophytou, Anderson Nascimento, Martine De Cock, and Golnoosh Farnadi. Priv-
fairfl: Privacy-preserving group fairness in federated learning. arXiv preprint arXiv:2205.11584 , 2022.
Adrián Pérez-Suay, Valero Laparra, Gonzalo Mateo-García, Jordi Muñoz-Marí, Luis Gómez-Chova, and
Gustau Camps-Valls. Fair kernel learning. In Joint European Conference on Machine Learning and
Knowledge Discovery in Databases , pp. 339–355. Springer, 2017.
Ali Rahimi and Benjamin Recht. Random features for large-scale kernel machines. Advances in neural
information processing systems , 20, 2007.
Michael Redmond and Alok Baveja. A data-driven software tool for enabling cooperative information sharing
among police departments. European Journal of Operational Research , 141(3):660–678, 2002.
Yuji Roh, Kangwook Lee, Steven Euijong Whang, and Changho Suh. Fairbatch: Batch selection for model
fairness. arXiv preprint arXiv:2012.01696 , 2020.
Yaniv Romano, Stephen Bates, and Emmanuel Candes. Achieving equalized odds by resampling sensitive
attributes. Advances in neural information processing systems , 33:361–371, 2020.
19Under review as submission to TMLR
Teresa Salazar, Miguel Fernandes, Helder Araujo, and Pedro Henriques Abreu. Fair-fate: Fair federated
learning with momentum. arXiv preprint arXiv:2209.13678 , 2022.
Teresa Salazar, Helder Araújo, Alberto Cano, and Pedro Henriques Abreu. A survey on group fairness in
federated learning: Challenges, taxonomy of solutions and directions for future research. arXiv preprint
arXiv:2410.03855 , 2024.
Quoc Tran Dinh, Nhan H Pham, Dzung Phan, and Lam Nguyen. FedDR: Randomized Douglas-Rachford
splitting algorithms for nonconvex federated composite optimization. In Advances in Neural Information
Processing Systems , volume 34, pp. 30326–30338. Curran Associates, Inc., 2021.
Ganghua Wang, Ali Payani, Myungjin Lee, and Ramana Kompella. Mitigating group bias in federated
learning: Beyond local fairness. arXiv preprint arXiv:2305.09931 , 2023.
Jia Wang and Jueyou Li. Federated dual averaging learning algorithm with delayed gradients for composite
optimization. Available at SSRN 4507875 , 2023.
Linda F Wightman. Lsac national longitudinal bar passage study. lsac research report series. 1998.
Felix Xinnan X Yu, Ananda Theertha Suresh, Krzysztof M Choromanski, Daniel N Holtmann-Rice, and
Sanjiv Kumar. Orthogonal random features. Advances in neural information processing systems , 29, 2016.
Honglin Yuan, Manzil Zaheer, and Sashank Reddi. Federated composite optimization. In Proceedings of the
38th International Conference on Machine Learning , volume 139, pp. 12253–12266. PMLR, 2021.
Hossein Zakerinia, Shayan Talaei, Giorgi Nadiradze, and Dan Alistarh. Blockchain-based optimized client
selection and privacy preserved framework for federated learning. arXiv preprint arXiv:2308.04442 , 2023.
URL https://arxiv.org/abs/2308.04442 .
Yuchen Zeng, Hongxu Chen, and Kangwook Lee. Improving fairness via federated learning. arXiv preprint
arXiv:2110.15545 , 2021.
Yuxin Zhang, Tian Li, Anit Kumar Sahu, Ameet Talwalkar, and Virginia Smith. Advancing personalized
federated learning: Group privacy, fairness, and beyond. SN Computer Science , 4(5):1–13, 2023. URL
https://link.springer.com/article/10.1007/s42979-023-02292-0 .
20Under review as submission to TMLR
A Appendix
A.1 Related Works
Methods for ensuring fairness within centralized machine learning are typically categorized into three distinct
groups: pre-processing, in-processing, and post-processing Mehrabi et al. (2021). In federated learning, bias
mitigation methods predominantly fall into in-processing approaches, although some work has also been
done in post-processing methods.
For in-processing methods of bias mitigation in federated learning, Ezzeldin et al. (2023) is notable for its
versatility and compatibility with various localbias mitigation techniques.In this approach, clients convey
their localized fairness metrics to the server, which then optimizes weighting coefficients to minimize the
contribution of the poorest-performing client with respect to a chosen fairness metric. Papadaki et al. (2022)
optimize model performance on the worst-performing demographic by adopting a minimax optimization
framework. Salazar et al. (2022) propose a fairness-aware momentum-based method to address bias in
federated learning. The approach in Mehrabi et al. (2022) strives for fair federated learning but requires
the server to maintain a validation dataset. Zeng et al. (2021) address the challenge of bias mitigation in
federated learning through a bi-level optimization problem; their analysis predominantly pertains to specific
loss functions. Pentyala et al. (2022) consider post-processing and pre-processing approaches to ensuring
fairness. Cui et al. (2021) require the clients to achieve Pareto optimality with respect to both fairness and
accuracy.
Other variants of group fairness have been explored in the federated setting. Hu et al. introduce the
concept of bounded group loss as a facet of group fairness in federated learning, although their work does
not specifically develop algorithms targeting bias mitigation. Chang & Shokri (2023) analyze how bias
within participating clients can propagate during the training process but do not propose methods aimed
at explicitly addressing group fairness.A comprehensive summary of additional approaches in group fairness
federated learning is provided in Table 3 of Salazar et al. (2024). For baseline comparisons, we limit our
focus to most published works in group fairness federated learning except the recent Wang et al.
(2023).
Significant related works from the centralized setting that aim to ensure fair models include Pérez-Suay
et al. (2017), which leverages the (non-kernel) Hilbert-Schmidt Independence Criterion (HSIC) to promote
the learning of fair kernel machines, and Baharlouei et al. (2019a), which incorporates the Rényi correlation
as a regularization term to achieve statistically fair models.
A.2 Proof of Theorem 1
In the following, Et[·] =E[·|ωt]denotes the expectation conditioned on all sources of randomness in the
algorithm up to and including the calculation of ωt, andEi[·] =1
N/summationtextN
i=1[·]denotes the average of a quantity
over the workers.
The computations are complicated by the presence of a composite objective and stochasticity in our estimate
of∇ψ(ω), but the conceptual outline of the proof of the convergence rate follows that of the proof of the
convergence rate for FedProx in Li et al. (2020). Namely,
•First, we establish that the distance between consecutive iterates, ∥ωt+1−ωt∥2, is upper bounded by
the quantity Ei∥∇ℓi(ωt) +∇ψ(ωt)∥2, and use the bounded dissimilarity condition to upper bound
the latter by a multiple of the composite objective gradient at ωt,∥∇F(ωt)∥2
2, plus a term due to
noise.
•Next, we use this result and the smoothness of the composite objective to establish that after one
round of the algorithm, the composite objective satisfies EtF(ωt+1)≤F(ωt)−αEt∥∇F(ωt)∥2
2+
(vanishing terms) +(noise).
21Under review as submission to TMLR
•Weconcludethatifthestep-size αischosenappropriately,thentheobjectivedecreasesinexpectation
ateachiteration, uptothenoiselevel. AstandardargumentwithJensen’sinequalityandtelescoping
sums delivers the claimed convergence rate.
Proof.We flesh out the preceeding outline.
Iterate proximity To bound the iterate proximity, begin by introducing the local exact minimizer,
/hatwideωi
t+1=argminωℓi
t(ω) :=ℓi(ω) +1
2α∥ω−ωt+1/2∥2
2.
The data-fitting term ℓiisL−-weakly convex and the quadratic regularizer is1
α-strongly convex, so the local
objectiveℓi
tisµstrongly convex for µ=1
α−L−.
Theµ-strong convexity of ℓi
timplies that the iterate distance between ωtandωi
t+1can be estimated using
the size of the gradient of ℓi
tat those models:
∥ωi
t+1−ωt∥2≤∥ωi
t+1−/hatwideωi
t+1∥2+∥ωt−/hatwideωi
t+1∥2
≤1
µ/bracketleftbig
∥∇ℓi
t(ωi
t+1)∥2+∥∇ℓi
t(ωt)∥2/bracketrightbig
.
Employing the γ-suboptimality of ωi
t+1to estimate the size of ∥∇ℓi
t(ωi
t+1)∥2refines this estimate to
∥ωi
t+1−ωt∥2≤1 +γ
µ∥∇ℓi
t(ωt)∥2.
We note that
∇ℓi
t(ωt) =∇ℓi(ωt) +1
α(ωt−ωt+1/2) =∇ℓi(ωt) +gt,
and consequently
∥ωi
t+1−ωt∥2≤1 +γ
µ/bracketleftbigg
∥∇ℓi(ωt) +∇ψ(ωt)∥2+∥∇ψ(ωt)−gt∥2/bracketrightbigg
.
Using Jensen’s inequality delivers
Et∥ωt+1−ωt∥2
2≤Et/bracketleftbig
Ei∥ωi
t+1−ωt∥2
2/bracketrightbig
≤2/parenleftbigg1 +γ
µ/parenrightbigg2
Et/bracketleftbigg
Ei∥∇ℓi(ωt) +∇ψ(ωt)∥2
2+∥∇ψ(ωt)−gt∥2
2/bracketrightbigg
≤2/parenleftbigg1 +γ
µ/parenrightbigg2/bracketleftbigg
B2∥∇F(ωt)∥2
2+G2+σ2/bracketrightbigg
. (20)
The last inequality holds because of the bounded dissimilarity condition and the upper bound on the variance
ofgt.
Similarly,
Et∥ωt+1−ωt∥2≤Et/bracketleftbig
Ei∥ωi
t+1−ωt∥2/bracketrightbig
≤1 +γ
µEt/bracketleftbigg/radicalig
Ei∥∇ℓi(ωt) +∇ψ(ωt)∥2
2+/radicalig
∥∇ψ(ωt)−gt∥2
2/bracketrightbigg
≤1 +γ
µ/bracketleftbigg
B∥∇F(ωt)∥2+G+σ/bracketrightbigg
. (21)
22Under review as submission to TMLR
Objective Decrease TheL-smoothness of the composite objective implies that
EtF(ωt+1)≤Et/bracketleftbigg
F(ωt) +⟨∇F(ωt),ωt+1−ωt⟩+L
2∥ωt+1−ωt∥2
2/bracketrightbigg
(22)
=F(ωt)−α∥∇F(ωt)∥2
2+Et/bracketleftbigg
⟨∇F(ωt),ωt+1−(ωt−α∇F(ωt)/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
= ∆ t⟩/bracketrightbigg
+L
2Et∥ωt+1−ωt∥2
2.
Equation 20 establishes that, up to noise terms, the term Et∥ωt+1−ωt∥2
2scales likeα2∥∇F(ωt)∥2
2, because
µ−2is on the order of α2. Now we develop a series of estimates to establish that the quantity Et⟨F(ωt),∆t⟩
also scales like α2∥∇F(ωt)∥2
2, up to noise terms.
We begin by using the γ-suboptimality of ωi
t+1to find a useful expression for ∆t. In particular, γ-
suboptimality implies that
∇ℓi(ωi
t+1) +1
α(ωi
t+1−ωt+1/2) =∇ℓi(ωi
t+1) +gt+1
α(ωi
t+1−ωt)
=/parenleftbig
∇ℓi(ωi
t+1) +∇ψ(ωt)/parenrightbig
−(∇ψ(ωt)−gt) +1
α(ωi
t+1−ωt)
=ei
t+1,
where∥ei
t+1∥2≤γ∥∇ℓi
t(ωt)∥2.Consequently,
ωt+1−ωt=Ei/bracketleftbig
ωi
t+1−ωt/bracketrightbig
=αEi/bracketleftbig
ei
t+1−/parenleftbig
∇ℓi(ωi
t+1) +∇ψ(ωt)/parenrightbig
+ (∇ψ(ωt)−gt)/bracketrightbig
and, adding and subtracting terms judiciously yields
=αEi/bracketleftbig
ei
t+1−∇F(ωt+1) +∇F(ωt+1)
−/parenleftbig
∇ℓi(ωi
t+1) +∇ψ(ωt)/parenrightbig
+∇ψ(ωi
t+1)−∇ψ(ωi
t+1)
+ (∇ψ(ωt)−gt)]
=−α∇F(ωt+1)−αEi/bracketleftbig
(∇ℓi(ωi
t+1) +∇ψ(ωi
t+1)−∇F(ωt+1)/bracketrightbig
−αEi/bracketleftbig
∇ψ(ωt)−∇ψ(ωi
t+1)/bracketrightbig
+α(∇ψ(ωt)−gt) +αEiei
t+1.
It follows that
∆t=ωt+1−ωt+α∇F(ωt)
=−α(∇F(ωt+1)−∇F(ωt))/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
=t1−αEi/bracketleftbig
∇ℓi(ωi
t+1) +∇ψ(ωi
t+1)−∇F(ωt+1)/bracketrightbig
/bracehtipupleft /bracehtipdownright/bracehtipdownleft /bracehtipupright
=t2
−αEi/bracketleftbig
∇ψ(ωt)−∇ψ(ωi
t+1)/bracketrightbig
/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
=t3+α(∇ψ(ωt)−gt)/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
=t4+αEiei
t+1/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
=t5.
Consider the quantity Et[⟨∇F(ωt),∆t⟩]:
Et[⟨∇F(ωt),∆t⟩]≤αEt/bracketleftbigg
∥∇F(ωt)∥2·(∥t1∥2+∥t2∥2+∥t3∥2+∥t4∥2+∥t5∥2)/bracketrightbigg
Observe that because the composite objective is L-smooth,
Et[∥t1∥2]≤LEt[∥ωt+1−ωt∥2]≤LEt/bracketleftbig
Ei/vextenddouble/vextenddoubleωi
t+1−ωt/vextenddouble/vextenddouble
2/bracketrightbig
.
Similarly, the estimate for t3uses theL-smoothness of the regularizer:
Et[∥t3∥2]≤Et/bracketleftbig
Ei/vextenddouble/vextenddouble∇ψ(ωt)−∇ψ(ωi
t+1)/vextenddouble/vextenddouble
2/bracketrightbig
≤LEt/bracketleftbig
Ei/vextenddouble/vextenddoubleωt−ωi
t+1/vextenddouble/vextenddouble
2/bracketrightbig
.
23Under review as submission to TMLR
Thet2term can also be bounded in terms of the iterate distance:
Et[∥t2∥2]≤Et/bracketleftbig
Ei/vextenddouble/vextenddouble∇ℓi(ωi
t+1) +∇ψ(ωi
t+1)−∇F(ωt+1)/vextenddouble/vextenddouble
2/bracketrightbig
≤Et/bracketleftbig
Ei/vextenddouble/vextenddouble∇ℓi(ωi
t+1) +∇ψ(ωi
t+1)−∇ℓi(ωt+1)−∇ψ(ωt+1)/vextenddouble/vextenddouble
2/bracketrightbig
,
where the last equality holds because ∇ℓ(ωt+1) =Ei∇ℓi(ωt+1). We use the triangle inequality and the
L-smoothness of ψand the functions ℓito continue our estimation:
≤2LEt/bracketleftbig
Ei/vextenddouble/vextenddoubleωi
t+1−ωt+1/vextenddouble/vextenddouble
2/bracketrightbig
≤2LEt∥ωt+1−ωt∥2+ 2LEt/bracketleftbig
Ei/vextenddouble/vextenddoubleωt−ωi
t+1/vextenddouble/vextenddouble
2/bracketrightbig
≤4LEt/bracketleftbig
Ei/vextenddouble/vextenddoubleωt−ωi
t+1/vextenddouble/vextenddouble
2/bracketrightbig
.
Thus we find that
Et/bracketleftbigg
∥∇F(ωt)∥2·(∥t1∥2+∥t2∥2+∥t3∥2)/bracketrightbigg
≤6L∥∇F(ωt)∥2·Et/bracketleftbig
Ei/vextenddouble/vextenddoubleωt−ωi
t+1/vextenddouble/vextenddouble
2/bracketrightbig
≤6L(1 +γ)
µ/bracketleftbig
B∥∇F(ωt)∥2
2+∥∇F(ωt)∥2·(G+σ)/bracketrightbig
≤6L(1 +γ)
µ/parenleftbig
(B+ 1)∥∇F(ωt)∥2
2+σ2+G2/parenrightbig
.
The last two inequalities are justified by equation 21 and the fact that |ab|≤1
2(a2+b2)for any real numbers
aandb.
The noise term t4is controlled by the variance of the stochastic gradient estimate
Et[∥t4∥2]≤/radicalig
Et∥∇ψ(ωt)−gt∥2≤σ.
To control the t5term, recall that ∥ei
t+1∥2≤γ∥∇ℓi
t(ωt)∥2. This implies that
Et[∥t5∥2] =Et/vextenddouble/vextenddoubleEiei
t+1/vextenddouble/vextenddouble
2≤Et/bracketleftbig
Ei/vextenddouble/vextenddoubleei
t+1/vextenddouble/vextenddouble
2/bracketrightbig
≤γEt/bracketleftbig
Ei/vextenddouble/vextenddouble∇ℓi(ωt) +gt/vextenddouble/vextenddouble
2/bracketrightbig
≤γEt/bracketleftbig
Ei/vextenddouble/vextenddouble∇ℓi(ωt) +∇ψ(ωt)/vextenddouble/vextenddouble
2+∥∇ψ(ωt)−gt∥2/bracketrightbig
≤γ(B∥∇F(ωt)∥2+G+σ).
The last inequality holds because of Jensen’s inequality, the bounded dissimilarity condition, and the bound
on the variance of the stochastic gradient estimate.
From these last two estimates, we find that
Et/bracketleftbigg
∥∇F(ωt)∥2·(∥t4∥2+∥t5∥2)/bracketrightbigg
≤∥∇F(ωt)∥2·σ+γ/parenleftbig
B∥∇F(ωt)∥2
2+∥∇F(ωt)∥2(G+σ)/parenrightbig
≤1
2∥∇F(ωt)∥2
2+1
2σ2+γ/parenleftbig
(B+ 1)∥∇F(ωt)∥2
2+G2+σ2/parenrightbig
,
and therefore we conclude that
Et[⟨∇F(ωt),∆t⟩]≤α6L(1 +γ)
µ/parenleftbig
(B+ 1)∥∇F(ωt)∥2
2+G2+σ2/parenrightbig
(23)
+α
2∥∇F(ωt)∥2
2+α
2σ2+αγ/parenleftbig
(B+ 1)∥∇F(ωt)∥2
2+G2+σ2/parenrightbig
≤α·cγ,L,B,µ·/parenleftbig
∥∇F(ωt)∥2
2+G2+σ2/parenrightbig
,
where, for convenience, we defined
cγ,L,B,µ =/parenleftbigg1
2+γ(B+ 1) +6L(1 +γ)(B+ 1)
µ/parenrightbigg
.
24Under review as submission to TMLR
Finally, consider the squared iterate distance in equation 22. In particular, equation 20 implies that
L
2Et∥ωt+1−ωt∥2
2≤L/parenleftbigg1 +γ
µ/parenrightbigg2/bracketleftbigg
B2∥∇F(ωt)∥2
2+G2+σ2/bracketrightbigg
.
Using this estimate and equation 23 in equation 22 gives that
Et[F(ωt+1)]≤F(ωt)−α∥∇F(ωt)∥2
2+Et/bracketleftbigg
⟨∇F(ωt),∆t⟩/bracketrightbigg
+L
2Et/bracketleftbig
∥ωt+1−ωt∥2
2/bracketrightbig
(24)
≤F(ωt)−α∥∇F(ωt)∥2
2+cγ,L,B,µ,α∥∇F(ωt)∥2
2+cγ,L,B,µ,α (G2+σ2),
where, for convenience, we define
cγ,L,B,µ,α =α·cγ,L,B,µ +LB2·/parenleftbigg1 +γ
µ/parenrightbigg2
=α/parenleftbigg1
2+γ(B+ 1) +6L(1 +γ)(B+ 1)
µ/parenrightbigg
+LB2·/parenleftbigg1 +γ
µ/parenrightbigg2
Becauseα<1
2L−,
1
µ=α
1−αL−1<2α,
and consequently
cγ,L,B,µ,α≤α/parenleftbigg1
2+γ(B+ 1) + 12αL(1 +γ)(B+ 1)/parenrightbigg
+ 4α2LB2(1 +γ)2.
We also choose γ <1
8(B+1)andγ <1
20, which further implies that
cγ,L,B,µ,α≤α/parenleftbigg5
8+ 13αL(B+ 1)/parenrightbigg
+ 5α2LB2,
and because α<min/braceleftig
1
120L(B+1),1
5LB2,1
20/bracerightig
, in fact
cγ,L,B,µ,α≤3
4α+α2≤4
5α.
Thus, we conclude that the expected decrease in the composite objective at each iteration satisfies
Et[F(ωt+1)]≤F(ωt)−α
5∥∇F(ωt)∥2
2+4α
5(G2+σ2). (25)
Convergence rate In the remainder of this proof, E[·]denotes the expectation with respect to all sources
of randomness and we take G= 0. Using the tower rule of expectations and summing over the first T
iterations, we find that
α
5T−1/summationdisplay
t=0E/bracketleftbig
∥∇F(ωt)∥2
2/bracketrightbig
−4αT
5σ2≤T/summationdisplay
t=0E[F(ωt)−F(ωt+1)]
=F(ω0)−E[F(ωT+1)]≤F(ω0)−F⋆.
Rearranging terms yields the claimed result:
1
TT−1/summationdisplay
t=0E/bracketleftbig
∥∇F(ωt)∥2
2/bracketrightbig
≤F(ω0)−F⋆
αT+ 4σ2.
25Under review as submission to TMLR
A.3 Proof of Theoram 2
Proof.We know from the definition of KHSIC that
r(ω) =1
(n−1)2Tr(KsHKfH)
=1
(n−1)2E/bracketleftbig
Tr(ZsZ⊤
sHZfZ⊤
fH)/bracketrightbig
=1
(n−1)2E/bracketleftbig
Tr(Z⊤
sHZf·Z⊤
fHZs)/bracketrightbig
=1
(n−1)2E/bracketleftbig
∥Z⊤
sHZf∥2
F/bracketrightbig
.
The first equality is the definition of the KHISC, and the second holds because the outer products of the
random feature maps are the kernel matrices, in expectation. The third holds due to the cyclicity of the
trace operator, and the final holds by the definition of the Frobenius norm. The rest of the proof follows
Lemma 1
A.4 Proof of Lemma 1:
Consider the following:
Proof.The reduced size fairness interaction matrix can be computed efficiently, by noting that
Z⊤
sHZf=Z⊤
sHHZf
Thus,
Z⊤
sH=Z⊤
s/parenleftbigg
I−1
n11⊤/parenrightbigg
=Z⊤
s−µs1⊤,and
HZf=/parenleftbigg
I−1
n11⊤/parenrightbigg
Zf=Zf−1µ⊤
f.
Putting these identities together and using the local paritition of the random feature matrices and their
means, we have that
Z⊤
sHZf=Z⊤
sZf−µs1⊤Zf−Z⊤
s1µ⊤
f+nµsµ⊤
f
=Z⊤
sZf−nµsµ⊤
f
=m/summationdisplay
i=1Z⊤
s,iZf,i−n/parenleftigg
1
nm/summationdisplay
i=1niµs,i/parenrightigg/parenleftigg
1
nm/summationdisplay
i=1niµf,i/parenrightigg⊤
, (26)
A.5 Proof of Corollary 1
Proof.We use the linearity of expectation to obtain an unbiased approximation of the gradient of the fairness
regularizer:
∇ωψ(ω) =E∇ω˜ψ(ω)
=1
(n−1)2E∇ω∥G(ω)∥2
F.
26Under review as submission to TMLR
A.6 Proof of Lemma 2
The stochastic gradient can then be computed in terms of the Jacobians of the local interaction terms Ωi
by a simple application of chain rule:
1
(n−1)2∇ω∥G(ω)∥2
F=2
(n−1)2JG(ω)TG(ω)
=2
(n−1)2m/summationdisplay
i=1JGi(ω)TG(ω).
B Details of the experimental Evaluation
B.1 Choice of Hyperparameters
Common Hyperparameters: To ensure a fair comparison, all evaluated algorithms utilize a consistent set
of common hyperparameters. The batch size is uniformly set to 64. Each algorithm undergoes a total of 10
global training rounds, with each round comprising 5 local epochs on every client. This choice of local epochs
ensured that the global model converges within 10 rounds or fewer for all datasets and distribution, allowing
us to limit the number of global rounds to 10. The experiments are conducted with 4 clients, a configuration
determined based on recent studies. Ezzeldin et al. (2023); Papadaki et al. (2022). The learning rate αwas
set to 0.01 and Adam Optimizer Kingma & Ba (2014) was used for optimization
Algorithm Specific Hyperparameters: Some hyperparameters are specific to the algorithm being used.
For example, the KFFLandKFFL-TD algorithms rely on feature maps Dto estimate the kernel regular-
izer. In our experiments, we use the Pyrfm librarypyr to generate random feature maps based on Orthogonal
Random Features Yu et al. (2016). The dimensionality of the feature maps used for kernel approximation,
denoted as D, is set to 10. While higher dimensions also yielded good results, we selected the smallest
feature map size that ensured KFFLperformed effectively..
For other baselines such as Ezzeldin et al. (2023), a tradeoff parameter called "fairness budget" βis used to
control the effect of reweighing. This tradeoff parameter determines the balance between model accuracy
and a specific evaluation metric, by varying βfrom 0.1 to 5 based on the suggestions provided in the paper.
However, it should be noted that for the best performance of the Ezzeldin et al. (2023) baseline, a local
debiasing mechanism is required. Based on the results from the paper, we used the Roh et al. (2020)
algorithm as a local demographic bias mitigation algorithm to compare with our method. Papadaki et al.
(2022) use a "global adversary rate" to control how the expected loss over the worst-performing demographic
is reduced. To consider an accuracy-fairness tradeoff, we varied this parameter from 0.001 to 0.1.
To enable fine-grained control over the tradeoff between fairness and other performance metrics, our methods
incorporateacontrollablefairnessweight λ. Thisweightcanbefine-tunedbasedonthedesiredtradeoff.More
on this in Section B.5
B.2 Dataset
Datasets for Classification Task
•ADULT : Becker & Kohavi (1996) is a binary classification dataset that contains up to 14 attributes
used in predicting whether an individual would earn an income ≥50K or≤50K. The features used
in the prediction include continuous attributes such as age, hours per week worked, etc, and discrete
attributes including relationship, race, sex, and education. For the purpose of our experimental
evaluation, we train a Logistic Regression model Mohri et al. (2019) on this dataset and we consider
sexas the protected sensitive variable.
•COMPAS :Barenstein (2019) is used for predicting criminal recidivism for individuals.The number
of samples considered is 6,172 samples and the number of predictive features used in determining
27Under review as submission to TMLR
recidivism is 52 including race, age, and previous criminal offenses. For the purpose of our experi-
mental evaluation on this dataset, we consider raceas the protected sensitive variable evaluated on
a Logistic Regression model.
•BANK:Data from a Portuguese bank utilized to forecast client subscriptions to term deposits
Han et al. (2023).Here we consider ageas the sensitive attribute and Loan Approval as the target
attribute.There are 64 predictive features (including the sensitive) and 41188 target samples.
•ACS: From the American Community Survey, utilized for various prediction tasks including income
and employment Han et al. (2023). There are 910 (including the sensitive) predictive features and
195665 samples for this dataset. We consider income as the target variable with sexas the protected
attribute.
•GERMAN :Dataon credit applicants from a German bank used for predicting credit risk ratings
Han et al. (2023) where the sensitive attribute we consider is sexand the target attribute is Credit
risk rating. There are 60 (including the sensitive) predictive features and 1000 target samples.
Datasets for Regression Task
•Law School : Sourced from the Law School Admissions Council’s National Longitudinal Bar Passage
Study Wightman (1998), this dataset contains 20,649 examples. The task is to predict a student’s
GPA—normalized to the range [0, 1]—using squared loss minimization. Race serves as the protected
attribute, categorized as white versus non-white.
•Communities and Crime : Thisdatasetcomprisessocio-economic,lawenforcement,andcrimestatis-
tics from various U.S. communities Redmond & Baveja (2002), totaling 1,994 examples. The objec-
tive is to predict the number of violent crimes per 100,000 inhabitants, normalized to [0, 1], through
squared loss minimization. The protected attribute is race, defined by whether the community’s
majority population is white.By including these datasets, we aim to thoroughly evaluate the fair
regression estimator’s performance across different contexts where fairness with respect to sensitive
attributes like race is crucial.
B.3 Data Distribution on Clients
We explore both the IID (Independent and Identically Distributed) and Non-IID (Non-Independent and
Non-Identically Distributed) settings in our evaluation:
•IID: In this setting, each client is provided with an equal number of samples and a consistent data
distribution for local training Li et al. (2020)
•Non-IID : In this setting, each of the clients has different distribution of the protected attribute.
Particularly, in our case, since the protected group Ais binary with attributes being A0andA1,
half of the clients have 90 % of A0and 10 % ofA1while the other half has 90 % of A1and 10 % of
A0Li et al. (2020)
B.4 Models
We consider two distinct types of models for classification and a linear model for regression , which
clients use for local training. In the fairness literature, Logistic Regression is commonly employed for fair
classification tasks Ezzeldin et al. (2023), while linear models are the standard choice for fair regression
Chzhen et al. (2020a). Beyond these, we extend our evaluation to include a more complex, non-convex
model for classification.
•Logistic Regression : This involves a binary logistic regression model with a sigmoid activation
function Han et al. (2023)
28Under review as submission to TMLR
•Neural Network : We also examine the performance of our algorithm using a neural network
configuration. This neural network consists of a single hidden layer with 100 neurons and employs
ReLU activation, culminating in an output layer.
B.5 Fairness weights
•ADULT: 0.00,20.00, 71.58, 123.16, 174.74, 226.32, 277.89, 329.47, 381.05, 432.63, 484.21, 535.79,
587.37, 690.53, 742.11, 793.68, 845.26, 896.84, 948.42, 1000.00
•COMPAS: 0.00, 0.01, 0.10, 20.00, 71.58, 123.16
•BANK: 0.00, 0.01, 0.10, 1.00
•GERMAN: 0.00, 0.01, 0.10, 1.00
•ACS:0.00, 0.01, 0.10, 1.00
DATA FAIR1 FAIR2Legend
KFFL-TD
DATA FAIRLegend
Figure 5: KFFLandKFFL-TD are illustrated in the figure. Different colors correspond to various segments of
communicationassociatedwitheitherthe FAIR1,FAIR2orDATAsub-rounds(seethe KFFLAlgorithmfor
detail on these flags). For KFFL-TD the relevant flags are FAIRandDATA(see see the KFFL-TD Algorithm
for detail on these flags) The direction of the arrows indicate an uplink or downlink communication and the
width of each arrowhead highlights the communication cost in each sub-round. Thicker lines indicate higher
communication overhead, while thinner lines represent smaller overhead.
C KFFL-TD - Kernel Regualarized Fair Learning with time delay
The KFFL-TD variant optimizes communication efficiency by incorporating delayed information for the fair
term. Assuming the training begins at round twitht≥1; the server transmits the current model Algorithm
5ωtand all global information from the preceding time step µs(t−1),µf(t−1),G(ωt−1)to the client for
localgradientcomputation. Thissetofdownlinkinformationisdenotedas Γ(ωt). Inthiscase, theserveralso
shares a common seed ζto control the randomness in the generation of random feature maps generated. The
client also receives a FAIRflag, indicating that no data-fitting operation is required. The clients leverage
this information to calculate the fair gradient gi(ωt−1)(if the global round is not zero) and relevant details
Φi(ωt)(see Algorithm 4), contributing to the computation of the global interaction G(ωt),µs(t), andµf(t)
which will be used in the subsequent round for the fair update (see Algorithm 5) . All of this information is
Ψi(ωt)sent by each client.
With these outdated fair gradients, the server updates the global model see Algorithm 5 and compute the
global fairness interaction terms G(ωt),µs(t)to be used by the clients in the next round. To steer the model
towards the data-fit direction, the server sends DATAflag instructing the clients perform local optimization
29Under review as submission to TMLR
Algorithm 4 KFFL-TD – Client Update
Input:(ROUND,..)
1:if ROUND =FAIR then
2:ift̸= 0then
3:Clients compute local interaction for gradients using Equation 18 at ωt−1to get Ωi(ωt−1)
4:The clients then compute the local gradient gi(ωt−1)using Equation 19
5:end if
6:Clients compute Mi(ωt)using Equation 12 with random seed ζand RFMs (such as ORFMs Yu et al.
(2016)) ,µf,i(t)using Equation 14 and µs,i(t)using 13
7: Φi(ωt) ={Mi(ωt),µs,i(t),µf,i(t)}
8:ift̸= 0then
9: Ψi(ωt) ={gi(ωt−1),Φi(ωt)}
10:else
11: Ψi(ωt) = Φi(ωt)
12:end if
13:Return:Ψi(ωt)
14:else if ROUND =DATA then
15:Clients do a local update on ωt+1/2following Equation 17 to get ωi
t+1
16:Return:ωi
t+1
17:end if
Algorithm 5 KFFL-TD – Server Side
1:ω=ω0{This is the initial model}
2:t←0
3:whileωnot converge do
4:for alli= 1,...,min parallel do
5:Generation of random seed ζ
6: ift̸= 0then
7: Γ(ωt) ={ωt,µs(t−1),µf(t−1),G(ωt−1),ζ,t}
8: else
9: Γ(ωt) ={ωt,ζ,t}
10: end if
11: Ψ(ωt) =Client Update (Γ(ωt),FAIR )
12:end for
13:ift̸= 0then
14:ωt+1/2←ωt−/summationtextm
i=1gi(ωt−1)
15:end if
16:From Ψ(ωt)clients get Φ(ωt) ={Φi(ωt)}m
i=1
17:From Φ(ωt)compute G(ωt)using Equation 11; µs(t)using Equation 13; and µf(t)using Equation
14
18:for alli= 1,...,min parallel do
19:ift̸= 0then
20:ωi
t+1=Client Update (ωt+1/2,DATA )
21:else
22:ωi
t+1=Client Update (ωt,DATA )
23:end if
24:end for
25:ωt+1←FedAvg (ωi
t+1)
26:end while
(see Equation 17) and communicate the updated copy to the server ; the server conducts Fed-Avg after
receiving these locally updated models, resulting in the generation of a the updated model. The process
continues till the model ωtconverges.
30Under review as submission to TMLR
D Additional Empirical Evaluation of Classification
Table 6 and 8 show the results of KFFLand its baselines on Logistic Regression and Neural Network across
different datasets. KFFLis most robust across datasets in the Non-IID setting and provides greater tradeoffs
for accuracy and fairness.
MethodAdult COMPAS BANK ACS GERMANAcc.FedAvg 84.30 ±1.41 61.13±1.25 91.21±1.10 81.14±1.20 72.50±1.15
KFFL 83.14 ±0.42 60.3±1.30 90.23±1.25 79.12±1.35 72.50±1.10
KFFL-TD 83.97 ±1.12 59.51±1.45 90.78±1.20 81.12±1.05 72.50±1.40
FairFed/FairBatch 76.34 ±0.1 55.47±1.50 88.05±1.30 58.77±1.20 30.00±1.25
KHSIC-Local 63.40 ±0.03 44.13±1.55 88.77±1.15 58.77±1.05 70.00±1.35
MinMax 76.34 ±0.1 56.68±1.40 64.93±1.20 58.77±1.25 70.00±1.10SPDFedAvg 0.18 ±0.06 0.16±0.02 0.23±0.01 0.08±0.04 0.19±0.03
KFFL 0.14 ±0.02 0.06±0.01 0.05±0.03 0.04±0.02 0.00±0.04
KFFL-TD 0.16 ±0.03 0.05±0.02 0.06±0.01 0.00±0.03 0.00±0.02
FairFed/FairBatch 0.004 ±0.001 0.05±0.03 0.00±0.02 0.00±0.01 0.00±0.03
KHSIC-Local 0.34 ±0.00 0.08±0.02 0.00±0.03 0.00±0.02 0.00±0.01
MinMax 0.004 ±0.001 0.03±0.01 0.21±0.02 0.00±0.03 0.00±0.02EODFedAvg 0.22 ±0.03 0.23±0.02 0.16±0.01 0.04±0.02 0.02±0.03
KFFL 0.12 ±0.03 0.07±0.01 0.04±0.02 0.02±0.03 0.00±0.02
KFFL-TD 0.04 ±0.1 0.08±0.02 0.05±0.01 0.03±0.02 0.00±0.03
FairFed/FairBatch 0.013 ±0.001 0.09±0.02 0.16±0.03 0.00±0.01 0.00±0.02
KHSIC-Local 0.12 ±0.00 0.05±0.03 0.00±0.02 0.00±0.01 0.00±0.03
MinMax 0.013 ±0.001 0.03±0.02 0.02±0.01 0.00±0.03 0.00±0.02
Table 7: Comparison of Methods in the Non-IID environment with Logistic Regression for 3 seperate
runs.Similar to the results in Table 6 under Non-IID conditions we have improved tradeoff points us-
ingKFFL
MethodAdult COMPAS BANK ACS GERMANAcc.FedAvg 84.35 ±1.45 63.20±1.30 94.25±1.15 84.10±1.25 72.55±1.20
KFFL 83.10 ±0.45 62.35±1.35 92.20±1.30 81.15±1.40 75.0±0.01
KFFL-TD 83.95 ±1.10 59.55±1.50 90.75±1.25 81.15±1.10 75.0±0.01
FairFed/FairBatch 76.30 ±0.15 55.50±1.55 88.10±1.35 58.75±1.25 37.50±1.30
KHSIC-Local 63.45 ±0.05 44.15±1.60 88.80±1.20 58.80±1.10 70.05±1.40
MinMax 76.30 ±0.15 56.70±1.45 64.95±1.25 58.75±1.30 70.05±1.15SPDFedAvg 0.17 ±0.05 0.15±0.03 0.22±0.02 0.09±0.05 0.20±0.04
KFFL 0.13 ±0.03 0.07±0.02 0.06±0.04 0.03±0.03 0.01±0.05
KFFL-TD 0.17 ±0.04 0.06±0.03 0.07±0.02 0.01±0.04 0.01±0.03
FairFed/FairBatch 0.005 ±0.002 0.06±0.04 0.01±0.03 0.01±0.02 0.01±0.04
KHSIC-Local 0.35 ±0.01 0.09±0.03 0.01±0.04 0.01±0.03 0.01±0.02
MinMax 0.005 ±0.002 0.04±0.02 0.20±0.03 0.01±0.04 0.01±0.03EODFedAvg 0.23 ±0.04 0.24±0.03 0.17±0.02 0.05±0.03 0.03±0.04
KFFL 0.13 ±0.04 0.08±0.02 0.05±0.03 0.03±0.04 0.01±0.03
KFFL-TD 0.05 ±0.11 0.09±0.03 0.06±0.02 0.04±0.03 0.01±0.04
FairFed/FairBatch 0.014 ±0.002 0.10±0.03 0.17±0.04 0.01±0.02 0.01±0.03
KHSIC-Local 0.13 ±0.01 0.06±0.04 0.01±0.03 0.01±0.02 0.01±0.04
MinMax 0.014 ±0.002 0.04±0.03 0.03±0.02 0.01±0.04 0.01±0.03
Table 8: Comparison of Methods in the Non-IID environment with Neural Network for 3 seperate runs.
Similar to the results in Table 6 under Non-IID conditions we have improved tradeoff using KFFL
E Additional Experiments for Regression Task
Tables 15, 13, 11, 12, 14, and 10 show how KFFLperforms under various regression tasks.
F Fair Regression
The KHSIC method facilitates the training of predictive models for regression tasks while ensuring fairness
across various sensitive groups. Fair regression has been extensively explored in centralized settings, with
significant contributions from studies such as Chzhen et al. (2020a); Agarwal et al. (2019a); Chzhen et al.
(2020b).
31Under review as submission to TMLR
Fairness weight λRMSE↓ KS Difference↓
0.0 0.322400±0.015698 0.462100±0.152637
1.0 0.326067±0.018071 0.386633±0.163709
50.0 0.311633±0.024243 0.410500±0.106058
100.0 0.322400±0.016542 0.277200±0.114275
Table 9: RMSE and KS Difference with standard deviations for 5 runs KFFL-TD with IIDfor the Com-
munities and Crime Dataset
Fairness weight λRMSE↓ KS Difference↓
0.0 0.317528±0.024826 0.671308±0.202138
1.0 0.317952±0.025052 0.620508±0.251276
5.0 0.316936±0.025075 0.662032±0.159920
50.0 0.317576±0.024314 0.444808±0.163534
100.0 0.317592±0.025111 0.395280±0.141982
Table 10: RMSE and KS Difference with standard deviations for 5 runs KFFLwithNon-IID for the Com-
munities and Crime Dataset
In our framework, we employ the Root Mean Squared Error (RMSE) as the primary evaluation metric to
assess the accuracy of the regression model. The objective function is defined as:
ℓ(y,f(x;ω)) =1
nn/summationdisplay
i=1(f(xi;ω)−yi)2+λψ(ω)
where xi∈Rddenotes the input features, yi∈Ris the target variable, and f(xi;ω)represents the model’s
prediction parameterized by ω. Consistent with the rest of this paper, we exclude the sensitive attribute si
from the training process of the fair regressor.
Consider a regression task on a dataset D={(xi,si,yi)}n
i=1, where xiis the input feature vector, si∈S
is the sensitive attribute (e.g., gender, race), and yiis the target variable (e.g., GPA, income). For each
sensitive group s∈S, we define the corresponding subset of data as:
Ds={(x,s,y)∈T:s=s}
To evaluate fairness in regression tasks, we utilize the Kolmogorov-Smirnov (KS) distance Chzhen et al.
(2020a), which measures the distributional differences between the model’s predictions for different sensitive
groupss∈S. The KS distance is a widely adopted fairness metric in regression, enabling the assessment of
disparities between groups. For instance, in a normalized GPA prediction task where the sensitive attribute
Srepresents gender (e.g., male and female), the KS distance quantifies the difference in GPA predictions
between these groups.
The KS distance between predictions for any two groups sands′is defined as:
KS(f(x,s)) = max
s,s′∈Ssup
t∈R/vextendsingle/vextendsingle/vextendsingleFs(t)−Fs′(t)/vextendsingle/vextendsingle/vextendsingle
whereFs(t)denotes the empirical cumulative distribution function (CDF) of the model’s predictions for
groups, calculated as:
Fs(t) =1
|Ds|/summationdisplay
(x,s,y)∈Ds1{f(x,s)≤t}
32Under review as submission to TMLR
Fairness weight λRMSE↓ KS Difference↓
0.00 0.800667±0.002491 0.450867±0.065047
0.01 0.800367±0.002579 0.398433±0.224212
0.10 0.800300±0.002524 0.412733±0.303714
1.00 0.799533±0.001940 0.148967±0.009340
Table 11: RMSE and KS Difference with standard deviations for 5 runs KFFL-TD with IIDfor the Law
School Dataset
Fairness weight λRMSE↓ KS Difference↓
0.00 0.799293±0.002132 0.514920±0.124809
0.01 0.799253±0.002306 0.452160±0.163044
0.10 0.799187±0.002101 0.467133±0.143954
1.00 0.798800±0.002080 0.140173±0.032955
Table 12: RMSE and KS Difference with standard deviations for 5 runs KFFL with IIDfor the Law School
Dataset
This formulation ensures that the regression model maintains fairness by minimizing the KS distance across
all sensitive groups, thereby promoting equitable outcomes.
33Under review as submission to TMLR
Fairness weight λRMSE↓ KS Difference↓
0.00 0.485100±0.005092 0.410600±0.031681
0.01 0.485100±0.005260 0.410833±0.026668
0.10 0.484967±0.005424 0.408967±0.013403
1.00 0.484767±0.004964 0.381000±0.009752
5.00 0.483967±0.004944 0.282967±0.010901
Table 13: RMSE and KS Difference with standard deviations for 5 runs KFFL-TD with IIDfor the Adult
Dataset
Fairness weight λRMSE↓ KS Difference↓
0.00 0.491523±0.006695 0.345782±0.082513
0.01 0.493383±0.008737 0.350317±0.111856
0.10 0.493500±0.008616 0.361175±0.080166
1.00 0.493492±0.008715 0.371725±0.040675
5.00 0.493467±0.009102 0.348567±0.034269
50.00 0.494740±0.009975 0.130180±0.050417
100.00 0.498000±0.011371 0.118580±0.100111
Table 14: RMSE and KS Difference with standard deviations for 5 runs KFFL with Non-IID for the Adult
Dataset
Fairness weight λRMSE↓KS Difference↓
0.00 0.49088±0.009294 0.38293±0.016433
0.01 0.49101±0.009303 0.39744±0.027059
0.10 0.49053±0.009130 0.37377±0.030239
1.00 0.49071±0.009039 0.38429±0.053008
5.00 0.49068±0.009474 0.26067±0.027564
50.00 0.52160±0.013804 0.06012±0.018358
100.00 0.83521±0.015799 0.34421±0.018229
Table 15: RMSE and KS Difference with standard deviations for 5 runs KFFL with IIDfor the Adult
Dataset
34Under review as submission to TMLR
G Additional: Communication-Efficient Kernel Regularized Fair Learning
In this section, we address the computational and communication challenges of incorporating kernel-based
fairness regularizers into federated learning. Specifically, we leverage Random Feature Maps (RFMs) to
approximate kernel functions efficiently, reducing both computational complexity and communication over-
head.
G.1 Random Feature Maps for Kernel Approximation
Kernel methods are powerful tools in machine learning but often suffer from high computational complexity,
especially when dealing with large datasets. Computing kernel matrices requires O(n2)memory andO(n3)
computational time, which is impractical for large n.
To overcome this, Rahimi & Recht (2007) introduced Random Feature Maps (RFMs) to approximate shift-
invariant kernel functions. A shift-invariant kernel κ(x,y) =κ(x−y)can be represented using the Fourier
transform via Bochner’s theorem. Specifically, the kernel can be expressed as:
κ(x,y) =/integraldisplay
Rdp(ω)ejω⊤(x−y)dω, (27)
wherep(ω)is the spectral density function of the kernel κ.
Constructing Random Feature Maps To approximate κ(x,y), we drawDrandom samples{ωk}D
k=1
fromp(ω)and define the random feature map ϕ:Rd→RDas:
ϕ(x) =/radicalbigg
2
D/bracketleftbig
cos(ω⊤
1x+b1),..., cos(ω⊤
Dx+bD)/bracketrightbig
, (28)
where{bk}D
k=1are drawn uniformly from [0,2π].
With this mapping, the kernel function can be approximated as:
κ(x,y)≈ϕ(x)⊤ϕ(y). (29)
Frequency of Drawing Random Features In our implementation, the random features are drawn once
at the beginning of global training round and are fixed throughout the optimization process. This ensures
consistency across iterations and clients, and avoids the overhead of regenerating random features at each
iteration.
G.2 Computing ZsandZf
In the context of our fairness regularizer, we need to compute feature maps for both the sensitive attributes
Sand the model outputs fω(X). Specifically:
•Sensitive Attributes Feature Map (Zs): For each data point i, we compute ϕ(si), wheresiis
the sensitive attribute of the i-th sample. The matrix Zs∈Rn×Dhas rowsϕ(si)⊤.
•Model Outputs Feature Map (Zf): For each data point i, we compute ϕ(fω(xi)), wherefω(xi)
is the model output (e.g., logits) for the i-th sample. The matrix Zf∈Rn×Dhas rowsϕ(fω(xi))⊤.
Example: Gaussian Kernel Approximation As an example, consider the Gaussian (RBF) kernel:
κ(x,y) = exp/parenleftbigg
−∥x−y∥2
2
2σ2/parenrightbigg
. (30)
35Under review as submission to TMLR
ThespectraldensityoftheGaussiankernelis p(ω) =N(ω;0,σ−2I). Therefore, toapproximatetheGaussian
kernel, we draw ωk∼N(0,σ−2I)and compute the feature maps as:
ϕ(x) =/radicalbigg
2
D/bracketleftbig
cos(ω⊤
1x+b1),..., cos(ω⊤
Dx+bD)/bracketrightbig
. (31)
Orthogonal Random Features To improve the quality of the approximation and reduce variance, we
employ Orthogonal Random Features (ORF) as proposed by Yu et al. (2016). Instead of sampling ωk
independently, we construct them to be orthogonal, which can lead to better kernel approximations with
fewer features.
G.3 Approximation of the Fairness Regularizer
Using the random feature maps, we approximate the kernel matrices:
Ks≈ZsZ⊤
s,Kf≈ZfZ⊤
f. (32)
The variance of the approximation decreases as the number of random features Dincreases.
Theorem 2. LetZfandZsben×Dmatrices constructed using RFMs as described above. Then, the
fairness regularizer can be approximated as:
ψ(ω) =E/bracketleftbig
∥G(ω)∥2
F/bracketrightbig
, (33)
where G(ω) =Z⊤
sZf(ω)−nµsµ⊤
f(ω)∈RD×D. Here,µs=1
n/summationtextn
i=1ϕ(si)andµf=1
n/summationtextn
i=1ϕ(fω(xi))are
the mean feature vectors.
Corollary 1. The gradient of the fairness regularizer can be approximated as:
g(ω) =∇ω∥G(ω)∥2
F, (34)
which is an unbiased stochastic estimate of ∇ωψ(ω).
G.4 Distributed Computation in Federated Settings
In a federated learning setup with mclients, the data is partitioned across clients. The random feature
matrices can be partitioned accordingly:
Zs=
Zs,1
...
Zs,m
,Zf=
Zf,1
...
Zf,m
, (35)
where Zs,i∈Rni×DandZf,i∈Rni×Dare the local random feature maps for client i, andniis the number
of samples at client i.
Lemma 1. The global feature interaction matrix G(ω)can be computed as:
G(ω) =m/summationdisplay
i=1/parenleftbig
Z⊤
s,iZf,i(ω)−niµs,iµ⊤
f,i(ω)/parenrightbig
, (36)
whereµs,i=1
ni1⊤Zs,iandµf,i=1
ni1⊤Zf,iare the local mean feature vectors at client i.
36Under review as submission to TMLR
Lemma 2. The gradient g(ω)can be partitioned into local computations as:
g(ω) =m/summationdisplay
i=1JΩi(ω)⊤G(ω), (37)
where Ωi(ω) =Z⊤
sZf,i(ω)−niµsµ⊤
f,i(ω)andJΩi(ω)is the Jacobian of Ωiwith respect to ω.
Communication Efficiency By utilizing RFMs and the above partitioning, clients only need to transmit
D×Dmatrices and D-dimensional vectors (the local interaction matrices and mean feature vectors) instead
ofn×nkernel matrices, significantly reducing communication costs.
For example, if we choose D= 1024andn= 32,000(as in the ADULT dataset), the communication cost is
reduced by a factor of (32,000/1024)2≈1000.
Synchronizing Random Features To ensure consistency across clients, we use a shared random seed ζ
to generate the random features {ωk}and{bk}at the beginning of training. All clients use the same random
feature map ϕ.
37