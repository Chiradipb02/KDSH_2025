Published in Transactions on Machine Learning Research (08/2024)
On the Data Heterogeneity in Adaptive Federated Learning
Yujia Wang yjw5427@psu.edu
College of Information Sciences and Technology
Pennsylvania State University
Jinghui Chen jzc5917@psu.edu
College of Information Sciences and Technology
Pennsylvania State University
Reviewed on OpenReview: https: // openreview. net/ forum? id= hv7iXsiBZE
Abstract
Adaptive federated learning, which benefits from the characteristic of both adaptive op-
timizer and federated training paradigm, has recently gained lots of attention. Despite
achieving outstanding performances on tasks with heavy-tail stochastic gradient noise dis-
tributions, adaptive federated learning also suffers from the same data heterogeneity issue as
standard federated learning: heterogeneous data distribution across the clients can largely
deteriorate the convergence of adaptive federated learning. In this paper, we propose a
novel adaptive federated learning framework with local gossip averaging to address this
issue. Particularly, we introduce a client re-sampling mechanism and peer-to-peer gossip
communications between local clients to mitigate the data heterogeneity without requiring
additional gradient computation costs. We theoretically prove the fast convergence for our
proposed method under non-convex stochastic settings and empirically demonstrate its su-
periorperformancesovervanillaadaptivefederatedlearningwithclientsampling. Moreover,
we extend our framework to a communication-efficient variant, in which clients are divided
into disjoint clusters determined by their connectivity or communication capabilities. We
exclusively perform local gossip averaging within these clusters, leading to an enhancement
in network communication efficiency for our proposed method.
1 Introduction
Federated learning (FL) (McMahan et al., 2017) has gained tons of attraction recently with the development
ofedgecomputingandedgedevicessuchasIoTdevicesandsmartphones. Itenablesclientstocollaboratively
learnamachinelearningmodelbyiterativelysynchronizingwiththecentralserverwithoutsharingtheirlocal
private data. Standard SGD-based federated learning methods such as FedAvg (McMahan et al., 2017) work
byaggregatingthelocal-updatedmodelsviastochasticgradientdescent. Recently, asthedemandfortraining
large-scale models such as BERT (Devlin et al., 2018), GPT-3 (Brown et al., 2020), and ViT (Dosovitskiy
et al., 2021), adaptive optimizations such as Adam (Kingma & Ba, 2014) and AMSGrad (Reddi et al., 2018)
show their efficiency compared to stochastic gradient descent (SGD). This led to the development of adaptive
federated learning methods such as FedAdam (Reddi et al., 2020) and FedAMS (Wang et al., 2022b) which
take the advantage of efficient iterative synchronization and stable adaptive optimization methods.
Despite achieving superior model training performances on tasks with heavy-tail stochastic gradient noise
distributions, adaptive federated learning still suffers from the same data heterogeneity issue as standard
SGD-based federated learning. Specifically, the statistical heterogeneity of data distribution across clients can
lead to overfitting issues of local models and degradation of global model convergence for adaptive federated
learning. This data heterogeneity issue becomes noticeable, especially in practical cases where clients are
not able to participate in each local training iteration due to system heterogeneity such as computational
capabilities. Despite that various attempts have been made in solving the data heterogeneity issue for
1Published in Transactions on Machine Learning Research (08/2024)
standard federated learning (Karimireddy et al., 2020b;a; Khanduri et al., 2021), few studies are tackling
this issue in adaptive federated learning, especially for partial participation case where only selected clients
have participated in each round of the training process.
Inthiswork, weaimtodevelopanovelfederatedlearningframework, Adaptive Federatedlearningwithlocal
GossipAveraging(AFGA),thataddressesthechallengesofstatisticalheterogeneityintheadaptivefederated
learning setting. AFGA introduces a client re-sampling strategy and peer-to-peer gossip communication
between clients during local training steps to reduce the dissimilarity between local models, thus tackling the
data heterogeneity issue. Note that AFGA does not incur extra communication between the central server
and the sampled clients, and it also does not result in extra local gradient computations. Our contributions
can be summarized as follows:
•We propose a novel adaptive federated optimization method, which benefits from both the client re-
sampling strategy and decentralized gossip averaging, to mitigate the impact of data heterogeneity
in adaptive federated optimization methods.
•We theoretically provide convergence guarantees of our proposed method in the stochastic non-
convex settings with data heterogeneity under partial client participation cases. Specifically, we
prove that our proposed method can achieve a faster convergence rate than FedAMSGrad (Wang
et al., 2022b) in partial participation settings.
•Moreover, wealsoextendourframeworktoacommunication-efficientvariant, CAFGA,whereclients
are divided into disjoint clusters and the local gossip communications are only performed within the
clusters, thus leading to an overall efficient communication network. We demonstrate that CAFGA
can achieve comparable performance and final accuracy to AFGA while simultaneously enhancing
overall communication efficiency.
•ExtensiveexperimentsonseveralbenchmarkdatasetsdemonstratetheproposedAFGAandCAFGA
achieving outstanding performance with heterogeneous data in low client participation ratios.
2 Related Work
Federated learning. Federated learning (Konečn` y et al., 2016) play a critical role in collaboratively
training models at edge devices with potential privacy protections. Basic optimization methods for federated
learning include SGD-based global optimizer, e.g., FedAvg (McMahan et al., 2017) (a.k.a. Local SGD (Stich,
2018) and its variants (Li et al., 2019a; Yang et al., 2021), adaptive gradient optimization based global
optimizer such as FedAdam, FedAdagrad, FedYogi (Reddi et al., 2020), FedAGM (Tong et al., 2020) and
FedAMS (Wang et al., 2022b). While these optimization methods for federated learning show their ability
on achieving stable results when data are heterogeneously distributed, they rarely study data heterogeneity
itself. Recently, several works address the data heterogeneity issue through several aspects. For example,
FedProx (Li et al., 2020a) adds a proximate term to align the local model with the global one, and FedDyn
(Acar et al., 2021) involves dynamic regularization term for local and global model consistency. FedNova
(Wang et al., 2020b) proposes a normalized averaging mechanism that reduces objective inconsistency with
heterogeneous data. Moreover, several works study to eliminate the client drift caused by data heterogeneity
from the aspect of variance reduction such as Karimireddy et al. (2020b;a); Khanduri et al. (2021); Cutkosky
& Orabona (2019). They introduce additional control variables to track and correct the local model shift
during local training, but they require extra communication costs for synchronizing these control variables.
Besides, FedDC (Gao et al., 2022) involves both dynamic regularization terms and local drift variables for
model correction.
Recent studies extend the decentralized training paradigm to federated learning with various adaption. For
example, Guo et al. (2021) considered heterogeneous communications for modern communication networks
that improve communication efficiency, and hierarchical federated learning algorithms (Liu et al., 2020; Abad
etal.,2020;Castigliaetal.,2020)developframeworksbyaggregatingclientmodelstoedgeserversfirstbefore
synchronizing them to the central server.1
1Due to space limitations, we leave the detailed related work for decentralized learning in Appendix.
2Published in Transactions on Machine Learning Research (08/2024)
3 Proposed Method
3.1 Preliminaries
In federated learning, we aim to minimize the following objective through Nlocal clients:
min
x∈Rdf(x) :=1
NN/summationdisplay
i=1fi(x) =1
NN/summationdisplay
i=1EDi[fi(x;ξi)], (1)
where xdenotes the model parameters, ddenotes the dimension of model parameters x,fi(x) =
Eξi∼Difi(x,ξi)is the local loss function corresponding to client iand letDidenotes the local data dis-
tribution associated with client i. In this work, we focus on the non-convex optimization problem with
heterogeneous data distributions, i.e., fiare non-convex and the local data distribution Diare non-i.i.d. dis-
tributed among clients. FedAvg (McMahan et al., 2017) is a basic optimization algorithm to solve equation 1,
with the sequential implementation of local SGD updates and global averaging.
Adaptive federated optimizations. Adaptive federated learning is proposed to incorporate adaptive
optimization methods (such as Adam (Kingma & Ba, 2014) and AMSGrad (Reddi et al., 2018)) to global
optimizer by replacing the global averaging step in FedAvg. Reddi et al. (2020) summarizes several adaptive
federated learning algorithms, and Jin et al. (2022) proposed FedDA, a momentum decoupling adaptive
optimization method from the perspective of the dynamics of ODEs. FAFED (Wu et al., 2022) also studied
adaptive federated learning but in the context of full participation. FedAMSGrad (Tong et al., 2020; Wang
et al., 2022b) considers local SGD updates and global AMSGrad (Reddi et al., 2018) update on the central
server. Specifically, at global round r∈[R], the server broadcasts the model xrto selected clients in the set
Sr. The selected client iconductsIsteps of local SGD updates with local learning rate ηland obtains the
local model xi
r,I. Then for the selected client i, it obtains a model difference ∆i
r=xi
r,I−xrand sends to
the server. The server aggregates ∆i
rthen updates the global model xr+1by taking ∆ras a pseudo gradient
for calculating momentum mrand variance vrfor AMSGrad optimizer, and performs one step AMSGrad
update with global learning rate η, i.e.,
mr=β1mr−1+ (1−β1)∆r,vr=β2vr−1+ (1−β2)∆2
r,
/hatwidevr= max{/hatwidevr−1,vr},xr+1=xr+ηmr√/hatwidevr+ϵ, (2)
the server finally obtains model xr+1by global round r. It’s worth mentioning that if the set of selected
clientsSrcontains all clients, i.e., |Sr|=N, it is known as full participation or without client sampling, and
if|Sr|=M <N, we denote it as partial participation or with client sampling.
Heterogeneous and inconsistency. Previous works show that FedAvg suffers from convergence degra-
dation when data is non-i.i.d. distributed on local clients (Karimireddy et al., 2020b;a; Wang et al., 2020b).
Several works on adaptive federated learning (Reddi et al., 2020; Wang et al., 2022b) empirically demon-
strate that the unbalanced data distribution across clients may lead to worse performance, which implies
these adaptive federated methods, unfortunately, do not escape from the convergence degradation as well.
Theoretically, it has been shown that when the local data are heterogeneously distributed among clients,
FedAMS/FedAMSGrad (Wang et al., 2022b) under partial participation setting is proved with convergence
rateO(√
I/√
RM)w.r.t. global communication rounds R, local update iterations Iand the number of
participated clients Mwhich has a certain gap between the desired rate O(1/√
RIM). Although several
works apply variance reduction techniques to show their ability to reduce the effect of data heterogeneity
in federated learning (Karimireddy et al., 2020a;b), they are less compatible with the global adaptive opti-
mizer. This motivates us to develop a new framework for mitigating the model inconsistency caused by data
heterogeneity in adaptive federated learning.
3.2 AFGA: Adaptive Federated Learning with Local Gossip Averaging
To reduce the inconsistency between local models and achieve a better convergence rate under heterogeneous
data in partial participation settings, we proposed a novel Adaptive Federated Learning with Local Gossip
3Published in Transactions on Machine Learning Research (08/2024)
Averaging (AFGA) method with peer-to-peer gossip communication and client re-sampling framework. The
peer-to-peer gossip communication implies that clients are able to communicate their local model without
help from the server. Suppose there are in total Nclients, we study the same objective function as other
adaptive federated learning methods with a similar global framework but a different local updating process.
Algorithm 1 AFGA: Adaptive Federated Learning with Local Gossip Averaging
Input:initial point x1, local step size ηland global step size η, optimizer hyperparameter β1,β2,ϵ, doubly
stochastic mixing matrix W
1:m0←0,v0←0
2:forr= 1toRdo
3:Randomly sample a subset of clients Srfor collecting local updates in round r
4:Clients Init: clients in Srreceive xrfrom the server and broadcast to all clients with local communi-
cations
5:fort= 0,...,I−1do
6:Randomly re-sample a subset of clients Sr,tfor gradient computation
7: foreach client i∈[N]in parallel do
8: ifi∈Sr,tthen
9: Compute gi
r,t=∇Fi(xi
r,t;ξi
r,t)
10: xi
r,t′=xi
r,t−ηlgi
r,t
11: else
12: xi
r,t′=xi
r,t
13: end if
14: Gossip: xi
r,t+1=/summationtext
j∈Ni(W)i,jxj
r,t′
15: end for
16: end for
17:Clientsi∈Srsend ∆i
r=xi
r,I−xrto the server
18:Aggregate model updates: ∆r=1
|Sr|/summationtext
i∈Sr∆i
r
19: mr=β1mr−1+ (1−β1)∆r
20: vr=β2vr−1+ (1−β2)∆2
r
21:/hatwidevr= max(/hatwidevr−1,vr)and/hatwideVr= diag(/hatwidevr+ϵ)
22:Server update xr+1=xr+ηmr√
/hatwidevr+ϵ
23:end for
If we take a deeper look at the local update steps (Lines 5-16), the major difference between AFGA and
FedAMS/FedAMSGrad is the re-sample step (Line 5) and the gossip communication step (Line 14), which
we will discuss in detail in the following.
Client re-sampling. Note that for each global training round, we have already sampled a subset of
participating clients Sr. Normally (e.g., in FedAMS/FedAMSGrad), this will be the fixed chosen subset of
clients who actually performs local gradient computations throughout this global training round. Yet for
AFGA, we perform client re-sampling at each local iteration to obtain a new subset Sr,tand only the selected
clients in the subset Sr,tare active for gradient computation in that local iteration, while the other clients
will stay idle. Note that such a design does not incur extra local gradient computations as the size of Sr,tis
the same asSr.
Gossip communications. After finishing the local gradient computations and model update with respect
to the selected subset of clients, AFGA introduces a gossip communication step that allow each client to
communicate their model weights with their connected neighbors (the selected subset of clients are connected
in a graphGwith a corresponding mixing matrix W). This gossip communication step is conducted by all
local clients despite being selected in Sr,tor not. While in practice, clients are not required to know the
whole mixing matrix W. Instead, client ionly needs to maintain the weights corresponding to those it
receives from other clients.
4Published in Transactions on Machine Learning Research (08/2024)
It’s important to note that AFGA does not necessitate the sampling of every client in specific rounds or
iterations. In practical cases, if a client is unavailable, then it would not be sampled during local steps. If
we remove the re-sampling step by setting Sr,t=Stand remove the gossip communication step by setting
xi
r,t+1=xj
r,t′, AFGA will reduce to standard FedAMSGrad algorithm.
Remark 3.1.Our AFGA algorithm benefits from both gossip communications and client re-sampling while
preserving the stable behavior of adaptive gradient methods. The steps of re-sampling in each local iteration
help reduce the impact of data heterogeneity. It allows more clients to be included and participate in local
training, which results in training a global model with a more balanced data distribution than without re-
sampling. The peer-to-peer gossip communication is inspired by the recent advancement in decentralized
optimization (Lian et al., 2017; Koloskova et al., 2020; Chen et al., 2021b), which has shown the ability
to reduce the data heterogeneity issues between clients. By involving gossip communications in adaptive
federated learning, it enables local models to average with their neighbors, thus preventing over-fitting
on local data. The frequent re-sampling and gossip communications make AFGA effectively reduce the
inconsistency between local clients, thus accelerating the overall convergence especially when the number
of local steps increases. AFGA is also crucial to practical scenarios as it is compatible with low client
participation ratios and limited local gradient computation capability while addressing the challenge of
statistical heterogeneity in adaptive federated methods.
4 Convergence Analysis
In this section, we provide the theoretical convergence analysis of the proposed AFGA method. Before
starting with the main theoretical results, let us first state the following assumptions based on stochastic
optimization and adaptive gradient methods. For vector xand matrix A, we let∥x∥=∥x∥2and∥A∥=
∥A∥F. and∥A∥2represents the spectral norm of A. We denote 1as vector with all elements equal to 1, and
Ias the identity matrix, with appropriate dimension.
Assumption 4.1. Each local objective function is L-smooth, i.e.,∀x,y∈Rd,/vextendsingle/vextendsinglefi(x)−fi(y)−⟨∇fi(y),x−
y⟩/vextendsingle/vextendsingle≤L
2∥x−y∥2,∀i∈[N]. This also implies the L-gradient Lipschitz condition, i.e., ∥∇fi(x)−∇fi(y)∥≤
L∥x−y∥.
Assumption 4.2. Thestochasticgradientoneachclienthasaboundedlocalvariance, i.e., ∀x∈Rd,i∈[N],
there is E/bracketleftbig
∥∇fi(x,ξ)−∇fi(x)∥2/bracketrightbig
≤σ2.
Assumption 4.1 to 4.2 are standard assumptions in centralized and federated non-convex stochastic opti-
mization problems (Kingma & Ba, 2014; Li et al., 2019a; Yang et al., 2021; Reddi et al., 2020).
Assumption 4.3. Each local objective function fi(x)hasG-bounded stochastic gradient on ℓ2, i.e., for all
ξ, we have∥∇fi(x,ξ)∥≤G,∀i∈[N].
Note that Assumption 4.3 is a standard assumption in non-convex adaptive optimization problems for under
centralized and federated learning settings (Kingma & Ba, 2014; Reddi et al., 2018; Chen et al., 2020; Reddi
et al., 2020; Wang et al., 2022a;b; 2024b)
Assumption 4.4. The dissimilarity between client’s objective function and the global objective function is
bounded, i.e.,∀x∈Rd, there is1
N/summationtextN
i=1∥∇fi(x)−∇f(x)∥2≤σ2
g.
Assumption 4.4 captures the objective dissimilarity between the local and global objectives. Similar data
heterogeneityassumption, whichconsidersthevariancebetweenlocalclients, iscommoninfederatedlearning
(Reddi et al., 2020; Yang et al., 2021; Wang et al., 2022b; 2024a) and decentralized learning (Lian et al.,
2017; Li et al., 2019b; Koloskova et al., 2020).
Assumption 4.5 (Spectral gap) .For the gossip communications, clients are connected in the graph G, and
the corresponding weighting matrix Wis adoubly stochastic matrix :W∈[0,1]n×n,W1=1,1⊤W=1⊤
and null (I−W) =span(1). We assume the spectral gap ρof matrixWsatisfies: there exists ρ∈[0,1)such
that∥W−1
n11⊤∥2≤ρ.
Assumption 4.5 is highly related to the gossip communication update process and is usually assumed for
decentralized learning framework (Koloskova et al., 2020; Chen et al., 2021b; Guo et al., 2021). For a doubly
5Published in Transactions on Machine Learning Research (08/2024)
stochastic matrix W,∥W−1
n11⊤∥2≤1naturally established2, and the spectral gap ρ∈[0,1)describes
the connectivity of the clients: a smaller spectral gap ρindicates a denser connectivity between clients.
Specifically, ρ= 0indicates that all elements in the matrix Ware1
n, and this means that each client would
be connected and communicated with other clients in the network with a mixing weight of1
n.ρ→1means
the matrix Wtends to be elements with either 0 or 1, corresponding to a graph that is nearly disconnected.
We assume that there exists ρ∈[0,1)to satisfy∥W−1
n11⊤∥2≤ρsince our proposed method is contributed
by gossip communications between clients. Several works (Lian et al., 2017; Li et al., 2019b) alternatively
assume the spectral gap ρof a weighting matrix Was the second largest eigenvalue of a doubly stochastic
matrixW, i.e.,ρ=|λ2(W)|, and this spectral gap holds the same role for revealing the connectivity of the
graph.
Theorem 4.6 (Convergence analysis for Algorithm 1) .Under Assumptions 4.1-4.5, if the local learning rate
η= Θ(N/radicalbig
I/M)andηl= Θ(1/√
RI2), and the network spectral gap satisfies ρ≤M
M+N, then the iterates
of Algorithm 1 satisfy
1
RR/summationdisplay
r=1E[∥∇f(xr)∥2]
=O/parenleftbigg1√
RIM/bracketleftbigg
∆f+L(σ2+σ2
g)/bracketrightbigg/parenrightbigg
+O/parenleftbigg1
R/bracketleftbigg
G2+L2(1 +ρ2)σ2
g+ρ2σ2
I/bracketrightbigg/parenrightbigg
+/tildewideO/parenleftbigg1
R3/2/parenrightbigg
,(3)
where ∆f=f0−f∗,/tildewideO(·)hides all the absolute constants and problem dependent constants including
ρ,σ,σ2
g,I,M,N,G .
Corollary 4.7. Theorem 4.6 suggests that with sufficient amounts of global communication rounds R, i.e.,
R≥IM, our proposed method achieves a convergence rate of O/parenleftbig1√
RIM/parenrightbig
. This improves the rate O/parenleftbig√
I√
RM/parenrightbig
of adaptive federated optimization methods under partial client participation (Wang et al., 2022b), which
suggests that AFGA can indeed bring accelerated convergence through local gossip communications.
Remark 4.8.The sufficient amounts of global communication rounds that R≥IMis a commonly-used
condition to obtain the convergence rate in FL (Wang et al., 2022b; Yang et al., 2021). This condition is
also practical as the algorithm usually converges after sufficient global rounds.
Remark 4.9.The impact of data heterogeneity is reflected in the variance σgwithin the convergence rate.
From equation 3, the variance σgappears in O/parenleftbig1√
RIM/parenrightbig
and smaller order terms w.r.t. R,I, andMfor
AFGA. The partially participated FedAvg in Yang et al. (2021) and adaptive FL models like FedAMS (Wang
et al., 2022b) obtain the rate of O/parenleftbig√
I√
RM/parenrightbig
, and the dominant O/parenleftbig√
I√
RM/parenrightbig
term directly relates to the variance
σg. This demonstrates improvements over partially participated adaptive FL models like FedAMS (Wang
et al., 2022b).
Remark 4.10.The second term of the convergence rate in equation 3 contains terms with spectral gap ρ
of the gossip communication network. A larger value of ρcorresponds to a sparser network, which results
in a larger variance term in the convergence rate, indicating that the dissimilarity variance has not been
completely eliminated.
5 Communication-efficiency: Clustered-clients AFGA and Further Adaptation
CAFGA. While the frequent gossip communications enhance the overall performance of heterogeneous
federated learning, it indeed involves extra peer-to-peer communication overhead, which makes our proposed
AFGA less efficient in communication especially when clients are densely connected. Recent studies (Guo
et al., 2021; Yuan et al., 2020) show that clients can be gathered into neighboring clusters based on locations
or network capabilities, in which gossip communications are less expensive than communicating with the
whole network. A similar idea of dividing clients into clusters has recently been studied in federated learning
(Guo et al., 2021; Malinovsky et al., 2022; Long et al., 2022) and receives a lot of attention. Note that
under a cluster-clients design, part of the network clients are grouped in a cluster, and clients within the
2Theoretical analysis is provided in the Appendix C.
6Published in Transactions on Machine Learning Research (08/2024)
Algorithm 2 CAFGA: Clustered-Client Adaptive Federated Learning with Local Gossip Averaging
Input:initial point x1, local step size ηland global step size η, , optimizer hyperparameter β1,β2,ϵ,
doubly stochastic mixing matrix W
1:m0←0,v0←0
2:forr= 1toRdo
3:foreach cluster k∈[K]in parallel do
4:Randomly sample a subset Sk
rfor collecting local updates in round r
5:Init: clients inSk
rreceive xrfrom the server and broadcast xrto all local neighbors
6: fort= 0,...,I−1do
7: Randomly re-sample a subset of clients Sk
r,tfor gradient computation
8: foreach client i∈Vkin parallel do
9: ifi∈Sk
r,tthen
10: Compute gi
r,t=∇Fi(xi
r,t;ξi
r,t)
11: xi
r,t′=xi
r,t−ηlgi
r,t
12: else
13: xi
r,t′=xi
r,t
14: end if
15: GossipComm: xi
r,t+1=/summationtext
j∈Ni
k(W)i,jxj
r,t′
16: end for
17: end for
18:Clientsi∈Sk
rsend ∆i
r=xi
r,I−xrto the server
19: end for
20:Aggregate: ∆r=1
K/summationtext
k∈[K]1
|Skr|/summationtext
i∈Skr∆i
r
21:Server update follows Lines 19-22, Algorithm 1
22:end for
cluster can be connected through high-bandwidth peer-to-peer communications, leading to an efficient gossip
communication network and a relatively smaller spectral gap. This leverages the communication efficiency
for applying gossip communications while maintaining comparable performance for our proposed AFGA.
Suppose there are still in total Nclients, we study the same objective as Eq. equation 1 but we partition
the clients into Kdisjoint clusters where each of them has nclients (N=Kn)3. We denoteVkas the set of
local clients in cluster k,k∈[K]and denote the neighbors for client i∈VkasNi
k. Similar to Algorithm 1,
we denote the weighted matrix of gossip averaging as Wk, and the corresponding spectral gap ρk. We then
referρmaxas the maximum spectral gap among all clusters to represent the overall density in the network.
Algorithm 2 summarizes the proposed Clustered-clients paradigm AFGA(CAFGA). At the beginning of
global round r, the server sample total Mclients (for convenience, uniformly sampled mclients in each
cluster) for global synchronization. The update rule inside each cluster follows the similar local update
rule as Algorithm 1 with clients re-sampling andgossip communications in each local iteration, all clusters
perform the training process parallelly. To be specific, at the t-th local iteration in cluster k, clients in the
re-sampled subset Sk
r,tare active for gradient computation, while the unselcted clients stay idle. All clients
in clusterkthen perform a gossip communication step with mixing matrix Wk. The leftover global update
process of the clustered-client framework is the same as Algorithm 1 and FedAMS.
We also provide a complete theoretical convergence analysis for the Clustered-clients paradigm of AFGA
(CAFGA); due to space limits, we referred interested readers to Appendix D for more details. In a nutshell,
our theoretical analysis suggests that the convergence of CAFGA is related to ρmaxwhich aligns with the
convergence rate of Algorithm 1, and implies that more densely connected gossip communications can help
reduce the impact of data heterogeneity. Empirically we observe that under the same gossip communica-
tion structure (e.g., ring topology), the clustered-clients paradigm obtains performance improvement since
3We omit the clustering process in the algorithm for simplicity. The algorithm is compatible with various clustering methods,
including clustering based on locations and network conditions, clustering based on client similarities, and random clustering.
7Published in Transactions on Machine Learning Research (08/2024)
grouping the whole network into disjoint clusters making the local clients more densely connected thus have
smallerρvalues. The clustered-clients paradigm enables efficient and dense connections for adequate model
averaging, which keeps the benefits of further mitigating the effects of data heterogeneity.
Communication-adapted: reduce the communication frequency. Despite AFGA achieves a faster
convergence rate, one noticeable drawback is that it requires all clients to stay online to conduct frequent
gossip averaging, even if some of the clients do not participate in local training (gradient computation).
We want to emphasize that this design is mainly for the ease of theoretical analysis. In practice, we can
avoid this issue by enforcing gossip communications only on selected clients in each round4. As shown in
the next Section, such a communication-adapted AFGA actually enjoys similar model training performances
compared to the original AFGA algorithm without requiring dense gossip communications for all clients.
Also, note that this communication-adapted can also be applied here to CAFGA for further improving
communication efficiency while achieving similar model performances.
6 Experiments
Datasets and models. We conduct experiments on CIFAR-10 (Krizhevsky et al., 2009), CIFAR-100
(Krizhevsky et al., 2009) and Shakespeare (Caldas et al., 2018) dataset with various data sampling levels
and client participation settings. We evaluate experiments on non-i.i.d. data distributions by a Dirichlet
distribution partitioned strategy with parameter α= 0.6similar to Wang et al. (2020a;b). For image clas-
sification tasks on CIFAR-10 and CIFAR-100 datasets, we adopt a ConvMixer-256-8 network (Trockman
& Kolter, 2022), which shares similar ideas to vision transformer (Dosovitskiy et al., 2021) to use patch
embeddings to preserve locality and similarly, and is trained via adaptive gradient methods by default. For
the next-character prediction task on Shakespeare, we adopt a 2-layer LSTM network, with 80-dimensional
word embedding and 256 hidden units per layer, and follow a dropout layer with dropout rate 0.05.
Baselines and methods. We compare our method with several federated learning and adaptive feder-
ated learning baselines including FedAvg (McMahan et al., 2017), FedAdam (Reddi et al., 2020), FedAMS-
Grad(Wang et al., 2022b)5, SCAFFOLD (Karimireddy et al., 2020b) FedProx (Li et al., 2020b) and FedDyn
(Acar et al., 2021).
Implementation overview. The number of local training iterations Ion each client is set to 24 for ex-
periments on CIFAR-10 and CIFAR-100 datasets, and I= 100for experiments on the Shakespeare dataset,
and the batch size is set to 50 for all experiments by default. We report 500 rounds (denoted as #R or
# Rounds in tables and figures) for the CIFAR 10 and the Shakespeare datasets and 600 rounds for the
CIFAR-100 dataset. For each dataset and setting, the number of local training iterations Iand the total
rounds of training #R are fixed across all baseline methods to ensure a fair comparison. For local update,
we use the SGD optimizer with a learning rate from {0.1, 1} for SGD-based global optimization methods
(FedAvg, SCAFFOLD, FedProx, and FedDyn), and use SGD optimizer with a learning rate from {1,2,10} for
adaptive global optimization methods. For a fair comparison, the local SGD updates apply no momentum
and no gradient clipping steps for all methods. We set the global learning rate as 1 for SGD-based global
update, and set the global learning rate as 0.01 for global adaptive optimization, FedAdam, FedAMSGrad,
and our proposed AFGA. See Appendix B for more details about the experimental setup including datasets,
models, and hyperparameter details.
6.1 Main Results
We summarize the performance of our proposed methods and other federated learning baselines in Table 1,
Table2and3. Duetospacelimits, weleavethelearningcurvesandmostablationstudiesinAppendixB.Our
experiments based on two settings, Setting 1: 100 clients with 5% participation ratio and Setting 2: 50
clients with 10% participation ratio. For the Clustered-clients AGFA (CAFGA), we evenly partition clients
into 5 clusters for both settings, i.e., for Setting 1: there are 20 clients in each cluster with participate
4For example, suppose we train AFGA with a ring topology and select Mout ofNclients to participate in each round. We
can form a new ring topology over the Mselected clients and only ask them to communicate over the new ring topology. In
this way, the gossip communications only include these active clients while other unselected clients do not need to stay online
and participate in the training process.
5FedAMSGrad is one of the variants of the FedAMS algorithm introduced in Wang et al. (2022b).
8Published in Transactions on Machine Learning Research (08/2024)
Table 1: The test accuracy of different methods on CIFAR-10 datasets. Setting 1 : 100 clients, 5% partici-
pation. Setting 2 : 50 clients, 10% participation. We report the average and the standard derivation over
3 runs with different random seeds.
MethodSetting 1 Setting 2
Acc. & std R# (78%) Acc.& std R# (78%)
FedAvg 75.57±1.10 313 76.85±1.69 180
FedAdam 77.07±0.05 425 78.46±0.19 157
FedAMSGrad 77.53±0.60 388 79.59±0.76 154
SCAFFOLD 76.94±1.17 273 76.46±3.95 146
FedProx 75.63±1.24 500+ 76.91±1.39 180
FedDyn 77.68±0.06 297 78.55±0.36 160
AFGA 78.45±0.58 302 80.02±2.00 152
CAFGA 79.18±1.02 233 82.10±0.67 112
Table 2: The test accuracy of different methods on CIFAR-100 datasets. Setting 1 : 100 clients, 5%
participation. Setting 2 : 50 clients, 10% participation. We report the average and the standard derivation
over 3 runs with different random seeds.
MethodSetting 1 Setting 2
Acc. & std R# (52%) Acc.& std R# (52%)
FedAvg 49.88±0.33 600+ 51.21±0.23 600+
FedAdam 50.40±0.53 600+ 51.99±0.81 375
FedAMSGrad 50.58±0.99 600+ 52.15±0.58 278
SCAFFOLD 51.71±0.21 396 55.12±1.01 235
FedProx 49.75±0.13 600+ 51.28±0.10 600+
FedDyn 49.93±0.22 396 51.93±0.52 600+
AFGA 52.08±0.17 436 53.87±0.68 369
CAFGA 53.08±0.72 380 54.41±0.24 230
ratio 5%, and for Setting 2: there are 10 clients in each cluster with participate ratio 10%. We set ring
topology as the default gossip communication topology.
Results on CIFAR-10 and CIFAR-100. Table 1 and Table 2 show the overall performance on training
CIFAR-10 and CIFAR-100 datasets with ConvMixer-256-8 model. We observe that AFGA shows improve-
ment upon other baselines, and the proposed CAFGA achieves better performance than AFGA.
ForSetting 1 on CIFAR-10, based on the results on three random seeds, AFGA shows an average 1.5%
improvement in accuracy compared to SCAFFOLD, nearly 0.8% improvement compared to FedDyn, and
nearly 1% improvement compared to FedAMSGrad, The proposed CAFGA, our extension on clustered-
clients setting, further improves 0.7% accuracy based over AFGA. For Setting 2 on CIFAR-10, CAFGA
demonstrated around 3.5% increase in accuracy over FedDyn and 2% increase over FedAMSGrad. Note that
inbothsettings, AFGAandCAFGAshowtheirsuperiorperformanceinachievingdesiredtestaccuracy. This
demonstrates our proposed AFGA and CAFGA achieve overall better performance than adaptive federated
learning methods and other federated learning baselines in both settings.
Table 2 shows that in experiments on CIFAR-100, for Setting 1 , AFGA and CAFGA obtain higher test
accuracy among other baselines including SCAFFOLD and FedDyn. Specifically, CAFGA significantly
outperforms all baselines with more than 1.3% increase over SCAFFOLD and more than 2% increase over
FedAdam and FedAMSGrad. For Setting 2 , our proposed AFGA and CAFGA still outperform other
federated learning baselines expect for SCAFFOLD.
9Published in Transactions on Machine Learning Research (08/2024)
Table 3: The test accuracy of different methods on Shakespeare datasets. Setting 1 : 100 clients, 5%
participation. Setting 2 : 50 clients, 10% participation. We report the average and the standard derivation
over 3 runs with different random seeds.
MethodSetting 1 Setting 2
Acc. R#(52%) Acc. R# (52%)
FedAvg 48.66±0.01 500+ 49.59±0.56 500+
FedAdam 52.35±0.10 391 52.23±0.08 189
FedAMSGrad 52.09±0.23 239 51.96±0.06 220
SCAFFOLD 51.39±0.02 500+ 52.76±0.06 166
FedProx 48.55±0.01 252 49.33±0.48 229
FedDyn 51.87±0.03 500+ 50.81±0.08 500+
AFGA 53.08±0.08 121 53.13±0.04 108
CAFGA 53.20±0.05 152 53.57±0.02 91
Results on Shakespeare. Table 3 shows the overall performance of training the Shakespeare dataset with
a 2-layer LSTM network. For Setting 1 on Shakespeare, AFGA shows approximately 2.5% improvement in
accuracy compared to SCAFFOLD, and 0.5% improvement compared to FedAMSGrad. The proposed
CAFGA achieves even higher final accuracy than AFGA and significantly outperforms other baselines.
ForSetting 2 on Shakespeare, AFGA addresses increasing in accuracy over FedAMSGrad, while CAFGA
outperforms AFGA in final results. In both settings, AFGA or CAFGA show their superior performance in
achieving desired test accuracy.
6.2 Ablation Studies
Sensitivity of gossip averaging and client re-sampling. We conduct experiments studying how the
individual components, gossip averaging and re-sampling, and the clustered-clients framework contribute
to the proposed AFGA and CAFGA. Table 4 presents the ablation study of the contribution of individual
components, which indicates that the gossip averaging and client re-sampling simultaneously contribute to
the accuracy improvements of AFGA. Furthermore, by the results from Table 4 (also with the observation
of the learning curves in Appendix B), it shows that the clustered-clients paradigm further improves overall
accuracy. These results show our intuition of utilizing gossip averaging and client re-sampling can effectively
mitigate data heterogeneity, and also address the benefit of the clustered-client framework that consistently
helps improve the performance. In addition to the aforementioned ablation studies, we have also conducted
further ablation studies to investigate the effect of data heterogeneity, examine different gossip averaging
topologies to understand the impact of the spectral gap on model performance, and explore the effects of
varying the number of local iterations. Due to constraints on space, we provide detailed ablation studies and
results in Appendix.
Table 4: Ablation of components at the last 5 rounds (in total 500 rounds) in training CIFAR-10 on
ConvMixer-256-8 model.
Methods (FedAMSGrad) Acc.
FedAMSGrad Only 79.59±0.76
+Gossip 77.39±0.01
+Gossip + Re-sampling ( AFGA) 80.02±2.00
+Gossip + Re-sampling + Clustered ( CAFGA )82.10±0.67
Ablation of gossip averaging topology. We also conduct ablation studies on how the gossip averaging
topology affects the overall performance in (C)AFGA. Figure 1 shows the ablation study on (a) spectral gap
in AFGA and (b) clusters’ maximum spectral gap ρfor 5 clusters in CAFGA.
10Published in Transactions on Machine Learning Research (08/2024)
0 100 200 300 400 500
#Rounds101
100Training Lossmax=0
max=0.455
max=0.995
0 100 200 300 400 500
#Rounds0.600.650.700.750.800.85Test Accuracy
max=0
max=0.455
max=0.995
(a) AFGA
0 100 200 300 400 500
#Rounds101
100Training Lossmax=0
max=0.335
max=0.766
max=0.873
0 100 200 300 400 500
#Rounds0.600.650.700.750.800.85T est Accuracymax=0
max=0.335
max=0.766
max=0.873
 (b) CAFGA
Figure 1: Ablation study with different heterogeneity degree of (C)AFGA in training CIFAR-10 on
ConvMixer-256-8 model.
We follow the Setting 2 in Table 1, i.e., 50 clients with a participation ratio of 0.1. For AFGA, we
compare various of ρfromρ={0,0.455,0.995}calculated by balanced fully-connected, random, and ring
typologies correspondingly. We observe that the balanced fully-connected topology with ρ= 0contributes to
faster convergence, which aligns with the theoretical result that smaller ρcan help reduce the impact of data
heterogeneity. SimilartoCAFGA,wecomparevariousof ρmaxfromρmax={0,0.335,0.766,0.873}calculated
by balanced fully-connected, unbalanced fully-connected6, random, and ring typologies correspondingly. It
shows that the fully-connected topology (relatively small ρmaxvalue) results in faster convergence as well.
Ablation on data heterogeneity. We further conduct experiments to investigate the impact of data
0 100 200 300 400 500
#Rounds101
100Training LossIID
=0.6
=0.3
0 100 200 300 400 500
#Rounds0.40.50.60.70.80.9Test AccuracyIID
=0.6
=0.3
(a) AFGA
0 100 200 300 400 500 600
#Rounds101
100Training LossIID
=0.6
=0.3
0 100 200 300 400 500 600
#Rounds0.500.550.600.650.700.750.800.850.90T est AccuracyIID
=0.6
=0.3
 (b) CAFGA
Figure 2: Ablation study with different heterogeneity degree of AFGA and CAFGA in training CIFAR-10
on ConvMixer-256-8 model.
heterogeneity as theoretically the proposed (C)AFGA show that the convergence rate is highly related to the
model dissimilarity. We use Dirichlet( α) distribution for data partitioned in experiments, where αrepresents
the degree of heterogeneity (smaller αimplies more heterogeneous data distribution), and we choose αfrom
{0.3,0.6}together with the i.i.d. data partitioned setting for ablation study. The rest of the experimental
setup is the same as Setting 2 in Table 1. Figure 2 shows the learning curves for different non-i.i.d.
degrees. We observe that the data heterogeneity across clients still significantly affects the convergence and
generalization performance for our proposed (C)AFGA, as a more balanced data distribution attains faster
convergence and higher accuracy.
6.3 Communication-Adapted AFGA and CAFGA
Table 5 shows the test accuracy and the total global round to reach target test accuracy of communication-
adapted AFGA and communication-adapted CAFGA which we have discussed in the previous Section. We
can observe that both communication-adapted methods achieve similar test accuracy compared with their
original version. This suggests that in practice we can still solve the data heterogeneity issue without
requiring all clients to participate in gossip communications. Due to space limitations, we left additional
results of the CIFAR-100 dataset in Appendix B.
6This means that clients in the cluster are connected with all their neighbors but with random weighted averaging elements.
11Published in Transactions on Machine Learning Research (08/2024)
Table 5: The test accuracy (Acc.) and the total global rounds (R#) to reach 78% test accuracy of different
methodswhentrainingConvMixer-256-8modelonCIFAR-10dataset, where(a)denotesthecommunication-
adaptive version. Setting 1 : 100 clients, 5% participation. Setting 2 : 50 clients, 10% participation.
Setting 3 : 100 clients, 10% participation. Setting 4 : 50 clients, 20% participation. To mitigate the effect
of randomness and fluctuation of the accuracy, we take the average of the last 5 global rounds to represent
final accuracy.
MethodSetting 1 Setting 2
Acc. R# Acc. R#
AFGA 78.80 302 82.61 152
AFGA (a) 76.59 419 81.51 259
MethodSetting 3 Setting 4
Acc. R# Acc. R#
CAFGA 81.56 142 83.15 69
CAFGA (a) 81.15 194 82.99 136
7 Conclusions and Future Works
In this paper, we propose a novel adaptive federated optimization algorithm, AFGA, that addresses data
heterogeneity across clients and mitigates local model inconsistency by introducing gossip communications
and client re-sampling during local training steps. We present a completed theoretical convergence analysis
for the proposed AFGA. We prove that AFGA achieves a faster convergence rate than the previous adaptive
federated optimization method for partial participation scenarios with heterogeneous data under non-convex
stochastic settings. We extend AFGA to a more communication-efficient clustered-clients paradigm, where
clients are divided into disjoint clusters and we only perform local gossip averaging within the clusters.
The extended CAFGA algorithm is aimed at reducing the communication overhead introduced by gossip
communications while maintaining the benefits of client re-sampling and gossip communications under het-
erogeneous data. Experiments on several benchmarks and ablation studies backup our theory.
Despite successfully tackling the data heterogeneity issue among clients by introducing gossip communica-
tions and client re-sampling, our current proposed methods also have certain limitations. First, extending
the theoretical analysis to the communication-adapted versions is challenging and highly non-trivial. More-
over, gossip communications also incur extra challenges if attempting to further apply secure aggregation
schemes to our method. Also if not all clients are trusted and there exist malicious clients, the frequent
gossip communications between clients may increase the risks of model poisoning or privacy attacks. We
leave those new challenges as future works.
Acknowledgments
We thank the anonymous reviewers for their helpful comments. This work is partially supported by the
National Science Foundation under Grant No. 2348541. The views and conclusions contained in this paper
are those of the authors and should not be interpreted as representing any funding agencies.
References
Mehdi Salehi Heydar Abad, Emre Ozfatura, Deniz Gunduz, and Ozgur Ercetin. Hierarchical federated
learning across heterogeneous cellular networks. In ICASSP 2020-2020 IEEE International Conference on
Acoustics, Speech and Signal Processing (ICASSP) , pp. 8866–8870. IEEE, 2020.
Durmus Alp Emre Acar, Yue Zhao, Ramon Matas, Matthew Mattina, Paul Whatmough, and Venkatesh
Saligrama. Federated learning based on dynamic regularization. In International Conference on Learning
Representations , 2021. URL https://openreview.net/forum?id=B7v4QMR6Z9w .
12Published in Transactions on Machine Learning Research (08/2024)
Stephen Boyd, Arpita Ghosh, Balaji Prabhakar, and Devavrat Shah. Randomized gossip algorithms. IEEE
transactions on information theory , 52(6):2508–2530, 2006.
Tom B Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind
Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are few-shot learners.
arXiv preprint arXiv:2005.14165 , 2020.
Sebastian Caldas, Sai Meher Karthik Duddu, Peter Wu, Tian Li, Jakub Konečn` y, H Brendan McMa-
han, Virginia Smith, and Ameet Talwalkar. Leaf: A benchmark for federated settings. arXiv preprint
arXiv:1812.01097 , 2018.
Timothy Castiglia, Anirban Das, and Stacy Patterson. Multi-level local sgd: Distributed sgd for heteroge-
neous hierarchical networks. In International Conference on Learning Representations , 2020.
Jinghui Chen, Dongruo Zhou, Yiqi Tang, Ziyan Yang, Yuan Cao, and Quanquan Gu. Closing the generaliza-
tion gap of adaptive gradient methods in training deep neural networks. In Proceedings of the International
Joint Conference on Artificial Intelligence (IJCAI) , 2020.
Xiangyi Chen, Belhal Karimi, Weijie Zhao, and Ping Li. On the convergence of decentralized adaptive
gradient methods. arXiv preprint arXiv:2109.03194 , 2021a.
Yiming Chen, Kun Yuan, Yingya Zhang, Pan Pan, Yinghui Xu, and Wotao Yin. Accelerating gossip sgd
with periodic global averaging. In International Conference on Machine Learning , pp. 1791–1802. PMLR,
2021b.
Ashok Cutkosky and Francesco Orabona. Momentum-based variance reduction in non-convex sgd. Advances
in neural information processing systems , 32, 2019.
JacobDevlin,Ming-WeiChang,KentonLee,andKristinaToutanova. Bert: Pre-trainingofdeepbidirectional
transformers for language understanding. arXiv preprint arXiv:1810.04805 , 2018.
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Un-
terthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, and Neil
Houlsby. An image is worth 16x16 words: Transformers for image recognition at scale. In International
Conference on Learning Representations , 2021.
Liang Gao, Huazhu Fu, Li Li, Yingwen Chen, Ming Xu, and Cheng-Zhong Xu. Feddc: Federated learning
with non-iid data via local drift decoupling and correction. In Proceedings of the IEEE/CVF Conference
on Computer Vision and Pattern Recognition , pp. 10112–10121, 2022.
Yuanxiong Guo, Ying Sun, Rui Hu, and Yanmin Gong. Hybrid local sgd for federated learning with hetero-
geneous communications. In International Conference on Learning Representations , 2021.
Jiayin Jin, Jiaxiang Ren, Yang Zhou, Lingjuan Lyu, Ji Liu, and Dejing Dou. Accelerated federated learning
withdecoupledadaptiveoptimization. In International Conference on Machine Learning , pp.10298–10322.
PMLR, 2022.
Sai Praneeth Karimireddy, Martin Jaggi, Satyen Kale, Mehryar Mohri, Sashank J Reddi, Sebastian U Stich,
and Ananda Theertha Suresh. Mime: Mimicking centralized stochastic algorithms in federated learning.
arXiv preprint arXiv:2008.03606 , 2020a.
Sai Praneeth Karimireddy, Satyen Kale, Mehryar Mohri, Sashank Reddi, Sebastian Stich, and
Ananda Theertha Suresh. Scaffold: Stochastic controlled averaging for federated learning. In International
Conference on Machine Learning , pp. 5132–5143. PMLR, 2020b.
Prashant Khanduri, Pranay Sharma, Haibo Yang, Mingyi Hong, Jia Liu, Ketan Rajawat, and Pramod
Varshney. Stem: A stochastic two-sided momentum algorithm achieving near-optimal sample and com-
munication complexities for federated learning. Advances in Neural Information Processing Systems , 34:
6050–6061, 2021.
13Published in Transactions on Machine Learning Research (08/2024)
Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint
arXiv:1412.6980 , 2014.
Anastasia Koloskova, Nicolas Loizou, Sadra Boreiri, Martin Jaggi, and Sebastian Stich. A unified theory
of decentralized sgd with changing topology and local updates. In International Conference on Machine
Learning , pp. 5381–5393. PMLR, 2020.
Jakub Konečn` y, H Brendan McMahan, Felix X Yu, Peter Richtárik, Ananda Theertha Suresh, and
Dave Bacon. Federated learning: Strategies for improving communication efficiency. arXiv preprint
arXiv:1610.05492 , 2016.
Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images. 2009.
Tian Li, Anit Kumar Sahu, Ameet Talwalkar, and Virginia Smith. Federated learning: Challenges, methods,
and future directions. IEEE Signal Processing Magazine , 37(3):50–60, 2020a.
Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and Virginia Smith. Federated
optimization in heterogeneous networks. Proceedings of Machine Learning and Systems , 2:429–450, 2020b.
Xiang Li, Kaixuan Huang, Wenhao Yang, Shusen Wang, and Zhihua Zhang. On the convergence of fedavg
on non-iid data. arXiv preprint arXiv:1907.02189 , 2019a.
Xiang Li, Wenhao Yang, Shusen Wang, and Zhihua Zhang. Communication-efficient local decentralized sgd
methods. arXiv preprint arXiv:1910.09126 , 2019b.
Xiangru Lian, Ce Zhang, Huan Zhang, Cho-Jui Hsieh, Wei Zhang, and Ji Liu. Can decentralized algorithms
outperform centralized algorithms? a case study for decentralized parallel stochastic gradient descent.
Advances in Neural Information Processing Systems , 30, 2017.
Lumin Liu, Jun Zhang, SH Song, and Khaled B Letaief. Client-edge-cloud hierarchical federated learning.
InICC 2020-2020 IEEE International Conference on Communications (ICC) , pp. 1–6. IEEE, 2020.
Guodong Long, Ming Xie, Tao Shen, Tianyi Zhou, Xianzhi Wang, and Jing Jiang. Multi-center federated
learning: clients clustering for better personalization. World Wide Web , pp. 1–20, 2022.
Yucheng Lu and Christopher De Sa. Optimal complexity in decentralized training. In International Confer-
ence on Machine Learning , pp. 7111–7123. PMLR, 2021.
Grigory Malinovsky, Kai Yi, and Peter Richtárik. Variance reduced proxskip: Algorithm, theory and appli-
cation to federated learning. arXiv preprint arXiv:2207.04338 , 2022.
Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas.
Communication-efficient learning of deep networks from decentralized data. In Artificial intelligence and
statistics , pp. 1273–1282. PMLR, 2017.
Parvin Nazari, Davoud Ataee Tarzanagh, and George Michailidis. Dadam: A consensus-based distributed
adaptive gradient method for online optimization. arXiv preprint arXiv:1901.09109 , 2019.
Sashank Reddi, Zachary Charles, Manzil Zaheer, Zachary Garrett, Keith Rush, Jakub Konečn` y, Sanjiv
Kumar, and H Brendan McMahan. Adaptive federated optimization. arXiv preprint arXiv:2003.00295 ,
2020.
SashankJ.Reddi, SatyenKale, andSanjivKumar. Ontheconvergenceofadamandbeyond. In International
Conference on Learning Representations , 2018.
Sebastian U Stich. Local sgd converges fast and communicates little. arXiv preprint arXiv:1805.09767 , 2018.
Hanlin Tang, Xiangru Lian, Ming Yan, Ce Zhang, and Ji Liu. d2: Decentralized training over decentralized
data. In International Conference on Machine Learning , pp. 4848–4856. PMLR, 2018.
14Published in Transactions on Machine Learning Research (08/2024)
Yunfei Teng, Wenbo Gao, Francois Chalus, Anna E Choromanska, Donald Goldfarb, and Adrian Weller.
Leader stochastic gradient descent for distributed training of deep learning models. Advances in Neural
Information Processing Systems , 32, 2019.
Qianqian Tong, Guannan Liang, and Jinbo Bi. Effective federated adaptive gradient methods with non-iid
decentralized data. arXiv preprint arXiv:2009.06557 , 2020.
Asher Trockman and J Zico Kolter. Patches are all you need? arXiv preprint arXiv:2201.09792 , 2022.
John Nikolas Tsitsiklis. Problems in decentralized decision making and computation. Technical report,
Massachusetts Inst of Tech Cambridge Lab for Information and Decision Systems, 1984.
Hongyi Wang, Mikhail Yurochkin, Yuekai Sun, Dimitris Papailiopoulos, and Yasaman Khazaeni. Federated
learning with matched averaging. In International Conference on Learning Representations , 2020a. URL
https://openreview.net/forum?id=BkluqlSFDS .
Jianyu Wang and Gauri Joshi. Cooperative sgd: A unified framework for the design and analysis of local-
update sgd algorithms. Journal of Machine Learning Research , 22(213):1–50, 2021. URL http://jmlr.
org/papers/v22/20-147.html .
JianyuWang,QinghuaLiu,HaoLiang,GauriJoshi,andHVincentPoor. Tacklingtheobjectiveinconsistency
problem in heterogeneous federated optimization. arXiv preprint arXiv:2007.07481 , 2020b.
YujiaWang,LuLin,andJinghuiChen. Communication-compressedadaptivegradientmethodfordistributed
nonconvex optimization. In International Conference on Artificial Intelligence and Statistics , pp. 6292–
6320. PMLR, 2022a.
Yujia Wang, Lu Lin, and Jinghui Chen. Communication-efficient adaptive federated learning. In Proceedings
of the 39th International Conference on Machine Learning , pp. 22802–22838. PMLR, 2022b.
Yujia Wang, Yuanpu Cao, Jingcheng Wu, Ruoyu Chen, and Jinghui Chen. Tackling the data heterogeneity in
asynchronous federated learning with cached update calibration. In The Twelfth International Conference
on Learning Representations , 2024a. URL https://openreview.net/forum?id=4aywmeb97I .
Yujia Wang, Shiqiang Wang, Songtao Lu, and Jinghui Chen. Fadas: Towards federated adaptive asyn-
chronous optimization. arXiv preprint arXiv:2407.18365 , 2024b.
Xidong Wu, Feihu Huang, Zhengmian Hu, and Heng Huang. Faster adaptive federated learning. arXiv
preprint arXiv:2212.00974 , 2022.
Haibo Yang, Minghong Fang, and Jia Liu. Achieving linear speedup with partial worker participation in
non-iid federated learning. arXiv preprint arXiv:2101.11203 , 2021.
JinliangYuan, Mengwei Xu, XiaoMa, AoZhou, Xuanzhe Liu, andShangguang Wang. Hierarchicalfederated
learning through lan-wan orchestration. arXiv preprint arXiv:2010.11612 , 2020.
Dongruo Zhou, Jinghui Chen, Yuan Cao, Yiqi Tang, Ziyan Yang, and Quanquan Gu. On the convergence
of adaptive gradient methods for nonconvex optimization. arXiv preprint arXiv:1808.05671 , 2018.
A Related Work
Federated learning. Federatedlearning(Konečn` yetal.,2016)playacriticalroleincollaborativelytraining
models at edge devices with potential privacy protections. Basic optimization methods for federated learning
include SGD-based global optimizer, e.g., FedAvg (McMahan et al., 2017) (a.k.a. Local SGD (Stich, 2018)
and its variants (Li et al., 2019a; Yang et al., 2021), adaptive gradient optimization based global optimizer
such as FedAdam, FedAdagrad, FedYogi (Reddi et al., 2020), FedAGM (Tong et al., 2020) and FedAMS-
Grad (Wang et al., 2022b). While these optimization methods for federated learning show their ability on
achieving stable results when data are heterogeneously distributed, they rarely study data heterogeneity
15Published in Transactions on Machine Learning Research (08/2024)
itself. Recently, several works address the data heterogeneity issue through several aspects. For example,
FedProx (Li et al., 2020a) adds a proximate term to align the local model with the global one, and FedDyn
(Acar et al., 2021) involves dynamic regularization term for local and global model consistency. FedNova
(Wang et al., 2020b) proposes a normalized averaging mechanism that reduces objective inconsistency with
heterogeneous data. Moreover, several works study to eliminate the client drift caused by data heterogeneity
from the aspect of variance reduction such as (Karimireddy et al., 2020b;a; Khanduri et al., 2021; Cutkosky
& Orabona, 2019). They introduce additional control variables to track and correct the local model shift
during local training, but they require extra communication costs for synchronizing these control variables.
Besides, FedDC (Gao et al., 2022) involves both dynamic regularization terms and local drift variables for
model correction.
Decentralized learning and beyond. Decentralized learning studies a distributed machine learning
paradigm without a central server. It can been tracked back from gossip averaging techniques (Tsitsiklis,
1984; Boyd et al., 2006). Decentralized (gossip) SGD algorithms (Lian et al., 2017; Li et al., 2019b; Boyd
et al., 2006; Tang et al., 2018) are then proposed that consider client-to-client communications after each step
of SGD update on the client for decentralized learning. Lu & De Sa (2021) proves a tight lower bound for
decentralized training under the non-convex setting. Teng et al. (2019) proposes a leader-distributed SGD
algorithm that pulls workers to the currently best-performing model among all models. There are recent
studies generalized various distributed SGD algorithms under unified frameworks, where Wang & Joshi
(2021) included reducing communication costs and decentralized training in i.i.d. settings, and Koloskova
et al. (2020) studied a general network topology-changing gossip SGD methods that summarize several
algorithms in distributed and federated learning.
Recent studies extend the decentralized training paradigm to federated learning with various adaption. For
example, Guo et al. (2021) considered heterogeneous communications for modern communication networks
that improve communication efficiency, and hierarchical federated learning algorithms (Liu et al., 2020; Abad
etal.,2020;Castigliaetal.,2020)developframeworksbyaggregatingclientmodelstoedgeserversfirstbefore
synchronizing them to the central server.
B Additional Experiments
In this section, we present additional empirical results for our proposed algorithm AFGA and CAFGA in
training ConvMixer-256-8 model (Trockman & Kolter, 2022) on CIFAR-10/100 (Krizhevsky et al., 2009)
datasets, and in training LSTM model on Shakespeare (Caldas et al., 2018) dataset. All experiments in this
paper are conducted on 4 NVIDIA RTX A6000 GPUs.
B.1 Additional Experimental Results
Additional Experimental Results on CIFAR-10. Figure 3 shows the overall test accuracy curves
of experiments on CIFAR-10. It demonstrates that our proposed AFGA and CAFGA achieve overall bet-
ter performance than adaptive federated learning methods and other federated learning baselines in both
settings.
Additional Experimental Results on training ResNet-18 on CIFAR-10. Table 6 presents the
empirical result for our proposed AFGA and CAFGA together with several federated learning baselines on
training CIFAR-10 with ResNet-18 model. It shows that the proposed CAFGA outperforms other federated
learning baselines, achieving a 0.4% improvement over FedAMSGrad and an enhancement of more than 1%
compared to other baselines.
Additional Experimental Results on CIFAR-100. Figure4showstheempiricalresultforourproposed
AFGA and CAFGA together with several federated learning baselines on training CIFAR-100 ConvMixer-
256-8 model. They demonstrate that our proposed AFGA and CAFGA achieve overall better performance
than adaptive federated learning methods and other federated learning baselines in both settings.
16Published in Transactions on Machine Learning Research (08/2024)
0 100 200 300 400 500
#Rounds0.500.550.600.650.700.750.80T est AccuracyFedAvg
FedAdam
FedAMSGrad
Scaffold
FedProx
FedDyn
AFGA
CAFGA
(a) CIFAR-10 100 clients 5%
0 100 200 300 400 500
#Rounds0.600.650.700.750.800.85T est AccuracyFedAvg
FedAdam
FedAMSGrad
Scaffold
FedProx
FedDyn
AFGA
CAFGA (b) CIFAR-10 50 clients 10%
Figure 3: The test accuracy for AFGA and CAFGA with several federated learning baselines in training
CIFAR-10 data on ConvMixer-256-8 model.
Table 6: The test accuracy of training ResNet-18 model on CIFAR-10 datasets considering 50 clients and
10% participation ratio.
Method Acc. & std.
FedAvg 70.32±0.44
FedAdam 73.80±0.58
FedAMSGrad 75.59±0.73
SCAFFOLD 74.60±0.67
FedProx 70.26±0.45
FedDyn 74.15±2.23
AFGA 74.72±0.32
CAFGA 75.96±0.67
B.1.1 Ablation Studies and Other Comparisons
Ablation of local iteration. We further study how the local iteration affects the convergence of our pro-
posed CAFGA algorithm. Figure 6 shows the ablation study about local iterations, we compare the number
of local iterations IfromI={12,24,48}. We observe that larger Iindeed helps accelerate convergence on
training loss and helps to obtain a higher test accuracy. This result backs up our theory that the increasing
number of local steps would help the overall performance.
Communication run-time simulations. Table 7 presents a simulation study as a substitution of the real-
worldmeasurementsimilartoGuoetal.(2021). Consideralimitedbandwidthsettingwheretheaveragetime
of client-to-client communication cost is 1.8 seconds, and the average time of client-to-server communication
cost is 18 seconds. Table 7 suggests that even when considering client-to-client communication costs, our
proposed AFGA and CAFGA can still efficiently achieve high accuracy with less overall communication
costs. This implies that though our proposed methods incur extra local gossip communications, it helps
mitigate the impact of data heterogeneity thus improve the overall performance.
Table 7: The communication time under for CIFAR-10. Setting 1: 100 clients, 5% participation ratio.
Test Accuracy 70% 75% 78% 80%
FedAMSGrad time (h) 76.0 128.0 194.0 281.0
AFGA time (h) 91.76 130.98 223.48 250.86
CAFGA time (h) 76.22 102.86 172.42 179.82
Comparisons to Decentralized Methods. We have briefly discussed decentralized learning in the
related work in the main paper, here we provide more discussion about our proposed methods and the
decentralized algorithms. Decentralized learning can certainly prevent single point failure without a central
17Published in Transactions on Machine Learning Research (08/2024)
0 100 200 300 400 500 600
#Rounds0.300.350.400.450.500.55T est AccuracyFedAvg
FedAdam
FedAMSGrad
Scaffold
FedProx
FedDyn
AFGA
CAFGA
(a) CIFAR-100 100 clients 5%
0 100 200 300 400 500 600
#Rounds0.300.350.400.450.500.55T est AccuracyFedAvg
FedAdam
FedAMSGrad
Scaffold
FedProx
FedDyn
AFGA
CAFGA (b) CIFAR-100 50 clients 10%
Figure 4: The test accuracy for AFGA and CAFGA with several federated learning baselines in training
CIFAR-100 data on ConvMixer-256-8 model.
0 100 200 300 400 500
#Rounds0.300.350.400.450.500.55T est AccuracyFedAvg
FedAdam
FedAMSGrad
Scaffold
FedProx
FedDyn
AFGA
CAFGA
(a) Shakespeare 100 clients 5%
0 100 200 300 400 500
#Rounds0.300.350.400.450.500.55T est AccuracyFedAvg
FedAdam
FedAMSGrad
Scaffold
FedProx
FedDyn
AFGA
CAFGA (b) Shakespeare 50 clients 10%
Figure 5: The test accuracy for AFGA and CAFGA with several federated learning baselines in training
Shakespeare data on LSTM model.
server, its performance is not on par with the conventional server-client FL setup, especially when data are
heterogeneous distributed. In sharp contrast, the periodic synchronization between server and clients in our
proposed method can help align local models for better convergence and ease the data heterogeneity issue
in adaptive federated learning, which is mainly focus of this paper. Moreover, the central server setting
allow us to easily apply adaptive optimizer for stable performances, while decentralized learning methods
are mostly limited to SGD-based update as the adaptive optimizer needs the alignment of gradient update,
otherwise suffers from some divergence issue (Chen et al., 2021a).
We provide some experimental results comparing our proposed methods with decentralized algorithms in-
cluding DSGD (Lian et al., 2017), DAdam (Nazari et al., 2019; Chen et al., 2021a) and PGA (Chen et al.,
2021b) under the same training settings. The following table shows the comparison result for several decen-
tralized methods and our proposed AFGA and CAFGA. It shows that our proposed AFGA and CAFGA
indeed attains better test accuracy results comparing to other decentralized baselines.
Table 8: Comparison to decentralized algorithms.
Method Test Accuracy(%) Rounds (78%)
DSGD 80.23 50
DAdam 70.37 227
PGA 80.93 210
AFGA 82.16 152
CAFGA 83.03 112
18Published in Transactions on Machine Learning Research (08/2024)
0 100 200 300 400 500
#Rounds101
100Training Loss=12
=24
=48
0 100 200 300 400 500
#Rounds0.500.550.600.650.700.750.800.85T est Accuracy
=12
=24
=48
Figure6: AblationstudywithdifferentheterogeneitydegreeofCAFGAintrainingCIFAR-10onConvMixer-
256-8 model.
B.2 Hyper-parameters Details
Hyper-parameter Settings. We conduct detailed hyper-parameter searches to find the best hyper-
parameter for each baseline. We grid over the local learning rate ηl∈{0.001,0.01,0.1,1.0}, and the global
learning rate η∈{0.001,0.01,0.1,1.0,2.0,5.0,10.0}for each method. For the global AMSGrad optimizer,
we setβ1= 0.9,β1= 0.99, and we search the best ϵfrom{10−10,10−8,10−6,10−4}. Table 9 summarizes
the hyper-parameter details in our experiments.
Experiments are set up with Setting 1: 100 total clients, and Setting 2 : 50 total clients in the network.
For CAFGA, clients are equally divided into 5clusters. The partial participation ratio is set to p= 0.05for
Setting 1 andp= 0.1forSetting 2 , and the gossip communication topology is ring topology by default.
For each method, we conduct I= 24iterations of local training with a batch size of 50by default.
Table 9: Hyper-parameters details.
Setting 1 (100 clients 5% participation)
FedAvg FedAdam FedAMSGrad SCAFFOLD FedProx FedDyn AFGA CAFGA
Data ηlη η lη η lη η lη η lη η lη η lη η lη
CIFAR-10 0.1 1.0 1.0 0.01 1.0 1.0 0.1 1.0 0.1 1.0 0.1 1.0 0.01 2.0 0.01 2.0
CIFAR-100 0.1 1.0 1.0 0.01 1.0 1.0 0.1 1.0 0.1 1.0 0.1 1.0 0.01 1.0 0.01 1.0
Shakespeare 1.0 1.0 1.0 0.01 1.0 1.0 0.1 1.0 0.1 1.0 0.1 1.0 0.01 10.0 0.01 10.0
Setting 2 (50 clients 10% participation)
FedAvg FedAdam FedAMSGrad SCAFFOLD FedProx FedDyn AFGA CAFGA
Data&Model ηlη η lη η lη η lη η lη η lη η lη η lη
CIFAR-10 0.1 1.0 1.0 0.01 1.0 1.0 0.1 1.0 0.1 1.0 0.1 1.0 0.01 2.0 0.01 2.0
CIFAR-100 0.1 1.0 1.0 0.01 1.0 1.0 0.1 1.0 0.1 1.0 0.1 1.0 0.01 1.0 0.01 1.0
Shakespeare 1.0 1.0 1.0 0.01 1.0 1.0 0.1 1.0 0.1 1.0 0.1 1.0 0.01 10.0 0.01 10.0
C Preliminaries
About weighted matrix:
null(In−Wk) =span(x|x∈Rn: (In−Wk)x=0) (4)
If we have null (In−Wk) =span(1), that means the following equation holds

1−w11−w12...−w1n
−w21 1−w22...−w2n
...
−wn1... ... 1−wnn
·
x1
x2
...
xn
=0 (5)
19Published in Transactions on Machine Learning Research (08/2024)
if and only if x1=x2=...=xn. Since we assume wij∈[0,1], there is a counter-example if Wk=
(W2,0; 0,In−2), then we have

1−w11−w12... 0
−w21 1−w22... 0
...
0 In−2
·
x1
x2
...
xn
=0, (6)
then (x1,x2,...,xn) = (c1,c2,0,...,0)(c1,c2̸= 0)can be a solution to the equation.
For the eigenvalues and eigenvectors of matrix Wk−(1/n)11T, we have
Wk−(1/n)11T=Wk−J,
(Wk−J)(Wk−J) =Wk−J,
λb= (Wk−J)b= (Wk−J)(Wk−J)b= (Wk−J)λb=λ2b,
(λ2−λ)b= 0, λ = 1orλ= 0. (7)
The eigenvectors of Wk−Jare(1,−1,0,...,0),(1,0,−1,...,0),...,(1,1,1,...,1).
The maximum of ∥Wk−(1/n)11T∥2is obtained when Wkis equivalent to In, and we have max∥Wk−
(1/n)11T∥2= 1, which implies∥Wk−(1/n)11T∥2≤1.
D Convergence Analysis for Clustered-clients framework
We re-state two cluster related assumptions, the assumption of inter-client dissimilarity and the assumption
of gossip mixing spectral gap, and the theorem in the following. First, we denote the local objective function
of clusterk, i.e., ¯fk(x) =1
n/summationtext
i∈Vkfi(x), then we state the following assumptions.
Assumption D.1. The dissimilarity between client’s objective function and corresponding cluster’s objec-
tive function is bounded, i.e., for all x,k∈[K], there is1
n/summationtext
i∈Vk∥∇fi(x)−∇ ¯fk(x)∥2≤σ2
k. Similarly,
clusters’ objective function the global objective has a bounded dissimilarity variance: for α≥1andσc≥0,
there is1
K/summationtext
k∈[K]∥∇¯fk(x)∥2≤α2∥∇f(x)∥2+σ2
c.
Assumption D.2 (Intra-cluster spectral gap) .Local clients in cluster k∈[K]are connected in the graph
Gkwith weighting matrix Wksatisfies same characteristic as Assumption 4.5. We assume the spectral gap
ρksatisfies: there exists ρk∈[0,1)such that∥Wk−1
n11⊤∥2≤ρk.
We further denote ¯σ2
l=1
K/summationtextK
k=1σ2
kas the average dissimilarity between local clients in the same cluster,
and denote ρmax= maxk∈[K]ρkas the maximum spectral gap among all Kclusters.
Note that Assumption D.1 and Assumption D.2 are general assumptions for the clustered-client AFGA
(CAFGA) framework. Specifically, if K= 1, i.e., there is only one cluster containing all clients [N]in the
network:
•Assumption D.1 reduces to Assumption 4.4: the cluster’s objective function in Assumption D.1 is ex-
actly the global objective, thus σc= 0, and there is a bounded dissimilarity between client’s objective
and global objective:1
n/summationtext
i∈[N]∥∇fi(x)−∇f(x)∥2≤σ2
g, which is consistent with Assumption 4.4.
•Assumption D.2 reduces to Assumption 4.5: the only cluster contains all i∈[N], clientsi∈
[N]are connected in the graph Gwith weighting matrix Wand there exists ρ∈[0,1)such that
∥W−1
n11⊤∥2≤ρ, which is consistent with Assumption 4.5.
In the following, we state the convergence rate for Algorithm 2, (CAFGA).
Theorem D.3. Under Assumptions 4.1-4.3, D.1 and D.2, if the local learning rate satisfies specific con-
straints, and the maximum spectral gap satisfies ρmax≤m
m+n, then the iterates of Algorithm 2 in partial
participation scenarios satisfy
20Published in Transactions on Machine Learning Research (08/2024)
1
RR/summationdisplay
r=1E[∥∇f(xr)∥2] =O/parenleftbigg1√
RIm/bracketleftbigg
[f0−f∗] +/parenleftbigg
/tildewideσ2+σ2
K/parenrightbigg
L/bracketrightbigg/parenrightbigg
+O/parenleftbigg1
R/bracketleftbigg
G2+L2[σ2
c+ (1 +ρ2
max)¯σ2
l] +ρ2
maxσ2
I/bracketrightbigg/parenrightbigg
+/tildewideO/parenleftbigg1
R3/2/parenrightbigg
, (8)
where/tildewideO(·)hides all the absolute constants and problem dependent constants including ρ,σ,σ2
c,¯σ2
l,I,M,N,
and additionally we denote /tildewideσ2=σ2+ ¯σ2
l+σ2
cas the variance summation.
E Proof of Theorem D.3 and Theorem 4.6
Preliminaries for the proof. We define the following auxiliary sequences, w.r.t. xr,t,xk
r,t. Firstly, we
denote the average model on cluster kas
¯xk
r,t+1=¯xk
r,t−ηl¯gk
r,t, (9)
where ¯gk
r,t=1
n/summationtext
i∈Vk¯gi
r,t, where ¯gi
r,t= 0as avirtual gradient if clientiinVkhas not been selected in
the setSk
t,r, and ¯gi
r,tis equal to the real gradient gi
r,t. ifi∈Sk
t,rWe also define the global average model
¯xr,t+1=¯xr,t−ηl1
NN/summationdisplay
i=1¯gi
r,t. (10)
We next define sequences related to model differences, we denote the average model difference on cluster k
as¯∆k
r, and the average global model difference ¯∆rwithout sampling consideration.
¯∆k
r=1
n/summationdisplay
i∈Vk∆i
r=1
n/summationdisplay
i∈Vk(xi
r,I−xr) =¯xk
r,I−xr=¯xk
r,0−ηlI−1/summationdisplay
t=0¯gk
r,t−xr=−ηlI−1/summationdisplay
t=0¯gk
r,t,
¯∆r=1
K/summationdisplay
k∈[K]1
n/summationdisplay
i∈Vk(xi
r,I−xr) =1
K/summationdisplay
k∈[K]¯∆k
r=−ηl1
K1
nI−1/summationdisplay
t=0/summationdisplay
k∈[K]/summationdisplay
i∈Vk¯gi
r,t. (11)
Since we have two sampling process: sampling clients for global communication per global round r, and
sampling selected clients for local gradient update per local iteration t. Thus we state the following auxiliary
equations
ESk
t,r[¯gk
t,r] =ESk
t,r/bracketleftbigg1
n/summationdisplay
i∈Vk¯gi
t,r/bracketrightbigg
=ESk
t,r/bracketleftbigg1
n/summationdisplay
i∈Sk
t,rgi
t,r/bracketrightbigg
,
ESk
t,r[¯∆k
r] =ESk
t,r/bracketleftbigg
−ηlI−1/summationdisplay
t=0¯gk
t,r/bracketrightbigg
=ESk
t,r/bracketleftbigg
−ηl
nI−1/summationdisplay
t=0/summationdisplay
i∈Sk
t,rgi
t,r/bracketrightbigg
,
ESr[¯∆r] =ESr/bracketleftbigg1
KK/summationdisplay
k=1¯∆k
r/bracketrightbigg
=1
KK/summationdisplay
k=1ESkr/bracketleftbigg
ESk
t,r/bracketleftbigg
−ηl
nI−1/summationdisplay
t=0/summationdisplay
i∈Sk
t,rgi
t,r/bracketrightbigg/bracketrightbigg
=1
KK/summationdisplay
k=1ESkr/bracketleftbigg
−1
m/summationdisplay
i∈Skrηl
nI−1/summationdisplay
t=0ESk
t,r/bracketleftbigg/summationdisplay
i∈Sk
t,rgi
t,r/bracketrightbigg/bracketrightbigg
=ESr[∆r]. (12)
Thus ¯∆ris the unbiased estimate of ∆r.
Proof of Theorem D.3. Similar to previous works (Zhou et al., 2018; Chen et al., 2020), we introduce a
Lyapunov sequence zr: assume x0=x1, for eachr≥1, we have
zr=xr+β1
1−β1(xr−xr−1) =1
1−β1xr−β1
1−β1xr−1. (13)
21Published in Transactions on Machine Learning Research (08/2024)
For the difference of two adjacent element in sequence zr, we have
zr+1−zr=1
β1(xr+1−xr)−β1
1−β1(xr−xr−1)
=1
1−β1(η/hatwideV−1/2
rmr)−β1
1−β1η/hatwideV−1/2
r−1mr−1
=1
1−β1η/hatwideV−1/2
r/bracketleftbigg
β1mr−1+ (1−β1)∆r/bracketrightbigg
−β1
1−β1η/hatwideV−1/2
r−1mr−1
=η/hatwideV−1/2
r ∆r−ηβ1
1−β1/parenleftbigg
/hatwideV−1/2
r−1−/hatwideV−1/2
r/parenrightbigg
mr−1.
By Assumption 4.1, with the property of L-smoothness, for r∈[R], taking conditional expectation at global
roundr, we have
E[f(zr+1)]−f(zr)≤E[⟨∇f(zr),zr+1−zr⟩] +L
2E[∥zr+1−zr∥2]
≤ηE/bracketleftbigg/angbracketleftig
∇f(zr),/hatwideV−1/2
r ∆r/angbracketrightig/bracketrightbigg
−ηE/bracketleftbigg/angbracketleftbigg
∇f(zr),β1
1−β1/parenleftig
/hatwideV−1/2
r−1−/hatwideV−1/2
r/parenrightig
mr−1/angbracketrightbigg/bracketrightbigg
+η2L
2E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble/hatwideV−1/2
r ∆r−β1
1−β1/parenleftig
/hatwideV−1/2
r−1−/hatwideV−1/2
r/parenrightig
mr−1/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
=ηE/bracketleftbigg/angbracketleftig
∇f(xr),/hatwideV−1/2
r ∆r/angbracketrightig/bracketrightbigg
/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
I−ηE/bracketleftbigg/angbracketleftbigg
∇f(zr),β1
1−β1/parenleftig
/hatwideV−1/2
r−1−/hatwideV−1/2
r/parenrightig
mr−1/angbracketrightbigg/bracketrightbigg
/bracehtipupleft /bracehtipdownright/bracehtipdownleft /bracehtipupright
II
+η2L
2E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble/hatwideV−1/2
r ∆r−β1
1−β1/parenleftig
/hatwideV−1/2
r−1−/hatwideV−1/2
r/parenrightig
mr−1/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
/bracehtipupleft /bracehtipdownright/bracehtipdownleft /bracehtipupright
III
+ηE/bracketleftbigg/angbracketleftig
∇f(zr)−∇f(xr),/hatwideV−1/2
r ∆r/angbracketrightig/bracketrightbigg
/bracehtipupleft /bracehtipdownright/bracehtipdownleft /bracehtipupright
IV, (14)
E.1 Bounding I
We have
I=ηE/bracketleftbigg/angbracketleftbigg
∇f(xr),∆r√/hatwidevr+ϵ/angbracketrightbigg/bracketrightbigg
=ηE/bracketleftbigg/angbracketleftbigg∇f(xr)√/hatwidevr+ϵ,¯∆r/angbracketrightbigg/bracketrightbigg
=−ηηlE/bracketleftbigg/angbracketleftbigg∇f(xr)√/hatwidevr+ϵ,1
KnI−1/summationdisplay
t=0/summationdisplay
k∈[K]/summationdisplay
i∈Vk¯gi
r,t/angbracketrightbigg/bracketrightbigg
=−ηηlE/bracketleftbigg/angbracketleftbigg∇f(xr)√/hatwidevr+ϵ,1
KnI−1/summationdisplay
t=0/summationdisplay
k∈[K]/summationdisplay
i∈Sk
r,tgi
r,t/angbracketrightbigg/bracketrightbigg
=−ηηlm
nI−1/summationdisplay
t=0E/bracketleftbigg/angbracketleftbigg∇f(xr)√/hatwidevr+ϵ,1
NN/summationdisplay
i=1gi
r,t/angbracketrightbigg/bracketrightbigg
=−ηηlm
nI−1/summationdisplay
t=0E/bracketleftbigg/angbracketleftbigg∇f(xr)√/hatwidevr+ϵ,1
NN/summationdisplay
i=1∇fi(xi
r,t)/angbracketrightbigg/bracketrightbigg
, (15)
22Published in Transactions on Machine Learning Research (08/2024)
where the first equation in equation 15 holds by ∆r=m
n¯∆r=−m
n·ηl
N/summationtextN
i=1/summationtextI−1
t=0gi
r,t. The last equation
above holds by the unbiasedness of stochastic gradient, then we have
−E/bracketleftbigg/angbracketleftbigg∇f(xr)√/hatwidevr+ϵ,1
NN/summationdisplay
i=1∇fi(xi
r,t)/angbracketrightbigg/bracketrightbigg
=−1
2E/bracketleftbigg/angbracketleftbigg∇f(xr)√/hatwidevr+ϵ,1
NN/summationdisplay
i=1∇fi(xi
r,t)/angbracketrightbigg/bracketrightbigg
−1
2E/bracketleftbigg/angbracketleftbigg∇f(xr)√/hatwidevr+ϵ,1
NN/summationdisplay
i=1∇fi(xi
r,t)±1
KK/summationdisplay
k=1∇¯fk(¯xk
r,t)/angbracketrightbigg/bracketrightbigg
=−1
2E/bracketleftbigg/angbracketleftbigg∇f(xr)
4√/hatwidevr+ϵ,1
4√/hatwidevr+ϵ1
NN/summationdisplay
i=1∇fi(xi
r,t)/angbracketrightbigg/bracketrightbigg
−1
2E/bracketleftbigg/angbracketleftbigg∇f(xr)
4√/hatwidevr+ϵ,1
4√/hatwidevr+ϵ/parenleftbigg1
NN/summationdisplay
i=1∇fi(xi
r,t)±1
KK/summationdisplay
k=1∇¯fk(¯xk
r,t)/parenrightbigg/angbracketrightbigg/bracketrightbigg
. (16)
Since we have inequalities, ⟨a,b⟩=∥a∥2+∥b∥2−∥a−b∥2and⟨a,b⟩≤1
2∥a∥2+1
2∥b∥2, then we have
−E/bracketleftbigg/angbracketleftbigg∇f(xr)√/hatwidevr+ϵ,1
NN/summationdisplay
i=1∇fi(xi
r,t)/angbracketrightbigg/bracketrightbigg
≤−1
4E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble∇f(xr)
4√/hatwidevr+ϵ/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
+/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
4√/hatwidevr+ϵ1
NN/summationdisplay
i=1∇fi(xi
r,t)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
−/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
4√/hatwidevr+ϵ/parenleftbigg
∇f(xr)−1
NN/summationdisplay
i=1∇fi(xi
r,t)/parenrightbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
−1
4E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble∇f(xr)
4√/hatwidevr+ϵ/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
+/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
4√/hatwidevr+ϵ1
KK/summationdisplay
k=1∇¯fk(¯xk
r,t)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
−/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
4√/hatwidevr+ϵ/parenleftbigg
∇f(xr)−1
KK/summationdisplay
k=1∇¯fk(¯xk
r,t)/parenrightbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
+1
4E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble∇f(xr)
4√/hatwidevr+ϵ/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
+1
4E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
4√/hatwidevr+ϵ/parenleftbigg1
NN/summationdisplay
i=1∇fi(xi
r,t)−1
KK/summationdisplay
k=1∇¯fk(¯xk
r,t)/parenrightbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
≤−1
4C0E[∥∇f(xr)∥2]−1
4C0E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
NN/summationdisplay
i=1∇fi(xi
r,t)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
−1
4C0E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
KK/summationdisplay
k=1∇¯fk(¯xk
r,t)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
+1
4√ϵE/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble∇f(xr)−1
NN/summationdisplay
i=1∇fi(xi
r,t)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
+1
4√ϵE/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble∇f(xr)−1
KK/summationdisplay
k=1∇¯fk(¯xk
r,t)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
+1
4√ϵE/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
NN/summationdisplay
i=1∇fi(xi
r,t)−1
KK/summationdisplay
k=1∇¯fk(¯xk
r,t)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
, (17)
where the second inequality holds by the property of variance /hatwidevr:∥x∥2C−1
0≤∥x∥2(/hatwidevr+ϵ)−1/2≤∥x∥2ϵ1/2
withC0=/radicalbig
η2
lI2G2+ϵ. After applying the property of L-smoothness, the last three terms above are highly
related to bound the inter-cluster consensus error ∥xr−¯xk
r,t∥and intra-cluster consensus error ∥¯xk
r,t−xi
r,t∥.
23Published in Transactions on Machine Learning Research (08/2024)
Thus by Assumption 4.1, we have the following result for bounding I
I=ηE/bracketleftbigg/angbracketleftbigg
∇f(xr),∆r√/hatwidevr+ϵ/angbracketrightbigg/bracketrightbigg
≤ηηl
4C0m
nI−1/summationdisplay
t=0/bracketleftbigg
−E[∥∇f(xr)∥2]−E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
NN/summationdisplay
i=1∇fi(xi
r,t)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
−/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
KK/summationdisplay
k=1∇¯fk(¯xk
r,t)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
+ηηl
4√ϵm
nI−1/summationdisplay
t=0/braceleftbigg
E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble∇f(xr)−1
NN/summationdisplay
i=1∇fi(xi
r,t)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
+E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble∇f(xr)−1
KK/summationdisplay
k=1∇¯fk(¯xk
r,t)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
+E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
NN/summationdisplay
i=1∇fi(xi
r,t)−1
KK/summationdisplay
k=1∇¯fk(¯xk
r,t)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg/bracerightbigg
≤ηηl
4C0m
nI−1/summationdisplay
t=0/bracketleftbigg
−E[∥∇f(xr)∥2]−E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
NN/summationdisplay
i=1∇fi(xi
r,t)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
−/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
KK/summationdisplay
k=1∇¯fk(¯xk
r,t)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
+ηηl
4√ϵm
nI−1/summationdisplay
t=0/braceleftbigg
E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble∇f(xr)±1
KK/summationdisplay
k=1∇¯fk(¯xk
r,t)−1
NN/summationdisplay
i=1∇fi(xi
r,t)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
+E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble∇f(xr)−1
KK/summationdisplay
k=1∇¯fk(¯xk
r,t)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
+E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
NN/summationdisplay
i=1∇fi(xi
r,t)−1
KK/summationdisplay
k=1∇¯fk(¯xk
r,t)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg/bracerightbigg
≤ηηl
4C0m
nI−1/summationdisplay
t=0/bracketleftbigg
−E[∥∇f(xr)∥2]−E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
NN/summationdisplay
i=1∇fi(xi
r,t)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
−/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
KK/summationdisplay
k=1∇¯fk(¯xk
r,t)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
+ηηl
4√ϵm
nI−1/summationdisplay
t=0/braceleftbigg2L2
KK/summationdisplay
k=1E[∥xr−¯xk
r,t∥2] +2L2
NK/summationdisplay
k=1/summationdisplay
i∈VkE[∥¯xk
r,t−xi
r,t∥2]
+L2
KK/summationdisplay
k=1E[∥xr−¯xk
r,t∥2] +L2
NK/summationdisplay
k=1/summationdisplay
i∈VkE[∥¯xk
r,t−xi
r,t∥2]/bracerightbigg
≤ηηl
4C0m
nI−1/summationdisplay
t=0/bracketleftbigg
−E[∥∇f(xr)∥2]−E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
NN/summationdisplay
i=1∇fi(xi
r,t)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
−/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
KK/summationdisplay
k=1∇¯fk(¯xk
r,t)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
+ηηl
4√ϵm
nI−1/summationdisplay
t=0/braceleftbigg3L2
KK/summationdisplay
k=1E[∥xr−¯xk
r,t∥2] +3L2
NK/summationdisplay
k=1/summationdisplay
i∈VkE[∥¯xk
r,t−xi
r,t∥2]/bracerightbigg
≤ηηl
4C0m
nI−1/summationdisplay
t=0/bracketleftbigg
−E[∥∇f(xr)∥2]−E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
NN/summationdisplay
i=1∇fi(xi
r,t)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
−/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
KK/summationdisplay
k=1∇¯fk(¯xk
r,t)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
+ηηl
4√ϵm
n/bracketleftbigg
3L2I2C1η2
l(I+ρ2
maxHI,ρ)(α2E[∥∇f(xr)∥2+σ2
c) + 3L2I2C1ρ2
maxHI,ρη2
l¯σ2
l
+ 3L2I2C1η2
lσ2ρ2
max+ 3L2C1/parenleftbig
I2+H2
I,ρ·ρ2
max/parenrightbig
η2
l/parenleftbiggσ2
n+m(n−m)
n(n−1)I¯σ2
l/parenrightbigg/bracketrightbigg
, (18)
where the last inequality holds by Lemma F.1 and F.2.
24Published in Transactions on Machine Learning Research (08/2024)
E.2 Bounding II
BoundingIImainly follows by the update rule and definition of virtual sequence zr,
II=−ηE/bracketleftbigg/angbracketleftbigg
∇f(zr),β1
1−β1/parenleftbig/hatwideV−1/2
r−1−/hatwideV−1/2
r/parenrightbig
mr−1/angbracketrightbigg/bracketrightbigg
=−ηE/bracketleftbigg/angbracketleftbigg
∇f(zr)−∇f(xr) +∇f(xr),β1
1−β1/parenleftbig/hatwideV−1/2
r−1−/hatwideV−1/2
r/parenrightbig
mr−1/angbracketrightbigg/bracketrightbigg
≤ηE/bracketleftbigg
∥∇f(xr)∥/vextenddouble/vextenddouble/vextenddouble/vextenddoubleβ1
1−β1/parenleftbig/hatwideV−1/2
r−1−/hatwideV−1/2
r/parenrightbig
mr−1/vextenddouble/vextenddouble/vextenddouble/vextenddouble/bracketrightbigg
+ηLE/bracketleftbigg
∥zr−xr∥/vextenddouble/vextenddouble/vextenddouble/vextenddoubleβ1
1−β1/parenleftbig/hatwideV−1/2
r−1−/hatwideV−1/2
r/parenrightbig
mr−1/vextenddouble/vextenddouble/vextenddouble/vextenddouble/bracketrightbigg
=ηE/bracketleftbigg
∥∇f(xr)∥/vextenddouble/vextenddouble/vextenddouble/vextenddoubleβ1
1−β1/parenleftbig/hatwideV−1/2
r−1−/hatwideV−1/2
r/parenrightbig
mr−1/vextenddouble/vextenddouble/vextenddouble/vextenddouble/bracketrightbigg
+η2LE/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble1/radicalbig
/hatwidevr−1+ϵβ1
1−β1mr−1/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddoubleβ1
1−β1/parenleftbig/hatwideV−1/2
r−1−/hatwideV−1/2
r/parenrightbig
mr−1/vextenddouble/vextenddouble/vextenddouble/vextenddouble/bracketrightbigg
≤β1
1−β1m
nηηlIG2E/bracketleftbig/vextenddouble/vextenddouble/hatwideV−1/2
r−1−/hatwideV−1/2
r/vextenddouble/vextenddouble
1/bracketrightbig
+β2
1
(1−β1)2m2
n2Lη2η2
lI2G2ϵ−1/2E/bracketleftbig/vextenddouble/vextenddouble/hatwideV−1/2
r−1−/hatwideV−1/2
r/vextenddouble/vextenddouble
1/bracketrightbig
,(19)
where the first iequality holds by Assumption 4.1, and the last one holds by Assumption 4.3 and Lemma F.8
about bounding∇f(xr)andmr.
E.3 Bounding III
For bounding III, use the similar way for bounding II,
III=η2L
2E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble/hatwideV−1/2
r ∆r+β1
1−β1/parenleftbig/hatwideV−1/2
r−1−/hatwideV−1/2
r/parenrightbig
mr−1/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
≤η2LE/bracketleftbig/vextenddouble/vextenddouble/hatwideV−1/2
r ∆r/vextenddouble/vextenddouble2/bracketrightbig
+η2LE/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddoubleβ1
1−β1/parenleftbig/hatwideV−1/2
r−1−/hatwideV−1/2
r/parenrightbig
mr−1/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
≤η2L
ϵE[∥∆r∥2] +β2
1
(1−β1)2m2
n2η2η2
lLI2G2E/bracketleftbig/vextenddouble/vextenddouble/hatwideV−1/2
r−1−/hatwideV−1/2
r/vextenddouble/vextenddouble2/bracketrightbig
, (20)
where the first inequality holds by Cauchy-Schwarz inequality, and the second one follows by Assumption
4.3 and Lemma F.8 about bounding ∇f(xr)andmr.
E.4 Bounding IV
Similarly, we bound the last term in equation 14,
IV=E/bracketleftig/angbracketleftig
∇f(zr)−∇f(xr),η/hatwideV−1/2
r ∆r/angbracketrightig/bracketrightig
≤E/bracketleftig
∥∇f(zr)−∇f(xr)∥/vextenddouble/vextenddouble/vextenddoubleη/hatwideV−1/2
r ∆r/vextenddouble/vextenddouble/vextenddouble/bracketrightig
≤LE/bracketleftig
∥zr−xr∥/vextenddouble/vextenddouble/vextenddoubleη/hatwideV−1/2
r ∆r/vextenddouble/vextenddouble/vextenddouble/bracketrightig
≤η2L
2E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddoubleβ1
1−β1/hatwideV−1/2
rmr/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
+η2L
2E/bracketleftig/vextenddouble/vextenddouble/vextenddouble/hatwideV−1/2
r ∆r/vextenddouble/vextenddouble/vextenddouble2/bracketrightig
≤η2L
2ϵβ2
1
(1−β1)2E[∥mr∥2] +η2L
2ϵE[∥∆r∥2], (21)
25Published in Transactions on Machine Learning Research (08/2024)
where the first inequality holds due to Young’s inequality, and the second one follows from Assumption 4.1
and the definition of virtual sequence zr. By Lemma F.7, we have
R/summationdisplay
r=1E[∥mr∥2]≤R/summationdisplay
r=1E[∥∆r∥2]. (22)
Therefore, the summation of IVterm is bounded by
R/summationdisplay
r=1IV≤/parenleftbiggη2L
2ϵβ2
1
(1−β1)2+η2L
2ϵ/parenrightbiggR/summationdisplay
r=1E[∥∆r∥2]. (23)
MergingItoIVtogether, we obtain the following result for bounding equation 14,
E[f(zr+1)]−f(z1)
≤ηηl
4C0m
n/braceleftbigg
−IE[∥∇f(xr)∥2]−I−1/summationdisplay
t=0E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
NN/summationdisplay
i=1∇fi(xi
r,t)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
−I−1/summationdisplay
t=0E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
KK/summationdisplay
k=1∇¯fk(¯xk
r,t)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg/bracerightbigg
+ηηl
4√ϵm
n/bracketleftbigg
3L2I2C1η2
l(I+ρ2
maxHI,ρ)(α2E[∥∇f(xr)∥2+σ2
c) + 3L2I2C1ρ2
maxHI,ρη2
l¯σ2
l
+ 3L2I2C1η2
lσ2ρ2
max+ 3L2C1/parenleftbig
I2+H2
I,ρ·ρ2
max/parenrightbig
η2
l/parenleftbiggσ2
n+m(n−m)
n(n−1)I¯σ2
l/parenrightbigg/bracketrightbigg
+/parenleftbigg
ηβ1
1−β1m
nηlIG2+η2β2
1
(1−β1)2m2
n2Lη2
lI2G2ϵ−1/2/parenrightbigg
E/bracketleftbig/vextenddouble/vextenddouble/hatwideV−1/2
r−1−/hatwideV−1/2
r/vextenddouble/vextenddouble
1/bracketrightbig
+η2Lβ2
1
(1−β1)2m2
n2η2
lI2G2E/bracketleftbig/vextenddouble/vextenddouble/hatwideV−1/2
r−1−/hatwideV−1/2
r/vextenddouble/vextenddouble2/bracketrightbig
+/parenleftbiggη2L
2ϵβ2
1
(1−β1)2+η2L
2ϵ+η2L
ϵ/parenrightbigg
E[∥∆r∥2],
then substituting the bound of ∥∆r∥2in Lemma F.5, and by applying Lemma F.4, then we have
n
mR/summationdisplay
r=1/bracketleftbig
E[f(zr+1)]−f(z1)/bracketrightbig
≤−ηηlI
4C0R/summationdisplay
r=1E[∥∇f(xr)∥2]−ηηl
4C0R/summationdisplay
r=1I−1/summationdisplay
t=0E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
NN/summationdisplay
i=1∇fi(xi
r,t)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
−ηηl
4C0R/summationdisplay
r=1I−1/summationdisplay
t=0E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
KK/summationdisplay
k=1∇¯fk(¯xk
r,t)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
+ηηl
4√ϵR/summationdisplay
r=1/bracketleftbigg
3L2I2C1η2
l(I+ρ2
maxHI,ρ)(α2E[∥∇f(xr)∥2] +σ2
c) + 3L2I2C1ρ2
maxHI,ρη2
l¯σ2
l
+ 3L2I2C1η2
lσ2ρ2
max+ 3L2C1/parenleftbig
I2+H2
I,ρ·ρ2
max/parenrightbig
η2
l/parenleftbiggσ2
n+m(n−m)
n(n−1)I¯σ2
l/parenrightbigg/bracketrightbigg
+/parenleftbigg
ηβ1
1−β1ηlIG2+η2β2
1
(1−β1)2m
nLη2
lI2G2ϵ−1/2/parenrightbiggR/summationdisplay
r=1E/bracketleftbig/vextenddouble/vextenddouble/hatwideV−1/2
r−1−/hatwideV−1/2
r/vextenddouble/vextenddouble
1/bracketrightbig
+η2Lβ2
1
(1−β1)2m
nη2
lI2G2R/summationdisplay
r=1E/bracketleftbig/vextenddouble/vextenddouble/hatwideV−1/2
r−1−/hatwideV−1/2
r/vextenddouble/vextenddouble2/bracketrightbig
26Published in Transactions on Machine Learning Research (08/2024)
+/parenleftbiggη2L
2ϵβ2
1
(1−β1)2+η2L
2ϵ+η2L
ϵ/parenrightbiggR/summationdisplay
r=1/braceleftbigg2η2
lI
Nσ2+64η2
lI(n−m)
n(n−1)[¯σ2
l+σ2
c]
+/parenleftbigg2n(n−m)
m2(n−1)+64η2
lIL2(n−m)
n(n−1)+ 4η2
l(I+ 1)2L2/parenrightbigg/bracketleftbigg
IC1η2
lHI,ρρ2
max(α2E[∥∇f(xr)∥2] +σ2
c)
+IC1η2
lHI,ρρ2
max¯σ2
l+IC1η2
lρ2
maxσ2+IC1η2
lH2
I,ρ
I2·ρ2
max/parenleftbiggσ2
n+m(n−m)
n(n−1)I¯σ2
l/parenrightbigg/bracketrightbigg
+64η2
lL2(n−m)
n(n−1)/bracketleftbigg
I3C1η2
l(α2E[∥∇f(xr)∥2] +σ2
c) +I2C1η2
l/parenleftbiggσ2
n+m(n−m)
n(n−1)I¯σ2
l/parenrightbigg/bracketrightbigg
+16η2
l(m−1)
(n−1)I−1/summationdisplay
t=0E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
NN/summationdisplay
i=1∇fi(xi
r,t)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
+8η2
lIm
nI−1/summationdisplay
t=0E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
KK/summationdisplay
k=1∇¯fk(¯xk
r,t)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg/bracerightbigg
. (24)
we need the certain constraint on local learning rate
Cβ,ηη/bracketleftbigg16η2
l
N2(m−1)
(n−1)+2(I+ 2)η2
lm
N2n/bracketrightbigg
≤ηηl
4C0
⇒ηl≤1
4C0Cβ,η/bracketleftbigg4
N2(m−1)
(n−1)+2(I+ 2)m
N2n/bracketrightbigg−1
, (25)
whereCβ,η=/parenleftig
ηL
ϵβ2
1
(1−β1)2+3ηL
ϵ/parenrightig
=O(max{η,1}), we further need the requirement of ηl, which is same as
the requirement in full participation settings
ηηl
4√ϵ3L2I2C1η2
l(I+ρ2
maxHI,ρ)α2+/parenleftbigg2n(n−m)
m2(n−1)+32η2
lL2(n−m)
n(n−1)/parenrightbigg
Cβ,ηηI2C1η2
lHI,ρρ2
maxα2
+32η2
lL2(n−m)
n(n−1)Cβ,ηηI3C1η2
lα2≤ηηlI
8C0,
⇒1
4√ϵ3L2IC1η2
l(I+ρ2
maxHI,ρ)α2+/parenleftbigg2n(n−m)
m2(n−1)+32η2
lL2(n−m)
n(n−1)/parenrightbigg
Cβ,ηIC1ηlHI,ρρ2
maxα2
+32η2
lL2(n−m)
n(n−1)Cβ,ηI2C1ηlα2≤1
8C0, (26)
⇒ηl≤4√ϵ/radicalbig
18L2C0C1I(I+ρ2maxHI,ρ)α2, (27)
thus we have
ηηlI
8C0RR/summationdisplay
r=1E[∥∇f(xr)∥2]
≤n
Rm/bracketleftbig
E[f(zr+1)]−f(z1)/bracketrightbig
+ηηl
4R√ϵR/summationdisplay
r=1/bracketleftbigg
3L2I2C1η2
l(I+ρ2
maxHI,ρ)σ2
c+ 3L2I2C1ρ2
maxHI,ρη2
l¯σ2
l
+ 3L2I2C1η2
lσ2ρ2
max+ 3L2C1/parenleftbig
I2+H2
I,ρ·ρ2
max/parenrightbig
η2
l/parenleftbiggσ2
n+m(n−m)
n(n−1)I¯σ2
l/parenrightbigg/bracketrightbigg
+β1
1−β1ηηlIG2d
R√ϵ
+ 2β2
1
(1−β1)2m
nη2η2
lLI2G2d
ϵ+/parenleftbiggη2L
2ϵβ2
1
(1−β1)2+η2L
2ϵ+η2L
ϵ/parenrightbigg/braceleftbigg2η2
lI
Nσ2
+/parenleftbigg2n(n−m)
m2(n−1)+64η2
lIL2(n−m)
n(n−1)+ 4η2
l(I+ 1)2L2/parenrightbigg/bracketleftbigg
IC1η2
lHI,ρρ2
maxσ2
c
+IC1η2
lHI,ρρ2
max¯σ2
l+IC1η2
lρ2
maxσ2+IC1η2
lH2
I,ρ
I2·ρ2
max/parenleftbiggσ2
n+m(n−m)
n(n−1)I¯σ2
l/parenrightbigg/bracketrightbigg
+ 64η2
lL2(n−m)
n(n−1)/bracketleftbigg
I3C1η2
lσ2
c+I2C1η2
l/parenleftbiggσ2
n+m(n−m)
n(n−1)I¯σ2
l/parenrightbigg/bracketrightbigg
+64η2
lI(n−m)
n(n−1)[¯σ2
l+σ2
c]/bracerightbigg
(28)
27Published in Transactions on Machine Learning Research (08/2024)
since there is HI,ρ= min{1
1−ρmax,I}≤Iandρmax≤1,
1
8C0RR/summationdisplay
r=1E[∥∇f(xr)∥2]
≤n
ηηlRIm/bracketleftbig
E[f(zr+1)]−f(z1)/bracketrightbig
+1
4√ϵ/bracketleftbigg
C·L2η2
lI(I+HI,ρ)σ2
c
+C·L2η2
lI/parenleftbigg
ρ2
maxHI,ρ¯σ2
l+m(n−m)
n(n−1)I¯σ2
l+σ2ρ2
max/parenleftbigg
1 +1
n/parenrightbigg/parenrightbigg/bracketrightbigg
+CβG2d
R√ϵ+ 2C2
βm
nLηηlIG2d
ϵ
+/parenleftbiggηL
2ϵβ2
1
(1−β1)2+ηL
2ϵ+ηL
ϵ/parenrightbigg/braceleftbigg2ηl
Nσ2+/parenleftbigg2n(n−m)
m2(n−1)+64η2
lIL2(n−m)
n(n−1)+ 4η2
l(I+ 1)2L2/parenrightbigg
·/bracketleftbigg
C1ηlHI,ρρ2
maxσ2
c+C1ηlHI,ρρ2
max¯σ2
l+C1ηlρ2
maxσ2+C1ηlH2
I,ρ
I2·ρ2
max/parenleftbiggσ2
n+m(n−m)
n(n−1)I¯σ2
l/parenrightbigg/bracketrightbigg
+64(n−m)
n(n−1)/bracketleftbigg
C1L2η3
lI2σ2
c+C1L2η3
lI/parenleftbiggσ2
n+m(n−m)
n(n−1)I¯σ2
l/parenrightbigg
+ηl¯σ2
l+ηlσ2
c/bracketrightbigg/bracerightbigg
, (29)
whereCis a constant irrelevant to parameters and ρmax= maxk∈[K]ρk,HI,ρ= min/braceleftbig1
1−ρmax,I/bracerightbig
,Cβ=β1
1−β1
and¯σ2
L=1
K/summationtextK
k=1σ2
k. This concludes the proof.
If we further apply the constraint of
n(n−m)
m2(n−1)HI,ρρ2
max≤1
n, (30)
where the condition Eq. 30 implies that the spectral gap ρmaxsatisfies
ρ2
max
1−ρmax≤m2
n2, (31)
with the condition of Eq. 31, then we assume there is ρmax≤m
m+n, which satisfies
n(n−m)
m2(n−1)HI,ρρ2
max=n(n−m)
m2(n−1)ρ2
max
1−ρmax≤n(n−m)
m2(n−1)m2
(m+n)n≤1
n. (32)
28Published in Transactions on Machine Learning Research (08/2024)
Also by choosing a constant /tildewideC, we have
1
RR/summationdisplay
r=1E[∥∇f(xr)∥2]
≤8C0/braceleftbiggn[E[f(zr+1)]−f(z0)]
ηηlRIm+1
R/parenleftbiggCβG2d√ϵ+2C2
βηηlILG2dm
ϵn/parenrightbigg
/bracehtipupleft /bracehtipdownright/bracehtipdownleft /bracehtipupright
T1
+CL2η2
l
4√ϵ/bracketleftbigg
I(I+HI,ρ)σ2
c+/parenleftbigg
Iρ2
maxHI,ρ¯σ2
l+n+ 1
nIσ2ρ2
max+m(n−m)
n(n−1)I2¯σ2
l/parenrightbigg/bracketrightbigg
/bracehtipupleft /bracehtipdownright/bracehtipdownleft /bracehtipupright
T2
+ηl
N/parenleftbiggηL
ϵβ2
1
(1−β1)2+3ηL
ϵ/parenrightbigg
σ2
/bracehtipupleft/bracehtipdownright/bracehtipdownleft /bracehtipupright
T3+C3ηl
n/parenleftbiggηL
ϵβ2
1
(1−β1)2+3ηL
ϵ/parenrightbigg
[¯σ2
l+σ2
c]
/bracehtipupleft /bracehtipdownright/bracehtipdownleft /bracehtipupright
T4
+C2ηl
n/parenleftbiggηL
ϵβ2
1
(1−β1)2+3ηL
ϵ/parenrightbigg/bracketleftbigg
σ2
c+ ¯σ2
l+σ2+HI,ρσ2
I2n+m(n−m)
n(n−1)HI,ρ
I¯σ2
l/bracketrightbigg
/bracehtipupleft /bracehtipdownright/bracehtipdownleft /bracehtipupright
T5
+C3L2η3
lI
n/parenleftbiggηL
ϵβ2
1
(1−β1)2+3ηL
ϵ/parenrightbigg
/bracehtipupleft /bracehtipdownright/bracehtipdownleft /bracehtipupright
T6
·/bracketleftbigg
(I+HI,ρρ2
max)σ2
c+HI,ρρ2
max¯σ2
l+n+ 1
nρ2
maxσ2+σ2
n+m(n−m)
n(n−1)I¯σ2
l/bracketrightbigg
/bracehtipupleft /bracehtipdownright/bracehtipdownleft /bracehtipupright
T7
+C4(I+ 1)2η3
lm
n/parenleftbiggηL
ϵβ2
1
(1−β1)2+3ηL
ϵ/parenrightbigg/bracketleftbigg
σ2
c+ ¯σ2
l+σ2+HI,ρσ2
I2n+m(n−m)
n(n−1)HI,ρ
I¯σ2
l/bracketrightbigg
/bracehtipupleft /bracehtipdownright/bracehtipdownleft /bracehtipupright
T8(33)
By adopting learning rates η= Θ(n/radicalig
I
m)andηl= Θ/parenleftbig1√
RI/parenrightbig
, then we have
T1=n[E[f(zr+1)]−f(z0)]
ηηlRIm+1
R/parenleftbiggCβG2d√ϵ+2C2
βηηlILG2dm
ϵn/parenrightbigg
=E[f(zr+1)]−f(z0)√
RIm+1
R/parenleftbiggCβG2d√ϵ+2C2
βLG2d√
Im
ϵ√
R/parenrightbigg
=O/parenleftbiggE[f(zr+1)]−f(z0)√
RIm+G2
R/parenrightbigg
+/tildewideO/parenleftbigg1
R3/2/parenrightbigg
.
T2=CL2η2
l
4√ϵ/bracketleftbigg
I(I+HI,ρ)σ2
c+/parenleftbigg
Iρ2
maxHI,ρ¯σ2
l+n+ 1
nIσ2ρ2
max+m(n−m)
n(n−1)I2¯σ2
l/parenrightbigg/bracketrightbigg
=CL2
4RI2√ϵ/bracketleftbigg
I(I+HI,ρ)σ2
c+/parenleftbigg
Iρ2
maxHI,ρ¯σ2
l+n+ 1
nIσ2ρ2
max+m(n−m)
n(n−1)I2¯σ2
l/parenrightbigg/bracketrightbigg
=CL2
4RI√ϵ/bracketleftbigg
(I+HI,ρ)σ2
c+/parenleftbigg
ρ2
maxHI,ρ¯σ2
l+n+ 1
nσ2ρ2
max+m(n−m)
n(n−1)I¯σ2
l/parenrightbigg/bracketrightbigg
≤CL2
4RI√ϵ/bracketleftbigg
2Iσ2
c+/parenleftbigg
ρ2
maxI¯σ2
l+n+ 1
nσ2ρ2
max+m
nI¯σ2
l/parenrightbigg/bracketrightbigg
=O/parenleftbigg1
R/bracketleftbigg
L2[σ2
c+ (1 +ρ2
max)¯σ2
l] +ρ2
maxσ2
I/bracketrightbigg/parenrightbigg
.
29Published in Transactions on Machine Learning Research (08/2024)
where the inequality holds by the definition of HI,ρ= min/braceleftbig1
1−ρmax,I/bracerightbig
, and the big-Oholds because m≤n.
T3=ηl
N/parenleftbiggηL
ϵβ2
1
(1−β1)2+3ηL
ϵ/parenrightbigg
σ2=1
N/parenleftbiggn√
RImL
ϵβ2
1
(1−β1)2+n√
RIm3L
ϵ/parenrightbigg
σ2
=O/parenleftbiggnL
N√
RImσ2/parenrightbigg
=O/parenleftbiggL
K√
RImσ2/parenrightbigg
. (34)
The simplification of T4is very similar to that of T3,
T4=C3ηl
n/parenleftbiggηL
ϵβ2
1
(1−β1)2+3ηL
ϵ/parenrightbigg
[¯σ2
l+σ2
c] =O/parenleftbiggL√
RIm[¯σ2
l+σ2
c]/parenrightbigg
.
The simplification of the first half of T5is very similar to that of T3andT4,
T5=C2ηl
n/parenleftbiggηL
ϵβ2
1
(1−β1)2+3ηL
ϵ/parenrightbigg/bracketleftbigg
σ2
c+ ¯σ2
l+σ2+HI,ρσ2
I2n+m(n−m)
n(n−1)HI,ρ
I¯σ2
l/bracketrightbigg
=C2
n/parenleftbiggn√
RImL
ϵβ2
1
(1−β1)2+n√
RIm3L
ϵ/parenrightbigg
·/bracketleftbigg
σ2
c+ ¯σ2
l+σ2+HI,ρσ2
I2n+m(n−m)
n(n−1)HI,ρ
I¯σ2
l/bracketrightbigg
≤C2/parenleftbigg1√
RImL
ϵβ2
1
(1−β1)2+1√
RIm3L
ϵ/parenrightbigg
·/bracketleftbigg
σ2
c+ ¯σ2
l+σ2+σ2
In+ ¯σ2
l/bracketrightbigg
=O/parenleftbiggL√
RIm[σ2
c+ ¯σ2
l+σ2]/parenrightbigg
,
The simplification of T6is very similar to that of T3andT4as well, so that
T6=C3L2η3
lI
n/parenleftbiggηL
ϵβ2
1
(1−β1)2+3ηL
ϵ/parenrightbigg
=O/parenleftbigg1
RI·L√
RIm[¯σ2
l+σ2
c]L2/parenrightbigg
=/tildewideO/parenleftbigg1
R3/2/parenrightbigg
.
We boundT6·T7together. since we previously have the bound for T6, then
T6·T7=T6·/bracketleftbigg
(I+HI,ρρ2
max)σ2
c+HI,ρρ2
max¯σ2
l+n+ 1
nρ2
maxσ2+σ2
n+m(n−m)
n(n−1)I¯σ2
l/bracketrightbigg
≤T6·/bracketleftbigg
2Iσ2
c+I¯σ2
l+n+ 1
nσ2+σ2
n+I¯σ2
l/bracketrightbigg
=/tildewideO/parenleftbigg1
R3/2/parenrightbigg
.
The simplification of the first half of T8is very similar to that of T3andT4,
T8=C4(I+ 1)2η3
lm
n/parenleftbiggηL
ϵβ2
1
(1−β1)2+3ηL
ϵ/parenrightbigg/bracketleftbigg
σ2
c+ ¯σ2
l+σ2+HI,ρσ2
I2n+m(n−m)
n(n−1)HI,ρ
I¯σ2
l/bracketrightbigg
=C4(I+ 1)2η2
lm
n/parenleftbiggηηlL
ϵβ2
1
(1−β1)2+3ηηlL
ϵ/parenrightbigg/bracketleftbigg
σ2
c+ ¯σ2
l+σ2+HI,ρσ2
I2n+m(n−m)
n(n−1)HI,ρ
I¯σ2
l/bracketrightbigg
=C4(I+ 1)2m
RI2n/parenleftbiggn√
RImL
ϵβ2
1
(1−β1)2+n√
RIm3L
ϵ/parenrightbigg
·/bracketleftbigg
σ2
c+ ¯σ2
l+σ2+HI,ρσ2
I2n+m(n−m)
n(n−1)HI,ρ
I¯σ2
l/bracketrightbigg
≤C4(I+ 1)2m
RI2n/parenleftbiggn√
RImL
ϵβ2
1
(1−β1)2+n√
RIm3L
ϵ/parenrightbigg
·/bracketleftbigg
σ2
c+ ¯σ2
l+σ2+σ2
In+ ¯σ2
l/bracketrightbigg
=/tildewideO/parenleftbigg1
R3/2/parenrightbigg
.
30Published in Transactions on Machine Learning Research (08/2024)
Therefore, merging terms from T1toT8, equation 33 should be
1
RR/summationdisplay
r=1E[∥∇f(xr)∥2] =T1+T2+T3+T4+T5+T6·T7+T8
=O/parenleftbiggE[f(zr+1)]−f(z0)√
RIm+G2
R/parenrightbigg
/bracehtipupleft /bracehtipdownright/bracehtipdownleft /bracehtipupright
T1+O/parenleftbigg1
R/bracketleftbigg
L2[σ2
c+ (1 +ρ2
max)¯σ2
l] +ρ2
maxσ2
I/bracketrightbigg/parenrightbigg
/bracehtipupleft /bracehtipdownright/bracehtipdownleft /bracehtipupright
T2
+O/parenleftbiggL
K√
RImσ2/parenrightbigg
/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
T3+O/parenleftbiggL√
RIm[¯σ2
l+σ2
c]/parenrightbigg
/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
T4+O/parenleftbiggL√
RIm[σ2
c+ ¯σ2
l+σ2]/parenrightbigg
/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
T5+/tildewideO/parenleftbigg1
R3/2/parenrightbigg
/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
T1,T6·T7,T8,(35)
note thatN=Kn, re-organizing them, we have
1
RR/summationdisplay
r=1E[∥∇f(xr)∥2] =O/parenleftbigg1√
RIm/bracketleftbigg
[f0−f∗] +/parenleftbigg
[σ2+ ¯σ2
l+σ2
c] +σ2
K/parenrightbigg
L/bracketrightbigg/parenrightbigg
+O/parenleftbigg1
R/bracketleftbigg
G2+L2[σ2
c+ (1 +ρ2
max)¯σ2
l] +ρ2
maxσ2
I/bracketrightbigg/parenrightbigg
+/tildewideO/parenleftbigg1
R3/2/parenrightbigg
.(36)
Based on the theoretical analysis above, we obtain the general convergence bound for (C)AFGA. Here we
conclude the proof for Theorem D.3.
Proof of Theorem 4.6. Note that the proof for AFGA is a special case of the proof for CAFGA. When there
is only one cluster containing all clients [N]in the CAFGA framework, it reduces to AFGA. Therefore,
for the convergence analysis of AFGA, we replace the Assumption D.1 with Assumption 4.4, and replace
Assumption D.2 with Assumption 4.5. This results in m=M,n =N,K = 1,ρmax=ρ,σc= 0and
σg=σk= ¯σl, and then we have
1
RR/summationdisplay
r=1E[∥∇f(xr)∥2]
=O/parenleftbigg1√
RIM/bracketleftbigg
[f0−f∗] +L[σ2+σ2
g]/bracketrightbigg/parenrightbigg
+O/parenleftbigg1
R/bracketleftbigg
G2+L2(1 +ρ2)σ2
g+ρ2σ2
I/bracketrightbigg/parenrightbigg
+/tildewideO/parenleftbigg1
R3/2/parenrightbigg
.(37)
hence we conclude the proof for Theorem 4.6.
F Supporting Lemmas
Lemma F.1 (Inter-cluster consensus error) .For local learning rate which satisfying the condition ηl≤1
8IL,
denoteCI= 1 +3
2·1
4I−1, recall the definition for ¯xin Eq. 9, the inter-cluster model difference after slocal
steps satisfies
1
KK/summationdisplay
k=1E[∥¯xk
r,t+1−xr∥2≤CI1
KK/summationdisplay
k=1E[∥¯xk
r,t−xr∥2+ 8Iη2
l(α2E[∥∇f(xr)∥2] +σ2
c) +η2
lσ2
n.(38)
31Published in Transactions on Machine Learning Research (08/2024)
Proof.Note that the following proof is similar to Lemma 3 in (Reddi et al., 2020). By definition and auxiliary
sequences, we have
E[∥¯xk
r,t+1−xr∥2] =E[∥¯xk
r,t−xr−ηl¯gk
r,t∥2]
=E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble¯xk
r,t−xr−ηl/parenleftbigg
¯gk
r,t∓1
n/summationdisplay
i∈Sk
r,t∇fi(xi
r,t)∓m
n∇¯fk(¯xk
r,t)∓m
n∇¯fk(xr)/parenrightbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
≤(1 +γ)E[∥¯xk
r,t−xr∥2] +η2
lE/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble¯gk
r,t−1
n/summationdisplay
i∈Sk
r,t∇fi(xi
r,t)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
+ 4(1 +γ−1)η2
lE/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
n/summationdisplay
i∈Sk
r,t[∇fi(xi
r,t)−∇fi(¯xk
r,t)]/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
+ 4(1 +γ−1)η2
lE/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
n/summationdisplay
i∈Sk
r,t∇fi(¯xk
r,t)−m
n∇¯fk(¯xk
r,t)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
+ 4(1 +γ−1)η2
lE[∥∇¯fk(¯xk
r,t)−∇¯fk(xr)∥2]
+ 4(1 +γ−1)η2
lE[∥∇¯fk(xr)∥2]
≤(1 +γ)E[∥¯xk
r,t−xr∥2] +η2
lσ2
n+ 4(1 +γ−1)η2
lL2E[∥¯xk
r,t−xr∥2] + 4(1 +γ−1)η2
lL21
nn/summationdisplay
i=1E[∥xi
r,t−¯xk
r,t∥2]
+ 4(1 +γ−1)η2
lE[∥∇¯fk(xr)∥2] +m(n−m)
n(n−1)4(1 +γ−1)η2
lσ2
k
≤[(1 +γ) + 4(1 +γ−1)η2
lL2]·E[∥¯xk
r,t−xr∥2] + 4(1 +γ−1)η2
lL21
nn/summationdisplay
i=1E[∥xi
r,t−¯xk
r,t∥2]
+η2
lσ2
n+ 4(1 +γ−1)η2
lE[∥∇¯fk(xr)∥2] +m(n−m)
n(n−1)4(1 +γ−1)η2
lσ2
k, (39)
where the first equality holds by Eq. 10. The first inequality holds due to gi
r,tis an unbiased estimator of
∇fi(xi
r,t)and Young’s inequality. The second inequality holds by Assumption 4.1 and 4.2, also the property
of sampling in the cluster (see details in Lemma F.6), i.e.,
E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
n/summationdisplay
i∈Sk
r,t∇fi(¯xk
r,t)−m
n∇¯fk(¯xk
r,t)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
=E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
n/summationdisplay
i∈VkI{i∈Sk
r,t}[∇fi(¯xk
r,t)−∇¯fk(¯xk
r,t)]/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
=m(n−m)
n(n−1)1
n2/summationdisplay
i∈VkE[∥∇fi(¯xk
r,t)−∇¯fk(¯xk
r,t)∥2] +m(m−1)
n(n−1)E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
n/summationdisplay
i∈Vk∇fi(¯xk
r,t)−∇¯fk(¯xk
r,t)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
≤m(n−m)
n(n−1)σ2
k.
Averaging Eq. 39 over k= 1,...,Kclusters, we have
1
KK/summationdisplay
k=1E[∥¯xk
r,t+1−xr∥2]
≤[(1 +γ) + 4(1 +γ−1)η2
lL2]1
KK/summationdisplay
k=1E[∥¯xk
r,t−xr∥2] + 4(1 +γ−1)η2
lL21
NK/summationdisplay
k=1n/summationdisplay
i=1E[∥xi
r,t−¯xk
r,t∥2]
+ 4(1 +γ−1)η2
l1
KK/summationdisplay
k=1E[∥∇¯fk(xr)∥2] +η2
lσ2
n+m(n−m)
n(n−1)4(1 +γ−1)η2
l¯σ2
l
≤[(1 +γ) + 4(1 +γ−1)η2
lL2]1
KK/summationdisplay
k=1E[∥¯xk
r,t−xr∥2] + 4(1 +γ−1)η2
lL21
NK/summationdisplay
k=1n/summationdisplay
i=1E[∥xi
r,t−¯xk
r,t∥2]
+ 4(1 +γ−1)η2
l(α2E[∥∇f(xr)∥2] +σ2
c) +η2
lσ2
n+m(n−m)
n(n−1)4(1 +γ−1)η2
l¯σ2
l, (40)
32Published in Transactions on Machine Learning Research (08/2024)
where the second inequality holds by Assumption 4.4, and incorporates the previously defined term ¯σ2
l=
1
K/summationtextK
k=1σ2
k. Choosing γ=1
4I−1with the condition of ηl≤1
8IL, we have
1
KK/summationdisplay
k=1E[∥¯xk
r,t+1−xr∥2]
≤/parenleftbigg
1 +1
4I−1+1
2(4I−1)/parenrightbigg1
KK/summationdisplay
k=1E[∥¯xk
r,t−xr∥2] + 16Iη2
lL21
NK/summationdisplay
k=1/summationdisplay
i∈VkE[∥xi
r,t−¯xk
r,t∥2]
+ 16Iη2
l(α2E[∥∇f(xr)∥2] +σ2
c) +η2
lσ2
n+m(n−m)
n(n−1)16Iη2
l¯σ2
l
=CI1
KK/summationdisplay
k=1E[∥¯xk
r,t−xr∥2] + 16Iη2
lL21
NK/summationdisplay
k=1/summationdisplay
i∈VkE[∥xi
r,t−¯xk
r,t∥2] + 16Iη2
l(α2E[∥∇f(xr)∥2] +σ2
c)
+η2
lσ2
n+m(n−m)
n(n−1)16Iη2
l¯σ2
l, (41)
whereCI= 1 +3
2·1
4I−1. This concludes the proof.
F.1 Lemma for intra-cluster consensus error
Lemma F.2. The intra-cluster consensus error/summationtextn
i=1∥¯xk
r,t−xi
r,t∥2, also known as∥Xk,⊥
r,t∥2
F, has the fol-
lowing upper bound,
1
NK/summationdisplay
k=1E[∥Xk,⊥
r,t+1∥2
F]
≤/parenleftbigg
max
k∈[K]ρ2
k(1 +ζ−1
k) +η2
l·4L2max
k∈[K]{ρ2
k(1 +ζk)}/parenrightbigg1
NK/summationdisplay
k=1E[∥Xk,⊥
r,t∥2]
+η2
lmax
k∈[K]{ρ2
k(1 +ζk)}·4L2E[∥¯xk
r,t−xr∥2] +η2
lmax
k∈[K]{ρ2
k(1 +ζk)}·4(α2E[∥∇f(xr)∥2] +σ2
c)
+η2
l1
KK/summationdisplay
k=1ρ2
k(1 +ζk)4σ2
k+η2
lσ2ρ2
max, (42)
whereζkis some constant related to the Young’s inequality, and it could be uniformly chosen for all k=
1,...,K.
Proof.By definition we have Xk
r,t= (x1
r,t,...,xn
r,t)′andXk,⊥
r,t=Xk
r,t(In−J), whereJ=1
n1n·1′
n. Thus we
have
n/summationdisplay
i=1∥¯xk
r,t−xi
r,t∥2=∥(x1
r,t,...,xn
r,t)(In−J)·In·(In−J)(x1
r,t,...,xn
r,t)′∥F
=∥Xk
r,t′(In−J)·(In−J)Xk
r,t∥F
=∥Xk,⊥
r,t′·Xk,⊥
r,t∥F
=∥Xk,⊥
r,t∥2
F, (43)
33Published in Transactions on Machine Learning Research (08/2024)
Recall the update rule of AFGA and CAFGA, there is Xk,⊥
r,t+1= (Wk−J)(Xk,⊥
r,t−ηlGk
r,t), then we have
E[∥Xk,⊥
r,t+1∥2
F] =E(E(∥(Wk−J)(Xk,⊥
r,t−ηlGk
r,t)∥2|Fr,t−1))
=E(E(∥(Wk−J)(Xk,⊥
r,t−ηl∇F(Xk
r,t) +ηl∇F(Xk
r,t)−ηlGk
r,t)∥2|Fr,t−1))
=E(E(∥(Wk−J)(Xk,⊥
r,t−ηl∇F(Xk
r,t))∥2|Fr,t−1))
+η2
lE(E(∥(Wk−J)(∇F(Xk
r,t)−Gk
r,t)∥2|Fr,t−1))
≤E[∥(Wk−J)(Xk,⊥
r,t−ηl∇F(Xk
r,t))∥2] +η2
lρ2
knσ2
≤ρ2
k(1 +ζ−1
k)·E[∥Xk,⊥
r,t∥2] +ρ2
k(1 +ζk)η2
lE[∥∇F(Xk
r,t))∥2] +η2
lρ2
knσ2, (44)
where the∇Fk(Xk)∈Rn×dis associated to cluster kby stacking∇fi(xi)fori∈Vkrow-wise. The third
equality is due to the unbiasedness of stochastic gradient. The first inequality holds by Assumption 4.2 and
∥∇F(Xk
r,t)−Gk
r,t∥F=/summationtextn
i=1∥∇fi(xi
r,t)−gi
r,t∥2. For the Frobenius norm, there is ∥AB∥F≤∥A∥2∥B∥F.
The second inequality holds by Young’s inequality with some parameter ζk>0and∥AB∥F≤∥A∥2∥B∥F
as well. For∇Fk(Xk
r,t), by definition, we have
∥∇Fk(Xk
r,t)∥2
F=/summationdisplay
i∈Vk∥∇fi(xi
r,t)∥2
=/summationdisplay
i∈Vk∥∇fi(xi
r,t)−∇fi(¯xk
r,t) +∇fi(¯xk
r,t)−∇¯fk(¯xk
r,t) +∇¯fk(¯xk
r,t)−∇¯fk(xr) +∇¯fk(xr)∥2
≤/summationdisplay
i∈Vk/bracketleftbigg
4∥∇fi(xi
r,t)−∇fi(¯xk
r,t)∥2+ 4∥∇fi(¯xk
r,t)−∇¯fk(¯xk
r,t)∥2+ 4∥∇¯fk(¯xk
r,t)−∇¯fk(xr)∥2
+ 4∥∇¯fk(xr)∥2/bracketrightbigg
≤/summationdisplay
i∈Vk/bracketleftbigg
4∥∇fi(¯xk
r,t)−∇¯fk(¯xk
r,t)∥2+ 4L2∥xi
r,t−¯xk
r,t∥2+ 4L2∥¯xk
r,t−xr∥2+ 4∥∇¯fk(xr)∥2/bracketrightbigg
≤4L2∥Xk,⊥
r,t∥2+ 4L2n∥¯xk
r,t−xr∥2+ 4n∥∇¯fk(xr)∥2+ 4nσ2
k, (45)
where the first inequality holds by Cauchy inequality, the second inequality holds by Assumption 4.1, and
the last inequality holds by Assumption 4.4. Averaging Eq. 45 over k= 1,...,K, we have the following
34Published in Transactions on Machine Learning Research (08/2024)
iteration
1
NK/summationdisplay
k=1E[∥Xk,⊥
r,t+1∥2]
≤1
NK/summationdisplay
k=1ρ2
k(1 +ζ−1
k)·E[∥Xk,⊥
r,t∥2] +1
NK/summationdisplay
k=1ρ2
k(1 +ζk)η2
lE[∥∇F(Xk
r,t))∥2] +η2
lσ21
KK/summationdisplay
k=1ρ2
k
≤1
NK/summationdisplay
k=1ρ2
k(1 +ζ−1
k)·E[∥Xk,⊥
r,t∥2] +η2
l1
NK/summationdisplay
k=1ρ2
k(1 +ζk)·4L2E[∥Xk,⊥
r,t∥2]
+η2
l1
KK/summationdisplay
k=1ρ2
k(1 +ζk)·4L2E[∥¯xk
r,t−xr∥2] +η2
l1
KK/summationdisplay
k=1ρ2
k(1 +ζk)·4E[∥∇¯fk(xr)∥2]
+η2
l1
KK/summationdisplay
k=1ρ2
k(1 +ζk)·4σ2
k+η2
lσ2ρ2
max
≤/parenleftbigg
max
k∈[K]ρ2
k(1 +ζ−1
k) +η2
l·4L2max
k∈[K]{ρ2
k(1 +ζk)}/parenrightbigg1
NK/summationdisplay
k=1E[∥Xk,⊥
r,t∥2]
+η2
lmax
k∈[K]{ρ2
k(1 +ζk)}·4L2E[∥¯xk
r,t−xr∥2] +η2
lmax
k∈[K]{ρ2
k(1 +ζk)}·4(α2E[∥∇f(xr)∥2] +σ2
c)
+η2
l1
KK/summationdisplay
k=1ρ2
k(1 +ζk)4σ2
k+η2
lσ2ρ2
max. (46)
This concludes the proof.
F.2 Lemma for summation of intra-cluster and inter-cluster consensus errors
Lemma F.3. If the local learning rate satisfies the condition: ηl≤1
8IL, the for all local round s= 0,...,I−1,
there is
1
NK/summationdisplay
k=1E[∥Xk,⊥
r,t∥2] +1
KK/summationdisplay
k=1E[∥¯xk
r,t−xr∥2]
≤(t+ 1)C1η2
l(I+ρ2
maxHI,ρ)(α2E[∥∇f(xr)∥2] +σ2
c) + (t+ 1)C1ρ2
maxHI,ρη2
l¯σ2
l
+ (t+ 1)C1η2
lσ2ρ2
max+ (t+ 1)C1/parenleftbigg
1 +H2
I,ρ
I2·ρ2
max/parenrightbigg
η2
l/parenleftbiggσ2
n+m(n−m)
n(n−1)I¯σ2
l/parenrightbigg
, (47)
whereC1is a constant independent to parameters.
Proof.Denote an auxiliary vector
Mr,t=/parenleftbigg1
NK/summationdisplay
k=1E[∥Xk,⊥
r,t∥2],1
KK/summationdisplay
k=1E[∥¯xk
r,t−xr∥2]/parenrightbiggT
. (48)
From Lemma F.1 and F.2, we have the following inequality which is defined element-wise for s= 0,...,I−1
Mr,t+1≤G·Mr,t+Br,t, (49)
where
G=/parenleftbigg
maxk∈[K]ρ2
k(1 +ζ−1
k) +η2
lρL·4L2η2
lρL·4L2
16Iη2
lL2CI/parenrightbigg
(50)
Br,t=/parenleftigg
4ρLη2
l(α2E[∥∇f(xr)∥2] +σ2
c) + 4ρLη2
l¯σ2
l+η2
lσ2ρ2
max
16Iη2
l(α2E[∥∇f(xr)∥2] +σ2
c) +η2
lσ2
n+16m(n−m)
n(n−1)Iη2
lσ2
k/parenrightigg
=/parenleftbiggb(1)
b(2)/parenrightbigg
. (51)
35Published in Transactions on Machine Learning Research (08/2024)
Consider the eigen-decomposition of matrix G,
G=1
16Iη2
lL2(λ1−λ2)/parenleftbiggλ1−CIλ2−CI
16Iη2
lL216Iη2
lL2/parenrightbigg
·/parenleftbiggλ10
0λ2/parenrightbigg
·/parenleftbigg16Iη2
lL2−λ2+CI
−16Iη2
lL2λ1−CI/parenrightbigg
,(52)
where we assume λ1≤λ2, thus we have
GjB=1
16Iη2
lL2(λ1−λ2)/parenleftbiggλ1−CIλ2−CI
16Iη2
lL216Iη2
lL2/parenrightbigg/parenleftbiggλ10
0λ2/parenrightbigg/parenleftbigg16Iη2
lL2−λ2+CI
−16Iη2
lL2λ1−CI/parenrightbigg/parenleftbiggb(1)
b(2)/parenrightbigg
=1
16Iη2
lL2(λ1−λ2)/parenleftbigg(λ1−CI)(λj
116Iη2
lL2b(1)+λj
1(−λ2+CI)b(2)) + (λ2−CI)(−λj
216Iη2
lL2b(1)+λj
2(λ1−CI)b(2))
16Iη2
lL2(λj
116Iη2
lL2b(1)+λj
1(−λ2+CI)b(2)) + 16Iη2
lL2(−λj
216Iη2
lL2b(1)+λj
2(λ1−CI)b(2))/parenrightbigg
.
(53)
Therefore the sum of two elements has the following result
(1,1)GjBr,t−j=λj
1b(1)+λj
2b(2)+λj
2−λj
1
λ2−λ1/parenleftbigg
16Iη2
lL2b(1)+ 4η2
lρLL2b(2)/parenrightbigg
≤λj
2(b(1)+b(2)) +λj
2−λj
1
λ2−λ1/parenleftbigg
16Iη2
lL2b(1)+ 4η2
lρLL2b(2)/parenrightbigg
. (54)
Therefore, we have the following result
t/summationdisplay
j=0(1,1)GjBr,t−j≤t/summationdisplay
j=0/parenleftbigg
λj
2(b(1)
r,t−j+b(2)
r,t−j) +λj
2−λj
1
λ2−λ1/parenleftbig
16Iη2
lL2b(1)+ 4η2
lρLL2b(2)/parenrightbig/parenrightbigg
.(55)
Sinceλ2≥CI>1, we have
λj
2−λj
1
λ2−λ1=λl−1
2l−1/summationdisplay
t=0/parenleftbiggλ1
λ2/parenrightbiggs
≤λj−1
2min/braceleftbiggλ2
λ2−λ1,l/bracerightbigg
≤λj
2min/braceleftbigg1
λ2−λ1,l/bracerightbigg
, (56)
thus we have
t/summationdisplay
j=0(1,1)GjBr,t−j≤t/summationdisplay
j=0λj
2(b(1)
r,t−j+b(2)
r,t−j) +s/summationdisplay
l=0/parenleftbigg
λj
2min/braceleftbigg1
λ2−λ1,l/bracerightbigg/parenleftbig
16Iη2
lL2b(1)+ 4η2
lρLL2b(2)/parenrightbig/parenrightbigg
.
(57)
By the definition of ρL= maxk∈[k]ρ2
k(1 +ζk)and by the Gershgorin’s theorem, since ηl>0, we have the
upper bound for λ2,
λ2≤max/braceleftbigg
max
k∈[K]ρ2
k(1 +ζ−1
k) +η2
lρL·8L2,CI+ 16Iη2
lL2/bracerightbigg
<max/braceleftbigg
max
k∈[K]ρ2
k(1 +ζ−1
k) +ρL
(4I−1)2I,1 +2
4I−1/bracerightbigg
, (58)
where the last inequality holds by the bound of η2
l≤1
64I2L2<1
16I(4I−1)L2. Define a distance constant
HI,ρ= min/braceleftbig
I,1
1−ρmax/bracerightbig
. Next we consider two cases: small or dense communication network with ρmax≤
1−1
Iandlarge and sparse communication network with ρmax>1−1
I.
Case 1: Forρmax≤1−1
I, i.e.,1
1−ρmax≤I, thus we have HI,ρ=1
1−ρmax. Letζk=ρk
1−ρk, then we have
max
k∈[k]ρ2
k(1 +ζ−1
k) =ρmax, ρL= max
k∈[k]/braceleftbiggρ2
k
1−ρk/bracerightbigg
=ρ2
max
1−ρmax=ρ2
maxHI,ρ, (59)
36Published in Transactions on Machine Learning Research (08/2024)
where the middle part of the second equality holds by the monotonically increasing ofx2
1−x. Then the bound
forλ2is formalized as
λ2≤max/braceleftbigg
ρmax+ρ2
max
(1−ρmax)2I(4I−1),1 +3
2(4I−1)/bracerightbigg
≤max/braceleftbigg
1−1
I+(1−1
I)2
2(I−1),1 +3
2(4I−1)/bracerightbigg
<1 +3
4I−1, (60)
where the second inequality holds by ρmax≤1−1
I. Then by s≤Iandλ2≥1(just by the definition of
matrixGcan get this result), we can obtain the following bound
t/summationdisplay
j=0λj
2b1
t−j≤/parenleftbigg/parenleftbigg
1 +2
4I−1/parenrightbiggI/parenrightbigg
·t/summationdisplay
j=0b(1)
j≤3·t/summationdisplay
j=0b(1)
j. (61)
We also have
ρmax+η2
lρL4L2≤ρmax+ρmax
(1−ρmax)(4I−1)4I≤1−1
I+(1−1
I)2
4(4I−1)≤CI, (62)
where the second inequality holds by the upper bound for ρmax. By the definition of matrix G, we bound
the difference of λ2−λ1,
λ2−λ1=CI−ρmax−η2
lρL4L2
≥CI−/parenleftbigg
ρmax+ρmax
(1−ρmax)(4I−1)4I/parenrightbigg
≥CI−/parenleftbigg
ρmax+ρmax·1−1
I
4(4I−1)/parenrightbigg
≥1 +1
4I−1−/parenleftbigg
ρmax+ρmax·1
4I−1/parenrightbigg
= (1−ρmax)/parenleftbigg
1 +1
4I−1/parenrightbigg
≥1−ρmax. (63)
where the first and second inequality hold by the defined notations. Then we have
t/summationdisplay
j=0(1,1)GjBr,t−j≤t/summationdisplay
j=0λj
2(b(1)
r,t−j+b(2)
r,t−j) +t/summationdisplay
j=0/parenleftbigg
λj
2min/braceleftbigg1
λ2−λ1,j/bracerightbigg/parenleftbig
16Iη2
lL2b(1)
r,t−j+ 4η2
lρLL2b(2)
r,t−j/parenrightbig/parenrightbigg
≤t/summationdisplay
j=03(b(1)
r,j+b(2)
r,j) +t/summationdisplay
j=03η2
l/parenleftbig
16IL2b(1)
r,j+ 4ρLL2b(2)
r,j/parenrightbig/parenleftbigg
min/braceleftbigg1
λ2−λ1,I/bracerightbigg/parenrightbigg
≤t/summationdisplay
j=03(b(1)
r,j+b(2)
r,j) +t/summationdisplay
j=03η2
l/parenleftbig
16IL2b(1)
r,j+ 4H2
I,ρρ2
maxL2b(2)
r,j/parenrightbig
≤t/summationdisplay
j=03(b(1)
r,j+b(2)
r,j) +t/summationdisplay
j=0HI,ρ
16I(4I−1)·/parenleftbig
48Ib(1)
r,j+ 12HI,ρρ2
maxb(2)
r,j/parenrightbig
≤t/summationdisplay
j=04(b(1)
r,j+b(2)
r,j) +t/summationdisplay
j=0H2
I,ρ
I2·ρ2
maxb(2)
r,j. (64)
37Published in Transactions on Machine Learning Research (08/2024)
Then by the definition of b(1)andb(2), we have
t/summationdisplay
j=0(1,1)GjBr,t−j
≤t/summationdisplay
j=04/parenleftbigg
(4ρLη2
l+ 16Iη2
l)(α2E[∥∇f(xr)∥2] +σ2
c) + 4ρLη2
l¯σ2
l+η2
lσ2ρ2
max+η2
lσ2
n+ 16m(n−m)
n(n−1)Iη2
l¯σ2
l/parenrightbigg
+t/summationdisplay
j=0H2
I,ρ
I2·ρ2
max/parenleftbigg
16Iη2
l(α2E[∥∇f(xr)∥2] +σ2
c) +η2
lσ2
n+ 16m(n−m)
n(n−1)Iη2
l¯σ2
l/parenrightbigg
= (t+ 1)/bracketleftbigg/parenleftbigg
4(4ρLη2
l+ 16Iη2
l) +H2
I,ρ
I2·ρ2
max16Iη2
l/parenrightbigg
(α2E[∥∇f(xr)∥2] +σ2
c) + 16ρLη2
l¯σ2
l
+ 16η2
lσ2ρ2
max+/parenleftbigg
4η2
l+H2
I,ρ
I2·ρ2
maxη2
l/parenrightbigg/parenleftbiggσ2
n+ 16m(n−m)
n(n−1)I¯σ2
l/parenrightbigg/bracketrightbigg
≤(t+ 1)/bracketleftbigg/parenleftbigg
16ρ2
maxHI,ρη2
l+ 64Iη2
l+ 16η2
lHI,ρ·ρ2
max/parenrightbigg
(α2E[∥∇f(xr)∥2] +σ2
c) + 16ρ2
maxHI,ρη2
l¯σ2
l
+ 16η2
lσ2ρ2
max+/parenleftbigg
4η2
l+H2
I,ρ
I2·ρ2
maxη2
l/parenrightbigg/parenleftbiggσ2
n+ 16m(n−m)
n(n−1)I¯σ2
l/parenrightbigg/bracketrightbigg
≤(t+ 1)C1η2
l(I+ρ2
maxHI,ρ)(α2E[∥∇f(xr)∥2] +σ2
c) + (t+ 1)C1ρ2
maxHI,ρη2
l¯σ2
l
+ (t+ 1)C1η2
lσ2ρ2
max+ (t+ 1)C1/parenleftbigg
1 +H2
I,ρ
I2·ρ2
max/parenrightbigg
η2
l/parenleftbiggσ2
n+m(n−m)
n(n−1)I¯σ2
l/parenrightbigg
, (65)
whereC1is some universal constant. The inequality holds by ρL=ρ2
maxHI,ρandHI,ρ≤I.
Case 2: In this case we have ρmax>1−1
I, which means HI,ρ=I. Letζk= (4I−1), thus we have
max
k∈[K]ρ2
k(1 +ζ−1
k) =ρ2
max(1 + (4I−1)−1), ρL= 4Iρ2
maxHI,ρ. (66)
The upper bound for λ2has the form of
λ2≤max/braceleftbigg
max
k∈[K]ρ2
k(1 +ζ−1
k) +η2
lρL·8L2,CI/bracerightbigg
≤max/braceleftbigg
ρ2
max(1 + (4I−1)−1) +2ρ2
max
4I−1,1 +3
2(4I−1)/bracerightbigg
≤1 +3
4I−1. (67)
By the fact of min/braceleftbig1
λ2−λ1,l/bracerightbig
≤I=HI,ρ, we have
t/summationdisplay
j=0(1,1)GjBr,t−j≤t/summationdisplay
j=0λj
2(b(1)
r,t−j+b(2)
r,t−j) +t/summationdisplay
j=0/parenleftbigg
λj
2min/braceleftbigg1
λ2−λ1,l/bracerightbigg
η2
l·4ρLL2b2
r,t−j/parenrightbigg
≤t/summationdisplay
j=03(b(1)
r,j+b(2)
r,j) +t/summationdisplay
j=0η2
l·16ρmaxHI,ρL2b(2)
l·3HI,ρ
≤t/summationdisplay
j=03(b(1)
r,j+b(2)
r,j) +t/summationdisplay
j=016ρmaxHI,ρb(2)
l·3
16HI,ρ
I2
=t/summationdisplay
j=03(b(1)
r,j+b(2)
r,j) +t/summationdisplay
j=03ρmaxb(2)
l·H2
I,ρ
I2, (68)
where the above inequalities hold by the fact that ρL= 4Iρ2
max= 4HI,ρρ2
maxand the constraint on step size
ηl. Thus we can get a similar upper bound as Eq. 65 in Case 1. This concludes the proof.
38Published in Transactions on Machine Learning Research (08/2024)
Lemma F.4. With the similar condition in Lemma F.3, we have the corresponding bound for the intra-
cluster consensus error ∥Xk,⊥
r,t∥2
F,
1
NK/summationdisplay
k=1E[∥Xk,⊥
r,t∥2]≤(t+ 1)C1η2
lHI,ρρ2
max(α2E[∥∇f(xr)∥2] +σ2
c) + (t+ 1)C1η2
lHI,ρρ2
max¯σ2
l
+ (t+ 1)C1η2
lρ2
maxσ2+ (t+ 1)C1H2
I,ρ
I2η2
lρ2
maxσ2
n+ (t+ 1)C1m(n−m)
n(n−1)H2
I,ρ
Iη2
lρ2
max¯σ2
l.
(69)
Proof.With the same definition of the auxiliary vector Mr,tand the matrix GandBr,tin the proof of
Lemma F.3, there is
Mr,t=/parenleftbigg1
NK/summationdisplay
k=1E[∥Xk,⊥
r,t∥2],1
KK/summationdisplay
k=1E[∥¯xk
r,t−xr∥2]/parenrightbigg⊤
,
Mr,t=Gt+1Mr,0+t/summationdisplay
j=0GjBr,t−j=t/summationdisplay
j=0GjBr,t−j, (70)
hence we have
1
NK/summationdisplay
k=1E[∥Xk,⊥
r,t∥2] = (1,0)·Mr,t= (1,0)·t/summationdisplay
j=0GjBr,t−j
=t/summationdisplay
j=0/bracketleftbigg
λj
1b(1)
r,j+λj
2−λj
1
λ2−λ14η2
lρLL2b(2)
r,j/bracketrightbigg
≤t/summationdisplay
j=0/bracketleftbigg
λj
2b(1)
r,j+λj
2−λj
1
λ2−λ14η2
lρLL2b(2)
r,j/bracketrightbigg
≤t/summationdisplay
j=0/bracketleftbigg
λj
2b(1)
r,j+λj
2−λj
1
λ2−λ14η2
lρLL2b(2)
r,j/bracketrightbigg
, (71)
with the similar proof techniques as in Lemma F.3, there is
1
NK/summationdisplay
k=1E[∥Xk,⊥
r,t∥2]≤t/summationdisplay
j=0/bracketleftbigg
3b(1)
r,j+1
I2H2
I,ρρ2
maxb(2)
r,j/bracketrightbigg
≤t/summationdisplay
j=0/bracketleftbigg
12ρLη2
l(α2E[∥∇f(xr)∥2] +σ2
c) + 12ρLη2
l¯σ2
l+ 3η2
lσ2ρ2
max
+H2
I,ρ
I2ρ2
max/parenleftbigg
16Iη2
l(α2E[∥∇f(xr)∥2] +σ2
c) + 16m(n−m)
n(n−1)Iη2
l¯σ2
l+η2
lσ2
n/parenrightbigg/bracketrightbigg
≤(t+ 1)C1η2
lHI,ρρ2
max(α2E[∥∇f(xr)∥2] +σ2
c) + (t+ 1)C1η2
lHI,ρρ2
max¯σ2
l
+ (t+ 1)C1η2
lρ2
maxσ2+ (t+ 1)C1η2
lH2
I,ρ
I2ρ2
maxσ2
n+ (t+ 1)C1m(n−m)
n(n−1)η2
lH2
I,ρ
Iρ2
max¯σ2
l.
(72)
This concludes the proof.
F.3 Lemmas for model difference ∆r
There is a corresponding Lemma about model difference ∆rfor the partial participation settings.
39Published in Transactions on Machine Learning Research (08/2024)
Lemma F.5. The global model difference ∆r=/summationtextK
k=1/summationtext
i∈cSr∆i
rin partial participation settings satisfies
E[∥∆r∥2]
≤2η2
lI
Nσ2+ 2η2
l(I−1)I−1/summationdisplay
t=0E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
NN/summationdisplay
i=1∇fi(xi
r,t)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
+ 4η2
lE/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
KK/summationdisplay
k=1∇¯fk(¯xk
r,I−1)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
+ 8/parenleftbiggn−m
m(n−1)+η2
lL2/parenrightbigg/parenleftbigg1
NK/summationdisplay
k=1E[∥Xk,⊥
r,I−1∥2]/parenrightbigg
+2η2
lσ2
N/parenleftbiggn−m
m·ρ2
max/parenrightbigg
. (73)
Proof.Recall the definition of ¯xr,t, there is ¯xr,t=1
N/summationtextN
i=1xi
r,t(here we don’t need to consider of client
sampling) and the intra-cluster average ¯xk
r,t+1=¯xk
r,t−ηl¯xk
r,t+1, where ¯xk
r,t+1=1
n/summationtext
i∈Vkgi
r,t.
For the model difference ∆r, we have
E[∥∆r∥2] =E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
KK/summationdisplay
k=11
m/summationdisplay
i∈Skrxi
r,I−xr/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
=E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
KK/summationdisplay
k=11
m/summationdisplay
i∈Skrxi
r,I∓¯xr,I∓¯xr,I−1∓···∓ ¯xr,1−xr/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
≤2E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
NpK/summationdisplay
k=1/summationdisplay
i∈Skrxi
r,I−¯xr,I/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
+ 2E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble¯xr,I∓¯xr,I−1∓···∓ ¯xr,1−xr/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
,(74)
where the inequality holds by Cauchy-Schwarz inequality. For the first term in Eq. 74, by the probability of
the sampling strategy (see details in Lemma F.6), we have
E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
NpK/summationdisplay
k=1/summationdisplay
i∈Skrxi
r,I−¯xr,I/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
=1
(Np)2E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddoubleK/summationdisplay
k=1/summationdisplay
i∈Skrxi
r,I−¯xr,I/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
≤1
(Np)2E/bracketleftbiggm(m−1)
n(n−1)/vextenddouble/vextenddouble/vextenddouble/vextenddoubleK/summationdisplay
k=1/summationdisplay
i∈Vkxi
r,I−¯xr,I/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
+Km(n−m)
n(n−1)K/summationdisplay
k=1/summationdisplay
i∈Vk∥xi
r,I−¯xr,I∥2/bracketrightbigg
=K
(Np)2m(n−m)
n(n−1)K/summationdisplay
k=1/summationdisplay
i∈VkE[∥xi
r,I−¯xr,I∥2]. (75)
40Published in Transactions on Machine Learning Research (08/2024)
For the second part in Eq. 74, we have
E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble¯xr,I±···± ¯xr,1−xr/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
=E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddoubleηlI−1/summationdisplay
t=0¯gr,t/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
=E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddoubleηl
NI−1/summationdisplay
t=0K/summationdisplay
k=1/summationdisplay
i∈Skrgi
r,t/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
=E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddoubleηl
NI−1/summationdisplay
t=0K/summationdisplay
k=1/summationdisplay
i∈Skr(gi
r,t±∇fi(xi
r,t))/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
=E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddoubleηl
NI−1/summationdisplay
t=0K/summationdisplay
k=1/summationdisplay
i∈Skr(gi
r,t−∇fi(xi
r,t))/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
+E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddoubleηl
NI−1/summationdisplay
t=0K/summationdisplay
k=1/summationdisplay
i∈Skr∇fi(xi
r,t)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
≤η2
l(I−1)M
N2σ2+E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddoubleηl
NI−1/summationdisplay
t=0K/summationdisplay
k=1/summationdisplay
i∈Skr∇fi(xi
r,t)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
, (76)
where
E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddoubleηl
NI−1/summationdisplay
t=0K/summationdisplay
k=1/summationdisplay
i∈Skr∇fi(xi
r,t)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
=E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddoubleI−1/summationdisplay
t=0/parenleftbiggηl
NK/summationdisplay
k=1/summationdisplay
i∈Skr∇fi(xi
r,t)∓ηl
NK/summationdisplay
k=1/summationdisplay
i∈Skr∇fi(¯xk
r,t)∓ηlM
N2N/summationdisplay
i=1∇fi(¯xk
r,t)/parenrightbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
≤2E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddoubleI−1/summationdisplay
t=0/parenleftbiggηl
NK/summationdisplay
k=1/summationdisplay
i∈Skr∇fi(¯xk
r,t)−ηlM
N2N/summationdisplay
i=1∇fi(¯xk
r,t)/parenrightbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
+ 4E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddoubleI−1/summationdisplay
t=0ηlm
NK/summationdisplay
k=1∇¯fk(¯xk
r,t)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
+ 4E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddoubleI−1/summationdisplay
t=0/parenleftbiggηl
NK/summationdisplay
k=1/summationdisplay
i∈Skr[∇fi(xi
r,t)−∇fi(¯xk
r,t)]/parenrightbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
≤2I−1/summationdisplay
t=0E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddoubleηl
NK/summationdisplay
k=1/summationdisplay
i∈Skr∇fi(¯xk
r,t)−ηlM
N2N/summationdisplay
i=1∇fi(¯xk
r,t)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
+ 4(I−1)I−1/summationdisplay
t=0E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddoubleηlm
NK/summationdisplay
k=1∇¯fk(¯xk
r,t)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
+ 4(I−1)I−1/summationdisplay
t=0L2η2
lM
N2K/summationdisplay
k=1/summationdisplay
i∈SkrE[∥xi
r,t−¯xk
r,t∥2],(77)
41Published in Transactions on Machine Learning Research (08/2024)
therefore,
E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddoubleηl
NI−1/summationdisplay
t=0K/summationdisplay
k=1/summationdisplay
i∈Skr∇fi(xi
r,t)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
≤4I−1/summationdisplay
t=0E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddoubleηl
NK/summationdisplay
k=1/summationdisplay
i∈Skr∇fi(¯xk
r,t)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
+ 4I−1/summationdisplay
t=0E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddoubleηlM
N2N/summationdisplay
i=1∇fi(¯xk
r,t)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
+ 4(I−1)I−1/summationdisplay
t=0E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddoubleηlm
NK/summationdisplay
k=1∇¯fk(¯xk
r,t)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
+ 4(I−1)L2η2
lM
N2I−1/summationdisplay
t=0K/summationdisplay
k=1/summationdisplay
i∈SkrE[∥xi
r,t−¯xk
r,t∥2]
= 4I−1/summationdisplay
t=0E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddoubleηl
NK/summationdisplay
k=1/summationdisplay
i∈Skr∇fi(¯xk
r,t)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
+ 4II−1/summationdisplay
t=0E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddoubleηlM
N2N/summationdisplay
i=1∇fi(¯xk
r,t)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
+ 4(I−1)L2η2
lM
N2I−1/summationdisplay
t=0K/summationdisplay
k=1/summationdisplay
i∈SkrE[∥xi
r,t−¯xk
r,t∥2]
≤8I−1/summationdisplay
t=0E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddoubleηl
NK/summationdisplay
k=1/summationdisplay
i∈Skr∇fi(xi
r,t)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
+ 4II−1/summationdisplay
t=0E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddoubleηlM
N2N/summationdisplay
i=1∇fi(¯xk
r,t)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
+ 4(I+ 1)L2η2
lM
N2I−1/summationdisplay
t=0K/summationdisplay
k=1/summationdisplay
i∈SkrE[∥xi
r,t−¯xk
r,t∥2], (78)
where the last inequality follows
4I−1/summationdisplay
t=0E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddoubleηl
NK/summationdisplay
k=1/summationdisplay
i∈Skr∇fi(¯xk
r,t)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
= 4I−1/summationdisplay
t=0E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddoubleηl
NK/summationdisplay
k=1/summationdisplay
i∈Skr[∇fi(¯xk
r,t)∓∇fi(xi
r,t)]/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
≤8I−1/summationdisplay
t=0E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddoubleηl
NK/summationdisplay
k=1/summationdisplay
i∈Skr∇fi(xi
r,t)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
+ 8I−1/summationdisplay
t=0E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddoubleηl
NK/summationdisplay
k=1/summationdisplay
i∈Skr[∇fi(¯xk
r,t)−∇fi(xi
r,t)]/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
≤8I−1/summationdisplay
t=0E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddoubleηl
NK/summationdisplay
k=1/summationdisplay
i∈Skr∇fi(xi
r,t)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
+ 8η2
lM
N2L2I−1/summationdisplay
t=0K/summationdisplay
k=1/summationdisplay
i∈SkrE[∥xi
r,t−¯xk
r,t∥2], (79)
and we use the characteristic of conditional expectation, where we use the characteristic of conditional
expectation, i.e., E[ESs[ηl
N/summationtextK
k=1/summationtext
i∈Skr∇fi(¯xk
r,t)]] =E[ηlM
N2/summationtextK
k=1/summationtext
i∈Vk∇fi(¯xk
r,t)], Update the expectation
term, that is E[ESs[ηl
N/summationtextK
k=1/summationtext
i∈Skr∇fi(¯xk
r,t)−ηlM
N2/summationtextN
i=1∇fi(¯xk
r,t)]] = 0and∀r̸=s,i∈Sk
ris independent
42Published in Transactions on Machine Learning Research (08/2024)
withi∈Sk
r. Then we have
8I−1/summationdisplay
t=0E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddoubleηl
NK/summationdisplay
k=1/summationdisplay
i∈Skr∇fi(xi
r,t)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
=8η2
l
N2I−1/summationdisplay
t=0E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddoubleK/summationdisplay
k=1/summationdisplay
i∈VkP{i∈Sk
r}∇fi(xi
r,t)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
≤8η2
lK
N2m(n−m)
n(n−1)I−1/summationdisplay
t=0K/summationdisplay
k=1/summationdisplay
i∈VkE[∥∇fi(xi
r,t)∥2]
+8η2
l
N2m(m−1)
n(n−1)I−1/summationdisplay
t=0E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddoubleK/summationdisplay
k=1/summationdisplay
i∈Vk∇fi(xi
r,t)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
=8η2
lK
N2m(n−m)
n(n−1)I−1/summationdisplay
t=0N/summationdisplay
i=1E[∥∇fi(xi
r,t)∥2] +8η2
l
N2m(m−1)
n(n−1)I−1/summationdisplay
t=0E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddoubleN/summationdisplay
i=1∇fi(xi
r,t)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
,(80)
where the inequality holds by Lemma F.6.
I−1/summationdisplay
t=0N/summationdisplay
i=1E[∥∇fi(xi
r,t)∥2]
=I−1/summationdisplay
t=0N/summationdisplay
i=1E[∥∇fi(xi
r,t)∓∇fi(¯xk
r,t)∓¯fk(¯xk
r,t)∓¯fk(xr)∥2]
≤I−1/summationdisplay
t=0K/summationdisplay
k=1E[4L2∥Xk,⊥
r,t∥2+ 4L2n∥¯xk
r,t−xr∥2+ 4n∥∇¯fk(xr)∥2+ 4nσ2
k]
≤I−1/summationdisplay
t=0K/summationdisplay
k=1/bracketleftbig
4L2E[∥Xk,⊥
r,t∥2] + 4L2nE[∥¯xk
r,t−xr∥2] + 4nα2E[∥∇f(xr)∥2] + 4nσ2
k+ 4nσ2
c/bracketrightbig
.(81)
43Published in Transactions on Machine Learning Research (08/2024)
Then combining the previous terms, we have
E[∥∆r∥2]
≤2E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
NpK/summationdisplay
k=1/summationdisplay
i∈Skrxi
r,I−¯xr,I/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
+ 2E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble¯xr,I∓¯xr,I−1∓···∓ ¯xr,1−xr/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
≤2K
(Np)2m(n−m)
n(n−1)K/summationdisplay
k=1/summationdisplay
i∈VkE[∥xi
r,I−¯xk
r,I∥2] +2η2
lIM
N2σ2
+ 2E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddoubleηl
NI−1/summationdisplay
t=0K/summationdisplay
k=1/summationdisplay
i∈Skr∇fi(xi
r,t)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
≤2K
(Np)2m(n−m)
n(n−1)K/summationdisplay
k=1/summationdisplay
i∈VkE[∥xi
r,I−¯xk
r,I∥2] +2η2
lIM
N2σ2
+ 16I−1/summationdisplay
t=0E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddoubleηl
NK/summationdisplay
k=1/summationdisplay
i∈Skr∇fi(xi
r,t)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
+ 8II−1/summationdisplay
t=0E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddoubleηlm
NK/summationdisplay
k=1∇¯fk(¯xk
r,t)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
+ 8(I+ 1)η2
lML2
N2I−1/summationdisplay
t=0K/summationdisplay
k=1/summationdisplay
i∈SrE[∥xi
r,t−¯xk
r,t∥2]
≤2K
(Np)2m(n−m)
n(n−1)K/summationdisplay
k=1/summationdisplay
i∈VkE[∥xi
r,I−¯xk
r,I∥2] +2η2
lIM
N2σ2
+16η2
lK
N2m(n−m)
n(n−1)I−1/summationdisplay
t=0N/summationdisplay
i=1E[∥∇fi(xi
r,t)∥2] +16η2
l
N2m(m−1)
n(n−1)I−1/summationdisplay
t=0E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddoubleN/summationdisplay
i=1∇fi(xi
r,t)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
+ 8II−1/summationdisplay
t=0E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddoubleηlm
NK/summationdisplay
k=1∇¯fk(¯xk
r,t)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
+ 8(I+ 1)η2
lML2
N2I−1/summationdisplay
t=0K/summationdisplay
k=1/summationdisplay
i∈SrE[∥xi
r,t−¯xk
r,t∥2]
≤2K
(Np)2m(n−m)
n(n−1)K/summationdisplay
k=1E[∥Xk,⊥
r,I∥2] +2η2
lIM
N2σ2
+16η2
lK
N2m(n−m)
n(n−1)I−1/summationdisplay
t=0K/summationdisplay
k=1/bracketleftbigg
4L2E[∥Xk,⊥
r,t∥2] + 4L2nE[∥¯xk
r,t−xr∥2]
+ 4nα2E[∥∇f(xr)∥2] + 4nσ2
k+ 4nσ2
c/bracketrightbigg
+16η2
l
N2m(m−1)
n(n−1)I−1/summationdisplay
t=0E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddoubleN/summationdisplay
i=1∇fi(xi
r,t)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
+ 8II−1/summationdisplay
t=0E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddoubleηlm
NK/summationdisplay
k=1∇¯fk(¯xk
r,t)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
+ 8(I+ 1)η2
lML2
N2I−1/summationdisplay
t=0K/summationdisplay
k=1/summationdisplay
i∈SrE[∥xi
r,t−¯xk
r,t∥2], (82)
44Published in Transactions on Machine Learning Research (08/2024)
where we have
16η2
lK
N2m(n−m)
n(n−1)I−1/summationdisplay
t=0K/summationdisplay
k=1/bracketleftbigg
4L2E[∥Xk,⊥
r,t∥2] + 4L2nE[∥¯xk
r,t−xr∥2]/bracketrightbigg
=16η2
lK
N2m(n−m)
n(n−1)I−1/summationdisplay
t=0K/summationdisplay
k=1/bracketleftbigg
4L2E[∥Xk,⊥
r,t∥2] + 4L2nE[∥¯xk
r,t−xr∥2]/bracketrightbigg
=64η2
lL2
Nm(n−m)
n2(n−1)I−1/summationdisplay
t=0K/summationdisplay
k=1E[∥Xk,⊥
r,t∥2] +64η2
lL2
Km(n−m)
n2(n−1)I−1/summationdisplay
t=0K/summationdisplay
k=1E[∥¯xk
r,t−xr∥2]
= 64η2
lL2m(n−m)
n2(n−1)I−1/summationdisplay
t=0/bracketleftbigg1
NK/summationdisplay
k=1E[∥Xk,⊥
r,t∥2] +1
KK/summationdisplay
k=1E[∥¯xk
r,t−xr∥2]/bracketrightbigg
≤64η2
lL2m(n−m)
n2(n−1)/bracketleftbigg
I2C1η2
l(I+ρ2
maxHI,ρ)(α2E[∥∇f(xr)∥2+σ2
c) +I2C1ρ2
maxHI,ρη2
l¯σ2
l
+I2C1η2
lσ2ρ2
max+I2C1/parenleftbigg
1 +H2
I,ρ
I2·ρ2
max/parenrightbigg
η2
l/parenleftbiggσ2
n+m(n−m)
n(n−1)I¯σ2
l/parenrightbigg/bracketrightbigg
, (83)
we have
2K
(Np)2m(n−m)
n(n−1)K/summationdisplay
k=1E[∥Xk,⊥
r,I∥2]
=2
Kn(n−m)
m(n−1)K/summationdisplay
k=1E[∥Xk,⊥
r,I∥2]
≤2(n−m)
m(n−1)/bracketleftbigg
IC1η2
lHI,ρρ2
max(α2E[∥∇f(xr)]∥2+σ2
c) +IC1η2
lHI,ρρ2
max¯σ2
l
+IC1η2
lρ2
maxσ2+IC1η2
lH2
I,ρ
I2·ρ2
max/parenleftbiggσ2
n+m(n−m)
n(n−1)I¯σ2
l/parenrightbigg/bracketrightbigg
, (84)
and
8(I+ 1)η2
lML2
N2I−1/summationdisplay
t=0K/summationdisplay
k=1/summationdisplay
i∈SrE[∥xi
r,t−¯xk
r,t∥2]
≤8(I+ 1)η2
lML2
N2I−1/summationdisplay
t=0K/summationdisplay
k=1/summationdisplay
i∈VkE[∥xi
r,t−¯xk
r,t∥2]
= 8(I+ 1)η2
lmL2
nI−1/summationdisplay
t=01
NK/summationdisplay
k=1E[∥Xk,⊥
r,t∥2]
= 8(I+ 1)η2
lmL2
nI−1/summationdisplay
t=0/bracketleftbigg
(t+ 1)C1η2
lHI,ρρ2
max(α2E[∥∇f(xr)]∥2+σ2
c) + (t+ 1)C1η2
lHI,ρρ2
max¯σ2
l
+ (t+ 1)C1η2
lρ2
maxσ2+ (t+ 1)C1η2
lH2
I,ρ
I2·ρ2
maxσ2
n/bracketrightbigg
= 4(I+ 1)2η2
lmL2
n/bracketleftbigg
IC1η2
lHI,ρρ2
max(α2E[∥∇f(xr)]∥2+σ2
c) +IC1η2
lHI,ρρ2
max¯σ2
l
+IC1η2
lρ2
maxσ2+IC1η2
lH2
I,ρ
I2·ρ2
max/parenleftbiggσ2
n+m(n−m)
n(n−1)I¯σ2
l/parenrightbigg/bracketrightbigg
. (85)
45Published in Transactions on Machine Learning Research (08/2024)
Then by merging pieces together, we have
E[∥∆r∥2]
≤2η2
lIM
N2σ2+/parenleftbigg2(n−m)
m(n−1)+4(I+ 1)2η2
lmL2
n/parenrightbigg/bracketleftbigg
IC1η2
lHI,ρρ2
max(α2E[∥∇f(xr)]∥2+σ2
c) +IC1η2
lHI,ρρ2
max¯σ2
l
+IC1η2
lρ2
maxσ2+IC1η2
lH2
I,ρ
I2ρ2
max/parenleftbiggσ2
n+m(n−m)
n(n−1)I¯σ2
l/parenrightbigg/bracketrightbigg
+ 64η2
lL2m(n−m)
n2(n−1)/bracketleftbigg
I2C1η2
l(I+ρ2
maxHI,ρ)(α2E[∥∇f(xr)∥2+σ2
c)
+I2C1ρ2
maxHI,ρη2
l¯σ2
l+I2C1η2
lσ2ρ2
max+I2C1η2
l/parenleftbigg
1 +H2
I,ρ
I2·ρ2
max/parenrightbigg/parenleftbiggσ2
n+m(n−m)
n(n−1)I¯σ2
l/parenrightbigg/bracketrightbigg
+16η2
lK
N2m(n−m)
n(n−1)I−1/summationdisplay
t=0K/summationdisplay
k=1[4nσ2
k+ 4nσ2
c]
+16η2
l
N2m(m−1)
n(n−1)I−1/summationdisplay
t=0E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddoubleN/summationdisplay
i=1∇fi(xi
r,t)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
+8η2
lIm2
n2I−1/summationdisplay
t=0E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
KK/summationdisplay
k=1∇¯fk(¯xk
r,t)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
≤2η2
lIM
N2σ2+64η2
lIm(n−m)
n2(n−1)[¯σ2
l+σ2
c]
+/parenleftbigg2(n−m)
m(n−1)+ 64η2
lL2m(n−m)
n2(n−1)I+4(I+ 1)2η2
lmL2
n/parenrightbigg/bracketleftbigg
IC1η2
lHI,ρρ2
max(α2E[∥∇f(xr)]∥2+σ2
c)
+IC1η2
lHI,ρρ2
max¯σ2
l+IC1η2
lρ2
maxσ2+IC1η2
lH2
I,ρ
I2ρ2
max/parenleftbiggσ2
n+m(n−m)
n(n−1)I¯σ2
l/parenrightbigg/bracketrightbigg
+ 64η2
lL2m(n−m)
n2(n−1)/bracketleftbigg
I3C1η2
l(α2E[∥∇f(xr)∥2+σ2
c) +I2C1η2
l/parenleftbiggσ2
n+m(n−m)
n(n−1)I¯σ2
l/parenrightbigg/bracketrightbigg
+16η2
lm(m−1)
n(n−1)I−1/summationdisplay
t=0E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
NN/summationdisplay
i=1∇fi(xi
r,t)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
+8η2
lIm2
n2I−1/summationdisplay
t=0E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
KK/summationdisplay
k=1∇¯fk(¯xk
r,t)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
. (86)
Thus it concludes the proof.
F.4 Additional Supporting Lemmas
Lemma F.6 (Cluster sampling) .For model weights yk,i
r,∀k∈[K],i∈Vk,r∈[R],t∈[I], there is
E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble/summationdisplay
k∈[K]n/summationdisplay
i=1I{i∈Sk
r}yk,i
r/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
≤E/bracketleftbiggm(m−1)
n(n−1)/vextenddouble/vextenddouble/vextenddouble/vextenddoubleK/summationdisplay
k=1/summationdisplay
i∈Vkyk,i
r/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
+Km(n−m)
n(n−1)K/summationdisplay
k=1/summationdisplay
i∈Vk/vextenddouble/vextenddoubleyk,i
r/vextenddouble/vextenddouble2/bracketrightbigg
.(87)
46Published in Transactions on Machine Learning Research (08/2024)
Proof.
E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddoubleK/summationdisplay
k=1/summationdisplay
i∈VkI{i∈Sk
r}yk,i
r/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
=P{i∈Sk
r}E/bracketleftbiggK/summationdisplay
k=1/summationdisplay
i∈Vk/vextenddouble/vextenddoubleyk,i
r/vextenddouble/vextenddouble2/bracketrightbigg
+P{i̸=j∈Sk
r}E/bracketleftbiggK/summationdisplay
k=1/summationdisplay
i̸=j∈Vk/parenleftbig
yk,i
r/parenrightbig′/parenleftbig
yk,j
r/parenrightbig/bracketrightbigg
+P{i∈Sk
r,j∈St
l|k̸=l∈[K]}E/bracketleftbigg/summationdisplay
k̸=l/summationdisplay
i∈Vk/summationdisplay
j∈Vl/parenleftbig
yi,k
r/parenrightbig′/parenleftbig
yj,l
r/parenrightbig/bracketrightbigg
=E/bracketleftbiggm
nK/summationdisplay
k=1/summationdisplay
i∈Vk/vextenddouble/vextenddoubleyk,i
r/vextenddouble/vextenddouble2+m(m−1)
n(n−1)K/summationdisplay
k=1/summationdisplay
i̸=j∈Vk/parenleftbig
yk,i
r/parenrightbig′/parenleftbig
yk,j
r/parenrightbig
+m2
n2/summationdisplay
k̸=l/summationdisplay
i∈Vk/summationdisplay
j∈Vl/parenleftbig
yi,k
r/parenrightbig′/parenleftbig
yj,l
r/parenrightbig/bracketrightbigg
=E/bracketleftbiggm(m−1)
n(n−1)/vextenddouble/vextenddouble/vextenddouble/vextenddoubleK/summationdisplay
k=1/summationdisplay
i∈Vkyk,i
r/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
+m(n−m)
n(n−1)K/summationdisplay
k=1/summationdisplay
i∈Vk/vextenddouble/vextenddoubleyk,i
r/vextenddouble/vextenddouble2
+m(n−m)
n2(n−1)/summationdisplay
k̸=l/summationdisplay
i∈Vk/summationdisplay
j∈Vl/parenleftbig
yi,k
r/parenrightbig′/parenleftbig
yj,l
r/parenrightbig/bracketrightbigg
≤E/bracketleftbiggm(m−1)
n(n−1)/vextenddouble/vextenddouble/vextenddouble/vextenddoubleK/summationdisplay
k=1/summationdisplay
i∈Vkyk,i
r/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
+m(n−m)
n(n−1)K/summationdisplay
k=1/summationdisplay
i∈Vk/vextenddouble/vextenddoubleyk,i
r/vextenddouble/vextenddouble2
+m(n−m)
n2(n−1)/summationdisplay
k̸=l/summationdisplay
i∈Vk/summationdisplay
j∈Vl/parenleftbigg1
2/vextenddouble/vextenddoubleyi,k
r/vextenddouble/vextenddouble2+1
2/vextenddouble/vextenddoubleyj,l
r/vextenddouble/vextenddouble2/parenrightbigg/bracketrightbigg
, (88)
where the third equation holds by the probability of random sampling with replacement, i.e., P{i∈Sk
r}=
m
n,P{i̸=j∈Sk
r}=m(m−1)
n(n−1),P{i∈Sk
r,j∈St
l|k̸=l∈[K]}=m2
n2. The forth equation holds by ⟨a,b⟩=
1
2[∥a∥2+∥b∥2−∥a−b∥2],1
2/summationtext
i̸=j∥ai−aj∥2=/summationtextn
i=1n∥ai∥2−∥/summationtextn
i=1ai∥2, and∥/summationtextK
k=1/summationtext
i∈Vkyk,i
r∥2=/summationtextK
k=1∥/summationtext
i∈Vkyk,i
r∥2+/summationtext
k̸=l/summationtext
i∈Vk/summationtext
j∈Vl⟨yk,i
ryl,j
r⟩. The last inequality holds by a′b≤1
2∥a∥2+1
2∥b∥2.
Re-organize the last item,
m(n−m)
n2(n−1)/summationdisplay
k̸=l/summationdisplay
i∈Vk/summationdisplay
j∈Vl/parenleftbigg1
2/vextenddouble/vextenddoubleyi,k
r/vextenddouble/vextenddouble2+1
2/vextenddouble/vextenddoubleyj,l
r/vextenddouble/vextenddouble2/parenrightbigg
=m(n−m)
n2(n−1)(K−1)nK/summationdisplay
k=1/summationdisplay
i∈Vk∥yk,i
r∥2,(89)
then we have
E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble/summationdisplay
k∈[K]n/summationdisplay
i=1I{i∈Sk
r}yk,i
r/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
≤E/bracketleftbiggm(m−1)
n(n−1)/vextenddouble/vextenddouble/vextenddouble/vextenddoubleK/summationdisplay
k=1/summationdisplay
i∈Vkyk,i
r/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
+m(n−m)
n(n−1)K/summationdisplay
k=1/summationdisplay
i∈Vk/vextenddouble/vextenddoubleyk,i
r/vextenddouble/vextenddouble2
+m(n−m)
n2(n−1)(K−1)nK/summationdisplay
k=1/summationdisplay
i∈Vk/vextenddouble/vextenddoubleyi
r/vextenddouble/vextenddouble2/bracketrightbigg
=E/bracketleftbiggm(m−1)
n(n−1)/vextenddouble/vextenddouble/vextenddouble/vextenddoubleK/summationdisplay
k=1/summationdisplay
i∈Vkyk,i
r/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
+Km(n−m)
n(n−1)K/summationdisplay
k=1/summationdisplay
i∈Vk/vextenddouble/vextenddoubleyk,i
r/vextenddouble/vextenddouble2/bracketrightbigg
. (90)
This concludes the proof.
47Published in Transactions on Machine Learning Research (08/2024)
Lemma F.7 (Lemma for momentum term in the update rule) .The first order momentum terms mrin
Algorithm 1 hold the following relationship w.r.t. model difference ∆r:
R/summationdisplay
r=1E[∥mr∥2]≤R/summationdisplay
r=1E[∥∆r∥2]. (91)
Proof.By the updating rule, we have
E[∥mr∥2] =E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble(1−β1)r/summationdisplay
u=1βr−u
1∆u/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
≤(1−β1)2d/summationdisplay
i=1E/bracketleftbigg/parenleftbiggr/summationdisplay
u=1βr−u
1∆u,i/parenrightbigg2/bracketrightbigg
≤(1−β1)2d/summationdisplay
i=1E/bracketleftbigg/parenleftbiggr/summationdisplay
u=1βr−u
1/parenrightbigg/parenleftbiggr/summationdisplay
u=1βr−u
1(∆u,i)2/parenrightbigg/bracketrightbigg
≤(1−β1)r/summationdisplay
u=1βr−u
1E[∥∆u∥2], (92)
summing over t= 1,...,Tyields
R/summationdisplay
r=1E[∥mr∥2] = (1−β1)R/summationdisplay
r=1r/summationdisplay
u=1βr−u
1E[∥∆u∥2]
= (1−β1)R/summationdisplay
u=1R/summationdisplay
r=uβr−u
1E[∥∆u∥2]
≤(1−β1)R/summationdisplay
u=11
1−β1E[∥∆u∥2]
=R/summationdisplay
u=1E[∥∆u∥2]. (93)
This concludes the proof.
Lemma F.8. Under Assumptions 4.3, for AFGA and CAFGA, we have ∥∇f(x)∥≤G,∥∆r∥≤mηlIG
n,
∥mr∥≤mηlIG
n,∥vr∥≤m2η2
lI2G2
n2and∥/hatwidevr∥≤m2η2
lI2G2
n2.
Proof.SincefhasG-bounded stochastic gradients, for any xandξ, we have∥∇f(x,ξ)∥≤G, we have
∥∇f(x)∥=∥Eξ∇f(x,ξ)∥≤Eξ∥∇f(x,ξ)∥≤G.
For AFGA and CAFGA, the model difference ¯∆k
ron clusterksatisfies,
¯∆k
r=¯xk
r,I−xr=−ηlI−1/summationdisplay
t=0¯gk
r,t=−ηlI−1/summationdisplay
t=01
n/summationdisplay
i∈Vk¯gi
r,t=−ηlI−1/summationdisplay
t=01
n/summationdisplay
i∈Sk
r,tgi
r,t,
therefore,
/vextenddouble/vextenddouble¯∆k
r/vextenddouble/vextenddouble=/vextenddouble/vextenddouble/vextenddouble/vextenddoubleηlI−1/summationdisplay
t=0¯gk
r,t/vextenddouble/vextenddouble/vextenddouble/vextenddouble=/vextenddouble/vextenddouble/vextenddouble/vextenddoubleηlI−1/summationdisplay
t=01
n/summationdisplay
i∈Sk
r,tgi
r,t/vextenddouble/vextenddouble/vextenddouble/vextenddouble≤mηlIG
n,
48Published in Transactions on Machine Learning Research (08/2024)
for the global model difference ∆r,
∥∆r∥=/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
K/summationdisplay
k∈[K]¯∆k
r/vextenddouble/vextenddouble/vextenddouble/vextenddouble≤mηlIG
n.
Thus we can obtain the bound for momentum mrand variance vr,
∥mr∥=/vextenddouble/vextenddouble/vextenddouble/vextenddouble(1−β1)r/summationdisplay
s=1βr−s
1∆s/vextenddouble/vextenddouble/vextenddouble/vextenddouble≤mηlIG
n,∥vr∥=/vextenddouble/vextenddouble/vextenddouble/vextenddouble(1−β2)r/summationdisplay
s=1βr−s
2∆2
s/vextenddouble/vextenddouble/vextenddouble/vextenddouble≤m2η2
lI2G2
n2.
By the updating rule of /hatwidevr, there exists a j∈[r]such that/hatwidevr=vj. Then
∥/hatwidevr∥≤m2η2
lI2G2
n2. (94)
This concludes the proof.
Lemma F.9. For the variance difference sequence /hatwideV−1/2
r−1−/hatwideV−1/2
r, we have
R/summationdisplay
r=1/vextenddouble/vextenddouble/vextenddouble/vextenddouble/hatwideV−1/2
r−1−/hatwideV−1/2
r/vextenddouble/vextenddouble/vextenddouble/vextenddouble
1≤d√ϵ,R/summationdisplay
r=1/vextenddouble/vextenddouble/vextenddouble/vextenddouble/hatwideV−1/2
r−1−/hatwideV−1/2
r/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
≤d
ϵ(95)
Proof.The proof of Lemma F.9 is exactly the same as the proof of Lemma C.2 in (Wang et al., 2022b).
49