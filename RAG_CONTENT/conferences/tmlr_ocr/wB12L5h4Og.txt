Under review as submission to TMLR
Robust Semi-Supervised Metric Learning
Meets with High Dimensionality
Anonymous authors
Paper under double-blind review
Abstract
Classical semi-supervised metric learning usually formulates the objectives via maximiz-
ing/minimizing the ratio formed with must-links and cannot-links. However, the presence
of noise and adversarial attacks can result in incorrect pairings, which will diminish the relia-
bility of learned projection directions. To develop a robust distance metric learning method,
we propose a new objective for distance metric learning using the /lscript2,q-norm ( 0< q < 2)
distances which will alleviate the inﬂuence of outliers or adversarial attacks. We develop
an algorithm that will decrease the objective monotonically with updates. Additionally,
we address computational burdens (e.g., O(d3)complexity, where dis the size of features)
by introducing a 2D metric learning algorithm and extending it to arbitrary dimensions
with kernel methods, backed by theoretical guarantees. Extensive empirical evaluations
consistently demonstrate the superiority of our methods across various experimental setups.
1 Introduction
Most clustering/classiﬁcation algorithms rely on deﬁning a distance metric to assess the similarity between
instances (Kulis et al., 2013; Kaya & Bilge, 2019; Bellet et al., 2013; Yang & Jin, 2006). Applying an
appropriate distance metric that can capture important features from instances is critical to improving per-
formance, as illustrated in Figure 2. While some general metrics are available, they often treat all features
equally, which is inadequate as certain features hold more signiﬁcance than others. Therefore, how to learn
a distance metric that eﬃciently captures the idiosyncrasies of data with good quality has emerged as a
prevalent research focus (Cakir et al., 2019; López-Sánchez et al., 2019; Karlinsky et al., 2019). Traditional
techniques require explicit class labels and labeled data for classiﬁcation transformations (Goldberger et al.,
2004). However, obtaining precise labels in real-world scenarios is costly and time-consuming, prompting
the development of semi-supervised methods that learn distance metrics with limited supervisory informa-
tion (Hoi et al., 2006). These methods typically assume either a small portion of labeled data or pairwise
constraints between examples. Clearly, the latter type is weaker. Therefore extensive research has been done
to learn distance metrics with pairwise relevance information: must-links and cannot-links (Xiang et al.,
2008). For more comprehensive survey of various metric learning algorithms, we refer our readers to the
classical monograph (Kulis et al., 2013) and references therein.
The goal of this paper is to develop a robust distance metric incorporating pairwise relevance relationships.
Existing metric learning methods, often based on squared Frobenius norm distances, are susceptible to
outliers, features, and adversarial attacks. To address this issue, we propose a robust distance metric
learning objective using the /lscript2,q-norm, oﬀering robustness against outliers/attacks for any 0< q < 2.
In addition, existing methods typically vectorize images before optimizing the projection matrix Wvia
eigenvalue decomposition, which becomes computationally demanding for large dimensions, such as 100×100
grayscale images ( d= 10000 ). Additionally, vectorization distorts image structure, leading to reduced
recognition accuracy. Inspired by above, we propose a 2D metric learning algorithm that avoids image
vectorization, utilizing covariance matrices with dimensions r×r, wherer= min{m,n}for eachm×ninput
image. This approach oﬀers signiﬁcant computational savings compared to existing methods, as shown in
Figure 1. Besides, inspired by Kernel Principal Component Analysis (Schölkopf et al., 1997) and Kernel
Support Vector Machine (Amari & Wu, 1999), we introduce a kernel-based metric learning algorithm to
1Under review as submission to TMLR
…Vectorized input imagesCovariance matrix
pm…12np x mnp x mp x mn input imagesTraditionalmethod
method2DCovariance matrixppEigenvalueDecompositionO(𝒑𝟑𝒎𝟑)
EigenvalueDecompositionO(𝒑𝟑)pppp…+
Figure 1: Upper ﬂow denotes metric learning via traditional methods by vectorizing images, lower ﬂow is
the 2D metric learning method proposed in this paper, the covariance matrix size is signiﬁcantly reduced.
addressnon-linearityinhigher-dimensionalspacesusingkerneltrick. Thismethodensuresthattheprojection
matrix Wsatisﬁes orthonormality constraints, even when obtained implicitly or in inﬁnite dimensions. Our
algorithms do not require explicit class labels; instead, they utilize pairwise relevance relationships in a
semi-supervised manner, and they are designed for minimal computational costs and rapid convergence.
In Section 2, we will formulate the objective for metric learning and discuss its connection with Fisher’s
LDA before introducing a general framework for solving maximizing trace ratio problem. In Section 3, we
discuss a more robust formulation against noise and adversarial samples which widely exist in real world.
Section 4 depicts 2D metric learning which can be naturally extended to higher dimension and Section 5
generalizes into kernel version for metric learning. Section 6 entails convergence analysis, which concludes
our method enjoys superlinear convergence rate and experiments in Section 7 demonstrate the superiority
of our proposed methods over existing counterparts. Our main contributions are summarized as below:
•Propose a robust metric learning formulation and solve it with an eﬃcient algorithm.
•Design novel 2D metric learning along with its robust version which works fast on high dimensional
data, and propose an eﬃcient algorithm which has superlinear convergence rate.
•Discuss and solve kernel version metric learning which goes beyond the linearity assumption.
2 Related Work
2.1 Mahalanobis Distance
HeishappyShe is happyHe is very happyShe is very happyHeisangryShe is angryHe is very angryShe is very angry
Figure 2: An illustration to demonstrate the impor-
tance of metric learning. If we do K-means directly
based on the word-count matrix generated from each
sentence, then it may yield poor results. A good met-
ric learning should be able to learn diﬀerent weights
for various features. For example, if ‘happy’ and ‘an-
gry’ are assigned with signiﬁcantly diﬀerent weights,
thenK-means can work well on the learned metrics.Assume that we have a set of ndata pointsX=
{xi∈Rp}n
i=1and two sets of pairwise constraints
over the data points Xare given under certain ap-
plicationcontext(Xingetal.,2003;Liuetal.,2019)1
/braceleftBigg
S={(xi,xj)|xiandxjare in the same class };
D={(xi,xj)|xiandxjfrom diﬀerent classes },
(1)
1We note that our model can be easily extended to triplet relationship R={(xi,xj,xl)|xiis more similar to xjthan to xl}
where xi−xlandxi−xjcan be conveyed in the numerator and denominator in Eq. (3) respectively.
2Under review as submission to TMLR
where we denote Sas must-links and Das cannot-links. Note that it is not necessary for all the data points
inXto be involved in SorD.
Given any two data points xiandxj, the Mahalanobis distance between them is deﬁned as:
/bardblxi−xj/bardblM=/radicalBig
(xi−xj)TM(xi−xj), (2)
where M∈Rp×pis the Mahalanobis distance metric (Shen et al., 2010; De Maesschalck et al., 2000), a
symmetric matrix of size p×p. In general, Mis a valid metric if and only if Mis a positive semi-deﬁnite
matrix by satisfying the non-negativity and the triangle inequality conditions, i.e.,M/followsequal0. The goal of
robust metric learning is to learn an optimal square matrix Mfrom a collection of data points Xin the
presence of outliers or adversarial attacks, coupled with a set of similar pairwise constraints Sand a set of
dissimilar pairwise constraints D, such that the distances between the data point pairs in Sare as small as
possible, whilst those in Dare as large as possible.
2.2 Metric Learning
Because Mis positive semi-deﬁnite, we can reasonably write M=WWT, where W∈Rp×rwith
r≤p. Thus the Mahalanobis distance under the metric Mcan be computed as /bardblxi−xj/bardblM=/radicalBig
(xi−xj)TWWT(xi−xj) =/vextenddouble/vextenddoubleWT(xi−xj)/vextenddouble/vextenddouble
2, which deﬁnes a transformation y=WTxunder pro-
jection matrix W. Our intuition is data points from diﬀerent classes after projection are far away while from
same class should be close, therefore we can formulate the objective as:
max
WTW=I/summationtext
(xi,xj)∈D/vextenddouble/vextenddoubleWT(xi−xj)/vextenddouble/vextenddouble2
2
/summationtext
(xi,xj)∈S/bardblWT(xi−xj)/bardbl2
2=d/summationtext
i=1/vextenddouble/vextenddoubleWTbi/vextenddouble/vextenddouble2
2
s/summationtext
i=1/bardblWTai/bardbl2
2=/vextenddouble/vextenddoubleWTB/vextenddouble/vextenddouble2
F
/bardblWTA/bardbl2
F=tr/parenleftbig
WTSbW/parenrightbig
tr(WTSwW), (3)
where A= [a1,a2,...,as]∈Rp×ssuch that each column of A: (xi−xj)satisﬁes (xi,xj)∈
S, and similarly B= [b1,b2,...,bd]∈Rp×dsuch that each column of B: (xi−xj)satisﬁes
(xi,xj)∈ D.Sw=/summationtext
(xi,xj)∈S(xi−xj) (xi−xj)Tis the covariance matrix of must-links and Sb=
/summationtext
(xi,xj)∈D(xi−xj) (xi−xj)Tdenotes covariance of cannot-links. For the sake of brevity, we denote |S|=s
and|D|=d. In the above objective, the numerator term measures the scatteredness of diﬀerent classes, while
the denominator term denotes the compactness of the same class. Orthogonality constraint is to prevent
degenerate solution(Xiang et al., 2008).
2.3 Connection with Fisher’s Linear Discriminant Analysis
It is easy to notice that the above equation has the same objective as Fisher’s Linear Discriminant Analysis
wheretheonlydiﬀerenceistheexistenceoforthonormalityconstrainton Winourformulation. Byobserving
the independence of each column of W, we can reformulate Eq. (3) as :
max
wi/summationdisplay
i=1wT
iSbwi, s.t.wT
iSwwi= 1,∀i∈[r]. (4)
By making use of Lagrangian Multipliers, we obtain Sbwi=λiSwwiandmax
wi/summationtext
i=1wT
iSbwi= max/summationtext
i=1λi.
If we assume Swis invertible and the projection is along diﬀerent directions, then to obtain optimal W,
it is equivalent to solve S−1
wSbwi=λiwiand ﬁnd the top reigenvalues of S−1
wSband the corresponding
eigenvectors. However, the main drawback of Fisher’s LDA is as S−1
wSbis not necessarily symmetric, each
column of optimal Wis generally non-orthogonal to each other, which means the new coordinate system
formed by W, has non-orthogonal axes. The reason to prefer orthogonal coordinates instead of general
curvilinear coordinates is simplicity: many complications arise when coordinates are not orthogonal. Our
experiments in Figure 4 demonstrate that the orthonormal constraint is nontrivial as it can not only obtain
better objective, but also the classiﬁcation accuracy is higher as it can avoid ill-conditioned coordinate base.
We refer our readers to Daubechies (1993); Ninness et al. (1999) and references therein.
3Under review as submission to TMLR
w1w2xw1w2w3WTx
(a) Projection as WTx.
w1w2w3w1w2w3 (b) Non-orthogoanl Axes.
w1w2w3w1w2w3 (c) Orthogonal Axes.
Figure 3: When/bardblwi/bardbl2= 1,WTxis the projection in new axes system formed by columns of W. Speciﬁcally,
wT
ixdetermines the position in i-th axis. In Fisher’s LDA formulation, each wiis not orthogonal to others.
In contrast, the orthonormality constraint ensures the new coordinate follows Cartesian system.
Algorithm 1 The algorithm to solve the problem (5).
Initialization: v∈C
repeat
Calculateλ=f(v)
g(v)
Updatevby solving the following problem:
v= arg max
v∈Cf(v)−λg(v) (6)
untilconvergence
2.4 An Optimization Framework
The objective formulation above is inherently nonconvex due to the nonconvex nature of orthogonality
constraint imposed on W. In response to this challenge, we propose to address the problem eﬀectively with
an iterative algorithm. We ﬁrst introduce a framework for maximization problem (Wang et al., 2014):
max
v∈Cf(v)
g(v),whereg(v)>0 (∀v∈C). (5)
The optimization procedure is described in Algorithm 1. The set Cin our metric learning problem is Stiefel
manifoldSt(p,r)deﬁned as{W:W∈Rp×r,WTW=Ir}. Several theorems are now in order.
Theorem 2.1. By updating as Algorithm 1, the objective in (5) is monotonically non-decreasing.
Proof.By deﬁnition v+= arg max v∈Cf(v)−λg(v), we have: f(v+)−λg(v+)≥f(v)−λg(v) = 0. Since
g(v)≥0, thereforef(v+)−λg(v+)≥0 =⇒λ+=f(v+)
g(v+)≥f(v)
g(v)=λ.
Theorem 2.2. If the updated vin Algorithm 1 is a stationary point of problem (6), the converged solution
in Algorithm 1 is a stationary point of problem (5).
Proof.Suppose the converged solution in Algorithm 1 is v∗. Ifv∗is a stationary point of problem (6),
f/prime(v∗)−f(v∗)
g(v∗)g/prime(v∗) = 0⇒f/prime(v∗)g(v∗) =f(v∗)g/prime(v∗). (7)
On the other hand, if v∗is a critical point of problem (5), then
(f(v)
g(v))/prime|v=v∗= 0⇒f/prime(v∗)g(v∗)−f(v∗)g/prime(v∗)
g2(v∗)= 0. (8)
Apparently, Eq. (7) is equivalent to (8) given the fact that g(v)>0, which completes the proof.
4Under review as submission to TMLR
1 1.5 2 2.5 3 3.5 4
iteration125130135140145150155160ObjectiveOur algorithm, with orthonormal constraint
LDA, no orthonormal constraint
(a) Objective comparison in Eq. 3.
k = 1 k = 3 k = 5 k = 70.60.70.80.91Accuracy, ORLOrthonormal
Not orthonormal (b) Accuracy on ORL dataset.
k = 1k = 3k = 5k = 7k = 90.60.70.80.91Accuracy, headpose
Orthonormal
Not orthonormal (c) Accuracy on Headpose dataset.
Figure 4: Experiments show that the orthonormality constraint can not only obtain better objective
(Fig. 4(a)), but also improve classiﬁcation results on real-world datasets (Fig. 4(b)–Fig. 4(c)).
3 Robust Metric Learning
3.1 Problem Formulation
Eq. (3) quantiﬁes the ratio between squared /lscript2-norm distances of pairs within must-links and cannot-links.
Like other least square minimization models in machine learning and statistics, it is sensitive to outliers.
Recent progress (Baccini et al., 1996; Gao, 2008; Ke & Kanade, 2004; Ding et al., 2006; Kwak, 2008; Wright
etal.,2009)hasshownthatthe /lscript1-normor/lscript2,1-normdistancecanpromoterobustnessagainstoutliersamples
or features, which have been widely applied to replace the squared /lscript2-norm distance in many traditional
machine learning methods, such as /lscript2,q-norm PCA (Wang et al., 2018). Inspired by the methods described
above, we propose a general robust metric learning formulation based on Eq. (3) as:
max
WTW=I/summationtext
(xi,xj)∈S/vextenddouble/vextenddoubleWT(xi−xj)/vextenddouble/vextenddoubleq
2/summationtext
(xi,xj)∈D/bardblWT(xi−xj)/bardblq
2=/summationtexts
i=1/vextenddouble/vextenddoubleWTai/vextenddouble/vextenddoubleq
2/summationtextd
i=1/bardblWTbi/bardblq
2=/bardblATW/bardbl2,q
/bardblBTW/bardbl2,q, (9)
where 0<q< 22and/bardblZ/bardbl2,q=/summationtext
i/bardblZ(i,:)/bardblq
2.
The above objective is obviously more challenging than Eq. 3 given the fact q/negationslash= 2. As we will discuss later,
we will propose a more generalized algorithm in which vanilla metric learning where q= 2is a special case.
3.2 Algorithm to Solve Eq. (6)
In this subsection, we are to develop an algorithm to obtain the optimal solution of Win the following
problem:
max
WTW=I/bardblATW/bardbl2,q−λ/bardblBTW/bardbl2,q, (10)
which is equivalent to:
min
WTW=Iλ/bardblBTW/bardbl2,q−/bardblATW/bardbl2,q. (11)
We start with a lemma that will be the foundation for analysis:
Lemma 3.1.∇W/bardblATW/bardbl2,1=ADATW, where Dis a diagonal matrix with D(i,i) =1
/bardblaT
iW/bardbl.
Proof of Lemma 3.1.
∇W/bardblATW/bardbl2,1=/summationdisplay
i∇W/bardblaT
iW/bardbl=/summationdisplay
iai1
/bardblaT
iW/bardblaT
iW=/summationdisplay
iaiD(i,i)aT
iW= (/summationdisplay
iaiD(i,i)aT
i)W=ADATW,
(12)
2Note our algorithm also works for q≥2or evenq≤0, but that makes less sense as our goal is to make the model robust
to outliers, therefore q> 2will make it more sensitive to noise.
5Under review as submission to TMLR
where the ﬁrst equation comes from the deﬁnition of the /lscript2,q-norm for matrices, the second equation comes
from the fact that ∇x/bardblx/bardbl=x
/bardblx/bardbl.
Based upon the lemma, we turn to study the /lscript2,q-norm case:
Lemma 3.2.∇W/bardblATW/bardbl2,q=ADATW, where Dis a diagonal matrix with D(i,i) =q/bardblaT
iW/bardblq−2.
Proof of Lemma 3.2.
∇W/bardblATW/bardbl2,q=/summationdisplay
i∇W/bardblaT
iW/bardblq=/summationdisplay
iq/bardblaT
iW/bardblq−1∇W/bardblaT
iW/bardbl
=/summationdisplay
iq/bardblaT
iW/bardblq−1ai1
/bardblaT
iW/bardblaT
iW=/summationdisplay
iaiD(i,i)aT
iW
=(/summationdisplay
iaiD(i,i)aT
i)W=ADATW,(13)
where the ﬁrst equation comes from the deﬁnition of matrix /lscript2,q-norm, the second equation comes from the
fact that∇xyq=qyq−1∇xyand the second line is directly from Lemma 3.1. One can see if q= 2, then the
gradient becomes 2AATWwhich is in accordance with the vanilla squared Frobenius norm case. Therefore,
our formulation is a more general case of traditional metric learning.
Denotef(W) =λ/bardblBTW/bardbl2,q−/bardblATW/bardbl2,q, then∇f(W) =λBDBBTW−ADAATW.
3.3 Algorithm to Solve Eq. (11) with Retraction
0 510 15 20 25 30 35 40 45 50
iteration1.241.251.261.271.281.291.31.311.321.33ObjectiveRobust metric learning with retraction
Figure 5: Objective update on syn-
thetic data demonstrates our retrac-
tion algorithm can make the objective
monotonically decreasing, which vali-
dates our theoretical analysis.Given the ﬁrst order (gradient) information of the objective, it is not
surprising to use projected gradient descent method where as long as
we can ﬁnd an appropriate stepsize, we can guarantee the objective
will be monotonically decreasing. Meanwhile, the orthonormality
constraint is nonconvex, which inspires us to propose a backtracking
line search style algorithm. For sake of further analysis, we start
with the following deﬁnition:
Deﬁnition 3.3. A retraction on a diﬀerentiable manifold Cis a
smooth mapping Retrfrom the agent space of C:TC, ontoCsatisfy-
ing the following two conditions, Retr XCdenotes the restriction of
RetrontoTXC: 1.Retr X(0) = X,∀X∈C; 2. For any X∈C
andδ∈TXC, it holds that limδ→0/bardblRetrX(δ)−(X+δ)/bardblF
/bardblδ/bardblF= 0.
For the Stiefel manifold St(p,r), common retractions include the
polar decomposition Retrpolar
X(δ) = (X+δ)(I+δTδ)−1/2, the QR
decomposition RetrQR
X(δ) =qf(X+δ), whereqf(X)is the Q factor of the QR factorization of X. For a
matrix W∈Rp×rwithr≤p, the total cost of computing the orthogonal projection is 8pr2+O(r3)ﬂops,
while if W=X+δandδ∈TXCthen the polar decomposition takes only 3pr2+O(r3)ﬂops and the
QR decomposition takes only 2pr2+O(r3). So if we can get a δ∈TXCeﬃciently, we can utilize cheaper
retraction operation rather than the expensive projection via singular value decomposition.
Based on the proximal gradient method described in Algorithm 2, in order to leverage retractions to handle
the Stiefel manifold constraint, we need to ﬁnd a descent direction in the tangent space TWkC, which is
formulated as:
Vk=argmin
V/angbracketleftgradf(Wk),V/angbracketright+1
2t/bardblV/bardbl2
F,s.t.V∈TWkC, (14)
where grad fdenotes the Riemannian gradient of f. And using the fact that for V∈TWkCwe have
/angbracketleftgradf(Wk),V/angbracketright=/angbracketleft∇f(Wk),V/angbracketright, we can simply solve the descent direction Vwithout computing the
6Under review as submission to TMLR
Algorithm 2 Robust metric learning algorithm to solve Eq. (11) with retractions.
Input:/epsilon1,0<γ < 1.
Initialization: t.
repeat
Obtain Vkby Eq. (18)
Setα= 1
Whilef(Retr Wk(αVk))>f(Wk)−α/bardblVk/bardbl2
F
2t
α=γα
End While
Wk+1=Retr Wk(αVk)
untilsatisfying stopping criterion /bardblVk/bardblF≤/epsilon1
L
Riemannian gradient grad f:
Vk=argminl (V) =argmin
V/angbracketleft∇f(Wk),V/angbracketright+1
2t/bardblV/bardbl2
F,s.t.V∈TWkC. (15)
With the deﬁnition of the tangent space to C=St(p,r)beingTWC={V|VTW+WTV= 0}, we can
obtain Vby checking the Karush–Kuhn–Tucker (KKT) conditions for the following Lagrangian function
with a Lagrange multiplier Γ:
minL(V,Γ) =/angbracketleft∇f(Wk),V/angbracketright+1
2t/bardblV/bardbl2
F−/angbracketleftVTW+WTV,Γ/angbracketright. (16)
The KKT conditions are
0∈∂VL(V,Γ),VTW+WTV= 0, (17)
and we can obtain the following closed-form solution for Vkassociated with Wk:
Vk=t((Wk∇f(W)TWk+WkWT
k∇f(Wk))
2/bardblWk/bardbl2
F−∇f(Wk)). (18)
We summarize the procedure by using retractions with a line search in Algorithm 2.
Here we also show the convergence properties of Algorithm 2, we present the following facts about retrac-
tions (Boumal et al., 2019) that will be leveraged in the later analysis:
Lemma 3.4. LetCbe a compact embedded submanifold of the Euclidean space, for all X∈Candδ∈TXC,
there exist constants C1>0andC2>0such that the following two inequalities hold:
/bardblRetr X(δ)−X/bardblF≤C1/bardblδ/bardblF,/bardblRetr X(δ)−(X+δ)/bardblF≤C2/bardblδ/bardbl2
F. (19)
First, we want to show that we can get a descent direction VinTWkCby solving Eq. (18).
Lemma 3.5. Withl(V)being the objective in Eq. (15), for any α∈[0,1], we have
l(αVk)−l(0)≤α2−2α
2t/bardblVk/bardbl2
F. (20)
Proof.lis1
t-strongly convex, then
l(V1)≥l(V2) +/angbracketleft∇l(V2),V1−V2/angbracketright+1
2/bardblV1−V2/bardbl2
F, (21)
and when V1,V2∈TWkC, we have/angbracketleft∇l(V2),V1−V2/angbracketright=/angbracketleftProjTWkC∇l(V2),V1−V2/angbracketright, and 0∈
ProjTWkC∇l(V2)based on the optimality condition. Then, let V1= 0,V2=Vkin Eq. (21), we have
l(0)≥l(Vk) +1
2t/bardblVk/bardbl2
F=/angbracketleft∇f(Wk),Vk/angbracketright+1
t/bardblVk/bardbl2
F, (22)
therefore, we have l(αVk)−l(0) =/angbracketleft∇f(Wk),αVk/angbracketright+1
2t/bardblαVk/bardbl2
F≤α2−2α
2t/bardblVk/bardbl2
F.
7Under review as submission to TMLR
We now show that the objective sequence {f(Wk)}is monotonically decreasing in Algorithm 2:
Lemma 3.6. For anyt >0, there exists a constant ¯α > 0such that for any 0< α≤min{1,¯α}, the
inequality in the line search procedure, i.e. f(Retr Wk(αVk))> f(Wk)−α/bardblVk/bardbl2
F
2t, is satisﬁed, and the
objective sequence {f(Wk)}generated by Algorithm 2 satisﬁes
f(Wk+1)−f(Wk)≤−α/bardblVk/bardbl2
F
2t. (23)
Proof.With Lemma 3.4, let W+
k=Wk+αVk, then for any α>0we have
f(Retr Wk(αVk))−f(Wk)≤/angbracketleft∇f(Wk),Retr Wk(αVk)−Wk/angbracketright+L
2/bardblRetr Wk(αVk)−Wk/bardbl2
F
≤C2/bardbl∇f(Wk)/bardblF/bardblαVk/bardbl2
F+α/angbracketleft∇f(Wk),Vk/angbracketright+LC2
1
2/bardblαVk/bardbl2
F.(24)
Since∇fis continuous onC, we can safely say /bardbl∇f(W)/bardblFis upper bounded by a constant number G> 0,
thus letc0=C2G+LC2
1
2, we can get
f(Retr Wk(αVk))−f(Wk)≤α/angbracketleft∇f(Wk),Vk/angbracketright+c0α2/bardblVk/bardbl2
F
=c0α2/bardblVk/bardbl2
F+l(αVk)−1
2t/bardblαVk/bardbl2
F−l(0)
≤c0α2/bardblVk/bardbl2
F−1
2t/bardblαVk/bardbl2
F+α2
2t/bardblVk/bardbl2
F−α
t/bardblVk/bardbl2
F
= (c0−1
αt)/bardblαVk/bardbl2
F,(25)
wherel(V)is deﬁned in Eq. (15) and the second inequality comes from Lemma 3.5. By setting ¯α=1
2tc0, we
guarantee that for 0<α≤min{1,¯α},f(Retr Wk(αVk))−f(Wk)≤−α
2t/bardblVk/bardbl2
F.
Deﬁnition 3.7. Wkis an/epsilon1-stationary point of g(W)if/bardblVk/bardblF≤/epsilon1
L.
Theorem 3.8. Algorithm 2 will return an /epsilon1-stationary point in O(1
/epsilon12)iterations.
Proof.Suppose Algorithm 2 doesn’t terminate until the Kthiteration, which means
/bardblVk/bardblF>/epsilon1
L,∀k= 0,1,...,K−1, (26)
and letαkdenote the actual αin thekthiteration, and we have αk≥γ¯αfrom Lemma 3.6, we have
f(W0)−f∗≥f(W0)−f(WK)≥K−1/summationdisplay
k=0αk
2t/bardblVk/bardbl2
F=t
2K−1/summationdisplay
k=0αk/bardblVk
t/bardbl2
F>t/epsilon12
2K−1/summationdisplay
k=0αk≥Kt/epsilon12
2γ¯α,(27)
which implies that the number of iterations needed to obtain an /epsilon1-stationary point in Algorithm 2 is O(1
/epsilon12).
4 2D Metric Learning
For a 2D dataset X={xi∈Rp×m}n
i=1(e.g., grayscale images) and given relevance relationships between
certain pairs, we group paired data into SorD. Unlike conventional metric learning, our 2D metric learning
algorithm operates directly on 2D matrices instead of 1D vectors, eliminating the need to transform image
data (Zhang & Zhou, 2005; Li & Yuan, 2005). This allows us to construct image covariance matrices directly
from the original matrices, resulting in signiﬁcantly reduced covariance matrix sizes, as shown in Fig. 1.
8Under review as submission to TMLR
4.1 Problem Formulation
Given any two 2D data points xiandxj, its Mahalanobis distance between them can be naturally given by:
/bardblxi−xj/bardbl2
M=tr/braceleftBig
(xi−xj)TM(xi−xj)/bracerightBig
=/bardblWT(xi−xj)/bardbl2
F, (28)
where M=WWT∈Rp×p.
Similar to the practices in traditional metric learning methods, suppose we are given a set of paired data
instances inD, along with some paired samples from Sdeﬁned in Eq. (1), without loss of generality, we
denote{D1,D2,...,Dd}where Dk=xk
i−xk
j∈Rp×mis the diﬀerence between paired samples taken from
setD. Similarly, we can denote {S1,S2,...,Ss}where Sk=xk
i−xk
jfrom setS. By following the idea
of Fisher’s LDA (Fisher, 1936), the projection matrix Wwill make the distance within the same class as
small as possible while setting the distance between diﬀerent classes as large as possible, therefore we can
formulate the 2D metric learning objective as:
max
WTW=I/summationtext
(xi,xj)∈D/vextenddouble/vextenddoubleWT(xi−xj)/vextenddouble/vextenddouble2
F
/summationtext
(xi,xj)∈S/bardblWT(xi−xj)/bardbl2
F=d/summationtext
i=1/vextenddouble/vextenddoubleWTDi/vextenddouble/vextenddouble2
F
s/summationtext
i=1/bardblWTSi/bardbl2
F, (29)
It is obvious that the denominator in Eq. (29) is nonnegative, therefore we could use the general framework
in Algorithm 1 to optimize Win Eq. (29) withCcorresponding to the orthonormal constraint on W.
Following Algorithm 1, now we turn to optimize max
WTW=If(W)−λg(W). By Eq. (29) we have:
f(W) =d/summationdisplay
i=1/vextenddouble/vextenddoubleWTDi/vextenddouble/vextenddouble2
F=d/summationdisplay
i=1tr/parenleftbig
WTDiDT
iW/parenrightbig
=tr/parenleftbig
WTSbW/parenrightbig
, (30)
where Sb=D1DT
1+D2DT
2+···+DdDT
ddenotes the covariance matrix of data pairs from diﬀerent
clusters. Similarly, we can get g(W) =/summationtexts
i=1/vextenddouble/vextenddoubleWTSi/vextenddouble/vextenddouble2
F=/summationtexts
i=1tr/parenleftbig
WTSiST
iW/parenrightbig
=tr/parenleftbig
WTSwW/parenrightbig
,with
Sw=S1ST
1+S2ST
2+···+SsST
sdenotes the covariance matrix from the same clusters.
The optimization problem now is in the following form:
max
Wtr/parenleftbig
WTSbW/parenrightbig
−λtr/parenleftbig
WTSwW/parenrightbig
=tr/braceleftbig
WT(Sb−λSw)W/bracerightbig
, (31)
with constraint WTW=Ir×r. Though the constraint is nonconvex, still there is a closed solution for W
by noticing the fact that Sb−λSwis symmetric, which can be obtained by doing eigenvalue decomposition
toSb−λSw∈Rp×pand pick the reigenvectors corresponding to the largest reigenvalues. The constraint
WTW=Ir×ris automatically satisﬁed due to the property of symmetric matrix eigenvalue decomposition.
Algorithm 3 2D metric learning algorithm.
Input:{D1,...,Dd},{S1,...,Ss},Sw,Sbandr.
Initialization: W
repeat
Calculateλ=tr(WTSbW)
tr(WTSwW);
[U,V] =eig(Sb−λSw,/primedescent/prime);
W+=UVT;
untilconvergence
9Under review as submission to TMLR
Algorithm 4 Robust 2D metric learning algorithm.
Input:{D1,...,Dd},{S1,...,Ss}andr.
Initialization: W
repeat
Calculateλ=tr(WTSbW)
tr(WTSwW)
repeat
Calculate Sb,Swaccording to Eq. (34);
[U,V] =eig(Sb−λSw,‘descent/prime);
W+=UVT;
untilconvergence
untilconvergence
Regarding the analysis of complexity, for the sake of simplicity, we assume the image dimension to be n×n.
Traditional metric learning methods vectorize an image to a vector of size n2, so the covariance matrix size
isn2×n2. Generally speaking, the complexity of eigenvalue decomposition is O(p3)given matrix size p×p.
Therefore, the time complexity of 2D metric learning proposed by this paper is O(n3)while traditional is
O(n6), which is a huge improvement, especially when nis considerably large. Assume there are Kloops to
updateλin Algorithm 1, then the whole complexity is O(K∗n3)since the most signiﬁcant consumption in
the algorithm comes from eigenvalue decomposition.
4.2 Robust 2D Metric Learning
The same robust strategy in Section 3 can be applied to 2D metric learning as well:
max
WTW=I/summationtext
(xi,xj)∈D/vextenddouble/vextenddoubleWT(xi−xj)/vextenddouble/vextenddoubleq
F
/summationtext
(xi,xj)∈S/bardblWT(xi−xj)/bardblq
F=d/summationtext
i=1/vextenddouble/vextenddoubleWTDi/vextenddouble/vextenddoubleq
F
s/summationtext
i=1/bardblWTSi/bardblq
F, (32)
where 0<q< 2. Following earlier analysis, we turn to optimize:
max
WTW=Id/summationdisplay
i=1/vextenddouble/vextenddoubleWTDi/vextenddouble/vextenddoubleq
F−λs/summationdisplay
i=1/vextenddouble/vextenddoubleWTSi/vextenddouble/vextenddoubleq
F. (33)
The robust 2D metric learning problem can be addressed using a very similar approach to vanilla 2D. By
denotingf(W) =d/summationtext
i=1/vextenddouble/vextenddoubleWTDi/vextenddouble/vextenddoubleq
F−λs/summationtext
i=1/vextenddouble/vextenddoubleWTSi/vextenddouble/vextenddoubleq
F, then∇f(W) =q(Sb−λSw)W, where we deﬁne:
Sw=S1ST
1
/bardblWTS1/bardbl2−q
F+···+SsST
s
/bardblWTSs/bardbl2−q
F,Sb=D1DT
1
/bardblWTD1/bardbl2−q
F+···+DdDT
d
/bardblWTDd/bardbl2−q
F. (34)
Algorithm 4 is slightly diﬀerent from Algorithm 3 in terms an inner loop to ensure WandSw,Sbconverge.
5 Kernel Version Metric Learning
While the preceding sections oﬀer methodologies for 1D and 2D data, it’s important to acknowledge that in
real-world scenarios, a substantial volume of data exists in high-dimensional spaces. Rather than transform-
ing the tensor data into 2D or 1D formats, we present a versatile approach to address such data by leveraging
the Kernel trick, which has demonstrated substantial promising performance, particularly when the data in
the original space ( Rd) may not be well separable but can be eﬀectively separated by projecting it into a
higher-dimensional space. ( Rn) via Φ(xi)where Φ :Rd→Rn(Liu et al., 2008; Leslie et al., 2001; Patle &
Chouhan, 2013; Ye et al., 2009; Cai et al., 2011). Assume we are given {D1,D2,...,Dd},{S1,S2,...,Ss},
10Under review as submission to TMLR
where Di,Si∈Rp. Diﬀerent from existing methods, the kernel method bypasses the explicit computation
of eigenvalues, while it provides the eﬃcient calculation of eigenvalues through the kernel trick instead. To
the best of our knowledge, kernel metric learning in the form of min-max ratio optimization has not been
previously explored in the literature.
5.1 Problem Formulation
Same as before, we formulate the kernel version objective as:
max
WTW=I/summationtext
(xi,xj)∈D/vextenddouble/vextenddoubleWTΦ (xi−xj)/vextenddouble/vextenddouble2
2
/summationtext
(xi,xj)∈S/bardblWTΦ (xi−xj)/bardbl2
2=d/summationtext
i=1/vextenddouble/vextenddoubleWTΦ(Di)/vextenddouble/vextenddouble2
2
s/summationtext
i=1/bardblWTΦ(Si)/bardbl2
2=/vextenddouble/vextenddoubleWTΦ(D)/vextenddouble/vextenddouble2
F
/bardblWTΦ(S)/bardbl2
F. (35)
Similar to the steps in the 2D version, we can ﬁrst initialize λfollowed by optimizing:
max
WTW=Itr/parenleftbig
WTΦ(D)ΦT(D)W/parenrightbig
−λtr/parenleftbig
WTΦ(S)ΦT(S)W/parenrightbig
=tr/braceleftbig
WT(Φ(D)ΦT(D)−λΦ(S)ΦT(S))W/bracerightbig
.
(36)
By observing that Φ(D)ΦT(D)−λΦ(S)ΦT(S)is symmetric, we can transfer it into ﬁnding the reigenvectors
corresponds to the top rlargest eigenvalue of Φ(D)ΦT(D)−λΦ(S)ΦT(S). If we denote an eigenvector as v,
and its corresponding eigenvalue as θ, we have:
(Φ(D)ΦT(D)−λΦ(S)ΦT(S))v=θv
⇔(d/summationdisplay
i=1Φ(Di)ΦT(Di)−λs/summationdisplay
i=1Φ(Si)ΦT(Si))v=θv
⇔d/summationdisplay
i=1Φ(Di)/angbracketleftΦT(Di),v/angbracketright/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
scalar−λs/summationdisplay
i=1Φ(Si)/angbracketleftΦT(Si),v/angbracketright/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
scalar=θv,(37)
we see that vis a linear combination of Φ(Di)andΦ(Si), therefore we have:
v= [Φ(D),Φ(S)]/bracketleftbiggαd
αs/bracketrightbigg
/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
α, (38)
whereα∈Rd+s. Now plug Eq. (38) in Eq. (37) we have:
(Φ(D)ΦT(D)−λΦ(S)ΦT(S))[Φ(D),Φ(S)]α=θ[Φ(D),Φ(S)]α, (39)
which is equivalent to:
[Φ(D)KDD−λΦ(S)KSD,Φ(D)KDS−λΦ(S)KSS]α=θ[Φ(D),Φ(S)]α. (40)
By multiplying [Φ(D),Φ(S)]Tto both sides of the above equation:
/bracketleftbiggKDDKDD−λKDSKSDKDDKDS−λKDSKSS
KSDKDD−λKSSKSDKSDKDS−λKSSKSS/bracketrightbigg
α=θ/bracketleftbiggKDDKDS
KSDKSS/bracketrightbigg
α, (41)
therefore,θandαare the eigenvalue and eigenvector of
/bracketleftbigg
KDDKDS
KSDKSS/bracketrightbigg−1/bracketleftbiggKDDKDD−λKDSKSDKDDKDS−λKDSKSS
KSDKDD−λKSSKSD KSDKDS−λKSSKSS/bracketrightbigg
, (42)
where KDD= Φ(D)TΦ(D),KDS= Φ(D)TΦ(S),KSD= Φ(S)TΦ(D),KSS= Φ(S)TΦ(S)3.
3Clearly,/bracketleftBigKDD KDS
KSD KSS/bracketrightBig
is a Kernel matrix, therefore it is SPD. To avoid the singular case, in practice, we can take its
inversion as/braceleftBig/bracketleftBigKDD KDS
KSD KSS/bracketrightBig
+/epsilon1I/bracerightBig−1
, where/epsilon1is a very small positive scalar.
11Under review as submission to TMLR
Algorithm 5 Kernel metric learning algorithm.
Input:{D1,...,Dd},{S1,...,Ss},rand calculate KDD,KDS,KSDandKSSaccordingly.
Initialization: λ
repeat
Obtain eigenvalue θand eigenvector αvia Eq. (41);
Calculateλas Eq. (43);
untilconvergence
It is worth noting that we do the eigenvalue decomposition based on the above matrix with dimension
(s+d)×(s+d)instead of high dimension n, and it’s computationally eﬃcient to get eigenvectors G=
[α1,...,αr]corresponding to the largest rlargest eigenvalues θ. After we obtain G∈R(s+d)×rcomposed of
the ﬁrstreigenvectors, according to Eq. (38), we obtain the projection matrix Was[Φ(D),Φ(S)]G. And
therefore:
λ=/vextenddouble/vextenddoubleWTΦ(D)/vextenddouble/vextenddouble2
F
/bardblWTΦ(S)/bardbl2
F=tr/parenleftbig
GT[Φ(D),Φ(S)]TΦ(D)ΦT(D)[Φ(D),Φ(S)]G/parenrightbig
tr(GT[Φ(D),Φ(S)]TΦ(S)ΦT(S)[Φ(D),Φ(S)]G)=tr/braceleftbigg
GT/bracketleftbigg
KDDKDDKDDKDS
KSDKDDKSDKDS/bracketrightbigg
G/bracerightbigg
tr/braceleftbigg
GT/bracketleftbigg
KDSKSDKDSKSS
KSSKSDKSSKSS/bracketrightbigg
G/bracerightbigg.
(43)
5.2 Image Recognition Via Kernel Version
In image clustering or classiﬁcation, the cluster/class assignment is based on Euclidean distance in the lower
dimension by projection matrix W. Also, for some kernels, say Gaussian kernel, Wcan not be explicitly
obtained as it is an inﬁnite dimension mapping. Therefore, we seek image recognition implicitly via the
Kernel trick. Assume we have anchor data samples A={aj}(j= 1,...,h )and query data ai, the squared
Euclidean distance in transformed space is /bardblWTΦ(Qj)/bardbl2
F, where Qj=aj−ai(j= 1,...,h ). Therefore:
/bardblWTΦ(Qj)/bardbl2
F=tr/parenleftbig
GT[Φ(D),Φ(S)]TΦ(Qj)ΦT(Qj)[Φ(D),Φ(S)]G/parenrightbig
=tr/braceleftbigg
GT/bracketleftbigg
KDQjKQjDKDQjKQjS
KSQjKQjDKSQjKQjS/bracketrightbigg
G/bracerightbigg
.
(44)
The kernel version metric learning algorithm is summarized in Algorithm 5. We end this section by pointing
out that diﬀerent kernel options may result in various performances, such as Linear, polynomial, and RBF
kernel,hyper-parameterneedstuningwhennecessary,but K(x,y) =/angbracketleftΦ(x),Φ(y)/angbracketrightiscomputationallyeﬃcient
via the Kernel trick. In the kernel version metric learning algorithm, the main consumption goes to inversion
and eigenvalue decomposition both on (s+d)×(s+d), therefore the whole complexity is O(K∗(s+d)3).
6 Convergence Analysis
We give the convergence rate of Algorithm 3 and Algorithm 5 in the following theorem:
Theorem 6.1. The convergence rate of Algorithm 3 and Algorithm 5 is superlinear.
Proof.We start the analysis with the deﬁnition of superlinear convergence rate: limk→∞/bardblFk+1−F∗/bardbl
/bardblFk−F∗/bardbl= 0,
where we deﬁne
F∗= max
WTW=Itr/parenleftbig
WTSbW/parenrightbig
tr(WTSwW):= max
WTW=If(W)
g(W)= max
WTW=IF(W), (45)
and we have
W∗∈argmaxf(W)−F(W∗)g(W). (46)
AsW∈Rp×r, we conclude the leading eigenvalues of Sb−F∗Swdenoted as λ1,...,λrsatisfy/summationtextr
i=1λi= 0.
Many previous works have focused on the convergence rate of the constrained maximum trace ratio problem,
including global linear or local quadratic, we refer the readers to Ngo et al. (2012); Zhang et al. (2010; 2013)
12Under review as submission to TMLR
and the references therein. Our analysis will utilize the global linear convergence result established by Zhang
et al. (2010), based on which we will show it is indeed superlinear:
F(W∗)−F(Wk+1)≤(1−1
κ(Sw))(F(W∗)−F(Wk)), (47)
whereκ(Sw) =/summationtextr
i=1λi(Sw)//summationtextr
i=1λp−i+1(Sw)>1almost surely .
For any symmetric matrix C∈Rp×pandV= (v1,v2,...,vp)be its eigenvectors in decreasing order w.r.t.
eigenvalues, then we have
r/summationdisplay
i=1λi−tr/parenleftbig
WTCW/parenrightbig
=r/summationdisplay
i=1λi−p/summationdisplay
i=1λi/bardblWTvi/bardbl2
2=r/summationdisplay
i=1λi(1−/bardblWTvi/bardbl2
2)−p/summationdisplay
i=r+1λi/bardblWTvi/bardbl2
2,(48)
with the fact that
/bardblWTvi/bardbl2
2=vT
iWWTvi≤/bardblWWT/bardbl2=/bardblWTW/bardbl2= 1, (49)
we have
r/summationdisplay
i=1λi−tr/parenleftbig
WTCW/parenrightbig
≥r/summationdisplay
i=1λi(1−/bardblWTvi/bardbl2
2)−λr+1p/summationdisplay
i=r+1/bardblWTvi/bardbl2
2
≥λr(r−r/summationdisplay
i=1/bardblWTvi/bardbl2
2)−λr+1(r−r/summationdisplay
i=1/bardblWTvi/bardbl2
2)
=(λr−λr+1)(r−r/summationdisplay
i=1/bardblWTvi/bardbl2
2).(50)
Denote ¯V= (v1,v2,...,vr)∈Rp×r, for any square rotation matrix R∈Rr×rsuch that RTR=RRT=I,
withσi(·)denoting the singular values, we have
min
W∗/bardblW−W∗/bardbl2
F≤min
R/bardblW−¯VR/bardbl2
F= min
R/bardblW/bardbl2
F+/bardbl¯VR/bardbl2
F−2tr/parenleftbig
WT¯VR/parenrightbig
= min
R2(r−tr/parenleftbig
RT¯VTW/parenrightbig
) = 2(r−r/summationdisplay
i=1σi(¯VTW))
≤2(r−r/summationdisplay
i=1σ2
i(¯VTW)) = 2(r−/bardbl¯VTW/bardbl2
F) = 2(r−r/summationdisplay
i=1/bardblWTvi/bardbl2
2).(51)
Combine Eq. (50) and Eq. (51), we get
r/summationdisplay
i=1λi−tr/parenleftbig
WTCW/parenrightbig
≥λr−λr+1
2min
W∗/bardblW−W∗/bardbl2
F. (52)
DenoteP(W) =f(W)−F(W∗)g(W) =g(W)(F(W)−F∗) =tr/parenleftbig
WT(Sb−F∗Sw)W/parenrightbig
, now set C=
Sb−F∗Sw, recall that the leading eigenvalues of Sb−F∗Swsatisfy/summationtextr
i=1λi= 0, and invoke Eq. (52), we
get
λr−λr+1
2min
W∗/bardblW−W∗/bardbl2
F≤−tr/parenleftbig
WTCW/parenrightbig
=g(W)(F∗−F(W)). (53)
With the deﬁnition of g(W)in Eq. (45), we have
g(W) =tr/parenleftbig
WTSwW/parenrightbig
≤r/summationdisplay
i=1λi(Sw), (54)
13Under review as submission to TMLR
therefore, by plugging W=Wk, we can obtain
min
W∗/bardblW−W∗/bardbl2
F≤2/summationtextr
i=1λi(Sw)
λr−λr+1(F∗−F(Wk))≤2/summationtextr
i=1λi(Sw)
λr−λr+1(F∗−F(W0))(1−1
κ(Sw))k.(55)
On the other side,
|g(W∗)−g(Wk)|=|/angbracketleftW∗−Wk,∇g(θWk+ (1−θ)W∗)/angbracketright|=|/angbracketleftW∗−Wk,2Sw(θWk+ (1−θ)W∗)/angbracketright|
≤2/bardblW∗−Wk/bardblF/bardblSw/bardbl2(θ/bardblWk/bardblF+ (1−θ)/bardblW∗/bardblF) = 2√rλ1(Sw)/bardblW∗−Wk/bardblF.(56)
Since Wk+1=argmaxWf(W)−F(Wk)g(W) = argmaxWg(W)f(W)
g(W)−g(W)F(Wk) =
argmaxWg(W)(F(W)−F(Wk)), we have
g(Wk+1)(F(Wk+1)−F(Wk))≥g(W∗)(F(W∗)−F(Wk)), (57)
dividing both sides by g(Wk+1)and addF(W∗)−F(Wk), we obtain
F(W∗)−F(Wk+1)≤g(W∗)
g(Wk+1)(F(Wk)−F(W∗)) +F(W∗)−F(Wk)
=g(Wk+1)−g(W∗)
g(Wk+1)(F(W∗)−F(Wk)).(58)
Thus, based on Eq. (55), Eq. (56) and Eq. (58), we can obtain
F∗−F(Wk+1)
F∗−F(Wk)≤g(Wk+1)−g(W∗)
g(Wk+1)≤2√rλ1(Sw)/bardblW∗−Wk/bardblF/summationtextr
i=1λp−i+1(Sw)
≤2√rλ1(Sw)/summationtextr
i=1λp−i+1(Sw)min
W∗/bardblWk+1−W∗/bardblF
≤2√rλ1(Sw)/summationtextr
i=1λp−i+1(Sw)/radicalBigg
2/summationtextr
i=1λi(Sw)
λr−λr+1(F∗−F(W0))(1−1
κ(Sw))k+1
2.(59)
We can see that when k→∞in Eq. (59), we haveF∗−F(Wk+1)
F∗−F(Wk)= 0, which is the superlinear convergence
rate, and we have
F∗−F(Wk)
F∗−F(W0)≤Sk(1−1
κ(Sw))/summationtextk
n=1n
2=Sk(1−1
κ(Sw))k(k+1)
4, (60)
whereS=2√rλ1(Sw)/summationtextr
i=1λp−i+1(Sw)/radicalbigg
2/summationtextr
i=1λi(Sw)
λr−λr+1(F∗−F(W0)).
7 Experiments
7.1 Toy Experiment
To test our approach, we conduct a toy experiment classifying dogs and cats. Training data deliberately
include mismatched pairs, as seen in Figure 6(a). Despite mislabeled images, both the robust method and
robust 2D method, designed for outlier robustness, correctly classify all images for q= 1, as shown in the
lower part of Figure 6(a). To further illustrate the robust metric learning method, we also provide the
details in Figure 2 example. Given the following sentences: ‘He/She is happy/angry’, ‘He/She is very/quite
happy/angry’ and ‘Happy/Angry’, with a total number of 14. We manually give 20 correct side constraints,
for example: ‘He is happy’ and ‘She is angry’ in diﬀerent sets, while ‘He is quite happy’ and ‘Happy’ in the
same. Also, there are some adversarial examples, where 5 links are mistakenly given, say ‘She is happy’ and
‘He is quite angry’ should be separated but they are put in the same set. Each sentence xis represented as a
14Under review as submission to TMLR
(a) Image recognition
p=2p=1SheHeishappyangryveryquiteWeights for each Word
-0.4221-0.4576
0.033860.069040.0045680.0045680.007688-0.70711.047e-093.246e-070.45340.50410.38310.7071
-0.6-0.4-0.200.20.40.6 (b) Sentiment recognition
Figure 6: Results from toy experiments. From left to right: (a) Image recognition: Training set (upper) and
recognition results (lower). Even with the existence of incorrect pairs, our robust metric learning method
still yields correct recognition; (b) Sentiment recognition: Our robust metric learning (p = 1) can learn
reasonable weights for features even under adversarial attack while the traditional one (p =2) will fail.
15 20 25 30
#nearest neighbors in knn0.550.60.650.70.75Sentiment recognition accuracyEuclidean
2D, r = 40
2D, r = 35
2D, r = 30
(a) IMDB
1020304050607080
#columns in transformation matrix0.90.920.940.960.981Face recognition accuracy2D gray
2D RGB
robust 2D gray
robust 2D RGB
kernel gray
kernel RGB (b) Headpose
12345678
#iteration0100200300400500Objective
headpose dataset
ORL dataset (c) Objective
Figure 7: From left to right: (a) Accuracy of the 2D metric learning with varying projected dimension r and k
ink-NN for the IMDB dataset; (b) Face recognition accuracy for the headpose dataset, where X-axis denotes
the projected dimension; (c) The objective of the 2D metric learning is monotonically non-decreasing, same
for the kernel method and the robust 2D method.
7-dimensional word-count vector (with each denoting a word such as ‘happy’, ‘angry’, etc.). As demonstrated
in Figure 6(b), for vanilla squared Frobenius ( q= 2), the learned weights for ‘is’, ‘happy’, and ‘angry’ are
close, which is not as they should be. However, if we set q= 1, which is supposed to remain robust with
outliers/attacks, it can obtain signiﬁcantly diﬀerent weights for ‘happy’ (0.707) and ‘angry’ (-0.707), while
the rest are all set close to 0. This is in perfect accordance with our common sense, which indicates the
potential application of our robust metric learning in other domains.
7.2 Sentiment Recognition
We evaluate the 2D metric learning method in a sentiment recognition task with the IMDB dataset. 5000
data instances are randomly sampled from the IMDB review dataset and are split into the training set and
test set evenly. For each review, only the ﬁrst 50 processed text words are embedded in a 50-dimension tensor
and are labeled as positive or negative. We obtain Wusing samples from the training set, and then apply
it when we use k-NN to do sentiment classiﬁcation. We test the 2D metric learning method with varying
numbers of columns in the transformation matrix and kin thek-NN classiﬁer. Figure 7(a) shows the result,
our method can achieve stable and better performance than Euclidean distance-based classiﬁcation.
15Under review as submission to TMLR
Table 1: Time consumption (in seconds) and mean recognition accuracy (10 test runs) for headpose dataset
MS GMML LMNN KISSME ITML
GrayscaleTime 155.981 56.221 6601.881 792.331 5310.871
k= 3 0.940 0.928 0.917 0.935 0.917
k= 5 0.931 0.922 0.825 0.931 0.883
k= 9 0.933 0.917 0.817 0.922 0.883
RGBTime 312.212 93.125 9925.917 1238.569 7555.825
k= 3 0.983 0.967 0.928 0.962 0.931
k= 5 0.983 0.933 0.917 0.958 0.925
k= 9 0.967 0.933 0.917 0.945 0.917
MRL RDML 2D Robust 2D Kernel
GrayscaleTime 698.329 1005.72 2.062 8.185 2.517
k= 3 0.933 0.933 0.933 0.967 0.967
k= 5 0.917 0.933 0.933 0.967 0.967
k= 9 0.883 0.917 0.933 0.967 0.933
RGBTime 1025.978 2955.96 5.959 10.121 5.012
k= 3 0.965 0.967 0.985 0.985 0.985
k= 5 0.932 0.933 0.983 0.985 0.983
k= 9 0.923 0.917 0.967 0.983 0.983
Table 2: Time consumption (in seconds) and mean recognition accuracy (10 test runs) for ORL dataset,
with full test images, with random missing pixels as noise on test images, and with mismatched pairs
MS GMML LMNN KISSME ITML
VanillaTime 102.763 35.758 5721.998 603.992 4125.722
k= 3 0.913 0.898 0.897 0.901 0.883
k= 5 0.891 0.885 0.852 0.882 0.867
k= 7 0.847 0.839 0.792 0.828 0.813
Noisek= 3 0.895 0.879 0.892 0.891 0.852
k= 5 0.873 0.868 0.839 0.852 0.839
k= 7 0.839 0.807 0.768 0.819 0.793
Miss-matchedk= 3 0.892 0.872 0.853 0.858 0.863
k= 5 0.875 0.827 0.822 0.839 0.817
k= 7 0.819 0.808 0.767 0.795 0.792
MRL RDML 2D Robust 2D Kernel
VanillaTime 465.827 805.386 2.287 8.552 2.817
k= 3 0.905 0.902 0.933 0.933 0.933
k= 5 0.887 0.872 0.917 0.917 0.902
k= 7 0.835 0.851 0.861 0.867 0.867
Noisek= 3 0.857 0.867 0.892 0.913 0.917
k= 5 0.825 0.845 0.873 0.892 0.892
k= 7 0.817 0.769 0.833 0.877 0.837
Miss-matchedk= 3 0.851 0.817 0.875 0.917 0.892
k= 5 0.818 0.813 0.835 0.902 0.875
k= 7 0.785 0.767 0.819 0.875 0.825
7.3 Image Segmentation and Recognition
We conduct image segmentation on some natural images (Martin et al., 2001) and evaluate our methods in
an image classiﬁcation task with k-NN classiﬁer on two datasets, the headpose dataset (Gourier et al., 2004)
and the ORL dataset (Samaria & Harter, 1994). For the headpose dataset, we conduct the experiment with
two settings: (1)with grayscale images; (2)with RGB images. To deal with RGB images, we treat the three
layers of images as three matrix blocks and append them together. Thus for an input image of size p×m, in
2D methods we stretch it into a matrix of size p×3m. In other methods, we vectorize the input image to get
16Under review as submission to TMLR
1020304050607080
#columns in transformation matrix0.80.850.90.95Face recognition accuracy, vanilla2D
Robust 2D
kernel
(a) Vanilla
1020304050607080
#columns in transformation matrix0.80.850.90.95Face recognition accuracy, noise2D
Robust 2D
kernel (b) Noise
1020304050607080
#columns in transformation matrix0.80.850.90.95Face recognition accuracy, mispaired2D
Robust 2D
kernel (c) Mispaired
Figure 8: Accuracy for the ORL dataset with varying projected dimensions, from left to right is obtained
with vanilla images, with noise, and with mispaired images, respectively.
a vector with length 3×p×m. For the Robust metric learning, we set q= 1. To evaluate the robustness of
the algorithms, we test on the ORL dataset in three situations: (1)learn with correct pairwise relationships,
test on vanilla images; (2)learn with correct information but test on images with 10% noises; (3)learn the
metric while there exist 7% miss-matched pairwise relationships, test on vanilla images. We also compare
our method with several metric learning methods, including Multi-Similarity-based deep metric learning
(MS) (Wang et al., 2019), GMML (Zadeh et al., 2016), ITML (Davis et al., 2007), LMNN (Weinberger et al.,
2006), KISSME (Koestinger et al., 2012), MRL(-ADMM) (Lim et al., 2013), and RDML (Liu et al., 2019).
Both GMML and MRL-ADMM claim their superiority in terms of low computation time, which will be
compared with our methods in computation time. We evaluate both the time consumption and recognition
accuracy of each algorithm. The time consumption to get W, and the recognition accuracy with varying k
ofk-NN classiﬁer are listed in Table 1 and Table 2, best results are highlighted. It is obvious that the time
consumption of our 2D methods and kernel method is a huge advantage and this merit is more signiﬁcant
with RGB images. Our methods require negligible computation time to get the transformation matrix, while
othermethodshavemuchhighercomputationalcosts. EvencomparedwiththeGMMLmethod, whichserves
as a breakthrough in terms of computation time, our proposed methods still have a great advantage in high
eﬃciency. Our methods are able to achieve the best recognition accuracy almost on all tested datasets, at
most times they are signiﬁcantly better than most other methods, and they have comparable performance
with deep metric learning on the two datasets. In Table 2, when we introduce noise and adversarial attack
in the training process, the robust 2D metric learning method and robust metric learning method are proved
to be able to achieve robust performance.
We also investigate the impact of varying the number of columns rin the transformation matrix W. By
testing diﬀerent values of rwhile keeping kof thek-NN classiﬁer set to 3, Figure 7(b) illustrates that higher
accuracy can be achieved as rincreases, reaching a threshold where the incremental gain diminishes. For
a more detailed exploration of how the number of columns rin the transformation matrix Winﬂuences
accuracy, refer to Figure 8. Figure 7(c) illustrates the objective change in the 2D version, with kernel and
robust methods exhibiting similar trends. Notably, an optimal transformation matrix Wcan be obtained
within very few iterations. The presented results collectively aﬃrm that the four proposed metric learning
algorithms eﬀectively address real-world cases. This validation aligns with our earlier analyses and suggests
their superiority over their counterparts. Figure 9 showcases image segmentation results utilizing RGB
pixel values and X,Ylocations as input features. The presence of red/green lines and pixels indicates
must-link and cannot-link relationships, respectively. In the ﬁrst row, images display user-speciﬁed pixels
denoting the background and foreground. Subsequent rows reveal the impact of learning an appropriate
distance metric transformation matrix Wfrom user-speciﬁed pixels. The improved performance of the
k-NN classiﬁer in segmentation is evident. Our algorithm consistently outperforms GMML and RDML
methods, as demonstrated in the lower rows. For instance, in the pyramid image, the black circled area,
situated far from the labeled foreground region, is accurately classiﬁed by our method but not by others.
Figure 10 demonstrates the results from the face recognition experiment. After imposing 10 %noise on the
query image randomly, our method excels in identifying the nearest anchor images compared to others.
17Under review as submission to TMLR
Figure 9: Image segmentation results. First row: Original images with labeled pixels. Second: Euclidean
distance.Third:GMML method. Fourth: RDML method. Fifth Row: Robust Algorithm 2.
Fig. 5. Face recognition results with missing pixelsFor papers published in translation journals, please give theEnglish citation ﬁrst, followed by the original foreign-languagecitation [6].REFERENCES[1]G. Eason, B. Noble, and I. N. Sneddon, “On certain integrals ofLipschitz-Hankel type involving products of Bessel functions,” Phil.Trans. Roy. Soc. London, vol. A247, pp. 529–551, April 1955.[2]J. Clerk Maxwell, A Treatise on Electricity and Magnetism, 3rd ed., vol.2. Oxford: Clarendon, 1892, pp.68–73.[3]I. S. Jacobs and C. P. Bean, “Fine particles, thin ﬁlms and exchangeanisotropy,” in Magnetism, vol. III, G. T. Rado and H. Suhl, Eds. NewYork: Academic, 1963, pp. 271–350.[4]K. Elissa, “Title of paper if known,” unpublished.[5]R. Nicole, “Title of paper with only ﬁrst word capitalized,” J. NameStand. Abbrev., in press.[6]Y. Yorozu, M. Hirano, K. Oka, and Y. Tagawa, “Electron spectroscopystudies on magneto-optical media and plastic substrate interface,” IEEETransl. J. Magn. Japan, vol. 2, pp. 740–741, August 1987 [Digests 9thAnnual Conf. Magnetics Japan, p. 301, 1982].[7]M. Young, The Technical Writer’s Handbook. Mill Valley, CA: Univer-sity Science, 1989.[8]S. Xiang, F. Nie, C Zhang, “Learning a Mahalanobis distance metricfor data clustering and classiﬁcation,”in Pattern Recognition, vol. 41,pp. 3600–3612, December 2008.IEEE conference templates contain guidance text for compos-ing and formatting conference papers. Please ensure that alltemplate text is removed from your conference paper prior tosubmission to the conference. Failure to remove the templatetext from your paper may result in your paper not beingpublished.
Figure 10: Face recognition results. First row: Euclidean distance. Second row: GMML method. Third
Row:RDML method. Fourth Row: Robust Algorithm 4.
18Under review as submission to TMLR
8 Conclusion
We introduce a robust metric learning approach that leverages the /lscript2,q-norm distance, oﬀering enhanced
resilience against data outliers and adversarial attacks. Additionally, we present 2D metric learning and
kernel metric learning algorithms, tailored to mitigate the computational challenges associated with eigen-
value decomposition on high-dimensional covariance matrices. Our methods come with a strong theoretical
foundation, ensuring the objective is monotonically increasing. Within each iteration, we obtain a closed-
form optimal solution for 2D and kernel metric learning respectively. In addition, we rigorously establish the
convergence rate of these proposed algorithms. Experiments on diverse real-world datasets are conducted to
validate the eﬀectiveness of our methods. The results highlight the eﬃciency and superior accuracy of our
approaches in addressing a range of practical tasks in comparison with the counterparts.
References
Shunichi Amari and Si Wu. Improving support vector machine classiﬁers by modifying kernel functions.
Neural Networks , 12(6):783–789, 1999.
A. Baccini, P. Besse, and A. de Faguerolles. A l1-norm pca and heuristic approach. International Conference
on Ordinal and Symbolic Data Analysis , pp. 359–368, 1996.
Aurélien Bellet, Amaury Habrard, and Marc Sebban. A survey on metric learning for feature vectors and
structured data. arXiv preprint arXiv:1306.6709 , 2013.
Nicolas Boumal, Pierre-Antoine Absil, and Coralia Cartis. Global rates of convergence for nonconvex opti-
mization on manifolds. IMA Journal of Numerical Analysis , 39(1):1–33, 2019.
Deng Cai, Xiaofei He, and Jiawei Han. Speed up kernel discriminant analysis. The VLDB Journal , 20:21–33,
2011.
Fatih Cakir, Kun He, Xide Xia, Brian Kulis, and Stan Sclaroﬀ. Deep metric learning to rank. In Proceedings
of the IEEE/CVF conference on computer vision and pattern recognition , pp. 1861–1870, 2019.
Ingrid Daubechies. Orthonormal bases of compactly supported wavelets ii. variations on a theme. SIAM
Journal on Mathematical Analysis , 24(2):499–519, 1993.
Jason V Davis, Brian Kulis, Prateek Jain, Suvrit Sra, and Inderjit S Dhillon. Information-theoretic metric
learning. In Proceedings of the 24th international conference on Machine learning , pp. 209–216. ACM,
2007.
Roy De Maesschalck, Delphine Jouan-Rimbaud, and Désiré L Massart. The mahalanobis distance. Chemo-
metrics and intelligent laboratory systems , 50(1):1–18, 2000.
C. Ding, D. Zhou, X. He, and H. Zha. R1-pca: rotational invariant l 1-norm principal component analysis
for robust subspace factorization. In ICML, pp. 281–288. ACM, 2006.
Ronald A Fisher. The use of multiple measurements in taxonomic problems. Annals of eugenics , 7(2):
179–188, 1936.
J. Gao. Robust l1 principal component analysis and its bayesian variational inference. Neural Computation ,
20:555–572, 2008.
Jacob Goldberger, Geoﬀrey E Hinton, Sam Roweis, and Russ R Salakhutdinov. Neighbourhood components
analysis. Advances in neural information processing systems , 17, 2004.
Nicolas Gourier, Daniela Hall, and James L Crowley. Estimating face orientation from robust detection
of salient facial features. In ICPR International Workshop on Visual Observation of Deictic Gestures .
Citeseer, 2004.
Steven CH Hoi, Michael R Lyu, and Rong Jin. A uniﬁed log-based relevance feedback scheme for image
retrieval. IEEE TRANSACTIONS on knowledge and Data Engineering , 18(4):509–524, 2006.
19Under review as submission to TMLR
Leonid Karlinsky, Joseph Shtok, Sivan Harary, Eli Schwartz, Amit Aides, Rogerio Feris, Raja Giryes, and
Alex M Bronstein. Repmet: Representative-based metric learning for classiﬁcation and few-shot object
detection. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pp.
5197–5206, 2019.
Mahmut Kaya and Hasan Şakir Bilge. Deep metric learning: A survey. Symmetry , 11(9):1066, 2019.
Q.KeandT.Kanade. Robustl1normfactorizationinthepresenceofoutliersandmissingdatabyalternative
convex programming. IEEE Conf. Computer Vision and Pattern Recognition , pp. 592–599, 2004.
Martin Koestinger, Martin Hirzer, Paul Wohlhart, Peter M Roth, and Horst Bischof. Large scale metric
learning from equivalence constraints. In Computer Vision and Pattern Recognition (CVPR), 2012 IEEE
Conference on , pp. 2288–2295. IEEE, 2012.
Brian Kulis et al. Metric learning: A survey. Foundations and Trends ®in Machine Learning , 5(4):287–364,
2013.
N. Kwak. Principal component analysis based on l1-norm maximization. IEEE Transactions on Pattern
Analysis and Machine Intelligence , 30:1672–1680, 2008.
Christina Leslie, Eleazar Eskin, and William Staﬀord Noble. The spectrum kernel: A string kernel for svm
protein classiﬁcation. In Biocomputing 2002 , pp. 564–575. World Scientiﬁc, 2001.
Ming Li and Baozong Yuan. 2d-lda: A statistical linear discriminant analysis for image matrix. Pattern
Recognition Letters , 26(5):527–532, 2005.
Daryl Lim, Gert Lanckriet, and Brian McFee. Robust structural metric learning. In Sanjoy Dasgupta
and David McAllester (eds.), Proceedings of the 30th International Conference on Machine Learning ,
volume 28 of Proceedings of Machine Learning Research , pp. 615–623, Atlanta, Georgia, USA, 17–19 Jun
2013. PMLR. URL https://proceedings.mlr.press/v28/lim13.html .
Kai Liu, Lodewijk Brand, Hua Wang, and Feiping Nie. Learning robust distance metric with side information
viaratiominimizationoforthogonallyconstrainedl21-normdistances. In Proceedings of the Twenty-Eighth
International Joint Conference on Artiﬁcial Intelligence , 2019.
Weifeng Liu, Puskal P Pokharel, and Jose C Principe. The kernel least-mean-square algorithm. IEEE
Transactions on signal processing , 56(2):543–554, 2008.
Daniel López-Sánchez, Angélica González Arrieta, and Juan M Corchado. Visual content-based web page
categorization with deep transfer learning and metric learning. Neurocomputing , 338:418–431, 2019.
D. Martin, C. Fowlkes, D. Tal, and J. Malik. A database of human segmented natural images and its
application to evaluating segmentation algorithms and measuring ecological statistics. In Proc. 8th Int’l
Conf. Computer Vision , volume 2, pp. 416–423, July 2001.
Thanh T Ngo, Mohammed Bellalij, and Yousef Saad. The trace ratio optimization problem. SIAM review ,
54(3):545–569, 2012.
Brett Ninness, Håkan Hjalmarsson, and Fredrik Gustafsson. The fundamental role of general orthonormal
bases in system identiﬁcation. IEEE Transactions on Automatic Control , 44(7):1384–1406, 1999.
Arti Patle and Deepak Singh Chouhan. Svm kernel functions for classiﬁcation. In 2013 International
Conference on Advances in Technology and Engineering (ICATE) , pp. 1–9. IEEE, 2013.
Ferdinando S Samaria and Andy C Harter. Parameterisation of a stochastic model for human face identi-
ﬁcation. In Proceedings of 1994 IEEE workshop on applications of computer vision , pp. 138–142. IEEE,
1994.
Bernhard Schölkopf, Alexander Smola, and Klaus-Robert Müller. Kernel principal component analysis. In
International conference on artiﬁcial neural networks , pp. 583–588. Springer, 1997.
20Under review as submission to TMLR
Chunhua Shen, Junae Kim, and Lei Wang. Scalable large-margin mahalanobis distance metric learning.
IEEE transactions on Neural Networks , 21(9):1524–1530, 2010.
Hua Wang, Feiping Nie, and Heng Huang. Robust distance metric learning via simultaneous l1-norm min-
imization and maximization. In International conference on machine learning , pp. 1836–1844. PMLR,
2014.
Qianqian Wang, Quanxue Gao, Xinbo Gao, and Feiping Nie. /lscript2,p-norm based pca for image recognition.
IEEE Transactions on Image Processing , 27(3):1336–1346, 2018. doi: 10.1109/TIP.2017.2777184.
Xun Wang, Xintong Han, Weilin Huang, Dengke Dong, and Matthew R Scott. Multi-similarity loss with
general pair weighting for deep metric learning. In Proceedings of the IEEE/CVF Conference on Computer
Vision and Pattern Recognition , pp. 5022–5030, 2019.
Kilian Q Weinberger, John Blitzer, and Lawrence K Saul. Distance metric learning for large margin nearest
neighbor classiﬁcation. In Advances in neural information processing systems , pp. 1473–1480, 2006.
John Wright, Arvind Ganesh, Shankar Rao, Yigang Peng, and Yi Ma. Robust principal component analysis:
Exact recovery of corrupted. Advances in Neural Information Processing Systems , pp. 116, 2009.
Shiming Xiang, Feiping Nie, and Changshui Zhang. Learning a mahalanobis distance metric for data clus-
tering and classiﬁcation. Pattern Recognition , 41(12):3600–3612, 2008.
EricPXing, MichaelIJordan, StuartJRussell, andAndrewYNg. Distancemetriclearningwithapplication
to clustering with side-information. In Advances in neural information processing systems , pp. 521–528,
2003.
Liu Yang and Rong Jin. Distance metric learning: A comprehensive survey. Michigan State Universiy , 2(2):
4, 2006.
FeiYe, ZhipingShi, andZhongzhiShi. Acomparativestudyofpca, ldaandkernelldaforimageclassiﬁcation.
In2009 International Symposium on Ubiquitous Virtual Reality , pp. 51–54. IEEE, 2009.
PouryaZadeh, ReshadHosseini, andSuvritSra. Geometricmeanmetriclearning. In International conference
on machine learning , pp. 2464–2471. PMLR, 2016.
Daoqiang Zhang and Zhi-Hua Zhou. (2d) 2pca: Two-directional two-dimensional pca for eﬃcient face
representation and recognition. Neurocomputing , 69(1-3):224–231, 2005.
Lei-Hong Zhang, Li-Zhi Liao, and Michael K Ng. Fast algorithms for the generalized foley–sammon discrim-
inant analysis. SIAM journal on matrix analysis and applications , 31(4):1584–1605, 2010.
Lei-Hong Zhang, Li-Zhi Liao, and Michael K Ng. Superlinear convergence of a general algorithm for the
generalized foley–sammon discriminant analysis. Journal of Optimization Theory and Applications , 157:
853–865, 2013.
21