Under review as submission to TMLR
Balancing Model Performance and Rapid Personalization in
Federated Learning with Learning Rate Scheduling
Anonymous authors
Paper under double-blind review
Abstract
Federated learning (FL) is a powerful technique for collaboratively training a single central-
ized model on distributed local data sources. By aggregating model information without
disclosing the local training data, FL preserves data privacy. However, the inherent hetero-
geneity in local data sets challenges the performance of FL techniques, especially when data
is very diverse across local sources. Personalized Federated Learning (PFL) can mitigate
this challenge using multiple models but often requires additional memory and computa-
tion. ThisworkdoesnotproposeanewPFLmethodbutintroduceshowlearningratedecay,
within each local training round, can improve model performance across local data sets after
fine-tuning. We provide theoretical insights and empirical evidence of efficacy across diverse
domains, including vision, text, and graph data. Our extensive experiments demonstrate
that learning rate scheduling alone outperforms other FL methods regarding generaliza-
tion to new data for both new and existing users. Moreover, it performs comparably to
PFL methods, particularly regarding new users, while maintaining similar computation and
memory requirements as FL techniques.
1 Introduction
Federated Learning (FL) is a compelling solution for constructing a shared (global) model from several local
data sources that inherently cannot be exchanged or aggregated (Yang et al., 2019; Kairouz et al., 2021; Li
et al., 2020b; Mahlool & Abed, 2022; Zhang et al., 2021a; Dupuy et al., 2022). Learning without sharing
data becomes particularly crucial when data privacy or security is paramount, as exemplified by healthcare
applications (Li et al., 2020a; Rieke et al., 2020; Wang et al., 2023). FL operates through an iterative
procedure involving rounds of model improvement. These rounds start with distributing the current global
model to local entities (users) and selecting participants to contribute to the model update. The chosen
users participate by training their local copies of the model using their respective data and returning the
updated model. Next, aggregation of the returned models produces a new global model. The described
process represents the typical procedure for FL solutions, which learns only one shared model for all users.
The most widely embraced FL method is FedAvg (McMahan et al., 2017), which computes the new global
model as the parameter-wise average of returned local models.
When users have similar data, a single model can perform well. However, when local data are very diverse,
ensuring good performance across users with a single shared global model can be challenging (Qu et al.,
2022; Caldarola et al., 2022). Recent works (Chen et al., 2022; Tan et al., 2022) argue that alternatively,
the focus should be on Personalized Federated Learning (PFL) methods that output models tailored to the
local data. However, learning additional models can require extra memory and computation, and managing
multiple models in PFL may lead to heightened communication requirements between users, a bottleneck in
real-world applications. We desire a method that can perform well with heterogeneous user data but with a
similar computational cost to FL techniques.
Next, meta-learning has been successfully applied to PFL to address the challenge of diverse user data with-
out requiring additional models during training. Instead of learning multiple models during the federated
training process, meta-learning methods focus on producing a shared model that can quickly adapt to local
1Under review as submission to TMLR
datasets through fine-tuning. This approach significantly reduces the computational and memory overhead
associated with PFL methods. Building on the foundational work by Nichol et al. (2018), which demon-
strated that meta-learning solutions inherently emphasize varying fixedbalances between initial model
success (shared model performance on local datasets) and rapid personalization (personalized model per-
formance after fine-tuning), we propose an enhancement tailored for FL applications. While traditional
meta-learning prioritizes adaptation across a wide distribution of tasks, the context of FL involves a more
constrained task distribution: the users’ local datasets. Due to this domain-specific constraint, focusing more
on initial model success can lead to more prominent personalized model performance after fine-tuning. We
leverage within-round learning rate decay to balance initial model performance and rapid personalization
flexibly. By adjusting the decay hyperparameter, our method enables application-specific emphasis, pro-
viding a customizable approach to optimize performance for varying levels of data heterogeneity. Crucially,
this modification generalizes the widely used FedAvg algorithm (McMahan et al., 2017), maintaining its
computational simplicity and convergence rate (Li et al., 2020c), requiring no additional gradients or models
to be computed or stored. In Section 3.2, we mathematically justify how this flexible balance leads to better
performance across heterogeneous data scenarios, enabling improved outcomes for new and existing users.
Finally, in Section 4, we provide extensive experimental results spanning diverse data sets across vision,
text, and graph applications. We show that within-round learning rate decay enhances FL techniques and
closes remaining performance gaps with PFL methods without the additional computation and communi-
cation overhead required by such methods. Importantly, we consistently observe a 1 to 4 percentage point
improvement in average test set accuracy for new and existing users over FedAvg.
Theorganizationofthisworkisasfollows. First, Section2brieflysummarizesrelatedworkfrompersonalized
federated learning and meta-learning. Second, Section 3 introduces our approach, mathematically justifies
its improved flexibility, and establishes its convergence rate. Finally, Section 4 gives empirical evidence for
performance improvements and computational cost compared with other benchmark methods.
2 Related Work
FederatedLearning(FL)enablescollaborativemodeltrainingacrossdistributeddatasourceswithoutsharing
raw data, preserving user privacy (Yang et al., 2019; Kairouz et al., 2021; Li et al., 2020b). However, data
heterogeneity among users remains a critical challenge, leading to suboptimal global model performance
for individual users. Various approaches have been proposed to address this, ranging from fine-tuning and
meta-learning adaptations to fully personalized federated learning (PFL) techniques.
A simple yet effective strategy for personalization is fine-tuning, where the global model is adjusted using
local user data post-training (Cheng et al., 2021; Chen et al., 2022; Tan et al., 2022). It is necessary to
clarify that we consider fine-tuning separate from PFL solutions, as the additional computation and models
happen after the federated training is completed. While computationally efficient during federated training,
fine-tuning assumes access to sufficient local data, and its success largely depends on the quality of the shared
initialization. Multiple works have found that FedAvg with fine-tuning typically outperforms more recent
meta-learning and PFL methods (Cheng et al., 2021; Matsuda et al., 2023; Chen & Chao, 2021).
Meta-learning methods extend this idea by learning a globally shared model well-suited for rapid person-
alization (Jiang et al., 2019; Chen et al., 2018; Fallah et al., 2020a; Acar et al., 2021). In the context of
FL, FOMAML (Jiang et al., 2019) and Per-FedAvg (Fallah et al., 2020b) have been adapted to optimize a
shared initialization that accelerates convergence during fine-tuning. In addition to applying conventional
meta-learning algorithms to the federated learning context, a variant named Reptile (Nichol et al., 2018)
can be shown to be equivalent to FedAvg under the condition of equally sized local data sets. In this article,
we exclusively consider aggregation with equally weighted users. Therefore, we will use the term FedAvg
to encompass both FedAvg and Reptile and refer to FedAvg as a meta-learning method. The limitations of
meta-learning approaches are that many require additional computation for second-order gradients, and the
initialization often requires fine-tuning to perform well. More recent adaptations of meta-learning for FL
include FedABML (Liu et al., 2023). However, in their experiments, FedABML typically performs around a
single percentage point better than FedAvg with fine-tuning.
2Under review as submission to TMLR
Next, PFL approaches address data diversity by learning personalized models for each user during federated
training (Tan et al., 2023; 2022). Other personalization techniques than meta-learning include cluster-
ing (Mansour et al., 2020; Sattler et al., 2019; Briggs et al., 2020), model mixture (Li et al., 2021a; Mansour
et al., 2020; Marfoq et al., 2021; Zhang et al., 2021b), parameter decoupling (Li et al., 2021b; Arivazhagan
et al., 2019; Collins et al., 2023; Liang et al., 2020), and knowledge distrillation (Lin et al., 2020; Matsuda
et al., 2021; Khalil et al., 2024; Shen et al., 2020). These intricate solutions often include learning a distinct
model for each user throughout training (Li et al., 2021a), sharing only a subset of the entire model globally
(Li et al., 2021b), or treating user data as a mixture of distributions (Marfoq et al., 2021). In general, PFL
methods often require substantial increases in memory and computation to produce and communicate ad-
ditional models during federated training, which challenges scalability and resource efficiency. Furthermore,
several prevailing methods may prove restrictive or inequitable for applications accommodating new users.
For instance, Ditto’s approach (Li et al., 2021a) of training personalized models during federated learning
becomes infeasible for users who do not participate in training. Likewise, FedBN (Li et al., 2021b) and
FedEM (Marfoq et al., 2021), which rely on insights from user data, encounter difficulties when new users
lack sufficient data for tailoring a model to new users.
Importantly, this work focuses on how including within-round learning rate decay can improve FL per-
formance without significant extra computation or the need for additional models. Moreover, unlike the
aforementioned meta-learning applications to FL, the learning rate decay can flexibly emphasize initial
model performance and rapid personalization. We demonstrate that within-round learning rate decay is a
generalization of FedAvg or Reptile, making them particularly relevant baselines for comparison. Several
other works (Zhao et al., 2018; ?; Karimireddy et al., 2021; Reddi et al., 2021) propose to improve the
original FedAvg procedure. However, many of these works improve the global optimization step. Unlike our
work, they do not consider the local learning rate, especially within the communication round. While we do
not propose a PFL method by definition, since fine-tuning occurs after federated training, we include PFL
methods in our comparisons to assess the performance gap between our process and PFL techniques. There
do exist more recent PFL solutions, like Marfoq et al. (2022), but comparison with PFL solutions is not
the main focus of our work. More importantly, experiments demonstrate consistent improvements compared
to FedAvg and FOMAML and close the performance gap with PFL methods with a simple, interpretable
learning rate modification which comes a without additional computational or memory overheads.
3 Methodology
We consider Federated Learning constructed over n= 1,...,Ncommunication rounds, each consisting of
k= 1,...,Klocal update steps. The set C= [1,...,M ]represents the users participating in federated
learning, each with local objective function Fi. Federated learning aims to find the model that minimizes
the average user objective. Note we distinguish Fi, which is evaluated on the entire local data set, from
F(n,k)
i, which is evaluated on data from the k-th local update step in round n. In each round, a subset of
users,S⊆C, participates in the update of the global model, and the case S=Cis full user participation.
We denote the global model at communication round nasθ(n)
g, andθ(n,k)
irepresents the i-th user’s copy
of the shared model after kofKplanned local update steps with learning rate η. This section begins with
introducing our notation for the federated learning process.
Before introducing the proposed method, we provide background information on the similarities and dif-
ferences between the popular existing methods: FedSGD, FedAvg (McMahan et al., 2017), and FOMAML
(Nichol et al., 2018). We believe this viewpoint of existing algorithms is essential for understanding the
derivation and benefits of our proposal. Importantly, we justify that our proposed method can flexibly
balance the goals of initial model success , shared model performance on the local datasets, and rapid
personalization , personalized model performance on local data after fine-tuning. Mathematically, we de-
fine initial model success in Equation 1 as the average user objective with the shared model at the end
of federated training. Similarly, rapid personalization in Equation 2 is the average user objective with the
personalized model, fine-tuned with the local data, after federated training is complete as indicated by the
3Under review as submission to TMLR
superscript (N+ 1).
FIMS =1
MM/summationdisplay
i=1Fi(θ(N)
g) (1)
FRP=1
MM/summationdisplay
i=1Fi(θ(N+1)
i ) (2)
We remark that either of these objectives could be weighted. However, in this work, we focus on an algo-
rithm that performs well for all users and treats all users equally. Note that FIMSis the same objective
as commonly minimized in traditional Federated Learning and FRPfor Personalized Federated Learning
(and meta-learning). We will demonstrate that controlling the application-specific focus between initial
model success and rapid personalization empirically improves personalization and can extend to new users
without sufficient data for fine-tuning. Counter to intuition, we find that placing additional emphasis on
initial model success, relative to previous applications of meta-learning, can improve performance after rapid
personalization. We believe that this is applicable to the majority of federated learning scenarios where some
similarities exist between users. Furthermore, we demonstrate how to maintain the same rate of conver-
gence as FedAvg under certain assumptions while preserving the interpretability of the model performance
trade-off mentioned above.
3.1 Global and Local Updates for Federated Learning
Consider any given communication round. To simplify the notation, we omit the communication round n
from the notation. We define the size Ksequence of loss functions denoted as {F(j)
i}K−1
j=0, whereKis the
number of local update steps. Recall that F(k)
iis the local objective function of the i-th user evaluated on
data from the k-th local update step. Let g(k)
i=∇F(k)
i/parenleftig
θ(k)
i/parenrightig
denote the gradient of user ion thek-th local
update step. Equation 3 defines the standard local update equation for the FedAvg ( K > 1) or FedSGD
(K= 1) procedure, which are produced by users performing stochastic gradient descent for Kupdates.
θ(k)
i=θ(k−1)
i−ηg(k−1)
ifor allk= 1,...,K (3)
AfterK-steps of local training, we aggregate the updated models θ(K)
ior, equivalently, the changes made by
local updates as in Equation 4. The new shared model becomes the averaged element-wise parameters from
the locally trained user models.
θg←1
|S|/summationdisplay
i∈Sθ(K)
i=θg+1
|S|/summationdisplay
i∈S/parenleftig
θ(K)
i−θg/parenrightig
/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
−η×gMethod(4)
Our comparison of various methods will focus on understanding their expressions of the θ(K)
i−θgterm given
in Equation 4. This expression is the change that a user’s locally training made to the shared model. For
the FedAvg procedure, we can use Equation 3 recursively to write
θ(K)
i=θ(0)
i−ηK−1/summationdisplay
j=0g(j)
i (5)
Notingθ(0)
i=θg, the change a user makes with the FedAvg procedure, θ(K)
i−θg, is driven by/summationtextK−1
j=0gj
i.
We refer to this component of a user’s change as the method gradient ,gMethod, due to its formulation
and use in Equation 5. Similarly, other FL methods have a method gradient consisting of the gradients at
local update steps. Equation 6 presents the specific gradients used from Equation 3 for FedSGD, FedAvg
4Under review as submission to TMLR
(McMahan et al., 2017), and FOMAML (Nichol et al., 2018).
gFedSGD =g(0)
i, gFedAvg =K−1/summationdisplay
j=0g(j)
i, gFOMAML =g(K−1)
i (6)
Notably, the above methods result in local changes to the global model based on sums of different local
gradients computed to update the model. In the next section, we demonstrate which and how much of
each local gradient used during local training determines how much emphasis is placed between minimizing
Equation1andEquation2. Furthermore, wediscoverthatwithin-roundlearningratescanflexiblyemphasize
objectives of initial model success and rapid personalization based on the decay used. In Section 4, we show
thatchoosingdecaythatplacesadditionalemphasisonEquation1, relativetoFedAvgandFOMAML,results
in solutions with improved personalized performance, despite Equation 2 being the objective associated with
rapid personalization.
3.2 FedDecay: Generalizing Local Updates With Gradient Decay
Within-RoundLearningRateDecay. FromEquation6, FedSGD,FedAvg, andFOMAMLfullyinclude
or omit gradient terms from the summation. We introduce within-round learning rate decay, FedDecay , to
enable a more general use of the local gradients. Within-round local learning rate decay is a simple, intuitive
modification that allows for flexible, application-specific control over how much local gradients are used in
local training, which determines the emphasis between minimizing Equation 1 and Equation 2. Equation 7
gives exponential within-round learning rate decay, which leads to Equation 8, the method gradient for
FedDecay. Our proposed method generalizes previous work by recovering FedSGD when β= 0and FedAvg
whenβ= 1.
θ(k)
i=θ(k−1)
i−ηβk−1g(k−1)
ifor allk= 1,...,K (7)
gFedDecay =K−1/summationdisplay
j=0βjg(j)
i (8)
Note, a within-round local learning rate of the form βk−1in Equation 7 results in less emphasis on the
successive local gradients for smaller βin Equation 8. Importantly, we next identify that the later local
gradients are associated with rapid personalization. Thus, by introducing within-round local learning rate
decay, we can place more relative emphasis on initial model success.
This work primarily focuses on exponential decay, simplifying the mathematical justification for the benefits
of within-round learning rate decay. Exponential decay allows us to explicitly compute the relative emphasis
between initial model success (minimizing Equation 1) and rapid personalization (minimizing Equation 2).
Our primary theoretical contribution is determining that the within-round learning rate controls the prior-
itization of the above objectives. In Appendix A.1, the coming results for FedDecay are presented more
generally for arbitrary positive sequences. Additionally, Appendix B.2 demonstrates that linear decay can
improve performance.
Balancing Initial Model Success and Rapid Personalization. The justification for FedDecay comes
from a Talyor analysis of the method gradients from Equations 6. As found by Nichol et al. (2018), each
method gradient in Equations 6, in expectation, is approximately the weighted sum of two other gradient
terms: one which promotes initial model success, and the second which prioritizes rapid personalization.
Consider the K-length sequence of loss functions {F(j)
i}K
j=0for thei-th user’s local update. Let ˜g(j−1)
i =
∇F(j−1)
i (θg)and ˜H(j−1)
i =∇2F(j−1)
i (θg)denote the gradient and Hessian, respectively, of the j-th loss
function evaluated instead at the most recent global model. We take expectation over the user iand mini-
batcheskandlfrom the local data. Following the work of Nichol et al. (2018), we refer to those expected
gradient terms E[˜g(k)
i]andE[˜H(k)
i˜g(l)
i]as AvgGrad and AvgGradInner, respectively. First, moving in the
negative direction of AvgGrad attempts to minimize the expected loss across users and data, encouraging the
final shared model to perform well on all user data, otherwise known as initial model success. Second, moving
5Under review as submission to TMLR
in the positive direction of AvgGradInner maximizes the inner product between gradients (as illustrated in
Equation 9 by the chain rule) from distinct mini-batches within the same user. Large inner products indicate
that the gradient will recommend moving in a similar direction regardless of the input data, which helps
facilitate rapid personalization.
E/bracketleftbig˜Hk
i˜gl
i/bracketrightbig
=1
2E/bracketleftbig˜Hk
i˜gl
i+˜Hl
i˜gk
i/bracketrightbig
=1
2E/bracketleftbigg∂
∂θg/parenleftbig
˜gk
i˜gl
i/parenrightbig/bracketrightbigg
(9)
Next, we will show that incorporating within-round learning rate decay allows for a flexible emphasis on each
objective, which can be optimized by tuning the hyperparameters associated with the given decay scheme.
Equation 10 gives the expected method gradient of FedDecay for exponential decay and exists in greater
generality in Section A.1.
E[gFedDecay ]≈/parenleftbigg1−βK
1−β/parenrightbigg
E/bracketleftig
˜g(k)
i/bracketrightig
−/parenleftbigg(1−βK−1)(1−βK)
(1 +β)(1−β)2/parenrightbigg
E/bracketleftig
˜H(k)
i˜g(l)
i/bracketrightig
(10)
Importantly, the inclusion of within-round learning rate decay results in coefficients for each gradient term
of interest, that depend on the decay hyper-parameter β. More relative emphasis will be placed on AvgGrad
whenβis small, and conversely AvgGradInner when βis large.
As stated previously, AvgGrad and AvgGradInner also appear in the expected method gradients of FedSGD,
FedAvg, and FOMAML (Nichol et al., 2018). By comparing the ratio of the weights of AvgGradInner to
AvgGrad for the considered methods, we can assess each method’s relative prioritization of rapid personal-
ization vs. initial model success. See Table 1 and contrast the more flexible ratio of FedDecay with those
of FedSGD, FedAvg, and FOMAML. Notably, FedSGD, FedAvg, and FOMAML have fixed ratios, given K.
On the other hand, the ratio of FedDecay still depends on the choice of βgiving us much greater flexibility
over the balance between initial model success and rapid personalization. Especially in applications where
communication is a bottleneck, Kmay be required to be large. In such applications, methods such as Fe-
dAvg and FOMAML, which place increasing emphasis on K, are forced to prioritize rapid personalization
over initial model success, even if users all had copies of the exact same data. In Section ??, we provide
strong empirical evidence that, in general, placing additional emphasis on initial model success can result in
improvements to performance after personalization.
Method FedSGD FedDecay FedAvg FOMAML
Ratio0
1/parenleftbig
β−βK/parenrightbig
η
1−β2(K−1)η
2(K−1)η
Limit (K→∞)0βη
1−β2∞∞
Table 1: Ratios of coefficients for AvgGradInner (rapid personalization) to AvgGrad (initial model success)
terms for several methods. Choice of βgives FedDecay much greater control over the ratio of emphasis on
the ability to personalize vs. initial model success. Note that we are assuming that β∈(0,1)for FedDecay
since FedSGD ( β= 0) and FedAvg ( β= 1) are already present.
When users possess similar data, a method consisting of only AvgGrad terms (FedSGD) can perform well
across all users. However, in cases where users’ data diverges, an approach prioritizing AvgGradInner terms
may be more suitable. Plausibly, most applications exist between the above two scenarios, especially for
appropriate applications of federated learning. In such cases, a method striking a flexible balance between
AvgGrad and AvgGradInner terms could yield superior performance across a spectrum of statistical data
heterogeneity. Our experimental results in Section ??consistently conclude that some decay improves
personalized performance compared to either no emphasis on rapid personalization (FedSGD) or no decay
(FedAvg). Furthermore, in Appendix B.1 we highlight that the tuned values of βare small for datasets
with obvious similarities between users and greater for datasets contrived to have a larger degree of diversity
between local datasets.
In summary, introducing within-round learning rate decay enables more control over the objective of train-
ing. This additional flexibility allows FedDecay to adapt to the problem-specific data heterogeneity for
6Under review as submission to TMLR
better performance. First, when local datasets are similar, a large amount of decay (small β) still places
some emphasis on rapid personalization that results in improved personalized performance when fine-tuning.
Secondly, when local datasets have some minor similarities, placing the majority of the focus on rapid per-
sonalization, but more emphasis on initial model success with a small amount of decay (large β) than FedAvg
and FOMAML also improves personalized performance. We believe intuitively that having a shared model
that performs well for all users and fine-tunes well is often better than a model that fine-tunes well, but
may not have any initial model success, which is not a prerequisite for the rapid personalization objective in
Equation 2.
Convergence Analysis. Within-round learning rate decay allows for an application-specific hyper-
parameter tuning of the emphasis between initial model success and rapid personalization. Separate from
the purpose of our work, Li et al. (2020c) demonstrate that the convergence of FedAvg on non-independent
and non-identically distributed (i.i.d.) local data sets is achieved with some learning rate at iteration tof the
formηt=αt=c
t+dwherecanddare positive. Note that the local update step kof the communication round
nis equivalent to iteration t=n∗K+k. We remark that this learning rate strategy is not within-round and
does not exist for understanding data heterogeneity. In fact, we argue that this strategy is insufficient for
convergence and balancing initial model success with rapid personalization. Performing federated training
for many communication rounds is needed to guarantee a close-to-optimal objective function value. However,
such decay of the learning rate every iteration places more relative emphasis on rapid personalization with
each communication round. Unfortunately this scheme results in a greater relative emphasis on personaliza-
tion with each addition communication round, similar to how FedAvg and FOMAML were found to place
additional relative emphasis on personalization for many local update steps ( K). Hence, we lose the ability
to prioritize initial model success for users with similar data with decay of the learning rate every iteration.
Additionally, we lose all interpretability about the degree of heterogeneity based on the size of the tuned
values forβ. We no longer are able to infer that applications that perform well with large βhave similar
local datasets (or conversely small β.
Instead, by composing our within-round learning rate decay, with previous decay applied across-round (in-
stead of each iteration), we can maintain the same convergence rate as FedAvg (Li et al., 2020c) while keeping
the relative balance between initial model success and rapid personalization constant across communication
rounds. The resulting learning rate is given by ηt=α⌊t/K⌋β(tmodK)whereβ0̸= 0andβk+1≤βkfor
k= 1,...,K. We extend the previous work Li et al. (2020c) to this modified decay scheme under the same
assumptions. FedDecay converges with complexity of O(N−1)on non-i.i.d. data as total communication
roundsN→∞for both full and partial user participation. Please see Appendix A.2 for additional details
and proofs. Note that we do not believe that the theoretical finding that applying the previous decay scheme
across-round converges in particularly novel, nor do we consider it a primary contribution of our work. How-
ever, we believe that having explicit convergence guarantees for application of our proposal are essential to
creating confidence in its application. Hence, we believe the important takeaway from this section is that
our proposal allows us adapt to application-specific data heterogeneity by adjusting the relative prioriti-
zation between objectives of initial model success and rapid personalization without sacrificing theoretical
convergence.
Assumption 1 (Lipschitz Continuous Gradients) .For all users i∈{1,...,M}, the local objective function
FiisL-smooth. For all vandwin the domain of Fi,
Fi(v)≤Fi(w) + (v−w)T∇Fi(w) +L
2∥v−w∥2
2
Assumption2 (StrongConvexity) .For all users i∈{1,...,M}, the local objective function Fiisµ-strongly
convex. Similarly,
Fi(v)≥Fi(w) + (v−w)T∇Fi(w) +µ
2∥v−w∥2
2
Assumption 3 (Bounded Variance) .Let mini-batch ξ(n,k)be sampled uniformly from the i-th user’s local
data. For all nandk, an upper bound exists on the variance of stochastic gradients in each user i.
E/vextenddouble/vextenddouble/vextenddouble∇F(n,k)
i/parenleftig
θ(n,k)
i,ξ(n,k)
i/parenrightig
−∇Fi/parenleftig
θ(n,k)
i/parenrightig/vextenddouble/vextenddouble/vextenddouble2
≤σ2
i
7Under review as submission to TMLR
whereF(n,k)
iis the average for i-th user’s local loss evaluated on data ξi.
Assumption 4 (Bounded Expected Squared Norm) .The expected squared norm of stochastic gradients is
uniformly bounded. Similarly,
E/vextenddouble/vextenddouble/vextenddouble∇F(n,k)
i(θ(n,k)
i,ξ(n,k)
i)/vextenddouble/vextenddouble/vextenddouble2
≤G2
Here, we consider the more general weighted objective function F=/summationtext
i∈CpiFiand aggregation step given
by Equation 11. Recall that Fiis the average local loss over all of the local data of the i-th user and S⊆C
of fixed size|S|contains the users chosen to update the global model in a given round of Federated Learning.
Sis sampled uniformly without replacement for each round with probabilities pi.
θg←|C|
|S|/summationdisplay
i∈Spiθ(K)
i (11)
Furthermore, let F∗andF∗
idenote the global minimums of the average objective function of users and the
i-th user’s average local loss over their data, respectively. We introduce Γ =F∗−/summationtextM
i=1piF∗
ito represent the
degree to which data sets are non-independent and non-identically distributed. The magnitude of Γreflects
how heterogeneous the data distributions are and Γ→0as the number of local data samples grows only
when data are iid.
Theorem 1 (Convergence Of FedDecay) .Let Assumptions 1 to 4 hold and L,µ, andGbe defined therein
and denote the condition number with κ=L/µ. Choose a positive, locally decaying sequence βk+1≤βk
fork= 1,...,K. With a learning rate for iteration t=nK+k(klocal updates into round n+ 1) of
the formηt=α⌊t/K⌋βtmodKfor positive βj≥βj+1and someαj=c
j+d. Ifαj=3
µβK−1(j+d)where
d= max/braceleftbigg12κ
βK−1,4−2
K/bracerightbigg
then
E/bracketleftig
F(θ(N)
g)/bracketrightig
−F∗≤κ
N+d−2/parenleftig9(B+D)
2µβ2
K−1+(1/K) +d−2
2×E/vextenddouble/vextenddouble/vextenddoubleθ(0)
g−θ∗
g/vextenddouble/vextenddouble/vextenddouble2/parenrightig
(12)
whereB=M/summationdisplay
i=1p2
iσ2
i+ 6LΓ + 2/parenleftbig
G(K−1)β0β−1
K−1/parenrightbig2(13)
andD=|C|−|S|
|S|(|C|−1)(14)
The convergence analysis outlined in Theorem 1 emphasizes that the gap between the optimal solution F∗
and the value F(θ(N)
g)evaluated on the global model, produced by FedDecay after Ntotal communication
rounds, converges to zero as N→ ∞. Akin to the outcomes seen with FedAvg, convergence happens
at rateO(N−1). However, the advantage of FedDecay lies in its ability to achieve this convergence while
accommodating a spectrum of diverse local updates from the sequence {βk}K
k=1. As illustrated in Section 3.2,
incorporating within-round learning rate decay enables a versatile balance between initial model success and
rapid personalization that allow us to adapt to application-specific data heterogeneity. In conclusion, this
enriched flexibility does not have to come at the expense of deteriorating algorithmic performance.
4 Experimental Results
In this section, we comprehensively evaluate our proposed method, FedDecay, alongside other prominent
federated learning techniques, using the benchmark established by Chen et al. (2022). To ensure unifor-
mity, we integrate our approach into their code base available at GitHub1 2. We leverage this established
infrastructure to experiment with identical data sets and models to facilitate a rigorous and fair comparison.
1Original benchmark at https://github.com/alibaba/FederatedScope/tree/Feature/pfl_bench
2Our modifications at https://github.com/JoeLavond/FedDecay/tree/bench
8Under review as submission to TMLR
Data. As discussed in Yuan et al. (2022), generalization in federated learning refers both to new users
(participation gap) and new data for existing users (out-of-sample gap). Our experiments involve holding
out both users and data to study both types of generality in the following manner. For each data set,
we maintain 20 percent of users as a holdout set, thereby simulating the challenge of generalization to new
users. Also, wedivideeachuser’sdataintodistincttraining, validation, andtestingsubsets. Ourexperiments
encompass the various data sets FEMNIST (Caldas et al., 2018), SST2 (Wang et al., 2018; Socher et al.,
2013), and PUBMED (Namata et al., 2012). This diversified selection of data sets empowers us to investigate
performance across varied domains, including vision, text, and graph data. We use the default data settings
chosen by Chen et al. (2022).
•FEMNIST: A 62-way handwritten character classification problem with images of size 28×28. This
sub-sampled version of FEMNIST in Chen et al. (2022) contains 43,400 images from 3,550 authors
as clients.
•SST2: A sentiment classification data set containing 68,200 movie review sentences labeled with
human sentiment. Partitioned into 50 clients using Dirichlet allocation with α= 0.4, it enables the
assessment of text-based applications.
•PUBMED: A graph of 19,717 nodes and 44,338 edges, this data set classifies scientific publications
into three classes. Louvain (Blondel et al., 2008) community partitioning parititons the graph into
five users.
Model. In our experiments, we adhere to the model architectures prescribed by Chen et al. (2022) for
consistency and comparative purposes.
•FEMNIST: We employ a Convolutional Neural Network (CNN) with a hidden size of 2,048. The
model incorporates two convolutional layers with 5×5kernels, followed by max pooling, batch
normalization, ReLU activation, and two dense layers.
•SST2: Our model leverages a pre-trained BERT-Tiny model (Turc et al., 2019) with 2-layer Trans-
former encoders and a hidden size 128.
•PUBMED: We employ the Graph Isomorphism Neural Network (GIN) (Xu et al., 2019), featuring
2-layer convolutions with batch normalization, a hidden size 64, and a dropout rate of 0.5.
Methods. To establish the prowess of FedDecay, we subject it to a rigorous comparison with a range of
federated learning techniques.
•Federated Learning: In this category, we include FedAvg/Reptile (McMahan et al., 2017; Nichol
etal.,2018)andFOMAML(Nicholetal.,2018). Thesemethodsmakeupthemostrelevantbaselines
to our proposal as they all can be seen, like our proposal, as various within-round learning rate
scheduling.
•Personalized Federated Learning: These encompass Ditto (Li et al., 2021a), FedBN (Li et al., 2021b),
FedEM (Marfoq et al., 2021), and pFedMe (T Dinh et al., 2020). Interpret these PFL solutions as an
upper bound on what performance could be for our method as they require additional computation
cost and memory.
Hyperparameters. We extend the hyper-parameter optimization methodology outlined in the original
benchmark paper. Leveraging a grid search technique, we conduct comprehensive explorations, leveraging
early termination and hyperband stopping (Biewald, 2020). Our exhaustive search covers a spectrum of
hyperparameters, as detailed in Table 2.
The final hyperparameters for each run are selected based on the highest average validation accuracy across
users. If runs do not terminate early, they will run for 1000, 500, and 500 epochs for FEMNIST, SST2, and
PUBMED, respectively. Other fixed configurations worth noting are 20 percent partial user participation
9Under review as submission to TMLR
Hyper-parameter Algorithm Data Set Tuning Grid
Local Epochs - -{1,3}
Batch Size - SST2{16,32,64}
Learning Rate - -{0.005,0.01,..., 1.0}
Regularization Rate Ditto, pFedMe -{0.05,0.1,0.2,0.5,0.9}
Meta-learning Step pFedMe -{1,3}
Mixture Number FedEM -{3}
Local Decay FedDecay -{0,0.2,..., 1.0}
Table 2: Hyper-parameter grid search details. If no algorithm or data set is specified, the given hyper-
parameter search will be applied for all.
for FEMNIST and SST2, batch size 32 for FEMNIST, and full-user participation with full-batch training
for PUBMED. To ensure a fair comparison and alignment with other methods, we maintain a fixed learning
rate (α) for FedDecay, while βis the key hyperparameter explored. Fine-tuning happens for one epoch with
the same learning rate αfor all methods. We conduct our experiments on 4 NVIDIA GeForce RTX 3090
GPUs. See Appendix B.1 to analyze FedDecay’s performance under misspecified β.
4.1 Generalization to New and Existing Users
Generalization Performance On New Users. To assess the robustness of the methods in accommo-
dating new users, we introduce the following performance metrics: ¯Acc(average accuracy), ˘Acc(bottom ten
percentile accuracy), and σAcc(standard deviation of accuracy). Average accuracy is the primary perfor-
mance metric, and it is desirable to identify methods that often return large values for ¯Acc, indicating that
the solution performs well for users, on average. In addition, we use the fairness metrics ˘AccandσAccto
understand if solutions are performing well for many users. A fair method consistently returns a large bottom
ten percentile of accuracy and a low standard deviation, which indicates a lower bound on performance for
the 90 percent majority of users and that the solution performs similarly across users. Please note that in the
PUBMED data set comprising only five users, ˘AccandσAccare not applicable due to the limited number of
held-out users. Additionally, we repeat the single-model-based results across multiple seeds in Appendix B.3
to gain insights into result variability and partially assess the sensitivity of our findings to different initial
conditions.
We initiate our analysis by investigating the proficiency of each method in catering to new users. See Table 3
Our approach, FedDecay, notably outperforms all FL methods in terms of average test accuracy for all data
sets. Furthermore, even in the FEMNIST data sets, it is worth highlighting that FedDecay significantly
narrows the performance gap between FL and PFL methods. While personalized methods such as FedEM
and pFedMe exhibit competitive results on FEMNIST, their performance drops noticeably in the SST2
data set. These findings underscore FedDecay’s exceptional ability to generalize to new users across diverse
applications effectively.
Generalization Performance On New Data For Existing Users Turning our attention to the per-
formance of users who participate in the federated learning process, we anticipate that personalized federated
learning methods, characterized by additional memory and computation for learning personalized models,
should outperform FL. The results, presented in Table 4, affirm this expectation. However, among the FL
methods, FedDecay emerges as the front-runner, achieving the highest average and bottom ten percentile
test accuracy across all data sets. Furthermore, FedDecay even secures the highest average accuracy among
all methods on the SST2 data set.
Delving into personalized federated learning techniques, we observe mixed results. Ditto and FedBN struggle
on the SST2 data set, pFedMe faces challenges on PUBMED, and FedEM encounters difficulties on FEM-
NIST. Additionally, it is worth noting that FedDecay consistently outperforms other methods on at least
one data set despite their additional computation and memory requirements. Please refer to Section 4.2 for
a detailed exploration of the cost implications.
10Under review as submission to TMLR
Type MethodFEMNIST (image) SST2 (text) PUBMED (graph)
¯Acc ˘Acc σ Acc¯Acc ˘Acc σ Acc¯Acc ˘Acc σAcc
Ditto 0.5672 0.4444 0.0921 0.4746 0.0000 0.4010 0.2442 - -
Personalized
MethodFedBN 0.9059 0.8302 0.0544 0.8030 0.6667 0.12750.8004 - -
FedEM 0.9175 0.8333 0.0526 0.7404 0.6379 0.2141 0.7879 - -
pFedMe 0.90360.8438 0.0751 0.7785 0.6406 0.1179 0.7932 - -
Single-model
BasedFOMAML 0.8989 0.8113 0.0604 0.7680 0.6667 0.1057 0.7950 - -
FedAvg 0.90550.8491 0.0530 0.7680 0.6667 0.1057 0.7914 - -
FedDecay 0.9152 0.8421 0.0485 0.8101 0.6724 0.10870.8039 - -
Table 3: Generalization to new users who did not participate in federated training after fine-tuning.
FedDecay has the most considerable average test set accuracy ( ¯Acc) of any single-model-based technique
on all data sets, even outperforming personalized methods on SST2 and PUBMED. Note that these PFL
methods are upper bounds, not relevant baselines, due to their higher computational cost and memory
requirements. With five total users for PUBMED, only a single user is held out to evaluate generalization.
Hence, there are no values for the bottom ten percentile ( ˘Acc) or standard deviation ( σAcc) for new users.
Type MethodFEMNIST (image) SST2 (text) PUBMED (graph)
¯Acc ˘Acc σ Acc¯Acc ˘Acc σ Acc¯Acc ˘Acc σ Acc
Ditto 0.9031 0.8333 0.0563 0.5949 0.0417 0.3449 0.8754 0.8465 0.0236
Personalized
MethodFedBN 0.9182 0.8571 0.0548 0.7360 0.4000 0.2292 0.87880.8540 0.0248
FedEM 0.8952 0.8200 0.0806 0.7808 0.5000 0.1845 0.8822 0.8478 0.0322
pFedMe 0.9280 0.8750 0.0694 0.76990.6087 0.1672 0.8666 0.8205 0.0334
Single-model
BasedFOMAML 0.8951 0.8140 0.0636 0.76540.5556 0.1634 0.8614 0.8292 0.0284
FedAvg 0.8851 0.8039 0.0750 0.76540.5556 0.1634 0.8671 0.8342 0.0267
FedDecay 0.8986 0.8214 0.07110.7815 0.5556 0.17270.8722 0.8490 0.0233
Table 4: Generalization to new data for existing users who participated in federated training after fine-
tuning. FedDecay produces the best test set average and bottom ten percentile accuracy of any single-model-
based method. Note that these PFL methods are upper bounds, not relevant baselines, due to their higher
computational cost and memory requirements.
11Under review as submission to TMLR
4.2 Computational and Memory Costs
The computational and communication costs incurred during training are integral to evaluating federated
learning methods. Personalized federated learning methods, in particular, often demand increased computa-
tion and memory resources. In this context, we draw attention to the cost implications of various methods.
As depicted in Figure 1, FedDecay exhibits comparable computational costs to other FL techniques. The cost
of learning rate scheduling is negligible per iteration, and the potential increase in communication rounds
due to decaying updates does not meaningfully affect computation. In our experiments, FedDecay returns an
identical cost to FedAvg for FEMNIST and SST2, which terminate in the same number of epochs. FedDecay
achieves similar or superior results without considerably higher communication and computation costs.
Figure 1: Computational And Memory Costs. Total bytes communication ( top) and total floating point
operations( bottom)performedbythebest-performingrunofeachmethod. FedDecayrequiressimilarcoststo
other FL techniques, like FedAvg. Furthermore, FedDecay incurs considerably lower costs than personalized
methods, especially FedEM and pFedMe.
FedDecay requires substantially less memory and computation than FedEM and pFedMe, the two per-
sonalized methods that occasionally outperformed FedDecay in Section 4.1. Although FedDecay does not
consistently outperform personalized federated learning methods, it is much more computationally efficient.
It often dramatically closes the gap between other FL methods and personalized federated learning solutions.
This realization emphasizes FedDecay’s efficiency in striking a favorable balance between performance and
resource utilization, making it an attractive solution for practical federated learning scenarios.
5 Concluding Remarks
Limitations. While our study offers valuable insights into the performance of our proposed method across
various datasets, we acknowledge certain limitations that open avenues for future exploration and optimiza-
tion. First, our analysis concentrated on a selection of data heterogeneity scenarios, encompassing natural
and partitioned heterogeneity. We acknowledge that our findings may not fully encapsulate the dynamics
present in more extreme non-iid scenarios. In fact, for unusually distance local datasets, we do not believe
that our proposal would offer performance improvements. In Section ??, we find that placing additional
emphasis on initial model success results in greater personalized performance. Our intuition is based on the
12Under review as submission to TMLR
hypothesis that a shared model that performs well for all users and can fine-tune well is often a better initial-
ization that a model that fine-tunes well but may have no initial model success. When users are extremely
difference, it will not be possible to find a model that has any ability to perform well for all users. In this
case, we expect our method to suggest using β= 1(no decay) and recover the FedAvg solution.
Next, we focus mainly on exponential decay to show that scaling local gradient updates allows for balancing
the objectives of initial model success and the ability to personalize rapidly. However, many alternative decay
schemes for learning rates exist, but we have only briefly explored linear decay in Appendix B.2. Future
research may explore these alternative decay schemes to enrich our understanding and potentially enhance
our method’s performance.
Finally, we evaluated our proposed method in isolation without extensively exploring its compatibility with
other state-of-the-art techniques. While this approach enabled us to assess our method’s intrinsic merits,
practicaldeploymentoftenrequirescombiningmultiplestrategiesforoptimalresults. Muchofourtheoretical
work relies on stochastic gradient descent as the optimizer, and we intend to expand our theory to alternative
optimizers in future work.
Conclusion. In summary, this study introduces an unexplored approach to federated learning by in-
corporating within-round learning rate decay to balance the objectives of initial model success and rapid
personalization. This additional flexibility allows FedDecay to adapt, less decay for more considerable user
differences, to the problem-specific data heterogeneity for better performance without changing the rate
of convergence. In Section ??, we consistently demonstrate that some within-round learning rate decay
outperforms both no emphasis on rapid personalization (FedSGD) and no decay (FedAvg). In addition to
consistently better performance than the popular FedAvg procedure, we often return similar metrics to per-
sonalized methods that require additional memory and computation, especially when generalizing to new
users. Notably, within-round learning rate decay does not require additional memory and computationally
requires only a simple grid search to find improved solutions. In summary, we propose a cheap, interpretable
modification to FedAvg that consistently returns a 1-4 percent increase in average test set accuracies.
References
Durmus Alp Emre Acar, Yue Zhao, Ruizhao Zhu, Ramon Matas, Matthew Mattina, Paul Whatmough, and
Venkatesh Saligrama. Debiasing model updates for improving personalized federated training. In Marina
Meila and Tong Zhang (eds.), Proceedings of the 38th International Conference on Machine Learning ,
volume 139 of Proceedings of Machine Learning Research , pp. 21–31. PMLR, 18–24 Jul 2021. URL
https://proceedings.mlr.press/v139/acar21a.html .
Manoj Ghuhan Arivazhagan, Vinay Aggarwal, Aaditya Kumar Singh, and Sunav Choudhary. Federated
learning with personalization layers, 2019. URL https://arxiv.org/abs/1912.00818 .
Lukas Biewald. Experiment tracking with weights and biases, 2020. URL https://www.wandb.com/ . Soft-
ware available from wandb.com.
Vincent D Blondel, Jean-Loup Guillaume, Renaud Lambiotte, and Etienne Lefebvre. Fast unfolding of
communities in large networks. Journal of statistical mechanics: theory and experiment , 2008(10):P10008,
2008.
Christopher Briggs, Zhong Fan, and Peter Andras. Federated learning with hierarchical clustering of local
updates to improve training on non-iid data. In 2020 International Joint Conference on Neural Networks
(IJCNN) , pp. 1–9, 2020. doi: 10.1109/IJCNN48605.2020.9207469.
Debora Caldarola, Barbara Caputo, and Marco Ciccone. Improving generalization in federated learning by
seeking flat minima. In European Conference on Computer Vision , pp. 654–672. Springer, 2022.
Sebastian Caldas, Sai Meher Karthik Duddu, Peter Wu, Tian Li, Jakub Konečn` y, H Brendan McMa-
han, Virginia Smith, and Ameet Talwalkar. Leaf: A benchmark for federated settings. arXiv preprint
arXiv:1812.01097 , 2018.
13Under review as submission to TMLR
Daoyuan Chen, Dawei Gao, Weirui Kuang, Yaliang Li, and Bolin Ding. pfl-bench: A comprehensive bench-
mark for personalized federated learning. Advances in Neural Information Processing Systems , 35:9344–
9360, 2022.
Fei Chen, Mi Luo, Zhenhua Dong, Zhenguo Li, and Xiuqiang He. Federated meta-learning with fast conver-
gence and efficient communication. arXiv preprint arXiv:1802.07876 , 2018.
Hong-You Chen and Wei-Lun Chao. On bridging generic and personalized federated learning, 07 2021.
Gary Cheng, Karan N. Chadha, and John C. Duchi. Fine-tuning is fine in federated learning. ArXiv,
abs/2108.07313, 2021. URL https://api.semanticscholar.org/CorpusID:237142163 .
Liam Collins, Hamed Hassani, Aryan Mokhtari, and Sanjay Shakkottai. Exploiting shared representations
for personalized federated learning, 2023. URL https://arxiv.org/abs/2102.07078 .
Christophe Dupuy, Tanya G. Roosta, Leo Long, Clement Chung, Rahul Gupta, and Salman Avestimehr.
Learnings from federated learning in the real world, 2022. URL https://arxiv.org/abs/2202.03925 .
Alireza Fallah, Aryan Mokhtari, and Asuman Ozdaglar. Personalized federated learning with theoretical
guarantees: A model-agnostic meta-learning approach. Advances in Neural Information Processing Sys-
tems, 33:3557–3568, 2020a.
Alireza Fallah, Aryan Mokhtari, and Asuman Ozdaglar. Personalized federated learning: A meta-learning
approach, 2020b. URL https://arxiv.org/abs/2002.07948 .
Yihan Jiang, Jakub Konečn` y, Keith Rush, and Sreeram Kannan. Improving federated learning personaliza-
tion via model agnostic meta learning. arXiv preprint arXiv:1909.12488 , 2019.
Peter Kairouz, H Brendan McMahan, Brendan Avent, Aurélien Bellet, Mehdi Bennis, Arjun Nitin Bhagoji,
Kallista Bonawitz, Zachary Charles, Graham Cormode, Rachel Cummings, et al. Advances and open
problems in federated learning. Foundations and Trends ®in Machine Learning , 14(1–2):1–210, 2021.
Sai Praneeth Karimireddy, Satyen Kale, Mehryar Mohri, Sashank J. Reddi, Sebastian U. Stich, and
Ananda Theertha Suresh. Scaffold: Stochastic controlled averaging for federated learning, 2021. URL
https://arxiv.org/abs/1910.06378 .
Yasser H. Khalil, Amir H. Estiri, Mahdi Beitollahi, Nader Asadi, Sobhan Hemati, Xu Li, Guojun Zhang,
and Xi Chen. Dfml: Decentralized federated mutual learning, 2024. URL https://arxiv.org/abs/2402.
01863.
Li Li, Yuxi Fan, Mike Tse, and Kuo-Yi Lin. A review of applications in federated learning. Computers
& Industrial Engineering , 149:106854, 2020a. ISSN 0360-8352. doi: https://doi.org/10.1016/j.cie.2020.
106854. URL https://www.sciencedirect.com/science/article/pii/S0360835220305532 .
Tian Li, Anit Kumar Sahu, Ameet Talwalkar, and Virginia Smith. Federated learning: Challenges, methods,
and future directions. IEEE Signal Processing Magazine , 37(3):50–60, 2020b. doi: 10.1109/MSP.2020.
2975749.
Tian Li, Shengyuan Hu, Ahmad Beirami, and Virginia Smith. Ditto: Fair and robust federated learning
through personalization. In International Conference on Machine Learning , pp. 6357–6368. PMLR, 2021a.
Xiang Li, Kaixuan Huang, Wenhao Yang, Shusen Wang, and Zhihua Zhang. On the convergence of fe-
davg on non-iid data. In International Conference on Learning Representations , 2020c. URL https:
//openreview.net/forum?id=HJxNAnVtDS .
Xiaoxiao Li, Meirui JIANG, Xiaofei Zhang, Michael Kamp, and Qi Dou. FedBN: Federated learning on
non-IID features via local batch normalization. In International Conference on Learning Representations ,
2021b. URL https://openreview.net/forum?id=6YEQUn0QICG .
14Under review as submission to TMLR
Paul Pu Liang, Terrance Liu, Liu Ziyin, Nicholas B. Allen, Randy P. Auerbach, David Brent, Ruslan
Salakhutdinov, and Louis-Philippe Morency. Think locally, act globally: Federated learning with local
and global representations, 2020. URL https://arxiv.org/abs/2001.01523 .
Tao Lin, Lingjing Kong, Sebastian U Stich, and Martin Jaggi. Ensemble distillation for robust
model fusion in federated learning. In H. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, and
H. Lin (eds.), Advances in Neural Information Processing Systems , volume 33, pp. 2351–2363. Cur-
ran Associates, Inc., 2020. URL https://proceedings.neurips.cc/paper_files/paper/2020/file/
18df51b97ccd68128e994804f3eccc87-Paper.pdf .
Shiyu Liu, Shaogao Lv, Dun Zeng, Zenglin Xu, Hui Wang, and Yue Yu. Personalized federated learning via
amortized bayesian meta-learning, 2023. URL https://arxiv.org/abs/2307.02222 .
Dhurgham Hassan Mahlool and Mohammed Hamzah Abed. A comprehensive survey on federated learning:
Concept and applications. Mobile Computing and Sustainable Informatics: Proceedings of ICMCSI 2022 ,
pp. 539–553, 2022.
Yishay Mansour, Mehryar Mohri, Jae Ro, and Ananda Theertha Suresh. Three approaches for personaliza-
tion with applications to federated learning, 2020.
Othmane Marfoq, Giovanni Neglia, Aurélien Bellet, Laetitia Kameni, and Richard Vidal. Federated multi-
task learning under a mixture of distributions. In M. Ranzato, A. Beygelzimer, Y. Dauphin, P.S. Liang,
and J. Wortman Vaughan (eds.), Advances in Neural Information Processing Systems , volume 34, pp.
15434–15447. Curran Associates, Inc., 2021. URL https://proceedings.neurips.cc/paper_files/
paper/2021/file/82599a4ec94aca066873c99b4c741ed8-Paper.pdf .
Othmane Marfoq, Giovanni Neglia, Laetitia Kameni, and Richard Vidal. Personalized federated learning
through local memorization, 2022. URL https://arxiv.org/abs/2111.09360 .
Koji Matsuda, Yuya Sasaki, Chuan Xiao, and Makoto Onizuka. Fedme: Federated learning via model
exchange, 2021. URL https://arxiv.org/abs/2110.07868 .
Koji Matsuda, Yuya Sasaki, Chuan Xiao, and Makoto Onizuka. Benchmark for personalized federated
learning. IEEE Open Journal of the Computer Society , PP:1–12, 01 2023. doi: 10.1109/OJCS.2023.
3332351.
Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas.
Communication-efficient learning of deep networks from decentralized data. In Artificial intelligence and
statistics , pp. 1273–1282. PMLR, 2017.
Galileo Namata, Ben London, Lise Getoor, Bert Huang, and U Edu. Query-driven active surveying for
collective classification. In 10th international workshop on mining and learning with graphs , volume 8, pp.
1, 2012.
Alex Nichol, Joshua Achiam, and John Schulman. On first-order meta-learning algorithms. arXiv preprint
arXiv:1803.02999 , 2018.
Zhe Qu, Xingyu Li, Rui Duan, Yao Liu, Bo Tang, and Zhuo Lu. Generalized federated learning via sharpness
aware minimization. In Kamalika Chaudhuri, Stefanie Jegelka, Le Song, Csaba Szepesvari, Gang Niu, and
Sivan Sabato (eds.), Proceedings of the 39th International Conference on Machine Learning , volume 162
ofProceedings of Machine Learning Research , pp. 18250–18280. PMLR, 17–23 Jul 2022. URL https:
//proceedings.mlr.press/v162/qu22a.html .
Sashank Reddi, Zachary Charles, Manzil Zaheer, Zachary Garrett, Keith Rush, Jakub Konečný, Sanjiv
Kumar, and H. Brendan McMahan. Adaptive federated optimization, 2021. URL https://arxiv.org/
abs/2003.00295 .
Nicola Rieke, Jonny Hancox, Wenqi Li, Fausto Milletari, Holger R Roth, Shadi Albarqouni, Spyridon Bakas,
Mathieu N Galtier, Bennett A Landman, Klaus Maier-Hein, et al. The future of digital health with
federated learning. NPJ digital medicine , 3(1):119, 2020.
15Under review as submission to TMLR
Felix Sattler, Klaus-Robert Müller, and Wojciech Samek. Clustered federated learning: Model-agnostic
distributed multitask optimization under privacy constraints. IEEE Transactions on Neural Networks and
Learning Systems , 32:3710–3722, 2019. URL https://api.semanticscholar.org/CorpusID:203736521 .
Tao Shen, Jie Zhang, Xinkang Jia, Fengda Zhang, Gang Huang, Pan Zhou, Kun Kuang, Fei Wu, and Chao
Wu. Federated mutual learning, 2020. URL https://arxiv.org/abs/2006.16765 .
Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher D Manning, Andrew Y Ng, and
Christopher Potts. Recursive deep models for semantic compositionality over a sentiment treebank. In
Proceedings of the 2013 conference on empirical methods in natural language processing , pp. 1631–1642,
2013.
Canh T Dinh, Nguyen Tran, and Josh Nguyen. Personalized federated learning with moreau envelopes.
Advances in Neural Information Processing Systems , 33:21394–21405, 2020.
Alysa Ziying Tan, Han Yu, Lizhen Cui, and Qiang Yang. Towards personalized federated learning. IEEE
Transactions on Neural Networks and Learning Systems , 2022.
Alysa Ziying Tan, Han Yu, Lizhen Cui, and Qiang Yang. Towards personalized federated learning. IEEE
Transactions on Neural Networks and Learning Systems , 34(12):9587–9603, December 2023. ISSN 2162-
2388. doi: 10.1109/tnnls.2022.3160699. URL http://dx.doi.org/10.1109/TNNLS.2022.3160699 .
Iulia Turc, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Well-read students learn better: On the
importance of pre-training compact models. arXiv preprint arXiv:1908.08962 , 2019.
Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel Bowman. GLUE: A
multi-task benchmark and analysis platform for natural language understanding. In Proceedings of the
2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP , pp. 353–
355, Brussels, Belgium, November 2018. Association for Computational Linguistics. doi: 10.18653/v1/
W18-5446. URL https://aclanthology.org/W18-5446 .
Jinbao Wang, Guoyang Xie, Yawen Huang, Jiayi Lyu, Feng Zheng, Yefeng Zheng, and Yaochu Jin. Fedmed-
gan: Federateddomaintranslationonunsupervisedcross-modalitybrainimagesynthesis. Neurocomputing ,
546:126282, 2023. ISSN 0925-2312. doi: https://doi.org/10.1016/j.neucom.2023.126282. URL https:
//www.sciencedirect.com/science/article/pii/S0925231223004058 .
Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka. How powerful are graph neural networks? In
International Conference on Learning Representations , 2019. URL https://openreview.net/forum?id=
ryGs6iA5Km .
Qiang Yang, Yang Liu, Tianjian Chen, and Yongxin Tong. Federated machine learning: Concept and
applications. ACM Transactions on Intelligent Systems and Technology (TIST) , 10(2):1–19, 2019.
Honglin Yuan, Warren Richard Morningstar, Lin Ning, and Karan Singhal. What do we mean by gener-
alization in federated learning? In International Conference on Learning Representations , 2022. URL
https://openreview.net/forum?id=VimqQq-i_Q .
Chen Zhang, Yu Xie, Hang Bai, Bin Yu, Weihong Li, and Yuan Gao. A survey on federated learning.
Knowledge-Based Systems , 216:106775, 2021a. ISSN 0950-7051. doi: https://doi.org/10.1016/j.knosys.
2021.106775. URL https://www.sciencedirect.com/science/article/pii/S0950705121000381 .
Michael Zhang, Karan Sapra, Sanja Fidler, Serena Yeung, and Jose M. Alvarez. Personalized federated
learning with first order model optimization, 2021b. URL https://arxiv.org/abs/2012.08565 .
Yue Zhao, Meng Li, Liangzhen Lai, Naveen Suda, Damon Civin, and Vikas Chandra. Federated learning
with non-iid data. 2018. doi: 10.48550/ARXIV.1806.00582. URL https://arxiv.org/abs/1806.00582 .
16Under review as submission to TMLR
A Supplementary Proofs
A.1 Balancing Initial Model Success and Rapid Personalization
We extend the work of Nichol et al. (2018) to understand how the updates of FedDecay impact initial model
success, rapid personalization, and generalization. Consider the gradient from a sequence of loss functions
{F(j)
i}K−1
j=0whereK∈{z∈Z|z≥2}. For example, the above sequence could be a local objective function
evaluated on different mini-batches. Consider the following update for any sequence of scaling coefficients
{βj|β0̸= 0}K−1
j=0.
θ(k)
i=θ(k−1)
i−ηβk−1×∇F(k−1)
i (θ(k−1)
i )fork= 1,...,K
Letg(j)
i=∇F(j)
i(θ(j)
i)and define ˜g(j)
i=∇F(j)
i(θg)and ˜H(j)
i=∇2F(j)
i(θg)as the gradient and Hessian of
thej-th loss function evaluated at the initial point.
g(j)
i=∇F(j)
i(θ(j)
i)≈∇F(j)
i(θg) +∇2F(j)
i(θg)/parenleftig
θ(j)
i−θg/parenrightig
= ˜g(j)
i+˜H(j)
i/parenleftig
θ(j)
i−θg/parenrightig
= ˜g(j)
i−η˜H(j)
ij−1/summationdisplay
h=0βh∇F(h)
i(θ(h)
i)
≈˜g(j)
i−η˜H(j)
ij−1/summationdisplay
h=0βh˜g(h)
i
Apply the previous expansion to the update of FedDecay.
gFedDecay =θ(K)
i−θg
−η=K−1/summationdisplay
j=0/parenleftigg
θ(j+1)
i−θ(j)
i
−η/parenrightigg
=K−1/summationdisplay
j=0βj∇F(j)
i(θ(j)
i)
≈K−1/summationdisplay
j=0βj/parenleftigg
˜g(j)
i−η˜H(j)
ij−1/summationdisplay
h=0βh˜g(h)
i/parenrightigg
=K−1/summationdisplay
j=0βj˜g(j)
i−ηK−1/summationdisplay
j=0
βj˜H(j)
i(j−1)/summationdisplay
h=0βh˜g(h)
i

E[gFedDecay ]≈K−1/summationdisplay
j=0βj˜g(j)
i−ηK−1/summationdisplay
j=0/parenleftigg
βj˜H(j)
ij−1/summationdisplay
h=0βh˜g(h)
i/parenrightigg
=E/bracketleftig
˜g(j)
i/bracketrightig
K−1/summationdisplay
j=0βj
−E/bracketleftig
˜H(j)
i˜g(h)
i/bracketrightig
ηK−1/summationdisplay
j=0/parenleftigg
βjj−1/summationdisplay
h=0βh/parenrightigg

Hence the following ratio of E/bracketleftig
˜H(j)
i˜g(h)
i/bracketrightig
toE/bracketleftig
˜g(j)
i/bracketrightig
for FedDecay. Let B(k) =/summationtextk−1
j=0βj−1.
RFedDecay =η/summationtextK−1
j=0βjB(j)
B(K)
17Under review as submission to TMLR
Note that these equations do not need to be within-round decay and that some expressions hold more
generally. However, our interest is in addressing our concern that existing meta-learning techniques, which
facilitate rapid personalization, do not require a model to have good initial success.
Exponential decay βj=βjallows for the simplification of the above ratio after using the finite sum formula
for the geometric series, B(k) =1−βk
1−β.
RFedDecay =η
K−1/summationdisplay
j=0βj/parenleftbigg1−βj
1−β/parenrightbigg
×/parenleftbigg1−β
1−βK/parenrightbigg
=ηβ/parenleftbigg(1−βK)(1−βK−1)
(1−β)2(1 +β)/parenrightbigg
×/parenleftbigg1−β
1−βK/parenrightbigg
=ηβ/parenleftbigg1−βK−1
(1−β)(1 +β)/parenrightbigg
=ηβ/parenleftbigg1−βK−1
1−β2/parenrightbigg
A.2 Convergence of FedDecay on Heterogenous Data
Full User Participation. We expand the theoretical work of Li et al. (2020c). Furthermore, we adopt
the following additional notations and use their Lemma 1 and Lemma 2. Let iteration t=nK+1denote the
k-th local update step of communication round n+ 1of federated training. The i-th users model at iteration
tis provided by wi
t. Hence, all previous notations can be converted similarly to wi
t=θ⌊t/K⌋,tmodK
i .
Recall that S⊆Cdenotes the set of users participating in the update of the global model for a given round
nof federated training. Here, S=Cand letpidenote the aggregation weight of the i-th user as introduced
in Section 3.2. We are most interested in assigning equal probability or aggregation weight to all users since
our objective is an improved initialization (for all users).
vi
t+1=wi
t−ηt∇ˆFi(wi
t,ξi
t)
wi
t+1=/braceleftigg
vi
t+1 if(t+ 1) modK̸= 0/summationtextM
i=1pivi
t+1else
Also, we need to define the following aggregated sequences, which are always equivalent under full user
participation. Furthermore, shorthand notation for various gradients is used for simplicity. Note ¯wtis only
accessible when tmodK= 0,¯gt=Egt, and ¯vt+1= ¯wt−ηtgt.
¯vt=M/summationdisplay
i=1pivi
t gt=M/summationdisplay
i=1pi∇Fi(wi
t,ξi
t)
¯wt=M/summationdisplay
i=1piwi
t ¯gt=M/summationdisplay
i=1pi∇Fi(wi
t)
We take the following two lemmas from Li et al. (2020c) and adopt the third to our learning rate scheduling.
Lemma 1. Assume Assumption 1 and 2. If ηt≤1
4L, we have
E/vextenddouble/vextenddouble¯v(t+1)−w∗/vextenddouble/vextenddouble2≤(1−ηt)E∥¯wt−w∗∥2+η2
tE∥gt−¯gt∥2
+ 2E/bracketleftiggM/summationdisplay
i=1pi/vextenddouble/vextenddouble¯wt−wt
i/vextenddouble/vextenddouble2/bracketrightigg
+ 6Lη2
tΓ
Lemma 2. Under Assumption 3, it follows that
E∥gt−¯gt∥2≤M/summationdisplay
i=1p2
iσ2
i
18Under review as submission to TMLR
Lemma 3. Under Assumption 4, a locally decaying, cyclic learning rate of the form ηt=α⌊t/K⌋βtmodK
such thatβt+1≤βtfort= 0,...,K−1satisfies
E/bracketleftiggM/summationdisplay
i=1pi/vextenddouble/vextenddouble¯wt−wi
t/vextenddouble/vextenddouble2/bracketrightigg
≤η2
t/parenleftbig
G(K−1)β−1
K−1/parenrightbig2
Proof.Note that for all t≥0there exists t0≤tsuch thatt−t0≤K−1andwi
t0= ¯wt0for alli∈[1,...,M ]
E/bracketleftiggM/summationdisplay
i=1pi/vextenddouble/vextenddouble¯wt−wi
t/vextenddouble/vextenddouble2/bracketrightigg
=E/bracketleftiggM/summationdisplay
i=1pi/vextenddouble/vextenddouble/parenleftbig
wi
t−¯wt0/parenrightbig
−( ¯wt−¯wt0)/vextenddouble/vextenddouble2/bracketrightigg
≤E/bracketleftiggM/summationdisplay
i=1pi/vextenddouble/vextenddouble/parenleftbig
wi
t−¯wt0/parenrightbig/vextenddouble/vextenddouble2/bracketrightigg
asE∥X−EX∥≤E∥X∥2whereX=wi
t−¯wt0
≤M/summationdisplay
i=1piE/bracketleftigg
(K−1)t−1/summationdisplay
i=t0η2
t/vextenddouble/vextenddouble/vextenddouble∇ˆFi/parenleftbig
wi
t,ξi
t/parenrightbig/vextenddouble/vextenddouble/vextenddouble2/bracketrightigg
as/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddoublet−1/summationdisplay
i=t0ηt∇ˆFi/parenleftbig
wi
t,ξi
t/parenrightbig/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
≤(t−t0)t−1/summationdisplay
i=t0η2
t/vextenddouble/vextenddouble/vextenddouble∇ˆFi/parenleftbig
wi
t,ξi
t/parenrightbig/vextenddouble/vextenddouble/vextenddouble2
≤(K−1)M/summationdisplay
i=1pit−1/summationdisplay
i=t0η2
t0G2
asE/vextenddouble/vextenddouble/vextenddouble∇ˆFi/parenleftbig
wi
t,ξi
t/parenrightbig/vextenddouble/vextenddouble/vextenddouble2
≤G2andηt≤ηt0fort0≤t≤t0+K
≤(K−1)M/summationdisplay
i=1pit−1/summationdisplay
i=t0/parenleftbiggGβ0
βK−1/parenrightbigg2
asηt0≤ηt/parenleftbiggβ0
βK−1/parenrightbigg
fort0≤t≤t0+K
≤η2
t/parenleftbig
G(K−1)β0β−1
K−1/parenrightbig2asM/summationdisplay
i=1pi= 1
The following proves convergence under full user participation S·=C.
Proof.Recall that for all t, under full user participation ¯wt= ¯vt. Let ∆t=E∥¯wt−w∗∥2. From Lemma 1,
2, and 3, it follows that
∆t+1≤(1−ηtµ) ∆t+η2
tB
whereB=M/summationdisplay
i=1p2
iσ2
i+ 6LΓ + 2/parenleftbig
G(K−1)β0β−1
K−1/parenrightbig2
We can assume without loss of generality that βtmodK≤1andβ0= 1. Otherwise
ηt=α⌊t/K⌋βtmodK= ˜α⌊t/K⌋˜βtmodK
19Under review as submission to TMLR
where ˜αt=β0/parenleftig
c
t+d/parenrightig
and ˜βt=βt
β0≤1. Additionally, we can assume that all β’s are positive-valued as we
could reduce Kuntil this is satisfied.
Forηt=α⌊t/K⌋βtmodKwhereαt=c
t+dfor somec>2
µβK−1andd>2−1
Ksuch thatη1≤1
4L.
c
(t/K) +d≤α⌊t/K⌋≤c
(t/K) +d−1
⇒cβK−1
(t/K) +d≤ηt≤c
(t/K) +d−1
asβK−1≤βtmodK≤1
By induction, we prove ∆t≤v
(t/K) +d−2where
v= max/braceleftbiggc2B
βK−1cµ−2,[(1/K) +d−2] ∆ 1/bracerightbigg
Note thatt= 1holds trivially by the definition of v. Assuming the conclusion holds for some t, then
∆t+1≤(1−ηtµ) ∆t+η2
tB
≤/parenleftbigg
1−βK−1cµ
(t/K) +d/parenrightbigg/parenleftbiggv
(t/K) +d−2/parenrightbigg
+/parenleftbiggc
(t/K) +d−1/parenrightbigg2
B
by the induction hypothesis, 1−ηtµ≤1−βK−1cµ
(t/K) +d,
andηt≤/parenleftbiggc
(t/K) +d−1/parenrightbigg
≤/parenleftbigg
1−βK−1cµ
(t/K) +d/parenrightbigg/parenleftbiggv
(t/K) +d−2/parenrightbigg
+c2B
[(t/K) +d] [(t/K) +d−2]
as(t/K) +d−2>(1/K) + 2−(1/K)−2 = 0
⇒[(t/K) +d] [(t/K) +d−2]≤[(t/K) +d−1]
Lettinga=1
[(t/K) +d] [(t/K) +d−2], we continue with the previous quantity.
=a/parenleftbig
[(t/K) +d−2]v+c2B−[cµβK−1−2]v/parenrightbig
≤a/parenleftig
[(t/K) +d−2]v+c2B−[cµβK−1−2]/bracketleftbiggc2B
βK−1cµ/bracketrightbigg/parenrightig
asβK−1cµ−2>0andv≤c2B
βK−1cµ
=[(t/K) +d−2]v
[(t/K) +d] [(t/K) +d−2]
=v
(t/K) +d
≤v
(t/K) +d/parenleftigg
(t/K) +d
(t/K) +d−/parenleftbig
2 +1
K/parenrightbig/parenrightigg
=v
(t/K) +d−/parenleftbig
2 +1
K/parenrightbig
=v/parenleftbigt+1
K/parenrightbig
+d−2
20Under review as submission to TMLR
Then byL-smoothness of F(·)
E[F( ¯wt)−F∗]≤L
2∆t≤L
2/parenleftbiggv
(t/K) +d−2/parenrightbigg
Specifically, if we choose the constants to be set as:
c=3
µβK−1−2andd= max/braceleftbigg12L
µβK−1,4−2
K/bracerightbigg
then,
α1=c
d+ 1<c
d=3
µβK−1d≤3
12L+µβK−1≤1
4L
asd≥12L
µβK−1
v= max/braceleftbiggc2B
βK−1cµ−2,[(1/K) +d−2] ∆ 1/bracerightbigg
≤c2B
βK−1cµ−2+ [(1/K) +d−2] ∆ 1
=c2B+ [(1/K) +d−2] ∆ 1
asc=3
µβK−1
=/parenleftbigg3
µβK−1/parenrightbigg2
B+ [(1/K) +d−2] ∆ 1
=2
µ/parenleftbigg9B
2µβ2
K−1+(1/K) +d−2
2∆1/parenrightbigg
E[F( ¯wt)−F∗]≤L
2/parenleftbiggv
(t/K) +d−2/parenrightbigg
≤κ
(t/K) +d−2/parenleftbigg9B
2µβ2
K−1+(1/K) +d−2
2∆1/parenrightbigg
Partial User Participation. Here, we focus on the case where the random set of users at iteration t(St)
of size|S|is selected to update the global model. Consider when the central server forms S·by sampling
uniformly without replacement. We modify the definition of wtto incorporate the new averaging scheme.
wi
t+1=/braceleftigg
vi
t+1 if(t+ 1) modK̸= 0/summationtext
i∈St+1piM
|S|vi
t+1else
We rely on the following previous work by Li et al. (2020c).
Lemma 4. Ift+ 1 modK= 0andS·is sampled uniformly without replacement, then
ESt(¯vt+1) = ¯vt+1
Lemma 5. Ift+ 1 modK= 0,S·is sampled uniformly without replacement, pi=1
nfor alli∈[1,...,M ],
andηt=α⌊t/K⌋βtmodKwhere both αjandβjare non-increasing, then
ESt∥¯vt+1−¯wt+1∥2≤η2
t/parenleftbiggM−|St|
K(M−1)/parenrightbigg
(GKβ 0βK−1)2
Proof.Replaceηt0≤2ηtwithηt0≤ηt/parenleftig
β0
βK−1/parenrightig
in the original proof.
21Under review as submission to TMLR
The following proves convergence under partial user participation in updating the global model. This proof
completes Theorem 1.
Proof.
ESt+1∥¯wt+1−w∗∥2
=ESt+1∥¯wt+1−¯vt+1+ ¯vt+1−w∗∥2
=ESt+1∥¯wt+1−¯vt+1∥2
+ESt+1∥¯vt+1−w∗∥2+ 2ESt+1⟨¯wt+1−¯vt+1,¯vt+1−w∗⟩
=ESt+1∥¯wt+1−¯vt+1∥2+ESt+1∥¯vt+1−w∗∥2
The last equality follows from Lemma 4. Next, by Lemma 5, we have
E∥¯wt+1−w∗∥2≤

(1−ηtµ)E∥¯wt−w∗∥2+ηtB
ift+ 1 modK̸= 0
(1−ηtµ)E∥¯wt−w∗∥2+ηt(B+D)
ift+ 1 modK= 0
Furthermore, the second bound holds for all tsinceD > 0. Next, similar to our proof under full user
participation:
•Assume without loss of generality that βtmodK≤1andβ0= 1.
•ηt=α⌊t/K⌋βtmodKwhereαj=c
t+dfor somec>2
µβK−1andd>2−1
K.
Then ∆t≤v
(t/K) +d−2wherev= max/braceleftbiggc2(B+D)
βK−1cµ−2,[(1/K) +d−2] ∆ 1/bracerightbigg
.
Hence E[F( ¯wt)]−F∗≤L
2∆t≤L
2/parenleftbiggv
(t/K) +d−2/parenrightbigg
.
Withc=3
µβK−1andd= max/braceleftbigg12L
µβK−1,4−2
K/bracerightbigg
,
E[F( ¯wt)−F∗]≤κ
(t/K) +d−2/parenleftig9(B+D)
2µβ2
K−1+/parenleftbigg(1/K) +d−2
2/parenrightbigg
∆1/parenrightig
B Supplementary Results
B.1 Sensitivity Analysis of FedDecay
FedDecay demonstrates sensitivity to the hyper-parameter βchoice; see Table 5. Specifically, in the case of
the FEMNIST data set, runs with β= 0.8were prematurely halted due to hyperband stopping, indicating
inferiorperformancecomparedtosmaller βchoices. Conversely,theremaining βvaluesimprovedaccuracyfor
newandexistingusers. Notably, theFEMNISTdataset, comprisedofhandwrittencharacterscontributedby
different authors, showcases inherent data heterogeneity. This real-world example underscores the presence
of substantial user similarities, owing to the shared language in which all characters are written.
This trend aligns with our assertion in Section 3.2, where we indicated that prioritizing AvgGrad terms
(via smaller βvalues) would be beneficial in cases where users share similarities. Consequently, we observe
FedSGD outperforming FedAvg in this context. However, FedSGD, which does not emphasize AvgGradInner
22Under review as submission to TMLR
FEMNIST (image) SST2 (text) PUBMED (graph)
Method βExisting ¯AccNew ¯AccExisting ¯AccNew ¯AccExisting ¯AccNew ¯Acc
FedSGD 0.0 88.51 90.55 73.60 80.30 86.70 79.14
FedDecay 0.2 89.86 91.52 67.01 59.02 85.67 79.68
FedDecay 0.4 89.74 90.77 69.42 67.26 87.22 80.39
FedDecay 0.6 89.76 90.93 78.15 81.01 86.65 79.86
FedDecay 0.8 Hyperband Stopped 74.64 76.14 86.59 79.32
FedAvg 1.0 87.91 89.78 76.54 76.80 86.29 79.50
Table 5: Performance of FedDecay under misspecified values for decay coefficient, β.
Figure 2: Alternative Without-Round Decay Scheme Performance. Linear decay scheme can also provide
improved performance over FedAvg. Within-round decay in general is an option for improving performance
without additional computation or memory cost.
(generalization, rapid personalization), is beaten by FedDecay. Here, we observe that having a more flexible
balance on initial model success, generalization, and fast personalization results in better performance for
various choices of β.
Unlike FEMNIST, heterogeneous users are created from SST2 by partitioning data into 50 clients using
Dirichlet allocation with α= 0.4. Many extreme non-iid data sets exist, but α= 0.4results in reasonably
non-iid users. Revisiting the claim discussed in our Section 3.2, we anticipate that an increased emphasis
(achieved via larger βvalues) on AvgGradInner is required as non-iid user diversity grows. In general, larger
values ofβperform better on SST2. While FedSGD demonstrates superior test-set performance compared to
FedAvg, its validation-set accuracy lags behind FedAvg’s, preventing it from securing the best run on SST2
for FedAvg in Section 4.1. More importantly, FedDecay balances AvgGrad and AvgGradInner terms, yielding
significantly improved metrics over FedAvg. Notably, FedDecay still has the best overall performance among
the three methods. Lastly, in the case of the PUBMED data set, our method’s performance seems resilient
to the choice of β. However, a straightforward grid search enhances performance for new and existing users
over FedAvg and FedSGD.
B.2 Linear Within-Round Learning Rate Decay
Inthissection, weexplorethepotentialofalternativedecayschemeswithintheFedDecayframework. Results
in Section 3.2 allow for more general sequences than exponential decay. While exponential decay has been
a focus, we believe other strategies for scaling gradient emphasis during federated training could enhance
performance by their balance between initial model success, generalization, and rapid personalization. We
expand our analysis to include the use of linear decay for FedDecay. We define linear decay as βj=
max{1−j(1−β),0}, where 1−βis employed for consistency aligning with FedSGD ( β= 0) and FedAvg
(β= 1). Figure 2 illustrates the average test set accuracy for new and existing users across different decay
schemes.
23Under review as submission to TMLR
It is evident from the results that both exponential and linear decay schemes yield performance improve-
ments over FedAvg. While linear decay performs slightly worse than FedAvg on the new PUBMED user,
it demonstrates robust performance on FEMNIST and SST2. These findings underscore the potential for
alternative decay schemes to enhance the overall model performance within the federated learning paradigm.
We emphasize that decay can be an effective tool for improving performance without additional cost.
B.3 Robustness of FedDecay to Choice of Seed
We address conducting a series of experiments to ensure the robustness of our findings against the selection
of random seeds. Given the constraints of our computational resources, we focus on replicating the less
computational FL methods using three distinct fixed seeds. We chose FEMNIST and PUBMED to have one
example of full and partial user participation. We present the averaged top-run metrics for new and existing
users across the FEMNIST and PUBMED data sets in Table 6 and Table 7. Notably, the FedDecay approach
consistently achieves the highest average accuracy among the FL algorithms, catering to new and existing
users. Moreover, it demonstrates exceptional performance regarding the best ten-percentile accuracy for
existing users. This reinforces the reliability and generalizability of our proposed FedDecay method.
Existing Users New Users
Method ¯Acc ˘Acc σ Acc¯Acc ˘Acc σ Acc
FOMAML 0.8971 0.8223 0.0687 0.90440.8371 0.0578
FedAvg 0.8948 0.8227 0.0701 0.9095 0.8318 0.0563
FedDecay 0.8993 0.8285 0.06880.9127 0.8294 0.0545
Table 6: Generalization metrics for new and existing users on the FEMNIST (image) data set. Values
reported are the average metric for each single-model-based method’s top run across several seeds. FedDecay
produces the maximum average test set accuracy on new and existing users.
Existing Users New Users
Method ¯Acc ˘Acc σ Acc¯Acc ˘Acc σAcc
FOMAML 0.8597 0.8234 0.0293 0.7855 - -
FedAvg 0.8666 0.8313 0.0328 0.7914 - -
FedDecay 0.8704 0.8420 0.02440.7950 - -
Table 7: Generalization metrics for new and existing users on the PUBMED (graph) data set. Values
reported are the average metric for each single-model-based method’s top run across several seeds. FedDecay
produces the maximum average test set accuracy on new and existing users. With five total users, only a
single user is held out to evaluate generalization. Hence, there are no values for the bottom ten percentile
(˘Acc) or standard deviation ( σAcc) for new users.
B.4 Method Hyper-parameters After Tuning
We provide the hyperparameter configurations for all methods that produce the top average validation set
accuracy. These hyperparameter configurations are then used to compute test set metrics for our main
experiments.
24Under review as submission to TMLR
Method Local Epochs ( K) Batch Size Learning Rate ( α)Regularization Rate Meta-learning Steps Local Decay ( β)
Ditto 3 - 0.10 0.50 - -
FedBN 3 - 0.01 - - -
FedEM 3 - 0.10 - - -
pFedMe 3 - 0.50 0.05 3.0 -
FOMAML 3 - 0.50 - - -
FedAvg 1 - 0.10 - - -
FedDecay - Exponential 3 - 0.05 - - 0.2
FedDecay - Linear 3 - 0.10 - - 0.6
Table 8: Main experiment hyper-parameters for all methods after tuning on FEMNIST
Method Local Epochs ( K) Batch Size Learning Rate ( α)Regularization Rate Meta-learning Steps Local Decay ( β)
Ditto 3 16.0 0.05 0.8 - -
FedBN 3 64.0 0.10 - - -
FedEM 3 16.0 0.05 - - -
pFedMe 3 64.0 0.05 0.8 3.0 -
FOMAML 3 16.0 0.05 - - -
FedAvg 3 16.0 0.05 - - -
FedDecay - Exponential 3 16.0 0.05 - - 0.6
FedDecay - Linear 3 16.0 0.05 - - 0.4
Table 9: Main experiment hyper-parameters for all methods after tuning on SST
Method Local Epochs ( K) Batch Size Learning Rate ( α)Regularization Rate Meta-learning Steps Local Decay ( β)
Ditto 1 - 0.005 0.1 - -
FedBN 3 - 0.005 - - -
FedEM 3 - 0.500 - - -
pFedMe 3 - 0.500 0.5 1.0 -
FOMAML 3 - 0.500 - - -
FedAvg 1 - 0.500 - - -
FedDecay - Exponential 3 - 0.500 - - 0.4
FedDecay - Linear 3 - 0.500 - - 0.4
Table 10: Main experiment hyper-parameters for all methods after tuning on PUBMED
25