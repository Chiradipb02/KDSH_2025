Published in Transactions on Machine Learning Research (01/2024)
AmbientFlow: Invertible generative models from incomplete,
noisy measurements
Varun A. Kelkar varun.kelkar@analog.com
University of Illinois at Urbana-Champaign, Urbana, IL 61801
Currently at Analog Devices, Inc., Boston, MA 02110
Rucha M. Deshpande r.deshpande@wustl.edu
Washington University in St. Louis, St. Louis, MO 63130
Arindam Banerjee arindamb@illinois.edu
University of Illinois at Urbana-Champaign, Urbana, IL 61801
Mark A. Anastasio maa@illinois.edu
University of Illinois at Urbana-Champaign, Urbana, IL 61801
Reviewed on OpenReview: https: // openreview. net/ forum? id= txpYITR8oa
Abstract
Generative models have gained popularity for their potential applications in imaging science,
such as image reconstruction, posterior sampling and data sharing. Flow-based generative
models are particularly attractive due to their ability to tractably provide exact density
estimates along with fast, inexpensive and diverse samples. Training such models, however,
requires a large, high quality dataset of objects. In applications such as computed imaging,
it is often difficult to acquire such data due to requirements such as long acquisition time
or high radiation dose, while acquiring noisy or partially observed measurements of these
objects is more feasible. In this work, we propose AmbientFlow, a framework for learning
flow-based generative models directly from noisy and incomplete data. Using variational
Bayesianmethods, anovelframeworkforestablishingflow-basedgenerativemodelsfromnoisy,
incomplete data is proposed. Extensive numerical studies demonstrate the effectiveness of
AmbientFlow in learning the object distribution. The utility of AmbientFlow in a downstream
inference task of image reconstruction is demonstrated.
1 Introduction
Generative models have become a prominent focus of machine learning research in recent years. Modern
generative models are neural network-based models of unknown data distributions learned from a large
number of samples drawn from the distribution. They ideally provide an accurate representation of the
distribution of interest and enable efficient, high-quality sampling and inference. Most modern generative
models are implicit, i.e. they map a sample from a simple, tractable distribution such as the standard normal,
to a sample from the distribution of interest. Popular generative models for image data distributions include
variational autoencoders (VAEs), generative adversarial networks (GANs), normalizing flows and diffusion
probabilistic models, among others (Kingma et al., 2019; Goodfellow et al., 2020; Kingma & Dhariwal, 2018;
Hoet al., 2020). Recently, many of these models have been successful in synthesizing high-quality perceptually
realistic images from the underlying distribution.
Generative models have also been investigated for applications in imaging science. For example, computed
imaging systems such as computed tomography (CT) or magnetic resonance imaging (MRI) rely on computa-
tional reconstruction to obtain an estimate of an object from noisy or incomplete imaging measurements.
Generative models have been investigated for their use as priors in image reconstruction in order to mitigate
1Published in Transactions on Machine Learning Research (01/2024)
the effects of data-incompleteness or noise in the measurements. While GANs have been explored for this
purpose (Bora et al., 2017; Menon et al., 2020; Kelkar & Anastasio, 2021), they suffer from shortcomings
such as inadequate mode coverage (Thanh-Tung & Tran, 2020), insufficient representation capacity (Karras
et al., 2020; Bora et al., 2017) and misrepresentation of important domain-specific statistics (Kelkar et al.,
2023a). On the other hand, invertible generative models (IGMs), or normalizing flows offer exact density
estimates, tractable log-likelihoods and useful representations of individual images (Dinh et al., 2016; 2014;
Kingma & Dhariwal, 2018; Kelkar et al., 2021), making them more reliable for downstream inference tasks in
imaging science (Asim et al., 2020; Jalal et al., 2021a). These models have shown potential for use in tasks
such as image reconstruction, posterior sampling, uncertainty quantification and anomaly detection (Kelkar
et al., 2021; Asim et al., 2020; Khorashadizadeh et al., 2023; Jalal et al., 2021a; Zhao et al.).
Although IGMs are attractive for imaging applications, training them requires a large dataset of objects
or high-quality image estimates as a proxy for the objects. Building such a dataset is challenging since
acquiring a complete set of measurements to uniquely specify each object can be infeasible. Therefore, it is of
interest to learn an IGM of objects directly from a dataset of noisy, incomplete imaging measurements. This
problem was previously addressed in the context of GANs via the AmbientGAN framework, which augments
a conventional GAN with the measurement operator (Bora et al., 2018; Zhou et al., 2022). It consists of
generator and discriminator networks that are jointly optimized via an adversarial training strategy. Here,
the generator attempts to synthesize synthetic objects that produce realistic measurements. The real and
synthetic object distributions are then compared indirectly via a discriminator that distinguishes between real
measurements and simulated measurements of the synthetic objects. This is fundamentally different from the
training procedure of IGMs, which directlycomputes and maximizes the log-probability of the training data
samples. Therefore, ideas from the AmbientGAN framework cannot be easily adapted to train an IGM of
objects when only incomplete measurements is available.
The key contributions of this work are as follows. First a new framework named AmbientFlow is developed
for training IGMs using noisy, incomplete measurements. Second, the accuracy of the object distribution
recovered via AmbientFlow is theoretically analyzed under prescribed ideal conditions using compressed
sensing. Next, numerical studies are presented to demonstrate the effectiveness of the proposed method on
several different datasets and measurement operators. Finally, the utility of AmbientFlow for a downstream
Bayesian inference task is illustrated using a case study of image reconstruction from simulated stylized MRI
measurements.
The remainder of this manuscript is organized as follows. Section 2 describes the background of invertible
generative models, computed imaging systems and image reconstruction from incomplete measurements.
Section 3 describes the notation used and the proposed approach. Section 4 describes the setup for the
numerical studies, with the results being presented in Section 5. Finally, the discussion and conclusion is
presented in Section 6.
2 Background
Invertible generative models. Invertible generative models (IGMs) or flow-based generative models, are
a class of generative models that employ an invertible neural network (INN) to learn an implicit mapping
from a simple distribution such as an independent and identically distributed (iid) Gaussian distribution
to the data distribution of interest. The INN is a bijective mapping Gθ:Rn→Rnconstructed using a
composition of Lsimpler bijective functions gi:Rn→Rn, with
h(i)=gi(h(i−1)) = (gi◦gi−1◦···◦g1)(z),0<i≤L,z,h(i)∈Rn, (1)
andx=Gθ(z) =h(L). As a consequence of bijectivity, the probability distribution function (PDF) pθofx
represented by the IGM can be related to the PDF qzofzas:
pθ(x)·|det∇zGθ(z)|=qz(z). (2)
In order the establish the IGM, a dataset D={x(i)}D
i=1is used, where x(i)are assumed to be independent
draws from the unknown true distribution qx. The INN is then trained by minimizing the following negative
2Published in Transactions on Machine Learning Research (01/2024)
log-likelihood objective over the training dataset D:
L(θ) =−D/summationdisplay
i=1logpθ(x(i)) =D/summationdisplay
i=1/bracketleftig
logqz(z(i))−log|det∇zGθ(z(i))|/bracketrightig
,z(i)=G−1
θ(x(i)). (3)
Minimizing the above loss function is equivalent to minimizing the Kullback–Leibler (KL) divergence
DKL(qx∥pθ):=Ex∼qx[logqx(x)−logpθ(x)]betweenpθand the true data distribution qx. Most invertible
generative models utilize a specialized architecture in order to guarantee invertibility of the constituent
functionsgiand tractable computation of the Jacobian loss term log|det∇zGθ(z)|. Popular building blocks
of such an architecture are affine coupling layers (Dinh et al., 2016), random permutations (Dinh et al., 2014)
and invertible 1×1convolutions (Kingma & Dhariwal, 2018).
Image reconstruction from incomplete imaging measurements. Many computed imaging systems
can be modeled using an imaging equation described by the following linear system of equations:
g=H˜f+n, (4)
where ˜f∈Rnis approximates the object to-be-imaged, H∈Rm×n, known as the forward model, is a linear
operator that models the physics of the imaging process, n∈Rm,n∼qnmodels the measurement noise,
andg∈Rmare the measurements of the object. Often, His ill-conditioned or rank deficient, in which
case the measurements gare not sufficient to form a unique and stable estimate ˆfof the object ˜f, and prior
knowledge about the nature of ˜fis needed. Traditionally, one way to incorporate this prior information is to
constrain the domain of H. For example, compressed sensing stipulates that if the true object is k-sparse
after a full-rank linear transformation Φ∈Rl×n, l≥n, then the object can be stably estimated if for all
vectors v∈Rnthat arek-sparse in the transform domain Φ,Hsatisfies the restricted isometry property
(RIP) (Candes et al., 2006):
Definition 2.1 (Restricted isometry property) .Fors∈N, define the restricted isometry constant (RIC) δs
as the smallest constant that satisfies
(1−δs)∥v∥2
2≤∥Hv∥2
2≤(1 +δs)∥v∥2
2, (5)
for all vsuch that∥Φv∥0≤s.His said to satisfy the restricted isometry property for all vsuch that
∥Φv∥0≤k, ifδk+δ2k+δ3k<1(Candes et al., 2006).
3 Approach
In this section, an AmbientFlow method is proposed for obtaining an IGM of objects from a dataset of
measurements. The following preliminary notation will be used in the remainder of this paper.
Notation. Letqf,qgandqndenote the unknown true object distribution to-be-recovered, the true
measurement distribution and the known measurement noise distribution, respectively. Let D={g(i)}D
i=1be
a dataset of independent and identically distributed (iid) measurements drawn from qg. LetGθ:Rn→Rn
be an INN. Let pθbe the distribution represented by Gθ, i.e. given a latent distribution qz=N(0,In),
Gθ(z)∼pθforz∼qz. Also, let ψθbe the distribution of synthetic measurements, i.e. for f∼pθ,
Hf+n∼ψθ. Letpθ(f|g)∝qn(g−Hf)pθ(f)denote the posterior induced by the learned object distribution
represented by Gθ. LetΦ∈Rl×n, l≥nbe a full-rank linear transformation (henceforth referred to as a
sparsifying transform). Also, let Sk={v∈Rns.t.∥Φv∥0≤k}be the set of vectors k-sparse with respect
toΦ. SinceΦis full-rank, throughout this work we assume without the loss of generality, that ∥Φ+∥2≤1,
whereΦ+is the Moore-Penrose pseudoinverse of Φ. Throughout the manuscript, we also assume that qfis
absolutely continuous with respect to pθ, andqgis absolutely continuous with respect to ψθ.
Conventionally, according to the discussion below Eq. (3), DKL(qf∥pθ)would have to be minimized in order to
train the IGM to estimate qf. However, in the present scenario, only samples from qgare available. Therefore,
we attempt to minimize the divergence DKL(qg∥ψθ), and show that for certain scenarios of interest, this
3Published in Transactions on Machine Learning Research (01/2024)
is formally equivalent to approximately minimizing a distance between qfandpθ. However, computing
DKL(qg∥ψθ)is non-trivial because a direct representation of ψθ(g)that could enable the computation of
logψθ(g)is not available. Fortunately, a direct representation of pθis available via Gθ, which can be
used to compute logpθ(f)for a given f∈Rn, using Eq. (2). Therefore, an additional INN, known as the
posterior network hϕ(·;g) :Rn→Rnis introduced that represents the model posterior pϕ(f|g)designed to
approximate pθ(f|g)when jointly trained along with Gθ. The posterior network hϕis designed to take two
inputs – a new latent vector ζ∼qζ=N(0,In), and an auxiliary conditioning input g∼qgfrom the training
dataset, to produce hϕ(ζ;g)∼pϕ(f|g). The following theorem establishes a loss function that minimizes
DKL(qg∥ψθ)using the posterior network, circumventing the need for direct access to ψθ(g), or samples of
true objects from qf.
Theorem 3.1. Lethϕbe such that pϕ(f|g)>0overRn. Minimizing DKL(qg∥ψθ)is equivalent to maximizing
the objective function L(θ,ϕ)overθ,ϕ, whereL(θ,ϕ)is defined as
L(θ,ϕ) =Eg∼qg/bracketleftigg
logEζ∼qζ/braceleftigg
pθ/parenleftbig
hϕ(ζ;g)/parenrightbig
qn/parenleftbig
g−Hhϕ(ζ;g)/parenrightbig
pϕ/parenleftbig
hϕ(ζ;g)|g/parenrightbig/bracerightigg/bracketrightigg
(6)
The proof of Theorem 3.1 is provided in the appendix. A variational lower bound of Lis employed, which
promotes consistency between the modeled posterior pϕ(·|g)and the posterior induced by the learned object
distribution, pθ(·|g):
LM(θ,ϕ) =Eg,ζilogavgexp
0<i≤M/bracketleftbig
logpθ/parenleftbig
hϕ(ζi;g)/parenrightbig
+ logqn/parenleftbig
g−Hhϕ(ζi;g)/parenrightbig
−logpϕ/parenleftbig
hϕ(ζi;g)|g/parenrightbig/bracketrightbig
,(7)
where ζi∼qζ,0<i≤M, and logavgexp0<i≤M(xi):= log/bracketleftig
1
M/summationtextM
i=1exp(xi)/bracketrightig
.
Intuitively, the three terms inside logavgexp in Eq. (7) can be interpreted as follows. The first term implies
thatGθis trained on samples produced by the posterior network hϕ. The second term is a data-fidelity term
that makes sure that hϕproduces objects consistent with the measurement model. The third term penalizes
degenerate hϕfor which∇ζhϕ(ζ;g)is ill-conditioned, for example when hϕproduces no variation due to ζ
and only depends on g. Note that the first and third terms are directly accessible via the INNs Gθandhϕ.
Also, for noise models commonly used in modeling computed imaging systems, such as the Gaussian noise
model (Barrett & Myers, 2013), qncan be explicitly computed.
Forsufficientlyexpressiveparametrizationsfor pθandhϕ, themaximumpossiblevalueof LMisEg∼qglogqg(g),
which corresponds to the scenario where the learned posteriors are consistent, i.e. pϕ(f|g) =pθ(f|g), and
the learned distribution of measurements matches the true measurement distribution, i.e. ψθ=qg. It can be
shown that for a class of forward operators, matching the measurement distribution is equivalent to matching
the object distribution:
Lemma 3.1. IfHis a square matrix ( n=m) with full-rank, if the noise nis independent of the object,
and if the characteristic function of the noise χn(ν) =En∼qnexp(ιν⊤n)has full support over Rm(ιis the
square-root of−1), thenψθ=qg⇒pθ=qf.
The proof of Lemma 3.1 is provided in Appendix A. Lemma 3.1 can be extended to a certain class random,
rank-deficient forward operators that nevertheless provide an invertible push-forward operator (Bora et al.,
2018). However, in computed imaging, forward models are often deterministic with a fixed null-space, where
it is typically not possible to design the hardware to ensure the invertibility of the push-forward operator
(Graff & Sidky, 2015; Lustig et al., 2008). In such a setting, it is not possible to uniquely relate the learned
object distribution pθto the learned measurement distribution ψθwithout additional information about qf.
Nevertheless, if the objects of interest are known to be compressible with respect to a sparsifying transform
Φ,pθcan be constrained to the set of distributions concentrated on these compressible objects. In order
to recover a distribution pθconcentrated on objects that are compressible with respect to Φ, the following
optimization problem is proposed:
ˆθ,ˆϕ= arg min
θ,ϕ−LM(θ,ϕ)subject to Eg∼qgEf∼pϕ(·|g)∥Φf−ΦprojSk(f)∥1<ϵ, (8)
4Published in Transactions on Machine Learning Research (01/2024)
whereprojSk(f)denotes the orthogonal projection of f∈Rnonto the setSkof objects for which Φfis
k−sparse. It can be shown that if Handf∼qfsatisfy the conditions of compressed sensing and the
AmbientFlow is trained sufficiently well using Eq. (8), then the error between the true and recovered object
distributions can be bounded. This is formalized as follows.
Theorem 3.2. For a PDF q:Rn→R, letqSkdenote the distribution of projSk(x), for x∼q. Also,
for distributions q1,q2, letW1(q1∥q2):=infq∈ΓE(x1,x2)∼q∥x1−x2∥2, denote the Wasserstein 1-distance,
withΓbeing the set of all joint distributions q:Rn×n→Rwith marginals q1,q2, i.e./integraltext
q(x1,x2)dx2=
q1(x1),/integraltext
q(x1,x2)dx1=q2(x2).
If the following hold:
1.W1(qf∥qSk
f)≤ϵ′(the true object distribution is concentrated on k-sparse objects under Φ),
2.Hsatisfies the RIP for objects k-sparse w.r.t. Φ, with isometry constant δk,
3. the characteristic function of noise χn(ν)has full support over Cm, and
4.(θ,ϕ)satisfyingpθ=qfandpϕ(·|g) =pθ(·|g)is a feasible solution to Eq. (8) ( Gθandhϕhave sufficient
capacity),
then the distribution pˆθrecovered via Eq. (8) is close to the true object distribution, in terms of the Wasserstein
distance i.e.
W1(pˆθ∥qf)≤/parenleftbigg
1 +1√1−δk∥H∥2/parenrightbigg
(ϵ+ϵ′). (9)
The proof of Theorem 3.2 is deferred to Appendix A.
In practice, Eq. (8) is reformulated in its Lagrangian
form, and a regularization parameter µis used to con-
trol the strength of the sparsity-promoting constraint.
Also, inspired by the β-VAE framework (Higgins et al.,
2017), an additional regularization parameter λwas
used to control the strength of the likelihood term
logqn(g−Hhϕ(ζi;g)). This modifies the problem
Training data
Posterior ﬂow
Main ﬂow
Figure 1: A schematic of the AmbientFlow framework
to maximizing the following objective function, which was optimized using gradient-based methods.
˜LM(θ,ϕ) =Eg∼qgEζi∼qζ/bracketleftbigg
logavgexp
0<i≤M/braceleftbig
logpθ/parenleftbig
hϕ(ζi;g)/parenrightbig
+λlogqn/parenleftbig
g−Hhϕ(ζi;g)/parenrightbig
−logpϕ/parenleftbig
hϕ(ζi;g)|g/parenrightbig/bracerightbig
−µ/vextenddouble/vextenddoubleΦhϕ(ζi;g)−projSk(Φhϕ(ζi;g))/vextenddouble/vextenddouble
1/bracketrightbigg
(10)
The proposed additive sparsifying penalty is computed by hard-thresholding the output of Φhϕ(ζi;g)to
project it onto the space of k-sparse signals, and computing the ℓ1norm of the residual, with kandµbeing
treated as tunable hyperparameters. However, note that consistent with Eq. (10), the loss terms for both the
INNs correspond to the original (un-thresholded) outputs of the posterior. This ensures that invertibility
is maintained, and the loss terms from both the INNs are well-defined. Empirically, we observe that the
proposedℓ1penalty also promotes sparse deviation of the output of hϕfromSk, which improves the quality
of the images generated by AmbientFlow.
4 Numerical Studies
This section describes the numerical studies used to demonstrate the utility of AmbientFlow for learning
object distributions from noisy and incomplete imaging measurements. The studies include toy problems in
two dimensions, low-dimensional problems involving a distribution of handwritten digits from the MNIST
dataset, problems involving face images from the CelebA-HQ dataset as well as the problem of recovering the
object distribution from stylized magnetic resonance imaging measurements. A case study that demonstrates
the utility of AmbientFlow in the downstream tasks of image reconstruction and posterior sampling is also
5Published in Transactions on Machine Learning Research (01/2024)
described. Additional numerical studies, including an evaluation of the posterior network, additional ablation
studies, and a face image inpainting case study are included in Appendix B.
Datasets and imaging models.
1) Toy problems: First, a two-dimensional object
distribution qf:R2→Rwas considered, which
was created as a sum of eight Gaussian distribu-
tionsN(ci,σ2
fI2),1≤i≤8, with centers cilo-
cated at the vertices of a regular octagon centered
at the origin, and standard deviation σf= 0.15,
as shown in Fig. 2a. The forward operator was
the identity operator, and the noise nwas dis-
tributed as a zero-mean Gaussian with covariance
σ2
nI2, withσn= 0.45. The distribution of the
(a) (b) (c) (d)Figure 2: (a) True distribution qf, (b) distribution qg
of measurements, (c) distribution learned by a flow
model trained on true objects, and (d) distribution
learned by AmbientFlow trained on measurements.
measurements g=f+nis shown in Fig. 2b. A training dataset of size D= 5×107was used.
Next, a problem of recovering the distribution of MNIST digits from noisy and/or blurred
images of MNIST digits was considered (LeCun
et al., 1998). For this problem, three different
forward models were considered, namely the
identity operator, and two Gaussian blurring
operatorsHblur1andHblur2with root-mean-
squared (RMS) width values σb= 1.5and3.0
pixels. The measurement noise was distributed
asn∼N(0,σ2
nIm), withσn= 0.3.
2) Face image study: For the face image
study, images of size n=64×64×3 from
the CelebA-HQ dataset were considered
(Karras et al., 2017). Two forward models
were considered, namely the identity operator
and the blurring operator with RMS width
σb= 1.5, and the measurement noise was
distributed as n∼N (0,σ2
nIm),σn= 0.2. A
discrete gradient operator was used as the
sparsifying transform Φ.
True objects
Flow trained 
on true objects
Measurements
AmbientFlow trained on measurementsg = f + n g = Hblur1f + n g = Hblur2f + n
FID = 203.8 FID = 269.3 FID = 301.4
FID = 146.9 FID = 187.4 FID = 244.1 FID = 146Figure 3: Samples from the flow model trained on true
objects and AmbientFlow trained on measurements shown
alongside samples of true objects and measurements for the
MNIST dataset.
3) Stylized MRI study: In this study, the problem of recovering the distribution of objects from simulated,
stylized MRI measurements was considered. T2-weighted brain images of size n=128×128 from the FastMRI
initiative database were considered (Zbontar et al., 2018) as samples from the object distribution. Stylized
MRI measurements with undersampling ratio n/m = 1(fully sampled) and n/m = 4were simulated using
the fast Fourier transform (FFT). Complex valued iid Gaussian measurement noise with standard deviation
0.1 times the total range of ground truth gray values was considered. A discrete gradient operator was used
as the sparsifying transform Φ.
Network architecture and training.1The architecture of the main flow model Gθwas adapted from
the Glow architecture (Kingma & Dhariwal, 2018). The posterior network was adapted from the conditional
INN architecture proposed by Ardizzone, et. al(Ardizzone et al., 2021). AmbientFlow was trained using
PyTorch using an NVIDIA Quadro RTX 8000 GPU. All hyperparameters for the main INN were fixed based
on a PyTorch implementation of the Glow architecture (Seonghyeon), except the number of blocks, which
was set to scale logarithmically by the image dimension.
1Our PyTorch implementation of AmbientFlow can be found at https://github.com/comp-imaging-sci/ambientflow
6Published in Transactions on Machine Learning Research (01/2024)
Baselines and evaluation metrics. For each dataset, an INN was trained on the ground-truth objects.
The architecture and hyperparameters used for this INN for a particular dataset were identical to the
ones used for main flow Gθwithin the AmbientFlow framework trained on that dataset. Besides, for each
forward model for the face image and stylized MRI study, a non-data-driven image restoration/reconstruction
algorithm was used to generate a dataset of individual estimates of the object. For H=Imwith
n∼N (0,σ2
nIm), the block-matching and 3D filtering (BM3D) denoising algorithm was used to perform
image restoration (Dabov et al., 2007). For the blurring operator with Gaussian noise, Wiener deconvolution
was used for this purpose (Blahut, 2004). For the stylized MRI study, a penalized least-squares with
TV regularization (PLS-TV) algorithm was used for image reconstruction (Beck & Teboulle, 2009). The
regularization parameter for the image reconstruction method was tuned to give the lowest RMS error
(RMSE) for every individual reconstructed image. Although this method of tuning the parameters is not
feasible in real systems, it gives the best set of reconstructed images in terms of the RMSE, thus providing a
strong baseline.
The Frechet Inception distance (FID) score, computed using the Clean-FID package (Parmar et al., 2022),
was used to compare a dataset of 5,000 true objects with an equivalent number of images synthesized using
(1) the INN trained on the true objects and (2) the AmbientFlow trained on the measurements, and (3)
images individually reconstructed from their corresponding measurements. Additionally, for the stylized
MRI study, radiomic features meaningful to medical imaging were computed on the true objects, generated
objects, and reconstructed images (Van Griethuysen et al., 2017).
Case study. Next, the utility of the AmbientFlow in a downstream Bayesian inference task was examined.
For this purpose, a case study of image reconstruction from incomplete measurements was considered, where
the AmbientFlow was used as a prior. Importantly, we consider the scenario where the forward model used for
simulating the measurements is different from the one associated with the AmbientFlow training. Preliminaries
of generative priors for image reconstruction are discussed in (Dimakis et al., 2022). In this study, the following
two image reconstruction tasks are considered – (1) approximate maximum a posteriori (MAP) estimation,
i.e. approximatingthemodeofthe posterior pθ(·|g), and(2)approximatesampling from theposterior pθ(·|g).
For both the tasks, an AmbientFlow trained on the fully sampled, noisy simulated MRI measurements, as
well as the flow trained on the true objects were considered. For the first task, the compressed sensing using
generative models (CSGM) formalism was used to obtained approximate MAP estimates from measurements,
for a held-out for a test dataset of size 45 (Asim et al., 2020):
ˆfMAP =Gθ(ˆzMAP),with ˆzMAP = arg min
z∥g−HGθ(z)∥2
2+λ∥z∥2
2. (11)
For the second task, approximate posterior sampling was performed with the flow models as priors using
annealed Langevin dynamics (ALD) iterations proposed in Jalal, et al.(Jalalet al., 2021a). For each true
object, the minimum mean-squared error (MMSE) estimate ˆfMMSEand the pixelwise standard deviation map
ˆσwere computed empirically using 40 samples obtained via ALD iterations. These image estimates were
compared with reconstructed images obtained using the PLS-TV method. The regularization parameters for
each image reconstruction method were tuned to achieve the best RMSE on a single validation image, and
then kept constant for the entire test dataset.
5 Results
Figure 2 shows the true object distribution, the distribution learned by a flow model trained on objects,
the measurement distribution, and the object distribution recovered by AmbientFlow trained using the
measurements. It can be seen that AmbientFlow is successful in generating nearly noiseless samples that
belong to one of the eight Gaussian blobs, although a small number of generated samples lie in the connecting
region between the blobs.
7Published in Transactions on Machine Learning Research (01/2024)
True objects Flow trained on true objects (FID = 57.8)
AmbientFlow trained on noisy blurred img. (FID=227.8) AmbientFlow trained on noisy img. (FID=135.5)BM3D recons from noisy images (FID=139.1) Wiener deconv. from noisy, blurred img. (FID=287.9)Noisy images with σn = 0.2 (FID=256.4) Blurred noisy img. with σb = 1.5,σn = 0.2 (FID=310)
Figure 4: True objects, noisy/blurred image measurements, reconstructed images and images synthesized by
the flow model trained on the true objects, as well as the AmbientFlows trained on the measurements for the
CelebA-HQ dataset.
For the MNIST dataset, Fig. 3 shows samples from the flow model trained on true objects and AmbientFlow
trained on measurements alongside samples of true objects and measurements, for different measurement
models. It can be seen that when the degradation process is a simple noise addition, the AmbientFlow
produces samples that visually appear denoised. When the degradation process consists of blurring and noise
addition, the AmbientFlow produces images that do not contain blur or noise, although the visual image
quality degrades as the blur increases. The visual findings are corroborated with quantitative results in terms
of the FID score, shown in Fig. 3.
Figure 4 shows the results of the face image study for the two different measurement processes considered -
(1) additive noise, and (2) Gaussian blur followed by additive noise. It can be seen that both visually and in
terms of the FID score, the quality of images generated by the AmbientFlow models was second only to the
flow trained directly on the true objects, for both the forward models considered. The images synthesized by
the AmbientFlow models had better visual quality and better fidelity in distribution with the true objects
with respect to FID than the ones produced by individually performing image restoration using BM3D
and Wiener deconvolution for the two forward models respectively. This suggests that an AmbientFlow
trained directly on the measurements would give a better approximation to the object distribution in terms
of the considered metrics as compared to a regular flow model trained on the image datasets individually
reconstructed via BM3D/Wiener deconvolution.
The results of the stylized MRI study are shown in Fig. 5. The visual and FID-based quality of images
synthesized by the AmbientFlow models was inferior only to the images synthesized by the flow trained
8Published in Transactions on Machine Learning Research (01/2024)
True objects Flow trained on true objects (FID = 45.6)
IFFT recons from fully sampled meas. (FID = 94.2) IFFT recons from 4x undersampled meas (FID=162.0)
PLS-TV recons from fully sampled meas. (FID=94.4) PLS-TV recons from 4x undersamp. meas (FID=181.7)
AmbientFlow trained on fully sampled meas (FID=72.4) AmbientFlow trained on 4x undersamp. meas (FID=88.2)
Figure 5: True objects, IFFT-based image estimates, PLS-TV based image estimates and images synthesized
by the flow model trained on the true objects, as well as the AmbientFlows trained on the measurements for
the stylized MRI study.
Table 1: The mean ±standard deviation of the RMSE and SSIM values computed over the following test
image datasets – (1) the images reconstructed using the PLS-TV method, (2) the MAP and MMSE estimates
using the flow prior trained on true objects, and (3) the MAP and MMSE estimates using the AmbientFlow
prior trained on fully sampled noisy measurements.
Method RMSE SSIM
PLS-TV 0.038 ±0.007 0.806±0.019
Flow prior trained on true objectsMAP Estimate 0.025 ±0.005 0.922±0.013
MMSE Estimate 0.022±0.003 0.940±0.006
AmbientFlow priorMAP Estimate 0.025 ±0.004 0.925±0.012
MMSE Estimate 0.022±0.004 0.936±0.008
9Published in Transactions on Machine Learning Research (01/2024)
directly on objects, and was superior to the images
reconstructed individually from the measurements
using the PLS-TV method. Since the underlying
Inception network used to compute the FID score is
not directly related to medical images, additional
evaluation was performed in terms of radiomic
features relevant to medical image assessments.
Figure 6 plots the empirical PDF over the first two
principal components of the radiomic features ex-
tracted from each of the MR image sets shown in
Fig. 5, except the IFFT image estimates. It can be
seen that there is a significant disparity between the
principal radiomic feature PDFs of the true objects
and the images reconstructed individually using PLS-
TV. On the other hand, the AmbientFlow-generated
images have a radiomic feature distribution closer to
the true objects for both the fully sampled and 4-
fold undersampled cases. This implies that, training
an AmbientFlow on the noisy/incomplete measure-
ments yielded an estimate of the object distribution
that was more accurate in terms of relevant radiomic
features, than the one defined by images individu-
ally reconstructed from the measurements using the
PLS-TV method.
(a) True objects
(b) Flow trained
on true objectsPLS-TV recons from noisy measurements 
(c) n/m = 1 (e) n/m = 4
AmbientFlow trained on noisy measurements 
(d) n/m = 1 (f) n/m = 4Figure 6: Empirical PDF over the first two principal
components of the radiomic features extracted from
MRI images. For each plot, the bold contour encloses
the region containing 80% of the probability mass. For
(b-f), thedottedcontourenclosestheregioncontaining
80% of the probability mass of the true objects.
Next, the utility of the AmbientFlow for Bayesian inference is
demonstrated with the help of an image reconstruction case
study. Figure 7 shows a true object alongside images recon-
structed from stylized 4-fold undersampled MR measurements
simulated from the object, using the reconstruction methods
described in Section 4. Recall that for both the flow-based
priors shown, the MAP estimate was obtained using the CSGM
framework (Bora et al., 2017), and the MMSE estimate and
the pixelwise standard deviation maps were computed empiri-
cally from samples from the posterior pθ(f|g)obtained using
annealed Langevin dynamics (Jalal et al., 2021a). Visually, it
can be seen that the images reconstructed using the Ambient-
Flow prior were comparable to the images reconstructed using
the flow prior trained on the true objects, and better than the
image reconstructed using the PLS-TV method. Table 1 shows
the root-mean-squared error (RMSE) and structural similarity
(SSIM) (Wang et al., 2004) of the reconstructed images with
respect to the true object, averaged over a dataset of 45 test
images. It can be seen that in terms of RMSE and SSIM, both
the MAP and the MMSE image estimates obtained using the
AmbientFlow prior are comparable to those obtained using the
flow prior trained on true objects, despite the AmbientFlow
being trained only using noisy stylized MR measurements.
AmbientFlow
prior
Flow prior trainedon true objects
00.1100.11Figure 7: Image estimates and pixelwise
standard deviation maps from the image
reconstruction case study.
6 Discussion and conclusion
An estimate of the distribution of objects is known to be important for applications in imaging science. This
is because an unconditional generative model of objects can potentially be used in image reconstruction
tasks without the need for paired data of images and measurements, and in a way that accommodates a
10Published in Transactions on Machine Learning Research (01/2024)
wide variety of relevant forward models (Bora et al., 2017; Asim et al., 2020). Additionally, unconditional
generative models can be used to approximate ideal Bayesian classifiers (Zhou et al., 2023), or for anomaly
detection (Zhao et al.), or image manipulation (Torres & Brefeld). However, obtaining such an estimate
in terms of a generative model that is useful for downstream tasks has remained challenging, especially
when only noisy and incomplete measurements of the objects are available. In this work, a framework for
learning flow-based generative models of objects from noisy/incomplete measurements was developed. The
presented numerical studies show that the proposed AmbientFlow framework was able to mitigate the effects
of data incompleteness and noise present in the measurements in order to build an accurate estimate of the
object distribution in terms of the considered evaluation metrics, and generate visually appealing images. In
terms of perceptual measures such as the FID score as well as domain specific radiomic features, the images
synthesized by AmbientFlow maintained higher distributional fidelity with the true objects than the images
individually reconstructed from the measurements. Furthermore, when the AmbientFlow trained on noisy
measurements was employed as a prior in an image reconstruction task, the image estimates obtained were
as accurate in terms of RMSE and SSIM as those obtained when a flow model trained directly on the true
objects was employed.
Some of the above observations also apply to the AmbientGAN framework developed by Bora, et al.(Bora
et al., 2018). Although the current state-of-the-art GANs may lead to images with better perceptual quality
than IGMs, GANs trained on medical images have been shown to misrepresent medically relevant statistics
despite producing visually appealing images (Kelkar et al., 2023a). Also, an important drawback of GANs
with in the context of imaging science is its unreliability in downstream Bayesian inference tasks. For example,
GAN-constrained image reconstruction methods are known to be prone to hallucinations caused by dataset
bias, distribution shifts and representation error, whereas IGMs used for the same purpose have been shown to
be comparatively robust (Bhadra et al., 2021; Asim et al., 2020; Menon et al., 2020; Kelkar et al., 2021; Jalal
et al., 2021b;a; Zhao et al., 2022). These drawbacks of GANs are in part due to the insufficient representation
capacity and inability to access the log-probability, both of which are applicable for GANs learned in the
ambient setting as well. IGMs, on the other hand, due to their ability to accurately represent images and
compute fast, exact density estimates, are more suitable for some downstream inference tasks such as image
reconstruction, posterior sampling and uncertainty quantification as compared to GANs. Further similarities
and differences between AmbientGAN and AmbientFlow are as follows. In some scenarios, AmbientGAN can
be more flexible since it can easily accommodate arbitrary differentiable random forward models, whereas
AmbientFlow is limited by the capabilities of the posterior network. However, in the presence of a fixed null
space, some studies have shown that AmbientGAN performance can degrade and the images produced by it
can display aliasing artifacts characteristic of the measurement operator (Zhou et al., 2022). To the best of
our knowledge, incorporating additional priors into the AmbientGAN loss function has not been rigorously
studied. Another key difference between the two approaches is that unlike AmbientGAN, AmbientFlow also
provides a posterior network which can be useful by itself for certain image reconstruction tasks, as shown in
Appendix B.
The AmbientFlow framework bears some similarity with variational autoencoders (VAEs). In both cases, a
variational lower bound of the evidence of the data is minimized. The object distribution in AmbientFlow is
analogous to the latent variable distribution in VAEs. However, in VAEs, the latent distribution is typically
simple and non-unique, and its desirable properties include disentanglement, tractable sampling, and accurate
representation of the data via a trained decoder. However, in the AmbientFlow framework, the object
distribution is a complex high dimensional distribution that is of primary interest and needs to be recovered as
accurately as possible. It is related to the measured data via a physical measurement process, and may have
known structure such as transform compressibility. Therefore, the aims and objectives of the two frameworks
that guide their design are radically different.
The posterior network in our work also has interesting connections to deep probabilistic imaging (DPI) (Sun
& Bouman, 2021), which also uses an invertible network to model the posterior, and trains it in a way that is
constrained by a prior. However, unlike DPI, the posterior model in our work is an end-to-end conditional
generative model that, when trained, can directly produce posterior samples by taking in the measurement
vector as one of the inputs.
11Published in Transactions on Machine Learning Research (01/2024)
The presented framework can be adopted to other generative models that utilize a log-likelihood-based training
objective, such as denoising diffusion probabilistic models (DDPMs) which enable high-quality Bayesian
inference in imaging (Song et al., 2021). Recent examples of learning diffusion models from noisy/incomplete
data include (Aali et al., 2023) and (Daras et al., 2023). However, the approach by Aali et al.applies only
to measurements with white Gaussian noise and an identity forward operator. In contrast, the approach
by Daras, et al.can incorporate a wide class of forward operators, but does not account for measurement
noise. In the future, an extension of the AmbientFlow framework to diffusion models could account for both,
forward operators with a null space, as well as measurement noise.
A key limitation of the proposed framework is that its performance depends heavily on the design of the
posterior network. The posterior network architecture currently employed is inspired by Ardizzone, et. al
(Ardizzone et al., 2021). It displays favourable inductive biases for images due to several design choices such
as wavelet-based downsampling layers, and a Laplacian pyramid feature extractor for the conditioning input.
However, this architecture may not be able to properly model the posterior when Hdepends on a random
parameter, such as a random view angle relevant for cryo-electron microscopy (Zhong et al., 2021). In theory,
it is straightforward to modify the loss function so that in addition to g, a random forward model H∼qH
is also a conditioning input to the posterior network. However, in practice, designing a posterior network
architecture that can successfully account for the random forward operator is nontrivial, and could be an
interesting avenue for future work. Also, although this work involves preliminary assessments of AmbientFlow
using the FID score and radiomic features, a proper evaluation of generative models for imaging applications
is still an open problem (Sankaranarayanan et al., 2023). Thorough evaluation of such models would involve
assessing whether they can reproduce image statistics that are relevant to a wide variety of downstream tasks
(Kelkaret al., 2023a;b).
Acknowledgements
This work was supported by the National Institute of Health (NIH) award EB034249. We acknowledge Carl
Edwards for useful discussions.
References
Asad Aali, Marius Arvinte, Sidharth Kumar, and Jonathan I Tamir. Solving inverse problems with score-based
generative priors learned from noisy data. arXiv preprint arXiv:2305.01166 , 2023.
Lynton Ardizzone, Jakob Kruse, Carsten Lüth, Niels Bracher, Carsten Rother, and Ullrich Köthe. Conditional
invertible neural networks for diverse image-to-image translation. In Pattern Recognition: 42nd DAGM German
Conference, DAGM GCPR 2020, Tübingen, Germany, September 28–October 1, 2020, Proceedings 42 , pp. 373–387.
Springer, 2021.
Muhammad Asim, Max Daniels, Oscar Leong, Ali Ahmed, and Paul Hand. Invertible generative models for inverse
problems: mitigating representation error and dataset bias. In International Conference on Machine Learning , pp.
399–409. PMLR, 2020.
Harrison H Barrett and Kyle J Myers. Foundations of image science . John Wiley & Sons, 2013.
Amir Beck and Marc Teboulle. A fast iterative shrinkage-thresholding algorithm for linear inverse problems. SIAM
journal on imaging sciences , 2(1):183–202, 2009.
Marcelo Bertalmio, Andrea L Bertozzi, and Guillermo Sapiro. Navier-stokes, fluid dynamics, and image and video
inpainting. In Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern
Recognition. CVPR 2001 , volume 1, pp. I–I. IEEE, 2001.
Sayantan Bhadra, Varun A Kelkar, Frank J Brooks, and Mark A Anastasio. On hallucinations in tomographic image
reconstruction. IEEE transactions on medical imaging , 40(11):3249–3260, 2021.
Richard E Blahut. Theory of remote image formation . Cambridge University Press, 2004.
Ashish Bora, Ajil Jalal, Eric Price, and Alexandros G Dimakis. Compressed sensing using generative models. In
International Conference on Machine Learning , pp. 537–546. PMLR, 2017.
12Published in Transactions on Machine Learning Research (01/2024)
Ashish Bora, Eric Price, and Alexandros G Dimakis. Ambientgan: Generative models from lossy measurements. In
International conference on learning representations , 2018.
Yuri Burda, Roger Grosse, and Ruslan Salakhutdinov. Importance weighted autoencoders. arXiv preprint
arXiv:1509.00519 , 2015.
Emmanuel J Candes, Justin K Romberg, and Terence Tao. Stable signal recovery from incomplete and inaccurate
measurements. Communications on Pure and Applied Mathematics: A Journal Issued by the Courant Institute of
Mathematical Sciences , 59(8):1207–1223, 2006.
Kostadin Dabov, Alessandro Foi, Vladimir Katkovnik, and Karen Egiazarian. Image denoising by sparse 3-d
transform-domain collaborative filtering. IEEE Transactions on image processing , 16(8):2080–2095, 2007.
Giannis Daras, Kulin Shah, Yuval Dagan, Aravind Gollakota, Alexandros G Dimakis, and Adam Klivans. Ambient
diffusion: Learning clean distributions from corrupted data. arXiv preprint arXiv:2305.19256 , 2023.
Alexandros G Dimakis, Ashish Bora, Dave Van Veen, Ajil Jalal, Sriram Vishwanath, and Eric Price. Deep generative
models and inverse problems. Mathematical Aspects of Deep Learning , pp. 400, 2022.
Laurent Dinh, David Krueger, and Yoshua Bengio. Nice: Non-linear independent components estimation. arXiv
preprint arXiv:1410.8516 , 2014.
Laurent Dinh, Jascha Sohl-Dickstein, and Samy Bengio. Density estimation using real nvp. arXiv preprint
arXiv:1605.08803 , 2016.
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and
Yoshua Bengio. Generative adversarial networks. Communications of the ACM , 63(11):139–144, 2020.
Christian G Graff and Emil Y Sidky. Compressive sensing in medical imaging. Applied optics , 54(8):C23–C44, 2015.
Irina Higgins, Loic Matthey, Arka Pal, Christopher Burgess, Xavier Glorot, Matthew Botvinick, Shakir Mohamed,
and Alexander Lerchner. beta-vae: Learning basic visual concepts with a constrained variational framework. In
International conference on learning representations , 2017.
Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. Advances in Neural Information
Processing Systems , 33:6840–6851, 2020.
Ajil Jalal, Sushrut Karmalkar, Alexandros G Dimakis, and Eric Price. Instance-optimal compressed sensing via
posterior sampling. arXiv preprint arXiv:2106.11438 , 2021a.
Ajil Jalal, Sushrut Karmalkar, Jessica Hoffmann, Alex Dimakis, and Eric Price. Fairness for image generation with
uncertain sensitive attributes. In International Conference on Machine Learning , pp. 4721–4732. PMLR, 2021b.
Tero Karras, Timo Aila, Samuli Laine, and Jaakko Lehtinen. Progressive growing of gans for improved quality,
stability, and variation. arXiv preprint arXiv:1710.10196 , 2017.
Tero Karras, Samuli Laine, Miika Aittala, Janne Hellsten, Jaakko Lehtinen, and Timo Aila. Analyzing and improving
the image quality of stylegan. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition ,
pp. 8110–8119, 2020.
Varun A Kelkar and Mark Anastasio. Prior image-constrained reconstruction using style-based generative models. In
International Conference on Machine Learning , pp. 5367–5377. PMLR, 2021.
Varun A Kelkar, Sayantan Bhadra, and Mark A Anastasio. Compressible latent-space invertible networks for generative
model-constrained image reconstruction. IEEE transactions on computational imaging , 7:209–223, 2021.
Varun A Kelkar, Dimitrios S Gotsis, Frank J Brooks, KC Prabhat, Kyle J Myers, Rongping Zeng, and Mark A
Anastasio. Assessing the ability of generative adversarial networks to learn canonical medical image statistics. IEEE
transactions on medical imaging , 2023a.
Varun A Kelkar, Dimitrios S Gotsis, Rucha Deshpande, Frank J Brooks, KC Prabhat, Kyle J Myers, Rongping Zeng,
and Mark A Anastasio. Evaluating generative stochastic image models using task-based image quality measures. In
Medical Imaging 2023: Image Perception, Observer Performance, and Technology Assessment , volume 12467, pp.
304–310. SPIE, 2023b.
13Published in Transactions on Machine Learning Research (01/2024)
AmirEhsan Khorashadizadeh, Konik Kothari, Leonardo Salsi, Ali Aghababaei Harandi, Maarten de Hoop, and Ivan
Dokmanić. Conditional injective flows for bayesian imaging. IEEE Transactions on Computational Imaging , 9:
224–237, 2023.
Diederik P Kingma, Max Welling, et al.An introduction to variational autoencoders. Foundations and Trends ®in
Machine Learning , 12(4):307–392, 2019.
Durk P Kingma and Prafulla Dhariwal. Glow: Generative flow with invertible 1x1 convolutions. Advances in neural
information processing systems , 31, 2018.
Bhagwandas Pannalal Lathi and Roger A Green. Linear systems and signals , volume 2. Oxford University Press New
York, 2005.
Yann LeCun, Léon Bottou, Yoshua Bengio, and Patrick Haffner. Gradient-based learning applied to document
recognition. Proceedings of the IEEE , 86(11):2278–2324, 1998.
Michael Lustig, David L Donoho, Juan M Santos, and John M Pauly. Compressed sensing mri. IEEE signal processing
magazine , 25(2):72–82, 2008.
Sachit Menon, Alexandru Damian, Shijia Hu, Nikhil Ravi, and Cynthia Rudin. Pulse: Self-supervised photo upsampling
via latent space exploration of generative models. In Proceedings of the ieee/cvf conference on computer vision and
pattern recognition , pp. 2437–2445, 2020.
Gaurav Parmar, Richard Zhang, and Jun-Yan Zhu. On aliased resizing and surprising subtleties in gan evaluation. In
Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 11410–11420, 2022.
Swami Sankaranarayanan, Thomas Hartvigsen, Camille Bilodeau, Ryutaro Tanno, Cheng Zhang, Florian Tramer, and
Phillip Isola. Challenges in deployable generative AI, ICML 2023 workshop. https://deployinggenerativeai.
github.io/index , 2023.
Kim Seonghyeon. PyTorch Implementation of Glow: Generative Flow with Invertible 1x1 Convolutions. URL
https://github.com/rosinality/glow-pytorch .
Yang Song, Liyue Shen, Lei Xing, and Stefano Ermon. Solving inverse problems in medical imaging with score-based
generative models. arXiv preprint arXiv:2111.08005 , 2021.
He Sun and Katherine L Bouman. Deep probabilistic imaging: Uncertainty quantification and multi-modal solution
characterization for computational imaging. In Proceedings of the AAAI Conference on Artificial Intelligence ,
volume 35, pp. 2628–2637, 2021.
Hoang Thanh-Tung and Truyen Tran. Catastrophic forgetting and mode collapse in gans. In 2020 international joint
conference on neural networks (ijcnn) , pp. 1–10. IEEE, 2020.
Ricardo da S Torres and Ulf Brefeld. Principled interpolation in normalizing flows.
Joost JMVan Griethuysen, AndriyFedorov, Chintan Parmar, Ahmed Hosny, Nicole Aucoin, Vivek Narayan, ReginaGH
Beets-Tan, Jean-Christophe Fillion-Robin, Steve Pieper, and Hugo JWL Aerts. Computational radiomics system to
decode the radiographic phenotype. Cancer research , 77(21):e104–e107, 2017.
Zhou Wang, Alan C Bovik, Hamid R Sheikh, and Eero P Simoncelli. Image quality assessment: from error visibility
to structural similarity. IEEE transactions on image processing , 13(4):600–612, 2004.
Jure Zbontar, Florian Knoll, Anuroop Sriram, Tullie Murrell, Zhengnan Huang, Matthew J. Muckley, Aaron Defazio,
Ruben Stern, Patricia Johnson, Mary Bruno, Marc Parente, Krzysztof J. Geras, Joe Katsnelson, Hersh Chandarana,
Zizhao Zhang, Michal Drozdzal, Adriana Romero, Michael Rabbat, Pascal Vincent, Nafissa Yakubova, James
Pinkerton, Duo Wang, Erich Owens, C. Lawrence Zitnick, Michael P. Recht, Daniel K. Sodickson, and Yvonne W.
Lui. fastMRI: An open dataset and benchmarks for accelerated MRI, 2018.
Xuebin Zhao, Andrew Curtis, and Xin Zhang. Bayesian seismic tomography using normalizing flows. Geophysical
Journal International , 228(1):213–239, 2022.
Yuzhong Zhao, Qiaoqiao Ding, and Xiaoqun Zhang. Ae-flow: Autoencoders with normalizing flows for medical images
anomaly detection. In The Eleventh International Conference on Learning Representations .
14Published in Transactions on Machine Learning Research (01/2024)
Ellen D Zhong, Tristan Bepler, Bonnie Berger, and Joseph H Davis. Cryodrgn: reconstruction of heterogeneous
cryo-em structures using neural networks. Nature methods , 18(2):176–185, 2021.
Weimin Zhou, Sayantan Bhadra, Frank J Brooks, Hua Li, and Mark A Anastasio. Learning stochastic object models
from medical imaging measurements by use of advanced ambient generative adversarial networks. Journal of
Medical Imaging , 9(1):015503–015503, 2022.
Weimin Zhou, Umberto Villa, and Mark A Anastasio. Ideal observer computation by use of markov-chain monte carlo
with generative adversarial networks. arXiv preprint arXiv:2304.00433 , 2023.
15Published in Transactions on Machine Learning Research (01/2024)
A Theoretical analysis for Section 3
First, the notation defined in Section 3 is rehashed here for convenience.
Notation. Letqf,qgandqndenote the unknown true object distribution to-be-recovered, the true
measurement distribution and the known measurement noise distribution, respectively. Let D={g(i)}D
i=1be
a dataset of independent and identically distributed (iid) measurements drawn from qg. LetGθ:Rn→Rn
be an INN. Let pθbe the distribution represented by Gθ, i.e. given a latent distribution qz=N(0,In),
Gθ(z)∼pθforz∼qz. Also, letψθbe the distribution of fake measurements, i.e. for f∼pθ,Hf+n∼ψθ.
Letpθ(f|g)∝qn(g−Hf)pθ(f)denote the posterior induced by the learned object distribution represented
byGθ. LetΦ∈Rl×n, l≥nbe a full-rank linear transformation (henceforth referred to as a sparsifying
transform). Also, let Sk={v∈Rns.t.∥Φv∥0≤k}be the set of vectors k-sparse with respect to Φ. SinceΦ
is full-rank, throughout this chapter we assume without the loss of generality, that ∥Φ+∥2≤1, whereΦ+is
the Moore-Penrose pseudoinverse of Φ. Throughout the manuscript, we also assume that qfis absolutely
continuous with respect to pθ, andqgis absolutely continuous with respect to ψθ.
A.1 Proof of Theorem 3.1
Theorem 3.1. Lethϕbe such that pϕ(f|g)>0overRn. Minimizing DKL(qg∥ψθ)is equivalent to
maximizing the objective function L(θ,ϕ)overθ,ϕ, whereL(θ,ϕ)is defined as
L(θ,ϕ) =Eg∼qg/bracketleftigg
logEζ∼qζ/braceleftigg
pθ/parenleftbig
hϕ(ζ;g)/parenrightbig
qn/parenleftbig
g−Hhϕ(ζ;g)/parenrightbig
pϕ/parenleftbig
hϕ(ζ;g)|g/parenrightbig/bracerightigg/bracketrightigg
(12)
Proof.From the definition of KL divergence, we have
DKL(qg∥ψθ) =Eg∼qg/bracketleftbigg
logqg(g)
ψθ(g)/bracketrightbigg
(13)
=Eg∼qglogqg(g)−Eg∼qglogψθ(g). (14)
Now,ψθ(g)can be written as
ψθ(g) =/integraldisplay
qg|f(g|f)pθ(f)df (15)
=/integraldisplay
pϕ(f|g)qn(g−Hf)pθ(f)
pϕ(f|g)df (16)
=Ef∼pϕ(·|g)/bracketleftbiggqn(g−Hf)pθ(f)
pϕ(f|g)/bracketrightbigg
. (17)
Therefore,
Eg∼qglogψθ(g) =Eg∼qg/bracketleftbigg
logEf∼pϕ(·|g)/braceleftbiggpθ(f)qn(g−Hf)
pϕ(f|g)/bracerightbigg/bracketrightbigg
(18)
=Eg∼qg/bracketleftigg
logEζ∼qζ/braceleftigg
pθ/parenleftbig
hϕ(ζ;g)/parenrightbig
qn/parenleftbig
g−Hhϕ(ζ;g)/parenrightbig
pϕ/parenleftbig
hϕ(ζ;g)|g/parenrightbig/bracerightigg/bracketrightigg
(19)
=L(θ,ϕ). (20)
Therefore,
DKL(qg∥ψθ) =Eg∼qglogqg(g)−L(θ,ϕ). (21)
SinceEg∼qglogqg(g)is a constant, minimizing DKL(qg∥ψθ)is equivalent to maximizing L(θ,ϕ).
16Published in Transactions on Machine Learning Research (01/2024)
Remark. As described in Section 3, a variational lower bound of Lis optimized in this work:
LM(θ,ϕ) =Eg,ζilogavgexp
0<i≤M/bracketleftbig
logpθ/parenleftbig
hϕ(ζi;g)/parenrightbig
+ logqn/parenleftbig
g−Hhϕ(ζi;g)/parenrightbig
−logpϕ/parenleftbig
hϕ(ζi;g)|g/parenrightbig/bracketrightbig
,(22)
where ζi∼qζ,0<i≤M, and logavgexp0<i≤M(xi):= log/bracketleftig
1
M/summationtextM
i=1exp(xi)/bracketrightig
.
Forsufficientlyexpressiveparametrizationsfor pθandhϕ, themaximumpossiblevalueof LMisEg∼qglogqg(g),
which corresponds to the scenario where the learned posteriors are consistent, i.e. pϕ(f|g) =pθ(f|g), and
the learned distribution of measurements matches the true measurement distribution, i.e. ψθ=qg. This can
be shown as follows.
ForM= 1,LM(θ,ϕ)reduces to the evidence lower bound (ELBO):
LELBO (θ,ϕ) =Eg∼qg,ζ∼qζ/bracketleftbig
logpθ/parenleftbig
hϕ(ζ;g)/parenrightbig
+ logqn/parenleftbig
g−Hhϕ(ζ;g)/parenrightbig
−logpϕ/parenleftbig
hϕ(ζ;g)|g/parenrightbig/bracketrightbig
. (23)
=Eg∼qglogψθ(g)−DKL(pϕ(·|g)∥pθ(·|g)). (24)
Similar to importance-weighted autoencoders (IWAE), (Burda et al., 2015), it can be shown that
LELBO (θ,ϕ)≤LM(θ,ϕ)≤Eg∼qglogψθ(g)≤Eg∼qglogqg(g), (25)
with equality occurring when ψθ=qgandpϕ(·|g) =pθ(·|g). Thus the maximum value that can be achieved
byLM(θ,ϕ)isEg∼qglogqg(g).
Lemma 3.1. IfHis a square matrix ( n=m) with full-rank, if the noise nis independent of the object,
and if the characteristic function of the noise χn(ν) =En∼qnexp(ιν⊤n)has full support over Rm(ιis the
square-root of−1), thenψθ=qg⇒pθ=qf.
Proof.This proof as been adapted from the AmbientGAN work (Bora et al., 2018). Let y=Hfrepresent
the noiseless measurements. Therefore,
g=y+n, (26)
⇒qg=qy∗qn, (27)
where∗represents a convolution (in the sense of linear systems theory) (Lathi & Green, 2005). Therefore,
χg(ν) =χy(ν)χn(ν),ν∈Rm. (28)
Sinceχnhas full support over Rm,χguniquely determines χy. Therefore, qguniquely determines qy.
Also, since His bijective, qyuniquely determines qf. Therefore, ψθ=qg⇒pθ=qf.
A.2 Proof of Theorem 3.2
InordertoproveTheorem3.2, wefirstestablishessentialnotationandintermediateresultsneeded. Specifically,
in Lemma A.1, we derive an expression for the wasserstein distance between a distribution of a random
variable, and the distribution of its projection onto a set. We then proceed to prove Theorem 3.2.
Notation. For a closed setS⊂Rn,letprojS(f)denote the orthogonal projection of fontoS, defined as
projS(f) = min
f′∈S∥f′−f∥2 (29)
For a PDF q:Rn→R, letqSdenote the distribution of projS(x), forx∼q. Also, for distributions q1,q2, let
W1(q1∥q2):= inf
γ∈Γ(q1,q2)E(x1,x2)∼γ∥x1−x2∥2 (30)
17Published in Transactions on Machine Learning Research (01/2024)
denote the Wasserstein 1-distance, with Γ(q1,q2)being the set of all joint distributions γ:Rn×n→Rwith
marginalsq1,q2, i.e.
/integraldisplay
γ(x1,x2)dx2=q1(x1),/integraldisplay
γ(x1,x2)dx1=q2(x2). (31)
Lemma A.1. Letx∈Rnbe a random vector with distribution q. Then, with the above notation,
W1(q∥qS) =Ex∼q∥x−projS(x)∥2. (32)
Proof.Letγ0:Rn×n→Rbe a degenerate joint distribution given by
γ0(x,w) =q(x)δ/parenleftbig
w−projS(x)/parenrightbig
,x,w∈Rn, (33)
where,δ(w)denotes the Dirac delta. Therefore, by definition of the Wasserstein distance,
W1(q∥qS)≤E(x,w)∼γ0∥x−w∥2, (34)
=/integraldisplay
q(x)δ/parenleftbig
w−projS(x)/parenrightbig
∥x−w∥2dxdw, (35)
=/integraldisplay
q(x)∥x−projS(x)∥2dx, (36)
=Ex∼q∥x−projS(x)∥2. (37)
On the other hand, by definition of orthogonal projection,
∥x−projS(x)∥2≤∥x−w∥2,∀w∈supp(qS). (38)
Therefore,
Ex∼q∥x−projS(x)∥2≤E(x,w)∼γ∥x−w∥2, γ∈Γ(q,qS). (39)
⇒Ex∼q∥x−projS(x)∥2≤ inf
γ∈Γ(q,qS)E(x,w)∼γ∥x−w∥2, (40)
=W1(q∥qS). (41)
Equations (37) and (41) imply
W1(q∥qS) =Ex∼q∥x−projS(x)∥2. (42)
With all the tools in place, we now proceed to prove Theorem 3.2. Consider the optimization problem stated
in Eq. (8):
ˆθ,ˆϕ= arg min
θ,ϕ−LM(θ,ϕ)subject to Eg∼qgEf∼pϕ(·|g)∥Φf−ΦprojSk(f)∥1<ϵ. (8)
Theorem 3.2. If the following hold:
1.W1(qf∥qSk
f)≤ϵ′(the true object distribution is concentrated on k-sparse objects under Φ),
2.Hsatisfies the RIP for objects k-sparse w.r.t. Φ, with isometry constant δk,
3. the characteristic function of noise χn(ν)has full support over Cm, and
4.(θ,ϕ)satisfyingpθ=qfandpϕ(·|g) =pθ(·|g)is a feasible solution to Eq. (8) ( Gθandhϕhave sufficient
capacity),
then the distrubution pˆθrecovered via Eq. (8) is close to the true object distribution, in terms of the Wasserstein
distance i.e.
W1(pˆθ∥qf)≤/parenleftbigg
1 +1√1−δk∥H∥2/parenrightbigg
(ϵ+ϵ′). (43)
18Published in Transactions on Machine Learning Research (01/2024)
The intuitive idea behind the proof of this theorem is as follows. Compressed sensing stipulates that under
precribed conditions, the forward operator is injective on a set of sparse vectors. Thus, if an object distribution
is sparse, then the distribution of its measurements should be uniquely linked to it. If the object distribution
qfis compressible, and if it is ensured that a compressible distribution pˆθis recovered via Eq. (8), then
bothqfandpˆθwill be concentrated on the sparse vectors, and will associated with the same measurement
distribution qg. Since the sparse vectors are uniquely determined by the measurements, pˆθandqfmust
themselves be close.
Proof.Since (θ,ϕ)satisfyingpθ=qf, andpϕ(·|g) =pθ(·|g)is a feasible solution to Eq. (8), the maximum
value ofLMunder Eq. (8) is Eg∼qglogqg(g). Therefore, according to Eq. (25), for the estimated ˆθand ˆϕ,
L(ˆθ,ˆϕ) =Eg∼qglogqg(g),
ψˆθ=qgandpˆϕ(·|g) =pˆθ(·|g). (44)
Letf1,f2∈Rn. Therefore, by triangle inequality,
∥f1−f2∥2=/vextenddouble/vextenddoublef1−fS
1+fS
2−f2+fS
1−fS
2/vextenddouble/vextenddouble
2, (45)
≤/vextenddouble/vextenddoublef1−fS
1/vextenddouble/vextenddouble
2+/vextenddouble/vextenddoublefS
2−f2/vextenddouble/vextenddouble
2+/vextenddouble/vextenddoublefS
1−fS
2/vextenddouble/vextenddouble
2, (46)
where fSis a shorthand for projSk(f)forf∈Rn.
f1,f2can be represented in terms of the spasifying transform Φ. Let ci=ΦfiandcS
i=ΦfS
i, fori= 1,2.
Therefore,
∥f1−f2∥2≤/vextenddouble/vextenddoublef1−fS
1/vextenddouble/vextenddouble
2+/vextenddouble/vextenddoubleΦ+/vextenddouble/vextenddouble
2/vextenddouble/vextenddoublec2−cS
2/vextenddouble/vextenddouble
2+/vextenddouble/vextenddoublefS
1−fS
2/vextenddouble/vextenddouble
2, (47)
whereΦ+is the Moore-Penrose pseudoinverse of Φ. Also, by definition, recall that cS
1andcS
2have at most k
non-zero values.
Now, let yi=Hfifori= 1,2. Therefore,
/vextenddouble/vextenddoubleyS
1−yS
2/vextenddouble/vextenddouble
2=/vextenddouble/vextenddoubleyS
1−y1+y2−yS
2+y1−y2/vextenddouble/vextenddouble
2(48)
≤/vextenddouble/vextenddoubley1−yS
1/vextenddouble/vextenddouble
2+/vextenddouble/vextenddoubley2−yS
2/vextenddouble/vextenddouble
2+∥y1−y2∥2, (49)
≤∥H∥2/vextenddouble/vextenddoublef1−fS
1/vextenddouble/vextenddouble
2+/vextenddouble/vextenddoubleHΦ+/vextenddouble/vextenddouble
2/vextenddouble/vextenddoublec2−cS
2/vextenddouble/vextenddouble
2+∥y1−y2∥2. (50)
Now, the restricted isometry property (RIP) on Hdefined in Definition 2.1 implies
/vextenddouble/vextenddoublefS
1−fS
2/vextenddouble/vextenddouble
2≤1√1−δk/vextenddouble/vextenddoubleyS
1−yS
2/vextenddouble/vextenddouble. (51)
Therefore, Equations (47), (50) and (51) give
∥f1−f2∥≤/vextenddouble/vextenddoublef1−fS
1/vextenddouble/vextenddouble
2+/vextenddouble/vextenddoubleΦ+/vextenddouble/vextenddouble
2/vextenddouble/vextenddoublec2−cS
2/vextenddouble/vextenddouble
2
+1√1−δk/bracketleftig
∥H∥2/vextenddouble/vextenddoublef1−fS
1/vextenddouble/vextenddouble
2
+/vextenddouble/vextenddoubleHΦ+/vextenddouble/vextenddouble
2/vextenddouble/vextenddoublec2−cS
2/vextenddouble/vextenddouble
2+∥y1−y2∥2/bracketrightig
. (52)
≤α/parenleftig/vextenddouble/vextenddoublef1−fS
1/vextenddouble/vextenddouble
2+/vextenddouble/vextenddoubleΦ+/vextenddouble/vextenddouble
2/vextenddouble/vextenddoublec2−cS
2/vextenddouble/vextenddouble
2/parenrightig
+1√1−δk∥y1−y2∥2, (53)
whereα= 1 +1√1−δk∥H∥2. (54)
19Published in Transactions on Machine Learning Research (01/2024)
Now, letB=Γ(qf,pˆθ), i.e. the set of all joint distributions β:Rn×n→Rthat have marginals qfandpˆθ.
Also, letρˆθbe the distribution of y=Hfforf∼pˆθ, i.e. the noiseless version of ψˆθ. Therefore, for β∈B,
E(f1,f2)∼β∥f1−f2∥2≤α/bracketleftig
Ef1∼qf/vextenddouble/vextenddoublef1−fS
1/vextenddouble/vextenddouble
2+∥Φ+∥2Ef2∼pˆθ/vextenddouble/vextenddoubleΦf2−ΦfS
2/vextenddouble/vextenddouble
2/bracketrightig
+1√1−δkE(f1,f2)∼β∥Hf1−Hf2∥2. (55)
From Lemma A.1, we have
Ef1∼qf/vextenddouble/vextenddoublef1−fS
1/vextenddouble/vextenddouble
2=W1(qf∥qSk
f)≤ϵ′. (56)
Also, from Eq. (6),
Ef2∼pˆθ/vextenddouble/vextenddoubleΦf2−ΦfS
2/vextenddouble/vextenddouble
2=Eg∼qgEf2∼pˆθ(·|g)/vextenddouble/vextenddoubleΦf2−ΦfS
2/vextenddouble/vextenddouble
2, (57)
=Eg∼qgEf∼pˆϕ(·|g)/vextenddouble/vextenddoubleΦf−ΦprojSk(f)/vextenddouble/vextenddouble
2, (58)
≤Eg∼qgEf∼pˆϕ(·|g)/vextenddouble/vextenddoubleΦf−ΦprojSk(f)/vextenddouble/vextenddouble
1, (59)
≤ϵ. (60)
Taking the infimum of Eq. (55) over β∈B, we get
inf
β∈BE(f1,f2)∼β∥f1−f2∥2≤α(ϵ′+∥Φ+∥2ϵ) +1√1−δkinf
β∈BE(f1,f2)∼β∥Hf1−Hf2∥2. (61)
Note that the left-hand side of the above equation is precisely W1(pˆθ∥qf). Also, note that the rightmost term
in Eq. (61) is W1(qy∥ρˆθ):
W1(qy∥ρˆθ) = inf
β∈BE(f1,f2)∼β∥Hf1−Hf2∥2. (62)
From Eq. (44), since qg=ψˆθ, Lemma 3.1 implies qy=ρˆθ
⇒W1(qy∥ρˆθ) = 0. (63)
Combining with Eq. (61), and setting ∥Φ+∥≤1andαaccording to Eq. (54), we get
W1(pˆθ∥qf)≤/parenleftbigg
1 +1√1−δk∥H∥2/parenrightbigg
(ϵ+ϵ′) (64)
B Additional numerical experiments
B.1 Evaluation of the posterior network
In order to evaluate the posterior network hϕ, the following experiments were designed using the setup of the
stylized MRI study. First, the consistency of the modeled posterior pϕ(·|g)and the posterior induced by the
main flow model pθ(·|g)∝qn(g−Hf)pθ(f)was examined. For a fixed measurement vector g, 50 images
were sampled from pϕ(·|g)usinghϕ. For the 50 samples, logpϕ(f|g)andlogqn(g−Hf) +logpθ(f)were
computed and plotted against each other. This was repeated was different measurement vectors g. A scatter
plot of logpϕ(f|g)versus logqn(g−Hf) +logpθ(f)is shown in Fig. 8 for the AmbientFlow trained on two
different measurement configurations – (1) fully sampled noisy measurements, and (2) 4x undersampled noisy
measurements. The scatter plots for each individual gare plotted in different colors. It can be seen that
the slope of a linear fit of the scattered points is close to 1 for all three measurement vectors considered.
This indicates that pϕ(·|g)∝qn(g−Hf)pθ(f), i.e. the modeled posterior and the posterior induced by the
learned prior are consistent.
20Published in Transactions on Machine Learning Research (01/2024)
(a) Fully sampled noisy measurements
 (b) 4x undersampled noisy measurements
Figure 8: Scatter plot of logpϕ(f|g)versus logqn(g−Hf) +logpθ(f)for three different measurement vectors
g, for AmbientFlow trained using two different measurement configurations from the stylized MRI study.
The scatter plots for each individual gare plotted in different colors.
Table 2: The mean ±standard deviation of the RMSE and SSIM values computed over the following test
image datasets – (1) the MMSE estimates using the flow prior trained on true objects, and (3) the MMSE
estimates using the AmbientFlow prior trained on measurements, and (3) the MMSE estimates using samples
fromhϕ(·|g). The forward and noise models in the image reconstruction task were the same as the ones
used to train the AmbientFlow.
Methodn/m = 1 n/m = 4
RMSE SSIM RMSE SSIM
Flow prior trained on true objects 0.017 ±0.002 0.95±0.01 0.022±0.003 0.94±0.01
AmbientFlow prior 0.016 ±0.002 0.96±0.01 0.025±0.004 0.92±0.01
Posterior network hϕ(·;g) 0.016±0.002 0.96±0.01 0.026±0.004 0.91±0.01
(a) Flow prior from true objects (b) AmbientFlow priorn/m = 1(c) Posterior networkn/m = 40.06
00.04
00.04
0
0.06
00.06
00.04
00.04
00.04
Figure 9: MMSE estimates obtained by an empirical average over images obtained from (a) Langevin dynamics-
based posterior sampling that employs the flow prior trained on true objects, (b) Langevin dynamics-based
posterior sampling that employs the AmbientFlow prior, and (c) the posterior network hϕ(·;g).
21Published in Transactions on Machine Learning Research (01/2024)
1 2 4 8
Subsampling ratio n/m for AmbientFlow training data50100150200250300FID score
AmbientFlow
PLS-TV individual recon.
Flow trained on true objects
Figure 10: FID score as a function of the undersampling ratio used to simulate the training data for
AmbientFlow for the stylized MRI study.
Table 3: MSE error in the mean of the images generated by the unconditional model relative to the true mean
image; and relative squared-Frobenius error in the rank-1000 approximation Σpof the learned covariance
matrix relative to the rank-1000 approximation Σqof the true covariance matrix.
Conventional flow n/m = 1n/m = 2n/m = 4n/m = 8
∥Epθf−Eqff∥2
2/∥Eqff∥2
20.3% 0.8% 0.7% 0.4% 1.4%
∥Σp−Σq∥2
F/∥Σq∥2
F14% 16% 15% 15% 35%
Next, for the two measurement configurations within the stylized MRI study and for a test dataset of size
20, the outputs of the posterior model hϕ(·;g)for a measurement input gwas compared with the images
reconstructed using the corresponding flow prior trained on the ground truths, as well as those reconstructed
using the corresponding AmbientFlow prior. The empirical MMSE estimates as well as pixelwise standard
deviation maps obtained from these posterior samples are shown in Fig. 9. The RMSE and SSIM of the
MMSE estimates are shown in Table 2. It can be seen that the MMSE estimates computed using samples
fromhϕ(·;g)closely resemble those computed via Langevin dynamics-based posterior sampling employing
the AmbientFlow prior, both visually, as well as in terms of the RMSE and SSIM.
B.2 Additional evaluation of unconditional models
In this section, we present additional evaluation and ablation studies on the learned unconditional models
for the stylized MRI study. Figure 10 shows the FID score as a function of the undersampling ratio used to
simulate the incomplete, noisy stylized MRI measurements used to train AmbientFlow. Next, we evaluate
the ability of our models to learn first- and second-order image statistics. For this experiment, a conventional
flow model trained on the true objects, as well as AmbientFlow models trained on noisy, undersampled
stylized MRI measurements with n/m = 1,2,4,8were considered. Figure 11 shows the empirical mean,
autocorrelation, and radial profile of the autocorrelation of images generated from the true unconditional
distribution qf, and learned unconditional distribution pθfor each of the flow models trained. The MSE error
in the empirical mean image relative to the squared ℓ2norm of the empirical mean of the true distribution is
shown in Table 3. Next, a rank-1000 approximation of the sample covariance matrix was computed for all
the models using randomized SVD of the data. Since the first and the 1000th singular values of this matrix
differed by almost 6 orders of magnitude, a low-rank approximation to the covariance matrix differs minimally
from the full covariance matrix in terms of the Frobenius norm, while also ensuring numerical stability in
computation. The error in the empirical mean image relative to the squared ℓ2norm of the empirical mean of
22Published in Transactions on Machine Learning Research (01/2024)
Real
Synthetic
Mean imageAutocorrelation &its radial proﬁlen/m = 1n/m = 2 n/m = 4 n/m = 8 True
Conventional ﬂow
Figure 11: The first row shows the empirical mean of the images generated from the true unconditional
distribution qf, and learned unconditional distribution pθfor four different undersampling ratios considered
in the sylized MRI study. The second row shows the image autocorrelations, and the third row shows the
radial profile of the autocorrelation along the dotted red line.
Table 4: The mean ±standard deviation of the RMSE and SSIM values for the CelebA face image inpainting
study computed over the following test image datasets – (1) the images reconstructed using the PLS-TV
method, (2) the MAP and MMSE estimates using the flow prior trained on true objects, and (3) the MAP
and MMSE estimates using the AmbientFlow prior trained on fully sampled noisy measurements.
Method RMSE SSIM
Navier-Stokes-based inpainting (Bertalmio et al., 2001) 24.3±6.0 0.81±0.03
Flow prior trained on true objectsMAP Estimate 17.8 ±4.5 0.81±0.05
MMSE Estimate 15.1±3.7 0.88±0.03
AmbientFlow priorMAP Estimate 17.7 ±4.4 0.80±0.03
MMSE Estimate 15.0±4.2 0.88±0.03
the true distribution is shown in Table 3. The squared-Frobenius error between the rank-1000 approximation
Σpand the learned covariance matrix relative to the rank-1000 approximation Σqof the true covariance
matrix relative to ∥Σq∥2
Fis shown in Table 3.
B.3 Additional case study: face image inpainting using AmbientFlow prior
Here, the results of a case study of face image inpainting is presented. In particular, we consider the case
where a trained uncomditional AmbientFlow is used as a prior in an image reconstruction task, where the
forward operator applicable to the task is different from the forward operator used to train the AmbientFlow.
The following two image reconstruction tasks are considered – (1) approximate maximum a posteriori (MAP)
estimation, i.e. approximating the mode of the posterior pθ(·|g), and (2) approximate sampling from the
posteriorpθ(·|g).
For both the tasks, an AmbientFlow trained on noisy face images from the CelebA dataset, as well as a
conventional flow model trained on the uncorrupted CelebA images were considered. For a held-out dataset of
size 20, the first task was performed using the compressed sensing using generative models (CSGM) formalism
(Asimet al., 2020). For the second task, approximate posterior sampling was performed with the flow models
as priors using annealed Langevin dynamics (ALD) iterations proposed in Jalal, et al.(Jalalet al., 2021a).
23Published in Transactions on Machine Learning Research (01/2024)
Flow prior trained on uncorrupted images AmbientFlow prior trained on noisy images
Figure 12: Image estimates and pixelwise standard deviation maps from the image inpainting case study.
For each true object, the MMSE estimate and the pixelwise standard deviation map ˆσwere computed
empirically using 36 samples obtained via ALD iterations. A baseline Navier-Stokes-based inpainting method
was also compared (Bertalmio et al., 2001). Table 4 shows the RMSE and SSIM of the reconstructed images
with respect to the true object, averaged over a dataset of 20 test images. It can be seen that in terms of
RMSE and SSIM, both the MAP and the MMSE image estimates obtained using the AmbientFlow prior are
comparable to those obtained using the flow prior trained on uncorrupted images, despite the AmbientFlow
being trained only using noisy CelebA images. Figure 12 shows the true and masked images along with
the images inpainted by the algorithms described above. It can be seen that although the AmbientFlow
prior provides comparable RMSE and SSIM estimates to the flow prior trained on uncorrupted images, it
still retains some smoothing artifacts characteristic of the sparsity-promoting penalty imposed on it during
training.
24