Under review as submission to TMLR
Meta-Learning an Approximate Inference Algorithm for Low-
Level Probabilistic Programs
Anonymous authors
Paper under double-blind review
Abstract
We present a meta-algorithm for learning an approximate posterior-inference algorithm for
low-level probabilistic programs that terminate. Our meta-algorithm takes a training set
of probabilistic programs that describe models with observations, and attempts to learn
an eﬃcient method for inferring the posterior of a similar program. A key feature of our
approach is the use of what we call a white-box inference algorithm that extracts information
directly from model descriptions themselves, given as programs. Concretely, our white-box
inference algorithm is equipped with multiple neural networks, one for each type of atomic
command, and computes an approximate posterior of a given probabilistic program by
analysing individual atomic commands in the program using these networks. The parameters
of the networks are learnt from a training set of programs by our meta-algorithm. We
empirically demonstrate that the learnt inference algorithm generalises well to programs
that are new in terms of both parameters and model structures, and report important use
cases where our approach, in combination with importance sampling (IS), achieves greater
test-time eﬃciency than alternatives such as HMC. The overall results show the promise as
well as remaining challenges.
1 Introduction
One key objective of probabilistic programming is to automate reasoning about probabilistic models from
diverse domains (Ritchie et al., 2015; Perov & Wood, 2016; Baydin et al., 2019; Schaechtle et al., 2016;
Cusumano-Towner et al., 2017; Saad & Mansinghka, 2016; Kulkarni et al., 2015; Young et al., 2019; Jäger
et al., 2020). As a way to realize this goal, researchers have extensively worked on the development of
posterior-inference or parameter-learning algorithms that are eﬃcient and universal; the algorithms can
be applied to all or nearly all models written in probabilistic programming languages (PPLs). This line
of research has led to performant probabilistic programming systems (Goodman et al., 2008; Wood et al.,
2014; Mansinghka et al., 2014; Minka et al., 2018; Narayanan et al., 2016; Salvatier et al., 2016; Carpenter
et al., 2017; Tran et al., 2016; Ge et al., 2018; Bingham et al., 2018). Yet, it also revealed the diﬃculty of
achieving eﬃciency and universality simultaneously, and the need for equipping PPLs with mechanisms for
customising inference or learning algorithms to a given problem. Recent PPLs allow user interactions by,
e.g., supporting constructs for specifying conditional independence in a model (Bingham et al., 2018) or for
deﬁning proposal distributions (Ritchie et al., 2015; Siddharth et al., 2017; Bingham et al., 2018; Tran et al.,
2018; Cusumano-Towner et al., 2019), but oftentimes successful customisation is highly demanding.
In this paper, we provide a limited yet promising answer to the question: can an inference algorithm learn
by experience andgeneralise to a similar but unseen probabilistic program? We present a meta-algorithm
for learning an approximate posterior-inference algorithm itself from a given set of low-level probabilistic
programs that terminate, which speciﬁes a “class” of conventional (e.g., hierarchical) or non-conventional
(e.g., Rosenbrock, and graphical with nonlinear operations) probabilistic models with observations. The
meta-algorithm aims at constructing a customised inference algorithm for the given set, while ensuring
universality to the extent that the constructed algorithm generalises within class: it works well for programs
not in the training set, as long as the programs are similar to the ones in the set.
1Under review as submission to TMLR
mass∼N(5,10); / /log of the mass of Milky Way
g1∼N(mass×2,5);/ /for the ﬁrst satellite galaxy
obs(N(g1,1),10); / /vel1= 10forvel1∼N(g1,1)
g2∼N(mass + 5,2);/ /for the second satellite galaxy
obs(N(g2,1),3)/ /vel2= 3forvel2∼N(g2,1)
Figure 1: Probabilistic program for a model for Milky Way and its two satellite galaxies. The obsstatements
refer to the observations of (unnamed) random variables vel1and vel2.
The distinguished feature of our approach is the use of what we call a white-box inference algorithm, which
extracts information directly from model descriptions themselves, given as programs in a PPL. Concretely,
our white-box inference algorithm is equipped with multiple neural networks, one for each type of atomic
command in a PPL, and computes an approximate posterior for a given program by analysing (or executing
in a sense) individual atomic commands in it using these networks. For instance, given the probabilistic
program in Fig. 1, which describes a simple model on the Milky Way galaxy, the white-box inference algorithm
analyses the program as if an RNN handles a sequence or an interpreter executes a program. Roughly, the
algorithm regards the program as a sequence of the ﬁve atomic commands (separated by the “;” symbol),
initialises its internal state h∈Rmwithh0, and transforms the state over the sequence. The internal
statehis the encoding of an approximate posterior at the current program point, which corresponds to an
approximate ﬁltering distribution of a state-space model. How to update this state over each atomic command
is directed by the corresponding neural network. Our meta-algorithm trains the parameters of these networks
by trying to make the inference algorithm compute accurate posterior approximations over a training set of
probabilistic programs. One can also view our white-box inference algorithm as a message-passing algorithm
in a broad sense where transforming the internal state hcorresponds to passing a message, and understand
our meta-algorithm as a method for learning how to pass a message for each type of atomic commands.
This way of exploiting model descriptions for posterior inference has two beneﬁts. First, it ensures that even
after customisation through the neural-network training, the inference algorithm does not lose its universality
and can be applied to any probabilistic programs. Thus, at least in principle, the algorithm has a possibility
to generalise beyond the training set; its accuracy degrades gracefully as the input probabilistic program
diverges from those in the training set. Second, our way of using model descriptions guarantees the eﬃciency
of the inference algorithm (although it does not guarantee the accuracy). The algorithm scans the input
program only once, and uses neural networks whose input dimensions are linear in the size of the program.
As a result, its time complexity is quadratic over the size of the input program. Of course, the guaranteed
speed also indicates that the customisation of the algorithm for a given training set, whose main goal is to
achieve good accuracy for probabilistic programs in the set, is a non-trivial process.
Our contributions are as follows: (i) we present a white-box posterior-inference algorithm, which works
directly on model description and can be customised to a given model class; (ii) we describe a meta-algorithm
for learning the parameters of the inference algorithm; (iii) we empirically analyse our approach with diﬀerent
model classes, and show the promise as well as the remaining challenges.
Related work The diﬃculty of developing an eﬀective posterior-inference algorithm is well-known, and has
motivated active research on learning or adapting key components of an inference algorithm. Techniques
for adjusting an MCMC proposal (Andrieu & Thoms, 2008) or an HMC integrator (Hoﬀman & Gelman,
2014) to a given inference task were implemented in popular tools. Recently, methods for meta-learning
these techniques themselves from a collection of inference tasks have been developed (Wang et al., 2018;
Gong et al., 2019). The meta-learning approach also features in the work on stochastic variational inference
where a variational distribution receives information about each inference task in the form of its dataset of
observations and is trained with a collection of datasets (Wu et al., 2020; Gordon et al., 2019; Iakovleva et al.,
2020). For a message-passing-style variational-inference algorithm, such as expectation propagation (Minka,
2Under review as submission to TMLR
u:= 0; v:= 5; w:= 1; z1∼N(u,v);z2∼N(u,v);
z3∼N(u,w);µ3:=if(z3>u)z1elsez2;
obs(N(µ3,w),−1.9);/ /x1∼N(µ3,w),x1=−1.9
z4∼N(u,w);µ4:=if(z4>u)z1elsez2;
obs(N(µ4,w),−2.2);/ /x2∼N(µ4,w),x2=−2.2
z5∼N(u,w);µ5:=if(z5>u)z1elsez2;
obs(N(µ5,w),2.4);/ /x3∼N(µ5,w),x3= 2.4
z6∼N(u,w);µ6:=if(z6>u)z1elsez2;
obs(N(µ6,w),2.2)/ /x4∼N(µ6,w),x4= 2.2
Figure 2: Probabilistic program for a simple clustering model on four data points.
2001; Wainwright & Jordan, 2008), Jitkrittum et al. (2015) studied the problem of learning a mechanism
to pass a message for a given singleinference task. A natural follow-up question is how to meta-learn
such a mechanism from a dataset of multiple inference tasks that can generalise to unseenmodels. Our
approach provides a partial answer to the question; our white-box inference algorithm can be viewed as a
message-passing-style variational inference algorithm that can meta-learn the representation of messages and
a mechanism for passing them for given probabilistic programs.
Amortised inference and inference compilation (Gershman & Goodman, 2014; Le et al., 2017; Paige & Wood,
2016; Stuhlmüller et al., 2013; Kingma & Welling, 2013; Mnih & Gregor, 2014; Rezende et al., 2014; Ritchie
et al., 2016; Marino et al., 2018) also attempt to learn a form of a posterior-inference algorithm, but the
learnt algorithm has limited scope in terms of generalisation: their learnt algorithm only generalises to unseen
inputs or observations of an assumed model, but not to new probabilistic programs. The distinction between
theirs and ours is similar to the one between a compiled program and a compiler. Note that the distinction is
language-independent; using a higher-level language in those approaches does not blur the distinction.
The idea of running programs with learnt neural networks also appears in the work on training neural
networks to execute programs (Zaremba & Sutskever, 2014; Bieber et al., 2020; Reed & de Freitas, 2016). As
far as we know, however, we are the ﬁrst to frame the problem of learning a posterior-inference algorithm as
the one of learning to execute.
2 Setup
Our results assume a low-level PPL with guaranteed termination. The PPL is low-level in the sense that it
only supports basic forms of expression and conditional statement, and does not support loops and recursion;
the design guarantees that there is no (common notion of) execution trace with inﬁnite length. The syntax of
the language is given by the following grammar, where rrepresents a real number, zandvivariables storing
a real, and pthe name of a procedure taking two real-valued parameters and returning a real number:
ProgramsC::=A|C1;C2
Atom. Commands A::=z∼N(v1,v2)|obs(N(v0,v1),r)
|v0:=if(v1>v2)v3elsev4
|v0:=r|v0:=v1|v0:=p(v1,v2)
Programs in the PPL are constructed by composing atomic commands. The language supports six types
ofatomic commands . The ﬁrst type is z∼N(v1,v2), which draws a sample from the normal distribution
with mean v1and variance v2, and assigns the sampled value to z. The second command, obs(N(v0,v1),r),
states that a random variable is drawn from N(v0,v1)and its value is observed to be r. The next is a basic
form of a conditional statement that selects one of v3andv4depending on the result of the comparison
3Under review as submission to TMLR
v1>v2. The following two commands are diﬀerent kinds of assignments, one for assigning a constant and
the other for copying a value from one variable to another. The last atomic command v0:=p(v1,v2)is a call
to one of the known deterministic procedures, which may be standard binary operations such as addition and
multiplication, or complex non-trivial functions that are used to build advanced, non-conventional models.
Whenpis a standard binary operation, we use the usual inﬁx notation and write, for example, v1+v2,
instead of +(v1,v2).
We permit only the programs where a variable does not appear more than once on the left-hand side of the
:=and∼symbols. This means that no variable is updated twice or more, and it corresponds to the so-called
static single assignment assumption in the work on compilers. This protocol lets us regard variables updated
by∼as latent random variables. We denote those variables by z1,...,zn.
The choice of the target PPL is intended. The use of basic forms of expression in atomic commands (e.g., only
variables as the arguments to a normal distribution or to a procedure p) allows the simple deﬁnition (and
training) of our white-box inference algorithm; each neural network focuses on exploiting useful information
from the kind of atomic command that it is deﬁned for, without having to discharge the complexity that
arises from general expressions. While having the important merit, the PPL can serve as an intermediate
language for a high-level PPL; the compilation scheme in §3 of (van de Meent et al., 2018), for instance,
translates a PPL with general conditional statements and for-loops into graphical models, and can be adopted
to compile such programs into our target PPL and hence to make our approach accessible to the end user.
Programs with while-loops and recursion cannot generally be translated into our PPL. See Appendix A for
further discussion.
Fig. 2 shows a simple model for clustering four data points {−1.9,−2.2,2.4,2.2}into two clusters, where
the cluster assignment of each data point is decided by thresholding a sample from the standard normal
distribution. The variables z1andz2store the centers of the two clusters, and z3,...,z 6hold the random
draws that decide cluster assignments for the data points. See Appendix B for the Milky Way example in
Fig. 1 compiled to a program in our language.
Probabilistic programs in the PPL denote unnormalised probability densities over Rnfor somen. Speciﬁcally,
for a program C, ifz1,...,znare all the variables assigned by the sampling statements zi∼N (...)in
Cin that order and Ccontainsmobserve statements with observations r1,...,rm, thenCdenotes an
unnormalised density pCover the real-valued random variables z1,...,zn:pC(z1:n) =pC(x1:m=r1:m|z1:n)×/producttextn
i=1pC(zi|z1:i−1), wherex1,...,xmare variables not appearing in Cand are used to denote observed
variables. This density is deﬁned inductively over the structure of C. See Appendix C for details. The goal of
our white-box inference algorithm is to compute eﬃciently the approximate posterior and marginal likelihood
estimate accurately for a given C(that is, for the normalised version of pCand the normalising constant of
pC), whenpChas a ﬁnite non-zero marginal likelihood and, as a result, a well-deﬁned posterior density. We
next describe how the algorithm attempts to achieve this goal.
3 White-box inference algorithm
Given a program C= (A1;...;Ak), our white-box inference algorithm views Cas a sequence of its constituent
atomic commands (A1,A2,...,Ak), and computes an approximate posterior and a marginal likelihood
estimate for Cby sequentially processing the Ai’s. Concretely, the algorithm starts by initialising its internal
state toh0=/vector0∈Rsand the current marginal-likelihood estimate to Z0= 1. Then, it updates these two
components based on the ﬁrst atomic command A1ofC. It picks a neural network appropriate for the type of
A1, applies it to h0and gets a new state h1∈Rs. Also, it updates the marginal likelihood estimate to Z1by
analysing the semantics of A1. This process is repeated for the remaining atomic commands A2,A3,...,Ak
ofC, and eventually produces the last state hkand estimate Zk. Finally, the state hkgets decoded to a
probability density on the latent variables of Cby a neural network, which together with Zkbecomes the
result of the algorithm.
Formally, our inference algorithm is built on top of three kinds of neural networks: the ones for transforming
the internal state h∈Rsof the algorithm; a neural network for decoding the internal states hto probability
densities; and the last neural network for approximately solving integration questions that arise from the
4Under review as submission to TMLR
marginal likelihood computation in observe statements. We present these neural networks for the programs
that sample n-many latent variables z1,...,zn, and use at most m-many variables (so m≥n). Let Vbe
[0,1]m, the space of the one-hot encodings of those mvariables, and Pthe set of procedure names. Our
algorithm uses the following neural networks:
nnsa,φ1:V3×Rs→Rs,nnob,φ2:V2×R×Rs→Rs,
nnif,φ3:V5×Rs→Rs,nnc
:=,φ4:V×R×Rs→Rs,
nnv
:=,φ5:V2×Rs→Rs,nnp,φp:P×V3×Rs→Rsfor everyp∈P,
nnde,φ6:Rs→(R×R)n,nnintg,φ7:V2×R×Rs→R,
whereφ1:7andφpforp∈Pare network parameters. The top six networks are for the six types of atomic
commands in our language. For instance, when an atomic command to analyse next is a sample statement
z∼N (v1,v2), the algorithm runs the ﬁrst network nnsaon the current internal state h, and obtains a
new stateh/prime=nnsa,φ1(z,v1:2,h), wherezandv1:2mean the one-hot encoded variables z,v1andv2. The
next nnde,φ6is a decoder of the states hto probability densities over the latent variables z1,...,zn, which
are the product of nindependent normal distributions. The network maps hto the means and variances
of these distributions. The last nnintg,φ7is used when our algorithm updates the marginal likelihood
estimate based on an observe statement obs(N(v0,v1),r). When we write the meaning of this observe
statement as the likelihood N(r;v0,v1), and the ﬁltering distribution for v0andv1under (the decoded
density of) the current state hasph(v0,v1),1the last neural network computes the following approximation:
nnintg,φ7(v0:1,r,h)≈/integraltext
N(r;v0,v1)ph(v0,v1)dv0dv1. See Appendix D for the full derivation of the marginal
likelihood.
Given a program C= (A1;...;Ak)that draws nsamples (and so uses latent variables z1,...,zn), the
algorithm approximates the posterior and marginal likelihood of Cas follows:
infer (C) =leth0=/vector0∈RsandZ0= 1∈Rin
let(hk,Zk) = (infer (Ak)◦...◦infer (A1))(h0,Z0)in
let((µ1,σ2
1),..., (µn,σ2
n)) = nnde,φ9(hk)in return/parenleftBign/productdisplay
i=1N(zi|µi,σ2
i), Zk/parenrightBig
,
where infer (Ai) :Rs×R→Rs×Rpicks an appropriate neural network based on the type of Ai, and uses
it to transform handZ:
infer (z∼N(v1,v2))(h, Z ) = ( nnsa(z,v1:2,h), Z),
infer (obs(N(v0,v1),r))(h, Z ) = ( nnob(v0:1,r,h),Z×nnintg(v0:1,r,h)),
infer (v0:=if(v1>v2)v3elsev4)(h, Z ) = ( nnif(v0:4,h), Z),
infer (v0:=r)(h, Z ) = ( nnc
:=(v0,r,h), Z),
infer (v0:=v1)(h, Z ) = ( nnv
:=(v0:1,h), Z),
infer (v0:=p(v1,v2))(h, Z ) = ( nnp(v0:2,h), Z).
We remind the reader that v0:krefers to the sequence of the one-hot encodings of variables v0,...,vk. For
the update of the state h, the subroutine infer (A)relies on neural networks. For the computation of the
marginal likelihood estimate, on the other hand, it exploits prior knowledge that non-observe commands do
not change the marginal likelihood (except only indirectly by changing the ﬁltering distribution), and keeps
the inputZfor those atomic commands without blindly neuralising the computation.
4 Meta-learning parameters
The parameters of our white-box inference algorithm are learnt from a collection of probabilistic programs
in our language. Assume that we are given a training set of programs D={C1,...,CN}such that each
1Theph(v0, v1)is a ﬁltering distribution, not prior.
5Under review as submission to TMLR
Cisamplesnlatent variables z1,...,znand uses at most mvariables. Let φ= (φ1:7,(φp)p∈P)be the
parameters of all the neural networks used in the algorithm. We learn these parameters by solving the
following optimisation problem:2
arg min
φ/summationdisplay
C∈DKL[πC(z1:n)||qC(z1:n)] +λ
2(NC−ZC)2
whereλ>0is a hyper-parameter, NCis the marginal likelihood (or the normalising constant)/integraltext
pC(z1:n)dz1:n
forpC, the next πC(z1:n)is the normalised posterior pC(z1:n)/NCforC, and the last qCandZCare
the approximate posterior and marginal likelihood estimate computed by the inference algorithm (that is,
(qC(z1:n),ZC) =infer (C)). Note that qCandZCboth depend on φ, since inferuses theφ-parameterised
neural networks.
We optimise the objective by stochastic gradient descent. The key component of the optimisation is a gradient
estimator derived as follows: (∇φ/summationtext
C∈DKL[πC||qC] +λ
2(NC−ZC)2) = (/summationtext
C∈DEz1:n∼πC[−∇φlogqC(z1:n)]−
λ(NC−ZC)∇φZC)≈/summationtext
C∈D−[LC,φ−λ(/hatwidestNC−ZC)∇φZC. Here [LC,φand/hatwidestNCare sample estimates of
Ez1:n∼πC[∇φlogqC(z1:n)]and the marginal likelihood, respectively. Both estimates can be computed using
standard Monte-Carlo algorithms. For instance, we can run the self-normalising IS with prior as proposal, and
generate weighted samples {(w(j),z(j)
1:n)}1≤j≤Mfor the unnormalised posterior pC. Then, we can use these sam-
ples to compute the required estimates: /hatwidestNC=1
M/summationtextM
j=1w(j)and[LC,φ=1
M/summationtextM
j=1(w(j)∇φlogqC(z(j)
1:n))//hatwidestNC.
Alternatively, we may run Hamiltonian Monte Carlo (HMC) (Duane et al., 1987) to generate posterior
samples, and use those samples to draw weighted importance samples using, for instance, the layered adaptive
IS (Martino et al., 2017). Then, we compute [LC,φusing posterior samples, and /hatwidestNCusing weighted importance
samples. Note that neither πCinEz1:n∼πC[−∇φlogqC(z1:n)]norNCdepends on the parameters φ. Thus, for
eachC∈D,NCneeds to be estimated only once throughout the entire optimisation process, and the posterior
samples from πCneed to be generated only once as well. We use this fact to speed up the computation of
each gradient-update step.
5 Empirical evaluation
An eﬀective meta-algorithm should generalise well: the learnt inference algorithm should accurately predict
the posteriors of programs unseen during training which have diﬀerent parameters (§5.1) and model structures
(§5.2), as long as the programs are similar to those in the training set. We empirically show that our
meta-algorithm learns such an inference algorithm, and demonstrate important use cases where the learnt
inference algorithm, when applied to IS as proposal, achieves higher test-time eﬃciency than alternatives
such as HMC (Duane et al., 1987) (§5.3). We implemented our inference algorithm and meta-algorithm
using ocaml-torch (Mazare, 2018) (Apache-2.0 License). For HMC, we used the NUTS sampler (Hoﬀman &
Gelman, 2014) from the Python interface for Stan (Carpenter et al., 2017) (CC-BY 4.0 license). We used
a Ubuntu server with Intel(R) Xeon(R) Gold 6234 CPU @ 3.30GHz with 16cores, 32threads, and 263G
memory. Table 1 summarizes the full list of the model classes that we considered in our empirical evaluation.
See Appendices E and F for the full details of our model classes and experimental setup.
5.1 Generalisation to new model parameters and observations
We evaluated our approach with six model classes: Gaussian models ( gauss), two hierarchical models ( hierl
and hierd), clustering models ( cluster), Milky Way models ( milkyand milkyo), and models ( rb) using the
Rosenbrock function,3(see Table 1). The purpose of our evaluation is to show the feasibility of our approach,
not to develop the state-of-the-art inference algorithm automatically, and also to identify the challenges of
the approach. These models are chosen for this purpose. For instance, an inference algorithm should be able
to reason about aﬃne transformations and Gaussian distributions (for gauss), and dependency relationships
2Strictly speaking, we assume that the marginal likelihood of any C∈Dis non-zero and ﬁnite.
3The function is often used to evaluate learning and inference algorithms (Goodman & Weare, 2010; Wang & Li, 2018; Pagani
et al., 2019).
6Under review as submission to TMLR
Table 1: Full list of the model classes in the empirical evaluation.
Section Model class Description Detail
§5.1gauss Gaussian models with a latent variable and
an observation where the mean of the Gaus-
sian likelihood is an aﬃne transformation
of the latent.AppendixE.1.1
hierl Hierarchical models with three hierarchi-
cally structured latent variables.AppendixE.1.2
hierd Hierarchicalormulti-levelmodelswithboth
latent variables and data structured hier-
archically where data are modelled as a
regression of latent variables of diﬀerent
levels.AppendixE.1.3
cluster Clustering models where ﬁve observations
are clustered into two groups.AppendixE.1.4
milkyandmilkyo Milky Way models ( milky), and their
multiple-observations extension ( milkyo)
where ﬁve observations are made for each
satellite galaxy.AppendixE.1.5
rb Models with the Rosenbrock function,
which is expressed as an external procedure.
The main purpose of rbis to show that our
approach can in principle handle models
with non-trivial computation blocks.AppendixE.1.6
§5.2ext1 Models with three Gaussian variables and
one deterministic variable storing the value
ofthefunction nl(x) = 50/π×arctan (x/10),
where the models have 12diﬀerent types
— four diﬀerent dependency graphs of the
variables, and three diﬀerent positions of
the deterministic nlvariable for each of
these graphs.AppendixE.2.1
(and Fig. 9)
ext2 Models with six Gaussian variables and
onenlvariable, which are grouped into
ﬁve model types based on their dependency
graphs.AppendixE.2.2
(and Fig. 10)
§5.3 mulmod Three-variable models where two latent
variables follow normal distributions and
the other stores the value of the function
mm(x) = 100×x3/(10 +x4). The models
in this class are grouped into three types
deﬁned by their dependency graphs and the
positions of mmin the programs.Appendix E.3
(and Fig. 11)
7Under review as submission to TMLR
1000 2000 3000 4000 500010100
Seed, T r or T e
1, Tr
1, Te
2, Tr
2, Te
3, Tr
3, Te
EpochLoss
(a)gauss
500 1000 1500 2000101001000
Seed, T r or T e
1, Tr
1, Te
2, Tr
2, Te
3, Tr
3, Te
EpochLoss (b)hierl
1000 2000 3000 400010100100010k
Seed, T r or T e
1, Tr
1, Te
2, Tr
2, Te
3, Tr
3, Te
EpochLoss (c)milky
Figure 3: Average training and test losses under three random seeds. The y-axes are log-scaled. The increases
in later epochs of Fig. 3c were due to only one or a few test programs out of 50.
pgm11_gammapgm11_theta1pgm11_theta2pgm12_gammapgm12_theta1pgm12_theta2pgm13_gammapgm13_theta1pgm13_theta2pgm14_gammapgm14_theta1pgm14_theta2pgm15_gammapgm15_theta1pgm15_theta2pgm16_gammapgm16_theta1pgm16_theta2pgm17_gammapgm17_theta1pgm17_theta2pgm18_gammapgm18_theta1pgm18_theta2pgm19_gammapgm19_theta1pgm19_theta2pgm20_gammapgm20_theta1pgm20_theta2−100−50050R efer ence
P r edicted
(a) Before training
pgm11_gammapgm11_theta1pgm11_theta2pgm12_gammapgm12_theta1pgm12_theta2pgm13_gammapgm13_theta1pgm13_theta2pgm14_gammapgm14_theta1pgm14_theta2pgm15_gammapgm15_theta1pgm15_theta2pgm16_gammapgm16_theta1pgm16_theta2pgm17_gammapgm17_theta1pgm17_theta2pgm18_gammapgm18_theta1pgm18_theta2pgm19_gammapgm19_theta1pgm19_theta2pgm20_gammapgm20_theta1pgm20_theta2−100−50050100150R efer ence
P r edicted (b) After 1K epochs
pgm11_gammapgm11_theta1pgm11_theta2pgm12_gammapgm12_theta1pgm12_theta2pgm13_gammapgm13_theta1pgm13_theta2pgm14_gammapgm14_theta1pgm14_theta2pgm15_gammapgm15_theta1pgm15_theta2pgm16_gammapgm16_theta1pgm16_theta2pgm17_gammapgm17_theta1pgm17_theta2pgm18_gammapgm18_theta1pgm18_theta2pgm19_gammapgm19_theta1pgm19_theta2pgm20_gammapgm20_theta1pgm20_theta2−100−80−60−40−2002040R efer ence
P r edicted (c) After 2K epochs
Figure 4: Comparisons of predicted (red) and reference (blue) marginal posteriors for the test programs, with
the inference algorithm instantiated at three diﬀerent training steps: at the initial step, after 1K epochs, and
after 2K epochs.
among variables (for hierland hierd) to compute a posterior accurately. Successful outcomes in the classes
indicate that our approach learns an inference algorithm with such capacity in some cases.
SetupFor each model class, we used 400programs to meta-learn an inference algorithm, and then applied
the learnt algorithm to 50unseen test programs. We measured the average test loss over the 50test programs,
and checked if the loss also decreases when the training loss decreases. We also compared the marginal
posteriors predicted by our learnt inference algorithm with the reference marginal posteriors that were
computed analytically, or approximately by HMC. When we relied on HMC, we computed the marginal
sample means and standard deviations using one of the 10Markov chains generated by independent HMC runs.
Each chain consisted of 500K samples after 50K warmups. We ensured the convergence of the chains using
diagnostics such as ˆR(Gelman et al., 1992). All training and test programs were automatically generated by
a random program generator. This generator takes a program class and hyperparameters (e.g., boundaries
of the quantities that are used to specify the models), and returns programs from the class randomly (see
Appendix E ).
For each training program, our meta-algorithm used 215samples from the analytic (for gauss) or approximate
(for the rest, by HMC) posterior distribution for the program.4Similarly, our meta-algorithm computed
the marginal likelihood analytically (for gauss) or approximately (for the rest) using layered adaptive IS
(Martino et al., 2017) where the proposals were deﬁned by an HMC chain. We performed mini-batch
training; a single gradient update was done with a training program and a mini batch of size 212(out of 215
samples for the program). We used Adam (Kingma & Ba, 2015) with its hyperparameters {β1= 0.9, β2=
0.999,weight_decay = 0}, and the initial learning rate was set to 0.001. When the average training loss
4Except for rb; see the discussion on Rosenbrock models in Appendix H.
8Under review as submission to TMLR
1000 2000 3000 4000 500010100100010k100k1M10M100M1B10B100B1T
Seed, T r or T e
1, Tr
1, Te
2, Tr
2, Te
3, Tr
3, Te
EpochLoss
(a) To 1st dep. graph.
2000 4000 6000 800010100100010k100k1M10M100M1B10B100B1T10T100T10 15 
Seed, T r or T e
1, Tr
1, Te
2, Tr
2, Te
3, Tr
3, Te
EpochLoss (b) To 2nd dep. graph.
1000 2000 3000 4000 500010100100010k100k1M10M100M1B10B
Seed, T r or T e
1, Tr
1, Te
2, Tr
2, Te
3, Tr
3, Te
EpochLoss (c) To 3rd dep. graph.
Figure 5: Average losses for generalisation to dependency graphs in ext1. The y-axes are log-scaled.
1000 2000 3000 4000 5000 60001001000
 Seed, T r or T e
1, Tr 1, Te 2, Tr 2, Te
3, Tr 3, Te
EpochLoss
(a) To 1st dep. graph.
1000 2000 3000 4000 5000 6000100100010k
Seed, T r or T e
1, Tr
1, Te
2, Tr
2, Te
3, Tr
3, Te
EpochLoss (b) To 2nd dep. graph.
1000 2000 3000 4000 5000100100010k100k
Seed, T r or T e
1, Tr
1, Te
2, Tr
2, Te
3, Tr
3, Te
EpochLoss (c) To 3rd dep. graph.
Figure 6: Average losses for generalisation to dependency graphs in ext2. The y-axes are log-scaled.
converged enough, the training stopped. We repeated the same experiments three times using diﬀerent
random seeds.
Results Fig. 3 shows the training and test losses for gauss,hierl, and milkyunder three random seeds. The
losses for the other model classes are in Appendix G. The training loss was averaged over the training set and
8batch updates, and the test loss over the test set. The training losses in all three experiments decreased
rapidly, and more importantly, these decreases were accompanied by the downturns of the test losses, which
shows that the learnt parameters generalised to the test programs well. The later part of Fig. 3c shows cases
where the test loss increases. This was because the loss of only a few programs in the test set (of 50programs)
became large. Even in this situation, the losses of the rest remained small.
Fig. 4 compares, for 10test programs in hierl, the reference marginal posteriors (blue) and their predicted
counterparts (red) by the learnt inference algorithm instantiated at three diﬀerent training epochs. The
predicted marginals were initially around zero (Fig. 4a), evolved to cover the reference marginals (Fig. 4b),
and ﬁnally captured them precisely in terms of both mean and standard deviation for most of the variables
(Fig. 4c). The results show that our meta-algorithm improves the parameters of our inference algorithm, and
eventually ﬁnds optimal ones that generalise well. We observed similar patterns for the other model classes
and random seeds, except for clusterandrb; programs from these classes often have multimodal posteriors,
and we provide an analysis for them in Appendix H.
5.2 Generalisation to new model structures
We let two kinds of model structure vary across programs: the dependency (or data-ﬂow) graph for the
variables of a program and the position of a nonlinear function in the program. Speciﬁcally, we considered
two model classes: (1) models ( ext1) with three Gaussian variables and one deterministic variable storing the
value of the function nl(x) = 50/π×arctan (x/10), where the models have 12diﬀerent types — four diﬀerent
dependency graphs of the variables, and three diﬀerent positions of the deterministic nlvariable for each of
9Under review as submission to TMLR
Table 2: ESS per sec for the 60test programs by HMC vs. IS-pred vs. IS-prior.
HMC IS-pred IS-prior
GM Q1 Q3 GM Q1 Q3 GM Q1 Q3
ESS 204.8K 4.1K 4.6M 4.2K 2.2K 13.8K 2.8K 1.1K 9.5K
Time 48.2s 27.4s 82.3s 22.7ms 21.4ms 23.0ms 23.1ms 22.1ms 24.0ms
ESS / sec 4.3K 124 127.7K196 .5K 102 .4K 646 .5K 123.8K 52.6K 436.1K
these graphs; and (2) models ( ext2) with six Gaussian variables and one nlvariable, which are grouped into
ﬁve types based on their dependency graphs. The evaluation was done for ext1andext2independently as in
§5.1, but here each of ext1andext2itself has programs of multiple ( 12forext1and5forext2) model types.
See Fig. 9 and 10 in the appendix for visualisation of the diﬀerent model types in ext1andext2.
SetupForext1, we ran seven diﬀerent experiments. Three of them evaluated generalisation to unseen
positions of the nlvariable, and the other four to unseen dependency graphs. Let Ti,jbe the type in ext1
that corresponds to the i-th position of nland thej-th dependency graph, and T−i,∗be all the types in ext1
that correspond to any nlpositions except the i-th and any of four dependency graphs. For generalisation
to thei-th position of nl(i= 1,2,3), we used programs from T−i,∗for training and those from Ti,∗for
testing. For generalisation to the j-th dependency graph ( j= 1,2,3,4), we used programs from T∗,−jfor
training and those from T∗,jfor testing. For ext2, we ran ﬁve diﬀerent experiments where each of them tested
generalisation to an unseen dependency graph after training with the other four dependency graphs. All these
experiments were repeated three times under diﬀerent random seeds. So, the total numbers of experiment
runs were 21 (= 7×3)and15 (= 5×3)forext1andext2, respectively.
In each experiment run for ext1, we used 720programs for training, and 90(when generalising to new graphs)
or100(when generalising to new positions of the nlvariable) unseen programs for testing. In each run for
ext2, we used 600programs for training and tested the learnt inference algorithm on 50unseen programs.
We ran HMC to estimate posteriors and marginal likelihoods, and used 200K samples after 10K warmups to
compute reference posteriors. We stopped training after giving enough time for convergence within a limit of
computational resources. The rest was the same as in §5.1.
Results Fig. 5 shows the average training and test losses for generalisation to the ﬁrst three dependency
graphs in ext1. Fig. 6 shows the losses for generalisation to the ﬁrst three dependency graphs in ext2. The
losses for generalisation to the last dependency graph and to all positions of the nlvariable in ext1, and those
for generalisation to the 4th and 5th dependency graphs in ext2are in Appendices I and J. In 17runs (out of
21) for ext1, the decrease in the training losses eventually stabilised or reduced the test losses, even when the
test losses were high and ﬂuctuated in earlier training epochs. In 8runs (out of 15) for ext2, the test losses
were stabilised as the training losses decreased. In 4runs out of the other 7, the test losses increased only
slightly. In terms of predicted posteriors, we observed highly accurate predictions in 8runs for ext1. For
ext2, the predicted posteriors were accurate in 7runs. We also measured the improvements in KL[p/prime(z)||q(z)]
for all the test programs, where p/primeis the marginal posterior for a latent variable z; we refer the reader to
Appendix K for the details. Overall, the learnt algorithms generalised to unseen types of models well or fairly
well in many cases.
5.3 Application to IS: test-time eﬃciency in comparison with alternatives
The learnt inference algorithm is a standalone artifact, but another important use case is its application to IS
as proposal. In fact, application of variational techniques to samplers such as IS Stites et al. (2021); Jerfel
et al. (2021) and MCMC Liang et al. (2021) is an active research, and we demonstrate the inference-time
beneﬁts of our application in the setup of generalisation across probabilistic programs.
Speciﬁcally, we studied a class ( mulmod) of three-variable models where two latent variables follow normal
distributions and the other stores the value of the function mm(x) = 100×x3/(10 +x4). The models are
grouped into three types deﬁned by their dependency graphs and the positions of mmin the programs
(see Fig.11 in the appendix). We ran our meta-algorithm using 600programs from all three types using
10Under review as submission to TMLR
0.3s1.1s3.7s27.3s84.2s
Elapsed time2000250030003500400045005000Sum of second moments
IS-ref
HMC
(a) Moments by HMC.
1.86ms
2.33ms
4.9ms
6.65ms
18ms
Elapsed time475048004850490049505000Sum of second moments
IS-ref
IS-pred
IS-prior (b) Moments by IS-pred and IS-prior.
1.86ms
2.33ms
4.9ms
6.65ms
18ms
Elapsed time0200040006000800010000120001400016000ESS
IS-pred
IS-prior (c) ESS by IS-pred and IS-prior.
Figure 7: Moments and ESS for pgm19from mulmod.
importance samples (not HMC samples). Then for 60test programs from the last model type, we measured
ESS and the sum of second moments along the wall-clock time using three approaches: IS (IS-pred; ours)
with the predicted posteriors as proposal using 70K samples, IS (IS-prior) with prior as proposal using 100K
samples, and HMC with 1M samples after 500warmups. As the reference sampler, we used IS (IS-ref) with
prior as proposal using 5M samples. All the approaches were repeated 10times.
Table 2 shows the average ESS per unit time over the 60test programs, by the three approaches. For HMC,
“ESS” and “ESS / sec” were computed using 10Markov chains, averaged over the 60programs. For IS-{pred,
prior}, “ESS” and “ESS / sec” were averaged over the 10trials and the 60programs. GM is the geometric
mean, and Q1 and Q3 are the ﬁrst and third quartiles, respectively. We used the geometric mean, since
the ESSes had outliers. The results show that IS-pred achieved the highest ESS per unit time in terms of
both mean (GM) and the quartiles (Q1 and Q3). Similarly to §5.2, we also observed the improvements in
KL[p/prime(z)||q(z)]for the marginal distributions (see Appendix K).
We provide further analysis for a test program ( pgm19; see Appendix L). Fig. 7a and 7b show the moments
estimated by HMC and IS-{pred, prior}, respectively, in comparison with the same (across the two ﬁgures)
reference moments by IS-ref. The estimates by IS-pred (red) quickly converged to the reference (green) within
18ms, while those by HMC (orange) did not converge even after 84s. IS-pred (red) and IS-prior (blue) tended
to produce better estimates as the elapsed time increased, but each time, IS-pred estimated the moments
more precisely with a smaller variance than IS-prior. In the same runs of the three approaches as in the last
columns of Fig. 7a and 7b, IS-pred produced over 16K eﬀective samples in 18ms, while HMC generated only
80eﬀective samples even after 84s. Similarly, IS-prior generated fewer than 1.4K eﬀective samples in the
approximately same elapsed time as in IS-pred. In fact, Fig. 7c shows that as the time increases, the gap
between the ESSes of IS-pred and IS-prior gets widen, because the former increases at a rate signiﬁcantly
higher than the latter. Note that IS-pred has to scan a program twice at test time, once for computing the
proposal and another for IS with the predicted proposal, whereas IS-prior only once; we observed that the
advantage to IS-prior quickly disappeared as the number of IS samples grew (see Appendix M). By manual
inspection, we found that the programs in mulmodoften had multimodal posteriors. We refer the reader to
Appendix N for more details.
6 Limitations and future work
Ideally, the meta-algorithm should learn an inference algorithm that eﬀectively solves an inference problem
for an arbitrary probabilistic program in the target PPL. Here we clarify the limitations of this work and
suggest important future work, as stepping stones to the ultimate goal:
•Though we have demonstrated eﬀective generalisation of the learnt inference algorithm to unseen
probabilistic programs, the generalisation is only within a controlled class of modeling problems. For
example, the learnt inference algorithm does not generalise to programs with diﬀerent sizes (Yan
et al., 2020); for clustering problems, it means that the learnt algorithm for two-cluster settings is
11Under review as submission to TMLR
unapplicable to ten-cluster scenarios. Each model class that we studied assumes a ﬁxed number of
variables, and the neural networks crucially exploit the assumption.
•Our meta-algorithm does not scale in practice. When applied to large programs, e.g., state-space
models with a few hundred time steps, it cannot learn an optimal inference algorithm within a
reasonable amount of time. Overcomming this limitation is important for more realistic problem
solving.
•Another direction of improvement is to remove the strong independence assumption (via mean ﬁeld
Gaussian) on the approximating distribution in our inference algorithm, and to equip the algorithm
with the capability of generating an appropriate form of the approximation distribution with rich
dependency structure, by, e.g., incorporating the ideas from Ambrogioni et al. (2021). This direction
is closely related to automatic guide generation in Pyro (Bingham et al., 2018).
7 Conclusion
In this paper, we presented a white-box inference algorithm that computes an approximate posterior and
a marginal likelihood estimate by analysing the given program sequentially using neural networks, and a
meta-algorithm that learns the network parameters over a training set of probabilistic programs. In our
experiments, the meta-algorithm learnt an inference algorithm that generalises well to unseen programs within
class, and the learnt inference algorithm brought test-time advantages over alternatives in the important
application to IS that we studied. A moral of this work is that the description of a probabilistic model itself
has useful information, and learning to exploit the information may lead to an eﬃcient inference. We hope
that our work encourages further exploration of this direction.
12Under review as submission to TMLR
References
Luca Ambrogioni, Gianluigi Silvestri, and Marcel van Gerven. Automatic variational inference with cascading
ﬂows.arXiv preprint arXiv:2102.04801 , 2021.
Christophe Andrieu and Johannes Thoms. A tutorial on adaptive MCMC. Stat. Comput. , 18(4):343–373,
2008.
Atilim Gunes Baydin, Lei Shao, Wahid Bhimji, Lukas Heinrich, Saeid Naderiparizi, Andreas Munk, Jialin
Liu, Bradley Gram-Hansen, Gilles Louppe, Lawrence Meadows, Philip Torr, Victor Lee, Kyle Cranmer,
Mr. Prabhat, and Frank Wood. Eﬃcient probabilistic inference in the quest for physics beyond the
standard model. In Advances in Neural Information Processing Systems , volume 32, pp. 5459–5472. Curran
Associates, Inc., 2019.
David Bieber, Charles Sutton, Hugo Larochelle, and Daniel Tarlow. Learning to execute programs with
instruction pointer attention graph neural networks. In Advances in Neural Information Processing Systems
33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12,
2020, virtual , 2020.
Eli Bingham, Jonathan P. Chen, Martin Jankowiak, Fritz Obermeyer, Neeraj Pradhan, Theofanis Karaletsos,
Rohit Singh, Paul Szerlip, Paul Horsfall, and Noah D. Goodman. Pyro: Deep universal probabilistic
programming. Journal of Machine Learning Research , 2018.
Bob Carpenter, Andrew Gelman, Matthew D Hoﬀman, Daniel Lee, Ben Goodrich, Michael Betancourt,
Marcus Brubaker, Jiqiang Guo, Peter Li, and Allen Riddell. Stan: A probabilistic programming language.
Journal of statistical software , 76(1), 2017.
Marco F Cusumano-Towner, Alexey Radul, David Wingate, and Vikash K Mansinghka. Probabilistic
programs for inferring the goals of autonomous agents. arXiv preprint arXiv:1704.04977 , 2017.
Marco F. Cusumano-Towner, Feras A. Saad, Alexander K. Lew, and Vikash K. Mansinghka. Gen: a
general-purpose probabilistic programming system with programmable inference. In Proceedings of the 40th
ACM SIGPLAN Conference on Programming Language Design and Implementation, PLDI 2019, Phoenix,
AZ, USA, June 22-26, 2019 , pp. 221–236. ACM, 2019.
Simon Duane, Anthony D Kennedy, Brian J Pendleton, and Duncan Roweth. Hybrid Monte Carlo. Physics
letters B, 195(2):216–222, 1987.
Hong Ge, Kai Xu, and Zoubin Ghahramani. Turing: Composable inference for probabilistic programming. In
International Conference on Artiﬁcial Intelligence and Statistics, AISTATS 2018, 9-11 April 2018, Playa
Blanca, Lanzarote, Canary Islands, Spain , volume 84 of Proceedings of Machine Learning Research , pp.
1682–1690. PMLR, 2018.
Andrew Gelman, Donald B Rubin, et al. Inference from iterative simulation using multiple sequences.
Statistical science , 7(4):457–472, 1992.
Samuel Gershman and Noah Goodman. Amortized inference in probabilistic reasoning. In Proceedings of the
annual meeting of the cognitive science society , volume 36, 2014.
Wenbo Gong, Yingzhen Li, and José Miguel Hernández-Lobato. Meta-learning for stochastic gradient MCMC.
In7th International Conference on Learning Representations, ICLR 2019, New Orleans, LA, USA, May
6-9, 2019 . OpenReview.net, 2019.
Jonathan Goodman and Jonathan Weare. Ensemble samplers with aﬃne invariance. Communications in
applied mathematics and computational science , 5(1):65–80, 2010.
Noah D Goodman, Vikash K Mansinghka, Daniel Roy, Keith Bonawitz, and Joshua B Tenenbaum. Church:
a language for generative models. In Proceedings of the Twenty-Fourth Conference on Uncertainty in
Artiﬁcial Intelligence , pp. 220–229, 2008.
13Under review as submission to TMLR
Jonathan Gordon, John Bronskill, Matthias Bauer, Sebastian Nowozin, and Richard E. Turner. Meta-learning
probabilistic inference for prediction. In 7th International Conference on Learning Representations, ICLR
2019, New Orleans, LA, USA, May 6-9, 2019 . OpenReview.net, 2019.
Matthew D. Hoﬀman and Andrew Gelman. The No-U-Turn sampler: adaptively setting path lengths in
Hamiltonian Monte Carlo. J. Mach. Learn. Res. , 15(1):1593–1623, 2014.
Ekaterina Iakovleva, Jakob Verbeek, and Karteek Alahari. Meta-learning with shared amortized variational
inference. In Proceedings of the 37th International Conference on Machine Learning, ICML 2020, 13-18
July 2020, Virtual Event , volume 119 of Proceedings of Machine Learning Research , pp. 4572–4582. PMLR,
2020.
Ghassen Jerfel, Serena Wang, Clara Wong-Fannjiang, Katherine A. Heller, Yian Ma, and Michael I. Jordan.
Variational reﬁnement for importance sampling using the forward Kullback-Leibler divergence. In Cassio
de Campos and Marloes H. Maathuis (eds.), Proceedings of the Thirty-Seventh Conference on Uncertainty
in Artiﬁcial Intelligence , volume 161 of Proceedings of Machine Learning Research , pp. 1819–1829. PMLR,
27–30 Jul 2021. URL https://proceedings.mlr.press/v161/jerfel21a.html .
Wittawat Jitkrittum, Arthur Gretton, Nicolas Heess, S. M. Ali Eslami, Balaji Lakshminarayanan, Dino
Sejdinovic, and Zoltán Szabó. Kernel-based just-in-time learning for passing expectation propagation
messages. In Proceedings of the Thirty-First Conference on Uncertainty in Artiﬁcial Intelligence, UAI
2015, July 12-16, 2015, Amsterdam, The Netherlands , pp. 405–414. AUAI Press, 2015.
Lena A. Jäger, Daniela Mertzen, Julie A. Van Dyke, and Shravan Vasishth. Interference patterns in subject-
verb agreement and reﬂexives revisited: A large-sample study. Journal of Memory and Language , 111:
104063, 2020. ISSN 0749-596X.
Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In 3rd International
Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference
Track Proceedings , 2015.
Diederik P Kingma and Max Welling. Auto-encoding variational Bayes. arXiv preprint arXiv:1312.6114 ,
2013.
Tejas D Kulkarni, Pushmeet Kohli, Joshua B Tenenbaum, and Vikash Mansinghka. Picture: A probabilistic
programming language for scene perception. In Proceedings of the ieee conference on computer vision and
pattern recognition , pp. 4390–4399, 2015.
Tuan Anh Le, Atilim Gunes Baydin, and Frank Wood. Inference compilation and universal probabilistic
programming. In Artiﬁcial Intelligence and Statistics , pp. 1338–1348. PMLR, 2017.
Feynman Liang, Nimar Arora, Nazanin Tehrani, Yucen Li, Michael Tingley, and Erik Meijer. Accelerating
Metropolis-Hastings with lightweight inference compilation. In Arindam Banerjee and Kenji Fukumizu
(eds.),Proceedings of The 24th International Conference on Artiﬁcial Intelligence and Statistics , volume
130 ofProceedings of Machine Learning Research , pp. 181–189. PMLR, 13–15 Apr 2021. URL https:
//proceedings.mlr.press/v130/liang21a.html .
Vikash Mansinghka, Daniel Selsam, and Yura Perov. Venture: a higher-order probabilistic programming
platform with programmable inference. arXiv preprint arXiv:1404.0099 , 2014.
Joe Marino, Yisong Yue, and Stephan Mandt. Iterative amortized inference. In International Conference on
Machine Learning , pp. 3403–3412, 2018.
Luca Martino, Victor Elvira, David Luengo, and Jukka Corander. Layered adaptive importance sampling.
Statistics and Computing , 27(3):599–623, 2017.
Laurent Mazare. ocaml-torch: OCaml bindings for pytorch, 2018. URL https://github.com/
LaurentMazare/ocaml-torch .
14Under review as submission to TMLR
T. Minka, J.M. Winn, J.P. Guiver, Y. Zaykov, D. Fabian, and J. Bronskill. /Infer.NET 0.3, 2018. Microsoft
Research Cambridge. http://dotnet.github.io/infer.
Thomas P. Minka. Expectation propagation for approximate Bayesian inference. In UAI ’01: Proceedings of
the 17th Conference in Uncertainty in Artiﬁcial Intelligence, University of Washington, Seattle, Washington,
USA, August 2-5, 2001 , pp. 362–369. Morgan Kaufmann, 2001.
Andriy Mnih and Karol Gregor. Neural variational inference and learning in belief networks. In International
Conference on Machine Learning , pp. 1791–1799, 2014.
Praveen Narayanan, Jacques Carette, Wren Romano, Chung-chieh Shan, and Robert Zinkov. Probabilistic
inference by program transformation in hakaru (system description). In International Symposium on
Functional and Logic Programming - 13th International Symposium, FLOPS 2016, Kochi, Japan, March
4-6, 2016, Proceedings , pp. 62–79. Springer, 2016.
Filippo Pagani, Martin Wiegand, and Saralees Nadarajah. An n-dimensional rosenbrock distribution for
mcmc testing. arXiv preprint arXiv:1903.09556 , 2019.
Brooks Paige and Frank Wood. Inference networks for sequential Monte Carlo in graphical models. In
International Conference on Machine Learning , pp. 3040–3049, 2016.
Yura Perov and Frank Wood. Automatic sampler discovery via probabilistic programming and approximate
Bayesian computation. In Artiﬁcial General Intelligence , pp. 262–273, Cham, 2016. Springer International
Publishing. ISBN 978-3-319-41649-6.
Scott E. Reed and Nando de Freitas. Neural programmer-interpreters. In 4th International Conference
on Learning Representations, ICLR 2016, San Juan, Puerto Rico, May 2-4, 2016, Conference Track
Proceedings , 2016.
Danilo Jimenez Rezende, Shakir Mohamed, and Daan Wierstra. Stochastic backpropagation and approximate
inference in deep generative models. In International Conference on Machine Learning , pp. 1278–1286,
2014.
Daniel Ritchie, Ben Mildenhall, Noah D. Goodman, and Pat Hanrahan. Controlling procedural modeling
programs with stochastically-ordered sequential Monte Carlo. ACM Trans. Graph. , 34(4), July 2015. ISSN
0730-0301.
Daniel Ritchie, Paul Horsfall, and Noah D Goodman. Deep amortized inference for probabilistic programs.
arXiv preprint arXiv:1610.05735 , 2016.
Feras Saad and Vikash K Mansinghka. A probabilistic programming approach to probabilistic data analysis.
InAdvances in Neural Information Processing Systems , pp. 2011–2019, 2016.
John Salvatier, Thomas V Wiecki, and Christopher Fonnesbeck. Probabilistic programming in python using
pymc3.PeerJ Computer Science , 2:e55, 2016.
Ulrich Schaechtle, Feras Saad, Alexey Radul, and Vikash Mansinghka. Time series structure discovery via
probabilistic program synthesis. arXiv preprint arXiv:1611.07051 , 2016.
N. Siddharth, Brooks Paige, Jan-Willem van de Meent, Alban Desmaison, Noah D. Goodman, Pushmeet
Kohli, Frank Wood, and Philip Torr. Learning disentangled representations with semi-supervised deep
generative models. In Advances in Neural Information Processing Systems 30 , pp. 5927–5937. Curran
Associates, Inc., 2017.
Sam Stites, Heiko Zimmermann, Hao Wu, Eli Sennesh, and Jan-Willem van de Meent. Learning proposals
for probabilistic programs with inference combinators. In Cassio de Campos and Marloes H. Maathuis
(eds.),Proceedings of the Thirty-Seventh Conference on Uncertainty in Artiﬁcial Intelligence , volume
161 ofProceedings of Machine Learning Research , pp. 1056–1066. PMLR, 27–30 Jul 2021. URL https:
//proceedings.mlr.press/v161/stites21a.html .
15Under review as submission to TMLR
Andreas Stuhlmüller, Jacob Taylor, and Noah Goodman. Learning stochastic inverses. In Advances in neural
information processing systems , pp. 3048–3056, 2013.
Dustin Tran, Alp Kucukelbir, Adji B. Dieng, Maja Rudolph, Dawen Liang, and David M. Blei. Edward: A
library for probabilistic modeling, inference, and criticism. arXiv preprint arXiv:1610.09787 , 2016.
Dustin Tran, Matthew D. Hoﬀman, Dave Moore, Christopher Suter, Srinivas Vasudevan, and Alexey Radul.
Simple, distributed, and accelerated probabilistic programming. In Advances in Neural Information
Processing Systems 31: Annual Conference on Neural Information Processing Systems 2018, NeurIPS 2018,
December 3-8, 2018, Montréal, Canada , pp. 7609–7620, 2018.
Jan-Willem van de Meent, Brooks Paige, Hongseok Yang, and Frank Wood. An introduction to probabilistic
programming. arXiv preprint arXiv:1809.10756 , 2018.
Martin J. Wainwright and Michael I. Jordan. Graphical models, exponential families, and variational inference.
Found. Trends Mach. Learn. , 1(1-2):1–305, 2008.
Hongqiao Wang and Jinglai Li. Adaptive gaussian process approximation for Bayesian inference with expensive
likelihood functions. Neural computation , 30(11):3072–3094, 2018.
Tongzhou Wang, Yi Wu, Dave Moore, and Stuart J. Russell. Meta-learning MCMC proposals. In Advances in
Neural Information Processing Systems 31: Annual Conference on Neural Information Processing Systems
2018, NeurIPS 2018, December 3-8, 2018, Montréal, Canada , pp. 4150–4160, 2018.
FrankWood, JanWillemvandeMeent, andVikashMansinghka. Anewapproachtoprobabilisticprogramming
inference. In Proceedings of the 17th International conference on Artiﬁcial Intelligence and Statistics , pp.
1024–1032, 2014.
Mike Wu, Kristy Choi, Noah D Goodman, and Stefano Ermon. Meta-amortized variational inference and
learning. In AAAI, pp. 6404–6412, 2020.
Yujun Yan, Kevin Swersky, Danai Koutra, Parthasarathy Ranganathan, and Milad Hashemi. Neural execution
engines: Learning to execute subroutines. In Advances in Neural Information Processing Systems 33:
Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020,
virtual, 2020.
Jean-Gabriel Young, Fernanda S Valdovinos, and Mark EJ Newman. Reconstruction of plant–pollinator
networks from observational data. bioRxiv, pp. 754077, 2019.
Wojciech Zaremba and Ilya Sutskever. Learning to execute. CoRR, abs/1410.4615, 2014. URL http:
//arxiv.org/abs/1410.4615 .
16Under review as submission to TMLR
A Further discussion about the translation of an expressive PPL into our
intermediate language
Programs with recursion or while-loops cannot generally be translated into our PPL, since such programs
may go into inﬁnite loops while the programs in our language always terminate. Programs with for-loops
and general branches can in theory be translated into a less expressive language such as ours. For example,
van de Meent et al. (2018) explain a language called FOPPL (Section 2), which has for-loops and branches,
and the translation of FOPPL into graphical models (Section 3). We think that these graphical models can
be translated into programs in our PPL. Of course, this does not mean that the learnt inference algorithm
would interact well with the compilation; the interaction between compilation and inference in the context of
meta-learning is something to be explored in future work.
one:= 1;t:= 2;f:= 5; ten:= 10;
z1∼N(f,ten);/ /log of the mass of Milky Way
mass 1:=z1×t;
z2∼N(mass 1,f);/ /for the ﬁrst satellite galaxy
obs(N(z2,one),ten);/ /x1= 10forx1∼N(z2,one)
mass 2:=z1+f;
z3∼N(mass 2,t);/ /for the second satellite galaxy
obs(N(z3,one),3)/ /x2= 3forx2∼N(z3,one)
Figure 8: Milky Way example compiled to the probabilistic programming language used in the paper.
B Milky Way example in the probabilistic programming language
Fig. 8 shows the compiled version of the Milky way example to the probabilistic programming language of
the paper.
C Formal semantics of the probabilistic programming language
In §2, we stated that a program Cin our language denotes an unnormalised density pCthat is factorised as
follows:
pC(z1:n) =pC(x1:m=r1:m|z1:n)×n/productdisplay
i=1pC(zi|z1:i−1).
Herez1,...,znare all the variables assigned by the sampling statements zi∼N(...)inCin that order, the
programCcontainsmobserve statements with observations r1,...,rm, and these observed random variables
are denoted by x1,...,xm. The goal of this section is to provide the details of our statement. That is, we
describe the formal semantics of our probabilistic programming language, and from it, we derive a map from
programsCto unnormalised densities pC.
To deﬁne the formal semantics of programs in our language, we need a type system that tracks information
about updated variables and observations, and also formalises the syntactic conditions that we imposed
informally in §2. The type system lets us derive the following judgements for programs Cand atomic
commands A:
(S,V,α )/turnstileleft1C: (T,W,β ),(S,V,α )/turnstileleft2A: (T,W,β ),
whereSandTare sequences of distinct variables, VandWare sets of variables that do not appear in S
andT, respectively, and αandβare sequences of reals. The ﬁrst judgement says that if before running the
17Under review as submission to TMLR
programC, the latent variables in Sare sampled in that order, the program variables in Vare updated
by non-sample statements, and the real values in the sequence αare observed in that order, then running
Cchanges these three data to T,W, andβ. The second judgement means the same thing except that we
consider the execution of A, instead of C. The triples (S,V,α )and(T,W,β )serve as types in this type
system.
The rules for deriving the judgements for CandAfollow from the intended meaning just explained. We show
these rules below, using the notation @for the concatenation operator for two sequences and also set(S)for
the set of elements in the sequence S:
(R,U,α )/turnstileleft1C1: (S,V,β ) (S,V,β )/turnstileleft1C2: (T,W,γ )
(R,U,α )/turnstileleft1(C1;C2) : (T,W,γ )(S,V,α )/turnstileleft2A: (T,W,β )
(S,V,α )/turnstileleft1A: (T,W,β )
z/negationslash∈set(S)∪V v 1,v2∈set(S)∪V
(S,V,α )/turnstileleft2(z∼N(v1,v2)) : (S@[z],V,α )v0,v1∈set(S)∪V
(S,V,α )/turnstileleft2obs(N(v0,v1),r) : (S,V,α @[r])
v0/negationslash∈set(S)∪V v 1,v2,v3,v4∈set(S)∪V
(S,V,α )/turnstileleft2(v0:=if(v1>v2)v3elsev4) : (S,V∪{v0},α)
v0/negationslash∈set(S)∪V
(S,V,α )/turnstileleft2(v0:=r) : (S,V∪{v0},α)v0/negationslash∈set(S)∪V v 1∈set(S)∪V
(S,V,α )/turnstileleft2(v0:=v1) : (S,V∪{v0},α)
v0/negationslash∈set(S)∪V v 1,v2∈set(S)∪V
(S,V,α )/turnstileleft2(v0:=p(v1,v2)) : (S,V∪{v0},α)
We now deﬁne our semantics, which speciﬁes mappings from judgements for CandAto mathematical entities.
First, we interpret each type (S,V,α )as a set, and it is denoted by J(S,V,α )K:
J(S,V,α )K={(p,f,l )|pis a (normalised) density on R|S|,f= (fv)v∈set(S)∪V,
eachfvis a measurable map from R|S|toR,
lis a measurable function from R|S|×R|α|toR+},
where|S|and|α|are the lengths of the sequences Sandα, andR+means the set of positive reals. Next, we
deﬁne the semantics of the judgements (S,V,α )/turnstileleft1C: (T,W,β )and(S,V,α )/turnstileleft2A: (T,W,β )that can be
derived by the rules from above. The formal semantics of these judgements, denoted by the J−Knotation, are
maps of the following type:
J(S,V,α )/turnstileleft1C: (T,W,β )K:J(S,V,α )K→J(T,W,β )K,
J(S,V,α )/turnstileleft2A: (T,W,β )K:J(S,V,α )K→J(T,W,β )K.
The semantics is given by induction on the size of the derivation of each judgement, under the assumption
that for each procedure name p∈P, we have its interpretation as a measurable map from R2toR:
JpK:R2→R.
We spell out the semantics below, ﬁrst the one for programs and next that for atomic commands.
J(S,V,α )/turnstileleft1A: (T,W,β )K(p,f,l ) = J(S,V,α )/turnstileleft2A: (T,W,β )K(p,f,l ),
J(R,U,α )/turnstileleft1(C1;C2) : (T,W,γ )K(p,f,l ) = ( J(S,V,β )/turnstileleft2C2: (T,W,γ )K
◦J(R,U,α )/turnstileleft2C1: (S,V,β )K)(p,f,l ).
LetN(a;b,c)be the density of the normal distribution with mean band variance cwhenc>0and1when
c≤0. For a family of functions f= (fv)v∈V, a variable w/negationslash∈V, and a function f/prime
w, we writef⊕f/prime
wfor the
extension of fwith a new w-indexed member f/prime
w.
J(S,V,α )/turnstileleft2z∼N(v1,v2) : (S@[z],V,α )K(p,f,l ) = (p/prime,f/prime,l/prime)
18Under review as submission to TMLR
(wherep/prime(a1:|S|+1) =p(a1:|S|)×N(a|S|+1;fv1(a1:|S|),fv2(a1:|S|)),
f/prime
v(a1:|S|+1) =fv(a1:|S|)for allv∈V, f/prime
z(a1:|S|+1) =a|S|+1,
l/prime(a1:|S|+1,b1:|α|) =l(a1:|S|,b1:|α|)),
J(S,V,α )/turnstileleft2obs(N(v0,v1),r) : (S,V,α @[r])K(p,f,l ) = (p,f,l/prime)
(wherel/prime(a1:|S|,b1:|α|+1) =l(a1:|S|,b1:|α|)×N(b|α|+1;fv1(a1:|S|),fv2(a1:|S|)),
J(S,V,α )/turnstileleft2(v0:=if(v1>v2)v3elsev4) : (S,V∪{v0},α)K(p,f,l ) = (p,f⊕f/prime
v0,l)
(wheref/prime
v0(a1:|S|) = if (fv1(a1:|S|)>fv2(a1:|S|)) thenfv3(a1:|S|) elsefv4(a1:|S|)),
J(S,V,α )/turnstileleft2(v0:=r) : (S,V∪{v0},α)K(p,f,l ) = (p,f⊕f/prime
v0,l)
(wheref/prime
v0(a1:|S|) =r),
J(S,V,α )/turnstileleft2(v0:=v1) : (S,V∪{v0},α)K(p,f,l ) = (p,f⊕f/prime
v0,l)
(wheref/prime
v0(a1:|S|) =fv1(a1:|S|)),
J(S,V,α )/turnstileleft2(v0:=p/prime(v0,v1)) : (S,V∪{v0},α)K(p,f,l ) = (p,f⊕f/prime
v0,l)
(wheref/prime
v0(a1:|S|) = Jp/primeK(fv0(a1:|S|),fv1(a1:|S|))).
Finally, we deﬁne pCfor the well-initialised well-typed programs C, i.e., programs Cfor which we can derived
([],∅,[])/turnstileleft1C: (S,V,α ).
For such aC, the deﬁnition of pCis given below:
pC(z1:|S|) =p(z1:|S|)×l(z1:|S|,α)
where (p,_,l) = J([],∅,[])/turnstileleft1C: (S,V,α )K(p0,f0,l0)for the constant- 1functionsp0andl0of appropriate
types and the empty family f0of functions.
D Marginal likelihood computation: derivation and correctness
Letxnbe the random variable (RV) that is observed by the command obs(N(v0,v1),r)andx1:(n−1)be the
(n−1)RVs that are observed before the command. When our algorithm is about to analyse this observe
command, we have (an estimate of) p(x1:(n−1))by induction. Then, the marginal likelihood of x1:ncan be
computed as follows:
p(x1:(n−1),xn)
=/integraldisplay/integraldisplay
p(x1:(n−1),xn,v0,v1)dv0dv1
=/integraldisplay/integraldisplay
p(x1:(n−1))p(v0,v1|x1:(n−1))p(xn|x1:(n−1),v0,v1)dv0dv1
≈p(x1:(n−1))/integraldisplay/integraldisplay
ph(v0,v1)p(xn|x1:(n−1),v0,v1)dv0dv1
// The ﬁltering distribution p(v0,v1|x1:(n−1))is approximated by ph.
=p(x1:(n−1))/integraldisplay/integraldisplay
ph(v0,v1)p(xn|v0,v1)dv0dv1
// The RV xnis conditionally independent of x1:(n−1)givenv0,v1.
=p(x1:(n−1))/integraldisplay/integraldisplay
ph(v0,v1)N(r;v0,v1)dv0dv1
//p(x1:(n−1))isZin the description of infer (Ai)in Section 4, and the neural network
//nnintg,φ7aims at approximating the integral term accurately.
19Under review as submission to TMLR
This derivation leads to the equation in the main text.
In a setting of probabilistic programming where observations are allowed to be diﬀerent in true and false
branches, the marginal likelihood may fail to be deﬁned, and such a setting is beyond the scope of our
language. Using variables multiple times or having observe commands spread out in the program does not
make diﬀerences in the derivation above.
E Detailed descriptions for probabilistic models used in the empirical evaluation
We detail the program speciﬁcations for the classes in §5 using the probabilistic programming language in §2,
and then describe how our program generator generated programs from those classes randomly.
In the program speciﬁcations to follow, randomly-generated constants are written in the Greek alphabets ( θ),
and latent and other program variables in the English alphabets. Also, we often use more intuitive variable
names instead of using zifor latent variables and vifor the other program variables, to improve readability.
When describing random generation of the parameter values, we let U(a,b)denote the uniform distribution
whose domain is (a,b)⊂R; we use this only for describing the random program generation process itself, not
the generated programs (only normal distributions are used in our programs, with the notation N).
E.1 Generalisation to new model parameters and observations
This section details the model classes in §5.1.
E.1.1 gauss
The model class is described as follows:
mz:=θ1;vz:=θ/prime
2;c1:=θ3;c2:=θ4;vx:=θ/prime
5;
z1∼N(mz,vz);z2:=z1×c1;z3:=z2+c2;
obs(N(z3,vx),o)
For each program of the class, our random program generator generated the parameter values as follows:
θ1∼U(−5,5), θ2∼U(0,20), θ/prime
2= (θ2)2, θ3∼U(−3,3)
θ4∼U(−10,10), θ5∼U(0.5,10), θ/prime
5= (θ5)2
and then generated the observation oby running the program forward where the value for z1was sampled
fromz1∼U(mz−2×√vz,mz+ 2×√vz).
E.1.2 hierl
The model class is described as follows:
mg:=θ1;vg:=θ/prime
2;vt1:=θ/prime
3;vt2:=θ/prime
4;vx1:=θ/prime
5;
vx2:=θ/prime
6;g∼N(mg,vg);t1∼N(g,vt1);t2∼N(g,vt2);
obs(N(t1,vx1),o1);obs(N(t2,vx2),o2)
For each program of the class, our generator generated the parameter values as follows:
θ1∼U(−5,5), θ2∼U(0,50), θ/prime
2= (θ2)2, θ3∼U(0,10)
θ/prime
3= (θ3)2, θ4∼U(0,10), θ/prime
4= (θ4)2, θ5∼U(0.5,10)
θ/prime
5= (θ5)2, θ6∼U(0.5,10), θ/prime
6= (θ6)2
and then generated the observations o1ando2by running the program (i.e., simulating the model) forward.
20Under review as submission to TMLR
E.1.3 hierd
The model class is described as follows:
ma0:=θ1;va0:=θ/prime
2;va1:=θ/prime
3;va2:=θ/prime
4;mb:=θ5;
vb:=θ/prime
6;d1=θ7;d2=θ8;vx1:=θ/prime
9;vx2:=θ/prime
10;
a0∼N(ma0,va0);a1∼N(a0,va1);a2∼N(a0,va2);
b∼N(mb,vb);
t1:=b×d1;t2:=a1+t1;obs(N(t2,vx1),o1);
t3:=b×d2;t4:=a2+t3;obs(N(t4,vx2),o2)
For each program of the class, our generator generated the parameter values as follows:
θ1∼U(−10,10), θ2∼U(0,100), θ/prime
2= (θ2)2, θ3∼U(0,10)
θ/prime
3= (θ3)2, θ4∼U(0,10), θ/prime
4= (θ4)2, θ5∼U(−5,5)
θ6∼U(0,10), θ/prime
6= (θ6)2, θ7∼U(−5,5), θ8∼U(−5,5)
θ9∼U(0.5,10), θ/prime
9= (θ9)2, θ10∼U(0.5,10), θ/prime
10= (θ10)2
and then generated the observations o1ando2by running the program forward where the values for a0,a1,
a2, andbin this speciﬁc simulation were sampled as follows:
a0∼U(ma0−2×√va0, ma0+ 2×√va0)
a1∼U(a0−2×√va1, a0+ 2×√va1)
a2∼U(a0−2×√va2, a0+ 2×√va2)
b∼U(mb−2×√vb, mb+ 2×√vb)
E.1.4 cluster
The model class is described as follows:
mg1:=θ1;vg1:=θ/prime
2;mg2:=θ3;vg2:=θ/prime
4;vx:=θ/prime
5;
g1∼N(mg1,vg1);g2∼N(mg2,vg2);
zero := 0; hund := 100;
t1∼N(zero,hund );m1:=if(t1>zero)g1elseg2;
obs(N(m1,vx),o1);
t2∼N(zero,hund );m2:=if(t2>zero)g1elseg2;
obs(N(m2,vx),o2);
t3∼N(zero,hund );m3:=if(t3>zero)g1elseg2;
obs(N(m3,vx),o3);
t4∼N(zero,hund );m4:=if(t4>zero)g1elseg2;
obs(N(m4,vx),o4);
t5∼N(zero,hund );m5:=if(t5>zero)g1elseg2;
obs(N(m5,vx),o5)
For each program of the class, our generator generated the parameter values as follows:
θ1∼U(−15,15), θ2∼U(0.5,50), θ/prime
2= (θ2)2
θ3∼U(−15,15), θ4∼U(0.5,50), θ/prime
4= (θ4)2
θ5∼U(0.5,10), θ/prime
5= (θ5)2
and then generated the observations o1:5by running the program forward.
21Under review as submission to TMLR
E.1.5 milkyand milkyo
The model class milkyis described as follows:
mmass :=θ1;vmass :=θ/prime
2;c1:=θ3;vg1:=θ/prime
4;c2:=θ5;
vg2:=θ/prime
6;vx1:=θ/prime
7;vx2:=θ/prime
8;
mass∼N(mmass,vmass);
mass 1:=mass×c1;g1∼N(mass 1,vg1);
mass 2:=mass +c2;g2∼N(mass 2,vg2);
obs(N(g1,vx1),o1);obs(N(g2,vx2),o2)
For each program of milky, our generator generated the parameter values as follows:
θ1∼U(−10,10), θ2∼U(0,30), θ/prime
2= (θ2)2, θ3∼U(−2,2)
θ4∼U(0,10), θ/prime
4= (θ4)2, θ5∼U(−5,5), θ6∼U(0,10)
θ/prime
6= (θ6)2, θ7∼U(0.5,10), θ/prime
7= (θ7)2, θ8∼U(0.5,10)
θ/prime
8= (θ8)2
and then generated the observations o1ando2by running the program forward.
Everything remained the same for the milkyoclass, except that the two obscommands were extended to
obs(N(g1,vx1),[o1,o2,o3,o4,o5])andobs(N(g2,vx2),[o6,o7,o8,o9,o10]), respectively, and all the observations
were generated similarly by running the extended model forward.
E.1.6 rb
The model class rbis described as follows:
mz1:=θ1;vz1:=θ/prime
2;mz2:=θ3;vz2:=θ/prime
4;vx:=θ/prime
5;
z1∼N(mz1,vz1);z2∼N(mz2,vz2);r:= Rosenbrock( z1,z2);
obs(N(r,vx),o)
where Rosenbrock (z1,z2) = 0.05×(z1−1)2+ 0.005×(z2−z12)2. For each program of the class, our generator
generated the parameter values as follows:
θ1∼U(−8,8), θ2∼U(0,5), θ/prime
2= (θ2)2, θ3∼U(−8,8)
θ4∼U(0,5), θ/prime
4= (θ4)2, θ5∼U(0.5,10), θ/prime
5= (θ5)2
and then generated the observation oby running the program forward where the values for z1andz2in this
speciﬁc simulation were sampled as follows:
z1∼U(mz1−1.5×√vz1, mz1+ 1.5×√vz1)
z2∼U(mz2−1.5×√vz2, mz2+ 1.5×√vz2)
E.2 Generalisation to new model structures
This section details the model classes, and diﬀerent types in each model class in §5.2. For readability,
we present canonicalised dependency graphs where variables are named in the breadth-ﬁrst order. In the
experiments reported in this section, we used a minor extension of our probabilistic programming language
with procedures taking one parameter.
E.2.1 ext1
Fig. 9 shows the dependency graphs for all model types in ext1. The variables z0,z1,...andx1,x2,...
represent latent and observed variables, respectively, and observed variables are colored in gray. The red
node in each graph represents the position of the nlvariable.
22Under review as submission to TMLR
Our program generator in this case generates programs from the whole model class ext1; it generates programs
of all twelve diﬀerent types in ext1. We explain this generation process for the model type (1,1) in Fig. 9,
while pointing out that the similar process is applied to the other eleven types. To generate programs of the
model type (1,1), we use the following program template:
mz0:=θ1;vz0:=θ/prime
2;vz2:=θ/prime
3;vz3:=θ/prime
4;vx1:=θ/prime
5;
z0∼N(mz0,vz0);z1:= nl(z0);z2∼N(z1,vz2);z3∼N(z2,vz3);
obs(N(z3,vx1),o1)
where nl(z) = 50/π×arctan (z/10). The generation involves randomly sampling the parameters of this
template, converting the template into a program in our language, and creating synthetic observations.
Speciﬁcally, our generator generates the parameter values as follows:
θ1∼U(−5,5), θ2∼U(0,20), θ/prime
2= (θ2)2, θ3∼U(0,20), θ/prime
3= (θ3)2
θ4∼U(0,20), θ/prime
4= (θ4)2, θ5∼U(0.5,10), θ/prime
5= (θ5)2
and generates the observation o1by running the program forward where the values for z0:3in this speciﬁc
simulation were sampled (and ﬁxed to speciﬁc values) as follows:
z0∼U(mz0−2×√vz0, mz0+ 2×√vz0)
z1= nl(z0)
z2∼U(z1−2×√vz2, z1+ 2×√vz2)
z3∼U(z2−2×√vz3, z2+ 2×√vz3).
The generator uses diﬀerent templates for the other eleven model types in ext1, while sharing the similar
process for generation of the parameters and observations.
E.2.2 ext2
Fig. 10 shows the dependency graphs for all ﬁve model types in ext2. Programs of these ﬁve types are
randomly generated by our program generator. As in the ext1case, we explain the generator only for one
model type, which corresponds to the ﬁrst dependency graph in Fig. 10. To generate programs of this type,
we use the following program template:
mz0:=θ1;vz0:=θ/prime
2;vz1:=θ/prime
3;vz3:=θ/prime
4;vz4:=θ/prime
5;vz5:=θ/prime
6;vz6:=θ/prime
7;
vx1:=θ/prime
8;vx2:=θ/prime
9;vx3:=θ/prime
10;vx4:=θ/prime
11;
z0∼N(mz0,vz0);z1∼N(z0,vz1);z2:= nl(z0);z3∼N(z0,vz3);
z4∼N(z1,vz4);z5∼N(z1,vz5);z6∼N(z2,vz6);
obs(N(z4,vx1),o1);obs(N(z5,vx2),o2);obs(N(z6,vx3),o3);obs(N(z3,vx4),o4)
In order to generate a program of this model type and observations, our generator instantiates the parameters
of the template as follows:
θ1∼U(−5,5), θ2∼U(0,10), θ/prime
2= (θ2)2, θ3∼U(0,10), θ/prime
3= (θ3)2, θ4∼U(0,10), θ/prime
4= (θ4)2
θ5∼U(0,10), θ/prime
5= (θ5)2, θ6∼U(0,10), θ/prime
6= (θ6)2, θ7∼U(0,10), θ/prime
7= (θ7)2
θ8∼U(0,10), θ/prime
8= (θ8)2, θ9∼U(0,10), θ/prime
9= (θ9)2, θ10∼U(0,10), θ/prime
10= (θ10)2
θ11∼U(0,10), θ/prime
11= (θ11)2.
Then, it generates the observations o1:4by running the program forward where the values for z0:6in this
speciﬁc simulation were sampled (and ﬁxed to speciﬁc values) as follows:
z0∼U(mz0−2×√vz0, mz0+ 2×√vz0)
z1∼U(z0−2×√vz1, z0+ 2×√vz1)
23Under review as submission to TMLR
z2= nl(z0)
z3∼U(z0−2×√vz3, z0+ 2×√vz3)
z4∼U(z1−2×√vz4, z1+ 2×√vz4)
z5∼U(z1−2×√vz5, z1+ 2×√vz5)
z6∼U(z2−2×√vz6, z2+ 2×√vz6).
The generator uses diﬀerent templates for the other four model types in ext2, while sharing the similar process
for generation of the parameters and observations.
E.3 Application to IS: test-time eﬃciency in comparison with alternatives
This section details the mulmod class in §5.3, which has three diﬀerent model types. Fig. 11 shows the
dependency graphs for all the model types. The red node in each graph represents the position of the mm
variable. We used all the three types in training, applied the learnt inference algorithm to programs in the
third model type, and compared the results with those returned by HMC.
We similarly explain the generator only using the model type corresponding to the ﬁrst dependency graph in
Fig. 11. To generate programs of this type, we use the following program template:
mz0:=θ1;vz0:=θ/prime
2;vz1:=θ/prime
3;vx1:=θ/prime
4;
z0∼N(mz0,vz0);z1∼N(z0,vz1);z2:= mm(z1);obs(N(z2,vx1),o1)
where mm(x) = 100×x3/(10 +x4). For each program in this model type, our generator instantiates the
parameter values as follows:
θ1∼U(−5,5), θ2∼U(0,20), θ/prime
2= (θ2)2, θ3∼U(0,20), θ/prime
3= (θ3)2
θ4∼U(0.5,10), θ/prime
4= (θ4)2
and synthesises the observation o1by running the program forward where the values for z0:2in this speciﬁc
simulation were sampled (and ﬁxed to speciﬁc values) as follows:
z0∼U(mz0−2×√vz0, mz0+ 2×√vz0)
z1∼U(z0−2×√vz1, z0+ 2×√vz1)
z2= mm(z1).
The generator uses diﬀerent templates for the other two model types in mulmod, while sharing the similar
process for instantiation of the parameters and observations.
F Detailed evaluation setup
In our evaluation, the dimension sof the internal state hwas10(i.e.,h∈R10). We used the same neural
network architecture for all the neural network components of our inference algorithm infer. Each neural
network had three linear layers and used the tanhactivation. The hidden dimension was 10for each layer in
all the neural networks except for nndewhere the hidden dimensions were 50. The hyper-parameter in our
optimisation objective (§4) was set to λ= 2in the evaluation. We did not use GPUs.
Before running our inference algorithm, we canonicalise the names of variables in a given program based on its
dependency (i.e., data-ﬂow) graph. Although not perfect, this preprocessing removes a superﬁcial diﬀerence
between programs caused by diﬀerent variable names, and enables us to avoid unnecessary complexity caused
by variable-renaming symmetries at training and inference times.
G Losses for hierd,cluster,milkyo, and rb
Fig. 12 shows the average training and test losses under three random seeds for hierd,cluster,milkyo, and rb.
The later part of Fig. 12a, 12c and 12d shows cases where the test loss surges. This was when the loss of only
24Under review as submission to TMLR
a few programs in the test set (of 50programs) became large. Even in this situation, the losses of the rest
remained small. We give analyses for clusterandrbseparately in §H.
H Multimodal posteriors: clusterand rb
The clusterandrbclasses in §5.1 posed another challenge: the models often had multimodal posteriors, and
it was signiﬁcantly harder for our meta-algorithm to learn an optimal inference algorithm. To make the
evaluation partially feasible for rb, we changed two parts of our meta-algorithm slightly, as well as increasing
the size of the test set from 50to100. First, we used importance samples instead of samples by HMC, which
often failed to converge, to learn an inference algorithm. Second, our random program generator placed some
restriction on the programs it generated (e.g., by using tight boundaries on some model parameters), guided
by the analysis of the geometry of the Rosenbrock function (Pagani et al., 2019). Consequently, HMC (with
500K samples after 50K warmups) failed to converge for only one ﬁfth of the test programs.
Fig. 13 shows the similar comparison plots between reference and predicted marginal posteriors for 10test
programs of the rbtype, after 52.4K epochs. Our inference algorithm computed the posteriors precisely for
most of the programs except two ( pgm75and pgm79) with signiﬁcant multimodality. The latent variable
pgm75_z0had at least two modes at around −10(visible in the ﬁgure) and around 10(hidden in the ﬁgure)5.
Our inference algorithm showed a mode-seeking behavior for this latent variable. Similarly, the variable
pgm79_z0had at least two modes in the similar domain region (one shown and one hidden), but this time
our inference algorithm showed a mode-covering behavior.
The multimodality issue raises two questions. First, how can our meta-algorithm generate samples from the
posterior more eﬀectively so that it can optimise the inference algorithm for classes of models with multimodal
posteriors? For example, our current results for clustersuﬀer from the fact that the samples used in the
training are often biased (i.e., only from a single mode of the posterior). One possible direction would be to
use multiple Markov chains simultaneously and apply ideas from the mixing-time research. Second, how can
our white-box inference algorithm catch more information from the program description and ﬁnd non-trivial
properties that may be useful for computing the posterior distributions having multiple modes? We leave the
answers for future work.
I Training and test losses for the other cases in ext1
Fig. 14 shows the average training and test losses in the ext1experiment runs (under three diﬀerent random
seeds) for generalisation to the last (4th) dependency graph and to all three positions of the nlvariable.
J Training and test losses for the other cases in ext2
Fig. 15 shows the average training and test losses in the ext2experiment runs (under three diﬀerent random
seeds) for generalisation to the 4th and 5th dependency graphs.
K Comparisons in terms of KL
For accuracy, it would be ideal to report KL[p||q], wherepis the fully joint target posterior and qis the
predicted distribution. It is, however, hard to compute this quantity since often we cannot compute the
density ofp. One (less convincing) alternative is to compute KL[p/prime(z)||q(z)]for a latent variable zwherep/prime(z)
is the best Gaussian approximation (i.e., the best approximation using the mean and standard deviation)
for the true marginal posterior p(z), and average the results over all the latent variables of interest. We
computed KL[p/prime(z)||q(z)]for the test programs from ext1and ext2in §5.2, and for the three from mulmod
that are reported in §5.3.
5The blue reference plots were drawn using an HMC chain, but the HMC chain got stuck in the mode around −10for this
variable.
25Under review as submission to TMLR
Forext1andext2, we measured the average KL[p/prime(z)||q(z)]over all the latent variables zin the test programs.
For instance, if there were 90test programs and each program had three latent variables, we averaged
90×3 = 270 KLmeasurements. In an experiment run for ext1(which tested generalisation to an unseen
dependency graph), the average KLwas around 1.32. In an experiment run for ext2, the estimation was
around 0.95. When we replaced qwith a normal distribution that is highly ﬂat (with mean 0and standard
deviation 10K), the estimation was 7.11and7.57, respectively. The results were similar in all the other
experiment runs that were reported in §5.2.
For three randomly picked test programs ( pgm19,pgm30, and pgm38) from mulmodin §5.3,p/primewas the best
Gaussian approximation whose mean and standard deviation were estimated by the reference importance
sampler (IS-ref), and qwas either the predicted marginal posterior by the learnt inference algorithm or the
best Gaussian approximation whose mean and standard deviation were estimated by HMC. The average
KLwas around 1.19whenqwas the predicted posterior, while the estimation was 40.9whenqwas the best
Gaussian approximation by HMC. The results demonstrate that the predicted posteriors were more accurate
on average than HMC at least in terms of p/prime.
L Program in §5.3
Fig. 16 shows the program that is reported in §5.3, written in our probabilistic programming language.
M Discussion of the cost of IS-pred vs. IS-prior
Our approach (IS-pred) must scan the given program “twice” at test time, once for computing the proposal
using the learnt neural networks and another for running the importance sampler with the predicted proposal,
while IS-prior only needs to scan the program once. Although it may seem that IS-prior has a huge advantage
in terms of saving the wall-clock time, our observation is that the eﬀect easily disappears as the sample size
increases. In fact, going through the neural networks in our approach (i.e., the ﬁrst scanning of the program)
does not depend on the sample size, and so its time cost remains constant given the program; the time cost
was0.6ms for the reported test program ( pgm19) in §5.3.
N Manual inspection into mulmod(§5.3)
Our manual inspection revealed that the programs in mulmodoften have multimodal posteriors. Fig. 17a
shows the posteriors for { pgm19,pgm30,pgm38} in the test set, computed by our learnt inference algorithm
(without IS), HMC ( 200K samples after 10K warmups) , and IS-ref. The variable z0in the three programs
had multimodal posteriors. For pgm19, the learnt inference algorithm took only 0.6ms to compute the
posteriors, while HMC took 120s on average to generate a chain. The predictions (red) from the learnt
inference algorithm for z0describe the reference posteriors (green) better than those (blue) by HMC in terms
of mean, variance, and mode covering.6The contour plots in Fig. 17b to 17d visualise three HMC chains for
pgm19. Here, HMC failed to converge, and Fig. 17b explains the poor estimate (blue) in the ﬁrst column of
Fig. 17a.
O Broader impact
Our work partially shows that an inference algorithm itself can be learnt from given inference tasks and can
generalise to unseen probabilistic models to some degree. If an inference algorithm can reason about the
speciﬁcs of the problem at hand (customisation) for distinct cases (universality) automatically, practitioners
will beneﬁt directly from it even without much knowledge about probabilities and programming languages.
This paper shows potential to develop such an automated reasoning over probabilistic models, and eventually
to lower the “entry barriers” to probabilistic programming.
6Ourinferencealgorithminamultimodal-posteriorcaseleadstoagoodapproximationinthefollowingsense: theapproximating
distribution qcovers the regions of the modes well, and also approximates the mean and variance of the target distribution
accurately. Note that such a qis useful when it is used as the proposal of IS.
26Under review as submission to TMLR
z0
z1
z2
z3
x1
(a) Model type (1,1).z0
z1
z2z3
x1x2
(b) Model type (1,2).z0
z1z2
z3
x1x2
(c) Model type (1,3).z0
z1z2z3
x1x2x3
(d) Model type (1,4).
z0
z1
z2
z3
x1
(e) Model type (2,1).z0
z1
z2z3
x1x2
(f) Model type (2,2).z0
z1z2
z3
x1x2
(g) Model type (2,3).z0
z1z2z3
x1x2x3
(h) Model type (2,4).
z0
z1
z2
z3
x1
(i) Model type (3,1).z0
z1
z2z3
x1x2
(j) Model type (3,2).z0
z1z2
z3
x1x2
(k) Model type (3,3).z0
z1z2z3
x1x2x3
(l) Model type (3,4).
Figure 9: Canonicalised dependency graphs for all 12model types in ext1. The rows are for diﬀerent positions
of the nlvariable, and the columns are for diﬀerent dependency graphs: the model type ( i,j) means one of
the12model types in ext1that corresponds to the i-th position of the nlvariable and j-th dependency graph.
27Under review as submission to TMLR
z0
z1 z2z3
z4z5z6
x1x2x3x4
(a) Model type for the 1st dependency graph.z0
z1z2z3
z4z5z6
x1x2x3
(b) Model type for the 2nd dependency graph.
z0
z1 z2
z3z4z5z6
x1x2x3x4
(c) Model type for the 3rd dependency graph.z0
z1z2z3z4
z5z6
x1x2x3x4
(d) Model type for the 4th dependency graph.
z0
z1 z2
z3z4z5z6
x1x2x3x4
(e) Model type for the 5th dependency graph.
Figure 10: Canonicalised dependency graphs for all ﬁve model types in ext2.
z0
z1
z2
x1
(a) 1st model type.z0
z1
z2
x1
(b) 2nd model type.z0
z1z2
x1x2
(c) 3rd model type.
Figure 11: Canonicalised dependency graphs for all three model types in the mulmodclass.
28Under review as submission to TMLR
0 5k 10k 15k 20k10100100010k100k1M10M
Seed, T r or T e
1, Tr
1, Te
2, Tr
2, Te
3, Tr
3, Te
EpochLoss
(a)hierd
500 1000 1500 2000 2500 30001001000
Seed, T r or T e
1, Tr
1, Te
2, Tr
2, Te
3, Tr
3, Te
EpochLoss (b)cluster
1000 2000 3000 4000 500010100100010k100k1M10M100M1B
Seed, T r or T e
1, Tr
1, Te
2, Tr
2, Te
3, Tr
3, Te
EpochLoss
(c)milkyo
1000 2000 3000 400010
Seed, T r or T e
1, Tr
1, Te
2, Tr
2, Te
3, Tr
3, Te
EpochLoss (d)rb
Figure 12: Losses for hierd,cluster,milkyo, and rb. They-axes are log-scaled. The surges in later epochs of
Fig. 12a, 12c and 12d were due to only a single or a few test programs out of 50.
pgm71_z0pgm71_z1pgm72_z0pgm72_z1pgm73_z0pgm73_z1pgm74_z0pgm74_z1pgm75_z0pgm75_z1pgm76_z0pgm76_z1pgm77_z0pgm77_z1pgm78_z0pgm78_z1pgm79_z0pgm79_z1pgm80_z0pgm80_z1−20−1001020R efer ence
P r edicted
Figure 13: Comparisons of reference and predicted marginal posteriors for 10programs in the rbtest set.
29Under review as submission to TMLR
1000 2000 3000 4000 5000 6000 700010100100010k100k1M10M100M1B10B100B1T10T100T10 15 10 16 10 17 10 18 10 19 
Seed, T r or T e
1, Tr
1, Te
2, Tr
2, Te
3, Tr
3, Te
EpochLoss
(a) To 4th dep. graph.
1000 2000 3000 4000 500010100100010k100k1M10M100M1B
Seed, T r or T e
1, Tr
1, Te
2, Tr
2, Te
3, Tr
3, Te
EpochLoss (b) To 1st nlposition.
1000 2000 3000 4000 500010100100010k
Seed, T r or T e
1, Tr
1, Te
2, Tr
2, Te
3, Tr
3, Te
EpochLoss
(c) To 2nd nlposition.
2000 4000 6000 8000110100100010k100k1M10M100M1B10B100B1T10T100T10 15 10 16 10 17 10 18 10 19 10 20 10 21 10 22 10 23 10 24 10 25 10 26 
Seed, T r or T e
1, Tr 1, Te 2, Tr 2, Te
3, Tr 3, Te
EpochLoss (d) To 3rd nlposition.
Figure 14: Average training and test losses for generalisation to the last (4th) dependency graph and to all
three positions of the nlvariable in ext1. The y-axes are log-scaled.
1000 2000 3000 4000 500010100100010k100k1M10M
Seed, T r or T e
1, Tr
1, Te
2, Tr
2, Te
3, Tr
3, Te
EpochLoss
(a) To 4th dep. graph.
2000 4000 6000 800010100100010k100k1M10M
Seed, T r or T e
1, Tr
1, Te
2, Tr
2, Te
3, Tr
3, Te
EpochLoss (b) To 5th dep. graph.
Figure 15: Average training and test losses for generalisation to the 4th and 5th dependency graphs in ext2.
The y-axes are log-scaled.
30Under review as submission to TMLR
a:= 3.93; b:= 348.16; c:= 57.5;d:= 14.04; e:= 40.34;
z1∼N(a,b);z2∼N(z1,c);z3:= mm(z1);
obs(N(z2,d),53.97); obs(N(z3,e),0.12)
Figure 16: The program that is reported in §5.3, written in our probabilistic programming language.
pgm19_z0 pgm19_z1 pgm30_z0 pgm30_z1 pgm38_z0 pgm38_z1−50050100 Predicted
Reference-IS
HMC
(a) Marginal posteriors
100200 300
400
500600700
800
−1.5 −1 −0.5 0 0.5 1 1.5303540455055
200400600800
pgm19_z0pgm19_z1(b) Chain 1
2k2k
4k6k
8k
10k
0 20 40 60 803035404550556065
2k4k6k8k10k12k14k
pgm19_z0pgm19_z1
(c) Chain 2
100100
200200300300
400500
600
700800
900
0 20 40 60 8035404550556065
2004006008001000
pgm19_z0pgm19_z1 (d) Chain 7
Figure 17: Marginal posteriors, and contours of three HMC chains for pgm_19from mulmodin §5.3. The
x-axis is for z0and the y-axis z1.
31