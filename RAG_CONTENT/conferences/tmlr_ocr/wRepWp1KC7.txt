Published in Transactions on Machine Learning Research (09/2023)
Fair and Useful Cohort Selection
Konstantina Bairaktari bairaktari.k@northeastern.edu
Khoury College of Computer Sciences
Northeastern University
Paul Langton langton.p@northeastern.edu
Khoury College of Computer Sciences
Northeastern University
Huy Le Nguyen hu.nguyen@northeastern.edu
Khoury College of Computer Sciences
Northeastern University
Niklas Smedemark-Margulies smedemark-margulie.n@northeastern.edu
Khoury College of Computer Sciences
Northeastern University
Jonathan Ullman jullman@ccs.neu.edu
Khoury College of Computer Sciences
Northeastern University
Reviewed on OpenReview: https://openreview.net/forum?id=wRepWp1KC7
Abstract
A challenge in fair algorithm design is that, while there are compelling notions of individual
fairness, these notions typically do not satisfy desirable composition properties, and down-
stream applications based on fair classiﬁers might not preserve fairness. To study fairness
under composition, Dwork & Ilvento (2019) introduced an archetypal problem called fair-
cohort-selection problem , where a single fair classiﬁer is composed with itself to select a
group of candidates of a given size, and proposed a solution to this problem. In this work
we design algorithms for selecting cohorts that not only preserve fairness, but also maximize
the utility of the selected cohort under two notions of utility that we introduce and motivate.
We give optimal (or approximately optimal) polynomial-time algorithms for this problem
in both an oﬄine setting, and an online setting where candidates arrive one at a time and
are classiﬁed as they arrive.
1 Introduction
The rise of algorithmic decision making has created a need for research on the design of fair algorithms,
especially for machine-learning tasks like classiﬁcation and prediction. Beginning with the seminal work of
Dwork et al. (2012), there is now a large body of algorithms that preserve various notions of fairness for
individuals. These notions of individual fairness capture the principle that similar people should be treated
similarly, according to some task-speciﬁc measure of similarity.
While these algorithms satisfy compelling notions of individual fairness in isolation, they will often be used
as parts of larger systems. To address this broader context, Dwork & Ilvento (2019) initiated the study of
fairness under composition , where one or more fair classiﬁers will be combined to make multiple decisions,
and we want these decisions to preserve the fairness properties of those underlying classiﬁers. Their work
1Published in Transactions on Machine Learning Research (09/2023)
introduced a number of models where fair mechanisms must be composed, demonstrated that naïve methods
of composing fair algorithms do not preserve fairness, and identiﬁed strategies for preserving fairness in these
settings. Importantly, these strategies treat the underlying classiﬁers as a black-box so that composition can
be modular, eliminating the need to redesign the underlying classiﬁer for every possible use.
Our work studies the archetypal fair cohort selection problem introduced by Dwork & Ilvento (2019). In this
problem, we would like to select kcandidates for a job from a universe of npossible candidates. We are
given a classiﬁer that assigns a scoresi∈[0,1]to each candidate,1with the guarantee that the scores are
individually fair with respect to some similarity metric D. We would like to select a set of kcandidates such
that the probability piof selecting any candidate should be fair with respect to the same metric.
Preserving Fairness. Since our goal is to treat the scores s1,...,snas a black-box, without knowing the
underlying fairness metric, we posit that the scores are fair with respect to some D, i.e. they satisfy
∀i,j,|si−sj|≤D (i,j), (1)
but that this metric is unknown . Thus, we will design our cohort selection algorithm so that its output
probabilities p1,...,pnwill satisfy
∀i,j,|pi−pj|≤|si−sj|≤D (i,j) (2)
as this guarantees that we preserve the underlying fairness constraint. Without further assumptions about
the fairness metric, the only way to preserve fairness is to satisfy (2).
We can trivially solve the fair cohort selection problem by ignoring the scores and selecting a uniformly
random set of kcandidates, so that every candidate is chosen with the same probability k/n. Thus, in
this paper we propose to study algorithms for fair cohort selection that produce a cohort with optimal (or
approximately optimal) utility subject to the fairness constraint. Speciﬁcally, we consider two variants of
the problem:
Linear Utilities. For the linear utility model, we assume that
1. the utility for selecting a cohort is the sum of independently assigned utilities for each member, and
2. the scores given by the original classiﬁer accurately reﬂect the utility of each member of the cohort.
Assumption1essentiallysaysthatmembersofthecohortarenotcomplementsorsubstitutesandassumption
2 makes sense if the task that we designed the classiﬁer to solve and the task that the cohort is being used
for are closely related. Under these assumptions, it is natural to deﬁne the utility for a cohort selection
algorithm to be/summationtext
ipisi, which is the expectation over the choice of the cohort of the sum of the scores
across members in the cohort.
Ratio Utilities. For the ratio utility model, we continue to rely on assumption 1, but we now imagine that
the expected utility for the cohort is some other linear function/summationtext
ipiuiwhere the variables uiare some
unknown measure of utility in [0,1]. Assuming that for every candidate ithe scoresiis generally correlated
with the utility uieven if they are not exactly the same, we normalize by/summationtext
isiui, as the original scores can
still be a reasonable choice of selection probabilities that satisfy the fairness constraint. Since the utility
function is unknown, our goal is now to produce a cohort that maximizes the utility in the worst case over
possible utility functions. As we show (Lemma 2.1), maximizing the worst-case utility amounts to assigning
probabilities that maximize the quantity minipi/si. Optimizing the ratio utility implies a lower bound on
the cohort utility under any utility function that satisﬁes assumption 1, including our linear utility above.
However, it does not necessarily optimize the linear utility, thus the two utility models are distinct.
Our technical contributions are polynomial-time algorithms for fair and useful cohort selection with both
linear and ratio utilities, in two diﬀerent algorithmic models.
1In the model of Dwork et al. (2012), fairness requires that the classiﬁer be randomized, so we can think of the output of
the classiﬁer as continuous scores rather than binary decisions.
2Published in Transactions on Machine Learning Research (09/2023)
Oﬄine Setting. In this setting, we are given all the scores s1,...,snat once, and must choose the optimal
cohort. We present a polynomial-time algorithm for each model that computes a fair cohort with optimal
expected utility.
Online Setting. In this setting, we are given the scores s1,s2,...as a stream. Ideally, after receiving si, we
would like to immediately accept candidate ito the cohort or reject them from the cohort. However, this goal
is too strong (Dwork & Ilvento, 2019), so we consider a relaxation where candidate ican be either rejected at
any point during the online process, or kept on hold until later, and we would like to output a fair cohort at
the end of the stream with optimal expected utility while minimizing the number of candidates who are kept
on hold. We must keep at least kcandidates pending in order to ﬁll our cohort. For ratio utilities we give a
fair and optimal algorithm in this setting that keeps at most O(k)candidates on hold. For linear utilities, we
give anapproximately fair and optimal algorithm. Speciﬁcally, we present a polynomial-time algorithm for
this online setting where the fairness constraints are satisﬁed with an εadditive error and utility is optimized
up to an additive error of O(k√ε), for any desired ε >0, while ensuring that the number of users on hold
never exceeds O(k+ 1/ε). To interpret our additive error guarantee, since the fairness constraint applies
to the probabilities p1,...,pn, allowing the fairness constraint to be violated by an additive error of, say,
ε= 0.01means that every candidate is selected with probability that is within ±1%of the probability that
candidate would have been selected by some fair mechanism.
1.1 Techniques
We start with a brief overview of the key steps in our algorithms for each setting. The formal description of
the algorithms can be found in Sections 3 and 4. All omitted proofs are in the appendix.
Oﬄine Setting. Our oﬄine algorithm is based on two main properties of the fair cohort selection problem.
First, we use a dependent-rounding procedure that takes a set of probabilities p1,...,pnsuch that/summationtextn
i=1pi=
kand outputs a random cohort C, represented by indicator random variables ˜p1,..., ˜pn∈ {0,1}with/summationtextn
i=1˜pi=ksuch that E(˜pu) =pufor every candidate u. Thus, it is enough for our algorithm to come up
with a set of marginal probabilities for each candidate to appear in the cohort, and then run this rounding
process, rather than directly ﬁnding the cohort.
Toﬁndthemarginalprobabilitiesthatmaximizethelinearutilitywithrespecttothescores s1,...,sn∈[0,1],
we would like to solve the linear program (LP)
maximize/summationtextn
i=1pisi
s.t./summationtextn
i=1pi≤k
∀i,j,|pi−pj|≤|si−sj|
∀i,0≤pi≤1
In this LP, the ﬁrst and third constraints ensure that the variables purepresent the marginal probability of
selecting candidate uin a cohort of size k. The second constraint ensures that these probabilities pare fair
with respect to the same measure Das the original scores s(i.e.|pu−pv|≤|su−sv|≤D (u,v)). Although
we could have used the stronger constraint |pu−pv|≤D (u,v), writing the LP as we do means that our
algorithm does not need to know the underlying metric, and that our solution will preserve any stronger
fairness that the scores shappen to satisfy.
While we could use a standard linear program solver, we can get a faster solution that is also useful for
extending to the online setting by noting that this LP has a speciﬁc closed form solution based on “water-
ﬁlling”. Speciﬁcally, if/summationtextn
i=1si≤k, then the optimal solution simply adds some number c≥0to all scores
and setspu= min{su+c,1}, and an analogous solution works when/summationtextn
i=1si>k.
For the ratio utility, although computing the optimal marginal probabilities does not correspond to solving a
linearprogram, thesolutionsforthetwoutilityfunctionsarethesamewhen/summationtextn
i=1si≤k. When/summationtextn
i=1si>k,
we maximize the ratio of marginal probability over score by scaling all the scores down by the same factor
k//summationtextn
i=1si.
3Published in Transactions on Machine Learning Research (09/2023)
Online Setting. In the online setting we do not have all the scores in advance, thus for the linear utility
we cannot solve the linear program, and do not even know the value of the constant cthat determines the
solution. We give two algorithms for addressing this problem. The basic algorithm begins by introducing
someapproximation , in which we group users into 1/εgroups based on their scores, where group gcontains
users with scores in ((g−1)ε,gε]. This grouping can only reduce utility by O(k√ε), and can only lead to
violating the fairness constraint by ε. Since users in each bucket are treated identically, we know that when
we reach the end of the algorithm, we can express the ﬁnal cohort as containing a random set of ngmembers
from each group g. Thus, to run the algorithm we use reservoir sampling to maintain a random set of at
mostkcandidates from each group, reject all other members, and then run the oﬄine algorithm at the end
to determine how many candidates to select from each group.
The drawback of this method is that it keeps as many as k/εcandidates on hold until the end. Thus, we
develop an improved algorithm that solves the linear program in an online fashion, and uses the information
it obtains along the way to more carefully choose how many candidates to keep from each group. This ﬁnal
algorithm reduces the number of candidates on hold by as much as a quadratic factor, down to 2k+1
ε.
For ratio utility, we are able to fully maximize the utility due to the way we decrease scores when the sum is
greater than k. When the sum of scores is less than k, we must be careful in order to avoid being unfair to
candidates eliminated early on. Thus, we maintain three groups; the top candidates, candidates undergoing
comparisons, and candidates given uniform probability. The groups are dynamic and candidates can move
from the ﬁrst to the second and then the third group before getting rejected. Once the sum of scores exceeds
kthe groups are no longer needed. The algorithm considers at most O(k)candidates at any time.
1.2 Related Work
Individual Fairness and Composition. Our work ﬁts into the line of work initiated by Dwork et al.
(2012) on individual fairness , which imposes constraints on how algorithms may distinguish speciﬁc pairs of
individuals. Within this framework, diﬃculties associated with composing fair algorithms were ﬁrst explored
by Dwork & Ilvento (2019), which introduced the fair-cohort-selection problem that we study. Issues of
composition in pipelines were further studied by Dwork et al. (2020).
Because the scores ﬁgure into both our fairness constraint and utility measure, our work has some superﬁcial
similarity to work on meritocratic fairness . At a high-level meritocratic fairness (Joseph et al., 2016; Kearns
et al., 2017; Joseph et al., 2017; Kleine Buening et al., 2022) is a kind of individual fairness where we assume
there exists an intrinsic notion of merit and requires that candidates with higher merit be given no less
reward than candidates with lower merit. In this work, we study a notion of individual metric fairness
that, intuitively, tries to preserve the distances between the scores and not necessarily their order. Our
algorithms turn out to also preserve the ordering, but meritocratically fair algorithms will not, in general,
preserve the distances. We note that in our cases the scores s1,...,snmight or may not be reﬂective of
true merit, since we assume that these scores satisfy individual fairness with respect to some underlying
metricD, which may or may not reﬂect meritocratic values. The work by Kleine Buening et al. (2022) on
set selection under meritocratic fairness is the most related to our work. Yet, their setting is diﬀerent as
the authors make the assumption that the utility function is non-linear and it depends on the combination
of the selected candidates. One of our main assumptions is that every individual contributes to the cohort
utility separately. The diﬀerences between the two problems are also highlighted in their work.
Individually Fair Ranking and Cohort Selection. Our problem has some similarity to fair ranking ,
where we have to produce a permutation over all ncandidates instead of just selecting a small cohort of
k/lessmuchncandidates. Any algorithm for ranking implies an algorithm for cohort selection, since we can select
the topkelements in the ranking as our cohort, and a cohort selected this way may inherit some notion of
fairness from the ranking. However, we do not know of any ranking algorithms that can be used in this way
to satisfy the notions of fairness and optimality we study in this work. In particular, the most closely related
work on individually fair ranking by Bower et al. (2021) uses an incomparable formulation of the ranking
problem, and it is not clear how to express our constraints in their framework. In addition to the diﬀerence
in how fairness and utility are deﬁned, we are not aware of any fair ranking papers that work in an online
model similar to the one we study.
4Published in Transactions on Machine Learning Research (09/2023)
Group Fairness. A complementary line of work, initiated by Hardt et al. (2016) considers notions of group
fairness, which imposes constraints on how algorithms may distinguish in aggregate between individuals from
diﬀerent groups. While our work is technically distinct from work on group fairness, cohort/set selection
has also been studied from this point of view (Zehlike et al., 2017; Stoyanovich et al., 2018) and diﬀerent
approaches for fair ranking have been proposed (Yang & Stoyanovich, 2017; Celis et al., 2018; Singh &
Joachims, 2018; Yang et al., 2019; Zehlike & Castillo, 2020). Issues of composition also arise in this setting,
as noted by several works (Bower et al., 2017; Kannan et al., 2019; Arunachaleswaran et al., 2021).
2 Preliminaries
2.1 Models
We consider the problem of selecting a cohort using the output of an individually fair classiﬁer as deﬁned in
Dwork & Ilvento (2019).
Deﬁnition 2.1 (Individual Fairness (Dwork et al., 2012)) .Given a universe of individuals Uand a metric
D, a randomized binary classiﬁer C:U→{0,1}is individually fair if and only if for all u,v∈U,|P(C(u) =
1)−P(C(v) = 1)|≤D (u,v).
We restate the formal deﬁnition of the problem for convenience.
Deﬁnition 2.2 (Fair Cohort Selection Problem) .Given a universe of candidates U, an integer kand a
metricD, select a set Sofkindividuals such that the selection is individually fair with respect to D, i.e. for
all pairs of candidates u,v∈U,|P(u∈S)−P(v∈S)|≤D (u,v).
In this work, we are interested in the setting of fairness under composition, and designing algorithms that
exploit the fairness properties of their components instead of having direct access to D. An algorithm which
solves this problem will either preserve or shrink the pairwise distances between the selection probabilities
of candidates. We can think of the probability of Cselecting a candidate uas a continuous score su.
Deﬁnition 2.3 (Fairness-Preserving Cohort Selection Problem) .Given a classiﬁer Cwho assigns score si
to candidate i, select a cohort of kindividuals where each individual ihas marginal selection probability pi
such that for any pair of individuals i,j,|pi−pj|≤|si−sj|.
In some contexts that we deﬁne below, we consider a relaxation of this deﬁnition by adding a small error ε
to the pairwise distances.
Deﬁnition 2.4 (ε-Approximate Fairness-Preserving Cohort Selection Problem) .Given a classiﬁer Cwho
assigns score sito any individual iand a parameter ε∈(0,1], select a cohort of kindividuals where each
individualihasmarginalselectionprobability pisuchthatforallpairsofindividuals i,j|pi−pj|≤|si−sj|+ε.
When the initial classiﬁer Cis individually fair and the cohort selection algorithm preserves fairness ε-
approximately, then the cohort selection probabilities satisfy ε-individual fairness.
Deﬁnition 2.5 (ε-Individual Fairness) .Given a universe of individuals U, a metricDand anεin[0,1], a
randomized binary classiﬁer C:U→{0,1}isε-individually fair if and only if for all u,v∈U,|P(C(u) =
1)−P(C(v) = 1)|≤D (u,v) +ε.
The problem of fairness-preserving cohort selection may be studied in an oﬄinesetting, where the universe
of candidates is known in advance, as well as in an onlinesetting, in which candidates arrive one-at-a-
time. Dwork & Ilvento (2019) prove that making immediate selection decisions while preserving fairness is
impossible, so we relax this to a setting in which we do not need to give immediate decisions as candidates
arrive. To control the degree of relaxation, we consider the number of candidates who wait for a response
during the selection stage; we seek to minimize the number of these pending candidates.
Individualfairnesscanbeachievedbymakinguniformrandomselectionsamongcandidates, whichistrivially
possible in the oﬄine case, and can be implemented in the online setting using reservoir sampling (Vitter,
1985). Therefore, it is important to consider an extension to the cohort selection problem in which we also
want to maximize the utility of the selected cohort. We consider two measures of utility and construct
5Published in Transactions on Machine Learning Research (09/2023)
algorithms for cohort selection which optimize these measures. Let the selection scores for individuals under
classiﬁerCbes1,...,sn, and let their marginal probabilities of selection under an algorithm Abep1,...,pn.
Utilities Correlated with Classiﬁer Output. We may consider that the classiﬁer scores sdirectly
indicate the qualiﬁcations of an individual and that the utility of a cohort is the sum of the scores of each
member. Then, our evaluation measure becomes the expected utility of the selected cohort.
Deﬁnition 2.6 (Linear Utility) .Consider a set of ncandidates whose scores from classiﬁer Cares1,...,sn
and whose selection probabilities by algorithm Aarep1,...,pn. We deﬁne the linear utility of Ato be
Utilitylinear (A,{si}) =/summationtextn
i=1sipi.
AsseeninExample2.1, themaximumlinearutilityunderthefairness-preservingconstraintisnotamonotone
function of the input scores; as the score siincreases, the maximum linear utility may either increase,
decrease, or stay constant. Yet, we show in Lemma 3.1 that it is robust to small input perturbations.
Therefore, it can handle minor noise or errors in the input value. We exploit this property to develop an
ε-individually fair algorithm for online cohort selection.
Example 2.1. Suppose we want to select 2 people from a set of 4 candidates and classiﬁer Cassigns scores
s1= 0.1,s2= 0.3,s3= 0.6ands4= 0.9. The optimal fairness-preserving solution has marginal selection
probabilities p1= 0.125,p2= 0.325,p3= 0.625andp4= 0.925and utility/summationtext4
i=1pisi= 1.3175. By increasing
the score of the ﬁrst individual to s/prime
1= 0.3, the cohort selection probabilities become p/prime
1= 0.275,p/prime
2=
0.275,p/prime
3= 0.575andp/prime
4= 0.875. The new utility is/summationtext4
i=1p/prime
is/prime
i= 1.2975, which is lower than the previous
one.
Arbitrary Utilities. Alternatively, we may consider the case where there exists an arbitrary, unknown
utility value for each candidate u1,...,unin[0,1], which may diﬀer from the scores s. Givensiandui, a
simple quantity to study is the ratio utility achieved by an algorithm A:/summationtext
ipiui/summationtext
isiui. Since we do not know the
distribution of utility, we must consider the utility achieved by an algorithm Afor a worst-case utility vector
/vector u.
Lemma 2.1. The worst case ratio utility is equal to the minimum ratio of selection probability and classiﬁer
score of one candidate min/vector u/summationtext
ipiui/summationtext
isiui= minipi
si.
We use this equivalence to redeﬁne the ratio utility as follows.
Deﬁnition 2.7 (Ratio Utility) .Givenncandidates with scores siand a cohort selection algorithm A
with marginal selection probabilities pi, let the ratio utility of an algorithm Abe deﬁned according to the
coordinate with the minimum ratio: Utilityratio (A,{si}) = minipi
si.
Of course other utility measures exist; we study the measures deﬁned above because they capture a natural
intuition about real world scenarios. We present an example to demonstrate the properties of these two
utility functions and the performance of pre-existing cohort selection algorithms.
Example 2.2. Consider the case where we would like to select 2out of 3candidates with scores s1= 0.5,
s2= 0.5,s3= 1. Theoptimalsolutionintermsofratioandlinearutilityistopick {1,3}and{2,3}, eachwith
probability 0.5. This solution achieves ratio utility 1and linear utility 1.5. The weighted sampling algorithm
by Dwork & Ilvento (2019) selects each subset with probability proportional to its weight, and would select
{1,2}with probability 1/4,{1,3}with probability 3/8, and{2,3}with probability 3/8. The ratio utility of
this solution is 3/4and its linear utility is 11/8. PermuteThenClassify by Dwork & Ilvento (2019) selects
{1,2}with probability 1/12and{1,3}or{2,3}with probability 11/24each. This solution achieves ratio
utility 11/12and linear utility 35/24. Hence, we see that weighted sampling and PermuteThenClassify are
sub-optimal for both utility deﬁnitions.
2.2 Dependent Rounding
Our cohort selection algorithms for ratio and linear utility in the oﬄine and online settings are based on a
simple dependent rounding algorithm described in the appendix. This algorithm makes one pass over a list
6Published in Transactions on Machine Learning Research (09/2023)
of numbers in [0,m], wherem∈R, and rounds them so that their sum is preserved and the expected value
of each element after rounding is equal to its original value. The algorithm operates on two entries at a time
- call these aandb. Ifa+b≤m, the algorithm randomly rounds one of them to a+band the other one to
0with the appropriate probabilities. If a+b>m, it rounds one to mand the other to the remainder.
This rounding procedure is a special case of rounding a fractional solution in a matroid polytope (in this
case, we have a uniform matroid). This problem has been studied extensively with rounding procedures
satisfying additional desirable properties (see e.g. Chekuri et al. (2010)). Here we use a simple and very
eﬃcient rounding algorithm for the special case of the problem arising in our work.
Lemma 2.2. Leta1,...,anbe a list of numbers in [0,m]withx=/summationtextn
i=1ai. There is a randomized algorithm
that outputs ˜a1,..., ˜an∈[0,m]such that⌊x
m⌋of theaiwill be equal to m, oneaiwill bex−⌊x
m⌋m, the rest
will be equal to 0, and for all i∈{1,...,n},E[˜ai] =ai. Whenm= 1, we call this algorithm round-pr and
whena1,...,anare natural numbers we call it round-nat .
We use the rounding procedure in two ways. We call round-pr when we want to round a list of real numbers
in[0,1]which represent selection probabilities and round-nat to round natural numbers which correspond
to counts.
Corollary 2.1. Ifm= 1and/summationtextn
i=1ai=k∈N, then after the dependent rounding of round-prkelements
will be equal to 1and the rest will be equal to 0.
3 Linear Utility
The ﬁrst deﬁnition of utility we study is that of linear utility. In this setting, the aim of the cohort selection
is to maximize the expected sum of scores of the group of kpeople selected while preserving fairness. We
can formulate this problem as a linear program, as shown in Section 1.1.
The key idea of the solution is to move all the selection scores up or down by the same amount, depending
on the value of their sum, and clip the probabilities that are less than zero or over one. The algorithm
we propose for the online setting solves approximately a relaxation of the cohort selection problem, where
the probabilities of two candidates can diﬀer by at most the given metric plus a small constant ε. The
new problem is deﬁned as the linear program presented in Section 1.1, where the second constraint, ∀i,j∈
[n],|pi−pj|≤|si−sj|, is replaced by∀i,j∈[n],|pi−pj|≤|si−sj|+ε.
3.1 Oﬄine Cohort Selection
In the oﬄine setting, the algorithm has full access to the set of candidates and their scores from classiﬁer C.
By Corollary 2.1, if the classiﬁer’s scores sum up to k, then the rounding algorithm can form a cohort by
simply using the input scores as the marginal probabilities of selection. Yet, the sum of the scores assigned by
Cmight not be k. If it is less than k, Algorithm 1 moves all the probabilities up by the same amount and clips
those that exceed 1, so that their sum becomes equal to k. In more detail, the marginal selection probability
of candidate ibecomespi= min{si+c,1}, where constant cis such that/summationtextn
i=1pi=k. This adjustment
preserves the probability diﬀerences between the pairs of candidates, unless some candidate gets assigned
probability 1, in which case some diﬀerences decrease. As a result, the diﬀerences of the new probabilities
will be bounded by the same metric as the scores. The case where the sum of scores is greater than kis
treated similarly. More speciﬁcally, the new marginal probabilities are of the form pi= max{0,si−c}. After
the adjustment, Algorithm 1 selects the cohort by running the dependent rounding procedure.
Theorem 3.1. For any classiﬁer Cthat assigns scores s1,...,sntoncandidates, Algorithm 1 solves the
fairness-preserving cohort selection problem by selecting kcandidates with marginal probabilities p1,...,pn
which achieve optimal linear utility/summationtextn
i=1pisi.
Corollary 3.1. IfCis individually fair, then Algorithm 1 is individually fair.
3.2 Online Cohort Selection
For the online setting of the problem with linear utility, we present Algorithm 2 which reads C’s output from
a stream and selects a cohort with high utility while deferring the decision for a small number of candidates.
7Published in Transactions on Machine Learning Research (09/2023)
Alg. 1:Oﬄine Cohort Selection for Linear Utility
Input:scoress1,...,sn∈[0,1]fromC, cohort size k
Output: set of accepted candidates
1sum←/summationtextn
i=1si
2ifsum<kthen
// move scores up
3c←k−sum
n;pi←si+c,∀i∈[n]
4while∃pi>1do
5S<1←{j:pj<1}
6pj←pj+pi−1
|S<1|,∀j∈S<1
7pi←1
8else
// move scores down
9c←sum−k
n;pi←si−c,∀i∈[n]
10while∃pi<0do
11S>0←{j:pj>0}
12pj←pj+pi
|S>0|,∀j∈S>0
13pi←0
// Now list sums to kand allpi∈[0,1]
14{˜pi}←round-pr (p1,...,pn, 1)// select cohort of size k
15returncandidates with non-zero ˜pi
Whileprocessingthestream, thisalgorithmonlyrejectscandidatesandreleasesalltheacceptancesattheend
of the stream. The main diﬀerence in comparison to the oﬄine cohort selection algorithm is that Algorithm
2 splits the candidates into groups with similar scores, within an εinterval, and treats any member of a
group as equivalent. Hence, the ﬁnal probability of being selected in the cohort is equal for any candidate of
the same group. This leads to a relaxation of the problem, which we call ε-approximate fairness-preserving
cohort selection problem.
As we mentioned, the algorithm splits the candidates from the stream into groups according to their score
fromC. Particularly, the interval (0,1]is divided into mintervals of size εeach, where m=⌈1
ε⌉. Thei-th
candidate gets assigned to group 0ifsi= 0or groupg∈{1,...,m}ifsi∈((g−1)ε,gε]. Once candidate iis
in the group, their score gets rounded up and their new score ˆsiis the same as that of all the other members
of the group, ˆsg=gε. The use of the groups aﬀects the performance of the algorithm in terms of not only
individual fairness, but also utility. Lemma 3.1 shows that the decrease in utility is caused only by the use
of rounding, as Algorithm 2 achieves the same linear utility as the corresponding oﬄine algorithm when the
scores are rounded to multiples of ε.
Lemma 3.1. Given selection scores s1,...,snfromC, for a set of ncandidates and a parameter ε∈(0,1],
we split (0,1]intom=⌈1
ε⌉intervals of length εand for all i∈[n]we set ˆsi=gε, wheregis such that
si∈((g−1)ε,gε]. When Algorithm 1 runs for input ˆs1,..., ˆsnand cohort size kit solves the ε-approximate
fairness-preserving cohort selection problem with marginal selection probabilities p1,...,pn, and it achieves
linear utility/summationtextn
i=1pisi≥/summationtextn
i=1p∗
isi−k(ε+ 2√ε), wherep∗
1,...,p∗
nis the optimal solution for the oﬄine
fairness-preserving problem for input s1,...,sn.
Since for each group we keep only some people on hold, we preserve the probability information of the
rejected candidates by considering that each pending candidate represents themselves and a fraction of the
rejected people from their group. The fraction of people represented by the i-th candidate is denoted by
ni. One approach is to maintain at most kpeople pending per group uniformly at random and have every
candidate within a certain group represent the same fraction of people. This basic algorithm keeps k/ε
candidates on hold. Our algorithm reduces the number of people pending by allowing candidates of the
8Published in Transactions on Machine Learning Research (09/2023)
Alg. 2:Online Cohort Selection for Linear Utility
Input:stream of scores s1,...,sn∈[0,1]fromC, cohort size k, constant ε∈(0,1]
Output: set of accepted candidates
1n←0; sum←0// number of candidates and sum of scores
2ng←0, for all groups g∈[⌈1
ε⌉]// size of group g
3forcandidateiin stream do
4addito groupgwheresi∈((g−1)ε,gε]
5ng←ng+ 1
6 ˆsi←gε; sum←sum+ ˆsi
7ni←1;n←n+ 1
// Compute group scores for this input
8ifsum<kthen
9c←k−sum
n
10sg←gε+c, for all groups g
11 while∃groupgwithsg>1do
12F<1←{groupf:sf<1}
13 n<1←/summationtext
f∈F<1nf
14 sf←sf+ng(sg−1)
n<1,∀f∈F<1
15 sg←1
16else ifsum>kthen
17c←sum−k
n
18sg←gε−c, for all groups g
19 while∃groupgwithsg<0do
20F>0←{groupf:sf>0}
21 n>0←/summationtext
f∈F>0nf
22 sf←sf+ngsg
n>0,∀f∈F>0
23 sg←0
24elsesg←gε, for all groups g
25forgroupgdo
26 ifsg>0then
27{ni:iing}← round-nat ({ni:iin g},v=⌊1
sg⌋)
// we ensure niv≤1
28 reject candidate iifni= 0
29 else
30 reject all candidates in g
31˜si←nisg, for all groups gand candidates iing
// Now candidate scores sum up to kand all ˜siin[0,1]
32{˜si}← round-pr ({˜si:iin any group}, 1)// select cohort of size k
33returncandidates with non-zero ˜si
same group to represent varying fractions of people. Procedure round-nat is used to eliminate candidates
and determine what fraction of people’s selection probabilities each candidate represents.
Theorem 3.2. For any classiﬁer Cthat assigns scores s1,...,sntoncandidates, Algorithm 2 solves the
onlineε-approximate fairness-preserving cohort selection problem for any ε∈(0,1]by selecting a cohort
of sizekwith marginal probabilities p1,...,pn, achieves linear utility/summationtextn
i=1pisi≥/summationtextn
i=1p∗
isi−k(ε+ 2√ε)
(wherep∗
1,...,p∗
nis the optimal solution for the oﬄine fairness-preserving problem for input s1,...,sn), and
keeps at most O(k+1
ε)candidates pending.
Corollary 3.2. IfCis individually fair, then Algorithm 2 is ε-individually fair.
9Published in Transactions on Machine Learning Research (09/2023)
4 Ratio Utility
In Deﬁnition 2.7 we consider the ratio utility obtained by a selection algorithm, and show that this is
controlled by the minimum ratio of piandsi.
4.1 Oﬄine Cohort Selection
We begin with the scenario of selecting kofnindividuals when all candidates are known in advance. Dwork
& Ilvento (2019) give a solution to this scenario (with non-optimal utility, as shown in Example 2.2); we
present Algorithm 3, an alternate one that achieves the optimal ratio utility. Notice that the sum of classiﬁer
scores/summationtext
isineed not add up to k. If the sum exceeds k, the algorithm simply scales down all probabilities
so that the new sum is k. It is not hard to show that this operation preserves fairness and gives optimal
utility. This multiplicative scaling will not work when the sum is smaller than k, however, since it increases
the probability diﬀerence among candidates and can be unfair. Intuitively, the solution in this case is to
additively increase all probabilities by the same amount, thus preserving fairness. However, some care is
needed, as no probability can exceed 1.
Alg. 3:Oﬄine Cohort Selection for Ratio Utility
Input:scoress1,...,sn∈[0,1]fromC, cohort size k
Output: set of accepted candidates
1sum←/summationtextn
i=1si
2ifsum<kthen
// move scores up
3c←k−sum
n;pi←si+c,∀i∈[n]
4while∃pi>1do
5S<1←{j:pj<1}
6pj←pj+pi−1
|S<1|,∀j:pj<1
7pi←1
8else
// move scores down
9pi←si·k
sum,∀i∈[n]
// Now list sums to kand allpi∈[0,1]
10{˜pi}←round-pr (p1,...,pn,1)// select cohort of size k
11returncandidates with non-zero ˜pi
Lemma 4.1. Ifsum<k, Algorithm 3 increases each input score sito a ﬁnal output pi=si+αi≥sisuch
that all of the candidates jwithpj<1receive the same cumulative adjustment value αj=v.
Theorem 4.1. For any classiﬁer Cthat assigns scores s1,...,sntoncandidates, Algorithm 3 solves the
fairness-preserving cohort selection problem by selecting kcandidates with marginal probabilities p1,...,pn
that achieve the optimal value of ratio utility minipi
si.
Corollary 4.1. IfCis individually fair, then Algorithm 3 is individually fair.
4.2 Online Cohort Selection
We now consider the online scenario, in which our goal is to keep as few candidates pending as possible.
It is clear that the number of candidates on hold must be at least ksince we need to accept kcandidates
at the end. We provide an algorithm that achieves optimal ratio utility for the online fairness-preserving
cohort selection problem, while leaving only O(k)candidates pending. We use a parameter α∈[0,1/2],
which controls the number of candidates pending, with α= 1/2by default. The update procedure depends
on the sum of scores of the candidates seen so far. We maintain a set of k/αcandidates with highest scores
called top, and two sets restandrandof the remaining candidates. A new candidate iis added to either
top(and thus bumps some other candidate from toptorest), or they are added to rest. We make sure
10Published in Transactions on Machine Learning Research (09/2023)
Alg. 4:Online Cohort Selection for Ratio Utility
Input:stream of scores s1,...,sn∈[0,1]fromC, cohort size k, constantα∈[0,1/2]
Output: set of accepted candidates
1sum←0
2top←∅;rest←∅;rand←∅
3forcandidateiin stream do
4sum←sum+si;pi←si
5ifsum<kthen
6if|top|<⌈k/α⌉thenadditotop
7else ifmin(sj)intop<sithen
8 move min element from toptorest
9 additotop
10 elseadditorest
11{pi:i∈rest}←round-pr ({pi:i∈rest},1−α)
12 forjinrestwithpj= 0do
13 removejfrom rest
14 addjto unif. reservoir sample of size k
15 reject candidate that was eliminated from the unif. reservoir sample
16 setrandto unif. reservoir sample
17else
18 ifﬁrst occurrence of sum ≥kthen
19 reject all candidates in randand remove rand
20 store topandrestinpending
21 incr←k
sum; scale←k
sum
22 else
23 incr←sum−si
sum; scale←scale·incr
24pi←pi·scale
25pj←pj·incr,∀j∈pending
26 additopending
27{pi:i∈pending}←round-pr ({pi:i∈pending }, 1)
28 rejectjand remove it from pending ifpj= 0
29ifsum<kthen
30c←k−sum
n;pi←pi+c,∀i∈top∪rest
31pi←k−/summationtext
i∈top∪restpi
|rand|,∀i∈rand
32while∃pi>1do
33S(≥1)←{i:pi≥1};c←pi−1
n−|S (≥1)|
34pj←pj+c,∀j∈top∪restwithpj<1
35 setnmodiﬁedto number of modiﬁed people
36pj←pj+c·(n−|S (≥1)|−nmodiﬁed )
|rand|,∀j∈rand
37pi←1
38{pi:i∈top∪rest∪rand}←round-pr ({pi:i∈top∪rest∪rand}, 1)
39setpending to indices of nonzero pi
40return pending
the list restis not too big by rounding and eliminating candidates. Eliminated candidates are sampled
uniformly to enter rand, which has size k.
During the online phase, it is tempting to use the idea from the oﬄine case to eliminate candidates; take
two candidates from restwith scores aandband round them to a+band0. However, we must be careful
11Published in Transactions on Machine Learning Research (09/2023)
when rounding restto ensure that probabilities will not later exceed 1if the stream ends with sum < k.
The key idea (and motivation for having top) is that candidates not in tophave increments at most α,
which we can see as follows. For restto be non-empty, we must have at least n>k/α candidates. Let xbe
the number of candidates who are in topwhen the algorithm ﬁnishes and achieve probability 1. For each
of the other candidates, the increment pi−siis less than (k−x)/(n−x)< k/n, sincek < n. Thus that
cumulative increment is at most α, and it is safe to round probabilities in restto0and1−α.
If the stream ends with/summationtext
isi< k, we will increase the scores of everyone pending, and use randto
compensate for already eliminated candidates. Let Abe the set of candidates in topandrestand ¯Abe
the set of all others seen. As in the oﬄine case, we will evenly increase the probabilities of all candidates
by adding the appropriate cto each candidate, and using water-ﬁlling where some candidates reach 1. For
candidates in A, this proceeds exactly as in the oﬄine case. For candidates in ¯A, we increase the probabilities
without explicitly storing all of them by maintaining a set called randconsisting of kuniformly random
candidates. Each member of randreceives probability equal to 1/ktimes the sum of the probabilities of the
candidates in ¯A. Since everyone in ¯Ahas the same probability, this rounding clearly preserves the marginal
probabilities. Finally, we use the oﬄine algorithm to select the cohort from the union of randandA.
The case where the sum of probabilities exceeds kis simpler. The algorithm always scales down all proba-
bilities so that they add up to exactly k. When a new candidate appears, they receive a probability equal
to whatCgives them, times the current scaling factor, and get added to top∪rest. The algorithm then
scales down all probabilities so that the sum is exactly kand reduces the size of top∪restby repeatedly
rounding pairs of candidate as in the oﬄine setting. In this case, the set randis not used.
Theorem 4.2. For any classiﬁer Cthat assigns scores s1,...,sntoncandidates, Algorithm 4 solves the
fairness-preserving cohort selection problem by selecting kcandidates with marginal probabilities p1,...,pn
that achieve the optimal value of ratio utility. The algorithm leaves no more than O(k)candidates pending
at any time.
Corollary 4.2. IfCis individually fair, then Algorithm 4 is individually fair.
5 Conclusion
In this work, we deﬁned two notions of utility for the problem of cohort selection, linear and ratio utility, and
designed polynomial time algorithms that optimize them (or approximately optimize them) while preserving
the fairness of the given classiﬁer. This means that if the given classiﬁer is individually fair, then our cohort
selection algorithms are also individually fair with respect to the same metric. We studied two settings, the
standard oﬄine setting and an online setting where we can reject candidates at any stage of the process and
accept candidates only at the end, keeping the number of candidates that are waiting for the decision low.
While our algorithms for ratio utility and oﬄine linear utility are optimal in terms of fairness and utility,
our online algorithm for linear utility achieves ε-individual fairness with an additive error in the utility and
the number of candidates kept on hold.
Overall, our approach is based on the assumptions that every candidate contributes to the utility of the
cohort separately and that the candidate utilities are correlated with their selection scores given by the
individually fair classiﬁer. As the linear utility requires the assumption that the utilities of the candidates
are their classiﬁcation scores, we tried to relax it by deﬁning the ratio utility in which the utilities are
unknown but still correlated with the classiﬁcation scores. The natural extension of this work would be to
design algorithms that optimize a utility function where the candidate utilities are known and decoupled
from the classiﬁcation scores. Another interesting direction would be to relax our ﬁrst assumption and study
utility functions where the candidates do not contribute separately, but the cohort utility depends on the
combination of candidates selected.
Acknowledgments
KB and JU were supported by NSF awards CCF-1750640 and CNS-2120603. KB and HN were supported
by NSF grant CCF-1750716.
12Published in Transactions on Machine Learning Research (09/2023)
References
Eshwar Ram Arunachaleswaran, Sampath Kannan, Aaron Roth, and Juba Ziani. Pipeline Interventions.
InInnovations in Theoretical Computer Science Conference , ITCS ’21, 2021. https://arxiv.org/abs/
2002.06592 .
Amanda Bower, Sarah N Kitchen, Laura Niss, Martin J Strauss, Alexander Vargas, and Suresh Venkata-
subramanian. Fair pipelines, 2017. https://arxiv.org/abs/1707.00391 .
Amanda Bower, Hamid Eftekhari, Mikhail Yurochkin, and Yuekai Sun. Individually fair rankings. In 9th
International Conference on Learning Representations, ICLR 2021, Virtual Event, Austria, May 3-7, 2021 .
OpenReview.net, 2021. https://arxiv.org/abs/2103.11023 .
L. Elisa Celis, Damian Straszak, and Nisheeth K. Vishnoi. Ranking with fairness constraints. In 45th
International Colloquium on Automata, Languages, and Programming, ICALP 2018, July 9-13, 2018,
Prague, Czech Republic , volume 107 of LIPIcs, pp. 28:1–28:15. Schloss Dagstuhl - Leibniz-Zentrum für
Informatik, 2018. doi: 10.4230/LIPIcs.ICALP.2018.28. URL https://doi.org/10.4230/LIPIcs.ICALP.
2018.28.https://arxiv.org/abs/1704.06840 .
Chandra Chekuri, Jan Vondrák, and Rico Zenklusen. Dependent randomized rounding via exchange prop-
erties of combinatorial structures. In IEEE Symposium on Foundations of Computer Science , FOCS ’10.
IEEE, 2010. https://arxiv.org/abs/0909.4348 .
Cynthia Dwork and Christina Ilvento. Fairness under composition. In Innovations in Theoretical Computer
Science, ITCS ’19, 2019. http://arxiv.org/abs/1806.06122 .
Cynthia Dwork, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Richard Zemel. Fairness through
awareness. In Innovations in Theoretical Computer Science , ITCS ’12. ACM, 2012. https://arxiv.org/
abs/1104.3913 .
Cynthia Dwork, Christina Ilvento, and Meena Jagadeesan. Individual Fairness in Pipelines. In Symposium
on Foundations of Responsible Computing , FORC ’20, 2020. https://arxiv.org/abs/2004.05167 .
Moritz Hardt, Eric Price, and Nathan Srebro. Equality of opportunity in supervised learning. In Conference
on Neural Information Processing Systems , NIPS ’16, 2016. https://arxiv.org/abs/1610.02413 .
Matthew Joseph, Michael J. Kearns, Jamie Morgenstern, and Aaron Roth. Fairness in learning: Classic and
contextual bandits. In Advances in Neural Information Processing Systems 29: Annual Conference on
Neural Information Processing Systems 2016, December 5-10, 2016, Barcelona, Spain , pp. 325–333, 2016.
https://arxiv.org/abs/1605.07139 .
Matthew Joseph, Michael Kearns, Jamie Morgenstern, Seth Neel, and Aaron Roth. Fair algorithms for
inﬁnite and contextual bandits, 2017. https://arxiv.org/abs/1610.09559 .
Sampath Kannan, Aaron Roth, and Juba Ziani. Downstream eﬀects of aﬃrmative action. In Conference
on Fairness, Accountability, and Transparency , FAT* ’19. ACM, 2019. https://arxiv.org/abs/1808.
09004.
Michael Kearns, Aaron Roth, and Zhiwei Steven Wu. Meritocratic fairness for cross-population selection.
InProceedings of the 34th International Conference on Machine Learning - Volume 70 , ICML’17, pp.
1828–1836. JMLR.org, 2017. https://arxiv.org/abs/1805.08716 .
Thomas Kleine Buening, Meirav Segal, Debabrota Basu, Anne-Marie George, and Christos Dimitrakakis. On
meritocracy in optimal set selection. In Equity and Access in Algorithms, Mechanisms, and Optimization ,
EAAMO ’22, New York, NY, USA, 2022. Association for Computing Machinery. ISBN 9781450394772.
doi: 10.1145/3551624.3555305. URL https://doi.org/10.1145/3551624.3555305 .
Ashudeep Singh and Thorsten Joachims. Fairness of exposure in rankings. In Proceedings of the 24th ACM
SIGKDD International Conference on Knowledge Discovery & Data Mining , KDD’18, pp.2219–2228, New
York, NY,USA,2018.AssociationforComputingMachinery. ISBN9781450355520. doi: 10.1145/3219819.
3220088. URL https://doi.org/10.1145/3219819.3220088 .https://arxiv.org/abs/1802.07281 .
13Published in Transactions on Machine Learning Research (09/2023)
Julia Stoyanovich, Ke Yang, and H. V. Jagadish. Online set selection with fairness and diversity constraints.
InAdvances in Database Technology - EDBT 2018 , Advances in Database Technology - EDBT, pp. 241–
252. OpenProceedings.org, 2018. doi: 10.5441/002/edbt.2018.22.
Jeﬀrey S. Vitter. Random sampling with a reservoir. ACM Trans. Math. Softw. , 11(1):37–57, March 1985.
ISSN 0098-3500. doi: 10.1145/3147.3165. URL http://doi.acm.org/10.1145/3147.3165 .
Ke Yang and Julia Stoyanovich. Measuring fairness in ranked outputs. In Proceedings of the 29th Interna-
tional Conference on Scientiﬁc and Statistical Database Management , SSDBM ’17, New York, NY, USA,
2017. Association for Computing Machinery. ISBN 9781450352826. doi: 10.1145/3085504.3085526. URL
https://doi.org/10.1145/3085504.3085526 .https://arxiv.org/abs/1610.08559 .
Ke Yang, Vasilis Gkatzelis, and Julia Stoyanovich. Balanced ranking with diversity constraints. In
Proceedings of the Twenty-Eighth International Joint Conference on Artiﬁcial Intelligence, IJCAI-19 ,
pp. 6035–6042. International Joint Conferences on Artiﬁcial Intelligence Organization, 7 2019. https:
//arxiv.org/abs/1906.01747 .
Meike Zehlike and Carlos Castillo. Reducing disparate exposure in ranking: A learning to rank approach.
InProceedings of The Web Conference 2020 , pp. 2849–2855, New York, NY, USA, 2020. Association
for Computing Machinery. ISBN 9781450370233. URL https://doi.org/10.1145/3366424.3380048 .
https://arxiv.org/abs/1805.08716 .
MeikeZehlike,FrancescoBonchi,CarlosCastillo,SaraHajian,MohamedMegahed,andRicardoBaeza-Yates.
Fa*ir: A fair top-k ranking algorithm. In Proceedings of the 2017 ACM on Conference on Information
and Knowledge Management , CIKM ’17, pp. 1569–1578, New York, NY, USA, 2017. Association for
Computing Machinery. ISBN 9781450349185. doi: 10.1145/3132847.3132938. URL https://doi.org/
10.1145/3132847.3132938 .https://arxiv.org/abs/1706.06368 .
A Proofs and Algorithm from Section 2
A.1 Proof of Lemma 2.1
Lemma 2.1. The worst case ratio utility is equal to the minimum ratio of selection probability and classiﬁer
score of one candidate min/vector u/summationtext
ipiui/summationtext
isiui= minipi
si.
Proof.Letjbe the index of the candidate with the smallest ratio of model output and classiﬁer score, i.e.
pj
sj≤pi
si,∀i/negationslash=j. Compare the minimum over all utility vectors to a particular choice of utility vector u∗
satisfyingu∗
j= 1, andu∗
i/negationslash=j= 0. We know that the ratio for any particular vector will be at least as large as
the minimum: min/vector u/summationtext
ipiui/summationtext
isiui≤/summationtext
ipiu∗
i/summationtext
isiu∗
i=pju∗
j
sju∗
j=pj
sj= minipi
si.
We can also obtain a bound from the other direction. Let mbe the smallest ratio between model output
and classiﬁer score m= minipi/siandu∈[0,1]nbe any utility vector with/summationtext
iui>0. Then, for all i∈[n]
we havepiui≥msiui. Therefore, min/vector u/summationtext
ipiui/summationtext
isiui≥minipi
si
A.2 Dependent Rounding Algorithm
Here we include a detailed description of the dependent rounding algorithm (Algorithm 5) mentioned in
Section 2.2.
A.3 Proof of Lemma 2.2
Lemma 2.2. Leta1,...,anbealistofnumbersin [0,m]withx=/summationtextn
i=1ai. Thereisarandomizedalgorithm
that outputs ˜a1,..., ˜an∈[0,m]such that⌊x
m⌋of theaiwill be equal to m, oneaiwill bex−⌊x
m⌋m, the
14Published in Transactions on Machine Learning Research (09/2023)
Algorithm 5: Rounding
Input:a list ofnnumbersa1,a2,...,an∈R≥0and the maximum value of a rounded number m∈R≥0
Output: list of rounded numbers ˜a1,˜a2,..., ˜an∈R≥0
1pendingIndex←1
2forifrom 2tondo
3ifai= 0andapendingIndex = 0thencontinue to next i
4a←ai;b←apendingIndex
5chooseurandomly from Unif (0,1)
6ifa+b≤mthen
7ifu<a
a+bthen
8 ai←a+b;apendingIndex←0; pendingIndex←i
9else
10 ai←0;apendingIndex←a+b
11 end
12else
13 ifu<m−b
2m−a−bthen
14 ai←m;apendingIndex←a+b−m
15 else
16 ai←a+b−m;apendingIndex←m; pendingIndex←i
17 end
18end
19end
20returna1,a2,...,an
rest will be equal to 0, and for all i∈{1,...,n},E[˜ai] =ai. Whenm= 1, we call this algorithm round-pr
and whena1,...,anare natural numbers we call it round-nat .
Proof.We begin by showing that for all i∈[n],E[˜ai] =ai. At stepi, we have two numbers aandbwhich
get rounded and obtain new values denoted by ˜aand˜b, respectively. The rounding depends on the value of
a+b. Ifa+bis less than or equal to β, then E[˜a] = (a+b)a
a+b=a. Ifa+bis greater than βand at most
2β, then E[˜a] =vβ−b
2β−a−b+ (a+b−β)β−a
2β−a−b=a. Similarly, we obtain E[˜b] =b. Since the expected values
remain constant throughout the process, we conclude that for all i∈[n],E[˜ai] =ai.
We notice that for any step iof the algorithm and for all jthat are smaller than ibut are not the pendingIn-
dex,aj= 0oraj=β. As a result, at the end of the algorithm all elements with index jsuch thatj < n
andj/negationslash=pendingIndex and one of the n-th or the pendingIndex elements are rounded to either 0orβ. The
remaining element is the only one that can have a value in all [0,β]. Since/summationtextn
i=1ai=sum,⌊sum
β⌋elements
areβand if the remainder sum −⌊sum
β⌋βis non-zero, it is assigned to the remaining element.
A.4 Proof of Corollary 2.1
Corollary 2.1. Ifm= 1and/summationtextn
i=1ai=k∈N, then after the dependent rounding of round-prkelements
will be equal to 1and the rest will be equal to 0.
Proof.The proof follows directly from Lemma 2.2.
15Published in Transactions on Machine Learning Research (09/2023)
B Proofs from Section 3
B.1 Proof of Theorem 3.1
Theorem 3.1. For any classiﬁer Cthat assigns scores s1,...,sntoncandidates, Algorithm 1 solves the
fairness-preserving cohort selection problem by selecting kcandidates with marginal probabilities p1,...,pn
which achieve optimal linear utility/summationtextn
i=1pisi.
Proof.Algorithm 1 consists of two parts. In the ﬁrst part, it modiﬁes the input scores so that they sum up
tok, which is the size of the cohort, and for the second part it randomly selects kindividuals by calling the
round-pr subroutine. We can simplify the ﬁrst part by rewriting it in a more concise way. If the sum of C’s
scoress1,...,snis less than k, then for any candidate i∈[n]we setpi= min{si+b,1}, withbin[0,1]such
that/summationtextn
i=1pi=k. More speciﬁcally, piare initially set to si+cso that their sum is equal to k. Their sum
will remain equal to k, because the following loop only redistributes probability mass among candidates. If
at any iteration some candidate ihaspi>1, then their marginal selection probability is set to 1and the
excess probability mass is redistributed evenly to all candidates with marginal probabilities less than 1. At
the end, any probability pithat is less than 1is equal tosiplus a constant bthat consists of the initial cand
the fractions of the probabilities that exceeded 1. Similarly, we have that if the sum of C’s scores is greater
thank, then for any candidate i,pi= max{si−b,0}for a real number b∈[0,1]such that/summationtextn
i=1pi=k. If
the sum is equal to k, the cohort selection marginal probabilities are equal to C’s scores. Finally, by Lemma
2.2 we obtain that for any i∈[n]the expected value of indicator ˜piispi, and since ˜piis either 0or1, the
i-th candidate is selected with probability pi.
First, we want to show that the cohort formed by Algorithm 1 preserves fairness. Depending on the value
of/summationtextn
i=1si, we have three cases.
1./summationtextn
i=1si=k. The input scores are used unaltered as the marginal probabilities for the cohort
selection and, thus, we have that for any pair of indices i,j,|pi−pj|=|si−sj|.
2./summationtextn
i=1si< k. The cohort selection marginal probabilities are of the form pi= min{si+b,1}. For
any pair of individuals i,j, if both have probability of being selected 1, then|pi−pj|= 0. Else, if
pi= 1andpj=sj+b, we have|pi−pj|<|si−sj|becausesi+b≥1. Finally, if pi=si+band
pj=sj+b, then it holds that |pi−pj|=|si−sj|. As a result, we conclude that for any pair of
individuals i,j, we have|pi−pj|≤|si−sj|.
3./summationtextn
i=1si>k. In this case, the cohort selection probabilities are of the form pi= max{si−b,0}. For
any pair of individuals i,j, if both have zero probability of being selected then |pi−pj|= 0. Else,
ifpi= 0andpj=sj−b, we have|pi−pj|<|si−sj|. Finally, if pi=si−bandpj=sj−b, then it
holds that|pi−pj|=|si−sj|. Thus, for any pair of individuals i,j, we have|pi−pj|≤|si−sj|.
Second, we show that this cohort optimizes linear utility. The fairness-preserving solution that optimizes
linear utility solves the linear program deﬁned in Section 1.1 and satisﬁes the ﬁrst constraint with equality,
i.e./summationtextn
i=1pi=k. This holds because otherwise we would be able to increase piby settingp/prime
i= min{pi+d,1},
for somed∈(0,1], so that/summationtextn
i=1p/prime
i=kand obtain greater utility while not violating any constraint.
We assume that there exists a diﬀerent fairness-preserving solution p/prime
1,...,p/prime
nwhich achieves higher utility,
i.e./summationtextn
i=1p/prime
isi>/summationtextn
i=1pisi. Without loss of generality we can assume that the original probabilities siare
sorted in increasing order. Speciﬁcally, we have s1≤s2≤...≤sn. The solution of Algorithm 1 maintains
the same order, i.e. p1≤p2≤...≤pn. Letibe the individual with the smallest index for whom the two
solutions diﬀer. There are two possible cases. If p/prime
i< pi, then since/summationtextn
i=1pi=/summationtextn
i=1p/prime
i=kthere exists
an individual with j > isuch thatp/prime
j> pj. In addition, we see that pi>0andpj<1. The values of
the probabilities depend on the sum of the input scores in comparison to k. If the sum is greater than k,
allpithat are not zero are of the form pi=si−b. Hence, considering that p/prime
i< pi≤pj< p/prime
jwe obtain
|p/prime
i−p/prime
j|=p/prime
j−p/prime
i>sj−b−(si−b) =sj−si=|si−sj|. Similarly, ifthesumislessthan k, thevaluesof pithat
are not one are of the form pi=si+b, therefore giving |p/prime
i−p/prime
j|=p/prime
j−p/prime
i>sj+b−(si+b) =sj−si=|si−sj|.
16Published in Transactions on Machine Learning Research (09/2023)
If the sum is equal to k, we have|p/prime
i−p/prime
j|=p/prime
j−p/prime
i> pj−pi=sj−si=|si−sj|. In all three cases the
constraints of the optimization are violated.
Ifp/prime
i> pi, then there exists an individual with j > isuch thatp/prime
j< pj. Letjbe the smallest such index.
If there exists another index l > jsuch thatp/prime
l≥pl, then by the previous argument the constraints are
not satisﬁed. Therefore, for any candidate lafterj p/prime
l< pl. This solution achieves non-optimal utility
because there exist candidates with h < landp/prime
h> ph, such that we can move probability mass from
candidates hto individuals lwithout violating the constraints. By constructing a solution p/prime/prime
1,...,p/prime/prime
nwhich
gives a greater utility than p/prime
1,...,p/prime
n, we arrive at a contradiction. Therefore, Algorithm 1 ﬁnds the optimal
fairness-preserving solution.
B.2 Proof of Corollary 3.1
Corollary 3.1. IfCis individually fair, then Algorithm 1 is individually fair.
Proof.The individual fairness condition for Algorithm 1 is satisﬁed by the assumption that the input scores
are individually fair. More speciﬁcally, if the individual scores from Care individually fair with respect to
a metricD, we obtain that∀i,j∈[n],|pi−pj|≤|si−sj|≤D (i,j).
B.3 Proof of Lemma 3.1
Lemma 3.1. Given selection scores s1,...,snfromC, for a set of ncandidates and a parameter ε∈(0,1],
we split (0,1]intom=⌈1
ε⌉intervals of length εand for all i∈[n]we set ˆsi=gε, wheregis such that
si∈((g−1)ε,gε]. When Algorithm 1 runs for input ˆs1,..., ˆsnand cohort size kit solves the ε-approximate
fairness-preserving cohort selection problem with marginal selection probabilities p1,...,pn, and it achieves
linear utility/summationtextn
i=1pisi≥/summationtextn
i=1p∗
isi−k(ε+ 2√ε), wherep∗
1,...,p∗
nis the optimal solution for the oﬄine
fairness-preserving problem for input s1,...,sn.
Proof.We have that for all individuals iin[n],0≤ˆsi−si≤ε. Therefore, we obtain that for any pair of
individuals i,j,|ˆsi−ˆsj|≤|si−sj|+ε. By Theorem 3.1 we have that |pi−pj|≤|ˆsi−ˆsj|. Combining the
two inequalities, we obtain that fairness is preserved ε-approximately.
Note that Algorithm 1 always adjusts the scores of candidates such that its ﬁnal output probabilities sum
tok. For any candidate iwe observe that since the rounded score ˆsiis greater than siby at most ε, the two
output probabilities, piandp∗
iare also close, at most εapart. Depending on the sum of the input scores
there are three cases.
1. If/summationtextn
i=1si≤kand/summationtextn
i=1ˆsi≤k, then Algorithm 1 shifts all the probabilities up. More speciﬁcally,
we have that p∗
i= min{1,si+x}andpi= min{1,ˆsi+y}, for some non-negative xandy. Suppose
thaty > x, then for any candidate iwhose marginal selection probability pihas not been clipped
to1,pi= ˆsi+y > si+x=p∗
i. By summing up for all candidates we obtain that k=/summationtextn
i=1p∗
i</summationtextn
i=1pi=k, which is not feasible. Similarly, suppose that x>y +ε, then for any candidate iwhose
marginal selection probability p∗
iis has not been clipped, p∗
i=si+x>ˆsi+y=pi. As a result, we
get that/summationtextn
i=1p∗
i>/summationtextn
i=1pi, which is again false. Hence, we see that y≤x≤y+ε.
2. If/summationtextn
i=1si≥kand/summationtextn
i=1ˆsi≥k, thenAlgorithm1shiftsalltheprobabilitiesdown, sothatbothsums
become equal to k. Thus,p∗
i= max{0,si−x}andpi= max{0,ˆsi−y}, for some non-negative xand
y. Suppose that y < x, then for any candidate iwho has non-zero marginal selection probability
p∗
i, we have that p∗
i=si−x < ˆsi−y=pi. By summing up for all candidates we obtain that
k=/summationtextn
i=1p∗
i</summationtextn
i=1pi=k, which is not feasible. Similarly, suppose that y >x +ε, then for any
candidateiwhose marginal selection probability piis not 0,pi= ˆsi−y<si−x=p∗
i. As a result,
we get that/summationtextn
i=1p∗
i>/summationtextn
i=1pi, which is false. Thus, we see that x≤y≤x+ε.
3. If/summationtextn
i=1si≤kand/summationtextn
i=1ˆsi≥k, then Algorithm 1 sets p∗
i= min{1,si+x}andpi= max{0,ˆsi−y},
for some non-negative xandy. Suppose that x+y>ε, then for any candidate iwho has non-zero
marginal selection probability pi, we have that pi= ˆsi−y < si+xandpi<1; thereforepi< p∗
i.
17Published in Transactions on Machine Learning Research (09/2023)
By summing up the selection probabilities of all the candidates we obtain that k=/summationtextn
i=1pi</summationtextn
i=1p∗
i=k, which is not feasible. Similarly, suppose that x+y < 0, then for any candidate i
whose marginal selection probability p∗
iis not 1,p∗
i=si+x<ˆsi−y=p∗
i. As a result, we get that/summationtextn
i=1p∗
i</summationtextn
i=1pi, which is false. Therefore, we know that 0≤x+y≤ε.
In all three cases we see that for any candidate ithe selection probabilities of the two solutions satisfy
|pi−p∗
i| ≤ε. Now, consider any coordinate ifor whichp∗
i≥√ε. Sincepi≥p∗
i−ε, we have that
pi≥(1−√ε)p∗
iand, thus,pisi≥(1−√ε)p∗
isi. LetEbe the set of all individuals who have p∗
i<√ε.
1. If/summationtextn
i=1si≤k, thenp∗
i= min{1,si+x}. Thus, 0≤si+x <√εbecause both siandxare
non-negative. Since both piandp∗
isum up tok, we obtain that−kx≤/summationtext
i∈Episi≤k√ε−kxand
−kx≤/summationtext
i∈Ep∗
isi≤k√ε−kx. Therefore,/summationtext
i∈Episi≥/summationtext
i∈Ep∗
isi−k√ε.
2. If/summationtextn
i=1si≥kand/summationtextn
i=1ˆsi≥k, thenp∗
i= max{0,si−x}andpi= max{0,ˆsi−y}. Thus,si−x<√ε.
Furthermore, both solutions assign zero probability to candidates with si−x<−ε. As a result, all
individuals in Ewhosesi−x>−ε, havesiwithin an interval of length√ε+ε. Similarly to case
1, we have that/summationtext
i∈Episi≥/summationtext
i∈Ep∗
isi−k(√ε+ε).
If we split the linear utility to the utility of individuals in Eand not in E, we see that
n/summationdisplay
i=1pisi=/summationdisplay
i/∈Episi+/summationdisplay
i∈Episi≥(1−√ε)/summationdisplay
i/∈Ep∗
isi+/summationdisplay
i∈Ep∗
isi−k(ε+√ε)≥n/summationdisplay
i=1p∗
isi−k(ε+ 2√ε)
B.4 Proof of Theorem 3.2
Theorem 3.2. For any classiﬁer Cthat assigns scores s1,...,sntoncandidates, Algorithm 2 solves the
onlineε-approximate fairness-preserving cohort selection problem for any ε∈(0,1]by selecting a cohort
of sizekwith marginal probabilities p1,...,pn, achieves linear utility/summationtextn
i=1pisi≥/summationtextn
i=1p∗
isi−k(ε+ 2√ε)
(wherep∗
1,...,p∗
nis the optimal solution for the oﬄine fairness-preserving problem for input s1,...,sn), and
keeps at most O(k+1
ε)candidates pending.
Proof.We want to prove that Algorithm 2 and the algorithm described in Lemma 3.1 compute the same
solution. In other words, we show that the probability pithat individual iis selected by Algorithm 2 is equal
to the probability qithatiis selected by Algorithm 1 applied to the modiﬁed individual scores ˆs1,..., ˆsn,
where ˆsi=gεifsi∈((g−1)ε,gε]. The ﬁrst step is to prove that the scores ˜s1,˜s2,..., ˜snwhich are the
input of the ﬁnal rounding in line 28 satisfy the following properties:
1./summationtextn
i=1˜si=k
2.E[˜si] =qi,∀i∈[n].
We saw in the proof of Theorem 3.1 that for the oﬄine algorithm all candidates of the same group have
the same selection probability qi. We will show that for any person iwe haveqi=sg, wheresgis the ﬁnal
calculated probability of any member of group gto whichibelongs. The sgwe are referring to is calculated
by the ﬁnal execution of lines 6-22. These lines of Algorithm 2 describe the same procedure as lines 2-15 of
Algorithm 1, but from the point of view of groups instead of individual candidates. We consider three cases
that depend on the value of the sum of scores from C.
Case 1:/summationtextn
i=1ˆsi=k. The oﬄine algorithm considers the scores as selection probabilities and, thus, assigns
probability qi= ˆsi=gεto candidate iof groupg. Similarly, Algorithm 2 assigns probability sg=gεto
groupgand in line 27 sets ˜si=nisg=nigε=niqifor the people who have not been rejected.
18Published in Transactions on Machine Learning Research (09/2023)
Case 2:/summationtextn
i=1ˆsi< k. The process that calculates sgstarts by setting sg=gε+c. The oﬄine algorithm
initializes the probability of iwho is a member of gasqi= ˆsi+c=gε+c. If for all groups g,gε+c≤1, then
the adjustment stops for both algorithms and we have that for any group g, any member iofghasqi=sg.
If there exists gsuch thatqi>1, then the corresponding sgexceeds 1by the same amount. Additionally,
at this point the probabilities of all people in the same group as iwill exceed 1by this amount. Therefore,
then<1of the two algorithms is the same. The oﬄine algorithm runs the loop for all members of all groups
that have individuals with qi>1. The online version aggregates the excess mass from all ngmembers of
groupgand redistributes it all at once instead of running separate iterations for every member of the group
as the oﬄine does. No extra mass is added after the initialization but it is only moved from group to group.
Hence, we obtain that at the end of this process qi=sg.
Case 3:/summationtextn
i=1ˆsi>k. Similar to case 2, if candidate iis a member of group g, thenqi=sg. Those who were
rejected have ˜si= 0andni= 0. As a result, we see that for any person i,˜si=niqi. From this we can infer
that
n/summationdisplay
i=1˜si=n/summationdisplay
i=1niqi=m/summationdisplay
g=0/summationdisplay
i∈gnisg=m/summationdisplay
g=0ngsg=m/summationdisplay
g=0/summationdisplay
i∈gqi=k.
As new people are added to the groups, the group probabilities sgbecome smaller in order for the sum of
probabilities ngsgto be equal to k. Therefore, the maximum number vof people that can be represented
by a candidate in a given group either stays the same or increases after every iteration. By Lemma 2.2,
we obtain that the rounding process maintains the expected value of the number of people each candidate
represents equal to their initial value. Since every person begins by representing only themselves, we have
that for the i-th candidate E[ni] = 1. Finally, we obtain E[ˆsi] =E[niqi] =E[ni]qi=qi, because the
calculation of sgs is deterministic. The ﬁnal rounding procedure makes the ﬁnal decisions and outputs 0if
the candidate is rejected and 1if the candidate is selected. Due to properties 1 and 2, the probability of
candidateibeing selected by the online algorithm is qi. Thus, Algorithm 2 and the oﬄine algorithm with
input scores rounded to multiples of εhave the same selection probabilities. By Lemma 3.1, Algorithm 2
preserves fairness ε-approximately and achieves linear utility/summationtextn
i=1pisi≥/summationtextn
i=1p∗
isi−k(ε+ 2√ε), where
p∗
1,...,p∗
nis the optimal solution for the oﬄine fairness-preserving problem for input s1,...,sn.
Because of the online probability adjustments, we have that for n≥kthe sum of all the probabilities is
equal tokat the end of each loop. Therefore, we have/summationtextm
g=0ngsg=k. Ifsf>0, each person can represent
at most⌊1
sg⌋candidates. By Lemma 2, the number of representatives per group is at most
/ceilingleftbiggng
⌊1
sg⌋/ceilingrightbigg
≤ng
⌊1
sg⌋+ 1≤2ngsg+ 1,
sinceng
⌊1
sg⌋≤2ngsg. If we sum up the number of representatives for all groups we obtain
m/summationdisplay
g=0/ceilingleftBigg
ng
/floorleftbig1
sg/floorrightbig/ceilingrightBigg
≤m/summationdisplay
g=0(2ngsg+ 1) = 2k+/ceilingleftbigg1
ε/ceilingrightbigg
+ 1.
This completes the proof.
B.5 Proof of Corollary 3.2
Corollary 3.2. IfCis individually fair, then Algorithm 2 is ε-individually fair.
Proof.If the individual probabilities of selection by Care individually fair with respect to a metric D, we
obtain that∀i,j∈[n]
|pi−pj|≤|si−sj|+ε≤D(i,j) +ε.
19Published in Transactions on Machine Learning Research (09/2023)
C Proofs from Section 4
C.1 Proof of Lemma 4.1
Lemma 4.1. Ifsum<k , Algorithm 3 increases each input score sito a ﬁnal output pi=si+αi≥sisuch
that all of the candidates jwithpj<1receive the same cumulative adjustment value αj=v.
Proof.First we observe that pi≥si,∀i. At each step of the algorithm the value of pieither increases, or is
clipped at 1. Sincesi∈[0,1],∀i, we therefore know that pi≥si.
Algorithm 3 initially adds a constant amount cto every candidate, then repeatedly redistributes overﬂow
evenlyacrossallcandidateswith si+αi<1. Weprovebyinductionthatforallcandidates iwithpi<1, their
incrementαiare the same. Consider two candidates i,jsuch that their ﬁnal pi,pj<1. As argued above,
bothpi,pjare smaller than 1throughout the execution of the algorithm. At the beginning, αi=αj=cso
the claim holds.
Given that these candidates are equal at a certain step d, we also know they will remain equal at the next
stepd+ 1. By assumption, neither candidate reaches 1on either of these steps; therefore they will both
receive an adjustment. When an adjustment is made, all candidates are aﬀected equally.
C.2 Proof of Theorem 4.1
Theorem 4.1. For any classiﬁer Cthat assigns scores s1,...,sntoncandidates, Algorithm 3 solves the
fairness-preserving cohort selection problem by selecting kcandidates with marginal probabilities p1,...,pn
that achieve the optimal value of ratio utility minipi
si.
Proof.We ﬁrst show that Algorithm 3 either preserves or decreases the diﬀerence between any pair of
individuals. Let pidenote the probability that candidate iis selected by Algorithm 3. Thus we must show,
for alli,j,|pi−pj|≤|si−sj|. We apply Algorithm 3 to a set of candidates and obtain two disjoint sets
of output candidates: let T(=1)be the set of candidates whose output pi= 1, and letT(<1)be the set of
candidates whose output pi<1. LetTallbe the union of these two disjoint sets. The algorithm behaves
diﬀerently depending on the value of/summationtext
isi.
1. First, consider when/summationtext
isi<k. Letαibe the cumulative adjustment received by candidate iduring
the algorithm. The adjustments are exactly chosen such that/summationtext
i(si+αi) =k. Then we apply
round-pr , where we know by Lemma 2.2 that the probability of being selected is preserved during
rounding Pr[round-pr selectsi] =pi=si+αiWe thus need to cover three cases:
(a) First, we consider two elements si,sj∈T(=1),|pi−pj|=|1−1|≤|si−sj|.
(b) Next, we have si,sj∈T(<1)By Lemma 4.1, these candidates all receive the same adjustment.
Let this adjustment be called b,|pi−pj|=|si+b−(sj+b)|=|si−sj|.
(c) Finally we have si∈T(=1),sj∈T(<1). Note that αi≤αj, andsi>sj. We see that|pi−pj|=
|si+αi−(sj+αj)|=|si−sj+αi−αj|≤|si−sj|.
2. Next, consider/summationtext
isi≥k. Here we knowk/summationtext
isi≤1. By Lemma 2.2, pi=k/summationtext
lslsi. Then, for
candidates iandj, we have:
|pi−pj|=/vextendsingle/vextendsingle/vextendsingle/vextendsinglek/summationtext
lslsi−k/summationtext
lslsj/vextendsingle/vextendsingle/vextendsingle/vextendsingle=/vextendsingle/vextendsingle/vextendsingle/vextendsinglek/summationtext
lsl(si−sj)/vextendsingle/vextendsingle/vextendsingle/vextendsingle≤|si−sj|
Thus we see that |si−sj|≥|pi−pj|.
We next show that among fairness-preserving solutions to the cohort selection problem, Algorithm 3 achieves
the maximum value of minipi
si. LetT(<1)andT(=1)be deﬁned as above, and note that T(=1)may be empty.
Consider for contradiction an arbitrary algorithm A/primewith probabilities of selection p/prime
iwhich also preserves
fairness while achieving better utility: minip/prime
i
si>minipi
si.
20Published in Transactions on Machine Learning Research (09/2023)
1. First, consider the case where/summationtext
isi< kandT(=1)is nonempty. Let individual jhave the most
extreme ratio:pj
sj= minipi
si. Consider how to make this ratio minimal. For all individuals in T(<1),
increasingsiwill reduce this ratio:pi
si=si+b
si= 1 +b
si. If any individuals jare inT(=1), they will
have received some adjustment αj≤b, and thus they will have an even smaller ratio. Therefore,
we know that individual jmust havesj≥si,∀iand be a member of T(=1), and we have that for
AlgorithmA,minipi
si=pj
sj=1
sj.
By our deﬁnition of A/prime, there is some potentially diﬀerent most extreme element lproviding better
utility:p/prime
l
sl= minip/prime
i
si>pj
sj.
(a) Ifsl=sj, the largest minimum ratiop/prime
l
slthatA/primecan achieve is1
sl=1
sj, which is the same ratio
as Algorithm A and contradicts our assumption.
(b) Ifsl/negationslash=sj, we knowsl<sj, since we already know that sjis at least as big as all other elements.
Sincepjis1, we know thatpj
sj≥p/prime
j
sj>p/prime
l
sl. This contradicts our assumption that A/primehas greater
utility than A.
2. Next, consider the case where/summationtext
isi< kandT(=1)group is empty. Again, let element jbe the
most extreme element for algorithm A, i.e. minipi
si=pj
sj. Consider A/primeon its most extreme element
lconstructed as in Item 1.
(a) This time, if sl=sj, we may have p/prime
l>pl, achieving greater utility. To preserve the distances,
ifA/primeadjusts element lby a certain amount, it must adjust all smaller elements by at least the
same amount. However, we know that/summationtext
ipi=k, so this required extra adjustment will mean
that/summationtext
ip/prime
i>k, andA/primewill not be selecting exactly kcandidates.
(b) Ifsl< sj, then person jhas the largest score, and similar to (2a), if p/prime
j> pjwe see that/summationtext
ip/prime
i>k. Ifp/prime
j≤pjwe have the contradiction in (1b).
3. Finally, consider the case where/summationtext
isi≥k. In Algorithm 3, all elements will be multiplied by
a factor ofk/summationtext
isi, and then by Lemma 2.2, any element will satisfy pi=k/summationtext
lslsi, so we have
minipi/si= mini/parenleftbigg
k/summationtext
lslsi/parenrightbigg
/si=k/summationtext
isiNotice that in this case, all elements are adjusted by
the same constant ratio. Using extreme element lfor algorithm A/primeas constructed previously, and
again supposing that this element is more extreme than any element in algorithm A, we derive that
p/prime
l> slk/summationtext
isi. Since element lwas the minimum ratio for algorithm A/prime, it follows that for all i,
p/prime
i>si/parenleftbigg
k/summationtext
isi/parenrightbigg
. Taking the sum on both sides we see/summationtext
ip/prime
i>/summationtext
isi/parenleftbigg
k/summationtext
isi/parenrightbigg
=k. As before, the
number of elements chosen by algorithm A/primewill be more than k, which is a contradiction.
Thus we conclude that A/primecannot exist.
C.3 Proof of Corollary 4.1
Corollary 4.1. IfCis individually fair, then Algorithm 3 is individually fair.
Proof.The proof is analogous to that of Corollary 3.1.
C.4 Proof of Theorem 4.2
Theorem 4.2. For any classiﬁer Cthat assigns scores s1,...,sntoncandidates, Algorithm 4 solves the
fairness-preserving cohort selection problem by selecting kcandidates with marginal probabilities p1,...,pn
that achieve the optimal value of ratio utility. The algorithm leaves no more than O(k)candidates pending
at any time.
21Published in Transactions on Machine Learning Research (09/2023)
Proof.We ﬁrst show that, for a list of candidate scores s1,...,sn, the selection probability given by the
oﬄine Algorithm 3 for any candidate iis the same as that given by Algorithm 4, and therefore provides
an optimal utility solution to the problem. Let Algorithm 4 be denoted Aand letAhave probability pi
of selecting candidate i. Let Algorithm 3 be denoted Bwith probability qiselecting candidate i.Anever
accepts candidates until the end of the stream, thus there are two major cases.
1. The stream ends with sum ≥k, andAselects all candidates in pending . A candidate iis added to
pending in one of three ways:
(a) Candidate iwas in topwhen the sum reached k. At each round after the sum exceeded k,
they must survive round-pr , which by Lemma 2.2 always preserves their marginal probability.
Therefore we only need to consider the eﬀect of the incremental scaling adjustments. First, let
scalet, sumt, and incr t, represent the values of these variables at some step twhen the sum ﬁrst
exceedsk. We initialized scale t←k
sumt. Consider the value of scale t+1:
scalet+1=incrt·scalet=sumt+1−st+1
sumt+1·scalet=sumt
sumt+1·k
sumt=k
sumt+1
Thus, we can see by induction that for all time steps t, scalet=k
sumt. Furthermore, we can
express the ﬁnal value of a single element si, which by deﬁnition is at position iin the stream,
as:
pi=si·scalei·n/productdisplay
t=i+1incrt=si·k
sumi·n/productdisplay
t=i+1sumt−st
sumt
=si·k
sumi·n/productdisplay
t=i+1sumt−1
sumt=si·k
sumn
Thus we see that the ﬁnal piis adjusted exactly the same way as it would be in the oﬄine case.
(b) Candidate iwas already in restor arrived at the moment when the sum reached k. For each
iteration, they must survive round-pr , which respects their marginal by Lemma 2.2. From that
point forward, they are part of pending and treated the same as in 1a.
(c) Candidate iwas encountered when sum ≥k. In this case, they are treated the same as in part
1a above.
In either case, when Aends, a subset of candidates are selected from pending using round-pr , which
again preserves their marginal probability. Thus pi=qiin these cases.
2. The stream ends with sum < k.Ahas three sets at this point: top(the greatest⌈k/α⌉elements
of the stream), rest(at most⌈k/α⌉elements rounded to 1−α) and rand(a randomly selected
group ofkcandidates, disjoint from topandrest).
No acceptances are made until the stream ends. The top candidates are placed into top, and
elements are added to restviaround-pr , which preserves original marginal probabilities exactly
by Lemma 2.2. The only change in probabilities then comes from the additive adjustments made
when the stream ends. The main diﬀerence between the additive adjustments here and the water-
ﬁlling behavior in Bis how we treat the people in rand.
For the purpose of proof, consider a conceptual algorithm A/primethat behaves exactly the same as A,
except instead of randit has zeros, a list of all candidates outside of topandrest. When this
conceptual algorithm ends, all the mass from water-ﬁlling in zeroswill be collected into a set of k
random candidates, which becomes the equivalent of the list randinA.
In more detail, at the end of A/prime, each member of top,rest, and zerosis givenk−sum
n, and
any overﬂow is redistributed using water-ﬁlling. Any candidate inow has the same probability of
selection by both A/primeandB:si+αi.A/primethen performs a ﬁnal round-pr step to select the outputs.
Thus, inA/prime,top,rest, and zerosare given the same treatment they would receive in B. Before
the ﬁnal step of selecting candidates by round-pr ,A/primecollects all of the mass accumulated in zeros
22Published in Transactions on Machine Learning Research (09/2023)
from water-ﬁlling into a random subset of kmembers from zeros. Thus the only diﬀerence between
AandA/primeis that,A/primeﬁrst kept everyone and later uniformly sampled a subset of kpeople, whereas
Aimmediately keeps a random subset of k. This subsampling step does not change the marginal
probabilities of any element in zeros; their probability before and after collecting the mass of zeros
At the end,Aselects candidates using round-pr on the entire set top∪rest∪rand, which does
not aﬀect the adjusted marginals si+αi. Thuspi=si+αi=qi∀i.
Next, we show that the algorithm keeps at most O(k)candidates pending. Any candidate not in one of:
top,rest,rand,pending is considered rejected. The sizes of topandrandare explicitly bounded by
⌈k/α⌉.restis not bounded in size explicitly, but note that the set is maintained by constantly applying
round-pr ({pi}i∈rest,1−α). After rounding, at most 1person in resthas a value <(1−α). If we
ever have more than ⌈k/(1−α)⌉elements, we have sum≥⌈k/(1−α)⌉(1−α)> k. This goes to the
sum≥kcase, which no longer adds elements to rest, thus it is bounded in length by ⌈k/(1−α)⌉.pending
is created initially by adding topandrest(⌈k/(1−α)⌉+⌈k/α⌉pending), but for subsequent steps is
never longer than kby Lemma 2.2. Thus the worst we can do is remain under a sum of k for the entire
stream. top,rest, and randwill all be kept pending until the end of the stream, but still we have at most
⌈k/α⌉+⌈k/(1−α)⌉+⌈k/α⌉=O(k)candidates pending.
C.5 Proof of Corollary 4.2
Corollary 4.2. IfCis individually fair, then Algorithm 4 is individually fair.
Proof.The proof is analogous to that of Corollary 4.1.
23