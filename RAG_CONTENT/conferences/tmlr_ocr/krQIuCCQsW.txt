Under review as submission to TMLR
Test-time recalibration of conformal predictors under distri-
bution shift based on unlabeled examples
Anonymous authors
Paper under double-blind review
Abstract
Modern image classifiers are very accurate, but the predictions come without uncertainty
estimates. Conformal predictors provide uncertainty estimates by computing a set of
classes containing the correct class with a user-specified probability based on the classifier’s
probability estimates. To provide such sets, conformal predictors often estimate a cutoff
threshold for the probability estimates based on a calibration set. Conformal predictors
guarantee reliability only when the calibration set is from the same distribution as the test set.
Therefore, conformal predictors need to be recalibrated for new distributions. However, in
practice, labeled data from new distributions is rarely available, making calibration infeasible.
In this work, we consider the problem of predicting the cutoff threshold for a new distribution
based on unlabeled examples. While it is impossible in general to guarantee reliability
when calibrating based on unlabeled examples, we propose a method that provides excellent
uncertainty estimates under natural distribution shifts, and provably works for a specific
model of a distribution shift.
1 Introduction
Consider a (black-box) image classifier, typically a deep neural network with a softmax layer at the end, that
is trained to output probability estimates for Lclasses given an input feature vector x∈Rd. Conformal
predictors are wrapped around such a classifier and generate a set of classes that contains the correct label
with a user-specified probability based on the classifier’s probability estimates.
Letx∈Rdbe a feature vector with associated label y∈{1,...,L}. We say that a set-valued function C
generates valid prediction sets for the distribution Pif
P(x,y)∼P[y∈C(x)]≥1−α, (1)
where 1−αis the desired coverage level. Conformal predictors generate valid sets Cfor the distribution P
by utilizing a calibration set consisting of labeled examples {(x1,y1),..., (xn,yn)}. An important caveat of
conformal predictors is that the examples from the calibration set are drawn from the same distribution as
the test dataset.
This assumption is difficult to satisfy in applications and potentially limits the applicability of conformal
prediction methods in practice. In fact, in practice one usually expects a distribution shift between the
calibration set and the examples at inference (or the test set), in which case the coverage guarantees provided
by conformal prediction methods are void. For example, the new ImageNetV2 test set was created in the
same way as the original ImageNet test sets, yet Recht et al. (2019) found a notable drop in classification
accuracy for all classifiers considered.
Ideally, a conformal predictor is recalibrated on a distribution before testing, otherwise the coverage guarantees
are not valid (Cauchois et al., 2020). However, in real-world applications, where distribution shifts are
ubiquitous, labeled data from new distributions is scarce or non-existent.
We therefore consider the problem of recalibrating a conformal predictor only based on unlabeled data from
the new domain. This is an ill-posed problem: it is in general impossible to calibrate a conformal predictor
1Under review as submission to TMLR
based on unlabeled data. Yet, we propose a simple calibration method that gives excellent performance for a
variety of natural distribution shifts.
Organization and contributions. We start with concrete examples on how conformal predictors yield
miscalibrated uncertainty estimates under natural distribution shifts. We next propose a simple recalibration
method that only uses unlabeled examples from the target distribution. We show that our method correctly
recalibrates a popular conformal predictor (Sadinle et al., 2019) on a theoretical toy model. We provide
empirical results for various natural distribution shifts of ImageNet showing that recalibrating conformal
predictors using our proposed method significantly reduces the performance gap. In certain cases, it even
achieves near oracle-level coverage.
Related work. Several works have considered the robustness of conformal prediction to distribution shift
(Tibshirani et al., 2019; Gibbs & Candes, 2021; Park et al., 2022; Barber et al., 2023; Prinster et al., 2022;
2023; Gibbs & Candès, 2023; Fannjiang et al., 2022). Gibbs & Candes (2021); Gibbs & Candès (2023) consider
a setting where the distribution varies over time and propose an adaptive conformal prediction method
to guarantee asymptotic and local coverage. Similarly, Barber et al. (2023) propose a weighted conformal
prediction method to provably generalize to the case where distribution changes over time. On the other
hand, Prinster et al. (2022; 2023) propose a weighted uncertainty quantification based on the jackknife+
method rather than the typical conformal prediction methods that we consider in this paper.
Particularly of interest, Tibshirani et al. (2019) and Park et al. (2022) propose methods that assume a
covariate shift and calibrate based on estimating the amount of covariate shift, we compare to those later in
Section 5.2. Podkopaev & Ramdas (2021) studies the related, but discrete setting of label shifts between
the source and target domains and proposes a method that is more robust under the label shift setting. In
contrast, we focus on complex image datasets for which covariate shift is not well defined and label shift not
broadly relevant.
We are not aware of other works studying calibration of conformal predictors under distribution shift based on
unlabeled examples. However, prior works propose to make conformal predictors robust to various distribution
shifts from the source distribution of the calibration set (Cauchois et al., 2020; Gendler et al., 2022), via
calibrating the conformal predictor to achieve a desired coverage in the worse case scenario of the considered
distribution shifts. Cauchois et al. (2020) considers covariate shifts and calibrates the conformal predictor
to achieve coverage for the worst-case distribution within the f-divergence ball of the source distribution.
Gendler et al. (2022) considers adversarial perturbations as distribution shifts and calibrates a conformal
predictor to achieve coverage for the worst-case distribution obtained through ℓ2-norm bounded adversarial
noise.
While making the conformal predictor robust to a range of worst-case distributions at calibration time
allows maintaining coverage under the worst-case distributions, these approaches have two shortcomings:
First, natural distribution shifts are difficult to capture mathematically, and models like covariate-shifts or
adversarial perturbations do not seem to model natural distribution shifts (such as that from ImageNet
to ImageNetV2) accurately. Second, calibrating for a worst-case scenario results in an overly conservative
conformal predictor that tends to yield much higher coverage than desired for test distributions that correspond
to a less severe shift from the source, which comes at the cost of reduced efficiency (i.e., larger set size,
or larger confidence interval length). In contrast, our method does not compromise the efficiency of the
conformal predictor on easier distributions as we recalibrate the conformal predictor for any new dataset.
A related problem is to predict the accuracy of a classifier on new distributions from unlabeled data sampled
from a new distribution (Deng & Zheng, 2021; Chen et al., 2021; Jiang et al., 2022; Deng et al., 2021; Guillory
et al., 2021; Garg et al., 2022). In particular, Garg et al. (2022) proposed a simple method that achieves
state-of-the-art performance in predicting classifier accuracy across a range of distributions. However, the
calibration problem we consider is fundamentally different than estimating the accuracy of a classifier. While
predicting the accuracy of the classifier would allow making informed decisions on whether to use the classifier
for a new distribution, it doesn’t provide a solution for recalibration.
2Under review as submission to TMLR
2 Background on conformal prediction
Consider a black-box classifier with input feature vector x∈Rdthat outputs a probability estimate
πℓ(x)∈[0,1]for each class ℓ= 1,...,L. Typically, the classifier is a neural network trained on some
distribution, and the probability estimates are the softmax outputs. We denote the order statistics of the
probability estimates by π(1)(x)≥π(2)(x)≥...≥π(L)(x).
Many conformal predictors use a calibration set DP
cal={(xi,yi)}n
i=1to find a cutoff threshold (Sadinle
et al., 2019; Romano et al., 2020; Angelopoulos et al., 2020; Bates et al., 2021) that achieves the desired
empirical coverage on this set. Here, the superscript Pdenotes the distribution from which the examples in
the calibration set are sampled from. Given a set-valued function C(x,u,τ)⊂{1,...,L}containing the set of
predicted classes by the conformal predictor, such conformal predictors compute the threshold parameter τas
τ∗= inf{τ:|{i:yi∈C(xi,ui,τ)}|≥ (1−α)(n+ 1)}, (2)
whereuiis added randomization to smoothen the cardinality term, chosen independently and uniformly from
the interval [0,1], see Vovk et al. (2005) on smoothed conformal predictors. Finally, the ‘ +1’ term in the
(n+ 1)term is a bias correction for the finite size of the calibration set.
This conformal calibration procedure achieves distributional coverage as defined in the expression (1),
for any set valued function C(x,u,τ)satisfying the nesting property C(x,u,τ 1)⊆C(x,u,τ 2)forτ1< τ2,
see (Angelopoulos et al., 2020, Thm. 1).
In this paper, we primarily focus on the popular conformal predictors Thresholded Prediction Sets
(TPS) (Sadinle et al., 2019) and Adaptive Prediction Sets (APS) (Romano et al., 2020). The set gen-
erating functions of the two conformal predictors are
CTPS(x,τ) ={ℓ= 1,...,L :πℓ(x)≥1−τ}, (3)
CAPS(x,u,τ) ={ℓ= 1,...,L :ℓ−1/summationdisplay
j=1π(j)(x) +u·π(ℓ)(x)≤τ}, (4)
withu∼U(0,1)for smoothing. The set generating function of TPS doesn’t require smoothing since each
softmax score is independently thresholded and therefore there are no discrete jumps.
Computingthethreshold τthroughconformalcalibration (2)requiresalabeledcalibrationsetfromdistribution
P. We therefore add a superscript to the threshold to designate which distribution the calibration set was
sampled from; for example τPindicates that the calibration set was sampled from the distribution P. The
prediction set function CTPSfor TPS andCAPSfor APS both satisfy the nesting property. Therefore, TPS
and APS calibrated on a calibration set DP
calby computing the threshold in the expression (2)is guaranteed
to achieve coverage on the distribution P. However, coverage is only guaranteed if the test distribution Qis
the same as the calibration distribution P.
3 Failures under distribution shifts and problem statement
Often we are most interested in quantifying uncertainty with conformal prediction when we apply a classifier
to new data that might come from a slightly different distribution than the distribution we calibrated on.
Yet, conformal predictors only provide coverage guarantees for data coming from the same distribution as the
calibration set, and the coverage guarantees often fail even under slight distribution shifts. For example, our
experiments (see Figure 3) show that APS calibrated on ImageNet-Val to yield 1−α= 0.9coverage only
achieves a coverage of 0.64on the ImageNet-Sketch dataset, which consists of sketches of the ImageNet-Val
images and hence constitutes a distribution shift (Wang et al., 2019).
Different conformal predictors typically have different coverage gaps under the same distribution shift. More
efficient conformal predictors (i.e., those that produce smaller prediction sets) tend to have a larger coverage
gap under a distribution shift. For example, both TPS and RAPS (a generalization of APS proposed
by Angelopoulos et al. (2020)) yield smaller confidence sets, but only achieve a coverage of 0.38vs.0.64for
APS on the ImageNet-Sketch distribution shift discussed above.
3Under review as submission to TMLR
DP
αConformal
calibration
τP
αx∼Q
Conformal
inferenceC(x,τP
α)QTC
DQ
tst
αQTC
quantileq(DQ,α)DP
QTC
estimate
ˆβConformal
calibration
ˆτQ
αx∼Q
Conformal
inferenceC(x,ˆτQ
α)
Figure 1: Left: Vanilla conformal prediction. Right: QTC recalibration. QTC encapsulates the conformal
calibration process to recalibrate the conformal predictor for each new distribution without altering the
underlying set generating function. DQ
tstis the unlabeled test set and DPis the labeled training/calibration
set. QTC finds a threshold on the scores of the model on the unlabeled samples and predicts the coverage
level by utilizing how the distribution of the scores changes across test distribution with respect to this
threshold.
Even under more subtle distribution shifts such as subpopulation shifts (Santurkar et al., 2021), the achieved
coverage can drop significantly. For example, APS calibrated to yield 1−α= 0.9coverage on the source
distribution of the Living-17 BREEDS dataset only achieves a coverage of 0.68on the target distribution.
The source and target distributions contain images of exclusively different breeds of animals while the animals’
species is shared as the label (Santurkar et al., 2021).
Problem statement. Our goal is to recalibrate a conformal predictor on a new distribution Qbased
on unlabeled data. Given an unlabeled dataset DQ
tst={x1,...,xn}sampled from the target distribution
Q, our goal is to provide an accurate estimate ˆτQfor the threshold τQ. Recall that the threshold τQis
so that the conformal predictor with set function C(x,u,τQ)achieves the desired coverage of 1−αon the
target distribution Q. Thus, in other words, our goal is to estimate a threshold ˆτQso that the setC(x,u,ˆτQ)
achieves close to the desired coverage of 1−αon the target distribution, based on the unlabeled dataset only.
In general, it is impossible to guarantee coverage since conformal prediction relies on exchangeability
assumptions which can not be guaranteed in practice for new datasets (Vovk et al., 2005; Romano et al.,
2020; Angelopoulos et al., 2020; Cauchois et al., 2020; Bates et al., 2021). However, we will see that we can
consistently estimate the threshold τQfor a variety of natural distribution shifts.
We refer to the difference between the target coverage of 1−αand the actual coverage achieved on a given
distribution without any recalibration efforts as the coverage gap . We assess how effective a recalibration
method is based on the reduction of the coverage gap after recalibration.
4 Methods
In this section we introduce our calibration method, termed Quantile Thresholded Confidence (QTC), along
with baseline methods we consider in our experiments.
4.1 Quantile thresholded confidence
Consider a conformal predictor with threshold τP
αcalibrated so that the conformal predictor achieves coverage
1−αon the source distribution P. On a different distribution Qthe coverage of the conformal predictor
is off. But there is a value βsuch that, if we calibrate the conformal predictor on the source distribution
using the value βinstead ofα, it achieves 1−αcoverage on the target distribution , i.e., the corresponding
thresholds obey τP
β=τQ
α.
Our method first estimates the value βbased on unlabeled examples. From the estimate ˆβ, we estimate τQ
α
based on computing the threshold τP
ˆβby calibrating the conformal predictor on the source calibration set
using ˆβ. This yields a threshold close to the desired one, i.e., τP
ˆβ≈τQ
α.
4Under review as submission to TMLR
Step 1, estimation of β:We are given a labeled source dataset DP
caland an unlabeled target dataset DQ
tst.
Our estimate of βrelies on the quantile function
q(D,c) = inf/braceleftigg
p:1
|D|/summationdisplay
x∈D1{s(π(x))<p}≥c/bracerightigg
. (5)
The quantile function depends on the classifier’s predictions through a score function s(π(x)) = maxℓπℓ(x),
which we take as the largest softmax score of the classifier’s predictions. Here, Dis a set of unlabeled examples
andc∈[0,1]is a scalar. Our method first identifies a threshold based on the unlabeled target dataset DQ
tst
for a desired coverage level αin expression (5)by computing q(DQ
tst,α). Since this process is identical to
finding the (α)thquantile of the scores on the dataset, we dub the method Quantile Thresholded Confidence
(QTC). QTC estimates βas
βQTC = min(βQTC−T,βQTC−S), (6)
where the QTC-Target and QTC-Source estimates are
βQTC−T(DQ
tst) =1
|DP
cal|/summationdisplay
x∈DP
cal1{s(π(x))<q(DQ
tst,α)}(7)
βQTC−S(DQ
tst) = 1−1
|DQ
tst|/summationdisplay
x∈DQ
tst1{s(π(x))<q(DP
cal,1−α)}. (8)
We consider two estimates for β, and aggregate them to a single value by taking the minimum of the two.
This yields best performance, as demonstrated by studying the three versions of QTC, corresponding to the
three estimates (6), (7), and (8).
The reasons for having two estimates and aggregating them is as follows. DNNs have a tendency to be
over-confident in their predictions (Guo et al., 2017). If the distribution of the softmax scores over the
dataset is not sufficiently smooth in the lower-confidence regime, the QTC-T estimate might be inaccurate.
In this higher-confidence regime QTC-S provides a better estimate. The minimum of the two provides a good
estimate in the high and low confidence regions.
The motivation behind QTC is that we essentially map the quantile function conformal prediction uses, which
relies on the labels, to the quantile function of QTC, which does not require labels. While this mapping is
not guaranteed to be preserved under distribution shift, we have observed that it works very well in practice
and provably works in the theoretical setting that we consider.
If there is no distribution shift between the source and target, QTC would recover the original α. That is,
both the QTC-T and QTC-S estimates of the βwould be asymptotically equal to αand1−αrespectively.
To see this more clearly, note that we can insert the definition of qin(5)in the RHS of the equations (7),(8).
Asn→∞, the sums over the datasets converge to the expectations which are equal when no distribution
shift is present.
Step 2, estimation of the threshold τQ
αbased on β:QTC predicts the conformal threshold τQ
αby
conformal calibration with target value βQTC. Specifically, we calibrate the conformal predictor on the dataset
DP
calas
τQTC = inf/braceleftbig
τ:|{i:yi∈C(xi,ui,τ)}|≥ (1−βQTC)(|DP
cal|+ 1)/bracerightbig
, (9)
which yields the estimate τQTCforτQ
α. QTC is illustrated in Figure 1.
QTC is inspired by a method for predicting a classifier’s accuracy from Garg et al. (2022). Garg et al. (2022)’s
method finds a threshold on the scores matching the accuracy of a classifier on the dataset and predicts the
accuracy on other datasets. Contrary, we predict the threshold of a conformal predictor, and our method is
based on predicting an auxillary parameter βinstead of a threshold directly.
5Under review as submission to TMLR
4.2 Baseline methods
We consider regression-based methods as baselines. Regression-based methods have been used for predicting
classification accuracy, assuming a correlation between the classification accuracy and a feature (e.g., average
confidence) across different distributions (Deng et al., 2021; Deng & Zheng, 2021; Guillory et al., 2021). We
consider regression-based methods as baselines for predicting the conformal threshold on a target distribution
that would achieve 1−αcoverage. We train the regression-based methods on a dataset consisting of
synthetically generated distributions given a source distribution (e.g. ImageNet-C from ImageNet) with the
goal of predicting the conformal threshold for a test dataset sampled from a natural distribution.
Letϕπ(D):RL→Rdbe the feature extractor part of a neural network that maps the softmax scores of the
classifier to the features for a given dataset D. A simple example is the one-dimensional feature ( d= 1)
extracted by computing the average confidence of a given classifier across the examples of a given dataset.
We fit a regression function fθparameterized by different feature extractors ϕπby minimizing the mean
squared error between the output and the calibrated threshold τacross the distributions as
ˆθ= arg min
θ/summationdisplay
j(fθ(ϕπ(Dj))−τPj)2. (10)
We consider the following choices for the feature extractor ϕπ(see App A.1 for details):
•Average confidence regression (ACR) : The average confidence of the classifier across the entire dataset.
•Difference of confidence regression (DCR) (Guillory et al., 2021): The average confidence of the
classifier across the entire dataset offset by the average confidence on the source dataset. Prediction
is also for the offset target τ−τP. DCR performs better than ACR for predicting a classifier’s
accuracy (Guillory et al., 2021).
•Confidence histogram-density regression (CHR) : Normalized histogram density of the classifier
confidence across the dataset, where the feature dimension is controlled by a hyperparameter that
determines the number of histogram bins in the probability range [0,1]. Neural networks tend to be
overconfident in their prediction which heavily skews the histogram densities to the last bin. We also
therefore consider a variant of CHR, dubbed CHR- , where we drop the last bin of the histogram as a
feature.
•Predicted class-wise average confidence regression (PCR) : Class-wise (by predicted class) average
confidence of the classifier across the samples.
5 Experiments
We study the performance of QTC on natural distribution shifts and on an artifical covariate shift.
5.1 Natural distribution shifts
We consider the following choices for the source distribution Pand associated natural distribution shifts:
ImageNet (Deng et al., 2009) distribution shifts: In our ImageNet experiments, ImageNet is the
source distribution Pand the following natural distribution shifts are the target distributions Q:
•ImageNetV2 (Rechtetal.,2019)wasconstructedbyfollowingthesameprocedureasforconstructing
and labeling the original ImageNet dataset. However, all standard models perform significantly worse
on ImageNetV2 relative to the original ImageNet test set.
•ImageNet-Sketch (Wang et al., 2019) contains sketch-like images of the objects in the original
ImageNet, but otherwise matches the original categories and scales.
6Under review as submission to TMLR
ACRCHRCHR-DCRPCR
QTC-TQTC-SQTC0.81
0.88
0.88
0.88
0.87
0.89
0.89
0.88
0.890.9achieved coverageImageNetV2
ACRCHRCHR-DCRPCR
QTC-TQTC-SQTC0.38
0.65
0.61
0.64
0.66
0.47
0.84
0.8
0.840.9ImageNet Sketch
ACRCHRCHR-DCRPCR
QTC-TQTC-SQTC0.34
0.56
0.54
0.54
0.57
0.36
0.73
0.75
0.750.9ImageNet-R
ACRCHRCHR-DCRPCR
QTC-TQTC-SQTC0.61
0.76
0.78
0.78
0.77
0.79
0.81
0.92
0.920.9achieved coverageEntity-13
ACRCHRCHR-DCRPCR
QTC-TQTC-SQTC0.57
0.73
0.75
0.74
0.73
0.74
0.79
0.89
0.890.9Entity-30
ACRCHRCHR-DCRPCR
QTC-TQTC-SQTC0.55
0.7
0.73
0.71
0.7
0.71
0.75
0.93
0.930.9Living-17
Figure 2: Coverage obtained by TPS for a desired coverage of 1−α= 0.9on the target distribution Qafter
recalibration using the unlabeled samples from Qfor various recalibration methods. The dotted line is the
coverage without recalibration, and the dashed line is the target coverage 1−α= 0.9. The figure shows
that QTC-T and QTC-S almost fully close the coverage gap across ImageNet and BREEDS test distribution
shifts, corresponding to varying severities.
0.20.40.60.81achieved coverageImageNetV2, TPS ImageNet-Sketch,TPS ImageNet-R,TPS
0.8 0.9 10.40.60.81
desired coverageachieved coverageImageNetV2, APS
y=x
original
QTC
CHR-
0.8 0.9 1
desired coverageImageNet-Sketch,APS
0.8 0.9 1
desired coverageImageNet-R,APS
Figure 3: Coverage obtained by TPS and APS on the target distribution Qas a function of the desired
coverage (i.e., 1−α) after recalibration with the respective prediction method. For regression methods, only
the best performing method, CHR-, is shown. QTC significantly closes the coverage gap across the range of
1−α, while CHR- yields inconsistent or insufficient performance improvements.
•ImageNet-R (Hendrycks et al., 2021) contains artwork images of the ImageNet class objects found
in the web. ImageNet-R only contains images for a 200-class subset of the original ImageNet. We
don’t limit our experiments to this subset but instead consider the adverse setting of calibrating on all
1000 classes since our main goal is to provide an end-to-end solution for recalibration of the conformal
predictors and we are interested in how well our method performs against possible adversaries such
as dataset imbalance that can be encountered in practice.
7Under review as submission to TMLR
BREEDS (Santurkar et al., 2021) distribution shifts: The BREEDS datasets feature sub-population
shiftsfrom the training set to test. The BREEDS datasets were constructed using the existing ImageNet
images, but with different classes. BREEDS utilizes the hierarchical WordNet structure of the classes to
choose a parent class that makes the original ImageNet classes the leaves. For example, in the BREEDS
Living-17 dataset, one of the classes is domestic cat . This is a parent class of several ImageNet classes, which
aretiger cat, Egyptian cat, Persian cat and Siamese cat . BREEDS induces a subpopulation shift from the
source distribution to the target by assigning these leaf classes to either the source or target. For example,
the images in the source dataset of Living-17 under the domestic cat class are that of either tiger cats or
Egyptian cats , whereas in the target are that of either Persian cats orSiamese cats . Therefore, despite having
the same label ( domestic cat ), the source and target distributions semantically differ due to the differences
between the breeds, which induces a subpopulation shift.
We consider three BREEDS datasets: Entity-13, Entity-30 and Living-17, which are named using the
convention theme/object type –#classes.
Experimental procedure. For the ImageNet experiments we use a ResNet-50 and DenseNet-121 pretrained
on the ImageNet training set. For the BREEDS experiments, we train a ResNet-18 model from scratch for
the BREEDS datasets. In both cases, the classifiers only see examples from the source distribution.
For all experiments, we first calibrate the conformal predictor on the source distribution Pto find the
cutoff threshold τP. For QTC and variants, we find the threshold qusing the expression (5). For the
regression methods, we use the ImageNet-C dataset (Hendrycks & Dietterich, 2019) as the source of synthetic
distributions, find the cutoff threshold τfor each of the distributions, and fit a regressor by minimizing the
loss (10). For the regression function we use a 4-layer MLP with ReLU activations. ImageNet-C consists of
90 different distributions obtained by synthetically perturbing the images of ImageNet-Val for 18 different
types of perturbations at 5 different levels of severity, resulting in 90 distinct distributions.
Recalibration experiments for a fixed target coverage. We first evaluate the recalibration methods
for a fixed target coverage of 1−α= 0.9. The results in Figure 2 for recalibrating TPS show that QTC
reduces the coverage gap much more than regression methods, and even closes it in some cases.
We also display QTC-T and QTC-S as ablation studies. Here it can be seen that sometimes QTC-T and
sometimes QTC-S performs best, which is why combining them is necessary. The different performance of
QTC-T and QTC-S can be attributed to the difference of the type of shifts (e.g. semantic vs. subpopulation)
between ImageNet and BREEDS. Note that QTC-T operates on the regime of samples with lower confidence
whereas QTC-S on the higher confidence regime. Therefore, QTC-T may perform subpar compared to QTC-S
for datasets consisting of fewer, more distinct classes like BREEDS, for which a well-trained classifier tends
to assign high confidence to its predictions.
Recalibration experiments for different target coverage levels. The coverage gap (i.e., the difference
of achieved coverage and targeted coverage) varies across the desired coverage level 1−α. We therefore next
evaluate the performance as a function of the desired coverage level.
Figure 3 shows the coverage obtained after recalibration with TPS and APS for different values of 1−αfor
the natural distribution shifts from ImageNet. QTC closes the coverage gap significantly for all choices of
1−α, whereas the best performing regression-based baseline method, CHR-, fails to significantly improve the
coverage gap consistently across all choices of 1−α.
5.2 Comparison to covariate shift based methods
QTC does not require labeled data from the target distribution at training or inference time. Existing
methods that aim to measure the amount of covariate shift based on unlabeled examples also improve the
robustness of conformal prediction, but rely on labeled examples from the target domain (Tibshirani et al.,
2019; Park et al., 2022). Here, we compare the performance of QTC to that of covariate shift based methods
and show that QTC outperforms the state-of-the-art when labeled data is not available during training, and
performs only marginally worse if labeled data is available.
8Under review as submission to TMLR
0.8 0.9 10.60.81
desired coverage 1−αachieved coverageP=DomainNetAll
0.8 0.9 1
desired coverage 1−αP=DomainNetReal
y=x
original
QTC
PS-W
WSCI
0.8 0.9 1101.5102102.5
desired coverage 1−αavg. set sizeP=DomainNetAll
0.8 0.9 1
desired coverage 1−αP=DomainNetReal
Figure 4: Coverage ( left) and the average set size ( right) obtained by TPS on the target Q=
DomainNet-Infograph for various settings of ( 1−α). For the setting where all domains are available
for the discriminator ( left), WSCI closes the coverage gap while QTC considerably improves it; whereas when
only DomainNet-Real is available, QTC slightly outperforms. In both settings, PS-W fails by constructing
uninformatively large confidence sets for the range 1−α>0.9.
Under a covariate shift, the conditional distribution of the label ygiven the feature vector xis fixed but the
marginal distribution of the feature vectors differ:
source: (x,y)∼P =pP(x)×p(y|x),target: (x,y)∼Q =pQ(x)×p(y|x),
wherepP(x)andpQ(x)are the marginal PDFs of the features x, andp(y|x)is the conditional PDF of the
labely.
In order to account for a covariate shift, Tibshirani et al. (2019); Park et al. (2022) utilize an approach called
weighted conformal calibration . Weighted conformal calibration uses the likelihood ratio of the covariate
distributions, i.e., the importance weights w(x) =pQ(x)/pP(x)to weigh the scores used for the set generating
function of the conformal predictor for each sample (x,y)∈DP
cal. A conformal predictor calibrated on a
source calibration set with the true importance weights for a target distribution is guaranteed to achieve the
desired coverage on the target, see Tibshirani et al. (2019, Cor. 1). In practice, the importance weights are
not known and are therefore estimated heuristically.
Covariate shifts is not well defined for complex tasks such as image classification. We therefore follow
the experimental setup of Park et al. (2022) and consider a backbone ResNet-101 classifier trained using
unsupervised domain adaptation based on training sets sampled from both the source and target distribution
as well as an auxillary classifier (discriminator) gthat yields probability estimates of membership between the
two for a given sample. For the weighted split conformal inference (WSCI) method of Tibshirani et al. (2019),
we estimate the importance weights using this discriminator gand for the PAC prediction sets method of Park
et al. (2022) based on rejection sampling (PS-W), using histogram density estimation over the probability
estimates. We use TPS as the conformal predictor.
We consider the DomainNet distribution shift problem (Peng et al., 2019) and choose DomainNet-Infograph
as the target distribution since the coverage gap is insignificant for the others (see Park et al. (2022, Table 1)).
We consider two scenarios, for both of which all six DomainNet domains, i.e. DomainNet-Sketch, DomainNet-
Clipart, DomainNet-Painting, DomainNet-Quickdraw, DomainNet-Real, and DomainNet-Infograph , are
available during training. In the first scenario all domains are also available at inference, whereas in the
second scenario, analogous to the ImageNet setup, we only have access to the examples from DomainNet-Real
(source) and DomainNet-Infograph (target).
The results in Figure 4 show that when the source includes all the domains, WSCI outperforms other methods.
However, when only DomainNet-Real is available for the source at calibration time, QTC slightly outperforms
WSCI. In both settings, PS-W fails if αis chosen such that 1−α>0.9, by constructing uninformatively large
confidence sets that tend to contain all possible labels. On the other hand, QTC and WSCI tend to construct
similarly sized confidence sets consistently across the range of 1−α. Note that while QTC considerably closes
the coverage gap in both setups, QTC-S fails to improve the coverage gap. This might be due to the fact that
9Under review as submission to TMLR
−2 0 2−11
xinvxspSourceP
−2 0 2
xinvTargetQ
y=−1
y= +1
Figure 5: Example source and target distributions PandQfor the binary classification model, and a
classifier with winv,wsp= 1. The decision boundary is shown with a faded dotted line. The correlation
between the feature xspand the label yis higher for the source than target ( pP>pQ).
ResNet-101 trained with domain adaptation tends to yield very high confidence across all examples. While a
separate discriminator that uses the representations of the ResNet-101 before the fully-connected linear layer
is utilized for the covariate shift based methods, this is not the case for QTC and its variants. Therefore, the
threshold found by QTC-S tends to be very close or even equal to 1.0, hindering the performance.
6 Theoretical results
We consider a simple binary classification distribution shift model from Nagarajan et al. (2021); Garg et al.
(2022), and adapt the analysis from Garg et al. (2022) to show that recalibrating provably succeeds within
this model. Specifically, we show that the conformal predictor TPS with QTC-T yields the desired coverage
of1−αon the target distribution based on unlabeled examples.
The distribution shift model from Nagarajan et al. (2021) is as follows. Consider a binary classification
problem with response y∈{− 1,1}and with two features x= [xinv,xsp]∈R2, an invariant one and a
spuriously correlated one. The source and target distributions PandQover the feature vector and label are
defined as follows. The label yis uniformly distributed over {−1,1}. The invariant fully-predictive feature
xinvis uniformly distributed in an interval determined by the constants c>γ≥0, with the interval being
conditional on y:
xinv|y∼/braceleftigg
U[γ,c]ify= 1
U[−c,−γ]ify=−1. (11)
The spurious feature xspis correlated with the response ysuch that P(x,y)∼P[xsp·y>0]=pP, where
pP∈(0.5,1.0)for some joint distribution P. A distribution shift is modeled by simulating target data with
different degrees of spurious correlation such that P(x,y)∼Q[xsp·y>0]=pQ, wherepQ∈[0,1]. There is a
distribution shift from source to target when pP̸=pQ. Two example distributions PandQare illustrated in
Figure 5.
We consider a logistic regression classifier that predicts class probability estimates for the classes y=−1and
y= 1asf(x) =/bracketleftig
1
1+ewTx,ewTx
1+ewTx/bracketrightig
,where w=[winv,wsp]∈R2. The classifier with winv>0andwsp= 0
minimizes the misclassification error across all choices of distributions PandQ(i.e., across all choices of p).
However, a classifier learned by minimizing the empirical logistic loss via gradient descent depends on both
the invariant feature xinvand the spuriously-correlated feature xsp, i.e.,wsp̸= 0due to the geometric skews
on the finite data and statistical skews of the optimization with finite gradient descent steps (Nagarajan
et al., 2021).
For the logistic regression classifier TPS recalibrated with QTC-T provably suceeds:
Theorem 6.1 (Informal) .Consider the logistic regression classifier for the binary classification problem
described above with winv>0,wsp̸= 0, letnbe the number of samples for the source and target datasets
andα∈(0,ϵ)be a user-defined value, where ϵis the error rate of the classifier on the source. The coverage
achieved on the target by recalibrating TPS on the source with the QTC estimate obtained in (7)by finding
the QTC threshold on the target as in (5)converges to 1−αasn→∞with high probability.
10Under review as submission to TMLR
Regarding the assumption on α: A value of αthat is larger than the error rate of the classifier does make
sense as it would result in empty confidence sets for a portion of the examples in the dataset.
In order to understand the intuition behind Theorem 6.1, we first explain how the coverage is off under a
distribution shift in this model. Consider a classifier that depends positively on the spurious feature (i.e.,
wsp>0). When the spurious correlation is decreased from the source distribution to the target, the error rate
of the classifier increases. TPS calibrated on the source samples finds a threshold τsuch that the prediction
sets yield 1−αcoverage on the source dataset as n→∞. In other words, the fraction of misclassified points
for which the model confidence is larger than the threshold τis equal to αon the source. As the spurious
correlation decreases and the error rate increases from source to target, the fraction of misclassified points
for which the model confidence is larger than the threshold τsurpassesα, leading to a gap in targeted and
actual coverage.
Now, we remark on how QTC recalibrates and ensures the target coverage is met. Note that there exists
an unknown coverage level 1−βthat can be used to calibrate TPS on the source distribution such that it
yields 1−αcoverage on the target. Theorem 6.1 guarantees that QTC correctly estimates βand therefore
recalibration of the conformal predictor using QTC yields the desired coverage level of 1−αon the target.
References
Anastasios Nikolas Angelopoulos, Stephen Bates, Michael Jordan, and Jitendra Malik. Uncertainty sets for
image classifiers using conformal prediction. International Conference on Learning Representations (ICLR) ,
2020.
Rina Foygel Barber, Emmanuel J. Candès, Aaditya Ramdas, and Ryan J. Tibshirani. Conformal prediction
beyond exchangeability. The Annals of Statistics , 2023.
Stephen Bates, Anastasios Angelopoulos, Lihua Lei, Jitendra Malik, and Michael I. Jordan. Distribution-free,
risk-controlling prediction sets. Journal of the ACM , 2021.
Maxime Cauchois, Suyash Gupta, Alnur Ali, and John C. Duchi. Robust validation: Confident predictions
even when distributions shift. arXiv:2008.04267 [cs, stat] , 2020.
Mayee Chen, Karan Goel, and Nimit Sohoni. Mandoline: Model evaluation under distribution shift.
International Conference on Machine Learning (ICML) , 2021.
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-scale hierarchical
image database. Conference on Computer Vision and Pattern Recognition (CVPR) , 2009.
Weijian Deng and Liang Zheng. Are labels always necessary for classifier accuracy evaluation? Conference
on Computer Vision and Pattern Recognition (CVPR) , 2021.
Weijian Deng, Stephen Gould, and Liang Zheng. What does rotation prediction tell us about classifier
accuracy under varying testing environments? International Conference on Machine Learning (ICML) ,
2021.
Clara Fannjiang, Stephen Bates, Anastasios N. Angelopoulos, Jennifer Listgarten, and Michael I. Jordan.
Conformal prediction under feedback covariate shift for biomolecular design. Proceedings of the National
Academy of Sciences , 2022.
Saurabh Garg, Sivaraman Balakrishnan, and Zachary C Lipton. Leveraging unlabeled data to predict
out-of-distribution performance. International Conference on Learning Representations (ICLR) , 2022.
Asaf Gendler, Tsui-Wei Weng, Luca Daniel, and Yaniv Romano. Adversarially robust conformal prediction.
International Conference on Learning Representations (ICLR) , 2022.
Isaac Gibbs and Emmanuel Candes. Adaptive conformal inference under distribution shift. In Advances in
Neural Information Processing Systems (NeurIPS) , 2021.
11Under review as submission to TMLR
Isaac Gibbs and Emmanuel Candès. Conformal inference for online prediction with arbitrary distribution
shifts.arXiv:2208.08401 [cs, stat] , 2023.
Devin Guillory, Vaishaal Shankar, Sayna Ebrahimi, Trevor Darrell, and Ludwig Schmidt. Predicting with
confidence on unseen distributions. IEEE International Conference on Computer Vision (ICCV) , 2021.
Chuan Guo, Geoff Pleiss, Yu Sun, and Kilian Q. Weinberger. On Calibration of Modern Neural Networks. In
International Conference on Machine Learning . PMLR, 2017.
Dan Hendrycks and Thomas Dietterich. Benchmarking neural network robustness to common corruptions
and perturbations. International Conference on Learning Representations (ICLR) , 2019.
Dan Hendrycks, Steven Basart, Norman Mu, Saurav Kadavath, Frank Wang, Evan Dorundo, Rahul Desai,
Tyler Zhu, Samyak Parajuli, Mike Guo, Dawn Song, Jacob Steinhardt, and Justin Gilmer. The many faces
of robustness: A critical analysis of out-of-distribution generalization. IEEE International Conference on
Computer Vision (ICCV) , 2021.
Yiding Jiang, Vaishnavh Nagarajan, Christina Baek, and J. Zico Kolter. Assessing generalization of sgd via
disagreement. International Conference on Learning Representations (ICLR) , 2022.
Jing Lei, Max G’Sell, Alessandro Rinaldo, Ryan J. Tibshirani, and Larry Wasserman. Distribution-Free
Predictive Inference For Regression. Journal of the American Statistical Association (JASA) , 2018.
Vaishnavh Nagarajan, Anders Andreassen, and Behnam Neyshabur. Understanding the failure modes of
out-of-distribution generalization. International Conference on Learning Representations (ICLR) , 2021.
Sangdon Park, Edgar Dobriban, Insup Lee, and Osbert Bastani. Pac prediction sets under covariate shift. In
International Conference on Learning Representations (ICLR) , 2022.
Xingchao Peng, Qinxun Bai, Xide Xia, Zijun Huang, Kate Saenko, and Bo Wang. Moment matching for
multi-source domain adaptation. In IEEE International Conference on Computer Vision (ICCV) , 2019.
Aleksandr Podkopaev and Aaditya Ramdas. Distribution-free uncertainty quantification for classification
under label shift. arXiv:2103.03323 [cs, stat] , 2021.
Drew Prinster, Anqi Liu, and Suchi Saria. Jaws: Auditing predictive uncertainty under covariate shift.
Advances in Neural Information Processing Systems (NeurIPS) , 2022.
Drew Prinster, Suchi Saria, and Anqi Liu. Jaws-x: Addressing efficiency bottlenecks of conformal prediction
under standard and feedback covariate shift. In International Conference on Machine Learning (ICML) ,
2023.
Benjamin Recht, Rebecca Roelofs, Ludwig Schmidt, and Vaishaal Shankar. Do imagenet classifiers generalize
to imagenet? International Conference on Machine Learning (ICML) , 2019.
Yaniv Romano, Matteo Sesia, and Emmanuel J. Candès. Classification with valid and adaptive coverage.
Advances in Neural Information Processing Systems (NeurIPS) , 2020.
Mauricio Sadinle, Jing Lei, and Larry Wasserman. Least ambiguous set-valued classifiers with bounded error
levels.Journal of the American Statistical Association (JASA) , 2019.
Shibani Santurkar, Dimitris Tsipras, and Aleksander Madry. Breeds: Benchmarks for subpopulation shift.
International Conference on Learning Representations (ICLR) , 2021.
Ryan J. Tibshirani, Rina Foygel Barber, Emmanuel J. Candes, and Aaditya Ramdas. Conformal prediction
under covariate shift. Advances in Neural Information Processing Systems (NeurIPS) , 2019.
Vladimir Vovk, A. Gammerman, and Glenn Shafer. Algorithmic learning in a random world . Springer, 2005.
Haohan Wang, Songwei Ge, Eric P Xing, and Zachary C Lipton. Learning robust global representations by
penalizing local predictive power. Advances in Neural Information Processing Systems (NeurIPS) , 2019.
12Under review as submission to TMLR
Appendix
A Proof of Theorem 6.1
In this section, we state and prove a formal version of Theorem 6.1. Our results rely on adapting the proof
idea of Garg et al. (2022, Theorem 3) for predicting the classification accuracy of a model to our conformal
prediction setup.
Recallthatweconsideradistributionshiftmodelforabinaryclassificationproblemwithaninvariantpredictive
feature and a spuriously correlated feature, where a distribution shift is induced by the spurious feature of
the target distribution being more or less correlated with the label than the source distribution (Nagarajan
et al., 2021; Garg et al., 2022).
We consider a logistic regression classifier that outputs class probability estimates (softmax scores) for the
two classes of y=−1andy= +1as
(x) =/bracketleftigg
1
1 +ewTx,ewTx
1 +ewTx/bracketrightigg
,
where w=[winv,wsp]∈R2. The classifier with winv>0andwsp= 0minimizes the misclassification error
across all choices of distributions PandQ(i.e., across all choices of p). However, a classifier learned by
minimizing the empirical logistic loss via gradient descent depends on both the invariant feature xinvand the
spuriously-correlated feature xsp, i.e.,wsp̸= 0due to the geometric skews on the finite data and statistical
skews of the optimization with finite gradient descent steps (Nagarajan et al., 2021).
In order to understand how geometric skews result in learning a classifier that depends on the spurious feature,
suppose the probability that the spurious feature agrees with the label is high, i.e., pis close to 1.0. Note
that in a finite-size training set drawn from this distribution, the fraction of samples for which the spurious
feature disagrees with the label (i.e., xsp̸=y) is small. Therefore, the margin on the invariant feature for
these samples alone can be significantly larger than the actual margin γof the underlying distribution. This
implies that the max-margin classifier depends positively on the spurious feature, i.e., wsp>0. Furthermore,
we assume that winv>0, which is required to obtain non-trivial performance (beating a random guess).
Conformal prediction in the distribution shift model. We consider the conformal prediction method
TPS (Sadinle et al., 2019) applied to the linear classifier described above. While other conformal prediction
methods such as APS and RAPS also work for this model, the smoothing induced by the randomization of
the model scores used in those conformal predictors would introduce additional complexity to the analysis.
TPS also tends to be more efficient in that it yields smaller confidence sets compared to APS and RAPS at
the same coverage level, see (Angelopoulos et al., 2020, Table 9).
In the remaining part of this section, we establish Theorem 6.1, which states that TPS recalibrated on the
source calibration set with QTC achieves the desired coverage of 1−αon any target distribution that has a
(potentially) different correlation probability pfor the spurious feature. We show this in two steps:
First, consider the oracle conformal predictor that is calibrated to achieve αmiscoverage on the target
distribution, i.e., the conformal predictor with threshold τQ
αchosen so that
α= P (x,y)∼Q/bracketleftbig
y /∈C(x,τQ
α)/bracketrightbig
. (12)
Define the miscoverage on the source distribution as
β= P (x,y)∼P/bracketleftbig
y /∈C(x,τQ
α)/bracketrightbig
.
From those two equations, it follows that a conformal predictor calibrated to achieve miscoverage βon the
source distribution Pachieves the desired miscoverage of αon the target distribution, provided that the
calibration sets are sufficiently large, which is assumed as we consider the case of n→∞.
Second, we provide a bound on the deviation of the QTC estimate from the true value of β. We show that
in the infinite sample size case, the QTC estimate converges to the true value of β. Those two steps prove
Theorem 6.1.
13Under review as submission to TMLR
Step 1: QTC relies on the fact that there exists an unknown β∈(0,1)that can be used to calibrate TPS
on the source distribution such that it yields 1−αcoverage on the target.
Here, we show that callibrating to achieve 1−βcoverage on the source calibration set DPvia computing the
threshold (2) achieves 1−αcoverage on the target distribution Qasn→∞.
We utilize the following coverage guarantee of conformal predictors established by Vovk et al. (2005); Lei
et al. (2018); Angelopoulos et al. (2020):
Lemma A.1. (Lei et al., 2018, Thm. 2.2), (Angelopoulos et al., 2020, Thm. 1, Prop. 1) Consider
(xi,yi),i= 1,...,ndrawn iid from some distribution P. LetC(x,τ)be the conformal set generating function
that satisfies the nesting property in τ, i.e.,C(x,τ′)⊆C(x,τ)ifτ′≤τ. Then, the conformal predictor
calibrated by finding τ∗that achieves 1−αcoverage on the finite set {(xi,y)}n
i=1as in(2)achieves 1−α
coverage on distribution P, i.e.,
P(x,y)∼P[y∈C(x,τ∗)]≥1−α. (13)
Furthermore, assume that the variables si=s(xi,yi) =inf{τ:yi∈C(xi,τ)}fori= 1,...,nare distinct
almost surely. Then, the coverage achieved by the calibrated conformal predictor with the set generating
functionC(x,τ) ={ℓ∈Y:s(x,ℓ)≤τ}is also accurate, in that it satisfies
P(x,y)∼P[y∈C(x,τ∗)]≤1−α+1
n+ 1. (14)
Both the lower bound (13)and the upper bound (14)of Lemma A.1 apply to TPS in the context of the binary
classification problem that we consider. To see this, we verify that TPS calibrated with the set generating
function (19)satisfies both assumptions of Lemma A.1. First, note that TPS satisfies the nesting property,
since we haveCTPS(x,τ′)⊆CTPS(x,τ)forτ′≤τ. Next, note that for TPS we have s(x,y) =πy(x). Further
note that the linear logistic regression model we consider assigns a distinct score to each data point and since
the invariant feature xinvis uniformly distributed in a continuous interval conditional on y, the variables si
are distinct almost surely.
Now, consider the oracle TPS threshold τQ
αthat achieves 1−αcoverage, or equivalently αmiscoverage, on
the target distribution, i.e.,
P(x,y)∼Q/bracketleftbig
y /∈CTPS(x,τQ
α)/bracketrightbig
=α. (15)
Next, note that y /∈CTPS(x,τQ
α)if and only if arg maxj∈{0,1}πj(x)̸=yandmaxj∈{0,1}πj(x)≥τQ
α. To see
that, note that the confidence set returned by TPS is a singleton containing only the top prediction of the
model when the confidence of this prediction is higher than the threshold τQ
α. Moreover, the confidence set
returned by TPS for the binary classification problem above does not contain the true label only when the
confidence set is the singleton set of the top prediction of the model and is different than the true label. Thus,
equation (15) implies
P(x,y)∼Q/bracketleftbigg
arg max
j∈{0,1}πj(x)̸=yand max
j∈{0,1}πj(x)≥τQ
α/bracketrightbigg
=α. (16)
We defineβas the miscoverage that the oracle TPS yields on the source distribution, i.e.,
β:= P (x,y)∼P/bracketleftbigg
arg max
j∈{0,1}πj(x)̸=yand max
j∈{0,1}πj(x)≥τQ
α/bracketrightbigg
. (17)
We haveβ̸=αif there is a distribution shift from target to source.
Consider the threshold ˆτP
βfound by calibrating TPS on the set DPto achieve empirical coverage of 1−βas
in(2). TPS with the threshold ˆτP
βachieves coverage on the source distribution Pas a result of Lemma A.1.
Moreover, combining (13)with(14)atn→∞yields exact coverage of 1−βon the source distribution P.
Thus, we have
P(x,y)∼P/bracketleftbigg
arg max
j∈{0,1}πj(x)̸=yand max
j∈{0,1}πj(x)≥ˆτP
β/bracketrightbigg
=β. (18)
14Under review as submission to TMLR
Comparing equation (18)to the definition of βin equation (17)yields ˆτP
β=τQ
α. Therefore, it follows that
TPS calibrated to achieve 1−βcoverage on the source calibration set DPas in(2)achieves exactly 1−α
coverage on the target distribution Qasn→∞.
Step 2: In the second step, we show that QTC correctly estimates the value of βdefined above. This is
formalized by the lemma below.
Recall that the calibration of TPS entails identifying a cutoff threshold τcomputed by the formula (2). The
set generating function of TPS for the linear classification problem described above simplifies to
CTPS(x,τ) ={j∈{0,1}:πj(x)≥1−τ}, (19)
whereπ0(x)andπ1(x)are the first and second entry of (x)as defined above.
We are only interested in the regime where the desired coverage level 1−αis larger than the classifier’s
accuracy, or equivalently α<ϵwithϵbeing the error rate of the classifier. This is because a trivial method
that constructs confidence sets with equal length of 1for all samples (i.e., singleton sets of only the predicted
label) already achieves coverage of 1−ϵ.
Lemma A.2. Given the logistic regression classifier for the binary classification problem described above
with anywinv>0,wsp̸= 0, assume that the threshold qfor QTC is computed using a dataset DQconsisting
ofnsamples, sampled from some target distribution Q, such that
1
|DQ|/summationdisplay
x∈DQ1{maxj∈{0,1}πj(x)<q}=α. (20)
Consider the oracle TPS conformal predictor with conformal threshold τQ
α, i.e., the predictor that achieves
1−αcoverage on the target distribution Q. Denote with 1−βthe coverage achieved on the source distribution
Pby this oracle TPS. Fix a δ>0. The QTC estimate of the miscoverage β, denoted by
βQTC =1
|DP|/summationdisplay
x∈DP1{maxj∈{0,1}πj<q}, (21)
satisfies the following inequality with probability at least 1−δover a randomly drawn set of examples DQ
|βQTC−β|≤/radicaligg
2 log(16/δ)
n·csp, (22)
wherecsp= (1−pQ)·(1−pP)2ifwsp>0andcsp=pQ·(pP)2otherwise.
Proof.We adapt the proof idea of Garg et al. (2022, Theorem 3), which pertains to the problem of estimating
the classification error of the classifier on the target, to estimating the source coverage of the oracle conformal
predictor that achieves 1−αcoverage on the target distribution.
For notational convenience, we define the event that a sample (x,y)is not in the prediction set of the oracle
TPS with conformal threshold τQ
α(i.e.,y /∈CTPS(x,τQ
α)) as
Emc={y /∈CTPS(x,τQ
α)}
={arg max
j∈{0,1}πj(x)̸=yand max
j∈{0,1}πj(x)≥τQ
α}.
The infinite sample size case ( n→∞).In this part we show that as n→∞, the QTC estimate βQTC
found as in (21)converges to the source miscoverage β, to illustrate the proof idea. For n→∞, the QTC
15Under review as submission to TMLR
estimateβQTCin (21) becomes
βQTC =E(x,y)∼P/bracketleftig
1{maxj∈{0,1}fj(x)≤q}/bracketrightig
= P (x,y)∼P/bracketleftbigg
max
j∈{0,1}πj(x)<q/bracketrightbigg
= P (x,y)∼P[Emc] (23)
=β,
where the last equality is the definition of βas given in equation (17). The critical step is equation (23),
which we establish in the remainder of this part of the proof.
First, we condition on the label y. Using the law of total probability, we get
P(x,y)∼P/bracketleftbigg
max
j∈{0,1}πj(x)<q/bracketrightbigg
= Px∼P|y=−1/bracketleftbigg
max
j∈{0,1}πj(x)<q/bracketrightbigg
·P(x,y)∼P[y=−1]
+ Px∼P|y=+1/bracketleftbigg
max
j∈{0,1}πj(x)<q/bracketrightbigg
·P(x,y)∼P[y= +1]
(i)=1
2·Px∼P|y=−1/bracketleftbigg
max
j∈{0,1}πj(x)<q/bracketrightbigg
+1
2·Px∼P|y=+1/bracketleftbigg
max
j∈{0,1}πj(x)<q/bracketrightbigg
(ii)= Px∼P|y/bracketleftbigg
max
j∈{0,1}πj(x)<q/bracketrightbigg
. (24)
For equation (i), we used that yis uniformly distributed across {−1,1}, and for equation (ii)that xis
symmetrically distributed with respect to the label y. That is, we have xinv∼U[−c,−γ]andP[xsp=−1]=p
ify=−1andxinv∼U[γ,c]andP [xsp= +1] =pify= +1, so the two probabilities in (i)are equal.
We can further expand the expression for the probability Px∼P|y/bracketleftbig
maxj∈{0,1}πj(x)<q/bracketrightbig
by additionally
conditioning on the spurious feature xsp, which yields
P(x,y)∼P/bracketleftbigg
max
j∈{0,1}πj(x)<q/bracketrightbigg
= Pxinv∼P|y,xsp=y/bracketleftbigg
max
j∈{0,1}πj(x)<q/bracketrightbigg
·Px∼P|y[xsp=y]
+ Pxinv∼P|xsp̸=y/bracketleftbigg
max
j∈{0,1}πj(x)<q/bracketrightbigg
·Px∼P|y[xsp̸=y].(25)
In order to simplify the expression in the RHS of equation (25), we consider the cases of wsp>0
andwsp<0separately. If wsp>0, we have maxj∈{0,1}πj(x)> qifxsp=y. Therefore, we have
Pxinv∼P|y,xsp=y/bracketleftbig
maxj∈{0,1}πj(x)<q/bracketrightbig
= 0ifwsp>0and equation (25) simplifies to
P(x,y)∼P/bracketleftbigg
max
j∈{0,1}πj(x)<q/bracketrightbigg
= Pxinv∼P|xsp̸=y/bracketleftbigg
max
j∈{0,1}πj(x)<q/bracketrightbigg
·Px∼P|y[xsp̸=y]
= Pxinv∼P|xsp̸=y/bracketleftbigg
max
j∈{0,1}πj(x)<q/bracketrightbigg
·(1−pP). (26)
Similarly, if wsp<0, we have maxj∈{0,1}πj(x)>qifxsp̸=y, and equation (25) becomes
P(x,y)∼P/bracketleftbigg
max
j∈{0,1}πj(x)<q/bracketrightbigg
= Pxinv∼P|xsp=y/bracketleftbigg
max
j∈{0,1}πj(x)<q/bracketrightbigg
·Px∼P|y[xsp=y]
= Pxinv∼P|xsp=y/bracketleftbigg
max
j∈{0,1}πj(x)<q/bracketrightbigg
·pP. (27)
We next follow the same steps that we carried out above for P(x,y)∼P/bracketleftbig
maxj∈{0,1}πj(x)<q/bracketrightbig
to rewrite the
probability P(x,y)∼P[Emc]. Ifwsp>0, the classifier makes no errors if xsp=yand only misclassifies a fraction
16Under review as submission to TMLR
of examples if xsp̸=y. Therefore, we have
Px∼P|y[Emc] = Pxinv∼P|xsp̸=y[Emc]·Px∼P|y[xsp̸=y]
= Pxinv∼P|xsp̸=y[Emc]·(1−pP). (28)
Similarly, for wsp<0, we have
Px∼P|y[Emc] = Pxinv∼P|xsp̸=y[Emc]·Px∼P|y[xsp=y]
= Pxinv∼P|xsp̸=y[Emc]·pP. (29)
Therefore, in order to establish equation (23), it suffices to show
Pxinv∼P|y,xsp̸=y/bracketleftbigg
max
j∈{0,1}πj(x)<q/bracketrightbigg
= Pxinv∼P|y,xsp̸=y[Emc],forwsp>0and (30)
Pxinv∼P|y,xsp=y/bracketleftbigg
max
j∈{0,1}πj(x)<q/bracketrightbigg
= Pxinv∼P|y,xsp=y[Emc],forwsp<0. (31)
The feature xinvis identically distributed conditioned on y, i.e., uniformly distributed in the same interval,
regardless of the underlying source or target distributions PandQ. Therefore, equations (30)and(31)are
equivalent to
Pxinv∼Q|y,xsp̸=y/bracketleftbigg
max
j∈{0,1}πj(x)<q/bracketrightbigg
= Pxinv∼Q|y,xsp̸=y[Emc],forwsp>0and (32)
Pxinv∼Q|y,xsp=y/bracketleftbigg
max
j∈{0,1}πj(x)<q/bracketrightbigg
= Pxinv∼Q|y,xsp=y[Emc],forwsp<0. (33)
Equations (32) and (33) in turn follow from
P(x,y)∼Q/bracketleftbigg
max
j∈{0,1}πj(x)<q/bracketrightbigg
= P (x,y)∼Q[Emc], (34)
by carrying out the same steps that we carried out to expand the probabilities Px∼P|y/bracketleftbig
maxj∈{0,1}πj(x)<q/bracketrightbig
andP(x,y)∼P/bracketleftbig
maxj∈{0,1}πj(x)<q/bracketrightbig
starting from equation (24)to establish equations (30)and(31). Equa-
tion(34)in turn is a consequence of combining (16)with(20)atn→∞. This establishes equation (23), as
desired.
The finite sample case: We next show that the desired results approximately hold with high probability
over a randomly drawn finite-sized set of examples DQ. We bound the difference between the LHS and RHS
of (32) and (33) with high probability.
First, consider the case of wsp>0. Recall that for the case of wsp>0we are interested in the regime where
xsp̸=y. We denote the set of points in the target set DQfor which the spurious feature disagrees with the
label as
XD={i= 1,...,n :xsp̸=y,(xi,yi)∈DQ},
and denote the set of points for which the spurious feature agrees with the label as
XA={i= 1,...,n :xsp=y,(xi,yi)∈DQ}.
Note that the QTC threshold qfound on the entire set DQas in (20) satisfies
1
|XD|/summationdisplay
i∈XD1{maxj∈{0,1}πj(xi)<q}=1
|XD|/summationdisplay
i∈XD1{Emc(xi,yi)}, (35)
17Under review as submission to TMLR
which follows from noting that the classifier only makes an error on the subset XDifwsp>0and therefore
the only points for which the event Emcis observed lie in the set XD. Similarly, as established before in the
infinite sample case, we have 1{maxj∈{0,1}πj(xi)<q}= 0for alli∈XD.
By the Dvoretzky-Kiefer-Wolfowitz-Massart (DKWM) inequality, for any q>0we have with probability at
least 1−δ/8
/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle1
|XD|/summationdisplay
i∈XD1{maxj∈{0,1}πj(xi)<q}−Exinv∼Q|y,xsp̸=y/bracketleftig
1{maxj∈{0,1}πj(x)<q}/bracketrightig/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle≤/radicaligg
log(16/δ)
2|XD|.(36)
Plugging equation (35) into (36), we have with probability at least 1−δ/8
/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingleExinv∼Q|y,xsp̸=y/bracketleftig
1{maxj∈{0,1}πj(x)<q}/bracketrightig
−1
|XD|/summationdisplay
i∈XD1{Emc}/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle≤/radicaligg
log(16/δ)
2|XD|. (37)
We next bound the second term in the LHS of equation (37)from its expectation. Using Hoeffding’s inequality,
we have with probability at least 1−δ/8
/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle1
|XD|/summationdisplay
i∈XD1{Emc}−Exinv∼Q|y,xsp̸=y/bracketleftbig
1{Emc}/bracketrightbig/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle≤/radicaligg
log(16/δ)
2|XD|. (38)
Combining equations (37)and(38)using the triangle inequality and union bound, we have with probability
at least 1−δ/4
/vextendsingle/vextendsingle/vextendsingleExinv∼Q|y,xsp̸=y/bracketleftig
1{maxj∈{0,1}πj(x)<q}/bracketrightig
−Exinv∼Q|y,xsp̸=y/bracketleftbig
1{Emc}/bracketrightbig/vextendsingle/vextendsingle/vextendsingle≤/radicaligg
2 log(16/δ)
|XD|. (39)
Recall that the invariant feature xinvis uniformly distributed in the same interval conditioned on yre-
gardless of the source or target distributions PandQand that Pxinv|y,xsp=y/bracketleftbig
maxj∈{0,1}πj(x)>q/bracketrightbig
=
Pxinv|y,xsp=y/bracketleftbig
arg maxj∈{0,1}πj(x)̸=y/bracketrightbig
= 0for the case of wsp>0as shown before. Therefore, by dividing
both sides of (39) with 1/Px∼P|y[xsp̸=y]we have with probability at least 1−δ/4
/vextendsingle/vextendsingle/vextendsingleE(x,y)∼P/bracketleftig
1{maxj∈{0,1}πj(x)<q}/bracketrightig
−E(x,y)∼P/bracketleftbig
1{Emc}/bracketrightbig/vextendsingle/vextendsingle/vextendsingle≤1
Px∼P|y[xsp̸=y]/radicaligg
2 log(16/δ)
|XD|
=1
1−pP/radicaligg
2 log(16/δ)
|XD|. (40)
For the case of wsp<0, we can show an analogous result by noting that the above results can be shown on
the setXA, wherexsp=y. Specifically, noting that1
|XA|/summationtext
i∈XA1{maxj∈{0,1}πj(xi)<q}=1
|XA|/summationtext
i∈XA1{Emc}
ifwsp<0and following exactly the same steps from equation (35)onward that lead to equation (40), we
have with probability at least 1−δ/4
/vextendsingle/vextendsingle/vextendsingleE(x,y)∼P/bracketleftig
1{maxj∈{0,1}πj(x)<q}/bracketrightig
−E(x,y)∼P/bracketleftbig
1{Emc}/bracketrightbig/vextendsingle/vextendsingle/vextendsingle≤1
pP/radicaligg
2 log(16/δ)
|XA|. (41)
Using Hoeffding’s inequality we can further bound the RHS of (40)and(41). For the setXD, we have with
probability at least 1−δ/2
/vextendsingle/vextendsingle|XD|−n·(1−pQ)/vextendsingle/vextendsingle≤/radicalbigg
log(4/δ)
2n, (42)
18Under review as submission to TMLR
0.8 0.9 10.70.80.91
desired coverage 1−αachieved coverageImageNetV2
0.8 0.9 10.40.60.81
desired coverage 1−αImageNet-Sketch
0.8 0.9 10.40.60.81
desired coverage 1−αImageNet-R
y=x
original
QTC
QTC-SC
QTC-ST
CHR-
Figure 6: Coverage obtained by RAPS on the target distribution Qfor various settings of ( 1−α) w/ and
w/o recalibration using QTC.
and for the setXA, we have with probability at least 1−δ/2
/vextendsingle/vextendsingle|XA|−n·pQ/vextendsingle/vextendsingle≤/radicalbigg
log(4/δ)
2n. (43)
We next bound the difference between the finite sample QTC estimation on the source from its expectation.
By DKWM inequality, for any q>0we have with probability at least 1−δ/4
/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle1
|DP|/summationdisplay
x∈DP1{maxj∈{0,1}πj(x)<q}−E(x,y)∼P/bracketleftig
1{maxj∈{0,1}πj(x)<q}/bracketrightig/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle≤/radicalbigg
log(8/δ)
2n. (44)
We first show the result for the case wsp>0. Combining equations (40)and(44)using the triangle inequality
and union bound, we have with probability at least 1−δ/2
/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle1
|DP|/summationdisplay
x∈DP1{maxj∈{0,1}πj(x)<q}−E(x,y)∼P/bracketleftbig
1{Emc}/bracketrightbig/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle≤1
1−pP/radicaligg
2 log(16/δ)
|XD|. (45)
Plugging in the definitions of βQTCin (21) and βin (17) above, equivalently we get
|βQTC−β|≤1
1−pP/radicaligg
2 log(16/δ)
|XD|, (46)
which holds with probability at least 1−δ/2. Combining (46)with(42)proves equation (22)forwsp>0, as
desired.
Similarly, for the case wsp<0, following the same steps by first combining equation (41)with(44), we have
with probability at least 1−δ/2
|βQTC−β|≤1
pP/radicaligg
2 log(16/δ)
|XA|. (47)
Combining (47) with (43) yields equation (22), as desired, for the case wsp<0, which concludes the proof.
A.1 Details on the baseline regression methods
In this section, we provide details on the baseline regression based methods. Recall that we consider several
regression-based methods as baselines by fitting a regression function fθparameterized by a feature extractor
19Under review as submission to TMLR
0.8 0.9 10.70.80.91
desired coverage 1−αachieved coverageλ= 0.2
0.8 0.9 10.70.80.91
desired coverage 1−αλ= 0.5
0.8 0.9 10.70.80.91
desired coverage 1−αλ= 1.0
y=x
original
QTC-ST
CHR-
Figure 7: Coverage obtained by RAPS on the target distribution Q(ImageNetV2) for kreg= 2and various
settings ofλwhen the threshold τis replaced with the predicted threshold ˆτwith the respective prediction
method. For regression methods, only the best performing method of CHR- is shown.
ϕπby minimizing the mean squared error between the output and the calibrated threshold τacross the
distributions as
ˆθ= arg min
θ/summationdisplay
j(fθ(ϕπ(Dj))−τPj)2.
We consider the following choices for the feature extractor ϕπ:
•Average confidence regression (ACR) : The one-dimensional ( d= 1) average confidence of the classifier
across the entire dataset which is ϕπ(D) =1
|D|/summationtext
x∈Dmaxℓπℓ(x).
•Difference of confidence regression (DCR) (Guillory et al., 2021): The one-dimensional ( d= 1)
average confidence of the classifier across the entire dataset offset by the average confidence on the
source dataset, which is ϕπ(D) =1
|D|/summationtext
x∈Dmaxℓπℓ(x)−1
|DP|/summationtext
x∈DPmaxℓπℓ(x), whereDPis the
source dataset. Prediction is also for the offset target τ−τP.
We consider DCR in addition to ACR, because DCR performs better for predicting the classifier
accuracy (Guillory et al., 2021). Since the threshold τfound by conformal calibration depends on the
distribution of the confidences beyond the average, we propose the below techniques for extracting
more detailed information from the dataset.
•Confidence histogram-density regression (CHR) : Variable dimensional ( d=p) features extracted as
ϕπ(D) =/braceleftig
1
|D|/summationtext
x∈D1{maxℓπℓ(x)∈[j−1
p,j
p]}/bracerightig
j={1,...,p}. This corresponds to the normalized histogram
density of the classifier confidence across the dataset, where p is a hyperparameter that determines
the number of histogram bins in the probability range [0,1]. Neural networks tend to be overconfident
in their prediction which heavily skews the histogram densities to the last bin. We also therefore
consider a variant of CHR, dubbed CHR- , where we have j={1,...,p−1}and henced=p−1,
equivalent to dropping the last bin of the histogram as a feature.
•Predicted class-wise average confidence regression (PCR) : Features with dimensionality equal to
the number of classes ( d=L) extracted as ϕπ(D) =/braceleftbigg/summationtext
x∈Dπj(x)· 1{l=arg maxℓπℓ(x)} /summationtext
x∈D1{l=arg maxℓπℓ(x)}/bracerightbigg
j={1,...,L}.This
corresponds to the average confidence of the classifier across the samples for each predicted class.
B RAPS recalibration experiments
APS is a powerful yet simple conformal predictor. However, other conformal predictors (Sadinle et al., 2019;
Angelopoulos et al., 2020) are more efficient (in that they have on average smaller confidence sets for a given
desired coverage 1−α).
20Under review as submission to TMLR
0.8 0.9 10.70.80.91
desired coverage 1−αachieved coverageImageNetV2
0.8 0.9 10.40.60.81
desired coverage 1−αImageNet-Sketch
0.8 0.9 10.40.60.81
desired coverage 1−αImageNet-R
y=x
original
QTC-ST
CHR-
Figure 8: Coverage obtained by RAPS on the target distribution Qforλ= 0.1and various settings of
(1−α) when the threshold τis replaced with the predicted threshold ˆτwith the respective prediction method.
For regression methods, only the best performing method of CHR- is shown.
Inthissection, wefocusontheconformalpredictorproposedbyAngelopoulosetal.(2020), dubbedRegularized
Adaptive Prediction Sets (RAPS). RAPS is an extension of APS that is obtained by adding a regularizing
term to the classifier’s probability estimates of the higher-order predictions (i.e., subsequent predictions after
the top-k predictions). RAPS is more efficient and tends to produce smaller confidence sets when calibrated
on the same calibration set as APS, as it penalizes large sets. While TPS tends to achieve slightly better
results in terms of efficiency compared to RAPS, see (Angelopoulos et al., 2020, Table 9), RAPS coverage
tends to be more uniform across different instances (in terms of difficult vs. easy instances) and therefore
RAPS still carries practical relevance.
Recall that while efficiency can be improved by constructing confidence sets more aggressively, efficient models
tend to be less robust, meaning the coverage gap is greater when there is distribution shift at test time. For
example, when calibrated to yield 1−α= 0.9coverage on ImageNet-Val and tested on Image-Sketch, the
coverage of RAPS drops to 0.38in contrast to that of APS, which only drops to 0.64(see Section 3). It is
therefore of great interest to understand how QTC performs for recalibration of RAPS under distribution
shift.
RAPS is calibrated using exactly the same conformal calibration process as APS and only differs from APS
in terms of the prediction set function C(x,u,τ). The prediction set function for RAPS is defined as
CRAPS(x,u,τ) =

ℓ∈{1,...,L}:ℓ−1/summationdisplay
j=1[π(j)(x) + 1{j−kreg>0}·λ/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
regularization] +u·π(ℓ)(x)≤τ

, (48)
whereu∼U(0,1), similar to APS and λ,kregare the hyperparameters of RAPS corresponding to the
regularization amount and the number of top non-penalized predictions respectively.
Note that the cutoff threshold τPobtained by calibrating RAPS on some calibration set DP
calcan be larger
than one due to the added regularization. Therefore, in order to apply QTC-ST, we map τPback to the
[0,1]range by dividing by the total scores after added regularization. QTC and QTC-SC do not require such
an additional step as the coverage level α∈[0,1]by definition. We show the results of RAPS’ performance
under distribution shift with or without calibration by QTC in Figure 6. The results show that while QTC is
not able to completely mitigate the coverage gap, it significantly reduces it.
Recall that RAPS utilizes a hyperparameter λ, which is the added penalty to the scores of the predictions
following the top- kregpredictions, that can significantly change the cutoff threshold τPwhen we calibrate
on the calibration set DP. The regularization amount λalso implicitly controls the change in the cutoff
threshold/vextendsingle/vextendsingleτQ−τP/vextendsingle/vextendsinglewhen the conformal predictor is calibrated on different distributions PandQ. That is,
the value of/vextendsingle/vextendsingleτQ−τP/vextendsingle/vextendsingleincreases with increasing λas long as the distributions PandQare meaningfully
different, as is the case for all the distribution shifts that we consider.
21Under review as submission to TMLR
Therefore, a good recalibration method should be relatively immune to the choice of λin order to successfully
predict the threshold τQbased only on unlabeled examples. In Figure 7, we show the performance of RAPS
under the ImageNetV2 distribution shift for various values of λ. While QTC is able to improve the coverage
gap for various choices of λ, the best performing regression-based baseline method does not generalize well to
natural distribution shifts when λis relatively large. In contrast, as demonstrated in Figure 8, when the
regularization amount λis relatively small, the best performing regression-based method of CHR- does very
well in reducing the coverage gap of RAPS under various distribution shifts.
22