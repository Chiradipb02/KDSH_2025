Under review as submission to TMLR
Estimating Unbiased Averages of Sensitive Attributes
without Handshakes among Agents
Anonymous authors
Paper under double-blind review
Abstract
We consider the problem of distributed averaging of sensitive attributes in a net-
work of agents without central coordinators, where the graph of the network has
an arbitrary degree sequence (degrees refer to numbers of neighbors of vertices).
Usually, existing works solve this problem by assuming that either (i) the agents
reveal their degrees to their neighbors or (ii) every two neighboring agents can per-
form handshakes (requests that rely on replies) in every exchange of information.
However, the degrees suggest the proﬁles of the agents and the handshakes are im-
practical upon inactive agents. We propose an approach which solves the problem
with privatized degrees and without handshakes upon a stronger self-organization.
In particular, we propose a simple gossip algorithm that computes averages that
are biased by the variance of the degrees and a mechanism that corrects that bias.
We will suggest a use case of the proposed approach that allows for ﬁtting a linear
regression model in a distributed manner, while privatizing the target values, the
features and the degrees. We will provide theoretical guarantees that the mean
squared error between an estimated regression parameter and a true regression pa-
rameter isO(1
n), wherenis the number of agents. We will show on synthetic graph
datasets that the theoretical error is close to its empirical counterpart. Also, we
will show on synthetic graph datasets and real graph datasets that the regression
model ﬁtted by our approach is close to the solution when locally privatized values
are averaged by central coordinators.
1 Introduction
Over the last decade there has been signiﬁcant interest in self-organizing distributed systems, where
the nodes (agents) in a communication network collaborate without central coordinators. One basic
task corresponds to the problem where every agent has an individual value and every agent would
like to know the average of those values. As we will argue, existing works usually assume a form
of handshakes between every two neighboring agents in every exchange of information, i.e., when
one agent uses information of a second agent, this second agent becomes aware of this and must
actively help the process. However, there exist practical scenarios where such interaction is time
consuming due to inactivity of some agents.
To give an illustrative example on communication without handshakes, let us consider a group of
researchers who aim at solving a particular problem. The researchers can follow each other, and
1Under review as submission to TMLR
thus read each other’s currently best strategy in each other’s most recently published paper. The
researchers work on their solution strategy individually and without necessarily directly contacting
others, attempting to improve their current solution strategies based on their individual skills and
the ideas read in the papers of the followed colleagues. They hope that at some point one of them
will ﬁnd a fully satisfactory solution.
Regarding our setting, we model the agents by a graph where neighboring agents are connected by
edges. The agents have sensitive attributes, such as their degree (the number of neighbors), which
they aim to privatize before sharing them with other agents as otherwise the sensitive attributes
wouldsuggesttheirproﬁle. Weremarkthattheagentshide(addappropriatenoiseto)theirsensitive
attributes on their own (without central coordinators).
Regarding our approach, the agents commit to a simple gossip algorithm for distributed averaging.
In particular, every agent hides their sensitive attributes under diﬀerential privacy noise (diﬀerential
privacy is a conventional guarantee of data privacy) and makes them visible to the neighbors.
Then, every agent repeatedly computes the averages over the values revealed by their neighbors
and updates the displayed value by the computed average. At some point this will converge, and
the computed averages will result in the averages that are biased by the variance in the degrees (the
averages are biased when the graph is non-regular). We will provide a mechanism that combines
such biased averages so that the bias is corrected. We remark that our approach is characterized
by self-organization: handshake-free interaction and asynchrony.
We will suggest a use case of our approach for ﬁtting a simple linear regression model, while
privatizing the target values, the features and the degrees. We will provide theoretical guarantees
that the mean squared error between an estimated regression parameter and a true regression
parameter isO(1
n), wherenis the number of agents. We will show on synthetic graph datasets
that the theoretical error is close to its empirical counterpart. Also, we will show on synthetic
graph datasets and real graph datasets that the regression model ﬁtted by the unbiased averages
computed by our strategy is close to the solution that relies on central coordinators.
We brieﬂy motivate several elements of our setting. Usually, there are two common types of
information ﬂow (Giakkoupis, 2011): pulling, where an agent asks its neighboring agent for its
value, and pushing, where an agent sends its value to a neighboring agent. In this paper, we study
a weak form of pulling where an agent obtains the current value of a neighbor without the neighbor
being aware of this. In particular, every agent continuously publishes its current values so that
its neighbors can obtain it, but there is no other communication (e.g., there is no communication
process to build overlay networks (Jelasity et al., 2009) that can improve distributed computations).
Since the agents do not exchange handshakes (like in the Transport Layer Security protocol),
information dissemination is more robust against inactive agents. Further, we assume that the
degree is a sensitive attribute because in some contexts it suggests the proﬁle of an agent (Hay
et al., 2009; 2010). Finally, we mention that our approach applies for graphs with power-law degree
sequences which, as suggested by Zipf’s law, are common in real-world (e.g., computer, social,
biological) networks.
Outline. In Section 2, we precise our setting. In Section 3, we provide the literature study. In
Section 4, we state our approach. In Section 5, we relate our approach to a use case on linear
regression. In Section 6, we provide theoretical guarantees for the mean squared error between
an estimated regression parameter and a true regression parameter. In Section 7, we discuss the
experiments on synthetic graph datasets and real graph datasets. In Section 8, we conclude.
2Under review as submission to TMLR
2 Preliminaries
In this section, we will precise our setting and notation by describing the graph model (the model
for the communication network of agents) and the attack model (the model for data privacy).
Graph model. We model our network of agents by a graph G= (V,E), whereVis the set of
vertices (v∈Vis a vertex) and Eis the set of edges (each edge is a tuple of two vertices). We
denote the order of the graph, i.e. |V|, byn. We denote the degree of a vertex vbydv. This way,
we denote the degree sequence of Gbyd= (d1,...,dn). Further, we denote the minimum degree
and the maximum degree by dminanddmax, respectively.
We highlight that we will follow the notation where lower-case characters (e.g., x) indicate scalars
or maps, bolded lower-case characters (e.g., x) indicate vectors, bolded upper-case characters (e.g.,
X) indicate matrices, and upper-case characters (e.g., X) do not have a strictly assigned role but
they usually indicate random variables or sets. Also, for x∈N, we deﬁne [x]as{1,...,x}. For
k∈Zandx∈Rn, we denote the k-th raw moment1
n/summationtextn
i=1xk
ibyµx,k(whenk= 1, we denote it
byµx). Similarly, for k,l∈Zandx,y∈Rn, we will denote1
n/summationtextn
i=1xk
iyl
ibyµxkyl. Finally, we
denote the vector of 1’s by1. We provide the tables summarizing the notations in Section A.
Our graph Gis an undirected graph with no self-loops or multiple edges. We will model Gby a
random graph (a graph with ﬁxed vertices but the presence of the edges being determined by draws
from probability distributions) drawn from the conﬁguration model which is deﬁned as follows:
Deﬁnition 1. The conﬁguration model is the probability distribution over graphs that is
parametrized by a degree sequence d, so that for i∈[n−1]andj∈{i+ 1,...,n}, edge (vi,vj)is
present with probability
didj
(/summationtextn
i/prime=1di/prime)−1.
Attack model. We assume that the agents are honest-but-curious, i.e., all agents follow the
established protocols (they are honest), but they try to use the available information to infer
sensitive information of other agents (they are curious). We remark that in our setting where agents
publish information and can see published information from others but no other communication is
possible, it is straightforward to protect against agents which are malicious in the sense they deviate
from the protocol in order to obtain more information. Protecting against agents which deviate
from the protocol to inﬂuence the result of the computation, e.g., by publishing false information
(also called data poisoning), is out of the scope of this paper.
We remark that we interpret a basic dataset as a table with instances over rows and (scalar)
attributes over its columns. We introduce a simpliﬁed version of the (/epsilon1,δ)-indistinguishability
proposed by Dwork et al. (2006), commonly known as diﬀerential privacy:
Deﬁnition 2. Let/epsilon1,δ≥0. A randomized algorithm Ais(/epsilon1,δ)-diﬀerentially private if and only
if for all tuples (D,D/prime)in a collection where datasets DandD/primediﬀer only in the attribute of one
instance, and for all S⊆image(A)we have
Pr(A(D)∈S)≤e/epsilon1Pr(A(D/prime)∈S) +δ.
In local diﬀerential privacy, the common idea is to add noise to attributes. We refer to such
attributes as sensitive attributes. In central diﬀerential privacy, central coordinators add noise
3Under review as submission to TMLR
to statistics computed from attributes, thus it is more common to refer to sensitive statistics as
opposed to sensitive attributes. In this work, we will focus on local diﬀerential privacy.
A classic strategy to guarantee (/epsilon1,δ)-diﬀerential privacy is to generate noisy values from the Gaus-
sian mechanism. We deﬁne the Gaussian mechanism in the context of local diﬀerential privacy:
Deﬁnition 3. Let/epsilon1,δ > 0. LetX⊆R. Letx∈Xbe a scalar attribute. Let xminandxmaxbe,
respectively, the smallest and the largest element in X. The Gaussian mechanism is a mechanism
that privatizes xby taking an observation of the following random variable:
N/parenleftbigg
x,2 log(1.25/δ)∆2
2(x)
/epsilon12/parenrightbigg
,
where
∆2(x) =/bardblxmax−xmin/bardbl2 (2.1)
is thel2sensitivity. (The deﬁnition can be generalized to vector attributes.)
We also give a deﬁnition of (/epsilon1,δ)-diﬀerential privacy for graph data (extends Deﬁnition 2):
Deﬁnition 4. Let/epsilon1,δ≥0. A randomized algorithm Ais(/epsilon1,δ)-diﬀerentially private if and only if
for all triples (D,D/prime,vo)datasetsD,D/primediﬀer only in vertex voand its attributes (i.e., the diﬀerence
is in the label value and the presence/absence of one edge), and for all S⊆image(A)we have
Pr(A(D)∈S)≤e/epsilon1Pr(A(D/prime)∈S) +δ.
3 Literature study
We are not aware of another approach of distributed averaging without handshakes and privatized
degrees to which we could directly compare our approach. This way, we will discuss some works
with partial solutions and give some reference works that were taken as building blocks.
If the degree was not a sensitive attribute, our problem can be solved by a gossip algorithm that
corrects the bias by an application of the Metropolis–Hastings algorithm (Hastings, 1970). More
speciﬁcally, in every gossip iteration, an agent can make use of the degrees of its neighbors to correct
the bias from every value that will be included in the average.
Further, if handshakes among agents were allowed, the community could solve the problem by
making use of an agreed-upon overlay network (a network “built” on top of the initial one). Though,
evenifoverlaynetworkswerepossible, suchsolutionwouldbecharacterizedbythetrade-oﬀbetween
robustness and communication delay, whereas in this work we try to maintain both. For example,
the spanning tree overlay network guarantees unbiased averages and requires only few handshakes
though it is vulnerable to node failure.
Then, there are several gossip algorithms that solve our problem by relying on handshakes. Boyd
et al. (2006) require the agents to agree on an independent edge set (so-called matching). Kempe
et al. (2003) assume that every agent knows if a sent message failed to reach its destination. Bellet
et al. (2019) assume that an agent always accepts a message sent to it. Dellenbach et al. (2018),
4Under review as submission to TMLR
every two neighbors initialize their communication by sharing a value related to a positive noise for
one and a negative noise for other. Ridgley et al. (2019) use pushing as opposed to pulling, which
in some contexts results in a weaker notion of self-organization.
We remark that garbled circuits (Gascón et al., 2017; Nikolaenko et al., 2013) is a common alter-
native for gossip algorithms. However, they rely on public-key cryptography and the exchange of
public keys is a form of handshakes.
Now we introduce the reference works that were taken as building blocks. Oliveira (2009) gave a
theorem on the matrix norm between the adjacency matrix of an Erdős–Rényi random graph and its
expectation. Such result is useful for obtaining guarantees for distributed computations on graphs
modelled by the Erdős–Rényi random graph, and it has motivated us to work on establishing a sim-
ilar groundwork for graph models with arbitrary degree sequences. Regarding other works, Iutzeler
et al. (2013) provided analysis of a gossip algorithm for distributed averaging on graphs with ar-
bitrary degree sequences. Chierichetti et al. (2011) considered graph models characterized by a
power-law degree sequence. Bellet et al. (2019) provided a deﬁnition of diﬀerential privacy for
gossip algorithms. Lindell and Pinkas (2009) provided a compendium on privacy-preserving dis-
tributed averaging techniques (though this work focuses more on security than data privacy). Aysal
et al. (2009) considered a gossip algorithm that is asynchronous. Bell et al. (2020) applied unbiased
averages that were computed in a distributed manner for ﬁtting a regression model.
4 Approach
In this section, we will describe the simple gossip algorithm that enables distributed averaging
in communication networks without central coordinators. Then, we will provide a bias removal
mechanism so that the simple gossip algorithm can be applied for computing unbiased averages.
4.1 The simple gossip algorithm
Let◦ind◦−1denotetheoperatorfortheelement-wisepower. Wedeﬁnethesimplegossipalgorithm:
Algorithm 1: SimpleGossip (SiGo)
Input : A∈[0,1]n×n:adjacency matrix of the graph of agents
itgo∈N:number of gossip iterations
w∈Rn
Output: z∈Rn
d←/summationtextn
i=1A·,i
T←diag(d◦−1)A
z←1
n1TTitgow
We remark that matrix Tis the transition matrix and acts as an averaging operator. The con-
struction of Tinvolves the complete adjacency matrix Awhich suggests that the operation is
synchronous. However, Boyd et al. (2006) mentions that such algorithm can be executed asyn-
chronously (the involvement of Ais partial in every iteration). We use the synchronous version for
simplicity.
5Under review as submission to TMLR
For Algorithm 1 to converge (elements of zget close to each other), it is required that itgois high
enough and Gis a simple, connected graph with at least one odd cycle. Kermarrec and van Steen
(2007) indicate that itgo=⌈logn⌉is suﬃcient for SiGoto converge, when lognis approximately
the diameter of Gand the degree sequence dis power-law. We state a theorem for the value of the
output of the algorithm when the algorithm converges and prove it in Subsection B.1:
Theorem 1. Letw∈Rn(the theorem holds when this value is a random vector). For every j∈[n],
SiGo ((wi)n
i=1)j≈1
n1
µdn/summationdisplay
i=1diwi, (4.1)
where SiGo ((.)n
i=1)jisj-th element of the output of Algorithm 1.
We remark that Theorem 1 is convenient to use for graphs modelled by the conﬁguration model
(Deﬁnition 1) since their expected degree sequence is the degree sequence that parametrizes the
conﬁguration model. We conclude that the theorem shows that the resulting average is biased by
µdanddi(for everyi∈[n]) whendi/negationslash=µd(i.e. the graph is non-regular). To give an example, we
will show that the squared diﬀerence between the output of Algorithm 1 and the average µwover
the elements of wis non-zero. For j∈[n], we have
/parenleftBig
SiGo ((wi)n
i=1)j−µw/parenrightBig2
≈/parenleftBigg
1
n1
µdn/summationdisplay
i=1diwi−µw/parenrightBigg2
(by Theorem 1)
=/parenleftbiggµdw
µd−µw/parenrightbigg2
, (4.2)
which is not equal to 0when the graph is non-regular, as only then µdw=µdµw.
4.2 The bias removal mechanism
We will devise a bias removal mechanism to correct the bias illustrated by Equation 4.2.
We give an example of how the community can compute an unbiased estimate of µwusing sev-
eral runs of Algorithm 1. Firstly, the community performs two runs of Algorithm 1 (executed
sequentially or in parallel), with inputs (wid−1
i)n
i=1and(d−1
i)n
i=1, resulting in
SiGo/parenleftbig
(wid−1
i)n
i=1/parenrightbig
j≈1
n1
µdn/summationdisplay
i=1wi=µw
µd, (by Theorem 1)
SiGo/parenleftbig
(d−1
i)n
i=1/parenrightbig
j≈1
n1
µdn/summationdisplay
i=11 =1
µd, (by Theorem 1)
wherej∈[n]. Then, the community can compute
SiGo/parenleftbig
(wid−1
i)n
i=1/parenrightbig
j
SiGo/parenleftbig
(d−1
i)n
i=1/parenrightbig
j≈µw. (4.3)
6Under review as submission to TMLR
Letk∈Zand letj∈[n]. We generalize Equation 4.3:
SiGo/parenleftbig
(wk
id−1
i)n
i=1/parenrightbig
j
SiGo/parenleftbig
(d−1
i)n
i=1/parenrightbig
j≈1
n1
µd/summationtextn
i=1di(wk
id−1
i)
1
n1
µd/summationtextn
i=1di(d−1
i)(by Theorem 1) (4.4)
=1
nn/summationdisplay
i=1wk
i=µwk.
Further, we deﬁne U-statistics which generalizes the notion of unbiased estimates:
Deﬁnition 5. Letr≥1be a natural number. Let n≥rbe a natural number. For i∈[n], let
xi∈Rrbe an observation of a random vector. Let φ:Rr→R. The value
1/parenleftbign
r/parenrightbig(n
r)/summationdisplay
i=1φ(xi,1,...,xi,r)
is a U-statistic of degree rand kernel φ.
We conclude that the estimates obtained from the bias removal mechanism (Equation 4.4) are U-
statistics of degree 1and kernel φ:x/mapsto→xkfork∈Z. We remark that U-statistics of degree 1are
present in some machine learning applications, for example, in classic strategies for ﬁtting linear
regression models and bootstrap aggregation in random forests.
5 Use case on linear regression
We will show a use case for applying our approach for ﬁtting a linear regression model, where every
agent is attributed a sensitive individual value which is derived from their sensitive degrees, and
every agent learns the regression model of those individual values.
We start by deﬁning the simple linear regression model (with one feature and one-dimensional
target value) of our use case. For every i∈[n],
yi=θ0+θ1xi+ξreg,i, (5.1)
whereθ0,θ1∈Rare regression parameters, Ξreg,i∼uni[−lreg/2,lreg/2]is independent, mean-0
regression noise, lregis the length of the interval of the regression noise, ξreg,iis an observation of
Ξreg,i,xi= (di−µd)2are features, and yiare target values.
Inregression, acommonwaytoestimatetheregressionparameters θ0,θ1istoperformcomputations
from pairs (yi,xi). We denote the estimates of θ0,θ1byˆθ0,ˆθ1, respectively.
Nowwewillshowabasicstrategytoobtaintheestimatesoftheregressionparametersfromunbiased
averages. Let X=/bracketleftbig1 x/bracketrightbig
∈Rn×2, where xis the vector of features (over all agents). Let ydenote
the vector of target values. Let ˆdenote the vector of the estimates of the regression parameters.
7Under review as submission to TMLR
The regression model (Equation 5.1) can be expressed and rearranged as follows:
y=Xˆ⇐⇒XTy=XTXˆ
⇐⇒ ˆ= (XTX)−1XTy
⇐⇒ ˆ=/parenleftbigg1
nXTX/parenrightbigg−11
nXTy, (5.2)
since/parenleftbig1
nXTX/parenrightbig−1=n/parenleftbig
XTX/parenrightbig−1. We have that
1
nXTX=/bracketleftbigg11
n/summationtext
ixi
1
n/summationtext
ixi1
n/summationtext
ix2
i/bracketrightbigg
=/bracketleftbigg1µx
µxµx2/bracketrightbigg
, (5.3)
1
nXTy=/bracketleftbig1
n/summationtext
iyi1
n/summationtext
iyixi/bracketrightbig
=/bracketleftbigµyµyx/bracketrightbig
, (5.4)
thus the estimates of the regression parameters can be computed from the values µx,µx2,µyand
µyx. By Deﬁnition 5, the values µx,µx2,µyandµyxare U-statistics of degree 1.
Using Algorithm 1 and its bias removal mechanism (Equation 4.4), the values µx,µx2,µy,µyxcan
be computed from SiGo/parenleftbig
(d−1
i)n
i=1/parenrightbig
j,SiGo/parenleftbig
(xid−1
i)n
i=1/parenrightbig
j,SiGo/parenleftbig
(x2
id−1
i)n
i=1/parenrightbig
j,SiGo/parenleftbig
(yid−1
i)n
i=1/parenrightbig
j,
SiGo/parenleftbig
(yixid−1
i)n
i=1/parenrightbig
j, wherej∈N. Though we leave a remark that the community needs to ﬁrstly
computeµd≈1
SiGo((d−1
i)n
i=1)jbecause for executing Algorithm 1 with some of the other inputs, it
is required to ﬁrstly compute the features xi= (di−µd)2which involves µd.
We will elaborate on the strategy which can be used by every agent for keeping their sensitive
attributes diﬀerentially private. Firstly, we split our privacy budget (/epsilon1,δ)evenly in ﬁve parts (i.e.,
/epsilon1/5,δ/5) because the community executes Algorithm 1 with ﬁve diﬀerent sensitive attributes (as
suggested in the previous paragraph, these are d−1
i,xid−1
i,x2
id−1
i,yid−1
iandyixid−1
i) to obtain
the U-statistics for regression, and thus we hide every input under independent and appropriate
noise. Such even split is suboptimal because some of those inputs are correlated, though this aspect
is outside the scope of this work. We remark that the even split is appropriate for the Gaussian
mechanism(Deﬁnition3)assuggestedbythetextbookondiﬀerentialprivacybyDworketal.(2014)
Further, instead of adding noise to the inputs of Algorithm 1, we could split the privacy budget to
two parts and hide only the attributes diand the target values yi. However, in the end we would
not necessarily have signiﬁcantly more accurate estimations of the U-statistics as the computations
of the features amplify the noise. Also, such strategy would complicate the theoretical guarantees
derived later.
We will deﬁne the privatized inputs to Algorithm 1. Let k,l,m∈Z. A privatized input νi,(k,l,m )
(with respect to the sensitive attribute yk
ixl
idm
i) is an observation of the following random variable:
Ξdp,i,(k,l,m )∼N/parenleftBig
yk
ixl
idm
i,σ2
dp,(k,l,m )/parenrightBig
, (5.5)
where
σ2
dp,(k,l,m )=2 log(1.25/(δ/5))∆2
2(yk
ixl
idm
i)
(/epsilon1/5)2(by Deﬁnition 3)
=50 log/parenleftbig25
41
δ/parenrightbig
∆2
2(yk
ixl
idm
i)
/epsilon1. (5.6)
8Under review as submission to TMLR
Wehavederivedthe l2sensitivities(Equation2.1)requiredforregressioninSubsectionC.1. Further,
we have described the clipping of the ﬁve privatized inputs needed for regression in Subsection C.2.
6 Error analysis
In this section, we will discuss the total theoretical error and the total empirical empirical error
between an average of privatized attributes (Equation 5.5) computed by Algorithm 1 and its bias
removal mechanism (Equation 4.4) and an average computed centrally and without privatization.
Firstly, for k,l∈Z, we deﬁne the unbiased averages computed by our approach from privatized
attributes as follows:
Ssa,dp,go
(k,l)=SiGo/parenleftbig
(Ξdp,i,(k,l,−1))n
i=1/parenrightbig
j
SiGo/parenleftbig
(Ξdp,i,(0,0,−1))n
i=1/parenrightbig
j, (similarly as in Equation 4.4) ,(6.1)
where Ξdp,i,(k,l,−1)is deﬁned in Equation 5.5 and j∈[n]is chosen arbitrarily because we assume
that Algorithm 1 is run for enough iterations to converge. We remark that the superscripts in
Ssa,dp,go
(k,l)indicate the presence of the three components that contribute to the error: “sa” stands for
ﬁnite sampling of individual values, “dp” stands for diﬀerential privacy for sensitive attributes and
“go” stands for the application of Algorithm 1 and its bias removal mechanism.
Further, we deﬁne the averages computed centrally, without sampling of individual values and
without privatization as follows:
S(k,l)=1
nn/summationdisplay
i=1Yk
reg,ixl
i, (6.2)
where, fori∈[n],Yreg,iis a random variable with
E[Yreg,i] =yi, (6.3)
var(Yreg,i) =var(Ξreg,i) =l2
reg
12. (6.4)
Theoretical error. Now we deﬁne the total theoretical error as follows:
etheo,total
(k,l)=E/bracketleftbigg/parenleftBig
S(k,l)−Ssa,dp,go
(k,l)/parenrightBig2/bracketrightbigg
,
whereSsa,dp,go
(k,l)is deﬁned in Equation 6.1 and S(k,l)is deﬁned in Equation 6.2.
We will state a theorem on the asymptotic theoretical guarantees for the total theoretical error in
the estimates required for regression.
Theorem 2. For(k,l)∈{(0,1),(0,2),(1,0),(1,1)}, we have
etheo,total
(k,l)=O/parenleftbigg1
n/parenrightbigg
,
when the privacy budget (/epsilon1,δ)is not extremely low and not extremely high.
9Under review as submission to TMLR
We remark that in Theorem 2 we have (k,l)∈{(0,1),(0,2),(1,0),(1,1)}since for ﬁtting a linear
regression model we aim for the estimates ˆµx,ˆµx2,ˆµy,ˆµyxas suggested by Equations 5.3, 5.4.
Thus,etheo,total
(0,1)is related to ˆµx,etheo,total
(0,2)is related to ˆµx2,etheo,total
(1,0)is related to ˆµy, andetheo,total
(1,1)
is related to ˆµyx.
We will sketch the proof of Theorem 2 by decomposing the total error into three components: the
error due to sampling, the error due to diﬀerential privacy noise, and the error due to Algorithm
1 and its bias removal mechanism. We remark that for error decomposition, we have followed the
lecture notes by Rosenberg (2016). We start by applying the triangle inequality as follows:
etheo,total
(k,l)=E/bracketleftbigg/parenleftBig
S(k,l)−Ssa,dp,go
(k,l)/parenrightBig2/bracketrightbigg
≤E/bracketleftbigg/parenleftBig
S(k,l)−ssa
(k,l)/parenrightBig2/bracketrightbigg
+E/bracketleftbigg/parenleftBig
ssa
(k,l)−Ssa,dp
(k,l)/parenrightBig2/bracketrightbigg
+E/bracketleftbigg/parenleftBig
Ssa,dp
(k,l)−Ssa,dp,go
(k,l)/parenrightBig2/bracketrightbigg
,(6.5)
where
ssa
(k,l)=1
nn/summationdisplay
i=1yk
ixl
i, (6.6)
Ssa,dp
(k,l)=1
nn/summationdisplay
i=1Ξdp,i,(k,l,0), (6.7)
Ξdp,i,(k,l,0)isdeﬁnedinEquation5.5, S(k,l)isdeﬁnedinEquation6.2, Ssa,dp,go
(k,l)isdeﬁnedinEquation
6.1, and (k,l)∈ {(0,1),(0,2),(1,0),(1,1)}as required for regression (Equations 5.3, 5.4). We
proceed with deﬁning the theoretical error due to sampling by
etheo,sa
(k,l)=E/bracketleftbigg/parenleftBig
S(k,l)−ssa
(k,l)/parenrightBig2/bracketrightbigg
. (6.8)
In Subsection B.2, we show that
etheo,sa
(k,l)=/braceleftBigg
1
nl2
reg
12µx2lwhenk= 1,
0 whenk= 0.(6.9)
Then, we deﬁne the theoretical error due to diﬀerential privacy by
etheo,dp
(k,l)=E/bracketleftbigg/parenleftBig
ssa
(k,l)−Ssa,dp
(k,l)/parenrightBig2/bracketrightbigg
. (6.10)
In Subsection B.3, we show that
etheo,dp
(k,l)≈1
n˜σ2
dp,(k,l,0), (6.11)
where the clipped standard deviation ˜σdp,(k,l,0)is deﬁned in Equation B.10. Finally, we deﬁne the
theoretical error due to Algorithm 1 and its bias removal mechanism by
etheo,go
(k,l)=E/bracketleftbigg/parenleftBig
Ssa,dp
(k,l)−Ssa,dp,go
(k,l)/parenrightBig2/bracketrightbigg
. (6.12)
10Under review as submission to TMLR
In Subsection B.4, we show that
etheo,go
(k,l)≈1
n˜σ2
dp,(k,l,0)+µ2
ykxl−2µ2
ykxl
µd√n√
2µd√µd2˜σdp,(0,0,−1)fdaw/parenleftbigg√n√2µd2˜σdp,(0,0,−1)/parenrightbigg
+/parenleftBigg
1
nµd2
µ2
d˜σ2
dp,(k,l,−1)+µ2
ykxl
µ2
d/parenrightBigg
nµ2
d
µd2˜σ2
dp,(0,0,−1)/parenleftbigg√n√
2√µd2˜σdp,(0,0,−1)fdaw/parenleftbigg√n√2µd2˜σdp,(0,0,−1)/parenrightbigg
−1/parenrightbigg
,
(6.13)
wherefdaw(x) =e−x2/integraltextx
0et2dtand˜σdp,(0,0,−1)(Equation B.10) is neither close to 0(privacy budget
is extremely high) nor high (privacy budget is extremely low). In Subsections B.2, B.3, B.4 we
conclude that etheo,sa
(k,l),etheo,dp
(k,l)andetheo,dp
(k,l)areO(1
n), thusetheo,total
(k,l)is alsoO(1
n).
Empirical error. We proceed with the deﬁnitions of the empirical errors in a similar way as was
done for the theoretical errors. We deﬁne the empirical error due to sampling:
eemp,sa
(k,l)=/parenleftBigg
1
nn/summationdisplay
i=1(yi−ξreg,i)kxl
i−1
nn/summationdisplay
i=1yk
ixl
i/parenrightBigg2
, (6.14)
where the term (yi−ξreg,i)k= (θ0+θ1xi)kand(k,l)∈{(0,1),(0,2),(1,0),(1,1)}as required for
regression (Equations 5.3, 5.4). Also, we deﬁne the empirical error due to diﬀerential privacy:
eemp,dp
(k,l)=/parenleftBigg
1
nn/summationdisplay
i=1yk
ixl
i−1
nn/summationdisplay
i=1νi,(k,l,0)/parenrightBigg2
. (6.15)
Then, we deﬁne the empirical error due to Algorithm 1 and its bias removal mechanism:
eemp,go
(k,l)=/parenleftBigg
1
nn/summationdisplay
i=1νi,(k,l,0)−SiGo/parenleftbig
(νi,(k,l,−1))n
i=1/parenrightbig
j
SiGo/parenleftbig
(νi,(0,0,−1))n
i=1/parenrightbig
j/parenrightBigg2
, (6.16)
wherej∈[n]is chosen arbitrarily as for the theoretical error. Finally, we combine the three
components to the total empirical error:
eemp,total
(k,l)=/parenleftBigg
1
nn/summationdisplay
i=1(yi−ξreg,i)kxl
i−SiGo/parenleftbig
(νi,(k,l,−1))n
i=1/parenrightbig
j
SiGo/parenleftbig
(νi,(0,0,−1))n
i=1/parenrightbig
j/parenrightBigg2
. (6.17)
7 Experiments
In this section, we will specify our hypotheses and experiments, and interpret the results.
We have conducted two sets of experiments to verify the following hypotheses. The ﬁrst hypothesis
is that the total theoretical error (Equation 6.5) is close to the total empirical error (Equation 6.17).
We state the details of the experiment for verifying it:
Experiment 1. We will obtain the errors due to sampling (Equations 6.14, 6.9), the errors due
to diﬀerential privacy (Equations 6.15, 6.11), the errors due to Algorithm 1 and its bias removal
mechanism (Equations 6.16, 6.13), and the total errors (Equations 6.17, 6.5) for each estimate
ˆµx,ˆµx2,ˆµx,ˆµyx. The vertical axis will be the error scale, and the horizontal axis will indicate
n∈{28,28+ 27,29,29+ 28,210,210+ 29}.
11Under review as submission to TMLR
The second hypothesis is that the regression parameters computed by Algorithm 1 and its bias
removal mechanism lead to a lower mean squared error between the true target values and the
predicted target values (over a test set) compared to the parameters computed by Algorithm 1
without its bias removal mechanism. We state the details of the experiment for verifying it:
Experiment2. We will compare the estimates ˆθ0,ˆθ1(Equation 5.2) obtained using our approach to
a baseline and a naive approach. The comparison will take the mean squared error between the true
target values and and the predicted target values over a test set. In particular, in each experiment
iteration, we will construct a test set by generating a power-law degree vector d/primeof size 27(Subsection
C.3) and generate a vector y/prime
i(Equation 5.1). Then, we will predict y/prime
pred,i=ˆθ0+ˆθ1(d/prime
i−ˆµd)2and
compute the mean squared error1
27/summationtext27
i=1/parenleftbig
y/prime
pred,i−y/prime
i/parenrightbig2. For the baseline, we take the case when
the estimates are computed centrally (Equation 6.6). For a naive approach, we take the case when
the estimates are computed by Algorithm 1 and its bias removal mechanism is disabled. The privacy
budget for the baseline and the naive approach is split in four even parts (the privacy budget in our
approach is split in ﬁve even parts). The vertical axis will indicate the mean squared error, and the
horizontal axis will indicate /epsilon1∈{2−2,20,22,24,26,28}.
We ﬁx the number of experiment repetitions to itexp= 211. Regarding randomization, in every
experiment repetition we generate new features and target values (for synthetic graphs, we generate
a new degree sequence and a new graph). In Subsection C.3, we discuss generation of synthetic
graphs with power-law degree sequences. In Subsection C.4, we provide the values of the remaining
experiments parameters. In Subsection C.5, we provide secondary hypotheses and experiments.
Thesyntheticdataset. InExperiment1, thetotaltheoreticalerrorapproachesthetotalempirical
error, illustrated by Figure 1. (Here, we only interpret the total errors for the estimate ˆµyx, i.e.
(k,l) = (1,1). The remaining interpretations are moved to Subsection C.6). The diﬀerence between
the two errors is mainly due to the approximation using the heuristics (Equations B.15, B.16).
Figure1: Comparisonofthetotalerrors(Equations6.5, 6.17)fortheestimate ˆµyx, i.e. (k,l) = (1,1)
In Experiment 2, the proposed approach performs better than the naive approach upon lower and
higher privacy budget but not an intermediate one, illustrated in Figure 2. This suggests that the
bias suggested by Equation 4.2 can get lower than the error due to diﬀerential privacy, as in the
naive approach the privacy budget is split in four even parts as opposed to ﬁve.
12Under review as submission to TMLR
Figure2: Comparisonofourapproach(Algorithm1anditsbiasremovalmechanism)tothebaseline
(centralized averaging) and the naive approach (Algorithm 1 without its bias removal mechanism)
The experiments on the synthetic dataset were run on a home machine and took 1hour and 43
minutes. The most time consuming operation was the matrix power (last line of Algorithm 1).
The storage is mostly aﬀected by the adjacency matrix of the graph. Our implementation becomes
inappropriate to execute in practical time and ordinary memory when ngets around 213.
The real datasets. We consider the graphs of the email-Eu-core network dataset and the au-
tonomous systems AS-733 dataset, both of which are part of SNAP (Leskovec and Krevl, 2014).
The former graph has 1005vertices, 25571edges and its diameter is 7; and the latter graph has
6474vertices, 13895edges and its diameter is 9. We have processed the graphs by Step 3 of the
procedure described in Subsection C.3 (this guarantees that Algorithm 1 converges and dmaxstays
not too high). We also remove the self-loops. Further, we ﬁx the number of experiment repetitions
toitexp= 27(opposed to itexp= 211since in the experiments on the real datasets we do not
generate graphs).
WewillinterprettheresultsinExperiment2. Algorithm1anditsbiasremovalmechanismperforms
better than the naive approach, illustrated in Figure 3 Unlike for the synthetic dataset, Algorithm
1 with its bias removal mechanism performs better over all evaluated privacy budget values. This is
the case because the average degree in the network is higher than for the synthetic dataset, which
results in a higher bias.
Figure 3: Comparing our approach (Algorithm 1 and its bias removal mechanism) to the baseline
(centralized averaging) and the naive approach (Algorithm 1 without its bias removal mechanism).
The email network dataset is on the left and the autonomous systems dataset is on the right
13Under review as submission to TMLR
The experiment on the real datasets was run on a home machine and took 3minutes for the email
network dataset and 10hours and 45minutes on the autonomous systems dataset.
8 Conclusion
Algorithm 1 with its bias removal mechanism performs better than the naive approach for graphs
with higher average degree partially because in such case the bias outweighs a lower split of the
privacy budget (four rather than ﬁve parts). We remind that the even privacy split is suboptimal.
Further, the application of the Gaussian mechanism to privatize the degrees is suboptimal since
degrees are natural numbers and the Gaussian mechanism produces real values. A more suitable
strategy could be an application of a diﬀerential privacy mechanism that is appropriated for discrete
values, e.g., the discrete Gaussian mechanism proposed by Canonne et al. (2020).
We remark that, in the regression model, features other than xi= (di−µd)2are possible. For this
work, we chose (di−µd)2because such choice guarantees the bias when the averages are computed
by Algorithm 1 and it also leads to convenient clipping as (di−µd)2is non-negative.
Finally, we remark that our approach might be applicable for estimating the unbiased sample
variance which is a U-statistic of degree 2. That is, for z∈Rn, the unbiased sample variance
is deﬁned as1
n(n−1)/summationtext
j>i(zi−zj)2=1
n−1/summationtextn
i(zi−µz)2, and our approach can compute µzand
1
n/summationtextn
i(zi−µz)2.
References
Tuncer C. Aysal, Mehmet E. Yildiz, Anand D. Sarwate, and Anna Scaglione. Broadcast gossip
algorithms for consensus. IEEE Trans. Signal Process. , 57(7):2748–2761, 2009. doi: 10.1109/
TSP.2009.2016247. URL https://doi.org/10.1109/TSP.2009.2016247 .
James Bell, Aurélien Bellet, Adrià Gascón, and Tejas Kulkarni. Private Protocols for U-Statistics
in the Local Model and Beyond. In AISTATS 2020 - 23rd International Conference on Arti-
ﬁcial Intelligence and Statistics , Palermo, Italy, August 2020. URL https://hal.inria.fr/
hal-02310236 .
Aurélien Bellet, Rachid Guerraoui, and Hadrien Hendrikx. Who started this rumor? quantifying
the natural diﬀerential privacy guarantees of gossip protocols. CoRR, abs/1902.07138, 2019. URL
http://arxiv.org/abs/1902.07138 .
Stephen P. Boyd, Arpita Ghosh, Balaji Prabhakar, and Devavrat Shah. Randomized gossip algo-
rithms.IEEE Transactions on Information Theory , 52:2508–2530, 2006.
Clément L. Canonne, Gautam Kamath, and Thomas Steinke. The discrete gaussian for diﬀer-
ential privacy. In Hugo Larochelle, Marc’Aurelio Ranzato, Raia Hadsell, Maria-Florina Bal-
can, and Hsuan-Tien Lin, editors, Advances in Neural Information Processing Systems 33:
Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, Decem-
ber 6-12, 2020, virtual , 2020. URL https://proceedings.neurips.cc/paper/2020/hash/
b53b3a3d6ab90ce0268229151c9bde11-Abstract.html .
14Under review as submission to TMLR
Flavio Chierichetti, Silvio Lattanzi, and Alessandro Panconesi. Rumor spreading in social networks.
Theor. Comput. Sci. , 412(24):2602–2610, 2011. doi: 10.1016/j.tcs.2010.11.001. URL https:
//doi.org/10.1016/j.tcs.2010.11.001 .
Pierre Dellenbach, Aurélien Bellet, and Jan Ramon. Hiding in the crowd: A massively distributed
algorithm for private averaging with malicious adversaries. CoRR, abs/1803.09984, 2018. URL
http://arxiv.org/abs/1803.09984 .
CynthiaDwork, KrishnaramKenthapadi, FrankMcSherry, IlyaMironov, andMoniNaor. Ourdata,
ourselves: Privacy via distributed noise generation. In Advances in Cryptology - EUROCRYPT
2006, 25th Annual International Conference on the Theory and Applications of Cryptographic
Techniques, St. Petersburg, Russia, May 28 - June 1, 2006, Proceedings , pages 486–503, 2006.
doi: 10.1007/11761679\_29. URL https://doi.org/10.1007/11761679_29 .
Cynthia Dwork, Aaron Roth, et al. The algorithmic foundations of diﬀerential privacy. Foundations
and Trends ®in Theoretical Computer Science , 9(3–4):211–407, 2014.
Adrià Gascón, Phillipp Schoppmann, Borja Balle, Mariana Raykova, Jack Doerner, Samee Zahur,
and David Evans. Privacy-preserving distributed linear regression on high-dimensional data.
PoPETs, 2017(4):345–364, 2017. doi: 10.1515/popets-2017-0053. URL https://doi.org/10.
1515/popets-2017-0053 .
George Giakkoupis. Tight bounds for rumor spreading in graphs of a given conductance. In 28th
International Symposium on Theoretical Aspects of Computer Science, STACS 2011, March 10-
12, 2011, Dortmund, Germany , pages 57–68, 2011. doi: 10.4230/LIPIcs.STACS.2011.57. URL
https://doi.org/10.4230/LIPIcs.STACS.2011.57 .
W Keith Hastings. Monte carlo sampling methods using markov chains and their applications.
1970.
Michael Hay, Chao Li, Gerome Miklau, and David D. Jensen. Accurate estimation of the degree
distribution of private networks. In Wei Wang, Hillol Kargupta, Sanjay Ranka, Philip S. Yu, and
Xindong Wu, editors, ICDM 2009, The Ninth IEEE International Conference on Data Mining,
Miami, Florida, USA, 6-9 December 2009 , pages 169–178. IEEE Computer Society, 2009. doi:
10.1109/ICDM.2009.11. URL https://doi.org/10.1109/ICDM.2009.11 .
Michael Hay, Vibhor Rastogi, Gerome Miklau, and Dan Suciu. Boosting the accuracy of diﬀer-
entially private histograms through consistency. Proc. VLDB Endow. , 3(1):1021–1032, 2010.
doi: 10.14778/1920841.1920970. URL http://www.vldb.org/pvldb/vldb2010/pvldb_vol3/
R91.pdf.
Franck Iutzeler, Philippe Ciblat, and Walid Hachem. Analysis of sum-weight-like algorithms for
averaging in wireless sensor networks. IEEE Trans. Signal Process. , 61(11):2802–2814, 2013. doi:
10.1109/TSP.2013.2256904. URL https://doi.org/10.1109/TSP.2013.2256904 .
Márk Jelasity, Alberto Montresor, and Özalp Babaoglu. T-man: Gossip-based fast overlay topology
construction. Computer Networks , 53(13):2321–2339, 2009. doi: 10.1016/j.comnet.2009.03.013.
URL https://doi.org/10.1016/j.comnet.2009.03.013 .
15Under review as submission to TMLR
David Kempe, Alin Dobra, and Johannes Gehrke. Gossip-based computation of aggregate informa-
tion. In44th Symposium on Foundations of Computer Science (FOCS 2003), 11-14 October 2003,
Cambridge, MA, USA, Proceedings , pages 482–491, 2003. doi: 10.1109/SFCS.2003.1238221. URL
https://doi.org/10.1109/SFCS.2003.1238221 .
Anne-Marie Kermarrec and Maarten van Steen. Gossiping in distributed systems. Operating Sys-
tems Review , 41(5):2–7, 2007. doi: 10.1145/1317379.1317381. URL https://doi.org/10.1145/
1317379.1317381 .
Jure Leskovec and Andrej Krevl. SNAP Datasets: Stanford large network dataset collection. http:
//snap.stanford.edu/data , June 2014.
Yehuda Lindell and Benny Pinkas. Secure multiparty computation for privacy-preserving data
mining. J. Priv. Conﬁdentiality , 1(1), 2009. doi: 10.29012/jpc.v1i1.566. URL https://doi.
org/10.29012/jpc.v1i1.566 .
linguisticturn (https://stats.stackexchange.com/users/328865/linguisticturn). Mean and variance
of the reciprocal of a random variable. Cross Validated. URL https://stats.stackexchange.
com/q/535924 . URL:https://stats.stackexchange.com/q/535924 (version: 2021-07-28).
Valeria Nikolaenko, Udi Weinsberg, Stratis Ioannidis, Marc Joye, Dan Boneh, and Nina Taft.
Privacy-preserving ridge regression on hundreds of millions of records. In 2013 IEEE Symposium
on Security and Privacy, SP 2013, Berkeley, CA, USA, May 19-22, 2013 , pages 334–348. IEEE
Computer Society, 2013. doi: 10.1109/SP.2013.30. URL https://doi.org/10.1109/SP.2013.
30.
Roberto Imbuzeiro Oliveira. Concentration of the adjacency matrix and of the laplacian in random
graphs with independent edges. arXiv preprint arXiv:0911.0600 , 2009.
Israel Donato Ridgley, Randy A. Freeman, and Kevin M. Lynch. Simple, private, and accurate
distributed averaging. In 57th Annual Allerton Conference on Communication, Control, and
Computing, Allerton 2019, Monticello, IL, USA, September 24-27, 2019 , pages 446–452. IEEE,
2019. doi: 10.1109/ALLERTON.2019.8919736. URL https://doi.org/10.1109/ALLERTON.
2019.8919736 .
David Rosenberg. Excess risk decomposition, 2016. URL https://www.coursehero.com/file/
13869964/2aexcess-risk-decomposition/ .
16Under review as submission to TMLR
A Notation
Table 1: Summary of general notation
Notation Meaning Comments
x lower-case character indicates a scalar sometimes denotes a map to a scalar
xbolded lower-case character indicates a vector –
Xbolded upper-case character indicates a matrix –
X upper-case character indicates a non-scalar a random variable, a set, ...
xi i-th element of x –
[x] {1,...,x},x∈N –
µxkyl1
n/summationtextn
i=1xk
iyl
i,k,l∈Z notationµxyimpliesk= 1,l= 1
1 vector of 1’s (of appropriate length) –
Table 2: Summary of notation related to graphs
Notation Meaning Comments
V set of vertices a vertex represents an agent
E set of edges an edge represents a link between two agents
G graph equivalent to a tuple (V,E)
nnumber of vertices or order of a graph equivalent to |V|
d (d1,...,dn)(degree sequence) –
dmin lowest degree in a degree sequence –
dmax highest degree in a degree sequence –
B Proofs
B.1 Theorem 1
Proof.Our proof is based on a manipulation of the adjacency matrix which allows for a favorable
eigendecomposition. Even though Tis not symmetric, we can deﬁne
X=diag(d◦1/2)Tdiag(d◦−1/2), (B.1)
where◦denotes the operator for the element-wise power. We remark that Xis symmetric. Both T
andXhave a largest eigenvalue 1, which has multiplicity 1ifGis connected. The right eigenvector
ofTis1, i.e., 1=T1. It follows that
diag(d◦1/2)1=Xdiag(d◦1/2)1,
so diag (d◦1/2)1is an eigenvector of Xwith eigenvalue 1, normalizing this eigenvector gives
v1=diag(d◦1/2)1√nµd, (B.2)
17Under review as submission to TMLR
since/radicalBig/summationtextn
i=1(√di)2=√nµd. We are interested in1
n1TTitgow. As Xis symmetric, it has real
eigenvalues and orthogonal eigenvectors. Let X=UΛUTbe the eigenvalue decomposition of X,
where Λis a diagonal matrix of eigenvalues in decreasing order, implying Λ1,1= 1. We can also
see that U:,1=v1. For a suﬃciently high itgo, it holds that
1
n1TTitgow=1
n1T/parenleftBig
diag(d◦−1/2)Xdiag(d◦1/2)/parenrightBigitgo
w (by Equation B.1)
=1
n1Tdiag(d◦−1/2)Xitgodiag(d◦1/2)w
=1
n1Tdiag(d◦−1/2)UΛitgoUTdiag(d◦1/2)w
≈1Tdiag(d◦−1/2)Udiag(1,0,..., 0)UTdiag(d◦1/2)w
=1
n1Tdiag(d◦−1/2)v1vT
1diag(d◦1/2)w
=1
n1Tdiag(d◦−1/2)diag(d◦1/2)1√nµd1Tdiag(d◦1/2)√nµddiag(d◦1/2)w(by Equation B.2)
=1
nµd1
n(1T1)1Tdiag(d)w
=1
nµd1Tdiag(d)w
=1
n1
µdn/summationdisplay
i=1diwi.
B.2 Error due to sampling
We will provide some guarantees for the theoretical error due to sampling. We ﬁrstly remark the
true average S(k,l)deﬁned in Equation 6.2 involves random variables only for the individual values
yi. The features xiare scalars because they only depend on the degrees diand their mean µd, and
we deﬁne the regression model (Equation 5.1) when the graph of agents is already generated. In
other words, the randomness in the graph generation will not be considered in the error due to
sampling. For (k,l)∈{(0,1),(0,2),(1,0),(1,1)}as required for regression, we have
etheo,sa
(k,l)=E/bracketleftbigg/parenleftBig
S(k,l)−ssa
(k,l)/parenrightBig2/bracketrightbigg
(by Equation 6.8)
=Ei=1,...,n
Yreg,i
/parenleftBigg
1
nn/summationdisplay
i=1Yk
reg,ixl
i−1
nn/summationdisplay
i=1yk
ixl
i/parenrightBigg2
 (by Equations 6.2, 6.6)
=E/bracketleftBig/parenleftbig
S(k,l)−µykxl/parenrightbig2/bracketrightBig
=E/bracketleftBig
S2
(k,l)/bracketrightBig
−2µykxlE/bracketleftbig
S(k,l)/bracketrightbig
+µ2
ykxl. (B.3)
We state a rearranged variance formula that we will use later:
E[Z2] =var(Z) +E2[Z], (B.4)
18Under review as submission to TMLR
whereZis any random variable. Further, for k∈{0,1}, we derive
E[S(k,l)] =E/bracketleftBigg
1
nn/summationdisplay
i=1Yk
reg,ixl
i/bracketrightBigg
=1
nn/summationdisplay
i=1E/bracketleftbig
Yk
reg,i/bracketrightbig
xl
i
=1
nn/summationdisplay
i=1yk
ixl
i (by Equation 6.3)
=µykxl, (B.5)
var/parenleftbig
S(k,l)/parenrightbig
=var/parenleftBigg
1
nn/summationdisplay
i=1Yk
reg,ixl
i/parenrightBigg
=1
n2var/parenleftBiggn/summationdisplay
i=1Yk
reg,ixl
i/parenrightBigg
=1
n2n/summationdisplay
i=1var/parenleftbig
Yk
reg,ixl
i/parenrightbig
=1
n2n/summationdisplay
i=1x2l
ivar/parenleftbig
Yk
reg,i/parenrightbig
=/braceleftBigg
1
n2l2
reg
12/summationtextn
i=1x2l
iwhenk= 1,
0 whenk= 0,(by Equation 6.4)
=/braceleftBigg
1
nl2
reg
12µx2lwhenk= 1,
0 whenk= 0.(B.6)
Now we are ready to continue the derivation of the theoretical error due to sampling:
etheo,sa
(k,l)=E/bracketleftBig
S2
(k,l)/bracketrightBig
−2µykxlE/bracketleftbig
S(k,l)/bracketrightbig
+µ2
ykxl (by Equation B.3)
=var/parenleftbig
S(k,l)/parenrightbig
+E2[S(k,l)]−2µykxlE/bracketleftbig
S(k,l)/bracketrightbig
+µ2
ykxl (by Equation B.4)
=/braceleftBigg
1
nl2
reg
12µx2l+µ2
yxl−2µyxlµyxl+µ2
yxlwhenk= 1,
µ2
xl−2µ2
xl+µ2
xl whenk= 0,(by Equations B.5, B.6)
=/braceleftBigg
1
nl2
reg
12µx2lwhenk= 1,
0 whenk= 0,
We conclude that etheo,sa
(0,l)= 0andetheo,sa
(1,l)=O(1
n).
19Under review as submission to TMLR
B.3 Error due to diﬀerential privacy
We will provide some guarantees for the theoretical error due to diﬀerential privacy. For (k,l)∈
{(0,1),(0,2),(1,0),(1,1)}as required for regression, we have
etheo,dp
(k,l)=E/bracketleftbigg/parenleftBig
ssa
(k,l)−Ssa,dp
(k,l)/parenrightBig2/bracketrightbigg
(by Equation 6.10)
=Ei=1,...,n
Ξdp,i,(k,l,0)
/parenleftBigg
1
nn/summationdisplay
i=1yk
ixl
i−1
nn/summationdisplay
i=1Ξdp,i,(k,l,0)/parenrightBigg2
(by Equations 6.6, 6.7)
=E/bracketleftbigg/parenleftBig
µykxl−Ssa,dp
(k,l)/parenrightBig2/bracketrightbigg
=µ2
ykxl−2µykxlE/bracketleftBig
Ssa,dp
(k,l)/bracketrightBig
+E/bracketleftbigg/parenleftBig
Ssa,dp
(k,l)/parenrightBig2/bracketrightbigg
. (B.7)
We derive
E[Ssa,dp
(k,l)] =E/bracketleftBigg
1
nn/summationdisplay
i=1Ξdp,i,(k,l,0)/bracketrightBigg
=1
nn/summationdisplay
i=1E/bracketleftbig
Ξdp,i,(k,l,0)/bracketrightbig
=1
nn/summationdisplay
i=1yk
ixl
i
=µykxl, (B.8)
var/parenleftBig
Ssa,dp
(k,l)/parenrightBig
=var/parenleftBigg
1
nn/summationdisplay
i=1Ξdp,i,(k,l,0)/parenrightBigg
=1
n2var/parenleftBiggn/summationdisplay
i=1Ξdp,i,(k,l,0)/parenrightBigg
=1
n2n/summationdisplay
i=1var/parenleftbig
Ξdp,i,(k,l,0)/parenrightbig
=1
nσ2
dp,(k,l,0). (by Equation 5.6) (B.9)
However, thevariance σ2
dp,(k,l,m )islargerthanwhatwehaveinpracticebecauseweclipthesensitive
attributes as discussed in Subsection C.2. Since we use the Gaussian mechanism where diﬀerential
privacy noise comes from the normal distribution, we approximate the variance of the clipped
privatized attributes using the formula for the variance of the truncated normal distribution. This
way, fori∈[n]and appropriate k,l,m, we have
˜σ2
dp,(k,l,m )=σ2
dp,(k,l,m )/parenleftBigg
1 +αφ(α)−βφ(β)
ω(β)−ω(α)−/parenleftbiggφ(α)−φ(β)
ω(β)−ω(α)/parenrightbigg2/parenrightBigg
, (B.10)
20Under review as submission to TMLR
whereα=a−νi,(k,l,m )
σdp,(k,l,m ),β=b−νi,(k,l,m )
σdp,(k,l,m ),ais the lowest value to which νi,(k,l,m )is clipped,bis the
highest value to which νi,(k,l,m )is clipped, φis the probability density function of the standard
normal distribution and ωis the cumulative distribution of the standard normal distribution.
Weremarkthatweapproximatethevarianceoftheclippedprivatizedattributesthatweregenerated
from the Gaussian mechanism as opposed to generating the privatized attributes from the truncated
normal distribution since we have not found the diﬀerential privacy guarantees for the truncated
normal distribution.
Now we are ready to continue the derivation of the theoretical error due to diﬀerential privacy:
etheo,dp
(k,l)=µ2
ykxl−2µykxlE/bracketleftBig
Ssa,dp
(k,l)/bracketrightBig
+E/bracketleftbigg/parenleftBig
Ssa,dp
(k,l)/parenrightBig2/bracketrightbigg
(by Equation B.7)
=µ2
ykxl−2µykxlE/bracketleftBig
Ssa,dp
(k,l)/bracketrightBig
+var/parenleftBig
Ssa,dp
(k,l)/parenrightBig
+E2[Ssa,dp
(k,l)] (by Equation B.4)
≈µ2
ykxl−2µ2
ykxl+1
n˜σ2
dp,(k,l,0)+µ2
ykxl (by Equations B.10, B.8)
=1
n˜σ2
dp,(k,l,0).
We conclude that etheo,dp
(k,l)=O(1
n).
21Under review as submission to TMLR
B.4 Error due to Algorithm 1 and its bias removal mechanism
We will provide some guarantees for the theoretical error due to Algorithm 1 and its bias removal
mechanism. For (k,l)∈{(0,1),(0,2),(1,0),(1,1)}as required for regression, we have
etheo,go
(k,l)=E/bracketleftbigg/parenleftBig
Ssa,dp
(k,l)−Ssa,dp,go
(k,l)/parenrightBig2/bracketrightbigg
(by Equation 6.12)
=Ei=1,...,n
Ξdp,i,(k,l,0),
Ξdp,i,(k,l,−1),
Ξdp,i,(0,0,−1)
/parenleftBigg
1
nn/summationdisplay
i=1Ξdp,i,(k,l,0)−SiGo/parenleftbig
(Ξdp,i,(k,l,−1))n
i=1/parenrightbig
j
SiGo/parenleftbig
(Ξdp,i,(0,0,−1))n
i=1/parenrightbig
j/parenrightBigg2
 (by Equations 6.7, 6.1)
=E/bracketleftbigg/parenleftBig
Ssa,dp
(k,l)/parenrightBig2/bracketrightbigg
+E/bracketleftbigg/parenleftBig
Ssa,dp,go
(k,l)/parenrightBig2/bracketrightbigg
−2E/bracketleftBig
Ssa,dp
(k,l)Ssa,dp,go
(k,l)/bracketrightBig
=E/bracketleftbigg/parenleftBig
Ssa,dp
(k,l)/parenrightBig2/bracketrightbigg
+E/bracketleftbigg/parenleftBig
SiGo/parenleftbig
(Ξdp,i,(k,l,−1))n
i=1/parenrightbig
j/parenrightBig2/bracketrightbigg
E
/parenleftBigg
1
SiGo/parenleftbig
(Ξdp,i,(0,0,−1))n
i=1/parenrightbig
j/parenrightBigg2

−2E/bracketleftBig
Ssa,dp
(k,l)/bracketrightBig
E/bracketleftBig
SiGo/parenleftbig
(Ξdp,i,(k,l,−1))n
i=1/parenrightbig
j/bracketrightBig
E/bracketleftBigg
1
SiGo/parenleftbig
(Ξdp,i,(0,0,−1))n
i=1/parenrightbig
j/bracketrightBigg
≈E/bracketleftbigg/parenleftBig
Ssa,dp
(k,l)/parenrightBig2/bracketrightbigg
+E
/parenleftBigg
1
n1
µdn/summationdisplay
i=1diΞdp,i,(k,l,−1)/parenrightBigg2
E
/parenleftBigg
1
1
n1
µd/summationtextn
i=1diΞdp,i,(0,0,−1)/parenrightBigg2
 (by Theorem 1)
−2E/bracketleftBig
Ssa,dp
(k,l)/bracketrightBig
E/bracketleftBigg
1
n1
µdn/summationdisplay
i=1diΞdp,i,(k,l,−1)/bracketrightBigg
E/bracketleftBigg
1
1
n1
µd/summationtextn
i=1diΞdp,i,(0,0,−1)/bracketrightBigg
(B.11)
We express
E/bracketleftBigg
1
n1
µdn/summationdisplay
i=1diΞdp,i,(k,l,−1)/bracketrightBigg
=1
n1
µdn/summationdisplay
i=1diE/bracketleftbig
Ξdp,i,(k,l,−1)/bracketrightbig
=µykxl
µd, (by Equation 5.5) (B.12)
var/parenleftBigg
1
n1
µdn/summationdisplay
i=1diΞdp,i,(k,l,−1)/parenrightBigg
=1
n21
µ2
dn/summationdisplay
i=1d2
ivar/parenleftbig
Ξdp,i,(k,l,−1)/parenrightbig
=1
nµd2
µ2
d˜σ2
dp,(k,l,−1). (by Equation B.10) (B.13)
22Under review as submission to TMLR
Thus,
E
/parenleftBigg
1
n1
µdn/summationdisplay
i=1diΞdp,i,(k,l,−1)/parenrightBigg2

=var/parenleftBigg
1
n1
µdn/summationdisplay
i=1diΞdp,i,(k,l,−1)/parenrightBigg
+E2/bracketleftBigg
1
n1
µdn/summationdisplay
i=1diΞdp,i,(k,l,−1)/bracketrightBigg
(by Equations B.4)
=1
nµd2
µ2
d˜σ2
dp,(k,l,−1)+µ2
ykxl
µ2
d. (by Equations B.10, B.12)
(B.14)
We state some heuristics for a Gaussian variable Zwith mean µand variance σ2(µandσare not
too close to 0andσnot too high):
E/bracketleftbigg1
Z/bracketrightbigg
≈√
2
σfdaw/parenleftbiggµ√
2σ/parenrightbigg
, (B.15)
E/bracketleftbigg1
Z2/bracketrightbigg
≈1
σ2/parenleftbigg
µ√
2
σfdaw/parenleftbiggµ√
2σ/parenrightbigg
−1/parenrightbigg
, (B.16)
wherefdaw(x) =e−x2/integraltextx
0et2dtis known as the Dawson function, and the comparison
of the heuristics to a sample of1
Zis performed on stats stack exchange (linguisticturn ,
https://stats.stackexchange.com/users/328865/linguisticturn). This way,
E/bracketleftBigg
1
1
n1
µd/summationtextn
i=1diΞdp,i,(0,0,−1)/bracketrightBigg
≈√
2/radicalBig
1
nµd2
µ2
d˜σ2
dp,(0,0,−1)fdaw
1
µd√
2/radicalBig
1
nµd2
µ2
d˜σ2
dp,(0,0,−1)
(by Equations B.15, B.12, B.13)
=√n√
2µd√µd2˜σdp,(0,0,−1)fdaw/parenleftbigg√n√2µd2˜σdp,(0,0,−1)/parenrightbigg
, (B.17)
E
/parenleftBigg
1
1
n1
µd/summationtextn
i=1diΞdp,i,(0,0,−1)/parenrightBigg2

≈1
1
nµd2
µ2
d˜σ2
dp,(0,0,−1)
1
µd√
2/radicalBig
1
nµd2
µ2
d˜σ2
dp,(0,0,−1)fdaw
1
µd√
2/radicalBig
1
nµd2
µ2
d˜σ2
dp,(0,0,−1)
−1
(by Equations B.16, B.12, B.13)
=nµ2
d
µd2˜σ2
dp,(0,0,−1)/parenleftbigg√n√
2√µd2˜σdp,(0,0,−1)fdaw/parenleftbigg√n√2µd2˜σdp,(0,0,−1)/parenrightbigg
−1/parenrightbigg
. (B.18)
23Under review as submission to TMLR
We continue the derivation of the theoretical error due to Algorithm 1 and its bias removal mech-
anism from Equation B.11:
etheo,go
(k,l)≈E/bracketleftbigg/parenleftBig
Ssa,dp
(k,l)/parenrightBig2/bracketrightbigg
−2E/bracketleftBig
Ssa,dp
(k,l)/bracketrightBig
E/bracketleftBigg
1
n1
µdn/summationdisplay
i=1diΞdp,i,(k,l,−1)/bracketrightBigg
E/bracketleftBigg
1
1
n1
µd/summationtextn
i=1diΞdp,i,(0,0,−1)/bracketrightBigg
+E
/parenleftBigg
1
n1
µdn/summationdisplay
i=1diΞdp,i,(k,l,−1)/parenrightBigg2
E
/parenleftBigg
1
1
n1
µd/summationtextn
i=1diΞdp,i,(0,0,−1)/parenrightBigg2

=E/bracketleftbigg/parenleftBig
Ssa,dp
(k,l)/parenrightBig2/bracketrightbigg
−2E/bracketleftBig
Ssa,dp
(0,1)/bracketrightBigµykxl
µd√n√
2µd√µd2˜σdp,(0,0,−1)fdaw/parenleftbigg√n√2µd2˜σdp,(0,0,−1)/parenrightbigg
(by Equations B.12, B.17)
+/parenleftBigg
1
nµd2
µ2
d˜σ2
dp,(k,l,−1)+µ2
ykxl
µ2
d/parenrightBigg
nµ2
d
µd2˜σ2
dp,(0,0,−1)/parenleftbigg√n√
2√µd2˜σdp,(0,0,−1)fdaw/parenleftbigg√n√2µd2˜σdp,(0,0,−1)/parenrightbigg
−1/parenrightbigg
(by Equations B.14, B.18)
=1
n˜σ2
dp,(k,l,0)+µ2
ykxl−2µ2
ykxl
µd√n√
2µd√µd2˜σdp,(0,0,−1)fdaw/parenleftbigg√n√2µd2˜σdp,(0,0,−1)/parenrightbigg
(by Equations B.4, B.9, B.8)
+/parenleftBigg
1
nµd2
µ2
d˜σ2
dp,(k,l,−1)+µ2
ykxl
µ2
d/parenrightBigg
nµ2
d
µd2˜σ2
dp,(0,0,−1)/parenleftbigg√n√
2√µd2˜σdp,(0,0,−1)fdaw/parenleftbigg√n√2µd2˜σdp,(0,0,−1)/parenrightbigg
−1/parenrightbigg
.
Since our analysis relies on the heuristics so that
√n√
2µd√µd2˜σdp,(0,0,−1)fdaw/parenleftbigg√n√2µd2˜σdp,(0,0,−1)/parenrightbigg
≈µd
and
nµ2
d
µd2˜σ2
dp,(0,0,−1)/parenleftbigg√n√
2√µd2˜σdp,(0,0,−1)fdaw/parenleftbigg√n√2µd2˜σdp,(0,0,−1)/parenrightbigg
−1/parenrightbigg
≈µ2
d+1
n˜σ2
dp,(k,l,−1),
we state a weak conclusion that etheo,go
(k,l)=O(1
n). We support this claim by indicating that
fdaw(√n) =O(1√n)and
/parenleftbigg√n√
2√µd2˜σdp,(0,0,−1)fdaw/parenleftbigg√n√2µd2˜σdp,(0,0,−1)/parenrightbigg
−1/parenrightbigg
≈µd
µd−1 = 0,
which result in etheo,go
(k,l)=O(1
n).
C Secondary material
C.1 Sensitivity derivations
We will use the Gaussian mechanism for generating diﬀerential privacy noise, thus will derive the
sensitivity terms for the ﬁve sensitive attributes. We note that the sensitivity terms 2.1involves
the identity functions because we are concerned with local diﬀerential privacy. We give a list of
individual descriptions:
24Under review as submission to TMLR
•The sensitive attribute d−1
i. We assume that dmin= 3. Based on Deﬁnition 4, adjacents
datasets of graph data diﬀer in 1edge, thus
∆2(d−1) = arg max
d/prime∈[dmin,dmax]/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
d/prime−1
d/prime+ 1/vextenddouble/vextenddouble/vextenddouble/vextenddouble
2
=/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
dmin(dmin+ 1)/vextenddouble/vextenddouble/vextenddouble/vextenddouble
2
=1
12
•The sensitive attribute xid−1
i. Firstly, we assume that ∆2(xd−1)≤2∆2(x)∆2(d−1)claim-
ing that, for scalars a≥a/prime≥0andb≥b/prime≥0, we have
(ab−a/primeb/prime)≤2ab+ 2a/primeb/prime−a/primeb−ab/prime
= 2(a−a/prime)(b−b/prime)
⇐⇒ab+ 3a/primeb/prime≥a/primeb+ab/prime.
Then,
∆2(x) = arg max
d/prime∈[dmin,dmax]/vextenddouble/vextenddouble(d/prime−µd)2−(d/prime+ 1−µd)2/vextenddouble/vextenddouble
2
=/vextenddouble/vextenddouble(dmax−µd)2−(dmax+ 1−µd)2/vextenddouble/vextenddouble
2
•The sensitive attribute x2
id−1
i. Similarly as for the sensitive attribute xid−1
i, we assume
that ∆2(x2d−1)≤2∆2(x2)∆2(d−1), where
∆2(x2) = arg max
d/prime∈[dmin,dmax]/vextenddouble/vextenddouble(d/prime−µd)4−(d/prime+ 1−µd)4/vextenddouble/vextenddouble
2
=/vextenddouble/vextenddouble(dmax−µd)4−(dmax+ 1−µd)4/vextenddouble/vextenddouble
2
•The sensitive attribute yd−1
i. Similarly as for the sensitive attribute xid−1
i, we assume that
∆2(yd−1)≤2∆2(y)∆2(d−1). Then, we claim that
∆2(y) =lreg,
as that’s the largest diﬀerence between two independent values of regression noise, and
state that in our setting the agents know lreg(otherwise the agents could not compute this
sensitivity). We highlight that in our setting every agent iknows its individual target value
yi=θ0+θ1xi+ξreg,ithough not its individual components θ0,θ1,µdandξreg,i. We assume
thatθ1is suﬃciently lower than lregso that the inﬂuence of the sensitive attribute diin
∆2(y)is insigniﬁcant (and thus absent in the calculation) as θ1xiis already hidden under
regression noise
•The sensitive attribute yixid−1
i. Similarly as for the sensitive attribute xid−1
i, we assume
that ∆2(yxd−1)≤3∆2(y)∆2(x)∆2(d−1), though here we have a coeﬃcient 3because we
have three sensitivity terms as opposed to two
25Under review as submission to TMLR
C.2 Clipping of diﬀerentially private values
We describe the clipping of the ﬁve privatized inputs needed for regression: νi,(0,0,−1),νi,(0,1,−1),
νi,(0,2,−1),νi,(1,0,−1),νi,(1,1,−1). Our sensitive attributes do not span over the set of real numbers,
thus the privatized values should stay in the original domains as the sensitive attributes. We
have thatd−1≥1
dmaxbecause we had ﬁxed dmax. Then, we have xi= (di−µd)2≥0and
x2
i= (di−µd)4≥0because squared real numbers are always non-negative. Finally, we assume
thatyi≥0.
We will clip the privatized inputs at their bounds, though above we listed only the lower bounds
of the elements of the sensitive attributes, and clipping them only at the lower bound would shift
away (bias) the mean of the privatized attributes from the mean of the sensitive attributes. To
avoid this shift, we ﬁx upper bounds at the distance equal to the diﬀerence between a sensitive
attribute and its lowers bound. This way, for i∈N,
1
dmax≤νi,(0,0,−1)≤νi,(0,0,−1)+/parenleftbigg
νi,(0,0,−1)−1
dmax/parenrightbigg
= 2νi,(0,0,−1)−1
dmax,
0≤νi,(0,1,−1)≤2νi,(0,1,−1),
0≤νi,(0,2,−1)≤2νi,(0,2,−1),
0≤νi,(1,0,−1)≤2νi,(1,0,−1),
0≤νi,(1,1,−1)≤2νi,(1,1,−1).
C.3 Generation of graph datasets with power-law degree sequences
We describe the procedure that we followed to generate graphs with power-law degree sequences:
1. We generate a power-law degree sequence d/prime= (d/prime
1,...,d/prime
n)whose every element is gener-
ated (drawn independently) from the following probability distribution:
fpow(d/prime|γ) =d/prime−γ
/summationtextdmax−3
d/prime=1d/prime−γ,
whereγ >1andthe support ofthe distributionis [1,dmax−3]. We remark thata power-law
degree sequence is characterized by a higher proportion of vertices being attributed with
lower degrees and a lower proportion of vertices being attributed with higher degrees
2. We generate a graph using the conﬁguration model (Deﬁnition 1), parametrizing it with
the degree sequence previously generated power-law degree sequence
3. Fori∈[n], we check if di>dmax−3and if so remove arbitrary edges that involve vertex
iuntildi=dmax−3. Then, for i∈[n−1], we add edge (vi,vi+1); and fori=n, we add
edge (vn,v1)so that there is at least one cycle in the graph, which guarantees that the
graph is connected. If, for example, edge (vi,vi+1)was already present, we would try to
add a subsequent edge that is absent, that is, we would check edges (vi,vi+2),(vi,vi+3),
...,(vi,vi−1). This guarantees that the degree of each vertex increases by 2. Further, if
edge (v1,v3)is absent, we add it also because this guarantees that there is at least one
cycle of odd length in the graph, as the presence of edges (v1,v2),(v2,v3)is assured by
26Under review as submission to TMLR
the previously mentioned procedure that connects the graph. Finally, if the degrees of
some vertices are still lower than 3, we add some arbitrary edges so that the degree of
every vertex is at least 3. Since the resulting graph is connected and has at least one cycle
of odd length, the principles of DeGroot learning suggest that the averages computed by
Algorithm 1 will eventually involve the values of all agents in the network and thus the
algorithm will converge. We denote the degree sequence that results after the addition and
removal edges by d= (d1,...,dn). We remark that min(d) =dmin= 3andmax(d) =dmax
C.4 Remaining experiment parameters
We list the values to which we will ﬁx the parameters of the experiment setting (unless indicated
diﬀerently in experiment descriptions):
•The order of the graph: n= 210
•The diﬀerential privacy parameters: (/epsilon1,δ) = (22,2−7)
•The number of gossip iterations: itgo= 210
•The signiﬁcance level αci= 0.05. We will compute the conﬁdence intervals based on
Student’st-distribution. Thatis,foravector zoflength itexpandwhoseelementsarescalars
(e.g., mean squared errors), we have the conﬁdence interval [µz−lci/2,µz+lci/2], whereµz
andσzare the sample mean and the unbiased sample standard deviation computed from
the elements of z,
lci= 2q/parenleftBig
1−αci
2|itexp−1/parenrightBigσz/radicalbigitexp
is the length of the conﬁdence interval and qis the quantile function of Student’s t-
distribution
•The true parameters of the regression model: θ0= 212,θ1= 20
•The length of the support of the uniform distribution for regression noise: lreg= 23
•The scale parameter of the probability distribution used to generate the degree sequence:
γ= 2
•The highest degree: dmax= 26
C.5 Secondary hypotheses and experiments
We have conducted two sets of experiments to verify the following secondary hypotheses.
Thethird(intotal)hypothesisisthatlargergraphsleadtomorepreciseestimationsoftheregression
parameters. We state the details of the experiment for verifying it:
Experiment 3. Similarly as in Experiment 2, we will evaluate the estimates ˆθ0,ˆθ1expressed
in Equation 5.2 by computing the mean squared error between the true values and the predicted
values over a test set. In the illustration, we will have a curve for each parameter γ∈{2,3,4}.
The vertical axis will indicate the mean squared error, and the horizontal axis will indicate n∈
{28,28+ 27,29,29+ 28,210,210+ 29}.
27Under review as submission to TMLR
The fourth hypothesis is that the number of gossip iterations approximately equal to the logarithm
of the number of vertices of a graph with a power-law degree sequence is suﬃcient for Algorithm 1
to converge. We state the details of the experiment for verifying it:
Experiment 4. We will evaluate the variance of the sample that contains the estimates ˆθ1obtained
over all agents. This variance indicates the convergence of Algorithm 1 because the computation of
ˆθ1involves all four estimates ˆµx,ˆµx2,ˆµy,ˆµyx. In the illustration, we will have a curve for each
parameter itgo∈{24≈log 210,210,211}. The vertical axis will indicate the variance of the elements
ofˆθ1, and the horizontal axis will indicate n∈{28,28+ 27,29,29+ 28,210,210+ 29}.
We interpret the results on Experiment 3 on the synthetic dataset. The mean squared error de-
creases when the number of vertices increases, illustrated in Figure 4. The illustration also suggests
that the decrease is smoother when the scale parameter γis lower. This happens because for higher
γthe degree sequence is likely to miss some higher values in the interval [dmin,dmax], and thus the
estimates ˆθ0,ˆθ1will lead to a poor ﬁt once the test set happens to include a feature computed using
a degree value that was absent upon computing the estimates for the initial ﬁt. However, for γ= 2
and lowernvalues we still have wider conﬁdence intervals which is also caused by a poor ﬁt.
Figure 4: Comparison of the mean squared errors between the true values and the predicted values
(over a test set) over several choices of γ
We interpret the results on Experiment 4 on the synthetic dataset. The variance of the sample
that contains the estimates θ1over all agents approaches a limit once itgoreaches 210, illustrated in
Figure 5. As observed in Experiment 2, for lower nvalues the conﬁdence intervals are wider due to
a poor ﬁt. For this reason, we evaluate the convergence looking at higher nvalues. When itgo= 24,
the variance of the parameter estimates is already signiﬁcantly low though not yet at the limit.
28Under review as submission to TMLR
Figure 5: Comparison of the variance of the sample that contains the estimates ˆθ1(over all agents)
over several choices of itgo
The complete run of experiments on the synthetic dataset performed on a home machine took 5
hours and 45minutes.
We interpret the results on Experiment 1 in on the real datasets. In Table 3, we provide the details
of the convergence on the real graph datasets. We remark that itgo= 24is not enough for Algorithm
1 to converge on the autonomous systems dataset. The better performance on the email network
dataset can be explained by the presence of a lower diameter.
Table 3: Comparison of the variance of the sample that contains the estimates ˆθ1(over all agents)
over several choices of itgo
itgovar(ˆθ1)(email network) var(ˆθ1)(autonomous systems)
24≈10−3≈102
210≈10−30≈10−15
211≈10−30≈10−28
The complete run of experiments on the real datasets performed on a home machine and took 5
minutes for the email network dataset and 19hours and 58minutes on the autonomous systems
dataset.
C.6 Continuation of Experiment 1 on the synthetic dataset
We will interpret the remaining results on Experiment 1. The theoretical errors for the estimates
of the U-statistics required for regression approximate the empirical errors signiﬁcantly closely, as
illustrated by Figures 6, 7, 8, 9. In Figure 6, we observe that the theoretical error due to sampling
is very close to the empirical error. In Figure 7, the theoretical error due to diﬀerential privacy
is sometimes lower than the empirical error. This eﬀect comes from the approximation (Equation
B.10) of the variance of the clipped noisy values, which neglects the fact that a signiﬁcant portion
of clipped noisy values should be at the extremes of the interval (the shape of the probability
distributionshouldhaveincreasingcurvesattheboundariesasopposedtothedrasticdisappearance
of the tails as in the truncated normal distribution). In Figure 8, the theoretical error due to
Algorithm 1 and its bias removal mechanism is sometimes lower than the empirical error. This
29Under review as submission to TMLR
eﬀect comes from the same reason as for the error due to diﬀerential privacy noise and also due
to the use of the approximation for the reciprocal of a random value obtained from the heuristics
given in Equations B.15, B.16. The heuristics worsen when the mean of the random variable gets
closer to 0, which, in our case, happens when dmaxincreases. The total error is illustrated in Figure
9.
Figure 6: Comparison of the theoretical error and the empirical error due to sampling (Equations
6.8, 6.14) for the estimate ˆµy,ˆµyx
Figure 7: Comparison of the theoretical error and the empirical error due to diﬀerential privacy
(Equations 6.10, 6.15) for the estimates ˆµx,ˆµx2,ˆµy,ˆµyx
30Under review as submission to TMLR
Figure 8: Comparison of the theoretical error and the empirical error due to Algorithm 1 and its
bias removal mechanism (Equations 6.10, 6.15) for the estimates ˆµx,ˆµx2,ˆµy,ˆµyx
Figure 9: Comparison of the total errors (Equations 6.5, 6.17) for the estimates ˆµx,ˆµx2,ˆµy,ˆµyx
31