Published in Transactions on Machine Learning Research (07/2023)
A Unified Perspective on Natural Gradient
Variational Inference with Gaussian Mixture Models
Oleg Arenz oleg.arenz@tu-darmstadt.de
Intelligent Autonomous Systems
Technical University of Darmstadt
Philipp Dahlinger philipp.dahlinger@kit.edu
Autonomous Learning Robots
Karlsruhe Institute of Technology
Zihan Ye zihan.ye@tu-darmstadt.de
Artificial Intelligence & Machine Learning
Hessian Center for AI (hessian.AI)
Technical University of Darmstadt
Michael Volpp michael.volpp@kit.edu
Gerhard Neumann gerhard.neumann@kit.edu
Autonomous Learning Robots
Karlsruhe Institute of Technology
Reviewed on OpenReview: https: // openreview. net/ forum? id= tLBjsX4tjs
Abstract
Variational inference with Gaussian mixture models (GMMs) enables learning of highly
tractableyetmulti-modalapproximationsofintractabletargetdistributionswithuptoafew
hundred dimensions. The two currently most effective methods for GMM-based variational
inference, VIPS and iBayes-GMM, both employ independent natural gradient updates for
the individual components and their weights. We show for the first time, that their derived
updates are equivalent, although their practical implementations and theoretical guarantees
differ. We identify several design choices that distinguish both approaches, namely with
respect to sample selection, natural gradient estimation, stepsize adaptation, and whether
trust regions are enforced or the number of components adapted. We argue that for both
approaches, the quality of the learned approximations can heavily suffer from the respective
design choices: By updating the individual components using samples from the mixture
model, iBayes-GMM often fails to produce meaningful updates to low-weight components,
and by using a zero-order method for estimating the natural gradient, VIPS scales badly
to higher-dimensional problems. Furthermore, we show that information-geometric trust-
regions (used by VIPS) are effective even when using first-order natural gradient estimates,
and often outperform the improved Bayesian learning rule (iBLR) update used by iBayes-
GMM. We systematically evaluate the effects of design choices and show that a hybrid
approach significantly outperforms both prior works. Along with this work, we publish our
highly modular and efficient implementation for natural gradient variational inference with
Gaussian mixture models, which supports 432different combinations of design choices, facil-
itates the reproduction of all our experiments, and may prove valuable for the practitioner.
1Published in Transactions on Machine Learning Research (07/2023)
1 Introduction
Many problems in machine learning involve inference from intractable distributions p(x), that might further
only be known up to a normalizing constant Z, that is,p(x) =1
Z˜p(x). For example when learning latent vari-
able models, ˜p(x)corresponds to the intractable distribution over the latent variable (Volpp et al., 2023); and
in maximum entropy reinforcement learning, ˜p(x)corresponds to the exponentiated return, ˜p(x) = expR(x)
of trajectory x(Ziebart, 2010). Bayesian inference is another example, where the intractable, unnormalized
target distribution ˜p(x)corresponds to the product of prior and likelihood. However, whereas in Bayesian
inference, there is particular interest in scaling to high-dimensional problems and large datasets, we stress
that our work considers problems of moderate dimensionality of up to a few hundred of dimensions, where
modeling the full covariance matrix of Gaussian distributions is still tractable. Important applications can be
found, for example, in robotics—where p(x)could be a multimodal distribution over joint-configurations that
reach the desired pose (Pignat et al., 2020) or over collision-free motions that reach a given goal (Ewerton
et al., 2020)—, or in non-amortized variational inference for latent variable models (Volpp et al., 2023).
Variational inference (VI) aims to approximate the intractable target distribution ˜p(x)by means of a
tractable, parametric model ˜qθ(x), with parameters θ. Variational inference is typically framed as the
problem of maximizing the evidence lower bound objective (ELBO), which is equivalent to minimizing the
reverse Kullback-Leibler (KL) divergence (Kullback and Leibler, 1951), KL (qθ||p), between approximation
qθand target distribution p. The reverse KL divergence is a principled choice for the optimization prob-
lem, as it directly corresponds to the average amount of information (measured in nats), that samples from
the approximation qθ(x)contain for discriminating between the approximation and the target distribu-
tion. In this work, we focus on a particular choice of variational distribution—a Gaussian mixture model
qθ(x) =/summationtext
oqθ(o)qθ(x|o)with weights qθ(o)and Gaussian components qθ(x|o). The ELBO is then given by
J(θ) =/summationdisplay
oqθ(o)/integraldisplay
xqθ(x|o) log ˜p(x)dx+H(qθ), (1)
whereH(qθ) =−/integraltext
xqθ(x) log(qθ(x))dxdenotes the entropy of the GMM. Hence, this work studies the
problem of maximizing Equation 1 with respect to the parameters θ, which correspond to the weights q(o)
and the mean and covariance matrix for each Gaussian component q(x|o).
Gaussian mixture models are a simple yet powerful choice for a model family since they can approximate
arbitrary distributions when assuming a sufficiently high number of components. Compared to more complex
models, such as normalizing flows (Kobyzev et al., 2020), they are more interpretable and tractable since not
only sampling and evaluating GMMs is cheap, but also marginalizations and certain expectations (of linear
or quadratic functions) can be computed in closed form. Furthermore, the simplicity of GMMs allows for
sample-efficient learning algorithms, that is, algorithms that require relatively few evaluations of the target
distribution for learning the model parameters θ. GMM-based variational inference is, in particular, relevant
for problem settings with up to a few hundred dimensions (Volpp et al., 2023; Ewerton et al., 2020; Pignat
et al., 2020), where learning and storing of full covariance matrices is still tractable.
Arguably the two most effective algorithms for maximizing Equation 1, both apply independent natural
gradient (NG) updates on each component as well as on the categorical distribution over weights (Arenz
et al., 2018; Lin et al., 2019a). Yet, both algorithms were derived from a different perspective, have different
theoretical guarantees, and even different objectives for the independent updates. Namely, iBayes-GMM (Lin
et al., 2019a; 2020) uses the original GMM objective (Eq. 1) for each independent update to perform natural
gradient descent also with respect to the full mixture model, whereas VIPS (Arenz et al., 2018; 2020) uses
a lower bound for an expectation-maximization procedure, which yields independent objective functions for
each component and the mixture weights. Their approach can be shown to converge, even when the M-Step
does not consist of single natural gradient updates. However, it was not yet proven, that their proposed
procedure, which does use single NG steps, also performs natural gradient descent on the full mixture.
In this work, we will further explore the previous works iBayes-GMM (Lin et al., 2019a; 2020) and
VIPS (Arenz et al., 2018; 2020), and use our findings to derive a generalized method that outperforms
both of them. In particular, we will present the following contributions.
2Published in Transactions on Machine Learning Research (07/2023)
•In Section 2, we will review and compare the derived update equations of IBayesGMM (Section 2.1) and
VIPS (Section 2.2) without considerations of implementation details and design choices. We will prove
in Section 2.3 that these update equations are actually equivalent and, therefore, the methods only differ
due to design choices not mandated by the derivations. By connecting these two previously separated
lines of research, we improve our theoretical understanding of GMM-based VI.
•In Section 3 we will present a general framework for learning a GMM approximation based on the up-
date equations discussed in Section 2. Our framework uses seven modules to independently select design
choices, for example, regarding how samples are selected, how natural gradients are estimated or how
the learning rate or the number of components is adapted. For each design choice, we will review and
compare the different options that have been used in prior works, and we will discuss potential limita-
tions. For example, VIPS uses an inefficient zero-order method for estimating natural gradients, whereas
IBayesGMM updates the individual components based on samples from current GMM approximation,
which can prevent component with low weight from receiving meaningful updates.
•In Section 4, we evaluate several design choices based on a highly modular implementation of our gen-
eralized framework. We propose a novel combination of design choices and show that it significantly
outperforms both prior methods. In particular, we combine KL-constrained trust regions, which have
been popularized in the gradient-free reinforcement learning setting (Peters et al., 2010; Schulman et al.,
2015; Otto et al., 2021), with gradient-based estimates of the NG (Lin et al., 2019b), use samples from
each component and adapt the number of components. Test problems are used from both prior works.
•We release the open-source implementation of our generalized framework for GMM-based VI. Our imple-
mentation allows each design choice to be set independently and outperforms the reference implementa-
tions of iBayes-GMM and VIPS when using their respective design choices. A separate reproducibility
packagecontainsthescriptsweusedforstartingeachexperiment, includinghyperparameteroptimization.
2 Two Derivations for the Same Updates
MaximizingtheELBOinEq.1withrespecttothewholemixturemodelcanbereducedtoindividualupdates
of the components and the weight distribution (Arenz et al., 2018; Lin et al., 2019a). VIPS (Arenz et al.,
2018) achieves this reduction using a lower-bound objective for an expectation-maximization procedure. In
contrast, Lin et al. (2019a) investigated the natural gradient of Eq. 1 with respect to the GMM parameters
and showed that it can be estimated independently for the parameters of the individual components and
the parameters of the weight distribution. While both decompositions can be applied to larger classes of
latent variable models, in the following we restrict our discussion to Gaussian mixture models. We will
briefly review the different derivations in Section 2.1 and 2.2 before presenting our main theoretical result
in Section 2.3, namely, that the derived updates are equivalent. Throughout this section, we deliberately
avoid the discussion of design choices and implementation details that are not mandated by the derivations.
Instead we will discuss the different options—which may significantly affect the performance—in Section 3.
2.1 iBayesGMM: Independently Computing the Natural Gradient
The ELBO objective (Eq. 1) could be straightforwardly optimized using (vanilla) gradient descent, using
the reparameterization trick (Kingma and Welling, 2014; Rezende et al., 2014) for obtaining the gradient
with respect to the parameters of each component and the weights. However, compared to gradient de-
scent, natural gradient descent (Amari, 1998) has been shown to be much more efficient for variational
inference (Khan and Nielsen, 2018). Whereas gradient descent performs steepest descent subject to the con-
straint of (infinitesimal) small (in the Euclidean sense) changes to the parameters, natural gradient descent
performs steepest descent subject to small changes to the underlying distribution (with respect to the Fisher
information metric). The natural gradient can be obtained from the vanilla gradient by preconditioning it
with the inverse Fisher information matrix (FIM), but explicitly computing the FIM is expensive. Instead,
Khan and Nielsen (2018) have shown that the natural gradient with respect to the natural parameters of
an exponential family distribution (such as a Gaussian) is given by the vanilla gradient with respect to the
3Published in Transactions on Machine Learning Research (07/2023)
expectation parameters (please refer to Appendix D for additional background). However, GMMs do not
belong to the exponential family and are, thus, not directly amenable to this procedure.
To derive efficient natural gradient updates for a broader class of models, Lin et al. (2019a) considered latent
variable models, such as GMMs, where the marginal distribution of the latent variable q(o)and the condi-
tional distribution of the observed variable q(x|o)are both minimal exponential family distributions. They
showed that for such minimal conditionally exponential family (MCEF) distributions, the Fisher informa-
tion matrix of the joint distribution q(x,o)is block-diagonal, which in turn justifies computing the natural
gradients of the individual components and the weight distribution independently.
2.2 VIPS: Independently Maximizing a Lower Bound
Whereas Lin et al. (2019a) showed that a single natural gradient update can be performed for every com-
ponent independently and that such procedure also performs natural gradient descent on the whole mixture
model, Arenz et al. (2018) proposed a method for GMM-based variational inference that is not derived for
natural gradient descent and that allows for independent optimizations (going beyond single step updates).
For understanding how VIPS (Arenz et al., 2018) decomposed the ELBO objective (Eq. 1) into independent
objectives, it is helpful to first understand which terms prevent independent optimization in the first place.
In particular, note that the first term of the ELBO given in Equation 1 already decomposes into indepen-
dent objectives for each component, and only the second term (the model entropy) prevents independent
optimization. More specifically, when using Bayes’ theorem to write the probability density of the GMM
in terms of the marginals and conditionals, the interdependence between the different components can be
narrowed down to the (log-)responsibilities qθ(o|x)within the entropy,
H(qθ) =−/summationdisplay
oqθ(o)/integraldisplay
xqθ(x|o)/parenleftig
logqθ(o)qθ(x|o)
qθ(o|x)/parenrightig
dx,
which is the only term in Equation 1 that creates a mutual dependence between different components. Hence,
Arenz et al. (2018) introduced an auxiliary distribution ˜q(o|x), to derive the lower bound
˜J(˜q,θ) =/summationdisplay
oqθ(o)/bracketleftig/integraldisplay
xqθ(x|o)/parenleftig
log ˜p(x) + log ˜q(o|x)/parenrightig
dx+H(qθ(x|o))/bracketrightig
+H(qθ(o)) (2)
=J(θ)−/integraldisplay
xqθ(x)KL(qθ(o|x)||˜q(o|x))dx.
As an expected KL is non-negative for any two distributions and equals zero, if both distributions are
equal, ˜J(˜q,θ)is a lower bound of J(θ)that is tight when ˜q(o|x) =qθ(o|x). Hence, VIPS uses a procedure
similar to expectation maximization: In the E-step of iteration i, the auxiliary distribution is set to the
current model, that is, ˜q(o|x):=qθ(i)(o|x). Then, in the M-step, the model parameters are optimized
with respect to the corresponding lower bound ˜J(qθ(i),θ). As the lower bound is tight before each M-step,
i.e,˜J(qθ(i),θ(i)) =J(θ(i)), it also improves the original objective. As the auxiliary distribution ˜q(o|x)is
independent of the model parameters (during the M-step), the weights qθ(o)and each component qθ(x|o)
can be optimized independently, resulting in a component-wise loss function
˜Jo(˜q,θ) =/integraldisplay
xqθ(x|o)/parenleftig
log ˜p(x) + log ˜q(o|x)−logqθ(x|o)/parenrightig
dx. (3)
While these derivations would justify any procedure that improves the model with respect to the lower
bound objective during the M-step, VIPS, performs single natural gradient steps, closely connecting it to
iBayes-GMM. Indeed, we will now show that the updates of both methods are equivalent, except for design
choices that are not mandated by the derivations and can be interchanged arbitrarily.
2.3 The Equivalence of Both Updates
Both previously described methods iteratively improve the GMM by applying at each iteration a single NG
step independently to each component and the weight distribution. Although the NG is computed with
4Published in Transactions on Machine Learning Research (07/2023)
respect to different objective functions, namely the original ELBO (Eq. 1) and the lower bound (Eq. 2), we
clarify in Theorem 2.1 that both natural gradients, and, thus, the derived updates, are indeed the same.
Theorem 2.1. Directly after the E-step (which sets the auxiliary distribution to the current model with
parametersθ(i), that is ˜q(o|x):=qθ(i)(o|x)), the natural gradient (denoted by ˜∇) of the lower bound objective
(Eq. 2) matches the natural gradient of the ELBO (Eq. 1), ˜∇θJ(θ)/vextendsingle/vextendsingle/vextendsingle
θ=θ(i)=˜∇θ˜J(qθ(i),θ)/vextendsingle/vextendsingle/vextendsingle
θ=θ(i).
Proof.See Appendix E.
This deep connection between both methods was previously not understood and has several implications.
First of all, it shows that VIPS actually performs natural gradient descent on the whole mixture model (not
only on the independent components) and with respect to the original ELBO objective (not only to the lower
bound). On the other hand, it may be interesting to exploit the milder convergence guarantees of VIPS
(even bad NG estimates may lead to convergences as long as we improve on the lower bound objective) to
perform more robust natural gradient descent. Increasing the robustness by monitoring the lower bound
may in particular become relevant when it is difficult to approximate the natural gradient sufficiently well,
for example in amortized variational inference, where we want to learn a neural network that predicts the
mean and covariances based on a given input. Finally, our new insights raise the question, why the reference
implementations of the different methods perform quite differently, despite using the same underlying update
equations. In the remainder of this work, we will shed some light on the latter question, by analyzing the
different design choices and evaluating their effects on the quality of the learned approximations.
3 A Modular and General Framework
We have shown that both derivations suggest exactly the same updates (although the decision to perform
single natural gradient steps is voluntary for the EM-based derivation). However, for realizing these up-
dates, several design choices can be made, for example, how to estimate the natural gradient when updating
a Gaussian component. By closely comparing both previous methods and their respective implementations,
we identified seven design choices that distinguish them. Hence, we can unify both methods in a common
framework (Algorithm 1) with seven modules that can be implemented depending on the design choice:
(1)TheSampleSelector selects the samples that are used during the current iteration for estimating the
natural gradients with respect to the parameters of the components and the weight distribution, (2)the
ComponentStepsizeAdaptation module chooses the stepsizes for the next component updates, (3)theNgEs-
timatorestimates the natural gradient for the component update based on the selected samples, (4)the
NgBasedUpdater performs the component updates based on the estimated natural gradients and the step-
sizes, (5)theWeightStepsizeAdaptation module chooses the stepsize for the next update of the weights, (6)
theWeightUpdater updates the weight distribution along the natural gradient based on the chosen stepsize,
and(7)theComponentAdaptation module decides whether to add or delete components. In the remainder
of this section, we will discuss and compare the different options that have been employed by prior work.
Algorithm 1 Natural Gradient GMM Variational Inference
repeat
samples, targetDensitiesAndGradients ←SampleSelector.selectSamples(GMM, SampleDatabase)
compStepsizes←ComponentStepsizeAdapation.updateStepsizes(numCompUpdates, compStepsizes)
naturalGradients ←NGEstimator.getNGs(samples, targetDensitiesAndGradients, GMM)
GMM←NGBasedUpdater.applyNgUpdate(naturalGradients, stepsizes, GMM)
weightStepsize←WeightStepsizeAdaptation.updateStepsizes(numIterations, weightStepsize)
GMM←WeightUpdater.updateWeights(weightStepsize, samples, targetDensities, GMM)
GMM←ComponentAdaptation.adaptNumberOfComponents(numIterations, GMM, SampleDatabase)
untilstoppingCriteria
5Published in Transactions on Machine Learning Research (07/2023)
3.1 Sample Selection
For estimating the natural gradients of the components and the weight distribution, the target distribution
˜p(x)needs to be evaluated on samples from the respective distribution. However, both iBayes-GMM and
VIPS use importance sampling to use the same samples for updating all distributions at a given iteration.
iBayesGMM obtains the samples for a given iteration by sampling from the current GMM, using standard
importance sampling to share samples between different components.
VIPSsamples from the individual components, rather than the GMM and also stores previous samples
(and their function evaluations) in a database. Using two additional hyperparameters, nreusedandndes,
VIPS starts by obtaining the nreusednewest samples from the database. Then, the effective sample size
neff(o) =/parenleftbig/summationtext
iwsn
i(o)2/parenrightbig−1is computed using the self-normalized importance weights wsn
i(o), andndes−neff(o)
new samples are drawn from each component.
In our implementation both options can make use of samples from previous iterations by setting the hy-
perparameter nreusedlarger than zero (Arenz et al., 2020). The first option, which generalizes the procedure
used by iBayes-GMM (Lin et al., 2020) computes the effective sample size neffon the GMM and draws
max(0,N·ndes−neff)new samples from the GMM. The second option computes neff(o)for each component
and draws max(0,ndes−neff(o))new samples from each component, matching the procedure used by VIPS.
3.2 Natural Gradient Estimation
For estimating the natural gradient for the individual component updates, VIPS only uses black-box evalu-
ations of the unnormalized target distribution log ˜p(xi)on samples xi. In contrast, the NG estimate used by
iBayes-GMM (Lin et al., 2020), which is based on Stein’s Lemma (Stein, 1981), uses first-order information
∇xilog ˜p(xi)which is less general but typically more sample efficient.
VIPSuses the policy search method MORE (Abdolmaleki et al., 2015), which is based on compatible
function approximation (Pajarinen et al., 2019; Peters and Schaal, 2008; Sutton et al., 1999). Namely,
as shown by Peters and Schaal (2008), an unbiased estimate of the natural gradient for an objective of
the form Eπθ(x)[R(x)]is given by the weights ωof a compatible function approximator (Sutton et al.,
1999), ˜R(x) =ω⊤ϕ(x), that is fitted using ordinary least squares to approximate R, based on a data set
X={(x,R(x))i}, with samples xithat are obtained by sampling from the distribution πθ. A function
approximator is compatible to the distribution πθ, if the basis functions ϕ(x)are given by the gradient of
the log distribution, ϕ(x) =∇θlogπθ(x). For updating a Gaussian component q(x|o)parameterized with
its natural parameters, ηo=/braceleftbig
Σ−1
oµo,−1
2Σ−1
o/bracerightbig
, the compatible function approximator can be written as
˜R(x) =x⊤Rx+x⊤r+r,
where the matrix R, the vector rand the scalar r, are the linear parameters that are learned using least
squares. Here, the constant offset rcan be discarded and Randrdirectly correspond to the natural
gradients, that could be used to update the natural parameters,
−1
2Σ−1
o=−1
2Σ−1
o,old+βoR, Σ−1
oµo=Σ−1
o,oldµo,old+βor. (4)
The least squares targets based on the ELBO (Eq. 1), RELBO (x) = log ˜p(x)−logqθ(x), and the least squares
targets based on the lower bound (Eq. 2), RLB(x) = log ˜p(x)+log ˜q(o|x)−log ˜q(x|o)only differ by a constant
offset logqθ(o)that would be consumed by the scalar rand not affect the NG estimates Randr.
For compatible function approximation, the data set Xshould be obtained by sampling the respective
component. However, VIPS uses importance weighting to make use of samples from previous iterations and
fromdifferentcomponents, byperformingweightedleastsquares, weightingeachdatapointbyitsimportance
weight. The importance weights wican be computed asq(xi|o)
z(xi), wherezis the actual distribution that was
used for sampling the data set. However, VIPS uses self-normalized importance weights wsn
i= (/summationtext
jwj)−1wi,
which yield lower-variance, biased, but asymptotically unbiased estimates. Furthermore, VIPS applies ridge
regularization during weighted least squares, which further introduces a bias.
6Published in Transactions on Machine Learning Research (07/2023)
iBayesGMM exploits that for exponential-family distributions, the natural gradient with respect to the
natural parameters η(for Gaussians η={Σ−1µ,−1
2Σ−1}) corresponds to the vanilla gradient with respect
to the expectation parameters m(for Gaussians m={µ,Σ+µµ⊤}) (Khan and Nielsen, 2018). Using the
chain rule, the gradient with respect to the expectation parameters can be expressed in terms of the gradient
with respect to the covariance Σand meanµ(Khan and Lin, 2017, Appendix B.1). Thus, the NG step for
a Gaussian component q(x|o)with stepsize βoand objective J(x)can be computed as
−1
2Σ−1
o=−1
2Σ−1
o,old+βo∇ΣoJ,Σ−1
oµo=Σ−1
o,oldµo,old+βo/parenleftig
−2/bracketleftig
∇ΣJ/bracketrightig
µo,old+∇µJ/parenrightig
,(5)
as shown by Khan et al. (2018, Appendix C). As the objective Jcorresponds to an expected value, i.e.,
J=Eq(x|o)/bracketleftig
R(x)/bracketrightig
withR(x) = log˜p(x)
˜q(x), the gradient with respect to mean and covariance are given by the
expected gradient and Hessian (Opper and Archambeau, 2009),
∇ΣJ=1
2Eq(x|o)/bracketleftig
∇xxR(x)/bracketrightig
,∇µJ=Eq(x|o)/bracketleftig
∇xR(x)/bracketrightig
. (6)
Hence, using Monte-Carlo to estimate the gradients with respect to mean and covariance (Eq. 6), we can
obtain unbiased estimates of the natural gradient (Eq. 5). However, evaluating the Hessian ∇xxR(x)is
computationally expensive, and therefore, Lin et al. (2019b) proposed an unbiased first-order estimate of the
expected Hessian based on Stein’s Lemma (Stein, 1981) given by (Lin et al., 2019b, Lemma 11)
Eq(x|o)/bracketleftig
∇xxR(x)/bracketrightig
=Eq(x|o)/bracketleftbig
Σ−1
o(x−µo) (∇xR(x))⊤/bracketrightbig
. (7)
Similar to VIPS, iBayes-GMM uses importance sampling to perform the Monte-Carlo estimates (Eq. 6 right,
Eq. 7) based on samples from different components. However, in contrast to VIPS, iBayes-GMM uses
standard (unbiased) importance weighting, rather than self-normalized importance weighting, which in our
implementation, can be selected using a hyperparameter that is available for both options.
Our implementation supports both options, where using standard importance weighting or self-normalized
importance weighting can be chosen using a hyperparameter that is available to both options.
3.3 Natural Gradient based Component Updates
For performing the natural gradient update, we identified three different options in the related literature. Lin
et al. (2019a) directly apply the natural gradient update (Eq. 4) based on the natural gradients R,rand the
stepsizeβo, which we assume given. However, this update may lead to indefinite covariance matrices, and
thereforeiBayes-GMM(Linetal.,2020)usesthe improved Bayesian learning rule (iBLR) ,whichmodifiesthe
update direction (no longer performing natural gradient descent) in a way that ensures that the covariance
matrix remains positive definite. Thirdly, VIPS indirectly control the stepsize by choosing an upper bound
ontheKLdivergencebetweentheupdatedandtheoldcomponent, KL (q(x|o)||qold(x|o)), andsolvesaconvex
optimization problem to find the largest βothat satisfies the trust region constraint. Directly performing
the natural gradient step is straightforward, and therefore, we now only discuss the two latter options.
iBayesGMM applies the improved Bayesian Learning Rule (iBLR), which approximates Riemannian gra-
dient descent (Lin et al., 2020),
−1
2Σ−1
o=−1
2Σ−1
o,old+βo(R−βoRΣo,oldR), Σ−1
oµo=Σ−1
oΣo,old/parenleftig
Σ−1
o,oldµo,old+βor/parenrightig
.(8)
The iBLR update (Eq. 8) differs from the NG update (Eq. 4) due to the additional terms −βoRΣo,oldRand
Σ−1
oΣo,old. Using this update, the new precision matrix can be shown to be an average of a positive definite
and a positive semidefinite term, Σ−1
o=1
2/parenleftig
Σ−1
o,old+U⊤U/parenrightig
, where U=L−2βL−⊤RandL⊤L=Σ−1
o,old.
VIPSupdates the components using natural gradient descent (Eq. 4). However, rather than controlling the
change of the component using the stepsize βo, it upper-bounds the KL divergence KL (qθ(x|o)||˜q(x|o))<ϵo
by solving for every component update an optimization problem that finds the largest stepsize βo, such that
7Published in Transactions on Machine Learning Research (07/2023)
the updated component will have a positive definite covariance matrix and a KL divergence to the original
component that is smaller than a bound ϵo, which is assumed given instead of the stepsize βo(Abdolmaleki
et al., 2015). The additional optimization problems for finding the stepsize add little computational overhead
since the KL divergence is convex in the stepsize and can be efficiently computed for Gaussian distributions.
Our implementation supports three options: (1) directly applying the NG update (Eq. 4), (2) the iBLR
update, and the (3) trust-region update of VIPS. However, VIPS uses an external L-BFGS-G optimizer to
find the largest stepsize that respects the trust-region, which was difficult to efficiently integrate into our
Tensorflow (Abadi et al., 2015) implementation. Instead we implemented a simple bisection method so solve
this convex optimization problem, see Appendix I for details.
3.4 Weight Update
The natural gradient update for the categorical distribution is performed by updating the log weights in the
direction of the expected reward of the corresponding component, that is,
q(o)∝q(o)oldexp/parenleftig
βˆR(o)/parenrightig
, (9)
where ˆR(o)is a Monte-Carlo estimate of R(o) =Eq(x|o)/bracketleftig
logp(x)
˜q(x)/bracketrightig
. The NG update is presented differently
by Lin et al. (2020), but we clarify in Appendix F that both updates are indeed equivalent1. However, we
identified two different options to perform the weight update.
IBayesGMM directly applies the stepsize β.
VIPSoriginallyoptimizedthestepsizewithrespecttoadesiredKLboundKL (q(o)||qold(o))≤ϵ,analogously
to the component update described in Section 3.3 (Arenz et al., 2018). Although in subsequent work, Arenz
et al. (2020) found that a fixed stepsize β= 1, corresponding to a greedy step to the optimum of their lower
bound objective, performs similarly well.
Our implementation supports both options, directly applying the stepsize and optimizing the stepsize with
respect to a trust-region. Directly applying the stepsize in combination with a WeightStepsizeAdaption that
always selects a fixed stepsize β= 1corresponds to the greedy procedure (Arenz et al., 2020).
3.5 Weight and Component Stepsize Adaptation
Whileweuseseparatemodulesfor WeightStepsizeAdaptation andComponentStepsizeAdaptation , weconsider
the same adaptation schemes in both modules.
iBayesGMM used fixed stepsizes in their implementation but used different stepsizes for weights and for the
components. Often, a weight stepsize β= 0was used to maintain a uniform distribution over the different
components. We believe that this concession was probably required due to their design choice, of using
samples from the GMM for updating the individual components, which may prevent components with low
weight to obtain meaningful updates. In prior work, Khan and Lin (2017) discussed a backtracking method
to adapt the stepsize for the component updates for ensuring positive definiteness, but they found it slow in
practice and did not test it in the GMM setting, and Khan et al. (2018) used a decaying stepsize.
VIPSoriginally used fixed trust-regions for the weight and component update (Arenz et al., 2018). Later
a fixed stepsize with β= 1for the weights was combined with adaptive trust-regions for the component
updates, where the bounds were chosen independently for each component, by increasing the bound if the
reward of the corresponding component improved during the last update, and by decreasing it otherwise.
Our implementation supports three options for each stepsize scheduler: (1) keeping the stepsize constant (2)
using a decaying stepsize (Khan et al., 2018) and (3) adapting the stepsize based on the improvement of the
last update (Arenz et al., 2020).
1The respective implementations still differ slightly because VIPS uses self-normalized importance weighting, rather than
standard importance-weighting, which we control in our implementation using a hyperparameter.
8Published in Transactions on Machine Learning Research (07/2023)
MODULE OPTIONS
NgEstimator More ZStein S
ComponentAdaptation Fixed EVips A
SampleSelector Lin et al. PVips M
NgBasedComponentUpdater Direct IiBLR YTrust-Region T
ComponentStepsizeAdaptation Fixed FDecaying DAdaptive R
WeightUpdater Direct UTrust-Region O
WeightStepsizeAdaptation Fixed XDecaying GAdaptive N
Table 1: We assign a unique letter to every option such that every combination of options can be specified
with a 7-letter word (one letter per module).
3.6 Component Adaptation
VIPSdynamically adapts the number of components by deleting components at poor local optima that do
not contribute to the approximation, and by adding new components in promising regions. The initial mean
for the new component is chosen based on a single-sample estimate of the initial reward ˜R(onew)for the new
component, evaluated for samples from the database.
iBayes-GMM uses a fixed number of components Kthat is specified by a hyperparameter.
Our implementation supports (1) a dummy option that does not do anything and (2) adapting the number
of components dynamically (Arenz et al., 2020).
4 Experiments
To evaluate the effect of the individual design choices, we implemented all previously discussed options in a
common framework, such that they can be chosen independently. Prior to the experiments we ensured that
our implementation performs comparably to the MATLAB implementation of iBayes-GMM (Lin et al., 2020)
and to the C++-implementation of VIPS (Arenz et al., 2020) when using the respective design choices. As
showninAppendixG,whencomparingourimplementationwiththereferenceimplementationontheirtarget
distributions, we always learn similar or better approximations. Additional details on the implementation are
described in Appendix I. An overview of the available options is shown in Table 1. Available hyperparameters
for each option are shown in Appendix H. Our framework allows for 24·33= 432different combinations
of options. We assign a unique letter to each option (see Table 1), such that we can refer to each of the
combinations with a 7-letter codeword. For example, Sepyfux refers to iBayes-GMM (Lin et al., 2020)
andZamtrux to VIPS (Arenz et al., 2020). However, evaluating each combination is computationally
prohibitive. Instead, we designed the following sequence of experiments.
Inthefirstgroupofexperiments, weevaluatethestabilityofthecomponentupdates, usingfixedweights, and
without adapting the number of components. In the second group of experiments, we use the most promising
design choices for the component update that we identified in the first group of experiments, and ablate over
the design choices that affect the update of the weights and the adaptation of the number of components.
Based on the results of the previous group of experiments, we then identify promising combinations and
evaluate them on the full test suite. For comparison with prior work, we also evaluate the design choices
used by iBayes-GMM (Lin et al., 2020) and VIPS (Arenz et al., 2020).
4.1 Experiment 1: Component Update Stability
For evaluating the effects of the design choices on the component update stability, we do not change the
number of components (Option E) and do not update the (uniformly initialized) weights ( XandU, with
initial weight-stepsize β= 0). Furthermore, we always sample from the GMM ( P), since the two options for
theSampleSelector hardly differ for uniform GMMs. We evaluate the different options for the NgEstimator ,
ComponentStepsizeAdaptation andNgBasedComponentUpdater resulting in 18 different combinations.
9Published in Transactions on Machine Learning Research (07/2023)
Design Choice BreastCancer BreastCancerMB Wine
Component NG EstimationMORE (Z) 78.88 152.84 N/A
Stein (S) 78.46 68.22 1431.09
Component UpdateDirect (I) 78.95 70.96 2263.78
iBLR (Y) 78.69 70.37 1431.09
Trust-Region (T) 78.46 68.22 1443.40
Component Stepsize AdaptationFixed (F) 78.46 69.01 1450.11
Decaying (D) 78.47 70.69 1468.50
Adaptive (R) 78.46 68.22 1431.09
Table 2: We show optimistic estimates of the best performance (negated ELBO) that we can achieve with
every option when optimizing a uniform GMM with a fixed number of components, by reporting the best
performance achieved during Bayesian optimization among all runs that used the respective option.
Weevaluateeachcandidateonthreetargetdistributions: Inthe BreastCancer experimentArenzetal.(2018)
we perform Bayesian logistic regression using the full “Breast Cancer” datatset (Lichman, 2013). Further, we
introduce the variant BreastCancerMB which uses minibatches of size 64to evaluate the effect of stochastic
target distributions. Thirdly, we evaluate the candidates in a more challenging Bayesian neural network
experiment on the “Wine” dataset (Lichman, 2013), where we use a batch size of 128. We use two hidden
layer with width 8, such that the 177-dimensional posterior distribution is still amenable to GMMs with full
covariance matrices. Please refer to Appendix J for details on the implementation for all experiments.
We tuned the hyperparameters of each of the 18candidates separately for each test problem using Bayesian
optimization. We granted each candidate exclusive access to a compute node with 96cores for two days per
experiment. The results of the hyperparameter search are summarized in Table 2, where we report the best
ELBO achieved for every design choice (maximizing over all tested hyperparameters and all combinations of
the remaining options). On Wine, which uses almost three times as many parameters as have been tested
by Arenz et al. (2020), we could not obtain reasonable performance when using MORE, as this zero-order
method requires significantly more samples, resulting in very slow optimization.
The values in Table 2 give an optimistic estimate of the best performance that we can expect for a given
design choice, however, it is in general not guaranteed that this performance can be robustly achieved over
different seeds. Hence, for the most promising candidates, Septrux andSepyrux , we used the best hyper-
parameters from the Bayesian optimization and evaluated the performance over ten seeds. The mean of the
final performance and its 99.7%standard error are shown in Table 3. We also show for every experiment a
second metric, where we use the maximum mean discrepancy (Gretton et al., 2012) (MMD) for BreastCancer
andBreastCancerMB (comparing samples from the GMM with baseline samples (Arenz et al., 2020)), and
the mean squared error of the Bayesian inference predictions for Wine. Unfortunately, the hyperparameters
forSepyrux onBreastCancer andBreastCancerMB led to unstable optimization for some seeds, despite
their good performance during hyperparameter search. We expect that using slightly more conservative hy-
perparameters, Sepyrux could reliably achieve a performance that is only slightly worse than the optimistic
value provided in Table 3 for BreastCancer (78.69). However, the performance of Septrux is even in expec-
tation over multiple seeds already better than this optimistic estimate. Furthermore, also on WINE, where
Sepyrux did not suffer from instabilities, the trust-region updates achieved better performance, albeit not
statistically significant. Hence, we decided to use trust-region updates for the second group of experiments.
We will further test the iBLR update in our main experiments for a more thorough comparison.
4.2 Experiment 2: Weight Update and Exploration
According to the first experiment, first-order estimates using Stein’s Lemma, adaptive component stepsizes
and trust-region updates are the most effective and stable options for the component updates, and therefore,
we fix the corresponding design choices ( S,T,R) for our second group of experiments. The modules that we
did not evaluate in the first group of experiments ( ComponentAdaptation ,SampleSelector ,WeightUpdater
andWeightStepsizeAdaptation ) are in particular relevant for discovering and approximating multiple modes
10Published in Transactions on Machine Learning Research (07/2023)
CandidateBreastCancer BreastCancerMB Wine
-ELBO MMD-ELBO
(full batch)MMD -ELBO MSE
SEPYRUX1042.28
±2699.320.004
±0.0021130.81
±799.660.033
±0.0141462.91
±35.700.481
±0.022
SEPTRUX78.53
±0.020.002
±0.00081.21
±1.130.002
±0.0001444.01
±30.780.478
±0.021
Table 3: We evaluated the best hyperparameters for the most promising candidates of our experiments for
Group 1 on 10different seeds with respect to ELBO and a secondary metric (maximum mean discrepancy
or mean squared error). Sepyrux , which uses the iBLR update for the component updates did not achieve
stableresultsonthebreastcancerexperiments. Septrux whichusestrust-regionupdatesforthecomponents
outperformed Sepyrux in all experiments, although in WINEthe advantage is not statistically significant.
Design Choice GMM20 STM20 PlanarRobot4
Component AdaptationNon-Adaptive (E) 0.00 0.08 12.33
Adaptive (A) 0.00 0.05 12.15
Sample SelectionFrom Mixture (P) 0.11 1.52 12.77
From Components (M) 0.00 0.05 12.15
Weight UpdateNatural Gradient Descent (U) 0.00 0.06 12.30
Trust-Region (O) 0.00 0.05 12.15
Weight Stepsize AdaptationFixed (X) 0.00 0.06 12.15
Decaying (G) 0.00 0.05 12.33
Improvement-Based (N) 0.00 0.06 12.22
Table 4: We show optimistic estimates of the best performance (negated ELBO) that we can achieve with
every option (updating the components using the design choices identified in the first experiment). We report
the best performance achieved during Bayesian optimization among all runs that used the respective option.
of the target distribution. Hence, we focus on multi-modal target distributions for the second set of experi-
ments. All test problems for these experiments were taken from prior work. Namely, we chose GMM20 and
PlanarRobot4 from Arenz et al. (2020) and STM20from Lin et al. (2020). For GMM20 andSTM20the
target distribution is given by an unknown mixture of 20-dimensional Gaussians and Student-Ts, respec-
tively. In PlanarRobot4 we want to approximate a distribution over joint configurations of a 10-link planar
robot, such that it approximately reaches any of four possible goal positions. For Bayesian optimization of
the hyperparameters, we grant each of the 24candidates exclusive access to our compute node for one day
per test problem. Optimistic estimates of the best performance for each design choices are shown in Table 4.
Based on our experiments sampling according to the mixture weights (Option P) seems to be clearly inferior
to sampling from the components (Option M), as it was the only option that was not able to solve the
GMM20 experiment. Furthermore, adapting the number of components (Option A) and using trust-region
updates for the weight update (Option O) seem beneficial for multimodal target distributions. However, for
WeightStepsizeAdaptation , also a fixed stepsize (when used as trust-region) achieved good performance.
4.3 Experiment 3: Evaluating the Promising Candidates
For our main experiment we focus on candidates that use first order NG estimates, adaptive number of
components and adaptive component-stepsizes and sample from the individual components (Options S,A,
M,R), and aim to better compare trust-region updates with the iBLR update (Option Tvs.Y). For
updating the weights, we evaluate fixed and adaptive trust-regions, and fixed direct NG updates ( OXvs.
ONvs.UX), resulting in six candidates: Samtrux ,Samtrox ,Samtron ,Samyrux ,Samyrox and
Samyron . Furthermore, to compare with prior work, we also evaluate Zamtrux (Arenz et al., 2020) and
Sepyfux (Lin et al., 2020) as well as the variant Sepyrux , combining iBLR updates with adaptive stepsizes.
11Published in Transactions on Machine Learning Research (07/2023)
Candidate
BreastCancer
BreatCancerMB
GermanCredit
GermanCreditMB
PlanarRobot
GMM20
GMM100
STM20
STM300
WINE
TALOS
Samtron78.00
±0.0278.41
±0.03585.10
±0.00585.12
±0.0011.47
±0.04−0.00
±0.000.01
±0.030.00
±0.0014.96
±0.481423.12
±31.55−24.43
±0.16
Samyron78.61
±0.0579.96
±0.26585.11
±0.01585.12
±0.0012.93
±0.130.00
±0.000.16
±0.090.03
±0.0122.50
±0.151433.87
±30.49−24.00
±0.23
iBayes-GMM
(Sepyfux)79.78
±0.4080.13
±0.69585.12
±0.01585.12
±0.0017.26
±2.130.43
±0.154.54
±0.520.46
±0.0626.87
±0.453279.32
±1425.12−16.64
±5.26
VIPS
(Zamtrux)78.14
±0.0183.65
±0.97585.10
±0.00585.35
±0.0311.48
±0.04−0.00
±0.001.21
±0.150.54
±0.17N/A16 503.38
±813.75−23.69
±0.16
Table 5: Along with the negated ELBO, we show the 3σconfidence intervals based on the standard er-
ror of its mean using ten different seeds. The proposed candidate clearly outperforms the prior methods
VIPS(Arenz et al., 2020) and iBayes-GMM (Lin et al., 2020). First-order natural gradient estimates
with trust-region constraints ( T) seem preferable over the iBLR update ( Y). We observed instabilities for
Sepyfux onPlanarRobot andTALOSand, thus, removed bad outliers when computing the reported values.
We evaluate these candidates on the full test suite, which uses the following test problems on top of the
previously discussed ones: GermanCredit (Arenz et al., 2020) and GermanCreditMB are similar to the
BreastCancer experiment, but use the 25-dimensional GermanCredit dataset (Lichman, 2013); GMM100
andSTM300 are higher-dimensional variants of the GMM20 andSTM20experiments; and, finally, TALOS
is a new experiment that we introduced to evaluate the different options on a test problem that was not
used during development. Somewhat related to the PlanarRobot4 experiment, in the TALOS experiment
we aim to learn a distribution over joint configurations to reach a goal position with the robot’s endeffector.
However, the TALOS experiment uses the kinematics of an actual robot–the humanoid TALOS from PAL
Robotics (Stasse et al., 2017). Furthermore, the target distribution is based on the work by Pignat et al.
(2020) and is more complex by using a product of expert that penalize pose errors for each foot and hand
as well as unstable configurations (that occur when the robot’s center of mass projected on the ground is
outside of the support polygon spanned by the feet), and that incorporate a prior distribution over the joint
angles. The target distribution is 34 dimensional (7 joint configurations for each leg, 6 joint angles for each
arm and 6 additional parameters that specify the pose of the torso with respect to a fixed reference frame.
OnTALOS, prior to the experiments of this group, we only performed few experiments using SEPIFOX to
optimize a single Gaussian component, to ensure that the target distribution is correctly implemented.
For selecting the hyperparameters, we perform for each candidate and each experiment a small grid search,
where we make use of the results from the previous experiments to select suitable ranges. Extensive hyperpa-
rametersearch(e.g. usingBayesianoptimization)wouldunfairlybenefitoptionswithmorehyperparameters.
Table 5 compares the final performance (negated ELBO) of the best-performing candidate ( Samtron ) with
the prior methods VIPS (Arenz et al., 2020) and iBayes-GMM (Lin et al., 2020). We also show Samyron for
comparing trust-region natural-gradient updates with the iBLR update. According to these experiments, we
can clearly improve upon Zamtrux by using Stein’s Lemma for estimating the natural gradient (in partic-
ular for higher-dimensional problems), and upon Sepifux , by sampling from the components and adapting
their number during optimization. Interestingly, trust-region constraints seem to be beneficial also when
using first-order estimates of the natural gradient, and showed a slight but consistent advantage compared
to the iBLR update (Lin et al., 2020) in our experiments. Full results of our main experiments are shown in
Appendix K, where we show the performance of all tested candidates, also with respect to secondary metrics.
12Published in Transactions on Machine Learning Research (07/2023)
5 Conclusion
Although VIPS and iBayes-GMM are derived from different perspectives—where the derivations for Bayes-
GMM are less general (by requiring single NG steps for the component update) but enjoy stronger guarantees
(by proving natural gradient descent on the whole mixture model)—, we showed that both algorithms
only differ in design choices and could have been derived from the other perspective, respectively. This
unification of both perspective shows that we can derive approximate natural gradient descent algorithms
also for mixtures of non-Gaussian components—where the approximation errors of the natural gradient are
potentially much larger—without having to give up on convergence guarantees. Furthermore, our results
are of high relevance for the practitioner, both due to our extensive study on the effects of the individual
design choices—which shows that both prior works can be improved by using a combination of their design
choices—and by releasing our modular framework for natural gradient GMM-based variational inference,
which is well-documented and easy to use and outperforms the reference implementations by Arenz et al.
(2020) and Lin et al. (2020) when using the respective design choices. Typical trade-offs for the practitioner
are discussed in Appendix M. The limitations of this study and the potential for negative societal impact
are discussed in Appendix A and B.
Acknowledgements
This research was supported by “The Adaptive Mind”, funded by the Excellence Program of the Hessian
Ministry of Higher Education, Science, Research and Art.
The authors gratefully acknowledge the computing time provided to them on the high-performance computer
Lichtenberg at the NHR Centers NHR4CES at TU Darmstadt. This is funded by the Federal Ministry of
Education and Research, and the state governments participating on the basis of the resolutions of the GWK
for national high performance computing at universities.
The authors acknowledge support by the state of Baden-Württemberg through bwHPC.
This work was performed on the HoreKa supercomputer funded by the Ministry of Science, Research and
the Arts Baden-Württemberg and by the Federal Ministry of Education and Research.
References
Michael Volpp, Philipp Dahlinger, Philipp Becker, Christian Daniel, and Gerhard Neumann. Accurate
bayesian meta-learning by accurate task posterior inference. In International Conference on Learning
Representations , 2023. URL https://openreview.net/forum?id=sb-IkS8DQw2 .
Brian D. Ziebart. Modeling purposeful adaptive behavior with the principle of maximum causal entropy . PhD
thesis, Carnegie Mellon University, 2010.
Emmanuel Pignat, Teguh Lembono, and Sylvain Calinon. Variational inference with mixture model ap-
proximation for applications in robotics. In International Conference on Robotics and Automation , pages
3395–3401. IEEE, 2020.
MarcoEwerton, Oleg Arenz, and JanPeters. Assistedteleoperationinchanging environmentswitha mixture
of virtual guides. Advanced Robotics , 34(18):1157–1170, 2020. doi: 10.1080/01691864.2020.1785326.
Solomon Kullback and Richard A Leibler. On information and sufficiency. The annals of mathematical
statistics , 22(1):79–86, 1951.
Ivan Kobyzev, Simon Prince, and Marcus Brubaker. Normalizing flows: An introduction and review of
current methods. IEEE Transactions on Pattern Analysis and Machine Intelligence , 2020.
Oleg Arenz, Mingjun Zhong, and Gerhard Neumann. Efficient gradient-free variational inference using policy
search. In International Conference on Machine Learning , 2018.
13Published in Transactions on Machine Learning Research (07/2023)
Wu Lin, Mohammad Emtiyaz Khan, and Mark Schmidt. Fast and simple natural-gradient variational
inference with mixture of exponential-family approximations. In International Conference on Machine
Learning , pages 3992–4002. PMLR, 2019a.
Wu Lin, Mark Schmidt, and Mohammad Emtiyaz Khan. Handling the positive-definite constraint in the
Bayesian learning rule. In Hal Daumé III and Aarti Singh, editors, International Conference on Machine
Learning , volume 119 of Proceedings of Machine Learning Research , pages 6116–6126. PMLR, 13–18 Jul
2020.
OlegArenz,MingjunZhong,andGerhardNeumann. Trust-regionvariationalinferencewithgaussianmixture
models.Journal of Machine Learning Research , 21(163):1–60, 2020. URL http://jmlr.org/papers/v21/
19-524.html .
Jan Peters, Katharina Mulling, and Yasemin Altun. Relative entropy policy search. In Conference on
Artificial Intelligence . AAAI, 2010.
John Schulman, Sergey Levine, Pieter Abbeel, Michael Jordan, and Philipp Moritz. Trust region policy
optimization. In International Conference on Machine Learning , pages 1889–1897. PMLR, 2015.
Fabian Otto, Philipp Becker, Vien Anh Ngo, Hanna Carolin Maria Ziesche, and Gerhard Neumann. Dif-
ferentiable trust region layers for deep reinforcement learning. In International Conference on Learning
Representations , 2021. URL https://openreview.net/forum?id=qYZD-AO1Vn .
Wu Lin, Mohammad Emtiyaz Khan, and Mark Schmidt. Stein’s lemma for the reparameterization trick with
exponential family mixtures. arXiv preprint arXiv:1910.13398 , 2019b.
Diederik Kingma and Max Welling. Auto-encoding variational bayes. In International Conference on Learn-
ing Representations (ICLR) , 2014.
Daniel Rezende, Shakir Mohamed, and Daan Wierstra. Stochastic backpropagation and approximate in-
ference in deep generative models. In International Conference on Machine Learning , pages 1278–1286,
2014.
Shun-Ichi Amari. Natural gradient works efficiently in learning. Neural computation , 10(2):251–276, 1998.
Mohammad Emtiyaz Khan and Didrik Nielsen. Fast yet simple natural-gradient descent for variational
inference in complex models. In International Symposium on Information Theory and Its Applications
(ISITA), pages 31–35. IEEE, 2018.
Charles M. Stein. Estimation of the mean of a multivariate normal distribution. The annals of Statistics ,
pages 1135–1151, 1981.
Abbas Abdolmaleki, Rudolf Lioutikov, Nuno Lau, Luis Paulo Reis, Jan Peters, and Gerhard Neumann.
Model-based relative entropy stochastic search. In Advances in Neural Information Processing Systems ,
pages 153–154, 2015.
Joni Pajarinen, Hong Linh Thai, Riad Akrour, Jan Peters, and Gerhard Neumann. Compatible natural
gradient policy search. Machine Learning , 108:1443–1466, 2019.
Jan Peters and Stefan Schaal. Natural actor-critic. Neurocomputing , 71(7-9):1180–1190, 2008.
Richard S Sutton, David McAllester, Satinder Singh, and Yishay Mansour. Policy gradient methods for
reinforcement learning with function approximation. In S. Solla, T. Leen, and K. Müller, editors, Advances
in Neural Information Processing Systems , volume 12. MIT Press, 1999. URL https://proceedings.
neurips.cc/paper/1999/file/464d828b85b0bed98e80ade0a5c43b0f-Paper.pdf .
Mohammad Khan and Wu Lin. Conjugate-computation variational inference: Converting variational infer-
ence in non-conjugate models to inferences in conjugate models. In Artificial Intelligence and Statistics ,
pages 878–887. PMLR, 2017.
14Published in Transactions on Machine Learning Research (07/2023)
Mohammad Khan, Didrik Nielsen, Voot Tangkaratt, Wu Lin, Yarin Gal, and Akash Srivastava. Fast and
scalable Bayesian deep learning by weight-perturbation in Adam. In Jennifer Dy and Andreas Krause,
editors,International Conference on Machine Learning , volume 80 of Proceedings of Machine Learning
Research , pages 2611–2620. PMLR, 10–15 Jul 2018.
Manfred Opper and Cédric Archambeau. The variational gaussian approximation revisited. Neural compu-
tation, 21(3):786–792, 2009.
M.Abadi, M.Agarwal, P.Barham, E.Brevdo, Z.Chen, C.Citro, G.S.Corrado, A.Davis, J.Dean, M.Devin,
S. Ghemawat, I. Goodfellow, A. Harp, G. Irving, M. Isard, Y. Jia, R. Jozefowicz, L. Kaiser, M. Kudlur,
J. Levenberg, D. Mané, R. Monga, S. Moore, D. Murray, C. Olah, M. Schuster, J. Shlens, B. Steiner,
I. Sutskever, K. Talwar, P. Tucker, V. Vanhoucke, V. Vasudevan, F. Viégas, O. Vinyals, P. Warden,
M. Wattenberg, M. Wicke, Y. Yu, and X. Zheng. TensorFlow: Large-scale machine learning on heteroge-
neous systems, 2015. URL https://www.tensorflow.org/ . Software available from tensorflow.org.
M. Lichman. UCI machine learning repository, 2013. URL http://archive.ics.uci.edu/ml .
A. Gretton, K. M. Borgwardt, M. J. Rasch, B. Schölkopf, and A. Smola. A kernel two-sample test. Journal
of Machine Learning Research (JMLR) , 13:723–773, March 2012. ISSN 1532-4435.
O. Stasse, T. Flayols, R. Budhiraja, K. Giraud-Esclasse, J. Carpentier, J. Mirabel, A. Del Prete, P. Souères,
N. Mansard, F. Lamiraux, J.-P. Laumond, L. Marchionni, H. Tome, and F. Ferro. Talos: A new humanoid
research platform targeted for industrial applications. In 2017 IEEE-RAS 17th International Conference
on Humanoid Robotics (Humanoids) , pages 689–695, 2017. doi: 10.1109/HUMANOIDS.2017.8246947.
Andrew C. Miller, Nicholas J. Foti, A. D’Amour, and Ryan P. Adams. Variational boosting: Iteratively
refining posterior approximations. In International Conference on Machine Learning , 2017.
Fangjian Guo, Xiangyu Wang, Kai Fan, Tamara Broderick, and David B. Dunson. Boosting variational
inference. arXiv:1611.05559v2 [stat.ML] , 2016.
Matthew D. Hoffman, David M. Blei, Chong Wang, and John Paisley. Stochastic variational inference.
Journal of Machine Learning Research , 14(4):1303–1347, 2013. URL http://jmlr.org/papers/v14/
hoffman13a.html .
Lucas Theis and Matthew Hoffman. A trust-region method for stochastic variational inference with appli-
cations to streaming data. In International Conference on Machine Learning , pages 2503–2511. PMLR,
2015.
Jeffrey Regier, Michael I Jordan, and Jon McAuliffe. Fast black-box variational inference through stochastic
trust-region optimization. In Advances in Neural Information Processing Systems , pages 2399–2408, 2017.
Mohammad Emtiyaz Khan, Pierre Baqué, François Fleuret, and Pascal Fua. Kullback-leibler proximal
variational inference. In Advances in Neural Information Processing Systems , 2015.
Mohammad Emtiyaz Khan, Reza Babanezhad, Wu Lin, Mark Schmidt, and Masashi Sugiyama. Faster
stochastic variational inference using proximal-gradient methods with general divergence functions. In
Conference on Uncertainty in Artificial Intelligence , pages 319–328, 2016.
Hugh Salimbeni, Stefanos Eleftheriadis, and James Hensman. Natural gradients in practice: Non-conjugate
variational inference in gaussian process models. In International Conference on Artificial Intelligence and
Statistics , pages 689–697. PMLR, 2018.
KaméliaDaudel,RandalDouc,andFrançoisRoueff. Monotonicalpha-divergenceminimisationforvariational
inference. Journal of Machine Learning Research , 24(62):1–76, 2023.
Warren Morningstar, Sharad Vikram, Cusuh Ham, Andrew Gallagher, and Joshua Dillon. Automatic
differentiation variational inference with mixtures. In Arindam Banerjee and Kenji Fukumizu, edi-
tors,Proceedings of The 24th International Conference on Artificial Intelligence and Statistics , volume
130 ofProceedings of Machine Learning Research , pages 3250–3258. PMLR, 13–15 Apr 2021. URL
https://proceedings.mlr.press/v130/morningstar21b.html .
15Published in Transactions on Machine Learning Research (07/2023)
S. J. Gershman, M. D. Hoffman, and D. M. Blei. Nonparametric variational inference. In International
Conference on Machine Learning) , 235–242, 2012.
Wu Lin, Frank Nielsen, Khan Mohammad Emtiyaz, and Mark Schmidt. Tractable structured natural-
gradient descent using local parameterizations. In Marina Meila and Tong Zhang, editors, International
Conference on Machine Learning , volume 139 of Proceedings of Machine Learning Research , pages 6680–
6691. PMLR, 18–24 Jul 2021. URL https://proceedings.mlr.press/v139/lin21e.html .
Philipp Becker, Oleg Arenz, and Gerhard Neumann. Expected information maximization: Using the i-
projection for mixture density estimation. In International Conference on Learning Representations , 2019.
Geoffrey Roeder, Yuhuai Wu, and David K Duvenaud. Sticking the landing: Simple, lower-variance gra-
dient estimators for variational inference. In I. Guyon, U. Von Luxburg, S. Bengio, H. Wallach, R. Fer-
gus, S. Vishwanathan, and R. Garnett, editors, Advances in Neural Information Processing Systems ,
volume 30. Curran Associates, Inc., 2017. URL https://proceedings.neurips.cc/paper/2017/file/
e91068fff3d7fa1594dfdf3b4308433a-Paper.pdf .
R.H. Byrd, P. Lu, J. Nocedal, and C. Zhu. A limited memory algorithm for bound constrained optimization.
SIAM Journal on Scientific Computing , 16(5):1190–1208, 1995.
16Published in Transactions on Machine Learning Research (07/2023)
A Limitations
The scope of this work is narrow, focusing on two specific approaches for natural-gradient GMM-based
variational inference. There are of course many other models that can be applied for variational inference,
and, depending on the problem setting, some of these models are highly preferable over GMMs, for example,
normalizing flows should likely be preferred for high-dimensional problem settings, such as (deep) Bayesian
neural networks. However, for this work we assume that we indeed want to optimize a Gaussian mixture
model, for example, because we require an interpretable model with smooth gradients (Ewerton et al.,
2020). Even in the field of GMM-based variational inference, alternative methods, based on boosting (Miller
et al., 2017; Guo et al., 2016) or the reparameterization trick are possible. By not using natural gradients,
these methods can be applied more straightforwardly to sparse covariance parameterizations which can be
beneficial for higher-dimensional problems. However, in the considered problem setting where we can learn
GMMs with full covariance matrices, these methods are not competitive (Arenz et al., 2020) to the natural
gradient based methods described in this work. Please refer to Appendix C for a discussion of related work.
Regarding our empirical study, we want to point out several aspects that could lead to misinterpretations of
the results. While we also report a secondary metric for each test problem in our main experiment (Table 8),
pleaserecallthatthehyperparameteroptimizationwasperformedonlywithrespecttotheELBO.Wenoticed
on theplanar robot experiment, that Samtrux could still achieve competitive ELBO when initializing the
mixturemodelwithfewercomponentsthanweusedforourevaluation, whileresultinginasignificantlyworse
MMD. Hence, one should consider that for each method, the performance with respect to the secondary
metric could potentially be better, if the hyperparameters were chosen correspondingly. Similarly, one
should be careful when comparing the learning curves (which can be found in Appendix L), with respect to
efficiency or stability, as the hyperparameters have only been chosen based on the final ELBO of each run.
We used this simple and hard criterion for selecting the hyperparameters, to make the experimental study
more transparent and objective by removing human influence.
Human influence, of course, could not be completely avoided: For our main experiment, we only allowed
for a coarse hyperparameter search over carefully chosen parameters. In contrast to the first two groups of
experiments, where we used extensive Bayesian optimization to identify the best performance that we can
expect for each design choice, in the main experiment we took into account that the computational budget
for hyperparameter search (also ours) is limited. As a consequence, the results of our main experiment, are to
some extend affected by our ability to propose good hyperparameter ranges for the different design choices.
However, we had good prior knowledge about suitable parameter ranges based on the previous groups of
experiments and also based on the parameters reported by prior work, and furthermore the results of our
main experiment are consistent with the performances we observed in the previous experiments (which used
much less subjective Bayesian optimization), and, hence, we conclude that the effect of the human factor
is rather small. To increase the transparency of our empirical study we release a separate reproducibility
package2, which contains scripts for running each experiment, thereby documenting the exact conditions
under which all our experiments have been started (including hyperparameter search).
B Potential for Negative Societal Impact
Machine learning methods can have a significant impact on our daily lives. They can have a positive impact
on society by taking work off our hands, addressing challenges like the climate crisis, or helping to develop
better medical treatments. But they can also have a negative impact on society by reinforcing prejudices,
discriminating against people, invading our privacy, wasting enormous amounts of energy, or exacerbating
the imbalance of power and wealth. They can cause serious harm if we overestimate their capabilities, and
they can be used maliciously, for example, to falsify data or carry out cyberattacks.
In terms of negative impact, this work is unlikely to contribute significantly to energy waste because we
focus on structured representations with few parameters that can be learned efficiently. Furthermore, our
work does not focus on processing or forgery of images, text, or speech, so it is unlikely to have a significant
negative impact on society due to privacy violations or misinformation. We are confident that we can use
2https://github.com/OlegArenz/gmmvi_reproducibility
17Published in Transactions on Machine Learning Research (07/2023)
our findings to help people in their daily lives and have a net positive impact on society, although we of
course can not foresee how our findings will be used by future work.
C Related Work
In addition to the aforementioned methods, several other methods have explored natural gradients and trust
regions for variational inference. For mean-field approximations, Hoffman et al. (2013) propose an efficient
method for estimating the natural gradient from mini-batches, and Theis and Hoffman (2015) proposed
a related KL-constrained trust-region method. Regier et al. (2017) proposed a second-order method for
Gaussian variational inference based on Euclidean trust regions. Khan et al. (2015) introduced a KL-based
proximal point method for conjugate models and related it to natural gradient descent. For non-conjugate
models, they proposed local linearizations. Khan et al. (2016) extended this approach to other divergences
and stochastic gradients. Salimbeni et al. (2018) compute the natural gradient based on the Jacobian of
the parameters of the Gaussian and its expectation parameters. The Jacobian can be computed using
forward-mode differentiation, or by using reverse-mode differentiation twice. For GMM-based variational
inference, Daudel et al. (2023) explored the optimization of alternate divergences by presenting a method
for minimizing alpha divergences. Alpha divergences are a family of divergences parameterized by a scalar
parameterα, that forα= 1also includes the KL divergence, which we consider in this work. However, the
procedure proposed by Daudel et al. (2023) assumes 0≤α < 1and is thus not applicable in our setting.
Morningstar et al. (2021) recently proposed a method for amortized variational inference with GMMs. In
amortized VI, the parameters of the GMM are not optimized directly. Instead a neural network is trained
to predict the GMM parameters based on a given input. NPVI (Gershman et al., 2012) was presented as
nonparametric variational inference. However, it can also be regarded as a method for optimizing a very
restricted type of GMM, namely, mixtures with uniform weights and Gaussian components with isotropic
covariance matrices. Miller et al. (2017) and Guo et al. (2016) proposed boosting methods, which, however,
can require unreasonably large mixture models, because components that have been added at previous
iterations do not longer receive updates. Recently, Lin et al. (2021) investigated natural gradient GMM-
based variational inference with a structured covariance matrix, which may be important for scaling these
methods to higher dimensions.
D Background Material
We will now provide a brief introduction to natural gradient descent, Fisher information, and exponential
family distributions.
D.1 Natural Gradient Descent
A possible way to update the parameters θ(i)at iteration ito minimize an objective J(θ)is the (vanilla)
gradient descent update,
θ(i+1)=θ(i)−β∇θJ(θ),
whereβis the stepsize. However, this update is not invariant to the chosen parameterization: Using a
different parameterization J∗(λ(i)) =J(θ(i)), performing the gradient descent update based on ∇λJ∗(λ)
and changing the obtained parameters λ(i+1)back toθ(i+1)may in general result in an update θ(i)→θ(i+1)
that is not along the gradient descent in the original parameterization. To understand the reason for this
dependency on the parameterization it helps to investigate the optimization problem that is solved by
gradient descent. Namely—as can be easily verified by the Lagrangian method—, the gradient descent
update maximizes a first-order Taylor approximation of the objective subject to a Euclidean trust region
constraint,
arg min
δθJ(θ(i)) +/parenleftig
∇θJ(θ)/vextendsingle/vextendsingle/vextendsingle
θ=θ(i)/parenrightig⊤
δθ (10)
s.t.δθ⊤δθ=ϵ, (11)
18Published in Transactions on Machine Learning Research (07/2023)
where the stepsize β= (2λ)−1depends on the Lagrangian multiplier λand, therefore on the trust region
ϵ. However, measuring the distance of the update step using the Euclidean distance of the parameters is in
general not meaningful as it depends on the chosen parameterization.
Instead, natural gradient descent (Amari, 1998) uses more general Riemannian distances d(δθ) =
δθ⊤G(θ(i))δθ, where G(θ(i))is a matrix that may smoothly change as a function of θ, which is also called
the Riemannian metric tensor. The Riemannian metric tensor defines a Riemannian manifold, a curved but
locally flat manifold. Minimizing the first-order Taylor approximation subject to a trust region constraint
on the Riemannian distance d(δθ)produces an update along the natural gradient
˜∇θJ(θ)/vextendsingle/vextendsingle/vextendsingle
θ=θ(i)=G(θ(i))−1∇θJ(θ)/vextendsingle/vextendsingle/vextendsingle
θ=θ(i)
where the stepsize is again dependent on the trust region. Hence, the natural gradient can be computed by
preconditioning the vanilla gradient with the inverse Riemannian metric tensor.
When optimizing an objective with respect to a probability distribution, we can use natural gradient de-
scent based on a Riemannian distance that approximates the Kullback-Leibler divergence KL (pθ(i)||pθ(i+1))
between the old and the updated distribution. Such distance metric is typically much more appropriate than
the Euclidean distance of the parameters, as it is invariant with respect to the chosen parameterization.
The corresponding Riemannian metric tensor corresponds to the Fisher information matrix, which we will
discuss in the next subsection.
D.2 Fisher Information
The Fisher information matrix F(θ)can be derived as the Riemannian distance metric that is obtained from
the second-order Taylor approximation of the KL divergence at δθ=0,
KL(pθ||pθ+δθ)≈/integraldisplay
xpθ(x) logpθ(x)
pθ(x)dx
/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
=0−δθ⊤/bracketleftigg/integraldisplay
xpθ(x)∇θlogpθ(x)dx/bracketrightigg
−1
2δθ⊤/bracketleftigg/integraldisplay
xpθ(x)∇θθlogpθ(x)dx/bracketrightigg
δθ
=−δθ⊤/integraldisplay
x∇θpθ(x)dx
/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
=0−1
2δθ⊤/bracketleftigg/integraldisplay
xpθ(x)∇θθlogpθ(x)dx/bracketrightigg
δθ
=1
2δθ⊤/bracketleftigg
−/integraldisplay
xpθ(x)∇θθlogpθ(x)dx/bracketrightigg
δθ
=1
2δθ⊤/bracketleftigg/integraldisplay
xpθ(x)/parenleftig
∇θlogpθ(x)/parenrightig/parenleftig
∇θlogpθ(x)/parenrightig⊤
dx/bracketrightigg
/bracehtipupleft /bracehtipdownright/bracehtipdownleft /bracehtipupright
F(θ)δθ.
Hence, the steepest descent update subject to a trust-region constraint based on the approximated KL
divergence is given by the natural gradient
˜∇θJ(θ)/vextendsingle/vextendsingle/vextendsingle
θ=θ(i)=F(θ(i))−1∇θJ(θ)/vextendsingle/vextendsingle/vextendsingle
θ=θ(i).
We will now revisit exponential family distributions, a family of distributions for which the natural gradient
can be computed without explicitly computing the Fisher information matrix, as mentioned in Section 3.2.
D.3 Exponential Family Distributions
Exponential family distributions are distributions that can be written in the form
p(x;θ) =h(x) exp/parenleftig
η(θ)·T(x)−A(θ)/parenrightig
,
19Published in Transactions on Machine Learning Research (07/2023)
with base measure h(x), natural parameters η(θ), sufficient statistics T(x)and log partition function A(θ).
Furthermore, exponential family distributions can be also specified using the expectation parameters, that
is, the expected value of the sufficient statistics m(θ) =/integraltext
xpθ(x)T(x)dx.
Exponential family distributions include a wide range of distributions, such as k-dimensional Gaussian
distributions, where
h(x) = (2π)−k
2,η(θ) =/bracketleftbiggΣ−1µ
−1
2Σ−1/bracketrightbigg
,T(x) =/bracketleftbiggx
xx⊤/bracketrightbigg
, A (θ) =1
2µ⊤Σ−1µ+1
2log|Σ|
and categorical distributions, where
h(x) = 1,η(θ) =
logp1
pK...
logpK−1
pK
0
,T(x) =
[x= 1]
[x= 2]
...
[x=K]
, A (θ) =−log/parenleftig
1−K−1/summationdisplay
i=1pi/parenrightig
,(12)
and where T(x)is the one-hot encoding of the outcome x. For minimal exponential family distributions
(where the natural parameters and sufficient statistics are linearly independent) the natural gradient with
respect to the natural parameters coincides with the gradient with respect to the expectation parameters,
that is
F(θ)−1∇η(θ)J(η(θ)) =∇m(θ)J∗(m(θ))
as shown by Khan and Nielsen (2018, c.f. Theorem 1).
E Proof of Theorem 2.1
The E-step of VIPS is performed by setting the auxiliary distribution to the current model. Using θ(i)to
denote the model parameters at iteration i, the auxiliary distribution at iteration iis given by
˜q(o|x) =qθ(i)(o|x)
by construction. Following Becker et al. (2019) we express the auxiliary distribution in terms of ˜q(o) =
qθ(i)(o),˜q(x) =qθ(i)(x), and ˜q(x|o) =qθ(i)(x|o)using ˜q(o|x) =˜q(o)˜q(x|o)
˜q(x), to reformulate the lower bound
objective as,
˜J(˜q,θ) =/summationdisplay
oqθ(o)/bracketleftig/integraldisplay
xqθ(x|o)/parenleftig
log˜p(x)
˜q(x)/parenrightig
dx−KL(qθ(x|o)||˜q(x|o)))/bracketrightig
−KL(qθ(o))||˜q(o)),(13)
̸=/summationdisplay
oqθ(o)/integraldisplay
xqθ(x|o)/parenleftig
log˜p(x)
qθ(x)/parenrightig
dx=J(θ). (14)
We can see that the lower bound objective (Arenz et al., 2018; Becker et al., 2019) differs from the original
ELBO objective by two additional KL divergences, and further, by computing the entropy based on the
fixed auxiliary distribution ˜q(x) =qθ(i)(x)rather than the model qθ(x). Directly after the E-Step, the lower
bound is tight, ˜J(qθ(i),θ(i)) =J(θ(i)), because the auxiliary distributions are equal to the current model.
For proving Theorem 2.1 we need to prove that also the gradients match, that is,
∇θ˜J(qθ(i),θ)/vextendsingle/vextendsingle/vextendsingle
θ=θ(i)=∇θJ(θ)/vextendsingle/vextendsingle/vextendsingle
θ=θ(i), (15)
which would also imply that the natural gradients match, since the Fisher Information Matrix only depends
on the current distribution qθ, not on the objective.
For proving the equivalence of the gradients, the following lemma will become handy:
Lemma E.1. The gradient of the Kullback-Leibler divergence between two equal distributions qθ′(x) = ˜q(x)
is zero, that is,
qθ′(x) = ˜q(x) =⇒ ∇θKL(qθ||˜q)/vextendsingle/vextendsingle/vextendsingle
θ=θ′=0.
20Published in Transactions on Machine Learning Research (07/2023)
Proof.
∇θKL(qθ||˜q) =∇θ/integraldisplay
xqθ(x) logqθ(x)
˜q(x)dx=/integraldisplay
x∇θqθ(x)·logqθ(x)
˜q(x)dx+/integraldisplay
x∇θqθ(x)dx
=
qθ=˜q/integraldisplay
x∇θqθ(x)·0dx+∇θ1 =0
As the gradient of the KL divergence between two equal distributions is zero, these terms do not affect the
gradient of the objective function directly after the E-step. Hence, we only need to show that
∇θ/bracketleftbigg/integraldisplay
xqθ(x) logqθ(x)dx/bracketrightbigg/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle
θ=θ′=∇θ/bracketleftbigg/integraldisplay
xqθ(x) logqθ(i)(x)dx/bracketrightbigg/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle
θ=θ′.
This equivalence can be verified as follows:
∇θ/bracketleftbigg/integraldisplay
xqθ(x) logqθ(x)dx/bracketrightbigg
=/integraldisplay
x∇θqθ(x)·logqθ(x)dx+/integraldisplay
x∇θqθ(x)dx
=/integraldisplay
x∇θqθ(x)·logqθ(x)dx+∇θ1 =
θ=θ(i)/integraldisplay
x∇θqθ(x)·logqθ(i)(x)dx=∇θ/bracketleftbigg/integraldisplay
xqθ(x) logqθ(i)(x)dx/bracketrightbigg
.
Pretending for a moment that we are optimizing both objectives using the reparameterization trick, it
is inspiring to relate the lower bound, to the common practice of not backpropagating through the score
function, yielding an unbiased, but often lower-variance estimate of the ELBO gradient (Roeder et al., 2017).
F Equivalence of the Weight Updates
We will now compare the weight update used by Lin et al. (2019a; 2020), with the weight updated used by
Arenz et al. (2018; 2020), and show their equivalence.
F.1 Weight Update of Lin et al. (2019a; 2020)
Lin et al. (2020) formulate the weight update in the natural parameter space η(see Eq. 12),
η=ηold+βδ (16)
where each dimension δoof the natural gradient is given by
δo=Eq(x|o) [log ˜p(x)−logqθ(x)]
−Eq(x|K) [log ˜p(x)−logqθ(x)].
Defining
ˆR(o) =Eq(x|o) [log ˜p(x)−logqθ(x)],
thei-th index of the natural parameters is given by
ηi=ηold,i+βˆR(o)−βˆR(K).
21Published in Transactions on Machine Learning Research (07/2023)
The new weight of component o<Kis given by
q(o;η) =exp (ηo)/bracketleftig/summationtextK−1
k=1expηk/bracketrightig
+ 1=exp/parenleftig
ηold,o+βˆR(o)−βˆR(K)/parenrightig
/bracketleftig/summationtextK−1
k=1exp/parenleftig
ηold,k+βˆR(k)−βˆR(K)/parenrightig/bracketrightig
+ 1
=q(o)old
q(K)oldexp/parenleftig
βˆR(o)/parenrightig
/bracketleftigK−1/summationdisplay
k=1q(k)old
q(K)oldexp/parenleftig
βˆR(k)/parenrightig/bracketrightig
+ expβˆR(K)=q(o)oldexp/parenleftig
βˆR(o)/parenrightig
K/summationdisplay
k=1q(k)oldexp/parenleftig
βˆR(k)/parenrightig.
Hence, for all components (including K), we have
q(o)∝q(o)oldexp/parenleftig
βˆR(o)/parenrightig
. (17)
F.2 Weight Update (VIPS)
We start be expressing the component’s reward R(o)in terms of ˆR(o), namely,
R(o) =Eqθ(x|o)/bracketleftig
log ˜p(x) + log ˜q(o|x)/bracketrightig
+H(q(x|o))
=Eqθ(x|o)/bracketleftig
log ˜p(x) + logq(o|x)−logq(x|o)/bracketrightig
=Eqθ(x|o)/bracketleftig
log ˜p(x) + logq(o)−logq(x)/bracketrightig
=ˆR(o) + logq(o),
where we exploited that the auxiliary distribution is chosen according to the true responsibilities, ˜q(o|x) =
q(o|x).
Expressing the weight update of VIPS (Arenz et al., 2018, Eq.8) in terms of ˆR(o),
q(o)∝/bracketleftig
qold(o)ηw
1+ηwexp (R(o))1
1+ηw
=qold(o)ηw
1+ηwexp/parenleftig
ˆR(o) + logqold(o)/parenrightig 1
1+ηw
=qold(o) exp/parenleftbigg1
1 +ηwˆR(o)/parenrightbigg/bracketrightig
,
we can see that it exactly matches the update in Equation 17 for β=1
1+ηw.
G Comparisons with Reference Implementations
The target distributions BreastCancer ,GermanCredit ,GMM20 andPlanarRobot4 were taken from
VIPS (Arenz et al., 2020). The design choices of VIPS correspond to the codename Zamtrux in our
implementation. Table 6 compares the final (negated) ELBO that we achieved in our main experiments (cf.
Table 5) with the performance of VIPS reported by Arenz et al. (2020), that was obtained using their (C++)
implementation. For all environments that have been tested in both works, the final ELBO performances
published in this work are better than the results published in the original work, except for GermanCredit
were, we could not measure any difference between both implementations.
We also compared our implementation with the Matlab implementation of Lin et al. (2020) on the target
distributions that we took from their work ( STM20andSTM300 ). However, our problem setting slightly
differsfromtheoriginalsetting,asLinetal.(2020)useanexpensiveHessian-basedpre-trainingforinitializing
the GMM and compare the methods only with respect to their fine-tuning performance. We found that such
pre-training is in general not necessary with our implementation and directly use the respective algorithms
22Published in Transactions on Machine Learning Research (07/2023)
Implementation BreastCancer GermanCredit GMM20 PlanarRobot4
VIPS/ Zamtrux (theirs) 78.20±0.04 585.10±0.00 0.01±0.00 12.02±0.13
VIPS/ Zamtrux (ours) 78.14±0.01 585.10±0.00−0.00±0.0011.48±0.04
Table 6: We compare the final (negated) ELBO achieved by both implementations. When using the same
design choices as VIPS (Arenz et al., 2020), our implementation and hyperparameters led to better approx-
imations on their target distributions.
starting from the original initialization of Lin et al. (2020). Figure 1, which compares the learned model
and the target distributions based on the marginals on the STM20 experiment, demonstrates that even
without pre-training, we can learn higher-quality approximations with our implementation (cf. Lin et al.,
2020, Fig.3). Here, we used the Samtron design choices, which performed best in our experiments.
We ran the STM20 experiments on the reference implementation (with disabled pre-training) using our
hyperparameters, and using the hyperparameters of Lin et al. (2020) and compare the learning curves with
ourSepyfux evaluation in Figure 2a. Our hyperparameters achieve better final ELBO even on the original
implementation. Using the same hyperparameters, the learning curves of both implementations do not
differ significantly, but our implementation performed slightly better. The STM300 experiment was not
evaluated by Lin et al. (2020) in the first-order setting, but only when using Hessian information (using
Eq. 6 left), which is often computationally prohibitive. Hence, we can only compare both implementations
using our hyperparameters. The respective learning curves are shown in Figure 2b and very similar for both
implementations.
H Hyperparameters
We list the hyperparameters for each design choice in Table 7. Please refer to Appendix I for a description
of the different hyperparameters. The tested and eventually chosen hyperparameters for each experiment
can be found in the reproducibility package; please refer to its README.rst file for links to all relevant config
files.
I Notes On Our Implementations
We implemented two different options for estimating the natural gradients for the component update in two
separate classes. The MoreNgEstimator uses weighted least squares to estimate the natural gradient using
compatible function approximation; the SteinNgEstimator makes use of gradient information, using Stein’s
Lemma to estimate the natural gradient. For both options, a boolean hyperparameter is available to select
whether self-normalized importance weighting, or standard importance weighting should be used to make
use of samples from different distributions. Furthermore, a boolean hyperparameter can be used to disable
importance sampling, only using samples from the respective component during the component update,
which we enabled for all methods on WINEto reduce memory footprint. When using MORE, an additional
hyperparameter can be used to select the initial ℓ2-regularization for linear least-squares; the regularizer is
automatically adapted as described by Arenz et al. (2020).
We implemented three options for performing the natural gradient update of the components based on the
estimated natural gradients and given stepsizes (or trust regions). The DirectNgBasedComponentUpdater
directly applies the natural gradient update given by Equation 4. If an updated component is no longer
positive definite, the update is undone, hoping that the update would succeed in the next iteration (poten-
tially with a smaller stepsize). The NgBasedComponentUpdaterIblr updates the components according to
the improved Bayesian learning rule (Eq. 8). We noticed that the update may still result in non-invertible
covariance matrices (albeit much less frequently compared to the natural gradient update) due to numerical
errors, in which case we also undo the respective updates. The KLConstrainedNgBasedComponentUpdater
solves an optimization problem to find stepsizes that result in positive definite covariance matrices and
updated distributions that respect the desired bound on the KL divergence, as discussed in Section 3.3.
For solving the convex optimization problem, Arenz et al. (2018) used an L-BFGS-B (Byrd et al., 1995)
23Published in Transactions on Machine Learning Research (07/2023)
0.000.050.100.15
0.00.10.20.3
0.000.050.100.150.200.25
0.00.10.20.3
0.000.050.100.15
0.000.050.100.150.200.25
0.000.050.100.15
0.000.050.100.15
0.000.050.100.150.20
0.000.050.100.150.200.25
0.000.050.100.150.200.25
0.000.050.100.150.20
0.00.10.20.30.4
0.000.050.100.15
0.000.050.100.150.200.25
0.000.050.100.150.200.25
20
 10
 0 10 200.00.10.20.3
20
 10
 0 10 200.00.10.20.3
20
 10
 0 10 200.000.050.100.150.20
20
 10
 0 10 200.000.050.100.150.20
Figure 1: A representative plot of the 20 marginal distributions of the GMM learned with Samtron for
theSTM20experiment is shown in red. The marginals of the Mixture of Student-T target distribution are
shown in blue and hardly distinguishable.
24Published in Transactions on Machine Learning Research (07/2023)
0 1 2 3 4
1e6100101
reference (our params)
reference (ref. params)
ours (our params)
(a) STM20
0.00 0.25 0.50 0.75 1.00 1.25 1.50
1e6102reference
ours (b) STM300
Figure 2: The learning curves plot the ELBO (in logarithmic scale) over the number of samples for our
implementation and the reference implementation, where both use the Sepyfux design choices. On STM20
our hyperparameters lead to a better approximation than the hyperparameters used by Lin et al. (2020),
and when using the same hyperparameters, our implementation performs slightly better. On STM300 both
implementations perform similarly using our hyperparameters. Reference hyperparameters are not available
forSTM300.
Module Design Choice Hyperparameters
Component
AdaptationFixed - - - -
Adaptive adding iter. deletion iter. # prior samples # DB samples
Component
Stepsize
AdaptationFixed initial_stepsize - - -
Decaying initial stepsize annealing exponent - -
Adaptive initial stepsize min stepsize max stepsize -
NgBased
Component
UpdaterDirect - - - -
iBLR - - - -
Trust-Region - - - -
NgEstimatorStein self-normalized IW use own samples - -
MORE self-normalized IW use own samples ℓ2-coefficient -
Sample
SelectorComp.-Based desired samples reused samples - -
Mixture-Based desired samples reused samples - -
Weight
Stepsize
AdaptationFixed initial_stepsize - - -
Decaying initial stepsize annealing exponent - -
Adaptive initial stepsize min stepsize max stepsize -
Weight
UpdaterDirect self-normalized IW - - -
Trust-Region self-normalized IW - - -
Table 7: The table lists each hyperparameter that was tuned at any of the experiments.
25Published in Transactions on Machine Learning Research (07/2023)
optimizer. However, it was difficult to efficiently integrate such optimizer into our Tensorflow (Abadi et al.,
2015) implementation, and furthermore, the optimizer would sometimes fail for numerical reasons. Instead,
we implemented a simple bisection method, by iteratively refining an initially sufficiently large bracket on
logβoby evaluating the center of the bracket and using it as new upper value when the corresponding KL
divergence is too small or the covariance matrix not positive definite, or, otherwise, as new lower value.
Although naive, this approach is numerically robust by only requiring the sign of the gradient of the KL
divergence, converges to the optimum due to the convexity of the problem and can be efficiently compiled
into a compute graph.
For theSampleSelector module, we implemented two options. Both options can make use of samples from
previous iterations (as discussed by Arenz et al. (2020)), by setting the hyperparameter nreusedlarger than
zero. The LinSampleSelector computes the effective sample size neffon the GMM and draws max(0,N·
ndes−neff)new samples from the GMM. For nreused = 0this approach corresponds to the procedure used
by iBayes-GMM (Lin et al., 2020). The VipsSampleSelector computesneff(o)for each component and draws
max(0,ndes−neff(o))new samples from each component, matching the procedure used by VIPS (Arenz
et al., 2020).
We implemented two options for performing the weight update. The DirectWeightUpdater directly updates
the categorical distribution using Eq. 9, whereas the TrustRegionBasedWeightUpdater uses our bracketing
search to stay within a given trust region. Whether standard importance sampling or self-normalized impor-
tance sampling should be used for estimating the component rewards R(o)can be chosen with a hyperpa-
rameter, that is available for both options and can be chosen independently to the respective hyperparameter
of theNgEstimator .
For stepsize adaptation, we implemented three options for both, the ComponentStepsizeAdaptation module
and theWeightStepsizeAdaptation module. The FixedComponentStepsizeAdaptation andFixedWeightStep-
sizeAdaptation simply return a fixed stepsize, chosen as a hyperparameter. The DecayingComponentStep-
sizeAdaptation andDecayingWeightStepsizeAdaptation return an exponentially decaying stepsize based on
the number of times the respective distribution has been updated, as described by Khan et al. (2018). The
ImprovementBasedComponentStepsizeAdaptation andImprovementBasedWeightStepsizeAdaptation increase
the stepsize if the last update of the respective distribution improved its reward, and decrease it otherwise,
as proposed by Arenz et al. (2020).
For theComponentAdaptation module, we implemented two options. The FixedComponentAdaptation does
nothing, keeping the number of components fixed throughout optimization; the VipsComponentAdaptation
uses the procedure of VIPS (Arenz et al., 2020) to delete bad components, and to add new components in
promising regions. Arenz et al. (2020) only considered samples from the sample database for initializing the
mean of the new component, however, we had to disable the sample database for the high-dimensional prob-
lemsSTM300 andWINEto reduce memory footprint. Hence, we introduced an additional hyperparameter
to specify additional samples from the prior distribution (the same distribution that was used for drawing
the means of the initial GMM), that should be drawn specifically for ComponentAdaptation .
J Test Problems
We performed several experiments on target distributions taken from related work. For additional details,
please refer to the corresponding work. The BreastCancer ,GermanCredit ,PlanarRobot andGMMexper-
iments were used by Arenz et al. (2020) and the Student-T experiments were used by Lin et al. (2020).
For the most detailed (and fully accurate) specification of all target distributions, please refer to our code
supplements ( https://github.com/OlegArenz/gmmvi ).
•In theBreastCancer andGermanCredit experiments, we aim to approximate the posterior distribu-
tion of a logistic regression problem. The dimensions are 25and31, respectively. The data sets can
be obtained from the UCI Machine Learning Repository (Lichman, 2013) and contain 1000and569
data points. Mimicking the setup of Arenz et al. (2020), the ELBO is computed on the full data set
during training and evaluation. For the minibatch variants GermanCreditMB andBreastCancerMB
we also use batches from the full data set, such that the respective ELBOs are comparable with the
26Published in Transactions on Machine Learning Research (07/2023)
original experiments. However, we report the full-batch ELBOs to remove unnecessary noise in the
evaluation.
•In theWINEexperiment we want to approximate the posterior distribution over the weights of a
neural network that predics the scalar wine quality based on eleven features using the WINE data
set Lichman (2013). The network has two hidden layers of width 8, resulting in 177parameters.
The likelihood is given by the root mean squared error over a minibatch of size 128. We split the
data set into a training and test set, and make sure that the training and test sets are deterministic
given the seed. As we are primarily interested in the ability of the different methods to approximate
a given target distribution (rather than testing how the approximations perform on the downstream
task), we report the training set ELBOs. However, Table 8 reports as secondary metric the mean
squared error of the prediction using approximate Bayesian inference on the test set.
•In the planar robot experiment, we aim to sample joint configurations of a 10-link planar robot (all
links have the same length) and aim to reach one of four goal positions. The target distribution
is Gaussian in the endeffector configuration space (but non-Gaussian in the joint configuration
space). A zero-mean Gaussian prior on the joint angles is additionally used to prevent non-smooth
configuration.
•In theGMMexperiment we aim to approximate an unknown Gaussian mixture model with 10
components and a varying number of dimensions. Arenz et al. (2020) only considered 60 dimensions,
but we increased the dimensionality to up to 100. The mean is sampled uniformly in the range
[−50,50]and the covariance matrices Σ=A⊤A+Iare created by randomly sampling the elements
of the square matrix A.
•The mixture of Student-T experiment ( STM) is similar to the GMMexperiment but uses Student-T
componentsinsteadofGaussians. WeexactlyfollowLinetal.(2020)byconsideringa20-dimensional
mixture with 10 components with mean uniformly sampled in [−20,20], and a 300-dimensional mix-
ture with 20 components sampled in [−25,25]. We follow Lin et al. (2020) by initializing the
components of the GMM by sampling the mean from a zero-mean Gaussian distribution with di-
agonal covariance with standard deviation 100, and by initializing the diagonal covariance matrices
withΣinit= 300 I. However, instead of pre-training with a second-order method, we directly start
training from the initial GMM.
•TheTALOS experiment is based on the implementation by Pignat et al. (2020). The poses of both
feet, as well as the positions of the left end-effector and the center-of-mass are computed for the
given joint positions based on a kinematic model of the robot. The target positions of the feet are
given by [−0.02,0.09,−0.]and[−0.02,−0.09,−0.]and their target orientation are given by identity
rotation matrices R=I3. The likelihood for each foot, is given by a 12-dimensional Gaussian
distribution that penalizes deviations from these goal-parameters using a standard deviation of 0.2
for the Cartesian positions and a standard deviation of 0.1for each entry of the rotation matrix.
The likelihood of the left endeffector position is given by a Gaussian with mean [0.1,0.5,1.]and
diagonal standard deviations of 0.02. Violations of the inequality constraints that the joint angles
should be within their limits, and the center-of-mass within the convex polygon spanned by the feet
are penalized using the log-density of a Gaussian distribution placed on the violated bound (Pignat
et al., 2020) using a standard deviation of 0.01for the center-of-mass and 0.05for the joint limits.
K Full Table for Experiment 3
The complete table for Experiment 3, showing all tested candidates, can be found in Table 8.
L Learning Curves
The learning curves (ELBO over time) for our main experiments are shown in Figure 3.
27Published in Transactions on Machine Learning Research (07/2023)
1000 2000 30000.001.753.505.257.00+7.8e1
(a) Breast Cancer
1000 2000 30000.03.57.010.514.017.521.0+7.8e1 (b) Breast Cancer (MB)
2000 4000 60000.000.020.040.060.080.10+5.8509e2 (c) German Credit
2000 4000 60000.000.240.480.720.961.20+5.8509e2
(d) German Credit (MB)
0 500 1000 15000.000.250.500.751.00 (e) GMM (20D)
0 500 1000 15000.000.250.500.751.00 (f) GMM (100D)
0 2000 4000 60000.000.250.500.751.00
(g) STM (20D)
0 20000 40000 600000.02.55.07.510.012.515.0+1.4e1 (h) STM (300D)
0 10000 200000.02.55.07.510.012.515.0+1.1e1 (i) Planar Robot (4 goals)
0 20000 40000 60000050100150200+1.35e3
(j) WINE
0 25000 50000 750000.000.450.901.351.802.5e1
 (k) TALOS
zamtrux
samyrux
samtron
samtrox
se
p
yfuxsepyrux
samyro
nsamyro
xsamtrux
Figure 3: The learning curves for our main experiment (Experiment 3) show the negated ELBO over time
(in seconds). Shaded areas show best and worst performance. Note that hyperparameters were selected with
respect to final ELBO.
28Published in Transactions on Machine Learning Research (07/2023)
Experiment Metric Samtrux Samtrox Samtron Samyrux Samyrox Samyron Sepyfux Sepyrux Zamtrux
-ELBO78 .01
±0.0278.05
±0.0278 .00
±0.0278.57
±0.0778.63
±0.0778.61
±0.0579.78
±0.4079.91
±0.9378.14
±0.01
MMD1.1e−3
±1e−41.1e−3
±1e−49.9e−4
±8e−51.2e−3
±1e−41.1e−3
±2e−41.3e−3
±1e−42.3e−3
±3e−42.8e−3
±3e−41.1e−3
±1e−4
-ELBO79.66
±0.3279.71
±0.4378 .41
±0.0379.68
±0.1979.94
±0.2379.96
±0.2680.13
±0.6979.38
±0.2583.65
±0.97
MMD2.9e−3
±1e−32.6e−3
±8e−41.7e−3
±2e−42.2e−3
±8e−42.8e−3
±9e−42.9e−3
±8e−42.5e−3
±4e−41.9e−3
±2e−48.3e−3
±2e−3
-ELBO585 .10
±0.00585 .10
±0.00585 .10
±0.00585 .11
±0.00585 .10
±0.00585 .11
±0.01585 .12
±0.01585 .11
±0.01585 .10
±0.00
MMD5.5e−4
±4e−55.9e−4
±6e−55.5e−4
±5e−55.7e−4
±3e−55.5e−4
±4e−55.7e−4
±3e−55.6e−4
±5e−55.6e−4
±5e−56.0e−4
±7e−5
-ELBO585 .12
±0.01585 .13
±0.01585 .12
±0.00585 .13
±0.00585 .13
±0.01585 .12
±0.00585 .12
±0.00585 .12
±0.00585 .35
±0.03
MMD6.5e−4
±1e−48.1e−4
±2e−45.9e−4
±4e−56.0e−4
±5e−56.2e−4
±7e−55.4e−4
±5e−55.8e−4
±1e−45.7e−4
±6e−51.9e−3
±6e−4
-ELBO11 .47
±0.0511 .47
±0.0411 .47
±0.0413.16
±0.2012.98
±0.0912.93
±0.1317.26
±2.1316.35
±0.6511 .48
±0.04
MMD1.6e−2
±8e−41.6e−2
±2e−31.6e−2
±1e−33.7e−2
±7e−32.6e−2
±2e−32.4e−2
±2e−34.5e−1
±6e−24.4e−1
±7e−21.6e−2
±9e−4
-ELBO−0.00
±0.000.00
±0.00−0.00
±0.000.00
±0.000.01
±0.030.00
±0.000.43
±0.150.28
±0.15−0.00
±0.00
Modes10 .00
±0.0010 .00
±0.0010 .00
±0.0010 .00
±0.009.90
±0.2810 .00
±0.007.90
±1.168.80
±1.1110 .00
±0.00
-ELBO0.00
±0.000.00
±0.000.01
±0.030.05
±0.030.09
±0.070.16
±0.094.54
±0.520.96
±0.361.21
±0.15
Modes10 .00
±0.0010 .00
±0.009.90
±0.2810 .00
±0.009.70
±0.439.40
±0.460.00
±0.007.00
±1.853.00
±0.42
-ELBO0.12
±0.070.02
±0.040.00
±0.000.04
±0.020.05
±0.030.03
±0.010.46
±0.060.46
±0.070.54
±0.17
Modes8.90
±0.669.80
±0.3810 .00
±0.0010 .00
±0.009.90
±0.2810 .00
±0.009.20
±0.839.20
±0.716.10
±0.99
-ELBO15 .00
±0.3815 .24
±0.3614 .96
±0.4822.41
±0.2322.28
±0.1322.50
±0.1526.69
±0.3926.87
±0.45N/A
Modes13 .70
±1.8014 .10
±1.5014 .30
±1.539.57
±1.739.80
±1.589.10
±0.990.90
±0.890.30
±0.43N/A
-ELBO1435 .65
±34 .061429 .02
±30 .931423 .12
±31 .551432 .72
±30 .491430 .80
±30 .661433 .87
±30 .493279 .32
±1425 .124100 .92
±1295 .5716 503 .38
±813 .75
MSE0.48
±0.020.48
±0.020.47
±0.020.48
±0.020.47
±0.020.48
±0.020.67
±0.140.76
±0.170.80
±0.13
-ELBO−24 .32
±0.22−24 .30
±0.10−24 .43
±0.16−24 .13
±0.14−23.91
±0.13−24.00
±0.23−16.64
±5.26−19.00
±1.07−23.69
±0.16
H(q)−16 .81
±0.07−16 .88
±0.09−16 .82
±0.07−17.26
±0.10−17.32
±0.16−17.25
±0.16−25.03
±5.46−22.34
±1.11−16 .91
±0.07BreastCancer
BreastCancer
(minibatches)
GermanCredit
GermanCredit
(minibatches)
Planar Robot
GMM20
GMM100
STM20
STM300
WINE
TALOS
Table 8: The full table for our main experiment shows all tested candidates, as well as the secondary metrics.
29Published in Transactions on Machine Learning Research (07/2023)
Experiment Metric Samtrux Samtrox Samtron Samyrux Samyrox Samyron Sepyfux Sepyrux Zamtrux
-ELBO78 .00
±0.0278.04
±0.0278 .01
±0.0178.62
±0.0878.62
±0.0578.61
±0.0679.68
±0.4080.13
±0.7978.15
±0.02
ACCURACY98 .72
±0.1198 .79
±0.1298 .75
±0.0998 .79
±0.0998 .70
±0.0898 .70
±0.1198 .77
±0.1398 .75
±0.0998 .70
±0.11
-ELBO79.54
±0.1979.54
±0.2478 .40
±0.0379.70
±0.2079.90
±0.2279.95
±0.2379.83
±0.7079.59
±0.7085.88
±3.41
ACCURACY98 .73
±0.1098 .79
±0.1298.66
±0.0898 .72
±0.1598 .77
±0.0798 .79
±0.1498 .80
±0.1098.75
±0.0598 .89
±0.08
-ELBO585 .10
±0.00585 .10
±0.00585 .10
±0.00585 .11
±0.00585 .11
±0.00585 .11
±0.00585 .12
±0.01585 .12
±0.01585 .10
±0.00
ACCURACY78 .47
±0.1378 .47
±0.1078 .55
±0.1078 .47
±0.1078 .55
±0.0678 .47
±0.1078 .52
±0.1278 .53
±0.0978 .54
±0.11
-ELBO585 .12
±0.01585 .14
±0.01585 .12
±0.00585 .13
±0.00585 .12
±0.01585 .12
±0.00585 .12
±0.01585 .11
±0.00585 .32
±0.02
ACCURACY78 .52
±0.0978 .52
±0.1578 .55
±0.1078 .49
±0.0978 .53
±0.0978 .52
±0.1378 .49
±0.1178 .54
±0.1078 .46
±0.14BreastCancer
BreastCancer
(minibatches)
GermanCredit
GermanCredit
(minibatches)
Table 9: We reran the experiments on the logistic regression tasks where we also evaluated to accuracy
of the Bayesian inference predictions (based on 2000 samples from the learned model). These experiments
use the same hyperparameters and seeds that were used for the experiments reported in Table 8. For these
tasks, slightly better approximations of the posterior, did not result in significant differences in the prediction
accuracy.
M Tips for the Practitioner
We do not want to make the impression that any variant, e.g. our proposed hybrid variant Samtron is to be
unconditionally preferred. Instead, the different variants have their own advantages and disadvantages. In
this section, we would like to discuss some tradeoffs that should be considered when applying our generalized
framework to a practical problem.
M.1 Exploitation vs. Exploration
We found that exploration is a key concern, when aiming to learn a highly accurate approximation that
covers many different modes of the target distribution. Several design choices are particular important for
discovering different modes.
•Sampling from the Components. Based on our experience, sampling from the individual compo-
nents (design choice M) is not only important for discovering different modes, but also for ensuring
that the discovered modes are actually covered by components with appropriate weight. Sampling
from the mixture ( P) may lead to a vicious circle, where components that don’t approximate their
respective mode very well, will have low weight and, thus, not receive sufficient samples to improve
the approximation and obtain larger weight. On the other hand, design choice Mmay end up
sampling at locations that are not relevant for a good approximation, which may lead to bad sample
efficiency. Hence, when very fast learning is essential, Pcan be preferable.
•Adapting the Number of Components. Adapting the number of components by adding new
components in promising regions is a very effective technique to improve exploration. Often, initial-
izing a GMM with a single, high-entropy component and adding new components at good sample
locations (Arenz et al., 2020) is still able to discover multiple different modes of the target distribu-
30Published in Transactions on Machine Learning Research (07/2023)
tion. However, we found that initializing with many components is an effective strategy to further
improve exploration. As the component adaptation strategy also involves deleting components with
low weights, it is even feasible to start with large initial GMMs and naturally reduce its size by
deleting low weight components that no longer improve. Dynamically growing and shrinking the
size of the GMM can not only help in exploration but may also improve sample efficiency, and
therefore seems generally preferable compared to optimizing a fixed-size GMM.
•Number of Samples. The hyperparameter of the SampleSelector that specifies the number of
desired samples does not only trade off training stability and efficiency, but also affects exploration.
Hence, it may be beneficial to use relatively large sample sizes, even if they are not needed for
improving the natural gradient estimates.
M.2 Efficiency vs. Stability
The training stability is another major concern. However, when using adaptive trust regions, we can often
obtain efficient and stable updates with little hyperparameter tuning.
•Sample Size and Learning Rate. Thenumberofsamplesusedforestimatingthenaturalgradient
andthestepsize(ortrustregion)ofthenaturalgradientupdateshouldbeconsideredincombination,
since better estimates allow for larger step sizes. We found that adaptive trust regions for the
component updates (design choices TandR) can ensure stable improvements for a wide range of
differentsamplesizes, whichresultsingoodsampleefficiencyandstabilitywithlittlehyperparameter
tuning. However, too small step sizes can lead to computational overhead and too large step sizes
can harm exploration. When evaluating the target distribution is cheap, we recommend to use large
sample sizes while upper-bounding the maximum trust-region to help exploration.
•Trust Regions. While the performance of the iBLR update was often comparable to trust regions,
it was typically at least slightly worse, and also the step size adaptation seems to work slightly
better when controlling a trust region rather than the learning rate. Hence, we recommend trust
regions for the component updates, although the iBLR update can also be worth trying. For the
weight update, adaptive trust regions are preferably as they require little hyperparameter tuning.
However, also directly controlling the stepsize, and even using fixed stepsize can achieve the same
performance with good hyperparameters.
•Natural Gradient Estimation. Exploiting first-order information by using Stein’s lemma for
estimating the natural gradient (design choice S) is often around one order of magnitude more
efficient than use the zero-order method MORE. Furthermore, solving the weighted least-squares
problem can become relatively slow for large number of dimensions. Hence, we recommend to always
use Stein’s lemma, when the target distribution is differentiable.
31