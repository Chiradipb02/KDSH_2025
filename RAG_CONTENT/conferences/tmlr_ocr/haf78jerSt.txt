Under review as submission to TMLR
Forecasting Company Fundamentals
Anonymous authors
Paper under double-blind review
Abstract
Company fundamentals are key to assessing companies’ financial and overall success and
stability. Forecasting them is important in multiple fields, including investing and econo-
metrics. While statistical and contemporary machine learning methods have been applied to
many time series tasks, there is a lack of comparison of these approaches on this particularly
challenging data regime. To this end, we try to bridge this gap and thoroughly evaluate
the theoretical properties and practical performance of 22 deterministic and probabilistic
company fundamentals forecasting models on real company data. We observe that deep
learning models provide superior forcasting performance to classical models, in particular
when considering uncertainty estimation. To validate the findings, we compare them to
human analyst expectations and find that their accuracy is comparable to the automatic
forecasts. We further show how these high-quality forecasts can benefit automated stock
allocation. We close by presenting possible ways of integrating domain experts to further
improve performance and increase reliability.
1 Introduction
Company fundamentals (CFs) are a set of metrics that summarize the current financial state of a business
based on aggregate statistics, like the total revenues, profit, assets, and many other indicators (Kumbure
et al., 2022). They are key in many different contexts, including controlling, compliance with regulations,
assessing financial stability, and—very importantly—active and passive investing. These key performance
indicators (KPIs) are vital in assessing the financial well-being of companies and, in turn, determining
their appeal for investing. It has been shown that they are decent proxies for a company’s future perfor-
mance (Wafi et al., 2015; Feng et al., 2020). Through the lens of value investing, practitioners look to
invest in companies whose shares appear underpriced relative to their “intrinsic value”, for which CFs are
indicators. They anticipate the market eventually recognizing and correcting the undervaluation, yielding
new growth in the assets invested earlier. Factor investing is stricter, where only the best assets ranked
by a pre-determined static rule are chosen (Feng et al., 2020), thereby overcoming some human biases and
information overlad (Rasmussen, 2003). For example, one might select companies proportional to some CF
value. A common choice would be the EV/EBIT, i.e., their enterprise value per earnings before interest and
taxes (Guida & Coqueret, 2018). Similarly, analysts following different investment paradigms also pay close
attention to company fundamentals as essential signals.
Specifically for a value or factor investor, knowing future company fundamentals would be enormously
beneficial in making successful investment decisions measured in total share price appreciation. For example,
it has been shown that if these CFs had been known prospectively, investments could have been made much
more successfully (Alberg & Lipton, 2018; Chauhan et al., 2020; Downey, 2020). For instance, using a
clairvoyant model that always “predicts” the correct value without error, Chauhan et al. are able to reach a
simulated annualized return of ∼40% (for one year of looked-ahead). This naturally leads to the question
of whether reliably forecasting CFs using machine learning models can enhance investment decisions. This
is particularly promising since the intersection of machine learning (ML) and quantitative financial analysis
has opened new possibilities for predicting company fundamentals, a domain traditionally dominated by
statistical methods and manual assessments by analysts with very specific domain expertise. When instead
of the clairvoyant model Chauhan et al. (2020) used real forecasts with inevitable prediction errors, this
1Under review as submission to TMLR
improved their lookahead factor model’sannualized return by 3.7 percentage points over a quantitative factor
modelbasedonmerelycurrentCFs. Ontheotherhand, theworkbyDowney(2020)didnotshowasignificant
benefit of using automated forecasts. This uncertain yet promising state of affairs motivates forecasting CFs
as precisely and reliably as possible to serve as building blocks for factor models. Subsequently, we can
rigorously assess the benefit of these prognoses to factor investing as a case study.
Specific challenges in this type of financial time series demand a thorough comparison of models. The data is
very diverse, as companies across regions and industries can exhibit vastly different dynamics. Also, different
variables that mirror different business processes and behave differently, yet depend on each other. For ex-
ample, a company’s revenue is usually a rough indicator of its income if their typical ratio is known from the
last years. Furthermore, the time series are predominantly non-stationary, meaning that the distributions
and dependencies of the variates change dramatically over time (cf. Section 4.1.2 and Schmitt et al. (2013)).
This reaches far beyond the mere increase in the mean market capitalization of companies and accompanying
heteroscedasticity (Kwon et al., 2023) since the interplay of the metrics and behavior of companies varies over
time as markets develop. For example, the role of intangible and, specifically, digital assets changed dramat-
ically over the last decades (Lim et al., 2020). Additionally, many sectors, like tourism, at least temporarily
experienced significant transformations in the pandemic years starting from 2020 (cf. Section 4.1.3). Our
concrete dataset of CFs contains further specific challenges, opening up many interesting research opportu-
nities. First of all, the number of samples is rather small compared to many other deep learning datasets,
considering that only 2578 companies fit our selection criterion explained in Section 4.1. Also, many fore-
casting models were developed for longer time series instead of quarterly data, available for less than two
decades. For example, the Prophet model (Taylor & Letham, 2018) assumes “business time series”, i.e.,
daily samples with the typical effects of weekends and holidays, to be applied most effectively. Furthermore,
the selected covariates contain a lot of information while exhibiting complicated dynamics. This puts the
models in danger of overfitting, especially the high-capacity ones. Furthermore, when forecasting time series
in general, it is often unclear which model and configuration is the most appropriate (Subrahmanyam, 2010;
Kumbure et al., 2022; Ma & Fildes, 2023). Luckily, the nature and amount of data permit a wide range of
models to be used. Conversely, this necessitates a comprehensive analysis to determine the best models for
each goal. These challenges make it a particularly interesting case study for research into ML forecasting.
Applying forecasting methods to CFs opens many interesting secondary research opportunities. For instance,
onecouldinvestigateiflatentpatternsofsocialbehaviorarerevealedbyinspectingtheforecastsandwhatthe
MLmodelsattendto(Kelly&Xiu,2023, Sec.1.1). Furthermore, uncoveringandquantifyingcorrelationsand
interdependencies between sectors and individual companies might help reveal the structure of complicated
and interwoven businesses that would otherwise remain opaque to outside observers.
Key Contributions After identifying the wide research gap of a comprehensive qualitative andquanti-
tative overview of company fundamentals forecasting methods, our main contributions can be summarized
as the following:
(i) Effective data selection and preprocessing measures appropriate to deal with the vast range of
magnitudes and the exponential nature of the variables under consideration.
(ii) A balanced examination of classical statistical and contemporary deep learning forecasting models.
We summarize their construction and classify them according to their capabilities and properties.
(iii) Aninvestigationofthemodel’sfitnessforforecastingcompanyfundamentals, acomparisontohuman
forecasts, the availability of uncertainty estimates, their applicability to investment strategies by
factor model backtesting.
(iv) A discussion of applicable methods for interpretability, explanations, and incorporation of expert
knowledge.
Overview We start by reviewing related research to contextualize this work and further motivate its
necessity (Section 2). We then describe the models under investigation and highlight their specific strengths
and weaknesses (Section 3). Finally, we empirically compare the models on a real-world dataset of company
2Under review as submission to TMLR
fundamentals and perform an in-depth comparison of the models based on that (Section 4). We continue by
discussing interpretability and opportunities for expert involvement (Section 5), and finally conclude with
an outlook on possible future research directions (Section 6).
2 Related Work
Use of Past Company Fundamentals For a long time, CFs have been widely used in many economic
contexts by both practitioners and researchers (Hayes, 1961, pp. 155ff). They serve as a foundation to assess
the current success and financial sustainability of businesses. As objective and quantitative measures, they
are often beneficially employed in factor investing (Aspris et al., 2013; Wafi et al., 2015; Muhammad & Ali,
2018; Guerard et al., 2015; Song & Lee, 2019). However, basing investment decisions solely on fundamental
values is viewed as naive and risky by many (Davis, 2017; Kok et al., 2017; Lev & Srivastava, 2022). For
example, the now famous short squeeze of the GameStop Corp. stock in January 2021 (Umar et al., 2021)
showed that additional signals like news and social media sentiment should be used to complement CFs
for trading descisions (Chen et al., 2020). However, this specific stock was overall unattractive to (value)
investing back then. These efforts complement the work in this research, where we primarily establish
effective forecasts of CFs as building blocks for further research. For instance, many stock price prediction
methods rely on a multitude of factors, including past CFs (Kumbure et al., 2022; Rasekhschaffe & Jones,
2019; Ta et al., 2020; Guida & Coqueret, 2018), and could leverage CF forecasts in the future.
Forecasting Company Fundamentals There have been some prior attempts at forecasting fundamen-
tals. Most notably, experiments with an idealized clairvoyant model always predicting the known future
and, subsequently, imperfect LSTMs showed that lookahead factor models (LFMs) based on CF forecasts
can improve returns of portfolios (Alberg & Lipton, 2018; Chauhan et al., 2020). Sun (2019) studied funda-
mentals forecasts with a few simple deep learning (DL) models yet did not apply them to stock selection.
Following the work of Alberg & Lipton (2018), Downey (2020) first replicated the “crystal ball” portfolio
based on perfect fundamental forecasts and confirmed its impressive hypothetical performance for stock al-
location. However, none of the investigated models (Random Forests, Gradient Boosting, Support Vector
Machines, Multilayer Perceptron, Linear Regression) could forecast CFs with sufficient reliability to affect
investing positively. Guerard et al. (2015) used analysts’ expectations on companies’ revenue and found this
to be a strongly beneficial signal for stock selection. This again highlights the need for accurate company
fundamental forecasts.
Financial Machine Learning There is a plethora of surveys on the broad topic of financial machine
learning (Hoang & Wiegratz, 2023; Nazareth & Ramana Reddy, 2023; Mosavi et al., 2020). Most of them
specialize in price and movement prediction of stocks, forex, or similar assets (Sezer et al., 2020; Nabipour
et al., 2020; Kumbure et al., 2022; Htun et al., 2023; Zhang et al., 2023; Kelly & Xiu, 2023). Existing surveys
often do not compare different approaches empirically, or if so, not on the same data and thereby do not
offer reliably comparable quantitative results (Spiliotis, 2023; Mahmoud & Mohammed, 2021). There is very
little comparative research into the focus topic of this work: CF forecasting.
3 Model Selection for Forecasting
We selected various models to provide a thorough overview of the available modeling toolbox, as summarized
in Table 1. Univariate forecasting models assume all variates to be independent, thereby effectively modeling
them as separate time series. Regarding notation, we will denote a univariate time series of length Tas a
sequencex1,...,xT∈R, and use bold x1,...,xT∈RDfor multivariate time series. The goal is to predict
theh∈{1,...,H}steps ahead by looking back at the last B≤Ttime steps. Some models directly predict
H > 1future steps, whereas the other models forecast one step at a time in an autoregressive fashion (see
ARin Table 1). This is sometimes called single-step and multi-step forecasting, respectively (Lim et al.,
2021). In addition to target variates and covariates, some models can additionally be conditioned on static
metadata per company, such as its primary business sector.
3Under review as submission to TMLR
Table 1: Overview of the models considered in this evaluation. It shows if they are local, global, or global
deep learning (DL) models. Further properties are if they are autoregressive (AR); the number of predicted
variates; theiruseofadditionalcovariates, staticvariables, orRevIN;andtheirabilitytoprovideprobabilistic
forecasts.
Capabilities
Model Reference Type AR # Var. Covar. Statics RevIN Prob.
Mean Value Herzen et al. (2022) local no uni ✗ ✗ ✗ ✗
ARMean( p) Herzen et al. (2022) local yes uni ✗ ✗ ✗ ✗
ARMA( p, q) Box & Jenkins (1976) local yes uni ✗ ✗ ✗ ✓
ARIMA( p, d, q ) Box & Jenkins (1976) local yes uni ✗ ✗ ✗ ✓
VARIMA( p, d, q ) Herzen et al. (2022) local yes multi ✓ ✗ ✗ ✓
AutoARIMA Hyndman & Khandakar (2008) local yes uni ✗ ✗ ✗ ✓
AutoTheta Hyndman & Billah (2003) local yes uni ✗ ✗ ✗ ✓
Prophet Taylor & Letham (2018) local yes uni ✗ ✗ ✗ ✓
Linear Reg. Herzen et al. (2022) global no multi ✓ ✓ ✗ ✓
Random Forest Breiman (2001) global no multi ✓ ✓ ✗ ✗
DLinear & NLinear Zeng et al. (2023) DL no uni ✓ ✓ ✓ ✓
RNN (LSTM) Hochreiter & Schmidhuber (1997) DL yes multi ✗ ✗ ✗ ✓
RNN (GRU) Cho et al. (2014) DL yes multi ✗ ✗ ✗ ✓
Block RNN Herzen et al. (2022) DL no multi ✗ ✗ ✗ ✓
TCN Bai et al. (2018) DL no multi ✓ ✗ ✓ ✓
Transformer Vaswani et al. (2017) DL yes multi ✓ ✗ ✓ ✓
TFT Lim et al. (2021) DL no multi ✓ ✓ ✓ ✓
N-BEATS Oreshkin et al. (2019) DL no multi ✓ ✗ ✓ ✓
N-HiTS Challu et al. (2023) DL no multi ✓ ✗ ✓ ✓
TiDE Das et al. (2023) DL no multi ✓ ✓ ✓ ✓
In addition to the preprocessing steps described later in Section 4.1.2, we evaluated applying Reversible
Instance Norm (RevIN) (Kim et al., 2022) in all non-recurrent deep learning models as shown in Table 1. It
removes some nonstationarity and possible shifts in distribution. RevIN removes the mean and rescaling to
unit variance along each individual time series and variate x. Furthermore, the result is then transformed
by an affine transform with learnable γandβ:RevIN(xt) =γ/parenleftbigg
xt−E[x]√
Var[x]+ϵ/parenrightbigg
+β.We found it to be mostly
beneficial, as shown quantitatively in detail in Appendix A.4, and will thus apply it throughout the paper.
3.1 Local Models
Thisclassofmodelsisestimatedonasingletimeseries, effectivelymodelingallcompaniesasentirelyseparate
processes. While fitting a single model is comparatively fast, estimating a separate model per company is
usually much more resource-intensive than learning a shared global model. We consider the following local
models for evaluation, also containing some simplistic baselines like Mean Value and ARMean(p).
Mean Value This simple baseline model repeatedly predicts the mean value of each variate it has seen
during training: xT+h=1
T/summationtextT
i=1xi. It is included as the arguably most simple model one should consider.
Autoregressive Mean ( ARMean( p))As another simple baseline, this predicts a simple arithmetic
mean of the last pvalues as
xt=1
pp/summationdisplay
i=1xt−i.
4Under review as submission to TMLR
Autoregressive Moving Average ( ARMA( p,q))This univariate model assumes the time series to be
recursively defined by an autoregressive (AR) and moving average (MA) component as
xt=E[x] +p/summationdisplay
i=1ϕixt−iq/summationdisplay
i=1ψiϵt−i,
with noise terms ϵtand the expected value E[·]of the time series (Box & Jenkins, 1976). The parameters ϕi
andψiare shared across the entire duration. If the time series has zero mean, the special case where ϕi=1
p
is equivalent to an ARMean(p)model.
Autoregressive Integrated Moving Average ( ARIMA( p,d,q ))TheARIMA(p,d,q )model improves
upon ARMA(p,q)byfirstcomputing ddifferencingsteps x′
t=xt−xt−1andusingthatasthebasictimeseries
to model (Box & Jenkins, 1976). VARIMA(p,d,q )is a vector-based variant of ARIMA(p,d,q )and would
thus be a good fit to model dependencies between multiple variates (Herzen et al., 2022). It is equivalent to
aVARMA(p,q)model (Lütkepohl, 2006) applied after ddifferencing steps.
AutoARIMA In practice, it is often unclear how p,d, andqshall be chosen. AutoARIMA introduces an
automated algorithm for automatically determining them in a data-driven search (Hyndman & Khandakar,
2008).
Theta Model (AutoTheta) This model was first described by Assimakopoulos & Nikolopoulos (2000)
but was later simplifed siginificantly (Hyndman & Billah, 2003). It first models a surrogate time series yt,θ,
which is connected to xtthrough its second-order derivative: y′′
t,θ=θx′′
t. This can then be used to derive
yt,θ=aθ+bθ(t−1) +θxt, withaθandbθderived from the data. The final forecast is then derived from the
casesθ= 0andθ= 2. AutoTheta then automatically optimizes its parameters (Fiorucci et al., 2016).
Prophet This model was initially geared toward business time series and conceptually decomposes the ob-
servationsintotrend, seasonality, holidays, andnoisecomponents, withseparateunivariatemodelseach(Tay-
lor & Letham, 2018). Since we model quarterly and international data, we omit the seasonality and holiday
components in this work. We found that the model performance increased when normalizing per time series
instead of across them, similar to RevIN, and thus applied it in all evaluations of the Prophet model (cf.
Appendix A.3).
3.2 Global Models
This class of models aims to learn common representations of the time series of all companies at once to
capture the dynamics shared among them. They are also usually much faster to train since only a single
model needs to be estimated instead of one per company. We consider the following global models for
evaluation.
Linear Regression This autoregressively performs a multiple and multivariate ordinary least squares
(OLS) linear regression for each predicted value on the last nlags of each of the target variates and context
covariates.
Random Forest This is an ensemble of multiple regression trees, where each one regresses on the same
observations as for linear regression (Breiman, 2001). In particular, separate random subsets of the training
data are used to grow multiple trees in the forest. Separate forests are learned for each predicted lag.
DLinear & NLinear This pair of models was proposed in 2023 as a simple baseline to compete with
comparatively intricate Transformer-based models in long-term time series forecasting (Zeng et al., 2023).
Both are only linear regression models, where multiple time steps are forecasted at once based on multiple
past steps. Predictions for different variates share weights. DLinear acts on a decomposition into trend and
residual, where NLinear only normalizes by subtracting the last value. While being rather shallow models,
they are grouped with the other deep learning (DL) models in Table 1 since they are trained similarly with
gradient descent.
5Under review as submission to TMLR
Recurrent Neural Network (RNN, specifically LSTM and GRU) While not being the first ever
RNNs, Long Short-term Memory models (LSTMs) (Hochreiter & Schmidhuber, 1997) popularized the con-
cept of iteratively consuming an input sequence to produce both an output and a hidden state propagated to
the next step. Using several gating functions, very deep LSTM networks can be trained via backpropagation
through time. Gated recurrent units (GRUs) simplify LSTMs, often reaching similar performance with fewer
parameters (Cho et al., 2014).
Block RNN (LSTM and GRU) This is a variant of the standard RNN introduced above, where the
time series is modeled as “blocks” of several observations passed to the network as one. This is akin to RNNs
trained on multivariate data.
TemporalConvolutionalNetwork(TCN) Thismodelappliesthebasicbuildingblocksofconvolutions
and residual connections to time series (Bai et al., 2018). They are crafted to induce a bias appropriate
for time series. Firstly, the convolutions are causal, meaning the kernel only receives data from preceding
timesteps. Secondly, theyaredilated, allowingthemodeltolookfurtherbackthaninaclassicalconvolutional
neural network with the same kernel size. Finally, skip connections are employed to stabilize training with
1x1 convolutions where channel dimensions misalign.
Transformer Originally proposed as a model for natural language (Vaswani et al., 2017), Transformers
have since been used as general sequence-to-sequence models. We model the data as a sequence of tokens,
i.e., vectors with added position information. Then, for each individual token, we add a combination of
projections of other tokens proportional to Scaled Dot-Product Self-Attention: softmax/parenleftbig
QKT/√dk/parenrightbig
V. Here,
the query Q, keyK, and value Vare learnable linear projections of the respective input tokens, and dk
is the token dimension. Then, skip connections and simple feed-forward layers are used to transform the
tokens. After several such layers, the prediction is extracted. Note that we use the specific implementation
from darts (Herzen et al., 2022).
Temporal Fusion Transformer (TFT) Recurrent neural networks, as in LSTMs, and attention-based
architectures of the Transformer family of models are often viewed as alternative and separate approaches.
Temporal Fusion Transformer is a take on combining them to benefit from both (Lim et al., 2021). To
this end, an LSTM encoder-decoder architecture is used for short-term patterns, where the outputs are
subsequently fed into a Transformer-like layer for long-term predictions. The architecture employs various
gating mechanisms to learn which variables to use, when to propagate features from the LSTM outputs, and
how to propagate features inside the Transformer-like layer.
N-BEATS It is often beneficial to decompose challenging tasks into a sequence of easier ones. N-BEATS,
therefore, comprises a stack of doubly residually connected blocks, where each block performs both a forecast
and a backcast (Oreshkin et al., 2019). The backcast is subtracted from the input and only then passed to the
subsequent block, in effect removing the component used by the block and only leaving the following block
with the residual. Similarly, the complete forecast is computed as the sum of individual forecasts, effectively
modeling it as an additive decomposition. Each back- and forecast is computed based on predicting basis
function coefficients to ease training and allow for inductive biases. We use the multivariate extension of
Darts (Herzen et al., 2022).
N-HiTS This model is an extension of N-BEATS, particularly made for long sequences, where hierarchical
input and outputs are used in addition to the doubly residual stacking (Challu et al., 2023). This model
assumes that the signal consists of separate low- and high-frequency components. Consequently, the blocks
in the stacks are arranged to progress from processing and generating at low to high resolution.
Time-Series Dense Encoder (TiDE) This model consists of an encoder-decoder architecture: It con-
sumes the lookback window, static metadata, and covariates; then produces a low-dimensional embedding;
and finally decodes it to the forecast (Das et al., 2023). To stabilize training, residual connections are
added within the individual encoder and decoder layers and around the entire architecture. Additionally,
the covariates are first projected, and the final forecast is un-projected per time step with another residual.
6Under review as submission to TMLR
4 Evaluation
To assess the models’ applicability to the challenging CF forecasting task, we empirically evaluate them in
several settings and across many different time scales. We continue to apply the forecasts to automatic stock
selection to determine the benefit in that field of application.
4.1 Forecasting Performance
Good data quality is crucial for accurate forecasting. Therefore, significant effort was put into curating the
covariates and targets to predict and cleaning the data to provide a consistent database. This later allows
the models to capture the common temporal dynamics of company fundamentals across different companies.
4.1.1 Selected Indicators
Based on reliable availability and the experience of experts, 20 indicators were deemed the most relevant
for predicting the future fundamentals of a company. All were used as context to predict five of them as
target variables. On the one hand, restricting the forecast to only a subset of all indicators deemed the most
insightful improved the performance slightly. Yet, learning a model forecasting all remaining five targets
jointly is a beneficial multi-task setting helping against overfitting on this rather small dataset (Zhang &
Yang, 2022). Indicators derived from cash flow and income statements are based on intervals instead of
reflecting the financial state at a single point in time, as balance sheets do. Therefore, we consider their
average over the last twelve months, denoted as LTM. The selected covariates used only to provide context
to the model are: Cost Of Revenues (LTM), Total Other Operating Expenses (LTM), Capital Expenditure
(LTM), Income Tax Expense (LTM), Total Interest Expense (LTM), Levered Free Cash Flow (LTM),
Cash from Financing (LTM), Cash from Investing (LTM), Total Cash and Short-Term Investments, Total
Current Assets, Total Assets, Total Current Liabilities, Total Liabilities, Total Debt, and Sector Revenue
Share (LTM). Based on expert experience, we chose the following five target variables as the most important
ones for decision-making: Total Revenues (LTM), Operating Income (LTM), Net Income (LTM), Cash
from Operations (LTM), and Total Equity.
We experimented with providing the model with additional static context for each company. Namely, we
added region information (Americas/Europe/Japan/Rest of Asia) and sector classifications according to the
Global Industry Classification Standard (GICS) by MSCI and S&P. We encoded them as numeric one-hot
statics for the global models that can use it (see Table 1). However, we only retained the latter since the
region information did not noticeably change the forecasts. This is likely due to it being very coarse and of
limited relevance in globally diversified companies.
4.1.2 Data Preparation
The primary quarterly company fundamentals data was obtained by integrating several commercial data
sourcesfromS&PGlobal. Considerablemanualpreprocessingwasrequiredtobringinformationfrombalance
sheets, income statements, and cash flow statements into a single format. In particular, restatements and pro
forma/hypothetical statements introduced significant inconsistencies and jumps in the data if not accounted
for appropriately. All values were converted into Euros for the sake of comparability. Companies were
included if (1) they were publicly traded throughout the entire period and, therefore, published reports, and
(2) they had at least 1 billion Euros in market capitalization once in the time span. Smaller businesses were
excluded because they typically show different dynamics than huge ones. An additional 19 companies were
removed due to highly atypical behavior. This left 2527 companies in the period from 2009 Q1 to 2023 Q3.
Appropriate data representation and normalization are critical in machine learning applications. In the
particular case of CFs, one has to counteract the different orders of magnitudes of the indicators to ensure
more similar numerical ranges of the data. We, therefore, propose an effective domain-specific normalization.
For each company individually, all variates derived from the income statement are normalized by Total
Revenues, and all variates from the balance sheet are normalized by Total Assets. Total Revenues and Total
Assets are divided by each other, respectively. This proved to be more effective than a generic Yeo–Johnson
power transformation (Yeo & Johnson, 2000). Finally, the data was normalized to have zero mean and unit
7Under review as submission to TMLR
0.000.250.500.751.001.251.501.75MSE
Mean ARMean
(1)ARMean
(4)ARMA
(1,1)ARMA
(4,4)Auto
ARIMAAuto
ThetaProphet Linear
Reg.Rand.
ForestDLinear NLinear LSTM GRU Block
LSTMBlock
GRUTCN Trans-
formerTFT N-BEATS N-HiTS TiDE
Models0.00.10.20.30.40.50.60.7sMAPE
Figure 1: The error of different deterministic models when forecasting the normalized features.
Lower is better. It shows the mean and standard deviation over all five target features, forecast horizon
steps, and folds.
variance per feature over all time steps and companies. Details on the resulting challenging dataset, including
its moments, high degree of non-stationarity, and diverse seasonality, are provided in Appendix A.2.
4.1.3 Results
We evaluated the previously described models with simulated historical forecasts, where we trained on past
in-sample (IS) data and evaluated them on unseen out-of-sample (OOS) time steps. This demonstrates
whether models can generalize to future unseen data—the crucial property in time series forecasting. To
obtain the most realistic benchmark scenarios, we used 2009 Q1 as a fixed origin and continuously expanded
the training data from only four years (16 quarters) at the beginning to 13.75years (55 quarters) at the end.
Weevaluatedseveralconfigurationstodeterminetheoptimallookbackwindow. Threeyears(twelvequarters)
was optimal for forecasting one year (four quarters). We evaluated all models on all companies and metrics
for each of the 40 simulated historical forecast chunks, each consisting of IS look-back data, IS training
forecasts, and OOS testing forecasts. To search hyperparameters and validate the deep learning models’
training success, we created a validation split by excluding 10% of the companies from training (but not from
testing). Note that the deep learning models have thus seen less of the training data, effectively including a
small generalization test to unseen companies in their evaluation. Model configurations and hyperparameters
are provided in Appendix A.3. The global models with and without RevIN are compared in Appendix A.4.
Due to numerical instabilities, we were not able to reliably fit ARIMA(4,1,4)orVARIMA(4 ,0,4)models,
for which reason they are excluded from the following analysis.
DeterministicForecasts Duetothedatanormalizationappliedpreviously, thescalesofdifferentfeatures
are more comparable than in the original data. However, the distribution of values is highly skewed, and
we want to produce forecasts that are correct relative to the specific scale of the predicted data. We,
therefore, mainly compare the deterministic predictions using the symmetric Mean Absolute Percentage
Error (sMAPE) and the training criterion Mean Squared Error (MSE):
sMAPE( y,ˆy) =2
HH/summationdisplay
i=1|yi−ˆyi|
max(|yi|+|ˆyi|,ϵ)and MSE(y,ˆy) =H/summationdisplay
i=1(yi−ˆyi)2,
where yare the targets, ˆythe predictions, and ϵa small constant added for numerical stability. In addition,
we provide results for Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), Mean Absolute
Percentage Error (MAPE), Root Squared Error (RSE), and the coefficient of determination (R2). The
probabilistic nCRPS (reduced to MAE for deterministic models) will be introduced later.
8Under review as submission to TMLR
Table 2: Comparison of average performance and standard deviation of the models measured by
different metrics. The average and standard deviation is taken over all five target features, forecast horizon
steps, and folds. The best is marked as boldand the runner-ups as underlined .
Models MAE ( ↓) MSE ( ↓) RMSE ( ↓) MAPE ( ↓) RSE ( ↓) sMAPE ( ↓) R2(↑) nCRPS ( ↓)
Mean 0.239 ±0.03 0.508 ±0.17 0.705 ±0.11 3.470 ±1.37 0.507 ±0.09 0.667 ±0.05 0.493 ±0.09 0.239 ±0.03
ARMean(1) 0.166±0.04 0.438±0.24 0.642 ±0.16 2.299 ±0.80 0.430±0.19 0.482±0.06 0.570±0.19 0.166 ±0.04
ARMean(4) 0.198 ±0.04 0.490 ±0.21 0.685 ±0.15 2.689 ±0.83 0.484 ±0.15 0.564 ±0.06 0.516 ±0.15 0.198 ±0.04
ARMA(1,1) 0.234 ±0.04 0.746 ±0.32 0.847 ±0.17 3.349 ±1.08 0.752 ±0.27 0.593 ±0.05 0.248 ±0.27 0.200 ±0.04
ARMA(4,4) 0.294 ±0.06 1.414 ±0.65 1.163 ±0.25 4.068 ±1.30 1.466 ±0.67 0.656 ±0.05 -0.466 ±0.67 0.273 ±0.05
AutoARIMA 0.183 ±0.05 0.829 ±1.21 0.808 ±0.42 2.214±0.89 0.813±1.15 0.529 ±0.05 0.187 ±1.15 0.149 ±0.04
AutoTheta 0.202 ±0.04 0.611 ±0.31 0.761 ±0.18 2.821 ±0.93 0.609 ±0.26 0.537 ±0.06 0.391 ±0.26 0.196 ±0.04
Prophet 0.298 ±0.05 1.297 ±1.21 1.077 ±0.37 4.190 ±1.33 1.410 ±1.68 0.697 ±0.06 -0.410 ±1.68 0.265 ±0.05
Linear Reg. 0.195 ±0.02 0.440 ±0.25 0.644 ±0.16 3.143 ±1.22 0.432 ±0.19 0.592 ±0.03 0.568 ±0.19 0.401 ±0.02
Random Forest 0.196 ±0.03 0.452 ±0.16 0.663 ±0.11 2.676 ±1.23 0.449 ±0.10 0.577 ±0.04 0.551 ±0.10 0.196 ±0.03
DLinear 0.186 ±0.03 0.561 ±0.35 0.719 ±0.21 2.600 ±0.99 0.560 ±0.31 0.547 ±0.03 0.440 ±0.31 0.131 ±0.02
NLinear 0.168 ±0.03 0.487±0.29 0.673 ±0.19 2.406 ±1.03 0.482 ±0.25 0.499 ±0.04 0.518±0.25 0.135 ±0.02
LSTM 0.176 ±0.03 0.395 ±0.16 0.616±0.13 2.455±0.94 0.385 ±0.09 0.535±0.04 0.615 ±0.09 0.124±0.02
GRU 0.175 ±0.03 0.378±0.16 0.602 ±0.13 2.369±0.93 0.368±0.09 0.540±0.04 0.632±0.09 0.124 ±0.02
Block LSTM 0.218 ±0.03 0.556 ±0.20 0.733 ±0.14 3.144 ±1.39 0.573 ±0.24 0.618 ±0.04 0.427 ±0.24 0.144 ±0.02
Block GRU 0.189 ±0.03 0.515 ±0.30 0.695 ±0.18 2.702 ±1.03 0.522 ±0.31 0.554 ±0.04 0.478 ±0.31 0.127 ±0.02
TCN 0.224 ±0.03 0.557 ±0.25 0.731 ±0.15 3.302 ±1.44 0.557 ±0.20 0.639 ±0.04 0.443 ±0.20 0.155 ±0.03
Transformer 0.183 ±0.03 0.483 ±0.19 0.682 ±0.14 2.494 ±0.92 0.487 ±0.18 0.534 ±0.04 0.513 ±0.18 0.132 ±0.02
TFT 0.206 ±0.02 0.477 ±0.17 0.679 ±0.13 2.918 ±1.03 0.480 ±0.15 0.595 ±0.04 0.520 ±0.15 0.134 ±0.02
N-BEATS 0.192 ±0.03 0.611 ±0.34 0.757 ±0.19 2.697 ±1.05 0.615 ±0.31 0.552 ±0.04 0.385 ±0.31 0.134 ±0.02
N-HiTS 0.185 ±0.03 0.652 ±0.42 0.773 ±0.24 2.490 ±0.73 0.636 ±0.35 0.530 ±0.04 0.364 ±0.35 0.130 ±0.02
TiDE 0.179 ±0.03 0.504 ±0.27 0.689 ±0.17 2.547 ±0.97 0.498 ±0.21 0.523 ±0.04 0.502 ±0.21 0.126 ±0.02
The comparison of the models is shown visually in Figure 1 and in full detail in Table 2. In both metrics,
the models fare notably differently. Overall, global models tend to give better results in terms of MSE, while
the picture is more varied if performance is measured in sMAPE. Specifically, the univariate local models
ARMA(4,4)and Prophet fail to provide consistent forecasts, as their high MSE and considerable variance
hint at some major mispredictions. While in terms of MSE, the two deep learning RNN models (LSTM and
GRU) give the best results, the simplistic local model ARMean(1) — somewhat surprisingly—is best in terms
of sMAPE. This highlights the need for forecasts that are not only accurate but reliable, too. Therefore, we
will now go over to probabilistic forecasts.
Probabilistic Forecasts To assess the reliability of the forecasters, we evaluated their ability to quantify
uncertaintycorrectly. Notallmodelscanestimateuncertainty,asshowninTable1. Samplingforecastscanbe
achieved in different ways. For instance, one can introduce noise in the state space as in the ARMA,ARIMA,
and AutoARIMA models or in the trend component of the Prophet model, which is similar to Monte Carlo
dropout in deep learning models (Gal & Ghahramani, 2016). The remaining models can directly estimate the
parameters of probability distributions. Therefore, and for a fair comparison, all remaining models perform
quantile regression, where the boundaries of certain quantiles were regressed on. Note that these models are
trained separately from the ones in the deterministic setting, even though represented jointly in Table 2. We
have drawn 100 samples from each probabilistic model and evaluated the resulting empirical distribution
to the known test data using the continuous ranked probability score (CRPS) (Gneiting & Raftery, 2007).
Intuitively, we first define a helper cumulative distribution function 1{x≥y}overxthat steps from zero to one
at the scalar value ythat we consider the ground truth. The CRPS then measures the integrated squared
difference between this helper and the true distribution E(x). It is defined as
CRPS(E,y) =/integraldisplay+∞
−∞/parenleftbig
E(x)−1{x≥y}/parenrightbig2dx=Eˆy∼E[|ˆy−y|]−1
2Ey1,y2∼E[|y1−y2|],
whereEis the empirical forecast distribution (i.e., the samples), yis the ground truth target, and 1{x≥y}is
an indicator that is 1 if the condition is met and 0 otherwise. This univariate metric is then averaged over
all time steps and features. We choose to present the negation of that score denoted with “nCRPS” to make
it consistent with the earlier metrics, where lower is better.
9Under review as submission to TMLR
Mean* ARMean
(1)*ARMean
(4)*ARMA
(1,1)ARMA
(4,4)Auto
ARIMAAuto
ThetaProphet Linear
Reg.Rand.
Forest*DLinear NLinear LSTM* GRU* Block
LSTM*Block
GRU*TCN Trans-
formerTFT N-BEATS N-HiTS TiDE
Models0.00.10.20.30.4nCRPS/MAE
Figure 2: The error of different models when forecasting the normalized features probabilis-
tically. Lower is better. It shows the mean and standard deviation over all five target features, forecast
horizon steps, and folds. Since the nCRPS score reduces to the absolute error (MAE) in the case of de-
terministic forecasts (i.e., a single sample), we include the non-deterministic models for direct comparison,
marked with∗.
01234EUR1e6 Cash from Operations
2
1
0121e6 Net Income
2010 2012 2014 2016 2018 2020 20221
0121e6 Operating Income
2010 2012 2014 2016 2018 2020 20223.03.23.43.63.84.0EUR1e7 T otal Equity
2010 2012 2014 2016 2018 2020 20220.40.60.81.01e8 T otal Revenues
T arget Variates
Forecast
Ground Truth
Figure 3: Qualitative example of forecasting the fundamentals forPacira BioSciences, Inc. over
several different horizons using the RNN (GRU) model. The shaded area indicates the 68% percentile.
The results are shown in Figure 2 and Table 2. We can clearly see that all deep learning models fare much
better than all others in estimating uncertainty, even though they did not see 10% of the companies before
testing. This shows their strength of learning across the time series of many companies, thereby enabling
good generalization and a more calibrated variance. The best models are again the RNN variants LSTM
and GRU, closely followed by TiDE.
An example forecast transformed back to the original feature domain is provided in Figure 3. The normalized
forecasts were inverse-transformed back into the original domain using the last-know training data to avoid
any information leakage. The model successfully captures the overall dynamics of the variates while tending
to lag slightly behind. In particular, the variance of the model appropriately captures the variability of the
ground-truth time series.
Discovering Patterns in Predictability As shown in Figure 4, not all features are equally predictable
by all models. For instance, the Total Equity is easily forecasted by ARMean(1) , yet much harder for other
models. This is plausible, given that it only moderately changes over time and thus might cause more
overfitting. On the other hand, it is surprising that Total Revenues is relatively straightforward to predict
for the deep learning models, indicating that some other covariates are predictive for it. The fact that
theOperating Income is more challenging to predict suggests that the cost of revenues varies significantly,
affecting the variate in ways that are hard to predict. Consequently, the Net Income is affected, albeit
reduced, possibly due to more steady constant taxation and interests. By cumulating it over time, one
derives the therefore equally predictable Cash from Operations .
10Under review as submission to TMLR
Cash from  
OperationsNet Income
Operating IncomeT otal Equity
T otal RevenuesMean
ARMean(1)
ARMean(4)
ARMA(1,1)
ARMA(4,4)
AutoARIMA
AutoTheta
Prophet
Random Forest
DLinear
NLinear
LSTM
GRU
Block LSTM
Block GRU
TCN
Transformer
TFT
N-BEATS
N-HiTS
TiDE0.255 0.268 0.232 0.246 0.192
0.210 0.202 0.156 0.121 0.141
0.239 0.242 0.189 0.164 0.155
0.232 0.246 0.186 0.175 0.163
0.232 0.220 0.317 0.343 0.254
0.114 0.119 0.180 0.189 0.143
0.140 0.129 0.251 0.253 0.209
0.213 0.200 0.325 0.335 0.254
0.165 0.164 0.237 0.229 0.183
0.104 0.108 0.156 0.160 0.125
0.109 0.110 0.160 0.166 0.131
0.108 0.109 0.147 0.143 0.116
0.108 0.107 0.147 0.142 0.115
0.121 0.117 0.170 0.176 0.135
0.106 0.108 0.150 0.155 0.118
0.136 0.121 0.175 0.183 0.148
0.109 0.109 0.157 0.163 0.124
0.113 0.113 0.160 0.161 0.123
0.109 0.110 0.158 0.165 0.126
0.105 0.106 0.155 0.161 0.124
0.102 0.106 0.151 0.153 0.1170.00.1
0.0 0.20.20.3
Figure 4: Models differ significantly in the features they can successfully forecast. This plot
shows the mean nCRPS/MAE per model and feature over all folds. Lower is better. It is apparent that the
Operating Income and theTotal Equity pose the greatest challenges to the models under investigation.
Global Black Swan events like the COVID-19 pandemic starkly impact forecasting performance, as shown
in Figure 5. Note that for most variates and models this extends far beyond the difficulties in forecasting
in the respective periods, like here, 2020 Q1 and onward. On the one hand, starting with 2019 Q2, the
forecast evaluation is already infected with COVID-19 effects since we forecast one year into the future.
Furthermore, the abnormal data from the pandemic period is then used to learn forecasts for later times,
which no longer share the same pandemic dynamics, extending the effect beyond the end of the special
period. We can also see that models excel in different parts of the time axis. For example, while ARMean(1)
appeared to be overall decent in Figure 2, it produces terrible forecasts in the more recent time spectrum
when we consider uncertainty estimation for Net Income while maintaining excellent performance on Total
Euqity. There seems to be a visibly recurring pattern in predictability in Cash from Operations every four
quarters, where the last quarter of each year is the least predictable.
Figure 6 shows the error at each of the four next quarters being predicted for all metrics. Interestingly, the
error does not increase arbitrarily at further steps ahead but instead falls again at four quarters into the
future. This is likely explained by the unique role of end-of-year reports, which makes them more predictable.
11Under review as submission to TMLR
2013 2014 2015 2016 2017 2018 2019 2020 2021 20220.00.10.20.30.40.5nCRPS/MAECash from Operations
2013 2014 2015 2016 2017 2018 2019 2020 2021 20220.00.10.20.30.40.5Net Income
2013 2014 2015 2016 2017 2018 2019 2020 2021 2022
Forecast Start0.00.10.20.30.40.5Operating Income
2013 2014 2015 2016 2017 2018 2019 2020 2021 2022
Forecast Start0.00.10.20.30.40.5nCRPS/MAET otal Equity
2013 2014 2015 2016 2017 2018 2019 2020 2021 2022
Forecast Start0.00.10.20.30.40.5T otal RevenuesModels
Mean
ARMean(1)
ARMean(4)
ARMA(1,1)
ARMA(4,4)
AutoARIMA
AutoTheta
Prophet
Linear Reg.
Random Forest
DLinearNLinear
LSTM
GRU
Block LSTM
Block GRU
TCN
Transformer
TFT
N-BEATS
N-HiTS
TiDE
Figure 5: Periods in which CFs are hard to predict vary across models and features. We can
immediately observe deeply impactful events like the global COVID-19 pandemic manifesting in more er-
roneous forecasts, as exemplified by the areas highlighted in blue. The mean is taken over all four-quarter
forecasts starting at each point.
1 2 3 4
look-ahead0.30.40.50.60.70.8sMAPE
1 2 3 4
look-ahead0.51.01.52.0MSE
1 2 3 4
look-ahead0.10.20.30.4nCRPS/MAEModels
Mean
ARMean(1)
ARMean(4)
ARMA(1,1)
ARMA(4,4)
AutoARIMA
AutoTheta
Prophet
Linear Reg.
Random Forest
DLinearNLinear
LSTM
GRU
Block LSTM
Block GRU
TCN
Transformer
TFT
N-BEATS
N-HiTS
TiDE
Figure 6: This shows the general trend of increasing forecast error with increasing look-ahead
horizon, with a noticeable drop at four steps. The error is over all features and folds, where lower is
better. The shaded area indicates one standard deviation. See Figure 5 for the legend.
Comparison to Human Forecasts We also compared the machine forecasts with the ones of human
expert analysts. To this end, we used data from StarMine byRefinitiv, which contains one-year-ahead non-
probabilistic forecasts of the expected Total Revenues for 87.96% of the companies from 2013 Q3 to 2022 Q2.
Thus, we need to compare them only with the automatic forecasts for that feature, those companies, the
last of the four look-ahead steps, and the valid time window. The results are provided in complete form in
Appendix A.5. In summary, automatic forecasts are superior for most metrics, even though different models
than in Table 2 are leading. However, human analysts make mispredictions that better match the scale of
the data, e.g., minor errors on small scales and large ones on bigger ground-truth numbers. This results in
much better MAPE and sMAPE scores and might hint at potentially more calibrated uncertainty estimates
if they were available. Given that human forecasts are commonly employed in investing (Guerard et al.,
2015), it is interesting to see how their utility compares to automatic forecasts.
4.2 Realisitc Market Evaluation
To investigate if the developed high-quality predictions translate to improved investment performance, we
apply them to factor models that are backtested in real-world market situations, similar to the LFMs of
Alberg & Lipton (2018). For brevity, we investigate GRU as the best model identified in Section 4.1.
12Under review as submission to TMLR
Table 3:Performance of different investment strategies employing ground truth forecasts ( Clairvoy-
ant), human analyst expectations, and forecasts from GRU models. We provide the final portfolio value, the
compound annual growth rate (CAGR), the annualized volatility, and the Beta. Overall, portfolios based
on idealized Clairvoyant and analyst expectations outperform the reference index, as well as one based on
the Operating Income forecasts using GRU and rebalanced every twelve months.
Rebalancing Forecast Perf. (%, ↑) CAGR (%, ↑) Vola. (%, ↓) Beta ( ↓)
MSCI World Reference n.a. n.a. 247.25 14.69 12.50 1.00
Operating Income
per Enterprise Value3 MonthsClairvoyant 315.42 16.97 15.41 1.13
GRU 233.22 14.17 15.81 1.16
12 MonthsClairvoyant 287.81 16.09 14.85 1.07
GRU 257.51 15.06 15.39 1.13
Total Revenues
per Enterprise Value3 MonthsClairvoyant 272.74 15.59 16.89 1.24
Analyst 312.13 16.87 15.81 1.17
GRU 238.48 14.37 16.27 1.19
12 MonthsClairvoyant 278.89 15.80 16.47 1.20
Analyst 326.29 17.31 15.55 1.14
GRU 212.76 13.38 16.23 1.19
Experimental Design We built simulated portfolios from the CF forecasts based on several different
strategies. First of all, we considered two different proxies to identify good stocks, namely, the highest
Operating Income or highest Total Revenues four quarters in the future, each normalized by the current
Enterprise Value of the company. Secondly, we rebalanced our portfolio either after each quarter or at the
start of each new year. In addition to the criteria in Section 4.1.2, we excluded the real estate and financial
sectors due to special reporting semantics.To ensure our method is not merely exploiting some current
sector-specific performances, we ensure our allocation replicates the sector composition of the MSCI World
reference index. We similarly approximate its regional distribution as closely as possible. Our portfolios
each consist of 50 stocks with a fixed 2% of the capital each. At each rebalancing step, the best possible
companies based on the above criteria are chosen, and stocks are sold and bought to reflect that reevaluation.
We compare our method to the reference index and two other investment strategies: First, we replicate the
Clairvoyant portfolios based on the same selection criteria but using the usually unknowable exact ground
truth future (Alberg & Lipton, 2018). Secondly, we compare portfolios using our forecasts with ones based
on available human analysts’ expectations for total revenues.
Findings The performance of portfolios based on CF forecasts and their baselines are shown in Table 3.
We can firstly see that for Operating Income, rebalancing each year is superior to each quarter, and vice versa
for Total Revenues, possibly due to the special annual cycle of financial reporting also visible in Figure 6.
Secondly, we can confirm that the hypothetical Clairvoyant models are effective tools for portfolio optimiza-
tion, further motivating the pursuit of improving CF forecasting. Thirdly, human analysts’ predictions are
highly effective for investing, possibly reinforced through self-fulfilling prophecies and feedback loops (Sant
& Zaman, 1996; Mauboussin, 2002). This confirms the empirical findings of Guerard et al. (2015). Lastly,
portfolios based on automated GRU forecasts are useful for investing, enabling a final portfolio value that is
10 percentage points larger than the reference index after about ten years when using the Operating Income
and rebalancing yearly. While the volatility and Beta are expectedly higher than the reference index, they
are on par with the other strategies. Detailed inspection of the entire time span reveals that our method
consistently finds better stocks than when following the reference index in the described setting, except
from the onset of the pandemic effects in Q2 2020 on to the end of 2020. Similarly, the increased volatility
originates to a large degree from the time of 2019 onwards, and was comparably low for the previous years.
This, again, matches with the findings in Figure 5, where pandemic uncertainty leaks back into the forecasts
starting 2019 Q2. This strongly motivates going beyond the probabilistic forecasting performed so far and
investigating methods to maintain reasonable performance in such unstable times too.
13Under review as submission to TMLR
Variable importance in %
Capital Expenditure (Past Covariate)Cost of Revenues (Past Covariate)Synthetic Relative Index (Future Covariate)T otal Liabilities (Past Covariate)T otal Current Assets (Past Covariate)Cash from Financing (Past Covariate)Cash from Operations (Past T arget)T otal Revenues (Past T arget)Net Income (Past T arget)Operating Income (Past T arget)T otal Equity (Past T arget)Covariates
0 2 4 6 8 10 12 14 16GICS sector: Consumer DiscretionaryGICS sector: Consumer StaplesGICS sector: UtilitiesGICS sector: Information T echnologyGICS sector: Communication ServicesGICS sector: MaterialsGICS sector: EnergyStatic Variables
Figure 7: Only some of the features are relevant for certain forecasts. The figure shows the exem-
plary importance of the input variables when forecasting using the TFT model. It shows the probabilistic
forecast for Pacira BioSciences, Inc. (see Figure 3) over all 40 folds.
5 Interpretability, Explanations and Domain Expertise
When building models, it is most often worthwhile to leverage the expertise of practitioners regularly working
with the data at hand (Collopy et al., 2001; Kelly & Xiu, 2023, Sec. 1.5). We thus provide an overview of
which of the investigated models can reasonably benefit from such information. Most models support simple
inductive biases by fixing, bounding, or regularizing certain parameters. However, this is only useful in
practice where such weights can be identified with a specific piece of domain knowledge and, therefore, not
helpful in most deep architectures. Therefore, it might be necessary to fall back to more general methods of
incorporating human insights like explainable interactive learning (XIL), where experts improve the model
by providing feedback based on explanations of model outputs (Teso & Kersting, 2019; Kraus et al., 2024).
We will discuss the possibilities of applying interpretability methods to the models at hand to permit such
approaches in the first place. This furthermore allows some degree of validation of the modeling outcomes
and is therefore highly desirable in most practical ML applications (Collopy et al., 2001; Hoang & Wiegratz,
2023). Also, parameters such as the lookback window or forecast horizon are always opportunities to use
expert knowledge and were already discussed in Section 4.1.3. In this section, we thus focus on more high-
level and human-understandable aspects specific to each model.
Local Models The simplistic ARMean(p)model only permits setting the lookback window p, thus lim-
iting its overall adaptability. Incorporating domain expertise is easily possible in the case of ARMA(p,q),
ARIMA(p,d,q ), and AutoARIMA models. For instance, we could assume that long-term means likely don’t
carry much information over shorter ones and therefore set p>q, effectively constraining ψi= 0for alli>q.
Seen the other way around, this means that if the model automatically determined such a value (either by
parameter estimation or by the search in AutoARIMA), it possibly teaches us something about the dynamics
at play. For example, a model mostly focusing on values from four quarters in the past hints at data of yearly
seasonality. Alternatively, if it has already been determined that some component is stationary, we could
setd= 0. Such an opportunity is less obvious in the case of the Theta method, though its relationship to
the exponential smoothing with drift model (SES-d) could be exploited for that (Hyndman & Billah, 2003).
The Prophet model was specifically designed to allow for human-in-the-loop modeling (Taylor & Letham,
2018). Time series are additively decomposed into trend, seasonality, holiday, and residual components.
Each is modeled separately and can accommodate expert insights. For instance, one can specify the type of
trend, manually define changepoints at which a linear trend changes, or provide capacities for trends with
saturating growth. The seasonality component allows multiple recurrence periods, and the holiday dates
can be set according to regional customs. Note, however, that the latter two do not fit the quarterly and
international data at hand and, therefore, have little applicability to CF forecasting.
14Under review as submission to TMLR
Global Models While Linear Regression permits constraining specific weights, this is hardly desirable
as this model is seldom used as more than a baseline. For most other global models, opportunities for
expert involvement are limited. However, general black-box explainability methods like SHAP or Integrated
Gradients apply to all deep learning methods (Marcinkevičs & Vogt, 2023), although the exact insight
gained from them can be challenging to understand for domain experts. Some of the models provide specific
white-box methods to gain insights into the forecasts. For example, models including and building on
Transformers (like TFT) allow inspecting the attention map to learn what the model “looks at” (Vaswani
et al., 2017) and when attention maps are atypical (Lim et al., 2021). Furthermore, TFT allows inspecting
the importance of the input variables. This is shown exemplarily in Figure 7 for all covariates with at least
3%, and static variables with at least 10% importance, respectively. The stacked N-BEATS architecture
allows for modeling different task-specific basis functions in different stacks and inspecting the backcasting
results. Thus, one can define detrending and seasonality-removing blocks and then inspect and validate their
behavior. The same is possible for the hierarchical extension N-HiTS. In summary, all of these methods allow
forinterpretingthedecisionsandexplainingtheoutputofdeeplearningmodels. Toeventuallyimprovethem,
human-in-the-loop methods like XIL can be used, helping to build better and more reliable forcasters.
6 Conclusion
We established the need for an in-depth comparison of company fundamentals forecasting models in both
qualitative and quantitative terms. This is relevant not only for finance but also as a case study for machine
learning and econometrics. We started with an in-depth analysis of the data and solutions to its specific
challenges. We explored the applicability of 22 classical statistical and modern machine learning models
and identified their properties and capabilities. Subsequently, we have shown that identifying the best
overall model requires a nuanced analysis. Particularly, we demonstrated that surpassing simple baselines
in deterministic forecasts is challenging. Yet, the much more helpful probabilistic forecasts can be obtained
by either AutoARIMA or, equivalently, by any of the deep learning models. These global models can learn
from the time series of many companies, effectively estimating a more adequate distribution. We have shown
that enriching the data with static context provides negligible benefits, suggesting that the key predictive
patterns are already latent in the covariate and target variables. Depending on the field of application and
the variables of interest, vastly different models should be selected. For example, a varying set of models
excelled before, during, and after the COVID-19 pandemic, respectively. We further find the quality of the
obtained forecasts to be similar to human analyst predictions. We continue by evaluating the best automated
forecasts on factor models to assess their practical use in investing. We find that they can outperform the
reference index over ten years and observe the benefit to be greatest in times of higher financial stability. We
finally motivated and showed possibilities for interpreting the models’ behavior and generating explanations
for their forecasts. This, in turn, permits domain experts to elevate and validate the quality of predictions
and eventually improve them.
The greatest challenge to CF forecasting seems to be the large variability of patterns across the years. This
is amplified by the relatively small amount of data available and the inherent out-of-sample task. Therefore,
ensemble methods and incorporating additional signals and domain knowledge appear to be very fruitful. For
instance, one could mine textual features from news, investor calls, or social media by extracting sentiment
scores or semantic information from that. Furthermore, causal models might help distinguish spurious
correlations, possibly from data collection artifacts, from actual causal relations, like the onset of disruptive
global events. This is closely tied to mining patterns in CF data for insights into the macroeconomic behavior
of entire sectors or countries in relation to each other. The task is, furthermore, inherently continual since a
new set of fundamentals is released each quarter. Explicit lifelong learning methods might aid in regulating
which of the learned patterns still apply in the new time period.
15Under review as submission to TMLR
References
JohnAlbergandZacharyC.Lipton. ImprovingFactor-BasedQuantitativeInvestingbyForecastingCompany
Fundamentals. In NIPS Time Series Workshop 2017 , April 2018. arXiv:1711.04837.
Angelo Aspris, Nigel Finch, Sean Foley, and Zachary Meyer. Fundamental Based Market Strategies. Aus-
tralian Accounting Review , 23:380–392, 2013. doi: auar.12038.
Vassilis Assimakopoulos and K. Nikolopoulos. The theta model: A decomposition approach to forecasting.
International Journal of Forecasting , 16:521–530, October 2000. doi: 10.1016/S0169-2070(00)00066-2.
Shaojie Bai, J. Zico Kolter, and Vladlen Koltun. An Empirical Evaluation of Generic Convolutional and
Recurrent Networks for Sequence Modeling, April 2018. arXiv:1803.01271.
EliBingham, JonathanP.Chen, MartinJankowiak, FritzObermeyer, NeerajPradhan, TheofanisKaraletsos,
Rohit Singh, Paul Szerlip, Paul Horsfall, and Noah D. Goodman. Pyro: Deep Universal Probabilistic
Programming. Journal of Machine Learning Research , 20(28):1–6, 2019. ISSN 1533-7928.
George E. P. Box and Gwilym M. Jenkins. Time series analysis: forecasting and control . Holden-Day series
in time series analysis and digital processing. Holden-Day, San Francisco, rev. ed. edition, 1976. ISBN
0-8162-1104-3.
Leo Breiman. Random Forests. Machine Learning , 45(1):5–32, October 2001. ISSN 1573-0565. doi: 10.
1023/A:1010933404324.
Cristian Challu, Kin G. Olivares, Boris N. Oreshkin, Federico Garza Ramirez, Max Mergenthaler Canseco,
and Artur Dubrawski. NHITS: Neural Hierarchical Interpolation for Time Series Forecasting. Proceedings
of the AAAI Conference on Artificial Intelligence , 37(6):6989–6997, June 2023. ISSN 2374-3468. doi:
10.1609/aaai.v37i6.25854.
Lakshay Chauhan, John Alberg, and Zachary Lipton. Uncertainty-Aware Lookahead Factor Models for
Quantitative Investing. In Proceedings of the 37th International Conference on Machine Learning , pp.
1489–1499. PMLR, November 2020.
Mingqin Chen, Zhenhua Zhang, Jiawen Shen, Zhijian Deng, Jiaxing He, and Shiting Huang. A Quantitative
Investment Model Based on Random Forest and Sentiment Analysis. Journal of Physics: Conference
Series, 1575(1):012083, June 2020. ISSN 1742-6588. doi: 10.1088/1742-6596/1575/1/012083.
Kyunghyun Cho, Bart van Merriënboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Holger
Schwenk, and Yoshua Bengio. Learning Phrase Representations using RNN Encoder–Decoder for Sta-
tistical Machine Translation. In Proceedings of the 2014 Conference on Empirical Methods in Natural
Language Processing (EMNLP) , pp. 1724–1734, Doha, Qatar, October 2014. Association for Computa-
tional Linguistics. doi: 10.3115/v1/D14-1179.
Fred Collopy, Monica Adya, and J. Scott Armstrong. Expert Systems for Forecasting. In Frederick S. Hillier
and J. Scott Armstrong (eds.), Principles of Forecasting , volume 30 of International Series in Operations
Research & Management Science , pp. 285–300. Springer US, Boston, MA, 2001. ISBN 978-0-7923-7401-5.
Abhimanyu Das, Weihao Kong, Andrew Leach, Shaan K. Mathur, Rajat Sen, and Rose Yu. Long-term
Forecasting with TiDE: Time-series Dense Encoder. Transactions on Machine Learning Research , May
2023. ISSN 2835-8856.
Phil Davis. Value Investing: Do Quant Strategies Measure Up? Financial Analysts Journal , 73(2):53–55,
2017. ISSN 0015-198X.
Steven Downey. Gazing into the Future: Using Ensemble Techniques to Forecast Company Fundamentals,
April 2020. URL https://dx.doi.org/10.2139/ssrn.3580018 .
Guanhao Feng, Stefano Giglio, and Dacheng Xiu. Taming the Factor Zoo: A Test of New Factors. The
Journal of Finance , 75(3):1327–1370, 2020. ISSN 1540-6261. doi: 10.1111/jofi.12883.
16Under review as submission to TMLR
Jose A. Fiorucci, Tiago R. Pellegrini, Francisco Louzada, Fotios Petropoulos, and Anne B. Koehler. Models
for optimising the theta method and their relationship to state space models. International Journal of
Forecasting , 32(4):1151–1161, October 2016. ISSN 0169-2070. doi: 10.1016/j.ijforecast.2016.02.005.
Yarin Gal and Zoubin Ghahramani. Dropout as a Bayesian Approximation: Representing Model Uncertainty
in Deep Learning. In Proceedings of The 33rd International Conference on Machine Learning , pp. 1050–
1059. PMLR, June 2016.
Tilmann Gneiting and Adrian E Raftery. Strictly Proper Scoring Rules, Prediction, and Estimation. Journal
of the American Statistical Association , 102(477):359–378, March 2007. ISSN 0162-1459. doi: 10.1198/
016214506000001437.
John B. Guerard, Harry Markowitz, and GanLin Xu. Earnings forecasting in a global stock selection model
and efficient portfolio construction and management. International Journal of Forecasting , 31(2):550–560,
April 2015. ISSN 0169-2070. doi: 10.1016/j.ijforecast.2014.10.003.
Tony Guida and Guillaume Coqueret. Machine Learning in Systematic Equity Allocation: A Model Com-
parison. Wilmott, 2018(98):24–33, 2018. ISSN 1541-8286. doi: 10.1002/wilm.10719.
Douglas Anderson Hayes. Investments: Analysis and Management . The Macmillan Company, New York, 1
edition, 1961.
Julien Herzen, Francesco Lässig, Samuele Giuliano Piazzetta, Thomas Neuer, Léo Tafti, Guillaume Raille,
Tomas Van Pottelbergh, Marek Pasieka, Andrzej Skrodzki, Nicolas Huguenin, Maxime Dumonal, Jan
Kościsz, Dennis Bader, Frédérick Gusset, Mounir Benheddi, Camila Williamson, Michal Kosinski, Matej
Petrik, and Gaël Grosch. Darts: User-Friendly Modern Machine Learning for Time Series. Journal of
Machine Learning Research , 23(124):1–6, 2022. ISSN 1533-7928.
Daniel Hoang and Kevin Wiegratz. Machine learning methods in finance: Recent applications and prospects.
European Financial Management , 29(5):1657–1701, 2023. ISSN 1468-036X. doi: 10.1111/eufm.12408.
Sepp Hochreiter and Jürgen Schmidhuber. Long Short-Term Memory. Neural Computation , 9(8):1735–1780,
November 1997. ISSN 0899-7667. doi: 10.1162/neco.1997.9.8.1735.
Htet Htet Htun, Michael Biehl, and Nicolai Petkov. Survey of feature selection and extraction tech-
niques for stock market prediction. Financial Innovation , 9(1):26, 2023. ISSN 2199-4730. doi:
10.1186/s40854-022-00441-7.
Rob J. Hyndman and Baki Billah. Unmasking the Theta method. International Journal of Forecasting , 19
(2):287–290, April 2003. ISSN 0169-2070. doi: 10.1016/S0169-2070(01)00143-1.
Rob J. Hyndman and Yeasmin Khandakar. Automatic Time Series Forecasting: The forecast Package for
R.Journal of Statistical Software , 27:1–22, July 2008. ISSN 1548-7660. doi: 10.18637/jss.v027.i03.
Bryan Kelly and Dacheng Xiu. Financial Machine Learning. Foundations and Trends in Finance , 13(3-4):
205–363, November 2023. doi: 10.1561/0500000064.
Taesung Kim, Jinhee Kim, Yunwon Tae, Cheonbok Park, Jang-Ho Choi, and Jaegul Choo. Reversible
Instance Normalization for Accurate Time-Series Forecasting against Distribution Shift. In International
Conference on Learning Representations , 2022.
U-Wen Kok, Jason Ribando, and Richard Sloan. Facts about Formulaic Value Investing. Financial Analysts
Journal, 73(2):81–99, April 2017. ISSN 0015-198X. doi: 10.2469/faj.v73.n2.2.
Maurice Kraus, David Steinmann, Antonia Wüst, Andre Kokozinski, and Kristian Kersting. Right on Time:
Revising Time Series Models by Constraining their Explanations, February 2024. arXiv:2402.12921.
Mahinda Mailagaha Kumbure, Christoph Lohrmann, Pasi Luukka, and Jari Porras. Machine learning tech-
niques and data for stock market forecasting: A literature review. Expert Systems with Applications , 197:
116659, July 2022. ISSN 0957-4174. doi: 10.1016/j.eswa.2022.116659.
17Under review as submission to TMLR
Denis Kwiatkowski, Peter C. B. Phillips, Peter Schmidt, and Yongcheol Shin. Testing the null hypothesis
of stationarity against the alternative of a unit root: How sure are we that economic time series have
a unit root? Journal of Econometrics , 54(1):159–178, October 1992. ISSN 0304-4076. doi: 10.1016/
0304-4076(92)90104-Y.
Spencer Yongwook Kwon, Yueran Ma, and Kaspar Zimmermann. 100 Years of Rising Corporate Concentra-
tion, February 2023. URL https://dx.doi.org/10.2139/ssrn.3936799 .
Baruch Lev and Anup Srivastava. Explaining the Recent Failure of Value Investing. Critical Finance Review ,
11(2):333–360, May 2022. doi: 104.00000115.
Bryan Lim, Sercan Ö Arık, Nicolas Loeff, and Tomas Pfister. Temporal Fusion Transformers for interpretable
multi-horizon time series forecasting. International Journal of Forecasting , 37(4):1748–1764, October 2021.
ISSN 0169-2070. doi: 10.1016/j.ijforecast.2021.03.012.
Steve C. Lim, Antonio J. Macias, and Thomas Moeller. Intangible assets and capital structure. Journal of
Banking & Finance , 118:105873, September 2020. ISSN 0378-4266. doi: 10.1016/j.jbankfin.2020.105873.
Ilya Loshchilov and Frank Hutter. Decoupled Weight Decay Regularization. In International Conference on
Learning Representations , September 2018. URL https://openreview.net/forum?id=Bkg6RiCqY7 .
Helmut Lütkepohl. Chapter 6 Forecasting with VARMA Models. In G. Elliott, C. W. J. Granger, and
A. Timmermann (eds.), Handbook of Economic Forecasting , volume 1, pp. 287–325. Elsevier, January
2006.
Shaohui Ma and Robert Fildes. Large-Scale Time Series Forecasting with Meta-Learning. In Mohsen
Hamoudia, Spyros Makridakis, and Evangelos Spiliotis (eds.), Forecasting with Artificial Intelligence: The-
ory and Applications , Palgrave Advances in the Economics of Innovation and Technology, pp. 221–250.
Springer Nature Switzerland, Cham, 2023. ISBN 978-3-031-35879-1.
James Mackinnon. Approximate Asymptotic Distribution Functions for Unit-Root and Cointegration Tests.
Journal of Business & Economic Statistics , 12:167–76, February 1994. doi: 10.1080/07350015.1994.
10510005.
Amal Mahmoud and Ammar Mohammed. A Survey on Deep Learning for Time-Series Forecasting. In
Aboul Ella Hassanien and Ashraf Darwish (eds.), Machine Learning and Big Data Analytics Paradigms:
Analysis, Applications and Challenges , Studies in Big Data, pp. 365–392. Springer International Publish-
ing, Cham, 2021. ISBN 978-3-030-59338-4.
Ričards Marcinkevičs and Julia E. Vogt. Interpretable and explainable machine learning: A methods-centric
overview with concrete examples. WIREs Data Mining and Knowledge Discovery , 13(3):e1493, 2023. ISSN
1942-4795. doi: 10.1002/widm.1493.
Michael J. Mauboussin. Revisiting Market Efficiency: The Stock Market as a Complex Adaptive System.
Journal of Applied Corporate Finance , 14(4):47–55, 2002. ISSN 1745-6622. doi: 10.1111/j.1745-6622.2002.
tb00448.x.
Amir Mosavi, Pedram Ghamisi, Yaser Faghan, Puhong Duan, Sina Faizollahzadeh Ardabili, Ely Salwana,
and Shahab Band. Comprehensive Review of Deep Reinforcement Learning Methods and Applications
in Economics. Mathematics, Recent Advances in Deep Learning , 8(10), September 2020. doi: 10.3390/
math8101640.
Shakeel Muhammad and Gohar Ali. The Relationship Between Fundamental Analysis and Stock Returns
Based on the Panel Data Analysis; Evidence from Karachi Stock exchange (KSE). Research Journal of
Finance and Accounting , 9(3):84, 2018. ISSN 2222-1697.
M. Nabipour, P. Nayyeri, H. Jabani, A. Mosavi, E. Salwana, and Shahab S. Deep Learning for Stock Market
Prediction. Entropy, 22(8):840, July 2020. ISSN 1099-4300. doi: 10.3390/e22080840.
18Under review as submission to TMLR
NoellaNazarethandYeruvaVenkataRamanaReddy. Financialapplicationsofmachinelearning: Aliterature
review.Expert Systems with Applications , 219:119640, June 2023. ISSN 0957-4174. doi: 10.1016/j.eswa.
2023.119640.
Nicki Skafte Detlefsen, Jiri Borovec, Justus Schock, Ananya Harsh, Teddy Koker, Luca Di Liello, Daniel
Stancl, Changsheng Quan, Maxim Grechkin, and William Falcon. TorchMetrics - Measuring Reproducibil-
ity in PyTorch. Journal of Open Source Software , 7(70):4101, February 2022. doi: 10.21105/joss.04101.
BorisN.Oreshkin, DmitriCarpov, NicolasChapados, andYoshuaBengio. N-BEATS:Neuralbasisexpansion
analysis for interpretable time series forecasting. In International Conference on Learning Representations
2020, September 2019.
F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer,
R.Weiss,V.Dubourg,J.Vanderplas,A.Passos,D.Cournapeau,M.Brucher,M.Perrot,andE.Duchesnay.
Scikit-learn: Machine learning in Python. Journal of Machine Learning Research , 12:2825–2830, 2011.
Keywan Christian Rasekhschaffe and Robert C. Jones. Machine Learning for Stock Selection. Financial
Analysts Journal , 75(3):70–88, July 2019. ISSN 0015-198X. doi: 10.1080/0015198X.2019.1596678.
Mikkel Rasmussen. Quantitative Portfolio Optimisation, Asset Allocation and Risk Management . Palgrave
Macmillan UK, London, 2003. ISBN 978-1-349-50944-7.
Rajiv Sant and Mir A. Zaman. Market reaction to Business Week ‘Inside Wall Street’ column: A self-
fulfilling prophecy. Journal of Banking & Finance , 20(4):617–643, May 1996. ISSN 0378-4266. doi:
10.1016/0378-4266(95)00025-9.
Thilo A. Schmitt, Desislava Chetalova, Rudi Schäfer, and Thomas Guhr. Non-stationarity in financial time
series: Generic features and tail behavior. Europhysics Letters , 103(5):58003, September 2013. ISSN
0295-5075. doi: 10.1209/0295-5075/103/58003.
Skipper Seabold and Josef Perktold. Statsmodels: Econometric and Statistical Modeling with Python. In
Python in Science Conference , pp. 92–96, Austin, Texas, 2010. doi: 10.25080/Majora-92bf1922-011.
Omer Berat Sezer, Mehmet Ugur Gudelek, and Ahmet Murat Ozbayoglu. Financial time series forecasting
with deep learning: A systematic literature review: 2005–2019. Applied Soft Computing , 90:106181, May
2020. ISSN 15684946. doi: 10.1016/j.asoc.2020.106181.
Yoojeong Song and Jongwoo Lee. Design of stock price prediction model with various configuration of input
features. In Proceedings of the International Conference on Artificial Intelligence, Information Processing
and Cloud Computing , pp. 1–5, Sanya China, December 2019. ACM. ISBN 978-1-4503-7633-4. doi:
10.1145/3371425.3371432.
EvangelosSpiliotis. TimeSeriesForecastingwithStatistical, MachineLearning, andDeepLearningMethods:
Past, Present, and Future. In Mohsen Hamoudia, Spyros Makridakis, and Evangelos Spiliotis (eds.),
Forecasting with Artificial Intelligence: Theory and Applications , Palgrave Advances in the Economics of
Innovation and Technology, pp. 49–75. Springer Nature Switzerland, Cham, 2023. ISBN 978-3-031-35879-
1.
Avanidhar Subrahmanyam. The Cross-Section of Expected Stock Returns: What Have We Learnt from
the Past Twenty-Five Years of Research? European Financial Management , 16(1):27–42, 2010. ISSN
1468-036X. doi: 10.1111/j.1468-036X.2009.00520.x.
Jessie Sun. A Stock Selection Method Based on Earning Yield Forecast Using Sequence Prediction Models,
May 2019. arXiv:1905.04842.
Van-Dai Ta, Chuan-Ming Liu, and Direselign Addis Tadesse. Portfolio Optimization-Based Stock Prediction
Using Long-Short Term Memory Network in Quantitative Trading. Applied Sciences , 10(2):437, January
2020. ISSN 2076-3417. doi: 10.3390/app10020437.
19Under review as submission to TMLR
Sean J. Taylor and Benjamin Letham. Forecasting at scale. The American Statistician, Special Issue on
Data Science , 72(1), April 2018. doi: 10.1080/00031305.2017.1380080.
Stefano Teso and Kristian Kersting. Explanatory Interactive Machine Learning. In Proceedings of the 2019
AAAI/ACM Conference on AI, Ethics, and Society , pp. 239–245, New York, NY, USA, January 2019.
Association for Computing Machinery. ISBN 978-1-4503-6324-2.
Zaghum Umar, Mariya Gubareva, Imran Yousaf, and Shoaib Ali. A tale of company fundamentals vs
sentiment driven pricing: The case of GameStop. Journal of Behavioral and Experimental Finance , 30:
100501, June 2021. ISSN 2214-6350. doi: 10.1016/j.jbef.2021.100501.
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser,
and Illia Polosukhin. Attention is All you Need. In Advances in Neural Information Processing Systems ,
volume 30, 2017.
Ahmed. S. Wafi, Hassan Hassan, and Adel Mabrouk. Fundamental Analysis Models in Financial Markets
– Review Study. Procedia Economics and Finance , 30:939–947, January 2015. ISSN 2212-5671. doi:
10.1016/S2212-5671(15)01344-1.
In-Kwon Yeo and Richard A. Johnson. A new family of power transformations to improve normality or
symmetry. Biometrika , 87(4):954–959, December 2000. ISSN 0006-3444. doi: 10.1093/biomet/87.4.954.
Ailing Zeng, Muxi Chen, Lei Zhang, and Qiang Xu. Are Transformers Effective for Time Series Forecasting?
Proceedings of the AAAI Conference on Artificial Intelligence , 37(9):11121–11128, June 2023. ISSN 2374-
3468. doi: 10.1609/aaai.v37i9.26317.
Cheng Zhang, Nilam Nur Amir Sjarif, and Roslina Ibrahim. Deep learning models for price forecasting of
financial time series: A review of recent advancements: 2020–2022. WIREs Data Mining and Knowledge
Discovery , 14(1):e1519, September 2023. ISSN 1942-4795. doi: 10.1002/widm.1519.
Yu Zhang and Qiang Yang. A Survey on Multi-Task Learning. IEEE Transactions on Knowledge and Data
Engineering , 34(12):5586–5609, December 2022. ISSN 1558-2191. doi: 10.1109/TKDE.2021.3070203.
20Under review as submission to TMLR
A Appendix
This supplement provides a discussion of wider ramifications of this work (Appendix A.1), detailed statistics
on the CF dataset, highlighting the challenges of the forecasting task (Appendix A.2), details for reproducing
the model training (Appendix A.3), insights on the effect of RevIn (Appendix A.4), and the complete results
for the comparison of human analyst expectations to the model’s forecasts (Appendix A.5).
A.1 Broader Impact Statement
This work employs publicly known models for widely discussed data where little rigorous evaluation has
been presented so far. We, therefore, anticipate minimal potential for harm. However, allocating large
quantities of assets solely based on CF forecasts could have adverse macroeconomic effects due to the one-
dimensional allocation rule, which overlooks crucial aspects of businesses, such as environmental and societal
impacts. Despitethis, suchascenarioishighlyunlikelyconsideringthecurrentdiverselandscapeofinvestors.
Similarly, future work could compare the quality of forecasts and resulting stock selections across different
regions of the world.
A.2 Charactersitics of the Dataset
EvenafterthenormalizationdescribedinSection4.1.2, thedataexhibitssignificantskewnessandheavytails,
effectively making it considerably non-Gaussian. That is shown in Figure 8 and Table 4. This reoccurring
problem in finance (Schmitt et al., 2013) invalidates some model assumptions, like of the ARIMA-family
models. This might explain some of the observed challenges with forecasting the CFs, especially using those
models.
3
 2
 1
 0 1 2 3
Normalized Value010002000300040005000CountCash from Operations
Net Income
Operating Income
T otal Equity
T otal Revenues
Figure 8: The histogram of the five target features. It is apparent that the data is not Gaussian.
Table 4:Statistics of the normalized target features. They are highly non-Gaussian.
Feature min median max mean std skew kurtosis
Cash from Operations -64.011 -0.111 105.825 0.000 1.000 5.921 1350.920
Net Income -49.323 0.007 37.237 0.000 1.000 -5.693 371.476
Operating Income -60.257 -0.051 30.921 0.000 1.000 -14.990 534.002
Total Equity -17.434 0.020 13.423 0.000 1.000 -2.202 25.443
Total Revenues -1.481 -0.201 17.418 0.000 1.000 2.254 12.264
A further challenge of the CF dataset is the lack of stationarity. To quantify this common challenge in
financial datasets, we applied the Augmented Dickey-Fuller (ADF) (Mackinnon, 1994) and Kwiatkowski-
Phillips-Schmidt-Shin (KPSS) (Kwiatkowski et al., 1992) tests each with a significance level of 0.05, as
implemented by statsmodels (Seabold & Perktold, 2010). Of all 50,540 time series (20 variates times 2527
companies), only 12.2% are stationary according to both.
21Under review as submission to TMLR
When tested with the auto-correlation function and a significance level of 0.05, about 42.2% of all time series
are seasonal. The frequency of the seasonal components varies significantly, as illustrated in Figure 9. This
further challenges machine learning forecasting methods.
5 10 15 20
Seasonality Period0500100015002000250030003500CountCash from Investing
Net Income
T otal Assets
T otal Current Liabilities
T otal Revenues
Cash from Financing
Cost of Revenues
Income T ax Expense
Operating Income
Other Operating Exp.T otal Cash and S. T. Inv.
T otal Current Assets
Net Interest Expense
Cash from Operations
Levered Free Cash Flow
T otal Debt
Sector Revenue Share
Capital Expenditure
T otal Equity
T otal Liabilities
Figure 9: Historgram over the strongest seasonalities in each feature. Notably, very different
seasonalities are present in the data, even for the same feature. Moreover, there is no strong seasonality
after four quarters (one year), yet for all other multiples of four.
A.3 Details on Model Configurations and Training
We based our analysis on the implementation in the dartssoftware library (Herzen et al., 2022). We used
scikit-learn (Pedregosa et al., 2011) for data normalization. For evaluation, we used torchmetrics (Nicki
Skafte Detlefsen et al., 2022) and the CRPS implementation of Pyro(Bingham et al., 2019). Some mod-
els obtain probabilistic forecasts via specialized architectures or sampling methods, while others simply
learn to predict the parameters of a distribution instead of the data directly. This is the case for Lin-
ear Regression as well as all deep learning models, where we, therefore, performed quantile regression on
0.01,0.05,0.1,0.15,0.2,0.25,0.3,0.4,0.5,0.6,0.7,0.75,0.8,0.85,0.9,0.95,0.99.
We introduced instance normalization to obtain a zero mean over the time steps per variate for the
Prophet model. This was empirically ineffective for all other local models. For ARMA(1,1),ARMA(4,4),
and VARIMA(4 ,0,4), we estimated an affine trend. Differencing already eliminated constant trends in
ARIMA(4,1,4), so a linear trend sufficed.
For the linear regression and random forest models, we estimated separate models for each of the target
variablesandfourfuturetimesteps. Forthelatter, eachforestcontained100treeslearnedfrombootstrapped
subsamples.
We trained all deep learning models with gradient descent on a batch size of 64 for 100 epochs. We adjusted
for different training duration requirements by early stopping after no change of the validation loss after
three epochs. We employed the AdamW optimizer (Loshchilov & Hutter, 2018) with learning rate 10−4,
weight decay weighting of 10−2,β1= 0.9, andβ2= 0.999. Furthermore, we clipped gradients to 1.0to
stabilize training. For all models except DLinear and NLinear, we used a 10% dropout rate. The following
lists the specific hyperparameters for each of the deep learning architectures. For DLinear, we used a kernel
size of 10 to estimate the moving average of the trend. All recurrent neural networks (GRU, LSTM, and
block variants) were three layers deep. The single models and block variants had a hidden size of 64 and
128, respectively. The TCN convolutions were set to a kernel width of 3 steps, 16 filters, and a dilation of 2
time steps. The Transformer was trained with a token size of 120, a feedforward dimension of 512, GELU
activations, four encoder layers, four decoder layers, and six attention heads. TFT used a hidden size of 36
and six attention heads covering the entire time span. We learned a single block of six layers with hidden
dimension 512 for N-BEATS. The N-HiTS models consisted of three stacks, each with a single two-layer
block and 512 hidden dimensions. Our configuration of TiDE had two encoder and decoder layers each, a
hidden size of 128, and a decoder with a hidden size of 32 and an output dimension of 16.
22Under review as submission to TMLR
A.4 The Benefit of Reversible Instance Norm
Table 5 shows that using RevIN is beneficial in many but not all models. In the case of DLinear and NLinear,
the detrending and normalization operations seem to be already sufficient and render RevIN unnecessary.
Table 5:A comparison showing the benefit of RevIN in percentage over the models without RevIN.
The scores are the nCRPS obtained from probabilistic forecasts, where lower is better.
Models Without RevIN With RevIN Improvement
DLinear 0.125 ±0.02 0.131 ±0.02 -4.80%
NLinear 0.127 ±0.02 0.135 ±0.02 -6.30%
TCN 0.163 ±0.03 0.153 ±0.02 6.13%
Transformer 0.136 ±0.02 0.132 ±0.02 2.94%
TFT 0.133 ±0.02 0.134 ±0.02 -0.75%
N-BEATS 0.134 ±0.02 0.134 ±0.02 0.00%
N-HiTS 0.129 ±0.02 0.130 ±0.02 -0.78%
TiDE 0.122 ±0.02 0.126 ±0.02 -3.28%
A.5 Algorithmic and Human Forecasts
To facilitate a relation of the human evaluation to the automated forecast, we provide comparable results in
Table 6, as discussed in Section 4.1.3. Here, we made sure to test the models only on the companies where
expert forecasts were available. Furthermore, only the fourth (one-year-ahead) time step is considered, which
aligns with the human expectations. For simplicity, we show the results for an entire company in the model
evaluation, even if individual human analyst predictions are missing since this happens only rarely. Since the
expectations contained some heavy outliers, we omitted metric results larger than four standard deviations
from the statistics. The comparison is performed on the transformed data as laid out in Section 4.1.2.
Consistent with the prior evaluation, the provided nCRPS score for the deterministic analyst expectations
is the special case of the MAE.
Table 6:Comparing automatic and human forecasts. This table is analogous to Table 2, but the
evaluation was restricted to the appropriate companies, feature ( Total Revenues ), horizon (4 quarters in the
future), and time steps.
Models MAE ( ↓) MSE ( ↓) RMSE ( ↓) MAPE ( ↓) RSE ( ↓) sMAPE ( ↓) R2(↑) nCRPS ( ↓)
Human Analyst 0.199 ±0.03 0.273 ±0.06 0.520 ±0.06 0.710±0.30 0.230±0.05 0.305±0.04 0.770±0.05 0.199 ±0.03
Mean 0.206 ±0.03 0.112 ±0.03 0.332 ±0.04 2.416 ±3.40 0.131 ±0.04 0.520 ±0.05 0.869 ±0.04 0.206 ±0.03
ARMean(1) 0.177 ±0.04 0.090±0.03 0.296 ±0.05 2.312 ±2.57 0.106 ±0.05 0.464 ±0.07 0.894 ±0.05 0.177 ±0.04
ARMean(4) 0.179 ±0.04 0.090 ±0.03 0.295 ±0.05 2.264 ±2.45 0.106 ±0.05 0.470 ±0.07 0.894 ±0.05 0.179 ±0.04
ARMA(1,1) 0.244 ±0.04 0.155 ±0.05 0.390 ±0.06 2.709 ±2.60 0.182 ±0.07 0.569 ±0.07 0.818 ±0.07 0.244 ±0.04
ARMA(4,4) 0.289 ±0.05 0.229 ±0.08 0.472 ±0.08 3.005 ±2.44 0.268 ±0.11 0.626 ±0.07 0.732 ±0.11 0.289 ±0.05
AutoARIMA 0.193 ±0.04 0.126 ±0.08 0.343 ±0.09 2.196 ±2.57 0.148 ±0.11 0.529 ±0.07 0.852 ±0.11 0.193 ±0.04
AutoTheta 0.215 ±0.04 0.128 ±0.04 0.354 ±0.06 2.645 ±2.73 0.152 ±0.07 0.521 ±0.08 0.848 ±0.07 0.215 ±0.04
Prophet 0.254 ±0.05 0.176 ±0.06 0.415 ±0.07 2.958 ±3.04 0.209 ±0.10 0.580 ±0.08 0.791 ±0.10 0.254 ±0.05
Linear Reg. 0.178 ±0.03 0.083±0.03 0.284 ±0.05 2.127±2.56 0.096±0.04 0.468±0.07 0.904±0.04 0.178±0.03
Random Forest 0.192 ±0.03 0.092 ±0.03 0.300 ±0.05 2.481 ±2.85 0.107 ±0.04 0.491 ±0.06 0.893 ±0.04 0.192 ±0.03
DLinear 0.177 ±0.03 0.088±0.03 0.292 ±0.05 2.164 ±2.83 0.103 ±0.04 0.466 ±0.06 0.897 ±0.04 0.177 ±0.03
NLinear 0.172±0.03 0.083 ±0.03 0.284 ±0.05 2.217±2.92 0.097 ±0.04 0.458±0.06 0.903±0.04 0.172±0.03
LSTM 0.184 ±0.03 0.090 ±0.03 0.296 ±0.04 2.392 ±3.07 0.104 ±0.04 0.477 ±0.07 0.896 ±0.04 0.184 ±0.03
GRU 0.182 ±0.03 0.088 ±0.03 0.293 ±0.05 2.008 ±1.85 0.102±0.04 0.473 ±0.06 0.898 ±0.04 0.182 ±0.03
Block LSTM 0.192 ±0.02 0.098 ±0.03 0.310 ±0.04 2.425 ±3.16 0.113 ±0.03 0.492 ±0.05 0.887 ±0.03 0.192 ±0.02
Block GRU 0.179 ±0.03 0.087 ±0.03 0.291 ±0.05 2.150 ±2.74 0.100 ±0.04 0.471 ±0.06 0.900 ±0.04 0.179 ±0.03
TCN 0.193 ±0.02 0.099 ±0.03 0.312 ±0.04 2.473 ±3.66 0.114 ±0.04 0.495 ±0.05 0.886 ±0.04 0.193 ±0.02
Transformer 0.177 ±0.03 0.085±0.03 0.288±0.05 2.366 ±3.05 0.099 ±0.04 0.468 ±0.06 0.901 ±0.04 0.177 ±0.03
TFT 0.192 ±0.02 0.099 ±0.03 0.311 ±0.04 2.398 ±3.45 0.114 ±0.03 0.493 ±0.05 0.886 ±0.03 0.192 ±0.02
N-BEATS 0.182 ±0.03 0.089 ±0.03 0.295 ±0.05 2.304 ±2.69 0.103 ±0.04 0.477 ±0.06 0.897 ±0.04 0.182 ±0.03
N-HiTS 0.177 ±0.03 0.085±0.03 0.287±0.05 2.162±2.44 0.098 ±0.04 0.468 ±0.06 0.902 ±0.04 0.177 ±0.03
TiDE 0.179 ±0.03 0.086 ±0.03 0.290 ±0.05 2.254 ±2.96 0.100 ±0.04 0.472 ±0.06 0.900 ±0.04 0.179 ±0.03
23