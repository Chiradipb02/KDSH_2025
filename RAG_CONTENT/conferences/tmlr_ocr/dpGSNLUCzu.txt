Published in Transactions on Machine Learning Research (07/2023)
The Score-Difference Flow for Implicit Generative Modeling
Romann M. Weber romann.weber@disneyresearch.com
Disney Research: Studios
Reviewed on OpenReview: https: // openreview. net/ forum? id= dpGSNLUCzu
Abstract
Implicit generative modeling (IGM) aims to produce samples of synthetic data matching the
characteristics of a target data distribution. Recent work (e.g. score-matching networks, dif-
fusion models) has approached the IGM problem from the perspective of pushing synthetic
source data toward the target distribution via dynamical perturbations or flows in the am-
bient space. In this direction, we present the score difference (SD) between arbitrary target
and source distributions as a flow that optimally reduces the Kullback-Leibler divergence
between them while also solving the Schrödinger bridge problem. We apply the SD flow to
convenient proxy distributions, which are aligned if and only if the original distributions are
aligned. We demonstrate the formal equivalence of this formulation to denoising diffusion
models under certain conditions. We also show that the training of generative adversarial
networks includes a hidden data-optimization sub-problem, which induces the SD flow un-
der certain choices of loss function when the discriminator is optimal. As a result, the SD
flow provides a theoretical link between model classes that individually address the three
challenges of the generative modeling trilemma —high sample quality, mode coverage, and
fast sampling—thereby setting the stage for a unified approach.
1 Introduction
The goal of implicit generative modeling (IGM) is to create synthetic data samples that are indistinguishable
from those drawn from a target distribution. A variety of approaches exist in the literature that address this
problem from the perspective of the dynamics imposed upon the synthetic data during sampling or training.
In particle-optimization sampling methods such as Langevin dynamics (Bussi & Parrinello, 2007; Welling
& Teh, 2011), Hamiltonian Monte Carlo (MacKay, 2003), and Stein variational gradient descent (Liu &
Wang, 2016), synthetic particles are drawn from a source distribution and perturbed over a number of steps
until they resemble particles drawn from the target distribution. Separately, parametric models have been
developed that either perform these perturbations implicitly under the hood, as in the case of normalizing
flows (Rezende & Mohamed, 2015; Papamakarios et al., 2021), or do so explicitly during inference, as in the
case of diffusion models (Ho et al., 2020; Nichol & Dhariwal, 2021).
This would seem to contrast with the training of parametric models for single-step generation by learning
a mapping between input drawn from a noise distribution and synthetic output resembling the target data.
Perhaps the most famous example of such a model is a generative adversarial network (GAN) (Goodfellow
et al., 2014), which leverages a separately trained discriminator to guide the generator toward more target-
like output. However, we will show that GAN training contains a hidden sub-problem that induces a flow
on the generated data that is completely determined by the loss being optimized. Consequently, this and
various other IGM methods can be understood in terms of the dynamics imposed upon the synthetic data.
The question then becomes one of asking what the optimaldynamics might be for the IGM task. In this
direction, we present the score difference (SD)—the difference in the gradients of the log-densities of the
target and source data distributions with respect to the data—as the flow direction that optimally reduces
the KL divergence between them at each step. We then argue that we can sidestep directly working with
the source and target distributions in favor of operating on convenient proxy distributions with common
support, which we show are aligned if and only if the original source and target distributions are aligned.
1Published in Transactions on Machine Learning Research (07/2023)
We derive the score difference from the analysis of the dynamical systems that govern probability flow.
But we also show that the score difference is hidden within or relates to various other IGM approaches,
most notably denoising diffusion models and GANs, under certain conditions. We also outline a flexible
algorithmic approach for leveraging SD flow when working with anysource and target distributions, with
no restrictions placed on either distribution.
Our aim is to provide an accessible treatment of a complex topic with important connections to various
areas of generative modeling and variational inference. The paper is organized around its key contributions
as follows:
1. In Section 2, we derive the score-difference (SD) flow from the study of probability flow dynamical
systems and show that SD flow optimally reduces the Kullback-Leibler (KL) divergence between the
source and target distributions and solves the Schrödinger bridge problem .
2. In Section 3, we consider modified proxy distributions for the source and target distributions, which
have common support and are generally easier to manage and estimate than the unmodified distri-
butions. We outline a method for aligning these proxies and show that this alignment occurs if and
only if the unmodified distributions are aligned.
3. In Section 4, we draw a connection between SD flow and denoising diffusion models and show that
they are equivalent under certain conditions. However, unlike diffusion models, SD flow places no
restrictions on the prior distribution.
4. In Section 5, we show that GAN generator training is composed of two sub-problems, a particle-
optimization step that induces a flow determined by the loss being optimized and a model-
optimization step, in which the flow-perturbed particles are fit by the generator via regression.
We then show that the SD flow is induced in GANs in the particle-optimization step under certain
conditions and choices of loss function.
5. In Section 6, we present flexible algorithms for applying SD flow to both direct sampling ( particle
optimization ) and parametric generator training ( model optimization ).
6. In Section 7, we report experiments on our kernel-based implementation of SD flow, including
comparisons to maximum mean discrepancy (MMD) gradient flow and Stein variational gradient
descent (SVGD) under a variety of conditions.
We conclude in Section 8. In the appendices we provide supplemental information, discuss theoretical links
to MMD gradient flow and SVGD, and report additional experimental results.
2 Probability Flow and the Score Difference
2.1 Derivation from Stochastic Differential Equations
Consider data x∈Rddrawn from a base distribution q=q0. We can describe a dynamical system that
perturbs the data and evolves its distribution q0→qtover time by the stochastic differential equation
dx=µ(x,t)dt+σ(t)dω, (1)
whereµ:Rd×R→Rdis adrift coefficient ,σ(t)is adiffusion coefficient , and dωdenotes the standard
Wiener process (Song et al., 2020).
Whenµ(x,t) =σ(t)2
2∇xlogp(x), the diffusion in equation 1 describes Langevin dynamics , which for a
suitable decreasing noise schedule σ(t)can be shown to produce samples from a target distribution pas
t→∞(Bussi & Parrinello, 2007; Welling & Teh, 2011). We indicate this convergence by writing qt⇝p.
2Published in Transactions on Machine Learning Research (07/2023)
As the data points xare perturbed over time t, the distribution q0evolves toqt. This evolution is described
by theFokker-Planck equation (Risken, 1996),
∂qt(x)
∂t=−d/summationdisplay
i=1∂
∂xi[µi(x,t)qt(x)] +d/summationdisplay
i=1d/summationdisplay
j=1∂2
∂xi∂xj[Dij(x,t)qt(x)]
=−∇x·[µi(x,t)qt(x)] +σ(t)2
2∇2
xqt(x)
=−σ(t)2
2∇x·[qt(x)∇xlogp(x)−∇xqt(x)]
=−σ(t)2
2∇x·[qt(x) (∇xlogp(x)−∇xlogqt(x))],(2)
whereD(x,t)is an isotropic diffusion tensor with elements Dij(x,t) =σ(t)2
2ifi=jandDij(x,t) = 0
otherwise,∇2=∇·∇represents the Laplacian operator ,1andσ(t)andµ(x,t)are defined as above. When
qt=p, equation 2 vanishes, and the evolution of qtstops. When the drift term µ(x,t)is defined as above,
namely as the gradient of a potential,2Jordan et al. (1998) show that the dynamics in equation 1 prescribe
a direction of steepest descent on a free-energy functional with respect to the Wasserstein metric.
A result due to Anderson (1982) shows that the forward dynamics in equation 1 can be reversed, effectively
undoing the evolution of qtop. These reverse dynamics are given by
dx=/bracketleftbig
µ(x,t)−σ(t)2∇xlogqt(x)/bracketrightbig
dt+σ(t)dˆω, (3)
where now dtis anegative time step, and ˆωis a time-reversed Wiener process. The reverse of a diffusion
process is therefore another diffusion process.
Remarkably, there is a deterministic process with the same marginal densities as those prescribed by equa-
tion 3. The corresponding dynamics are given by the probability flow ODE (Maoutsa et al., 2020; Song et al.,
2020),
dx=/bracketleftbigg
µ(x,t)−σ(t)2
2∇xlogqt(x)/bracketrightbigg
dt. (4)
If we substitute in the Langevin drift term µ(x,t) =σ(t)2
2∇xlogp(x)from above, equation 4 becomes
dx=σ(t)2
2[∇xlogp(x)−∇xlogqt(x)] dt. (5)
Since dtisassumedtobeanegativetimestepinthereverseprocess, equation5aswrittenprovidesthe
dynamics of the forwardprocess—pushing qttowardthe target distribution p—when dtis positive.
Equation 5 represents the score-difference (SD) flow of a probability distribution qtevolving toward
p(or away from p, depending on the sign). Note that this is no longer a diffusion but rather defines
a deterministic trajectory.
Combining equation 2 and equation 5 yields
∂qt(x)
∂t=−∇x·/bracketleftbigg
qt(x)dx
dt/bracketrightbigg
. (6)
This is the Liouville equation (Ehrendorfer, 1994; Maoutsa et al., 2020), which describes the evolution of
deterministic systems analogously to how the Fokker-Planck equation describes stochastic systems.
1Many authors denote the Laplacian by ∆, but we have reserved its use for discrete-time differences.
2Here the potential is given by U(x) =−logp(x).
3Published in Transactions on Machine Learning Research (07/2023)
2.2 SD Flow Optimally Reduces KL Divergence
A continuous flow dx=f(x)dtcan be approximated by defining a transformation T(x) =x+εf(x)for some
small stepε>0.3Ifx∼qandx′=T(x)∼q[T], then Liu & Wang (2016) show that the Kullback-Leibler
(KL) divergence between q[T]andp,
DKL(q[T]∥p) =Ex∼q[T]/bracketleftbig
logq[T](x)−logp(x)/bracketrightbig
, (7)
varies according to its functional derivative,
∇εDKL(q[T]∥p)|ε=0=−Ex∼q[T][Tr(Apf(x))], (8)
where
Apf(x) =∇xlogp(x)f(x)⊤+∇xf(x) (9)
is theStein operator (Gorham & Mackey, 2015).
By applying Stein’s identity (Stein, 1981; Lin et al., 2019) to equation 8, we obtain
Ex∼q[T][Tr(Apf(x))] =Ex∼q[T]/bracketleftbig
∇xlogp(x)⊤f(x)/bracketrightbig
−Ex∼q[T]/bracketleftbig
∇xlogq[T](x)⊤f(x)/bracketrightbig
=Ex∼q[T]/bracketleftig/parenleftbig
∇xlogp(x)−∇xlogq[T](x)/parenrightbig⊤f(x)/bracketrightig
,(10)
which is the inner product of the score difference and the flow vector f(x).4Maximizing the reduction in the
KL divergence (equation 8) corresponds to maximizing this inner product. Since the inner product of two
vectors is maximized when they are parallel, choosing f(x)to output a vector parallel to the score difference
will decrease the KL divergence as fast as possible. We can also see from equation 8 and equation 10 that
the decrease in the KL divergence is then proportional to the Fisher divergence ,
DF(q[T]∥p) =Ex∼q[T]/bracketleftbig
∥∇xlogp(x)−∇xlogq[T](x)∥2/bracketrightbig
, (11)
which, never being negative, shows that moving along the SD flow in sufficiently small steps will not increase
the KL divergence.
We note that the SD flow also naturally emerges from variational gradient flows defined over f-divergences
(Gao et al., 2019; Feng et al., 2021; Gao et al., 2022). Specifically, Gao et al. (2019) show that the negative
gradient of the first variation of thef-divergence functional evaluated at qdefines a flow that minimizes
the divergence. When that f-divergence is the KL divergence, DKL(q∥p), the first variation is given by
δF[q]/δq= logq(x)−logp(x) + 1, whose negative gradient is the SD flow. Dynamics closely resembling
the SD flow also emerge in the study of optimal interventions for constraining stochastic interacting particle
systems in Kullback-Leibler control problems (Maoutsa & Opper, 2022).
2.3 SD Flow Solves the Schrödinger Bridge Problem
The Schrödinger bridge (SB) problem considers the most likely evolution between two marginal densities q
andpover timet∈[0,T](Chen et al., 2015). Specifically, the problem solves
P∗= arg min
P∈Π(q,p)DKL(P∥Q), (12)
where Π(q,p)is the collection of densities with marginals P0=qandPT=p, andQis a reference diffusion
with initial density qthat causes the solution to be unique (Winkler et al., 2023).5
Chen et al. (2021) show that solutions to the SB problem correspond to the following forward and backward
SDEs:
dx= [µ(x,t) +σ2(t)∇log Ψ(x,t)]dt+σ(t)dω (13)
dx= [µ(x,t)−σ2(t)∇logˆΨ(x,t)]dt+σ(t)dˆω, (14)
3Ifεis sufficiently small, then the Jacobian of Tis of full rank, meaning that the transformation is bijective.
4We assume the mild condition that f(x)p(x)→0andf(x)q[T](x)→0as∥x∥→∞.
5Note that we are considering the diffusion from qtopfor consistency with the Langevin example in Section 2.1.
4Published in Transactions on Machine Learning Research (07/2023)
where Ψand ˆΨare non-negative potentials (or Schrödinger factors ) such that Ψ(x,t)ˆΨ(x,t) =qt(x), and
all other notation is as defined in Section 2.1. If we set Ψ(x,t) = 1and ˆΨ(x,t) =qt(x), then the necessary
conditions on the potentials are met, and the backward SDE (14) matches equation 3, from which the
probability flow ODE in equation 4 and the SD flow in equation 5 directly follow. Therefore, SD flow defines
a Schrödinger bridge between the source and target distributions qandp.
3 Applying SD Flow to Proxy Distributions
One of the difficulties in applying Langevin dynamics or other score-based methods is the requirement that
we have access to the true score of the target distribution, ∇xlogp(x), which is almost never available in
practice. It is also the case that when operating in the ambient space of x∈Rd, the score may not be
well defined in areas of limited support if the data exist on a lower-dimensional manifold, which is generally
assumed for a variety of data types of interest, such as image data. A large literature has emerged that is
dedicated to the estimation of this score or the design of training procedures that are equivalent to estimating
it (Hyvärinen & Dayan, 2005; Song & Ermon, 2020; Song & Kingma, 2021; Karras et al., 2022).
Applying SD flow would appear to be at least twice as difficult, since instead of one score to estimate, now
we have two. The distribution qtis also changing over time, so even a reasonably good estimate at one time
would have to be discarded and re-estimated at another. Our approach will be to essentially ignore pand
qtand work instead with modified proxy distributions that are easier to estimate and manage. Importantly,
aligning these proxy distributions will automatically align the unmodified source and target distributions.
3.1 Aligning Proxy Distributions
We can assess the alignment of two distributions qandpby computing a statistical distance between them.6
Although this quantity is not always a true “distance” in a strict mathematical sense, it will have the two
key properties that (1) D(q∥p)≥0for all distributions p,qand (2) D(q∥p) =D(p∥q) = 0if and only if p=q.
Perhaps the best-known statistical distance is the KL divergence, DKL(q∥p)(equation 7), although it can
diverge to infinity if pandqhave unequal support.
One way to equalize the support of two distributions is to corrupt their data with additive noise defined over
the whole space Rd. Let us assume a Gaussian noise model. The distribution of z=x+σϵ, withx∼pand
ϵ∼N(0,I), is given by the convolution ˜p=p∗N(0,σ2I):
˜p(z) =p(z;σ) =/integraldisplay
Rdp(x)N(z;x,σ2I) dx
=Ex∼p/bracketleftbig
N(z;x,σ2I)/bracketrightbig
,(15)
with ˜q(z) =q(z;σ) =Ey∼q/bracketleftbig
N(z;y,σ2I)/bracketrightbig
defined analogously. Although DKL(˜q∥˜p)≤DKL(q∥p)and
DKL(˜q∥˜p)→0asσ→ ∞(Sriperumbudur et al., 2017), it is easy to show that DKL(˜q∥˜p) = 0if and
only ifq=p(Zhang et al., 2020). As a result, aligning the proxy distributions ˜qand ˜pis equivalent to
aligning the generative distribution qwith the target distribution p.
We have shown that moving parallel to the score difference optimally reduces the KL divergence, so we define
an SD flow between ˜qand˜pto alignqwithp. The score corresponding to ˜p(z) =p(z;σ)(15) is
∇zlogp(z;σ) =∇zp(z;σ)
p(z;σ)
=Ex∼p/bracketleftbig
∇zN(z;x,σ2I)/bracketrightbig
Ex∼p[N(z;x,σ2I)]
=1
σ2/parenleftigg
Ex∼p/bracketleftbig
N(z;x,σ2I)x/bracketrightbig
Ex∼p[N(z;x,σ2I)]−z/parenrightigg
.(16)
6We will suppress the time index on qhere for convenience.
5Published in Transactions on Machine Learning Research (07/2023)
The score for ˜q(z) =q(z;σ)is derived in the same way for z=y+σϵ, withy∼q. This leads to the
following expression for the score difference:
∇zlogp(z;σ)−∇zlogq(z;σ) =1
σ2/parenleftbiggEx∼p[Kσ(z,x)x]
Ex∼p[Kσ(z,x)]−Ey∼q[Kσ(z,y)y]
Ey∼q[Kσ(z,y)]/parenrightbigg
, (17)
whereKσ(z,x) = exp/parenleftig
−∥z−x∥2
2σ2/parenrightig
is the Gaussian kernel.7
If we set the noise level according to the schedule σ(t) =σ, then the variance term cancels from equation 5,
leading to the update
∆z=η
2/bracketleftbiggEx∼p[Kσ(z,x)x]
Ex∼p[Kσ(z,x)]−Ey∼q[Kσ(z,y)y]
Ey∼q[Kσ(z,y)]/bracketrightbigg
(18)
for someη>0defining the step size.
We treat the dynamics of y∼q(y)as being the same as the dynamics of z∼˜q(z)and set ∆y= ∆zunder
the following rationale: At time t, we drawyt∼qt(y)andϵ∼N(0,I)to formyt+σϵ=zt∼˜q(z). We then
perturbztaccording to equation 18, forming zt+ ∆zt=zt+1∼˜qt+1(z), which is closer to the distribution
˜p(z)than the point ztwas. However, there is a second way to obtain the point zt+1∼˜qt+1(z), which is
to first create yt+ ∆yt=yt+1∼qt+1(y)via the (unknown) update ∆ytand then corrupt it with noise to
formyt+1+σϵ=zt+1∼˜qt+1(z).8If we think of our random noise ϵas coming from a queue,9then the
value ofϵis thesamein both scenarios. The only difference is that ϵis drawn from the queue at time tin
the first scenario and is saved until time t+ 1in the second. As a result, we can equate the two definitions
ofzt+1and write
zt+1/bracehtipdownleft/bracehtipupright/bracehtipupleft/bracehtipdownright
yt+ ∆yt/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
yt+1+σϵ=zt+1/bracehtipdownleft/bracehtipupright/bracehtipupleft/bracehtipdownright
yt+σϵ/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
zt+∆zt, (19)
which, when we cancel like terms, leads to ∆yt= ∆zt. In this case the update ∆ydoes not necessarily equal
the score difference of the “clean” distributions, ∇ylogp(y)−∇ylogq(y), but is rather the perturbation to
the clean data required for optimally aligning the proxies ˜qand˜p. Recalling that the alignment of the proxy
distributions implies the alignment of the original distributions, the update ∆ystill serves to align qwithp.
3.2 Limitations and Alternative Formulations of SD Flow
In the limit of infinite data, equation 17 is exact. But applying this formulation in a large-data setting can be
computationally expensive, and estimates using smaller batches may suffer from low accuracy, especially in
high dimensions. Recent work by Ba et al. (2021) shows that SVGD, which has a kernel-based specification
similar to our description of SD flow in Section 3.1, tends to underestimate the target variance unless the
number of particles is greater than the dimensionality. However, those authors note that MMD gradient
descent (Arbel et al., 2019), which is closer in formulation to SD flow (see Appendix B.3), does not have this
limitation. Additionally, recent work by Wang et al. (2022) proposed a Wasserstein gradient descent method
essentially identical to the SD flow formulation in Section 3.1, albeit operating in a projected space, which
the authors claim scales favorably to high dimensions.
In any case, it is useful to consider each term of equation 17 as a modulethat can be swapped out for another
estimate, depending on the problem setting. For example, we can rewrite equation 17 in the equivalent form
∇zlogp(z;σ)−∇zlogq(z;σ) =1
σ2[E[x|z]−E[y|z]] (20)
=1
σ2/bracketleftbig
D∗
p(z;σ)−D∗
qt(z;σ)/bracketrightbig
, (21)
whereD∗
p(z;σ)andD∗
qt(z;σ)are theoptimaldenoising models for the distributions pandqt, respectively,
when corrupted by Gaussian noise at level σ. A simple derivation of this result is possible by rearranging
7This is possible because the normalization constant of the normal distribution cancels from the numerator and denominator.
8Here we assume a constant noise schedule, σ(t) =σfor allt.
9This is the case with random number tables as well as our computers’ pseudorandom number generators.
6Published in Transactions on Machine Learning Research (07/2023)
Tweedie’s formula (Efron, 2011),10but we provide a separate proof of optimality in Appendix B.1. This
formulation is particularly well-suited to high-dimensional applications, as it admits the use of specialized
U-net architectures that form the backbone of modern denoising diffusion models (Karras et al., 2022).
As a practical consideration, the denoiser corresponding to the target data would need to be trained only
once, while the denoiser for the generative distribution would, at least in principle, need to be retrained
after each step along the flow. This is not in itself a major limitation, since the iterative fine-tuning of
the generative-distribution denoiser Dqtis no more onerous than the standard practice of training a GAN
generator and discriminator in alternating steps, although it does create a potential burden on resources
by requiring a second denoiser to be loaded in memory. However, since we actually observe y∼qtbefore
corrupting it to form z=y+σϵ, we can replace D∗
qt(z;σ) =E[y|z]withyin equation 21,11leading to the
update
y←(1−ρ)y+ρD∗
p(z;σ) (22)
for some small step size ρ. In Section 4, we show that this approximate formulation of SD flow is equivalent
to the reverse process in denoising diffusion models.
4 Relation to Denoising Diffusion Models
In diffusion modeling, data from the target distribution pis corrupted in a forward diffusion process by
Gaussian noise under the scale and noise schedules αt=α(t)andσt=σ(t), respectively. Then for z0=
x∼p, the conditional distribution at time trelative to that at time s<tis given by
p(zt|zs) =N(αt|szs,σ2
t|sI),
whereαt|s=αt/αsandσ2
t|s=σ2
t−α2
t|sσ2
s(Kingma et al., 2021).
The hard part is inferring the reversediffusion process, p(zs|zt), which is intractable unless also conditioned
onz0=x:p(zs|zt,x) =N(µs|t,σ2
s|t), whereµs|t= (αt|sσ2
s/σ2
t)zt+ (αsσ2
t|s/σ2
t)xandσ2
s|t=σ2
t|sσ2
s/σ2
t. In
practice,xis replaced by D(zt;σt), the output of a denoising model.12
If we letαs=αt= 1for alls,t, then
zs=σ2
s
σ2
tzt+/parenleftbigg
1−σ2
s
σ2
t/parenrightbigg
D(zt;σt) +σs|tϵs (23)
= (1−ρ)zt+ρD(zt;σt) +√ρσsϵs (24)
forϵs∼N(0,I)andρ= 1−σ2
s/σ2
t. Recalling that in our framework, zt=yt+σtϵt∼qt(zt;σt)for allt,
equation 24 becomes
zs= (1−ρ)yt+ρD(zt;σt) +√ρσsϵs+ (1−ρ)σtϵt
= (1−ρ)yt+ρD(zt;σt) +/radicalig
ρσ2s+ (1−ρ)2σ2
tϵ
= (1−ρ)yt+ρD(zt;σt)/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
ys+/radicaligg/parenleftbigg
1−σ2s
σ2
t/parenrightbigg
σ2s+/parenleftbiggσ2s
σ2
t/parenrightbigg2
σ2
t
/bracehtipupleft/bracehtipdownright/bracehtipdownleft /bracehtipupright
σsϵ
=ys+σsϵ,(25)
whereϵ,ϵs,ϵt∼N(0,I)andysfollows from equation 22. In other words, the updating process under SD
flow is equivalent to the denoising diffusion reverse process under the substitution described in Section 3.2.
10Tweedie’s formula states that E[x|z] =z+σ2∇zlogp(z;σ).
11This is an approximation, since D∗
qt(z;σ) =E[y|z]will not necessarily equal yand may be closer to a local mean for large σ.
12In alternative but equivalent implementations, the error between xandztis predicted by a parametric model ϵθ(zt;t).
7Published in Transactions on Machine Learning Research (07/2023)
5 Implicit Flows in Generative Adversarial Networks
5.1 Decomposing Generator Training into Sub-problems
When training a generative model gθ, we define a loss L, which is a scalar function that quantifies the
discrepancy between the current model output and the target distribution. We typically treat this loss as
a function of the parameters θ∈Rnand then optimize θto minimizeLvia gradient13descent at some
learning rate η>0:
θ′=θ−η/parenleftbigg∂L
∂θ/parenrightbigg⊤
. (26)
However, theloss Lisalso afunctionofthe generateddata y=gθ(ξ)∈Rd, which is itselfafunction ofeither
ξ∈Rlorθ∈Rn, depending on our perspective. This perspective can be made explicit by decomposing the
derivative of the loss via the multivariate chain rule,
∂L
∂θ/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
1×n=∂L
∂y/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
1×d∂y
∂θ/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
d×n. (27)
This allows us to consider each component of the decomposition as corresponding to its own sub-problem.
In thefirst sub-problem , we perturb the generated data yin the direction of the negative gradient,
y′=y−λ1/parenleftbigg∂L
∂y/parenrightbigg⊤
, (28)
whereλ1>0is some small step size. Intuitively, the perturbed data y′corresponds to a potential output of
the generator that would have a lower loss, but we can also interpret it as resulting from a gradient flow on
the synthetic data. In GANs, this flow serves to approximately “invert” the discriminator (Weber, 2021).
In thesecond sub-problem , we update the generator parameters θby regressing the new, perturbed target
y′on the original generator input ξvia the least-squares loss,
J=1
2∥gθ(ξ)−y′∥2=1
2∥y−y′∥2. (29)
Putting the pieces together leads to the parameter update
θ′=θ−λ2/parenleftbigg∂J
∂θ/parenrightbigg⊤
(30)
=θ−λ2/parenleftbigg∂gθ(ξ)
∂θ/parenrightbigg⊤
(gθ(ξ)−y′) (31)
=θ−λ2/parenleftbigg∂y
∂θ/parenrightbigg⊤
(y−y′) (32)
=θ−λ1λ2/parenleftbigg∂y
∂θ/parenrightbigg⊤/parenleftbigg∂L
∂y/parenrightbigg⊤
(33)
=θ−λ1λ2/parenleftbigg∂L
∂θ/parenrightbigg⊤
, (34)
which is is equal to the standard gradient update of θunder the original loss L(equation 26) with step size
η=λ1λ2. Here equation 33 follows from equation 32 by rearranging and substituting equation 28, while
equation 34 follows from equation 33 via equation 27.
13We treat the gradient as the transpose of the derivative.
8Published in Transactions on Machine Learning Research (07/2023)
Although this decomposition is a direct consequence of gradient descent, it shows that hidden within gen-
erator training are two sub-problems with separate control options (their learning rates, for instance), each
of which may be easier to conceptualize and handle than the original problem. In particular, we see that
the model-optimization step of generator training is preceded, at least implicitly, by a particle-optimization
step that prescribes a flow in the ambient data space Rd, regardless of the overall loss being optimized. This
suggests that we can treat this particle-optimization step as a target-generation module that can be swapped
out in favor of other procedures, such as SD flow. We note that this interpretation is consistent with recently
proposed flow-based methods for training parametric generators (Gao et al., 2019; 2022). Furthermore, it
suggests that a wide variety of generative models can be understood in terms of the dynamics imposed on
the generated data during training.
5.2 SD Flow in GANs
Many GAN generators employ the widely used non-saturating loss (Goodfellow, 2016) given by
L(θ) =−Eξ∼p0[logf(gθ(ξ))]≈−1
|B|/summationdisplay
y∈B∼qtlogf(y), (35)
whereξ∈Rlis a random noise input to the generator drawn from a prior distribution p0andf:Rd→(0,1)
is a separately trained discriminatorthat estimates the probability thatits argument is real datacoming from
a target distribution p(in which case f≈1), as opposed to fake data coming from the generator distribution
qt(in which case f≈0). We note that in every practical case we are working with an empirical estimate of
the expectation over a finite batch of generated data y=gθ(ξ)collected in the set B. Intuitively, the aim
of the loss given by equation 35 is to tune the parameters θtomaximize the discriminator’s assessment of
generated data as real.
It can be shown that, if the prior probabilities of coming from either porqtare equal, the Bayes optimal
classifierftis given by
ft(y) =p(y)
p(y) +qt(y), (36)
wherewehaveincludedthetimesubscripttoindicatetheoptimaldiscriminator’sdependenceonthechanging
distribution qt. An optimal discriminator is often assumed in the analysis of GANs but almost never holds
in actual practice.
When implemented as a neural network, the discriminator ftusually terminates with a sigmoid activation,
ft(y) =1
1 + exp[−ht(y)], (37)
whereht(y)is thepre-activation output of the discriminator ft. Equating equation 36 and equation 37, we
see that in the case of an optimal discriminator, ht(y) = logp(y)−logqt(y), whose gradient is the score
difference,
∇yht(y) =∇ylogp(y)−∇ylogqt(y). (38)
When trained using the non-saturating loss (equation 35), the gradient flow induced on a point yis
−∇yL=1
|B|∇yft(y)
ft(y)+1
|B|/summationdisplay
y′∈B\y∇yft(y′)
ft(y′)/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
0
=1
|B|(1−ft(y))∇yht(y)
∝(1−ft(y)) [∇ylogp(y)−∇ylogqt(y)].(39)
Since [1−ft(y)]>0for ally, taking the results of Section 5.1 into account, we see that standard GAN
training with an optimal discriminator consistently pushes the generated data toward the target data in a
direction parallel to the score difference (equation 38).
9Published in Transactions on Machine Learning Research (07/2023)
We can also consider an alternative to the non-saturating loss that focuses on the sum of the discriminator’s
pre-activation outputs for generated data,
Lalt=−/summationdisplay
y∈Bht(y), (40)
which induces a flow exactly equal to the score difference when the discriminator is optimal:
−∇yLalt=∇yht(y) +/summationdisplay
y′∈B\y∇yht(y′)/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
0
=∇ylogp(y)−∇ylogqt(y).(41)
6 Algorithms
In this section we provide pseudocode algorithms for two main applications of SD flow: (1) direct sampling
viaparticle optimization , which transports a set of particles from a source distribution to match a target
distribution, interpolating between the distributions in the process, and (2) the model optimization of a
parametric generator by (a) progressively perturbing generator output toward the target distribution and
then (b) regressing those perturbed targets on the generator input. In Section 5, we showed that the training
of a GAN generator can be decomposed into steps (a) and (b). This creates the opportunity to replace a
separately trained discriminator with another target-generation method, such as SD flow, in step (a).
The algorithms reflect that SD flow has more than one representation or specification. There is the kernel-
basedspecification (Section 3.1) derived from considering noise-injected proxy distributions; there is the
denoiser-based specification (Section 3.2), which exploits a link between SD flow and diffusion models; and
there is the density-ratio specification (Section 5) as estimated via a discriminator, such as one would use
in GAN training. Other specifications and estimation methods are possible, especially considering the
fundamental role played by the density ratio in machine learning applications (Sugiyama et al., 2012).
6.1 Particle Optimization
Algorithm 1 Particle optimization with SD flow
Input:Target data{xi}N
i=1∼p, base (prior) data {yj}M
j=1∼q0, noise schedule σ(t), step schedule η(t)
repeat
Draw data batches x∼pandy∼qt
Draw noiseϵ∼N(0,I)and perturb data: z=y+σ(t)ϵ
# Calculate SD (equation 18, 21, or 38).
∆z∝Ex∼p[Kσ(t)(z,x)x]
Ex∼p[Kσ(t)(z,x)]−Ey∼qt[Kσ(t)(z,y)y]
Ey∼qt[Kσ(t)(z,y)]=D∗
p(z;σ(t))−D∗
qt(z;σ(t))∝∇zht(z)
# Move (clean) data in SD direction.
y←y+η(t)∆z
untilTerminated
In theparticle-optimization application (Algorithm 1), a sample is generated by perturbing a single batch
of “base data,” much like one would via Langevin dynamics or Hamiltonian Monte Carlo. Here we interpret
the base data as being drawn from q0and evolving to the distribution qt⇝pthrough iterative perturbation.
6.2 Model Optimization
Ordinary regression problems involve paired training data {(ξ,y)}implicitly defining the mapping g:ξ∝⇕⊣√∫⊔≀→y
tobelearned. Inthecaseofgenerativemodeling, wheretheaimistomapdatafromapriornoisedistribution
to a target distribution, no a prioripairing exists. This requires the mapping to be learned indirectly. With
GANs, the sub-problem interpretation of Section 5.1 is that the discriminator provides this pairing by
associating a noise input ξwith a perturbed output y′that then serves as a regression target.
10Published in Transactions on Machine Learning Research (07/2023)
Algorithm 2 Model optimization with SD flow
Input:Target data{xi}N
i=1∼p, noise input for generator ξ∼p0, initialized generator gθ(θ∈Rn), noise
scheduleσ(t), step schedule η(t), learning rate schedule λ(t)
repeat
Draw data batches x∼pandξ∼p0
Generate sample y=gθ(ξ)
Draw noiseϵ∼N(0,I)and perturb data: z=y+σ(t)ϵ
# Calculate SD (equation 18, 21, or 38).
∆z∝Ex∼p[Kσ(t)(z,x)x]
Ex∼p[Kσ(t)(z,x)]−Ey∼qt[Kσ(t)(z,y)y]
Ey∼qt[Kσ(t)(z,y)]=D∗
p(z;σ(t))−D∗
qt(z;σ(t))∝∇zht(z)
# Move (clean) data in SD direction.
y←y+η(t)∆z
# Update generator parameters via regression.
θ←θ−λ(t)
2∇θ∥gθ(ξ)−y∥2
untilTerminated
Themodel-optimization application (Algorithm 2) trains a generator with unpaired data via regression on
perturbed targets that move progressively closer to the target distribution. Here we interpret q0as the
distribution of the output of the generator gθbefore training. As the generator regresses on perturbed
targets, its output distribution changes to qtat time step tas governed by the Liouville equation.14When
the choice of SD flow is the gradient of the pre-activation discriminator output, ∇zht(z)(equation 38), this
algorithm is equivalent to GAN training with the alternative loss described in equation 40.
7 Experiments
Herewereportseveralexperimentsontoydata. Wefocusinthissectiononparticle-optimizationapplications
using the kernel-based definition of SD flow (Section 3.1). This allows us to compare the performance of
SD flow against two other kernel-based particle-optimization algorithms, namely MMD gradient flow (Arbel
etal.,2019)andSteinvariationalgradientdescent(SVGD)(Liu&Wang,2016). Consistentwiththoseworks,
we focus on low-dimensional data, although we present additional results on moderately high-dimensional
data in a model-optimization application in Appendix C.4.
We leave a thorough exploration of our alternative specifications of SD flow (Section 3.2) on high-dimensional
imagedatatofollow-upwork, sincebeyondtheconsiderablecomputationalanddatademandsinthatsetting,
there are many architectural design choices and training tricks behind the current state of the art in image
generation, which fall outside the scope of this paper. Nevertheless, several suggestions for applying SD
flow to high-dimensional data, such as images, are given in Section 3.2. The general procedures given in
Algorithms 1 and 2 still apply in the high-dimensional case.
7.1 Experimental Conditions
For the experiments reported in this section, we vary the conditions below, which we describe along with
the labels used in Tables 1 and 2. All methods were tested with a default learning rate of η= 0.1.
ADAGRAD: The published implementation of SVGD (Liu & Wang, 2016) relies on the adaptive gradient opti-
mization algorithm AdaGrad (Duchi et al., 2011). We tested all algorithms using AdaGrad versus
standard stochastic gradient descent (SGD).
BATCH: The moderate size of our toy data sets allows us to test both batch-based and full-data versions of
the algorithms. Batch sizes of 128 were used in the batch condition.
CONST: In Section 4, we showed that an approximation of SD flow is equivalent to denoising diffusion under
a decreasing noise schedule. However, we also showed in Section 3.1 that we can work entirely
14See Section 2.1 and Appendix B.2.
11Published in Transactions on Machine Learning Research (07/2023)
with noise-corrupted proxy distributions, which allows for a constant noise schedule. Both MMD
gradient flow and SVGD can be interpreted in the constant-noise setting, so we tested all algorithms
with both constant and varying noise schedules. When using a constant noise schedule, we used the
method described by Liu & Wang (2016), which determines the kernel bandwidth as a function of the
median squared pairwise distance among the source (base) data and the number of points.15In the
non-constant setting, we used a modified cosine noise schedule to interpolate between a maximum
and minimum variance: σ2(t) =σ2
maxcos(πt/2)fort∈[0,tmax], withtmax= 2/πcos−1(σ2
min/σ2
max).
ANNEAL: Although the kernel-based realization of SD flow is motivated by considering noise-annealed proxy
distributions (Section 3.1), annealing is not necessary for SD flow to converge. Further, since SVGD
does not anneal data during training, and MMD gradient flow introduces annealing only as a regu-
larization technique, we tested all algorithms in both annealed and non-annealed conditions.
OFFSET: In our experiments in R3, we introduced the condition of initializing the base distribution either
away from the center of the target distribution (offset) or centered at the target distribution’s mean.
A discussion of the relationship between SD flow and MMD gradient flow is given in Appendix B.3 and
between SD flow and SVGD in Appendix B.4. That discussion provides additional context behind some of
the experimental conditions described above.
7.2 Results
To measure distribution alignment, we define a mean characteristic function distance (CFD),
DCF(p∥qt) =1
KK/summationdisplay
k=1|Ex∼p/bracketleftbig
exp(iω⊤
kx)/bracketrightbig
−Ey∼qt/bracketleftbig
exp(iω⊤
ky)/bracketrightbig
|,
where i =√−1is the imaginary unit. DCF(p∥qt)is the mean absolute difference between the empirical
characteristic functions of pandqtevaluated at Kfrequencies ( K= 256in our case) ωk∈Rddrawn
from a normal distribution. For the reporting in Tables 1 and 2, we establish convergence in the following
way: We compute the CFD for two independent random samples of the target distribution and record the
maximum value over 1000 trials, which provides a threshold for the CFD estimated from finite data when
the distributions are equal. We say that an algorithm has converged if the CFD between the synthetic and
target distributions falls below this threshold.
7.2.1 Fitting a 25-Gaussian Grid
For our first particle-optimization experiment, we created a target distribution of 1024 points drawn from
a mixture of 25 spherical Gaussians arranged on a grid in R2and initialized 1024 points from a spherical
Gaussian base distribution at a large distance from the target distribution but closest to its top-left compo-
nent. (See Figure 1.) For the non-constant condition, we used a cosine noise schedule (described above) with
σ2
max= 10andσ2
min= 0.5. The results of this experiment are summarized in Table 1. Note that SD flow is
the only algorithm to converge in every condition and that each algorithm consistently either converges or
fails to converge in each condition.
7.2.2 Fitting a Gaussian Mixture
In this experiment, our target “mystery distribution” pis a mixture of 30 Gaussians in R3arranged in the
shape of a question mark. (See Figure 2.) In addition to the experimental conditions tested in Section
7.2.1, we also tested initializing the base distribution offset from the target distribution versus centered at
the target distribution’s mean. For the non-constant condition, we used a cosine noise schedule (described
above) with σ2
max= 4andσ2
min= 0.5. The convergence results are given in Table 2. Once again, SD flow is
the only algorithm to converge in every condition.
15σ2= 2×median [D2(y,y′)]/log(N+ 1)
12Published in Transactions on Machine Learning Research (07/2023)
Table 1: Convergence probabilities (final three columns) for the SD flow (SD), MMD gradient flow (MMD)
and Stein variational gradient descent (SVGD) algorithms after 1000 iterations over five independent trials
on the 25-Gaussian particle-optimization problem in R2under the experimental conditions described in
Section 7.1. Convergence is defined as obtaining a minimum characteristic function distance less than a
threshold empirically determined by comparing independent copies of the target distribution (see text). SD
flow is the only algorithm to converge under all conditions.
ADAGRAD BATCH CONST ANNEAL SD (OURS) MMD SVGD
N N N N 1 0 0
N N N Y 1 0 0
N N Y N 1 0 0
N N Y Y 1 0 0
N Y N N 1 0 0
N Y N Y 1 0 0
N Y Y N 1 0 0
N Y Y Y 1 0 0
Y N N N 1 0 1
Y N N Y 1 0 1
Y N Y N 1 0 1
Y N Y Y 1 0 1
Y Y N N 1 0 1
Y Y N Y 1 0 1
Y Y Y N 1 0 1
Y Y Y Y 1 0 1
7.2.3 Discussion of Experimental Results
Our experiments show that there are conditions under which all tested algorithms successfully and consis-
tently transport particles from a source distribution to a target distribution. However, only SD flow showed
itself to be robust to all experimental conditions. SVGD converged in every condition in which AdaGrad
was employed in our experiments, where its performance was extremely close to that of SD flow. However,
SVGD consistently failed to converge in any condition in which AdaGrad was not employed, while SD flow
did converge in these conditions. MMD gradient flow fared worse in general and exhibited a tendency to
cause a subset of the synthetic data to diverge.16We note, however, that noise plays a different role in our
setup than it does in the work of Arbel et al. (2019), where it serves a regularizing purpose.
The convergence results reported in Tables 1 and 2 were determined by comparing the minimum CFD
achieved by an algorithm after 1000 iterations to a threshold empirically determined by multiple comparisons
of independent random draws of the target distribution. Failure to meet this threshold could mean that the
algorithmfailedtosteerthesyntheticdatatowardthetargetdistributionatallorsimplyfailedtodosointhe
allotted number of iterations. For completeness, we provide the average minimum CFD values corresponding
to Tables 1 and 2 in Appendix C.1. Additional experimental results are also reported in Appendix C.
8 Concluding Remarks
In this work, we presented the score-difference (SD) flow as an optimal trajectory for aligning a source
distribution with a target distribution. We also showed that this alignment can be performed by working
entirely with proxy distributions formed by smoothing the data with additive noise. As a result, while the SD
flow defines a deterministic trajectory, its application to noise-injected points adds a stochastic component.
16See Remark 1 in Appendix B.3.
13Published in Transactions on Machine Learning Research (07/2023)
SD Flow
MMD Flow
SVGD
Figure 1: Evolution of synthetic data points from an offset base distribution toward the target distribution
of 25 Gaussians over 1000 steps of SD flow (top row), MMD gradient flow (middle row) and SVGD (bottom
row) in the no-AdaGrad, full-data, batched, and annealed condition (corresponding to the second row of
Table 1). Only SD flow converged in this condition.
SD flow can be used as a direct sampling technique, in which case a sample of base data is converted to a
sample from the target distribution via the flow. It can also be used in the training of parametric generative
models, in which case generator output is perturbed by the flow to provide the generator with regression
targets guaranteed to be closer to the target distribution than the previous output. Unlike most other score-
based methods, there are no restrictions on the choice of base or prior distributions. Consistent with this
advantage, we have shown that SD flow forms a Schrödinger bridge (Schrödinger, 1932; De Bortoli et al.,
2021) between source and target distributions.
We have shown that SD flow emerges in both GANs and diffusion models under certain conditions. The
conditions for GANs include the presence of an optimal discriminator, which is often unattainable when
training with finite, categorically labeled data. By contrast, diffusion models have the comparatively easier
task of learning to denoise an image, a task for which the ground truth is more readily represented in the
training data. Modern neural denoising architectures that employ attention provide another edge, since
they have shown themselves to be extraordinarily capable of capturing patterns in data due to their error-
correction and pattern-retrieval characteristics reminiscent of Hopfield networks (Ramsauer et al., 2020).
SD flow supplies a link between IGM methods—namely GANs and diffusion models—that collectively per-
form well on all three desiderata of the so-called generative learning trilemma (Xiao et al., 2021): high
sample quality, mode coverage, and fast sampling. Inserting SD flow as an alternative, non-adversarial
target-generation module within generator training,17replacing the need for an optimal discriminator, could
lead to the development of “triple threat” models that produce high-quality, diverse output in a single in-
ference step. The various alternatives we have described in this paper for representing SD flow—namely
those based on kernels, denoisers, and density ratios—suggest a variety of opportunities for integrating this
approach into a number of IGM frameworks. We look forward to further developments in this direction.
17See Section 5.1 and Appendix C.4.
14Published in Transactions on Machine Learning Research (07/2023)
Table 2: Convergence probabilities (final three columns) for the SD flow (SD), MMD gradient flow (MMD)
andSteinvariationalgradientdescent(SVGD)algorithmsafter1000iterationsoverfiveindependenttrialson
the “mystery distribution” particle-optimization problem in R3under the experimental conditions described
in Section 7.1. Convergence is defined as obtaining a minimum characteristic function distance less than a
threshold empirically determined by comparing independent copies of the target distribution (see text). SD
flow is the only algorithm to converge under all conditions.
ADAGRAD BATCH CONST ANNEAL OFFSET SD (OURS) MMD SVGD
N N N N N 1 0 0
N N N N Y 1 0 0
N N N Y N 1 0 0
N N N Y Y 1 0 0
N N Y N N 1 0 0
N N Y N Y 1 0 0
N N Y Y N 1 0 0
N N Y Y Y 1 0 0
N Y N N N 1 0 0
N Y N N Y 1 0 0
N Y N Y N 1 0 0
N Y N Y Y 1 0 0
N Y Y N N 1 0 0
N Y Y N Y 1 0 0
N Y Y Y N 1 0 0
N Y Y Y Y 1 0 0
Y N N N N 1 1 1
Y N N N Y 1 0 1
Y N N Y N 1 1 1
Y N N Y Y 1 0 1
Y N Y N N 1 1 1
Y N Y N Y 1 0 1
Y N Y Y N 1 1 1
Y N Y Y Y 1 0 1
Y Y N N N 1 0 1
Y Y N N Y 1 0 1
Y Y N Y N 1 0 1
Y Y N Y Y 1 0 1
Y Y Y N N 1 0 1
Y Y Y N Y 1 0 1
Y Y Y Y N 1 0 1
Y Y Y Y Y 1 0 1
Broader Impact Statement
Implicit generative modeling in the image and text domains has matured to the point of producing output
with an unprecedented level of realism, with other modalities not far behind. It is getting increasingly
difficult to tell real data from fake, which is exciting when one reflects on how far the field has come in the
past few years but also disturbing when one considers the consequences of advanced IGM methods in the
hands of bad actors. We promote the responsible development and use of IGM not only with respect to its
deployment but also its training, which should only use data with the proper usage rights secured. We also
support continuing research into detecting generated or manipulated data in the effort of counteracting the
misuse of this technology and minimizing the societal effects of any misuse.
15Published in Transactions on Machine Learning Research (07/2023)
SD Flow
MMD Flow
SVGD
Figure 2: Evolution of synthetic data points from an offset base distribution toward the target distribution of
30Gaussiansover1000stepsofSDflow(toprow), MMDgradientflow(middlerow)andSVGD(bottomrow)
in the no-AdaGrad, full-data, cosine-noise annealed condition (corresponding to the fourth row of Table 2).
Only SD flow converged in this condition.
References
Brian DO Anderson. Reverse-time diffusion equation models. Stochastic Processes and their Applications ,
12(3):313–326, 1982.
Michael Arbel, Anna Korba, Adil Salim, and Arthur Gretton. Maximum mean discrepancy gradient flow.
Advances in Neural Information Processing Systems , 32, 2019.
Jimmy Ba, Murat A Erdogdu, Marzyeh Ghassemi, Shengyang Sun, Taiji Suzuki, Denny Wu, and Tianzong
Zhang. Understanding the variance collapse of svgd in high dimensions. In International Conference on
Learning Representations , 2021.
Kevin Beyer, Jonathan Goldstein, Raghu Ramakrishnan, and Uri Shaft. When is “nearest neighbor” mean-
ingful? In Database Theory—ICDT’99: 7th International Conference Jerusalem, Israel, January 10–12,
1999 Proceedings 7 , pp. 217–235. Springer, 1999.
Giovanni Bussi and Michele Parrinello. Accurate sampling using langevin dynamics. Physical Review E , 75
(5):056707, 2007.
Ricky TQ Chen, Yulia Rubanova, Jesse Bettencourt, and David K Duvenaud. Neural ordinary differential
equations. Advances in neural information processing systems , 31, 2018.
Tianrong Chen, Guan-Horng Liu, and Evangelos Theodorou. Likelihood training of schrödinger bridge using
forward-backward sdes theory. In International Conference on Learning Representations , 2021.
Yongxin Chen, Tryphon T Georgiou, and Michele Pavon. Optimal steering of a linear stochastic system to
a final probability distribution, part i. IEEE Transactions on Automatic Control , 61(5):1158–1169, 2015.
16Published in Transactions on Machine Learning Research (07/2023)
Valentin De Bortoli, James Thornton, Jeremy Heng, and Arnaud Doucet. Diffusion schrödinger bridge with
applications to score-based generative modeling. Advances in Neural Information Processing Systems , 34:
17695–17709, 2021.
JohnDuchi, EladHazan, andYoramSinger. Adaptivesubgradientmethodsforonlinelearningandstochastic
optimization. Journal of machine learning research , 12(7), 2011.
Bradley Efron. Tweedie’s formula and selection bias. Journal of the American Statistical Association , 106
(496):1602–1614, 2011.
Martin Ehrendorfer. The liouville equation and its potential usefulness for the prediction of forecast skill.
part i: Theory. Monthly Weather Review , 122(4):703–713, 1994.
Xingdong Feng, Yuan Gao, Jian Huang, Yuling Jiao, and Xu Liu. Relative entropy gradient sampler for
unnormalized distributions. arXiv preprint arXiv:2110.02787 , 2021.
Yuan Gao, Yuling Jiao, Yang Wang, Yao Wang, Can Yang, and Shunkang Zhang. Deep generative learning
via variational gradient flow. In International Conference on Machine Learning , pp. 2093–2101. PMLR,
2019.
Yuan Gao, Jian Huang, Yuling Jiao, Jin Liu, Xiliang Lu, and Zhijian Yang. Deep generative learning via
euler particle transport. In Mathematical and Scientific Machine Learning , pp. 336–368. PMLR, 2022.
Ian Goodfellow. Nips 2016 tutorial: Generative adversarial networks. arXiv preprint arXiv:1701.00160 ,
2016.
Ian J Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron
Courville, and Yoshua Bengio. Generative adversarial networks. arXiv preprint arXiv:1406.2661 , 2014.
Jackson Gorham and Lester Mackey. Measuring sample quality with stein’s method. Advances in Neural
Information Processing Systems , 28, 2015.
Will Grathwohl, Ricky TQ Chen, Jesse Bettencourt, Ilya Sutskever, and David Duvenaud. Ffjord: Free-form
continuous dynamics for scalable reversible generative models. arXiv preprint arXiv:1810.01367 , 2018.
Arthur Gretton, Karsten M Borgwardt, Malte J Rasch, Bernhard Schölkopf, and Alexander Smola. A kernel
two-sample test. The Journal of Machine Learning Research , 13(1):723–773, 2012.
Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. Advances in Neural
Information Processing Systems , 33:6840–6851, 2020.
Aapo Hyvärinen and Peter Dayan. Estimation of non-normalized statistical models by score matching.
Journal of Machine Learning Research , 6(4), 2005.
Richard Jordan, David Kinderlehrer, and Felix Otto. The variational formulation of the fokker–planck
equation. SIAM journal on mathematical analysis , 29(1):1–17, 1998.
Tero Karras, Miika Aittala, Timo Aila, and Samuli Laine. Elucidating the design space of diffusion-based
generative models. arXiv preprint arXiv:2206.00364 , 2022.
Diederik Kingma, Tim Salimans, Ben Poole, and Jonathan Ho. Variational diffusion models. Advances in
neural information processing systems , 34:21696–21707, 2021.
Wu Lin, Mohammad Emtiyaz Khan, and Mark Schmidt. Stein’s lemma for the reparameterization trick with
exponential family mixtures. arXiv preprint arXiv:1910.13398 , 2019.
Qiang Liu and Dilin Wang. Stein variational gradient descent: A general purpose bayesian inference algo-
rithm.Advances in neural information processing systems , 29, 2016.
Qiang Liu, Jason Lee, and Michael Jordan. A kernelized stein discrepancy for goodness-of-fit tests. In
International conference on machine learning , pp. 276–284. PMLR, 2016.
17Published in Transactions on Machine Learning Research (07/2023)
David JC MacKay. Information theory, inference and learning algorithms . Cambridge university press, 2003.
Dimitra Maoutsa and Manfred Opper. Deterministic particle flows for constraining stochastic nonlinear
systems. Physical Review Research , 4(4):043035, 2022.
Dimitra Maoutsa, Sebastian Reich, and Manfred Opper. Interacting particle solutions of fokker–planck
equations through gradient–log–density estimation. Entropy, 22(8):802, 2020.
Henry P McKean Jr. A class of markov processes associated with nonlinear parabolic equations. Proceedings
of the National Academy of Sciences , 56(6):1907–1911, 1966.
Alexander Quinn Nichol and Prafulla Dhariwal. Improved denoising diffusion probabilistic models. In
International Conference on Machine Learning , pp. 8162–8171. PMLR, 2021.
George Papamakarios, Eric Nalisnick, Danilo Jimenez Rezende, Shakir Mohamed, and Balaji Lakshmi-
narayanan. Normalizing flows for probabilistic modeling and inference. The Journal of Machine Learning
Research , 22(1):2617–2680, 2021.
Hubert Ramsauer, Bernhard Schäfl, Johannes Lehner, Philipp Seidl, Michael Widrich, Thomas Adler, Lukas
Gruber, Markus Holzleitner, Milena Pavlović, Geir Kjetil Sandve, et al. Hopfield networks is all you need.
arXiv preprint arXiv:2008.02217 , 2020.
Danilo Rezende and Shakir Mohamed. Variational inference with normalizing flows. In International con-
ference on machine learning , pp. 1530–1538. PMLR, 2015.
Hannes Risken. Fokker-planck equation . Springer, 1996.
Erwin Schrödinger. Sur la théorie relativiste de l’électron et l’interprétation de la mécanique quantique. In
Annales de l’institut Henri Poincaré , volume 2(4), pp. 269–310, 1932.
Yang Song and Stefano Ermon. Improved techniques for training score-based generative models. Advances
in neural information processing systems , 33:12438–12448, 2020.
Yang Song and Diederik P Kingma. How to train your energy-based models. arXiv preprint
arXiv:2101.03288 , 2021.
Yang Song, Jascha Sohl-Dickstein, Diederik P Kingma, Abhishek Kumar, Stefano Ermon, and Ben
Poole. Score-based generative modeling through stochastic differential equations. arXiv preprint
arXiv:2011.13456 , 2020.
Bharath Sriperumbudur, Kenji Fukumizu, Arthur Gretton, Aapo Hyvärinen, and Revant Kumar. Density
estimation in infinite dimensional exponential families. Journal of Machine Learning Research , 18, 2017.
Bharath K Sriperumbudur, Kenji Fukumizu, and Gert RG Lanckriet. Universality, characteristic kernels
and rkhs embedding of measures. Journal of Machine Learning Research , 12(7), 2011.
Charles M Stein. Estimation of the mean of a multivariate normal distribution. The annals of Statistics , pp.
1135–1151, 1981.
Masashi Sugiyama, Taiji Suzuki, and Takafumi Kanamori. Density ratio estimation in machine learning .
Cambridge University Press, 2012.
YifeiWang,PengChen,andWuchenLi. Projectedwassersteingradientdescentforhigh-dimensionalbayesian
inference. SIAM/ASA Journal on Uncertainty Quantification , 10(4):1513–1532, 2022.
RomannMWeber. Exploitingthehiddentasksofgans: Makingimplicitsubproblemsexplicit. arXiv preprint
arXiv:2101.11863 , 2021.
Max Welling and Yee W Teh. Bayesian learning via stochastic gradient langevin dynamics. In Proceedings
of the 28th international conference on machine learning (ICML-11) , pp. 681–688, 2011.
18Published in Transactions on Machine Learning Research (07/2023)
Ludwig Winkler, Cesar Ojeda, and Manfred Opper. A score-based approach for training schrödinger bridges
for data modelling. Entropy, 25(2):316, 2023.
Zhisheng Xiao, Karsten Kreis, and Arash Vahdat. Tackling the generative learning trilemma with denoising
diffusion gans. arXiv preprint arXiv:2112.07804 , 2021.
Mingtian Zhang, Peter Hayes, Thomas Bird, Raza Habib, and David Barber. Spread divergence. In Inter-
national Conference on Machine Learning , pp. 11106–11116. PMLR, 2020.
A Guide to the Appendices
In Appendix B.1, we show that the score difference corresponds to the difference between the outputs of
optimaldenoisers corresponding to the target ( p) and current synthetic ( qt) distributions. In Appendix B.2,
we describe the evolution of the generative distribution of a GAN under anyloss. In Appendix B.3, we draw
a connection between the kernel definition of SD flow and maximum mean discrepancy (MMD) gradient flow
(Arbel et al., 2019). In Appendix B.4, we draw a connection between SD flow and Stein variational gradient
descent (SVGD). Additional experimental results are reported in Appendix C.
B Supplemental Results
B.1 The Score Difference as the Difference of Optimal Denoisers
We follow an approach similar to that found in Appendix B.3 of Karras et al. (2022) to derive the optimal
denoiser for p. We define the denoising loss by
E(Dp;σ) =Ex∼pEϵ∼N(0,σ2I)/bracketleftbig
∥Dp(x+ϵ;σ)−x∥2/bracketrightbig
=Ex∼pEz∼N(x,σ2I)/bracketleftbig
∥Dp(z;σ)−x∥2/bracketrightbig
=Ez∼N(x,σ2I)Ex∼p/bracketleftbig
∥Dp(z;σ)−x∥2/bracketrightbig
=/integraldisplay
RdEx∼p/bracketleftbig
N(z;x,σ2I)∥Dp(z;σ)−x∥2/bracketrightbig
/bracehtipupleft /bracehtipdownright/bracehtipdownleft /bracehtipupright
E(Dp;z,σ)dz.(42)
We can optimize E(Dp;σ)by minimizing the integrand E(Dp;z,σ)pointwise. The optimal denoiser is then
given by
D∗
p(z;σ) = arg min
Dp(z;σ)E(Dp;z,σ), (43)
which defines a convex optimization problem. We can then find the global minimum by setting
∇Dp(z;σ)E(Dp;z,σ)to zero, leading to
Ex∼p/bracketleftbig
N(z;x,σ2I)∇Dp(z;σ)∥Dp(z;σ)−x∥2/bracketrightbig
=0
2Dp(z;σ)Ex∼p/bracketleftbig
N(z;x,σ2I)/bracketrightbig
= 2Ex∼p/bracketleftbig
N(z;x,σ2I)x/bracketrightbig
D∗
p(z;σ) =Ex∼p/bracketleftbig
N(z;x,σ2I)x/bracketrightbig
Ex∼p[N(z;x,σ2I)],(44)
the final term of which is equal to the first term inside the brackets in equation 18 when Kσis the Gaussian
kernel. The derivation for D∗
qt(z;σ)is identical, which leads to the result.
B.2 GAN Dynamics Under General Losses
Since the negative gradient of the GAN loss defines a flow on the generated data y, which the generator fits
via regression, we can track the evolution of the synthetic distribution qtwithin the context of normalizing
flows(Rezende & Mohamed, 2015; Papamakarios et al., 2021). In particular, the dynamics induced by a
19Published in Transactions on Machine Learning Research (07/2023)
generator loss constitute, in the limit of arbitrarily small steps, a continuous normalizing flow whose effect on
the synthetic (generated) data distributionis governed by the Liouville equation (see equation 6, Section 2.1),
∂qt(yt)
∂t=∇yt·[qt(yt)∇yL], (45)
a continuity equation with solution
qt(yt) =q0(y0) exp/parenleftbigg/integraldisplayt
0Tr[HL(yτ)] dτ/parenrightbigg
=q0(y0) exp/parenleftbigg/integraldisplayt
0∇2
yτLdτ/parenrightbigg
, (46)
whereHL(yτ)is the Hessian matrix of the loss Levaluated at yτ, whose trace is the Laplacian ∇2
yL=/summationtext
i∂2/∂y2
iL. Taking the logarithm of both sides of equation 46 yields the solution to the instantaneous
change of variables differential equation (Chen et al., 2018; Grathwohl et al., 2018). Note that this evolution
holds for any generator loss Land does not make any assumptions about an optimal discriminator.
B.3 Relation to MMD Gradient Flow
In the study of reproducing kernel Hilbert spaces (RKHS), the Gaussian kernel Kσ(z,x)is known as a
characteristic kernel (Sriperumbudur et al., 2011). This means that the mapping φp(z) =Ex∼p[Kσ(z,x)]
isinjective, andφp(z) =φq(z)for allzif and only if p=q. This forms the basis of the maximum mean
discrepancy (MMD), which is equal to the Hilbert space norm ∥Wp,q∥H, where
Wp,q(z) =φq(z)−φp(z) =Ey∼q[Kσ(z,y)]−Ex∼p[Kσ(z,x)] (47)
is known as the witness function (Gretton et al., 2012; Arbel et al., 2019).
In the theory of optimal transport, we wish to efficiently transport “mass” from an initial distribution q0to
a target distribution p, which we can do by defining a flow from q0topvia intermediate distributions qt.
One such flow is defined by the solution to
∂qt
∂t=∇·[qt∇Wp,qt], (48)
another instance of the Liouville equation (6, 45) that defines a McKean-Vlasov process (McKean Jr, 1966)
with dynamics
dzt=−∇ztWp,qt(zt) dt
= (Ex∼p[∇ztKσ(zt,x)]−Ey∼q[∇ztKσ(zt,y)]) dt,(49)
wherez0∼q0. The results of Section 3.1 suggest that, in the limit of infinite data, this direction is
proportional to∇ztp(zt;σ)−∇ztqt(zt;σ).
For the Gaussian kernel, we have
∇ztKσ(zt,x) =Kσ(zt,x)/parenleftbiggx−zt
σ2/parenrightbigg
,
and for discrete time and finite data we can write equation 49 as
∆zt=1
NN/summationdisplay
i=1/bracketleftbigg
Kσ(zt,xi)/parenleftbiggxi−zt
σ2/parenrightbigg/bracketrightbigg
−1
MM/summationdisplay
j=1/bracketleftbigg
Kσ(zt,yj)/parenleftbiggyj−zt
σ2/parenrightbigg/bracketrightbigg
(50)
=N/summationdisplay
i=1w(p)
ixi−M/summationdisplay
j=1w(qt)
jyj+
M/summationdisplay
j=1w(qt)
j−N/summationdisplay
i=1w(p)
i
zt, (51)
wherew(p)
i=Kσ(zt,xi)/(Nσ2)andw(qt)
j=Kσ(zt,yj)/(Mσ2). This process defines the MMD gradient
flow(Arbel et al., 2019). The kernel version of SD flow (equation 18) can also be written in the form
20Published in Transactions on Machine Learning Research (07/2023)
of equation 51 by setting w(p)
i=1
2Kσ(zt,xi)//summationtextN
i=1Kσ(zt,xi)andw(qt)
j=1
2Kσ(zt,xi)//summationtextM
j=1Kσ(zt,yj),
which causes the ztterm to vanish.
There are practical consequences of this difference in weighting schemes between methods, which put the
MMD gradient flow at a disadvantage in some conditions, as discussed in the following remark.
Remark 1 Ifpandqtare far apart, for a point zt=y+σϵ, withy∼qtand a small kernel bandwidth
σ, equation 51 shows that under the MMD framework/summationtext
jw(qt)
j≈1/(Mσ2)and/summationtext
iw(p)
i≈0. This
suggests that under these conditions, the MMD gradient flow direction ∆zMMD
twill be nearly parallel to
zt−y=σϵ, which would have the effect of increasing the variance of qtwhile not necessarily pushing it
towardp. Evidence of this variance-exploding effect emerged in our experiments and also apparent in the
authors’ original paper (e.g. Appendix G.2 therein). Normalizing the weights in equation 51 to sum to one
resolves this issue, however, and MMD gradient flow and SD flow then become equivalent.
Remark 2 Our method prescribes that we inject noise at a level equal to the kernel bandwidth in order to
sample from the noise-smoothed proxy distribution. In contrast, with MMD gradient flow the noise level is a
separate parameter that essentially controls a regularization effect. In that case, this added noise is typically
at a level far greater than that of the kernel bandwidth, which remains fixed during training.
B.4 Relation to Stein Variational Gradient Descent (SVGD)
Another statistical distance that measures the discrepancy between distributions pandqis theStein dis-
crepancy (Gorham & Mackey, 2015),
DS(p∥q) =Ex∼q[Tr(Apf(x))], (52)
whereApis the Stein operator defined in equation 9, and fis a function that vanishes on the boundary of
the support of p,qor (equivalently) behaves such that f(x)p(x)→0andf(x)q(x)→0as∥x∥→∞.
The discrepancy 52 vanishes if and only if p=q, which can be seen by expanding out equation 52 as in
equation 10,
Ex∼q[Tr(Apf(x))] =Ex∼q/bracketleftig
(∇xlogp(x)−∇xlogq(x))⊤f(x)/bracketrightig
, (53)
since for nontrivial functions f, the above vanishes only when ∇xlogp(x) =∇xlogq(x). When fis re-
stricted to bounded functions within a reproducing kernel Hilbert space (RKHS), one obtains the kernel
Stein discrepancy (Liu et al., 2016).
As reported in Section 2.2, Liu & Wang (2016) establish a link between the kernel Stein discrepancy and the
variation in the KL divergence, which leads to their derivation of Stein variational gradient descent (SVGD)
as an optimal direction for reducing the KL divergence between qandpwhen operating in a RKHS:
ϕ(z) =Ex∼q[∇xlogp(x)K(z,x) +∇xK(z,x)]
=Ex∼q[(∇xlogp(x)−∇xlogq(x))K(z,x)],(54)
which shows SVGD to be the kernel-weighted average of the score difference. Ba et al. (2021) provide a
separate analysis of the connection between SVGD and MMD gradient flow.
C Additional Experimental Results
C.1 Average CFD Values for Particle-Optimization Experiments
InSections7.2.1and7.2.2, wereportedconvergenceprobabilitiesforSDflow, MMDgradientflow, andSVGD
under various experimental conditions. Convergence was defined as achieving a minimum characteristic
function distance (CFD) below a threshold empirically determined by multiple comparisons of independent
copiesofthetargetdistribution( 0.0651forthe25-Gaussiangridproblemin R2and0.0612forthe30-Gaussian
“mystery distribution” in R3). In Tables 3 and 4, we report average CFD minimum values achieved by the
algorithms after 1000 steps over five separate trials.
21Published in Transactions on Machine Learning Research (07/2023)
Table 3: Average minimum CFD (final three columns) for the SD flow (SD), MMD gradient flow (MMD) and
Stein variational gradient descent (SVGD) algorithms after 1000 iterations over five independent trials on the
25-Gaussian particle-optimization problem in R2under the experimental conditions described in Section 7.1.
ADAGRAD BATCH CONST ANNEAL SD (OURS) MMD SVGD
N N N N 0.0007 0.6129 0.8495
N N N Y 0.0007 0.6111 0.8521
N N Y N 0.0007 0.5816 0.7878
N N Y Y 0.0009 0.5837 0.7978
N Y N N 0.0374 0.9382 0.7944
N Y N Y 0.0357 0.9365 0.7863
N Y Y N 0.0371 0.9230 0.7454
N Y Y Y 0.0389 0.9249 0.7494
Y N N N 0.0006 0.1584 0.0033
Y N N Y 0.0006 0.1622 0.0031
Y N Y N 0.0006 0.1566 0.0029
Y N Y Y 0.0006 0.1553 0.0028
Y Y N N 0.0359 0.1884 0.0412
Y Y N Y 0.0399 0.1895 0.0414
Y Y Y N 0.0381 0.1892 0.0377
Y Y Y Y 0.0385 0.1902 0.0359
C.2 Data-Set Interpolation
Standard score-based generative modeling is designed such that the end of the forward process is a Gaussian
distribution. While this has the advantage of defining a prior that is easy to sample from for the reverse,
generative process, it limits the flexibility of the method. Recent work on approximating a Schrödinger bridge
between source and target distributions (De Bortoli et al., 2021) relaxes this limitation, but the method itself
is relatively complicated.
SD flow, on the other hand, is (in our opinion) a simpler and more intuitive method that also solves the
Schrödinger bridge problem (see Section 2.3) and places no restrictions on the distributions pandq. It
is therefore also capable of performing interpolation between arbitrary data sets. The results of one such
interpolation experiment are shown in Figure 3. The figure actually shows twointerpolation experiments:
The first evolves 1024 points of the “Swiss roll” data toward the “mystery” distribution (Section 7.2.2) in
R3, while the second evolves from the “mystery” distribution to the “Swiss roll.” The same cosine variance
schedule as in Section 7.2.2 was employed.
C.3 Nearest-Neighbor Analysis
It is important to note that SD flow does not cause the synthetic data to collapse to nearest neighbors
in the target distribution. In Figure 4, we show the distribution of distances from points in the synthetic
distribution to their first nearest neighbors in the target distribution (shaded in green) for the particle-
optimization experiment described in Section 7.2.2. Note the overlap with the distribution of distances
between target data points and their first nearest neighbors (excluding themselves) in the target distribution.
Overfitting to the target data would result in a large concentration of mass near zero for the synthetic data.
C.4 Model Optimization
Although we do not run experiments on high-dimensional image data in the present work for the reasons
described in Section 7, we report here an experiment using the model-optimization application (Algorithm 2)
on “high”-dimensional data in R50. Here the scare quotes acknowledge that this dimensionality is far lower
22Published in Transactions on Machine Learning Research (07/2023)
Table 4: Average minimum CFD (final three columns) for the SD flow (SD), MMD gradient flow (MMD) and
Stein variational gradient descent (SVGD) algorithms after 1000 iterations over five independent trials on
the “mystery distribution” particle-optimization problem in R3under the experimental conditions described
in Section 7.1.
ADAGRAD BATCH CONST ANNEAL OFFSET SD (OURS) MMD SVGD
N N N N N 0.0002 0.1020 0.2407
N N N N Y 0.0026 0.7050 0.6994
N N N Y N 0.0004 0.1020 0.2407
N N N Y Y 0.0020 0.7050 0.6995
N N Y N N 0.0005 0.1186 0.2761
N N Y N Y 0.0006 0.5953 0.7006
N N Y Y N 0.0005 0.1185 0.2762
N N Y Y Y 0.0006 0.5953 0.7006
N Y N N N 0.0146 0.1689 0.1804
N Y N N Y 0.0136 0.8250 0.6060
N Y N Y N 0.0157 0.1734 0.1725
N Y N Y Y 0.0172 0.8231 0.6051
N Y Y N N 0.0159 0.2086 0.2410
N Y Y N Y 0.0157 0.8348 0.6168
N Y Y Y N 0.0167 0.2045 0.2359
N Y Y Y Y 0.0168 0.8404 0.6265
Y N N N N 0.0039 0.0029 0.0059
Y N N N Y 0.0038 0.1945 0.0057
Y N N Y N 0.0037 0.0033 0.0059
Y N N Y Y 0.0042 0.1938 0.0060
Y N Y N N 0.0056 0.0039 0.0077
Y N Y N Y 0.0056 0.0847 0.0081
Y N Y Y N 0.0056 0.0041 0.0082
Y N Y Y Y 0.0056 0.0841 0.0083
Y Y N N N 0.0154 0.0972 0.0175
Y Y N N Y 0.0163 0.3141 0.0185
Y Y N Y N 0.0148 0.0972 0.0176
Y Y N Y Y 0.0162 0.3117 0.0164
Y Y Y N N 0.0146 0.1122 0.0242
Y Y Y N Y 0.0162 0.2915 0.0228
Y Y Y Y N 0.0165 0.1111 0.0222
Y Y Y Y Y 0.0149 0.2922 0.0238
than the thousands to millions of dimensions typical in high-resolution image data, but it is high enough to
exhibit the problematic, intuition-challenging characteristics of high-dimensional data in general.
Specifically, it is well known that as data dimensionality grows, the ratio of the distance of a point to its
farthest neighbor,Dmax, and the distance to its nearestneighbor,Dmin, tends toward unity. The ratio
Dmax/Dmindrops precipitously in lower dimensions before leveling off at around 30 dimensions and very
slowlyapproachinganasymptoteofoneafterward(Beyeretal.,1999). Wethereforechose R50asareasonable
setting to challenge our approach in high dimensions.
We generated a ground-truth target distribution by randomly populating a 50×25matrixBwith values
drawn fromN(0,0.25I)and a 50-vectorµwith values drawn from N(10,I). Target data samples from
N(µ,BB⊤)were then generated18by drawing samples ξ∼N(0,I)∈R25and forming x=Bξ+µ. The
18Technically, this is not completely well defined as a normal distribution, since BB⊤is not of full rank.
23Published in Transactions on Machine Learning Research (07/2023)
Figure 3: Top: Data-set interpolation via evolution of 1024 points from the “Swiss roll” distribution to the
“mystery” distribution in R3. Bottom: The reverse interpolation, from the “mystery” distribution to the
“Swiss roll” distribution.
Figure 4: Distribution of distances from synthetic (blue) and target (red) data points to their first nearest
neighbors in the target distribution.
model parameters to be learned were a 50×25matrix ˆB, initialized from N(0,0.01I), and a 50-vector ˆµ,
initialized to all zeros. This model can be interpreted as a single-layer linear neural network, but it is most
important to note that it exactly matches the capacity of the data-generating model.
If we retained the input vectors ξ∈Ξfor the outputs x∈X, then the task of learning the parameters
would be fairly straightforward in the context of a regression problem on paired data {(ξ,x)}. But in the
general IGM problem, we have only unpaired data to work with, so we assume that all information about
the target data inputs is unavailable.
We performed 1000 steps of SD flow using Algorithm 2 with a constant noise schedule of 10 times the
average distance of the initial synthetic (base) distribution to first nearest neighbors in the target distribution
24Published in Transactions on Machine Learning Research (07/2023)
Figure 5: Model optimization results in R50using a constant noise schedule. SD flow allows a parametric
model to be learned that very closely matches the target mean ( µversus ˆµ, left panel) and the elements of
the covariance matrix ( BB⊤vsˆBˆB⊤, center panel). Diagonals are included for reference. Nearest-neighbor
analysisshowednooverfittingofthedata(rightpanel)butshowedaslightlyloweraveragedistancetonearest
neighbors in the target set than exhibited by the target data relative to itself.
(corresponding to σ2>700),19with a batch size of 1024, an SD flow step size of η= 1, and a regression
learning rate of λ= 10−3. Other than brief experimentation to set reasonable values, no effort was made to
optimize these hyperparameters.
The results of this experiment are shown in Figure 5. Despite (or perhaps because of ) a massive and constant
injection of noise, SD flow successfully fit the target distribution. Analysis of nearest neighbors once again
showed that SD flow did not overfit to the target distribution, although there was a very slight shift toward
lower distances between synthetic data and their nearest neighbors in the target distribution as compared
with the target data’s nearest-neighbor distances relative to itself.
This experiment provides a basic proof of concept for a much more general procedure, one that can benefit
from more sophisticated model architectures specifically suited to the problem at hand. For instance, for
image generation, the kernel-based specification of SD flow from Section 3.1 can be exchanged for the
denoising-based specification from Section 3.2, allowing one to take advantage of attention-equipped U-net
denoising architectures. Furthermore, methods can be mixed and matched: A denoising model can be
employed for the pscore component while a kernel-based estimate can be used for the qtscore component,
for example.
19We found that using a higher amount of noise somewhat improved the convergence profile of the algorithm.
25