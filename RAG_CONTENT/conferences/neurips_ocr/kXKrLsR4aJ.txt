Input-to-State Stable Coupled Oscillator Networks for
Closed-form Model-based Control in Latent Space
Maximilian Stölzle
Department of Cognitive Robotics
Delft University of Technology
M.W.Stolzle@tudelft.nlCosimo Della Santina
Department of Cognitive Robotics
Delft University of Technology
C.DellaSantina@tudelft.nl
Abstract
Even though a variety of methods have been proposed in the literature, efficient and
effective latent-space control (i.e., control in a learned low-dimensional space) of
physical systems remains an open challenge. We argue that a promising avenue is to
leverage powerful and well-understood closed-form strategies from control theory
literature in combination with learned dynamics, such as potential-energy shaping.
We identify three fundamental shortcomings in existing latent-space models that
have so far prevented this powerful combination: (i) they lack the mathematical
structure of a physical system, (ii) they do not inherently conserve the stability
properties of the real systems, (iii) these methods do not have an invertible mapping
between input and latent-space forcing. This work proposes a novel Coupled
Oscillator Network (CON) model that simultaneously tackles all these issues.
More specifically, (i) we show analytically that CON is a Lagrangian system - i.e.,
it possesses well-defined potential and kinetic energy terms. Then, (ii) we provide
formal proof of global Input-to-State stability using Lyapunov arguments. Moving
to the experimental side, we demonstrate that CON reaches SoA performance when
learning complex nonlinear dynamics of mechanical systems directly from images.
An additional methodological innovation contributing to achieving this third goal is
an approximated closed-form solution for efficient integration of network dynamics,
which eases efficient training. We tackle (iii) by approximating the forcing-to-input
mapping with a decoder that is trained to reconstruct the input based on the encoded
latent space force. Finally, we leverage these three properties and show that they
enable latent-space control. We use an integral-saturated PID with potential force
compensation and demonstrate high-quality performance on a soft robot using raw
pixels as the only feedback information.
1 Introduction
Learning how the environment evolves around us from high-dimensional observations (i.e., world
models [ 1]) is essential for achieving both artificial and physical intelligence [ 2]. For example,
world models are required for effectively planning an artificial/robotic agent’s actions in complex
and unstructured environments [ 3]. However, learning such dynamics directly in high-dimensional
observation space is usually intractable. Seminal works have shown that we can leverage autoencoders
to compress the state information into a low-dimensional latent space [ 4,5] in which it is much more
feasible to learn the dynamics [ 6,7,8,9,10]. However, strong limitations still persist when it comes
to using these learned models to generate low-level intelligence.
One outstanding challenge is how to perform closed-loop control in the learned latent space -
i.e., how to generate control inputs based on a high dimensional sensory input such that a desired
movement is generated. Prior works have explored, among other approaches, Reinforcement Learning
(RL) [ 11,12,13,14], Model Predictive Control (MPC) [ 7,15,16,17], Linear-quadratic Regulators
(LQRs) [ 18,19,20] and gradient-based optimization [ 21] for planning and control towards a target
evolution that is given in observation space. However, all existing latent-space control strategies have
38th Conference on Neural Information Processing Systems (NeurIPS 2024).<latexit sha1_base64="zIwYGdaFVBaiIZRzsEFi57A+yBE=">AAAB7XicbVDLSgNBEOz1GeMr6tHLYBA8hV3xeQt48RjBPCBZwuzsbDJmdmeZ6Q2EkH/w4kERr/6PN//GSbIHTSxoKKq66e4KUikMuu63s7K6tr6xWdgqbu/s7u2XDg4bRmWa8TpTUulWQA2XIuF1FCh5K9WcxoHkzWBwN/WbQ66NUMkjjlLux7SXiEgwilZqdIahQtMtld2KOwNZJl5OypCj1i19dULFspgnyCQ1pu25KfpjqlEwySfFTmZ4StmA9njb0oTG3Pjj2bUTcmqVkERK20qQzNTfE2MaGzOKA9sZU+ybRW8q/ue1M4xu/LFI0gx5wuaLokwSVGT6OgmF5gzlyBLKtLC3EtanmjK0ARVtCN7iy8ukcV7xriqXDxfl6m0eRwGO4QTOwINrqMI91KAODJ7gGV7hzVHOi/PufMxbV5x85gj+wPn8Acv6j0M=</latexit>...
<latexit sha1_base64="zIwYGdaFVBaiIZRzsEFi57A+yBE=">AAAB7XicbVDLSgNBEOz1GeMr6tHLYBA8hV3xeQt48RjBPCBZwuzsbDJmdmeZ6Q2EkH/w4kERr/6PN//GSbIHTSxoKKq66e4KUikMuu63s7K6tr6xWdgqbu/s7u2XDg4bRmWa8TpTUulWQA2XIuF1FCh5K9WcxoHkzWBwN/WbQ66NUMkjjlLux7SXiEgwilZqdIahQtMtld2KOwNZJl5OypCj1i19dULFspgnyCQ1pu25KfpjqlEwySfFTmZ4StmA9njb0oTG3Pjj2bUTcmqVkERK20qQzNTfE2MaGzOKA9sZU+ybRW8q/ue1M4xu/LFI0gx5wuaLokwSVGT6OgmF5gzlyBLKtLC3EtanmjK0ARVtCN7iy8ukcV7xriqXDxfl6m0eRwGO4QTOwINrqMI91KAODJ7gGV7hzVHOi/PufMxbV5x85gj+wPn8Acv6j0M=</latexit>...
<latexit sha1_base64="zIwYGdaFVBaiIZRzsEFi57A+yBE=">AAAB7XicbVDLSgNBEOz1GeMr6tHLYBA8hV3xeQt48RjBPCBZwuzsbDJmdmeZ6Q2EkH/w4kERr/6PN//GSbIHTSxoKKq66e4KUikMuu63s7K6tr6xWdgqbu/s7u2XDg4bRmWa8TpTUulWQA2XIuF1FCh5K9WcxoHkzWBwN/WbQ66NUMkjjlLux7SXiEgwilZqdIahQtMtld2KOwNZJl5OypCj1i19dULFspgnyCQ1pu25KfpjqlEwySfFTmZ4StmA9njb0oTG3Pjj2bUTcmqVkERK20qQzNTfE2MaGzOKA9sZU+ybRW8q/ue1M4xu/LFI0gx5wuaLokwSVGT6OgmF5gzlyBLKtLC3EtanmjK0ARVtCN7iy8ukcV7xriqXDxfl6m0eRwGO4QTOwINrqMI91KAODJ7gGV7hzVHOi/PufMxbV5x85gj+wPn8Acv6j0M=</latexit>...<latexit sha1_base64="zIwYGdaFVBaiIZRzsEFi57A+yBE=">AAAB7XicbVDLSgNBEOz1GeMr6tHLYBA8hV3xeQt48RjBPCBZwuzsbDJmdmeZ6Q2EkH/w4kERr/6PN//GSbIHTSxoKKq66e4KUikMuu63s7K6tr6xWdgqbu/s7u2XDg4bRmWa8TpTUulWQA2XIuF1FCh5K9WcxoHkzWBwN/WbQ66NUMkjjlLux7SXiEgwilZqdIahQtMtld2KOwNZJl5OypCj1i19dULFspgnyCQ1pu25KfpjqlEwySfFTmZ4StmA9njb0oTG3Pjj2bUTcmqVkERK20qQzNTfE2MaGzOKA9sZU+ybRW8q/ue1M4xu/LFI0gx5wuaLokwSVGT6OgmF5gzlyBLKtLC3EtanmjK0ARVtCN7iy8ukcV7xriqXDxfl6m0eRwGO4QTOwINrqMI91KAODJ7gGV7hzVHOi/PufMxbV5x85gj+wPn8Acv6j0M=</latexit>...
<latexit sha1_base64="tQ9+lo50UIBoTKRtWJm6U0D8rk8=">AAACCXicbVC7SgNBFJ2Nrxhfq5Y2g4lgFXaDrzJgY2cE84AkhNnJbDJkZnaZuRsIS77AX7DV3k5s/Qpbv8RJsoUmHrhwOOdezuUEseAGPO/Lya2tb2xu5bcLO7t7+wfu4VHDRImmrE4jEelWQAwTXLE6cBCsFWtGZCBYMxjdzvzmmGnDI/UIk5h1JRkoHnJKwEo91y3xEgzxvaFcCAKR7rlFr+zNgVeJn5EiylDrud+dfkQTyRRQQYxp+14M3ZRo4FSwaaGTGBYTOiID1rZUEclMN51/PsVnVunjMNJ2FOC5+vsiJdKYiQzspiQwNMveTPzPaycQ3nRTruIEmKKLoDARGCI8qwH3uWYUxMQSQjW3v2I6JJpQsGX9SQnktGBL8ZcrWCWNStm/Kl8+VIrVi6yePDpBp+gc+egaVdEdqqE6omiMntELenWenDfn3flYrOac7OYY/YHz+QNC/5m0</latexit>ith Oscillator
<latexit sha1_base64="a3In6a/dc0UAbm/2Z+OuPDE7fBI=">AAACBXicbVC7SgNBFJ31GeMramkzGASrsBt8lQEbOyOYByRrmJ3MJkPmsczcFUJI7S/Yam8ntn6HrV/iJNnCJB64cDjnXs7lRIngFnz/21tZXVvf2Mxt5bd3dvf2CweHdatTQ1mNaqFNMyKWCa5YDTgI1kwMIzISrBENbiZ+44kZy7V6gGHCQkl6isecEnDSY2AB31nKhSCgTadQ9Ev+FHiZBBkpogzVTuGn3dU0lUwBFcTaVuAnEI6IAU4FG+fbqWUJoQPSYy1HFZHMhqPp12N86pQujrVxowBP1b8XIyKtHcrIbUoCfbvoTcT/vFYK8XU44ipJgSk6C4pTgUHjSQW4yw2jIIaOEGq4+xXTPjGEgitqLiWS47wrJVisYJnUy6XgsnRxXy5WzrN6cugYnaAzFKArVEG3qIpqiCKDXtArevOevXfvw/ucra542c0RmoP39Qu/opj6</latexit>1st Oscillator<latexit sha1_base64="v929Q/qE0N2ruhmowWr8pLZzTSo=">AAAB7XicbVDLSgNBEJyNrxhfUY9eBoMQL2FXfOQY8OIxgnlAsoTZyWwyZnZmmekVliX/4MWDIl79H2/+jZNkD5pY0FBUddPdFcSCG3Ddb6ewtr6xuVXcLu3s7u0flA+P2kYlmrIWVULpbkAME1yyFnAQrBtrRqJAsE4wuZ35nSemDVfyAdKY+REZSR5ySsBK7XTAq3A+KFfcmjsHXiVeTiooR3NQ/uoPFU0iJoEKYkzPc2PwM6KBU8GmpX5iWEzohIxYz1JJImb8bH7tFJ9ZZYhDpW1JwHP190RGImPSKLCdEYGxWfZm4n9eL4Gw7mdcxgkwSReLwkRgUHj2Oh5yzSiI1BJCNbe3YjommlCwAZVsCN7yy6ukfVHzrmtX95eVRj2Po4hO0CmqIg/doAa6Q03UQhQ9omf0it4c5bw4787HorXg5DPH6A+czx8AS468</latexit>yi(t)<latexit sha1_base64="K4VZxsEFYN+nYF0r/RCqST8o6S8=">AAAB63icbVDLSsNAFL3xWeur6tLNYBHqpiTio8uCG5cV7APaUCbTSTt0ZhJmJkII/QU3LhRx6w+582+ctFlo64ELh3Pu5d57gpgzbVz321lb39jc2i7tlHf39g8OK0fHHR0litA2iXikegHWlDNJ24YZTnuxolgEnHaD6V3ud5+o0iySjyaNqS/wWLKQEWxyKa2Zi2Gl6tbdOdAq8QpShQKtYeVrMIpIIqg0hGOt+54bGz/DyjDC6aw8SDSNMZniMe1bKrGg2s/mt87QuVVGKIyULWnQXP09kWGhdSoC2ymwmehlLxf/8/qJCRt+xmScGCrJYlGYcGQilD+ORkxRYnhqCSaK2VsRmWCFibHxlG0I3vLLq6RzWfdu6tcPV9Vmo4ijBKdwBjXw4BaacA8taAOBCTzDK7w5wnlx3p2PReuaU8ycwB84nz+Djo3g</latexit>y(t)
<latexit sha1_base64="K4VZxsEFYN+nYF0r/RCqST8o6S8=">AAAB63icbVDLSsNAFL3xWeur6tLNYBHqpiTio8uCG5cV7APaUCbTSTt0ZhJmJkII/QU3LhRx6w+582+ctFlo64ELh3Pu5d57gpgzbVz321lb39jc2i7tlHf39g8OK0fHHR0litA2iXikegHWlDNJ24YZTnuxolgEnHaD6V3ud5+o0iySjyaNqS/wWLKQEWxyKa2Zi2Gl6tbdOdAq8QpShQKtYeVrMIpIIqg0hGOt+54bGz/DyjDC6aw8SDSNMZniMe1bKrGg2s/mt87QuVVGKIyULWnQXP09kWGhdSoC2ymwmehlLxf/8/qJCRt+xmScGCrJYlGYcGQilD+ORkxRYnhqCSaK2VsRmWCFibHxlG0I3vLLq6RzWfdu6tcPV9Vmo4ijBKdwBjXw4BaacA8taAOBCTzDK7w5wnlx3p2PReuaU8ycwB84nz+Djo3g</latexit>y(t)
<latexit sha1_base64="K4VZxsEFYN+nYF0r/RCqST8o6S8=">AAAB63icbVDLSsNAFL3xWeur6tLNYBHqpiTio8uCG5cV7APaUCbTSTt0ZhJmJkII/QU3LhRx6w+582+ctFlo64ELh3Pu5d57gpgzbVz321lb39jc2i7tlHf39g8OK0fHHR0litA2iXikegHWlDNJ24YZTnuxolgEnHaD6V3ud5+o0iySjyaNqS/wWLKQEWxyKa2Zi2Gl6tbdOdAq8QpShQKtYeVrMIpIIqg0hGOt+54bGz/DyjDC6aw8SDSNMZniMe1bKrGg2s/mt87QuVVGKIyULWnQXP09kWGhdSoC2ymwmehlLxf/8/qJCRt+xmScGCrJYlGYcGQilD+ORkxRYnhqCSaK2VsRmWCFibHxlG0I3vLLq6RzWfdu6tcPV9Vmo4ijBKdwBjXw4BaacA8taAOBCTzDK7w5wnlx3p2PReuaU8ycwB84nz+Djo3g</latexit>y(t)
<latexit sha1_base64="K4VZxsEFYN+nYF0r/RCqST8o6S8=">AAAB63icbVDLSsNAFL3xWeur6tLNYBHqpiTio8uCG5cV7APaUCbTSTt0ZhJmJkII/QU3LhRx6w+582+ctFlo64ELh3Pu5d57gpgzbVz321lb39jc2i7tlHf39g8OK0fHHR0litA2iXikegHWlDNJ24YZTnuxolgEnHaD6V3ud5+o0iySjyaNqS/wWLKQEWxyKa2Zi2Gl6tbdOdAq8QpShQKtYeVrMIpIIqg0hGOt+54bGz/DyjDC6aw8SDSNMZniMe1bKrGg2s/mt87QuVVGKIyULWnQXP09kWGhdSoC2ymwmehlLxf/8/qJCRt+xmScGCrJYlGYcGQilD+ORkxRYnhqCSaK2VsRmWCFibHxlG0I3vLLq6RzWfdu6tcPV9Vmo4ijBKdwBjXw4BaacA8taAOBCTzDK7w5wnlx3p2PReuaU8ycwB84nz+Djo3g</latexit>y(t)
<latexit sha1_base64="kAWcSlkXwbXKFkJ2bWJ9+DsAq9s=">AAAB/3icbVDLSgNBEOyNrxhfUY9eBoMgCGFXfOQY8OIxAfOAZAmzk9lkyOzMMjMrhCUHz171G7yJVz/FT/AvnE32oIkFDUVVN91dQcyZNq775RTW1jc2t4rbpZ3dvf2D8uFRW8tEEdoikkvVDbCmnAnaMsxw2o0VxVHAaSeY3GV+55EqzaR4MNOY+hEeCRYygo2VmheDcsWtunOgVeLlpAI5GoPyd38oSRJRYQjHWvc8NzZ+ipVhhNNZqZ9oGmMywSPas1TgiGo/nR86Q2dWGaJQKlvCoLn6eyLFkdbTKLCdETZjvexl4r9ephgpuV46wIQ1P2UiTgwVZLE/TDgyEmVhoCFTlBg+tQQTxewLiIyxwsTYyEo2G285iVXSvqx6N9Xr5lWlXstTKsIJnMI5eHALdbiHBrSAAIVneIFX58l5c96dj0VrwclnjuEPnM8f6ueWiw==</latexit>+<latexit sha1_base64="VmUWqJgL2CWL95h7mZiZB6Bf6UA=">AAAB/3icbVDLSgNBEOyNrxhfUY9eBoPgxbArPnIMePGYgHlAsoTZyWwyZHZmmZkVwpKDZ6/6Dd7Eq5/iJ/gXziZ70MSChqKqm+6uIOZMG9f9cgpr6xubW8Xt0s7u3v5B+fCorWWiCG0RyaXqBlhTzgRtGWY47caK4ijgtBNM7jK/80iVZlI8mGlM/QiPBAsZwcZKzYtBueJW3TnQKvFyUoEcjUH5uz+UJImoMIRjrXueGxs/xcowwums1E80jTGZ4BHtWSpwRLWfzg+doTOrDFEolS1h0Fz9PZHiSOtpFNjOCJuxXvYy8V8vU4yUXC8dYMKanzIRJ4YKstgfJhwZibIw0JApSgyfWoKJYvYFRMZYYWJsZCWbjbecxCppX1a9m+p186pSr+UpFeEETuEcPLiFOtxDA1pAgMIzvMCr8+S8Oe/Ox6K14OQzx/AHzucP7h2WjQ==</latexit> 
<latexit sha1_base64="kAWcSlkXwbXKFkJ2bWJ9+DsAq9s=">AAAB/3icbVDLSgNBEOyNrxhfUY9eBoMgCGFXfOQY8OIxAfOAZAmzk9lkyOzMMjMrhCUHz171G7yJVz/FT/AvnE32oIkFDUVVN91dQcyZNq775RTW1jc2t4rbpZ3dvf2D8uFRW8tEEdoikkvVDbCmnAnaMsxw2o0VxVHAaSeY3GV+55EqzaR4MNOY+hEeCRYygo2VmheDcsWtunOgVeLlpAI5GoPyd38oSRJRYQjHWvc8NzZ+ipVhhNNZqZ9oGmMywSPas1TgiGo/nR86Q2dWGaJQKlvCoLn6eyLFkdbTKLCdETZjvexl4r9ephgpuV46wIQ1P2UiTgwVZLE/TDgyEmVhoCFTlBg+tQQTxewLiIyxwsTYyEo2G285iVXSvqx6N9Xr5lWlXstTKsIJnMI5eHALdbiHBrSAAIVneIFX58l5c96dj0VrwclnjuEPnM8f6ueWiw==</latexit>+<latexit sha1_base64="VmUWqJgL2CWL95h7mZiZB6Bf6UA=">AAAB/3icbVDLSgNBEOyNrxhfUY9eBoPgxbArPnIMePGYgHlAsoTZyWwyZHZmmZkVwpKDZ6/6Dd7Eq5/iJ/gXziZ70MSChqKqm+6uIOZMG9f9cgpr6xubW8Xt0s7u3v5B+fCorWWiCG0RyaXqBlhTzgRtGWY47caK4ijgtBNM7jK/80iVZlI8mGlM/QiPBAsZwcZKzYtBueJW3TnQKvFyUoEcjUH5uz+UJImoMIRjrXueGxs/xcowwums1E80jTGZ4BHtWSpwRLWfzg+doTOrDFEolS1h0Fz9PZHiSOtpFNjOCJuxXvYy8V8vU4yUXC8dYMKanzIRJ4YKstgfJhwZibIw0JApSgyfWoKJYvYFRMZYYWJsZCWbjbecxCppX1a9m+p186pSr+UpFeEETuEcPLiFOtxDA1pAgMIzvMCr8+S8Oe/Ox6K14OQzx/AHzucP7h2WjQ==</latexit> 
<latexit sha1_base64="kAWcSlkXwbXKFkJ2bWJ9+DsAq9s=">AAAB/3icbVDLSgNBEOyNrxhfUY9eBoMgCGFXfOQY8OIxAfOAZAmzk9lkyOzMMjMrhCUHz171G7yJVz/FT/AvnE32oIkFDUVVN91dQcyZNq775RTW1jc2t4rbpZ3dvf2D8uFRW8tEEdoikkvVDbCmnAnaMsxw2o0VxVHAaSeY3GV+55EqzaR4MNOY+hEeCRYygo2VmheDcsWtunOgVeLlpAI5GoPyd38oSRJRYQjHWvc8NzZ+ipVhhNNZqZ9oGmMywSPas1TgiGo/nR86Q2dWGaJQKlvCoLn6eyLFkdbTKLCdETZjvexl4r9ephgpuV46wIQ1P2UiTgwVZLE/TDgyEmVhoCFTlBg+tQQTxewLiIyxwsTYyEo2G285iVXSvqx6N9Xr5lWlXstTKsIJnMI5eHALdbiHBrSAAIVneIFX58l5c96dj0VrwclnjuEPnM8f6ueWiw==</latexit>+<latexit sha1_base64="VmUWqJgL2CWL95h7mZiZB6Bf6UA=">AAAB/3icbVDLSgNBEOyNrxhfUY9eBoPgxbArPnIMePGYgHlAsoTZyWwyZHZmmZkVwpKDZ6/6Dd7Eq5/iJ/gXziZ70MSChqKqm+6uIOZMG9f9cgpr6xubW8Xt0s7u3v5B+fCorWWiCG0RyaXqBlhTzgRtGWY47caK4ijgtBNM7jK/80iVZlI8mGlM/QiPBAsZwcZKzYtBueJW3TnQKvFyUoEcjUH5uz+UJImoMIRjrXueGxs/xcowwums1E80jTGZ4BHtWSpwRLWfzg+doTOrDFEolS1h0Fz9PZHiSOtpFNjOCJuxXvYy8V8vU4yUXC8dYMKanzIRJ4YKstgfJhwZibIw0JApSgyfWoKJYvYFRMZYYWJsZCWbjbecxCppX1a9m+p186pSr+UpFeEETuEcPLiFOtxDA1pAgMIzvMCr8+S8Oe/Ox6K14OQzx/AHzucP7h2WjQ==</latexit> <latexit sha1_base64="SBHfdTWZzi6AKGVbvIXRTXhYlKM=">AAAB7XicbVDLSgNBEOz1GeMr6tHLYhDiJeyKxBwDgniMYB6QLGF2MpuMmZ1ZZnqFEPIPXjwo4tX/8ebfOEn2oIkFDUVVN91dYSK4Qc/7dtbWNza3tnM7+d29/YPDwtFx06hUU9agSijdDolhgkvWQI6CtRPNSBwK1gpHNzO/9cS04Uo+4DhhQUwGkkecErRS87bnl/CiVyh6ZW8Od5X4GSlChnqv8NXtK5rGTCIVxJiO7yUYTIhGTgWb5rupYQmhIzJgHUsliZkJJvNrp+65VfpupLQtie5c/T0xIbEx4zi0nTHBoVn2ZuJ/XifFqBpMuExSZJIuFkWpcFG5s9fdPteMohhbQqjm9laXDokmFG1AeRuCv/zyKmlelv1KuXJ/VaxVszhycApnUAIfrqEGd1CHBlB4hGd4hTdHOS/Ou/OxaF1zspkT+APn8wdcu45S</latexit>F1(t)
<latexit sha1_base64="zf6lPHJ/tldIlYz8fN12ScW1ZK4=">AAAB7XicbVDLSgNBEOz1GeMr6tHLYhDiJeyKxBwDgniMYB6QLGF2MpuMmZ1ZZnqFEPIPXjwo4tX/8ebfOEn2oIkFDUVVN91dYSK4Qc/7dtbWNza3tnM7+d29/YPDwtFx06hUU9agSijdDolhgkvWQI6CtRPNSBwK1gpHNzO/9cS04Uo+4DhhQUwGkkecErRS87bHS3jRKxS9sjeHu0r8jBQhQ71X+Or2FU1jJpEKYkzH9xIMJkQjp4JN893UsITQERmwjqWSxMwEk/m1U/fcKn03UtqWRHeu/p6YkNiYcRzazpjg0Cx7M/E/r5NiVA0mXCYpMkkXi6JUuKjc2etun2tGUYwtIVRze6tLh0QTijagvA3BX355lTQvy36lXLm/KtaqWRw5OIUzKIEP11CDO6hDAyg8wjO8wpujnBfn3flYtK452cwJ/IHz+QOyQ46K</latexit>Fi(t)
<latexit sha1_base64="EYWfZzllUGV5O1yLOIvO2tyCRIo=">AAAB7XicbVDLSgNBEOz1GeMr6tHLYhDiJeyKxBwDgniMYB6QLGF2MpuMmZ1ZZnqFEPIPXjwo4tX/8ebfOEn2oIkFDUVVN91dYSK4Qc/7dtbWNza3tnM7+d29/YPDwtFx06hUU9agSijdDolhgkvWQI6CtRPNSBwK1gpHNzO/9cS04Uo+4DhhQUwGkkecErRS87YnS3jRKxS9sjeHu0r8jBQhQ71X+Or2FU1jJpEKYkzH9xIMJkQjp4JN893UsITQERmwjqWSxMwEk/m1U/fcKn03UtqWRHeu/p6YkNiYcRzazpjg0Cx7M/E/r5NiVA0mXCYpMkkXi6JUuKjc2etun2tGUYwtIVRze6tLh0QTijagvA3BX355lTQvy36lXLm/KtaqWRw5OIUzKIEP11CDO6hDAyg8wjO8wpujnBfn3flYtK452cwJ/IHz+QO55o6P</latexit>Fn(t)<latexit sha1_base64="9Zzfm6b0zquxbsqxw2AcJW6fHD4=">AAADCnicbVLLatwwFNW4r9R9JemyG9OhkEIZJL+9C3TTZQqdSSAzDLIsT9TIspHkwmD8B11k235Gd6Xb/kR/ot9Q2TNtUk8uCA7n3nvO1eWmFWdKQ/hrZN25e+/+g72H9qPHT54+2z84nKmyloROSclLeZZiRTkTdKqZ5vSskhQXKaen6eXbLn/6iUrFSvFBryu6KPBKsJwRrA01Wy/FkX693B/DCezD2QVoC8ZgGyfLg9HveVaSuqBCE46VOkew0osGS80Ip609rxWtMLnEK3puoMAFVYumH7d1Xhkmc/JSmie007M3OxpcKLUuUlNZYH2hhrmOvDXXMbosuRoMoPN40TBR1ZoKsvHPa+7o0ulW4mRMUqL52gBMJDNfcMgFlphoszjbnmc0N9vtx2yKtaRZ28hV2jZwEicQJSGMYt9DXuQGb8zW3A30/6Z60kNR6EcwiGPXC9zEb4eqK0mp+KeLfHSzweskbvVKYuglLgrCOHQjP9iRTXlNr1XhoLyTCK6H6j07LhxYtba5EDS8h10wcyconITv/fFxvL2VPfACvARHAIEIHIN34ARMAQEfwRX4Ar5an61v1nfrx6bUGm17noP/wvr5B6hg3rI=</latexit>yn(t)
<latexit sha1_base64="QcTHR5MU018ymfikujaK8XUOoCE=">AAADCnicbVLLatwwFNW4r9R9JemyG9OhkEIZJL+9C3TTZQqdSSAzDLIsT9TIspHkwmD8B11k235Gd6Xb/kR/ot9Q2TNtUk8uCA7n3nvO1eWmFWdKQ/hrZN25e+/+g72H9qPHT54+2z84nKmyloROSclLeZZiRTkTdKqZ5vSskhQXKaen6eXbLn/6iUrFSvFBryu6KPBKsJwRrA01Wy3FUf16uT+GE9iHswvQFozBNk6WB6Pf86wkdUGFJhwrdY5gpRcNlpoRTlt7XitaYXKJV/TcQIELqhZNP27rvDJM5uSlNE9op2dvdjS4UGpdpKaywPpCDXMdeWuuY3RZcjUYQOfxomGiqjUVZOOf19zRpdOtxMmYpETztQGYSGa+4JALLDHRZnG2Pc9obrbbj9kUa0mztpGrtG3gJE4gSkIYxb6HvMgN3pituRvo/031pIei0I9gEMeuF7iJ3w5VV5JS8U8X+ehmg9dJ3OqVxNBLXBSEcehGfrAjm/KaXqvCQXknEVwP1Xt2XDiwam1zIWh4D7tg5k5QOAnf++PjeHsre+AFeAmOAAIROAbvwAmYAgI+givwBXy1PlvfrO/Wj02pNdr2PAf/hfXzD3tW3qE=</latexit>gn(u)
<latexit sha1_base64="yVugM+z1WFJEj64PD+e5Tl2B2A8=">AAACJ3icbVDLSsNAFJ34rPFVdelmsAiuSlJ8LQsiuKxgH9CEMpnctkMnkzAzEUvoX/gT/oJb3bsTXeqXOG0j2NYDA4dz7uHeOUHCmdKO82ktLa+srq0XNuzNre2d3eLefkPFqaRQpzGPZSsgCjgTUNdMc2glEkgUcGgGg6ux37wHqVgs7vQwAT8iPcG6jBJtpE6x7AXQYyKjIDTIkX39QJmeeJ6HORmCtD0Q4a/fKZacsjMBXiRuTkooR61T/PbCmKaRiVNOlGq7TqL9jEjNKIeR7aUKEkIHpAdtQwWJQPnZ5F8jfGyUEHdjaZ7QeKL+TWQkUmoYBWYyIrqv5r2x+J/XTnX30s+YSFINgk4XdVOOdYzHJeGQSaCaDw0hVDJzK6Z9Igk1HcxuCaKRbUpx5ytYJI1K2T0vn91WStXTvJ4COkRH6AS56AJV0Q2qoTqi6BE9oxf0aj1Zb9a79TEdXbLyzAGagfX1A2Lspx4=</latexit>Excitationlayer<latexit sha1_base64="ixeDw9+PVUH4uiHOcIEH5wXYZtY=">AAACNHicbVDLSgMxFM34rOOr6tJNsAiuykzxBW4KgrisYFXolJLJ3LaheQxJRihDP8af8Bfc6lJwpbj1G0xrBdt6IHA459zc5MQpZ8YGwas3N7+wuLRcWPFX19Y3Notb2zdGZZpCnSqu9F1MDHAmoW6Z5XCXaiAi5nAb986H/u09aMOUvLb9FJqCdCRrM0qsk1rFsyiGDpM5BWlBD/wL5e5NsADaJdKleBT5ylDGObFKGz8CmfyGW8VSUA5GwLMkHJMSGqPWKr5HiaKZcOOUE2MaYZDaZk60ZZTDwI8yAymhPdKBhqOSCDDNfPTJAd53SoLbSrsjLR6pfydyIozpi9glBbFdM+0Nxf+8Rmbbp82cyTSzIOnPonbGsVV42BhOmAZqed8RQjVzb8WuHE2o62BySywGvislnK5gltxUyuFx+eiqUqoejuspoF20hw5QiE5QFV2iGqojih7QE3pGL96j9+Z9eJ8/0TlvPLODJuB9fQPzV6x8</latexit>Forced mechanicaloscillators
<latexit sha1_base64="sCYJBBFxUUzulT4CXJHCPPk2UKs=">AAAB7HicbVDLSgMxFL2pr1pfVZdugkVwVWaKr2XBje4qOG2hHUomzbShmcyQZIQy9BvcuFDErR/kzr8x085CWw8EDufcS+45QSK4No7zjUpr6xubW+Xtys7u3v5B9fCoreNUUebRWMSqGxDNBJfMM9wI1k0UI1EgWCeY3OZ+54kpzWP5aKYJ8yMykjzklBgrefcySc2gWnPqzhx4lbgFqUGB1qD61R/GNI2YNFQQrXuukxg/I8pwKtis0k81SwidkBHrWSpJxLSfzY+d4TOrDHEYK/ukwXP190ZGIq2nUWAnI2LGetnLxf+8XmrCGz/jeSIm6eKjMBXYxDhPjodcMWrE1BJCFbe3YjomilBj+6nYEtzlyKuk3ai7V/XLh0ateVHUUYYTOIVzcOEamnAHLfCAAodneIU3JNELekcfi9ESKnaO4Q/Q5w/mj462</latexit>Input<latexit sha1_base64="SAUXJxwnDcdtCn1BuVbwe8CHJA8=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0mKX8eCF48VTVtoQ9lsN+3SzSbsToRS+hu8eFDEqz/Im//GbZuDtj4YeLw3w8y8MJXCoOt+O4W19Y3NreJ2aWd3b/+gfHjUNEmmGfdZIhPdDqnhUijuo0DJ26nmNA4lb4Wj25nfeuLaiEQ94jjlQUwHSkSCUbSS/4AUea9ccavuHGSVeDmpQI5Gr/zV7Scsi7lCJqkxHc9NMZhQjYJJPi11M8NTykZ0wDuWKhpzE0zmx07JmVX6JEq0LYVkrv6emNDYmHEc2s6Y4tAsezPxP6+TYXQTTIRKM+SKLRZFmSSYkNnnpC80ZyjHllCmhb2VsCHVlKHNp2RD8JZfXiXNWtW7ql7e1yr1izyOIpzAKZyDB9dQhztogA8MBDzDK7w5ynlx3p2PRWvByWeO4Q+czx/P7o6n</latexit>State
<latexit sha1_base64="MSKKPBOCbwNd0B1+Sj6xUeLsnIo=">AAAB7XicbVDLSgNBEOyNrxhfUY9eBoMQL2FXfOQY8OIxgnlAsoTZyWwyZnZmmZkVliX/4MWDIl79H2/+jZNkD5pY0FBUddPdFcScaeO6305hbX1jc6u4XdrZ3ds/KB8etbVMFKEtIrlU3QBrypmgLcMMp91YURwFnHaCye3M7zxRpZkUDyaNqR/hkWAhI9hYqZ0OvKo5H5Qrbs2dA60SLycVyNEclL/6Q0mSiApDONa657mx8TOsDCOcTkv9RNMYkwke0Z6lAkdU+9n82ik6s8oQhVLZEgbN1d8TGY60TqPAdkbYjPWyNxP/83qJCet+xkScGCrIYlGYcGQkmr2OhkxRYnhqCSaK2VsRGWOFibEBlWwI3vLLq6R9UfOua1f3l5VGPY+jCCdwClXw4AYacAdNaAGBR3iGV3hzpPPivDsfi9aCk88cwx84nz+qtI6E</latexit>y1(t)
<latexit sha1_base64="mP4+kvOsJqNhIj2LpODhVi6axQ0=">AAADCHicbVLLahRBFK1pX7F9JNGlm8ZBiCBDVb97F3DjMoKTBDJDqK6+M1Ok+kFVtTA0/QMu3OpnuBO3/oU/4TdY3TOa2JMLBYdz7z3n1uWmleBKY/xrZN25e+/+g72H9qPHT57uHxw+O1VlLRlMWSlKeZ5SBYIXMNVcCzivJNA8FXCWXr3t8mcfQSpeFh/0uoJ5TpcFX3BGdUfVR/r15cEYT3Afzi4gWzBG2zi5PBz9nmUlq3MoNBNUqQuCKz1vqNScCWjtWa2gouyKLuHCwILmoOZNP2zrvDJM5ixKaV6hnZ692dHQXKl1nprKnOqVGuY68tZcx+iyFGowgF7E84YXVa2hYBv/RS0cXTrdQpyMS2BarA2gTHLzBYetqKRMm7XZ9iyDhdltP2aTryVkbSOXadvgSZxgkoQ4in2PeJEbvDFbczfQ/5vqSY9EoR/hII5dL3ATvx2qLiVA8U+X+ORmg9dJ3OqVxNhLXBKEcehGfrAjm4oarlXxoLyTCK6H6j07LhxYtba5EDK8h11w6k5IOAnf++PjeHsre+gFeomOEEEROkbv0AmaIoZW6DP6gr5an6xv1nfrx6bUGm17nqP/wvr5BzL93c0=</latexit>u(t)<latexit sha1_base64="qHHxmamcJWvrX46HD0eeUP29LI4=">AAADCnicbVJLahtBEG1Nfs7kZzvLbIaIgANBdM9/doZssnQgkg2WED2tktxxz4funoAY5gZZeJscI7uQbS6RS+QM6RkpsTNyQcPjVdV71UWlpeBKY/xrYN25e+/+g72H9qPHT54+2z84nKiikgzGrBCFPEupAsFzGGuuBZyVEmiWCjhNL9+2+dNPIBUv8g96XcIso6ucLzmj2lCT1ZwfVa/n+0M8wl04u4BswRBt42R+MPg9XRSsyiDXTFClzgku9aymUnMmoLGnlYKSsku6gnMDc5qBmtXduI3zyjALZ1lI83LtdOzNjppmSq2z1FRmVF+ofq4lb821jC4KoXoD6GU8q3leVhpytvFfVsLRhdOuxFlwCUyLtQGUSW6+4LALKinTZnG2PV3A0my3G7PO1hIWTS1XaVPjUZxgkoQ4in2PeJEbvDFbczfQ/5vqSI9EoR/hII5dL3ATv+mrriRA/k+X+ORmg9dK3OqVxNhLXBKEcehGfrAjm4oKrlVxr7yVCK6H6jxbLuxZNba5ENK/h10wcUckHIXv/eFxvL2VPfQCvURHiKAIHaN36ASNEUMf0RX6gr5an61v1nfrx6bUGmx7nqP/wvr5B24i3pw=</latexit>gi(u)
<latexit sha1_base64="lI9XYotrEkGt04VOeAXfa5f/9w0=">AAADCnicbVJLatxAEO1Rfo7ys51lNiJDwIEwdOuvnSGbLB3IjA2eYWi1SmPFrQ/drcAgdIMsvE2OkV3INpfIJXKGtDST2NG4oOHxquq96qLiimdSYfxrZNy5e+/+g72H5qPHT54+2z84nMmyFgymrOSlOIupBJ4VMFWZ4nBWCaB5zOE0vnzb5U8/gZBZWXxQ6woWOV0VWZoxqjQ1Wy3JUf16uT/GE9yHtQvIFozRNk6WB6Pf86RkdQ6FYpxKeU5wpRYNFSpjHFpzXkuoKLukKzjXsKA5yEXTj9tarzSTWGkp9CuU1bM3OxqaS7nOY12ZU3Uhh7mOvDXXMaosuRwMoNJw0WRFVSso2MY/rbmlSqtbiZVkApjiaw0oE5n+gsUuqKBM6cWZ5jyBVG+3H7PJ1wKSthGruG3wJIwwiXwchK5DnMD23uit2Rvo/k31pEMC3w2wF4a249mR2w5VVwKg+KdLXHKzwekkbvWKQuxENvH80LcD19uRjXkN16p4UN5JeNdD9Z4d5w+sWlNfCBnewy6Y2RPiT/z37vg43N7KHnqBXqIjRFCAjtE7dIKmiKGP6Ap9QV+Nz8Y347vxY1NqjLY9z9F/Yfz8A9oz3mQ=</latexit>g1(u)
<latexit sha1_base64="mfJDUaPzT1ufQsK14UAuk0vgx2g=">AAADQHicbVJLb9QwEPaGVwmvLRy5RFRIHOgq72Q5VUJCcCsS21ZqVivHmU2tJnZkO0irKP+F38KBK1z5B5xAXDnhZLe0ZDuSpU/fzHzz8KRVQaWy7e8j48bNW7fv7Nw1791/8PDRePfxkeS1IDAjvODiJMUSCspgpqgq4KQSgMu0gOP0/HXnP/4IQlLOPqhVBfMS54wuKcFKU4vxqySFnLKGAFMgWtOy3rGqVvuK77/hglCWJ4kmS1xVGpsJsOwidjHesyd2b9Y2cDZgD23scLE7+plknNSlzicFlvLUsSs1b7BQlBTQmkktocLkHOdwqiHDJch50w/ZWs81k1lLLvRjyurZqxkNLqVclamOLLE6k0NfR17r6xjFeSEHDahlPG9otw1gZF1/WReW4la3SCujAogqVhpgIqgewSJnWGCidyNNM8lgqf+kb7MpVwKythF52jb2JJ7azjS0o9j3HC9yg5d6a+4a+heunvScKPQjO4hj1wvcqd8OVXMBwP7pOr5zNcHrJK6tNY1tb+o6QRiHbuQHW7JpUcOlqj0I7ySCy6b6mh0XDkq1pr4QZ3gP2+DInTjhJHzv7h34m1vZQU/RM/QCOShCB+gtOkQzRNAn9AV9Rd+Mz8YP45fxex1qjDY5T9B/Zvz5C9br9Bc=</latexit>Input-to-Forcingmapping<latexit sha1_base64="pcE63Qt/mTsMwniOI0MfctogkHQ=">AAADFnicbVLLbtQwFPWEVxsencKSTcQUiQUa2XlnV4kNO4rEtJU6o5HjeGasOnFkO5VGUf6DBVv4DHaILVt+gm+okxloyfRKlo7Ovfec66ublpwpDeHvgXXv/oOHj/b27cdPnj47GB4+P1WikoROiOBCnqdYUc4KOtFMc3peSorzlNOz9PJdmz+7olIxUXzS65LOcrws2IIRrA01Hw6PiiO9cj4owjjHWsj5cATHsAtnF6AtGIFtnMwPB3+mmSBVTgtNOFbqAsFSz2osNSOcNva0UrTE5BIv6YWBBc6pmtXd6I3z2jCZsxDSvEI7HXu7o8a5Uus8NZU51ivVz7XknbmW0UJw1RtAL+JZzYqy0rQgG/9FxR0tnHY9TsYkJZqvDcBEMvMFh6ywxESbJdr2NKMLs+luzDpfS5o1tVymTQ3HcQJREsIo9j3kRW7w1mzN3UD/b6ojPRSFfgSDOHa9wE38pq+6lJQW/3SRj243eK3EnV5JDL3ERUEYh27kBzuyKa/ojSrslbcSwc1QnWfLhT2rxjYXgvr3sAtO3TEKx+FHd3Tsb29lD7wEr8AbgEAEjsF7cAImgIAr8AV8Bd+sz9Z364f1c1NqDbY9L8B/Yf26BsMH4wQ=</latexit>nth Oscillator
<latexit sha1_base64="KQt64t/eOTEDhoXKN9P2bRNQ3Y4=">AAADlnicdVLbihNBEO3Z8bLGW1ZfBBEag5qgG3qumYDKgoqCLxHMZmEnhJ6eTjJkbkz3SMLQH+Hn+RE++2rPJWwS14KGw6mqc4qu8tIwYByhX8qReuPmrdvHd1p3791/8LB98uicJXlG6JgkYZJdeJjRMIjpmAc8pBdpRnHkhXTirT6U+ckPmrEgib/zTUqnEV7EwTwgmEtq1v7pcrrmlU4RbRYZpbEoXN9PeLEW8DV0VzhNMVxL6EO3pit+t80LcyqK7tfTurpXVnc/nvo990qH43jZnVRCXk/Ad/sKGfVFsejmPdGatTuoj6qAu0CzDWRDrWE6oInR7ET5LX1IHtGYkxAzdqmhlE8LnPGAhFS03JzRFJMVXtBLCWMcUTYtKmsBX0jGh/Mkky/msGJ3OwocMbaJPFkZYb5kh7mSvC53mfO5My2COM05jUltNM9DyBNYLgL6QUYJDzcSYJIFclZIljjDhMt17bmU2jxJQiZaLdenc7nqvX/LFp4oUN8ZIm1oo4FjGpox0K038tf0GprbVEUa2sA2B8hyHN2w9KEpDlWbM2h0NVPbbTBKiWu9hg4yhrpm2Y6tD0zrH9n6TLaq6KC8lLCuhqo8S84+sBLyQLZXAP8PzvW+Zvftb2bn7G1zKsfgKXgOukADA3AGvoARGAMC/ijPlJfKK/WJ+l79pH6uS4+Upucx2At19Be5+Q5o</latexit>¨x+x+d˙x+(K )x+(D d)˙x+ tanh(Wx+b)=g(u)(a) Coupled Oscillator Network (CON)
<latexit sha1_base64="X+2HmOZqFnyMvKFaAvTVxq+/r7M=">AAAB83icbVA9TwJBEJ3DL8Qv1NJmI5hgQ+4o0JLERjtMBEngQvaWPdiwt3fZDxNy4W/YWGiMrX/Gzn/jHlyh4EsmeXlvJjPzgoQzpV332ylsbG5t7xR3S3v7B4dH5eOTroqNJLRDYh7LXoAV5UzQjmaa014iKY4CTh+D6U3mPz5RqVgsHvQsoX6Ex4KFjGBtpcGdSIxGVVPTl9VhueLW3QXQOvFyUoEc7WH5azCKiYmo0IRjpfqem2g/xVIzwum8NDCKJphM8Zj2LRU4ospPFzfP0YVVRiiMpS2h0UL9PZHiSKlZFNjOCOuJWvUy8T+vb3R47acse4wKslwUGo50jLIA0IhJSjSfWYKJZPZWRCZYYqJtTCUbgrf68jrpNupes968b1RazTyOIpzBOdTAgytowS20oQMEEniGV3hzjPPivDsfy9aCk8+cwh84nz93HpCh</latexit>Inputu(t)<latexit sha1_base64="TIgizCD7UAMMckdEoZ8vEzorE9M=">AAACFXicbVBNS8NAFNzUrxq/oh69BFuhgpSkh+qxIILHCrYWmlA2m9d26WYTdjdCCf0TXvwrXjwo4lXw5r9x20bQ1oGFYeYNb98ECaNSOc6XUVhZXVvfKG6aW9s7u3vW/kFbxqkg0CIxi0UnwBIY5dBSVDHoJAJwFDC4C0aXU//uHoSkMb9V4wT8CA847VOClZZ61pkXwIDyjABXICbmFSdxCMLzzPKgkp6WTQ94+OP2rJJTdWawl4mbkxLK0exZn14YkzTSccKwlF3XSZSfYaEoYTAxvVRCgskID6CrKccRSD+bXTWxT7QS2v1Y6MeVPVN/JzIcSTmOAj0ZYTWUi95U/M/rpqp/4WeUJ6kCTuaL+imzVWxPK7JDKoAoNtYEE0H1X20yxAIT3YE0dQnu4snLpF2ruvVq/aZWatTzOoroCB2jCnLROWqga9RELUTQA3pCL+jVeDSejTfjfT5aMPLMIfoD4+MbarGeUQ==</latexit>Encoderg(u)<latexit sha1_base64="pPCk1xCV74ZZfOejRORDGrE98sQ=">AAACG3icbVDLSsNAFJ3UV42vqEs3wVaom5J0UV0WdOGygn1AE8pkctsOnUzCzEQoof/hxl9x40IRV4IL/8ZpG0FbDwwczjmXO/cECaNSOc6XUVhb39jcKm6bO7t7+wfW4VFbxqkg0CIxi0U3wBIY5dBSVDHoJgJwFDDoBOOrmd+5ByFpzO/UJAE/wkNOB5RgpaW+VfMCGFKeEeAKxNS8BhKHIDzPLHugcMVTOD0vmx7w8CfTt0pO1ZnDXiVuTkooR7NvfXhhTNJIjxOGpey5TqL8DAtFCYOp6aUSEkzGeAg9TTmOQPrZ/LapfaaV0B7EQj+u7Ln6eyLDkZSTKNDJCKuRXPZm4n9eL1WDSz+jPEkVcLJYNEiZrWJ7VpQdUgFEsYkmmAiq/2qTERaY6A6kqUtwl09eJe1a1a1X67e1UqOe11FEJ+gUVZCLLlAD3aAmaiGCHtATekGvxqPxbLwZ74towchnjtEfGJ/fPWCg4w==</latexit>Decoder⌘(⌧)<latexit sha1_base64="v292+ZRf3H+dMYJq944CTebpP1U=">AAACJ3icbVDLSgMxFM34rOOr6tJNsAq6KTNdVFdScOOyilWhU0omc9sGM5khuSOUoX/jxl9xI6iILv0T04egrQcCh3Pu5eacMJXCoOd9OnPzC4tLy4UVd3VtfWOzuLV9bZJMc2jwRCb6NmQGpFDQQIESblMNLA4l3IR3Z0P/5h60EYm6wn4KrZh1legIztBK7eJpEEJXqJyDQtAD9xJ4ogzqjCNEQeAKlWZI94MewzwbHOLRvhuAin7m28WSV/ZGoLPEn5ASmaDeLr4EUcKz2K5zyYxp+l6KrZxpFFzCwA0yAynjd6wLTUsVi8G08lHOAT2wSkQ7ibZPIR2pvzdyFhvTj0M7GTPsmWlvKP7nNTPsnLTyUVZQfHyok0mKCR2WRiOhgaPsW8K4FvavlPeYZrYkbVxbgj8deZZcV8p+tVy9qJRq1UkdBbJL9sgh8ckxqZFzUicNwskDeSKv5M15dJ6dd+djPDrnTHZ2yB84X98D/KaY</latexit>Reconstructedinput ˆu(t)
<latexit sha1_base64="hlhJtK3Vf0euRghOTNPv8sxZEJs=">AAACH3icbVC7SgNBFJ31GddX1NJmMAhWYTdFtAyksdII5gFJCLOzd5MhszPLzKwSlvyJjb9iY6GI2OVvnDwETbzV4Ty4954g4Uwbz5s4a+sbm1vbuR13d2//4DB/dNzQMlUU6lRyqVoB0cCZgLphhkMrUUDigEMzGFanevMBlGZS3JtRAt2Y9AWLGCXGUr18uRNAn4mMgjCgxm5VpgmHEN9qyjgnRip8A+ZRqqHbARH++Hr5glf0ZoNXgb8ABbSYWi//1QklTWMbp5xo3fa9xHQzogyjHMZuJ9WQEDokfWhbKEgMupvN/hvjc8uEOLK3RFIYPGN/JzISaz2KA+uMiRnoZW1K/qe1UxNddTMmktSAoPNFUcqxkXhaFg6ZAmr4yAJCFbO3YjogilDbgXZtCf7yy6ugUSr65WL5rlSolBd15NApOkMXyEeXqIKuUQ3VEUVP6AW9oXfn2Xl1PpzPuXXNWWRO0J9xJt9sraPQ</latexit>Coupled Oscillator Network<latexit sha1_base64="DpDwYl3l5+4XXS1ZcLGgaeRRKrE=">AAACD3icbVC7TsMwFHV4lvAKMLJEVCCmKulQGCuxwFYk+pCaqHKcm9Sq40S2g1RF/QMWfoWFAYRYWdn4G9w2SNByJMtH59wj+54gY1Qqx/kyVlbX1jc2K1vm9s7u3r51cNiRaS4ItEnKUtELsARGObQVVQx6mQCcBAy6wehq6nfvQUia8js1zsBPcMxpRAlWWhpYZ14AMeUFAa5ATMwbfcUCq1SYHvDwRx9YVafmzGAvE7ckVVSiNbA+vTAleaLjhGEp+66TKb/AQlHCYGJ6uYQMkxGOoa8pxwlIv5jtM7FPtRLaUSr04cqeqb8TBU6kHCeBnkywGspFbyr+5/VzFV36BeVZroCT+UNRzmyV2tNy7JAKIIqNNcFEUP1XmwyxwER3IE1dgru48jLp1Gtuo9a4rVebjbKOCjpGJ+gcuegCNdE1aqE2IugBPaEX9Go8Gs/Gm/E+H10xyswR+gPj4xv8s509</latexit>Integrator
<latexit sha1_base64="HWYsgoesXTJ1X8ln8clyHTgRh/0=">AAAB7XicbVDLSgNBEOyNrxhfUY9eFoMQL2FXJHoMePEYwTwgWcLsZDYZMzuzzPQKMeQfvHhQxKv/482/cZLsQRMLGoqqbrq7wkRwg5737eTW1jc2t/LbhZ3dvf2D4uFR06hUU9agSijdDolhgkvWQI6CtRPNSBwK1gpHNzO/9ci04Ure4zhhQUwGkkecErRS86mMPe+8Vyx5FW8Od5X4GSlBhnqv+NXtK5rGTCIVxJiO7yUYTIhGTgWbFrqpYQmhIzJgHUsliZkJJvNrp+6ZVfpupLQtie5c/T0xIbEx4zi0nTHBoVn2ZuJ/XifF6DqYcJmkyCRdLIpS4aJyZ6+7fa4ZRTG2hFDN7a0uHRJNKNqACjYEf/nlVdK8qPjVSvXuslSrZnHk4QROoQw+XEENbqEODaDwAM/wCm+Ocl6cd+dj0Zpzsplj+APn8weqiI6D</latexit>z(t0)
<latexit sha1_base64="yBf9sgifhlaXZuXwj7eKcDq8mQQ=">AAAB63icbVBNS8NAEJ3Ur1q/qh69LBbBU0lEqseCF48V7Ae0oWy2m3bpbhJ2J0IJ/QtePCji1T/kzX/jps1BWx8MPN6bYWZekEhh0HW/ndLG5tb2Tnm3srd/cHhUPT7pmDjVjLdZLGPdC6jhUkS8jQIl7yWaUxVI3g2md7nffeLaiDh6xFnCfUXHkQgFo5hLA6TpsFpz6+4CZJ14BalBgdaw+jUYxSxVPEImqTF9z03Qz6hGwSSfVwap4QllUzrmfUsjqrjxs8Wtc3JhlREJY20rQrJQf09kVBkzU4HtVBQnZtXLxf+8forhrZ+JKEmRR2y5KEwlwZjkj5OR0JyhnFlCmRb2VsImVFOGNp6KDcFbfXmddK7qXqPeeLiuNRtFHGU4g3O4BA9uoAn30II2MJjAM7zCm6OcF+fd+Vi2lpxi5hT+wPn8ASEjjkc=</latexit>⌧
<latexit sha1_base64="tK321McjNpX905VSJeWeFsGFQHo=">AAAB7nicbVBNS8NAEJ3Ur1q/qh69LBahXkoiUj0WvHisYD+gDWWz3bRLN5uwOxFK6I/w4kERr/4eb/4bt20O2vpg4PHeDDPzgkQKg6777RQ2Nre2d4q7pb39g8Oj8vFJ28SpZrzFYhnrbkANl0LxFgqUvJtoTqNA8k4wuZv7nSeujYjVI04T7kd0pEQoGEUrdfpI0ypeDsoVt+YuQNaJl5MK5GgOyl/9YczSiCtkkhrT89wE/YxqFEzyWamfGp5QNqEj3rNU0YgbP1ucOyMXVhmSMNa2FJKF+nsio5Ex0yiwnRHFsVn15uJ/Xi/F8NbPhEpS5IotF4WpJBiT+e9kKDRnKKeWUKaFvZWwMdWUoU2oZEPwVl9eJ+2rmlev1R+uK416HkcRzuAcquDBDTTgHprQAgYTeIZXeHMS58V5dz6WrQUnnzmFP3A+fwDAQI8q</latexit>⌧(t)<latexit sha1_base64="NHsMrmvDHn1mjZPjNKRJltKM25Y=">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0lEWo8FLx4r2g9oQ9lsN+3SzSbsToQS+hO8eFDEq7/Im//GbZuDtj4YeLw3w8y8IJHCoOt+O4WNza3tneJuaW//4PCofHzSNnGqGW+xWMa6G1DDpVC8hQIl7yaa0yiQvBNMbud+54lrI2L1iNOE+xEdKREKRtFKDzhwB+WKW3UXIOvEy0kFcjQH5a/+MGZpxBUySY3peW6CfkY1Cib5rNRPDU8om9AR71mqaMSNny1OnZELqwxJGGtbCslC/T2R0ciYaRTYzoji2Kx6c/E/r5dieONnQiUpcsWWi8JUEozJ/G8yFJozlFNLKNPC3krYmGrK0KZTsiF4qy+vk/ZV1atVa/fXlUYtj6MIZ3AOl+BBHRpwB01oAYMRPMMrvDnSeXHenY9la8HJZ07hD5zPHwQKjZo=</latexit>t0
<latexit sha1_base64="NHsMrmvDHn1mjZPjNKRJltKM25Y=">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0lEWo8FLx4r2g9oQ9lsN+3SzSbsToQS+hO8eFDEq7/Im//GbZuDtj4YeLw3w8y8IJHCoOt+O4WNza3tneJuaW//4PCofHzSNnGqGW+xWMa6G1DDpVC8hQIl7yaa0yiQvBNMbud+54lrI2L1iNOE+xEdKREKRtFKDzhwB+WKW3UXIOvEy0kFcjQH5a/+MGZpxBUySY3peW6CfkY1Cib5rNRPDU8om9AR71mqaMSNny1OnZELqwxJGGtbCslC/T2R0ciYaRTYzoji2Kx6c/E/r5dieONnQiUpcsWWi8JUEozJ/G8yFJozlFNLKNPC3krYmGrK0KZTsiF4qy+vk/ZV1atVa/fXlUYtj6MIZ3AOl+BBHRpwB01oAYMRPMMrvDnSeXHenY9la8HJZ07hD5zPHwQKjZo=</latexit>t0<latexit sha1_base64="Vcku6nvsUOem31YbJRkplz3lufs=">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0lEWo8FLx4r2g9oQ9lsN+3SzSbsToQS+hO8eFDEq7/Im//GbZuDtj4YeLw3w8y8IJHCoOt+O4WNza3tneJuaW//4PCofHzSNnGqGW+xWMa6G1DDpVC8hQIl7yaa0yiQvBNMbud+54lrI2L1iNOE+xEdKREKRtFKDzjwBuWKW3UXIOvEy0kFcjQH5a/+MGZpxBUySY3peW6CfkY1Cib5rNRPDU8om9AR71mqaMSNny1OnZELqwxJGGtbCslC/T2R0ciYaRTYzoji2Kx6c/E/r5dieONnQiUpcsWWi8JUEozJ/G8yFJozlFNLKNPC3krYmGrK0KZTsiF4qy+vk/ZV1atVa/fXlUYtj6MIZ3AOl+BBHRpwB01oAYMRPMMrvDnSeXHenY9la8HJZ07hD5zPHwWOjZs=</latexit>t1
<latexit sha1_base64="tERXxmCn8TrPcJWaLsIUx6uI5Rs=">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0lEWo8FLx4r2g9oQ9lsN+3SzSbsToQS+hO8eFDEq7/Im//GbZuDtj4YeLw3w8y8IJHCoOt+O4WNza3tneJuaW//4PCofHzSNnGqGW+xWMa6G1DDpVC8hQIl7yaa0yiQvBNMbud+54lrI2L1iNOE+xEdKREKRtFKDziYDMoVt+ouQNaJl5MK5GgOyl/9YczSiCtkkhrT89wE/YxqFEzyWamfGp5QNqEj3rNU0YgbP1ucOiMXVhmSMNa2FJKF+nsio5Ex0yiwnRHFsVn15uJ/Xi/F8MbPhEpS5IotF4WpJBiT+d9kKDRnKKeWUKaFvZWwMdWUoU2nZEPwVl9eJ+2rqler1u6vK41aHkcRzuAcLsGDOjTgDprQAgYjeIZXeHOk8+K8Ox/L1oKTz5zCHzifP112jdU=</latexit>tk
<latexit sha1_base64="rVAdKM6avlsDJ1HSbj9MGrqNuSE=">AAAB83icbVDLSgMxFL3js9ZX1aWbYBHqpsyIVJcFNy4r2Ad0hpJJ0zY0kxmSO2IZ+htuXCji1p9x59+YtrPQ1gOBwzn3cG9OmEhh0HW/nbX1jc2t7cJOcXdv/+CwdHTcMnGqGW+yWMa6E1LDpVC8iQIl7ySa0yiUvB2Ob2d++5FrI2L1gJOEBxEdKjEQjKKVfL8fY+Y/iWkFL3qlslt15yCrxMtJGXI0eqUvG2dpxBUySY3pem6CQUY1Cib5tOinhieUjemQdy1VNOImyOY3T8m5VfpkEGv7FJK5+juR0ciYSRTayYjiyCx7M/E/r5vi4CbIhEpS5IotFg1SSTAmswJIX2jOUE4soUwLeythI6opQ1tT0ZbgLX95lbQuq16tWru/KtdreR0FOIUzqIAH11CHO2hAExgk8Ayv8Oakzovz7nwsRtecPHMCf+B8/gDgFJGO</latexit>˙⇠(t)<latexit sha1_base64="E8ce3863uvsirNizL2qRvXewMy4=">AAAB7XicbVDLSgNBEOyNrxhfUY9eFoMQL2FXJHoMePEYwTwgWcLsZDYZMzuzzPQKMeQfvHhQxKv/482/cZLsQRMLGoqqbrq7wkRwg5737eTW1jc2t/LbhZ3dvf2D4uFR06hUU9agSijdDolhgkvWQI6CtRPNSBwK1gpHNzO/9ci04Ure4zhhQUwGkkecErRS86mMPf+8Vyx5FW8Od5X4GSlBhnqv+NXtK5rGTCIVxJiO7yUYTIhGTgWbFrqpYQmhIzJgHUsliZkJJvNrp+6ZVfpupLQtie5c/T0xIbEx4zi0nTHBoVn2ZuJ/XifF6DqYcJmkyCRdLIpS4aJyZ6+7fa4ZRTG2hFDN7a0uHRJNKNqACjYEf/nlVdK8qPjVSvXuslSrZnHk4QROoQw+XEENbqEODaDwAM/wCm+Ocl6cd+dj0Zpzsplj+APn8wesDY6E</latexit>z(t1)
<latexit sha1_base64="IZx22dOcqaCE+C9RPgiwoLBzfBs=">AAAB7XicbVDLSgNBEOyNrxhfUY9eFoMQL2FXJHoMePEYwTwgWcLsZDYZMzuzzPQKMeQfvHhQxKv/482/cZLsQRMLGoqqbrq7wkRwg5737eTW1jc2t/LbhZ3dvf2D4uFR06hUU9agSijdDolhgkvWQI6CtRPNSBwK1gpHNzO/9ci04Ure4zhhQUwGkkecErRS86mMvdF5r1jyKt4c7irxM1KCDPVe8avbVzSNmUQqiDEd30swmBCNnAo2LXRTwxJCR2TAOpZKEjMTTObXTt0zq/TdSGlbEt25+ntiQmJjxnFoO2OCQ7PszcT/vE6K0XUw4TJJkUm6WBSlwkXlzl53+1wzimJsCaGa21tdOiSaULQBFWwI/vLLq6R5UfGrlerdZalWzeLIwwmcQhl8uIIa3EIdGkDhAZ7hFd4c5bw4787HojXnZDPH8AfO5w8EPo6+</latexit>z(tk)<latexit sha1_base64="gD6ORxOA6TmVbR/nCj9WeQ/PBgI=">AAAB7HicbVBNS8NAFHypX7V+VT16WSyCp5KIVI8FLx4rmLbQhrLZbtqlm03YfRFK6G/w4kERr/4gb/4bt20O2jqwMMy8Yd+bMJXCoOt+O6WNza3tnfJuZW//4PCoenzSNkmmGfdZIhPdDanhUijuo0DJu6nmNA4l74STu7nfeeLaiEQ94jTlQUxHSkSCUbSS3x8maAbVmlt3FyDrxCtIDQq0BtUvm2NZzBUySY3peW6KQU41Cib5rNLPDE8pm9AR71mqaMxNkC+WnZELqwxJlGj7FJKF+juR09iYaRzayZji2Kx6c/E/r5dhdBvkQqUZcsWWH0WZJJiQ+eVkKDRnKKeWUKaF3ZWwMdWUoe2nYkvwVk9eJ+2ruteoNx6ua81GUUcZzuAcLsGDG2jCPbTABwYCnuEV3hzlvDjvzsdytOQUmVP4A+fzB/FejsE=</latexit>...
<latexit sha1_base64="gD6ORxOA6TmVbR/nCj9WeQ/PBgI=">AAAB7HicbVBNS8NAFHypX7V+VT16WSyCp5KIVI8FLx4rmLbQhrLZbtqlm03YfRFK6G/w4kERr/4gb/4bt20O2jqwMMy8Yd+bMJXCoOt+O6WNza3tnfJuZW//4PCoenzSNkmmGfdZIhPdDanhUijuo0DJu6nmNA4l74STu7nfeeLaiEQ94jTlQUxHSkSCUbSS3x8maAbVmlt3FyDrxCtIDQq0BtUvm2NZzBUySY3peW6KQU41Cib5rNLPDE8pm9AR71mqaMxNkC+WnZELqwxJlGj7FJKF+juR09iYaRzayZji2Kx6c/E/r5dhdBvkQqUZcsWWH0WZJJiQ+eVkKDRnKKeWUKaF3ZWwMdWUoe2nYkvwVk9eJ+2ruteoNx6ua81GUUcZzuAcLsGDG2jCPbTABwYCnuEV3hzlvDjvzsdytOQUmVP4A+fzB/FejsE=</latexit>...
<latexit sha1_base64="+fnOs4XfnSUS/Elg7OZWeHIV83A=">AAACJXicbVDLSgMxFM3UVx1fVZduBluhbspMF9WFi4Ib3VWwD+iUkklv29BMMiSZQhn6M278FTcuLCK48ldMpxW09UDg5NxzuNwTRIwq7bqfVmZjc2t7J7tr7+0fHB7ljk8aSsSSQJ0IJmQrwAoY5VDXVDNoRRJwGDBoBqPb+bw5Bqmo4I96EkEnxANO+5RgbaRu7sYPYEB5QoBrkFP7nlNNMfN9WwQK5Di1mV9BFHXXvSzYPvDej7uby7slN4WzTrwlyaMlat3czO8JEocmThhWqu25ke4kWGpKGExtP1YQYTLCA2gbynEIqpOkV06dC6P0nL6Q5nHtpOrvRIJDpSZhYJwh1kO1OpuL/83ase5fdxLKo1gDJ4tF/Zg5WjjzypwelUA0mxiCiTT9EIcMscTEdKBsU4K3evI6aZRLXqVUeSjnq5VlHVl0hs5REXnoClXRHaqhOiLoCb2gNzSznq1X6936WFgz1jJziv7A+voGK0Ck/w==</latexit>Initialobservationo(t0)<latexit sha1_base64="sya9dvMJ4vOQeragLAUsL86U8nY=">AAACHXicbVDLSsNAFJ34rPEVdekmWARXJSlSXRbcuKxgH9CEMpnctEMnkzAzKZTQH3Hjr7hxoYgLN+LfOE0jaOuBgcM553LnniBlVCrH+TLW1jc2t7YrO+bu3v7BoXV03JFJJgi0ScIS0QuwBEY5tBVVDHqpABwHDLrB+GbudycgJE34vZqm4Md4yGlECVZaGliXXgBDynMCXIGYmS0BISUKQs8zk0CCmBRBaXrAw5/UwKo6NaeAvUrcklRRidbA+vDChGSxHicMS9l3nVT5ORaKEgYz08skpJiM8RD6mnIcg/Tz4rqZfa6V0I4SoR9XdqH+nshxLOU0DnQyxmokl725+J/Xz1R07eeUp5kCThaLoozZKrHnVdkhFUAUm2qCiaD6rzYZYYF1PUKaugR3+eRV0qnX3EatcVevNhtlHRV0is7QBXLRFWqiW9RCbUTQA3pCL+jVeDSejTfjfRFdM8qZE/QHxuc3Dn2jHw==</latexit>Predictedobservations<latexit sha1_base64="+4/wKfTrP1S5OpNbG0ooKQTKKkw=">AAAB83icbVBNS8NAEJ3Ur1q/qh69LBahXkoiUj0WvHisYD+gCWWz3bZLN5uwOxFK6N/w4kERr/4Zb/4bt20O2vpg4PHeDDPzwkQKg6777RQ2Nre2d4q7pb39g8Oj8vFJ28SpZrzFYhnrbkgNl0LxFgqUvJtoTqNQ8k44uZv7nSeujYjVI04THkR0pMRQMIpW8v0xxSyeVbHvXfbLFbfmLkDWiZeTCuRo9stf/iBmacQVMkmN6XlugkFGNQom+azkp4YnlE3oiPcsVTTiJsgWN8/IhVUGZBhrWwrJQv09kdHImGkU2s6I4tisenPxP6+X4vA2yIRKUuSKLRcNU0kwJvMAyEBozlBOLaFMC3srYWOqKUMbU8mG4K2+vE7aVzWvXqs/XFca9TyOIpzBOVTBgxtowD00oQUMEniGV3hzUufFeXc+lq0FJ585hT9wPn8AcjWRRg==</latexit>ˆo(t1)
<latexit sha1_base64="jQfpIVWJkKJNcqEwQBpSeYjgKm4=">AAAB83icbVBNS8NAEJ3Ur1q/qh69LBahXkoiUj0WvHisYD+gCWWz3bZLN5uwOxFK6N/w4kERr/4Zb/4bt20O2vpg4PHeDDPzwkQKg6777RQ2Nre2d4q7pb39g8Oj8vFJ28SpZrzFYhnrbkgNl0LxFgqUvJtoTqNQ8k44uZv7nSeujYjVI04THkR0pMRQMIpW8v0xxSyeVbE/ueyXK27NXYCsEy8nFcjR7Je//EHM0ogrZJIa0/PcBIOMahRM8lnJTw1PKJvQEe9ZqmjETZAtbp6RC6sMyDDWthSShfp7IqORMdMotJ0RxbFZ9ebif14vxeFtkAmVpMgVWy4appJgTOYBkIHQnKGcWkKZFvZWwsZUU4Y2ppINwVt9eZ20r2pevVZ/uK406nkcRTiDc6iCBzfQgHtoQgsYJPAMr/DmpM6L8+58LFsLTj5zCn/gfP4AyleRgA==</latexit>ˆo(tk)
<latexit sha1_base64="8ucjkMdk81R0AiPJ1q4/4HiM9KU=">AAACGHicbVDLSgMxFM3UVx1foy7dDLZC3dSZLqrLggguK9gHdErJZG7b0EwyJBmhDP0MN/6KGxeKuO3OvzF9CFo9EDiccy4394QJo0p73qeVW1vf2NzKb9s7u3v7B87hUVOJVBJoEMGEbIdYAaMcGppqBu1EAo5DBq1wdD3zWw8gFRX8Xo8T6MZ4wGmfEqyN1HMughAGlGcEuAY5sW84ERHIILCLQX1IS+K8aAfAo+9Azyl4ZW8O9y/xl6SAlqj3nGkQCZLGZpwwrFTH9xLdzbDUlDCY2EGqIMFkhAfQMZTjGFQ3mx82cc+MErl9Ic3j2p2rPycyHCs1jkOTjLEeqlVvJv7ndVLdv+pmlCepBk4Wi/opc7VwZy25EZVANBsbgomk5q8uGWKJielA2aYEf/Xkv6RZKfvVcvWuUqhVl3Xk0Qk6RSXko0tUQ7eojhqIoEf0jF7Rm/VkvVjv1scimrOWM8foF6zpF6f2n38=</latexit>Encoder (o)<latexit sha1_base64="Rs4vVJGf/Y0hNKScvfA2l1zAVZ4=">AAACGHicbVDLSsNAFJ3UV42vqEs3wVaom5p0UV0WdOGygn1AE8pkctsOnUzCzESooZ/hxl9x40IRt935N04fgrYeGDiccy537gkSRqVynC8jt7a+sbmV3zZ3dvf2D6zDo6aMU0GgQWIWi3aAJTDKoaGoYtBOBOAoYNAKhtdTv/UAQtKY36tRAn6E+5z2KMFKS13rwgugT3lGgCsQY/MGSByC8Dyz6NUlLT2eF00PePgT6FoFp+zMYK8Sd0EKaIF615p4YUzSSI8ThqXsuE6i/AwLRQmDsemlEhJMhrgPHU05jkD62eywsX2mldDuxUI/ruyZ+nsiw5GUoyjQyQirgVz2puJ/XidVvSs/ozxJFXAyX9RLma1ie9qSHVIBRLGRJpgIqv9qkwEWmOgOpKlLcJdPXiXNStmtlqt3lUKtuqgjj07QKSohF12iGrpFddRABD2hF/SG3o1n49X4MD7n0ZyxmDlGf2BMvgG6ZJ+L</latexit>Decoder (z) (b) Learning latent-space dynamics with CON
Figure 1: Panel (a) : The proposed CON network consists of ndamped harmonic oscillators that are coupled
through the neuron-like connection tanh( Wx+b)and the non-diagonal stiffness K−kand damping coefficients
D−d, respectively. The state of the network is captured by the positions x(t)and velocities ˙x(t)of the oscillators.
The time-dependent input is mapped through the (possibly nonlinear) function g(u)to a forcing τacting on the
oscillators. Panel (b): Exploiting Coupled Oscillator Networks (CONs) for learning latent dynamics from pixels:
We encode the initial observation o(t0)and the input u(t)into latent space where we leverage the Coupled
Oscillator Network (CON) to predict future latent states. Finally, we decode both the latent-space torques τ(t)
and the predicted latent states z(t).
shortcomings, such as a limited planning horizon and slow control rates (MPC and gradient-based
approaches), sample inefficiency (RL), or they pose a requirement for learning linear dynamics [ 6]
(LQR), which is not even possible for systems that are inherently non-linearizable [ 22]. One
interesting avenue is to leverage model-based control approaches, such as potential shaping [23, 24,
10], for effective and computationally efficient control in latent space [ 25]. For these techniques to be
feasible, the dynamical model needs to fulfill four characteristics: (i) the dynamics need to have the
mathematical structure of physical systems, (ii) conserve the stability properties of real systems, (iii)
the latent state needs to be relatively low-dimensional, and (iv) there needs to exist a well-defined,
invertible mapping between the input and the forcing in latent space. However, existing model
structures that are used for learning latent dynamics [ 26] do not meet all of these criteria. Relevant
examples are Multilayer Perceptrons (MLPs), Neural ODEs (NODEs) [ 27,28], many variants
of Recurrent Neural Networks (RNNs) (e.g., LSTMs [ 29], Gated Recurrent Units (GRUs) [ 30],
etc.), and physics-informed neural networks (e.g., Lagrangian Neural Networks (LNNs) [ 31,32,10],
Hamiltonian Neural Networks (HNNs)) [ 33]. For example, MLPs do not have a physical interpretation
and do not provide an invertible mapping of the forcing generated by the input, NODEs are usually
not easily stabilizable [ 34], most RNNs require a relatively high-dimensional latent space (i.e., many
hidden states), and energy-shaping control approaches based on LNNs [ 10] do not come with any
formal stability guarantees.
In recent years, oscillatory networks [35, 36, 37, 38, 39] have been shown to exhibit state-of-the-art
performance on time sequence modeling tasks while being parameter-efficient, thus fulfilling our
requirement (iii). Consequently, we believe that they are a promising option for control-oriented
dynamics learning in latent space. Still, these models do not fulfill the remaining requirements that
we have listed above. Despite being an interpretable combination of harmonic oscillators, they do
not have the structure of a physical system - i.e., they do not possess a well-defined energy function.
Moreover, only local stability [ 35,37] has been shown, with sufficient conditions that appear to be
very stringent. Finally, in addition to training an encoder that maps inputs to latent-space forcing, we
propose also training a decoder that learns to reconstruct inputs based on latent-space forcing. This
enables us to easily switch between inputs and forcing, which is essential when implementing control
strategies.
We resolve all the above-mentioned challenges by proposing Coupled Oscillator Networks (CONs),
a new formulation of a coupled oscillator network that is inherently Input-to-State Stability (ISS)
stable, for learning the dynamics of physical systems and subsequently exploiting its structure for
model-based control in latent space. The network consists of damped, harmonic oscillators connected
through elastic springs, damping elements, and a neuron-like coupling force and can be excited by a
nonlinear actuation term. We identify a transformation into a set of coordinates from which we can
derive the networks’ kinetic and potential energy. This allows us to leverage Lyapunov arguments [ 40]
for proving the global asymptotic stability of the unforced system and ISS stability for the forced
system under relatively mild assumptions on the network parameters. Even though we constrain
the dynamics to a very specific structure, we demonstrate (a) the CON network achieves similar
performance as NODEs when learning the dynamics of unactuated, mechanical systems with two
2orders of magnitude fewer parameters and (b) that the proposed model achieves, for the complex
task of learning the actuated, highly nonlinear dynamics of continuum soft robots [ 41,42] directly
from pixels, a 60 % lower prediction error than Coupled Oscillatory Recurrent Neural Network
(coRNN) [ 35] and reaches the SoA performance across all techniques that we tested. Finally, we
show some initial results that the proposed CON model is also able to learn the latent dynamics of
Partial Differential Equations (PDEs), in this case containing reaction-diffusion [9, 43] dynamics.
Subsequently, we derive an approximate closed-form solution, that is, in parameter regimes in which
the linear, decoupled dynamics dominate transient, more accurate than numerical integrators with
comparable computational requirements and which increases training speed by 2x with a small
decrease in prediction accuracy. Finally, as we can derive the system’s potential energy, we can
leverage potential shaping [ 23,24] to derive a controller that combines an integral-saturated PID
controller with a feedforward term compensating potential forces. As the feedback acts on a well-
shaped potential field, tuning the feedback gains becomes very simple and out-of-the-box, and the
controller exhibits a faster response time and a 26 % lower trajectory tracking Root Mean Squared
Error (RMSE) than a pure feedback controller based on a latent NODE [27] model.
The proposed methodology is particularly well-suited for learning the latent dynamics of mechanical
systems with continuous dynamics, dissipation, and a single, attractive equilibrium point. Examples of
such systems include many soft robots, deformable objects with dominant elastic behavior, Lagrangian
systems immersed in a dominant potential field, or locally other mechanical systems such as robotic
manipulators, legged robots, etc. For these systems, we can fully leverage the structural prior of the
proposed latent dynamics, including the integrated stability guarantees. If the system is actuated, the
learned dynamics can be subsequently exploited for model-based control, as demonstrated in Sec. 5.
The code associated with this paper is available on GitHub1.
2 Input-to-State Stable (ISS) Coupled Oscillator Networks (CONs)
Formulation. The integral component to (coupled) oscillatory RNNs [ 35,36,37,38] are one-
dimensional, potentially damped, harmonic oscillators, which are described by their state yi=
[xi˙xi]T∈R2, where xiand˙xiare the position and velocity of the oscillator, respectively. Then,
the oscillator’s dynamics are defined by the following Equation of Motion (EOM)
mi¨xi(t) +di˙xi(t) +κixi(t) =Fi(t), withmi, κi, di∈R+. (1)
Here, miis the mass, κiis the stiffness, and diis the damping coefficient of the damped harmonic
oscillator. Fi(t)∈Ris a (possibly time-dependent) external forcing term acting on the mass.
Even though the state is extremely low dimensional and the number of parameters is small, this single,
damped harmonic oscillator can already exhibit a variety of (designable) behaviors: The expressions
ωn,i=q
κi
miandζi=di
2√κimilet us determine the natural frequency and the damping factor,
respectively and allow us to design the transient behavior. For example, ωn,ilets us isolate a spectrum
of the input signal Fi(t)[37] and ζidetermines the damping regime: underdamped ( ωn,i<1),
critically damped ( ωn,i= 1), overdamped ( ωn,i>1). Furthermore, as (damped) harmonic oscillators
are omnipresent in nature (and especially in physical systems), they have been intensively studied and
are well understood (e.g., characteristics, closed-form solutions, etc.). In this work, we will exploit
some of these properties and knowledge to learn stable (latent) dynamics efficiently.
By intercoupling damped harmonic oscillators, we can drastically increase the expressiveness of the
dynamical system [ 35,37,38] while preserving some of the intuition and understanding we have
for these systems. In this work, we propose a ISS-stable CON consisting of ndamped harmonic
oscillators that are coupled through both linear and nonlinear terms. The networks’ state is defined
asy=
xT˙xTT∈R2nand its dynamics can be formulated as a 2nd-order Ordinary Differential
Equation (ODE)
˙y(t) =dx
dtd ˙x
dt
=f(y(t), u(t)) =
˙x(t)
g(u(t))−Kx(t)−D˙x(t)−tanh( W x(t) +b)
, (2)
where K, D∈Rn×nare the linear stiffness and damping matrices, respectively. The neuron-inspired term
tanh( W x(t) +b)withW∈Rn×n,b∈Rnprovides nonlinear coupling between the harmonic oscillators.
The network is excited by the time-dependent input u(t)∈Rmthrough the possibly nonlinear mapping
g:Rm→Rn. Specifically, we consider in this work a formulation where an input-dependent matrix
1https://github.com/tud-phi/uncovering-iss-coupled-oscillator-networks-from-pixels
3B(u)∈Rn×mprojects the input u(t)to a time-dependent forcing on the oscillators: τ=g(u) =B(u)u.
HereB(u)could, for example, be parametrized by a MLP.
We specifically designed the network architecture such that (i) the system exhibits a unique and isolated
equilibrium and (ii) we can derive expressions for the kinetic and potential energies. These two features allow us
to (a) prove Global Asymptotic Stability (GAS) and ISS stability using an established procedure based on strict
Lyapunov arguments [44, 45], and (b) implement model-based controller based on potential shaping.
One key insight of this work is that in the coordinates x(t),˙x(t), we cannot derive a potential as the hyperbolic
force tanh( Wx(t)+b)is not symmetric. Therefore, we propose a coordinate transformation into W-coordinates:
yw(t) =
xw(t)
˙xw(t)
=
W x(t)
W˙x(t)
∈R2n. The coordinate transformation is valid if its Jacobian is full-rank, which
is the case if rank( W) =n. InW-coordinates, the dynamics can be rewritten as
˙yw(t) =dxw
dtd ˙xw
dt
=fw(y(t), u(t)) =˙xw(t)
M−1
w(g(u(t))−Kwxw(t)−Dw˙xw(t)−tanh( xw(t) +b))
(3)
withKw=K W ,Dw=D W andMw=W−1.
A difference of this formulation compared to prior work [ 35,36,37,38] is that (i) the forcing produced by the
input term τ=g(u)is fully separated from the forcing produced by the elastic coupling terms Kw, and (ii)
the generalized force is symmetric, which we prove in Appendix A.1, allowing us to define a potential energy
expression, which we can later on leverage for stability analysis and control.
The equilibria ¯yw=
¯xT
w0TT∈R2nof the unforced network are given by the roots of the characteristic
equation tanh(¯ xw+b) +Kw¯xw= 0.
Lemma 1. LetKw≻0. Then, the dynamics defined in (3)have a single, isolated equilibrium ¯yw=
¯xT
w0TT.
Proof. The proof is straightforward and provided in Appendix A.2.
Next, we introduce a mapping into the ˜tilde coordinates ˜yw=yw−¯yw. The residual dynamics (w.r.t. the
equilibrium ¯yw) can now be stated as
˙˜yw(t) =˜fw(y, u) =˙˜xw(t)
M−1
w 
g(u(t))−Kw(¯xw+ ˜xw(t))−Dw˙˜xw(t)−tanh(¯ xw+ ˜xw(t) +b)
(4)
In the following, we will write ∥A∥to denote the induced norm of matrix Aandλm(A),λM(A)to refer to its
minimum and maximum Eigenvalue respectively.
Global Asymptotic Stability (GAS) for the unforced system. We first consider the unforced system
withτ=g(u) = 0 ,∀t∈[t0, t∞)and strive to prove global asymptotic stability [ 40] for the attractor ¯x. We
propose a strict Lyapunov candidate with skewed level sets [45]
Vµ(˜yw) =1
2˜yT
wPV˜yw+nX
i=1Z˜xw,i
0tanh(¯ xw,i+σ+bi) dσ−nX
i=1Z˜xw,i
0tanh(¯ xw,i+bi) dσ,
=1
2˜yT
wPV˜yw+nX
i=1(lcosh(¯ xw,i+ ˜xw,i+bi)−lcosh(¯ xw,i+bi)−tanh(¯ xw,i+bi) ˜xw,i),
withPV=Kw µ M w
µ MT
w Mw
∈R2n×2n, lcosh(·) = log(cosh( ·)), andµ >0.(5)
Lemma 2. The scalar function Vµ(˜yw)defined in (5)is continuously differentiable and verifies the condition
Vµ(0) = 0 . Furthermore, let Mw, Kw≻0. Now, if we choose 0< µ <√
λm(Mw)λm(Kw)
∥Mw∥:=µV, then
Vµ(˜yw)>0∀˜yw∈R2n\{0}. Additionally, then Vµ(˜yw)is radially unbounded as ∥˜yw∥ → ∞ ⇒ Vµ(˜yw)→
∞.
Proof. We provide the proof in Appendix A.3 and demonstrate that the bounds on µare required for the
Lyapunov candidate to be positive-definite.
Theorem 1. LetMw, KwandDwbe positive definite and suppose the system be unforced: g(u(t)) = 0 . Then,
˜yw= 0is globally asymptotically stable for the system dynamics defined (4)such that ˙Vµ(˜yw)<0,∀˜yw∈
R2n\ {0}.
4Proof. First, we show that ˜yw= 0is an equilibrium of (4):
˜fw(0,0) =0
M−1
w(−Kw¯xw−tanh(¯ xw+b))
=0
M−1
w(−Kw¯xw+Kw¯xw)
=
0
0
(6)
Lemma 2 states that we can always choose µsuch that (5)is strict Lyapunov function (e.g., Lipschitz continuous,
zero-valued at ˜yw= 0, positive definite, and radially unbounded) [ 40,45]. We now evaluate the time-derivative
of˙Vµ(˜yw)in the case of an unforced system (i.e., g(u(t)) = 0 ):
˙Vµ(˜yw) =∂Vµ
∂˜yw˙˜yw=∂Vµ
∂˜yw˜fw(˜yw) = ˜yT
wPV˙˜yw+ (tanh(¯ xw+ ˜xw+b)−tanh(¯ xw+b))T˙˜xw
=−˜yT
wµ Kw1
2µ Dw
1
2µ DT
wDw−µ M w
| {z }
P˙V˜yw−µ
tanh(¯ xw+ ˜xw+b)T+ ˜xT
wKw
˜xw,
=−˜yT
wP˙V˜yw−µ(tanh(¯ xw+ ˜xw+b)−tanh(¯ xw+b))T˜xw,
≤ − ˜yT
wP˙V˜yw≤ −λm(P˙V)∥˜yw∥2
2,(7)
where we exploited the force balance at equilibrium Kw¯xw=−tanh(¯ xw+b)and Lemma 7 for defining
the upper bound on ˙Vµ(˜yw). Lemma 8 states that P˙V≻0for0< µ < µ ˙V. Similarly, Lemma 2 requests
that0< µ < µ V. Indeed, both conditions can always be fulfilled by choosing µ∈(0,min{µV, µ˙V}). With
P˙V≻0⇔λm(P˙V)>0[46], we can state that ˙Vµ(˜yw)<0∀˜yw∈R2n\ {0}and conclude that the unforced
system is globally asymptotically stable around ˜yw= 0.
Global Input-to-State Stability (ISS) for the forced system. We now take the forcing g(u)into
account again and demonstrate that the system states remain proportionally bounded to the initial conditions and
as a function of the supremum of the input forcing.
Theorem 2. Suppose Mw, Kw, Dw≻0,0< θ < 1, and that we choose 0< µ < min{µV, µ˙V}}. Then, (4)
is globally Input-to-State Stable (ISS) such that the solution ˜yw(t)verifies
∥˜yw∥2≤β(∥˜yw(t0)∥2, t−t0) +γ 
sup
t0≤t′≤t∥g(u(t′))∥2!
,∀t≥t0 (8)
where β(r, t)∈ KL ,γ(r) =r
(1+µ2)λM(PV)r2+4θ√n√
1+µ2λm(P˙V)r
θ2λm(PV)λ2m(P˙V)∈ K.
Proof. The proof is provided in Appendix A.5. We first demonstrate that the ISS-Lyapunov function is bounded
from both sides by K∞functions. Subsequently, we derive the energy dissipation of the forced system and
establish attracting regions as a function of the norm of the forcing. Outside these regions, it is ensured that the
system has a minimal rate of decay and, therefore, converges exponentially fast into the attracting region.
0 10 20 30 40
Time [s]−0.75−0.50−0.250.000.250.500.751.00Position [m]
CON ground-truth
CON Euler δt= 0.05s
CFA-CON δt= 0.1s
(a) Positions
0 10 20 30 40
Time [s]−0.4−0.20.00.20.4Velocity [m/s]
CON Tsit5 δt= 5e−05s
CON Euler δt= 0.05s
CFA-CON δt= 0.1s (b) Velocities
Figure 2: Analysis of approximation error of CFA-CON: we compare the ground-truth solution of a 40 srollout
of the CON network consisting of three oscillators ( n= 3) with the CFA-CON executed at a time step of
δt= 0.1 sand a solution generated by integrating the ODE at a time step of δt= 0.05 swith the Euler method.
53 An approximate closed-form solution for the rollout of CON
To predict future system states, we need to integrate the ODE in Eq. (2), with the solution given by y(tk+1) =
ytk+Rtk+1
tkf(y(t′), u(t′)) dt′. Unfortunately, a closed-form solution for the nonlinear dynamics f(y, u)
does not (yet) exist. Therefore, we traditionally need to revert to (high-order) numerical ODE solvers that are
computationally very expensive and introduce additional memory overhead [ 47]. This considerably increases the
training time of models involving such continuous-time dynamics. While the computational time can be reduced
by increasing the (minimum) time step of the integrator, this comes at the expense of an integration error, and
we lose (part of) the theoretical guarantees and practical characteristics that the nominal ODE provides. In this
work, we take an alternative approach by splitting the problem into (i) decoupled linear dynamics that can be
cheaply and precisely integrated using a closed-form solution and (ii) the residual, coupled nonlinear dynamics,
which we integrate numerically at a slower time scale:
¨x(t) = F−κx(t)−d˙x(t)| {z }
f¨x,ld(y):decoupled, linear dynamics+g(u(t)−(K−κ)x(t)−(D−d) ˙x(t)−tanh( Wx(t) +b)| {z }
f¨x,nld(y,u):coupled, nonlinear dynamics(9)
where κ= diag( K11. . . K nn),d= (D11. . . D nn)are the diagonal components of the stiffness and damping
matrices, respectively, and F∈Rnis a constant, external forcing term on the oscillators.
For a short-time-interval δt, we now approximate (9) as
¨x(tk+δt)≈f¨x,ld(y(tk+δt), F(tk)) withF(tk) =−f¨x,nld(y(tk), u(tk)). (10)
For a scalar 2nd-order, linear ODE of form ˙yi=fld,i(x(t′), F(tk)), a well-known, closed-form solution [ 48]
exists. We exploit this characteristic by formulating the approximate solution as
y(tk+δt)≈fCFA−CON(y(tk), u(tk)) =y(tk) +Ztk+δt
tkfld(y(t′), F(tk)) dt′(11)
and denote fCFA−CON :Rn×Rm→Rnas the Closed-Form Approximation of the Coupled Oscillator
Network (CFA-CON) model. The implicit assumption behind (10) is that f¨x,ld(y)≻f¨x,nld(y, u)(i.e., the
linear, decoupled dynamics dominate the nonlinear, coupled, time-varying dynamics). We refer the interested
reader to Appendix B for derivation and implementation details, where we summarize the integration procedure
in Algorithm 1. We also provide qualitative results for the integration accuracy in Fig. 2 and quantitative results
for the integration accuracy and computational speed-up w.r.t. numerical integrators in Appendix B.
4 Learning control-oriented latent dynamics from pixels
We now move towards learning latent dynamical models based on CON and CFA-CON. CONs are an ideal fit
for learning latent dynamics as they guarantee that the latent states stay bounded.
We assume to have access to observations in the form of images o∈Rho×wo×co, where codenotes the number
of channels. Please note that this could also be other high-dimensional observations such as LiDAR scans, point
clouds, etc. We now leverage an encoder-decoder architecture to map these high-dimensional observations
into a compressed latent space: The encoder Φ :Rho×wo×co→Rnzwithnz≪howoidentifies a low-
dimensional latent representation z∈Rnzof the images. The decoder Ψ :Rnz→Rho×wo×coapproximates
the inverse operation by reconstructing an image ˆo∈Rho×wo×cobased on the latent representation. To promote
the learning of a smooth and monotonic mapping into latent space, we specifically choose to implement the
autoencoder here as a β-Variational Autoencoder (V AE) [ 5,49]. Instead of just statically reconstructing the
image ˆo(tk), we are interested in predicting future observations ˆo(tk+l), where l∈1. . . N . For this, we train a
2nd-order dynamical model that is, when integrated, able to predict future latent representations z(tk+l). This
requires us to define a latent state ξ(t) =
zT(t) ˙zT(t)T∈R2nzconsisting of the latent representation and
latent velocity ˙z(t)∈Rnz.
We now rely on CON with n=nzoscillators to provide us with the latent state derivative ˙ξ=fw(yw(t), u(t)),
where we defined ξ=yw, and z=xw. To ensure stability, we make use of the Cholvesky decomposition to
ensure that Mw, KwandDwalways remain positive definite (see Theorem 2). It is important to note that we
train the encoder, decoder, and dynamical model all jointly. Please refer to Appendix C for more implementation
details.
Training. It is important to remember that because we are using a β-V AE [ 5,49], the image encoding becomes
stochastic, and the encoder neural network actually outputs µz(o),2 log( σz)(o)∈Rnz. After executing the
reparametrization trick as z(tk)∼ N (µz(tk), σ2
z(tk)), we formulate the loss function, evaluated on each
trajectory consisting of Ntime-steps, as
L=NX
k=0
MSE( o(tk),Ψ(z(tk)))
N+ 1| {z }
Static image reconstruction loss+βDKL((µz(tk), σz(tk))
N+ 1| {z }
Kullback–Leibler divergence
+NX
k=1
λ⃗ oMSE( o(tk),Ψ(ˆz(tk)))
N| {z }
Dynamic image reconstruction loss+λzMSE( z(tk),ˆz(tk))
N| {z }
Latent dynamics consistency loss
,
(12)
6Model RMSE M-SP+F [26]↓RMSE S-P+F [26]↓RMSE D-P+F [26]↓ RMSE CS ↓ RMSE PCC-NS-2 ↓RMSE PCC-NS-3 ↓
RNN 0.2739±0.0057 0 .2378±0.0352 0 .1694±0.0004 0.1011±0.0009 0.1373±0.0185 0 .2232±0.0075
GRU [30] 0.0267±0.0033 0 .1457±0.0078 0 .1329±0.0005 0 .1125±0.0100 0.0951±0.0021 0.2148±0.0196
coRNN [35] 0.0265±0.0002 0.1333±0.0044 0 .1324±0.0016 0 .2537±0.0018 0 .2504±0.0899 0 .2474±0.0018
NODE [27] 0.0264±0.0010 0 .1260±0.0013 0.1324±0.0024 0 .2415±0.0021 0 .1867±0.0561 0 .3373±0.0565
MECH-NODE 0.0328±0.0034 0 .1650±0.0205 0 .1710±0.0111 0 .2494±0.0028 0 .1035±0.0012 0 .1900±0.0024
CON-S (our) 0.0303±0.0053 0 .1303±0.0064 0 .1323±0.0018 0 .1993±0.0646 0 .0996±0.0012 0 .1792±0.0038
CON-M (our) 0.0303±0.0053 0 .1303±0.0064 0 .1323±0.0018 0 .1063±0.0027 0 .1008±0.0006 0.1785±0.0023
CFA-CON (our) 0.0313±0.0026 0 .1352±0.0073 0.1307±0.0012 0.1462±0.0211 0 .1124±0.0025 0 .1803±0.0003
Table 1: Benchmarking of CON and CFA-CON at learning latent dynamics against baseline methods. The first
three datasets, based on [ 26], contain samples of a mass-spring with friction ( M-SP + F ), a single pendulum with
friction ( S-P + F ), and a double pendulum with friction ( D-P + F ) (all without system inputs). The CSdataset
considers a continuum soft robot consisting of one segment with three constant planar strains. The PCC-NS-2
andPCC-NS-3 datasets contain trajectories of a continuum soft robot made of two and three piecewise constant
curvature segments, respectively. We choose the latent dimensions of the models as nz= 4,nz= 4, and
nz= 12 for the M-SP + F ,S-P + F , and D-P + F datasets, and nz= 8,nz= 12 , and nz= 12 for the
PCC-NS-2 ,PCC-NS-3 , and CSsoft robotic datasets. We report the mean and standard deviation over three
different random seeds.
Dataset nzRNN GRU [30] coRNN [35] NODE [27] MECH-NODE CON-S (our) CON-M (our) CFA-CON (our)
M-SP+F 488 248 40 3368 3244 34 34 34
D-P+F 12672 1968 348 4404 4032 246 246 246
PCC-NS-2 8320 928 152 3856 3062 676 7048 7048
Table 2: Number of trainable parameters for the various latent dynamic models and the examples of the M-SP+F
(nz= 4, unactuated), D-P+F (nz= 12 , unactuated) and PCC-NS-2 (nz= 8, actuated) datasets. The number
of trainable parameters for all models and datasets can be found in Appendix D.
where ˆz(tk)is predicted by ˆξ(tk) =Rtk
t=t0fξ(ξ(t′), u(t′)) dt′, andξ(t0) =
zT(t0) ˙zT(t0)T. Here, z(t0)
is given by the encoder, and ˙z(t0)is approximated using finite differences in image-space (see Appendix C.5 for
more details). β, λ⃗ o, λz∈Rare loss weights.
Models. We train the CON with the input-to-forcing mapping g(u) =B(u)u, where B(u)is parametrized
by a MLP with a hyperbolic tangent activation function applied in between layers. We report results for
two variants of the CON model: for the medium-sized CON-M and small-sized CON-S , the MLP consists
of five and two layers with a hidden dimension of 30and12, respectively. The model CFA-CON uses the
same architecture as CON-M . We compare against several popular latent space model architectures: The
NODE model uses a MLP with an hyperbolic activation functions and predicts ˙ξ(t) =fNODE (ξ(t), u(t)).
To make the comparison fair, we parametrize the NODE’s MLP in the same fashion as for CON-M . The
MECH-NODE integrates prior knowledge towards learning 2nd-order mechanical ODEs and, therefore, predicts
¨z(t) =fMECH −NODE (ξ(t), u(t)). Furthermore, we consider multiple autoregressive models: RNN, GRU, and
coRNN and let them parameterize the following transition function: ξ(tk+1) =far(ξ(tk), u(tk))As common
in the relevant literature [ 26], we allow the autoregressive models to perform multiple time step transitions before
predicting the next sample. For the autoencoder, we use a vanilla Convolutional Neural Network (CNN). More
details can be found in Appendix C.
Datasets. We consider in total six datasets that are based on simulations of unactuated mechanical systems,
and actuated continuum soft robots. The first three, mechanical dataset are based on the work of Botev et al. [ 26]
and contain video sequences of a mass-spring system with friction ( M-SP+F ), a single pendulum with friction
(S-P+F ), and a double pendulum with friction ( D-P+F ). Continuum soft robots have theoretically infinite
Degree of Freedom (DOF), evolve with highly nonlinear and often time-dependent dynamical behaviors, and are
notoriously difficult to model from first principles [ 50]. For that reason, it is a very interesting proposition if
we could learn latent-space dynamical models directly from video [ 51] and later leverage them for control [ 52].
Therefore, we generate three datasets based on the Piecewise Constant Strain (PCS) soft robot model. CS
considers one segment with constant strain and is modeled using three configuration variables. PCC-NS-2 and
PCC-NS-3 only consider bending deformations and contain soft robots with two and three segments, respectively.
For all datasets, we render images with a resolution of 32x32px of the system’s state. More information on the
datasets can be found in Appendix C.1.
We tune all hyperparameters for each model and dataset separately using Optuna [53].
Results. Unactuated mechanical datasets: The results in Tab. 1 show that the NODE model slightly
outperforms the CON network on the M-SP+F andS-P+F datasets. However, as the datasets do not consider
system inputs, we can remove the input mapping from all models (e.g., RNN ,GRU ,coRNN ,CON , and CFA-
CON ). With that adjustment, the CON network has the fewest parameters among all models, particularly two
orders of magnitude less than the NODE model. Therefore, we find it very impressive that the CON network
is roughly on par with the NODE model. For the D-P+F dataset, we can conclude that the CFA-CON model
offers the best performance across all methods. Finally, most of the time, the CON &CFA-CON networks
outperform the other baseline methods that have more trainable parameters. Actuated continuum soft robot
datasets: The results in Tab. 1 show that CON-M matches the performance of the state-of-the-art methods
70 5 10 15 20 25 30
nz0.10.20.30.40.5RMSE
RNN
MECH-NODE-S
MECH-NODE
CON-S
CON-M
CFA-CON(a) RMSE vs. latent dimension nz
0 2000 4000 6000 8000 10000 12000
Model parameters0.10.20.30.40.5RMSE
RNN
MECH-NODE-S
MECH-NODE
CON-S
CON-M
CFA-CON (b) RMSE vs. model parameters
Figure 3: Evaluation of prediction performance of the various models vs. the dimension of their latent
representation nzand the number of trainable parameters of the dynamics model, respectively, on the PCC-NS-2
dataset. All hyperparameters are tuned for each model separately for nz= 8. The error bar denotes the standard
deviation across three random seeds.
across all experiments. In the case of PCC-NS-3 ,CON-M even decreases the RMSE error by 6 %w.r.t. the
closest baseline method (MECH-NODE). Impressively, the performance is not reduced (but instead often even
improved) compared to other models that offer a much larger design space for learning the dynamics (e.g.
NODE). Furthermore, CON-S andCFA-CON often only exhibit slightly lower performance than CON-M ,
even though they have significantly fewer parameters and consider an approximated solution, respectively.
Supplementary results (e.g., more evaluation metrics) can be found in Appendix D. We also conduct on the
PCC-NS-2 dataset an analysis concerning the effect of the latent dimension on the performance (see Fig. 3).
For this experiment, all hyperparameters were tuned for nz= 8, and we observe that the CON models have a
much-improved consistency and smaller variance w.r.t. the baseline methods when the latent dimensionality is
increased.
The results for a dataset based on the 1st-order reaction-diffusion PDE [9] are presented in Apx. D.1.
5 Exploiting the dynamic structure for latent-space control
We consider the problem setting of guiding the system towards a desired observation odby providing a sequence
of inputs u(tk)such that at time tN, the actual observation o(tN)matches od. A relatively simple way would
be to encode the desired observation into latent space zd= Φ(od)and then to design a feedback controller (e.g.,
PID) in latent space: g(u) = PID( zd−z(t),−˙z). Unfortunately, several challenges appear: first, it is not clear
how the latent-space force τ=g(u)can be mapped back to an actual input u(t)as the inverse input-to-forcing
mapping g−1is generally not known. Furthermore, relying entirely on a PID controller has several well-known
drawbacks, such as poor and slow transient behavior, steady-state errors (in case the integral gain is chosen to
be zero), and instability for high proportional and integral gains. We take inspiration from potential shaping
strategies [ 23,24], which are widely used for effectively controlling (elastic) robots, and, therefore, combine a
feedforward term compensating the latent-space potential forces with an integral-saturated, PID-like feedback
term. For mapping the desired forcing τback to an input u(t), we train an forcing decoder η:Rn→Rm
that approximates g−1. Specifically, we consider here the structure u=η(τ) =E(τ)τ, where E∈Rm×nis
parameterized by an MLP.
The latent-space control law is given by
τ(t) =g(u) =Kwzd+ tanh( zd+b)| {z }
Feedforward term:
compensation of potential forces+Kp(zd−z)−Kd˙z+KiZt
0tanh( υ(zd(t′)−z(t′)))dt′
| {z }
Feedback term: P-satI-D(13)
where Kp, Ki, Kd∈Rn×nare the proportional, integral, and derivative control gains, respectively. As
integral terms can often lead to instability when applied to nonlinear systems [ 54], we adopt an integral term
saturation [ 55] with the associated dimensionless gain υ∈R, which ensures that the integral error added at
each time step is bounded to the interval (−1,1). Subsequently, τis decoded to the input as u(t) =η(τ) =
E(τ)τ. For training this decoder, we add a reconstruction loss to (12):Lu(tk) =λuMSE( u(tk),ˆu(tk)) =
λuMSE ( u(tk), η(g(u(tk)))).
Experimental setup. We train a CON model with two latent variables ( nz= 2) on the PCC-NS-2 dataset.
Analog to the input encoder mapping B(u), the forcing decoder mapping E(τ)is parametrized by an MLP
consisting of five layers with hidden dimension 30and a hyperbolic tangent activation function. The CON model
achieves an RMSE of 0.1628 on the test set. We benchmark two controllers on the simulated continuum soft
robot consisting of two segments: (i) a pure P-satI-D controller (i.e., the feedback term in (13)) that leverages
the smooth mapping into the latent representation enabled by the CON dynamic model and the β-V AE, and (ii)
aP-satI-D+FF (i.e., (13)) that exploits the structure of the CON dynamics by compensating for the potential
forces. The stable closed-loop system dynamics made the control gain tuning very easy, and we selected
8<latexit sha1_base64="jfqHcM0BSP+JPfEDheJHaxE0Rmw=">AAACKHicbVBdSwJBFJ3t07Yvq8dehiQwRNn1wXpLCKQXwTAzcEVmx6sNzs4uM7OBLP6cXvorvUQU4Wu/pPEjKO3AwLnn3sOde/yIM6UdZ2ytrK6tb2ymtuztnd29/fTB4Z0KY0mhQUMeynufKOBMQEMzzeE+kkACn0PTH1xN+s1HkIqF4lYPI2gHpC9Yj1GijdRJX3o+9JlIKAgNcmRXiVL5eiSZ6HuencMVyehk0hTZar5ey1XObA9E98fQSWecgjMFXibunGTQHLVO+s3rhjQOjJ1ys6zlOpFuJ0RqRjmMbC9WEBE6IH1oGSpIAKqdTA8d4VOjdHEvlOYJjafqb0dCAqWGgW8mA6If1GJvIv7Xa8W6d9FOmIhiDYLOFvVijnWIJ6nhLpNANR8aQqhk5q+YPhBJqMlA2SYEd/HkZXJXLLilQummmCkX53Gk0DE6QVnkonNURteohhqIoif0gt7Rh/VsvVqf1ng2umLNPUfoD6yvb+lPpTQ=</latexit>Mass-Spring
+ Friction
(M-SP+F)<latexit sha1_base64="0ucuZ35ygjt1mlMdtHlSi8X11mQ=">AAACKHicbVDLSgMxFM34dnxVXboJFkEXlpkK6k6hG1dSH1WhU0omvVODmWRI7ghl6Oe48VfciCji1i8xrRV8HQicnHMPyT1xJoXFIHjzxsYnJqemZ2b9ufmFxaXS8sqF1bnh0OBaanMVMwtSKGigQAlXmQGWxhIu45vawL+8BWOFVufYy6CVsq4SieAMndQuHUQxdIUqOCgE0/drWqFQeZ5GkX+mE6SnOtboLpv1Wm37+Gx7Z8uPQHW+Au1SOagEQ9C/JByRMhmh3i49RR3N89TFuWTWNsMgw1bBDAouoe9HuYWM8RvWhaajiqVgW8Vw0T7dcEqHJtq4o5AO1e+JgqXW9tLYTaYMr+1vbyD+5zVzTPZbhVBZjqD450NJLilqOmiNdoQBjrLnCONGuL9Sfs0M464D67sSwt8r/yUX1Uq4W9k9qZYPq6M6ZsgaWSebJCR75JAckTppEE7uyAN5Ji/evffovXpvn6Nj3iizSn7Ae/8AVCalcQ==</latexit>Continuum
Soft Robot
(PCC-NS-3)<latexit sha1_base64="h/TRQF1ulvrWNB3MoPKmdaDvkM4=">AAACLXicbVDLSgMxFM34rOOr6tJNsAiVYpnpQl0KluKygrWFTimZ9LYNzWSGPIQy9Ifc+CsiuKiIW3/D9CFo64HAyTn3kNwTJpwp7XljZ2V1bX1jM7Plbu/s7u1nDw4fVGwkhRqNeSwbIVHAmYCaZppDI5FAopBDPRzcTPz6I0jFYnGvhwm0ItITrMso0VZqZ8tBCD0mUgpCgxy55djYaBC4VRAdw01kaQFXJKOTeXvJl8+rhcqZG1j/J9XO5ryiNwVeJv6c5NAc1Xb2NejE1EQ2TjlRqul7iW6lRGpGOYzcwChICB2QHjQtFSQC1Uqn247wqVU6uBtLe4TGU/V3IiWRUsMotJMR0X216E3E/7ym0d2rVspEYjQIOnuoazjWMZ5UhztMAtV8aAmhktm/YtonklDbgXJtCf7iysvkoVT0L4oXd6XcdWleRwYdoxOURz66RNfoFlVRDVH0hF7QGL07z86b8+F8zkZXnHnmCP2B8/UN6P+nPQ==</latexit>Double
Pendulum
+ Friction
(D-P+F)<latexit sha1_base64="1THYeLuef25HkTHGav2Xs+wh6ho=">AAACHXicbVDLSsNAFJ3UV42vqks3wSK4sSRFqsuCG91VsQ9oQplMbtqhk0mYmSgl9Efc+CtuXCjiwo34N07TCtp6YOBwzrncucdPGJXKtr+MwtLyyupacd3c2Nza3int7rVknAoCTRKzWHR8LIFRDk1FFYNOIgBHPoO2P7yY+O07EJLG/FaNEvAi3Oc0pAQrLfVKp64PfcozAlyBGJs3gNnJfSxY4LrmFZcJFXnSdIEHP6leqWxX7BzWInFmpIxmaPRKH24QkzTS44RhKbuOnSgvw0JRwmBsuqmEBJMh7kNXU44jkF6WXze2jrQSWGEs9OPKytXfExmOpBxFvk5GWA3kvDcR//O6qQrPvYzyJFXAyXRRmDJLxdakKiugAohiI00wEVT/1SIDLDDRHUhTl+DMn7xIWtWKU6vUrqvlenVWRxEdoEN0jBx0huroEjVQExH0gJ7QC3o1Ho1n4814n0YLxmxmH/2B8fkNlZCi0Q==</latexit>Real-world
Inspiration<latexit sha1_base64="qNLgn8Ctvx2RS5kauX0A8QbS86w=">AAACHXicbVDLSsNAFJ3UV42vqEs3g0VwVZIi1WVBF7qrYmuhCWUyuW2HTiZhZiKU0B9x46+4caGICzfi3zh9CNp6YeBwzj33zj1hypnSrvtlFZaWV1bXiuv2xubW9o6zu9dUSSYpNGjCE9kKiQLOBDQ00xxaqQQShxzuwsH5WL+7B6lYIm71MIUgJj3BuowSbaiOc+KH0GMipyA0yJF9AyICCZHv2xdEm8EaXxkL2L4Rfro6Tsktu5PCi8CbgRKaVb3jfPhRQrPY2CknSrU9N9VBTqRmlMPI9jMFKaEDs6htoCAxqCCfXDfCR4aJcDeR5gmNJ+xvR05ipYZxaDpjovtqXhuT/2ntTHfPgpyJNNMg6HRRN+NYJ3gcFY6YBKr50ABCJTN/xbRPJKEmA2WbELz5kxdBs1L2quXqdaVUq8ziKKIDdIiOkYdOUQ1dojpqIIoe0BN6Qa/Wo/VsvVnv09aCNfPsoz9lfX4D2emiWg==</latexit>Rendered
Dataset Image
NATURE NANOTECHNOLOGY  | VOL 11 | APRIL 2016 | www.nature.com/naturenanotechnology  317Future perspective
Whereas evolution has integrated self-assembly, self-organization 
and periodic RD processes at the nanoscale to produce beautiful 
nanomachinery, there is clearly a lot to do to combine these three 
processes in nanoscale abiological systems. We believe that the 
advances outlined in this Review have laid the foundation for inves -
tigating self-assembly, self-organization and RD at the nano- and 
microscales in a holistic manner.
Recent studies of the prototypical BZ oscillating chemical reac -
tion in nano- and microdroplets have provided considerable insight 
into how emergent properties arise from RD processes. Moreover, 
self-assembly systems have reached a high level of sophistication. 
Using DNA origami, for example, it is now possible to design a 
sequence of DNA that will give almost any desired shape102. A future challenging task would be to render such DNA objects with 
desired functionalities as well47. From an instrumentation point of 
view, the rapid progress of tools such as cryo-electron microscopy103 
and X-ray crystallography104 has greatly enhanced our capability to 
study self-assembly, self-organization and RD processes.
Finally, observing that a key feature of life is its rhythmic 
nature105, we take chemical oscillation as an example to direct the 
reader towards a set of speci /f_ic problems that merit attention from 
researchers. First, new chemical oscillators: the BZ reaction has 
revealed many important insights about oscillating reactions and 
may still serve as a good toy model; how can we use these princi -
ples to develop new types of chemical oscillator for controlling RD 
processes106,107 or regulating RD processes in living systems? Second, 
communication, computation and memory: we know that BZ oscilla -
tors can communicate and exhibit certain features of computation108 
and memory systems, so how can we develop synthetic systems, with 
intermediate complexity between chemical oscillators and the brain, 
but not based on silicon electronics, that can perform such tasks? 
/T_hird, motion: nature has evolved ATP motors by integrating self-
assembly, self-organization and RD processes, so what do we need to 
construct an analogous e ﬃcient chemomechanical engine? Fourth, 
periodicity: how can nanoscale oscillations that result in micro- and 
macroscale phenomena help us to develop RD processes for control -
ling the fate of cells and treating diseases? (Although some progress 
has been made towards this latter goal, we are still at a very early 
stage before we can treat diseases109–111.) Fi/f_th, multiscale aspects: 
although there is an observable, phenomenological link between a 
variety of nanoscale processes and microscale phenomena, how can 
we rationalize how large-scale behaviour emerges from an under -
standing of nanoscale processes and interactions?
We hope that this short Review will stimulate scientists to develop 
new, nanoscale, synthetic systems for a wide range of functions and 
inspire them to shi /f_t from studying single molecules (or objects) to 
multiple entities, from homotypic to heterotypic molecular interac -
tions, from single to multiple events, from static to dynamic patterns, 
and from structure to function. Of course, it is unlikely that the inte -
gration of self-assembly, self-organization and RD processes at the 
nanoscale will produce systems that capture all the features of living 
systems. But exploration along these lines will undoubtedly not only 
lead to a new paradigm of doing nanoscience and to the develop -
ment of new nanotechnologies, but may also help address fundamen -
tal questions, such as how life evolves from the coupling of chemical 
reactions1,112–114 and other types of nonlinear behaviour115,116.
Received 1 September 2015; accepted 18 February 2016; 
published online 5 April 2016
References
1. Epstein, I. %R. /T_he consequences of imperfect mixing in autocatalytic chemical 
and biological systems. Nature  374,  321–327 (1995).  
/T_his paper shows that autocatalysis and heterogeneity in chemical 
reactions can generate complex behaviours in both biological and 
abiological systems.
2. Bánsagi, T. Jr, Vanag, V . %K. & Epstein, I. %R. Tomography of reaction–di &usion 
microemulsions reveals three-dimensional Turing patterns. Science  
331,  1309–1312 (2011).  
/T_his paper demonstrates that reaction–di ﬀusion in nanoemulsions can 
generate 3D Turing patterns.
3. Vanag, V . %K. & Epstein, I. %R. Segmented spiral waves in a reaction–di &usion 
system. Proc. Natl Acad. Sci. USA  100,  14635–14638 (2003).
4. Mattia, E. & Otto, S. Supramolecular systems chemistry. Nature Nanotech.  
10, 111–119 (2015).
5. Mann, S. Self-assembly and transformation of hybrid nano-objects and 
nanostructures under equilibrium and non-equilibrium conditions. 
Nature Mater.  8, 781–792 (2009).
6. Epstein, I. %R. et al. Chemical oscillators in structured media. Acc. Chem. Res.  
45, 2160–2168 (2012).
7. Noble, D. /T_he Music of Life: Biology Beyond Genes  (Oxford Univ. Press, 2008).
8. Whitesides, G. %M. & Grzybowski, B. Self-assembly at all scales. Science  
295,  2418–2421 (2002).
a
Jumping waves
Time
Space
Spiral in
chaotic waves
Bubble waves
T uring patterns
 Segmented spirals
 MemoryOscillon
Standing waves
 Packet waves
 AntispiralsLocalized 
waves
1 2 3
6 4 5 7
8 9 10 11 12
13 14 15 16
17 18 19b
BZ
BZ
Reduced
[Ru( ii)]Oxidized 
[Ru( iii)]~500% volume
changec
Figure 5 |  Pattern formation, communication and energy conversion 
produced by chemical oscillations. a, Pattern formation in BZ reactions 
occurring in a microemulsion of the surfactant sodium bis(2-ethylhexyl)
sulfosuccinate. Jumping waves are presented as snapshots (left) and 
as a space–time plot (right, obtained across the white line shown in 
the left snapshot). Three types of T uring pattern are shown: left, ‘black 
dots’ (honeycomb); centre, ‘frozen waves’; and right, ‘white dots’ 
(distorted hexagons). Standing waves are shown as two antiphase 
snapshots. ‘Memory’ shows persistence of image brieﬂy projected 
onto a photosensitive medium that exhibits localized subcritical T uring 
structures. Localized waves are obtained in the same manner using a 
striped mask. Other patterns are spiral in chaotic waves, bubble waves, 
oscillion, segmented sprials, packet waves, and antispirals.  b, Pattern 
generation in macroemulsions produced by microﬂuidics. Schematic of 
two-dimensional ‘ π–S’ pattern in which each triangle of drops is composed 
of two drops that are π radians out of phase with one another, and the third 
is stationary: grey circles represent stationary (non-oscillatory) droplets; 
blue and red circles show oscillatory droplets 180 ° out of phase with each 
other. c,/uni00A0Chemomechanical oscillation of active gels with ﬂow of aqueous 
BZ solution that achieve ~500% volume change. Figure adapted with 
permission from: a, ref. 6, American Chemical Society; b,/uni00A0ref. /uni00A092, American 
Chemical Society; c, ref. 96, American Chemical Society.REVIEW ARTICLE NATURE NANOTECHNOLOGY  DOI: 10.1038/NNANO.2016.41
©
 2016
 Macmillan
 Publishers
 Limited.
 All
 rights
 reserved.<latexit sha1_base64="U8ZZexJQrWaAht1OM7DdjCxw/H0=">AAACJ3icbVDLSgMxFM3UVx1fVZdugkXQhWWmi+pKCnbhshb7gE4pmfROG5rJDElGKEP/xo2/4kZQEV36J6YvUOuFwLnn3MPNPX7MmdKO82llVlbX1jeym/bW9s7uXm7/oKGiRFKo04hHsuUTBZwJqGumObRiCST0OTT94fVEb96DVCwSd3oUQyckfcECRok2VDd35fnQZyKlIDTIsY1xDQidaJ5nmgoLgkQtutPaeeXM9kD0FvPdXN4pONPCy8CdgzyaV7Wbe/F6EU1CY6ecKNV2nVh3UiI1oxzGtpcoiAkdkj60DRQkBNVJp3eO8YlhejiIpHlC4yn705GSUKlR6JvJkOiB+qtNyP+0dqKDy07KRJxoEHS2KEg41hGehIZ7TALVfGQAoZKZv2I6INIEZaK1TQju35OXQaNYcEuF0m0xXy7O48iiI3SMTpGLLlAZ3aAqqiOKHtATekVv1qP1bL1bH7PRjDX3HKJfZX19AzIgpD4=</latexit>Reaction
Di↵usion
(R-D)
(a) Samples of used datasets
<latexit sha1_base64="b2wFAZekV+NphkNj4kWHRf6rfBE=">AAAB6HicdVDLSgNBEOyNrxhfUY9eBoMgCGFXZfUY8OIxAfOAZAmzk95kzOyDmVkhLPkCLx4U8eonefNvnCQrRNGChqKqm+4uPxFcadv+tAorq2vrG8XN0tb2zu5eef+gpeJUMmyyWMSy41OFgkfY1FwL7CQSaegLbPvjm5nffkCpeBzd6UmCXkiHEQ84o9pIjbN+uWJX7TnIMnHcC9slTq5UIEe9X/7oDWKWhhhpJqhSXcdOtJdRqTkTOC31UoUJZWM6xK6hEQ1Redn80Ck5McqABLE0FWkyV5cnMhoqNQl90xlSPVK/vZn4l9dNdXDtZTxKUo0RWywKUkF0TGZfkwGXyLSYGEKZ5OZWwkZUUqZNNiUTwven5H/SOq86btVtXFZqbh5HEY7gGE7BgSuowS3UoQkMEB7hGV6se+vJerXeFq0FK585hB+w3r8AiAeMvg==</latexit>+
<latexit sha1_base64="Co6OPWdqelnoZAqV/jaSOEI7Ccw=">AAACGXicdVDLSsNAFJ3UV42vqEs3g0VwVZIK0WXBjcsK9gFNKZPpTTp0MgkzE6GE/oYbf8WNC0Vc6sq/cfqCKnpg4HDOvdw5J8w4U9p1v6zS2vrG5lZ5297Z3ds/cA6PWirNJYUmTXkqOyFRwJmApmaaQyeTQJKQQzscXU/99j1IxVJxp8cZ9BISCxYxSrSR+o4bhBAzUVAQGuTExriRasMZ4VgNScZEbNsBiMFyou9U3Ko7A14lnn/h+thbKBW0QKPvfASDlOaJWaecKNX13Ez3CiI1oxwmdpAryAgdkRi6hgqSgOoVs2QTfGaUAY5SaZ7QeKaubhQkUWqchGYyIXqofntT8S+vm+voqlcwkeUmLZ0finKOdYqnNeEBk0A1HxtCqGTmr5gOiSTUdKBsU8IyKf6ftGpVz6/6t7VK3V/UUUYn6BSdIw9dojq6QQ3URBQ9oCf0gl6tR+vZerPe56Mla7FzjH7A+vwGe9qglg==</latexit>Potential shaping<latexit sha1_base64="ufdVOncBds1D1TJ6momsihM5G2k=">AAACJ3icdVDLSsNAFJ34rPEVdelmsAhuLEmF6EoKbly4qGAf0JQymdy2QyeTMDMRSujfuPFX3Agqokv/xOkLquiFC4dzzuXee8KUM6Vd99NaWl5ZXVsvbNibW9s7u87efl0lmaRQowlPZDMkCjgTUNNMc2imEkgccmiEg6ux3rgHqVgi7vQwhXZMeoJ1GSXaUB3nMgihx0ROQWiQIxvjG6INPlUpoRAEhugmkjLRwxHQJAJpByCiub/jFN2SOym8CDz/zPWxN2OKaFbVjvMSRAnNYjNOOVGq5bmpbudEakY5jOwgU2A2D0gPWgYKEoNq55M/R/jYMNH4HtNC4wm7OJGTWKlhHBpnTHRf/dbG5F9aK9Pdi3bORJqZ3+l0UTfjWCd4HBqOmASq+dAAQiUzt2LaJ5JQk4GyTQjzT/H/oF4ueX7Jvy0XK/4sjgI6REfoBHnoHFXQNaqiGqLoAT2hV/RmPVrP1rv1MbUuWbOZA/SjrK9vvtel3w==</latexit>Latent-spaceforcing decoder
<latexit sha1_base64="DqBYlr253hP9Us3gas2vOwaUJ7A=">AAACGHicdVDLSgMxFM34rOOr6tJNsAhuWmcqjC4LutBdBfuAtpRM5k4bmskMSUYoQz/Djb/ixoUibrvzb0xfUEUPBA7nnMvNPX7CmdKO82WtrK6tb2zmtuztnd29/fzBYV3FqaRQozGPZdMnCjgTUNNMc2gmEkjkc2j4g+uJ33gEqVgsHvQwgU5EeoKFjBJtpG7+vO1Dj4mMgtAgRzbG1aIi+q54g0OAwCd0YLdBBItAN19wSs4UeJm43oXjYXeuFNAc1W5+3A5imkZmnHKiVMt1Et3JiNSMchjZ7VRBYraQHrQMFSQC1cmmh43wqVECHMbSPKHxVF2eyEik1DDyTTIiuq9+exPxL6+V6vCqkzGRpBoEnS0KU451jCct4YBJoJoPDSFUMvNXTPtEEmo6ULYpYXEp/p/UyyXXK3n35ULFm9eRQ8foBJ0hF12iCrpFVVRDFD2hF/SG3q1n69X6sD5n0RVrPnOEfsAafwOuX5+M</latexit>P-satI-D feedback
<latexit sha1_base64="jWBisV3aY+4ZNOqVwki9MLcRRJE=">AAACiHicdVFbT9swFHbCGKzsUuBxL0erGK3YqoRLGQ9IiL1M2gtIKyA1JXIch1o4TmSfILVRfsv+E2/8G5xSRpngSLY/fd+5+Zwol8Kg59057sKbxbdLy+8aK+8/fPzUXF07M1mhGe+zTGb6IqKGS6F4HwVKfpFrTtNI8vPo+metn99wbUSm/uA458OUXimRCEbRUmHzb4C0CIOU4kinZRJVcPgVfv8j8gqCb9CeXD4ScQXfYdKx15NTPHUK4gzLSQVbc4qwilAYepcItpAatYMiN0Jm6nnONm7WKSf12+k88bgZNlte15sazAO/t+P1wJ8xLTKzk7B5axthRcoVMkmNGfhejsOSahRM8qoRFIbnlF3TKz6wUNGUm2E5HWQFG5aJIcm0PQphys5HlDQ1ZpzaKW3UPZr/tZp8SRsUmPwYlkLlBXLFHgolhQTMoN4KxEJzhnJsAWVa2F6BjaimDO3uGnYIjz+F18HZdtfvdXunu62j7dk4lsln8oW0iU/2yRH5RU5InzBn0dlydp09t+F67r578ODqOrOYdfLM3ON7PazCDQ==</latexit>⌧fb=Kp(zd z) Kd˙z+KiZt0tanh( (zd(t0) z(t0)))dt0
<latexit sha1_base64="OhW6rQyNeBYhL40qLaNGkL1/W04=">AAACMnicdVDLSgMxFM3UV62vqks3wSIoSpmpUt0IBTeKmwr2AZ1aMmmmDc1khiSj1GG+yY1fIrjQhSJu/QgzfUgteiBw7rn3kHuPEzAqlWm+GKmZ2bn5hfRiZml5ZXUtu75RlX4oMKlgn/mi7iBJGOWkoqhipB4IgjyHkZrTO0v6tVsiJPX5teoHpOmhDqcuxUhpqZW9sBUKW7aHVFd4kevG8BRe/tR3MbQP4P3NuG7HcB9qB+/uTonOXiubM/PmAHCSWMVDswitkZIDI5Rb2Se77ePQI1xhhqRsWGagmhESimJG4owdShIg3EMd0tCUI4/IZjQ4OYY7WmlD1xf6cQUH6qQjQp6Ufc/Rk8macrqXiH/1GqFyT5oR5UGoCMfDj9yQQeXDJD/YpoJgxfqaICyo3hXiLhIIK51yRocwvhT+T6qFvFXMF6+OcqXCKI402ALbYBdY4BiUwDkogwrA4AE8gzfwbjwar8aH8TkcTRkjzyb4BePrG5EaqkM=</latexit>⌧↵=Kwzd+ tanh(zd+b)<latexit sha1_base64="BN1bD6y1skfENVS6QSyZD24cpFU=">AAAB/HicdVDLSsNAFJ34rPUV7dLNYBEqSEmqRDdCQQSXFewDmlAm00k7dPJgHkII9VfcuFDErR/izr9x0kaoogcuHM65l3vv8RNGhbSsT2NpeWV1bb20Ud7c2t7ZNff2OyJWHJM2jlnMez4ShNGItCWVjPQSTlDoM9L1J1e5370nXNA4upNpQrwQjSIaUIyklgZmRcFLeF1zJVLH0D2BORmYVatuzQAXie2cWg60C6UKCrQG5oc7jLEKSSQxQ0L0bSuRXoa4pJiRadlVgiQIT9CI9DWNUEiEl82On8IjrQxhEHNdkYQzdXEiQ6EQaejrzhDJsfjt5eJfXl/J4MLLaJQoSSI8XxQoBmUM8yTgkHKCJUs1QZhTfSvEY8QRljqvsg7h+1P4P+k06rZTd27Pqs1GEUcJHIBDUAM2OAdNcANaoA0wSMEjeAYvxoPxZLwab/PWJaOYqYAfMN6/AAdKkxA=</latexit>u=E(⌧)⌧
<latexit sha1_base64="E+/U+hUhTzjxOLTXC9CrRS0zsKQ=">AAAB7nicdVBNS8NAEJ3Ur1q/qh69LBbBU0kqRI8FETxWsB/QhrLZbNqlm92wuxFK6I/w4kERr/4eb/4bt22EKvpg4PHeDDPzwpQzbVz30ymtrW9sbpW3Kzu7e/sH1cOjjpaZIrRNJJeqF2JNORO0bZjhtJcqipOQ0244uZ773QeqNJPi3kxTGiR4JFjMCDZW6t4IIiOqhtWaW3cXQKvE8y9cH3mFUoMCrWH1YxBJkiVUGMKx1n3PTU2QY2UY4XRWGWSapphM8Ij2LRU4oTrIF+fO0JlVIhRLZUsYtFBXJ3KcaD1NQtuZYDPWv725+JfXz0x8FeRMpJmhgiwXxRlHRqL57yhiihLDp5Zgopi9FZExVpgYm1DFhvD9KfqfdBp1z6/7d41a0y/iKMMJnMI5eHAJTbiFFrSBwAQe4RlenNR5cl6dt2VrySlmjuEHnPcvVsaPjQ==</latexit>Encoder
<latexit sha1_base64="LKI88LtM6NDwHNA+S9uDx9pJF3E=">AAACHnicdVDLSgMxFM34rOOr6tJNsAiuykzF0WWhG5cV7AM6Q8mkt21oJjMkmUIZ+iVu/BU3LhQRXOnfmLZTqKIHAifnnkNyT5hwprTjfFlr6xubW9uFHXt3b//gsHh03FRxKik0aMxj2Q6JAs4ENDTTHNqJBBKFHFrhqDabt8YgFYvFvZ4kEERkIFifUaKN1C1e+SEMmMgoCA1yamNcS6U0F983PA4VyPHcavsgektbt1hyys4ceJW43qXjYTdXSihHvVv88HsxTSMTp5wo1XGdRAcZkZpRDlPbTxUkhI7IADqGChKBCrL5elN8bpQe7sfSHKHxXF1NZCRSahKFxhkRPVS/ZzPxr1kn1f2bIGMiSTUIunion3KsYzzrCveYBKr5xBBCJTN/xXRIJKGmA2WbEpab4v9Js1J2vbJ3VylVvbyOAjpFZ+gCuegaVdEtqqMGougBPaEX9Go9Ws/Wm/W+sK5ZeeYE/YD1+Q1G5KKV</latexit>Currentobservation<latexit sha1_base64="8Pl1+qf27vLuc9M/8nPzie5gsE4=">AAACHXicdVDLSsNAFJ34rPFVdelmsAiuSlIluiy4cVmhL2hCmUxu26GTSZiZFEroj7jxV9y4UMSFG/FvnL6gih4YOJxzLnfuCVPOlHacL2ttfWNza7uwY+/u7R8cFo+OmyrJJIUGTXgi2yFRwJmAhmaaQzuVQOKQQysc3k791gikYomo63EKQUz6gvUYJdpI3eKVH0KfiZyC0CAnNsZ1Ivugfd/QJFQgR7Ok7YOIlqluseSUnRnwKnG9S8fD7kIpoQVq3eKHHyU0i8045USpjuukOsiJ1IxymNh+piAldEj60DFUkBhUkM+um+Bzo0S4l0jzhMYzdXUiJ7FS4zg0yZjogfrtTcW/vE6mezdBzkSaaRB0vqiXcawTPK0KR0wC1XxsCKGSmb9iOiCSUNOBsk0Jy0vx/6RZKbte2buvlKreoo4COkVn6AK56BpV0R2qoQai6AE9oRf0aj1az9ab9T6PrlmLmRP0A9bnN07Mog8=</latexit>Targetobservation<latexit sha1_base64="E+/U+hUhTzjxOLTXC9CrRS0zsKQ=">AAAB7nicdVBNS8NAEJ3Ur1q/qh69LBbBU0kqRI8FETxWsB/QhrLZbNqlm92wuxFK6I/w4kERr/4eb/4bt22EKvpg4PHeDDPzwpQzbVz30ymtrW9sbpW3Kzu7e/sH1cOjjpaZIrRNJJeqF2JNORO0bZjhtJcqipOQ0244uZ773QeqNJPi3kxTGiR4JFjMCDZW6t4IIiOqhtWaW3cXQKvE8y9cH3mFUoMCrWH1YxBJkiVUGMKx1n3PTU2QY2UY4XRWGWSapphM8Ij2LRU4oTrIF+fO0JlVIhRLZUsYtFBXJ3KcaD1NQtuZYDPWv725+JfXz0x8FeRMpJmhgiwXxRlHRqL57yhiihLDp5Zgopi9FZExVpgYm1DFhvD9KfqfdBp1z6/7d41a0y/iKMMJnMI5eHAJTbiFFrSBwAQe4RlenNR5cl6dt2VrySlmjuEHnPcvVsaPjQ==</latexit>Encoder<latexit sha1_base64="b2wFAZekV+NphkNj4kWHRf6rfBE=">AAAB6HicdVDLSgNBEOyNrxhfUY9eBoMgCGFXZfUY8OIxAfOAZAmzk95kzOyDmVkhLPkCLx4U8eonefNvnCQrRNGChqKqm+4uPxFcadv+tAorq2vrG8XN0tb2zu5eef+gpeJUMmyyWMSy41OFgkfY1FwL7CQSaegLbPvjm5nffkCpeBzd6UmCXkiHEQ84o9pIjbN+uWJX7TnIMnHcC9slTq5UIEe9X/7oDWKWhhhpJqhSXcdOtJdRqTkTOC31UoUJZWM6xK6hEQ1Redn80Ck5McqABLE0FWkyV5cnMhoqNQl90xlSPVK/vZn4l9dNdXDtZTxKUo0RWywKUkF0TGZfkwGXyLSYGEKZ5OZWwkZUUqZNNiUTwven5H/SOq86btVtXFZqbh5HEY7gGE7BgSuowS3UoQkMEB7hGV6se+vJerXeFq0FK585hB+w3r8AiAeMvg==</latexit>+
<latexit sha1_base64="0rSdlPgu0RDXRvESBIT1FVBGDt4=">AAAB6HicdVDLSgNBEOyNrxhfUY9eBoPgxbCrsnoMePGYgHlAsoTZSW8yZvbBzKwQlnyBFw+KePWTvPk3TpIVomhBQ1HVTXeXnwiutG1/WoWV1bX1jeJmaWt7Z3evvH/QUnEqGTZZLGLZ8alCwSNsaq4FdhKJNPQFtv3xzcxvP6BUPI7u9CRBL6TDiAecUW2kxlm/XLGr9hxkmTjuhe0SJ1cqkKPeL3/0BjFLQ4w0E1SprmMn2suo1JwJnJZ6qcKEsjEdYtfQiIaovGx+6JScGGVAgliaijSZq8sTGQ2VmoS+6QypHqnf3kz8y+umOrj2Mh4lqcaILRYFqSA6JrOvyYBLZFpMDKFMcnMrYSMqKdMmm5IJ4ftT8j9pnVcdt+o2Lis1N4+jCEdwDKfgwBXU4Bbq0AQGCI/wDC/WvfVkvVpvi9aClc8cwg9Y71+LD4zA</latexit> 
<latexit sha1_base64="QeDzNGXsFS4nxHtN7XfkxWInPfo=">AAAB83icdVDLSsNAFJ3UV62vqks3g0VwVRKV6LLgxmUF+4Amlslk0g6dR5iZCCX0N9y4UMStP+POv3HSRqiiBwYO59zLPXOilFFtXPfTqaysrq1vVDdrW9s7u3v1/YOulpnCpIMlk6ofIU0YFaRjqGGknyqCeMRIL5pcF37vgShNpbgz05SEHI0ETShGxkqBvA84MmPF83g2rDfcpjsHXCaef+760CuVBijRHtY/gljijBNhMENaDzw3NWGOlKGYkVktyDRJEZ6gERlYKhAnOsznmWfwxCoxTKSyTxg4V5c3csS1nvLIThYJ9W+vEP/yBplJrsKcijQzRODFoSRj0EhYFABjqgg2bGoJworarBCPkULY2JpqtoTvn8L/Sfes6flN//ai0fLLOqrgCByDU+CBS9ACN6ANOgCDFDyCZ/DiZM6T8+q8LUYrTrlzCH7Aef8CobmSDw==</latexit>od
<latexit sha1_base64="xlIX3dKHWH6l7Ysx9CUD+WGYSpo=">AAAB6HicdVBNS8NAEJ34WetX1aOXxSJ4KolK9Fjw4rEF+wFtKJvtpF272YTdjVBKf4EXD4p49Sd589+4bSNU0QcDj/dmmJkXpoJr47qfzsrq2vrGZmGruL2zu7dfOjhs6iRTDBssEYlqh1Sj4BIbhhuB7VQhjUOBrXB0M/NbD6g0T+SdGacYxHQgecQZNVaqJ71S2a24c5Bl4vkXrk+8XClDjlqv9NHtJyyLURomqNYdz01NMKHKcCZwWuxmGlPKRnSAHUsljVEHk/mhU3JqlT6JEmVLGjJXlycmNNZ6HIe2M6ZmqH97M/Evr5OZ6DqYcJlmBiVbLIoyQUxCZl+TPlfIjBhbQpni9lbChlRRZmw2RRvC96fkf9I8r3h+xa9flqt+HkcBjuEEzsCDK6jCLdSgAQwQHuEZXpx758l5dd4WrStOPnMEP+C8fwHvF40C</latexit>o<latexit sha1_base64="9JuWWRHHwDJ1tKp5IDjqx9Dm7rg=">AAAB63icdVBNS8NAEJ3Ur1q/qh69LBbBU0lUoseCF48V7Ae0oWy2m3bpZhN2J0Ip/QtePCji1T/kzX/jpo2gog8GHu/NMDMvTKUw6LofTmlldW19o7xZ2dre2d2r7h+0TZJpxlsskYnuhtRwKRRvoUDJu6nmNA4l74ST69zv3HNtRKLucJryIKYjJSLBKOZSH2k2qNbcursA+U48/9z1iVcoNSjQHFTf+8OEZTFXyCQ1pue5KQYzqlEwyeeVfmZ4StmEjnjPUkVjboLZ4tY5ObHKkESJtqWQLNTvEzMaGzONQ9sZUxyb314u/uX1MoyugplQaYZcseWiKJMEE5I/ToZCc4ZyagllWthbCRtTTRnaeCo2hK9Pyf+kfVb3/Lp/e1Fr+EUcZTiCYzgFDy6hATfQhBYwGMMDPMGzEzuPzovzumwtOcXMIfyA8/YJN6+OVw==</latexit>⌧
<latexit sha1_base64="jhCud80NR0BHVouCP53T2/WQYCY=">AAAB+XicdVDLSsNAFL2pr1pfUZduBovgqiQq0WXBjcsK9gFNKJPppB06mYSZSaGE/okbF4q49U/c+TdO2ghV9MDA4Zx7uWdOmHKmtON8WpW19Y3Nrep2bWd3b//APjzqqCSThLZJwhPZC7GinAna1kxz2kslxXHIaTec3BZ+d0qlYol40LOUBjEeCRYxgrWRBrbta5wN/BjrsYzzKJoP7LrTcBZAq8T1Lh0PuaVShxKtgf3hDxOSxVRowrFSfddJdZBjqRnhdF7zM0VTTCZ4RPuGChxTFeSL5HN0ZpQhihJpntBooa5u5DhWahaHZrKIqH57hfiX1890dBPkTKSZpoIsD0UZRzpBRQ1oyCQlms8MwUQykxWRMZaYaFNWzZTw/VP0P+lcNFyv4d1f1ZteWUcVTuAUzsGFa2jCHbSgDQSm8AjP8GLl1pP1ar0tRytWuXMMP2C9fwE6NJQI</latexit>⌧↵
<latexit sha1_base64="eAb6dkgzpdG69Sn/xD4U2qGRneQ=">AAAB+XicdVDLSsNAFL2pr1pfUZduBovgqiQq0WXBjcsK9gFNKJPppB06mYSZSaGE/okbF4q49U/c+TdO2ghV9MDA4Zx7uWdOmHKmtON8WpW19Y3Nrep2bWd3b//APjzqqCSThLZJwhPZC7GinAna1kxz2kslxXHIaTec3BZ+d0qlYol40LOUBjEeCRYxgrWRBrbta5wN/BjrsYzzKJwP7LrTcBZAq8T1Lh0PuaVShxKtgf3hDxOSxVRowrFSfddJdZBjqRnhdF7zM0VTTCZ4RPuGChxTFeSL5HN0ZpQhihJpntBooa5u5DhWahaHZrKIqH57hfiX1890dBPkTKSZpoIsD0UZRzpBRQ1oyCQlms8MwUQykxWRMZaYaFNWzZTw/VP0P+lcNFyv4d1f1ZteWUcVTuAUzsGFa2jCHbSgDQSm8AjP8GLl1pP1ar0tRytWuXMMP2C9fwE0IJQE</latexit>⌧fb<latexit sha1_base64="gX+3H37FbhFdIFyQ2nfC1ILNamc=">AAAB6HicdVBNS8NAEJ34WetX1aOXxSJ4KolK9Fjw4rEF+wFtKJvtpF272YTdjVBKf4EXD4p49Sd589+4bSNU0QcDj/dmmJkXpoJr47qfzsrq2vrGZmGruL2zu7dfOjhs6iRTDBssEYlqh1Sj4BIbhhuB7VQhjUOBrXB0M/NbD6g0T+SdGacYxHQgecQZNVaqZ71S2a24c5Bl4vkXrk+8XClDjlqv9NHtJyyLURomqNYdz01NMKHKcCZwWuxmGlPKRnSAHUsljVEHk/mhU3JqlT6JEmVLGjJXlycmNNZ6HIe2M6ZmqH97M/Evr5OZ6DqYcJlmBiVbLIoyQUxCZl+TPlfIjBhbQpni9lbChlRRZmw2RRvC96fkf9I8r3h+xa9flqt+HkcBjuEEzsCDK6jCLdSgAQwQHuEZXpx758l5dd4WrStOPnMEP+C8fwH4L40I</latexit>u
<latexit sha1_base64="ANZesX/3Fp+PdGob6Tz7LAOh4kI=">AAAB6HicdVDLSgNBEOyNrxhfUY9eBoPgKeyqrB4DXjwmYB6QLGF20puMmX0wMyvEJV/gxYMiXv0kb/6Nk2SFKFrQUFR1093lJ4IrbdufVmFldW19o7hZ2tre2d0r7x+0VJxKhk0Wi1h2fKpQ8AibmmuBnUQiDX2BbX98PfPb9ygVj6NbPUnQC+kw4gFnVBup8dAvV+yqPQdZJo57brvEyZUK5Kj3yx+9QczSECPNBFWq69iJ9jIqNWcCp6VeqjChbEyH2DU0oiEqL5sfOiUnRhmQIJamIk3m6vJERkOlJqFvOkOqR+q3NxP/8rqpDq68jEdJqjFii0VBKoiOyexrMuASmRYTQyiT3NxK2IhKyrTJpmRC+P6U/E9aZ1XHrbqNi0rNzeMowhEcwyk4cAk1uIE6NIEBwiM8w4t1Zz1Zr9bborVg5TOH8APW+xf/w40N</latexit>z<latexit sha1_base64="bou4H+z3K7dqJ0wRQBpYDLhDVz8=">AAAB83icdVBNS8NAFHypX7V+VT16WSyCp5KoRI8FLx4r2FZoYtlsNu3S3STsboQa+je8eFDEq3/Gm//GTRuhig4sDDPv8WYnSDlT2rY/rcrS8srqWnW9trG5tb1T393rqiSThHZIwhN5G2BFOYtpRzPN6W0qKRYBp71gfFn4vXsqFUviGz1JqS/wMGYRI1gbyXu48wTWIynycDqoN+ymPQNaJI57arvIKZUGlGgP6h9emJBM0FgTjpXqO3aq/RxLzQin05qXKZpiMsZD2jc0xoIqP59lnqIjo4QoSqR5sUYzdXEjx0KpiQjMZJFQ/fYK8S+vn+nows9ZnGaaxmR+KMo40gkqCkAhk5RoPjEEE8lMVkRGWGKiTU01U8L3T9H/pHvSdNyme33WaLllHVU4gEM4BgfOoQVX0IYOEEjhEZ7hxcqsJ+vVepuPVqxyZx9+wHr/ArLekho=</latexit>zd<latexit sha1_base64="MuWgD9Acsgs5Qi9p5YiHfmuoWrE=">AAAB+HicdVDLSgMxFL3js9ZHR126CRbBVZmpMLosuHFZwT6gHUomTdvQJDMkGWEc+iVuXCji1k9x59+YtiNU0QMXTs65l9x7ooQzbTzv01lb39jc2i7tlHf39g8q7uFRW8epIrRFYh6rboQ15UzSlmGG026iKBYRp51oej33O/dUaRbLO5MlNBR4LNmIEWysNHArzUmm7YsjnWlDxcCtejVvAbRK/ODCC5BfKFUo0By4H/1hTFJBpSEca93zvcSEOVaGEU5n5X6qaYLJFI9pz1KJBdVhvlh8hs6sMkSjWNmSBi3U1YkcC60zEdlOgc1E//bm4l9eLzWjqzBnMkkNlWT50SjlyMRongIaMkWJ4ZklmChmd0VkghUmxmZVtiF8X4r+J+16zQ9qwW292giKOEpwAqdwDj5cQgNuoAktIJDCIzzDi/PgPDmvztuydc0pZo7hB5z3Lwg5k1A=</latexit>Physical system (b) Blockscheme of model-based control in latent space
Figure 4: Panel (a): Samples of some of the datasets used as part of the experimental verification, specifically
for the results reported in Tab. 1. The real-world Reaction-Diffusion image is adopted from [ 43].Panel (b):
Model-based control in latent space by exploiting the physical structure of the CON model.
Kp= 1, Ki= 2, Kd= 0.02, υ= 1for the P-satI-D controller and Kp= 0, Ki= 2, Kd= 0.05, υ= 1for
theP-satI-D+FF controller, respectively.
Furthermore, we compare the control performance of our model-based controllers with a baseline control strategy
based on the MECH-NODE (nz= 2) that achieves an error of 0.1104 on the test set. First, we utilize the same
P-satI-D feedback controller as for the CON model to generate the control action τ(t)in latent space. As the
MECH-NODE uses an MLP to parameterize the function ˙ξ=fξ(ξ, u), we cannot easily map τ(t)into an input
u(t). Therefore, we linearize the latent space dynamics w.r.t to the input as fξ,ac(ξ, u) =fξ(ξ,0) +A(ξ)u,
where A(ξ) =∂fξ
∂u(ξ,0)is computed using autodiff. Then, u(t) =AT(ξ)τ(t). After tuning the control gains,
we choose Kp= 0.001, Ki= 0.02, Kd= 1e−5, υ= 1.
We train all models (e.g., MECH-NODE ,CON ) on three different random seed and choose the best model
instance. Please refer to Appendix E for more details on the model selection. We generate a trajectory of 7
setpoints, where qd(tj)∼ U(−5π,5π) rad/m∈R2is a sampled configuration of the soft robot. Then, we
render an image od(tj)that represents the target observation for the controller and encode it into latent space
to retrieve zd∈R2. At time step k, we render an image o(tk)of the robot’s current configuration q(tk)and
encode the image. Subsequently, we evaluate the control law and apply the decoder u(tk) =η(τ(tk))), which
is finally passed to the simulator that integrates the ground-truth dynamics to the next time-step tk+1considering
the actuation u(tk). The controller runs at 100 Hz , and we simulate the ground-truth dynamics with a Dopri5
ODE integrator at a time-step of 1e−5 s.
Results. As an evaluation metric, we consider the RMSE between the actual and the reference trajectory.
TheP-satI-D applied to the MECH-NODE model (baseline) achieves an RMSE of 2.88 rad /mw.r.t. to the
desired configuration qd(but unknown to the algorithm). The P-satI-D CON controller, which does not exploit
the learned latent dynamics for control, exhibits an RMSE of 4.08 rad /mw.r.t. to the desired configuration qd.
TheP-satI-D+FF controller exhibits an RMSE of 2.12 rad /mw.r.t. to the desired configuration qd. We also
visualize the closed-loop trajectories in Fig. 5 and as sequences of stills in Apx. E. We conclude that the nicely
structured latent space generated by the β-V AE allows the P-satI-D controller to effectively regulate the system
towards the setpoint, although the response time is rather slow. The P-satI-D+FF controller is able to exploit
the structure of the CON model through its potential shaping feedforward term. With that, CON P-satI-D+FF
exhibits a faster response time and a 26 % lower RMSE than the MECH-NODE P-satI-D baseline. We provide
results for the control of an actuated damped harmonic oscillator in Apx. D.
6 Conclusion and Limitations
Conclusion. In this work, we propose a new formulation for a coupled oscillator that is inherently input-to-
state stable. Additionally, we identify a closed-form approximation, that is able to simulate the network dynamics
more accurately compared to numerical ODE integrators with similar computational costs. When learning latent
dynamics with CON, we observe that the performance is on par or slightly better compared to SoA methods such
as RNNs, NODEs, etc., even though we constrained the solution space to a ISS-stable coupled oscillator structure.
Furthermore, we point out that the performance of the CON models is more consistent across latent dimensions
compared to the baselines and improved when not specifically tuned for a given dimension. Furthermore, as
seen in Tab. 8, the closed-form approximation achieves, with the same number of model parameters, similar
accuracies and double the training speed w.r.t. to the continuous-time model. Finally, we demonstrate that even
a simple PID-like latent-space controller can effectively regulate the system to a setpoint. By exploiting the
90 5 10 15 20 25 30 35
Timet[s]−15−10−50510Conﬁguration q[rad/m]
qd
0
q0
qd
1
q1(a) Config. for P-satI-D with MECH-NODE.
0 5 10 15 20 25 30 35
Timet[s]−0.06−0.04−0.020.000.020.04Latent variable z
zd
0
z0
zd
1
z1 (b) Latent for P-satI-D with MECH-NODE.
0 5 10 15 20 25 30 35
Timet[s]−15−10−50510Conﬁguration q[rad/m]
qd
0
q0
qd
1
q1
(c) Configuration for P-satI-D with CON.
0 5 10 15 20 25 30 35
Timet[s]−0.3−0.2−0.10.00.10.2Latent variable z
zd
0
z0
zd
1
z1 (d) Latent for P-satI-D with CON.
0 5 10 15 20 25 30 35
Timet[s]−20−1001020Conﬁguration q[rad/m]
qd
0
q0
qd
1
q1
(e) Configuration for P-satI-D+FF with CON.
0 5 10 15 20 25 30 35
Timet[s]−0.6−0.4−0.20.00.20.4Latent variable zzd
0
z0
zd
1
z1 (f) Latent for P-satI-D+FF with CON.
Figure 5: Latent-space control of a continuum soft robot (simulated using two piecewise constant curvature
segments) at following a sequence of setpoints: The upper two rows show the performance of a pure P-satI-D
feedback controller operating in latent space zlearned with the MECH-NODE and CON models, respectively.
The lower row displays the results for a latent space controller based on the CON model that additionally also
compensates for the learned potential forces.
network structure and compensating for potential forces, regulation performance can be greatly improved, and
response time decreased by more than 55 % .
Limitations. While we think our proposed method shows great potential and opens interesting avenues for
future research, there exist certain limitations. For example, the proposed method of learning (latent) dynamics
implicitly assumes that the underlying system adheres to the Markov property (e.g., the full state of the system is
observable), that a system with mechanical structure can approximate it, and that it has an isolated, globally
asymptotically stable equilibrium. This is, for example, the case for many mechanical systems (e.g., some
continuum soft robots, deformable objects, and elastic structures) with continuous dynamics, convex elastic
behavior, dissipation, and whose time-dependent effects (e.g., viscoelasticity, hysteresis) are negligible. Even
if these conditions are not met globally, the method can be applied to model the local behavior around an
asymptotic equilibrium point of the system (e.g., robotic manipulators, legged robots) with added stability
benefits for out-of-distribution samples. Alternatively, the method could be extended to relax some of these
assumptions, e.g., by allowing for multiple equilibria, zero damping, or by incorporating additional terms to
capture discontinuous dynamics (e.g., stick-slip models) or period motions (e.g., limit cycles such as the Van der
Pol oscillator). The proposed method might not be suitable for some physical systems, such as nonholonomic
systems, partially observable systems, or systems with non-Markovian properties. Examples of such systems
include mobile robots and systems with hidden states or delayed observations.
Furthermore, the approximated closed-form solution shows the best integration for situations where linear,
decoupled dynamics dominate the transient. For dominant nonlinear, coupled forces, the performance of CFA-
CON degrades, and it might be better to revert to numerical integration of the CON ODE. Finally, the control
works exceptionally well in the setting where the latent dimension equals the input dimension. We hypothesize
that this enables the method to identify a diffeomorphism between the input and the latent-space forcing. Still
not investigated is how the performance could degrade if nz> m (ornz< m for that matter).
10Acknowledgments and Disclosure of Funding
This work was supported under the European Union’s Horizon Europe Program from Project EMERGE - Grant
Agreement No. 101070918.
References
[1] David Ha and Jürgen Schmidhuber. World models. arXiv preprint arXiv:1803.10122 , 2018. 1
[2]Danijar Hafner, Jurgis Pasukonis, Jimmy Ba, and Timothy Lillicrap. Mastering diverse domains through
world models. arXiv preprint arXiv:2301.04104 , 2023. 1
[3]Yutaka Matsuo, Yann LeCun, Maneesh Sahani, Doina Precup, David Silver, Masashi Sugiyama, Eiji
Uchibe, and Jun Morimoto. Deep learning, reinforcement learning, and world models. Neural Networks ,
152:267–275, 2022. 1
[4]Cheng-Yuan Liou, Wei-Chen Cheng, Jiun-Wei Liou, and Daw-Ran Liou. Autoencoder for words. Neuro-
computing , 139:84–96, 2014. 1
[5]Diederik P Kingma and Max Welling. Auto-encoding variational bayes. In Proceedings of the International
Conference on Learning Representations , 2014. 1, 6, 25
[6]Manuel Watter, Jost Springenberg, Joschka Boedecker, and Martin Riedmiller. Embed to control: A locally
linear latent dynamics model for control from raw images. Advances in neural information processing
systems , 28, 2015. 1, 2
[7]Ian Lenz, Ross A Knepper, and Ashutosh Saxena. Deepmpc: Learning deep latent features for model
predictive control. In Robotics: Science and Systems , volume 10, page 25. Rome, Italy, 2015. 1
[8]Niklas Wahlström, Thomas B Schön, and Marc Peter Deisenroth. Learning deep dynamical models from
image pixels. IFAC-PapersOnLine , 48(28):1059–1064, 2015. 1
[9]Kathleen Champion, Bethany Lusch, J Nathan Kutz, and Steven L Brunton. Data-driven discovery of
coordinates and governing equations. Proceedings of the National Academy of Sciences , 116(45):22445–
22451, 2019. 1, 3, 8, 25
[10] Yaofeng Desmond Zhong and Naomi Leonard. Unsupervised learning of lagrangian dynamics from images
for prediction and control. Advances in Neural Information Processing Systems , 33:10741–10752, 2020. 1,
2
[11] Herke Van Hoof, Nutan Chen, Maximilian Karl, Patrick van der Smagt, and Jan Peters. Stable reinforcement
learning with autoencoders for tactile and visual data. In 2016 IEEE/RSJ international conference on
intelligent robots and systems (IROS) , pages 3928–3934. IEEE, 2016. 1
[12] Carles Gelada, Saurabh Kumar, Jacob Buckman, Ofir Nachum, and Marc G Bellemare. Deepmdp:
Learning continuous latent space models for representation learning. In International conference on
machine learning , pages 2170–2179. PMLR, 2019. 1
[13] Danijar Hafner, Timothy Lillicrap, Jimmy Ba, and Mohammad Norouzi. Dream to control: Learning
behaviors by latent imagination. In International Conference on Learning Representations , 2019. 1
[14] Wilko Schwarting, Tim Seyde, Igor Gilitschenski, Lucas Liebenwein, Ryan Sander, Sertac Karaman, and
Daniela Rus. Deep latent competition: Learning to race using visual control policies in latent space. In
Conference on Robot Learning , pages 1855–1870. PMLR, 2021. 1
[15] Danijar Hafner, Timothy Lillicrap, Ian Fischer, Ruben Villegas, David Ha, Honglak Lee, and James
Davidson. Learning latent dynamics for planning from pixels. In International conference on machine
learning , pages 2555–2565. PMLR, 2019. 1
[16] Lukas Hewing, Kim P Wabersich, Marcel Menner, and Melanie N Zeilinger. Learning-based model
predictive control: Toward safe learning in control. Annual Review of Control, Robotics, and Autonomous
Systems , 3:269–296, 2020. 1
[17] John Irvin Alora, Luis A Pabon, Johannes Köhler, Mattia Cenedese, Ed Schmerling, Melanie N Zeilinger,
George Haller, and Marco Pavone. Robust nonlinear reduced-order model predictive control. In 2023 62nd
IEEE Conference on Decision and Control (CDC) , pages 4798–4805. IEEE, 2023. 1
[18] Steven L Brunton, Bingni W Brunton, Joshua L Proctor, and J Nathan Kutz. Koopman invariant subspaces
and finite linear representations of nonlinear dynamical systems for control. PloS one , 11(2):e0150171,
2016. 1
[19] Giorgos Mamakoukas, Maria Castano, Xiaobo Tan, and Todd Murphey. Local koopman operators for
data-driven control of robotic systems. In Robotics: science and systems , 2019. 1
[20] David A Haggerty, Michael J Banks, Ervin Kamenar, Alan B Cao, Patrick C Curtis, Igor Mezi ´c, and
Elliot W Hawkes. Control of soft robots with inertial dynamics. Science robotics , 8(81):eadd6864, 2023. 1
[21] Jun Yamada, Chia-Man Hung, Jack Collins, Ioannis Havoutis, and Ingmar Posner. Leveraging scene
embeddings for gradient-based motion planning in latent space. In 2023 IEEE International Conference
on Robotics and Automation (ICRA) , pages 5674–5680. IEEE, 2023. 1
11[22] Mattia Cenedese, Joar Axås, Bastian Bäuerlein, Kerstin Avila, and George Haller. Data-driven modeling
and prediction of non-linearizable dynamics via spectral submanifolds. Nature communications , 13(1):872,
2022. 2
[23] Anthony M Bloch, Dong Eui Chang, Naomi Ehrich Leonard, and Jerrold E Marsden. Controlled lagrangians
and the stabilization of mechanical systems. ii. potential shaping. IEEE Transactions on Automatic Control ,
46(10):1556–1571, 2001. 2, 3, 8
[24] Romeo Ortega, José Guadalupe Romero, Pablo Borja, and Alejandro Donaire. PID passivity-based control
of nonlinear systems with applications . John Wiley & Sons, 2021. 2, 3, 8
[25] Marco Lepri, Davide Bacciu, and Cosimo Della Santina. Neural autoencoder-based structure-preserving
model order reduction and control design for high-dimensional physical systems. IEEE Control Systems
Letters , 2023. 2
[26] Aleksandar Botev, Andrew Jaegle, Peter Wirnsberger, Daniel Hennes, and Irina Higgins. Which priors mat-
ter? benchmarking models for learning latent dynamics. In Thirty-fifth Conference on Neural Information
Processing Systems Datasets and Benchmarks Track (Round 1) , 2021. 2, 7, 24, 27, 33, 34, 49
[27] Ricky TQ Chen, Yulia Rubanova, Jesse Bettencourt, and David K Duvenaud. Neural ordinary differential
equations. Advances in neural information processing systems , 31, 2018. 2, 3, 7, 26, 29, 30, 31
[28] Aleksei Sholokhov, Yuying Liu, Hassan Mansour, and Saleh Nabi. Physics-informed neural ode (pinode):
embedding physics into models using collocation points. Scientific Reports , 13(1):10166, 2023. 2
[29] Sepp Hochreiter and Jürgen Schmidhuber. Long short-term memory. Neural computation , 9(8):1735–1780,
1997. 2
[30] Kyunghyun Cho, Bart Van Merriënboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Holger
Schwenk, and Yoshua Bengio. Learning phrase representations using rnn encoder-decoder for statistical
machine translation. arXiv preprint arXiv:1406.1078 , 2014. 2, 7, 26, 29, 30, 31
[31] Michael Lutter, Christian Ritter, and Jan Peters. Deep lagrangian networks: Using physics as model prior
for deep learning. In International Conference on Learning Representations , 2018. 2
[32] Miles Cranmer, Sam Greydanus, Stephan Hoyer, Peter Battaglia, David Spergel, and Shirley Ho. La-
grangian neural networks. arXiv preprint arXiv:2003.04630 , 2020. 2
[33] Samuel Greydanus, Misko Dzamba, and Jason Yosinski. Hamiltonian neural networks. Advances in neural
information processing systems , 32, 2019. 2
[34] Alistair White, Niki Kilbertus, Maximilian Gelbrecht, and Niklas Boers. Stabilized neural differential
equations for learning dynamics with explicit constraints. Advances in Neural Information Processing
Systems , 36:12929–12950, 2023. 2
[35] T Konstantin Rusch and Siddhartha Mishra. Coupled oscillatory recurrent neural network (cornn): An
accurate and (gradient) stable architecture for learning long time dependencies. In International Conference
on Learning Representations , 2020. 2, 3, 4, 7, 29, 30, 31
[36] T Konstantin Rusch and Siddhartha Mishra. Unicornn: A recurrent model for learning very long time
dependencies. In International Conference on Machine Learning , pages 9168–9178. PMLR, 2021. 2, 3, 4
[37] Andrea Ceni, Andrea Cossu, Maximilian Stölzle, Jingyue Liu, Cosimo Della Santina, Davide Bacciu, and
Claudio Gallicchio. Random oscillators network for time series processing. In International Conference
on Artificial Intelligence and Statistics , pages 4807–4815. PMLR, 2024. 2, 3, 4
[38] Samuel Lanthaler, T Konstantin Rusch, and Siddhartha Mishra. Neural oscillators are universal. Advances
in Neural Information Processing Systems , 36, 2024. 2, 3, 4
[39] T Konstantin Rusch and Daniela Rus. Oscillatory state-space models. arXiv preprint arXiv:2410.03943 ,
2024. 2
[40] Hassan K Khalil. Nonlinear systems third edition. Patience Hall , 115, 2002. 2, 4, 5, 18, 19
[41] John Irvin Alora, Mattia Cenedese, Edward Schmerling, George Haller, and Marco Pavone. Data-driven
spectral submanifold reduction for nonlinear optimal control of high-dimensional robots. In 2023 IEEE
International Conference on Robotics and Automation (ICRA) , pages 2627–2633. IEEE, 2023. 3
[42] Maximilian Stölzle and Cosimo Della Santina. Piston-driven pneumatically-actuated soft robots: Modeling
and backstepping control. IEEE Control Systems Letters , 6:1837–1842, 2021. 3, 37
[43] Irving R Epstein and Bing Xu. Reaction–diffusion processes at the nano-and microscales. Nature
nanotechnology , 11(4):312–319, 2016. 3, 9
[44] Davide Calzolari, Cosimo Della Santina, and Alin Albu-Schäffer. Exponential convergence rates of
nonlinear mechanical systems: The 1-dof case with configuration-dependent inertia. IEEE Control Systems
Letters , 5(2):445–450, 2020. 4
[45] Xuwei Wu, Christian Ott, Alin Albu-Schäffer, and Alexander Dietrich. Passive decoupled multitask
controller for redundant robots. IEEE Transactions on Control Systems Technology , 31(1):1–16, 2022. 4, 5
[46] Gene H Golub and Charles F Van Loan. Matrix computations . JHU press, 2013. 5, 16, 18
[47] P Kidger. On neural differential equations . PhD thesis, University of Oxford, 2021. 6, 27
12[48] Pieter Pas. The damped harmonic oscillator, Mar 2023. 6, 20
[49] Irina Higgins, Loic Matthey, Arka Pal, Christopher P Burgess, Xavier Glorot, Matthew M Botvinick,
Shakir Mohamed, and Alexander Lerchner. beta-vae: Learning basic visual concepts with a constrained
variational framework. ICLR (Poster) , 3, 2017. 6
[50] Costanza Armanini, Frédéric Boyer, Anup Teejo Mathew, Christian Duriez, and Federico Renda. Soft
robots modeling: A structured overview. IEEE Transactions on Robotics , 39(3):1728–1748, 2023. 7
[51] Thomas George Thuruthel and Fumiya Iida. Multi-modal sensor fusion for learning rich models for
interacting soft robots. In 2023 IEEE International Conference on Soft Robotics (RoboSoft) , pages 1–6.
IEEE, 2023. 7
[52] Elijah Almanzor, Fan Ye, Jialei Shi, Thomas George Thuruthel, Helge A Wurdemann, and Fumiya
Iida. Static shape control of soft continuum robots using deep visual inverse kinematic models. IEEE
Transactions on Robotics , 2023. 7
[53] Takuya Akiba, Shotaro Sano, Toshihiko Yanase, Takeru Ohta, and Masanori Koyama. Optuna: A
next-generation hyperparameter optimization framework. In Proceedings of the 25th ACM SIGKDD
international conference on knowledge discovery & data mining , pages 2623–2631, 2019. 7, 27
[54] Maximilian Stölzle, Daniela Rus, and Cosimo Della Santina. An experimental study of model-based
control for planar handed shearing auxetics robots. In Experimental Robotics , pages 153–167, Cham, 2024.
Springer Nature Switzerland. 8, 24
[55] Pietro Pustina, Pablo Borja, Cosimo Della Santina, and Alessandro De Luca. P-sati-d shape regulation of
soft robots. IEEE Robotics and Automation Letters , 8(1):1–8, 2022. 8
[56] Stephen P Boyd and Lieven Vandenberghe. Convex optimization . Cambridge university press, 2004. 17, 18
[57] Mattia Gazzola, LH Dudte, AG McCormick, and Lakshminarayanan Mahadevan. Forward and inverse
problems in the mechanics of soft filaments. Royal Society open science , 5(6):171628, 2018. 24
[58] Federico Renda, Vito Cacucciolo, Jorge Dias, and Lakmal Seneviratne. Discrete cosserat approach for
soft robot dynamics: A new piece-wise constant strain model with torsion and shears. In 2016 IEEE/RSJ
International Conference on Intelligent Robots and Systems (IROS) , pages 5495–5502. IEEE, 2016. 24
[59] Cosimo Della Santina, Christian Duriez, and Daniela Rus. Model-based control of soft robots: A survey of
the state of the art and open challenges. IEEE Control Systems Magazine , 43(3):30–65, 2023. 24
[60] James Bradbury, Roy Frostig, Peter Hawkins, Matthew James Johnson, Chris Leary, Dougal Maclau-
rin, George Necula, Adam Paszke, Jake VanderPlas, Skye Wanderman-Milne, and Qiao Zhang. JAX:
composable transformations of Python+NumPy programs, 2018. 24, 27
[61] Maximilian Stölzle, Sonal Santosh Baberwal, Daniela Rus, Shirley Coyle, and Cosimo Della Santina. Guid-
ing soft robots with motor-imagery brain signals and impedance control. In 2024 IEEE 7th International
Conference on Soft Robotics (RoboSoft) , pages 276–283. IEEE, 2024. 24
[62] G. Bradski. The OpenCV Library. Dr. Dobb’s Journal of Software Tools , 2000. 24
[63] Robert J Webster III and Bryan A Jones. Design and kinematic modeling of constant curvature continuum
robots: A review. The International Journal of Robotics Research , 29(13):1661–1683, 2010. 24
[64] Emanuele Riccardo Rosi, Maximilian Stölzle, Fabio Solari, and Cosimo Della Santina. Sensing soft
robots’ shape with cameras: an investigation on kinematics-aware slam. In 2022 IEEE 5th International
Conference on Soft Robotics (RoboSoft) , pages 795–801. IEEE, 2022. 24
[65] Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton. Layer normalization. arXiv preprint
arXiv:1607.06450 , 2016. 25
[66] Vincent Dumoulin and Francesco Visin. A guide to convolution arithmetic for deep learning. arXiv preprint
arXiv:1603.07285 , 2016. 25
[67] Kaare Brandt Petersen, Michael Syskind Pedersen, et al. The matrix cookbook. Technical University of
Denmark , 7(15):510, 2008. 25
[68] Jonathan Heek, Anselm Levskaya, Avital Oliver, Marvin Ritter, Bertrand Rondepierre, Andreas Steiner,
and Marc van Zee. Flax: A neural network library and ecosystem for JAX, 2023. 27
[69] J. R. Dormand and P. J. Prince. A family of embedded Runge–Kutta formulae. J. Comp. Appl. Math ,
6:19–26, 1980. 27
[70] Ilya Loshchilov and Frank Hutter. Sgdr: Stochastic gradient descent with warm restarts. In International
Conference on Learning Representations , 2016. 27
[71] Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint
arXiv:1412.6980 , 2014. 27
[72] Ilya Loshchilov and Frank Hutter. Decoupled weight decay regularization. In International Conference on
Learning Representations , 2018. 27
[73] Shuhei Watanabe. Tree-structured parzen estimator: Understanding its algorithm components and their
roles for better empirical performance. arXiv preprint arXiv:2304.11127 , 2023. 27
13[74] Liam Li, Kevin Jamieson, Afshin Rostamizadeh, Ekaterina Gonina, Jonathan Ben-Tzur, Moritz Hardt, Ben-
jamin Recht, and Ameet Talwalkar. A system for massively parallel hyperparameter tuning. Proceedings
of Machine Learning and Systems , 2:230–246, 2020. 27
[75] Guilin Liu, Fitsum A Reda, Kevin J Shih, Ting-Chun Wang, Andrew Tao, and Bryan Catanzaro. Image
inpainting for irregular holes using partial convolutions. In Proceedings of the European Conference on
Computer Vision (ECCV) , pages 85–100, 2018. 27
[76] Jiahui Yu, Zhe Lin, Jimei Yang, Xiaohui Shen, Xin Lu, and Thomas S Huang. Generative image
inpainting with contextual attention. In Proceedings of the IEEE conference on computer vision and
pattern recognition , pages 5505–5514, 2018. 27
[77] Maximilian Stölzle, Takahiro Miki, Levin Gerdes, Martin Azkarate, and Marco Hutter. Reconstructing oc-
cluded elevation information in terrain maps with self-supervised learning. IEEE Robotics and Automation
Letters , 7(2):1697–1704, 2022. 27
[78] Zhou Wang, Alan C Bovik, Hamid R Sheikh, and Eero P Simoncelli. Image quality assessment: from error
visibility to structural similarity. IEEE transactions on image processing , 13(4):600–612, 2004. 27, 28
[79] DeepMind, Igor Babuschkin, Kate Baumli, Alison Bell, Surya Bhupatiraju, Jake Bruce, Peter Buchlovsky,
David Budden, Trevor Cai, Aidan Clark, Ivo Danihelka, Antoine Dedieu, Claudio Fantacci, Jonathan
Godwin, Chris Jones, Ross Hemsley, Tom Hennigan, Matteo Hessel, Shaobo Hou, Steven Kapturowski,
Thomas Keck, Iurii Kemaev, Michael King, Markus Kunesch, Lena Martens, Hamza Merzic, Vladimir
Mikulik, Tamara Norman, George Papamakarios, John Quan, Roman Ring, Francisco Ruiz, Alvaro
Sanchez, Laurent Sartran, Rosalia Schneider, Eren Sezener, Stephen Spencer, Srivatsan Srinivasan, Miloš
Stanojevi ´c, Wojciech Stokowiec, Luyu Wang, Guangyao Zhou, and Fabio Viola. The DeepMind JAX
Ecosystem, 2020. 28
14A Appendix on proof of Input-to-State Stability (ISS)
In the following, we will write ∥A∥to denote the induced norm of matrix Aandλm(A),λM(A)to refer to its
minimum and maximum Eigenvalue respectively.
<latexit sha1_base64="jxCwLauGKavr6Ye9VQzgiI7Mxbs=">AAACMHicdVBNSyNBEO3xM8ZdN+rRS2MQsqChJy4ab4IHBT0omChkwtDTqWhjT8/QXaOEYX6SF3+KXhQU8eqvcCaJoMvug4bXr15RVS+IlbTI2JMzMTk1PTNbmivP//i58KuyuNS2UWIEtESkInMecAtKamihRAXnsQEeBgrOgqu9on52DcbKSJ/iIIZuyC+07EvBMZf8yr4XAPKap9pgkHooVQ/SQeZ7IcdLE6Y3WQ199pt6pjCsU9wYfaWmQ4vgKj08ysp+pcrqO81N5jLK6myIgmy6rMGoO1aqZIxjv3Lv9SKRhKBRKG5tx2UxdlNuUAoFWdlLLMRcXPEL6ORU8xBsNx0enNG1XOnRfmTyp5EO1a8dKQ+tHYRB7iyWtH/XCvFftU6C/WY3lTpOELQYDeonimJEi/RoTxoQqAY54cLIfFcqLrnhAvOMixA+L6X/J+1G3d2qb538qe42xnGUyApZJTXikm2ySw7IMWkRQW7JA3kmL86d8+i8Om8j64Qz7lkm3+C8fwA2/qkA</latexit> (k˜yw(t0)k,t t0)2KL<latexit sha1_base64="AsSlD7JgiwnltDbvB3dY2OlBUxc=">AAAB/XicdVDLSsNAFJ3UV62v+Ni5GSyCq5JUiS4LblxWsA9oQphMJu3QyYOZiRJD8FfcuFDErf/hzr9x0kaoogcGDufcyz1zvIRRIQ3jU6stLa+srtXXGxubW9s7+u5eX8Qpx6SHYxbzoYcEYTQiPUklI8OEExR6jAy86WXpD24JFzSObmSWECdE44gGFCOpJFc/sCVlPsmzwrVDJCc8zO8KV28aLWMGuEhM69SwoFkpTVCh6+ofth/jNCSRxAwJMTKNRDo54pJiRoqGnQqSIDxFYzJSNEIhEU4+S1/AY6X4MIi5epGEM3VxI0ehEFnoqckyofjtleJf3iiVwYWT0yhJJYnw/FCQMihjWFYBfcoJlixTBGFOVVaIJ4gjLFVhDVXC90/h/6TfbplWy7o+a3baVR11cAiOwAkwwTnogCvQBT2AwT14BM/gRXvQnrRX7W0+WtOqnX3wA9r7F8oPlhA=</latexit>˜yw
(a) GAS: g(u) = 0
<latexit sha1_base64="rTQBn89HPHzifYsoG8uv5YsyQwg=">AAACaHicdVFdb9MwFHXC1+j4CF9CiBdrFVqqQZWUrYO3SbzwOCTaTaqryHFvUmt2EuwbUBVF/Efe+AG88CtwukwCBFeyfHzOvde+x2mlpMUo+u75167fuHlr5/Zg987de/eDBw/ntqyNgJkoVWnOU25ByQJmKFHBeWWA61TBWXrxrtPPPoOxsiw+4qaCpeZ5ITMpODoqCb6yFJCHTM3BIGUo1QqaTZswzXFtdPOlDTGJRpSZLuElxVfb4wFlOdeaU6YgQxpSZusqaZzWMZ8o7vd723fOwzrE/dFVI7fJfI2jQRIMo/E0Pjw+img0jrbRgdeTt/ERjXtmSPo4TYJvbFWKWkOBQnFrF3FU4bLhBqVQ0A5YbaHi4oLnsHCw4Brsstka1dIXjlnRrDRuFUi37O8VDdfWbnTqMrv57d9aR/5LW9SYvVk2sqhqhEJcXpTVimJJO9fpShoQqDYOcGGkeysVa264QPc3nQlXk9L/g/lkHE/H0w+Hw5NJb8cOeU72SEhickxOyHtySmZEkB/ervfYe+L99AP/qf/sMtX3+ppH5I/w934BRoC2NQ==</latexit> (k˜yw(t0)k,t t0)+ ✓supt0t0tkg(u(t0))k◆
<latexit sha1_base64="jxCwLauGKavr6Ye9VQzgiI7Mxbs=">AAACMHicdVBNSyNBEO3xM8ZdN+rRS2MQsqChJy4ab4IHBT0omChkwtDTqWhjT8/QXaOEYX6SF3+KXhQU8eqvcCaJoMvug4bXr15RVS+IlbTI2JMzMTk1PTNbmivP//i58KuyuNS2UWIEtESkInMecAtKamihRAXnsQEeBgrOgqu9on52DcbKSJ/iIIZuyC+07EvBMZf8yr4XAPKap9pgkHooVQ/SQeZ7IcdLE6Y3WQ199pt6pjCsU9wYfaWmQ4vgKj08ysp+pcrqO81N5jLK6myIgmy6rMGoO1aqZIxjv3Lv9SKRhKBRKG5tx2UxdlNuUAoFWdlLLMRcXPEL6ORU8xBsNx0enNG1XOnRfmTyp5EO1a8dKQ+tHYRB7iyWtH/XCvFftU6C/WY3lTpOELQYDeonimJEi/RoTxoQqAY54cLIfFcqLrnhAvOMixA+L6X/J+1G3d2qb538qe42xnGUyApZJTXikm2ySw7IMWkRQW7JA3kmL86d8+i8Om8j64Qz7lkm3+C8fwA2/qkA</latexit> (k˜yw(t0)k,t t0)2KL<latexit sha1_base64="AsSlD7JgiwnltDbvB3dY2OlBUxc=">AAAB/XicdVDLSsNAFJ3UV62v+Ni5GSyCq5JUiS4LblxWsA9oQphMJu3QyYOZiRJD8FfcuFDErf/hzr9x0kaoogcGDufcyz1zvIRRIQ3jU6stLa+srtXXGxubW9s7+u5eX8Qpx6SHYxbzoYcEYTQiPUklI8OEExR6jAy86WXpD24JFzSObmSWECdE44gGFCOpJFc/sCVlPsmzwrVDJCc8zO8KV28aLWMGuEhM69SwoFkpTVCh6+ofth/jNCSRxAwJMTKNRDo54pJiRoqGnQqSIDxFYzJSNEIhEU4+S1/AY6X4MIi5epGEM3VxI0ehEFnoqckyofjtleJf3iiVwYWT0yhJJYnw/FCQMihjWFYBfcoJlixTBGFOVVaIJ4gjLFVhDVXC90/h/6TfbplWy7o+a3baVR11cAiOwAkwwTnogCvQBT2AwT14BM/gRXvQnrRX7W0+WtOqnX3wA9r7F8oPlhA=</latexit>˜yw (b) ISS
Figure 6: Illustration of global asymptotic stability for the unforced system with g(u) = 0 and input-to-state
stability for the forced system, where the black dashed line denotes the input u(t).
We introduce some expressions often used throughout this section: The gradient of Vµ(˜yw)w.r.t. the residual
coordinate ˜ywis given by
∂Vµ
∂˜yw(˜yw) =PV˜yw+
tanh(¯ xw+ ˜xw+b)
0n
−
tanh(¯ xw+b)
0n
. (14)
Next, the Hessian of the Lyapunov candidate can be derived as
HV(˜xw) =∂2Vµ
∂˜y2w=
Kw+S2
sech(˜xw)µ M w
µ MT
w Mw
∈R2n×2n, (15)
where
Ssech(˜xw) = diag(sech(¯ xw+ ˜xw+b))∈Rn×n≻0∀˜xw∈Rn. (16)
Furthermore, the Schur complement of PVis given by
SPV=Mw−µ2MT
wKwMw (17)
A.1 Potential force and energy
Lemma 3. Let˜xw∈Rnbe generalized coordinates and ¯xw, b∈Rnconstants. Then, the potential force of
system (4)
˜fUw(˜xw) =Kw(¯xw+ ˜xw) + tanh(¯ xw+ ˜xw+b), (18)
stems from the potential
Uw(˜xw) =nX
i=1Z˜xw,i
0tanh(¯ xw,i+σ+bi) dσ−nX
i=1Z˜xw,i
0tanh(¯ xw,i+bi) dσ∈R. (19)
Proof. First, we take the derivative of U(˜xw):
∂Uw
∂˜xw=Kw(¯xw+ ˜xw) + tanh(¯ xw+ ˜xw+b) =˜fUw. (20)
The Hessian of the potential is given by
HUw(˜xw) =∂2Uw
∂˜x2w=∂˜fUw
∂˜xw=Kw+S2
sech(˜xw)∈Rn×n. (21)
AsKw≻0⇒Kw=KT
w, we can easily show that the potential force is symmetric:
HT
Uw=KT
w+S2
sech(˜xw)T=Kw+S2
sech(˜xw) =HUw. (22)
15A.2 Proof of Lemma 1: single & isolated equilibrium
Lemma 1 restated. LetKw≻0. Then, the dynamics defined in (3)have a single, isolated equilibrium
¯yw=
¯xT
w0TT.
Proof. We regard the characteristic equation as a function: heq(xw) = tanh( xw+b) +Kwxw. For there
to exist multiple equilibria, heq(¯xw) = 0 would need to be true for multiple ¯x. However, we take the partial
derivative of heq(xw)w.r.t. xwand see that
∂heq
∂xw=Kw+S2
sech(xw)≻0,∀xw∈RnwithSsech(xw) = diag(sech( xw+b))∈Rn×n(23)
asSsech(xw)≻0∀xw∈RnandKw≻0. Therefore, heq(xw)is continuously increasing and can only cross
the zero line once.
A.3 Proof of Lemma 2: Validity of strict Lyapunov candidate Vµ(˜yw)
Lemma 4. Suppose Mw≻0, Kw≻0and0< µ <√
λm(Mw)λm(Kw)
∥Mw∥:=µV. Then SPV, as defined in (17),
is positive definite.
Proof. The minimum Eigenvalue of SPVis bounded by
λm(SPV)≥λm(Mw)−µ2∥MT
wKwMw∥,
≥λm(Mw)−µ2∥Mw∥2
λw(Kw)(24)
Based on the assumption Mw≻0, Kw≻0, we can state∥Mw∥
λw(Kw)>0. Therefore, the critical case for the
lower bound on λm(SPV)isµ=√
λm(Mw)λm(Kw)
∥Mw∥:=µV. Hence,
λm(SPV)> λm(Mw)−λm(Mw)λm(Kw)
∥Mw∥2∥Mw∥2
λw(Kw)= 0 (25)
Consequently, the Eigenvalue sensitivity theorem [46] demands that SPV≻0.
Lemma 5. LetMw≻0, Kw≻0, and 0< µ <√
λm(Mw)λm(Kw)
∥Mw∥:=µV. Then, it follows that PV≻0and
HV(˜xw)≻0∀˜xw∈Rn.
Proof. By inspecting the expressions for PV≻0andHV(˜xw)≻0∀˜xw∈Rnin Equations (5)and(15),
respectively, it can be easily seen that HV(˜xw)⪰PV∀˜xw∈R. As Lemma 4 states that the Schur complement
ofPVis positive definite, it follows that HV(˜xw)⪰PV≻0.
Lemma 6. Suppose ¯xw,˜xw, b∈Rnandn∈N+. Then,
hV,th(˜xw) =nX
i=1Z˜xw,i
0tanh(¯ xw,i+σ+bi) dσ−nX
i=1Z˜xw,i
0tanh(¯ xw,i+bi) dσ (26)
is a positive semi-definite function.
Proof. Proving hV,th(˜xw)≥0is equivalent to showing that the scalar function ˘hV,th(r) =Rr
0tanh( σ+
a) dσ−Rr
0tanh( a) dσ≥0∀r, a∈R, where we set r= ˜xw,ianda= ¯xw,i+bi.
We strive to find the critical points (i.e., minimas and maximas) ¯rof˘hV,th(r)and, for this, analyze where the
first derivative of ˘hV,th(r)is zero
∂˘hV,th
∂r(¯r) = tanh(¯ r+a)−tanh( a) = 0 , (27)
which is the case only for ¯r= 0. Next, we compute the second derivative at ¯ras
∂˘hV,th
∂r(¯r) = sech2(¯r) = 1 . (28)
Thus, ˘hV,th(r)is convex and its global minimum at ¯r= 0takes the value hV,th(0) = 0 . As a result, hV,th(˜xw)
is also positive semi-definite.
16A.3.1 Proof of Lemma 2:
Lemma 2 restated. The scalar function Vµ(˜yw)defined in (5)is continuously differentiable and verifies the
condition Vµ(0) = 0 . Furthermore, let Mw, Kw≻0. Now, if we choose 0< µ <√
λm(Mw)λm(Kw)
∥Mw∥:=µV,
thenVµ(˜yw)>0∀˜yw∈R2n\ {0}. Additionally, then Vµ(˜yw)is radially unbounded as ∥˜yw∥ → ∞ ⇒
Vµ(˜yw)→ ∞ .
Proof. Step 1: It can be easily seen that Vµ(˜yw)in (5) is smooth and continuously differentiable.
Step 2: Proof that Vµ(0) = 0 .
Vµ(0) = 0 +nX
i=1Z0
0tanh(¯ yw,i+σ+bi) dσ−nX
i=1Z0
0tanh(¯ yw,i+bi) dσ= 0. (29)
Step 3: Proof that the Lyapunov candidate is positive definite; i.e., Vµ(˜yw)>0∀˜yw∈Rn\ {0}.
As the gradient of the Lyapunov candidate, as defined in (14), is zero for ˜yw= 0:
∂Vµ
∂˜yw(0) =
tanh(¯ xw+b)
0n
−
tanh(¯ xw+b)
0n
= 0, (30)
˜yw= 0 is a critical point of Vµ(˜yw). According to Lemma 5, the Hessian in (15) is positive-definite [ 56]:
HV(˜yw)≻0∀˜yw∈R2n. With that, (5)is convex and its global minimum is at ˜yw= 0, where Vµ(0) = 0 . In
summary, we state Vµ(˜yw)>0∀˜yw∈Rn\ {0}.
Step 4: Proof that the Lyapunov candidate is radially unbounded: i.e., ∥˜yw∥ → ∞ ⇒ Vµ(˜yw)→ ∞ . Lemma 6
is exploited for identifying a lower bound on Vµ(˜yw):
Vµ(˜yw) =1
2˜yT
wPV˜yw+nX
i=1Z˜xw,i
0tanh(¯ xw,i+σ+bi) dσ−nX
i=1Z˜xw,i
0tanh(¯ xw,i+bi) dσ,
≥1
2˜yT
wPV˜yw≥1
2λm(PV)∥˜yw∥2.(31)
Lemma 5 tells us that PV≻0and with that λm(PV)>0. Therefore, if ∥˜yw∥ → ∞ , it also follows that
Vµ(˜yw)→ ∞ .
A.4 Proof of Theorem 1: Global asymptotic stability of unforced network
The Lemmas introduced below are used to prove Theorem 1.
Lemma 7. Suppose ¯xw,˜xw, b∈Rnandn∈N+. Then, the function h˙V,th(˜xw)defined as
h˙V,th(˜xw) = (tanh(¯ xw+ ˜xw+b)−tanh(¯ xw+b))T˜xw, (32)
is positive semi-definite.
Proof. Proving h˙V,th(˜xw)≥0is equivalent to proving that the scalar function ˘h˙V,th(r) =
(tanh( r+a)−tanh( a))r≥0∀r, a∈R, where we set r= ˜xw,ianda= ¯xw,i+bi. Now, we ex-
pand the hyperbolic tangent:
˘h˙V,th(r) = (tanh( r+a)−tanh( a))r=e2(r+a)−1
e2(r+a)+ 1−e2a−1
e2a+ 1
r,
=2e2a 
e2r−1
e2r+4a+e2r+2a+e2a+ 1r≥0,(33)
as the denominator e2r+4a+e2r+2a+e2a+ 1>0∀r∈Rand as sign 
2e2a 
e2r−1
= sign( r). For
example, e2r−1≥0∀r≥0. Analog, e2r−1<0∀r <0.
Lemma 8. LetMw≻0,Kw≻0, and Dw≻0. Also, let µ∈R+be chosen such that 0< µ <
λm(Dw)
λm(Mw)+∥Dw∥2
4λm(Kw):=µ˙V. Then, the matrix P˙V=µKw1
2µDw
1
2µDT
wDw−µMw
∈Rnis positive definite.
Proof. The Schur complement of P˙Vis given by
SP˙V=Dw−µMw−1
4µDT
wK−1
wDw. (34)
17The lower bound on the smallest Eigenvalue of SP˙Vcan be identified as
λm 
SP˙V
≥λm(Dw)−µ λm(Mw)−µ∥Dw∥2
4λm(Kw). (35)
AsKw, Dw≻0, we know that∥Dw∥2
λm(Kw)>0. Therefore, the case µ=λm(Dw)
λm(Mw)+∥Dw∥2
4λm(Kw):=µ˙Vdetermines
the lower bound on λm(SP˙V):
λm 
SP˙V
> λm(Dw)−µ˙V
λm(Mw)−∥Dw∥2
4λm(Kw)
= 0. (36)
We conclude, based on the Eigenvalue sensitivity theorem of symmetric matrices [ 46], that SP˙V≻0and with
thatP˙V≻0[56].
A.5 Proof of Theorem 2: Proof of Input-to-State Stability (ISS)
Lemma 9. Let¯xw,˜xw, b∈Rn. Then,
hV,th(˜xw) =nX
i=1Z˜xw,i
0tanh(¯ xw,i+σ+bi) dσ−nX
i=1Z˜xw,i
0tanh(¯ xw,i+bi) dσ≤2|˜xw|. (37)
Proof. Proving hV,th(˜xw)≤2|˜xw|is equivalent to proving that the scalar function ˘hV,th(r) =Rr
0tanh( σ+
a) dσ−Rr
0tanh( a) dσ≤2|r| ∀r, a∈R, where we set r= ˜xw,ianda= ¯xw,i+bi. We perform the
integration contained in ˘hV,th(r):
˘hV,th(r) =Zr
0tanh( σ+a) dσ−Zr
0tanh( a) dσ,
˘hV,th(r) = log(cosh( r+a))−log(cosh( a))−tanh( a)r.(38)
Next, we demonstrate that the slope of 2|r|is always larger than the magnitude of the slope of ˘hV,th(r):∂˘hV,th
∂r=|tanh( r+a)−tanh( a)|<2 =∂
∂r(2|r|). (39)
Additionally, ˘hV,th(0) = 2 |0|= 0. We conclude that ˘hV,th(r)≤2|r| ∀r∈Rand with that, hV,th(˜xw)≤
2|˜xw| ∀˜xw∈Rn.
Lemma 10. LetMw≻0andKw≻0. Then, (5)is bounded by the two scalar, class K∞functions
α1(r) =1
2λm(PV)r2andα2(r) =1
2λM(PV)r2+ 2√n r:α1(∥˜yw∥2
2)≤Vµ(˜yw)≤α2(∥˜yw∥)2
2.
Proof. With Lemma 2, we already showed that Vµ(˜yw)is a Lyapunov candidate. Now, we additionally also
verify the conditions for ISS-Lyapunov candidates [40].
Step 1: Establishing bounds on Vµ(˜yw).
We first identify the lower bound of Vµ(˜yw)by leveraging Lemma 6:
Vµ(˜yw) =1
2˜yT
wPV˜yw+nX
i=1Z˜xw,i
0tanh(¯ xw,i+σ+bi) dσ−nX
i=1Z˜xw,i
0tanh(¯ xw,i+bi) dσ,
=1
2˜yT
wPV˜yw+hV,th(˜xw),
≥1
2˜yT
wPV˜yw≥1
2λm(PV)∥˜yw∥2
2=α1(∥˜yw∥2).(40)
Similarly, we derive an upper bound for Vµ(˜yw)exploiting Lemma 9.
Vµ(˜yw) =1
2˜yT
wPV˜yw+nX
i=1Z˜xw,i
0tanh(¯ xw,i+σ+bi) dσ−nX
i=1Z˜xw,i
0tanh(¯ xw,i+bi) dσ
≤1
2λM(PV)∥˜yw∥2
2+ 2∥˜xw∥1≤1
2λM(PV)∥˜yw∥2
2+ 2√n∥˜xw∥2
≤1
2λM(PV)∥˜yw∥2
2+ 2√n∥˜yw∥2=α2(∥˜yw∥2).(41)
Step 2: Proof that α1(r), α2(r)belong to class K∞.
According to Lemma 5, PV≻0and with that λm(PV)>0. First, we analyze the behavior of α1(r): as it is
strictly increasing and α1(0) = 0 , it belongs to class K. Furthermore, we can evaluate limr→∞α1(r) =∞.
Therefore, α1(r)∈ K∞[40].α2(r)is also strictly increasing for r∈[0,∞),α2(0) = 0 , and it is radially
unbounded as limr→∞α2(r) =∞. For that reason, α2(r)∈ K∞as well.
18A.5.1 Proof of Theorem 2
Theorem 2 restated. Suppose Mw, Kw, Dw≻0,0< θ < 1, and that we choose 0< µ < min{µV, µ˙V}}.
Then, (4)is globally Input-to-State Stable (ISS) such that the solution ˜yw(t)verifies
∥˜yw∥2≤β(∥˜yw(t0)∥2, t−t0) +γ
sup
t0≤τ≤t∥g(u(τ))∥2
,∀t≥t0 (42)
where β(r, t)∈ KL ,γ(r) =r
(1+µ2)λM(PV)r2+4θ√n√
1+µ2λm(P˙V)r
θ2λm(PV)λ2m(P˙V)∈ K.
Proof. Step 1: Bounds on ISS-Lyapunov candidate.
Lemma 10 provides the K∞functions α1(r) =1
2λm(PV)r2andα2(r) =1
2λM(PV)r2+ 2√n rsuch that
α1(∥˜yw∥2
2)≤Vµ(˜yw)≤α2(∥˜yw∥)2
2.
Step 2: Minimum energy dissipation.
Let0< µ < min{µV, µ˙V}}as in the proof of Theorem 1. We compute the input-dependent time-derivative
of the ISS Lyapunov candidate. We do not repeat the derivations already made as part of (7)(e.g., exploiting
Lemmas 7 and 8).
˙Vµ(˜yw, u(t)) =−˜yT
wP˙V˜yw−µ(tanh(¯ xw+ ˜xw+b)−tanh(¯ xw+b))T˜xw+ ˜yT
w
µ g(u(t))
g(u(t))
,
≤ − λm(P˙V)∥˜yw∥2
2+˜yT
w
µ g(u(t))
g(u(t))
1,
≤ − λm(P˙V)∥˜yw∥2
2+∥˜yw∥2
µ g(u(t))
g(u(t))
2,
≤ − λm(P˙V)∥˜yw∥2
2+p
1 +µ2∥˜yw∥2∥g(u(t))∥2,(43)
where we leveraged Hölder’s inequality. We choose θsuch that 0< θ < 1. As a consequence,
˙Vµ(˜yw, u(t))≤ −(1−θ)λm(P˙V)∥˜yw∥2
2,∀ ∥˜yw∥2≥p
1 +µ2
θ λm(P˙V)∥g(u(t))∥2>0. (44)
We define
α3(r) = (1 −θ)λm(P˙V)r2, andρ(r) =p
1 +µ2
θ λm(P˙V)r. (45)
Lemma 8 shows that λm(P˙V)>0. Therefore, α3(r)is a continuous positive function. Furthermore, as µ >0,
ρ(r)is a strictly increasing for r∈[0,∞). Additionally with ρ(0) = 0 verified, it can be stated that ρ(r)
belongs to class K[40]. We conclude that
˙Vµ(˜yw, u(t))≤ −α3 
∥˜yw∥2
2
,∀ ∥˜yw∥2≥ρ(∥g(u(t))∥2)>0. (46)
Step 3: Conclusions.
As a result of Steps 1 and 2, the system is input-to-state stable, and with that, the solution ˜ytsatisfies [40]
∥˜yw∥2≤β(∥˜yw(t0)∥2, t−t0) +γ 
sup
t0≤t′≤t∥g(u(t′))∥2!
, (47)
with
γ(r) =α−1
1◦α2◦ρ(r) =s
(1 +µ2)λM(PV)r2+ 4θ√np
1 +µ2λm(P˙V)r
θ2λm(PV)λ2m(P˙V). (48)
Indeed, based on Theorem 1 and the associated proof, we can easily verify that γ(r)is strictly increasing for
r∈[0,∞)and that γ(0) = 0 . As a consequence, γ(r)∈ K [40].
19B Appendix on an approximate closed-form solution for coupled oscillator
networks
(a) Parameters of a harmonic oscillator
(b) Time evolution of a harmonic oscillator
 (c) Damping regimes of a harmonic oscillator
Figure 7: Panel 7(a) : Parameters of a forced and damped harmonic oscillator: mi∈R+denotes the mass,
κi∈R+the stiffness, and ki∈R+the damping coefficient. The position and velocity of the oscillator
are measured as xi(t)∈Rand˙xi(t)∈R, respectively. The oscillator can be excited by the (potentially
time-varying) external forcing Fi(t)∈R.Panel 7(b): Time evolution of a 1D harmonic oscillator for different
values of κi,di, all in the undamped or underdamped regime. Panel 7(c): The four damping regimes of a
harmonic oscillator: undamped ( ζ= 0), underdamped ( 0< ζ < 1), critically damped ( ζ= 1), and overdamped
(zeta > 1).
B.1 Closed-form solution to a forced harmonic oscillator
As introduced in (1), we consider the linear dynamics of a 1D forced harmonic oscillator with state yi=
[xi˙xi]∈R2
˙yi=dxi
dtd ˙xi
dt
=fld,i(yi, Fi) =
˙xi
Fi(t)−κixi(t)−di˙xi(t)
, (49)
where Fi(t)∈Ris the externally applied force acting on the oscillator.
The characteristic equation for the unforced dynamics (i.e., Fi(t) = 0) can be stated as [48]
λ2+ 2ζiωn,iλ+ω2
n,i= 0, with the solutions λ1,2=−ζiωn,i±ωn,iq
ζ2
i−1, (50)
where ωn,i=√κiandζi=di
2√κiare the natural frequency and the damping factor of the ith homogeneous
oscillator, respectively. This harmonic oscillator exhibits three regimes: underdamped ( ζi<1), critically
damped ( ζi= 1), and overdamped regime ( ζi>1).
We approximate the forcing using the Heavyside function H(t):Fi(t) =Fi(tk)H(t), where Fi(tk)is the
constant external forcing as computed by (10). The solution for ζi̸= 1is given by [48]
yi(tk+1) =
xi(tk+1)
˙xi(tk+1)
=(c1,icos(βiδt) +c2,isin(βiδt))e−αiδt+Fi
κi
−((c1,iαi−c2,iβi) cos( βiδt) + (c1,iβi+c2,iαi) sin( βiδt))e−αiδt
,(51)
where δt=tk+1−tk,αi=ζiωn,i, and βi=ωn,ip
1−ζ2
i. After enforcing the initial conditions
xi(tk), xi(tk), the integration constants
c1,i=xi(tk)−Fi(tk)
κi, c 2,i=−2j˙xi(tk) +αi
xi(tk)−Fi
ki
∆λi, (52)
20can be identified with ∆λi=λi,2−λi,1=−2βij, where jis the imaginary value. While we could derive
the solution for the critically damped case di<2√κiseparately, we instead approximate it in our network
dynamics with (51) by setting ∆λi∼=sign(−2βij)ϵ|2βij|< ϵ
−2βij |2βij| ≥ϵ, where ϵ∈R+≪1is a small, positive
value.
B.2 Algorithmic implementation
We can now leverage the closed form solution to the evolution of a single, decoupled damped harmonic oscillator
of (51) to solve the integral in (11)
y(tk+1)≈fCFA−CON(y(tk), u(tk)),

x(tk+1)
˙x(tk+1)
≈
(c1⊙cos(β δt) +c2⊙sin(β δt))⊙e−α δt+F(tk)
κ
−((c1⊙α−c2⊙β) cos( β δt) + (c1⊙β+c2⊙α) sin( β δt))⊙e−α δt
,(53)
with
κ= diag( K11. . . K nn), d= (D11. . . D nn), ωn=√κ, ζ=d
2√κ, α=ζ⊙ωn, β=ωnp
1−ζ2,
F(tk) =g(u(tk))−(K−κ)x(tk)−(D−d) ˙x(tk)−tanh ( Wx(tk) +b),
c1=x(tk)−F(tk)
κ, c 2=1
β
˙x(tk) +α⊙
x(tk)−F(tk)
κ
.
(54)
We summarize the approach of integrating/rolling out the CFA-CON dynamics in Algorithm 1.
Algorithm 1 Rollout of CFA-CON.
Inputs: initial state y(t0), input sequence {u(t0), . . . u (tk), . . . u (tN)}
Outputs: state sequence {y(t0), . . . y (tk), . . . y (tN)}
1:k←0
2:while k≤Ndo
3: (x(tk),˙x(tk))←y(tk)
4: F(tk)←g(u(tk))−(K−κ)x(tk)−(D−d) ˙x(tk)−tanh ( Wx(tk) +b)
5: ωn, ζ←√κ,d
2√κ▷Compute the characteristics of the decoupled harmonic oscillators.
6: α, β←ζ⊙ωn, ωnp
1−ζ2
7: c1←x(tk)−F(tk)
κ▷Compute integration constants using initial conditions.
8: c2←1
β
˙x(tk) +α⊙
x(tk)−F(tk)
κ
9: δt=tk+1−tk ▷Set time step.
10: ▷Update state with approximated closed-form solution.
11: x(tk+1)←(c1⊙cos(β δt) +c2⊙sin(β δt))⊙e−α δt+F
κ
12: ˙x(tk+1)← − ((c1⊙α−c2⊙β) cos( β δt) + (c1⊙β+c2⊙α) sin( β δt))⊙e−α δt
13: k←k+ 1 ▷Update time index.
14:end while
B.3 Approximation bounds for CFA-CON
Lemma 11 demonstrates how, for the particular case of no external input and linearly decoupled oscillators
(which we are always free to choose), we can establish bounds on the approximation error when using the
closed-form solution instead of the ground-truth coupled oscillator dynamics.
Lemma 11. Suppose that the network is unforced with g(u(t)) = 0 and that K= diag( κ1, . . . , κ n),D=
diag( d1, . . . , d n)such that the oscillators are not linearly coupled. Then, given any t≥0, and the initial state
y(0)∈R2n, the error between the continuous dynamics ¨x(t)of(2)and the approximated dynamics ˆ˙x(t)in
(10), is bounded by ∥¨x(t)−ˆ¨x(t)∥ ≤2.
Proof. (2), (10) and F=−f¨x,nld(y(0),0)give us
∥¨x(t)−ˆ¨x(t)∥= (f¨x,ld(y(t),0) +f¨x,nld(y(t),0))−f¨x,ld(y(t), F),
=−Kx(t)−D˙x−tanh( Wx(t) +b) +Kx(t) +D˙x+ tanh( Wx(0) + b),
=∥−tanh( Wx(t) +b) + tanh( Wx(0) + b)∥ ≤ 2.(55)
21B.4 Empirical evaluation of approximation error
In Table 3, we present a comparison of CFA-CON with several other strategies for integrating nonlinear
dynamics, such as CON. Following the implicit assumption made in Section B, we consider the case of
g(u) = 0 ,K= diag( κ1, . . . , κ n)andD= diag( d1, . . . , d n)but with the hyperbolic coupling between the
oscillators active (i.e., a full Wmatrix). Integrating the dynamics at a very small time step (i.e., δt= 5e−5 s)
with a high-order ODE solver would give us a very accurate solution, but this is computationally infeasible in
practice. We, therefore, regard this as the upper bound on the accuracy of the solution. A feasible solution would
be to implement either a high-order solver such as Tsit5 at a larger integration time-step, e.g., δt= 1e−1 s)
or a low-order solver with a slightly smaller integration time step, e.g., δt= 5e−2 s). Therefore, we also
benchmark these options. We also benchmark an implementation specialized on the underdamped case (i.e.,
ζi<1): Closed-Form Approximation of the Underdamped Coupled Oscillator Network (CFA-UDCON). This
specialized implementation allows us to avoid using complex numbers in the algorithm and reduces the number
of computations necessary for calculating the approximated solution. As a result, we see a considerable increase
in the sim-time to real-time factor.
B.4.1 Integration error
We perform the integration error benchmark over 100different network configurations, all consisting of 50
oscillators ( n= 50 ): First, we sample the natural frequency of the ith oscillator from a uniform distribution as
ωn,i∼ U(0.05 Hz ,0.5 Hz) , then we sample κi∼ U(0.2 N/m,2 N/m)such that K= diag( κ1, . . . , κ n)≻0,
which lets us determine each mass mi=κi
ω2
n,i. Next, the damping ratio is determined as ζi∼ U(0.1,0.9)and
ζi∼ U(0.1,2.0)for the underdamped and general case, respectively. As a result, D= diag( d1, . . . , d n)≻0
withdi= 2ζi√miκigiven. Finally, by leveraging the Cholesky decomposition, we sample a W≻0and
bi∼ U(−1,1). We compute the estimation error of all integrated trajectories with respect to the high-precision
solution (i.e., Tsitouras’ 5/4 method (Tsit5) at δt= 5e−4 s). For this, we compute the RMSE for each 60 s
trajectory and then take the mean and standard deviation across the 100different network configurations.
B.4.2 Simulation-time to real-time factor
The simulation vs. real-time factor is computed as the simulated rollout duration per second of computational
time. For this, we let each method simulate a 60 strajectory for 100times and record the minimum run time on
an Intel Core i7-10870H CPU (single core) over 10trials. Because of computational constraints, we simulated
with the high-precision Tsit5 solver the trajectory only 5times.
B.4.3 Results
The results in Table 3 show that CFA-CON is 30 % more accurate than the Euler integrator at half of the speed.
Compared against the Tsit5 integrator, CFA-CON exhibits a 1.56x speed increase while being significantly less
accurate. For the underdamped case with ζ <1, the specialized implementation CFA-UDCON is 14.8 %faster
and at the same time 32 % more accurate than the Euler integrator. Furthermore, CFA-UDCON is 3.7x faster
and significantly less accurate than the Tsit5 integrator. We can conclude that in the pure rollout setting (i.e., no
backpropagation involved) for a generic CON, the CFA-CON does not show clear advantages to an appropriately
tuned Euler or Tsit5 solver. However, the specialized version CFA-UDCON demonstrates a 2.4x speed-up at no
reduction of accuracy vs. CFA-CON for underdamped oscillator networks.
22Method RMSE [m]↓ RMSE ζ <1[m]↓ Complexity ↓Sim. time
Real time↑
CON with Tsit5
atδt= 5e−5 sn/a n/a O
nlog27ph
δt
=O(3.5e11) 5 .68x
CON with Tsit5
atδt= 1e−1 s5e−5±1e−5 8e −6±1e−5 O
nnlog27ph
δt
=O(1.8e8) 11310 x
CON with Euler
atδt= 5e−2 s0.010±0.003 0 .022±0.005 O
nlog27h
δt
=O(7.1e7) 36500 x
CFA-CON (our)
withδt= 1e−1 s0.007±0.002 0 .015±0.003 O
nlog27h
δt
=O(3.5e7) 17680 x
CFA-UDCON (our)
withδt= 1e−1 sn/a 0.015±0.003 O
nlog27h
δt
=O(3.5e7) 41900 x
Table 3: Benchmarking of various methods for integrating the CON dynamics. The RMSE is computed with
respect to the Tsitouras’ 5/4 method (Tsit5) (i.e., extremely high accuracy but also extremely high computational
complexity). We denote with nthe number of oscillators in the network (in this case n= 50 ), with pthe order
of the numerical ODE solver, and with δtthe time-step. When stating the complexity, we refer to h=tN−t0as
the rollout horizon in seconds. In this case, we report the results for a horizon of h= 60 s . The RMSE column
states the RMSE of the various integration strategies with respect to the CON with Tsit5 at δt= 5e−5ssolution,
which we consider to be the ground-truth. The RMSE ζ <1computes the same metrics, but this time for a
dataset that contains only underdamped oscillators. TheSim. time
Real timecolumn states the ratio between the duration of
the simulation achieved (in seconds) per second of real-time (i.e., computational time). We report the mean and
standard deviation of the RMSE over 100different network configurations.
23C Appendix on experimental setup and datasets
C.1 Datasets
For all datasets, we generate images of size 32×32px and subsequently normalize the pixels to the interval
[−1,1].
C.1.1 Unactuated mechanical datasets
We consider multiple mechanical datasets based on a standard implementation included in the Toy Physics
category of the NeurIPS 2021 Track on Datasets and Benchmarks publication by Botev et al. [ 26]: mass-spring
with friction (M-SP+F), a single pendulum with friction (S-P+F), and a double pendulum with friction (D-P+F).
All datasets contain 5000 system trajectories in the training set and 1000 trajectories each in the validation and
test set. Each trajectory is generated by first randomly initializing the system, then rolling it out for 3 susing an
Euler integrator with a time step size of 5 ms . Samples are recorded at a rate of 20 Hz (i.e., a time step of 0.05 s).
As a result, each trajectory contains 60images of the system’s state. As all of these datasets are unactuated, we
can deactivate the input-to-forcing mapping component from all models (e.g., set g(u) = 0 for the CON model).
TheM-SP+F dataset contains motion samples of a damped harmonic oscillator with a mass of 0.5 kg, a spring
stiffness of 2 N/m, and a damping coefficient of 0.05 Ns /m. For each trajectory, the initial condition of the mass-
spring is randomly sampled by combining a random sign(q)with a uniformly sampled |q| ∼ U (0.1 m,1 m) .
The position of the mass is rendered with a filled circle in a grayscale image.
TheSP+F andDP+F datasets include the evolutions of a single-link pendulum and double-link pendulum,
respectively, with a mass of 0.5 kg attached to the end of each link, which has a length of 1 m. The dataset
considers a gravitational acceleration of 3 m/s2. A rotational damper with coefficient 0.05 Nms /radprovides
the friction. Similarly to the M-SP+F dataset, both the sign and the absolute value of the initial configuration
are randomly sampled, where |q(0)| ∼ U (1.3 rad,2.3 rad) . The position of each mass is rendered with a filled
circle. For the single-link pendulum, this is done in grayscale, and for the double pendulum, each mass is
rendered with a different color (i.e., blue and red).
C.1.2 Actuated continuum soft robot datasets
The shape of slender and deformable rods can be approximated by considering the deformations along the
1D curve of the backbone [ 57]. While this curve is still infinite-dimensional, it is possible to discretize
the backbone into (many) segments with piecewise constant strain [ 58,57]. Accordingly, we describe the
kinematics of a planar continuum soft robot consisting of nbsegments with the PCS model [ 58]. We assume
each segment has a length of 100 mm and a diameter of 20 mm . The PCS model assumes each segment to
have constant strain. In the planar case, this means that the shape of the ith segment can be parametrized by
ξi= [κbe,iσsh,iσax,i]T∈R3where κbe,iis the bending strain (i.e., the curvature) in the unit rad/m,
σsh,iis the shear strain (dimensionless), and σax,iis the axial elongation strain (dimensionless). The robot’s
configuration is then defined as q=
ξT
1··· ξT
i··· ξT
nbT. In the case of Piecewise Constant Curvature
(PCC), only the bending strain is active as shear strains and axial strains are neglected, and the configuration is
nowq∈Rnb. The PCS model generates EOM in the form of [59]
B(q) ¨q+C(q,˙q) ˙q+G(q) +Kqq+Dq˙q=u(t), (56)
where B(q)≻0andC(q,˙q)are the inertia and Corioli matrices, respectively. G(q)collects the gravitational
forces, Kq≻0is the stiffness matrix, and Dq≻0contains the damping coefficients. u(t)∈Rnbis an external
force acting on the generalized coordinates, and now m=nb.
We derive the corresponding dynamics for a continuum soft robot of material density 600 kg /m3, elastic
modulus of 20 000 Pa , shear modulus of 10 000 Pa , and damping coefficients of 0.000 01 Nm2sfor bending
strains, 0.01 Ns for shear strains, and 0.01 Ns for axial strains, respectively. Gravity is pointing downwards.
The implementation of the dynamics in JAX [ 60] is based on the JSRM library [ 54,61], and we simulate the
robot using a constant integration time step of 0.1 ms . We render grayscale images of the robot with a size of
32×32px at a rate of 50 Hz using OpenCV [ 62]. We generate 10000 trajectories, each of duration 2.0 sand a
sampling time-step of 0.02 s. We use 60 % training, 20 % validation, and 20 % test split. For each trajectory,
we randomly sample a constant actuation/input u∼ U(−umax, umax). We choose the maximum actuation
magnitude to be equal to the sum of the contribution of the potential forces (i.e., elastic and gravitational forces):
umax=G(qmax) +K qmaxwithqmax,i= [5πrad/m,0.2,0.2]T.
We generate three datasets based on this continuum soft robot model: in the CSdataset, we consider one segment
with all three planar strains active (i.e., bending, shear, and elongation). This results in three DOF and six-state
variables in the dynamical model. In the case of the PCC-NS-2 andPCC-NS-3 datasets, we base the dataset on a
simulated system consisting of two planar bending segments, respectively. Each segment is parametrized using
Constant Curvature (CC) [63, 64], which results in two configuration variables and a state dimension of four.
24C.1.3 Unactuated PDE reaction-diffusion dataset
We consider the 1st-order Reaction-diffusion ( R-D) PDE on which (Champion et al, 2019). [ 9] evaluated their
SINDy Autoencoder on. The PDE of the high-dimensional lambda-omega reaction-diffusion system is defined
as
∂u
∂t= 
1−(u2+v2)
u+β(u2+v2)v+d1∂2u
∂q2
1+∂2u
∂q2
2
,
∂v
∂t=−β(u2+v2)u+ (1−(u2+v2))v+d2∂2v
∂q2
1+∂2v
∂q2
2
,(57)
where u(t, q) :R×R2→Randv(t, q) :R×R2→Rare time-dependent two vector fields defined over the
spatial domain q∈R2. We choose the same system parameters and initial condition as Champion et al. [ 9]:
d1, d2= 0.1, andβ= 1and
u(0, q) = tanhq
q2
1+q2
2cos
∠(q1+iq2)−q
q2
1+q2
2
,
v(0, q) = tanhq
q2
1+q2
2sin
∠(q1+iq2)−q
q2
1+q2
2
.(58)
After discretizing the spatial domain into 32points along each dimension, we solve the PDE with a MATLAB
ODE45 solver the solution of u(t, q)andv(t, q)at each time step and grid point. Subsequently, the solution is
multiplied with a Gaussian centered at the origin [9]
¯u(t, q) = exp( −0.01 (q2
1+q2
2)) ¯u(t, q),
¯v(t, q) = exp( −0.01 (q2
1+q2
2)) ¯v(t, q).(59)
We integrate the system from the specified initial condition for 500 s and store samples at a time step of 0.05 s.
We divide the entire sequence into 99subsequences each containing 101samples. We train the models to predict
these subsequences that have a horizon of 5.0 seach.
We stack the solution of ¯u(t, q)and¯v(t, q)contained in the two grids ou(t), ov(t)∈R32×32, respectively, to
gather the images o(t)∈R32×32×2containing two channels. A sample sequence of the generated images is
presented in Apx. 17. We use 60 % of the subsequences (i.e., 59) as our training set, and employ 20 % (i.e.,19)
for the validation and test sets, respectively.
C.2 Autoencoder architecture
For the encoder and decoder, we rely on a vanilla CNNs implemented as a β-V AE [5].
Encoder. The encoder consists of two convolutional layers with kernel size (3,3)and stride (1,1)mapping to
16,32, respectively. The features are flattened and then passed to two linear layers with hidden dimension 256
andnz. Each layer (except for the last) is followed by a layer norm [65] and a LeakyReLU nonlinearity.
Decoder. The decoder first uses two linear layers to map to hidden dimensions of 256and32768 , respectively.
We then apply two 2D transposed convolutions [ 66] reducing the number of channels first to 16, and then to 1.
Each layer (except for the last linear and last convolutional) is followed by a layer norm [ 65] and a LeakyReLU
nonlinearity. Finally, we apply a sigmoid function to clip the output into the range [−1,1].
C.3 Latent dynamic models
In the following section, we provide implementation details for the latent dynamic models that we evaluated as
part of this work.
C.3.1 Coupled Oscillator Network (CON)
We leverage the CON in W-coordinates given by (3)for learning latent space dynamics. Specifically, we
consider the input-to-force mapping g(u)) =B(u)u(t), where B(u)∈Rn×mis parametrized by few-layer
MLP. We report results for two different sizes of the MLP: one medium-sized variant consisting of five layers
with a hidden dimension of 30and a small variant with two layers and a hidden dimension of 12. In both cases,
we use a hyperbolic tangent as a nonlinearity.
When training the model, we jointly optimize M−1
w, Kw, Dw, bandg(u). However, we also need to make
sure that we adhere to the stability constraints M−1
w, Kw, Dw≻0. For this, we leverage the Cholvesky
decomposition [ 67]. Instead of directly learning the full matrix A∈Rnz×nz, we designate the elements of an
upper triangular matrix U∈Rnz×nzas the trainable parameters. The Cholesky decomposition demands that
diag( U11, . . . , U nznz)>0. Therefore, we apply the operation
Uii= log
1 +e˘Uii+ϵ1
+ϵ2, (60)
25where ˘Uis the learned upper triangular matrix, and ϵ1= 1e−6andϵ2= 2e−6are two small, positive values.
The positive-definite matrix Ais now given by A=UTU≻0.
C.3.2 Neural ODEs
We consider two kinds of Neural ODEs [ 27]: the vanilla fNODE :ξ(t)×u(t)7→˙ξ(t)maps latent state and
system actuation directly into a time derivative of the latent state. In contrast, for the MECH-NODE , we enforce
the latent dynamics to have a mechanical structure
˙ξ(t) =dz
dtd ˙z
dt
=
˙z(t)
fMECH −NODE (ξ(t), u(t))
. (61)
We represent both fNODE andfMECH −NODE as MLPs consisting of 5layers, a hidden dimension of 30, and a
hyperbolic tangent nonlinearity.
C.3.3 Autoregressive models
For the below stated autoregressive models, we divide the integration between two (latent) samples ξ(tk)
andξ(tk+1)intoNintintegration steps ξ(tk+δt), . . . , ξ (tk+k′δt), . . . , ξ (tk+Nintδt)where δtis the
integration step size and tk+1=tk+Nintδt. The autoregressive model now describes the transition ξ(tk′+1) =
far(ξ(tk′), u(tk)))∀k′∈1, . . . , N int.
RNN. We implement a standard, single-layer Elman RNN with tanh nonlinearity. The hidden state captures
the latent state of the system. The latent state transition functions are given by
ξ(tk′+1) = tanh( Whhξ(tk′) +bhh+Wihu(tk) +bih), (62)
where Whh∈R2nz×2nz,bhh∈R2nz,Wih∈R2nz×m, andbih∈R2nz.
GRU. We implement a standard, single-layer GRU [ 30] with sigmoid activation function where we interpret
the latent state of the system as the hidden state of the cell. The latent state transition functions are given by
r=σ(Whrξ(tk′) +bhr+Wiru(tk) +bir)
p=σ(Whpξ(tk′) +bhp+Wipu(tk) +bip)
n= tanh ( r⊙(Whnξ(tk′) +bhn) +Winu(tk) +bin)
ξ(tk′+1) = (1 −p)⊙n+p⊙ξ(tk′)(63)
where σis the sigmoid function, ⊙the Hadamard product, Whr, Whp, Whn∈R2nz×2nz,Wir, Wip, Win∈
R2nz×m, andbhr, bir, bip, bin∈R2nz.
coRNN. A time-discrete coRNN is defined by the transition function
ξ(tk′+1) =
z(tk′+1)
˙z(tk′+1)
=
z(tk′) +δt˙z(tk′)
˙z(tk′) +δt(−γz(tk′)−ε˙z(tk′) + tanh ( Wξ(tk′) +V u(tk) +b))
(64)
where γ, ε∈R+are positive, scalar hyperparameters representing the stiffness and damping coefficients,
respectively. The term tanh ( Wξ(tk′) +V u(tk) +b)withW∈R2nz×2nz,V∈Rnz×m, and b∈Rnz
contributes nonlinear state-to-state connections. It is implemented with a linear layer operating on (ξ(tk′), u(tk))
followed by a hyperbolic tangent nonlinearity.
CFA-CON. We adapt the Alg. 1 for predicting the time evolution in latent-space
ξ(tk′+1) =fCFA−CON(ξ(t′
k), u(tk)), (65)
where fCFA−CON describe the autoregressive state transition by the CFA-CON model as introduced in Eq. 11.
C.4 First-order variants of dynamical models
For learning (latent) dynamics of 1st-order systems (e.g., the reaction-diffusion dataset R-D), it might be beneficial
also to formulate the dynamical model to be of 1st-order. While this is straightforward for some dynamics that
do not explicitly take the order into account (e.g., RNN, GRU, NODE), for other models such as coRNN, CON,
and CFA-CON more adjustments are necessary. Namely, we substitute thedz
dtcomponent of the ODE with the
expression ford ˙z
dt. Furthermore, we remove any terms that depend on the velocity ˙z(e.g., damping effects).
Below, we report in detail the adapted, 1st-order formulations for the coRNN, CON, and CFA-CON models.
CON. In the 1st-order version, we adapt the standard, 2nd-order ODE of the CON network as defined in (3)to
˙ξ(t) = ˙z(t) =M−1
w(g(u(t))−Kwz(t)−tanh( z(t) +b)). (66)
26coRNN. In the 1st-order version, we define the transition function as
ξ(tk′+1) =z(tk′+1) =z(tk′)−δt γ z (tk′) +δttanh ( Wξ(tk′) +V u(tk) +b). (67)
CFA-CON. We adapt a 1st-order version of Alg. 1 for predicting the time evolution in latent-space
ξ(tk′+1) =z(tk′+1) =z(tk′) +Ztk′+δt
tk′F(tk′)−κ z(t′) dt′,
F(tk′) =g(u(tk))−(K−κ)z(tk′)−tanh( Wz(tk′) +b),(68)
where the closed-form solution for the integral is given by
Ztk′+δt
tk′F(tk′)−κ z(t′) dt′=F(tk′)
κ
1−e−κ δt
. (69)
C.5 Estimation of the initial latent velocity
For 2nd-order systems and when integrating the evolution of the latent state ξ(t) =
zT(t) ˙zT(t)Tin time,
we need to have access to an initial latent velocity ˙z(t0)such that we can roll out the latent state ξ(t)in time. A
naive approach to estimating such an initial latent velocity would be to encode multiple (at least two) images of
the system at the start of the trajectory into latent space and then perform numerical differentiation (e.g., finite
differences) in latent space. However, we found the resulting ˙z(tk)to be relatively noisy and susceptible to small
encoding errors. Instead, we propose to perform numerical differentiation in image space and then map this
velocity into latent space using the encoder’s Jacobian. First, we estimate the image-space velocity at tkusing
finite differences: ˙o(tk)≈o(tk+1)−o(tk−1)
tk+1−tk−1. The latent velocity is then estimated as ˙z(tk) =∂Φ
∂o(o(tk)) ˙o(tk),
where∂Φ
∂ois obtained with forward-mode automatic differentiation.
C.6 Training
We implement the network dynamics and the neural networks (e.g., encoder, decoder, and MLPs) in JAX [ 60]
and Flax [ 68], respectively. When training or inferring time-continuous dynamical models (e.g., NeuralODE,
CON), we rely on Diffrax [ 47] for numerical integration of the ODE using the Dormand-Prince’s 5/4 method [ 69]
(Dopri5). For the numerical integration of both the time-continuous and the time-discrete models (e.g., RNN,
coRNN, CFA-CON), we use an integration time-step δtof0.025 s and0.01 sfor the Toy Physics [26] and soft
robotic datasets, respectively.
Because of the GPU memory constraints, we limit ourselves to a batch size of 30and80trajectories for the
Toy Physics [26] and soft robotic datasets, respectively. We implement a learning rate schedule consisting
of a warm-up (5 epochs) and a cosine annealing [ 70] period (remaining epochs). We employ an AdamW
optimizer [ 71,72] with β1= 0.9,β2= 0.999for updating both neural network weights (e.g., encoder, decoder)
and parameters of the dynamical model (e.g., K, D w,Mw, etc.).
Before training, we conduct a hyperparameter selection study using Optuna [ 53]. For this, we leverage a
Tree-Structured Parzen Estimator [ 73] for identifying hyperparameters such as the base learning rate, the weight
decay, the loss function weights, and model-specific hyperparameters such as the number of MLP layers, the
hidden dimension of the MLP layers, the γandϵvalues for the coRNN model etc. that minimize the RMSE of
the predicted images. To reduce computational requirements, we employ the Asynchronous Successive Halving
Algorithm [74] to stop unpromising trials early.
C.7 Evaluation metrics
Similar to other publications in the field [ 75,76,77], we state the RMSE, the Peak Signal-to-Noise Ratio (PSNR)
and the Structural Similarity Index Measure (SSIM) [ 78] between the ground-truth image o∈Rho×woand the
predicted image image ˆo∈Rho×wo. We use the separated test set for all evaluation results.
C.7.1 Root Mean-Square Error
The RMSE between the two images is given by
RMSE (o,ˆo) =vuuthoX
u=1woX
v=1(ouv−ˆouv)2
howo. (70)
27C.7.2 Peak Signal-to-Noise Ratio
The PSNR is a function of the total Mean Squared Error (MSE) loss and the maximum dynamic range of the
image L.
PSNR( o,ˆo) = 20 log10(L)−10 log10 hoX
u=1woX
v=1(ouv−ˆouv)2
howo!
. (71)
As we work with normalized images with pixels in the interval [−1,1], the dynamic range is L= 2.
C.7.3 Structural Similarity Index Measure
As simple pixel-by-pixel metrics such as RMSE or PSNR tend to average out any encountered errors, this could
lead to a situation in which a significant reconstruction error in a part of the image is not seen in the RMSE
metric but has a huge impact on the visual appearance of the reconstruction. SSIM [ 78] incorporates not just the
absolute errors , but also the strong inter-dependencies between pixels, especially when they are spatially close.
The SSIM metric between two observations oandˆois given by
SSIM( o,ˆo) =lα(o,ˆo)cβ(o,ˆo)sγ(o,ˆo), (72)
where
l(o,ˆo) =2µoµˆo+C1
µ2o+µ2
ˆo+C1, c(o,ˆo) =2σoσˆo+C2
σ2o+σ2
ˆo+C2, s(o,ˆo) =σoˆo+C3
σoσˆo+C3. (73)
We use the constants C1= (k1L)2,C2= (k2L)2andC3=C2/2, where Lsignifies the dynamic range as
previously used for the PSNR metric, and k1= 0.01andk2= 0.03. The average µand the variance σ2is
computed with a Gaussian filter with a 1D kernel of size 11and sigma 1.5. We set the weight exponents α,β,
andγfor the luminance, contrast, and structure comparisons all to one. We rely on the PIX library [ 79] for
efficiently computing the SSIM metric.
C.8 Compute resources
We trained the models on several desktop workstations for a total duration of roughly 150 h . In total, we relied
on 10x RTX 3090/4090 GPUs, each with 24 GB of VRAM, training the models in parallel. Each workstation
contained between 64 and 128 GB of RAM, and we used roughly 100 GB of total storage. Training each model
on one random seed took between 45 min and4 hdepending on the model type, the integration time constant,
and the number of trainable parameters. The hyperparameter tuning we conducted beforehand (only on one
random seed) took roughly the same time and computational resources as generating the final results.
For the control experiments, we additionally used a laptop with a 16-core Intel Core i7-10870H CPU and 32 GB
RAM. We did not need to use a GPU for evaluating the model during closed-loop control.
28D Appendix on learning latent dynamics
We report the full set of quantitative results, including the additional evaluation metrics PSNR and SSIM, in
Tables 7 to 9. For PCC-NS-2 in Tab. 8, we additionally also recorded the training steps per second on an Nvidia
RTX 3090 GPU with a batch size of 80(which leads to 8080 images per batch). We plot the results of a sweep
across the latent dimensions for the additional evaluation metrics PSNR and SSIM in Fig. 8. Correspondingly,
we visualize the number of trainable parameters of each model vs. the latent dimension in Fig. 9. In Figs. 10- 16,
we present sequences of stills for the rollout of the trained CON (-M) models on the various datasets.
Model RMSE ↓ PSNR ↑ SSIM↑ # Parameters ↓
RNN 0.2739±0.0057 4 .16±0.02 0 .6958±0.0122 88
GRU [30] 0.0267±0.0033 6.13±0.09 0.9861±0.0022 248
coRNN [35] 0.0265±0.0002 6 .13±0.01 0 .9853±0.0006 40
NODE [27] 0.0264±0.0010 6 .14±0.03 0 .9858±0.0009 3368
MECH-NODE 0.0328±0.0034 5 .99±0.07 0 .9821±0.0024 3244
CON (our) 0.0303±0.0053 6 .05±0.13 0 .9847±0.0027 34
CFA-CON (our) 0.0313±0.0026 6 .02±0.06 0 .9843±0.0008 34
Table 4: Benchmarking of CON and CFA-CON at learning latent dynamics on the M-SP+F (mass-spring with
friction) dataset . For all models, a latent dimension of nz= 4 is chosen. As this dataset does not consider
any inputs, we remove all parameters in the RNN, GRU, coRNN, CON, and CFA-CON models related to the
input mapping. MECH-NODE is a NODE with prior knowledge about the mechanical structure of the system
(i.e.,dx
dt= ˙x). We report the mean and standard deviation over three different random seeds and the number of
parameters of each latent dynamics model.
Model RMSE ↓ PSNR ↑ SSIM↑ # Parameters ↓
RNN 0.2378±0.0352 4 .31±0.15 0 .7568±0.0350 88
GRU [30] 0.1457±0.0078 4 .78±0.05 0 .9168±0.0093 248
coRNN [35] 0.1333±0.0044 4 .86±0.03 0 .9194±0.0055 40
NODE [27] 0.1260±0.0013 4 .91±0.01 0 .9379±0.0009 3368
MECH-NODE 0.1650±0.0205 4 .67±0.12 0 .8985±0.0153 3244
CON (our) 0.1303±0.0064 4 .88±0.04 0 .9175±0.0095 34
CFA-CON (our) 0.1352±0.0073 4 .85±0.05 0 .9133±0.0052 34
Table 5: Benchmarking of CON and CFA-CON at learning latent dynamics on the S-P+F (single pendulum
with friction) dataset . For all models, a latent dimension of nz= 4is chosen. As this dataset does not consider
any inputs, we remove all parameters in the RNN, GRU, coRNN, CON, and CFA-CON models related to the
input mapping. MECH-NODE is a NODE with prior knowledge about the mechanical structure of the system
(i.e.,dx
dt= ˙x). We report the mean and standard deviation over three different random seeds and the number of
parameters of each latent dynamics model.
Model RMSE ↓ PSNR ↑ SSIM↑ # Parameters ↓
RNN 0.1694±0.0004 4 .631±0.002 0 .7082±0.0032 672
GRU [30] 0.1329±0.0005 4 .858±0.003 0.8340±0.0021 1968
coRNN [35] 0.1324±0.0016 4 .862±0.012 0 .8229±0.0039 348
NODE [27] 0.1324±0.0024 4 .861±0.016 0 .8101±0.0024 4404
MECH-NODE 0.1710±0.0111 4 .624±0.063 0 .7170±0.0439 4032
CON (our) 0.1323±0.0018 4 .862±0.013 0 .8067±0.0038 246
CFA-CON (our) 0.1307±0.0012 4 .873±0.008 0.8147±0.0034 246
Table 6: Benchmarking of CON and CFA-CON at learning latent dynamics on the D-P+F (double pendulum
with friction) dataset . For all models, a latent dimension of nz= 12 is chosen. As this dataset do not consider
any inputs, we remove all parameters in the RNN, GRU, coRNN, CON, and CFA-CON models related to the
input mapping. MECH-NODE is a NODE with prior knowledge about the mechanical structure of the system
(i.e.,dx
dt= ˙x). We report the mean and standard deviation over three different random seeds and the number of
parameters of each latent dynamics model.
29Model RMSE ↓ PSNR ↑ SSIM↑ # Parameters ↓
RNN 0.1011±0.0009 25 .92±0.08 0 .9777±0.0004 696
GRU [30] 0.1125±0.0100 24 .99±0.74 0 .9730±0.0040 2040
coRNN [35] 0.2537±0.0018 17 .93±0.06 0 .8820±0.0024 336
NODE [27] 0.2415±0.0021 18 .36±0.08 0 .8946±0.0023 4374
MECH-NODE 0.2494±0.0028 18 .08±0.10 0 .8898±0.0016 4002
CON-S (our) 0.1993±0.0646 20 .03±2.44 0 .9218±0.0380 1386
CON-M (our) 0.1063±0.0027 25 .49±0.22 0 .9758±0.0011 8568
CFA-CON (our) 0.1462±0.0211 22 .72±1.17 0 .9573±0.0103 8568
Table 7: Benchmarking of CON and CFA-CON at learning latent dynamics on the CS(soft robot with one
constant strain segment) dataset . For all models, a latent dimension of nz= 12 is chosen. CON-S and
CON-M are small and medium-sized versions of the CON model, respectively. MECH-NODE is a NODE with
prior knowledge about the mechanical structure of the system (i.e.,dx
dt= ˙x). We report the mean and standard
deviation over three different random seeds and the number of parameters of each latent dynamics model.
Model RMSE ↓ PSNR↑ SSIM↑ # Parameters ↓Train. steps
second↑Inf. time [ms]↑
RNN 0.1373±0.0185 23 .27±1.10 0 .9643±0.0077 320 1 .87 02 .6
GRU [30] 0.0951±0.0021 26.45±0.190.9730±0.0040 928 1 .83 03 .2
coRNN [35] 0.2504±0.0899 18 .05±2.66 0 .9814±0.0006 152 1 .89 02.7
NODE [27] 0.1867±0.0561 20 .60±2.28 0 .8774±0.0857 3856 0 .79 50 .2
MECH-NODE 0.1035±0.0012 25 .07±0.06 0 .9778±0.0004 3062 0 .79 50 .3
CON-S (our) 0.0996±0.0012 26 .05±0.110.9792±0.0007 676 0 .78 50 .2
CON-M (our) 0.1008±0.0006 25 .95±0.05 0 .9786±0.0003 7048 0 .60 60 .1
CFA-CON (our) 0.1124±0.0025 25 .01±0.19 0 .9734±0.0012 7048 1 .12 13 .6
Table 8: Benchmarking of CON and CFA-CON at learning latent dynamics on the PCC-NS-2 (soft robot with
two constant curvature segments) dataset . For all models, a latent dimension of nz= 8is chosen. CON-S
andCON-M are small and medium-sized versions of the CON model, respectively. MECH-NODE is a NODE
with prior knowledge about the mechanical structure of the system (i.e.,dx
dt= ˙x). We report the mean and
standard deviation over three different random seeds. Furthermore, we state the number of parameters of each
latent dynamics model and the training steps per second on a Nvidia RTX 3090 GPU. Each batch contains 80
trajectories and 8080 images of resolution 32x32px in total. Finally, we report the inference time averaged over
5000 runs for performing a rollout of 2.02 s(while encoding and decoding all images along the trajectory) on an
Nvidia RTX 3090 GPU with a batch size of 1.
D.1 Results for Reaction-diffusion dataset
As all previous examples exampled ODEs, we strive to test the proposed approach also on a system that is
governed by PDEs. Specifically, we consider the Reaction-diffusion ( R-D) dataset as introduced in Apx. C.1.3.
To address the unactuated nature of the dataset, we remove, analog to the M-SP+F ,S-P+F , and D-P+F datasets,
the input-to-state mapping parameters of the dynamical models (e.g., the B(u)andE(τ)MLPs for the CON
models). Furthermore, the PDE describing the system dynamics is of 1st-order. Therefore, we leverage the
1st-order versions of the latent dynamics as specified in Apx. C.4.
We report the metrics of the test set evaluations in Tab. 10. Furthermore, we also present a sequence of stills of
the rollout of a trained latent dynamics CON model in Fig. 17. We find it impressive that CON with its strong
stability guarantees can accurately model the dynamics of a high-dimensional PDE system.
30Model RMSE ↓ PSNR ↑ SSIM↑ # Parameters ↓
RNN 0.2232±0.0075 19 .05±0.29 0 .8955±0.0083 696
GRU [30] 0.2148±0.0196 19 .38±0.76 0 .9039±0.0223 2040
coRNN [35] 0.2474±0.0018 18 .15±0.06 0 .8877±0.0011 336
NODE [27] 0.3373±0.0565 15 .46±1.34 0 .7432±0.0935 4374
MECH-NODE 0.1900±0.0024 20 .45±0.11 0 .9315±0.0011 4002
CON-S (our) 0.1792±0.0038 20 .96±0.18 0 .9392±0.0023 1386
CON-M (our) 0.1785±0.0023 20 .99±0.11 0 .9395±0.0018 8568
CFA-CON (our) 0.1803±0.0003 20 .90±0.01 0 .9366±0.0004 8568
Table 9: Benchmarking of CON and CFA-CON at learning latent dynamics on the PCC-NS-3 (soft robot with
three constant curvature segments) dataset . For all models, a latent dimension of nz= 12 is chosen. CON-S
andCON-M are small and medium-sized versions of the CON model, respectively. MECH-NODE is a NODE
with prior knowledge about the mechanical structure of the system (i.e.,dx
dt= ˙x). We report the mean and
standard deviation over three different random seeds and the number of parameters of each latent dynamics
model.
Model RMSE ↓ PSNR ↑ SSIM↑ # Parameters ↓
RNN 0.3763±0.0374 3 .82±0.12 0 .4463±0.1358 20
GRU [30] 0.3232±0.0368 3.99±0.13 0.6798±0.0949 52
1st-order coRNN [35] 0.0741±0.0001 5 .35±0.00 0 .9724±0.0014 20
NODE [27] 0.0738±0.0007 5 .36±0.01 0 .9683±0.0022 3064
CON (our) 0.1110±0.0160 5 .03±0.12 0 .9372±0.0109 24
CFA-CON (our) 0.1068±0.0059 5 .05±0.05 0 .9418±0.0026 24
Table 10: Benchmarking of CON and CFA-CON at learning latent dynamics on the R-D (reaction-diffusion)
dataset . For all models, a latent dimension of nz= 4is chosen. As this dataset does not consider inputs, we
remove all parameters in the RNN, GRU, coRNN, CON, and CFA-CON models related to the input mapping.
Also, as the reaction-diffusion system is governed by 1st-order PDE dynamics, we use specialized, 1st-order
version of the CON ,CFA-CON , and coRNN dynamics. We report the mean and standard deviation over three
different random seeds and the number of parameters of each latent dynamics model.
310 5 10 15 20 25 30
nz101520PSNR
RNN
MECH-NODE-S
MECH-NODE
CON-S
CON-M
CFA-CON(a) PSNR vs. latent dimension nz
0 2000 4000 6000 8000 10000 12000
Model parameters101520PSNR
RNN
MECH-NODE-S
MECH-NODE
CON-S
CON-M
CFA-CON (b) PSNR vs. model parameters
0 5 10 15 20 25 30
nz0.60.81.0SSIM
RNN
MECH-NODE-S
MECH-NODE
CON-S
CON-M
CFA-CON
(c) SSIM vs. latent dimension nz
0 2000 4000 6000 8000 10000 12000
Model parameters0.60.81.0SSIM
RNN
MECH-NODE-S
MECH-NODE
CON-S
CON-M
CFA-CON (d) SSIM vs. model parameters
Figure 8: Evaluation of prediction performance of the various models vs. the dimension of their latent
representation nzand the number of trainable parameters of the dynamics model, respectively. We optimize the
hyperparameters for the case of nz= 8, and execute the tuning separately for each model and dataset.
0 5 10 15 20 25 30
nz02500500075001000012500Model parametersRNN
MECH-NODE-S
MECH-NODE
CON-S
CON-M
CFA-CON
Figure 9: Plot of number of trainable parameters vs. the latent dimension nzof various models trained on the
PCC-NS-2 dataset. As we have configured them, CON-M andCFA-CON always have the same number of
parameters (i.e., overlaying lines).
32(a) t= 0.0 s
 (b) t= 0.55 s
 (c) t= 1.10 s
 (d) t= 1.65 s
 (e) t= 2.20 s
 (f) t=2.75 s
Figure 10: Prediction sequence of a CON model with latent dimension nz= 4trained on the damped harmonic
oscillator ( M-SP+F ) dataset [ 26].Top row: Ground-truth evolution of the system. Bottom row: Predictions of
theCON model.
The prediction model is given three images centered around t= 0 for encoding the initial latent z(0)and
estimation of the initial latent velocity ˙z(0). Subsequently, we roll out the autonomous network dynamics (i.e.,
unforced) and compare the decoded predictions with the ground-truth evolution of the system.
(a) t= 0.0 s
 (b) t= 0.55 s
 (c) t= 1.10 s
 (d) t= 1.65 s
 (e) t= 2.20 s
 (f) t=2.75 s
Figure 11: Prediction sequence of a CON model with latent dimension nz= 4trained on the single pendulum
with friction ( S-P+F ) dataset [ 26].Top row: Ground-truth evolution of the system. Bottom row: Predictions of
theCON model.
The prediction model is given three images centered around t= 0 for encoding the initial latent z(0)and
estimation of the initial latent velocity ˙z(0). Subsequently, we roll out the autonomous network dynamics (i.e.,
unforced) and compare the decoded predictions with the ground-truth evolution of the system.
33(a) t= 0.0 s
 (b) t= 0.55 s
 (c) t= 1.10 s
 (d) t= 1.65 s
 (e) t= 2.20 s
 (f) t=2.75 s
Figure 12: Prediction sequence of a CON model with latent dimension nz= 12 trained on the double pendulum
with friction ( D-P+F ) dataset [ 26].Top row: ground-truth evolution of the system. Bottom row: predictions of
theCON model.
The prediction model is given three images centered around t= 0 for encoding the initial latent z(0)and
estimation of the initial latent velocity ˙z(0). Subsequently, we roll out the autonomous network dynamics (i.e.,
unforced) and compare the decoded predictions with the ground-truth evolution of the system.
(a) t= 0.00 s
 (b) t= 0.04 s
 (c) t= 0.08 s
 (d) t= 0.12 s
 (e) t= 0.16 s
 (f) t=0.20 s
Figure 13: Prediction sequence of a forced CON model with latent dimension nz= 12 trained on the soft
robotic CSdataset containing trajectories of a simulated constant strain robot with one segment. Top row:
Ground-truth evolution of the system. Bottom row: Predictions of the CON-M model.
The prediction model is given three images centered around t= 0 for encoding the initial latent z(0)and
estimation of the initial latent velocity ˙z(0). Subsequently, we roll out the autonomous network dynamics (i.e.,
unforced) and compare the decoded predictions with the ground-truth evolution of the system.
34(a) t= 0.0 s
 (b) t= 0.3 s
 (c) t= 0.6 s
 (d) t= 0.9 s
 (e) t= 1.2 s
Figure 14: Prediction sequence of an unforced CON model with latent dimension nz= 8 trained on the
PCC-NS-2 dataset. Top row: Ground-truth evolution of the system. Bottom row: Predictions of the CON-M
model.
The prediction model is given three images centered around t= 0 for encoding the initial latent z(0)and
estimation of the initial latent velocity ˙z(0). Subsequently, we roll out the autonomous network dynamics (i.e.,
unforced) and compare the decoded predictions with the ground-truth evolution of the system.
(a) t= 0.0 s
 (b) t= 0.3 s
 (c) t= 0.6 s
 (d) t= 0.9 s
 (e) t= 1.2 s
Figure 15: Prediction sequence of a forced CON model with latent dimension nz= 8trained on the PCC-NS-2
dataset. Top row: Ground-truth evolution of the system. Bottom row: Predictions of the CON-M model.
The prediction model is given three images centered around t= 0 for encoding the initial latent z(0)and
estimation of the initial latent velocity ˙z(0). Subsequently, we provide the same constant input uto both the
simulator and the network dynamics (i.e., unforced) and compare the decoded predictions with the ground-truth
evolution of the system.
35(a) t= 0.0 s
 (b) t= 0.36 s
 (c) t= 0.72 s
 (d) t= 1.08 s
 (e) t= 1.44 s
 (f) t=1.80 s
Figure 16: Prediction sequence of a forced CON model with latent dimension nz= 12 trained on the soft
robotic PCC-NS-3 dataset containing trajectories of a simulated piecewise constant curvature robot with three
segments. Top row: Ground-truth evolution of the system. Bottom row: Predictions of the CON-M model.
The prediction model is given three images centered around t= 0 for encoding the initial latent z(0)and
estimation of the initial latent velocity ˙z(0). Subsequently, we roll out the autonomous network dynamics (i.e.,
unforced) and compare the decoded predictions with the ground-truth evolution of the system.
(a) t= 0.0 s
 (b) t= 1.0 s
 (c) t= 2.0 s
 (d) t= 3.0 s
 (e) t= 4.0 s
 (f) t=5.0 s
Figure 17: Prediction sequence of an unforced, 1st-order CON model with latent dimension nz= 4trained on
the reaction-diffusion ( R-D) dataset. Top row: Ground-truth evolution of the system. Bottom row: Predictions
of the CON-M model. We roll out the autonomous, 1st-order network dynamics (i.e., unforced) and compare the
decoded predictions with the ground-truth evolution of the system.
36E Appendix on latent-space control
E.1 Latent-space control of a damped harmonic oscillator
We consider an actuated version of the M-SP+F dataset (i.e., a damped harmonic oscillator) and denote it with
M-SP+F+A . All system, trajectory sampling and rendering parameters remain the same, except that for each
trajectory in the dataset we randomly sample a forcing u∼ U(−1 N,1 N).
We train a CON model with latent dimension nz= 1over three random seeds on the M-SP+F+A dataset. This
means that the network consists of a single oscillator. From the three different random seeds, we choose the
model that achieves the best validation loss, which results in an RMSE of 0.0327 , a PSNR of 5.99, and SSIM of
0.9796 on the test set.
Fig. 18 shows how the encoder learns an almost linear relationship between the actual configuration of the
system and the predicted latent space representation. Furthermore, we notice that both the ground-truth and the
learned potential energy are convex and exhibit a global minimum at q= 0 m .
We compare the performance of P-satI-D ,D+FF , and P-satI-D+FF controllers based on the CON model in
Fig. 19. For the P-satI-D controller, we choose the control gains Kp= 10, Ki= 10, Kd= 5, υ= 1. The D+FF
controller uses Kd= 3.5. Finally, the P-satI-D+FF is configured with Kp= 2, Ki= 0.3, Kd= 3.5, υ= 1.
The results show that the P-satI-D+FF controller exhibits thanks to its feedforward term no overshooting and
a faster response time than the pure feedback controller P-satI-D . The high accuracy of the feedfoward term
can be seen from the performance of the D+FF controller, that only exhibits relatively small steady-state error.
Adding small proportional and integral feedback actions in the P-satI-D+FF controller keeps the compliance
high while removing the steady-state error and reducing the response time.
Finally, we visualize the behavior of the P-satI-D+FF controller as a sequence of stills in Fig. 20.
−1.00−0.75−0.50−0.25 0.00 0.25 0.50 0.75 1.00
q[m]−0.2−0.10.00.10.2zz(q)
(a) Configuration qto latent zmapping
−1.00−0.75−0.50−0.25 0.00 0.25 0.50 0.75 1.00
q[m]0.00.20.40.60.81.0UUgt(q)
ˆU(q) (b) Ground-truth and learned potential energy U
Figure 18: Panel (a): Learned mapping from configuration to latent space for the CON model with nz(i.e.,
consisting of a single oscillator) trained on the actuated damped harmonic oscillator ( M-SP+F+A ) dataset.
Panel (b): The blue line represents the ground-truth potential energy of the damped harmonic oscillator. The
orange line represents the learned potential energy of the CON model evaluated vs. the system configuration by
rendering and subsequently encoding into latent space each configuration value.
E.2 Latent-space control of a two segment PCC soft robot
E.2.1 Potential energy landscape
When leveraging (learned) dynamical models for setpoint regulation, it is essential to accurately estimate the
potential energy as this dictates the efficacy of the feedforward terms. Therefore, we qualitatively evaluate the
potential energy landscape of the CON latent dynamic model.
In Fig. 21(a), we can see how CON contains a single, isolated, and globally asymptotically stable equilibrium as
proven in Appendix A.2 and Section 2, respectively.
Furthermore, we want to verify that the learned potential corresponds to the actual potential energy of the simu-
lated system. An autonomous continuum soft robot with the tip pointing downwards in a straight configuration
exhibits an isolated, globally asymptotically stable equilibrium at q= 0(i.e., zero strains) [ 42]. For this purpose,
we can compare the learned potential energy field in Fig. 21(b) with the ground-truth potential energy field in
Fig. 21(c). We confirm, based on Fig. 21(b), that, indeed, the learned potential also has its minimum close to/at
q= 0. Although the field is shaped slightly differently, the potential forces are clearly pointing inwards towards
the global attractor.
370 5 10 15 20 25 30 35
Timet[s]−1.00−0.75−0.50−0.250.000.250.500.75Conﬁguration q[m]
Targetqd
P-satI-Dq
D+FFq
P-satI-D+FF q(a) Configuration q(t)∈R2
0 5 10 15 20 25 30 35
Timet[s]−0.2−0.10.00.10.2Latent variable z
Targetzd
P-satI-Dz
D+FFz
P-satI-D+FF z(b) Latent representation z(t)∈R2
0 5 10 15 20 25 30 35
Timet[s]−6−4−2024Control input u[N]P-satI-Du
D+FFu
P-satI-D+FF u
(c) Control input u(t)∈R2
0 5 10 15 20 25 30 35
Timet[s]0.000.020.040.060.08EnergyTargetUd
P-satI-DU
D+FFU
P-satI-D+FFU(d) Potential energy U(t)∈R
Figure 19: Latent-space control of an actuated damped harmonic oscillator ( M-SP+F+A ) following a sequence
of setpoints. We compare multiple controllers based on a trained CON network with nz= 1. The CON model
weights are initialized using a random seed of 0. The blue line represents a pure feedback controller ( P-satI-D ).
The orange line visualizes the behavior of a feedforward controller with only a damping term applied in feedback
(D+FF ). The green line shows the performance of our proposed combination of feedback and feedforward terms
(P-satI-D+FF ). The dotted and solid lines show the reference and actual values, respectively. For each setpoint,
we randomly sample a desired shape qdand render the corresponding image od. This image is then encoded to a
target latent zd. The controller then computes a latent-space torque Fd, which is decoded to an input u. Finally,
we provide this input to the simulator, which performs a roll-out of the closed-loop dynamics. Important: The
robot’s configuration (i.e., the first-principle, minimal-order state) is solely used for generating a target image
and simulating the closed-loop system.
E.2.2 Model selection
For the control experiments, we train instances of the MECH-NODE andCON-M models with latent dimension
nz= 2and with neural network weights initialized with three different random seeds. For MECH-NODE , we
choose the model with the lowest validation loss (seed 0).
For the CON network, we found that model-based control does not perform as well when the latent stiffness
Γw(as visualized in Fig. 21(a)) is significantly larger along one of the Eigenvectors than along the other one.
Therefore, we evaluate the Eigenvalues of the learned stiffness matrix in W-coordinates after training: λ1,2(Γw).
Particularly, we choose the seed that minimizes the normalized standard deviation of the Eigenvalues
µλ=λ1(Γw) +λ2(Γw)
2,
σλ=r
(λ1(Γw)−µλ)2+ (λ2(Γw)−µλ)2
2,
seed = arg minσλ
µλ.(74)
E.2.3 Additional control results
Additional results for the P-satI-D feedback controller based on the MECH-NODE and CON models are
provided in Fig. 23, Fig. 24, respectively and for the P-satI-D+FF controller based on the CON model in Fig. 25.
Sequences of stills for the CON P-satI-D+FF controller are provided in Fig. 22.
38(a) t= 0.0 s
 (b) t= 0.5 s
 (c) t= 1.0 s
 (d) t= 1.5 s
 (e) t= 2.0 s
 (f) Target 0−4.9s
(g) t= 5.00 s
 (h) t= 5.5 s
 (i) t=6.0 s
 (j) t=6.5 s
 (k) t= 7.5 s
 (l) Target 5−9.9s
Figure 20: Sequence of closed-loop control of an actuated damped harmonic oscillator ( M-SP+F+A ) with a
P-satI-D+FF controller based on a trained CON with nz= 1.Columns 1-4: show the actual behavior of the
closed-loop system. Column 5: demonstrates the target image that the control sees for all time instances in the
row.
39−0.15−0.10−0.05 0.00 0.05 0.10 0.15
z1−0.4−0.3−0.2−0.10.00.10.20.30.4z2
0.0000.0360.0720.1080.1440.1800.2160.2520.2880.324
U(a) Learned potential energy as a function of z
−15−10−5 0 5 10 15
q1[rad/m]−15−10−5051015q2[rad/m]
0.0000.0330.0660.0990.1320.1650.1980.2310.2640.297
U
(b) Learned potential energy as a function of q
−15−10−5 0 5 10 15
q1[rad/m]−15−10−5051015q2[rad/m]
0.03680.04400.05120.05840.06560.07280.08000.08720.09440.1016
U (c) Ground-truth potential energy as a function of q
Figure 21: Potential energy landscapes of a CON with nz= 2trained to learn the latent space dynamics of a
continuum soft robots (simulated with two PCC segments). Panel (a): Here, we visualize the learned potential
energy of CON using the color scale as a function of the latent representation z=xw∈R2. The arrows denote
the gradient of the potential field∂U
∂z(i.e., the potential force), with the magnitude of the gradient expressed
as the length of the arrow. Panel (b): Again, we display the learned potential energy of CON using the color
scale, but in this case, as a function of the configuration q∈Rof the robot (that is hidden from the model). First,
we render an image oof the shape of the robot for each configuration q= [q1q2]T∈R2. Then, we encode
the image into latent space as z= Φ(o). This allows us then to compute the potential energy U(z)of the CON
latent dynamics model. Panel (c): Here, we display the potential energy and its associated potential forces of
the actual (i.e., simulated) system.
40(a) t= 0.0 s
 (b) t= 0.2 s
 (c) t= 0.4 s
 (d) t= 0.6 s
 (e) t= 0.8 s
 (f) Target 0−4.9s
(g) t= 5.00 s
 (h) t= 5.2 s
 (i) t=5.4 s
 (j) t=5.6 s
 (k) t= 5.8 s
 (l) Target 5−9.9s
Figure 22: Sequence of closed-loop control of a continuum soft robot consisting of two constant curvature
segments with the P-satI-D+FF based on a trained CON with nz= 2.Columns 1-4: show the actual behavior
of the closed-loop system. Column 5: demonstrates the target image that the control sees for all time instances
in the row.
0 5 10 15 20 25 30 35
Timet[s]−15−10−50510Conﬁguration q[rad/m]
qd
0
q0
qd
1
q1
(a) Configuration q(t)∈R2
0 5 10 15 20 25 30 35
Timet[s]−0.06−0.04−0.020.000.020.04Latent variable z
zd
0
z0
zd
1
z1(b) Latent representation z(t)∈R2
0 5 10 15 20 25 30 35
Timet[s]−0.004−0.0020.0000.0020.004Control input u[Nm]u0
u1
(c) Control input u(t)∈R2
Figure 23: Latent-space control of a continuum soft robot (simulated using two PCC segments) following a
sequence of setpoints with a pure P-satI-D feedback controller operating in a 2D latent space learned with the
MECH-NODE model. The CON model weights are initialized using a random seed of 0 . The dotted and solid
lines show the reference and actual values, respectively. For each setpoint, we randomly sample a desired shape
qdand render the corresponding image od. This image is then encoded to a target latent zd. The controller
then computes a latent-space torque Fd, which is decoded to an input u. Finally, we provide this input to the
simulator, which performs a roll-out of the closed-loop dynamics. Important: The robot’s configuration (i.e., the
first-principle, minimal-order state) is solely used for generating a target image and simulating the closed-loop
system.
410 5 10 15 20 25 30 35
Timet[s]−15−10−50510Conﬁguration q[rad/m]
qd
0
q0
qd
1
q1(a) Configuration q(t)∈R2
0 5 10 15 20 25 30 35
Timet[s]−0.3−0.2−0.10.00.10.2Latent variable z
zd
0
z0
zd
1
z1(b) Latent representation z(t)∈R2
0 5 10 15 20 25 30 35
Timet[s]0.000.050.100.150.20EnergyUd
U
(c) Control input u(t)∈R2
0 5 10 15 20 25 30 35
Timet[s]0.000.050.100.150.20EnergyUd
U(d) Potential energy U(t)∈R
Figure 24: Latent-space control of a continuum soft robot (simulated using two PCC segments) following a
sequence of setpoints with a pure P-satI-D feedback controller operating in a 2D latent space learned with the
CON model. The CON model weights are initialized using a random seed of 0. The dotted and solid lines
show the reference and actual values, respectively. For each setpoint, we randomly sample a desired shape
qdand render the corresponding image od. This image is then encoded to a target latent zd. The controller
then computes a latent-space torque Fd, which is decoded to an input u. Finally, we provide this input to the
simulator, which performs a roll-out of the closed-loop dynamics. Important: The robot’s configuration (i.e., the
first-principle, minimal-order state) is solely used for generating a target image and simulating the closed-loop
system.
420 5 10 15 20 25 30 35
Timet[s]−20−1001020Conﬁguration q[rad/m]
qd
0
q0
qd
1
q1(a) Configuration q(t)∈R2
0 5 10 15 20 25 30 35
Timet[s]−0.6−0.4−0.20.00.20.4Latent variable zzd
0
z0
zd
1
z1(b) Latent representation z(t)∈R2
0 5 10 15 20 25 30 35
Timet[s]0.00.10.20.30.4EnergyUd
U
(c) Control input u(t)∈R2
0 5 10 15 20 25 30 35
Timet[s]0.00.10.20.30.4EnergyUd
U(d) Potential energy U(t)∈R
Figure 25: Latent-space control of a continuum soft robot (simulated using two PCC segments) following a
sequence of setpoints with a pure P-satI-D+FF feedback & feedforward controller operating in a 2D latent space
learned with the CON model. The CON model weights are initialized using a random seed of 0. The dotted and
solid lines show the reference and actual values, respectively. For each setpoint, we randomly sample a desired
shape qdand render the corresponding image od. This image is then encoded to a target latent zd. The controller
then computes a latent-space torque Fd, which is decoded to an input u. Finally, we provide this input to the
simulator, which performs a roll-out of the closed-loop dynamics. Important: The robot’s configuration (i.e., the
first-principle, minimal-order state) is solely used for generating a target image and simulating the closed-loop
system.
43F Extended discussion on future applications and limitations
F.1 Systems for which we would expect the proposed method to work
Mechanical systems with continuous dynamics, dissipation, and a single, attractive equilibrium
point. The proposed method is a very good fit for mechanical systems with continuous dynamics, dissipation,
and a single, attractive equilibrium point. In this case, the real system and the latent dynamics share the energetic
structure and stability guarantees. Examples of such systems include many soft robots, deformable objects with
dominant elastic behavior, and other mechanical structures with elasticity.
Local modeling of (mechanical) systems that do not meet the global assumptions. Even if the
global assumptions of the proposed method are not met, the method can still be applied to model the local
behavior around a local asymptotic equilibrium point of the system (i.e., in the case of multi-stability). For
example, the method could be used to model the behavior of a robotic leg locally in contact with the ground, a
cobot’s interaction with its environment, etc.
F.2 Systems for which we could envision the proposed method to work under (minor)
modifications
Mechanical systems without dissipation. The proposed method would currently not work well for
mechanical systems without any dissipation, as (a) the original system will likely not have a globally asymp-
totically stable equilibrium point, and more importantly, (b) we currently force the damping learned in latent
space to be positive definite. However, these systems are not common in practice as friction and other dissi-
pation mechanisms are omnipresent, and the proposed method can learn very small damping values (e.g., the
mass-spring+friction system). A possible remedy could be to relax the positive definiteness of the damping
matrix in the latent space, allowing for zero damping. This would allow the method to work for systems without
dissipation, such as conservative systems. Examples of such systems include a mass-spring system without
damping, the n-body problem, etc.
Systems with discontinuous dynamics. The proposed method might underperform for systems with
highly discontinuous dynamics, such as systems with impacts, friction, or other discontinuities. In these cases,
the latent dynamics might not capture the real system’s behavior accurately, and the control performance of
feedforward + feedback will very likely be worse than pure feedback. Again, the method should be able to
capture local behavior well. A possible remedy for learning global dynamics could be to augment the latent
dynamics with additional terms that capture the discontinuities, such as contact and friction models (e.g.,
stick-slip friction).
Systems with multiple equilibrium points. The original system having multiple equilibria conflicts with
the stability assumptions underlying the proposed CON latent dynamics. In this case, as, for example, seen
on the pendulum+friction and double pendulum + friction results, the method might work locally but will not
be able to capture the global behavior of the system. A possible remedy could be to relax the global stability
assumptions of the CON network. For example, the latent dynamics could be learned in the original coordinates
of CON while allowing Walso to be negative definite. This would allow the system to have multiple equilibria
& attractors. Examples of such systems include a robotic arm under gravity, pendula under gravity, etc.
Systems with periodic behavior. The proposed method will likely not work well for systems with periodic
behavior, as they do not have a single, attractive equilibrium point. Examples of such systems include a mass-
spring system with a periodic external force, a pendulum with a periodic external force, some chemical reactions,
etc. Again, it is likely possible to apply the presented method to learning a local behavior (i.e., not completing
the full orbit). A possible remedy could be to augment the latent dynamics with additional terms that capture the
periodic behavior, such as substituting the harmonic oscillators with Van der Pol oscillators to establish a limit
cycle or a supercritical Hopf bifurcation.
F.3 Systems for which we would not expect the proposed method to work
Nonholonomic systems. The proposed method likely would not work well for nonholonomic systems,
as both structure (e.g., physical constraints) and stability characteristics would not be shared between the real
system and the latent dynamics. Examples of such systems include vehicles, a ball rolling on a surface, and
many mobile robots.
Partially observable and non-markovian systems. As the CON dynamics are evaluated based on
the latent position and velocity encoded by the observation of the current time step and the observation-space
velocity, we implicitly assume that the system is (a) fully observable and (b) fulfills the Markov property. This
assumption might not hold for partially observable systems, such as systems with hidden states or systems
with delayed observations. Examples of such cases include settings where the system is partially occluded
or in situations without sufficient (camera) perspectives covering the system. Furthermore, time-dependent
material properties, such as viscoelasticity or hysteresis, that are present and significant in some soft robots and
deformable objects are not captured by the method in its current formulation.
44NeurIPS Paper Checklist
1.Claims
Question: Do the main claims made in the abstract and introduction accurately reflect the paper’s
contributions and scope?
Answer: [Yes]
Justification: The claims and contributions made in the abstract and introduction are all supported by
theoretical and/or experimental results included in the paper.
Guidelines:
•The answer NA means that the abstract and introduction do not include the claims made in the
paper.
•The abstract and/or introduction should clearly state the claims made, including the contributions
made in the paper and important assumptions and limitations. A No or NA answer to this
question will not be perceived well by the reviewers.
•The claims made should match theoretical and experimental results and reflect how much the
results can be expected to generalize to other settings.
•It is fine to include aspirational goals as motivation as long as it is clear that these goals are not
attained by the paper.
2.Limitations
Question: Does the paper discuss the limitations of the work performed by the authors?
Answer: [Yes]
Justification: The known limitations of the proposed method are listed and presented in multiple places
in the manuscript: the last paragraph of the introduction, in Section 6, and an extended version in
Appendix F.
Guidelines:
•The answer NA means that the paper has no limitation while the answer No means that the paper
has limitations, but those are not discussed in the paper.
• The authors are encouraged to create a separate "Limitations" section in their paper.
•The paper should point out any strong assumptions and how robust the results are to violations of
these assumptions (e.g., independence assumptions, noiseless settings, model well-specification,
asymptotic approximations only holding locally). The authors should reflect on how these
assumptions might be violated in practice and what the implications would be.
•The authors should reflect on the scope of the claims made, e.g., if the approach was only tested
on a few datasets or with a few runs. In general, empirical results often depend on implicit
assumptions, which should be articulated.
•The authors should reflect on the factors that influence the performance of the approach. For
example, a facial recognition algorithm may perform poorly when image resolution is low or
images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide
closed captions for online lectures because it fails to handle technical jargon.
•The authors should discuss the computational efficiency of the proposed algorithms and how
they scale with dataset size.
•If applicable, the authors should discuss possible limitations of their approach to address problems
of privacy and fairness.
•While the authors might fear that complete honesty about limitations might be used by reviewers
as grounds for rejection, a worse outcome might be that reviewers discover limitations that
aren’t acknowledged in the paper. The authors should use their best judgment and recognize
that individual actions in favor of transparency play an important role in developing norms that
preserve the integrity of the community. Reviewers will be specifically instructed to not penalize
honesty concerning limitations.
3.Theory Assumptions and Proofs
Question: For each theoretical result, does the paper provide the full set of assumptions and a complete
(and correct) proof?
Answer: [Yes]
Justification: All equations, Theorems, and Lemmas are numbered and cross-referenced. In each
Theorem/Lemma, we clearly state the assumptions under which the proof is valid (e.g., positive
definite matrices for the ISS stability proof). All Theorems are included in the main paper: for the
global asymptotic stability proof, we directly detail the proof in the main paper, and for the ISS proof,
we provide a sketch with the full proof appearing in the Appendix. We also include auxiliary Lemmas
in the Appendix.
Guidelines:
• The answer NA means that the paper does not include theoretical results.
45• All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced.
• All assumptions should be clearly stated or referenced in the statement of any theorems.
•The proofs can either appear in the main paper or the supplemental material, but if they appear in
the supplemental material, the authors are encouraged to provide a short proof sketch to provide
intuition.
•Inversely, any informal proof provided in the core of the paper should be complemented by
formal proofs provided in appendix or supplemental material.
• Theorems and Lemmas that the proof relies upon should be properly referenced.
4.Experimental Result Reproducibility
Question: Does the paper fully disclose all the information needed to reproduce the main experimental
results of the paper to the extent that it affects the main claims and/or conclusions of the paper
(regardless of whether the code and data are provided or not)?
Answer: [Yes]
Justification: All the code for the experiments has been open-sourced on GitHub. Furthermore, we
provide a detailed description of the implementation details in Appendix C.
Guidelines:
• The answer NA means that the paper does not include experiments.
•If the paper includes experiments, a No answer to this question will not be perceived well by the
reviewers: Making the paper reproducible is important, regardless of whether the code and data
are provided or not.
•If the contribution is a dataset and/or model, the authors should describe the steps taken to make
their results reproducible or verifiable.
•Depending on the contribution, reproducibility can be accomplished in various ways. For
example, if the contribution is a novel architecture, describing the architecture fully might suffice,
or if the contribution is a specific model and empirical evaluation, it may be necessary to either
make it possible for others to replicate the model with the same dataset, or provide access to
the model. In general. releasing code and data is often one good way to accomplish this, but
reproducibility can also be provided via detailed instructions for how to replicate the results,
access to a hosted model (e.g., in the case of a large language model), releasing of a model
checkpoint, or other means that are appropriate to the research performed.
•While NeurIPS does not require releasing code, the conference does require all submissions
to provide some reasonable avenue for reproducibility, which may depend on the nature of the
contribution. For example
(a)If the contribution is primarily a new algorithm, the paper should make it clear how to
reproduce that algorithm.
(b)If the contribution is primarily a new model architecture, the paper should describe the
architecture clearly and fully.
(c)If the contribution is a new model (e.g., a large language model), then there should either be
a way to access this model for reproducing the results or a way to reproduce the model (e.g.,
with an open-source dataset or instructions for how to construct the dataset).
(d)We recognize that reproducibility may be tricky in some cases, in which case authors are
welcome to describe the particular way they provide for reproducibility. In the case of
closed-source models, it may be that access to the model is limited in some way (e.g.,
to registered users), but it should be possible for other researchers to have some path to
reproducing or verifying the results.
5.Open access to data and code
Question: Does the paper provide open access to the data and code, with sufficient instructions to
faithfully reproduce the main experimental results, as described in supplemental material?
Answer: [Yes]
Justification: The code associated with this paper is available on GitHub2. It allows the user to generate
the datasets, run the hyperparameters selection, train the models, and generats result plots based on
training checkpoints.
Guidelines:
• The answer NA means that paper does not include experiments requiring code.
•Please see the NeurIPS code and data submission guidelines ( https://nips.cc/public/
guides/CodeSubmissionPolicy ) for more details.
•While we encourage the release of code and data, we understand that this might not be possible,
so “No” is an acceptable answer. Papers cannot be rejected simply for not including code, unless
this is central to the contribution (e.g., for a new open-source benchmark).
2https://github.com/tud-phi/uncovering-iss-coupled-oscillator-networks-from-pixels
46•The instructions should contain the exact command and environment needed to run to reproduce
the results. See the NeurIPS code and data submission guidelines ( https://nips.cc/
public/guides/CodeSubmissionPolicy ) for more details.
•The authors should provide instructions on data access and preparation, including how to access
the raw data, preprocessed data, intermediate data, and generated data, etc.
•The authors should provide scripts to reproduce all experimental results for the new proposed
method and baselines. If only a subset of experiments are reproducible, they should state which
ones are omitted from the script and why.
•At submission time, to preserve anonymity, the authors should release anonymized versions (if
applicable).
•Providing as much information as possible in supplemental material (appended to the paper) is
recommended, but including URLs to data and code is permitted.
6.Experimental Setting/Details
Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters,
how they were chosen, type of optimizer, etc.) necessary to understand the results?
Answer: [Yes]
Justification: In Appendix C, we include implementation details such as the used libraries,
algorithms, optimizers, and evaluation procedures. All hyperparameters (e.g., learning rate,
loss weights, weight decay, etc.) can be found in the code on GitHub (specifically, in
thesweep_generic_dynamics_autoencoder.py Python script that is placed in the
examples/sweeping folder).
Guidelines:
• The answer NA means that the paper does not include experiments.
•The experimental setting should be presented in the core of the paper to a level of detail that is
necessary to appreciate the results and make sense of them.
•The full details can be provided either with the code, in the appendix, or as supplemental material.
7.Experiment Statistical Significance
Question: Does the paper report error bars suitably and correctly defined or other appropriate informa-
tion about the statistical significance of the experiments?
Answer: [Yes]
Justification: We run all experiments with various initializations (i.e., different random seeds), and
each result table/plot is accompanied by a description of how the variability of results is captured.
Guidelines:
• The answer NA means that the paper does not include experiments.
•The authors should answer "Yes" if the results are accompanied by error bars, confidence
intervals, or statistical significance tests, at least for the experiments that support the main claims
of the paper.
•The factors of variability that the error bars are capturing should be clearly stated (for example,
train/test split, initialization, random drawing of some parameter, or overall run with given
experimental conditions).
•The method for calculating the error bars should be explained (closed form formula, call to a
library function, bootstrap, etc.)
• The assumptions made should be given (e.g., Normally distributed errors).
•It should be clear whether the error bar is the standard deviation or the standard error of the
mean.
•It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report
a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is
not verified.
•For asymmetric distributions, the authors should be careful not to show in tables or figures
symmetric error bars that would yield results that are out of range (e.g. negative error rates).
•If error bars are reported in tables or plots, The authors should explain in the text how they were
calculated and reference the corresponding figures or tables in the text.
8.Experiments Compute Resources
Question: For each experiment, does the paper provide sufficient information on the computer
resources (type of compute workers, memory, time of execution) needed to reproduce the experiments?
Answer: [Yes]
Justification: In Section C.8, we report details about the necessary compute for performing the
experiments reported in this paper.
Guidelines:
• The answer NA means that the paper does not include experiments.
47•The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud
provider, including relevant memory and storage.
•The paper should provide the amount of compute required for each of the individual experimental
runs as well as estimate the total compute.
•The paper should disclose whether the full research project required more compute than the
experiments reported in the paper (e.g., preliminary or failed experiments that didn’t make it into
the paper).
9.Code Of Ethics
Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code
of Ethics https://neurips.cc/public/EthicsGuidelines ?
Answer: [Yes]
Justification: The authors have reviewed the NeurIPS Code of Ethics, and this research conforms, in
every respect, with this code.
Guidelines:
• The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
•If the authors answer No, they should explain the special circumstances that require a deviation
from the Code of Ethics.
•The authors should make sure to preserve anonymity (e.g., if there is a special consideration due
to laws or regulations in their jurisdiction).
10.Broader Impacts
Question: Does the paper discuss both potential positive societal impacts and negative societal impacts
of the work performed?
Answer: [NA]
Justification: This paper primarily involves fundamental research, and the presented application of
predicting and controlling the future evolutions of dynamical systems does not directly have any
broader societal impact.
Guidelines:
• The answer NA means that there is no societal impact of the work performed.
•If the authors answer NA or No, they should explain why their work has no societal impact or
why the paper does not address societal impact.
•Examples of negative societal impacts include potential malicious or unintended uses (e.g.,
disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deploy-
ment of technologies that could make decisions that unfairly impact specific groups), privacy
considerations, and security considerations.
•The conference expects that many papers will be foundational research and not tied to particular
applications, let alone deployments. However, if there is a direct path to any negative applications,
the authors should point it out. For example, it is legitimate to point out that an improvement in
the quality of generative models could be used to generate deepfakes for disinformation. On the
other hand, it is not needed to point out that a generic algorithm for optimizing neural networks
could enable people to train models that generate Deepfakes faster.
•The authors should consider possible harms that could arise when the technology is being used
as intended and functioning correctly, harms that could arise when the technology is being used
as intended but gives incorrect results, and harms following from (intentional or unintentional)
misuse of the technology.
•If there are negative societal impacts, the authors could also discuss possible mitigation strategies
(e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitor-
ing misuse, mechanisms to monitor how a system learns from feedback over time, improving the
efficiency and accessibility of ML).
11.Safeguards
Question: Does the paper describe safeguards that have been put in place for responsible release of
data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or
scraped datasets)?
Answer: [NA]
Justification: This work by itself does not pose any risk for misuse.
Guidelines:
• The answer NA means that the paper poses no such risks.
•Released models that have a high risk for misuse or dual-use should be released with necessary
safeguards to allow for controlled use of the model, for example by requiring that users adhere to
usage guidelines or restrictions to access the model or implementing safety filters.
•Datasets that have been scraped from the Internet could pose safety risks. The authors should
describe how they avoided releasing unsafe images.
48•We recognize that providing effective safeguards is challenging, and many papers do not require
this, but we encourage authors to take this into account and make a best faith effort.
12.Licenses for existing assets
Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper,
properly credited and are the license and terms of use explicitly mentioned and properly respected?
Answer: [Yes]
Justification: The code accompanying this submission is original. While we do rely on common
open-source 3rd-party packages (e.g., JAX, flax, diffrax, etc.), we clearly document these dependencies
in the requirements.txt file of the accompanying code archive. Furthermore, we leverage the
datasets that are part of the DeepMind Hamiltonian Dynamics Suite [26]3and have been open-sourced
with an Apache 2.0 license.
Guidelines:
• The answer NA means that the paper does not use existing assets.
• The authors should cite the original paper that produced the code package or dataset.
• The authors should state which version of the asset is used and, if possible, include a URL.
• The name of the license (e.g., CC-BY 4.0) should be included for each asset.
•For scraped data from a particular source (e.g., website), the copyright and terms of service of
that source should be provided.
•If assets are released, the license, copyright information, and terms of use in the package should
be provided. For popular datasets, paperswithcode.com/datasets has curated licenses
for some datasets. Their licensing guide can help determine the license of a dataset.
•For existing datasets that are re-packaged, both the original license and the license of the derived
asset (if it has changed) should be provided.
•If this information is not available online, the authors are encouraged to reach out to the asset’s
creators.
13.New Assets
Question: Are new assets introduced in the paper well documented and is the documentation provided
alongside the assets?
Answer: [Yes]
Justification: We release the necessary code to generate the datasets that we used in this paper alongside
the submission.
Guidelines:
• The answer NA means that the paper does not release new assets.
•Researchers should communicate the details of the dataset/code/model as part of their sub-
missions via structured templates. This includes details about training, license, limitations,
etc.
•The paper should discuss whether and how consent was obtained from people whose asset is
used.
•At submission time, remember to anonymize your assets (if applicable). You can either create an
anonymized URL or include an anonymized zip file.
14.Crowdsourcing and Research with Human Subjects
Question: For crowdsourcing experiments and research with human subjects, does the paper include
the full text of instructions given to participants and screenshots, if applicable, as well as details about
compensation (if any)?
Answer: [NA]
Justification: This research did not involve any crowdsourcing experiments or trials with human
subjects.
Guidelines:
•The answer NA means that the paper does not involve crowdsourcing nor research with human
subjects.
•Including this information in the supplemental material is fine, but if the main contribution of the
paper involves human subjects, then as much detail as possible should be included in the main
paper.
•According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other
labor should be paid at least the minimum wage in the country of the data collector.
15.Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects
3https://github.com/mstoelzle/dm_hamiltonian_dynamics_suite
49Question: Does the paper describe potential risks incurred by study participants, whether such
risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an
equivalent approval/review based on the requirements of your country or institution) were obtained?
Answer: [NA]
Justification: This research did not involve any trials with human subjects.
Guidelines:
•The answer NA means that the paper does not involve crowdsourcing nor research with human
subjects.
•Depending on the country in which research is conducted, IRB approval (or equivalent) may be
required for any human subjects research. If you obtained IRB approval, you should clearly state
this in the paper.
•We recognize that the procedures for this may vary significantly between institutions and
locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for
their institution.
• For initial submissions, do not include any information that would break anonymity (if applica-
ble), such as the institution conducting the review.
50