TAS-GNN: Topology-Aware Spiking Graph Neural
Networks for Graph Classification
Anonymous Author(s)
Affiliation
Address
email
Abstract
The recent integration of spiking neurons into graph neural networks has been 1
gaining much attraction due to its superior energy efficiency. Especially because 2
the irregular connection among graph nodes fits the nature of the spiking neural 3
networks, spiking graph neural networks are considered strong alternatives to 4
vanilla graph neural networks. However, there is still a large performance gap for 5
graph tasks between the spiking neural networks and artificial neural networks. The 6
gaps are especially large when they are adapted to graph classification tasks, where 7
none of the nodes in the testset graphs are connected to the training set graphs. We 8
diagnose the problem as the existence of neurons under starvation, caused by the 9
irregular connections among the nodes and the neurons. To alleviate the problem, 10
we propose TAS-GNN. Based on a set of observations on spiking neurons on 11
graph classification tasks, we devise several techniques to utilize more neurons to 12
deliver meaningful information to the connected neurons. Experiments on diverse 13
datasets show up to 27.20% improvement, demonstrating the effectiveness of the 14
TAS-GNN. 15
1 Introduction 16
Graph neural networks (GNNs) are types of popular neural networks to learn the representations from 17
graphs, which comprise multiple nodes and edges between them. Because of their flexibility to model 18
any kind of connection existing in nature, it has various applications ranging from drug discovery [6, 19
47, 9], social influence prediction [39, 2], traffic forecasting [3, 7], and recommendation systems [38, 20
15, 61]. One known challenge of GNNs is their sparse memory and computational pattern. Because 21
many messages are passed between randomly connected nodes, there is a significant inefficiency in 22
processing them with conventional systems [53, 58, 57, 19]. 23
To address the inefficiency, spiking neural networks (SNNs) are considered strong alternatives. 24
Inspired by the way biological behavior of brains, SNNs process information by communicating 25
binary spikes between the neurons. Because SNNs utilize intermittently occurring spikes, they have 26
superior energy efficiency, especially for the domain of GNNs [1]. 27
Although the spiking graph neural network (SGNN) has been recently studied by many researchers [32, 28
64, 48], we find that its performance experiences a huge drop when adapted to graph classification, 29
compared to that of the conventional GNNs implemented with artificial neural networks (ANNs). 30
Upon closer analysis of the performance degradation, we identify spike frequency deviation of the 31
neurons within the model. In our investigation, many neurons experience starvation , which do not 32
emit any spike during the inference. This leads to severe information loss, due to being unable to 33
deliver signals to the subsequent neurons. 34
Submitted to 38th Conference on Neural Information Processing Systems (NeurIPS 2024). Do not distribute.Such a problem was less exposed in previous spiking GNNs. This is because the testset nodes are 35
available during the training time (transductive learning [27]) or they are part of the training graph 36
(inductive learning [21]). In such settings, the model could be trained to mitigate the performance 37
drop. However, in graph classification tasks, the graphs are independent of each other, and the testset 38
comprises multiple unseen graphs, aggravating the problem. 39
Fortunately, our further analysis reveals that such phenomena are related to the topology of the input 40
graphs. We discover that a strong pattern exists among the neurons in the GNN, where 1) neurons in a 41
node have similar behaviors, 2) each feature causes different behaviors, and 3) neurons in high-degree 42
nodes tend to emit more spikes. 43
Motivated by the observations, we propose to group the neurons according to the degree of the node 44
(topology-aware group-adaptive neurons ). The neurons in each group adapt the threshold together to 45
steer the firing rate toward ideal rates. To further mitigate the initial value sensitivity problem, we 46
further propose to learn the initial values. 47
We evaluate TAS-GNN over multiple GNN models and datasets. Experiments reveal that the proposed 48
TAS-GNN achieves superior performance over the baselines, setting a new state-of-the-art method 49
for graph classification. Our contributions are summarized as the following: 50
• We identify starvation problem of spiking neurons in GNNs for graph classification tasks. 51
• We observe the spike frequency patterns have a strong correlation with the graph topology. 52
•Based on the observations, we propose topology-aware group-adaptive neurons, which 53
dynamically adjusts the threshold together with the other neurons in the group to address 54
the spike frequency deviations. 55
•We propose techniques to reduce the initial value sensitivity caused by the topology-aware 56
group-adaptive neurons. 57
•We evaluate TAS-GNN on several public datasets and achieve superior performance over 58
existing techniques. 59
2 Background 60
2.1 Spiking Neural Networks and Spike Training 61
Spiking neural networks (SNNs) are third-generation neural network designs that mimic the human 62
biological neural systems [35]. They use spike-based communication and adopt event-driven charac- 63
teristics that promote better energy efficiency than current ANNs. Similar to human neural systems, 64
SNNs consist of spiking neurons that can model spatio-temporal dynamics of the actual biological 65
neurons. The early forms of such neuron models are Hodgkin-Huxley neurons [23], which accurately 66
model the biophysical characteristics of the membrane through differential equations. However, its 67
mathematical complexity prohibits its practical use and scalability. Instead, Leaky Integrated-and-Fire 68
(LIF) model finds a middle ground between mathematical simplificity and biological plausibility, and 69
is popularly adopted as the baseline architecture [23]. In the LIF neuron, the weighted sum of input 70
spikes is accumulated over time within the neuron as membrane potential, and the output spike is 71
generated only when the membrane potential exceeds a present threshold value. This is represented 72
as a differential function: 73
τdV(t)
dt=−V(t) +I(t), (1)
where V(t)denotes the membrane potential value at time t,τa time constant of membrane, and I(t) 74
is the input from connected synapses at time t. To make this time-varying function computationally 75
feasible, we discretize and rewrite it iteratively for sequential simulation as follows: 76
V(t) =V(t−1) +β(WX(t)−(V(t−1)−Vreset)), (2)
V(t) =V(t)(1−S(t)) +VresetS(t), (3)
S(t) =1,ifV(t)≥Vth
0,otherwise ,(4)
where βis simplified decay rate constant, Vreset is the reset value and Vththe threshold for the 77
membrane potential. Note that I(t) is simplified as weighted input WX(t) which can be obtained 78
2through any operations with learnable weights including convolutional operation, self-attention, or a 79
simple MLP. We will denote this process of forwarding through LIF neuron as SNN (·)in this paper. 80
Direct SNN Training. The initial adoption of SNNs was through ANN-SNN conversion, primarily 81
due to their remarkable potential for reducing energy consumption. Various studies have aimed to 82
address the accuracy degradation that occurs during the conversion from ANNS to SNNs [22, 41, 24, 83
42]. 84
The spike generation by the step function in Equation (4) interfered with direct training without 85
modifying the functions. To bypass the step function, which is non-differentiable and thus unsuitable 86
for backpropagation, several approaches have been proposed [43, 5, 13, 14, 8, 51, 10]. Recent 87
research has demonstrated that directly training SNNs can yield competitive results by addressing 88
the challenges posed by non-differentiability. Our work focuses on directly training graph neural 89
networks (GNNs) with SNNs and exploring a different domain, such as ANN-SNN conversion 90
methods, which do not focus on using backpropagation concepts directly. 91
2.2 Graph Neural Networks 92
Graph neural networks (GNNs) take graph-represented data as input, which consist of nodes and 93
their connected edges G= (V, E), with node features X∈R|V|×Fand optionally edge features 94
E∈R|E|×D. The common GNN architectures follow a message passing paradigm [20], which 95
learns node or edge representations through aggregating information from its neighboring nodes 96
and updating the node features iteratively. Thus a single forward of message passing layer consists 97
of message passing, aggregation, and update: h(l+1)
i =ϕ(h(l)
i,L
j∈N(i)ψ(h(l)
i, h(l)
j, eij)),where 98
landiare indices for layer and node, respectively, and ψ(·)denote message passing function. 99
After aggregation of neighboring features, ϕ(·)is used for feature update. For graph convolutional 100
network [27], the overall process can be simplified as: 101
X(l+1)=AX(l)W(l), (5)
where the feature matrix is a concatenation of node features X(l)= [h(l)
0||h(l)
1||...||h(l)
(|V|−1)]Twhich 102
is updated through iterations of aggregation ( AX) and combination ( XW ). After iterative updates of 103
Xthrough the layers, the learned node or edge embeddings are passed through additional classification 104
layer for node-level or edge-level predictions. 105
Graph Classification In this paper we put emphasis on graph-level classification tasks where each 106
graph is considered an individual input. Graph classification follows the same node-wise message 107
passing framework to obtain node embeddings, but appends a readout layer to turn them into a single 108
graph embedding: 109
hG=R(h(L)
i|Vi∈ G), (6)
where Rdenotes readout function. Readout function reduces the node dimension to a single channel 110
regardless of the input size. This is due to the inductive nature of graph classification task where 111
the number of nodes is not known in advance. While all the other GNN layers focus on aggregating 112
only the local features, the readout layer considers the entire graph to generate global features, 113
and is unique to the graph classification tasks. The obtained graph embedding is passed through a 114
classification layer for graph predictions. Graph classification tasks usually hold more difficulty than 115
node-level classification due to its inductive nature, where inference is done on unseen graphs and 116
thus cannot utilize any graph-specific statistics from the train set. 117
2.3 Spiking Graph Neural Networks 118
In this paper, we adopt conventional SNN designs where LIF neurons are connected through learn- 119
abled weights, and apply is to GNN framework [64]. As mentioned in Section 2.2, each GNN layer 120
outputs updated feature matrix X(l+1)∈R|V|×F. This is converted to spike representation through 121
SNN layer: 122
X(l+1)=SNN (AX(l)W(l)). (7)
After passing the GNN layer, all of the updated h(l)
idirectly pass through the SNN layer, consist the 123
feature matrix X(l)always contains spike information consistently. 124
3(a) Histogram plotting distribution of total spikes counted over time for each node. X-axis denotes spike counts
from each node, while y-axis denotes density of each bin.
max
minmax
minmax
min321
(b) Spike frequency visualization using each layer output. X-axis denotes feature dimension, while y-axis
denotes nodes grouped and sorted by degree in descending order, top to bottom. Brighter spots denote higher
frequency.
Figure 1: Analysis on spike frequency variation of GCN using IMDB-BINARY [54] dataset.
3 Analysis on Spike Frequency Variation of GNNs 125
To analyze the cause of the accuracy drop, we plot the behavior of the neurons during inference in 126
Figure 1a, on a IMDB-BINARY dataset over five timesteps ( T= 5). We create a histogram of spike 127
counts created from each node, which is associated with 128 neurons. As depicted in the plot, it is 128
clear that most of the neurons are under starvation. This is caused by the inputs of those neurons 129
being insufficient to reach the threshold, and this leads to severe information loss between the layers. 130
While unveiling the exact dynamics would require more research, we hypothesize that this is caused 131
by the topology of the real-world graphs. 132
To validate the hypothesis and further investigate the phenomena, we display the spike frequency 133
heatmap of the neurons sorted by the degree of the nodes in Figure 1b. From the heatmap, we make 134
three observations: 135
1(Brighter on the top and darker at the bottom) High-degree nodes tend to exhibit higher spike 136
frequencies. 137
2(The horizontal strips) The spike frequencies are associated with the corresponding nodes. 138
3(The vertical strips) The feature neurons within a node behave differently according to their 139
positions. 140
We believe such patterns come from the connectivity of the nodes, and the distinct role of the neurons 141
assigned to each node. The connectivity will affect the number of receiving spikes of neurons 142
associated with each node. It is known that most of the real-world graphs exhibit an extremely skewed 143
distribution of degrees (i.e., power-law distribution [30]). Due to such a characteristic, there are a few 144
nodes with very high degrees, while a majority of nodes have low degrees. Because a GNN layer 145
communicates signals between the neighbors, a high-degree node will likely receive a lot of spikes, 146
while a low-degree node will receive only a few. 147
4tInput Graphs
⊕ClassificationPoisson EncoderGNN LayerTopology-Aware  Group-Adaptive NeuronsFReadout LayercClassification HeadFt=1SNN Layer
t=TGNN Layer N layers×
Poisson EncoderGNN LayerTopology-Aware  Group-Adaptive NeuronsFReadout LayercClassification HeadFSNN LayerGNN Layer N layers×Figure 2: Overall graph classification architecture with proposed methods.
In addition, the neurons assigned to each node are known to have different semantic functionality 148
according to their positions, analogous to channels in convolutional neural networks or heads in 149
large language models. For example, the input first layer of a molecular graph will have information 150
such as its energy, x/y/z location, and atom numbers. In the intermediate layers, they represent a 151
specific pattern sensed by the network (such as high energy + hydrogen atom), even though the exact 152
behaviors are yet to be human-interpretable. In such a manner, the neurons in the same position are 153
expected to behave similarly, even though they correspond to different nodes. 154
These three observations shed light on how to close the performance gap between spiking GNNs are 155
ANN-based GNNs. In the next section, we describe how the observations are used to build better 156
spiking GNNs for graph classification. 157
4 Proposed Method 158
4.1 Overall Graph Classification Architecture 159
Many recent studies have tried to adapt SNN architectures into GNN tasks, however, they simply 160
try to contact with only node classification tasks. In this work, we propose a spiking neural network 161
specifically designed for graph classification tasks and show that it can be trained using spikes. We 162
demonstrate the overall architecture of our graph classification model TAS-GNN in Figure 2. For each 163
timestep, the input graphs are first translated into spike representations through the poisson encoder, 164
then the message passing is done in spike format. After the combination phase in the GNN layer, the 165
node features are once again binarized into spike format through passing the SNN layer. In the last 166
layer, we perform an extra operation of aggregation and combination on the spike features before 167
passing the readout layer. The readout layer is essential to graph classification and is responsible for 168
aggregating all the node embeddings in the graph into a single graph representation. A batch of graph 169
embeddings is passed through a classification head that outputs logits for that timestep. To make the 170
final prediction, we simply take the sum of logits from all timesteps and use softmax to obtain the 171
class probabilities. 172
4.2 Topology-Aware Group-Adaptive Neurons 173
As discussed in Section 3, GNNs suffer from a huge gap in spike frequencies between neurons. As 174
observed, there exist some patterns (Figure 5) that we can utilize to address the issue. One naive 175
way of addressing the issue is to use learnable [49], or adaptive [4] threshold for each neuron. By 176
adjusting the threshold, one can expect the neurons to naturally change, such that neurons under 177
starvation will have lower thresholds to fire more often, and a few neurons with high firing rates will 178
have higher thresholds to shift toward an ideal distribution. 179
5Unfortunately, such an idea cannot be directly applied unless all the testset nodes are available at 180
training time (i.e., transductive task). However, such a setting would be considered a data leak for 181
graph classification, and would also lose the advantage SNNs have on lightweight inference. 182
Moreover, the number of nodes in a real-world dataset often ranges from at least thousands to several 183
billions. Considering that GNNs often involve only a sub-million number of learnable parameters, 184
storing such a large number of thresholds is considered too much overhead. 185
To address the aforementioned issues, we propose topology-aware group adaptive neurons (TAG), 186
which partitions the neurons by their degrees. Note that Vgdenotes the node group to which the 187
node is mapped, considering degree information. Sgi(t)andVgi(t)represent the output spike and 188
membrane potential of the i-th node in group gat time t, respectively, as reformulated by Equation (4). 189
We use gto represent the unique degree distribution of the training sets. When an unseen node is 190
encountered, we apply the initial threshold, as it has not been trained at all. 191
Sgi(t) =1,ifVgi(t)≥Vg
th(t−1)
0,otherwise(8)
Sg(t) =1
|Vg|X
i∈VgSgi(t) (9)
Vg
th(t) =γVg
th(t−1) + (1 −γ)Sg(t) (10)
The major advantage of this scheme is that it is straightforward to put an unseen node or an unseen 192
graph into a group at inference. To further consider intra-node deviation, we split the group into 193
F(number of features) neurons, which is a fixed parameter determined by the model architecture. 194
For any unseen node, finding out its degree is trivial because visiting its neighbors is one of the 195
fundamental requirements of graph data structures [26, 50, 36, 28]. Based on the observation 1 196
from Section 3 that the neuron behavior is related to the degree, this will let neurons in the group 197
collaboratively find an adequate threshold. 198
4.3 Reducing the Initial Threshold Sensitivity 199
Figure 3: Sensitivity of neurons to its
initial threshold.The proposed Group-adaptive threshold scheme effec- 200
tively reduces the spike frequency variation issue. How- 201
ever, we find that the adaptive neurons in the proposed 202
TAG are sensitive to their initial thresholds. As depicted 203
in Figure 3, the performance of the adaptive neurons can 204
severely drop when the initial threshold value is not care- 205
fully tuned, which aligns with the findings from [4]. More- 206
over, manually tuning the initial thresholds individually is 207
difficult because there are thousands of neuron groups. 208
To address the problem, we choose to learn the two pa- 209
rameters: the initial threshold per group ( Vg
th(0)) and the 210
decay rate ( β). During training, we adopted the backprop- 211
agation algorithm [51, 10, 8] to update the value of Vg
th(0) 212
with the gradients at time step t=1. This is done because Vg
th(t)keeps updating with TAG Section 4.2 213
as time passes. During training, we also learn the decay rate ( β) [16], which prevents the membrane 214
voltage of neurons in low-degree nodes from leaking faster than it accumulates. For evaluation, we 215
use the Vg
th(0)values obtained during the training phase, adjusted for each group. The overall training 216
procedure is in the Appendix. 217
5 Evaluation 218
5.1 Experiment Settings 219
We use a total of 5 graph datasets commonly used for benchmarking GNNs: MUTAG [9], PRO- 220
TEINS [6], ENZYMES [6], NCI1 [47], and IMDB-Binary [54]. For the GNN layer in our architecture, 221
we use 3 different designs, including GCN [27], GAT [45], and GIN [52]. The baselines include 222
3 works from SNN that are applicable to graph datasets: SpikingGNN [64], SpikeNet [32], and 223
6Table 1: Performance comparison against baseline methods.
Model Method MUTAG PROTEINS ENZYMES NCI1 IMDB-BINARY
GCNANN [27] 88.86 ±5.48 77.81 ±3.46 72.00 ±4.37 76.42 ±2.98 56.80 ±4.80
SpikingGNN [64] 90.96 ±3.99 74.39 ±2.68 50.67 ±4.91 73.41 ±1.60 68.40 ±2.96
SpikeNet [32] 87.81 ±5.60 74.75 ±3.20 50.00 ±3.33 73.92 ±1.54 70.30 ±2.17
PGNN [16] 87.28 ±5.87 77.36 ±2.68 56.33 ±3.17 76.52 ±1.46 71.60 ±2.17
TAS-GNN 96.32±3.10 (+5.35) 77.45±1.94 (+0.09) 56.50±3.87 (+0.17) 77.81±1.28 (+1.29) 80.10±2.49 (+8.50)
GATANN [45] 83.04 ±4.23 77.54 ±3.22 59.67 ±3.48 67.88 ±3.00 54.50 ±2.14
SpikingGNN [64] 78.71 ±5.34 59.66 ±0.21 29.17 ±3.14 66.25 ±1.77 50.00 ±0.00
SpikeNet [32] 78.22 ±3.67 64.60 ±3.22 51.67 ±4.96 66.84 ±1.60 50.00 ±0.00
PGNN [16] 82.49 ±4.98 64.06 ±2.37 39.50 ±2.87 68.32 ±1.49 50.00 ±0.00
TAS-GNN 96.32±3.10 (+13.83) 71.34±3.03 (+6.74) 52.33±3.47 (+0.67) 75.33±2.41 (+7.01) 77.90±2.18 (+27.90)
GINANN [52] 95.23 ±5.61 78.79 ±3.74 33.67 ±4.66 79.17 ±3.07 70.40 ±4.14
SpikingGNN [64] 92.60 ±4.41 77.81 ±2.71 45.17 ±5.01 70.29 ±2.01 74.30 ±1.47
SpikeNet [32] 93.66 ±4.62 78.43 ±2.63 44.33 ±3.98 74.77 ±1.63 74.80±2.74
PGNN [16] 94.18 ±4.84 79.16 ±2.61 43.33 ±5.45 75.38 ±1.41 72.80 ±4.63
TAS-GNN 95.76±3.47 (+1.58) 80.32±2.42 (+1.17) 48.00±4.01 (+2.83) 77.52±1.49 (+2.14) 73.70 ±3.11 (-1.10)
†Did not converge
Table 2: Ablation study on the proposed method
Model Method MUTAG PROTEINS ENZYMES NCI1 IMDB-BINARY
GCNBaseline 90.96 74.39 50.67 73.41 68.40
+ TAG 93.66 (+2.69) 75.65 (+1.26) 49.00 (-1.67) 73.65 (+0.24) 71.90 (+3.50)
TAS-GNN (Proposed) 96.32 (+5.35) 77.45 (+3.06) 56.50 (+5.83) 77.81 (+4.40) 80.10 (+11.70)
GATBaseline 78.71 59.66 29.17 66.25 50.00
+ TAG 80.35 (+1.64) 66.48 (+6.82) 51.83 (+22.67) 67.98 (+1.73) 50.00 (+0.00)
TAS-GNN (Proposed) 96.32 (+17.60) 71.34 (+11.68) 52.33 (+23.16) 75.33 (+9.08) 77.90 (+27.90)
GINBaseline 92.60 77.81 45.17 70.29 74.30
+ TAG 93.66 (+1.05) 78.35 (+0.53) 46.16 (+0.99) 73.67 (+3.38) 75.20 (+0.90)
TAS-GNN (Proposed) 95.76 (+3.16) 80.32 (+2.51) 48.00 (+2.83) 77.52 (+7.23) 73.70 (-0.60)
PGNN [16]. Since this is the first SNN design to target graph classification, we apply minor modi- 224
fications to each architecture, such as appending a readout layer. Note that SpikingGNN [64] was 225
originally proposed for GCN, but we extend it to both GAT and GIN. More details on the experiment 226
setting are included in the Appendix. 227
5.2 Results on Graph Classification 228
We compare TAS-GNN against prior works that adopt a spiking neural network to graph the dataset, 229
shown in Table 1. We also report the performance of conventional ANN for comparison. In all but 2 230
cases, TAS-GNN outperforms the baselines by a noticeable margin. In the cases where TAS-GNN 231
underperforms, the gaps are less than 1.1%p, smaller than the error bounds. In the opposite cases, the 232
improvement is up to 27.90%p, showing a great amount of improvement. 233
An intriguing result is that TAS-GNN performs better than ANN-based GNNs in several cases. 234
Improvements beyond the error bounds are found in MUTAG (GCN and GAT), NCI1 (GAT), and 235
IMDB-BINARY (GCN and GAT). Note that the model architecture and the number of learnable 236
parameters are the same in all methods. We believe this could come from the spiking neurons 237
efficiently capturing the irregular connections over several timesteps, thereby showing an advantage 238
over ANNs. 239
5.3 Ablation Study 240
In this section, we break down individual components of TAS-GNN and perform an ablation study, 241
which is reported in Table 2. Starting from baseline implementation, which does not differentiate 242
neurons used by each node, we apply TAG to show the effect of topology-aware group-adaptive 243
neurons. Then, we add our learnable initial threshold scheme to complete TAS-GNN. The results 244
show that TAG alone can improve the performance across all datasets and models. This means that 245
uneven spike distribution caused by indegree variance is a general problem shared across different 246
graph datasets, and simply grouping the nodes with similar indegree to share the same threshold helps 247
alleviate this problem. Lastly, adding a learnable initial threshold scheme further boosts the accuracy 248
in almost all cases, demonstrating its efficacy and stability. 249
7Model MethodVinit
0.50 1.50 2.50 5.00 7.00 10.00
GCNTAG 87.84 86.75 88.33 89.91 88.30 68.16
Ours 95.79 97.37 96.32 95.79 95.23 90.99
GATTAG 85.70 81.96 80.35 80.85 77.72 77.19
Ours 94.18 93.65 96.32 93.68 91.58 92.60
GINTAG 92.08 93.13 92.57 94.21 92.08 93.68
Ours 94.18 94.74 95.76 93.68 94.71 89.94
Figure 4: Sensitivity study of neurons to its initial threshold.
5.4 Sensitivity Study 250
Table 3: Sensitivity study on threshold learning
rate using MUTAG.
η
Model 0.001 0.005 0.01 0.05 0.1 0.5
GCN 93.68 96.84 96.32 96.84 96.84 84.15
GAT 86.78 94.18 96.32 94.18 94.71 92.05
GIN 89.97 95.26 95.76 93.16 93.13 91.02To validate our method’s efficacy in alleviat- 251
ing the sensitivity of the initial threshold value, 252
we perform a sensitivity study varying the val- 253
ues from 0.0 to 10.0. We compare our scheme 254
against the TAG method, which also adaptively 255
modulates the threshold during inference but 256
does not learn it from training. Our method 257
consistently performs indifferently to the initial 258
threshold value, which means arduous search or 259
tuning is unnecessary to achieve stable accuracy. 260
On the other hand, TAG is highly sensitive to the initial threshold and shows a performance gap up to 261
19.68%p except for GIN architecture, which is capturing structure well. 262
Since our scheme uses a learnable initial threshold, we also study its sensitivity for the learning rate, 263
shown in Table 3. TAS-GNN performs best around η= [0.005,0.1], and starts to degrade for further 264
increment or decrement. As denoted in the experimental setting, we use η= 0.01as the default. 265
5.5 Additional Analysis 266
In this section, we give additional analysis on TAS-GNN by studying its spike frequency distribution. 267
In Figure 5, we provide the same spike frequency visualization as done in Section 3, but using 268
TAS-GNN. Unlike Figure 1, which showed severe starvation with most nodes not generating spikes, 269
Figure 5a reveals that most nodes fire spikes, significantly alleviating the starvation problem. This 270
is further illustrated Figure 5b, where most neurons have non-zero spike values and, what’s more, 271
meaningfully reflect the topology of the graph. For nodes with higher degrees, the spikes are more 272
frequent (close to 5) due to having more incoming spikes from their neighbors. For GNNs, such 273
information is essential to capture the global topology of the graph. This shows that our design of 274
TAS-GNN faithfully reflects such information and can successfully propagate such information using 275
spikes. 276
6 Related Works 277
Graph Classification Graph classification requires identifying the global characteristics of each 278
graph and is commonly applied to domains such as bioinformatics [6], chemoinformatics [63], or 279
social network analysis [21, 37]. Popular examples include the molecular classification of chemical 280
compounds, proteins, or RNAs, where identifying the graph structural information is crucial. Due 281
to the success of GNNs, [27, 45, 52, 57] Most GNNs use a message passing paradigm [20] that 282
only aggregates local features. Thus, to obtain global features representing the entire graph, graph 283
pooling [56] is often used. Global pooling summarizes the entire graph into a fixed-size graph 284
embedding, which can be done by simply averaging or taking minimum or maximum values of the 285
node-wise embeddings. Other variations replace such simple operations with neural networks [46, 286
33] or integrate sorting to selectively choose which node embeddings to include [60]. More advanced 287
techniques such as hiearchical pooling utilze hiearchical information of graphs [40, 29, 18, 11] and 288
usually show better representation learning. [60] 289
8(a) Histogram plotting the distribution of total spikes counted over time for each node. X-axis denotes spike
counts from each node, while y-axis denotes density of each bin.
max
minmax
minmax
min
(b) Spike frequency visualization on TAS-GNN using each layer output. X-axis denotes feature dimension,
while y-axis denotes nodes grouped and sorted by degree in descending order, top to bottom. Brighter spots
denote higher frequency.
Figure 5: Analysis on spike frequency variation of GCN using IMDB-BINARY [54] dataset.
Spiking Neural Networks SNNs are a type of neural network where information is transmitted 290
using spikes, similar to how biological neurons work. They use different neuron models for capturing 291
spike signals effectively [23, 24] or adjusting parameters dynamically to compromise the accuracy 292
[16, 49, 4, 34]. One major area of SNN research is converting traditional ANNs into SNNs by 293
mapping ANN activation functions into spike signals [22, 41, 24, 42, 17]. Another focus is training 294
SNNs directly using backpropagation, similar to ANNs, which involves using various techniques 295
such as surrogate functions for backpropagation [43, 8] and adapting normalization techniques to 296
SNNs [42, 12, 25, 62]. 297
SNN for Graphs Previous attempts to apply SNNs to graph datasets have primarily focused on 298
node-level classification tasks [59, 44, 64] and have not yet been extended to graph-level tasks. While 299
[48] explored the application of spike training to Graph Attention Networks (GAT), it implemented the 300
message passing phase after the spiking phase, which deviates from previous structures. Additionally, 301
recent efforts have begun to integrate SNNs with other techniques for contrastive learning [31], 302
particularly in dynamic graphs [55], to adopt collaboration between GNNs and SNNs. 303
7 Conclusion 304
In this paper, we explore the application of SNNs to graph neural networks for graph classification 305
for the first time. After thoroughly analyzing the graph’s uneven spike distribution, we identify that 306
the degree of each node correlates to this phenomenon. To better accommodate such characteristics 307
of graphs, we propose topology-aware group-adaptive neurons, which uses separate neurons for each 308
degree group in the graph. In addition, we propose to learn the initial threshold and adaptively adjust 309
the threshold simultaneously to reduce its sensitivity and facilitate training using spikes. Combined 310
with the modified architecture for graph classification, we name our method TAS-GNN, and show 311
that it outperforms existing works by a noticeable margin. 312
9References 313
[1] James B. Aimone et al. “Provable Advantages for Graph Algorithms in Spiking Neural 314
Networks”. In: SPAA ’21. Virtual Event, USA: Association for Computing Machinery, 2021, 315
pp. 35–47. ISBN : 9781450380706. DOI:10.1145/3409964.3461813 .URL:https://doi. 316
org/10.1145/3409964.3461813 . 317
[2] Marco Arazzi et al. “Predicting tweet engagement with graph neural networks”. In: Proceedings 318
of the 2023 ACM International Conference on Multimedia Retrieval . 2023, pp. 172–180. 319
[3] Lei Bai et al. “Adaptive graph convolutional recurrent network for traffic forecasting”. In: 320
Advances in neural information processing systems 33 (2020), pp. 17804–17815. 321
[4] Guillaume Bellec et al. “Long short-term memory and learning-to-learn in networks of spiking 322
neurons”. In: Advances in neural information processing systems 31 (2018). 323
[5] Sander M Bohte, Joost N Kok, and Han La Poutre. “Error-backpropagation in temporally 324
encoded networks of spiking neurons”. In: Neurocomputing 48.1-4 (2002), pp. 17–37. 325
[6] Karsten M Borgwardt et al. “Protein function prediction via graph kernels”. In: Bioinformatics 326
21.suppl_1 (2005), pp. i47–i56. 327
[7] Defu Cao et al. “Spectral temporal graph neural network for multivariate time-series forecast- 328
ing”. In: Advances in neural information processing systems 33 (2020), pp. 17766–17778. 329
[8] Kaiwei Che et al. “Differentiable hierarchical and surrogate gradient search for spik- 330
ing neural networks”. In: Advances in Neural Information Processing Systems . Ed. 331
by S. Koyejo et al. V ol. 35. Curran Associates, Inc., 2022, pp. 24975–24990. URL: 332
https : / / proceedings . neurips . cc / paper _ files / paper / 2022 / file / 333
9e8c2895db691eaab85af37bddee75aa-Paper-Conference.pdf . 334
[9] Asim Kumar Debnath et al. “Structure-activity relationship of mutagenic aromatic and het- 335
eroaromatic nitro compounds. Correlation with molecular orbital energies and hydrophobicity”. 336
In:Journal of Medicinal Chemistry 34.2 (1991), pp. 786–797. DOI:10.1021/jm00106a046 . 337
eprint: https://doi.org/10.1021/jm00106a046 .URL:https://doi.org/10.1021/ 338
jm00106a046 . 339
[10] Shikuang Deng et al. “Temporal Efficient Training of Spiking Neural Network via Gradient 340
Re-weighting”. In: International Conference on Learning Representations . 2022. URL:https: 341
//openreview.net/forum?id=_XNtisL32jv . 342
[11] Frederik Diehl. “Edge contraction pooling for graph neural networks”. In: arXiv preprint 343
arXiv:1905.10990 (2019). 344
[12] Chaoteng Duan et al. “Temporal Effective Batch Normalization in Spiking Neural Networks”. 345
In:Advances in Neural Information Processing Systems . Ed. by S. Koyejo et al. V ol. 35. 346
Curran Associates, Inc., 2022, pp. 34377–34390. URL:https://proceedings.neurips. 347
cc/paper_files/paper/2022/file/de2ad3ed44ee4e675b3be42aa0b615d0-Paper- 348
Conference.pdf . 349
[13] Steve K Esser et al. “Backpropagation for Energy-Efficient Neuromorphic Computing”. In: 350
Advances in Neural Information Processing Systems . Ed. by C. Cortes et al. V ol. 28. Curran 351
Associates, Inc., 2015. URL:https://proceedings.neurips.cc/paper_files/paper/ 352
2015/file/10a5ab2db37feedfdeaab192ead4ac0e-Paper.pdf . 353
[14] Steven K Esser et al. “From the cover: Convolutional networks for fast, energy-efficient 354
neuromorphic computing”. In: Proceedings of the National Academy of Sciences of the United 355
States of America 113.41 (2016), p. 11441. 356
[15] Wenqi Fan et al. “Graph neural networks for social recommendation”. In: The world wide web 357
conference . 2019, pp. 417–426. 358
[16] Wei Fang et al. “Incorporating learnable membrane time constant to enhance learning of 359
spiking neural networks”. In: Proceedings of the IEEE/CVF international conference on 360
computer vision . 2021, pp. 2661–2671. 361
[17] Wei Fang et al. “Parallel Spiking Neurons with High Efficiency and Ability to Learn 362
Long-term Dependencies”. In: Advances in Neural Information Processing Systems . 363
Ed. by A. Oh et al. V ol. 36. Curran Associates, Inc., 2023, pp. 53674–53687. URL: 364
https : / / proceedings . neurips . cc / paper _ files / paper / 2023 / file / 365
a834ac3dfdb90da54292c2c932c997cc-Paper-Conference.pdf . 366
[18] Hongyang Gao and Shuiwang Ji. “Graph u-nets”. In: international conference on machine 367
learning . PMLR. 2019, pp. 2083–2092. 368
10[19] Tong Geng et al. “AWB-GCN: A graph convolutional network accelerator with runtime 369
workload rebalancing”. In: 2020 53rd Annual IEEE/ACM International Symposium on Mi- 370
croarchitecture (MICRO) . IEEE. 2020, pp. 922–936. 371
[20] Justin Gilmer et al. “Neural message passing for Quantum chemistry”. In: Proceedings of the 372
34th International Conference on Machine Learning-Volume 70 . 2017, pp. 1263–1272. 373
[21] Will Hamilton, Zhitao Ying, and Jure Leskovec. “Inductive representation learning on large 374
graphs”. In: Advances in neural information processing systems (2017). 375
[22] Bing Han, Gopalakrishnan Srinivasan, and Kaushik Roy. “Rmp-snn: Residual membrane 376
potential neuron for enabling deeper high-accuracy and low-latency spiking neural network”. 377
In:Proceedings of the IEEE/CVF conference on computer vision and pattern recognition . 378
2020, pp. 13558–13567. 379
[23] Alan L Hodgkin and Andrew F Huxley. “A quantitative description of membrane current and 380
its application to conduction and excitation in nerve”. In: The Journal of physiology 117.4 381
(1952), p. 500. 382
[24] Eric Hunsberger and Chris Eliasmith. “Spiking deep networks with LIF neurons”. In: arXiv 383
preprint arXiv:1510.08829 (2015). 384
[25] Haiyan Jiang et al. “TAB: Temporal Accumulated Batch Normalization in Spiking Neural 385
Networks”. In: The Twelfth International Conference on Learning Representations . 2024. URL: 386
https://openreview.net/forum?id=k1wlmtPGLq . 387
[26] Farzad Khorasani et al. “CuSha: vertex-centric graph processing on GPUs”. In: Proceedings of 388
the 23rd international symposium on High-performance parallel and distributed computing . 389
2014. 390
[27] Thomas N Kipf and Max Welling. “Semi-Supervised Classification with Graph Convolutional 391
Networks”. In: International Conference on Learning Representations . 2016. 392
[28] Jinho Lee et al. “Extrav: boosting graph processing near storage with a coherent accelerator”. 393
In:Proceedings of the VLDB Endowment (2017). 394
[29] Junhyun Lee, Inyeop Lee, and Jaewoo Kang. “Self-attention graph pooling”. In: International 395
conference on machine learning . PMLR. 2019, pp. 3734–3743. 396
[30] Jure Leskovec et al. “Patterns of Cascading Behavior in Large Blog Graphs”. In: Proceedings 397
of the 2007 SIAM International Conference on Data Mining (SDM) , pp. 551–556. DOI: 398
10.1137/1.9781611972771.60 .URL:https://epubs.siam.org/doi/abs/10.1137/ 399
1.9781611972771.60 . 400
[31] Jintang Li et al. “A Graph is Worth 1-bit Spikes: When Graph Contrastive Learning Meets Spik- 401
ing Neural Networks”. In: The Twelfth International Conference on Learning Representations . 402
2024. URL:https://openreview.net/forum?id=LnLySuf1vp . 403
[32] Jintang Li et al. “Scaling up dynamic graph representation learning via spiking neural net- 404
works”. In: Proceedings of the AAAI Conference on Artificial Intelligence . V ol. 37. 7. 2023, 405
pp. 8588–8596. 406
[33] Yujia Li et al. “Gated Graph Sequence Neural Networks”. In: Proceedings of ICLR’16 . 2016. 407
[34] Shuang Lian et al. “IM-LIF: Improved Neuronal Dynamics With Attention Mechanism for 408
Direct Training Deep Spiking Neural Network”. In: IEEE Transactions on Emerging Topics in 409
Computational Intelligence (2024). 410
[35] Wolfgang Maass. “Networks of spiking neurons: the third generation of neural network 411
models”. In: Neural networks 10.9 (1997), pp. 1659–1671. 412
[36] Kiran Kumar Matam et al. “GraphSSD: graph semantics aware SSD”. In: Proceedings of the 413
46th international symposium on computer architecture . 2019. 414
[37] Andrew Kachites McCallum et al. “Automating the construction of internet portals with 415
machine learning”. In: Information Retrieval 3 (2000), pp. 127–163. 416
[38] Aditya Pal et al. “Pinnersage: Multi-modal user embedding framework for recommendations at 417
pinterest”. In: Proceedings of the 26th ACM SIGKDD International Conference on Knowledge 418
Discovery & Data Mining . 2020, pp. 2311–2320. 419
[39] Jiezhong Qiu et al. “Deepinf: Social influence prediction with deep learning”. In: Proceedings 420
of the 24th ACM SIGKDD international conference on knowledge discovery & data mining . 421
2018, pp. 2110–2119. 422
11[40] Ekagra Ranjan, Soumya Sanyal, and Partha Talukdar. “Asap: Adaptive structure aware pooling 423
for learning hierarchical graph representations”. In: Proceedings of the AAAI conference on 424
artificial intelligence . V ol. 34. 04. 2020, pp. 5470–5477. 425
[41] Bodo Rueckauer et al. “Conversion of continuous-valued deep networks to efficient event- 426
driven networks for image classification”. In: Frontiers in neuroscience 11 (2017), p. 294078. 427
[42] Abhronil Sengupta et al. “Going deeper in spiking neural networks: VGG and residual archi- 428
tectures”. In: Frontiers in neuroscience 13 (2019), p. 95. 429
[43] Sumit B Shrestha and Garrick Orchard. “Slayer: Spike layer error reassignment in time”. In: 430
Advances in neural information processing systems 31 (2018). 431
[44] Yundong Sun et al. “SpikeGraphormer: A High-Performance Graph Transformer with Spiking 432
Graph Attention”. In: arXiv preprint arXiv:2403.15480 (2024). 433
[45] Petar Veli ˇckovi ´c et al. “Graph Attention Networks”. In: International Conference on Learning 434
Representations . 2018. 435
[46] Oriol Vinyals, Samy Bengio, and Manjunath Kudlur. “Order matters: Sequence to sequence 436
for sets”. In: arXiv preprint arXiv:1511.06391 (2015). 437
[47] Nikil Wale, Ian A Watson, and George Karypis. “Comparison of descriptor spaces for chemical 438
compound retrieval and classification”. In: Knowledge and Information Systems 14 (2008), 439
pp. 347–375. 440
[48] Beibei Wang and Bo Jiang. “Spiking gats: Learning graph attentions via spiking neural 441
network”. In: arXiv preprint arXiv:2209.13539 (2022). 442
[49] Siqi Wang, Tee Hiang Cheng, and Meng-Hiot Lim. “LTMD: learning improvement of spiking 443
neural networks with learnable thresholding neurons and moderate dropout”. In: Advances in 444
Neural Information Processing Systems 35 (2022), pp. 28350–28362. 445
[50] Yangzihao Wang et al. “Gunrock: A high-performance graph processing library on the GPU”. 446
In:Proceedings of the 21st ACM SIGPLAN symposium on principles and practice of parallel 447
programming . 2016. 448
[51] Yujie Wu et al. “Spatio-temporal backpropagation for training high-performance spiking neural 449
networks”. In: Frontiers in neuroscience 12 (2018), p. 323875. 450
[52] Keyulu Xu et al. “How Powerful are Graph Neural Networks?” In: International Conference 451
on Learning Representations . 2019. 452
[53] Mingyu Yan et al. “Hygcn: A gcn accelerator with hybrid architecture”. In: 2020 IEEE 453
International Symposium on High Performance Computer Architecture (HPCA) . IEEE. 2020, 454
pp. 15–29. 455
[54] Pinar Yanardag and SVN Vishwanathan. “Deep graph kernels”. In: Proceedings of the 21th 456
ACM SIGKDD international conference on knowledge discovery and data mining . 2015, 457
pp. 1365–1374. 458
[55] Nan Yin et al. “Dynamic spiking graph neural networks”. In: Proceedings of the AAAI Confer- 459
ence on Artificial Intelligence . V ol. 38. 15. 2024, pp. 16495–16503. 460
[56] Zhitao Ying et al. “Hierarchical graph representation learning with differentiable pooling”. In: 461
Advances in neural information processing systems 31 (2018). 462
[57] Mingi Yoo et al. “Sgcn: Exploiting compressed-sparse features in deep graph convolutional net- 463
work accelerators”. In: 2023 IEEE International Symposium on High-Performance Computer 464
Architecture (HPCA) . IEEE. 2023, pp. 1–14. 465
[58] Mingi Yoo et al. “Slice-and-Forge: Making Better Use of Caches for Graph Convolutional Net- 466
work Accelerators”. In: Proceedings of the International Conference on Parallel Architectures 467
and Compilation Techniques . 2022, pp. 40–53. 468
[59] Huizhe Zhang et al. “SGHormer: An Energy-Saving Graph Transformer Driven by Spikes”. 469
In:arXiv preprint arXiv:2403.17656 (2024). 470
[60] Muhan Zhang et al. “An end-to-end deep learning architecture for graph classification”. In: 471
Proceedings of the AAAI conference on artificial intelligence . V ol. 32. 1. 2018. 472
[61] Yiming Zhang et al. “Graph learning augmented heterogeneous graph neural network for social 473
recommendation”. In: ACM Transactions on Recommender Systems 1.4 (2023), pp. 1–22. 474
[62] Yaoyu Zhu et al. “Online Stabilization of Spiking Neural Networks”. In: The Twelfth Inter- 475
national Conference on Learning Representations . 2024. URL:https://openreview.net/ 476
forum?id=CIj1CVbkpr . 477
12[63] Yuanyuan Zhu et al. “Graph classification: a diversified discriminative feature selection ap- 478
proach”. In: Proceedings of the 21st ACM international conference on Information and 479
knowledge management . 2012, pp. 205–214. 480
[64] Zulun Zhu et al. “Spiking graph convolutional networks”. In: arXiv preprint arXiv:2205.02767 481
(2022). 482
13A Appendix / supplemental material 483
A.1 Limitation 484
Currently, our work is experimenting with the small-scale dataset for the graph classification that is 485
generally used. However, we will extend our work into the large-scale dataset that could apply to 486
the real. In addition, we will continue our future work for theoretical proof for updating the initial 487
threshold that is fused with adaptative changes in the timestep. 488
A.2 Code 489
The code which includes our implementation of this work is included in a zip archive of the sup- 490
plementary material. The code is under Nvidia Source Code License-NC and GNU General Public 491
License v3.0. 492
A.3 Detailed Experiment Settings 493
Dataset Details Given the diverse properties of graph datasets, we selected five datasets from the 494
well-known TUDatasets, commonly used for graph classification. We compiled statistics for these 495
datasets to briefly represent their key properties. 496
Table 4: Summary of datasets used in the study.
Dataset # GraphsAvg.
Nodes# Nodes
(1stgraph )Avg.
Edges# Edges
(1stgraph )# Classes
MUTAG [9] 188 17.93 17 19.79 38 2
PROTEINS [6] 1113 39.06 42 72.82 162 2
ENZYMES [6] 600 32.6 37 62.1 168 6
NCI1 [47] 4110 29.87 21 32.30 42 2
IMDB-BINARY [54] 1000 19.77 20 96.53 146 2
Network Architecture In this work, we consider the following three GNN architectures where the 497
distinctions lie in their update rules: 498
•Graph Convolution Network [27] (GCN): h(l+1)
i =σ(P
j∈N(i)S{i}Wh(l)
j √
|N(i)||N(j)|), where 499
ϕ(·)is replaced by affine transformation Wfollowed by nonlinearity σ. 500
•Graph Attention Network [45] (GAT): h(l+1)
i =αi,iWh(l)
i+P
j∈N(i)αijWh(l)
j, where 501
αijis the normalized attention score between node iandj. 502
•Graph Isomorphism Network [52] (GIN): h(l+1)
i =MLP ((1 + ϵ)h(l)
i+P
j∈N(i)h(l)
j), 503
where ϵis a learnable constant. 504
For the GCN layers, 128 dimensions were used for hidden dimensions, and GAT layers were used for 505
4 multi-head attentions. GIN was used for 2-MLP layers for the above equation. 506
Experiment Settings We trained and evaluated our models using 10-fold cross-validation for all 507
datasets. Note that the IMDB-BINARY dataset lacks inherent features, so we constructed features 508
using the node degrees for the GNN layer. Additionally, we did not apply any multiplier to adjust 509
the width of the sigmoid function. The details of our evaluation procedure are outlined below. Our 510
experiment was evaluated on a single RTX-4090 GPU for the full batch GNN training. 511
• Epochs: 1000 512
• Surrogate function: σ(x) =1
1+e−x 513
• Learning rate( η): 0.01 (for main table) 514
• Optimizer: Adamw 515
• Loss function: Cross entropy 516
• Adaptive step size( γ): 0.2 517
14A.4 Analysis on Spike Frequency 518
We provide additional figures that we referenced on Section 3. Appendix A.4 shows MUTAG, 519
PROTEINS, ENZYMES, NCI1 dataset total spike histogram bins. 520
521
A.5 Overall training procedure 522
As referred on Section 4 our TAG method and overall updating initial values of group threshold is 523
reffed on Algorithm 1. Note that our initial group values updated after timestep T. 524
Algorithm 1 Updataing Vg
th(0)procedure
1:Inputs: Initial start points of threshold Vinit, graph’s vertex feature X∈RV XF, learning rate for training
η, total time step T,l-th layer’s threshold V(l)
th,l-th layer’s GNN layer GNN(l), true label Y,
2:Initialize: Vg
th(0)= [Vinit, ...Vinit] ▷Initialize all of the g threshold groups with initial values
3:forep= 1toepochs do
4: fort= 1toTdo
5: X=PoissonEncoder (X) ▷Binarize first input layer with Poisson encoder
6: forl= 1toLdo
7: forgin group Gdo
8: Xg,(l)=GNN(l)(Xg,(l)) ▷Operate by GCN, GAT, GIN architectures
9: fori= 1to|Vg|do
10: Xgi,(l)=Sgi,(l)(t) =SNN(l)(Xgi,(l)) ▷ Xgi,(l)represents i-th row of Xg,(l)
11: Sg,(l)(t) =1
|Vg|P
i∈VgSgi(t)
12: end for
13: Vg,(l)
th (t) =γVg,(l)
th (t−1) + (1 −γ)Sg,(l)(t)▷Update threshold through TAG Equation (10)
14: end for
15: end for
16: Ot←FC(POOL (GNN (X(L)))) + Ot−1
17: end for
18: Vth(0) = Vth(0)−η∇Vth(0)L(Ot=1, Y)
19:end for
A.6 Sensitivity Study on Degree Group 525
Our experiments were conducted on a number of degree groups. Please refer Table 5 for the sensitivity 526
depending on the number of degree groups. Please note that the optimal values of the degree groups 527
are different depending on the graph datasets. We reported to the max degree group setting that 528
unseen nodes will use the initial values Vinitthat represents the Vth(0)that does not trained at all. 529
A.7 Sensitivity Study on Learning Rate 530
Our experiments were conducted under various learning rate conditions η∈[0.001,0.5]to assess their 531
impact. As reported in Table 3 for the MUTAG dataset, we also present results for the PROTEINS, 532
ENZYMES, NCI1, and IMDB-BINARY datasets across GCN, GAT, and GIN architectures. Our 533
model’s ability to learn Vinitdemonstrates a sensitivity to learning rate similar to other ANN models. 534
We found that the optimal performance was achieved at a learning rate of η= 0.01. 535
15(a) MUTAG-SpikingGNN spikes per node
(b) MUTAG-TASGNN spikes per node
(c) PROTEINS-SpikingGNN spikes per node
(d) PROTEINS-TASGNN spikes per node
(e) ENZYMES-SpikingGNN spikes per node
(f) ENZYMES-TASGNN spikes per node
16(g) NCI1-SpikingGNN spikes per node
(h) NCI1-TASGNN spikes per node
Figure 6: Histogram plotting distribution of total spikes counted over time for each node. X-axis
denotes spike counts from each node, while y-axis denotes density of each bin.
NeurIPS Paper Checklist 536
The checklist is designed to encourage best practices for responsible machine learning research, 537
addressing issues of reproducibility, transparency, research ethics, and societal impact. Do not remove 538
the checklist: The papers not including the checklist will be desk rejected. The checklist should 539
follow the references and precede the (optional) supplemental material. The checklist does NOT 540
count towards the page limit. 541
Please read the checklist guidelines carefully for information on how to answer these questions. For 542
each question in the checklist: 543
• You should answer [Yes] , [No] , or [NA] . 544
•[NA] means either that the question is Not Applicable for that particular paper or the 545
relevant information is Not Available. 546
• Please provide a short (1–2 sentence) justification right after your answer (even for NA). 547
The checklist answers are an integral part of your paper submission. They are visible to the 548
reviewers, area chairs, senior area chairs, and ethics reviewers. You will be asked to also include it 549
(after eventual revisions) with the final version of your paper, and its final version will be published 550
with the paper. 551
The reviewers of your paper will be asked to use the checklist as one of the factors in their evaluation. 552
While "[Yes] " is generally preferable to "[No] ", it is perfectly acceptable to answer "[No] " provided a 553
proper justification is given (e.g., "error bars are not reported because it would be too computationally 554
expensive" or "we were unable to find the license for the dataset we used"). In general, answering 555
"[No] " or "[NA] " is not grounds for rejection. While the questions are phrased in a binary way, we 556
acknowledge that the true answer is often more nuanced, so please just use your best judgment and 557
write a justification to elaborate. All supporting evidence can appear either in the main paper or the 558
supplemental material, provided in appendix. If you answer [Yes] to a question, in the justification 559
please point to the section(s) where related material for the question can be found. 560
IMPORTANT, please: 561
•Delete this instruction block, but keep the section heading “NeurIPS paper checklist" , 562
•Keep the checklist subsection headings, questions/answers and guidelines below. 563
•Do not modify the questions and only use the provided macros for your answers . 564
17Table 5: Comparison on using different number of degree group
Dataset#Degree
GroupGCN GAT GIN
MUTAG1 87.81 80.88 94.71
2 96.84 87.78 96.32
3 93.10 95.79 95.79
4(max) 96.32 96.32 95.76
PROTEINS1 78.89 64.33 78.89
2 78.98 63.88 78.98
5 75.83 67.39 75.83
10 77.45 69.55 77.45
15 77.99 70.54 77.99
17(max) 77.45 71.34 80.32
ENZYMES1 58.33 41.33 45.17
2 56.50 40.50 44.33
5 52.00 45.00 41.50
10(max) 56.50 52.33 48.00
NCI11 75.74 67.86 73.82
2 75.77 68.08 75.06
3 77.86 72.48 76.86
4 77.81 74.26 76.74
5(max) 77.81 75.33 77.52
IMDB-BINARY1 71.70 50.00 74.60
2 70.40 50.30 72.90
5 69.30 56.80 71.00
10 66.70 56.40 66.70
20 64.00 61.30 66.20
50 65.99 64.51 65.55
65(max) 80.10 77.90 73.70
1.Claims 565
Question: Do the main claims made in the abstract and introduction accurately reflect the 566
paper’s contributions and scope? 567
Answer: [Yes] 568
Justification: Our paper contributes on the scope of Spiking Neural Networks and Graph 569
Neural Networks scopes in graph classification task specifically 570
Guidelines: 571
•The answer NA means that the abstract and introduction do not include the claims 572
made in the paper. 573
•The abstract and/or introduction should clearly state the claims made, including the 574
contributions made in the paper and important assumptions and limitations. A No or 575
NA answer to this question will not be perceived well by the reviewers. 576
•The claims made should match theoretical and experimental results, and reflect how 577
much the results can be expected to generalize to other settings. 578
•It is fine to include aspirational goals as motivation as long as it is clear that these goals 579
are not attained by the paper. 580
2.Limitations 581
Question: Does the paper discuss the limitations of the work performed by the authors? 582
Answer: [Yes] 583
Justification: We discuss the limitation on the Appendix. 584
Guidelines: 585
•The answer NA means that the paper has no limitation while the answer No means that 586
the paper has limitations, but those are not discussed in the paper. 587
18Table 6: Extended sensitivity study on threshold learning rate.
η
Dataset Model 0.001 0.005 0.01 0.05 0.1 0.5
MUTAGGCN 93.68 96.84 96.32 96.84 96.84 84.15
GAT 86.78 94.18 96.32 94.18 94.71 92.05
GIN 89.97 95.26 95.76 93.16 93.13 91.02
PROTEINSGCN 75.11 76.82 77.45 77.36 76.82 65.67
GAT 64.14 70.35 71.34 73.23 74.93 70.53
GIN 77.72 79.07 80.32 78.17 76.55 75.65
ENZYMESGCN 45.00 51.17 56.50 56.83 54.67 29.17
GAT 32.00 45.00 52.33 55.83 42.67 34.33
GIN 37.33 44.33 48.00 35.17 31.33 29.33
NCI1GCN 73.87 77.37 77.81 80.07 78.81 66.95
GAT 66.93 73.31 75.33 76.06 73.48 66.69
GIN 72.80 76.57 77.52 70.54 69.05 64.94
IMDB-BinaryGCN 78.90 79.90 80.10 80.50 80.60 73.60
GAT 74.80 75.80 77.90 75.60 75.90 75.30
GIN 74.10 73.00 73.70 75.40 74.70 73.60
• The authors are encouraged to create a separate "Limitations" section in their paper. 588
•The paper should point out any strong assumptions and how robust the results are to 589
violations of these assumptions (e.g., independence assumptions, noiseless settings, 590
model well-specification, asymptotic approximations only holding locally). The authors 591
should reflect on how these assumptions might be violated in practice and what the 592
implications would be. 593
•The authors should reflect on the scope of the claims made, e.g., if the approach was 594
only tested on a few datasets or with a few runs. In general, empirical results often 595
depend on implicit assumptions, which should be articulated. 596
•The authors should reflect on the factors that influence the performance of the approach. 597
For example, a facial recognition algorithm may perform poorly when image resolution 598
is low or images are taken in low lighting. Or a speech-to-text system might not be 599
used reliably to provide closed captions for online lectures because it fails to handle 600
technical jargon. 601
•The authors should discuss the computational efficiency of the proposed algorithms 602
and how they scale with dataset size. 603
•If applicable, the authors should discuss possible limitations of their approach to 604
address problems of privacy and fairness. 605
•While the authors might fear that complete honesty about limitations might be used by 606
reviewers as grounds for rejection, a worse outcome might be that reviewers discover 607
limitations that aren’t acknowledged in the paper. The authors should use their best 608
judgment and recognize that individual actions in favor of transparency play an impor- 609
tant role in developing norms that preserve the integrity of the community. Reviewers 610
will be specifically instructed to not penalize honesty concerning limitations. 611
3.Theory Assumptions and Proofs 612
Question: For each theoretical result, does the paper provide the full set of assumptions and 613
a complete (and correct) proof? 614
Answer: [NA] 615
Justification: Our work does not include theoretical results. 616
Guidelines: 617
• The answer NA means that the paper does not include theoretical results. 618
•All the theorems, formulas, and proofs in the paper should be numbered and cross- 619
referenced. 620
•All assumptions should be clearly stated or referenced in the statement of any theorems. 621
19•The proofs can either appear in the main paper or the supplemental material, but if 622
they appear in the supplemental material, the authors are encouraged to provide a short 623
proof sketch to provide intuition. 624
•Inversely, any informal proof provided in the core of the paper should be complemented 625
by formal proofs provided in appendix or supplemental material. 626
• Theorems and Lemmas that the proof relies upon should be properly referenced. 627
4.Experimental Result Reproducibility 628
Question: Does the paper fully disclose all the information needed to reproduce the main ex- 629
perimental results of the paper to the extent that it affects the main claims and/or conclusions 630
of the paper (regardless of whether the code and data are provided or not)? 631
Answer: [Yes] 632
Justification: We provided our codes that able to reproduce our model’s result. 633
Guidelines: 634
• The answer NA means that the paper does not include experiments. 635
•If the paper includes experiments, a No answer to this question will not be perceived 636
well by the reviewers: Making the paper reproducible is important, regardless of 637
whether the code and data are provided or not. 638
•If the contribution is a dataset and/or model, the authors should describe the steps taken 639
to make their results reproducible or verifiable. 640
•Depending on the contribution, reproducibility can be accomplished in various ways. 641
For example, if the contribution is a novel architecture, describing the architecture fully 642
might suffice, or if the contribution is a specific model and empirical evaluation, it may 643
be necessary to either make it possible for others to replicate the model with the same 644
dataset, or provide access to the model. In general. releasing code and data is often 645
one good way to accomplish this, but reproducibility can also be provided via detailed 646
instructions for how to replicate the results, access to a hosted model (e.g., in the case 647
of a large language model), releasing of a model checkpoint, or other means that are 648
appropriate to the research performed. 649
•While NeurIPS does not require releasing code, the conference does require all submis- 650
sions to provide some reasonable avenue for reproducibility, which may depend on the 651
nature of the contribution. For example 652
(a)If the contribution is primarily a new algorithm, the paper should make it clear how 653
to reproduce that algorithm. 654
(b)If the contribution is primarily a new model architecture, the paper should describe 655
the architecture clearly and fully. 656
(c)If the contribution is a new model (e.g., a large language model), then there should 657
either be a way to access this model for reproducing the results or a way to reproduce 658
the model (e.g., with an open-source dataset or instructions for how to construct 659
the dataset). 660
(d)We recognize that reproducibility may be tricky in some cases, in which case 661
authors are welcome to describe the particular way they provide for reproducibility. 662
In the case of closed-source models, it may be that access to the model is limited in 663
some way (e.g., to registered users), but it should be possible for other researchers 664
to have some path to reproducing or verifying the results. 665
5.Open access to data and code 666
Question: Does the paper provide open access to the data and code, with sufficient instruc- 667
tions to faithfully reproduce the main experimental results, as described in supplemental 668
material? 669
Answer: [Yes] 670
Justification: We provide our codes that are able to reproduce our full experiments. 671
Guidelines: 672
• The answer NA means that paper does not include experiments requiring code. 673
•Please see the NeurIPS code and data submission guidelines ( https://nips.cc/ 674
public/guides/CodeSubmissionPolicy ) for more details. 675
20•While we encourage the release of code and data, we understand that this might not be 676
possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not 677
including code, unless this is central to the contribution (e.g., for a new open-source 678
benchmark). 679
•The instructions should contain the exact command and environment needed to run to 680
reproduce the results. See the NeurIPS code and data submission guidelines ( https: 681
//nips.cc/public/guides/CodeSubmissionPolicy ) for more details. 682
•The authors should provide instructions on data access and preparation, including how 683
to access the raw data, preprocessed data, intermediate data, and generated data, etc. 684
•The authors should provide scripts to reproduce all experimental results for the new 685
proposed method and baselines. If only a subset of experiments are reproducible, they 686
should state which ones are omitted from the script and why. 687
•At submission time, to preserve anonymity, the authors should release anonymized 688
versions (if applicable). 689
•Providing as much information as possible in supplemental material (appended to the 690
paper) is recommended, but including URLs to data and code is permitted. 691
6.Experimental Setting/Details 692
Question: Does the paper specify all the training and test details (e.g., data splits, hyper- 693
parameters, how they were chosen, type of optimizer, etc.) necessary to understand the 694
results? 695
Answer: [Yes] 696
Justification: We wrote experiment setting in the experiment settings including GNN layers, 697
hyperparameter for the hidden dimension, and learning rate of the whole dataset. Also, we 698
wrote epochs and dataset we split was used by 10 fold CV for our evaluations. 699
Guidelines: 700
• The answer NA means that the paper does not include experiments. 701
•The experimental setting should be presented in the core of the paper to a level of detail 702
that is necessary to appreciate the results and make sense of them. 703
•The full details can be provided either with the code, in appendix, or as supplemental 704
material. 705
7.Experiment Statistical Significance 706
Question: Does the paper report error bars suitably and correctly defined or other appropriate 707
information about the statistical significance of the experiments? 708
Answer: [Yes] 709
Justification: We reported error of confidence level in the main table. 710
Guidelines: 711
• The answer NA means that the paper does not include experiments. 712
•The authors should answer "Yes" if the results are accompanied by error bars, confi- 713
dence intervals, or statistical significance tests, at least for the experiments that support 714
the main claims of the paper. 715
•The factors of variability that the error bars are capturing should be clearly stated (for 716
example, train/test split, initialization, random drawing of some parameter, or overall 717
run with given experimental conditions). 718
•The method for calculating the error bars should be explained (closed form formula, 719
call to a library function, bootstrap, etc.) 720
• The assumptions made should be given (e.g., Normally distributed errors). 721
•It should be clear whether the error bar is the standard deviation or the standard error 722
of the mean. 723
•It is OK to report 1-sigma error bars, but one should state it. The authors should 724
preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis 725
of Normality of errors is not verified. 726
21•For asymmetric distributions, the authors should be careful not to show in tables or 727
figures symmetric error bars that would yield results that are out of range (e.g. negative 728
error rates). 729
•If error bars are reported in tables or plots, The authors should explain in the text how 730
they were calculated and reference the corresponding figures or tables in the text. 731
8.Experiments Compute Resources 732
Question: For each experiment, does the paper provide sufficient information on the com- 733
puter resources (type of compute workers, memory, time of execution) needed to reproduce 734
the experiments? 735
Answer: [Yes] 736
Justification: It refers to the appendix for experimental settings. 737
Guidelines: 738
• The answer NA means that the paper does not include experiments. 739
•The paper should indicate the type of compute workers CPU or GPU, internal cluster, 740
or cloud provider, including relevant memory and storage. 741
•The paper should provide the amount of compute required for each of the individual 742
experimental runs as well as estimate the total compute. 743
•The paper should disclose whether the full research project required more compute 744
than the experiments reported in the paper (e.g., preliminary or failed experiments that 745
didn’t make it into the paper). 746
9.Code Of Ethics 747
Question: Does the research conducted in the paper conform, in every respect, with the 748
NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines ? 749
Answer: [Yes] 750
Justification: Research conducted in the paper conforms, in every respect, with the NeurIPS 751
Code of Ethics 752
Guidelines: 753
•The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. 754
•If the authors answer No, they should explain the special circumstances that require a 755
deviation from the Code of Ethics. 756
•The authors should make sure to preserve anonymity (e.g., if there is a special consid- 757
eration due to laws or regulations in their jurisdiction). 758
10.Broader Impacts 759
Question: Does the paper discuss both potential positive societal impacts and negative 760
societal impacts of the work performed? 761
Answer: [Yes] 762
Justification: SNN would be one of the breakthrough idea in respect of energy consumption. 763
Guidelines: 764
• The answer NA means that there is no societal impact of the work performed. 765
•If the authors answer NA or No, they should explain why their work has no societal 766
impact or why the paper does not address societal impact. 767
•Examples of negative societal impacts include potential malicious or unintended uses 768
(e.g., disinformation, generating fake profiles, surveillance), fairness considerations 769
(e.g., deployment of technologies that could make decisions that unfairly impact specific 770
groups), privacy considerations, and security considerations. 771
•The conference expects that many papers will be foundational research and not tied 772
to particular applications, let alone deployments. However, if there is a direct path to 773
any negative applications, the authors should point it out. For example, it is legitimate 774
to point out that an improvement in the quality of generative models could be used to 775
generate deepfakes for disinformation. On the other hand, it is not needed to point out 776
that a generic algorithm for optimizing neural networks could enable people to train 777
models that generate Deepfakes faster. 778
22•The authors should consider possible harms that could arise when the technology is 779
being used as intended and functioning correctly, harms that could arise when the 780
technology is being used as intended but gives incorrect results, and harms following 781
from (intentional or unintentional) misuse of the technology. 782
•If there are negative societal impacts, the authors could also discuss possible mitigation 783
strategies (e.g., gated release of models, providing defenses in addition to attacks, 784
mechanisms for monitoring misuse, mechanisms to monitor how a system learns from 785
feedback over time, improving the efficiency and accessibility of ML). 786
11.Safeguards 787
Question: Does the paper describe safeguards that have been put in place for responsible 788
release of data or models that have a high risk for misuse (e.g., pretrained language models, 789
image generators, or scraped datasets)? 790
Answer: [NA] 791
Justification: Our paper poses no such risks for high risk for misuse. 792
Guidelines: 793
• The answer NA means that the paper poses no such risks. 794
•Released models that have a high risk for misuse or dual-use should be released with 795
necessary safeguards to allow for controlled use of the model, for example by requiring 796
that users adhere to usage guidelines or restrictions to access the model or implementing 797
safety filters. 798
•Datasets that have been scraped from the Internet could pose safety risks. The authors 799
should describe how they avoided releasing unsafe images. 800
•We recognize that providing effective safeguards is challenging, and many papers do 801
not require this, but we encourage authors to take this into account and make a best 802
faith effort. 803
12.Licenses for existing assets 804
Question: Are the creators or original owners of assets (e.g., code, data, models), used in 805
the paper, properly credited and are the license and terms of use explicitly mentioned and 806
properly respected? 807
Answer: [Yes] 808
Justification: We reported owners of assets used in the paper in the Appendix 809
Guidelines: 810
• The answer NA means that the paper does not use existing assets. 811
• The authors should cite the original paper that produced the code package or dataset. 812
•The authors should state which version of the asset is used and, if possible, include a 813
URL. 814
• The name of the license (e.g., CC-BY 4.0) should be included for each asset. 815
•For scraped data from a particular source (e.g., website), the copyright and terms of 816
service of that source should be provided. 817
•If assets are released, the license, copyright information, and terms of use in the 818
package should be provided. For popular datasets, paperswithcode.com/datasets 819
has curated licenses for some datasets. Their licensing guide can help determine the 820
license of a dataset. 821
•For existing datasets that are re-packaged, both the original license and the license of 822
the derived asset (if it has changed) should be provided. 823
•If this information is not available online, the authors are encouraged to reach out to 824
the asset’s creators. 825
13.New Assets 826
Question: Are new assets introduced in the paper well documented and is the documentation 827
provided alongside the assets? 828
Answer: [Yes] 829
23Justification: Considering our implemtation code is our asset, our work provides necessary 830
license and documents for further usage. 831
Guidelines: 832
• The answer NA means that the paper does not release new assets. 833
•Researchers should communicate the details of the dataset/code/model as part of their 834
submissions via structured templates. This includes details about training, license, 835
limitations, etc. 836
•The paper should discuss whether and how consent was obtained from people whose 837
asset is used. 838
•At submission time, remember to anonymize your assets (if applicable). You can either 839
create an anonymized URL or include an anonymized zip file. 840
14.Crowdsourcing and Research with Human Subjects 841
Question: For crowdsourcing experiments and research with human subjects, does the paper 842
include the full text of instructions given to participants and screenshots, if applicable, as 843
well as details about compensation (if any)? 844
Answer: [NA] 845
Justification: Our work does not involve crowdsourcing nor research with human subjects. 846
Guidelines: 847
•The answer NA means that the paper does not involve crowdsourcing nor research with 848
human subjects. 849
•Including this information in the supplemental material is fine, but if the main contribu- 850
tion of the paper involves human subjects, then as much detail as possible should be 851
included in the main paper. 852
•According to the NeurIPS Code of Ethics, workers involved in data collection, curation, 853
or other labor should be paid at least the minimum wage in the country of the data 854
collector. 855
15.Institutional Review Board (IRB) Approvals or Equivalent for Research with Human 856
Subjects 857
Question: Does the paper describe potential risks incurred by study participants, whether 858
such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) 859
approvals (or an equivalent approval/review based on the requirements of your country or 860
institution) were obtained? 861
Answer: [NA] 862
Justification: Our work does not require IRB approvals and does not involve human subjects. 863
Guidelines: 864
•The answer NA means that the paper does not involve crowdsourcing nor research with 865
human subjects. 866
•Depending on the country in which research is conducted, IRB approval (or equivalent) 867
may be required for any human subjects research. If you obtained IRB approval, you 868
should clearly state this in the paper. 869
•We recognize that the procedures for this may vary significantly between institutions 870
and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the 871
guidelines for their institution. 872
•For initial submissions, do not include any information that would break anonymity (if 873
applicable), such as the institution conducting the review. 874
24