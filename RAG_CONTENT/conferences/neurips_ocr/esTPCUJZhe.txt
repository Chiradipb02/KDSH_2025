Overcoming Brittleness in Pareto-Optimal
Learning-Augmented Algorithms
Alex Elenter
Sorbonne University, CNRS, LIP6
4 place Jussieu
Paris, France 75005
alexelenter@gmail.comSpyros Angelopoulos
International Laboratory on Learning Systems
Montreal, Canada, and
Sorbonne University, CNRS, LIP6
Paris, France 75005
spyros.angelopoulos@lip6.fr
Christoph Dürr
Sorbonne University, CNRS, LIP6
4 place Jussieu
Paris, France 75005
christoph.durr@lip6.frYanni Lefki∗
Institut Polytechnique de Paris
Rte de Saclay
Palaiseau, 91120, France
yanni.lefki@gmail.com
Abstract
The study of online algorithms with machine-learned predictions has gained consid-
erable prominence in recent years. One of the common objectives in the design and
analysis of such algorithms is to attain (Pareto) optimal tradeoffs between the con-
sistency of the algorithm, i.e., its performance assuming perfect predictions, and its
robustness , i.e., the performance of the algorithm under adversarial predictions. In
this work, we demonstrate that this optimization criterion can be extremely brittle,
in that the performance of Pareto-optimal algorithms may degrade dramatically
even in the presence of imperceptive prediction error. To remedy this drawback,
we propose a new framework in which the smoothness in the performance of
the algorithm is enforced by means of a user-specified profile . This allows us to
regulate the performance of the algorithm as a function of the prediction error,
while simultaneously maintaining the analytical notion of consistency/robustness
tradeoffs, adapted to the profile setting. We apply this new approach to a well-
studied online problem, namely the one-way trading problem. For this problem, we
further address another limitation of the state-of-the-art Pareto-optimal algorithms,
namely the fact that they are tailored to worst-case, and extremely pessimistic
inputs. We propose a new Pareto-optimal algorithm that leverages any deviation
from the worst-case input to its benefit, and introduce a new metric that allows us
to compare any two Pareto-optimal algorithms via a dominance relation.
1 Introduction
The field of learning-augmented online algorithms has witnessed remarkable growth in recent years,
starting with the seminal works of Lykouris and Vassilvitskii [ 31] and Purohit et al. [36]. The
focus, in this field, is on improving the algorithmic performance by leveraging some inherently
imperfect prediction on the online input. This is in contrast to the standard framework of competitive
analysis [15], in which the algorithm has no access to any information about the future, and the
analysis is based on adversarial inputs tailored to the myopic nature of the algorithm.
∗Research done while at LIP6, Sorboonne University.
38th Conference on Neural Information Processing Systems (NeurIPS 2024).Learning-augmented online algorithms are typically analyzed with respect to three performance
metrics. The first is the consistency of the algorithm, namely its competitive ratio assuming that
the prediction is error-free. The second is the robustness , that is, the competitive ratio assuming
that the prediction is adversarial, and is thus generated by a malicious oracle. A third consideration
is the degradation of the competitive ratio as a function of the prediction error; here, the notion of
smoothness captures the requirement that the competitive ratio smoothly interpolates between the
two extremes, namely the consistency and the robustness.
As expected, not all three objectives can be simultaneously optimized. Many works have thus focused
on the trade-off between consistency and robustness. Algorithms with optimal tradeoffs are often
called Pareto-optimal since their performance lies on the Pareto front of the two extreme metrics.
Examples of problems studied in the Pareto setting include online conversion problems [ 38,29],
searching for a hidden target [ 4], ski rental [ 39,6], online covering [ 14] metrical task systems [ 17],
energy-minimization scheduling [28], scheduling [7, 5] and online state exploration [23].
Pareto-based analysis is attractive for several reasons. First, it fully characterizes the performance of
the algorithm on the extreme scenarios, with respect to the reliability of the prediction. In addition, it
provides a mathematically clean formulation of the desired objectives, which is often quite challenging
even for seemingly simple online problems. However, as we will discuss, this type of analysis may
very well suffer from brittleness , in that the performance ratio of any Pareto-optimal algorithm may
be as high as its robustness, even if the prediction is near-perfect. This has an important implication
for the algorithm designer: namely, in many realistic situations, a Pareto-optimal algorithm may
perform even worse than the best competitive algorithm with no predictions.
To illustrate this drawback, as well as our proposed methodology for counteracting it, we will use
the well-known one-way trading problem, which is one of the fundamental formulations for online
financial transactions. In this problem, a decision maker must convert a unit in a given currency,
say USD, to a different currency, say EUR, by performing exchanges over an unknown horizon.
Specifically, prior to each transaction, the algorithm is informed about the current exchange rate, and
must irrevocably exchange a fraction of its USD budget to EUR, according to the rate in question.
This problem has served as a proving ground for the competitive analysis of more involved settings
such as two-way trading and portfolio optimization; see Chapter 14 in [ 15] and the survey [ 35].
In addition, it has connections to other problems such as fractional knapsack [ 16] and sponsored
auctions [ 41]. Optimal competitive ratios, in the standard framework, were first obtained in [ 19].
An elegant Pareto-optimal algorithm for maximum-rate prediction was given in [ 38], based on the
concept of an online threshold function. However, [ 38] does not take into consideration the prediction
error other than at the two extreme values. In contrast, the interplay between the prediction error
across the entire spectrum and the performance of the algorithm is at the heart of our study.
1.1 Contribution
Our first result (Theorem 3.1) establishes the brittleness of all Pareto-optimal algorithms for one-way
trading. To remedy this undesirable situation, in Section 3 we introduce the novel concept of a
performance profile F, chosen by the end user. Informally, Fmaps the prediction error to an upper
bound on the desired performance ratio of the algorithm. This concept is motivated by practical
considerations in everyday applications. E.g., in financial markets, a trader may choose a customized
profile based on historical stock exchange data, and how accurate past predictions have proven.
Naturally, not every profile may be feasible , in that there may not exist an online algorithm whose
performance abides with it. Our next main result is an algorithm that decides whether a given profile
is feasible (Theorem 3.2). Note that this is an offline problem, however, our algorithm also yields an
online strategy, if Fis indeed feasible. This further allows us to obtain an online algorithm that not
only abides with a feasible profile F, but also with the “best” possible profile that has a shape similar
to that of F(Remark 4.1). We formalize this intuitive notion based on the concept of the best vertical
translation of F. We thus obtain a generalization of the concept of consistency (which is brittle) to the
consistency according to profile F, which is inherently non-brittle by virtue of the profile definition.
In Section 5, we address another limitation of the known Pareto-optimal algorithms for one-way
trading. Specifically, we note that the algorithm of [ 38] is tailored to worst-case inputs in which
the exchange rates increase continuously until a certain point, then drop to the lowest rate. Again
from a practical standpoint, such a worst-case scenario never arises in real markets. Motivated by
2the concept of the lenient adversary of [19] (in the standard, no-prediction setting), we present and
analyze an adaptive , Pareto-optimal algorithm that leverages any deviation from the worst-case
sequence to its benefit. To formally quantify the performance gain, we introduce an additional metric
that captures the profit of the algorithm on all exchange rates that are at least as high as the predicted
maximum rate, and allows us to compare any two Pareto-optimal algorithms via a dominance relation.
Another novelty of our algorithm, in the context of the problem at hand, is that it does not require
the prediction to be given ahead of time, instead the prediction can be revealed during its execution
(Remark 5.1). This is a clearly desirable algorithmic feature, that has been achieved in other online
problems, e.g., [9].
In Section 6 we give an experimental evaluation of all our algorithms, over both real data (Bitcoin
exchange rates) and synthetic data, which validates the theoretical results and quantifies the obtained
performance improvements. We emphasize that our framework can be readily applicable to other
learning-augmented problems, in particular those which suffer from brittleness. We discuss another
well-known application from AI, namely contract scheduling [7] in Section 7.
In terms of techniques, our algorithms and analysis are based on the concept of a threshold function
which carefully guides the actions of the algorithm. While online threshold algorithms have been
used in previous studies, including one-way trading [ 41,40,38,29], the settings we study pose novel
challenges. For the profile-based setting, the design of the function must take into consideration all
the constraints induced by the profile. To this end, we use an iterative approach that considers the
constraints incrementally, until they are all satisfied. For the adaptive setting, the threshold function
must change dynamically, according to the revealed sequence. This is unlike the standard Pareto
setting, in which a static function suffices.
While our framework is directly applicable to single-valued predictions, it can also be applied to
more complex settings in which the prediction is a vector of values. This is because the concept of
the profile still applies, since the error is defined by a distance norm between the predicted and the
actual vector.
1.2 Related Work
There has been a significant body of recent work on online algorithms with predictions, see, e.g.,
the surveys [ 34,33]. Several problems have been studied in learning-augmented settings, e.g.,
paging [ 31,22], metrical task systems [ 9,17], rent-or buy problems [ 36,6,20,39,3], packing and
covering [ 14,8,21], scheduling [ 26,28,11,32,18,25], matching [ 27,10,24], graph optimization [ 1,
2, 12, 13], and many others. This is only a partial list; for a comprehensive summary of the existing
literature, we refer the reader to the online repository [ 30]. As discussed earlier, many works have
focused exclusively on consistency/robustness tradeoffs, without an explicit error-based analysis,
e.g. [ 38,29,4,39,6,14,17,28,7,23,1]. Incorporating smoothness in regards to the prediction error
is a challenging task, both in terms of modeling and analysis. For instance, [ 13,1] studied online
combinatorial optimization problems in which the performance of the online degrades as a function
of a distance measure between the predicted and the actual solution. Our work differs from such
studies in that the dependency on the prediction error is user specific , and can change according to
the application setting, while still maintaining the concepts of consistency and robustness.
2 Preliminaries
In the one-way trading problem, the input σis a sequence of exchange rates , where pidenotes the i-th
rate in the sequence. The trader has a starting budget equal to 1. We follow the standard assumption
thatpi∈[1, M], where Mrepresents an upper bound on the rates that is known in advance. Once
piis revealed, the trader must decide the amount to be exchanged to the secondary currency, which
cannot exceed her current budget. We consider the general setting in which the horizon nis not
known ahead of time. The problem formulation also assumes that the trader is notified once the last
rate is revealed, and is thus obliged to exchange all of its remaining fund at rate pn.
An algorithm Adecides the fractional exchanges upon revealing of pi, as a function of the previous
i−1rates , i.e., the sequence σ[1, i−1]. We denote by A(σ)theprofit ofAonσ, i.e., the total amount
thatAhas produced after the last exchange. We denote by p∗
σ= max i∈[1,n]pithemaximum rate
inσand by OPT(σ)the profit of the optimal offline strategy, hence OPT(σ) =p∗
σ. The competitive
3ratio of Ais thus defined as CR(A) = supσOPT(σ)
A(σ). For given σ, we refer to the ratio OPT(σ)/A(σ)
as the performance ratio ofAonσ. The optimal competitive ratio, denoted by r∗isΘ(log M), and
more precisely, it is equal to the root of the equation r∗= lnM−1
r∗−1[19].
Given algorithm A, we denote by wA,i(σ)andsA,i(σ), the budget used by Aand its accrued profit
right before piis revealed, respectively. We refer to wA,i(σ)as the utilization ofA. Formally, for
every sequence σ, and every algorithm A, we have wA,i=wAi−1+xi, where xiis the amount
traded on the i-th rate, that is, wA,iis the total amount exchanged up to and including the i-th request.
We also have that si=Pi−1
j=1pj(wj+1−wj), with s1= 0. For simplicity, we may omit the input σ,
or the algorithm Awhen it is clear from context. For example, we will denote by p∗the maximum
rate in σ.
The above definitions assume the standard setting in which the algorithm has no information on
the input. In regards to learning-augmented settings, we consider the model of [ 38] in which the
algorithm has an imperfect prediction ˆponp∗. We define formally, the consistency and the robustness
of an algorithm Aasc(A) = supσ:p∗σ=ˆpp∗
σ
A(σ)andr(A) = supσsupˆp∈[1,M]p∗
σ
A(σ), respectively. An
algorithm Awith prediction ˆpisPareto-optimal if, for any given r, it has robustness at most r, and
has the smallest possible consistency, which we will denote by c(r).
Remark 2.1. It suffices to consider only sequences in which the exchange rates increase up to a
certain point, then drop to 1 [ 19]. Moreover, for any competitively optimal algorithm, the worst-case
inputs are such in which the exchange rates increase continuously, i.e., by infinitesimal amounts.
3 Brittleness of Pareto-Optimal Algorithms and Performance Profiles
We first define formally the concept of brittleness .
Definition 3.1. Letˆpdenote a maximum-rate prediction for p∗
σ. We say that ˆpisbrittle if for any
Pareto-optimal strategy Aof robustness rand consistency c(r), and for every ϵ >0,there exists σ
with|ˆp−p∗
σ| ≤ϵ, for whichp∗(σ)
A(σ)=r.
The definition deems a prediction to be brittle if there exist sequences for which the slightest prediction
error forces every Pareto-Optimal strategy to have a performance that is equal to its robustness.
Theorem 3.1 (Appendix A) .The maximum-rate prediction is brittle for one-way trading.
Theorem 3.1 shows that Pareto-optimality is a very “fragile” metric for comparing strategies with
max-rate prediction. To remedy this drawback, we introduce the new concept of a profile .
Definition 3.2. LetPbe a partition of [1, M]tolintervals, i.e., P=Sl
i=1[qi, qi+1), with q1= 1
andql+1=M, and let ˆpbe a maximum-rate prediction. A profile function F:P →R+is a step
function that maps each interval in Ptoti∈R+, and which satisfies the following conditions. There
exists ˆı∈[1, l]such that: (i) ti−1≥ti, for all i≤ˆıandti+1≥ti, for all i≥ˆı, and (ii) ˆp∈[qˆı, qˆı+1).
The profile function allows the end user to impose a requirement on the performance of the algorithm,
as expressed in the following definition.
Definition 3.3. We say that an online strategy Arespects a given profile F:Sl
i=1[qi, qi+1)→R+
if for all input sequences σfor which p∗
σ∈[qi, qi+1), it holds thatOPT(σ)
A(σ)≤F([qi, qi+1)).
Informally, a profile Freflects a desired worst-case performance of an algorithm, assuming that
theactual but unknown maximum rate in the input sequence is in the interval [qi, qi+1). Thus, the
profile represents the desired upper bound on the performance of an algorithm, as a function of
the prediction error. Unlike Pareto-optimality, which only cares about performance at extremes,
the relation between performance and prediction error becomes now definable across the entire
spectrum of error. The definition also reflects the expectation that the algorithm performs best when
the prediction is error-free, and its performance degrades monotonically as a function of the error.
We illustrate the above concepts using the profile depicted in Figure 1a. Here, the profile consists of
l= 6intervals, where the first 3 intervals correspond to the decreasing part of the profile and the
4maximum
rateperformance
ratio
q1= 1 q7=M ˆpt1
t3
q2 q4t2
q3t4
q5t5t6
q6
(a) A profile function Fwith six intervals.maximum
rateperformance
ratio
q1= 1q4=Mt1
q2=q3= ˆpt2
(b) Pareto profile
Figure 1: Illustration of profile functions.
last 4 to the increasing part of the profile. Note that the interval [q3, q4)contains the prediction ˆpand
belongs in both the decreasing and the increasing parts. Note also that the profile allows to define an
asymmetric dependency on the prediction error. This is a very useful property in applications such
as one-way trading. For example, a trader may want to be more cautious if the market will perform
worse in the future, than better in the future, relative to what has been predicted.
Figure 1b depicts a different profile in which the performance ratio must be at most t1, for any error,
unless the prediction is error-free, in which case the performance ratio has to be at most t2< t1.
Such a profile yields Pareto-optimality, if t1=randt2=c(r).
We are interested in profiles Fthat are feasible , in the sense there exists an online algorithm that
respects F. The following is one of our main results, whose proof will follow from Theorem 4.1 and
Corollary 4.1, as we will show in Section 4.
Theorem 3.2. Given a profile Fdefined over lintervals, there exists an algorithm for deciding
whether Fis feasible that runs in time O(l). Furthermore, if Fis feasible, there exists an online
algorithm that respects F.
Given our algorithm that decides the feasibility of a profile, we can also answer a more general
question. Suppose that Fis infeasible, but we would like, nevertheless, to be able to respect a profile
F′that is “similar” to F. Conversely, if Fis feasible, then we know we can likely do even better, for
example, we would like to follow a profile F′that is similar to F, but maps some intervals to smaller
ratios. The following definition formalizes this intuitive objective.
Definition 3.4. LetF:P →R+denote a profile. Given a∈R+, we define the extension Ga
ofFas the vertical transformation of F, in which, for every interval [qi, qi+1)∈ P it holds that
Ga([qi, qi+1)) =a·F([qi, qi+1)).
We can generalize the concepts of consistency and robustness relative to a profile Fas follows,
recalling that ˆp∈[qˆı, qˆı+1).
Definition 3.5. Given a profile Ffor a prediction ˆp, and a robustness r, we say that algorithm Ais
r-robust and c-consistent according to F, if there exists an extension GaofFfor which: (i) for every
interval, we have Ga([qi, qi+1))≤r; (ii)Ga([qˆı, qˆı+1))≤c; and (iii) Arespects Ga.
Remark 3.1. The smoothness of a profile is related to the number of intervals, l. The larger the l, the
smoother the performance of an algorithm which respects the profile.
4 Profile-Based Algorithms
In this section, we present an algorithm which decides whether a given profile Fis feasible or not.
Note that this is an offline , decision problem, which we will denote by FEASIBLE (F). In addition, if
Fis feasible, we also provide an online algorithm that respects F.
Our algorithms are inspired by the class of threshold algorithms (OTA), introduced in [ 41]. In these
algorithms, a threshold function Φguides the decision about the amount to be exchanged when a
5Algorithm 1 Algorithm P ROFILE for F EASIBLE (F); also an online strategy if Fis feasible
Input: F:P=Sl
i=1[qi, qi+1)→R+. Denote F([qi, qi+1))byti.
1:w1←0, s←0
2:fori∈1, . . . , l do
3: ρi←ti·(s+ 1−wi)
4: ifρi≥qithen
5: wi+1←1
ti·ln
qi+1−1
ρi−1
+wi
6: Φi(w)←Φi−1(w) ifw∈[1, wi)
(ρi−1)·eti·(w−wi)+ 1 ifw∈[wi, wi+1)
7: s←s+Rwi+1
wiΦi(t)dt
8: else
9: w′
i←qi−ti·(si−wiqi+1)
tj·(qi−1)
10: s′←s+qi·(w′
i−wi)
11: wi+1←1
ti·ln
qi+1−1
ti·(s′+1−w′
i)−1
+w′
i
12: Φi(w)←Φi−1(w) ifw∈[1, wi)
(ti·(s′+ 1−w′
i)−1)·eti·(w−w′
i)+ 1 ifw∈[w′
i, wi+1)
13: wi←w′
i
14: s←s′+Rwi+1
wiΦi(t)dt
15:ifwl+1>1then return Fis infeasible else return Fis feasible and output Φl
new rate is revealed. Specifically, Φmaps utilization toreservation rates . Here, a utilization value
w∈[0,1]represents the fractional amount exchanged so far by the online algorithm, whereas the
reservation rate, ρ, is the minimum rate in [1, M]at which the algorithm will make an exchange. At
each point a new rate piis revealed, the algorithm updates its utilization by setting wi+1= Φ−1(pi),
ifpi>Φ(wi), otherwise wi+1=wi. In both cases, it exchanges an amount equal to wi+1−wiat
ratepi. The function Φmust be increasing, and its codomain must include [1, M].
The main challenge posed in our setting is to guarantee the varying performance ratios globally, i.e.,
for all intervals and not just locally for a given interval. Thus, we need a global approach that takes
into account the entirety of the profile, and in particular the transitions between consecutive intervals.
We will thus design a function Φso as to satisfy lset of constraints, where each set of constraints
applies to a specific interval. Define ˜si=Rwi
0Φ(u)du, with ˜s1= 0. We seek a function Φand
values 0 =w1≤. . .≤wl+1≤1such that the following constraints are satisfied for all i∈[1, l].
[β] ∀β∈[wi, wi+1) :Φ(β)
˜si+Rβ
wiΦ(t)dt+ 1−β≤ti.
[wi+1] Φ(wi+1) =qi+1.
[u] wi≤wi+1≤1.
Constraint [ β] expresses the requirement on the performance ratio F([qi, qi+1))that is imposed by
the profile. Note that here ˜siis the minimum profit of an OTA at the point it reaches utilization wi.
This follows from Remark 2.1. Constraint [ wi+1] allows us to obtain the partition of the utilization
levels induced by the profile. Moreover, such a constraint is needed for constraint [ β] to correctly
represent the performance ratio indicated by the profile. Constraint [u] establishes that the utilization
levels defined are increasing and that they do not exceed the unit budget available to the algorithm.
The following lemma follows straightforwardly from the above discussion.
Lemma 4.1. Fis feasible if and only if there exist Φandw1, . . . , w l+1that satisfy the above sets of
constraints, for all i∈[1, l].
Algorithm 1, which we call PROFILE , shows how to obtain the threshold function Φ, along with the
utilization values w1, . . . w l+1, assuming that Fis feasible. This is formally stated in Theorem 4.1.
We emphasize that the theorem proves an even stronger statement; namely, if Fis not feasible, then
PROFILE correctly outputs its infeasibility. That is, the algorithm fully solves F EASIBLE (F).
6Theorem 4.1 (Appendix B) .A profile Fadmits an online strategy which respects Fif and only if
PROFILE terminates with a value wl+1≤1.
Furthermore, if Fis feasible, then P ROFILE directly provides an online algorithm that respects F:
Corollary 4.1. IfFis feasible, then the threshold function Φlreturned by PROFILE defines an OTA
which respects F.
Remark 4.1. For a profile F, we can use binary search in combination with PROFILE , in order to
find the minimum a∈R+, such that Gaextends FandGais feasible, according to Definition 3.4.
We give some intuition about PROFILE , and how we obtain Φ, and the values wi, for all i. The
algorithm computes Φincrementally: namely, in iteration i, it obtains a new function Φithat aims to
satisfy the sets of constraints for the intervalsSi
k=1[qk, qk+1), and computes a value for wi+1, as
well as an updated value for wi. In each iteration i, the algorithm guarantees that an OTA based on Φi
respects the profile on all sequences whose maximum rate is in [1, qi+1)(provided that this is indeed
feasible) and, furthermore, that the utilization at the end of iteration i, namely wi+1is as small as
possible. This is crucial, since it allows us to decide FEASIBLE (F)based on the final value of wl+1.
The algorithm makes a distinction between two types of updates. The first type occurs in the
increasing part of the profile, i.e., when ti< ti−1. This is a relatively simpler case, because the
algorithm has already guaranteed a smaller ratio in the previous interval. Hence the algorithm can
afford to wait until it sees a rate that exceeds the reservation rate ρi(line 5-7). The second type occurs
in the decreasing part of the profile (lines 9-14). This is intuitively a harder case, because on every
new interval the algorithm must do even better than in the previous intervals. That is, when observing
a rate equal to qi, the algorithm now needs to perform at a ratio ti< ti−1, hence it should have made
a bigger profit. To this end, we need first to increase wi(lines 9 and 13) then extend Φi−1to account
for interval i(line 12). The precise amount by which we increase wiis guided by the requirement that
the algorithm must have performance ratio tifor the worst-case sequence of increasing rates up to qi.
5 An Adaptive Pareto-Optimal Algorithm
In this section we study another generalization of Pareto-optimality. The starting observation is
that the Pareto-optimal OTA of [ 38] is tailored to worst-case scenarios. Namely, the threshold
function in [ 38] isstatic , i.e., determined prior to the execution of the algorithm, and tailored to
a sequence of continuously increasing exchange rates that may suddenly drop to 1. However, in
practice, such sequences never occur in real markets. We show how to obtain an algorithm that is not
only Pareto-optimal, but also leverages deviations from the worst-case sequence to its benefit.
Our setting is further motivated by [ 19], who studied the basic setting of standard competitive analysis
without predictions. Their solution is based on threat-based policies, i.e., algorithms that exchange at
each point in time the minimum required amount so as to guarantee the optimal competitive ratio. In
this section, instead, we consider the learning-augmented setting in which the algorithm has access
to a max-rate prediction ˆp. Our algorithm uses an adaptive threshold policy, in which the threshold
function is updated every time a deviation from the worst-case input is observed. We follow this
approach since OTAs are typically more versatile than threat-based policies, and can apply to more
complex problems and settings, such as several variants of the knapsack problem, e.g., [40].
In a nutshell, we seek a Pareto-optimal algorithm that is not only optimal over worst-case sequences,
but also over all other sequences. To describe this formally, we first define some concepts. Let ˆpbe
a max-rate prediction for an input σof increasing rates, and define ˜σas the suffix of σcomprised
of rates at least as high as ˆp. (in the event that ˜σis the empty sequence, our problem reduces to
standard Pareto optimality). Let ˜σ= ˜p1, . . . , ˜pm, and ˜si+1(A, σ)denote the profit made by an online
algorithm Aonσafter its exchange over rate ˜pi, for any i∈[1, m], . Let also s(A, σ)denote the
vector⟨˜si(A, σ)⟩:i∈[1, m]. We say that algorithm Adominates another algorithm Bon input σ, if
s(A, σ)is lexicographically no smaller than s(B, σ).
Informally, s(A, σ)is the vector of profits that Ahas made so far, for each rate that is at least as
high as the predicted maximum rate. The lexicographic ordering assigns priority to profits made at
exchange rates close to, but larger than the prediction. We now state our main result.
Theorem 5.1 (Appendix C) .For any robustness requirement r,ADA-PO is Pareto-optimal and
dominates every other Pareto-optimal algorithm, on every possible sequence σ.
7Note that the algorithm of [ 38] is dominant only for sequences in which the exchange rates increase
continuously up to some p∗≥ˆp, then drop to 1. For those and all other sequences, our algorithm
dominates that of [38]. Note also that a dominant r-robust algorithm is a Pareto-optimal algorithm.
Algorithm 2 ADA-PO (adaptive Pareto-optimal)
Input: r∈R,ˆp∈[1, M]
1:w←0, s←0, p∗←1
2:forpi∈σdo
3: ifpi> p∗then
4: p∗←pi
5: ifpi≤ˆpthen
6: wi+1←pi−r·(s+1−wpi)
r·(pi−1)
7: s←s+pi·(wi+1−w)
8: w←wi+1
9: else
10: ifr·(s+ 1−pw+w∗)≥Mthen
11: wi+1←1
12: else
13: wi+1←w∗
14: s←s+pi·(wi+1−w)
15: w←wi+1
ADA-PO consists of two phases. The first phase (lines 5-9) consists of revealed rates strictly smaller
thanˆp. In this phase, the algorithm exchanges the minimum amounts so as to guarantee r-robustness
(i.e., it makes threat-based decisions). Here, adaptivity allows the algorithm to reserve its budget
for the second phase. The second phase (lines 11-15) consists of revealed rates at least as high as ˆp.
This is the challenging part, since we need to ensure simultaneously dominance and r-robustness, but
these two objectives are in a trade-off relation. Here, adaptivity allows us to exchange more money at
each revealed rate without sacrificing robustness.
Suppose that piis revealed in the second phase (i.e., pi≥ˆp). To achieve simultaneously the
robustness and the dominance, we need to find a continuous increasing Φwhose domain is [wi+1,1],
along with a value for wi+1. To this end, we solve the optimization problem Oi, described below.
Here, constraint [ β] is for guaranteeing r-robustness; and constraint [ M] and [u] guarantee that Φ
is well-defined as a threshold function. Maximizing wmaximizes the amount exchanged at rate pi,
which is essential for dominance. In Appendix C we give further details, and we show that Oihas
optimal solution w∗equal to the root of the equation w∗= 1−1
rln
M−1
r(si+1−piwi+w∗(pi−1)−1)
,
which is used in line 13 of A DA-PO.
max w (Oi)
subj. to
[β] ∀β∈[w,1) :Φ(β)
si+pi·(w−wi) +Rβ
wΦ(t)dt+ 1−β=r,
[M] Φ(1)≥M,
[u] wi≤w≤1.
Remark 5.1. ADA-PO, unlike the known static OTAs, does not require a prediction ˆpahead of time;
the prediction can be revealed during its execution instead, since it is only used in the second phase.
This can be very useful in practice, e.g., if the trader obtains information “on-the-fly”.
6 Experimental evaluation
We present experimental results for both the profile-based algorithm PROFILE (Algorithm 1) and the
adaptive Pareto-optimal algorithm A DA-PO (Algorithm 2). We compare our algorithms to the state
of the art Pareto-optimal algorithm of [38], which we denote by PO.
8Profile setting. We use a profile Fthat consists of three intervals [q1= 1, q2),[q2, q3)and[q3, q4=
M], where M= 100 . The profile is defined in terms of the prediction ˆp, by choosing q2= 0.9ˆpand
q3= 1.1ˆp. In addition, Fis such that F([q1, q2)) =t1=F([q3, q4]) =t3=r, where r= 4(larger
than, but close to the optimal competitive ratio r∗). Here, F([q2, q3)) =t2< ris the smallest value
such that Fis feasible. To find t2, we use binary search in [1, r]in combination with PROFILE , and
note that this depends on ˆp.Fis depicted in Figure 2a. Intuitively, rcorresponds to the robustness,
whereas t2is the performance ratio if the input σis such that p∗∈[0.9ˆp,1.1ˆp), i.e. if ˆpis “close” to
p∗. The length of [q2, q3), which is equal to 0.2ˆp, reflects how much the user trusts the prediction.
Figure 2b depicts the performance of PROFILE , and POwith robustness r, on the worst case sequences
of maximum rate p∗, as a function of p∗. Recall that such sequence is of the form 1, . . . , p∗,1, with
infinitesimal increments up to p∗, simulated using a step equal to 0.01. We denote this sequence
byσw
p∗. We choose ˆpu.a.r. in [1, M](ˆp= 67.8in Figure 2b). We observe that POexhibits high
brittleness if p∗is very close, but smaller than ˆp, namely has performance ratio of r, which validates
Theorem 3.1. In contrast, PROFILE guarantees a performance ratio equal to t2in the entire interval
[0,9ˆp,1.1ˆp], as required by F, thus tolerating a prediction error as high as 10%, while remaining
r-robust for all errors. This validates Theorem 4.1. As expected, POhas better ratio if p∗= ˆp(from
the definition of Pareto optimality).
To further quantify the performance difference between the two algorithms, we evaluated both
algorithms on 100 randomly defined worst-case sequences. Each sequence σw
p∗is obtained by
sampling ˆpu.a.r. in [1, M], and for such ˆp, by randomly picking p∗∈[0.9ˆp,1.1ˆp], the significant
prediction error for the user. Figure 2c depicts the relative performance difference of the two
algorithms for each σw
p∗, as a function of the prediction error. We observe that if p∗<ˆp, then
PROFILE improves upon POby 20% to 50% , whereas if p∗>ˆp,PROFILE is inferior by only 10% to
20%. The average improvement we report, taken over the 100 ratios is 22%. We conclude that while
both algorithms guarantee robustness r,PROFILE is not only smooth around the prediction, but also
performs better on the average, which supports the benefits from using a profile.
In addition, we performed experiments over sequences obtained from real trading data, using the
profile Fas above. We used exchange rates from Bitcoin (BTC) to USD; specifically, we used a list
of the last 1000 daily exchange rates (finishing on May 20, 2024), defining as the prediction ˆpthe
maximum rate in the first 200 rates, and running the algorithm on a sequence consisting of the last
800 rates. Figure 2d depicts the performance ratios of PROFILE andPO, where each point in the plot
corresponds to the maximum rate observed so far: these are the only rates at which the algorithms
make exchanges. We observe that POcontinues to suffer from brittleness, whereas PROFILE still
exhibits smooth degradation in the interval [0.9ˆp,1.1ˆp].
In Appendix E we report an additional experiment on the average performance over BTC sequences.
The key takeaway from all experiments on both synthetic and real sequences is that PROFILE performs
much better if p∗<ˆp, and at the same time it is only slightly worse, if p∗>ˆp. This behavior is due
to the smoothness enforced around the prediction, as guaranteed by the profile.
Adaptive setting. Since, by definition, POandADA-PO perform the same over worst-case sequences,
we focus on sequences from BTC rates. Based on a list of the last 1000 daily BTC rates, we obtain
a prediction ˆpand the sequence, as in our profile-based experiments above. Figure 2e plots the
performance ratio as a function of the currently observed maximum rate in the sequence. For every
such rate that exceeds ˆp,ADA-PO outperforms PO, which validates Theorem 5.1. This comes at an
unavoidable increase in brittleness, as expected, and illustrates the tradeoff between smoothness and
dominance. We expect ADA-PO to be the algorithm of choice when the prediction is conservative, or
when ˆpis not given to the trader ahead of time, but is rather revealed at some point in the sequence.
7 Discussion
Our profile-based framework can apply to many other problems augmented with ML predictions, and
is not specific to one-way trading. To illustrate this, in Appendix D we analyze another application
in the context of contract scheduling , which is a classic problem from resource-bounded reasoning
in AI, and which, likewise, suffers from brittleness. Our work is the first towards understanding the
power and limitations of imperfect ML predictions in competitive financial optimization beyond
extreme values of the prediction error. The techniques introduced will help address problems such as
two-way trading and portfolio optimization, which have not yet been studied in learning augmented
9maxrateperformanceratio(a) Profile F.
1 0.9p
p
1.1p
M
max rate1.01.52.02.53.03.54.0performance ratioPO
Profile (b) Perf. ratio of P ROFILE onσw’s.
7.5
 5.0
 2.5
 0.0 2.5 5.0 7.5 10.0
p*p
0.2
0.1
0.00.10.20.30.40.5relative improvement
(c) Average performance improve-
ment on σw’s.
0.9p
p
 M
max rate1.51.61.71.81.92.02.12.22.3performance ratio
PO
Profile
(d) P ROFILE performance ratio on BTC.
p
 M
max rate1.52.02.53.03.54.0performance ratio
PO
Adap-PO (e) A DA-PO performance ratio on BTC.
Figure 2: Summary of the experimental results.
settings. Other potential applications include several well-known variants knapsack problems, where
online threshold algorithms are commonly used, especially in learning-augmented settings [ 16,40].
Last, it would be interesting to study dynamic settings, in which the predictions are obtained as the
sequence is revealed to the algorithm.
8 Acknowledgements
This work was funded by the project PREDICTIONS, grant ANR-23-CE48-0010 from the French
National Research Agency (ANR). The first author acknowledges the support of AANI (Agencia
Nacional de Investigacion e Innovacion).
References
[1]Matteo Almanza, Flavio Chierichetti, Silvio Lattanzi, Alessandro Panconesi, and Giuseppe Re.
Online facility location with multiple advice. In Advances in Neural Information Processing
Systems , NeurIPS 2021 , pages 4661–4673, 2021.
[2]Keerti Anand, Rong Ge, Amit Kumar, and Debmalya Panigrahi. Online algorithms with
multiple predictions. In International Conference on Machine Learning, ICML , volume 162 of
Proceedings of Machine Learning Research , pages 582–598. PMLR, 2022.
[3]Keerti Anand, Rong Ge, and Debmalya Panigrahi. Customizing ML predictions for online
algorithms. In Proceedings of the 37th International Conference on Machine Learning, ICML ,
volume 119 of Proceedings of Machine Learning Research , pages 303–313. PMLR, 2020.
[4] Spyros Angelopoulos. Online search with a hint. Inf. Comput. , 295(Part B):105091, 2023.
[5]Spyros Angelopoulos, Marcin Bienkowski, Christoph Dürr, and Bertrand Simon. Contract
scheduling with distributional and multiple advice. In Proceedings of the 33rd International
Joint Conference on Artificial Intelligence (IJCAI) , 2024. arXiv:2404.12485.
10[6]Spyros Angelopoulos, Christoph Dürr, Shendan Jin, Shahin Kamali, and Marc P. Renault.
Online computation with untrusted advice. In Thomas Vidick, editor, 11th Innovations in
Theoretical Computer Science Conference, ITCS , volume 151 of LIPIcs , pages 52:1–52:15.
Schloss Dagstuhl - Leibniz-Zentrum für Informatik, 2020.
[7]Spyros Angelopoulos and Shahin Kamali. Contract scheduling with predictions. J. Artif. Intell.
Res., 77:395–426, 2023.
[8]Spyros Angelopoulos, Shahin Kamali, and Kimia Shadkami. Online bin packing with predic-
tions. Journal of Artificial Intelligence Research , 78:1111–1141, 2023.
[9]Antonios Antoniadis, Christian Coester, Marek Eliás, Adam Polak, and Bertrand Simon. Online
metric algorithms with untrusted predictions. ACM Trans. Algorithms , 19(2):19:1–19:34, 2023.
[10] Antonios Antoniadis, Themis Gouleakis, Pieter Kleer, and Pavel Kolev. Secretary and online
matching problems with machine learned advice. Discret. Optim. , 48(Part 2):100778, 2023.
[11] Yossi Azar, Stefano Leonardi, and Noam Touitou. Flow time scheduling with uncertain
processing time. In Samir Khuller and Virginia Vassilevska Williams, editors, STOC ’21: 53rd
Annual ACM SIGACT Symposium on Theory of Computing , pages 1070–1080. ACM, 2021.
[12] Yossi Azar, Debmalya Panigrahi, and Noam Touitou. Online graph algorithms with predictions.
In Joseph (Seffi) Naor and Niv Buchbinder, editors, Proceedings of the 2022 ACM-SIAM
Symposium on Discrete Algorithms, SODA , pages 35–66. SIAM, 2022.
[13] Yossi Azar, Debmalya Panigrahi, and Noam Touitou. Discrete-smoothness in online algorithms
with predictions. In Advances in Neural Information Processing Systems 36: Annual Conference
on Neural Information Processing Systems 2023, NeurIPS , 2023.
[14] Etienne Bamas, Andreas Maggiori, and Ola Svensson. The primal-dual method for learning
augmented algorithms. Advances in Neural Information Processing Systems , 33:20083–20094,
2020.
[15] Allan Borodin and Ran El-Yaniv. Online computation and competitive analysis . Cambridge
University Press, 1998.
[16] Ying Cao, Bo Sun, and Danny H.K. Tsang. Optimal online algorithms for one-way trading and
online knapsack problems: A unified competitive analysis. In 2020 59th IEEE Conference on
Decision and Control (CDC) , pages 1064–1069, 2020.
[17] Nicolas Christianson, Junxuan Shen, and Adam Wierman. Optimal robustness-consistency
tradeoffs for learning-augmented metrical task systems. In AISTATS , volume 206 of Proceedings
of Machine Learning Research , pages 9377–9399. PMLR, 2023.
[18] Franziska Eberle, Ruben Hoeksma, Nicole Megow, Lukas Nölke, Kevin Schewior, and Bertrand
Simon. Speed-robust scheduling: sand, bricks, and rocks. Math. Program. , 197(2):1009–1048,
2023.
[19] Ran El-Yaniv, Amos Fiat, Richard M Karp, and Gordon Turpin. Optimal search and one-way
trading online algorithms. Algorithmica , 30(1):101–139, 2001.
[20] Sreenivas Gollapudi and Debmalya Panigrahi. Online algorithms for rent-or-buy with expert
advice. In Proceedings of the 36th International Conference on Machine Learning, ICML ,
volume 97 of Proceedings of Machine Learning Research , pages 2319–2327. PMLR, 2019.
[21] Elena Grigorescu, Young-San Lin, Sandeep Silwal, Maoyuan Song, and Samson Zhou. Learning-
augmented algorithms for online linear and semidefinite programming. In Advances in Neural
Information Processing Systems 35: Annual Conference on Neural Information Processing
Systems 2022, NeurIPS 2022 , 2022.
[22] Sungjin Im, Ravi Kumar, Aditya Petety, and Manish Purohit. Parsimonious learning-augmented
caching. In International Conference on Machine Learning, ICML , volume 162 of Proceedings
of Machine Learning Research , pages 9588–9601. PMLR, 2022.
11[23] Sungjin Im, Benjamin Moseley, Chenyang Xu, and Ruilong Zhang. Online state exploration:
Competitive worst case and learning-augmented algorithms. In ECML/PKDD (4) , volume
14172 of Lecture Notes in Computer Science , pages 333–348. Springer, 2023.
[24] Zhihao Jiang, Pinyan Lu, Zhihao Gavin Tang, and Yuhao Zhang. Online selection problems
against constrained adversary. In Proceedings of the 38th International Conference on Machine
Learning, ICML , volume 139 of Proceedings of Machine Learning Research , pages 5002–5012.
PMLR, 2021.
[25] Alexandra Anna Lassota, Alexander Lindermayr, Nicole Megow, and Jens Schlöter. Minimalis-
tic predictions to schedule jobs with online precedence constraints. In ICML , volume 202 of
Proceedings of Machine Learning Research , pages 18563–18583. PMLR, 2023.
[26] Silvio Lattanzi, Thomas Lavastida, Benjamin Moseley, and Sergei Vassilvitskii. Online schedul-
ing via learned weights. In Proceedings of the 2020 ACM-SIAM Symposium on Discrete
Algorithms , pages 1859–1877. SIAM, 2020.
[27] Thomas Lavastida, Benjamin Moseley, R. Ravi, and Chenyang Xu. Learnable and instance-
robust predictions for online matching, flows and load balancing. In 29th Annual European
Symposium on Algorithms, ESA) , volume 204 of LIPIcs , pages 59:1–59:17, 2021.
[28] Russell Lee, Jessica Maghakian, Mohammad H. Hajiesmaili, Jian Li, Ramesh K. Sitaraman,
and Zhenhua Liu. Online peak-aware energy scheduling with untrusted advice. In e-Energy ,
pages 107–123. ACM, 2021.
[29] Russell Lee, Bo Sun, Mohammad Hajiesmaili, and John C. S. Lui. Online search with pre-
dictions: Pareto-optimal algorithm and its applications in energy markets. In e-Energy , pages
50–71. ACM, 2024.
[30] Alexander Lindermayr and Nicole Megow. Repository of works on algorithms with predictions.
https://algorithms-with-predictions.github.io , 2023. Accessed: 2023-12-01.
[31] Thodoris Lykouris and Sergei Vassilvitskii. Competitive caching with machine learned advice.
J. ACM , 68(4):24:1–24:25, 2021.
[32] Michael Mitzenmacher. Scheduling with predictions and the price of misprediction. In 11th
Innovations in Theoretical Computer Science Conference, ITCS , volume 151 of LIPIcs , pages
14:1–14:18. Schloss Dagstuhl - Leibniz-Zentrum für Informatik, 2020.
[33] Michael Mitzenmacher and Sergei Vassilvitskii. Algorithms with predictions. In Beyond the
Worst-Case Analysis of Algorithms , pages 646–662. Cambridge University Press, 2020.
[34] Michael Mitzenmacher and Sergei Vassilvitskii. Algorithms with predictions. Commun. ACM ,
65(7):33–35, 2022.
[35] Esther Mohr, Iftikhar Ahmad, and Günter Schmidt. Online algorithms for conversion problems:
a survey. Surveys in Operations Research and Management Science , 19(2):87–104, 2014.
[36] Manish Purohit, Zoya Svitkina, and Ravi Kumar. Improving online algorithms via ML predic-
tions. In Advances in Neural Information Processing Systems , volume 31, pages 9661–9670,
2018.
[37] Stuart J. Russell and Shlomo Zilberstein. Composing real-time systems. In Proceedings of the
12th International Joint Conference on Artificial Intelligence (IJCAI) , pages 212–217, 1991.
[38] Bo Sun, Russell Lee, Mohammad Hajiesmaili, Adam Wierman, and Danny Tsang. Pareto-
optimal learning-augmented algorithms for online conversion problems. Advances in Neural
Information Processing Systems , 34:10339–10350, 2021.
[39] Alexander Wei and Fred Zhang. Optimal robustness-consistency trade-offs for learning-
augmented online algorithms. In Proceedings of the 33rd Conference on Neural Information
Processing Systems (NeurIPS) , 2020.
12[40] Lin Yang, Ali Zeynali, Mohammad H Hajiesmaili, Ramesh K Sitaraman, and Don Towsley.
Competitive algorithms for online multidimensional knapsack problems. Proceedings of the
ACM on Measurement and Analysis of Computing Systems , 5(3):1–30, 2021.
[41] Yunhong Zhou, Deeparnab Chakrabarty, and Rajan Lukose. Budget constrained bidding in
keyword auctions and online knapsack problems. In Proceedings of the 17th international
conference on world wide web , pages 1243–1244, 2008.
13Appendix
A Details from Section 3
Proof of Theorem 3.1. LetAbe a Pareto-optimal algorithm of robustness r, and consistency c(r).
We will show that for any fixed ϵ > 0, there exists a sequence σand a prediction ˆpsuch that
η=|ˆp−p∗
σ| ≤ϵ, andAsatisfies Definition 3.1. Since Ais Pareto-optimal, there exists a non-empty
set of sequences Σc, such that for all σc∈Σc, ifAis given as prediction p∗
σc, then
p∗
σc
A(σc)=c(r).
As shown in [ 19] we can assume, without loss of generality, that every σcis increasing, i.e., it is
of the form σc=p1, . . . , p k, p∗
σcwithpi> pj, for all i < j , and p∗
σc> pk. We define Σto be the
co-domain of the following function, f:
f: Σc→Σsuch that f(σc) =σc if|p∗
σc−pk| ≤ϵ,
p1, . . . , p k, p∗
σc−ϵ, p∗
σcotherwise.(A.1)
Given a σ∈Σ, letn=|σ| −1, and let xnbe the fraction exchanged by A. Since Aisr-robust, it
needs to account for the scenario in which the adversary chooses to drop all rates to 1 after exchanging
at the rate pn. Thus, xnmust satisfy
pn
sn+pn·xn+ 1−xn−wn≤r,
or equivalently,
xn≥pn−r·(sn+ 1−wn)
r·(pn−1). (A.2)
Define ωto be the RHS of (A.2) Suppose first, that there exists a sequence σ∈Σfor which A
exchanges xn=ω. In this case, if Ais given a prediction ˆp=p∗
σ, then for the the sequence
σr=σ[1, n]we have that |ˆp−p∗
σr| ≤ϵ, and:
p∗
σr
A(σr)=pn
sn+pn·ω+ 1−ω−wn=r,
and the proof is complete in this case.
It thus remains to consider the case that for all σ∈Σ,xn> ω. Letxn+1be the amount exchanged by
Aat rate p∗
σ. We define an online algorithm A′, whose statement is given in Algorithm 3. Intuitively,
while the rate is below p∗
σ,A′makes the same decisions as A. If the rate is between p∗
σ−ϵandp∗
σ,
A′exchanges ω. If the rate is precisely p∗
σA′exchanges xnplus what Adid not exchange on rates
which were between p∗
σ−ϵandp∗
σ. Finally, A′makes the same decisions as Afor all rates that
exceed p∗
σ. We will show that A′has robustness at most rand consistency cA′such that cA′< c(r),
which contradicts that Ais Pareto-optimal.
We first show that A′isr-robust. Let σ′be an input sequence and ˆpa prediction given to A′, we will
show that p∗
σ′≤rA(σ′). Ifp∗
σ′<ˆp−ϵ, then has A′made the same decisions as A, hence remains
r-robust. If ˆp−ϵ < p∗
σ′<ˆp, then by definition of ω,A′is guaranteed to be r-robust. Last, if p∗
σ′≥ˆp,
thenA′achieves a strictly better profit than A.
It remains to show that A′has consistency strictly smaller than c(r). To this end, it suffices to show
that: (i) for all σc∈Σcit holds thatOPT(σc)
A′(σc)< c(r), and that (ii) for all σ′/∈Σcit holds that
OPT(σc)
A′(σc)< c(r), assuming that both AandA′are given a prediction ˆp=p∗
σ′.
To show (i), note that for σ′∈Σcit holds thatOPT(f(σ′))
A(f(σ′))< c(r), due to Aexchanging xn> ω
andA′exchanging xn=ω. Iff(σ′) =σ′(first case in (A.1) ) thenOPT(σ′)
A(σ′)< c(r). Otherwise,
(second case in (A.1) )A(σ′)> A(f(σ′))hence the same result holds. To show (ii), observe that
A′(σ′)> A(σ′)due to Aexchanging xn> ω andA′exchanging xn=ω. Hence, by the definition
ofΣc, we have
14Algorithm 3 Statement of the online algorithm A′
Input: Algorithm A,ˆp, ϵ
1:p∗= 1, e←0
2:foreach rate piin the input sequence do
3: ifpi> p∗then
4: p∗←pi
5: ifpi<ˆp−ϵthen
6: Exchange the same amount as A
7: else if ˆp−ϵ < p i<ˆpthen
8: Exchange ω
9: e←e+xi−ω
10: else if pi= ˆpthen
11: Exchange xn+e
12: else
13: Exchange the same amount as A
OPT(σc)
A′(σc)<OPT(σc)
A(σc)< c(r),
which concludes the proof.
B Details from Section 4
In this section, we show how to compute the function Φused in PROFILE (Algorithm 1), for deciding
whether a profile Fis feasible. Recall that we seek a function Φand values 0 =w1≤. . .≤wl+1≤1
that satisfy the following sets of constraints.
[β] ∀β∈[wi, wi+1) :Φ(β)
si+Rβ
wiΦ(t)dt+ 1−β≤ti
[wi+1] Φ(wi+1) =qi+1
[u] wi≤wi+1≤1
for each rate interval [qi, qi+1).
As explained in Section 4, our algorithm builds a function Φand values wiin an iterative way. That
is, it processes each set of constraints iteratively, and at each step j∈[1, l]it builds a function Φjand
computes values w1, . . . , w j+1which satisfy the sets of constraints for all intervals [qi, qi+1)with
i≤j. Each function Φjand the new values w1, . . . , w j+1are a function of Φj−1and the previous
values w1, . . . , w j+1.
We explain an iteration of this process. Suppose that the algorithm is at a step where it has computed
Φj−1and values w1, . . . , w jas to satisfy the sets of constraints for the intervals [qi, qi+1)withi < j .
Constraint [ β] requires us to guarantee a ratio of at least tjfor every sequence whose maximum rate
is in[qj, qj+1). We derive a function which achieves a ratio equal totjfor such sequences. The
equality is sought, instead of the inequality, in order to minimize utilization. Intuitively, enforcing a
ratio smaller than tjwould force the algorithm to exchange more money to achieve a bigger profit.
Thus the following constraint
∀β∈[wj, wj+1) :Φ(β)
sj+Rβ
wjΦ(t)dt+ 1−β=tj,
from which we can obtain the differential equation:
˙Φ =tj·Φ−tj, (B.1)
which is a separable first order differential equation. We can hence find the unique solution
Φ(β) =C·etj·β+ 1.
15We then apply constraint [ β], for an arbitrary β∈[wj, wj+1), so to find the value of the constant C,
which yields
Φ(β) = (tj·(sj+ 1−wj)−1)·etj·(β−wj)+ 1 (B.2)
The obtained function is the unique solution to such an equation. We denote ρj=tj·(sj+ 1−wj).
We then use constraint [ wj+1] to find an expression for wj+1:
wj+1=1
tjlnqj+1−1
ρj−1
+wj (B.3)
Note that Φ(wj) =ρj. There are two cases to be analyzed.
First, if ρj> qj, then we can define Φjas follows:
Φj(w) =Φj−1(w) ifw∈[1, wj)
(tj·(sj+ 1−wj)−1)·etj·(β−wj)+ 1 ifw∈[wj, wj+1),
where wj+1is defined in (B.3) . We say that we extend the previous Φj−1. This scenario materializes
when the algorithm has achieved a profit sj, which allows it to not exchange while observing rates
in[qj, ρj]and still remain tj-competitive. This occurs when tj> tj−1, hence it occurs for the
increasing part of the profile.
On the other hand, ρj< qj, iftj< tj−1. If this case occurs, the algorithm has not obtained a
sufficient profit to be tj-competitive when presented with the sequence which continuously increases
from 1toqj, which is the worst-case sequence as stated in Remark 2.1. As we will show in the
proof of Theorem 4.1 wjis the least utilization that can be spent so to satisfy every set of constraints
[qk, qk+1)withk < j . To enforce a ratio of tjand still minimize utilization, the algorithm must
exchange a bigger amount when rate qjis revealed, since exchanging more at a lower rate would lead
to a larger utilization. To guarantee a ratio of tjfor the continuous increasing sequence, the algorithm
should trade an amount equal to w′
j−wj, where w′
jis obtained from:
qj
sj+qj·(w′
j−wj) + 1−w′
j=tj
and leads to
w′
j=qj−tj·(sj−wjqj+ 1)
tj·(qj−1).
We now wish to extend function Φj−1, obtained in the previous iteration, so as to satisfy all constraints
for interval [qj, qj+1). Lets′
j=sj+qj·(w′
j−wj), which is the profit obtained by the OTA in the
worst case where the maximum rate is qj. We may express this problem by a new set of constraints,
which are:
[β] ∀β∈[w′
j, wj+1) :Φ(β)
s′
j+Rβ
w′
jΦ(t)dt+ 1−β≤tj,
[wj+1] Φ(wj+1) =qj+1,
[u] w′
j≤wj+1≤1.
Note that this set of constraints is the same as the ones we started with, but sjwas replaced by s′
jand
wjbyw′
j. Hence, the Φandwj+1which satisfy the constraints and minimize wj+1are:
Φ(β) = (tj·(s′
j+ 1−w′
j)−1)·etj·(β−w′
j)+ 1, (B.4)
wj+1=1
tjlnqj+1−1
ti·(s′+ 1−w′
i)−1
+w′
j. (B.5)
We can now proceed with the proof for Theorem 4.1.
16Proof of Theorem 4.1. As stated in Remark 2.1, every online strategy will exchange on rates which
are best-seen so far. We can hence state every strategy as an OTA. It suffices then to prove the
following: There exists an OTA which respects Fif and only if PROFILE terminates with a value
wl+1≤1.
LetFbe a performance profile. The if direction follows directly from the design of PROFILE . It
suffices to observe that the obtained function Φlcan be used as the threshold function for an OTA
which respects the profile F.
To prove the only if direction, we will prove that every wiobtained by PROFILE is the least utilization
needed to satisfy all sets of constraints for intervals [qk, qk+1)fork < i . In other words, we
will prove that if A is an OTA, which respects F, defined by Φ, and where w′
1, . . . , w′
l+1are the
respective utilization levels reached by A when observing rates q1, . . . , q l+1, i.e:Φ(w′
i) =qifor each
i∈[1, . . . , l + 1], then wi≤w′
i. This statement follows, once again, from the design of PROFILE .
By replacing the inequality constraint in [ β] by an equality, we manage to achieve a ratio which is
exactly the one demanded by the profile, hence reserving budget for futures rates. PROFILE obtains a
function Φlwhich enforces, for each i∈[1, l]and for each q∈[qi, qi+1)the equation:
q
RΦ−1
l(q)
1Φl(u)du+ 1−Φ−1
l(q)=ti.
We conclude that PROFILE minimizes utilization while satisfying every set of constraints, thus proving
the theorem.
Figure 3 illustrates PROFILE . Here we observe that for the increasing part of the profile, Φiwith
i∈[4,7]extends Φi−1with an exponential function starting at wi, where Φi(wi)>Φi−1(wi). Here
the vertical “jumps” reflect the less stringent requirement in the increasing part (we can afford to
reserve our budget for later). For the decreasing part of the profile, Φiwithi∈[1,3]extends Φi−1
with an exponential function starting at w′
i> w i(line 9 in the statement) where Φi(w′
i) = Φ i−1(wi),
which is reflected in the presence of straight lines in Figure 3.
w1 w2 w3 w4 w5 w6
utilizationq1q2q3q4q5q6reservation rate
Figure 3: An illustration of PROFILE . Here the profile Fis as follows: F([1,20) = 7 ,F([20,35]) = 5 ,
F([35,50]) = 3 ,F([50,70]) = 3 .5, and F([70,100]) = 4
.
17C Details from Section 5
In this section, we detail the calculations that lead to the value wi+1, which is the maximum an online
algorithm can spend on rate piwhile ensuring r-robustness.
The aforementioned wi+1is the solution to the following optimization problem:
max w (Oi)
subj. to
[β] ∀β∈[w,1) :Φ(β)
si+pi·(w−wi) +Rβ
wΦ(t)dt+ 1−β=r,
[M] Φ(1)≥M,
[u] wi≤w≤1.
From constraint [ β], we do the same analysis as in B to find Φ(β) =C·erβ+ 1. Once again, to find
the constant Cwe use constraint [ β] for an arbitrary value β∈[wi+1,1], which leads to:
Φ(β) = 
r·(si+ 1−piwi+wi+1·(pi−1))−1
·er·(β−wi+1)+ 1.
We then use constraint [M] to obtain an upper bound on wi+1:
 
r·(si+ 1−piwi+wi+1·(pi−1))−1
·er·(1−wi+1)+ 1≥M,
which leads to:
wi+1≤1−1
rlnM−1
r(si+ 1−piwi+wi+1(pi−1)−1)
.
Thus the largest value of wi+1is the root of the equation
wi+1= 1−1
rlnM−1
r(si+ 1−piwi+wi+1(pi−1)−1)
,
which can be solved using numerical methods. Let ρbe the reservation rate for utilization wi+1, then
ρ= Φ(wi+1) =r·(si+ 1−piwi+wi+1·(pi−1)).
Ifρ > M , then the algorithm has achieved a sufficient profit to guarantee r-robustness independently
of future rates. Hence, to maximize wi+1, we can safely set it to 1. However, if ρ < M , then
constraint [M]was saturated, and the algorithm will achieve a performance ratio of rfor every
sequence which grows continuously from ρuntil a rate p∗∈[ρ, M]. Moreover, for every sequence
whose maximum rate p∗∈[pi, ρ)the algorithm will have a performance ratio smaller than r.
As explained in Appendix B using constraint [ β] with an equality allows us to guarantee a performance
ratio of rminimizing utilization. Observe that to maximize wi+1we need to minimize the left-over
budget to remain r-robust in the future. We can hence conclude that wi+1−wiis indeed the largest
amount of money we can exchange at rate piand remain r-robust.
We will next provide the proof for Theorem 5.1.
Proof of Theorem 5.1. We are to prove that ADA-PO is Pareto-Optimal and dominates every other
Pareto-Optimal algorithm on any sequence σ.
First, we will prove that ADA-PO is Pareto-Optimal. Let rbe a a robustness requirement, and c(r)
the respective consistency. To start with, we prove that ADA-PO isr-robust. Consider first the (easy)
case where p∗<ˆpthen A DA-PO assures a performance ratio of rusing the threat-based approach.
Consider then the (harder) case in which p∗>ˆp. Let pibe the first rate above ˆpandwi+1,Φibe
the respective solution to problem Oi. We must prove that no matter how the sequence continues
ADA-PO achieves a performance ratio of at least r. IfΦ(wi+1)≥Mthen a performance ratio of
ris guaranteed, due toM
si+1+1−wi+1≤r, from constraint [ β]. Suppose then Φi(wi+1)< M , then
by constraints [M] and [u] we know that wi+1<1. When the next rate pi+1> piis revealed the
same analysis can be applied. We thus obtain a non-decreasing sequence of reservation rates Φj(pj)
18forj > i . For each rate, problem Oiis solved. Note that the feasibility of problem Oiwith rate pi
implies the feasibility of the problem Oiwith the next rate as shown by the next analysis. Namely,
ifpi≤Φ(pi−1)thenw=wi,Φi= Φ i−1is a solution, and if pi>Φ(pi−1), then w= Φ−1
i−1(pi),
Φi= Φ i−1is as well. Furthermore, both cases lead to a performance ratio of at least rin case the
next rate equals 1and is the last rate. We hence conclude, that either one of the reservation rates is
greater or equal than MorADA-PO successfully achieves a performance ratio of rfor each rate
(wi<1was a solution for each problem). We conclude then that A DA-PO is r-robust.
We will now prove that ADA-PO isc(r)-consistent. We must prove that for every error-free sequence
the performance ratio is at most c(r). LetA′be any Pareto-Optimal algorithm. When observing rates
below ˆp,ADA-PO follows the threat-based policy, hence for every error-free sequence, its budget is
at least the same as A′when a rate equal to ˆpis exhibited. Then by solving the optimization problem,
ADA-PO exchanges the most it can in order to remain r-robust, a larger amount would make the
problem infeasible. In other words, there would not exist a function Φsatisfying the constraints,
and the continuously increasing function from ˆptoMwill lead to a performance ratio bigger than r.
Hence, no other algorithm could achieve a better profit. We conclude that ADA-PO isc(r)-consistent.
We finally prove that ADA-PO dominates A′. By the previous analysis, when observing the first rate
above the prediction, ADA-PO has a budget at least the budget than A′. As ADA-PO exchanges
the most it can to remain r-robust, it will obtain a next utilization which is equal or smaller than
A′, hence achieving a better profit, because A′exchanged the same or less at lower rates. If A′has
behaved the same as ADA-PO, then this process repeats for every following rate. We conclude then
that A DA-PO dominates or performs equally to A′.
Remark C.1. To conclude we offer an intuitive explanation of dominance. If the maximum rate
of the sequence is below the prediction, then ADA-PO’s profit will be smaller or equal than any
other Pareto-Optimal algorithm. Its profit will be equal if the sequence is a continuously increasing
one. Moreover, for the first rate equal or greater than the prediction, its profit will be greater or
equal than any other Pareto-Optimal algorithm. By definition of dominance, while observing rates
above the prediction, either the two profits will be equal, or ADA-PO’s profit is larger, unless the
Pareto-Optimal algorithm attained a smaller profit at an earlier rate.
D Profile-based contract scheduling
In this section, we discuss another application of our profile-based framework of Section 3. Specifi-
cally, we focus on another well-known optimization problem that has been studied under learning-
augmented settings, namely contract scheduling. In its standard variant, the problem consists of
finding an increasing sequence X= (xi)∞
i=0which minimizes the acceleration ratio , formally
defined as
acc(X) = sup
TT
ℓ(X, T). (D.1)
where ℓ(X, T)denotes the largest contract completed by TinX, namely
ℓ(X, T) = max
j{xj:jX
i=0xi≤T}.
Contract scheduling is a classic problem that has been studied under several settings. In its simplest
variant stated above, the optimal acceleration ratio is equal to 4 [ 37], but many more complex settings
have been studied in the literature; see [ 7] and references therein. In this section we are interested in
the learning augmented setting introduced in [ 7] in which there is a prediction τon the interruption
timeT. The prediction error is defined as η=|T−τ|. In this context, the consistency c(X)of
schedule Xis defined as
c(X) =τ
ℓ(X, τ),
whereas its robustness is defined as
r(X) = sup
T≥1T
ℓ(X, T),
19i.e., the worst-case performance of X, assuming adversarial interruptions. Since the latter occur
arbitrarily close to the completion time of any contract, we obtain an equivalent interpretation of the
robustness as
r(X) = sup
i≥1Pi
j=0xj
xi−1.
In [7] it was shown that the optimal consistency of a 4-robust schedule is equal to 2. However, as
proven in [ 5], any such schedule suffers from brittleness. Namely, for any ϵ >0, there exists a
prediction τand an actual interruption time Tsuch that |T−τ|=ϵ, and any 4-robust and 2-consistent
schedule satisfies ℓ(X, T)≤T+ϵ
4.
In the remainder of this section we will show how to use our framework of profile-based performance
so as to remedy this drawback. For definiteness, and to illustrate the application of the techniques, we
consider the requirement that the performance of the schedule degrades linearly as a function of the
prediction error. Namely, suppose that we require that f(X, T) :=T/ℓ(X, T)be respect a profile
Fϕ, where the latter is defined as a symmetric, bilinear function that is decreasing for T≤τ, and
increasing for T≥τ, with slope ϕ, as illustrated in Figure 4. This profile is chosen by the schedule
designer, and the angle ϕcaptures the “smoothness” at which the schedule is required to degrade as a
function of the prediction error.
ϕ ϕ
Figure 4: An illustration of the profile Fϕ.
More specifically, for a given prediction τ, and a profile Fϕas above, we are interested in finding the
best extension of Fϕsuch that there exists a 4-robust schedule that respects the extension. We can
thus define the analytical concept of consistency according to Fϕas
cFϕ:= sup
τinf
TT
ℓ(X, T):Xrespects Fϕ.
The following theorem states our main result.
Theorem D.1. Given a profile Fϕand a prediction τon an interruption time, we can compute a
4-robust schedule that respects Fϕand has optimal consistency according to Fϕ.
Proof. We will assume that Xif of the form (λ2i)i∈Z. This is not a limiting assumption, as discussed
in [5], and its purpose is to simplify the calculations. Since any 4-robust schedule is of the above
form [ 5], it will suffice to compute a λthat satisfies the constraints of our problem, and the result will
follow.
Recall that f(X, T)denotes the function T/ℓ(X, T). By definition, for every i∈N,f(X, T)is
a linear, increasing function of Tfunction in the interval Ik= [Tk, Tk+1] = [λ2k, λ2k+1], with
smallest value equal to 2, and largest value equal to 4.
With the above observation in mind, for a given, fixed λ, letkbe such that τ∈Ik+1, i.e., we have
thatℓ(X, τ) =λ2k. Define α∈[1,2]to be such that τ=αTk, and note that by construction, αis a
function of λ. Moreover
f(X, τ) =τ
λ2k=αTk
λ2k=αλ2k+1
λ2k= 2α, (D.2)
which implies that it suffices to compute α, then λmust be chosen so that λ= 2{log(2α)}, where {x}
denotes the fractional part of x.
20In order to minimize f, subject to Xrespecting the profile, λmust be chosen such that one of the
two cases occur, which we analyze separately.
Case 1. The profile Fϕhas a unique intersection point with fatT=τ, and moreover F(Tk+ϵ) = 4 ,
for infinitesimally small ϵ >0. This situation is illustrated in Figure 5. For this case to arise, and for
the schedule to be consistent with F, it must be that
tan(π
2−ϕ)≥4−2
Tk+1−Tk=2
Tk=2α
τ. (D.3)
It must then be that f(X, τ) +τ−Tk
tanϕ= 4, hence
4−ρ(1−1
α) = 2 α,where ρ=τ
tanϕ.
Solving the above equality for αminimizes f, by means of (D.2). We obtain that
α=1
4(p
ρ2+ 16−ρ+ 4) andf(X, τ) = 2 α,
subject to the condition (D.3).
TimeT/ℓ (X, T )
24
Tk Tk+1τϕ ϕ
Figure 5: An illustration of Case 1.
Case 2. This case occurs if the condition in Case 1 does not apply. The profile Fϕis such that
F(Tk+ϵ) =F(Tk+1−ϵ), for infinitesimally small ϵ >0. This situation is illustrated in Figure 6.
For this case to arise, and for the schedule to respect Fϕit must be that τ=Tk+1+Tk
2=3
2τ
α, hence
α= 3/2. In this case, we obtain that
f(X, τ) = 4−Tk+1−τ
tanϕ= 4−ρ,where ρ=τ
tanϕ.
We observe that in both cases in the analysis of Theorem D.1 we obtain that f∈(2,4], as a function
ofτandϕ. This result makes intuitively sense, since Xis4-robust, and the smallest consistency is
equal to 2(when ϕ→0).
E Further experimental analysis
To further quantify the performance difference between the two algorithms, PROFILE andPO, we
performed additional experiments. Specifically, we used a list of the last 20,000 minute-exchange
rates of BTC to USD, so as to create 20 different sequences, each with its own prediction, using the
same method as in Fig 2c. For each sequence, we computed the average improvement over POfor
rates in the interval of interest [0.9ˆp,1.1ˆp]. Figure 7 depicts this average for each of the 20 sequences.
We observe that for the sequences in which PROFILE outperforms PO(12 out of 20), the improvement
ranges from roughly 15% to30%, whereas POoutperforms PROFILE in 8 out of 20 sequences, by a
factor that is at most 10%, roughly.
21TimeT/ℓ (X, T )
24
Tk Tk+1τϕ ϕ
Figure 6: An illustration of Case 2.
12345678910 111213141516171819
sequence0.1
0.00.10.20.3relative improvement
Figure 7: Average ratio improvement of P ROFILE over PO
F Computational setup
The experiments are reproducible on any standard computer, and do not require any memory or
computational power beyond the standard requirements. They run typically within few milliseconds.
22NeurIPS Paper Checklist
1.Claims
Question: Do the main claims made in the abstract and introduction accurately reflect the
paper’s contributions and scope?
Answer: [Yes]
Justification: We provide full theoretical results and all proofs, as well as an experimental
evaluation over real and synthetic data.
Guidelines:
•The answer NA means that the abstract and introduction do not include the claims
made in the paper.
•The abstract and/or introduction should clearly state the claims made, including the
contributions made in the paper and important assumptions and limitations. A No or
NA answer to this question will not be perceived well by the reviewers.
•The claims made should match theoretical and experimental results, and reflect how
much the results can be expected to generalize to other settings.
•It is fine to include aspirational goals as motivation as long as it is clear that these goals
are not attained by the paper.
2.Limitations
Question: Does the paper discuss the limitations of the work performed by the authors?
Answer: [Yes]
Justification: ADA-PO exhibits unavoidable brittleness, since it is a Pareto-optimal algo-
rithm. Our profile definition for one-way trading is not continuous, but nevertheless it
can approximate any continuous function for sufficiently large l. The O(l)complexity of
PROFILE reflects this fact.
Guidelines:
•The answer NA means that the paper has no limitation while the answer No means that
the paper has limitations, but those are not discussed in the paper.
• The authors are encouraged to create a separate "Limitations" section in their paper.
•The paper should point out any strong assumptions and how robust the results are to
violations of these assumptions (e.g., independence assumptions, noiseless settings,
model well-specification, asymptotic approximations only holding locally). The authors
should reflect on how these assumptions might be violated in practice and what the
implications would be.
•The authors should reflect on the scope of the claims made, e.g., if the approach was
only tested on a few datasets or with a few runs. In general, empirical results often
depend on implicit assumptions, which should be articulated.
•The authors should reflect on the factors that influence the performance of the approach.
For example, a facial recognition algorithm may perform poorly when image resolution
is low or images are taken in low lighting. Or a speech-to-text system might not be
used reliably to provide closed captions for online lectures because it fails to handle
technical jargon.
•The authors should discuss the computational efficiency of the proposed algorithms
and how they scale with dataset size.
•If applicable, the authors should discuss possible limitations of their approach to
address problems of privacy and fairness.
•While the authors might fear that complete honesty about limitations might be used by
reviewers as grounds for rejection, a worse outcome might be that reviewers discover
limitations that aren’t acknowledged in the paper. The authors should use their best
judgment and recognize that individual actions in favor of transparency play an impor-
tant role in developing norms that preserve the integrity of the community. Reviewers
will be specifically instructed to not penalize honesty concerning limitations.
3.Theory Assumptions and Proofs
23Question: For each theoretical result, does the paper provide the full set of assumptions and
a complete (and correct) proof?
Answer: [Yes]
Justification: The proofs of all theorems and statements are provided in the technical
appendix. All assumptions are stated in the statements
Guidelines:
• The answer NA means that the paper does not include theoretical results.
•All the theorems, formulas, and proofs in the paper should be numbered and cross-
referenced.
•All assumptions should be clearly stated or referenced in the statement of any theorems.
•The proofs can either appear in the main paper or the supplemental material, but if
they appear in the supplemental material, the authors are encouraged to provide a short
proof sketch to provide intuition.
•Inversely, any informal proof provided in the core of the paper should be complemented
by formal proofs provided in appendix or supplemental material.
• Theorems and Lemmas that the proof relies upon should be properly referenced.
4.Experimental Result Reproducibility
Question: Does the paper fully disclose all the information needed to reproduce the main ex-
perimental results of the paper to the extent that it affects the main claims and/or conclusions
of the paper (regardless of whether the code and data are provided or not)?
Answer: [Yes]
Justification: The code and data are provided in the supplemental material. We also provided
a README file that explains how to execute and reproduce the code.
Guidelines:
• The answer NA means that the paper does not include experiments.
•If the paper includes experiments, a No answer to this question will not be perceived
well by the reviewers: Making the paper reproducible is important, regardless of
whether the code and data are provided or not.
•If the contribution is a dataset and/or model, the authors should describe the steps taken
to make their results reproducible or verifiable.
•Depending on the contribution, reproducibility can be accomplished in various ways.
For example, if the contribution is a novel architecture, describing the architecture fully
might suffice, or if the contribution is a specific model and empirical evaluation, it may
be necessary to either make it possible for others to replicate the model with the same
dataset, or provide access to the model. In general. releasing code and data is often
one good way to accomplish this, but reproducibility can also be provided via detailed
instructions for how to replicate the results, access to a hosted model (e.g., in the case
of a large language model), releasing of a model checkpoint, or other means that are
appropriate to the research performed.
•While NeurIPS does not require releasing code, the conference does require all submis-
sions to provide some reasonable avenue for reproducibility, which may depend on the
nature of the contribution. For example
(a)If the contribution is primarily a new algorithm, the paper should make it clear how
to reproduce that algorithm.
(b)If the contribution is primarily a new model architecture, the paper should describe
the architecture clearly and fully.
(c)If the contribution is a new model (e.g., a large language model), then there should
either be a way to access this model for reproducing the results or a way to reproduce
the model (e.g., with an open-source dataset or instructions for how to construct
the dataset).
(d)We recognize that reproducibility may be tricky in some cases, in which case
authors are welcome to describe the particular way they provide for reproducibility.
In the case of closed-source models, it may be that access to the model is limited in
some way (e.g., to registered users), but it should be possible for other researchers
to have some path to reproducing or verifying the results.
245.Open access to data and code
Question: Does the paper provide open access to the data and code, with sufficient instruc-
tions to faithfully reproduce the main experimental results, as described in supplemental
material?
Answer: [Yes]
Justification: We used Bitcoin exchange rates from Binance, which are publicly available,
and fully explained how precisely it was obtained.
Guidelines:
• The answer NA means that paper does not include experiments requiring code.
•Please see the NeurIPS code and data submission guidelines ( https://nips.cc/
public/guides/CodeSubmissionPolicy ) for more details.
•While we encourage the release of code and data, we understand that this might not be
possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not
including code, unless this is central to the contribution (e.g., for a new open-source
benchmark).
•The instructions should contain the exact command and environment needed to run to
reproduce the results. See the NeurIPS code and data submission guidelines ( https:
//nips.cc/public/guides/CodeSubmissionPolicy ) for more details.
•The authors should provide instructions on data access and preparation, including how
to access the raw data, preprocessed data, intermediate data, and generated data, etc.
•The authors should provide scripts to reproduce all experimental results for the new
proposed method and baselines. If only a subset of experiments are reproducible, they
should state which ones are omitted from the script and why.
•At submission time, to preserve anonymity, the authors should release anonymized
versions (if applicable).
•Providing as much information as possible in supplemental material (appended to the
paper) is recommended, but including URLs to data and code is permitted.
6.Experimental Setting/Details
Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
results?
Answer: [Yes]
Justification: For sequences from real data, we explain how predictions are generated by
observing some prefix of the unknown input. For synthetic data, prediction are chosen
randomly, as specified in Section 6.
Guidelines:
• The answer NA means that the paper does not include experiments.
•The experimental setting should be presented in the core of the paper to a level of detail
that is necessary to appreciate the results and make sense of them.
•The full details can be provided either with the code, in appendix, or as supplemental
material.
7.Experiment Statistical Significance
Question: Does the paper report error bars suitably and correctly defined or other appropriate
information about the statistical significance of the experiments?
Answer: [No]
Justification: We do not believe that an error bar provides further insight to the results
obtained.
Guidelines:
• The answer NA means that the paper does not include experiments.
•The authors should answer "Yes" if the results are accompanied by error bars, confi-
dence intervals, or statistical significance tests, at least for the experiments that support
the main claims of the paper.
25•The factors of variability that the error bars are capturing should be clearly stated (for
example, train/test split, initialization, random drawing of some parameter, or overall
run with given experimental conditions).
•The method for calculating the error bars should be explained (closed form formula,
call to a library function, bootstrap, etc.)
• The assumptions made should be given (e.g., Normally distributed errors).
•It should be clear whether the error bar is the standard deviation or the standard error
of the mean.
•It is OK to report 1-sigma error bars, but one should state it. The authors should
preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis
of Normality of errors is not verified.
•For asymmetric distributions, the authors should be careful not to show in tables or
figures symmetric error bars that would yield results that are out of range (e.g. negative
error rates).
•If error bars are reported in tables or plots, The authors should explain in the text how
they were calculated and reference the corresponding figures or tables in the text.
8.Experiments Compute Resources
Question: For each experiment, does the paper provide sufficient information on the com-
puter resources (type of compute workers, memory, time of execution) needed to reproduce
the experiments?
Answer: [Yes]
Justification: The experiments are reproducible on any computer with the experimental
setting described in the README file. See Section F.
Guidelines:
• The answer NA means that the paper does not include experiments.
•The paper should indicate the type of compute workers CPU or GPU, internal cluster,
or cloud provider, including relevant memory and storage.
•The paper should provide the amount of compute required for each of the individual
experimental runs as well as estimate the total compute.
•The paper should disclose whether the full research project required more compute
than the experiments reported in the paper (e.g., preliminary or failed experiments that
didn’t make it into the paper).
9.Code Of Ethics
Question: Does the research conducted in the paper conform, in every respect, with the
NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines ?
Answer: [Yes]
Justification: We abide by the code of Ethics.
Guidelines:
•The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
•If the authors answer No, they should explain the special circumstances that require a
deviation from the Code of Ethics.
•The authors should make sure to preserve anonymity (e.g., if there is a special consid-
eration due to laws or regulations in their jurisdiction).
10.Broader Impacts
Question: Does the paper discuss both potential positive societal impacts and negative
societal impacts of the work performed?
Answer: [Yes]
Justification: Our work studies foundational issues in the analysis of learning-augmented
algorithms. However, we briefly discuss how the proposed methods can be applied in online
financial optimization.
Guidelines:
26• The answer NA means that there is no societal impact of the work performed.
•If the authors answer NA or No, they should explain why their work has no societal
impact or why the paper does not address societal impact.
•Examples of negative societal impacts include potential malicious or unintended uses
(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
(e.g., deployment of technologies that could make decisions that unfairly impact specific
groups), privacy considerations, and security considerations.
•The conference expects that many papers will be foundational research and not tied
to particular applications, let alone deployments. However, if there is a direct path to
any negative applications, the authors should point it out. For example, it is legitimate
to point out that an improvement in the quality of generative models could be used to
generate deepfakes for disinformation. On the other hand, it is not needed to point out
that a generic algorithm for optimizing neural networks could enable people to train
models that generate Deepfakes faster.
•The authors should consider possible harms that could arise when the technology is
being used as intended and functioning correctly, harms that could arise when the
technology is being used as intended but gives incorrect results, and harms following
from (intentional or unintentional) misuse of the technology.
•If there are negative societal impacts, the authors could also discuss possible mitigation
strategies (e.g., gated release of models, providing defenses in addition to attacks,
mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
feedback over time, improving the efficiency and accessibility of ML).
11.Safeguards
Question: Does the paper describe safeguards that have been put in place for responsible
release of data or models that have a high risk for misuse (e.g., pretrained language models,
image generators, or scraped datasets)?
Answer: [NA]
Justification:
Guidelines:
• The answer NA means that the paper poses no such risks.
•Released models that have a high risk for misuse or dual-use should be released with
necessary safeguards to allow for controlled use of the model, for example by requiring
that users adhere to usage guidelines or restrictions to access the model or implementing
safety filters.
•Datasets that have been scraped from the Internet could pose safety risks. The authors
should describe how they avoided releasing unsafe images.
•We recognize that providing effective safeguards is challenging, and many papers do
not require this, but we encourage authors to take this into account and make a best
faith effort.
12.Licenses for existing assets
Question: Are the creators or original owners of assets (e.g., code, data, models), used in
the paper, properly credited and are the license and terms of use explicitly mentioned and
properly respected?
Answer: [Yes]
Justification: The only data used is obtained from publicly available datasets, namely
Binance.
Guidelines:
• The answer NA means that the paper does not use existing assets.
• The authors should cite the original paper that produced the code package or dataset.
•The authors should state which version of the asset is used and, if possible, include a
URL.
• The name of the license (e.g., CC-BY 4.0) should be included for each asset.
27•For scraped data from a particular source (e.g., website), the copyright and terms of
service of that source should be provided.
•If assets are released, the license, copyright information, and terms of use in the
package should be provided. For popular datasets, paperswithcode.com/datasets
has curated licenses for some datasets. Their licensing guide can help determine the
license of a dataset.
•For existing datasets that are re-packaged, both the original license and the license of
the derived asset (if it has changed) should be provided.
•If this information is not available online, the authors are encouraged to reach out to
the asset’s creators.
13.New Assets
Question: Are new assets introduced in the paper well documented and is the documentation
provided alongside the assets?
Answer: [Yes]
Justification: The code is provided along with its documentation, in the README file.
Guidelines:
• The answer NA means that the paper does not release new assets.
•Researchers should communicate the details of the dataset/code/model as part of their
submissions via structured templates. This includes details about training, license,
limitations, etc.
•The paper should discuss whether and how consent was obtained from people whose
asset is used.
•At submission time, remember to anonymize your assets (if applicable). You can either
create an anonymized URL or include an anonymized zip file.
14.Crowdsourcing and Research with Human Subjects
Question: For crowdsourcing experiments and research with human subjects, does the paper
include the full text of instructions given to participants and screenshots, if applicable, as
well as details about compensation (if any)?
Answer: [NA]
Justification:
Guidelines:
•The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
•Including this information in the supplemental material is fine, but if the main contribu-
tion of the paper involves human subjects, then as much detail as possible should be
included in the main paper.
•According to the NeurIPS Code of Ethics, workers involved in data collection, curation,
or other labor should be paid at least the minimum wage in the country of the data
collector.
15.Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
Subjects
Question: Does the paper describe potential risks incurred by study participants, whether
such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
approvals (or an equivalent approval/review based on the requirements of your country or
institution) were obtained?
Answer: [NA]
Justification:
Guidelines:
•The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
28•Depending on the country in which research is conducted, IRB approval (or equivalent)
may be required for any human subjects research. If you obtained IRB approval, you
should clearly state this in the paper.
•We recognize that the procedures for this may vary significantly between institutions
and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
guidelines for their institution.
•For initial submissions, do not include any information that would break anonymity (if
applicable), such as the institution conducting the review.
29