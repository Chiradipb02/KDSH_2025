SegCSR: Weakly-Supervised Cortical Surfaces
Reconstruction from Brain Ribbon Segmentations
Anonymous Author(s)
Affiliation
Address
email
Abstract
Deep learning-based cortical surface reconstruction (CSR) approaches typically 1
rely on supervision information provided by pseudo ground truth generated by 2
conventional CSR methods, subject to errors associated with the supervision in- 3
formation and also increasing computational cost of training data preparation.We 4
propose a new method to jointly reconstruct multiple cortical surfaces using weak 5
supervision from brain MRI ribbon segmentation results. Our approach initializes a 6
midthickness surface, which is then deformed inward and outward to form the inner 7
(white matter) and outer (pial) cortical surfaces, respectively, by jointly learning 8
diffeomorphic flows by minimizing loss functions to optimize the surfaces towards 9
the boundaries of the cortical ribbon segmentation maps. Specifically, a boundary 10
surface loss drives the initialization surface to the inner and outer boundaries, while 11
an inter-surface normal consistency loss regularizes the pial surface in challenging 12
deep cortical sulci regions. Additional regularization terms are utilized to enforce 13
edge length uniformity and smoothness of the reconstructed surfaces. Our method 14
has been evaluated on two large-scale adult brain MRI datasets and one infant brain 15
MRI dataset, demonstrating comparable or superior performance in CSR in terms 16
of accuracy and surface regularity compared to alternative supervised deep learning 17
methods. 18
1 Introduction 19
Cortical surface reconstruction (CSR) is a crucial step for both qualitative visualization and quan- 20
titative characterization of cortical surfaces in imaging studies of brain morphology [ 15,51], neu- 21
rodegenerative diseases [ 6,12,43], and psychological disorders [ 42]. Well-established cortical 22
analysis pipelines, such as BrainSuite [ 48], FreeSurfer [ 17], Connectome Workbench [ 18], and 23
iBEAT V2.0 [ 52], have achieved significant success in reconstructing cortical surfaces from brain 24
MRI data. However, these pipelines typically involve multiple processing steps, including iterative 25
surface deformation and topology check and correction, resulting in lengthy processing time (e.g., 26
∼6h/subject). Moreover, each pipeline requires meticulously tuned parameters, posing challenges for 27
generalization across diverse data domains, age groups, or acquisition protocols. 28
Deep learning (DL) approaches have significantly accelerated CSR, demonstrating orders of magni- 29
tude faster inference speeds while maintaining high accuracy and topology correctness [ 8,11,13, 30
22,26,30–32,41,47,54]. One line of research predicts implicit surface representations, such as 31
signed distance functions [ 13,21] or level sets [ 41], from which 3D meshes are extracted using the 32
Marching Cube (MC) algorithm [ 27] and refined with topology correction algorithms [ 4] to detect 33
and rectify topology errors, ensuring that the reconstructed surface conforms to a sphere-like topology. 34
Another line of research focuses on learning explicit surface deformations, using methods such as 35
flow-based [ 8,11,22,26,47,54] or NODE-based techniques [ 30,31]), to deform an initial mesh 36
towards target cortical surfaces. However, all these methods heavily rely on supervision information 37
Submitted to 38th Conference on Neural Information Processing Systems (NeurIPS 2024). Do not distribute.provided by pseudo ground truth (pGT) of cortical surfaces generated by conventional CSR methods , 38
regardless of whether they use implicit or explicit surface representations. The prolonged processing 39
time for generating pGT surfaces limits the collection of sufficiently large datasets for training, 40
and a general pipeline capable of extracting pGT surfaces across various data domains (e.g., age, 41
modality) is currently lacking. Conversely, segmentation of brain structures is comparatively simpler, 42
inspiring us to explore avenues to eliminate the need for supervised learning in CSR and to generalize 43
DL-based CSR approaches to scenarios where ribbon segmentation results are readily available. 44
The key challenges for achieving accurate weakly supervised reconstruction of cortical surfaces 45
span three primary aspects. First , devising sub-voxel supervision signals presents a formidable 46
hurdle. While existing approaches can produce precise segmentations [ 7,20,29,45,52], voxel-level 47
representations may struggle to capture the intricate morphology of the cerebral cortex, especially 48
its thin and highly-folded structure, due to the partial volume effect (PVE) inherent in brain MRI 49
scans. This problem becomes particularly prominent in deep cortical sulci [ 17], where the two banks 50
of grooves nearly converge, or in low-resolution images [ 52], such as under-sampled or infant MRIs. 51
Second , effectively modeling the interdependence between multiple surfaces is crucial. Incorporating 52
this prior knowledge into the design of models and training algorithms can alleviate the complexity 53
of reconstructing both the inner (white matter) and outer (pial) surfaces, ensuring the spherical 54
topology of the reconstructed surfaces [ 8,54]. However, in the absence of pGT, it becomes more 55
challenging to forcibly deform surfaces and less stable to optimize multiple surfaces concurrently. 56
Third , maintaining optimal surface topology is paramount. Mesh uniformity, smoothness, and 57
topology are susceptible to distortion during large deformations if networks are optimized based on 58
randomly sampled vertices in 3D space for dense volumetric fields. 59
In this paper, we introduce SegCSR , a novel weakly supervised DL framework aimed at reconstructing 60
multiple cortical surfaces using ribbon segmentations derived from brain MRIs. We address the 61
diffeomorphic deformation problem in a continues coordinate space, deforming the initialization 62
midthickness surface towards the target inner and outer surfaces via innovative loss functions. 63
Specifically, the boundary surface loss function based on the ribbon segmentations and the intensity 64
gradient loss function based on the raw image facilitate sub-voxel-level surface movement. The 65
inter-surface normal consistency loss function explicitly integrates the normal directions of the WM, 66
midthickness, and pial surfaces, thereby regularizing the pial surface in challenging deep cortical 67
sulci regions. Furthermore, we devise a customized edge length loss, in conjunction with the known 68
normal consistency loss, to ensure surface uniformity and smoothness. Our main contributions can 69
be summarized as follows: 70
•We propose a new weakly supervised paradigm for reconstructing multiple cortical surfaces, 71
reducing the dependence on pGT cortical surfaces in training, unlike existing DL methods. 72
•We design two loss functions to optimize the surfaces towards the boundary of the cortical 73
ribbon segmentation maps, along with regularization terms to enforce regularity of surfaces. 74
•We conduct extensive experiments on two large-scale adult brain MRI datasets and one 75
infant brain MRI dataset. Our new method achieves comparable or superior performance 76
compared to existing supervised DL-based CSR alternatives. 77
2 Related Works 78
Cortical Surface Reconstruction (CSR). (I) Traditional CSR methods typically rely on empirically 79
defined automatic image/surface processing techniques to accomplish tissue segmentation (e.g., WM, 80
GM, cerebrospinal fluid (CSF)), hemisphere separation, subcortical filling, topology correction, WM 81
surface reconstruction, and pial surface reconstruction sequentially. Established pipelines such as 82
FreeSurfer [ 17], BrainSuite [ 48], and HCP [ 18] are tailored for processing adult brain images, while 83
dHCP [ 34] and iBEAT V2.0 [ 52] are designed for neonatal brain images, which exhibit distinct 84
differences in intensity values, size, and shape compared to adult brains. Despite achieving sub-voxel 85
accuracy and maintaining spherical topology, the iterative surface deformation and topology check and 86
correction procedures lead to lengthy processing times. (II)DL-based CSR methods have significantly 87
enhanced reconstruction speed while preserving high accuracy. Approaches like SegRecon [ 19] and 88
DeepCSR [ 13] predict a signed distance map for implicit surface representation, embedding the target 89
surface as the zero level-set and extracting it using MC algorithms. However, these methods require 90
topology correction to eliminate artifacts and ensure spherical topology. Alternatively, PialNN [32], 91
TopoFit [ 22], V ox2cortex [ 8], the CorticalFlow series [ 26,47], SurfFlow [ 11], CortexODE [ 31], 92
2and CoCSR [ 54] leverage explicit representation to maintain good topology and overcome PVE by 93
learning volumetric or vertex-wise diffeomorphic deformations and progressively deforming genus-0 94
template meshes. However, both implicit and explicit methods heavily rely on the supervision of pGT 95
of cortical surfaces generated by traditional pipelines. Our proposed method is based on the explicit 96
representation but differs significantly from them by utilizing ribbon segmentation maps for weakly 97
supervising the model training process. 98
Weakly-/Un-supervised Mesh Reconstruction. Although geometric DL methods for general 99
computer vision tasks have been extensively studied, research on mesh reconstruction from 3D 100
images under weakly-/un-supervised settings is relatively underexplored. One approach involves 101
constructing mesh-to-image rasterizer loss functions, as demonstrated in [ 36], where 2D projection 102
views are extracted from predicted 3D meshes and compared with ground truth segmentations. 103
Another line of research, exemplified by [ 39], focuses on learning the correspondence between 104
a template image and a target image, which is then utilized to deform the template mesh to the 105
target location. However, these methods have primarily been applied to biomedical tasks involving 106
organs with relatively simple shapes, such as the liver and heart. But the cerebral cortex presents a 107
highly-folded thin structure with a significantly complex shape, necessitating more advanced methods. 108
Diffeomorphic Deformation. Diffeomorphic deformation is a spatial transformation that guarantees 109
both smoothness and invertibility in the mapping process [ 46]. It has been widely used in the 110
modeling and analysis of brain morphometry, including image registration and surface reconstruction 111
tasks. LDDMM [ 5] computes diffeomorphic deformation based on a time-dependent velocity vector 112
field, while Arsigny et al. [ 2] employ a stationary velocity field (SVF) in conjunction with the 113
scaling and squaring method to reduce computation complexity. Learning-based methods [ 3,28, 114
38] improve the computation efficiency, with regularizations such as smoothness [ 3] and inverse- 115
consistency [ 38] enchancing the diffeomorphic property of the deformation. In the CSR task, 116
diffeomorphic deformation strategies have been adopted to solve an ordinary differential equation 117
(ODE) modeling the trajectories of each vertex of a surface. For instance, CoticalFlow methods [ 26, 118
47] propose solving the ODE vertex-wise and derive a numerical condition to ensure homeomorphism 119
of integration by training a chain of diffeomorphic deformation models in sequential stages. Recently, 120
with the advances in neural ODE solver [ 10], CortexODE [ 31] parameterizes the trajectories of 121
vertices on the surface as ODEs and proposes a pipeline to reconstruct WM and pial surfaces 122
sequentially . Our method builds upon these works [ 31,47,54] and integrates multiple CSR tasks 123
into a single framework, leveraging the efficiency and diffeomorphic properties of these strategies. 124
3 Methodology 125
Our proposed framework, depicted in Fig. 1, is designed to reconstruct multiple cortical surfaces 126
simultaneously, eliminating the dependency on pGT generated by conventional and time-consuming 127
CSR pipelines. We leverage as weak supervision the brain ribbon segmentation maps that are less 128
accurate than pGT surfaces but more accessible. Section3.1 outlines the network structure that couples 129
multiple cortical surfaces to reduce the learning difficulty. Section 3.2 describes the loss functions 130
devised to supervise the network optimization, facilitating sub-voxel reconstruction accuracy and 131
preserving optimal surface topology. 132
3.1 Coupled Cortical Surface Reconstruction 133
Existing supervised methods require pGT obtained from traditional CSR pipelines to provide precise 134
sub-voxel supervision. They can effectively learn the deformation field, even from distant initial 135
locations, to accurately align the initialization surface with the target surfaces [ 11,26,47]. However, 136
brain ribbon segmentation maps are inherently discrete voxel grids, offering much coarser supervision. 137
Consequently, the selection of the initialization surface becomes more critical. Moreover, given the 138
intricate folded patterns of the cerebral cortex, the proximity of the two banks of grooves in deep 139
cortical sulci often poses a considerable risk of generating topology errors (e.g., handles, holes) in the 140
reconstructed surfaces. Conversely, voxels closer to the WM surface exhibit clearer contrast, enabling 141
a distinct separation between sulci (Fig. 2 (b)). Thus, following [ 54], we opt for the midthickness 142
layer, positioned midway between the WM and pial surfaces, to serve as a connection for coupling 143
the reconstructions of both surfaces and achieve a balanced performance for both surfaces. 144
As illustrated in Fig. 1, SegCSR employs a neural network to jointly model three diffeomorphic flows: 145
Fθ(I,S0) = (vm,vo,vi). Here, Irepresents a multi-channel input consisting of brain MRI, cortical 146
3Mesh loss
Multi-channel inputVelocityField 𝑉𝐹!VelocityField 𝑉𝐹"
Initial mid surf.Mid surf.
WM surf. 𝑆!GM surf. 𝑆"SSS𝑉𝐹#SS𝑉𝐹"𝑳𝒄𝒚𝒄𝑳𝒄𝒚𝒄𝑆!"𝑆!""3D CNNVelocityField 𝑉𝐹#DeformDeformDeformDeform
Deform𝑆%
CBrain MRIRibbon seg.SDFsWeakly supervised loss
Weakly supervised lossIntensity grad. lossInter-mesh NC loss
Mesh quality lossSConcatenationData flowCVertex-wise sampling
pGTsurf
Weakly supervised loss terms:
Figure 1: The SegCSR framework overview. SegCSR takes as input a brain MRI image, cortical
ribbon segmentation maps, and signed distance maps of cortical surfaces, and simultaneously learns
three diffeomorphic deformations to optimize the initial midthickness surface S0to align with the
target midthickness surface SM, and then deform SMoutwards and inwards to the pial surface SGand
the WM surface SW, respectively. The model is optimized using weakly supervised loss functions:
the mesh loss guides the surfaces towards the boundaries of the cortical ribbon segmentation maps; the
inter-surface normal consistency loss regularizes the pial surface in deep cortical sulci; the intensity
gradient loss facilitates sub-voxel-level movement; and additional regularization terms control the
deformation trajectories of multiple surfaces as well as the uniformity and smoothness of the surfaces.
ribbon masks, and signed distance functions (SDFs); S0denotes the initialization midthickness 147
surface; and vm,vo,vicorrespond to the velocity fields that drive S0towards the true midthickness 148
surface SM, outward to the pial surface SG, and inward to the WM surface SW, respectively. The 149
SegCSR establishes an explicit one-to-one mapping between multiple surfaces and is trained by 150
minimizing weakly supervised losses between the predicted mesh and the ribbon segmentations. 151
The diffeomorphic deformation between the initialization surface and the target surface can be 152
computed as the integration of an ODE [1] based on the velocity field v: 153
dΦ(x, t)
dt=v(Φ(x, t), t)s.t.Φ(x,0) =x(0),and thus Φ(x, t) =x(0)+Zt
ov(Φ(x, s), s)ds,(1)
where Φ(x, t)defines a trajectory from the source position x(0)= Φ( x,0)to the target position 154
x(1)= Φ(x,1). According to the Cauchy-Lipschitz theorem [ 50], if the velocity field is Lipschitz 155
continuous, the resulting mapping Φis bijective with continuous inverse (i.e., a diffeomorphism). 156
To solve this initial value problem, we perform the integration on the predicted velocity fields 157
using standard numerical integration techniques, such as the Euler method and the Runge-Kutta 158
method [ 9]. Specifically, for each integration step t∈[0,1], each vertex’s coordinates can be updated 159
byx(t+1)=x(t)+hv(Φ(x, t), t), where h=1
Tis the step size and Tis the total time steps, and 160
the velocity vector vfor a vertex is trilinearly interpolated from its neighboring velocity vectors [ 54]. 161
3.2 Weak Supervision Loss Functions 162
Mesh Loss . Weak supervision for SegCSR is derived from cortical ribbon segmentation maps of 163
WM and GM (see Fig. 1, the filled interior area of WM and pial surfaces), which can be obtained 164
from existing segmentation approaches [ 7,20,29,45,52]. Although these ribbon segmentation 165
maps do not perfectly represent the intricate pial surface, the WM surface is relatively easier to 166
recognize due to its clear local intensity contrast, providing a better-separable boundary (see Fig. 2 167
(a-b)). Therefore, we use the boundary of the pGT WM segmentation to supervise the WM surface 168
reconstruction. Inspired by [ 31,54], we generate an SDF for the WM surface by using a distance 169
transform algorithm, where voxels with values of zero represent the surface boundaries and voxels 170
with negative or positive values encode their distances to the surface boundaries inward or outward, 171
4(a) Raw image(b) Cortical surfaces(c-1) Bi-directional Chamfer loss(c-2) Uni-directional Chamfer loss
(d) Inter-mesh normal consistency loss
(e) Intensity gradient loss(f) Cycle consistency loss𝐴𝜇𝜇𝜇=2!"(g) Customized edge length loss
!!"!!!"Pial Surf.WM Surf.Mid Surf.!"#$!"#$′!!"!"#$!"#$′′Pial Surf.Mid Surf.WM Surf.!!!"−𝐾+𝐾00Intensity gradient
Sample location−𝐾+𝐾Figure 2: (a) A brain MRI region. (b)-(g) are illustration of loss terms. (b) WM, midthickness,
pial surfaces in a deep sulcus region. (c-1) Bi-directional Chamfer loss for the WM surface; (c-2)
Uni-directional Chamfer loss for the pGT pial surface generated from the GM segmentation. (d)
Normal consistency between three reconstructed surfaces. (e) Intensity gradient along the normal
direction of a vertex in the surface. (f) The symmetric deformation trajectory. voandviare outward
and inward velocity fields respectively. (g) The customized edge length loss. A: area; µ: edge length.
respectively. We then apply a fast topology check and correction algorithm [ 4] to the SDF to ensure 172
the surface maintains spherical topology. The WM surface SW∗is extracted using the Marching 173
Cubes algorithm [ 27]. The distance of the vertices between the predicted surface SWand the pGT 174
surface SW∗is minimized using the bi-directional Chamfer distance [26]: 175
LchW=1
|SW|X
p∈SWmin
p∗∈SW∗∥p−p∗∥2
2+1
|SW∗|X
p∗∈SW∗min
p∈SW∥p∗−p∥2
2, (2)
where pandp∗are the coordinates of vertices on meshes. See Fig. 2 (c-1) for illustration. 176
For the pial surface, GM segmentation may fail to delineate the boundary in deep cortical sulci. 177
As shown in Fig. 2 (c-2), using a similar pGT surface generation protocol as the WM surface to 178
generate the pial surface SG∗fail to capture cortical folding accurately. Directly fitting to SG∗with 179
bi-directional Chamfer loss causes the model to predict similarly inaccurate cortical sulci. To address 180
this issue, we propose the boundary surface loss, which uses a uni-directional Chamfer distance to 181
compute the shortest distance from the pGT pial surface SG∗to the predicted pial surface SG: 182
LchG=1
|SG|X
p∈SGmin
p∗∈SG∗∥p−p∗∥2
2. (3)
In this way, the deformed surface is not influenced by the inaccuracies of SG∗and does not move 183
outward from the deep sulci. The overall mesh loss is computed as Lmesh =LchW+LchG. 184
Inter-Mesh Normal Consistency Loss . To further alleviate the difficulty of constraining the pial 185
surface using the WM and midthickness surfaces, we propose leveraging the prior knowledge that 186
the cerebral cortex has a sheet-like topology (i.e., the inner, middle, and outer surfaces are locally 187
parallel to each other). As shown in Fig. 2 (d), this loss is defined to ensure that the deformation 188
of the midthickness surface aligns with its normal direction, thereby maintaining similar normal 189
directions on the target surfaces: 190
Limnc =1
|SM|X
p∈SM(1−cos(npG,npW)), (4)
5where npGandnpWare the normal vectors of the deformed vertex ponSMandSGrespectively. 191
Intensity Gradient Loss . In addition to ribbon segmentaions, inspired by the fact that traditional 192
methods utilize raw image intensity contrast to define and optimize the target surfaces, we propose to 193
adjust the nuance between GT target surface and the pGT segmentation boundaries. By definition [ 17, 194
52], the WM (or pial) surface lies at the WM/GM (or GM/CSF) interface where image intensity change 195
most drastically. We sample Kpoints along the extended lines on each side of the normal direction at 196
vertex p, and compute the gradients of neighboring points: Lgrad=1
|SW|P
p∈SMPK
i=1grad i(p) + 197
1
|SG|P
p∈SGPK
i=1grad i(p). 198
Cycle Consistency Loss. We utilize the midthickness layer to establish a correspondence between 199
the inner and outer surfaces, thereby reducing the difficulty of learning large deformations. However, 200
there is no true midthickness surface available for supervision, nor a definitive criterion for choosing 201
between bi-directional or uni-directional approaches for different regions on the midthickness surface. 202
Additionally, the learned velocity fields voandvicould potentially cause non-inverse transformations 203
at the midthickness surface. To address these issues, we propose a loss function that enforces the 204
midthickness surface resides halfway between the WM and pial surfaces and maintains consistency 205
along the entire trajectory: 206
Lcyc=1
|SM|X
p∈SM∥pΦW◦ΦG−p∥2
2+∥pΦG◦ΦW−p∥2
2+∥LMid→GM(p)−LMid→WM(p)∥2
2,(5)
where pΦb◦Φarepresents deforming a vertex p∈ SMwith velocity field vaandvbsequentially, and 207
LMid→GM(p)is the accumulated trajectory length over Tsteps of deformation. For example, as 208
shown in Fig. 2 (f), the deformations move a vertex pMidoutward to pGMusing voand then inward 209
top′
Midusing vi, in which the two trajectories are aligned by minimizing the distance between pMid 210
andp′
Mid. Similarly, we enforce the consistency between pΦG◦ΦWandp. Furthermore, starting 211
from the midthickness layer, the trajectory lengths of the vertex moving to the WM and pial surfaces 212
should be equal, which is regularized by the third term in the equation above. 213
Mesh Quality Loss. First, the reconstructed surface should be composed of uniformally distributed 214
triangles. To accommodate various sizes of brain volume and image resolution, we devise a cus- 215
tomized edge length loss to constrain the size of triangles in the predicted meshes for each subject. 216
Specifically, we assume an ideal prediction where the faces are equilateral and of the same area A 217
and drive the edge length to the target edge length µel= 2q
A√
3(see Fig. 2 (g)). Second, we employ 218
anormal consistency loss to promote the surfaces’ smoothness. The mesh quality loss is defined as: 219
Lqua=1
|S|
X
p∈S1
|N(p)|X
k∈N(p)(µel− ∥p−k∥2)2+X
e∈S,f0∩f1=e(1−cos(nf0,nf1))
,(6)
whereSdenotes the predicted mesh, N(p)are the neighbors of vertex p,eis an edge, f0andf1are 220
e’s two neighboring faces with their unit normals nf0andnf1. 221
In summary, we combine all the losses to jointly optimize our SegCSR model: L=λ1Lmesh + 222
λ2Limnc+λ3Lgrad+λ4Lcyc+λ5Lqua, where {λi}i=1,···,5are weights to balance the loss terms. 223
4 Experiments 224
4.1 Experimental Setups 225
Datasets. We evaluate our method on two large-scale adult datasets and one infant dataset of low 226
resolution. The ADNI-1 [ 24] dataset consists of 817 subjects aged 55 to 90. We randomly split it into 227
subsets of 654, 50, and 113 subjects for training, validation, and testing, respectively. The OASIS- 228
1 [35] dataset consists of 413 subjects aged 18 to 96. We randomly split it into subsets of 330, 25, and 229
58 subjects for training, validation, and testing, respectively. We followed a pre-processing protocol 230
used in previous works [ 8,13,26,31] for fair comparison. The T1-weighted MRI scans were aligned 231
to the MNI152 template and clipped to the size of 192×224×192at1mm3isotropic resolution. 232
The pseudo ground-truth (pGT) of ribbon segmentation and cortical surfaces were generated using 233
FreeSurfer v7.2.0 [ 17]. The BCP [ 23] dataset consists of 121 subjects ranging in age from 2 weeks 234
to 12 months. We randomly allocate 90, 12, and 19 subjects for training, validation, and testing, 235
6Table 1: Quantitative analysis of cortical surface reconstruction on geometric accuracy and self-intersections.
The Chamfer distance (CD), average symmetric surface distance (ASSD), Hausdorff distance (HD), and the ratio
of the self-intersecting faces (SIF) were measured for WM and pial surfaces on three datasets. The mean value
and standard deviation are reported. Lower scores indicate better results for all metrics. “S” denotes the use of
pGT surfaces from conventional pipelines, while “W” represents weak supervision by pGT ribbon segmentations.
In each supervision setting, the best results are in bold, and the second best results are underlined.
Data
Sup.MethodL-Pial Surface L-WM Surface
CD (mm ) ASSD ( mm ) HD (mm ) SIF (%) CD (mm ) ASSD ( mm ) HD (mm ) SIF (%)ADNISCorticalFlow++ [47] 0.545±0.036 0.410 ±0.033 0.886 ±0.069 0.098 ±0.067 0.544±0.034 0.401 ±0.030 0.878 ±0.066 0.069 ±0.042
cortexODE [31] 0.476±0.017 0.214 ±0.020 0.455 ±0.058 0.022 ±0.012 0.458±0.016 0.192 ±0.015 0.436 ±0.014 0.015 ±0.011
V ox2Cortex [8] 0.582±0.028 0.370 ±0.025 0.746 ±0.057 0.059 ±0.039 0.577±0.027 0.353 ±0.022 0.722 ±0.055 0.043 ±0.023
CoCSR [54] 0.322±0.021 0.123±0.010 0.267±0.022 0.013±0.011 0.303±0.018 0.117±0.010 0.254±0.021 0.005±0.002
WDeepCSR [13] 0.945±0.078 0.593 ±0.065 1.149 ±0.203 \ 0.938±0.076 0.587 ±0.064 1.137 ±0.193 \
3D U-Net [44] 0.598±0.049 0.341 ±0.037 0.782 ±0.163 \ 0.473±0.013 0.265 ±0.015 0.558 ±0.028 \
SegCSR (Ours) 0.578±0.019 0.324±0.019 0.749±0.049 0.008 ±0.009 0.467±0.014 0.258±0.019 0.545±0.036 0.009 ±0.009OASISSCorticalFlow++ [47] 0.531±0.035 0.399 ±0.030 0.812 ±0.057 0.088 ±0.045 0.529±0.033 0.398 ±0.030 0.810 ±0.055 0.086 ±0.042
cortexODE [31] 0.481±0.019 0.218 ±0.021 0.461 ±0.062 0.026 ±0.015 0.463±0.018 0.207 ±0.017 0.435 ±0.015 0.018 ±0.010
V ox2Cortex [8] 0.588±0.032 0.381 ±0.030 0.750 ±0.063 0.061 ±0.037 0.581±0.028 0.375 ±0.027 0.731 ±0.059 0.046 ±0.027
CoCSR [54] 0.410±0.034 0.142±0.016 0.281±0.024 0.016±0.012 0.349±0.024 0.128±0.019 0.266±0.022 0.007±0.002
WDeepCSR [13] 0.986±0.085 0.617 ±0.070 1.331 ±0.212 \ 0.975±0.081 0.594 ±0.067 1.151 ±0.197 \
3D U-Net [44] 0.611±0.069 0.332 ±0.050 0.774 ±0.267 \ 0.454±0.013 0.245 ±0.017 0.489 ±0.031 \
SegCSR (Ours) 0.581±0.016 0.321±0.018 0.725±0.040 0.010 ±0.010 0.449±0.011 0.223±0.016 0.461±0.027 0.010 ±0.009BCPSCorticalFlow++ [47] 0.927±0.271 0.731 ±0.036 1.943 ±0.175 1.114 ±0.385 0.895±0.242 0.722 ±0.034 1.880 ±0.151 0.533 ±0.107
cortexODE [31] 0.759±0.082 0.396 ±0.032 0.823 ±0.103 0.124 ±0.061 0.678±0.071 0.349 ±0.031 0.816 ±0.099 0.101 ±0.034
CoCSR [54] 0.576±0.041 0.216±0.023 0.468±0.063 0.064±0.040 0.544±0.038 0.199±0.020 0.447±0.049 0.058±0.033
WDeepCSR [13] 2.673±1.131 1.224 ±0.215 3.112 ±1.218 \ 1.440±0.521 0.428 ±0.051 0.933 ±0.118 \
3D U-Net [44] 1.175±0.314 0.793 ±0.059 2.140 ±1.021 \ 0.688±0.120 0.377 ±0.041 0.791 ±0.064 \
SegCSR (Ours) 0.927±0.070 0.497±0.061 1.287±0.144 0.061 ±0.058 0.876±0.067 0.478±0.052 1.206±0.132 0.055 ±0.057
respectively. Rigid registration was applied to the T1w and T2w image pairs. The pGT of ribbon 236
segmentation and cortical surfaces were generated by the iBEAT v2.0 [ 52]. The intensity values of 237
MRI scans, ribbon segmentation maps, and SDFs were normalized to [0,1]and the coordinates of the 238
vertices were normalized to [−1,1]. All the models were trained on the training set until they reached 239
a loss plateau on the validation set and evaluated on the test set. 240
Implementation Details Our framework was implemented in PyTorch [ 40] and trained on a worksta- 241
tion with 12 GB NVIDIA P100 GPU. The 3D U-Net [ 44] for segmentation of ribbons was trained for 242
200 epochs using Adam [ 25] optimization and achieved an average Dice index of 0.96 on the testing 243
set. The SegCSR model utilized T= 5steps (i.e., step size is 0.2) in Euler solver. We trained our 244
SegCSR model using Adam optimizer ( β1= 0.9,β2= 0.999,ϵ= 1e−10, learning rate 1e−4) for 245
400 epochs to reconstruct both WM, midthickness, and pial surfaces of both brain hemispheres. We 246
setλ1=λ4= 1andλ2=λ3=λ5= 0.1. The surface meshes had ∼130kvertices. More details 247
can be found in the Supplementary Materials. 248
Evaluation Metrics We utilized three distance-based metrics to measure the CSR accuracy: Chamfer 249
distance (CD), average symmetric surface distance (ASSD), and 90th-percentile Hausdorff distance 250
(HD). CD [ 16,53] measures the mean distance between two sets of vertices. ASSD [ 13] and 251
HD [ 13,49] measure the average and maximum distance between two surfaces. They were computed 252
bidirectionally over ∼130kpoints uniformly sampled from the predicted and target surfaces. A lower 253
distance means a better result. Since topology is also important in CSR, we utilized the ratio of 254
self-intersection faces (SIF) [13, 14, 31, 54] to measure reconstructed surface quality. 255
4.2 Comparison with Related Works 256
We compare SegCSR with both implicit and explicit learning-based cortical surface reconstruction 257
approaches described in Section 1 and summarize the experimental results in Table 5. 258
On Adult Datasets. (I) Comparison with Implicit Approaches . We compare SegCSR with two 259
representative implicit representation approaches on the ADNI and OASIS datasets. As shown 260
in Table 5, SegCSR achieves superior geometric accuracy. Note that both DeepCSR [ 13] and 3D 261
U-Net [ 44] require post-processing to correct topology and extract a mesh, resulting in SIFs of 0. 262
Without post-processing, the SIFs for 3D U-Net’s WM and pial surfaces range from 3%to15%. 263
SegCSR produces a negligible number of self-intersecting faces, ∼0.3%on average for both white 264
and pial surfaces. Fig. 3 shows that SegCSR effectively deforms the pial surface into deep sulci, 265
while the baseline approaches exhibit large geometric errors due to the PVE problem of brain MRI. 266
7(a) DeepCSR(b) CortexODE(c) SegCSR(S0 setting)(d) SegCSR(S0* setting)(e) pGTfrom FreeSurferFigure 3: Visualization of reconstructed pial surfaces compared to DeepCSR and CortexODE. CortexODE is
trained with pGT from FreeSurfer; DeepCSR and ours are trained with pGT ribbon segmentations.
Additionally, SegCSR requires only 0.37s of runtime per brain hemisphere, orders of magnitude 267
faster than traditional FreeSurfer pipelines. (II) Comparison with Explicit Approaches . We compare 268
SegCSR with explicit learning-based approaches, including CorticalFlow++ [ 47], V ox2Cortex [ 8], 269
CortexODE [ 31], and CoCSR [ 54]. These methods are trained with pGT surfaces generated by 270
conventional pipelines, providing more accurate supervision than pGT ribbon segmentations. For 271
a fair comparison, we employ the same network structure for the current best CoCSR [ 54] and our 272
SegCSR, with CoCSR serving as an upper-bound performance benchmark for our weakly supervised 273
SegCSR. As shown in Table 5, SegCSR surprisingly surpasses some supervised baselines in terms of 274
both geometric and morphological accuracy, demonstrating its potential to replace existing methods 275
when accurate surface supervision is not available. 276
On Infant Dataset. Infant brain MRIs present additional challenges due to the smaller size of fetal 277
brains, limited image resolution, and lower image contrast, which together make the reconstruction 278
task more difficult. Consequently, overall performance is inferior compared to adult datasets. We 279
compare SegCSR with both implicit and explicit representation approaches. The results in Table 5 280
show that SegCSR achieves superior performance than the implicit DeepCSR and 3D U-Net methods, 281
and comparable performance to explicit methods like CorticalFlow++, CortexODE, and CoCSR. 282
4.3 Ablation Studies 283
Table 2: Ablation studies on the ADNI dataset. The setting S0 refers to our complete setting (cf. Table 5). Top:
The impact of loss functions. Bottom: The impact of initialization surface location.
SettingLoss L-Pial Surface L-WM Surface
LmeshLimncLgradLcycLqua CD (mm ) ASSD ( mm ) HD (mm ) SIF (%) CD (mm ) ASSD ( mm ) HD (mm ) SIF (%)
S0 ✓ ✓ ✓ ✓ ✓ 0.578±0.019 0.324 ±0.019 0.749 ±0.049 0.008 ±0.009 0.467±0.014 0.258 ±0.019 0.545 ±0.036 0.009 ±0.009
S1 ✓ ✓ ✓ ✓ 0.576±0.019 0.323 ±0.019 0.747 ±0.046 0.012 ±0.011 0.467±0.015 0.257 ±0.020 0.542 ±0.036 0.011 ±0.011
S2 ✓ ✓ ✓ 0.579±0.019 0.325 ±0.019 0.748 ±0.047 0.014 ±0.013 0.469±0.016 0.248 ±0.019 0.544 ±0.042 0.015 ±0.014
S3 ✓ ✓ 0.579±0.020 0.325 ±0.021 0.749 ±0.050 0.018 ±0.014 0.473±0.013 0.249 ±0.018 0.544 ±0.039 0.017 ±0.013
S4 ✓ 0.589±0.034 0.356 ±0.039 0.764 ±0.067 0.015 ±0.012 0.473±0.012 0.256 ±0.020 0.564 ±0.042 0.014 ±0.013
S0⋆✓⋆✓ ✓ ✓ ✓ 0.607±0.034 0.327 ±0.024 0.752 ±0.077 0.026 ±0.016 0.469±0.015 0.258 ±0.020 0.547 ±0.038 0.020 ±0.015
S4⋆✓⋆0.626±0.053 0.321 ±0.039 0.773 ±0.168 0.034 ±0.025 0.476±0.013 0.256 ±0.018 0.562 ±0.034 0.031 ±0.017
Init. Surface
LocationL-Pial Surface L-WM Surface
CD (mm ) ASSD ( mm ) HD ( mm ) SIF(%) CD (mm ) ASSD ( mm ) HD ( mm ) SIF(%)
WM 0.878±0.077 0.587 ±0.060 1.084 ±0.097 0.012 ±0.011 0.439±0.011 0.211 ±0.013 0.430 ±0.028 0.007 ±0.008
Mid 0.578±0.019 0.324 ±0.019 0.749 ±0.049 0.008 ±0.009 0.467±0.014 0.258 ±0.019 0.545 ±0.036 0.009 ±0.009
GM 0.489±0.016 0.317 ±0.018 0.567 ±0.044 0.008 ±0.008 0.889±0.085 0.597 ±0.059 1.211 ±0.104 0.020 ±0.018
Loss Functions. We evaluated the contribution of different losses of our method to the surface 284
reconstruction performance in terms of both accuracy (CD, ASSD, HD) and topological correctness 285
(SIF). The results are summarized in Table 2 (Top). The setting S4 represents using our proposed 286
Chamfer loss (i.e., uni-directional for the pial surface) alone, while S4⋆referes to using existing 287
bi-directional Chamfer loss for both WM and pial surfaces. The results of S4 and S4⋆indicated 288
that the model using bi-directional Chamfer loss overfitted to the pGT segmentation boundary and 289
failed to fit the deep cortical sulci. Another pair of comparison, S0 and S0⋆, showed a similar 290
phenomenon. Enforcing the inter-mesh normal consistency of the WM and pial surfaces (S3, Limnc ) 291
improved geometric accuracy by explicitly constraining the nromal direction of two surfaces but 292
slightly worsened the topology, which might be caused by the discrepancy between the midthickness 293
and the WM (and pial) surface. The proposed intensity gradient loss (S2, Lgrad) helped adjust the 294
deformed surfaces locally, leading to slightly improved geometric accuracy and reduced topology 295
error. Enforcing equality of the trajectories from the midthickness surface to the WM and pial surfaces 296
8and symmetric cycle consistency of two trajectories (S1, Lcyc) helped optimize the midthickness 297
surface and promoted the invertibility of deformations. Moreover, the inclusion of regularization 298
terms on the uniformity and smoothness of the reconstructed surfaces (S0, Lqua) enhanced the 299
surface quality and significantly reduce the self-intersection face ratio. Overall, our proposed method 300
struck a balance between geometric accuracy and topology quality, with each component playing a 301
complementary role. 302
Initialization Surface Location. Table 2 (Bottom) shows the impact of the initialization surface 303
location. Starting from either the WM or midthickness surfaces leads to satisfactory results. Con- 304
versely, initializing from the GM surface introduced more difficulty in learning large deformations 305
into deep sulci due to the severe partial volume effect, resulting in worse average geometric accuracy 306
for both surfaces. The results also indicated that the closer the initial surface was to its target surface, 307
the higher the reconstruction accuracy achieved. Therefore, starting from the midthickness surface 308
strikes a balance between WM and pial surface reconstruction outcomes. 309
4.4 Reproducibility 310Table 3: Reproducibility analysis.
MethodL-WM Surface
CD (mm ) ASSD ( mm ) HD ( mm )
SegCSR (Ours) 0.473±0.016 0.254 ±0.024 0.520 ±0.062
DeepCSR 0.505±0.047 0.297 ±0.053 0.610 ±0.100
CoCSR 0.451±0.019 0.235 ±0.030 0.492 ±0.059
CortexODE 0.457±0.021 0.238 ±0.031 0.504 ±0.071
FreeSurfer 0.476±0.015 0.253 ±0.022 0.519 ±0.048
MethodL-Pial Surface
CD (mm ) ASSD ( mm ) HD ( mm )
SegCSR (Ours) 0.529±0.023 0.285 ±0.033 0.622 ±0.066
DeepCSR 0.560±0.055 0.341 ±0.060 0.668 ±0.118
CoCSR 0.493±0.024 0.276 ±0.036 0.573 ±0.070
CortexODE 0.506±0.029 0.272 ±0.034 0.581 ±0.079
FreeSurfer 0.526±0.021 0.283 ±0.032 0.595 ±0.068We conducted an experiment on the Test-Retest 311
dataset [ 33], which comprises 40 MRIs collected within 312
a short period for each of the 3 subjects. The cor- 313
tical surfaces of the same subject should be nearly 314
identical. Following the experimental setup outlined 315
in [8,13,31,54], we utilized the iterative closest-point 316
algorithm to align image pairs and computed the ge- 317
ometric distance between surfaces. The results for 318
the left hemisphere are presented in Table 3, showing 319
that SegCSR obtained superior reproducibility com- 320
pared with DeepCSR (implicit representation; weakly 321
supervised) and was comparable to the conventional 322
FreeSurfer pipeline and supervised DL-based CSR 323
methods. This implied that the results generated by SegCSR can be reliably used for downstream 324
analyses, such as investigating cortical thickness changes in patients. 325
5 Conclusions 326
We introduce SegCSR, a novel approach to jointly reconstruct multiple cortical surfaces using 327
weak supervision from ribbon segmentations derived from brain MRIs. Our method initializes a 328
midthickness surface and then deforms it inward and outward to the inner and outer cortical surfaces by 329
jointly learning diffeomorphic flows. The new boundary loss function optimizes the surfaces toward 330
the boundaries of the cortical ribbon segmentation maps while the inter-surface normal consistency 331
loss regularizes the pial surface in complex and challenging cortical sulci regions. Additional 332
regularization terms are incorporated to enforce reconstructed surfaces’ uniformity, smoothness, 333
and topology. Extensive experiments conducted on large-scale adult and infant brain MRI datasets 334
demonstrate superior performance in terms of accuracy and surface regularity compared to existing 335
supervised DL-based alternatives. 336
Limitations and Future Directions. The efficacy of SegCSR is influenced by the quality of pGT 337
segmentations. Also, We can utilize brain tissue segmentation as auxiliary functions to supervise the 338
model training. SegCSR constrains the inter-mesh consistency of the deformation on the midthickness 339
surface, potentially affecting anatomical fidelity of pial surfaces. The method should be tested on 340
more diverse cohorts of subjects to demonstrate its efficacy on real world neuroimage analysis tasks. 341
Societal Impact. Our proposed method has been rigorously evaluated on four real-world brain MRI 342
datasets, showcasing its capacity to assist doctors and scientists in both quantitative and qualitative 343
analyses of the cerebral cortex. Nonetheless it is imperative to conduct more thorough evaluation on 344
a larger cohort of subjects and across various imaging qualities. And the deployment of the model in 345
clinical settings should be approached with caution and under human supervision. 346
References 347
[1] V . I. Arnold. Ordinary differential equations . Springer Science & Business Media, 1992. 348
9[2]V . Arsigny, O. Commowick, X. Pennec, and N. Ayache. A log-euclidean framework for statistics 349
on diffeomorphisms. In International Conference on Medical Image Computing and Computer 350
Assisted Intervention , pages 924–931. Springer, 2006. 351
[3]G. Balakrishnan, A. Zhao, M. R. Sabuncu, J. Guttag, and A. V . Dalca. V oxelmorph: a learning 352
framework for deformable medical image registration. IEEE Transactions on Medical Imaging , 353
38(8):1788–1800, 2019. 354
[4]P.-L. Bazin and D. L. Pham. Topology correction of segmented medical images using a fast 355
marching algorithm. Computer Methods and Programs in Biomedicine , 88(2):182–190, 2007. 356
[5]M. F. Beg, M. I. Miller, A. Trouvé, and L. Younes. Computing large deformation metric 357
mappings via geodesic flows of diffeomorphisms. International Journal of Computer Vision , 358
61:139–157, 2005. 359
[6]M. Bertoux, J. Lagarde, F. Corlier, L. Hamelin, J.-F. Mangin, O. Colliot, M. Chupin, M. N. 360
Braskie, P. M. Thompson, M. Bottlaender, et al. Sulcal morphology in alzheimer’s disease: an 361
effective marker of diagnosis and cognition. Neurobiology of Aging , 84:41–49, 2019. 362
[7]B. Billot, D. N. Greve, O. Puonti, A. Thielscher, K. Van Leemput, B. Fischl, A. V . Dalca, J. E. 363
Iglesias, et al. Synthseg: Segmentation of brain mri scans of any contrast and resolution without 364
retraining. Medical image analysis , 86:102789, 2023. 365
[8]F. Bongratz, A.-M. Rickmann, S. Pölsterl, and C. Wachinger. V ox2Cortex: Fast explicit 366
reconstruction of cortical surfaces from 3D MRI scans with geometric deep neural networks. In 367
Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 368
20773–20783, 2022. 369
[9] R. L. Burden, J. D. Faires, and A. M. Burden. Numerical analysis . Cengage learning, 2015. 370
[10] R. T. Chen, Y . Rubanova, J. Bettencourt, and D. K. Duvenaud. Neural ordinary differential 371
equations. Advances in Neural Information Processing Systems , 31:6572–6583, 2018. 372
[11] X. Chen, J. Zhao, S. Liu, S. Ahmad, and P.-T. Yap. SurfFlow: A flow-based approach for rapid 373
and accurate cortical surface reconstruction from infant brain mri. In International Conference 374
on Medical Image Computing and Computer-Assisted Intervention , pages 380–388. Springer, 375
2023. 376
[12] S. J. Crutch, M. Lehmann, J. M. Schott, G. D. Rabinovici, M. N. Rossor, and N. C. Fox. 377
Posterior cortical atrophy. The Lancet Neurology , 11(2):170–178, 2012. 378
[13] R. S. Cruz, L. Lebrat, P. Bourgeat, C. Fookes, J. Fripp, and O. Salvado. DeepCSR: A 3D deep 379
learning approach for cortical surface reconstruction. In Proceedings of the IEEE/CVF Winter 380
Conference on Applications of Computer Vision , pages 806–815, 2021. 381
[14] R. Dahnke, R. A. Yotter, and C. Gaser. Cortical thickness and central surface estimation. 382
Neuroimage , 65:336–348, 2013. 383
[15] A. M. Dale, B. Fischl, and M. I. Sereno. Cortical surface-based analysis: I. segmentation and 384
surface reconstruction. Neuroimage , 9(2):179–194, 1999. 385
[16] H. Fan, H. Su, and L. J. Guibas. A point set generation network for 3d object reconstruction 386
from a single image. In Proceedings of the IEEE/CVF Conference on Computer Vision and 387
Pattern Recognition , pages 605–613, 2017. 388
[17] B. Fischl. Freesurfer. Neuroimage , 62(2):774–781, 2012. 389
[18] M. F. Glasser, S. N. Sotiropoulos, J. A. Wilson, T. S. Coalson, B. Fischl, J. L. Andersson, J. Xu, 390
S. Jbabdi, M. Webster, J. R. Polimeni, et al. The minimal preprocessing pipelines for the human 391
connectome project. Neuroimage , 80:105–124, 2013. 392
[19] K. Gopinath, C. Desrosiers, and H. Lombaert. SegRecon: Learning joint brain surface re- 393
construction and segmentation from images. In International Conference on Medical Image 394
Computing and Computer Assisted Intervention , pages 650–659. Springer, 2021. 395
10[20] L. Henschel, S. Conjeti, S. Estrada, K. Diers, B. Fischl, and M. Reuter. Fastsurfer-a fast and 396
accurate deep learning based neuroimaging pipeline. NeuroImage , 219:117012, 2020. 397
[21] Y . Hong, S. Ahmad, Y . Wu, S. Liu, and P.-T. Yap. V ox2Surf: Implicit surface reconstruction 398
from volumetric data. In Intl. Workshop on Machine Learning in Medical Imaging , pages 399
644–653. Springer, 2021. 400
[22] A. Hoopes, J. E. Iglesias, B. Fischl, D. Greve, and A. V . Dalca. Topofit: Rapid reconstruction of 401
topologically-correct cortical surfaces. In Medical Imaging with Deep Learning , 2022. 402
[23] B. R. Howell, M. A. Styner, W. Gao, P.-T. Yap, L. Wang, K. Baluyot, E. Yacoub, G. Chen, 403
T. Potts, A. Salzwedel, et al. The unc/umn baby connectome project (bcp): An overview of the 404
study design and protocol development. NeuroImage , 185:891–905, 2019. 405
[24] C. R. Jack Jr, M. A. Bernstein, N. C. Fox, P. Thompson, G. Alexander, D. Harvey, B. Borowski, 406
P. J. Britson, J. L. Whitwell, C. Ward, et al. The alzheimer’s disease neuroimaging initiative 407
(ADNI): MRI methods. Journal of Magnetic Resonance Imaging: An Official Journal of the 408
International Society for Magnetic Resonance in Medicine , 27(4):685–691, 2008. 409
[25] D. P. Kingma and J. Ba. Adam: A method for stochastic optimization. In International 410
Conference on Learning Representations , 2015. 411
[26] L. Lebrat, R. Santa Cruz, F. de Gournay, D. Fu, P. Bourgeat, J. Fripp, C. Fookes, and O. Salvado. 412
CorticalFlow: A diffeomorphic mesh transformer network for cortical surface reconstruction. 413
Advances in Neural Information Processing Systems , 34:29491–29505, 2021. 414
[27] T. Lewiner, H. Lopes, A. W. Vieira, and G. Tavares. Efficient implementation of marching 415
cubes’ cases with topological guarantees. Journal of Graphics Tools , 8(2):1–15, 2003. 416
[28] H. Li, Y . Fan, and A. D. N. Initiative. MDReg-Net: Multi-resolution diffeomorphic image 417
registration using fully convolutional networks with deep self-supervision. Human Brain 418
Mapping , 43(7):2218–2231, 2022. 419
[29] Y . Li, H. Li, and Y . Fan. ACEnet: Anatomical context-encoding network for neuroanatomy 420
segmentation. Medical image analysis , 70:101991, 2021. 421
[30] Q. Ma, L. Li, V . Kyriakopoulou, J. V . Hajnal, E. C. Robinson, B. Kainz, and D. Rueckert. Condi- 422
tional temporal attention networks for neonatal cortical surface reconstruction. In International 423
Conference on Medical Image Computing and Computer-Assisted Intervention , pages 312–322. 424
Springer, 2023. 425
[31] Q. Ma, L. Li, E. C. Robinson, B. Kainz, D. Rueckert, and A. Alansary. CortexODE: Learning 426
cortical surface reconstruction by neural ODEs. IEEE Trans. on Medical Imaging , 42(2):430– 427
443, 2022. 428
[32] Q. Ma, E. C. Robinson, B. Kainz, D. Rueckert, and A. Alansary. PialNN: A fast deep learning 429
framework for cortical pial surface reconstruction. In International Workshop on Machine 430
Learning in Clinical Neuroimaging , pages 73–81. Springer, 2021. 431
[33] J. Maclaren, Z. Han, S. B. V os, N. Fischbein, and R. Bammer. Reliability of brain volume 432
measurements: a test-retest dataset. Scientific Data , 1(1):1–9, 2014. 433
[34] A. Makropoulos, E. C. Robinson, A. Schuh, R. Wright, S. Fitzgibbon, J. Bozek, S. J. Counsell, 434
J. Steinweg, K. Vecchiato, J. Passerat-Palmbach, et al. The developing human connectome 435
project: A minimal processing pipeline for neonatal cortical surface reconstruction. Neuroimage , 436
173:88–112, 2018. 437
[35] D. S. Marcus, T. H. Wang, J. Parker, J. G. Csernansky, J. C. Morris, and R. L. Buckner. Open 438
access series of imaging studies (OASIS): cross-sectional MRI data in young, middle aged, 439
nondemented, and demented older adults. Journal of Cognitive Neuroscience , 19(9):1498–1507, 440
2007. 441
[36] Q. Meng, W. Bai, D. P. O’Regan, and D. Rueckert. Deepmesh: Mesh-based cardiac motion 442
tracking using deep learning. IEEE Transactions on Medical Imaging , 2023. 443
11[37] M. Modat, D. M. Cash, P. Daga, G. P. Winston, J. S. Duncan, and S. Ourselin. Global 444
image registration using a symmetric block-matching approach. Journal of medical imaging , 445
1(2):024003–024003, 2014. 446
[38] T. C. Mok and A. Chung. Fast symmetric diffeomorphic image registration with convolutional 447
neural networks. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern 448
Recognition , pages 4644–4653, 2020. 449
[39] D. H. Pak, M. Liu, S. S. Ahn, A. Caballero, J. A. Onofrey, L. Liang, W. Sun, and J. S. Duncan. 450
Weakly supervised deep learning for aortic valve finite element mesh generation from 3D CT 451
images. In International Conference on Information Processing in Medical Imaging , pages 452
637–648. Springer, 2021. 453
[40] A. Paszke, S. Gross, F. Massa, A. Lerer, J. Bradbury, G. Chanan, T. Killeen, Z. Lin, 454
N. Gimelshein, L. Antiga, et al. PyTorch: An imperative style, high-performance deep learning 455
library. Advances in Neural Information Processing Systems , 32:8026–8037, 2019. 456
[41] J. Ren, Q. Hu, W. Wang, W. Zhang, C. S. Hubbard, P. Zhang, N. An, Y . Zhou, L. Dahmani, 457
D. Wang, et al. Fast cortical surface reconstruction from MRI using deep learning. Brain 458
Informatics , 9(1):1–16, 2022. 459
[42] L. M. Rimol, R. Nesvåg, D. J. Hagler Jr, Ø. Bergmann, C. Fennema-Notestine, C. B. Hartberg, 460
U. K. Haukvik, E. Lange, C. J. Pung, A. Server, et al. Cortical volume, surface area, and 461
thickness in schizophrenia and bipolar disorder. Biological Psychiatry , 71(6):552–560, 2012. 462
[43] J. M. Roe, D. Vidal-Piñeiro, Ø. Sørensen, A. M. Brandmaier, S. Düzel, H. A. Gonzalez, R. A. 463
Kievit, E. Knights, S. Kühn, U. Lindenberger, et al. Asymmetric thinning of the cerebral 464
cortex across the adult lifespan is accelerated in alzheimer’s disease. Nature Communications , 465
12(1):721, 2021. 466
[44] O. Ronneberger, P. Fischer, and T. Brox. U-Net: Convolutional networks for biomedical image 467
segmentation. In International Conference on Medical Image Computing and Computer-Assisted 468
Intervention , pages 234–241, 2015. 469
[45] A. G. Roy, S. Conjeti, N. Navab, C. Wachinger, A. D. N. Initiative, et al. Quicknat: A fully 470
convolutional network for quick and accurate segmentation of neuroanatomy. NeuroImage , 471
186:713–727, 2019. 472
[46] D. Ruelle and D. Sullivan. Currents, flows and diffeomorphisms. Topology , 14(4):319–327, 473
1975. 474
[47] R. Santa Cruz, L. Lebrat, D. Fu, P. Bourgeat, J. Fripp, C. Fookes, and O. Salvado. Corti- 475
calFlow++: Boosting cortical surface reconstruction accuracy, regularity, and interoperability. 476
InInternational Conferences on Medical Image Computing and Computer Assisted Intervention , 477
pages 496–505. Springer, 2022. 478
[48] D. W. Shattuck and R. M. Leahy. Brainsuite: an automated cortical surface identification tool. 479
Medical Image Analysis , 6(2):129–142, 2002. 480
[49] A. A. Taha and A. Hanbury. Metrics for evaluating 3D medical image segmentation: analysis, 481
selection, and tool. BMC Medical Imaging , 15(1):1–28, 2015. 482
[50] G. Teschl. Ordinary differential equations and dynamical systems , volume 140. American 483
Mathematical Soc., 2012. 484
[51] D. C. Van Essen, H. A. Drury, S. Joshi, and M. I. Miller. Functional and structural mapping of 485
human cerebral cortex: solutions are in the surfaces. Proceedings of the National Academy of 486
Sciences , 95(3):788–795, 1998. 487
[52] L. Wang, Z. Wu, L. Chen, Y . Sun, W. Lin, and G. Li. ibeat v2.0: a multisite-applicable, deep 488
learning-based pipeline for infant cerebral cortical surface reconstruction. Nature protocols , 489
18(5):1488–1509, 2023. 490
12[53] N. Wang, Y . Zhang, Z. Li, Y . Fu, H. Yu, W. Liu, X. Xue, and Y .-G. Jiang. Pixel2Mesh: 3D 491
mesh model generation via image guided deformation. IEEE Transactions on Pattern Analysis 492
and Machine Intelligence , 43(10):3600–3613, 2020. 493
[54] H. Zheng, H. Li, and Y . Fan. Coupled reconstruction of cortical surfaces by diffeomorphic mesh 494
deformation. Advances in Neural Information Processing Systems , 37, 2023. 495
A Model Details 496
A.1 Cortical Ribbon Segmentation Network Architecture 497
Fig. 4 (Left) shows the detailed network architecture of our cortical ribbon segmentation network, 498
which is a 5-level hierarchical encoder-decoder with skip connections. The network processes a 3D 499
brain MRI to produce a cortical ribbon segmentation map. The white matter (WM) segmentation 500
includes the interior of the WM surface, encompassing cortical WM, deep gray matter, ventricles, 501
hippocampus, and other tissues within the surface. Similarly, the gray matter (GM) segmentation 502
includes the interior of the pial surface. The output map has five classes: left hemisphere WM and 503
GM, right hemisphere WM and GM, and background. In the encoder, each level uses a 3×3×3 504
convolutional layer with a stride of 2 to downsample the features. In the decoder, features are 505
upsampled by 2×at each scale, concatenated with the corresponding features from the encoder via 506
skip connections, and then fused using a 3×3×3convolutional layer with a stride of 1. For feature 507
extraction at the input, a 3×3×3convolutional layer with a stride of 1 is used. Before the final 508
prediction, three consecutive convolutional layers are applied. Each convolutional layer is followed 509
by a leaky ReLU activation function, except for the last one, which uses a Softmax function before 510
computing the cross-entropy loss with the ground truth. 511
326412812812812864643232
16
Input(1-channel)
643216161616165
3×3×3conv, stride = 22×upsampling
32Input (4-channel)641282561281286464323232
Skip connection
Velocity field2×2×2deconv, stride = 23×3×3conv, stride = 1
Figure 4: Left: 3D U-Net architecture for ribbon segmentation. The output, i.e., the cortical ribbon
map, is overlaid on the input image for illustration. Right: 3D U-Net architecture for cortical surface
reconstruction. The learned velocity fields are used to calculate deformations.
A.2 Cortical Surface Reconstruction Network Architecture and Training details 512
As shown in Fig.4 (Right), our cortical surface reconstruction (CSR) network operates at five scales. 513
To conserve memory, we downsample the input image using a 3×3×3convolution with a stride of 514
2 and skip complex feature fusion via skip connections in the decoding path at this scale. To improve 515
the accuracy of the velocity fields (VFs), we use 2×2×2deconvolutions with a stride of 2 in the 516
decoding path instead of 2×trilinear upsampling. At the output stage, we employ three parallel 517
3×3×3convolutional layers to generate VFs for the white matter (WM), midthickness, and pial 518
surfaces, respectively. ReLU activation functions are used after each convolutional layer, except for 519
the three parallel layers, where Softsign functions are applied. The VFs are then utilized to compute 520
diffeomorphic deformations. 521
13B Experimental Settings 522
B.1 Dataset Preprocessing 523
We preprocessed all the MRIs of the ADNI-1 [ 24] and OASIS-1 [ 35] datasets with the same protocols 524
as following: Based on the standard processing protocol in FreeSurfer V7.2.0 [ 17], the original 525
images were conformed and normalized (saved as orig.mgz ), affinely registered to the MNI152 526
template [8] using the NiftyReg toolbox [37]. The respective ribbon segmentation maps, SDFs, and 527
pseudo-ground-truth surfaces were also transformed using the computed transformation. Similarly, 528
we utilize iBEAT V2.0 [ 52] to process the BCP [ 23] dataset and merge the brain tissue segmentation 529
results as the ribbon segmentation maps. 530
B.2 Baselines 531
We compared our SegCSR with representatives from the two categories of existing DL-based CSR 532
methods and evaluated their performance for both WM and pial surface reconstruction. DeepCSR [ 13] 533
and 3D U-Net [ 44] represent implicit surface reconstruction methods, while others fall into the 534
category of explicit methods. Note that we modify the 3D U-Net method to first generate SDFs 535
based on the ribbon segmentation results, then perform topology correction, and finally utilize 536
the Marching Cubes algorithm to extract the mesh. Since it does not require pGT surfaces from 537
FreeSurfer for training supervision, it can be treated as a weakly supervised learning-based baseline. 538
CorticalFlow++[ 47] utilizes smoothed convex hulls as the initialization template, trains a chain of 539
deformation fields, and employs a fourth-order Runge-Kutta (RK4) solver to compute the integration 540
for the initial value problem. CortexODE[ 31] uses WM segmentation for surface initialization and 541
Neural ODE for deformation computation. V ox2cortex [ 8] deforms averaged surface templates with 542
a GNN-based network to reconstruct multiple surfaces. CoCSR [ 54] integrates multiple cortical 543
surface reconstructions into a single network. A summary of the state-of-the-art CSR methods is 544
provided in Table 4. 545
Table 4: Summary of baseline methods in terms of surface representation, supervision in training,
and loss functions.
Method Representation Supervision Primary Loss function
3D U-Net [44]ImplicitRibbon segmentation Cross Entropy
DeepCSR [13] SDFs L1 Loss
CorticalFlow++ [47]
ExplicitMesh Bi-directional Chamfer Loss
cortexODE [31] Mesh Bi-directional Chamfer Loss
V ox2Cortex [8] Mesh Bi-directional Chamfer Loss
CoCSR [54] Mesh Bi-directional Chamfer Loss
SegCSR (Ours) Explicit Ribbon segmentation Weak Supervision
C More Experimental Results 546
C.1 Quantitative comparison of our methods with Related Works 547
Due to space limit, we only showcase the quantitative results on left hemisphere in the main paper. 548
Quantitative comparison results on the right hemisphere are summarized as a supplement to Table 1 549
in the main paper. 550
14Table 5: Quantitative analysis of cortical surface reconstruction on geometric accuracy and self-
intersections. The Chamfer distance (CD), average symmetric surface distance (ASSD), Hausdorff
distance (HD), and the ratio of the self-intersecting faces (SIF) were measured for WM and pial
surfaces on three datasets. The mean value and standard deviation are reported. Lower scores indicate
better results for all metrics. “S” denotes the use of pGT surfaces from conventional pipelines, while
“W” represents weak supervision by pGT ribbon segmentations. In each supervision setting, the best
results are in bold, and the second best results are underlined.
Data
Sup.MethodR-Pial Surface R-WM Surface
CD (mm ) ASSD ( mm ) HD (mm ) SIF (%) CD (mm ) ASSD ( mm ) HD (mm ) SIF (%)ADNISCorticalFlow++ [47] 0.550±0.038 0.413 ±0.034 0.891 ±0.071 0.101 ±0.069 0.548±0.035 0.403 ±0.032 0.883 ±0.068 0.071 ±0.042
cortexODE [31] 0.482±0.019 0.220 ±0.022 0.461 ±0.060 0.033 ±0.017 0.470±0.020 0.207 ±0.019 0.444 ±0.018 0.023 ±0.016
V ox2Cortex [8] 0.593±0.032 0.382 ±0.029 0.755 ±0.061 0.071 ±0.045 0.588±0.029 0.363 ±0.024 0.741 ±0.057 0.059 ±0.035
CoCSR [54] 0.326±0.023 0.126±0.012 0.271±0.024 0.015±0.013 0.320±0.020 0.124±0.012 0.265±0.022 0.006±0.003
WDeepCSR [13] 0.948±0.080 0.597 ±0.068 1.154 ±0.207 \ 0.942±0.077 0.589 ±0.065 1.140 ±0.195 \
3D U-Net [44] 0.601±0.048 0.342 ±0.037 0.784 ±0.166 \ 0.476±0.014 0.268 ±0.016 0.563 ±0.031 \
SegCSR (Ours) 0.582±0.021 0.328±0.022 0.751±0.050 0.009 ±0.009 0.470±0.015 0.261±0.021 0.548±0.038 0.011 ±0.010OASISSCorticalFlow++ [47] 0.540±0.037 0.405 ±0.032 0.834 ±0.060 0.095 ±0.052 0.536±0.035 0.402 ±0.031 0.830 ±0.058 0.088 ±0.049
cortexODE [31] 0.497±0.023 0.225 ±0.024 0.473 ±0.065 0.038 ±0.027 0.481±0.021 0.214 ±0.021 0.450 ±0.022 0.025 ±0.019
V ox2Cortex [8] 0.598±0.033 0.386 ±0.031 0.761 ±0.064 0.072 ±0.040 0.592±0.031 0.379 ±0.028 0.752 ±0.061 0.061 ±0.037
CoCSR [54] 0.411±0.034 0.144±0.017 0.284±0.022 0.018±0.015 0.353±0.026 0.130±0.021 0.272±0.024 0.009±0.004
WDeepCSR [13] 0.989±0.086 0.619 ±0.071 1.336 ±0.215 \ 0.980±0.082 0.601 ±0.069 1.175 ±0.202 \
3D U-Net [44] 0.613±0.070 0.333 ±0.050 0.777 ±0.268 \ 0.456±0.014 0.249 ±0.020 0.493 ±0.033 \
SegCSR (Ours) 0.584±0.018 0.323±0.019 0.728±0.041 0.012 ±0.011 0.452±0.012 0.224±0.016 0.465±0.030 0.012 ±0.010BCPSCorticalFlow++ [47] 0.926±0.271 0.729 ±0.035 1.940 ±0.174 1.113 ±0.374 0.892±0.240 0.721 ±0.033 1.877 ±0.148 0.531 ±0.105
cortexODE [31] 0.758±0.081 0.394 ±0.032 0.820 ±0.102 0.121 ±0.060 0.676±0.069 0.346 ±0.029 0.814 ±0.098 0.098 ±0.033
CoCSR [54] 0.575±0.038 0.214±0.022 0.464±0.059 0.060±0.037 0.542±0.038 0.198±0.020 0.446±0.049 0.056±0.030
WDeepCSR [13] 2.672±1.131 1.222 ±0.214 3.101 ±1.209 \ 1.437±0.519 0.426 ±0.049 0.927 ±0.116 \
3D U-Net [44] 1.174±0.312 0.790 ±0.058 2.136 ±1.020 \ 0.687±0.118 0.376 ±0.039 0.788 ±0.063 \
SegCSR (Ours) 0.926±0.070 0.497±0.060 1.287±0.142 0.058 ±0.056 0.875±0.067 0.476±0.050 1.203±0.130 0.054 ±0.055
NeurIPS Paper Checklist 551
1.Claims 552
Question: Do the main claims made in the abstract and introduction accurately reflect the 553
paper’s contributions and scope? 554
Answer: [Yes] 555
Justification: We clearly summarize the contributions in Section 1 Introduction. 556
Guidelines: 557
•The answer NA means that the abstract and introduction do not include the claims 558
made in the paper. 559
•The abstract and/or introduction should clearly state the claims made, including the 560
contributions made in the paper and important assumptions and limitations. A No or 561
NA answer to this question will not be perceived well by the reviewers. 562
•The claims made should match theoretical and experimental results, and reflect how 563
much the results can be expected to generalize to other settings. 564
•It is fine to include aspirational goals as motivation as long as it is clear that these goals 565
are not attained by the paper. 566
2.Limitations 567
Question: Does the paper discuss the limitations of the work performed by the authors? 568
Answer: [Yes] 569
Justification: We discuss the limitations of the work in Section 5 Conclusions. 570
Guidelines: 571
•The answer NA means that the paper has no limitation while the answer No means that 572
the paper has limitations, but those are not discussed in the paper. 573
• The authors are encouraged to create a separate "Limitations" section in their paper. 574
•The paper should point out any strong assumptions and how robust the results are to 575
violations of these assumptions (e.g., independence assumptions, noiseless settings, 576
model well-specification, asymptotic approximations only holding locally). The authors 577
15should reflect on how these assumptions might be violated in practice and what the 578
implications would be. 579
•The authors should reflect on the scope of the claims made, e.g., if the approach was 580
only tested on a few datasets or with a few runs. In general, empirical results often 581
depend on implicit assumptions, which should be articulated. 582
•The authors should reflect on the factors that influence the performance of the approach. 583
For example, a facial recognition algorithm may perform poorly when image resolution 584
is low or images are taken in low lighting. Or a speech-to-text system might not be 585
used reliably to provide closed captions for online lectures because it fails to handle 586
technical jargon. 587
•The authors should discuss the computational efficiency of the proposed algorithms 588
and how they scale with dataset size. 589
•If applicable, the authors should discuss possible limitations of their approach to 590
address problems of privacy and fairness. 591
•While the authors might fear that complete honesty about limitations might be used by 592
reviewers as grounds for rejection, a worse outcome might be that reviewers discover 593
limitations that aren’t acknowledged in the paper. The authors should use their best 594
judgment and recognize that individual actions in favor of transparency play an impor- 595
tant role in developing norms that preserve the integrity of the community. Reviewers 596
will be specifically instructed to not penalize honesty concerning limitations. 597
3.Theory Assumptions and Proofs 598
Question: For each theoretical result, does the paper provide the full set of assumptions and 599
a complete (and correct) proof? 600
Answer: [NA] 601
Justification: This is not a theoretical paper. 602
Guidelines: 603
• The answer NA means that the paper does not include theoretical results. 604
•All the theorems, formulas, and proofs in the paper should be numbered and cross- 605
referenced. 606
•All assumptions should be clearly stated or referenced in the statement of any theorems. 607
•The proofs can either appear in the main paper or the supplemental material, but if 608
they appear in the supplemental material, the authors are encouraged to provide a short 609
proof sketch to provide intuition. 610
•Inversely, any informal proof provided in the core of the paper should be complemented 611
by formal proofs provided in appendix or supplemental material. 612
• Theorems and Lemmas that the proof relies upon should be properly referenced. 613
4.Experimental Result Reproducibility 614
Question: Does the paper fully disclose all the information needed to reproduce the main ex- 615
perimental results of the paper to the extent that it affects the main claims and/or conclusions 616
of the paper (regardless of whether the code and data are provided or not)? 617
Answer: [Yes] 618
Justification: We clearly illustrate the methodology in Section 3, the experimental setups in 619
Section 4.1, and more implementation details in the Supplementary Materials. 620
Guidelines: 621
• The answer NA means that the paper does not include experiments. 622
•If the paper includes experiments, a No answer to this question will not be perceived 623
well by the reviewers: Making the paper reproducible is important, regardless of 624
whether the code and data are provided or not. 625
•If the contribution is a dataset and/or model, the authors should describe the steps taken 626
to make their results reproducible or verifiable. 627
•Depending on the contribution, reproducibility can be accomplished in various ways. 628
For example, if the contribution is a novel architecture, describing the architecture fully 629
might suffice, or if the contribution is a specific model and empirical evaluation, it may 630
16be necessary to either make it possible for others to replicate the model with the same 631
dataset, or provide access to the model. In general. releasing code and data is often 632
one good way to accomplish this, but reproducibility can also be provided via detailed 633
instructions for how to replicate the results, access to a hosted model (e.g., in the case 634
of a large language model), releasing of a model checkpoint, or other means that are 635
appropriate to the research performed. 636
•While NeurIPS does not require releasing code, the conference does require all submis- 637
sions to provide some reasonable avenue for reproducibility, which may depend on the 638
nature of the contribution. For example 639
(a)If the contribution is primarily a new algorithm, the paper should make it clear how 640
to reproduce that algorithm. 641
(b)If the contribution is primarily a new model architecture, the paper should describe 642
the architecture clearly and fully. 643
(c)If the contribution is a new model (e.g., a large language model), then there should 644
either be a way to access this model for reproducing the results or a way to reproduce 645
the model (e.g., with an open-source dataset or instructions for how to construct 646
the dataset). 647
(d)We recognize that reproducibility may be tricky in some cases, in which case 648
authors are welcome to describe the particular way they provide for reproducibility. 649
In the case of closed-source models, it may be that access to the model is limited in 650
some way (e.g., to registered users), but it should be possible for other researchers 651
to have some path to reproducing or verifying the results. 652
5.Open access to data and code 653
Question: Does the paper provide open access to the data and code, with sufficient instruc- 654
tions to faithfully reproduce the main experimental results, as described in supplemental 655
material? 656
Answer: [No] 657
Justification: (1) We used and cited public datasets and gave pre-processing steps in Sec- 658
tion 4.1 and more details in the Supplementary Materials. (2) We provided code links for 659
public baselines in the Supplementary Materials. (3) Code of our proposed method will be 660
made public upon acceptance of the paper. 661
Guidelines: 662
• The answer NA means that paper does not include experiments requiring code. 663
•Please see the NeurIPS code and data submission guidelines ( https://nips.cc/ 664
public/guides/CodeSubmissionPolicy ) for more details. 665
•While we encourage the release of code and data, we understand that this might not be 666
possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not 667
including code, unless this is central to the contribution (e.g., for a new open-source 668
benchmark). 669
•The instructions should contain the exact command and environment needed to run to 670
reproduce the results. See the NeurIPS code and data submission guidelines ( https: 671
//nips.cc/public/guides/CodeSubmissionPolicy ) for more details. 672
•The authors should provide instructions on data access and preparation, including how 673
to access the raw data, preprocessed data, intermediate data, and generated data, etc. 674
•The authors should provide scripts to reproduce all experimental results for the new 675
proposed method and baselines. If only a subset of experiments are reproducible, they 676
should state which ones are omitted from the script and why. 677
•At submission time, to preserve anonymity, the authors should release anonymized 678
versions (if applicable). 679
•Providing as much information as possible in supplemental material (appended to the 680
paper) is recommended, but including URLs to data and code is permitted. 681
6.Experimental Setting/Details 682
Question: Does the paper specify all the training and test details (e.g., data splits, hyper- 683
parameters, how they were chosen, type of optimizer, etc.) necessary to understand the 684
results? 685
17Answer: [Yes] 686
Justification: We specify all the training and test details in Section 4.1 and the Supplementary 687
Materials. 688
Guidelines: 689
• The answer NA means that the paper does not include experiments. 690
•The experimental setting should be presented in the core of the paper to a level of detail 691
that is necessary to appreciate the results and make sense of them. 692
•The full details can be provided either with the code, in appendix, or as supplemental 693
material. 694
7.Experiment Statistical Significance 695
Question: Does the paper report error bars suitably and correctly defined or other appropriate 696
information about the statistical significance of the experiments? 697
Answer: [Yes] 698
Justification: We reported mean and standard deviation of each experimental setting and 699
computed the statistical significance. 700
Guidelines: 701
• The answer NA means that the paper does not include experiments. 702
•The authors should answer "Yes" if the results are accompanied by error bars, confi- 703
dence intervals, or statistical significance tests, at least for the experiments that support 704
the main claims of the paper. 705
•The factors of variability that the error bars are capturing should be clearly stated (for 706
example, train/test split, initialization, random drawing of some parameter, or overall 707
run with given experimental conditions). 708
•The method for calculating the error bars should be explained (closed form formula, 709
call to a library function, bootstrap, etc.) 710
• The assumptions made should be given (e.g., Normally distributed errors). 711
•It should be clear whether the error bar is the standard deviation or the standard error 712
of the mean. 713
•It is OK to report 1-sigma error bars, but one should state it. The authors should 714
preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis 715
of Normality of errors is not verified. 716
•For asymmetric distributions, the authors should be careful not to show in tables or 717
figures symmetric error bars that would yield results that are out of range (e.g. negative 718
error rates). 719
•If error bars are reported in tables or plots, The authors should explain in the text how 720
they were calculated and reference the corresponding figures or tables in the text. 721
8.Experiments Compute Resources 722
Question: For each experiment, does the paper provide sufficient information on the com- 723
puter resources (type of compute workers, memory, time of execution) needed to reproduce 724
the experiments? 725
Answer: [Yes] 726
Justification: We specify the computation resources for training and testing in Section 4.1 727
and more details in the Supplementary Materials. 728
Guidelines: 729
• The answer NA means that the paper does not include experiments. 730
•The paper should indicate the type of compute workers CPU or GPU, internal cluster, 731
or cloud provider, including relevant memory and storage. 732
•The paper should provide the amount of compute required for each of the individual 733
experimental runs as well as estimate the total compute. 734
•The paper should disclose whether the full research project required more compute 735
than the experiments reported in the paper (e.g., preliminary or failed experiments that 736
didn’t make it into the paper). 737
189.Code Of Ethics 738
Question: Does the research conducted in the paper conform, in every respect, with the 739
NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines ? 740
Answer: [Yes] 741
Justification: We review and conform with the NeurIPS Code of Ethics. 742
Guidelines: 743
•The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. 744
•If the authors answer No, they should explain the special circumstances that require a 745
deviation from the Code of Ethics. 746
•The authors should make sure to preserve anonymity (e.g., if there is a special consid- 747
eration due to laws or regulations in their jurisdiction). 748
10.Broader Impacts 749
Question: Does the paper discuss both potential positive societal impacts and negative 750
societal impacts of the work performed? 751
Answer: [Yes] 752
Justification: We discuss the societal impacts of the work in Section 5 Conclusions. 753
Guidelines: 754
• The answer NA means that there is no societal impact of the work performed. 755
•If the authors answer NA or No, they should explain why their work has no societal 756
impact or why the paper does not address societal impact. 757
•Examples of negative societal impacts include potential malicious or unintended uses 758
(e.g., disinformation, generating fake profiles, surveillance), fairness considerations 759
(e.g., deployment of technologies that could make decisions that unfairly impact specific 760
groups), privacy considerations, and security considerations. 761
•The conference expects that many papers will be foundational research and not tied 762
to particular applications, let alone deployments. However, if there is a direct path to 763
any negative applications, the authors should point it out. For example, it is legitimate 764
to point out that an improvement in the quality of generative models could be used to 765
generate deepfakes for disinformation. On the other hand, it is not needed to point out 766
that a generic algorithm for optimizing neural networks could enable people to train 767
models that generate Deepfakes faster. 768
•The authors should consider possible harms that could arise when the technology is 769
being used as intended and functioning correctly, harms that could arise when the 770
technology is being used as intended but gives incorrect results, and harms following 771
from (intentional or unintentional) misuse of the technology. 772
•If there are negative societal impacts, the authors could also discuss possible mitigation 773
strategies (e.g., gated release of models, providing defenses in addition to attacks, 774
mechanisms for monitoring misuse, mechanisms to monitor how a system learns from 775
feedback over time, improving the efficiency and accessibility of ML). 776
11.Safeguards 777
Question: Does the paper describe safeguards that have been put in place for responsible 778
release of data or models that have a high risk for misuse (e.g., pretrained language models, 779
image generators, or scraped datasets)? 780
Answer: [NA] 781
Justification: Our paper poses no such risks. 782
Guidelines: 783
• The answer NA means that the paper poses no such risks. 784
•Released models that have a high risk for misuse or dual-use should be released with 785
necessary safeguards to allow for controlled use of the model, for example by requiring 786
that users adhere to usage guidelines or restrictions to access the model or implementing 787
safety filters. 788
19•Datasets that have been scraped from the Internet could pose safety risks. The authors 789
should describe how they avoided releasing unsafe images. 790
•We recognize that providing effective safeguards is challenging, and many papers do 791
not require this, but we encourage authors to take this into account and make a best 792
faith effort. 793
12.Licenses for existing assets 794
Question: Are the creators or original owners of assets (e.g., code, data, models), used in 795
the paper, properly credited and are the license and terms of use explicitly mentioned and 796
properly respected? 797
Answer: [Yes] 798
Justification: We properly cite relevant baseline methods and datasets. 799
Guidelines: 800
• The answer NA means that the paper does not use existing assets. 801
• The authors should cite the original paper that produced the code package or dataset. 802
•The authors should state which version of the asset is used and, if possible, include a 803
URL. 804
• The name of the license (e.g., CC-BY 4.0) should be included for each asset. 805
•For scraped data from a particular source (e.g., website), the copyright and terms of 806
service of that source should be provided. 807
•If assets are released, the license, copyright information, and terms of use in the 808
package should be provided. For popular datasets, paperswithcode.com/datasets 809
has curated licenses for some datasets. Their licensing guide can help determine the 810
license of a dataset. 811
•For existing datasets that are re-packaged, both the original license and the license of 812
the derived asset (if it has changed) should be provided. 813
•If this information is not available online, the authors are encouraged to reach out to 814
the asset’s creators. 815
13.New Assets 816
Question: Are new assets introduced in the paper well documented and is the documentation 817
provided alongside the assets? 818
Answer: [Yes] 819
Justification: We communicate the details of the dataset/code/model in our main paper and 820
Supplementary Materials. We will make code and model public upon the acceptance of the 821
paper. 822
Guidelines: 823
• The answer NA means that the paper does not release new assets. 824
•Researchers should communicate the details of the dataset/code/model as part of their 825
submissions via structured templates. This includes details about training, license, 826
limitations, etc. 827
•The paper should discuss whether and how consent was obtained from people whose 828
asset is used. 829
•At submission time, remember to anonymize your assets (if applicable). You can either 830
create an anonymized URL or include an anonymized zip file. 831
14.Crowdsourcing and Research with Human Subjects 832
Question: For crowdsourcing experiments and research with human subjects, does the paper 833
include the full text of instructions given to participants and screenshots, if applicable, as 834
well as details about compensation (if any)? 835
Answer: [NA] 836
Justification: Our paper does not involve crowdsourcing nor research with human subjects. 837
Guidelines: 838
20•The answer NA means that the paper does not involve crowdsourcing nor research with 839
human subjects. 840
•Including this information in the supplemental material is fine, but if the main contribu- 841
tion of the paper involves human subjects, then as much detail as possible should be 842
included in the main paper. 843
•According to the NeurIPS Code of Ethics, workers involved in data collection, curation, 844
or other labor should be paid at least the minimum wage in the country of the data 845
collector. 846
15.Institutional Review Board (IRB) Approvals or Equivalent for Research with Human 847
Subjects 848
Question: Does the paper describe potential risks incurred by study participants, whether 849
such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) 850
approvals (or an equivalent approval/review based on the requirements of your country or 851
institution) were obtained? 852
Answer: [NA] 853
Justification: Our paper does not involve crowdsourcing nor research with human subjects. 854
Guidelines: 855
•The answer NA means that the paper does not involve crowdsourcing nor research with 856
human subjects. 857
•Depending on the country in which research is conducted, IRB approval (or equivalent) 858
may be required for any human subjects research. If you obtained IRB approval, you 859
should clearly state this in the paper. 860
•We recognize that the procedures for this may vary significantly between institutions 861
and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the 862
guidelines for their institution. 863
•For initial submissions, do not include any information that would break anonymity (if 864
applicable), such as the institution conducting the review. 865
21