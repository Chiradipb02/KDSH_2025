A Primal-Dual-Assisted Penalty Approach to Bilevel
Optimization with Coupled Constraints
Liuyuan Jiang†, Quan Xiao†, Victor M. Tenorio⋆, Fernando Real-Rojas⋆
Antonio G. Marques⋆, Tianyi Chen†
†Rensselaer Polytechnic Institute, Troy, NY , United States
⋆King Juan Carlos University, Madrid, Spain
{jiangl7, xiaoq5, chent18 }@rpi.edu
{victor.tenorio, antonio.garcia.marques }@urjc.es ;f.real.2018@alumnos.urjc.es
Abstract
Interest in bilevel optimization has grown in recent years, partially due to its appli-
cations to tackle challenging machine-learning problems. Several exciting recent
works have been centered around developing efficient gradient-based algorithms
that can solve bilevel optimization problems with provable guarantees. However,
the existing literature mainly focuses on bilevel problems either without constraints,
or featuring only simple constraints that do not couple variables across the upper
and lower-levels, excluding a range of complex applications. Our paper studies this
challenging but less explored scenario and develops a (fully) first-order algorithm,
which we term BLOCC , to tackle BiLevel Optimization problems with Coupled
Constraints. We establish rigorous convergence theory for the proposed algorithm
and demonstrate its effectiveness on two well-known real-world applications -
hyperparameter selection in support vector machine (SVM) and infrastructure
planning in transportation networks using the real data from the city of Seville.
1 Introduction
Bilevel optimization (BLO) approaches are pertinent in various machine learning problems, including
hyperparameter optimization [ 49,24], meta-learning [ 22], and reinforcement learning [ 67,63].
Moreover, the ability to handle BLO with constraints is particularly important, as these constraints
appear in applications such as pricing [ 15], transportation [ 50,1], and kernelized SVM [ 30]. Although
there is extensive research on BLO problems without constraints or with uncoupled constraints
[31,12,39,42,62], solutions for BLO problems with coupled constraints (CCs) remain limited;
see details in Table 1. However, it is of particular interest to investigate BLO with lower-level CCs.
Taking infrastructure planning in a transportation network as an example, the lower-level seeks to
optimize a utility constrained by the upper-level parameter, network configuration.
Motivated by this, we consider the coupled-constrained BLO problem in the following form
min
x∈Xf(x, y∗
g(x)) (1a)
s.t. y∗
g(x) := arg min
y∈Y(x)g(x, y)with Y(x) :={y∈ Y:gc(x, y)≤0} (1b)
where f:Rdx×Rdy→Ris the upper-level objective, g:Rdx×Rdy→Ris the lower-level
The work was supported by NSF project 2412486, NSF SCALE-MoDL project 2401297, NSF CAREER
project 2047177, Cisco Research Award, Amazon Research Award, the IBM-Rensselaer Future of Computing
Research Collaboration, and the Comunidad de Madrid (via URJC grants F840 and F978).
38th Conference on Neural Information Processing Systems (NeurIPS 2024).objective which is strongly convex, gc(x, y) :Rdx×Rdy→Rdcdefines the lower-level CCs, and
X ⊆Rdx,Y ⊆Rdyare the domain of xandythat are easy to project, such as the Euclidean ball.
The challenge in solving (1)arises from the coupling of the upper and lower-level problems. Prior
work addressed this by starting with the unconstrained BLO problem, using implicit gradient descent
(IGD) methods [ 27,31,34,12,13,40,61,43,66] and penalty-based methods [ 45,44,61,41,42].
To solve BLO with CCs, AiPOD [ 71] and GAM [ 72] investigated the IGD method under different
constraint settings. However, AiPOD only considered equality constraints, and GAM lacked finite-
time convergence guarantees. Leveraging a penalty reformulation, [ 75] developed a Hessian-free
method with finite-time convergence. However, a key algorithm step in [ 75] is a joint projection of
the current iterate (x, y)onto the coupled constraint set. This projection, required at each iteration,
becomes particularly challenging when gc(x, y)is not jointly convex and can be computationally
expensive for large-scale problems with a high number of variables ( dx, dy) or constraints ( dc).
To this end, this paper aims to address the following question
Can we develop an efficient algorithm that bypasses joint projections on gc(x, y)and quickly solves
the BLO problem with coupled inequality constraints in (1)?
We address this question affirmatively, focusing on the setting where the lower-level objective, g(x, y),
is strongly convex in y, and the constraints gc(x, y)are convex in y. To avoid implementing a joint
projection, we put forth a novel single-level primal-dual-assisted penalty reformulation that decouples
xandy. Specifically, with µ∈Rdcdenoting the Lagrange multiplier of (1b), we propose solving
min
x∈XFγ(x) := max
µ∈Rdx
+min
y∈Yf(x, y) +γ(g(x, y)−v(x))| {z }
penalty term+⟨µ, gc(x, y)⟩|{z}
Lagrangian term(2a)
where v(x) := min
y∈Y(x)g(x, y) (2b)
where the penalty constant γcontrols the distance between yandy∗
g(x)by penalizing g(x, y)to its
value function v(x), and the Lagrangian term penalizes the constraint violation of gc(x, y).
However, recognizing the max-min subproblems involved in (2a), it becomes computationally costly
to evaluate the penalty function Fγ(x)and its gradient. To this end, we pose the following question
Can we develop efficient algorithms to solve the max-min subproblem and evaluate ∇Fγ(x)?
We answer this question by proving that this reformulation exhibits several favorable properties,
including smoothness. These properties are critical for designing gradient-based algorithms and
characterizing their performance. However, the presence of the CCs renders the calculation of the
gradient ∇Fγ(x)more challenging than for its unconstrained counterpart [ 62]. Building upon this,
we design a primal-dual gradient method with rigorous convergence guarantees for the BLO with
general inequality CCs, and provide an improved result for the case of gcbeing affine in y.
1.1 Main contributions
In a nutshell, our main contributions are outlined below.
C1) In Section 2, leveraging the Lagrangian duality theorem, we introduce the function Fγ(x)
in(2a)as a penalty-based reformulation of (1), establish the continuity and smoothness of
Fγ(x), and develop a novel way to compute its gradient.
C2) In Section 3, we develop BLOCC, a fully first-order algorithm to tackle BLO problems
with CCs. With ϵbeing the target error for the generalized gradient norm square of Fγ(x),
we establish that the iteration complexity under the generic constraint gc(x, y)in(1b) is
˜O(ϵ−2.5). We establish, for the first time, the linear convergence of a strongly convex-
concave max-min problem with linear interaction and a constrained maximization parameter,
reducing BLOCC’s complexity to ˜O(ϵ−1.5)when the constraint gc(x, y)is affine in y.
C3) In Section 4, we apply our BLOCC algorithm to two real-world applications: SVM model
training and transportation network planning. By comparison with LV-HBA [ 75] and GAM
[72], we demonstrate the algorithm’s effectiveness and its robustness to large-scale problems.
2LL constraint First Order Complexity
BLOCCgc(x, y)≤0convex in yand LICQ holds;✓˜O(ϵ−2.5);
Special case: gc(x, y)affine in y ˜O(ϵ−1.5)
LV-HBA gc(x, y)≤0convex in x×y ✓ O(ϵ−3)
GAM gc(x, y)≤0convex in x×yand LICQ holds ✘ ✘
BVFSM gc(x, y)≤0satisfying other requirements ✓ ✘
AiPOD gc(x, y) =Ay−b(x) = 0 ✘ O(ϵ−1.5)
Table 1: Comparison of our work with LV-HBA [ 75], BVFSM [ 46], AiPOD [ 71], and Gradient
Approximation method (GAM) [ 72]. LL convergence is on metric the squared distance of ytto its
optimal solution, and UL convergence is on squared (generalized) gradient norm.
1.2 Related works
BLO has a long history, dating back to the seminal work of [ 8]. It has inspired a rich body of literature,
e.g., [ 76,68,14,65]. The recent focus on BLO is centered on developing efficient gradient-based
approaches with provable finite-time guarantees.
Methods for BLO without constraints. A cluster of BLO gradient-based approaches gravitates
around the implicit gradient descent (IGD) method [ 55], where the key idea is to approximate
the hypergradient by the implicit function theorem. The finite-time convergence of IGD was first
established in [ 27] for unconstrained strongly-convex lower-level problems. Subsequent works
improved the convergence rates and/or relaxed the assumptions under various settings; see [ 31,34,
12,13,40,61,43,66,73,35,70]. Another cluster of works is based on iterative differentiation (ITD)
[49,23,53,60], which estimates the hypergradient by differentiating the entire iterative algorithm
used to solve the lower-level problem with respect to the upper-level variables. The finite-time
guarantee was first established in [ 28,47,33,6]. Viewing the lower-level problem as a constraint
such as in [64], penalty-based methods have also emerged as a promising approach for BLO. Dated
back to [ 77], this line of works [ 45,51,44,41,62,25,48] reformulated the original BLO as the
single-level problems with various penalty terms and leveraged first-order methods to solve them.
BLO with constraints. While substantial progress has been made for unconstrained BLO, the
analysis for constrained BLO is more limited. Upper-level constraints of the form x∈ X were
considered in [ 31,12]. For the lower-level uncoupled constraint, SIGD [ 39] considered the uncoupled
constraint Ay≤band achieved asymptotic convergence, [ 42,62] employed penalty reformulation
and considered both upper and lower uncoupled constraints. However, the literature on BLO with
CCs is scarce. BVFSM [ 46] conducted a penalty-based method to avoid the calculation of the Hessian,
as IGD methods do. However, only asymptotic convergence was achieved. GAM [ 72] investigated
the IGD method under inequality constraints while failing to provide finite-time convergence results
as well. AiPOD [ 71] also applied IGD and successfully achieved finite-time convergence, but it
only considered equality constraints. LV-HBA [ 75] considered inequality constraints and constructed
a penalty-based reformulation. However, it employed a joint projection of (x, y)onto{X × Y :
gc(x, y)≤0}which is computationally inefficient when there are many constraints or when gc(x, y)
is not jointly convex. After our initial submission, we found a concurrent work [ 74] posted on ArXiv,
which used Lagrange duality theory differently from ours, applying it to construct a new smoothed
penalty term. However, it does not quantify the relationship between the relaxation of this penalty
and the relaxation of lower-level optimality, and it does not guarantee lower-level feasibility. We
summarized prior works on BLO with lower-level CCs in Table 1.
2 Primal-dual Penalty-based Reformulation
In this section, our goal is to construct a primal-dual-assisted penalty reformulation for our BLOCC
problem. The technical challenge comes from finding a suitable penalty function for BLO with CCs.
2.1 The challenges in BLO with coupled constraints
Here, we will elaborate on the two technical challenges of BLO with CCs.
The first challenge associated with the presence of CCs is the difficulty to find the descent di-
rection for x, which involves finding the closed-form expression of the gradient ∇v(x). The ex-
pression without CCs, ∇v(x) =∇xg(x, y∗
g(x))provided in [ 62,42,41,44], is not applicable.
3Figure 1: Calculation of
∇v(x). The blue line is v(x),
the the yellow dashed line is
calculated by the formulation
given in [ 62,41], while red
dashed line is derived by our
BLOCC. It can be seen that
∇v(x)without the Lagrange
multiplier is very biased from
the true gradient.For example, when g(x, y) = ( y−2x)2andgc(x, y) = 3 x−y,
the optimal lower-level solution is y∗
g(x) = 3 xand thus, v(x) =x2
with∇v(x) = 2 x. However, ∇xg(x, y∗
g(x)) =−4x̸=∇v(x).
The closed form gradient for BLO with CCs should be (8), which
considers a Lagrange term that will be illustrated later in this paper.
In Figure 1, we present the gradient ∇v(x)without the Lagrange
multiplier in [ 62,42,41,44] and ours with the Lagrange term. In
this example, the gradient without the Lagrange term leads to the
opposite direction to the true gradient.
The second challenge associated with the presence of CCs is the
difficulty of performing the joint projection. If we directly extend
the penalty reformulation in [ 62,41], we could treat the coupling
constraint set Y(x)as a joint constraint {(x, y) :gc(x, y)≤0},
and employ a joint projection of (x, y)to ensure the feasibility.
However, this can be computationally inefficient when the problem
is large-scale, i.e. the number of variables or constraints is large.
The detailed analysis of computational cost can be seen in Appendix
H. Moreover, when gc(x, y)is complex, the projection may not have
a closed form and may not even be well-defined if gc(x, y)is not
jointly convex.
2.2 The Lagrangian duality-based penalty reformulation
Before proceeding, we summarize the assumptions considered as follows.
Assumption 1 (Lipschitz Continuity) .Assume that f,∇f,∇g,gcand∇gc, and are respectively lf,0,
lf,1,lg,1,lgc,0, and lgc,1-Lipschitz jointly over (x, y)∈ X × Y , and gislgx,0-Lipschitz in x∈ X.
Assumption 2 (Convexity in y).For any given x∈ X,g(x, y)andgc(x, y)areαg-strongly convex
and convex in y∈ Y, respectively.
Assumption 3 (Domain Feasibility) .Domain X ⊆RdxandY ⊆Rdyare non-empty, closed, and
convex. For any given x∈ X,Y(x) :={y∈ Y:gc(x, y)≤0}is non-empty.
Assumption 4 (Constraint Qualification) .For any given x∈ X,gcsatisfies the Linear Independence
Constraint Qualification (LICQ) condition for every yYin a neighborhood of y∗
g(x).
The Lipschitz continuity in Assumption 1 and the strong convexity of goveryin Assumption 2 are
conventional [ 27,31,41,71,35,13]. Moreover, we only require gc(x, y)to be convex in yrather
than: i) jointly convex in (x, y)as in [ 75], or ii) linear as in [ 39,71]. Assumption 3 pertains to the
convexity and closeness of the domain, which is also conventional, and Assumption 4 is a standard
constraint qualification condition.
To build a penalty reformulation for BLO with lower-level CCs, the first challenge is to find a penalty
that regulates ∥y−y∗
g(x)∥. In the following lemma, we show that g(x, y)−v(x)is a good choice.
Lemma 1. Suppose that Assumptions 2-4 hold and v(x)is defined as in (2b). Then, it holds that
c1)g(x, y)−v(x)≥α′
g
2∥y−y∗
g(x)∥2, for some α′
g>0, for all y∈ Y(x); and
c2)g(x, y) =v(x)if and only if y=y∗
g(x), for all y∈ Y(x).
The technical challenge of proving this lemma lies in showing the quadratic growth property as in c1)
of Lemma 1. For BLO without the CCs, this naturally holds as the lower-level objective g(x, y)is
strongly convex in y. For BLO with CCs, one needs to use the Lagrangian duality theorem. The full
proof of Lemma 1 is given in Appendix B.1, where the key challenge is to show the invariance of the
modulus of strong convexity in the Lagrangian reformulated lower-level objective.
With γdenoting a penalty constant, we consider the following penalty reformulation:
min
(x,y)∈{X×Y :gc(x,y)≤0}f(x, y) +γ(g(x, y)−v(x)) (3)
where the penalty term confines the squared Euclidean distance from ytoy∗
g(x). Furthermore, to
avoid projecting (x, y)onto the {X ×Y :gc(x, y)≤0}, we propose the primal-dual-assisted penalty
4reformulation, which was defined in (2). The approximate equivalence of the reformulation (2)to the
original BLO problem (1) is established in the following theorem.
Theorem 1 (Equivalence) .Suppose that fis Lipschitz in yand∇fislf,1-Lipschitz in (x, y)in
Assumption 1 hold, and Assumptions 2-4 hold. Then, solving the ϵ-approximation problem of (1):
min
(x,y)∈{X×Y :gc(x,y)≤0}f(x, y)s.t.∥y−y∗
g(x)∥2≤ϵ, (4)
is equivalent to solve the primal-dual penalty reformulation in (2)withγ=O(ϵ−0.5)andγ >lf,1
αg.
The detailed proof is provided in Appendix B.2. By setting γ=O(ϵ−0.5), we effectively state the
equivalence between the penalty reformulation in (3)and the approximated original problem (4). We
can then decouple the joint minimization on (x, y)to a min-min problem on xandgcconstrained
y. For the inner minimization problem in y, we choose γin a way that γαg−lf,1>0holds. This
ensures the objective in (2a)being strongly convex in y, aslf,1-smoothness ensures a lower bound
for negative curvature of f(x, y). Furthermore, the convexity of gc(x, y)inyvalidates the strong
duality theorem in [59, 32], thereby enabling the max-min primal-dual reformulation in (2).
2.3 Smoothness of the penalty reformulation
To evaluate Fγ(x)defined in (2a), we can find the solution to the inner max-min problem:
(µ∗
F(x), y∗
F(x)) := arg max
µ∈Rdx
+min
y∈Yf(x, y) +γ(g(x, y)−v(x)) +⟨µ, gc(x, y)⟩| {z }
=:LF(µ,y;x). (5)
The uniqueness of y∗
F(x)andµ∗
F(x)is guaranteed under Assumptions 2 and 4 (see Lemma 5 in
Appendix A). Therefore, Fγ(x)in (2a) can be evaluated using the unique optimal solutions by
Fγ(x) =LF(µ∗
F(x), y∗
F(x);x). (6)
Similarly, we can evaluate v(x) =Lg(µ∗
g(x), y∗
g(x);x), where
(µ∗
g(x), y∗
g(x)) := arg max
µ∈Rdx
+min
y∈Yg(x, y) +⟨µ, gc(x, y)⟩| {z }
=:Lg(µ,y;x). (7)
The penalty reformulation Fγ(x)can hardly be convex, as −v(x)may be concave, even when
g(x, y) =g(y)andgc(x, y) =A⊤y−x; see Lemma 4.24 in [ 59]. Instead, in the subsequent lemma,
we not only show that v(x)is differentiable, but also provide a closed-form expression of ∇v(x).
Lemma 2 (Danskin-like theorem for v(x)).Suppose that Assumptions 1–4 hold, and let Bg<∞be
a constant such that ∥µ∗
g(x)∥< B gfor all x∈ X. Then, it holds that
1.y∗
g(x)andµ∗
g(x)defined in (7)areLg-Lipschitz for some finite constant Lg≥0.
2.v(x)defined in (2b) islv,1-smooth where lv,1≤(lg,1+Bglgc,1)(1 + Lg) +lgc,0Lgand
∇v(x) =∇xg(x, y∗
g(x)) +⟨µ∗
g(x),∇xgc(x, y∗
g(x))⟩. (8)
The assumption of the existence of the upper bound for the Lagrange multiplier is a consequence of
the LICQ condition [ 69, Theorem 1]. This assumption is mild and traditional [ 75]. Finding ∇v(x)is
crucial for the design of a gradient-based method to solve minx∈XFγ(x). Leveraging Lemma 2, the
gradient ∇Fγ(x)can be obtained by the next lemma.
Lemma 3 (Danskin-like theorem for Fγ(x)).Suppose that the conditions in Lemma 2 hold. Moreover,
assume that γ >lf,1
αg, and there exist BF<∞such that ∥µ∗
F(x)∥<BF,∀x∈ X. Then, it holds that
1.y∗
F(x)andµ∗
F(x)defined in (5)areLF-Lipschitz for some constant LF≥0.
2.Fγ(x)islF,1-smooth with lF,1≤(lf,1+γlg,1+BFlgc,1)(1 + LF) +γlv,1+lfc,0LF, and
∇Fγ(x) =∇xf(x, y∗
F(x)) +γ(∇xg(x, y∗
F(x))− ∇v(x)) +⟨µ∗
F(x),∇xgc(x, y∗
F(x))⟩.(9)
The proof of Lemmas 2 and 3 is provided in Appendix C. Similar to [ 62], the Danskin-like theorems
in Lemmas 2 and 3 rely on the Lipschitzness of the solutions in (5)and(7). Different from BLO
without CCs [62], the results here also hinge on the Lagrange multipliers µ∗
g(x)andµ∗
F(x).
53 Main Results
We will first introduce an algorithm tailored for BiLevel Optimization problems with inequality
Coupled Constraints, and present its convergence analysis. In Section 3.2, we will propose a
primal-dual solver for the inner max-min problems and characterize the overall convergence.
3.1 BLOCC algorithm
Algorithm 1 Meta algorithm: BLOCC
1:inputs: initial points x0,yg,0,µg,0,yF,0,
µF,0; stepsize η,ηg,ηF; counters Tg,
TF.
2:fort= 0,1, . . . , T do
3: (yTg
g,t, µTg
g,t) =MaxMin (Tg, Tg
y)
4: (yTF
F,t, µTF
F,t) =MaxMin (TF, TF
y)
5: update xt+1via (10)
▷withgF,tin (13)
6:end for
7:outputs: (xT, yTF
F,T)AsFγ(x)features differentiability and smoothness,
we can apply a projected gradient descent (PGD)-
based method to solve minx∈XFγ(x). At iteration
t, update
xt+1= ProjX(xt−ηgF,t) (10)
with stepsize ηandgF,tas an estimate of ∇Fγ(xt).
In the previous section, we have obtained the closed-
form expressions of ∇v(x)in(8)and∇Fγ(x)in(9).
Evaluating the closed-form expression requires find-
ing(y∗
g(xt), µ∗
g(xt))and(y∗
F(xt), µ∗
F(xt)), the solu-
tions to the max-min problem Lg(µ, y;x)in(7)and
LF(µ, y;x)in (5) respectively.
Given xt∈ X , we can use some minmax optimization solvers with Tgiterations on (7)andTF
iterations on (5) to find an ϵg-solution (yTg
g,t, µTg
g,t)and an ϵF-solution (yTF
F,t, µTF
F,t)satisfying
∥(yTg
g,t, µTg
g,t)−(y∗
g(xt), µ∗
g(xt))∥2=O(ϵg);∥(yTF
F,t, µTF
F,t)−(y∗
F(xt), µ∗
F(xt))∥2=O(ϵF)(11)
for target estimation accuracy ϵg, ϵF>0. Such an effective minmax optimization solver will be
introduced in the following Section 3.2. In this way, ∇v(xt)in (9) can be estimated as
gv,t=∇xg(xt, yTg
g,t) +⟨µTg
g,t,∇xgc(xt, yTg
g,t)⟩. (12)
Leveraging gv,t, the gradient ∇Fγ(x)can be estimated via (8) as
gF,t=∇xf(xt, yTF
F,t) +γ
∇xg(xt, yTF
F,t)−gv,t
+⟨µTF
F,∇xgc(x, yTF
F,t)⟩. (13)
We summarize the oracle for finding minFγ(x)as in Algorithm 1, which we term BLOCC, an
algorithm designed for BiLevel Optimization with Coupled Constraints. Notably, our BLOCC
algorithm can be seamlessly integrated with any MaxMin Solver (or min-max solver) that converges
to the optimal solutions of the max-min subproblems by achieving (11). In the following, we present
the convergence result of it allowing estimation error ϵg, ϵF>0from the MaxMin Solver.
Theorem 2. Suppose that the assumptions in Lemma 3 hold. Run Algorithm 1 with some effective
inner MaxMin solver to find (yTg
g,t, µTg
g,t)and(yTF
F,t, µTF
F,t)respectively O(ϵg)andO(ϵF)-optimal in
squared distance as in (11). Setη≤1
lF,1with some lF,1defined in Lemma 3. It then holds that
1
TT−1X
t=0∥Gη(xt)∥2:=1
Tη2T−1X
t=0∥(xt+1−xt)∥2=O(γT−1+γ2ϵF+γ2ϵg). (14)
The proof is available in Appendix D.1. Using the projected gradient Gη=η−1(xt+1−xt)as the
convergence metric for constrained optimization problems is standard [ 26]. The term O(γ2ϵF+γ2ϵg)
arises from estimation errors using specific MaxMin Solver. Although the inner oracle can be any
one that achieves (11), we value the computational effectiveness and therefore present a particular
efficient solver Algorithm 2 in the following section.
3.2 MaxMin Solver for the BLO with inequality CCs
In this section, we specify the MaxMin solver in Algorithm 1. By viewing Lg(µ, y;x)in(7)and
LF(µ, y;x)in (5) as L(µ, y)for fixed given x∈ X, we consider the following max-min problem
max
µ∈Rdc
+min
y∈YL(µ, y) (15)
6Algorithm 2 Subroutine on MaxMin (T, Ty)
1:inputs: initial points y0,µ0; stepsizes η1, η2;
counters T, Ty.Blue part is the version with
acceleration; and red part is without.
2:fort= 0, . . . , T −1do
3: update µt+1
2via (17) orµt+1
2=µt
4: forty= 0, . . . , T y−1do
5: update yt,ty+1via (18) ▷setyt,0=yt
6: end for
7: update µt+1via (19) ▷setyt+1=yt,Ty
8:end for
9:outputs: (yT, µT)which is concave (linear) in µand strongly
convex in y. We can evaluate the dual function
ofL(µ, y)defined below by finding y∗
µ(µ).
D(µ) := min
y∈YL(µ, y) =L(µ, y∗
µ(µ))(16)
where y∗
µ(µ) := arg min
y∈YL(µ, y).
According to Danskin’s theorem, we have
∇D(µ) =∇µL(µ, y∗
µ(µ)). Taking either
Lg(µ, y;x)orLF(µ, y;x)asL(µ, y)for
given x∈ X,D(µ)defined as (16) exhibits
favorable properties namely smoothness and
concavity, with details illustrated in Lemma
10 in Appendix D.2. We can, therefore, ap-
ply accelerated gradient methods designed for
smooth and convex functions such as [52, 4].
At each iteration t, we first perform a momentum-based update step to update µt+1
2as
µt+1
2=µt+t−1
t+ 2(µt−µt−1),withµ−1=µ0. (17)
To evaluate ∇D(µt+1
2) =∇µL(µt+1
2, y∗
µ(µt+1
2), with an arbitrary small target accuracy ϵ >0, we
can run Ty=O(ln 
ϵ−1
)PGD steps on L(µt+1
2, y)inyvia
yt,ty+1= ProjY
yt,ty−η1∇yL(µt+1
2, yt,ty)
. (18)
Defining the output after Tyiterations as yt+1, since strongly convexity of L(µ,·)ensures that PGD
converges linearly [9, Theorem 3.10], it implies that ∥yt+1−y∗
µ(µt+1
2)∥=O(ϵ). We can conduct
µt+1= ProjRdc
+(µt+1
2+η2∇µL(µt+1
2, yt+1)). (19)
We summarize this oracle in Algorithm 2 based on an accelerated method [ 52]. When we skip the
momentum update, i.e. setting µt+1
2=µt, it is a simple PGD method on D(µ).
However, for a convex function −D(µ), the standard results only provide convergence of the function
value, i.e. maxµ∈Rdc
+D(µ)−D(µt)t→∞−→0. To establish the convergence of ∥µTg
g,t−µ∗
g(xt)∥and
∥µTF
F,t−µ∗
F(xt)∥, we define the dual functions associated with inner problems (7) and (5) as
Dg(µ) = min
y∈YLg(µ, y;x)and DF(µ) = min
y∈YLF(µ, y;x) (20)
and make the following curvature assumption near the optimum.
Assumption 5. There exist δg, δF>0andCδg, CδF>0such that
⟨−∇Dg(µ) +∇Dg(µ∗
g(x)), µ−µ∗
g(x)⟩ ≥Cδg∥µ−µ∗
g(x)∥2,∀µ∈ B(µ∗
g(x);δg), (21a)
⟨−∇DF(µ) +∇DF(µ∗
F(x)), µ−µ∗
F(x)⟩ ≥CδF∥µ−µ∗
F(x)∥2,∀µ∈ B(µ∗
F(x);δF).(21b)
It is worth noting that ⟨−∇Dg(µ) +∇Dg(µ∗
g(x)), µ−µ∗
g(x)⟩ ≥0holds for all µdue to concavity
and in a neighborhood of the optimal, the equality only happens at the optimal due to the uniqueness
ofµ∗
g(x). The same argument applies to DFdue to the concavity of the dual functions. Therefore,
Assumption 5 essentially asserts a positive lower bound on the curvature of the left-hand side term,
which is mild as it only applies to the neighborhood of the optima µ∗
g(x)andµ∗
F(x). It is also weaker
than the local strong concavity or global restricted secant inequality (RSI) conditions.
By choosing Algorithm 2 with acceleration as the MaxMin solver, we provide the convergence
analysis of Algorithm 1 next, the proof of which can be found in Appendix D.2.
Theorem 3. Suppose that Assumptions 1–5 and the conditions in Theorem 2 hold. Let γ >lf,1
αg,
ϵg≤Cδg
2δgandϵF≤CδF
2δF. If we choose Algorithm 2 with acceleration as the inner loop and
input Tg=O(ϵ−0.5
g), TF=O(ϵ−0.5
F), and Tg
y=O(ln 
ϵ−1
g
), TF
y=O(ln 
ϵ−1
F
)with proper
constant stepsizes in Remark 3, then the iterates generated by the Algorithm 1 satisfy (11):
∥(yTg
g,t, µTg
g,t)−(y∗
g(xt), µ∗
g(xt))∥2=O(ϵg);∥(yTF
F,t, µTF
F,t)−(y∗
F(xt), µ∗
F(xt))∥2=O(ϵF).
7Theorem 3 concludes the O(ϵ−0.5
g)complexity for achieving ϵg-optimal solutions for the constrained
concave-strongly-convex problem maxµ∈Rdx
+miny∈YL(µ, y), and so as for ϵF. For solving an ϵ-
approximation problem of BLO defined in (4), we solve minx∈XFγ(x)withγ=O(ϵ−0.5)according
to Theorem 1. In this way, to achieve1
TPT−1
t=0∥Gη(xt)∥2=O(γT−1+γ2ϵF+γ2ϵg)≤ϵby
(14), we need ϵg, ϵF=O(ϵ2), i.e. complexity ˜O(ϵ−1)for the MaxMin solver in Algorithm 2, and
T=O(γϵ−1) =O(ϵ−1.5)for the number of iteration in BLOCC (Algorithm 1). Therefore, the
overall complexity is ˜O(ϵ−2.5), where ˜Oomits the lnterms.
3.3 Special case of the MaxMin Solver: gc(x, y)being affine in yandY=Rdy
In this section, we investigate a special case of BLO with CCs where Assumption 5 automatically
holds. Specifically, we focus on the case where gcis affine in yandY=Rdy, i.e.
gc(x, y) =gc
1(x)⊤y−gc
2(x). (22)
In this case, fixing x, taking Lg(µ, y;x)in (7) and LF(µ, y;x)asL(µ, y), (16) gives
Dg(µ) = min
y∈Rdy−⟨gc
2(x), µ⟩+⟨y, gc
1(x)µ⟩+g(x, y)and (23a)
DF(µ) = min
y∈Rdy−⟨gc
2(x), µ⟩+⟨y, gc
1(x)µ⟩+f(x, y) +γ(g(x, y)−v(x)). (23b)
When gc
1(x)is of full column rank, both Dg(µ)andDF(µ)are strongly concave according to Lemma
13 in Appendix so that Assumption 5 holds globally. Moreover, when applying PGD on −Dg(µ)
and−DF(µ), strongly convexity guarantees linear convergence (Theorem 3.10 in [ 9]). Therefore,
even without acceleration, Algorithm 2 with Tysufficiently large performs PGD on −D(µ)and it
converges linearly up to inner loop accuracy. Moreover, PGD on L(µ, y)inyalso converges linearly.
This motivates us to implement a single-loop version ( Ty= 1) of Algorithm 2.
When both yandµare unconstrained, the analysis has been established in [ 19]. However, as µ
is constrained to Rdc
+in the Lagrangian formulation for inequality constraints, the convergence
analysis in [ 19] is not applicable, and the extension is nontrivial due to the non-differentiability
of the projection. We address this technical challenge by treating Rdc
+as an inequality constraint
and reformulating it as an unconstrained problem using Lagrange duality theory. This approach
demonstrates that a single-loop Ty= 1update in Algorithm 2, without acceleration, achieves linear
convergence for the max-min problem (15). The detailed proof is provided in Appendix D.3.
Thus, by selecting the single-loop version ( Ty= 1) of Algorithm 2 without acceleration as the
MaxMin solver in Algorithm 1, we establish the following theorem with proof available in Appendix
D.3.
Theorem 4 (Inner linear convergence) .Consider BLO with Y=Rdyandgc(x, y)defined in (22).
Suppose Assumptions 1–4 and the conditions in Theorem 2 hold. Suppose for any x∈ X , there
exist constants sminandsmaxsuch that 0< smin≤σmin(gc
1(x))≤σmax(gc
1(x))≤smax<∞.
Letγ >lf,1
αg. If we choose Algorithm 2 without acceleration as the inner loop and input Tg=
O(ln 
ϵ−1
g
), TF=O(ln 
ϵ−1
F
), andTg
y=TF
y= 1with proper constant stepsizes in Remark 4, then
the iterates generated by Algorithm 1 satisfy (11):
∥(yTg
g,t, µTg
g,t)−(y∗
g(xt), µ∗
g(xt))∥2=O(ϵg);∥(yTF
F,t, µTF
F,t)−(y∗
F(xt), µ∗
F(xt))∥2=O(ϵF).
Theorem 4 establishes, for the first time, the linear convergence of a strongly convex-concave max-
min problem with a constrained maximization parameter. Similar to the previous analysis, we choose
γ=O(ϵ−0.5)to solve the equivalent (2a) toϵ-approximation problem of BLO (4). To achieve
1
TPT−1
t=0∥Gη(xt)∥2≤ϵ, the number of iteration in BLOCC T=O(γϵ−1) =O(ϵ−1.5)by(14). As
the inner MaxMin solver convergences linearly, the overall complexity is ˜O(ϵ−1.5)where ˜Oomits
thelnterms. We summarized the overall iteration complexity of our BLOCC algorithm in different
settings in Table 1.
4 Numerical Experiments
This section reports the results of numerical experiments for three different problems: a toy example
used to validate our method, an SVM training application, and a network design problem in both
8synthetic and real-world transportation scenarios. We provide sensitivity analysis and insights for
hyper-parameter choices in Appendix G.1. In the two real-world experiments, we compare the
proposed algorithm with two baselines, LV-HBA [ 75] and GAM [ 72]. The code is available at
https://github.com/Liuyuan999/Penalty Based Lagrangian Bilevel.
4.1 Toy example
y0
1
2
3x
0123f(x,y)
2468f(x,y)|y=x
(xT,yTg
g,T,f(xT,yTg
g,T))
Figure 2: 3-D plot of the upper-
level objective f(x, y)of the toy
example, with the line f(x, y)|y=x
shown in dashed red and the con-
vergence points marked as red dots.Consider the BLO problem with an inequality coupled con-
straint Y(x) :={y∈ Y:y−x≤0}, given by
min
x∈[0,3]f(x, y∗
g(x)) =e−y∗
g(x)+2
2 + cos(6 x)+1
2ln 
(4x−2)2+ 1
with y∗
g(x)∈argmin
y∈Y(x)g(x, y) = (y−2x)2. (24)
Problem (24) satisfies all assumptions for Theorem 2 and
Theorem 4. The lower-level problem is strongly convex and
y∗
g(x) =x. Therefore, the BLO problem with inequality con-
straint in (24) reduces to minx∈[0,3]f(x, y)|y=x. In Figure 2,
we plot the dashed line as the intersected line of the surface
f(x, y)and the plane f(x, y∗
g(x)), and the red points as the
converged points by running BLOCC with γ= 5 and with
200 different initialization values. It can be seen that BLOCC
consistently finds the local minima, verifying the effectiveness.
4.2 Hyperparameter optimization for SVM
Methods diabetes fourclass
BLOCC 0.767±0.039 0.761±0.014
(Ours) (1.729±0.529)(1.922±0.108)
LV-HBA0.765±0.039 0.748±0.060
(2.899±1.378) (2.404±0.795)
GAM0.721±0.047 0.715±0.056
(8.752±4.736) (13.481±0.970)
Table 2: Numerical results on the training outcome
of our BLOCC in comparison with LV-HBA [ 75] and
GAM [ 72]. The first row represents accuracy mean ±
standard deviation, and the second row between brack-
ets represents the running time until the upper-level
objective’s update is smaller than 1e−5.We test the performance of our algorithm
BLOCC with γ= 12 when training a linear
SVM model on the diabetes [ 20] and four-
class datasets [ 29]. The model is trained
via the BLO formulation (1)with inequal-
ity CCs; see the details in Appendix E.
We compared performance with two base-
lines, LV-HBA [ 75] and GAM [ 72], as they
are the only existing algorithms address-
ing coupled constraints and experimentally
evaluated on SVM problems in their respec-
tive papers.
Table 2 shows that the model trained by
our BLOCC algorithm outperforms that of
GAM [ 72] significantly and is of a similar level as that of LV-HBA [ 75]. We present some of the
performance plots for the diabetes dataset as in Figure 3. Looking into the test accuracy (left), our
algorithm achieves more than 0.76 accuracy in the first 2 iterations, which is significantly better than
the other ones. For the upper-level objective (middle), in the first few iterations, the loss decreases
significantly under all algorithms, in which our BLOCC achieves the lowest results. Moreover, in
Figure 3 (right), the lower-level optimum for LV-HBA was not attained until the very end. This
indicates that the decrease of upper loss between 0-40 iterations in the middle figure may be due to
the suboptimality of lower-level variables. For our BLOCC and GAM, the lower-level minimum is
attained as lower-level objective g≥0in this case.
4.3 Transportation network design problem
BLO is particularly relevant in transportation, where network planning must consider different time
horizons and actors. Those problems are large-scale with a large number of upper- and lower-level
variables and CCs, challenging the use of traditional BLO techniques, which involve expensive
calculations of second order information. As a result, our final experiment considers a network design
problem, where we act as an operator whose profit is modeled as the upper-level objective that is
determined by the passengers’ behavior, modeled in the lower-level. We considered three networks:
90 25 50 75
Iteration Count0.600.650.700.750.80AccuracyTest Accuracy
BLOCC
LV-HBA
GAM
0 25 50 75
Iteration Count1.52.02.53.0LossValidation Loss (Upper Level)
BLOCC
LV-HBA
GAM
0 25 50 75
Iteration Count024LossLower Level Objective
BLOCC
LV-HBA
GAMFigure 3: Test accuracy (left), upper loss f(x, y)(middle), and lower loss g(x, y)(right) for the SVM
on the diabetes dataset. The experiments are executed for 50 different random train-validation-test
splits, with the bold line representing the mean, and the shaded regions being the standard deviation.
NN = 3, NV = 48 NN = 9, NV = 2,262 NN = 26, NV = 49,216
NC = 24, NZ = 126 NC = 678, NZ = 6,222 NC = 13,336, NZ = 129,256
Methods Runtime (s) UL utility Runtime (s) UL utility Runtime (s) UL utility
LV-HBA 3.51e2 1.53 / / / /
BLOCC (Ours)- γ= 2 2.02e1 1.07 7.27e2 8.09 6.82e4 98.40
BLOCC (Ours)- γ= 3 2.00e1 1.69 8.50e2 10.37 6.42e4 111.39
BLOCC (Ours)- γ= 4 2.01e1 1.71 8.68e2 11.04 6.70e4 138.78
Table 3: Results of the transportation experiment, both in terms of running time (Runtime) and
convergenced upper-level objective value (UL utility, larger there better), with stepsize η= 1.6e−4.
We use ”/” for algorithms that cannot converge within 24 hours of execution. NN (Number of Nodes)
is the number of stations in the network. Analogously, NV (Number of Variables), NC (Number of
Constraints), and NNZ (Number of non-zero elements) are the number of optimization variables,
constraints, and non-zero elements of the constraints matrix, respectively.
two synthetic networks of 3 and 9 nodes, respectively, and a real-world network of 26 nodes in the
city of Seville, Spain. Further details about the formulation and the experiment can be found in
Appendix F.
In this experiment, we only compare our BLOCC with LV-HBA [ 75] as the sole baseline, which is the
only existing algorithm that addresses both coupled inequality gc(x, y)≤0and domain constraints
Y. GAM [ 72] and BVFSM [ 46] cannot handle lower-level domain constraints as they rely on the
hypergradient of lower-level and require LL stationarity in an unconstrained space. From Table 3, we
can see that LV-HBA failed to work efficiently, especially for large networks. This is mainly because
the increased constraints render the projection step impracticable. Our BLOCC, in contrast, is much
faster, and it successfully converges even with large real-world networks. We provided computational
complexity analysis in Appendix H and we can conclude that our BLOCC is robust to large-scale
problems.
5 Conclusions and Future Work
This paper proposed a novel primal-dual-assisted penalty reformulation for BLO problems with
coupled lower-level constraints, and developed a new first-order method BLOCC to solve the resultant
problem. The non-asymptotic convergence rate of our algorithm is ˜O(ϵ−2.5), tightening to ˜O(ϵ−1.5)
when the lower-level constraints are affine in ywithout any other constraints. Our method achieves
the best-known convergence rate and is projection-free, making it more favorable for large-scale, high-
dimensional, constrained BLO problems. Experiments on SVM model training and transportation
network planning showcased the effectiveness of our algorithm.
10References
[1]Seyed Mehdi Alizadeh, Patrice Marcotte, and Gilles Savard. Two-stage stochastic bilevel
programming over a transportation network. Transportation Research Part B: Methodological ,
58:92–105, 2013.
[2]Aram V Arutyunov, Evgeniy R Avakov, and Alexey F Izmailov. Directional regularity and
metric regularity. SIAM Journal on Optimization , 18(3):810–833, 2007.
[3]Dominique Az ´e and Jean-Paul Penot. Uniformly convex and uniformly smooth convex functions.
InAnnales de la Facult ´e des sciences de Toulouse: Math ´ematiques , 1995.
[4]Amir Beck and Marc Teboulle. A fast iterative shrinkage-thresholding algorithm for linear
inverse problems. SIAM journal on imaging sciences , 2(1):183–202, 2009.
[5]Moshe E Ben-Akiva and Steven R Lerman. Discrete choice analysis: theory and application to
travel demand , volume 9. MIT press, 1985.
[6]J. Bolte, E. Pauwels, and S. Vaiter. Automatic differentiation of nonsmooth iterative algorithms.
InAdvances in Neural Information Processing Systems , 2022.
[7]J Fr´ed´eric Bonnans and Alexander Shapiro. Perturbation analysis of optimization problems .
Springer Science & Business Media, 2013.
[8]Jerome Bracken and James T McGill. Mathematical programs with optimization problems in
the constraints. Operations Research , 21(1):37–44, 1973.
[9]S´ebastien Bubeck. Convex Optimization: Algorithms and Complexity . Foundations and Trends®
in Machine Learning, 2015.
[10] Luis Cadarso and Angel Marin. Combining robustness and recovery in rapid transit network
design. Transportmetrica A: Transport Science , 12:1–26, 11 2015.
[11] Ennio Cascetta. Transportation systems analysis: models and applications , volume 29. Springer
Science & Business Media, 2009.
[12] Tianyi Chen, Yuejiao Sun, Quan Xiao, and Wotao Yin. A single-timescale method for stochastic
bilevel optimization. In International Conference on Artificial Intelligence and Statistics , virtual,
2022.
[13] Tianyi Chen, Yuejiao Sun, and Wotao Yin. Closing the gap: Tighter analysis of alternating
stochastic gradient methods for bilevel problems. In Advances in Neural Information Processing
Systems , Virtual, 2021.
[14] Beno ˆıt Colson, Patrice Marcotte, and Gilles Savard. An overview of bilevel optimization.
Annals of operations research , 153(1):235–256, 2007.
[15] Jean-Philippe C ˆot´e, Patrice Marcotte, and Gilles Savard. A bilevel modelling approach to pricing
and fare optimisation in the airline industry. Journal of Revenue and Pricing Management ,
2:23–36, 2003.
[16] Olivier Devolder, Fran c ¸ois Glineur, and Yurii Nesterov. First-order methods of smooth convex
optimization with inexact oracle. Mathematical Programming , 146:37–75, 2014.
[17] Asen L Dontchev and R Tyrrell Rockafellar. Implicit functions and solution mappings , volume
543. Springer, 2009.
[18] Dmitriy Drusvyatskiy and Adrian S Lewis. Error bounds, quadratic growth, and linear conver-
gence of proximal methods. Mathematics of Operations Research , 43(3):919–948, 2018.
[19] Simon S Du and Wei Hu. Linear convergence of the primal-dual gradient method for convex-
concave saddle point problems without strong convexity. In The 22nd International Conference
on Artificial Intelligence and Statistics , pages 196–205, 2019.
[20] Dheeru Dua and Casey Graff. Uci machine learning repository, 2017. Accessed: 2024-05-21.
11[21] Laureano Escudero and Susana Mu ˜noz. An approach for solving a modification of the extended
rapid transit network design problem. Top, 17:320–334, 12 2009.
[22] Chelsea Finn, Pieter Abbeel, and Sergey Levine. Model-agnostic meta-learning for fast adapta-
tion of deep networks. In International Conference on Machine Learning , pages 1126–1135,
Sydney, Australia, 2017.
[23] Luca Franceschi, Michele Donini, Paolo Frasconi, and Massimiliano Pontil. Forward and
reverse gradient-based hyperparameter optimization. In International Conference on Machine
Learning , pages 1165–1173, 2017.
[24] Luca Franceschi, Paolo Frasconi, Saverio Salzo, Riccardo Grazzi, and Massimiliano Pontil.
Bilevel programming for hyperparameter optimization and meta-learning. In International
Conference on Machine Learning , Stockholm, Sweden, 2018.
[25] Lucy L Gao, Jane Ye, Haian Yin, Shangzhi Zeng, and Jin Zhang. Value function based
difference-of-convex algorithm for bilevel hyperparameter selection problems. In International
Conference on Machine Learning , pages 7164–7182, Baltimore, MD, 2022.
[26] Saeed Ghadimi, Guanghui Lan, and Hongchao Zhang. Mini-batch stochastic approxima-
tion methods for nonconvex stochastic composite optimization. Mathematical Programming ,
155(1):267–305, 2016.
[27] Saeed Ghadimi and Mengdi Wang. Approximation methods for bilevel programming. arXiv
preprint arXiv:1802.02246 , 2018.
[28] Riccardo Grazzi, Luca Franceschi, Massimiliano Pontil, and Saverio Salzo. On the iteration
complexity of hypergradient computation. In International Conference on Machine Learning ,
pages 3748–3758, virtual, 2020.
[29] Tin Kam Ho and Eugene M Kleinberg. Building projectable classifiers of arbitrary complexity.
InProceedings of 13th International Conference on Pattern Recognition , volume 2, pages
880–885, 1996.
[30] Thomas Hofmann, Bernhard Sch ¨olkopf, and Alexander J Smola. Kernel methods in machine
learning. 2008.
[31] Mingyi Hong, Hoi-To Wai, Zhaoran Wang, and Zhuoran Yang. A two-timescale framework
for bilevel optimization: Complexity analysis and application to actor-critic. SIAM Journal on
Optimization , 33(1), 2023.
[32] Kazufumi Ito and Karl Kunisch. Lagrange Multiplier Approach to Variational Problems and
Applications , volume 15 of Advances in Design and Control . Not specified in the provided
information, 2008. Includes bibliographical references and index.
[33] Kaiyi Ji, Mingrui Liu, Yingbin Liang, and Lei Ying. Will bilevel optimizers benefit from loops.
arXiv preprint arXiv:2205.14224 , 2022.
[34] Kaiyi Ji, Junjie Yang, and Yingbin Liang. Provably faster algorithms for bilevel optimization
and applications to meta-learning. In Advances in Neural Information Processing Systems ,
2020.
[35] Kaiyi Ji, Junjie Yang, and Yingbin Liang. Bilevel optimization: Convergence analysis and
enhanced design. In International Conference on Machine Learning , virtual, 2021.
[36] Sham Kakade, Shai Shalev-Shwartz, Ambuj Tewari, et al. On the duality of strong convexity and
strong smoothness: Learning applications and matrix regularization. Unpublished Manuscript,
http://ttic. uchicago. edu/shai/papers/KakadeShalevTewari09. pdf , 2(1):35, 2009.
[37] Hamed Karimi, Julie Nutini, and Mark Schmidt. Linear convergence of gradient and proximal-
gradient methods under the polyak-łojasiewicz condition. In Machine Learning and Knowledge
Discovery in Databases: European Conference, ECML PKDD 2016, Riva del Garda, Italy,
September 19-23, 2016, Proceedings, Part I 16 , pages 795–811, 2016.
12[38] Narendra Karmarkar. A new polynomial-time algorithm for linear programming. In Proceedings
of the sixteenth annual ACM symposium on Theory of computing , pages 302–311, 1984.
[39] Prashant Khanduri, Ioannis Tsaknakis, Yihua Zhang, Jia Liu, Sijia Liu, Jiawei Zhang, and
Mingyi Hong. Linearly constrained bilevel optimization: A smoothed implicit gradient approach.
InInternational Conference on Machine Learning , pages 16291–16325, 2023.
[40] Prashant Khanduri, Siliang Zeng, Mingyi Hong, Hoi-To Wai, Zhaoran Wang, and Zhuoran
Yang. A near-optimal algorithm for stochastic bilevel optimization via double-momentum. In
Advances in Neural Information Processing Systems , Virtual, 2021.
[41] Jeongyeol Kwon, Dohyun Kwon, Stephen Wright, and Robert D Nowak. A fully first-order
method for stochastic bilevel optimization. In International Conference on Machine Learning ,
pages 18083–18113, 2023.
[42] Jeongyeol Kwon, Dohyun Kwon, Steve Wright, and Robert Nowak. On penalty methods
for nonconvex bilevel optimization and first-order stochastic approximation. In International
Conference on Learning Representations , Vienna, Austria, 2024.
[43] Junyi Li, Bin Gu, and Heng Huang. A fully single loop algorithm for bilevel optimization
without hessian inverse. In Association for the Advancement of Artificial Intelligence , pages
7426–7434, virtual, 2022.
[44] Bo Liu, Mao Ye, Stephen Wright, Peter Stone, and Qiang Liu. Bome! bilevel optimization
made easy: A simple first-order approach. Advances in neural information processing systems ,
35:17248–17262, 2022.
[45] Risheng Liu, Xuan Liu, Xiaoming Yuan, Shangzhi Zeng, and Jin Zhang. A value-function-based
interior-point method for non-convex bi-level optimization. In International conference on
machine learning , pages 6882–6892, 2021.
[46] Risheng Liu, Xuan Liu, Shangzhi Zeng, Jin Zhang, and Yixuan Zhang. Value-function-based
sequential minimization for bi-level optimization. IEEE Transactions on Pattern Analysis and
Machine Intelligence , 2023.
[47] Risheng Liu, Yaohua Liu, Shangzhi Zeng, and Jin Zhang. Towards gradient-based bilevel
optimization with non-convex followers and beyond. In Advances in Neural Information
Processing Systems , volume 34, pages 8662–8675, 2021.
[48] Songtao Lu. Slm: A smoothed first-order lagrangian method for structured constrained noncon-
vex optimization. Advances in Neural Information Processing Systems , 36, 2023.
[49] Dougal Maclaurin, David Duvenaud, and Ryan Adams. Gradient-based hyperparameter opti-
mization through reversible learning. In International Conference on Machine Learning , pages
2113–2122, Lille, France, 2015.
[50] Patrice Marcotte. Network design problem with congestion effects: A case of bilevel program-
ming. Mathematical programming , 34(2):142–162, 1986.
[51] Akshay Mehra and Jihun Hamm. Penalty method for inversion-free deep bilevel optimization.
InAsian conference on machine learning , pages 347–362, 2021.
[52] Yu Nesterov. Smooth minimization of non-smooth functions. Mathematical programming ,
103:127–152, 2005.
[53] Alex Nichol, Joshua Achiam, and John Schulman. On first-order meta-learning algorithms.
arXiv preprint arXiv:1803.02999 , 2018.
[54] Norbert Oppenheim. Equilibrium trip distribution/assignment with variable destination costs.
Transportation Research Part B: Methodological , 27(3):207–217, 1993.
[55] Fabian Pedregosa. Hyperparameter optimization with approximate gradient. In International
conference on machine learning , pages 737–746, 2016.
13[56] Fernando Real-Rojas. Dise ˜no de redes de transporte: integrando la competencia modal con
t´ecnicas de optimizaci ´on convexa, BSc Thesis, King Juan Carlos University. June 2024.
[57] Fernando Real-Rojas, Victor M. Tenorio, and Antonio G. Marques. A sparse nonlinear approach
for designing hub-and-spoke air transportation networks. In Asilomar Conference on Signals,
Systems, and Computers , Pacific Grove, CA, 2024.
[58] R. Tyrrell Rockafellar. Convex Analysis . Princeton University Press, Princeton, NJ, USA,
1970s.
[59] Andrzej Ruszczy ´nski. Nonlinear Optimization . Princeton University Press, 2006.
[60] Amirreza Shaban, Ching-An Cheng, Nathan Hatch, and Byron Boots. Truncated back-
propagation for bilevel optimization. In The 22nd International Conference on Artificial
Intelligence and Statistics , pages 1723–1732, 2019.
[61] Han Shen and Tianyi Chen. A single-timescale analysis for stochastic approximation with
multiple coupled sequences. Advances in Neural Information Processing Systems , 35:17415–
17429, 2022.
[62] Han Shen, Quan Xiao, and Tianyi Chen. On penalty-based bilevel gradient descent method. In
International Conference on Machine Learning , Honolulu, HI, 2023.
[63] Han Shen, Zhuoran Yang, and Tianyi Chen. Principled penalty-based methods for bilevel
reinforcement learning and RLHF. In International Conference on Machine Learning , Vienna,
Austria, 2024.
[64] Ankur Sinha, Samish Bedi, and Kalyanmoy Deb. Bilevel optimization based on kriging
approximations of lower level optimal value function. In 2018 IEEE congress on evolutionary
computation (CEC) , pages 1–8. IEEE, 2018.
[65] Ankur Sinha, Pekka Malo, and Kalyanmoy Deb. A review on bilevel optimization: from
classical to evolutionary approaches and applications. IEEE Transactions on Evolutionary
Computation , 22(2):276–295, 2017.
[66] Daouda Sow, Kaiyi Ji, and Yingbin Liang. On the convergence theory for hessian-free bilevel
algorithms. volume 35, pages 4136–4149, 2022.
[67] Bradly Stadie, Lunjun Zhang, and Jimmy Ba. Learning intrinsic rewards as a bi-level optimiza-
tion problem. In Conference on Uncertainty in Artificial Intelligence , virtual, 2020.
[68] Luis N Vicente and Paul H Calamai. Bilevel and multilevel programming: A bibliography
review. Journal of Global optimization , 5(3):291–306, 1994.
[69] Gerd Wachsmuth. On licq and the uniqueness of lagrange multipliers. Operations Research
Letters , 41(1):78–80, 2013.
[70] Quan Xiao, Songtao Lu, and Tianyi Chen. A generalized alternating method for bilevel learning
under the polyak-łojasiewicz condition. In Advances in Neural Information Processing Systems ,
2023.
[71] Quan Xiao, Han Shen, Wotao Yin, and Tianyi Chen. Alternating implicit projected sgd and its
efficient variants for equality-constrained bilevel optimization. In International Conference on
Artificial Intelligence and Statistics , 2023.
[72] Siyuan Xu and Minghui Zhu. Efficient gradient approximation method for constrained bilevel
optimization. In Proceedings of the AAAI Conference on Artificial Intelligence , 2023.
[73] Haikuo Yang, Luo Luo, Chris Junchi Li, Michael Jordan, and Maryam Fazel. Accelerating
inexact hypergradient descent for bilevel optimization. In OPT 2023: Optimization for Machine
Learning , 2023.
[74] Wei Yao, Haian Yin, Shangzhi Zeng, and Jin Zhang. Overcoming lower-level constraints
in bilevel optimization: A novel approach with regularized gap functions. arXiv preprint
arXiv:2406.01992 , 2024.
14[75] Wei Yao, Chengming Yu, Shangzhi Zeng, and Jin Zhang. Constrained bi-level optimization:
Proximal lagrangian value function approach and hessian-free algorithm. arXiv preprint
arXiv:2401.16164 , 2024.
[76] Jane J Ye and Daoli Zhu. Optimality conditions for bilevel programming problems. Optimization ,
33(1):9–27, 1995.
[77] Jane J Ye, Daoli Zhu, and Qiji Jim Zhu. Exact penalization and necessary optimality conditions
for generalized bilevel programming problems. SIAM Journal on optimization , 7(2):481–507,
1997.
15Supplementary Material for “A Primal-Dual-Assisted Penalty Approach to
Bilevel Optimization with Coupled Constraints”
Table of Contents
A Preliminaries 16
B Analysis of the Penalty-Based Lagrangian Reformulation 17
B.1 Proof of Lemma 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17
B.2 Proof of Theorem 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17
C Analysis of the Differentiability of Value Functions 18
C.1 Proof of Lemma 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19
C.2 Proof of Lemma 3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19
D Convergence Analysis of the Main Result 20
D.1 Proof of Theorem 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20
D.2 Proof of Theorem 3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21
D.3 Proof of Theorem 4 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24
E Applications to Hyperparameter Optimization for SVM 29
E.1 Problem formulation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29
E.2 Experiment details . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30
F Applications to Transportation Network Planning 31
F.1 Problem formulation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31
F.2 Numerical results for the 3-node network . . . . . . . . . . . . . . . . . . . . . 34
F.3 Numerical results for the 9-node network . . . . . . . . . . . . . . . . . . . . . 35
F.4 Numerical results for the Seville network . . . . . . . . . . . . . . . . . . . . . 36
G Sensitivity Analysis 37
G.1 Sensitivity analysis for the toy example . . . . . . . . . . . . . . . . . . . . . . 37
G.2 Sensitivity Analysis for the 3-node network . . . . . . . . . . . . . . . . . . . . 37
H Analysis of the Computational Complexity 38
H.1 Complexity comparison . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38
H.2 Complexity analysis of BLOCC . . . . . . . . . . . . . . . . . . . . . . . . . . 39
A Preliminaries
This section will provide some preliminaries for our subsequent analysis.
Definition 5. For a convex function h:Rdq→Rwhose domain is Q ⊆Rdq, the Legendre conjugate
ofh∗:Q∗→Ris defined as:
h∗(q) := sup
q′∈Q{⟨q′, q⟩ −h(q′)}=−inf
q′∈Q{−⟨q′, q⟩+h(q′)},
∀q∈ Q∗:={q∈Rdq: sup
q′∈Q{⟨q′, q⟩ −h(q′)}<∞}.
Remark 1. When his strongly convex in Rdq, it is lower bounded and therefore Q∗=Rdy.
Lemma 4. Suppose h:Rdy→Rislh,1-smooth and αh-strongly convex and its domain Q ⊆Rdqis
convex, closed and non-empty.
1.IfQ=Rdq, the gradient mappings ∇hand∇h∗are inverse of each other ([ 58]); and
h∗:Rdq→Ris1
αh-smooth and1
lh,1-strongly convex (Proposition 2.6 [3]).
162. IfQ ⊂Rdq,h∗is1
αh-smooth ([36]) and and convex (Theorem 4.43 [32]).
Lemma 5. Suppose Q ⊆Rdqis convex, closed and non-empty, h:Rdq→Ris strongly convex on
Q,hc:Rdq→Rdcis convex on Qanddcis finite, and {q∈ Q:hc(q)≤0}is non-empty.
1. The problem minq∈{q∈Q:hc(q)≤0}h(q)has a unique feasible solution.
2.When linear independence constraint qualification (LICQ) condition holds for hc(q), the
Lagrange multiplier for the problem minq∈{q∈Q:hc(q)≤0}h(q), i.e. solution to the problem
maxµ∈Rdc
+minq∈Qh(q) +⟨µ, hc(q)⟩is unique [69].
Lemma 6 (Lemma 3.1 in [ 9]).Suppose Q ⊆Rdqis convex, closed, and nonempty. For any q1∈Rdq
and any q2∈ Q, it follows that
⟨ProjQ(q1)−q2,ProjQ(q1)−q1⟩ ≤0. (25)
In this way, take q1=q3−ηgfor any q3∈ Q, and denote qη,g
3= ProjQ(q3−ηg)as a projected
gradient update in direction gwith stepsize η, we have,
⟨g, qη,g
3−q2⟩ ≤ −1
η⟨qη,g
3−q2, qη,g
3−q3⟩,∀q2, q3∈ Q. (26)
Lemma 7 (Theorem 3.10 [ 9]).Suppose a differentiable function hislh,1-smooth and αh2-strongly
convex. Consider the constrained problem minq∈Qh(q)where Qis non-empty, closed and convex.
Projected Gradient Descent with η≤1
lh,1converges linearly to the unique q∗= arg min q∈Qh(q):
∥ProjQ(q−η∇h(q))−q∗∥ ≤(1−αη)1/2∥q−q∗∥ ≤(1−αη/2)∥q−q∗∥,∀q∈ Q.(27)
B Analysis of the Penalty-Based Lagrangian Reformulation
B.1 Proof of Lemma 1
According to Lemma 5, for any fixed x, there exists a unique µ∗
g(x). Therefore, according to Lagrange
duality theorem, for any fixed x, the primal problem
min
y∈Yg(x, y)s.t.gc(x, y)≤0⇔ min
y∈Yg(x, y) +⟨µ∗
g(x), gc(x, y)⟩.
Asg(x, y)isαg-strongly convex in yandgc(x, y)is convex in y, we know g(x, y)+⟨µ∗
g(x), gc(x, y)⟩
isαg-strongly convex in y, where the modulus αgis independent of x. Therefore, according to
Appendix F and G in [ 37], and Theorem 3.3 in [ 18], the quadratic growth in statement 1 can be
concluded.
Asg(x, y)is strongly convex in y, andY(x)is a non-empty, closed and convex set under assumption
3, there exists a unique solution y∗
g(x)such that g(x, y∗
g(x)) = v(x)by Lemma 5. In this way, if
y̸=y∗
g(x)andy∈ Y(x), we have g(x, y)> v(x). This completes the proof of statement 2.
B.2 Proof of Theorem 1
We know from Lemma 1 that g(x, y)−v(x)≥αg
2∥y−y∗
g(x)∥2andg(x, y) =v(x)if and only if
y=y∗
g(x). This is squared-distance bound follows Definition 1 in [ 62]. Under Lipschitzness of
f(x, y)with respect to y, finding the solutions to the ϵ-approximate problem in (4)is equivalent to
finding the solutions to its penalty reformulation
min
(x,y)∈{X×Y :gc(x,y)≤0}f(x, y) +γ(g(x, y)−v(x)) (28)
withγ=O(ϵ−0.5)following Theorems 1 and 2 in [62].
Moreover, jointly finding solution for (x, y)in (28) is in equivalence to finding solutions in
min
x∈Xmin
y∈Y(x)f(x, y) +γ(g(x, y)−v(x)). (29)
17The proof of this equivalence is as follows. Suppose (x0, y0)∈ {X × Y :gc(x, y)≤0}being a
solution to (28). Suppose for any x∈ X,y∗
F(x)∈arg min y∈Y(x)f(x, y) +γ(g(x, y)−v(x)). We
know that for any x∈ X,y∈ Y(x), it follows that
f(x0, y0) +γ(g(x0, y0)−v(x0))≤f(x, y∗
F(x)) +γ(g(x, y∗
F(x))−v(x))
≤f(x, y) +γ(g(x, y)−v(x)).
This means any solution to (28) is a solution to (29). On the other hand, suppose x0∈ X,y∗
F(x0)∈
Y(x0)is a solution to (29). We know that for any (x, y)∈ {X × Y :gc(x, y)≤0},
f(x0, y∗
F(x0)) +γ(g(x0, y∗
F(x0))−v(x0))≤f(x, y∗
F(x)) +γ(g(x, y∗
F(x))−v(x))
≤f(x, y) +γ(g(x, y)−v(x)).
This means any solution to (29) is a solution to (28).
Besides, we know f(x, y)islf,1-smooth, g(x, y)isαg-strongly convex in y. By the definitions of
strongly convexity and smoothness, we know for fixed x, for any y1, y2∈ Y,
f(x, y1) +γ(g(x, y1)−v(x))−f(x, y2) +γ(g(x, y2)−v(x))
=f(x, y1)−f(x, y2) +γ(g(x, y1)−g(x, y2))
≥⟨∇ yf(x, y2), y1−y2⟩ −lf,1
2∥y1−y2∥2+γ⟨∇yg(x, y2), y1−y2⟩+γαg
2∥y1−y2∥2
=⟨∇yf(x, y2) +γ∇yg(x, y2), y1−y2⟩+γαg−lf,1
2∥y1−y2∥2. (30)
This proves that f(x, y)+γ(g(x, y)−v(x))is(γαg−lf,1)-strongly convex in y. Moreover, according
to Assumption 2, the constraint gc(x, y)is convex in y, and miny∈Y(x)f(x, y) +γ(g(x, y)−v(x))
is equivalent to its equivalent Lagrangian Dual Form [59]
max
µ∈Rdc
+min
y∈Yf(x, y) +γ(g(x, y)−v(x)) +⟨µ, gc(x, y)⟩. (31)
Therefore, (28) can be recovered to (2a) and this completes the proof.
C Analysis of the Differentiability of Value Functions
Lemma 8 (Theorem 2.16 in [ 32]).Suppose h(x, y)is strongly convex in y∈ Y and is Lipschitz with
respect to x∈ X,hc(x, y)is convex in yand is Lipschitz with respect to x, and both Yand{y∈ Y:
hc(x, y)≤0}are non-empty, closed, and convex. For the problem miny∈{y∈Y:hc(x,y)≤0}h(x, y),
the unique solution y∗
h(x)and unique Lagrange multiplier µ∗
h(x), defined as
(y∗
h(x), µ∗
h(x)) := arg max
µ∈Rdx
+min
y∈Yh(x, y) +⟨µ, hc(x, y)⟩, (32)
is Lipschitz in x. In other words, there exist Lh≥0that, for all x1, x2∈ X,
∥(y∗
h(x1);µ∗
h(x1))−(y∗
h(x2);µ∗
h(x2))∥ ≤Lh∥x1−x2∥.
Before proving Lemmas 2 and 3, we would like to introduce a more general form.
Lemma 9. Suppose Yand{y∈ Y:hc(x, y)≤0}are both non-empty, closed and convex, h(x, y)
is jointly smooth in (x, y)and is strongly convex in y,hc(x, y)is convex in y, and both h(x, y)and
hc(x, y)are Lipschitz with respect to x. Then we have
vh(x) = min
y∈Yh(x, y)s.t.hc(x, y)≤0
is differentiable with its gradient as
∇vh(x) =∇xh(x, y∗
h(x)) +⟨µ∗
h(x), hc(x, y∗
h(x))⟩, (33)
where (y∗
h(x), µ∗
h(x))defined in (32) are unique.
18Proof. We prove this using Theorem 4.24 in [7].
i) As h(x, y)being strongly convex in y, Condition 1 in Theorem 4.24 in [ 7] is satisfied and the
solution sets are of singleton value (y∗
h(x), µ∗
h(x))according to Lemma 5.
ii) Moreover, the smoothness of h(x, y)guarantees Robinson’s constraint qualification [ 2], which
implies the directional regularity condition (Definition 4.8 in [ 7]) for any direction d(Theorem 4.9.
(ii) in [7]). This guarantees Condition 2 in Theorem 4.24 in [7] can be satisfied for all directions d.
iii) Additionally, under the Lipschitzness of h(x, y)andhc(x, y)with respect to x,y∗
h(x), µ∗
h(x)are
Lipschitz according to Lemma 8. This implies condition 3 in Theorem 4.24 in [7] holds.
In this way, all conditions in Theorem 4.24 in [ 7] hold and it gives the gradient as in (33) for unique
(y∗
h(x), µ∗
h(x)). This completes the proof.
C.1 Proof of Lemma 2
Proof. The problem miny∈Yg(x, y)s.t.gc(x, y)≤0fits in the setting of Lemma 9 by taking
h(x, y) =g(x, y)andhc(x, y) =gc(x, y). Therefore the derivative (8)can be obtained accordingly.
Moreover, for any x1, x2∈ X,
∥∇v(x1)− ∇v(x2)∥
=∥∇xg(x1, y∗
g(x1)) +⟨µ∗
g(x1),∇xgc(x1, y∗
g(x1))⟩ − ∇ xg(x2, y∗
g(x2))
− ⟨µ∗
g(x2),∇xgc(x2, y∗
g(x2))⟩∥
(a)
≤∥∇ xg(x1, y∗
g(x1))− ∇ xg(x2, y∗
g(x2))∥
+∥⟨µ∗
g(x1),∇xgc(x1, y∗
g(x1))⟩ − ⟨µ∗
g(x1),∇xgc(x2, y∗
g(x2))⟩∥
+∥⟨µ∗
g(x1),∇xgc(x2, y∗
g(x2))⟩ − ⟨µ∗
g(x2),∇xgc(x2, y∗
g(x2))⟩∥
(b)
≤(lg,1+Bglgc,1)(∥x1−x2∥+∥y∗
g(x1)−y∗
g(x2)∥) +lgc,0∥µ∗
g(x1)−µ∗
g(x2)∥
(c)
≤((lg,1+Bglgc,1)(1 + Lg) +lgc,0Lg)∥x1−x2∥,
where (a)follows triangle inequality; (b)leverage on the Lipschitzness of ∇g,gcand∇gcinx, and
the upper bound for ∥µ∗
g(x)∥; and (c)uses the Lipschitzness of y∗
g(x)andµ∗
g(x)from Lemma 8. As
the bound is loose due to the use of triangle inequality, we can conclude that v(x)islv,1-smooth
where lv,1≤((1 + Bg)(1 + Lg)lgc,1+lgc,0Lg).
C.2 Proof of Lemma 3
By assumption, f(x, y)islf,1-smooth and g(x, y)isαg-strongly convex in y. We know f(x, y) +
γ(g(x, y)−v(x))is(γαg−lf,1)-strongly convex when γ >lf,1
αgas discussed in (30). Moreover,
constraint gc(x, y)is convex in yby Assumption 2. In this way, the problem
min
y∈Yf(x, y) +γ(g(x, y)−v(x)) s.t.gc(x, y)≤0
features strong convexity according to Chapter 4 in [59] and it equals to
Fγ(x) = max
µ∈Rdc
+min
y∈Yf(x, y) +γ(g(x, y)−v(x)) +⟨µ, gc(x, y)⟩.
Considering the smoothness of v(x)as presented in Lemma 2, all assumptions in Lemma 9 are
satisfied. Therefore the derivative (9) can be obtained. In addition, for any x1, x2∈ X,
∥∇F(x1)− ∇F(x2)∥
=∥∇xf(x1, y∗
F(x1)) +γ(∇xg(x1, y∗
F(x1))− ∇v(x1)) +⟨µ∗
F(x1),∇xgc(x1, y∗
F(x1))⟩
− ∇ xf(x2, y∗
F(x2))−γ(∇xg(x2, y∗
F(x2))− ∇v(x2))− ⟨µ∗
F(x2),∇xgc(x2, y∗
F(x2))⟩∥
(a)
≤∥∇ xf(x1, y∗
F(x1))− ∇ xf(x2, y∗
F(x2))∥+γ∥∇xg(x1, y∗
F(x1))− ∇ xg(x2, y∗
F(x2))∥
+γ∥∇v(x1)− ∇v(x2)∥+∥⟨µ∗
F(x1),∇xgc(x1, y∗
F(x1))⟩ − ⟨µ∗
F(x1),∇xgc(x2, y∗
F(x2))⟩∥
19+∥⟨µ∗
F(x1),∇xgc(x2, y∗
F(x2))⟩ − ⟨µ∗
F(x2),∇xgc(x2, y∗
F(x2))⟩∥
(b)
≤(lf,1+γlg,1+BFlgc,1)(∥x1−x2∥+∥y∗
F(x1)−y∗
F(x2)∥) +γlv,1∥x1−x2∥
+lgc,0∥µ∗
F(x1)−µ∗
F(x2)∥
(c)
≤((lf,1+γlg,1+BFlgc,1)(1 + LF) +γlv,1+lfc,0LF)∥x1−x2∥,
where (a)follows triangle inequality; (b)leverage on the Lipschitzness of ∇f,∇g,gcand∇gcinx,
and the upper bound for ∥µ∗
F(x)∥; and (c)uses the Lipschitzness of y∗
F(x)andµ∗
F(x)from Lemma
8. As the bound is loose due to the use of triangle equality, we can conclude that F(x)islF,1-smooth
where lF,1≤(lf,1+γlg,1+BFlgc,1)(1 + LF) +γlv,1+lfc,0LF.
D Convergence Analysis of the Main Result
D.1 Proof of Theorem 2
Define the bias term b(xt)of the gradient ∇Fγ(xt)as
b(xt) :=∇Fγ(xt)−gF,t
=
∇xf(xt, y∗
F(xt)) +γ 
∇xg(x, y∗
F(xt))− 
∇xg(xt, y∗
g(xt)) +
µ∗
g(xt),∇xgc(xt, y∗
g(xt))
+⟨µ∗
F(xt),∇xgc(xt, y∗
F(xt))⟩
−
∇xf(xt, yTF
F,t) +γ
∇xg(xt, yTF
F,t)−
∇xg(xt, yTg
g,t) +D
µTg
g,t,∇xgc(xt, yTg
g,t)E
+⟨µTF
F,∇xgc(xt, yTF
F,t)⟩
.
In this way, we have
∥b(xt)∥(a)
≤∥∇ xf(xt, yTF
F,t)− ∇ xf(xt, y∗
F(xt))∥
+γ
∥∇xg(xt, yTF
F,t)− ∇ xg(xt, y∗
F(xt))∥+∥∇xg(xt, yTg
g,t)− ∇ xg(xt, y∗
g(xt))∥
+
µ∗
g(xt),∇xgc(xt, y∗
g(xt))
−D
µ∗
g(xt),∇xgc(xt, yTg
g,t)E
+D
µ∗
g(xt),∇xgc(xt, yTg
g,t)E
−D
µTg
g,t,∇xgc(xt, yTg
g,t)E
+∥⟨µTF
F,∇xgc(xt, yTF
F,t)⟩ − ⟨µ∗
F(xt),∇xgc(xt, yTF
F,t)⟩∥
+∥⟨µ∗
F(xt),∇xgc(xt, yTF
F,t)⟩ − ⟨µ∗
F(xt),∇xgc(xt, y∗
F(xt))⟩∥
(b)
≤lf,1∥yTF
F,t−y∗
F(xt)∥+γ
lg,1∥yTF
F,t−y∗
F(xt)∥+lg,1∥yTg
g,t−y∗
g(xt)∥
+lgc,0∥µTg
g,t−µ∗
g(xt)∥+Bglgc,1∥yTg
g,t−y∗
g(xt)∥
+lgc,0∥µTF
F,t−µ∗
F(xt)∥+BFlgc,1∥yTF
F,t−y∗
F(xt)∥
(c)=(lf,1+γlg,1+BFlgc,0)∥yTF
F,t−y∗
F(xt)∥+lgc,0∥µTF
F,t−µ∗
F(xt)∥
+γ
(lg,1+Bglgc,1)∥yTg
g,t−y∗
g(xt)∥+lgc,0∥µTg
g,t−µ∗
g(xt)∥
,
where (a)uses triangle inequality, (b)relies on the Lipschitzness of ∇f,∇g,gc, and∇gcin
x, the upper bounds for ∥µ∗
F(x)∥and∥µ∗
g(x)∥, and Cauchy-Schwartz inequality, and (c)is by
rearrangement.
20Furthermore, according to Young’s inequality, it follows that
∥b(xt)∥2≤2
(lf,1+γlg,1+BFlgc,0)∥yTF
F,t−y∗
F,t∥+lgc,0∥µTF
F,t−µ∗
F,t∥2
+ 2γ2
(lg,1+Bglgc,1)∥yTg
g,t−y∗
g(xt)∥+lgc,0∥µTg
g,t−µ∗
g(xt)∥2
=O(γ2ϵF+γ2ϵg).
According to Lemma 3, Fγ(x)islF,1-smooth in X. In this way, by the smoothness, we have
F(xt+1)≤F(xt) +⟨∇F(xt), xt+1−xt⟩+lF,1
2∥xt+1−xt∥2
≤F(xt) +⟨gF,t, xt+1−xt⟩+1
2η∥xt+1−xt∥2+⟨b(xt), xt+1−xt⟩, (34)
where the second inequality is by η≤1
lF,1and∇F(xt) =gFt+b(xt).
The projection guarantees that xt+1andxtare inX. Following Lemma 6, we know that
⟨gF,t, xt+1−xt⟩ ≤ −1
η∥xt+1−xt∥2.
Plugging this back to (34), it follows
F(xt+1)≤F(xt)−1
2η∥xt+1−xt∥2+⟨b(xt), xt+1−xt⟩
≤F(xt)−1
2η∥xt+1−xt∥2+η∥b(xt)∥2+1
4η∥xt+1−xt∥2
=F(xt)−1
4η∥xt+1−xt∥2+η∥b(xt)∥2,
where the second inequality is from Young’s inequality. Telescoping therefore gives
1
TT−1X
t=0∥Gη(xt)∥2≤4
ηT(F(x0)−F(xT)) +4
TT−1X
t=0∥b(xt)∥2
=O(η−1T−1) +O(γ2ϵF+γ2ϵg)
=O(γT−1+γ2ϵF+γ2ϵg)
where last equality comes from η=O(γ−1)asη≤1
lF,1andlF,1≤(lf,1+γlg,1+BFlgc,1)(1 +
LF) +γlv,1+lfc,0LF=O(γ). This completes the proof.
D.2 Proof of Theorem 3
To restate, we are viewing Lg(µ, y;x)in(7)andLF(µ, y;x)in(5)respectively as L(µ, y)and
considering the following max-min problem
max
µ∈Rdc
+min
y∈YL(µ, y).
In (16), we defined the minimization part as
D(µ) := min
y∈YL(µ, y) =L(µ, y∗
µ(µ))where y∗
µ(µ) := arg min
y∈YL(µ, y).
To evaluate D(µ)forLg(µ, y;x)in(7)andLF(µ, y;x)in(5)asL(µ, y), we define the following
mappings for fixed x∈ X:
y∗
µ,g(µ) := arg min
y∈YLg(µ, y;x), (35)
y∗
µ,F(µ) := arg min
y∈YLF(µ, y;x). (36)
21In this way, for Lg(µ, y;x)in(7)andLF(µ, y;x)in(5)respectively as L(µ, y),D(µ)defined in
(16) equals to Dg(µ)andDF(µ)respectively, where
Dg(µ) = min
y∈YLg(µ, y;x) =Lg(µ, y∗
µ,g(µ);x), (37)
DF(µ) = min
y∈YLF(µ, y;x) =LF(µ, y∗
µ,F(µ);x). (38)
In the following lemma, we show that D(µ)exhibits concavity and smoothness, which are favorable
properties for conducting gradient-based algorithm.
Lemma 10 (Smoothness and Concavity of D(µ)).Suppose all the assumptions in Theorem 3 hold.
For fixed x∈ X, the following holds
1.y∗
µ,g(µ)in(35) andy∗
µ,F(µ)in(36) are respectively1
αgand1
γαg−lf,1-Lipschitz to µ.
2.Dg(µ)in(37) is concave andlgc,0
αg-smooth, and DF(µ)in(38) is concave andlgc,0
γαg−lf,1-
smooth.
Proof. To restate,
Lg(µ, y;x) =g(x, y) +⟨µ, gc(x, y)⟩,
LF(µ, y;x) =f(x, y) +γ(g(x, y)−v(x)) +⟨µ, gc(x, y)⟩.
Under Assumption 1 and 2, for fixed xand given µ,Lg(µ, y;x)isαg-strongly convex and (lg,1+
∥µ∥lgc,1)-smooth in y, andLF(µ, y;x)is(γαg−lf,1)-strongly convex and (lf,1+γlg,1+∥µ∥lgc,1)-
smooth in y. Therefore, we know y∗
µ,g(µ)in(35) andy∗
µ,F(µ)in(36) are respectively1
αgand
1
γαg−lf,1-Lipschitz to µby directly quoting Theorem F.10 in [ 17] or Theorem 4.47 in [ 32]. This
proves the first part of the Lemma.
For the second part, the concavity of Dg(µ)andDF(µ)can be directly obtained by Lemma 2.58 in
[59] as Lg(µ, y;x)andLg(µ, y;x)are both convex in y.
Moreover, following Theorem 4.24 in [7], we have
∇Dg(µ) =∇µLg(µ, y∗
µ,g(µ)) =gc(x, y∗
µ,g(µ)),
∇DF(µ) =∇µLF(µ, y∗
µ,F(µ)) =gc(x, y∗
µ,F(µ)).
Asgc(x, y)islgc,0-Lipschitz by Assumption 1, for any µ1, µ2∈Rdc
+:
∥∇Dg(µ1)− ∇Dg(µ2)∥=∥gc(x, y∗
µ,g(µ1))−gc(x, y∗
µ,g(µ2))∥
≤lgc,0∥y∗
µ,g(µ1)−y∗
µ,g(µ2)∥ ≤lgc,0
αg∥µ1−µ2∥, (39)
and similarly,
∥∇DF(µ1)− ∇DF(µ2)∥=∥gc(x, y∗
µ,F(µ1))−gc(x, y∗
µ,F(µ2))∥
≤lgc,0∥y∗
µ,F(µ1)−y∗
µ,F(µ2)∥ ≤lgc,0
γαg−lf,1∥µ1−µ2∥. (40)
We can conclude that Dg(µ)andDF(µ)are respectivelylgc,0
αgandlgc,0
γαg−lf,1-smooth.
In Algorithm 2, we are implementing an accelerated projected gradient descent on −D(µ)where
the gradient bias is controlled by Ty. Following [ 16], the following lemma presents the convergence
analysis of the accelerated method on smooth and convex functions.
Lemma 11 (Section 5 and 6 in [ 16]).Suppose D(µ)is concave and lD,1-smooth. Consider the
constrained problem maxµ∈Rdc
+D(µ). At iteration t= 0, . . . , T −1, perform accelerated projected
gradient update with stepsize η≤1
lD,1and initial value µ0=µ−1:
µt+1
2=µt+t−1
t+ 2(µt−µt−1) (41a)
22µt+1= ProjRdc
+(µt+1
2+ηgt+1
2) (41b)
where gt+1
2is anϵ1.5-approximate to ∇D(µt+1
2)satisfying ∥gt+1
2− ∇D(µt+1
2)∥=O(ϵ1.5), for a
given accuracy ϵ >0. Denote D∗= maxµ∈Rdc
+D(µ), performing T=O(ϵ−0.5)iterations leads to
D∗−D(µT) =O(ϵ).
Remark 2. The domain for µ∈Rdc
+can be replaced by any closed, convex, non-empty domain.
In this way, we are ready to proceed to the proof of Theorem 3 .
proof of Theorem 3. Algorithm 2 solves (7)and(5)by taking Lg(µ, y;x)andLF(µ, y;x)respec-
tively as L(µ, y)and run respectively iterations Tequals TgandTF
We begin our proof with analysis on (7). The accelerated version of Algorithm 2 solves this by taking
Lg(µ, y;x)in (7) with fixed x∈ X asL(µ, y).
Fixing µt+1
2, steps 4-6 are Ty-step projected gradient descent in y. AsLg(µ, y;x)is(lg,1+lgc,1)-
smooth and αg-strongly convex in y, taking the inner loop stepsize η1asηg,1≤1
lg,1+lgc,1ensures
linear convergence according to Lemma 7. Choosing Ty=O(ln 
(ϵ1.5)−1
) =O(ln 
ϵ−1
g
)leads to
∥yt+1−y∗
µ,g(µt+1
2)∥=O(ϵ1.5
g)
for target accuracy ϵg>0where y∗
µ,g(µ)is defined in (35).
In step 7, we update µwith a projected gradient descent step which takes ∇µL(µt+1
2, yt+1) =
gc(x, yt+1)as an estimate of ∇Dg(µt+1
2) =gc(x, y∗
µ,g). The estimation bias is bounded by
∥∇µL(µt+1
2, yt+1)− ∇Dg(µt+1
2)∥=∥gc(x, yt+1)−gc(x, y∗
µ,g(µt+1
2))∥
≤lgc,0∥yt+1−y∗
µ,g(µt+1
2)∥=O(ϵ1.5
g).
By Lemma 11, we can conclude the complexity is ˜O(ϵ−0.5
g)for conducting the accelerated version
of Algorithm 2 on Lg(µ, y;x)in (7) as L(µ, y)to achieve
Dg(µ∗
g(x))−Dg(µTg) =O(ϵg). (42)
Similarly, the complexity of the accelerated version of Algorithm 2 for (5) is ˜O(ϵ−0.5
F), i.e.,
DF(µ∗
F(x))−DF(µTF) =O(ϵF). (43)
In the following, we are going to show that (42) and(43) and respectively sufficient to bound
∥µTg−µ∗
g(x)∥and∥µTF−µ∗
F(x)∥considering Assumption 5 is satisfied.
AsDg(µ)andDF(µ)are both concave in µandµ∈Rdc
+is equivalent to µ≥0, the problems
max
µ∈Rdc
+Dg(µ)and max
µ∈Rdc
+DF(µ)
are respectively equivalent to the unconstrained problems
max
µ∈Rdc˜Dg(µ) :=Dg(µ) +λ⊤
gµand max
µ∈Rdc˜DF(µ) :=DF(µ) +λ⊤
Fµ
with the Lagrange multipliers λg, λFbeing non-negative and finite in all dimension, i.e. 0≤λg<∞,
0≤λF<∞according to Lagrange duality Theorem. Moreover, it is well known (Chapter 4 in
[59]) that the Largrangian terms respectively equal zero when the problems attain the optimals. i.e.
λ⊤
gµ∗
g(x) = 0 and λ⊤
Fµ∗
F(x) = 0 . (44)
Moreoever, the first-order stationary condition requires ∇˜Dg(µ∗
g(x)) =∇Dg(µ∗
g(x)) +λg= 0and
∇˜DF(µ∗
F(x)) =∇DF(µ∗
F(x)) +λF= 0and therefore
∇Dg(µ∗
g(x)) =−λgand∇DF(µ∗
F(x)) =−λF. (45)
23In this way, for all µ∈ B(µ∗
g(x);δg)∩Rdc
+.
Dg(µ∗
g(x))−Dg(µ) =Z1
τ=0⟨∇Dg(µ+τ(µ∗
g(x)−µ)), µ∗
g(x)−µ⟩dτ
=Z1
τ=01
τ⟨∇Dg(µ∗
g(x))−Dg(µ+τ(µ∗
g(x)−µ)), τ(µ−µ∗
g(x))⟩dτ
− ⟨∇ Dg(µ∗
g(x)), µ−µ∗
g(x)⟩
(a)
≥Z1
0Cδg∥µ−µ∗
g(x)∥2τdτ− ⟨∇ Dg(µ∗
g(x)), µ−µ∗
g(x)⟩
(b)=Cδg
2∥µ−µ∗
g(x)∥2+⟨λg, µ−µ∗
g(x)⟩
(c)
≥Cδg
2∥µ−µ∗
g(x)∥2,
where (a)uses (21a) in Assumption 5 and the fact that the µ, µ∗
g(x)∈ B(µ∗
g(x);δg)∩Rdc
+implies
µ+τ(µ∗
g(x)−µ)∈ B(µ∗
g(x);δg)∩Rdc
+;(b)solves the integral and uses λg=−∇Dg(µ∗
g(x))in
(45); and (c)follows from the fact that ⟨λ, µ∗
g(x)⟩= 0in (44) and µ, λg≥0.
Analogously, for all µ∈ B(µ∗
F(x);δF)∩Rdc
+, it follows that
DF(µ∗
F(x))−DF(µ)≥CδF
2∥µ−µ∗
F(x)∥2.
In this way, for arbitrary ϵg<Cδg
2δg, the complexity of Algorithm 2 to solve (7) is ˜O(ϵ−0.5
F), i.e.,
∥µTg−µ∗
g(x)∥2=O(ϵg),
and∥yTg−y∗
g(x)∥2≤∥yTg−y∗
g(µTg;x)∥2+∥µTg−µ∗
g(x)∥2
≤(1/αg+ 1)∥µTg−µ∗
g(x)∥2=O(ϵg).
At each iteration tin Algorithm 1, x=xt, and the output (yTg, µTg)is chosen as (yTg
g,t, µTg
g,t).
Similarly, to solve (5), for arbitrary ϵg<Cδg
2δg, applying Algorithm 2 with complexity ˜O(ϵ−0.5
F)to
achieve (43) can achieve
∥µTF−µ∗
F(x)∥2=O(ϵF),
and∥yTF−y∗
F(x)∥2≤∥yTF−y∗
F(µTF;x)∥2+∥µTF−µ∗
F(x)∥2
≤(1/αF+ 1)∥µTF−µ∗
F(x)∥2=O(ϵF).
At each iteration tin Algorithm 1, x=xt, and the output (yTF, µTF)is chosen as (yTF
F,t, µTF
F,t).
This completes the proof.
Remark 3. Under the same assumptions as in Theorem 3, we cam choose ηg,1≤(lg,1+lgc,1)−1,
ηg,2≤αg
lgc,0as stepsizes for running the accelerated version of Algorithm 2 to solve (7), and
ηF,1≤(lf,1+γlg,1+lgc,1)−1,ηF,2≤γαg−lf,1
lgc,0as the ones for (5).
D.3 Proof of Theorem 4
In this section, we consider
gc(x, y) =gc
1(x)⊤y−gc
2(x) (46)
being affine in y, andY=Rdy.
Therefore, for a fixed x, taking either Lg(µ, y;x)in(7)orLF(µ, y;x)in(5)asL(µ, y)fits into a
special case of strongly-convex-concave saddle point problems in the following form:
max
µ∈Rdc
+min
y∈RdyL(µ, y) =−h1(µ) +y⊤Aµ+h2(y) (47)
24where h1(µ)is smooth and linear (concave) in µandh2(y)is smooth and strongly convex in
y. Specifically, for Lg(µ, y;x)asL(µ, y),h1(µ) =⟨gc
2(x), µ⟩is0-smooth and linear (concave),
A=gc
1(x), and h2(y) =g(x, y)islg,1-smooth and αg-strongly convex.
In this context, performing PGD on L(µ, y)onyis equivalent to a gradient descent step since
Y=Rdy. The following lemma summarizes the error of ∥yt−y∗
µ(µt)∥where y∗
µ(µ)is defined in
(16) and the update of µt+1andyt+1is the non-accelerated version of Algorithm 2 with Ty= 1.
Lemma 12 (Update of ∥yt− ∇h∗
2(−Aµt)∥).Consider the problem (47) where Ais of full column
rank and h2(y)isαh2-strongly convex and lf,1-smooth. y∗
µ(µ)defined in (16) satisfies
y∗
µ(µ) =∇h∗
2(−Aµ) (48)
where h∗
2(y)is the conjugate function of h2(y)by Definition 5. At iteration t,µt, ytare known, and
conduct yt+1=yt−η1∇yL(µt, yt), a gradient descent step for L(µt, y)iny. This gives
∥yt+1− ∇h∗
2(−Aµt)∥ ≤(1−η1αh2/2)∥yt− ∇h∗
2(−Aµt)∥ (49)
when η1≤1
lh2,1. Additionally, given another µt+1, we know
∥yt+1− ∇h∗
2(−Aµt+1)∥ ≤(1−η1αh2/2)∥yt− ∇h∗
2(−Aµt)∥+σmax(A)
αh2∥µt+1−µt∥.(50)
Proof. Recall the definition y∗
µ(µ) = arg min yL(µ, y)following (16). The first-order stationary
optimality condition requires that for any given µ, it holds
∇yL(µ, y∗
µ) =Aµ+∇h2(y∗
µ) = 0 ⇔ ∇ h2(y∗
µ) =−Aµ.
As the mapping ∇h2and∇h∗
2are the inverse of each other according to Lemma 4, for any µ:
y∗
µ=∇h∗
2(−Aµ).
At iteration t, conducting a gradient descent step on L(µt, y)gives yt+1=yt−η1∇yL(µt, yt). As
L(µt, y)isαh2-strongly convex and lh2,1-smooth in y, following Lemma 7, take η1≤1
lh2,1, we have
∥yt+1− ∇h∗
2(−Aµt)∥ ≤(1−η1αh2/2)∥yt− ∇h∗
2(−Aµt)∥.
Following triangle inequality, we also have
∥yt+1− ∇h∗
2(−Aµt+1)∥
≤∥yt+1− ∇h∗
2(−Aµt)∥+∥∇h∗
2(−Aµt)− ∇h∗
2(−Aµt+1)∥
≤(1−η1αh2/2)∥yt− ∇h∗
2(−Aµt)∥+σmax(A)
αh2∥µt+1−µt∥ (51)
where the second term comes from the smoothness of the conjugate function (see Lemma 4).
In(50), the update behavior of ∥yt− ∇h∗
2(−Aµt)∥depends on ∥µt+1−µt∥. Therefore, we are
interested in the the update behavior of ∥µt+1−µt∥where µt+1= ProjRdc(µt+η∇µL(µt, yt+1))
as in the non-accelerated version of Algorithm 2 with Ty= 1. Before proceeding, we would like to
look into the properties of D(µ)defined in (16) under the setting (47):
D(µ) = min
y−h1(µ) +⟨y, Aµ⟩+h2(y) (52)
where h1(µ)is smooth and linear (concave) in µ,h2(y)is smooth and strongly convex in y, andAis
of full rank in column. The next lemma shows that D(µ)features strong concavity and smoothness.
Lemma 13 (Smoothness and strongly concavity of D(µ)).Suppose h1is concave and lh1,1-smooth,
h2isαh2-strongly convex and lh2,1-smooth, and Ais full column rank. Then D(µ)in(52) satisfies
D(µ) =−h1(µ)−h∗
2(−Aµ),
and isσ2
min(A)
lh2,1-strongly concave and (lh1,1+σ2
max(A)
αh2)-smooth with respect to µ.
25Proof. Following Definition 5, we have
D(µ) =−h1(µ)−h∗
2(−Aµ)
where h∗
2(y)is1
lh2,1-strongly convex and1
αh2-smooth according to Lemma 4.
For all µ1, µ2,
−D(µ1)−(−D(µ2)) =h∗
2(−Aµ1)−h∗
2(−Aµ2) +h1(µ1)−h1(µ2)
≥⟨∂h∗
2(−Aµ2)
∂−Aµ2,−Aµ1+Aµ2⟩+1/lh2,1
2∥Aµ1−Aµ2∥2
+⟨∇h1(µ2), µ1−µ2⟩⟩
≥⟨∇D(µ2), µ1−µ2⟩+σ2
min(A)/lh2,1
2∥µ1−µ2∥2.
where the first inequality follows the strong convexity of h∗
2(y)and the fact that −h1(µ)is convex as
h1(y)is concave. and the second inequality follows the chain rule to formulate ∇D(µ2). Therefore,
−D(µ)isσ2
min(A)
lh2,1-strongly convex, and D(µ)isσ2
min(A)
lh2,1-strongly concave.
Moreover D(µ)is(lh1,1+σ2
max(A)
αh2)-smooth as
D(µ1)−D(µ2) =−h∗
2(−Aµ1)−(−h∗
2(−Aµ2))−h1(µ1) +h1(µ2)
≤⟨∂−h∗
2(−Aµ2)
∂−Aµ2,−Aµ1−(−Aµ2)⟩+1/αh2
2∥ −Aµ1−(−Aµ2)∥2
+⟨−∇h1(µ2), µ1−µ2⟩⟩+lh1,1
2∥µ1−µ2∥2
≤⟨∇D(µ2), µ1−µ2⟩+lh1,1+σ2
max(A)
αh2
2∥µ1−µ2∥2.
The first inequality holds as h∗
2(y)andh1(µ)are smooth. The second follows the chain rule.
Note σmax(A)≥σmin(A)>0asAis full column rank. This completes the proof.
Knowing D(µ)has such favorable properties, we next analyze the update of ∥µt+1−µt∥, where
{µt}is the sequence generated in the non-accelerated version of Algorithm 2 with Ty= 1.
Lemma 14 (Update of ∥µt+1−µt∥).Consider the problem in (47) where h1is concave and
lh1,1-smooth, h2isαh2-strongly convex and lh2,1-smooth, and Ais full column rank. Running the
non-accelerated version of Algorithm 2 with Ty= 1andη1≤lh2,1−1gives
1
η2∥µt+1−µt∥ ≤
lh1,1+σ2
max(A)
αh2
∥µt−µ∗∥
+σmax(A)(1−η1αh2/2)∥yt− ∇h∗
2(−Aµt)∥+∥λ∥ (53)
where the constant λsatisfies 0≤λ <∞andµ∗= arg maxµ∈Rdc
+D(µ)withD(µ)defined in (52).
Proof. According to Lemma 13,
D(µ) = min
y∈Rdy−h1(µ) +y⊤Aµ+h2(y) =−h1(µ)−h∗
2(−Aµ)
isσ2
min(A)
lh2,1-strongly concave and (lh1,1+σ2
max(A)
αh2)-smooth with respect to µ. Moreover, the problem
maxµ∈Rdc
+D(µ)is equivalent to the unconstrained problem with the Lagrange multiplier
max
µ∈Rdc˜D(µ) :=D(µ) +λ⊤µ
where unique λis non-negative and finite in all dimension, i.e. 0≤λ <∞, asD(µ)is strongly
convex and µ∈Rdc
+is equivalent to µ≥0satisfying the LICQ condition (Lemma 5). In this way,
∇˜D(µ) =∇D(µ) +λ=−∇h1(µ) +A⊤∇h∗
2(−Aµ) +λ. (54)
26We can see that ˜D(µ)is smooth and strongly concave with the same modulus as D(µ). The first-order
stationary condition requires
∇˜D(µ∗) =−∇h1(µ∗) +A⊤∇h∗
2(−Aµ∗) +λ= 0. (55)
In this way,
1
η2∥µt+1−µt∥=1
η2∥ProjRdc
+ 
µt+η2(−∇h1(µt) +A⊤yt+1)
−µt∥
(a)
≤∥ − ∇ h1(µt) +A⊤yt+1∥
=∥ − ∇ h1(µt) +A⊤∇h∗
2(−Aµt) +λ+A⊤yt+1−A⊤∇h∗
2(−Aµt)−λ∥
(b)
≤∥∇ ˜D(µt)∥+σmax(A)∥yt+1− ∇h∗
2(−Aµt)∥+∥λ∥
(c)
≤∥∇ ˜D(µt)− ∇ ˜D(µ∗)∥+σmax(A)(1−η1αh2/2)∥yt− ∇h∗
2(−Aµt)∥+∥λ∥
(d)
≤
lh1,1+σ2
max(A)
αh2
∥µt−µ∗∥+σmax(A)(1−η1αh2/2)∥yt− ∇h∗
2(−Aµt)∥+∥λ∥
Inequality (a)comes from the non-expansiveness (1-Lipschitzness) of the projection operation, (b)
follows triangle inequality and uses (54),(c)uses (55) and(49) in Lemma 12, and (d)comes from
the smoothness of ˜D(µ), which is of the same modulus as D(µ). This completes the proof.
In(53), the update behavior of ∥µt+1−µt∥depends on ∥µt−µ∗∥. We further look into the update
of∥µt−µ∗∥and summarize in the following lemma the bound of the update of ∥µt−µ∗∥.
Lemma 15 (Update of ∥µt−µ∗∥).Consider the problem in (47) where h1is concave and lh1,1-
smooth, h2isαh2-strongly convex and lh2,1-smooth, and Ais full column rank. Conduct the
non-accelerated version of Algorithm 2 with Ty= 1, gives
∥µt+1−µ∗∥ ≤
1−η2σ2
min(A)
2lh2,1
∥µt−µ∗∥+η2σmax(A)(1−η1αh2/2)∥yt− ∇h∗
2(−Aµt)∥.
(56)
when η1≤lh2,1−1andη2≤
lh1,1+σ2
max(A)
αh2−1
. Here µ∗= arg minµ∈Rdc
+D(µ)where D(µ)is
defined in (52).
Proof. Define an auxiliary update as
˜µt+1:= ProjRdc
+(µt+η2∇D(µt)) = ProjRdc
+ 
µt+η2(−∇h1(µt) +A⊤∇h∗
2(−Aµt))
.(57)
This is a projected gradient descent on strongly convex −D(µ). AsRdc
+is closed and convex,
following Lemma 7, for η2≤
lh1,1+σ2
max(A)
αh2−1
, where
lh1,1+σ2
max(A)
αh2
is the modulus for
smoothness of D(µ)by Lemma 13, we have
∥˜µt+1−µ∗∥ ≤
1−η2σ2
min(A)
2lh2,1
∥µt−µ∗∥.
As the real update is µt+1= ProjRdc
+ 
(µt+η2(−∇h1(µt) +A⊤yt)
, by the non-expansiveness
(1-Lipschitzness) of projection operation, we have
∥˜µt+1−µt+1∥ ≤∥η2A⊤(yt+1− ∇h∗
2(−Aµt))∥ ≤η2σmax(A)∥yt+1− ∇h∗
2(−Aµt)∥
By triangle inequality and (49), we have
∥µt+1−µ∗∥ ≤
1−η2σ2
min(A)
2lh2,1
∥µt−µ∗∥+η2σmax(A)∥yt+1− ∇h∗
2(−Aµt)∥
≤
1−η2σ2
min(A)
2lh2,1
∥µt−µ∗∥+η2σmax(A)(1−η1αh2/2)∥yt− ∇h∗
2(−Aµt)∥. (58)
This completes the proof.
27We are ready to proceed with the convergence analysis for the single-loop algorithm (Algorithm 2)
without acceleration and Ty= 1, on the problems (47), which is a general form to (7)and(5). In this
way, Theorem 4 follows directly from the following theorem.
Theorem 6. Suppose L(µ, y)is in the form of (47) where Ais full column rank, h1is concave
andlh1,1-smooth, h2isαh2-strongly convex and lh2,1-smooth satisfying lh1,1=O(1),lh2,1, lα2≥
O(1), andlh2,1
αh2=O(1). Conduct the non-accelerated version of Algorithm 2 with Ty= 1. For
arbitrary small positive ϵ≤4lh2,1σmax(A)
αh2σ2
min(A)(lh1,1+σ2
max(A)
αh2)−1
, when η1=O(1
lh2,1)≤1
lh2,1and
η2=O(ϵ)≤1
lh1,1+σ2max(A)/αh2, the algorithm yields output (µT, yT)such that
∥µT−µ∗∥2< ϵ, and∥yT−y∗∥2< ϵ
with complexity T=O(ln 
ϵ−1
). Here, (µ∗, y∗) = arg max µ∈Rdcminy∈RdyL(µ, y).
Proof. For some positive constant ρ >0, denote
Pt:=ρ∥µt−µ∗∥+∥yt− ∇h∗
2(−Aµt)∥. (59)
Plugging (50) in Lemma 12 , (53) in Lemma 14, and (56) in Lemma 15 to (59), we know
Pt+1=ρ∥µt+1−µ∗∥+∥yt+1− ∇h∗
2(−Aµt+1)∥
≤ρ
1−η2σ2
min(A)
2lh2,1
∥µt−µ∗∥+η2σmax(A)(1−η1αh2/2)∥yt− ∇h∗
2(−Aµt)∥
+ (1−η1αh2/2)∥yt− ∇h∗
2(−Aµt)∥+σmax(A)
αh2η2
×
(lh1,1+σ2
max(A)
αh2)∥µt−µ∗∥+σmax(A)(1−η1αh2/2)∥yt− ∇h∗
2(−Aµt)∥+∥λ∥
=
1−η2σ2
min(A)
2lh2,1+1
ρσmax(A)
αh2η2(lh1,1+σ2
max(A)
αh2)
ρ∥µt−µ∗∥
+ (1−η1αh2/2)
1 +ρη2σmax(A) +σ2
max(A)
αh2η2
∥yt− ∇h∗
2(−Aµt)∥+σmax(A)
αh2η2∥λ∥.
To construct Pt+1≤(1−c)Pt+σmax(A)
αh2η2∥λ∥for some constant 0< c < 1, it is sufficient to find
η1≤1
lh2,1, η2≤1
(lh1,1+σ2max(A)
αh2), and ρ >0such that


0<
1−η2σ2
min(A)
2lh2,1+1
ρσmax(A)
αh2η2(lh1,1+σ2
max(A)
αh2)
≤1−η2σ2
min(A)
4lh2,1<1
0<(1−η1αh2/2)
1 +ρη2σmax(A) +σ2
max(A)
αh2η2
≤(1−η1αh2/2)(1 + η1αh2/2)<1
This can be obtained when


ρ≥4lh2,1σmax(A)
αh2σ2
min(A)(lh1,1+σ2
max(A)
αh2)
η2≤η1αh2
2
ρσmax(A)+σ2max(A)
αh2 (60)
Conditions in (60) can be satisfied when ϵ > 0is sufficiently small such that ρ=ϵ−1≥
4lh2,1σmax(A)
αh2σ2
min(A)(lh1,1+σ2
max(A)
αh2),η1=O(1
lh2,1)andη2=O(αh2
lh2,1ρ−1) =O(ϵ−1). In this way,
Pt+1≤(1−c)Pt+O(α−1
h2ϵ)
where c >0is of the order O(ϵ). Iteration gives
Pt≤(1−c)tP0+O(α−1
h2). (61)
28Notice O(α−1
h2)<O(1)andP0=O(ϵ−1)asρ=ϵ−1. In this way, there exist T1=O(ln 
ϵ−1
)
such that for all t > T 1,(1−c)tP0=O(1)andO(α−1
h2)≤ O(1). Accordingly, we can achieve
Pt=O(1),∀t > T 1.
Moreover, as Pt=ϵ−1∥µt−µ∗∥+∥yt− ∇h∗
2(−Aµt)∥,
∥µt−µ∗∥ ≤ϵPt=O(ϵ),∀t > T 1. (62)
Furthermore, choose η1=O(1
lh2,1)satisfying η1≤1
lh2,1, fort > T 1,
∥yt− ∇h∗
2(−Aµt)∥ ≤(1−η1αh2/2)t−T1∥yT1− ∇h∗
2(−AµT1)∥+O(ϵ).
This is an iteration outcome using (50) in Lemma 12, (62), and the fact that η1αh2/2 =O(αh2
lh2,1) =
O(1). In this way, for another T2=O(ln 
ϵ−1
)steps, we have
∥yt− ∇h∗
2(−Aµt)∥=O(ϵ),
and∥yt−y∗∥ ≤ ∥ yt− ∇h∗
2(−Aµt)∥+∥∇h∗
2(−Aµt)− ∇h∗
2(−Aµ∗)∥
≤ ∥yt− ∇h∗
2(−Aµt)∥+σ2
max(A)
αh2∥µt−µ∗∥
=O 
ϵ+α−1
h2ϵ
=O(ϵ),∀t > T 1+T2.
We can see that the algorithm converges linearly with complexity O(T1+T2) =O(ln 
ϵ−1
). In
this way, obtaining
∥yT−y∗∥2=O(ϵ)and∥µT−µ∗∥2=O(ϵ),
requires complexity T=O(ln 
(√ϵ)−1
) =O(ln 
ϵ−1
). This completes the proof.
Remark 4. Under the same assumptions as in Theorem 4, we cam choose ηg,2≲(lg,1)−1,ηg,1≤
α2
gϵg(2smaxαg+s2
maxϵ−1)−1ηg,2as stepsizes for running the single-loop version of Algorithm 2 to
solve (7), andηF,2≲(lf,1+γlg,1)−1,ηF,2≤(γαg−lf,1)2ϵF(2smax(γαg−lf,1)+s2
maxϵ−1)−1ηF,2
as the ones for (5).
E Applications to Hyperparameter Optimization for SVM
In this section, we provide additional details about the SVM model training experiment for the linear
SVM model, including the problem formulation and analysis of the results.
E.1 Problem formulation
SVMs train a machine learning model by finding the optimal hyperplane that separates data points
of different classes with the maximum margin w. Misclassification is not tolerated for hard-margin
SVMs. In contrast, some samples are allowed to be misclassified for soft-margin SVMs. Specifically,
one first introduces variables ξi, which measure the violation associated with the classification of
sample i, and then augments the original SVM objective with the norm of ξ, which is a vector
collecting the values of ξifor all the samples in the training set.
BLO can be applied to the hyperparameter selection task of SVM. For example, it can be used to
choose the value of the regularization parameters during soft-margin linear SVM training. Let us
consider a classification problem and define Dtr:={(ztr,i, ltr,i)}|Dtr|
i=1as the training set, with ztr,i
being the input feature vector for sample iandltr,ibeing its associated binary label. Similarly, let
Dval:={(zval,, lval,)}|Dval|
i=1 be the validation set. For a linear classification problem, the parameters
of the SVM are w, a vector of coefficients with the same size as ztr,i, and the intercept b.
In short, we are interested in the following constrained BLO problem
min
cLDval(w∗, b∗) =X
(zval,lval)∈Dvalexp 
1−lval 
z⊤
valw∗+b∗
+1
2∥c∥2(63a)
29withw∗, b∗, ξ∗= arg min
w,b,ξ1
2∥w∥2(63b)
s.t.ltr,i(z⊤
tr,iw+b)≥1−ξi∀i∈ {1, . . . ,|Dtr|}(63c)
ξi≤ci ∀i∈ {1, . . . ,|Dtr|}.(63d)
The first term of upper-level objective (63a) is a validation loss, evaluated on the validation set Dval,
the second is a regulation term on the upper-level variable c; the lower-level problem is designed to
train the parameters of the hyperplane on the training set Dtr, with the soft margin violation ξibeing
upper bounded by the hyperparameter ci[cf.(63d) , which are the CCs]. The lower-level objective
(63b) focuses on maximizing the margin by minimizing ∥w∥2while allowing for violations ξto the
separating hyperplane, which are regulated by the hyperparameter c. The BLO formulation aims to
adjust the hyperparameter cusing the validation loss (upper-level objective), ensuring that the model
parameters (lower-level variables) are optimal for the training dataset.
E.2 Experiment details
In this section, we present detailed experimental results for the training of the SVM model in
(63) using our BLOCC algorithm. We compare our algorithm to two baselines, LV-HBA [ 75] and
GAM [ 72], both designed for BLO problems with inequality CCs. We use γ= 12 andη= 0.01
for running our BLOCC and we apply α= 0.01,γ1= 0.1,γ2= 0.1,η= 0.001for LV-HBA
andα= 0.05,ϵ= 0.005for GAM respectively. The hyper-parameters for LV-HBA and GAM
are the ones used in the SVM experiments in their paper. The GAM algorithm often encounters
issues with matrix inversion, as the matrix required for the GAM algorithm to solve the problem
in(63) can be singular, preventing it from finding a solution. Consequently, only BLOCC and
LV-HBA solve the problem in (63), while GAM uses a different formulation as introduced in [ 72].
We compare the algorithms based on validation loss (the first term in the upper-level objective) and
classification accuracy. These metrics are computed for both validation and test datasets. We evaluate
the algorithms on two datasets: diabetes [20] and fourclass [29].
The detailed results are shown in Figure 4 and 5. Ten realizations of the problem are run, each with
different training and validation sets. The plots show both the mean (line) and standard deviation
(shaded region). The results reveal that our algorithm converges faster in terms of accuracy and
loss, achieving a lower loss value than the alternatives for both datasets, in validation and test sets.
Furthermore, in terms of accuracy, we observe that for the diabetes dataset, our algorithm reaches a
higher accuracy value faster than the alternatives in both validation and test sets.
0 2 4
Running time /s0.600.650.700.750.80AccuracyTest Accuracy
BLOCC
LV-HBA
GAM
(a) Test accuracy.
0 2 4
Running Time /s1.52.02.53.03.54.0LossValidation Loss (Upper Level)
BLOCC
LV-HBA
GAM (b) Validation loss.
0 25 50 75
Iteration Count024LossLower Level Objective
BLOCC
LV-HBA
GAM(c) Lower-level objective.
Figure 4: Plots for diabetes dataset
0 1 2
Running time /s0.60.70.8AccuracyTest Accuracy
BLOCC
LV-HBA
GAM
(a) Test accuracy.
0 1 2
Running Time /s1.52.02.53.03.54.0LossValidation Loss (Upper Level)
BLOCC
LV-HBA
GAM (b) Validation loss.
0 25 50 75
Iteration Count0.00.10.2LossLower Loss
BLOCC
LV-HBA
GAM (c) Lower-level objective.
Figure 5: Plots for fourclass dataset
30F Applications to Transportation Network Planning
This section applies the proposed BLOCC algorithm to a transportation network design problem,
comparing it with the baselines from [72] and [75].
F.1 Problem formulation
In transportation network planning, the planning operator is to construct a new transportation network
(upper level) connecting a collection of stations S, and the passengers will decide whether to use the
new network (lower-level), considering the options given by the new network and existing alternatives
(constraints). The goal is to design a network that maximizes the operator’s benefit, knowing the
passengers will make rational choices depending on the given design.
The operator considers building a new network on a collection of links A ⊆ S × S . For any link
(i, j)∈ A connecting stations i∈ S toj∈ S, the operator needs to design the capacity xij. If the
link’s capacity is set to zero, then the link is not constructed. The larger the capacity, the larger the
number of travelers, thus the larger the revenue while the higher the construction cost cij.
The passengers are in demand to travel in the network K ⊆ S × S . For every origin-destination pair
(o, d), the traffic demand wodand the traffic time on the existing route tod
extis known. We assume
that there is only oneexisting network. The proportion of passengers choosing the new network yod
andyod
ijthe fraction of passengers using link (i, j)to travel from otodwill be determined following
passengers’ rational choice, modeled by logit choice model [ 5,11] that will be explained later. If
yod
ij= 0, then the link does not belong to the route that passengers follow to travel from otod.
In a) of Figure 6, the station Sare presented as the dots, and links Aare as the dashed lines (input
topology); b) of Figure 6 shows a heatmap for the demand matrix for each (o, d)∈ K (input to the
design); c) is an example of the constructed network connecting some of the stations (output of the
design); and d) illustrates the number of passengers using the constructed network (design output).
To summarize, in this experiment, we assume that
A1) Only one existing alternative network exists;
A2) Passengers decide whether to use our network rationally, which is modeled by the logit
choice model considering a utility depends on travel attributes (travel time) [5, 11]; and,
A3) The demand per market, the trip prices, and the travel times per link are known to operators.
We summarize the optimization variables as follows
•xij∈R+, the capacity constructed for the link (i, j)∈ A. The number of capacity variables
is|A|. The link is not constructed if xij= 0.
•yod∈[0,1], the fraction (proportion) of passengers from market (o, d)∈ K choosing the
new network for their travel. The number of flow variables is |K|. Since we consider only
one competitor, 1−yodrepresents the fraction of incumbent network passengers. If yod= 0,
then the passengers of market (o, d)do not use the new network.
•yod
ij∈[0,1], the fraction of passengers from market (o, d)∈ K that, when choosing the new
network to travel from otod, use the link (i, j)∈ A in their route to the destination. The
number of link flow variables is |A||K| . With this definition, it holds that yod
ij≤yod; and, if
yod
ij= 0, then link (i, j)does not belong to the route when traveling from otod.
To simplify the notation and to make it consistent with the notations used in the paper, we denote
•x={xij}∀(i,j)∈Arepresents the upper-level variables to be optimized.
•X=R|A|
+represents the domain of x.
•y={yod,{yod
ij}∀(i,j)∈A}∀(o,d)∈Krepresents the lower-level variables to be optimized
•Y= [ε,1−ε]|K|×[ε,1−ε]|A||K|, where εis a small positive number set by the designer
of the network, represents the domain of y.
31Figure 6: Example of a transportation network design. (a) represents the set of stations S=
{1,2,3,4,5,6,7,8,9}and the set of links A ⊆ S × S , where the number of links is |A|= 30 (15
segments with two orientations each) and the value on each edge represents the travel time. (b)
represents the demand {wod}between all (o, d)pairs, where |K|= 9×8 = 72 values are provided
(those in the off-diagonal elements of the heatmap). (c) represents the constructed network, where,
to facilitate visualization, we have assumed that the capacity is symmetric and used the width of
the edge to represent the capacity of every link. (d) represents {wodyod}{∀(o,d)∈K}, the number of
passengers served by the constructed network.
Besides the optimization variables, our objective and constraints include the following parameters
•wod, the total estimated demand (number of passengers) for the market (o, d)∈ K.
•mod, the revenue obtained by the operator from a passenger in the market (o, d)∈ K.
•cij, the construction cost per passenger associated with link (i, j)∈ A.
•tij, the travel time for link (i, j)∈ A.
•tod
ext, travel time on the alternative network for passengers in the market (o, d)∈ K.
•ωt<0, the coefficient associated with the travel time in passengers’ utility function.
In transportation network design, a bilevel formulation is essential due to the interaction between
two players with different levels of influence: the operator, who constructs the network, and the
passengers, who choose their routes based on the network’s characteristics. The operator’s goal is
to maximize their benefit by minimizing construction costs and maximizing attracted demand, with
link capacity as the optimization variable. Conversely, passengers aim to maximize their trip utility,
determining the proportion of demand using each link. This dual optimization requires that passenger
choices comply with link capacity constraints set by the operator, coupling the variables at both
levels. This necessitates a bilevel optimization approach, specifically using BLOCC, to address the
interdependent decisions and constraints effectively.
32Now, we are ready to introduce the objective formulations of our BLO problem. For the upper level,
the network operator aims to maximize profits and minimize costs, and therefore, its interest is
min
x∈Xf(x, y∗
g(x)) :=− X
∀(o,d)∈Kmodyod∗(x)
| {z }
profit−X
∀(i,j)∈Acijxij
|{z}
cost!
, (64)
where yod∗(x)are optimal lower-level passenger flows associated with the network design x.
For the lower-level, we model the passenger’s behavior by finding the flow variables that maximize
utility and minimizes flow entropy cost.
min
y∈Yg(x, y) :=− X
(o,d)∈KX
(i,j)∈Awodωttijyod
ij+X
(o,d)∈Kwodωttod
ext(1−yod)
| {z }
passengers utility(65)
+X
(o,d)∈Kwodyod(ln 
yod
−1) +X
(o,d)∈Kwod(1−yod)(ln 
1−yod
−1)
| {z }
flow entropy cost!
.
The passengers’ utility considers the time cost of choosing the new network and the existing network.
The users set the flow variables yso that the transportation network yielding a higher utility is
preferred. Here, the probability of chosing new network is modeled by a logistic (softmax) model.
However, setting the objective as a simple linear utility maximization would lead to an all-or-nothing
policy, which is not the behavior observed in practice. Hence, the second term is brought to consider.
The approach considered here is to formulate an objective given by the Legendre transform (cf.
Definition 5) of the softmax sharing (see [ 54,57,56] for additional details). Intuitively, this means
that rather than imposing the softmax sharing a fortiori, we formulate a convex problem whose KKT
conditions lead to the softmax sharing. Using the fact that the Legendre transform of an exponential
eyis the negative entropy function y(ln(y)−1), the lower-level objective is traditional as in [57].
Having introduced the optimization variables, parameters, and objective functions, we next formulate
our BLO problem, where we also incorporate the network constraints:
min
x∈X−X
∀(o,d)∈Kmodyod∗+X
∀(i,j)∈Acijxij (66a)
s.t.(yod∗, yod∗
ij) = arg min
y∈Y−X
(o,d)∈KX
(i,j)∈Awodωttijyod
ij−X
(o,d)∈Kwodωttod
ext(1−yod) (66b)
+X
(o,d)∈Kwodyod(ln 
yod
−1) +X
(o,d)∈Kwod(1−yod)(ln 
1−yod
−1)
s.t.X
∀j|(i,j)∈Ayod
ij−X
∀j|(j,i)∈Ayod
ji=

yodifi=o
−yodifi=d
0 otherwise∀i,(o, d)∈ S × K (66c)
X
∀(o,d)∈Kwodyod
ij≤xij ∀(i, j)∈ A (66d)
where (66c) are the flow-conservation constraints, (66d) are the capacity constraints that involve both
upper and lower-level variables, coupling the optimization and motivating the use of BLOCC. Note
that, for networks with nstations (nodes): i) the number of CCs is approximately n2; and ii) each of
the constraints involves approximately n2variables. Hence, even for a moderate-size network (say
30-50 nodes), we may have thousands of CCs involving millions of variables.
Experiment roadmap. To provide numerical results illustrating the behavior of our algorithm, we
solve the optimization in (66) for three scenarios:
S1)The design of a 3-node simple synthetic network;
330 20 40 60
Running time /s-3.0-2.5-2.0-1.5-1.0-0.50.0f(xt,yt)LV-HBA
BLOCC =2
BLOCC =3
BLOCC =4
Figure 7: Upper-level objective f(xt, yt)for a
3-node network design problem; Solid lines show
mean value of f(xt, yTg
g,t)with the shaded region
as a standard deviation; Dashed lines show the
mean value of f(xt, yTF
F,t)with the shaded region
as a standard deviation; Three different γvalues
(red, purple, blue) and fixed stepsize η= 1.6×
10−4; The orange color represents the result of
the LV-HBA algorithm.
0 20 40 60
Running time /s0.00.51.01.52.02.5g(xt,yF,t)g(xt,yg,t(xt))
LV-HBA
BLOCC =2
BLOCC =3
BLOCC =4
Figure 8: Optimality gap of the lower-level
problem for a 3-node network design prob-
lemg(xt, yt)−g(xt, y∗
t). Solid lines repre-
sent the mean value of the 10 realizations of
the upper-level variables, dashed lines represent
g(xt, yTF
F,t)−g(xt, y∗
t), and the shaded region is
the standard deviation. Three different γvalues
are represented in our algorithm, and fixed step-
sizeη= 1.6×10−4.
S2)The design of a 9-node synthetic network from the prior transportation literature; and
S3)The design of a (real-world) subway network for the city of Seville, Spain, with 24 nodes
where S1)involves 6 CCs and 48 variables, and S3)involves around 100 CCs and 50,000 variables.
For the 3-node network scenario, we will conduct a comparative analysis against other algorithms to
evaluate the efficacy of our approach. In the other two scenarios, the baseline algorithms cannot find
a solution; hence, for the 9-node and Seville networks, we will focus on providing insights into the
performance and behavior of our algorithm under varying parameters, shedding light on the versatility
and adaptability of our approach to real-world transportation networks.
Before delving into the presentation and analysis of the results, two additional remarks are in order:
R1) While one of the goals of these experiments was to compare our BLOCC algorithm against
LV-HBA [ 75] and GAM [ 72], for the scenario at hand, the GAM algorithm cannot be
implemented, since the inverse of a matrix at each iteration for the problem in (66) is not
tractable. In this way, we only conducted the experiments using our BLOCC and LV-HBA.
R2) The BLOCC algorithm produces two lower-level variables: yTF
F,TandyTg
g,T. While Theorems
1 and 2 guarantee that (xT, yTF
F,T)is an ϵ-approximate solution, the pair (xT, yTg
g,T)is
strictly feasible, meaning that yTg
g,T=y∗
g(xT). Since strict feasibility is important in the
transportation network, this section will report the results using both yTF
F,TandyTg
g,T.
F.2 Numerical results for the 3-node network
In this section, we address the problem defined in equation (66) for a network comprising 3 nodes
(stations). We assume that the graph of potential links Ais complete, leading to a total of 6 link
capacities that need to be determined in the upper level. Additionally, as in the rest of the manuscript,
we assume that there is demand for all markets, meaning that the set Kis complete and includes all 6
possible origin-destination pairs. The specific values of the key parameters can be found in Table 4,
with further details about the simulated scenario available in the online code repository.
For BLOCC, we set the stepsize to η= 1.6×10−4and analyze the algorithm’s convergence for
three different values of γ:γ= 2,γ= 3, andγ= 4. The upper-level objective values are computed
using f(xt, yTg
g,t)andf(xt, yTF
F,t). The results are presented in Figures 7 and 8.
34Market (o, d)
Parameter (1,2) (1,3) (2,1) (2,3) (3,1) (3,2)
demand wod1 1 1 1 1 1
revenue mod2 6 2 1 6 1
travel time incumbent tod
ext 3 3 3 3 3 3
Link (i, j)
Parameter (1,2) (1,3) (2,1) (2,2) (3,1) (3,2)
link construction cost cij 1 10 1 3 10 3
link travel time tij 1 10 1 2 10 2
Table 4: Value of the parameters for scenario 1 (3-node network). The value of ωtis set to 0.1.
200 400 600 800
Running time /s-20-15-10-50f(xt,yt)BLOCC =2
BLOCC =3
BLOCC =4
Figure 9: Upper-level objective f(xt, yt)for a
9-node network design problem; Solid lines show
the mean value of f(xt, yTg
g,t)with the shaded re-
gion as a standard deviation; Dashed lines show
the mean value of f(xt, yTF
F,t)with the shaded
region as a standard deviation; Three different
γvalues (red, purple, blue) and fixed stepsize
η= 1.6×10−4; The orange color represents the
result of the LV-HBA algorithm.
Figure 10: Upper-level objective f(xt, yt)for a
metro network design problem in Seville, Spain,
for 2 random initializations of the upper-level
variables. Solid lines represent the mean of
f(xt, yTg
g,t), and the shaded region is the standard
deviation. The dashed lines represent the mean of
f(xt, yTF
F,t), and the shaded region is the standard
deviation. Three different γvalues are tested with
a fixed stepsize η= 1.6×10−4.
Figure 7 illustrates the performance of our BLOCC algorithm over time. The orange line represents
the evolution of f(xt, yt)for the LV-HBA algorithm, while the other six lines represent different
implementations of BLOCC. Each color represents a different value of γ; solid lines represent
f(xt, yTg
g,t)and dashed lines represent f(xt, yTF
F,t). Each simulation is conducted 10 times with 10
different random initializations of the upper-level variables, and both the mean and the standard
deviation values are displayed. The results indicate that all versions of our BLOCC algorithm
converge in less than 10 seconds, while LV-HBA shows slight fluctuations even after running for
more than 50 seconds. This may be attributed to the fact that the LV-HBA algorithm requires a joint
projection into {X × Y :gc(x, y)≤0}at each iteration, involving 42 variables and 6 CCs.
Figure 8 shows the lower-level optimality gap, namely g(xt, yt)−g(xt, y∗(xt))for LV-HBA and
BLOCC with 3 different values of γ. In the case of LV-HBA, lower-level optimality is not attained
within 70 seconds of running time. Conversely, for BLOCC, lower-level optimality is achieved by
construction when ytis set to yTg
g,T, resulting in a zero gap. Additionally, when ytis set to yTF
F,T, we
observe that: i) lower-level optimality is accomplished for γ≥3, and ii) when γ= 2, an optimality
gap exists, but it is one order of magnitude smaller than that for LV-HBA.
F.3 Numerical results for the 9-node network
In this case, we consider the network in [ 21], see also Figure 6, which has |S|= 9 nodes and
|A|= 30 potential links. As before, we consider that all markets exist, so that |K|= 9·8 = 72 . The
remaining parameters are described in Figure 6 and the code repository.
35Figure 9 is the counterpart of Figure 7 for the 9-node scenario, showing the behavior of our BLOCC
algorithm for η= 1.6×10−4andγ∈ {2,3,4}. Each simulation is repeated 10 times (using 10
different random initializations of the upper-level variables), and both the mean and the standard
deviation values are shown. Since the number of variables and constraints is almost one order of
magnitude larger, the algorithm requires more time to converge. However, convergence takes place in
a reasonable amount of time (20-40 times longer than in the previous 3-node test case). Regarding the
optimal value, we observe that: i) the sensitivity of the (steady-state) optimal value with respect to γis
not too large; ii) the solutions based on yTF
F,Tyield better upper-level values than those based on yTg
g,T;
and iii) the gap between f(xT, yTg
g,T)andf(xT, yTF
F,T)decreases as γincreases. Observation ii) is due
to the fact that yTF
F,Tis not feasible (meaning that it violates the optimality of the lower-level); hence, it
is able to achieve a better upper-level objective. In addition, the behavior observed in iii) is consistent
with the discussion in Section 2.2, with the value of γhaving an impact on the suboptimality of yTF
F,t
at the lower-level. Specifically, higher values of γpushyTF
F,tcloser to yTg
g,tand, hence, decrease the
lower-level optimality gap. Finally, we must note that for the solid lines (associated with yTg
g,t), it
holds that f(xt, yTg
g,t) =f(xt, y∗(xt)). This implies that if we need a solution that is feasible at the
lower-level, then better objective values are associated with higher values of γ.
F.4 Numerical results for the Seville network
Figure 11: Topology of the Seville network.In this section, we demonstrate the practical use
of BLOCC in a real transportation network de-
sign problem. Specifically, we address the de-
sign of a metro network in the city of Seville,
which has approximately one million inhabitants
and is located in the south of Spain, with the bus
system as its competitor. The data for the de-
mand, number of stations, and locations have
been taken from [ 21]. Information about the
construction costs, capacity, and travel time has
been obtained from Spanish rapid transit oper-
ators (see references in [ 10,56] for full details).
The city authorities considered |S|= 24 poten-
tial station locations. Regarding the links, the following assumptions are made:
A1) The link between nodes (i, j)∈ S × S only exists if node jis one of the three closest
neighbors to i, or vice versa. The distance here is measured in terms of travel time. This
assumption limits the number of lines in any station to be at most 3, which is a very mild
assumption for a network with 24 stations.
A2) The link between nodes (i, j)∈ S ×S only exists if the travel time tijis less than 7 minutes.
This is also a mild assumption, since it enables all the stations to be connected, including
those that are further away from the city center (the airport and the university campus [ 21]).
Under these two conditions, the set Aof potential links contains |A|= 88 links. The sets of links and
stations, along with their actual locations, are shown in Figure 11. Finally, we consider all possible
markets between nodes, so |K|= 24×23 = 552 .
Following the narrative in Sections F.2 and F.3, Figure 10 presents the evolution of the upper-level
objective function with time for three values of the parameter γ∈ {2,3,4}. The stepsize value has
been set to η= 1.6×10−4, and two different initializations have been considered. Regarding the
behavior of the algorithm with respect to the value of γand the particular output chosen ( yTg
T,gvs.
yTF
T,F), the findings are very similar to those in Figure 9. Namely, smaller gaps are found for larger
values of γ, and if feasibility at the lower-level (i.e., consistency with the user preference level) must
be preserved, better objective values are achieved for larger values of γ.
The most important observation, however, is related to the running time. Specifically, Figure 10
reveals that, for this real-world scenario, our BLOCC algorithm converges in 10-20 hours. While this
is more than 1,000 times larger than the convergence interval for the 3-node network, the number
36of variables and constraints here is 100 times larger. More importantly, in the context of network
transportation design, optimization times of 100 hours are widely accepted even for single-level
formulations. Overall, we believe that the numerical results demonstrate that the BLOCC algorithm
proposed in this work can solve problems with a large number of variables and CCs, which can have
practical value in real-world applications, such as the one studied in this section.
G Sensitivity Analysis
Regarding the selection and impact of hyper-parameters on the performance of BLOCC, we conducted
an ablation study on various values of the two critical parameters, γandη, and measured their effects
on the optimal value and computational time. In this section, we present the sensitivity analysis on the
toy example that we introduced in Section 4.1 and the 3-node network example for the transportation
network planning problem in Section 4.3.
G.1 Sensitivity analysis for the toy example
We present in Table 5 the results of lower-level optimality ∥y∗
g(xT)−yF,T∥using different γandη
to conduct BLOCC (Algorithm 1) on the toy example in Section 4.1.
∥y∗
g(xT)−yF,T∥
η γ= 0.001 γ= 0.01 γ= 0.1 γ= 1.0
0.0010.028±0.042 0.035±0.076 0.027±0.064 0.000±0.000
(3.314±0.042) (3.186±0.076) (2.049±0.064) (1.967±0.000)
0.010.020±0.031 0.020±0.041 0.009±0.019 0.000±0.000
(2.242±0.031) (1.575±0.041) (1.118±0.019) (0.585±0.000)
0.10.006±0.010 0.017±0.027 0.011±0.033 0.000±0.000
(1.616±0.010) (1.475±0.027) (1.257±0.033) (0.383±0.000)
1.00.023±0.019 0.030±0.022 0.020±0.045 0.000±0.000
(7.118±0.019) (4.570±0.022) (3.477±0.045) (1.645±0.000)
10.00.034±0.123 0.019±0.014 0.025±0.070 0.000±0.000
(6.565±0.123) (4.365±0.014) (2.808±0.070) (1.750±0.000)
Table 5: Sensitivity analysis for the hyperparameters in Section 4.1. Top line in each cell represents
the optimality gap ∥y∗
g(xT)−yF,T∥, while the bottom line represents the time required for the
algorithm to converge. Both the mean and the standard deviation are for 40 simulations.
From the table, we can draw the following empirical observations:
O1) Larger values of γbring the upper-level objectives closer to optimal . This is consistent
with Theorem 1 which illustrated that larger γimproves the accuracy of the lower-level
optimality. Since the obtained solution yF,Tis closer to y∗
g(xT)for larger γvalues, the
distance between the f(xT, yF,T)andf(xT, y∗
g(xT))will be closer as well.
O2) For a sufficiently small fixed η, larger γlead to faster convergence . This implies that smaller
η≤1
lF,1choice due to larger γwill not significantly dampen the convergence time . This
is because a large value of γincreases lF,1, sharpening the function Fγ(x)and its gradient
will be larger for most points. Thus, the gradient update η∇Fγ(xt)will not be very small
and thus won’t make the convergence slower.
G.2 Sensitivity Analysis for the 3-node network
We present in Table 6 the results of the upper-level objective value f(x, y)in network planning
problem for a 3-node network, whose detailed framework is introduced in Section F.
37f(x, y )
η γ= 1 γ= 2 γ= 3 γ= 4 γ= 5 γ= 6 γ= 7 γ= 8 γ= 9 γ= 10
1.6×10−4−0.9625±0.76−1.4274±0.28−1.6081±0.27−1.4507±0.41 0.0000±0.00 0.0000±0.00 0.0000±0.00 0.0000±0.00 0.0000±0.00 0.0000±0.00
13.99±6.32 5.43±1.94 7.85±2.92 13.02±4.47 5.85±1.77 4.51±1.72 3.06±0.97 2.71±0.95 2.18±0.81 1.77±0.68
3.2×10−5−0.9649±0.76−1.4768±0.22−1.6081±0.27−1.6214±0.27−1.4582±0.41−1.3772±0.44−1.1278±0.69 0.0000±0.00 0.0000±0.00 0.0000±0.00
51.85±12.12 15.61±6.33 22.56±6.29 20.83±8.59 22.48±7.89 29.13±10.19 0.56±0.31 14.38±3.63 7.59±2.84 6.05±2.12
1.6×10−5−1.0461±0.66−1.4744±0.22−1.6081±0.27−1.6214±0.27−1.4582±0.41−1.3772±0.44−1.3808±0.45−1.2106±0.73−0.6792±0.59 0.0000±0.00
21.26±12.85 30.82±8.59 46.02±9.89 35.98±11.00 32.53±9.90 32.37±11.80 40.79±12.98 40.31±13.95 1.47±0.57 17.27±4.27
3.2×10−6−0.7819±0.68−1.4725±0.22−1.6081±0.27−1.6214±0.27−1.6297±0.27−1.6355±0.27−1.4671±0.42−1.4700±0.42−1.3856±0.45−1.3873±0.45
888.38±256.38 213.22±33.88 335.63±43.42 253.26±46.92 210.03±44.41 206.14±48.21 172.50±43.31 153.57±43.90 138.12±38.92 117.68±34.65
1.6×10−6−0.9665±0.63−1.4723±0.23−1.6840±0.03−1.6214±0.27−1.6297±0.27−1.6355±0.27−1.6397±0.27−1.4700±0.42−1.4722±0.42−1.4741±0.42
805.74±268.20 377.37±54.25 629.90±65.16 496.31±69.79 464.33±68.94 418.23±67.45 390.74±65.78 356.06±60.70 334.36±61.03 305.70±57.01
Table 6: Sensitivity analysis for hyperparameters ηandγin the experiment of the 3-node network
transportation design described in Section 4.3 and Appendix F. Top line in each cell represents the
upper-level objective value f(xT, yg,T), while the bottom line represents convergence time. Both the
mean and the standard deviation of 10 simulations are provided.
We know from Section F that the goal is to minimize f(x, y), and negative values of f(x, y)are
expected. Therefore, f(xT, yT) = 0 in the table indicates a failure to converge and we can see that
O3) Smaller ηis needed to satisfy η≤1
lF,1to ensure convergence if γis chosen larger. The
algorithm tends to converge for different γvalues when ηis small enough. This is because
the Lipschitz smoothness constant lF,1ofFγ(x)increases with γ(Lemma 3), and the
BLOCC algorithm is guaranteed to converge if η≤1
lF,1(Theorem 2).
In summary, the experimental results align with the theoretical analysis, demonstrating that the
penalty constant γis robust and can be effectively set around 10, and the stepsize should be adjusted
to ensure smooth and monotonic convergence.
H Analysis of the Computational Complexity
H.1 Complexity comparison
We present in the following the computational complexity of our BLOCC algorithm in comparison
with LV-HBA [75] and GAM [72] as baselines.
Method Iteration Cost Computational Cost per Iteration
BLOCC Outer loop (Algorithm 1): General setting (Theorem 3) :˜O(dcdx+d2
x+ϵ−1(dcdy+d2
y));
T=O(ϵ−1.5) Special case (Theorem 4) :˜O(d2
x+d2
y+dc(dx+dy))
LV-HBA O(ϵ−3) O(dxdydc+ (dx+dy)3.5)
GAM Asymptotic More than O(d3
y+d2
x+dc(dx+dy))
Table 7: Complexity comparison of our work with LV-HBA [75] and GAM [72].
The iteration costs are detailed in the earlier sections, and in [ 75] and [ 72]. Hence, we discuss next
the per-iteration cost. In the following discussion, we assume
A1) the complexity of calculating a function is proportional to the dimension of the inputs .
For example, The complexity of finding ∇xg(x, y),∇xf(x, y)areO(dx), and the one for
gc(x, y)⟩isO(dxdy).
A2) Projection cost on XandYis respectively no more than O(d2
x)andO(d2
y).As discussed
in the introduction, XandYare assumed to be easy-to-project domains, i.e. projection can
be done using a projection matrix or a simple formula, and the projection costs are no more
thanO(d2
x)andO(d2
y), respectively.
In this way, BLOCC is a first-order method with gradient calculation costs of O(dxdc)andO(dydc),
and the projection cost of O(d2
x)andO(d2
y). We present the detailed analysis of achieving the
computational cost in the table in the following Section H.2.
In the SVM model training and network planning experiments in Section 4, projections are simpler
(e.g., truncation), resulting in O(dx)andO(dy)costs. In this scenario, for the general setting
(Theorem 3), the complexity is ˜O(ϵ−1.5dcdx+ϵ−2.5dcdy); and for the gcaffine in ysetting (Theorem
4), it is ˜O(ϵ−1.5dc(dx+dy)). Therefore, our BLOCC is especially robust to large-scale problems.
38LV-HBA [75], also a first-order method, has similar gradient calculation costs. However, its projection
onto{X × Y :gc(x, y)≤0}is expensive, with a complexity of O((dx+dy)3.5)of using interior
point method to find the projected point [ 38], and evaluating gc(x, y)≤0addsO(dxdydc)as it
requires dcinequality judgment on functions taking input dimension dx, dy.
GAM [72] lacks an explicit algorithm for lower-level optimality and Lagrange multipliers. Even
if we omit this, calculating ∇2
yygand its inverse incurs a cost of O(d3
y). Additionally, it has cost
O(d2
x+dc(dx+dy))for projection onto Xand calculating gradients.
We can see that BLOCC stands out with the lowest computational cost in both iterational and
overall complexity thanks to its first-order and joint-projection-free nature. Consequently, BLOCC is
particularly well-suited for large-scale applications with high-dimensional parameters.
H.2 Complexity analysis of BLOCC
At each iteration t, our proposed BLOCC algorithm in Algorithm 1 involves:
Step 1: Solve two max-min problems.
Step 2: Calculate gF,tin (13) and update xt+1= ProjX 
xt−ηgF,t
.
where Step 1 can be achieved by our proposed max-min solver in Algorithm 2. In the following, we
provide analysis for using the accelerated version of the Algorithm 2 in the general case (Theorem 3)
and the single-loop version for the special case (Theorem 4) as discussed in Section 3.3.
In the general case , we use the accelerated version of Algorithm 2 to solve both (7)and(5). For
solving (7), at each inner loop iteration t, line 3 of the algorithm is of computational cost O(dc). The
update of yin line 4-6 involves calculating ∇yg(x, y)with a cost of O(dy), finding ⟨µ,∇ygc(x, y)⟩
for fixed xofO(dydc)following assumption A1), and the projection ProjYof complexity O(d2
y)
according to A2). Moreover, yconverges linearly as L(µ, y)is strongly convex in y(Lemma 7), this
inner update for ygives an iteration complexity of O(ln 
ϵ−1
). Therefore, the cost of the update for
ytotals up to O(ln 
ϵ−1
(dydc+d2
y)). The update of µin line 7 involves O(dydc)for calculating
∇µL(µt+1/2, yt+1) =gc(x, yt+1)withxbeing fixed, and O(dc)for projection onto Rdc
+.
Moreover, to achieve target accuracy ϵon the metric1
TPT
t=0∥Gη(xt)∥2≤ϵ, with γ=O(ϵ−1)
using the BLOCC algorithm, the iteration complexity of the max-min solver is O(ϵ−1)according
to Theorem 3. Therefore, the complexity for solving (7)in the general case using the accelerated
version of Algorithm 2 (Theorem 3) is
O(ϵ−1(ln 
ϵ−1
(dydc+d2
y) +dcdy+dc)) = ˜O(ϵ−1(dydc+d2
y)). (67)
Solving (5)is of the same order as the only difference is in calculating ∇yf(x, y). In this way, we
can conclude that Step 1 is at a cost of ˜O(ϵ−1(dydc+d2
y))in the general case .
In the special case (Theorem 4), the non-accelerated (single-loop) version of Algorithm 2 involves
yt+1= ProjY(yt−η1∇yL(µt, yt))with complexity O(d2
y+dydc), and µt+1= ProjRdc
+(µt+
η2∇µL(µt, yt+1))with complexity O(dc+dydc)following a similar analysis as in the general case.
Moreover, the algorithm converges linearly in the special case of gcbeing affine in yand the
computational complexity is O(ln 
ϵ−1
), according to Theorem 4. Therefore, the complexity for the
max-min Step 1 in the special case is
O(ln 
ϵ−1
(dydc+d2
y+dc)) = ˜O(dydc+d2
y+dc). (68)
Step 2 involves calculating ∇xg(x, y)with with a fixed y, and⟨µ,∇xgc(x, y)⟩for fixed µ, y, which
are of complexity O(dx)andO(dxdc)respectively, and conducting a projection on Xof cost O(d2
x)
according to assumption A2).
In this way, the computational complexity of Step 2 is
O(dxdc+d2
x). (69)
We can therefore conclude the complexity of BLOCC in Table 7.
39NeurIPS Paper Checklist
1.Claims
Question: Do the main claims made in the abstract and introduction accurately reflect the
paper’s contributions and scope?
Answer: [Yes]
Justification: The abstract and introduction clearly state the claims made, including the
contributions made in the paper and important assumptions and limitations.
2.Limitations
Question: Does the paper discuss the limitations of the work performed by the authors?
Answer: [Yes]
Justification: yes, we have discussed in the conclusions.
3.Theory Assumptions and Proofs
Question: For each theoretical result, does the paper provide the full set of assumptions and
a complete (and correct) proof?
Answer: [Yes]
Justification: All have been clearly listed.
4.Experimental Result Reproducibility
Question: Does the paper fully disclose all the information needed to reproduce the main ex-
perimental results of the paper to the extent that it affects the main claims and/or conclusions
of the paper (regardless of whether the code and data are provided or not)?
Answer: [Yes]
Justification: The code used to run the experiments is published on GitHub.
5.Open access to data and code
Question: Does the paper provide open access to the data and code, with sufficient instruc-
tions to faithfully reproduce the main experimental results, as described in supplemental
material?
Answer: [Yes]
Justification: The data files considered and the code used to run the experiments are published
on GitHub.
6.Experimental Setting/Details
Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
results?
Answer: [Yes]
Justification: All the necessary details to run the experiments are available in the code.
7.Experiment Statistical Significance
Question: Does the paper report error bars suitably and correctly defined or other appropriate
information about the statistical significance of the experiments?
Answer: [Yes]
Justification: The figures in the paper include confidence intervals representing the standard
deviation for different realizations of the experiments. Also, the tables include the standard
deviation of the simulations.
8.Experiments Compute Resources
Question: For each experiment, does the paper provide sufficient information on the com-
puter resources (type of compute workers, memory, time of execution) needed to reproduce
the experiments?
Answer: [NA]
40Justification: The paper is theory paper, and does not include much computation-heavy
experiments.
9.Code Of Ethics
Question: Does the research conducted in the paper conform, in every respect, with the
NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines ?
Answer: [Yes]
Justification: We follow the NeurIPS Code of Ethics.
10.Broader Impacts
Question: Does the paper discuss both potential positive societal impacts and negative
societal impacts of the work performed?
Answer: [NA]
Justification: The work is foundational research, and there is no societal impact of the work
performed.
11.Safeguards
Question: Does the paper describe safeguards that have been put in place for responsible
release of data or models that have a high risk for misuse (e.g., pretrained language models,
image generators, or scraped datasets)?
Answer: [NA]
Justification: The paper poses no such risks.
12.Licenses for existing assets
Question: Are the creators or original owners of assets (e.g., code, data, models), used in
the paper, properly credited and are the license and terms of use explicitly mentioned and
properly respected?
Answer: [NA]
Justification: The paper does not use existing assets.
13.New Assets
Question: Are new assets introduced in the paper well documented and is the documentation
provided alongside the assets?
Answer: [NA]
Justification: the paper does not release new assets.
14.Crowdsourcing and Research with Human Subjects
Question: For crowdsourcing experiments and research with human subjects, does the paper
include the full text of instructions given to participants and screenshots, if applicable, as
well as details about compensation (if any)?
Answer: [NA]
Justification: The paper does not involve crowdsourcing nor research with human subjects.
15.Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
Subjects
Question: Does the paper describe potential risks incurred by study participants, whether
such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
approvals (or an equivalent approval/review based on the requirements of your country or
institution) were obtained?
Answer: [NA] .
Justification: The paper does not involve crowdsourcing nor research with human subjects.
41