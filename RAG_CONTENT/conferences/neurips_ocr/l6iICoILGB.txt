Practical 0.385-Approximation for Submodular
Maximization Subject to a Cardinality Constraint
Murad Tukan
DataHeroes Israel
murad@dataheroes.aiLoay Mualem
Department of Computer Science
University of Haifa
Haifa Israel
loaymual@gmail.com
Moran Feldman
Department of Computer Science
University of Haifa
Haifa Israel
moranfe@cs.haifa.ac.il
Abstract
Non-monotone constrained submodular maximization plays a crucial role in various
machine learning applications. However, existing algorithms often struggle with a
trade-off between approximation guarantees and practical efficiency. The current
state-of-the-art is a recent 0.401-approximation algorithm, but its computational
complexity makes it highly impractical. The best practical algorithms for the
problem only guarantee 1/e-approximation. In this work, we present a novel
algorithm for submodular maximization subject to a cardinality constraint that
combines a guarantee of 0.385-approximation with a low and practical query
complexity of O(n+k2), where nis the size of the ground set and kis the maximum
size of a feasible solution. Furthermore, we evaluate the empirical performance of
our algorithm in experiments based on the machine learning applications of Movie
Recommendation, Image Summarization, and Revenue Maximization. These
experiments demonstrate the efficacy of our approach.
1 Introduction
In the last few years, the ability to effectively summarize data has gained importance due to the
advent of massive datasets in many fields. Such summarization often consists of selecting a small
representative subset from a large corpus of images, text, movies, etc. Without a specific structure, this
task can be as challenging as finding a global minimum of a non-convex function. Fortunately, many
practical machine learning problems exhibit some structure, making them suitable for optimization
techniques (either exact or approximate).
A key structure present in many such problems is submodularity, also known as the principle of
diminishing returns. This principle suggests that the incremental value of an element decreases
as the set it is added to grows. Submodularity enables the creation of algorithms that can provide
near-optimal solutions, making it fundamental in machine learning. It has been successfully applied to
various tasks, such as social graph analysis [ 39], adversarial attacks [ 26,36], dictionary learning [ 13],
data summarization [ 32,34,35], interpreting neural networks [ 14], robotics [ 45,41], and many more.
To exemplify the notion of submodularity, consider the following task. Given a large dataset, our goal
is to identify a subset that effectively summarizes (or covers) the data, with a good representative
38th Conference on Neural Information Processing Systems (NeurIPS 2024).set being one that covers the majority of the data. Note that adding an element sto a set Bis less
beneficial to this goal than adding it to a subset A⊂Bdue to the higher likelihood of overlapping
coverage. Formally, if Nis the set of elements in the dataset, and we define a function f: 2N→R
mapping every set of elements to its coverage, then, the above discussion implies that, for every
two sets A⊆B⊆ N and element s∈ N \ B, it must hold that f(s|A)≥f(s|B), where
f(s|A)≜f({s} ∪A)−f(A)denotes the marginal gain of the element swith respect to the set A.
We say that a set function is submodular if it obeys this property.
Unfortunately, maximizing submodular functions is NP-hard even without a constraint [ 16], and
therefore, works on maximization of such functions aim for approximations. Many of these works
make the extra assumption that the submodular function f: 2N→Rismonotone , i.e., that for every
two sets A⊆B⊆ N , it holds that f(B)≥f(A). Two of the first works of this kind, by Nemhauser
and Wolsey [ 37] and Nemhauser et al. [ 38], showed that a greedy algorithm achieves a tight 1−1/e
approximation for the problem of maximizing a non-negative monotone submodular function subject
to a cardinality constraint using O(nk)function evaluations, where nis the size of the ground set N
andkis the maximum cardinality allowed for the output set. An important line of work aimed to
improve the time complexity of the last algorithm, culminating with deterministic and randomized
algorithms that have managed to reduce the time complexity to linear at the cost of an approximation
guarantee that is worse only by a factor of 1−ε[6, 31, 27, 22, 20].
Unfortunately, the submodular functions that arise in machine learning applications are often non-
monotone, either because they are naturally non-monotone, or because a diversity-promoting non-
monotone regularizer is added to them. Maximizing a non-monotone submodular function is chal-
lenging. The only tight approximation known for such functions is for the case of unconstrained
maximization, which enjoys a tight approximation ratio of 1/2[16,7]. A slightly more involved case
is the problem of maximizing a non-negative (not necessarily monotone) submodular function subject
to a cardinality constraint. This problem has been studied extensively. First, Lee et al. [ 25] suggested
an algorithm guaranteeing (1/4−ε)-approximation for it. This approximation ratio was improved in
a long series of works [ 5,11,15,43], leading to a very recent 0.401-approximation algorithm due to
Buchbinder and Feldman [ 4], which improved over a previous 0.385-approximation algorithm due to
Buchbinder and Feldman [ 3]. On the inapproximability side, it has been shown that no algorithm can
guarantee a better approximation ratio than 0.478in polynomial time [40].
Most of the results in the above-mentioned line of work are only of theoretical interest due to a very
high time complexity. The two exceptions are the Random Greedy algorithm of Buchbinder et al. [ 5]
that guarantees 1/e-approximation using O(nk)queries to the objective function, and the Sample
Greedy algorithm of Buchbinder et al. [ 6] that reduces the query complexity to Oε(n)at the cost of a
slightly worse approximation ratio of 1/e−ε.
1.1 Our contribution
In this work, we introduce a novel combinatorial algorithm for maximizing a non-negative submodular
function subject to a cardinality constraint. Our suggested method combines a practical query
complexity of O(n+k2)with an approximation guarantee of 0.385, which improves over the
1/e-approximation of the state-of-the-art practical algorithm. To emphasize the effectiveness of
our suggested method, we empirically evaluate it on 3applications: (i) Movie Recommendation,
(ii) Image Summarization, and (iii) Revenue Maximization. Our experiments on these applications
demonstrate that our algorithm (Algorithm 3) outperforms the current practical state-of-the-art
algorithms.
Remark. An independent work that recently appeared on arXiv [ 12] suggests another 0.385-
approximation algorithm for our problem using O(nk)oracle queries. Interestingly, their algorithm
is very similar to a basic version of our algorithm presented in Appendix A. In this work, our main
goal is to find ways to speed up this basic algorithm, which leads to our main result. In contrast, the
main goal of [12] is to derandomize the basic algorithm and extend it to other constraints.
1.2 Additional notation
Let us define some additional notation used throughout the paper. Given an element u∈ N and a set
S⊆ N , we use S+uandS−uas shorthands for S∪ {u}andS\ {u}, respectively. Given also a
set function f: 2N→R, we recall that f(u|S)is used to denote the marginal contribution of uto
2S. Similarly, given an additional set T⊆ N , we define f(T|S)≜f(S∪T)−f(S). Finally, we
denote by OPT an arbitrary optimal solution for the problem we consider.
2 Method
In this section, we present our algorithm for non-monotone submodular maximization under car-
dinality constraints, which is the algorithm used to prove the main theoretical result of our work
(Theorem 2.3). We begin with a brief overview of our algorithm. Motivated by the ideas underlying
the impractical 0.385-approximation algorithm of [3], our algorithm comprises three steps:
1.Initial Solution: We start by searching for a good initial solution that guarantees a constant
approximation to the optimal set. This is accomplished by running the recent deterministic
1/4-approximation algorithm of Balkanski et al. [2].1
2.Accelerated Local Search (Algorithm 1): Next, the algorithm aims to find an (approximate)
local optimum set Zusing a local search method. This can be done using a classical local
search algorithm at the cost of Oε(nk2)queries (see Appendix A for more detail). As
an alternative, we introduce, in Subsection 2.1, our accelerated local search algorithm
FAST-LOCAL -SEARCH (Algorithm 1), which reduces the query complexity to Oε(n+k2).
3.Accelerated Stochastic Greedy Improvement (Algorithm 2): It can be shown that when
the set Zdoes not have a good value, it contains only little of the value of the optimal
solution, and at the same time, it contains many of the elements that negatively affects this
optimal solution. Thus, it makes sense to try to avoid this set. Accordingly, after obtaining
the set Z, our algorithm constructs a second possible solution using a stochastic greedy
algorithm that picks only elements of N \Zin its first iterations. One can use for this
purpose a version of the Random Greedy algorithm suggested by Buchbinder et al. [ 5] that
usesO(nk)queries (see Appendix A for details). To get the same result using fewer queries,
we employ Algorithm 2 (described in Subsection 2.2), which is accelerated using ideas
borrowed from the Sample Greedy algorithm of [6].
Our final algorithm (given as Algorithm 3 in Subsections 2.3) returns the better among the two sets
produced in the last two steps (i.e., the output sets of Algorithm 1, and Algorithm 2). Intuitively, this
algorithm guarantees our target approximation ratio of 0.385because when f(Z)is smaller than this
value, the set Zis bad enough that avoiding it (in the first iterations) allows Algorithm 2 to get a good
enough solution.
2.1 Fast local search
In this section, we present our accelerated local search algorithm, which is the algorithm used to
implement the first two steps of our main algorithm. The properties of this algorithm are formally
given by Theorem 2.1. Let OPT be an optimal solution.
Theorem 2.1. There exists an algorithm that given a positive integer k, a value ε∈(0,1), and a
non-negative submodular function f: 2N→R≥0, outputs a set S⊆ N of size at max kthat, with
probability at least 1−ε, obeys
f(S)≥f(S∩OPT) +f(S∪OPT)
2 +εand f(S)≥f(S∩OPT)
1 +ε.
Furthermore, the query complexity of the above algorithm is Oε(n+k2).
Note that the guarantee of Theorem 2.1 is similar to the guarantee of a classical local search algorithm
(see Appendix A for details). However, such a classical local search algorithm uses Oε(nk2)queries,
which is higher than the number of queries required for the algorithm from Theorem 2.1.
We defer the formal proof of Theorem 2.1 to Appendix B. However, we note that this proof is based
on Algorithm 1. Algorithm 1 implicitly assumes that the ground set Nincludes at least k+ 1dummy
1A previous version of this paper used for this purpose the randomized Sample Greedy algorithm of [ 6].
Since this algorithm is randomized, to get a good solution with a high enough probability, that previous version
had to run this algorithm O(logε−1)times and select the solution with the highest function value. The code in
the supplemental material of this paper includes the option to use either of these initialization options.
3elements that always have a zero marginal contribution to f. Such elements can always be added to
the ground set (before executing the algorithm) without affecting the properties of f, and removing
them from the output set of the algorithm does not affect the guarantee of Theorem 2.1.
Algorithm 1: FAST-LOCAL -SEARCH (k, f, ε, L )
input : A positive integer k≥1, a submodular function f, an approximation factor ε∈(0,1), and a
number Lof iterations.
output : A subset of Nof cardinality at most k.
1Initialize S0to be a feasible solution that with probability at least 1−εprovides c-approximation for
the problem for some constant c∈(0,1].
2FillS0with dummy elements to ensure |S0|=k.
3forj= 1to⌈log21
ε⌉do
4 LetSj
0←S0.
5 fori= 1toLdo
6 Zj
i←Samplen
kitems from Nuniformly at random.
7 uj
i←arg maxu′∈Zj
if(uj
i|Sj
i−1).
8 iff(uj
i|Sj
i−1)≤0then uj
i←dummy element that does not belong to Sj
i−1.
9 vj
i←arg minv′∈Sj
i−1f(v′|Sj
i−1−v′).
10 iff(Sj
i−1)< f(Sj
i−1−vj
i+uj
i)then Sj
i←Sj
i−1−vj
i+uj
i.
11 elseSj
i←Sj
i−1.
12 Pick a uniformly random integer 0≤i∗< L.
13 iffor every integer 0≤t≤kit holds that
max
S⊆N\ Sj
i∗,|S|=tP
u∈Sf(u|Sj
i∗)≤ min
S⊆Sj
i∗,|S|=tP
v∈Sf(v|Sj
i∗−v) +εf(Sj
i∗)then return Sj
i∗.
14return FAILURE.
Algorithm 1 starts by finding an initial solution S0guaranteeing constant approximation (we imple-
ment this step using the deterministic 1/4-approximation algorithm of Balkanski et al. [ 2]). If the
size of the initial solution is less than k(i.e.,|S0|< k), the algorithm adds to it k− |S0|dummy
elements. Then, Algorithm 1 makes roughly log2ε−1attempts to find a good output. Each attempt
trys to improve the (same) initial solution using Literations. Each iteration consisting of three steps:
In Step (i), the algorithm samplesn
kitems, and picks the element ufrom the sample with the largest
marginal contribution to the current solution Si−1. If there are no elements in the sample with a
positive marginal contribution, the algorithm picks a dummy element outside Si−1asu. In Step (ii),
the algorithm picks the element v∈Si−1that has the lowest marginal value, i.e., the element whose
removal from Si−1would lead to the smallest drop in value. In Step (iii), the algorithm swaps
the elements uandvif such a swap increases the value of the current solution. Once Literations
are over, the algorithm picks a uniformly random solution among all the solutions seen during this
attempt (recall that the algorithm makes roughly log2ε−1attempts to find a good solution). If the
random solution found obeys the technical condition given on Line 13, then the algorithm returns
it. Otherwise, the algorithm continues to the next attempt. If none of the attempts returns a set, the
algorithm admits failure.
2.2 Guided stochastic greedy
In this section, we prove Theorem 2.2, which provides the last step of our main algorithm.
Theorem 2.2. There exists an algorithm that given a positive integer k, a value ε∈(0,1), a value
ts∈[0,1], a non-negative submodular function f: 2N→R≥0, and a set Z⊆ N obeying the
inequalities stated in Theorem 2.1, outputs a solution Sk, obeying
E[f(Sk)]≥k− ⌈ts·k⌉
kαk−⌈ts·k⌉−1+αk−⌈ts·k⌉−αk
f(OPT)+
+
αk+αk−1−2k− ⌈ts·k⌉
kαk−⌈ts·k⌉−1
f(OPT∪Z)
+ (αk−αk−⌈ts·k⌉)f(OPT∩Z)−2εf(OPT),
4where α≜1−1/k. Moreover, this algorithm requires only Oε(n)queries to the objective function.
The algorithm used to prove Theorem 2.2 is Algorithm 2. This algorithm starts with an empty set and
adds elements to it in iterations (at most one element per iteration) until its final solution is ready after
kiterations. In its first ⌈k·ts⌉iterations, the algorithm ignores the elements of Z, and in the other
iterations, it considers all elements. However, except for this difference, the behavior of the algorithm
in all iterations is very similar. Specifically, in each iteration ithe algorithm does the following two
steps. In Step (i), the algorithm samples a subset Micontaining Oε(n/k)elements from the data. In
Step (ii), the algorithm considers a subset of Mi(of size either s1⌈p(n− |Z|)⌉ors2⌈pn⌉) containing
the elements of Miwith the largest marginal contributions with respect to the current solution Si−1,
and adds a uniformly random element out of this subset to the solution (if this element has a positive
marginal contribution).
Algorithm 2: Guided Stochastic Greedy
input : A set Z⊆ N , a positive integer k≥1, values ε∈(0,1)andts∈[0,1], and a non-negative
submodular function f
output : A set Sk⊆ N
1Initialize S0← ∅.
2Define p←min{1,8k−1ε−2ln(2ε−1)}.
3Define s1←k/(n− |Z|)ands2←k/n.
4fori= 1to⌈k·ts⌉do
5 LetMi⊆ N \ Zbe a uniformly random set containing ⌈p·(n− |Z|)⌉elements.
6 Letdibe uniformly random scalar from the range (0, s1⌈p·(n− |Z|)⌉].
7 Letuibe an element of Miassociated with the ⌈di⌉-th largest marginal contribution to Si−1(if
⌈di⌉>|Mi|, we set uito be a dummy element having 0marginal contribution to f).
8 iff(ui|Si−1)≥0then
9 Si←Si−1∪ {ui}.
10 else
11 Si←Si−1.
12fori=⌈k·ts⌉+ 1tokdo
13 LetMi⊆ N be a uniformly random set containing ⌈p·n⌉elements.
14 Letdibe uniformly random scalar from the range (0, s2⌈p·n⌉].
15 Letuibe an element of Miassociated with the ⌈di⌉-th largest marginal contribution to Si−1.
16 iff(ui|Si−1)≥0then Si←Si−1∪ {ui}.
17 elseSi←Si−1.
18return Sk.
2.3 0.385-Approximation guarantee
In this section, our objective is to prove the following theorem.
Theorem 2.3. Given an integer k≥1and a non-negative submodular function f: 2N→R≥0,
there exists an 0.385-approximation algorithm for the problem of finding a set S⊆ N of size at most
kmaximizing f. This algorithm uses O(n+k2)queries to the objective function.
The algorithm used to prove Theorem 2.3 is Algorithm 3. Our technical guarantee for Algorithm 3
is given as Lemma 2.4. When kis large enough, this lemma immediately implies Theorem 2.3
by choosing εto be a small enough positive constant. If kis small, getting Theorem 2.3 from
Lemma 2.4 requires a three steps process. First, we choose an integer constant ρsuch that ρkis large
enough, and we create a new ground set Nρ={ui|u∈ N, i∈[ρ]}and a new objective function
g: 2Nρ→Rdefined as g(S) =E[f(R(S))],where R(S)is a random subset of Nthat includes
every element u∈ N with probability |S∩({u} ×[ρ])|/ρ. Then, we use Lemma 2.4 to get a set
ˆSthat provides 0.385-approximation for the problem max{g(S)| |S| ≤ρk}. Finally, the Pipage
Rounding technique of [ 8] can be used to get from ˆSa0.385-approximation for our original problem.
Notice that since the size of ˆSis constant (as we consider the case of a small k), this rounding can be
done using a constant number of queries to the objective.
Lemma 2.4. Algorithm 3 makes Oε(n+k2)queries to the objective function, and returns a set
whose expected value is at least (c−O(ε+k−1))f(OPT)for some constant c >0.385.
5Algorithm 3: A0.385-approximation algorithm for submodular maximization
input : A positive integer k≥1, a non-negative submodular function f, error parameter ε∈(0,1),
and a flip point 0≤ts≤1
output : A set SL⊆ N
1Z←FAST-LOCAL -SEARCH (k, f, ε, L :=⌈2k/(ε(1−1/e))⌉.
2ifthe last algorithm did not fail then
3 A←GUIDED -STOCHASTIC -GREEDY (Z, k, t s, ε).
4 return the set maximizing famong ZandA.
5else return ∅.
Proof. According to the proof of Theorem 2.1, our choice of the parameter Lin Algorithm 1
guarantees that with probability at least 1−εthe set Zobeys the inequalities
f(Z)≥f(Z∪OPT) +f(Z∩OPT)
2 +εand f(Z)≥f(Z∩OPT)
1 +ε.
Let us denote by Ethe event that these inequalities hold. By Theorem 2.2,
E[f(A)| E]≥k− ⌈ts·k⌉
kαk−⌈ts·k⌉−1+αk−⌈ts·k⌉−αk
f(OPT)+
+
αk+αk−1−2k− ⌈ts·k⌉
kαk−⌈ts·k⌉−1
E[f(OPT∪Z)| E]
+ (αk−αk−⌈ts·k⌉)E[f(OPT∩Z)| E]−2εf(OPT).
Since the output of Algorithm 2 is the better set among AandZ, we can lower bound its value by
any convex combination of lower bounds on the values of AandZ. More formally, if we denote by
p1,p2andp3any three non-negative values that add up to 1, then we get
E[max{f(A), f(Z)} | E]≥p3k− ⌈ts·k⌉
kαk−⌈ts·k⌉−1+αk−⌈ts·k⌉−αk
f(OPT)
+p1
2 +ε+p3
αk+αk−1−2k− ⌈ts·k⌉
kαk−⌈ts·k⌉−1
E[f(OPT∪Z)| E]
+p2
1 +ε+p1
2 +ε−p3
αk−⌈ts·k⌉−αk
E[f(OPT∩Z)| E]−2εp3f(OPT).(1)
To simplify the above inequality, we need to bound some of the terms in it. First,
k− ⌈ts·k⌉
kαk−⌈ts·k⌉−1+αk−⌈ts·k⌉−αk≥
2−ts−1
k
αk(1−ts)−αk
≥
2−ts−1
k
ets−1
1−1
k1−ts
−e−1
≥
2−ts−3
k
ets−1−e−1≥ 
2−ts−e−ts
ets−1−3
k,
where the first inequality holds since ⌈ts·k⌉ ≤ts·k+ 1,α≤1, the second inequality follows since
αk(1−ts)≥ets−1 
1−1
k1−ts, and the last inequality holds since ets−1≤1. Second,
αk+αk−1−2k− ⌈ts·k⌉
kαk−⌈ts·k⌉−1≥2e−1−2k−ts·k
kαk−ts·k−2−2e−1
k
≥2e−1−(2−ts)ets−1−8 + 2 e−1
k
=−ets−1 
2−ts−2e−ts
−8 + 2 e−1
k,
where the first inequality holds since αk−1≥αk≥e−1 
1−1
k
, and the second inequality holds
since αk−ts·k−2≤ets−1+4/k. Finally, it holds that αk−αk−⌈ts·k⌉≥e−1(1−1
k)−ets−1/(1−1
k)≥
e−1(1−1
k)−ets−1(1 +1
k)≥ −ets−1(1−e−ts)−2
k.
6Plugging all the above lower bounds into Inequality (1)yields the promised simplified guarantee that
E[max{f(A), f(Z)} | E]≥p3 
2−ts−e−ts
ets−1f(OPT)−O(ε+k−1)f(OPT)
+p1
2 +ε−p3ets−1 
2−ts−2e−ts
−O(k−1)
E[f(OPT∪Z)| E]
+p2
1 +ε+p1
2 +ε−p3ets−1 
1−e−ts
−O(k−1)
E[f(OPT∩Z)| E].
By [3], for an appropriate choice of values for p1,p2,p3andtsthe last inequality implies
E[max{f(A), f(Z)} | E]≥(c−O(ε+k−1))f(OPT)
−O(k−1)·E[f(OPT∪Z) +f(OPT∩Z)](2)
for some constant c >0.385. To get from the last inequality the bound on E[max{f(A), f(Z)} | E]
stated in the lemma, we need to show that the conditioning on Eand the last term of the inequality
can both be dropped. To see why the conditioning can be dropped, note that the event Ehappens with
probability at least 1−ε, and when it does not happen the set returned by the algorithm still has a non-
negative value. These observations show together that removing the conditioning on Ein Inequality (2)
only affects the constant inside the big Onotation. Notice now that since OPT∩Z⊆OPT is
always a feasible solution, it deterministically holds that f(OPT∩Z)≤f(OPT). Similarly, since
Zis a feasible solution, the submodularity of fguarantees that f(OPT∪Z) +f(OPT∩Z)≤
f(OPT) +f(Z)≤2f(OPT). These two bounds allow us to drop the last term of Inequality (2)at
the cost of increasing (again) the constant inside the big Onotation.
To complete the proof of the lemma, note that Line 1 of Algorithm 3 requires Oε 
n+k2
queries to
the objective function as shown in the proof of Theorem 2.1, while Line 3 of Algorithm 3 requires
Oε(n)queries to the objective function as dictated by Theorem 2.2.
3 Experiments
To emphasize the effectiveness of our suggested method from Section 2, in this section, we empirically
compare Algorithm 3 with two benchmark algorithms on three machine-learning applications: movie
recommendation, image summarization, and revenue maximization. Each one of these applications
necessitates maximization of a non-monotone submodular function. The benchmark algorithms we
consider are the Random Greedy algorithm of Buchbinder et al. [ 5], and the Random Sampling
algorithm of [ 6]. These algorithms are the current state-of-the-art practical algorithms for maximizing
non-monotone submodular functions.
As stated, Algorithm 2 requires O(n·lnε−1
ε2)queries to the objective function, where the dependence
onεcomes from the choice of value for the parameter pof the algorithm. However, we have found
out that in practice a more modest choice of value for psuffices. Specifically, in our experiments, we
have replaced Line 2 of Algorithm 2 with p←min{1,8
k·ε}. Throughout the experiments, we have
setε= 0.1; and all the reported results are averaged across 8executions. We use shades in our plots
to depict the standard deviations of the individual results obtained in these 8executions.
Software/Hardware . Our algorithms were implemented in Python 3.11 using mainly “Numpy” [ 19],
and Numba [ 23]. The implementations’ code can be found at https://github.com/muradtuk/
385ApproximationSubMax . The experiments were performed on a 2.2GHz i9-13980HX (24 cores
total) machine with 64GB RAM.
3.1 Personalized movie recommendation
Consider a movie recommendation system in which each user specifies what genres they are interested
in, and the system has to provide a representative subset of movies from these genres. Assume that
each movie is represented by a vector consisting of users’ ratings for the corresponding movie.
One challenge here is that each user does not necessarily rate all the movies. Hence, the vectors
representing the movies do not necessarily have similar sizes. To overcome this challenge, low-rank
matrix completion techniques [ 9] can be performed on the matrix with missing values to obtain a
complete rating matrix. Formally, given a few ratings from kusers to nmovies we obtain in this
way a rating matrix Mof size k×n. Following [ 33,30], to score the quality of a selected subset of
7movies, we use the function f(S) =P
u∈NP
v∈Ssu,v−λP
u∈SP
v∈Ssu,v. Here, Nis the set
ofnmovies, λ∈[0,1]is a parameter and su,vdenotes the similarity between movies uandv(the
similarity su,vcan be calculated based on the matrix Min multiple ways: cosine similarity, inner
product, etc). Note that the first term in f’s definition captures the coverage, while the second term
captures diversity. Thus, the parameter λcontrols the importance of diversity in the returned subset.
For any λ≤0.5,f(S)is monotone [34], however, it can be non-monotone for larger values of λ.
We followed the experimental setup of the prior works [ 33,30] and used a subset of movies from the
MovieLens data set [ 18] which includes 10,437movies. Each movie in this data set is represented by
a25dimensional feature vector calculated using user ratings, and we used the inner product similarity
to obtain the similarity values su,vbased on these vectors. When experimenting with this application,
we fixed λto be either 0.55or0.75, and varied k.
20 40 60 80 1003.92k5.88k7.85k9.81k11.77k
Algorithm 3
Buchbinder et al. 2017
Buchbinder et al. 2014
kFunction value
(a) Function values for λ= 0.75.
20 40 60 80 1005.35k7.14k8.92k10.7k12.49k
Algorithm 3
Buchbinder et al. 2017
Buchbinder et al. 2014
kFunction value (b) Function values for λ= 0.55.
20 40 60 80 1000.213M0.425M0.638M0.85M1.063MAlgorithm 3
Buchbinder et al. 2017
Buchbinder et al. 2014
kOracle calls
(c) Number of queries for λ= 0.75.
20 40 60 80 1000.213M0.425M0.638M0.85M1.063MAlgorithm 3
Buchbinder et al. 2017
Buchbinder et al. 2014
kOracle calls (d) Number of queries for λ= 0.55.
Figure 1: Experimental results for Personalized Movie Recommendation. Plots (a) and (b) compare
the output of our algorithm with the benchmark algorithms mentioned at the beginning of Section 3
for a particular value of the parameter λand a varying number kof movies. Plots (c) and (d) compare
the number of queries used by the various algorithms.
The results of these experiments are depicted in Figure 1. One can observe that our proposed
method, Algorithm 3, demonstrates superior performance compared to the other methods. Moreover,
this performance is stable, and presents a much smaller variance compared to the variance in the
performance of the two benchmark algorithms. The number of queries used by our algorithm is only
slightly larger than the number of queries used by the Random Sampling algorithm of [ 6], and is
typically smaller than the number of queries used by the Random Greedy algorithm of Buchbinder et
al. [5], sometimes by as much as a factor of 2.
3.2 Personalized image summarization
Consider a setting in which we get as input a collection Nof images from ℓdisjoint categories (e.g.,
birds, dogs, cats) and the user specifies r∈[ℓ]categories, and then demands a subset of the images
in these categories that summarizes all the images of the categories. Following [ 30] again, to evaluate
a given subset of images, we use the function f(S) =P
u∈Nmax v∈Ssu,v−1
|N|P
u∈SP
v∈Ssu,v,
where su,vis a non-negative similarity between images uandv.
To obtain the similarity between pair of images u, v, we utilized the DINO-VITB16 model [ 10] from
HuggingFace [ 44] as the feature encoder for vision datasets. Specifically, the final layer CLS token
8embedding output was used as the feature representation. The similarity between pairs of images
was then computed as the cosine similarity of the corresponding embedding vectors. To experiment
in this setting, we used three datasets: (i) CIFAR10 [21] – A dataset of 50,000images belonging to
10different classes (categories). (ii) CIFAR100 [21] – A dataset of 50,000images belonging to 100
different classes. (iii) Tiny ImageNet [24] – A dataset of 100,000images belonging to 200different
classes. In each one of our experiments, the task was to summarize a set of 10,000images sampled
uniformly from one of these datasets. The upper bound kon the number images allowed in the
summary varied between experiments. The results of our experiments are depicted in Figure 2.
Similarly to Section 3.1, we observe that our algorithm (Algorithm 3) produces higher values
compared to the state-of-the-art practical algorithms, and enjoys a lower variance in the quality of
its output. However, due to the small values used for k, our algorithm requires significantly more
queries to the objective function compared to the two other algorithms.
2 4 6 8 1082508360847085808690
Algorithm 3
Buchbinder et al. 2017
Buchbinder et al. 2014
kFunction value
(a) Function values for the CIFAR10 dataset.
2 4 6 8 1082808400852086408760
Algorithm 3
Buchbinder et al. 2017
Buchbinder et al. 2014
kFunction value (b) Function values for the CIFAR100 dataset.
2 4 6 8 1091209240936094809600
Algorithm 3
Buchbinder et al. 2017
Buchbinder et al. 2014
kFunction value
(c) Function values for the Tiny ImageNet dataset.
2 4 6 8 1027.6k55.2k82.7k110.3k137.9k Algorithm 3
Buchbinder et al. 2017
Buchbinder et al. 2014
kOracle calls (d) Number of queries for the CIFAR10 dataset.
2 4 6 8 1027.6k55.2k82.7k110.3k137.9k Algorithm 3
Buchbinder et al. 2017
Buchbinder et al. 2014
kOracle calls
(e) Number of queries for the CIFAR100 dataset.
2 4 6 8 1027.6k55.2k82.7k110.3k137.9k Algorithm 3
Buchbinder et al. 2017
Buchbinder et al. 2014
kOracle calls (f) Number of queries for the Tiny ImageNet dataset.
Figure 2: Experimental results for Personalized Image Summarization. Plots (a)–(c) compare the
output of our algorithm with the benchmark algorithms mentioned at the beginning of Section 3 for a
varying number kof images. Each plot corresponds to a different dataset. Plots (d)–(f) compare the
number of queries used by the various algorithms.
3.3 Revenue maximization
Consider a company whose objective is to promote a product to users to boost revenue through the
“word-of-mouth” effect. More specifically, given a social network, we need to choose a subset of
9up to kusers to receive a product for free in exchange for advertising it to their network neighbors,
and the goal is to choose users in a manner that maximizes revenue. The problem of optimizing
this objective can be formalized as follows. The input is a weighted undirected graph G= (V, E)
representing a social network, where wijrepresents the weight of the edge between vertex iand
vertex j(with wij= 0if the edge (i, j)is absent from the graph). Given a set S⊆Vof users who
have become advocates for the product, the expected revenue generated is proportional to the total
influence of S’s users on non-advocate users, formally expressed as f(x) =P
i∈SP
j∈V\Swij. It
has been demonstrated that fis non-monotone and submodular [1].
20 40 60 80 1006601320198026403300
Algorithm 3
Buchbinder et al. 2017
Buchbinder et al. 2014
kFunction value
(a) Function values for Advogato network dataset.
1015202530354045504.59k6.88k9.17k11.47k13.76k
Algorithm 3
Buchbinder et al. 2017
Buchbinder et al. 2014
kFunction value (b) Function values for Facebook network dataset.
20 40 60 80 100133k265k398k530k663kAlgorithm 3
Buchbinder et al. 2017
Buchbinder et al. 2014
kOracle calls
(c) Number of queries for Advogato network dataset.
1015202530354045500.599M1.198M1.796M2.395M2.994MAlgorithm 3
Buchbinder et al. 2017
Buchbinder et al. 2014
kOracle calls (d) Number of queries for Facebook network dataset.
Figure 3: Experimental results for Revenue Maximization. Plots (a) and (b) compare the output of
our algorithm with the benchmark algorithms mentioned at the beginning of Section 3 for a varying
number kof images on the Advogato and Facebook network datasets. Plots (c) and (d) compare the
number of queries used by the various algorithms.
In our experiment, we compared the performance of Algorithm 3 and the two benchmark algorithms
on the Facebook network [ 42] and the Advogato network [ 29]. The results of this experiment are
depicted in Figure 3. Once again, our algorithm enjoys both better output values and lower standard
deviations compared to the benchmark algorithms. Our algorithm uses more queries compared to
the Random Sampling algorithm of [ 6], but the ratio between the number of queries used by the two
algorithms tends to decrease as kincreases. The behavior of the Random Greedy algorithm of [ 5]
greatly depends on k. For smaller values of kthis algorithm requires roughly as many queries as
Random Sampling, but for larger value of kit requires significantly more queries than our algorithm.
4 Conclusion
In this work, we have presented a novel algorithm for submodular maximization subject to cardinality
constraint that combines a practical query complexity of O(n+k2)with an approximation guarantee
of0.385, which improves over the 1/e-approximation of the state-of-the-art practical algorithms.
In addition to giving a theoretical analysis of our algorithm, we have demonstrated its empirical
superiority (compared to practical state-of-the-art methods) in various machine learning applications.
We hope future work will be able to improve the query complexity of our algorithm to be cleanly
linear without sacrificing either the approximation guarantee or the practicality of the algorithm.
10Acknowledgment
The work of Loay Mualem and Moran Feldman was supported in part by Israel Science Foundation
(ISF) grant number 459/20.
References
[1]Eric Balkanski, Adam Breuer, and Yaron Singer. Non-monotone submodular maximization in
exponentially fewer iterations. Advances in Neural Information Processing Systems , 31, 2018.
[2]Eric Balkanski, Steven DiSilvio, and Alan Kuhnle. Submodular maximization in exactly n
queries. CoRR , abs/2406.00148, 2024.
[3]Niv Buchbinder and Moran Feldman. Constrained submodular maximization via a nonsymmet-
ric technique. Mathematics of Operations Research , 44(3):988–1005, 2019.
[4]Niv Buchbinder and Moran Feldman. Constrained submodular maximization via new bounds
for dr-submodular functions. arXiv preprint arXiv:2311.01129 , 2023.
[5]Niv Buchbinder, Moran Feldman, Joseph Naor, and Roy Schwartz. Submodular maximization
with cardinality constraints. In Proceedings of the twenty-fifth annual ACM-SIAM symposium
on Discrete algorithms , pages 1433–1452. SIAM, 2014.
[6]Niv Buchbinder, Moran Feldman, and Roy Schwartz. Comparing apples and oranges: Query
trade-off in submodular maximization. Mathematics of Operations Research , 42(2):308–329,
2017.
[7]Niv Buchbinder, Moran Feldman, Joseph Seffi, and Roy Schwartz. A tight linear time (1/2)-
approximation for unconstrained submodular maximization. SIAM Journal on Computing ,
44(5):1384–1402, 2015.
[8]Gruia C ˘alinescu, Chandra Chekuri, Martin Pál, and Jan V ondrák. Maximizing a monotone
submodular function subject to a matroid constraint. SIAM J. Comput. , 40(6):1740–1766, 2011.
[9]Emmanuel J Candès and Benjamin Recht. Exact matrix completion via convex optimization.
Foundations of Computational mathematics , 9(6):717–772, 2009.
[10] Mathilde Caron, Hugo Touvron, Ishan Misra, Hervé Jégou, Julien Mairal, Piotr Bojanowski,
and Armand Joulin. Emerging properties in self-supervised vision transformers. In Proceedings
of the IEEE/CVF international conference on computer vision , pages 9650–9660, 2021.
[11] Chandra Chekuri, Jan V ondrák, and Rico Zenklusen. Submodular function maximization via the
multilinear relaxation and contention resolution schemes. SIAM J. Comput. , 43(6):1831–1879,
2014.
[12] Yixin Chen, Ankur Nath, Chunli Peng, and Alan Kuhnle. Guided combinatorial algorithms for
submodular maximization. arXiv preprint arXiv:2405.05202 , 2024.
[13] Abhimanyu Das and David Kempe. Submodular meets spectral: greedy algorithms for subset
selection, sparse approximation and dictionary selection. In ICML , pages 1057–1064, 2011.
[14] Ethan R. Elenberg, Alexandros G. Dimakis, Moran Feldman, and Amin Karbasi. Streaming
weak submodularity: interpreting neural networks on the fly. In NeurIPS , pages 4047–4057,
2017.
[15] Alina Ene and Huy L Nguyen. Constrained submodular maximization: Beyond 1/e. In 2016
IEEE 57th Annual Symposium on Foundations of Computer Science (FOCS) , pages 248–257.
IEEE, 2016.
[16] Uriel Feige, Vahab S. Mirrokni, and Jan V ondrák. Maximizing non-monotone submodular
functions. SIAM J. Comput. , 40(4):1133–1153, 2011.
11[17] Kai Han, Shuang Cui, Benwei Wu, et al. Deterministic approximation for submodular max-
imization over a matroid in nearly linear time. Advances in Neural Information Processing
Systems , 33:430–441, 2020.
[18] F. Maxwell Harper and Joseph A. Konstan. The movielens datasets: History and context. Acm
transactions on interactive intelligent systems (TiiS) , 5(4):1–19, 2015.
[19] Charles R. Harris, K. Jarrod Millman, Stéfan J van der Walt, Ralf Gommers, Pauli Virtanen,
David Cournapeau, Eric Wieser, Julian Taylor, Sebastian Berg, Nathaniel J. Smith, Robert Kern,
Matti Picus, Stephan Hoyer, Marten H. van Kerkwijk, Matthew Brett, Allan Haldane, Jaime
Fernández del Río, Mark Wiebe, Pearu Peterson, Pierre Gérard-Marchant, Kevin Sheppard,
Tyler Reddy, Warren Weckesser, Hameer Abbasi, Christoph Gohlke, and Travis E. Oliphant.
Array programming with NumPy. Nature , 585:357–362, 2020.
[20] Chien-Chung Huang and Naonori Kakimura. Multi-pass streaming algorithms for monotone
submodular function maximization. Theory of Computing Systems , 66(1):354–394, 2022.
[21] Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images.
Technical report, University of Toronto, Toronto, Ontario, Canada, 2009.
[22] Alan Kuhnle. Quick streaming algorithms for maximization of monotone submodular functions
in linear time. In International Conference on Artificial Intelligence and Statistics , pages
1360–1368. PMLR, 2021.
[23] Siu Kwan Lam, Antoine Pitrou, and Stanley Seibert. Numba: A llvm-based python jit compiler.
InProceedings of the Second Workshop on the LLVM Compiler Infrastructure in HPC , pages
1–6, 2015.
[24] Ya Le and Xuan Yang. Tiny imagenet visual recognition challenge. CS 231N , 7(7):3, 2015.
[25] Jon Lee, Vahab S. Mirrokni, Viswanath Nagarajan, and Maxim Sviridenko. Non-monotone
submodular maximization under matroid and knapsack constraints. In Michael Mitzenmacher,
editor, Proceedings of the 41st Annual ACM Symposium on Theory of Computing (STOC) , pages
323–332. ACM, 2009.
[26] Qi Lei, Lingfei Wu, Pin-Yu Chen, Alex Dimakis, Inderjit S. Dhillon, and Michael J. Witbrock.
Discrete adversarial attacks and submodular optimization with applications to text classification.
In Ameet Talwalkar, Virginia Smith, and Matei Zaharia, editors, MLSys . mlsys.org, 2019.
[27] Wenxin Li, Moran Feldman, Ehsan Kazemi, and Amin Karbasi. Submodular maximization in
clean linear time. Advances in Neural Information Processing Systems , 35:17473–17487, 2022.
[28] László Lovász. Submodular functions and convexity. In A. Bachem, M. Grötschel, and B. Korte,
editors, Mathematical Programming: the State of the Art , pages 235–257. Springer, 1983.
[29] Paolo Massa, Martino Salvetti, and Danilo Tomasoni. Bowling alone and trust decline in
social network sites. In IEEE International Conference on Dependable, Autonomic and Secure
Computing (DASC) , pages 658–663. IEEE Computer Society, 2009.
[30] Baharan Mirzasoleiman, Ashwinkumar Badanidiyuru, and Amin Karbasi. Fast constrained
submodular maximization: Personalized data summarization. In ICML , pages 1358–1367.
PMLR, 2016.
[31] Baharan Mirzasoleiman, Ashwinkumar Badanidiyuru, Amin Karbasi, Jan V ondrák, and An-
dreas Krause. Lazier than lazy greedy. In Proceedings of the AAAI Conference on Artificial
Intelligence , pages 1812–1818. AAAI Press, 2015.
[32] Marko Mitrovic, Ehsan Kazemi, Morteza Zadimoghaddam, and Amin Karbasi. Data sum-
marization at scale: A two-stage submodular approach. In ICML , pages 3596–3605. PMLR,
2018.
[33] Loay Mualem and Moran Feldman. Using partial monotonicity in submodular maximization.
Advances in Neural Information Processing Systems , 35:2723–2736, 2022.
12[34] Loay Mualem and Moran Feldman. Resolving the approximability of offline and online non-
monotone dr-submodular maximization over general convex sets. In International Conference
on Artificial Intelligence and Statistics , pages 2542–2564. PMLR, 2023.
[35] Loay Mualem, Murad Tukan, and Moran Fledman. Bridging the gap between general and
down-closed convex sets in submodular maximization. arXiv preprint arXiv:2401.09251 , 2024.
[36] Loay Raed Mualem, Ethan R Elenberg, Moran Feldman, and Amin Karbasi. Submodular mini-
max optimization: Finding effective sets. In International Conference on Artificial Intelligence
and Statistics , pages 1081–1089. PMLR, 2024.
[37] George L Nemhauser and Laurence A Wolsey. Best algorithms for approximating the maximum
of a submodular set function. Mathematics of operations research , 3(3):177–188, 1978.
[38] George L Nemhauser, Laurence A Wolsey, and Marshall L Fisher. An analysis of approximations
for maximizing submodular set functions—i. Mathematical programming , 14:265–294, 1978.
[39] Ashkan Norouzi-Fard, Jakub Tarnawski, Slobodan Mitrovic, Amir Zandieh, Aidasadat Mousav-
ifar, and Ola Svensson. Beyond 1/2-approximation for submodular maximization on massive
data streams. In ICML , pages 3829–3838. PMLR, 2018.
[40] Benjamin Qi. On maximizing sums of non-monotone submodular and linear functions. In
Sang Won Bae and Heejin Park, editors, International Symposium on Algorithms and Computa-
tion (ISAAC) , volume 248 of LIPIcs , pages 41:1–41:16. Schloss Dagstuhl - Leibniz-Zentrum
für Informatik, 2022.
[41] Murad Tukan, Fares Fares, Yotam Grufinkle, Ido Talmor, Loay Mualem, Vladimir Braverman,
and Dan Feldman. Orbslam3-enhanced autonomous toy drones: Pioneering indoor exploration.
arXiv preprint arXiv:2312.13385 , 2023.
[42] Bimal Viswanath, Alan Mislove, Meeyoung Cha, and Krishna P Gummadi. On the evolution
of user interaction in facebook. In Proceedings of the 2nd ACM workshop on Online social
networks , pages 37–42, 2009.
[43] Jan V ondrák. Symmetry and approximability of submodular maximization problems. SIAM J.
Comput. , 42(1):265–304, 2013.
[44] T Wolf. Huggingface’s transformers: State-of-the-art natural language processing. arXiv
preprint arXiv:1910.03771 , 2019.
[45] Lifeng Zhou and Pratap Tokekar. Risk-aware submodular optimization for multirobot coordina-
tion. IEEE Transactions on Robotics , 38(5):3064–3084, 2022.
13A A warmup version of our algorithm
In this section, we present and analyze a simpler version of our algorithm with the same general
structure, but excluding the speedup techniques used to obtain our main result. Inspired by Buchbinder
et al. [ 3], and similar to Algorithm 3, this simpler version (given as Algorithm 6) comprises three
steps: (i) Searching for a good initial solution that guarantees a constant approximation to the optimal
set. This is accomplished by running the Twin Greedy algorithm of [ 17], (ii) Finding an (approximate)
local search optimum set Zusing a local search method. In this simple version, we use the classical
local search algorithm for this purpose, which requires O(nk2)queries to the objective function.
(iii) Lastly, we construct another solution using a version of the Random Greedy algorithm suggested
by Buchbinder et al. [ 5] that avoids elements of the set Zin its first iterations. The algorithm
terminates by outputting the better of the two solutions generated in the last two steps.
A.1 Local search
In this section, we present (as Algorithm 4) a simple local search algorithm, which is the algorithm
used to implement the first two steps of Algorithm 6. Algorithm 4 begins by finding an initial solution
Susing the Twin Greedy algorithm of [ 17]. The algorithm then proceeds as follows: (i) If |S|< k, it
checks for an element usuch that adding utoSincreases the function value by at least (1 +ε
2k)f(S).
If such an element is found, it is added to S. (ii) If |S|=k, it looks for two elements u∈ N \ S
andv∈Ssuch that swapping uandv(i.e., removing vfrom Sand adding utoS) increases the
function value by at least (1 +ε
2k)f(S). If such elements exist, the algorithm performs the swap.
(iii) If no elements satisfy the previous two conditions, the algorithm checks for an element vsuch
that removing vfromSincreases the function value by (1 +ε
2k)f(S). If such an element is found, it
is removed from S. Algorithm 4 continues to search for elements satisfying any of the above three
conditions until no such elements exist any longer. When this happens, the algorithm terminates and
returns the set Sas its output.
Algorithm 4: LOCAL -SEARCH (k, f)
input : A positive integer k≥1, a non-negative submodular function f, and an error parameter
ε∈(0,1).
output : A set S⊆ N
1Initialize Sto be a feasible solution guaranteeing c-approximation for the problem for some constant
c∈(0,1].
2while true do
3 if∃u∈ N \ Ssuch that f(S+u)≥ 
1 +ε
2k
f(S)and|S|< kthen
4 S←S+u.
5 else if ∃u∈ N \ S, v∈Ssuch that f(S+u−v)≥ 
1 +ε
2k
f(S)and|S|=kthen
6 S←S−v+u.
7 else if ∃v∈Ssuch that f(S−v)≥ 
1 +ε
2k
f(S)then
8 S←S−v.
9 else
10 return S
The properties of Algorithm 4 are formally established by Theorem A.1.
Theorem A.1. Given a positive integer k, a non-negative submodular function fand an error
parameter ε∈(0,1), Algorithm 4 returns a set S⊆ N of size at most ksuch that
f(S)≥f(S∪OPT) +f(S∩OPT)
2 +εandf(S∩OPT)
1 +ε,
while requiring Oε 
nk2
queries to the objective function.
Proof. LetSdenote the output of Algorithm 4, and let E−,E±, and E+be defined as follows.
•E−is the event that there exists v∈Ssuch that f(S−v)≥ 
1 +ε
2k
f(S).
14•E±is the event that there exists u∈ N \ S, v∈Ssuch that f(S+u−v)≥ 
1 +ε
2k
f(S)
and|S|=k.
•E+is the event that there exists u∈ N \ Ssuch that f(S+u)≥ 
1 +ε
2k
f(S)and
|S|< k.
Since the algorithm terminated with the set S, none of the events E+,E−orE±occurs. To lower
bound the value of the set S, we inspect the implications arising from each of these events not
occurring.
Implications of E−not occurring. Since E−does not occur, for every v∈S, 
1 +ε
2k
f(S)>
f(S−v). Summing this inequality across every element in v∈S\OPT yields

1 +ε
2k
f(S)≥f(S) +1
|S\OPT|X
v∈S\OPT[f(S−v)−f(S)]
≥f(S) +1
|S\OPT|(f(S∩OPT)−f(S)),
where the second inequality holds by submodularity of f. By rearrangement, we obtain that
f(S)≥1
ε
2k|S\OPT|+ 1f(S∩OPT)≥1
1 +ε/2f(S∩OPT), (3)
where the last inequality holds since |S\OPT| ≤ |S| ≤k.
The above proves the second inequality guaranteed by the theorem. Below we show that the first
inequality guaranteed by the theorem is implied either by E+not occurring, or by E±not occuring,
depending on the size of S.
Implications of E+not occurring when |S|< k.Since E+does not occur and |S|< k, for every
u∈ N \ S, it holds that 
1 +ε
2k
f(S)> f(S+u). Summing the above inequality across every
element in u∈OPT\Syields

1 +ε
2k
f(S)≥f(S) +1
|OPT\S|X
u∈OPT\S[f(S+u)−f(S)]
≥f(S) +1
|OPT\S|(f(S∪OPT)−f(S)),
where the second inequality follows from the submodularity of f. By rearrangement, we now obtain
f(S)≥1
ε
2k|OPT\S|+ 1f(S∪OPT)≥1
1 +ε/2f(S∪OPT), (4)
where the last inequality holds since |OPT\S| ≤ |OPT| ≤k. Averaging Inequalities (3)and(4)
gives
f(S)≥f(S∪OPT) +f(S∩OPT)
2 + 2 ε,
which proves the first inequality guaranteed by the theorem in the case of |S|< k.
Implications of E±not occurring when |S|=k.Since E±does not occur and |S|=k, for
every pair u, vwhere u∈ N \ Sandv∈S, 
1 +ε
2k
f(S)≥f(S+u−v). Summing the above
inequality for every v∈S\OPT andu∈OPT\S, yields that

1 +ε
2k
f(S)≥1
|S\OPT| · |OPT\S|X
u∈OPT\SX
v∈S\OPTf(S+u−v).
15Observe that
1
|S\OPT| · |OPT\S|X
u∈OPT\SX
v∈S\OPTf(S+u−v)−f(S)
=Az }| {P
u∈OPT\SP
v∈S\OPT[f(S+u−v)−f(S−v)]
|S\OPT| · |OPT\S|+Bz }| {P
u∈OPT\SP
v∈S\OPT[f(S−v)−f(S)]
|S\OPT| · |OPT\S|.
To bound A, note that, by the submodularity of f,
X
u∈OPT\S[f(S+u−v)−f(S−v)]≥X
u∈OPT\S[f(S+u)−f(S)]
≥f(S∪OPT)−f(S),
and hence,
P
u∈OPT\SP
v∈S\OPT[f(S+u−v)−f(S−v)]
|S\OPT| · |OPT\S|≥f(S∪OPT)−f(S)
|OPT\S|.
To bound B, we note that the submodularity of fimplies that
P
u∈OPT\SP
v∈S\OPT[f(S−v)−f(S)]
|S\OPT| · |OPT\S|=P
v∈S\OPT[f(S−v)−f(S)]
|S\OPT|≥f(S∩OPT)−f(S)
|S\OPT|.
Combining all of the above yields that
ε
2kf(S)≥f(S∩OPT)−f(S)
|S\OPT|+f(S∪OPT)−f(S)
|OPT\S|,
which by rearrangement implies
f(S)≥f(S∩OPT)
1 +ε
2k|S\OPT|+|S\OPT|
|OPT\S|+f(S∪OPT)
1 +ε
2k|OPT\S|+|OPT\S|
|S\OPT|
≥f(S∪OPT) +f(S∩OPT)
2 +ε,
where the last inequality holds since |OPT\S|=|S\OPT| ≤k. This completes the proof of the
first inequality guaranteed by the theorem in the case of |S|=k.
To complete the proof of the theorem, it remains to analyze the query complexity of Algorithm 1.
First, we recall that Sis initialized on Line 1 of Algorithm 4 by the Twin Greedy algorithm of [ 17],
which gives an approximation ratio c=1/5using O(nlogk)queries to the objective function. Each
iteration of the loop of Algorithm 4 can be implemented using O(nk)queries since there are only
O(nk)ways to choose u∈ N \ Sandv∈S. Let us bound the number Lof such iterations. Observe
that the function value of the set Sin Algorithm 4 increases by a multiplicative factor of 1 +ε
2kfollowing each iteration of the while loop (except for the last one). Since Sis initialized with a
solution of value at least cf(OPT), and its value is never larger than f(OPT )(because it remains
feasible), we get
f(OPT )≥
1 +ε
kL−1
cf(OPT),
and rearranging gives us
L≤1 +ln1
c
ln(1 +ε
2k)= 1 +ln 5
ln(1 +ε
2k)=O(k/ε).
Combining the above results, we get that the query complexity of Algorithm 4 is upper bounded by
O(nlogk) +O(nk)·L=O(nlogk) +O(nk)·O(k/ε) =O(nk2ε−1).
16A.2 Guided Random Greedy
In this section, we present the Guided Random Greedy algorithm (Algorithm 5), which is the variant
of the Random Greedy algorithm of [ 5] used to implement the last step of Algorithm 6. Algorithm 5
starts with an empty set, and adds to it one element in each iteration until returning the final solution
afterkiterations. In its first ⌈k·ts⌉iterations, the algorithm ignores the elements of Z, and in the
rest of the iterations, it considers all elements. However, except for this difference, the behavior of
the algorithm in all iterations is very similar. Specifically, in each iteration ithe algorithm does the
following two steps. In Step (i) the algorithm finds a subset Miof size kmaximizing the sum of
marginal gains of the elements u∈Miwith respect to the current solution Si−1. In step (ii), the
algorithm chooses a random element from Miand adds it to the solution. This algorithm implicitly
assumes that |N| ≥ 3k. If this is not the case, one can fix that by adding to the ground set 2kdummy
elements of value 0before executing the algorithm (and then removing any dummy elements that
appear in the solution of the algorithm).
Algorithm 5: Guided Random Greedy
input : A set Z⊆ N , a positive integer k≥1, a non-negative submodular function f, and a flip
point ts∈[0,1]
output : A set S⊆ N
1Initialize S0← ∅.
2fori= 1to⌈k·ts⌉do
3 LetMi⊆ N \ (Si−1∪Z)be a subset of size kmaximizingP
u∈Mif(u|Si−1+u).
4 Letuibe a uniformly random element from Mi.
5 Si←Si−1+ui.
6fori=⌈k·ts⌉+ 1tokdo
7 LetMi⊆ N \ Si−1be a subset of size kmaximizingP
u∈Mif(u|Si−1+u).
8 Letuibe a uniformly random element from Mi.
9 Si←Si−1+ui.
10return Sk.
The properties of Algorithm 5 are given by Theorem A.2.
Theorem A.2. There exists an algorithm that given a positive integer k, a value ts∈[0,1], a
non-negative submodular function f: 2N→R≥0, and a set Z⊆ N obeying the inequalities given
in Theorem A.1, outputs a solution Sk, obeying
E[f(Sk)]≥k− ⌈ts·k⌉
kαk−⌈ts·k⌉−1+αk−⌈ts·k⌉−αk
f(OPT)+
+
αk+αk−1−2k− ⌈ts·k⌉
kαk−⌈ts·k⌉−1
f(OPT∪Z)
+
αk−αk−⌈ts·k⌉
f(OPT∩Z),
where α= 1−1/k. Furthermore, this algorithm requires only O(nk)queries to the objective
function.
To prove Theorem A.2, we first need to present some preliminaries. The Lovász extension of fis a
function ˆf: [0,1]N→Rdefined as follows. For every vector x∈[0,1]N,
ˆf(x) =Z1
0f(Tλ(x))dλ ,
where Tλ(x)≜{u∈ N | xu≥λ}. The Lovász extension of a submodular function is known to
be convex. More important for us is the following known lemma regarding this extension. This
lemma stems from an equality, proved by Lovász [ 28], between the Lovász extension of a submodular
function and another extension known as the convex closure.
Lemma A.3. Letf: 2N→Rbe a submodular function, and let ˆfbe its Lovász extension. For
every x∈[0,1]Nand random set Dx⊆ N obeying Pr[u∈Dx] =xufor every u∈ N (i.e., the
marginals of Dxagree with x),ˆf(x)≤E[f(Dx)].
17Using the last lemma, we now prove a lower bound on the expected value of the union of any set A
with the solution Siof Algorithm 5 after iiterations.
Lemma A.4. For every integer 0≤i≤kand set A⊆ N , it holds that
E[f(Si∪A)]≥
1−1
kβi
·f(A)−h
1−1
kβi−
1−1
ki−1i
·f(A∪Z),
where βi= max {0, i− ⌈ts·k⌉}.
Proof. Letx(i)∈[0,1]Nbe the vector of the marginal probabilities of elements to belong to Si.
In other words, for every element u∈ N ,x(i)
u= Pr[ u∈Si]. Since each iteration of Algorithm 5
adds each element to the solution with probability at most 1/k, the coordinates of x(i)are all upper
bounded by 1−(1−1/k)i. For elements of Zwe also know that they are not added by Algorithm 5
to the solution in the first ⌈k·ts⌉iterations, and therefore, their coordinates in x(i)are upper bounded
by
1−(1−1/k)max{0,i−⌈k·ts⌉}= 1−(1−1/k)βi.
Let1Adenote a vector in {0,1}Ncontaining 1s at the entries that correspond to elements present in
Aand0in the remaining coordinates. We also denote by x(i)∨1Athe coordinate-wise maximum of
x(i)and1A. By Lemma A.3,
E[f(Si∪A)]≥ˆf(xSi∨1A) =1Z
0f(Tλ(xSi∨1A))dλ
≥1−(1−1
k)i−1Z
1−(1−1
k)βif(Tλ(xSi∨1A))dλ+1Z
1−(1−1
k)i−1f(Tλ(xSi∨1A))dλ
=1−(1−1
k)i−1Z
1−(1−1
k)βif(Tλ(xSi∨1A))dλ+
1−1
ki−1
f(A)
≥h
1−1
kβi
−
1−1
ki−1i
·[f(A)−f(A∪Z)] +
1−1
ki−1
f(A),
where the second inequality holds by the non-negativity of f, and the last inequality follows since
Tλ(xSi∨1A) =Bλ∪Afor some set Bλ⊂ N \ Z, and the submodularity and non-negativity of f
imply together that
f(Bλ∪A)≥f(A) +f(A∪Bλ∪Z)−f(A∪Z)≥f(A)−f(A∪Z).
With the above result, we are now ready to bound the expected value of f(Si).
Lemma A.5. Letα= 1−1
k. Then, for every integer 0≤i≤ ⌈ts·k⌉,
E[f(Si)]≥ 
1−αi
f(OPT\Z)−
1−αi−i(1−α)αi−1
f(OPT∪Z),
and for every integer ⌈ts·k⌉ ≤i≤k,
E[f(Si)]≥i− ⌈ts·k⌉
kαi−⌈ts·k⌉−1f(OPT)−i− ⌈ts·k⌉
k
αi−⌈ts·k⌉−1−αi−1
f(OPT∪Z)
+αi−⌈ts·k⌉·f(S⌈ts·k⌉).
Proof. LetEibe an event fixing all the random decisions in Algorithm 5 up to iteration i−1
(including), and let Ai=OPT\Zfori≤ ⌈ts·k⌉andAi=OPT fori >⌈ts·k⌉. Since all the
elements of Aican be chosen to be in Mi, and so can the dummy elements, we get that, conditioned
onEi
E[f(ui|Si−1)]≥max
u∈Mif(u|Si−1)≥k−1X
u∈Mif(u|Si−1)
≥k−1X
u∈Aif(u|Si−1)≥k−1[f(Si−1∪Ai)−f(Si−1)],
18where the last inequality holds by the submodularity of f. Since Si=Si−1+ui, rearranging the
last inequality gives E[f(Si)]≥k−1f(Si−1∪Ai) +αf(Si−1). Taking expectation now over all
possible events Eiwe get that, without conditioning on anything,
E[f(Si)]≥k−1E[f(Si−1∪Ai)] +αE[f(Si−1)]. (5)
Proving the first inequality of the lemma. We prove the first inequality of the lemma (for
0≤i≤ ⌈ts·k⌉) by induction on i. Fori= 0the inequality holds by the non-negativity of f. Assume
now that 1≤i≤ ⌈ts·k⌉and the inequality holds for i−1, and let us prove the inequality for i.
E[f(Sj)]≥k−1E[f(Si−1∪Ai)] +αE[f(Si−1)]
≥k−1h
f(OPT\Z)−
1−
1−1
ki−1
·f(OPT∪Z)i
+α(1−αi−1)f(OPT\Z)−α
1−αi−1−(1−α)(i−1)αi−2
f(OPT∪Z)
= (1−α)h
f(OPT\Z)−(1−αi−1)·f(OPT∪Z)i
+α(1−αi−1)f(OPT\Z)−α
1−αi−1−(1−α)(i−1)αi−2
f(OPT∪Z)
=α(1−αi)f(OPT\Z)−
1−αi−(1−α)iαi−1
f(OPT∪Z),
where the second inequality holds by Lemma A.5 and the induction hypothesis since Ai=OPT\Z,
and the first equality holds by definition of α.
Proving the second inequality of the lemma. We prove the second inequality of the lemma (for
⌈ts·k⌉ ≤i≤k) by induction on i. One can verify that for i=⌈ts·k⌉the inequality trivially holds.
Assume now that ⌈ts·k⌉< i≤kand the inequality holds for i−1, and let us prove the inequality
fori.
E[f(Sj)]≥k−1E[f(Si−1∪Ai)] +αE[f(Si−1)]
≥k−1h
1−1
ki−⌈ts·k⌉−1
·f(OPT)−
1−1
ki−⌈ts·k⌉−1
−
1−1
ki−1
·f(OPT∪Z)i
+i− ⌈ts·k⌉ −1
kαi−⌈ts·k⌉−1f(OPT)
−i− ⌈ts·k⌉ −1
k
αi−⌈ts·k⌉−1−αi−1
f(OPT∪Z) +αi−⌈ts·k⌉·f(S⌈ts·k⌉)
=k−1[αi−⌈ts·k⌉−1·f(OPT)−(αi−⌈ts·k⌉−1−αi−1)·f(OPT∪Z)]
+i− ⌈ts·k⌉ −1
kαi−⌈ts·k⌉−1f(OPT)
−i− ⌈ts·k⌉ −1
k
αi−⌈ts·k⌉−1−αi−1
f(OPT∪Z) +αi−⌈ts·k⌉·f(S⌈ts·k⌉)
=i− ⌈ts·k⌉
kαi−⌈ts·k⌉−1f(OPT)−i− ⌈ts·k⌉
k
αi−⌈ts·k⌉−1−αi−1
f(OPT∪Z)
+αi−⌈ts·k⌉·f(S⌈ts·k⌉),
where the second inequality holds by Lemma A.5 and the induction hypothesis since Ai=OPT , and
the first equality holds by definition of α.
We are now ready to prove Theorem A.2.
Proof of Theorem A.2. Note that by submodularity and non-negativity of f,
f(OPT\Z)≥f(∅) +f(OPT)−f(OPT∩Z)≥f(OPT)−f(OPT∩Z).
The lower bound in the theorem follows by combining the above inequality with the following two
inequalities: the inequality arising by plugging i=⌈ts·k⌉into the first case of Lemma A.5, and the
inequality arising by plugging i=kinto the second case of Lemma A.5.
To conclude the proof, observe that each one of the kiterations of Algorithm 5 requires us to compute
the marginal gain of at most nelements with respect to the set Si−1, which can be done using O(n)
queries to the objective function per iteration, and O(nk)queries in total.
19A.3 0.385-Approximation Guarantee
We are now ready to present Algorithm 6 (the simpler version of our main algorithm). Recall that
this algorithm returns the better among the two sets produced in the last two steps described in
the beginning of this appendix. Formally, these sets are the output sets of LOCAL -SEARCH and
Algorithm 5.
Algorithm 6: Warmup Algorithm
input : A positive integer k≥1, a non-negative submodular function f, and a flip point 0≤ts≤1
output : A set S⊆ N
1S1←LOCAL -SEARCH (k, f).
2S2←the output of Algorithm 5.
3return max{f(Z), f(A)}.
The following theorem is proved by setting εin Algorithm 6 to be a small enough positive constant.
Theorem A.6 (Approximation guarantee) .Given an integer k≥1and a non-negative submodular
function f: 2N→R≥0, there exists a 0.385-approximation algorithm for the problem of finding
a setS⊆ N of size at most kmaximizing f. This algorithm uses O(nk2)queries to the objective
function.
Proof. The proof of the approximation guarantee is very similar to the corresponding part in the
proof Theorem 2.3, and is thus, omitted. The query complexity stated in the theorem follows directly
from Theorems A.1 and A.2 and the fact that εis set to a positive constant value.
B Omitted Proofs of Section 2
In this section, we prove the theorems whose proofs have been omitted from Section 2, namely,
Theorems 2.1, and 2.2.
B.1 Proof of Theorem 2.1
In this section, we prove Theorem 2.1. We begin with the following lemma. We assume without loss
of generality that OPT is of size k(otherwise, we add to OPT dummy elements).
Lemma B.1. If the set S0provides c-approximation, then each iteration of the loop starting on Line 3
in Algorithm 1 returns a set with probability at least k/(cε(1−1/e)L). Moreover, when this happens,
the output set Sreturned obeys
f(S)≥f(S∩OPT) +f(S∪OPT)
2 +εand f(S)≥f(S∩OPT)
1 +ε.
Proof. For every two integers 0≤i < L and1≤j≤ ⌈log1
ε⌉, we denote by Aj
ithe event that the
setSj
iobeys the condition on Line 13 of Algorithm 1, i.e., the event that for every integer 0≤t≤k
it holds that
max
S⊆N\ Sj
i,|S|=tX
u∈Sf(u|Sj
i)≤ min
S⊆Sj
i,|S|=tX
v∈Sf(v|Sj
i−v) +εf(Sj
i).
To better understand the implication of an event Aj
i, assume that such an event occurs, and observe
that for t=|OPT\Sj
i|, it holds that
f(Sj
i)−f(Sj
i∩OPT) +εf(Sj
i) =|Kj
i|X
ℓ=1f(uℓ|Jj
i∪ {u1, . . . , u ℓ−1}) +εf(Sj
i) (6)
≥|Kj
i|X
ℓ=1f(uℓ|Jj
L∪Kj
L−uℓ) +εf(Sj
i)
20=X
v∈Sj
i\OPTf(v|Sj
i−v) +εf(Sj
i)
≥ min
S⊆Sj
i,|S|=tX
v∈Sf(v|S−v) +εf(Sj
i)
≥ max
S⊆N\ Sj
i,|S|=tX
u∈Sf(u|Sj
i)
≥X
u∈OPT\Sj
if(u|Sj
i)≥f(Sj
i∪OPT)−f(Sj
i),
where the first equality holds by setting Jj
i≜Sj
i∩OPT ,Kj
i≜Sj
i\OPT and using u1, u2, . . . , u|Kj
i|
to denote the elements of Kj
iin some arbitrary order. The first and last inequalities follow from
submodularity of f, the second inequality holds since the fact that Sj
iandOPT are both of size k
implies that t=|OPT\Sj
i|=|Sj
i\OPT|, and the third inequality holds under the assumption that
event Aj
ioccurs. Rearranging the last inequality, we get
f(Sj
i)≥f(Sj
i∪OPT) +f(Sj
i∩OPT)
2 +ε.
In addition, the existence of the dummy elements implies that max
S⊆N\ Sj
i,|S|=tP
u∈Sf(u|Sj
i)≥0, and
plugging this inequality into Inequality (6) yields that the event Aj
ialso implies
f(Sj
i)−f(Sj
i∩OPT) +εf(Sj
i)≥ min
S⊆Sj
i,|S|=tX
v∈Sf(v|Sj
i−v) +εf(Sj
i)≥0,
and rearranging this inequality gives f(Sj
i)≥f(Sj
i∩OPT)
1+ε.
The above shows that to prove the lemma it suffices to show that the probability that Aj
i∗holds is at
leastk/(cε(1−1/e)L). Towards this goal, let us study the implications of the complementary event
¯Aj
i. Specifically, we would like to lower bound Eh
f(Sj
i+1)−f(Sj
i)|¯Aj
ii
.
Fix a particular set Sj
ithat causes the event ¯Aj
ito occur (notice that the occurrence of this event
depends only on the set Sj
i). Then, there must exist sets T+⊆ N \ Sj
iandT−⊆Sj
iof size t≤k
such thatX
u∈T+f(u|Sj
i)>X
v∈T−f(v|Sj
i−v) +εf(Sj
i).
We can now define the event Bj
ias the event that Zj
i+1∩T+̸=∅(notice that the event Bj
iis defined
only for this particular set Si
j). The probability of the event Bj
iis
Pr(Bj
i|Sj
i)≥1−n−n/k
n|T+|
≥1−e−|T+|
k≥(1−1/e)|T+|
k,
where the first inequality holds since (1−1
k)x≤e−x
kfor any x≥0, and the second inequality
holds for any x∈[0,1]by the concavity of 1−e−x. By the law of total expectation and the fact that
f(Sj
i+1)is always at least f(Sj
i), we now get
Eh
f(Sj
i+1)−f(Sj
i)|Sj
ii
≥Pr(Bj
i|Sj
i)·Eh
f(Sj
i+1)−f(Sj
i)|Sj
i, Bj
ii
≥(1−1/e)|T+|
k·Eh
f(Sj
i+1)−f(Sj
i)|Sj
i, Bj
ii
≥1−1/e
kεcf(OPT),
21where the last inequality holds since
Eh
f(Sj
i+1)−f(Sj
i)|Sj
i, Bj
ii
≥Eh
f(Sj
i−vj
i+1+uj
i+1)−f(Sj
i)|Sj
i, Bj
ii
=Eh
f(Sj
i−vj
i+1+uj
i+1)−f(Sj
i−vj
i+1) +f(Sj
i−vj
i+1)−f(Sj
i)|Sj
i, Bj
ii
≥Eh
f(Sj
i+uj
i+1)−f(Sj
i) +f(Sj
i−vj
i+1)−f(Sj
i)|Sj
i, Bj
ii
≥Eh
f(Sj
i+u′)−f(Sj
i)|Sj
i, Bj
ii
+Eh
f(Sj
i−v′)−f(Sj
i)|Sj
i, Bj
ii
=P
u∈T+f(u|Sj
i)
|T+|−P
v∈T−f(v|Sj
i−v)
|T−|≥εf(Sj
i)
|T+|≥cεf(OPT)
|T+|,
where the second inequality holds by submodularity of f(·), the third inequality holds by the way
Algorithm 1 chooses uj
iandvj
iif we let u′be a uniformly random element of T+∩Zj
i+1andv′be a
uniformly random element of T−, the penultimate inequality holds by our assumption that Sj
iimplies
the event ¯Aj
i, and finally, the last inequality holds since it is guaranteed that f(Sj
i)≥f(Sj
0) =
f(S0)≥c·f(OPT).
Since the above bound on the expectation holds conditioned on every set Sj
ithat implies the event
¯Aj
i, it holds (by the law of total expectation) also conditioned on the event ¯Aj
iitself. Adding this
lower bound for all ivalues, and using the non-negativity of f, we get
Eh
f(Sj
L)i
≥L−1X
ℓ=0Eh
f(Sj
ℓ+1)−f(Sj
ℓ)i
≥L−1X
ℓ=0Pr(¯Aj
ℓ)·Eh
f(Sj
ℓ+1)−f(Sj
ℓ)|¯Aj
ℓi
≥1−1/e
kcεf(OPT)·LX
ℓ=1Pr(¯Aj
ℓ).
Combining the last inequality with the fact that f(Sj
L)is deterministically at most f(OPT), it must
hold that
1≥1−1/e
kcε·LX
ℓ=1Pr¯Aj
ℓ
⇒LX
ℓ=1Pr¯Aj
ℓ
≤k
cε(1−1/e).
Hence, the probability that the event Aj
i∗does not hold for a uniformly random i∗∈[L]is
PL
ℓ=1Pr¯Aj
ℓ
L≤k
cε(1−1/e)L.
Theorem 2.1. There exists an algorithm that given a positive integer k, a value ε∈(0,1), and a
non-negative submodular function f: 2N→R≥0, outputs a set S⊆ N of size at max kthat, with
probability at least 1−ε, obeys
f(S)≥f(S∩OPT) +f(S∪OPT)
2 +εand f(S)≥f(S∩OPT)
1 +ε.
Furthermore, the query complexity of the above algorithm is Oε(n+k2).
Proof. As mentioned above, we initialize the set S0using the deterministic 1/4-approximation
algorithm of Balkanski et al. [ 2], which uses only O(n)queries to the objective function. Thus,
c= 1/4in our implementation of Algorithm 1. Let us now set L=l
2k
cε(1−1/e)m
in Algorithm 1.
Then, Lemma B.1 guarantees that every iteration of the outer loop of the algorithm returns a set
(obeying the requirement of the theorem) with probability at least 1/2. Hence, by repeating this
loop⌈log2ε−1⌉times, we are guaranteed that Algorithm 1 outputs a set with probability at least
1−ε. To complete the proof of the theorem, it only remains to bound the number of queries to
the objective function that are necessary for implementing it. Each iteration of Algorithm 1 can be
22implemented using O(n/k+k)queries, and for the above choices of L, Algorithm 1 has only Oε(k)
iterations. Thus, all the iterations of the algorithm can be implemented using Oε(n+k2)queries in
total. It should also be mentioned that evaluating the condition on Line 13 of the algorithm requires
O(n+k)queries to the objective, and since this condition is evaluated ⌈log2ε−1⌉=Oε(1)times,
all its evaluations require in total only Oε(n+k)queries.
B.2 Proof of Theorem 2.2
In this section, we prove Theorem 2.2. We begin by observing that, like in Algorithm 5, each
iteration of Algorithm 2 adds each element u∈ N into the solution with probability at most 1/k,
and furthermore, the first ⌈ts·k⌉iterations of the algorithm do not pick elements of Zat all (see the
analysis of Sample Greedy in [ 6] for a proof of a similar observation that is given in more detail).
Given this observation, the proof of Lemma A.4 applies also to Algorithm 2. Thus, this lemma can
be used in the proof of the following result.
Lemma B.2. Letα= 1−1
k. Then, for every integer 0≤i≤ ⌈ts·k⌉,
E[f(Si)]≥ 
1−αi
f(OPT\Z)−
1−αi−i(1−α)αi−1
f(OPT∪Z)−2εi
k,
and for every integer ⌈ts·k⌉ ≤i≤k,
E[f(Si)]≥i− ⌈ts·k⌉
kαi−⌈ts·k⌉−1f(OPT)−i− ⌈ts·k⌉
k
αi−⌈ts·k⌉−1−αi−1
f(OPT∪Z)
+αi−⌈ts·k⌉·f(S⌈ts·k⌉)−2ε(i− ⌈ts·k⌉)
k.
Proof. LetEibe an event fixing all the random decisions in Algorithm 2 up to iteration i−1
(including), and let Ai=OPT\Zfori≤ ⌈ts·k⌉andAi=OPT fori >⌈ts·k⌉. Since all the
elements of Aican be sampled in iteration i, by following the proof of Lemma 13 in the analysis of
the Sample Greedy algorithm by [6], one can obtain that, conditioned on Ei,
E[max{0, f(ui|Si−1)}]≥1−ε
k[f(Ai∪Si−1)−f(Si−1)].
To be more specific, Lemma 11 of [ 6] shows that with probability at least 1−εthe element chosen
asuiin iteration iof Algorithm 2 belongs to the kelements with the largest marginal values among
the elements that can be sampled in this iteration (if less than kelements can be sampled, dummy
elements should added for the purpose of this argument). Let Bidenote the set of these kelements.
Since the probability of each element of Bito be selected as uiis non-decreasing in f(ui|Si−1), by
Chebyshev’s sum inequality, we get
E[max{0, f(ui|Si−1)}]≥(1−ε)P
u∈Bimax{0, f(u|Si−1)}
k
≥(1−ε)P
u∈Aif(u|Si−1)
k≥1−ε
k[f(Ai∪Si−1)−f(Si−1)],
where the second inequality holds since Bicontains the kelements with the largest marginals among
the elements that can be samples, and Aiis a set of up to ksuch elements; and the last inequality
follows from the submodularity of f.
Since Si=Si−1+uiwhen f(ui|Si−1)≥0andSi=Si−1otherwise, we get f(Si)−f(Si−1) =
max{0, f(ui|Si−1)}. Plugging this observation into the previous inequality, and rearranging gives
E[f(Si)]≥1−ε
kf(Si−1∪Ai) +
1−1−ε
k
f(Si−1)
≥1
kf(Si−1∪Ai) +αf(Si−1)−ε
kf(Si−1∪Ai)
≥1
kf(Si−1∪Ai) +αf(Si−1)−2ε
kf(OPT),
where the second inequality uses the non-negativity of f, and the last inequality holds since f(Si−1∪
Ai)≤f(Si−1) +f(Ai)−f(Si−1∩Ai)≤f(Si−1) +f(Ai)≤2f(OPT)because both Si−1and
23Aiare feasible solutions, and thus, cannot have a value larger than f(OPT). Taking expectation now
over all possible events Eiwe get that, without conditioning on anything,
E[f(Si)]≥k−1E[f(Si−1∪Ai)] +αE[f(Si−1)]−2ε
kf(OPT).
The remaining part of this proof is omitted since it is very similar to the corresponding part in the
proof of Lemma A.5, except that the last inequality should be used instead of Inequality (5).
We are now ready to prove Theorem 2.2.
Theorem 2.2. There exists an algorithm that given a positive integer k, a value ε∈(0,1), a value
ts∈[0,1], a non-negative submodular function f: 2N→R≥0, and a set Z⊆ N obeying the
inequalities stated in Theorem 2.1, outputs a solution Sk, obeying
E[f(Sk)]≥k− ⌈ts·k⌉
kαk−⌈ts·k⌉−1+αk−⌈ts·k⌉−αk
f(OPT)+
+
αk+αk−1−2k− ⌈ts·k⌉
kαk−⌈ts·k⌉−1
f(OPT∪Z)
+ (αk−αk−⌈ts·k⌉)f(OPT∩Z)−2εf(OPT),
where α≜1−1/k. Moreover, this algorithm requires only Oε(n)queries to the objective function.
Proof of Theorem 2.2. The lower bound in Theorem 2.2 follows from the same arguments used in
the proof of Theorem A.2, except that Lemma B.2 is used instead of Lemma A.5, which results in the
additional error term 2εf(OPT)in the lower bound of Theorem 2.2.
To bound the number of queries to the objective function necessary for implementing Algorithm 2,
observe that each iteration of Algorithm 2 samples Oε(n/k)elements, and the marginal gain (with re-
spect to Si−1) has to be computed only for the sampled elements. Thus, each iteration of Algorithm 2
requires only Oε(n/k)queries to the objective function. Since the algorithm has only kiterations, its
total query complexity is k·Oε(n/k) =Oε(n).
24NeurIPS Paper Checklist
1.Claims
Question: Do the main claims made in the abstract and introduction accurately reflect the
paper’s contributions and scope?
Answer: [Yes]
Justification: Our theoretical contribution can be found in Section 2, while the empirical
evaluation of our method can be found in Section 3.
Guidelines:
•The answer NA means that the abstract and introduction do not include the claims
made in the paper.
•The abstract and/or introduction should clearly state the claims made, including the
contributions made in the paper and important assumptions and limitations. A No or
NA answer to this question will not be perceived well by the reviewers.
•The claims made should match theoretical and experimental results, and reflect how
much the results can be expected to generalize to other settings.
•It is fine to include aspirational goals as motivation as long as it is clear that these goals
are not attained by the paper.
2.Limitations
Question: Does the paper discuss the limitations of the work performed by the authors?
Answer: [NA]
Justification: Our paper has no limitations.
Guidelines:
•The answer NA means that the paper has no limitation while the answer No means that
the paper has limitations, but those are not discussed in the paper.
• The authors are encouraged to create a separate "Limitations" section in their paper.
•The paper should point out any strong assumptions and how robust the results are to
violations of these assumptions (e.g., independence assumptions, noiseless settings,
model well-specification, asymptotic approximations only holding locally). The authors
should reflect on how these assumptions might be violated in practice and what the
implications would be.
•The authors should reflect on the scope of the claims made, e.g., if the approach was
only tested on a few datasets or with a few runs. In general, empirical results often
depend on implicit assumptions, which should be articulated.
•The authors should reflect on the factors that influence the performance of the approach.
For example, a facial recognition algorithm may perform poorly when image resolution
is low or images are taken in low lighting. Or a speech-to-text system might not be
used reliably to provide closed captions for online lectures because it fails to handle
technical jargon.
•The authors should discuss the computational efficiency of the proposed algorithms
and how they scale with dataset size.
•If applicable, the authors should discuss possible limitations of their approach to
address problems of privacy and fairness.
•While the authors might fear that complete honesty about limitations might be used by
reviewers as grounds for rejection, a worse outcome might be that reviewers discover
limitations that aren’t acknowledged in the paper. The authors should use their best
judgment and recognize that individual actions in favor of transparency play an impor-
tant role in developing norms that preserve the integrity of the community. Reviewers
will be specifically instructed to not penalize honesty concerning limitations.
3.Theory Assumptions and Proofs
Question: For each theoretical result, does the paper provide the full set of assumptions and
a complete (and correct) proof?
Answer: [Yes]
25Justification: The proofs of the theoretical results can be found in Section 2, Appendix A,
and Appendix B.
Guidelines:
• The answer NA means that the paper does not include theoretical results.
•All the theorems, formulas, and proofs in the paper should be numbered and cross-
referenced.
•All assumptions should be clearly stated or referenced in the statement of any theorems.
•The proofs can either appear in the main paper or the supplemental material, but if
they appear in the supplemental material, the authors are encouraged to provide a short
proof sketch to provide intuition.
•Inversely, any informal proof provided in the core of the paper should be complemented
by formal proofs provided in appendix or supplemental material.
• Theorems and Lemmas that the proof relies upon should be properly referenced.
4.Experimental Result Reproducibility
Question: Does the paper fully disclose all the information needed to reproduce the main ex-
perimental results of the paper to the extent that it affects the main claims and/or conclusions
of the paper (regardless of whether the code and data are provided or not)?
Answer: [Yes]
Justification: All the information needed to reproduce the main experimental results of the
paper can be found in Section 3.
Guidelines:
• The answer NA means that the paper does not include experiments.
•If the paper includes experiments, a No answer to this question will not be perceived
well by the reviewers: Making the paper reproducible is important, regardless of
whether the code and data are provided or not.
•If the contribution is a dataset and/or model, the authors should describe the steps taken
to make their results reproducible or verifiable.
•Depending on the contribution, reproducibility can be accomplished in various ways.
For example, if the contribution is a novel architecture, describing the architecture fully
might suffice, or if the contribution is a specific model and empirical evaluation, it may
be necessary to either make it possible for others to replicate the model with the same
dataset, or provide access to the model. In general. releasing code and data is often
one good way to accomplish this, but reproducibility can also be provided via detailed
instructions for how to replicate the results, access to a hosted model (e.g., in the case
of a large language model), releasing of a model checkpoint, or other means that are
appropriate to the research performed.
•While NeurIPS does not require releasing code, the conference does require all submis-
sions to provide some reasonable avenue for reproducibility, which may depend on the
nature of the contribution. For example
(a)If the contribution is primarily a new algorithm, the paper should make it clear how
to reproduce that algorithm.
(b)If the contribution is primarily a new model architecture, the paper should describe
the architecture clearly and fully.
(c)If the contribution is a new model (e.g., a large language model), then there should
either be a way to access this model for reproducing the results or a way to reproduce
the model (e.g., with an open-source dataset or instructions for how to construct
the dataset).
(d)We recognize that reproducibility may be tricky in some cases, in which case
authors are welcome to describe the particular way they provide for reproducibility.
In the case of closed-source models, it may be that access to the model is limited in
some way (e.g., to registered users), but it should be possible for other researchers
to have some path to reproducing or verifying the results.
5.Open access to data and code
26Question: Does the paper provide open access to the data and code, with sufficient instruc-
tions to faithfully reproduce the main experimental results, as described in supplemental
material?
Answer: [Yes]
Justification: The code can be accessed at the URL https://github.com/muradtuk/
385ApproximationSubMax .
Guidelines:
• The answer NA means that paper does not include experiments requiring code.
•Please see the NeurIPS code and data submission guidelines ( https://nips.cc/
public/guides/CodeSubmissionPolicy ) for more details.
•While we encourage the release of code and data, we understand that this might not be
possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not
including code, unless this is central to the contribution (e.g., for a new open-source
benchmark).
•The instructions should contain the exact command and environment needed to run to
reproduce the results. See the NeurIPS code and data submission guidelines ( https:
//nips.cc/public/guides/CodeSubmissionPolicy ) for more details.
•The authors should provide instructions on data access and preparation, including how
to access the raw data, preprocessed data, intermediate data, and generated data, etc.
•The authors should provide scripts to reproduce all experimental results for the new
proposed method and baselines. If only a subset of experiments are reproducible, they
should state which ones are omitted from the script and why.
•At submission time, to preserve anonymity, the authors should release anonymized
versions (if applicable).
•Providing as much information as possible in supplemental material (appended to the
paper) is recommended, but including URLs to data and code is permitted.
6.Experimental Setting/Details
Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
results?
Answer: [Yes]
Justification: All the details can be found in Section 3.
Guidelines:
• The answer NA means that the paper does not include experiments.
•The experimental setting should be presented in the core of the paper to a level of detail
that is necessary to appreciate the results and make sense of them.
•The full details can be provided either with the code, in appendix, or as supplemental
material.
7.Experiment Statistical Significance
Question: Does the paper report error bars suitably and correctly defined or other appropriate
information about the statistical significance of the experiments?
Answer: [Yes]
Justification: We present the error bars as the shaded regions in all of the figures. In Section 3,
we clearly explain that the sizes of the error bars are determined by the standard deviations.
Guidelines:
• The answer NA means that the paper does not include experiments.
•The authors should answer "Yes" if the results are accompanied by error bars, confi-
dence intervals, or statistical significance tests, at least for the experiments that support
the main claims of the paper.
•The factors of variability that the error bars are capturing should be clearly stated (for
example, train/test split, initialization, random drawing of some parameter, or overall
run with given experimental conditions).
27•The method for calculating the error bars should be explained (closed form formula,
call to a library function, bootstrap, etc.)
• The assumptions made should be given (e.g., Normally distributed errors).
•It should be clear whether the error bar is the standard deviation or the standard error
of the mean.
•It is OK to report 1-sigma error bars, but one should state it. The authors should
preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis
of Normality of errors is not verified.
•For asymmetric distributions, the authors should be careful not to show in tables or
figures symmetric error bars that would yield results that are out of range (e.g. negative
error rates).
•If error bars are reported in tables or plots, The authors should explain in the text how
they were calculated and reference the corresponding figures or tables in the text.
8.Experiments Compute Resources
Question: For each experiment, does the paper provide sufficient information on the com-
puter resources (type of compute workers, memory, time of execution) needed to reproduce
the experiments?
Answer: [No]
Justification: In Section 3, we wrote the computer type and memory needed to reproduce the
experiments. Due to its high dependence on implementation details, we do not provide the
time of execution. Instead, we provide in Section 3 the number of queries needed to obtain
the results.
Guidelines:
• The answer NA means that the paper does not include experiments.
•The paper should indicate the type of compute workers CPU or GPU, internal cluster,
or cloud provider, including relevant memory and storage.
•The paper should provide the amount of compute required for each of the individual
experimental runs as well as estimate the total compute.
•The paper should disclose whether the full research project required more compute
than the experiments reported in the paper (e.g., preliminary or failed experiments that
didn’t make it into the paper).
9.Code Of Ethics
Question: Does the research conducted in the paper conform, in every respect, with the
NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines ?
Answer: [Yes]
Justification: The research conducted in the paper conform, in every respect, with the
NeurIPS Code of Ethics.
Guidelines:
•The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
•If the authors answer No, they should explain the special circumstances that require a
deviation from the Code of Ethics.
•The authors should make sure to preserve anonymity (e.g., if there is a special consid-
eration due to laws or regulations in their jurisdiction).
10.Broader Impacts
Question: Does the paper discuss both potential positive societal impacts and negative
societal impacts of the work performed?
Answer: [NA]
Justification: Our paper studies a well-known submodular optimization problem without
societal impact.
Guidelines:
• The answer NA means that there is no societal impact of the work performed.
28•If the authors answer NA or No, they should explain why their work has no societal
impact or why the paper does not address societal impact.
•Examples of negative societal impacts include potential malicious or unintended uses
(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
(e.g., deployment of technologies that could make decisions that unfairly impact specific
groups), privacy considerations, and security considerations.
•The conference expects that many papers will be foundational research and not tied
to particular applications, let alone deployments. However, if there is a direct path to
any negative applications, the authors should point it out. For example, it is legitimate
to point out that an improvement in the quality of generative models could be used to
generate deepfakes for disinformation. On the other hand, it is not needed to point out
that a generic algorithm for optimizing neural networks could enable people to train
models that generate Deepfakes faster.
•The authors should consider possible harms that could arise when the technology is
being used as intended and functioning correctly, harms that could arise when the
technology is being used as intended but gives incorrect results, and harms following
from (intentional or unintentional) misuse of the technology.
•If there are negative societal impacts, the authors could also discuss possible mitigation
strategies (e.g., gated release of models, providing defenses in addition to attacks,
mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
feedback over time, improving the efficiency and accessibility of ML).
11.Safeguards
Question: Does the paper describe safeguards that have been put in place for responsible
release of data or models that have a high risk for misuse (e.g., pretrained language models,
image generators, or scraped datasets)?
Answer: [NA]
Justification: The paper poses no such risks.
Guidelines:
• The answer NA means that the paper poses no such risks.
•Released models that have a high risk for misuse or dual-use should be released with
necessary safeguards to allow for controlled use of the model, for example by requiring
that users adhere to usage guidelines or restrictions to access the model or implementing
safety filters.
•Datasets that have been scraped from the Internet could pose safety risks. The authors
should describe how they avoided releasing unsafe images.
•We recognize that providing effective safeguards is challenging, and many papers do
not require this, but we encourage authors to take this into account and make a best
faith effort.
12.Licenses for existing assets
Question: Are the creators or original owners of assets (e.g., code, data, models), used in
the paper, properly credited and are the license and terms of use explicitly mentioned and
properly respected?
Answer: [Yes]
Justification: The creators or original owners of assets (e.g., code, data, models) used in the
paper are properly credited in Section 3.
Guidelines:
• The answer NA means that the paper does not use existing assets.
• The authors should cite the original paper that produced the code package or dataset.
•The authors should state which version of the asset is used and, if possible, include a
URL.
• The name of the license (e.g., CC-BY 4.0) should be included for each asset.
•For scraped data from a particular source (e.g., website), the copyright and terms of
service of that source should be provided.
29•If assets are released, the license, copyright information, and terms of use in the
package should be provided. For popular datasets, paperswithcode.com/datasets
has curated licenses for some datasets. Their licensing guide can help determine the
license of a dataset.
•For existing datasets that are re-packaged, both the original license and the license of
the derived asset (if it has changed) should be provided.
•If this information is not available online, the authors are encouraged to reach out to
the asset’s creators.
13.New Assets
Question: Are new assets introduced in the paper well documented and is the documentation
provided alongside the assets?
Answer: [NA]
Justification: This paper does not release new assets.
Guidelines:
• The answer NA means that the paper does not release new assets.
•Researchers should communicate the details of the dataset/code/model as part of their
submissions via structured templates. This includes details about training, license,
limitations, etc.
•The paper should discuss whether and how consent was obtained from people whose
asset is used.
•At submission time, remember to anonymize your assets (if applicable). You can either
create an anonymized URL or include an anonymized zip file.
14.Crowdsourcing and Research with Human Subjects
Question: For crowdsourcing experiments and research with human subjects, does the paper
include the full text of instructions given to participants and screenshots, if applicable, as
well as details about compensation (if any)?
Answer: [NA]
Justification: The paper involves neither crowdsourcing nor research with human subjects.
Guidelines:
•The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
•Including this information in the supplemental material is fine, but if the main contribu-
tion of the paper involves human subjects, then as much detail as possible should be
included in the main paper.
•According to the NeurIPS Code of Ethics, workers involved in data collection, curation,
or other labor should be paid at least the minimum wage in the country of the data
collector.
15.Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
Subjects
Question: Does the paper describe potential risks incurred by study participants, whether
such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
approvals (or an equivalent approval/review based on the requirements of your country or
institution) were obtained?
Answer: [NA]
Justification: The paper involves neither crowdsourcing nor research with human subjects.
Guidelines:
•The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
•Depending on the country in which research is conducted, IRB approval (or equivalent)
may be required for any human subjects research. If you obtained IRB approval, you
should clearly state this in the paper.
30•We recognize that the procedures for this may vary significantly between institutions
and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
guidelines for their institution.
•For initial submissions, do not include any information that would break anonymity (if
applicable), such as the institution conducting the review.
31