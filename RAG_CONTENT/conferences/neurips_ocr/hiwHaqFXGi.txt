Disentangled Generative Graph
Representation Learning
Anonymous Author(s)
Affiliation
Address
email
Abstract
Recently, generative graph models have shown promising results in learning graph 1
representations through self-supervised methods. However, most existing gener- 2
ative graph representation learning (GRL) approaches rely on random masking 3
across the entire graph, which overlooks the entanglement of learned representa- 4
tions. This oversight results in non-robustness and a lack of explainability. Fur- 5
thermore, disentangling the learned representations remains a significant challenge 6
and has not been sufficiently explored in GRL research. Based on these insights, 7
this paper introduces DiGGR (Disentangled Generative Graph Representation 8
Learning), a self-supervised learning framework. DiGGR aims to learn latent 9
disentangled factors and utilizes them to guide graph mask modeling, thereby 10
enhancing the disentanglement of learned representations and enabling end-to-end 11
joint learning. Extensive experiments on 11 public datasets for two different graph 12
learning tasks demonstrate that DiGGR consistently outperforms many previous 13
self-supervised methods, verifying the effectiveness of the proposed approach. 14
1 Introduction 15
Self-supervised learning (SSL) has received much attention due to its appealing capacity for learning 16
data representation without label supervision. While contrastive SSL approaches are becoming 17
increasingly utilized on images [Chen et al., 2020] and graphs [You et al., 2020], generative SSL has 18
been gaining significance, driven by groundbreaking practices such as BERT for language [Devlin 19
et al., 2018], BEiT [Bao et al., 2021], and MAE [He et al., 2022a] for images. Along this line, there is 20
a growing interest in constructing generative SSL models for other modalities, such as graph masked 21
autoencoders (GMAE). Generally, the fundamental concept of GMAE [Tan et al., 2022] is to utilize 22
an autoencoder architecture to reconstruct input node features, structures, or both, which are randomly 23
masked before the encoding step. Recently, various well-designed GMAEs have emerged , achieving 24
remarkable results in both node classification and graph classification [Hou et al., 2022, Tu et al., 25
2023, Tian et al., 2023]. 26
Despite their significant achievements, most GMAE approaches typically treat the entire graph as 27
holistic, ignoring the graph’s latent structure. As a result, the representation learned for a node tends 28
to encapsulate the node’s neighborhood as a perceptual whole, disregarding the nuanced distinctions 29
between different parts of the neighborhood [Ma et al., 2019, Li et al., 2021, Mo et al., 2023]. 30
For example, in a social network G, individual nis a member of both a mathematics group and 31
several sports interest groups. Due to the diversity of these different communities, she may exhibit 32
different characteristics when interacting with members from various communities. Specifically, 33
the information about the mathematics group may be related to her professional research, while the 34
information about sports clubs may be associated with her hobbies. However, the existing approach 35
overlooks the heterogeneous factors of node n, failing to identify and disentangle these pieces of 36
Submitted to 38th Conference on Neural Information Processing Systems (NeurIPS 2024). Do not distribute.Factors
Factors
Factors
FactorsFactorsFactorsFactors
Factors
FactorsFactors
FactorsFactorsFactors
Factors
(a) Applying previous methods to GMAE (b) Latent  factor  learningFactor  Analysis
Probability  Bar
Maximum  ProbabilityDifferent  node  typesFigure 1: The number of latent factors is set to 4. In Fig. 1(a), the probabilities of nodes belonging
to different latent groups are similar, resulting in nodes of the same type being incorrectly assigned to
different factors. In contrast, Fig. 1(b) shows that the probabilities of node-factor affiliation are more
discriminative, correctly categorizing nodes of the same type into the same latent group.
information effectively [Hou et al., 2022]. Consequently, the learned features may be easily influenced 37
by irrelevant factors, resulting in poor robustness and difficulty in interpretation. 38
To alleviate the challenge described above, there is an increasing interest in disentangled graph 39
representation learning [Bengio et al., 2013, Li et al., 2021, Ma et al., 2019, Mo et al., 2023, Xiao 40
et al., 2022], which aims at acquiring representations that can disentangle the underlying explanatory 41
factors of variation in the graph. Specifically, many of these methods rely on a latent factor detection 42
module, which learns the latent factors of each node by comparing node representations with various 43
latent factor prototypes. By leveraging these acquired latent factors, these models adeptly capture 44
factor-wise graph representations, effectively encapsulating the latent structure of the graph. Despite 45
significant progress, few studies have endeavored to adapt these methods to to generative graph 46
representation learning methods, such as GMAE. This primary challenge arises from the difficulty of 47
achieving convergence in the latent factor detection module under the generative training target, thus 48
presenting obstacles in practical implementation. As shown in Fig.1(a), directly applying the previous 49
factor learning method to GMAE would make the factor learning module difficult to converge, 50
resulting in undistinguished probabilities and misallocation of similar nodes to different latent factor 51
groups. 52
To address these challenges, we introduce Disentangled Generative Graph Representation Learning 53
(DiGGR ), a self-supervised graph generation representation learning framework. Generally speaking, 54
DiGGR learns how to generate graph structures from latent disentangle factors zand leverages this to 55
guide graph mask reconstruction, while enabling end-to-end joint learning. Specifically, i)To capture 56
the heterogeneous factors in the nodes, we introduce the latent factor learning module. This module 57
models how edges and nodes are generated from latent factors, allowing graphs to be factorized into 58
multiple disentangled subgraphs. ii)To learn a deeper disentangled graph representation, we design a 59
factor-wise self-supervised graph representation learning framework. For each subgraph, we employ 60
a distinct masking strategy to learn an improved factor-specific graph representation. Evaluation 61
shows that the proposed framework can achieve significant performance enhancement on various 62
node and graph classification benchmarks. 63
The main contributions of this paper can be summarized as follows: 64
•We utilized the latent disentangled factor to guide mask modeling. A probabilistic graph 65
generation model is employed to identify the latent factors within a graph, and it can be 66
jointly trained with GMAE through variational inference. 67
•Introducing DiGGR (Disentangled Generative Graph Representation Learning) to further 68
capture the disentangled information in the latent factors, enhancing the disentanglement of 69
the learned node representations. 70
•Empirical results show that the proposed DiGGR outperforms many previous self-supervised 71
methods in various node- and graph-level classification tasks. 72
2 Related works 73
Graph Self-Supervised Learning: Graph SSL has achieved remarkable success in addressing label 74
scarcity in real-world network data, mainly consisting of contrastive and generative methods. Con- 75
2trastive methods, includes feature-oriented approaches[Hu et al., 2019, Zhu et al., 2020, Veli ˇckovi ´c 76
et al., 2018], proximity-oriented techniques [Hassani and Khasahmadi, 2020, You et al., 2020], and 77
graph-sampling-based methods [Qiu et al., 2020]. A common limitation across these approaches 78
is their heavy reliance on the design of pretext tasks and augmentation techniques. Compared to 79
contrastive methods, generative methods are generally simpler to implement. Recently, to tackle the 80
challenge of overemphasizing neighborhood information at the expense of structural information 81
[Hassani and Khasahmadi, 2020, Veli ˇckovi ´c et al., 2018], the Graph Masked Autoencoder (GMAE) 82
has been proposed. It applies a masking strategy to graph structure [Li et al., 2023a], node attributes 83
[Hou et al., 2022], or both [Tian et al., 2023] for representation learning. Unlike most GMAEs, which 84
employ random mask strategies, this paper builds disentangled mask strategies. 85
Disentangled Graph Learning: Disentangled representation learning aims to discover and isolate 86
the fundamental explanatory factors inherent in the data [Bengio et al., 2013]. Existing efforts in 87
disentangled representation learning have primarily focused on computer vision [Higgins et al., 88
2017, Jiang et al., 2020]. Recently, there has been a surge of interest in applying these techniques 89
to graph-structured data [Li et al., 2021, Ma et al., 2019, Mercatali et al., 2022, Mo et al., 2023]. 90
For example, DisenGCN [Ma et al., 2019] utilizes an attention-based methodology to discriminate 91
between distinct latent factors, enhancing the representation of each node to more accurately reflect 92
its features across multiple dimensions. DGCL [Li et al., 2021] suggests learning disentangled 93
graph-level representations through self-supervision, ensuring that the factorized representations 94
independently capture expressive information from various latent factors. Despite the excellent results 95
achieved by the aforementioned methods on various tasks, these methods are difficult to converge 96
in generative graph SSL, as we demonstrated in the experiment of Table.3. Therefore, this paper 97
proposes a disentangled-guided framework for generative graph representation learning, capable of 98
learning disentangled representations in an end-to-end self-supervised manner. 99
3 Proposed Method 100
In this section, we propose DiGGR (Disentangled Generative Graph Representation Learning) for 101
self-supervised graph representation learning with mask modeling. The framework was depicted 102
in Figure 2, comprises three primary components: Latent Factor Learning (Section 3.2), Graph 103
Factorization (Section 3.2) and Disentangled Graph Masked autoencder (Section 3.3). Before 104
elaborating on them, we first show some notations. 105
3.1 Preliminaries 106
A graph Gcan be represented as a multi-tuple G={V, A, X }withNnodes and Medges, where 107
|V|=Nis the node set, |A|=Mis the edge set, and X∈RN×Lis the feature matrix for N 108
nodes with Ldimensional feature vector. The topology structure of graph Gcan be found in its 109
adjacency matrix A∈RN×N.z∈RN×Kis the latent disentangled factor matrix, and Kis the 110
predefined factor number. Since we aim to obtain the zto guide the mask modeling, we first utilize a 111
probabilistic graph generation model to factorize the graph before employing the mask mechanism. 112
Given the graph G, it is factorized into {G1, G2, ..., G K}, and each factor-specific graph Gkconsists 113
of its factor-specific edges A(k), node set V(k)and node feature matrix X(k). Other notations will be 114
elucidated as they are employed. 115
3.2 Latent Factor Learning 116
In this subsection, we describe the latent factor learning method. In this phase, our objective is to 117
derive factor-specific node sets {V(1), V(2), ..., V(K)}and adjacency matrices {A(1), A(2), ..., A(K)}, 118
serving as basic unit of the graph to guide the subsequent masking. The specific approach involves 119
modeling the distribution of nodes and edges, utilizing the generative process developed in EPM 120
[Zhou, 2015]. The generative process of EPM under the Bernoulli-Poisson link [Zhou, 2015] can be 121
described as: 122
Muv∼Poisson (XK
k=1γkzukzvk), zuk∼Gamma (α, β), u, v∈[1, N] (1)
where Kis the predefined number of latent factors, and uandvare the indexes of the nodes. Here, 123
Muvis the latent count variable between node uandv;γkis a positive factor activation level indicator, 124
which measures the node interaction frequency via factor k;zukis a positive latent variable for node 125
3Graph Factorization via MaskMaskMaskFeature ReconstructionRandom Mask phase𝑳𝒐𝒔𝒔GNNFeedBack𝒌𝝀Input Graph 𝑮 
Masked NodeHiddenLatent Factor LearningReconstruction-basedRepresentation Learning
GAEGAEGAEGAEDisentangled Graph MaskFigure 2: The overview of proposed DiGGR’s computation graph. The input data successively passes
three modules described in Sections 3.2 and 3.3: Latent Factor Learning, Graph Factorization, and
Disentangled Graph Mask Autoencoder. Graph information will be first processed through Latent
Factor Learning and Graph Factorization, the former processed the input graph to get the latent factor
z; the latter performs graph factorization via z, such that in each factorized subgraph, nodes exchange
more information with intensively interacted neighbors. Hence, during the disentangled graph
masking phase, we will individually mask each factorized subgraph to enhance the disentanglement
of the obtained node representations.
u, which measures how strongly node uis affiliated with factor k. The prior distribution of latent 126
factor variable zukis set to Gamma distribution, where αandβare normally set to 1. Therefore, the 127
intuitive explanation for this generative process is that, with zukandzvkmeasuring how strongly 128
node uandvare affiliated with the k-th factor, respectively, the product γkzukzvkmeasures how 129
strongly nodes uandvare connected due to their affiliations with the k-th factor. 130
Node Factorization: Equation 1 can be further augmented as follows: 131
Muv=XK
kMukv,Mukv∼Poisson (γkzukzvk) (2)
where Mukvrepresents how often nodes uandvinteract due to their affiliations with the k-th factor. 132
To represent how often node uis affiliated with the k-th factor, we further introduce the latent count 133
Muk·=P
v̸=uMukv. Then, we can soft assign node uto multiple factors in {k:Muk·} ≥1, or 134
hard assign node uto a single factor using arg max
k(Muk·). However, our experiments show that 135
soft assignment method results in significant overlap among node sets from different factor group, 136
diminishing the distinctiveness. Note that previous study addressed a similar issue by selecting the 137
top-k most attended regions [Kakogeorgiou et al., 2022]. Thus, we choose the hard assign strategy to 138
factorize the graph node set Vgraph into factor-specific node sets {V(1), V(2),···, V(K)}. 139
Edge Factorization: To create factor-specific edges A(k)for a factor-specific node set V(k), a 140
straightforward method involves removing all external nodes connected to other factor groups. This 141
can be defined as: 142
A(k)
uv=(
Auv,∀u, v∈V(k);u, v∈[1, N] ;
0,∃u, v /∈V(k);u, v∈[1, N].(3)
Besides, the global graph edge Acan also be factorized into positive-weighted edges [He et al., 143
2022b] for each latent factor as: 144
A(k)
uv=Auv·exp (γkzukzvk)P
k′exp (γk′zuk′zvk′);k∈[1, K], u, v∈[1, N]. (4)
Applying Equation 4 to all pairs of nodes yields weighted adjacency matrices {A(k)}k
k=1, with A(k)145
corresponding to latent factor zk. Note that A(k)has the same dimension as Aand Equation 4 146
4presents a trainable weight for each edge, which can be jointly optimized through network training, 147
showcasing an advantage over Equation 3 in this aspect. Therefore, we apply Equation 4 for edge 148
factorization. 149
Variational Inference: The latent factor variable zdetermines the quality of node and edge factor- 150
ization, so we need to approximate its posterior distribution. Denoting zu= (zu1, ..., z uK), zu∈RK
+, 151
which measures how strongly node uis affiliated with all the Klatent factors, we adopt a Weibull 152
variational graph encoder [Zhang et al., 2018, He et al., 2022b]: 153
q(zu|A, X) =Weibull (ku, λu),(ku, λu) =GNN EPM(A, X), u∈[1, N] (5)
where GNN EPM(·)stands for graph neural networks, and we select a two-layer Graph Convolution 154
Networks ( i.e., GCN [Kipf and Welling, 2016a]) for our models; ku, λu∈RK
+are the shape and 155
scale parameters of the variational Weibull distribution, respectively. The latent variable zucan be 156
conveniently reparameterized as: 157
zu=λu(−ln(1−ε))1/ku, ε∼Uniform (0,1). (6)
The optimization objective of latent factor learning phase can be achieved by maximizing the evidence 158
lower bound (ELBO) of the log marginal likelihood of edge logp(A), which can be computed as: 159
Lz=Eq(Z|A,X)[lnp(A|Z)]−NX
u=1Eq(zu|A,X)
lnq(zu|A, X)
p(zu)
(7)
where the first term is the expected log-likelihood or reconstruction error of edge, and the second 160
term is the Kullback–Leibler (KL) divergence that constrains q(zu)to be close to its prior p(zu). The 161
analytical expression for the KL divergence and the straightforward reparameterization of the Weibull 162
distribution simplify the gradient estimation of the ELBO concerning the decoder parameters and 163
other parameters in the inference network. 164
3.3 Disentangled Grpah Masked Autoencoder 165
With the latent factor learning phase discussed in 3.2, the graph can be factorized into a series of 166
factor-specific subgraphs {G1, G2, ..., G K}via the latent factor z. To incorporate the disentangled 167
information encapsulated in zinto the graph masked autoencoder, we proposed Disentangled Graph 168
Masked Autoencoder in this section. Specifically, this section will first introduce the latent factor-wise 169
GMAE and the graph-level GMAE. 170
3.3.1 Latent Factor-wise Grpah Masked Autoencoder 171
To capture disentangled patterns within the latent factor z, for each latent subgraph 172
Gk= (V(k), A(k), X(k)), the latent factor-wise GMAE can be described as: 173
H(k)
d=GNN enc(A(k),¯X(k)),˜Xd=GNN dec(A, H d). (8)
where ¯X(k)is the masked node feature matrix for the k-th latent factor, and ˜Xddenotes the recon- 174
structed node features. GNN enc(.)andGNN dec(.)are the graph encoder and decoder, respectively; 175
H(k)
d∈RN×Dare factor-wise hidden representations, and Hd=H(1)
d⊕H(2)
d···⊕ H(K)
d. After the 176
concatenation operation ⊕in feature dimension, the multi factor-wise hidden representation becomes 177
Hd∈RN×(K·D), which is used as the input of GNN dec(.). 178
Regarding the mask opeartion, we uniformly random sample a subset of nodes ¯V(k)∈V(k)and 179
mask each of their features with a mask token, such as a learnable vector X[M]∈Rd. Thus, the node 180
feature in the masked feature matrix can be defined as: 181
¯X(k)
i=(
X[M];vi∈¯V(k);
Xi;vi/∈¯V(k).(9)
The objective of latent factor-wise GMAE is to reconstruct the masked features of nodes in ¯V(k)182
given the partially observed node signals ¯X(k)and the input adjacency matrix A(k). Another crucial 183
component of the GMAE is the feature reconstruction criterion, often used in language as cross- 184
entropy error [Devlin et al., 2018] and in the image as mean square error [He et al., 2022a]. However, 185
5texts and images typically involve tokenized input features, whereas graph autoencoders (GAE) do 186
not have a universal tokenizer. We adopt the scored cosine error of GraphMAE [Hou et al., 2022] as 187
the loss function. Generally, given the original feature X(k)and reconstructed node feature ˜X(k), the 188
defined SCE is: 189
LD=1
|¯V|X
i∈¯V 
1−XT
i˜Xd
i
∥Xi∥ · ∥˜Xd
i∥!γ
, γ≥1 (10)
where ¯V=¯V(1)∪¯V(2)...∪¯V(K)and Equation 10 are averaged over all masked nodes.The scaling 190
factor γis a hyper-parameter adjustable over different datasets. This scaling technique could also 191
be viewed as adaptive sample reweighting, and the weight of each sample is adjusted with the 192
reconstruction error. This error is also famous in the field of supervised object detection as the focal 193
loss [Lin et al., 2017]. 194
Graph-level Graph Mask Autoencoder: For the node classification task, we have integrated 195
graph-level GMAE into DiGGR. We provide a detailed experimental analysis and explanation for 196
this difference in Appendix A.1.2. The graph-level masked graph autoencoder is designed with the 197
aim of further capturing the global patterns, which can be designed as: 198
Hg=GNN enc(A,¯X),˜Xg=GNN dec(A, H g). (11)
¯Xis the masked node feature matrix, whose mask can be generated by uniformly random sampling 199
a subset of nodes ˜V∈V, or obtained by concatenating the masks of all factor-specific groups 200
˜V=¯V(1)∪¯V(2)...∪¯V(K). The global hidden representation encoded by GNN enc(.)isHg, which is 201
then passed to the decoder. Similar to Equation 10, we can define the graph-level reconstruct loss as: 202
LG=1
|˜V|X
i∈˜V(1−XT
i˜Xg
i
∥Xi∥ · ∥˜Xg
i∥)γ, γ≥1. (12)
which is averaged over all masked nodes. 203
3.4 Joint Training and Inference 204
Benefiting from the effective variational inference method, the proposed latent factor learning and 205
dsientangled graph masked autoencoder can be jointly trained in one framework. We combine the 206
aforementioned losses with three mixing coefficient λd,λgandλzduring training, and the loss for 207
joint training can be written as 208
L=λd· LD+λg· LG+λz· Lz. (13)
Since Weibull distributions have easy reparameterization functions, these parameters can be jointly 209
trained by stochastic gradient descent with low-variance gradient estimation. We summarize the 210
training algorithm at Algorithm 1 in Appendix A.4. For downstream applications, the encoder is 211
applied to the input graph without any masking in the inference stage. The generated factor-wise 212
node embeddings Hdand graph-level embeddings Hgcan either be concatenated in the feature 213
dimensions or used separately. The resulting final representation Hcan be employed for various 214
graph learning tasks, such as node classification and graph classification. For graph-level tasks, we 215
use a non-parameterized graph pooling (readout) function, e.g., MaxPooling and MeanPooling to 216
obtain the graph-level representation. 217
Time and space complexity: Let’s recall that in our context, N,M, andKrepresent the number of 218
nodes, edges, and latent factors in the graph, respectively. The feature dimension is denoted by F, 219
while L1,L2,L3, and L4represent the number of layers in the latent factor learning encoder, the 220
latent factor-wise GMAE’s encoder, the graph-level GMAE’s encoder, and the decoder respectively. 221
In DiGGR, we constrain the hidden dimension size in latent factor-wise GMAE’s encoder to be 222
1/Kof the typical baseline dimensions. Consequently, the time complexity for training DiGGR can 223
be expressed as O((L1+L2+L3)MF+ (L1+L2/K+L3)NF2+N2F+L4NF2), and the 224
space complexity is O((L1+L2+L3+L4)NF+KM + (L1 +L2/K+L3 +L4)F2), with 225
O((L1+L2/K+L3+L4)F2)attributed to model parameters. We utilize the Bayesian factor model 226
in our approach to reconstruct edges. Its time complexity aligns with that of variational inference 227
in SeeGera Li et al. [2023b], predominantly at O(N2F); Therefore, the complexity of DiGGR is 228
comparable to previous works. 229
6Table 1: Experiment results for node classification. Micro-F1 score is reported for PPI, and accuracy
for other datasets. The best unsupervised method scores in each dataset are highlighted in bold.
Methods Cora Citeseer Pubmed PPI
GCN [Kipf and Welling, 2016a] 81.50 70.30 79.00 75.70 ±0.10
GAT [Velickovic et al., 2017] 83.00 ±0.70 72.50 ±0.70 79.00 ±0.30 97.30 ±0.20
DisenGCN[Ma et al., 2019] 83.7 73.4 80.5 -
VEPM[He et al., 2022b] 84.3 ±0.1 72.5 ±0.1 82.4 ±0.2 -
MVGRL [Hassani and Khasahmadi, 2020] 83.50 ±0.40 73.30 ±0.50 80.10 ±0.70 -
InfoGCL [Xu et al., 2021] 83.50 ±0.30 73.50 ±0.40 79.10 ±0.20 -
DGI [Veli ˇckovi ´c et al., 2018] 82.30 ±0.60 71.80 ±0.70 76.80 ±0.60 63.80 ±0.20
GRACE [Zhu et al., 2020] 81.90 ±0.40 71.20 ±0.50 80.60 ±0.40 69.71 ±0.17
BGRL [Thakoor et al., 2021] 82.70 ±0.60 71.10 ±0.80 79.60 ±0.50 73.63 ±0.16
CCA-SSG [Zhang et al., 2021] 84.20 ±0.40 73.10 ±0.30 81.00 ±0.40 73.34 ±0.17
GAE [Kipf and Welling, 2016b] 71.50 ±0.40 65.80 ±0.40 72.10 ±0.50 -
VGAE [Kipf and Welling, 2016b] 76.30 ±0.20 66.80 ±0.20 75.80 ±0.40 -
Bandana [Zhao et al., 2024] 84.62 ±0.37 73.60 ±0.16 83.53±0.51 -
GiGaMAE[Shi et al., 2023] 84.72 ±0.47 72.31 ±0.50 - -
SEEGERA [Shi et al., 2023] 84.30 ±0.40 73.00 ±0.80 80.40 ±0.40 -
GraphMAE [Hou et al., 2022] 84.20 ±0.40 73.40 ±0.40 81.10 ±0.40 74.50 ±0.29
GraphMAE2[Hou et al., 2023] 84.50 ±0.60 73.40 ±0.30 81.40 ±0.50 -
DiGGR 84.96±0.32 73.98±0.27 81.30±0.26 78.30±0.71
4 Experiments 230
We compare the proposed self-supervised framework DiGGR against related baselines on two funda- 231
mental tasks: unsupervised representation learning on node classification andgraph classification . 232
We evaluate DiGGR on 11 benchmarks. For node classification, we use 3 citation networks (Cora, 233
Citeseer, Pubmed [Yang et al., 2016]), and protein-protein interaction networks (PPI) [Hamilton et al., 234
2017]. For graph classification, we use 3 bioinformatics datasets (MUTAG, NCI1, PROTEINS) and 4 235
social network datasets (IMDB-BINARY , IMDB-MULTI, REDDIT-BINARY and COLLAB). The 236
specific information of the dataset and the hyperparameters used by the network are listed in the 237
Appendix A.2 in table 5 and 6. We also provide the detailed experiment setup in Appendix A.2 for 238
node classification (4.1) and graph classification (4.2) 239
4.1 Node Classification 240
The baseline models for node classification can be divided into three categories: i)supervised methods, 241
including GCN [Kipf and Welling, 2016a] , DisenGCN[Ma et al., 2019], VEPM[He et al., 2022b] 242
and GAT [Velickovic et al., 2017]; ii)contrastive learning methods, including MVGRL [Hassani and 243
Khasahmadi, 2020], InfoGCL [Xu et al., 2021], DGI [Veli ˇckovi ´c et al., 2018], GRACE [Zhu et al., 244
2020], BGRL [Thakoor et al., 2021] and CCA-SSG [Zhang et al., 2021]; iii)generative learning 245
methods, including GraphMAE [Hou et al., 2022], GraphMAE2[Hou et al., 2023], Bandana[Zhao 246
et al., 2024], GiGaMAE[Shi et al., 2023], SeeGera[Li et al., 2023b], GAE and VGAE [Kipf and 247
Welling, 2016b]. The node classification results were listed in Table 1. DiGGR demonstrates 248
competitive results on the provided dataset, achieving results comparable to those of supervised 249
methods. 250
4.2 Graph Classification 251
Baseline Models We categorized the baseline models into four groups: i)supervised methods, 252
including GIN [Xu et al., 2018], DiffPool[Ying et al., 2018] and VEPM[He et al., 2022b]; ii)classical 253
graph kernel methods: Weisfeiler-Lehman sub-tree kernel (WL) [Shervashidze et al., 2011] and 254
deep graph kernel (DGK) [Yanardag and Vishwanathan, 2015]; iii)contrastive learning methods, 255
including GCC [Qiu et al., 2020], graph2vec [Narayanan et al., 2017], Infograph [Sun et al., 2019], 256
GraphCL [You et al., 2020], JOAO [You et al., 2021], MVGRL [Hassani and Khasahmadi, 2020], 257
and InfoGCL [Xu et al., 2021]; 4)generative learning methods, including graph2vec [Narayanan 258
et al., 2017], sub2vec [Adhikari et al., 2018], node2vec [Grover and Leskovec, 2016], GraphMAE 259
[Hou et al., 2022], GraphMAE2[Hou et al., 2023], GAE and VGAE [Kipf and Welling, 2016b]. Per 260
graph classification research tradition, we report results from previous papers if available. 261
7Table 2: Experiment results in unsupervised representation learning for graph classification. We report
accuracy ( %) for all datasets. The optimal outcomes for methods, excluding supervised approaches
(GIN and DiffPool), on each dataset are emphasized in bold.
Methods IMDB-B IMDB-M MUTAG NCI1 REDDIT-B PROTEINS COLLAB
GIN 75.1 ±5.1 52.3 ±2.8 89.4 ±5.6 82.7 ±1.7 92.4 ±2.5 76.2 ±2.8 80.2 ±1.9
DiffPool 72.6 ±3.9 - 85.0 ±10.3 - 92.1 ±2.6 75.1 ±3.5 78.9 ±2.3
VEPM 76.7 ±3.1 54.1 ±2.1 93.6 ±3.4 83.9 ±1.8 90.5 ±1.8 80.5 ±2.8 -
WL 72.30 ±3.44 46.95 ±0.46 80.72 ±3.00 80.31 ±0.46 68.82 ±0.41 72.92 ±0.56 -
DGK 66.96 ±0.56 44.55 ±0.52 87.44 ±2.72 80.31 ±0.46 78.04 ±0.39 73.30 ±0.82 73.09 ±0.25
Infograph 73.03 ±0.87 49.69 ±0.53 89.01 ±1.13 76.20 ±1.06 82.50 ±1.42 74.44 ±0.31 70.65 ±1.13
GraphCL 71.14 ±0.44 48.58 ±0.67 86.80 ±1.34 77.87 ±0.41 89.53±0.84 74.39 ±0.45 71.36 ±1.15
JOAO 70.21 ±3.08 49.20 ±0.77 87.35 ±1.02 78.07 ±0.47 85.29 ±1.35 74.55 ±0.41 69.50 ±0.36
GCC 72.0 49.4 - - 89.9 - 78.9
MVGRL 74.20 ±0.70 51.20 ±0.50 89.70 ±1.10 - 84.50 ±0.60 - -
InfoGCL 75.10 ±0.90 51.40 ±0.80 91.20±1.30 80.20 ±0.60 - - 80.00 ±1.30
graph2vec 71.10 ±0.54 50.44 ±0.87 83.15 ±9.25 73.22 ±1.81 75.78 ±1.03 73.30 ±2.05 -
sub2vec 55.3 ±1.5 36.7 ±0.8 61.1 ±15.8 52.8 ±1.5 71.5 ±0.4 53.0 ±5.6 -
node2vec - - 72.6 ±10.2 54.9 ±1.6 - 57.5 ±3.6 -
GAE 52.1 ±0.2 - 84.0 ±0.6 73.3 ±0.6 74.8 ±0.2 74.1 ±0.5 -
VGAE 52.1 ±0.2 - 84.4 ±0.6 73.7 ±0.3 74.8 ±0.2 74.8 ±0.2 -
GraphMAE 75.52±0.66 51.63 ±0.52 88.19 ±1.26 80.40 ±0.30 88.01 ±0.19 75.30 ±0.39 80.32 ±0.46
GraphMAE2 73.88±0.53 51.80 ±0.60 86.63 ±1.33 78.56 ±0.26 76.84 ±0.21 74.86 ±0.34 77.59 ±0.22
DiGGR 77.68±0.48 54.77±2.63 88.72±1.03 81.23±0.40 88.19±0.28 77.40±0.05 83.76±3.70
Performance Comparison The graph classification results are presented in Table 2. In general, we 262
find that DiGGR gained the best performance among other baselines on five out of seven datasets, 263
while achieving competitive results on the other two datasets. The performance of DiGGR is 264
comparable to that of supervised learning methods. For instance, the accuracy on IMDB-B and 265
IMDB-M surpasses that of GIN and DiffPool. Moreover, within the reported datasets, our method 266
demonstrates improved performance compared to random mask methods like GraphMAE, particularly 267
on the IMDB-M, COLLAB, and PROTEINS datasets. This underscores the effectiveness of the 268
proposed method. 269
4.3 Exploratory Studies 270
Visualizing latent representations To examine the influence of the learned latent factor on classifi- 271
cation results, we visualized the latent disentangled factor z, which reflects the node-factor affiliation, 272
and the hidden representation Hused for classification. MUTAG is selected as the representative 273
for classification benchmarks. We encodes the representations into 2-D space via t-SNE [Van der 274
Maaten and Hinton, 2008]. The result is shown in Figure 3(a), where each node is colored according 275
to its node labels. The clusters in Figure 3(a) still exhibit differentiation in the absence of label 276
supervision, suggesting that zobtained through unsupervised learning can enhance node information 277
and offer a guidance for the mask modeling. We then visualize the hidden representation used for 278
classification tasks, and color each node according to the latent factor to which it belongs. The results 279
are depicted in Figure 3(b), showcasing separability among different color clusters. This illustrates 280
the model’s ability to extract information from the latent factor, thereby enhancing the quality of the 281
learned representations. 282
Task-relevant factors To assess the statistical correlation between the learned latent factor and the 283
task, we follow the approach in [He et al., 2022b] and compute the Normalized Mutual Information 284
(NMI) between the nodes in the factor label and the actual node labels. NMI is a metric that ranges 285
from 0 to 1, where higher values signify more robust statistical dependencies between two random 286
variables. In the experiment, we utilized the MUTAG dataset, comprising 7 distinct node types, 287
and the NMI value we obtained was 0.5458. These results highlight that the latent factors obtained 288
through self-supervised training are meaningful for the task, enhancing the correlation between the 289
inferred latent factors and the task. 290
Disentangled representations To assess DiGGR’s capability to disentangle the learned represen- 291
tation for downstream task, we provide a qualitative evaluation by plotting the correlation of the 292
80.0 0.2 0.4 0.6 0.8 1.00.00.20.40.60.81.0 node class  0
node class  1
node class  2(a)z, node label
0.0 0.2 0.4 0.6 0.8 1.00.00.20.40.60.81.0 node class  0
node class  1
node class  2
node class  3
node class  4
node class  5
node class  6 (b)H, factor label
Figure 3: T-SNE visualization of MUTAG
dataset, where zis the latent factor, His the
learned node representation used for down-
stream tasks.
(a) GraphMAE
 (b) DiGGR
Figure 4: representation correlation matrix on
Cora with number of factors K= 4. 4(a)
depicts the representation of entanglement,
while 4(b) illustrates disentanglement.
Table 3: The NMI between the latent factors extracted by DiGGR and Non-probabilistic factor
learning method across various datasets, and its performance improvement compared to GraphMAE,
are examined. A lower NMI indicates a more pronounced disentanglement between factor-specific
graphs, resulting in a greater performance enhancement.
Dataset RDT-B MUTAG NCI-1 IMDB-B PROTEINS COLLAB IMDB-M
DiGGRNMI 0.95 0.90 0.89 0.82 0.76 0.35 0.24
ACC Gain + 0.18% + 0.53% + 0.83% + 2.16% + 2.1% + 3.44% + 3.14%
Non-probabilistic
Factor LearningNMI 1.00 1.00 0.80 1.00 0.60 1.00 0.94
ACC Gain -2.23% -2.02% -0.45% -0.80% -2.15% -3.00% -0.11%
node representation in Figure 4. The figure shows the absolute values of the correlation between the 293
elements of 512-dimensional graph representation and representation obtained from GraphMAE and 294
DiGGR, respectively. From the results, we can see that the representation produced by GraphMAE 295
exhibits entanglement, whereas DiGGR’s representation displays a overall block-level pattern, 296
indicating that DiGGR can capture mutually exclusive information in the graph and disentangle the 297
hidden representation to some extent. Results for more datasets can be found in Appendix A.3. 298
299Why DiGGR works better: To validate that disentangled learning can indeed enhance the quality of 300
the representations learned by GMAE, we further conduct quantitative experiments. The Normalized 301
Mutual Information (NMI) is used to quantify the disentangling degree of different datasets. Generally, 302
the NMI represents the similarity of node sets between different factor-specific graphs, and the lower 303
NMI suggests a better-disentangled degree with lower similarity among factor-specific graphs. The 304
NMI between latent factors and the corresponding performance gain (compared to GraphMAE) 305
are shown in the Table.3. As the results show, DiGGR’s performance improvement has a positive 306
correlation with disentangled degree, where the better the disentangled degree, the more significant 307
the performance improvement. For methods relying on Non-probabilistic Factor Learning, the NMI 308
tends to approach 1. This is attributed to the challenges faced by the factor learning module in 309
converging, thereby hindering the learning of distinct latent factors. The presence of confused latent 310
factors offers misleading guidance for representation learning, consequently leading to decreased 311
performance. 312
5 Conclusions 313
In this paper, we propose DiGGR (Disentangled Generative Graph Representation Learning), de- 314
signed to achieve disentangled representations in graph masked autoencoders by leveraging latent 315
disentangled factors. In particular, we achieve this by two steps: 1) We utilize a probabilistic graph 316
generation model to factorize the graph via the learned disentangled latent factor; 2) We develop a 317
Disentangled Graph Masked Autoencoder framework, with the aim of integrating the disentangled in- 318
formation into the representation learning of Graph Masked Autoencoders. Experiments demonstrate 319
that our model can acquire disentangled representations, and achieve favorable results on downstream 320
tasks. 321
9References 322
Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton. A simple framework for 323
contrastive learning of visual representations. In International conference on machine learning , 324
pages 1597–1607. PMLR, 2020. 325
Yuning You, Tianlong Chen, Yongduo Sui, Ting Chen, Zhangyang Wang, and Yang Shen. Graph 326
contrastive learning with augmentations. Advances in neural information processing systems , 33: 327
5812–5823, 2020. 328
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: Pre-training of deep 329
bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805 , 2018. 330
Hangbo Bao, Li Dong, Songhao Piao, and Furu Wei. Beit: Bert pre-training of image transformers. 331
arXiv preprint arXiv:2106.08254 , 2021. 332
Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Dollár, and Ross Girshick. Masked 333
autoencoders are scalable vision learners. In Proceedings of the IEEE/CVF conference on computer 334
vision and pattern recognition , pages 16000–16009, 2022a. 335
Qiaoyu Tan, Ninghao Liu, Xiao Huang, Rui Chen, Soo-Hyun Choi, and Xia Hu. Mgae: Masked 336
autoencoders for self-supervised learning on graphs. arXiv preprint arXiv:2201.02534 , 2022. 337
Zhenyu Hou, Xiao Liu, Yukuo Cen, Yuxiao Dong, Hongxia Yang, Chunjie Wang, and Jie Tang. 338
GraphMAE: Self-supervised masked graph autoencoders. In Proceedings of the 28th ACM 339
SIGKDD Conference on Knowledge Discovery and Data Mining , pages 594–604, 2022. 340
Wenxuan Tu, Qing Liao, Sihang Zhou, Xin Peng, Chuan Ma, Zhe Liu, Xinwang Liu, and Zhiping 341
Cai. Rare: Robust masked graph autoencoder. arXiv preprint arXiv:2304.01507 , 2023. 342
Yijun Tian, Kaiwen Dong, Chunhui Zhang, Chuxu Zhang, and Nitesh V Chawla. Heterogeneous 343
graph masked autoencoders. In Proceedings of the AAAI Conference on Artificial Intelligence , 344
volume 37, pages 9997–10005, 2023. 345
Jianxin Ma, Peng Cui, Kun Kuang, Xin Wang, and Wenwu Zhu. Disentangled graph convolutional 346
networks. In International conference on machine learning , pages 4212–4221. PMLR, 2019. 347
Haoyang Li, Xin Wang, Ziwei Zhang, Zehuan Yuan, Hang Li, and Wenwu Zhu. Disentangled 348
contrastive learning on graphs. Advances in Neural Information Processing Systems , 34:21872– 349
21884, 2021. 350
Yujie Mo, Yajie Lei, Jialie Shen, Xiaoshuang Shi, Heng Tao Shen, and Xiaofeng Zhu. Disentangled 351
multiplex graph representation learning. In International Conference on Machine Learning , pages 352
24983–25005. PMLR, 2023. 353
Yoshua Bengio, Aaron Courville, and Pascal Vincent. Representation learning: A review and new 354
perspectives. IEEE transactions on pattern analysis and machine intelligence , 35(8):1798–1828, 355
2013. 356
Teng Xiao, Zhengyu Chen, Zhimeng Guo, Zeyang Zhuang, and Suhang Wang. Decoupled self- 357
supervised learning for graphs. Advances in Neural Information Processing Systems , 35:620–634, 358
2022. 359
Weihua Hu, Bowen Liu, Joseph Gomes, Marinka Zitnik, Percy Liang, Vijay Pande, and Jure Leskovec. 360
Strategies for pre-training graph neural networks. arXiv preprint arXiv:1905.12265 , 2019. 361
Yanqiao Zhu, Yichen Xu, Feng Yu, Qiang Liu, Shu Wu, and Liang Wang. Deep graph contrastive 362
representation learning. arXiv preprint arXiv:2006.04131 , 2020. 363
Petar Veli ˇckovi ´c, William Fedus, William L Hamilton, Pietro Liò, Yoshua Bengio, and R Devon 364
Hjelm. Deep graph infomax. arXiv preprint arXiv:1809.10341 , 2018. 365
Kaveh Hassani and Amir Hosein Khasahmadi. Contrastive multi-view representation learning on 366
graphs. In International conference on machine learning , pages 4116–4126. PMLR, 2020. 367
10Jiezhong Qiu, Qibin Chen, Yuxiao Dong, Jing Zhang, Hongxia Yang, Ming Ding, Kuansan Wang, 368
and Jie Tang. Gcc: Graph contrastive coding for graph neural network pre-training. In Proceedings 369
of the 26th ACM SIGKDD international conference on knowledge discovery & data mining , pages 370
1150–1160, 2020. 371
Jintang Li, Ruofan Wu, Wangbin Sun, Liang Chen, Sheng Tian, Liang Zhu, Changhua Meng, Zibin 372
Zheng, and Weiqiang Wang. What’s behind the mask: Understanding masked graph modeling 373
for graph autoencoders. In Proceedings of the 29th ACM SIGKDD Conference on Knowledge 374
Discovery and Data Mining , pages 1268–1279, 2023a. 375
Irina Higgins, Loic Matthey, Arka Pal, Christopher P Burgess, Xavier Glorot, Matthew M Botvinick, 376
Shakir Mohamed, and Alexander Lerchner. beta-vae: Learning basic visual concepts with a 377
constrained variational framework. ICLR (Poster) , 3, 2017. 378
Wentao Jiang, Si Liu, Chen Gao, Jie Cao, Ran He, Jiashi Feng, and Shuicheng Yan. Psgan: Pose 379
and expression robust spatial-aware gan for customizable makeup transfer. In Proceedings of the 380
IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 5194–5202, 2020. 381
Giangiacomo Mercatali, André Freitas, and Vikas Garg. Symmetry-induced disentanglement on 382
graphs. Advances in neural information processing systems , 35:31497–31511, 2022. 383
Mingyuan Zhou. Infinite edge partition models for overlapping community detection and link 384
prediction. In Artificial intelligence and statistics , pages 1135–1143. PMLR, 2015. 385
Ioannis Kakogeorgiou, Spyros Gidaris, Bill Psomas, Yannis Avrithis, Andrei Bursuc, Konstantinos 386
Karantzalos, and Nikos Komodakis. What to hide from your students: Attention-guided masked 387
image modeling. In European Conference on Computer Vision , pages 300–318. Springer, 2022. 388
Yilin He, Chaojie Wang, Hao Zhang, Bo Chen, and Mingyuan Zhou. A variational edge partition 389
model for supervised graph representation learning. Advances in Neural Information Processing 390
Systems , 35:12339–12351, 2022b. 391
Hao Zhang, Bo Chen, Dandan Guo, and Mingyuan Zhou. Whai: Weibull hybrid autoencoding 392
inference for deep topic modeling. arXiv preprint arXiv:1803.01328 , 2018. 393
Thomas N Kipf and Max Welling. Semi-supervised classification with graph convolutional networks. 394
arXiv preprint arXiv:1609.02907 , 2016a. 395
Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, and Piotr Dollár. Focal loss for dense 396
object detection. In Proceedings of the IEEE international conference on computer vision , pages 397
2980–2988, 2017. 398
Xiang Li, Tiandi Ye, Caihua Shan, Dongsheng Li, and Ming Gao. Seegera: Self-supervised semi- 399
implicit graph variational auto-encoders with masking. In Proceedings of the ACM web conference 400
2023 , pages 143–153, 2023b. 401
Zhilin Yang, William Cohen, and Ruslan Salakhudinov. Revisiting semi-supervised learning with 402
graph embeddings. In International conference on machine learning , pages 40–48. PMLR, 2016. 403
Will Hamilton, Zhitao Ying, and Jure Leskovec. Inductive representation learning on large graphs. 404
Advances in neural information processing systems , 30, 2017. 405
Petar Velickovic, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, Yoshua Bengio, 406
et al. Graph attention networks. stat, 1050(20):10–48550, 2017. 407
Dongkuan Xu, Wei Cheng, Dongsheng Luo, Haifeng Chen, and Xiang Zhang. Infogcl: Information- 408
aware graph contrastive learning. Advances in Neural Information Processing Systems , 34: 409
30414–30425, 2021. 410
Shantanu Thakoor, Corentin Tallec, Mohammad Gheshlaghi Azar, Mehdi Azabou, Eva L Dyer, Remi 411
Munos, Petar Veli ˇckovi ´c, and Michal Valko. Large-scale representation learning on graphs via 412
bootstrapping. arXiv preprint arXiv:2102.06514 , 2021. 413
11Hengrui Zhang, Qitian Wu, Junchi Yan, David Wipf, and Philip S Yu. From canonical correlation 414
analysis to self-supervised graph neural networks. Advances in Neural Information Processing 415
Systems , 34:76–89, 2021. 416
Zhenyu Hou, Yufei He, Yukuo Cen, Xiao Liu, Yuxiao Dong, Evgeny Kharlamov, and Jie Tang. 417
Graphmae2: A decoding-enhanced masked self-supervised graph learner. In Proceedings of the 418
ACM Web Conference 2023 , pages 737–746, 2023. 419
Ziwen Zhao, Yuhua Li, Yixiong Zou, Jiliang Tang, and Ruixuan Li. Masked graph autoencoder with 420
non-discrete bandwidths. arXiv preprint arXiv:2402.03814 , 2024. 421
Yucheng Shi, Yushun Dong, Qiaoyu Tan, Jundong Li, and Ninghao Liu. Gigamae: Generalizable 422
graph masked autoencoder via collaborative latent space reconstruction. In Proceedings of the 32nd 423
ACM International Conference on Information and Knowledge Management , pages 2259–2269, 424
2023. 425
Thomas N Kipf and Max Welling. Variational graph auto-encoders. arXiv preprint arXiv:1611.07308 , 426
2016b. 427
Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka. How powerful are graph neural 428
networks? arXiv preprint arXiv:1810.00826 , 2018. 429
Zhitao Ying, Jiaxuan You, Christopher Morris, Xiang Ren, Will Hamilton, and Jure Leskovec. Hier- 430
archical graph representation learning with differentiable pooling. Advances in neural information 431
processing systems , 31, 2018. 432
Nino Shervashidze, Pascal Schweitzer, Erik Jan Van Leeuwen, Kurt Mehlhorn, and Karsten M 433
Borgwardt. Weisfeiler-lehman graph kernels. Journal of Machine Learning Research , 12(9), 2011. 434
Pinar Yanardag and SVN Vishwanathan. Deep graph kernels. In Proceedings of the 21th ACM 435
SIGKDD international conference on knowledge discovery and data mining , pages 1365–1374, 436
2015. 437
Annamalai Narayanan, Mahinthan Chandramohan, Rajasekar Venkatesan, Lihui Chen, Yang Liu, 438
and Shantanu Jaiswal. graph2vec: Learning distributed representations of graphs. arXiv preprint 439
arXiv:1707.05005 , 2017. 440
Fan-Yun Sun, Jordan Hoffmann, Vikas Verma, and Jian Tang. Infograph: Unsupervised and semi- 441
supervised graph-level representation learning via mutual information maximization. arXiv preprint 442
arXiv:1908.01000 , 2019. 443
Yuning You, Tianlong Chen, Yang Shen, and Zhangyang Wang. Graph contrastive learning automated. 444
InInternational Conference on Machine Learning , pages 12121–12132. PMLR, 2021. 445
Bijaya Adhikari, Yao Zhang, Naren Ramakrishnan, and B Aditya Prakash. Sub2vec: Feature 446
learning for subgraphs. In Advances in Knowledge Discovery and Data Mining: 22nd Pacific-Asia 447
Conference, PAKDD 2018, Melbourne, VIC, Australia, June 3-6, 2018, Proceedings, Part II 22 , 448
pages 170–182. Springer, 2018. 449
Aditya Grover and Jure Leskovec. node2vec: Scalable feature learning for networks. In Proceedings 450
of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining , 451
pages 855–864, 2016. 452
Laurens Van der Maaten and Geoffrey Hinton. Visualizing data using t-sne. Journal of machine 453
learning research , 9(11), 2008. 454
Chih-Chung Chang and Chih-Jen Lin. Libsvm: a library for support vector machines. ACM 455
transactions on intelligent systems and technology (TIST) , 2(3):1–27, 2011. 456
Reid Andersen, Fan Chung, and Kevin Lang. Local graph partitioning using pagerank vectors. 457
In2006 47th Annual IEEE Symposium on Foundations of Computer Science (FOCS’06) , pages 458
475–486. IEEE, 2006. 459
12A Appendix / supplemental material 460
Optionally include supplemental material (complete proofs, additional experiments and plots) in 461
appendix. All such materials SHOULD be included in the main submission. 462
A.1 Ablation Study 463
A.1.1 Number of factors 464
One of the crucial hyperparameters in DiGGR is the number of latent factors , denoted as K. When 465
K= 1DiGGR degenerates into ordinary GMAE, only performing random masking over the entire 466
input graph on the nodes. The influence of tuning Kis illustrated in Figure 5. Given the relatively 467
small size of the graphs in the dataset, the number of meaningful latent disentangled factor zis 468
not expected to be very large. The optimal number of zthat maximizes performance tends to be 469
concentrated in the range of 2-4. 470
1 2 4 8 16
Factor Number K82.583.584.585.586.5Accuracy (%)
(a) Cora
1 2 4 8 16
Factor Number K8687888990Accuracy (%)
 (b) MUTAG
1 2 4 8 16
Factor Number K72.573.073.574.074.5Accuracy (%)
 (c) Citeseer
1 2 4 8 16
Factor Number K7274767880Accuracy (%)
 (d) IMDB-B
Figure 5: Performance of the task under different choices of latent factor number K, where the
horizontal axis represents the change in Kand the vertical axis is accuracy.
A.1.2 Representation for downstream tasks 471
We investigate the impact of various combinations of representation levels on downstream tasks. As 472
illustrated in Table 4, for the node classification task, both HdandHgare required, i.e., concatenating 473
them in feature dimension, whereas for the graph classification task, Hdalone is sufficient. This 474
difference may be due to the former not utilizing pooling operations, while the latter does. Specifically, 475
the graph pooling operation aggregates information from all nodes, providing a comprehensive 476
view of the entire graph structure. Thus, in node classification, where the node representation has 477
not undergone pooling, a graph-level representation ( Hg) is more critical. In contrast, in graph 478
classification, the node representation undergoes pooling, making disentangled information Hdmore 479
effective.
Table 4: The average accuracy of datasets is calculated through 5 random initialization tests when
using different representations.
HdHg Cora IMDB-MULTI Citeseer PROTEINS
✓ 61.10±1.83 54.77±2.63 71.82 ±0.98 77.76±2.46
✓ 84.22±0.38 51.62 ±0.61 73.41 ±0.43 75.52 ±0.49
✓ ✓ 84.96±0.32 53.69 ±2.06 73.98±0.27 77.61 ±0.97
480
A.2 Implementation Details 481
Environment All experiments are conducted on Linux servers equipped with an 12th Gen Intel(R) 482
Core(TM) i7-12700, 256GB RAM and a NVIDIA 3090 GPU. Models of node and graph classification 483
are implemented in PyTorch version 1.12.1, scikit-learn version 1.0.2 and Python 3.7. 484
Experiment Setup for Node Classification The node classification task involves predicting the 485
unknown node labels in networks. Cora, Citeseer, and Pubmed are employed for transductive learning, 486
whereas PPI follows the inductive setup outlined in GraphSage [Hamilton et al., 2017]. For evaluation, 487
13Table 5: Statistics for node classification datasets.
Dataset Cora Citeseer Pubmed PPI
Statistics# node 2708 3327 19717 56944
# feature 1433 3703 500 50
# edges 5429 4732 44338 818736
# classes 7(s) 6(s) 3(s) 121(m)
Hyper-parametersMask Rate 0.5 0.5 0.75 0.5
Hidden Size 512 512 1024 1024
Max Epoch 1750 200 1000 1000
λd;λg;λz 1; 1; 1 1; 1; 2 1; 1; 1 1; 1; 1
Learning Rate 0.001 0.0005 0.001 0.0001
Factor_Num 4 4 2 2
we use the concatenated representations of HdandHgin the feature dimension for the downstream 488
task. We then train a linear classifier, report the mean accuracy on the test nodes through 5 random 489
initializations. The graph encoder GNN enc(.)and decoder GNN dec(.)are both specified as standard 490
GAT [Velickovic et al., 2017].We train the model using Adam Optimizer with β1= 0.9,β2= 0.999, 491
ϵ= 1×108, and we use the cosine learning rate decay without warmup. We follow the public data 492
splits of Cora, Citeseer, and PubMed. 493
Experiment Setup for Graph Classification The graph classification experiment was conducted on 494
7 benchmarks, in which node labels are used as input features in MUTAG, PROTEINS and NCI1, and 495
node degrees are used in IMDB-BINARY , IMDB-MULTI, REDDIT-BINARY , and COLLAB. The 496
backbone of encoder and decoder is GIN [Xu et al., 2018], which is commonly used in previous graph 497
classification works. The evaluation protocol primarily follows GraphMAE [Hou et al., 2022]. Notice 498
that we only utilize the factor-wise latent representation Hdfor the downstream task. Subsequently, 499
we feed it into a downstream LIBSVM [Chang and Lin, 2011] classifier to predict the label and 500
report the mean 10-fold cross-validation accuracy with standard deviation after 5 runs. We set the 501
initial learning rate to 0.0005 with cosine learning rate decay for most cases. For the evaluation, the 502
parameter C of SVM is searched in the sets {103, ...,10}. 503
Data Preparation The node features for the citation networks (Cora, Citeseer, Pubmed) are bag-of- 504
words document representations. For the protein-protein interaction networks (PPI), the features of 505
each node are composed of positional gene sets, motif gene sets and immunological signatures (50 in 506
total). For graph classification, the MUTAG, PROTEINS, and NCI1 datasets utilize node labels as 507
node features, represented in the form of one-hot encoding. For IMDB-B, IMDB-M, REDDIT-B, and 508
COLLAB, which lack node features, we utilize the node degree and convert it into a one-hot encoding 509
as a substitute feature. The maximum node degree is set to 400. Nodes with degrees surpassing 400 510
are uniformly treated as having a degree of 400, following the methodology of GraphMAE[Hou et al., 511
2022]. Table 5 and Table 6 show the specific statistics of used datasets. 512
Details for Visualization MUTAG is selected as the representative benchmark for visualization 513
in 4.3. The MUTAG dataset comprises 3,371 nodes with seven node types. The distribution is 514
highly skewed, as 3,333 nodes belong to three types, while the remaining four types collectively 515
represent less than 1.2% of the nodes. For clarity in legend display, we have visualized only the nodes 516
belonging to the first three types. 517
A.3 Disentangled Representations Visualization 518
We chose PROTEINS and IMDB-MULTI as representatives of the graph classification dataset, and 519
followed the same methodology as in Section 4.3 to visualize their representation correlation matrices 520
on GraphMAE, and community representation correlation matrices on DiGGR, respectively. The 521
feature dimensions of PROTEINS and IMDB-MULTI are both 512 dimensions, and the number of 522
communities is set to 4. 523
14Table 6: Statistics for graph classification datasets.
Dataset IMDB-B IMDB-M PROTEINS COLLAB MUTAG REDDIT-B NCI1
StatisticsAvg. # node 19.8 13.0 39.1 74.5 17.9 429.7 29.8
# features 136 89 3 401 7 401 37
# graphs 1000 1500 1113 5000 188 2000 4110
# classes 2 3 2 3 2 2 2
Hyper-
parametersMask Rate 0.5 0.5 0.5 0.75 0.75 0.75 0.25
Hidden Size 512 512 512 256 32 512 1024
Max Epoch 300 200 50 20 20 200 200
Learning Rate 0.0001 0.001 0.0005 0.001 0.001 0.0005 0.0005
λd;λg;λz 1; 1; 1 1; 1; 1 1; 1; 1 1; 1; 1 1; 1; 1 1; 1; 1 1; 0.5; 1
Batch_Size 32 32 32 32 32 16 32
Pooling_Type mean mean max max sum max max
Factor_Num 2 4 4 4 2 2 4
The result is presented in Figure 6. We can see from the results that the graph representations of 524
GraphMAE are entangled. In contrast, the correlation pattern exhibited by DiGGR reveals four 525
distinct diagonal blocks. This suggests that DiGGR is proficient at capturing mutually exclusive 526
information within the latent factor, resulting in disentangled representations. 527
(a) PROTEINS, GraphMAE
 (b) PROTEINS, DiGGR
(c) IMDB-MULTI, GraphMAE
 (d) IMDB-MULTI, DiGGR
Figure 6: The absolute correlation between the representations learned by GraphMAE and DiGGR is
measured on the PROTEINS andIMDB-MULTI datasets when K= 4.
A.4 Training Algorithm 528
15Algorithm 1 The Overall Training Algorithm of DiGGR
1:Input : Graph G={V, A, X }; latent factor number K.
2:Parameters :Θin the inference network of Latent Factor Learning phase, Ωin the encoding
network of DiGGR, Ψin the decoding network of DiGGR.
3:Initialize Θ,Ω, andΨ;
4:foriter = 1,2, · ··do
5: Infer the variational posterior ofzubased on Eq. 5;
6: Sample latent factors zufrom the variational posterior according to Eq. 6;
7: Factorize the graph GintoKfactor-wise groups {G(k)}K
k=1by node and edge factorization
methods;
8: Encoding {G(k)}K
k=1via latent factor-wise Graph Masked Autoencoder according to Eq. 8;
9: Encoding Gvia graph-level graph masked autoencoder according to Eq. 11;
10: Calculate ∇Θ,Ω,ΨL(Θ,Ω,Ψ;G)according to Eq. 13, and update parameters Θ,Ω, andΨ
jointly.
11:end for =0
A.5 Broader Impacts 529
This paper presents work whose goal is to advance the field of Machine Learning. There are many 530
potential societal consequences of our work, none which we feel must be specifically highlighted 531
here. 532
A.6 Limitations 533
Despite the promising experimental justifications, our work might potentially suffer from limitation: 534
Although the complexity of the model is discussed in Section 3.4, and it is comparable to previously 535
published work, extending DiGGR to extremely large graph datasets remains challenging at this stage 536
due to the incorporation of an additional probabilistic model into the generative graph framework. 537
One potential solution to this problem could be utilizing PPR-Nibble [Andersen et al., 2006] for 538
efficient implementation, a method that has proven effective in some graph generative models [Hou 539
et al., 2023]. This approach will be pursued in our future work. 540
16NeurIPS Paper Checklist 541
1.Claims 542
Question: Do the main claims made in the abstract and introduction accurately reflect the 543
paper’s contributions and scope? 544
Answer: [Yes] 545
Justification: We listed our main contribution in the last paragraph of Section 1 546
Guidelines: 547
•The answer NA means that the abstract and introduction do not include the claims 548
made in the paper. 549
•The abstract and/or introduction should clearly state the claims made, including the 550
contributions made in the paper and important assumptions and limitations. A No or 551
NA answer to this question will not be perceived well by the reviewers. 552
•The claims made should match theoretical and experimental results, and reflect how 553
much the results can be expected to generalize to other settings. 554
•It is fine to include aspirational goals as motivation as long as it is clear that these goals 555
are not attained by the paper. 556
2.Limitations 557
Question: Does the paper discuss the limitations of the work performed by the authors? 558
Answer: [Yes] 559
Justification: We’ve discuss about the limitations in Appendix A.6 560
Guidelines: 561
•The answer NA means that the paper has no limitation while the answer No means that 562
the paper has limitations, but those are not discussed in the paper. 563
• The authors are encouraged to create a separate "Limitations" section in their paper. 564
•The paper should point out any strong assumptions and how robust the results are to 565
violations of these assumptions (e.g., independence assumptions, noiseless settings, 566
model well-specification, asymptotic approximations only holding locally). The authors 567
should reflect on how these assumptions might be violated in practice and what the 568
implications would be. 569
•The authors should reflect on the scope of the claims made, e.g., if the approach was 570
only tested on a few datasets or with a few runs. In general, empirical results often 571
depend on implicit assumptions, which should be articulated. 572
•The authors should reflect on the factors that influence the performance of the approach. 573
For example, a facial recognition algorithm may perform poorly when image resolution 574
is low or images are taken in low lighting. Or a speech-to-text system might not be 575
used reliably to provide closed captions for online lectures because it fails to handle 576
technical jargon. 577
•The authors should discuss the computational efficiency of the proposed algorithms 578
and how they scale with dataset size. 579
•If applicable, the authors should discuss possible limitations of their approach to 580
address problems of privacy and fairness. 581
•While the authors might fear that complete honesty about limitations might be used by 582
reviewers as grounds for rejection, a worse outcome might be that reviewers discover 583
limitations that aren’t acknowledged in the paper. The authors should use their best 584
judgment and recognize that individual actions in favor of transparency play an impor- 585
tant role in developing norms that preserve the integrity of the community. Reviewers 586
will be specifically instructed to not penalize honesty concerning limitations. 587
3.Theory Assumptions and Proofs 588
Question: For each theoretical result, does the paper provide the full set of assumptions and 589
a complete (and correct) proof? 590
Answer: [NA] 591
17Justification: This paper is not focus on theoretical explanations and assumptions 592
Guidelines: 593
• The answer NA means that the paper does not include theoretical results. 594
•All the theorems, formulas, and proofs in the paper should be numbered and cross- 595
referenced. 596
•All assumptions should be clearly stated or referenced in the statement of any theorems. 597
•The proofs can either appear in the main paper or the supplemental material, but if 598
they appear in the supplemental material, the authors are encouraged to provide a short 599
proof sketch to provide intuition. 600
•Inversely, any informal proof provided in the core of the paper should be complemented 601
by formal proofs provided in appendix or supplemental material. 602
• Theorems and Lemmas that the proof relies upon should be properly referenced. 603
4.Experimental Result Reproducibility 604
Question: Does the paper fully disclose all the information needed to reproduce the main ex- 605
perimental results of the paper to the extent that it affects the main claims and/or conclusions 606
of the paper (regardless of whether the code and data are provided or not)? 607
Answer: [Yes] 608
Justification: We have listed the specific settings of the experiment in the appendix A.2 of 609
the paper, including the datasets used and the hyperparameter settings of the model. We 610
have also uploaded the code in the supplementary material. 611
Guidelines: 612
• The answer NA means that the paper does not include experiments. 613
•If the paper includes experiments, a No answer to this question will not be perceived 614
well by the reviewers: Making the paper reproducible is important, regardless of 615
whether the code and data are provided or not. 616
•If the contribution is a dataset and/or model, the authors should describe the steps taken 617
to make their results reproducible or verifiable. 618
•Depending on the contribution, reproducibility can be accomplished in various ways. 619
For example, if the contribution is a novel architecture, describing the architecture fully 620
might suffice, or if the contribution is a specific model and empirical evaluation, it may 621
be necessary to either make it possible for others to replicate the model with the same 622
dataset, or provide access to the model. In general. releasing code and data is often 623
one good way to accomplish this, but reproducibility can also be provided via detailed 624
instructions for how to replicate the results, access to a hosted model (e.g., in the case 625
of a large language model), releasing of a model checkpoint, or other means that are 626
appropriate to the research performed. 627
•While NeurIPS does not require releasing code, the conference does require all submis- 628
sions to provide some reasonable avenue for reproducibility, which may depend on the 629
nature of the contribution. For example 630
(a)If the contribution is primarily a new algorithm, the paper should make it clear how 631
to reproduce that algorithm. 632
(b)If the contribution is primarily a new model architecture, the paper should describe 633
the architecture clearly and fully. 634
(c)If the contribution is a new model (e.g., a large language model), then there should 635
either be a way to access this model for reproducing the results or a way to reproduce 636
the model (e.g., with an open-source dataset or instructions for how to construct 637
the dataset). 638
(d)We recognize that reproducibility may be tricky in some cases, in which case 639
authors are welcome to describe the particular way they provide for reproducibility. 640
In the case of closed-source models, it may be that access to the model is limited in 641
some way (e.g., to registered users), but it should be possible for other researchers 642
to have some path to reproducing or verifying the results. 643
5.Open access to data and code 644
18Question: Does the paper provide open access to the data and code, with sufficient instruc- 645
tions to faithfully reproduce the main experimental results, as described in supplemental 646
material? 647
Answer: [Yes] 648
Justification: We have uploaded the code in the supplementary material. 649
Guidelines: 650
• The answer NA means that paper does not include experiments requiring code. 651
•Please see the NeurIPS code and data submission guidelines ( https://nips.cc/ 652
public/guides/CodeSubmissionPolicy ) for more details. 653
•While we encourage the release of code and data, we understand that this might not be 654
possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not 655
including code, unless this is central to the contribution (e.g., for a new open-source 656
benchmark). 657
•The instructions should contain the exact command and environment needed to run to 658
reproduce the results. See the NeurIPS code and data submission guidelines ( https: 659
//nips.cc/public/guides/CodeSubmissionPolicy ) for more details. 660
•The authors should provide instructions on data access and preparation, including how 661
to access the raw data, preprocessed data, intermediate data, and generated data, etc. 662
•The authors should provide scripts to reproduce all experimental results for the new 663
proposed method and baselines. If only a subset of experiments are reproducible, they 664
should state which ones are omitted from the script and why. 665
•At submission time, to preserve anonymity, the authors should release anonymized 666
versions (if applicable). 667
•Providing as much information as possible in supplemental material (appended to the 668
paper) is recommended, but including URLs to data and code is permitted. 669
6.Experimental Setting/Details 670
Question: Does the paper specify all the training and test details (e.g., data splits, hyper- 671
parameters, how they were chosen, type of optimizer, etc.) necessary to understand the 672
results? 673
Answer: [Yes] 674
Justification: We have listed the specific exprimental setup in Appendix A.2 675
Guidelines: 676
• The answer NA means that the paper does not include experiments. 677
•The experimental setting should be presented in the core of the paper to a level of detail 678
that is necessary to appreciate the results and make sense of them. 679
•The full details can be provided either with the code, in appendix, or as supplemental 680
material. 681
7.Experiment Statistical Significance 682
Question: Does the paper report error bars suitably and correctly defined or other appropriate 683
information about the statistical significance of the experiments? 684
Answer: [Yes] 685
Justification: In the main experiment 4, we ran 5 different random seeds for each dataset 686
and reported the average results and variances in the table6 and 5. 687
Guidelines: 688
• The answer NA means that the paper does not include experiments. 689
•The authors should answer "Yes" if the results are accompanied by error bars, confi- 690
dence intervals, or statistical significance tests, at least for the experiments that support 691
the main claims of the paper. 692
•The factors of variability that the error bars are capturing should be clearly stated (for 693
example, train/test split, initialization, random drawing of some parameter, or overall 694
run with given experimental conditions). 695
19•The method for calculating the error bars should be explained (closed form formula, 696
call to a library function, bootstrap, etc.) 697
• The assumptions made should be given (e.g., Normally distributed errors). 698
•It should be clear whether the error bar is the standard deviation or the standard error 699
of the mean. 700
•It is OK to report 1-sigma error bars, but one should state it. The authors should 701
preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis 702
of Normality of errors is not verified. 703
•For asymmetric distributions, the authors should be careful not to show in tables or 704
figures symmetric error bars that would yield results that are out of range (e.g. negative 705
error rates). 706
•If error bars are reported in tables or plots, The authors should explain in the text how 707
they were calculated and reference the corresponding figures or tables in the text. 708
8.Experiments Compute Resources 709
Question: For each experiment, does the paper provide sufficient information on the com- 710
puter resources (type of compute workers, memory, time of execution) needed to reproduce 711
the experiments? 712
Answer: [Yes] 713
Justification: We listed the experiment environment in AppendixA.2 714
Guidelines: 715
• The answer NA means that the paper does not include experiments. 716
•The paper should indicate the type of compute workers CPU or GPU, internal cluster, 717
or cloud provider, including relevant memory and storage. 718
•The paper should provide the amount of compute required for each of the individual 719
experimental runs as well as estimate the total compute. 720
•The paper should disclose whether the full research project required more compute 721
than the experiments reported in the paper (e.g., preliminary or failed experiments that 722
didn’t make it into the paper). 723
9.Code Of Ethics 724
Question: Does the research conducted in the paper conform, in every respect, with the 725
NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines ? 726
Answer: [Yes] 727
Justification: We conform with the NeurIPS Code of Ethics in every respect for this paper. 728
Guidelines: 729
•The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. 730
•If the authors answer No, they should explain the special circumstances that require a 731
deviation from the Code of Ethics. 732
•The authors should make sure to preserve anonymity (e.g., if there is a special consid- 733
eration due to laws or regulations in their jurisdiction). 734
10.Broader Impacts 735
Question: Does the paper discuss both potential positive societal impacts and negative 736
societal impacts of the work performed? 737
Answer: [Yes] 738
Justification: We have discussed in appendix A.5 739
Guidelines: 740
• The answer NA means that there is no societal impact of the work performed. 741
•If the authors answer NA or No, they should explain why their work has no societal 742
impact or why the paper does not address societal impact. 743
•Examples of negative societal impacts include potential malicious or unintended uses 744
(e.g., disinformation, generating fake profiles, surveillance), fairness considerations 745
(e.g., deployment of technologies that could make decisions that unfairly impact specific 746
groups), privacy considerations, and security considerations. 747
20•The conference expects that many papers will be foundational research and not tied 748
to particular applications, let alone deployments. However, if there is a direct path to 749
any negative applications, the authors should point it out. For example, it is legitimate 750
to point out that an improvement in the quality of generative models could be used to 751
generate deepfakes for disinformation. On the other hand, it is not needed to point out 752
that a generic algorithm for optimizing neural networks could enable people to train 753
models that generate Deepfakes faster. 754
•The authors should consider possible harms that could arise when the technology is 755
being used as intended and functioning correctly, harms that could arise when the 756
technology is being used as intended but gives incorrect results, and harms following 757
from (intentional or unintentional) misuse of the technology. 758
•If there are negative societal impacts, the authors could also discuss possible mitigation 759
strategies (e.g., gated release of models, providing defenses in addition to attacks, 760
mechanisms for monitoring misuse, mechanisms to monitor how a system learns from 761
feedback over time, improving the efficiency and accessibility of ML). 762
11.Safeguards 763
Question: Does the paper describe safeguards that have been put in place for responsible 764
release of data or models that have a high risk for misuse (e.g., pretrained language models, 765
image generators, or scraped datasets)? 766
Answer: [NA] 767
Justification: this paper poses no such risks. 768
Guidelines: 769
• The answer NA means that the paper poses no such risks. 770
•Released models that have a high risk for misuse or dual-use should be released with 771
necessary safeguards to allow for controlled use of the model, for example by requiring 772
that users adhere to usage guidelines or restrictions to access the model or implementing 773
safety filters. 774
•Datasets that have been scraped from the Internet could pose safety risks. The authors 775
should describe how they avoided releasing unsafe images. 776
•We recognize that providing effective safeguards is challenging, and many papers do 777
not require this, but we encourage authors to take this into account and make a best 778
faith effort. 779
12.Licenses for existing assets 780
Question: Are the creators or original owners of assets (e.g., code, data, models), used in 781
the paper, properly credited and are the license and terms of use explicitly mentioned and 782
properly respected? 783
Answer: [Yes] 784
Justification: All these are properly credited. 785
Guidelines: 786
• The answer NA means that the paper does not use existing assets. 787
• The authors should cite the original paper that produced the code package or dataset. 788
•The authors should state which version of the asset is used and, if possible, include a 789
URL. 790
• The name of the license (e.g., CC-BY 4.0) should be included for each asset. 791
•For scraped data from a particular source (e.g., website), the copyright and terms of 792
service of that source should be provided. 793
•If assets are released, the license, copyright information, and terms of use in the 794
package should be provided. For popular datasets, paperswithcode.com/datasets 795
has curated licenses for some datasets. Their licensing guide can help determine the 796
license of a dataset. 797
•For existing datasets that are re-packaged, both the original license and the license of 798
the derived asset (if it has changed) should be provided. 799
21•If this information is not available online, the authors are encouraged to reach out to 800
the asset’s creators. 801
13.New Assets 802
Question: Are new assets introduced in the paper well documented and is the documentation 803
provided alongside the assets? 804
Answer: [NA] 805
Justification: This paper does not release new assets. 806
Guidelines: 807
• The answer NA means that the paper does not release new assets. 808
•Researchers should communicate the details of the dataset/code/model as part of their 809
submissions via structured templates. This includes details about training, license, 810
limitations, etc. 811
•The paper should discuss whether and how consent was obtained from people whose 812
asset is used. 813
•At submission time, remember to anonymize your assets (if applicable). You can either 814
create an anonymized URL or include an anonymized zip file. 815
14.Crowdsourcing and Research with Human Subjects 816
Question: For crowdsourcing experiments and research with human subjects, does the paper 817
include the full text of instructions given to participants and screenshots, if applicable, as 818
well as details about compensation (if any)? 819
Answer: [NA] 820
Justification: This paper does not involve crowdsourcing nor research with human subjects. 821
Guidelines: 822
•The answer NA means that the paper does not involve crowdsourcing nor research with 823
human subjects. 824
•Including this information in the supplemental material is fine, but if the main contribu- 825
tion of the paper involves human subjects, then as much detail as possible should be 826
included in the main paper. 827
•According to the NeurIPS Code of Ethics, workers involved in data collection, curation, 828
or other labor should be paid at least the minimum wage in the country of the data 829
collector. 830
15.Institutional Review Board (IRB) Approvals or Equivalent for Research with Human 831
Subjects 832
Question: Does the paper describe potential risks incurred by study participants, whether 833
such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) 834
approvals (or an equivalent approval/review based on the requirements of your country or 835
institution) were obtained? 836
Answer: [NA] 837
Justification: This paper does not involve crowdsourcing nor research with human subjects. 838
Guidelines: 839
•The answer NA means that the paper does not involve crowdsourcing nor research with 840
human subjects. 841
•Depending on the country in which research is conducted, IRB approval (or equivalent) 842
may be required for any human subjects research. If you obtained IRB approval, you 843
should clearly state this in the paper. 844
•We recognize that the procedures for this may vary significantly between institutions 845
and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the 846
guidelines for their institution. 847
•For initial submissions, do not include any information that would break anonymity (if 848
applicable), such as the institution conducting the review. 849
22