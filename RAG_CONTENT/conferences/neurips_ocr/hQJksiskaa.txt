Autobidder’s Dilemma: Why More Sophisticated
Autobidders Lead to Worse Auction Efficiency
Yuan Deng
Google Research
dengyuan@google.comJieming Mao
Google Research
maojm@google.comVahab Mirrokni
Google Research
mirrokni@google.com
Hanrui Zhang
Chinese University of Hong Kong
hanrui@cse.cuhk.edu.hkSong Zuo
Google Research
szuo@google.com
Abstract
The recent increasing adoption of autobidding has inspired the growing interest
in analyzing the performance of classic mechanism with value-maximizing auto-
bidders both theoretically and empirically. It is known that optimal welfare can be
obtained in first-price auctions if autobidders are restricted to uniform bid-scaling
and the price of anarchy is 2when non-uniform bid-scaling strategies are allowed.
In this paper, we provide a fine-grained price of anarchy analysis for non-uniform
bid-scaling strategies in first-price auctions, demonstrating the reason why more
powerful (individual) non-uniform bid-scaling strategies may lead to worse (ag-
gregated) performance in social welfare. Our theoretical results match recent
empirical findings that a higher level of non-uniform bid-scaling leads to lower
welfare performance in first-price auctions.
1 Introduction
The online advertising market has witnessed increasing adoption of autobidding in recent years,
which shifts the bidding behavior model of advertisers from the classic utility-maximizing bidding
to value-maximizing bidding [Aggarwal et al., 2019, Balseiro et al., 2021b]. Unlike the classic
utility maximizers who maximize their quasi-linear utility given by the difference between value
and payment, value maximizers maximize the total value subject to a return-on-spend (RoS) con-
straint [Balseiro et al., 2021b].
The shift in the bidding behavior model has motivated a growing body of literature on auction design
with value-maximizing autobidders. Notably, it has been shown that the price of anarchy (PoA) in
second-price auctions [Aggarwal et al., 2019] and first-price auctions [Deng et al., 2022, Liaw et al.,
2023] are both 2. However, (1) these PoA results measure the welfare performance in the worst-case
scenario (i.e., the worst-case equilibrium of the worst-case instance); moreover, (2) these PoA results
assume the bidding agents can find the optimal bidding strategies in response to other bidders so
that their bidding profile forms an equilibrium, while computing optimal bidding strategies and/or
finding equilibria could be computationally infeasible [Aggarwal et al., 2023, Chen et al., 2021, Li
and Tang, 2024, Paes Leme et al., 2024]. On the other hand, Balseiro et al. [2021a] demonstrate
that optimal welfare can be obtained in first-price auctions if autobidders are restricted to the simple
uniform bid-scaling strategy (i.e., always bid θvwhen the bidder’s value is vwith a universal bid
multiplier θ). But, uniform bid-scaling is not always an optimal strategy for autobidders in first-price
auctions as non-uniform bidding scaling, in which autobidder may apply different bid multipliers in
different auctions, may result in better bidding performance.
38th Conference on Neural Information Processing Systems (NeurIPS 2024).To circumvent the above mentioned limitations of PoA results and bridge the gap between uniform
bid-scaling and non-uniform bid-scaling, Deng et al. [2024] propose a hierarchical structure over ad
auction instances in which the auctions are partitioned to different categories following a multi-layer
laminar structure. Autobidders are required to adopt the same bid multipliers for auctions within the
same slice but can use different bid multipliers across different slices. Such a multi-layer structure
enables the comparison between non-uniform bid-scaling strategies of different degrees of freedom
and the empirical results from [Deng et al., 2024] show that a higher level of non-uniform bid-scaling
may lead to lower aggregated welfare performance in first-price auctions. In this paper, we take a
theoretical approach to non-uniform bid-scaling in first-price marketplaces, aiming to (1) provide a
formal understanding of the phenomenon observed by Deng et al. [2024], and (2) establish principles
that can guide the design of marketplaces where non-uniform bid-scaling is involved.
1.1 Our Results
Our main technical result is a fine-grained analysis of the price of anarchy of automated first-price
marketplaces when autobidders are capable of non-uniform bidding. We adopt the high-level model
introduced by Deng et al. [2024]: Roughly speaking, the entire market is divided into a number of
slices, and autobidders may choose one bid multiplier independently for each slice. Here, intuitively,
the granularity of the slices measures autobidders’ capability of non-uniform bidding. Through a
refined analysis, we present a parameterized price of anarchy bound, which connects the efficiency of
an automated marketplace to the power of autobidders measured by their capability of non-uniform
bidding, as well as the “balancedness” of slices. Here, the balancedness of a slice roughly measures
the smallest “market share” across all bidders. Qualitatively, our results suggest:
•First-price markets are more efficient when autobidders are less powerful . This is reminis-
cent of the prisoner’s dilemma, where both prisoners end up in a strictly worse situation,
when each of them chooses an action that is superior to the alternative, regardless of the
other prisoner’s choice. In automated marketplaces, fixing others’ bids, a more powerful
autobidder always achieves a (weakly) better payoff. And yet, the interplay of such “better”
autobidders could lead to worse auction efficiency. This provides a theoretical explanation
for the phenomenon observed by Deng et al. [2024].
•First-price markets are more efficient with more balanced slices . In particular, when the
granularity of non-uniform bidding is fixed, one can improve the efficiency of the market by
creating slices that are more balanced. Intuitively, this introduces more intense competition
within each slice, resulting in better auction efficiency. Such an insight can also be applied to
marketplaces with the multi-channel setting [Deng et al., 2023a, Susan et al., 2023], where
advertisers can procure ad impressions simultaneously on multiple channels with different
bidding strategies. In the multi-channel setting, more balanced channels could lead to better
auction efficiency across all channels.
1.2 Further Related Work
The price of anarchy in first-price auctions with quasi-linear utility maximizers has been extensively
studied [Roughgarden et al., 2017]. For Bayesian settings, the price of anarchy is at least 1/2
for subadditive valuations [Feldman et al., 2013] and the price of anarchy is at least 1−1/efor
submodular valuations [Syrgkanis and Tardos, 2013]. When values are independently distributed,
Hoy et al. [2018] improved the price of anarchy to ≈0.743. Recently, Jin and Lu [2022] resolve
the long-standing open problem and show that the price of anarchy in first-price auctions with
independently distributed values is exactly 1−1/e2.
Our work is also closely related to the recent growing body of research [Aggarwal et al., 2019, Deng
et al., 2021, Balseiro et al., 2021a, Mehta, 2022, Deng et al., 2023b, Liaw et al., 2024] which study
the price of anarchy (PoA) with value-maximizing bidders in several classic auction mechanisms like
second-price auctions, (randomized) first-price auctions, and generalized second-price auctions. In
particular, it has been shown the price of anarchy of first-price auctions is exactly 1/2[Liaw et al.,
2023, Deng et al., 2022]. In the multi-channel setting, Deng et al. [2023a] study the problem of
multi-channel bidding where an advertiser aims to maximize their total value across and analyze the
effectiveness of levers of return-on-spend and budget. Susan et al. [2023] develop multi-channel
bidding algorithms when channels adopt auction rules that may or may not be incentive-compatible
2under the presence of budget constraints. More recently, Feng et al. [2023] investigate the PoA of
running first-price auctions with strategic budget-constrained autobidders, in which advertisers may
manipulate their reported budget constraints for the autobidders. For a more comprehensive overview
of auctions and autobidding, see, e.g., [Aggarwal et al., 2024].
2 Preliminaries
The multi-auction model. Following prior works [Aggarwal et al., 2019, Balseiro et al., 2021b],
we consider the following model where multiple bidders participate in multiple auctions simul-
taneously. There are nbidders (generally indexed by i) and mauctions (generally indexed by
j). In each auction j, each bidder ihas a value vi,j, and places a bid bi,j. In this paper, we as-
sume these bids are placed through autobidders using non-uniform bidding, in which the bids are
subject to certain restrictions to be discussed below. For brevity, we let vi= (vi,1, . . . , v i,m),
v= (v1, . . . ,vn),v−i= (v1, . . . ,vi−1,vi+1, . . . ,vn),vj= (v1,j, . . . , v n,j), and v−i,j=
(v1,j, . . . , v i−1,j, vi+1,j, . . . , v n,j). We use bin a similar way.
Each bidder i’s allocation xi,jand payment pi,jin each auction jis determined by the auction rule
and all bidders’ bids bjin auction j. We focus on first-price auctions: In each auction j, the bidder
with the highest bid1wins, receives the whole item and pays the bid. All other bidders receive nothing
and pay 0. Formally, for each auction j, leti∗(j) = argmaxibi,j. The allocation xi,jand payment
pi,jof each bidder iis given by
xi,j=1,ifi=i∗(j)
0,otherwise, and pi,j=bi,j,ifi=i∗(j)
0, otherwise.
We will omit the dependency of xi,jandpi,jonbfor simplicity. For each auction j, we also identify
a “rightful winner” rw(j) = argmaxi∈[n]vi,j, who has the highest value and therefore should win in
auction jin the socially optimal allocation.2
Slices and partially non-uniform bidding. We capture the power of autobidders beyond uniform
bidding with a fine-grained slice-based model [Deng et al., 2024]. Intuitively, we assume that the m
auctions are partitioned into slices. Within each slice, the autobidder must bid uniformly, while across
slices, it can use different bidding multipliers. Formally, there are sslices (generally indexed by k),
which together form a partition of the mauctions. Each slice kis described by the set Sk⊆[m]of
(indices of) auctions it contains. We always have Sk∩Sk′=∅for all k̸=k′, andS
kSk= [m]. For
each auction j∈Sk, we let slice(j) =k. The bids biof each bidder iis generated in the following
way: For each slice k, the autobidder chooses a bid multiplier θi,ksuch that for each auction j∈Sk,
bi,j=vi,j·θi,k. We use θin a similar way to vandb.
Constrained value maximizers. We adopt the value maximization model prevalent in the autobid-
ding literature [Aggarwal et al., 2019, Balseiro et al., 2021b]. The objective of a value maximizer is to
maximize the total value that they win in all auctions, subject to the constraint that the overall return
on spend (RoS) is larger than a given target, by choosing the optimal bid multipliers for all sslices
conditioned on other bidders’ bids. In addition, we make the following regularity assumption about
bidders’ strategies: On each slice k, each bidder inever underbids (i.e., never chooses a multiplier
θi,k<1) unless iwins in all auctions j∈Skwhere iis the rightful winner (i.e., where rw(j) =i).
The assumption rules out brittle and pathological equilibrium behavior, which allows us to focus
on the relation between the power of autobidders and auction efficiency. Intuitively, if a bidder iis
forced to underbid on a slice k, then imust be overbidding on some other slices (because the overall
RoS constraint must be binding — see below for the formal definition). In such cases, the assumption
says that autobidders are conservative, in the sense that bidder iwould try to secure i’s share in the
socially optimal allocation on each slice first, before bidding more aggressively and trying to acquire
other bidders’ share on other slices. We also remark that such regularity assumptions are used in prior
work (e.g., [Deng et al., 2021]) to derive meaningful efficiency bounds for other auction formats.
1We assume ties are broken arbitrarily and consistently throughout the paper.
2Ties are broken in the same way as in winner determination.
3Formally, let vali,j=xi,j·vi,jbei’s value in auction j. Let
vali=X
j∈[m]vali,j and pi=X
j∈[m]pi,j.
Moreover, for each bidder iand slice k, fixing θ−i,k, letθi,k(θ−i,k) = min {1, θ}, where
θ= min {θi,k|xi,j= 1,∀j∈Skwhere rw(j) =i}.
Let
Θi(θ−i) = [θi,1(θ−i,1),∞)× ··· × [θi,s(θ−i,s),∞).
Then, fixing θ−i(and therefore b−i), each bidder isolves the following optimization problem:
max
θi∈Θi(θ−i)vali
s.t. vali≥pi.
We say θi∈BRi(θ−i)ifθiachieves the maximum of the above optimization problem given θ−i.
Note that here, we are assuming that bidder i’s target RoS is 1. This is without loss of generality,
because scaling each bidder’s values by their target RoS preserves the auction outcomes and the
liquid welfare, the latter being the standard measure of efficiency with constrained value maximizers.
Equilibria and price of anarchy. We consider stable auction outcomes based on Nash equilibria,
where all bidders are best responding to each other. Formally, we say a strategy profile θis an
equilibrium, iff for each bidder i,θi∈BRi(θ−i). We measure efficiency by considering the
standard notion of the Price of Anarchy (PoA), which is the ratio between the liquid welfare at
the worst equilibrium and the optimal liquid welfare. Formally, the PoA of a particular instance
(n, m, s, {Sk},v)in the multi-auction model is defined as follows:
PoA(n, m, s, {Sk},v) = inf
θis an equilibriumP
i∈[n]valiP
j∈[m]max i∈[n]vi,j.
Note that the above definition of PoA is with respect to a single market instance. In later sections, we
will adopt a specific parametrization of non-uniformity, and consider the worst-case PoA for any fixed
non-uniformity parameters. This allows us to clearly depict the relation between non-uniformity and
efficiency of auction outcomes. We also remark that this approach refines the standard PoA analysis,
which normally establishes a single worst-case PoA bound over all instances.
3 Fine-Grained PoA of First-Price Auctions with Non-Uniform autobidders
In this section, we present and prove the main result of this paper: a fine-grained PoA bound capturing
the effect of non-uniform bidding on auction efficiency. As we will discuss later, our result implies that
more sophisticated (i.e., more non-uniform) autobidders generally lead to worse auction efficiency.
3.1 The Balancedness Parametrization
We first introduce our parametrization of non-uniformity. Fix a market instance (n, m, s, {Sk},v).
Definition 1 (Market share) .The market share of a bidder iin a set of auctions S⊆[m]isi’s
contribution to the optimal liquid welfare in S, as a fraction of the optimal liquid welfare. Formally,
share i,S=P
j∈S:rw(j)=ivi,jP
j∈[m]max i′∈[n]vi′,j.
Definition 2 (Balancedness) .The balancedness of a set of auctions S⊆[m]is the minimum
market share of all bidders in S, as a fraction of the sum of all bidders’ market shares in S(i.e., the
contribution of Sto the optimal liquid welfare). Formally,
balS=mini∈[n]share i,SP
i∈[n]share i,S.
4Without loss of generality, we assume (unless otherwise specified) that slices are numbered such
thatbalkis weakly decreasing in k, i.e., for each k∈[s−1],balk+1≤balk. Higher balancedness
generally means that the contribution to the optimal welfare is more equally distributed among
bidders. We will pay special attention to the market share in, and the balancedness of, a whole slice,
where S=Skfor some slice k. Abusing notation, we let share i,k=share i,Skfor each bidder iand
slicek, and share k=P
i∈[n]share i,kandbalk=balSkfor each slice k.
We discuss the intuition behind these definitions below. Generally speaking, inefficiency in first-price
auctions with value maximizers often manifests in the following way:
•A bidder wins in a large fraction of auctions where that bidder is the rightful winner, without
much competition. This means the bidder wins by bidding far below their true value in these
auctions, which gives the bidder a significant amount of buyer surplus.
•While the bidder (being a value maximizer) does not intrinsically care about buyer surplus, it
allows the bidder to bid more aggressively (i.e., far above their true value) in other auctions,
and win extra auctions in which they are not the rightful winners, which makes the auction
outcome less efficient.
For autobidders using slice-based non-uniform bidding strategies, since each bidder must bid uni-
formly (i.e., equally aggressively) within each slice, intuitively, more balanced slices make it harder
for the above phenomenon to happen. In particular, in the first bullet point, on a balanced slice, all
bidders are bidding seriously because they want to defend their market share, which leads to higher
competition and lower buyer surplus. In particular, this means they are more likely to use higher bid
multipliers. In the second bullet point, by bidding aggressively above their true values, the bidder
is also paying much more than they “should” in auctions where they are the rightful winner, which
depletes their buyer surplus without hurting the efficiency (because they are the rightful winner in
these auctions). We will prove below that this is in fact what happens.
In order to measure the balancedness of a market instance, we will aggregate the balancedness across
slices via the balancedness quantile function defined as follows.
Definition 3 (Balancedness quantile function) .Fix any market instance (n, m, s, {Sk},v). The
balancedness quantile function Fof the market instance is a function such that for any given t∈[0,1],
F(t)is the infimum value bsuch that at least a tfraction of the entire market has balancedness at
most b. That is,
F(t) = inf

bX
k∈[s]:balk≤bshare k≥t

.
The balancedness quantile function can also be viewed as the inverse of the “cumulative distribution
function” of the unbalancedness in the entire market. Note that F(t)∈[0,1/2]since balk∈[0,1/2]
whenever n≥2. Our actual bound will depend on the following parameter related to F(t).
Definition 4 (Unbalancedness of market instance) .Fix any market instance (n, m, s, {Sk},v). Let
αbe the function such that for any b∈[0,1/2]andu∈R,
α(b, u) = 1−2b+p
b·(1−b)·u.
Moreover, let βbe the function such that for any w∈[0,1],β(w)is the unique number usuch that,
Zw
0α(F(t), u) dt= 1−w.
The unbalancedness unbal (n, m, s, {Sk},v)of the market instance is defined such that
unbal (n, m, s, {Sk},v) =
max
w∈[0,1]Zw
0
1 +α(F(t), β(w))−p
(1−α(F(t), β(w)))2+ 4F(t)·α(F(t), β(w))
dt.
We establish the following intuitive properties of the unbalancedness, which will help make the
conceptual messages of our main result (to be discussed in the next subsection) clearer.
Proposition 1. The unbalancedness parameter has the following properties:
5tF(t)
112
t1F(t1)t2F(t2)Figure 1: A graphical example of the balancedness quantile function. Each grey rectangle corre-
sponds to a slice k, where the height is balkand the width share k. Observe that the height of each
rectangle is at most balk≤1/2, and the widths of all rectangles sum toP
k∈[s]share k= 1.
•unbal (n, m, s, {Sk},v)weakly increases when balkdecreases for some slice k∈[s].
•unbal (n, m, s, {Sk},v)weakly increases when a slice is subdivided, i.e.,
unbal (n, m, s, {Sk},v)≤unbal (n, m, s + 1,{S′
k},v),
where there exists k∗∈[s], such that S′
k=Skfor all k∈[s]\{k∗}andS′
s+1∪S′
k∗=Sk∗.3
•unbal (n, m, s, {Sk},v)∈[2/5,1]for each market instance (n, m, s, {Sk},v)where n≥2
ands≥2.
Proof. Note that the unbalancedness depends only on the balancedness quantile function. We first
argue that the unbalancedness weakly increases when the balancedness quantile function pointwise
weakly decreases. Observe that unbal (·)can be equivalently defined in the following way: For each
w∈[0,1], let
γ(w) = max
λ∈Λ(w)Zw
0
1 +λ(t)−p
(1−λ(t))2+ 4F(t)·λ(t)
dt,
where Λ(w)is the set of mappings from [0, w]to[0,∞), satisfying for each λ∈Λ(w),
Zw
0λ(t) dt= 1−w.
Note that this maximum is guaranteed to exist.4Then
unbal (n, m, s, {Sk},v) = max
w∈[0,1]γ(w).
This alternative definition is equivalent to Definition 4 because for a fixed w, the maximizing λof
γ(λ)must satisfy: For each t1, t2∈[0, w]
∂(1 +λ(t1)−p
(1−λ(t1))2+ 4F(t1)λ(t1))
∂(λ(t1))=∂(1 +λ(t2)−p
(1−λ(t2))2+ 4F(t2)λ(t2))
∂(λ(t2)).
3Here we do not assume slices are ordered such that the balancedness is weakly increasing.
4To quickly see why this is the case, observe that without loss of generality λis piecewise constant with at
mosts+ 1pieces, because Fis piecewise constant with at most spieces.
6This must be true because otherwise one can adjust λlocally and achieve a larger value of the integral.
Given the above, one can show (see the proof of Lemma 1 in Appendix A for a detailed argument) that
the maximizing λmust satisfy: There exists some usuch that for each t∈[0, w],λ(t) =α(F(t), u),
where αis defined in Definition 4. The unique choice of uthat satisfies the constraint on λis then
β(w), and the alternative definition then reduces to Definition 4.
Now to argue that unbal weakly increases when Fpointwise weakly decreases, we only need to
show that for each w∈[0,1],γ(w)weakly increases when Fpointwise weakly decreases. The latter
further reduces to: Fixing any λsatisfying the conditions above, the integral
Zw
0
1 +λ(t)−p
(1−λ(t))2+ 4F(t)·λ(t)
dt
weakly increases when Fpointwise weakly decreases. This is true because the integrand increases
when F(t)decreases.
Now we come back to the properties to be proved. The first property becomes almost obvious, because
when balkweakly decreases for some slice k,Fmust pointwise weakly decrease, and therefore unbal
must weakly increase. As for the third property, we consider extreme cases of F: When F(t) = 0
for each t∈[0,1], in Definition 4, α(F(t), u)is always 1, and unbal (n, m, s, {Sk},v) = 1 . This
is the largest unbalancedness possible. When F(t) = 1 /2for each t∈[0,1],α(F(t), u) =u/2,
β(w) = 2 /w−2, and one can show unbal (n, m, s, {Sk},v) = 2 /5(achieved when w= 3/5). This
is the smallest unbalancedness possible.
The second property is a bit trickier. To see why this is true, consider the parameters wandλthat
achieve unbal (n, m, s, {Sk},v)in the alternative definition. Moreover, without loss of generality
(recall that λis without loss of generality piecewise constant), suppose λis weakly decreasing onP
k∈[k∗−1]share k,P
k∈[k∗]share k
. Let share′
kandbal′
kbe the market share and balancedness
of each slice kin the new market instance. Without loss of generality, suppose bal′
k∗≤bal′
s+1.
Define Gto be the “partially unordered” balancedness quantile function of the new market instance
(n, m, s + 1,{S′
k},v)that preserves the ordering of the slices before subdivision, i.e.,
G(t) =

F(t), ift≤P
k∈[k∗−1]share kort >P
k∈[k∗]share k
bal′
k∗,ifP
k∈[k∗−1]share k< t≤P
k∈[k∗]share′
k
bal′
s+1,otherwise.
Intuitively, Gis obtained by splitting slice k∗“in place” from F. One can show that
unbal (n, m, s + 1,{S′
k},v)≥Zw
0
1 +λ(t)−p
(1−λ(t)2+ 4G(t)·λ(t)
dt.
This is essentially because the alternative definition is oblivious to “ordering” of the balancedness
quantile function. So,
unbal (n, m, s + 1,{S′
k},v)−unbal (n, m, s, {Sk},v)
≥ZP
k∈[k∗]sharek
P
k∈[k∗−1]sharekp
(1−λ(t))2+ 4F(t)·λ(t)−p
(1−λ(t))2+ 4G(t)·λ(t)
dt.
We only need to argue that the right hand side is at least 0. Since λis weakly decreasing, Fis
constant, and Gis weakly increasing (because bal′
k∗≤bal′
s+1), in the worst case, λis constant on
the interval of interest here (say λ(t) =ℓ >0). Then, the right hand side becomes
share k∗·p
(1−ℓ)2+ 4balk∗·ℓ
−share′
k∗·q
(1−ℓ)2+ 4bal′
k∗·ℓ−share′
s+1·q
(1−ℓ)2+ 4bal′
s+1·ℓ.
Here we have
share′
k∗+share′
s+1=share k∗and bal′
k∗·share′
k∗+bal′
s+1·share′
s+1≤balk∗·share k∗,
because the two new slices are obtained by subdividing the old slice k∗. For brevity, let
a=share′
k∗, b=share′
s+1, c=share k∗, x=bal′
k∗, y=bal′
s+1, z=balk∗.
7We only need to show
cp
(1−ℓ)2+ 4zℓ≥ap
(1−ℓ)2+ 4xℓ+bp
(1−ℓ)2+ 4yℓ,
where
a+b=cand ax+by≤cz.
Applying Cauchy-Schwarz, we have
ap
(1−ℓ)2+ 4xℓ+bp
(1−ℓ)2+ 4yℓ≤p
(a+b)·(a((1−ℓ)2+ 4xl) +b((1−ℓ)2+ 4yℓ))
=p
(a+b)2(1−ℓ)2+ (a+b)(4ax+ 4by)ℓ
≤p
c2(1−ℓ)2+ 4c2zℓ
=cp
(1−ℓ)2+ 4zℓ.
This finishes the proof.
3.2 Efficiency under the Balancedness Parametrization
Now we are ready to prove our main result, which links auction efficiency with unbalancedness when
autobidders perform partially non-uniform bidding.
Theorem 1 (PoA of FPA with partially non-uniform bidding) .For any t∈[2/5,1], we have
inf
(n,m,s, {Sk},v)∈ItPoA(n, m, s, {Sk},v) = 1−1
2t,
where
It={(n, m, s, {Sk},v)|unbal (n, m, s, {Sk},v)≤t}.
The theorem is a corollary of Lemma 1 and Lemma 2, which are stated and proved in Appendix A.
Below we discuss the conceptual implications of Theorem 1.
Better autobidders lead to worse efficiency. Theorem 1 and Proposition 1 together establish
a possibly counterintuitive relation between the capability of autobidders and the efficiency of
the auction outcome: Better optimized autobidders generally are capable of implementing more
sophisticated non-uniform bidding strategies, which correspond to establishing finer partitions of
the entire market into slices. However, by the second bullet of Proposition 1, any refinement of
the slices can only lead to higher unbalancedness, which, by Theorem 1, leads to worse auction
efficiency. In the extreme case where autobidders are capable of bidding optimally in each individual
auction (which, in our model, corresponds to the case in which each auction forms its own slice
with balancedness 0), the unbalancedness of the market is 1, and therefore, Theorem 1 states that the
PoA of such a market is 1/2, matching the bound established in prior work [Liaw et al., 2023, Deng
et al., 2022]. In fact, this is precisely the phenomenon observed empirically by Deng et al. [2024].
Our results therefore provide a theoretical explanation for their empirical findings. Together with
empirical results from [Deng et al., 2024], our theoretical results further suggest that it is unlikely to
achieve better auction efficiency (especially in first-price marketplaces) by using autobidders that are
(more) capable of non-uniform bidding in practice.
The importance of balanced channels / slices. In situations where there are naturally multiple
channels or slices (e.g., different ad exchanges operated by different companies, or by different
organizations within a single company) [Deng et al., 2023a, Susan et al., 2023], our results also
highlight the importance of keeping each channel / slice balanced. In particular, the first bullet
of Proposition 1 suggests that if the balancedness of one slice can be improved without hurting
the balancedness of the other slices, then the unbalancedness of the entire market decreases, and
Theorem 1 guarantees better efficiency overall. In practice, our results suggest that it is better off for
different channels / slices to coordinate to achieve higher overall efficiency.
Even perfectly balanced slices introduce inefficiency. Proposition 1 states that whenever there
are at least 2slices in the market instance, the unbalancedness of the market instance is at least 2/5,
even if all slices are perfectly balanced. Theorem 1 then implies that the efficiency of such market
instances is at most 4/5, which suggests that efficiency loss is inevitable whenever the market consists
8of multiple slices. In contrast, when autobidders perform uniform bidding over the entire market (i.e.,
when there is only 1slice), it is known that first-price marketplaces achieve full efficiency [Balseiro
et al., 2021a]. In other words, this indicates that one may expect to see a phase transition in market
efficiency when moving away from uniform bidding to (even highly restrictive) non-uniform bidding.
We also remark that for second-price marketplaces, the PoA is 2even with perfectly balanced slices,
or a single slice. This suggests that first-price marketplaces generally achieve higher efficiency
compared to second-price ones.
Acknowledgments and Disclosure of Funding
We thank anonymous reviewers for their helpful feedback.
References
Gagan Aggarwal, Ashwinkumar Badanidiyuru, and Aranyak Mehta. Autobidding with constraints. In Web and
Internet Economics: 15th International Conference, WINE 2019, New York, NY, USA, December 10–12, 2019,
Proceedings 15 , pages 17–30. Springer, 2019.
Gagan Aggarwal, Andres Perlroth, and Junyao Zhao. Multi-channel auction design in the autobidding world. In
Proceedings of the 24th ACM Conference on Economics and Computation , EC ’23, page 21, New York, NY ,
USA, 2023. Association for Computing Machinery.
Gagan Aggarwal, Ashwinkumar Badanidiyuru, Santiago R Balseiro, Kshipra Bhawalkar, Yuan Deng, Zhe Feng,
Gagan Goel, Christopher Liaw, Haihao Lu, Mohammad Mahdian, et al. Auto-bidding and auctions in online
advertising: A survey. ACM SIGecom Exchanges , 22(1):159–183, 2024.
Santiago Balseiro, Yuan Deng, Jieming Mao, Vahab Mirrokni, and Song Zuo. Robust auction design in the
auto-bidding world. Advances in Neural Information Processing Systems , 34:17777–17788, 2021a.
Santiago R Balseiro, Yuan Deng, Jieming Mao, Vahab S Mirrokni, and Song Zuo. The landscape of auto-bidding
auctions: Value versus utility maximization. In Proceedings of the 22nd ACM Conference on Economics and
Computation , pages 132–133, 2021b.
Xi Chen, Christian Kroer, and Rachitesh Kumar. The complexity of pacing for second-price auctions. In EC,
2021. URL https://arxiv.org/abs/2103.13969 .
Yuan Deng, Jieming Mao, Vahab Mirrokni, and Song Zuo. Towards efficient auctions in an auto-bidding world.
InProceedings of the Web Conference 2021 , pages 3965–3973, 2021.
Yuan Deng, Jieming Mao, Vahab Mirrokni, Hanrui Zhang, and Song Zuo. Efficiency of the first-price auction in
the autobidding world. arXiv preprint arXiv:2208.10650 , 2022.
Yuan Deng, Negin Golrezaei, Patrick Jaillet, Jason Cheuk Nam Liang, and Vahab Mirrokni. Multi-channel
autobidding with budget and ROI constraints. In Proceedings of the 40th International Conference on Machine
Learning , volume 202 of Proceedings of Machine Learning Research , pages 7617–7644. PMLR, 23–29 Jul
2023a.
Yuan Deng, Mohammad Mahdian, Jieming Mao, Vahab Mirrokni, Hanrui Zhang, and Song Zuo. Efficiency of
the generalized second-price auction for value maximizers. arXiv preprint arXiv:2310.03105 , 2023b.
Yuan Deng, Jieming Mao, Vahab Mirrokni, Yifeng Teng, and Song Zuo. Non-uniform bid-scaling and equilibria
for different auctions: An empirical study. In Proceedings of the ACM on Web Conference 2024 , page
256–266, 2024.
Michal Feldman, Hu Fu, Nick Gravin, and Brendan Lucier. Simultaneous auctions are (almost) efficient. In
Proceedings of the forty-fifth annual ACM symposium on Theory of computing , pages 201–210, 2013.
Yiding Feng, Brendan Lucier, and Aleksandrs Slivkins. Strategic budget selection in a competitive autobidding
world, 2023.
Darrell Hoy, Samuel Taggart, and Zihe Wang. A tighter welfare guarantee for first-price auctions. In Proceedings
of the 50th Annual ACM SIGACT Symposium on Theory of Computing , pages 132–137, 2018.
Yaonan Jin and Pinyan Lu. First price auction is 1−1/e2efficient. In 2022 IEEE 63rd Annual Symposium on
Foundations of Computer Science (FOCS) , pages 179–187. IEEE Computer Society, 2022.
Juncheng Li and Pingzhong Tang. Vulnerabilities of single-round incentive compatibility in auto-bidding: Theory
and evidence from roi-constrained online advertising markets. In Proceedings of the Thirty-Third International
Joint Conference on Artificial Intelligence, IJCAI-24 . International Joint Conferences on Artificial Intelligence
Organization, 2024. Main Track.
Christopher Liaw, Aranyak Mehta, and Andres Perlroth. Efficiency of non-truthful auctions in auto-bidding:
The power of randomization. In Proceedings of the ACM Web Conference 2023 , WWW ’23, page 3561–3571,
New York, NY , USA, 2023. Association for Computing Machinery.
9Christopher Liaw, Aranyak Mehta, and Wennan Zhu. Efficiency of non-truthful auctions in auto-bidding with
budget constraints. In Proceedings of the ACM Web Conference 2024 , WWW ’24, 2024.
Aranyak Mehta. Auction design in an auto-bidding setting: Randomization improves efficiency beyond vcg. In
Proceedings of the ACM Web Conference 2022 , pages 173–181, 2022.
Renato Paes Leme, Georgios Piliouras, Jon Schneider, Kelly Spendlove, and Song Zuo. Complex dynamics in
autobidding systems. In Proceedings of the 25th ACM Conference on Economics and Computation , 2024.
Tim Roughgarden, Vasilis Syrgkanis, and Eva Tardos. The price of anarchy in auctions. Journal of Artificial
Intelligence Research , 59:59–101, 2017.
Fransisca Susan, Negin Golrezaei, and Okke Schrijvers. Multi-platform budget management in ad markets with
non-ic auctions. arXiv preprint arXiv:2306.07352 , 2023.
Vasilis Syrgkanis and Eva Tardos. Composable and efficient mechanisms. In Proceedings of the forty-fifth
annual ACM symposium on Theory of computing , pages 211–220, 2013.
10A Proof of Theorem 1
Lemma 1. For each market instance (n, m, s, {Sk},v),
PoA(n, m, s, {Sk},v)≥1−1
2unbal (n, m, s, {Sk},v).
Proof. Fix a market instance (n, m, s, {Sk},v), together with an equilibrium given by bid multipliers
θ. Without loss of generality, suppose the optimal liquid welfare is 1, i.e.,
X
j∈[m]max
i∈[n]vi,j= 1.
For each bidder i∈[n]and auction j∈[m], let the “loss of efficiency” lossi,jcaused by iinjbe:
lossi,j=xi,j·(vrw(j),j−vi,j).
Moreover, abusing notation, for each bidder i∈[n]and each slice k∈[s], let
lossi,k=X
j∈Sklossi,j and lossk=X
i∈[n]lossi,k.
We only need to show
X
i∈[n],j∈[m]vi,j·xi,j≥1−1
2unbal (n, m, s, {Sk},v),
which is equivalent toX
k∈[s]lossk≤1
2unbal (n, m, s, {Sk}, v).
To upper bound the total loss of efficiency, we first establish a tradeoff between the total loss on slice
kand the total “overpayment” on the same slice. This will involve upper bounding the loss and lower
bounding the overpayment. Fix a slice kand partition auctions on kinto3sets:
•Ak: auctions where the rightful winner wins with a bid multiplier smaller than 1, i.e.,
Ak={j∈Sk|xrw(j),j= 1andθrw(j),k<1};
•Bk: auctions where the rightful winner wins with a bid multiplier larger than or equal to 1,
i.e.,
Bk={j∈Sk|xrw(j),j= 1andθrw(j),k≥1};
•Ck: auctions where the rightful winner does not win, i.e.,
Ck={j∈Sk|xrw(j),j= 0}.
For brevity, we define the “reserved” share reskto be the market share of set Ak, i.e., resk=
share Ak≤share k.
Consider any bidder i. First observe that for each auction j∈Sk,lossi,j>0only if the following
happen simultaneously:
• Bidder imust outbid the rightful winner in auction j, i.e., pi,j=bi,j≥brw(j),j.
•Since the rightful winner rw(j)is not winning in j, we must have θrw(j),k≥1, which
implies brw(j),j≥vrw(j),j.
Given the above properties, for each auction j∈Skwhere lossi,j>0, we have xi,j= 1 and
θi,k·vi,j=bi,j≥brw(j),j≥vrw(j),j. As a result,
lossi,j=vrw(j),j−vi,j≤vrw(j),j−vrw(j),j/θi,k=θi,k−1
θi,k·vrw(j),j≤θi∗,k−1
θi∗,k·vrw(j),j,
11where i∗∈[n]is the bidder i∗who has the largest bid multiplier on slice k. Recall that Ckis the set
of auctions in SkwhereP
ilossi,j>0. Since for any auction j∈Skwhere rw(j) =i∗,xi∗,j= 1,
we must have
share Ck≤share k−resk−share i∗,k≤(1−balk)·share k−resk.
Summing the upper bound for lossi,joveri∈[n]andj∈Sk, and plugging in the above inequality
involving share Ck, we get
lossk=X
i∈[n],j∈Sk:lossi,j>0lossi,j
≤X
j∈Ckθi∗,k−1
θi∗,k·vrw(j),j
=θi∗,k−1
θi∗,k·share Ck
≤θi∗,k−1
θi∗,k·((1−balk)·share k−resk).
This is our upper bound on the total loss, which will be useful later.
Now we lower bound the total overpayment. Note that xi,j= 1implies bi,j=pi,j. So whenever
lossi,j>0, based on the observations in the two bullet points above, we must have
lossi,j≤xi,j·(brw(j),j−vi,j)≤xi,j·(bi,j−vi,j) =xi,j·(pi,j−vi,j) =pi,j−xi,j·vi,j.
In words, ican only cause as much loss of efficiency in jas the amount ioverpays in j. To this end,
let
suri,j=xi,j·vi,j−pi,j
be the surplus igets from j. We have: for each i∈[n]andj∈[m],
lossi,j≤max{0,−suri,j}.
Summing over i∈[n]andj∈Ck, we get
X
i∈[n],j∈Lkmax{0,−suri,j} ≥X
i∈[n],j∈Lklossi,j=lossk.
This is one of the two inequalities that we will use to lower bound the total overpayment.
On the other hand, consider the bidder i∗who has the largest bid multiplier on slice k. Recall that for
any auction j∈Skwhere rw(j) =i∗,xi∗,j= 1. This means i∗overpays in auctions where i∗is the
rightful winner without causing any loss of efficiency. In fact, the amount of overpayment here can
be bounded as
X
j∈Sk:rw(j)=i∗−suri∗,j=X
j∈Sk:rw(j)=i∗(θi∗,k−1)·vi∗,j
= (θi∗,k−1)·share i∗,k
≥(θi∗,k−1)·share k·balk.
So, combining this inequality with the one above, we get
X
i∈[n],j∈Skmax{0,−suri,j} ≥(θi∗,k−1)·share k·balk+lossk.
This is the desired lower bound on the total overpayment.
Now let us put the bounds for the loss and that for the overpayment together into a tradeoff between
the two quantities. For brevity, let
sur−
k=X
i∈[n],j∈Skmax{0,−suri,j}.
12Recall the upper bound we have on the total loss:
lossk≤θi∗,k−1
θi∗,k·((1−balk)·share k−resk).
This gives us
θi∗,k≥(1−balk)·share k−resk
(1−balk)·share k−resk−lossk.
Plugging this into the lower bound we have on the total overpayment, we get
sur−
k≥lossk
(1−balk)·share k−resk−lossk·share k·balk+lossk
=⇒loss2
k−(share k−resk+sur−
k)·lossk+ ((1−balk)·share k−resk)·sur−
k≥0.
The latter is a quadratic inequality in lossk, which in our case implies
lossk≤1
2
share k−resk+sur−
k−q
(share k−resk−sur−
k)2+ 4share k·balk·sur−
k
.
The above tradeoff is useful because together with an additional constraint on {resk}and{sur−
k},
it gives an upper bound onP
klossk, which is the quantity we want to bound. The additional
constraint is from bidders’ RoS constraints. For each bidder i, the RoS constraint requires thatP
j∈[m]suri,j≥0, which impliesX
i∈[n],j∈[m]suri,j≥0.
On the other hand, for each auction j,suri,j>0only if j∈Aslice(j)(i.e.,θrw(j),slice(j)<1). This
means X
i∈[n],j∈[m]max{0,suri,j} ≤X
k∈[s]share Ak=X
k∈[s]resk.
As a result,X
k∈[s]sur−
k≤X
i∈[n],j∈[m]max{0,suri,j} ≤X
k∈[s]resk.
This is the additional constraint we need.
Now the problem of upper boundingP
k∈[s]losskreduces to solving the following optimization
problem (replacing all variables with shorthands: xkforresk,ykforsur−
k, and zkforlossk):
maxX
k∈[s]zk
s.t.∀k∈[s] :zk≤1
2
share k−xk+yk−p
(share k−xk−yk)2+ 4share k·balk·yk
X
k∈[s]yk≤X
k∈sxk
∀k∈[s] : 0≤xk≤share k
∀k∈[s] :yk≥0.
The rest of the proof is devoted to solving this optimization problem.
First we make some structural observations. Let fk(xk, yk)be the right hand side of the upper bound
onzk. When optimality is achieved:
•zk=fk(xk, yk)for all k∈[s], andP
k∈[s]yk=P
k∈[s]sk. The latter is simply because
fk(xk, yk)is strictly increasing in yk.
•For each k∈[s], ifxk≥(1−balk)·share k, then yk= 0andxk=share k. This is because
in such cases, fk(xk, yk)≤0, and fk(xk, yk) = 0 when yk= 0. So we would save our
budget for {yk′}on slice kand spend it elsewhere. For similar reasons, we would max out
xkto create more budget for {yk′}. In particular, this property implies that xk=share kand
yk>0cannot happen simultanously.
13With the above observations enforced as constraints (which does not change the optimal objective
value), we further relax the problem. In particular, for each slice k, we replace the constraint that
zk≤fk(xk, yk)withzk≤gk(xk, yk), where
gk(xk, yk) =1
2
share k−xk+yk−p
(share k−xk−yk)2+ 4(share k−xk)·balk·yk
.
This relaxation essentially means we imagine slices are arbitrarily divisible, and we can divide each
slice into two with the same balancedness, whose market shares sum to that of the one before division.
As we will see, the relaxation has no cost under our parametrization, because the hard market
instances are precisely the ones that divide slices in the way that achieves the maximum objective
value in the relaxed problem. We consider this relaxed problem with the additional constraints (in the
bullet points) from now on.
For this relaxed problem, we make more structural observations when optimality is achieved:
• There is at most one slice kwhere 0< xk<share k. This is because fixingP
k∈[s]xk, the
most efficient way to distribute this sum into slices is greedy. That is, we first find the last
sliceswhich has the minimum balancedness balsand increase xs. If we reach the limit, i.e.,
xs=share s, then we move on to the next slice s−1among the remaining ones with the
minimum balancedness and repeat this, etc., until we reach the desired sum. One may check
that this procedure in fact induces the sub-optimization problem over {yk}and{zk}with
the largest optimal objective value givenP
k∈[s]xk.
• For any k, k′∈[s]where min{yk, yk′}>0, we must have
∂gk(xk, yk)
∂yk=∂gk′(xk′, yk′)
∂yk′,
because otherwise we can locally adjust ykandyk′(while keeping the sum unchanged) and
get a strictly larger objective value.
Putting the above observations together, we conclude that the optimal solution to the optimization
problem must have the following structure: There is an integer s′∈[s], a positive real number
C∈[0,1], and “effective” market shares {share′
k}, such that:
•share′
k=share kfor each k∈[s′−1],share′
s′≤share s′, and
X
k∈[s′]share′
k=C.
•xk=share k−share′
kfor each k∈[s].
• There exists a real number D > 0such thatdhk(yk)
dyk=Dfor each k∈[s′], where
hk(yk) =1
2
share′
k+yk−q
(share′
k−yk)2+ 4share′
k·balk·yk
.
In particular, fixing C,yk/share′
kshould only depend on balk.
• For each k > s′,yk= 0, and
X
k∈[s′]yk= 1−C.
14Below we solve the relaxed problem given all simplifying observations above. The key step is to pin
down the dependency of yk/share′
konbalkgiven C. In fact, for each k∈[s′],
∃D,∀k∈[s′],dhk(yk)
dyk=D
=⇒ ∃D,∀k∈[s′],(yk−share′
k) + 2 share′
k·balkp
(yk−share′
k)2+ 4share′
k·balk·yk=D
=⇒ ∃D,∀k∈[s′],(yk−share′
k)2+ 4share′
k·balk·(yk−share′
k) + 4 share′
k2·bal2
k
(yk−share′
k)2+ 4share′
k·balk·yk=D
=⇒ ∃D,∀k∈[s′],share′
k2·balk·(1−balk)
(yk−share′
k)2+ 4share′
k·balk·yk=D
=⇒ ∃D,∀k∈[s′],(yk−share′
k)2+ 4share′
k·balk·yk
share′
k2·balk·(1−balk)=D
=⇒ ∃D,∀k∈[s′], yk=share′
k·
(1−2balk)±p
balk·(1−balk)·(D−4)
=⇒ ∃D,∀k∈[s′], yk=share′
k·
(1−2balk)±p
balk·(1−balk)·D
.
Moreover, observe that the sign in the above expression must be the same for all k∈[s′]in order for
the derivatives to be the same, which means
∃D∈R,∀k∈[s′], yk=share′
k·
(1−2balk) +p
balk·(1−balk)·D
.
Abusing notation, let
yk(D) =share′
k·
(1−2balk) +p
balk·(1−balk)·D
.
Note that here Dcan be either positive or negative.
Given the above observation, when optimality is achieved, the solution is essentially parametrized by
the parameter C. In particular, s′and{share′}are uniquely determined by C, and the parameter Dis
unique given C.5In fact, since yk(D)is monotone for each k∈[s′], there is a unique Dsuch that
X
k∈[s′]yk(D) = 1−C.
So we may alternatively write yk(C) =yk(D(C))for the unique choice of ykgiven C. Below we
link the maximum value of the objective to the unbalancedness of the market instance and conclude
the proof.
Recall that
α(b, u) = 1−2b+p
b·(1−b)·u.
So
yk(C) =share′
k·α(balk, D(C)).
Note that here share′
kdepends on C, and we omit this dependency for brevity. Given the choice of
D(C), since the slices are indexed such that balkis weakly increasing, we must have
ZC
0α(F(t), D(C)) dt=X
k∈[s′]α(balk, D(C))·share′
k=X
k∈[s′]yk(C) = 1−C,
where F(t)is the balancedness quantile function of the market instance. In other words, the choice of
Dgiven Cis precisely D(C) =β(C)as defined in Definition 4. Then the objective can be bounded
5Strictly speaking, this is not true when balk= 0for all k∈[s′]. However, in such case, the choice of D
does not matter, and one must choose Cto satisfy the constraint onP
k∈[s′]yk. In the rest of the proof, we omit
further discussion as this is a relatively straightforward corner case, and simply assume Dis unique given C.
15as
X
k∈[s]hk(yk)
=X
k∈[s]1
2
share′
k+yk−q
(share′
k−yk)2+ 4share′
k·balk·yk
=X
k∈[s′]1
2share′
k·
1 +yk/share′
k−q
(1−yk/share′
k)2+ 4balk·yk/share′
k
=X
k∈[s′]1
2share′
k·
1 +α(balk, β(C))−p
(1−α(balk, β(C)))2+ 4balk·α(balk, β(C))
=1
2ZC
0
1 +α(F(t), β(C))−p
(1−α(F(t), β(C)))2+ 4F(t)·α(F(t), β(C))
dt
≤1
2max
w∈[0,1]Zw
0
1 +α(F(t), β(w))−p
(1−α(F(t), β(w)))2+ 4F(t)·α(F(t), β(w))
dt
=1
2unbal (n, m, s, {Sk},v).
This concludes the proof of the lemma.
Lemma 2. For each t∈[2/5,1], there exists a market instance (n, m, s, {Sk},v)which satisfies
unbal (n, m, s, {Sk},v) =tandPoA(n, m, s, {Sk},v) = 1−t/2.
Proof. Recall that the proof of Proposition 1 establishes that unbal (F)(abusing notation here since
unbal depends only on F) weakly increases whenever Fpointwise weakly decreases. Moreover,
unbal (F)is clearly continuous in F(where we use any natural norm for the space where Fresides,
e.g.,L1). These properties together ensures that for any t∈[2/5,1], there exists some Fsuch that
unbal (F) =t— in fact, there exists a constant function Fsuch that unbal (F) =t, i.e., there exists
f∈[0,1/2]such that the function Fwhere F(x) =ffor all x∈[0,1]satisfies unbal (F) =t.
So, we only need to show that given any constant function Fwhere (1) F(x)is constantly ffor
some f∈[0,1/2]and (2) unbal (F) =t, there exists a market instance (n, m, s, {Sk},v)whose
balancedness quantile function is F, and PoA(n, m, s, {Sk},v)≤1−t/2.
We construct such a market instance with n= 3bidders, m= 6auctions, and s= 3slices where
each slice contains precisely 2auctions. Let S1={1,2},S2={3,4}, and S3={5,6}. Intuitively,
we will construct valuations together with an equilibrium, where (1) on S1, bidder 1steals from
bidder 3, (2) on S2, bidder 2steals from bidder 3, and (3) on S3, both bidder 1and bidder 2win their
market share without any competition. Below we choose the exact valuations that implement this
plan.
Letw∈[0,1]be a parameter to be optimized later. The valuations we choose depend on f
andw. Below we will only specify the non-zero part of the valuations. Consider S3first: We let
v1,5=f·(1−w)andv2,6= (1−f)·(1−w). On slice S1, we let v1,1=f2·w,v3,2=f·(1−f)·w,
andv1,2be such thatv3,2
v1,2−1
·(v1,1+v1,2) =f·(1−w).
In particular, the choice of v1,2guarantees that when bidder 1pays precisely the minimum amount to
“steal” the entire market share of bidder 3onS1, bidder 1’s overall buyer surplus is 0. Similarly, on
sliceS2, we let v2,3=f·(1−f)·w,v3,4= (1−f)2·w, and v2,4be such that
v3,4
v2,4−1
·(v2,3+v2,4) = (1 −f)·(1−w).
In particular, the choice of v2,4guarantees that when bidder 2pays precisely the minimum amount to
“steal” the entire market share of bidder 3onS2, bidder 2’s overall buyer surplus is 0.
16Now observe that the following bidding strategies form an equilibrium: θ1,1=v3,2/v1,2,θ2,2=
v3,4/v2,4, and all other bid multipliers are 1.6This means
PoA(n, m, s, {Sk},v)≤v1,1+v1,2+v2,3+v2,4+v1,5+v2,6
share 1+share 2+share 3
=share 1−h1(f·(1−w)) +share 2−h2((1−f)·(1−w)) +share 3.
Recall that we still have the freedom to choose w∈[0,1]. So we only need to show
max
w(h1(f·(1−w)) +h2((1−f)·(1−w))) =1
2unbal (n, m, s, {Sk},v).
In fact, we show that for each w∈[0,1],
h1(f·(1−w))+h2((1−f)·(1−w)) = max
λ∈Λ(w)Zw
0
1 +λ(τ)−p
(1−λ(τ))2+ 4f·λ(τ)
dτ.
Here, h1andh2are as defined in the proof of Lemma 1. This implies the above equation given the
alternative definition of unbal established in the proof of Proposition 1. To see why this equation
holds, observe that the right hand side is equal to
max
x∈[0,1]h1(x·(1−w)) +h2((1−x)·(1−w)).
Moreover, since bal1=bal2=f, the optimizer must satisfy x/share 1= (1−x)/share 2, which
means x=f. This concludes the proof of the lemma.
6Here we assume a particular tiebreaking rule. The proof works without the assumption since one can perturb
the valuations to avoid tiebreaking.
17NeurIPS Paper Checklist
1.Claims
Question: Do the main claims made in the abstract and introduction accurately reflect the
paper’s contributions and scope?
Answer: [Yes]
Justification: The abstract and introduction discuss our theoretical claims and their implica-
tions.
Guidelines:
•The answer NA means that the abstract and introduction do not include the claims
made in the paper.
•The abstract and/or introduction should clearly state the claims made, including the
contributions made in the paper and important assumptions and limitations. A No or
NA answer to this question will not be perceived well by the reviewers.
•The claims made should match theoretical and experimental results, and reflect how
much the results can be expected to generalize to other settings.
•It is fine to include aspirational goals as motivation as long as it is clear that these goals
are not attained by the paper.
2.Limitations
Question: Does the paper discuss the limitations of the work performed by the authors?
Answer: [Yes]
Justification: We discuss scenarios where our results do not apply, and also present negative
results.
Guidelines:
•The answer NA means that the paper has no limitation while the answer No means that
the paper has limitations, but those are not discussed in the paper.
• The authors are encouraged to create a separate "Limitations" section in their paper.
•The paper should point out any strong assumptions and how robust the results are to
violations of these assumptions (e.g., independence assumptions, noiseless settings,
model well-specification, asymptotic approximations only holding locally). The authors
should reflect on how these assumptions might be violated in practice and what the
implications would be.
•The authors should reflect on the scope of the claims made, e.g., if the approach was
only tested on a few datasets or with a few runs. In general, empirical results often
depend on implicit assumptions, which should be articulated.
•The authors should reflect on the factors that influence the performance of the approach.
For example, a facial recognition algorithm may perform poorly when image resolution
is low or images are taken in low lighting. Or a speech-to-text system might not be
used reliably to provide closed captions for online lectures because it fails to handle
technical jargon.
•The authors should discuss the computational efficiency of the proposed algorithms
and how they scale with dataset size.
•If applicable, the authors should discuss possible limitations of their approach to
address problems of privacy and fairness.
•While the authors might fear that complete honesty about limitations might be used by
reviewers as grounds for rejection, a worse outcome might be that reviewers discover
limitations that aren’t acknowledged in the paper. The authors should use their best
judgment and recognize that individual actions in favor of transparency play an impor-
tant role in developing norms that preserve the integrity of the community. Reviewers
will be specifically instructed to not penalize honesty concerning limitations.
3.Theory Assumptions and Proofs
Question: For each theoretical result, does the paper provide the full set of assumptions and
a complete (and correct) proof?
18Answer: [Yes]
Justification: We state the full model in Preliminaries and prove all the claims made in the
paper.
Guidelines:
• The answer NA means that the paper does not include theoretical results.
•All the theorems, formulas, and proofs in the paper should be numbered and cross-
referenced.
•All assumptions should be clearly stated or referenced in the statement of any theorems.
•The proofs can either appear in the main paper or the supplemental material, but if
they appear in the supplemental material, the authors are encouraged to provide a short
proof sketch to provide intuition.
•Inversely, any informal proof provided in the core of the paper should be complemented
by formal proofs provided in appendix or supplemental material.
• Theorems and Lemmas that the proof relies upon should be properly referenced.
4.Experimental Result Reproducibility
Question: Does the paper fully disclose all the information needed to reproduce the main ex-
perimental results of the paper to the extent that it affects the main claims and/or conclusions
of the paper (regardless of whether the code and data are provided or not)?
Answer: [NA]
Justification: No experimental results.
Guidelines:
• The answer NA means that the paper does not include experiments.
•If the paper includes experiments, a No answer to this question will not be perceived
well by the reviewers: Making the paper reproducible is important, regardless of
whether the code and data are provided or not.
•If the contribution is a dataset and/or model, the authors should describe the steps taken
to make their results reproducible or verifiable.
•Depending on the contribution, reproducibility can be accomplished in various ways.
For example, if the contribution is a novel architecture, describing the architecture fully
might suffice, or if the contribution is a specific model and empirical evaluation, it may
be necessary to either make it possible for others to replicate the model with the same
dataset, or provide access to the model. In general. releasing code and data is often
one good way to accomplish this, but reproducibility can also be provided via detailed
instructions for how to replicate the results, access to a hosted model (e.g., in the case
of a large language model), releasing of a model checkpoint, or other means that are
appropriate to the research performed.
•While NeurIPS does not require releasing code, the conference does require all submis-
sions to provide some reasonable avenue for reproducibility, which may depend on the
nature of the contribution. For example
(a)If the contribution is primarily a new algorithm, the paper should make it clear how
to reproduce that algorithm.
(b)If the contribution is primarily a new model architecture, the paper should describe
the architecture clearly and fully.
(c)If the contribution is a new model (e.g., a large language model), then there should
either be a way to access this model for reproducing the results or a way to reproduce
the model (e.g., with an open-source dataset or instructions for how to construct
the dataset).
(d)We recognize that reproducibility may be tricky in some cases, in which case
authors are welcome to describe the particular way they provide for reproducibility.
In the case of closed-source models, it may be that access to the model is limited in
some way (e.g., to registered users), but it should be possible for other researchers
to have some path to reproducing or verifying the results.
5.Open access to data and code
19Question: Does the paper provide open access to the data and code, with sufficient instruc-
tions to faithfully reproduce the main experimental results, as described in supplemental
material?
Answer: [NA]
Justification: No data or code.
Guidelines:
• The answer NA means that paper does not include experiments requiring code.
•Please see the NeurIPS code and data submission guidelines ( https://nips.cc/
public/guides/CodeSubmissionPolicy ) for more details.
•While we encourage the release of code and data, we understand that this might not be
possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not
including code, unless this is central to the contribution (e.g., for a new open-source
benchmark).
•The instructions should contain the exact command and environment needed to run to
reproduce the results. See the NeurIPS code and data submission guidelines ( https:
//nips.cc/public/guides/CodeSubmissionPolicy ) for more details.
•The authors should provide instructions on data access and preparation, including how
to access the raw data, preprocessed data, intermediate data, and generated data, etc.
•The authors should provide scripts to reproduce all experimental results for the new
proposed method and baselines. If only a subset of experiments are reproducible, they
should state which ones are omitted from the script and why.
•At submission time, to preserve anonymity, the authors should release anonymized
versions (if applicable).
•Providing as much information as possible in supplemental material (appended to the
paper) is recommended, but including URLs to data and code is permitted.
6.Experimental Setting/Details
Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
results?
Answer: [NA]
Justification: No experimental results.
Guidelines:
• The answer NA means that the paper does not include experiments.
•The experimental setting should be presented in the core of the paper to a level of detail
that is necessary to appreciate the results and make sense of them.
•The full details can be provided either with the code, in appendix, or as supplemental
material.
7.Experiment Statistical Significance
Question: Does the paper report error bars suitably and correctly defined or other appropriate
information about the statistical significance of the experiments?
Answer: [NA]
Justification: No experimental results.
Guidelines:
• The answer NA means that the paper does not include experiments.
•The authors should answer "Yes" if the results are accompanied by error bars, confi-
dence intervals, or statistical significance tests, at least for the experiments that support
the main claims of the paper.
•The factors of variability that the error bars are capturing should be clearly stated (for
example, train/test split, initialization, random drawing of some parameter, or overall
run with given experimental conditions).
•The method for calculating the error bars should be explained (closed form formula,
call to a library function, bootstrap, etc.)
20• The assumptions made should be given (e.g., Normally distributed errors).
•It should be clear whether the error bar is the standard deviation or the standard error
of the mean.
•It is OK to report 1-sigma error bars, but one should state it. The authors should
preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis
of Normality of errors is not verified.
•For asymmetric distributions, the authors should be careful not to show in tables or
figures symmetric error bars that would yield results that are out of range (e.g. negative
error rates).
•If error bars are reported in tables or plots, The authors should explain in the text how
they were calculated and reference the corresponding figures or tables in the text.
8.Experiments Compute Resources
Question: For each experiment, does the paper provide sufficient information on the com-
puter resources (type of compute workers, memory, time of execution) needed to reproduce
the experiments?
Answer: [NA]
Justification: No experimental results.
Guidelines:
• The answer NA means that the paper does not include experiments.
•The paper should indicate the type of compute workers CPU or GPU, internal cluster,
or cloud provider, including relevant memory and storage.
•The paper should provide the amount of compute required for each of the individual
experimental runs as well as estimate the total compute.
•The paper should disclose whether the full research project required more compute
than the experiments reported in the paper (e.g., preliminary or failed experiments that
didn’t make it into the paper).
9.Code Of Ethics
Question: Does the research conducted in the paper conform, in every respect, with the
NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines ?
Answer: [Yes]
Justification: In particular, we have done our best to preserve anonymity.
Guidelines:
•The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
•If the authors answer No, they should explain the special circumstances that require a
deviation from the Code of Ethics.
•The authors should make sure to preserve anonymity (e.g., if there is a special consid-
eration due to laws or regulations in their jurisdiction).
10.Broader Impacts
Question: Does the paper discuss both potential positive societal impacts and negative
societal impacts of the work performed?
Answer: [NA]
Justification: We present only theoretical results that do not have immediate societal impacts.
Guidelines:
• The answer NA means that there is no societal impact of the work performed.
•If the authors answer NA or No, they should explain why their work has no societal
impact or why the paper does not address societal impact.
•Examples of negative societal impacts include potential malicious or unintended uses
(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
(e.g., deployment of technologies that could make decisions that unfairly impact specific
groups), privacy considerations, and security considerations.
21•The conference expects that many papers will be foundational research and not tied
to particular applications, let alone deployments. However, if there is a direct path to
any negative applications, the authors should point it out. For example, it is legitimate
to point out that an improvement in the quality of generative models could be used to
generate deepfakes for disinformation. On the other hand, it is not needed to point out
that a generic algorithm for optimizing neural networks could enable people to train
models that generate Deepfakes faster.
•The authors should consider possible harms that could arise when the technology is
being used as intended and functioning correctly, harms that could arise when the
technology is being used as intended but gives incorrect results, and harms following
from (intentional or unintentional) misuse of the technology.
•If there are negative societal impacts, the authors could also discuss possible mitigation
strategies (e.g., gated release of models, providing defenses in addition to attacks,
mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
feedback over time, improving the efficiency and accessibility of ML).
11.Safeguards
Question: Does the paper describe safeguards that have been put in place for responsible
release of data or models that have a high risk for misuse (e.g., pretrained language models,
image generators, or scraped datasets)?
Answer: [NA]
Justification: No data or models released.
Guidelines:
• The answer NA means that the paper poses no such risks.
•Released models that have a high risk for misuse or dual-use should be released with
necessary safeguards to allow for controlled use of the model, for example by requiring
that users adhere to usage guidelines or restrictions to access the model or implementing
safety filters.
•Datasets that have been scraped from the Internet could pose safety risks. The authors
should describe how they avoided releasing unsafe images.
•We recognize that providing effective safeguards is challenging, and many papers do
not require this, but we encourage authors to take this into account and make a best
faith effort.
12.Licenses for existing assets
Question: Are the creators or original owners of assets (e.g., code, data, models), used in
the paper, properly credited and are the license and terms of use explicitly mentioned and
properly respected?
Answer: [NA]
Justification: No assets used.
Guidelines:
• The answer NA means that the paper does not use existing assets.
• The authors should cite the original paper that produced the code package or dataset.
•The authors should state which version of the asset is used and, if possible, include a
URL.
• The name of the license (e.g., CC-BY 4.0) should be included for each asset.
•For scraped data from a particular source (e.g., website), the copyright and terms of
service of that source should be provided.
•If assets are released, the license, copyright information, and terms of use in the
package should be provided. For popular datasets, paperswithcode.com/datasets
has curated licenses for some datasets. Their licensing guide can help determine the
license of a dataset.
•For existing datasets that are re-packaged, both the original license and the license of
the derived asset (if it has changed) should be provided.
22•If this information is not available online, the authors are encouraged to reach out to
the asset’s creators.
13.New Assets
Question: Are new assets introduced in the paper well documented and is the documentation
provided alongside the assets?
Answer: [NA]
Justification: No new assets introduced.
Guidelines:
• The answer NA means that the paper does not release new assets.
•Researchers should communicate the details of the dataset/code/model as part of their
submissions via structured templates. This includes details about training, license,
limitations, etc.
•The paper should discuss whether and how consent was obtained from people whose
asset is used.
•At submission time, remember to anonymize your assets (if applicable). You can either
create an anonymized URL or include an anonymized zip file.
14.Crowdsourcing and Research with Human Subjects
Question: For crowdsourcing experiments and research with human subjects, does the paper
include the full text of instructions given to participants and screenshots, if applicable, as
well as details about compensation (if any)?
Answer: [NA]
Justification: No crowdsourcing or human subjects involved.
Guidelines:
•The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
•Including this information in the supplemental material is fine, but if the main contribu-
tion of the paper involves human subjects, then as much detail as possible should be
included in the main paper.
•According to the NeurIPS Code of Ethics, workers involved in data collection, curation,
or other labor should be paid at least the minimum wage in the country of the data
collector.
15.Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
Subjects
Question: Does the paper describe potential risks incurred by study participants, whether
such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
approvals (or an equivalent approval/review based on the requirements of your country or
institution) were obtained?
Answer: [NA]
Justification: No human subjects involved.
Guidelines:
•The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
•Depending on the country in which research is conducted, IRB approval (or equivalent)
may be required for any human subjects research. If you obtained IRB approval, you
should clearly state this in the paper.
•We recognize that the procedures for this may vary significantly between institutions
and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
guidelines for their institution.
•For initial submissions, do not include any information that would break anonymity (if
applicable), such as the institution conducting the review.
23