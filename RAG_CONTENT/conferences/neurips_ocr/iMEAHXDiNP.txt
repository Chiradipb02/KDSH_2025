Improved Algorithms for Contextual Dynamic Pricing
Matilde Tullii∗
FairPlay Team, CREST, ENSAESolenne Gaucher∗
FairPlay Team, CREST, ENSAE
Nadav Merlis
FairPlay Team, CREST, ENSAEVianney Perchet
FairPlay Team, CREST, ENSAE - Criteo AI Lab
Abstract
In contextual dynamic pricing, a seller sequentially prices goods based on contex-
tual information. Buyers will purchase products only if the prices are below their
valuations. The goal of the seller is to design a pricing strategy that collects as much
revenue as possible. We focus on two different valuation models. The first assumes
that valuations linearly depend on the context and are further distorted by noise.
Under minor regularity assumptions, our algorithm achieves an optimal regret
bound of ˜O(T2/3), improving the existing results. The second model removes the
linearity assumption, requiring only that the expected buyer valuation is β-Hölder
in the context. For this model, our algorithm obtains a regret ˜O(Td+2β/d+3β),
where dis the dimension of the context space.
1 Introduction
Setting a price and devising a strategy to dynamically adjust it poses a fundamental challenge in
revenue management. This problem, known as dynamic pricing or online posted price auction,
finds applications across various industries and has received significant attention from economists,
operations researchers, statisticians, and machine learning communities. In this problem, a seller
sequentially offers goods to arriving buyers by presenting a one-time offer at a specified price. If
the offered price falls below the buyer’s (unknown) valuation of the item, a transaction occurs, and
the seller obtains the posted price as revenue. Conversely, if the price exceeds the buyer’s valuation,
the transaction fails, resulting in zero gain for the seller. Crucially, the seller solely receives binary
feedback indicating whether the trade happened. Her objective is to learn from this limited feedback
how to set prices that maximize her cumulative gains while ensuring that transactions take place. In
this paper, we study the problem of designing an adaptive pricing strategy, when the seller can rely
on contextual information, describing the product itself, the marketing environment, or the buyer.
While this problem has been extensively studied, previous results either rely on strong assumptions
on the structure of the problem, greatly limiting the applicability of such approaches, or achieve
sub-optimal regret bounds. In this work, we aim to improve both aspects—achieving better regret
bounds while making minimal assumptions about the problem. Specifically, we study two different
models for the valuation of buyers as a function of the context: 1) linear valuations , where the
item valuation of buyers is an unknown noisy linear function of the context; and 2) non-parametric
valuations , where the valuation is given by an unknown Hölder-continuous function of the contextual
information, perturbed by noise.
∗Equal contribution.
38th Conference on Neural Information Processing Systems (NeurIPS 2024).Table 1: Summary of existing regret bounds. gis the expected valuation function, Fis the c.d.f. of
the noise, and π(x, p)is the reward for price pand context x, defined in Section 2.1.
Model Noise Assumption Regret
LinearFis known ˜O(T2/3)[11]
Fis known or parametric, and log-concave ˜O(T1/2)[15]
Fhasm-th order derivatives ˜O(T2m+1/4m−1)[14]
F′′is bounded ˜O(T2/3)∨ ∥θ−bθ∥1T[22]
Fis Lipschitz˜O(T3/4)[14, 21], ˜O(T2/3)[this work]
Ω(T2/3)[31]
Bounded noise ˜O(T3/4), [31]
Non-
parametricπ(x,·)is quadratic around its maximum
for all x,Fandgare Lipschitz˜O(Td+2/d+4)[10]
Ω(Td+2/d+4)[10]
Fis Lipschitz and gis Hölder ˜O(Td+2β/d+3β)[this work]
1.1 Related Work
Dynamic pricing has been extensively studied for half a century [ 19,26], leading to rich research
on both theoretical and empirical fronts. For comprehensive surveys on the topic, we refer the
readers to [ 6,12]. While earlier works assumed that the buyer’s valuations are i.i.d. [ 18,5,16,9],
recent research has increasingly focused on feature-based (or contextual) pricing problems. In this
scenario, product value and pricing strategy depend on covariates. Pioneering works considered
valuations depending deterministically on the covariates. Linear valuations have been the most
studied [3, 15, 11, 20], yet a few authors have also explored non-parametric valuations [24].
Recent works have extended these methods to random valuations, mainly assuming that valuations
are given by a function of the covariate, distorted by an additive i.i.d. noise. As this poses more
challenges, authors have mostly focused on the simplest case of linear valuation functions, under
additional assumptions. Initial studies assumed knowledge of the noise distribution [ 11,15,30].
This assumption was later relaxed, albeit with additional regularity requirements on the cumulative
distribution function (c.d.f.) of the noise and/or the reward function [ 14,22], and then again by [ 31],
that achieves a regret bound of ˜O(T3/4)for linear valuations, while assuming only the boundedness
of the noise. Closest to our work [ 14,21] also focus on the case in which the only regularity required
is the Lipschitzness of the CDF. Their approaches show some similarities with our work but still
achieve suboptimal regret rates. A more detailed comparison between ours an their algorithms is
presented later on in the paper. Other parametric models have been explored, with, for example,
generalized linear regression models [ 28], though they also require strong assumptions, including
quadratic behavior of the reward function around each optimal price. Few works have considered
non-deterministic valuations with non-parametric valuation functions. Among those, [ 10] consider
Lipschitz-continuous valuation functions of d-dimensional covariates. They achieve a regret of order
˜O(Td+2/d+4), assuming again quadratic behaviour around optimal prices. We refer to Table 1 for a
comprehensive comparison between different previous works, their assumptions and regret bounds.
To improve on previous results, we design algorithms that share information on the noise distribution
across different contexts. This idea relates to methods used in cross-learning , a research direction
stemming from online bandit problems with graph feedback [ 23,2]. In this framework, introduced by
[4] and further studied in [ 27], when choosing to take action iin context xt, the agent observes the
reward ri(xt)along with rewards ri(x′
t)associated with other contexts xt′. Our algorithms leverage
similar principles to learn information usable across different contexts. However, compared to the
typical problems addressed by cross-learning methods (e.g., first-price auctions, sleeping bandits,
multi-armed bandits with exogenous costs), the contextual dynamic problem is more complex due to
the intricate dependence of the reward on the unknown valuation function.
1.2 Outline and Contributions
In this work, we tackle the problem of dynamic pricing with contextual information. We consider
two models for the expected valuations of the buyer, assuming respectively that they are given by a
2linear function, or by a non-parametric function. For both models, we present a general algorithmic
scheme called VALUATION APPROXIMATION - PRICE ELIMINATION (VAPE) , and provide bounds
on its regret in both models:
•In the linear model, we obtain a regret of ˜O(T2/3), assuming only that the c.d.f. of the noise
is Lipschitz. This concludes an extensive series of papers on the topic, as it establishes the
minimax optimal regret rate and proves it is attainable under minimal assumptions.
•In the non-parametric model, we obtain a regret rate of ˜O(Td+2β/d+3β), assuming only the
Lipschitz-continuity of the noise and the Hölder one of the valuation function. This result is
the first of its kind under such minimal assumptions.
The rest of the paper is organized as follows. We begin by presenting the model and summarizing
the notations used throughout the paper in Section 2.1. Section 2.2 outlines our assumptions and
compares them with those in previous works. In Section 2.3, we discuss the main sources of difficulty
of the problem and highlight the importance of information sharing in contextual dynamic pricing. In
Section 3, we present our algorithmic scheme, VAPE , and provide an initial informal result bounding
its regret. Then, in Section 4, we apply this algorithmic scheme to linear valuations and provide a
bound on its regret. Finally, in Section 5, we extend this algorithm to non-parametric valuations.
2 Preliminaries
2.1 Model and Notations
The problem of dynamic pricing with contextual information is formalized as follows. At each step
t≤T, a context xt∈Rd, describing a sale session (product, customer, and context) is revealed. The
customer assigns a hidden valuation ytto the product, and the seller proposes a price pt, based on xt
and on historical sales records. If pt≤yt, the trade is successful, and the seller receives a reward
yt; otherwise the trade fails. The seller’s only feedback is the binary outcome ot=1{pt≤yt}. We
assume that the seller’s valuation is given by
yt=g(xt) +ξt, (1)
where g:Rd7→Ris the valuation function, and ξtis a centered, bounded, i.i.d. noise term,
independent of xtand of (xs, ps, ξs)s<t. In the present paper, we consider successively linear and
non-parametric valuation functions gin Sections 4 and 5. The seller’s objective is to maximize the
sum of her cumulative earnings. We denote by π(p, xt)the expected reward of the seller if she posts
a price pfor a product described by covariate xt:
π(xt, p) =E[p1{p≤yt}|p, xt].
Adopting the terminology of the literature on multi-armed bandits, we measure the performance of
our algorithm and the difficulty of the problem through the regret RT, defined as
RT=TX
t=1max
p∈Rπ(xt, p)−TX
t=1π(xt, pt).
Notations Throughout this paper, we make use of the following notation. We denote by ∥·∥the
Euclidean norm. For all A, B∈R, we denote by JA, B Kthe set {A, A + 1, . . . , B }.RT≲BT
(resp. RT=˜O(BT)) means that there exists a (possibly problem-dependent) constant Csuch that
RT≤CBT(resp. RT=O(log(T)CBT)). Finally, fandFdenote the p.d.f. and c.d.f. of the noise,
respectively.
2.2 Assumptions
For both valuation models, we make the following assumptions on the context and noise distribution.
Assumption 1. Contexts and expected valuations are bounded: ∥xt∥2≤Bxand|g(xt)| ≤Bga.s.
This assumption is classical in contextual dynamic pricing problems. We underline that contexts
do not need to be random. In particular, they can be chosen by an adaptive adversary, aware of the
3seller’s strategy, and based on past realizations of (xs, ps, ξs)s<t. Assumption 1 is milder than the
i.i.d. context assumption appearing in [14, 28, 10].
Dynamic pricing strategies mostly assume that the buyer’s valuations are bounded. To enforce this,
we assume that the noise is bounded; moreover, we assume that its c.d.f. Lipschitz continuous.
Assumption 2. The noise ξtis bounded: |ξt| ≤Bξa.s. Moreover, its c.d.f. FisLξ-Lispchitz
continuous: for all (δ, δ′)∈Rd,|F(δ)−F(δ′)| ≤Lξ|δ−δ′|.
Assumption 2 is weaker than most of the assumptions in related works. For example, [ 15] require
bothFand1−Fto be log-concave. [ 14] assume that Fhasm-th derivative, and that δ−1−F(δ)/F′(δ)
is greater than some positive constant for all δ, achieving a regret of order ˜O(T2m+1/4m−1). In the
casem= 1, they propose a different algorithm, reaching a regret ˜O(T3/4). [22] consider Lipschitz-
continuous noise, under the additional assumption that, for every x,p∗(x)∈arg maxpπ(x, p)is
unique, and that F′′is bounded. [ 10] assume quadratic behaviour around every maxima: for every x,
p∗(x)∈arg maxpπ(x, p),p∗(x)is unique, and for all p,C(p∗(x)−p)2≤π(x, p∗(x))−π(x, p)≤
C′(p∗(x)−p)2for some constants C, C′. The only work considering non-Lipschitz c.d.f. is [ 31];
however, they achieve a higher regret bound of ˜O(T3/4).
2.3 Information Sharing in Contextual Dynamic Pricing
Forδ∈R, we denote D(δ) =P(ξt≥δ) = 1−F(δ), the demand function associated with the noise
ξt. Note that, under Assumption 2, DisLξ-Lipschitz continuous. Straightforward computations show
that, for any price increment δ∈R, the expected reward corresponding to the price p=g(xt) +δin
the context xtis given by
π(xt, g(xt) +δ) = (g(xt) +δ)D(δ). (2)
Equation (2)highlights the intricate roles played by the expected valuation g(xt)and the price
increment δ=p−g(xt)in the reward. An immediate consequence is that the optimal price
increment δdepends on the value of g(xt). Intuitively, if g(xt)is large, the seller should choose δto
be small to ensure a high probability D(δ)to perform a trade. However, for smaller values of g(xt),
the seller might prefer a larger δto ensure significant rewards when a trade occurs. Importantly, there
is no explicit relationship between the optimal increments δfor different valuations g(xt), so knowing
the optimal price for a value g(xt)does not allow optimal pricing for a different value g(xt′).
This reasoning suggests that the optimal price increment may span a wide range of values as the
expected valuation g(xt)varies. Unfortunately, as is typical in bandit problems, it is necessary
to estimate the reward function around the optimal price with high precision to ensure low regret.
Consequently, solving the dynamic pricing problem may entail estimating the demand function
precisely across a broad range of price increments. This marks a significant departure from non-
contextual dynamic pricing and non-parametric bandit problems, where precise estimation of the
reward function is often only necessary around its (single) maximum. Thus, the contextual dynamic
pricing problem might be more challenging than its non-contextual counterpart, potentially leading to
higher regret. This intuition is supported by the fact that straightforward application of basic bandit
algorithms, even in the most simple linear model, leads to regret higher than the rate of order ˜O(T2/3)
encountered in non-contextual dynamic pricing problems, as we show in the following discussion.
Naïve bandit algorithms for contextual dynamic pricing. As a first attempt, one might apply a
simple explore-then-commit algorithm. Such algorithms start with an exploration phase to obtain
uniformly good estimates of both gand of the demand function Dover a finite grid of price increments
{δk}k∈K. Then, in a second exploitation phase, prices are set greedily to maximize the estimated
reward. To bound the regret of this approach, note that uniform estimation of Dover the grid {δk}k∈K
with precision ϵrequires ϵ−2|K|estimation rounds. Moreover, the Lipschitz continuity of the reward
function implies a discretization error of order 1/|K|. Classical arguments suggest that the regret
would be at least T(ϵ+1/|K|) +|K|ϵ−2, which is minimized for ϵ=1/|K|=T−1/4. Thus, this
approach would lead to a regret of order ˜O(T3/4).
Another approach, akin to that used in [ 10], involves partitioning the covariate space into bins and
running independent algorithms for non-parametric bandits (such as CAB1 [ 17]) within each bin. Let
us assume, for simplicity, contexts in [0,1], and that we partition this segment into Kbins. Then,
the discretization error is 1/K. Classical results show that the regret in one bin is ˜O(T2/3
K), where
4TK=T/Kis the number of rounds in each bin. Consequently, the regret is ˜O(T/K+K×(T/K)2/3),
which is minimized for K=T1/4, resulting in a regret ˜O(T3/4).
Thus, both approaches – using either independent bandit algorithms over binned contexts or common
exploration rounds followed by an exploitation phase – suffer a regret of order T3/4in the linear model.
This raises the question of whether this rate is optimal for the linear model, and if the contextual
dynamic pricing problem is indeed more difficult than the non-contextual one. Strikingly, we show
that this is not the case. We rely on an intermediate approach, based on regret-minimizing algorithms
for each valuation level g(xt)thatshare information across different values of g(xt). We show that it
achieves an optimal regret rate of order ˜O(T2/3)in the linear valuation model. Moreover, it achieves
a rate of order ˜O(Td+2β/d+3β)in the non-parametric valuation model under minimal assumptions.
3 Algorithmic Approach
In this section, we present the general algorithmic approach that we use to tackle dynamic pricing
with covariates, called VALUATION APPROXIMATION - PRICE ELIMINATION (VAPE) . Before
presenting the full scheme, described in Algorithm 1, we start with some intuition that leads to its
design. Then, we provide a first analysis of the regret of this algorithm.
3.1 Outline of the Algorithm
Equation (2)highlights how the reward is influenced by the expected valuation g(xt)and by the
demand at the price increment δ=pt−g(xt). To separate the effect of these terms, we estimate g
andDindependently. Hereafter, we assume that the valuations ytare bounded, in [−By, By].
Estimation of g.To estimate g(xt), we rely on the following observation: when prices ptare
uniformly chosen from the interval [−By, By], the random variable 2By(ot−1/2)can serve as
an unbiased estimate of g(xt)conditioned on xt. Given that 2By(ot−1/2)is bounded, classical
concentration results can be employed to bound the error of our estimates for g(xt). Thus, in each
round, we test whether our estimate of g(xt)is precise enough to ensure that the error g(xt)−bg(xt)
is small. If this is not the case, we conduct a VALUATION APPROXIMATION round by setting a
uniform price. In the next sections, we consider linear and non-parametric valuation functions, and
we discuss how to ensure sufficient precision in a limited number of valuation approximation rounds.
Previous approaches for estimating valuation functions in the linear model include the regularized
maximum-likelihood estimator [ 15,30], which requires knowledge of the noise distribution. Another
approach used in [ 22] relies on the relation between estimating a linear valuation function from binary
feedback and the classical linear classification problem. The authors propose recovering the linear
parameters θthrough logistic regression; however, they do not provide an explicit estimation rate
forθ. [20] use the EXP-4 algorithm to aggregate policies corresponding to different values of θ
andF, thus circumventing the necessity to estimate them. In a similar vein, in the non-parametric
valuation model, [ 10] avoid the need to estimate g(xt)by employing independent bandit algorithms
for each (binned) value of xt. Closer to our method are the works of [ 14] and [ 21], who also set
uniform prices to obtain unbiased estimates of the valuations. Nonetheless, their algorithms are
significantly different from ours. First, they propose two-phased algorithms for which the phase
length is set beforehand. Such an approach necessitates additional assumptions on how contexts are
drawn; specifically, contexts are assumed to be i.i.d. from a distribution with a lower bound on the
eigenvalues of the covariance matrix. This is needed to ensure that contexts observed in the first
phase can represent the context distribution well. By contrast, our phases are adaptive, allowing our
algorithm also to handle adversarial contexts and render these assumptions superfluous. Second,
we obtain better regret rates by using piecewise-constant estimators, fitted in a regret-minimization
sub-routine, as detailed in the next paragraph. On the other hand, [ 14] performs a phase of pure
exploitation, relying on an estimate of the CDF Fthat is constructed using Kernel methods. [ 21],
instead, re-frames the problem as a perturbed linear bandit, which exhibits a regret linear in the
dimension. However, this dimension depends on the size of the discretization grid – which is horizon
dependent – leading to worse rates.
Estimation of D.If the expected valuation g(xt)is known with sufficient precision, we can use it
to estimate the demand function over a set of candidate price increments {δk}k∈K. More precisely,
assume we set a price pt=bg(xt) +δk, and that |bg(xt)−g(xt)| ≤ϵ. Then, the observation otcan
5Algorithm 1 VALUATION APPROXIMATION - PRICE ELIMINATION (VAPE): General scheme
1:Input : Price increments {δk}k∈K, expected valuation precision errt(x), reward confidence
intervals [LCB t(k),UCB t(k)], parameters α,ϵ.
2:while t≤Tdo
3: iferrt(xt)> ϵthen ▷Valuation Approximation
4: Post a price pt∼ U([−By, By])
5: Useotto improve the valuation estimator bg(xt)
6: else ▷Price Elimination
7: At← {k∈ K:bgt+δk∈[0, By]}
8: Kt← {k∈ At:UCB t(k)≥max k′∈AtLCB t(k′)}
9: Choose kt∈arg mink∈KtNk
tand post a price pt=bgt+δkt
10: Update bDkt
t+1,Nkt
t+1
be used as an almost unbiased estimate of the demand at level δk, since
E[ot] =E[1{bg(xt) +δk≤g(xt) +ξt}] =D(δk+bg(xt)−g(xt)).
Under Assumption 2, DisLξ-Lipschitz, so the bias is of order Lξϵ. Then, relying on classical
bandit techniques, we show that with high probability (for αsmall enough), |D(δk)−bDk
t|is of
order Lξϵ+p
log(1/α)/Nk
t, where bDk
tis the average of the observations otwhen setting a price
pt=bg(xt) +δk, and Nk
tis the number of rounds in which we chose the price increment δkup
to round t. Importantly, to estimate bDk
t, we share information collected during all rounds we
chose the increment δkacross all values of bg(xt); this is necessary to obtain better regret rates.
Then, using ptbDk
tas an estimate of the reward π(xt, pt)given the price pt=bg(xt) +δk, the error
|π(xt, pt)−ptbDk
t|is of order By(Lξϵ+p
log(1/α)/Nk
t).
ThePRICE ELIMINATION subroutine relies on the previous remark to select a price increment. For
each increment δk, we build a confidence bound [LCB t(δk),UCB t(δk)] = [ ptbDk
t±By(2Lξϵ+p
2 log(1 /α)/Nk
t)]for the reward of price pt=bg(xt) +δk. Then, we use a successive elimination
algorithm [ 13,25] to select a good increment. More precisely, we consider increments δksuch that
UCB t(δk)≥max lLCB t(δl), and we choose among these increments the increment δktthat has
been selected the least frequently. By doing so, we ensure to only select potentially optimal prices
and gradually eliminate sub-optimal increments.
3.2 A First Bound on the Regret
Before discussing the application of the algorithmic scheme VAPE to linear and non-parametric
valuation functions, we provide some intuition on regret bounds achievable through this scheme.
Claim 1. (Informal) Letδk=kϵfork∈ K≜J⌊−By−1/ϵ⌋,⌈By+1/ϵ⌉K. Assume that, on a high-
probability event, |bg(xt)−g(xt)| ≤ϵfor every round twhere PRICE ELIMINATION is conducted.
Then, on a high-probability event, the regret of VAPE verifies
RT≲TVA(ϵ) +Tϵ+ log(1 /α)ϵ−2.
where TVA(ϵ)is a bound on the length of the VALUATION APPROXIMATION phase.
Claim 1 is proved in the Appendix by combining Equations (4)and(5), and Lemma 4. We provide a
sketch of proof below. To bound on regret of VAPE using Claim 1, it will suffice to bound the length
of the V ALUATION APPROXIMATION phase, and prove high-probability error bounds on g(xt).
Sketch of proof. Note that the regret in the VALUATION APPROXIMATION phase scales at most
linearly with its length. Then, to prove Claim 1, it is enough to bound the regret during the PRICE
ELIMINATION phase. We begin by bounding the sub-optimality gap of the price chosen at round t,
showing that it is of order ϵ+p
log(1/α)/Nkt
t.
To do so, for p∈R, we define ∆t(xt, p) = max p′π(xt, p′)−π(xt, p)the sub-optimality gap
corresponding to price p. Recall that δktis the increment chosen at round t, i.e. that pt=bg(xt) +δkt.
6Classical arguments from the bandit literature show that with high probability, for all k∈ K, the
upper and lower confidence bounds on π(xt,bg(xt) +δk)given by UCB t(δk)andLCB t(δk)are
valid. Then, the optimal increment δk∗
tdefined by k∗= arg maxk∈Atπ(xt,bg(xt) +δk)belongs
to the set of non-eliminated increments. Now, on the one hand, since UCB t(δkt)≥LCB t(δk∗
t),
and since the confidence interval are valid, the gap π(xt,bg(xt) +δk∗
t)−π(xt, pt)is of order
ϵ+p
2 log(1 /α)/Nkt
t+q
2 log(1 /α)/Nk∗
t
t. Our round-robin sampling scheme ensures that Nk∗
t
t≥Nkt
t,
so this bound is of order ϵ+p
log(1/α)/Nkt
t. On the other hand, our choice of grid {δk}k∈K, together
with the Lipschitz-continuity of the reward in Assumption 2, imply that the cost ∆t(xt,bg(xt) +δk∗
t)
of considering a discrete price grid is of order ByLξϵ. Thus, at each round, the gap ∆t(xt,bg(xt)+δkt)
is at most of order ϵ+p
log(1/α)/Nkt
t(up to problem-dependent constants).
Now, let us decompose the regret of the P RICE ELIMINATION phase as follows:
X
t∈PRICE ELIMINATION phase∆(xt, pt) =X
k∈KX
t:kt=k∆(xt, pt).
In order to boundP
t:kt=k∆(xt, pt)fork∈ K, we begin by introducing further notations. Let
us denote τk
1, . . . , τk
Tthe rounds in the PRICE ELIMINATION phase where we choose kt=k. We
also define ∆a= 2−aandasuch that ∆a≈ϵ. For all a≤a, we also define tasuch that the
bound ϵ+p
log(1/α)/tais of order ∆a. Then, our previous reasoning implies that if i≥tafor some
a∈ {1,a}, it must be that ∆t(xt, pτk
i)≤∆a. Moreover, for a≥1, each phase {ta, . . . , ta+1}is of
length approximately log(1/α)(∆−2
a+1−∆−2
a). Thus,
X
t:kt=k∆(xt, pt)≲log(1/α)
∆1+a−1X
a=1∆a×log(1/α)
∆2
a+1−log(1/α)
∆2a
+ ∆ aNk
T.
Using the definitions of ∆aanda, we find that this sum is of order log(1/α)/ϵ+ϵNk
T. We conclude
by summing over the values of k∈ K, usingP
k∈KNk
T≤Tand the fact that |K|is of order ϵ−1.
4 Linear Valuation Functions
In this section, we consider the linear valuation model, given by
g(x) =x⊤θ , (3)
where θ∈Rdis an unknown parameter. To ensure that the valuations are bounded, we assume the
boundedness of the parameter θ.
Assumption 3. The parameter θis bounded: ∥θ∥ ≤Bθ
Note that under Assumptions 1 and 3, the expected valuations g(xt)verify |g(xt)| ≤Bgfor
Bg=Bx×Bθ. Moreover, the random valuations verify a.s. |yt| ≤ByforBy=Bg+Bξ.
We apply the VAPE algorithmic scheme to the problem of dynamic pricing with linear valuations.
To estimate the valuation function, we use a ridge estimator for the parameter θ. Moreover, we
distinguish between phases by setting ιt= 1iftbelongs to the VALUATION APPROXIMATION phase
andιt= 0iftbelongs to the P RICE ELIMINATION one. The details are presented in Algorithm 2.
Theorem 1. Assume that the valuations follow the model given by Equations (1)and(3). Under
Assumptions 1, 2, and 3, the regret of Algorithm VAPE for Linear Valuations with parameters
ϵ= (d2log(T)2/T)1/3,µ=ϵ/ 
Bys
dlog
1+B2xT
α
+Bθ!
, and α=1/
T+2T2
3+(Bξ+1)T1/3verifies
RT≤CBξ,Bx,Bθ,Lξd2/3T2/3log(T)2/3
with probability 1−T−1, where CBξ,Bx,Bθ,Lξis a constant that polynomially depends on Bξ,Bx,
Bθ, and Lξ.
Sketch of proof. [See Appendix B for the full proof] Using Claim 1, we see that it is enough to
prove that the VALUATION APPROXIMATION phase allows to estimate g(xt)up to precision ϵ=
(d2log(T)2/T)1/3in at most O(d2/3T2/3log(T)2/3)rounds.
7Algorithm 2 VALUATION APPROXIMATION - PRICE ELIMINATION (V APE) for Linear Valuations
1:Input : bounds ByandLξ, parameters α,µ,ϵ.
2:Initialize :bθ1=0d,V1=Id,K=⌈(By+1)/ϵ⌉,K=J−K, K K, and for k∈ K,Nk
1=bDk
1= 0.
3:while t≤Tdo
4: if∥xt∥V−1
t> µ then ▷Valuation Approximation
5: Post a price pt∼ U([−By, By])
6: ιt←1,Vt+1←P
s≤tιsxsx⊤
s+Id,bθt+1←2ByV−1
t+1P
s≤tιs 
os−1
2
xs
7: else ▷Price Elimination
8: ιt←0,bgt←x⊤
tbθt,At← {k∈ K:bgt+kϵ∈[0, By]}
9: fork∈ Atdo
10: UCB t(k)←(bgt+kϵ) (bDk
t+q
2 log( 1/α)
Nk
t+ 2Lξϵ)
11: LCB t(k)←(bgt+kϵ) (bDk
t−q
2 log( 1/α)
Nk
t−2Lξϵ)
12: Kt← {k∈ At:UCB t(k)≥max k′∈AtLCB t(k′)}
13: Choose kt∈arg mink∈KtNk
tand post a price pt=bgt+ktϵ
14: Update bDkt
t+1←Nkt
tbDkt
t+ot
Nkt
t+1,Nkt
t+1←Nkt
t+ 1.
To prove the first part of the claim, note that for all rounds in the PRICE ELIMINATION phase,
∥xt∥V−1
t≤µ=ϵ/
Byq
dlog(1+B2
xT/α)+Bθ
. Then,
|bg(xt)−g(xt)| ≤ ∥θ−bθt∥Vt∥xt∥V−1
t≤ ∥θ−bθt∥Vt×ϵ/
Byq
dlog(1+B2
xT/α)+Bθ
.
Classical result on ridge regression in bandit framework [ 1] show that on a large probability event,
∥θ−bθt∥Vt≤
Byq
dlog 
1+B2
xT/α
+Bθ
, so|bg(xt)−g(xt)| ≤ϵ.
To prove the second part of the claim, we rely on the elliptical potential lemma to bound the number
of rounds where ∥xt∥V−1
t≥µ. This Lemma states thatP|G|
i=1∥xti∥V−1
ti−1≤p
|G|dlog (|G|+d/d),
where tiis the i-th round of the VALUATION APPROXIMATION phase, and |G|is its length. Using
the fact that ∥xti∥V−1
ti−1≥µ, we conclude that |G| ≤dlog(T+d/d)
µ2 , which implies the result.
Theorem 1 provides a regret bound of order ˜O(T2/3), showing that VAPE for Linear Valuations
is minimax optimal, possibly up to sub-logarithmic terms and to sub-linear dependence in the
dimension. Indeed, it matches the T2/3lower bound established in [ 31] for linear valuation functions
and Lipschitz-continuous demand functions. This result represents a clear improvement over the
existing regret bounds for the same problem. Indeed, VAPE achieves the regret bound conjectured in
[22] while at the same time removing their regularity assumption on the revenue function. On the
other hand, we improve on the regret rate ˜O(T3/4)achieved respectively in [ 31] under assumptions
slightly milder than ours, and in [14] under stronger assumptions.
5 Non-Parametric Valuation Functions
In this Section, we consider the non-parametric valuation model. As usual in dynamic pricing, we
assume that the valuation function gis bounded. Furthermore, we assume that it is ( Lg,β)-Hölder
continuous for some constants Lg>0and0< β≤1.
Assumption 4. The valuation function gis (Lg,β)-Hölder: for all (x, x′)∈Rd,|g(x)−g(x′)| ≤
Lg∥x−x′∥β.
Under Assumptions 1 and 2, the random valuations ytverify|yt| ≤ByforBy=Bξ+Bg.
Next, we apply the VAPE algorithmic scheme to the non-parametric valuation model. To estimate
the function g, we use a finite grid of points, on which this function is evaluated. More precisely, we
8Algorithm 3 VALUATION APPROXIMATION - PRICE ELIMINATION (VAPE) for Non-Parametric
Valuations
1:Input : bounds ByandLξ, finite set X ⊂Rd, parameters α,τ,ϵ.
2:Initialize :Gx=∅for all x∈X,K=⌈By+1/ϵ⌉,K=J−K, K K, and for k∈ K,Nk
1=bDk
1= 0.
3:while t≤Tdoxt←arg minx′∈X∥xt−x′∥
4: if|Gxt|< τthen ▷Price Elimination
5: Post a price pt∼ U([−By, By])
6: Gxt← G xt∪ {t},bg(xt)←2By
|Gxt|P
s∈Gxt 
os−1
2
7: else ▷Run Successive Elimination
8: bgt←bg(xt),At← {k∈ K:bgt+kϵ∈[0, By]}
9: fork∈ Atdo
10: UCB t(k)←(bgt+kϵ) (bDk
t+q
2 log( 1/α)
Nk
t+ 2Lξϵ)
11: LCB t(k)←(bgt+kϵ) (bDk
t−q
2 log( 1/α)
Nk
t−2Lξϵ)
12: Kt← {k∈ At:UCB t(k)≥max k′∈AtLCB t(k′)}
13: Choose kt∈arg mink∈KtNk
tand post a price pt=bgt+ktϵ
14: Update bDkt
t+1←Nkt
tbDkt
t+ot
Nkt
t+1,Nkt
t+1←Nkt
t+ 1.
consider a minimal (ϵ/3Lg)1/β-covering Xof the ball of radius BxinRd, i.e. a finite set of points, of
minimal cardinality, such that for any context xsuch that ∥x∥ ≤Bx, there exists a point in Xat a
distance at most (ϵ/3Lg)1/βfrom x.
At each round, we round the context xtto the closest context xinXby setting xt=
arg minx′∈X∥xt−x′∥, and acting as if we observed the context xt. If this context has not been
observed sufficiently, we conduct a round of VALUATION APPROXIMATION : we sample a price
uniformly at random and use it to update our estimate of g(xt); otherwise, we proceed with the PRICE
ELIMINATION phase. To distinguish between the VALUATION APPROXIMATION steps corresponding
to contexts x∈X, we collect their indices in sets Gx. The algorithm is presented in Algorithm 3.
Theorem 2. Assume that the valuations follow the model given by Equation (1). Under Assumptions
1, 2, and 4, with probability 1−T−1the regret of Algorithm VAPE for non-parametric Valuations
with parameters ϵ= (T/log(T))−β
d+3β,α=T−4,τ=18B2
ylog( 2|X|/α)/ϵ2, andXa minimal (ϵ/3Lg)1/β-
covering of the ball of radius Bxverifies
RT≤CBx,Bg,Bξ,Lg,Lξ,d,βTd+2β
d+3βlog(T)β
d+3β,
where CBx,Bg,Bξ,Lg,Lξ,d,βis a constant that polynomially depends on Bx,Bg,Bξ,Lg,Lξ,d, and β.
Sketch of proof. [See Appendix C for the full proof] Using Claim 1, we only need to show that the
length of the VALUATION APPROXIMATION phase is at most of order Td+2β/d+3βlog(T)β/d+3βand
that w.h.p., it allows estimating guniformly on a ball of radius Bxwith precision ϵ=(T/log(T))−β/d+3β.
To prove the first part of the claim, we note that classical results imply that the size of a minimal
covering of precision ϵ1/βof a ball in dimension dscales as ϵ−d/β. Then, the total length of the
VALUATION APPROXIMATION phase is of order ϵ−d/βτ≈Td+2β/d+3βlog(T)β/d+3β. To prove the
second part of the lemma, note that the Hölder-continuity of gand the definition of the (ϵ/3Lg)1/β-
covering Gensure that |g(xt)−g(xt)| ≤ϵ/3. Then, standard concentration arguments reveal that τ≈
log(|X|/α)/ϵ2samples are sufficient to estimate g(xt)with precision ϵwith high probability.
Theorem 2 shows that the Algorithm VALUATION APPROXIMATION – PRICE ELIMINATION for
non-parametric valuations enjoys a ˜O(Td+2β/d+3β)regret bound when the noise c.d.f. is Lipschitz
and the valuation function Hölder-continuous. This result is the first of its kind under such minimal
assumptions. In particular, previous work by [ 10] assumes quadratic behavior around the optimal price
for all values of g(x)– a very strong assumption. However, this rate is higher than the ˜O(Td+β/d+2β)
9rates that are usually encountered in β-Hölder non-parametric bandits [ 7]. Thus, the question of
optimality of the VAPE algorithmic scheme in the non-parametric valuation problem remains open.
6 Conclusions
In this paper, we studied the problem of dynamic pricing with covariates. We first presented a novel
algorithmic approach called VAPE , which adaptively alternates between improving the valuation
approximation and learning to set prices through successive elimination. We then applied VAPE
under two valuation models – when the buyer’s valuation corresponds to a noisy linear function
and when expected valuations follow a smooth non-parametric model. In the linear case, our regret
bounds are order-optimal, while in the non-parametric setting, we improve existing results. All our
results are proven under regularity assumptions that are either milder or match existing assumptions.
Our results on the linear valuation model are the first to match the existing lower bound rate of
Ω 
T2/3
under our assumptions. However, the optimal dependence of this rate on the dimension of
the context remains unknown. Additionally, there are no similar lower bounds for non-parametric
valuations. We conjecture that our results are also tight in this setting but leave this for future work.
Future research directions also include exploring other valuation models, and further relaxing our
assumptions, as Lipschitz-continuity of the noise (Assumption 2). Without this, even minor increases
in the price could lead to a major drop in revenue, magnifying the impact of valuation approximation
errors. Another limiting assumption is that the noise is independent and identically distributed, such
that its distribution can be learned across different contexts. It is of great interest to study problems
where the noise distribution can change between rounds, or depends on the context.
Broader Impacts
As all pricing problems, dynamic pricing can have both positive and negative impacts – offering
prices that are more suited to the buyers on the one hand, while increasing the seller’s revenue at the
expense of buyers on the other hand. In addition, as with many contextual problems, there might be
biases and challenges involving fairness – one should make sure that similar customers are offered
similar prices. While acknowledging these issues, our work was meant to focus only on the theoretical
analysis of what is considered a well-established problem in literature, leaving the study of these
related topics as future work.
Acknowledgments
This project has received funding from the European Union’s Horizon 2020 research and innovation
programme under the Marie Skłodowska-Curie grant agreement No 101034255. Solenne Gaucher
gratefully acknowledges funding from the Fondation Mathématique Jacques Hadamard. Vianney
Perchet acknowledges support from the French National Research Agency (ANR) under grant number
(ANR-19-CE23-0026 as well as the support grant, as well as from the grant “Investissements d’Avenir”
(LabEx Ecodec/ANR-11-LABX-0047). This research was supported in part by the French National
Research Agency (ANR) in the framework of the PEPR IA FOUNDRY project (ANR-23-PEIA-0003)
and through the grant DOOM ANR-23-CE23-0002. It was also funded by the European Union (ERC,
Ocean, 101071601). Views and opinions expressed are however those of the author(s) only and do
not necessarily reflect those of the European Union or the European Research Council Executive
Agency. Neither the European Union nor the granting authority can be held responsible for them.
References
[1]Yasin Abbasi-Yadkori, Dávid Pál, and Csaba Szepesvári. Improved algorithms for linear
stochastic bandits. Advances in neural information processing systems , 24, 2011.
[2]Noga Alon, Nicolo Cesa-Bianchi, Ofer Dekel, and Tomer Koren. Online learning with feedback
graphs: Beyond bandits. In Conference on Learning Theory , pages 23–35. PMLR, 2015.
[3]Kareem Amin, Afshin Rostamizadeh, and Umar Syed. Repeated contextual auctions with
strategic buyers. Advances in Neural Information Processing Systems , 27, 2014.
10[4]Santiago Balseiro, Negin Golrezaei, Mohammad Mahdian, Vahab Mirrokni, and Jon Schneider.
Contextual bandits with cross-learning. Advances in Neural Information Processing Systems ,
32, 2019.
[5]Omar Besbes and Assaf Zeevi. Dynamic pricing without knowing the demand function: Risk
bounds and near-optimal algorithms. Operations research , 57(6):1407–1420, 2009.
[6]Gabriel Bitran and René Caldentey. An overview of pricing models for revenue management.
Manufacturing & Service Operations Management , 5(3):203–229, 2003.
[7]Sébastien Bubeck, Rémi Munos, Gilles Stoltz, and Csaba Szepesvári. <i>x</i>-armed bandits.
Journal of Machine Learning Research , 12(46):1655–1695, 2011. URL http://jmlr.org/
papers/v12/bubeck11a.html .
[8]Alexandra Carpentier, Claire Vernade, and Yasin Abbasi-Yadkori. The elliptical potential lemma
revisited. arXiv preprint arXiv:2010.10182 , 2020.
[9]Nicolo Cesa-Bianchi, Tommaso Cesari, and Vianney Perchet. Dynamic pricing with finitely
many unknown valuations. In Algorithmic Learning Theory , pages 247–273. PMLR, 2019.
[10] Ningyuan Chen and Guillermo Gallego. Nonparametric pricing analytics with customer covari-
ates. Operations Research , 69(3):974–984, 2021.
[11] Maxime C Cohen, Ilan Lobel, and Renato Paes Leme. Feature-based dynamic pricing. Manage-
ment Science , 66(11):4921–4943, 2020.
[12] Arnoud V Den Boer. Dynamic pricing and learning: historical origins, current research, and
new directions. Surveys in operations research and management science , 20(1):1–18, 2015.
[13] Eyal Even-Dar, Shie Mannor, Yishay Mansour, and Sridhar Mahadevan. Action elimination and
stopping conditions for the multi-armed bandit and reinforcement learning problems. Journal
of machine learning research , 7(6), 2006.
[14] Jianqing Fan, Yongyi Guo, and Mengxin Yu. Policy optimization using semiparametric models
for dynamic pricing. Journal of the American Statistical Association , 119(545):552–564, 2024.
[15] Adel Javanmard and Hamid Nazerzadeh. Dynamic pricing in high-dimensions. Journal of
Machine Learning Research , 20(9):1–49, 2019.
[16] N Bora Keskin and Assaf Zeevi. Dynamic pricing with an unknown demand model: Asymptoti-
cally optimal semi-myopic policies. Operations research , 62(5):1142–1167, 2014.
[17] Robert Kleinberg. Nearly tight bounds for the continuum-armed bandit problem. Advances in
Neural Information Processing Systems , 17, 2004.
[18] Robert Kleinberg and Tom Leighton. The value of knowing a demand curve: Bounds on regret
for online posted-price auctions. In 44th Annual IEEE Symposium on Foundations of Computer
Science, 2003. Proceedings. , pages 594–605. IEEE, 2003.
[19] Kenneth Littlewood. Forecasting and control of passenger bookings. The Airline Group of the
International Federation of Operational Research Societies , 12:95–117, 1972.
[20] Allen Liu, Renato Paes Leme, and Jon Schneider. Optimal contextual pricing and extensions.
InProceedings of the 2021 ACM-SIAM Symposium on Discrete Algorithms (SODA) , pages
1059–1078. SIAM, 2021.
[21] Yiyun Luo, Will Wei Sun, and Yufeng Liu. Contextual dynamic pricing with unknown noise:
Explore-then-ucb strategy and improved regrets. Advances in Neural Information Processing
Systems , 35:37445–37457, 2022.
[22] Yiyun Luo, Will Wei Sun, and Yufeng Liu. Distribution-free contextual dynamic pricing.
Mathematics of Operations Research , 49(1):599–618, 2024.
[23] Shie Mannor and Ohad Shamir. From bandits to experts: On the value of side-observations.
Advances in Neural Information Processing Systems , 24, 2011.
11[24] Jieming Mao, Renato Leme, and Jon Schneider. Contextual pricing for lipschitz buyers.
Advances in Neural Information Processing Systems , 31, 2018.
[25] Vianney Perchet and Philippe Rigollet. The multi-armed bandit problem with covariates. The
Annals of Statistics , 41(2):693–721, 2013.
[26] Marvin Rothstein. Hotel overbooking as a markovian sequential decision process. Decision
Sciences , 5(3):389–404, 1974.
[27] Jon Schneider and Julian Zimmert. Optimal cross-learning for contextual bandits with unknown
context distributions. Advances in Neural Information Processing Systems , 36, 2024.
[28] Virag Shah, Ramesh Johari, and Jose Blanchet. Semi-parametric dynamic contextual pricing.
Advances in Neural Information Processing Systems , 32, 2019.
[29] Roman Vershynin. High-dimensional probability: An introduction with applications in data
science , volume 47. Cambridge university press, 2018.
[30] Chi-Hua Wang, Zhanyu Wang, Will Wei Sun, and Guang Cheng. Online regularization toward
always-valid high-dimensional dynamic pricing. Journal of the American Statistical Association ,
pages 1–13, 2023.
[31] Jianyu Xu and Yu-Xiang Wang. Towards agnostic feature-based dynamic pricing: Linear
policies vs linear valuation with unknown noise. In International Conference on Artificial
Intelligence and Statistics , pages 9643–9662. PMLR, 2022.
12A Simulations
Figure 1: The plots here show the regrets rate of VAPE for linear evaluations, both in the standard and
logarithmic scale (left and right respectively). The solid lines represent the average of the performance
over15repetitions of the routine. The faded red area shows the standard error, while in the right
subplot the dotted line corresponds to the theoretical regret bound.
Figure 2: The two subplots show a comparison between VAPE and the algorithm in [ 14] in the
stochastic and adversarial case, where the time horizons used are T∈[1000 ,1700,3000,5000] (left
subplot), and T∈[1000 ,1400,4200,9000] (right subplot). In both cases the solid lines represent
the average of the regret rates across the 15repetitions of the simulations, while the faded area the
standard error. In the subplot on the right, due to the specificity of the setting, the variance across
runs is minimal, hence the faded area results invisible. The regret graph is in both cases plotted in
logaritmic scale.
In this section, we illustrate some numerical simulations that aim to show the empirical per-
formance of our VAPE algorithm for Linear Valuations. Moreover we present a compari-
son with the algorithm proposed in [ 14] in the case in which the only regularity assumed
on the CDF of the noise distribution is Lipschitzness. The code implemented for these
simulations is publicly available in the repository: https://github.com/MatildeTulii1/
Improved-Algorithms-for-Contextual-Dynamic-Pricing
VAPE In order to test our algorithm, we built a dataset of 5contexts belonging to R3generated by a
canonical gaussian distribution and subsequently normalized. Throughout the run the contexts are
chosen from this set uniformly at random, while the noise term is picked from a gaussian distribution
truncated between −1and1with mean 0and variance 0.1. Similarly, also the parameter θis a
normalized vector initially drawn from a gaussian distribution. The algorithm has been tested on
time horizons T∈[1000 ,10000 ,50000 ,200000 ,500000 ,800000] , and the hyperparameters α, µ, ϵ
are set as in the statement of Theorem 1. Figure 1 shows the results of this implementation. The
empirical regret rates of VAPE respect the theoretical upper-bound expressed in the paper, moreover
it shows optimal computational times that can handle big time horizons.
13Comparison with [ 14]Next we compare our algorithm with the algorithm proposed in Appendix F
of [14], in which they propose a routine to tackle the dynamic pricing problem with linear valuation
in the case in which the CDF Fis Lipschitz. The comparison is carried out in two different settings:
a stochastic and an adversarial one, and to make it more fair both algorithm receive as input the time
horizon T.
In the stochastic case, similarly as before we consider a set of possible contexts in R3drawn
uniformly at random and then normalised. During the routine, at each time step one of these is
randomly selected. This method of receiving contexts meets the assumption included in [ 14], making
sure that no eigenvalue of the covariance matrix of the distribution of contexts is too small. As for
the contexts, the parameter θis selected ex-novo with every new run of the algorithm. We chose
to implement a comparison with this specific algorithms since it was among the closest with our
work, as discussed in the main paper, but its prohibitive computational costs make difficult to see the
good behaviour of VAPE which, being based on a bandit approach, requires bigger time horizons to
converge.
The adversarial case, instead is a toy example which is purposely designed to badly interfere with the
algorithm proposed by [ 14]. In this case the set of contexts is made of only two samples of orthogonal
vectors, specifically in the form [x,0, z]and[0,1,0]. To make sure that the effect of this choice of
contexts is not invalidated by the parameter θ, this is considered to be fixed as [0.3,0.3,0.3]. The
algorithm receives the first context during the exploration phase and the second during the exploitation
one, such that the information gathered initially result meaningless in the latter subroutine. As before
the computational costs of [ 14] limited the time horizons on which we were able to run this simulation,
still it can be noted how VAPE , exposed to the same contexts in the same order, does not suffer from
such choice, since the phases are defined adaptively, thus its regret rates remain consistent with the
stochastic case. The results of this comparison are shown in Figure 2.
B Proof of Theorem 1
We state several lemmas before proving Theorem 1. We begin by bounding the length of the
exploration phase corresponding to lines 5 and 6 of Algorithm 2.
Lemma 1. LetG={t≤T:ιt= 1}. Almost surely, the length of exploration phase Gis bounded as
|G| ≤dlog T+d
d
µ2.
The following lemma bounds the error of our estimates for θandD, for the values of µprescribed in
Theorem 1. Before stating the Lemma, we define the event
E=(
∀t /∈ G,|bgt−g(xt)| ≤ϵ,andbDk
t−D(kϵ)≤s
2 log(1 /α)
Nk
t+Lξϵ)
.
Lemma 2. The event Ehappens with probability at least 1−(α+ 2T2|K|α).
Finally, we bound the number of times a sub-optimal price increment kϵcan be selected. For p∈R,
x∈Rd, we define
∆(x, p) = sup
p′∈[0,By]π(x, p′)−π(x, p).
Lemma 3. On the event E, for all t /∈ G, ifkt=k, then kmust be such that
∆(xt,bgt+kϵ)≤By 
4s
2 log(1 /α)
Nk
t+ 9Lξϵ!
.
We are now ready to bound the regret of Algorithm V APE for Linear Valuations. We begin by
rewriting the regret as
RT=TX
t=1
max
p∈[0,By]π(xt, p)−π(xt, pt)
=X
t∈G
max
p∈[0,By]π(xt, p)−π(xt, pt)
+X
t/∈G
max
p∈[0,By]π(xt, p)−π(xt, pt)
. (4)
14Under Assumptions 1, 2, and 3, both the optimal price and ptare in [0, By], we know that the
instantaneous regret is bounded by By. Then,
X
t∈G
max
p∈[0,By]π(xt, p)−π(xt, pt)
≤By|G|. (5)
Using Lemma 1 together with the definition of µ, we find that
X
t∈Gmax
p∈[0,By](π(xt, p)−π(xt, pt))≤Bydlog T+d
d
Byq
dlog BxT+1
α
+Bθ2
ϵ2.(6)
We rely on the following Lemma to boundP
t/∈G 
max p∈[0,By]π(xt, p)−π(xt, pt)
.
Lemma 4. On the event E,
X
t/∈G
max
p∈[0,By]π(xt, p)−π(xt, pt)
≤ |K|
512Bylog(1/α) + 22Bylog(1/α)
Lξϵ
+ 36ByTLξϵ.
Combining Equations (4), (6), and Lemma 4, we find that
RT≤Bydlog T+d
d
Byq
dlog BxT+1
α
+Bθ2
ϵ2+|K|
512Bylog(1/α) + 22Bylog(1/α)
Lξϵ
+ 36ByTLξϵ.
Using the definition of K,ϵandαallows us to conclude the proof.
C Proof of Theorem 2
The proof of Theorem 2 follows closely the proof of Theorem 1. The following two Lemmas are
analogues of Lemmas 1 and 2.
Lemma 5. LetXbe an (ϵ
3Lg)1/β-covering of BBx,dof minimal cardinality, and let G=S
x∈XGx.
Almost surely, the length of exploration phase Gis bounded as
|G| ≤ 
2Bx3Lg
ϵ1/β
+ 1!d
(τ+ 1).
Recall that we defined the event Eas
E=(
∀t /∈ G,|bgt−g(xt)| ≤ϵ,andbDk
t−D(kϵ)≤s
2 log(1 /α)
Nk
t+Lξϵ)
.
The following lemma shows that Ehappens with large probability.
Lemma 6. The event Ehappens with probability at least 1−(α+ 2T2|K|α).
The rest of the proof holds follows the proof of Theorem 1. In particular, on the event E, we still have
RT=X
t∈G
max
p∈[0,By]π(xt, p)−π(xt, pt)
+X
t/∈G
max
p∈[0,By]π(xt, p)−π(xt, pt)
≤By|G|+|K|
512Bylog(1/α) + 22Bylog(1/α)
Lξϵ
+ 36ByTLξϵ.
where we used the fact that the instantaneous regret is bounded by Byalong with Lemma 4. Using
Lemma 5, we obtain
RT≤By 
2Bx3Lg
ϵ1/β
+ 1!d
(τ+ 1) + |K|
512Bylog(1/α) + 22Bylog(1/α)
Lξϵ
+ 36ByTLξϵ.
Using the definition of K,ϵ,τandαallows us to conclude the proof.
15D Proof of Auxilliary Lemmas
D.1 Proof of Lemma 1
We use the elliptical potential Lemma (see, e.g., Proposition 1 in [ 8]) to bound the total number of
rounds used to estimate θ. Formally, denote the estimation indices G=
t1. . . , t|G|	
and notice that
ιt= 1 only for these indices. Thus, for all i∈[|G|], we can write Vti=Pi
k=1xtkx⊤
tk+Idand
Vti−1=Vti−1. In particular, the elliptical potential lemma implies that
|G|X
i=1∥xti∥V−1
ti−1=|G|X
i=1∥xti∥V−1
ti−1≤s
|G|dlog|G|+d
d
.
Since for all tsuch that ιt= 1,x⊤
tV−1
ti−1xt≥µ, this implies that
|G|µ≤s
|G|dlog|G|+d
d
.
Now, almost surely, |G| ≤ T. Using this bound and reorganizing the inequality leads to the desired
result
|G| ≤dlog T+d
d
µ2.
D.2 Proof of Lemma 2
Lemma 2 is obtained by combining the following two results.
Lemma 7. Let us define the event
E1={∀t /∈ G:|g(xt)−bgt| ≤ϵ}
Then, the event E1happens with probability at least 1−α.
The remainder of the proof follows from the following lemma.
Lemma 8. Let us define the event
E=(
∀t∈[T], k∈ K,bDk
t−D(kϵ)≤s
2 log(1 /α)
Nk
t+Lξϵ)
∩ E1
Assume that event E1holds with probability 1−α. Then, the event Ehappens with probability at
least1−(α+ 2T2|K|α).
D.3 Proof of Lemma 3
We assume that t /∈ G, that kt=k, and that Nk
t>0(otherwise the statement is trivial). We begin by
stating an auxiliary result, which follows immediately from Lemma 2.
Lemma 9. On the event E, we have that for all t /∈ G, and all k∈ At;
LCB t(k)≤π(xt,bgt+kϵ)≤UCB t(k).
Moreover, k∗
t∈ Kt, where
k∗
t∈arg max
k∈Atπ(xt,bgt+kϵ).
On the event E, Lemma 9 implies that
π(xt,bgt+kϵ)≥LCB(k)
=UCB(k)−(UCB(k)−LCB(k)).
Since k∗
t∈ At, we have
UCB t(k)≥LCB t(k∗
t).
16This implies
π(xt,bgt+kϵ)≥LCB t(k∗
t)−(UCB t(k)−LCB t(k))
=UCB t(k∗
t)−(UCB t(k)−LCB t(k))−(UCB t(k∗
t)−LCB t(k∗
t))
≥π(xt,bgt+k∗
tϵ)−(UCB t(k)−LCB t(k))−(UCB t(k∗
t)−LCB t(k∗
t))
Thus,
π(xt,bgt+k∗
tϵ)−π(xt,bgt+kϵ)
≤(UCB t(k)−LCB t(k)) + ( UCB t(k∗
t)−LCB t(k∗
t)).
Now,
UCB t(k)−LCB t(k) = (bgt+kϵ) s
8 log(1 /α)
Nk
t+ 4Lξϵ!
≤By s
8 log(1 /α)
Nk
t+ 4Lξϵ!
since k∈ At. Moreover, since kt=k, and since k∗
t∈ Ktby Lemma 9, we know that Nk
t≤Nk∗
t.
This implies that
UCB t(k∗
t)−LCB t(k∗
t) = (bgt+k∗
tϵ) s
8 log(1 /α)
Nk∗
t
t+ 4Lξϵ!
≤By s
8 log(1 /α)
Nk
t+ 4Lξϵ!
Thus,
π(xt,bgt+k∗
tϵ)−π(xt,bgt+kϵ)≤2By s
8 log(1 /α)
Nk
t+ 4Lξϵ!
. (7)
Next, we bound the discretization error using the following Lemma.
Lemma 10. On the event E, we have that
sup
p∈[0,By]π(xt, p)−π(xt,bgt+k∗
tϵ)≤ByLξϵ.
By Lemma 10, Equation (7) implies that on the event E,
∆(xt,bgt+kϵ)≤By 
4s
2 log(1 /α)
Nk
t+ 9Lξϵ!
.
D.4 Proof of Lemma 4
Note that
X
t/∈G
max
p∈[0,By]π(xt, p)−π(xt, pt)
=X
k∈KX
t/∈G:kt=k∆(xt,bgt+kϵ) (8)
We bound this term on the high-probability event E. For k∈ K, we define tk
1<···< tk
Nk
T+1
the rounds where t /∈ G andkt=k. We split these rounds into episodes as follows. We define
a=⌊−log2(18Lξϵ)⌋. For a∈J1,aK, we also define
ta=128 log(1 /α)
2−2a.
17With these notations, we have
X
t/∈G:kt=k∆(xt,bgt+kϵ) =X
i≤t1∧Nk
T+1∆(xtk
i,bgtk
i+kϵ) +a−1X
a=1X
ta∧Nk
T+1<i≤ta+1∧Nk
T+1∆(xtk
i,bgtk
i+kϵ)
+X
ta∧Nk
T+1<i≤Nk
T+1∆(xtk
i,bgtk
i+kϵ)
On the one hand, ∆(xt, pt)≤Byfor all t≤T, so
X
i≤t1∧Nk
T+1∆(xtk
i,bgtk
i+kϵ)≤Byt1
On the other hand, using Lemma 3, we see that on the event E, ifi≥taanda∈J1,aK,
∆(xtk
i,bgtk
i+kϵ)≤By
4s
2 log(1 /α)
ta+ 9Lξϵ

≤By2−a
2+ 9Lξϵ
Since 2−a≥18Lξϵ, this implies that
∆(xtk
i,bgtk
i+kϵ)≤2−aBy.
Then,
a−1X
a=1X
ta∧Nk
T+1<i≤ta+1∧Nk
T+1∆(xtk
i,bgtk
i+kϵ)≤Bya−1X
a=1(ta+1− ⌈ ta⌉+ 1) 2−a
≤Bya−1X
a=1(ta+1−ta) 2−a+By
By definition of ta, this implies that
a−1X
a=1X
ta∧Nk
T+1<i≤ta+1∧Nk
T+1∆(xtk
i,bgtk
i+kϵ)≤128Bylog(1/α)a−1X
a=1 
22a+2−22a
2−a+By
≤384Bylog(1/α) 
1 +a−1X
a=12a!
≤384Bylog(1/α)2a
≤22Bylog(1/α)
Lξϵ
where we used that 2a≤1
18Lξϵ. Similarly,
X
ta∧Nk
T+1<i≤Nk
T+1∆(xtk
i,bgtk
i+kϵ)≤2−aByNk
T+1
≤36ByNk
T+1Lξϵ.
Combining these results, we find that
X
t/∈G:kt=k∆(xt,bgt+kϵ)≤512Bylog(1/α) + 22Bylog(1/α)
Lξϵ+ 36ByNk
T+1Lξϵ. (9)
We conclude the proof by summing over k∈ K, and using the fact thatP
k∈KNk
T+1≤T.
18D.5 Proof of Lemma 5
We note that
|G| ≤ | X|(τ+ 1).
We conclude by using classical results on covering number of the ball (see, e.g., Corollary 4.2.13
in [29]), stating that there exists an (ϵ
3Lg)1/β-covering of the ball of radius Bxin dimension dof
cardinality at most
2Bx
3Lg
ϵ1/β
+ 1d
.
D.6 Proof of Lemma 6
The proof of Lemma 6 relies on the following Lemma.
Lemma 11. Let us define the event
E1={∀t /∈ G:|g(xt)−bg(xt)| ≤ϵ}
Then, the event E1happens with probability at least 1−α.
Note that Lemma 8 still holds for non-parametric valuations. This concludes the proof of Lemma 6.
D.7 Proof of Lemma 7
We introduce the variables
˜xt=ιtxtand ˜yt= 2Byιt
ot−1
2
and the σ-algebra Ft=σ((xs)s≤t+1,(os)s≤t).Since Vt−1andxtareFt−1-measurable, then so
doesιt, and thus both ˜xt+1and˜ytareFt-measurable. Moreover, for any round where ιt= 1, the
price is chosen uniformly at random and we have
E[˜yt|Ft−1] =ιt× 
2ByZBy
−ByP[u≤yt|Ft−1]du
2By−By!
=ιt× ZBy
−ByZBξ
−Bξ1
u≤x⊤
tθ+ξ	
f(ξ) dξdu−By!
=ιt× ZBξ
−BξZξ+x⊤
tθ
−Byduf(ξ) dξ−By!
=ιt× 
x⊤
tθ+ZBξ
−Bξξf(ξ) dξ!
=ιt×x⊤
tθ
where in the last equality we used thatRBξ
−Bξξf(ξ) dξ=E[ξt] = 0 . The same relation also trivially
holds when ιt= 0. Thus, conditionally on Ft−1,˜yt−˜x⊤
tθis centered and in [−By, By], which
implies that it is By-subgaussian. Now, for all t≤T, we have
bθt= 2By X
s<tιsxsx⊤
s+Id!−1X
s∈G
os−1
2
xs
= X
s<t˜xs˜x⊤
s+Id!−1X
s<t˜ys˜xs.
Using the fact that for all t≥1,∥˜xt∥ ≤Bx, and that ∥θ∥ ≤Bθ, and applying Theorem 2 in [ 1], we
find that for all t≥0, with probability 1−α,
∥bθt−θ∥(P
s<t˜xl˜x⊤
l+Id)≤Bys
dlog1 +B2xT
α
+Bθ.
19Note that our definitions of ˜xtand˜ytensure that ∥bθt−θ∥(P
s<t˜xl˜x⊤
l+Id)=∥bθt−θ∥Vt.Moreover,
for all t,
|x⊤
t(bθt−θ)| ≤ ∥x⊤
t∥V−1
t∥bθt−θ∥Vt.
In particular, if t /∈ G,∥x⊤
t∥(Vt)−1≤µ, so
|x⊤
t(bθt−θ)| ≤µ 
Bys
dlog1 +B2xT
α
+Bθ!
.
The conclusion follows from the choice ϵ=µ
Byr
dlog
1+B2xT
α
+Bθ
, and the fact that
bgt=x⊤
tbθt.
D.8 Proof of Lemma 8
We rely on the following well-known result (we provide proof in the appendix for the sake of
completeness).
Lemma 12. Let(yt)t≥1be a sequence of random variables adapted for a filtration Ft, such that
yt−E[yt|Ft−1]∈[m, M ]. Assume that for t∈N∗,ιt∈ {0,1}isFt−1-measurable, and define
Nt=P
s≤tιs, andbµt=P
s≤tιs(ys−E[ys|Fs−1])
NtifNt≥1. Then, for any t∈N∗andα∈(0,1),
P
Nt= 0or|bµt| ≤(M−m)s
log(1/α)
2Nt
≥1−2tα.
Moreover, for any l >0andα∈(0,1),
P
Nt=land|bµt| ≥(M−m)s
log(1/α)
2Nt
≤2α.
Note Lemma 8 holds trivially for all tsuch that Nk
t= 0. Therefore we assume w.l.o.g. that Nk
t≥1
(otherwise the statement is trivial). For any such given t∈[T], we control the error |bFk
t−F(kϵ)|
uniformly for k∈ K. To do so, we rely on Lemma 12; we define ˜ιt=1{ιt= 0andkt=k}, and
note that for Ft=σ((x1, . . . , x t+1),(o1, . . . , o t)),˜ιtisFt−1-measurable, and otisFtadapted.
Moreover,
˜ιtE[ot|Ft−1] = ˜ιtP(g(xt) +ξt≥bgt+kϵ)
= ˜ιtD(bgt−g(xt) +kϵ),
and directly by definition, it holds that bDk
t=P
s≤t˜ιtot
Nt. Using Lemma 12, we find that with
probability 1−2αt,Nk
t= 0or
bDk
t−P
s≤t˜ιtD(bgt−g(xt) +kϵ)
Nk
t≤s
2 log(1 /α)
Nk
t.
Moreover, on the event E1, which happens w.p. at least 1−α, for all t /∈ G,|bgt−g(xt)| ≤ϵ. Using
the fact that DisLξ-Lipschitz, we find that for all t /∈ G,
|D(bgt−g(xt) +kϵ)−D(kϵ)| ≤Lξ|bgt−g(xt)| ≤Lξϵ.
Thus, with probability 1−2αt,
bDk
t−D(kϵ)≤s
2 log(1 /α)
Nk
t+Lξϵ.
Using a union bound over all k∈ K andt∈[T]and then intersecting with E1using another union
bound yields the desired result.
20D.9 Proof of Lemma 9
For any t /∈ G, denoting pt(k) =bgt+kϵ, we first rewrite
π(xt, pt(k)) =E[pt(k)1{pt(k)≤yt}|pt(k), xt]
=pt(k)E[1{pt(k)≤g(xt) +ξt}|pt(k), xt]
=pt(k)D(pt(k)−g(xt))
= (bgt+kϵ)D(bgt−g(xt) +kϵ)
= (bgt+kϵ)bDk
t+ (bgt+kϵ)
D(bgt−g(xt) +kϵ)−bDk
t
.
Since the event Eholds, the following hold for all t /∈ Gandk∈ At:
|bgt−g(xt)| ≤ϵ, andbDk
t−D(kϵ)≤s
2 log(1 /α)
Nk
t+Lξϵ.
In particular, we have that:
D(bgt−g(xt) +kϵ)−bDk
t≤ |D(bgt−g(xt) +kϵ)−D(kϵ)|+D(kϵ)−bDk
t
(1)
≤Lξ|bgt−g(xt)|+D(kϵ)−bDk
t
≤Lξϵ+s
2 log(1 /α)
Nk
t+Lξϵ
=s
2 log(1 /α)
Nk
t+ 2Lξϵ
Relation (1)holds since DisLξ-Lipschitz and (2)is under the event Efor all t /∈ E. As the set Atis
chosen such that bgt+kϵ≥0for all k∈ At, it implies that
π(xt,bgt+kϵ)−(bgt+kϵ)bDk
t≤(bgt+kϵ) s
2 log(1 /α)
Nk
t+ 2Lξϵ!
.
Reorganizing, we get for all k∈ Atandt /∈ G
LCB t(k)≤π(xt,bgt+kϵ)≤UCB t(k).
which proves the first part of the statement.
Now let k∗
t∈arg maxk∈Atπ(xt,bgt+kϵ). By the first part of the claim, it holds that
UCB t(k∗
t)(∗)
≥π(xt,bgt+k∗
tϵ) = max
k∈Atπ(xt,bgt+kϵ)(∗)
≥max
k∈AtLCB t(k),
where relations (∗)are due to the first part of the lemma; this proves that k∗
t∈ Kt.
D.10 Proof of Lemma 10
The proof follows by noticing that, on the one hand, Kensures that for all p∈[0, By], there
exists k∈ K such that bgt+kϵ∈[0, By]and|bgt+kϵ−p| ≤ϵ. On the other hand, the prices
considered are bounded by By, and the demand function DisLξ-Lipschitz, so the reward function π
isByLξ-Lipschitz.
D.11 Proof of Lemma 11
Forx∈ X , let us define recursively the variables ιx
1=1{x1=x}, and for t > 1,ιx
t=
1
xt=x,andP
s<tιx
s< τ	
, and define the variables
˜gx
t=ιx
tg(xt)and ˜yx
t= 2Byιx
t
ot−1
2
21and the σ-algebra Ft=σ((xs)s≤t+1,(os)s≤t).Note that ιx
tisFt−1-measurable, and thus both
˜xt+1and˜ytareFt-measurable. Moreover, for any round where ιx
t= 1, the price is chosen uniformly
at random and we have
E
˜yx
t|Ft−1
=ιx
t× 
2ByZBy
−ByP[u≤yt|Ft−1]du
2By−By!
=ιx
t× ZBy
−ByZBξ
−Bξ1{u≤g(xt) +ξ}f(ξ) dξdu−By!
=ιx
t× ZBξ
−BξZξ+g(xt)
−Byduf(ξ) dξ−By!
=ιx
t× 
g(xt) +ZBξ
−Bξξf(ξ) dξ!
= ˜gx
t
where in the last equality we used thatRBξ
−Bξξf(ξ) dξ=E[ξt] = 0 . The same relation also trivially
holds when ιx
t= 0. Thus, conditionally on Ft−1,˜yt−˜gx
tis centered and in [−By, By]. We denote
Nx
t=P
s<tιx
s, we note that if t /∈ Gx, then Nx
t=⌈τ⌉a.s. Using Lemma 12, we find that for all
t /∈ Gx, a.s., Nx
t=⌈τ⌉. Then,
P
∃t /∈ Gx:P
s∈Gx,s<t˜yx
t−˜gx
t
Nx
t≥2Bys
log(2|X|/α)
2⌈τ⌉

≤P
Nx
t=⌈τ⌉andP
s∈Gx,s<t˜yx
t−˜gx
t
Nx
t≥2Bys
log(2|X|/α)
2⌈τ⌉

≤α
|X|.
Moreover, since gis (Lg,β)-Holder- continuous, and ∥xt−xt∥ ≤(ϵ
3Lg)1/βa.s., we have
|g(xt)−˜gx
t| ≤Lg·"ϵ
3Lg1/β#β
=ϵ
3.
Then, with probability at least 1−α/|X|, for all t /∈ Gx,
|bg(xt)−g(xt)| ≤2Bys
log(2|X|/α)
2⌈τ⌉+ϵ
3
≤2ϵ
3.
where we used τ=18B2
ylog(|X|/α)
ϵ2 . Using a union bound over X, we find that with probability at
least1−α, for all t /∈ Gx,
|bg(xt)−g(xt)| ≤2ϵ
3.
Similarly, for all t /∈ G,∥g(xt)−g(xt)∥ ≤Lgϵ
3Lg.Then, we have that with probability 1−α, for
allt /∈ Gx,
|bg(xt)−g(xt)| ≤ϵ.
22D.12 Proof of Lemma 12
Let us define Zt=P
s≤tιs(ys−E[ys|Fs−1]), and for x∈R,Mt= exp
xZt−x2(M−m)2Nt
8
.
We begin by showing that Mtis a super-martingale. Indeed, we have that
Eh
exιt(yt−E[yt|Ft−1])Ft−1i
=Eh
ιtex(yt−E[yt|Ft−1])+ (1−ιt)Ft−1i
≤ιtex2(M−m)2
8 + (1−ιt)
≤ex2(M−m)2ιt
8 .
where we use the fact that (yt−E[yt|Ft−1])is bounded in [m, M ]together with the conditional
version of Hoeffding’s Lemma. Noticing that
Mt=Mt−1exιt(yt−E[yt|Ft−1])−x2(M−m)2ιt
8 ,
this proves that Mtis a super-martingale, and so E[Mt]≤E[M0] = 1 .
Now, for all ϵ >0and all l∈N, and all x >0, by a Markov-Chernoff argument,
P(Zt≥ϵandNt=l) =P 
1{Nt=l}exZt≥eϵx
≤e−ϵxE 
exZt1{Nt=l}
=e−ϵx+x2(M−m)2l
8E
exZt−x2(M−m)2l
81{Nt=l}
.
Using the previous result, we have that
E
exZt−x2(M−m)2l
81{Nt=l}
=E
exZt−x2(M−m)2Nt
8 1{Nt=l}
≤E
exZt−x2(M−m)2Nt
8
=E(Mt)
≤E(M0) = 1 .
so
P(Zt≥ϵandNt=l)≤e−ϵx+x2(M−m)2l
8 .
In particular, for ϵ= (M−m)q
l·log(1/α)
2andx=4ϵ
l(M−m)2,
P 
Zt≥(M−m)r
l·log(1/α)
2andNt=l!
≤α.
This proves the first part of the Lemma. Summing over the values of lfrom 1tot, we find that
P 
Zt≥(M−m)r
Ntlog(1/α)
2andNt≥1!
≤tα.
Similar arguments can be used to prove that
P 
−Zt≥(M−m)r
Ntlog(1/α)
2andNt≥1!
≤tα.
Noting that Zt= ˆµtNtand normalizing by Nt(and since adding the case Nt= 0can only increase
the probability) concludes the proof of the Lemma.
23NeurIPS Paper Checklist
1.Claims
Question: Do the main claims made in the abstract and introduction accurately reflect the
paper’s contributions and scope?
Answer: [Yes]
Justification: In the abstract and introduction, we claim to present a novel approach to
dynamic pricing that enjoys improved regret bounds. We clearly state the approach and
explain its novelty, while proving all stated bounds in the appendix.
Guidelines:
•The answer NA means that the abstract and introduction do not include the claims
made in the paper.
•The abstract and/or introduction should clearly state the claims made, including the
contributions made in the paper and important assumptions and limitations. A No or
NA answer to this question will not be perceived well by the reviewers.
•The claims made should match theoretical and experimental results, and reflect how
much the results can be expected to generalize to other settings.
•It is fine to include aspirational goals as motivation as long as it is clear that these goals
are not attained by the paper.
2.Limitations
Question: Does the paper discuss the limitations of the work performed by the authors?
Answer: [Yes]
Justification: The main limitations of our papers are due to the assumptions on the setting.
While we follow a minimal set of assumptions that is standard in the dynamic pricing
literature, we discuss how to alleviate them in the conclusion section. The computational
complexity of our algorithm is comparable to previous work on the topic: the complexity
of the price elimination is polylog (d, T), while the complexity of the valuation estimation
depends on the valuation model. For linear valuations, it is polynomial, while for non-
parametric ones, it is exponential – as standard in the non-parametric bandit literature.
Guidelines:
•The answer NA means that the paper has no limitation while the answer No means that
the paper has limitations, but those are not discussed in the paper.
• The authors are encouraged to create a separate "Limitations" section in their paper.
•The paper should point out any strong assumptions and how robust the results are to
violations of these assumptions (e.g., independence assumptions, noiseless settings,
model well-specification, asymptotic approximations only holding locally). The authors
should reflect on how these assumptions might be violated in practice and what the
implications would be.
•The authors should reflect on the scope of the claims made, e.g., if the approach was
only tested on a few datasets or with a few runs. In general, empirical results often
depend on implicit assumptions, which should be articulated.
•The authors should reflect on the factors that influence the performance of the approach.
For example, a facial recognition algorithm may perform poorly when image resolution
is low or images are taken in low lighting. Or a speech-to-text system might not be
used reliably to provide closed captions for online lectures because it fails to handle
technical jargon.
•The authors should discuss the computational efficiency of the proposed algorithms
and how they scale with dataset size.
•If applicable, the authors should discuss possible limitations of their approach to
address problems of privacy and fairness.
•While the authors might fear that complete honesty about limitations might be used by
reviewers as grounds for rejection, a worse outcome might be that reviewers discover
limitations that aren’t acknowledged in the paper. The authors should use their best
24judgment and recognize that individual actions in favor of transparency play an impor-
tant role in developing norms that preserve the integrity of the community. Reviewers
will be specifically instructed to not penalize honesty concerning limitations.
3.Theory Assumptions and Proofs
Question: For each theoretical result, does the paper provide the full set of assumptions and
a complete (and correct) proof?
Answer: [Yes]
Justification: We clearly state our assumptions and prove the results in the appendix.
Guidelines:
• The answer NA means that the paper does not include theoretical results.
•All the theorems, formulas, and proofs in the paper should be numbered and cross-
referenced.
•All assumptions should be clearly stated or referenced in the statement of any theorems.
•The proofs can either appear in the main paper or the supplemental material, but if
they appear in the supplemental material, the authors are encouraged to provide a short
proof sketch to provide intuition.
•Inversely, any informal proof provided in the core of the paper should be complemented
by formal proofs provided in appendix or supplemental material.
• Theorems and Lemmas that the proof relies upon should be properly referenced.
4.Experimental Result Reproducibility
Question: Does the paper fully disclose all the information needed to reproduce the main ex-
perimental results of the paper to the extent that it affects the main claims and/or conclusions
of the paper (regardless of whether the code and data are provided or not)?
Answer: [Yes]
Justification: The information needed to reproduce the experiment is detailed in Appendix A.
Guidelines:
• The answer NA means that the paper does not include experiments.
•If the paper includes experiments, a No answer to this question will not be perceived
well by the reviewers: Making the paper reproducible is important, regardless of
whether the code and data are provided or not.
•If the contribution is a dataset and/or model, the authors should describe the steps taken
to make their results reproducible or verifiable.
•Depending on the contribution, reproducibility can be accomplished in various ways.
For example, if the contribution is a novel architecture, describing the architecture fully
might suffice, or if the contribution is a specific model and empirical evaluation, it may
be necessary to either make it possible for others to replicate the model with the same
dataset, or provide access to the model. In general. releasing code and data is often
one good way to accomplish this, but reproducibility can also be provided via detailed
instructions for how to replicate the results, access to a hosted model (e.g., in the case
of a large language model), releasing of a model checkpoint, or other means that are
appropriate to the research performed.
•While NeurIPS does not require releasing code, the conference does require all submis-
sions to provide some reasonable avenue for reproducibility, which may depend on the
nature of the contribution. For example
(a)If the contribution is primarily a new algorithm, the paper should make it clear how
to reproduce that algorithm.
(b)If the contribution is primarily a new model architecture, the paper should describe
the architecture clearly and fully.
(c)If the contribution is a new model (e.g., a large language model), then there should
either be a way to access this model for reproducing the results or a way to reproduce
the model (e.g., with an open-source dataset or instructions for how to construct
the dataset).
25(d)We recognize that reproducibility may be tricky in some cases, in which case
authors are welcome to describe the particular way they provide for reproducibility.
In the case of closed-source models, it may be that access to the model is limited in
some way (e.g., to registered users), but it should be possible for other researchers
to have some path to reproducing or verifying the results.
5.Open access to data and code
Question: Does the paper provide open access to the data and code, with sufficient instruc-
tions to faithfully reproduce the main experimental results, as described in supplemental
material?
Answer: [Yes]
Justification: The code to reproduce the experiments is publicly
available in the repository https: // github. com/ MatildeTulii1/
Improved-Algorithms-for-Contextual-Dynamic-Pricing
Guidelines:
• The answer NA means that paper does not include experiments requiring code.
•Please see the NeurIPS code and data submission guidelines ( https://nips.cc/
public/guides/CodeSubmissionPolicy ) for more details.
•While we encourage the release of code and data, we understand that this might not be
possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not
including code, unless this is central to the contribution (e.g., for a new open-source
benchmark).
•The instructions should contain the exact command and environment needed to run to
reproduce the results. See the NeurIPS code and data submission guidelines ( https:
//nips.cc/public/guides/CodeSubmissionPolicy ) for more details.
•The authors should provide instructions on data access and preparation, including how
to access the raw data, preprocessed data, intermediate data, and generated data, etc.
•The authors should provide scripts to reproduce all experimental results for the new
proposed method and baselines. If only a subset of experiments are reproducible, they
should state which ones are omitted from the script and why.
•At submission time, to preserve anonymity, the authors should release anonymized
versions (if applicable).
•Providing as much information as possible in supplemental material (appended to the
paper) is recommended, but including URLs to data and code is permitted.
6.Experimental Setting/Details
Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
results?
Answer: [Yes]
Justification: The details of the implementations of the simulations are detailed in Appendix
A.
Guidelines:
• The answer NA means that the paper does not include experiments.
•The experimental setting should be presented in the core of the paper to a level of detail
that is necessary to appreciate the results and make sense of them.
•The full details can be provided either with the code, in appendix, or as supplemental
material.
7.Experiment Statistical Significance
Question: Does the paper report error bars suitably and correctly defined or other appropriate
information about the statistical significance of the experiments?
Answer: [Yes]
Justification: All the information relative to the statistical significance of the algorithm is
contained in Appendix A.
26Guidelines:
• The answer NA means that the paper does not include experiments.
•The authors should answer "Yes" if the results are accompanied by error bars, confi-
dence intervals, or statistical significance tests, at least for the experiments that support
the main claims of the paper.
•The factors of variability that the error bars are capturing should be clearly stated (for
example, train/test split, initialization, random drawing of some parameter, or overall
run with given experimental conditions).
•The method for calculating the error bars should be explained (closed form formula,
call to a library function, bootstrap, etc.)
• The assumptions made should be given (e.g., Normally distributed errors).
•It should be clear whether the error bar is the standard deviation or the standard error
of the mean.
•It is OK to report 1-sigma error bars, but one should state it. The authors should
preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis
of Normality of errors is not verified.
•For asymmetric distributions, the authors should be careful not to show in tables or
figures symmetric error bars that would yield results that are out of range (e.g. negative
error rates).
•If error bars are reported in tables or plots, The authors should explain in the text how
they were calculated and reference the corresponding figures or tables in the text.
8.Experiments Compute Resources
Question: For each experiment, does the paper provide sufficient information on the com-
puter resources (type of compute workers, memory, time of execution) needed to reproduce
the experiments?
Answer: [Yes]
Justification: All the simulation can be (and were) run on a laptop without gpus.
Guidelines:
• The answer NA means that the paper does not include experiments.
•The paper should indicate the type of compute workers CPU or GPU, internal cluster,
or cloud provider, including relevant memory and storage.
•The paper should provide the amount of compute required for each of the individual
experimental runs as well as estimate the total compute.
•The paper should disclose whether the full research project required more compute
than the experiments reported in the paper (e.g., preliminary or failed experiments that
didn’t make it into the paper).
9.Code Of Ethics
Question: Does the research conducted in the paper conform, in every respect, with the
NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines ?
Answer: [Yes]
Justification: The paper theoretically studies a well-established theoretical problem; as such,
it does not have any direct ethical implications.
Guidelines:
•The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
•If the authors answer No, they should explain the special circumstances that require a
deviation from the Code of Ethics.
•The authors should make sure to preserve anonymity (e.g., if there is a special consid-
eration due to laws or regulations in their jurisdiction).
10.Broader Impacts
Question: Does the paper discuss both potential positive societal impacts and negative
societal impacts of the work performed?
27Answer: [Yes]
Justification: The paper theoretically studies a well-established theoretical problem and
the broader impact of our work is only due to the potential impact of advancements in this
problem. As all pricing problems, dynamic pricing can have both positive and negative
impacts – offering prices that are more suited to the buyers on the one hand, while increasing
the seller’s revenue at the expense of buyers on the other hand. In addition, as with many
contextual problems, there might be biases and challenges involving fairness – one should
make sure that similar customers are offered similar prices. This study is orthogonal to ours,
and we leave it for future work.
Guidelines:
• The answer NA means that there is no societal impact of the work performed.
•If the authors answer NA or No, they should explain why their work has no societal
impact or why the paper does not address societal impact.
•Examples of negative societal impacts include potential malicious or unintended uses
(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
(e.g., deployment of technologies that could make decisions that unfairly impact specific
groups), privacy considerations, and security considerations.
•The conference expects that many papers will be foundational research and not tied
to particular applications, let alone deployments. However, if there is a direct path to
any negative applications, the authors should point it out. For example, it is legitimate
to point out that an improvement in the quality of generative models could be used to
generate deepfakes for disinformation. On the other hand, it is not needed to point out
that a generic algorithm for optimizing neural networks could enable people to train
models that generate Deepfakes faster.
•The authors should consider possible harms that could arise when the technology is
being used as intended and functioning correctly, harms that could arise when the
technology is being used as intended but gives incorrect results, and harms following
from (intentional or unintentional) misuse of the technology.
•If there are negative societal impacts, the authors could also discuss possible mitigation
strategies (e.g., gated release of models, providing defenses in addition to attacks,
mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
feedback over time, improving the efficiency and accessibility of ML).
11.Safeguards
Question: Does the paper describe safeguards that have been put in place for responsible
release of data or models that have a high risk for misuse (e.g., pretrained language models,
image generators, or scraped datasets)?
Answer: [NA]
Justification: The paper poses no such risks.
Guidelines:
• The answer NA means that the paper poses no such risks.
•Released models that have a high risk for misuse or dual-use should be released with
necessary safeguards to allow for controlled use of the model, for example by requiring
that users adhere to usage guidelines or restrictions to access the model or implementing
safety filters.
•Datasets that have been scraped from the Internet could pose safety risks. The authors
should describe how they avoided releasing unsafe images.
•We recognize that providing effective safeguards is challenging, and many papers do
not require this, but we encourage authors to take this into account and make a best
faith effort.
12.Licenses for existing assets
Question: Are the creators or original owners of assets (e.g., code, data, models), used in
the paper, properly credited and are the license and terms of use explicitly mentioned and
properly respected?
Answer: [NA]
28Justification: The paper does not use existing assets.
Guidelines:
• The answer NA means that the paper does not use existing assets.
• The authors should cite the original paper that produced the code package or dataset.
•The authors should state which version of the asset is used and, if possible, include a
URL.
• The name of the license (e.g., CC-BY 4.0) should be included for each asset.
•For scraped data from a particular source (e.g., website), the copyright and terms of
service of that source should be provided.
•If assets are released, the license, copyright information, and terms of use in the
package should be provided. For popular datasets, paperswithcode.com/datasets
has curated licenses for some datasets. Their licensing guide can help determine the
license of a dataset.
•For existing datasets that are re-packaged, both the original license and the license of
the derived asset (if it has changed) should be provided.
•If this information is not available online, the authors are encouraged to reach out to
the asset’s creators.
13.New Assets
Question: Are new assets introduced in the paper well documented and is the documentation
provided alongside the assets?
Answer: [NA]
Justification: The paper does not release new assets.
Guidelines:
• The answer NA means that the paper does not release new assets.
•Researchers should communicate the details of the dataset/code/model as part of their
submissions via structured templates. This includes details about training, license,
limitations, etc.
•The paper should discuss whether and how consent was obtained from people whose
asset is used.
•At submission time, remember to anonymize your assets (if applicable). You can either
create an anonymized URL or include an anonymized zip file.
14.Crowdsourcing and Research with Human Subjects
Question: For crowdsourcing experiments and research with human subjects, does the paper
include the full text of instructions given to participants and screenshots, if applicable, as
well as details about compensation (if any)?
Answer: [NA]
Justification: The paper does not involve crowdsourcing nor research with human subjects.
Guidelines:
•The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
•Including this information in the supplemental material is fine, but if the main contribu-
tion of the paper involves human subjects, then as much detail as possible should be
included in the main paper.
•According to the NeurIPS Code of Ethics, workers involved in data collection, curation,
or other labor should be paid at least the minimum wage in the country of the data
collector.
15.Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
Subjects
Question: Does the paper describe potential risks incurred by study participants, whether
such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
approvals (or an equivalent approval/review based on the requirements of your country or
institution) were obtained?
29Answer: [NA]
Justification: The paper does not involve crowdsourcing nor research with human subjects.
Guidelines:
•The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
•Depending on the country in which research is conducted, IRB approval (or equivalent)
may be required for any human subjects research. If you obtained IRB approval, you
should clearly state this in the paper.
•We recognize that the procedures for this may vary significantly between institutions
and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
guidelines for their institution.
•For initial submissions, do not include any information that would break anonymity (if
applicable), such as the institution conducting the review.
30