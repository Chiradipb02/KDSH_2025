Synthetic Data (Almost) from Scratch:
Generalized Instruction Tuning for Language Models
Anonymous Author(s)
Affiliation
Address
email
Abstract
We introduce Generalized Instruction Tuning (called GLAN ), a general and scal- 1
able method for instruction tuning of Large Language Models (LLMs). Unlike prior 2
work that relies on seed examples or existing datasets to construct instruction-tuning 3
data, GLAN exclusively utilizes a pre-curated taxonomy of human knowledge and 4
capabilities as input and generates large-scale synthetic instruction data across all 5
disciplines. Specifically, inspired by the systematic structure in human education 6
system, we build the taxonomy by decomposing human knowledge and capabilities 7
to various fields, sub-fields and ultimately, distinct disciplines semi-automatically, 8
facilitated by LLMs. Subsequently, we generate a comprehensive list of subjects 9
for every discipline and proceed to design a syllabus tailored to each subject, again 10
utilizing LLMs. With the fine-grained key concepts detailed in every class session 11
of the syllabus, we are able to generate diverse instructions with a broad coverage 12
across the entire spectrum of human knowledge and skills. Extensive experiments 13
on large language models (e.g., Mistral) demonstrate that GLAN excels in mul- 14
tiple dimensions from mathematical reasoning, coding, academic exams, logical 15
reasoning to general instruction following without using task-specific training data 16
of these tasks. In addition, GLAN allows for easy customization and new fields or 17
skills can be added by simply incorporating a new node into our taxonomy. 18
1 Introduction 19
Large Language Models (LLMs) have enabled unprecedented capabilities to understand and generate 20
text like humans. By scaling up model size and data size [ 17,13], LLMs are better at predicting 21
next tokens and prompting to perform certain tasks with a few demonstrations [ 2]. However, these 22
capabilities do not directly translate to better human instruction following [ 25]. Instruction tuning 23
[34] bridges this gap by fine-tuning LLMs on instructions paired with human-preferred responses. 24
Prior work constructs instruction tuning data from seed examples or existing datasets. Initially, natural 25
language processing (NLP) datasets described via instructions are used to fine-tune LLMs and the 26
resulting LLMs can generalize on unseen (NLP) tasks [ 34]. However, there are only thousands of 27
NLP tasks [ 33,19] available, which limits the tuned LLMs to generalize in real-world scenarios [ 39]. 28
Self-instruct [ 32] is a cost-effective method for creating synthetic instruction tuning datasets, which 29
starts from a small pool of human-written seed instructions and generates new instructions by few- 30
shot prompting an LLM (e.g., text-davinci-002 ) with randomly selected instructions from the 31
pool. Unfortunately, the diversity of generated instructions is still an issue, since few-shot prompting 32
tends to generate new instructions similar to its demonstrations. In addition, the process of creating 33
high-quality seed instructions requires considerable human effort and expertise. Evolve-Instruct [ 39] 34
improves self-instruct by augmenting existing instruction tuning datasets with different rewriting 35
operations using LLMs, which is essentially data argumentation. Consequently, the scope of domains 36
Submitted to 38th Conference on Neural Information Processing Systems (NeurIPS 2024). Do not distribute.Figure 1: Comparing GLAN with FLAN, Self-Instruct and Evolve-Instruct. The inputs of FLAN,
Self-Instrct and Eovlve-Instruct are either seed examples or existing datasets, which limits the scope
of domains of instructions that these methods can generate. GLAN takes the taxonomy of human
knowledge & capabilities as input to ensure the broad coverage of generated instructions in various
domains. This taxonomy is then broken down into smaller pieces and recombined to generate diverse
instruction data.
or tasks that these augmented datasets can cover is limited by the original input datasets. See Figure 1 37
for illustrations of these methods described above. There are also studies concentrated on developing 38
instruction-tuning datasets tailored to particular domains or tasks. For instance, [ 20] creates datasets 39
targeting mathematical reasoning. In contrast, [3] and [21] focus on coding-related tasks. All of the 40
above methods cannot produce instruction datasets that are generally applicable to a wide range of 41
domains. 42
How to create a general instruction tuning dataset? We draw inspiration from the systematic structure 43
in human education system. The structure of human education includes several levels, starting 44
from early childhood education up to higher education and beyond [ 37]. Within each level, a 45
student acquires knowledge, skills, and values in a systematic process. The courses a student learns 46
from primary school to college cover a broad range of knowledge and skills, which facilitates the 47
development of a diverse array of abilities. We believe that the systemic framework of the human 48
education system has the potential to help the generation of high-quality and general instruction data, 49
which spans a diverse range of disciplinary areas. 50
In this paper, we introduce a generalized instruction tuning paradigm GLAN (shorthand for 51
Generalized Instruction-Tuning for Large L ANguage Models) to generate synthetic instruction 52
tuning data almost from scratch. Unlike existing work [ 39,21,20,24],GLAN exclusively utilizes 53
a pre-curated taxonomy of human knowledge and capabilities as input and generates large-scale 54
instruction data systematically and automatically across all disciplines. Specifically, inspired by 55
the structure of the human education system, the input taxonomy is constructed by decomposing 56
human knowledge and capabilities to various fields, sub-fields, and, ultimately, distinct disciplines 57
semi-automatically, facilitated by LLMs and human verification. The cost of human verification 58
process is low due to the limited number of disciplines in the taxonomy. As shown in Figure 1, 59
we then further break down these disciplines into even smaller units. We continue to generate a 60
comprehensive list of subjects for every discipline and proceed to design a syllabus tailored to each 61
subject, again utilizing LLMs. With the fine-grained key concepts detailed in every class session 62
of the syllabus, we can first sample from them and then generate diverse instructions with broad 63
coverage across the entire spectrum of human knowledge and skills. The process described above 64
mirrors the human educational system, where educators in each discipline craft a series of subjects 65
for student learning. Instructors then develop a syllabus for each subject, breaking down the content 66
into specific class sessions. These sessions are then further divided into core concepts that students 67
must comprehend and internalize. Based on these detailed core concepts outlined in the syllabus, 68
teaching materials and exercises are subsequently created, which are our instruction tuning data. 69
2GLAN is general, scalable and customizable. GLAN is a general method, which is task-agnostic 70
and is capable of covering a wide range of domains. GLAN is scalable. Similar to [ 32,39],GLAN 71
generates instructions using LLMs, which can produce instructions on a massive scale. Moreover, the 72
input of GLAN is a taxonomy, which is generated by prompting an LLM and human verification, 73
requiring minimal human effort. GLAN allows for easy customization. New fields or skills can be 74
added by simply incorporating a new node into our taxonomy. Note that each node of the taxonomy 75
can be expanded independently, which means that we only need to apply our method to the newly 76
added nodes without re-generating the entire dataset. Extensive experiments on large language 77
models (e.g., Mistral) demonstrate that GLAN excels in multiple dimensions from mathematical 78
reasoning, coding, academic exams, and logical reasoning to general instruction following without 79
using task-specific training data of these tasks. 80
2 GLAN: Generalized Instruction-Tuned Language Models 81
GLAN aims to create synthetic instruction data covering various domains of human knowledge 82
and capabilities on a large scale. As shown in Algorithm 1, we first build a taxonomy of human 83
knowledge and capabilities using frontier LLMs (i.e., GPT-4 ) and human verification. The taxonomy 84
naturally breaks down human knowledge and capabilities to fields ,sub-fields , and ultimately different 85
disciplines (see Section 2.1). The following steps are fully autonomously facilitated by GPT-4 (or 86
GPT-3.5 ). Then for each discipline, we again instruct GPT-4 to further decompose it into a list of 87
subjects within this discipline (Section 2.2). Similar to an instructor, GPT-4 continues to design 88
a syllabus for each subject, which inherently breaks a subject into various class sessions with key 89
concepts students need to master (Section 2.3). With obtained class sessions and key concepts, we 90
are ready to construct synthetic instructions. We prompt GPT-4 to generate homework questions 91
based on randomly sampled class sessions and key concepts as well as the syllabus (Section 2.4). 92
We recursively decompose human knowledge and capabilities into smaller units until atomic-level 93
components (i.e., class sessions and key concepts). We expect to randomly combine these class 94
sessions and key concepts to ensure the coverage and diversity of synthetic instructions. 95
Algorithm 1 GLAN Instruction Generation
D←build_taxonomy() ▷build a taxonomy and return a list of disciplines (Section 2.1)
L←∅
foreach discipline d∈Ddo
S←generate_subjects (d) ▷Obtain a list of subjects ind(Section 2.2)
foreach subject s∈Sdo
A ←generate_syllabus (s, d) ▷Return syllabus Afors(Section 2.3)
C,K←extract_class_details (A) ▷Extract class sessions and key concepts
(Section 2.3)
Q←generate_instructions (A,C,K, d)▷Generate instructions by sampling class
sessions and key concepts (Section 2.4)
L←L∪Q
end for
end for
return L
2.1 Taxonomy of Human Knowledge and Capabilities 96
We build a taxonomy of human knowledge and capabilities to guide the generation of synthetic 97
instructions. Therefore, its coverage is important. On the other hand, it is also essential to make 98
the taxonomy highly extensible, since the preferred capabilities of LLMs may change over time. 99
In the first step, we propose to generate the taxonomy by prompting GPT-4 with a set of different 100
instructions (e.g., list all fields of human knowledge and capabilities ). Then, we do 101
human post-editing to ensure its correctness and completeness. Due to the limited number of fields, 102
sub-fields, and disciplines in our taxonomy, the cost of human verification is reasonably low. Another 103
advantage of human post-editing is that we can easily add new fields or disciplines to the taxonomy 104
as needed. 105
3Our taxonomy currently covers a diverse range of knowledge and capabilities in both academic 106
education and vocational training. The top level of the taxonomy contains fields such as Natural 107
Sciences ,Humanities , orServices (vocational training). These fields branch out to various sub-fields 108
and/or disciplines such as Chemistry ,Sociology orRetailing . We keep breaking down nodes of the 109
taxonomy until disciplines , and we leave the breaking down of disciplines to automatic methods 110
described in the following sections. By collecting the leaf nodes of the taxonomy, we obtain a list of 111
disciplines D={d1, d2, . . . , d M}. 112
2.2 Subject Generator 113
As in Algorithm 1, for each discipline d, we aim to extract the list of subjects in it through prompt 114
engineering. Specifically, we instruct GPT-4 toact as an education expert of discipline 115
dand design a list of subjects a student should learn . The completion of GPT-4 116
contains a comprehensive list of subjects and their meta data (e.g., level, introduction and subtopics 117
of the subject) in unstructured text format, which can not be directly used in subsequent steps. We 118
therefore used another round of prompting to convert the completion to JSONL format: 119
Awesome! Transform the above to JSONL format so that it is easier for 120
a computer to understand. Enclose the JSONL output between two sets of 121
triple backticks. For each JSONL object, use the keys “subject_name”, 122
“level” and “subtopics”. 123
It is worth noting that generating a subject list in JSONL format using a single prompt is feasible. 124
However, we refrain to do so, because we observe that incorporating additional formatting instructions 125
directly into the prompt can compromise the quality of the resulting subject list. These extracted 126
subjects (as well as their meta data) S={s1, s2, . . . , s N}can be subsequently used in next steps. 127
For each s∈S, lets.name ,s.level ands.subtopics denote the name, grade level and subtopics 128
of subject s, respectively. We can apply the above prompts multiple times to ensure better coverage 129
of subjects within this discipline. 130
2.3 Syllabus Generator 131
For each subject s, we have already extracted its name ( s.name ), grade level ( s.level ), and a 132
small set of included sub-topics ( s.subtopics ) in a structured format. In this section, we aim to 133
further segment each subject into smaller units, making them more suitable for creating homework 134
assignments. We consult GPT-4 to design a syllabus for this subject. We opt for syllabus generation 135
for the following reasons. Firstly, a syllabus essentially breaks down the main topic of a subject 136
into smaller segments in a hierarchical manner. Specifically, each subject comprises several class 137
sessions, and each session covers a variety of sub-topics and key concepts. Secondly, a syllabus 138
provides an introduction, objectives, and expected outcomes of a subject, which are inherently useful 139
for formulating homework questions. We instruct GPT-4 to 1) design a syllabus based on its meta 140
data (s.level ,s.name ands.subtopics ); 2) break the subject into different class sessions; 3) 141
provide details for each class session with a description and detailed key concepts students need to 142
master. 143
LetAdenote the generated syllabus. The resulting syllabus Ais in unstructured text format. However, 144
class session names and key concepts of each class are required in the instruction generation step (see 145
Algorithm 1). Similar to the process of subject list extraction in Section 2.2, we again extract these 146
meta data of each class session by prompting GPT-4 . As a result, we obtain a list of class sessions 147
C={c1, c2, . . . , c |C|}and their corresponding key concepts K={k1,k2, . . . ,k|C|}. The detailed 148
prompt for syllabus generation is in Appendix A.3. 149
2.4 Instruction Generator 150
Given a syllabus Aas well as a list of its class sessions Cand their associated key concepts K, 151
we are ready to generate homework questions and their answers. To generate diverse homework 152
questions, we first sample one or two class session names from Cand one to five key concepts under 153
these selected class sessions. Let ˆCdenote the selected class session names and ˆKthe selected key 154
concepts. Then we prompt GPT-4 (orGPT-3.5 ) to generate a homework question given the selected 155
class sessions ˆCand key concepts ˆKas well as the syllabus A. We intend to give GPT-4/3.5 more 156
4context (e.g., what students have already learned in previous sessions) when creating assignments. 157
Therefore, we additionally instruct GPT to consider that students have learned up to class sessions ˆC 158
when crafting homework and try to leverage multiple key concepts across different class sessions. 159
See details of our prompt for instruction generation in Appendix A.4. 160
Sampling Class Sessions and Key Concepts In a single syllabus, there are numerous class sessions 161
and key concepts. We have two strategies to sample from them. In the first strategy, we generate 162
assignments from a single class session. Therefore, we have only one class session name. Suppose 163
we have mkey concepts in total in this session. We randomly sample one to five key concepts from 164
themkey concepts, which means we have totallyP5
i=1 m
i
combinations. In this strategy, we focus 165
on creating basic homework questions. To make the resulting questions more challenging (combine 166
knowledge from multiple class sessions), we propose a second strategy to combine key concepts 167
from two class sessions in the second strategy. We intend to generate questions leverage knowledge 168
from two different class sessions. Suppose we have m1andm2key concepts in the first and second 169
class sessions, respectively. We can haveP5
i=2 m1+m2
i
−P5
i=2 m1
i
−P5
i=2 m2
i
different 170
combinations, which is significantly more than that of the first strategy. We use both strategies to 171
ensure our created questions are diverse in difficulty levels. 172
Answer Generation After we generate questions in previous steps, we simply send these questions 173
toGPT-3.5 and collect answers. We use GPT-3.5 for answer generation, because we find the quality 174
of generated answers from GPT-3.5 is sufficiently good and using GPT-3.5 is significantly faster 175
thanGPT-4 . The resulting question-answer pairs are our instruction tuning data. With a huge amount 176
of question-answer pairs ranging from different disciplines with various difficulty levels, we expect 177
the resulting LLM can excel in a wide range of tasks. 178
3 Experiments 179
3.1 Data Generation 180
Taxonomy Creation By asking GPT-4 to create a taxonomy of human knowledge and capabilities, 181
we end up with a set of fields, sub-fields, and disciplines that cover a broad range of domains in human 182
knowledge and capabilities. Next, we ask human annotators to decide whether these elements in the 183
taxonomy should be kept or not in order to reduce the redundancy of the taxonomy while maintaining 184
its correctness. Note that if a field or sub-field is marked as remove , we remove its descendant as 185
well. We kept 126 disciplines after majority voting (provided in supplementary materials). Note that 186
it is feasible to manually add extra disciplines, sub-fields, or fields whenever necessary. 187
Subject and Syllabus Generation During the subject list and syllabus generation, we prompt 188
GPT-4 and employ nucleus sampling [ 14] with temperature T= 1.0and top- p= 0.95to encourage 189
diversity. We do not use GPT-3.5-turbo since some subjects belong to the long-tail distribution 190
which may not be effectively modeled by GPT-3.5-turbo . To ensure diversity and completeness of 191
the generated subjects, we query GPT-4 10 times for each discipline (Section 2.2). There are 100 to 192
200 subjects for each discipline on average. It is worth noting that the same subjects may appear in 193
different disciplines. For instance, the subject calculus is both in physics and mathematics. We do 194
not de-duplicate those subjects, since it may reflect their importance in human knowledge. Given a 195
subject in a specified discipline, we query GPT-4 for only one time to design a syllabus (see details in 196
section 2.3). The temperature and top- pare still set to 1.0 and 0.95, respectively. The number of class 197
sessions contained in each syllabus varies from 10 to 30 and each class session contains around five 198
key concepts. 199
Instruction Generation Each instruction data consists of a question and its answer. We choose to 200
generate questions and answers separately since we observed that separate generations lead to better 201
quality. After question generation with GPT-4 , each question is then answered by GPT-3.5-turbo 202
with temperature T= 0.7, top- p= 0.95(we use a lower temperature in order to make the re- 203
sulting answers more accurate). We use GPT-3.5-turbo instead of GPT-4 for answer generation, 204
becauseGPT-3.5-turbo is significantly faster with reasonably good results. We generate 10 million 205
instruction-response pairs in total and then we do training data decontamination. Specifically, the 206
training instruction-response pairs are decontaminated by removing pairs that contain questions or 207
5Table 1: Main results on Mathematical Reasoning, Coding, Logical Reasoning, and Academic Exam
benchmarks. Best results are in boldface, while the second best results are underscored.
Model | θ| HumanE MBPP GSM8K MATH BBH ARC-E ARC-C MMLU
GPT-4 – 88.4 80.0 92.0 52.9 86.7 95.4 93.6 86.4
GPT-3.5-turbo – 72.6 70.8 74.1 37.8 70.1 88.9 83.7 70.0
LLaMA2 7B 12.8 36.2 15.4 4.2 39.6 74.6 46.3 45.9
Orca 2 7B 17.1 28.4 55.7 10.1 42.8 87.8 78.4 53.9
WizardLM v1.2 13B 31.7 47.9 46.8 9.0 48.4 74.2 50.2 52.7
Mistral 7B 28.0 50.2 43.4 10.0 56.1 79.5 53.9 62.3
Mistral Instruct 7B 46.7 31.7 24.4 8.2 46.0 76.9 52.0 53.7
MetaMath Mistral 7B 35.4 48.6 77.7 28.2 55.7 77.3 51.0 61.0
WizardMath v1.1 7B 51.2 54.1 83.2 33.0 58.2 79.8 53.2 60.3
Mistral CodeAlpaca 7B 35.4 50.2 34.6 8.3 56.1 79.1 54.2 60.9
GLAN 7B 48.8 57.6 80.8 32.7 60.7 90.7 81.1 62.9
input prompts from the test and training (if any) sets of benchmarks we evaluate. We exclude the 208
training set of benchmarks we evaluate to verify the generalization capability of our synthetic data. 209
3.2 Model Training 210
We employ Mistral 7B [ 16] as our base model. During training, we concatenate each instruction and 211
response pair to a single sequence and only compute loss on response tokens. We train our model for 212
3 epochs with a learning rate of 3e-6. The batch size is set to approximately 512 instruction-response 213
pairs. We employ a dynamic batch size to ensure a constant total number of tokens per batch. We 214
use a cosine learning rate schedule and we start with a linear warm-up of 1000 steps and the final 215
learning rate is reduced to 0. The training requires approximately 8 days using 32 A100 GPUs. 216
3.3 Benchmark Evaluation 217
The instruction data GLAN generated spans a wide range of subjects. We evaluate its effectiveness 218
in mathematical reasoning, coding, logical reasoning, and academic exams. 219
Mathematical Reasoning :Mathematics is a common subject in many different disciplines. Hence, it 220
is necessary to test the math reasoning ability of GLAN . We choose the two popular benchmarks for 221
evaluation (i.e., GSM8K [ 7] and MATH [ 12]). GSM8K [ 7] is a high-quality math problem dataset 222
that measures the basic multi-step mathematical reasoning ability. It contains around 7k problems for 223
training and 1K problems for test. MATH [ 12] is a challenging math dataset that contains mathematics 224
competition-level problems from AMC, AIME, etc. The 7.5k training and 5K test problems cover 225
seven math subjects, i.e., Prealgebra, Precalculus, Algebra, Intermediate Algebra, Number Theory, 226
Counting and Probability, and Geometry. Note that GLAN does not use any examples in the training 227
set of GSM8K or MATH. Following [ 20], we report 0-shot setting results for GLAN .Coding :To 228
evaluate the coding capability of GLAN , we opt for two coding benchmarks HumanEval [ 4] and 229
MBPP [ 1]. We employ 0-shot setting for HumanEval and 3-shot setting for MBPP following prior art 230
[4,21].BBH :The instruction dataset we generated covers many disciplines, which can potentially 231
enhance the reasoning ability of GLAN . Therefore, we evaluate GLAN on the BIG-Bench Hard 232
dataset (BBH [ 29]), which contains 23 challenging tasks from Big-Bench [ 28]. We employ the 233
standard 3-shot setting with chain-of-thought demonstrations. Academic Exams :We also evaluate 234
GLAN on different academic benchmarks to verify whether GLAN is capable of solving exam 235
questions. We choose two benchmarks (i.e., ARC [ 6] and MMLU [ 11]). Both benchmarks are 236
composed of multi-choice questions. AI2 Reasoning Challenge (ARC [ 6]) contains grade-school 237
level, multi-choice science questions. It contains two sub-sets, which are ARC-Challenge (ARC-C) 238
and ARC-Easy (ARC-E). Massive Multitask Language Understanding (MMLU [ 11]) consists of a 239
set of multiple-choice questions about 57 subjects ranging in difficulty from elementary levels to 240
professional levels. It covers various of domains of knowledge, including humanities, STEM and 241
social sciences. Note that there is a training set for ARC. However, we have excluded it from our 242
6Table 2: Detailed Results on Academic Exam benchmarks.
Model ARC-E ARC-CMMLU
STEM Humanities Social Sciences Other
Mistral 79.5 53.9 52.0 56.5 73.3 70.1
GLAN 90.7 81.1 60.1 54.9 71.8 68.6
5e4 2e5 5e51e6 1e74243444546474849Pass@1
HumanEval
5e4 2e5 5e51e6 1e758.559.059.560.060.5Exact Match
BBH
5e4 2e5 5e51e6 1e76065707580Exact Match
GSM8K
5e4 2e5 5e51e6 1e720222426283032Exact Match
MATH
Figure 2: The scaling curve of GLAN on downstream tasks. The x-axis denotes GLAN data size (in
log10scale following [17]), and the y-axis denotes the task performance.
training set during the decontamination process described in Section 3.1. Previous models mostly 243
leverage probability-based methods on ARC and MMLU, which returns the best option based on the 244
probabilities of the four options conditioned on the corresponding multi-choice question. We observe 245
that after training on 10 million instructions, GLAN is able to generate its predicted options and 246
analysis of multi-choice questions in plain text as GPT-3.5 does. We therefore opt for 0-shot setting 247
for GLAN and extract predictions using rules based on its completions as in [22]. 248
Results Our main results are shown in Table 1. We compare GLAN against general domain models 249
(Orca 2 [ 22], Mistral Instruct [ 16] and WizardLM [ 39]), math optimized models (MetaMath [ 40] 250
and WizardMath [ 20]) and coding optimized models (CodeAlpaca [ 3]). We also report results of 251
base LLMs (i.e., LLaMA2 [ 31] and Mistral [ 16]) as references. GLAN either obtains the best results 252
or results close to the best across all benchmarks. We observe that capabilities of math or coding 253
optimized models increase on math or coding benchmarks while usually not others. After instruction 254
tuning, GLAN excels on multiple dimensions from mathematical reasoning, coding, reasoning, and 255
academic exams with a systematical data generation approach. Also note that our method does not 256
use any task-specific training data such as training sets of GSM8K, MATH, or ARC as in Orca 2, 257
MetaMath, and WizardMath, which indicates the general applicability of GLAN. 258
A Closer Look at Academic Exams ARC and MMLU are all multi-choice based benchmarks on 259
academic exams. However, we observe that improvements of GLAN over Mistral on ARC are much 260
larger than these on MMLU (see Table 1). By grouping the 57 subjects in MMLU into four categories 261
(i.e., STEM, Humanities, Social Sciences, and Other (business, health, misc.)), we observe GLAN 262
wildly improves on STEM in MMLU while not in other categories (Table 2). Also note that ARC 263
is composed of high school science problems, which are also STEM questions. GLAN is good at 264
STEM subjects may be because responses of our dataset are from GPT-3.5-turbo , which by default 265
generates responses with Chain-of-Thoughts (CoT) reasoning. Indeed, we observe that GLAN 266
generates solutions with CoT for multi-choice questions. CoT may help the multi-step reasoning in 267
STEM multi-choice questions [ 35], while humanities and social sciences questions involve more 268
memorization and single-step reasoning, where CoT may introduce additional errors. 269
3.4 Scaling Property of GLAN 270
We investigate the scaling property of GLAN by training Mistral on different numbers of examples 271
(i.e., 50K, 200K, 500K, 1M, and 10M) we generated. The results on downstream tasks are shown in 272
Figure 2. It can be observed that overall task performance tends to increase as we increase the data size. 273
Notably, the curve has not reached a plateau, indicating the potential for further improvement through 274
the continued scaling of the data size of GLAN . However, we defer further scaling experiments to 275
future work. 276
7Table 3: The evaluation of loss values between the test data and training data. Large positive ∆(or
∆(%) ) indicates task-specific in-domain training data might be exposed to the model during training.
Benchmark/Loss LLaMA2-7B Orca2-7B Mistral-7B-Instruct WizardLM-13B-V1.2 GLAN-7B
ARC-C∆ -0.01 0.05 -0.01 -0.01 -0.03
∆(%) -0.5% 2.10% -0.43% -0.47% -0.74%
ARC-E∆ -0.02 0.04 -0.03 -0.02 -0.01
∆(%) -0.95% 1.61% -1.19% -0.91% -0.23%
GSM8K∆ 0 0.13 0 0.05 0.02
∆(%) 0% 11.4% 0% 4.39% 0.92%
MATH∆ -0.03 0.03 -0.03 -0.02 -0.03
∆(%) -2.70% 2.54% -2.67% -1.63% -1.79%
3.5 Task-specific Training Data 277
GLAN is a generalized method to create synthetic data for instruction tuning. In order to evaluate 278
the generalization capabilities of this synthetic data, we deliberately exclude task-specific training 279
sets from all benchmarks on which we conduct our assessments. Similar to [ 36], we explore whether 280
models have been trained on task-specific in-domain data. We compute the training loss Ltrain and 281
test loss Lteston ARC Challenge (ARC-C), GSM8K, and MATH for GLAN and other models in 282
comparison. We choose these datasets because among all benchmarks evaluated in Section 3.3, these 283
benchmarks contain training sets. Intuitively, the larger ∆ =Ltest−Ltrain is, the more likely the 284
training set is exposed. To make ∆easier to interpret, we additionally compute the relative difference 285
∆(%) = ( Ltest−Ltrain)/Ltest. Table 3 shows the losses of the training and test splits for GLAN 286
are nearly identical (or ∆is negative). This suggests that GLAN has not been exposed to in-domain 287
data during training and tuning procedures. Please refer detailed Ltrain andLtestlosses in Table 8 (in 288
Appendix). Additionally, as shown in Table 8, we observe that GLAN obtains higher losses on both 289
test and training splits on GSM8K, MATH, and ARC compared to other models, while performances 290
ofGLAN on these datasets are high (see Table 1). This might imply that synthetic data generated by 291
GLAN is diverse and our resulting model avoids convergence to any specific domain or style present 292
in existing benchmarks. 293
3.6 Instruction Following Evaluation 294
IFEval We assess the instruction-following capabilities of GLAN utilizing the Instruction Fol- 295
lowing Evaluation dataset (IFEval [ 42]). IFEval consists of a collection of “verifiable instructions”, 296
encompassing 25 distinct types of instructions (around 500 prompts in total). Each prompt comprises 297
one or more verifiable instructions. The evaluation involves four types of metrics at both prompt 298
level and instruction level, evaluating strict and loose accuracies. As shown in Table 4, GLAN 299
demonstrates superior instruction-following capabilities in both prompt-level and instruction-level 300
evaluations. However, there is still a considerable gap compared to GPT-3.5-turbo andGPT-4 . 301
Table 4: Instruction following capability evaluation on IFEval.
Model Prompt-level
strict-accuracyInstruction-level
strict-accuracyPrompt-level
strict-accuracyInstruction-level
loose-accuracy
GPT-3.5-turbo 53.8 64.7 56.6 67.5
GPT-4 77.1 83.7 79.7 85.6
LLaMA2-7B 14.8 27.1 16.6 29.4
Orca2-7B 19.4 28.9 26.1 34.7
Mistral-7B-Instruct-v0.1 32.0 42.8 37.7 48.0
WizardLM-13B-V1.2 23.1 33.5 26.6 37.6
GLAN-7B 34.0 44.8 41.2 51.6
Evol-Instruct Test Evol-Instruct testset [ 39] contains real-world human instructions from diverse 302
sources, and it consists of 218 instances with 29 distinct skills. Each instruction is associated with 303
a difficulty level from 1 to 10. The responses are often open-ended descriptions, and we believe 304
this benchmark is a necessary supplement to IFEval (answers to their instructions are “verifiable”). 305
Following [ 39] and [ 5], we adopt a GPT-4-based automatic evaluation method to conduct a pairwise 306
comparison between GLAN and other models. Specifically, GPT-4 is instructed to assign a score 307
between 1 and 10 overall score w.r.t. the helpfulness, relevance, accuracy, and level of detail of 308
8Table 5: Pairwise comparison on various difficulty levels between GLAN and other models on
Evol-Instruct testset. The scores are the average gap of scores assigned by GPT-4, calculated as
avg_score( GLAN)−avg_score (x).
Difficulty Ratio LLaMA2-7B Orca2-7B Mistral-7B-Instruct Wizard-13B-V1.2 GPT-3.5-turbo
(1-5) Easy 41.00% 5.46 2.19 1.13 1.32 -1.22
(6-10) Hard 59.00% 5.38 2.28 1.68 0.99 -0.68
responses generated by two different models for a given input question. A higher score indicates 309
better overall performance. To mitigate potential order bias, we perform bidirectional comparisons 310
for each response pair and determine their average score. The average score difference to GLAN 311
(i.e.,avg_score( GLAN)−avg_score (x)) serves as the final metric. Table 5 presents the results 312
of pairwise comparisons across various levels of instruction difficulty. GLAN showcases superior 313
performance compared to LLaMA-2, Orca 2, Mistral Instruct, and even WizardLM-13B (note that 314
GLAN contains only 7B parameters) on most difficulty levels and overall scores. This suggests that 315
GLAN demonstrates improved ability to process diverse instructions, regardless of their difficulty 316
or complexity. Also, note that GLAN falls behind GPT-3.5-turbo as other models in comparison. 317
Additionally, we group Evol-Instruct test according to the 29 skills and observe the same trends. 318
Detailed results are listed in Appendix (Table 9 and 10). GLAN demonstrates strong performance on 319
most skills, especially in Math, Coding, and Reasoning. However, it slightly falls short in common- 320
sense related tasks. We also created GLAN -Test, similar to the Evol-Instruct Test but much larger in 321
size, where GLAN outperforms other models as well (see Appendix A.8). 322
4 Related Work 323
Recent literature has extensively explored the collection of various human-made resources for 324
instruction tuning. An intuitive direction is to collect existing NLP datasets and corresponding 325
task descriptions [ 26,33,41], typical LLMs such as BLOOMZ [ 23] and FLAN [ 34] are trained 326
on this type of instruction tuning data. However, with only tens to thousands of existing datasets 327
available, the scope and diversity of instruction tuning are inevitably limited. Another common 328
practice is to implement instruction tuning with real-world human user prompts. For instance, 329
InstructGPT [ 25] was trained on high-quality human prompts submitted by real-world users to 330
OpenAI GPT APIs. Vicuna [ 5] leverages user-shared prompts along with ChatGPT responses for 331
instruction tuning, and Dolly[ 8] was trained on simulated human-user interactions written by over 332
5k employees. Nevertheless, acquiring instructional data from human users typically involves high 333
costs and involves privacy concerns. As LLM capabilities improve, instruction tuning with LLM- 334
generated data exhibits better scalability and potential in addressing the super-alignment problem [ 27]. 335
Leveraging the in-context learning ability of LLMs, Unnatural instructions [ 15] and Self-instruct [ 32] 336
sampled seed instructions as examples to elicit LLMs to generate new instructions. Taking advantage 337
of the rephrasing ability of LLMs, WizardLM [ 39] and WizardMath [ 20] were trained using Evol- 338
Instruct. Evol-Instruct iteratively employs ChatGPT to rewrite seed instructions into increasingly 339
complex instructions. Similar to generation from seed instructions, carefully selected seed topics 340
are used for generating textbook-like synthetic data [ 18] or self-chat multi-turn dialogues [ 38,9] 341
for instruction tuning. However, models trained on these LLM-generated data only work well in 342
specific domains such as math [ 20,40], dialogue [ 38,9] or open-ended question answering [ 30,39]. 343
These methods encounter challenges in generalization [ 10], as the data diversity is restricted by seed 344
instructions or seed topics. 345
5 Conclusions 346
We propose GLAN , a general and scalable method for synthesizing instruction data. Experiments 347
show that GLAN can help large language models improve their capabilities in multiple dimensions, 348
from mathematical reasoning, coding, academic exams, and logical reasoning to general instruction 349
following. Currently, our synthetic data are based on the taxonomy of human knowledge and 350
capabilities, and there are other types of useful data that have not been covered. We are interested in 351
designing methods with border coverage. Our current instruction data are mostly question-answer 352
pairs, and in the next step, we plan to generate synthetic data of multi-turn conversations and long 353
documents. 354
9References 355
[1]J. Austin, A. Odena, M. Nye, M. Bosma, H. Michalewski, D. Dohan, E. Jiang, C. Cai, M. Terry, 356
Q. Le, et al. Program synthesis with large language models. arXiv preprint arXiv:2108.07732 , 357
2021. 358
[2]T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, 359
G. Sastry, A. Askell, et al. Language models are few-shot learners. Advances in neural 360
information processing systems , 2020. 361
[3]S. Chaudhary. Code alpaca: An instruction-following llama model for code generation. https: 362
//github.com/sahil280114/codealpaca , 2023. 363
[4]M. Chen, J. Tworek, H. Jun, Q. Yuan, H. P. d. O. Pinto, J. Kaplan, H. Edwards, Y . Burda, 364
N. Joseph, G. Brockman, et al. Evaluating large language models trained on code. arXiv 365
preprint arXiv:2107.03374 , 2021. 366
[5]W.-L. Chiang, Z. Li, Z. Lin, Y . Sheng, Z. Wu, H. Zhang, L. Zheng, S. Zhuang, Y . Zhuang, J. E. 367
Gonzalez, I. Stoica, and E. P. Xing. Vicuna: An open-source chatbot impressing gpt-4 with 368
90%* chatgpt quality, March 2023. 369
[6]P. Clark, I. Cowhey, O. Etzioni, T. Khot, A. Sabharwal, C. Schoenick, and O. Tafjord. Think 370
you have solved question answering? try arc, the ai2 reasoning challenge. arXiv preprint 371
arXiv:1803.05457 , 2018. 372
[7]K. Cobbe, V . Kosaraju, M. Bavarian, M. Chen, H. Jun, L. Kaiser, M. Plappert, J. Tworek, 373
J. Hilton, R. Nakano, C. Hesse, and J. Schulman. Training verifiers to solve math word 374
problems. arXiv preprint arXiv:2110.14168 , 2021. 375
[8]M. Conover, M. Hayes, A. Mathur, J. Xie, J. Wan, S. Shah, A. Ghodsi, P. Wendell, M. Zaharia, 376
and R. Xin. Free dolly: Introducing the world’s first truly open instruction-tuned llm, 2023. 377
[9]N. Ding, Y . Chen, B. Xu, Y . Qin, Z. Zheng, S. Hu, Z. Liu, M. Sun, and B. Zhou. Enhancing 378
chat language models by scaling high-quality instructional conversations. arXiv preprint 379
arXiv:2305.14233 , 2023. 380
[10] A. Gudibande, E. Wallace, C. V . Snell, X. Geng, H. Liu, P. Abbeel, S. Levine, and D. Song. 381
The false promise of imitating proprietary language models. In International Conference on 382
Learning Representations , 2024. 383
[11] D. Hendrycks, C. Burns, S. Basart, A. Zou, M. Mazeika, D. Song, and J. Steinhardt. Mea- 384
suring massive multitask language understanding. In International Conference on Learning 385
Representations , 2021. 386
[12] D. Hendrycks, C. Burns, S. Kadavath, A. Arora, S. Basart, E. Tang, D. Song, and J. Steinhardt. 387
Measuring mathematical problem solving with the math dataset. In Advances in Neural 388
Information Processing Systems , 2021. 389
[13] J. Hoffmann, S. Borgeaud, A. Mensch, E. Buchatskaya, T. Cai, E. Rutherford, D. de Las Casas, 390
L. A. Hendricks, J. Welbl, A. Clark, T. Hennigan, E. Noland, K. Millican, G. van den Driessche, 391
B. Damoc, A. Guy, S. Osindero, K. Simonyan, E. Elsen, O. Vinyals, J. Rae, and L. Sifre. Training 392
compute-optimal large language models. In Advances in Neural Information Processing Systems , 393
2022. 394
[14] A. Holtzman, J. Buys, L. Du, M. Forbes, and Y . Choi. The curious case of neural text 395
degeneration. In International Conference on Learning Representations , 2020. 396
[15] O. Honovich, T. Scialom, O. Levy, and T. Schick. Unnatural instructions: Tuning language 397
models with (almost) no human labor. In Proceedings of the 61st Annual Meeting of the 398
Association for Computational Linguistics (Volume 1: Long Papers) , 2023. 399
[16] A. Q. Jiang, A. Sablayrolles, A. Mensch, C. Bamford, D. S. Chaplot, D. d. l. Casas, F. Bressand, 400
G. Lengyel, G. Lample, L. Saulnier, et al. Mistral 7b. arXiv preprint arXiv:2310.06825 , 2023. 401
10[17] J. Kaplan, S. McCandlish, T. Henighan, T. B. Brown, B. Chess, R. Child, S. Gray, A. Rad- 402
ford, J. Wu, and D. Amodei. Scaling laws for neural language models. arXiv preprint 403
arXiv:2001.08361 , 2020. 404
[18] Y . Li, S. Bubeck, R. Eldan, A. Del Giorno, S. Gunasekar, and Y . T. Lee. Textbooks are all you 405
need ii: phi-1.5 technical report. arXiv preprint arXiv:2309.05463 , 2023. 406
[19] S. Longpre, L. Hou, T. Vu, A. Webson, H. W. Chung, Y . Tay, D. Zhou, Q. V . Le, B. Zoph, J. Wei, 407
and A. Roberts. The flan collection: Designing data and methods for effective instruction tuning. 408
InInternational Conference on Machine Learning , 2023. 409
[20] H. Luo, Q. Sun, C. Xu, P. Zhao, J. Lou, C. Tao, X. Geng, Q. Lin, S. Chen, and D. Zhang. 410
Wizardmath: Empowering mathematical reasoning for large language models via reinforced 411
evol-instruct. arXiv preprint arXiv:2308.09583 , 2023. 412
[21] Z. Luo, C. Xu, P. Zhao, Q. Sun, X. Geng, W. Hu, C. Tao, J. Ma, Q. Lin, and D. Jiang. 413
Wizardcoder: Empowering code large language models with evol-instruct. arXiv preprint 414
arXiv:2306.08568 , 2023. 415
[22] A. Mitra, L. Del Corro, S. Mahajan, A. Codas, C. Simoes, S. Agarwal, X. Chen, A. Razdaibied- 416
ina, E. Jones, K. Aggarwal, et al. Orca 2: Teaching small language models how to reason. arXiv 417
preprint arXiv:2311.11045 , 2023. 418
[23] N. Muennighoff, T. Wang, L. Sutawika, A. Roberts, S. Biderman, T. Le Scao, M. S. Bari, 419
S. Shen, Z. X. Yong, H. Schoelkopf, X. Tang, D. Radev, A. F. Aji, K. Almubarak, S. Albanie, 420
Z. Alyafeai, A. Webson, E. Raff, and C. Raffel. Crosslingual generalization through multitask 421
finetuning. In Proceedings of the 61st Annual Meeting of the Association for Computational 422
Linguistics (Volume 1: Long Papers) , 2023. 423
[24] S. Mukherjee, A. Mitra, G. Jawahar, S. Agarwal, H. Palangi, and A. Awadallah. Orca: Pro- 424
gressive learning from complex explanation traces of gpt-4. arXiv preprint arXiv:2306.02707 , 425
2023. 426
[25] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. Wainwright, P. Mishkin, C. Zhang, S. Agarwal, 427
K. Slama, A. Ray, et al. Training language models to follow instructions with human feedback. 428
InAdvances in Neural Information Processing Systems , 2022. 429
[26] V . Sanh, A. Webson, C. Raffel, S. H. Bach, L. Sutawika, Z. Alyafeai, A. Chaffin, A. Stiegler, 430
A. Raja, M. Dey, M. S. Bari, C. Xu, U. Thakker, S. S. Sharma, E. Szczechla, T. Kim, G. Chh- 431
ablani, N. V . Nayak, D. Datta, J. Chang, M. T. Jiang, H. Wang, M. Manica, S. Shen, Z. X. 432
Yong, H. Pandey, R. Bawden, T. Wang, T. Neeraj, J. Rozen, A. Sharma, A. Santilli, T. Févry, 433
J. A. Fries, R. Teehan, T. L. Scao, S. Biderman, L. Gao, T. Wolf, and A. M. Rush. Multi- 434
task prompted training enables zero-shot task generalization. In International Conference on 435
Learning Representations , 2022. 436
[27] T. Shen, R. Jin, Y . Huang, C. Liu, W. Dong, Z. Guo, X. Wu, Y . Liu, and D. Xiong. Large 437
language model alignment: A survey. arXiv preprint arXiv:2309.15025 , 2023. 438
[28] A. Srivastava, A. Rastogi, A. Rao, A. A. M. Shoeb, A. Abid, A. Fisch, A. R. Brown, A. Santoro, 439
A. Gupta, A. Garriga-Alonso, A. Kluska, A. Lewkowycz, A. Agarwal, A. Power, A. Ray, 440
A. Warstadt, A. W. Kocurek, A. Safaya, A. Tazarv, A. Xiang, A. Parrish, A. Nie, A. Hussain, 441
A. Askell, A. Dsouza, et al. Beyond the imitation game: Quantifying and extrapolating the 442
capabilities of language models. Transactions on Machine Learning Research , 2023. 443
[29] M. Suzgun, N. Scales, N. Schärli, S. Gehrmann, Y . Tay, H. W. Chung, A. Chowdhery, Q. Le, 444
E. Chi, D. Zhou, and J. Wei. Challenging BIG-bench tasks and whether chain-of-thought can 445
solve them. In Findings of the Association for Computational Linguistics: ACL 2023 , 2023. 446
[30] R. Taori, I. Gulrajani, T. Zhang, Y . Dubois, X. Li, C. Guestrin, P. Liang, and T. B. Hashimoto. 447
Stanford alpaca: An instruction-following llama model. https://github.com/tatsu-lab/ 448
stanford_alpaca , 2023. 449
11[31] H. Touvron, L. Martin, K. Stone, P. Albert, A. Almahairi, Y . Babaei, N. Bashlykov, S. Batra, 450
P. Bhargava, S. Bhosale, et al. Llama 2: Open foundation and fine-tuned chat models. arXiv 451
preprint arXiv:2307.09288 , 2023. 452
[32] Y . Wang, Y . Kordi, S. Mishra, A. Liu, N. A. Smith, D. Khashabi, and H. Hajishirzi. Self-instruct: 453
Aligning language models with self-generated instructions. In Proceedings of the 61st Annual 454
Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) . Association 455
for Computational Linguistics, 2023. 456
[33] Y . Wang, S. Mishra, P. Alipoormolabashi, Y . Kordi, A. Mirzaei, A. Naik, A. Ashok, A. S. 457
Dhanasekaran, A. Arunkumar, D. Stap, E. Pathak, G. Karamanolakis, H. Lai, I. Purohit, I. Mon- 458
dal, J. Anderson, K. Kuznia, K. Doshi, K. K. Pal, M. Patel, M. Moradshahi, M. Parmar, 459
M. Purohit, N. Varshney, P. R. Kaza, P. Verma, R. S. Puri, R. Karia, S. Doshi, S. K. Sampat, 460
S. Mishra, S. Reddy A, S. Patro, T. Dixit, and X. Shen. Super-NaturalInstructions: Generaliza- 461
tion via declarative instructions on 1600+ NLP tasks. In Proceedings of the 2022 Conference 462
on Empirical Methods in Natural Language Processing , 2022. 463
[34] J. Wei, M. Bosma, V . Zhao, K. Guu, A. W. Yu, B. Lester, N. Du, A. M. Dai, and Q. V . Le. 464
Finetuned language models are zero-shot learners. In International Conference on Learning 465
Representations , 2022. 466
[35] J. Wei, X. Wang, D. Schuurmans, M. Bosma, F. Xia, E. Chi, Q. V . Le, D. Zhou, et al. Chain- 467
of-thought prompting elicits reasoning in large language models. In Advances in Neural 468
Information Processing Systems , 2022. 469
[36] T. Wei, L. Zhao, L. Zhang, B. Zhu, L. Wang, H. Yang, B. Li, C. Cheng, W. Lü, R. Hu, C. Li, 470
L. Yang, X. Luo, X. Wu, L. Liu, W. Cheng, P. Cheng, J. Zhang, X. Zhang, L. Lin, X. Wang, 471
Y . Ma, C. Dong, Y . Sun, Y . Chen, Y . Peng, X. Liang, S. Yan, H. Fang, and Y . Zhou. Skywork: 472
A more open bilingual foundation model, 2023. 473
[37] Wikipedia contributors. Education, 2023. Last edited on 24 March 2023. 474
[38] C. Xu, D. Guo, N. Duan, and J. McAuley. Baize: An open-source chat model with parameter- 475
efficient tuning on self-chat data. In Proceedings of the 2023 Conference on Empirical Methods 476
in Natural Language Processing , 2023. 477
[39] C. Xu, Q. Sun, K. Zheng, X. Geng, P. Zhao, J. Feng, C. Tao, and D. Jiang. Wizardlm: Empow- 478
ering large language models to follow complex instructions. arXiv preprint arXiv:2304.12244 , 479
2023. 480
[40] L. Yu, W. Jiang, H. Shi, J. YU, Z. Liu, Y . Zhang, J. Kwok, Z. Li, A. Weller, and W. Liu. Meta- 481
math: Bootstrap your own mathematical questions for large language models. In International 482
Conference on Learning Representations , 2024. 483
[41] C. Zhou, P. Liu, P. Xu, S. Iyer, J. Sun, Y . Mao, X. Ma, A. Efrat, P. Yu, L. YU, S. Zhang, 484
G. Ghosh, M. Lewis, L. Zettlemoyer, and O. Levy. LIMA: Less is more for alignment. In 485
Advances in Neural Information Processing Systems , 2023. 486
[42] J. Zhou, T. Lu, S. Mishra, S. Brahma, S. Basu, Y . Luan, D. Zhou, and L. Hou. Instruction- 487
following evaluation for large language models. arXiv preprint arXiv:2311.07911 , 2023. 488
12A Appendix 489
A.1 Limitations 490
While GLAN presents significant advancements in academic benchmarks. However, there may 491
still have several limitations in real world deployment. The resulting LLMs train on generated data 492
using GLAN may occasionally produce factual incorrect (or even toxic) responses. Further training 493
for refusal, hallucination reduction as well as toxic content reduction should be performed before 494
deployment. 495
A.2 Broader Impacts 496
Data synthesizing is crucial for the continual scaling of large language models, especially as we 497
exhaust available human data. GLAN demonstrates the potential to generate vast amounts of synthetic 498
data from scratch, paving the way for even larger-scale data synthesis efforts. While GLAN has 499
shown the effectiveness of synthetic data, we must point out that synthetic data may inherit and even 500
amplify social biases present in the frontier LLMs for generation. Future research should focus on 501
developing techniques to identify and correct biases in the generated datasets and models trained on 502
them. 503
A.3 Prompt for Syllabus Generator 504
The prompt template for syllabus generation is in Table 6. 505
Table 6: Prompt template for Syllabus Generator.
You are an expert in { s.name }.
Using the given data, design a syllabus for teaching students at the specified level.
Note that example subtopics or descriptions are just give you an impression of what this class like.
Feel free to add extra subtopics if needed (remember you are the expert in { s.name }).
Data:
- Level: { s.level }
- Main Topic: { s.name }
- Description or Example Subtopics: { s.subtopics }
### Syllabus Design Guide
1. **Introduction**: Start with an overview of the primary topic for the syllabus.
2. **Class Details**: For each class session, provide:
- **Description**: Briefly describe the focus of the session.
- **Knowledge Points**: Enumerate key concepts or topics.
These will be used to craft homework questions.
- **Learning Outcomes & Activities**: Offer expected learning results and suggest related
exercises or activities.
A.4 Prompt for Instruction Generator 506
The prompt template for instruction generator is in Table 7. 507
A.5 Task-specific Training Data 508
We provide the specific train/test values of different models on different benchmarks in Table 8. 509
A.6 Evol-Instruct Test Results on Different Difficulty Levels 510
The concrete Evol-Instruct test results on different difficulty levels are shown in Table 9. 511
13Table 7: Prompt template for Instruction Generator.
## Background
- You are an expert in { s.name } education and you have designed a syllabus (i.e., ‘## Syllabus‘)
- We invite you (again) to design ONE homework question for given class sessions and some
knowledge points.
- The student have already learned all class sessions up to the current sessions
(i.e., ‘## Current Session(s)‘).
- There might be multiple class session in ‘## Current Session(s)‘
- The designed homework question should focus on the topics in ‘## Current Session(s)‘ and you should
try to cover the given knowledge points in ‘## Given Knowledge Points‘
- We prefer homework questions leveraging multiple knowledge points and across different topics
## Syllabus
{A}
## Current Session(s)
{ˆC}
## Given Knowledge Points
{ˆK}
Table 8: The evaluation of loss values between the test data and training data. Large positive ∆(or
∆(%) ) indicate task specific in-domain training data may be exposed to the model during training.
Benchmark/Loss LLaMA2-7B Orca2-7B Mistral-7B-Instruct WizardLM-13B-V1.2 GLAN-7B
Ltest 2.02 2.39 2.32 2.11 4.03
ARC-C Ltrain 2.03 2.34 2.33 2.12 4.06
∆ -0.01 0.05 -0.01 -0.01 -0.03
∆(%) -0.5% 2.10% -0.43% -0.47% -0.74%
Ltest 2.10 2.47 2.51 2.18 4.31
ARC-E Ltrain 2.12 2.43 2.54 2.20 4.32
∆ -0.02 0.04 -0.03 -0.02 -0.01
∆(%) -0.95% 1.61% -1.19% -0.91% -0.23%
Ltest 1.38 1.14 1.26 1.14 2.17
GSM8K Ltrain 1.38 1.01 1.26 1.09 2.15
∆ 0 0.13 0 0.05 0.02
∆(%) 0% 11.4% 0% 4.39% 0.92%
Ltest 1.11 1.18 1.12 1.22 1.67
MATH Ltrain 1.14 1.15 1.15 1.24 1.70
∆ -0.03 0.03 -0.03 -0.02 -0.03
∆(%) -2.70% 2.54% -2.67% -1.63% -1.79%
A.7 Evol-Instruct Test Results on Different Skills 512
The concrete Evol-Instruct test results on different skills are shown in Table 10. 513
A.8 GLAN-Test Overall Results 514
GLAN -Test There are only hundreds of instructions in In IFEval and Evol-Instruct Test and 515
we believe the domains or skills they can cover are rather limited. Therefore, we propose a held- 516
out test set using GLAN data and we call it GLAN -Test. It contains 6,300 instructions on 126 517
disciplines (50 instructions for each discipline). We further categorize the 126 disciplines to 8 518
distinct fields (i.e., Academic-Humanities, Academic-Social Science, Academic-Natural Science, 519
Academic-Applied Science, Academic-Formal Science, Industry-Manufacturing, Industry-Services 520
and Industry-Agriculture). We believe that the extensive domain coverage of GLAN -Test renders 521
it an effective test bed for the assessment of generalization capabilities in LLMs. We adopt the 522
same GPT-4 based evaluation protocol as in Evol-Instruct Test (previous paragraph). We prompt 523
GPT-4 to do a pairwise ranking of GLAN and other models in comparison. The overall results and 524
results across the 8 fields are presented in Table 11, where GLAN obtains higher GPT-4 scores than 525
Orca2-7B, Mistral-7B Instruct and WizardLM-13B, despite using only 7B parameters. GLAN still 526
14Table 9: Pairwise comparison on various difficulty levels between GLAN and other models on
Evol-Instruct testset. The scores are the average gap of scores assigned by GPT-4, calculated as
avg_score( GLAN)−avg_score (x).
Difficulty Ratio LLaMA2-7B Orca2-7B Mistral-7B-Instruct Wizard-13B-V1.2 GPT-3.5-turbo
1 5.1% 5.41 2.23 -0.37 -0.21 -2.41
2 8.7% 5.87 1.74 1.06 1.41 -1.18
3 12.4% 5.72 2.35 1.04 1.37 -1.14
4 10.5% 5.61 1.34 1.52 1.54 -0.92
5 4.1% 4.67 3.31 2.39 2.5 -0.45
6 19.3% 4.43 2.42 0.74 1.54 -1.36
7 11.0% 4.97 1.26 1.62 1.36 -0.41
8 17.9% 6.02 3.58 3.17 1.7 0.15
9 6.0% 6.35 4.2 1.36 0.9 -0.92
10 5.1% 5.14 -0.05 1.53 -0.54 -0.85
(1-5) Easy 41.00% 5.46 2.19 1.13 1.32 -1.22
(6-10) Hard 59.00% 5.38 2.28 1.68 0.99 -0.68
Table 10: Pairwise comparison on various skills between GLAN and other models on Evol-
Instruct testset. The scores are the average gap of scores assigned by GPT-4, calculated as
avg_score( GLAN)−avg_score (x).
Skill Ratio LLaMA2-7B Orca2-7B Mistral-7B-Instruct Wizard-13B-V1.2 GPT-3.5-turbo
Math 8.7% 6.58 2.16 2.41 2.46 -1.42
Code Generation 8.3% 6.16 3.87 4.22 2.59 -0.25
Writting 8.3% 5.2 0.79 -0.22 0.24 -1.1
Computer Science 6.9% 7.1 4.4 0.83 1.22 0.02
Reasoning 6.0% 6.3 2.52 3.38 3.02 0.62
Complex Format 5.5% 3.13 3.5 -0.17 2.41 -1.96
Code Debug 4.6% 5.85 2.3 1.4 0.2 -2.5
Common-Sense 4.1% 6.5 3.19 -1.33 -0.92 -2.78
Counterfactual 3.7% 7.06 2.15 3 1.5 0.72
Multilingual 3.2% 7.35 0.79 1.71 -0.68 -2.75
Roleplay 2.8% 7.08 2.25 3.5 0.92 -0.59
Biology 2.8% 6.66 2.75 1.46 -0.09 1.38
Technology 2.8% -0.08 2.54 -3 -1.5 -2.75
Ethics 2.8% 6.59 3.38 2.41 5.42 -0.21
TruthfulQA 2.3% 3.1 3.7 -1.05 -1.3 -0.85
Sport 2.3% 4.3 0.55 -0.2 4.8 -0.3
Law 2.3% 7.7 4.65 5.85 1.7 0.2
Medicine 2.3% 3.9 -2.05 1.9 0.15 -1.25
Literature 2.3% 6.3 1.9 0.2 1.45 -0.15
Entertainment 2.3% 4.5 2.7 -3 1.9 -3.2
Art 2.3% 4.9 1 2.9 -0.85 -2.05
Music 2.3% 4.4 4.1 0.5 1.45 -2.3
Toxicity 1.8% 7.25 3.12 3.75 1.63 -1.32
Economy 2.3% 6 0.15 1.9 0 0
Physics 2.3% 6.8 2.5 4.35 3.65 -1
History 1.8% 4.12 -0.56 3.76 -0.31 0.12
Academic Writing 1.8% 6.76 6.37 2.44 1.37 0.62
Chemistry 0.9% 9.5 0.63 5.25 2.5 0.75
Philosophy 0.5% 11 -0.25 0.25 -0.25 0.5
Avg.(29 skills) 100% 5.42 2.24 1.41 1.16 -0.95
lag behind GPT-4 . Detailed results for the 126 fine-grained disciplines can be found in Appendix 527
A.9 (see Table 12 for more details). GLAN demonstrates its effectiveness on multiple domains (or 528
disciplines) such as Mathematics, Physics, Chemistry, Computer science, Electrical, Mechanical, etc., 529
indicating that smaller models may yield general improvements on various domains through strategic 530
fine-tuning. Furthermore, it is noted that GLAN demonstrates less-than-ideal performance across 531
distinct disciplines such as American history, Divinity, or Radiology. This observation underscores 532
the potential for further refinement and development of our methodology within these domains. 533
A.9 GLAN-Test Results on Different Disciplines 534
15Table 11: Pairwise comparison between GLAN and other models on GLAN -Test (the 126 disciplines
are categorized into 8 fields for clarity of the illustration). The scores are the average gap of scores
assigned by GPT-4, calculated as avg_score( GLAN)−avg_score (x).
Field (Ratio) Orca2-7B Mistral-7B-Instruct WizardLM-13B-V1.2 GPT-4
Academic-Humanities (15.9%) 0.79 0.25 0.02 -0.62
Academic-Social Science (7.9%) 1.22 0.21 0.09 -0.63
Academic-Natural Science (4.0%) 1.73 1.23 0.53 -0.5
Academic-Applied Science (42.1%) 1.58 0.32 0.08 -0.58
Academic-Formal Science (3.2%) 3.87 2.48 2.32 -0.55
Industry-Manufacturing (12.7%) 2.26 0.56 0.33 -0.43
Industry-Services (11.9%) 1.82 0.23 0.09 -0.5
Industry-Agriculture (2.4%) 1.2 0.46 0.13 -0.33
Overall (100.0%) 1.61 0.43 0.19 -0.55
16Table 12: Pairwise comparison across 126 disciplines (or domains) on GLAN-Test . The scores are
generated from the average gap between GLAN and other model xin assessment scores assigned by
GPT-4, calculated as avg_score( GLAN)−avg_score (x).
Discipline Orca-2-7b Mistral-7B-Instruct-v0.1 WizardLM-13B-V1.2 GPT-4
Avg. 1.61 0.43 0.19 -0.55
Advertising 1.92 0.46 0.21 -0.04
Aerospace industry 3.24 1.24 0.6 -0.42
Agriculture 2.44 0.04 -0.05 -0.48
American history -0.49 -0.27 -0.76 -0.83
American politics 1.23 -0.3 -0.4 -0.87
Anthropology 0.59 0.17 0.06 -0.27
Applied mathematics 3.75 2.6 2.74 -0.47
Archaeology 2.59 -0.11 0.1 -0.56
Architecture and design 2.63 0.34 0.4 -0.37
Astronomy 1.01 0.83 0.03 -0.44
Automotive industry 1.27 0.71 0.46 -0.06
Biblical studies -0.05 0.33 -0.47 -0.65
Biology 1.09 0.22 -0.09 -0.17
Business 3.61 1.14 0.88 -0.26
Chemical Engineering 3.15 1.6 1.18 -0.77
Chemistry 3.06 2.09 0.8 -0.87
Civil Engineering 1.94 0.74 0.75 -0.25
Clinical laboratory sciences 1.32 0.94 -0.11 -0.47
Clinical neuropsychology 2.15 0.29 0.25 -0.4
Clinical physiology 2.07 0.41 0.51 -0.08
Communication studies 0.3 0.26 -0.15 -0.3
Computer science 4.29 1.45 1.9 -0.33
Cultural industry 3.15 0.44 0.05 -0.36
Dance 2.11 0.21 0.4 -0.47
Dentistry 1.67 0.66 0.48 0.01
Dermatology 2.12 0.55 -0.05 -0.65
Divinity -0.34 -0.17 -0.48 -0.89
Earth science 0.39 0.44 -0.08 -0.33
Economics 2.62 0.96 0.62 -0.4
Education 2.67 0.42 0.2 -0.84
Education industry 2.19 0.4 0.56 -1.33
Electric power industry 3.23 1.31 0.39 -0.79
Electrical Engineering 3.81 1.26 1.41 -0.34
Emergency medicine 2.04 0.44 -0.18 -0.86
Energy industry 3.59 0.98 0.54 -0.22
Environmental studies and forestry 0.12 0.41 0.1 -0.45
Epidemiology 3.02 0.52 0.33 -0.46
European history 0.14 0.62 0.15 -0.18
Fashion 2.5 0.66 0.47 -0.53
Film 0.76 0.45 -0.16 -0.78
Film industry 1.58 0.46 0.25 -0.59
Fishing industry 1.67 1 0.57 -0.09
Floral 1.92 0.89 0.58 -0.09
Food industry 3.64 0.12 0.14 -0.42
Foreign policy 2.4 0.49 0.16 -0.46
Geography 0.88 0.6 0.28 -0.66
Geriatrics 2.19 -0.32 -0.56 -0.71
Gynaecology 1.05 -0.27 -0.26 -0.67
Healthcare industry 1.62 -0.25 0.14 -0.5
Hematology 0.35 0.32 -0.05 -0.72
History 0.75 0.54 -0.04 -0.38
Holistic medicine 0.85 0.48 0.26 -0.27
Hospitality industry 2.36 0.48 0.28 -0.07
Housing 4.04 0.15 -0.22 -0.62
Industrial robot industry 3.84 1.22 0.84 -0.71
Infectious disease 1.76 0.14 0.18 -0.56
Insurance industry 2.67 0.42 0.61 -0.4
Intensive care medicine 1.11 0.56 0.08 -0.33
Internal medicine 1.02 0.45 -0.01 -0.42
Journalism 2.77 -0.13 -0.21 -0.69
Languages and literature 0.45 0.05 -0.39 -0.84
Law 0.42 0.39 0.04 -0.49
Leisure industry 1.49 0.12 -0.09 -0.49
Library and museum studies 1.52 0.5 0.33 -0.3217Discipline Orca-2-7b Mistral-7B-Instruct-v0.1 WizardLM-13B-V1.2 GPT-4
Linguistics 0.39 0.38 -0.12 -0.96
Logic 2.95 1.56 1.62 -0.79
Materials Science and Engineering 1.71 0.97 0.54 -0.91
Mathematics 4.69 3.81 2.73 -0.61
Mechanical Engineering 2.25 1.71 1.15 -0.95
Medical toxicology 0.62 0 0.11 -1.01
Medicine 1.49 0.93 0.36 -0.37
Military sciences 0.42 0.53 0.17 -0.45
Mining 3.17 0.32 0.41 -0.61
Music 2.85 0.38 1.07 -0.05
Music industry 2.05 -0.03 -0.08 -0.8
Nursing 1.49 0.14 -0.12 -0.59
Nutrition 1.15 -0.2 -0.13 -0.65
Obstetrics 1.49 0.08 -0.43 -0.53
Ophthalmology 0.97 0.01 -0.47 -0.97
Otolaryngology 1.51 -0.44 -0.29 -1.11
Pathology 0.23 0.35 0.19 -0.72
Pediatrics 1.62 0.55 -0.34 -0.47
Performing arts 0.38 0.09 -0.36 -1.06
Petroleum industry 3.12 0.44 0.08 -0.54
Pharmaceutical industry 2.75 0.41 0.4 -0.46
Pharmaceutical sciences 0.77 0.19 0.16 -0.8
Philosophy 0.51 0.25 0.49 -0.64
Physics 3.15 2.67 2.05 -0.73
Political science 0.04 -0.05 -0.31 -0.91
Prehistory 0.35 0.19 0.05 -0.41
Preventive medicine 2.69 0.57 0.09 -0.36
Psychiatry 2.93 0.27 -0.07 -0.32
Psychology 0.53 -0.02 -0.3 -0.96
Public administration 0.94 -0.27 0.1 -1.2
Public health 1.21 0.07 0.22 -0.56
Public policy 0.78 -0.06 -0.28 -0.92
Pulp and paper industry 1.13 0.63 0.57 -0.25
Radiology -0.17 -0.19 -0.82 -0.62
Real estate industry 1.01 0.02 -0.12 -0.5
Religious Studies 0.38 0 -0.32 -0.63
Retail industry 1.1 -0.25 -0.37 -0.6
Semiconductor industry 1.49 0.64 0.71 -0.42
Sexology 1.81 -0.44 -0.37 -0.96
Shipbuilding industry 1.54 0.37 0.42 -0.32
Social work 0.93 -0.42 -0.53 -0.77
Sociology 1.49 0.21 0.76 -0.3
Steel industry 0.88 0.45 0.09 -0.34
Surgery 0.86 -0.02 -0.35 -0.73
Systems science 1.9 0.56 0.41 -0.45
Telecommunications industry 1.81 0.4 0.39 -0.27
Television 0.37 -0.33 -0.69 -1
Textile industry 0.82 -0.26 -0.68 -0.59
Theatre 0.31 -0.27 -0.34 -1.07
Theology -0.38 0.37 -0.45 -0.54
Tobacco industry 0.59 -0.13 -0.48 -0.67
Transport industry 1.19 -0.33 -0.36 -0.56
Transportation 1.74 0.26 0.17 -0.74
Urology 0.05 -0.29 -0.36 -0.64
Veterinary medicine -0.14 0.36 -0.31 -0.62
Video game industry 1.67 0.2 -0.24 -0.62
Visual arts 0.98 0.22 0.26 -0.56
Water industry 0.9 -0.11 -0.09 -0.51
Wood industry 1.36 0.5 0.31 -0.25
18NeurIPS Paper Checklist 535
1.Claims 536
Question: Do the main claims made in the abstract and introduction accurately reflect the 537
paper’s contributions and scope? 538
Answer: [Yes] 539
Justification: See Abstract and Section 1. 540
Guidelines: 541
•The answer NA means that the abstract and introduction do not include the claims 542
made in the paper. 543
•The abstract and/or introduction should clearly state the claims made, including the 544
contributions made in the paper and important assumptions and limitations. A No or 545
NA answer to this question will not be perceived well by the reviewers. 546
•The claims made should match theoretical and experimental results, and reflect how 547
much the results can be expected to generalize to other settings. 548
•It is fine to include aspirational goals as motivation as long as it is clear that these goals 549
are not attained by the paper. 550
2.Limitations 551
Question: Does the paper discuss the limitations of the work performed by the authors? 552
Answer: [Yes] 553
Justification: See Section 5 and Appendix A.1 554
Guidelines: 555
•The answer NA means that the paper has no limitation while the answer No means that 556
the paper has limitations, but those are not discussed in the paper. 557
• The authors are encouraged to create a separate "Limitations" section in their paper. 558
•The paper should point out any strong assumptions and how robust the results are to 559
violations of these assumptions (e.g., independence assumptions, noiseless settings, 560
model well-specification, asymptotic approximations only holding locally). The authors 561
should reflect on how these assumptions might be violated in practice and what the 562
implications would be. 563
•The authors should reflect on the scope of the claims made, e.g., if the approach was 564
only tested on a few datasets or with a few runs. In general, empirical results often 565
depend on implicit assumptions, which should be articulated. 566
•The authors should reflect on the factors that influence the performance of the approach. 567
For example, a facial recognition algorithm may perform poorly when image resolution 568
is low or images are taken in low lighting. Or a speech-to-text system might not be 569
used reliably to provide closed captions for online lectures because it fails to handle 570
technical jargon. 571
•The authors should discuss the computational efficiency of the proposed algorithms 572
and how they scale with dataset size. 573
•If applicable, the authors should discuss possible limitations of their approach to 574
address problems of privacy and fairness. 575
•While the authors might fear that complete honesty about limitations might be used by 576
reviewers as grounds for rejection, a worse outcome might be that reviewers discover 577
limitations that aren’t acknowledged in the paper. The authors should use their best 578
judgment and recognize that individual actions in favor of transparency play an impor- 579
tant role in developing norms that preserve the integrity of the community. Reviewers 580
will be specifically instructed to not penalize honesty concerning limitations. 581
3.Theory Assumptions and Proofs 582
Question: For each theoretical result, does the paper provide the full set of assumptions and 583
a complete (and correct) proof? 584
Answer: [NA] 585
19Justification: No theoretical results. 586
Guidelines: 587
• The answer NA means that the paper does not include theoretical results. 588
•All the theorems, formulas, and proofs in the paper should be numbered and cross- 589
referenced. 590
•All assumptions should be clearly stated or referenced in the statement of any theorems. 591
•The proofs can either appear in the main paper or the supplemental material, but if 592
they appear in the supplemental material, the authors are encouraged to provide a short 593
proof sketch to provide intuition. 594
•Inversely, any informal proof provided in the core of the paper should be complemented 595
by formal proofs provided in appendix or supplemental material. 596
• Theorems and Lemmas that the proof relies upon should be properly referenced. 597
4.Experimental Result Reproducibility 598
Question: Does the paper fully disclose all the information needed to reproduce the main ex- 599
perimental results of the paper to the extent that it affects the main claims and/or conclusions 600
of the paper (regardless of whether the code and data are provided or not)? 601
Answer: [Yes] 602
Justification: In Section 2 and 3.1, we provide a detailed description of the data generation 603
process. Although we haven’t shared the original prompts yet, they are quite simple and 604
customizable. Besides, we are actively working to gain authorization to release them as 605
soon as possible. 606
Guidelines: 607
• The answer NA means that the paper does not include experiments. 608
•If the paper includes experiments, a No answer to this question will not be perceived 609
well by the reviewers: Making the paper reproducible is important, regardless of 610
whether the code and data are provided or not. 611
•If the contribution is a dataset and/or model, the authors should describe the steps taken 612
to make their results reproducible or verifiable. 613
•Depending on the contribution, reproducibility can be accomplished in various ways. 614
For example, if the contribution is a novel architecture, describing the architecture fully 615
might suffice, or if the contribution is a specific model and empirical evaluation, it may 616
be necessary to either make it possible for others to replicate the model with the same 617
dataset, or provide access to the model. In general. releasing code and data is often 618
one good way to accomplish this, but reproducibility can also be provided via detailed 619
instructions for how to replicate the results, access to a hosted model (e.g., in the case 620
of a large language model), releasing of a model checkpoint, or other means that are 621
appropriate to the research performed. 622
•While NeurIPS does not require releasing code, the conference does require all submis- 623
sions to provide some reasonable avenue for reproducibility, which may depend on the 624
nature of the contribution. For example 625
(a)If the contribution is primarily a new algorithm, the paper should make it clear how 626
to reproduce that algorithm. 627
(b)If the contribution is primarily a new model architecture, the paper should describe 628
the architecture clearly and fully. 629
(c)If the contribution is a new model (e.g., a large language model), then there should 630
either be a way to access this model for reproducing the results or a way to reproduce 631
the model (e.g., with an open-source dataset or instructions for how to construct 632
the dataset). 633
(d)We recognize that reproducibility may be tricky in some cases, in which case 634
authors are welcome to describe the particular way they provide for reproducibility. 635
In the case of closed-source models, it may be that access to the model is limited in 636
some way (e.g., to registered users), but it should be possible for other researchers 637
to have some path to reproducing or verifying the results. 638
5.Open access to data and code 639
20Question: Does the paper provide open access to the data and code, with sufficient instruc- 640
tions to faithfully reproduce the main experimental results, as described in supplemental 641
material? 642
Answer: [No] 643
Justification: While we are temporarily unable to provide open access to the data and code, 644
we are actively working to gain the necessary authorization to release these resources. Once 645
obtained, we will ensure that all data and code, along with detailed instructions, are made 646
available to faithfully reproduce the main experimental results. 647
Guidelines: 648
• The answer NA means that paper does not include experiments requiring code. 649
•Please see the NeurIPS code and data submission guidelines ( https://nips.cc/ 650
public/guides/CodeSubmissionPolicy ) for more details. 651
•While we encourage the release of code and data, we understand that this might not be 652
possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not 653
including code, unless this is central to the contribution (e.g., for a new open-source 654
benchmark). 655
•The instructions should contain the exact command and environment needed to run to 656
reproduce the results. See the NeurIPS code and data submission guidelines ( https: 657
//nips.cc/public/guides/CodeSubmissionPolicy ) for more details. 658
•The authors should provide instructions on data access and preparation, including how 659
to access the raw data, preprocessed data, intermediate data, and generated data, etc. 660
•The authors should provide scripts to reproduce all experimental results for the new 661
proposed method and baselines. If only a subset of experiments are reproducible, they 662
should state which ones are omitted from the script and why. 663
•At submission time, to preserve anonymity, the authors should release anonymized 664
versions (if applicable). 665
•Providing as much information as possible in supplemental material (appended to the 666
paper) is recommended, but including URLs to data and code is permitted. 667
6.Experimental Setting/Details 668
Question: Does the paper specify all the training and test details (e.g., data splits, hyper- 669
parameters, how they were chosen, type of optimizer, etc.) necessary to understand the 670
results? 671
Answer: [Yes] 672
Justification: See Section 3.2, 3.3 673
Guidelines: 674
• The answer NA means that the paper does not include experiments. 675
•The experimental setting should be presented in the core of the paper to a level of detail 676
that is necessary to appreciate the results and make sense of them. 677
•The full details can be provided either with the code, in appendix, or as supplemental 678
material. 679
7.Experiment Statistical Significance 680
Question: Does the paper report error bars suitably and correctly defined or other appropriate 681
information about the statistical significance of the experiments? 682
Answer: [No] 683
Justification: We did not include error bars in the experiments due to the high computational 684
demands. 685
Guidelines: 686
• The answer NA means that the paper does not include experiments. 687
•The authors should answer "Yes" if the results are accompanied by error bars, confi- 688
dence intervals, or statistical significance tests, at least for the experiments that support 689
the main claims of the paper. 690
21•The factors of variability that the error bars are capturing should be clearly stated (for 691
example, train/test split, initialization, random drawing of some parameter, or overall 692
run with given experimental conditions). 693
•The method for calculating the error bars should be explained (closed form formula, 694
call to a library function, bootstrap, etc.) 695
• The assumptions made should be given (e.g., Normally distributed errors). 696
•It should be clear whether the error bar is the standard deviation or the standard error 697
of the mean. 698
•It is OK to report 1-sigma error bars, but one should state it. The authors should 699
preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis 700
of Normality of errors is not verified. 701
•For asymmetric distributions, the authors should be careful not to show in tables or 702
figures symmetric error bars that would yield results that are out of range (e.g. negative 703
error rates). 704
•If error bars are reported in tables or plots, The authors should explain in the text how 705
they were calculated and reference the corresponding figures or tables in the text. 706
8.Experiments Compute Resources 707
Question: For each experiment, does the paper provide sufficient information on the com- 708
puter resources (type of compute workers, memory, time of execution) needed to reproduce 709
the experiments? 710
Answer: [Yes] 711
Justification: We included compute resources in Section 3.2. 712
Guidelines: 713
• The answer NA means that the paper does not include experiments. 714
•The paper should indicate the type of compute workers CPU or GPU, internal cluster, 715
or cloud provider, including relevant memory and storage. 716
•The paper should provide the amount of compute required for each of the individual 717
experimental runs as well as estimate the total compute. 718
•The paper should disclose whether the full research project required more compute 719
than the experiments reported in the paper (e.g., preliminary or failed experiments that 720
didn’t make it into the paper). 721
9.Code Of Ethics 722
Question: Does the research conducted in the paper conform, in every respect, with the 723
NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines ? 724
Answer: [Yes] 725
Justification: This study strictly adheres to the NeurIPS Code of Ethics. 726
Guidelines: 727
•The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. 728
•If the authors answer No, they should explain the special circumstances that require a 729
deviation from the Code of Ethics. 730
•The authors should make sure to preserve anonymity (e.g., if there is a special consid- 731
eration due to laws or regulations in their jurisdiction). 732
10.Broader Impacts 733
Question: Does the paper discuss both potential positive societal impacts and negative 734
societal impacts of the work performed? 735
Answer: [Yes] 736
Justification: See Appendix A.2 737
Guidelines: 738
• The answer NA means that there is no societal impact of the work performed. 739
•If the authors answer NA or No, they should explain why their work has no societal 740
impact or why the paper does not address societal impact. 741
22•Examples of negative societal impacts include potential malicious or unintended uses 742
(e.g., disinformation, generating fake profiles, surveillance), fairness considerations 743
(e.g., deployment of technologies that could make decisions that unfairly impact specific 744
groups), privacy considerations, and security considerations. 745
•The conference expects that many papers will be foundational research and not tied 746
to particular applications, let alone deployments. However, if there is a direct path to 747
any negative applications, the authors should point it out. For example, it is legitimate 748
to point out that an improvement in the quality of generative models could be used to 749
generate deepfakes for disinformation. On the other hand, it is not needed to point out 750
that a generic algorithm for optimizing neural networks could enable people to train 751
models that generate Deepfakes faster. 752
•The authors should consider possible harms that could arise when the technology is 753
being used as intended and functioning correctly, harms that could arise when the 754
technology is being used as intended but gives incorrect results, and harms following 755
from (intentional or unintentional) misuse of the technology. 756
•If there are negative societal impacts, the authors could also discuss possible mitigation 757
strategies (e.g., gated release of models, providing defenses in addition to attacks, 758
mechanisms for monitoring misuse, mechanisms to monitor how a system learns from 759
feedback over time, improving the efficiency and accessibility of ML). 760
11.Safeguards 761
Question: Does the paper describe safeguards that have been put in place for responsible 762
release of data or models that have a high risk for misuse (e.g., pretrained language models, 763
image generators, or scraped datasets)? 764
Answer: [No] 765
Justification: To ensure future responsible release, we are still in the process of implementing 766
comprehensive safeguards. 767
Guidelines: 768
• The answer NA means that the paper poses no such risks. 769
•Released models that have a high risk for misuse or dual-use should be released with 770
necessary safeguards to allow for controlled use of the model, for example by requiring 771
that users adhere to usage guidelines or restrictions to access the model or implementing 772
safety filters. 773
•Datasets that have been scraped from the Internet could pose safety risks. The authors 774
should describe how they avoided releasing unsafe images. 775
•We recognize that providing effective safeguards is challenging, and many papers do 776
not require this, but we encourage authors to take this into account and make a best 777
faith effort. 778
12.Licenses for existing assets 779
Question: Are the creators or original owners of assets (e.g., code, data, models), used in 780
the paper, properly credited and are the license and terms of use explicitly mentioned and 781
properly respected? 782
Answer: [Yes] 783
Justification: All existing assets used in this paper are properly credited. The license and 784
terms of use are properly respected. 785
Guidelines: 786
• The answer NA means that the paper does not use existing assets. 787
• The authors should cite the original paper that produced the code package or dataset. 788
•The authors should state which version of the asset is used and, if possible, include a 789
URL. 790
• The name of the license (e.g., CC-BY 4.0) should be included for each asset. 791
•For scraped data from a particular source (e.g., website), the copyright and terms of 792
service of that source should be provided. 793
23•If assets are released, the license, copyright information, and terms of use in the 794
package should be provided. For popular datasets, paperswithcode.com/datasets 795
has curated licenses for some datasets. Their licensing guide can help determine the 796
license of a dataset. 797
•For existing datasets that are re-packaged, both the original license and the license of 798
the derived asset (if it has changed) should be provided. 799
•If this information is not available online, the authors are encouraged to reach out to 800
the asset’s creators. 801
13.New Assets 802
Question: Are new assets introduced in the paper well documented and is the documentation 803
provided alongside the assets? 804
Answer: [Yes] 805
Justification: Once authorization is obtained, we will ensure that comprehensive documenta- 806
tion is provided alongside the assets to facilitate their proper use and understanding. 807
Guidelines: 808
• The answer NA means that the paper does not release new assets. 809
•Researchers should communicate the details of the dataset/code/model as part of their 810
submissions via structured templates. This includes details about training, license, 811
limitations, etc. 812
•The paper should discuss whether and how consent was obtained from people whose 813
asset is used. 814
•At submission time, remember to anonymize your assets (if applicable). You can either 815
create an anonymized URL or include an anonymized zip file. 816
14.Crowdsourcing and Research with Human Subjects 817
Question: For crowdsourcing experiments and research with human subjects, does the paper 818
include the full text of instructions given to participants and screenshots, if applicable, as 819
well as details about compensation (if any)? 820
Answer: [NA] 821
Justification: This paper does not involve crowdsourcing nor research with human subjects. 822
Guidelines: 823
•The answer NA means that the paper does not involve crowdsourcing nor research with 824
human subjects. 825
•Including this information in the supplemental material is fine, but if the main contribu- 826
tion of the paper involves human subjects, then as much detail as possible should be 827
included in the main paper. 828
•According to the NeurIPS Code of Ethics, workers involved in data collection, curation, 829
or other labor should be paid at least the minimum wage in the country of the data 830
collector. 831
15.Institutional Review Board (IRB) Approvals or Equivalent for Research with Human 832
Subjects 833
Question: Does the paper describe potential risks incurred by study participants, whether 834
such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) 835
approvals (or an equivalent approval/review based on the requirements of your country or 836
institution) were obtained? 837
Answer: [NA] 838
Justification: This paper does not involve crowdsourcing nor research with human subjects. 839
Guidelines: 840
•The answer NA means that the paper does not involve crowdsourcing nor research with 841
human subjects. 842
•Depending on the country in which research is conducted, IRB approval (or equivalent) 843
may be required for any human subjects research. If you obtained IRB approval, you 844
should clearly state this in the paper. 845
24•We recognize that the procedures for this may vary significantly between institutions 846
and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the 847
guidelines for their institution. 848
•For initial submissions, do not include any information that would break anonymity (if 849
applicable), such as the institution conducting the review. 850
25