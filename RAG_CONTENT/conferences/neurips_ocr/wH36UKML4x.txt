Trained Models Tell Us How to Make Them Robust to
Spurious Correlation without Group Annotation
Anonymous Author(s)
Affiliation
Address
email
Abstract
Classifiers trained with Empirical Risk Minimization (ERM) tend to rely on at- 1
tributes that have high spurious correlation with the target. This can degrade the 2
performance on underrepresented (or minority ) groups that lack these attributes, 3
posing significant challenges for both out-of-distribution generalization and fair- 4
ness objectives. Many studies aim to improve robustness to spurious correlation, 5
yet nearly all require group annotation for training and/or model selection. This 6
constrains their applicability in situations where the nature of the spurious correla- 7
tion is not known, or when group labels for certain spurious attributes are either 8
insufficient or completely absent. To meet the demand for effectively enhancing the 9
model robustness under minimal assumptions about group annotation, we propose 10
Environment-based Validation and Loss-based Sampling (EVaLS). It uses the losses 11
from a trained model to construct a balanced dataset of high-loss and low-loss 12
samples in which the training data group imbalance is mitigated. This results in 13
a significant robustness to group shifts when equipped with a simple mechanism 14
of last layer retraining. Furthermore, by utilizing environment inference methods 15
for creating diverse environments with correlation shifts, EVaLS can potentially 16
eliminate the need for group annotation in the validation data. In such a context, the 17
worst environment accuracy acts as a reliable surrogate throughout the retraining 18
process for tuning hyperparameters and finding a model that performs well across 19
diverse group shifts. EVaLS effectively achieves group robustness, showing that 20
group annotation is not necessary even for validation. It is a fast, straightforward, 21
and effective approach that reaches near-optimal worst group accuracy without 22
needing group annotations, marking a new chapter in the robustness of trained 23
models against spurious correlation. 24
1 Introduction 25
Training deep learning models using Empirical Risk Minimization (ERM) on a dataset, poses the 26
risk of relying on spurious correlation . These are correlations between certain patterns in the 27
training dataset and the target (e.g., the class label in a classification task) despite lacking any causal 28
relationship. Learning such correlations as shortcuts can negatively impact the models’ accuracy on 29
minority groups that do not contain the spurious patterns associated with the target [ 1,2]. This problem 30
leads to concerns regarding fairness [ 3], and can also cause a marked reduction in the performance. 31
This occurs particularly when minority groups, which are underrepresented during training, become 32
overrepresented at the time of testing, as a result of shifts within the subpopulations [ 4]. Hence, 33
ensuring robustness to group shifts and developing methods that improve worst group accuracy 34
(WGA) is crucial for achieving both fairness and robustness in the realm of deep learning. 35
Submitted to 38th Conference on Neural Information Processing Systems (NeurIPS 2024). Do not distribute.Many studies have proposed solutions to address this challenge. A promising line of research 36
focuses on increasing the contribution of minority groups in the model’s training [ 1,5–7]. A strong 37
assumption that is considered by some previous works is having access to group annotations for 38
training or fully/partially fine-tuning a pretrained model [ 8,7,1]. The study by Kirichenko et al. [1] 39
proposes that retraining the last layer of a model on a dataset which is balanced in terms of group 40
annotation can effectively enhance the model’s robustness against shifts in spurious correlation. While 41
these works have shown tremendous robustness performance, their assumption for the availability of 42
group annotation restricts their usage. 43
In many real-world applications, the process of labeling samples according to their respective groups 44
can be prohibitively expensive, and sometimes impractical, especially when all minority groups 45
may not be identifiable beforehand. A widely adopted strategy in these situations involves the 46
indirect inference of various groups, followed by the training of models using a loss function that is 47
balanced across groups [ 5,9,10,4]. The loss value of the model or its similar metrics is a popular 48
signal for recognizing minority groups [ 5,9–11]. While most of these techniques necessitate full 49
training of a model, Qiu et al. [9]attempt to adapt the DFR method [ 1] with the aim of preserving 50
computational efficiency while simultaneously improving robustness to group shift. However, this 51
method still requires group annotations of the validation set for model selection and hyperparameter 52
tuning. Consequently, this constitutes a restrictive assumption when adequate annotations for certain 53
groups are not supplied. It also applies to situations where some shortcut attributes are completely 54
unidentified. 55
In this study, we present a novel strategy that effectively mitigates reliance on spurious correlation, 56
completely eliminating the need for group annotations during both training and retraining. More 57
interestingly, we provide empirical evidence indicating that group annotations are not necessary, 58
even for model selection. We show that assembling a diverse collection of environments for model 59
selection, which reflect group shifts can serve as an effective alternative approach. Our proposed 60
method, Environment-based Validation and Loss-based Sampling (EVaLS), is a technique that 61
strengthens the robustness of trained models against spurious correlation, all without relying on group 62
annotations. EVaLS is pioneering in its ability to eliminate the need for group annotations at every 63
phase , including the model selection step. EVaLS posits that in the absence of group annotations, a 64
set of environments showcasing group shifts is sufficient. Worst Environment Accuracy (WEA) could 65
then be utilized for model selection. Our findings demonstrate that utilizing environment inference 66
methods [ 12], or even dividing the validation data based on the predictions of a random linear layer 67
atop a trained model’s feature space can markedly enhance group robustness. Figure 1 demonstrates 68
the overall procedure of the main parts of EVaLS. 69
Our empirical observations support prior research which suggests that high-loss data points in a 70
trained model may signal the presence of minority groups [ 5,9,10]. Our method, EVaLS, evenly 71
selects from both high-loss and low-loss data to form a balanced dataset that is used for last-layer 72
retraining. We offer theoretical explanations for the effectiveness of this approach in addressing group 73
imbalances, and experimentally show the superiority of our efficient solution to the previous strategies. 74
Comprehensive experiments conducted on spurious correlation benchmarks such as CelebA [ 13], 75
Waterbirds [ 7], and UrbanCars [ 14], demonstrate that EVaLS achieves optimal accuracy. Moreover, 76
when group annotations are accessible solely for model selection, our approach, EVaLS-GL, exhibits 77
enhanced performance against various distribution shifts, including attribute imbalance, as seen in 78
MultiNLI [ 15], and class imbalance, exemplified by CivilComments [ 16]. We further present a 79
new dataset, Dominoes Colored-MNIST-FashionMNIST , which depicts a situation featuring multiple 80
independent shortcuts, that group annotations are only available for part of them (see Section 2.2). In 81
this setting, we show that strategies with lower levels of group supervision are paradoxically more 82
effective in mitigating the reliance on both known and unknown shortcuts. 83
The main contributions of this paper are summarized as follows: 84
•We present EVaLS, a simple yet effective approach that enhances model robustness against 85
spurious correlation without relying on ground-truth group annotations. 86
•We offer both theoretical and practical insights on how balanced sampling from high-loss and 87
low-loss samples can result in a dataset in which the group imbalance is notably mitigated. 88
•Using simple environment inference techniques, EVaLS leverages worst environment accu- 89
racy as a reliable indicator for model selection. 90
2•EVaLS attains near-optimal worst group accuracies or even exceeds them in spurious 91
correlation benchmarks, all with zero group annotations. 92
•When group annotations are available for model selection, EVaLS delivers state-of-the-art 93
performance across a variety of subpopulation shift benchmarks. 94
•We introduce a new dataset consisting of two spurious features in which partial supervision 95
may negatively impact the performance of the underrepresented groups. 96
2 Preliminaries 97
2.1 Problem Setting 98
We assume a general setting of a supervised learning problem with distinct data partitions Dtrfor 99
training, Dvalfor validation, and Dtestfor final evaluation. Each dataset comprises a set of paired 100
samples (x, y), where x∈ X represents the data and y∈ Y denotes the corresponding labels. 101
Conventionally, Dtr,Dval, andDtestare assumed to be uniformly sampled from the same distribution. 102
However, this idealized assumption does not hold in many real-world problems where distribution 103
shift is inevitable. In this context, we consider the sub-population shift problem [ 4]. In a general 104
form of this setting, it is assumed that data samples consist of different groups Gi, where each 105
group comprises samples that share a property. More specifically, the overall data distribution 106
p(x, y) =P
iαipi(x, y)is a composition of individual group distributions pi(x, y)weighted by their 107
respective proportions αi, whereP
iαi= 1. In this work, we assume that Dtr,Dval, andDtestare 108
composed of identical groups but with a different set of mixing coefficients {αi}. It is noteworthy 109
that the validation set may have approximately identical coefficients to those of the training or testing 110
sets, or it may have entirely different coefficients. 111
Several kinds of subpopulation shifts are defined in the literature, including class imbalance, attribute 112
imbalance, and spurious correlation [ 4]. Class imbalance refers to the cases where there is a difference 113
between the proportion of samples from each class, while attribute imbalance occurs when instances 114
with a certain attribute are underrepresented in the training data, even though this attribute may not 115
necessarily be a reliable predictor of the label. On the other hand, spurious correlation occurs when 116
various groups are differentiated by spurious attributes that are partially predictive and correlated with 117
class labels but are causally irrelevant. More precisely, we can consider a set of spurious attributes 118
Sthat partition the data into |S| × |Y| groups. When the concurrence of a spurious attribute with a 119
label is significantly higher than its correlation with other labels, that spurious attribute could become 120
predictive of the label, resulting in deep models relying on the spurious attributes as shortcuts instead 121
of the core ones. This is followed by a decrease in the model’s performance on groups that do not 122
have this attribute. 123
Given a class, the group containing samples with correlated spurious attributes is referred to as 124
majority group of that class, while the other groups are called the minority groups. As an example, 125
in the Waterbirds dataset [ 7], for which the task is to classify images of birds into landbird and 126
waterbird, there are spurious attributes {water background ,land background }. Each background is 127
spuriously correlated with its associated label, decompose the data into two majority groups waterbird 128
on water background , and landbird on land background , and two minority groups waterbird on land 129
background andlandbird on water background . Our goal is to make the classifier robust to spurious 130
attributes by increasing performance for all groups. 131
2.2 Robustness of a Trained Model to an Unknown Shortcut 132
In scenarios where group annotations are absent, traditional methods that depend on these annotations 133
for training or model selection become infeasible. Moreover, as previously discussed by [ 14], when 134
data contains multiple spurious attributes and annotations are only available for some of them, such 135
methods would make the model robust only to the known spurious attributes. To explore such complex 136
scenarios, we introduce the Dominoes Colored-MNIST-FashionMNIST (Dominoes CMF) dataset 137
(Figure 3(d)). Drawing inspiration from Pagliardini et al. [17] and Arjovsky et al. [18], Dominoes 138
CMF merges an image from CIFAR10 [ 19] at the top with a colored (red or green) MNIST [ 20] or 139
FashionMNIST [ 21] image at the bottom. The primary label is derived from the CIFAR10 image, 140
while the bottom part introduces two independent spurious attributes: color and shape. Although 141
3Split class group sample
1 min
maj
2 min
maj
train
𝑫𝑳𝑳1 min
maj
2 min
maj
random splitting
ERM classifier
train splithigh -loss samples
low-loss samplesrank -based sampling
top-k high and low 
loss samplesloss-based sorting
K=3Environment 
Inference method{Env 1, Env 2, Env 3, Env 4}
validation splitK=2
K=3
K=4WEA: 0.70Env 1 Env 2 Env 3 Env 4
WEA: 0.80
WEA: 0.65acc: 0.95 acc: 0.75 acc: 0.70 acc: 0.85
acc: 0.90 acc: 0.85 acc: 0.90 acc: 0.80
acc: 0.65 acc: 0.95 acc: 0.90 acc: 0.70(a) Held -out data split
(c) Loss -based sampling(b) Environment inference (d) Last -layer retraining
training model selection✓train
𝑫𝑳𝑳validation
𝑫𝑴𝑺Figure 1: Overview of the proposed method. Given an ERM-trained model (similar to DFR [ 1]), the
following steps are performed: (a) we randomly split the held-out dataset into train and validation
splits. (b) An environment inference method is utilized to infer diverse environments from the
validation split. (c) We evaluate train split samples on the initial ERM classifier and sort high-loss and
low-loss samples of each class for loss-based sampling. (d) Finally, we perform last-layer retraining
on the loss-based selected samples. Each retraining setting (e.g. different kfor loss-based sampling)
is validated based on the worst accuracy of the inferred environments. Note that majority and minority
groups are shown with dark and light colors for better visualization, but are not known in our setting.
annotations for shape are provided for training and model selection, color remains an unknown 142
variable until testing. For more details on the dataset refer to the Appendix. 143
The illustrations in Figure 3(a-c) depict the outlined scenario. A classifier trained using ERM is 144
dependent on both spurious features (Figure 3(b)). Yet, achieving robustness against one spurious 145
correlation (Figure 3(c)), does not ensure robustness against both (Figure 3(a)). In Section 4 we 146
show that our method, which does not rely on the group annotations of the identified group, achieves 147
enhanced robustness against both spurious correlations, outperforming strategies that depend on the 148
known group’s information. 149
3 Environment-based Validation and Loss-based Sampling 150
Our method, EVaLS, is designed to improve the robustness of deep learning models to group shifts 151
without the need for group annotation. In line with the DFR [ 1] approach, we utilize a classifier 152
defined as f=hϕ◦gθ, where gθrepresents a deep neural network serving as a feature extractor, and 153
hϕdenotes a linear classifier. The classifier is initially trained with the ERM objective on the training 154
dataset Dtr. Subsequently, we freeze the feature extractor gθand focus solely on retraining the last 155
linear layer hϕusing the validation dataset Dvalas a held-out dataset. 156
We randomly divide the validation set Dvalinto two subsets, DLLandDMSwhich are used for last 157
layer training and model selection, respectively. In Section 3.1 we explain how to sample a subset 158
ofDLLthat statistically handles the group shifts inherent in the dataset. In Section 3.2 we describe 159
howDMSis divided into different environments that are later used for model selection. The optimal 160
number of selected samples from DLLand other hyperparameters is determined based on the worst 161
environment accuracies among environments that are obtained from DMS. By combining our novel 162
sampling and validation strategy, we aim to provide a robust linear classifier hϕ∗that significantly 163
improves the accuracy of underrepresented groups without requiring group annotations of training 164
or validation sets. Figure 1 illustrates the comprehensive workflow of the EVaLS methodology. 165
Finally in Section 3.3, we provide theoretical support for the loss-based sampling procedure and its 166
effectiveness. 167
3.1 Loss-Based Instance Sampling 168
Following previous works [ 5,10,9], we use the loss value as an indicator for identifying minority 169
groups. We first evaluate classifier fon samples within DLLand choose ksamples with the highest 170
and lowest loss values for a given k. By combining these 2ksamples from each class, we construct a 171
4balanced set Dbalanced, consisting of high-loss and low-loss samples (see Figure 1(c)). Dbalancedis 172
then used for the training of the last layer of the model. 173
As depicted in Figure 2, the proportion of minority samples among various percentiles of samples 174
with the highest loss values increases as we select a smaller subset of samples with the highest loss. 175
This suggests that high and low-loss samples could serve as effective representatives of minority 176
and majority groups, respectively. In Section 3.3, we offer theoretical insights explaining why this 177
approach could lead to the creation of group-balanced data. 178
3.2 Partitioning Validation Set into Environments 179
Contrary to common assumptions and practices in the field, precise group labels for the validation 180
set are not essential for training models robust to spurious correlations. Our empirical findings, 181
detailed in Section 4, reveal that partitioning the validation set into environments that exhibit sig- 182
nificant subpopulation shifts can be used for model selection. Under these conditions, the worst 183
environment accuracy (WEA) emerges as a viable metric for selecting the most effective model and 184
hyperparameters. 185
The concept of an environment , as frequently discussed in the invariant learning literature, denotes 186
partitions of data that exhibit different distributions. A model that consistently excels across these 187
varied environments, achieving impressive worst environment accuracy (WEA), is likely to perform 188
equally well across different groups in the test set. Several methods for inferring environments 189
with notable distribution shifts have been introduced [ 12,22]. Environment Inference for Invariant 190
Learning (EIIL) [ 12], leverages the predictions from an earlier trained ERM model to divide the data 191
into two distinct environments that significantly deviate from the invariant learning principle proposed 192
by Arjovsky et al. [18], thus creating environments with distribution shifts. Initially, EIIL is employed 193
to split DMSinto two environments. Subsequently, each environment is further divided based on 194
sample labels, resulting in 2× |Y| environments. To measure the difference between the distribution 195
of environments, we define group shift of a class as the absolute difference in the proportion of 196
a minority group between two environments of that class. A higher group shift suggests a more 197
distinct separation between environments. As detailed in the Appendix, environments inferred by 198
EIIL demonstrate an average group shift of 28.7%over datasets with spurious correlation. Further 199
information about EIIL and the group shift quantities for each dataset can be found in the Appendix. 200
We demonstrate that even more straightforward techniques, such as applying a random linear layer 201
over the feature embedding space and distinguishing environments based on correctly and incorrectly 202
classified samples of each class, can be effective to an extent in several cases (See Appendix E.2). 203
It underscores that the feature space of a trained model is a valuable resource of information for 204
identifying groups affected by spurious correlations. This supports the logic of previous research that 205
employs clustering [23] or contrastive methods [24] in this space to differentiate between groups. 206
3.3 Theoretical Analysis 207
In this subsection, we provide theoretical insights into why loss-based sampling in a class can be 208
utilized to create a balanced dataset of each group under sufficient conditions. We will show the close 209
relationship between the existence of a balanced dataset and the difference between the minority vs. 210
majority group means, calculated based on the logits of an ERM-trained classifier. Such logits are 211
known to depend on spurious features. Hence the mentioned group mean difference is expected to be 212
high if spurious features are present in the dataset. 213
Consider a binary classification problem with a cross-entropy loss function. Let logits be denoted as 214
L. Because loss is a monotonic function of logits, the tails of the distribution of loss across samples 215
are equivalent to that of the logits in each class. 216
We assume that in feature space (output of gθ) samples from the minority and majority of a class are 217
derived from Gaussian distributions. So, we can consider N(µmin, σ2
min)andN(µmaj, σ2
maj)as the 218
distribution of minority and majority samples in logits space. 219
Proposition 3.1 (Feasiblity Of Loss-based Group Balancing) .Suppose that Lis derived from the 220
mixture of two distributions N(µmin, σ2
min)andN(µmaj, σ2
maj)with proportion of εand1−ε, 221
respectively, where ε≤1
2. Under sufficient (see App.C) and necessary conditions on µmin,µmaj, 222
σminandσmajincluding inequality 1, there exists αandβsuch that restricting Lto the α-left and 223
5/uni00000013 /uni00000018/uni00000013 /uni00000014/uni00000013/uni00000013
/uni00000008/uni00000003/uni00000052/uni00000049/uni00000003/uni0000002b/uni0000004c/uni0000004a/uni0000004b/uni00000010/uni0000002f/uni00000052/uni00000056/uni00000056/uni00000003/uni00000036/uni00000044/uni00000050/uni00000053/uni0000004f/uni00000048/uni00000018/uni00000013/uni00000019/uni00000013/uni0000001a/uni00000013/uni0000001b/uni00000013/uni0000001c/uni00000013/uni00000014/uni00000013/uni00000013/uni00000008/uni00000003/uni00000052/uni00000049/uni00000003/uni00000030/uni0000004c/uni00000051/uni00000052/uni00000055/uni0000004c/uni00000057/uni0000005c/uni00000003/uni00000036/uni00000044/uni00000050/uni00000053/uni0000004f/uni00000048/uni00000056/uni00000046/uni0000004f/uni00000044/uni00000056/uni00000056/uni00000003/uni00000014
/uni00000046/uni0000004f/uni00000044/uni00000056/uni00000056/uni00000003/uni00000015
/uni00000013 /uni00000018/uni00000013 /uni00000014/uni00000013/uni00000013
/uni00000008/uni00000003/uni00000052/uni00000049/uni00000003/uni0000002f/uni00000052/uni0000005a/uni00000010/uni0000002f/uni00000052/uni00000056/uni00000056/uni00000003/uni00000036/uni00000044/uni00000050/uni00000053/uni0000004f/uni00000048/uni00000018/uni00000013/uni00000019/uni00000013/uni0000001a/uni00000013/uni0000001b/uni00000013/uni0000001c/uni00000013/uni00000014/uni00000013/uni00000013/uni00000008/uni00000003/uni00000052/uni00000049/uni00000003/uni00000030/uni00000044/uni0000004d/uni00000052/uni00000055/uni0000004c/uni00000057/uni0000005c/uni00000003/uni00000036/uni00000044/uni00000050/uni00000053/uni0000004f/uni00000048/uni00000056/uni00000046/uni0000004f/uni00000044/uni00000056/uni00000056/uni00000003/uni00000014
/uni00000046/uni0000004f/uni00000044/uni00000056/uni00000056/uni00000003/uni00000015(a) Waterbirds
/uni00000013 /uni00000015/uni00000018 /uni00000018/uni00000013 /uni0000001a/uni00000018 /uni00000014/uni00000013/uni00000013
/uni00000008/uni00000003/uni00000052/uni00000049/uni00000003/uni0000002b/uni0000004c/uni0000004a/uni0000004b/uni00000010/uni0000002f/uni00000052/uni00000056/uni00000056/uni00000003/uni00000036/uni00000044/uni00000050/uni00000053/uni0000004f/uni00000048/uni00000014/uni00000013/uni00000015/uni00000013/uni00000016/uni00000013/uni00000008/uni00000003/uni00000052/uni00000049/uni00000003/uni00000030/uni0000004c/uni00000051/uni00000052/uni00000055/uni0000004c/uni00000057/uni0000005c/uni00000003/uni00000036/uni00000044/uni00000050/uni00000053/uni0000004f/uni00000048/uni00000056/uni00000046/uni0000004f/uni00000044/uni00000056/uni00000056/uni00000003/uni00000015
/uni00000013 /uni00000018/uni00000013 /uni00000014/uni00000013/uni00000013
/uni00000008/uni00000003/uni00000052/uni00000049/uni00000003/uni0000002f/uni00000052/uni0000005a/uni00000010/uni0000002f/uni00000052/uni00000056/uni00000056/uni00000003/uni00000036/uni00000044/uni00000050/uni00000053/uni0000004f/uni00000048/uni0000001c/uni00000017/uni0000001c/uni00000019/uni0000001c/uni0000001b/uni00000014/uni00000013/uni00000013/uni00000008/uni00000003/uni00000052/uni00000049/uni00000003/uni00000030/uni00000044/uni0000004d/uni00000052/uni00000055/uni0000004c/uni00000057/uni0000005c/uni00000003/uni00000036/uni00000044/uni00000050/uni00000053/uni0000004f/uni00000048/uni00000056/uni00000046/uni0000004f/uni00000044/uni00000056/uni00000056/uni00000003/uni00000015 (b) CelebA
Figure 2: The proportion of minority(majority) samples across different classes within various
percentages of DLLsamples with highest (lowest) loss for the Waterbirds (a) and CelebA (b) datasets.
Minority group samples are more prevalent among high-loss samples, while majority group samples
dominate the low-loss areas. The error bars are calculated across three ERM models.1
β-right tails of its distribution results in a group-balanced distribution; in which both components 224
are equally represented. 225
ϵ≥sigmoid 
−(µmaj−µmin2
2(σ2
maj−σ2
min)−logσmaj
σmin!
(1)
We provide an outline for proof of Proposition 3.1 here and leave the complete and formal proof and 226
also exact bounds to Appendix C. We also analyze the conditions and effects of spurious correlation 227
in satisfying these conditions. To proceed with the outline we first define a key concept to outline our 228
proof. 229
Definition 3.1 (Proportional Density Difference) .For any interval I= (a, b]and a mixture distri-
bution εP1(x) + (1 −ε)P2(x), the proportional density difference is defined as the difference of
accumulation of two component distributions in the interval Iand is denoted by ∆εPmixture (I).
∆εPmixture (I)∆=εP1 
x∈I
−(1−ε)P2 
x∈I
Proof outline Our proof proceeds with three steps. First, we reformulate the theorem as an equality 230
of left- and right-tail proportional distribution differences. In other words, we show that the more 231
mass the minority distribution has on one tail, the more mass the majority distribution must have on 232
the other tail. Afterward, supposing µmin< µ majWOLG, we propose a proper range for βvalues 233
on the right tail. We show that when σmaj≤σmin, values for αtrivially exist that can overcome the 234
imbalance between the two distributions. In the last step, for the case in which the variance of the 235
majority is higher than the minority, we discuss a necessary and sufficient condition for the existence 236
ofαandβbased on the left-tail proportional density difference using the properties of its derivative 237
with respect to α. 238
Condition 1 suggests that for a given degree of spurious correlation ϵand variations σmaj, σmin, an 239
essential prerequisite for the efficacy of loss-based sampling is a sufficiently large disparity between 240
the mean distributions of minority and majority samples, denoted by ∥µmaj−µmin∥2. This indicates 241
that the groups should be distinctly separable in the logits space. 242
Although the parameters αandβare theoretically established under certain conditions, their actual 243
values are undetermined. Therefore, validation data is necessary to ascertain them. For practicality 244
and simplicity in this study, we consider that α=βand explore its corresponding sample number 245
(the count of high- and low-loss samples) from a predefined set of possibilities. By leveraging the 246
worst environment accuracy, as elaborated in Section 3.2, we identify the optimal candidate that 247
ensures uniform accuracy across all environments. 248
4 Experiments 249
In this section, we evaluate the effectiveness of our proposed method through comprehensive experi- 250
ments on multiple datasets and compare it with various methods and baselines. We begin by briefly 251
1Note that in the CelebA dataset, only the "blond hair" class includes a minority group.
6Core Dimension3
2
1
0
1
2
3
Spurious 1 Dimension3
2
1
012Spurious 2 DimensionClass 1Class
 2Spurious
 1 = 1, Spurious 2 =  -1Spurious
 1 = -1, Spurious 2 =  -1Spurious
 1 = 1 Spurious 2 =  1Spurious
 1 = -1 Spurious 2 =  1Spurious
 
1 
Dimension2(a)
Core Dimension3
2
1
0
1
2
3Spurious 1 Dimension3
2
1
012Spurious 2 Dimension (b)
Core Dimension3
2
1
0
1
2
3Spurious 1 Dimension3
2
1
012Spurious 2 Dimension (c)
TextVehicle Animal
Red
GreenMNIST MNIST FMNIST FMNIST (d)
Figure 3: Two spurious correlations in a dataset. (a) If both spurious attributes are known, they can be
utilized to fit a classifier that captures the essential attributes. (b) In the absence of knowledge about
both spurious attributes, the model would depend on them for classification, leading to incorrect
classification of minority samples. (c) If one spurious attribute is unknown (Spurious 2), the model
becomes robust only to the known spurious correlation (Spurious 1), but it still underperforms on
minority samples. (d) The Dominoes-CMF dataset, which contains two spurious attributes.
describing evaluation datasets and then introduce baselines and comparative methods. Finally, we 252
report and fully explain the results. 253
Datasets Our method, along with other baselines, is evaluated on Waterbirds [ 7], CelebA [ 13], 254
UrbanCars [ 14], CivilComments [ 16], and MultiNLI [ 15]. As per the study by Yang et al. [4], 255
Waterbirds, CelebA, and UrbanCars among these datasets exhibit spurious correlation. Among the 256
rest, CivilComments has class and attribute imbalance, whereas MultiNLI exhibits attribute imbalance. 257
For additional details on the datasets, please refer to the Appendix. 258
Baselines We compare our method with four baselines in addition to standard ERM. GroupDRO [7] 259
trains a model on the data with the objective of minimizing its average loss on the minority samples. 260
This method requires group labels of both the training and validation sets. DFR [1] argues that 261
models trained with ERM are capable of extracting the core features of images. Thus, it first trains a 262
model with ERM, and retrains only the last linear classifier layer on a group-balanced subset of the 263
validation or the held-out training data. While DFR reduces the number of group-annotated samples, 264
it still requires group labels in the training phase. GroupDRO + EIIL [12] infers environments of 265
the training set and trains a model with GroupDRO on the inferred environments. JTT [5] first trains 266
a model with ERM on the dataset, and then retrains it on the dataset by upweighting the samples that 267
were misclassified by the initial ERM model. AFR [9] trains a model with ERM on a portion of the 268
training set, and retrains the classifier on the weighted held-out training data. The weights assigned to 269
retraining samples are based on the loss of the ERM model, upweighting samples from the minority 270
groups. Group DRO + EIIL, JTT and AFR remove the reliance on group annotation in the training 271
phase. However, unlike our method, they all require group labels for model selection. 272
Setup Similar to all the works mentioned in Section 4, we use ResNet-50 [ 25] pretrained on 273
ImageNet [ 26] for image classification tasks. We used random crop and random horizontal flip 274
as data augmentation, similar to [ 1]. For a fair comparison with the baselines, we did not employ 275
any data augmentation techniques in the process of retraining the last layer of the model. For the 276
CivilComments and MultiNLI, we use pretrained BERT [ 27] and crop sentences to 220 tokens length. 277
In EvaLS, we use the implementation of EIIL by spuco package [ 28] for environments inference on 278
the model selection set with 20000 steps, SGD optimizer, and learning rate 10−2for all datasets. 279
Model selection and hyper-parameter fine-tuning are done according to the worst environment(or 280
group if annotations are assumed to be available) accuracy on the validation set. For each dataset, 281
we assess the performance of our model in two cases: fine-tuning the ERM classifier or retraining it. 282
For all datasets except MultiNLI, retraining yielded better validation results. We report the results 283
of our experiments in two settings: (i) EVaLS, which incorporates loss-based instance sampling for 284
training the last layer, and environment inference for model selection. (ii) EVaLS-GL, similar to 285
EVaLS except in using ground-truth group labels for model selection. For more details on the ERM 286
training and last layer re-training hyperparameters refer to the Appendix. 287
74.1 Results 288
The results of our experiments along with the reported results on GroupDRO [ 7], DFR [ 1], JTT [ 5], 289
and AFR [ 9] on five datasets are shown in Table 1. The reported results for GroupDRO, DFR, JTT, 290
and AFR except those for the UrbanCars are taken from Qiu et al. [9]. For EIIL+Group DRO, the 291
results are reported from Zhang et al. [24]. We report only the worst group accuracy of methods in 292
Table 1. The average group accuracies are documented in the Appendix. The Group Info column 293
shows whether group annotation is required for training or model selection entry for each method. 294
When compared to other methods with the same level of supervision, EVaLS-GL outperforms on four 295
of the five datasets, achieving near-optimal worst group accuracy on Waterbirds, demonstrating the 296
effectiveness of loss-based sample selection compared to the weighting scheme in AFR [ 9]. Given 297
that AFR employs exponential weights with a temperature parameter to assign a positive weight 298
to all samples, proportional to the model’s assigned probability of the correct class, an increase 299
in the number of low-loss samples will lead to a corresponding rise in their cumulative weight. 300
Consequently, in situations where spurious correlation is high and an uptick in majority samples leads 301
to a greater proportion of low-loss over high-loss samples, determining an appropriate parameter 302
becomes challenging. 303
The comparison between EVaLS and Group DRO + EIIL indicates that when environments are 304
available instead of groups, our method, which uses environments solely for model selection and 305
utilizes loss-based sampling, is more effective than GroupDRO, a potent invariant learning method, 306
which uses this annotation for training. 307
Regarding the UrbanCars, which contains an un-annotated spurious attribute, Li et al. [14] has shown 308
that shortcut mitigation methods often struggle to address multiple shortcuts simultaneously. Notably, 309
techniques such as DFR [ 1] which are designed to reduce reliance on a specific shortcut feature, 310
cannot make the model robust to an unknown shortcut. In contrast, our experiments suggest that 311
loss-based methods can mitigate the impact of both labeled and unlabeled shortcut features more 312
effectively. Also, in the case of CivilComments, which is viewed as a benchmark for class imbalance, 313
EVaLS-GL exceeds all prior methods, even those with complete group annotation, thanks to the class 314
balancing for the training of the last layer. 315
Our evaluation of EVaLS is based on the spurious correlation benchmarks. This is because, in 316
other instances of subpopulation shift, the attributes that differ across groups are not predictive of 317
the label, thereby reducing the visibility of these attributes’ effects in the model’s final layers [ 29]. 318
Consequently, EIIL, which depends on output logits for prediction, might not effectively separate 319
the groups. This observation is further supported by our findings related to the degree of group 320
shift between the environments inferred by EIIL for each class in the CivilComments and MultiNLI 321
datasets. The average group shift (defined in the Section 3.2) in the environments of the minority 322
class of CivilComments is only 5.6±0.8%. Also, environments associated with Classes 1 and 2 in 323
MultiNLI show only 1.1±0.3%and1.9±1.0%group shift respectively. More results and ablation 324
studies can be found in the Appendix. 325
Mitigating Multiple Shortcut Attributes To evaluate the performance of our method in the case 326
of unknown spurious correlations, we train a ResNet-18 [ 25] model on the Dominoes-CMF dataset. 327
We apply DFR [ 1], EVaLS-GL, and EVaLS on top of the trained ERMs to assess their ability to 328
mitigate multiple shortcuts. For the last layer training set, we consider the MNIST/Fashion-MNIST 329
feature as the known group label, and the color as the unknown attribute. The results are shown in 330
Table 2. To clarify, we calculate the worst-group accuracy on the validation set considering only the 331
label of one shortcut, i.e., the lowest accuracy among the four groups based on the combination of the 332
target label and the single known shortcut label. Note that EVaLS does not require group annotations. 333
Our results confirm findings by Li et al. [14], suggesting that methods using group labels mitigate 334
reliance on the known shortcut but not necessarily on the unknown one. EVaLS-GL mitigates this 335
phenomenon using its loss-based sampling approach, but surprisingly EVaLS even outperforms 336
EVaLS-GL. Combining a loss-based sampling approach for last layer training and environment-based 337
model selection, results in a completely group-annotation-free method in a multi-shortcut setting and 338
successfully re-weights features to perform well with respect to both spurious attributes. 339
8Table 1: A comparison of the worst group accuracy across various methods, ours included, on
five datasets. The Group Info column indicates if each method utilizes group labels of the train-
ing/validation data, with ✓ ✓denoting that group information is employed during both the training
and validation stages. Bold numbers are the highest results overall, while underlined ones are the
best among methods that may require group annotation only for model selection. CivilComments is
class imbalanced, MultiNLI has imbalanced attributes, and the other three datasets have spurious
correlations. The ×sign indicates that the dataset is out of the scope of the method. The mean and
standard deviation are calculated over three runs with different seeds.
MethodGroup Info Datasets
Train/Val Waterbirds CelebA UrbanCars CivilComments MultiNLI
GDRO [7] ✓/✓ 91.4 88.9 - 69.9 77.7
DFR [1] ✗/✓ ✓ 92.9±0.288.3±1.179.6±2.22 70.1±0.8 74.7±0.7
GDRO + EIIL [12] ✗/✓ 77.2±1 81.7±0.8 - 67.0±2.4 -
JTT [5] ✗/✓ 86.7 81 .1 - 69.3 72 .6
AFR [9] ✗/✓ 90.4±1.182.0±0.5 80.2±2.0 68.7±0.6 73.4±0.6
EVaLS-GL (Ours) ✗/✓ 89.4±0.384.6±1.682.27±1.16 80.5±0.4 75.1±1.2
ERM ✗/✗ 66.4±2.347.4±2.318.67±2.01 61.2±3.6 64.8±1.9
EVaLS (Ours) ✗/✗ 88.4±3.185.3±0.482.13±0.92 × ×
Table 2: Worst test group accuracy of ERM, DFR, EVaLS, and EVaLS-GL on the Dominoes-CMF
Dataset. The mean and standard deviation are calculated based on runs with three distinct seeds.
ERM DFR EVaLS-GL EVaLS
Worst Group Accuracy 50.6±1.060.2±1.2 63.6±1.367.1±4.2
5 Discussion 340
This study presents EVaLS, a novel approach to improve robustness to spurious correlations with 341
zero group annotation. EVaLS uses loss-based sampling to create a balanced training dataset that 342
effectively disrupts spurious correlations and employs EIIL to infer environments for model selection. 343
We also explore situations with multiple spurious correlations where not all spurious factors are 344
known. In this context, we introduce Dominoes-CMF, a dataset in which two factors are spuriously 345
correlated with the label, but only one is identified. Our findings suggest that EVaLS attains near- 346
optimal worst test group accuracy on spurious correlation datasets. We also present EVaLS-GL, which 347
needs group labels only for model selection. Our empirical tests on various datasets demonstrate 348
EVaLS-GL outperforms state-of-the-art methods requiring group data during evaluation or training. 349
Note that this paper remains consistent with the findings of Lin et al. [30]. Our approach does not 350
involve identifying spurious attributes without auxiliary information. Instead, the objective is to make 351
a trained model robust against its reliance on shortcuts. Specifically, conditioning on what a trained 352
model learns, we ascertain that both the loss value and the model’s feature space are instrumental in 353
mitigating shortcuts and effectuating notable shifts among groups. 354
EVaLS and EVaLS-GL may struggle with small datasets due to a low number of selected samples 355
for the last layer training. Also, as environment inference from the last layer features is not effective 356
for all types of subpopulation shifts, EVaLS is limited to datasets with spurious correlation. Similar 357
to other methods in the field, EVaLS prioritizes the worst group accuracy at the cost of less average 358
accuracy. Additionally, a notable variance has been observed in some of our experiments. 359
EVaLS represents a significant advancement in the development of methods for enhancing model 360
fairness and robustness without prior knowledge about group annotations. Future work could explore 361
developing environment inference methods effective for other types of subpopulation shift, such as 362
attribute and class imbalance. 363
9References 364
[1]Polina Kirichenko, Pavel Izmailov, and Andrew Gordon Wilson. Last layer re-training is suffi- 365
cient for robustness to spurious correlations. In The Eleventh International Conference on Learn- 366
ing Representations , 2023. URL https://openreview.net/forum?id=Zb6c8A-Fghk . 367
[2]Tyler LaBonte, Vidya Muthukumar, and Abhishek Kumar. Towards last-layer retraining for 368
group robustness with fewer annotations. In Thirty-seventh Conference on Neural Information 369
Processing Systems , 2023. URL https://openreview.net/forum?id=kshC3NOP6h . 370
[3]Tatsunori Hashimoto, Megha Srivastava, Hongseok Namkoong, and Percy Liang. Fairness 371
without demographics in repeated loss minimization. In International Conference on Machine 372
Learning , pages 1929–1938. PMLR, 2018. 373
[4]Yuzhe Yang, Haoran Zhang, Dina Katabi, and Marzyeh Ghassemi. Change is hard: A closer 374
look at subpopulation shift. In International Conference on Machine Learning , 2023. 375
[5]Evan Z Liu, Behzad Haghgoo, Annie S Chen, Aditi Raghunathan, Pang Wei Koh, Shiori 376
Sagawa, Percy Liang, and Chelsea Finn. Just train twice: Improving group robustness without 377
training group information. In Marina Meila and Tong Zhang, editors, Proceedings of the 378
38th International Conference on Machine Learning , volume 139 of Proceedings of Machine 379
Learning Research , pages 6781–6792. PMLR, 18–24 Jul 2021. URL https://proceedings. 380
mlr.press/v139/liu21f.html . 381
[6]Yu Yang, Eric Gan, Gintare Karolina Dziugaite, and Baharan Mirzasoleiman. Identifying 382
spurious biases early in training through the lens of simplicity bias. ArXiv , abs/2305.18761, 383
2023. URL https://api.semanticscholar.org/CorpusID:258967752 . 384
[7]Shiori Sagawa, Pang Wei Koh, Tatsunori B Hashimoto, and Percy Liang. Distributionally robust 385
neural networks. In International Conference on Learning Representations , 2019. 386
[8]Junhyun Nam, Jaehyung Kim, Jaeho Lee, and Jinwoo Shin. Spread spurious attribute: Improving 387
worst-group accuracy with spurious attribute estimation. In International Conference on 388
Learning Representations , 2021. 389
[9]Shikai Qiu, Andres Potapczynski, Pavel Izmailov, and Andrew Gordon Wilson. Simple and fast 390
group robustness by automatic feature reweighting. In International Conference on Machine 391
Learning , pages 28448–28467. PMLR, 2023. 392
[10] Junhyun Nam, Hyuntak Cha, Sungsoo Ahn, Jaeho Lee, and Jinwoo Shin. Learning from failure: 393
De-biasing classifier from biased classifier. Advances in Neural Information Processing Systems , 394
33:20673–20684, 2020. 395
[11] Fahimeh Hosseini Noohdani, Parsa Hosseini, Aryan Yazdan Parast, HamidReza Yaghoubi 396
Araghi, and Mahdieh Soleymani Baghshah. Decompose-and-compose: A compositional 397
approach to mitigating spurious correlation. CoRR , abs/2402.18919, 2024. doi: 10.48550/ 398
ARXIV .2402.18919. URL https://doi.org/10.48550/arXiv.2402.18919 . 399
[12] Elliot Creager, Joern-Henrik Jacobsen, and Richard Zemel. Environment inference for invariant 400
learning. In Marina Meila and Tong Zhang, editors, Proceedings of the 38th International 401
Conference on Machine Learning , volume 139 of Proceedings of Machine Learning Research , 402
pages 2189–2200. PMLR, 18–24 Jul 2021. URL https://proceedings.mlr.press/v139/ 403
creager21a.html . 404
[13] Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang. Deep learning face attributes in the 405
wild. 2015 IEEE International Conference on Computer Vision (ICCV) , pages 3730–3738, 406
2014. URL https://api.semanticscholar.org/CorpusID:459456 . 407
[14] Zhiheng Li, Ivan Evtimov, Albert Gordo, Caner Hazirbas, Tal Hassner, Cristian Canton Ferrer, 408
Chenliang Xu, and Mark Ibrahim. A whac-a-mole dilemma: Shortcuts come in multiples where 409
mitigating one amplifies others. In Proceedings of the IEEE/CVF Conference on Computer 410
Vision and Pattern Recognition (CVPR) , pages 20071–20082, June 2023. 411
10[15] Adina Williams, Nikita Nangia, and Samuel R Bowman. A broad-coverage challenge corpus 412
for sentence understanding through inference. arXiv preprint arXiv:1704.05426 , 2017. 413
[16] Daniel Borkan, Lucas Dixon, Jeffrey Sorensen, Nithum Thain, and Lucy Vasserman. Nuanced 414
metrics for measuring unintended bias with real data for text classification. In Companion 415
proceedings of the 2019 world wide web conference , pages 491–500, 2019. 416
[17] Matteo Pagliardini, Martin Jaggi, François Fleuret, and Sai Praneeth Karimireddy. Agree to 417
disagree: Diversity through disagreement for better transferability. In The Eleventh International 418
Conference on Learning Representations , 2022. 419
[18] Martin Arjovsky, Léon Bottou, Ishaan Gulrajani, and David Lopez-Paz. Invariant risk mini- 420
mization, 2020. 421
[19] Alex Krizhevsky. Learning multiple layers of features from tiny images. pages 32–33, 2009. 422
URL https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf . 423
[20] Yann LeCun and Corinna Cortes. MNIST handwritten digit database. 2010. URL http: 424
//yann.lecun.com/exdb/mnist/ . 425
[21] Han Xiao, Kashif Rasul, and Roland V ollgraf. Fashion-mnist: a novel image 426
dataset for benchmarking machine learning algorithms, 2017. URL http://arxiv. 427
org/abs/1708.07747 . cite arxiv:1708.07747Comment: Dataset is freely available at 428
https://github.com/zalandoresearch/fashion-mnist Benchmark is available at http://fashion- 429
mnist.s3-website.eu-central-1.amazonaws.com/. 430
[22] Jiashuo Liu, Zheyuan Hu, Peng Cui, Bo Li, and Zheyan Shen. Heterogeneous risk minimization. 431
In Marina Meila and Tong Zhang, editors, Proceedings of the 38th International Conference on 432
Machine Learning , volume 139 of Proceedings of Machine Learning Research , pages 6804– 433
6814. PMLR, 18–24 Jul 2021. URL https://proceedings.mlr.press/v139/liu21h. 434
html . 435
[23] Nimit Sohoni, Jared Dunnmon, Geoffrey Angus, Albert Gu, and Christopher Ré. No subclass 436
left behind: Fine-grained robustness in coarse-grained classification problems. Advances in 437
Neural Information Processing Systems , 33:19339–19352, 2020. 438
[24] Michael Zhang, Nimit Sharad Sohoni, Hongyang R. Zhang, Chelsea Finn, and Christopher Ré. 439
Correct-n-contrast: A contrastive approach for improving robustness to spurious correlations. 440
InNeurIPS 2021 Workshop on Distribution Shifts: Connecting Methods and Applications , 2021. 441
URL https://openreview.net/forum?id=Q41kl_DwS3Y . 442
[25] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image 443
recognition. In 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 444
pages 770–778, 2016. doi: 10.1109/CVPR.2016.90. 445
[26] Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng 446
Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, et al. Imagenet large scale visual 447
recognition challenge. International journal of computer vision , 115:211–252, 2015. 448
[27] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: Pre-training of 449
deep bidirectional transformers for language understanding. In Jill Burstein, Christy Doran, and 450
Thamar Solorio, editors, Proceedings of the 2019 Conference of the North American Chapter 451
of the Association for Computational Linguistics: Human Language Technologies, Volume 1 452
(Long and Short Papers) , pages 4171–4186, Minneapolis, Minnesota, June 2019. Association 453
for Computational Linguistics. doi: 10.18653/v1/N19-1423. URL https://aclanthology. 454
org/N19-1423 . 455
[28] Siddharth Joshi, Yu Yang, Yihao Xue, Wenhan Yang, and Baharan Mirzasoleiman. To- 456
wards mitigating spurious correlations in the wild: A benchmark & a more realistic dataset. 457
ArXiv , abs/2306.11957, 2023. URL https://api.semanticscholar.org/CorpusID: 458
259211935 . 459
11[29] Yoonho Lee, Annie S Chen, Fahim Tajwar, Ananya Kumar, Huaxiu Yao, Percy Liang, and 460
Chelsea Finn. Surgical fine-tuning improves adaptation to distribution shifts. In The Eleventh 461
International Conference on Learning Representations , 2023. URL https://openreview. 462
net/forum?id=APuPRxjHvZ . 463
[30] Yong Lin, Shengyu Zhu, Lu Tan, and Peng Cui. Zin: When and how to learn invariance without 464
environment partition? In S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh, 465
editors, Advances in Neural Information Processing Systems , volume 35, pages 24529–24542. 466
Curran Associates, Inc., 2022. URL https://proceedings.neurips.cc/paper_files/ 467
paper/2022/file/9b77f07301b1ef1fe810aae96c12cb7b-Paper-Conference.pdf . 468
[31] Zheyan Shen, Jiashuo Liu, Yue He, Xingxuan Zhang, Renzhe Xu, Han Yu, and Peng Cui. 469
Towards out-of-distribution generalization: A survey. ArXiv , abs/2108.13624, 2021. URL 470
https://api.semanticscholar.org/CorpusID:237364121 . 471
[32] Seonguk Seo, Joon-Young Lee, and Bohyung Han. Information-theoretic bias reduction via 472
causal view of spurious correlation. In Proceedings of the AAAI Conference on Artificial 473
Intelligence , volume 36, pages 2180–2188, 2022. 474
[33] Yuzhen Mao, Zhun Deng, Huaxiu Yao, Ting Ye, Kenji Kawaguchi, and James Zou. Last-layer 475
fairness fine-tuning is simple and effective for neural networks. arXiv preprint arXiv:2304.03935 , 476
2023. 477
[34] David Krueger, Ethan Caballero, Joern-Henrik Jacobsen, Amy Zhang, Jonathan Binas, Dinghuai 478
Zhang, Remi Le Priol, and Aaron Courville. Out-of-distribution generalization via risk extrapo- 479
lation (rex). In Marina Meila and Tong Zhang, editors, Proceedings of the 38th International 480
Conference on Machine Learning , volume 139 of Proceedings of Machine Learning Research , 481
pages 5815–5826. PMLR, 18–24 Jul 2021. URL https://proceedings.mlr.press/v139/ 482
krueger21a.html . 483
[35] Alexandre Rame, Corentin Dancette, and Matthieu Cord. Fishr: Invariant gradient variances for 484
out-of-distribution generalization. In International Conference on Machine Learning , pages 485
18347–18377. PMLR, 2022. 486
[36] Faruk Ahmed, Yoshua Bengio, Harm van Seijen, and Aaron Courville. Systematic generalisation 487
with group invariant predictions. In International Conference on Learning Representations , 488
2021. URL https://openreview.net/forum?id=b9PoimzZFJ . 489
[37] Matteo Pagliardini, Martin Jaggi, François Fleuret, and Sai Praneeth Karimireddy. Agree 490
to disagree: Diversity through disagreement for better transferability. arXiv preprint , 491
arXiv:2202.04414, 2022. 492
[38] Harshay Shah, Kaustav Tamuly, Aditi Raghunathan, Prateek Jain, and Praneeth Netrapalli. 493
The pitfalls of simplicity bias in neural networks. Advances in Neural Information Processing 494
Systems , 33:9573–9585, 2020. 495
[39] Pang Wei Koh, Shiori Sagawa, Henrik Marklund, Sang Michael Xie, Marvin Zhang, Akshay 496
Balsubramani, Weihua Hu, Michihiro Yasunaga, Richard Lanas Phillips, Irena Gao, Tony Lee, 497
Etienne David, Ian Stavness, Wei Guo, Berton Earnshaw, Imran Haque, Sara M Beery, Jure 498
Leskovec, Anshul Kundaje, Emma Pierson, Sergey Levine, Chelsea Finn, and Percy Liang. 499
Wilds: A benchmark of in-the-wild distribution shifts. In Marina Meila and Tong Zhang, 500
editors, Proceedings of the 38th International Conference on Machine Learning , volume 139 of 501
Proceedings of Machine Learning Research , pages 5637–5664. PMLR, 18–24 Jul 2021. URL 502
https://proceedings.mlr.press/v139/koh21a.html . 503
[40] Sara Beery, Grant Van Horn, and Pietro Perona. Recognition in terra incognita. In Proceedings 504
of the European Conference on Computer Vision (ECCV) , September 2018. 505
12A Related Work 506
Robustness to spurious correlation is a critical concern across various machine learning subfields. 507
It is a form of out-of-distribution generalization [ 31] where the distribution shift arises from the 508
disproportionate representation of minority groups—those instances that are devoid of the correlated 509
spurious patterns associated with their labels [ 4]. The issue of spurious correlation also intersects 510
with the discourse on fairness in machine learning. [32, 33]. 511
Past studies have proposed a range of strategies to mitigate the models’ reliance on spurious correla- 512
tion. Broadly speaking, these methods can be categorized according to the degree of supervision they 513
require regarding group labels. 514
Invariant learning (IL) methods [ 18,34,35] operate under the assumption of having access to a 515
collection of environments that comprise group shift. By imposing invariant conditions on these envi- 516
ronments, IL methods strive to create classifiers robust against group-sensitive features. IRM [ 18] is 517
designed to learn a feature extractor, which, when utilized, guarantees the existence of a classifier that 518
would be optimal in all training environments. VREx [ 34] aims to decrease the risk variance among 519
different training environments. PGI [ 36] works by minimizing the distance between the expected 520
softmax distribution of labels, conditioned on inputs across both majority and minority environments. 521
Lastly, Fishr [ 35] focuses on bringing the variance of risk gradients closer together across different 522
training environments. For scenarios which environments are not available, environment inference 523
methods [ 12,22] are used to obtain a set of environments. Creager et al. [12] introduce environment 524
inference for invariant learning (EIIL), which tries to partition samples into two groups such that the 525
objective of IRM [ 18] is maximized. HRM [ 22] aims to optimize both an environment inference 526
module and an invariant prediction module jointly, with the goal of achieving an invariant predictor. 527
When group annotations are accessible, various methods leverage this information to equalize the 528
impact of different groups on the model’s loss. The Group Distributionally Robust Optimization 529
(GDRO) approach [ 7], for instance, focuses on optimizing the loss for the worst-performing group 530
during training. Kirichenko et al. [1]has shown that models can still learn and extract core data 531
features even in the presence high spurious correlation. Consequently, They suggest that retraining 532
just the last layer of a model initially trained with Empirical Risk Minimization (ERM) can effectively 533
reduce reliance on spurious correlation for predicting class labels. This method, termed Deep Feature 534
Re-weighting (DFR), has been validated as not only highly effective but also significantly more 535
efficient than earlier techniques that necessitated retraining the full model [ 8,7]. However, availability 536
of group annotations is considered a serious restrictive assumption. 537
Several recent studies have endeavored to enhance model robustness against spurious correlation, 538
even in the absence of group annotations [ 5,24,9,2,6]. Liu et al. [5]introduce a two-stage method 539
that involves training a model using ERM for a number of epochs before retraining it to give more 540
weight to misclassified samples. The study by Zhang et al. [24] employs the same two-stage training 541
process, but with a twist for the second stage: they utilize contrastive methods. The goal is to 542
bring samples from the same class but with divergent predictions closer in the feature space, while 543
simultaneously increasing the separation between samples from different classes that have similar 544
predictions. Another method, known as automatic feature reweighting (AFR) [ 9], reweights the last 545
layer of an ERM-pretrained model to favor samples that the original model was less accurate on. 546
LaBonte et al. [2]refine the last layer of an ERM-trained model through class-balanced finetuning, 547
identifying challenging data points by comparing the classifier’s predictions with those of an early- 548
stopped version. While these methods have significantly reduced the reliance on group annotations, 549
some are still required for validation and model selection. This remains a constraint, particularly 550
when the spurious correlation is completely unknown. 551
For making a trained model robust to spurious correlation with zero group annotations, recently, 552
LaBonte et al. [2]have empirically demonstrated that the class-balanced retraining of a model 553
pretrained with ERM can effectively improve the WGA for certain datasets. However, this approach 554
fails in datasets with a high degree of spurious correlation. 555
13Table 3: The average and variation percentage (%)(across 3 seeds) of group shift between the
inferred environments using EIIL [ 12] for each class, which is the absolute difference between the
proportion of a minority group in the two environments of a class. Higher group shift indicates better
separation of environments. In most cases, a significant group shift is observed between the inferred
environments.
Class No.Dataset
Waterbirds CelebA UrbanCars
0 16 .6±0.7 3.6±0.217.7±1.2,23.5±0.1,62.1±1.9
1 50 .5±0.314.1±0.940.7±7.9,13.8±0.1,19.2±3.9
B Environment Inference for Invariant Learning 556
Consider the training dataset Dtr={(x(i), y(i))|x(i)∈ X, y(i)∈ Y} , where XandYrepresent the 557
input and output spaces, respectively. This dataset can be partitioned into different environments 558
Etr={e1, ..., e n}, such that for any i̸=j, the data distribution in eiandejdiffers. The objective 559
of invariant learning is to train a predictor that performs consistently across all environments in Etr. 560
Under certain conditions, this predictor is also expected to perform well on etst, a test environment 561
with a distribution distinct from the training data. Invariant Risk Minimization (IRM) [ 18] approaches 562
this problem by learning a feature extractor Φ(.)such that a classifier ω(.)exists, where ω◦Φ(.) 563
performs consistently across all training environments. The practical implementation of the IRM 564
objective is to minimize 565X
e∈EtrRe(Φ) + λ||∇¯ωRe(¯ω◦Φ)||2, (2)
where ¯ωis a constant scalar with a value of 1.0,λis a hyperparameter, and Re(f) = 566
E(x,y)∼pe[l(f(x), y)]is referred to as the risk on environment e. 567
In real-world scenarios, training environments might not always be available. To address this, 568
Environment Inference for Invariant Learning (EIIL) [ 12] partitions samples into two environments 569
in a way that maximizes the objective in Eq 2. 570
During the training phase, the EIIL algorithm replaces the hard assignment of environments to 571
samples with a soft assignment qi(e) =p(e|(x(i), y(i)), where qiis learnable. Consequently, the 572
relaxed version of the risk function is defined as ˜Re(Φ) =1
NPN
iqi(e)[l(Φ(x(i)), y(i))]. Given a 573
model Φthat has been trained with ERM on the dataset, EIIL optimizes 574
q∗= arg max
q||∇¯ω˜Re(¯ω◦Φ)||. (3)
As discussed in Creager et al. [12], using a biased base model Φcould lead to environments exhibiting 575
varying degrees of spurious correlation. During the inference phase, the soft assignment is converted 576
to a hard assignment. The average group shift between the inferred environments using EIIL is 577
illustrated in Table 3. 578
14C Theoretical Analysis 579
In this section, we establish a more formal description of loss-based sampling for balanced dataset 580
creation and then prove it. We thoroughly analyze the close relationship between the availability of 581
the balanced dataset and the gap between spurious features of minority and majority groups. 582
Consider a binary classification problem with a cross-entropy loss function. Let logits be denoted 583
asL. Because loss is a monotonic function of logits, the tails of the distribution of loss across 584
samples are equivalent to that of the logits in each class. We assume that in feature space (output 585
ofgθ) samples from the minority and majority of a class are derived from Gaussian distributions 586
N(hmin, t2
minId)andN(hmaj, t2
majId), respectively. Before diving into the group balance problem we 587
initially show that the distribution of minority and majority samples in the logit space (output of hϕ) 588
are Gaussian too. 589
Lemma C.1 (Gaussain Distribution of Logits) .ifZ∼ N(h, t2Id)in feature space and W∈Rd590
then logits L=⟨W, Z⟩ ∼ N 
Wh, t2∥W∥2
591
Proof. LetZ∼ N(h, t2Id). 592
Consider the linear combination L=⟨W, Z⟩=WTZ, where W∈Rdwhich is a univariate 593
gaussian. 594
To find the distribution of L, we need to determine its mean and variance. 595
1.Mean of L 596
E[L] =E[⟨W, Z⟩] =E[WTZ] =WTE[Z] =WTh=⟨W, h⟩.
Therefore, the mean of LisWh. 597
2.Variance of L: 598
The variance of Lcan be computed using the properties of covariance. Recall that if Z∼ N(h, t2Id), 599
then the covariance matrix of Zist2Id. 600
The variance of the linear combination L=WTZis given by: 601
Var(L) = Var( WTZ) =WTCov(Z)W.
Given Cov(Z) =t2Id, we have: 602
Var(L) =WT(t2Id)W=t2WTIdW=t2∥W∥2,
where ∥W∥denotes the Euclidean norm of W. 603
Combining the mean and variance results, we conclude that Lis normally distributed with mean Wh 604
and variance t2∥W∥2: 605
L=⟨W, Z⟩ ∼ N (Wh, t2∥W∥2).
Thus, we have proved that if Z∼ N(h, t2Id), then the logits L=⟨W, Z⟩follow the distribution 606
N(Wh, t2∥W∥2). 607
From now on, we consider N(µmin, σ2
min)andN(µmaj, σ2
maj)as the distribution of minority and 608
majority samples in logits space. 609
Next, we prove the more formal version of the main proposition 3.1 which describes the existence of 610
a balanced dataset, only after we define a key concept, proportional density difference (illustrated in 611
figure 4) to outline our proof. 612
15Definition C.1 (Proportional Density Difference) .For any interval I= (a, b]and a mixture dis-
tribution εP1(x) + (1 −ε)P2(x), proportional density difference is defined by the difference of
accumulation of two component distributions in the interval Iand is denoted by ∆εPmixture (I).
∆εPmixture (I)∆=εP1 
x∈I
−(1−ε)P2 
x∈I
Definition C.2 (Tail Proportional Density Difference) .For a mixture distribution εP1(x) + (1 − 613
ε)P2(x), we define tailL(α)as∆εPmixture
(−∞, α]
andtailR(β)as−∆εPmixture
(β,+∞)
. 614
Corollary C.1.
tailL(α) =εF1(α)−(1−ε)F2(β)
tailR(α) = (1 −ε)
1−F2(β)
−ε
1−F1(β)
where F1andF2are CDF of two component distributions. 615
Proportional Density Diﬀerence
I/epsilon1=0.4
majority
minority
(a)
β αtailR(β) tailL(α)/epsilon1=0.4
majority
minority (b)
Figure 4: (a) Illustration of proportion density difference C.1, (b) equation of tailL(α) =tailR(β)
at C.2.
Proposition C.1 (Feasiblity Of Loss-based Group Balancing) .Suppose that Lis derived from 616
the mixture of two distributions N(µmin, σ2
min)andN(µmaj, σ2
maj)with proportion of εand1−ε, 617
respectively, where ε≤1
2. There exists αandβsuch that restricting Lto the α-left and β-right tails 618
of its distribution results in a group-balanced distribution if and only if σmin≥σmajor 619
tailL(−B+√
∆
2A)>0 (4)
and 620
ϵ≥sigmoid 
−(µmaj−µmin2
2(σ2
maj−σ2
min)−logσmaj
σmin!
(5)
where A=
1
2σ2
maj−1
2σ2
min
,B=
µmin
σ2
min−µmaj
σ2
maj
and∆ =(µmin−µmaj)2
σ2
minσ2
maj−4h
log
σmaj
σmin
+ 621
log
ϵ
1−ϵih
1
2σ2
maj−1
2σ2
mini
. 622
Proof outline Our proof proceeds with three steps. First, we reformulate the theorem as an equality 623
of left- and right-tail proportional distribution differences. In other words, we show that the more 624
mass the minority distribution has on one tail, the more mass the majority distribution must have on 625
the other tail. Afterward, supposing µmin< µ majWOLG, we propose a proper range for βvalues 626
on the right tail. We show that when σmaj≤σmin, values for αtrivially exist that can overcome the 627
imbalance between the two distributions. In the last step, for the case in which the variance of the 628
majority is higher than the minority, we discuss a necessary and sufficient condition for the existence 629
ofαandβbased on the left-tail proportional density difference using the properties of its derivative 630
with respect to α. 631
16Step 1 Reformulating the problem based on proportional distribution difference. 632
We introduce a utility random variable Logit Value Tier asT, which is defined as a function of a 633
random variable L. 634
Tα,β=

High ifL≥β
Mid ifα < L < β
Low ifL≤α(6)
We can rewrite the problem in formal form as finding an αandβwhich satisfies the following 635
equation: 636
P
g=minTα,β̸=Mid
=P
g=majTα,β̸=Mid
(7)
Equation 5 now can be rewritten to a more suitable form: 637
P
g=minTα,β̸=Mid
=P
g=majTα,β̸=Mid
(8)
⇐⇒P
Tα,β̸=Midg=min
P 
g=min
P
Tα,β̸=Mid =P
Tα,β̸=Mid|g=maj
P 
g=maj
P
Tα,β̸=Mid (9)
⇐⇒ P
Tα,β̸=Midg=min
P 
g=min
=P
Tα,β̸=Midg=maj
P 
g=maj
(10)
⇐⇒ εP
Tα,β̸=Midg=min
= (1−ε)P
Tα,β̸=Midg=maj
(11)
⇐⇒ ε
P
Tα,β=Lowg=min
+P
Tα,β=Highg=min
= (12)
(1−ε)
P
Tα,β=Lowg=maj
+P
Tα,β=Highg=maj
(13)
⇐⇒ ε
P
L≤αg=min
+P
L≥βg=min
= (14)
(1−ε)
P
L≤αg=maj
+P
L≥βg=maj
(15)
⇐⇒ ε
Fmin(α) +
1−Fmin(β)
= (1−ε)
Fmaj(α) +
1−Fmaj(β)
(16)
⇐⇒ εFmin(α)−(1−ε)Fmaj(α) = (1 −ε)h
1−Fmaj(β)i
−εh
1−Fmin(β)i
(17)
We can see the left side of equation 17 is just a function of alpha . The same goes for the right side of 638
the equation which is a function of β. 639
Rewriting the left side of the equation as tailL(α)and right side as tailR(β), the problem is now 640
reduced to finding an αandβthat satisfies 641
tailL(α) =tailR(β) (18)
which is shown in figure 4. 642
Before reaching out to step two we discuss the properties of tailLandtailRin Lemma C.2. 643
Lemma C.2. tailL(α)andtailR(β)are continuous functions and limα→−∞ tailL(α) = 0 , 644
limα→+∞tailL(α) = 2 ε−1<0,limβ→+∞tailR(β) = 0 andlimβ→−∞ tailR(β) = 1−2ε >0. 645
646
Proof. Simply proved by the definition of tailfunctions and properties of CDF. 647
Step 2 Solving the equation 18 for simple cases. 648
17Lemma C.3. tailR(µmaj)>1
2−ε≥0 649
Proof.
tailR(µmaj) = (1 −ε)h
1−Fmaj(µmaj)i
−εh
1−Fmin(µmaj)i
(19)
= (1−ε)h
1−ϕ(0)i
−εh
1−ϕ µmaj−µmin
σmini
(20)
>(1−ε)
2−ε 
1−1
2
=1−2ε
2=1
2−ε (21)
650
Corollary C.2. Because tailRis continuous and limβ→+∞tailR(β) = 0 , based on the mean value 651
theorem, any value between zero and(1−2ε)
2is obtainable by selecting a βin[µ2,+∞). 652
According to the previous corollary C.2 finding a positive tailL(α)will satisfy our need. to find a 653
suitable point, we employ derivatives and properties of relative PDFs to maximize tailL(α)and find 654
a positive value. 655
dtailL(α)
dα=εfmin(α)−(1−ε)fmaj(α) =εfmaj(α)hfmin(α)
fmaj(α)−1−ε
εi
(22)
The term [fmin(α)
fmaj(α)−1−ε
ε]has the same sign with derivative of tailL(α), also it’s roots are critical 656
points of tailL, analyzing characteristics of logfmin(α)
fmaj(α)is the key insight to find a proper αvalue. 657
logfmin(α)−logfmaj(α) = log1−ϵ
ϵ
⇒logσmaj
σmin
−log1−ϵ
ϵ
−(α−µmin)2
2σ2
min+(α−µmaj)2
2σ2
maj= 0
⇒1
2σ2
maj−1
2σ2
min
α2+µmin
σ2
min−µmaj
σ2
maj
α+hµ2
maj
2σ2
maj−µ2
min
2σ2
min+ logσmaj
σmin
+ logϵ
1−ϵi
= 0
Because limα→−∞ tailL(α) = 0 andlimβ→+∞tailR(β)<0to have a positive tailL(α)we need 658
to have an interval whichdtailL(α)
dαis positive, for a second degree polynomial like ax2+bx+cto 659
have positive value, either a≥0or∆>0, in our case ais
1
σ2
maj−1
σ2
min
. ifσmin≥σmajthena≥0 660
and the minority CDF function will dominate the majority CDF function in the left-side tail and by 661
choosing a negative number with big enough absolute value for alpha and tailL(α)will be positive. 662
Step 3 Solving equation 18 for special case σmin< σmajIn case of σmin≤σmaj, having ∆>0 663
is a necessary condition, also derivative of tailL(α)is only positive in (−b−√
∆
2a,−b+√
∆
2a)so the 664
maximum of tailLis either in −∞ or in−b+√
∆
2a. Having tailL(−b+√
∆
2a)>0next to ∆>0 665
condition, would be the necessary and also sufficient in this case. 666
B2=µ2
min
σ4
min+µ2
maj
σ4
maj−2µmajµmin
σ2
majσ2
min
4AC=µ2
min
σ4
min−µ2
min
σ2
majσ2
min−µ2
maj
σ2
majσ2
min+µ2
maj
σ4
maj+ 4h
logσmaj
σmin
+ logϵ
1−ϵih1
2σ2
maj−1
2σ2
mini
18=0.35
majority
minority(a)
=0.4
majority
minority (b)
=0.45
majority
minority (c)
Figure 5: Tail thresholds for three cases: (a) minority group variance is less than majority ( σmin<
σmaj), (b) the variance of two groups are equal ( σmin=σmaj) and (c) the variance of the minority
group is more than majority ( σmin> σ maj).
∆ =(µmin−µmaj)2
σ2
minσ2
maj−4h
logσmaj
σmin
+ logϵ
1−ϵih1
2σ2
maj−1
2σ2
mini
≥0
⇐⇒ (µmin−µmaj)2≥2h
log1−ϵ
ϵ
−logσmaj
σminih
σ2
maj−σ2
mini
⇐⇒ ϵ≥sigmoid 
−(µmaj−µmin2
2(σ2
maj−σ2
min)−logσmaj
σmin!
Next, we investigate properties of the conditions of the proposition C.1 in case of σmaj< σ min. 667
Schematic interpretation of these conditions is presented in figure 6. 668
•As equation 5 indicates, the minority group is not allowed to be too underrepresented. This 669
especially has a direct relation with the difference of means. The more mean values of 670
groups are different, the more imbalance can be mitigated through loss-based sampling. 671
Mean value difference is especially affected by the spurious correlation, it escalates as the 672
model relies on spurious correlation and also when the spurious features between groups are 673
too different. 674
•On the other hand condition 4 is more complex and doesn’t have a simple closed form, we 675
analytically describe its behaviors by fixating the means and calculating the valid values for 676
ε. As the results show in figure 6, most of εare feasible in for σmin<∆µas we can see the 677
possible region declines with an increase of σminand valid εvalues cease to exist. 678
19max
S1
S2
>0
=0.27
majority
minority(a)
0 1 2 3 4 5
σmin012345σmaj
0.00000.10530.21050.31580.42110.52630.63160.73680.84210.9474 (b)
0 1 2 3 4 5
σmin012345σmaj
0.00000.10530.21050.31580.42110.52630.63160.73680.84210.9474
(d)
0 1 2 3 4 5
σmin012345σmaj
0.00000.10530.21050.31580.42110.52630.63160.73680.84210.9474 (c)
Figure 6: (a) Conditions if σmin> σ maj, (b), (c), (d) Minimum, maximum and interval length of
feasible εvalues across (σmin, σmaj)field for µmin= 0,µmaj= 1.
20Table 4: A comparison of the various methods, ours included, on spurious correlation datasets. The
Group Info column indicates if each method utilizes group labels of the training/validation data,
with✓ ✓denoting that group information is employed during both the training and validation stages.
Both the average test accuracy and worst test group accuracy are reported. The mean and standard
deviation are calculated over three runs with different seeds. The numbers in bold represent the
highest results among all methods, while the underlined numbers represent the best results among
methods that do not require group annotation in the training phase.
MethodGroup Info Waterbirds CelebA UrbanCars
Train/Val Worst Best Worst Best Worst Best
GDRO [7] ✓/✓ 91.4 93 .5 88.9 92.9 - -
DFR [1] ✗/✓ ✓ 92.9±0.294.2±0.488.3±1.191.3±0.3 79.6±2.22 87.5±0.6
GDRO + EIIL [12] ✗/✓ 77.2±196.5±0.281.7±0.885.7±0.1 - -
JTT [5] ✗/✓ 86.7 93 .3 81 .1 88 .0 - -
AFR [9] ✗/✓ 90.4±1.1 94.21.2 82.0±0.591.3±0.3 80.2±2.0 87.1±1.2
EVaLS-GL (Ours) ✗/✓ 89.4±0.395.1±0.384.6±1.691.1±0.682.27±1.1688.2±0.6
ERM ✗/✗ 66.4±2.390.3±0.547.4±2.395.5±0.018.67±2.01 76.5±4.6
EVaLS (Ours) ✗/✗ 88.4±3.194.1±0.185.3±0.489.4±0.582.13±0.92 88.1±0.9
Table 5: A comparison of the various methods, ours included, on CivilComments and MultiNLI.
The Group Info column indicates if each method utilizes group labels of the training/validation data,
with✓ ✓denoting that group information is employed during both the training and validation stages.
Both the average test accuracy and worst test group accuracy are reported. The mean and standard
deviation are calculated over three runs with different seeds. The numbers in bold represent the
highest results among all methods, while the underlined numbers represent the best results among
methods that do not require group annotation in the training phase.
MethodGroup Info CivilComments MultiNLI
Train/Val Worst Best Worst Best
GDRO [7] ✓/✓ 69.9 88 .9 77.7 81.4
DFR [1] ✗/✓ ✓ 70.1±0.8 87.2±0.374.7±0.782.1±0.2
GDRO + EIIL [12] ✗/✓ 67.0±2.4 90.5±0.2 - -
JTT [5] ✗/✓ 69.3 91 .1 72 .6 78 .6
AFR [9] ✗/✓ 68.7±0.6 89.8±0.673.4±0.681.4±0.2
EVaLS-GL (Ours) ✗/✓ 80.5±0.488.0±0.475.1±1.281.6±0.2
ERM ✗/✗ 61.2±3.692.0±0.064.8±1.982.6±0.0
D Experimental Details 679
D.1 Complete Results 680
The complete results on Waterbirds, CelebA, and UrbanCars, in addition to complete results on 681
CivilComments and MultiNLI are reported in Tables 4 and 5 respectively. The results for all methods 682
except Group DRO + EIIL on all datasets except UrbanCars are reported by Qiu et al. [9]. The 683
results for Group DRO + EIIL are taken from Zhang et al. [24]. Also, the results of our method and 684
DFR are shown in Table 6 685
D.2 Dominoes-Colored-MNIST-FashionMNIST 686
Dominoes-Colored-MNIST-FashionMNIST (Dominoes-CMF) is a synthetic dataset. We adopt 687
a similar approach to previous works [ 37,38,1] using a modified version of the Dominoes binary 688
classification dataset. This dataset consists of images with the top half showing CIFAR-10 images 689
[19], divided into two meaningful classes: vehicles (airplane, car, ship, truck) and animals (cat, 690
dog, horse, deer). The bottom half displays either MNIST [ 20] images from classes {0−3}or 691
Fashion-MNIST [ 21] images from classes {T-shirt ,Dress ,Coat,Shirt}. The complex feature (top 692
21Table 6: A Comparison of ERM, DFR, EVaLS, and EVaLS-GL on the Dominoes-CMF Dataset. Both
the worst and average of test group accuracies are presented. The mean and standard deviation are
calculated based on runs with three distinct seeds.
Method Worst Average
ERM 50.6±1.084.1±0.0
DFR 60.2±1.284.6±0.4
EVaLS-GL 63.6±1.378.7±1.5
EVaLS 67.1±4.278.6±2.0
half) serves as the core feature and the simple feature (bottom half) is linearly separable and correlated 693
with the class label at 75%. Furthermore, inspired by the approaches in Zhang et al. [24], Arjovsky 694
et al. [18], we intentionally introduce an additional spurious attribute by artificially coloring a subset 695
of images in the following manner: 90% of the bottom half images in class c1are randomly assigned 696
a red color, while 10% are assigned a green color, and vice versa for class c2. See Table 7 for more 697
details about the dataset statistics.
Table 7: Dominoes-CMF Dataset Statistics
Top part Bottom part
CIFAR-10 Class Color MNIST Fashion-MNIST
c1(Vehicle)Red 13,500 4,500
Green 1,500 500
c2(Animal)Red 500 1,500
Green 4,500 13,500
Total 40,000
698
Table 8: ERM Accuracies on Dominoes-CMF Dataset. The mean and standard deviation are reported
based on three runs with different seeds.
Top part Bottom part
CIFAR-10 Class Color MNIST Fashion-MNIST
c1(Vehicle)Red 99.2±0.01% 95 .21.1%
Green 84.5±2.4% 54 .7±0.5%
c2(Animal)Red 56.8±5.6% 86 .7±2.4%
Green 96.2±0.5% 99 .3±0.2%
D.3 Datasets 699
Waterbirds [ 7]The dataset comprises images of diverse bird species, classified into two categories: 700
waterbirds and landbirds. Each image features a bird set against a backdrop of either water or land. 701
Interestingly, the background scene acts as a spurious feature in this classification task. Waterbirds are 702
primarily shown against water backgrounds, and landbirds against land backgrounds. Consequently, 703
waterbirds on water and landbirds on land form the minority groups in the training data. It’s important 704
to note that the validation dataset for waterbirds is group-balanced, meaning birds from each class are 705
equally represented against both water and land backgrounds. This dataset is mainly categorized as a 706
spurious correlation dataset. 707
CelebA [ 13]is a widely used dataset in image classification tasks, featuring annotations for 40 708
binary facial attributes such as hair color, gender, and age. Hair color classification is particularly 709
prominent in literature focusing on spurious correlation robustness. Notably, gender serves as a 710
spurious attribute within this dataset, where a significant majority 94% of individuals with blond hair 711
22/uni00000013 /uni00000015/uni00000018 /uni00000018/uni00000013 /uni0000001a/uni00000018 /uni00000014/uni00000013/uni00000013
/uni00000008/uni00000003/uni00000052/uni00000049/uni00000003/uni0000002b/uni0000004c/uni0000004a/uni0000004b/uni00000010/uni0000002f/uni00000052/uni00000056/uni00000056/uni00000003/uni00000036/uni00000044/uni00000050/uni00000053/uni0000004f/uni00000048/uni00000013/uni00000018/uni00000014/uni00000013/uni00000014/uni00000018/uni00000015/uni00000013/uni00000008/uni00000003/uni00000052/uni00000049/uni00000003/uni00000030/uni0000004c/uni00000051/uni00000052/uni00000055/uni0000004c/uni00000057/uni0000005c/uni00000003/uni00000036/uni00000044/uni00000050/uni00000053/uni0000004f/uni00000048/uni00000056/uni00000046/uni0000004f/uni00000044/uni00000056/uni00000056/uni00000003/uni00000014
/uni00000046/uni0000004f/uni00000044/uni00000056/uni00000056/uni00000003/uni00000015
/uni00000046/uni0000004f/uni00000044/uni00000056/uni00000056/uni00000003/uni00000016
/uni00000013 /uni00000015/uni00000018 /uni00000018/uni00000013 /uni0000001a/uni00000018 /uni00000014/uni00000013/uni00000013
/uni00000008/uni00000003/uni00000052/uni00000049/uni00000003/uni0000002f/uni00000052/uni0000005a/uni00000010/uni0000002f/uni00000052/uni00000056/uni00000056/uni00000003/uni00000036/uni00000044/uni00000050/uni00000053/uni0000004f/uni00000048/uni00000017/uni00000013/uni00000019/uni00000013/uni0000001b/uni00000013/uni00000014/uni00000013/uni00000013/uni00000008/uni00000003/uni00000052/uni00000049/uni00000003/uni00000030/uni00000044/uni0000004d/uni00000052/uni00000055/uni0000004c/uni00000057/uni0000005c/uni00000003/uni00000036/uni00000044/uni00000050/uni00000053/uni0000004f/uni00000048/uni00000056/uni00000046/uni0000004f/uni00000044/uni00000056/uni00000056/uni00000003/uni00000014
/uni00000046/uni0000004f/uni00000044/uni00000056/uni00000056/uni00000003/uni00000015
/uni00000046/uni0000004f/uni00000044/uni00000056/uni00000056/uni00000003/uni00000016(a) MultiNLI
/uni00000013 /uni00000015/uni00000013 /uni00000017/uni00000013 /uni00000019/uni00000013 /uni0000001b/uni00000013 /uni00000014/uni00000013/uni00000013
/uni00000008/uni00000003/uni00000052/uni00000049/uni00000003/uni0000002b/uni0000004c/uni0000004a/uni0000004b/uni00000010/uni0000002f/uni00000052/uni00000056/uni00000056/uni00000003/uni00000036/uni00000044/uni00000050/uni00000053/uni0000004f/uni00000048/uni00000013/uni00000015/uni00000013/uni00000017/uni00000013/uni00000019/uni00000013/uni0000001b/uni00000013/uni00000008/uni00000003/uni00000052/uni00000049/uni00000003/uni00000030/uni0000004c/uni00000051/uni00000052/uni00000055/uni0000004c/uni00000057/uni0000005c/uni00000003/uni00000036/uni00000044/uni00000050/uni00000053/uni0000004f/uni00000048/uni00000056/uni00000046/uni0000004f/uni00000044/uni00000056/uni00000056/uni00000003/uni00000014/uni0000000b/uni0000004a/uni00000055/uni00000052/uni00000058/uni00000053/uni00000003/uni00000014/uni0000000c
/uni00000046/uni0000004f/uni00000044/uni00000056/uni00000056/uni00000003/uni00000014/uni0000000b/uni0000004a/uni00000055/uni00000052/uni00000058/uni00000053/uni00000003/uni00000015/uni0000000c
/uni00000046/uni0000004f/uni00000044/uni00000056/uni00000056/uni00000003/uni00000014/uni0000000b/uni0000004a/uni00000055/uni00000052/uni00000058/uni00000053/uni00000003/uni00000016/uni0000000c
/uni00000046/uni0000004f/uni00000044/uni00000056/uni00000056/uni00000003/uni00000015/uni0000000b/uni0000004a/uni00000055/uni00000052/uni00000058/uni00000053/uni00000003/uni00000017/uni0000000c
/uni00000046/uni0000004f/uni00000044/uni00000056/uni00000056/uni00000003/uni00000015/uni0000000b/uni0000004a/uni00000055/uni00000052/uni00000058/uni00000053/uni00000003/uni00000018/uni0000000c
/uni00000046/uni0000004f/uni00000044/uni00000056/uni00000056/uni00000003/uni00000015/uni0000000b/uni0000004a/uni00000055/uni00000052/uni00000058/uni00000053/uni00000003/uni00000019/uni0000000c
/uni00000013 /uni00000015/uni00000013 /uni00000017/uni00000013 /uni00000019/uni00000013 /uni0000001b/uni00000013 /uni00000014/uni00000013/uni00000013
/uni00000008/uni00000003/uni00000052/uni00000049/uni00000003/uni0000002f/uni00000052/uni0000005a/uni00000010/uni0000002f/uni00000052/uni00000056/uni00000056/uni00000003/uni00000036/uni00000044/uni00000050/uni00000053/uni0000004f/uni00000048/uni00000017/uni00000013/uni00000019/uni00000013/uni0000001b/uni00000013/uni00000014/uni00000013/uni00000013/uni00000008/uni00000003/uni00000052/uni00000049/uni00000003/uni00000030/uni00000044/uni0000004d/uni00000052/uni00000055/uni0000004c/uni00000057/uni0000005c/uni00000003/uni00000036/uni00000044/uni00000050/uni00000053/uni0000004f/uni00000048/uni00000056/uni00000046/uni0000004f/uni00000044/uni00000056/uni00000056/uni00000003/uni00000014
/uni00000046/uni0000004f/uni00000044/uni00000056/uni00000056/uni00000003/uni00000015 (b) UrbanCars
Figure 7: The proportion of minority and majority samples across different classes within various
percentages of DLLsamples with highest and lowest loss for the MultiNLI (a) and UrbanCars (b)
datasets. MultiNLI exhibits attribute imbalance rather than spurious correlation, which explains its
different behavior compared to Waterbirds and CelebA.
are women, while men with blond hair represent a minority group. In addition to spurious correlation 712
in the class of blond hair, this dataset also exhibits class imbalance. 713
MultiNLI [ 15]dataset involves a text classification task focused on determining the relationship 714
between pairs of sentences: contradiction, entailment, or neutral. Sentences containing negation 715
words such as "no" or "never" are under-represented in all three classes, inducing attribute imbalance 716
in the dataset. Figure 7 illustrates the distinct behavior of this dataset compared to other datasets that 717
contain spurious attributes. 718
CivilComments [ 16]dataset, as part of the WILDS benchmark, involves a text classification task 719
focused on labeling online comments as either "toxic" or "not toxic". Each comment is associated 720
with 8 attributes, including gender (male, female), sexual orientation (LGBTQ), race (black, white), 721
and religion (Christian, Muslim, or other), based on whether these characteristics are mentioned 722
in the comment. While there is a small attribute imbalance in the dataset, it can categorized into 723
datasets with class imbalance. In this paper, we use the implementation of the dataset by the WILDS 724
package [39]. 725
UrbanCars [ 14]is an image classification dataset with multiple shortcuts. Each image in the 726
dataset consists of a car in the center of the image on a natural scene background, with another object 727
to the right of the image. Images are labeled Urban orCity according to the type of car present in 728
the center. However, each of the backgrounds and the additional objects is highly correlated with 729
the label. While the test set consists of 8 environments based on combinations of the core and two 730
spurious patterns, the training and validation set consist of four groups, based on combinations of the 731
label and only one of the shortcuts. 732
D.4 Training Details 733
ERM For Waterbirds and CelebA, we utilize the ResNet50 checkpoints available in 734
the GitHub repository of Kirichenko et al. [1] as our base model. We use the 735
ResNet-50 architecture provided by the torchvision package. In the case of Civil- 736
Comments and MultiNLI, we adopt a similar approach to Kirichenko et al. [1], using 737
BertForSequenceClassification.from_pretrained(’bert-base-uncased’, ...) from 738
thetransformers package. The model is trained using the AdamW optimizer with a learning 739
rate of 10−5, weight decay of 10−4, and a batch size of 16 for a total of 5 epochs. 740
For the UrbanCars dataset, we adhere to the settings described in Li et al. [14], which involves 741
training a ResNet-50 model pretrained on ImageNet using the SGD optimizer with a learning rate 742
of10−3, momentum of 0.9, weight decay of 10−4, and a batch size of 128 for 300 epochs. For the 743
Dominoes-CMF dataset, we train a ResNet18 model pretrained on ImageNet for 20 epochs with a 744
batch size of 128 and an SGD optimizer with a learning rate of 10−3, momentum of 0.9, and weight 745
decay of 10−4. 746
EVaLS and EVaLS-GL For every dataset, EIIL was utilized with a learning rate of 0.01, a total of 747
20000 steps, and a batch size of 128. The last layer of the model was trained on all datasets using the 748
23Adam optimizer. A batch size of 32 and a weight decay of 10−4were used for all datasets. Our method 749
was evaluated on the validation sets of each dataset, considering both fine-tuning and retraining of the 750
last layer. For all datasets, with the exception of MultiNLI, retraining provided superior validation 751
results. The specifics regarding the number of epochs and the ranges for hyperparameter search 752
(including learning rate, l1-regularization coefficient ( λ), and the number of selected samples ( k)) for 753
each dataset are as follows: 754
•Waterbirds . 755
–epochs = 100, 756
–lr =5×10−4, 757
–λ∈ {0,0.01,0.02,0.03,0.04,0.05,0.06,0.07,0.08,0.09,0.1,0.2,0.3,0.4,0.5}, 758
–k∈ {20,25,30,35,40,45,50,55,60}. 759
•CelebA 760
–epochs = 50, 761
–lr =5×10−4, 762
–λ∈ {0,0.01,0.02,0.03,0.04,0.05,0.06,0.07,0.08,0.09,0.1,0.2,0.3,0.4,0.5, 763
0.6,0.7,0.8,0.9,1,2}, 764
–k∈ {50,100,150,200,250,300}. 765
•UrbanCars 766
–epochs = 100, 767
–lr∈{5×10−4,10−3}, 768
–λ∈ {0,0.01,0.02,0.05,0.1,1}, 769
–k∈ {10,20,30,50,63}. 770
•CivilComments 771
–epochs = 50, 772
–lr =5×10−4, 773
–λ∈ {0,0.01,0.02,0.03,0.04,0.05,0.06,0.07,0.08,0.09,0.1,0.2,0.3,0.4,0.5, 774
0.6,0.7,0.8,0.9,1,2}, 775
–k∈ {500,750,1000,1250,1500}. 776
•MultiNLI 777
–epochs = 200, 778
–lr∈ {10−2,10−3}, 779
–λ∈ {0,0.01,0.02,0.03,0.04,0.05,0.06,0.07,0.08,0.09,0.1,0.2,0.3,0.4,0.5}, 780
–k∈ {20,30,40,50,60,75,100,125,150,200,250,300}. 781
24E Ablation Study 782
E.1 Use of EIIL with DFR and AFR 783
We conducted an ablation study to investigate the impact of using environments inferred from EIIL on 784
model selection. Specifically, we benchmarked the performance of DFR and AFR with EIIL-inferred 785
groups. The results, presented in Table 9, demonstrate the effectiveness of incorporating EIIL-inferred 786
groups in model selection. The results show that while EIIL-inferred groups reduce the performance 787
compared to ground-truth annotations for model selection, they still can be effective for robustness to 788
an extent. Moreover, EVaLS outperforms these two methodw when using EIIL inferred environments. 789
Table 9: Results of DFR and AFR with EIIL-inferred environment for model selection.
Method Waterbirds Celeba
DFR (with EIIL) 92.21±0.02 85 .55±1.0
AFR (with EIIL) 82.6±0.04 72 .5±0.01
E.2 Other Group Inference Methods 790
In addition to EIIL, other group inference methods could be utilized for partitioning the model 791
selection set into environments. 792
Error Splitting JTT [ 5] partitions data into two correctly classified and misclassified sets based 793
on the predictions of a model trained with ERM. We split each of these two sets based on labels of 794
samples, obtaining |Y| × 2environments. 795
Random Classifier Splitting uses a random classifier to classify features obtained from a model 796
trained with ERM into correctly classified and misclassified sets. Similar to error splitting, we split 797
the sets based on group labels. The difference between error splitting and random classifier splitting 798
is solely in the reinitialization of the classification layer. 799
The results for EVaLS-ES (EVaLS+Error Sampling) and EVaLS-RC (EVaLS+Random Classifier) are 800
shown in Table 10. One limitation of error splitting is that in datasets with noisy labels or corrupted 801
images, samples that an ERM model misclassifies may not always belong to minority groups. In these 802
situations, choosing models based on their accuracy on corrupted data could lead to the selection of 803
models that are not robust to spurious correlations. This is demonstrated by the results of EVaLS-ES 804
on the CelebA dataset. 805
This shortcoming of error splitting can be alleviated by employing a random classifier instead of 806
the ERM-trained one. Due to the feature-level similarity between minority and majority samples in 807
datasets affected by spurious correlation [ 23,1,29], it is expected that the classifier can differentiate 808
between the groups to some extent. As shown in Table 10, surprisingly, EVaLS-RC produces results 809
that are generally comparable to EVaLS. However, the performance of this method may have high 810
variance, depending on the different initializations of the classifier. 811
Table 10: The performances of three environment inference methods, when combined with loss-based
sample selection, are evaluated on spurious correlation benchmarks. The mean and standard deviation
values are calculated over three separate runs, each initiated with a different seed.
MethodWaterbirds CelebA UrbanCars
Worst Average Worst Average Worst Average
EVaLS-ES 82.1±1.294.3±0.04 48.4±11.669.5±6.579.2±2.986.1±0.9
EVaLS-RC 88.7±1.0 94.3±1.1 78.1±5.193.5±0.282.4±3.288.2±0.8
EVaLS 88.4±3.1 94.1±0.185.3±0.489.4±0.579.4±3.1 86 .5±1.5
25F Societal Impacts 812
Real-world datasets often encapsulate social biases that stem from entrenched stereotypes and 813
historical discrimination, affecting various groups such as genders and races. Machine learning 814
methods, which learn the correlation between patterns in input data and their targets (e.g., labels 815
in a classification task) [ 40], inadvertently absorb this bias. This unintended consequence leads to 816
fairness issues in many applications. While strategies to mitigate such biases have been proposed 817
(as discussed comprehensively in Section A), societal biases are not always known and determined. 818
We believe that our work, as it addresses these unidentified biases, takes a significant step towards 819
making machine learning fairer for our society. 820
G Computational Resources 821
Each experiment was conducted on one of the following GPUs: NVIDIA A100 with 80G memory, 822
NVIDIA Titan RTX with 24G memory, Nvidia GeForce RTX 3090 with 24G memory, and NVIDIA 823
GeForce RTX 3080 Ti with 12G memory. 824
26NeurIPS Paper Checklist 825
1.Claims 826
Question: Do the main claims made in the abstract and introduction accurately reflect the 827
paper’s contributions and scope? 828
Answer: [Yes] 829
Justification: The scope of the effectiveness and main claims are clearly demonstrated in the 830
abstract and introduction. 831
Guidelines: 832
•The answer NA means that the abstract and introduction do not include the claims 833
made in the paper. 834
•The abstract and/or introduction should clearly state the claims made, including the 835
contributions made in the paper and important assumptions and limitations. A No or 836
NA answer to this question will not be perceived well by the reviewers. 837
•The claims made should match theoretical and experimental results, and reflect how 838
much the results can be expected to generalize to other settings. 839
•It is fine to include aspirational goals as motivation as long as it is clear that these goals 840
are not attained by the paper. 841
2.Limitations 842
Question: Does the paper discuss the limitations of the work performed by the authors? 843
Answer: [Yes] 844
Justification: The limitations are discussed in the discussion section. 845
Guidelines: 846
•The answer NA means that the paper has no limitation while the answer No means that 847
the paper has limitations, but those are not discussed in the paper. 848
• The authors are encouraged to create a separate "Limitations" section in their paper. 849
•The paper should point out any strong assumptions and how robust the results are to 850
violations of these assumptions (e.g., independence assumptions, noiseless settings, 851
model well-specification, asymptotic approximations only holding locally). The authors 852
should reflect on how these assumptions might be violated in practice and what the 853
implications would be. 854
•The authors should reflect on the scope of the claims made, e.g., if the approach was 855
only tested on a few datasets or with a few runs. In general, empirical results often 856
depend on implicit assumptions, which should be articulated. 857
•The authors should reflect on the factors that influence the performance of the approach. 858
For example, a facial recognition algorithm may perform poorly when image resolution 859
is low or images are taken in low lighting. Or a speech-to-text system might not be 860
used reliably to provide closed captions for online lectures because it fails to handle 861
technical jargon. 862
•The authors should discuss the computational efficiency of the proposed algorithms 863
and how they scale with dataset size. 864
•If applicable, the authors should discuss possible limitations of their approach to 865
address problems of privacy and fairness. 866
•While the authors might fear that complete honesty about limitations might be used by 867
reviewers as grounds for rejection, a worse outcome might be that reviewers discover 868
limitations that aren’t acknowledged in the paper. The authors should use their best 869
judgment and recognize that individual actions in favor of transparency play an impor- 870
tant role in developing norms that preserve the integrity of the community. Reviewers 871
will be specifically instructed to not penalize honesty concerning limitations. 872
3.Theory Assumptions and Proofs 873
Question: For each theoretical result, does the paper provide the full set of assumptions and 874
a complete (and correct) proof? 875
Answer: [Yes] 876
27Justification: All the lemmas and propositions are stated upon exact definitions, assumptions 877
and conditions. All the theorems, formulas, and proofs in the paper are numbered and 878
cross-referenced. 879
Guidelines: 880
• The answer NA means that the paper does not include theoretical results. 881
•All the theorems, formulas, and proofs in the paper should be numbered and cross- 882
referenced. 883
•All assumptions should be clearly stated or referenced in the statement of any theorems. 884
•The proofs can either appear in the main paper or the supplemental material, but if 885
they appear in the supplemental material, the authors are encouraged to provide a short 886
proof sketch to provide intuition. 887
•Inversely, any informal proof provided in the core of the paper should be complemented 888
by formal proofs provided in appendix or supplemental material. 889
• Theorems and Lemmas that the proof relies upon should be properly referenced. 890
4.Experimental Result Reproducibility 891
Question: Does the paper fully disclose all the information needed to reproduce the main ex- 892
perimental results of the paper to the extent that it affects the main claims and/or conclusions 893
of the paper (regardless of whether the code and data are provided or not)? 894
Answer: [Yes] 895
Justification: The training precedure is described accurately and all the training details and 896
hyperparameters required for reproducing the results are provided. 897
Guidelines: 898
• The answer NA means that the paper does not include experiments. 899
•If the paper includes experiments, a No answer to this question will not be perceived 900
well by the reviewers: Making the paper reproducible is important, regardless of 901
whether the code and data are provided or not. 902
•If the contribution is a dataset and/or model, the authors should describe the steps taken 903
to make their results reproducible or verifiable. 904
•Depending on the contribution, reproducibility can be accomplished in various ways. 905
For example, if the contribution is a novel architecture, describing the architecture fully 906
might suffice, or if the contribution is a specific model and empirical evaluation, it may 907
be necessary to either make it possible for others to replicate the model with the same 908
dataset, or provide access to the model. In general. releasing code and data is often 909
one good way to accomplish this, but reproducibility can also be provided via detailed 910
instructions for how to replicate the results, access to a hosted model (e.g., in the case 911
of a large language model), releasing of a model checkpoint, or other means that are 912
appropriate to the research performed. 913
•While NeurIPS does not require releasing code, the conference does require all submis- 914
sions to provide some reasonable avenue for reproducibility, which may depend on the 915
nature of the contribution. For example 916
(a)If the contribution is primarily a new algorithm, the paper should make it clear how 917
to reproduce that algorithm. 918
(b)If the contribution is primarily a new model architecture, the paper should describe 919
the architecture clearly and fully. 920
(c)If the contribution is a new model (e.g., a large language model), then there should 921
either be a way to access this model for reproducing the results or a way to reproduce 922
the model (e.g., with an open-source dataset or instructions for how to construct 923
the dataset). 924
(d)We recognize that reproducibility may be tricky in some cases, in which case 925
authors are welcome to describe the particular way they provide for reproducibility. 926
In the case of closed-source models, it may be that access to the model is limited in 927
some way (e.g., to registered users), but it should be possible for other researchers 928
to have some path to reproducing or verifying the results. 929
5.Open access to data and code 930
28Question: Does the paper provide open access to the data and code, with sufficient instruc- 931
tions to faithfully reproduce the main experimental results, as described in supplemental 932
material? 933
Answer: [Yes] 934
Justification: Codes and information of datasets that are constructed or reused in the paper 935
are anonymized and included in the main paper and supplementary material. 936
Guidelines: 937
• The answer NA means that paper does not include experiments requiring code. 938
•Please see the NeurIPS code and data submission guidelines ( https://nips.cc/ 939
public/guides/CodeSubmissionPolicy ) for more details. 940
•While we encourage the release of code and data, we understand that this might not be 941
possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not 942
including code, unless this is central to the contribution (e.g., for a new open-source 943
benchmark). 944
•The instructions should contain the exact command and environment needed to run to 945
reproduce the results. See the NeurIPS code and data submission guidelines ( https: 946
//nips.cc/public/guides/CodeSubmissionPolicy ) for more details. 947
•The authors should provide instructions on data access and preparation, including how 948
to access the raw data, preprocessed data, intermediate data, and generated data, etc. 949
•The authors should provide scripts to reproduce all experimental results for the new 950
proposed method and baselines. If only a subset of experiments are reproducible, they 951
should state which ones are omitted from the script and why. 952
•At submission time, to preserve anonymity, the authors should release anonymized 953
versions (if applicable). 954
•Providing as much information as possible in supplemental material (appended to the 955
paper) is recommended, but including URLs to data and code is permitted. 956
6.Experimental Setting/Details 957
Question: Does the paper specify all the training and test details (e.g., data splits, hyper- 958
parameters, how they were chosen, type of optimizer, etc.) necessary to understand the 959
results? 960
Answer: [Yes] 961
Justification: The training details, hyperparameters, model selection criteria, etc. have are 962
written in the Appendix and the data and metadata have been provided in our code. 963
Guidelines: 964
• The answer NA means that the paper does not include experiments. 965
•The experimental setting should be presented in the core of the paper to a level of detail 966
that is necessary to appreciate the results and make sense of them. 967
•The full details can be provided either with the code, in appendix, or as supplemental 968
material. 969
7.Experiment Statistical Significance 970
Question: Does the paper report error bars suitably and correctly defined or other appropriate 971
information about the statistical significance of the experiments? 972
Answer: [Yes] 973
Justification: All tables report standard deviation and how it was computed and the plot 974
contains error bar (also by standard deviation). 975
Guidelines: 976
• The answer NA means that the paper does not include experiments. 977
•The authors should answer "Yes" if the results are accompanied by error bars, confi- 978
dence intervals, or statistical significance tests, at least for the experiments that support 979
the main claims of the paper. 980
29•The factors of variability that the error bars are capturing should be clearly stated (for 981
example, train/test split, initialization, random drawing of some parameter, or overall 982
run with given experimental conditions). 983
•The method for calculating the error bars should be explained (closed form formula, 984
call to a library function, bootstrap, etc.) 985
• The assumptions made should be given (e.g., Normally distributed errors). 986
•It should be clear whether the error bar is the standard deviation or the standard error 987
of the mean. 988
•It is OK to report 1-sigma error bars, but one should state it. The authors should 989
preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis 990
of Normality of errors is not verified. 991
•For asymmetric distributions, the authors should be careful not to show in tables or 992
figures symmetric error bars that would yield results that are out of range (e.g. negative 993
error rates). 994
•If error bars are reported in tables or plots, The authors should explain in the text how 995
they were calculated and reference the corresponding figures or tables in the text. 996
8.Experiments Compute Resources 997
Question: For each experiment, does the paper provide sufficient information on the com- 998
puter resources (type of compute workers, memory, time of execution) needed to reproduce 999
the experiments? 1000
Answer: [No] 1001
Justification: The paper does provide details about the hardware used for the experiments. 1002
However, since experiments were done on different hardwares, the computational resources 1003
needed for each individual experiment are not documented. 1004
Guidelines: 1005
• The answer NA means that the paper does not include experiments. 1006
•The paper should indicate the type of compute workers CPU or GPU, internal cluster, 1007
or cloud provider, including relevant memory and storage. 1008
•The paper should provide the amount of compute required for each of the individual 1009
experimental runs as well as estimate the total compute. 1010
•The paper should disclose whether the full research project required more compute 1011
than the experiments reported in the paper (e.g., preliminary or failed experiments that 1012
didn’t make it into the paper). 1013
9.Code Of Ethics 1014
Question: Does the research conducted in the paper conform, in every respect, with the 1015
NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines ? 1016
Answer: [Yes] 1017
Justification: All codes and rules have been thoroughly reviewed and checked, with no 1018
instances of non-compliance found. 1019
Guidelines: 1020
•The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. 1021
•If the authors answer No, they should explain the special circumstances that require a 1022
deviation from the Code of Ethics. 1023
•The authors should make sure to preserve anonymity (e.g., if there is a special consid- 1024
eration due to laws or regulations in their jurisdiction). 1025
10.Broader Impacts 1026
Question: Does the paper discuss both potential positive societal impacts and negative 1027
societal impacts of the work performed? 1028
Answer: [Yes] 1029
Justification: In the Social Impacts section we discuss that our work can significantly 1030
contribute to fairness in machine learning. We did not find any negative social impacts of 1031
our work. 1032
30Guidelines: 1033
• The answer NA means that there is no societal impact of the work performed. 1034
•If the authors answer NA or No, they should explain why their work has no societal 1035
impact or why the paper does not address societal impact. 1036
•Examples of negative societal impacts include potential malicious or unintended uses 1037
(e.g., disinformation, generating fake profiles, surveillance), fairness considerations 1038
(e.g., deployment of technologies that could make decisions that unfairly impact specific 1039
groups), privacy considerations, and security considerations. 1040
•The conference expects that many papers will be foundational research and not tied 1041
to particular applications, let alone deployments. However, if there is a direct path to 1042
any negative applications, the authors should point it out. For example, it is legitimate 1043
to point out that an improvement in the quality of generative models could be used to 1044
generate deepfakes for disinformation. On the other hand, it is not needed to point out 1045
that a generic algorithm for optimizing neural networks could enable people to train 1046
models that generate Deepfakes faster. 1047
•The authors should consider possible harms that could arise when the technology is 1048
being used as intended and functioning correctly, harms that could arise when the 1049
technology is being used as intended but gives incorrect results, and harms following 1050
from (intentional or unintentional) misuse of the technology. 1051
•If there are negative societal impacts, the authors could also discuss possible mitigation 1052
strategies (e.g., gated release of models, providing defenses in addition to attacks, 1053
mechanisms for monitoring misuse, mechanisms to monitor how a system learns from 1054
feedback over time, improving the efficiency and accessibility of ML). 1055
11.Safeguards 1056
Question: Does the paper describe safeguards that have been put in place for responsible 1057
release of data or models that have a high risk for misuse (e.g., pretrained language models, 1058
image generators, or scraped datasets)? 1059
Answer: [NA] 1060
Justification: The paper poses no such risks. 1061
Guidelines: 1062
• The answer NA means that the paper poses no such risks. 1063
•Released models that have a high risk for misuse or dual-use should be released with 1064
necessary safeguards to allow for controlled use of the model, for example by requiring 1065
that users adhere to usage guidelines or restrictions to access the model or implementing 1066
safety filters. 1067
•Datasets that have been scraped from the Internet could pose safety risks. The authors 1068
should describe how they avoided releasing unsafe images. 1069
•We recognize that providing effective safeguards is challenging, and many papers do 1070
not require this, but we encourage authors to take this into account and make a best 1071
faith effort. 1072
12.Licenses for existing assets 1073
Question: Are the creators or original owners of assets (e.g., code, data, models), used in 1074
the paper, properly credited and are the license and terms of use explicitly mentioned and 1075
properly respected? 1076
Answer: [Yes] 1077
Justification: Every asset that we utilized for our implementations have been appropriately 1078
referenced, both within the paper itself and in the code (if needed). Although we did not 1079
specify the names of their respective licenses, you can find these details on the webpages 1080
we’ve cited. 1081
Guidelines: 1082
• The answer NA means that the paper does not use existing assets. 1083
• The authors should cite the original paper that produced the code package or dataset. 1084
31•The authors should state which version of the asset is used and, if possible, include a 1085
URL. 1086
• The name of the license (e.g., CC-BY 4.0) should be included for each asset. 1087
•For scraped data from a particular source (e.g., website), the copyright and terms of 1088
service of that source should be provided. 1089
•If assets are released, the license, copyright information, and terms of use in the 1090
package should be provided. For popular datasets, paperswithcode.com/datasets 1091
has curated licenses for some datasets. Their licensing guide can help determine the 1092
license of a dataset. 1093
•For existing datasets that are re-packaged, both the original license and the license of 1094
the derived asset (if it has changed) should be provided. 1095
•If this information is not available online, the authors are encouraged to reach out to 1096
the asset’s creators. 1097
13.New Assets 1098
Question: Are new assets introduced in the paper well documented and is the documentation 1099
provided alongside the assets? 1100
Answer: [NA] 1101
Justification: The paper does not release new assets. 1102
Guidelines: 1103
• The answer NA means that the paper does not release new assets. 1104
•Researchers should communicate the details of the dataset/code/model as part of their 1105
submissions via structured templates. This includes details about training, license, 1106
limitations, etc. 1107
•The paper should discuss whether and how consent was obtained from people whose 1108
asset is used. 1109
•At submission time, remember to anonymize your assets (if applicable). You can either 1110
create an anonymized URL or include an anonymized zip file. 1111
14.Crowdsourcing and Research with Human Subjects 1112
Question: For crowdsourcing experiments and research with human subjects, does the paper 1113
include the full text of instructions given to participants and screenshots, if applicable, as 1114
well as details about compensation (if any)? 1115
Answer: [NA] 1116
Justification: The paper does not involve crowdsourcing nor research with human subjects. 1117
Guidelines: 1118
•The answer NA means that the paper does not involve crowdsourcing nor research with 1119
human subjects. 1120
•Including this information in the supplemental material is fine, but if the main contribu- 1121
tion of the paper involves human subjects, then as much detail as possible should be 1122
included in the main paper. 1123
•According to the NeurIPS Code of Ethics, workers involved in data collection, curation, 1124
or other labor should be paid at least the minimum wage in the country of the data 1125
collector. 1126
15.Institutional Review Board (IRB) Approvals or Equivalent for Research with Human 1127
Subjects 1128
Question: Does the paper describe potential risks incurred by study participants, whether 1129
such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) 1130
approvals (or an equivalent approval/review based on the requirements of your country or 1131
institution) were obtained? 1132
Answer: [NA] 1133
Justification: The paper does not involve crowdsourcing nor researh with human subjects. 1134
Guidelines: 1135
32•The answer NA means that the paper does not involve crowdsourcing nor research with 1136
human subjects. 1137
•Depending on the country in which research is conducted, IRB approval (or equivalent) 1138
may be required for any human subjects research. If you obtained IRB approval, you 1139
should clearly state this in the paper. 1140
•We recognize that the procedures for this may vary significantly between institutions 1141
and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the 1142
guidelines for their institution. 1143
•For initial submissions, do not include any information that would break anonymity (if 1144
applicable), such as the institution conducting the review. 1145
33