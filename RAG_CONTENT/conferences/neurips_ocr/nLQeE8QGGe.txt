Active learning of neural population dynamics
using two-photon holographic optogenetics
Andrew Wagenmaker∗
University of California, BerkeleyLu Mi∗
Georgia TechMarton Rozsa
Allen Institute for Neural Dynamics
Matthew S. Bull
Allen Institute for Brain ScienceKarel Svoboda
Allen Institute for Neural Dynamics
Kayvon Daie†
Allen Institute for Neural DynamicsMatthew D. Golub†
University of WashingtonKevin Jamieson†
University of Washington
Abstract
Recent advances in techniques for monitoring and perturbing neural populations
have greatly enhanced our ability to study circuits in the brain. In particular,
two-photon holographic optogenetics now enables precise photostimulation of
experimenter-specified groups of individual neurons, while simultaneous two-
photon calcium imaging enables the measurement of ongoing and induced activity
across the neural population. Despite the enormous space of potential photostimula-
tion patterns and the time-consuming nature of photostimulation experiments, very
little algorithmic work has been done to determine the most effective photostimu-
lation patterns for identifying the neural population dynamics. Here, we develop
methods to efficiently select which neurons to stimulate such that the resulting
neural responses will best inform a dynamical model of the neural population activ-
ity. Using neural population responses to photostimulation in mouse motor cortex,
we demonstrate the efficacy of a low-rank linear dynamical systems model, and
develop an active learning procedure which takes advantage of low-rank structure
to determine informative photostimulation patterns. We demonstrate our approach
on both real and synthetic data, obtaining in some cases as much as a two-fold
reduction in the amount of data required to reach a given predictive power. Our
active stimulation design method is based on a novel active learning procedure for
low-rank regression, which may be of independent interest.
1 Introduction
Neural population dynamics describe how the activities across a population of neurons evolve over
time due to local recurrent connectivity and inputs to the population from other neurons or brain areas.
Identifying these population dynamics can provide critical insight into the computations performed
by a neural population [ 1]. Dynamical systems models have enabled neuroscientists to generate and
test a multitude of hypotheses about how specific neural populations support the neural computations
that underlie, for example, motor control [ 2–4], motor timing [ 5,6], decision making [ 7–10], working
memory [11], social behavior [12], and learning [13–16].
∗Equally contributing first authors.
†Equally contributing senior authors.
Correspondence to: ajwagen@berkeley.edu orlmi7@gatech.edu .
38th Conference on Neural Information Processing Systems (NeurIPS 2024).The traditional approach to data-driven modeling of a neural population typically involves two sep-
arate stages. First, neural population activity is recorded while an animal performs a task of interest.
Then, a dynamical systems model is fit to the recorded neural responses [ 17–33]. This approach
suffers from two key limitations. First, any inferred structure is purely correlational, and cannot be
interpreted with any notion of causality. Second, the experimenter has limited control over how the
neural population dynamics are sampled, which can lead to inefficient data collection—oversampling
in some parts of neural activity space while altogether missing others. Given constraints on time
and resources in neurophysiological experiments, there is a strong need for techniques that minimize
the amount of experimental data required to identify the neural population dynamics.
We seek to overcome these limitations by actively designing the causal circuit perturbations that
will be most informative to learning a dynamical model of the neural population response. For
circuit perturbations, we employ two-photon holographic photostimulation (Figure 1), which provides
temporally precise, cellular-resolution optogenetic control over the activity of ensembles of neurons
[34–41]. When paired with two-photon calcium imaging, photostimulation protocols can provide
insight into network connectivity by enabling the measurement of the causal influence that each
perturbed neuron exerts on all other recorded neurons [ 36,39,42–46]. This platform enables targeted
excitation of the neural population dynamics, thus providing the experimenter with unprecedented
control over the data collected for informing a model of the neural population dynamics.
Here, we develop active learning techniques for designing photostimulation patterns that allow for
efficient estimation of low-rank neural population dynamics and the underlying network connectiv-
ity. First, we introduce a low-rank autoregressive model that captures low-dimensional structure
in neural population dynamics and allows inference of the causal interactions between recorded
neurons. We then propose an active learning procedure which chooses photostimulations to target
this low-dimensional structure, and demonstrate it in two settings: estimating the underlying causal
interactions when using the learned autoregressive model as a simulator of the true dynamics, and
adaptively selecting which samples to observe from our dataset of neural population activity recorded
via two-photon calcium imaging of mouse motor cortex in response to two-photon holographic
photostimulation. In both cases, we show that our active approach obtains substantially more accurate
estimates with fewer measurements compared to passive baselines. Our methodology is based on a
novel analysis of nuclear-norm regression with non-isotropic inputs. To the best of our knowledge,
this is the first approach to demonstrate significant gains applying active learning to low-rank matrix
estimation problems, and thus we believe this may be of independent interest.
2 Related Work
Modeling Neural Responses to Stimulation. Many studies have applied direct electrical or optical
stimulation to neural populations to probe the dynamical properties of neural circuits and their
relation to circuit function [ 4,10,26,47–49]. However, these stimulation techniques lack the spatial
specificity needed to precisely probe the causal influence of individuals neurons on the population
dynamics, and these experimental designs were passive in that the stimulation protocols were specified
prior to data collection (with [ 44,48] as notable exceptions). Other work has explored a related but
separate problem of minimizing off-target effects when photostimulating individual neurons [41].
Low-Rank Matrix Recovery. Low-rank matrix recovery has been intensively researched over the
last decade and a half [ 50–52]. However, existing analyses rely critically on the assumption that the
set of measurements taken are highly symmetric and satisfy some notion of the restricted isometry
property (RIP) or incoherence. The matrix recovery problem of our setting departs from the classical
literature in several ways. First, the set of feasible measurements we can take is constrained by the
physical limits of the photostimulation system. Second, as we aim to adapt andactively learn these
matrix coefficients, we should expect that our resulting set of measurements should be highly skewed
by design. Motivated by this, we develop, to the best of our knowledge, the first bounds on low-rank
estimation using the nuclear norm heuristic that gives a quantification of the estimation error in terms
of the precise individual measurements taken (i.e., in contrast to a more global property like RIP).
Active Learning and Low-Rank Estimation. The active learning literature is vast, and a full survey
is beyond the scope of this work. We focus in particular on active learning for dynamical systems, and
problems with low-rank structure. The estimation of dynamical systems—the system identification
problem—is central to many areas of engineering and science [ 53]. The problem of actively designing
2in-vivo neural population dynamics recording (b)
100
0
100
0neuron index neuron index
time (s)0 5 10 15stimulation inputs
neural activity recordings
F/F
0 200 10035
0 singular value
singular value indexsingular values of neural activity
singular values of shuﬄed neural activitysingular values of neural activity data (c)
stimulation 
laserimaging 
lasertwo-photon holographic stimulation (a)
Figure 1: (a) Two-photon imaging and holographic photostimulation platform (left) and a representative image
frame (right). Purple circles indicate neurons photostimulated immediately before frame acquisition. Red
and blue indicate increases and decreases of firing activity, respectively, relative to before photostimulation.
(b) Example time series photostimulation inputs (top) and neural responses (bottom) from 100 randomly
selected neurons (out of d= 663 recorded neurons identified in the FoV). (c) Neural responses ytoccupy
a low-dimensional subspace. Singular values from a representative dataset’s demeaned neural activity data
matrix (blue) indicate substantially more data variance residing in a few dozen dimensions (out of the full
d= 663 dimensional neural activity space) than is expected by chance (orange, singular values when removing
low-dimensional structure by shuffling time indices independently for each neuron; note clipped horizontal axis).
inputs to effectively estimate the parameters of a dynamical system has been studied extensively for
decades [ 54–61]. More recently, a variety of provably efficient approaches have been developed for
both linear [ 62,63] and nonlinear [ 64,65] systems. Other related work has considered active learning
for latent variable models [ 66], which are often effective models of neural dynamics. As compared
to these works, a key feature of our setting is the low-rank structure present in the data, which to
our knowledge has not been previously studied within the active system identification literature.
Beyond dynamical systems, some attention has been devoted to active learning with low-rank struc-
ture, in particular works on low-rank bandits [ 67–70]. While the setting considered in these works is
somewhat different—they aim to solve a bandit problem, while we are interested in regression—they
similarly seek to develop active learning approaches which make efficient use of low-rank structure.
Also related is the work of [ 71], which shows that in the related sparse estimation setting, there
does not exist more than a logarithmic gain to being adaptive. The results of this work are minimax,
however—only applying to certain “hard” problems—and do not address the matrix recovery problem.
3 Preliminaries
Dataset Details. Neural population activity was recorded in mouse motor cortex using two-photon
calcium imaging at 20Hz of a 1mm ×1mm field of view (FoV) containing 500-700 neurons. Each
recording spanned approximately 25 minutes and 2000 photostimulation trials. In each trial, a 150ms
photostimulus was delivered and was followed by a 600ms response period before the next trial began.
Each photostimulus targeted a group of 10-20 randomly selected neurons, and a total of 100 unique
photostimulation groups were defined for each experiment ( ≈20trials per group). We evaluate our
techniques on four such datasets.
3.1 Fitting Low-Rank Dynamical Models
We first seek to develop effective dynamical models of the neural activity in our photostimulation
datasets. Obtaining such models will provide insight into which photostimuli are most informative,
and gives us a means to evaluate the effectiveness of our active learning methods. We consider three
classes of models: autoregressive (AR) models, low-rank AR models, and nonlinear RNN models.
Results from fitting these models are shown in Figure 2. We describe the model details next.
At discrete time t∈N, we denote the true neural activity across the dimaged neurons as xt∈Rd,
the noisy, measured activity as yt∈Rd, and the photostimulus intensity applied across those
same dneurons as ut∈Rd. Applying stimulus utinfluences the measured neural activity at the
next timestep yt+1. However, just the snapshot ytmay not capture the full true state of the neural
population, which may include not just the current neural activity, but potentially also multiple orders
of temporal derivatives. To capture these effects, we consider an AR- kmodel defined as:
xt+1=Pk−1
s=0(Asxt−s+Bsut−s) +v, y t=xt+wtwith wt∼ N(0, σ2Id), (3.1)
3predictionmeasured activity
c
AUROC
7.5e-4
AR-K model rank dim663 100 50 35 15 10 5GRUMSE
5.5e-40.85
0.65all responses
indirect responses
0.0 1.0false positi ve rate (FPR)true positiv e rate (TPR)
0.01.0ROC cur ve for indi rect responses
0.0 1.0false positi ve rate (FPR)true positiv e rate (TPR)
0.01.0ROC cur ve for all responses
AR-K r ank = 663
AR-K r ank = 100
AR-K r ank = 50
AR-K r ank = 35
AR-K r ank = 15
AR-K r ank = 10
AR-K r ank = 5
GRUdbindirect stimulationdirect stimulation to neuron i(    F/F)imaged activity of neuron ia
AR-K model (full rank) r = 663
AR-K model (low rank) r = 35 AR-K model (low rank) r = 15gated recurrent network (GRU)
0 25 50 time (s) 100 0 25 50 time (s) 100stimulation
inputs
Figure 2: Example data and cross-validated model predictions. (a) Roll-out predictions of the activity
of an example neuron iusing low-rank AR- kmodels ( k= 4) and GRU networks for 22 example
data segments (3.3s per segment; segments separated by brief horizontal spaces). Each model’s
predictions are seeded with the first k= 4timesteps (200ms) of activity from d= 663 neurons and
are then unrolled to predict the activity across all dneurons over the next 66 timesteps, given the full
70-timestep sequence of photostimulation to all dneurons. Most responses of neuron iare tied to
“direct” photostimulation of neuron i(pink, first row of panels). Several “indirect responses” are tied
to stimulation of other neurons j̸=ithat influence neuron ithrough the population dynamics. To
avoid showing all indirect stimuli (to d−1neurons), only select indirect stimuli are shown (green,
second row of panels). (b) Receiver operator characteristic (ROC) curve of true-positive rate and
false-positive rate for response detection are calculated on indirect responses only (left) and all direct
and indirect responses (right). (c) Area under ROC curve (AUROC) and (d) mean square error (MSE)
for all predictions.
where As∈Rd×dandBs∈Rd×ddescribe the coupling between neurons and stimulus at the time
lag of stimesteps, s= 0, . . . , k −1, and offset v∈Rdaccounts for baseline neural activity. Given
input-observation pairs {(ut, yt)}t, the coefficients {(As, Bs)k−1
s=0, v}of(3.1) can be fit using least
squares. Despite its simplicity, this linear model reproduces the recorded neural activity remarkably
well (see “full rank” model of Figure 2).
Neural population dynamics are frequently reported as residing in a subspace of lower dimension
than the total number of recorded neurons [ 2,7,17,72–77]. The population dynamics in our datasets
are consistent with such low-dimensional structure, as indicated by the singular value spectrum in Fig-
ure 1(c). Inspired by this observation, we introduce a set of low-rank dynamical models, where each
matrix of {(As, Bs)k−1
s=0}is re-defined as diagonal plus low-rank. Explicitly, we parameterize As=
DAs+UAsV⊤
AsandBs=DBs+UBsV⊤
Bs, where D∈Rd×dwithDij= 0for all i̸=j,U∈Rd×r,
andV∈Rd×rfor predefined rank r. The diagonal matrices account for substantial autocorrelation
in each neuron’s activity ( DAs) and for the reliable response of each neuron to direct photostimu-
lation ( DBs), whereas the low-rank matrices (UV⊤)confer coupling between neurons. To fit these
parameters, we optimize the following objective function with gradient descent over all parameters:
minimize
As,Bs∈Rd×d,s=0,...,k−1,v∈RdPT
t=1 
yt+1−Pk−1
s=0Asyt−s−Pk−1
s=0Bsut−s−v)2. (3.2)
Figure 2 shows that these low-rank models perform comparably to the full rank versions in terms of
predictive performance; indeed the rank r= 35 model appears almost indistinguishable from the full
4rank model. From a statistical perspective, low-rank models have far fewer degrees of freedom, and
hence require less data to fit.
To assess whether more expressive nonlinear models could be advantageous, we also fit a gated
recurrent unit (GRU) network model, adapted from [ 22], as shown in Figure 2. Interestingly, the
GRU model did not perform as well as the AR- kmodels, potentially due to the complexities of
hyperparameter tuning. Therefore, we focus on linear models in the analysis that follows. Additional
details on model fitting are provided in Appendix B.2.
3.2 The Causal Connectivity Matrix
While we require dynamical models to predict the temporal evolution of the neural population activity,
we are also interested in inferring how the activity of one recorded neuron causally influences the
activity of the other recorded neurons. To address this need, we define a causal connectivity matrix ,
H∈Rd×d, to be the mapping such that Hu∈Rdquantifies the total response (across time) of
each neuron to a single-timestep photostimulus u. That is,P∞
t=1xt=Hu, where x1, x2, x3, . . .are
the neural activities generated by the population dynamics if u0=u, ut≥1= 0, and xt≤0=x∞is
the steady state or resting state of the system subject to no photostimulation. If the dynamics are
linear, or more specifically follow (3.1) , such a matrix His guaranteed to exist, and can be formed by
simply rolling out (3.1) with the appropriate initializations. While His not explicitly constrained to
be low-rank, if it is obtained from a low-rank AR- kmodel, it too will exhibit low-rank structure.
In our experimental paradigm, photostimulation acts as a causal perturbation to the population
dynamics, and as such, our statistical framework is able to capture causal interactions, as opposed
to merely correlative interactions. This is in contrast to the majority of work on neural population
dynamics, which involves fitting dynamical models to passively obtained data. Due to the lack of
causal manipulations in these studies, one cannot distinguish whether statistical relationships arise
between neurons due to correlation (e.g., due to a shared upstream influence) versus causation (e.g.,
neuron idirectly influences neuron j). Such correlative relationships are typically referred to as
“functional connectivity”; we instead use the term “causal connectivity” to convey the additional
causal interpretability afforded in our setting.
To fit H, we could first fit {bAs,bBs}k−1
s=0and then use these as plug-in estimates for their true values to
compute H. Alternatively, we take a more direct approach inspired by the definition of Hitself. By
inspecting the raw data of Figure 2(a) and observing the rate at which each stimulated neuron returns
to baseline activity, it is clear that the system mixes (i.e., forgets the past) quickly. This suggests that
the total response due to input uasymptotes after some finite number of timesteps τ. Thus, we can
apply some photostimulus u∈Rdat time t= 0and then measure the total response z=Pτ
t=1yt,
where yt∈Rdis the noisy measurement of the true neural response xt. If we repeat this for many
pairs{(un, zn)}nthen we can approximate Has
bH:= arg min H′P
n∥zn−H′un∥2
2.
In this work we adopt this latter approach. Since we believe Hto be low rank, this amounts to a
low-rank matrix recovery problem with matrix-vector observations. In the next section, we will
describe how to adaptively choose {un}nto estimate Husing as few (stimulus, response) pairs as
possible. Subsequently in Section 5, we will demonstrate that actively designing inputs to accelerate
the learning of Heffectively accelerates the learning of the full dynamics as well.
4 Active Learning of Low-Rank Matrices
In the previous section, we saw that estimating the causal connectivity matrix Hinduced by the neural
population dynamics amounts to low-rank matrix recovery, where we apply some photostimulus
u∈Rdand observe the neural population response z≈Huplus noise. In this section we seek to
understand how we should choose the photostimuli to estimate the causal connectivity as quickly as
possible. To this end, in Section 4.1 we present novel results characterizing the estimation error of the
nuclear norm regression estimator, and in Section 4.2 present an algorithm motivated by these results
which seeks to actively estimate low-rank matrices. These results will directly motivate a procedure
for designing photostimulation inputs.
To demonstrate the generality of our results, in Section 4.1 we consider a general matrix regression
setting. In particular, let Θ⋆∈Rd1×d2be a rank r(potentially non-square) matrix, φn∈Rd1×d2
5some input matrix, and assume scalar observations:
zn=⟨Θ⋆, φn⟩+ηn, η n∼ N(0,1), (4.1)
where ⟨Θ⋆, φn⟩= tr(Θ⊤
⋆φn)fortr(·)the trace of a matrix. Note that the setting considered in
Section 3.2 is a special case of this observation model with Θ⋆←Hand, for each input stimulation
u, measuring the response of (4.1) to dinputs φjof the form φj≡eju⊤forj= 1, . . . , d .
Matrix Notation. We let ∥ · ∥ F,∥ · ∥ op,∥ · ∥∗denote the Frobenius, operator, and nuclear norm of
a matrix, respectively. †denotes the pseudo-inverse of a matrix. vec(·)denotes the vectorization of a
matrix, and mat(·)the inverse of the vectorization. We also let △Udenote the simplex—the set of
distributions—over a set U.
4.1 Constrained Nuclear Norm Estimator under Non-Isotropic Measurements
We are interested in understanding how we can effectively take into account the low-rank structure
ofΘ⋆, if our goal is to estimate Θ⋆from the observations of (4.1) . To this end, we consider the
following nuclear-norm constrained least-squares estimator for Θ⋆:
bΘ = arg min
Θ∈K∥Φ(Θ)−z∥2
2:=PN
n=1(⟨φn,Θ⟩ −zn)2forK:={Θ :∥Θ∥∗≤ ∥Θ⋆∥∗},(4.2)
where here we let Φ(Θ ⋆)∈RNdenote the vector where the nth element is ⟨φn,Θ⋆⟩, and z=
Φ(Θ ⋆) +ηthe vector of observations, for ηthe vector with elements ηn. Define Θ⋆=UΣV⊤as
the skinny SVD such that U∈Rd1×r,V∈Rd2×r, and consider the linear projection operators
P⊥, P∥:Rd1×d2→Rd1×d2defined as:
P⊥(M) := ( I−UU⊤)M(I−V V⊤)and P∥(M) :=M−P⊥(M),
for any M∈Rd1×d2. We call P∥the projection onto the tangent space ofΘ⋆. Note that the
dimension of the range of P∥is equal to just r(d1+d2)−r2≪d1d2. We are now ready to state our
main result on the estimation error of bΘ, forbΘas defined in (4.2).
Theorem 1. Define µ:=∥(Φ∗Φ)1/2((P∥Φ∗ΦP∥)†)1/2∥op. Then with probability at least 1−2δ:
∥bΘ−Θ⋆∥F≤4
1−µq
tr 
(P∥Φ∗ΦP∥)†
+ 2∥(P∥Φ∗ΦP∥)†∥oplogd1d2
δ
+ 4∥P⊥(Φ∗Φ)1/2∥op∥(P∥Φ∗ΦP∥)†∥op(p
d1+p
d2+q
2 log1
δ),
where here Φ∗Φ(M) :=P
nφn⟨φn, M⟩andtr(·)describes the sum of the eigenvalues of the linear
operator (P∥Φ∗ΦP∥)†:Rd1×d2→Rd1×d2.
Theorem 1 provides a precise bound on the estimation error of the nuclear norm estimator under
arbitrary inputs {φn}n. To the best of our knowledge, this is the first such characterization of this
estimator. This characterization is particularly essential in active learning problems, such as the prob-
lem considered here, where it is critical that we understand precisely how the estimation error scales
with different inputs, in order to determine which inputs will most effectively reduce the estimation
error. As the observation model of Section 3.2 is a special case of the setting considered in (4.1) with
Θ⋆←H, Theorem 1 provides a quantification of how quickly we can estimate the causal connectivity
matrix given some set of inputs; we expand on the implications of this connection in Section 4.2.
Theorem 1 states that the estimation error of the estimator (4.2) scales (predominantly) with the
strength of our inputs φnin the tangent space of Θ⋆. Indeed, if [w1, . . . , w d1]and[v1, . . . , v d2]are
the left and right singular vectors of the full SVD of Θ⋆, andL∈Rd1d2×r(d1+d2)−r2is a matrix with
orthonormal columns vec (wiv⊤
j)for(i, j) :{i≤r} ∪ {j≤r}, then
tr 
(P∥Φ∗ΦP∥)†
= tr  
L⊤PN
n=1vec(φn)vec(φn)⊤L†
,
so we see that the estimation error depends only on the scaling ofPN
n=1vec(φn)vec(φn)⊤in the
space spanned by vec(uiv⊤
j)fori≤rorj≤r—the tangent space to Θ⋆. As an example of how this
scales, assume that for n= 1, . . . , N the entries of each φnare IID N(0,1)andN≥r(d1+d2)−r2.
6Then µ≈0,tr 
(P∥Φ∗ΦP∥)†
≈r(d1+d2)−r2
N,∥(P∥Φ∗ΦP∥)†∥op≈1
N, and∥P⊥(Φ∗Φ)1/2∥op≈√
N. This translates to a bound of ∥bΘ−Θ⋆∥2
F≤r(d1+d2)−r2+log(1 /δ)
N. Critically, we see that this
does not scale with the total number of parameters, d1d2, but instead with r(d1+d2), which could
be much smaller. The following result, due to [ 78], provides a lower bound on the estimation error of
any unbiased estimator, and shows that the rate obtained by Theorem 1 is essentially unimprovable.
Theorem 2 (Corollary 1 of [78]) .For unbiased estimator bΘ,E[∥bΘ−Θ⋆∥2
F]≥tr 
(P∥Φ∗ΦP∥)†
.
4.2 Active Learning for Low-Rank Matrix Estimation
Given the above characterization, we turn now to the active learning problem: how can we best
choose our inputs φnto speed up estimation error of Θ⋆? For simplicity, rather than the general
matrix regression setting of (4.1) , we consider here the vector regression case, as this is the setting of
interest in learning the causal connectivity. In particular, assume that we play some un∈Rd2and
observe zn= Θ ⋆un+ηn, forηn∼ N(0, Id1). A single vector observation corresponds to observing
d1observations from (4.1) , the responses to the matrix inputs φj≡eju⊤
nforj= 1, . . . , d 1. Assume
thatΘ⋆is rank rand let V0:= [v1, . . . , v r]denote the first rright singular vectors of the full SVD of
Θ⋆. Then we have that:
tr 
(P∥Φ∗ΦP∥)†
= (d1−r)·tr 
(V⊤
0ΣNV0)†
+r·tr 
(ΣN)†
,ΣN:=PN
n=1unu⊤
n.(4.3)
This calculation, combined with Theorem 1, shows that the estimation error of Θ⋆scales with a weight-
ing of two terms: one quantifying the amount of input energy we put into directions spanned by the top-
rright singular vectors, and one that quantifies the amount of input energy played isotropically (that is,
in all directions). Note, however, that the input energy played in directions V0is weighted by a factor
ofd1−r≈d1, much larger weight than the weight of rgiven to the term quantifying the isotropic in-
put energy. This suggests that, to minimize the estimation error of Θ⋆, we should focus a large portion
of our sampling budget to target the directions spanned by the top- rright singular vectors of Θ⋆.
This strategy admits a transparent intuition. If Θ⋆is rank- rand some vector uis orthogonal to the top-
rright singular vectors of Θ⋆, then Θ⋆u= 0. Thus, if we know what subspace the top- rright singular
vectors of Θ⋆span, playing uorthogonal to this subspace gives us no additional information about
Θ⋆; in this case we should instead play ualigned with this subspace. This is precisely what the first
term in (4.3) quantifies, while the second term reflects the fact that we must also estimate the subspace
spanned by the top- rright singular vectors of Θ⋆, for which playing inputs isotropically is optimal.
In general, as we do not know Θ⋆, we do not know V0, and so cannot directly compute inputs minimiz-
ing(4.3) . To circumvent this, we consider the following iterative procedure, which alternates between
obtaining an estimate of Θ⋆,bΘ, and then playing the inputs that would minimize the estimation
error—minimize (4.3)—if bΘwere the true parameter. We present this procedure in Algorithm 1.
Algorithm 1 Active Estimation of Low-Rank Matrices
1:input: horizon N, feasible inputs U, rank r, feasible set K
2:bΘ1←I,D← ∅
3:forℓ= 1,2,3, . . . ,⌈log2N⌉do
4: LetbV0denote the top- rright singular vectors of bΘℓandΛ(λ) :=P
u∈Uλuuu⊤, solve:
λV
ℓ←arg minλ∈△Utr 
(bV⊤
0Λ(λ)bV0)†
, λunif
ℓ←arg minλ∈△Utr 
Λ(λ)†
5: For2ℓsteps, play input un∼1
2λV
ℓ+1
2λunif
ℓ, add observations to D
6: Update estimate of Θ⋆:bΘℓ+1←arg minΘ∈KP
(u,z)∈D∥z−Θu∥2
F
7:return bΘℓ+1.
At every iteration ℓ, Algorithm 1 computes two distributions over inputs: λV
ℓ, which targets the
top-rright singular vectors of our current estimate of Θ⋆, andλunif
ℓ, which plays inputs isotropically,
covering all directions. Rather than playing these distributions according to the precise weighting
given in (4.3) , we instead found it most effective to mix them at an equal rate. As we do not initially
know which directions are spanned by the top- rright singular vectors of Θ⋆,λV
ℓis not guaranteed
to target the correct directions, especially in early iterations. λunif
ℓplays inputs in every direction,
7however, and thus, even if λV
ℓis not aligned to the top- rright singular vectors of Θ⋆, will ensure
sufficient energy is still being played in the correct directions to allow for learning. Given this, we
increase the weight of playing λunif
ℓrelative to that prescribed by (4.3).
Note that the computation of the optimal inputs is a form of A-optimal experiment design [79], which
in general can be efficiently solved by, for example, the Frank-Wolfe algorithm [ 80]. Furthermore,
efficient procedures for solving nuclear-norm regression problems exist, allowing us to estimate bΘℓ+1
on line 6 efficiently [ 81]. We remark that Algorithm 1 takes as input r, the rank of Θ⋆, andK, which
requires knowledge of ∥Θ⋆∥∗. In general, when these quantities are unknown, they can be chosen via
standard cross-validation procedures.
We emphasize again that the setting considered here corresponds precisely to the setting considered
in Section 3.2 with Θ⋆←H,unthe input stimulation patterns, and znthe observed neural response
to input un. As such, if the causal connectivity His low rank, Algorithm 1 and the preceding results
provide a methodology to select input stimuli to most efficiently estimate H. In the following section,
we will apply this to our photostimulation datasets.
5 Active Learning for Estimating Neural Population Dynamics
We return now to the problem of photostimulus design for learning neural population dynamics,
and seek to apply the insights of Section 4 to this setting. We present two sets of experiments. In
Section 5.1 we use real data to fit a model of the population dynamics, treat this fitted model as
asimulator for the true dynamics, and then demonstrate that we can learn the causal connectivity
matrix Hof this simulator faster using active inputs versus passive inputs. Then, in Section 5.2 we
split our real data into 750ms long trials of (stimulus, response) pairs (see Section 3) and demonstrate
that our active learning algorithm is able to improve the performance of learning dynamical models
on real data by adaptively selecting which trials to observe, training a model on the observed trials,
and evaluating on a hold-out set of unseen trials. Here we find that our approach is able to learn an
accurate model of the dynamics more quickly than non-adaptive approaches.
5.1 Active Learning on Data-Driven Neural Population Dynamics Simulator
In Section 3.1, we demonstrated that photostimulation data can be effectively reconstructed using an
AR-kdynamics model. Given the effectiveness of these models at fitting our data, in this section we
treat them as a simulated representation of our true dynamics, allowing us to query them arbitrarily
as a stand-in for the ground truth dynamics, and seek to determine whether carefully choosing the
photostimulation pattern allows for efficient estimation of the causal connectivity matrix H.
Experiment Details. To obtain models of the population dynamics to use for simulation, we fit an
AR-kmodel to each dataset as described in Section 3.1. In all cases we use an AR- kmodel with
order k= 4. We do one run of the experiments using low-rank model parameters UV⊤with rank
r= 15 , and then repeat the experiments using r= 35 . In each case, we simulate N= 10000 trials,
where each trial corresponds to applying a photostimulus and observing the response for τ= 15
timesteps, simulating our true data generation process. To simulate measurement noise and other
trial-to-trial variability in neural responses, we corrupt the observations with Gaussian random noise.
Motivated by the empirically observed fast decay of population dynamics in our datasets, we reset
the initial state of the simulator at each new trial.
In practice, both the magnitude of the stimuli and number of neurons stimulated at each timestep are
constrained by the photostimulation platform. To reflect this limitation in our simulator, we constrain
our inputs to lie in [0,1], and also impose a sparsity penalty. Precisely, we choose the input set Uin
Algorithm 1 to be U:={u∈[0,1]d:∥u∥1≤γ}, for some value γ >0(which we set to γ= 30 ).
While this does not explicitly constrain inputs to be sparse, it can be efficiently optimized over, and
we found in practice that the optimal inputs within this constraint set are in general at least 2γ-sparse.
As baseline methods, we consider the following:
•Random Stimulation : At each trial n, choose γneurons at random, and set corresponding elements
ofunto 1.
•Uniform Stimulation : Compute λunifas in Algorithm 1 and play inputs un∼λuniffor all n.
8Rank = 15
2000 4000 6000 8000 10000
Number of Trials0.70.80.91.0Estimation Error
Active (Ours)
Random
Uniform
2000 4000 6000 8000 10000
Number of Trials0.70.80.91.0Estimation Error
2000 4000 6000 8000 10000
Number of Trials0.40.60.8Estimation Error
2000 4000 6000 8000 10000
Number of Trials0.40.6Estimation Error
 Rank = 35
2000 4000 6000 8000 10000
Number of Trials0.70.80.91.0Estimation Error
Active (Ours)
Random
Uniform
(a) Mouse 1
2000 4000 6000 8000 10000
Number of Trials0.70.80.91.0Estimation Error
 (b) Mouse 2
2000 4000 6000 8000 10000
Number of Trials0.50.60.70.8Estimation Error
 (c) Mouse 3 (FoV A)
2000 4000 6000 8000 10000
Number of Trials0.40.60.8Estimation Error
 (d) Mouse 3 (FoV B)
Figure 3: Performance of active stimulation design on estimating learned dynamics model. For each
mouse dataset, we fit a low-rank AR- kmodel as described in Section 3.1 (for ranks of 15 and 35, and
k= 4). Treating this as a simulator of the true dynamics, we compare our active stimulation design
procedure (Active, Algorithm 1) to randomly choosing groups of neurons to excite (Random), and
uniformly allocating stimulation across all neurons (Uniform), and plot how effectively each is able
to estimate the connectivity of the simulator dynamics. For each figure and method we average over
20 trials, and plot the mean performance with error bars denoting 1 standard error (note that the error
bars are barely visible as the standard deviation is very small).
Our goal is to estimate the causal connectivity matrix Hinduced by our learned dynamics (see
Section 3.2). In practice, we are most interested in estimating the off-diagonal elements of H, as
these correspond to causal interactions between different neurons. To this end, we consider the error
metric∥M⊙(H−bH)∥F
∥M⊙H∥F, forbHour estimate of H,Ma matrix with all entries 1except its diagonal,
which is 0, and⊙element-wise multiplication.
Experiment Results. We present our results in Figure 3. As can be seen, across all learned
simulators and rank levels, our active learning approach yields a non-trivial gain over both baseline
approaches. In particular, on Mouse 1 and both datasets for Mouse 3, we observe a gain of between
1.5-2×over baselines—that is, to achieve a given estimation error, our approach requires between
1.5-2×fewer samples than baseline methods. This demonstrates the effectiveness of our active
learning procedure for estimating low-rank matrices—our method is able to exploit the low-rank
structure present in the underlying dynamics to speed up estimation, as compared to methods which
do not take into account this structure. Furthermore, it shows that on a realistic simulation of neural
population dynamics, we can effectively design stimuli to speed up the estimation of the dynamics.
5.2 Active Ranking of Real Data Observations
As described in Section 3, each of our datasets consist of roughly 2000 (stimulus, response) trials.
In an online photostimulation experiment, we would choose the photostimulus actively for each
trial. Here we seek to simulate this process using real experimental data, but offline, by choosing
theordering of the trials available in our pre-collected datasets. This serves as a testbed for active
learning procedures: if we can more efficiently learn models in this offline setting, that is a strong
indication that we should also see gains in online experiments. Indeed, those gains may be even
greater online because in our offline setting we are severely restricted to choosing from only 100
candidate stimulation patterns. Thus, we interpret the results in this section as a lower bound on the
performance we might expect online.
To validate this approach, we randomly choose 20 (out of the 100 total) unique photostimulation
patterns and set aside a test set containing all 20 repeated trials of those photostimuli. This creates an
80%/20% train-test split of non-overlapping stimulus patterns. For Dtrain andDtestour train and
test datasets, respectively, we consider the following query model:
1:D← ∅
2:fortrials n= 1,2, . . . ,|Dtrain|do
3: Choose input trajectory τ∈Dtrain, setD←D∪ {τ},Dtrain←Dtrain\{τ}
4: Estimate model using data in D, and compute prediction MSE of model on Dtest
9Average
500 1000 1500
Number of Trials0.2500.2520.2540.2560.258MSE on Heldout Trials
Active (Ours)
Random
500 1000 1500
Number of Trials0.1350.1360.1370.138MSE on Heldout Trials
500 1000 1500
Number of Trials0.5050.5100.5150.520MSE on Heldout Trials
500 1000 1500
Number of Trials0.5700.5750.580MSE on Heldout Trials
 Best
500 1000 1500
Number of Trials0.24750.25000.25250.2550MSE on Heldout Trials
Active (Ours)
Random
500 1000 1500
Number of Trials0.1440.1450.1460.1470.148MSE on Heldout Trials
500 1000 1500
Number of Trials0.5350.5400.5450.550MSE on Heldout Trials
500 1000 1500
Number of Trials0.5750.5800.585MSE on Heldout Trials
 Worst
500 1000 1500
Number of Trials0.2400.2420.2440.2460.248MSE on Heldout Trials
Active (Ours)
Random
(a) Mouse 1
500 1000 1500
Number of Trials0.1220.1230.1240.125MSE on Heldout Trials
 (b) Mouse 2
500 1000 1500
Number of Trials0.4600.4650.470MSE on Heldout Trials
 (c) Mouse 3 (FoV A)
500 1000 1500
Number of Trials0.5550.5600.565MSE on Heldout Trials
 (d) Mouse 3 (FoV B)
Figure 4: Performance of active learning estimating photostimulation response on held-out trials.
Each mouse dataset is split into trials corresponding to a stimulus-response pair, and we consider
how these trials might be ordered to obtain more effective estimates with fewer training data trials,
simulating the active learning process. Our approach (Active) is motivated by the low-rank excitation
criteria of Algorithm 1 (see Appendix B.4 for more details) and we compare with randomly choosing
which trial to observe next (Random). We plot the accuracy of the learned model in predicting neural
responses on held-out test trials. We consider 20 different train-test splits (with 20 trials per split),
and include plots of average performance across these splits, as well as splits where Active has the
largest and smallest improvement over Random. We plot error bars denoting 1 standard error (note
again that the error bars are barely visible as the standard deviation is very small).
We fit a dynamics model to the current set of observed trials, as described in Section 3.1, and use
this model to predict the response of the true system on the held-out test inputs, computing the
mean-squared error of these predictions as our metric. We apply a variant of Algorithm 1, described
in more detail in Appendix B.4, and adapted to the query model above. In particular, to apply
Algorithm 1 to learning a full dynamical system, we choose our inputs to target the right singular
vectors of Bsin(3.1) . As a baseline method, we consider the procedure which randomly chooses an
unobserved segment from Dtrain at each iteration.
We run the above experiment for 20 different randomly generated train-test splits on each dataset, and
present our results in Figure 4, providing the results for the average performance over the train-test
splits, as well as the best- and worst-case splits for active learning performance. As these results
illustrate, though active learning does not give a substantial gain in all cases, in many cases it is able
to give a gain of up to a factor of 2×in the number of samples required over the random baseline, and
in the worst case, matches the baseline performance. This further confirms that taking into account
low-rank structure when choosing which measurements to take can improve estimation rates, and, we
believe, is a strong indicator that our active learning procedure would speed up estimation of neural
population dynamics in online settings.
6 Discussion
In this work, we have developed a principled approach to active learning of photostimulation inputs for
the identification of neural population dynamics and connectivity. We discuss three limitations of our
approach, which each suggest potential future directions. First, we have considered active learning of
the causal connectivity matrix and minimization of prediction error, both uniformly across all recorded
neurons. Future work may focus on more specific scenarios, such as targeting particular dimensions of
the neural activity space or changes in connectivity due to learning. Second, while we found that linear
dynamics fit our data remarkably well, this may not always be the case. Does our methodology effec-
tively scale to nonlinear dynamics? Finally, our real-data experiments were performed offline. Future
work may explore running our algorithm online during closed-loop photostimulation experiments.
10Acknowledgments
This work was supported by NSF DMR award 2308979 to the University of Washington Materials
Science Research Center (AW & KJ), the Shanahan Foundation Fellowship (LM & MSB), the Paul
G. Allen Foundation (MR, KS, KD & MDG), NIH award R00-MH121533 (MDG), NSF CCF award
2007036 (KJ), and NSF CAREER award 2141511 (KJ).
References
[1]Saurabh Vyas, Matthew D Golub, David Sussillo, and Krishna V Shenoy. Computation through
neural population dynamics. Annual Review of Neuroscience , 43:249–275, 2020.
[2]Mark M Churchland, John P Cunningham, Matthew T Kaufman, Justin D Foster, Paul Nuyu-
jukian, Stephen I Ryu, and Krishna V Shenoy. Neural population dynamics during reaching.
Nature , 487(7405):51–56, 2012.
[3]David Sussillo, Mark M Churchland, Matthew T Kaufman, and Krishna V Shenoy. A neural net-
work that finds a naturalistic solution for the production of muscle activity. Nature Neuroscience ,
18(7):1025–1033, 2015.
[4]Nuo Li, Kayvon Daie, Karel Svoboda, and Shaul Druckmann. Robust neuronal dynamics in
premotor cortex during motor planning. Nature , 532(7600):459–464, 2016.
[5]Evan D Remington, Devika Narain, Eghbal A Hosseini, and Mehrdad Jazayeri. Flexible
sensorimotor computations through rapid reconfiguration of cortical dynamics. Neuron , 98(5):
1005–1019, 2018.
[6]Hidehiko K Inagaki, Susu Chen, Margreet C Ridder, Pankaj Sah, Nuo Li, Zidan Yang, Hana
Hasanbegovic, Zhenyu Gao, Charles R Gerfen, and Karel Svoboda. A midbrain-thalamus-cortex
circuit reorganizes cortical dynamics to initiate movement. Cell, 185(6):1065–1081, 2022.
[7]Valerio Mante, David Sussillo, Krishna V Shenoy, and William T Newsome. Context-dependent
computation by recurrent dynamics in prefrontal cortex. Nature , 503(7474):78–84, 2013.
[8]Federico Carnevale, Victor de Lafuente, Ranulfo Romo, Omri Barak, and Néstor Parga. Dynamic
control of response criterion in premotor cortex during perceptual detection under temporal
uncertainty. Neuron , 86(4):1067–1077, 2015.
[9]Krithika Mohan, Ou Zhu, and David J Freedman. Interaction between neuronal encoding and
population dynamics during categorization task switching in parietal cortex. Neuron , 109(4):
700–712, 2021.
[10] Arseny Finkelstein, Lorenzo Fontolan, Michael N Economo, Nuo Li, Sandro Romani, and Karel
Svoboda. Attractor dynamics gate cortical information flow during decision-making. Nature
Neuroscience , 24(6):843–850, 2021.
[11] Warasinee Chaisangmongkon, Sruthi K Swaminathan, David J Freedman, and Xiao-Jing Wang.
Computing by robust transience: how the fronto-parietal network performs sequential, category-
based decisions. Neuron , 93(6):1504–1517, 2017.
[12] Aditya Nair, Tomomi Karigo, Bin Yang, Surya Ganguli, Mark J Schnitzer, Scott W Linderman,
David J Anderson, and Ann Kennedy. An approximate line attractor in the hypothalamus
encodes an aggressive state. Cell, 186(1):178–193, 2023.
[13] Saurabh Vyas, Nir Even-Chen, Sergey D Stavisky, Stephen I Ryu, Paul Nuyujukian, and
Krishna V Shenoy. Neural population dynamics underlying motor learning transfer. Neuron , 97
(5):1177–1186, 2018.
[14] Britton A Sauerbrei, Jian-Zhong Guo, Jeremy D Cohen, Matteo Mischiati, Wendy Guo, Mayank
Kabra, Nakul Verma, Brett Mensh, Kristin Branson, and Adam W Hantman. Cortical pattern
generation during dexterous movement is input-driven. Nature , 577(7790):386–391, 2020.
[15] Xulu Sun, Daniel J O’Shea, Matthew D Golub, Eric M Trautmann, Saurabh Vyas, Stephen I
Ryu, and Krishna V Shenoy. Cortical preparatory activity indexes learned motor memories.
Nature , 602(7896):274–279, 2022.
[16] Emily R Oby, Alan D Degenhart, Erinn M Grigsby, Asma Motiwala, Nicole T McClain, Patrick J
Marino, Byron Yu, and Aaron P Batista. Dynamical constraints on neural population activity.
bioRxiv , pages 2024–01, 2024.
11[17] Byron M Yu, John P Cunningham, Gopal Santhanam, Stephen I Ryu, Krishna V Shenoy, and
Maneesh Sahani. Gaussian-process factor analysis for low-dimensional single-trial analysis of
neural population activity. Journal of Neurophysiology , 102(1):614–635, 2009.
[18] Jakob H Macke, Lars Buesing, John P Cunningham, Byron M Yu, Krishna V Shenoy, and
Maneesh Sahani. Empirical models of spiking in neural populations. Advances in Neural
Information Processing Systems , 24, 2011.
[19] Evan W Archer, Urs Koster, Jonathan W Pillow, and Jakob H Macke. Low-dimensional models
of neural population activity in sensory cortical circuits. Advances in Neural Information
Processing Systems , 27, 2014.
[20] Scott Linderman, Ryan P Adams, and Jonathan W Pillow. Bayesian latent structure discovery
from multi-neuron recordings. Advances in Neural Information Processing Systems , 29, 2016.
[21] Yuanjun Gao, Evan W Archer, Liam Paninski, and John P Cunningham. Linear dynamical
neural population models through nonlinear embeddings. Advances in Neural Information
Processing Systems , 29, 2016.
[22] Chethan Pandarinath, Daniel J O’Shea, Jasmine Collins, Rafal Jozefowicz, Sergey D Stavisky,
Jonathan C Kao, Eric M Trautmann, Matthew T Kaufman, Stephen I Ryu, Leigh R Hochberg,
Jaimie M Henderson, Krishna V Shenoy, Larry F Abbott, and David Sussillo. Inferring single-
trial neural population dynamics using sequential auto-encoders. Nature Methods , 15(10):
805–815, 2018.
[23] Joshua Glaser, Matthew Whiteway, John P Cunningham, Liam Paninski, and Scott Linderman.
Recurrent switching dynamical systems models for multiple interacting neural populations.
Advances in Neural Information Processing Systems , 33:14867–14878, 2020.
[24] Timothy D Kim, Thomas Z Luo, Jonathan W Pillow, and Carlos D Brody. Inferring latent
dynamics underlying neural population activity via neural differential equations. In International
Conference on Machine Learning , pages 5551–5561. PMLR, 2021.
[25] Orren Karniol-Tambour, David M Zoltowski, E Mika Diamanti, Lucas Pinto, David W Tank,
Carlos D Brody, and Jonathan W Pillow. Modeling communication and switching nonlinear
dynamics in multi-region neural activity. bioRxiv , pages 2022–09, 2022.
[26] Daniel J O’Shea, Lea Duncker, Werapong Goo, Xulu Sun, Saurabh Vyas, Eric M Trautmann,
Ilka Diester, Charu Ramakrishnan, Karl Deisseroth, Maneesh Sahani, et al. Direct neural
perturbations reveal a dynamical mechanism for robust computation. bioRxiv , pages 2022–12,
2022.
[27] Mohammad Reza Keshtkaran, Andrew R Sedler, Raeed H Chowdhury, Raghav Tandon, Diya
Basrai, Sarah L Nguyen, Hansem Sohn, Mehrdad Jazayeri, Lee E Miller, and Chethan Pandari-
nath. A large-scale neural network training framework for generalized estimation of single-trial
population dynamics. Nature Methods , 19(12):1572–1577, 2022.
[28] Adrian Valente, Jonathan W. Pillow, and Srdjan Ostojic. Extracting computational mechanisms
from neural data using low-rank RNNs. In Alice H. Oh, Alekh Agarwal, Danielle Belgrave,
and Kyunghyun Cho, editors, Advances in Neural Information Processing Systems , 2022.
[29] Arthur Pellegrino, N Alex Cayco Gajic, and Angus Chadwick. Low tensor rank learning of
neural dynamics. Advances in Neural Information Processing Systems , 36:11674–11702, 2023.
[30] Daniel Durstewitz, Georgia Koppe, and Max Ingo Thurm. Reconstructing computational system
dynamics from neural data with recurrent neural networks. Nature Reviews Neuroscience , 24
(11):693–710, 2023.
[31] Hyun Dong Lee, Andrew Warrington, Joshua Glaser, and Scott Linderman. Switching autore-
gressive low-rank tensor models. Advances in Neural Information Processing Systems , 36:
57976–58010, 2023.
[32] Aniruddh R Galgali, Maneesh Sahani, and Valerio Mante. Residual dynamics resolves recurrent
contributions to neural computation. Nature Neuroscience , 26(2):326–338, 2023.
[33] Omid G Sani, Bijan Pesaran, and Maryam M Shanechi. Dissociative and prioritized modeling
of behaviorally relevant neural dynamics using recurrent neural networks. Nature Neuroscience ,
pages 1–13, 2024.
12[34] Adam M Packer, Lloyd E Russell, Henry WP Dalgleish, and Michael Häusser. Simultaneous
all-optical manipulation and recording of neural circuit activity with cellular resolution in vivo.
Nature methods , 12(2):140–146, 2015.
[35] Zihui Zhang, Lloyd E Russell, Adam M Packer, Oliver M Gauld, and Michael Häusser. Closed-
loop all-optical interrogation of neural circuits in vivo. Nature methods , 15(12):1037–1040,
2018.
[36] Selmaan N Chettih and Christopher D Harvey. Single-neuron perturbations reveal feature-
specific competition in v1. Nature , 567(7748):334–340, 2019.
[37] James H Marshel, Yoon Seok Kim, Timothy A Machado, Sean Quirin, Brandon Benson,
Jonathan Kadmon, Cephra Raja, Adelaida Chibukhchyan, Charu Ramakrishnan, Masatoshi
Inoue, et al. Cortical layer–specific critical dynamics triggering perception. Science , 365(6453):
eaaw5202, 2019.
[38] Luis Carrillo-Reid, Shuting Han, Weijian Yang, Alejandro Akrouh, and Rafael Yuste. Con-
trolling visually guided behavior by holographic recalling of cortical ensembles. Cell, 178(2):
447–457, 2019.
[39] Kayvon Daie, Karel Svoboda, and Shaul Druckmann. Targeted photostimulation uncovers
circuit motifs supporting short-term memory. Nature Neuroscience , 24(2):259–265, 2021.
[40] Hillel Adesnik and Lamiae Abdeladim. Probing neural codes with two-photon holographic
optogenetics. Nature Neuroscience , 24(10):1356–1366, 2021.
[41] Marcus Triplett, Marta Gajowa, Hillel Adesnik, and Liam Paninski. Bayesian target optimisation
for high-precision holographic optogenetics. Advances in Neural Information Processing
Systems , 36, 2024.
[42] Christopher A Baker, Yishai M Elyada, Andres Parra, and M McLean Bolton. Cellular resolution
circuit mapping with temporal-focused excitation of soma-targeted channelrhodopsin. Elife , 5:
e14193, 2016.
[43] Laurence Aitchison, Lloyd Russell, Adam M Packer, Jinyao Yan, Philippe Castonguay, Michael
Hausser, and Srinivas C Turaga. Model-based bayesian inference of neural activity and con-
nectivity from all-optical interrogation of a neural circuit. Advances in Neural Information
Processing Systems , 30, 2017.
[44] Anne Draelos and John Pearson. Online neural connectivity estimation with noisy group testing.
Advances in Neural Information Processing Systems , 33:7437–7448, 2020.
[45] Travis A Hage, Alice Bosma-Moody, Christopher A Baker, Megan B Kratz, Luke Campagnola,
Tim Jarsky, Hongkui Zeng, and Gabe J Murphy. Distribution and strength of interlaminar
synaptic connectivity in mouse primary visual cortex revealed by two-photon optogenetic
stimulation. BioRxiv , pages 2019–12, 2019.
[46] Arseny Finkelstein, Kayvon Daie, Marton Rozsa, Ran Darshan, and Karel Svoboda. Connectiv-
ity underlying motor cortex activity during naturalistic goal-directed behavior. bioRxiv , pages
2023–11, 2023.
[47] Mark M Churchland and Krishna V Shenoy. Delay of movement caused by disruption of
cortical preparatory activity. Journal of neurophysiology , 97(1):348–359, 2007.
[48] Nishal Shah, Sasidhar Madugula, Pawel Hottowy, Alexander Sher, Alan Litke, Liam Paninski,
and EJ Chichilnisky. Efficient characterization of electrically evoked responses for neural
interfaces. Advances in Neural Information Processing Systems , 32, 2019.
[49] Yuxiao Yang, Shaoyu Qiao, Omid G Sani, J Isaac Sedillo, Breonna Ferrentino, Bijan Pesaran,
and Maryam M Shanechi. Modelling and prediction of the dynamic responses of large-scale
brain networks during direct electrical stimulation. Nature biomedical engineering , 5(4):
324–345, 2021.
[50] Emmanuel Candes and Benjamin Recht. Exact matrix completion via convex optimization.
Communications of the ACM , 55(6):111–119, 2012.
[51] Roman Vershynin. High-dimensional probability: An introduction with applications in data
science , volume 47. Cambridge university press, 2018.
[52] Martin J Wainwright. High-dimensional statistics: A non-asymptotic viewpoint , volume 48.
Cambridge university press, 2019.
13[53] Lennart Ljung. System identification . Springer, 1998.
[54] Raman Mehra. Optimal input signals for parameter estimation in dynamic systems–survey and
new results. IEEE Transactions on Automatic Control , 19(6):753–768, 1974.
[55] László Gerencsér and Håkan Hjalmarsson. Adaptive input design in system identification. In
Proceedings of the 44th IEEE Conference on Decision and Control , pages 4988–4993. IEEE,
2005.
[56] Dimitrios Katselis, Cristian R Rojas, Håkan Hjalmarsson, and Mats Bengtsson. Application-
oriented finite sample experiment design: A semidefinite relaxation approach. IFAC Proceedings
Volumes , 45(16):1635–1640, 2012.
[57] Ian R Manchester. Input design for system identification via convex relaxation. In 49th IEEE
Conference on Decision and Control (CDC) , pages 2041–2046. IEEE, 2010.
[58] Cristian R Rojas, James S Welsh, Graham C Goodwin, and Arie Feuer. Robust optimal
experiment design for system identification. Automatica , 43(6):993–1008, 2007.
[59] Graham Clifford Goodwin and Robert L Payne. Dynamic system identification: experiment
design and data analysis . Academic press, 1977.
[60] Kristian Lindqvist and Håkan Hjalmarsson. Identification for control: Adaptive input design
using convex optimization. In Proceedings of the 40th IEEE Conference on Decision and
Control (Cat. No. 01CH37228) , volume 5, pages 4326–4331. IEEE, 2001.
[61] László Gerencsér, Jonas Mårtensson, and Håkan Hjalmarsson. Adaptive input design for arx
systems. In 2007 European Control Conference (ECC) , pages 5707–5714. IEEE, 2007.
[62] Andrew Wagenmaker and Kevin Jamieson. Active learning for identification of linear dynamical
systems. In Conference on Learning Theory , pages 3487–3582. PMLR, 2020.
[63] Andrew J Wagenmaker, Max Simchowitz, and Kevin Jamieson. Task-optimal exploration in
linear dynamical systems. In International Conference on Machine Learning , pages 10641–
10652. PMLR, 2021.
[64] Horia Mania, Michael I Jordan, and Benjamin Recht. Active learning for nonlinear system
identification with guarantees. J. Mach. Learn. Res. , 23:32–1, 2022.
[65] Andrew Wagenmaker, Guanya Shi, and Kevin G Jamieson. Optimal exploration for model-based
rl in nonlinear systems. Advances in Neural Information Processing Systems , 36, 2024.
[66] Aditi Jha, Zoe C Ashwood, and Jonathan W Pillow. Active learning for discrete latent variable
models. Neural Computation , 36(3):437–474, 2024.
[67] Sumeet Katariya, Branislav Kveton, Csaba Szepesvari, Claire Vernade, and Zheng Wen. Stochas-
tic rank-1 bandits. In Artificial Intelligence and Statistics , pages 392–401. PMLR, 2017.
[68] Kwang-Sung Jun, Rebecca Willett, Stephen Wright, and Robert Nowak. Bilinear bandits
with low-rank structure. In International Conference on Machine Learning , pages 3163–3172.
PMLR, 2019.
[69] Yangyi Lu, Amirhossein Meisami, and Ambuj Tewari. Low-rank generalized linear bandit
problems. In International Conference on Artificial Intelligence and Statistics , pages 460–468.
PMLR, 2021.
[70] Yue Kang, Cho-Jui Hsieh, and Thomas Chun Man Lee. Efficient frameworks for generalized
low-rank matrix bandit problems. Advances in Neural Information Processing Systems , 35:
19971–19983, 2022.
[71] Ery Arias-Castro, Emmanuel J Candes, and Mark A Davenport. On the fundamental limits of
adaptive sensing. IEEE Transactions on Information Theory , 59(1):472–481, 2012.
[72] John P Cunningham and Byron M Yu. Dimensionality reduction for large-scale neural record-
ings. Nature Neuroscience , 17(11):1500–1509, 2014.
[73] Patrick T Sadtler, Kristin M Quick, Matthew D Golub, Steven M Chase, Stephen I Ryu,
Elizabeth C Tyler-Kabara, Byron M Yu, and Aaron P Batista. Neural constraints on learning.
Nature , 512:423–426, 2014.
[74] Saul Kato, Harris S Kaplan, Tina Schrödel, Susanne Skora, Theodore H Lindsay, Eviatar
Yemini, Shawn Lockery, and Manuel Zimmer. Global brain dynamics embed the motor
command sequence of caenorhabditis elegans. Cell, 163(3):656–669, 2015.
14[75] Matthew D Golub, Patrick T Sadtler, Emily R Oby, Kristin M Quick, Stephen I Ryu, Eliza-
beth C Tyler-Kabara, Aaron P Batista, Steven M Chase, and Byron M Yu. Learning by neural
reassociation. Nature Neuroscience , 21(4):607–616, 2018.
[76] Juan A Gallego, Matthew G Perich, Stephanie N Naufel, Christian Ethier, Sara A Solla, and
Lee E Miller. Cortical population activity within a preserved neural manifold underlies multiple
motor behaviors. Nature Communications , 9(1):4233, 2018.
[77] Rishidev Chaudhuri, Berk Gerçek, Biraj Pandey, Adrien Peyrache, and Ila Fiete. The intrinsic
attractor manifold and population dynamics of a canonical cognitive circuit across waking and
sleep. Nature Neuroscience , 22(9):1512–1520, 2019.
[78] Gongguo Tang and Arye Nehorai. Lower bounds on the mean-squared error of low-rank matrix
reconstruction. IEEE Transactions on Signal Processing , 59(10):4559–4571, 2011.
[79] Friedrich Pukelsheim. Optimal design of experiments . SIAM, 2006.
[80] Marguerite Frank and Philip Wolfe. An algorithm for quadratic programming. Naval research
logistics quarterly , 3(1-2):95–110, 1956.
[81] Maryam Fazel. Matrix rank minimization with applications . PhD thesis, PhD thesis, Stanford
University, 2002.
[82] Marius Pachitariu, Carsen Stringer, Sylvia Schröder, Mario Dipoppa, L Federico Rossi, Matteo
Carandini, and Kenneth D Harris. Suite2p: beyond 10,000 neurons with standard two-photon
microscopy. BioRxiv , page 061507, 2016.
[83] Diederik P Kingma. Adam: A method for stochastic optimization. arXiv preprint
arXiv:1412.6980 , 2014.
15A Proof of Theorem 1
AsbΘis a minimizer, we have that ∥Φ(bΘ)−z∥2
2≤ ∥Φ(Θ ⋆)−z∥2
2. Consequently,
∥Φ(Θ ⋆)−z∥2
2< min
Θ⋆+∆∈K:∥∆∥F≥ρ∥Φ(Θ ⋆+ ∆)−z∥2
2=⇒bΘ̸∈ {Θ⋆+ ∆∈ K:∥∆∥F≥ρ}
=⇒ ∥bΘ−Θ⋆∥F< ρ.
Thus, our strategy will attempt to find a minimum ρ > 0that makes the first expression true.
Equivalently, we show that the following quantity is non-positive
∥Φ(Θ ⋆)−z∥2
2− min
Θ⋆+∆∈K:∥∆∥F≥ρ∥Φ(Θ ⋆+ ∆)−z∥2
2
=−
min
Θ⋆+∆∈K:∥∆∥F≥ρ2⟨Φ(∆) ,Φ(Θ ⋆)−z⟩+∥Φ(∆)∥2
2
= max
M+∆∈K:∥∆∥F≥ρ2⟨Φ(∆) , η⟩ − ∥Φ(∆)∥2
2
= max
t≥ρmax
M+∆∈K:∥∆∥F=t2⟨Φ(∆) , η⟩ − ∥Φ(∆)∥2
2.
Intuitively, when tis large, the quadratic term will dominate the inner product making the entire
expression non-positive. We will employ a geometric fact about the nuclear norm ball.
Lemma A.1. LetK={Θ :∥Θ∥∗≤ ∥Θ⋆∥∗}. IfΘ⋆+ ∆∈ K then∥P⊥(∆)∥∗≤ −⟨ ∆, UV⊤⟩ ≤
∥P∥(∆)∥F.
Proof. If∥Θ⋆+ ∆∥∗>∥Θ⋆∥∗thenΘ⋆+ ∆̸∈ K. By the convexity of the nuclear norm ball, we
have that
∥Θ⋆+ ∆∥∗≥ ∥Θ⋆∥∗+⟨∆, UV⊤⟩+⟨∆, W⟩ ∀ W:W=P⊥(W),∥W∥2≤1.
Consequently, as the dual norm to ∥ · ∥ 2is the nuclear norm ∥ · ∥∗we have
∥Θ⋆+ ∆∥∗≥ ∥Θ⋆∥∗+⟨∆, UV⊤⟩+∥P⊥(∆)∥∗.
Thus, if ⟨∆, UV⊤⟩+∥P⊥(∆)∥∗>0thenΘ⋆+ ∆̸∈ K. Consequently, if Θ⋆+ ∆∈ K then
⟨∆, UV⊤⟩+∥P⊥(∆)∥∗≤0.
Recalling that ∥M∥F≤ ∥M∥∗for any matrix M, an interesting consequence of the above lemma is
that∥P⊥(∆)∥F≤ ∥P∥(∆)∥Fwhich implies ∥P∥(∆)∥2
F≤ ∥∆∥2
F≤2∥P∥(∆)∥2
F. That is, the total
error is dominated by the error in the tanget space of Θ⋆.
Applying this lemma, we have that
max
M+∆∈K:∥∆∥F=t2⟨Φ(∆) , η⟩−∥Φ(∆)∥2
2≤ max
∆:∥P⊥(∆)∥∗≤∥P∥(∆)∥F,∥∆∥F=t2⟨Φ(∆) , η⟩ − ∥Φ(∆)∥2
2
= max
∆:∥P⊥(∆)∥∗≤∥P∥(∆)∥F,∥∆∥F=t2⟨Φ(P∥(∆)) + Φ( P⊥(∆)), η⟩ − ∥Φ(∆)∥2
2
≤ max
∆:∥P⊥(∆)∥∗≤∥P∥(∆)∥F,∥∆∥F=t2⟨Φ(P∥(∆)), η⟩ − ∥Φ(∆)∥2
2
+ max
∆:∥P⊥(∆)∥∗≤∥P∥(∆)∥F,∥∆∥F=t2⟨Φ(P⊥(∆)), η⟩
where the equality uses the fact that ∆ =P∥(∆) + P⊥(∆)and the linearity of Φ. For any v∈RN
we have
⟨Φ(∆) , v⟩=⟨∆,NX
n=1Xnvn⟩=:⟨∆,Φ∗(v)⟩
where Φ∗denotes the adjoint of Φ. We also recognize that the operator Φ∗Φ :Rd1×d2→Rd1×d2
is also linear, defined as Φ∗Φ(M) = Φ∗({⟨Xn, M⟩}n) =PN
n=1Xn⟨Xn, M⟩. Consequently
(Φ∗Φ)1/2is well-defined and is the same operator as Φ∗Φafter taking the square root of its eigenval-
ues.
The next three lemmas bound the two terms of above. Combining them yields the result of the
theorem.
16Lemma A.2. With probability at least 1−δwe have
max
∆:∥P⊥(∆)∥∗≤∥P∥(∆)∥F,∥∆∥F=t2⟨Φ(P⊥(∆)), η⟩ ≤2t∥P⊥(Φ∗Φ)1/2∥op(p
d1+p
d2+p
2 log(1 /δ)).
Proof. Computing this term amounts to bounding a Gaussian width. Begin by recognizing that by the
non-expansive property of projections, ∥P∥(∆)∥F≤ ∥∆∥F≤twhich results in the simplification:
max
∆:∥P⊥(∆)∥∗≤∥P∥(∆)∥F,∥∆∥F=t2⟨Φ(P⊥(∆)), η⟩ ≤ max
∆:∥P⊥(∆)∥∗≤t2⟨Φ(P⊥(∆)), η⟩
= max
∆:∥P⊥(∆)∥∗≤t2⟨NX
n=1ηnXn, P⊥(∆)⟩
= max
∆:∥P⊥(∆)∥∗≤t2⟨P⊥(NX
n=1ηnXn), P⊥(∆)⟩
≤2t∥P⊥(NX
n=1ηnXn)∥op
using the fact that the operator norm and nuclear norm are dual to each other, and that the projection
P⊥is non-expansive. Note that
NX
n=1ηnXn=mat(NX
n=1ηnvec(Xi)) = mat((NX
n=1vec(Xn)vec(Xn)⊤)1/2vec(η′)) =: (Φ∗Φ)1/2(η)
where η′∈Rd1×d2withη′
i,j∼ N(0,1). We then observe that
∥P⊥(NX
n=1ηnXn)∥op=∥P⊥(mat((NX
n=1vec(Xn)vec(Xn)⊤)1/2vec(η′)))∥op
≤ ∥P⊥(Φ∗Φ)1/2∥op∥η′∥op
which completes the proof of the first claim. Recognizing that ∥η′∥opis just the largest singular value
of a Gaussian matrix, we find that E[sup∥u∥2≤1,∥v∥2≤1⟨uv⊤, η⟩]≤√d1+√d2by Exercise 5.14 of
[52]. Applying a sub-Gaussian tail bound completes the proof.
Lemma A.3. Define µ:=∥(Φ∗Φ)1/2((P∥Φ∗ΦP∥)†)1/2∥op. Then
max
∆:∥P⊥(∆)∥∗≤∥P∥(∆)∥F,∥∆∥F=t2⟨Φ(P∥(∆)), η⟩ − ∥Φ(∆)∥2
2
≤ max
∆:∥P∥(∆)∥F≥t/√
22⟨Φ(P∥(∆)), η⟩ −(1−µ)∥Φ(P∥(∆))∥2
2
Proof. Recognizing that Φ(∆)∈RNwe have
∥Φ(∆)∥2
2=∥Φ(P∥(∆) + P⊥(∆))∥2
2
=∥Φ(P∥(∆)) + Φ( P⊥(∆))∥2
2
=∥Φ(P∥(∆))∥2
2+∥Φ(P⊥(∆))∥2
2+ 2⟨Φ(P∥(∆)),Φ(P⊥(∆))⟩.
To aid in readability, we make a number of notational modifications. First, we drop parentheses so that
Φ(P∥(∆)) is just notated as ΦP∥∆. Second, we define M†/2:= (M†)1/2where M†is the pseudoin-
verse. If Φ∗Φis invertible restricted to the range of P∥, then P∥∆ = ( P∥Φ∗ΦP∥)†/2(Φ∗Φ)1/2P∥∆
for all ∆. Thus,
|⟨Φ(P∥(∆)),Φ(P⊥(∆))⟩|=|⟨ΦP∥∆,ΦP⊥∆⟩|
=|⟨P∥∆,(Φ∗Φ)P⊥∆⟩|
=|⟨(Φ∗Φ)1/2P∥∆,(Φ∗Φ)1/2P⊥∆⟩|
=|⟨(Φ∗Φ)1/2P∥(P∥Φ∗ΦP∥)†/2(Φ∗Φ)1/2P∥∆,(Φ∗Φ)1/2P⊥∆⟩|
≤ ∥(Φ∗Φ)1/2(P∥Φ∗ΦP∥)†/2(Φ∗Φ)1/2P∥∆∥F∥(Φ∗Φ)1/2P⊥∆∥F
≤ ∥(Φ∗Φ)1/2(P∥Φ∗ΦP∥)†/2∥op∥(Φ∗Φ)1/2P∥∆∥F∥(Φ∗Φ)1/2P⊥∆∥F
17where the last two lines follow from Cauchy-Schwartz. Observe that for µ <1we have
a2+b2−2abµ= (1−µ)a2+ (1−µ)b2+µa2+µb2−2abµ
= (1−µ)a2+ (1−µ)b2+µ(a−b)2
≥(1−µ)a2.
Thus, if µ:=∥(Φ∗Φ)1/2(P∥Φ∗ΦP∥)†/2∥opthen
∥Φ(∆)∥2
2≥ ∥Φ(P∥(∆))∥2
2+∥Φ(P⊥(∆))∥2
2−2|⟨Φ(P∥(∆)),Φ(P⊥(∆))⟩|
≥ ∥Φ(P∥(∆))∥2
2+∥Φ(P⊥(∆))∥2
2−2µ∥(Φ∗Φ)1/2P∥∆∥F∥(Φ∗Φ)1/2P⊥∆∥F
≥(1−µ)∥Φ(P∥(∆))∥2
2
Thus,
max
∆:∥P⊥(∆)∥∗≤∥P∥(∆)∥F,∥∆∥F=t2⟨Φ(P∥(∆)), η⟩ − ∥Φ(∆)∥2
2
≤ max
∆:∥P⊥(∆)∥∗≤∥P∥(∆)∥F,∥∆∥F=t2⟨Φ(P∥(∆)), η⟩ −(1−µ)∥Φ(P∥(∆))∥2
2
≤ max
∆:∥P⊥(∆)∥F≤∥P∥(∆)∥F,∥∆∥F=t2⟨Φ(P∥(∆)), η⟩ −(1−µ)∥Φ(P∥(∆))∥2
2
≤ max
∆:∥P∥(∆)∥F≥t/√
22⟨Φ(P∥(∆)), η⟩ −(1−µ)∥Φ(P∥(∆))∥2
2
where we’ve used the facts that ∥ · ∥∗≤ ∥ · ∥ Fandt2=∥∆∥2
F=∥P∥(∆)∥2
F+∥P⊥(∆)∥2
F≤
2∥P∥(∆)∥2
F.
Lemma A.4. LetK= min {log2(N), d1d2}. Then for any α >0, if
t≥1
1−µr
16tr
(P∥Φ∗ΦP∥)†
+ 32∥(P∥Φ∗ΦP∥)†∥oplog(K/δ) +2α∥(P∥Φ∗ΦP∥)†∥op
1−µ
then with probability at least 1−δwe have
αt+ max
∆:∥P∥(∆)∥F≥t/√
22⟨Φ(P∥(∆)), η⟩ −(1−µ)∥Φ(P∥(∆))∥2
2≤0.
Proof. The linear operator ΦP∥:Rd1×d2→RNcan be decomposed as ΦP∥=PN
n=1βnwnψn
where {wn}nare orthonormal on RT,{ψn}nare orthonormal linear operators on Rd1×d2, and
βn≥0are decreasing. For k= 0,1, . . . , min{log2(N), d1d2} −1letWk= [w2k, . . . , w 2k+1−1]
so that
β2k= max
∥∆∥F=1,∥u∥2=1u⊤W⊤
kΦP∥(∆)≥ min
∥∆∥F=1,∥u∥2=1u⊤W⊤
kΦP∥(∆)≥β2k+1
Then
max
∆:∥P∥(∆)∥F≥t/√
22⟨Φ(P∥(∆)), η⟩ −(1−µ)∥Φ(P∥(∆))∥2
2
= max
∆:∥P∥(∆)∥F≥t/√
2KX
k=02⟨WkW⊤
kΦ(P∥(∆)), η⟩ −(1−µ)∥WkW⊤
kΦ(P∥(∆))∥2
2
= max
∆:∥P∥(∆)∥F≥t/√
2KX
k=02⟨W⊤
kΦ(P∥(∆)), W⊤
kη⟩ −(1−µ)∥W⊤
kΦ(P∥(∆))∥2
2
≤KX
k=0max
∆:∥P∥(∆)∥F≥t/√
22∥W⊤
kΦ(P∥(∆))∥2∥W⊤
kη∥2−(1−µ)∥W⊤
kΦ(P∥(∆))∥2
2
≤KX
k=0t√
2β2k+1∥W⊤
kη∥2−t2(1−µ)
2β2
2k+1
18where the first inequality holds by Cauchy-Schwartz, and the second holds for all t≥
max k=0,...,K∥W⊤
kη∥22√
2
(1−µ)β2k+1. Moreover, t√
2β2k+1∥W⊤
kη∥2−t2(1−µ)
2β2
2k+1≤ −αtif
t≥max
k=0,...,K∥W⊤
kη∥22√
2
(1−µ)β2k+1+ max
k=0,...,K2α
(1−µ)β2
2k+1=s
max
k=0,...,K8∥W⊤
kη∥2
2
(1−µ)2β2
2k+1+ max
k=0,...,K2α
(1−µ)β2
2k+1
Note that for K= min {log2(N), d1d2}we have
P(∪K
k=1{∥W⊤
kη∥2≥√
2k+p
2 log( K/δ)})≤P(∪K
k=1{∥W⊤
kη∥2≥E[∥W⊤
kη∥2] +p
2 log( K/δ)})≤δ.
On this good event, we have that
max
k=0,...,K∥W⊤
kη∥2
2
β2
2k+1≤max
k=0,...,K(√
2k+p
2 log( K/δ))2
β2
2k+1
≤max
k=0,...,K2k+1
β2
2k+1+4 log( K/δ)
β2
2k+1
≤2NX
n=11
β2n+ max
n=1,...,N4 log( K/δ)
β2n
= 2tr
(P∥Φ∗ΦP∥)†
+ 4∥(P∥Φ∗ΦP∥)†∥oplog(K/δ)
where we use the fact that
NX
n=11
β2n=KX
k=02k+1−1X
n=2k1
β2n≥K−1X
k=02k
β2
2k+1≥ max
k=0,...,K−12k
β2
2k+1.
B Additional Details on Experiments
B.1 Further Details on Dataset
The photostimulation data were collected from transgenic reporter mice Ai229, which express Cre-
recombinase-dependent cytosolic GCaMP6m and soma-targeted ChRmine, crossed with the Vglut1-
cre mouse line. Imaging and photostimulation experiments were performed on a Bergamo (Thorlabs)
microscope equipped with a 16x (0.8 NA) Nikon objective. Post-hoc motion correction and neuron
segmentation were performed with the Suite2p package [ 82] (https://github.com/MouseLand/suite2p).
B.2 Further Details on Experiment of Section 3.1
We split each of our photostimulation datasets into non-overlapping training and test datasets. All
models were trained exclusively using the training dataset and were then evaluated (as shown in
Figure 2) using the test dataset. To build our test datasets, we randomly chose 5 (out of the 100 total)
unique photostimulation patterns and then included all 70-timestep windows about each of the 20
instances of those 5 unique photostimuli. The resulting test set amounted to ∼20% of each dataset. In
Figure 2, all models were evaluated using these 70-timestep test sequences of the form {yt, ut}70
t=1,
where yt∈Rdis the recorded neural activity and ut∈Rdis the photostimulation delivered at time t.
During evaluation on a given test window, all models were provided {yt}4
t=1and{ut}70
t=1to predict
{yt}70
t=5.
Autoregressive-k models: We fit the full-rank AR- kmodels to training datasets via linear regression
by expressing
yt+1=k−1X
s=0Asyt−s+k−1X
s=0Bsut−s+v (B.1)
19asY=XW , where
Y=
y1
y2
...
yT+1
X=
y0y−1. . . y 1−ku0u−1. . . u 1−k1
y1y0. . . y 2−ku1u0. . . u 2−k1
.................. 1
yTyT−1. . . y T+1−kuTuT−1. . . u T+1−k1

W=
A0
A1
...
Ak−1
B0
B1
...
Bk−1
v

and the closed-form solution is cW= (XTX)−1XTY. For the low-rank AR- kmodels, we fit all
parameters via gradient descent using Adam [ 83] over 100 training epochs with a learning rate of
0.01. Gradient descent was implemented in PyTorch and ran on a single NVIDIA Tesla T4 GPU.
During evaluation of the AR- kmodels, for each test window we first computed byk+1given{yt, ut}k
t=1
using (B.1) . Then for all subsequent predictions, on the right-hand side of (B.1) we replaced all
instances of ytwithbytfort > k . In this manner, each entire roll-out prediction of {yt}70
t=k+1used all
photostimulation inputs {ut}70
t=1, but only the first ktimesteps of neural activity {yt}k
t=1. All AR- k
models in this paper used k= 4.
Gated recurrent unit (GRU) networks: GRU networks were loosely based on the sequential
variational autoencoders of [ 22]. Each model consisted of an encoder GRU network that encodes
k= 4initial timesteps of recorded neural activity into a bottlenecked initial state for a decoder GRU
network. The decoder then unrolls an entire predicted timeseries of recorded neural activity given
(as input) all photostimulation that was delivered over that time period. Model fitting proceeded by
optimizing the evidence lower bound (ELBO) with respect to all model parameters. Both encoder
and decoder GRUs had 512 hidden units. We used Adam optimization with a learning rate of 0.001
over 4000 training epochs of batch size 100. Models were implemented with PyTorch, and optimized
on a single NVIDIA Tesla T4 GPU.
Evaluation metrics: We evaluated all models using roll-out predictions on held-out test windows. We
quantified performance with mean squared error between recorded and predicted neural activity for
each neuron. We also performed thresholded response detection, whereby detections were defined as
timesteps at which a given neuron’s measured calcium fluorescence exceeded a predefined threshold.
To calculate a receiver operator characteristic (ROC) curve, we enumerated a range of thresholds,
normalized by the standard deviation of each neuron’s empirical activity distribution, and performed
threshold detection separately on the real and model-predicted neural activity traces. We then compute
the overall false-positive rate and true-positive rate at each threshold level to trace out an ROC curve.
We calculate area under the ROC curve (AUROC) to quantify the accuracy of each model.
Longer roll-out evaluations: To assess AR- kmodels’ ability to predict over longer time horizons,
we implemented another train-test strategy, where the first 80% of timesteps in a recording are used
for training, and the last 20% of timesteps (6736 steps) are used for testing. During the test phase, we
use the same procedure described above, providing only the k= 4initial timesteps of neural activity
and then unrolling predictions over the remainder of this long test window. We report these results in
Figure 5.
20predictionmeasured activity
AUROC MSE
0.0 1.0false positi ve rate (FPR)true positiv e rate (TPR)
0.01.0ROC cur ve for indir ect responses
0.0 1.0false positi ve rate (FPR)true positiv e rate (TPR)
0.01.0ROC cur ve for all responses
dbindirect stimulationdirect stimulation to neuron i(    F/F)imaged activity of neuron ia
AR-K model (full rank) r = 663
AR-K model (low rank) r = 15 AR-K model (low rank) r = 5AR-K model (low rank) r = 35
0 25 50 time (s) 100 0 25 50 time (s) 100
all responses
indirect responses
AR-K r ank = 663
AR-K r ank = 100
AR-K r ank = 50
AR-K r ank = 35
AR-K r ank = 15
AR-K r ank = 5AR-K r ank = 10stimulation
inputs
663 100 50     35    15    10      5
AR-K model rank dim4.8e-45.8e-40.85
0.55Figure 5: Longer roll-out evaluations. Same format as in Figure 2.
B.3 Further Details on Experiment of Section 5.1
To fit the Hparameter in this experiment, we generate observations as described in Section 5.1. We
then estimate Has:
bH←arg min
H∈KX
(u,z)∈D∥z−Hu∥2
F
foruour input, and z=Pτ
t=1xtthe observed response, where here xtare the observations generated
from playing input u, and τ= 15 .
AsKis defined with respect to the nuclear norm of the true parameter, which we do not assume is
known, we run each method with a range of possible values for the nuclear-norm constraint, and plot
the performance of each method for the constraint value that has minimum error. We state the value
of the nuclear-norm constraint used for each plot below:
Active Random Uniform
Mouse 1, rank 15 10 10 10
Mouse 1, rank 35 10 10 10
Mouse 2, rank 15 5 5 5
Mouse 2, rank 35 5 5 5
Mouse 3 (FoV A), rank 15 25 25 25
Mouse 3 (FoV A), rank 35 25 25 25
Mouse 3 (FoV B), rank 15 50 100 100
Mouse 3 (FoV B), rank 35 100 100 100
Table 1: Nuclear-Norm Constraint Settings for Results of Section 5.1
To choose the input rank of Algorithm 1, we ran our experiment with several different ranks and
provide results for the best-performing rank. We found, however, that results are typically robust to
the setting of the rank parameter of Algorithm 1, and our choice of rdid not significantly impact
performance. Furthermore, we believe this could effectively be chosen adaptively. We state our
chosen values of rbelow.
For all experiments, we add observation noise distributed as N(0,0.4·I)toz=Pτ
t=1xt.
21Input Rank r
Mouse 1, rank 15 10
Mouse 1, rank 35 10
Mouse 2, rank 15 5
Mouse 2, rank 35 5
Mouse 3 (FoV A), rank 15 25
Mouse 3 (FoV A), rank 35 25
Mouse 3 (FoV B), rank 15 25
Mouse 3 (FoV B), rank 35 50
Table 2: Input Rank rfor Results of Section 5.1
(a) Ground Truth
 (b) Error = 0.1
 (c) Error = 0.2
 (d) Error = 0.3
 (e) Error = 0.4
(f) Error = 0.5
 (g) Error = 0.6
 (h) Error = 0.7
 (i) Error = 0.8
 (j) Error = 0.9
Figure 6: Causal connectivity matrix for Mouse 3 FoV B with different levels of estimation error
(corresponding to Figure 3).
To ground the estimation error values shown in Figure 3, in Figure 6 will illustrate the causal
connectivity matrix for Mouse 3 FoV B with different levels of estimation error.
B.4 Further Details on Experiment of Section 5.2
For this experiment, on the data Dwe observed thus far, we fit the AR- kmodel described in
Section 3.1 with k= 1. We found that for this experiment, simply using the least squares estimator
with no low-rank penalty produced the best results. We use the same estimation method for both our
method and the baseline method.
Given a input response trajectory in the test set, (x1, . . . , x 15), with input u, to compute the test MSE,
we provide our learned dynamics model with the initial state x1and input u, and then roll this out for
15 timesteps to generate predictions bx2, . . . ,bx15. Precisely, if bAandbBare our estimated parameters,
we let
bx2=bAx1+bBu,
bxt+1=bAbxt, t≥1.
We the compute the MSE on this segment as:
1
1415X
t=2∥bxt−xt∥2
2
It is not immediately obvious how to apply Algorithm 1 to this setting, since we must choose each
trajectory sequentially, and once we have observed a trajectory it can no longer be chosen again.
Rather than solving the optimization of Algorithm 1 to find the best inputs, we instead seek to
22(a) Neuron 0, MSE = 0.175
 (b) Neuron 0, MSE = 0.150
 (c) Neuron 0, MSE = 0.140
 (d) Neuron 0, MSE = 0.138
(e) Neuron 3, MSE = 0.175
 (f) Neuron 3, MSE = 0.150
 (g) Neuron 3, MSE = 0.140
 (h) Neuron 3, MSE = 0.138
(i) Neuron 95, MSE =
0.175
(j) Neuron 95, MSE =
0.150
(k) Neuron 95, MSE =
0.140
(l) Neuron 95, MSE =
0.138
Figure 7: Estimated neural activity vs true neural activity on heldout trials for Mouse 2, Neurons 0, 3,
and 95, at different levels of overall MSE on heldout trials (corresponding to Figure 4).
iteratively choose the next input that would maximize “information gain” in some sense. In particular,
note that applying the Frank-Wolfe algorithm [80] to the objective, if we have inputs Uavailable:
min
λ∈△Utr((V⊤Λ(λ)V)−1),
the update is given by:
ui+1= min
u∈Uu⊤V(V⊤Λ(λi)V)−2V⊤u
λi+1←(1−γi)λi+γiI{u=ui+1}
for learning rate γi.
In this experiment, we simply choose unas above, with Uthe set of remaining active inputs in Dtrain,
andΛ(λn)replaced withPn−1
s=1usu⊤
s. This therefore approximates the solution to the experiment
design of Algorithm 1, and has the advantage of being very computationally efficient. Furthermore,
we set Vto be the right singular vectors of bB. We believe this is reasonable in dynamical system
settings with fast decay.
The primary hyperparameter for this experiment is the choice of r, the rank of V. As in the previous
section, we did not find the results particularly sensitive to setting of r. For each dataset, we ran with
r∈[25,50,75,100,125,150], and include results for the best-performing setting.
For both sets of experiments in Section 5, we ran on 56 Intel(R) Xeon(R) CPU E5-2690 v4 @
2.60GHz CPUs.
To ground the MSE values shown in Figure 4, in Figure 7 we plot the predictions from the estimated
model at different MSE values on heldout trials for Mouse 2.
23NeurIPS Paper Checklist
1.Claims
Question: Do the main claims made in the abstract and introduction accurately reflect the
paper’s contributions and scope?
Answer: [Yes]
Justification: We validate all claims with theoretical results or experiments.
Guidelines:
•The answer NA means that the abstract and introduction do not include the claims
made in the paper.
•The abstract and/or introduction should clearly state the claims made, including the
contributions made in the paper and important assumptions and limitations. A No or
NA answer to this question will not be perceived well by the reviewers.
•The claims made should match theoretical and experimental results, and reflect how
much the results can be expected to generalize to other settings.
•It is fine to include aspirational goals as motivation as long as it is clear that these goals
are not attained by the paper.
2.Limitations
Question: Does the paper discuss the limitations of the work performed by the authors?
Answer: [Yes]
Justification: Please see our discussion section.
Guidelines:
•The answer NA means that the paper has no limitation while the answer No means that
the paper has limitations, but those are not discussed in the paper.
• The authors are encouraged to create a separate "Limitations" section in their paper.
•The paper should point out any strong assumptions and how robust the results are to
violations of these assumptions (e.g., independence assumptions, noiseless settings,
model well-specification, asymptotic approximations only holding locally). The authors
should reflect on how these assumptions might be violated in practice and what the
implications would be.
•The authors should reflect on the scope of the claims made, e.g., if the approach was
only tested on a few datasets or with a few runs. In general, empirical results often
depend on implicit assumptions, which should be articulated.
•The authors should reflect on the factors that influence the performance of the approach.
For example, a facial recognition algorithm may perform poorly when image resolution
is low or images are taken in low lighting. Or a speech-to-text system might not be
used reliably to provide closed captions for online lectures because it fails to handle
technical jargon.
•The authors should discuss the computational efficiency of the proposed algorithms
and how they scale with dataset size.
•If applicable, the authors should discuss possible limitations of their approach to
address problems of privacy and fairness.
•While the authors might fear that complete honesty about limitations might be used by
reviewers as grounds for rejection, a worse outcome might be that reviewers discover
limitations that aren’t acknowledged in the paper. The authors should use their best
judgment and recognize that individual actions in favor of transparency play an impor-
tant role in developing norms that preserve the integrity of the community. Reviewers
will be specifically instructed to not penalize honesty concerning limitations.
3.Theory Assumptions and Proofs
Question: For each theoretical result, does the paper provide the full set of assumptions and
a complete (and correct) proof?
Answer: [Yes]
24Justification: Proofs are given in the supplemental for stated theorems (or citations given to
works where they proved).
Guidelines:
• The answer NA means that the paper does not include theoretical results.
•All the theorems, formulas, and proofs in the paper should be numbered and cross-
referenced.
•All assumptions should be clearly stated or referenced in the statement of any theorems.
•The proofs can either appear in the main paper or the supplemental material, but if
they appear in the supplemental material, the authors are encouraged to provide a short
proof sketch to provide intuition.
•Inversely, any informal proof provided in the core of the paper should be complemented
by formal proofs provided in appendix or supplemental material.
• Theorems and Lemmas that the proof relies upon should be properly referenced.
4.Experimental Result Reproducibility
Question: Does the paper fully disclose all the information needed to reproduce the main ex-
perimental results of the paper to the extent that it affects the main claims and/or conclusions
of the paper (regardless of whether the code and data are provided or not)?
Answer: [Yes]
Justification: To the extent possible, we provide as much information as we can on all results
to ensure they are reproducible.
Guidelines:
• The answer NA means that the paper does not include experiments.
•If the paper includes experiments, a No answer to this question will not be perceived
well by the reviewers: Making the paper reproducible is important, regardless of
whether the code and data are provided or not.
•If the contribution is a dataset and/or model, the authors should describe the steps taken
to make their results reproducible or verifiable.
•Depending on the contribution, reproducibility can be accomplished in various ways.
For example, if the contribution is a novel architecture, describing the architecture fully
might suffice, or if the contribution is a specific model and empirical evaluation, it may
be necessary to either make it possible for others to replicate the model with the same
dataset, or provide access to the model. In general. releasing code and data is often
one good way to accomplish this, but reproducibility can also be provided via detailed
instructions for how to replicate the results, access to a hosted model (e.g., in the case
of a large language model), releasing of a model checkpoint, or other means that are
appropriate to the research performed.
•While NeurIPS does not require releasing code, the conference does require all submis-
sions to provide some reasonable avenue for reproducibility, which may depend on the
nature of the contribution. For example
(a)If the contribution is primarily a new algorithm, the paper should make it clear how
to reproduce that algorithm.
(b)If the contribution is primarily a new model architecture, the paper should describe
the architecture clearly and fully.
(c)If the contribution is a new model (e.g., a large language model), then there should
either be a way to access this model for reproducing the results or a way to reproduce
the model (e.g., with an open-source dataset or instructions for how to construct
the dataset).
(d)We recognize that reproducibility may be tricky in some cases, in which case
authors are welcome to describe the particular way they provide for reproducibility.
In the case of closed-source models, it may be that access to the model is limited in
some way (e.g., to registered users), but it should be possible for other researchers
to have some path to reproducing or verifying the results.
5.Open access to data and code
25Question: Does the paper provide open access to the data and code, with sufficient instruc-
tions to faithfully reproduce the main experimental results, as described in supplemental
material?
Answer: [No]
Justification: We have not yet released our code but plan to in the future. We also hope to
release the data we used in the future.
Guidelines:
• The answer NA means that paper does not include experiments requiring code.
•Please see the NeurIPS code and data submission guidelines ( https://nips.cc/
public/guides/CodeSubmissionPolicy ) for more details.
•While we encourage the release of code and data, we understand that this might not be
possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not
including code, unless this is central to the contribution (e.g., for a new open-source
benchmark).
•The instructions should contain the exact command and environment needed to run to
reproduce the results. See the NeurIPS code and data submission guidelines ( https:
//nips.cc/public/guides/CodeSubmissionPolicy ) for more details.
•The authors should provide instructions on data access and preparation, including how
to access the raw data, preprocessed data, intermediate data, and generated data, etc.
•The authors should provide scripts to reproduce all experimental results for the new
proposed method and baselines. If only a subset of experiments are reproducible, they
should state which ones are omitted from the script and why.
•At submission time, to preserve anonymity, the authors should release anonymized
versions (if applicable).
•Providing as much information as possible in supplemental material (appended to the
paper) is recommended, but including URLs to data and code is permitted.
6.Experimental Setting/Details
Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
results?
Answer: [Yes]
Justification: To the extent possible, we state all hyperparameters.
Guidelines:
• The answer NA means that the paper does not include experiments.
•The experimental setting should be presented in the core of the paper to a level of detail
that is necessary to appreciate the results and make sense of them.
•The full details can be provided either with the code, in appendix, or as supplemental
material.
7.Experiment Statistical Significance
Question: Does the paper report error bars suitably and correctly defined or other appropriate
information about the statistical significance of the experiments?
Answer: [Yes]
Justification: Where possible, we state confidence intervals in our results.
Guidelines:
• The answer NA means that the paper does not include experiments.
•The authors should answer "Yes" if the results are accompanied by error bars, confi-
dence intervals, or statistical significance tests, at least for the experiments that support
the main claims of the paper.
•The factors of variability that the error bars are capturing should be clearly stated (for
example, train/test split, initialization, random drawing of some parameter, or overall
run with given experimental conditions).
26•The method for calculating the error bars should be explained (closed form formula,
call to a library function, bootstrap, etc.)
• The assumptions made should be given (e.g., Normally distributed errors).
•It should be clear whether the error bar is the standard deviation or the standard error
of the mean.
•It is OK to report 1-sigma error bars, but one should state it. The authors should
preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis
of Normality of errors is not verified.
•For asymmetric distributions, the authors should be careful not to show in tables or
figures symmetric error bars that would yield results that are out of range (e.g. negative
error rates).
•If error bars are reported in tables or plots, The authors should explain in the text how
they were calculated and reference the corresponding figures or tables in the text.
8.Experiments Compute Resources
Question: For each experiment, does the paper provide sufficient information on the com-
puter resources (type of compute workers, memory, time of execution) needed to reproduce
the experiments?
Answer: [Yes]
Justification: Computational resources are listed in the supplemental.
Guidelines:
• The answer NA means that the paper does not include experiments.
•The paper should indicate the type of compute workers CPU or GPU, internal cluster,
or cloud provider, including relevant memory and storage.
•The paper should provide the amount of compute required for each of the individual
experimental runs as well as estimate the total compute.
•The paper should disclose whether the full research project required more compute
than the experiments reported in the paper (e.g., preliminary or failed experiments that
didn’t make it into the paper).
9.Code Of Ethics
Question: Does the research conducted in the paper conform, in every respect, with the
NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines ?
Answer: [Yes]
Justification: Our work does not raise any ethical concerns, and conforms with all ethical
guidelines.
Guidelines:
•The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
•If the authors answer No, they should explain the special circumstances that require a
deviation from the Code of Ethics.
•The authors should make sure to preserve anonymity (e.g., if there is a special consid-
eration due to laws or regulations in their jurisdiction).
10.Broader Impacts
Question: Does the paper discuss both potential positive societal impacts and negative
societal impacts of the work performed?
Answer: [NA]
Justification: This work studies fundamental concepts in machine learning and neuroscience,
and we do not believe it has any immediate societal consequences.
Guidelines:
• The answer NA means that there is no societal impact of the work performed.
•If the authors answer NA or No, they should explain why their work has no societal
impact or why the paper does not address societal impact.
27•Examples of negative societal impacts include potential malicious or unintended uses
(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
(e.g., deployment of technologies that could make decisions that unfairly impact specific
groups), privacy considerations, and security considerations.
•The conference expects that many papers will be foundational research and not tied
to particular applications, let alone deployments. However, if there is a direct path to
any negative applications, the authors should point it out. For example, it is legitimate
to point out that an improvement in the quality of generative models could be used to
generate deepfakes for disinformation. On the other hand, it is not needed to point out
that a generic algorithm for optimizing neural networks could enable people to train
models that generate Deepfakes faster.
•The authors should consider possible harms that could arise when the technology is
being used as intended and functioning correctly, harms that could arise when the
technology is being used as intended but gives incorrect results, and harms following
from (intentional or unintentional) misuse of the technology.
•If there are negative societal impacts, the authors could also discuss possible mitigation
strategies (e.g., gated release of models, providing defenses in addition to attacks,
mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
feedback over time, improving the efficiency and accessibility of ML).
11.Safeguards
Question: Does the paper describe safeguards that have been put in place for responsible
release of data or models that have a high risk for misuse (e.g., pretrained language models,
image generators, or scraped datasets)?
Answer: [NA]
Justification: We are not releasing high-risk models or data with this work.
Guidelines:
• The answer NA means that the paper poses no such risks.
•Released models that have a high risk for misuse or dual-use should be released with
necessary safeguards to allow for controlled use of the model, for example by requiring
that users adhere to usage guidelines or restrictions to access the model or implementing
safety filters.
•Datasets that have been scraped from the Internet could pose safety risks. The authors
should describe how they avoided releasing unsafe images.
•We recognize that providing effective safeguards is challenging, and many papers do
not require this, but we encourage authors to take this into account and make a best
faith effort.
12.Licenses for existing assets
Question: Are the creators or original owners of assets (e.g., code, data, models), used in
the paper, properly credited and are the license and terms of use explicitly mentioned and
properly respected?
Answer: [Yes]
Justification: We have credited all those involved with the collection of the data we utilize.
Guidelines:
• The answer NA means that the paper does not use existing assets.
• The authors should cite the original paper that produced the code package or dataset.
•The authors should state which version of the asset is used and, if possible, include a
URL.
• The name of the license (e.g., CC-BY 4.0) should be included for each asset.
•For scraped data from a particular source (e.g., website), the copyright and terms of
service of that source should be provided.
•If assets are released, the license, copyright information, and terms of use in the
package should be provided. For popular datasets, paperswithcode.com/datasets
has curated licenses for some datasets. Their licensing guide can help determine the
license of a dataset.
28•For existing datasets that are re-packaged, both the original license and the license of
the derived asset (if it has changed) should be provided.
•If this information is not available online, the authors are encouraged to reach out to
the asset’s creators.
13.New Assets
Question: Are new assets introduced in the paper well documented and is the documentation
provided alongside the assets?
Answer: [NA]
Justification: No new assets are introduced in this work.
Guidelines:
• The answer NA means that the paper does not release new assets.
•Researchers should communicate the details of the dataset/code/model as part of their
submissions via structured templates. This includes details about training, license,
limitations, etc.
•The paper should discuss whether and how consent was obtained from people whose
asset is used.
•At submission time, remember to anonymize your assets (if applicable). You can either
create an anonymized URL or include an anonymized zip file.
14.Crowdsourcing and Research with Human Subjects
Question: For crowdsourcing experiments and research with human subjects, does the paper
include the full text of instructions given to participants and screenshots, if applicable, as
well as details about compensation (if any)?
Answer: [NA]
Justification: No human subjects were involved in this work.
Guidelines:
•The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
•Including this information in the supplemental material is fine, but if the main contribu-
tion of the paper involves human subjects, then as much detail as possible should be
included in the main paper.
•According to the NeurIPS Code of Ethics, workers involved in data collection, curation,
or other labor should be paid at least the minimum wage in the country of the data
collector.
15.Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
Subjects
Question: Does the paper describe potential risks incurred by study participants, whether
such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
approvals (or an equivalent approval/review based on the requirements of your country or
institution) were obtained?
Answer: [NA]
Justification: No human subjects were involved with this work.
Guidelines:
•The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
•Depending on the country in which research is conducted, IRB approval (or equivalent)
may be required for any human subjects research. If you obtained IRB approval, you
should clearly state this in the paper.
•We recognize that the procedures for this may vary significantly between institutions
and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
guidelines for their institution.
•For initial submissions, do not include any information that would break anonymity (if
applicable), such as the institution conducting the review.
29