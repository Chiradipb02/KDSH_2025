Trading off Consistency and Dimensionality of Convex
Surrogates for Multiclass Classification
Enrique Nueve
Department of Computer Science
University of Colorado Boulder
enrique.nueveiv@colorado.eduBo Waggoner
Department of Computer Science
University of Colorado Boulder
bwag@colorado.edu
Dhamma Kimpara
Department of Computer Science
University of Colorado Boulder
dhamma.kimpara@colorado.eduJessie Finocchiaro∗
Department of Computer Science
Boston College
finocch@bc.edu
Abstract
In multiclass classification over noutcomes, we typically optimize some surrogate
lossL:Rd× Y → Rassigning real-valued error to predictions in Rd. In this
paradigm, outcomes must be embedded into the reals with dimension d≈nin
order to design a consistent surrogate loss. Consistent losses are well-motivated
theoretically, yet for large n, such as in information retrieval and structured pre-
diction tasks, their optimization may be computationally infeasible. In practice,
outcomes are typically embedded into some Rdford≪n, with little known about
their suitability for multiclass classification. We investigate two approaches for
trading off consistency and dimensionality in multiclass classification while using
a convex surrogate loss. We first formalize partial consistency when the optimized
surrogate has dimension d≪n. We then check if partial consistency holds under
a given embedding and low-noise assumption, providing insight into when to use a
particular embedding into Rd. Finally, we present a new method to construct (fully)
consistent losses with d≪nout of multiple problem instances. Our practical
approach leverages parallelism to sidestep lower bounds on d.
1 Introduction
Multiclass classification, due to its combinatorial and discontinuous nature, is intractable to optimize
directly, which drives machine learners to optimize some nicer surrogate loss . To ensure these
surrogates properly “correspond” to the discrete classification task, we seek to design consistent
surrogates. If one uses a consistent surrogate loss, in the limit of infinite data and model expressivity,
one ends up with the same classifications as if one had solved the original intractable problem directly
with probability 1.
Surrogate losses form the backbone of gradient-based optimization for classification tasks. Optimizing
a surrogate is easier than direct optimization, but a large dimension dof the surrogate loss L:
Rd× Y → Rcan make gradient-based optimization intractable. Therefore, previous literature has
operated under the premise that the prediction dimension dshould be as low as possible, subject to
consistency for the classification task [Ramaswamy and Agarwal, 2016, Finocchiaro et al., 2024,
2020]. For multi-class classification over noutcomes, the lower bound on disn−1[Ramaswamy
and Agarwal, 2016].
∗Most of this work was completed while author was at Harvard University CRCS
38th Conference on Neural Information Processing Systems (NeurIPS 2024).These previous works implicitly focus on a binary approach to consistency: a surrogate is either
consistent for every possible label distribution, or it is not consistent. But there is a way out: lower
bounds on the surrogate dimension drely on edge-cases that rarely show up in reality [Ramaswamy
and Agarwal, 2016]. As a result, practitioners are often willing to trade-off the guarantee of con-
sistency in order to improve the computational tractability of optimization. However, we currently
lack rigorous analysis tools to analyze many of the partially-consistent surrogates commonly used in
practice. Thus, unlike previous works, our work focuses on this more realistic paradigm of partial
consistency. We apply our unique approach to rigorously analyze a popular surrogate construction
that encompasses methods such as one-hot and binary encoding. Our approach allows for fine-grained
control of the trade-off between consistency and dimension.
Prior works have informally brushed upon the proposed partial-consistency paradigm, without
rigorous study. For example, Agarwal and Agarwal [2015] impose a low-noise assumption to
construct a surrogate for classification with d= log( n). However, their work does not provide any
way to control the consistency-dimension trade-off. Similarly, Struminsky et al. [2018] characterize
the excess risk bounds of inconsistent surrogates, which teaches us about the learning rates for
inconsistent surrogates, but not under which distributional assumptions we can recover consistency
guarantees.
Using different techniques than both of these approaches, we seek to understand the tradeoffs of
consistency, surrogate prediction dimension, and number of problem instances through the use of
polytope embeddings which are common in the literature [Wainwright et al., 2008, Blondel et al.,
2020]. When embedding outcomes into d≪ndimensions, we first show there always exists a
set of distributions where hallucinations occur: where the report minimizing the surrogate leads
to a prediction ˆysuch that the underlying true distribution has no weight on the prediction; that is,
Pr[Y= ˆy] = 0 (Theorem 3). Following this, we show that every polytope embedding is partially
consistent under strong enough low-noise assumptions (Theorem 5). Finally, we demonstrate through
leveraging the embedding structure and multiple problem instances that the mode (in particular, a
full rank ordering) over noutcomes embedded into an
2dimensional surrogate space is elicitable
over all distributions via O(n2)problem instances (Theorem 10). This alternative approach to
recovering consistency is parallelizable, detangling the complexity of gradient computation of one
high-dimensional surrogate.
2 Background and Notation
LetYbe a finite label space, and throughout let n=|Y|. Define RY
+to be the nonnegative orthant.
Let∆Y={p∈RY
+| ∥p∥1= 1}be the set of probability distributions on Y, represented as vectors.
We denote the point mass distribution of an outcome y∈ Y byδy∈∆Y. Let [d] :={1, . . . , d }.
In general, we denote a discrete loss by ℓ:Y × Y → R+with outcomes denoted by y∈ Y and a
surrogate loss by L:Rd×Y → Rwith surrogate reports u∈Rdand outcomes y∈ Y. The surrogate
must be accompanied by a link ψ:Rd→ Y mapping the convex surrogate model’s predictions back
into the discrete target space, and we discuss consistency of a pair(L, ψ)with respect to the target ℓ.
Forϵ >0, we define an epsilon ball via Bϵ(u) ={x∈Rd| ∥u−x∥2< ϵ}andBϵ:=Bϵ(⃗0).
Given a closed convex set C ⊂Rd, we define a projection operation onto CviaProjC(u) :=
arg minx∈C∥u−x∥2. Given a closed convex set C ⊂Rdandu∈Rd, we let the set-pointwise
distance to be defined as ∥u− C∥ 2:=∥u−ProjC(u)∥2. Full tables of notation are found in
Appendix A.
2.1 Property Elicitation, Consistency, and Prediction Dimension
Discrete label prediction requires optimization of a target loss function, ℓ, e.g. multi-class classifica-
tion and 0-1 loss. When designing surrogate losses, consistency is the key notion of correspondence
between surrogate and target loss. Intuitively, consistency implies that minimizing surrogate risk cor-
responds to solving the target problem. Finocchiaro et al. [2021] show that surrogate loss consistency
is a necessary precursor to excess risk bounds and convergence rates.
Consistency is generally a difficult condition to work with directly. Hence, we will use the notion
ofcalibration , which is equivalent to consistency in our setting with finite outcomes. Our approach
follows from the property elicitation literature, which allows us to abstract away from the feature space
2Xand focus on the conditional distributions over the labels, p= Pr[ Y|X=x]∈∆Y[Bartlett
et al., 2006, Tewari and Bartlett, 2007, Zhang, 2004, Ramaswamy and Agarwal, 2016, Steinwart,
2007]. In this approach, the central object of study is a property which maps label distributions to
reports that minimize the loss.
Definition 1 (Property, Elicits, Level Set) .LetRbe an arbitrary report set. For P ⊆∆Y, a property
is a set-valued function Γ :P → 2R\ {∅}, which we denote Γ :P⇒Y. A loss L:R × Y → R
elicits the property ΓonPif
∀p∈ P,Γ(p) = arg min
u∈REY∼p[L(u, Y)].
IfLelicits a property, it is unique and we denote it prop[ L]. The level set of Γfor report ris the set
Γr:={p∈ P | r= Γ(p)}. Ifprop[ L] = Γ and|Γ(p)|= 1for all p∈ P, we say that Lis strictly
proper for Γ.
In this work, R=Yfor target losses and R=Rdfor surrogate losses.
Once a model is optimized wrt. a surrogate L, it predicts reports in the surrogate space, Rd. Then, to
map surrogate reports to discrete labels, the surrogate loss must be paired with a link, ψ:Rd→ Y .
Intuitively, a surrogate and link pair (L, ψ)are calibrated with respect to a target loss ℓ, if the optimal
expected surrogate loss when making the incorrect classification (byψ) is strictly greater than the
optimal surrogate loss.
Definition 2 (ℓ-Calibrated Loss) .Given discrete loss ℓ:Y ×Y → R+, surrogate loss L:Rd×Y →
R, and link function ψ:Rd→ Y . We say that (L, ψ)isℓ-calibrated over P ⊆∆Yif, for all p∈ P,
inf
u∈Rd:ψ(u)/∈prop[ ℓ](p)EY∼p[L(u, Y)]>inf
u∈RdEY∼p[L(u, Y)].
IfPis not specified, then we are discussing calibration over ∆Y. In general, when (L, ψ)is
ℓ-calibrated over Psuch that P ⊂∆Y, we say partial calibration holds with respect to P.
Our analysis crucially relies on the ability to specify Pwhen invoking the definition of calibration.
This is because the surrogates we analyze break the d=n−1lower bound on the dimension of any
consistent surrogate loss. So the surrogates will not be calibrated over the whole simplex ∆Y. To aid
in our analysis, we use a condition that shows that converging to a property value implies calibration
for the target loss itself [Agarwal and Agarwal, 2015].
Definition 3 (ℓ-Calibrated Property) .LetP ⊆∆Y,Γ :P⇒Rd, discrete loss ℓ:Y ×Y → R+, and
ψ:Rd→ Y . We will say (Γ, ψ)isℓ-calibrated for all p∈ P and all sequences in {um}inRdif,
um→Γ(p)⇒EY∼p[ℓ(ψ(um), Y)]→min
r∈YEY∼p[ℓ(r, Y)].
Theorem 1 ([Agarwal and Agarwal, 2015, Theorem 3]) .Letℓ:Y × Y → R+andP ⊆ ∆Y. Let
Γ :P⇒Rdandψ:Rd→ Y be such that Γis elicitable and (Γ, ψ)is anℓ-calibrated property over
P. LetL:Rd×Y → Rbe a convex function for all y∈ Y and strictly proper for Γi.e.prop[ L] = Γ
and|Γ(p)|= 1for all p∈ P. Then, (L, ψ)isℓ-calibrated over P.
Finally, we present the 0-1 loss that we analyze, which is the target loss for multiclass classification.
Definition 4 (0-1 Loss) .We denote the 0-1 loss by ℓ0−1:Y × Y → { 0,1}such that ℓ0−1(y,ˆy) :=
1y̸=ˆy. Observe γmode(p) := prop[ ℓ0−1](p) ={y∈ Y|y∈arg maxypy}.
3 Polytope Embedding and Existence of Calibrated Regions
Often, discrete outcomes are embedded in continuous space onto the vertices of the simplex via
one-hot encoding, or the vertices of the unit cube via binary encoding [Seger, 2018]. Generalizing,
we introduce an approach to surrogate construction inspired by Wainwright et al. [2008] and Blondel
et al. [2020] that encompasses the aforementioned embedding methods. This construction utilizes
embeddings onto the vertices of arbitrary low-dimensional polytopes φ:Y →Rd. Then, an
embedding scheme naturally induces a large class of loss functions LG
φdefined by the embedding,
anyG-Bregman Divergence, and a link function ψφ.
Our analysis begins by defining a condition stronger than inconsistency that arises when embedding
intod < n −1dimensions for multiclass classification. To this end, we introduce the notion of
3hallucination as a means to characterize the “worst case” behavior of a surrogate pair (§ 3.2). In a
positive manner, we characterize the calibration regions of various embeddings (§ 3.3), which are
setsP ⊆∆Ysuch that our surrogate and link pair (LG
φ, ψφ)areℓ-calibrated over P. We refer the
reader to the Appendix B for omitted full proofs.
3.1 Polytope Embedding Construction
A Convex Polytope P⊂Rd, or simply a polytope, is the convex hull of a finite number of points
u1, . . . , u n∈Rd. An extreme point of a convex set A, is a point u∈Asuch that if u=λy+(1−λ)z
withy, z∈Aandλ∈[0,1], then y=uand/or z=u. We shall denote by vert(P)a polytope’s
set of extreme points. A polytope can be expressed by the convex hull of its extreme points, i.e.
P= conv (vert( P))[Brondsted, 2012, Theorem 7.2]. Additional definitions pertaining to polytopes
are used for proofs that are omitted to the appendix, we refer the reader to (§ B.1) for said definitions.
We propose the following embedding procedure that allows one to construct surrogate losses with
almost anypolytope, and anyBregman divergence.
Construction 1 (Polytope Embedding) .Given Youtcomes, |Y|=n, choose a polytope P⊂Rd
such that |vert(P)|=n. Choose a bijection between Yandvert(P). According to this bijection,
assign each vertex a unique outcome so that {vy∈Rd|y∈ Y} = vert( P). Then the polytope
embedding φ: ∆Y→Pisφ(p) :=P
y∈Ypyvy, which is the sum of p-scaled vectors
Following the work of Blondel [2019] and their proposed Projection-based losses, we use the
extremely general class of Bregman divergences (Definition 5) and a polytope embedding φto define
an induced loss LG
φ(Definition 6).
Definition 5 (Bregman Divergence) .Given a strictly convex function G:Rd→R,DG(u, v) :=
G(v)−[G(u) +⟨dGv, u−v⟩]is a Bregman divergence where dGvdenotes a subgradient of Gatv.
For this work, we shall always assume that dom( G) =Rd.
Definition 6 ((DG, φ)Induced Loss) .Given a Bregman divergence DGand a polytope embedding
φ, we say (DG, φ)induces a loss LG
φ:Rd× Y → R+defined as
LG
φ(u, y) :=DG(u, vy) =G(vy)−[G(u) +⟨dGvy, u−vy⟩].
Note, that for any fixed y∈ Y,LG
φ(u, y)is convex with respect to u∈Rd.
We show that for any p∈∆Y, the report that uniquely minimizes the expectation of the loss LG
φis
φ(p), the embedding point of p. Furthermore, the polytope Pcontains all of, and only the minimizing
reports in expectation under LG
φ.
Proposition 2. For a given induced loss LG
φ, the unique report which minimizes the expected loss
isu∗:= arg minu∈RdEY∼p[LG
φ(u, Y)] =φ(p)such that u∗∈P. Furthermore, every ˆu∈Pis a
minimizer of EY∼ˆp[LG
φ(u, Y)]for some ˆp∈∆Y.
We now define the maximum a posteriori (MAP) link, which will be used in conjunction with
an induced loss LG
φto form a surrogate pair for the 0-1 loss. The MAP link projects surrogate
predictions onto the polytope P, then links to the nearest vertex of P, and is commonly used in
the literature [Tsochantaridis et al., 2005, Blondel, 2019, Xue et al., 2016]. Since the MAP link
performs a projection, one may ask if this is computationally challenging; fortunately this operation
is computationally feasible due to the convexity of the polytope [Blondel, 2019].
Definition 7 (MAP Link) .Letφbe a polytope embedding from ∆YtoP. The MAP link ψφ:
Rd→ Y is defined as ψφ(u) = arg miny∈Y||ProjP(u)−vy||2. The level set of the link for yis
ψφ
y={u∈Rd|y=ψφ(u)}. We break ties arbitrarily but deterministically.
3.2 Hallucination Regions
Since our polytope embedding violates surrogate dimension bounds, calibration for 0-1 loss will
not hold for all distributions. In particular, we show there always exists some distribution psuch
thatpy= 0 yetEY∼p[LG
φ(u, Y)]is minimized at some usuch that ψφ(u) =y. This implies a
“worst case” inconsistency where the reported outcome could never actually occur with respect to our
embedding of nevents via φintovert(P).
4Figure 1: (Left) Mode level sets of ∆YwhereY={a, b, c, d }embedded into a two dimensional unit
cube. The center red point denotes the origin (0,0)which is the hallucination region. (Right) An
embedding of ∆Ywhere Y={a, b, c, d, e, f }into a three-dimensional permutahedron: the beige
region expresses strict calibration regions, the light pink regions expresses regions with inconsistency,
and the auburn region expresses regions with hallucinations. For example, consider the report u=⃗0.
Since losses are convex, if p= (0,1
2,0,0,1
2,0), then conv ({b, e})(dashed grey) is optimal, which
includes u. However, ⃗0is also contained in conv ({a, d})which is optimal for the distribution
p′= (1
2,0,0,1
2,0,0). Therefore, we cannot distinguish the optimal reports for a hallucination at ⃗0.
Definition 8 (Hallucination) .Given (L, ψ)such that L:Rd× Y → R+,|Y|=n,d < n , and
ψ:Rd→ Y , we say that a hallucination occurs at a surrogate report u∈Rdif, for some p∈∆Y,
u∈arg minˆu∈RdEY∼p[L(ˆu, Y)]andψ(u) :=ybutpy= 0. We denote by H ⊆ P⊂Rdas the
hallucination region as the elements of Pat which hallucinations can occur.
We express the subspace of the surrogate space where hallucinations can occur as the hallucination
region denoted by H. In Theorem 3, we characterize the hallucination region for any polytope
embedding while using the surrogate pair (LG
φ, ψφ)and show that His never empty.
Theorem 3. For any given pair (LG
φ, ψφ)andℓ0−1with embedding dimension d < n −1; it holds
thatH=∪y∈Yconv (vert( P)\ {vy})∩ψφ
yand furthermore H ̸=∅.
Sketch. Fixy∈ Y . We abuse notation and write vert(P−y) := vert( P)\ {vy}. Observe
conv (vert( P−y))∩ψφ
y⊆ H since any point in this set can be expressed as a convex combina-
tion without needing vertex vyimplying there is a distribution embedded by φto said point which
has no weight on y. We seek to show that H ⊆ ∪ y∈Yconv (vert( P−y))∩ψφ
y. Assume there exists a
point u /∈conv (vert( P)\vy)∩ψφ
ysuch that there exists some p∈∆Ywhere φ(p) =u,py= 0,
andψφ(u) =y. Since ψφ(u) =yandu /∈conv (vert( P−y))∩ψφ
y, it must be the case that
u /∈conv (vert( P−y)). However, that implies that uis strictly in the vertex figure and thus must
have weight on the coefficient for y. Thus, forming a contradiction that py= 0which implies that
H ⊆ ∪ y∈Yconv (vert( P−y))∩ψφ
y. Finally, using Helly’s Theorem [Rockafellar, 1997, Corollary
21.3.2] we show that ∩y∈Yconv (vert( P)\vy)̸=∅, which implies the non-emptiness of Has
well.
Theorem 3 suggests that using machine learning in high-risk settings such as medical and legal
applications while violating the known n−1dimensional bound for surrogate losses in multiclass
classification is inherently ill-advised without human intervention given the possibility for hallucina-
tions. Furthermore, hallucinations may be forced by the target loss, as in the case of Hamming loss
(see Appendix C). In these cases practitioners should carefully consider the choice of target loss. We
conjecture that hallucinations are common for many structured prediction losses. However this is not
a concern in our primary loss of study of multi-class classification.
3.3 Calibration Regions
Ideally, we would like calibration to hold over the entire simplex since that would imply minimizing
surrogate risk would always correspond to solving the target problem regardless of the true underlying
5distribution. We observe that the mode’s embedded level sets in the polytope overlap (see Figure 1L),
which is unsurprising given that we are violating the lower bounds on surrogate prediction for the
mode and hence calibration does not hold over the entire simplex. Since |2Y\ {∅}|is a finite set, we
know that the number of unique mode level sets is finite. Although every point in the polytope is a
minimizing report for some distribution, if multiple distributions with non-intersecting mode sets
are embedded to the same point, there is no way to define a link function that is correct in all cases.
However, if the union of mode sets for the p’s mapped to any u∈Pis a singleton, regardless of the
underlying distribution†, a link ψwould be calibrated over the union if it mapped uto the mentioned
singleton. Given (L, ψ),φ, and a target loss ℓ, we define strict calibrated regions as the points for
which calibration holds regardless of the actual distribution realized, which are possible at said points.
Definition 9 (Strict Calibrated Region) .Suppose we are given (L, ψ),φ, and a target loss ℓ. We
sayR⊆Pis astrict calibrated region via(L, ψ)with respect to ℓif(L, ψ)isℓ-calibrated for all
p∈φ−1(R) :={p∈∆Y:φ(p)∈R}.
For any y∈ Y, we define Ry:=R∩ψy. We let RY:=∪y∈YRy.
By violating lower bounds, we are in a partially consistent paradigm where surrogate reports do not
necessarily correspond to a unique distribution p. However, strict calibration regions allow us to
check whether or not the loss is calibrated for the distribution pgenerating the data — even without
explicit access to p. One simply has to check whether the report uis inRY.
In Theorem 4, regardless of one’s chosen P, we show that there always exists a non-zero Lebesgue
measurable strict calibration region and that (LG
φ, ψφ)is calibrated for the 0-1 loss overall distri-
butions embedded into the strict calibration region. This result shows that our surrogate and link
construction for anyd, always yields discernible calibration regions — lending support to the practical
use and study of these surrogates.
Theorem 4. LetDGbe a Bregman divergence, φbe any polytope embedding, ψφbe the MAP link,
andLG
φbe the loss induced by (DG, φ). There exists a P ⊆∆Ywith non-zero Lebesgue measure
andφ(P)⊆RYvia(LG
φ, ψφ)with respect to ℓ0−1.
Although strict calibration regions Ryexist for each outcome y∈ Y via the polytope embedding,
tightly characterizing strict calibration regions is non-trivial. Since the level sets of elicitable
properties are convex within the underlying simplex, characterizing the strict calibration regions
becomes a collision detection problem, which is often computationally hard.
4 Restoring Inconsistent Surrogates via Low-Noise Assumptions
Looking towards application, we refine our results on the existence of strict calibration regions by
examining a low-noise assumption, which provides an interpretable calibration region (§ 4.1). We
show which low-noise assumptions imply calibration when embedding 2doutcomes into ddimensions
andd!outcomes into ddimensions (§ 4.2). We refer the reader to Appendix B for omitted proofs.
4.1 Calibration via Low Noise Assumptions
We demonstrate that every polytope embedding leads to calibration under some low-noise assumption.
Our results enable practictioners to choose the dimension d, unlike in previous works. Following
previous work [Agarwal and Agarwal, 2015], we define a low noise assumption to be a subset of the
probability simplex on the label distribution parameterized by ˆα:Θˆα={p∈∆Y|max y∈Ypy≥
1−ˆα}where ˆα∈[0,1]. This noise assumption can be understood as Massart noise [Massart and
Nédélec, 2006] in the multiclass setting.
Given α∈[0,1]andy∈ Y, we define the set Ψy
α={(1−α)δy+αδˆy|ˆy∈ Y} . With an embedding
φontoP, we define the set Py
α:=φ(conv (Ψy
α)), a scaled version of Panchored at vy, that moves
vertices (1−α)proportionally towards y, (Figure 2R).
Theorem 5. LetDGbe a Bregman divergence, φbe any polytope embedding, and LG
φbe the loss
induced by (DG, φ). There exists an α∈[0, .5)such that for the link ψφ,α(u) = arg miny∈Y∥u−
Py
α∥2,(LG
φ, ψφ,α)isℓ0−1-calibrated over the distributions Θα:={p∈∆Y|max y∈Ypy≥1−α}.
†We leave the more general case of linking uwhenT
p∈φ−1(u)γ(p)̸=∅to future work.
6Proof. Part 1 (Choosing α∈[0, .5)): By Theorem 4, there exists an ϵ >0such that Bϵ(vy)∩P⊆
Ryfor all y∈ Y. Given that vert(P)are unique points, there exists a sufficiently small ϵ′>0such
thatBϵ′(v)∩Bϵ′(ˆv) =∅for all v,ˆv∈vert(P)where v̸= ˆv. Letϵ′′= min ( ϵ, ϵ′). For any y∈ Y,
observe the set conv (Ψy
α), defined using any α∈[0, .5), is a scaled-down translated unit simplex
and that for all p∈conv (Ψy
α)⊂∆Yit holds that y=mode (p).
We shall show that for some sufficiently small α∈[0, .5),Py
αis a scaled down version of P
positioned at the respective vertex vy. Furthermore, we shall show that Py
α⊂Bϵ′′(vy)∩P⊆Ryfor
ally∈ Y. Observe that by linearity of φ,
Py
α:=φ(conv (Ψy
α)) = conv ( φ({(1−α)δy+αδˆy|ˆy∈ Y} )) = conv ( {(1−α)vy+αvˆy|ˆy∈ Y} )
and hence, Py
αis a scaled version of Ppositioned at vy. Hence for some sufficiently small α,
(1−α)vy+αvˆy∈Bϵ′′(vy)for all ˆyand hence Py
α⊆Bϵ′′(vy)⊆Ry. With said sufficiently small
α, define ψφ,αand the respective sets conv (Ψy
α)for each y∈ Y. Using the previous α, define the
setΘαas well.
Part 2 (Showing Calibration) : Recall, by Proposition 2, for any p∈∆Y,u=φ(p)minimizes the
expected surrogate loss EY∼p[LG
φ(u, Y)]. For any fixed y∈ Y, observe that conv{(1−α)δy+αδˆy|
ˆy∈ Y} ={p∈∆Y:py≥1−α} ⊂∆Yand hence, by Proposition 2, ∪y∈YPy
αcontains all
of the minimizing surrogate reports with respect to Θα. By our choice of αand the construction
ofψP
α, every u∈ ∪y∈YPy
αis linked to the proper unique mode outcome since ∪y∈YPy
α⊆RY.
Assuming a low-noise condition where p∈Θα, anyu /∈ ∪y∈YPy
αis never optimal for any low-noise
distribution. In such cases, we project the point to the nearest Py
αas a matter of convention. Given that
calibration is a result pertaining to minimizing reports, this design choice is non-influential. Finally,
since every ∪y∈YPy
α⊆RY, by the definition of strict calibration region, it holds that (LG
φ, ψφ,α)is
ℓ0−1-calibrated for Θα.
4.2 Embedding into the Unit Cube and Permutahedron under Low-Noise
In this section, we demonstrate embedding onto the unit cube and the permutahedron [Blondel et al.,
2020, Seger, 2018]. We show that by embedding 2doutcomes into a ddimensional unit cube P□,
(LG
φ, ψP□,α)is calibrated over Θαfor all α∈[0,1
2). Furthermore, we found that by embedding d!
outcomes into a ddimensional permutahedron Pw,(LG
φ, ψPw,α)is calibrated for Θαforα∈[0,1
d).
Theorem 6 enables us to simultaneously study the aforementioned embeddings.
Theorem 6. LetDGbe a Bregman divergence, φbe any polytope embedding, and LG
φbe the
loss induced by (DG, φ). Fix α∈[0, .5)and with it define Θα. If for all y,ˆy∈ Y such that
y̸= ˆyit holds that Py
α∩Pˆy
α=∅, then (LG
φ, ψφ,α)isℓ0−1-calibrated for Θαwhere ψφ,α(u) =
arg miny∈Y∥u−Py
α∥2.
Proof. Pick an αsuch that for all y,ˆy∈ Y,Py
α∩Pˆy
α=∅. Define Θαandψφ,αaccordingly. For
p∈Θαand some y∈ Y, say a sequence {um}converges to prop[ LG
φ](p) =φ(p)∈Py
α, where the
equality follows from Proposition 2. Given that each Py
αis closed and pairwise disjoint, there exists
some ˆϵ >0such that for all y,ˆy∈ Y where y̸= ˆy, it also holds that (Py
α+Bˆϵ)∩(Pˆy
α+Bˆϵ) =∅
where +denotes the Minkowski sum. Since {um}converges to φ(p), there exists some N∈Nsuch
that for all n≥N,∥un−φ(p)∥2<ˆϵ. By the definition of ψφ,α, any unwhere n≥Nwill be
mapped to y, the correct unique report given that prop[ LG
φ](p)∈Py
α. Hence, (prop[ LG
φ], ψφ,α)is
ℓ0−1-calibrated property with respect to Θα. Finally, since LG
φis strictly proper for prop[ LG
φ], by
Theorem 1, we have that (LG
φ, ψφ,α)isℓ0−1-calibrated for Θα.
Unit Cube Define a unit cube in d-dimensions by P□:= conv ( {−1,1}d). Binary encoding
outcomes into the elements of {−1,1}d(the vertices of a unit cube) is a commonly used method in
practice (e.g., [Seger, 2018, Yu and Blaschko, 2018]). We show that calibration holds under a low
noise assumption of Θαwhen α < . 5.
Corollary 7. Letφbe an embedding from 2doutcomes into the vertices of P□ind-dimensions and
define an induced loss LG
φ. Fixα∈[0, .5)and define Θα.(LG
φ, ψP□,α)isℓ0−1-calibrated for Θα.
7Figure 2: (Left) Corners represent the strict calibration regions for Θαwhere Y={a, b, c, d }is
embedded into a two dimensional unit cube such that α=.25. (Right) Auburn regions show that
strict calibration holds for Θαwhere Y={a, b, c, d, e, f }is embedded into a three-dimensional
permutahedron such that α=1
3−ϵ.
Corollary 7 suggests that binary encoding is an appropriate methodology when one has a prior over
the data that the mode of the label distribution Pr[Y|X=x]is greater than half for all x∈ X.
Interestingly, the bound of αis not dependent on the dimension of d. We now present a result for
embedding outcomes into a factorially lower dimension via the permutahedron. Intuitively, ranking
can be recast as a multiclass classification problem, in which case the outcomes are orderings of the d
possible labels.
Permutahedron LetSdexpress the set of permutations on [d]. The permutahedron associated
with a vector w∈Rdis defined to be the convex hull of the permutations of the indices of w, i.e.,
Pw:= conv ( {π(w)|π∈ Sd})⊂Rd. The permutahedron may serve as an embedding from d!
outcomes into d-dimensions; it is a natural choice for embedding full rankings over ditems.
Corollary 8. Letφbe an embedding from d!outcomes into the vertices of Pwinddimensions
such that w= (0,1
βd,2
βd, . . . ,d−1
βd)∈Rdwhere β=d−1
2. Fix α∈[0,1
d). Then (LG
φ, ψPw,α)is
ℓ0−1-calibrated over Θα.
The calibration region in Corollary 8 show that consistency in Θαshrinks exponentially in d. Unless
one has a prior that the data follows some form of a power distribution, Corollary 8 suggests not to
factorially embed outcomes.
5 Elicitation in Low Dimensions with Multiple Problem Instances
The tools developed in previous sections now enable us to address the setting in which we require full
consistency, P= ∆Y, but also desire surrogate prediction dimension d≪n−1. We side-step the
n−1lower bound by utilizing multiple problem instances and aggregation of the outputs. Although
cumulatively we have a larger surrogate prediction dimension than n−1, each individual problem
instance has a less than n−1surrogate prediction dimension. This approach is well-motivated since
it allows for distributed computing of separate, smaller models which leads to faster convergence
overall since in general optimization is at least poly(d). Previous work such as Ramaswamy et al.
[2014] has explored the consistency of multiclass problem reductions; however, we take a different,
geometrically motivated, approach.
Definition 10. Extending Definition 1, we say a loss and link pair (L, ψ), where L:Rd× Y → R
andψ:Rd→ Y , elicits a property Γ :P⇒YonP ⊆ ∆Yif∀p∈ P,Γ(p) =
ψ(arg minu∈RdEY∼p[L(u, Y)]).
Definition 11 ((n, d, m )-Polytope Elicitable) .Suppose we are given a property γ:P⇒Ysuch that
P ⊆ ∆Yand|Y|=nfinite outcomes. Say we have munique polytope embeddings {φj: ∆Y→
Rd}m
j=1where d < n −1, and a set of induced losses {LG
φj}m
j=1and links ψj:Rd→ B jdefined
wrt.φj, where Bjis an arbitrary report set. For each j∈[m], assume the pair (LG
φj, ψj)elicits the
property Γj:P⇒Bj. If there exists a function Υ :B1× ··· × B m⇒Ysuch that for any p∈∆Y
it holds that Υ(Γ 1(p), . . . , Γm(p)) =γ(p), we say that γis(n, d, m )-Polytope Elicitable over P.
8Figure 3: Four outcomes embedded in R2in two different ways, with the minimizing reports •for a
distribution p." (Left) Configuration φ1with•at(−.5, .3)implying pa> pdandpb> pc. (Right)
Configuration φ2with•at(0,0)implying pa=pbandpc=pd. This implies the true distribution is
p= (0.4,0.4,0.1,0.1)."
Equivalently, we will also say that the pair ({(LG
φj, ψj)}m
j=1,Υ) (n, d, m )-Polytope elicits the prop-
ertyγwith respect to P.
We shall express a d-cross polytope by P⊕:= conv ( {π((±1,0, . . . , 0))|π∈ S d})where
(±1,0, . . . , 0)∈Rd. Observe that a d-cross polytope has 2dvertices. For any vertex of a d-cross
polytope v∈vert(P⊕), we shall say that (v,−v)forms a diagonal vertex pair.
Lemma 9. Say we are given a cross-polytope embedding φ: ∆2d→P⊕and induced loss LG
φ.
Let(vai, vbi), be the ithdiagonal pair (i.e. φ(δai) =vai). Define the property Γφ: ∆2d→ B
element-wise by
Γφ(p)i:=((<, ai, bi)ifpai< pbi
(>, ai, bi)ifpai> pbi
(=, ai, bi)ifpai=pbi.
Furthermore define the link ψP⊕:Rd→ B with respect to each diagonal pair as
ψ(u;vai, vbi)P⊕
i:=((<, ai, bi)if||u−vai||2>||u−vbi||2
(>, ai, bi)if||u−vai||2<||u−vbi||2
(=, ai, bi) o.w.
Then (LG
φ, ψP⊕)elicits Γφ.
The following theorem states that by using multiple problem instances, based on Lemma 9, we can
Polytope-elicit the mode. Algorithm 1 outlines how to aggregate the individual solutions to infer the
mode. We defer the proof to Appendix B.
Theorem 10. Letd≥2. The mode is (2d, d, m )-Polytope Elicitable for some m∈[2d−1, d(2d−1)].
Algorithm 1 Elicit mode via comparisons and the d-Cross Polytopes
Require: M={(LG
φj, ψP⊕
j)}m
j=1
Learn a model hj:X →Rdfor each instance (LG
φj, ψP⊕
j)∈M
For some fixed x∈ X, collect all Bj←ψP⊕
j(hj(x))where Bj∈ Bj
Report R←FindMaxes†(B1, . . . , B m)
Although Theorem 10 states that the mode is (2d, d, m )-Polytope Elicitable for some m∈[2d−
1, d(2d−1)], it does not state how we select said {(LG
φj, ψP⊕
j)}m
j=1problem instances in an optimal
manner. Unfortunately, selecting the min number of problem instances reduces to a a minimum set
cover problem which is computationally hard. Even so, through a greedy approach, one can choose
†Given all comparisons, a sorting algorithm can be used to compute the set of r∈ Y such that pris
maximum.
9problem instances that are log approximate optimal relative to the true best configuration. In practice
using real data, given that these are asymptotic results, we may have conflicting logic for the provided
individual reports. In Appendix D, we discuss an approach of how to address this in practice.
6 Discussion and Conclusion
This work examines various tradeoffs between surrogate loss dimension, restricting the region of
consistency in the simplex when using the 0-1 loss, and number of problem instances. Since our
analysis is based on an embedding approach commonly used in practice, our work provides theoretical
guidance for practitioners choosing an embedding. We see several possible future directions. The
first is a deeper investigation into hallucinations. Future work could investigate the size of the
hallucination region in theory, and the frequency of reports in the hallucination region in practice.
Another direction would be to construct a method that efficiently identifies the strict calibration
regions and the distributions embedded into them. This would provide better guidance on whether or
not a particular polytope embedding aligns with one’s prior over the data. Another possible direction
would be to explore whether concepts from this paper could be applied to the underlying problem of
cost-sensitive multiclass classification. Finally, another direction is to identify other properties that
can be elicited via multiple problem instances while also reducing the dimension of any one instance.
Broader Impacts: Our work broadly informs the selection of loss functions for machine learning.
Thus our work may influence practitioners’ choice of loss function. Of course, such loss functions
can be used for ethical or unethical purposes. We do not know of particular risks of negative impacts
of this work beyond risks of machine learning in general.
Acknowledgments and Disclosure of Funding
We thank Rafael Frongillo for discussions about hallucinations, which led to the exploration of many
of the ideas in this work and Amzi Jeffs for discussions regarding convex geometry. This material is
based upon work supported by the National Science Foundation under Award No. 2202898 (JF).
10References
Arpit Agarwal and Shivani Agarwal. On consistent surrogate risk minimization and property
elicitation. In Conference on Learning Theory , pages 4–22. PMLR, 2015.
Arindam Banerjee, Xin Guo, and Hui Wang. On the optimality of conditional expectation as a
bregman predictor. IEEE Transactions on Information Theory , 51(7):2664–2669, 2005.
Peter L Bartlett, Michael I Jordan, and Jon D McAuliffe. Convexity, classification, and risk bounds.
Journal of the American Statistical Association , 101(473):138–156, 2006.
Mathieu Blondel. Structured prediction with projection oracles. Advances in neural information
processing systems , 32, 2019.
Mathieu Blondel, André FT Martins, and Vlad Niculae. Learning with fenchel-young losses. The
Journal of Machine Learning Research , 21(1):1314–1382, 2020.
Arne Brondsted. An introduction to convex polytopes , volume 90. Springer Science & Business
Media, 2012.
Jessie Finocchiaro, Rafael Frongillo, and Bo Waggoner. Embedding dimension of polyhedral losses.
InConference on Learning Theory , pages 1558–1585. PMLR, 2020.
Jessie Finocchiaro, Rafael Frongillo, and Bo Waggoner. Unifying lower bounds on prediction
dimension of consistent convex surrogates. arXiv preprint arXiv:2102.08218 , 2021.
Jessie Finocchiaro, Rafael M Frongillo, and Bo Waggoner. An embedding framework for the design
and analysis of consistent polyhedral surrogates. Journal of Machine Learning Research , 25(63):
1–60, 2024.
Peter M Gruber. Convex and discrete geometry , volume 336. Springer, 2007.
Jean-Baptiste Hiriart-Urruty and Claude Lemaréchal. Fundamentals of convex analysis . Springer
Science & Business Media, 2004.
Pascal Massart and Élodie Nédélec. Risk bounds for statistical learning. 2006.
Harish G Ramaswamy and Shivani Agarwal. Convex calibration dimension for multiclass loss
matrices. The Journal of Machine Learning Research , 17(1):397–441, 2016.
Harish G Ramaswamy, Balaji Srinivasan Babu, Shivani Agarwal, and Robert C Williamson. On
the consistency of output code based learning algorithms for multiclass learning problems. In
Conference on Learning Theory , pages 885–902. PMLR, 2014.
R Tyrrell Rockafellar. Convex analysis , volume 11. Princeton university press, 1997.
Cedric Seger. An investigation of categorical variable encoding techniques in machine learning:
binary versus one-hot and feature hashing, 2018.
Ingo Steinwart. How to compare different loss functions and their risks. Constructive Approximation ,
26(2):225–287, 2007.
Kirill Struminsky, Simon Lacoste-Julien, and Anton Osokin. Quantifying learning guarantees for
convex but inconsistent surrogates. Advances in Neural Information Processing Systems , 31, 2018.
Ambuj Tewari and Peter L Bartlett. On the consistency of multiclass classification methods. Journal
of Machine Learning Research , 8(5), 2007.
Ioannis Tsochantaridis, Thorsten Joachims, Thomas Hofmann, Yasemin Altun, and Yoram Singer.
Large margin methods for structured and interdependent output variables. Journal of machine
learning research , 6(9), 2005.
Martin J Wainwright, Michael I Jordan, et al. Graphical models, exponential families, and variational
inference. Foundations and Trends® in Machine Learning , 1(1–2):1–305, 2008.
11Yexiang Xue, Zhiyuan Li, Stefano Ermon, Carla P Gomes, and Bart Selman. Solving marginal
map problems with np oracles and parity constraints. Advances in Neural Information Processing
Systems , 29, 2016.
Jiaqian Yu and Matthew B Blaschko. The lovász hinge: A novel convex surrogate for submodular
losses. IEEE transactions on pattern analysis and machine intelligence , 42(3):735–748, 2018.
Tong Zhang. Statistical analysis of some multi-category large margin classification methods. Journal
of Machine Learning Research , 5(Oct):1225–1251, 2004.
12A Notation tables
Notation Explanation
r∈ R Prediction space
y∈ Y Label space
P ⊆∆Y Subset of simplex over Y
δy Point mass distribution on y∈ Y
[d] :={1, . . . , d } Index set
1S∈ {0,1}ds.t.( 1S)i= 1⇔i∈S0-1 Indicator on set S⊆[d]
C ⊂RdClosed convex set
u∈RdSurrogate prediction space
ProjC(u) := arg minx∈C||u−x||2 Projection onto closed convex set
π∈ Sd Permutations of [d]
ℓ:Y × Y → R+ Discrete loss
L:Rd× Y → R Surrogate loss
ψ:Rd→ Y Link function
EY∼p[ℓ(r, Y)] Expected discrete loss
EY∼p[L(u, Y)] Expected surrogate loss
Γ :P → 2R\ {∅} Property
Γr:={p∈ P | r= Γ(p)} Level set of property
prop[ L] Property elicited by L
ℓ0−1:Y × Y → { 0,1} Zero-one loss
γmode: ∆Y→2Y\ {∅} Mode property
Table 1: Table of general notation
Notation Explanation
P⊂RdPolytope
vert(P) Vertex Set
E(P) Edge set of P
φ: ∆Y→P Polytope Embedding
P□:= conv ( {−1,1}d) Unit cube
Pw:= conv ( {π(w)|π∈ Sd})s.t.w∈RdPermutahedron
P⊕:= conv ( {π((±1,0, . . . , 0))|π∈ Sd})Cross polytope
DG:Rd→R+ Bregman divergence w.r.t G
LG
φ:Rd× Y → R+ (DG, φ)Induced Loss
ψφ:Rd→ Y MAP Link
Table 2: Table of polytope and embedding notation
Notation Explanation
H ⊆ P Hallucination region
R⊂P Strict calibrated region
Ry:=R∩ψy Intersection of link level set and strict cal. region
RY:=∪y∈YRy Union of Ry
Θα⊂∆Y Low-noise assumption
Ψy
α={(1−α)δy+αδˆy|ˆy∈ Y} Scaled vertex set
Py
α:=φ(conv (Ψy
α)) Scaled version of Panchored at vy
Table 3: Table of calibration region notation
13B Polytopes, Omitted Proofs, and Results
B.1 Polytopes
A Convex Polytope P⊂Rd, or simply a polytope, is the convex hull of a finite number of points
u1, . . . , u n∈Rd. An extreme point of a convex set A, is a point u∈Asuch that if u=λy+(1−λ)z
withy, z∈Aandλ∈[0,1], then y=uand/or z=u. We shall denote by vert(P)a polytope’s
set of extreme points. A polytope can be expressed by the convex hull of its extreme points, i.e.
P= conv (vert( P))[Brondsted, 2012, Theorem 7.2].
We define the dimension of Pviadim(P) := dim(affhull( P))where affhull( P)denotes the smallest
affine set containing P. A set F⊆Pis a face of Pis there exists a hyperplane H(y, α) :={u∈
Rd| ⟨u, y⟩=α}such that F=P∩HandP⊆H+such that H+(y, α) :={u∈Rd| ⟨u, y⟩ ≤α}.
LetFi(P)where i∈[d−1]denote set of faces of dim iof a polytope P. A face of dimension zero
is called a vertex and a face of dimension one is called an edge. We define the edge set of a polytope
PbyE(P) :={conv (( vi, vj))|(vi, vj)⊆ vert(P)
2
,conv (( vi, vj))∈F1(P)}. We define the
neighbors of a vertex vbyne(v;P) :={ˆv∈vert(P)|conv (( v,ˆv))∈E(P)}. We will denote
conv (( v,ˆv))∈E(P)by as ev,ˆvandne(v;P)byne(v)when clear from context.
B.2 Omitted Proofs from § 3
Proposition 2. For a given induced loss LG
φ, the unique report which minimizes the expected loss
isu∗:= arg minu∈RdEY∼p[LG
φ(u, Y)] =φ(p)such that u∗∈P. Furthermore, every ˆu∈Pis a
minimizer of EY∼ˆp[LG
φ(u, Y)]for some ˆp∈∆Y.
Proof. By [Banerjee et al., 2005, Theorem 1], the minimizer of EY∼p[LG
φ(u, Y)]isP
y∈Ypyvy=
φ(p). Thus, by the construction of the polytope embedding, it holds that u∗=φ(p). Since
Bregman divergences are defined with respect to strictly convex functions, u∗uniquely minimizes
EY∼p[LG
φ(u, Y)].
Conversely, every ˆu∈Pis expressible as a convex combination of vertices; hence, by the definition
ofφ, for some distribution, say ˆp∈∆Y, it holds ˆu=φ(ˆp). Therefore, it holds that ˆuminimizes
EY∼ˆp[LG
φ(u, Y)].
Theorem 3. For any given pair (LG
φ, ψφ)andℓ0−1with embedding dimension d < n −1; it holds
thatH=∪y∈Yconv (vert( P)\ {vy})∩ψφ
yand furthermore H ̸=∅.
Proof. Choose a y∈ Y. We abuse notation and write vert(P)\vy:= vert( P)\ {vy}. Observe all
u∈conv (vert( P)\vy)∩ψφ
ycan be expressed as a convex combination of vertices without needing
vertex vy. The coefficients of said convex combination express a p∈∆Ythat is embedded to the point
u∈Pwhere py= 0. Yet, by Proposition 2, said uis an expected minimizer of LG
φwith respect to p.
Given the intersection with ψφ
yand by Definition 8, it holds that ∪y∈Yconv (vert( P)\vy)∩ψφ
y⊆ H .
We now shall show that H ⊆ ∪ y∈Yconv (vert( P)\vy)∩ψφ
y. Fix y∈ Y. Assume there exists a
point u /∈conv (vert( P)\vy)∩ψφ
ysuch that there exists some p∈∆Ywhere φ(p) =u,py= 0,
andψφ(u) =y. Since ψφ(u) =yandu /∈conv (vert( P)\vy))∩ψφ
y, it must be the case that
u /∈conv (vert( P)\vy). However, that implies that uis strictly in the vertex figure and thus must
have weight on the coefficient for y. Thus, forming a contradiction that py= 0which implies that
H=∪y∈Yconv (vert( P)\vy)∩ψφ
y.
To show non-emptiness of H, we shall use Helly’s Theorem (Rockafellar [1997], Corollary 21.3.2).
W.l.o.g, assign an index such that Y={y1, . . . , y d, yd+1, . . . , y n}. Observe the elements of the set
{Y \ yi}n
i=1each differ by one element. W.l.o.g, pick the first d+ 1elements of the previous set.
Observe | ∩d+1
i=1Y \yi|=|Y \ { y1, . . . , y d, yd+1}|=n−(d+ 1) >0. Hence, by Helly’s theorem
and uniqueness of yi’s,∩y∈Yconv (vert( P)\vy)̸=∅.
Pick a point u′∈ ∩y∈Yconv (vert( P)\vy). Since ψφis well-defined, u′will be linked to some
outcome y′∈ Y and thus u′∈conv (vert( P)\vy′)∩ψφ
y′⊂ H . Yet, u′can be expressed as a
14convex combination which does not use vy′since it lies in ∩y∈Yconv (vert( P)\vy). Thus, by using
Proposition 2 and by the definition of Hallucination (Def. 8), we have that H ̸=∅.
Lemma 1 (Proposition 1.2.4) .[Hiriart-Urruty and Lemaréchal, 2004] If φis an affine transformation
ofRnandA⊂Rnis convex, then then the image φ(A)is also convex. In particular, if the set Ais a
convex polytope, the image is also a convex polytope.
Lemma 2. LetDGbe a Bregman divergence, φbe any polytope embedding, ψbe the MAP link,
andLG
φbe the loss induced by (DG, φ). Assume the target loss is ℓ0−1. If a point is in a strict
calibrated region such that u∈Ryfor some y∈ Y, it is necessary that u∈conv ({vy} ∪ne(vy))\
conv (ne( vy)).
Proof. Ifu∈Ryandu∈P\ 
conv ({vy} ∪ne(vy))\conv (ne( vy))
, then ucan be expressed as
a convex combination which has no weight on the coefficient for vy. Hence, there exists a distribution
embedded into uwhere ywould not be the mode, thus violating the initial claim that u∈Ry.
Lemma 3. LetDGbe a Bregman divergence, φbe any polytope embedding, ψbe the MAP link, and
LG
φbe the loss induced by (DG, φ). For any u∈e(vi,vj)∈E(P), it holds that |φ−1(u)|= 1.
Proof. Observe, the two vertices of an edge define the convex hull making up the edge and hence,
by (Gruber [2007] ,Theorem 2.3) the two vertices are affinely independent. Therefore, all elements
of the edge have a unique convex combination which are expressed by the convex combinations
of the edge’s vertices. Given the relation of the embedding φand convex combinations of vertices
expressing distributions, it holds that |φ−1(u)|= 1.
Lemma 4. LetDGbe a bregman divergence, φbe a polytope embedding, and LG
φbe the induced
loss by (DG, φ). For all y∈ Y, it holds that dim(φ(mode y)) = dim( P)≥2.
Proof. By the construction of φ, we know that dim(P)≥2. Fix y∈ Y. By Lemma 3, we know
that any edge connected from vyandˆv∈ne(vy), the distributions embedded into the half of the line
segment closer to vy,yis in the mode. By Lemma 1, we know that φ(γmode
y)is a convex set. Thus,
the convex hull of the half line segments is part of φ(γmode
y). Since each vertex has at least dim(P)
neighbors, it holds that dim(φ(γmode
y)) = dim( P).
Theorem 4. LetDGbe a Bregman divergence, φbe any polytope embedding, ψφbe the MAP link,
andLG
φbe the loss induced by (DG, φ). There exists a P ⊆∆Ywith non-zero Lebesgue measure
andφ(P)⊆RYvia(LG
φ, ψφ)with respect to ℓ0−1.
Proof. Recall that γmode(p) := prop[ ℓ0−1](p) =mode (p). Fix y∈ Y. For contradiction, assume
for any ˆy∈ Y where y̸= ˆy, it holds that Bϵ(vy)∩φ(γmode
ˆy)̸=∅for all ϵ >0. By Lemma 3,
it holds that conv ({vy} ∪mvy,α)⊆φ(γmode
y)where mvy,α:={(1−α)vy+αv|v∈ne(vy)}
defined by any α∈(0, .5). Furthermore, the elements of ∪m∈mvy,αconv ({vy} ∪ {m})have one
distribution embedded onto it where yis the only valid mode thus, we know that φ(mode ˆy)∩
∪m∈mvy,αconv ({vy} ∪ { m}) =∅. Since φ(γmode
ˆy)⊂Pis closed and convex, there must exist
some non-negative min distance between φ(γmode
ˆy)andvywhich we shall denote by dv. For any
ϵ∈(0, dvy), we can define Bϵ(vy)such that Bϵ(vy)∩φ(γmode
ˆy) =∅, forming a contradiction.
For each vy∈vert(P)define a dvyand let ϵ′∈ ∩vy∈vert(P)(0, dvy). By the construction of Pand
the definition of ψφ, there exists a ϵ′′>0such that for all u∈Bϵ′′(vy)it holds that ψ(u) =yand
Bϵ′′(vy)⊂ψφ
y. For any y∈ Y, we know that Bmin{ϵ′,ϵ′′}(vy))∩P⊆Ryby the construction of
our epsilon ball. We claim φ−1(Bmin{ϵ′,ϵ′′}(vy)∩P)is a set of distributions for which calibration
holds.
Forp∈∆Ysuch that φ(p)∈Bmin{ϵ′,ϵ′′}(vy)∩Pfor some vy∈vert(P), suppose a se-
quence {um}converges to prop[ LG
φ](p) = φ(p)(equality by Proposition 2). By construction
ofBmin{ϵ′,ϵ′′}(vy)∩P,ψφ(φ(p)) = y∈mode (p)and hence, a minimizing report for ℓ0−1(y;p).
Furthermore, since Bmin{ϵ′,ϵ′′}(vy)⊂ψφ
φ−1(vy), all elements within Bmin{ϵ′,ϵ′′}(vy)link to y. Since
{um}converges to prop[ LG
φ](p), there exists some N∈Nandn≥N, such that ∥un−φ(p)∥2<
15min{ϵ′, ϵ′′}, meaning that EY∼p[ℓ0−1(ψφ(um), Y)]→miny∈YEY∼p[ℓ0−1(y, Y)]. Hence, for any
vy∈vert(P),(prop[ LG
φ], ψφ)isℓ0−1-calibrated property with respect to φ−1(Bmin{ϵ′,ϵ′′}(vy)∩P).
Furthermore, by the construction of Bminϵ′,ϵ′′(vy)for each vy∈vert(P), we have that LG
φis
strictly for prop[ LG
φ]. Thus, by Theorem 1, (LG
φ, ψφ)isℓ0−1-calibrated for at least the distributions
P=∪vy∈vert(P)φ−1(Bmin{ϵ′,ϵ′′}(vy)∩P)as well as φ(P)⊆RY. Furthermore, since Bmin{ϵ′,ϵ′′}
for each vy∈vert(P)is non-empty, we have that P ̸=∅.
B.3 Omitted Proofs from § 4
Corollary 7. Letφbe an embedding from 2doutcomes into the vertices of P□ind-dimensions and
define an induced loss LG
φ. Fixα∈[0, .5)and define Θα.(LG
φ, ψP□,α)isℓ0−1-calibrated for Θα.
Proof. W.l.o.g, say the outcome y1∈ Y is embedded into 1[d]∈vert(P□). Say α=.5. Observe
that
Ψy1
α=


1
0
...
0
0
,
1−α
α
...
0
0
,
1−α
0
α
...
0
, . . . ,
1−α
0
...
α
0
,
1−α
0
...
0
α



and that 1≥(1−α)±α≥0for any α∈(0, .5). Hence, for any α∈(0, .5)it holds that
Py1
0.5= conv ( {0,1}d)and furthermore Py1α⊂Py1
0.5⊂Rd
>0. By symmetry of P□and the linearity
ofφ, for any α∈(0, .5)andy∈ Y, we have that Py
αis a strict subset of the orthant that contains
vy. Hence, for all y,ˆy∈ Y such that y̸= ˆy, it holds that Py
α∩Pˆy
α=∅. Thus by Theorem 6,
(LG
φ, ψP□,α)isℓ0−1-calibrated for Θαwhere α∈(0, .5).
Corollary 8. Letφbe an embedding from d!outcomes into the vertices of Pwinddimensions
such that w= (0,1
βd,2
βd, . . . ,d−1
βd)∈Rdwhere β=d−1
2. Fix α∈[0,1
d). Then (LG
φ, ψPw,α)is
ℓ0−1-calibrated over Θα.
Proof. Let∆d:= conv ( { 1i∈Rd|i∈[d]})and observe Pw⊂∆dsince for all π,∥π·w∥1=
∥w∥1= 1. Observe that Pwcan be symmetrically partitioned into d!regions with disjoint interiors,
one for each permutation π∈ Sdvia∆π
d:={u∈∆d|u1≤ ··· ≤ ud}. Fix π∈ Sdand
w.l.o.g assume πis associated with the constraints ∆π
w:={u∈∆w|u1≤ ··· ≤ ud}implying that
π(w) = (0
βd,1
βd, . . . ,d−1
βd). Letα=1
dand define Θα. With respect to Θα, lety:=φ−1(π(w))∈ Y
andˆy:=φ−1(ˆπ(w))∈ Y such that ˆπ∈ Sd. Thus the set Ψy
α:={(1−1
d)δy+ (1
d)δˆy|ˆy∈ Y} is
mapped via φto the following points
φ(Ψy
α) ={(1−1
d)(π(w)) + (1
d)(ˆπ(w))|ˆπ∈ Sd}
within the permutahedron.
We shall show that Py
α⊆∆π
d. If this were not true, there would exists an element of wπ,ˆπ∈φ(Ψy
α)
such such that for some pair of adjacent indices, say i, i+ 1∈[d−1],wπ,ˆπ
i> wπ,ˆπ
i+1. For sake of
contradiction, fix i∈[d−1]and assume there exists a ˆπ∈ Sdsuch that wπ,ˆπ
i> wπ,ˆπ
i+1. Observe that
16any element of ˆπ(w)can be expressed byj
βdusing some j∈ {0,1, . . . , d −1}. Thus,
wπ,ˆπ
i> wπ,ˆπ
i+1
⇔(1−1
d)(i−1
βd) + (1
d)(ˆπ(w))j>(1−1
d)(i
βd) + (1
d)(ˆπ(w))ˆj
⇒ (1−1
d)(i−1
βd) + (1
d)(j
βd)>(1−1
d)(i
βd) + (1
d)(ˆj
βd)
⇒ (i−1)(1−1
d) +j(1
d)> i(1−1
d) +ˆj(1
d) Multiply by βd
⇒ 1−d >ˆj−j
for some j,ˆj∈ {0,1, . . . , d −1}where j̸=ˆj.
Case 1 : (j <ˆj): The smallest value possible for ˆj−jis0−(d−1)however, 1−d≯1−d.
Case 2 :(j >ˆj): The smallest value possible for ˆj−jis1however, 1−d≯1.
Hence, Py
α⊆∆π
dand specifically, there can exists an extreme point of Py
αthat lies on the boundary
of∆π
das shown in Case 1 . However, if α∈(0,1
d), every extreme point of Py
αmoves closer to
π(w)(besides the extreme point itself already on π(w)) and therefore Py
αlies strictly within ∆π
d. By
symmetry of Pwand the linearity of φ, this would imply that for all y′, y′′∈ Y such that y′̸=y′′
it holds that Py′
α∩Py′′
α=∅. Thus by Corollary 6, (LG
φ, ψPw,α)isℓ0−1-calibrated for Θαwhere
α∈(0,1
d).
B.4 Omitted Proofs from § 5
Lemma 9. Say we are given a cross-polytope embedding φ: ∆2d→P⊕and induced loss LG
φ.
Let(vai, vbi), be the ithdiagonal pair (i.e. φ(δai) =vai). Define the property Γφ: ∆2d→ B
element-wise by
Γφ(p)i:=((<, ai, bi)ifpai< pbi
(>, ai, bi)ifpai> pbi
(=, ai, bi)ifpai=pbi.
Furthermore define the link ψP⊕:Rd→ B with respect to each diagonal pair as
ψ(u;vai, vbi)P⊕
i:=((<, ai, bi)if||u−vai||2>||u−vbi||2
(>, ai, bi)if||u−vai||2<||u−vbi||2
(=, ai, bi) o.w.
Then (LG
φ, ψP⊕)elicits Γφ.
Proof. W.l.o.g, fix a diagonal pair (va, vb)and let va:= 11andvb:=− 11. Define the embedding
φaccordingly. We will show that the following is true for all distributions mapped via φtou∈P⊕.
||u−va||2>||u−vb||2⇐⇒ pa< pb
OR||u−va||2<||u−vb||2⇐⇒ pa> pb
OR||u−va||2=||u−vb||2⇐⇒ pa=pb.
First, fix p∈∆2d. Recall, by Proposition 2, the minimizing report for LG
φin expectation is
u=φ(p)∈P⊂Rd. We will prove the forward direction of the first and second lines. Then the
reverse directions follow from the contrapositives.
17Case 1 ,=⇒: Assume for contradiction that pa< pband||φ(p)−va||2<||φ(p)−vb||2. Then
⟨φ(p)− 11, φ(p)− 11⟩<⟨φ(p) + 11, φ(p) + 11⟩
(u1−1)2+X
i=1u2
i<(u1+ 1)2+X
i=1u2
i
−u1<u1.
By the definition of a d-cross polytope P⊕:= conv ( {π((±1,0, . . . , 0))|π∈ S d})and the
orthogonal relation between vertices, to express a u∈P⊕as a convex combination of vertices, each
diagonal pair of vertices coefficients solely influence the position along a single unit basis vector.
Hence, due to the definition of φ, we have u1= 11·pa− 11·pb<0since we have assumed that
pa< pb. Hence −u1< u 1<0, a contradiction.
Case 2 ,=⇒: Assume pa> pband||φ(p)−va||2<||φ(p)−vb||2. By symmetry with case 1, all
the inequalities are reversed, leading to the contradiction that −u1> u 1>0.
Case 3 : (pa=pb): Follows from the if and only ifs of cases 1 and 2.
Hence (LG
φ, ψφ)elicits Γφ.
Theorem 10. Letd≥2. The mode is (2d, d, m )-Polytope Elicitable for some m∈[2d−1, d(2d−1)].
Proof. We will elicit the mode via the intermediate properties, Γφj, defined in Lemma 9. First we
construct a set of embeddings so that we guarantee that all the φj’s allow comparison between any
pair of outcome probabilities. For example, for each unique pair (a, b)j∈ Y
2
define an embedding:
φj(δa) = 11andφj(δb) =− 11, and embed every other remaining report r∈ Y \ { a, b}arbitrarily.
Since (LG
φ, ψP⊕)elicits Γφ, minimizing each LG
φjwith a separate model yields us comparisons
via the link ψP⊕. To find the set r∈ Y such that pris maximum, we use a sorting algorithm
that uses pairwise comparisons, such as bubble sort. Hence with Υas Algorithm 1, we have that
Υ({LG
φj, ψP⊕}) =mode (p).
Assuming there exist φjs such that there is no redundancy in comparison pairs between each Γφj, we
would need onlyd(2d−1)
d= 2d−1problem instances. Hence, we establish our lower bound on the
needed number of problem instances.
C Hamming Loss Hallucination Example
Hamming loss ℓ:Y × Y → R+is defined by ℓ(y,ˆy) =Pd
i=11yi̸= ˆyiwhere Y={−1,1,}d.
Suppose d= 3and we have the following indexing over outcomes
Y:={y1≡(1,1,1), y2≡(1,1,−1), y3≡(1,−1,1), y4≡(−1,1,1),
y5≡(−1,−1,1), y6≡(1,−1,−1), y7≡(−1,1,−1), y8≡(−1,−1,−1)}.
Let us define the following distribution
pϵ= (0,1
3−ϵ,1
3−ϵ,1
3−ϵ,0,0,0,3ϵ)∈∆Y
such that ϵ >0.
•EY∼pϵ[ℓ(y1, Y)] = 1 + 6 ϵ
•EY∼pϵ[ℓ(y2, Y)] =EY∼pϵ[ℓ(y3, Y)] =EY∼pϵ[ℓ(y4, Y)] =4
3+ 2ϵ
•EY∼pϵ[ℓ(y5, Y)] =EY∼pϵ[ℓ(y6, Y)] =EY∼pϵ[ℓ(y7, Y)] =7
3−4ϵ
•EY∼pϵ[ℓ(y8, Y)] = 2 −6ϵ
For all ϵ∈[0,1
12), the minimizing report in expectation is y1= (1,1,1). However, pϵ,1= 0and
thus, a hallucination would occur under a calibrated surrogate and link pair.
18D Linking under Multiple Problem Instances
As stated in § 5, when using real data, given that these are asymptotic results, we may have conflicting
logic for the provided individual reports. In this section, we provide an approach such that the
algorithm still reports information in the aforementioned scenario and will reduce to Algorithm 1
asymptotically. We build a binary relation table M∈ {0,1}n×nwith the provided reports. Based
onM, we select a largest subset of S⊆ Y such that when Mis restricted to rows and columns
corresponding to the elements of S, denoted by MS, we have that MSis reflexive, antisymmetric,
transitive, and strongly connected implying MShas a total-order relation defined over its elements.
Having a total-order relation infers the mode can be found via comparisons. The algorithm returns
(R, S), where Ris the mode set with respect to the elements of S.
Algorithm 2 Elicit mode via comparisons and the d-Cross Polytopes over well-defined partial
orderings
Require: M={(LG
φj, ψP⊕
j)}m
j=1
Learn a model hj:X →Rdfor each instance (LG
φj, ψP⊕
j)∈M
For some fixed x∈ X, collect all Bj←ψP⊕
j(hj(x))where Bj∈ Bj
Build M∈ {0,1}n×nbinary relation table with provided {Bj}m
j=1as such
• Label rows top to bottom by y1, . . . , y nand columns left to right by y1, . . . , y n.
• For all (·, pyi, pyk)∈Bj, ifpyi≤pyksetM[i, k] = 1 and0otherwise.
Select largest subset S⊆ Y such that MSis reflexive, antisymmetric, transitive, and strongly
connected.
Report (R, S)←FindMaxElements-of- S(M;S)
19NeurIPS Paper Checklist
The checklist is designed to encourage best practices for responsible machine learning research,
addressing issues of reproducibility, transparency, research ethics, and societal impact. Do not remove
the checklist: The papers not including the checklist will be desk rejected. The checklist should
follow the references and precede the (optional) supplemental material. The checklist does NOT
count towards the page limit.
Please read the checklist guidelines carefully for information on how to answer these questions. For
each question in the checklist:
• You should answer [Yes] , [No] , or [NA] .
•[NA] means either that the question is Not Applicable for that particular paper or the
relevant information is Not Available.
• Please provide a short (1–2 sentence) justification right after your answer (even for NA).
The checklist answers are an integral part of your paper submission. They are visible to the
reviewers, area chairs, senior area chairs, and ethics reviewers. You will be asked to also include it
(after eventual revisions) with the final version of your paper, and its final version will be published
with the paper.
The reviewers of your paper will be asked to use the checklist as one of the factors in their evaluation.
While "[Yes] " is generally preferable to "[No] ", it is perfectly acceptable to answer "[No] " provided a
proper justification is given (e.g., "error bars are not reported because it would be too computationally
expensive" or "we were unable to find the license for the dataset we used"). In general, answering
"[No] " or "[NA] " is not grounds for rejection. While the questions are phrased in a binary way, we
acknowledge that the true answer is often more nuanced, so please just use your best judgment and
write a justification to elaborate. All supporting evidence can appear either in the main paper or the
supplemental material, provided in appendix. If you answer [Yes] to a question, in the justification
please point to the section(s) where related material for the question can be found.
IMPORTANT, please:
•Delete this instruction block, but keep the section heading “NeurIPS paper checklist" ,
•Keep the checklist subsection headings, questions/answers and guidelines below.
•Do not modify the questions and only use the provided macros for your answers .
1.Claims
Question: Do the main claims made in the abstract and introduction accurately reflect the
paper’s contributions and scope?
Answer: [Yes]
Justification: Any claimed result in the abstract is proved within this work.
Guidelines:
•The answer NA means that the abstract and introduction do not include the claims
made in the paper.
•The abstract and/or introduction should clearly state the claims made, including the
contributions made in the paper and important assumptions and limitations. A No or
NA answer to this question will not be perceived well by the reviewers.
•The claims made should match theoretical and experimental results, and reflect how
much the results can be expected to generalize to other settings.
•It is fine to include aspirational goals as motivation as long as it is clear that these goals
are not attained by the paper.
2.Limitations
Question: Does the paper discuss the limitations of the work performed by the authors?
Answer: [Yes]
Justification: Yes, our paper discuss how these results are asymptotic.
20Guidelines:
•The answer NA means that the paper has no limitation while the answer No means that
the paper has limitations, but those are not discussed in the paper.
• The authors are encouraged to create a separate "Limitations" section in their paper.
•The paper should point out any strong assumptions and how robust the results are to
violations of these assumptions (e.g., independence assumptions, noiseless settings,
model well-specification, asymptotic approximations only holding locally). The authors
should reflect on how these assumptions might be violated in practice and what the
implications would be.
•The authors should reflect on the scope of the claims made, e.g., if the approach was
only tested on a few datasets or with a few runs. In general, empirical results often
depend on implicit assumptions, which should be articulated.
•The authors should reflect on the factors that influence the performance of the approach.
For example, a facial recognition algorithm may perform poorly when image resolution
is low or images are taken in low lighting. Or a speech-to-text system might not be
used reliably to provide closed captions for online lectures because it fails to handle
technical jargon.
•The authors should discuss the computational efficiency of the proposed algorithms
and how they scale with dataset size.
•If applicable, the authors should discuss possible limitations of their approach to
address problems of privacy and fairness.
•While the authors might fear that complete honesty about limitations might be used by
reviewers as grounds for rejection, a worse outcome might be that reviewers discover
limitations that aren’t acknowledged in the paper. The authors should use their best
judgment and recognize that individual actions in favor of transparency play an impor-
tant role in developing norms that preserve the integrity of the community. Reviewers
will be specifically instructed to not penalize honesty concerning limitations.
3.Theory Assumptions and Proofs
Question: For each theoretical result, does the paper provide the full set of assumptions and
a complete (and correct) proof?
Answer: [Yes]
Justification: Yes, we thoroughly introduce every necessary definition and past result
necessary to understand the assumptions that hold under our results.
Guidelines:
• The answer NA means that the paper does not include theoretical results.
•All the theorems, formulas, and proofs in the paper should be numbered and cross-
referenced.
•All assumptions should be clearly stated or referenced in the statement of any theorems.
•The proofs can either appear in the main paper or the supplemental material, but if
they appear in the supplemental material, the authors are encouraged to provide a short
proof sketch to provide intuition.
•Inversely, any informal proof provided in the core of the paper should be complemented
by formal proofs provided in appendix or supplemental material.
• Theorems and Lemmas that the proof relies upon should be properly referenced.
4.Experimental Result Reproducibility
Question: Does the paper fully disclose all the information needed to reproduce the main ex-
perimental results of the paper to the extent that it affects the main claims and/or conclusions
of the paper (regardless of whether the code and data are provided or not)?
Answer: [Yes]
Justification: The results of this work have rigorous proofs presented next to the results or
referenced clearly in the appendix.
Guidelines:
• The answer NA means that the paper does not include experiments.
21•If the paper includes experiments, a No answer to this question will not be perceived
well by the reviewers: Making the paper reproducible is important, regardless of
whether the code and data are provided or not.
•If the contribution is a dataset and/or model, the authors should describe the steps taken
to make their results reproducible or verifiable.
•Depending on the contribution, reproducibility can be accomplished in various ways.
For example, if the contribution is a novel architecture, describing the architecture fully
might suffice, or if the contribution is a specific model and empirical evaluation, it may
be necessary to either make it possible for others to replicate the model with the same
dataset, or provide access to the model. In general. releasing code and data is often
one good way to accomplish this, but reproducibility can also be provided via detailed
instructions for how to replicate the results, access to a hosted model (e.g., in the case
of a large language model), releasing of a model checkpoint, or other means that are
appropriate to the research performed.
•While NeurIPS does not require releasing code, the conference does require all submis-
sions to provide some reasonable avenue for reproducibility, which may depend on the
nature of the contribution. For example
(a)If the contribution is primarily a new algorithm, the paper should make it clear how
to reproduce that algorithm.
(b)If the contribution is primarily a new model architecture, the paper should describe
the architecture clearly and fully.
(c)If the contribution is a new model (e.g., a large language model), then there should
either be a way to access this model for reproducing the results or a way to reproduce
the model (e.g., with an open-source dataset or instructions for how to construct
the dataset).
(d)We recognize that reproducibility may be tricky in some cases, in which case
authors are welcome to describe the particular way they provide for reproducibility.
In the case of closed-source models, it may be that access to the model is limited in
some way (e.g., to registered users), but it should be possible for other researchers
to have some path to reproducing or verifying the results.
5.Open access to data and code
Question: Does the paper provide open access to the data and code, with sufficient instruc-
tions to faithfully reproduce the main experimental results, as described in supplemental
material?
Answer: [NA]
Justification:This paper does not include experiments requiring code.
Guidelines:
• The answer NA means that paper does not include experiments requiring code.
•Please see the NeurIPS code and data submission guidelines ( https://nips.cc/
public/guides/CodeSubmissionPolicy ) for more details.
•While we encourage the release of code and data, we understand that this might not be
possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not
including code, unless this is central to the contribution (e.g., for a new open-source
benchmark).
•The instructions should contain the exact command and environment needed to run to
reproduce the results. See the NeurIPS code and data submission guidelines ( https:
//nips.cc/public/guides/CodeSubmissionPolicy ) for more details.
•The authors should provide instructions on data access and preparation, including how
to access the raw data, preprocessed data, intermediate data, and generated data, etc.
•The authors should provide scripts to reproduce all experimental results for the new
proposed method and baselines. If only a subset of experiments are reproducible, they
should state which ones are omitted from the script and why.
•At submission time, to preserve anonymity, the authors should release anonymized
versions (if applicable).
22•Providing as much information as possible in supplemental material (appended to the
paper) is recommended, but including URLs to data and code is permitted.
6.Experimental Setting/Details
Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
results?
Answer: [NA]
Justification: The paper does not include experiments
Guidelines:
• The answer NA means that the paper does not include experiments.
•The experimental setting should be presented in the core of the paper to a level of detail
that is necessary to appreciate the results and make sense of them.
•The full details can be provided either with the code, in appendix, or as supplemental
material.
7.Experiment Statistical Significance
Question: Does the paper report error bars suitably and correctly defined or other appropriate
information about the statistical significance of the experiments?
Answer: [NA]
Justification: The paper does not include experiments.
Guidelines:
• The answer NA means that the paper does not include experiments.
•The authors should answer "Yes" if the results are accompanied by error bars, confi-
dence intervals, or statistical significance tests, at least for the experiments that support
the main claims of the paper.
•The factors of variability that the error bars are capturing should be clearly stated (for
example, train/test split, initialization, random drawing of some parameter, or overall
run with given experimental conditions).
•The method for calculating the error bars should be explained (closed form formula,
call to a library function, bootstrap, etc.)
• The assumptions made should be given (e.g., Normally distributed errors).
•It should be clear whether the error bar is the standard deviation or the standard error
of the mean.
•It is OK to report 1-sigma error bars, but one should state it. The authors should
preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis
of Normality of errors is not verified.
•For asymmetric distributions, the authors should be careful not to show in tables or
figures symmetric error bars that would yield results that are out of range (e.g. negative
error rates).
•If error bars are reported in tables or plots, The authors should explain in the text how
they were calculated and reference the corresponding figures or tables in the text.
8.Experiments Compute Resources
Question: For each experiment, does the paper provide sufficient information on the com-
puter resources (type of compute workers, memory, time of execution) needed to reproduce
the experiments?
Answer: [NA]
Justification: The paper does not include experiments.
Guidelines:
• The answer NA means that the paper does not include experiments.
•The paper should indicate the type of compute workers CPU or GPU, internal cluster,
or cloud provider, including relevant memory and storage.
23•The paper should provide the amount of compute required for each of the individual
experimental runs as well as estimate the total compute.
•The paper should disclose whether the full research project required more compute
than the experiments reported in the paper (e.g., preliminary or failed experiments that
didn’t make it into the paper).
9.Code Of Ethics
Question: Does the research conducted in the paper conform, in every respect, with the
NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines ?
Answer: [Yes]
Justification: None of our conducted work for this paper violates the code of ethics presented.
Guidelines:
•The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
•If the authors answer No, they should explain the special circumstances that require a
deviation from the Code of Ethics.
•The authors should make sure to preserve anonymity (e.g., if there is a special consid-
eration due to laws or regulations in their jurisdiction).
10.Broader Impacts
Question: Does the paper discuss both potential positive societal impacts and negative
societal impacts of the work performed?
Answer: [Yes]
Justification: In the body of our paper, we provide a broader impace section.
Guidelines:
• The answer NA means that there is no societal impact of the work performed.
•If the authors answer NA or No, they should explain why their work has no societal
impact or why the paper does not address societal impact.
•Examples of negative societal impacts include potential malicious or unintended uses
(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
(e.g., deployment of technologies that could make decisions that unfairly impact specific
groups), privacy considerations, and security considerations.
•The conference expects that many papers will be foundational research and not tied
to particular applications, let alone deployments. However, if there is a direct path to
any negative applications, the authors should point it out. For example, it is legitimate
to point out that an improvement in the quality of generative models could be used to
generate deepfakes for disinformation. On the other hand, it is not needed to point out
that a generic algorithm for optimizing neural networks could enable people to train
models that generate Deepfakes faster.
•The authors should consider possible harms that could arise when the technology is
being used as intended and functioning correctly, harms that could arise when the
technology is being used as intended but gives incorrect results, and harms following
from (intentional or unintentional) misuse of the technology.
•If there are negative societal impacts, the authors could also discuss possible mitigation
strategies (e.g., gated release of models, providing defenses in addition to attacks,
mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
feedback over time, improving the efficiency and accessibility of ML).
11.Safeguards
Question: Does the paper describe safeguards that have been put in place for responsible
release of data or models that have a high risk for misuse (e.g., pretrained language models,
image generators, or scraped datasets)?
Answer: [NA]
Justification: The answer NA means that the paper poses no such risks.
Guidelines:
• The answer NA means that the paper poses no such risks.
24•Released models that have a high risk for misuse or dual-use should be released with
necessary safeguards to allow for controlled use of the model, for example by requiring
that users adhere to usage guidelines or restrictions to access the model or implementing
safety filters.
•Datasets that have been scraped from the Internet could pose safety risks. The authors
should describe how they avoided releasing unsafe images.
•We recognize that providing effective safeguards is challenging, and many papers do
not require this, but we encourage authors to take this into account and make a best
faith effort.
12.Licenses for existing assets
Question: Are the creators or original owners of assets (e.g., code, data, models), used in
the paper, properly credited and are the license and terms of use explicitly mentioned and
properly respected?
Answer: [NA]
Justification: The paper does not use existing assets.
Guidelines:
• The answer NA means that the paper does not use existing assets.
• The authors should cite the original paper that produced the code package or dataset.
•The authors should state which version of the asset is used and, if possible, include a
URL.
• The name of the license (e.g., CC-BY 4.0) should be included for each asset.
•For scraped data from a particular source (e.g., website), the copyright and terms of
service of that source should be provided.
•If assets are released, the license, copyright information, and terms of use in the package
should be provided. For popular datasets, paperswithcode.com/datasets has
curated licenses for some datasets. Their licensing guide can help determine the license
of a dataset.
•For existing datasets that are re-packaged, both the original license and the license of
the derived asset (if it has changed) should be provided.
•If this information is not available online, the authors are encouraged to reach out to
the asset’s creators.
13.New Assets
Question: Are new assets introduced in the paper well documented and is the documentation
provided alongside the assets?
Answer: [NA]
Justification: The paper does not release new assets.
Guidelines:
• The answer NA means that the paper does not release new assets.
•Researchers should communicate the details of the dataset/code/model as part of their
submissions via structured templates. This includes details about training, license,
limitations, etc.
•The paper should discuss whether and how consent was obtained from people whose
asset is used.
•At submission time, remember to anonymize your assets (if applicable). You can either
create an anonymized URL or include an anonymized zip file.
14.Crowdsourcing and Research with Human Subjects
Question: For crowdsourcing experiments and research with human subjects, does the paper
include the full text of instructions given to participants and screenshots, if applicable, as
well as details about compensation (if any)?
Answer: [NA]
Justification: The paper does not involve crowdsourcing nor research with human subjects.
25Guidelines:
•The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
•Including this information in the supplemental material is fine, but if the main contribu-
tion of the paper involves human subjects, then as much detail as possible should be
included in the main paper.
•According to the NeurIPS Code of Ethics, workers involved in data collection, curation,
or other labor should be paid at least the minimum wage in the country of the data
collector.
15.Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
Subjects
Question: Does the paper describe potential risks incurred by study participants, whether
such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
approvals (or an equivalent approval/review based on the requirements of your country or
institution) were obtained?
Answer: [NA]
Justification: the paper does not involve crowdsourcing nor research with human subjects.
Guidelines:
•The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
•Depending on the country in which research is conducted, IRB approval (or equivalent)
may be required for any human subjects research. If you obtained IRB approval, you
should clearly state this in the paper.
•We recognize that the procedures for this may vary significantly between institutions
and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
guidelines for their institution.
•For initial submissions, do not include any information that would break anonymity (if
applicable), such as the institution conducting the review.
26