Dueling Over Dessert, Mastering the Art of Repeated
Cake Cutting
Simina Brânzei
Purdue University
simina.branzei@gmail.comMohammadTaghi Hajiaghayi
University of Maryland
hajiaghayi@gmail.comReed Phillips
Purdue University
phill289@purdue.edu
Suho Shin
University of Maryland
suhoshin@umd.eduKun Wang
Purdue University
wang5675@purdue.edu
Abstract
We consider the setting of repeated fair division between two players, denoted Alice
and Bob, with private valuations over a cake. In each round, a new cake arrives,
which is identical to the ones in previous rounds. Alice cuts the cake at a point of her
choice, while Bob chooses the left piece or the right piece, leaving the remainder
for Alice. We consider two versions: sequential , where Bob observes Alice’s cut
point before choosing left/right, and simultaneous , where he only observes her cut
point after making his choice. The simultaneous version was first considered in
Aumann and Maschler (1995).
We observe that if Bob is almost myopic and chooses his favorite piece too often,
then he can be systematically exploited by Alice through a strategy akin to a
binary search. This strategy allows Alice to approximate Bob’s preferences with
increasing precision, thereby securing a disproportionate share of the resource over
time.
We analyze the limits of how much a player can exploit the other one and show
that fair utility profiles are in fact achievable. Specifically, the players can enforce
the equitable utility profile of (1/2,1/2)in the limit on every trajectory of play, by
keeping the other player’s utility to approximately 1/2on average while guaran-
teeing they themselves get at least approximately 1/2on average. We show this
theorem using a connection with Blackwell approachability.
Finally, we analyze a natural dynamic known as fictitious play, where players best
respond to the empirical distribution of the other player. We show that fictitious
play converges to the equitable utility profile of (1/2,1/2)at a rate of O(1/√
T).
38th Conference on Neural Information Processing Systems (NeurIPS 2024).1 Introduction
Cake cutting is a model of fair division Steinhaus (1948), where the cake is a metaphor for a
heterogeneous divisible resource such as land, time, memory in shared computing systems, clean
water, greenhouse gas emissions, fossil fuels, or other natural deposits (Procaccia (2013)). The
problem is to divide the resource among multiple participants so that everyone believes the allocation
is fair. There is an extensive literature on cake cutting in mathematics, political science, economics
(Robertson and Webb (1998); Brams and Taylor (1996); Moulin (2003)) and computer science
(Brandt et al. (2016)), with a number of protocols implemented (Goldman and Procaccia (2014)).
Traditional approaches to cake cutting often consider single instances of division. However, many
real-world scenarios require a repeated division of resources. For instance, consider the recurring task
of allocating classroom space in educational institutions each quarter or that of repeatedly dividing
computational resources (such as CPU and memory) among the members of an organization. These
settings reflect the reality of many social and economic interactions, necessitating a model that not
only addresses the fairness of a single division, but also the dynamics and strategies that emerge
among participants over repeated interactions.
Repeated fair division is a classic problem first considered by Aumann and Maschler (1995), where
two players—denoted Alice and Bob—have private valuations over the cake and interact in the
following environment. Every day a new cake arrives, which is the same as the ones in previous days.
Alice cuts the cake at a point of her choosing, while Bob chooses either the left piece or the right
piece, leaving the remainder to Alice. Aumann and Maschler (1995) considered the simultaneous
setting, where both players take their actions at the same time each day, and analyzed the payoffs
achievable by Bob when he can have one of two types of valuations.
In this paper, we provide the first substantial progress in this classic setting. We further analyze the
simultaneous version from Aumann and Maschler (1995) and also go beyond it, by considering the
sequential version where Bob has the advantage of observing Alice’s chosen cut point before making
his selection. Tactical considerations remain pivotal in the sequential version, which is none other
than the repeated Cut-and-choose protocol with strategic players.
A key observation in our study is the strategic vulnerability inherent in repeated Cut-and-choose. At
a high level, if Bob consistently chooses his preferred piece, then he can be systematically exploited
by Alice through a strategy akin to a binary search. This strategy allows Alice to approximate Bob’s
preferences with increasing precision, thereby securing a disproportionate share of the resource over
time. To fight back Alice’s attempt to exploit him, Bob could deceive her by being unpredictable,
thus hiding his preferences. While this behavior has the potential to reduce Alice’s share of the cake,
it could also come at the price of affecting Bob’s own payoff guarantees in the long term.
Our analysis of the repeated cake cutting game formalizes the intuition that Alice can exploit a (nearly)
myopic Bob that often chooses his favorite piece. This outcome, where Alice gains more value,
is not entirely fair, as it leaves her happier than Bob. The fairness notion of equitability addresses
this imbalance, embodying the idea that players should be equally happy. Formally, it requires that
Alice’s value for her allocation should equal Bob’s value for his allocation. Achieving equitability is
particularly important in scenarios with potential for conflict, such as splitting an inheritance.
We show that achieving equitable outcomes in the repeated interaction is in fact possible. Specifically,
each player has a strategy that guarantees the other player receives no more than approximately 1/2
on average, while securing at least approximately 1/2for themselves. This approaches the equitable
utility profile of (1/2,1/2)in the limit. We obtain this result by using a connection with Blackwell
approachability (1956). Moreover, we consider a natural dynamic known as fictitious play (Brown
(1951)), where players best respond to the empirical frequency of the other player’s past actions. We
show that fictitious play converges to the equitable utility profile of (1/2,1/2)at a rate of O(1/√
T).
1.1 Model
Cake cutting model for two players. The cake is modelled as the interval [0,1]. There are players
N={A, B}, where Astands for Alice and Bfor Bob. Each player ihas a private value density
function vi: [0,1]→R+. Apiece of cake is a measurable set S⊆[0,1]. The value of player i
forSisVi(S) =R
x∈Svi(x)dx. Atoms are worth zero and the valuations are normalized so thatVi([0,1]) = 1 ∀i∈[n]. We require bounded densities, i.e. there exist fixed arbitrary δ,∆>0such
thatδ≤vi(x)≤∆for all x∈[0,1].
An allocation Z= (ZA, ZB)is a partition of the cake among the players such that each player i
receives piece Zi, the pieces are disjoint, andS
i∈NZi= [0,1]. The valuation (aka utility or payoff)
of player iat an allocation ZisVi(Zi). An allocation Zisequitable if the players are equally happy
with their pieces, meaning VA(ZA) =VB(ZB).
LetmAbe Alice’s midpoint of the cake and mBBob’s midpoint. Alice’s Stackelberg value , denoted
u∗
A, is the utility she receives when she cuts the cake at mBand Bob chooses his favorite piece,
breaking ties in Alice’s favor. The midpoints and Alice’s Stackelberg value are depicted in Figure 1.
Figure 1: Densities for Alice (blue) and Bob (red). Figure (a) shows Alice’s midpoint mAand Bob’s
midpoint mB. The shaded area in Figure (b) is Alice’s Stackelberg value.
Repeated cake cutting. Each round t= 1,2, . . . , T , the next steps take place:
• A new cake arrives, which is identical to the ones in previous rounds.
•Alice cuts the cake at a point at∈[0,1]of her choice. Bob chooses either the left piece or
the right piece, then Alice takes the remainder.
We consider two versions: sequential , where Bob observes Alice’s cut point atbefore choosing
left/right, and simultaneous , where he only observes her cut point after making his choice.
A pure strategy is a map from the history observed by a player to the next action to play. A mixed
strategy is a probability distribution over pure strategies.
1.2 Our Results
Our results will examine how players fare in the repeated game over Trounds. Given a history H,
Alice’s Stackelberg regret is RegA(H) =PT
t=1[u∗
A−ut
A(H)], where u∗
Ais Alice’s Stackelberg
value and ut
A(H)is Alice’s utility in round tunder history H.
Suppose Alice uses a mixed strategy SAand Bob uses a mixed strategy SB. Then SAensures Alice’s
Stackelberg regret is at most γagainst SBifRegA(H)≤γfor all T-round histories Hthat could
have arisen under the strategies (SA, SB). Precise definitions for strategies/regret and the remaining
notation needed for the full proofs can be found in Section 3.
Alice exploiting Bob
We start with an observation about the sequential setting. If Bob chooses his favorite piece in each
round, then Alice can exploit him by running binary search until identifying his midpoint within a
small error and then cutting near it for the rest of time. This will lead to Alice getting essentially her
Stackelberg value in all but O(logT)rounds, while Bob will get 1/2in all but O(logT)rounds.
Proposition 1. If Bob plays myopically in the sequential setting, then Alice has a strategy that
ensures her Stackelberg regret is O(logT).
This exploitation phenomenon holds more generally: if Bob’s strategy has bounded regret with
respect to the standard of selecting his preferred piece in every round in hindsight, then Alice can
almost get her Stackelberg value in each round. Her Stackelberg regret is a function of Bob’s regret
guarantee, as quantified in the next theorem.
2Theorem 1 (Exploiting a nearly myopic Bob) .Letα∈[0,1). Suppose Bob plays a strategy that
ensures his regret is O(Tα)in the sequential setting. Let Bαdenote the set of all such Bob strategies.
•If Alice knows α, she has a strategy SA=SA(α)that ensures her Stackelberg regret is
O(Tα+1
2logT). The exponent is sharp: Alice’s Stackelberg regret is Ω(Tα+1
2)for some Bob
strategy in Bα.
•If Alice does not know α, she has a strategy SAthat ensures her Stackelberg regret is O T
logT
.
The exponent is sharp: if SAguarantees Alice Stackelberg regret O(Tβ)against all Bob strategies
inBαfor some β∈[0,1), then SAhas Stackelberg regret Ω(T)for some Bob strategy in Bβ.
In contrast, in the simultaneous setting, Alice may not approach her Stackelberg value on every
trajectory of play. In order to get her Stackelberg value in any given round, Alice needs to cut near
Bob’s midpoint and Bob needs to pick the piece he prefers, say R. However, if Bob deterministically
commits to picking R, he will be completely exploited by an Alice who cuts at 1, breaking any
reasonable regret guarantee he might have. Indeed, any Bob with a deterministic strategy (possibly
using different actions over the rounds) has a corresponding Alice who can completely exploit
him. Therefore, any Bob strategy with a good regret guarantee would behave randomly, making it
impossible for Alice to reliably get her Stackelberg value on every trajectory. For this reason, we
focus on the sequential setting when studying how Alice can exploit Bob.1
Equitable payoffs.
Motivated by Theorem 1, we examine the general limits of how much each player can exploit the
other and whether fair outcomes are achievable, in both the sequential and simultaneous settings.
Given a history H, player iis said to get an average payoff of γif 1
TPT
t=1ut
i(H) =γ, where the
left hand side is not expected utility, but rather the observed total utility averaged over Trounds.
We say a utility profile (uA, uB)isequitable ifuA=uB. In the single round setting, uAanduB
will naturally represent the utilities of the players at an allocation. In the repeated setting, uAanduB
will represent the time-average utilities of the players.
The next theorems show that each player can keep the other player at 1/2while guaranteeing 1/2for
themselves. This type of behavior is reminiscent of spiteful bidding in auctions (Tang and Sandholm
(2012)), where a buyer’s utility diminishes if other bidders are too satisfied.
Theorem 2 (Alice enforcing equitable payoffs; informal) .In both the sequential and simultaneous
settings, Alice has a pure strategy SA, such that for every Bob strategy SB:
•on every trajectory of play, Alice’s average payoff is at least 1/2−o(1), while Bob’s average
payoff is at most 1/2 +o(1). More precisely,uA
T≥1
2−Θ
1√
T
anduB
T≤1
2+ Θ 1
lnT
,
where uiis the cumulative payoff of player iover the time horizon T.
A key ingredient in the proof of Theorem 2 is a connection with Blackwell’s approachability the-
orem Blackwell (1956). Generally speaking, Blackwell approachability can be used by a player
to limit the payoff of the other player in a certain region of the utility profile. However, the main
challenge is that there are uncountably many types of Bob and so Alice cannot apply the strategy
from Blackwell directly. Instead, Alice’s strategy constructs a countably infinite set of representatives,
which allows us to adapt Blackwell’s argument to this setting.
We show a symmetric theorem for Bob in the sequential setting, while in the simultaneous setting
Bob’s guarantee only holds in expectation.
Theorem 3 (Bob enforcing equitable payoffs; informal) .
•In the sequential setting: Bob has a pure strategy SB, such that for every Alice strategy SA, on
every trajectory of play, Bob’s average payoff is at least 1/2−o(1), while Alice’s average
payoff is at most 1/2 +o(1). More precisely,uB
T≥1
2−1√
TanduA
T≤1
2+ Θ
1√
T
.
1One may explore a weaker regret benchmark for Bob of always picking the better of left or right in hindsight,
which we believe would be an interesting direction for future work.
3•In the simultaneous setting: Bob has a mixed strategy SB, such that for every Alice strategy SA,
both players have average payoff 1/2in expectation.
When Alice and Bob play such strategies against each other, they approach an equitable utility profile
of(1/2,1/2). If just one player follows such a strategy, then the best the other player can do is to
ensure the safety value of 1/2for themselves, thus achieving the utility profile (1/2,1/2).
Fictitious play
Fictitious play is a classic learning rule where at each round, each player best responds to the empirical
frequency of play of the other player. Fictitious play was introduced in Brown (1951). Convergence
to Nash equilibria has been shown for zero-sum games (Robinson (1951)) and special cases of
general-sum games (Nachbar (1990); Monderer and Shapley (1996b,a)).
In the cake cutting model, learning rules such as fictitious play are more meaningful in the simul-
taneous setting, where there is uncertainty for both players due to the simultaneous actions. The
precise definition of the fictitious play dynamic is in Section 6, while an example of trajectories for
an instance with random valuations and uniform random tie-breaking can be found in Figure 2.
(a) Alice’s utility.
 (b) Bob’s utility.
Figure 2: Illustration of Alice’s and Bob’s average payoff in a randomly generated instance of
valuations. The X axis shows the time and the Y axis shows the average payoff up to that round.
The convergence properties of fictitious play can be characterized as follows.
Theorem 4 (Fictitious Play; informal) .When both Alice and Bob run fictitious play, the average
payoff of each player converges to 1/2at a rate of O(1/√
T).
Roadmap to the paper. Related work is in Section 2. Formal notation and preliminaries can be
found in Section 3. An overview of how Alice can exploit a nearly myopic Bob can be found in
Section 4, with formal proofs in Appendix A. An overview of how players can enforce equitable
payoffs can be found in Section 5, with formal proofs in Appendix B. Fictitious play can be found in
Section 6, with formal proofs in Appendix C. Concluding remarks can be found in Section 7.
2 Related Work
Cake cutting and fairness notions. The cake cutting model is due to Steinhaus (1948). Standard
fairness notions include proportionality, equitability, envy-freeness (Even and Paz (1984); Dubins
and Spanier (1961); Edward Su (1999); Stromquist (1980); Alon (1987)). For surveys, see Robertson
and Webb (1998); Brams and Taylor (1996); Moulin (2003); Brandt et al. (2016); Procaccia (2013).
In the Robertson-Webb (RW) query model for cake cutting (Woeginger and Sgall (2007)), a mediator
asks the players enough queries about their preferences until it can output a fair allocation. For
studies on the query complexity of cake cutting, see Even and Paz (1984); Woeginger and Sgall
(2007); Edmonds and Pruhs (2006); Procaccia (2009); Aziz and Mackenzie (2016); Amanatidis et al .
(2018); Cheze (2020); Stromquist (2008); Deng et al .(2012); Goldberg et al .(2020a); Filos-Ratsikas
et al.(2022); Segal-Halevi (2018); Deligkas et al .(2021); Goldberg et al .(2020b); Brânzei and Nisan
(2022, 2019); Filos-Ratsikas et al. (2020); Alon and Graur (2020); Filos-Ratsikas et al. (2021).
4Mossel and Tamuz (2010); Branzei and Miltersen (2015) studied truthful cake cutting in the RW
query model, and Chen et al .(2013); Bu et al .(2023); Bei et al .(2022); Tao (2022) in the direct
revelation model. The equilibria of cake cutting protocols were considered in Nicolò and Yu (2008);
Brânzei and Miltersen (2013); Brânzei et al. (2016); Goldberg and Iaru (2021).
Multiple divisible/indivisible goods and chores. The algorithms and complexity of finding fair
allocations in settings with multiple divisible/indivisible goods/bads were considered in Oh et al .
(2021); Plaut and Roughgarden (2020, 2019); Manurangsi and Suksompong (2021); Chaudhury
et al.(2021c); Bilò et al .(2019); Amanatidis et al .(2022); Procaccia (2020); Chaudhury et al .(2020,
2021b); Procaccia and Wang (2014); Kulkarni et al .(2021); Chaudhury et al .(2021a). Tucker-Foltz
and Zeckhauser (2023) analyze how the cutter should act in a single-round cut-and-choose on multiple
goods where the players’ valuations of the goods are drawn from a publicly known distribution.
Ghodsi et al. (2011) studied fairness in cloud computing settings, where there are multiple divisible
goods (e.g. CPU and memory) and the users have to run jobs with different resource requirements.
Kandasamy et al. (2020) studied players who do not know their own resource requirements.
Dynamic fair division. Closest to our setting is the analysis in the book of Aumann and Maschler
(1995) (page 243), where two players are dividing a cake with a cherry. Alice (the cutter) has a
uniform density and so she does not care for the cherry, while Bob (the chooser) may or may not like
the cherry. Alice and Bob declare their actions simultaneously and Alice is only allowed to cut in
one of two locations. Additionally, Alice has a prior over the type of Bob she is facing. Aumann and
Maschler (1995) analyzes the set of payoffs approachable for Bob using Blackwell approachability.
In contrast, we allow arbitrary value densities for the players and do not assume priors and also
consider the sequential version of the game.
Tamuz et al .(2018) introduced exploitability in repeated cut-and-choose protocols, with some cuts
made by a mediator, designing non-exploitable protocols. Online cake cutting was studied by Walsh
(2011), where agents can arrive/depart over time. For dynamic fair division where goods are allocated
irrevocably upon arrival, see Kash et al. (2014); Friedman et al. (2015); Benadè et al. (2022).
Learning in repeated Stackelberg games. The Stackelberg game was introduced by Stackelberg
(1934) to understand the first mover advantage of firms when entering a market. The Stackelberg
equilibrium concept has important applications such as security games Tambe (2011); Balcan et al .
(2015), online strategic classification Dong et al .(2018), and online principal agent problems
Hajiaghayi et al .(2023). Our model can be seen as each player facing an online learning version of a
repeated Stackelberg game.
Kleinberg and Leighton (2003) considered a seller’s problem of designing an efficient repeated posted
price mechanism to buy identical goods when it interacts with a sequence of myopic buyers. Gan et al .
(2019); Birmpas et al .(2020); Zhao et al .(2023) considered a repeated Stackelberg game to study
how the follower or leader can exploit the opponent in a general game with arbitrary payoffs. Their
techniques, however, do not apply to our model as they typically consider the setting of one player
knowing the entire payoff matrix trying to deceive the other player given behavioral assumptions.
Exploiting no-regret agents. Several works considered the extent to which one player can exploit
the knowledge that the other player has a strategy with sublinear regret. The goal is often to approach
the Stackelberg value, the maximum payoff that the exploiter could get by selecting an action first
and allowing the opponent to best-respond. In simultaneous games, Deng et al .(2019) showed the
exploiter can approach their Stackelberg value, assuming knowledge of the other player’s payoff
function. Haghtalab et al .(2022) showed that, for certain types of sequential games, an exploiting
leader can approach their Stackelberg value in the limit. Theorem 1 is a similar statement in our
setting, but we bound the exploited agent’s behavior with an explicit regret guarantee rather than
using discounted future payoffs; also, our setting is not captured by the types of games they consider.
Fictitious play. Fictitious play was introduced in Brown (1951). Convergence to Nash equilibria
has been shown for zero-sum games (Robinson (1951)) and special cases of general-sum games
(Nachbar (1990); Monderer and Shapley (1996b,a)). None of these results directly apply to our
setting, but the most relevant is Berger (2005), which covered non-degenerate 2×ngames (i.e. where
every action has a unique best response). Our “ 2× ∞ " game is degenerate, as Bob does not have a
unique best response to Alice cutting at mB. Few existing works apply fictitious play to games with
continuous action spaces. An example is Perkins and Leslie (2014), which showed that stochastic
fictitious play does converge in two-player zero-sum games with continuous action spaces.
5Karlin (1959) conjectured that fictitious play converges at a rate of O(T−1/2). Brandt et al .(2013)
found small games where the convergence rate is O(T−1/2), but with very large constants in the
O(). Daskalakis and Pan (2014) disproved Karlin’s conjecture, showing there exist games with
n×npayoff matrices in which convergence takes place at a rate of Ω(T−1/n)using adversarial
tie-breaking rules. Panageas et al. (2023) found examples of even slower convergence.
Harris (1998) showed that fictitious play converges at a rate of O(T−1)in2×2zero-sum games.
Abernethy et al .(2021) considered diagonal payoff matrices with non-adversarial tie-breaking rules,
showing convergence rates of O(T−1/2). Abernethy et al .(2021) does not give a rate of convergence
in our setting because requiring the payoff matrix to be diagonal would correspond to Alice only
being allowed to cut at 0or1. This assumption is not as natural in our setting. In fact, if Alice can
only cut at 0or1the game becomes zero-sum. Furthermore, we allow arbitrary tie-breaking rules.
3 Preliminaries
In this section we formally define the notation used in our proofs. All our notation applies to both the
sequential and simultaneous settings, unless otherwise stated.
History. Recall Tis the number of rounds. For each round t∈[T],
•letat∈[0,1]be Alice’s cut at time tandbt∈ {L, R}be Bob’s choice at time t, where L
stands for the left piece [0, at]andRfor the right piece [at,1].
•letAt= (a1, . . . , a t)be the history of cuts until the end of round tandBt= (b1, . . . , b t)
the history of choices made by Bob until the end of round t.
A history H= (AT, BT)denotes an entire trajectory of play.
Strategies. LetPbe the space of integrable value densities over [0,1]. A pure strategy for Alice at
timetis a function St
A: [0,1]t−1× {L, R}t−1× P × N→[0,1], such that St
A(At−1, Bt−1, vA, T)
is the next cut point made by Alice as a function of the history At−1of Alice’s cuts, the history Bt−1
of Bob’s choices, Alice’s valuation vA, and the horizon T.
For Bob, we define pure strategies separately for the sequential and simultaneous settings due to the
different feedback that he gets:
Sequential: A pure Bob strategy at time tis a map St
B: [0,1]t× {L, R}t−1× P × N→ {L, R}.
That is, Bob observes Alice’s cut point and then responds.
Simultaneous: A pure Bob strategy at time tis a map St
B: [0,1]t−1×{L, R}t−1×P×N→ {L, R}.
Thus here Bob chooses L/Rbefore observing Alice’s cut point at time t.
A pure strategy for Alice over the entire time horizon Tis denoted SA= (S1
A, . . . , ST
A)and tells
Alice what cut to make at each time t. A pure strategy for Bob over the entire time horizon Tis
denoted SB= (S1
B, . . . , ST
B)and tells Bob whether to play L/Rat each time t.
A mixed strategy is a probability distribution over the set of pure strategies.2
Rewards and utilities. Suppose Alice has mixed strategy SAand Bob has mixed strategy SB. Let
ut
Aandut
Bbe the random variables for the utility (payoff) experienced by Alice and Bob, respectively,
at round t. The utility of player i∈ {A, B}is denoted ui=ui(SA, SB) =PT
t=1ut
i.The utility of
player ifrom round t1tot2isui(t1, t2) =Pt2
t=t1ut
i.
The expected utility of player iisE[ui] =PT
t=1E[ut
i],where the expectation is taken over the
randomness of the strategies SAandSB.
Given a history H, letut
i(H)be player i’s utility in round tunder Hand let ui(H) =PT
t=1ut
i(H)
be player i’s cumulative utility under H.
2In fact, this is equivalent to the behavior strategy in which the player assigns a probability distribution given
a history, thanks to Kuhn’s theorem Kuhn (1950); Kuhn1(1953). The original version of Kuhn’s theorem is
restricted to games with finite action space, but can be extended to any action space that is isomorphic to unit
interval by Aumann (1961); Dresher et al. (2016), which contains our setting.
6Midpoints and Stackelberg value. LetmA∈[0,1]be Alice’s midpoint of the cake, with
VA([0, mA]) = 1 /2, and mB∈[0,1]be Bob’s midpoint, with VB([0, mB]) = 1 /2. Since the
densities are bounded from below, the midpoint of each player is uniquely defined. Alice’s Stackel-
berg value , denoted u∗
A, is the utility Alice gets when she cuts at mBand Bob chooses his favorite
piece breaking ties in favor of Alice (i.e. taking the piece she prefers less).
4 Alice exploiting Bob
In this section we give an overview of Theorem 1, which considers the sequential setting and quantifies
the extent to which Alice can exploit a Bob that has sub-linear regret with respect to the benchmark
of choosing the best piece in each round. Formal proofs for this section are in Appendix A.
We start by defining the notion of Stackelberg regret (Dong et al. (2018); Haghtalab et al. (2022)).
Definition 1 (Stackelberg regret) .Given a history Hof the places Alice cut and the pieces Bob chose
in each round, Alice’s Stackelberg regret is RegA(H) =PT
t=1[u∗
A−ut
A(H)], where u∗
Ais Alice’s
Stackelberg value and ut
A(H)is Alice’s utility in round tunder history H.
For Bob, we consider the basic notion of static regret, where Bob compares his payoff to what would
have happened if Alice’s actions remained the same but he chose the best piece in each round.
Definition 2 (Regret) .Given a history H, Bob’s regret is
RegB(H) =TX
t=1h
maxn
VB([0, at]), VB([at,1])o
−ut
B(H)i
,
recalling that ut
B(H)is Bob’s utility in round tunder history H.
Next we provide a proof sketch for Theorem 1, which is divided in the next two propositions,
corresponding to the cases where Alice knows αand does not know α.
Proposition 2. Letα∈[0,1). Suppose Bob plays a strategy that ensures his regret is O(Tα)and
letBαdenote the set of all such Bob strategies. Assume Alice knows α. Then she has a strategy
SA=SA(α)that ensures her Stackelberg regret is O 
Tα+1
2logT
. The exponent is sharp: Alice’s
Stackelberg regret is Ω 
Tα+1
2
for some Bob strategy in Bα.
Proof sketch. We sketch both the upper and lower bounds.
Sketch for the upper bound. LetSBdenote Bob’s strategy, which guarantees his regret is O(Tα).
Suppose Alice knows α. Then Alice initializes an interval I= [0,1]and uses the following strategy.
Iteratively, for i= 0,1, . . . , :
(1)Alice discretizes the interval I= [u, w]in a constant number of sub-intervals (set to 6) of equal
value to her, by cutting at points ai,jforj∈[5]such that u < a i,1< ai,2< . . . < a i,5< w.
Denote ai,0=uandai,6=w. An illustration is in Figure 3.
Figure 3: Illustration of step (1)fori= 0. Alice divides the interval [0,1]in6disjoint intervals of
equal value to her, demarcated by points a0,0= 0< a0,1< a0,2< a0,3< a0,4< a0,5<1 =a0,6.
(2)Alice selects a number η, which will be set “large enough” as a function of Tandα. In the next
5ηrounds, Alice cuts an equal number of times at each point ai,jforj∈[5]. That is:
•In each of the next ηrounds, Alice cuts at ai,1and observes Bob’s choices there,
computing the majority answer as ci,1=Lif Bob picked the left piece more times than
the right piece, and ci,1=Rotherwise. The next ηrounds after that Alice switches to
cutting at ai,2, and so on.
In this fashion, Alice computes ci,jas Bob’s majority answer corresponding to cut point
ai,jfor all j∈[5]. Also, by default ci,0=Randci,6=L. An illustration is in Figure 4.
7Figure 4: Illustration of step (2)fori= 0. Suppose η= 3. Alice cuts 3times at each of the points
a0,jand observes Bob’s choices, which are marked near each such cut point. By default, Alice knows
what the answer would be if she cut at 0or1, so those are set to RandL, respectively. The truthful
answers (reflecting Bob’s favorite piece according to his actual valuation) are marked with green,
while the lying answers are marked with orange.
(3)The points ai,jforj∈ {0, . . . , 6}are arranged on a line and each is labelled LorR, with the
leftmost point ai,0= 0labelled Rand the rightmost point ai,6= 1labelled L. Then there
is an index j∈ {0, . . . , 5}such that ci,j=Randci,j+1=L.
Alice computes a smaller interval Ii+1, essentially consisting of [ai,j, ai,j+1]and some extra
space around it to make sure that Ii+1contains Bob’s midpoint as follows. If j∈ {1, . . . , 4},
setIi+1= [ai,j−1, ai,j+2]. Ifj= 0, setIi+1= [ai,0, ai,3]. Ifj= 5, setIi+1= [ai,3, ai,6].
Then Alice iterates steps (1−3)on the interval I1. An illustration is in Figure 5.
Figure 5: Illustration of step (3)fori= 0. Alice labels each point a0,jwith the majority answer
there. Then she identifies the index jsuch that the point a0,jis labelled Rand the point a0,j+1is
labelled L. At this stage she is assured that either the interval [a0,j, a0,j+1]or one of the adjacent
ones contains Bob’s midpoint. Alice sets I1= [a0,3, a0,6]and recurses on it.
The full proof explains why the index jfrom step 3is unique and why it is in fact necessary to include
a slightly larger interval than [ai,j, ai,j+1]in the recursion step, due to Bob potentially having lied if
his midpoint was very close to a boundary of [ai,j, ai,j+1]but on the other side.
Sketch for the lower bound. The lower bound of Ω 
Tα+1
2
relies on the observation that rounds
where Alice cuts near mBand Bob picks his less-preferred piece cost Bob very little but cost Alice a
lot. More precisely, suppose mA< m Band Alice cuts at mB−ε. Then compared to his regret bound,
Bob loses Θ(ε)if he picks the wrong piece. On the other hand, Alice loses Θ(mB−mA) = Θ(1)
compared to her Stackelberg value.
Bob can use this asymmetry by acting as if his midpoint were Θ 
Tα−1
2
closer to mAthan it really
is. Lying Θ 
Tα+1
2
times costs Bob only Θ(Tα)regret, but costs Alice Θ 
Tα+1
2
regret. To avoid
accumulating more regret than this, Bob can afterwards revert to picking his truly preferred piece; the
damage to Alice’s payoff has already been done.
Proposition 3. Letα∈[0,1). Suppose Bob plays a strategy that ensures his regret is O(Tα). Let
Bαdenote the set of all such Bob strategies. If Alice does not know α, she has a strategy SAthat
ensures her Stackelberg regret is O T
logT
.
The exponent is sharp: if SAguarantees Alice Stackelberg regret O(Tβ)against all Bob strategies in
Bαfor some β∈[0,1), then SAhas Stackelberg regret Ω(T)for some Bob strategy in Bβ.
Proof sketch. Alice’s strategy that achieves O(T/logT)regret follows the same template as her
strategy from Proposition 2. The only difference is that she sets ηdifferently (and much larger) to
cover any possible regret bound Bob could have.
The idea of the lower bound is that, if Alice does not know the value of αin Bob’s regret bound, she
cannot know when she has true information about Bob’s preferences. We use this by having a Bob
withO(Tβ)regret behave exactly like one with O(Tα)regret but a different midpoint. Then Bob can
hide his deception from an Alice with O(Tβ)regret since he can tolerate more regret than her.
Theorem 1 is implied by Propositions 2 and 3. The players’ value densities must be bounded for
Theorem 1 to hold; see Remark 1 in Appendix A.2 for a counterexample with unbounded densities.
85 Equitable payoffs
Here we sketch the proofs of Theorems 2 and 3. The formal proofs can be found in Appendix B.
Theorem 2 shows how Alice can get at least 1/2per round while keeping Bob at 1/2per round.
Proof sketch of Theorem 2. Alice’s strategy uses Blackwell approachability (1956). A challenge is
that Blackwell’s original version required the number of player types to be finite, but Alice has to be
prepared for an uncountably infinite variety of Bob’s valuation functions. Another difference is that
Alice’s action space is also infinite, which turns out to be necessary.
We get around the infinite-Bob issue in two steps. First, Alice defines a countably infinite set Vas a
stand-in for the full variety of Bobs; Vincludes arbitrarily good approximations to any valuation.
Second, we replace Blackwell’s original finite-dimensional space with a countably-infinite-
dimensional one, where the elements of Vare the axes. We define an inner product on this space and
adapt Blackwell’s argument for it. Briefly, Alice’s strategy tracks the average payoff to each type of
Bob in Vand defines Sto be the region of the space where all of them have payoffs at most 1/2. In
each round, she constructs a cut point which moves the Bobs’ average payoff closer to S, and in the
limit traps them in S.
Under this strategy, Alice’s payoff guarantee is mostly a byproduct of Bob’s. If Bob and Alice have
the same value density, then their payoffs sum to 1, so bounding Bob’s payoff to 1/2also bounds
Alice’s to 1/2. We achieve the substantially better bound on Alice’s payoff by explicitly including
her value density vAin the set Vof Bobs, thus eliminating any approximation error.
Theorem 3 shows how Bob can do the same, albeit only in expectation in the simultaneous setting.
Proof sketch of Theorem 3. We cover the simultaneous setting first because it informs the sequential
setting. In the simultaneous setting, Bob’s algorithm is extremely simple: in each round, randomly
select LorRwith equal probability. The expected payoffs to each player follow immediately.
Bob’s strategy for the sequential setting can be seen as a derandomized version of the simultaneous
strategy. The simplest way to derandomize it would be to strictly alternate between LandR, but
if Bob runs that strategy Alice can easily exploit it. Instead, Bob mentally partitions the cake into√
Tintervals I1, . . . , I√
Tof equal value to him. He then treats each interval Iias a separate cake,
alternating between LandRfor the rounds Alice cuts in Ii. Alice can still exploit this strategy
on a single interval Ii, but doing so can only give her an average payoff of 1/2 +O(VA(Ii))∈
1/2 +O(1/√
T). The full proof shows this bound applies for any Alice strategy.
6 Fictitious play
In this section we include a proof sketch of Theorem 4, which analyzes the fictitious play dynamic.
The formal proof can be found in Appendix C.
Proof sketch of Theorem 4. To analyze the fictitious play dynamic, we define for each t= 0, . . . , T
two quantities called αtandβt. Letαt=rt−ℓt, where rtis the number of times Bob picked Rup
to round tandℓtis the number of times he picked L. Letβt=Pt
τ=1 
2VB([0, aτ])−1
.
The quantities αtandβtcontrol what happens under fictitious play: Alice’s decision in round t+ 1
is based on αtand Bob’s decision in round t+ 1is based on βt. These decisions in turn affect αt+1
andβt+1, forming a dynamical system that results in a counterclockwise spiral through α-βspace.
Figure 6 illustrates the sequences αtandβtfor the instance in Figure 2.
We define ρt=|αt|+|βt|and formalize this spiral, by showing that the sequence {ρ}T
t=0is
non-decreasing and analyzing the change in (αt, βt)from round to round. Figure 6 illustrates the
parameter ρtover time, while Figure 7 illustrates the spiral (associated with the same trajectory as in
Figure 2 and 6), where the spiral is visualized as a scatter plot of the sequence (αt, βt)t≥1.
We first use these dynamics to bound Bob’s payoff. Bob’s payoff can be almost directly read off due
to changes in βtclosely matching changes in Bob’s payoff. Bob’s total payoff to round tturns out to
be of the order t/2±ρt, so bounding the rate at which the spiral expands also bounds Bob’s payoff.
9(a) The sequence αt.
 (b) The sequence βt.
(c) The sequence ρt.
Figure 6: Illustration of the sequences {αt}∞
t=1,{βt}∞
t=1, and{ρt}∞
t=1for the instance with trajecto-
ries shown in Figure 2. The X axis shows the round number tand the Y axis the variable plotted.
(a) The spiral over the first 100rounds.
 (b) The spiral over the first 1000 rounds.
Figure 7: Scatter plot of the sequence (αt, βt)t≥1, illustrating the spiral for the instance with
trajectories shown in Figure 2, where the sequences αtandβtare illustrated separately in Figure 6.
We then use the dynamics to bound the total payoff to Alice and Bob. Alice can only cut in the
interior of the cake when αt= 0, which happens less and less often as the spiral expands. The
players’ total payoff when Alice cuts at one end of the cake is 1, so across Trounds we show the
sum of cumulative payoffs of the players is of the order T±Θ(√
T). Combining the bound on the
total payoff with the bound on Bob’s payoff gives a bound for Alice’s payoff.
7 Concluding remarks
There are several directions for future work. One direction is to consider a wider class of regret
benchmarks and understand how the choice of benchmark influences the outcomes reached. Moreover,
what payoff profiles are attained when the players use randomized algorithms such as exponential
weights to update their strategies? It would also make sense to consider settings where the cake has
both good and bad parts. Finally, studying richer feedback models, e.g., when Alice and Bob takes
turns cutting and choosing, or allowing Alice to divide the cake into any multiple measurable sets
would be intriguing directions.
10Acknowledgements
We would like to thank the reviewers for useful feedback that helped improve the paper. This
work was supported by US National Science Foundation CAREER grant CCF-2238372, DARPA
QuICC, NSF AF:Small #2218678, NSF AF:Small #2114269, Army-Research Laboratory (ARL)
#W911NF2410052, and MURI on Algorithms, Learning and Game Theory.
References
Jacob Abernethy, Kevin A. Lai, and Andre Wibisono. 2021. Fast Convergence of Fictitious Play for
Diagonal Payoff Matrices . 1387–1404. https://doi.org/10.1137/1.9781611976465.84
arXiv:https://epubs.siam.org/doi/pdf/10.1137/1.9781611976465.84
N. Alon. 1987. Splitting necklaces. Advances in Mathematics 63, 3 (1987), 247–253.
Noga Alon and Andrei Graur. 2020. Efficient Splitting of Measures and Necklaces. https:
//doi.org/10.48550/ARXIV.2006.16613
Georgios Amanatidis, Georgios Birmpas, Aris Filos-Ratsikas, and Alexandros A. V oudouris. 2022.
Fair Division of Indivisible Goods: A Survey. In Proceedings of the Thirty-First International
Joint Conference on Artificial Intelligence, IJCAI 2022, Vienna, Austria, 23-29 July 2022 , Luc De
Raedt (Ed.). ijcai.org, 5385–5393. https://doi.org/10.24963/IJCAI.2022/756
G. Amanatidis, G. Christodoulou, J. Fearnley, E. Markakis, C.-Alexandros Psomas, and E. Vakaliou.
2018. An Improved Envy-Free Cake Cutting Protocol for Four Agents. In Proceedings of the 11th
International Symposium on Algorithmic Game Theory SAGT . 87–99.
Robert Aumann and Michael Maschler. 1995. Repeated Games with Incomplete Information . MIT
Press.
Robert J Aumann. 1961. Mixed and behavior strategies in infinite extensive games . Princeton
University Princeton.
H. Aziz and S. Mackenzie. 2016. A Discrete and Bounded Envy-Free Cake Cutting Protocol for Any
Number of Agents. In FOCS . 416–427.
Maria-Florina Balcan, Avrim Blum, Nika Haghtalab, and Ariel D Procaccia. 2015. Commitment
without regrets: Online learning in stackelberg security games. In Proceedings of the sixteenth
ACM conference on economics and computation . 61–78.
Xiaohui Bei, Xinhang Lu, and Warut Suksompong. 2022. Truthful cake sharing. In Proceedings of
the AAAI Conference on Artificial Intelligence , V ol. 36. 4809–4817.
Gerdus Benadè, Daniel Halpern, and Alexandros Psomas. 2022. Dynamic fair division with partial
information. Advances in neural information processing systems 35 (2022), 3703–3715.
U. Berger. 2005. Fictitious Play in 2xN Games. Journal of Economic Theory 120 (2005), 139–154.
Vittorio Bilò, Ioannis Caragiannis, Michele Flammini, Ayumi Igarashi, Gianpiero Monaco, Dominik
Peters, Cosimo Vinci, and William S. Zwicker. 2019. Almost Envy-Free Allocations with Con-
nected Bundles. In 10th Innovations in Theoretical Computer Science Conference, ITCS 2019,
January 10-12, 2019, San Diego, California, USA (LIPIcs, Vol. 124) , Avrim Blum (Ed.). Schloss
Dagstuhl - Leibniz-Zentrum für Informatik, 14:1–14:21. https://doi.org/10.4230/LIPIcs.
ITCS.2019.14
Georgios Birmpas, Jiarui Gan, Alexandros Hollender, Francisco Marmolejo, Ninad Rajgopal, and
Alexandros V oudouris. 2020. Optimally deceiving a learning leader in stackelberg games. Advances
in Neural Information Processing Systems 33 (2020), 20624–20635.
David Blackwell. 1956. An analog of the minimax theorem for vector payoffs. Pacific J. Math. 6, 1
(1956), 1 – 8.
S. Brams and A. Taylor. 1996. Fair Division: from cake cutting to dispute resolution . Cambridge
University Press.
11F. Brandt, V . Conitzer, U. Endriss, J. Lang, and A. D. Procaccia (Eds.). 2016. Handbook of Computa-
tional Social Choice (1 ed.). Cambridge University Press.
Felix Brandt, Felix Fischer, and Paul Harrenstein. 2013. On the rate of convergence of fictitious play.
Theory of Computing Systems 53 (2013), 41–52.
Simina Brânzei, Ioannis Caragiannis, David Kurokawa, and Ariel D. Procaccia. 2016. An Algorithmic
Framework for Strategic Fair Division. In Proceedings of the Thirtieth AAAI Conference on
Artificial Intelligence, February 12-17, 2016, Phoenix, Arizona, USA , Dale Schuurmans and
Michael P. Wellman (Eds.). AAAI Press, 418–424. http://www.aaai.org/ocs/index.php/
AAAI/AAAI16/paper/view/12294
Simina Brânzei and Peter Bro Miltersen. 2013. Equilibrium analysis in cake cutting.. In AAMAS .
Citeseer, 327–334.
S. Branzei and P. B. Miltersen. 2015. A Dictatorship Theorem for Cake Cutting. In IJCAI . 482–488.
Simina Brânzei and Noam Nisan. 2019. Communication Complexity of Cake Cutting. In Proceedings
of the 2019 ACM Conference on Economics and Computation (EC) . 525.
Simina Brânzei and Noam Nisan. 2022. The Query Complexity of Cake Cutting. In
NeurIPS . 37905–37919. http://papers.nips.cc/paper_files/paper/2022/hash/
f7a7bb369e48f10e85fce85b67d8c516-Abstract-Conference.html
G.W. Brown. 1951. Iterative Solutions of Games by Fictitious Play. Activity Analysis of Production
and Allocation (1951).
Xiaolin Bu, Jiaxin Song, and Biaoshuai Tao. 2023. On existence of truthful fair cake cutting mech-
anisms. Artificial Intelligence 319 (2023), 103904. https://doi.org/10.1016/j.artint.
2023.103904
Bhaskar Ray Chaudhury, Jugal Garg, Peter McGlaughlin, and Ruta Mehta. 2021a. Competitive
allocation of a mixed manna. In Proceedings of the 2021 ACM-SIAM Symposium on Discrete
Algorithms (SODA) . SIAM, 1405–1424.
Bhaskar Ray Chaudhury, Jugal Garg, and Kurt Mehlhorn. 2020. EFX exists for three agents. In
Proceedings of the 21st ACM Conference on Economics and Computation . 1–19.
Bhaskar Ray Chaudhury, Jugal Garg, Kurt Mehlhorn, Ruta Mehta, and Pranabendu Misra. 2021b.
Improving EFX guarantees through rainbow cycle number. In Proceedings of the 22nd ACM
Conference on Economics and Computation . 310–311.
Bhaskar Ray Chaudhury, Telikepalli Kavitha, Kurt Mehlhorn, and Alkmini Sgouritsa. 2021c. A
Little Charity Guarantees Almost Envy-Freeness. SIAM J. Comput. 50, 4 (2021), 1336–1358.
https://doi.org/10.1137/20M1359134
Yiling Chen, John K. Lai, David C. Parkes, and Ariel D. Procaccia. 2013. Truth, justice, and cake
cutting. Games and Economic Behavior 77, 1 (2013), 284–297. https://EconPapers.repec.
org/RePEc:eee:gamebe:v:77:y:2013:i:1:p:284-297
Guillaume Cheze. 2020. Envy-free cake cutting: A polynomial number of queries with high
probability.
Constantinos Daskalakis and Qinxuan Pan. 2014. A Counter-example to Karlin’s Strong Conjecture
for Fictitious Play. In 2014 IEEE 55th Annual Symposium on Foundations of Computer Science .
11–20. https://doi.org/10.1109/FOCS.2014.10
Argyrios Deligkas, Aris Filos-Ratsikas, and Alexandros Hollender. 2021. Two’s Company, Three’s
a Crowd: Consensus-Halving for a Constant Number of Agents. In EC ’21: The 22nd ACM
Conference on Economics and Computation, Budapest, Hungary, July 18-23, 2021 , Péter Biró,
Shuchi Chawla, and Federico Echenique (Eds.). ACM, 347–368. https://doi.org/10.1145/
3465456.3467625
X. Deng, Q. Qi, and A. Saberi. 2012. Algorithmic Solutions for Envy-Free Cake Cutting. Oper. Res
60, 6 (2012), 1461–1476.
12Yuan Deng, Jon Schneider, and Balasubramanian Sivan. 2019. Strategizing against no-regret learners.
Advances in neural information processing systems 32 (2019).
Jinshuo Dong, Aaron Roth, Zachary Schutzman, Bo Waggoner, and Zhiwei Steven Wu. 2018.
Strategic classification from revealed preferences. In Proceedings of the 2018 ACM Conference on
Economics and Computation . 55–70.
Melvin Dresher, Lloyd S Shapley, and Albert William Tucker. 2016. Advances in Game Theory.(AM-
52), Volume 52 . V ol. 52. Princeton University Press.
L. E. Dubins and E. H. Spanier. 1961. How to Cut A Cake Fairly. Am. Math. Mon 68, 1 (1961),
1–17.
J. Edmonds and K. Pruhs. 2006. Cake Cutting Really Is Not a Piece of Cake. In SODA . 271–278.
Francis Edward Su. 1999. Rental harmony: Sperner’s lemma in fair division. The American
mathematical monthly 106, 10 (1999), 930–942.
S. Even and A. Paz. 1984. A note on cake cutting. Discrete Applied Mathematics 7, 3 (1984), 285 –
296.
Aris Filos-Ratsikas, Kristoffer Arnsfelt Hansen, Kasper Hogh, and Alexandros Hollender. 2022.
FIXP-membership via Convex Optimization: Games, Cakes, and Markets. In 2021 IEEE 62nd
Annual Symposium on Foundations of Computer Science (FOCS) . 827–838. https://doi.org/
10.1109/FOCS52979.2021.00085
Aris Filos-Ratsikas, Alexandros Hollender, Katerina Sotiraki, and Manolis Zampetakis. 2020.
Consensus-Halving: Does It Ever Get Easier?. In Proceedings of the 21st ACM Conference
on Economics and Computation (Virtual Event, Hungary) (EC ’20) . Association for Computing
Machinery, New York, NY , USA, 381–399. https://doi.org/10.1145/3391403.3399527
Aris Filos-Ratsikas, Alexandros Hollender, Katerina Sotiraki, and Manolis Zampetakis. 2021. A
topological characterization of modulo-p arguments and implications for necklace splitting. In
Proceedings of the 2021 ACM-SIAM Symposium on Discrete Algorithms (SODA) . SIAM, 2615–
2634.
Eric Friedman, Christos-Alexandros Psomas, and Shai Vardi. 2015. Dynamic fair division with mini-
mal disruptions. In Proceedings of the sixteenth ACM conference on Economics and Computation .
697–713.
Jiarui Gan, Haifeng Xu, Qingyu Guo, Long Tran-Thanh, Zinovi Rabinovich, and Michael Wooldridge.
2019. Imitative follower deception in stackelberg games. In Proceedings of the 2019 ACM
Conference on Economics and Computation . 639–657.
Ali Ghodsi, Matei Zaharia, Benjamin Hindman, Andy Konwinski, Scott Shenker, and Ion Stoica.
2011. Dominant resource fairness: Fair allocation of multiple resource types. In 8th USENIX
symposium on networked systems design and implementation (NSDI 11) .
Paul Goldberg, Alexandros Hollender, and Warut Suksompong. 2020a. Contiguous Cake Cutting:
Hardness Results and Approximation Algorithms. J. Artif. Intell. Res. 69 (2020), 109–141.
https://doi.org/10.1613/jair.1.12222
Paul W. Goldberg, Alexandros Hollender, Ayumi Igarashi, Pasin Manurangsi, and Warut Suksompong.
2020b. Consensus Halving for Sets of Items. In Web and Internet Economics - 16th International
Conference, WINE 2020, Beijing, China, December 7-11, 2020, Proceedings (Lecture Notes in
Computer Science, Vol. 12495) , Xujin Chen, Nikolai Gravin, Martin Hoefer, and Ruta Mehta
(Eds.). Springer, 384–397. https://doi.org/10.1007/978-3-030-64946-3_27
Paul W. Goldberg and Ioana Iaru. 2021. Equivalence of Models of Cake-Cutting Protocols. https:
//doi.org/10.48550/ARXIV.2108.03641
J. Goldman and A. D. Procaccia. 2014. Spliddit: Unleashing fair division algorithms. ACM SIG.
Exch 13, 2 (2014), 41–46.
13Nika Haghtalab, Thodoris Lykouris, Sloan Nietert, and Alexander Wei. 2022. Learning in stackelberg
games with non-myopic agents. In Proceedings of the 23rd ACM Conference on Economics and
Computation . 917–918.
MohammadTaghi Hajiaghayi, Mohammad Mahdavi, Keivan Rezaei, and Suho Shin. 2023. Regret
Analysis of Repeated Delegated Choice. arXiv preprint arXiv:2310.04884 (2023).
Christopher Harris. 1998. On the Rate of Convergence of Continuous-Time Fictitious Play. Games and
Economic Behavior 22, 2 (1998), 238–259. https://doi.org/10.1006/game.1997.0582
Kirthevasan Kandasamy, Gur-Eyal Sela, Joseph E Gonzalez, Michael I Jordan, and Ion Stoica. 2020.
Online Learning Demands in Max-min Fairness. arXiv:2012.08648 [stat.ML]
Samuel Karlin. 1959. Mathematical Methods and Theoryin Games, Programming, and Economics .
Addison Wesley.
Ian Kash, Ariel D Procaccia, and Nisarg Shah. 2014. No agent left behind: Dynamic fair division of
multiple resources. Journal of Artificial Intelligence Research 51 (2014), 579–603.
Robert Kleinberg and Tom Leighton. 2003. The value of knowing a demand curve: Bounds on regret
for online posted-price auctions. In 44th Annual IEEE Symposium on Foundations of Computer
Science, 2003. Proceedings. IEEE, 594–605.
Harold W Kuhn. 1950. Extensive games. Proceedings of the National Academy of Sciences 36, 10
(1950), 570–576.
HW Kuhn1. 1953. Extensive games and the problem of information. Contributions to the Theory of
Games 24 (1953), 193.
Rucha Kulkarni, Ruta Mehta, and Setareh Taki. 2021. Indivisible mixed manna: On the computability
of MMS+ PO allocations. In Proceedings of the 22nd ACM Conference on Economics and
Computation . 683–684.
Pasin Manurangsi and Warut Suksompong. 2021. Closing Gaps in Asymptotic Fair Division.
SIAM Journal on Discrete Mathematics 35, 2 (2021), 668–706. https://doi.org/10.1137/
20M1353381 arXiv:https://doi.org/10.1137/20M1353381
D. Monderer and L.S. Shapley. 1996a. Fictitious Play Property for Games with Identical Interests.
Journal of Economic Theory 68 (1996), 258–265.
D. Monderer and L.S. Shapley. 1996b. Potential Games. Games and Economic Behavior 14 (1996),
124–143.
Elchanan Mossel and Omer Tamuz. 2010. Truthful Fair Division. In Algorithmic Game Theory ,
Spyros Kontogiannis, Elias Koutsoupias, and Paul G. Spirakis (Eds.). Springer Berlin Heidelberg,
Berlin, Heidelberg, 288–299.
H. Moulin. 2003. Fair Division and Collective Welfare . The MIT Press.
J. Nachbar. 1990. Evolutionary Selection Dynamics in Games: Convergence and Limit Properties.
International Journal of Game Theory 19 (1990), 59–89.
Antonio Nicolò and Yan Yu. 2008. Strategic divide and choose. Games and Economic Behavior 64,
1 (2008), 268–289. https://doi.org/10.1016/j.geb.2008.01.006
Hoon Oh, Ariel D. Procaccia, and Warut Suksompong. 2021. Fairly Allocating Many Goods
with Few Queries. SIAM Journal on Discrete Mathematics 35, 2 (2021), 788–813. https:
//doi.org/10.1137/20M1313349 arXiv:https://doi.org/10.1137/20M1313349
Ioannis Panageas, Nikolas Patris, Stratis Skoulakis, and V olkan Cevher. 2023. Exponential Lower
Bounds for Fictitious Play in Potential Games. arXiv:2310.02387 [cs.GT]
S. Perkins and D.S. Leslie. 2014. Stochastic fictitious play with continuous action sets. Journal of
Economic Theory 152 (2014), 179–213. https://doi.org/10.1016/j.jet.2014.04.008
14Benjamin Plaut and Tim Roughgarden. 2019. Communication Complexity of Discrete Fair Division.
InProceedings of the Thirtieth Annual ACM-SIAM Symposium on Discrete Algorithms, SODA
2019, San Diego, California, USA, January 6-9, 2019 , Timothy M. Chan (Ed.). SIAM, 2014–2033.
https://doi.org/10.1137/1.9781611975482.122
Benjamin Plaut and Tim Roughgarden. 2020. Almost envy-freeness with general valuations. SIAM
Journal on Discrete Mathematics 34, 2 (2020), 1039–1068.
A. D. Procaccia. 2009. Thou Shalt Covet Thy Neighbor’s Cake. In IJCAI . 239–244.
A. D. Procaccia. 2013. Cake Cutting: Not Just Child’s Play. Commun. ACM 56, 7 (2013), 78–87.
Ariel D. Procaccia. 2020. Technical perspective: An answer to fair division’s most enigmatic question.
Commun. ACM 63, 4 (mar 2020), 118. https://doi.org/10.1145/3382131
Ariel D Procaccia and Junxing Wang. 2014. Fair enough: Guaranteeing approximate maximin shares.
InProceedings of the fifteenth ACM conference on Economics and computation . 675–692.
J. M. Robertson and W. A. Webb. 1998. Cake Cutting Algorithms: Be Fair If You Can . A. K. Peters.
J. Robinson. 1951. An Iterative Method of Solving a Game. Annals of Mathematics 54 (1951),
296–301.
Erel Segal-Halevi. 2018. Cake-Cutting with Different Entitlements: How Many Cuts are Needed?
CoRR abs/1803.05470 (2018). arXiv:1803.05470 http://arxiv.org/abs/1803.05470
Heinrich von Stackelberg. 1934. Marktform und gleichgewicht. (No Title) (1934).
H. Steinhaus. 1948. The Problem of Fair Division. Econometrica 16 (1948), 101–104.
W. Stromquist. 1980. How to cut a cake fairly. Am. Math. Mon 8 (1980), 640–644. Addendum, vol.
88, no. 8 (1981). 613-614.
W. Stromquist. 2008. Envy-free cake divisions cannot be found by finite protocols. Electron. J.
Combin. 15 (2008).
Milind Tambe. 2011. Security and game theory: algorithms, deployed systems, lessons learned .
Cambridge university press.
Omer Tamuz, Shai Vardi, and Juba Ziani. 2018. Non-Exploitable Protocols for Repeated Cake Cutting.
InProceedings of the Thirty-Second AAAI Conference on Artificial Intelligence, (AAAI-18), the
30th innovative Applications of Artificial Intelligence (IAAI-18), and the 8th AAAI Symposium
on Educational Advances in Artificial Intelligence (EAAI-18), New Orleans, Louisiana, USA,
February 2-7, 2018 , Sheila A. McIlraith and Kilian Q. Weinberger (Eds.). AAAI Press, 1226–1233.
https://doi.org/10.1609/AAAI.V32I1.11472
Pingzhong Tang and Tuomas Sandholm. 2012. Optimal Auctions for Spiteful Bidders. In Proceedings
of the Twenty-Sixth AAAI Conference on Artificial Intelligence, July 22-26, 2012, Toronto, Ontario,
Canada , Jörg Hoffmann and Bart Selman (Eds.). AAAI Press, 1457–1463. https://doi.org/
10.1609/AAAI.V26I1.8235
Biaoshuai Tao. 2022. On Existence of Truthful Fair Cake Cutting Mechanisms. In Proceedings
of the 23rd ACM Conference on Economics and Computation (Boulder, CO, USA) (EC ’22) .
Association for Computing Machinery, New York, NY , USA, 404–434. https://doi.org/10.
1145/3490486.3538321
Jamie Tucker-Foltz and Richard J. Zeckhauser. 2023. Playing Divide-and-Choose Given Uncertain
Preferences. In Proceedings of the 24th ACM Conference on Economics and Computation (London,
United Kingdom) (EC ’23) . Association for Computing Machinery, New York, NY , USA, 1127.
https://doi.org/10.1145/3580507.3597811
Toby Walsh. 2011. Online cake cutting. In Algorithmic Decision Theory: Second International
Conference, ADT 2011, Piscataway, NJ, USA, October 26-28, 2011. Proceedings 2 . Springer,
292–305.
15Gerhard J Woeginger and Ji ˇrí Sgall. 2007. On the complexity of cake cutting. Discrete Optimization
4, 2 (2007), 213–220.
Geng Zhao, Banghua Zhu, Jiantao Jiao, and Michael Jordan. 2023. Online learning in stackelberg
games with an omniscient follower. In International Conference on Machine Learning . PMLR,
42304–42316.
16A Appendix: Alice exploiting Bob
In this section we present the proofs for Proposition 1, showing how Alice can exploit a myopic Bob
that chooses his favorite piece in each round, and for Theorem 1, where Bob is nearly myopic.
Before giving the proofs, we formally define what we mean for Alice or Bob to ensure themselves a
certain amount of regret.
Definition 3 (Ensuring Alice’s regret) .Suppose Bob plays a strategy SB. A mixed strategy SA
for Alice ensures her Stackelberg regret is at most γagainst SBifRegA(H)≤γfor all T-round
histories Hthat could have arisen under the strategy pair (SA, SB).
If instead Alice only knows that Bob plays some strategy from a set Bof strategies, then a mixed
strategy SAfor Alice ensures her Stackelberg regret is at most γif it ensures her Stackelberg regret is
at most γagainst all SB∈ B.
Definition 4 (Ensuring Bob’s regret) .Suppose Alice plays a strategy SA. A mixed strategy SBfor
Bob ensures his regret is at most γagainst SAifRegB(H)≤γfor all T-round histories Hthat
could have arisen under the strategy pair (SA, SB).
In general, a mixed strategy SBfor Bob ensures his regret is at most γif it ensures his regret is at
mostγagainst all Alice strategies.
A.1 Appendix: Exploiting a Myopic Bob
Restatement of Proposition 1. If Bob plays myopically in the sequential setting, then Alice has a
strategy that ensures her Stackelberg regret is O(logT).
Proof. We consider an explore-then-commit type of algorithm for Alice. In the exploration phase,
Alice does binary search to find Bob’s midpoint (within accuracy of 1/T). In the commitment
(exploitation) phase, Alice repeatedly cuts at Bob’s approximate midpoint. This leads to Alice getting
nearly her Stackelberg value in nearly every round. Figure 8 shows a visualization of a cake instance
with Alice and Bob’s midpoints, respectively, with Alice’s search process.
Figure 8: Alice’s algorithm against myopic Bob in the exploration phase. Alice’s density is shown
with blue and her midpoint is mA, while Bob’s density is shown with red and his midpoint is mB.
The algorithm initialized ℓ1= 0andr1= 1and then re-computes them iteratively depending on
Bob’s answers. The constructed interval [ℓt, rt]shrinks exponentially and becomes closer to mBas
the time tincreases.
Alice’s algorithm is described precisely in Figure 9.
17Alice’s algorithm when Bob is myopic:
Initialization Setℓ1= 0, r1= 1andτ= ln( T).
Exploration Fort= 1,2, . . . , τ :
•Cut at a point xt∈[ℓt, rt]such that VA([ℓt, xt]) = VA([xt, rt]). Then observe
Bob’s action bt.
• Ifbt=L, then set (ℓt+1, rt+1) = (ℓt, xt).
• Else if bt=R, then set (ℓt+1, rt+1) = (xt, rt).
Exploitation Fort=τ+ 1, . . . , T :
• IfmA≤ℓτ, then cut at ℓτ−1/T.
• IfmA≥rτ, then cut at rτ+ 1/T.
Figure 9: Algorithm A.1
We show that Algorithm A.1 in Figure 9 with τ= Θ(ln T)gives the desired regret bound in several
steps.
Bob’s midpoint lies in the interval [rt, ℓt]for all tTo this end, we first claim that Bob’s midpoint
lies in [ℓt, rt]at each round t. We proceed by induction on t. The base case is t= 1clearly holds since
ℓ1= 0andr1= 1, somB∈[ℓ1, r1]. Suppose that mB∈[ℓt, rt]for some t≥1. Given that Alice
cuts at xt∈(ℓt, rt), ifbt=L, this implies that mB∈[ℓt, xt]. Hence mB∈[ℓt, xt] = [ℓt+1, rt+1].
This argument also holds when Bob chooses R. Thus by induction, we conclude that mB∈[ℓt, rt]
for every t∈[T].
Alice’s midpoint satisfies mA/∈(ℓt, rt)for every t≥2Now, during the execution of the
algorithm, we will next show that Alice’s midpoint mAsatisfies either of mA≤ℓtandmA≥rt,
i.e.,mA/∈(ℓt, rt)for every t≥2. To see this, recall that in the first round, Alice cuts x1=mA. If
b1=L, then ℓ2= 0andr2=mA. In this case, [ℓ2, r2] = [0 , mA], somA/∈(ℓ2, r2). Afterwards, it
still holds since the intervals only shrink, i.e.,(ℓt+1, rt+1)⊂(ℓt, rt). Similarly, consider the case
thatb1=R. Then, we have ℓ2=mAandr2= 1. Thus [ℓ2, r2] = [mA,1], which implies that
mA/∈(ℓ2, r2). Again since the intervals (ℓt, rt)only shrink, we conclude that mA/∈(ℓt, rt)for
every t≥2.
Interval exponentially shrinks We have VA([ℓt, rt]) =VA([ℓt−1, rt−1])/2for every t∈[T], as
we shrink the interval by cutting a point that equalizes Alice’s value for both parts within the interval.
This implies that VA([ℓτ, rτ]) = 2−τ+1.
Bounding exploitation phase regret In the exploitation phase, due to the observation above, we
have two cases: (i) mA≤ℓτand (ii) mA≥rτ. We will prove that in either case, Alice’s single-round
regret in the exploitation phase is at most 2−τ+1+ ∆/T.
•For the first case of mA≤ℓτ, Alice keeps cutting at ℓτ−1/Tfor the rest of rounds as
per the algorithm’s description. Then, Bob will myopically choose Rand Alice will obtain
VA([0, ℓτ−1/T]). In this case, we have that mA≤mBsince mB∈[ℓτ, rτ]. Then, Alice’s
single-round regret in the exploitation phase is bounded by
VA([0, mB])−VA([0, ℓτ−1/T]) =VA([ℓτ, mB]) +VA([ℓτ−1/T, ℓ τ])
≤VA([ℓτ, rτ]) +∆
T
= 2−τ+1+∆
T.
•Otherwise suppose mA≥rτ. According to the algorithm, Alice keeps cutting rτ+ 1/T
for all the rest of the rounds, and Bob will respond with L. In this case we have mA≥mB
18since mB∈[ℓτ, rτ]. Similarly, Alice’s single-round regret can be upper-bounded by
VA([mB,1])−VA([rτ+ 1/T,1]) = VA([mB, rτ]) +VA([rτ, rτ+ 1/T])
≤VA([ℓτ, rτ]) +∆
T
= 2−τ+1+∆
T.
Hence in both cases, Alice’s single-round regret in the exploitation phase is at most 2−τ+1+ ∆/T.
Final regret bound Overall, by simply upper-bounding Alice’s single-round regret in the explo-
ration phase by 1, we obtain the following upper bound for the total regret:
τ·1 + (T−τ)·
2−τ+1+∆
T
.
Plugging τ= ln( T), we obtain the regret bound of O(lnT), which completes the proof.3
A.2 Appendix: Exploiting a Nearly Myopic Bob
In this section we prove Theorem 1, which explains the payoffs achievable by Alice when Bob has a
strategy with sub-linear regret. We restate it here for reference.
Restatement of Theorem 1 (Exploiting a nearly myopic Bob) .Letα∈[0,1). Suppose Bob plays a
strategy that ensures his regret is O(Tα). LetBαdenote the set of all such Bob strategies.
•If Alice knows α, she has a strategy SA=SA(α)that ensures her Stackelberg regret is
O 
Tα+1
2logT
. The exponent is sharp: Alice’s Stackelberg regret is Ω 
Tα+1
2
for some Bob
strategy in Bα.
•If Alice does not know α, she has a strategy SAthat ensures her Stackelberg regret is O T
logT
.
The exponent is sharp: if SAguarantees Alice Stackelberg regret O(Tβ)against all Bob strategies
inBαfor some β∈[0,1), then SAhas Stackelberg regret Ω(T)for some Bob strategy in Bβ.
Proof of Theorem 1. The known- αupper bound of O 
Tα+1
2logT
follows from invoking Proposi-
tion 4 with f(T) =Tα. The Ω 
Tα+1
2
lower bound is Proposition 5.
The lower bound for the case where αis unknown follows from Lemma 3. The upper bound follows
from invoking Proposition 4 with f(T) =T
(logT)4.
Both upper bounds follow the same template, which is captured by the following proposition.
Proposition 4. Suppose Bob’s strategy has regret O(f(T)), forf(T)∈o T
(logT)2
andf(T)≥1. If
Alice knows f, then she has a strategy that guarantees her Stackelberg regret is O(p
T·f(T) logT).
In particular, if
•Bob’s strategy has regret at most rf(T), for some r >0; and
•Tis large enough so that T >exp 4r∆
δ
andf(T)<T
(lnT)2;
then Alice’s payoff satisfies:
uA≥T·u∗
A−5
ln 2+ 6p
f(T)·TlnT .
Before proving the proposition, we present the algorithm that Alice will run to beat a Bob with a
regret guarantee of O(f(T)).
3We do not optimize over τ.
19Alice’s strategy when Bob’s regret is at most r·f(T), for some constant r >0:
Informational assumption: Alice needs to know fandT, but not r.
Initialization Define
x0= 0; y0= 1; η=⌈p
f(T)·T⌉;n=⌊−log2 
3p
f(T)/TlnT
⌋.
Exploration Fori= 0,1, . . . , n −1:
•Step 1: Setai,0=xiandai,6=yi. For j∈[5], letai,jbe the point with
VA([xi, ai,j]) =j
6VA([xi, yi]).
•Step 2: Forj∈[5]:
–Cut at ai,jforηrounds. Define ci,j=Lif the majority of Bob’s answers were
left when the cut point was ai,j, and ci,j=Rotherwise.
•Step 3:
(3.a): Ifci,j=L∀j∈[5], then set xi+1=xiandyi+1=ai,3.
(3.b): Ifci,j=R∀j∈[5], then set xi+1=ai,3andyi+1=yi.
(3.c): Else, there exists a unique k∈[4]such that ci,j=Rfor all j≤kand
ci,j=Lfor all j > k . Setxi+1=ai,k−1andyi+1=ai,k+2.
Exploitation For the rest of the rounds, Alice cuts at χbased on the following cases:
χ=

xnmA< xn
ynmA> yn
mAmA∈[xn, yn].
Figure 10: Algorithm A.2
Proof of Proposition 4. Overall, Alice will use an explore-then-commit style of algorithm:
•In the exploration phase, Alice conducts a variant of binary search to locate Bob’s midpoint
mBwithin an accuracy of O p
f(T)/TlogT
.
• In the exploitation phase, Alice cuts near the estimated midpoint for the rest of the rounds.
The main difficulty that Alice encounters is to precisely locate Bob’s midpoint in the exploration
phase, since Bob can fool Alice if she cuts sufficiently close to his midpoint. We overcome this
challenge by having Alice’s algorithm stay far enough from mBso that Bob is forced to answer
truthfully most of the time.
Notation. Letw=p
f(T)/TlnT. Then n=⌊−log2(3w)⌋. Since f(T)<T
(lnT)2by the
assumption in the proposition statement, we have w < 1and thereby n≥0. Also recall the
proposition statement assumes that Bob’s strategy guarantees him a regret of at most rf(T)for some
r >0. Moreover, Twas chosen such that T >exp 4r∆
δ
.
Consider the Alice strategy described in Algorithm A.2 (Fig. 10). By Lemma 1, the exploration
phase in Alice’s strategy is well-defined.
Next we derive some useful observations and then combine them to upper-bound Alice’s regret.
Useful observations. By Lemma 2, we have mB∈[xn, yn]. Consider the cut point χin the
exploitation phase. We write INTV[x, y]to denote the interval [x, y]ify≥xand[y, x]ifx > y .
20Then, we obtain
VA(INTV[χ, m B])≤VA([xn, yn]) (By definition of χ)
= 2−n(By property 2 of Lemma 2)
≤2log2(3w)+1(Plugging in nand using −⌊−x⌋ ≤x+ 1)
= 6r
f(T)
TlnT, (1)
where the last identity in (1) holds by definition of w.
To upper-bound the number of times that Bob chooses the piece he likes less in the exploitation phase,
we consider the following three cases with respect to χ:
(a)Ifχ=xnthenmA< xn. Thus xn̸= 0, soVB([χ, m B])> rp
f(T)/Tby Lemma 2. Since
Bob’s regret is at most rf(T), it follows that Bob takes the wrong piece at most1
2p
f(T)·T
times.
(b)Ifχ=ynthenmA> yn. Thus yn̸= 1, soVB([mB, χ])> rp
f(T)/Tby Lemma 2. Since
Bob’s regret is at most rf(T), it follows that Bob takes the wrong piece at most1
2p
f(T)·T
times.
(c)Ifχ=mA, then there is no wrong piece because Alice values both equally. Thus this case does
not increase the count of incorrect decisions.
Putting it all together. In the exploration phase, Alice accumulates regret at most n·5lp
f(T)·Tm
,
since that is the length of the exploration phase. In the exploitation phase, the regret comes from two
sources:
• The gap between χandmB, which is bounded in equation (1).
•The rounds in the exploitation phase in which Bob chooses his least favorite piece. There
are at most1
2p
f(T)·Tsuch rounds by cases (a-c). Thus Alice’s cumulative regret due to
these rounds is also at most1
2p
f(T)·T.
Then Alice’s overall regret is at most:
n·5lp
f(T)·Tm
+T·6p
f(T)/TlnT+1
2p
f(T)·T
≤n·10p
f(T)·T+T·6p
f(T)/TlnT+1
2p
f(T)·T
(Since ⌈x⌉ ≤2x∀x≥1)
≤5
ln 2+ 6p
f(T)·TlnT, (Plugging in nand rearranging)
which is Op
f(T)·TlnT
. This completes the proof.
The following lemma shows that the exploration phase is well-defined.
Lemma 1. Alice’s strategy from Algorithm A.2 (Fig. 10) has the following properties:
(i)If step (3.c)is executed in Alice’s exploration phase, then there is a unique index k∈[4]such
thatci,j=R∀j≤kandci,j=L∀j > k .
(ii)For each j∈[5], define ˜ci,j=Lif Bob prefers [0, ai,j]to[ai,j,1]and˜ci,j=Rotherwise. If
there exists j∈[5]such that ˜ci,j̸=ci,j, then mB∈(ai,j−1, ai,j+1).
(iii)For all i∈ {0, . . . , n −1}andj∈ {0,1, . . . , 5}, we have VB([ai,j, ai,j+1])>2rp
f(T)/T.
Proof. We prove each of the parts (i−iii)required by the lemma.
21Proof of part (iii).Letj∈ {0, . . . , 5}. Bob’s valuation for the interval [ai,j, ai,j+1]can be lower
bounded as follows:
VB([ai,j, ai,j+1])≥δ·(ai,j+1−ai,j) (Since vB(x)≥δ∀x∈[0,1])
≥δ
∆VA([ai,j, ai,j+1]) (Since vA(x)≤∆∀x∈[0,1])
=δ
∆·1
6VA([xi, yi]). (2)
By definition, Alice’s strategy halves the cake interval considered with each iteration
i∈ {0, . . . , n −1}, that is: VA([xi, yi]) = 1 /2·VA([xi−1, yi−1]). Thus VA([xi, yi]) = 2−iand
2−i≥2−nfor all i∈ {0, . . . , n }. Combining these observations with inequality (2), we obtain
VB([ai,j, ai,j+1])≥2·δ
12∆2−n. (3)
Letw=p
f(T)/TlnT. Then n=⌊−log2(3w)⌋. We have
δ
12∆2−n=δ
12∆2−⌊− log2(3w)⌋(By definition of n)
≥δ
12∆2log2(3w)(Since −⌊−x⌋ ≥x)
>δ
4∆·r
f(T)
T·4r∆
δ(By definition of wand since T >exp 4r∆
δ
)
=rp
f(T)/T . (4)
Combining inequalities (3) and (4), we conclude that
VB([ai,j, ai,j+1])>2rr
f(T)
T. (5)
This concludes the proof of part (iii).
Proof of parts (i)and(ii).For each i= 0, . . . , n −1, we will show that at most one of the
majority answers ci,j, forj∈[5], is different from Bob’s truthful response.
To be precise, recall from the lemma statement that ˜ci,j∈ {L, R}is Bob’s truthful response that
maximizes his value when Alice cut at ai,j.
Define
Si=n
j∈[5] :ci,j̸= ˜ci,jo
. (6)
LetINTV[x, y]denote the interval [x, y]ify≥xand[y, x]ifx > y . Ifj∈Si, it must be the case
that Bob picked the wrong piece in at least1
2p
f(T)·Trounds in which the cut was ai,j. Then Bob
accumulated at least VB(INTV[mB, ai,j])regret in each such round. Let ℓ∈[4]. We have
1
2p
f(T)·TX
j∈SiVB(INTV[mB, ai,j])≤r·f(T)(Since Bob’s total regret is at most r·f(T))
<1
2VB([ai,ℓ, ai,ℓ+1])p
f(T)·T . (By (5))
Dividing both sides by1
2p
f(T)·Tgives:
X
j∈SiVB(INTV[mB, ai,j])< VB([ai,ℓ, ai,ℓ+1])∀ℓ∈[4]. (7)
We show that |Si| ≤1. Suppose towards a contradiction that |Si|>1, meaning there exist indices
j, ℓ∈Siwithj̸=ℓ. Then
INTV[ai,j, ai,ℓ]⊆(INTV[mB, ai,j]∪INTV[mB, ai,ℓ]).
22This implies that
VB(INTV[ai,j, ai,ℓ])≤VB(INTV[mB, ai,j]) +VB(INTV[mB, ai,ℓ])≤X
j∈SiVB(INTV[mB, ai,j]),
(8)
which contradicts (7). Thus the assumption was false and |Si| ≤1.
For any j∈Si, we must have either mB∈(ai,j−1, ai,j]ormB∈[ai,j, ai,j+1), as otherwise (7)
would be violated. Therefore, if ˜ci,j̸=ci,jfor some j∈[5], then mB∈(ai,j−1, ai,j+1). This is
part(ii)required by the lemma.
Finally, we prove part (i). We will show there exists a unique k∈[4]such that ci,j=R∀j≤kand
ci,j=L∀j > k . The proof considers two cases:
•Case|Si|= 0. Then every ci,jtruthfully reflects Bob’s preferences: ci,j=Rifai,j< m B,
andci,j=Lifai,j> m B;ci,j∈ {L, R}ifai,j=mB. An illustration can be seen in
Figure 11. In all cases, there is a single switch from RtoL, and so the index kis unique.
(a)
 (b)
Figure 11: Illustration of Alice’s initial cuts for i= 0. In this example, she cuts 3times at each of
the points a0,jand observes Bob’s choices, which are marked with L/Rnear each such cut point.
By default, Alice knows what the answer would be if she cut at 0or1, so those are set to RandL,
respectively. In Figure (a), the truthful answers (reflecting Bob’s favorite piece according to his actual
valuation) are marked with green, while the lying answers are marked with orange. The majority
answer at each cut point a0,j, denoted c0,j, is illustrated in Figure (b). In this example, the majority
answer at each cut point is consistent with Bob’s true preference.
•Case|Si|= 1. Then all but one of the ci,j’s truthfully reflect Bob’s preferences. An
illustration can be seen in Figure 12.
(a)
 (b)
Figure 12: Illustration of Alice’s initial cuts for i= 0. In this example, she cuts 3times at each of
the points a0,jand observes Bob’s choices, which are marked with L/Rnear each such cut point.
By default, Alice knows what the answer would be if she cut at 0or1, so those are set to RandL,
respectively. In Figure (a), the truthful answers (reflecting Bob’s favorite piece according to his actual
valuation) are marked with green, while the lying answers are marked with orange. The majority
answer at each cut point a0,j, denoted c0,j, is illustrated in Figure (b). In this example, the majority
answer at each cut point is consistent with Bob’s true preference except for cut point a0,4where Bob
lied every time and so the majority is incorrect as well.
By part (ii)of the lemma, the only exception occurs at an index jwith the property
mB∈(ai,j−1, ai,j+1). But then ci,ℓ= ˜ci,ℓ=Rforℓ≤j−1andci,ℓ= ˜ci,ℓ=Lfor
ℓ≥j+ 1, so regardless of ci,jthere will be a single switch from RtoL.
This concludes that the conditions for ci,jin Step 3.c hold if the conditions in steps 3.a and 3.b do
not. This concludes the proof of part (i).
23The following lemma further reveals several properties of the constructed intervals during the
execution of the algorithm.
Lemma 2. In the exploration phase of Algorithm A.2 (Fig. 10), Alice constructs a sequence of
intervals
[x0, y0],[x1, y1], . . . , [xn, yn]
such that the following properties hold:
• Property 1: x0= 0andy0= 1,
• Property 2: VA([xi+1, yi+1]) =1
2VA([xi, yi])fori= 0, . . . , n −1,
• Property 3: mB∈[xi, yi], for all i,
• Property 4: Ifxi̸= 0, then VB([xi, mB])> rp
f(T)/T.
• Property 5: Ifyi̸= 1, then VB([mB, yi])> rp
f(T)/T.
Proof. Property 1holds since [x0, y0] = [0 ,1]by definition of the algorithm.
Property 2 follows from our choice of xi+1andyi+1always ensuring that [xi+1, yi+1]contains 3of
the6intervals of equal value the ai,jdivide [xi, yi]into.
We will show Properties 3-5 by induction. The base case is i= 0. Then [x0, y0] = [0 ,1]. Properties
3-5 are vacuously true for this interval.
Assume that Properties 3-5 hold for i∈ {0,1, . . . , n −1}. For each j∈[5], let˜ci,jrepresent Bob’s
truthful answer when the cut point is ai,j. Formally, we have ˜ci,j=Lif Bob prefers [0, ai,j]to
[ai,j,1]and˜ci,j=Rotherwise.
We show Properties 3-5 also hold for i+ 1by considering the next three cases:
Case ci,j=Lfor all j.In this case, the majority of Bob’s answers is Lat each cut point used by
Alice. An illustration can be seen in Figure 13.
(a)
 (b)
Figure 13: Illustration of Alice’s initial cuts for i= 0. At each cut point a0,j, the majority of Bob’s
answers is L(i.e.c0,j=L). Then the algorithm recurses in the interval [0, a0,3].
Then the algorithm recurses in the interval [xi+1, yi+1]given by xi+1=xiandyi+1=ai,3.
By Lemma 1, we have ˜ci,j=ci,jfor each of j∈ {2,3,4,5}, as otherwise Bob’s “true"
preferences would alternate between RandLmore than once.
We claim that mB∈[xi, ai,2). To see this, consider two cases:
•Case ˜ci,1=ci,1: then mB∈[xi, ai,1]since the majority answers are consistent with
Bob’s true preference.
•Case ˜ci,1̸=ci,1: then mB∈(xi, ai,2)by Lemma 1.
Then mB∈[xi, ai,2)⊂[xi+1, yi+1], which proves Property 3 for i+ 1.
Ifxi+1= 0, then Property 4 vacuously follows. Otherwise, we have xi+1=xi. Then by
the inductive hypothesis we obtain VB([xi+1, mB]) =VB([xi, mB])> rp
f(T)/T. Thus
Property 4 holds for i+ 1as well.
24Since mB∈[xi, ai,2), we have
VB([mB, yi+1])≥VB([ai,2, ai,3])>2rp
f(T)/T,
and so Property 5 holds for i+ 1.
Case ci,j=Rfor all j.In this case, the majority of Bob’s answers is Rat each cut point used by
Alice. An illustration can be seen in Figure 14.
(a)
 (b)
Figure 14: Illustration of Alice’s initial cuts for i= 0. At each cut point a0,j, the majority of Bob’s
answers is R(i.e.c0,j=R). Then the algorithm recurses in the interval [a0,3,1].
Then the algorithm recurses in the interval [xi+1, yi+1]given by xi+1=ai,3andyi+1=yi.
By Lemma 1, we have ˜ci,j=ci,jfor each of j∈ {1,2,3,4}.
We claim that mB∈(ai,4, yi]. To see this, consider two cases:
•Case ˜ci,5=ci,5: then mB∈[ai,5, yi]since the majority answers are consistent with
Bob’s true preference.
•Case ˜ci,5̸=ci,5: then mB∈(ai,4, yi)by Lemma 1.
Then mB∈(ai,4, yi]⊂[xi+1, yi+1], which proves Property 3 for i+ 1.
Since mB∈(ai,4, yi], we have
VB([xi+1, mB])≥VB([ai,3, ai,4])>2rp
f(T)/T,
and so Property 4 holds for i+ 1.
Ifyi+1= 1, then Property 5 vacuously follows. Otherwise, we have yi+1=yi. Then by
the inductive hypothesis we obtain VB([mB, yi+1]) =VB([mB, yi])> rp
f(T)/T. Thus
Property 5 holds for i+ 1as well.
Case where there is a transition from RtoLand the last Risci,kfor some k∈ {1, . . . , 4}.An
illustration can be seen in Figure 15.
(a)
 (b)
Figure 15: Illustration of Alice’s initial cuts for i= 0. In this example, there is a transition from
RtoLin the interval [a0,2, a0,3]. Then the algorithm recurses in the interval [a0,1, a0,4], which is
guaranteed to contain Bob’s midpoint.
In this case, Alice recurses on the interval [xi+1, yi+1]given by
xi+1=ai,k−1andyi+1=ai,k+2.
If any of the ci,jdiffer from the ˜ci,j, it must be ci,korci,k+1because otherwise Bob’s true
preferences would alternate between RandLmore than once, which is impossible. We
consider three sub-cases:
251.Case ˜ci,k̸=ci,k.Each time Bob picked his less-preferred piece when Alice cut at
ai,k, he lost 2VB(INTV[ai,k, mB])in value compared to his regret benchmark. Since
˜ci,k̸=ci,k, he did so at least1
2p
f(T)·Ttimes. In order to have regret at most rf(T),
he must have
VB(INTV[ai,k, mB])≤rr
f(T)
T. (9)
By Lemma 1, we have
mB∈(ai,k−1, ai,k+1) (10)
and
VB([ai,k−1, ai,k])>2rr
f(T)
T. (11)
Combining equations (9), (10), and (11) we obtain
VB([xi+1, mB]) =VB([ai,k−1, mB]) (Since xi+1=ai,k−1)
≥VB([ai,k−1, ai,k])−VB(INTV[ai,k, mB])
(Since mB> ai,k−1by (10))
> rp
f(T)/T . (By (9) and (11))
Thus VB([xi+1, mB])> rp
f(T)/T, so Property 4 holds for i+ 1.
Since mB∈(ai,k−1, ai,k+1), we have
VB([mB, yi+1])≥VB([ai,k+1, ai,k+2])>2rp
f(T)/T,
proving Property 5 for i+ 1.
2.Case ˜ci,k+1̸=ci,k+1.Each time Bob picked his less-preferred piece when Alice cut
atai,k+1, he lost 2VB(INTV[ai,k+1, mB])in value compared to his regret benchmark.
Since ˜ci,k+1̸=ci,k+1, he did so at least1
2p
f(T)·Ttimes. In order to have regret at
most rf(T), he must have
VB(INTV[ai,k+1, mB])≤rr
f(T)
T. (12)
By Lemma 1, we have
mB∈(ai,k, ai,k+2) (13)
and
VB([ai,k, ai,k+1])>2rr
f(T)
T. (14)
Combining equations (12), (13), and (14) we obtain
VB([mB, yi+1]) =VB([mB, ai,k+2]) (Since yi+1=ai,k+2)
≥VB([ai,k+1, ai,k+2])−VB(INTV[ai,k+1, mB])
(Since mB< ai,k+2by (13))
> rp
f(T)/T . (By (12) and (14))
Thus VB([mB, yi+1])> rp
f(T)/T, so Property 5 holds for i+ 1.
Since mB∈(ai,k, ai,k+2), we have
VB([xi+1, mB])≥VB([ai,k−1, ai,k])>2rp
f(T)/T,
which proves Property 4 for i+ 1.
263.Case ˜ci,j=ci,jfor all j∈[5].Then mB∈[ai,k, ai,k+1]. By Lemma 1, we have
VB([xi, mB])≥VB([xi, ai,k]) =VB([ai,k−1, ai,k])>2rp
f(T)/T (15)
and
VB([mB, yi])≥VB([ai,k+1, yi]) =VB([ai,k+1, ai,k+2])>2rp
f(T)/T . (16)
Inequality (15) implies Property 4 for i+ 1, while inequality (16) implies Property 5
fori+ 1.
In all three cases, mB∈[ai,k−1, ai,k+2] = [xi+1, yi+1], showing Property 3 for i+ 1.
Thus, in all three cases, Properties 3-5 hold for i+1. By induction, they hold for all i∈ {0,1, . . . , n }.
This completes the proof.
Proposition 5. LetvAbe an arbitrary Alice density and α∈[0,1). Then there exists a value density
function ˜vB= ˜vB(vA)and strategy ˜SB=˜SB(vA, α)that ensures Bob’s regret is O(Tα)while
Alice’s Stackelberg regret is Ω
Tα+1
2
.
Proof. At a high level, the Bob we construct will behave as if his midpoint were at mB−Tα−1
2.
If Alice calls his bluff, i.e. cuts close to mB“enough” times, then Bob reverts to being honest by
actually selecting his preferred piece.
Formally, let ybe an arbitrary point such that y > m A. Define the Bob value density ˜vBas follows:
˜vB(x) =(
1
2y∀x∈[0, y]
1
2(1−y)∀x∈(y,1].(17)
Bob’s value density ˜vBis bounded since yis a fixed constant. Moreover, Bob’s midpoint mBis
exactly at y. Let ˜SBbe Bob’s strategy as defined in Figure 16.
Bob strategy ˜SB:
Input: α.
Initialize c= 0. For t∈[T]:
• IfmB< at≤1then play bt=L.
• If0≤at< m B−Tα−1
2then play bt=R.
• IfmB−Tα−1
2≤at≤mBthen:
Ifc≥Tα+1
2then play bt=R; Else, play bt=L.
Update c←c+ 1.
Figure 16: Algorithm A.3
Strategy ˜SBensures that Bob takes his less-favorite piece at most Tα+1
2times, and this only happens
when Alice cuts in the interval
P= [mB−Tα−1
2, mB]. (18)
Since the density ˜vBis bounded from above by a constant, Bob gives up a value of at most O(Tα−1
2)
in each such round. Thus Bob’s regret is O(Tα).
Now let us compute Alice’s regret with respect to her Stackelberg value. Suppose that Tis sufficiently
large, so that mB−Tα−1
2> m A. There are two cases depending on whether Alice triggers the
switch in Bob’s strategy or not.
27•Alice cuts in Pat least Tα+1
2times. Consider the first Tα+1
2times Alice cuts in P. Whenever
Alice cuts at some point x∈P, her utility will be VA([x,1])since Bob plays L. Therefore,
her payoff in that round is maximized when xis minimized, which occurs at the left-hand
endpoint x=mB−Tα−1
2. However,
mB−Tα−1
2> m A,
and so
VAh
mB−Tα−1
2,1i
<1/2. (19)
Then her Stackelberg regret over all the rounds in which she cuts in Pis at least
Tα+1
2·
VA([0, mB])−VAh
mB−Tα−1
2,1i
> Tα+1
2·
VA([0, mA]) +VA([mA, mB])−1
2
=Tα+1
2VA([mA, mB])∈Ω
Tα+1
2
.
•Alice cuts in Pfewer than Tα+1
2times . In this case, we will show that Alice’s payoff per
round cannot be more than VAh
0, mB−Tα−1
2i
. To see this, we consider two sub-cases.
If Alice cuts at a point x < m B−Tα−1
2, then Bob picks R and Alice’s utility in that round
is
VA([0, x])< VAh
0, mB−Tα−1
2i
. (20)
If Alice cuts at a point x≥mB−Tα−1
2, then Bob picks L and Alice’s utility in that round
is
VA([x,1])<1
2< VAh
0, mB−Tα−1
2i
. (21)
Combining (20) and (21), we obtain that in each round t∈[T], Alice’s utility is
ut
A≤VAh
0, mB−Tα−1
2i
. (22)
Summing over all rounds t∈[T], we obtain that Alice’s Stackelberg regret is
TX
t=1 
u∗
A−ut
A
≥TX
t=1
VA([0, mB])−VAh
0, mB−Tα−1
2i
(23)
=TX
t=1VAh
mB−Tα−1
2, mBi
(24)
≥TX
t=1δ·Tα−1
2∈Ω
Tα+1
2
. (25)
Thus in both cases, Alice’s Stackelberg regret is at least Ω
Tα+1
2
, which concludes the proof.
Lemma 3. Letα, β∈[0,1). Suppose Alice’s density is vAand her strategy is SA. There exists a
BobBob1= (vB,1, SB,1)that depends on vAand a Bob Bob2= (vB,2, SB,2)that depends on vA
andSA, such that
•Bob1has regret O(Tα)(i.e. strategy SB,1ensures that a player with density vB,1has regret
O(Tα))
•Bob2has regret O(Tβ); and
28•ifSAensures Alice Stackelberg regret of O(Tβ)against Bob1, then SAhas regret at least
T/6against Bob2.
Proof. Letxbe the cake position such that VA([0, x]) = 2 /3, and let ybe the cake position such that
VA([0, y]) = 5 /6. The first Bob, Bob1, will have a valuation function vB,1that has midpoint x. We
define Bob1’s strategy SB,1so that it truthfully picks his preferred piece, i.e.,
SB,1(At, Bt−1) =Lifat∈(x,1]
Rifat∈[0, x].(26)
Against Bob1, Alice’s Stackelberg value is 2/3. Suppose SAensures Alice Stackelberg regret at most
rTβagainst Bob1for some r >0.
Then we define our second Bob, denoted Bob2, having a valuation function vB,2which has a midpoint
aty. Let k(t)be the number of times Alice cuts in the interval (x, y]in rounds {1, . . . , t}. Then
Bob2’s strategy will be defined as follows:
SB,2(At, Bt−1) =

SB,1(At, Bt−1)ifk(t)≤3rTβ
L ifk(t)>3rTβandat∈(y,1]
R ifk(t)>3rTβandat∈[0, y].(27)
Intuitively, SB,2switches to being honest after Alice cuts in (x, y]sufficiently many times. This
transition gives Bob2a regret guarantee of O(Tβ).
When Alice plays SAagainst Bob1, her total payoff is
uA(SA, SB,1)≥2T/3−rTβ. (28)
However, every round she cuts in (x, y], her payoff is less than 1/3. Therefore, against Bob1, her
total payoff can also be bounded by
uA(SA, SB,1)≤2T/3−k(T)/3. (29)
Combining inequalities (28) and (29), we obtain
k(T)≤3rTβ. (30)
By definition, strategy SB,2behaves the same as strategy SB,1when k(T)≤3rTβ. By (30), we
havek(T)≤3rTβwhen Alice uses strategy SA. Thus, if Alice uses strategy SA, then Bob1and
Bob2behave exactly the same way. Therefore, Alice receives no more than 2/3per round against
Bob2, so her regret is at least T/6∈Ω(T).
If Bob’s density is not lower bounded by any constant, then Theorem 1 fails as shown in the next
remark.
Remark 1. Letα∈(0,1). There exist value densities vAandvB, where vA(x)∈[δ,∆]∀x∈[0,1]
andvB(x)∈(0,∆]∀x∈[0,1]such that Bob has a strategy SBwhich guarantees his regret is at
mostTαand Alice’s Stackelberg regret is at least Ω(T/logT), no matter what strategy she uses.
Proof. The specific valuations will be defined in terms of cumulative valuations. Let Alice’s valuation
be:
VA([0, x]) =1
2x ifx∈[0,1/2]
3
2x−1
2ifx∈(1/2,1]
Let Bob’s valuation be:
VB([0, x]) =(
x ifx∈[0,1/2]
1
2+ 2−1
2x−1ifx∈(1/2,1](31)
Intuitively, Alice has a well-behaved piecewise uniform density with midpoint mA= 2/3. Bob’s
density is well-behaved for x≤1/2, but the density rapidly approaches zero just to the right of
x= 1/2.
29Fix an arbitrary α∈(0,1). There exists a point yon the cake such that VB([1/2, y]) =1
2Tα−1.
Define Bob’s strategy SBas follows:
SB(At, Bt−1, vB, T) =Rifat< y
Lifat≥y .
This strategy would be honest if Bob’s midpoint were at yrather than 1/2. That means it only differs
from his preferred piece when at∈(1/2, y]. The worst outcome for Bob occurs when at=y. But
by construction, even in a round where Alice cuts at y, Bob only loses Tα−1utility compared to
picking his preferred piece. Since there are Trounds, his overall regret is at most Tα.
Alice, on the other hand, cannot do very well compared to her Stackelberg value. Her Stackelberg
value is 3/4, achieved by cutting at Bob’s midpoint of 1/2and receiving her preferred piece. But Bob
prevents this payoff by pretending his midpoint is at y. To obtain the exact location of y, note that
VB([1/2, y]) =1
2Tα−1.
Plugging (31), this is equivalent to
2−1
2y−1=1
2Tα−1.
Solving for y, we have
y=1
2+1
(2−2α) log2T+ 2.
For sufficiently large T, we have y∈(mB, mA). Alice’s best cut location in each round is then at y
itself, which gives her a per-round payoff of
VA([y,1]) =3
4−3
(4−4α) log2T+ 4.
Adding this up over all Trounds gives a total regret of at least, we obtain
3T
(4−4α) log2T+ 4,
which is Ω(T/logT)as required. This completes the proof.
30B Appendix: Equitable payoffs
This appendix has two parts. In Appendix B.1, we prove Theorem 2, which shows that Alice can
enforce equitable payoffs. In Appendix B.2, we prove Theorem 3, which shows that Bob can enforce
equitable payoffs.
B.1 Appendix: Alice enforcing equitable payoffs
In this section we prove Theorem 2, the statement of which is included next.
Restatement of Theorem 2 (Alice enforcing equitable payoffs; formal) .In both the sequential and
simultaneous settings, Alice has a pure strategy SA, such that for every Bob strategy SB:
•on every trajectory of play, Alice’s average payoff is at least 1/2−o(1), while Bob’s average
payoff is at most 1/2 +o(1). More precisely, for all t∈ {3, . . . , T }:
uB(1, t)
t≤1
2+5∆ + 11
ln(2t/5)(32)
uA(1, t)
t≥1
2−4√t−1, (33)
recalling that ∆is the upper bound on the players’ value densities.
Moreover, even if Bob’s value density is unbounded, his average payoff will still converge to 1/2.
The proof of the theorem is deferred until additional definitions have been stated and helpful lemmas
have been proved. We first define some notations.
Definition 5 (Set of valuations Wn).For each n∈N∗, we define the following set of non-decreasing
piecewise linear functions with npieces:
Wn=n
f: [0,1]→[0,1]|fis non-decreasing with f(0) = 0 , f(1) = 1 , f(i/n)·n∈Z≥0,and
f(x) =fi
n
+
x−i
n
fi+ 1
n
−fi
n
∀i∈ {0, . . . , n −1}∀x∈i
n,i+ 1
no
.
Definition 6 (Set of functions Vn).For each n∈N∗, recall Wnwas given in Definition 5 and define
Vnas the following set of functions:
Vn=Wn ifn̸= 2
W2∪ {fA}ifn= 2,where fA: [0,1]→[0,1]is the function fA(x) =VA([0, x]).
Definition 7 (The set V).LetV=S∞
n=1{(n, V) :V∈ Vn},where Vnis given by Definition 6.
Remark 2. By construction, for each n∈N∗, every function f∈ Vnis non-decreasing.
For each n∈N∗,Wncontains the nondecreasing piecewise linear functions through a grid with
spacing 1/n. For large n, then, Wnshould contain approximations to any given function accurate to
roughly O(1/n).
If Alice bases her strategy on limiting the payoff of the Bobs in each Wn, then she will limit Bob’s
payoff but not necessarily guarantee herself a very good payoff. The inclusion of Alice’s valuation
function in Vrectifies this, allowing us to show a much tighter bound on Alice’s payoff.
To formalize the ability of the elements of the Vnto approximate arbitrary valuation functions, we
prove the following three lemmas. The first of them (Lemma 4) is somewhat technical, but most
directly shows the richness of the Vn. It will be used to prove Lemmas 5 and 6, which will be used
directly to bound the payoff of an unbounded-density and bounded-density Bob, respectively.
Lemma 4. Letf: [0,1]→[0,1]be continuous and increasing with f(0) = 0 andf(1) = 1 .
Suppose there exist n∈N∗andε∈(0,∞)such that
|f(x)−f(y)| ≤ε∀x, y∈[0,1]with|x−y| ≤1/n . (34)
Then there exists Vn∈ Vn, where Vnis the set of functions from Definition 6, such that
|f(x)−Vn(x)| ≤ε+ 2/n∀x∈[0,1].
31Proof. Forx∈R, let⌊x⌉denote the nearest integer to x, breaking ties in favor of ⌈x⌉when
x=⌊x⌋+ 1/2.
Recall the set of functions Wnfrom Definition 5. Let Vnbe the function in Wnsuch that:
Vn(i/n) =⌊n·f(i/n)⌉
n∀i∈[n−1]. (35)
Then we claim the function Vnapproximates well the function fat the points i/n, that is:
|Vn(i/n)−f(i/n)|=⌊n·f(i/n)⌉
n−f(i/n)≤1
2n∀i∈ {0, . . . , n }, (36)
where
• for i∈[n−1]the inequality in (36) follows from (35);
• for i= 0it follows from Vn(0) = 0 = f(0), and
• for i=nit follows from Vn(1) = 1 = f(1).
Letx∈[0,1]. We show three inequalities next:
1.By inequality (34) from the lemma statement with parameters ⌊xn⌋/nand⌈xn⌉/n, we get
f⌈xn⌉
n
−f⌊xn⌋
n
≤ε . (37)
2. By inequality (36) with i=⌈xn⌉, we have
Vn⌈xn⌉
n
−f⌈xn⌉
n≤1
2n. (38)
3. By inequality (36) with i=⌊xn⌋, we have
f⌊xn⌋
n
−Vn⌊xn⌋
n≤1
2n. (39)
Summing up inequalities (37), (38), (39) and applying the triangle inequality, we obtain
Vn⌈xn⌉
n
−Vn⌊xn⌋
n≤ε+1
n. (40)
We obtain
Vn⌊xn⌋
n
−1
2n≤f⌊xn⌋
n
(By (36) with i=⌊xn⌋)
≤f(x) (Since fis non-decreasing)
≤f⌈xn⌉
n
(Since fis non-decreasing)
≤Vn⌈xn⌉
n
+1
2n. (By (36) with i=⌈xn⌉)
Denoting J=h
Vn ⌊xn⌋
n
−1/(2n), Vn ⌈xn⌉
n
+ 1/(2n)i
, we conclude that f(x)∈J. Since the
function Vnis non-decreasing by Remark 2, we have
Vn⌊xn⌋
n
−1
2n≤Vn(x)−1
2n< Vn(x)< Vn(x) +1
2n≤Vn⌈xn⌉
n
+1
2n. (41)
32Thus Vn(x)∈J. Since both f(x)∈JandVn(x)∈J, we can bound |f(x)−Vn(x)|as follows:
|f(x)−Vn(x)| ≤ |J|
=
Vn⌈xn⌉
n
+1
2n
−
Vn⌊xn⌋
n
−1
2n
≤ε+2
n. (Since Vn ⌈xn⌉
n
−Vn ⌊xn⌋
n
≤ε+ 1/nby (40))
Since this holds for all x∈[0,1], the function Vnrequired by the lemma exists.
Lemma 5. Letf: [0,1]→[0,1]be continuous and increasing with f(0) = 0 andf(1) = 1 . For
eachε >0, there exists n∈N∗and a function Vn∈ Vnsuch that
|Vn(x)−f(x)| ≤ε∀x∈[0,1], (42)
recalling that the set of functions Vnis given by Definition 6.
Proof. Letϵ >0. Since fis continuous and increasing, its inverse f−1is also continuous and
increasing. Since f(0) = 0 andf(1) = 1 , we have f−1(0) = 0 andf−1(1) = 1 . Consider a
function g: [0,1−ε/4]→[0,1]defined as
g(x) =f−1(x+ε/4)−f−1(x). (43)
Since f−1is continuous and bounded over a closed interval, so is the function g. Therefore, by the
extreme value theorem, gattains a global minimum value δ∗. Since f−1is strictly increasing, gis
never zero, so
δ∗>0. (44)
Since we will analyze g(f(x)), it will be useful to define the set of values xfor which g(f(x))is
well defined, that is:
Sε={x∈[0,1]|f(x)∈[0,1−ε/4]}. (45)
Since δ∗is a global minimum of g, we have
g(f(x))≥δ∗∀x∈Sε. (46)
Using the definition of g(equation (43)) in (46) yields
g(f(x)) =f−1(f(x) +ε/4)−f−1(f(x))≥δ∗∀x∈Sε. (47)
Since f−1(f(x)) =x, inequality (47) yields f−1(f(x) +ε/4)−x≥δ∗, or equivalently,
f−1(f(x) +ε/4)≥x+δ∗∀x∈Sε. (48)
Applying fto both sides of (48) and using monotonicity of f, we obtain f(x) +ε/4≥f(x+δ∗)
for all x∈Sε, or equivalently
f(x+δ∗)−f(x)≤ε/4∀x∈Sε. (49)
Since ε >0andδ∗>0by (44), there exists n∈Nsuch that
n >1/δ∗andn >4/ε . (50)
Note that because the range of f−1is[0,1], the left side of (48) is at most 1. Therefore, from (48)
and the fact that δ∗>1/nby (50):
1≥x+δ∗> x+ 1/n ∀x∈Sε (51)
Consider an arbitrary x, y∈[0,1]withx≤y≤x+ 1/n. We consider two cases:
• Case x∈Sε: Since fis strictly increasing and x+δ∗≤1by (51), we have:
f(y)≤f(x+ 1/n)< f(x+δ∗) (52)
Subtracting f(x)from both sides of (52) and applying (49), we obtain
f(y)−f(x)< ε/4 (53)
33• Case x̸∈Sε: Then f(x)>1−ε/4. Since f(y)≤1, we have:
f(y)−f(x)<1−(1−ε/4) = ε/4. (54)
Combining cases x∈Sεandx̸∈Sεgives f(y)−f(x)< ε/4∀x, y∈[0,1]withx≤y≤x+1/n .
Since fis strictly increasing, we have f(x)≤f(y)when x≤y, and so
|f(x)−f(y)|< ε/4∀x, y∈[0,1]with|x−y| ≤1/n . (55)
By Lemma 4, there exists a function Vn∈ Vnsuch that:
|f(x)−Vn(x)| ≤ε/4 + 2 /n ∀x∈[0,1]. (56)
Since n >4/εby (50), inequality (56) gives
|f(x)−Vn(x)| ≤ε/4 + 2 /n < ε/ 4 +ε/2< ε ∀x∈[0,1]. (57)
This completes the proof.
Lemma 6. Suppose vBis a value density function for Bob with vB(x)≤∆for some ∆>0and all
x∈[0,1]. Then for all n∈N∗, there exists a function Vn∈ Vnsuch that
Vn(x)−VB([0, x])≤∆ + 2
n∀x∈[0,1].
Proof. Letn∈N∗. Since Bob’s density is upper bounded by ∆, we have
|VB([0, x])−VB([0, y])| ≤∆|x−y| ∀ x, y∈[0,1]. (58)
When|x−y| ≤1/n, we get |VB([0, x])−VB([0, y])| ≤∆|x−y| ≤D/n .
By Lemma 4 applied to the function f: [0,1]→[0,1]given by f(x) =VB([0, x]), there exists
Vn∈ Vnwith|Vn(x)−VB([0, x])| ≤∆/n+ 2/nfor all x∈[0,1].This completes the proof.
The set of functions Vnwill be used to construct a strategy for Alice. Next we bound the size of Vn
as a function of n, as this rate of growth will influence the error bounds on the players’ utilities.
Lemma 7. |Vn| ≤4n−1∀n∈N∗.
Proof. We first estimate the size of each set Wn, and then will infer the bound for the size of Vn.
Consider the density function corresponding to any particular V∈ W n. Because Vis piecewise linear,
its density is piecewise constant. Each Vis then uniquely determined by a sequence d1, d2, . . . , d n,
where diis the value density betweeni−1
nandi
n. Each dimust be a non-negative integer, because
each of these intervals has width 1/nand sees Vrise by an integer multiple of 1/n. More strongly,
because V(0) = 0 andV(1) = 1 , we must have the next relation between the di’s:
nX
i=1di
n= 1⇐⇒nX
i=1di=n . (59)
Thus, the size |Wn|is the number of possible partitions of nintonparts with nonnegative integer
sizes. The size of Wncan then be counted by a standard combinatorics technique. Represent each
choice of d1, d2, . . . , d nwith a sequence of n“stars" and n−1“bars": d1stars, then a bar, then d2
stars, then another bar, and so on. Each choice of d1, . . . , d ncorresponds to a unique arrangement of
stars and bars. The opposite is also true: given an arrangement, the number of stars between each
pair of bars can be read off as d1, . . . , d n. The size of Vnis then the number of arrangements, which
is 2n−1
n
.
The upper bound can then be shown by induction. As a base case, 2·1−1
1
= 1
1
= 1≤41−1.
34Now assume 2n−1
n
≤4n−1for an arbitrary n≥1. We have
2(n+ 1)−1
n+ 1
=(2n+ 1)!
(n+ 1)!·n!=(2n−1)!·2n·(2n+ 1)
n!·(n−1)!·n(n+ 1)=2n−1
n
·2n(2n+ 1)
n(n+ 1)
≤4n−1·4n+1
2
n+ 1(By the inductive hypothesis)
≤4n−1·4 = 4(n+1)−1
So by induction, the bound holds for all n≥1.
Because Vn=Wnfor all n̸= 2, the only case left to verify is n= 2. By calculation, |W2|= 3
2
= 3,
so including the extra function makes |V2|= 4 = 42−1.
Some other technical lemmas are necessary. The first two relate to the following function, which acts
like an infinite-dimensional inner product.
Definition 8. LetXbe the collection of all functions X:V → [−1,1]. For each pair of functions
X, Y :V → [−1,1],define P:X × X → Ras follows:
P(X, Y) =∞X
n=11
2n|Vn|X
V∈VnX(n, V)Y(n, V).
Lemma 8. The function Phas the properties of an inner product. In particular, for all functions
X, Y, Z :V → [−1,1]and all constants c∈[−1,1], the following holds:
(1)P(X, Y)exists, and the infinite sum converges absolutely
(2)P(X, Y) =P(Y, X)
(3)|P(X, Y)| ≤1
(4)P(cX, Y ) =cP(X, Y)
(5)P(X+Z, Y) =P(X, Y) +P(Z, Y), assuming X+Zis in the domain of P
(6)P(X, X ) = 0 ifX(n, V) = 0 for all nand all V, and P(X, X )>0otherwise
Proof. We separately prove each of the properties.
For the first property, note that the individual terms go to zero
lim
n→∞1
2n|Vn|X
V∈VnX(n, V)Y(n, V)≤lim
n→∞1
2n|Vn|X
V∈Vn|X(n, V)Y(n, V)|
≤lim
n→∞1
2n|Vn|X
V∈Vn1 (By the bounds on XandY)
= lim
n→∞1
2n|Vn||Vn|= lim
n→∞1
2n
= 0.
Using the above upper bound for individual terms, the sum of the absolute values does not diverge as
follows
∞X
n=11
2n|Vn|X
V∈VnX(n, V)Y(n, V)≤∞X
n=11
2n= 1.
SoP(X, Y)exists and the infinite sum converges absolutely.
The existence is enough for property (2), which follows directly from the product X(n, V)Y(n, V)
being commutative. This calculation directly verifies property (3).
35The absolute convergence allows for the linear operations in properties (4) and (5) to factor through
the sum.
First, for property (4) we obtain
P(cX, Y ) =∞X
n=11
2n|Vn|X
V∈VncX(n, V)Y(n, V)
=c∞X
n=11
2n|Vn|X
V∈VnX(n, V)Y(n, V)
=cP(A, B).
For property (5) observe that:
P(X+Z, Y) =∞X
n=11
2n|Vn|X
V∈Vn(X(n, V) +Z(n, V))Y(n, V)
=∞X
n=11
2n|Vn|X
V∈VnX(n, V)Y(n, V) +Z(n, V)Y(n, V)
=∞X
n=11
2n|Vn|X
V∈VnX(n, V)Y(n, V) +∞X
n=11
2n|Vn|X
V∈VnZ(n, V)Y(n, V)
=P(X, Y) +P(Z, Y).
For property (6), observe that the expression can be rewritten as:
P(X, X ) =∞X
n=11
2n|Vn|X
V∈VnX(n, V)2.
This is a sum of squares, which will be zero if all the included X(n, V)are zero and positive
otherwise.
Lemma 9. For each x∈[0,1], letGx:V → [−1/2,−1/2]be given by Gx(n, V) =V(x)−1
2.
Then, for all Z:V → [−1,1], the following function is continuous in x:
P(Gx, Z) =∞X
n=11
2n|Vn|X
V∈Vn
V(x)−1
2
Z(n, V).
Proof. Alice’s valuation function in V2needs to be handled separately. Accordingly, write:
P(Gx, Z) =∞X
n=11
2n|Vn|X
V∈Vn
V(x)−1
2
Z(n, V)
=1
22|V2|
VA([0, x])−1
2
Z(n, VA) +∞X
n=11
2n|Vn|X
V∈Wn
V(x)−1
2
Z(n, V).
As long as each of these two parts is continuous, the sum will be too. The first part is continuous
because VA([0, x])is continuous. To prove the second part, for notational simplicity, define
P′(Gx, Z) =∞X
n=11
2n|Vn|X
V∈Wn
V(x)−1
2
Z(n, V)
The continuity of P′will be shown by directly appealing to the definition of a limit. First, note that
eachV∈ W nis made of nlinear segments, each of width1
nand height at most 1. Therefore, if
V∈ W n, for all x, y∈[0,1]:
|V(y)−V(x)| ≤ |y−x|n (60)
36Fix an arbitrary ε >0andx∈[0,1]. Choose δ=ε/2. For any ysuch that |y−x|< δ:
|P′(Gy, Z)−P′(Gx, Z)|=|P′(Gy−Gx, Z)| (By property (5))
=∞X
n=11
2n|Vn|X
V∈Wn(V(y)−V(x))Z(n, V)
≤∞X
n=11
2n|Vn|X
V∈Wn|V(y)−V(x)| · |Z(n, V)|(Triangle inequality)
≤∞X
n=11
2n|Vn|X
V∈Wnn|y−x| ·1 (By ineq (60) and Z≤1)
≤ |y−x|∞X
n=1n
2n(Since |Wn| ≤ |V n|)
=|y−x| ·2
<2δ (By choice of δ)
=ε .
Therefore, for all x∈[0,1]:
lim
y→xP′(Gy, Z) =P′(Gx, Z),
which is the definition of P′(Gx, Z)being continuous in x. This concludes that P(Gx, Z)is
continuous in x.
Finally, the last one is a strengthening of Lemma 1 from Blackwell (1956), under stronger hypotheses.
Lemma 10. Suppose a sequence of nonnegative values δ1, δ2, . . . satisfies, for all t≥1:
δt+1≤1
(t+ 1)2+t−1
t+ 1
δt.
Then limt→∞δt= 0. In particular, for all t≥2:
δt≤1
t(t−1)tX
i=2i−1
i≤1
t.
Proof. The latter bound will be shown by induction. As a base case, consider t= 2. The condition
fort= 1gives:
δ2≤1
(1 + 1)2+1−1
1 + 1
δ1=1
4=1
2(2−1)2X
i=2i−1
i. (61)
So the base case holds. Now suppose the conclusion holds for some t≥2. Assume that the claim
holds for δt. We can expand the upper bound of δt+1as follows.
δt+1≤1
(t+ 1)2+t−1
t+ 1
δt (62)
≤1
(t+ 1)2+t−1
t+ 11
t(t−1)tX
i=2i−1
i(By the induction hypothesis)
=1
(t+ 1)2+1
t(t+ 1)tX
i=2i−1
i(63)
=1
(t+ 1)tt+1X
i=2i−1
i. (64)
37Now it suffices to show that the last term in (64) is upper bounded by 1/t, which follows from the
following inequality:
1
t(t−1)tX
i=2i−1
i≤1
t(t−1)tX
i=21 =1
t(t−1)·(t−1) =1
t. (65)
Thus δt+1≤1/t, which completes the proof.
Now the groundwork is laid to prove Theorem 2. The idea is to limit every strategy and every
valuation in every Vnto an average payoff of 1/2, which is sufficient to limit Bob equipped with
arbitrary valuation as well.
Proof of Theorem 2. We first define the Alice’s strategy in an analytical manner, and then prove that
it is well-defined. Then we will show that this strategy will force Bob’s payoff to be at most 1/2
on average, by showing both that Bob’s valuation can be well-approximated by functions in Vand
that such valuation functions are limited to a payoff of 1/2on average. Finally, we establish explicit
convergence rates for Bob’s payoff if his valuation is bounded, as well as the convergence of Alice’s
payoff to 1/2.
Defining Alice’s strategy SAConsider Alice’s decision in round T. In each round t < T , let
the payoff to Bob whose cumulative valuation function is Vbeut,V. For each x∈[0,1], let
Gx:V → [−1,1]be a function defined as Gx(n, V) =V(x)−1/2. LetUt(n, V) =ut,V−1/2for
t= 1, . . . , T −1, and let Ut(n, V) =Pt
i=1Ui(n, V)/t. Let Wt(n, V) = max {0,Ut(n, V)}for
t= 1, . . . , T −1. In round T, Alice’s strategy SAis to cut at a point xsuch that P(Gx, WT−1) = 0 .
We then show that SAis well-defined. It suffices to prove that such an xalways exists. To this end,
observe that
P(G0, WT−1) =∞X
n=11
2n|Vn|X
V∈Vn
V(0)−1
2
WT−1(n, V)
=∞X
n=11
2n|Vn|X
V∈Vn−1
2WT−1(n, V)
≤∞X
n=11
2n|Vn|X
V∈Vn0 (Since WT−1(·)is nonnegative)
= 0.
Using similar algebra for P(G1, WT−1), we obtain
P(G1, WT−1) =∞X
n=11
2n|Vn|X
V∈Vn
V(1)−1
2
WT−1(n, V)
=∞X
n=11
2n|Vn|X
V∈Vn1
2WT−1(n, V)
≥∞X
n=11
2n|Vn|X
V∈Vn0 (Since WT−1(·)is nonnegative)
= 0
By Lemma 9, P(Gx, WT−1)is continuous in x, so by the Intermediate Value Theorem there exists x
such that P(Gx, WT−1) = 0 .
Bounding Bob’s payoff Define
S=
X:−1
2≤X(n, V)≤0for all (n, V)∈V
.
38For each round t, letδtbe the distance from StoUt, defined as:
δt= inf
X∈SP(Ut−X,Ut−X). (66)
Fort < T , letYt:V → [−1/2,1/2]be the function defined by:
Yt(n, V) = min {0,Ut(n, V)}
By Claim 3, we have δt≤1/tfor all t≥2.
Now we will show that this strategy guarantees that, for any Bob’s valuation function vBand any
strategy SBBob employs, his average payoff is at most 1/2. Consider an arbitrary ε >0. It will be
shown that, for some sufficiently large T, Bob’s average payoff up to any point after round Tis at
most 1/2 +ε.
In the general case, this convergence can be established from Lemma 5. Consider N, T∈N∗such
that
•Nis such that there exists V′∈ VNwith|V′(x)−VB([0, x])|< ε/2for all x∈[0,1].
•Tis sufficiently large so that
δt<ε2
4·2N|VN|∀t≥T . (67)
For example, taking T=4·2N|VN|
ε2
would suffice.
We will show that for each t≥T, we have Ut(N, V′)< ε/2. This trivially holds if Ut(N, V′)≤0,
so assume Ut(N, V′)>0. We then obtain
Ut(N, V′) =s
2N|VN| ·1
2N|VN|Ut(N, V′)2
=s
2N|VN| ·1
2N|VN| 
Ut(N, V′)−Yt(N, V′)2, (68)
where (68) follows from the fact that Yt(N, V′) = min {0,Ut(N, V′)}= 0. Using (68), we can
upper bound Ut(N, V′)as follows:
Ut(N, V′)≤vuut2N|VN|∞X
n=11
2n|Vn|X
V∈Vn 
Ut(n, V)−Yt(n, V)2
=q
2N|VN|P(Ut−Yt,Ut−Yt)
=q
2N|VN|δt (69)
<s
2N|VN| ·ε2
4·2N|VN|=ε
2. (By (67))
Therefore, we have Ut(N, V′)< ε/2for all t≥T. Translating back into payoffs, this gives a Bob
whose cumulative valuation function is V′an average payoff of less than 1/2 +ε/2. By the choice
ofV′, we have
|V′(x)−VB([0, x])|< ε/2 for all x∈[0,1]. (70)
so the average payoff to a Bob whose valuation function is vBis less than 1/2 +ε. Since this
construction works for all ε >0, Bob’s average payoff satisfies the following inequality as required:
uB(1, t)
t≤1
2+o(1).
39Explicit bounds It remains to prove inequality (32) when Bob’s density is upper bounded by ∆,
and prove Alice’s explicit payoff in inequality (33). Choose an integer Nlarge enough that
∆ + 2
N<ε
2.
For instance, taking N=⌈2(∆ + 2) /ε⌉is sufficient. By Lemma 6, there exists V′∈ VNsuch that
|V′(x)−VB([0, x])|<(∆ + 2) /N for all x∈[0,1].
Choose Tin exactly the same way as the general case, i.e. T=⌈4·2N|VN|/ε2⌉. By exactly the
same algebra as the general case, we can conclude that Ut(N, V′)< ε/2for all t≥T. By the choice
ofV′, we have
|V′(x)−VB([0, x])|< ε/2 for all x∈[0,1], (71)
so the average payoff to Bob is at most1
2+ε.
In this case, Bob’s average payoff will be within εof1/2by time
Tε=4·2N|VN|
ε2
, where N=⌈2(∆ + 2) /ε⌉. (72)
Hence, for such Tε, we have
Tε≤4·2N·4N−1
ε2
.
Since⌈x⌉ ≤2xforx≥1/2, this implies
Tε≤28N
ε2.
Due to our choice of N, we can further obtain
Tε≤2·82(∆+2)
ε+1
ε2. (73)
Taking the natural logarithm of both sides in (73), we have
ln(Tε)≤ln(16) +2(∆ + 2)
εln(8) + 2 ln1
ε
.
Using the fact that ln(x)≤x−1for every x >0, it follows that
ln(Tε)≤ln(16) +2(∆ + 2)
εln(8) + 21
ε−1
. (74)
Rearranging (74), we finally obtain
ε≤2 ln(8)(∆ + 2) + 2
ln(Tε)−ln(16) + 2.
Note that this requires the step of dividing by ln(Tε)−ln(16) + 2 and it needs this quantity to be
positive, which is indeed positive for T≥3. Rounding the terms gives the desired regret bound for
Bob.
To provide Alice’s payoff bound in inequality (33), consider a hypothetical Bob whose valuation
function ˜vBis exactly the same as Alice’s valuation function vA. For all rounds τ, the payoff ˜uτ
Bto
this Bob then satisfies:
uτ
A+ ˜uτ
B=VA([0, aτ]) +VA([aτ,1])
(One player gets VA([0, aτ])and the other gets VA([aτ,1]))
= 1 (75)
For any t, summing uτ
A+ ˜uτ
Boverτ∈[t]and dividing by tthen gives:
uA(1, t)
t+˜uB(1, t)
t= 1 (76)
40So it suffices to upper-bound this particular Bob’s payoff to lower-bound Alice’s payoff.
Choose an arbitrary ε >0. LetTε=22|V2|
ε2
, ensuring δt<ε2
22|V2|for all t≥Tε. By construction,
Alice’s valuation function VA([0, x])∈ V2. Taking N= 2andV′=VA, we can then use identical
algebra as the general-Bob case up to (69) to conclude that, for t≥Tε:
Ut(2, VA)≤p
22|V2|δt (Copying over (69))
<s
22|V2| ·ε2
22|V2|=ε (77)
So this Bob’s payoff is upper-bounded by 1/2 +ε, and so by (76) Alice’s payoff is lower-bounded by
1/2−ε. To solve for ε, observe that Tε≤16/ε2+ 1. Solving this bound on Tεforεgives
ε≤4√Tε−1,
and it finishes the proof.
We finally provide the claims and their proofs used throughout the main proof.
Claim 1. In the setting of Theorem 2, if Ut/∈ S, then argminX∈SP(Ut−X,Ut−X)exists.
Furthermore:
argmin
X∈SP(Ut−X,Ut−X) =Yt= min {0,Ut(n, V)}
Proof of the claim. LetYt= min {0,Ut(n, V)} ∈ S . For any X∈ S,
P(Ut−X,Ut−X) =∞X
n=11
2n|Vn|X
V∈Vn 
Ut(n, V )−X(n, V )2
=∞X
n=11
2n|Vn|
X
V∈Vn
Ut(n,V )>0 
Ut(n, V )−X(n, V )2+X
V∈Vn
Ut(n,V )≤0 
Ut(n, V )−X(n, V )2

(78)
Since X∈ S, we have that X(n, V)≤0for every nandV, due to our construction of S.
Therefore, replacing them with 0brings them closer to any positive value and so decreases the first
sum of squares. The second sum of squares is nonnegative, so it can be reduced by replacing it with
0. Applying these simplifications, we obtain
∞X
n=11
2n|Vn|
X
V∈Vn
Ut(n,V)>0 
Ut(n, V)−X(n, V)2+X
V∈Vn
Ut(n,V)≤0 
Ut(n, V)−X(n, V)2

≥∞X
n=11
2n|Vn|
X
V∈Vn
Ut(n,V)>0 
Ut(n, V)−02+ 0

=D(Ut−Yt,Ut−Yt), (Only the U(n, V)>0terms remain)
and it proves the claim.
Claim 2. In the setting of Theorem 2, the following properties hold when Ut/∈ S.
1.P(Yt, Wt) = 0
2.P(Ut+1, Wt) = 0
413.P(Ut, Wt)>0
4.P(X, W t)≤0for all X∈ S
Proof of the claim. All of these properties can be explained by expanding the dot product Pand
referring to the strategy SA. The first one is the most straightforward: YtandWtare never nonzero
in the same coordinate, so P(Yt, Wt) = 0 . For the second one, by definition, in round t+ 1Alice
cuts at a point xsuch that P(Gx, Wt) = 0 . If Bob selects the left piece, Ut+1=Gx. If Bob instead
selects the right piece:
Ut+1(n, V) = (1 −V(x))−1
2
=1
2−V(x)
=−Gx(n, V).
So by property 4 of Lemma 8, we have P(Ut+1, Wt) =−P(Gx, Wt) = 0 . Because Pis linear as per
property 5 in Lemma 8, any mixed strategy over these outcomes must also satisfy P(Ut+1, Wt) = 0 .
For part (3) of the lemma, expanding the dot product gives:
P(X, W t) =∞X
n=11
2n|Vn|X
V∈VnX(n, V)·max{0,Ut(n, V)}
=∞X
n=11
2n|Vn|X
V∈Vn,Ut(n,V)>0X(n, V)Ut(n, V).
As there exists (n, V)such that Ut(n, V)>0, this sum is strictly positive when X=Ut(n, V), and
soP(Ut, Wt)>0. Similarly, for X∈ S, we have X(n, V)≤0for all (n, V), soP(X, W t)≤
0.
Claim 3. In the setting of Theorem 2, the sequence {δt}∞
t=1defined in (66) satisfies the inequality
δt≤1/tfor all t≥2.
Proof. We will show that our construction of δtsatisfies the recursion formula defined in Lemma 10.
We first focus on the case such that δt>0, which is equivalent to Ut/∈ S, and then prove that it also
holds for δt= 0. Given that δt>0, we observe that
δt+1= inf
X∈SP(Ut+1−X,Ut+1−X)≤P(Ut+1−Yt,Ut+1−Yt). (79)
By rewriting the right hand side of (79), we obtain
δt+1≤P((Ut+1−Ut) + (Ut−Yt),(Ut+1−Ut) + (Ut−Yt)) (80)
Distributing over Pin the expression on the right hand side of (80), we get that (80) is equivalent to
δt+1≤P(Ut+1−Ut,Ut+1−Ut) + 2P(Ut+1−Ut,Ut−Yt) +P(Ut−Yt,Ut−Yt)
=P(Ut+1−Ut,Ut+1−Ut) + 2P(Ut+1−Ut,Ut−Yt) +δt, (81)
where the inequality follows from Claim 1.
Noting that Ut+1−Ut= (Ut+1−Ut)/(t+ 1) , we have
P(Ut+1−Ut,Ut−Yt) =1
t+ 1P(Ut+1−Ut,Ut−Yt)
=1
t+ 1P((Ut+1−Yt) + (Yt−Ut),Ut−Yt)
=1
t+ 1 
P(Ut+1−Yt,Ut−Yt) +P(Yt−Ut,Ut−Yt)
.
42By using Ut=Wt+Yt, we can expand it by
P(Ut+1−Ut,Ut−Yt) =1
t+ 1 
P(Ut+1, Wt)−P(Yt, Wt)−P(Yt−Ut,Ut−Yt)
.
=1
t+ 1(P(Ut+1, Wt)−P(Yt, Wt)−δt) (By Claim 1)
=1
t+ 1(0−0−δt) (By Claim 2)
=−1
t+ 1·δt. (82)
Further, observe that
P(Ut+1−Ut,Ut+1−Ut) =1
(t+ 1)2P(Ut+1−Ut, Ut+1−Ut)
≤1
(t+ 1)2, (83)
where the inequality follows from Property (3) in Lemma 8.
Putting (81), (82) and (83) together, we obtain the following inequality for δt>0:
δt+1≤P(Ut+1−Ut,Ut+1−Ut) + 2P(Ut+1−Ut,Ut−Yt) +δt
≤1
(t+ 1)2−2
t+ 1δt+δt
=1
(t+ 1)2+
1−2
t+ 1
δt.
Now, we show that the same inequality holds for the case such that δt= 0too. Since Ut∈ S, we
obtain
δt+1= inf
X∈SP(Ut+1−X,Ut+1−X)
≤P(Ut+1−Ut,Ut+1−Ut)
≤1
(t+ 1)2(By (83))
=1
(t+ 1)2+
1−2
t+ 1
δt.
By Lemma 10, we therefore have that δt≤1/tfort≥2.
B.2 Appendix: Bob enforcing equitable payoffs
In this section, we prove Theorem 3, which shows how Bob can enforce equitable payoffs.
Restatement of Theorem 3 (Bob enforcing equitable payoffs; formal) .
•In the sequential setting: Bob has a pure strategy SB, such that for every Alice strategy
SA, on every trajectory of play, Bob’s average payoff is at least 1/2−o(1), while Alice’s
average payoff is at most 1/2 +o(1). More precisely,
uB
T≥1
2−1√
TanduB
T≤1
2+∆
2δ+ 21√
T,
recalling that δand∆are, respectively, the lower and upper bounds on the players’ value
densities.
•In the simultaneous setting: Bob has a mixed strategy SB, such that for every Alice strategy
SA, both players have average payoff 1/2in expectation.
43Proof of Theorem 3. Bob’s strategy for the simultaneous setting follows from Proposition 6. His
strategy for the sequential setting follows from Proposition 7.
Proposition 6. In the simultaneous setting, Bob has a mixed strategy SBsuch that, for every Alice
strategy SA:
E[uA]
T=E[uB]
T=1
2.
Proof. Bob’s strategy is very simple: in each round, randomly pick LorRwith equal probability.
To analyze the expected payoffs, consider an arbitrary player i∈ {A, B}and arbitrary round t. Bob
is equally likely to pick LorRin round t, so each player is equally likely to receive [0, at]or[at,1]
in round t. Therefore, their expected payoff is:
E[ut
i] =1
2Vi([0, at]) +1
2Vi([at,1])
=1
2Vi([0,1]) (Since valuations are additive)
=1
2. (84)
Summing (84) over the Trounds gives the desired expected payoffs for each player.
Proposition 7. Bob has a pure strategy SB, such that for every Alice strategy SA, the cumulative
utilities in the sequential game are bounded by:
uA(SA, SB)≤T/2 +∆
2δ+ 2
·√
T and uB(SA, SB)≥T/2−√
T .
Proof. Bob devises his strategy SBby considering a division of the cake into P=⌈√
T⌉consecutive
intervals I1, . . . , I Pof equal value to him. That is, Bob chooses points 0 =z0≤z1. . .≤zP= 1
such that
Ij=[zj−1, zj) if1≤j≤P−1;
[zP−1, zP]ifj=P;and VB(Ij) = 1 /P∀j∈[P]. (85)
An illustration of the division into intervals used by Bob can be seen in Figure 17.
𝒛𝟐𝟎𝟏𝒛𝟏𝒛𝟑𝒛𝟒
Figure 17: Example of a Bob density and the discretization used by Bob when T= 10 . The number
of intervals is P=⌈√
T⌉= 4. The intervals are Ij= [zj−1, zj)forj∈[3]andI4= [z3, z4], with
VB(Ij) = 1 /4∀j∈[4].
Bob’s strategy SBis defined as follows. Bob keeps a counter jassociated with each interval Ij, such
that the value of the counter at time t, denoted cj,t, represents how many times Alice has cut inside
the interval Ijin the first trounds (including round t). For each time t∈[T]:
44• Let Ijbe the interval that contains Alice’s cut at time t(that is, at∈Ij), for j∈[P].
• Ifcj,tis even then Bob plays L; if cj,tis odd, then Bob plays R.
Informally, Bob alternates between L and R inside each interval Ij. We argue that this Bob strategy
ensures his payoff is at least 1/2−o(1)per round, while Alice cannot get more than 1/2 +o(1)per
round.
For each i∈[P]andj∈[ci,T], letri,jbe the first time when the number of cuts in Iireached j.
That is,
ri,j= min {t∈N|ci,t=jandat∈Ii}.
By definition of the sequence {ri,ℓ}, for each i, j∈Nwith2j≤ci,T:
• Alice cut in the interval Iiin both rounds ri,2j−1andri,2j(meaning ari,2j−1, ari,2j∈Ii);
• Bob played different actions in the rounds ri,2j−1andri,2j.
We view rounds ri,2j−1andri,2jas a pair. For each i∈[P], there is at most one round ri,jthat does
not have a pair, namely round ri,ci,T: the last round Alice cut in Ii. However, this loss only represents
at most Prounds in total, which will translate to a sub-linear loss for either Alice’s or Bob’s utility
estimates.
Now we can bound the cumulative utility of each player.
Bob’s payoff. For each i, j∈Nwith2j≤ci,T, Bob’s payoff across the two rounds ri,2j−1and
ri,2jis bounded by
uri,2j−1
B +uri,2j
B≥1−VB(Ii) = 1−1
P. (86)
Since the rounds ri,jwithi∈[P]and2j≤ci,Trepresent a subset of the total set of rounds
[T], Bob’s cumulative payoff is at least
TX
t=1ut
B≥PX
i=1
X
j∈N:2j≤ci,Turi,2j−1
B +uri,2j
B

≥PX
i=1
X
j∈N:2j≤ci,T
1−1
P
 (By (86))
≥
1−1
PT−P
2(Since the sum is over at leastT−P
2pairs of rounds)
Since P=⌈√
T⌉ ≥√
T, we get
uB=TX
t=1ut
B≥
1−1
PT−P
2=T
2−⌈√
T⌉
2−T
2⌈√
T⌉+1
2
≥T
2−√
T+ 1
2−√
T
2+1
2
=T
2−√
T . (87)
Alice’s payoff. For each i, j∈Nwith2j≤ci,T, Alice’s payoff across rounds ri,2j−1andri,2jis
uri,2j−1
A +uri,2j
A≤1 +VA(Ii)≤1 +∆
δVB(Ii) = 1 +∆
δ·1
P. (88)
45There is at most one round without a pair for each interval Ii, namely round ri,ci,T: the last
time Alice cut in Ii. For each such round without a pair, we upper bound Alice’s payoff by
1. Then we can upper bound Alice’s cumulative utility by
TX
t=1ut
A≤P+PX
i=1
X
j∈N:2j≤ci,Turi,2j−1
A +uri,2j
A

≤P+PX
i=1
X
j∈N:2j≤ci,T
1 +∆
δ·1
P
 (By (88))
≤P+T
2
1 +∆
Pδ
(Since the sum is over at most T/2pairs)
=T
2+T
P·∆
2δ+P
≤T
2+√
T∆
2δ+ 2
(P=⌈√
T⌉ ≤2√
T)
This completes the proof.
46C Appendix: Fictitious play
In this section, we analyze the fictitious play dynamics. We first formally define fictitious play in
terms of the empirical frequency andempirical distribution :
• The empirical frequency of Alice’s play up to (but not including) time tis:
ϕt
A(x) =t−1X
τ=11{aτ=x}∀x∈[0,1].
• The empirical frequency of Bob’s play up to (but not including) time tis:
ϕt
B(x) =t−1X
τ=11{bτ=x}∀x∈ {L, R}.
• The empirical distribution of player i’s play up to (but not including) time tis:
pt
i(x) =ϕt
i(x)
(t−1),
Where x∈[0,1]for Alice and x∈ {L, R}for Bob.
Definition 9. (Fictitious play) In round t= 1, each player simultaneously selects an arbitrary action.
In every round t= 2, . . . , T , each player simultaneously best responds to the empirical distribution of
the other player up to time t. If there are multiple best responses, the player chooses one arbitrarily.
We now give the proof of Theorem 4 using lemmas that will be presented later, and then prove the
required lemmas.
Restatement of Theorem 4. When both Alice and Bob run fictitious play, regardless of tie-breaking
rules, their average payoff will converge to 1/2at a rate of O(1/√
T). Formally:
uA
T−1
2≤2√
10√
TanduB
T−1
2≤√
10√
T∀T≥5. (89)
Proof. The bounds on Bob’s payoff follow immediately from Lemma 21, which states that
T
2−√
10T≤TX
t=1ut
B≤T
2+√
10T . (90)
By Lemma 22,
T−√
10T≤TX
t=1 
ut
A+ut
B
≤T+√
10T. (91)
Subtracting equation (90) from (91) gives
T
2−2√
10T≤TX
t=1ut
A≤T
2+ 2√
10T . (92)
Since uA=PT
t=1ut
AanduB=PT
t=1ut
B, both players’ utilities are bounded as required, which
completes the proof.
To prove the required lemmas, we first introduce several notations. For ease of exposition, we often
use round t= 0as a fake round in which nothing actually happens and all the defined quantities are
zero.
Definition 10. Fort∈ {0,1, . . . , T }:
•Letrtbe the number of rounds in which Bob has picked R, up to and including round t.
47•Letℓtbe the number of rounds in which Bob has picked Lup to and including round t.
•Letαt=rt−ℓt.
•Letβt=Pt
i=1(2VB([0, ai])−1).
•Letρt=|αt|+|βt|, which we call the radius .
We remark that in the fake round of t= 0, all these variables have the value zero. Alice’s action
under fictitious play entirely depends on the variable αtwhile Bob’s action entirely depends on βt.
Overall, we will bound the payoffs using the growth of the radius ρtovert= 0,1, . . . , T . To this
end, we introduce two lemmas that will play an essential role throughout the proof.
First, the following lemma formally argues that the action taken by each player is guided by their
corresponding variable αandβt, respectively.
Lemma 11. Lett∈ {0,1, . . . , T −1}. Then the following hold for round t+ 1:
•Alice’s action with respect to αt:
–Ifαt>0, Alice will cut at 1.
–Ifαt<0, Alice will cut at 0.
–Ifαt= 0, any action would incur the same payoff, so she could cut anywhere.
•Bob’s action with respect to βt:
–Ifβt>0, Bob will pick L.
–Ifβt<0, Bob will pick R.
–Ifβt= 0, any action would incur the same payoff, so he could pick either LorR.
Proof. First, consider Alice’s choice. For t= 0, there is no history, so any choice has the same value
to her; accordingly, α0= 0. Fort≥1, the expected value she assigns to any particular cut location x
is:
1
t(rtVA([0, x]) +ℓtVA([x,1])) =1
t(rtVA([0, x]) +ℓt(1−VA([0, x]))
=rt−ℓt
tVA([0, x]) +ℓt
t
=αt
tVA([0, x]) +ℓt
t. (93)
From (93), we get that Alice’s cut decision is entirely based on αt. Ifαt<0, she will minimize
VA([0, x]), which means she cuts at 0. If αt>0, she will maximize VA([0, x]), which means she
cuts at 1. If αt= 0, then her choice of xdoesn’t affect her expected value.
Now consider Bob’s choice. For t= 0, there is no history, so Bob is indifferent between LandR;
accordingly, β0= 0. For t≥1, the expected value he assigns to choosing Lis:
EL=1
ttX
i=1VB([0, ai]). (94)
The expected value he assigns to choosing Ris:
ER=1
ttX
i=1VB([ai,1]). (95)
Combining (94) and (95), the difference between his expected value for choosing LandRis:
EL−ER= 
1
ttX
i=1VB([0, ai])!
− 
1
ttX
i=1VB([ai,1])!
=1
ttX
i=1(2VB([0, ai])−1) =βt
t.
(96)
From (96), we get that Bob’s decision is entirely based on βt. Ifβt<0, he values Rmore than L, so
he picks R. Ifβt>0, he values Lmore than R, so he picks L. Ifβt= 0, he values each equally.
48The following lemma further describes the evolution of αtandβtgiven the actions taken by the
players.
Lemma 12. For each round t∈[T]:
•Alice’s action affects βtas follows:
–If Alice cuts at 0in round t, then βt=βt−1−1.
–If Alice cuts at 1in round t, then βt=βt−1+ 1.
–If she cuts at x∈(0,1), then|βt−βt−1|<1.
•Bob’s action affects αtas follows:
–If Bob picks Lin round t, then αt=αt−1−1.
–If Bob picks Rin round t, then αt=αt−1+ 1.
Proof. First, we consider the impact of Alice’s cut point atonβt. Explicitly writing out the difference
βt−βt−1gives:
βt−βt−1=tX
i=1(2VB([0, ai])−1)−t−1X
i=1(2VB([0, ai])−1) = 2 VB([0, at])−1. (97)
Ifat= 0, then VB([0, at]) =VB([0,0]) = 0 , so by (97) we have βt−βt−1=−1as desired.
Ifat= 1, then VB([0, at]) =VB([0,1]) = 1 , so by (97) we have βt−βt−1= 1.
Ifat∈(0,1), then there is at least some cake on each side of at, so we have VB([0, at])∈(0,1). By
(97), we have βt−βt−1∈(−1,1), so|βt−βt−1|<1as stated by the lemma.
Second, we consider the impact of Bob’s choice on αt. Explicitly writing out the difference αt−αt−1,
we obtain the following:
αt−αt−1= (rt−ℓt)−(rt−1−ℓt−1) = (rt−rt−1)−(ℓt−ℓt−1) =1 bt=R
−1bt=L(98)
This completes the proof.
Let us elaborate more the dynamics of each player based on Lemma 11 and 12. If either of αtorβt
is exactly 0, the corresponding player will use their tie-breaking rules. Ignoring these cases, these
choices lead to movement through (αt, βt)space that spirals counter-clockwise around the origin at
exactly 45degree angles. Figure 18-(a) describes the overall dynamics of the variables (αt, βt).
The following lemma shows a symmetry that will help reduce the number of cases in the subsequent
analysis. Figure 18-(b) depicts the rotational symmetry of fictitious play dynamics in the α-β-plane
shown by the lemma. Specifically, the symmetry will allow us to assume αt≥0without loss of
generality when analyzing ρtandut
B.
Lemma 13. Consider an arbitrary pair of tie-breaking rules for both players. Consider the resulting
sequence for the variables αt, βtandut
Bfort= 0, . . . , T . Then, there exists another choice of
tie-breaking rules that would result in the sequence of variables ˜αt,˜βt, and ˜ut
Bfort= 0, . . . , T such
that
˜αt=−αt;˜βt=−βt; ˜ut
B=ut
B. (99)
Proof. The proof will proceed by induction.
Base case All of α0,˜α0,β0,˜β0,u0
B, and ˜u0
Bare zero, so (99) trivially holds.
Inductive hypothesis Assume that (99) holds for some t≥0.
491−1𝛽𝛼12340567891011−3−22(a) Overall dynamics
1𝛽
𝛼12340567891011
23−1−2 (b) Reflected dynamics by Lemma 13
Figure 18: Figure (a) represents the overall illustration of the dynamics of the action quantities αt
andβtfort= 0,1, . . . , T . The x-axis denotes the quantity of αtand the y-axis denotes that of βt.
Blue circles represent the sequence of points in the plane, where the number inside the circle denotes
the index t. Note that αtonly takes integer values, while βtpossibly takes noninteger values at some
rounds. Figure (b) also depicts an overall dynamics implemented by another pair of tiebreaking
rules guaranteed by Lemma 13. Note that each point is reflected with respect to the origin point.
Importantly, Lemma 13 guarantees that ρtandut
Bfort= 0,1, . . . , T remain exactly the same for
both dynamics.
Inductive step We show that (99) holds for t+ 1. Suppose that, under the original tie-breaking
rules, Alice cut at at+1and Bob picked bt+1∈ {L, R}in round t+ 1. First, we analyze for Alice.
Leta′
t+1∈[0,1]be the unique point for which
VB([0, at+1]) =VB([a′
t+1,1]). (100)
The point a′
t+1is uniquely defined since Bob’s density is strictly positive.
We show that there exists another choice of tie-breaking rules under which, starting from ˜αtand˜βt,
Alice cuts at a′
t+1in round t+ 1. We split into cases based on αt:
(αt>0):Then at+1= 1by Lemma 11. Since VB([0, at+1]) =VB([0,1]), we have a′
t+1= 0by
definition. By the inductive hypothesis, we have ˜αt=−αt, and so ˜αt<0. Then, regardless
of tie-breaking rules, Alice cuts at 0 =a′
t+1.
(αt<0):Then at+1= 0by Lemma 11. Since VB([0, at+1] = 0 = VB([1,1]), we have a′
t+1= 1
by definition. By the inductive hypothesis, ˜αt=−αt, and so ˜αt>0. Then, regardless of
tie-breaking rules, Alice cuts at 1 =a′
t+1.
(αt= 0) :Then Alice can break ties any way she likes by Lemma 11. However, ˜αt=−αt= 0,
so any cut point is a valid choice for her new tie-breaking rule. In particular, she can cut at
a′
t+1.
Second, we analyze for Bob. Let b′
t+1∈ {L, R}be such that b′
t+1̸=bt+1. We show that there exist
tie-breaking rules under which, starting from ˜αtand˜βt, Bob chooses b′
t+1. We split into cases based
onβt:
(βt>0):Then bt+1=Lby Lemma 11; therefore, b′
t+1=R. By the inductive hypothesis,
˜βt=−βt, so˜βt<0. Then, regardless of tie-breaking rules, Bob picks R=b′
t+1.
(βt<0):Then bt+1=Rby Lemma 11; therefore, b′
t+1=L. By the inductive hypothesis,
˜βt=−βt, so˜βt>0. Then, regardless of tie-breaking rules, Bob picks L=b′
t+1.
50(βt= 0) :Then Bob can break ties any way he likes by Lemma 11. However, ˜βt=−βt= 0, so
either LorRis a valid choice for his new tie-breaking rule. In particular, he can choose
b′
t+1.
Finally, we show that these opposite choices have exactly the desired effect on ˜αt+1,˜βt+1, and ˜ut+1
B.
Covering each in turn:
•Since Bob picks the opposite side under the trajectory associated with ˜αand˜β, the change
from αttoαt+1is in the opposite direction as the change from ˜αtto˜αt+1by Lemma 12.
By the inductive hypothesis, we have ˜αt=−αt, and so ˜αt+1=−αt+1.
•Since Alice picks the mirror image of her cut point under the trajectory associated with
˜αand˜β, the change from βttoβt+1is exactly opposite to the change from ˜βtto˜βt+1.
Specifically,
βt+1=βt+
2VB([0, at+1])−1
, (101)
while
˜βt+1=˜βt+
2VB([0, a′
t+1])−1
=˜βt+ 2(1−VB([a′
t+1,1]))−1
=˜βt+ 2(1−VB([0, at+1]))−1
=˜βt−
2VB([0, at+1])−1
. (102)
By the inductive hypothesis, we have ˜βt=−βt. Using equations (101) and (102), we obtain
˜βt+1=−βt+1.
•Under Alice’s new cut point a′
t+1, Bob’s valuation of the left and right sides of the cake
swap, i.e.,VB([0, a′
t+1]) =VB([at+1,1]). But he also chooses the opposite side, so he gets
exactly the same payoff as under the original tie-breaking rules in round t+ 1. Therefore,
˜ut+1
B=ut+1
B.
By induction, the claim holds for all t, which completes the proof.
In addition, it is helpful to distinguish between the rounds that cross an axis in the α-βplane and
those that do not. The following formalizes the definition of such rounds, which are depicted in
Figure 19-(a).
Definition 11. Anaxis-crossing round is a round twhere at least one of the following occurs:
•αt= 0
•βt+1>0, butβt≤0
•βt+1<0, butβt≥0.
Importantly, we will show that ρtcan strictly increase only if the current round is axis-crossing, while
it is non-decreasing over the entire game. The following lemma formalizes this observation. We
provide an example in Figure 19-(b).
Lemma 14. Lett∈ {0,1, . . . , T }. The radius ρtsatisfies the following properties:
(a)ρt=ρt+1iftis not axis-crossing
(b)ρt≤ρt+1≤2 +ρtiftis axis-crossing
(c)ρ0= 0
(d)ρt≥1fort≥1.
511−1𝛽𝛼12340567891011−3−22(a) Axis-crossing rounds
1−1𝛽𝛼12340567891011−3−22 (b) Non-decreasing radius ρtover rounds
Figure 19: Overall dynamics of αtandβtwith non axis-crossing rounds (blue circles) and axis-
crossing rounds (red circles). Figure (b) shows that the radius ρt=|αt|+|βt|is nondecreasing in t
as shown by Lemma 14. In particular, ρtremains the same for non axis-crossing rounds but possibly
increases for axis-crossing rounds.
In particular, the radius ρtis non-decreasing in t.
Proof. First, we will show (a) and (b). Consider an arbitrary round t∈ {0, . . . , T }. By Lemma 12,
we have |αt+1−αt| ≤1and|βt+1−βt| ≤1, so by the triangle inequality
ρt+1−ρt=|αt+1|+|βt+1| − |αt| − |βt|≤2. (103)
Therefore, ρt+1≤2 +ρt, as required by (b). Thus for (a) and (b) it remains to show that ρt+1≥ρt
∀t∈ {0, . . . , T }and that ρt+1=ρtiftis not axis-crossing.
By Lemma 13, it suffices to consider αt≥0. More precisely, this is because if αt≤0, then there
exists a tie-breaking rule with associated ˜αtsatisfying ˜αt=−αtfor every t= 0,1, . . . , T , so˜αt≥0.
Crucially, the lemma ensures the sequences ˜αtandαthave the same radius ρt.
We consider a few cases based on αtandβt, considering only αt≥0. Since αtis an integer, also
divide into αt≥1andαt= 0:
(αt≥1andβt>0):By Lemma 11 Alice will cut at 1 and Bob will pick L. Then by Lemma 12,
we have αt+1=αt−1andβt+1=βt+ 1. Therefore:
ρt+1=|αt+1|+|βt+1|=αt−1 +βt+ 1 (Since αt+1≥0)
=|αt|+|βt| (Because αt, βt≥0)
=ρt. (104)
(αt≥1andβt= 0) :Then Alice will cut at 1 and Bob will pick whichever piece he likes. There-
foreαt+1=αt±1andβt+1=βt+ 1 = 1 . Since βt≤0butβt+1>0, round tis
axis-crossing. What remains is to show that ρt+1≥ρtin this case:
ρt+1=|αt+1|+|βt+1| ≥ |αt| −1 + 1 (Because |x±y| ≥ |x| − |y|for all x, y)
=|αt|+|βt| (Since βt= 0)
=ρt. (105)
(αt≥1and−1< βt<0):Then Alice will cut at 1 and Bob will pick R. Therefore, αt+1=
αt+ 1andβt+1=βt+ 1. Since βt<0butβt+1>0, round tis axis-crossing. What
52remains is to show that ρt+1≥ρt:
ρt+1=|αt+1|+|βt+1|=αt+ 1 + |βt+ 1|
≥αt+ 1 + |βt| −1 (Since |x+y| ≥ |x| − |y|for all x, y)
=ρt. (106)
(αt≥1andβt≤ −1):Then Alice will cut at 1 and Bob will pick R. Therefore, αt+1=αt+ 1
andβt+1=βt+ 1. In this case, ρt+1=ρt:
ρt+1=|αt+1|+|βt+1|=αt+ 1−(βt+ 1) (Because βt+ 1≤0)
=|αt|+|βt| (Since βt≤0)
=ρt. (107)
(αt= 0andβt≥0):Then tis an axis-crossing round. Bob could pick either L or R, but either
way|αt+1|= 1. Alice could cut anywhere, but since |βt+1−βt| ≤1we can still conclude
|βt| − |βt+1| ≤1. Therefore:
ρt+1=|αt+1|+|βt+1| ≥1 +|βt| −1
=|αt|+|βt| (Since αt= 0)
=ρt. (108)
(αt= 0andβt<0):Then we can use the symmetry of Lemma 13 to consider βt>0instead,
which has already been covered.
In all cases, properties (a) and (b) must hold.
Now we show that the properties (c) and (d) hold. Property (c) follows from α0=β0= 0. Because
ρt+1≥ρtfor all t, property (d) would follow from showing ρ1≥1, which can be seen true from the
following inequality:
ρ1=|α1|+|β1|= 1 + |β1| (Since α0= 0, soα1=±1)
≥1. (109)
This finishes the proof.
Lemma 15. Suppose t−1is an axis-crossing round and τ > t−1is the next axis-crossing round
aftert−1. Then, there exists at least ρt−2and at most ρtrounds between them, i.e.,
ρt−2≤τ−t≤ρt. (110)
Proof. By Lemma 13, we can assume αt−1≥0. Then it suffices to consider only four types that the
axis-crossing round t−1could have:
(i)αt−1≥1,βt−1≤0, and βt>0;
(ii)αt−1≥1,βt−1≥0, and βt<0;
(iii)αt−1= 0andβt−1≥1;
(iv)αt−1= 0and0≤βt−1<1.
We show separately for each of the types (i)-(iv).
(i)αt−1≥1,βt−1≤0, and βt>0.Because αt−1>0, Alice will cut at 1 in round tby Lemma 11,
soβt=βt−1+ 1. Since βt−1andβthave different signs, it must be that −1< βt−1≤0
and0< βt≤1. As long as αremains positive, Alice will keep cutting at 1 and increasing
βby Lemma 11 and Lemma 12, so the next axis-crossing round τcannot be one where β
changes sign. Thus, it must be the one satisfying ατ= 0. Until then, Bob will keep picking
L, so αwill decrease by 1 every round. Therefore, this implies that τ=t+αt. To show
τ−t≤ρtas required by (110), we have
τ−t=αt≤ |αt|+|βt| ≤ρt.
53To prove ρt−2≤τ−t, observe that αt≥αt−1−1. Since αt−1≥1, we have αt≥0.
Thus
τ−t=αt
≥ |αt|+|βt| −1 (Since 0< βt≤1andαt≥0)
=ρt−1> ρt−2. (111)
(ii)αt−1≥1,βt−1≥0, and βt<0.Because αt−1>0, Alice will cut at 1in round t, soβt=
βt−1+ 1. But then βt> βt−1≥0, contradicting βt<0. Therefore, this case cannot
happen.
(iii)αt−1= 0andβt−1≥1.By Lemma 11, Alice can cut wherever she likes, but Bob will pick L.
Wherever Alice cuts, we will have αt=−1andβt≥0. In order to return to α= 0, Bob
must start picking R, but he cannot do so until β≤0by Lemma 11. Therefore, the next
axis-crossing round τwill be the one where βτ+1<0andβτ≥0. Until then, Alice will
keep cutting at 0, so βwill decrease by 1 every round. Therefore, τ=t+⌊βt⌋, and this
implies that
τ−t=⌊βt⌋ ≤ |αt|+|βt|=ρt.
Again to show ρt−2≤τ−t, observe that
τ−t=⌊βt⌋
≥ |αt| −1 +|βt| −1 (Since αt=−1andβt≥0)
=ρt−2.
(iv)αt−1= 0and0≤βt−1<1.Under these constraints, we have ρt−1=|αt−1|+|βt−1|<1,
so part (d) of Lemma 14 implies that t−1 = 0 . Therefore, we have αt−1=βt−1= 0.
Accounting for all possible choices Alice and Bob can make, it must be the case that
αt=±1and−1≤βt≤1, which implies that 1≤ρt≤2. Thus it suffices to show that
τ−t≤1. We have a few cases:
•Ifαt= 1andβt>0, then Bob will pick L in round t+ 1by Lemma 11. Therefore,
αt+1= 0, soτ=t+ 1.
•Ifαt= 1 and−1< βt≤0, then Alice will cut at 1 in round t+ 1by Lemma 11.
Therefore, βt+1>0, so round tis axis-crossing and τ−t= 0.
•Ifαt= 1andβt=−1, then Alice will cut at 1 and Bob will pick R in round t+ 1by
Lemma 11. That will lead to αt+1= 2andβt+1= 0, so round t+ 1is axis-crossing.
Therefore, τ−t= 1.
• Ifαt=−1, we can reduce to the αt= 1case by Lemma 13.
Thus for all types (i)-(iv), it follows that ρt−2≤τ−t≤ρtas desired.
The next two lemmas show different conditions under which ρmust increase. The first (Lemma 16)
is more technical in nature, while the second (Lemma 17) is key to bounding the players’ total payoff.
Lemma 16. Suppose there exists a round tsuch that βt̸∈Z. Letτ > t be the first round after tsuch
thatβtβτ≤0,i.e.,βτis zero or has the opposite sign of βt. Then the following inequality holds:
ρτ≥ ⌊ρt⌋+ 1.
Proof. Again by Lemma 13, we can assume without loss of generality that βt≥0. Since βt̸∈Z, we
can further assume βt>0.
Suppose that βτ̸∈Z. Because τ > t is the first round after twithβτ≤0, we must have βτ−1>0.
Since βτ̸∈Z, we also have βτ<0. Combining |βτ−βτ−1| ≤1andβτ<0yields 0< βτ−1<1.
Since βτ−1>0, Bob picked L in round τby Lemma 11, so we have ατ=ατ−1−1. Asβτ< βτ−1,
54Alice must have not cut at 1 in round τby Lemma 12. This implies that ατ−1≤0. Finally, we obtain
ρτ=|ατ|+|βτ| ≥ |ατ−1−1|+ 0 (Since ατ=ατ−1−1)
= 1−ατ−1 (Since ατ−1≤0)
= 1 + |ατ−1|+⌊|βτ−1|⌋ (Since ατ−1≤0and0< βτ−1<1)
= 1 + ⌊ρτ−1⌋ (Since ατ−1∈Z)
≥1 +⌊ρt⌋. (By Lemma 14)
On the other hand, suppose βτ∈Z. By Lemma 14, we have ρτ≥ρt. Since βt̸∈Zbutαt∈Zand
ατ∈Z, we have ρτ∈Zbutρt̸∈Z. Therefore, ⌊ρt⌋< ρt≤ρτ. Since both ⌊ρt⌋ ∈Zandρτ∈Z,
we have ρτ≥ ⌊ρt⌋+ 1.
Lemma 17. Lettbe a round in which Alice cuts at at∈(0,1). Letτ−1be the first axis-crossing
round strictly after t−1. Then ρτ≥ ⌊ρt−1⌋+ 1.
Proof. By Lemma 11, Alice will cut at 0 or 1 if αt−1̸= 0. As Alice does not cut at 0or1in
round t, this implies that αt−1= 0. First, if βt−1= 0, then Lemma 14 implies t−1 = 0 , so
ρτ≥1 =⌊ρt−1⌋+ 1as required.
Otherwise, by Lemma 13, we can assume without loss of generality that βt−1>0. Because
ρt−1≥ |βt−1|>0, Lemma 14 implies t−1≥1. By part (d) of Lemma 14, we further have
1≤ρt−1=|αt−1|+|βt−1|=βt−1.
Since Alice does not cut at 0 in round t, we have βt> βt−1−1by Lemma 11, which implies
thatβt>0. As βt−1>0, Bob picked L in round tby Lemma 11, so we have αt<0. Again
by Lemma 11, for αto return to 0, Bob would have to start picking R, but he won’t until βstops
being positive. Therefore, the next axis-crossing round after twill be one where βcrosses into being
non-positive from positive, so βτ<0.
Lets > t−1be the first round after t−1such that βs≤0. Because βτ<0, we have s≤τ.
Because βt>0, we have s > t .
Ifβt−1̸∈Z, then applying Lemma 16 to t−1yields ρs≥ ⌊ρt−1⌋+ 1. By Lemma 14, we have
ρτ≥ρs, and so ρτ≥ρs≥ ⌊ρt−1⌋+ 1as required.
Ifβt̸∈Z, then applying Lemma 16 to tyields ρs≥ ⌊ρt⌋+ 1. By Lemma 14, we have ρτ≥ρsand
ρt≥ρt−1, and so ρτ≥ρs≥ ⌊ρt⌋+ 1≥ ⌊ρt−1⌋+ 1as required.
Else, we have βt−1, βt∈Z. Since Alice did not cut at 0 or 1 in round t, by Lemma 12 we have
|βt−βt−1|<1. Since βt, βt−1∈Z, we get βt−1=βt. Moreover, since αt−1= 0, we have
|αt|=|αt−1±1|= 1. This implies that
ρτ≥ρt (By Lemma 14)
=ρt−1+ 1 (Since βt=βt−1and|αt|=|αt−1|+ 1)
≥ ⌊ρt−1⌋+ 1.
This completes the proof.
The following lemma bounds Bob’s total payoff using the radius ρt.
Lemma 18. For every round t≥0, the following inequalities hold:
−ρt≤tX
i=1(2ui
B−1)≤ρt. (112)
Proof. We will first show the following stronger set of inequalities by induction on t:
0≤ |αt|+tX
i=1(2ui
B−1)≤ρt. (113)
As a base case, consider t= 0. Before anything has happened, all three sides of (113) are zero, so the
inequalities trivially hold.
55Now assume that (113) holds for some t≥0, and we will prove that it still holds for round t+ 1.
We consider three cases separately in what follows, depending on the values of αtandβt. Note that
again by Lemma 13, it suffices to only consider cases where αt≥0.
•Ifαt>0, Alice will cut at 1 in round t+ 1by Lemma 11. If Bob picks L, then he will
receive a payoff of 1 and αtwill decrease by 1 due to Lemma 12. If Bob picks R, then he
will receive a payoff of 0 and αtwill increase by 1 due to Lemma 12. In either case, the
changes to |αt|+Pt
i=1(2uB(i)−1)cancel out, which implies that
|αt|+tX
i=1(2ui
B−1) =|αt+1|+t+1X
i=1(2ui
B−1). (114)
Further, by Lemma 14 we have ρt+1≥ρt. Together with the induction hypothesis (113),
this concludes
0≤ |αt+1|+t+1X
i=1(2ui
B−1)≤ρt+1,
and thus the induction holds for the first case.
•Ifαt= 0andβt≥0, then regardless of whether Bob picks L or R in round t+ 1we have
|αt+1|=|0±1|= 1asαnecessarily changes by 1. Therefore, we have
 
|αt+1|+t+1X
i=1(2ui
B−1)!
− 
|αt|+tX
i=1(2ui
B−1)!
= 1 + 2 ut+1
B−1
= 2ut+1
B (115)
Also, the change in ρcan be bounded as follows:
ρt+1−ρt=|αt+1|+|βt+1| − |αt| − |βt|
= 1 +t+1X
i=1(2VB([0, ai])−1)−0−βt (βt≥0)
= 1 + |(2VB([0, at+1])−1) +βt| −βt
≥1 + 2 VB([0, at+1])−1 (Removing the absolute value)
= 2VB([0, at+1]) (116)
If Bob picked Lin round t+ 1, this is exactly the same as (115). If Bob picked R, then by
Lemma 11 and the assumption that βt≥0we must have βt= 0. The change in the radius
can be bounded as follows:
ρt+1−ρt=|αt+1|+|βt+1| − |αt| − |βt|
= 1 + |2VB([0, at+1])−1| −0−0 (βt= 0)
= 1 + |1−2VB([at+1,1])| (VB([0, at+1]) +VB([at+1,1]) = 1 )
= 1 + |−(1−2VB([at+1,1]))|
≥1−1 + 2 VB([at+1,1]) (Removing the absolute value)
= 2ut+1
B (Since Bob picked R)
In either case, the radius increased by at least as much as the middle of (113). More precisely,
by the induction hypothesis (113), we obtain
|αt+1|+tX
i=1(2ui
B−1) =|αt|+tX
i=1(2ui
B−1) + 2 ut+1
B−1 +|αt+1| − |αt|
≥0 + 2 ut+1
B (αt= 0and|αt+1|= 1)
≥0. (ut+1
B≥0)
56Note further that
|αt+1|+tX
i=1(2ui
B−1) =|αt|+tX
i=1(2ui
B−1) + 2 ut+1
B−1 +|αt+1| − |αt|
≤ρt+ 2ut+1
B (By the induction hypothesis)
=ρt+1. (ρt+1−ρt= 2ut+1
B)
This finishes the proof of the induction for the second case.
•Ifαt= 0 andβt<0, then by Lemma 13 we can consider αt= 0 andβt>0instead,
which has already been shown above.
In all cases, the inductive step holds. Therefore, by induction principle, (113) holds for all t.
Subtracting |αt|from all three sides of it, we obtain
−|αt| ≤tX
i=1(2ui
B−1)≤ |βt|.
Since ρt=|αt|+|βt|, this immediately implies the desired bounds.
Now that we have bounds on the relevant events in terms of α,β, and ρ, we can bound them as
functions of Tto obtain our final result.
Lemma 19. Letn≥7. Lett1, t2, . . . , t nbe a sequence of rounds such that for all i∈[n−1]the
following inequality holds:
ρti+1≥ ⌊ρti⌋+ 1. (117)
Then tn−t1>1
10n2.
Proof. First, we will show by induction that, for i∈[n], we have ρti≥i−1. For the base case,
ρt1≥ρ0= 0, so the inequality trivially holds.
Now assume ρti≥i−1for some i∈[n−1]and we will prove that the induction step holds for the
casei+ 1. By (117), observe that
ρti+1≥ ⌊ρti⌋+ 1
≥ ⌊i−1⌋+ 1
= (i+ 1)−1.
Thus, by the induction principle we have
ρti≥i−1fori= 1, . . . , n (118)
Now consider an arbitrary i∈[n−1]. Note that ρti+1≥ ⌊ρti⌋+ 1implies ρti+1> ρti. Therefore,
by Lemma 14, there must be an axis-crossing round ciamong the interval [ti, ti+1). This is because
if this is not true, we have ρti+1=ρtiwhich contradicts ρti+1> ρti. Repeating the same argument
for each i, we conclude that there exists a sequence of rounds c1, c2, . . . , c n−1each of which is
axis-crossing, and satisfies the following inequality for every i∈[n−1]:
ti≤ci< ti+1 (119)
In addition, for any i∈[n−1], we observe that
ci+1−(ci+ 1)≥ρci+1−2 (By Lemma 15, with τ=ci+1andt=ci+ 1)
≥ρti−2 (By (119))
≥i−3 (By (118))
Slightly rearranging, we obtain
ci+1−ci≥i−2∀i∈[n−1]. (120)
57Combining (119) and (120), we finally obtain
tn−t1> cn−1−c1 (By (119))
=n−2X
i=1(ci+1−ci)
≥n−2X
i=1(i−2) (By (120))
=1
2n2−7
2n+ 5.
Forn≥7, we have1
2n2−7
2n+ 5≥1
10n2,4and so tn−t1> n2/10, as required.
The following lemma will finally be combined with Lemma 18 to obtain the desired bound for Bob’s
payoff.
Lemma 20. ForT≥5, the final radius ρTsatisfies the following:
ρT≤2√
10T.
Proof. Lett1= 0, and for i≥2recursively define tibe the first round after ti−1satisfying
ρti≥ ⌊ρti−1⌋+ 1. Letnbe the last index of such tigiven the time horizon T.
As an immediate corollary of Lemma 19, we have
n≤max{7,√
10T}.
ForT≥5, this implies that
n≤√
10T (121)
By Lemma 14, we also know that ρcan increase by at most 2per round. Furthermore, since tnis the
last element in the sequence {ti}i∈[n], we have ρT<⌊ρtn⌋+ 1. Relaxing this slightly, we have
ρT≤ρtn+ 2 (122)
Therefore, we obtain the following inequalities:
ρT≤2 +ρtn (By (122))
= 2 +n−1X
i=1(ρi+1−ρi)
≤2 + 2( n−1) (By Lemma 14)
= 2n (123)
Putting (121) and (123) together, we obtain
ρT≤2√
10T,
which finishes the proof of the lemma.
Using the above bound on the radius together with Lemma 18, Bob’s payoff can now be bounded as
follows.
Lemma 21. ForT≥5, Bob’s total payoff satisfies:
T
2−√
10T≤TX
t=1ut
B≤T
2+√
10T .
4We omit the elementary calculus.
58Proof. We start from the inequality (112). Halving all three sides of (112) for t=Tand adding
T/2, we obtain
T
2−1
2ρT≤TX
t=1ut
B≤T
2+1
2ρT.
Using the upper bound ρT≤2√
10Tfrom Lemma 20 gives the desired bounds.
Combined with Lemma 21, Alice’s payoff can eventually be bounded using the following lemma,
which effectively bounds the summation of Alice and Bob’s total payoff.
Lemma 22. ForT≥5, the summation of total payoff to Alice and Bob satisfies the following:
T−√
10T≤TX
t=1 
ut
A+ut
B
≤T+√
10T .
Proof. Given the time horizon T, lets1, s2, . . . , s kbe the rounds in which Alice cuts at a point other
than0or1, where kdenotes the number of such rounds. These are the only rounds in which the total
payoff ut
A+ut
Bis not necessarily 1. The total payoff in these rounds can be bounded as
0≤usi
A+usi
B≤2,
for any i∈[k]. Thus, we obtain
T−k≤TX
t=1ut
A+ut
B≤T+k.
Therefore, it suffices to prove that k≤√
10T.
Ifk <7, the proof follows as k <7≤√
10T.
Otherwise, we have k≥7. For each si, letτibe the round after the next axis-crossing round after
si−1. Consider sifor an arbitrary i∈[k]. Due to Lemma 11, if αsi−1̸= 0then Alice cuts at 0or1
in round si, which contradicts our definition of round si. Thus we have αsi−1= 0. This argument
holds for arbitrary i∈[k], so both si−1andsi+1−1are axis-crossing rounds. Moreover, since
bothαsi−1= 0andαsi+1−1= 0, there must have been some rounds between si−1andsi+1−1
where Bob picked Land some where he picked R. Therefore, βmust have changed sign at least
once, so there is another axis-crossing round in between si−1andsi+1−1where βchanged sign.
This implies that for every i= 1, . . . , k −1, the next axis crossing round τiaftersi−1should exist
at least before si+1−1,i.e.,
τi≤si+1−1. (124)
Due to the monotonicity of ρby Lemma 14, for any i∈ {1, . . . , k −1}we have
ρsi+1−1≥ρτi (By (124))
≥ ⌊ρsi−1⌋+ 1. (By Lemma 17)
By Lemma 19, we have:
(sk−1)−(s1−1)>1
10k2. (125)
Re-arranging (125) and using the fact that sk−s1≤T, we obtain k <√
10T. This finishes the
proof of the case k≥7, which completes the lemma.
59NeurIPS Paper Checklist
1.Claims
Question: Do the main claims made in the abstract and introduction accurately reflect the
paper’s contributions and scope?
Answer: [Yes] .
Justification: We prove all the theorems and propositions that are summarized in the abstract.
Guidelines:
•The answer NA means that the abstract and introduction do not include the claims
made in the paper.
•The abstract and/or introduction should clearly state the claims made, including the
contributions made in the paper and important assumptions and limitations. A No or
NA answer to this question will not be perceived well by the reviewers.
•The claims made should match theoretical and experimental results, and reflect how
much the results can be expected to generalize to other settings.
•It is fine to include aspirational goals as motivation as long as it is clear that these goals
are not attained by the paper.
2.Limitations
Question: Does the paper discuss the limitations of the work performed by the authors?
Answer: [Yes] .
Justification: The paper clearly states the modelling assumptions under which the theorems
and propositions hold. We also suggest a few directions for future work in Concluding
Remarks.
Guidelines:
•The answer NA means that the paper has no limitation while the answer No means that
the paper has limitations, but those are not discussed in the paper.
• The authors are encouraged to create a separate "Limitations" section in their paper.
•The paper should point out any strong assumptions and how robust the results are to
violations of these assumptions (e.g., independence assumptions, noiseless settings,
model well-specification, asymptotic approximations only holding locally). The authors
should reflect on how these assumptions might be violated in practice and what the
implications would be.
•The authors should reflect on the scope of the claims made, e.g., if the approach was
only tested on a few datasets or with a few runs. In general, empirical results often
depend on implicit assumptions, which should be articulated.
•The authors should reflect on the factors that influence the performance of the approach.
For example, a facial recognition algorithm may perform poorly when image resolution
is low or images are taken in low lighting. Or a speech-to-text system might not be
used reliably to provide closed captions for online lectures because it fails to handle
technical jargon.
•The authors should discuss the computational efficiency of the proposed algorithms
and how they scale with dataset size.
•If applicable, the authors should discuss possible limitations of their approach to
address problems of privacy and fairness.
•While the authors might fear that complete honesty about limitations might be used by
reviewers as grounds for rejection, a worse outcome might be that reviewers discover
limitations that aren’t acknowledged in the paper. The authors should use their best
judgment and recognize that individual actions in favor of transparency play an impor-
tant role in developing norms that preserve the integrity of the community. Reviewers
will be specifically instructed to not penalize honesty concerning limitations.
3.Theory Assumptions and Proofs
Question: For each theoretical result, does the paper provide the full set of assumptions and
a complete (and correct) proof?
60Answer: [Yes]
Justification: The main body of the paper has our model, theorem statements, and proof
sketches. The formal proofs are in the appendix.
Guidelines:
• The answer NA means that the paper does not include theoretical results.
•All the theorems, formulas, and proofs in the paper should be numbered and cross-
referenced.
•All assumptions should be clearly stated or referenced in the statement of any theorems.
•The proofs can either appear in the main paper or the supplemental material, but if
they appear in the supplemental material, the authors are encouraged to provide a short
proof sketch to provide intuition.
•Inversely, any informal proof provided in the core of the paper should be complemented
by formal proofs provided in appendix or supplemental material.
• Theorems and Lemmas that the proof relies upon should be properly referenced.
4.Experimental Result Reproducibility
Question: Does the paper fully disclose all the information needed to reproduce the main ex-
perimental results of the paper to the extent that it affects the main claims and/or conclusions
of the paper (regardless of whether the code and data are provided or not)?
Answer: [Yes] .
Justification: We included a few example trajectories from the fictitious play dynamic. The
code is included with the submission. All our results are proved mathematically and the
experimental data is purely illustrative.
Guidelines:
• The answer NA means that the paper does not include experiments.
•If the paper includes experiments, a No answer to this question will not be perceived
well by the reviewers: Making the paper reproducible is important, regardless of
whether the code and data are provided or not.
•If the contribution is a dataset and/or model, the authors should describe the steps taken
to make their results reproducible or verifiable.
•Depending on the contribution, reproducibility can be accomplished in various ways.
For example, if the contribution is a novel architecture, describing the architecture fully
might suffice, or if the contribution is a specific model and empirical evaluation, it may
be necessary to either make it possible for others to replicate the model with the same
dataset, or provide access to the model. In general. releasing code and data is often
one good way to accomplish this, but reproducibility can also be provided via detailed
instructions for how to replicate the results, access to a hosted model (e.g., in the case
of a large language model), releasing of a model checkpoint, or other means that are
appropriate to the research performed.
•While NeurIPS does not require releasing code, the conference does require all submis-
sions to provide some reasonable avenue for reproducibility, which may depend on the
nature of the contribution. For example
(a)If the contribution is primarily a new algorithm, the paper should make it clear how
to reproduce that algorithm.
(b)If the contribution is primarily a new model architecture, the paper should describe
the architecture clearly and fully.
(c)If the contribution is a new model (e.g., a large language model), then there should
either be a way to access this model for reproducing the results or a way to reproduce
the model (e.g., with an open-source dataset or instructions for how to construct
the dataset).
(d)We recognize that reproducibility may be tricky in some cases, in which case
authors are welcome to describe the particular way they provide for reproducibility.
In the case of closed-source models, it may be that access to the model is limited in
some way (e.g., to registered users), but it should be possible for other researchers
to have some path to reproducing or verifying the results.
615.Open access to data and code
Question: Does the paper provide open access to the data and code, with sufficient instruc-
tions to faithfully reproduce the main experimental results, as described in supplemental
material?
Answer: [Yes] .
Justification: This is a theoretical paper, so the paper provides all the proofs for the stated
theorems. We also include the code for the fictitious play dynamic, which we illustrate an
example trajectory of in the main file.
Guidelines:
• The answer NA means that paper does not include experiments requiring code.
•Please see the NeurIPS code and data submission guidelines ( https://nips.cc/
public/guides/CodeSubmissionPolicy ) for more details.
•While we encourage the release of code and data, we understand that this might not be
possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not
including code, unless this is central to the contribution (e.g., for a new open-source
benchmark).
•The instructions should contain the exact command and environment needed to run to
reproduce the results. See the NeurIPS code and data submission guidelines ( https:
//nips.cc/public/guides/CodeSubmissionPolicy ) for more details.
•The authors should provide instructions on data access and preparation, including how
to access the raw data, preprocessed data, intermediate data, and generated data, etc.
•The authors should provide scripts to reproduce all experimental results for the new
proposed method and baselines. If only a subset of experiments are reproducible, they
should state which ones are omitted from the script and why.
•At submission time, to preserve anonymity, the authors should release anonymized
versions (if applicable).
•Providing as much information as possible in supplemental material (appended to the
paper) is recommended, but including URLs to data and code is permitted.
6.Experimental Setting/Details
Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
results?
Answer: [NA] .
Justification: As mentioned above, we just included one example trajectory for visualization
purposes. Code which generates similar trajectories is included. Our results are not based
on experiments.
Guidelines:
• The answer NA means that the paper does not include experiments.
•The experimental setting should be presented in the core of the paper to a level of detail
that is necessary to appreciate the results and make sense of them.
•The full details can be provided either with the code, in appendix, or as supplemental
material.
7.Experiment Statistical Significance
Question: Does the paper report error bars suitably and correctly defined or other appropriate
information about the statistical significance of the experiments?
Answer: [NA] .
Justification: This is not relevant to our paper.
Guidelines:
• The answer NA means that the paper does not include experiments.
•The authors should answer "Yes" if the results are accompanied by error bars, confi-
dence intervals, or statistical significance tests, at least for the experiments that support
the main claims of the paper.
62•The factors of variability that the error bars are capturing should be clearly stated (for
example, train/test split, initialization, random drawing of some parameter, or overall
run with given experimental conditions).
•The method for calculating the error bars should be explained (closed form formula,
call to a library function, bootstrap, etc.)
• The assumptions made should be given (e.g., Normally distributed errors).
•It should be clear whether the error bar is the standard deviation or the standard error
of the mean.
•It is OK to report 1-sigma error bars, but one should state it. The authors should
preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis
of Normality of errors is not verified.
•For asymmetric distributions, the authors should be careful not to show in tables or
figures symmetric error bars that would yield results that are out of range (e.g. negative
error rates).
•If error bars are reported in tables or plots, The authors should explain in the text how
they were calculated and reference the corresponding figures or tables in the text.
8.Experiments Compute Resources
Question: For each experiment, does the paper provide sufficient information on the com-
puter resources (type of compute workers, memory, time of execution) needed to reproduce
the experiments?
Answer: [NA] .
Justification: The code we included is a very simple dynamical system that can be run on
any laptop in a minute or two.
Guidelines:
• The answer NA means that the paper does not include experiments.
•The paper should indicate the type of compute workers CPU or GPU, internal cluster,
or cloud provider, including relevant memory and storage.
•The paper should provide the amount of compute required for each of the individual
experimental runs as well as estimate the total compute.
•The paper should disclose whether the full research project required more compute
than the experiments reported in the paper (e.g., preliminary or failed experiments that
didn’t make it into the paper).
9.Code Of Ethics
Question: Does the research conducted in the paper conform, in every respect, with the
NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines ?
Answer: [Yes]
Justification: We do not propose a model, use a dataset, or involve human participants. Our
theoretical results do not have immediate possibilities for misuse.
Guidelines:
•The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
•If the authors answer No, they should explain the special circumstances that require a
deviation from the Code of Ethics.
•The authors should make sure to preserve anonymity (e.g., if there is a special consid-
eration due to laws or regulations in their jurisdiction).
10.Broader Impacts
Question: Does the paper discuss both potential positive societal impacts and negative
societal impacts of the work performed?
Answer: [NA]
Justification: We do not propose a concrete technology. Our idealized setting does not have
any immediate societal applications.
Guidelines:
63• The answer NA means that there is no societal impact of the work performed.
•If the authors answer NA or No, they should explain why their work has no societal
impact or why the paper does not address societal impact.
•Examples of negative societal impacts include potential malicious or unintended uses
(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
(e.g., deployment of technologies that could make decisions that unfairly impact specific
groups), privacy considerations, and security considerations.
•The conference expects that many papers will be foundational research and not tied
to particular applications, let alone deployments. However, if there is a direct path to
any negative applications, the authors should point it out. For example, it is legitimate
to point out that an improvement in the quality of generative models could be used to
generate deepfakes for disinformation. On the other hand, it is not needed to point out
that a generic algorithm for optimizing neural networks could enable people to train
models that generate Deepfakes faster.
•The authors should consider possible harms that could arise when the technology is
being used as intended and functioning correctly, harms that could arise when the
technology is being used as intended but gives incorrect results, and harms following
from (intentional or unintentional) misuse of the technology.
•If there are negative societal impacts, the authors could also discuss possible mitigation
strategies (e.g., gated release of models, providing defenses in addition to attacks,
mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
feedback over time, improving the efficiency and accessibility of ML).
11.Safeguards
Question: Does the paper describe safeguards that have been put in place for responsible
release of data or models that have a high risk for misuse (e.g., pretrained language models,
image generators, or scraped datasets)?
Answer: [NA]
Justification: The paper poses no such risks.
Guidelines:
• The answer NA means that the paper poses no such risks.
•Released models that have a high risk for misuse or dual-use should be released with
necessary safeguards to allow for controlled use of the model, for example by requiring
that users adhere to usage guidelines or restrictions to access the model or implementing
safety filters.
•Datasets that have been scraped from the Internet could pose safety risks. The authors
should describe how they avoided releasing unsafe images.
•We recognize that providing effective safeguards is challenging, and many papers do
not require this, but we encourage authors to take this into account and make a best
faith effort.
12.Licenses for existing assets
Question: Are the creators or original owners of assets (e.g., code, data, models), used in
the paper, properly credited and are the license and terms of use explicitly mentioned and
properly respected?
Answer: [NA] .
Justification: We wrote the paper and the simulation of fictitious play, which is a very
standard type of dynamic. There is no license or asset used from other sources. We cite all
the related papers in the literature that we are aware of.
Guidelines:
• The answer NA means that the paper does not use existing assets.
• The authors should cite the original paper that produced the code package or dataset.
•The authors should state which version of the asset is used and, if possible, include a
URL.
• The name of the license (e.g., CC-BY 4.0) should be included for each asset.
64•For scraped data from a particular source (e.g., website), the copyright and terms of
service of that source should be provided.
•If assets are released, the license, copyright information, and terms of use in the
package should be provided. For popular datasets, paperswithcode.com/datasets
has curated licenses for some datasets. Their licensing guide can help determine the
license of a dataset.
•For existing datasets that are re-packaged, both the original license and the license of
the derived asset (if it has changed) should be provided.
•If this information is not available online, the authors are encouraged to reach out to
the asset’s creators.
13.New Assets
Question: Are new assets introduced in the paper well documented and is the documentation
provided alongside the assets?
Answer: [NA] .
Justification: Not applicable.
Guidelines:
• The answer NA means that the paper does not release new assets.
•Researchers should communicate the details of the dataset/code/model as part of their
submissions via structured templates. This includes details about training, license,
limitations, etc.
•The paper should discuss whether and how consent was obtained from people whose
asset is used.
•At submission time, remember to anonymize your assets (if applicable). You can either
create an anonymized URL or include an anonymized zip file.
14.Crowdsourcing and Research with Human Subjects
Question: For crowdsourcing experiments and research with human subjects, does the paper
include the full text of instructions given to participants and screenshots, if applicable, as
well as details about compensation (if any)?
Answer: [NA]
Justification: The paper does not involve crowdsourcing nor research with human subjects.
Guidelines:
•The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
•Including this information in the supplemental material is fine, but if the main contribu-
tion of the paper involves human subjects, then as much detail as possible should be
included in the main paper.
•According to the NeurIPS Code of Ethics, workers involved in data collection, curation,
or other labor should be paid at least the minimum wage in the country of the data
collector.
15.Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
Subjects
Question: Does the paper describe potential risks incurred by study participants, whether
such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
approvals (or an equivalent approval/review based on the requirements of your country or
institution) were obtained?
Answer: [NA]
Justification: The paper does not involve crowdsourcing nor research with human subjects.
Guidelines:
•The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
65•Depending on the country in which research is conducted, IRB approval (or equivalent)
may be required for any human subjects research. If you obtained IRB approval, you
should clearly state this in the paper.
•We recognize that the procedures for this may vary significantly between institutions
and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
guidelines for their institution.
•For initial submissions, do not include any information that would break anonymity (if
applicable), such as the institution conducting the review.
66