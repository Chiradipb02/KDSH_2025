DeepDRK: Deep Dependency Regularized Knockoff
for Feature Selection
Hongyu Shen1Yici Yan2Zhizhen Zhao1
Department of Electrical and Computer Engineering1,
University of Illinois at Urbana Champaign.
Department of Statistics2,
University of Illinois at Urbana Champaign.
{hongyu2, yiciyan2, zhizhenz }@illinois.edu
Abstract
Model-X knockoff has garnered significant attention among various feature selec-
tion methods due to its guarantees for controlling the false discovery rate (FDR).
Since its introduction in parametric design, knockoff techniques have evolved to
handle arbitrary data distributions using deep learning-based generative models.
However, we have observed limitations in the current implementations of the deep
Model-X knockoff framework. Notably, the “swap property” that knockoffs require
often faces challenges at the sample level, resulting in diminished selection power.
To address these issues, we develop “Deep Dependency Regularized Knockoff
(DeepDRK),” a distribution-free deep learning method that effectively balances
FDR and power. In DeepDRK, we introduce a novel formulation of the knockoff
model as a learning problem under multi-source adversarial attacks. By employing
an innovative perturbation technique, we achieve lower FDR and higher power.
Our model outperforms existing benchmarks across synthetic, semi-synthetic, and
real-world datasets, particularly when sample sizes are small and data distributions
are non-Gaussian.
1 Introduction
Feature selection (FS) has garnered significant attention over the past few decades due to the
rapidly increasing dimensionality of data, as well as the associated computational, storage, and
noise challenges [ 22,15]. Successfully identifying the true informative features among inputs can
significantly enhance the performance of analysis frameworks and drive advancements in fields such
as biology, neuroscience, medicine, economics, and social sciences [ 15,55]. However, the task
of accurately pinpointing informative features is often considered nearly impossible, particularly
due to the limited availability of data relative to the increasing dimensionality [ 55,11]. A practical
approach to address this challenge is the development of algorithms designed to select features while
maintaining controlled error rates. Targeting this goal, Model-X knockoffs, a novel framework, is
proposed in [ 4,11] to select relevant features while controlling the false discovery rate (FDR). In
contrast to the classical setup, where assumptions on the correlations between input features and the
response are imposed [ 6,19], the Model-X knockoff framework only requires a linear relationship
between the response and the features. With a strong finite-sample FDR guarantee, Model-X knockoff
saw broad applications in domains such as biology, neuroscience, and medicine, where the sample
size is limited [4, 11, 27, 47, 55, 38, 62].
There have been considerable developments of knockoffs since its debut. In scenarios where feature
distributions are complex, various deep learning methods [ 27,47,55,38,62] have been proposed.
However, we observe major limitations despite improved performance. First, the performance of
existing methods varies across different data distributions. Second, the quality of selection declines
38th Conference on Neural Information Processing Systems (NeurIPS 2024).when the sample size is relatively small. Third, training the deep knockoff generation models can be
challenging due to competing loss terms in the training objective. We elaborate on the drawbacks in
Sections 2.2 and 3.2.
In this paper, we address these issues by proposing the Deep Dependency Regularized Knockoff
(DeepDRK), a deep learning-based pipeline. We formulate the knockoff generation as an adver-
sarial attack problem involving multiple sources. By optimizing a model against the adversarial
environments, we achieve better “swap property” [ 4] compared to the baseline models. DeepDRK is
also equipped with a novel perturbation technique to reduce “reconstructability” [ 54], which in turn
controls FDR and boosts selection power. The experiments conducted on synthetic, semi-synthetic,
and real datasets demonstrate that our pipeline outperforms existing methods across various scenarios.
2 Background and Related Works
2.1 Model-X Knockoffs for FDR control
The Model-X knockoffs framework consists of two main components. Given the explanatory
variables X“pX1, X2, . . . , X pqJPRpand the response variable Y(Ycontinuous for regression
and categorical for classification), the framework requires: 1. a knockoff ˜X“p˜X1,˜X2, . . . , ˜XpqJ
that “fakes” X; 2. the knockoff statistics wjforjPrpsthat assess the importance of each feature Xj.
The knockoff ˜Xis required to be independent of Yconditioning on X, and must satisfy the swap
property:
pX,˜XqswappBqd“pX,˜Xq,@BĂrps. (1)
Here swappBqexchanges the positions of any variable Xj,jPB, with its knockoff ˜Xj. The knockoff
statistic wjppX,˜Xq, Yq(forjPrps) depends on the concatenated variable pX,˜XqandYand must
satisfy the flip-sign property:
wj´
pX,˜XqswappBq, Y¯
“"
wjppX,˜Xq, YqifjRB
´wjppX,˜Xq, YqifjPB(2)
The functions wjp¨qwithjPrpshave many candidates, for example wj“|βj|´|˜βj|, where βj
and˜βjare the corresponding regression coefficients of Xjand˜Xjwith the regression function
Y“řp
j“1pXjβj`˜Xj˜βjq`ϵ, where ϵis independently drawn from the normal distribution.
When the two knockoff conditions (i.e., Eq. (1)and(2)) are met, one can select features by S“
twjěτqu, where
τq“min
tą0!
t:1`|tj:wjď´tu|
maxp1,|tj:wjětu|qďq)
. (3)
To assess the feature selection quality, FDR is commonly used as an average Type I error of selected
features [ 4], which is defined as follows. Let SĂrpsbe an arbitrary set of selected indices, and let
β˚denote the underlying true regression coefficients. The FDR for the selection Sis
FDR“E«
#␣
j:β˚
j“0andjPS(
#tj:jPSu_1ff
(4)
The control of FDR is guaranteed by the following theorem from [11]:
Theorem 2.1. Given the knockoff that satisfies the swap property in Eq. (1), the knockoff statistic
that satisfies Eq. (2), andS“twjěτqu, we have FDRďq.
2.2 Related Works
Model-X knockoff is first studied under Gaussian design. Namely, the original variable X„Npµ,Σq
withµandΣknown. Since Gaussian design does not naturally generalize to complex data distribu-
tions, several methods are proposed to weaken the assumption. Among them, model-specific ones
2Figure 1: The illustration of the DeepDRK pipeline, which consists of two components: 1. the
training stage that optimizes the knockoff Transformer and swappers by LSLandLDRL; 2. the
post-training stage that generates the knockoff ˜XDRPθvia dependency regularized perturbation.
such as AEknockoff [ 34], Hidden Markov Model (HMM) knockoff [ 51], and MASS [ 20] all propose
parametric alternatives to Gaussian design. These methods can better learn the data distribution,
while keeping the sampling process relatively simple. Nevertheless, they pose assumptions to the
design distribution, which can be problematic if actual data does not coincide. To gain further flexi-
bility, various deep-learning-based models are developed to generate knockoffs from distributions
beyond parametric setup. DDLK [ 55] and sRMMD [ 38] utilize different metrics to measure the
distances between the original and the knockoff covariates. They apply different regularization terms
to impose the “swap property”. He et al. [24] introduced a KnockoffScreen procedure to generate
multiple knockoffs to improve the stability by minimizing the variance during knockoff construction.
KnockoffGAN [ 27] and Deep Knockoff [ 47] take advantage of the deep learning structures to create
likelihood-free generative models for the knockoff generation.
Despite the flexibility to learn the data distribution, deep-learning-based models suffer from a major
drawback. Knockoff generations based on distribution-free sampling methods such as generative
adversarial networks (GAN) [ 21,3] tend to overfit, namely to learn the data Xexactly. The reason
is that the notion of swap property for continuous distributions is not well defined at the sample
level. To satisfy the swap property, one needs to independently sample ˜Xjfrom the conditional law
PXjp¨|X´jq, where X´jdenotes the vector pX1, . . . , X j´1, Xj`1, . . . , X pq. At the sample level,
each realization of X´j“xi
´jis almost surely different and only associates to one corresponding
sample Xj“xi
j, causing the conditional law to degenerate to sum of Diracs. As a result, minimizing
the distance between pX,˜XqandpX,˜XqswappBqwill push ˜Xtowards Xand introduce high collinear-
ity that makes the feature selection powerless, i.e., with high type II error. To tackle this issue, DDLK
[55] suggests an entropic regularization. Yet it still lacks power and is computationally expensive.
2.3 Boost Power by reducing reconstructability
The issue of lacking power in the knockoff selection is solved in the Gaussian case [ 54]. Assuming
the knowledge of both mean and covariance of X„Npµ,Σq, the swap property is easily satisfied
by setting ˜Xj„Npµj,ΣjjqandΣij“VarpXi,˜Xjq, fori‰j,i, jP rps. Barber & Cand `es
[4]originally propose to minimize VarpXj,˜Xjqfor all jPrpsusing semi-definite programming
(SDP), to prevent ˜Xjto be highly correlated with Xj. However, Spector & Janson [54] observed
that the SDP knockoff still lacks feature selection power, as merely decorrelating Xjand˜Xjis not
enough, andpX,˜Xqcan still be (almost) linearly dependent in various cases. This is referred to
as high reconstructability1in their paper, which can be considered as a population counterpart of
collinearity (see Appendix A for more details). To tackle the problem, [ 54] proposed to maximize the
expected conditional variance EVarpXj|X´j,˜Xq, which admits close-form solution whenever Xis
Gaussian.
3 Method
DeepDRK in Figure 1 provides a novel way to generate knockoff ˜Xwhile reducing the recon-
structability (see Section 2.3) between the generated knockoff ˜Xand the input Xfor data with
1The “reconstructability” describes how easy a variable Xjcan be constructed deterministically from X´j
and ˜X[54].
3complex distributions. The generated knockoff can then be used to perform FDR-controlled fea-
ture selection following the Model-X knockoff framework (see Section 2.1). Overall, DeepDRK
contains two main components. It first trains a transformer-based deep learning model, referred
to as Knockoff Transformer (KT), to obtain the swap property and reduce the reconstructability of
the generated knockoff. This is achieved by incorporating adversarial attacks with multi-swappers.
Secondly, a dependency regularized perturbation technique (DRP) is developed to further reduce the
reconstructability for ˜Xpost training. We will elaborate on these two components in the following
two subsections. In this section, we slightly abuse the notation such that Xand˜Xalso denote the
corresponding data matrices.
3.1 Training with Knockoff Transformer and Swappers
The KT aims to generate knockoffs, denoted by ˜Xθ, which are parameterized by a transformer
network with parameters θ. The loss for training the KT contains a swap loss (SL) LSL, which
enforces the swap property, and a dependency regularization loss (DRL) LDRL, which controls the
reconstructibility of the knockoff. Kdifferent neural network parameterized swappers, denoted by
tSωiuK
i“1, are used to test whether the generated knockoffs satisfy the swap property. Thus, the KT is
trained adversarially according to the following objective,
min
θmax
ω1,...,ω K␣
LSLpX,˜Xθ,tSωiuK
i“1q`LDRLpX,˜Xθq(
. (5)
Note that we use ˜Xθand˜Xinterchangeably; however, the former emphasizes that the knockoff
depends on the model weights θ. We discuss each loss function below. Details on the network
architectures for KT and swappers are deferred to Appendix B.1. The training algorithm is in
Appendix B.2.
3.1.1 Swap Loss
The swap loss is designed to enforce the swap property and is defined as follows:
LSLpX,˜Xθ,tSωiuK
i“1q“1
KKÿ
i“1SWDppX,˜Xθq,pX,˜XθqSωiq
`λ1¨RExpX,˜Xθ,tSωiuK
i“1q`λ2¨LswapperptSωiuK
i“1q, (6)
where λ1andλ2are hyperparameters.
The first term in Eq. (6)uses the sliced Wasserstein distance (SWD, see Appendix C for definition) to
measure the distance between a pair of joint distributions for pX,˜XθqandpX,˜XθqSωi, where the
swapper is parameterized by ωi. We sum over KSWDs computed for the distributions modified
under different swappers to capture the effects of multiple swap attacks. We utilize SWD to com-
pare distributions because it excels in handling complex data distributions and is computationally
efficient [13, 28, 14].
Sudarshan et al. [55] introduced a single swap attack parameterized by a neural network. However, we
observe that minimizing the worst case swap for all BĂrps, as suggested by [ 55], cannot guarantee
the swap property of ˜Xθ. To address this limitation, we introduce a “multi-swapper” setup that uses
multiple swappers to enforce the swap property. And this leads to the introduction of the second and
the third terms in the objective in Eq. (6).
The second term in Eq. (6),RExpX,˜Xθ,tSωiuK
i“1qevaluates the variance of the sliced Wasserstein
distances SWDppX,˜Xθq,pX,˜XθqSωqwithKrealizations of ω[30]. When RExpX,˜Xθ,tSωiuK
i“1q“
0, the sliced Wasserstein distances are identical across all swappers. Therefore, complementary to the
first term, minimizing this term improves the adherence of swap property for the generated ˜Xθ.
The third term in Eq. (6)is introduced to avoid mode collapse on the parameters ωiof different
swappers and ensure each swapper characterizes a different adversarial environment:
LswapperptSωiuK
i“1q“1
|C|ÿ
pi,jqPCsimpSωi, Sωjq, (7)
4where C“tpi, jq|i, jPrKs, i‰ju, and simp¨,¨qis the cosine similarity between the weights ωof a
pair of different swappers. Without this regularization, all swappers could collapse to a single mode
such that the multi-swapper scheme reduces to a single-swapper setup.
Overall, the swap loss LSLenforces the swap property via the novel multi-swapper design. Such
design provides a more robust assurance of the swap property through multiple adversarial swap
attacks, which is shown in the ablation studies in Appendices I.2 and I.3.
3.1.2 Dependency Regularization Loss
As discussed in Section 2.2, pursuing the swap property at the sample level often leads to severe
overfitting of ˜Xθ, i.e., pushing ˜Xθtowards X, which results in high collinearity in feature selection.
To address this, the DRL is introduced to reduce the reconstructability between Xand˜X:
LDRLpX,˜Xθq“λ3¨SWCpX,˜Xθq, (8)
where λ3is a hyperparameter. The SWC term in Eq. (8)refers to the sliced Wasserstein correla-
tion [ 33], which quantitatively measures the dependency between two random vectors in the same
space. More specifically, let Z1andZ2be two p-dimensional random vectors. SWCpZ1, Z2q“0
indicates that Z1andZ2are independent, while SWCpZ1, Z2q“1suggests a linear relationship
between each other (see Appendix D for more details on SWC). In DeepDRK, we minimize SWC
to reduce the reconstructability, a procedure similar to [ 54]. The intuition is as follows. If the
joint distribution of Xis known, then for each jPrps, the knockoff ˜Xjshould be sampled from
Pjp¨|X´jq, making Xjand˜Xjless dependent. In such case the swap property is ensured, and
collinearity/reconstructability is reduced due to independence. As we do not have access to the
joint law, we want the variables to be less dependent. Since collinearity exists with in X, merely
decorrelate Xjand˜Xjis not enough. Thus, we minimize SWC to reduce the dependence between
Xand˜X. We refer readers to Appendix A for more discussions.
3.2 Dependency Regularization Perturbation
Empirically we observe a competition between LSLandLDRLin Eq. (5), which adds difficulty to the
training procedure. Specifically, the LSLis dominating and the LDRLincreases quickly after a short
decreasing period. We are the first to observe this phenomenon in all deep-learning based knockoff
generation models when one tries to gain power [ 47,55,38,27]. We include the experimental
evidence in Appendix E. We suggest the following explanation: minimizing the swap loss, which
corresponds to FDR control, is the same as controlling Type I error. Similarly, minimizing the
dependency loss is to control Type II error. With a fixed number of observations, it is well known that
Type I error and Type II error can not decrease at the same time after reaching a certain threshold. In
the framework of model-X knockoff, we aim to boost as much power as possible given the FDR is
controlled at a certain level, a similar idea as the uniformly most powerful (UMP) test [ 12]. For this
reason, we propose DRP as a post-training technique to further boost power.
DRP is a sample-level perturbation that further eliminates dependency between Xand and the
knockoff. More specifically, DRP perturbs the generated ˜Xθwith the row-permuted version of X,
denoted as Xrp. After applying DRP, the final knockoff ˜XDRP
θ,nbecomes:
˜XDRP
θ,n“p1´αnq¨˜Xθ`αn¨Xrp, (9)
where αnis a preset perturbation weight, nis the sample size, and αnÑ0when nÑ 8 . In
the following, we remove norθwhenever the context is clear. ˜XDRPhas a smaller SWC with X,
since Xrpis independent of X. Despite the perturbation increases the swap loss, such impact is
negligible when the sample size is large. More specifically, we present the following Lemma 3.1
and Proposition 3.2. Let ˆPnandˆPB
ndenote the empirical joint distribution of the sample Xand
˜Xbefore and after the swap: pX,˜Xq„ˆPn,pX,˜XqswappBq„ˆPB
n. And PandPBdenote their
corresponding population distributions.
Lemma 3.1. Under mild conditions[ 41], the slice Wasserstein distance between the empirical
distributions of pX,˜XqandpX,˜XqswappBqand their corresponding population distributions is of
scaleOpn´1{2q, i.e., SWDpˆPn,ˆPB
nq“SWDpP, PBq`Opn´1{2q.
50.20.40.60.81.0Power1.00
0.880.95
0.860.94
0.82
0.650.78
0.440.700.99
0.350.70
0.170.601.00
0.880.94
0.780.930.99
0.300.66
0.59Sample Size: 200
Gaussian Mixture
Copula: Clayton & ExponentialCopula: Clayton & Gamma Copula: Joe & ExponentialCopula: Joe & Gamma
Datasets0.00.10.20.30.40.50.60.70.8FDR0.74
0.29
0.250.40
0.26
0.11 0.110.080.120.090.44
0.070.09
0.050.090.72
0.29
0.240.31
0.260.79
0.130.27
0.040.320.20.40.60.81.0Power1.00
0.890.93
0.720.890.98
0.920.97
0.480.940.98
0.450.80
0.180.711.00
0.880.94
0.780.941.000.961.00
0.690.99Sample Size: 2000
Gaussian Mixture
Copula: Clayton & ExponentialCopula: Clayton & Gamma Copula: Joe & ExponentialCopula: Joe & Gamma
Datasets0.00.10.20.30.40.50.60.70.8FDR0.63
0.11
0.050.14
0.050.07 0.08
0.040.09
0.050.11
0.030.040.030.050.64
0.08
0.040.16
0.050.70
0.12 0.110.090.12Methods
Deep Knockoff
DeepDRK
KnockoffGAN
sRMMD
DDLKFigure 2: Power and FDR for different knockoff models on the synthetic datasets with β„p
15¨?
N¨
Rademacher(0.5). The red horizontal line indicates the 0.1 FDR threshold.
Proposition 3.2. LetαnÀOpn´1{2qin Eq. (9), and denote pX,˜XDRPq „ ˆPn,DRP,
pX,˜XDRPqswappBq„ˆPB
n,DRP. Then SWDpˆPn,DRP,ˆPB
n,DRPq“SWDpP, PBqwhen nÑ8 .
The proofs can be found in Appendix F. Lemma 3.1 suggests a general case where the swap loss
enforced at the sample level differs from that of the population level from a term of scale n´1{2, which
vanishes when nÑ8 . Proposition 3.2 provides the rationale on the proposal of the perturbation
technique in Eq. (9), such that the DRP term is negligible asymptotically. Besides the theoretical
justification, we also empirically show in Appendix G that the perturbation is beneficial.
4 Experiment
We assess the performance of DeepDRK against several benchmark models under three experimental
setups: 1. a fully synthetic setup where both the input variables and the response variable follow
predefined distributions; 2. a semi-synthetic setup, in which the input variables are derived from real-
world datasets and the response variable is generated based on known relationships with the inputs;
and 3. feature selection (FS) using a real-world dataset. The experiments are designed to encompass
a range of datasets with varying p{nratios and distributions of X, aiming to provide a comprehensive
evaluation of model performance. The benchmark models are Deep Knockoff [ 47]2, DDLK [ 55]3,
KnockoffGAN [ 27]4and sRMMD [ 38]5, with links of the code implementation listed in the footnote.
The implementation details for the training, feature selection, and data preparation are available in
Appendix H. In the following, we describe the datasets and the associated experimental results. We
also consider the ablation study to illustrate the benefits obtained by having the following proposed
terms: REx,Lswapper , the multi-swapper setup, and the dependency regularization perturbation.
Empirically, these terms help to improve power and control the FDR. Due to space limitation,
we defer details for the ablation studies to Appendix I.2 and I.3. DeepDRK is implemented in
PyTorch [45] and is accessible at: https://github.com/nowonder2000/DeepDRK .
4.1 The Synthetic Experiments
0.20.40.60.81.0Power1.00 1.00
0.79 0.790.980.961.00 1.00
0.910.97Sample Size: 200
0.7 0.8
base
0.00.10.20.30.40.50.60.70.8FDR0.73 0.75
0.150.210.420.460.75 0.750.730.780.20.40.60.81.0Power1.00 1.000.950.920.98 0.961.00 1.00 1.00 1.00Sample Size: 2000
Methods
Deep Knockoff
DeepDRK
KnockoffGAN
sRMMD
DDLK
0.7 0.8
base
0.00.10.20.30.40.50.60.70.8FDR0.680.71
0.120.190.160.250.630.670.740.77
Figure 3: Power and FDR for different knockoff models on
the mixture of Gaussian data on different ρbasesetups. The
red horizontal line indicates the 0.1 FDR threshold. This
figure is complementary to Figure 2 for including two addi-
tional Gaussian mixture data with higher ρbasevalues.To properly evaluate the performance,
we follow a well-designed experimen-
tal setup by [ 55,38] to generate differ-
ent datasets specified by pX, Yq. Here
XPRpis the collection dependent
variables that follows pre-defined dis-
tributions. YPRis the response
variable that is modeled as Y„
NpXTβ,1q. The underlying true β
is ap-dimensional vector, where each
entry is drawn independently from the
distributionp
15¨?n¨Rademacher(0.5) .
2https://github.com/msesia/deepknockoffs
3https://github.com/rajesh-lab/ddlk
4https://github.com/vanderschaarlab/mlforhealthlabpub/tree/main/alg/knockoffgan
5https://github.com/ShoaibBinMasud/soft-rank-energy-and-applications
6n Method FDR Power
mean std median 5% quantile 95% quantile mean std median 5% quantile 95% quantile
200DDLK 0.772 0.025 0.781 0.726 0.791 0.971 0.033 0.983 0.911 0.995
Deep Knockoff 0.735 0.028 0.740 0.692 0.769 0.999 0.001 0.999 0.997 1.000
KnockoffGAN 0.390 0.110 0.396 0.230 0.550 0.971 0.038 0.986 0.904 0.997
sRMMD 0.720 0.047 0.741 0.640 0.752 0.998 0.002 0.998 0.994 1.000
DeepDRK 0.116 0.040 0.100 0.086 0.187 0.791 0.039 0.804 0.720 0.824
2000DDLK 0.725 0.050 0.734 0.667 0.778 1.000 0.000 1.000 1.000 1.000
Deep Knockoff 0.626 0.092 0.672 0.460 0.694 1.000 0.001 1.000 0.997 1.000
KnockoffGAN 0.118 0.014 0.114 0.102 0.139 0.973 0.012 0.978 0.953 0.986
sRMMD 0.658 0.060 0.644 0.583 0.736 1.000 0.001 1.000 0.998 1.000
DeepDRK 0.081 0.018 0.076 0.059 0.110 0.973 0.011 0.978 0.956 0.983
Table 1: Comparison of different methods on FDR and power across different pπ1, π2, π3qfor the
components in the Gaussian mixture setup.
Compared to the previous works [ 55,38], which considerp?nas the scaling factor for the Rademacher
distribution, we reduce the magnitude of βby a factor of 15. This is because we find that in the
original setup, the βscale is too large such that the feature selection enjoys high powers and low
FDRs for all models. To compare the performance of the knockoff generation methods on various
data, we consider the following distributions for X:
Gaussian mixture : We consider a Gaussian mixture model X„ř3
k“1πkNpµk,Σkq, where π
is the proportion of the k-th Gaussian with pπ1, π2, π3q “ p 0.4,0.2,0.4q.µkPRpdenotes the
mean of the k-th Gaussian with µk“1p¨20¨pk´1q, where 1pis the p-dimensional vector that
has universal value 1 for all entries. ΣkPRpˆpis the covariance matrices whose pi, jq-th entry
taking the value ρ|i´j|
k, where ρk“ρk´0.1
base andρbase“0.6. Besides this experiment, we further
perform two additional tests. The first one focuses on a mixture of Gaussians data of various ρbase
to study the feature selection performance with highly correlated features. Namely, we consider
additional ρbasePt0.7,0.8u. The second one explores the effect of pπ1, π2, π3qto the feature selection
performance. In this case, we uniformly draw 10 sets of pπ1, π2, π3q, and evaluate the FS performance
of all the models considered in this paper. The values of the mixture weights are presented in Table 4
in Appendix H.3.1.
Copulas [49]: We further use copula to model complex correlations within X. To the best of our
knowledge, this is a first attempt to consider complex distributions other than the Gaussian mixture
model in the knockoff framework. Specifically, we consider two copula families: Clayton, Joe with
the consistent copula parameter of 2 in both cases. For each family, we consider two candidates for
the marginal distributions: a uniform distribution (using the identity conversion function) and an
exponential distribution with a rate of 1. We implement the copulas according to PyCop6.
We consider the following pn, pqsetups:p200,100qandp2000,100q. This is in contrast to existing
works, which consider only the p2000,100qas the smallest sample size setup [ 55,38,47]. Our goal
is to demonstrate the consistent performance of DeepDRK across various p{nratios, particularly
when the sample size is small.
Results : Figure 2 compare FDRs and powers for all models across the datasets with two different
setups for β. Figure 2 shows that DeepDRK consistently controls the false discovery rate (FDR)
compared to other benchmark models across various data distributions and p{nratios, with the
exception of a few cases where the FDR exceeds the 0.1threshold in the small sample size ( n“200)
scenarios. Other models, though being able to reach higher power, comes at a cost of sacrificing
FDR, which contradicts to the UMP philosophy (see Section 3.2). We also evaluate the performance
on a mixture of Gaussians with increasing ρbase, indicating a higher correlation among the input
variables. Note that the mixture of Gaussians example in Figure 2 has ρbase“0.6. The results
forρbaseP t0.7,0.8uare presented in Figure 3. Compared to other baseline models, DeepDRK
maintains the lowest FDRs while achieving competitive powers across all ρbasevalues, highlighting
its robustness to correlations in X. Overall, the results demonstrate the ability of DeepDRK in
consistently performing FS with controlled FDR compared to other models across a range of different
datasets, p{nratios, and feature correlations in X. In addition, we present common statistics for
the FDR and power on the mixture of Gaussians experiment with 10 different sets of pπ1, π2, π3q
in Table 1. It is clear that DeepDRK improves the robustness in maintaining FDR across various
configurations of the Gaussian mixture models compared to existing approaches.
6https://github.com/maximenc/pycop/
7Nonnull Null0.1
0.00.10.20.30.40.5MeanDeepDRK
Nonnull Null0.1
0.00.10.20.30.40.5sRMMD
Nonnull Null0.1
0.00.10.20.30.40.5Deep Knockoff
Nonnull Null0.1
0.00.10.20.30.40.5KnockoffGAN
Nonnull Null0.1
0.00.10.20.30.40.5DDLK
Datasets
Gaussian Mixture
Copula: Clayton & Exponential
Copula: Clayton & Gamma
Copula: Joe & Exponential
Copula: Joe & GammaFigure 4: The knockoff statistics ( wj) for different knockoff models on the synthetic datasets with
β„p
15¨?
N¨Rademacher(0.5) . Each bar in the plot represents the mean of the null/nonnull knockoff
statistics averaging on 600 experiments. The error bar indicates the standard deviation. The sample
size is 200.
0.00.20.40.60.81.0PowerGaussian Mixture Copula: Clayton & Exponential Copula: Joe & Exponential Copula: Joe & Gamma Copula: Clayton & Gamma
0.0 0.2 0.4 0.6 0.8
FDR0.00.20.40.60.81.0PowerGaussian Mixture
0.0 0.2 0.4 0.6 0.8
FDRCopula: Clayton & Exponential
0.0 0.2 0.4 0.6 0.8
FDRCopula: Joe & Exponential
0.0 0.2 0.4 0.6 0.8
FDRCopula: Joe & Gamma
0.0 0.2 0.4 0.6 0.8
FDRCopula: Clayton & GammaSample Size: 200
Sample Size: 2000Method
sRMMD
Deep Knockoff
DeepDRK
KnockoffGAN
DDLK
Scale
5
10
15
20
Figure 5: Scatter plots of Power against FDR for different datasets and models. The red vertical
line indicates the 0.1 FDR threshold. Different scales for β(e.g.,p
5¨?n,p
10¨?n,p
15¨?nandp
20¨?n) are
indicated by different marker styles. Different models are indicated by different colors.
To understand why DeepDRK outperforms other baseline models, we consider measuring the
distribution of the knockoff statistics, i.e., wj, for both nonnull and null features of X. Fan et al. [17]
and Cand `es et al. [11] pointed out that a good knockoff requires the corresponding knockoff statistics
to concentrate symmetrically around zero for the null features and to maintain high positive values for
the nonnulls. However, theoretical analysis on the goodness of FDR or power requires access to the
true knockoff ˜X[17] to compare the distribution of wj’s with the ground truth, which is infeasible
for non-Gaussian data. Nevertheless, we can still examine the distribution of the knockoff statistics
as a surrogate to analyze model performance in terms of false discovery rate (FDR) or power, given
the necessary properties of the knockoff statistics mentioned earlier.
Figure 4 shows the means and standard deviations of the empirical distributions of the knockoff
statistics wjfor both null and nonnull variables across different datasets and models. Clearly,
compared to other benchmarks, DeepDRK maintains high values of wjfor the nonnulls and relatively
symmetric values around zero for the nulls. All other models experience positive shifts to the null
statistics to some extent. Positive shifts in the null statistics lead to a degeneracy in performance
because the threshold selection rule for false discovery rate (FDR) is based on the negative values
ofwj’s (see Eq. (3)). This has two negative impacts, one on the FS threshold and the other on
its subsequent FS process. First, according to Eq. (3), the shift causes the chosen threshold to
approach zero, as there are fewer null statistics remaining on the negative side, and those that do
remain have smaller amplitudes. Subsequently, a lowered threshold leads to an increase in false
positives, a phenomenon that becomes more pronounced with positive shifts in the null statistics.
As shown in Figure 4, the wjvalues calculated using DeepDRK are centered around zero for the
nulls, while exhibiting large positive values for the nonnulls. This aligns with the results in Figure 2,
which demonstrate that DeepDRK effectively achieves good FDR control and high power. Due to
space limit, we defer the results for n“2000 and the comparison of wjstatistics for the Gaussian
correlation setup to Appendix I.3.
To further verify the performance consistency of the proposed method, we include a comparison on
different βscales. Specifically, we consider 4 different sets of βscales, i.e.,p
5¨?n,p
10¨?n,p
15¨?nand
p
20¨?n, for the previously considered data distributions. The results are summarized in Figure 5. It
is observed that in all cases considered with various βscale, the proposed DeepDRK successfully
8maintains relatively low FDRs with a higher power, compared to baseline methods. This phenomenon
is especially pronounced with a low sample size ( n“200).
In addition to the above results, we provide the measurement of the swap property in Appendix I.1.
The evaluation of model runtime is also included in Appendix I.4.
4.2 The Semi-synthetic Experiments
0.20.40.60.81.0Power
0.140.730.81Synthetic Rule: Tanh
RNASeq0.00.10.20.30.40.50.60.70.8FDR
0.000.08
0.00 0.000.14Methods
Deep Knockoff
DeepDRK
KnockoffGAN
sRMMD
DDLK0.20.40.60.81.0Power0.730.900.86
0.700.83Synthetic Rule: Linear
RNASeq0.00.10.20.30.40.50.60.70.8FDR
0.060.100.070.120.09Methods
Deep Knockoff
DeepDRK
KnockoffGAN
sRMMD
DDLK
Figure 6: Power and FDR for different knockoff models
on the semi-synthetic RNA dataset. The red horizontal
line indicates the 0.1 FDR threshold.We consider a semi-synthetic study with de-
signXdrawn from two real-world datasets
and use Xto simulate response Y. The
first dataset contains single-cell RNA se-
quencing (scRNA-seq) data from 10ˆGe-
nomics7. Each entry in XPRnˆprep-
resents the observed gene expression of p
genes in ncells. We refer readers to [ 23]
and [ 1] for more background. Following
the same preprocessing in [ 23], we obtain
the final dataset Xwithn“10000 and
p“1008. The preprocessing of Xand
the synthesis of Y(denoted as “Linear” and
“Tanh” cases) are deferred to Appendix H.3.2.
The second publicly available dataset9is from a real case study entitled “Longitudinal Metabolomics
of the Human Microbiome in Inflammatory Bowel Disease (IBD)” [ 35]. The study seeks to identify
important metabolites of two representative diseases of the inflammatory bowel disease (IBD):
ulcerative colitis (UC) and Crohn’s disease (CD). Specifically, we use the C18 Reverse-Phase
Negative Mode dataset that has 546 samples and 91 metabolites. To mitigate the effects of missing
values, we preprocess the dataset following a common procedure to remove metabolites that have over
20% missing values, resulting in 80 metabolites. We normalize the data matrix entry-wise to have zero
mean and unit variance after a log transform and an imputation via the k-nearest neighbor algorithm
following the same procedure in [ 38]. Finally, we synthesize the response Ywith the real dataset of
XviaY„NpXTβ,1q, where the entries of βdrawn independently from one of the following three
distributions: Unif(0, 1), Np0,1q, and Rademacher p0.5q, in three separate experiments.
Results : Figure 6 and 7 compare the feature selection performance on the RNA data and the IBD
data respectively. In Figure 6, we observe that all but DDLK are bounded by the nominal 0.1 FDR
threshold in the “Tanh” case. However, KnockoffGAN and sRMMD have almost zero power. The
power for Deep Knockoff is also very low compared to that of DeepDRK. Although DDLK provides
high power, the associated FDR is not controlled by the threshold. In the “Linear” case, almost all
models have well controlled FDR, among which DeepDRK provides the highest power. Similar
observations can be found in Figure 7. For the IBD data generated under the aforementioned synthesis
rules, it is clear that all models except DDLK achieve well-controlled FDR. Apart from DDLK,
DeepDRK consistently demonstrates the highest power. These results further underscore the potential
of DeepDRK for real-world data applications.
4.3 A Case Study
Besides (semi-)synthetic setups, we carry out a case study with real data for both design Xand
response Y, in order to qualitatively evaluate the selection performance of DeepDRK. In this
subsection, we use the IBD dataset [ 35] with the empirical response. The response variable Yis
categorical: Yequals 1 if a given sample is associated with UC/CD and 0 otherwise. The covariates
Xis identical to the second semi-synthetic setup considered in Section 4.2. To properly evaluate
results with no ground truth available, we search for the evidence of the IBD-associated metabolites
using the existing literature. Specifically, we use three sources: 1. metabolites that are explicitly
7https://kb.10xgenomics.com/hc/en-us
8The data processing code is adopted from this repo: https://github.com/dereklhansen/
flowselect/tree/master/data
9https://www.metabolomicsworkbench.org/ under the project DOI: 10.21228/M82T15.
90.20.40.60.81.0Power0.99 1.00 0.98 0.98 1.00Synthetic Rule: Linear & Normal
IBD0.00.10.20.30.40.50.60.70.8FDR
0.020.06 0.050.020.430.20.40.60.81.0Power0.540.68
0.47 0.490.92Synthetic Rule: Linear & Rade.
IBD0.00.10.20.30.40.50.60.70.8FDR
0.030.070.050.020.570.20.40.60.81.0Power0.920.97
0.90 0.890.99Synthetic Rule: Linear & Uniform
IBD0.00.10.20.30.40.50.60.70.8FDR
0.040.100.05 0.040.24Methods
Deep Knockoff
DeepDRK
KnockoffGAN
sRMMD
DDLKFigure 7: Power and FDR for different knockoff models on the semi-synthetic IBD dataset. The red
horizontal line indicates the 0.1 FDR threshold.
Model DeepDRK Deep Knockoff sRMMD KnockoffGAN DDLK
Referenced / Identified 19/23 15/20 5/5 12/14 17/25
Table 2: The number of literature-supported metabolites among the identified metabolites vs. the
number of identified metabolites.
documented to have associations with IBD, UC, or CD in the PubChem database10; 2. metabolites
that are reported in the existing peer-reviewed publications; 3. metabolites that are reported in
pre-prints. We identify 47 metabolites that are reported to have association with IBD. All referenced
metabolites are included in Table 5 in Appendix H.3.3.
Our DeepDRK model training and knockoff generation are the same as before (see Table 3 in
Appendix H.1). Likewise, to generate knockoff for the benchmark models, we follow their default
setups. During the FS step, however, we use 0.2 as the FDR threshold instead of 0.1, and apply a
different algorithm—DeepPINK [ 37] that is included in the knockpy11library—to generate wj.
The values are subsequently used to identify metabolites. We choose DeepPINK over the previously
considered ridge regression due to the nonlinear relationships between metabolites Xand responses
Yin this case study.
We compare the FS results with the 47 literature-supported metabolites and report the number of
selections in Table 2. A detailed list of selected features for each model can be found in Table 9 in
Appendix I.5. From Table 2, it is clear that, compared to the benchmark models, DeepDRK identifies
the largest number of referenced metabolites while effectively limiting the number of metabolites
not reported in existing literature (see Table 5 in Appendix H.3.3). The sRMMD model achieves the
lowest false discovery rate, but this comes at the cost of missing a significant number of documented
metabolites. Since there is no ground truth available, the results here should be viewed and analyzed
qualitatively.
5 Conclusion
In this paper, we introduce DeepDRK, a deep learning-based knockoff generation pipeline consisting
of two steps. First, it trains a Knockoff Transformer with multiple swappers to achieve the swap
property while reducing reconstructability. In the post-training stage, a dependency-regularized
perturbation is applied to further enhance power with controlled FDR. DeepDRK effectively balances
FDR and power, which compete with each other at the sample level. To the best of our knowledge, this
relationship has not been previously reported in the literature. Empirically, DeepDRK demonstrates
the ability to maintain both controlled false discovery rates (FDR) and high power across various
data distributions and different p{nratios. Additionally, we provide insights into the distribution of
knockoff statistics, which elucidate the reasons behind DeepDRK’s consistently strong performance.
The numerical results indicate that DeepDRK outperforms existing deep learning-based benchmark
models. Experiments with real and semi-synthetic data further highlight the potential of DeepDRK
for feature selection tasks involving non-Gaussian data.
10https://pubchem.ncbi.nlm.nih.gov/
11https://amspector100.github.io/knockpy/
10Acknowledgments
This research was partially supported by Alfred P. Sloan foundation and NSF #1934757.
References
[1]Agarwal, D., Wang, J., and Zhang, N. R. Data denoising and post-denoising corrections in
single cell RNA sequencing. Statistical Science , 35(1):112 – 128, 2020.
[2]Ananthakrishnan, A. N., Luo, C., Yajnik, V ., Khalili, H., Garber, J. J., Stevens, B. W., Cleland,
T., and Xavier, R. J. Gut microbiome function predicts response to anti-integrin biologic therapy
in inflammatory bowel diseases. Cell host & microbe , 21(5):603–610, 2017.
[3]Arjovsky, M., Chintala, S., and Bottou, L. Wasserstein generative adversarial networks. In
ICML , pp. 214–223, 2017.
[4]Barber, R. F. and Cand `es, E. J. Controlling the false discovery rate via knockoffs. The Annals
of Statistics , 43(5):2055–2085, 2015.
[5]Bauset, C., Gisbert-Ferr ´andiz, L., and Cos ´ın-Roger, J. Metabolomics as a promising resource
identifying potential biomarkers for inflammatory bowel disease. Journal of Clinical Medicine ,
10(4):622, 2021.
[6]Benjamini, Y . and Hochberg, Y . Controlling the false discovery rate: a practical and powerful
approach to multiple testing. Journal of the Royal statistical society: series B (Methodological) ,
57(1):289–300, 1995.
[7]Bin Masud, S., Jenkins, C., Hussey, E., Elkin-Frankston, S., Mach, P., Dhummakupt, E., and
Aeron, S. Utilizing machine learning with knockoff filtering to extract significant metabolites in
Crohn’s disease with a publicly available untargeted metabolomics dataset. Plos one , 16(7):
e0255240, 2021.
[8]Blaker, P. A., Arenas-Hernandez, M., Smith, M. A., Shobowale-Bakre, E. A., Fairbanks, L.,
Irving, P. M., Sanderson, J. D., and Marinaki, A. M. Mechanism of allopurinol induced TPMT
inhibition. Biochemical pharmacology , 86(4):539–547, 2013.
[9]Bonneel, N., Rabin, J., Peyr ´e, G., and Pfister, H. Sliced and Radon Wasserstein barycenters of
measures. Journal of Mathematical Imaging and Vision , 51:22–45, 2015.
[10] Bonnotte, N. Unidimensional and evolution methods for optimal transportation . PhD thesis,
Universit ´e Paris Sud-Paris XI; Scuola normale superiore (Pise, Italie), 2013.
[11] Cand `es, E., Fan, Y ., Janson, L., and Lv, J. Panning for gold: ‘Model-X’ knockoffs for high
dimensional controlled variable selection. Journal of the Royal Statistical Society: Series B
(Statistical Methodology) , 80(3):551–577, 2018.
[12] Casella, G. and Berger, R. L. Statistical inference . Cengage Learning, 2021.
[13] Deshpande, I., Zhang, Z., and Schwing, A. G. Generative modeling using the sliced Wasserstein
distance. In CVPR , pp. 3483–3491, 2018.
[14] Deshpande, I., Hu, Y .-T., Sun, R., Pyrros, A., Siddiqui, N., Koyejo, S., Zhao, Z., Forsyth, D.,
and Schwing, A. G. Max-sliced Wasserstein distance and its use for GANs. In CVPR , pp.
10648–10656, 2019.
[15] Dhal, P. and Azad, C. A comprehensive survey on feature selection in the various fields of
machine learning. Applied Intelligence , 52(4):4543–4581, 2022.
[16] Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., Dehghani,
M., Minderer, M., Heigold, G., Gelly, S., Uszkoreit, J., and Houlsby, N. An image is worth
16ˆ16 words: Transformers for image recognition at scale. In ICLR , 2021.
[17] Fan, Y ., Gao, L., and Lv, J. ARK: Robust Knockoffs inference with coupling. arXiv preprint
arXiv:2307.04400 , 2023.
11[18] Fretland, D., Widomski, D., Levin, S., and Gaginella, T. Colonic inflammation in the rabbit
induced by phorbol-12-myristate-13-acetate. Inflammation , 14(2):143–150, 1990.
[19] Gavrilov, Y ., Benjamini, Y ., and Sarkar, S. K. An adaptive step-down procedure with proven
FDR control under independence. The Annals of Statistics , 37(2):619–629, 2009.
[20] Gimenez, J. R., Ghorbani, A., and Zou, J. Knockoffs for the mass: new feature importance
statistics with false discovery guarantees. In AISTATS , pp. 2125–2133, 2019.
[21] Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A.,
and Bengio, Y . Generative adversarial networks. Communications of the ACM , 63(11):139–144,
2020.
[22] Guyon, I. and Elisseeff, A. An introduction to variable and feature selection. Journal of machine
learning research , 3(Mar):1157–1182, 2003.
[23] Hansen, D., Manzo, B., and Regier, J. Normalizing flows for knockoff-free controlled feature
selection. In Advances in Neural Information Processing Systems , volume 35, pp. 16125–16137,
2022.
[24] He, Z., Liu, L., Wang, C., Le Guen, Y ., Lee, J., Gogarten, S., Lu, F., Montgomery, S., Tang, H.,
Silverman, E. K., et al. Identification of putative causal loci in whole-genome sequencing data
via knockoff statistics. Nature communications , 12(1):1–18, 2021.
[25] Hristache, M., Juditsky, A., and Spokoiny, V . Direct estimation of the index coefficient in a
single-index model. Annals of Statistics , 29(3):595–623, 2001.
[26] Jang, E., Gu, S., and Poole, B. Categorical reparameterization with Gumbel-softmax. In ICLR ,
2017.
[27] Jordon, J., Yoon, J., and van der Schaar, M. KnockoffGAN: Generating knockoffs for feature
selection using generative adversarial networks. In ICLR , 2018.
[28] Kolouri, S., Nadjahi, K., Simsekli, U., Badeau, R., and Rohde, G. Generalized sliced Wasserstein
distances. In NeurIPS , volume 32, 2019.
[29] Koon, H. W. A novel orally active metabolite reverses Crohn’s disease-associated intestinal
fibrosis. Inflammatory Bowel Diseases , 28(Supplement 1):S61–S62, 2022.
[30] Krueger, D., Caballero, E., Jacobsen, J.-H., Zhang, A., Binas, J., Zhang, D., Le Priol, R., and
Courville, A. Out-of-distribution generalization via risk extrapolation (REx). In ICML , pp.
5815–5826, 2021.
[31] Lavelle, A. and Sokol, H. Gut microbiota-derived metabolites as key actors in inflammatory
bowel disease. Nature reviews Gastroenterology & hepatology , 17(4):223–237, 2020.
[32] Lee, T., Clavel, T., Smirnov, K., Schmidt, A., Lagkouvardos, I., Walker, A., Lucio, M., Michalke,
B., Schmitt-Kopplin, P., Fedorak, R., et al. Oral versus intravenous iron replacement therapy
distinctly alters the gut microbiota and metabolome in patients with IBD. Gut, 66(5):863–871,
2017.
[33] Li, T., Yu, J., and Meng, C. Scalable model-free feature screening via sliced-Wasserstein
dependency. Journal of Computational and Graphical Statistics , 32(4):1501–1511, 2023.
[34] Liu, Y . and Zheng, C. Auto-encoding knockoff generator for FDR controlled variable selection.
arXiv preprint arXiv:1809.10765 , 2018.
[35] Lloyd-Price, J., Arze, C., Ananthakrishnan, A. N., Schirmer, M., Avila-Pacheco, J., Poon,
T. W., Andrews, E., Ajami, N. J., Bonham, K. S., Brislawn, C. J., et al. Multi-omics of the gut
microbial ecosystem in inflammatory bowel diseases. Nature , 569(7758):655–662, 2019.
[36] Loshchilov, I. and Hutter, F. Decoupled weight decay regularization. In ICLR , 2019.
[37] Lu, Y ., Fan, Y ., Lv, J., and Stafford Noble, W. DeepPINK: reproducible feature selection in
deep neural networks. In NeurIPS , volume 31, 2018.
12[38] Masud, S. B., Werenski, M., Murphy, J. M., and Aeron, S. Multivariate soft rank via entropy-
regularized optimal transport: Sample efficiency and generative modeling. Journal of Machine
Learning Research , 24(160):1–65, 2023.
[39] Mehta, R. S., Taylor, Z. L., Martin, L. J., Rosen, M. J., and Ramsey, L. B. SLCO1B1 *15 allele
is associated with methotrexate-induced nausea in pediatric patients with inflammatory bowel
disease. Clinical and translational science , 15(1):63–69, 2022.
[40] Minderhoud, I. M., Oldenburg, B., Schipper, M. E. I., Ter Linde, J. J. M., and Samsom, M.
Serotonin synthesis and uptake in symptomatic patients with Crohn’s disease in remission.
Clinical Gastroenterology and Hepatology , 5(6):714–720, 2007.
[41] Nadjahi, K., Durmus, A., Simsekli, U., and Badeau, R. Asymptotic guarantees for learning
generative models with the sliced-Wasserstein distance. In Advances in Neural Information
Processing Systems , volume 32, 2019.
[42] Narasimhan, R. L., Throm, A. A., Koshy, J. J., Saldanha, K. M. R., Chandranpillai, H., Lal,
R. D., Kumravat, M., K. M., A. K., Batra, A., Zhong, F., et al. Inferring intestinal mucosal
immune cell associated microbiome species and microbiota-derived metabolites in inflammatory
bowel disease. bioRxiv , 2020.
[43] Nies, T. G., Staudt, T., and Munk, A. Transport dependency: Optimal transport based depen-
dency measures. arXiv preprint arXiv:2105.02073 , 2021.
[44] Nuzzo, A., Saha, S., Berg, E., Jayawickreme, C., Tocker, J., and Brown, J. R. Expanding the
drug discovery space with predicted metabolite–target interactions. Communications biology , 4
(1):1–11, 2021.
[45] Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Killeen, T., Lin, Z.,
Gimelshein, N., Antiga, L., et al. Pytorch: An imperative style, high-performance deep learning
library. In NeurIPS , volume 32, 2019.
[46] Qin, X. Etiology of inflammatory bowel disease: a unified hypothesis. World journal of
gastroenterology: WJG , 18(15):1708, 2012.
[47] Romano, Y ., Sesia, M., and Cand `es, E. Deep knockoffs. Journal of the American Statistical
Association , 115(532):1861–1872, 2020.
[48] Saber, S., Khalil, R. M., Abdo, W. S., Nassif, D., and El-Ahwany, E. Olmesartan ameliorates
chemically-induced ulcerative colitis in rats via modulating NF κB and Nrf-2/HO-1 signaling
crosstalk. Toxicology and applied pharmacology , 364:120–132, 2019.
[49] Schmidt, T. Coping with copulas. Copulas-From theory to application in finance , 3:1–34, 2007.
[50] Scoville, E. A., Allaman, M. M., Brown, C. T., Motley, A. K., Horst, S. N., Williams, C. S.,
Koyama, T., Zhao, Z., Adams, D. W., Beaulieu, D. B., et al. Alterations in lipid, amino acid,
and energy metabolism distinguish Crohn’s disease from ulcerative colitis and control subjects
by serum metabolomic profiling. Metabolomics , 14(1):1–12, 2018.
[51] Sesia, M., Sabatti, C., and Cand `es, E. J. Gene hunting with hidden Markov model knockoffs.
Biometrika , 106(1):1–18, 08 2018.
[52] Soderholm, J. D., Oman, H., Blomquist, L., Veen, J., Lindmark, T., and Olaison, G. Reversible
increase in tight junction permeability to macromolecules in rat ileal mucosa in vitro by sodium
caprate, a constituent of milk fat. Digestive diseases and sciences , 43(7):1547–1552, 1998.
[53] S¨oderholm, J. D., Olaison, G., Peterson, K. H., Franzen, L. E., Lindmark, T., Wir ´en, M.,
Tagesson, C., and Sj ¨odahl, R. Augmented increase in tight junction permeability by luminal
stimuli in the non-inflamed ileum of Crohn’s disease. Gut, 50(3):307–313, 2002.
[54] Spector, A. and Janson, L. Powerful knockoffs via minimizing reconstructability. The Annals of
Statistics , 50(1):252–276, 2022.
[55] Sudarshan, M., Tansey, W., and Ranganath, R. Deep direct likelihood knockoffs. In NeurIPS ,
volume 33, 2020.
13[56] Suhre, K., Shin, S.-Y ., Petersen, A.-K., Mohney, R. P., Meredith, D., W ¨agele, B., Altmaier, E.,
Deloukas, P., Erdmann, J., Grundberg, E., et al. Human metabolic individuality in biomedical
and pharmaceutical research. Nature , 477(7362):54–60, 2011.
[57] Uchiyama, K., Odahara, S., Nakamura, M., Koido, S., Katahira, K., Shiraishi, H., Ohkusa, T.,
Fujise, K., and Tajiri, H. The fatty acid profile of the erythrocyte membrane in initial-onset
inflammatory bowel disease patients. Digestive diseases and sciences , 58(5):1235–1243, 2013.
[58] Uko, V ., Thangada, S., and Radhakrishnan, K. Liver disorders in inflammatory bowel disease.
Gastroenterology research and practice , 2012(1):642923, 2012.
[59] Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, Ł., and
Polosukhin, I. Attention is all you need. In NeurIPS , volume 30, 2017.
[60] Villani, C. Optimal transport: old and new , volume 338. Springer, 2009.
[61] Wiesel, J. C. Measuring association with Wasserstein distances. Bernoulli , 28(4):2816–2832,
2022.
[62] Zhu, Z., Fan, Y ., Kong, Y ., Lv, J., and Sun, F. DeepLINK: Deep learning inference using
knockoffs with applications to genomics. Proceedings of the National Academy of Sciences ,
118(36):e2104683118, 2021.
14Appendix
A Reconstructability and Selection Power
The concept of reconstructability was introduced by [ 54] as a population-level counterpart to what
is commonly referred to as collinearity in linear regression. Under a Gaussian design where X„
Np0,Σq, reconstructability is high if Σis not of full rank, implying that there exists some jsuch
thatXjis almost surely a linear combination of X´j. More generally, if there exists more than one
representation of the response Yusing the explanatory variable X, we qualitatively consider the
reconstructability to be high. High collinearity often impairs statistical power, and similarly, high
reconstructability diminishes feature selection power. To illustrate this, we state a linear version of
Theorem 2.3 from [54], originally formulated for a more general single-index model [25].
Theorem A.1. LetY“XJβJ`X´Jβ´J`ε, where JĂ rpsandεis centered Gaussian
noise. Equivalently, this implies YK KXJ|XJβJ, X´J. Suppose there exists a β˚
Jsuch that
XJβJ“XJβ˚
Jalmost surely. Then, denoting Y˚“XJβ˚
J`X´Jβ´J`ε, we have
ppX,˜Xq, Yqd“´
pX,˜XqswappJq, Y˚¯
and
´
pX,˜Xq, Y˚¯
d“´
pX,˜XqswappJq, Y¯
. (10)
Furthermore, in the knockoff framework [ 4], letw“wppX,˜Xq, yqandw˚“wppX,˜Xq, y˚q. Then,
for all jPJ,
Ppwją0q`P`
w˚
ją0˘
ď1. (11)
Eq.(11) implies a “no free lunch” situation for selection power when there is exact reconstructability.
To address the reconstructability issue, [ 54] proposed two methods in Gaussian design. The first is
the minimal variance-based reconstructability (MVR) knockoff, in which the knockoff ˜Xis sampled
to minimize the loss
LMVR“pÿ
j“11
E”
Var´
Xj|X´j,˜X¯ı. (12)
Note that this is equivalent to maximizing E”
Var´
Xj|X´j,˜X¯ı
for all jPrps. Another approach
is the maximum entropy (ME) knockoff, where ˜Xis sampled to maximize
LME“ż ż
ppx,˜xqlogpppx,˜xqqd˜x dx. (13)
Under Gaussian design, both optimizations have closed-form solutions. Since Xis Gaussian,pX,˜Xq
must also be jointly Gaussian to satisfy the swap property. To optimize, one first calculates the
covariance matrix using the SDP method in [ 4], yielding a diagonal matrix S. Then, both MVR and
ME reduce to an optimization on S:
LMVRpSq9Tr`
G´1
S˘
“2pÿ
j“11
λjpGSq
and LMEpSq“log det`
G´1
S˘
“2pÿ
j“1logˆ1
λjpGSq˙
. (14)
Although both methods show high power for feature selection, neither MVR nor ME can be directly
extended to arbitrary distributions due to the intractability of conditional variance and likelihood.
In DeepDRK, we consider regularizing with a sliced-Wasserstein-based dependency correlation,
which can be considered a stronger dependency regularization than entropy. A post-training pertur-
bation is also applied to further reduce collinearity. However, the theoretical understanding of how
these affect the swap property and power remains an open question.
15B DeepDRK Model Architecture and Training Algorithm
B.1 Model Architecture
DeepDRK’s knockoff Transformer (KT) model is based on the popular Vision Transformer (ViT) [ 16].
The primary difference is that the input dimension is 1D, not 2D, for X. We do not use patches as
input; instead, we treat all entries of Xto account for correlations between each pair of entries in the
knockoff ˜X. This structure is similar to the original Transformer [ 59]. Nonetheless, we retain other
components from ViT, such as patch embedding, PreNorm, and 1D-positional encoding [16]. Since
knockoff generation requires a distribution, we feed Xand a uniformly distributed random variable
Zwith the same dimension as Xto inject randomness. Specifically for the DeepDRK model, we use
8 attention heads, 8 layers, and a hidden dimension of 512 in the ViT model.
The swapper module, first introduced in DDLK [ 55], produces the index subset Bfor the adversarial
swap attack. Optimizing knockoff against these adversarial swaps enforces the swap property.
Specifically, the swapper consists of a matrix with shape 2ˆp(i.e., trainable model weights), where
pis the dimension of X. This matrix controls the Gumbel-softmax distribution [ 26] for all pentries.
Each entry is represented by a binary Gumbel-softmax random variable (i.e., it can only take values
of 0 or 1). To generate the subset B, we sample bjfrom the corresponding j-th Gumbel-softmax
random variable, and Bis defined astjPrps;bj“1u. During optimization, we maximize Eq. (5)
with respect to the weights ωiof the swapper Sωi, so that the sampled indices, with which the swap
is applied, lead to a higher SWD in the objective in Eq. (5). Minimizing this objective with respect to
˜Xθrequires the knockoff to counteract the adversarial swaps, thereby enforcing the swap property.
Compared to DDLK, the proposed DeepDRK utilizes multiple independent swappers (i.e., K“2).
And we set the temperature for the Gumbel-softmax to be 0.2.
B.2 Training Algorithm
In Algorithm 1, we provide pseudo code for training the Knockoff Transformer and the swappers
(i.e., the first stage shown in Figure 1).
Algorithm 1 DeepDRK Training
1:Input: Knockoff transformer ˜Xθ, denoted as gθp¨q; swappers Sω; number of swappers K;
learning rate αsfor the swappers; learning rate αθfor the knockoff transformer; early stop
tolerance η; number of epochs T; batch size Bs; dataset D; swapper update frequency γ“3
2:Output: θfor˜Xθ
3:Split dataset Dinto training set Dtrainand validation set Dval
4:Initialize the knockoff transformer gθp¨qwith random weights
5:Initialize swappers Sωi,i“1, . . . , K with random weights
6:Initialize the AdamW optimizer optθwith learning rate αθforgθp¨q
7:Initialize the AdamW optimizer optωiwith learning rate αsforSωi,i“1, . . . , K
8:fort“1toTdo
9: forl“1to|Dtrain|
Bsdo
10: Sample Bssamples of XfromDtrain:Xl
11: Generate knockoff ˜Xl“gθpXlq
12: Calculate LSLpXl,˜Xl,tSωiuK
i“1qandLDRLpXl,˜Xlq
13: θÐθ`optθpLSLpXl,˜Xl,tSωiuK
i“1q`LDRLpXl,˜Xlqq
14: iflmod γ“0then
15: ωiÐωi`optωip´LSLpXl,˜Xl,tSωiuK
i“1qq,i“1, . . . , K
16: end if
17: end for
18: Calculate the validation loss on Dval:Lval
SL`Lval
DRL
19: ifLval
SL`Lval
DRLmeets early stop condition at tolerance ηthen
20: break
21: end if
22:end for
16C From Wasserstein to Sliced Wasserstein Distance
The Wasserstein distance has gained popularity in both mathematics and machine learning due to its
ability to compare different types of distributions [ 60] and its differentiability [ 3]. Here, we provide
its definition. Let X, Y be two Rdrandom vectors following distributions PX, PYwith finite p-th
moments. The Wasserstein- pdistance between PXandPYis:
WppPX, PYq“ inf
γPΓpPX,PYq`
Epx,yq„γ}x´y}p˘1
p(15)
where ΓpPX, PYqdenotes the set of all joint distributions such that their marginals are PXandPY.
When d“1, the Wasserstein distance between two one-dimensional distributions can be written as:
WppPX, PYq“ˆż1
0|F´1
Xpvq´F´1
Ypvq|pdv˙1
p
(16)
“}F´1
X´F´1
Y}Lppr0,1sq,
where FXandFYare the cumulative distribution functions (CDFs) of PXandPY, respectively.
Moreover, if p“1, the Wasserstein distance further simplifies to
W1pPX, PYq“ż
|FXpvq´FYpvq|dv“}FX´FY}L1pRq. (17)
From the above, it is evident that the 1D Wasserstein distance is straightforward to compute, leading
to the development of the sliced Wasserstein distance (SWD) [ 9]. To leverage this computational
advantage in 1D, one first projects both distributions uniformly onto a 1D direction and computes the
Wasserstein- pdistance between the two projected distributions. SWD is then calculated by taking the
expectation over the random direction. Specifically, let µPSd´1denote a projection direction, and
the push-forward distribution [ 60]µ7PXdenotes the law of µTX. When µis uniformly distributed
on the d-dimensional sphere, the p-sliced Wasserstein distance between PXandPYis given by:
SWppPX, PYq“ż
µPSd´1Wppµ7PX, µ7PYqdµ. (18)
Combining Eq. (18) and Eq. (16) yields:
SWppPX, PYq“
ż
µPSd´1ˆż1
0|pFµ
Xq´1pvq´pFµ
Yq´1pvq|pdv˙1
p
dµ (19)
“ż
µPSd´1ż
|Fµ
Xpvq´Fµ
Ypvq|dv dµ when p“1. (20)
Despite faster computation, the convergence of SWD has been shown to be equivalent to the conver-
gence of the Wasserstein distance under mild conditions [ 10]. In practice, the expectation over µis
approximated by a finite summation over a number of projection directions chosen uniformly from
Sd´1.
D Sliced Wasserstein Correlation
The idea of metricizing independence is recently advanced using the Wasserstein distance [ 61,43].
Given a joint distribution pX, Yq „ΓXYand its marginal distributions X„PX, Y„PY, the
Wasserstein Dependency (WD) between XandYis defined by WDpX, Yq“WppΓXY, PXbPYq.
A trivial observation is that WDpX, Yq “0implies that XandYare independent. Due to the
high computational cost of Wasserstein distance, sliced Wasserstein dependency (SWDep) [ 33] is
developed using sliced Wasserstein distance (see Appendix C for SWD details). The SW dependency
(SWDep) between XandYis defined as SWppΓXY, PXbPYq, and a zero SWDep indicates
independence. Since the dependency metric is not bounded from above, sliced Wasserstein correlation
171 5 10 15 20
Epoch0.00.20.40.60.81.01.2Normalized ValueSwap Property v.s. Dependency Regularization
DeepDRK(Swap)
DeepDRK(Depend.)
Deep Knockoff(Swap)
Deep Knockoff(Depend.)
KnockoffGAN(Depend.)
sRMMD(Swap)
sRMMD(Depend.)
DDLK(Swap)
DDLK(Depend.)Figure 8: The competing relationship between the swap property ( LSLin solid curves) and dependency
regularization ( LDRLin dashed curves).
(SWC) is introduced to normalize SWDep. More specifically, the SWC between XandYis defined
as
SWC ppX, Yq:“SWDepppX, Yqb
SWDepppX, XqSWDepppY, Yq
“SWD ppΓXY, PXbPYqa
SWD ppΓXX, PXbPXqSWD ppΓY Y, PYbPYq, (21)
where ΓXXandΓYYare the joint distributions of pX, XqandpY, Yqrespectively. It is shown that
0ďSWC ppX, Yqď1andSWC ppX, Yq“1when Xhas a linear relationship with Y[33].
In terms of computing SWC, we follow [ 33] and consider both laws of XandYto be sums of
2nDiracs, i.e., both variables are empirical distributions with data Ifull“tpxi,yiqu2n
i“1. Define
I“tpxi,yiqun
i“1and˜I“tp˜xi,˜yiqun
i“1, wherep˜xi,˜yiq“pxn`i,yn`iq. Because data is i.i.d., I
and˜Iare independent. We further introduce the following notation:
Ixy“tpxi,yiqun
i“1,˜Ixy“tp˜xi,yiqun
i“1
Ixx“tpxi,xiqun
i“1,˜Ixx“tp˜xi,xiqun
i“1,
Iyy“tpyi,yiqun
i“1,˜Iyy“tp˜yi,yiqun
i“1
Then the empirical SWC can be computed by:
{SWC ppX, Yq:“SWD p´
IIxy, IrIxy¯
c
SWD p´
IIxx, IrIxx¯
SWD p´
IIyy, IrIyy¯. (22)
E Competing Losses
In Figure 8, we present scaled LSLandLDRLcurves for each model considered. For better visualiza-
tion, these curves are normalized to values between 0 and 1. We observe the first 20 epochs, as LDRL
flattens out in later epochs without further decrease. The competition between losses is evident: as
LSLdecreases, LDRLincreases, indicating difficulty in maintaining low reconstructability.
F Proofs
F.1 Proof of Lemma 3.1
Assuming all conditions in [ 41] hold, we prove this by applying inequalities on SWDpˆPn,ˆPB
nqand
SWDpP, PBq:
SWDpˆPn,ˆPB
nqďSWDpˆPn, Pq`SWDpP, PBq`SWDpPB,ˆPB
nq
“SWDpP, PBq`Opn´1{2q, (23)
180.0 0.2 0.4 0.6 0.8 1.0
n
0.040.060.080.100.120.14FDR
0.0 0.2 0.4 0.6 0.8 1.0
n
0.20.40.60.81.0Power Dataset
Gaussian Mixture
Copula: Clayton & Exponential
Copula: Clayton & Gamma
Copula: Joe & Exponential
Copula: Joe & GammaFigure 9: The effect of αnfor˜XDRP
θin Eq. (8) on FDR and power. When αnis 0, we consider the
knockoff generated from the knockoff transformer without any dependency regularization perturbation.
When αnis 1, there is only perturbation Xrpwithout the knockoff. The sample size n“2000 .
where the first inequality is a direct application of the triangle inequality, and the second equality
follows from Theorem 5 in [41]. Similarly, we obtain
SWDpP, PBqďSWDpP,ˆPnq`SWDpˆPn,ˆPB
nq`SWDpˆPB
n, PBq
“SWDpˆPn,ˆPB
nq`Opn´1{2q. (24)
Combining Eq. (23) and Eq. (24), we have
SWDpP, PBq“SWDpˆPn,ˆPB
nq`Opn´1{2q. (25)
F.2 Proof of Proposition 3.2
From Eq. (9), we know ˜XDRP
θ,na.s.ÝÝÑ ˜XθasnÑ8 . Combining this with Eq. (25), we obtain
SWDpP, PBq“SWDpˆPn,ˆPB
nq“SWDpˆPn,DRP,ˆPB
n,DRPqasnÑ8 .
G Effect of αnin˜XDRP
θ
As discussed in Section 3.2, obtaining the swap property while maintaining low reconstructability at
the sample level is empirically challenging. To address this, dependency regularization perturbation
(DRP) is introduced. In this section, we evaluate the effect of αnin˜XDRP
θin Eq. (9)on feature
selection performance. Results are summarized in Figure 9 for five synthetic datasets with the sample
sizen“2000 .
When αnis decreased, we observe an increase in power. However, the FDR exhibits a bowl-shaped
pattern, consistent with the findings of [ 54]: introducing the permuted Xrpreduces reconstructability,
thereby increasing power. However, an overly dominant Xrpcompromises the swap property, resulting
in higher FDRs. Based on our hyperparameter search and the results in Figure 9, we recommend
choosing αnwithin the range of 0.4 to 0.5.
H Implementation Details
H.1 Training
To fit models, we first split datasets of Xinto training and validation sets with an 8:2 ratio. The
training sets are used for model optimization, and the validation sets are used for early stopping based
on the validation loss, with a patience period of 6. Since knockoffs are not unique [ 11], testing sets are
not required. To evaluate DeepDRK’s performance, we compare it with four state-of-the-art (SOTA)
deep-learning-based knockoff generation models, focusing on non-parametric data. Specifically, we
19Parameter Value Parameter Value
SωLearning Rate 1ˆ10´3˜XθLearning Rate 1ˆ10´5
Dropout Rate 0.1 # of Epochs 200
Batch Size 64 λ1 30.0
λ2 1.0 λ3 20.0
Early Stop Tolerance 6 αn 0.5
Table 3: Training configuration.
include Deep Knockoff [ 47]12, DDLK [ 55]13, KnockoffGAN [ 27]14, and sRMMD [ 38]15. We use the
recommended hyperparameter settings for each model, with the only difference being the number of
training epochs, set to 200 for consistency across models.
We follow the model configuration in Table 3 to optimize DeepDRK. The architecture of the swappers
Sωis based on [ 55]. Both the swappers and ˜Xθare trained using the AdamW optimizer [ 36].
During training, we alternately optimize ˜Xθand the swappers Sω, updating weights θthree times
for each update of weights ω. This training scheme is similar to GAN training [ 21], though without
discriminators. We apply early stopping to prevent overfitting. A pseudocode of the optimization
is provided in Appendix B.2. In experiments, we set αn“0.5universally as the dependency
regularization coefficient due to its consistent performance16. A discussion on the effect of αnis
provided in Appendix G.
Once trained, models generate the knockoff ˜Xgiven Xdata. The generated ˜Xis then combined with
Xfor feature selection. Experiments are conducted on a single NVIDIA V100 16GB GPU.
H.2 Feature Selection
Once ˜Xis obtained, feature selection is performed in three steps. We first concatenate Xand˜X
to form an nˆ2pdesign matrix pX,˜Xq. In the second step, we use Ridge regression to get the
estimated regression coefficients tˆβju2p
j“1from YandpX,˜Xq. Finally, we compute the knockoff
statistics wj“|ˆβj|´|ˆβj`p|, forj“1,2, . . . , p , and then select features using the threshold defined
in Eq. (3). We set q“0.1as the FDR threshold, following its common use in other knockoff-based
feature selection studies [ 47,38]. Each experiment is repeated 600 times, with results reported as the
average power and FDR over these 600 repetitions.
H.3 Data Preparation
H.3.1 Weights for the Gaussian mixture models Set No. π1 π2 π3
1 0.562 0.384 0.054
2 0.430 0.168 0.402
3 0.317 0.324 0.359
4 0.316 0.388 0.296
5 0.439 0.488 0.073
6 0.314 0.041 0.645
7 0.656 0.282 0.062
8 0.200 0.300 0.500
9 0.500 0.300 0.200
10 0.333 0.333 0.333
Table 4: 10 sets of pπ1, π2, π3qfor the
Gaussian mixture models.Table 4 includes 10 sets of pπ1, π2, π3qfor the Gaussian
mixture models.
H.3.2 Preparation of the RNA Data
We first normalize the raw data Xto value ranger0,1sand
then standardize it to have zero mean and unit variance. Y
is synthesized according to X. We consider two different
ways of synthesizing Y. The first, denoted as “Linear”, is
similar to the previous setup in the full synthetic case with
Y„NpXTβ,1qandβ„p
12.5¨?
N¨Rademacher(0.5) .
For the second, denoted as “Tanh”, the response Yis
12https://github.com/msesia/deepknockoffs
13https://github.com/rajesh-lab/ddlk
14https://github.com/vanderschaarlab/mlforhealthlabpub/tree/main/alg/knockoffgan
15https://github.com/ShoaibBinMasud/soft-rank-energy-and-applications
16We present this value for its consistent performance; however, it may not be the globally optimal value.
Future work may improve on αn’s design.
20Reference Type Metabolite Source Meatbolite Source
PubChempalmitate CID: 985 taurocholate CID: 6675
cholate CID: 221493 p-hydroxyphenylacetate CID: 127
linoleate CID: 5280450 deoxycholate CID: 222528
taurochenodeoxycholate CID: 387316
Publications12.13-diHOME [7] dodecanedioate [7]
arachidonate [7] eicosatrienoate [7, 5]
eicosadienoate [7] docosapentaenoate [7, 5]
taurolithocholate [7] salicylate [7]
saccharin [7] 1.2.3.4-tetrahydro-beta-carboline-1.3-dicarboxylate [7]
oleate [5] arachidate [5]
glycocholate [5] chenodeoxycholate [5]
phenyllactate [38, 31] glycolithocholate [5]
urobilin [38, 46] caproate [38, 32]
hydrocinnamate [38, 29] myristate [38, 18]
adrenate [38, 35] olmesartan [38, 48]
tetradecanedioate [56, 39] hexadecanedioate [56, 39]
oxypurinol [8] porphobilinogen [40]
caprate [52, 53] undecanedionate [32, 58]
stearate [2, 5] oleanate [44]
glycochenodeoxycholate [50] sebacate [32]
nervonic acid [57] lithocholate [5]
Preprintsalpha-muricholate [42] tauro-alpha-muricholate/tauro-beta-muricholate [42]
17-methylstearate [42] myristoleate [42]
taurodeoxycholate [42] ketodeoxycholate [42]
Table 5: IBD-associated metabolites that are supported by the literature. This table includes all 47
referenced metabolites for the IBD case study. Each metabolite is supported by one of the three
sources: PubChem, peer-reviewed publications or preprints. For PubChem case, we report the
PubChem reference ID (CID), and for the other two cases we report the publication references.
generated following the expression:
kPrm{4s
φp1q
k, φp2q
k„Np1,1q
φp3q
k, φp4q
k, φp5q
k„Np2,1q
Y|X“ϵ`m{4ÿ
k“1φp1q
kX4k´3`φp3q
kX4k´2
`φp4q
ktanh´
φp2q
kX4k´1`φp5q
kX4k¯
,(26)
where ϵfollows the standard normal distribution and the 20 covariates are sampled uniformly.
H.3.3 Metabolite Information for the IBD Study
Here we provide the implementation details for the experiments described in Section 4.3. In Table 5,
we provide all 47 referenced metabolites based on our comprehensive literature review.
I Additional Results
Abbreviation Full Name
J+G Copula: Joe & Gamma
C+G Copula: Clayton & Gamma
C+E Copula: Clayton & Exponential
J+E Copula: Joe & Exponential
MG Mixture of Gaussians
Table 6: The abbreviations of the names for the datasets.In this section, we include all results that
are deferred from the main paper.
I.1 Swap Property
We use different metrics to empirically eval-
uate the swap property on the generated
knockoff ˜Xand the original data Xaccord-
ing to Eq. (1). In this paper, three metrics
are considered: mean discrepancy distance
with linear kernel, or “MMD(Linear)” for
21Dataset MMD(Linear) SWD 1SWD 2
DDLKJ+G 2.68 0.18 0.08
C+G 2.49 0.18 0.07
C+E 1.80 0.15 0.05
J+E 2.29 0.15 0.06
MG 306.49 2.15 9.99
KnockoffGANJ+G 7.01 0.15 0.08
C+G 5.11 0.16 0.04
C+E 0.52 0.06 0.01
J+E 1.24 0.08 0.02
MG 1.08 3.28 26.09
Deep KnockoffJ+G 13.09 0.21 0.11
C+G 19.04 0.27 0.14
C+E 6.65 0.18 0.07
J+E 6.78 0.19 0.13
MG 2770.00 8.98 196.54
DeepDRK (Ours)J+G 0.47 0.13 0.06
C+G 0.71 0.14 0.05
C+E 0.23 0.09 0.02
J+E 0.14 0.10 0.04
MG 380 6.13 84.37
sRMMDJ+G 130.02 0.68 0.71
C+G 175.74 0.73 0.96
C+E 49.09 0.41 0.35
J+E 33.24 0.35 0.29
MG 3040 8.51 142.99
Table 7: Evaluation of the swap property. This table empirically measures the swap property by
three different metrics: MMD(Linear), SWD 1, and SWD 2. The evaluation considers all baseline
models and all datasets in the synthetic dataset setup. For space consideration, we use abbreviations
to indicate the name of the datasets. The full name can be found in Table 6.
short; sliced Wasserstein-1 distance (SWD 1); and sliced Wasserstein-2 distance (SWD 2). We mea-
sure the sample level distances between the vector that concatenates Xand˜X(i.e.,pX,˜Xq) and
the vector after randomly swapping the entries (i.e., pX,˜XqswappBq). To avoid repetition, please
refer to section 2.1 and Eq. (1)for the definition of notation. Empirically, it is time consuming
to evaluate all subsets Bof the index set rps. As a result, we alternatively define a swap ratio
rsPt0.1,0.3,0.5,0.7,0.9u. The swap ratio controls the amount of uniformly sampled indices (i.e.,
the cardinality |B| “rs¨p) in a subset of rps. For any Xand˜Xfrom the same experiment, 5
different subsets Bare formed according to 5 different swap ratios. We report the average values
over the swap ratios to represent the empirical quantification of the swap property. Results can be
found in Table 7.
Clearly, compared to other models, the proposed DeepDRK achieves the smallest values in almost
every entry across the three metrics and the first 4 datasets (i.e., J+G, C+G, C+E and J+E in Table 7).
This explains why DeepDRK has lower FDRs as DeepDRK maintains the swap property relatively
better than the baseline models (see results in Figure 2). Similarly, we observe that KnockoffGAN
also achieves relatively small values, which leads to well-controlled FDRs compared to other baseline
models. Overall, this verifies the argument in Cand `es et al. [11] that the swap property is important
in guaranteeing FDR during feature selection.
However, we observe a difference for Gaussian mixture data. The proposed DeepDRK achieves the
best performance in FDR control and power (see results in Figure 2), yet its swap property measured
under the metrics in Table 7 is not the lowest. Despite this counter-intuitive observation, we want
to highlight that it does not conflict with the argument in Cand `es et al. [11]. Rather, it supports our
statement that the low reconstructability and the swap property cannot be achieved at the sample
level (e.g., the free lunch dilemma in practice). After all, the swap property is not the only factor that
determines FDR and power during feature selection.
220.20.40.60.81.0Power0.82
0.650.78
0.440.700.97
0.690.74
0.260.580.97
0.88
0.82
0.54
0.171.00 0.99 0.99 0.99 0.99
0.950.99 0.99 0.99 0.99Sample Size: 200
Gaussian Mixture
Copula: Clayton & ExponentialCopula: Clayton & Gamma Copula: Joe & ExponentialCopula: Joe & Gamma
Datasets0.00.10.20.30.40.50.60.70.8FDR
0.11 0.11
0.080.120.090.40
0.120.10 0.110.080.37
0.33
0.100.18
0.080.75
0.64
0.530.72
0.62
0.210.63
0.520.72
0.590.20.40.60.81.0Power0.98
0.920.97
0.480.94
0.890.98
0.190.660.690.980.95
0.110.650.890.99 1.00 1.00 1.00 1.00 0.99 1.00 1.00 1.00 1.00Sample Size: 2000
Methods
DeepDRK
DeepDRK
No swapper
No REx
K=1
Gaussian Mixture
Copula: Clayton & ExponentialCopula: Clayton & Gamma Copula: Joe & ExponentialCopula: Joe & Gamma
Datasets0.00.10.20.30.40.50.60.70.8FDR
0.070.08
0.040.09
0.05 0.060.14
0.060.11
0.07 0.060.10
0.040.110.080.290.770.79
0.62
0.290.640.79Figure 10: Power and FDR in the ablation studies. The red horizontal line indicates the 0.1 FDR
threshold. DeepDRK:is the model with dependency regularized perturbation removed. Kindicates
the number of swappers.
Nonnull Null0.05
0.000.050.100.150.20MeanDeepDRK
Nonnull Null0.05
0.000.050.100.150.20sRMMD
Nonnull Null0.05
0.000.050.100.150.20Deep Knockoff
Nonnull Null0.05
0.000.050.100.150.20KnockoffGAN
Nonnull Null0.05
0.000.050.100.150.20DDLK
Datasets
Gaussian Mixture
Copula: Clayton & Exponential
Copula: Clayton & Gamma
Copula: Joe & Exponential
Copula: Joe & Gamma
Figure 11: Knockoff statistics ( wj) for different knockoff models on the synthetic datasets. Each bar
in the plot represents the mean of the null/nonnull knockoff statistics averaging on 600 experiments.
The error bar indicates the standard deviation. The sample size is 2000.
I.2 Ablation Studies
In this subsection, we perform ablation studies on different terms introduced in Section 3.1.1, to show
the necessity of designing these terms during the optimization for knockoffs. We consider the fully
synthetic setup described in Section 4.1, and consider n“200andn“2000 . The distribution of β
isp
15¨?
N¨Rademacher(0.5) . We test the following terms: 1. REx; 2. the number of swappers K; 3.
Lswapper ; 4. the dependency regularized perturbation (denoted as DeepDRK:). Five synthetic datasets
are considered as before and we report the values for FDR and Power under each setup. The results
are presented in Figure 10.
Figure 10 illustrates the clear drawbacks of using only a single swapper ( K“1) and the case without
the loss term REx. In those two cases, we fail to control the FDR on all datasets. The REx term
is essential, as it ensures that the adversarial attacks generated by different swappers are addressed
simultaneously. Lswapper is also an important term, as it promotes a diverse adversarial environments.
Without this term we observe an increase in FDR compared to DeepDRK or DeepDRK:. The
difference between DeepDRK and DeepDRK:is more subtle as DeepDRK:has already obtained
high quality knockoffs. However, we empirically observe that adding the perturbation further
increases the power for some datasets without sacrificing the FDR controllability. To interpret these
observations, we follow a similar procedure in Section 4.1 to study the distribution of the knockoff
statistics. Results are included in Section I.3.
Overall, we verify that all terms are necessary components to achieve higher powers and controlled
FDRs through the ablation studies.
I.3 Analysis on the distribution of knockoff statistics
We present the additional results on the means and standard deviations of both null and nonnull
knockoff statistics under various experimental setups.
Figure 11 shows the results on wjforn“2000 and it complements the results on Power and FDR
in Figure 2. We notice that all models have concentrated null features around zero and relatively
high values for the nonnull knockoff statistics for the case with 2000 samples. This corresponds to
consistently accurate FS results across all models and datasets, as shown in Figure 2.
23Nonnull Null0.1
0.00.10.20.30.40.5MeanDeepDRK
Nonnull Null0.1
0.00.10.20.30.40.5sRMMD
Nonnull Null0.1
0.00.10.20.30.40.5Deep Knockoff
Nonnull Null0.1
0.00.10.20.30.40.5KnockoffGAN
Nonnull Null0.1
0.00.10.20.30.40.5DDLK
base
0.7
0.8Figure 12: Knockoff statistics ( wj) for different models with the increased correlation of the Gaussian
mixture data. Each bar in the plot represents the mean of the null/nonnull knockoff statistics averaging
on 600 experiments. The error bar indicates the standard deviation. The sample size is 200.
Nonnull Null0.05
0.000.050.100.150.20MeanDeepDRK
Nonnull Null0.05
0.000.050.100.150.20sRMMD
Nonnull Null0.05
0.000.050.100.150.20Deep Knockoff
Nonnull Null0.05
0.000.050.100.150.20KnockoffGAN
Nonnull Null0.05
0.000.050.100.150.20DDLK
base
0.7
0.8
Figure 13: Knockoff statistics ( wj) for different models with the increased correlation of the mixture
of Gaussians data. Each bar in the plot represents the mean of the null/nonnull knockoff statistics
averaging on 600 experiments. The error bar indicates the standard deviation. The sample size
considered is 2000.
Figure 12 and Figure 13 show the results for the Gaussian mixture data with increased correlations
(ρbase“0.7and0.8) forn“200andn“2000 respectively. The figures complement the FDR-
power results in Figure 3. It is clear for both n“200andn“2000 cases, all models experience
an increase in FDR and a decrease in power. This phenomenon can be reflected by the positive
shifts of the knockoff statistics for the null features in Figure 12 and Figure 13. However, DeepDRK
significantly controls the shifts, achieving the best results with the lowest FDRs and comparable
power as shown in Figure 3.
In addition, we also compare the knockoff statistics for the models considered in the ablation studies
in I.2. The results for both n“200andn“2000 are in Figure 14 and Figure 15. Although the null
knockoff statistics for DeepDRK, DeepDRK:and “No Lswapper ” models concentrate symmetrically
around zero, the heights of the nonnull knockoff statistics for DeepDRK are the highest, resulting
higher power. And because some nonnull knockoff statistics have small values for the DeepDRK:
and “No Lswapper ” cases, we also expect them to have higher FDRs (see Figure 10). On the other
hand, compared to DeepDRK, the models of “No REx” and “ K“1” experience clear positive shifts
for the null knockoff statistics, leading to higher FDRs during FS (see Figure 10).
I.4 Training time
We consider evaluating and comparing model training runtime in Table 8 with the (2000, 100) setup,
as it is common in the existing literature. Although DeepDRK is not the fastest among the compared
models, the time cost—7.35 minutes—is still short, especially when the performance is taken into
account.
Nonnull Null0.2
0.00.20.40.6MeanDeepDRK
Nonnull Null0.2
0.00.20.40.6DeepDRK
Nonnull Null0.2
0.00.20.40.6No swapper
Nonnull Null0.2
0.00.20.40.6No REx
Nonnull Null0.2
0.00.20.40.6K=1
Datasets
Gaussian Mixture
Copula: Clayton & Exponential
Copula: Clayton & Gamma
Copula: Joe & Exponential
Copula: Joe & Gamma
Figure 14: Knockoff statistics ( wj) for different models in ablation studies. Each bar in the plot
represents the mean of the null/nonnull knockoff statistics averaging on 600 experiments. The error
bar indicates the standard deviation. Krefers to the number of swappers. The sample size is 200.
24Nonnull Null0.2
0.00.20.40.6MeanDeepDRK
Nonnull Null0.2
0.00.20.40.6DeepDRK
Nonnull Null0.2
0.00.20.40.6No swapper
Nonnull Null0.2
0.00.20.40.6No REx
Nonnull Null0.2
0.00.20.40.6K=1
Datasets
Gaussian Mixture
Copula: Clayton & Exponential
Copula: Clayton & Gamma
Copula: Joe & Exponential
Copula: Joe & GammaFigure 15: Knockoff statistics ( wj) for different models in ablation studies. Each bar in the plot
represents the mean of the null/nonnull knockoff statistics averaging on 600 experiments. Krefers to
the number of swappers. The sample size considered is 2000.
DeepDRK Deep Knockoff sRMMD KnockoffGAN DDLK
7.35 min 1 .08 min 6 .38 min 10 .52 min 53 .63 min
Table 8: The training time for the models with n“2000 andp“100. The batch size is 64and the
models are all trained with 100epochs.
I.5 Additional Results for the IBD Study
Here we provide the supplementary information for the experimental results described in Section 4.3.
In Table 9, we provide the list of identified metabolites by each of the considered models. This table
provides additional information for Table 2 in the main paper which only includes metabolite counts
due to limited space.
25Metabolite DeepDRK Deep Knockoff sRMMD KnockoffGAN DDLK
12.13-diHOME ˚
9.10-diHOME
caproate ˚ ˚ ˚ ˚
hydrocinnamate
mandelate
3-hydroxyoctanoate
caprate
indoleacetate ˚
3-hydroxydecanoate
dodecanoate ˚
undecanedionate ˚ ˚
myristoleate
myristate
dodecanedioate ˚
pentadecanoate
hydroxymyristate
palmitoleate
palmitate ˚
tetradecanedioate ˚
10-heptadecenoate
2-hydroxyhexadecanoate
alpha-linolenate ˚
linoleate
oleate
stearate ˚
hexadecanedioate ˚ ˚ ˚
10-nonadecenoate
nonadecanoate
17-methylstearate ˚ ˚ ˚
eicosapentaenoate ˚ ˚ ˚
arachidonate ˚ ˚ ˚ ˚
eicosatrienoate ˚ ˚ ˚
eicosadienoate ˚ ˚ ˚ ˚
eicosenoate
arachidate ˚
phytanate
docosahexaenoate ˚ ˚ ˚
docosapentaenoate ˚ ˚ ˚ ˚
adrenate ˚ ˚ ˚ ˚ ˚
13-docosenoate
eicosanedioate ˚ ˚
oleanate
masilinate
lithocholate ˚
chenodeoxycholate
deoxycholate ˚ ˚ ˚
hyodeoxycholate/ursodeoxycholate
ketodeoxycholate ˚
alpha-muricholate ˚
cholate ˚
glycolithocholate ˚
glycochenodeoxycholate
glycodeoxycholate
glycoursodeoxycholate
glycocholate
taurolithocholate ˚
taurochenodeoxycholate
taurodeoxycholate
taurohyodeoxycholate/tauroursodeoxycholate
tauro-alpha-muricholate/tauro-beta-muricholate ˚ ˚
taurocholate
salicylate ˚ ˚ ˚ ˚
saccharin ˚
azelate ˚
sebacate ˚ ˚
carboxyibuprofen
olmesartan
1.2.3.4-tetrahydro-beta-carboline-1.3-dicarboxylate
4-hydroxystyrene ˚ ˚ ˚
acetytyrosine
alpha-CEHC
carnosol ˚
oxypurinol
palmitoylethanolamide
phenyllactate ˚ ˚ ˚ ˚
p-hydroxyphenylacetate ˚ ˚ ˚
porphobilinogen ˚
urobilin ˚ ˚ ˚ ˚
nervonic acid
oxymetazoline ˚ ˚ ˚
Table 9: A list of literature-supported metabolites out of a total of 80 candidates. “ ˚” indicates the
important metabolites marked by the corresponding algorithms.
26NeurIPS Paper Checklist
The checklist is designed to encourage best practices for responsible machine learning research,
addressing issues of reproducibility, transparency, research ethics, and societal impact. Do not remove
the checklist: The papers not including the checklist will be desk rejected. The checklist should
follow the references and follow the (optional) supplemental material. The checklist does NOT count
towards the page limit.
Please read the checklist guidelines carefully for information on how to answer these questions. For
each question in the checklist:
• You should answer [Yes] , [No] , or [NA] .
•[NA] means either that the question is Not Applicable for that particular paper or the
relevant information is Not Available.
• Please provide a short (1–2 sentence) justification right after your answer (even for NA).
The checklist answers are an integral part of your paper submission. They are visible to the
reviewers, area chairs, senior area chairs, and ethics reviewers. You will be asked to also include it
(after eventual revisions) with the final version of your paper, and its final version will be published
with the paper.
The reviewers of your paper will be asked to use the checklist as one of the factors in their evaluation.
While ”[Yes] ” is generally preferable to ”[No] ”, it is perfectly acceptable to answer ”[No] ”
provided a proper justification is given (e.g., ”error bars are not reported because it would be too
computationally expensive” or ”we were unable to find the license for the dataset we used”). In
general, answering ”[No] ” or ”[NA] ” is not grounds for rejection. While the questions are phrased
in a binary way, we acknowledge that the true answer is often more nuanced, so please just use your
best judgment and write a justification to elaborate. All supporting evidence can appear either in the
main paper or the supplemental material, provided in appendix. If you answer [Yes] to a question, in
the justification please point to the section(s) where related material for the question can be found.
IMPORTANT, please:
•Delete this instruction block, but keep the section heading “NeurIPS paper checklist” ,
•Keep the checklist subsection headings, questions/answers and guidelines below.
•Do not modify the questions and only use the provided macros for your answers .
1.Claims
Question: Do the main claims made in the abstract and introduction accurately reflect the
paper’s contributions and scope?
Answer: [Yes]
Justification: We clearly describe the scope and the objective of the paper in the abstract and
the introduction sections (also in the related work section).
Guidelines:
•The answer NA means that the abstract and introduction do not include the claims
made in the paper.
•The abstract and/or introduction should clearly state the claims made, including the
contributions made in the paper and important assumptions and limitations. A No or
NA answer to this question will not be perceived well by the reviewers.
•The claims made should match theoretical and experimental results, and reflect how
much the results can be expected to generalize to other settings.
•It is fine to include aspirational goals as motivation as long as it is clear that these goals
are not attained by the paper.
2.Limitations
Question: Does the paper discuss the limitations of the work performed by the authors?
Answer: [Yes]
27Justification: The limitation is described in the footnote 15 on page 20.
Guidelines:
•The answer NA means that the paper has no limitation while the answer No means that
the paper has limitations, but those are not discussed in the paper.
• The authors are encouraged to create a separate ”Limitations” section in their paper.
•The paper should point out any strong assumptions and how robust the results are to
violations of these assumptions (e.g., independence assumptions, noiseless settings,
model well-specification, asymptotic approximations only holding locally). The authors
should reflect on how these assumptions might be violated in practice and what the
implications would be.
•The authors should reflect on the scope of the claims made, e.g., if the approach was
only tested on a few datasets or with a few runs. In general, empirical results often
depend on implicit assumptions, which should be articulated.
•The authors should reflect on the factors that influence the performance of the approach.
For example, a facial recognition algorithm may perform poorly when image resolution
is low or images are taken in low lighting. Or a speech-to-text system might not be
used reliably to provide closed captions for online lectures because it fails to handle
technical jargon.
•The authors should discuss the computational efficiency of the proposed algorithms
and how they scale with dataset size.
•If applicable, the authors should discuss possible limitations of their approach to
address problems of privacy and fairness.
•While the authors might fear that complete honesty about limitations might be used by
reviewers as grounds for rejection, a worse outcome might be that reviewers discover
limitations that aren’t acknowledged in the paper. The authors should use their best
judgment and recognize that individual actions in favor of transparency play an impor-
tant role in developing norms that preserve the integrity of the community. Reviewers
will be specifically instructed to not penalize honesty concerning limitations.
3.Theory Assumptions and Proofs
Question: For each theoretical result, does the paper provide the full set of assumptions and
a complete (and correct) proof?
Answer: [Yes]
Justification: Please refer to the method section and the appendix for the complete proof.
We provide assumptions in the method section.
Guidelines:
• The answer NA means that the paper does not include theoretical results.
•All the theorems, formulas, and proofs in the paper should be numbered and cross-
referenced.
•All assumptions should be clearly stated or referenced in the statement of any theorems.
•The proofs can either appear in the main paper or the supplemental material, but if
they appear in the supplemental material, the authors are encouraged to provide a short
proof sketch to provide intuition.
•Inversely, any informal proof provided in the core of the paper should be complemented
by formal proofs provided in appendix or supplemental material.
• Theorems and Lemmas that the proof relies upon should be properly referenced.
4.Experimental Result Reproducibility
Question: Does the paper fully disclose all the information needed to reproduce the main ex-
perimental results of the paper to the extent that it affects the main claims and/or conclusions
of the paper (regardless of whether the code and data are provided or not)?
Answer: [Yes]
Justification: We run the experiments multiple times for reproducibility check.
Guidelines:
28• The answer NA means that the paper does not include experiments.
•If the paper includes experiments, a No answer to this question will not be perceived
well by the reviewers: Making the paper reproducible is important, regardless of
whether the code and data are provided or not.
•If the contribution is a dataset and/or model, the authors should describe the steps taken
to make their results reproducible or verifiable.
•Depending on the contribution, reproducibility can be accomplished in various ways.
For example, if the contribution is a novel architecture, describing the architecture fully
might suffice, or if the contribution is a specific model and empirical evaluation, it may
be necessary to either make it possible for others to replicate the model with the same
dataset, or provide access to the model. In general. releasing code and data is often
one good way to accomplish this, but reproducibility can also be provided via detailed
instructions for how to replicate the results, access to a hosted model (e.g., in the case
of a large language model), releasing of a model checkpoint, or other means that are
appropriate to the research performed.
•While NeurIPS does not require releasing code, the conference does require all submis-
sions to provide some reasonable avenue for reproducibility, which may depend on the
nature of the contribution. For example
(a)If the contribution is primarily a new algorithm, the paper should make it clear how
to reproduce that algorithm.
(b)If the contribution is primarily a new model architecture, the paper should describe
the architecture clearly and fully.
(c)If the contribution is a new model (e.g., a large language model), then there should
either be a way to access this model for reproducing the results or a way to reproduce
the model (e.g., with an open-source dataset or instructions for how to construct
the dataset).
(d)We recognize that reproducibility may be tricky in some cases, in which case
authors are welcome to describe the particular way they provide for reproducibility.
In the case of closed-source models, it may be that access to the model is limited in
some way (e.g., to registered users), but it should be possible for other researchers
to have some path to reproducing or verifying the results.
5.Open access to data and code
Question: Does the paper provide open access to the data and code, with sufficient instruc-
tions to faithfully reproduce the main experimental results, as described in supplemental
material?
Answer: [Yes]
Justification: We provide open code access.
Guidelines:
• The answer NA means that paper does not include experiments requiring code.
•Please see the NeurIPS code and data submission guidelines ( https://nips.cc/
public/guides/CodeSubmissionPolicy ) for more details.
•While we encourage the release of code and data, we understand that this might not be
possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not
including code, unless this is central to the contribution (e.g., for a new open-source
benchmark).
•The instructions should contain the exact command and environment needed to run to
reproduce the results. See the NeurIPS code and data submission guidelines ( https:
//nips.cc/public/guides/CodeSubmissionPolicy ) for more details.
•The authors should provide instructions on data access and preparation, including how
to access the raw data, preprocessed data, intermediate data, and generated data, etc.
•The authors should provide scripts to reproduce all experimental results for the new
proposed method and baselines. If only a subset of experiments are reproducible, they
should state which ones are omitted from the script and why.
•At submission time, to preserve anonymity, the authors should release anonymized
versions (if applicable).
29•Providing as much information as possible in supplemental material (appended to the
paper) is recommended, but including URLs to data and code is permitted.
6.Experimental Setting/Details
Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
results?
Answer: [Yes]
Justification: They are included in the experiment section.
Guidelines:
• The answer NA means that the paper does not include experiments.
•The experimental setting should be presented in the core of the paper to a level of detail
that is necessary to appreciate the results and make sense of them.
•The full details can be provided either with the code, in appendix, or as supplemental
material.
7.Experiment Statistical Significance
Question: Does the paper report error bars suitably and correctly defined or other appropriate
information about the statistical significance of the experiments?
Answer: [Yes]
Justification: Results shown in the experiment section are repeated for 600 times.
Guidelines:
• The answer NA means that the paper does not include experiments.
•The authors should answer ”Yes” if the results are accompanied by error bars, confi-
dence intervals, or statistical significance tests, at least for the experiments that support
the main claims of the paper.
•The factors of variability that the error bars are capturing should be clearly stated (for
example, train/test split, initialization, random drawing of some parameter, or overall
run with given experimental conditions).
•The method for calculating the error bars should be explained (closed form formula,
call to a library function, bootstrap, etc.)
• The assumptions made should be given (e.g., Normally distributed errors).
•It should be clear whether the error bar is the standard deviation or the standard error
of the mean.
•It is OK to report 1-sigma error bars, but one should state it. The authors should
preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis
of Normality of errors is not verified.
•For asymmetric distributions, the authors should be careful not to show in tables or
figures symmetric error bars that would yield results that are out of range (e.g., negative
error rates).
•If error bars are reported in tables or plots, The authors should explain in the text how
they were calculated and reference the corresponding figures or tables in the text.
8.Experiments Compute Resources
Question: For each experiment, does the paper provide sufficient information on the com-
puter resources (type of compute workers, memory, time of execution) needed to reproduce
the experiments?
Answer: [Yes]
Justification: All experiments are performed with a single NVIDIA V100 GPU. It is
described in the experiment section.
Guidelines:
• The answer NA means that the paper does not include experiments.
•The paper should indicate the type of compute workers CPU or GPU, internal cluster,
or cloud provider, including relevant memory and storage.
30•The paper should provide the amount of compute required for each of the individual
experimental runs as well as estimate the total compute.
•The paper should disclose whether the full research project required more compute
than the experiments reported in the paper (e.g., preliminary or failed experiments that
didn’t make it into the paper).
9.Code Of Ethics
Question: Does the research conducted in the paper conform, in every respect, with the
NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines ?
Answer: [Yes]
Justification: N/A
Guidelines:
•The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
•If the authors answer No, they should explain the special circumstances that require a
deviation from the Code of Ethics.
•The authors should make sure to preserve anonymity (e.g., if there is a special consid-
eration due to laws or regulations in their jurisdiction).
10.Broader Impacts
Question: Does the paper discuss both potential positive societal impacts and negative
societal impacts of the work performed?
Answer: [Yes]
Justification: The paper focuses purely on methodology. How to use this method, and
to serve what purpose is completely dependent on people who use it (see the conclusion
section).
Guidelines:
• The answer NA means that there is no societal impact of the work performed.
•If the authors answer NA or No, they should explain why their work has no societal
impact or why the paper does not address societal impact.
•Examples of negative societal impacts include potential malicious or unintended uses
(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
(e.g., deployment of technologies that could make decisions that unfairly impact specific
groups), privacy considerations, and security considerations.
•The conference expects that many papers will be foundational research and not tied
to particular applications, let alone deployments. However, if there is a direct path to
any negative applications, the authors should point it out. For example, it is legitimate
to point out that an improvement in the quality of generative models could be used to
generate deepfakes for disinformation. On the other hand, it is not needed to point out
that a generic algorithm for optimizing neural networks could enable people to train
models that generate Deepfakes faster.
•The authors should consider possible harms that could arise when the technology is
being used as intended and functioning correctly, harms that could arise when the
technology is being used as intended but gives incorrect results, and harms following
from (intentional or unintentional) misuse of the technology.
•If there are negative societal impacts, the authors could also discuss possible mitigation
strategies (e.g., gated release of models, providing defenses in addition to attacks,
mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
feedback over time, improving the efficiency and accessibility of ML).
11.Safeguards
Question: Does the paper describe safeguards that have been put in place for responsible
release of data or models that have a high risk for misuse (e.g., pretrained language models,
image generators, or scraped datasets)?
Answer: [NA]
Justification: It is an unreleated question to this paper.
31Guidelines:
• The answer NA means that the paper poses no such risks.
•Released models that have a high risk for misuse or dual-use should be released with
necessary safeguards to allow for controlled use of the model, for example by requiring
that users adhere to usage guidelines or restrictions to access the model or implementing
safety filters.
•Datasets that have been scraped from the Internet could pose safety risks. The authors
should describe how they avoided releasing unsafe images.
•We recognize that providing effective safeguards is challenging, and many papers do
not require this, but we encourage authors to take this into account and make a best
faith effort.
12.Licenses for existing assets
Question: Are the creators or original owners of assets (e.g., code, data, models), used in
the paper, properly credited and are the license and terms of use explicitly mentioned and
properly respected?
Answer: [Yes]
Justification: The code is open-sourced on GitHub, with necessary licenses.
Guidelines:
• The answer NA means that the paper does not use existing assets.
• The authors should cite the original paper that produced the code package or dataset.
•The authors should state which version of the asset is used and, if possible, include a
URL.
• The name of the license (e.g., CC-BY 4.0) should be included for each asset.
•For scraped data from a particular source (e.g., website), the copyright and terms of
service of that source should be provided.
•If assets are released, the license, copyright information, and terms of use in the
package should be provided. For popular datasets, paperswithcode.com/datasets
has curated licenses for some datasets. Their licensing guide can help determine the
license of a dataset.
•For existing datasets that are re-packaged, both the original license and the license of
the derived asset (if it has changed) should be provided.
•If this information is not available online, the authors are encouraged to reach out to
the asset’s creators.
13.New Assets
Question: Are new assets introduced in the paper well documented and is the documentation
provided alongside the assets?
Answer: [Yes]
Justification: Code is the only asset. Since it is associated with the method (see the method
section), the answer is yes.
Guidelines:
• The answer NA means that the paper does not release new assets.
•Researchers should communicate the details of the dataset/code/model as part of their
submissions via structured templates. This includes details about training, license,
limitations, etc.
•The paper should discuss whether and how consent was obtained from people whose
asset is used.
•At submission time, remember to anonymize your assets (if applicable). You can either
create an anonymized URL or include an anonymized zip file.
14.Crowdsourcing and Research with Human Subjects
Question: For crowdsourcing experiments and research with human subjects, does the paper
include the full text of instructions given to participants and screenshots, if applicable, as
well as details about compensation (if any)?
32Answer: [NA]
Justification: It is unrelated.
Guidelines:
•The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
•Including this information in the supplemental material is fine, but if the main contribu-
tion of the paper involves human subjects, then as much detail as possible should be
included in the main paper.
•According to the NeurIPS Code of Ethics, workers involved in data collection, curation,
or other labor should be paid at least the minimum wage in the country of the data
collector.
15.Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
Subjects
Question: Does the paper describe potential risks incurred by study participants, whether
such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
approvals (or an equivalent approval/review based on the requirements of your country or
institution) were obtained?
Answer: [NA]
Justification: It is unrelated.
Guidelines:
•The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
•Depending on the country in which research is conducted, IRB approval (or equivalent)
may be required for any human subjects research. If you obtained IRB approval, you
should clearly state this in the paper.
•We recognize that the procedures for this may vary significantly between institutions
and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
guidelines for their institution.
•For initial submissions, do not include any information that would break anonymity (if
applicable), such as the institution conducting the review.
33