Carrot and Stick:
Eliciting Comparison Data and Beyond
Yiling Chen
Harvard University
yiling@seas.harvard.eduShi Feng
Harvard University
shifeng@fas.harvard.eduFang-Yi Yu
George Mason University
fangyiyu@gmu.edu
Abstract
Comparison data elicited from people are fundamental to many machine learning
tasks, including reinforcement learning from human feedback for large language
models and estimating ranking models. They are typically subjective and not
directly verifiable. How to truthfully elicit such comparison data from rational
individuals? We design peer prediction mechanisms for eliciting comparison data
using a bonus-penalty payment [ 11]. Our design leverages on the strong stochastic
transitivity for comparison data [ 60,13] to create symmetrically strongly truthful
mechanisms such that truth-telling 1) forms a strict Bayesian Nash equilibrium, and
2) yields the highest payment among all symmetric equilibria. Each individual only
needs to evaluate one pair of items and report her comparison in our mechanism.
We further extend the bonus-penalty payment concept to eliciting networked data,
designing a symmetrically strongly truthful mechanism when agents’ private signals
are sampled according to the Ising models. We provide the necessary and sufficient
conditions for our bonus-penalty payment to have truth-telling as a strict Bayesian
Nash equilibrium. Experiments on two real-world datasets further support our
theoretical discoveries.
1 Introduction
In the past two decades, researchers have been embracing the challenge of eliciting private information
from individuals when there is no ground truth available to evaluate the quality of elicited contribu-
tions, and have made amazing progress. Many mechanisms, collectively called peer prediction [42],
have been developed to incentivize individuals to strictly truthfully report their information at a
Bayesian Nash equilibrium (BNE), by artful design of payment functions that only depend on reports
from individuals. Moreover, in multi-task peer prediction mechanisms, the truthful BNE gives each
individual the highest expected payoff among all BNEs (i.e. it’s a strongly truthful BNE). [ 11,57,30]
However, all prior multi-task peer prediction mechanisms require tasks being ex-ante identical, and
hence individuals’ private information is independently and identically distributed (iid) for each task.
Multi-task peer prediction leverages this structure of information to succeed at truthful elicitation.
But what if such structure of information doesn’t hold for an information elicitation problem?
One notable application is to elicit pair-wise comparisons of multiple alternatives, such as preferences
for consumer products [ 53], translation [ 34], peer grading [ 55], and relevance of language model
outputs [ 9,10]. Such pair-wise comparison data are crucial for estimating a ranking of the alternatives
and for devising reward functions for reinforcement learning. Comparison tasks for different pairs
are clearly not ex-ante identical — answers to the tasks demonstrate a certain degree of transitivity
(e.g. if𝑎is preferred to 𝑎′and𝑎′is preferred to 𝑎′′, then it’s more likely that 𝑎is preferred to 𝑎′′),
rendering existing peer prediction mechanisms not applicable.
38th Conference on Neural Information Processing Systems (NeurIPS 2024).In this paper, we design a peer prediction mechanism for eliciting comparison data. We model
individuals’ private information of pair-wise comparisons as Bayesian strongly stochastically tran-
sitive (Bayesian SST), which takes many widely used models (e.g. Thurstone [ 58], Bradley-Terry-
Luce [ 4,38], and Mallows [ 39]) as special cases. Our mechanism uses a simple bonus-penalty
payment [ 11] (hence carrot and stick) that takes three reports as inputs and admits a strongly truthful
symmetric BNE. The key insight that we develop is a condition of information structure that we call
uniform dominance . When uniform dominance is satisfied, the bonus-penalty payment is the only
type of payment that induces a strictly truthful BNE. Information of individuals, 𝑖,𝑗, and𝑘, satisfies
uniform dominance if, conditioned on any realization of agent 𝑖’s information, the probability for
𝑗’s information to agree with 𝑖’s is higher than the probability for 𝑘’s information to agree with 𝑖’s.
Bayesian SST allows us to group three pairwise comparisons, (𝑎,𝑎′),(𝑎′′,𝑎′)and(𝑎′′,𝑎), together
such that private information about these pairs satisfies uniform dominance. After identifying uniform
dominance as a central structure for incentivizing truthful elicitation, we further generalize the
bonus-penalty payment to truthfully elicit private information over social networks that demonstrate
homophily (i.e. friends tend to have similar opinions than non-friends) [ 40], and our mechanism can
be integrated with common survey techniques such as snowball sampling [24].
Our contributions. Our work is a leap forward for designing mechanisms for complex information
elicitation settings where ground truth verification is not available.
•We are the first to design mechanisms to truthfully elicit pairwise comparison data under Bayesian
SST and networked data under Ising models. In our mechanisms, truthful reporting forms a BNE
and yields a strictly higher payoff than any symmetric non-permutation equilibrium.
•We identify a key structure of information, uniform dominance, as a lever such that the simple
bonus-penalty payment is the unique payment inducing a strictly truthful BNE. This identification
may offer a path for developing truthful elicitation mechanisms for other settings in the future.
•We use Griffiths’ inequality and Weitz’s self-avoiding walk [ 65] to prove the uniform dominance
property in the Ising model. The resulting correlation bounds may be of independent interest.
•We test our mechanisms on real-world data (sushi preference dataset [ 26,27] and Last.fm
dataset [ 8]). Even though these datasets do not perfectly satisfy our theoretical assumptions, our
mechanisms still provide a stronger incentive for truthful reporting compared to misreporting.
Related work. Information elicitation has two settings according to whether verification is possible.
Our paper focuses on elicitation without verification.
For information elicitation without verification, Miller et al. [41] introduce the first mechanism
for single task signal elicitation that has truth-telling as a strict Bayesian Nash equilibrium but
requires full knowledge of the common prior. Bayesian truth serum (BTS) [ 47] is the first strongly
truthful peer prediction mechanism, but requires complicated reports from agents (their private signal
and predictions on other’s reports). A series of works [ 48,49,67,66,68,3,51,31] relax certain
assumptions of BTS but still require complicated reports from agents. Dasgupta and Ghosh [11]
introduces the multi-task setting where agents are assigned batch iid tasks and only report their
signals. Several works extend this to multiple-choice questions [29, 33, 56, 11], predictions [37], or
even continuous value [ 50], and investigate the limitation and robustness [ 52,6,70,17,70]. Another
related line of work is co-training and federated learning, which wants to elicit models [ 32,36], or
samples [ 64] when multiple iid data or feature of data are available. For more related works, see
Faltings [16].
One popular line of work considers information elicitation when verification is possible. Spot-
checking requires direct verification of the agent’s report [ 21]. Recent work on comparison data
elicitation [ 19] utilizes spot-checking concepts and focuses on incentivizing effort. Another form
of verification involves using additional samples to evaluate how the agent’s reports improve model
performance [ 1,28]. Additionally, the verification may have a general relation to the agent’s signal,
e.g., proper scoring rules [23, 46, 35, 20].
2 Problem Formulation
We discuss our model for eliciting comparison data in this section and defer the extensions to
Section 5. Given a collection of items Aand a set of strategic agents N. Agents privately observe
2noisy comparisons between pairs of items. Our goal is to design mechanisms to truthfully elicit agents’
private information. We will first introduce the information structure of agents’ private information of
pairwise comparisons in Section 2.1 and then define the information elicitation problem in Section 2.2.
2.1 Bayesian SST Models for Comparison Data
We introduce Bayesian Strong Stochastic Transitivity (Bayesian SST) models to capture the structure
of agents’ private information for comparison data.
Given the set of items A, the underlying unknown state about the items is 𝜃∈Θ.𝜃can be the
vector of quality scores for the items (Example 2.2) or a reference ranking (Example 2.4). 𝜃is drawn
according to a common prior 𝑃Θ:𝜃∼𝑃Θ. Any realized 𝜃has an associated stochastic comparison
function𝑇𝜃:A2→{− 1,1}. For comparisons of two items 𝑎and𝑎′,𝑇𝜃(𝑎,𝑎′)and𝑇𝜃(𝑎′,𝑎)
stochastically take value 1or−1, with Pr[𝑇𝜃(𝑎,𝑎′)=1]=1−Pr[𝑇𝜃(𝑎′,𝑎)=−1]. For any𝜃,𝑇𝜃is
strongly stochastically transitive as defined below.
Definition 2.1 ([60,13]).A stochastic comparison function, 𝑇:A2→ {− 1,1}, isstrongly
stochastically transitive (SST) if for all𝑎,𝑎′,𝑎′′∈ A with Pr[𝑇(𝑎,𝑎′)=1]>1/2and
Pr[𝑇(𝑎′,𝑎′′)=1]>1/2, we have
Pr[𝑇(𝑎,𝑎′′)=1]>max{Pr[𝑇(𝑎,𝑎′)=1],Pr[𝑇(𝑎′,𝑎′′)=1]}.
Intuitively, a comparison function is SST when for any three items 𝑎,𝑎′,𝑎′′, if𝑎is more favorable
than𝑎′and𝑎′is more favorable than 𝑎′′, then𝑎is even more favorable than 𝑎′′. The concept of SST
is a well-established property of comparisons in social science and psychology [18].
Each agent𝑖∈ N has the knowledge of (𝑇𝜃)𝜃∈Θand𝑃Θ. When asked to compare a pair of
items(𝑎,𝑎′), the agent observes an independent draw according to the stochastic comparison
function:𝑆𝑖=𝑇𝜃(𝑎,𝑎′), where realization 𝑠𝑖=1represent item 𝑎is preferred over item 𝑎′
by agent𝑖. We assume items are a priori similar but ex-post distinct so that for all 𝑎,𝑎′∈A ,
E[𝑇𝜃(𝑎,𝑎′)]=E[E[𝑇𝜃(𝑎,𝑎′)|𝜃]]=0andE[𝑇𝜃(𝑎,𝑎′)|𝜃]≠0for all𝜃.
Examples of Bayesian SST models. Bayesian SST models are a general family of models that take
many classical parametric ranking models, including Bradley-Terry Luce [ 4,38], Thurstone (Case
V) [58], and Mallows 𝜂-model [39], as special cases.
Example 2.2 (Bradley-Terry-Luce, Thurstone model, and more [ 59]).Let𝜃∈RA=Θwhere each
coordinate is independently and identically sampled from a fixed non-atomic distribution 𝜈onR, and
each item𝑎have a scalar quality 𝜃𝑎∈R. Let𝐹:R→[0,1]be any strictly increasing function such
that𝐹(𝑡)=1−𝐹(−𝑡)for all𝑡∈R. Conditional on a fixed 𝜃,
Pr[𝑇𝜃(𝑎,𝑎′)=1]=𝐹(𝜃𝑎−𝜃𝑎′)for all𝑎,𝑎′∈A.
This model recovers the Thurstone model [ 58] by setting𝐹(𝑡)=Φ(𝑡)whereΦis the Gaussian CDF,
and the Bradley-Terry-Luce model [ 4] by setting𝐹(𝑡)=𝑒𝑡
1+𝑒𝑡, the sigmoid function. Moreover, this
model also contains any additive random utility model [ 2] where𝑇(𝑎,𝑎′)=1if𝜃𝑎+𝑍 >𝜃𝑎′+𝑍′
with iid noise 𝑍and𝑍′, because we can set 𝐹to be the CDF of the difference of two iid noise.
Proposition 2.3. For any strictly increasing 𝐹and non-atomic 𝜈onR, the parametric model in
Example 2.2 is a Bayesian SST model.
Example 2.4 (Mallows𝜂-model [ 39]).LetΘbe the set of rankings on Aand𝜂>0be a dispersion
parameter. Given a reference ranking 𝜃∈Θ, theMallows𝜂-model generate a ranking 𝜙∈Θwith prob-
ability Pr(𝜙)∝exp(−𝜂𝑑(𝜃,𝜙))where𝑑(𝜃,𝜙)={(𝑎,𝑎′)∈A2:𝜃(𝑎)<𝜃(𝑎′)and𝜙(𝑎)>𝜙(𝑎′)}
is Kendall’s tau distance, and 𝜃(𝑎)is the rank of item 𝑎. Therefore, to generate comparisons, we first
sample a uniform 𝜃and
Pr[𝑇𝜃(𝑎,𝑎′)=1]=∑︁
𝜙:𝜙(𝑎)>𝜙(𝑎′)Pr(𝜙),for all𝑎,𝑎′∈A.
Proposition 2.5. For any𝜂 > 0, Mallows𝜂-model in Example 2.4 with uniform distribution on
reference ranking is an Bayesian SST model.
The proofs for propositions 2.3 and 2.5 are closely related to strong stochastic transitivity [ 54,7], but
are provided in the appendix for completeness.
32.2 Peer Prediction Mechanism Design
To truthfully elicit comparison data from agents, a peer prediction mechanism creates a game between
the agents outlined below: First, we choose an assignmentE={𝑒𝑖=(𝑎𝑢𝑖,𝑎𝑣𝑖):𝑖∈N} where
agent𝑖∈N gets a pair of items 𝑒𝑖=(𝑎𝑢𝑖,𝑎𝑣𝑖)∈A2to compare. Then each agent 𝑖∈N privately
observes the realization of the comparison (signal) 𝑠𝑖∈{−1,1}, which is an independent realization
of𝑇𝜃(𝑎𝑢𝑖,𝑎𝑣𝑖), and reports ˆ𝑠𝑖∈{−1,1}potentially different from her signal. We use 𝑆𝑖=𝑆(𝑎𝑢𝑖,𝑎𝑣𝑖)
to denote the random variable of agent 𝑖’s signal, where the randomness of 𝑆(·,·)comes from both 𝜃
and𝑇𝜃. Let Srepresent the random vector of all agents’ signals, s=(𝑠𝑖)𝑖∈Nbe all agents’ realized
private signals and ˆs=(ˆ𝑠𝑖)𝑖∈Nbe all agents’ reports. Finally, a peer prediction mechanism (𝑀𝑖)𝑖∈N
takes all agents’ reports ˆsand pays agent 𝑖with𝑀𝑖(ˆs)∈R.
Each agent𝑖’s strategy is a random function from her signal to a report 𝜎𝑖:𝑠𝑖↦→ˆ𝑠𝑖, and the
randomness of their strategies is independent of each other’s and all signals. With slight abuse of
notation, we write 𝜎𝑖(𝑠𝑖,ˆ𝑠𝑖)=Pr[ˆ𝑆𝑖=ˆ𝑠𝑖|𝑆𝑖=𝑠𝑖]as the conditional probability of reporting ˆ𝑠𝑖
given private signal 𝑠𝑖. A strategy profile 𝝈is a collection of all agent’s strategies. All agents are
rational and risk-neutral, so they want to maximize their expected payments. Thus, given prior 𝑃Θ,
randomness of 𝑇𝜃and a strategy profile 𝝈, agent𝑖wants to maximize her ex-ante payment denoted
asE𝝈,𝜃,𝑇𝜃[𝑀𝑖(ˆS)]where ˆSis the random vector of all agents’ report that depends on the signals S
and strategy profile 𝝈.
We introduce three families of strategies, truth-telling, permutation, and uninformed strategy profiles,
which are central to understanding effective peer prediction mechanisms.
•A strategy𝜎𝑖istruthful (or truth-telling) if it is a deterministic identity map, 𝜎𝑖(𝑠𝑖)=𝑠𝑖. A
strategy profile is truthful if all agents’ strategies are truthful.
•Apermutation strategy profile is where agents simultaneously relabel their signals and then report
the relabeled ones. A permutation strategy is indistinguishable from truth-telling unless the peer
prediction mechanism has additional knowledge about the prior signal distribution.[33]
•Finally, a strategy is uninformed if it has the same report distribution across all signals, and it is
informed otherwise. Common examples include consistently reporting all signals as a constant
value, such as 1or−1, or using a random report regardless of the signal. Uninformed strategies
are undesirable as the reports bear no relationship to the private signals.
A strategy profile is symmetric if all agents use the same strategy. For example, both truth-telling and
permutation strategy profiles are symmetric.
We now introduce goals for a peer prediction mechanism that favors truth-telling more than other
strategies. First, we want the truth-telling (strategy profile) to be a strict Bayesian Nash equilibrium
(BNE) so that any agent’s payment would strictly decrease if she unilaterally changes to any non-
truthful strategy. Moreover, there may be multiple equilibria, and a desirable mechanism should
ensure that truth-telling is better than all other equilibria. In this paper, we aim for symmetrically
strongly truthful mechanisms defined below.
Definition 2.6. A peer prediction mechanism is symmetrically strongly truthful if truth-telling is a
BNE, and each agent’s expected payment in truth-telling is no less than the payment in any other
symmetric equilibrium with equality for the equilibrium with a permutation strategy profile.1
3 Bonus-penalty Payment Mechanism for Comparison Data
We now propose a bonus-penalty payment mechanism for eliciting comparison data. The mechanism
makes use of a bonus-penalty payment function, which can be seen as an agreement payment
and introduced by Dasgupta and Ghosh [11] in a different context (see discussion in appendix A).
Formally, for any ˆ𝑠𝑖,ˆ𝑠𝑗,ˆ𝑠𝑘∈{−1,1}, the bonus-penalty payment function is
𝑈𝐵𝑃𝑃(ˆ𝑠𝑖,ˆ𝑠𝑗,ˆ𝑠𝑘)=ˆ𝑠𝑖ˆ𝑠𝑗−ˆ𝑠𝑖ˆ𝑠𝑘=2 1[ˆ𝑠𝑖=ˆ𝑠𝑗]−1[ˆ𝑠𝑖=ˆ𝑠𝑘], (1)
which rewards when the first input agrees with the second but punishes when it agrees with the third.
1Kong and Schoenebeck [30] shows that it is impossible to pay the truth-telling strategy profile strictly better
than other permutation strategy profiles without additional knowledge of the prior signal distribution.
4Mechanism 1 uses the bonus-penalty payment eq. (1) for each agent 𝑖by carefully choosing agent 𝑗
and𝑘such that agent 𝑗’s signal is more likely to agree with agent 𝑖’s than agent 𝑘’s signal is. The
crux of finding such pair of agents is to show that if agent 𝑖prefers item 𝑎over𝑎′, she would expect
that others will prefer any third item 𝑎′′over𝑎′, and prefer 𝑎over𝑎′′. Thus, if agent 𝑗has pair
(𝑎′′,𝑎′)and agent𝑘has pair(𝑎′′,𝑎), then agent 𝑗’s signal is more likely to take the same value
as𝑖’s than agent 𝑘’s signal is. This is the main idea behind the proof of Theorem 3.1, where we
establish the symmetrically strongly truthfulness of Mechanism 1. To ensure the existence of such
pairs are assigned, we require the assignment Eto be admissible where for all(𝑎,𝑎′)∈E , there
exists𝑎′′∈A so that(𝑎′′,𝑎′)and(𝑎′′,𝑎)∈E .
Mechanism 1: BPP mechanism for comparison data
Input: LetAbe a collection of items, Ebe an admissible assignment, and ˆsbe agents’ reports.
foragent𝑖∈N with pair𝑒𝑖=(𝑎𝑢𝑖,𝑎𝑣𝑖)=(𝑎,𝑎′)do
Find𝑎′′∈A and two agents 𝑗and𝑘so that𝑒𝑗=(𝑎′′,𝑎′)and𝑒𝑘=(𝑎′′,𝑎), and pay agent 𝑖
𝑀𝑖(ˆs)=𝑈𝐵𝑃𝑃(ˆ𝑠𝑖,ˆ𝑠𝑗,ˆ𝑠𝑘)=ˆ𝑠𝑖ˆ𝑠𝑗−ˆ𝑠𝑖ˆ𝑠𝑘. (2)
Theorem 3.1. Given a collection of items Aand a set of agents Nwith|A|,|N|≥ 3, for any
admissible assignment matrix Eand Bayesian SST model with (𝑇𝜃)𝜃∈Θand𝑃Θ, the BPP mechanism
for comparison (Mechanism 1) is symmetrically strongly truthful.
We defer the proof of theorem 3.1 to section 4. The admissible condition imposes little overhead on
downstream learning problems, including rank recovery [ 25] and identification of the top 𝑘items [ 15].
Specifically, the size of assignment Eis the number of comparisons and corresponds to the sample
complexity for these learning problems. If a learning algorithm requires a set of pairs to compare
E𝑀𝐿, we can construct an admissible superset Ethat introduces a constant factor overhead and can
recoverE𝑀𝐿⊆E.2
We remark that the bonus-penalty payment function eq. (2) can be seen as a boolean function for
transitivity [45]; see remark 3.2 for a formal statement. Hence, theorem 3.1 implies that agents’
manipulations can only decrease the probability of transitivity among their reports.
Remark 3.2. Note that a deterministic comparison function 𝑡:A×A→{− 1,1}satisfies transitivity
on three items 𝑎,𝑎′,𝑎′′∈ A if and only if 𝑡(𝑎,𝑎′),𝑡(𝑎′,𝑎′′),𝑡(𝑎′′,𝑎)are not all equal, that is
𝑁𝐴𝐸(𝑡(𝑎,𝑎′),𝑡(𝑎′,𝑎′′),𝑡(𝑎′′,𝑎))=1where
𝑁𝐴𝐸(𝑤1,𝑤2,𝑤3)=3
4−1
4𝑤1𝑤2−1
4𝑤1𝑤3−1
4𝑤2𝑤3.
The agent’s random noisy comparisons may or may not satisfy transitivity. The probability of
transitivity is the probability that they do.
We can show that the bonus-penalty payment in eq. (2) is equivalent to the above transitivity test
when agents are truth-telling. Formally,
𝑁𝐴𝐸(𝑆(𝑎,𝑎′),𝑆(𝑎′,𝑎′′),𝑆(𝑎′′,𝑎))
=3
4−1
4(𝑆(𝑎,𝑎′)𝑆(𝑎′,𝑎′′)+𝑆(𝑎,𝑎′)𝑆(𝑎′′,𝑎)+𝑆(𝑎′,𝑎′′)𝑆(𝑎′′,𝑎))
=1
4(𝑆(𝑎,𝑎′)𝑆(𝑎′′,𝑎′)−𝑆(𝑎,𝑎′)𝑆(𝑎′′,𝑎))+3
4+1
4𝑆(𝑎′′,𝑎′)𝑆(𝑎′′,𝑎)(𝑆(𝑎′,𝑎′′)=−𝑆(𝑎′′,𝑎′))
=1
4 𝑠𝑖𝑠𝑗−𝑠𝑖𝑠𝑘+3
4+1
4𝑠𝑗𝑠𝑘=1
4𝑀𝑖(s)+3
4+1
4𝑠𝑗𝑠𝑘 (truth-telling)
Therefore, arg maxˆ𝑠𝑖E[𝑁𝐴𝐸(ˆ𝑠𝑖,−𝑆𝑗,𝑆𝑘)|𝑆𝑖=𝑠𝑖]=arg maxˆ𝑠𝑖E1
4𝑀𝑖(ˆ𝑠𝑖,𝑆𝑗,𝑆𝑘)+3
4+1
4𝑆𝑗𝑆𝑘|𝑆𝑖=𝑠𝑖
=
arg maxˆ𝑠𝑖E[𝑀𝑖(ˆ𝑠𝑖,𝑆𝑗,𝑆𝑘)|𝑆𝑖=𝑠𝑖].
2Specifically, given any assignment E0, we can construct a superset Eso that for any(𝑎,𝑎′)∈E0find an
arbitrary𝑎′′≠𝑎,𝑎′and add(𝑎,𝑎′),(𝑎′,𝑎),(𝑎,𝑎′′),(𝑎′′,𝑎),(𝑎′,𝑎′′),(𝑎′′,𝑎′)intoE. Thus,Eis admissible
and at most six times larger than E0.
54 Proof of Theorem 3.1: from Bayesian SST Model to Uniform Dominance
To prove theorem 3.1, we formalize the idea that agent 𝑗’s signal is more likely to agree with agent 𝑖’s
than agent𝑘’s is as what we call uniform dominance in definition 4.1. We’ll show that any Bayesian
SST model satisfies this property. Then, we’ll prove that BPP mechanism is symmetrically strongly
truthful when agents’ private signals satisfy uniform dominance.
Definition 4.1. Given a random vector (𝑆𝑖,𝑆𝑗,𝑆𝑘)∈{− 1,1}3with joint distribution 𝑃,𝑆𝑗uniformly
dominates𝑆𝑘for𝑆𝑖ifPr[𝑆𝑗=1|𝑆𝑖=1]>Pr[𝑆𝑘=1|𝑆𝑖=1]andPr[𝑆𝑗=−1|𝑆𝑖=−1]>
Pr[𝑆𝑘=−1|𝑆𝑖=−1]. We call such an ordered tuple ⟨𝑆𝑖,𝑆𝑗,𝑆𝑘⟩a uniformly dominant tuple.3
Lemma 4.2 shows how to identify uniformly dominant tuples under Bayesian SST models.
Lemma 4.2. Under any Bayesian SST model, for any agent 𝑖and items𝑎,𝑎′and𝑎′′, agent𝑗’s signal
𝑆𝑗=𝑆(𝑎′′,𝑎′)uniformly dominates agent 𝑘’s signal𝑆𝑘=𝑆(𝑎′′,𝑎)for signal𝑆𝑖=𝑆(𝑎,𝑎′).
In other words, under any Bayesian SST model, the distribution of 𝑆(𝑎,𝑎′),𝑆(𝑎′′,𝑎′),𝑆(𝑎′′,𝑎)
satisfies uniform dominance for any 𝑎,𝑎′,𝑎′′. In the rest of this section, we can view (𝑆𝑖,𝑆𝑗,𝑆𝑘)as
an abstract random vector with some joint distribution 𝑃.
We now establish some implications of uniform dominance on the bonus-penalty payment. Lemma
4.3 shows that truth-telling is the best response if other signals are reported truthfully. Lemma 4.4
states that the expected payment is zero if everyone uses uninformed strategies (random functions
independent of input). Lemma 4.5 characterizes the best response under symmetric strategy profiles
(the same random function on each coordinate).
Lemma 4.3 (Truthfulness) .Given a uniformly dominant tuple ⟨𝑆𝑖,𝑆𝑗,𝑆𝑘⟩with distribution 𝑃, for all
𝑠𝑖∈{− 1,1},𝑠𝑖=arg maxˆ𝑠𝑖∈{−1,1}E𝑃
𝑈𝐵𝑃𝑃(ˆ𝑠𝑖,𝑆𝑗,𝑆𝑘)|𝑆𝑖=𝑠𝑖andE𝑃
𝑈𝐵𝑃𝑃(𝑆𝑖,𝑆𝑗,𝑆𝑘)
>
0.
Lemma 4.4. Given a uniformly dominant tuple ⟨𝑆𝑖,𝑆𝑗,𝑆𝑘⟩, with joint distribution 𝑃if agent𝑗and
𝑘both use an uninformed strategy 𝜎so that ˆ𝑆𝑗=𝜎(𝑆𝑗)andˆ𝑆𝑘=𝜎(𝑆𝑘), for all𝑠𝑖andˆ𝑠𝑖in{−1,1},
E𝜎,𝑃
𝑈𝐵𝑃𝑃(ˆ𝑠𝑖,ˆ𝑆𝑗,ˆ𝑆𝑘)|𝑆𝑖=𝑠𝑖
=0.
Lemma 4.5. Given a uniformly dominant tuple ⟨𝑆𝑖,𝑆𝑗,𝑆𝑘⟩with distribution 𝑃, for any strategy 𝜎and
𝑠𝑖∈{− 1,1}when agent 𝑗and𝑘both use𝜎,arg maxˆ𝑠𝑖∈{−1,1}E𝜎,𝑃
𝑈𝐵𝑃𝑃(ˆ𝑠𝑖,ˆ𝑆𝑗,ˆ𝑆𝑘)|𝑆𝑖=𝑠𝑖
=
arg maxˆ𝑠𝑖∈{−1,1}{𝜎(𝑠𝑖,ˆ𝑠𝑖)−𝜎(−𝑠𝑖,ˆ𝑠𝑖)}.
We’d like to highlight that lemmas 4.3 to 4.5 as well as the proof of theorem 3.1 below hold for any
uniformly dominant tuple ⟨𝑆𝑖,𝑆𝑗,𝑆𝑘⟩, not necessarily derived from the Bayesian SST model. This
offers a path to generalize our mechanism for comparison data to other settings.
Proof of theorem 3.1. By lemma 4.2, for any agent 𝑖, the associated agent 𝑗’s signal𝑆𝑗=𝑆(𝑎′′,𝑎′)
uniformly dominates the associated 𝑘’s signal𝑆𝑘=𝑆(𝑎′′,𝑎)for signal𝑆𝑖=𝑆(𝑎,𝑎′). By lemma 4.3,
if agent𝑗and𝑘are truthful, agent 𝑖’s best response is truthful reporting, so truth-telling is a BNE.
Now we show that all other symmetric equilibria are permutation or uninformed equilibria. For any
symmetric equilibrium 𝝈=(𝜎𝜄)𝜄∈Nso that everyone uses the same strategy 𝜎𝜄=𝜎for all𝜄∈N. If
𝜎is not deterministic so that 𝜎(𝑠,𝑠),𝜎(𝑠,−𝑠)>0for some𝑠∈{−1,1}, agent𝑖must be indifferent
between reporting 𝑠and−𝑠when getting 𝑆𝑖=𝑠.𝜎(𝑠,𝑠)−𝜎(−𝑠,𝑠)=𝜎(𝑠,−𝑠)−𝜎(−𝑠,−𝑠)by
lemma 4.5. This means 𝜎(𝑠,𝑠)=𝜎(−𝑠,𝑠)and𝜎(𝑠,−𝑠)=𝜎(−𝑠,−𝑠), and𝜎is an uninformed
strategy. If the strategy is deterministic, there are two cases. If 𝜎(𝑠)=𝜎(−𝑠), the strategy is also
uninformed. If 𝜎(𝑠)≠𝜎(−𝑠),𝜎is either truth-telling 𝑠↦→𝑠or flipping𝑠↦→−𝑠for all𝑠.
Finally, by lemma 4.4, any uninformed equilibrium’s expectation is zero. Additionally, because
eq. (1) is invariant when all inputs are flipped, the truth-telling and flipping/permutation equilibria
has the same expected payment which is positive by lemma 4.3. □
3If we view𝑆𝑗and𝑆𝑘as two statistical tests for a binary event 𝑆𝑖, the two inequalities in definition 4.1 say
that𝑆𝑗has a better type II and type I error than 𝑆𝑘respectively.
65 Generalization of Bonus-penalty Payment Mechanisms
We now leverage the key idea of uniform dominance to design peer prediction mechanisms for
networked data in section 5.1. In section 5.2, we summarize our design approach as a general scheme
that first identifies uniform dominance structures and then engages the bonus-penalty payment. We
prove the uniqueness of bonus-penalty payment: it is the only payment function, up to some positive
affine transformation, that induces truth-telling as a strict BNE for all uniform dominant tuples.
5.1 Bonus-penalty Payment Mechanisms for Networked Data
Uniform dominance implies agent 𝑖’s signal is more likely to agree with agent 𝑗’s than with agent
𝑘’s. Social networks are another natural domain exhibiting this property, as homophily [ 40] suggests
that agents’ opinions or signals in a social network are more likely to agree with their friends than
with non-friends. Leveraging this insight, we use a bonus-penalty payment scheme to elicit binary
networked data.
Mechanism 2: BPP mechanism for networked data
Input: Let(𝑉,𝐸)be a graph of agents in 𝑉,ˆs∈{−1,1}𝑉from all agent’s reports.
foragent𝑖∈𝑉do
Find agents 𝑗(friend) and 𝑘(non-friend) so that (𝑖,𝑗)∈𝐸but(𝑖,𝑘)∉𝐸, and pay agent 𝑖
𝑀𝑖(ˆs)=𝑈𝐵𝑃𝑃(ˆ𝑠𝑖,ˆ𝑠𝑗,ˆ𝑠𝑘)=ˆ𝑠𝑖ˆ𝑠𝑗−ˆ𝑠𝑖ˆ𝑠𝑘. (3)
Below, we provide a theoretical guarantee for our mechanism under a popular graphical model
for social network data, Ising model [14,43], which captures the correlation between agents and
their friends. Formally, an Ising model consists of an undirected graph (𝑉,𝐸)and correlation
parameter𝛽𝑖,𝑗≥0for each edge(𝑖,𝑗)∈𝐸. Each agent is a node in the graph, N=𝑉, and has a
binary private signal ( 1or−1) jointly distributed as the following: For all s=(𝑠𝑖)𝑖∈𝑉∈{− 1,1}𝑉,
Pr𝜷[S=s]∝exp(𝐻(s))where the energy function is 𝐻(s)=Í
(𝑖,𝑗)∈𝐸𝛽𝑖,𝑗𝑠𝑖𝑠𝑗.
Theorem 5.1. If agents’ signals are sampled from an Ising model on undirected graph (𝑉,𝐸)with
correlation parameters 𝜷, Mechanism 2 is symmetrically strongly truthful, when2𝛽
𝑑>ln𝑒2(𝑑+1)𝛽+1
𝑒2𝛽+𝑒2𝑑𝛽
where𝛽=min(𝑖,𝑗)∈𝐸𝛽𝑖,𝑗,𝛽=max(𝑖,𝑗)∈𝐸𝛽𝑖,𝑗, and𝑑is the maximal degree of graph (𝑉,𝐸).
Mechanism 2 does not require knowledge about parameters of the Ising model, but only the connection
of the network(𝑉,𝐸). Social network platforms, which already possess this knowledge, can easily
integrate our mechanism when conducting surveys. Additionally, snowball sampling [ 24], which
relies on participants referring their friends, is also naturally compatible with our mechanism.
The complete proof of theorem 5.1 is quite technical and is deferred to the appendix, where we also
explain why the bound between 𝜷and𝑑is necessary. Below, we provide a sketch of the proof.
Proof sketch for theorem 5.1. As discussed in section 4, we only need to show that for any agent 𝑖,
for all agent 𝑗with(𝑖,𝑗)∈𝐸and𝑘with(𝑖,𝑘)∉𝐸,𝑗’s signal uniformly dominates 𝑘’s signal for
𝑖’s signal. Because the energy function 𝐻(s)above remains invariant when the signs are flipped,
Pr[𝑆𝑖=1]=Pr[𝑆𝑗=1]=Pr[𝑆𝑘=1]=1/2, it is sufficient to prove that
Pr[𝑆𝑖=1|𝑆𝑗=1]>Pr[𝑆𝑖=1|𝑆𝑘=1]. (4)
We then prove a lower bound for the left-hand side and an upper bound for the right-hand side
separately. For the left-hand side, we use the Griffiths’ inequality [ 44] to show that the minimum
value of Pr[𝑆𝑖=1|𝑆𝑗=1]happens when 𝑗is the only friend of 𝑖. For the right-hand side, we use
Weitz’s self-avoiding walk [ 65] and reduce any graph with maximum degree 𝑑into a𝑑-ary tree. □
5.2 General Design Scheme and Uniqueness
The design of BPP mechanisms for comparison data and networked data has suggested a general
design scheme for other elicitation settings. That is, if one can identify a uniformly dominant tuple for
7Mechanism 3: General design scheme using BPP
Input: Letˆsbe reports from agents in N.
foragent𝑖∈N do
Find two agents 𝑗and𝑘so that𝑗’s signal uniformly dominates 𝑘’s for𝑖’s, and pay agent 𝑖
𝑀𝑖(ˆs)=𝑈𝐵𝑃𝑃(ˆ𝑠𝑖,ˆ𝑠𝑗,ˆ𝑠𝑘)=ˆ𝑠𝑖ˆ𝑠𝑗−ˆ𝑠𝑖ˆ𝑠𝑘.
each agent , adopting the bonus-penalty payment gives a symmetrically strongly truthful mechanism.
We further show that the bonus-penalty payment is in some sense unique.
Theorem 5.2. If for each agent 𝑖the associated agent 𝑗’s signal uniformly dominates 𝑘’s signal for
𝑖’s signal, the above scheme is symmetrically strongly truthful.
When an agent 𝑖has multiple pairs of (𝑗1,𝑘1),...,(𝑗ℓ,𝑘ℓ)so that𝑗𝑙’s signal uniformly dominates
𝑘𝑙’s for𝑖’s for each𝑙=1,...,ℓ , we may pay agent 𝑖the average of bonus-penalty payment on all
pairs𝑀𝑖(ˆs)=1
ℓÍℓ
𝑙=1𝑈𝐵𝑃𝑃(ˆ𝑠𝑖,ˆ𝑠𝑗𝑙,ˆ𝑠𝑘𝑙). This average maintains our symmetrically strongly truthful
guarantee while potentially reducing the variance in payments.
Theorem 5.2 shows that bonus-penalty payment is a sufficient condition for designing good elicitation
mechanisms for information structures with uniform dominance. We now prove it is also a necessary
condition: any payment that induces truth-telling as a strict BNE under all uniformly dominant tuples
must be an affine transformation of the bonus-penalty payment.
Theorem 5.3 (Uniqueness) .A payment𝑈:{−1,1}3→Rsatisfies that, for all uniformly dominant
tuples⟨𝑆𝑖,𝑆𝑗,𝑆𝑘⟩,𝑠𝑖=arg maxˆ𝑠𝑖∈{−1,1}E
𝑈(ˆ𝑠𝑖,𝑆𝑗,𝑆𝑘)|𝑆𝑖=𝑠𝑖, if and only if there exist 𝜆 >0
and𝜇:{−1,1}2→Rso that
𝑈(𝑠𝑖,𝑠𝑗,𝑠𝑘)=𝜆𝑈𝐵𝑃𝑃(𝑠𝑖,𝑠𝑗,𝑠𝑘)+𝜇(𝑠𝑗,𝑠𝑘),for all𝑠𝑖,𝑠𝑗,𝑠𝑘∈{−1,1}
where choice of 𝜇does not affect the set of equilibria.
6 Experiments
We present experiments on real-world data to evaluate our models and mechanisms. We hope to cast
insights on two questions empirically. Does our mechanism provide better rewards when all agents
report truthfully than when all agents report randomly? Does our mechanism incentivize truth-telling
for each agent if all other agents are truthful? We evaluate Mechanism 1 and 2 by comparing three
settings, truth-telling, uninformed, and unilateral deviation, using empirical cumulative distribution
functions (ECDF) on agents’ payments. Each point on ECDF denotes the fraction of agents who get
paid less than a particular value.
For both comparison and networked datasets (figs. 1 and 2), we find our mechanisms provide better
payments to agents under truthful settings than the other two settings. The ECDF under truth-telling
lies below the other two ECDFs, which is known as first-order stochastic dominance. This implies
that the truth-telling strategy results in higher average, quantiles (e.g., first quartile, median, and third
quartile), and a greater expectation of any monotone function on the empirical distribution than the
other two settings. We provide additional
6.1 SUSHI Preference Dataset for Comparison Data
We consider preference data for a collection of 10sushi items (item set A) [ 26,27], and focus on a
group of 249agents. Each agent provides a complete ranking of all 10types of sushi in the dataset.
These agents are female, aged thirty to forty-nine, who took more than three hundred seconds to rank
the items and mostly lived in Kanto and Shizuoka until age fifteen. We restrict the set of agents to
avoid significant violations of transitivity across different agents and to better align with our model
assumptions. In the appendix, we will present the experimental results for other groups of users and
further test whether the dataset satisfies transitivity.
For the first question, we use Mechanism 1 to compute each agent’s payment under the truth-telling
or uninformed strategy profile. For each agent 𝑖, we 1) randomly sample three items 𝑎,𝑎′,𝑎′′and
8two agents𝑗,𝑘, 2) derive agent 𝑖’s comparison on the first two items (𝑎,𝑎′)from her ranking, (and
similarly for agent 𝑗’s comparison on(𝑎′,𝑎′′), and agent𝑘’s comparison on(𝑎,𝑎′′)), 3) compute
bonus-penalty payment on these three comparisons, 4) repeat the above procedure 100times and
pay agent𝑖with the average of those 100trials. For the uninformed strategy setting, we replace
every agent’s comparisons with uniform random bits and compute the payment. The left column of
fig. 1 presents the ECDF of payments for the agents in both settings. The figure shows that in the
uninformed random strategy setting only about 50% of the agents receive positive payments, while in
the original dataset (truthful strategy setting) over 75% of the users receive positive payments. The
right column of fig. 1 tests the second question if the agent has the incentive to deviate when every
other agent is truthful. The truth-telling curve is identical to the left column of fig. 1. For unilateral
deviation, each agent gets the above bonus-penalty payment when her comparisons are replaced by
uniform random bits. We plot the ECDFs of payments for both settings in the right column of fig. 1.
The figure shows that the ECDF of the unilateral deviation payments is above the ECDF of human
users’ payments, indicating that our mechanism pays more to the truth-telling agents.
Figure 1: SUSHI preference dataset
6.2 Last.fm Dataset for Networked Data
We test our BPP mechanism on the Last.fm dataset from Cantador et al. [8]. This dataset consists
of1892 agents on Last.fm, forming a social network with 12704 edges and an average degree of
6.71. It records agents’ top fifty favorite artists whom they have listened to the most. We note that, in
the dataset, listener fractions for all artists are much smaller than non-listener fractions. This bias
differs from our Ising model in section 5.1 where every agent has the same chance to get both signals.
Thus, the result can be seen as a stress test for our mechanism even when the data deviate from the
assumption of our theoretical results.
Figure 2 focuses on the most popular artist in the dataset, Lady Gaga, who has a listener fraction of
32.3%. The results for additional artists are presented in the supplementary material. The left column
of fig. 2 tests the first question. Each agent has a binary signal about whether or not she listens to a
particular artist (Lady Gaga in this section). For the truth-telling setting, everyone reports her signal
truthfully and gets payment by the bonus-penalty payment (formally defined in section 5.1). For the
uninformed setting, everyone gets the bonus-penalty payment when all reports are iid according to
the prior ( 0.322for Lady Gaga). When everyone is truthful, more than 76% of agents get positive
payments and have an average payment of 0.37for Lady Gaga, while when agents report randomly,
only half get positive payments, and have a near zero average payment. These results suggest that
agents got more incentive to choose the truth-telling equilibrium than the uninformed equilibrium.
The right column of fig. 2 tests the second question. The truth-telling curve is identical to the left
column of fig. 2. For the unilateral deviation setting, each agent gets the bonus-penalty payment
when she reports listener/non-listener uniformly at random. The unilateral deviation’s payment is
worse than the payments for truth-telling, decreasing from 0.37to near zero for Lady Gaga.
9Figure 2: Last.fm dataset for Lady Gaga
7 Conclusion and Discussion
We introduce a symmetrically strongly truthful peer prediction mechanism for eliciting comparison
data without verification and extend it to eliciting networked data under Ising models. Our mech-
anisms are evaluated using real-world data. A key insight from our work is the identification of a
structure we term “uniform dominance,” which suggests a path for designing mechanisms in more
complex elicitation settings. For example, in time-series data, adjacent points tend to be more related
than distant ones, and in contextual settings, feedback from similar contexts is typically more related
than from different contexts.
A central assumption in this study is that agents are a priori similar . Hence, noisy comparisons
of item pairs are independent of the assigned agent’s identity. This assumption is reasonable for
items with widely agreed-upon rankings, such as quality assessments of large language model (LLM)
outputs. However, it may break down in settings where preferences are highly polarized, such as
political opinions or social choice problems4. Despite this, our additional experiments in appendix F,
which relax the selection rule used in obtaining fig. 1, show that the mechanism remains robust even
when some dissimilarities among agents exist.
Agents in our model are assumed to focus solely on maximizing their payments, without accounting
for efforts or external incentives such as minimizing others’ rewards or intentionally distorting
rankings. While our mechanism may be extended to handle binary effort as suggested in previous
work [ 11,57], accommodating more than two effort levels would require additional assumptions
[69]. Moreover, one may hope to incorporate the designer’s utility, by factoring in downstream
learning problems along with elicitation payments. This would necessitate a significant overhaul of
the existing learning framework.
Our mechanisms achieve a symmetric, strongly truthful equilibrium. This does not rule out the
existence of non-symmetric equilibria with potentially higher utility. However, such equilibria would
require complex coordination among agents, making them less likely to arise naturally.
From a technical standpoint, our approach involves several assumptions that can be generalized
or relaxed. Our Bayesian SST model, which relies on strong stochastic transitivity, serves as a
non-parametric extension of several widely used parametric ranking models. In appendix C.2, we
present both positive and negative results regarding weaker notions of transitivity (e.g., [ 5]). While
we assume admissible assignments, this can be relaxed to random assignments with full support.
Additionally, limited liability can be ensured in our mechanism. For example, adding a constant of 1
to the payment function in eq. (2) ensures that the payment is either 2or0.
4For example, when ranking phone features (e.g., innovation, performance, brand reputation, price, ease
of use), consumers often fall into two groups: early adopters, who prioritize cutting-edge technology, and late
adopters, who favor stability, affordability, and ease of use. Their opposing preferences violate the a priori
similarity assumption. Imagine an early adopter whose payment in eq. (2) depends on two late adopters. Since
their preferences may differ significantly, the early adopter might have an incentive to misreport her preferences.
10Acknowledgments
This research was partially supported by the National Science Foundation under grant no. IIS-
2147187.
References
[1]Jacob D Abernethy and Rafael Frongillo. A collaborative mechanism for crowdsourcing
prediction problems. Advances in neural information processing systems , 24, 2011.
[2]Hossein Azari, David Parks, and Lirong Xia. Random utility theory for social choice. Advances
in Neural Information Processing Systems , 25, 2012.
[3]Aurélien Baillon. Bayesian markets to elicit private information. Proceedings of the National
Academy of Sciences , 114(30):7958–7962, 2017.
[4]Ralph Allan Bradley and Milton E Terry. Rank analysis of incomplete block designs: I. the
method of paired comparisons. Biometrika , 39(3/4):324–345, 1952.
[5]Mark Braverman and Elchanan Mossel. Noisy sorting without resampling. In Proceedings
of the Nineteenth Annual ACM-SIAM Symposium on Discrete Algorithms , SODA ’08, page
268–276, USA, 2008. Society for Industrial and Applied Mathematics.
[6]Noah Burrell and Grant Schoenebeck. Measurement integrity in peer prediction: A peer assess-
ment case study. In Proceedings of the 24th ACM Conference on Economics and Computation ,
pages 369–389, 2023.
[7]Róbert Busa-Fekete, Eyke Hüllermeier, and Balázs Szörényi. Preference-based rank elicitation
using statistical models: The case of mallows. In International conference on machine learning ,
pages 1071–1079. PMLR, 2014.
[8]Iván Cantador, Peter Brusilovsky, and Tsvi Kuflik. Second workshop on information hetero-
geneity and fusion in recommender systems. In Proceedings of the fifth ACM conference on
Recommender systems , pages 387–388, 2011.
[9]Mingyue Cheng, Hao Zhang, Jiqian Yang, Qi Liu, Li Li, Xin Huang, Liwei Song, Zhi Li,
Zhenya Huang, and Enhong Chen. Towards personalized evaluation of large language models
with an anonymous crowd-sourcing platform. In Companion Proceedings of the ACM on Web
Conference 2024 , pages 1035–1038, 2024.
[10] Wei-Lin Chiang, Lianmin Zheng, Ying Sheng, Anastasios Nikolas Angelopoulos, Tianle Li,
Dacheng Li, Hao Zhang, Banghua Zhu, Michael Jordan, Joseph E Gonzalez, et al. Chatbot arena:
An open platform for evaluating llms by human preference. arXiv preprint arXiv:2403.04132 ,
2024.
[11] Anirban Dasgupta and Arpita Ghosh. Crowdsourced judgement elicitation with endogenous
proficiency. In Proceedings of the 22nd international conference on World Wide Web , pages
319–330, 2013.
[12] Constantinos Daskalakis, Nishanth Dikkala, and Gautam Kamath. Concentration of multilinear
functions of the ising model with applications to network data. Advances in Neural Information
Processing Systems , 30, 2017.
[13] Donald Davidson and Jacob Marschak. Experimental tests of a stochastic decision theory.
Measurement: Definitions and theories , 17(2), 1959.
[14] Glenn Ellison. Learning, local interaction, and coordination. Econometrica: Journal of the
Econometric Society , pages 1047–1071, 1993.
[15] Brian Eriksson. Learning to top-k search using pairwise comparisons. In Artificial Intelligence
and Statistics , pages 265–273. PMLR, 2013.
[16] Boi Faltings. Game-theoretic mechanisms for eliciting accurate information. In IJCAI , 2022.
11[17] Shi Feng, Fang-Yi Yu, and Yiling Chen. Peer prediction for learning agents. Advances in Neural
Information Processing Systems , 35:17276–17286, 2022.
[18] Peter C Fishburn. Binary choice probabilities: on the varieties of stochastic transitivity. Journal
of Mathematical psychology , 10(4):327–352, 1973.
[19] Kiriaki Frangias, Andrew Lin, Ellen Vitercik, and Manolis Zampetakis. Algorithmic contract
design for crowdsourced ranking. arXiv preprint arXiv:2310.09974 , 2023.
[20] Rafael Frongillo and Ian A Kash. Vector-valued property elicitation. In Conference on Learning
Theory , pages 710–727. PMLR, 2015.
[21] Xi Alice Gao, James R Wright, and Kevin Leyton-Brown. Incentivizing evaluation with peer
prediction and limited access to ground truth. Artificial Intelligence , 275:618–638, 2019.
[22] Hans-Otto Georgii. Gibbs measures and phase transitions . Walter de Gruyter GmbH & Co.
KG, Berlin, 2011.
[23] Tilmann Gneiting and Adrian E Raftery. Strictly proper scoring rules, prediction, and estimation.
Journal of the American statistical Association , 102(477):359–378, 2007.
[24] Leo A Goodman. Snowball sampling. The annals of mathematical statistics , pages 148–170,
1961.
[25] David R Hunter. Mm algorithms for generalized bradley-terry models. The annals of statistics ,
32(1):384–406, 2004.
[26] Toshihiro Kamishima. Nantonac collaborative filtering: recommendation based on order
responses. In Proceedings of the ninth ACM SIGKDD international conference on Knowledge
discovery and data mining , pages 583–588, 2003.
[27] Toshihiro Kamishima and Shotaro Akaho. Efficient clustering for orders. In Sixth IEEE
International Conference on Data Mining-Workshops (ICDMW’06) , pages 274–278. IEEE,
2006.
[28] Sai Praneeth Karimireddy, Wenshuo Guo, and Michael I Jordan. Mechanisms that incentivize
data sharing in federated learning. arXiv preprint arXiv:2207.04557 , 2022.
[29] Yuqing Kong. Dominantly truthful multi-task peer prediction with a constant number of tasks.
InProceedings of the fourteenth annual acm-siam symposium on discrete algorithms , pages
2398–2411. SIAM, 2020.
[30] Yuqing Kong and Grant Schoenebeck. A framework for designing information elicitation
mechanisms that reward truth-telling. CoRR , abs/1605.01021, 2016. URL http://arxiv.
org/abs/1605.01021 .
[31] Yuqing Kong and Grant Schoenebeck. Equilibrium selection in information elicitation without
verification via information monotonicity. In 9th Innovations in Theoretical Computer Science
Conference (ITCS 2018) . Schloss-Dagstuhl-Leibniz Zentrum für Informatik, 2018.
[32] Yuqing Kong and Grant Schoenebeck. Water from two rocks: Maximizing the mutual infor-
mation. In Proceedings of the 2018 ACM Conference on Economics and Computation , pages
177–194, 2018.
[33] Yuqing Kong and Grant Schoenebeck. An information theoretic framework for designing
information elicitation mechanisms that reward truth-telling. ACM Transactions on Economics
and Computation (TEAC) , 7(1):1–33, 2019.
[34] Julia Kreutzer, Joshua Uyheng, and Stefan Riezler. Reliability and learnability of human bandit
feedback for sequence-to-sequence reinforcement learning. arXiv preprint arXiv:1805.10627 ,
2018.
[35] Nicolas S Lambert, David M Pennock, and Yoav Shoham. Eliciting properties of probability
distributions. In Proceedings of the 9th ACM Conference on Electronic Commerce , pages
129–138, 2008.
12[36] Yang Liu, Rixing Lou, and Jiaheng Wei. Auditing for federated learning: A model elicitation
approach. In Proceedings of the Fifth International Conference on Distributed Artificial
Intelligence , DAI ’23, New York, NY , USA, 2023. Association for Computing Machinery.
ISBN 9798400708480. doi: 10.1145/3627676.3627683. URL https://doi.org/10.1145/
3627676.3627683 .
[37] Yang Liu, Juntao Wang, and Yiling Chen. Surrogate scoring rules. ACM Transactions on
Economics and Computation , 10(3):1–36, 2023.
[38] R Duncan Luce. Individual choice behavior: A theoretical analysis . Courier Corporation, 2005.
[39] C. L. Mallows. Non-null ranking models. i. Biometrika , 44(1/2):114–130, 1957. ISSN
00063444. URL http://www.jstor.org/stable/2333244 .
[40] Miller McPherson, Lynn Smith-Lovin, and James M Cook. Birds of a feather: Homophily in
social networks. Annual review of sociology , 27(1):415–444, 2001.
[41] N. Miller, P. Resnick, and R. Zeckhauser. Eliciting informative feedback: The peer-prediction
method. Management Science , pages 1359–1373, 2005.
[42] Nolan Miller, Paul Resnick, and Richard Zeckhauser. Eliciting informative feedback: The
peer-prediction method. Management Science , 51(9):1359–1373, 2005.
[43] Andrea Montanari and Amin Saberi. The spread of innovations in social networks. Proceedings
of the National Academy of Sciences , 107(47):20196–20201, 2010.
[44] Marc Mézard and Andrea Montanari. Information, Physics, and Computation . Oxford Univer-
sity Press, 01 2009. ISBN 9780198570837. doi: 10.1093/acprof:oso/9780198570837.001.0001.
URL https://doi.org/10.1093/acprof:oso/9780198570837.001.0001 .
[45] Ryan O’Donnell. Analysis of boolean functions . Cambridge University Press, 2014.
[46] Kent Harold Osband. Providing Incentives for Better Cost Forecasting (Prediction, Uncertainty
Elicitation) . University of California, Berkeley, 1985.
[47] Drazen Prelec. A bayesian truth serum for subjective data. science , 306(5695):462–466, 2004.
[48] Goran Radanovic and Boi Faltings. A robust bayesian truth serum for non-binary signals. In
Proceedings of the AAAI Conference on Artificial Intelligence , volume 27, pages 833–839,
2013.
[49] Goran Radanovic and Boi Faltings. Incentives for truthful information elicitation of continuous
signals. In Proceedings of the Twenty-Eighth AAAI Conference on Artificial Intelligence , pages
770–776, 2014.
[50] Grant Schoenebeck and Fang-Yi Yu. Learning and strongly truthful multi-task peer prediction:
A variational approach. In 12th Innovations in Theoretical Computer Science Conference (ITCS
2021) . Schloss Dagstuhl-Leibniz-Zentrum für Informatik, 2021.
[51] Grant Schoenebeck and Fang-Yi Yu. Two strongly truthful mechanisms for three heterogeneous
agents answering one question. ACM Transactions on Economics and Computation , 10(4):1–26,
2023.
[52] Grant Schoenebeck, Fang-Yi Yu, and Yichi Zhang. Information elicitation from rowdy crowds.
InProceedings of the Web Conference 2021 , pages 3974–3986, 2021.
[53] Sören W Scholz, Martin Meissner, and Reinhold Decker. Measuring consumer preferences
for complex products: A compositional approach basedonpaired comparisons. Journal of
Marketing Research , 47(4):685–698, 2010.
[54] Nihar Shah, Sivaraman Balakrishnan, Aditya Guntuboyina, and Martin Wainwright. Stochas-
tically transitive models for pairwise comparisons: Statistical and computational issues. In
International Conference on Machine Learning , pages 11–20. PMLR, 2016.
13[55] Nihar B Shah, Joseph K Bradley, Abhay Parekh, Martin Wainwright, and Kannan Ramchandran.
A case for ordinal peer-evaluation in moocs. In NIPS workshop on data driven education ,
volume 15, page 67, 2013.
[56] Victor Shnayder, Arpit Agarwal, Rafael Frongillo, and David C. Parkes. Informed truthfulness
in multi-task peer prediction. In Proceedings of the 2016 ACM Conference on Economics and
Computation , EC ’16, pages 179–196, New York, NY , USA, 2016. ACM. ISBN 978-1-4503-
3936-0.
[57] Victor Shnayder, Arpit Agarwal, Rafael M. Frongillo, and David C. Parkes. Informed
truthfulness in multi-task peer prediction. CoRR , abs/1603.03151, 2016. URL http:
//arxiv.org/abs/1603.03151 .
[58] Louis L Thurstone. A law of comparative judgment. In Scaling , pages 81–92. Routledge, 2017.
[59] Amos Tversky and J Edward Russo. Substitutability and similarity in binary choices. Journal
of Mathematical psychology , 6(1):1–12, 1969.
[60] Stephan Vail. A stochastic model for utilities. Unpublished manuscript , 1953.
[61] Luis V on Ahn and Laura Dabbish. Labeling images with a computer game. In Proceedings of
the SIGCHI conference on Human factors in computing systems , pages 319–326, 2004.
[62] Luis von Ahn and Laura Dabbish. Designing games with a purpose. Commun. ACM , 51(8):
58–67, aug 2008. ISSN 0001-0782. doi: 10.1145/1378704.1378719. URL https://doi.
org/10.1145/1378704.1378719 .
[63] Bo Waggoner and Yiling Chen. Output agreement mechanisms and common knowledge. In
Proceedings of the AAAI Conference on Human Computation and Crowdsourcing , volume 2,
pages 220–226, 2014.
[64] Jiaheng Wei, Zuyue Fu, Yang Liu, Xingyu Li, Zhuoran Yang, and Zhaoran Wang. Sample
elicitation. In International Conference on Artificial Intelligence and Statistics , pages 2692–
2700. PMLR, 2021.
[65] Dror Weitz. Counting independent sets up to the tree threshold. In Proceedings of the thirty-
eighth annual ACM symposium on Theory of computing , pages 140–149, 2006.
[66] Jens Witkowski and David C. Parkes. A Robust Bayesian Truth Serum for Small Populations.
InProceedings of the 26th AAAI Conference on Artificial Intelligence (AAAI 2012) , 2011.
[67] Jens Witkowski and David C. Parkes. Peer prediction without a common prior. In Proceedings
of the 13th ACM Conference on Electronic Commerce, EC 2012, Valencia, Spain, June 4-8,
2012 , pages 964–981. ACM, 2012.
[68] Peter Zhang and Yiling Chen. Elicitability and knowledge-free elicitation with peer prediction.
InProceedings of the 2014 international conference on Autonomous agents and multi-agent
systems , pages 245–252. International Foundation for Autonomous Agents and Multiagent
Systems, 2014.
[69] Yichi Zhang and Grant Schoenebeck. High-effort crowds: Limited liability via tournaments.
InProceedings of the ACM Web Conference 2023 , WWW ’23, page 3467–3477, New York,
NY , USA, 2023. Association for Computing Machinery. ISBN 9781450394161. doi: 10.1145/
3543507.3583334. URL https://doi.org/10.1145/3543507.3583334 .
[70] Shuran Zheng, Fang-Yi Yu, and Yiling Chen. The limits of multi-task peer prediction. In
Proceedings of the 22nd ACM Conference on Economics and Computation , pages 907–926,
2021.
14A Further discussion on BPP payment
In this section, we discuss the connection of bonus-penalty payment and existing peer prediction
mechanisms. First, if we substitute the third input with a uniformly random bit, denoted as ˆ𝑠𝑘=𝑍∼𝑢
{−1,1}, the bonus-penalty payment simplifies to the agreement mechanism [62,61,63], one of the
most basic peer prediction mechanisms,
E
𝑈𝐵𝑃𝑃(ˆ𝑠𝑖,ˆ𝑠𝑗,𝑍)
=ˆ𝑠𝑖ˆ𝑠𝑗=21[ˆ𝑠𝑖=ˆ𝑠𝑗]−1.
However, the agreement mechanism is not symmetrically strongly truthful, as all agents always
reporting 1and−1can result in higher payments than truth-telling.
The bonus-penalty payment eq. (1) is originally proposed by [ 11,57] for the multi-task setting.
Our BPP mechanism in Mechanism 3 can be seen as a generalization of multi-task setting. In the
multi-task setting, agents works on multiple tasks and for each task the private signals are jointly
identically and independently (iid) sampled from a fixed distribution and the each agent’s strategy
also are iid. Take two agents (Isabel and Julia) and two tasks as an example: Isabel has a private
signal(𝑠1
𝑖,𝑠2
𝑖)and reports(ˆ𝑠1
𝑖,ˆ𝑠2
𝑖)and Julia has(𝑠1
𝑗,𝑠2
𝑗)and reports(ˆ𝑠1
𝑗,ˆ𝑠2
𝑗)where(𝑠𝑙
𝑖,𝑠𝑙
𝑗)are iid
from random vector (𝑆𝑖,𝑆𝑗). Isabel and Julia decide their reports on each task using random function
𝜎𝑖,𝜎𝑗:{−1,1}↦→{− 1,1}respectively. Dasgupta and Ghosh [11] use the following payments for
Isabel
1[ˆ𝑠1
𝑖=ˆ𝑠1
𝑗]−1[ˆ𝑠1
𝑖=ˆ𝑠2
𝑗]=1
2𝑈𝐵𝑃𝑃
ˆ𝑠1
𝑖,ˆ𝑠1
𝑗,ˆ𝑠2
𝑗
.
The payment is a special case of Mechanism 3 by taking the second input as ˆ𝑠1
𝑗and the third input as
ˆ𝑠2
𝑗. Additionally, 𝑆1
𝑗uniform dominates 𝑆2
𝑗for𝑆1
𝑖if and only if
Pr[𝑆𝑗=1|𝑆𝑖=1]>Pr[𝑆𝑗=1],andPr[𝑆𝑗=−1|𝑆𝑖=−1]>Pr[𝑆𝑗=−1]
which is called categorical signal distributions [57].
Finally, similar to Shnayder et al. [57], we may extend to non-binary signal setting by extending the
payment to
𝑈𝐵𝑃𝑃(ˆ𝑠𝑖,ˆ𝑠𝑗,ˆ𝑠𝑘)=2 1[ˆ𝑠𝑖=ˆ𝑠𝑗]−1[ˆ𝑠𝑖=ˆ𝑠𝑘]
and the definition of uniform dominance to the following.
Definition A.1. Given a random vector (𝑆𝑖,𝑆𝑗,𝑆𝑘)∈Ω3on a discrete domain, we say 𝑆𝑗uniformly
dominates𝑆𝑘for𝑆𝑖if
Pr[𝑆𝑗=𝑠|𝑆𝑖=𝑠]−Pr[𝑆𝑘=𝑠|𝑆𝑖=𝑠]>0and
Pr[𝑆𝑗=𝑠′|𝑆𝑖=𝑠]−Pr[𝑆𝑘=𝑠′|𝑆𝑖=𝑠]<0
for all𝑠,𝑠′∈Ωwith𝑠≠𝑠′.
However, the guarantee for truth-telling ( informed truthfulness ) is weaker than the binary setting.
Theorem A.2. Given any discrete domain Ω, if for each agent 𝑖the associated agent 𝑗’s signal
uniformly dominates 𝑘’s signal for𝑖’s signal (definition A.1), Mechanism 3’s scheme is symmetrically
informed truthful so that
1. truth-telling is a strict equilibrium, and
2.each agent’s expected payment in truth-telling is no less than the payment in any other
symmetric equilibria and strictly better than any uninformed equilibrium’s.
Proof. First truth-telling is a strict equilibrium, because if 𝑆𝑖=𝑠,
arg max
ˆ𝑠E
𝑈𝐵𝑃𝑃(ˆ𝑠,𝑆𝑗,𝑆𝑘)|𝑆𝑖=𝑠
=arg max
ˆ𝑠Pr[𝑆𝑗=ˆ𝑠|𝑆𝑖=𝑠]−Pr[𝑆𝑘=ˆ𝑠|𝑆𝑖=𝑠]
=𝑠 (by definition A.1)
15Additionally, because Pr[𝑆𝑗=𝑠|𝑆𝑖=𝑠]−Pr[𝑆𝑘=𝑠|𝑆𝑖=𝑠]>Pr[𝑆𝑗=𝑠′|𝑆𝑖=𝑠]−Pr[𝑆𝑘=
𝑠′|𝑆𝑖=𝑠]for all𝑠′≠𝑠, summing over all possible 𝑠′∈Ωon both sides gets Pr[𝑆𝑗=𝑠|𝑆𝑖=
𝑠]−Pr[𝑆𝑘=𝑠|𝑆𝑖=𝑠]>0and
E
𝑈𝐵𝑃𝑃(𝑆𝑖,𝑆𝑗,𝑆𝑘)
>0.
For any informed equilibrium, by a direct computation E
𝑈𝐵𝑃𝑃(ˆ𝑆𝑖,ˆ𝑆𝑗,ˆ𝑆𝑘)
=0.
Finally, we show that the truth-telling has the maximum expected payment for each agents. When all
agent use a strategy 𝜎:Ω→Ω, agent𝑖’s expected payment is
∑︁
𝑠𝑖,ˆ𝑠𝑖∈ΩPr[𝑆𝑖=𝑠𝑖]𝜎(𝑠𝑖,ˆ𝑠𝑖)E
𝑈𝐵𝑃𝑃(ˆ𝑠𝑖,ˆ𝑆𝑗,ˆ𝑆𝑘)|𝑆𝑖=𝑠𝑖
=2∑︁
𝑠𝑖,ˆ𝑠𝑖∈ΩPr[𝑆𝑖=𝑠𝑖]𝜎(𝑠𝑖,ˆ𝑠𝑖)∑︁
𝑠∈Ω(Pr[𝑆𝑗=𝑠|𝑆𝑖=𝑠𝑖]−Pr[𝑆𝑘=𝑠|𝑆𝑖=𝑠𝑖])𝜎(𝑠,ˆ𝑠𝑖)
=2∑︁
𝑠𝑖∈ΩPr[𝑆𝑖=𝑠𝑖]∑︁
ˆ𝑠𝑖,𝑠∈Ω𝜎(𝑠𝑖,ˆ𝑠𝑖)𝜎(𝑠,ˆ𝑠𝑖)(Pr[𝑆𝑗=𝑠|𝑆𝑖=𝑠𝑖]−Pr[𝑆𝑘=𝑠|𝑆𝑖=𝑠𝑖])
Let𝑓𝑠𝑖(𝑠):=Í
ˆ𝑠𝑖∈Ω𝜎(𝑠𝑖,ˆ𝑠𝑖)𝜎(𝑠,ˆ𝑠𝑖)which is between 0and 1, because 𝑓𝑠𝑖(𝑠) ≤Í
ˆ𝑠𝑖∈Ω𝜎(𝑠𝑖,ˆ𝑠𝑖)Í
ˆ𝑠𝑖∈Ω𝜎(𝑠,ˆ𝑠𝑖)=1. Then the expectation becomes
∑︁
𝑠𝑖,ˆ𝑠𝑖∈ΩPr[𝑆𝑖=𝑠𝑖]𝜎(𝑠𝑖,ˆ𝑠𝑖)E
𝑈𝐵𝑃𝑃(ˆ𝑠𝑖,ˆ𝑆𝑗,ˆ𝑆𝑘)|𝑆𝑖=𝑠𝑖
=2∑︁
𝑠𝑖∈ΩPr[𝑆𝑖=𝑠𝑖]∑︁
𝑠∈Ω Pr[𝑆𝑗=𝑠|𝑆𝑖=𝑠𝑖]−Pr[𝑆𝑘=𝑠|𝑆𝑖=𝑠𝑖]𝑓𝑠𝑖(𝑠)
≤2∑︁
𝑠𝑖∈ΩPr[𝑆𝑖=𝑠𝑖] Pr[𝑆𝑗=𝑠𝑖|𝑆𝑖=𝑠𝑖]−Pr[𝑆𝑘=𝑠𝑖|𝑆𝑖=𝑠𝑖]
=E
𝑈𝐵𝑃𝑃(𝑆𝑖,𝑆𝑗,𝑆𝑘)
The inequality holds because 𝑓𝑠𝑖∈[0,1]and definition A.1. Therefore, we complete the proof. □
B Proofs in Section 2: Bayesian SST model and other models
The proofs of propositions 2.3 and 2.5 are standard, and variations can be found in related literature.
We include proofs here for completeness.
Proof of proposition 2.3. First given 𝜃∈RA, for all distinct 𝑎,𝑎′,𝑎′′∈ A ,Pr[𝑇𝜃(𝑎,𝑎′)=
1],Pr[𝑇𝜃(𝑎′,𝑎′′)=1]>1/2implies that 𝜃𝑎−𝜃𝑎′>0and𝜃𝑎′−𝜃𝑎′′>0becuase𝐹is strictly
increasing and 𝐹(0)=1/2. Because𝜃𝑎−𝜃𝑎′′=𝜃𝑎−𝜃𝑎′+𝜃𝑎′−𝜃𝑎′′>max(𝜃𝑎−𝜃𝑎′,𝜃𝑎′−𝜃𝑎′′),
we have
Pr[𝑇𝜃(𝑎,𝑎′′)=1]=𝐹(𝜃𝑎−𝜃𝑎′′)
>max𝐹(𝜃𝑎−𝜃𝑎′),𝐹(𝜃𝑎′−𝜃𝑎′′)
=max Pr[𝑇𝜃(𝑎,𝑎′)=1],Pr[𝑇𝜃(𝑎′,𝑎′′)=1]
and thus𝑇𝜃is strongly stochastically transitive for all 𝜃with distinct coordinates which happens
surely as𝜈is non-atomic. Finally, since the distribution on 𝜃is exchangeable on each coordinate,
E[E[𝑇𝜃(𝑎,𝑎′)]]=0for all𝑎,𝑎′. □
Proof of proposition 2.5. First given𝜃∈Θ, for all distinct 𝑎,𝑎′∈A, if the rank of 𝑎is higher than
𝑎′,
Pr[𝑇𝜃(𝑎,𝑎′)=1]=ℎ𝜂(𝜃(𝑎′)−𝜃(𝑎)+1)−ℎ𝜂(𝜃(𝑎′)−𝜃(𝑎))
whereℎ𝜂(𝑥)=𝑥
1−exp(−𝜂𝑥)by Busa-Fekete et al. [7].
Claim B.1. For any𝜂>0and𝑥∈Z>0, the difference ℎ𝜂(𝑥+1)−ℎ𝜂(𝑥)is increasing and larger
than 1/2whereℎ𝜂(𝑥)=𝑥
1−exp(−𝜂𝑥).
16By claim B.1, Pr[𝑇𝜃(𝑎,𝑎′)=1],Pr[𝑇𝜃(𝑎′,𝑎′′)=1]>1/2implies that 𝜃(𝑎′)−𝜃(𝑎)>0and
𝜃(𝑎′′)−𝜃(𝑎′)>0. Thus,𝜃(𝑎′′)−𝜃(𝑎)>max(𝜃(𝑎′′)−𝜃(𝑎′),𝜃(𝑎′′)−𝜃(𝑎′)), and
Pr[𝑇𝜃(𝑎,𝑎′′)=1]=ℎ(𝜃(𝑎′′)−𝜃(𝑎)+1)−ℎ(𝜃(𝑎′′)−𝜃(𝑎))
>maxℎ(𝜃(𝑎′′)−𝜃(𝑎′)+1)−ℎ(𝜃(𝑎′′)−𝜃(𝑎′)),ℎ(𝜃(𝑎′)−𝜃(𝑎)+1)−ℎ(𝜃(𝑎′)−𝜃(𝑎))
=max Pr[𝑇𝜃(𝑎,𝑎′)=1],Pr[𝑇𝜃(𝑎′,𝑎′′)=1]
where the second inequality is due to claim B.1. Therefore, 𝑇𝜃is strongly stochastically transitive for
all𝜃. Finally, E[E[𝑇𝜃(𝑎,𝑎′)]]=0for all𝑎,𝑎′since𝜃is an uniform distribution on rankings. □
Proof of claim B.1. We first prove that the function ℎ𝜂(𝑥)=𝑥
1−exp(−𝜂𝑥)is increasing and strictly
convex on𝑥≥0. Becauseℎ𝜂(𝑥)=1
𝜂ℎ1(𝜂𝑥), for all𝜂,𝑥, it is sufficient to consider 𝜂=1. First,
ℎ′
1(𝑥)=1−(𝑥+1)𝑒−𝑥
(1−𝑒−𝑥)2>0, soℎ1is increasing. Second, as ℎ′′
1(𝑥)=𝑒−𝑥((𝑥−2)+(𝑥+2)𝑒−𝑥)
(1−𝑒−𝑥)3 , to show
ℎ′′
1(𝑥)>0for all𝑥 > 0, it is sufficient to show that 𝑔(𝑥)=(𝑥−2)+(𝑥+2)𝑒−𝑥>0. Because
𝑔(0)=0and𝑔′(𝑥)=1−(𝑥+1)𝑒−𝑥>0,𝑔(𝑥)>0for all𝑥 >0. Therefore, ℎ1is strictly convex.
On the other hand, ℎ𝜂(𝑥+2)−ℎ𝜂(𝑥+1)> ℎ𝜂(𝑥+1)−ℎ𝜂(𝑥)for all𝑥by convexity, and ℎ𝜂(2)−ℎ𝜂(1)=
1
1+𝑒−𝜂>1
2which completes the proof. □
C Proofs in Section 3 and 4
C.1 Uniform dominance from Bayesian SST
Proof of lemma 4.2. With a prior similar assumption for Bayesian SST model, we only need to show
Pr[𝑆(𝑎′′,𝑎′)=1|𝑆(𝑎,𝑎′)=1]>Pr[𝑆(𝑎′′,𝑎)=1|𝑆(𝑎,𝑎′)=1], (5)
and the other case Pr[𝑆(𝑎′′,𝑎′)=−1|𝑆(𝑎,𝑎′)=−1]>Pr[𝑆(𝑎′′,𝑎)=−1|𝑆(𝑎,𝑎′)=−1]follows
by symmetry. To prove eq. (5), we can rewrite the conditional probability in expectations of 𝑇𝜃.
Pr[𝑆(𝑎′′,𝑎′)=1|𝑆(𝑎,𝑎′)=1]
=∫
Pr[𝑇𝜃(𝑎′′,𝑎′)=1,𝑇𝜃(𝑎,𝑎′)=1|𝜃]𝑑𝑃Θ∫
Pr[𝑇𝜃(𝑎,𝑎′)=1|𝜃]𝑑𝑃Θ
=∫
Pr[𝑇𝜃(𝑎′′,𝑎′)=1|𝜃]Pr[𝑇𝜃(𝑎,𝑎′)=1|𝜃]𝑑𝑃Θ∫
Pr[𝑇𝜃(𝑎,𝑎′)=1|𝜃]𝑑𝑃Θ(conditional independent)
=2∫
Pr[𝑇𝜃(𝑎′′,𝑎′)=1|𝜃]Pr[𝑇𝜃(𝑎,𝑎′)=1|𝜃]𝑑𝑃Θ (a prior similar)
=2∫E[𝑇𝜃(𝑎′′,𝑎′)|𝜃]+1
2E[𝑇𝜃(𝑎,𝑎′)|𝜃]+1
2𝑑𝑃Θ (binary value)
=1
2∫
E[𝑇𝜃(𝑎′′,𝑎′)|𝜃]E[𝑇𝜃(𝑎,𝑎′)|𝜃]+E[𝑇𝜃(𝑎′′,𝑎′)|𝜃]+E[𝑇𝜃(𝑎,𝑎′)|𝜃]+1𝑑𝑃Θ
=1
2∫
E[𝑇𝜃(𝑎′′,𝑎′)|𝜃]E[𝑇𝜃(𝑎,𝑎′)|𝜃]+1𝑑𝑃Θ. (a prior similar)
Claim C.1. For any strongly stochastically transitive 𝑇𝜃onA, and distinct 𝑎,𝑎′,𝑎′′∈A
E[𝑇𝜃(𝑎,𝑎′)|𝜃]E[𝑇𝜃(𝑎′′,𝑎′)|𝜃]>E[𝑇𝜃(𝑎,𝑎′)|𝜃]E[𝑇𝜃(𝑎′′,𝑎)|𝜃].
With claim C.1, we have
Pr[𝑆(𝑎′′,𝑎′)=1|𝑆(𝑎,𝑎′)=1]=1
2∫
E[𝑇𝜃(𝑎′′,𝑎′)|𝜃]E[𝑇𝜃(𝑎,𝑎′)|𝜃]+1𝑑𝑃Θ
>1
2∫
E[𝑇𝜃(𝑎′′,𝑎)|𝜃]E[𝑇𝜃(𝑎,𝑎′)|𝜃]+1𝑑𝑃Θ=Pr[𝑆(𝑎′′,𝑎)=1|𝑆(𝑎,𝑎′)=1].
This completes the proof of eq. (5), and thus the uniform dominance. □
17Proof of claim C.1. We let𝑄(𝛼,𝛼′):=E[𝑇𝜃(𝛼,𝛼′)|𝜃]=2 Pr[𝑇𝜃(𝛼,𝛼′)=1|𝜃]−1for all𝛼,𝛼′.
Note that𝑄(𝛼,𝛼′)>0if and only if Pr[𝑇𝜃(𝛼,𝛼′)=1|𝜃]>1/2and𝑄(𝛼,𝛼′)=−𝑄(𝛼′,𝛼).
By symmetry, let 𝑄(𝑎,𝑎′)>0. It is sufficient to show that
𝑄(𝑎′′,𝑎′)>𝑄(𝑎′′,𝑎).
If𝑄(𝑎′,𝑎′′)>0, by definition 2.1 𝑄(𝑎,𝑎′′)> 𝑄(𝑎′,𝑎′′)>0so𝑄(𝑎′′,𝑎′)> 𝑄(𝑎′′,𝑎). Now
consider𝑄(𝑎′,𝑎′′)<0. If𝑄(𝑎′′,𝑎)<0,𝑄(𝑎′′,𝑎′)>0> 𝑄(𝑎′′,𝑎). If𝑄(𝑎′′,𝑎)>0, we have
𝑄(𝑎′′,𝑎)>0,𝑄(𝑎,𝑎′)>0, and thus𝑄(𝑎′′,𝑎′)>𝑄(𝑎′′,𝑎)by definition 2.1 □
C.2 Uniform dominance and weak notions of stochastic transitivity
There are weaker forms of stochastic transitivity, raising the question of whether they are sufficient
for uniform dominance as in lemma 4.2. We show that general weak stochastic transitivity is not
sufficient. Additionally, we show that although the noisy sorting model from [ 5] is only weakly
stochastically transitive but does not satisfy definition 2.1, it exhibits uniform dominance.
Definition C.2 ([13]).A stochastic comparison function, 𝑇:A2→{− 1,1}, isweakly stochastically
transitive if for all𝑎,𝑎′,𝑎′′∈A with Pr[𝑇(𝑎,𝑎′)=1]>1/2andPr[𝑇(𝑎′,𝑎′′)=1]>1/2,
Pr[𝑇(𝑎,𝑎′′)=1]>1/2.
Compared to definition 2.1, the weak stochastic transitivity only require the item 𝑎is favorable than
𝑎′′. Below we provide a simple weakly stochastically transitive example with a prior similar property
that does not satisfy the uniform dominance in eq. (5).
Example C.3. Consider the set of three items and Θconsists of all ranking on Awith uniform prior
where𝜃maps each items to its value. Given 𝜃∈Θso that if𝜃(𝑎)>𝜃(𝑎′)>𝜃(𝑎′′),
Pr[𝑇𝜃(𝑎,𝑎′)=1]=Pr[𝑇𝜃(𝑎′,𝑎′′)=1]=0.9andPr[𝑇𝜃(𝑎,𝑎′′)=1]=0.6.
Note that the model is weakly stochastically transitive, because an item with a larger value is more fa-
vorable and the weak stochastic transitivity is reduced to transitivity on the values. However, the model
is not strongly stochastically transitive, because Pr[𝑇𝜃(𝑎,𝑎′′)=1]=0.6<max{Pr[(𝑇(𝑎,𝑎′)=
1],Pr[(𝑇(𝑎′,𝑎′′)=1]]}=0.9. Finally, as the rank 𝜃has a uniform prior, the model satisfies a prior
similar assumption.
To conclude the example, we show that eq. (5) does not hold for the above model. By direct
computation over all six possible ranking 𝜃, we have
Pr[𝑆(𝑎′′,𝑎′)=1|𝑆(𝑎,𝑎′)=1]
=1
2∫
E[𝑇𝜃(𝑎′′,𝑎′)|𝜃]E[𝑇𝜃(𝑎,𝑎′)|𝜃]+1𝑑𝑃Θ
=1
2
1−64
6
,
butPr[𝑆(𝑎′′,𝑎)=1|𝑆(𝑎,𝑎′)=1]=1
2
1+64
6
. Therefore, we have Pr[𝑆(𝑎′′,𝑎′)=1|𝑆(𝑎,𝑎′)=
1]<Pr[𝑆(𝑎′′,𝑎)=1|𝑆(𝑎,𝑎′)=1], and show that eq. (5) does not hold.
Though the above example shows that weak stochastic transitivity is not sufficient.5Below we show a
popular weakly stochastically transitive model in Braverman and Mossel [5]has uniform dominance
as in lemma 4.2.
Example C.4. LetΘbe the set of rankings on Aand𝜂 > 0be a parameter. Given a uniformly
distributed reference ranking 𝜃∈Θ, the noise ranking model [5] ensures that for all 𝜃(𝑎)>𝜃(𝑎′)
Pr[𝑇𝜃(𝑎,𝑎′)=1]=1
2+𝜂
Note that the above model does not satisfy the strict inequality in definition 2.1, but by direct
computation, Pr[𝑆(𝑎′′,𝑎′)=1|𝑆(𝑎,𝑎′)=1]=1
2
1+4𝛾2
3
andPr[𝑆(𝑎′′,𝑎)=1|𝑆(𝑎,𝑎′)=1]=
1
2
1−4𝛾2
3
, which satisfies lemma 4.2.
5In the above example, we can also decrease 0.9to a smaller number that satisfies both uniform dominance
and weak stochastic transitivity.
18C.3 Symmetrically strongly truthful from uniform dominance
Proof of lemma 4.3. Suppose𝑆𝑖=1. Because Pr[𝑆𝑗=1|𝑆𝑖=1]>Pr[𝑆𝑘=1|𝑆𝑖=1],Pr[𝑆𝑗=
−1|𝑆𝑖=1]<Pr[𝑆𝑘=−1|𝑆𝑖=1]. Therefore, arg maxˆ𝑠∈{−1,1}Pr[𝑆𝑗=ˆ𝑠|𝑆𝑖=1]−Pr[𝑆𝑘=ˆ𝑠𝑖|𝑆𝑖=
1]=1. Identical argument holds for the case of 𝑆𝑖=−1which completes the proof.
Additionally, the expected payment of truth-telling is
E
𝑈𝐵𝑃𝑃(𝑆𝑖,𝑆𝑗,𝑆𝑘)
=∑︁
𝑎Pr[𝑆𝑖=𝑠𝑖]∑︁
𝑠𝑗,𝑠𝑘Pr[𝑆𝑗=𝑠𝑗,𝑆𝑘=𝑠𝑘|𝑆𝑖=𝑠𝑖]𝑈𝐵𝑃𝑃(𝑠𝑖,𝑠𝑗,𝑠𝑘)
=2∑︁
𝑎Pr[𝑆𝑖=𝑠𝑖]∑︁
𝑠𝑗,𝑠𝑘Pr[𝑆𝑗=𝑠𝑗,𝑆𝑘=𝑠𝑘|𝑆𝑖=𝑠𝑖](1[𝑠𝑖=𝑠𝑘]−1[𝑠𝑖=𝑠𝑘])
=2∑︁
𝑎Pr[𝑆𝑖=𝑠𝑖] Pr[𝑆𝑗=𝑠𝑖|𝑆𝑖=𝑠𝑖]−Pr[𝑆𝑘=𝑠𝑖|𝑆𝑖=𝑠𝑖]
>0
The last inequality holds due to definition 4.1. □
Proof of lemma 4.4. As𝜎is uninformed, let 𝜇(𝑠)=𝜎(𝑠,𝑠)=𝜎(−𝑠,𝑠)and𝜇(−𝑠)=𝜎(𝑠,−𝑠)=
𝜎(−𝑠,−𝑠)for all𝑠.
E
𝑈𝐵𝑃𝑃(ˆ𝑠𝑖,ˆ𝑆𝑗,ˆ𝑆𝑘)|𝑆𝑖=𝑠𝑖
=∑︁
ˆ𝑠𝑗,ˆ𝑠𝑘𝜇(ˆ𝑠𝑗)𝜇(ˆ𝑠𝑘)𝑈𝐵𝑃𝑃(ˆ𝑠𝑖,ˆ𝑆𝑗,ˆ𝑆𝑘)=∑︁
ˆ𝑠𝑗,ˆ𝑠𝑘𝜇(ˆ𝑠𝑗)𝜇(ˆ𝑠𝑘)(ˆ𝑠𝑖ˆ𝑠𝑗−ˆ𝑠𝑖ˆ𝑠𝑘)=0
The first equality holds as the reports are independent of signals. □
Proof of lemma 4.5.
E𝑃,𝜎
𝑈𝐵𝑃𝑃(ˆ𝑠𝑖,ˆ𝑆𝑗,ˆ𝑆𝑘)|𝑆𝑖=𝑠𝑖
=∑︁
𝑠𝑗,𝑠𝑘,ˆ𝑠𝑗,ˆ𝑠𝑘Pr[𝑆𝑗=𝑠𝑗,𝑆𝑘=𝑠𝑘|𝑆𝑖=𝑠𝑖]𝜎(𝑠𝑗,ˆ𝑠𝑗)𝜎(𝑠𝑘,ˆ𝑠𝑘)𝑈𝐵𝑃𝑃(ˆ𝑠𝑖,ˆ𝑠𝑗,ˆ𝑠𝑘)
=2∑︁
𝑠𝑗,𝑠𝑘,ˆ𝑠𝑗,ˆ𝑠𝑘Pr[𝑆𝑗=𝑠𝑗,𝑆𝑘=𝑠𝑘|𝑆𝑖=𝑠𝑖]𝜎(𝑠𝑗,ˆ𝑠𝑗)𝜎(𝑠𝑘,ˆ𝑠𝑘) 1[ˆ𝑠𝑖=ˆ𝑠𝑗]−1[ˆ𝑠𝑖=ˆ𝑠𝑘]
(by eq. (1))
=2∑︁
𝑠𝑗,ˆ𝑠𝑗Pr[𝑆𝑗=𝑠𝑗|𝑆𝑖=𝑠𝑖]𝜎(𝑠𝑗,ˆ𝑠𝑗)1[ˆ𝑠𝑖=ˆ𝑠𝑗]−2∑︁
𝑠𝑘,ˆ𝑠𝑘Pr[𝑆𝑘=𝑠𝑘|𝑆𝑖=𝑠𝑖]𝜎(𝑠𝑘,ˆ𝑠𝑘)1[ˆ𝑠𝑖=ˆ𝑠𝑘]
=2∑︁
𝑠,ˆ𝑠(Pr[𝑆𝑗=𝑠|𝑆𝑖=𝑠𝑖]−Pr[𝑆𝑘=𝑠|𝑆𝑖=𝑠𝑖])𝜎(𝑠,ˆ𝑠)1[ˆ𝑠𝑖=ˆ𝑠](renaming dummy variables)
=2∑︁
𝑠(Pr[𝑆𝑗=𝑠|𝑆𝑖=𝑠𝑖]−Pr[𝑆𝑘=𝑠|𝑆𝑖=𝑠𝑖])𝜎(𝑠,ˆ𝑠𝑖)
Let𝛿=Pr[𝑆𝑗=𝑠𝑖|𝑆𝑖=𝑠𝑖]−Pr[𝑆𝑘=𝑠𝑖|𝑆𝑖=𝑠𝑖]>0, because𝑆𝑗uniformly dominates 𝑆𝑘
for𝑆𝑖. Additionally, Pr[𝑆𝑗=−𝑠𝑖|𝑆𝑖=𝑠𝑖]−Pr[𝑆𝑘=−𝑠𝑖|𝑆𝑖=𝑠𝑖]=1−Pr[𝑆𝑗=𝑠𝑖|𝑆𝑖=
𝑠𝑖]−1+Pr[𝑆𝑘=𝑠𝑖|𝑆𝑖=𝑠𝑖]=−𝛿. We have
E𝑃,𝜎
𝑈𝐵𝑃𝑃(ˆ𝑠𝑖,ˆ𝑆𝑗,ˆ𝑆𝑘)|𝑆𝑖=𝑠𝑖
=2∑︁
𝑠(Pr[𝑆𝑗=𝑠|𝑆𝑖=𝑠𝑖]−Pr[𝑆𝑘=𝑠|𝑆𝑖=𝑠𝑖])𝜎(𝑠,ˆ𝑠𝑖)
=2𝛿(𝜎(𝑠𝑖,ˆ𝑠𝑖)−𝜎(−𝑎,ˆ𝑠𝑖)),
soarg maxˆ𝑠𝑖∈{−1,1}E𝑃,𝜎
𝑈𝐵𝑃𝑃(ˆ𝑠𝑖,ˆ𝑆𝑗,ˆ𝑆𝑘)|𝑆𝑖=𝑠𝑖
=arg maxˆ𝑠𝑖∈{−1,1}{𝜎(𝑠𝑖,ˆ𝑠𝑖)−𝜎(−𝑠𝑖,ˆ𝑠𝑖)}
which completes the proof. □
D Proofs in Section 5.1
Before diving into the proof, we introduce some notations. We further introduce Ising models with
bias parameter 𝜶∈R𝑉
≥0in addition to 𝜷where
𝐻(s)=∑︁
𝑖,𝑗∈𝑉𝛽𝑖,𝑗𝑠𝑖𝑠𝑗+∑︁
𝑖∈𝑉𝛼𝑖𝑠𝑖
19andPr𝜶,𝜷[S=s]∝exp(𝐻(s)), for all configuration s. Given𝑖∈𝑉, let the expectation and ratio be
𝜈𝑖(𝜶,𝜷)=E𝜶,𝜷[𝑆𝑖]=Pr
𝜶,𝜷[𝑆𝑖=1]−Pr
𝜶,𝜷[𝑆𝑖=−1]and𝜌𝑖(𝜶,𝜷)=Pr𝜶,𝜷[𝑆𝑖=1]
Pr𝜶,𝜷[𝑆𝑖=−1]
respectively which are monotone to each other. We will omit 𝜶,𝜷when clear. Given a subset 𝑈⊆𝑉,
s𝑈∈{− 1,1}𝑈is a configuration over the nodes in 𝑈, and s𝑈=1if𝑥𝜄=1for all𝜄∈𝑈. We write
Pr[·|S𝑈=s𝑈],𝜈𝑖|S𝑈=s𝑈, and𝜌𝑖|S𝑈=s𝑈for the conditional probability, expectation and ratio when the
configuration in 𝑈is fixed as specified by s𝑈.
A lower bound for LHS Informally, we want to lower bound the correlation between adjacent 𝑖and
𝑗(friends). Note that as we remove edges (setting coordinates of 𝜷to zeros), the correlation should
decrease, and the smallest correlation between neighboring nodes 𝑖and𝑗happens when 𝐸={(𝑖,𝑗)}.
Lemma D.2 formalizes this idea using the following monotone inequality [44, Theorem 17.2].
Theorem D.1 (Griffiths’ inequality) .For any𝑖∈𝑉,𝜈𝑖(𝜶,𝜷)=E𝜶,𝜷[𝑆𝑖]is non-negative and
non-decreasing in all 𝛽𝑗,𝑘≥0and𝛼𝑗≥0with𝑗,𝑘∈𝑉.
Lemma D.2. Given𝑉and𝑖,𝑗∈𝑉, for all 𝜶,𝜷, and 𝜷′, if𝛽′
𝑒=𝛽𝑒when𝑒=(𝑖,𝑗)and𝛽′
𝑒=0
otherwise, we have
𝜈𝑖|𝑆𝑗=1(𝜶,𝜷)≥𝜈𝑖|𝑆𝑗=1(𝜶,𝜷′)and𝜌𝑖|𝑆𝑗=1(𝜶,𝜷)≥𝜌𝑖|𝑆𝑗=1(𝜶,𝜷′).
Proof. First, note that we can write the conditional expectation E𝜶,𝜷
𝑆𝑖|𝑆𝑗=1as marginal
expectation. Formally, consider 𝜶𝜂so that𝛼𝜂
𝜄=𝛼𝜄if𝜄≠𝑗and𝛼𝜂
𝑗=𝛼𝑗+𝜂. Because
𝜂→𝜶𝜂is non-decreasing, 𝜂→𝜈𝑖(𝜶𝜂,𝜷)is non-decreasing by theorem D.1. In addition,
Pr𝜶𝜂,𝜷[𝑆𝑖|𝑆𝑗=𝑠]=Pr𝜶,𝜷[𝑆𝑖|𝑆𝑗=𝑠]for all𝑠, and Pr𝜶𝜂,𝜷[𝑆𝑗=−1]=𝑂(𝑒−2𝜂), so
𝜈𝑖|𝑆𝑗=1(𝜶,𝜷)=E𝜶,𝜷[𝑆𝑖|𝑆𝑗=1]=lim
𝜂→+∞𝜈𝑖(𝜶𝜂,𝜷).
Similarly,
𝜈𝑖|𝑆𝑗=1(𝜶,𝜷′)=E𝜶,𝜷′[𝑆𝑖|𝑆𝑗=1]=lim
𝜂→+∞𝜈𝑖(𝜶𝜂,𝜷′).
On the other hand, consider 𝜷𝜆so that𝛽𝜆
𝑒=𝛽𝑒if𝑒≠(𝑖,𝑗)and𝛽𝜆
𝑖,𝑗=𝛽𝑖,𝑗+𝜆. By theorem D.1,
𝜈𝑖(𝜶𝜂,𝜷𝜆)is non-decreasing in 𝜆for all𝜂. Because 𝜷0=𝜷′and𝜷1=𝜷, we have
𝜈𝑖|𝑆𝑗=1(𝜶,𝜷′)=lim
𝜂→+∞𝜈𝑖(𝜶𝜂,𝜷′)≤ lim
𝜂→+∞𝜈𝑖(𝜶𝜂,𝜷)=𝜈𝑖|𝑆𝑗=1(𝜶,𝜷)
Because𝜌𝑖=1+𝜈𝑖
1−𝜈𝑖is monotone in 𝜈𝑖, the second part follows. □
Given 𝜷′defined in lemma D.2, by some direct computation with 𝜶=0
𝜌𝑖|𝑆𝑗=1(𝜶,𝜷)≥𝜌𝑖|𝑆𝑗=1(𝜶,𝜷′)=𝑒2𝛼𝑖+2𝛽𝑖,𝑗=𝑒2𝛽. (6)
An upper bound for RHS Now, we need to upper bound the correlation between non-adjacent
𝑖and𝑘(non-friends). We will use Weitz’s self-avoiding walks reduction [ 65] to upper bound the
correlation on general graph 𝐺by the correlation on trees.
Given a general graph 𝐺, and an arbitrary node 𝑖, we can construct the Self Avoiding Walk Tree
of𝐺rooted at𝑖, denoted𝑇𝑆𝐴𝑊(𝐺,𝑖), so that Pr[𝑆𝑖=1|S𝑈=s𝑈]is the same in 𝐺as in the tree.
We outline the construction. 𝑇𝑆𝐴𝑊(𝐺,𝑖)enumerates all self-avoiding walks in 𝐺starting at𝑖which
terminates when it revisits a previous node (closes a cycle). Then, 𝑇𝑆𝐴𝑊(𝐺,𝑖)introduces a leaf with
a certain boundary condition. The self-avoiding walk never revisits a node immediately, so there all
the leaves with fixed boundary conditions are at least three hops away from node 𝑖. Note that if 𝐺has
maximum degree 𝑑,𝑇𝑆𝐴𝑊 is a𝑑-ary tree.
Theorem D.3 ([65]) .For any 𝜶,𝜷, node𝑖∈𝑉, and configuration s𝑈on𝑈⊂𝑉,
Pr
𝜶,𝜷[𝑆𝑖=1|S𝑈=s𝑈]= Pr
𝑇𝑆𝐴𝑊(𝐺,𝑖)[𝑆𝑖=1|S𝑈=s𝑈].
20First, with the above theorem, we have 𝜈𝑖|𝑆𝑘=1(𝜶,𝜷)=E𝜶,𝜷[𝑆𝑖|𝑆𝑘=1]=E𝑇𝑆𝐴𝑊(𝐺,𝑖)[𝑆𝑖|𝑆𝑘=1].
By the monotone property in theorem D.1, setting all two-hop neighbors 𝑈in𝑇𝑆𝐴𝑊(𝐺,𝑖)to1
(recalled that any boundary conditions for 𝑇𝑆𝐴𝑊(𝐺,𝑖)being at least three hops away) increases the
conditional expectation,
E𝑇𝑆𝐴𝑊(𝐺,𝑖)[𝑆𝑖|𝑆𝑘=1]≤E𝑇𝑆𝐴𝑊(𝐺,𝑖)[𝑆𝑖|S𝑈=1,𝑆𝑘=1].
Let𝑇be the tree by truncating 𝑇𝑆𝐴𝑊(𝐺,𝑖)at level 2. By the Markov property of Ising models, the
expectation is equal to the expectation on 𝑇.
E𝜶,𝜷[𝑆𝑖|𝑆𝑘=1]≤E𝑇𝑆𝐴𝑊(𝐺,𝑖)[𝑆𝑖|S𝑈=1]=E𝑇[𝑆𝑖|S𝑈=1]. (7)
Finally, we can recursively compute the probability ratio 𝜌𝑖(and thus expectation 𝜈𝑖) on trees.
Specifically, given a rooted tree 𝑇′, we define𝜌𝑇′as the ratio of probabilities for the root to be
+1and−1respectively, and 𝜌𝑇′|S𝑈=s𝑈for the ratio of conditional probabilities. As stated in the
following lemma, it is well known (see, for example, [ 22]) that the ratio of each node can be computed
recursively over the children’s ratio.
Lemma D.4. Given a tree 𝑇rooted at𝑖with parameter(𝜶,𝜷)and boundary condition s𝑈,
𝜌𝑇|S𝑈=s𝑈=𝑒2𝛼𝑖𝑑Ö
𝑙=1𝜌𝑇𝑙|S𝑈=s𝑈𝑒2𝛽𝑖,𝑗𝑙+1
𝑒2𝛽𝑖,𝑗𝑙+𝜌𝑇𝑙|S𝑈=s𝑈
where𝑗1,...,𝑗𝑑are children of 𝑖and𝑇𝑙is the subtree rooted at 𝑗𝑙for all𝑙.
By the monotone property in theorem D.1, the maximum of right-hand side of eq. (7) happens when
𝑇is a complete 𝑑-ary tree with 𝜷=𝛽. Therefore,
𝜌𝑖|𝑆𝑘=1(𝜶,𝜷)≤ 
𝑒2(𝑑+1)𝛽+1
𝑒2𝛽+𝑒2𝑑𝛽!𝑑
. (8)
Finally, with eqs. (6) and (8), we have 𝜌𝑖|𝑆𝑗=1(𝜶,𝜷)≥𝑒2𝛽≥
𝑒2(𝑑+1)𝛽+1
𝑒2𝛽+𝑒2𝑑𝛽𝑑
≥𝜌𝑖|𝑆𝑘=1(𝜶,𝜷)which
implies eq. (4).
Remark D.5. Note that for any graph 𝐺there exists small enough 𝛽,𝛽so that the condition in
theorem 5.1 is satisfied, because the inequality become equality when 𝛽=𝛽=0, and𝜕
𝜕𝛽2𝛽
𝑑>0=
𝜕
𝜕𝛽ln𝑒2(𝑑+1)𝛽+1
𝑒2𝛽+𝑒2𝑑𝛽.
The bound between 𝜷and𝑑is necessary as shown in fig. 3. On the other hand, by the Markov
property of the Ising model, the majority of all neighbor’s signals is a sufficient statistic, and we
can show the majority of all neighbor’s signals are uniformly dominant to a non-neighbor’s signal.
Therefore, we can get a symmetrically strongly truthful mechanism by replacing 𝑗’s reports with the
majority of reports from 𝑖’s neighbors.
E Proof of Theorem 5.3
The sufficient condition is done by lemma 4.3, because
arg max
ˆ𝑠𝑖∈{−1,1}E
𝜆𝑈𝐵𝑃𝑃(ˆ𝑠𝑖,𝑆𝑗,𝑆𝑘)+𝜇(𝑆𝑗,𝑆𝑘)|𝑆𝑖=𝑠𝑖
=arg max
ˆ𝑠𝑖∈{−1,1}E
𝜆𝑈𝐵𝑃𝑃(ˆ𝑠𝑖,𝑆𝑗,𝑆𝑘)|𝑆𝑖=𝑠𝑖
=arg max
ˆ𝑠𝑖∈{−1,1}E
𝑈𝐵𝑃𝑃(ˆ𝑠𝑖,𝑆𝑗,𝑆𝑘)|𝑆𝑖=𝑠𝑖
(𝜆>0)
=𝑠𝑖 (by lemma 4.3)
For the necessary, given 𝑈, define𝐷(𝑠𝑗,𝑠𝑘)=1
2 𝑈(1,𝑠𝑗,𝑠𝑘)−𝑈(−1,𝑠𝑗,𝑠𝑘)and𝜇(𝑠𝑗,𝑠𝑘)=
1
2(𝑈(1,𝑠𝑗,𝑠𝑘)+𝑈(−1,𝑠𝑗,𝑠𝑘))for all𝑠𝑗and𝑠𝑘in{−1,1}. Hence
𝑈(𝑠𝑖,𝑠𝑗,𝑠𝑘)=𝑠𝑖·𝐷(𝑠𝑗,𝑠𝑘)+𝜇(𝑠𝑗,𝑠𝑘),∀𝑠𝑖,𝑠𝑗,𝑠𝑘∈{−1,1} (9)
21Figure 3: As fixing any 𝛽,𝛽, we can construct a simple graph with 𝑉={𝑣0,...,𝑣𝑛−1}and𝐸=
{(𝑣0,𝑣𝑙),(𝑣𝑙,𝑣𝑛−1):𝑙=1,...,𝑛−2}where agent 𝑣0and𝑣𝑛−1are not connected but share 𝑛−2
common friends. We can show that the correlation between 𝑆0and𝑆𝑛−1converge to 1as the number
of common friends 𝑑increases, while the correlation between 𝑆0and𝑆1is bounded away from 1.
Given a joint distribution satisfying definition 4.1, we let 𝑝𝑠𝑖(𝑠𝑗,𝑠𝑘)=Pr[𝑆𝑗=𝑠𝑗,𝑆𝑘=𝑠𝑘|𝑆𝑖=𝑠𝑖]
and additionally write 𝑝𝑠𝑖=
𝑝𝑠𝑖(1,1)𝑝𝑠𝑖(1,−1)
𝑝𝑠𝑖(−1,1)𝑝𝑠𝑖(−1,−1)
. Then definition 4.1 ensures that
𝑝1(1,−1)> 𝑝1(−1,1)and𝑝−1(1,−1)< 𝑝−1(−1,1).
Because𝑈is truthful for all uniformly dominant tuples, we have
0<E
𝑈(1,𝑆𝑗,𝑆𝑘)|𝑆𝑖=1
−E
𝑈(−1,𝑆𝑗,𝑆𝑘)|𝑆𝑖=1
=2∑︁
𝑠𝑗,𝑠𝑘𝐷(𝑠𝑗,𝑠𝑘)𝑝1(𝑠𝑖,𝑠𝑗)
0>E
𝑈(1,𝑆𝑗,𝑆𝑘)|𝑆𝑖=−1
−E
𝑈(−1,𝑆𝑗,𝑆𝑘)|𝑆𝑖=−1
=2∑︁
𝑠𝑗,𝑠𝑘𝐷(𝑠𝑗,𝑠𝑘)𝑝−1(𝑠𝑖,𝑠𝑗).(10)
Suppose the following are true
𝐷(1,−1)=−𝐷(−1,1)>0 (11)
𝐷(1,1)=𝐷(−1,−1)=0 (12)
Let𝜆=𝐷(1,−1)>0. By eqs. (11) and (12), we have
𝑈(𝑠𝑖,𝑠𝑗,𝑠𝑘)=𝑠𝑖·𝐷(𝑠𝑗,𝑠𝑘)+𝜇(𝑠𝑗,𝑠𝑘) (by eq. (9))
=𝜆·𝑠𝑖(𝑠𝑗−𝑠𝑘)+𝜇(𝑠𝑗,𝑠𝑘) (by eqs. (9) and (11))
which completes the proof. Thus, we will construct three joint distributions satisfying definition 4.1
to prove eqs. (11) and (12).
The first joint distribution 𝑝𝑠𝑖
1(𝑠𝑗,𝑠𝑘)with 0<𝛿≤1/2
𝑝1=
0 1/2+𝛿
1/2−𝛿 0
and𝑝−1=
0 1/2−𝛿
1/2+𝛿 0
.
Then eq. (10) on the first distribution reduces to
0<𝐷(1,−1)𝑝1
1(1,−1)+𝐷(−1,1)𝑝1
1(−1,1)=1
2(𝐷(1,−1)+𝐷(−1,1))+𝛿(𝐷(1,−1)−𝐷(−1,1))
0>𝐷(1,−1)𝑝−1
1(1,−1)+𝐷(−1,1)𝑝−1
1(−1,1)=1
2(𝐷(1,−1)+𝐷(−1,1))−𝛿(𝐷(1,−1)−𝐷(−1,1)).
As we take𝛿to zero, we prove 𝐷(1,−1)=−𝐷(−1,1). Then plugging in with nonzero 𝛿, we have
𝐷(1,−1)>0and complete the proof of eq. (11).
22The second joint distribution 𝑝𝑠𝑖
2(𝑠𝑗,𝑠𝑘)with 0≤𝜖≤1is
𝑝1=
1−𝜖3
4𝜖
𝜖
40
and𝑝−1=1−𝜖𝜖
43𝜖
40
.
With eq. (11), eq. (10) reduces to
0<(1−𝜖)𝐷(1,1)+𝜖
4(𝐷(1,−1)−𝐷(−1,1))
0>(1−𝜖)𝐷(1,1)−𝜖
4(𝐷(1,−1)−𝐷(−1,1)).
By taking𝜖to zero, we prove 𝐷(1,1)=0. We can prove 𝐷(−1,−1)=0using the similar trick and
complete the proof of eq. (12).
F Additional empirical results
F.1 Comparison data
Here we test if the dataset satisfy transitivity property. We denote the proportion of rankings such that
item𝑎is higher than item 𝑎′in the dataset by 𝑝𝑎>𝑎′. If𝑝𝑎>𝑎′>1/2,𝑝𝑎′>𝑎′′>1/2, and𝑝𝑎>𝑎′′>1/2,
we say the triple of items {𝑎,𝑎′,𝑎′′}empirically satisfies transitivity. If 𝑝𝑎>𝑎′>1/2,𝑝𝑎′>𝑎′′>1/2,
and𝑝𝑎>𝑎′′>max{𝑝𝑎>𝑎′,𝑝𝑎′>𝑎′′}, we say the triple of items {𝑎,𝑎′,𝑎′′}empirically satisfies strong
transitivity. We first test the transitivity of the SUSHI subdataset selected in section 6.1. We find that
100% of the item triples empirically satisfy transitivity, and 69.17% of the item triples empirically
satisfy strong transitivity. This suggests that our transitivity assumption for the comparison data is
mostly aligned.
Moreover, we conducted an experiment on the entire SUSHI dataset without any selection criteria
and demonstrated the results in fig. 4. Observe that the ECDF of payments from original human users
also dominates the payments under the uninformed strategy and the unilateral deviating strategy. This
is consistent with our experimental results in section 6.1. However, there are two minor difference.
First the separation of truth-telling from the other two is slightly less prominent than fig. 1 with
the selection criteria. This may be due to a slightly lower degree of transitivity across agents with
different backgrounds. In particular, we found the average value of 𝑝𝑎>𝑎′′−max{𝑝𝑎>𝑎′,𝑝𝑎′>𝑎′′}is
0.0559 without the selection criteria which is less than 0.0604 with the selection criteria in fig. 1.
Second, the fraction of agents receiving positive payments is slightly higher than in fig. 1 ( 0.785
and0.763respectively). This aligned with or empirical (strong) transitively which are 1and0.7667
compared to the above 1and0.69117 . Furthermore, we also conducted experiments on other groups
of users by changing the selection criteria. Those interested can refer to fig. 5, fig. 6 and table 1 for
the results, which further verify the effectiveness of our mechanism.
Selection criteria Number of users Average utility Fraction of positive utility
All (No selection) 5000 0 .138 78 .5%
Female, 30-49, Kanto/Shizuoka 249 0 .137 76 .3%
Male, 30-49, Kanto/Shizuoka 185 0 .167 82 .2%
Female, 5-29, Kanto/Shizuoka 146 0 .175 84 .2%
Female, 50+, Kanto/Shizuoka 26 0 .13 80 .8%
Female, 30-49, Tohoku 30 0 .174 83 .3%
Female, 30-49, Hokuriku 23 0 .105 69 .6%
Table 1: Summary of truth-telling utility in appendix F.1.
F.2 Networked data
Alongside fig. 2, Figure 7 and table 2 present empirical results for the top five popular artists in the
dataset, excluding Lady Gaga, who are Britney Spears, Rihanna, The Beatles, and Katy Perry. All
these settings show similar results. However, the Beatles’ data is less conclusive as the payment
distribution under the uninformed strategy profile is close to the truth-telling. This observation is
23Figure 4: ECDF comparisons on all users without any selection.
also documented in Daskalakis et al. [12] which notes that the Ising model performs much better for
rock artists than for pop artists. The authors conjecture that this may be due to the highly divisive
popularity of pop artists like Lady Gaga and Britney Spears, whose listeners may form dense cliques
within the graph.
Note that there is a buck of agent with a payment of around 0.5under the truth-telling. This is because
many non-listeners have no listener friends, and payment is 1−[(1−𝑝)−𝑝]=2𝑝is twice the
popularity𝑝≈0.25. Moreover, the jump is most minor for the Beatles, and indicates less agreement
between non-listeners. Additionally, by the definition of bonus-penalty payment, we can see the
payment of deviation is the minus of the truthful payment, so that the ECDF is symmetric around
(0,0.5).
Artists Fraction of listener Average utility Fraction of positive utility
Lady Gaga 32.2% 0 .37 76%
Britney Spears 27.6% 0 .420 82 .6%
Rihanna 25.6% 0 .422 83 .4%
The Beatles 25.4% 0 .137 68 .5%
Katy Perry 25.0% 0 .361 79 .9%
Table 2: Summary of truth-telling utility in appendix F.2.
Figure 8 further shows the scatter plot of average payment and fraction of agents with positive
payments across the top fifty popular artists where all settings have more than 60% percent of agents
get positive payment. However, for less popular artists, the performance of our mechanism declines.
This is expected, as we cannot provide effective incentives when only one agent listens to an artist.
24Figure 5: In each of the rows, we present the ECDF comparisons after changing the selection criteria
for the user group as follows: from female to male, from ages 30–49 to ages 5–29, from ages 30–49
to ages 50+, respectively.
25Figure 6: In each of the rows, we present the ECDF comparisons after changing the location criteria
for the user group as follows: from mostly living in Kanto or Shizuoka to Tohoku until age 15, and
from mostly living in Kanto or Shizuoka to Hokuriku until age 15, respectively.
26Figure 7: Last.fm dataset for other top five popular artists excluding Lady Gaga.
27Figure 8: Average payment and fraction of positive payment under the truth-telling across top fifty
popular artists.
28NeurIPS Paper Checklist
The checklist is designed to encourage best practices for responsible machine learning research,
addressing issues of reproducibility, transparency, research ethics, and societal impact. Do not remove
the checklist: The papers not including the checklist will be desk rejected. The checklist should
follow the references and follow the (optional) supplemental material. The checklist does NOT count
towards the page limit.
Please read the checklist guidelines carefully for information on how to answer these questions. For
each question in the checklist:
• You should answer [Yes] , [No] , or [NA] .
•[NA] means either that the question is Not Applicable for that particular paper or the
relevant information is Not Available.
• Please provide a short (1–2 sentence) justification right after your answer (even for NA).
The checklist answers are an integral part of your paper submission. They are visible to the
reviewers, area chairs, senior area chairs, and ethics reviewers. You will be asked to also include it
(after eventual revisions) with the final version of your paper, and its final version will be published
with the paper.
The reviewers of your paper will be asked to use the checklist as one of the factors in their evaluation.
While "[Yes] " is generally preferable to "[No] ", it is perfectly acceptable to answer "[No] " provided a
proper justification is given (e.g., "error bars are not reported because it would be too computationally
expensive" or "we were unable to find the license for the dataset we used"). In general, answering
"[No] " or "[NA] " is not grounds for rejection. While the questions are phrased in a binary way, we
acknowledge that the true answer is often more nuanced, so please just use your best judgment and
write a justification to elaborate. All supporting evidence can appear either in the main paper or the
supplemental material, provided in appendix. If you answer [Yes] to a question, in the justification
please point to the section(s) where related material for the question can be found.
IMPORTANT, please:
•Delete this instruction block, but keep the section heading “NeurIPS paper checklist" ,
•Keep the checklist subsection headings, questions/answers and guidelines below.
•Do not modify the questions and only use the provided macros for your answers .
1.Claims
Question: Do the main claims made in the abstract and introduction accurately reflect the
paper’s contributions and scope?
Answer: [Yes]
Justification: Our claims accurately reflect the contributions and scope of the paper.
Guidelines:
•The answer NA means that the abstract and introduction do not include the claims
made in the paper.
•The abstract and/or introduction should clearly state the claims made, including the
contributions made in the paper and important assumptions and limitations. A No or
NA answer to this question will not be perceived well by the reviewers.
•The claims made should match theoretical and experimental results, and reflect how
much the results can be expected to generalize to other settings.
•It is fine to include aspirational goals as motivation as long as it is clear that these goals
are not attained by the paper.
2.Limitations
Question: Does the paper discuss the limitations of the work performed by the authors?
Answer: [Yes]
Justification: In section 7, we discuss potential future research directions, which are the
limitations of our current work.
29Guidelines:
•The answer NA means that the paper has no limitation while the answer No means that
the paper has limitations, but those are not discussed in the paper.
• The authors are encouraged to create a separate "Limitations" section in their paper.
•The paper should point out any strong assumptions and how robust the results are to
violations of these assumptions (e.g., independence assumptions, noiseless settings,
model well-specification, asymptotic approximations only holding locally). The authors
should reflect on how these assumptions might be violated in practice and what the
implications would be.
•The authors should reflect on the scope of the claims made, e.g., if the approach was
only tested on a few datasets or with a few runs. In general, empirical results often
depend on implicit assumptions, which should be articulated.
•The authors should reflect on the factors that influence the performance of the approach.
For example, a facial recognition algorithm may perform poorly when image resolution
is low or images are taken in low lighting. Or a speech-to-text system might not be
used reliably to provide closed captions for online lectures because it fails to handle
technical jargon.
•The authors should discuss the computational efficiency of the proposed algorithms
and how they scale with dataset size.
•If applicable, the authors should discuss possible limitations of their approach to
address problems of privacy and fairness.
•While the authors might fear that complete honesty about limitations might be used by
reviewers as grounds for rejection, a worse outcome might be that reviewers discover
limitations that aren’t acknowledged in the paper. The authors should use their best
judgment and recognize that individual actions in favor of transparency play an impor-
tant role in developing norms that preserve the integrity of the community. Reviewers
will be specifically instructed to not penalize honesty concerning limitations.
3.Theory Assumptions and Proofs
Question: For each theoretical result, does the paper provide the full set of assumptions and
a complete (and correct) proof?
Answer: [Yes]
Justification: We present all the assumptions. The complete proofs are provided in the
appendix.
Guidelines:
• The answer NA means that the paper does not include theoretical results.
•All the theorems, formulas, and proofs in the paper should be numbered and cross-
referenced.
•All assumptions should be clearly stated or referenced in the statement of any theorems.
•The proofs can either appear in the main paper or the supplemental material, but if
they appear in the supplemental material, the authors are encouraged to provide a short
proof sketch to provide intuition.
•Inversely, any informal proof provided in the core of the paper should be complemented
by formal proofs provided in appendix or supplemental material.
• Theorems and Lemmas that the proof relies upon should be properly referenced.
4.Experimental Result Reproducibility
Question: Does the paper fully disclose all the information needed to reproduce the main ex-
perimental results of the paper to the extent that it affects the main claims and/or conclusions
of the paper (regardless of whether the code and data are provided or not)?
Answer: [Yes]
Justification: The code is uploaded in the supplementary material. All the information
required to reproduce the experimental results is provided.
Guidelines:
• The answer NA means that the paper does not include experiments.
30•If the paper includes experiments, a No answer to this question will not be perceived
well by the reviewers: Making the paper reproducible is important, regardless of
whether the code and data are provided or not.
•If the contribution is a dataset and/or model, the authors should describe the steps taken
to make their results reproducible or verifiable.
•Depending on the contribution, reproducibility can be accomplished in various ways.
For example, if the contribution is a novel architecture, describing the architecture fully
might suffice, or if the contribution is a specific model and empirical evaluation, it may
be necessary to either make it possible for others to replicate the model with the same
dataset, or provide access to the model. In general. releasing code and data is often
one good way to accomplish this, but reproducibility can also be provided via detailed
instructions for how to replicate the results, access to a hosted model (e.g., in the case
of a large language model), releasing of a model checkpoint, or other means that are
appropriate to the research performed.
•While NeurIPS does not require releasing code, the conference does require all submis-
sions to provide some reasonable avenue for reproducibility, which may depend on the
nature of the contribution. For example
(a)If the contribution is primarily a new algorithm, the paper should make it clear how
to reproduce that algorithm.
(b)If the contribution is primarily a new model architecture, the paper should describe
the architecture clearly and fully.
(c)If the contribution is a new model (e.g., a large language model), then there should
either be a way to access this model for reproducing the results or a way to reproduce
the model (e.g., with an open-source dataset or instructions for how to construct
the dataset).
(d)We recognize that reproducibility may be tricky in some cases, in which case
authors are welcome to describe the particular way they provide for reproducibility.
In the case of closed-source models, it may be that access to the model is limited in
some way (e.g., to registered users), but it should be possible for other researchers
to have some path to reproducing or verifying the results.
5.Open access to data and code
Question: Does the paper provide open access to the data and code, with sufficient instruc-
tions to faithfully reproduce the main experimental results, as described in supplemental
material?
Answer: [Yes]
Justification: The code is uploaded in the supplementary material.
Guidelines:
• The answer NA means that paper does not include experiments requiring code.
•Please see the NeurIPS code and data submission guidelines ( https://nips.cc/
public/guides/CodeSubmissionPolicy ) for more details.
•While we encourage the release of code and data, we understand that this might not be
possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not
including code, unless this is central to the contribution (e.g., for a new open-source
benchmark).
•The instructions should contain the exact command and environment needed to run to
reproduce the results. See the NeurIPS code and data submission guidelines ( https:
//nips.cc/public/guides/CodeSubmissionPolicy ) for more details.
•The authors should provide instructions on data access and preparation, including how
to access the raw data, preprocessed data, intermediate data, and generated data, etc.
•The authors should provide scripts to reproduce all experimental results for the new
proposed method and baselines. If only a subset of experiments are reproducible, they
should state which ones are omitted from the script and why.
•At submission time, to preserve anonymity, the authors should release anonymized
versions (if applicable).
31•Providing as much information as possible in supplemental material (appended to the
paper) is recommended, but including URLs to data and code is permitted.
6.Experimental Setting/Details
Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
results?
Answer: [Yes]
Justification: Most of these details are explained in section 6 and in the provided code.
Guidelines:
• The answer NA means that the paper does not include experiments.
•The experimental setting should be presented in the core of the paper to a level of detail
that is necessary to appreciate the results and make sense of them.
•The full details can be provided either with the code, in appendix, or as supplemental
material.
7.Experiment Statistical Significance
Question: Does the paper report error bars suitably and correctly defined or other appropriate
information about the statistical significance of the experiments?
Answer: [No]
Justification: We believe the error bars are not relevant to our empirical metrics.
Guidelines:
• The answer NA means that the paper does not include experiments.
•The authors should answer "Yes" if the results are accompanied by error bars, confi-
dence intervals, or statistical significance tests, at least for the experiments that support
the main claims of the paper.
•The factors of variability that the error bars are capturing should be clearly stated (for
example, train/test split, initialization, random drawing of some parameter, or overall
run with given experimental conditions).
•The method for calculating the error bars should be explained (closed form formula,
call to a library function, bootstrap, etc.)
• The assumptions made should be given (e.g., Normally distributed errors).
•It should be clear whether the error bar is the standard deviation or the standard error
of the mean.
•It is OK to report 1-sigma error bars, but one should state it. The authors should
preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis
of Normality of errors is not verified.
•For asymmetric distributions, the authors should be careful not to show in tables or
figures symmetric error bars that would yield results that are out of range (e.g. negative
error rates).
•If error bars are reported in tables or plots, The authors should explain in the text how
they were calculated and reference the corresponding figures or tables in the text.
8.Experiments Compute Resources
Question: For each experiment, does the paper provide sufficient information on the com-
puter resources (type of compute workers, memory, time of execution) needed to reproduce
the experiments?
Answer: [Yes]
Justification: We believe the computer resources are not relevant to our main contributions.
Guidelines:
• The answer NA means that the paper does not include experiments.
•The paper should indicate the type of compute workers CPU or GPU, internal cluster,
or cloud provider, including relevant memory and storage.
32•The paper should provide the amount of compute required for each of the individual
experimental runs as well as estimate the total compute.
•The paper should disclose whether the full research project required more compute
than the experiments reported in the paper (e.g., preliminary or failed experiments that
didn’t make it into the paper).
9.Code Of Ethics
Question: Does the research conducted in the paper conform, in every respect, with the
NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines ?
Answer: [Yes]
Justification: The research conducted in our paper conforms with the NeurIPS Code of
Ethics.
Guidelines:
•The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
•If the authors answer No, they should explain the special circumstances that require a
deviation from the Code of Ethics.
•The authors should make sure to preserve anonymity (e.g., if there is a special consid-
eration due to laws or regulations in their jurisdiction).
10.Broader Impacts
Question: Does the paper discuss both potential positive societal impacts and negative
societal impacts of the work performed?
Answer: [Yes]
Justification: Our work contributes to the theory of information elicitation. We discussed
the applicability and limitations for elicitation settings.
Guidelines:
• The answer NA means that there is no societal impact of the work performed.
•If the authors answer NA or No, they should explain why their work has no societal
impact or why the paper does not address societal impact.
•Examples of negative societal impacts include potential malicious or unintended uses
(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
(e.g., deployment of technologies that could make decisions that unfairly impact specific
groups), privacy considerations, and security considerations.
•The conference expects that many papers will be foundational research and not tied
to particular applications, let alone deployments. However, if there is a direct path to
any negative applications, the authors should point it out. For example, it is legitimate
to point out that an improvement in the quality of generative models could be used to
generate deepfakes for disinformation. On the other hand, it is not needed to point out
that a generic algorithm for optimizing neural networks could enable people to train
models that generate Deepfakes faster.
•The authors should consider possible harms that could arise when the technology is
being used as intended and functioning correctly, harms that could arise when the
technology is being used as intended but gives incorrect results, and harms following
from (intentional or unintentional) misuse of the technology.
•If there are negative societal impacts, the authors could also discuss possible mitigation
strategies (e.g., gated release of models, providing defenses in addition to attacks,
mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
feedback over time, improving the efficiency and accessibility of ML).
11.Safeguards
Question: Does the paper describe safeguards that have been put in place for responsible
release of data or models that have a high risk for misuse (e.g., pretrained language models,
image generators, or scraped datasets)?
Answer: [NA]
Justification: We believe this paper poses no such risks.
33Guidelines:
• The answer NA means that the paper poses no such risks.
•Released models that have a high risk for misuse or dual-use should be released with
necessary safeguards to allow for controlled use of the model, for example by requiring
that users adhere to usage guidelines or restrictions to access the model or implementing
safety filters.
•Datasets that have been scraped from the Internet could pose safety risks. The authors
should describe how they avoided releasing unsafe images.
•We recognize that providing effective safeguards is challenging, and many papers do
not require this, but we encourage authors to take this into account and make a best
faith effort.
12.Licenses for existing assets
Question: Are the creators or original owners of assets (e.g., code, data, models), used in
the paper, properly credited and are the license and terms of use explicitly mentioned and
properly respected?
Answer: [Yes]
Justification: The datasets used in this paper are mentioned with URLs and the licenses and
terms of use are properly respected.
Guidelines:
• The answer NA means that the paper does not use existing assets.
• The authors should cite the original paper that produced the code package or dataset.
•The authors should state which version of the asset is used and, if possible, include a
URL.
• The name of the license (e.g., CC-BY 4.0) should be included for each asset.
•For scraped data from a particular source (e.g., website), the copyright and terms of
service of that source should be provided.
•If assets are released, the license, copyright information, and terms of use in the
package should be provided. For popular datasets, paperswithcode.com/datasets
has curated licenses for some datasets. Their licensing guide can help determine the
license of a dataset.
•For existing datasets that are re-packaged, both the original license and the license of
the derived asset (if it has changed) should be provided.
•If this information is not available online, the authors are encouraged to reach out to
the asset’s creators.
13.New Assets
Question: Are new assets introduced in the paper well documented and is the documentation
provided alongside the assets?
Answer: [NA]
Justification: The paper does not release new assets.
Guidelines:
• The answer NA means that the paper does not release new assets.
•Researchers should communicate the details of the dataset/code/model as part of their
submissions via structured templates. This includes details about training, license,
limitations, etc.
•The paper should discuss whether and how consent was obtained from people whose
asset is used.
•At submission time, remember to anonymize your assets (if applicable). You can either
create an anonymized URL or include an anonymized zip file.
14.Crowdsourcing and Research with Human Subjects
Question: For crowdsourcing experiments and research with human subjects, does the paper
include the full text of instructions given to participants and screenshots, if applicable, as
well as details about compensation (if any)?
34Answer: [NA]
Justification: The paper does not involve crowdsourcing or research with human subjects.
Guidelines:
•The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
•Including this information in the supplemental material is fine, but if the main contribu-
tion of the paper involves human subjects, then as much detail as possible should be
included in the main paper.
•According to the NeurIPS Code of Ethics, workers involved in data collection, curation,
or other labor should be paid at least the minimum wage in the country of the data
collector.
15.Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
Subjects
Question: Does the paper describe potential risks incurred by study participants, whether
such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
approvals (or an equivalent approval/review based on the requirements of your country or
institution) were obtained?
Answer: [NA]
Justification: The paper does not involve crowdsourcing or research with human subjects.
Guidelines:
•The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
•Depending on the country in which research is conducted, IRB approval (or equivalent)
may be required for any human subjects research. If you obtained IRB approval, you
should clearly state this in the paper.
•We recognize that the procedures for this may vary significantly between institutions
and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
guidelines for their institution.
•For initial submissions, do not include any information that would break anonymity (if
applicable), such as the institution conducting the review.
35