Unified Mechanism-Specific Amplification by
Subsampling and Group Privacy Amplification
Jan Schuchardt1, Mihail Stoian2∗, Arthur Kosmala1∗, Stephan Günnemann1
{j.schuchardt, a.kosmala, s.guennemann}@tum.de, mihail.stoian@utn.de
1Dept. of Computer Science & Munich Data Science Institute, Technical University of Munich
2Dept. of Engineering, University of Technology Nuremberg
Abstract
Amplification by subsampling is one of the main primitives in machine learning
with differential privacy (DP): Training a model on random batches instead of
complete datasets results in stronger privacy. This is traditionally formalized via
mechanism-agnostic subsampling guarantees that express the privacy parameters
of a subsampled mechanism as a function of the original mechanism’s privacy
parameters. We propose the first general framework for deriving mechanism-
specific guarantees, which leverage additional information beyond these parameters
to more tightly characterize the subsampled mechanism’s privacy. Such guarantees
are of particular importance for privacy accounting , i.e., tracking privacy over
multiple iterations. Overall, our framework based on conditional optimal transport
lets us derive existing and novel guarantees for approximate DP, accounting with
Rényi DP, and accounting with dominating pairs in a unified, principled manner.
As an application, we analyze how subsampling affects the privacy of groups of
multiple users. Our tight mechanism-specific bounds outperform tight mechanism-
agnostic bounds and classic group privacy results.
1 Introduction
Composability and amplification by subsampling are two key properties of Differential Privacy
(DP) [ 1–3] that make it possible to provide provable privacy guarantees for machine learning
algorithms that iteratively learn from batches of data.
Composability means that privacy gracefully deteriorates when iteratively applying a differentially
private mechanism to a dataset [ 2]. Kairouz et al. [4], Murtagh and Vadhan [5]ultimately derived
tight composition theorems that optimally characterize the privacy parameters (ε′, δ′)of a composed
mechanism as a function of the component mechanisms’ parameters (ε, δ). However, later work
demonstrated that these guarantees are only tight in a mechanism-agnostic sense [ 6]. Stronger
mechanism-specific composition guarantees can often be obtained by using additional information
beyond the fact that the mechanisms satisfies some notion of DP. Methods for tracking privacy over
multiple iterations (e.g. [6–12]) are refererred to as privacy accountants .
Amplification by subsampling means that privacy can be strenghtened by applying a differentially
private mechanism to randomly sampled batches of a dataset [ 13,14]. Similar to Kairouz et al.
[4], Balle et al. [15] ultimately proposed a framework for deriving tight subsampling theorems that
optimally characterize the privacy parameters (ε′, δ′)of a subsampled mechanism as a function of
the underlying base mechanism ’s parameters (ε, δ).
However, their framework for deriving subsampling theorems has two key limitations. Firstly, as
we shall demonstrate, the resultant guarantees are generally only tight in a mechanism-agnostic
∗Equal contribution
38th Conference on Neural Information Processing Systems (NeurIPS 2024).sense: Given (ε, δ), one can construct some worst-case (ε, δ)-DP mechanism that is (ε′, δ′)-DP under
subsampling. The specific mechanism at hand may however be significantly more private. Secondly,
their framework does not explain how to derive subsampling guarantees for privacy accountants. In
fact, there is so far no unified framework for deriving subsampling guarantees for privacy accountants.
To address these two limitations, we propose a novel framework for unified mechanism-specific
amplification by subsampling analysis, using conditional optimal transport. Our proposed framework
(1) lets us derive mechanism-specific subsampling guarantees, which can be stronger than mechanism-
agnostic guarantees, (2) lets us recover mechanism-agnostic guarantees via a pessimistic upper bound
– essentially subsuming the approach from [ 15] – and (3) lets us derive guarantees for approximate
differential privacy [ 2], moments accounting [ 6] (i.e., Rényi differential privacy [ 7]), and accounting
with dominating pairs [ 10] (e.g., numerical accounting [ 16,8,17–21]) in a unified, principled manner.
��� 𝑥𝑥1𝑥𝑥2 𝑥𝑥𝑁𝑁𝑥𝑥𝑥1𝑥𝑥𝑥2
Base mechanism 𝐵𝐵Subsampling scheme 𝑆𝑆
𝑥𝑥1𝑥𝑥2𝑥𝑥6
𝑥𝑥2𝑥𝑥10𝑥𝑥6𝑥𝑥5𝑥𝑥5𝑥𝑥9𝑥𝑥𝑥1
𝑥𝑥7𝑥𝑥10𝑥𝑥9𝑥𝑥𝑥2𝑥𝑥9𝑥𝑥𝑥1𝑥𝑥𝑥2
𝑥𝑥17𝑥𝑥25𝑥𝑥𝑥1𝑥𝑥𝑥2Pr=(1−𝑟𝑟)2Pr=2𝑟𝑟(1−𝑟𝑟) Pr=𝑟𝑟2
��� ��� ���𝑥𝑥𝑥3
Figure 1: Group members x′
1, x′
2contribute to a
dataset, while group member x′
3does not. For
small subsampling rates r, it is unlikely to access a
single ( Pr = 2 r(1−r)) or even both ( Pr = r2) in-
serted elements when applying a base mechanism
Bto a subsampled batch (e.g., the yellow one).
This further obfuscates which data was contributed
by members of group {x′
1, x′
2, x′
3}.As a practical application, we consider the prob-
lem of tightly analyzing group privacy under
subsampling (see Fig. 1). Assume a scenario
where Kindividuals may independently decide
to contribute to a dataset. Further assume that
this dataset is processed by randomly sampling
a batch and applying an (ε, δ)-DPbase mecha-
nism . A special case of this setting is discussed
in a recent technical note [ 22], which assumes
that the Kindividuals collaboratively agree to
either contribute or not contribute all their data
and that the base mechanism is Gaussian. In
the general setting we consider, the best known
method for providing privacy guarantees for the
entire group is to (1) use existing bounds to
show that the subsampled mechanism guaran-
tees(ε′, δ′)-DP for individuals and (2) use the
group privacy property[ 23] to show that this im-
plies(K·ε′, K·eK·ε′·δ′)-DP for the group.
Our proposed framework lets us derive stronger, tight group privacy amplification guarantees. By
analyzing group privacy and subsampling jointly, these guarantees accurately capture that it is unlikely
for a large fraction of the group’s data to simultaneously appear in a batch. Our framework further
lets us derive dominating pairs [ 10], which enables tight tracking of group privacy under composition.
Overall, our main contributions are that we
•demonstrate for the first time that there is a qualitative difference between mechanism-
specific and mechanism-agnostic tightness in privacy amplification,
•propose a general framework for deriving mechanism-specific amplification by subsampling
guarantees, subsuming prior work on mechanism-agnostic amplification,
•develop the first unified method for deriving subsampling guarantees for privacy accounting,
• and derive the first tight subsampling guarantees for general group privacy.
As part of our group privacy analysis, we also significantly generalize recent results derived for
subsampled matrix mechanisms [ 24], which is of independent interest. Experimental evaluation
demonstrates that our tight mechanism-specific guarantees outperform both tight mechanism-agnostic
bounds and post-hoc use of the group privacy property.
2 Background and preliminaries
Problem setting. We consider the same setting as Balle et al. [15], but with an additional privacy
accounting and group privacy perspective. We assume a space of datasets X, a space of batches
Ythat can be constructed from these datasets, and an output space Z. For the sake of exposition,
we assume that Xis the powerset P(A)of some finite discrete set A, thatY={y⊆x|x∈X},
and that Z=RD. We further consider a random subsampling scheme S:X→Ythat generates
batches from datasets, and a random base mechanism B:Y→RDthat maps batches to outputs.
We write sx(y)for the pmf of S(X)andby(z)for the pdf of B(y). In Appendix D, we introduce a
more general setting that admits arbitrary spaces, for which we derive all our results. Our goal is to
2provide formal privacy guarantees for the subsampled mechanism M=B◦S, which takes a dataset,
subsamples a batch from it, and then applies the random base mechanism to this batch.
Dataset and batch relations. Specifically, we want to prove privacy under neighboring relations
≃X⊆X2between datasets. For example, the insertion/removal relation x≃±,Xx′implies that
x′=x∪ {a}orx′=x\ {a}for some a. The substitution relation x≃∆,Xx′implies that
x′=x\ {a} ∪ { a′}for some a, a′. In addition, we assume that Yis equipped with a batch
neighboring relation ≃Y⊆Y2. The batch relation ≃Ycan be distinct from the dataset relation ≃X.
Subsampling schemes. While we consider arbitrary subsampling schemes S:X→Y, we shall
later apply our framework to three particularly common ones: Subsampling without replacement
andwith replacement sample sets and multisets of fixed size |y|=quniformly at random. Poisson
subsampling includes each element of xwith independent probability (“rate”) r∈[0,1].
Approximate differential privacy. A mechanism M:X→RDis privacy-preserving under
symmetric neighboring relation ≃Xwhen the distributions of M(x), M(x′)with densities mx, m′
x
are almost indistinguishable for all x≃Xx′. Approximate differential privacy (ADP) [ 2] quantifies
this via hockey stick divergences [25]:
Definition 2.1. Forε≥0, a mechanism M:X→RDis(ε, δ)-DP under symmetric relation ≃Xiff
∀x≃Xx′:Heε(mx||mx′)≤δwithHα(mx||mx′) =R
RDmax{mx(z)/mx′(z)−α,0}·mx′(z) dz.
Note that this divergence-based definition of approximate differential privacy is equivalent to requiring
for all datasets x≃Xx′and all events S⊆RDthatPr[M(x)∈S]≤eε·Pr[M(x′)∈S] +δ.
Rényi differential privacy. Privacy accounting was first popularized by methods that used moment
bounds instead of (ε, δ)pairs to better track privacy under composition [ 6,26,27]. These methods
were later developed into a moments-based notion of privacy – Rényi differential privacy (RDP) [ 7]:
Definition 2.2. Forα≥1, a mechanism M:X→RDis(α, ρ)-RDP under symmetric relation ≃X
iff∀x≃Xx′: log(Λ α(mx||mx′))/(α−1)≤ρwithΛα(mx||mx′) =R
RDmx(z)α·mx′(z)1−αdz.
Note that Λαis not the Rényi divergence, but its αth moment, i.e., a scaled and exponentiated Rényi
divergence. We use this notation to eliminate exponential terms that arise in amplification for RDP
(see [ 28–30]). If a mechanism is (α, ρ)-RDP, its T-fold self-composition is (α, T·ρ)-RDP. These
RDP parameters can then be converted to ADP parameters ( ε, δ), albeit in a lossy manner [ 7,31,32].
Dominating pairs. Later work proposed other numerical [ 16,8,17–21] or analytical accounting
techniques [ 9,33,28,34,35]. Zhu et al. [10] developed a unified view on these works by introducing
the notion of dominating pairs :
Definition 2.3. A pair of distributions (P, Q)with densities (p, q)is a dominating pair for mechanism
Munder neighboring relation ≃X, ifHα(mx||mx′)≤Hα(p||q)for all x≃Xx′and all α≥0.
Given a dominating pair (P, Q), one can use various numerical or analytic techniques, such as
convolution of privacy loss distributions [ 16] or central limit theorems of tradeoff functions [ 9], to
track the privacy of mechanism Munder composition (see Fig. 2 in [10]).
Group privacy. The group privacy property is the graceful decay of privacy when considering
multiple user’s data. This is normally formalized via the notion of induced distance (see [ 7,15,23]):
Definition 2.4. The distance dX(x, x′)induced by relation ≃Xis the length of the shortest sequence
(x1, . . . , x K−1)∈XK−1such that x≃Xx1,∀k:xk≃Xxk+1, and xK−1≃Xx′.
Example 2.5.Let≃Xbe the insertion/removal relation ≃±. Then the induced distance dXbetween
x={1,2}andx′={2,3}is2, because {1,2} ≃±{1,2,3} ≃±{2,3}.
Proposition 2.6 (Vadhan [23]).If mechanism M:X→RDis(ε, δ)-DP under relation ≃X, then it
is(K·ε, K·eK·ε·δ)-DP under group relation {(x, x′)∈X2|dX(x, x′) =K}.
That is, for sufficiently small εthe ADP parameters deteriorate appproximately linearly with induced
distance. As baselines for our experiments, we use even tighter bounds (see Appendix C.1.4).
3 Unified mechanism-specific amplification by subsampling
Our goal is to develop a general procedure for (tightly) deriving ADP parameters (ε′, δ′), RDP
parameters (α′, ρ′), or dominating pairs (P′, Q′)for the subsampled mechanism M=B◦Swith
3subsampling scheme Sand base mechanism B. Based on Definitions 2.1 to 2.3, this requires that we
evaluate or bound the hockey stick divergence Hαor the scaled and exponentiated Rényi divergence
Λαbetween the distributions of M(x)andM(x′)withx≃Xx′. To discuss both simultaneously, let
us write Ψαfor either HαorΛαand assume that α≥0orα≥1, respectively.
There are two challenges: Firstly, the distribution of M(x)is high-dimensional mixture distribution
with one component per possible batch y∈Yand weights given by batch probabilitites sx(y), i.e.,
mx(z) =P
y∈Yby(z)·sx(y).Secondly, there may be no simple analytic formula for the component
densities. For instance, evaluating the density of perturbed model gradients in noisy SGD [ 36]
requires backpropagation. Both challenges make it hard to evaluate or bound Ψα(mx||mx′).
A useful property that will help us in addressing the first problem of having a large number of mixture
components is the joint convexity of Ψαin the space of probability density functions [37, 38]:
Lemma 3.1. Consider arbitrary densities f(1)
1, f(1)
2, f(2)
1, f(2)
2:RD→R+and weight w∈[0,1].
Then, Ψα(wf(1)
1+(1−w)f(1)
2||wf(2)
1+(1−w)f(2)
2)≤wΨα(f(1)
1||f(2)
1)+(1−w)Ψα(f(1)
2||f(2)
2).
In our case, the fs can be base mechanism densities bywith different y∈Y, and the weights
can be given by the subsampling distribution. We could thus upper-bound the mixture divergence
Ψα(mx||mx′)in terms of component divergences – if the mixtures had identical weights. This is
generally not the case, since subsampling mass functions sx(·)andsx′(·)depend on datasets x̸=x′.
To still leverage the joint convexity of Ψα(mx||mx′), we want to rewrite mxandmx′as mixtures with
identical weights. This is exactly what is offered by couplings between probability mass functions.
Intuitively, a coupling between two pmfs p1, p2:Y→[0,1]specifies for every y1, y2∈Yhow much
probability should be transported from y1toy2to transform p1intop2. Couplings can be formalized
and generalized to multiple pmfs as follows (for a more thorough introduction, see [39]):
Definition 3.2. A coupling between Npmfs p1, . . . , p N:Y→[0,1]on batch space Yis a joint pmf
γ:YN→[0,1]where the nth marginal is pn, i.e., pn(y∗
n) =P
y∈YN 1[yn=y∗
n]·γ(y).
Given a valid coupling γbetween subsampling mass functions sxandsx′, we can use marginalization
to rewrite mx(z)asP
y∈Y2by1(z)γ(y). Similarly, we can rewrite mx′(z)asP
y∈Y2by2(z)γ(y).
Now, both mxandmx′are mixtures with identical weights and one component per pair of batches in
Y2. We can thus recursively apply Lemma 3.1 to show (full proof in Appendix E):
Theorem 3.3. Consider a subsampled mechanism M=B◦S, and an arbitrary coupling γbetween
subsampling mass functions sx(·)andsx′(·). Then,
Ψα(mx||mx′)≤X
y∈Y2cα(y(1), y(2))·γ(y(1), y(2)) (1)
with cost function cα:Y×Y→R+defined by cα(y(1), y(2)) = Ψ α(by(1)||by(2)).
We write y(1)instead of y1to simplify later notations. While every coupling γyields a valid upper
bound, the guarantees can be tightened by finding a coupling γ∗that minimizes the r.h.s. of Eq. (1).
We thus have an optimal transport problem , where the cost cαof transporting probability from batch
y(1)to batch y(2)depends on the divergence Ψαof base mechanism densities by(1)andby(2).
Unfortunately, experimental evaluation in Appendix B.1.4 shows that the resultant guarantees can be
much weaker than those from prior work – even with an optimal coupling γ∗. This is because Theo-
rem 3.3 results from recursively applying the joint convexity property (Lemma 3.1) to Ψα(mx||mx′).
Each recursive step splits each mixture into two smaller mixtures and further upper-bounds the
divergence that is achieved by our specific subsampled mechanism Mon our specific pair of datasets
x, x′. Upon fully decomposing the overall divergence into divergences between single-mixture com-
ponents, this sequence of bounds is in fact larger than even the divergence Ψα( ˜m˜x||˜m˜x′)achieved
bya worst-case subsampled mechanism ˜Mon a worst-case pair of datasets ˜x,˜x′. To overcome
this limitation, we propose to limit the recursion depth in order to obtain a tighter upper bound that
matches our specific subsampled mechanism Mon a worst-case pair of datasets ˆx,ˆx′.
Limiting the recursion depth to which Lemma 3.1 is applied means upper-bounding Ψα(mx||mx′)
in terms of mixture divergences that have not been fully decomposed into their individual compo-
nents. Specifically, we propose to do so by defining an optimal transport problem between multiple
subsampling mass functions conditioned on different events (proof in Appendix E):
4Theorem 3.4. Consider a subsampled mechanism M=B◦S. Further consider two disjoint
partitioningsSI
i=1Ai=YandSJ
j=1Ej=Yof batch space Ysuch that all AiandEjhave
non-zero probability under the distribution of SxandSx′, respectively. Let γbe an arbitrary coupling
between conditional mass functions sx(· |A1), . . . , s x(· |AI), sx′(· |E1), . . . , s x′(· |EJ). Then,
Ψα(mx||mx′)≤X
y∈YI+Jcα(y(1),y(2))·γ((y(1),y(2))),
with cost function cα:YI×YJ→R+defined by
cα(y(1),y(2)) = Ψ α
IX
i=1by(1)
i·Pr[S(x)∈Ai]||JX
j=1by(2)
j·Pr[S(x′)∈Ej]
. (2)
In other words: We now have an optimal transport problem between I+Jprobability mass functions
coupled by γ. The transport cost cαis a divergence between two mixtures. The components of the
first mixture are base mechanisms densities given batches y(1)
i∈Yfrom batch tuple y(1)∈YI. The
weights of the first mixture are probabilities of events Ai. The second mixture is defined analogously.
Note that we can recover Theorem 3.3 by conditioning on a single event, i.e., A1=Y, E1=Y. As
we shall demonstrate, a more fine-grained partitioning lets us obtain tighter bounds that match the
divergence Ψα(m˜x||m˜x′)of our specific subsampled mechanism Mon a worst-case pair of datasets
ˆx,ˆx′. In the extreme case of defining event per possible batch, Theorem 3.4 holds with equality.
Overall, Theorem 3.4 reduces the broad problem of bounding mixture divergences to the canonical
problem of optimal transport between conditional distributions. But before we can apply it, we need
to address two open problems: Evaluating the cost function and designing optimal couplings.
Cost function bound. Not having an analytic expression for every base mechanism density by(z)
may make it intractable to evaluate cost function cα. We thus propose to bound it via an approach
that is inherent to differential privacy: Considering worst-case inputs (proof in Appendix E).
Proposition 3.5. Consider y(1)∈YI,y(2)∈YJ, and cost function cdefined in Eq. (2). LetdYbe
the distance induced by ≃Y(see Definition 2.4). Then, cα(y(1),y(2))≤ˆcα(y(1),y(2)), with
ˆcα(y(1),y(2)) = max
ˆy(1),ˆy(2)cα(ˆy(1),ˆy(2)) (3)
subject to ∀k, l∈ {1,2},∀t, u:dY(ˆy(k)
t,ˆy(l)
u)≤dY(y(k)
t, y(l)
u)andˆy(1)∈YI,ˆy(2)∈YJ.
Put differently: We construct two new mixtures with components that are adversarially chosen to
maximize divergence while retaining the pairwise distances between batches in y(1)andy(2). Note
that, for the special case of Ψα=HαandI=J= 1, this bound corresponds to the “group privacy
profile” in [ 15]. As we shall demonstrate in the next sections, this bound ˆccan often be evaluated
using high-level information about the base mechanism B:Y→RD, such as global sensitivity.
Sufficient optimality condition. While every coupling γyields a valid upper bound in Theorem 3.4,
this bound can be tightened by designing an optimal coupling γ∗. To inform this design, we generalize
the notion of distance-compatible couplings from [15] to an arbitrary number of distributions:
Definition 3.6. A coupling γbetween mass functions p1, . . . , p Non batch space YisdY-compatible
when γ(y)>0only if ∀u >1 :dY(y1, yu) =dY({y1},supp( pu))and∀u > t > 1 :dY(yu, yt) =
dY(supp( pt),supp( pu)), where supp( pu)is the support of suand the distance between two sets is
the minimum distance of their elements.
Essentially, a dY-compatible coupling only assigns probability to a tuple of batches ywhen all pairs
yi, yjhave the smallest possible distance to y1and each other while still being in the support of their
distributions. In Appendix F, we prove that dY-compatibility is sufficient for optimality. We further
show that the optimal value has a canonical form whenever a dY-compatible couplings exists.
Summary. To summarize, we propose the following three-step procedure for deriving subsampling
guarantees: (1) Define two partitions of the batch space into IandJevents. (2) Define a simultaneous
coupling between the corresponding I+Jconditional distributions to obtain a bound in terms of
divergences between small mixtures with IandJcomponents. (3) Bound these mixture divergences
by considering I+Jworst-case mixture components under pairwise batch distance constraints.
53.1 Tight mechanism-specific group privacy amplification
As a concrete example, and to illustrate the difference between mechanism-specific and -agnostic
(see Section 3.2) bounds, let us consider the group privacy setting from Fig. 1. We have a group of
Kusers that can independently decide to contribute or not contribute their data, and the resulting
dataset is Poisson subsampled. To provide formal privacy guarantees to the group, we need to prove
that the distributions of M(x), M(x′)are almost indistinguishable for x, x′with induced distance
d±,X(x, x′)≤K. Letx≃K+,K−,Xx′be the relation that implies that K+records are inserted and
K−records are removed to construct x′from x. We can then show (full proof in Appendix M):
Theorem 3.7. LetM=B◦S, where Sis Poisson subsampling with rate r. Let≃Ybe the
insertion/removal batch relation ≃±,Y. Then, for all x≃K+,K−,Xx′,Ψα(mx||mx′)is l.e.q.
max
yΨα
K−+1X
i=1by(1)
i·Binom( i−1|K−, r)||K++1X
j=1by(2)
j·Binom( j−1|K+, r)
,(4)
subject to constraints y∈YK−+K++2, as well as ∀l∈ {1,2},∀t, u:dY(y(l)
t, y(l)
u)≤ |t−u|, and
∀t, u:dY(y(1)
t, y(2)
u)≤(t−1) + ( u−1).
Proof sketch. We let AiandEjbe the events that S(x)contains i−1deleted elements and S(x′)
contains j−1inserted elements, respectively. Our coupling defines the following generative process:
We sample y(1)
1from sx(· |A1)and let y(2)
1←y(1)
1. We then iteratively generate the other y(1)
iby
sampling a permutation in which we add the K−deleted elements to y(1)
1. We then generate the
other y(2)
jby sampling a permutation in which we add the K+inserted elements to y(2)
1. The result
then follows from the cost function bound in Proposition 3.5 and dY-compatibility of the coupling.
Batches y(1)
uandy(1)
tand have a distance bounded by |u−t|, because one can be obtained from
the other by removing/inserting |u−t|elements. The constraints for y(2)
uandy(2)
tare analogous.
Batches y(1)
uandy(2)
thave a distance bounded by (t−i) + (u−1)because we need to remove t−1
elements and insert u−1elements to construct one from the other.
Next, we can solve the constrained optimization problem in Theorem 3.7 – i.e., determine worst-case
components – to obtain mechanism-specific guarantees. For instance (proof in Appendix M.2.1):
Theorem 3.8. LetM=B◦S, where Sis Poisson subsampling with rate r, and Bis the Gaussian
mechanism h+Vwithh:Y→RDandV∼ N (0, σ2ID). Define the ℓ2-sensitivity L2=
max y≃±,Yy′||f(y)−f(y′)||2. Then for all x≃K+,K−,Xx′,Ψα(mx||mx′)is l.e.q.
Ψα
K−+1X
i=1f(1)
i·Binom( i−1|K−, r)||K++1X
j=1f(2)
j·Binom( j−1|K+, r)
,
with univariate normal densities f(1)
i=N(· |(i−1), σ / L 2),f(2)
j=N(· | −(j−1), σ / L 2).
Note that this bound is mechanism-specific in that it explictly depends on Bbeing a Gaussian
mechanism with standard deviation σand sensitivity L2. The bound can be numerically evaluated to
arbitrary precision using standard techniques from privacy accounting literature (see Appendix M.4).
In Appendix M.2 we derive similar guarantees for Laplace and randomized response mechanisms.
Tightness. These bounds are tight in a mechanism-specific sense: One cannot derive stronger ADP
or RDP guarantees without additional information about the datasets x, x′∈Xor the underlying
function h(proofs in Appendix M.3).
Asymptotic bounds. Our focus is on tight bounds that can be explicitly computed. However, some
early works on RDP accounting (e.g.[ 6,28]) also provided asymptotic versions of their bounds, e.g.,
as a function of divergence parameter α. For completeness, we use Theorem 3.8 to generalize the
asymptotic bounds of Abadi et al. [6] to the group privacy setting in Appendix N.5.
Other contributions. Our solutions to the optimization problem in Theorem 3.7 are of independent
interest: The special case of Ψα=Hα,K−= 0 orK+= 0, and Gaussian mechanisms was
6𝑆𝑆(𝑋𝑋)|𝐴𝐴1𝑆𝑆(𝑋𝑋)|𝐴𝐴2𝑆𝑆(𝑋𝑋𝑋)|𝐸𝐸1𝑆𝑆(𝑋𝑋𝑋)|𝐸𝐸2𝑆𝑆(𝑋𝑋)|𝐴𝐴1, ,𝑆𝑆(𝑋𝑋)|𝐴𝐴𝐼𝐼 ,𝑆𝑆(𝑋𝑋𝑋)|𝐸𝐸𝐽𝐽
OT OT OT��� ���𝑆𝑆(𝑋𝑋𝑋)
𝑆𝑆(𝑋𝑋𝑋)|𝐸𝐸1,𝑆𝑆(𝑋𝑋) 𝑆𝑆(𝑋𝑋𝑋) 𝑆𝑆(𝑋𝑋)𝑆𝑆(𝑋𝑋𝑋)
OT𝑆𝑆(𝑋𝑋𝑋) 𝑆𝑆(𝑋𝑋)
JOINTCONVEXITY𝑆𝑆(𝑋𝑋)|𝐴𝐴1𝑆𝑆(𝑋𝑋)|𝐴𝐴2𝑆𝑆(𝑋𝑋)
JOINTCONVEXITY(a) (b) (c) (d)
Figure 2: Mechanism-agnostic guarantees for (a) graph modification [ 40–42] (b) inser-
tion/removal [ 14,15,29,30] (c) substitution [ 43,44,15,28] can be derived from (d) our proposed
framework. In (b-c), events AiandEjindicate the presence of inserted or substituted elements.
derived to analyze matrix mechanisms in [ 24]. We significantly generalize it via an entirely different
proof strategy that admits Ψα∈ {Hα,Λα}, arbitrary K+, K−∈N0, and non-Gaussian mechanisms
(see Appendix O).
3.2 Tight mechanism-agnostic group privacy amplification
To further illustrate the difference between mechanism-specific and -agnostic bounds, let us apply
the framework of Balle et al. [15] to the same setting: For K−= 0 orK+= 0 andε≥0, their
ansatz shows that the subsampled mechanism M=B◦Sis(ε′, δ′)-DP with ε′= log(1 + (1 −
Binom(0 |K, r))·(eε−1))andδ′=PK
k=1Binom( k|K, r)·δk, with group privacy parameters
δk= max y,y′Hexp(ε)(by||by′)s.t.dY(y, y′)≤k(see Appendix N).
Tightness. This bound is tight in a mechanism-agnostic sense, i.e., for every ε≥0, one can construct
some worst-case mechanism that exactly attains the bound (see Appendix N.2).
Mechanism-specific vs mechanism-agnostic tightness. An apparent advantage of this result is that
it expresses (ε′, δ′)as a simple analytic formula of base mechanism DP parameters ε, δ1, . . . , δ K.
However, this simplicity comes at a cost: As we show in Appendix N.3, this guarantee implicitly
upper-bounds the tight mixture divergence bound from Theorem 3.7 in terms of its component
divergences using joint convexity.2As we experimentally demonstrate in Section 4, this relaxation
leads to weaker privacy guarantees for group size K≥2. This gap has gone unnoticed in earlier work,
because Theorem 3.8 happens to be identical to the bound of Balle et al. [15] for the special case of
K= 1(see proof of Proposition 30 in [ 10]). By studying the more complex group privacy setting,
we demonstrate for the first time that there is a qualitative difference between mechanism-agnostic
and mechanism-specific tightness in privacy amplification .
3.3 From mechanism-specific to mechanism-agnostic guarantees
The observed relation between tight mechanism-specific and mechanism-agnostic bounds does in fact
extend beyond group privacy (see Fig. 2): As we demonstrate in Appendices G and H, mechanism-
agnostic subsampling guarantees from prior work can equivalently be derived by (1) conditioning on
at most 4events indicating the presence of inserted / deleted / substituted elements, (2) defining a
simultaneous coupling, and (3) using joint convexity to upper-bound the resultant mechanism-specific
guarantee by component divergences. This includes the ADP guarantees of Balle et al. [15] (and thus
prior work [14, 43, 44]) and the RDP guarantees from [28–30, 40].
Subsumption of [ 15].Going even further, we show in Appendix G.2 that our approach subsumes the
entire framework of Balle et al. [15]: Any mechanism-agnostic guarantee derived via their ansatz can
equivalently be derived by defining a (potentially suboptimal) simultaneous coupling between four
subsampling distributions and upper-bounding the resultant guarantee via (advanced) joint convexity.
Contribution. Importantly, our contribution is not in the bounds themselves, but in the identification
of this implicitly underlying pattern that unifies prior work. We further generalize this pattern through
our proposed framework to enable tight analysis for more challenging scenarios like group privacy.
Novel RDP accounting bounds. In Appendix I, we use this observation to derive a variety of
novel mechanism-agnostic RDP bounds for different combinations of ≃X,≃Y, and subsampling
schemes, such as insertion/removal and subsampling without replacement. We further derive a simple
but tight mechanism-specific guarantee for subsampled randomized response under substitution
(see Theorem I.3) that outperforms the best known mechanism-agnostic bound (see Section 4).
2In combination with “advanced joint convexity” [15].
73.4 From mechanism-specific guarantees to dominating pairs.
Because the mechanism-specific guarantees derived via our framework do not obfuscate the un-
derlying distributions, they can be used to identify dominating pairs. These dominating pairs can
then be combined with arbitrary (numerical) accountants to track privacy under composition. For
example, we can immediately read off from Theorem 3.8 that the two Gaussian mixtures are a
dominating pair for the “insert- K+-remove- K−“ relation. In Appendix J, we describe a procedure for
constructing dominating pairs when the bound is a weighted sum of multiple mixture divergences. We
can thus determine dominating pairs for any bound derived via optimal transport. As we demonstrate
in Appendix K, the dominating pairs for subsampled mechanisms derived by Zhu et al. [10] (special
cases of which appear in [8, 17–19, 11]) can equivalently be proven via our framework.
Subsampling with replacement. As a novel contribution, we derive for the first time dominating
pairs for subsampling with replacement (see Theorem L.5), which were posited but not proven in [ 8]
(see discussion in Appendix L). This is enabled by our solution to the problem in Theorem 3.7. As we
experimentally show in Appendix B.1.5, these bounds can be much stronger than those derived via
the framework of Balle et al. [15]. These results thus demonstrate that there is a qualitative difference
between mechanism-specific and mechanism-agnostic tightness even for group size K= 1.
3.5 Limitations and future work
Limitations. While our proposed framework can be applied to arbitrary subsampling distributions,
conditioning on a finite set of events may be too restrictive in certain settings (e.g., continuous batch
spaces). Also, while we found conditioning on the number of modified elements to be sufficient for
all considered scenarios, an automated procedure for selecting events would be desirable. Maximal
couplings fulfill this purpose in [15], but only yield pairs of distributions.
Future work. A natural direction is applying our ansatz to novel settings other than group privacy. In
particular, it could potentially be used to provide epoch-level guarantees for correlated subsampling
(e.g., batching via shuffling), similar to [ 38]. We present a preliminary result for 2-fold non-adaptive
composition in Appendix P. Future work could also use our solutions to the problem in Theorem 3.7 to
generalize the matrix mechanism analysis from [ 24] to substitutions and non-Gaussian distributions.
4 Experimental evaluation
The purpose of the following experiments is to verify that there can be a benefit to using mechanism-
specific over mechanism-agnostic subsampling bounds, and that a joint analysis of subsampling and
group privacy can offer stronger guarantees than post-hoc application of the generic group privacy
property. In all figures, “specific“ refers to our proposed mechanism-specific bounds, “agnostic“
refers to (tight) mechanism-agnostic bounds, and “post-hoc“ refers to applying the generic group
privacy property to tight mechanism-specific bounds derived for group size 1. For all experiments,
we assume ℓpsensitivities of 1. Further details on the experimental setup are provided in Appendix C.
An implementation will be made available at https://cs.cit.tum.de/daml/group-amplification.
101102103104
RDPα10−610−410−2RDPρ(α)
θ
0.9
0.75
0.6Agnostic
Specific
Figure 3: Randomized response with WOR sub-
sampling ( q / N = 0.001), group size 1, and
varying true response probability θ.0 1 2 3 4 5 6
ADP ε0.00.20.40.6ADP δ(ε)Group size
16
8
4
2
1Agnostic
Specific
Figure 4: Laplace mechanisms with scale λ=
1, Poisson subsampling ( r= 0.2), and varying
group size.
84.1 Mechanism-agnostic and mechanism-specific guarantees
Randomized response and RDP. One potential source of looseness in mechanism-agnostic bounds
is that they bound mixture divergences in terms of component divergences that can be summarized by
a single privacy parameter. As an example, let us consider the best known guarantee for substitution,
subsampling without replacement, and RDP from [ 28]. As discussed by the authors, it is only tight
up to factors that are constant in α. In Fig. 3 we compare it to our tight mechanism-specific bound for
randomized response (see Theorem I.3) with batch-to-dataset ratio q / N = 0.001and true response
probability θ∈ {0.6,0.75,0.9}. In Appendix B.1.1 we consider other ratios. The tight guarantee
eliminates the constant factors and thus achieves much smaller ρfor a wide range of α∈(1,104].
Group privacy and ADP. Another potential source of looseness in mechanism-agnostic bounds
is that they stem from a binary partitioning of the batch space (recall Fig. 2), which may not be
sufficient when there are multiple possible levels of privacy leakage (e.g. number of sampled group
elements). We demonstrate this in Fig. 4, by comparing the tight mechanism-agnostic group privacy
bound derived via the framework from [ 15] to our tight mechanism-specific bound for Laplace
mechanisms (see Theorem M.2), ADP, scale λ= 1, subsampling rate r= 0.2, and varying group
size. In Appendix B.1.2 we repeat the experiment with other mechanisms and parameter values, and
also consider RDP. As discussed in Section 3.2, the mechanism-agnostic bound is identical to the
mechanisms-specific bound for group size K= 1. For group sizes K≥2, however, the fine-grained
partitioning underlying the mechanism-specific bound yields stronger privacy guarantees. These
results confirm that we need to distinguish between mechanism-agnostic and mechanism-specific
tightness when analyzing complex subsampling settings.
4.2 Post-hoc and mechanism-specific group privacy analysis
Single-iteration group privacy. Our next goal is to demonstrate the benefit of analyzing group
privacy and subsampling jointly. In Fig. 5, we evaluate our tight guarantee for Gaussian mechanisms
(see Theorem 3.8) with σ= 2, rate r= 0.2, and varying group size. As a baseline, we evaluate the
same tight guarantee with K++K−= 1 and apply the generic group privacy property (see Ap-
pendix C.1.4) in a post-hoc manner. As can be seen, our tight analysis can lead to much stronger
privacy guarantees. However, we interestingly observe in Appendix B.2.1 that the generic group
privacy properties of ADP and RDP can serve as increasingly tight upper bounds when considering
more private base mechanisms (e.g., σ= 5) and much smaller subsampling rates (e.g., r= 10−3).
Composed group privacy. Nevertheless, even the gaps in tightness for very private mechanisms may
quickly accumulate when repeatedly applying these mechanisms to a dataset. In Fig. 6, we use the
dominating pairs derived via our framework to conduct tight PLD accounting [ 16,8] with “connect
the dots” [ 20] quantization using Google’s dp_accounting library [ 45]. For σ= 5,r= 10−3, and
fixed ε= 2 (for other pararameters and mechanisms, see Appendix B.2.3), the post-hoc analysis
quickly diverges with increasing group size and number of iterations. For example, with group size
16and privacy budget δ= 10−6, the post-hoc analysis allows less than 100iterations of DP-SGD
training [ 36,6], whereas our tight analysis enables training for over 1000 iterations. In Appendix B.2.5
we train an image classification model on MNIST with PLD accounting to demonstrate that this
increased number of training iterations can translate to much higher model utility.
0 1 2 3 4 5 6
ADP ε0.00.20.40.6ADP δ(ε)Group size
16
8
4
2
1Post-hoc
Specific
Figure 5: Gaussian mechanisms with standard
deviation σ= 2, Poisson subsampling ( r= 0.2),
and varying group size.0 250 500 750 1000
Iteration t10−2210−1610−1010−4ADP δ(ε)
Group size
16
84
21Post-hoc
Specific
Figure 6: PLD accounting for Gaussian mecha-
nisms ( σ= 5), Poisson subsampling ( r= 10−3),
and varying group size at ε= 2.
95 Related Work
Amplification by subsampling for ADP. Using subsampling to strenghten (ε, δ)-DP guarantees
has a long history [ 13,14] particularly in privacy-preserving machine learning [ 46,47,6]. For a
thorough introduction to subsampling and its interaction with composition, we refer the reader to [ 48].
Balle et al. [15] ultimately proposed a framework for deriving tight mechanism-agnostic subsampling
guarantees. Our work subsumes theirs and enables the derivation of mechanism-specific guarantees.
Amplification for privacy accountants. Abadi et al. [6]’s seminal work on moments accounting
already considered subsampling. Similiar results were derived for the more general notion of RDP [ 7]
in [28–30]. More recent works on accounting generally include a discussion of either Poisson
subsampling or subsampling without replacement [ 17–19,21,11]. Subsampling with replacement is
discussed in [ 8], albeit without complete proofs, which we provide in Appendix L. We demonstrate
that amplification guarantees for the central notions of RDP [ 7] and dominating pairs [ 10] can – just
like guarantees for ADP – be derived via optimal transport. Our novel approach not only unifies prior,
but also enables a principled analysis of challenging scenarios like group privacy.
Group privacy amplification. A special case of group privacy amplification (which we use as an
example to demonstrate the utility of our general framework) with hockey stick divergences, Gaussian
mechanisms, and groups that collaboratively agree to contribute all their data was posited in [ 24]
and proven in a recent follow-up note [ 22]. However, their result (and proof strategy) does not cover
Rényi divergences, other mechanisms (Laplace, randomized response), and the standard notion of
group privacy under which group members are not forced to collaborate (see, e.g., [3, 7, 9, 15, 23]).
Hierarchical randomized smoothing. Randomized smoothing [ 49–51] is a technique for construct-
ing provably robust models via DP achieved through input perturbations (e.g. [ 52–68]). Similar to
subsampling, Scholten et al. [69] proposed to only apply perturbations to randomly sampled parts of
an input. We repurpose their technique of treating subsampling indicators as observable random vari-
ables in order to construct dominating pairs from weighted sums of divergences (see Appendix J.1).
Unified amplification for f-DP. Wang et al. [70] proved a form of joint concavity for the tradeoff
functions underlying f-DP accounting [ 9,34]. This enables them to analyze mixtures induced by
random initialization and shuffling in a unified manner. However, they do notconsider amplification
by subsampling, and explicitly state that they need to address this problem in future work. Note that
dominating pairs, which can be derived via our proposed framework, can be used in f-DP accounting
due to duality of privacy profiles and tradeoff functions [9, 10].
6 Conclusion
The main purpose of this work is to provide a unified, principled framework for mechanism-specific
subsampling analysis and subsampling analysis for privacy accountants. To this end, we proposed
a three-step procedure based on optimal transport between conditional subsampling distributions.
Beyond recovering known guarantees for Rényi DP and dominating pairs, this procedure lets us
derive novel results that were previously only available for approximate DP, such as non-standard
combinations of subsampling schemes and neighboring relations, or subsampling with replacement.
We then applied this procedure to the problem of analyzing group privacy under subsampling.
Our experimental evaluation demonstrates that our mechanism-specific group privacy amplification
bounds are not only tight, but can also significantly outperform tight mechanism-agnostic bounds and
traditional group privacy results – even under composition. On a higher level, these bounds represent
a novel contribution to a larger body of work (e.g., [ 38,71,72]) that demonstrates the benefit of
analyzing multiple properties of differential privacy jointly instead of independently.
7 Acknowledgements
We are grateful to Georgios Kaissis for valuable discussions and feedback on generalizing our work
beyond Rényi differential privacy, Yan Scholten for pointing out connections between subsampled
mechanisms and hierarchical randomized smoothing, as well as Leo Schwinn and Nicholas Gao for
proofreading our manuscript. This research was funded by the German Research Foundation, grant
GU 1409/4-1, and the Munich Data Science Institute (MDSI) at Technical University of Munich
(TUM) via the Linde/MDSI Doctoral Fellowship program and the MDSI Seed Fund.
10References
[1]Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith. Calibrating noise to
sensitivity in private data analysis. In Theory of Cryptography , pages 265–284. Springer, 2006.
[2]Cynthia Dwork, Krishnaram Kenthapadi, Frank McSherry, Ilya Mironov, and Moni Naor.
Our data, ourselves: Privacy via distributed noise generation. In Advances in Cryptology -
EUROCRYPT , pages 486–503, 2006.
[3]Cynthia Dwork, Aaron Roth, et al. The algorithmic foundations of differential privacy. Founda-
tions and Trends in Theoretical Computer Science , 9(3–4):211–407, 2014.
[4]Peter Kairouz, Sewoong Oh, and Pramod Viswanath. The composition theorem for differential
privacy. In International conference on machine learning , pages 1376–1385, 2015.
[5]Jack Murtagh and Salil Vadhan. The complexity of computing the optimal composition of
differential privacy. In Theory of Cryptography Conference , pages 157–175, 2015.
[6]Martin Abadi, Andy Chu, Ian Goodfellow, H Brendan McMahan, Ilya Mironov, Kunal Talwar,
and Li Zhang. Deep learning with differential privacy. In Proceedings of the SIGSAC conference
on computer and communications security , pages 308–318, 2016.
[7]Ilya Mironov. Rényi differential privacy. In IEEE 30th computer security foundations symposium
(CSF) , pages 263–275, 2017.
[8]Antti Koskela, Joonas Jälkö, and Antti Honkela. Computing tight differential privacy guarantees
using fft. In International Conference on Artificial Intelligence and Statistics , pages 2560–2569,
2020.
[9]Jinshuo Dong, Aaron Roth, and Weijie J Su. Gaussian differential privacy. Journal of the Royal
Statistical Society Series B: Statistical Methodology , 84(1):3–37, 2022.
[10] Yuqing Zhu, Jinshuo Dong, and Yu-Xiang Wang. Optimal accounting of differential privacy
via characteristic function. In International Conference on Artificial Intelligence and Statistics ,
pages 4782–4817, 2022.
[11] Wael Alghamdi, Juan Felipe Gómez, Shahab Asoodeh, Flávio P. Calmon, Oliver Kosut, and
Lalitha Sankar. The saddle-point method in differential privacy. In International Conference on
Machine Learning , 2023.
[12] Jiachen Tianhao Wang, Saeed Mahloujifar, Tong Wu, Ruoxi Jia, and Prateek Mittal. A random-
ized approach to tight privacy accounting. Advances in Neural Information Processing Systems ,
36, 2023.
[13] Shiva Prasad Kasiviswanathan, Homin K Lee, Kobbi Nissim, Sofya Raskhodnikova, and Adam
Smith. What can we learn privately? SIAM Journal on Computing , 40(3):793–826, 2011.
[14] Ninghui Li, Wahbeh Qardaji, and Dong Su. On sampling, anonymization, and differential pri-
vacy or, k-anonymization meets differential privacy. In Proceedings of the 7th ACM Symposium
on Information, Computer and Communications Security , pages 32–33, 2012.
[15] Borja Balle, Gilles Barthe, and Marco Gaboardi. Privacy amplification by subsampling: Tight
analyses via couplings and divergences. Advances in neural information processing systems , 31,
2018.
[16] Sebastian Meiser and Esfandiar Mohammadi. Tight on budget? tight bounds for r-fold approxi-
mate differential privacy. In Proceedings of the ACM SIGSAC Conference on Computer and
Communications Security , pages 247–264, 2018.
[17] Antti Koskela and Antti Honkela. Computing differential privacy guarantees for heterogeneous
compositions using fft. In International Conference on Learning Representations , 2021.
[18] Antti Koskela, Joonas Jälkö, Lukas Prediger, and Antti Honkela. Tight differential privacy
for discrete-valued mechanisms and for the subsampled gaussian mechanism using fft. In
International Conference on Artificial Intelligence and Statistics , pages 3358–3366, 2021.
11[19] Sivakanth Gopi, Yin Tat Lee, and Lukas Wutschitz. Numerical composition of differential
privacy. Advances in Neural Information Processing Systems , 34:11631–11642, 2021.
[20] Vadym Doroshenko, Badih Ghazi, Pritish Kamath, Ravi Kumar, and Pasin Manurangsi. Connect
the dots: Tighter discrete approximations of privacy loss distributions. Proceedings on Privacy
Enhancing Technologies , 2022.
[21] Badih Ghazi, Pritish Kamath, Ravi Kumar, and Pasin Manurangsi. Faster privacy accounting via
evolving discretization. In International Conference on Machine Learning , pages 7470–7483,
2022.
[22] Arun Ganesh. Tight group-level dp guarantees for dp-sgd with sampling via mixture of gaussians
mechanisms. arXiv preprint arXiv:2401.10294 , 2024.
[23] Salil Vadhan. The complexity of differential privacy. Tutorials on the Foundations of Cryptog-
raphy , pages 347–450, 2017.
[24] Christopher A. Choquette-Choo, Arun Ganesh, Thomas Steinke, and Abhradeep Guha Thakurta.
Privacy amplification for matrix mechanisms. In International Conference on Learning Repre-
sentations , 2024.
[25] Gilles Barthe and Federico Olmedo. Beyond differential privacy: Composition theorems
and relational logic for f-divergences between probabilistic programs. In Fedor V . Fomin,
R¯usin,š Freivalds, Marta Kwiatkowska, and David Peleg, editors, Automata, Languages, and
Programming , pages 49–60, 2013.
[26] Cynthia Dwork and Guy N Rothblum. Concentrated differential privacy. arXiv preprint
arXiv:1603.01887 , 2016.
[27] Mark Bun and Thomas Steinke. Concentrated differential privacy: Simplifications, extensions,
and lower bounds. In Theory of Cryptography Conference , pages 635–658, 2016.
[28] Yu-Xiang Wang, Borja Balle, and Shiva Prasad Kasiviswanathan. Subsampled rényi differential
privacy and analytical moments accountant. In The 22nd International Conference on Artificial
Intelligence and Statistics , pages 1226–1235, 2019.
[29] Ilya Mironov, Kunal Talwar, and Li Zhang. Rényi differential privacy of the sampled gaussian
mechanism. arXiv preprint arXiv:1908.10530 , 2019.
[30] Yuqing Zhu and Yu-Xiang Wang. Poisson subsampled rényi differential privacy. In International
Conference on Machine Learning , pages 7634–7642, 2019.
[31] Borja Balle, Gilles Barthe, Marco Gaboardi, Justin Hsu, and Tetsuya Sato. Hypothesis testing
interpretations and renyi differential privacy. In Proceedings of the Twenty Third International
Conference on Artificial Intelligence and Statistics , volume 108, pages 2496–2506, 2020.
[32] Shahab Asoodeh, Jiachun Liao, Flavio P Calmon, Oliver Kosut, and Lalitha Sankar. A better
bound gives a hundred rounds: Enhanced privacy guarantees via f-divergences. In IEEE
International Symposium on Information Theory (ISIT) , 2020.
[33] David M. Sommer, Sebastian Meiser, and Esfandiar Mohammadi. Privacy loss classes: The
central limit theorem in differential privacy. Proceedings on Privacy Enhancing Technologies ,
2019(2):245–269, 2019.
[34] Zhiqi Bu, Jinshuo Dong, Qi Long, and Weijie J Su. Deep learning with gaussian differential
privacy. Harvard data science review , 2020(23):10–1162, 2020.
[35] Hua Wang, Sheng Gao, Huanyu Zhang, Milan Shen, and Weijie J Su. Analytical composition
of differential privacy via the edgeworth accountant. arXiv preprint arXiv:2206.04236 , 2022.
[36] Shuang Song, Kamalika Chaudhuri, and Anand D Sarwate. Stochastic gradient descent with
differentially private updates. In IEEE global conference on signal and information processing ,
pages 245–248, 2013.
12[37] Borja Balle, Gilles Barthe, and Marco Gaboardi. Privacy profiles and amplification by subsam-
pling. Journal of Privacy and Confidentiality , 10(1), 2020.
[38] Jiayuan Ye and Reza Shokri. Differentially private learning needs hidden state (or much faster
convergence). Advances in Neural Information Processing Systems , 35:703–715, 2022.
[39] Cédric Villani. Couplings and changes of variables , pages 5–20. 2009. ISBN 978-3-540-71050-
9.
[40] Ameya Daigavane, Gagan Madan, Aditya Sinha, Abhradeep Guha Thakurta, Gaurav Aggarwal,
and Prateek Jain. Node-level differentially private graph neural networks. In ICLR 2022
Workshop on PAIR^2Struct: Privacy, Accountability, Interpretability, Robustness, Reasoning on
Structured Data , 2022.
[41] Morgane Ayle, Jan Schuchardt, Lukas Gosch, Daniel Zügner, and Stephan Günnemann. Training
differentially private graph neural networks with random walk sampling. In Workshop on
Trustworthy and Socially Responsible Machine Learning, NeurIPS , 2022.
[42] Zihang Xiang, Tianhao Wang, and Di Wang. Preserving Node-level Privacy in Graph Neural
Networks. In IEEE Symposium on Security and Privacy (SP) , pages 4714–4732, 2024.
[43] Mark Bun, Kobbi Nissim, Uri Stemmer, and Salil Vadhan. Differentially private release and
learning of threshold functions. In 2015 IEEE 56th Annual Symposium on Foundations of
Computer Science , pages 634–649, 2015.
[44] Jonathan Ullman. Cs7880: Rigorous approaches to data privacy. https://www.khoury.
northeastern.edu/home/jullman/cs7880s17/HW1sol.pdf , 2017. Accessed May 21,
2024.
[45] Google Differential Privacy Team. Privacy loss distributions. https://raw.
githubusercontent.com/google/differential-privacy/main/common_docs/
Privacy_Loss_Distributions.pdf , 2024. Accessed May 22, 2024.
[46] Raef Bassily, Adam Smith, and Abhradeep Thakurta. Private empirical risk minimization:
Efficient algorithms and tight error bounds. In IEEE 55th annual symposium on foundations of
computer science , pages 464–473, 2014.
[47] Yu-Xiang Wang, Stephen Fienberg, and Alex Smola. Privacy for free: Posterior sampling
and stochastic gradient monte carlo. In International Conference on Machine Learning , pages
2493–2502, 2015.
[48] Thomas Steinke. Composition of differential privacy & privacy amplification by subsampling.
arXiv preprint arXiv:2210.00597 , 2022.
[49] Mathias Lécuyer, Vaggelis Atlidakis, Roxana Geambasu, Daniel Hsu, and Suman Jana. Certified
robustness to adversarial examples with differential privacy. In IEEE Symposium on Security
and Privacy , pages 656–672, 2019.
[50] Bai Li, Changyou Chen, Wenlin Wang, and Lawrence Carin. Certified adversarial robustness
with additive noise. Advances in neural information processing systems , 2019.
[51] Jeremy Cohen, Elan Rosenfeld, and Zico Kolter. Certified adversarial robustness via randomized
smoothing. In International Conference on Machine Learning , 2019.
[52] Alexander Levine and Soheil Feizi. Robustness certificates for sparse adversarial attacks
by randomized ablation. In Proceedings of the AAAI Conference on Artificial Intelligence ,
volume 34, pages 4585–4593, 2020.
[53] Aleksandar Bojchevski, Johannes Klicpera, and Stephan Günnemann. Efficient robustness
certificates for discrete data: Sparsity-aware randomized smoothing for graphs, images and
more. In International Conference on Machine Learning , 2020.
[54] Marc Fischer, Maximilian Baader, and Martin Vechev. Certified defense to image transfor-
mations via randomized smoothing. Advances in Neural information processing systems ,
2020.
13[55] Yihan Wu, Aleksandar Bojchevski, Aleksei Kuvshinov, and Stephan Günnemann. Completing
the picture: Randomized smoothing suffers from curse of dimensionality for a large family of
distributions. In International Conference on Artificial Intelligence and Statistics , 2021.
[56] Aounon Kumar and Tom Goldstein. Center smoothing: Certified robustness for networks with
structured outputs. Advances in Neural Information Processing Systems , 2021.
[57] Jan Schuchardt and Stephan Günnemann. Invariance-aware randomized smoothing certificates.
InAdvances in Neural Information Processing Systems , 2022.
[58] Motasem Alfarra, Adel Bibi, Naeemullah Khan, Philip HS Torr, and Bernard Ghanem. De-
formRS: Certifying input deformations with randomized smoothing. In Proceedings of the
AAAI Conference on Artificial Intelligence , number 6, pages 6001–6009, 2022.
[59] Yan Scholten, Jan Schuchardt, Simon Geisler, Aleksandar Bojchevski, and Stephan Günnemann.
Randomized message-interception smoothing: Gray-box certificates for graph neural networks.
InAdvances in Neural Information Processing Systems , 2022.
[60] Nikita Murarev and Aleksandr Petiushko. Certified robustness via randomized smoothing
over multiplicative parameters of input transformations. In International Joint Conference on
Artificial Intelligence , 2022.
[61] Peter Súkeník, Aleksei Kuvshinov, and Stephan Günnemann. Intriguing properties of input-
dependent randomized smoothing. In International conference on machine learning , 2022.
[62] Mikhail Pautov, Olesya Kuznetsova, Nurislam Tursynbek, Aleksandr Petiushko, and Ivan Os-
eledets. Smoothed embeddings for certified few-shot learning. Advances in Neural Information
Processing Systems , 2022.
[63] Jan Schuchardt, Tom Wollschläger, Aleksandar Bojchevski, and Stephan Günnemann. Localized
randomized smoothing for collective robustness certification. In International Conference on
Learning Representations , 2023.
[64] Taras Rumezhak, Francisco Girbal Eiras, Philip HS Torr, and Adel Bibi. Rancer: Non-axis
aligned anisotropic certification with randomized smoothing. In Proceedings of the IEEE/CVF
Winter Conference on Applications of Computer Vision , pages 4672–4680, 2023.
[65] Aman Saxena, Tom Wollschläger, Nicola Franco, Jeanette Miriam Lorenz, and Stephan Gün-
nemann. Randomized smoothing-inspired quantum encoding schemes with formal robustness
guarantees. In Quantum Techniques in Machine Learning , 2023.
[66] Samuel Pfrommer, Brendon G. Anderson, and Somayeh Sojoudi. Projected randomized
smoothing for certified adversarial robustness. Transactions on Machine Learning Research ,
2023. ISSN 2835-8856.
[67] Jan Schuchardt, Yan Scholten, and Stephan Günnemann. Provable adversarial robustness for
group equivariant tasks: Graphs, point clouds, molecules, and more. In Advances in Neural
Information Processing Systems , 2023.
[68] Zhuoqun Huang, Neil Marchant, Keane Lucas, Lujo Bauer, Olya Ohrimenko, and Benjamin
I. P. Rubinstein. RS-Del: Edit distance robustness certificates for sequence classifiers via
randomized deletion. In Advances in Neural Information Processing Systems , NeurIPS, 2023.
[69] Yan Scholten, Jan Schuchardt, Aleksandar Bojchevski, and Stephan Günnemann. Hierarchical
randomized smoothing. Advances in Neural Information Processing Systems , 36, 2023.
[70] Chendi Wang, Buxin Su, Jiayuan Ye, Reza Shokri, and Weijie J Su. Unified enhancement
of privacy bounds for mixture mechanisms via $f$-differential privacy. In Thirty-seventh
Conference on Neural Information Processing Systems , 2023.
[71] Jason Altschuler and Kunal Talwar. Privacy of noisy stochastic gradient descent: More iterations
without more privacy loss. Advances in Neural Information Processing Systems , 35, 2022.
14[72] Antonious Girgis, Deepesh Data, and Suhas Diggavi. Rényi differential privacy of the sub-
sampled shuffle model in distributed learning. In Advances in Neural Information Processing
Systems , volume 34, pages 29181–29192, 2021.
[73] Ashkan Yousefpour, Igor Shilov, Alexandre Sablayrolles, Davide Testuggine, Karthik Prasad,
Mani Malek, John Nguyen, Sayan Ghosh, Akash Bharadwaj, Jessica Zhao, Graham Cormode,
and Ilya Mironov. Opacus: User-friendly differential privacy library in PyTorch. arXiv preprint
arXiv:2109.12298 , 2021.
[74] Borja Balle and Yu-Xiang Wang. Improving the gaussian mechanism for differential privacy:
Analytical calibration and optimal denoising. In International Conference on Machine Learning ,
pages 394–403, 2018.
[75] Úlfar Erlingsson, Vitaly Feldman, Ilya Mironov, Ananth Raghunathan, Kunal Talwar, and
Abhradeep Thakurta. Amplification by shuffling: From local to central differential privacy
via anonymity. In Proceedings of the Thirtieth Annual ACM-SIAM Symposium on Discrete
Algorithms , pages 2468–2479, 2019.
[76] Albert Cheu, Adam Smith, Jonathan Ullman, David Zeber, and Maxim Zhilyaev. Distributed
differential privacy via shuffling. In Advances in Cryptology–EUROCRYPT , pages 375–403,
2019.
15A Table of contents
B Additional experiments 18
B.1 Mechanism-agnostic and mechanism-specific bounds . . . . . . . . . . . . . . . . 18
B.2 Post-hoc and tight group privacy . . . . . . . . . . . . . . . . . . . . . . . . . . . 25
C Experimental setup 36
C.1 Evaluation of privacy guarantees . . . . . . . . . . . . . . . . . . . . . . . . . . . 36
C.2 Computational resources . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37
C.3 Assets and licenses . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37
D General setting and definitions 38
D.1 Spaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38
D.2 Neighboring relations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38
D.3 Mechanisms and subsampling schemes . . . . . . . . . . . . . . . . . . . . . . . . 38
D.4 Differential privacy notions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39
D.5 Joint convexity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39
D.6 Couplings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39
E Proof of optimal transport bounds 40
E.1 Proof of Theorem 3.3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40
E.2 Proof of Theorem 3.4 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40
E.3 Proof of Proposition 3.5 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41
F Distance-compatible couplings of multiple distributions 42
G Recovering known mechanism-agnostic ADP guarantees 45
G.1 Overview of Balle et al. framework . . . . . . . . . . . . . . . . . . . . . . . . . . 45
G.2 Subsumption of Balle et al. framework . . . . . . . . . . . . . . . . . . . . . . . . 46
G.3 Deficiencies of mechanism-agnostic ADP bounds. . . . . . . . . . . . . . . . . . . 48
H Recovering known mechanism-agnostic RDP guarantees 49
H.1 Subsampling without replacement and substitution . . . . . . . . . . . . . . . . . 49
H.2 Poisson subsampling and insertion/removal . . . . . . . . . . . . . . . . . . . . . 52
H.3 Graph subsampling without replacement and node modification . . . . . . . . . . . 54
I Novel RDP guarantees 56
I.1 Hybrid neighboring relations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56
I.2 Subsampling without replacement under insertion/removal . . . . . . . . . . . . . 57
I.3 Tight mechanism-specific subsampling without replacement for randomized response 59
J From mechanism-specific guarantees to dominating pairs 61
J.1 Step 1: Eliminating weighted sums . . . . . . . . . . . . . . . . . . . . . . . . . . 61
16J.2 Step 2: Resolving non-constancy in dataset pairs . . . . . . . . . . . . . . . . . . 62
J.3 Step 3: Resolving non-constancy in divergence order . . . . . . . . . . . . . . . . 63
K Recovering known dominating pairs 64
K.1 Poisson subsampling and insertion/removal . . . . . . . . . . . . . . . . . . . . . 64
K.2 Subsampling without replacement and insertion/removal . . . . . . . . . . . . . . 65
K.3 Subsampling without replacement and substitution . . . . . . . . . . . . . . . . . 65
L Novel results for dominating pairs 67
L.1 Subsampling without replacement and substitution . . . . . . . . . . . . . . . . . 67
L.2 Subsampling with replacement and substitution . . . . . . . . . . . . . . . . . . . 68
M Tight mechanism-specific group privacy amplification 71
M.1 Proof of Theorem 3.7 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 71
M.2 Instantiations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72
M.3 Tightness . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 74
M.4 Numerical evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76
N Tight mechanism-agnostic group privacy amplification 78
N.1 ADP guarantee . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 78
N.2 Tightness of ADP guarantee . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 79
N.3 Relation to tight mechanism-specific bound . . . . . . . . . . . . . . . . . . . . . 80
N.4 RDP guarantee . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 81
N.5 Asymptotic RDP guarantees . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 81
O Worst-case mixture components 83
O.1 Gaussian and Laplacian mixtures . . . . . . . . . . . . . . . . . . . . . . . . . . . 83
O.2 Reduction of the divergence to a univariate integral . . . . . . . . . . . . . . . . . 91
O.3 Randomized Response Proofs . . . . . . . . . . . . . . . . . . . . . . . . . . . . 92
P Towards epoch-level subsampling analysis 97
P.1 Problem setting . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 97
P.2 Optimal transport without conditioning . . . . . . . . . . . . . . . . . . . . . . . . 97
P.3 Optimal transport with conditioning . . . . . . . . . . . . . . . . . . . . . . . . . 98
P.4 Experimental Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99
Q Broader impact 100
17B Additional experiments
B.1 Mechanism-agnostic and mechanism-specific bounds
B.1.1 Randomized response and RDP
In Fig. 7, we repeat the experiment from Fig. 3 with other ratios of batch and dataset sizes. That
is, we compare our tight mechanism-specific RDP guarantee from Theorem I.3 to the best known
mechanism-agnostic bound from [ 28] to illustrate that mechanism-agnostic bounds may loose privacy
by bounding mixture divergences in terms of component divergences – even outside the group privacy
setting. The tight guarantee eliminates constant factors and thus achieves much smaller ρfor a wide
range of α∈(1,104], especially for small ratios.
q / N = 0.01
101102103104
RDPα10−410−310−210−1RDPρ(α)
θ
0.9
0.75
0.6Agnostic
Specificq / N = 0.1
101102103104
RDPα10−210−1RDPρ(α)
q / N = 0.2
101102103104
RDPα10−210−1100RDPρ(α)q / N = 0.5
101102103104
RDPα10−1100RDPρ(α)
Figure 7: Randomized response under subsampling without replacement, with varying true response
probability θand batch-to-dataset ratio q / N . Theorem I.3 significantly improves upon the baseline
for a wide range of α.
B.1.2 Group privacy and ADP
In Figs. 8 and 9 we repeat the experiment from Fig. 4 for other subsampling rates r, standard
deviations σ, and also with Laplace mechanisms. That is, we compare our tight mechanism-specific
group privacy guarantees to the tight mechanism-agnostic bounds derived via the framework of [ 15].
The results demonstrate that mechanism-specific tightness is a stronger property that can result in
better privacy guarantees – although the difference in significantly more pronounced for Laplace
mechanisms and/or larger group sizes.
In Fig. 10 we repeat the experiment with randomized response mechanisms. Here, both approaches
yield identical guarantees. This verifies that randomized reseponse is indeed the worst-case mecha-
nisms for which the mechanism-agnostic bound is optimal (see [15] and Appendix N.2).
18Gaussian mechanism
r= 0.1, σ= 1
0 2 4 6 8 10
ADP ε0.00.20.4ADP δ(ε)Group size
16
8
4
2
1Agnostic
Specificr= 0.1, σ= 2
0 1 2 3 4 5
ADP ε0.00.10.20.3ADP δ(ε)
r= 0.1, σ= 5
0.0 0.5 1.0 1.5 2.0
ADP ε0.000.050.10ADP δ(ε)r= 0.2, σ= 2
0 1 2 3 4 5 6
ADP ε0.00.20.4ADP δ(ε)
r= 0.2, σ= 5
0.0 0.5 1.0 1.5 2.0 2.5 3.0
ADP ε0.00.10.2ADP δ(ε)r= 0.5, σ= 1
0 2 4 6 8 10
ADP ε0.000.250.500.751.00ADP δ(ε)
r= 0.5, σ= 2
0 2 4 6 8 10
ADP ε0.00.20.40.60.8ADP δ(ε)r= 0.5, σ= 5
0 1 2 3 4 5 6
ADP ε0.00.20.4ADP δ(ε)
Figure 8: Gaussian mechanisms under Poisson subsampling, with varying standard deviation σ,
subsampling rate r, and group size. The tight mechanism-specific guarantees are stronger than the
tight mechanism-agnostic bounds, especially for larger group sizes and smaller subsampling rates.
19Laplace mechanism
r= 0.1, λ= 0.5
0 2 4 6 8 10
ADP ε0.00.20.40.6ADP δ(ε)Group size
16
8
4
2
1Agnostic
Specificr= 0.1, λ= 1
0 1 2 3 4
ADP ε0.00.10.20.30.4ADP δ(ε)
r= 0.1, λ= 2
0.0 0.5 1.0 1.5 2.0
ADP ε0.00.10.20.3ADP δ(ε)r= 0.2, λ= 0.5
0 2 4 6 8 10
ADP ε0.00.20.40.60.8ADP δ(ε)
r= 0.2, λ= 2
0.0 0.5 1.0 1.5 2.0 2.5 3.0
ADP ε0.00.20.4ADP δ(ε)r= 0.5, λ= 0.5
0 2 4 6 8 10
ADP ε0.000.250.500.751.00ADP δ(ε)
r= 0.5, λ= 1
0 2 4 6 8 10
ADP ε0.000.250.500.751.00ADP δ(ε)r= 0.5, λ= 2
0 1 2 3 4 5 6
ADP ε0.00.20.40.60.8ADP δ(ε)
Figure 9: Laplace mechanisms under Poisson subsampling, with varying scale λ, subsampling rate
r, and group size. The tight mechanism-specific guarantees are stronger than the tight mechanism-
agnostic bounds, especially for larger group sizes.
20Randomized response mechanism
r= 0.1, θ= 0.7
0.0 0.5 1.0 1.5 2.0 2.5 3.0
ADP ε0.00.10.20.3ADP δ(ε)Group size
16
8
4
2
1Agnostic
Specificr= 0.1, θ= 0.8
0.0 0.5 1.0 1.5 2.0 2.5 3.0
ADP ε0.00.20.4ADP δ(ε)
r= 0.1, θ= 2
0.0 0.5 1.0 1.5 2.0 2.5 3.0
ADP ε0.00.20.40.6ADP δ(ε)r= 0.2, θ= 0.7
0.0 0.5 1.0 1.5 2.0 2.5 3.0
ADP ε0.00.10.20.30.4ADP δ(ε)
r= 0.2, θ= 0.8
0.0 0.5 1.0 1.5 2.0 2.5 3.0
ADP ε0.00.20.40.6ADP δ(ε)r= 0.5, θ= 0.7
0.0 0.5 1.0 1.5 2.0 2.5 3.0
ADP ε0.00.10.20.30.4ADP δ(ε)
r= 0.5, θ= 0.8
0.0 0.5 1.0 1.5 2.0 2.5 3.0
ADP ε0.00.20.40.6ADP δ(ε)r= 0.5, θ= 0.9
0.0 0.5 1.0 1.5 2.0 2.5 3.0
ADP ε0.00.20.40.60.8ADP δ(ε)
Figure 10: Randomized response under Poisson subsampling, with varying true response probability
θ, subsampling rate r, and group size. Randomized response is the worst-case mechanism for which
the mechanism-agnostic guarantee is optimal, so both ansätze yield identical results.
21B.1.3 Group privacy and RDP
In Fig. 11 we repeat our comparison of mechanism-agnostic (Theorem N.5) and tight mechanism-
specific group privacy amplification (Theorem 3.8) with RDP instead of ADP. We observe that the
tight guarantee delays the phase transition from a high- to a low-privacy regime that was already
observed in [ 30]. In other words, we have small ρfor larger α, which is beneficial for conversion to
ADP after composition (see conversion formulae in [7, 31]).
r= 0.1, σ= 1
1.1×1002×1004×100
RDPα10−1101103105RDPρ(α)Group size
8
4
2
1Agnostic
Specificr= 0.001, σ= 1
101 1.1×1004×100
RDPα10−410−1102105RDPρ(α)
r= 0.1, σ= 2
101 1.1×1004×100
RDPα10−2100102104RDPρ(α)r= 0.001, σ= 2
101
RDPα10−510−2101104RDPρ(α)
r= 0.001, σ= 5
101102103104
RDPα10−310−1101103RDPρ(α)r= 0.001, σ= 5
101102103104
RDPα10−610−3100103RDPρ(α)
Figure 11: Gaussian mechanisms under Poisson subsampling, with varying standard deviation σ,
subsampling rate r, and group size. The mechanism-specific guarantee delays the phase transition
from high to low privacy.
22B.1.4 Benefit of conditioning
Next, we demonstrate the benefit of coupling multiple conditional distributions over coupling just
two subsampling distributions in deriving amplification guarantees. Specifically, we evaluate Proposi-
tion H.7, which can be derived via Theorem 3.3, i.e., optimal transport without conditioning. Note
that, unlike with the guarantees of Wang et al. [28], this bound depends on both the dataset size and
the batch size, not just their ratio. We make the following observations: For large αProposition H.7
converges to the baseline. Furthermore, this approach never outperforms the baseline for group size
1. Neither does it outperform the baseline for ratios q / L∈ {0.01,0.001}. But, for q / L = 0.1,
there is a sweet spot of alphas between 101and102in which it offers stronger guarantees. This
further reinforces our claim that there is a benefit to treating group privacy and amplification jointly.
Furthermore, we observe that in the case of q= 1, Proposition H.7 outperforms the baseline for large
alpha, since it can capture that one cannot possibly include more than one substituted element in a
singleton batch.
Overall, we can conclude that there is a benefit to jointly analyzing group privacy and subsampling
in this manner, but that optimal transport without conditioning is not sufficient for tightly analyzing
such complicated scenarios.
N= 105, q= 104
101102103104
RDPα10−2100102RDPρ(α)
Group size
4
2
1No conditioning
Post-hocN= 105, q= 102
101102103104
RDPα10−510−2101104RDPρ(α)
Group size
4
2
1No conditioning
Post-hoc
N= 104, q= 103
101102103104
RDPα10−2100102RDPρ(α)
Group size
4
2
1No conditioning
Post-hocN= 104, q= 101
101102103104
RDPα10−510−2101104RDPρ(α)
Group size
4
2
1No conditioning
Post-hoc
N= 103, q= 102
101102103104
RDPα10−2100102RDPρ(α)
Group size
4
2
1No conditioning
Post-hocN= 103, q= 100
101102103104
RDPα10−510−2101104RDPρ(α)
Group size
4
2
1No conditioning
Post-hoc
Figure 12: Proposition H.7 derived from Theorem 3.3 applied to Gaussian mechanism ( σ= 5.0)
under sampling without replacement for varying dataset size N, batch size q, and group size. Optimal
transport without conditioning does not always improve upon the baseline.
23B.1.5 Subsampling with replacement
The previous experiments demonstrated that mechanism-specific analysis can improve upon non-tight
mechanism-agnostic and – in the group privacy setting – tight mechanism-agnostic analysis. In the fol-
lowing, we demonstrate that mechanism-specific bounds can improve upon tight mechanism-agnostic
bounds even for single-element relations, i.e., group size 1. To this end, we consider subsampling
with replacement for Gaussian mechanisms under the substitution relation, comparing Theorem L.5
to Theorem 10 of Balle et al. [15].
Fig. 13 shows the resultant privacy profiles for standard deviation σ= 1, dataset size N= 100 , and
batch size q= 8. For ε≥2, the mechanism-specific bound is more than an order of magnitude
smaller. Intuitively, this gap can be explained similarly to the gap in the group privacy setting: The
single substituted element can be sampled 0,1,2, or up to qtimes, with each case causing different
levels of privacy leakage. Mechanism-agnostic bounds rely on a binary partitioning of the event
space, which is not sufficient for capturing this granular behavior (recall Fig. 2.
Note that due to the relaxations of distance constraints we performed in deriving Theorem L.5, the
mechanism-specific bound is not tight. A tight bound might lead to an even larger gap. Thus, this
experiments further reinforces that there is a qualitative difference between mechanism-specific and
mechanism-agnostic tightness.
100101
ADP ε10−910−710−510−3ADP δ(ε)
Agnostic
Specific
Figure 13: Gaussian mechanism ( σ= 1) under sampling with replacement for single-element
substitutions, dataset size N= 100 , and batch size q= 8. Using the mechanism-specific bound
results in stronger privacy guarantees.
24B.2 Post-hoc and tight group privacy
B.2.1 Single-iteration ADP
In Figs. 14 to 15 we repeat the experiment from Fig. 5 for other subsampling rates r, standard
deviations σ, and mechanisms. That is, we compare our tight mechanism-specific guarantees to
post-hoc use of the group privacy property. For all mechanisms, the tight mechanism-specific analysis
yields stronger privacy guarantees than the baseline – particularly for large group sizes. However, we
interestingly see that with increasing base mechanisms noise level and decreasing subsampling rate,
the post-hoc bound converges towards the tight bound.
25Gaussian mechanism
r= 0.1, σ= 1
0 2 4 6 8 10
ADP ε0.00.20.40.6ADP δ(ε)Group size
16
8
4
2
1Post-hoc
Specificr= 0.1, σ= 2
0 1 2 3 4 5
ADP ε0.00.10.20.3ADP δ(ε)
r= 0.1, σ= 5
0.0 0.5 1.0 1.5 2.0
ADP ε0.000.050.10ADP δ(ε)r= 0.2, σ= 1
0 2 4 6 8 10
ADP ε0.000.250.500.751.00ADP δ(ε)
r= 0.2, σ= 5
0.0 0.5 1.0 1.5 2.0 2.5 3.0
ADP ε0.00.10.2ADP δ(ε)r= 0.5, σ= 1
0 2 4 6 8 10
ADP ε0.000.250.500.751.00ADP δ(ε)
r= 0.5, σ= 2
0 2 4 6 8 10
ADP ε0.000.250.500.751.00ADP δ(ε)r= 0.5, σ= 5
0 1 2 3 4 5 6
ADP ε0.00.20.40.6ADP δ(ε)
Figure 14: Gaussian mechanisms under Poisson subsampling, with varying standard deviation σ,
subsampling rate r, and group size. Analyzing group privacy and subsampling jointly instead of in a
post-hoc manner offers stronger guarantees.
26Laplace mechanism
r= 0.1, λ= 0.5
0 2 4 6 8 10
ADP ε0.000.250.500.751.00ADP δ(ε)Group size
16
8
4
2
1Post-hoc
Specificr= 0.1, λ= 1
0 1 2 3 4
ADP ε0.00.20.40.6ADP δ(ε)
r= 0.1, λ= 2
0.0 0.5 1.0 1.5 2.0
ADP ε0.00.10.20.3ADP δ(ε)r= 0.2, λ= 0.5
0 2 4 6 8 10
ADP ε0.000.250.500.751.00ADP δ(ε)
r= 0.2, λ= 2
0.0 0.5 1.0 1.5 2.0 2.5 3.0
ADP ε0.00.20.40.6ADP δ(ε)r= 0.5, λ= 0.5
0 2 4 6 8 10
ADP ε0.000.250.500.751.00ADP δ(ε)
r= 0.5, λ= 1
0 2 4 6 8 10
ADP ε0.000.250.500.751.00ADP δ(ε)r= 0.5, λ= 2
0 1 2 3 4 5 6
ADP ε0.000.250.500.751.00ADP δ(ε)
Figure 15: Laplace mechanisms under Poisson subsampling, with varying scale λ, subsampling rate
r, and group size. Analyzing group privacy and subsampling jointly instead of in a post-hoc manner
offers stronger guarantees.
27Randomized response mechanism
r= 0.1, θ= 0.7
0.0 0.5 1.0 1.5 2.0
ADP ε0.00.20.40.6ADP δ(ε)Group size
16
8
4
2
1Post-hoc
Specificr= 0.1, θ= 0.8
0 1 2 3 4 5 6
ADP ε0.000.250.500.751.00ADP δ(ε)
r= 0.1, θ= 2
0 1 2 3 4 5 6
ADP ε0.000.250.500.751.00ADP δ(ε)r= 0.2, θ= 0.7
0.0 0.5 1.0 1.5 2.0
ADP ε0.000.250.500.751.00ADP δ(ε)
r= 0.2, θ= 0.8
0 1 2 3 4
ADP ε0.000.250.500.751.00ADP δ(ε)r= 0.5, θ= 0.7
0 1 2 3 4 5 6
ADP ε0.000.250.500.751.00ADP δ(ε)
r= 0.5, θ= 0.8
0 2 4 6 8 10
ADP ε0.000.250.500.751.00ADP δ(ε)r= 0.5, θ= 0.9
0 2 4 6 8 10
ADP ε0.000.250.500.751.00ADP δ(ε)
Figure 16: Randomized response mechanisms under Poisson subsampling, with varying true response
probability θ, subsampling rate r, and group size. Analyzing group privacy and subsampling jointly
instead of in a post-hoc manner offers stronger guarantees.
28B.2.2 Single-iteration RDP
In Fig. 17 we repeat our comparison of tight mechanism-specific group privacy amplification and
post-hoc group privacy for RDP instead of ADP. The tight analysis yields stronger guarantees and
delays the phase transition from a high- to a low-privacy regime. However, as with ADP, the post-hoc
bound can be a good upper bound for small subsampling rates and very private base mechanisms.
r= 0.1, σ= 1
1.1×1002×1004×100
RDPα10−1101103105RDPρ(α)Group size
8
4
2
1Post-hoc
Specificr= 0.001, σ= 1
101 1.1×1004×100
RDPα10−410−1102105RDPρ(α)
r= 0.1, σ= 2
101 1.1×1004×100
RDPα10−2100102104RDPρ(α)r= 0.001, σ= 2
101
RDPα10−510−2101104RDPρ(α)
r= 0.001, σ= 5
101102103104
RDPα10−310−1101103RDPρ(α)r= 0.001, σ= 5
101102103104
RDPα10−610−3100103RDPρ(α)
Figure 17: Gaussian mechanisms under Poisson subsampling, with varying standard deviation σ,
subsampling rate r, and group size. Analyzing group privacy and subsampling jointly instead of
in a post-hoc manner delays the phase transition from high to low privacy. For very private base
mechanisms and small subsampling rates, the baseline is nevertheless a good upper bound.
29B.2.3 PLD Accounting
In Figs. 18 to 21 we repeat our comparison of tight mechanism-specific and post-hoc group privacy
amplification guarantees under composition from. We consider different combinations of subsampling
rater, standard deviation σ, privacy parameter ε, as well as Laplace mechanisms. Even in high
privacy scenarios, where the mechanism-specific and post-hoc analysis yield similar results on a
single-iteration level, the mechanism-specific guarantees are significantly stronger under composition.
Specifically, the post-hoc analysis diverges to much larger δafter some number of iterations. In
settings with moderate privacy (e.g. σ= 1) or large group sizes (e.g. 16), the baseline diverges after
less than 100iterations.
Gaussian mechanism ( r= 0.001)
ε= 0.5, σ= 1
0 250 500 750 1000
Iteration t10−1110−810−510−2ADP δ(ε)Group size
16
8
4
2
1Post-hoc
Specificε= 0.5, σ= 5
0 250 500 750 1000
Iteration t10−2210−1610−1010−4ADP δ(ε)
ε= 1, σ= 1
0 250 500 750 1000
Iteration t10−1310−910−510−1ADP δ(ε)ε= 1, σ= 5
0 250 500 750 1000
Iteration t10−2210−1610−1010−4ADP δ(ε)
ε= 2, σ= 1
0 250 500 750 1000
Iteration t10−1710−1210−710−2ADP δ(ε)ε= 2, σ= 5
0 250 500 750 1000
Iteration t10−2210−1610−1010−4ADP δ(ε)
Figure 18: Self-composed Gaussian mechanisms under Poisson subsampling with subsampling rate
r= 0.001and varying standard deviation σ, privacy parameter εand group size. For sufficiently
large group sizes, the post-hoc analysis divergence from the tight mechanism-specific guarantee
within less than 1000 iterations.
30Gaussian mechanism ( r= 0.01)
ε= 0.5, σ= 1
0 200 400 600 800 1000
Iteration t10−510−310−1ADP δ(ε)Group size
16
8
4
2
1Post-hoc
Specificε= 0.5, σ= 5
0 250 500 750 1000
Iteration t10−2110−1510−910−3ADP δ(ε)
ε= 1, σ= 1
0 200 400 600 800 1000
Iteration t10−710−510−310−1ADP δ(ε)ε= 1, σ= 5
0 250 500 750 1000
Iteration t10−2110−1510−910−3ADP δ(ε)
ε= 2, σ= 1
0 250 500 750 1000
Iteration t10−1010−710−410−1ADP δ(ε)ε= 2, σ= 5
0 250 500 750 1000
Iteration t10−2110−1510−910−3ADP δ(ε)
Figure 19: Self-composed Gaussian mechanisms under Poisson subsampling with subsampling rate
r= 0.01and varying standard deviation σ, privacy parameter εand group size. For sufficiently large
group sizes, the post-hoc analysis divergence from the tight mechanism-specific guarantee within
less than 1000 iterations.
31Laplace mechanism ( r= 0.001)
ε= 0.5, λ= 1
0 250 500 750 1000
Iteration t10−1510−1110−710−3ADP δ(ε)Group size
16
8
4
2
1Post-hoc
Specificε= 0.5, λ= 5
0 250 500 750 1000
Iteration t10−1410−1010−610−2ADP δ(ε)
ε= 1, λ= 1
0 250 500 750 1000
Iteration t10−1510−1110−710−3ADP δ(ε)ε= 1, λ= 5
0 250 500 750 1000
Iteration t10−1410−1010−610−2ADP δ(ε)
ε= 2, λ= 1
0 250 500 750 1000
Iteration t10−1510−1110−710−3ADP δ(ε)ε= 2, λ= 5
0 250 500 750 1000
Iteration t10−1410−1010−610−2ADP δ(ε)
Figure 20: Self-composed Laplace mechanisms under Poisson subsampling with subsampling rate
r= 0.001and varying scale λ, privacy parameter εand group size. For sufficiently large group sizes,
the post-hoc analysis divergence from the tight mechanism-specific guarantee within less than 1000
iterations.
32Laplace mechanism ( r= 0.01)
ε= 0.5, λ= 1
0 250 500 750 1000
Iteration t10−1510−1110−710−3ADP δ(ε)Group size
16
8
4
2
1Post-hoc
Specificε= 0.5, λ= 5
0 250 500 750 1000
Iteration t10−1410−1010−610−2ADP δ(ε)
ε= 1, λ= 1
0 250 500 750 1000
Iteration t10−1510−1110−710−3ADP δ(ε)ε= 1, λ= 5
0 250 500 750 1000
Iteration t10−1410−1010−610−2ADP δ(ε)
ε= 2, λ= 1
0 250 500 750 1000
Iteration t10−1510−1110−710−3ADP δ(ε)ε= 2, λ= 5
0 250 500 750 1000
Iteration t10−1410−1010−610−2ADP δ(ε)
Figure 21: Self-composed Laplace mechanisms under Poisson subsampling with subsampling rate
r= 0.001and varying scale λ, privacy parameter εand group size. For sufficiently large group sizes,
the post-hoc analysis divergence from the tight mechanism-specific guarantee within less than 1000
iterations.
33B.2.4 RDP accounting
Finally, we compare tight group privacy amplification to the post-hoc approach for RDP accounting.
We begin with the Gaussian mechanism and subsampling rate r= 0.001in Fig. 22. Our bound offers
stronger group privacy guarantees for σ= 1.0, but both results are almost identical for very private
base mechanisms with σ= 5.0. We suspect that this is because the phase transition from high to low
privacy (recall Fig. 17), which the tight guarantee delays, gets shifted to very high αregions that are
not useful for conversion to (ε, δ)-DP.
Our observations for randomized response mechanisms (see Fig. 23 are also consistent with earlier
results: For moderate subsampling rates r= 0.1, our guarantees are stronger, particularly for group
size8and large numbers of iterations. But, when decreasing the subsampling rate to 0.001, both
methods are almost identical. Nevertheless, group privacy amplification can demonstrably improve
upon a direct combination of independently derived group privacy and amplification guarantees.
Note that these observations are mostly of theoretic interest. In practice, one would use PLD
accounting, which tightly characterizes the composed mechanism’s privacy leakage, instead of the
looser RDP accounting. As shown in Figs. 18 to 21, the tight mechanisms-specific analysis drastically
outperforms the post-hoc analysis for PLD accounting.
Gaussian mechanism
r= 0.001, σ= 1
100101102103104105
Iteration t100101ADP εGroup size
8
4
2
1Post-hoc
Specificr= 0.001, σ= 5
100101102103104105
Iteration t10−1100ADP ε
Figure 22: Self-composed Gaussian mechanisms under Poisson subsampling with privacy parameter
δ= 10−8, subsampling rate r= 0.001, and varying standard deviation σand group size. The tight
mechanism-specific analysis yields better privacy guarantees than the post-hoc baseline, except for
large σwhere the baseline is a good upper bound.
Randomized response mechanism
r= 0.1, θ= 0.6
100101102103104105
Iteration t100102104ADP εGroup size
8
4
2
1Post-hoc
Specificr= 0.001, σ= 0.6
100101102103104105
Iteration t10−310−210−1100ADP ε
Figure 23: Self-composed randomized response mechanisms under Poisson subsampling with privacy
parameter δ= 10−8, true response probability θ= 0.6, and varying subsampling rate rand group
size. The tight mechanism-specific analysis yields better privacy guarantees than the post-hoc
baseline, except for small rwhere the baseline is a good upper bound.
34B.2.5 Model utility
The previous results demonstrated that handling group privacy via a tight mechanism-specific analysis
allows for a larger number of compositions, i.e., iterations at a given privacy budget than post-hoc
use of the group privacy property. In the following, we demonstrate that this increased number of
iterations can in fact result in increased utility for group-private machine learning models.
We train a convolutional neural network (2 convolution layers with kernel sizes 3and32/64
channels, followed by two linear layers with hidden dimension 128) for image classification on
MNIST ( 55000 training, 5000 validation, 10000 test samples). We set the gradient clipping norm of
DP-SGD [ 6] toC= 10−4, the Gaussian noise standard deviation to 0.6·C, and the subsampling
rate to r= 64 /55000 . The optimizer is ADAM with learning rate 1e−3. If the privacy budget is
not used up earlier, training is terminated after 8epochs, with ⌈55000 /64⌉iterations per epoch.
Even with a large privacy budget of ε= 8andδ= 1e−5, training with the post-hoc privacy analysis
needs to terminate after less than 200iterations. With the mechanism-specific analysis, δdoes not
even exceed 1e−7after8epochs, i.e., the model could potentially be trained for even more iterations.
The resultant validation accuracy’s are 79.6%and91.2%, respectively. This showcases the superior
privacy-utility trade-off that can be achieved by analyzing subsampling and group privacy jointly.
0 2000 4000 6000
Iteration t10−1010−710−4ADP δ(ε= 8)
Post-hoc
Specific
Budget
(a) Privacy0 2 4 6 8
Epoch0.00.20.40.60.81.0Val. accuracyPost-hoc
Specific
(b) Utility
Figure 24: Differentially private training of a 2-layer convolutional network on MNIST with PLD
accounting for group size 2. Our tight mechanism-specific analysis allows us to train for significantly
more epochs or to terminate training after 8epochs with less privacy leakage and higher accuracy.
35C Experimental setup
C.1 Evaluation of privacy guarantees
In all experiments, we assume that all mechanisms have underlying sensitivity 1w.r.t.ℓ∞(randomized
response), ℓ1(Laplace), or ℓ2(Gaussian) output norms. We thus only specify noise parameters σor
λ, rather than the ratio of σorλand the sensitivities.
C.1.1 Single-iteration approximate differential privacy
Privacy parameters. We evaluate all guarantees for 121equidistant values of εin[0,4]and121
logspace-equidistant values in 10−3,101, i.e.,{10x|x∈ {− 3,−3 +4
120, . . . , 1}}. We clip values
ofδ(ε)that are larger than 1to[0,1]. For our baselines, we enforce that δ(ε)is monotonically
decreasing by taking a running minimum from larger to smaller ε(this may improve but never
worsens the baselines).
Mechanism-agnostic group privacy baseline. As our mechanism-agnostic group privacy baselines,
we use Proposition N.1. We take the maximum over the two cases (K+=K, K −= 0) and
(K+= 0, K−=K), where Kis the group size. For Gaussian and Laplace mechanisms, we evaluate
group privacy profiles δk(ε)by determining δ(ε)for the same mechanism with sensitivity k. For
randomized response, we let δk=δ1. This is referred to to as “white-box” group privacy in [ 15]).
We evaluate this baseline analytically.
Post-hoc group privacy baseline. For our post-hoc baseline, we combine the tight Poisson sub-
sampling guarantee for insertion/removal from [ 15] with the group privacy property of approximate
differential privacy (see Appendix C.1.4 below). We evaluate this baseline analytically.
Tight mechanism-specific group privacy. In all ADP figures “specific” refers to our tight group
privacy guarantees for Gaussian (Theorem 3.8), Laplace (Theorem M.2), or randomized response
mechanisms (Theorem M.3). We take the maximum over all K+, K−∈N0withK++K−=
K, where Kis the group size. To evaluate the bounds for Gaussian and Laplace mechanisms,
we pessimistically invert the privacy loss of dominating pairs P, Q via binary search (see details
in Appendix M.4), as implemented in the dp_accounting library [ 45]. We set the precision to
10−6, i.e., find the global optimum over multiples of 10−6. The bound for the randomized response
mechanism is evaluated analytically in O(1).
C.1.2 Single-iteration Rényi differential privacy
Privacy parameters . We evaluate all guarantees for α∈ {2,3, . . . , 1000}, as well as 121logspace-
equidistant values in [0,104]rounded to the next smallest integer (without 0or1), and 121logspace-
equidistance values in (1,10]. For our baselines, we enforce that ρ(α)is monotonically increasing
by taking a running minimum from smaller to larger α(this may improve but never worsens the
baselines).
Mechanism-agnostic group privacy baseline. As our mechanism-agnostic group privacy baselines,
we use Proposition N.1. We take the maximum over the two cases (K+=K, K −= 0) and
(K+= 0, K−=K), where Kis the group size. For integer α, we use the binomial expansion
in Eq. (33) (without factor 2). For Gaussian and Laplace mechanisms, we evaluate group privacy
profiles ζk(α)by determining ζ(α)for the same mechanism with sensitivity k. For randomized
response, we let ζk=ζ1. For continuous α, we apply tanh -sinh-quadrature with 50digits of decimal
precision to Eq. (33)
Post-hoc group privacy baseline. For our post-hoc baselines, we combine either tight Poisson
subsampling guarantee for insertion/removal from [ 30] or the subsampling without replacement
guarantee for insertion/removal from [ 28] with the group privacy property of approximate differential
privacy (see Appendix C.1.4 below). For Poisson subsampling and integer α, we use the binomial
expansion from [ 30] (without factor 2). For continuous α, we apply tanh -sinh-quadrature with
50digits of decimal precision. For subsampling without replacement, we use the improved self-
consistency bound (Theorem 27 from [ 28]), which we evaluate via tanh -sinh-quadrature with 50
digits of decimal precision due to the intractability of the nested binomial expansions for larger α.
Tight mechanism-specific group privacy. In all RDP figures “specific” refers to our tight group
privacy guarantees for Gaussian (Theorem 3.8), Laplace (Theorem M.2), or randomized response
36mechanisms (Theorem M.3). We take the maximum over all K+, K−∈N0withK++K−=K,
where Kis the group size. To evaluate the bounds for Gaussian and Laplace mechanisms, we use
tanh -sinh-quadrature with 50digits of decimal precision (see discussion in Appendix M.4). The
bound for the randomized response mechanism is evaluated analytically in O(1).
C.1.3 Privacy accounting
RDP accounting. For RDP accounting, we simply evaluate the single-iteration guarantees as
described in Appendix C.1.2. We then multiply the ρ(α)with the number of iterations, apply the
improved RDP-to-ADP formula from [ 31], and take the minimum over all obtained values. For the
post-hoc baseline, we apply the group privacy property before composition (which is equivalent to
applying it after composition, due to additivity of composition).
PLD accounting. For PLD accounting with dominating pairs, we use the implementation of
thedp_accounting library [ 45]. To quantize the privacy loss distribution, we use “connect the
dots” [ 20] with pessimistic estimates, a discretization interval size of 10−3, and truncation of e−50
of the probability mass. During composition, we truncate 10−15of the tail mass. For the post-hoc
baseline, we apply the group privacy property after composition.
C.1.4 Post-hoc group privacy
ADP. For RDP, we use the following result from the proof of Lemma 2.2 in [ 23], which provides
tigher guarantees than Lemma 2.2 itself: Let Mbe(ε, δ)-DP under neighboring relation ≃X. Then,
Mis(ε′, δ′)-DP with ε′=ε·Kandδ′=PK−1
k=0ek·ε·δ.
RDP. For RDP, we use the following result from Corollary 4 of [ 7], which provides tighter guarantees
than the upper bound in their Proposition 2. Let Dαbelog(Λ α)/(α−1). This Dαfulfills the
following triangle inequality:
Dα(p||q)≤α−1
2
α−1D2α(p||r) +α
α−1D2α−1(r||q).
We recursively apply this bound log2(K)times when evaluating the group privacy of our baselines
for groups of size K.
C.2 Computational resources
We conduct all experiments on a set of Xeon E5-2630 v4 CPUs @ 2.2 GHz .
We use one worker and job per subsampling theorem, base mechanism noise level, subsampling rate,
and combination of group privacy parameters K−, K+. Per job, we allocate 2CPU cores, 4 GB and
10minutes of runtime (in practice, most jobs were completed in a few seconds). In total, we ran
13060 such jobs for ADP, 9731 for RDP, and 984for RDP accounting. We estimate that over the
course of the full research project twice as many jobs were executed.
C.3 Assets and licenses
To perform high-precision quadrature for RDP guarantees, we use the tanh -sinh quadrature im-
plementation from the mpmath library (version 1.3.0.), which is available under the BSD- 3-Clause
license at https://github.com/mpmath/mpmath .
For PLD accounting and evaluation of ADP guarantees via bisection, we use and extend
thedp_accounting library [ 45] (commit 0b109e959470c43e9f177d5411603b70a56cdc7a ),
which is available under Apache- 2.0license at https://github.com/google/
differential-privacy
For conversion from RDP to ADP guarantees, we use the get_privacy_spent method implemented
in the Opacus library [ 73] (version 1.4.1), which is available under Apache- 2.0license at https:
//github.com/pytorch/opacus .
An implementation will be made available at https://cs.cit.tum.de/daml/group-amplification.
37D General setting and definitions
In the following, we generalize some of the definitions introduced in Sections 2 and 3 to their
measure-theoretic equivalents. The purpose of this generalization is to handle both continuous and
discrete spaces, base mechanisms, and subsampling schemes, without having to make constant case
distinctions.
We use these more general definitions throughout the remaining appendix sections. The theoretic
results presented in Section 3 follow as special cases.
D.1 Spaces
Unlike before, we assume that dataset space Xis some arbitrary space, whose elements do not have
to be sets. Instead, datasets x∈Xcan also be graphs, sequences or any other data collection. We
further assume that the batch space is a measurable space (Y,Y)withσ-algebra Y. For example, Y
can be composed of subsets, subgraphs, or subsequences. We also assume the output space to be a
measurable space (Z,Z). Finally, we assume the existence of some measure λon the output space,
such as the Lebesgue measure for continuous Zor the counting measure #for discrete Z.
Whenever we consider Poisson subsampling, we assume that X⊆ P(A),Y={y⊆x|x∈X},
Y=P(Y), where Ais some discrete, finite set and P(·)is the powerset.
Whenever we consider subsampling without replacement with batch size q, we assume that X⊆
{x∈ P(A)| |x|> q},Y={y⊆x|x∈X,|y|=q},Y=P(Y), where Ais some discrete, finite
set and P(·)is the powerset.
D.2 Neighboring relations
For set-valued datasets and batches, the insertion/removal relation and the substitution relation are
formally defined as follows:
Definition D.1. Setsx, x′∈Xare related by the insertion/removal relation ( x≃±x′)ifx̸=x′and
there is some asuch that x′=x∪ {a}orx′=x\ {a}.
Definition D.2. Setsx, x′∈Xare related by the substitution relation ( x≃∆x′)if there is some
a∈xanda′/∈xsuch that x′=x\ {a} ∪ {a′}.
In our general setting, we also allow non-symmetric neighboring relations.
D.3 Mechanisms and subsampling schemes
As before, the term “mechanism” refers to random functions that map to the output space (Z,Z).
Formally, a random function M:X→Zis a family of random variables indexed by elements of X.
Definition D.3. A random function M:X→Zis a function M:X×Ω→Z, where (Ω,F, P)is
some probability space and all M(x,·) :ω7→M(x, ω)are measurable.
We write PMx:Z → [0,1]for the distribution of random variable M(x). We further assume that each
PMxis absolutely continuous w.r.t. the aforementioned output measure λ, i.e.,∀x∈X:PMx≪λ,
and write mx:Z→R+for the corresponding Radon–Nikodym derivative dPMx/dλ. For example,
when the output space (Z,Z)is continuous and λis the Lebesgue measure, then mxis the density.
Similarly, we define our base mechanism to be a random function B:Y→Zand write PBy:Z →
[0,1]for the distribution of base mechanism outputs given a batch y∈Y. We assume that each PBy
is absolutely continuous w.r.t. output measure λand write by:Z→R+fordPBy/dλ.
Finally, we define our subsampling scheme to be a random function S:X→Zand write PSx:Y →
[0,1]for the distribution of batches given a dataset x∈X. We generally do not require PSxto be
absolutely continuous w.r.t. some other measure. When PSxis absolutely continuous w.r.t. counting
measure #, we write sx:Y→[0,1]for the corresponding probability mass function dPSx/d#.
In particular, Poisson subsampling and subsampling without replacement are defined as follows:
Definition D.4. Poisson subsampling with rate r∈[0,1]has probability mass function sx(y) =
r|y|(1−r)|x|−|y|for batches y⊆x.
38Definition D.5. Subsampling without replacement with batch size qhas probability mass function
sx(y) = |x|
q−1for batches y⊆xwith|y|=q.
As before, our goal is to provide privacy guarantees for subsampled mechanisms M=B◦S. Similar
to our discussion in Section 2, its distribution PMxgiven a dataset x∈Xis a mixture3with
mx(z) =Z
Yby(z) dPSx(y). (5)
There is one component per batch yfrom batch space Y, and the weights depend on subsampling
distribution PSx.
D.4 Differential privacy notions
Since we no longer require the output space to be continuous, we also need to generalize the definitions
of approximate differential privacy, Rényi differential privacy, dominating pairs, and the divergences
underlying their definition. For this, recall that λis our assumed measure on output space (Z,Z).
Definition D.6. Forε≥0, a mechanism M:X→Zis(ε, δ)-DP under relation ≃Xif∀x≃Xx′:
Hexp(ε)(mx||mx′)≤δandHexp(ε)(mx′||mx)≤δwith hockey stick divergence
Hα(mx||mx′) =Z
Zmax{mx(z)/ mx′(z)−α,0} ·mx′(z) dλ(z). (6)
Definition D.7. A pair of distributions (P, Q)withp= dP /dλandq= dQ /dλis a dominating
pair for mechanism Munder neighboring relation ≃X, ifHα(mx||mx′)≤Hα(p||q)for all x≃Xx′
and all α≥0.
Definition D.8. Forα≥1, a mechanism M:X→RDis(α, ρ)-RDP under neighboring relation
≃Xif∀x≃Xx′: log(Λ α(mx||mx′))/(α−1)≤ρandlog(Λ α(mx′||mx))/(α−1)≤ρwith
Λα(mx||mx′) =Z
RDmx(z)α·mx′(z)1−αdz. (7)
Importantly, note that Λαis not the Rényi divergence as used in [ 7]. It is its αth moment, i.e., a scaled
and exponentiated Rényi divergence. This is why a logarithm and quotient appears in Definition D.8.
We use this definition, so that we can simultaneously discuss ADP and RDP without notational clutter.
D.5 Joint convexity
The joint convexity of Ψα∈ {Hα,Λα)is not limited to densitites, but also applies to other non-
negative Radon–Nikodym derivatives of probability distributions [37, 38]:
Lemma D.9. Consider arbitrary Radon–Nikodym derivatives f(1)
1, f(1)
2, f(2)
1, f(2)
2:Z→R+and
weight w∈[0,1]. Then,
Ψα(wf(1)
1+ (1−w)f(1)
2||wf(2)
1+ (1−w)f(2)
2)≤wΨα(f(1)
1||f(2)
1) + (1 −w)Ψα(f(1)
2||f(2)
2).
D.6 Couplings
As with the discrete, finite-support subsampling distributions we considered in Section 3, the key tool
we use for analyzing amplification are couplings. However, we no longer assume the subsampling
scheme to always have a mass function. We thus use a more general notion of couplings between
distributions instead of couplings between mass functions:
Definition D.10. A coupling between probability measures P1, . . . , P Non space (Y,Y)is a proba-
bility measure Γon product space (Y,Y)N, where the nth marginal is Pn, i.e., Γ◦π−1
n=Pnwith
projection πn(y) =yn.
Here,◦is the composition operator and π−1
nis the preimage (not necessarily the inverse) of the
projection function. As before, when considering a coupling between two distributions P1,P2, the
value Γ(T, R)specifies for all events T, R∈ Y how much probability should be transported from
P1(T)toP2(R)to transform P1intoP2.
3assuming that (y, Z)7→PBy(Z)is a valid Markov kernel
39E Proof of optimal transport bounds
E.1 Proof of Theorem 3.3
In the following, we show a more general statement for the general setting introduced in Appendix D.
Theorem 3.3 immediately follows in the special case where batch space Yis finite and discrete, and
the subsampling distribution has a probability mass function sx.
Theorem E.1. Consider a subsampled mechanism M=B◦S, and an arbitrary coupling Γbetween
subsampling distributions PSxandPSx′. Then
Ψα(mx||mx′)≤Z
Y2cα(y(1), y(2)) dΓ(( y(1), y(2))) (8)
with cost function cα(y(1), y(2)) = Ψ α(by(1)||by(2)).
Proof. Recall that mxandmx′are mixtures with mx(z) =R
by(z)dPSx(y)andmx′(z) =R
by(z)dPSx′(y). Since Γis a coupling between PSxandPSx′, we can use the projection
πn(y) =ynand change of variables to rewrite these mixtures as
mx(z) =Z
Yby(z)d 
Γ◦π−1
1
(y) =Z
Y2bπ1(y)(z)dΓ(y) =Z
Y2by1(z)dΓ(y),
mx′(z) =Z
Yby(z)d 
Γ◦π−1
2
(y) =Z
Y2bπ2(y)(z)dΓ(y) =Z
Y2by2(z)dΓ(y).
Since mx(z)andmx′(z)are now expectations w.r.t. the same measure, we can use the joint convexity
ofΨα(Lemma D.9) to show Ψα(mx, mx′)≤R
Y2Ψα(by1||by2) dΓ(y).
E.2 Proof of Theorem 3.4
As before, we prove a more general statement from which Theorem 3.4 immediately follows. For
this, recall that Yis the σ-algebra of batch space (Y,Y), and that P(T|R) =P(T∩R)/ P(R).
Theorem E.2. Consider a subsampled mechanism M=B◦S. Further consider two dis-
joint partitioningsSI
i=1Ai=YandSJ
j=1Ej=Ysuch that all Ai, Ejare in Yand have
non-zero measure under SxandSx′, respectively. Let Γbe an arbitrary coupling between
PSx(· |A1), . . . , P Sx(· |AI), PSx′(· |E1), . . . , P Sx′(· |EJ). Then,
Ψα(mx||mx′)≤Z
YI+Jcα(y(1),y(2)) dΓ(( y(1),y(2))),
with cost function c:YI×YJ→R+defined by
cα(y(1),y(2)) = Ψ α
IX
i=1by(1)
i·PSx(Ai)||JX
j=1by(2)
j·PSx′(Ej)
. (9)
Proof. Using the law of total expectation, linearity of integration, and change of variables with
projection πn(y) =ynshows that
mx(z) =IX
i=1Z
Yby(z)dPSx(y|Ai)
PSx(Ai)
=Z
YIX
i=1by(z)·PSx(Ai)dPSx(y|Ai)
=Z
YIX
i=1by(z)·PSx(Ai)d(Γ◦π−1
i)(y)
=Z
YI+J IX
i=1byi(z)·PSx(Ai)!
dΓ(y)
40and
mx′(z) =Z
YI+J
JX
j=1by(j+I)(z)·PSx(Ej)
dΓ(y).
Since mx(z)andmx′(z)are now expectations w.r.t. the same measure, we can use the joint convexity
ofΨα(Lemma D.9) to show
Ψα(mx||mx′)≤Z
YI+JΨα
IX
i=1byi(z)·PSx(Ai)||JX
j=1by(j+I)(z)·PSx(Ej)
dΓ(y).
A change of indexing via y(1)
i=yiandy(2)
j=y(j+I)concludes our proof.
E.3 Proof of Proposition 3.5
Proposition 3.5. Consider y(1)∈YI,y(2)∈YJ, and cost function cdefined in Eq. (2). LetdYbe
the distance induced by ≃Y(see Definition 2.4). Then, cα(y(1),y(2))≤ˆcα(y(1),y(2)), with
ˆcα(y(1),y(2)) = max
ˆy(1),ˆy(2)cα(ˆy(1),ˆy(2)) (3)
subject to ∀k, l∈ {1,2},∀t, u:dY(ˆy(k)
t,ˆy(l)
u)≤dY(y(k)
t, y(l)
u)andˆy(1)∈YI,ˆy(2)∈YJ.
Proof. The original tuples of batches y(1)∈YIandy(2)∈YJconstitute a feasible solution to the
maximization problem, since they fulfill the constraints with equality, i.e., ∀k, l, t, u :dY(y(k)
t, y(l)
u) =
dY(y(k)
t, y(l)
u). The value of any feasible solution to a maximization problem is l.e.q. its optimal
value.
41F Distance-compatible couplings of multiple distributions
d = 2 d = 1
d = 1𝑦1
𝑦2
𝑦3supp(𝑠1)
supp(𝑠2)
supp(𝑠3)
(a) Distance- compatible coupling
d = 2 d > 1
d > 1𝑦1
𝑦2
𝑦3supp(𝑠1)
supp(𝑠2)
supp(𝑠3) (b) Distance- incompatible coupling
Figure 25: Example of a distance-compatible and a distance-incompatible coupling
In the following, we generalize the notion of distance-compatible couplings proposed in [ 15] from two
distributions to an arbitrary number of distributions. This provides a sufficient optimality condition
for Theorem E.2.
Note that we use a more general, measure-theoretic definition of distance-compatibility (see Defini-
tion F.4). Definition 3.6 is a special case for subsampling schemes with finite, discrete support.
As discussed in Section 3, a dY-compatible coupling between (conditional) subsampling distributions
only assigns probability to tuples of batches ywhen all pairs yi, yjhave the smallest possible distance
toy1and to each other, while still being in the support of their respective distributions.
To avoid having to make additional assumptions about the topology of batch space (Y,Y), we will
assume that all subsampling schemes have densities and reason about the support of these densities.
Definition F.1. The support of a function p:Y→R+issupp( p) ={y∈Y|p(y)>0}.
Based on this notion of support, we can define a notion of distance between a batch y∈Yand the
support of a density:
Definition F.2. Consider a distance dYinduced by a neighboring relation ≃Y. The distance between
an element y∈Yand the support of a function p:Y→R+is defined as dY(y,supp( p)) =
miny′∈supp( p)dY(y, y′).
Furthermore, we can define a notion of distance between the support of two different densities:
Definition F.3. Consider a distance dYinduced by a neighboring relation ≃Y. The distance between
the support of functions p1, p2:Y→R+is defined as
dY(supp( p1),supp( p2)) = min
y1,y2dY(y1, y2)s.t.∀i∈ {1,2}:yi∈supp( pi).
Based on these definitions, we can now formally define distance-compatible couplings between
multiple distributions.
Definition F.4. Consider a coupling Γbetween probability measures P1, . . . , P Non measurable space
(Y,Y)with symmetric neighboring relation ≃Yand induced distance dY. Assume that ∀n:Pn≪νn
for some measures ν1, . . . , ν Nand define pn= dPn/dνn. Further assume that Γ≪QN
n=1νnwith
product measureQN
n=1νn, and define γ=dΓ/dQνn. Then, Γis adY-compatible coupling if
(y∈supp(Γ) = ⇒ ∀u >1 :dY(y1, yu) =dY(y1,supp( su)))
∧(y∈supp(Γ) = ⇒ ∀u > t > 1 :dY(yu, yt) =dY(supp( st),supp( su))).
That is, Γonly assigns probability to a tuple of batches yif allytandyuare as close as possible to y1
and as close as possible to each other, while still being in the support of their corresponding densities.
Note that our choice of focusing on y1is arbitrary, and dY-compatibility could also be defined for
any other reference index n∈ {1, . . . , N }.
We shall now prove that dY-compatibility is a sufficient optimality condition for our optimal transport
problem. For this proof, we will use the following lemma, which immediately follows from Defini-
tions F.2 and F.3:
42Lemma F.5. Consider a distance dYinduced by a relation ≃Yand two functions p1, p2:Y→R+.
Then, for all y1∈supp( p1), y2∈supp( p2),
dY(y1, y2)≥dY(y1,supp( p2))≥dY(supp( p1),supp( p2)).
Theorem F.6. Consider a subsampled mechanism M=B◦S. Further consider two finite partitions
A1, . . . , A I∈ Y andE1, . . . , E J∈ Y ofYsuch that all AiandEjhave non-zero measure under Sx
andSx′, respectively. Let dYbe the distance induced by a symmetric neighboring relation ≃Y. LetΓ∗
be adY-compatible coupling between PSx(· |A1), . . . , P Sx(· |AI), PSx′(· |E1), . . . , P Sx′(· |EJ),
which have Radon–Nikodym derivatives s1, . . . , s I+J. Then, for all α >1,
Γ∗∈arg min
Γ∈G≤Z
YI+Jˆcα(y(1),y(2)) dΓ(( y(1),y(2))). (10)
where Gis the set of valid couplings between the I+Jmeasures, and ˆcα:YI×YJ→R+is the
cost function upper bound defined in Proposition 3.5.
Proof. Consider an arbitrary, not necessarily dY-compatible coupling Γ. By definition of ˆcand
symmetry of ≃, we haveZ
YI+Jˆcα(y(1),y(2)) dΓ(( y(1),y(2)))
=Z
YI+J
max
ˆy∈YI+Jcα(ˆy:I,ˆyI:)s.t.∀t < u :dY(ˆyt,ˆyu)≤dY(yt, yu)
dΓ(y),
with original cost function cα:YI×YJ→R+defined in Theorem E.2.
We can now use Lemma F.5 to tighten the constraints of the optimization problem inside the integrand
and thus lower-bound its optimal value for all y∈supp(Γ) :
max
ˆy∈YI+Jcα(ˆy:I,ˆyI:)s.t.∀t < u :dY(ˆyt,ˆyu)≤dY(yt, yu)
≥max
ˆy∈YI+Jcα(ˆy:I,ˆyI:)
s.t.∀u >1 :dY(ˆy1,ˆyu)≤dY(y1,supp( su)),
∀u > t > 1 :dY(ˆyt,ˆyu)≤dY(supp( st),supp( su)).
We notice that the lower bound only depends on y1and shall thus refer to it as κα(y1). Further
note that any y/∈supp(Γ) does not contribute to the integral. Since Γis a valid coupling, we can
marginalize out all variables except y1via projection π1(y) =y1to showZ
YI+Jˆcα(y(1),y(2)) dΓ(( y(1),y(2)))
≥Z
YI+Jκα(π1(y)) dΓ( y) =Z
Yκα(y1) d(Γ◦π−1
1)(y1) =Z
Yκα(y1) dPSx(y1|A1).
By construction of κα, this holds with equality whenever Γ∗is adY-compatible coupling.
Finally, the exact derivations we used for Theorem F.6 can also be used to show that the optimal value
of our transport problem has a simple, canonical form whenever a dY-compatible coupling exists:
Corollary F.7. Consider a subsampled mechanism M=B◦S. Further consider two finite partitions
A1, . . . , A I∈ Y andE1, . . . , E J∈ Y ofYsuch that all AiandEjhave non-zero measure under Sx
andSx′, respectively. Let dYbe the distance induced by a symmetric neighboring relation ≃Y. Assume
that a dY-compatible coupling between PSx(· |A1), . . . , P Sx(· |AI), PSx′(· |E1), . . . , P Sx′(· |EJ)
with Radon–Nikodym derivatives s1, . . . , s I+Jexists. Then, for all α >1,
min
Γ∈GZ
YI+Jˆcα(y(1),y(2)) dΓ(( y(1),y(2))) =Z
Yκα(y1) dPSx(y1|A1), (11)
where Gis the space of valid couplings between the I+Jmeasures,
κα(y1) = max
ˆy∈YI+Jcα(ˆy:I,ˆyI:)s.t.∀u >1 :dY(ˆy1,ˆyu)≤dY(y1,supp( su)),
∀u > t > 1 :dY(ˆyt,ˆyu)≤dY(supp( st),supp( su)),
andcα:YI×YJ→R+is the original cost function defined in Theorem E.2.
43Thus, we can focus on constructing distance-compatible couplings when trying to derive existing or
novel amplification by subsampling guarantees. Note that these result also generalize to asymmetric
neighboring relations ≃Y. We just wanted to avoid further complicating the indexing. Future work
may want to generalize these results to a more general, topological notion of support that does not
rely on the existence of subsampling densities.
44G Recovering known mechanism-agnostic ADP guarantees
In the following, we first provide an overview of the framework for deriving mechanism-agnostic
ADP guarantees proposed by Balle et al. [15]. We then show that the same guarantees can be derived
via optimal transport between multiple subsampling distributions. Finally, we use observations made
during the proof to explain why the mechanism-agnostic guarantees derived via this approach can be
suboptimal.
G.1 Overview of Balle et al. framework
The framework from [ 15] uses four steps to derive tight mechanism-agnostic guarantees for subsam-
pled mechanisms: (1) Partitioning the subsampling distributions via maximal couplings, (2) applying
advanced joint convexity, (3) applying joint convexity, and (4) defining two couplings involving two
distributions.
Maximal couplings are a construction that makes it possible to partition the subsampling probability
mass functions as
sx(y) = (1 −w)px(y) +wqx(y)
sx′(y) = (1 −w)px(y) +wqx′(y),
with probability mass functions px, qx, qx′:Y→[0,1]chosen such that qxandqx′have disjoint
support and w∈[0,1]is as small as possible.
Note that, when considering typical subsampling schemes (Poisson, without replacement, with
replacement) and single-element neighboring relations (insertion/removal, substitution), this partition
is simply equivalent to
sx(y) = Pr[ Sx∈A1]·sx(y|A1) + Pr[ Sx∈A2]·sx(y|A2)
sx′(y) = Pr[ Sx′∈E1]·sx′(y|E1) + Pr[ Sx∈E2]·sx′(y|E2),
where A1andE1are the event that the inserted/removed or substituted element is not sampled, and
A2,E2are their complements (see Appendix B in [15]).
Using this construction, the densitities mxandmx′of subsampled mechanisms M=B◦Scan be
rewritten as
mx(z) = (1 −w)X
y∈Yby(z)px(y) +wX
y∈Yby(z)qx(y) (12)
mx′(z) = (1 −w)X
y∈Yby(z)px(y) +wX
y∈Yby(z)qx′(y) (13)
Next, one can rewrite the divergence Hα(mx||mx′)via the following property:
Proposition G.1 (Advanced joint convexity [ 15]).Letmx, m′
x:Z→[0,1]be probability mass
functions satisfying mx(z) = (1 −w)f(z) +wg(z)andmx′(z) = (1 −w)f(z) +wg′(z)for some
w∈[0,1],f, g, g′:Z→[0,1]. Given α≥1, letα′= 1 + w(α−1)andβ=α′/ α. Then the
following holds:
Dα′(mx||mx′) =wDα(g||(1−β)f+βg′).
Applying advanced joint convexity, followed by joint convexity to Eqs. (12) and (13) shows that
Hα′(mx||mx′)≤(1−β)Hα
X
y∈Ybyqx(y)||X
y∈Ybypx(y)

+βHα
X
y∈Ybyqx(y)||X
y∈Ybyqx′(y)

Finally, one can construct a coupling γ:Y2→[0,1]between qxandpx, as well as a coupling
γ′:Y2→[0,1]between qxandqx′. One can then invoke a special case of Theorem 3.3 with
Ψα=Hαand the cost function upper bound from Proposition 3.5 to show
Hα′(mx||mx′)≤(1−β)X
y∈Y2ˆcα(y(1), y(2))γ(y(1), y(2)) +βX
y∈Y2ˆcα(y(1), y(2))γ′(y(1), y(2)).
45Since we are only considering pairs of batches, we have
ˆcα(y(1), y(2)) = max
ˆyHα(bˆy(1)||bˆy(1))s.t.dY(y(1), y(2))≤dY(ˆy(1),ˆy(2))
with induced distance dYfrom Definition 2.4. This specific cost function bound is referred to as
“group privacy profile” in [15].
G.2 Subsumption of Balle et al. framework
Next, we show that we can always obtain the same guarantee by defining a (potentially suboptimal)
coupling between four subsampling distributions, and then pessimistically upper-bounding the
guarantee we would obtain through Theorem 3.4:
Theorem G.2. Consider a subsampled mechanism M=B◦Sand some x, x′∈X. Assume
that subsampling pmfs sx, sx′:Y→[0,1]satisfy sx(z) = (1 −w)px(z) +wqx(z)andsx′(z) =
(1−w)px(z) +wqx′(z)for some w∈[0,1]andpx, qx, qx′:Y→[0,1]. Letγ:Y2→[0,1]be an
arbitrary coupling of qx, px, and γ′:Y2→[0,1]be an arbitrary coupling of qx, px′. Then, there is
a coupling ˜γ:Y4→[0,1]ofpx, qx, px, qx′such that for all α≥1
Hα′(mx||mx′)≤X
y∈Y2+2ˆcα′(y(1),y(2))˜γ(y(1),y(1))
≤(1−β)X
y∈Y1+1ˆcα(y(1), y(2))γ(y(1), y(2)) +βX
y∈Y1+1ˆcα(y(1), y(2))γ′(y(1), y(2)),
with cost function upper bound ˆcαdefined in Proposition 3.5, α′= 1 + w(α−1), and β=α′/ α.
Proof. The main idea is to invoke Theorem 3.4 with a specifically crafted coupling, and then apply
advanced joint convexity and joint convexity.
Specifically, we define a coupling ˜γ:Y→[0,1]that corresponds to the following generative process:
We first sample y(1)
2andy(2)
2from the coupling γ′(recall that a coupling is a joint mass function).
This gives us two elements from the support of qxandqx′, respectively. Then, we sample y(1)
1from
γconditioned on y(1)
2. This gives us an element from the support of px. Finally, we let y(2)
1←y(1)
1.
Formally, this coupling can be defined as
˜γ(y(1),y(2)) =γ′(y(1)
2, y(2)
2)·γ(y(1)
2, y(1)
1)
qx(y(1)
2)· 1h
y(2)
1=y(1)
1i
.
Validity of coupling. Before proceeding, we need to verify that this is a valid coupling, i.e., its four
marginals are px, qx, px, qx′. For any y(1)
1∈Y, we have
X
y(1)
2,y(2)
1,y(2)
2∈Y3˜γ(y(1)
1, y(1)
2, y(2)
1, y(2)
2)
=X
y(1)
2,y(2)
2∈Y2γ′(y(1)
2, y(2)
2)·γ(y(1)
2, y(1)
1)
qx(y(1)
2)
=X
y(1)
2∈Yqx(y(1)
2)·γ(y(1)
2, y(1)
1)
qx(y(1)
2)
=X
y(1)
2∈Yγ(y(1)
2, y(1)
1)
=px(y(1)
1).
where the first inequality is due to the indicator function, the second equality follows from marginal-
izing γ′, and the last equality follows from marginalizing γ.
The proof for any y(2)
1∈Yis analogous.
46For any y(1)
2∈Y, we similarly have
X
y(1)
1,y(2)
1,y(2)
2∈Y3˜γ(y(1)
1, y(1)
2, y(2)
1, y(2)
2) (14)
=X
y(1)
1,y(2)
2∈Y2γ′(y(1)
2, y(2)
2)·γ(y(1)
2, y(1)
1)
qx(y(1)
2)(15)
=X
y(1)
1∈Y1γ(y(1)
2, y(1)
1) (16)
=qx(y(1)
2), (17)
and for any y(2)
2we have
X
y(1)
1,y(1)
2,y(2)
1∈Y3˜γ(y(1)
1, y(1)
2, y(2)
1, y(2)
2) (18)
=X
y(1)
1,y(1)
2∈Y2γ′(y(1)
2, y(2)
2)·γ(y(1)
2, y(1)
1)
qx(y(1)
2)(19)
=X
y(1)
2∈Yγ′(y(1)
2, y(2)
2)·qx(y(1)
2)
qx(y(1)
2)(20)
=qx′(y(2)
2). (21)
First inequality. Now that we have a valid coupling, we can use the same joint-convexity argument
as in our proof of Theorem 3.4, combined with our cost function bound ˆcαto show
Hα′(mx||mx′)≤X
Y2+2max
ˆyHα′
(1−w)bˆy(1)
1+wbˆy(1)
2]||1−w)bˆy(2)
1+wbˆy(2)
2
·γ(y(1),y(2)),
with each of the |Y2+2|optimization problems being constrained by ∀k, l, t, u :dY(ˆy(k)
t,ˆy(l)
u)≤
dY(y(k)
t, y(l)
u)andˆy(1)∈Y2,ˆy(2)∈Y2. This corresponds to the first equality in our Theorem.
Second inequality. Due to construction of our coupling, we always have dY(y(1)
1, y(2)
1) = 0 , i.e.,
y(1)
1=y(2)
1. We can thus use advanced joint convexity, joint convexity, and linearity of summation to
obtain a looser bound via
Hα′(mx||mx′)≤(1−β)X
Y2+2max
ˆyHα
bˆy(1)
2||bˆy(1)
1
·γ(y(1),y(2))
+βX
Y2+2max
ˆyHα
bˆy(1)
2||bˆy(2)
2
·γ(y(1),y(2)),
with each of the 2· |Y2+2|optimization problems being constrained by ∀k, l, t, u :dY(ˆy(k)
t,ˆy(l)
u)≤
dY(y(k)
t, y(l)
u)andˆy(1)∈Y2,ˆy(2)∈Y2.
Next, we can further loosen this bound by dropping all constraints involving y(2)
1andy(2)
2in the
first optimization problem. We can also drop all constraints involving y(1)
1andy(2)
1in the second
optimization problem. Thus, by definition of the group privacy profile, we have
Hα′(mx||mx′)≤(1−β)X
Y2+2ˆcα
y(1)
2,y(1)
1
·γ(y(1),y(2))
+βX
Y2+2ˆcα
y(1)
2,y(2)
2
·γ(y(1),y(2)).
Note that the first cost function term does not depend on y(2)
1nory(2)
2, and the second cost function
term does not depend on y(1)
1nory(2)
1. We can thus marginalize out these variables (recall Eq. (16)
and Eq. (20)) to conclude our proof.
47The same argument also applies to the general problem setting defined in Appendix D: Given two
couplings Γ,Γ′, we can define a product coupling ˜Γ∝Γ·Γ′, invoke Theorem 3.4, and then apply
(advanced) joint convexity to pessimistically upper-bound the guarantee that would be obtained
through our proposed framework.
G.3 Deficiencies of mechanism-agnostic ADP bounds.
Following our discussion, we can identify three potential sources for looseness in this approach
for deriving mechanism-agnostic bounds. Firstly, it only uses a binary partitioning of subsampling
pmfs sxandsx′. The resultant mechanism-specific guarantee only depends on divergences between
two-component mixtures, which may not be sufficient to tightly bound the overall divergence in
complicated scenarios like group privacy. Secondly, it neglects the pairwise distances of y(1)
1andy(2)
2,
resulting in potentially very large values of the cost function. Thirdly, the bound might be further
loosened by applying joint convexity once more.
48H Recovering known mechanism-agnostic RDP guarantees
In the following, we demonstrate that existing amplification by subsampling guarantees for Rényi-DP
can be derived by instantiating our proposed framework (see Fig. 2). Specifically, we demonstrate
that these guarantees can be derived via the procedure discussed in Section 3.3 and shown in Figs. 2b
and 2c: (1) Conditioning on at most 4events indicating the presence of inserted / deleted / substituted
elements, (2) defining a simultaneous coupling, and (3) using joint convexity to upper-bound the
resultant mechanism-specific guarantee by component divergences.
These guarantees are mechanism-agnostic in the sense that they express the subsampled mechanism’s
privacy parameters (α, ρ)as a function of the base mechanism’s privacy parameters. We derive
guarantees for the general measure-theoretic problem setting introduced in Appendix D, where the
base mechanism can be either discrete or continuous.
The reader may notice that parts of the proofs in Appendices H.1 and H.2 are very similar to those
in [28,30], safe for the discussion of couplings and dY-compatibility. That is precisely the point:
There is an optimal transport problem that implicitly underlies results from prior work, which we have
identified and can now generalize to more challenging scenarios like group privacy amplification.
For this section, recall that ∆αis not the Rényi divergence, but its αth moment, i.e., a scaled and
exponentiated Rényi divergence (see Definition D.8).
H.1 Subsampling without replacement and substitution
For subsampling without replacement and substitution relation ≃∆we first show a more general
result Theorem H.1. We then demonstrate that it can be upper-bounded via joint convexity of
exponentiated Rényi divergence ∆αto recover the guarantee from [28].
Theorem H.1. LetM=B◦Sbe a subsampled mechanism, where Sis subsampling without
replacement with batch size q. Let≃Ybe the substitution relation ≃∆,Y. Then, for α >1and all
x≃∆,Xx′of size N,
∆α(mx||mx′)≤max
ˆy∆α((1−w)·by(1)
1+w·by(1)
2||(1−w)·by(2)
1+w·by(2)
2)
subject to d∆,Y(y(1)
1, y(1)
2)≤1,d∆,Y(y(1)
1, y(2)
2)≤1,d∆,Y(y(1)
2, y(2)
2)≤1,y(1)
1=y(2)
1, and with
w=q / N .
Proof. Consider arbitrary x≃∆,Xx′. By definition of ≃∆, there must be some a∈x,a′∈x′such
thatx′=x\ {a} ∪ {a′}. We thus define both A1andE1from Theorem E.2 to be the event that
neither anora′is sampled, i.e., A1=E1={y∈Y|y∩ {a, a′}=∅}. We further define A2and
E2to be the event that aora′is sampled, i.e., A2=A1andE2=E1.
By definition of subsampling without replacement, we have
PSx(A1) =PSx′(E1) = HyperGeom(0 |N,1, q) = 1−q
N,
PSx(A2) =PSx′(E2) = HyperGeom(1 |N,1, q) =q
N,
which corresponds to the weights (1−w)andw, respectively. We further have
sx(y|A1) =( |x|−1|
q−1ify⊆x∧a /∈y
0 otherwise, s x(y|A2) =( |x|−1
q−1−1ify⊆x∧a∈y
0 otherwise,
and
sx′(y|E1) =( |x|−1
q−1ify⊆x′∧a′/∈y
0 otherwise, s x(y|E2) =( |x|−1
q−1−1ify⊆x′∧a′∈y
0 otherwise.
Coupling. We now define a coupling γ:Y2+2→R+that corresponds to the following generative
process: We first generate y(1)
1by sampling a batch that does not contain auniformly at random from
49x. We then let y(2)
1←y(1)
1Finally, we pick a random element ˜aofy(1)
1and replace it with aanda′
to generate y(1)
2andy(2)
2, respectively. More formally:
γ(y(1),y(2)) =(
sx(y(1)
1|A1)·1
qify(1),y(2)fulfills H.2
0 otherwise.
Condition H.2. A tuple y(1)∈Y2,y(2)∈Y2fulfills this condition when y(2)
1=y(1)
1and
∃˜a∈y(1)
1:
y(1)
2=y(1)
1\ {˜a} ∪ {a} ∧y(2)
2=y(1)
1\ {˜a} ∪ {a′}
.
Validity. We now show that this constitutes a valid coupling. Consider y(1)
1. If and only if sx(y(1)
1|
A1)>0, there are exactly qcombinations of y(1)
2, y(2)
1, y(2)
2for which γ(y)is non-zero. Thus,
X
y(1)
2,y(2)
1,y(2)
2∈Y3γ(y) =q·sx(y(1)
1|A1).
The proof for y(2)
1is analogous.
Next, consider y(1)
2. If and only if sx(y(1)
2|A1)>0, there are exactly |x| −qelements that could
have been replaced by ato generate y(1)
2fromy(1)
2. Specifically, these elements are all elements that
do not appear in y(1)
2. We thus have
X
y(1)
1,y(2)
1,y(2)
2∈Y3γ(y) = (|x| −q)·(|x| −1−q)!·q!
|x| −1·1
q=|x| −1
q−1−1
.
The proof for y(2)
2is analogous.
Compatibility. Finally, we show that γis adY-compatible coupling (see Appendix F). Whenever
γ(y)>0, then
dY(y(1)
1, y(1)
2) =dY
y(1)
1,supp( sx(· |A2))
= 1,
dY(y(1)
1, y(2)
1) =dY
y(1)
1,supp( sx′(· |E1))
= 0,
dY(y(1)
1, y(2)
2) =dY
y(1)
1,supp( sx′(· |E2))
= 1.
Similarly, the pairwise distances between all yt, yuwithu > t > 1are identical to the distance
of their respective supports: The batches have a distance of 1because one can transform one into
another using a single substitution. The supports have a distance of 1because one can transition from
one to another using a single substitution.
The result then immediately follows from Corollary F.7.
Next, we can derive the upper bound from [ 28]. For this derivation, we will use the following Lemma,
which is proven in Appendix B of [6]:
Lemma H.3. Consider two probability measures P, Q on output measure space (Z,Z, λ). Define
p= dP /dλandq= dQ /dλ. Then
∆α(p||q) = 1 +αX
l=2α
lZ
(p(z)−q(z))lq(z)1−ldλ(z).
The following proof essentially follows that of [ 28], but skips their Appendix B.2, since we have
already successfully decomposed mixtures mxandmx′into small terms that only involve base
mechanism densities.
50Proposition H.4 (Wang et al. [28]).LetM=B◦Sbe a subsampled mechanism, where Sis
subsampling without replacement with batch size q. Let≃Ybe the substitution relation ≃∆,Y. Then,
forα >1and all x≃∆,Xx′of size N,∆α(mx||mx′)is l.e.q.
1 + 2αX
l=2α
l
wlmax
y≃∆,Yy′∆l(by||by′),
withw=q / N .
Proof. Using the constraint y(1)
1=y(2)
1in Theorem H.1, we can rewrite its objective as
max
y(1)
1,y(1)
2,y(2)
2∆α((1−w)·by(1)
1+w·by(1)
2||(1−w)·by(1)
1+w·by(2)
2).
Using Lemma H.3, we can upper-bound its optimal value via
max
y(1)
1,y(1)
2,y(2)
2∆α((1−w)·by(1)
1+w·by(1)
2||(1−w)·by(1)
1+w·by(2)
2)
= max
y(1)
1,y(1)
2,y(2)
21 +αX
l=2α
lZ(w·by(1)
2−w·by(2)
2)l

(1−w)·by(1)
1+w·by(2)
2l−1dλ(z)
≤ max
y(1)
1,y(1)
2,y(2)
21 +αX
l=2α
l
wlZ|by(1)
2−by(2)
2|l

(1−w)·by(1)
1+w·by(2)
2l−1dλ(z)
≤αX
l=0α
l
wlmax
y(1)
1,y(1)
2,y(2)
2Z|by(1)
2−by(2)
2|l

(1−w)·by(1)
1+w·by(2)
2l−1dλ(z),
where each of the α+ 1optimization problems is independently constrained by dY(y(1)
1, y(1)
2)≤1,
dY(y(1)
1, y(2)
2)≤1, and dY(y(1)
2, y(2)
2)≤1.
Next, we bound the optimal value of each of the α+ 1optimization problems. Using the joint
convexity of x, y7→xl·y1−l, which implies convexity in the second component, shows that
max
y(1)
1,y(1)
2,y(2)
2Z|by(1)
2−by(2)
2|l

(1−w)·by(1)
1+w·by(2)
2l−1dλ(z)
≤ max
y(1)
1,y(1)
2,y(2)
2(1−w)·Z|by(1)
2−by(2)
2|l
bl−1
y(1)
1dλ(z) +w·Z|by(1)
2−by(2)
2|l
bl−1
y(2)
2dλ(z)
≤(1−w)·
 max
y(1)
1,y(1)
2,y(2)
2Z|by(1)
2−by(2)
2|l
bl−1
y(1)
1dλ(z)
+w·
 max
y(1)
1,y(1)
2,y(2)
2Z|by(1)
2−by(2)
2|l
bl−1
y(2)
2dλ(z)

≤(1−w)·
 max
y(1)
1,y(1)
2,y(2)
2Z|by(1)
2−by(2)
2|l
bl−1
y(1)
1dλ(z)
+w·
 max
y(1)
1,y(1)
2,y(2)
2Z|by(1)
2−by(2)
2|l
bl−1
y(1)
1dλ(z)

= max
y(1)
1,y(1)
2,y(2)
2Z|by(1)
2−by(2)
2|l
bl−1
y(1)
1dλ(z),
where all optimization problems are independent, with each one being independently constrained by
dY(y(1)
1, y(1)
2)≤1,dY(y(1)
1, y(2)
2)≤1, and dY(y(1)
2, y(2)
2)≤1. Note that, for the last inequality, we
replaced a y(2)
2in the second maximization with a y(1)
1, which essentially adds a degree of freedom
and thus leads to an upper bound.
In [28], the optimal value of the final problem is referred to as the ternary- |χ|l-divergence of b2,by(2)
2,
andby(1)
1. As shown in their Lemma 19, it can be upper bounded via 2·max y≃∆,Yy′∆l(by||by′),
which concludes our proof.
51Additional terms. Note that [ 28] derive three additional bounds (see their Lemma 17, Lemma 19,
and Theorem 27) on the the ternary- |χ|l-divergence. This introduces additional terms, but does not
change the fact that their result is lower-bounded by Theorem H.1. We use their full theorem as a
baseline in our experiments.
H.2 Poisson subsampling and insertion/removal
Next, we show that the Poisson subsampling guarantees in [ 30,7] follow from another optimal
transport problem. For our proof, we will use the following Lemma, which corresponds to the “novel
alternative decomposition” in Appendix A.1 of [30].
Lemma H.5. Consider K+ 1∈Ndistributions P, Q 1, . . . , Q Kon output measure space (Z,Z, λ),
and define p= dP /dλ,qk= dQk/dλ. Further consider some w1, . . . , w K∈[0,1]withPK
k=1wk= 1. Then,
∆α 
p||KX
k=1wk·qk!
≤KX
k=1wk·∆α 
qk+p−KX
l=1wl·ql||qk!
.
Proof. Based on the definition of ∆α, we have
∆α 
p||KX
k=1wk·qk!
=Zp(z)α
PK
k=1wk·qk(z)α−1dλ(z)
=ZPK
k=1wk·qk(z)
+p(z)−PK
l=1wl·ql(z)α
PK
k=1wk·qk(z)α−1dλ(z)
=ZPK
k=1wk·
qk(z) +p(z)−PK
l=1wl·ql(z)α
PK
k=1wk·qk(z)α−1dλ(z)
The result then follows from joint convexity of ∆α.
Note that the proof of this lemma is very similar to the proof strategy we used in deriving Propo-
sition H.4 using Lemma H.3: We add 0 =c−cwith some cto the numerator (which leads to the
binomial expansion in Lemma H.3) and then apply joint convexity to obtain an upper bound.
Proposition H.6 (Zhu and Wang [30]).LetM=B◦Sbe a subsampled mechanism, where Sis
Poisson subsampling with rate r. Let≃Ybe the insertion/removal relation ≃±,Y. Then, for α >1
and all x≃±,Xx′,∆α(mx||mx′)is l.e.q.
2·αX
l=0α
l
rl(1−r)α−lmax
y≃±,Yy′∆l(by||by′).
Proof. Since we are concerned with insertion/removal, we need to consider two cases:
Case 1: Removal. In this case, there is some a∈xsuch that x′=x\ {a}. We let A1be the event
thatais not sampled, i.e. A1={y∈Y|a /∈y}, and let A2=A1. We let E1=Y, i.e., do not
condition on any particular event.
By definition of Poisson subsampling, we have PSx(A1) = 1−r,PSx(A2) =r, andPSx′(E1) = 1 .
We further have
sx(y|A1) =r|y|(1−r)|x|−|y|−1ify⊆x∧a /∈y
0 otherwise
sx(y|A2) =r|y|−1(1−r)|x|−|y|ify⊆x∧a∈y
0 otherwise,
52and
sx′(y|E1) =r|y|(1−r)|x′|−|y|ify⊆x′
0 otherwise=r|y|(1−r)|x|−|y|−1ify⊆x∧a /∈y
0 otherwise.
Note that sx(y|A1) =sx′(y|E1).
Coupling. We now define a coupling γ:Y2+1→R+that corresponds to the following generative
process: We first generate y(1)
1by sampling a batch that does not contain avia Poisson subsampling
from x\ {a}. We then let y(2)
1←y(1)
1. Finally, we deterministically insert ato generate y(1)
2. This
can be formally defined via
γ(y(1),y(2)) =(
sx(y(1)
1|A1)ify(1)
1=y(2)
1∧y(1)
2=y(1)
1∪ {a}
0 otherwise.
Validity. We can verify the validity of this coupling as follows: For every y(1)
1withsx(y(1)
1|A1)>0,
there is exactly one combination y(1)
2, y(2)
1for which γ(y)>0, namely y(2)
1=y(1)
1andy(1)
2=
y(1)
1∪ {a}. We thus haveP
y(1)
2,y(2)
1∈Y2γ(y(1)
1, y(1)
2, y(2)
1) =sx(y(1)
1|A1).The proof for y(2)
1is
analogous. For every y(1)
2, we have exactly one combination of y(1)
1, y(2)
1for which γ(y)>0, namely
y(1)
1=y(2)
1=y(1)
2\ {a}. We thus have
X
y(1)
1,y(2)
1∈Y2γ(y(1)
1, y(1)
2, y(2)
1)
=sx(y(1)
2\ {a} |A1) =r|y(1)
2|−1(1−r)|x|−(|y|−1)−1=r|y(1)
2|−1(1−r)|x|−|y|=sx(y(1)
2|A2).
Compatibility. Finally, it can be easily shown that γis adY-compatible coupling (see Appendix F).
Whenever γ(y)>0, then
dY(y(1)
1, y(1)
2) =dY
y(1)
1,supp( sx(· |A2))
= 1,
dY(y(1)
1, y(2)
1) =dY
y(1)
1,supp( sx′(· |E1))
= 0.
Similarly, the pairwise distance between y(1)
2andy(2)
1is always 1. This is identical to the distance of
their supports, because one can always transition between them via a single insertion/removal.
It thus follows from Corollary F.7 that
∆α(mx||mx′)≤ max
y(1)
1,y(1)
2,y(2)
1∆α((1−r)·by(1)
1+r·by(1)
2||by(2)
1)
s.t.d±,Y(y(1)
1, y(1)
2)≤1, y(1)
1=y(2)
1, d±,Y(y(1)
2, y(2)
1)≤1
Because y(1)
1=y(2)
1and because d±,Y(y(1)
1, y(1)
2)≤1is equivalent to y(1)
1≃±,Yy(1)
2, this bound
can be restated as
∆α(mx||mx′)≤max
y≃±,Yy′∆α((1−r)·by+r·by′||by).
Finally, one can use the definition of ∆αand binomial expansion to show
∆α(mx||mx′)≤max
y≃±,Yy′Z
Z((1−r)by(z) +rby′(z))α
by(z)α−1dλ(z)
= max
y≃±,Yy′Z
Z(1−r)by(z) +rby′(z)
by(z)α
by(z) dλ(z)
= max
y≃±,Yy′Z
Z
(1−r) +rby′(z)
by(z)α
by(z) dλ(z)
= max
y≃±,Yy′αX
l=0α
l
rl(1−r)α−l∆l(by||by′)
≤αX
l=0α
l
rl(1−r)α−lmax
y≃±,Yy′∆l(by||by′).
53Note that this is smaller than the term in Proposition H.6 by a factor of 2.
Case 2: Insertion In this case, there is some a∈x′such that x=x′\ {a}. Very similar to before,
we let A1=Y, i.e., we do not condition on any particular event. We further let E1be the event that
ais not sampled, i.e. E1={y∈Y|a /∈y}, and let E2=E1. We notice that we have exactly the
same conditional distributions as in the first case. We can thus define exactly the same coupling (up
to changes in indexing) to show that
∆α(mx||mx′)≤max
y≃±,Yy′∆α(by||(1−r)by+rby′).
Next, applying Lemma H.5 and using the definition of ∆αshows that
∆α(mx||mx′)
≤max
y≃±,Yy′∆α(by||(1−r)by+rby′)
≤max
y≃±,Yy′(1−r)∆α(by+by−((1−r)by+rby′)||by) +r∆α(by′+by−((1−r)by+rby′)||by′)
= max
y≃±,Yy′(1−r)∆α((1 + r)by−rby′||by) +r∆α((1−r)by′+rby||by′)
This corresponds exactly to Eq. 6 of the “novel alternative decomposition” in Appendix A.1 of [ 30].
One can then through the remaining steps in their Appendix A to show that this term is at most two
times larger than the one we derived in the deletion case.
As already mentioned at the beginning of this section, the proof is very similar to that in [ 30],
except for the discussion of couplings and dY-compatibility. We emphasize that the crucial aspect,
which is not discussed in any prior work on Rényi-DP amplification, is that there is an implicit,
underlying optimal transport problem between conditional subsampling distributions. Now that we
have identified this connection, we can apply this more general optimal transport principle to a much
broader range of amplification by subsampling scenarios for Rényi-DP.
Further tightening. The factor 2in Proposition H.6 can be eliminated for distributions with particular
symmetries (see Theorem 5 in [ 29]) or bounded Pearson-Vajda χl-pseudo-divergence (see Theorem
8 in [ 30]). We thus do not include the factor 2when using this amplification guarantee as a baseline
in our experiments.
H.3 Graph subsampling without replacement and node modification
Daigavane et al. [40] consider a setting that differes from the usual insertional/removal into datasets:
Node-level privacy for graphs. There, the dataset space is the set of all directed, attributed graphs
X=S
N,D∈NRN×D× {0,1}N×N, which are composed of a continuous feature matrix and a
discrete adjacency matrix. Two graphs x, x′are related by dataset relation ≃Xifx′can be constructed
by inserting a node (including new edges) into x, or removing a node (including its edges) from x.
To analyze this problem setting, they perform a preprocessing step (see their Algorithm 2) to represent
each graph by a set of subgraphs, with each subgraph corresponding to a node in the graph. Via
this construction, they return to the traditional setting where X⊆ P(A)for some set A, and the
modification of a node’s features and edges corresponds to the substitution of Kelements,4i.e.
≃K∆,X={(x, x′)∈X| ∃g∈x\x′, g′∈x′\x:x′=x\g∪g′∧ |g|=|g′|=K}, (22)
where Kdepends on the maximum considered graph degree.
Irrespective of the graph neural network specific details, this discussion suggests that group privacy
and differentially private learning for graphs are related.
We shall now demonstrate that their result for subsampling without replacement can be derived
from Theorem E.1, i.e. optimal transport without conditioning.
Proposition H.7 (Daigavane et al. [40]).LetM=B◦Sbe a subsampled mechanism, where Sis
subsampling without replacement with batch size q. Let≃Ybe the substitution relation ≃∆,Y. Let
4Note that they do not actually consider insertion/removal, because their analysis assumes the number of
subgraphs to remain constant.
54≃K∆,Xbe the K-fold substitution relation defined in Eq. (22). Then, for α >1and all x≃K∆,Xx′
of size N,
∆α(mx||mx′)≤KX
k=0wk·max
y≃k∆,Yy′∆k(by||by′).
withwk= HyperGeom( k|N, K, q ).
Proof. Consider arbitrary x≃∆,Xx′. By definition of ≃∆, there must be some g∈x\x′,g′∈x′\x
such that x′=x\g∪g′and|g|=|g′|=K.
We condition on the events A1=YandE1=Y, meaning
sx(y|A1) =( N
q−1ify⊆x
0 otherwiseand sx′(y|E1) =( N
q−1ify⊆x′
0 otherwise.
Coupling. We now define a coupling via γ:Y1+1→R+that define the following generative
process: We first define y(1)by sampling a batch of size qfrom xwithout replacement. We then
remove all elements that are in gand insert an equal number of elements, which are chosen uniformly
at random from g′. This coupling can be formally defined as
γ(y(1), y(2)) =(
sx(y(1)|A1)· K
|y(1)∩g|−1ify(1), y(2)fulfills Condition H.8, .
0 otherwise.
Condition H.8. A tuple y(1)∈Y,y(2)∈Yfulfills this condition when there exists a ˜g⊆gsuch
thaty(2)=y(1)\g∪˜gand|y(2)∩˜g|=|y(1)∩g|.
Validity. We now show that this constitutes a valid coupling. Consider any y(1)withsx(y(1)|A1)>
0and|y(1)∩g|=k. There are exactly K
k
different y(2)for which γ(y)is non-zero, and each one
has the same probability. Thus,
X
y(2)∈Yγ(y) =K
k
·sx(y(1)|A1)·K
k−1
=sx(y(1)|A1).|x−1|
q
.
The other case is analogous.
Compatibility. Evidently, this is a dY-compatible coupling, because (a) whenever y(1)contains k
elements from g, it has a distance of kfrom sx′(y|E1)and (b) whenever y(1)contains kelements
from g, we generate y(2)by substituting exactly kelements.
It thus follows from Corollary F.7 that
∆α(mx||mx′)≤X
ysx(y(1)|A1)κα(y(1))
with
κα(y(1)) = max
y,y′∆α(by||by′)s.t.dY(y, y′)≤ |y(1)∩g|.
The result then follows from the definition of induced distance, the definition of the K-fold
substitution relation ≃K∆,Xand the fact that |y(1)∩g|is a random variable with distribution
HyperGeom( N, K, q ).
Note that [ 40] instantiate this result with Gaussian mechanisms with sensitivity C, for which
max y≃k∆,Yy′∆α(by||by′) = exp( α·(α−1)·k2C2
σ2).
In Appendix B.1.4, we experimentally demonstrate that this result can improve upon the baseline of
combining [ 28] with the traditional group privacy property, but is not sufficiently tight to consistently
outperform it across a wide range of parameters. This emphasizes the benefit of considering optimal
transport between proper conditional distributions when deriving amplification guarantees.
55I Novel RDP guarantees
Now that we have a framework that enables generic subsampling analysis for Rényi differential pri-
vacy, we can derive a variety of novel guarantees that were previously only available for approximate
differential privacy.
In the following, we first demonstrate that RDP guarantees for a dataset relation ≃Xcan be derived
from a base mechanism that is only known to be RDP under a different batch relation ≃Y, i.e.,
“hybrid neighboring relations” [ 15]. We then show that we can derive RDP guarantees for non-
standard combinations of subsampling schemes and neighboring relations, such as subsampling
without replacement and insertion/removal. Finally, we derive a simple, tight mechanism-specific
subsampling guarantee for randomized response. We use this guarantee in Section 4 to demonstrate
the limitations of using mechanism-agnostic RDP bounds instead of mechanism-specific RDP bounds.
For this section, recall again that Λαis not the Rényi divergence, but its αth moment, i.e., a scaled
and exponentiated Rényi divergence (see Definition D.8).
I.1 Hybrid neighboring relations
Hybrid neighboring relations have thus far not been discussed in the context of Rényi-DP. Analyzing
such scenarios may be particularly useful when the dataset space Xand the batch space (Y,Y)are
different from each other, e.g., when mapping from large text corpora to short sequences of token
embeddings. Note that hybrid relations may also be useful for noisy stochastic gradient descent with
fixed batch sizes (see end of Appendix I.2).
As an example, we consider the following scenario: Subsampling without replacement, with sub-
stitution relation ≃∆,Xfor datasets and insertion/removal relation ≃±,Yfor batches. The proof is
largely identical to that of Theorem H.1, but uses the fact that a substitution can be represented by an
insertion, followed by a removal.
Theorem I.1. LetM=B◦Sbe a subsampled mechanism, where Sis subsampling without
replacement with batch size q. Let≃Ybe the insertion/removal relation ≃±,Yand≃Xbe the
substitution relation ≃∆,X. Then, for α >1and all x≃∆,Xx′of size N,
Λα(mx||mx′)≤max
yΛα((1−w)·by(1)
1+w·by(1)
2||(1−w)·by(2)
1+w·by(2)
2)
withy∈Y2+2subject to y(1)
1=y(2)
1,d±,Y(y(1)
1, y(1)
2)≤2,d±,Y(y(1)
1, y(2)
2)≤2,d±,Y(y(1)
2, y(2)
2)≤
2, and with w=q / N .
Proof. Consider arbitrary x≃∆,Xx′. By definition of ≃∆, there must be some a∈x,a′∈x′such
thatx′=x\ {a} ∪ {a′}. We thus define both A1andE1from Theorem E.2 to be the event that
neither anora′is sampled, i.e., A1=E1={y∈Y|y∩ {a, a′}=∅}. We further define A2and
E2to be the event that aora′is sampled, i.e., A2=A1andE2=E1.
By definition of subsampling without replacement, we have
PSx(A1) =PSx′(E1) = HyperGeom(0 |N,1, q) = 1−q
N,
PSx(A2) =PSx′(E2) = HyperGeom(1 |N,1, q) =q
N,
which corresponds to the weights (1−w)andw, respectively.
Coupling. We now define a coupling via γ:Y4→R+:
γ(y(1),y(2)) =(
sx(y(1)
1|A1)·1
qify(1),y(2)fulfill Condition H.2,
0 otherwise.
Condition H.2. A tuple y(1)∈Y2,y(2)∈Y2fulfills this condition when y(2)
1=y(1)
1and
∃˜a∈y(1)
1:
y(1)
2=y(1)
1\ {˜a} ∪ {a} ∧y(2)
2=y(1)
1\ {˜a} ∪ {a′}
.
56As explained before, γdefines the following generative process: We first generate y(1)
1by sampling a
batch that does not contain auniformly at random from x. We then let y(2)
1←y(1)
1Finally, we pick a
random element ˜aofy(1)
1and replace it with aanda′to generate y(1)
2andy(2)
2, respectively. Note
that each of these substitution corresponds to exactly one insertion and one removal.
Validity. The validity of this coupling has already been demonstrated in our proof of Theorem H.1,
since validity of a coupling does not depend on batch neighboring relation ≃Y.
Compatibility. We can thus focus on showing that γis adY-compatible coupling (see Appendix F).
Whenever γ(y)>0, then
dY(y(1)
1, y(1)
2) =dY
y(1)
1,supp( sx(· |A2))
= 2,
dY(y(1)
1, y(2)
1) =dY
y(1)
1,supp( sx′(· |E1))
= 0,
dY(y(1)
1, y(2)
2) =dY
y(1)
1,supp( sx′(· |E2))
= 2.
We see that the pairwise distances between all yt, yuwithu > t > 1are identical to the distance
of their respective supports: The batches have a distance of 2because one can transform one into
another using a single substitution, i.e. an insertion and a removal. The supports also have a distance
of2because one can transition from one to another using a single substitution.
The result then immediately follows from Corollary F.7.
If we wanted to express this result in terms of the Rényi-DP parameters of the base mechanism, we
could go through the same derivations as in our proof of Proposition H.4 to show that
Λα(mx||mx′)≤1 + 2αX
l=2α
l
wl
max
y,y′Λl(by||by′)s.t.d±,Y(y, y′)≤2
,
withw=q / N . The inner term can, for instance, be evaluated using the traditional group privacy
property from [31].
I.2 Subsampling without replacement under insertion/removal
To demonstrate that our framework is not limited to analyzing the usually considered combination of
subsampling without replacement and substitution or Poisson subsampling and insertion/removal,
we consider the following non-standard combination: Subsampling without replacement and inser-
tion/removal.
We show that we can derive a guarantee that is qualitatively similar to that of [ 30], while preserving a
fixed batch size. Such results could be useful when implementing noisy stochastic gradient descent in
deep learning frameworks with static computation graphs, where the variable batch sizes resulting
from Poisson subsampling may be problematic. However, note that this guarantee only guarantees
privacy for spaces of datasets whose elements are larger than some Q∈NwithQ > q , where q is
the batch size.
For the following proof, we condition on the same events as in our proof of Proposition H.6, but need
to construct a different dY-compatible coupling, since we have a different subsampling distribution.
Theorem I.2. Assume a dataset space and batch space defined by X⊆ {x∈ P(A)| |x|> Q},
Y={y⊆x|x∈X,|y|=q},Y=P(Y)and finite set A, with Q, q∈NandQ > q . Let
M=B◦Sbe a subsampled mechanism, where Sis subsampling without replacement with batch
size q r. Let≃Ybe the insertion/removal relation ≃±,Y. Then, for α >1and all x≃±,Xx′,
Λα(mx||mx′)≤max
N∈N 
2·αX
l=0α
l
wl(1−w)α−l
max
y,y′Λl(by||by′)s.t.dY(y, y′)≤2!
subject to N > Q and with w=q / N .
Proof. Like in our proof of Proposition H.6, we need to distinguish between insertion and removal.
57Case 1: Removal. In this case, there is some a∈xsuch that x′=x\ {a}. We define N=|x′|,
which fulfills N > Q by definition of dataset space X.
We let A1be the event that ais not sampled, i.e. A1={y∈Y|a /∈y}, and let A2=A1. We let
E1=Y, i.e., do not condition on any particular event.
By definition of subsampling without replacement, we have PSx(A1) = 1−qN,PSx(A2) =q / N ,
andPSx′(E1) = 1 . We further have
sx(y|A1) =( N
q−1ify⊆x∧a /∈y
0 otherwise, s x(y|A2) =( N
q−1−1ify⊆x∧a∈y
0 otherwise,
and
sx′(y|E1) =( N
q−1ify⊆x′
0 otherwise.
Note that sx(y|A1) =sx′(y|E1)and that all three conditional distribution are subsampling
without replacement from sets of size N, not of size N+ 1orN−1. Further note that, for event A1,
we only need to sample q−1elements, since one element is always fixed to be a.
Coupling. We now define a coupling via γ:Y2+1→R+:
γ(y(1),y(2)) =(
sx(y(1)
1|A1)·1
qify(1)
1=y(2)
1∧y(1)
2=y(1)
1∪ {a}
0 otherwise.
Simply put, γdefines the following generative process: We first generate y(1)
1by sampling a batch
that does not contain avia subsampling without replacement from x\ {a}. We then let y(2)
1←y(1)
1.
We then randomly replace one of the qbatch elements with ato generate y(1)
2.
Validity. We can verify the validity of this coupling as follows: For every y(1)
1withsx(y(1)
1|
A1)>0, there are exactly qcombination y(1)
2, y(2)
1for which γ(y)>0. We thus haveP
y(1)
2,y(2)
1∈Y2γ(y(1)
1, y(1)
2, y(2)
1) =sx(y(1)
1|A1).The proof for y(2)
1is analogous.
For every y(1)
2, there are exactly N−(q−1)combinations of y(1)
1, y(2)
1for which γ(y)>0. This is
because amust have replaced one of the N−(q−1)elements of x′that are not in y(2)
1.
We thus have
X
y(1)
1,y(2)
1∈Y2γ(y(1)
1, y(1)
2, y(2)
1)
=(N−(q−1))·N
q−1
·1
q=q
N−q+ 1·N
q−1
=N
q−1−1
.
Compatibility. Finally, it can be easily shown that γis adY-compatible coupling. Whenever
γ(y)>0, then
dY(y(1)
1, y(1)
2) =dY
y(1)
1,supp( sx(· |A2))
= 2,
dY(y(1)
1, y(2)
1) =dY
y(1)
1,supp( sx′(· |E1))
= 0.
Similarly, the pairwise distance between y(1)
2andy(2)
1is always 2. This is identical to the distance of
their supports, because one can always transition between them via a substitution, i.e., an insertion
and a removal.
It thus follows from Corollary F.7 that
Λα(mx||mx′)≤ max
y(1)
1,y(1)
2,y(2)
1Λα((1−q / N )·by(1)
1+q / N·by(1)
2||by(2)
1)
s.t.d±,Y(y(1)
1, y(1)
2)≤1, y(1)
1=y(2)
1, d±,Y(y(1)
2, y(2)
1)≤2
58As in our proof of Proposition H.6 one can use the definition of Λαand binomial expansion to finally
show that
Λα(mx||mx′)≤αX
l=0α
l
wl(1−w)α−l
max
y,y′Λl(by||by′)s.t.dYy, y′≤2.
withw=q / N . Note that this is smaller than the term in Proposition H.6 by a factor of 2.
Case 2: Insertion In this case, there is some a∈x′such that x=x′\ {a}. We can thus define the
same events and the same coupling in a symmetric manner to show
Λα(mx||mx′)≤max
y,y′(1−w)Z
Z(1 +w)by(z)−wby′(z)
by(z)α
by(z) dλ(z)
+wZ
Z(1−w)by′(z) +wby(z)
by′(z)α
by′(z) dλ(z),
subject to dY(y, y′)≤2. with w=q / N . Again, this corresponds exactly to Eq. 6 of the “novel
alternative decomposition” in Appendix A.1 of [ 30]. One can then through the remaining steps in
their Appendix A to show that this term is at most two times larger than the one we derived in the
deletion case.
Finally, since this bound depends on N, and we want the guarantee to hold for all x≃±,Xx′, we
need to determine the Nthat maximizes the bound.
Hybrid Relations. Note that we could have also gone through the above derivations with batch
substitution relation ≃∆,Y. Then, each substitution would correspond to an actual substitution, instead
of a pair of insertion and deletion, and we would obtain
Λα(mx||mx′)≤max
N∈N 
2·αX
l=0α
l
wl(1−w)α−lmax
y≃∆,Yy′Λl(by||by′)!
s.t.N > Q,
withw=q / N .
I.3 Tight mechanism-specific subsampling without replacement for randomized response
As mentioned earlier, the following result is meant as a simple example to demonstrate the benefit of
using mechanism-specific over mechanism-agnostic RDP bounds in Section 4. For the following
discussion, recall Theorem H.1, which we proved in the previous section.
Theorem H.1. LetM=B◦Sbe a subsampled mechanism, where Sis subsampling without
replacement with batch size q. Let≃Ybe the substitution relation ≃∆,Y. Then, for α >1and all
x≃∆,Xx′of size N,
∆α(mx||mx′)≤max
ˆy∆α((1−w)·by(1)
1+w·by(1)
2||(1−w)·by(2)
1+w·by(2)
2)
subject to d∆,Y(y(1)
1, y(1)
2)≤1,d∆,Y(y(1)
1, y(2)
2)≤1,d∆,Y(y(1)
2, y(2)
2)≤1,y(1)
1=y(2)
1, and with
w=q / N .
We shall now solve Theorem H.1 for randomized response and prove the tightness of the resultant
guarantee.
Theorem I.3. LetBbe the randomized response mechanism |h−(1−V)|withh:Y→ {0,1},
V∼Bern( θ), and true response probability θ∈[0,1]. LetSbe subsampling without replacement
with batch size q. Then, for all x≃∆,Xx′of size N,Λα(mx||mx′)is l.e.q.
max
τΛα((1−w)Bern( · |θ) +wBern(· |τ)||(1−w)Bern( · |θ) +wBern(· |1−τ))
subject to τ∈ {θ,1−θ}and with w=q / N .
Proof. Because we have no further information, we must consider the worst possible underlying
function h:Y→ {0,1}.
59Due to the last constraint in Theorem H.1, we must have h(y(1)
1) =h(y(2)
1). Due to symmetry in
Λα(we are summing over z∈ {0,1}), we can assume w.l.o.g. that h(y(1)
1) =h(y(2)
1) = 1 and thus
by(1)
1(z) =by(1)
1(z) = Bern( z|θ).
Because the batches y(1)
2andy(1)
2can differ from y(1)
1, we can choose the corresponding function
values h(y(1)
2)andh(y(2)
2)arbitrarily. To make Λαgreater than 1, the two mixtures must be different
from each other. Thus, we must choose either h(y(1)
2) = 1 andh(y(2)
2) = 0 , orh(y(1)
2) = 0 and
h(y(2)
2) = 1 . This corresponds to by(1)
2(z) = Bern( z|τ)andby(2)
2(z) = Bern( z|1−τ)with
τ∈ {θ,1−θ}. Maximizing over both options yields our result.
Note that this guarantee can be evaluated in O(1): We need to iterate over two possible values of τ,
and evaluating the corresponding Λαrequires summing over two values z∈ {0,1}.
Next, we prove the mechanism-specific tightness of this result, meaning it is not possible to de-
rive stronger guarantees without additional information about dataset space Xand the function h
underlying the randomized response mechanism.
Theorem I.4. LetSbe subsampling without replacement with arbitrary batch size q∈Nand
θ∈[0,1]be some true response probability. There exists a dataset space Xand a batch space
(Y,Y)fulfilling the constraints in Definition D.5, as well a pair of datasets x≃∆,Xof size N, and a
function h:Y→ {0,1}, such that the corresponding subsampled randomized response mechanism
M=B◦Sfulfills
Λα(mx||mx′)
= max
τΛα((1−w)Bern( · |θ) +wBern(· |τ)||(1−w)Bern( · |θ) +wBern(· |1−τ))
subject to τ∈ {θ,1−θ}and with w=q / N .
Proof. LetX={x⊆N| |x|> q}. Consider an arbitrary x∈Xand select arbitrary elements a∈x,
a′∈N\x. Define x′=x\ {a} ∪ {a′}.
Assume w.l.o.g. that the divergence is maximized by τ=θ. We now construct an indicator function
h:Y→ {0,1}foraanda′that leads to the largest possible divergence.
h(y) =

1ify∩ {a, a′}=∅
1ifa∈y
0ifa′∈y
By construction of h, the corresponding base mechanism pmf is
by(z) =

Bern( z|θ) ify∩ {a, a′}=∅
Bern( z|θ) ifa∈y
Bern( z|1−θ)ifa′∈y
Under the distribution of S(x), the first case occurs with probability 1−wand the second case occurs
with probability w. Under the distribution of S(x), the first case occurs with probability 1−wand
the second case occurs with probability w. We thus have
mx(z) = (1 −w)Bern( z|θ) +wBern( z|θ),
mx′(z) = (1 −w)Bern( z|θ) +wBern( z|1−θ),
which exactly attains the desired divergence when τ=θis the optimal value.
60J From mechanism-specific guarantees to dominating pairs
Our proposed optimal transport approach lets us derive mechanism-specific guarantees, which upper-
bound the hockey stick divergence between the distribution of M(x)andM(x′)withx≃Xx′via a
weighted sum5of mixture divergences, i.e.,
Hα(mx||mx′)≤KX
k=1w(x,x′)
α,k·Hα(p(x,x′)
α,k||q(x,x′)
α,k) (23)
Here, the w(x,x′)
α,k are weights withPK
k=1w(x,x′)
α,k= 1, which depend on the chosen coupling γ
and are indexed by α≥0,1≤k≤K, and x, x′∈X. The p(x,x′)
α,k andp(x,x′)
α,K are densities of
mixture distributions P(x,x′)
α,kandq(x,x′)
α,K on the output space RD,6which are also indexed by α≥0,
1≤k≤K, and x, x′∈X.
Our goal is to construct dominating pairs from such bounds, so that we can then use them for privacy
accounting. For this discussion, recall the definition of dominating pairs:
Definition 2.3. A pair of distributions (P, Q)with densities (p, q)is a dominating pair for mechanism
Munder neighboring relation ≃X, ifHα(mx||mx′)≤Hα(p||q)for all x≃Xx′and all α≥0.
If the densities on the r.h.s. of Eq. (23) are constant in α,k,x, andx′, i.e.., p(x,x′)
α,k= ˜pandq(x,x′)
α,k= ˜q
with some densitities ˜p,˜q, then we can immediately identify that the corresponding distributions
˜Pand˜Qare a dominating pair. For instance, in Section 3.4 we could immediately determine that
the two Gaussian mixtures in Theorem 3.8 are a dominating pair for Poisson subsampling and the
“insert- K+-remove- K−” relation.
However, this is generally not the case. In the following, we discuss a three-step procedure that
let us (1) reduce the weighted sum of divergences in Eq. (23) to a single divergence (2) resolve
non-constancy in the dataset pairs (x, x′), and (3) resolve non-constancy in the divergence order α.
Note that, depending on the considered setting, it may be possible to skip one or multiple of these
steps (like in our group privacy example).
J.1 Step 1: Eliminating weighted sums
Consider some fixed order αand fixed datasets x≃Xx′. Let us thus omit the corresponding indexes.
In this step, we construct a pair of distributions ˜P,˜Qwith densitities ˜pand˜qsuch that
KX
k=1wk·Hα(pk||qk) =Hα(˜p||˜q).
To achieve this, we notice that there is no requirement for dominating pairs to be distributions on the
same space RD. Taking inspiration from hierarchical randomized smoothing [ 69], we thus construct
˜pand˜qthat are mixtures of the pkandqkand additionally release their component indices:
Lemma J.1. Consider arbitrary densitities p1, . . . , p K, q1, . . . , q K:RD→R+and arbitrary
weights w1, . . . , w K∈[0,1]withPK
k=1wk= 1. Further let r:{1, . . . , K } → [0,1]be the
probability mass function of Categorical( w1, . . . , w K). Define ˜p,˜q:RD× {1, . . . , K } →R+as
˜p(z, k) =pk(z)·r(k)and˜q(z, k) =qk(z)·r(k). Then, Hα(˜p||˜q) =PK
k=1wk·Hα(pk||qk).
5assuming that the batch space is finite and discrete
6the arguments in this section also apply to the general problem setting from Appendix D, where we allow
arbitrary output spaces
61Proof. By the definition of hockey stick divergence and ˜p,˜q, we have
Hα(˜p||˜q) =KX
k=1Z
RDmax˜p(z, v)
˜q(z, v),0
·˜q(z, v) dz
=KX
k=1Z
RDmaxpk(z)·r(k)
qk(z)·r(k),0
·qk(z)·r(k) dz
=KX
k=1r(k)·Z
RDmaxpk(z)
qk(z),0
·qk(z) dz
=KX
k=1wk·Hα(pk||qk).
Note that one could equivalently construct continuous distributions ˜Pand˜Qby defining the categori-
cal distribution as a transformation of a uniform distribution. Further note that the distribution of
privacy loss random variable log(˜p(Z)/˜q)withZ∼˜Pis simply a weighted sum of the components’
privacy loss distributions, which can be easily shown via law of total probability. This makes this
construction amenable to numerical privacy accounting.
J.2 Step 2: Resolving non-constancy in dataset pairs
After applying the construction from the previous step, we have bounds of the form Hα(mx||mx′)≤
Hα(˜p(x,x′)
α||˜q(x,x′)
α). If these bounds are not constant in the datasets x, x′∈X, we cannot simply
read off a dominating pair.
However, the ultimate goal behind identifying dominating pairs is to use them in a privacy accounting
method to algorithmically derive guarantees for all possible pair x≃Xx′under composition.
Providing guarantees for all possible pair does not require that we derive guarantees for all pairs
simultaneously. To formalize this, recall that the neighboring relation ≃Xis a set of tuples from X2.
Lemma J.2. Consider any α≥0, mechanism MandLdifferent neighboring relations ≃(1)
, . . . ,≃(L)⊆X2. Assume that there are Lconstants c(1), . . . , c(L)such that Hα(mx||mx′)≤c(l)for
alll∈ {1, . . . , L }and all x≃(l)x′. If the neighboring relations partition ≃X, i.e.,≃X=SL
l=1≃(l),
then
∀x≃Xx′:Hα(mx||mx′)≤max
lc(l).
Proof. Consider any x≃Xx′. Because the neighboring relations partition ≃X, there must be some
l∗such that x≃(l∗)x′and thus Hα(mx||mx′)≤c(l∗)≤max lc(l).
For the purposes of privacy accounting, it is thus sufficient to determine some sufficiently fine-grained
partition ≃(1), . . . ,≃(L)such that for all l∈ {1, . . . , L }and all α≥0
∀x≃(l)x′:Hα(˜p(x,x′)
α||˜q(x,x′)
α) =Hα(ˆp(l)
α||ˆq(l)
α),
where ˆpl
αandˆq(l)
αare families of densities indexed by partition index land divergence order α. One
can then perform privacy accounting independently for each of the relations.
This goal can always be achieved by having one atomic relation per possible pair of neighboring
elements. In practice, however, much more coarse-grained partitions may be sufficient. Zhu et al.
[10] applied this ansatz to the insertion/removal relation, by deriving dominating pairs for insertion
and removal separately. In our work, we partition the group insertion/removal relation for groups of
sizeKintoK+ 1different “insert- K+-remove- K−” relations with K++K−=K.
62J.3 Step 3: Resolving non-constancy in divergence order
Consider some fixed partition index l∈ {1, . . . , L }, which we omit in the following. We are now left
with a bound of the form ∀x≃x′:Hα(mx||mx′)≤Hα(ˆpα||ˆqα). If the families of densitities ˆpα,
ˆqαis constant in α, i.e.
∀α:Hα(ˆpα||ˆqα) =Hα(ˇp||ˇq),
with some ˇp,ˇq, then the corresponding distributions ˇP,ˇQare dominating pairs. Importantly, the
numeric value of the bound can vary with α. We just want the numeric value to be identical to the
divergence Hαof two specific distributions for all α.
If this is not the case, there are two options to construct a dominating pair. The first option uses a
characterization of dominating pairs as a function of privacy profiles. It was applied by Zhu et al.
[10] to determine dominating pairs for subsampling without replacement and the substitution relation.
The second option is enabled by our novel optimal transport and constrained optimization perspective
on subsampling.
J.3.1 Option 1: Convex conjugation of privacy profiles
The following result from [ 10] establishes a correspondence between privacy profiles and dominating
pairs, as well as providing a formula for constructing dominating pairs from privacy profiles:
Proposition J.3 (Zhu et al. [10]).For a given f:R+→R, there exists ˇP,ˇQsuch that ∀α≥0 :
H(α) =Hα(P, Q)if and only if f∈ F where
F={f:R+→R|fis convex, decreasing, f(0) = 1 andf(x)≥max{1−x,0}}. (24)
Moreoever, one can explicitly construct such PandQ:PhasCDF 1 +f∗(x−1)in[0,1)and
Q= Uniform([0 ,1]), where f∗is the convex conjugate of f.
Next, we show how to construct a function f(α)∈ F from our families of densities ˆqα,ˆqαindexed
byαthat allows us to determine dominating pairs.
Lemma J.4. Consider two families of densities ˆpα,ˆqαindexed by α≥0such that ∀x≃x′:
Hα(mx||mx′)≤Hα(ˆpα||ˆqα). Define the function f:R+→Rwith
f(α) = max
β≥0Hα(ˆpβ||ˆqβ).
Then fis a valid privacy profile, i.e., f∈ F withHdefined in Eq. (24).
Proof. For every β≥0, letfβ(α) =Hα(ˆpβ||ˆqβ)be the privacy profile associated with a specific
pair from the considered families. All these functions are elements of Fas per the first part
of Proposition J.3. We thus know that each fβis convex, decreasing, and has value 1atα= 0.
Naturally, their maximum is also convex, decreasing, and has value 1atα= 0. We further know that,
for all β≥0,fβ(x)≥max{1−x,0}. Thus, we have f(x)≥fβ(x)≥(1−x)for any β≥0.
We can then invoke the second part of Proposition J.3 to define our dominating pair.
As mentioned earlier, Zhu et al. [10] applied this principle to subsampling without replacement by
taking a maximum over two different pairs of distributions. Lemma J.4 generalizes this principle to
larger families.
J.3.2 Option 2: Relaxation of cost function constraints
A novel solution is enabled by our proposed framework for deriving mechanism-specific subsampling
guarantees: Recall that the densitities ˆpαandˆqαare the result of identifying worst-case mixture com-
ponents under pairwise batch distance constraints (Proposition 3.5). In Appendix L, we demonstrate
that it is possible to relax some of these constraints to obtain a single pair of densitities that bounds
Hα(mx||mx′for all αand pairs of datasets x≃x′. Specifically, we apply this principle to the
substitution relation and subsampling without replacement, as well as subsampling with replacement.
Due to the relaxation, these dominating pairs are not necessarily tight. They may however be easier
to use in practice than convex conjugation, which requires solving an optimization problem.
63K Recovering known dominating pairs
In this section, we demonstrate that known dominating pairs for the standard combinations of Poisson
subsampling under insertion/removal and subsampling without replacement under substitution, as
well as subsampling without replacement under insertion/removal, can also be derived via our
proposed optimal transport framework.
As before, our contribution are not the guarantees themselves. Our contribution is identifying that,
just like mechanism-agnostic guarantees for ADP and RDP, these guarantees can be derived by
defining an (optimal) coupling and then identifying worst-case mixture components under pairwise
batch distance constraints.
K.1 Poisson subsampling and insertion/removal
As discussed in Appendix J, it is beneficial to partition the insertion removal ≃±,Xinto two relations:
The insertion relation ≃+,X, where x≃+,Xx′implies that there is some a /∈xsuch that x′=x∪{a}
and the removal relation ≃−,X, where x≃−,Ximplies that there is some a∈xsuch that x′=x\{a}.
While we could derive dominating pairs for both relations from scratch, we can use the following
result from [10] to reduce our workload:
Lemma K.1. If distributions (P, Q)are a dominating pair for mechanism Munder the insertion
relation ≃+, then (Q, P)are a dominating pair under the removal relation ≃−.
Next, we use our proposed framework to derive the following guarantee in a very natural manner that
does not require reasoning about tradeoff functions and optimal testing rules (c.f. proof of Lemma 29
in [10]).
Proposition K.2 (Zhu et al. [10]).Consider a subsampled mechanism M=B◦S, where Sis
Poisson subsampling with subsampling rate r∈[0,1]. assume that (P, Q)are a dominating pair
for base mechanism Bunder the batch insertion relation ≃+,Y. Then, (P,(1−r)P+rQ)are a
dominating pair for Munder the dataset insertion relation ≃+,Xand((1−r)P+rQ, Q )are a
dominating pair for Munder the dataset removal relation ≃−,X.
Proof. We begin by deriving the dominating pair for the removal relation ≃−,X. Consider an arbitrary
pairx≃−x′and an arbitrary α≥0. Recall from our proof of the mechanism-agnostic Poisson
subsampling guarantee Proposition H.6 that we can construct a dY-compatible coupling to show that
Hα(mx||mx′)≤max
yHα((1−r)by(1)
1+rby(1)
2||by(2)
1)
subject to y∈Y2+1,y(1)
1=y(2)
1,dY(y(1)
2, y(1)
1)≤1,dY(y(1)
1, y(1)
2)≤ ∞ .
The last constraint is because there is no sequence of deletions that will result in an insertion. It can
be ignored, meaning our optimization problem is equivalent to
max
y≃−y′Hα((1−r)by′+rby||by′).
Using the definition of hockey stick divergence,7this can be restated as
max
y≃−y′Hα((1−r)by′+rby||by′)
= max
y≃−y′Z
RDmax(1−r)by′(z) +rby(z)
by′(z)−α,0
·by′(z) dz
= max
y≃−y′Z
RDmax
(1−r) +rby(z)
by′(z)−α,0
·by′(z) dz
= max
y≃−y′r·Z
RDmaxby(z)
by′(z)−
α−1−r
r
,0
·by′(z) dz
7For simplicity, we assume that we have continuous-valued mechanisms, but the same proof strategy can
also be used for the more general definition of hockey stick divergence from Appendix D by calculating
d((1−r)PBy′+rPBy)/dPBy′.
64We can now distinguish two cases, based on the value of α‘ =α−(1−r)/ r.
Case 1: Assume that α′<0. Then, the integrand is always non-negative, and the objective function
evaluates to a constant r(1−a′). We can thus choose y, y′arbitrarily, because
max
y≃+y′Hα((1−r)by′+rby||by′) =r(1−a′) =Hα((1−r)q+rp||q),
where pandqare the densities of dominating pair (P, Q).
Case 2: Assume that α′≥0. Because (P, Q)is a dominating pair for the batch insertion relation
≃+,Y, we know from Lemma K.1 that (Q, P)is a dominating pair for the batch removal relation
≃−,Y. Thus
max
y≃−y′Hα((1−r)by′+rby||by′)
= max
y≃−y′r·Hα′(by||by′)
≤r·Hα′(q||p)
=Hα((1−r)p+rq||q)
This shows that ((1−r)P+rQ, Q )is a dominating pair for the removal relation ≃−,X. It then
follows from Lemma K.1 that (Q,(1−r)P+rQ)is a dominating pair for the insertion relation
≃+,X.
Note that case 1 (but not case 2) of Theorem 11 in [ 10] states that ((1−r)Q+rP, P )were a
dominating pair for the removal relation. This does however appear to be a typographical error, since
the authors use the same symmetry argument (Lemma K.1) for their proof.
K.2 Subsampling without replacement and insertion/removal
The proof for the following result is virtually identical to the previous one. They only differ in the
coupling which we need to construct, which again highlights the generality and usefulness of our
proposed framework.
Proposition K.3 (Zhu et al. [10]).Assume a dataset space and batch space defined by X⊆ {x∈
P(A)| |x| ∈ {N, N−1},Y={y⊆x|x∈X,|y|=q}, and finite set A, with q < N . Consider
a subsampled mechanism M=B◦S, where Sis subsampling without replacement with batch
sizeq, and define batch-to-dataset ratio w=q / N . assume that (P, Q)are a dominating pair for
base mechanism Bunder the batch substitution relation ≃∆,Y. Then, (P,(1−w)P+wQ)are a
dominating pair for Munder the dataset insertion relation ≃+,Xand((1−w)P+wQ, Q )are a
dominating pair for Munder the dataset removal relation ≃−,X.
Proof. As in the previous proof, we begin with removal relation ≃−,X. Consider an arbitrary pair
x≃−x′and an arbitrary α≥0. Recall from our novel proof of the mechanism-agnostic RDP
guarantee for subsampling without replacement and insertion/removal (see Theorem I.2) that we can
construct a dY-compatible coupling to show that
Hα(mx||mx′)≤max
yHα((1−w)by(1)
1+wby(1)
2||by(2)
1)
subject to y∈Y2+1,y(1)
1=y(2)
1,dY(y(1)
2, y(1)
1)≤1,dY(y(1)
1, y(1)
2)≤1.
By definition of the induced distance, this optimization problem is equivalent to
max
y≃∆y′Hα((1−r)by′+rby||by′).
We can now go through exactly the same steps as in our derivation of Proposition K.2, replacing
every occurrence of “ ≃−” with “ ≃′′
∆, to conclude our proof.
K.3 Subsampling without replacement and substitution
In the case of subsampling without replacement and substitution (as well as Poisson subsampling
and insertion/removal without partitioning of the neighboring relation) we do not need to provide a
65new proof. This is because Zhu et al. [10] prove this result by invoking a tight mechanism-agnostic
subsampling guarantee derived by Balle et al. [15] and then applying advanced joint convexity in
reverse order (see proof of Proposition 30 in [10]).
As we discussed in Appendix G.2 and formalized in Theorem G.2, any guarantee that is derived via
the framework from [ 15] can be equivalently derived by defining a (potentially suboptimal) coupling
between multiple conditional subsampling distributions. Thus, we know that the guarantee could
have equivalently been derived via our proposed framework
Proposition K.4 (Zhu et al. [10]).Consider a subsampled mechanism M=B◦S, where Sis
subsampling without replacement with batch size q∈N. Assume that (P, Q)are a dominating pair
for base mechanism Bunder the batch substitution relation ≃∆,Y. Consider arbitrary x≃∆,Xx′of
sizeNand define batch-to-dataset ratio w=q / N . Then
Hα(mx||mx′)≤Hα((1−w)q+wp||q) forα≥1
Hα(p,(1−w)p+wq||q)for0< α < 1
Note that this result does not immediately specify a dominating pair. However, as shown in [ 10], one
can construct a dominating pair via convex conjugation (recall Appendix J.3.1 and Proposition J.3).
66L Novel results for dominating pairs
In the following, we formally derive dominating pairs for subsampling with replacement under
the substitution relation. We also derive an alternative dominating pair for subsampling without
replacement under substitution which does not require convex conjugation (c.f. Appendix K.3). These
results are novel in three respects.
Novel contribution 1 – Formal guarantees. Using the dominating pairs we shall shortly derive
for privacy accounting was already proposed in [ 8]. However, the authors did not provide a formal
proof for why they should lead to valid privacy guarantees. They only proved that if two pairs of
multivariate Gaussians with colinear means were to be a dominating pair8, then one could use a
change of variable and marginalization to reduce them to a univariate dominating pair (see Appendix
B.1 in [ 8]). They did not prove why this assumption should hold. A formal proof of this assumption
is now enabled by the analysis we conducted for solving the group privacy optimization problem
in Theorem M.6 (see Appendix O).
Novel contribution 2 – Other base mechanisms. The generality of our solution to the group
privacy optimization problem in Theorem M.6 lets us not only derive dominating pairs for Gaussian
mechanisms, but also for Laplace mechanisms and randomized response.
Novel contribution 3 – Resolving non-constancy via constraint relaxation. Perhaps most impor-
tantly, our proposed framework offers a novel perspective on an issue encountered when analyzing
subsampling without replacement: While one can derive a tight mechanism-specific guarantee, this
guarantee depends on different mixture distributions for α <1andα≥1(see Proposition K.4 [ 10]
and our more general discussion in Appendix J.3). Thus, one cannot simply read off a dominating
pair from this mechanism-specific guarantee, as we did with our group privacy bounds. However,
as we shall demonstrate, this issue no longer appears when we relax some of the batch distance
constraints in our proposed cost function bound from Proposition 3.5. This suggests that this could
be a more general approach for addressing this non-constancy issue. While the resultant dominating
pairs are not necessarily tight, they may be easier to use in practice than the convex conjugation
construction from [10].
L.1 Subsampling without replacement and substitution
We begin with subsampling without replacement to demonstrate the potential benefit of relaxing
batch distance constraints to determine tractable dominating pairs.
Theorem L.1. LetM=B◦S, where Sis subsampling without replacement with batch size q, andB
is the Gaussian mechanism h+Vwithh:Y→RDandV∼ N(0, σ2ID). Define the ℓ2-sensitivity
L2= max y≃∆,Yy′||f(y)−f(y′)||2, where ≃∆is the substitution relation. Consider an arbitrary
dataset size N∈Nand define batch-to-dataset ratio w=q
N. Then, for any pair x≃∆,Xx′of size
N,
Hα(mx||mx′)≤Hα
f(1)
1·(1−w) +f(1)
2·w||f(2)
1·(1−w) +f(2)
2·w
, (25)
with univariate normal densities f(1)
i=N(· |(i−1), σ / L 2),f(2)
j=N(· | −(j−1), σ / L 2).
Proof. Recall from our proof of the mechanism-agnostic subsampling without replacement guaran-
tee Proposition H.4 that we can construct a dY-compatible coupling to show that
Hα(mx||mx′)≤max
yHα((1−w)by(1)
1+wby(1)
2||(1−w)by(2)
1+wby(2)
2)
subject to y∈Y2+1,y(1)
1=y(2)
1,dY(y(1)
1, y(1)
2)≤1,dY(y(1)
1, y(2)
2)≤1,dY(y(2)
1, y(2)
1)≤1.
Next, we relax the constraint between the two components that contain a substituted element:
dY(y(2)
1, y(2)
1)≤2.
We now observe that this optimization problem is identical to the optimization problem from our
group privacy bound (Theorem 3.7) with one insertion ( K+= 1), one deletion (K−= 1) , and
subsampling rate r=w. The result thus follows immediately from our mechanism-specific group
privacy amplification bound for Gaussian mechanism (Theorem 3.8).
8Technically, the notion of dominating pairs[ 10] had not been introduced at this point, which is why the
authors discuss a vaguer notion of “worst-case distributions”, similar to other early work on numerical accounting.
67We can generalize this result to other mechanisms by using group privacy amplification bounds for
Laplace mechanisms (Theorem M.2) and randomized response mechanisms (Theorem M.2).
We see that the upper bound in Eq. (25) depends on the same pair of mixture distributions for
allα≥0. Thus, this pair of mixture distributions is a dominating pair for subsampling without
replacement under substitution.
L.2 Subsampling with replacement and substitution
Next, we provide the first formal derivation of dominating pairs for subsampling with replacement.
In subsampling with replacement, a single element may appear in a batch multiple times. To formalize
this, we assume a dataset space X⊆ P(A)that is composed of sets (not multisets) of elements from
an underlying set A. We further assume a batch space Y⊆ P multi(A)that is composed of multisets
of elements from A. Given some y∈Y, we write ξy(a)for the number of times that aappears in y.
We further define the support of batch y∈Yassupp( y) ={a∈Y|ξy(a)≥0}.
Definition L.2. Subsampling with replacement with batch size qhas probability mass function
sx(y) = |x|+q−1
q−1for batches y∈Ywithsupp( y)⊆xand|y|=q.
Given this subsampling scheme, we can use optimal transport to derive the following constrained
optimization problem, which we shall then relax and solve:
Theorem L.3. LetM=B◦S, where Sis subsampling without replacement with batch size q, andB
is the Gaussian mechanism h+Vwithh:Y→RDandV∼ N(0, σ2ID). Define the ℓ2-sensitivity
L2= max y≃∆,Yy′||f(y)−f(y′)||2, where ≃∆is the substitution relation. Consider an arbitrary
dataset size N∈Nand define batch-to-dataset ratio w=q
N. Then, for any pair x≃∆,Xx′of size
N,
Hα(mx||mx′)≤max
yHα
q+1X
i=1by(1)
i·wi||q+1X
j=1by(2)
i·wj
,
subject to y∈Y(q+1)+( q+1),∀l, t, u :dY(y(l)
t, y(l)
u)≤ |t−u|,∀t, u:dY(y(1)
t, y(2)
u)≤max{t, u},
and with weights wi= 1
Ni· 
1−1
Nq−i.
Proof. By definition of the substitution relation ≃∆there is some a∈xwitha /∈x′and some
a′∈x′witha′/∈xsuch that x′=x\ {a} ∪ {a′}.
To simplify indexing, we define zero-based indexed events A0, . . . , A qandE0, . . . , E q. We define
Aito be the event that ais sampled itimes, i.e., ξy(a) =i. We define Ejto be the event that a′is
sampled jtimes, i.e., ξy(a′) =j.
By definition subsampling with replacement, we have PSx(Ai) =wi, and PSx(Ej) =wjwith
weights wi= 1
Ni· 
1−1
Nq−i.
For dataset size N, we have
sx(y|Ai) =( (N−1)+(q−i)−1
q−i−1ifsupp( y)⊆x∧ξy(a) =i
0 otherwise
=(
(1
N−1)q−i(q−i)!Q
˜a̸=a1
ξy(˜a)!ifsupp( y)⊆x∧ξy(a) =i
0 otherwise
and
sx′(y|Ej) =( (N−1)+(q−i)−1
q−i−1ifsupp( y)⊆x′∧ξy(a′) =j
0 otherwise
=(
(1
N−1)q−i(q−i)!Q
˜a̸=a′1
ξy(˜a)!ifsupp( y)⊆x′∧ξy(a′) =j
0 otherwise
Note that sx(y|A0) =sx′(y|E0). Further note that sx(y|Aq) = 1[supp( y) ={a} ∧ |y|=q]
andsx′(y|Eq) = 1[supp( y) ={a′} ∧ |y|=q].
68Coupling. We now define a coupling γ:Y(q+1)+( q+1)→R+that corresponds to the following
generative process: We first generate y(1)
qby constructing a batch of size qwhose elements are all
a. Beginning at i←q, we then iteratively generate y(1)
i−1from y(1)
i−1by replacing one instance of a
with an element ˜a∈x\athat is sampled uniformly at random. Finally, we construct the y(2)
jby
replacing every occurence of ainy(1)
jwitha′. More formally,
γ(y(1),y(2)) =(
1
N−1q
ify(1),y(2)fulfills Condition L.4
0 otherwise.
Condition L.4. A tuple y(1)∈Yq+1,y(q+1)∈YK++1fulfills this condition when ξy(1)
q(a) =
ξy(2)
q(a′) =qand∀i,∃˜α∈x\ {a}:y(1)
i−1=y(1)
i−1\ {a} ∪ { ˜a}and∀i,∀˜a /∈ {a, a′}) :ξy(1)
q(˜a) =
ξy(2)
q(˜a)andξy(1)
q(a) =ξy(2)
q(a′).
Validity. To verify the validity of this coupling, consider an arbitrary iand an arbitrary ysuch that
γ(y(1),y(2))>0. We know that there are (q−i)!Q
˜a̸=a1
ξy(˜a)!sequences of y(1)
q, y(1)
q−1, . . . , y(1)
i
that could have generated y(1)
i. We further know that there are
1
N−1i
possible sequences of
y(1)
i−1, . . . , y(1)
0that can be generated from y(1)
i. Ally(2)
jare deterministically determined by y(1)
j. We
thus haveX
y∈Y(q+1)+( q+1)1[y(1)
i=y]γ(y(1),y(2))
=(q−i)!Y
˜a̸=a1
ξy(˜a)!1
N−1i1
N−1q
=1
N−1q−i
(q−i)!Y
˜a̸=a1
ξy(˜a)!
=sx(y|Ai).
The proof for the y(2)
jis analogous.
Compatibility. Finally, it can be easily shown that γis adY-compatible coupling (recall Appendix F).
Whenever γ(y)>0, then
∀1≤i≤K−:dY(y(1)
0, y(1)
i) =dY
y(1)
0,supp( sx(· |Ai))
=i,
∀0≤j≤K+:dY(y(1)
0, y(2)
i) =dY
y(1)
0,supp( sx′(· |Ej))
=j
because we generate the y(1)
ifrom y(1)
0by substituting exactly ielements, and construct the y(2)
jby
substituting exactly jelements. Similarly, we have for the pairwise distances that do not involve y(1)
0
∀0< t < u ≤K−:dY(y(1)
t, y(1)
u) =dY(supp( sx(· |At),supp( sx(· |Au))) =|t−u|,
∀0< t < u ≤K−:dY(y(2)
t, y(2)
u) =dY(supp( sx′(· |Et),supp( sx′(· |Eu))) =|t−u|.
∀0≤t < u≤K−:dY(y(1)
t, y(2)
u) =dY(supp( sx(· |At),supp( sx′(· |Eu))) = max {t, u}.
The last equality holds for t≤ubecause to construct y(2)
ufrom y(1)
twe need to substitute all
occurrences of awitha′and then substitute u−tadditional elements with a′It also holds for t > u ,
because then we need to replace uoccurences of awitha′and then replace another t−uoccurences
with values other than a′.
Applying Corollary F.7, with PSx(Ai) =wi,PSx′(Ej) =wj, shows that
Finally, we can relax and solve Theorem L.3 for specific mechanisms, such as the Gaussian mecha-
nism:
69Theorem L.5. LetM=B◦S, where Sis subsampling with replacement with batch size q, and Bis
the Gaussian mechanism h+Vwithh:Y→RDandV∼ N(0, σ2ID). Define the ℓ2-sensitivity
L2= max y≃∆,Yy′||f(y)−f(y′)||2, where ≃∆is the substitution relation. Consider an arbitrary
dataset size N∈N. Then, for any pair x≃∆,Xx′of size N,
Hα(mx||mx′)≤Hα
qX
i=1f(1)
i·wi||qX
j=1f(2)
j·wj
, (26)
with univariate normal densities f(1)
i=N(· |(i−1), σ / L 2),f(2)
j=N(· | −(j−1), σ / L 2), and
weights wi= 1
Nq· 
1−1
Nq−i.
Proof. We first relax the optimization problem in Theorem L.3 by replacing the last constraint
∀t, u:dY(y(1)
t, y(2)
u)≤max{t, u}with a new constraint ∀t, u:dY(y(1)
t, y(2)
u)≤t+u.
This leaves us with
max
yHα
q+1X
i=1by(1)
i·wi||q+1X
j=1by(2)
i·wj
,
subject to y∈Y(q+1)+( q+1),∀l, t, u :dY(y(l)
t, y(l)
u)≤ |t−u|,∀t, u:dY(y(1)
t, y(2)
u)≤t+u, and
with weights wi= 1
Ni· 
1−1
Nq−i.
We now observe that this optimization problem is identical to the optimization problem from our
group privacy bound (Theorem 3.7) with qinsertions ( K+=q),qdeletions (K−=q), and a
different set of weights. The result thus follows immediately from our solution to the group privacy
amplification problem from Theorem 3.7, which did not make any specific assumptions about the
weights.
We see that the upper bound in Eq. (25) depends on the same pair of mixture distributions for
allα≥0. Thus, this pair of mixture distributions is a dominating pair for subsampling without
replacement under substitution.
70M Tight mechanism-specific group privacy amplification
In the following, we first prove our generic group privacy amplification guarantee for Poisson
subsampling and insertion/removal, which gives us a constrained optimization problem whose optimal
value bounds Ψα(mx||mx′. We then solve this constrained optimization problem for Gaussian,
Laplace, and randomized response mechanisms. After that, we prove the mechanism-specific tightness
for the resultant guarantees. Finally, we discuss how to evaluate these guarantees numerically.
M.1 Proof of Theorem 3.7
Theorem 3.7. LetM=B◦S, where Sis Poisson subsampling with rate r. Let≃Ybe the
insertion/removal batch relation ≃±,Y. Then, for all x≃K+,K−,Xx′,Ψα(mx||mx′)is l.e.q.
max
yΨα
K−+1X
i=1by(1)
i·Binom( i−1|K−, r)||K++1X
j=1by(2)
j·Binom( j−1|K+, r)
,(4)
subject to constraints y∈YK−+K++2, as well as ∀l∈ {1,2},∀t, u:dY(y(l)
t, y(l)
u)≤ |t−u|, and
∀t, u:dY(y(1)
t, y(2)
u)≤(t−1) + ( u−1).
Proof. By definition of the “insert K+, remove K−“ relation ≃K+,K−,Xthere is some inserted set
g+⊆x′of size K+withg+∩x=∅and some removed set g−⊆xof size K−withg−∩x′=∅
such that x′=x\g−∪g+.
To simplify indexing, we define zero-based indexed events A0, . . . , A K−andE0, . . . , E K+. We
define Aito be the event that iremoved elements are sampled, i.e. |y∩g−|=i. We define Ejto be
the event that jinserted elements are sampled, i.e. |y∩g+|=j.
By definition of Poisson subsampling, we have PSx(Ai) = Binom( i|K−, r), and PSx(Ej) =
Binom( j|K+, r). We further have
sx(y|Ai) =r|y|(1−r)|x|−|y|·Binom( i|K−, r)−1ify⊆x∧ |g−∩y|=i
0 otherwise
=(
r|y|−i(1−r)|x|−|y|−(K−−i)· K−
i−1ify⊆x∧ |g−∩y|=i
0 otherwise
and
sx′(y|Ej) =r|y|(1−r)|x|−|y|·Binom( i|K+, r)−1ify⊆x′∧ |g+∩y|=i
0 otherwise
=(
r|y|−j(1−r)|x|−|y|−(K+−j)· K+
j−1ify⊆x′∧ |g+∩y|=i
0 otherwise
Note that sx′(y|E0) =sx(y|A0).
Coupling. We now define a coupling γ:Y(K++1)+( K−+1)→R+that corresponds to the following
generative process: We first generate y(1)
0by sampling a batch that does not contain any inserted or
removed elements via Poisson subsampling from x\g−. We then let y(2)
0←y(1)
0. Finally, we sample
uniformly at random an order in which we include removed elements from g−and inserted elements
from g+to iteratively construct batches from (Ai)i>1and(Ej)j>1, respectively. More formally,
γ(y(1),y(2)) =(
sx(y(1)
0|A0)·(K+!·K−!)−1ify(1),y(2)fulfills Condition M.1
0 otherwise.
Condition M.1. A tuple y(1)∈YK−+1,y(2)∈YK++1fulfills this condition when y(1)
0=y(2)
0,
and∀i:∃a−∈g−\y(1)
i:y(1)
i+1=y(1)
i∪ {a−}, and∀j:∃a+∈g+\y(2)
j:y(2)
j+1=y(2)
j∪ {a−}.
71Validity. We can verify the validity of this coupling as follows:
ForA0and every ywithsx(y|A0)>0, there are exactly K+!·K−!combinations with y(1)
0=y
for which γ(y)>0. We thus haveP
y∈YK++K−+2 1[y(1)
0=y]γ(v) =sx(y|A0).The proof for E0
is analogous.
Next, consider an arbitrary Aiwith0< i≤K−. For every ywithsx(y|A0)>0, there are exactly
i!·(K−−i)!·K+!combinations with y(1)
i=yfor which γ(y)>0, because there are (a) i!orders
in which the removed elements leading up to icould have been sampled (b) (K−−i!)permutations
for the remaining removed elements (c) K+!permutations for the inserted elements that are only
relevant for y(2). We thus haveX
y∈YK++K−+21[y(1)
i=y]γ(y)
= (i!·(K−−i)!·K+!)·sx(y(1)
0|A0)·(K+!·K−!)−1
= (i!·(K−−i)!·K+!)·r|y(1)
0|(1−r)|x|−|y(1)
0|−(K−)·(K+!·K−!)−1
=i!(K−−i)!·r|y(1)
0|(1−r)|x|−|y(1)
0|−(K−)·(K−!)−1
=r|y(1)
0|(1−r)|x|−|y(1)
0|−(K−)·K−
i−1
=r|y|−i(1−r)|x|−|y|−(K−−i)·K−
i−1
For the last step, we have used that y(1)
0contains 0of the removed elements from g−, whereas y
contains iof the removed elements.
The proof for Ejwith0< j≤K+is analogous.
Compatibility. Finally, it can be easily shown that γis adY-compatible coupling (recall Appendix F).
Whenever γ(y)>0, then
∀1≤i≤K−:dY(y(1)
0, y(1)
i) =dY
y(1)
0,supp( sx(· |Ai))
=i,
∀0≤j≤K+:dY(y(1)
0, y(2)
i) =dY
y(1)
0,supp( sx′(· |Ej))
=j
because we generate the y(1)
ifrom y(1)
0by inserting exactly ielements, and construct the y(2)
jby
inserting exactly jelements. Similarly, we have for the pairwise distances that do not involve y(1)
0
∀0< t < u ≤K−:dY(y(1)
t, y(1)
u) =dY(supp( sx(· |At),supp( sx(· |Au))) =|t−u|,
∀0< t < u ≤K−:dY(y(2)
t, y(2)
u) =dY(supp( sx′(· |Et),supp( sx′(· |Eu))) =|t−u|.
∀0≤t < u≤K−:dY(y(1)
t, y(2)
u) =dY(supp( sx(· |At),supp( sx′(· |Eu))) = t+u.
The last equality holds because to construct y(2)
ufromy(1)
twe need to remove telements and insert u
elements.
The result then follows from Corollary F.7, PSx(Ai) = Binom( i|K−, r),PSx′(Ej) = Binom( j|
K+, r), and reverting back to one-based indexing.
M.2 Instantiations
Next, we can solve the derived optimization problem. In this section, we only provide proof sketches
in which we reduce the optimization problem over batches to an optimization problem over the
means of multiple Gaussian, Laplace, or Bernoulli random variables. Because solving these problems
requires some further exposition, we then refer the reader to Appendix O.
M.2.1 Gaussian mechanism guarantee
Theorem 3.8. LetM=B◦S, where Sis Poisson subsampling with rate r, and Bis the Gaussian
mechanism h+Vwithh:Y→RDandV∼ N (0, σ2ID). Define the ℓ2-sensitivity L2=
72max y≃±,Yy′||f(y)−f(y′)||2. Then for all x≃K+,K−,Xx′,Ψα(mx||mx′)is l.e.q.
Ψα
K−+1X
i=1f(1)
i·Binom( i−1|K−, r)||K++1X
j=1f(2)
j·Binom( j−1|K+, r)
,
with univariate normal densities f(1)
i=N(· |(i−1), σ / L 2),f(2)
j=N(· | −(j−1), σ / L 2).
Proof sketch. Recall from Theorem 3.7 that we need to solve the optimization problem
max
yΨα
K−+1X
i=1w(1)
i·by(1)
i||K++1X
j=1w(2)
j·by(2)
j
,
subject to y∈Y(K++1)+( K−+1),∀l, t, u :dY(y(l)
t, y(l)
u)≤ |t−u|,∀t, u:dY(y(1)
t, y(2)
u)≤(t−1) +
(u−1), and with w(1)
i= Binom( i−1|K−, r),w(2)
j= Binom( j−1|K+, r).
Letµ(1)
i=h(y(1)
i)andµ(2)
j=h(y(2)
j). Since we do not have any additional information about
hbeyond its ℓ2-sensitivity, we have to make the worst-case assumption that the µ(1)
i,µ(2)
jare
arbitrary vectors constrained by ∀l, t, u :||µ(l)
t−µ(l)
u||2≤L2|t−u|,∀t, u:||µ(1)
t−µ(2)
u||2≤
L2((t−1) + ( u−1)),
Thus, the optimization problem is equivalent to
max
µ(1),µ(2)
Ψα(K−+1X
i=1w(1)
iN(· |µ(1)
i, σ2ID/ L2
2)||K++1X
j=1w(2)
jN(· |µ(2)
j, σ2ID/ L2
2)

subject to ∀l, t, u :||µ(l)
t−µ(l)
u||2≤ |t−u|,∀t, u:||µ(1)
t−µ(2)
u||2≤(t−1) + ( u−1).
In Appendix O, we rigorously prove that the maximum is attained by co-linear, equidistant means that
fulfill these distance constraints exactly. Thus, we can perform a coordinate transformation such that
µ1=0andµ(1)
i= (i−1)e1andµ(2)
j=−(j−1)e1with first-component indicator vector e1∈RD.
Since the likelihood ratio in Ψαis Gaussian with zero mean in all but the first dimension, we can
marginalize all other dimensions out to obtain our one-dimensional result (cf. Appendix O).
M.2.2 Laplace mechanism guarantee
Theorem M.2. LetM=B◦S, where Sis Poisson subsampling with rate r, and Bis the Laplacian
mechanism h+Vwithh:Y→RDandV∼Lap(0, σ2ID), with location 0∈RDand diagonal
scale matrix λID∈RD×D
+ , which adds independent Laplacian noise to each dimension. Define the
ℓ1-sensitivity L1= max y≃±,Yy′||f(y)−f(y′)||1. Then, for all x≃K+,K−,Xx′,Ψα(mx||mx′)is
l.e.q.
Ψα
K−+1X
i=1f(1)
i·Binom( i−1|K−, r)||K++1X
j=1f(2)
j·Binom( j−1|K+, r)
,
with univariate Laplace densities f(1)
i= Lap( · |(i−1), λ / L 1),f(2)
j= Lap( · | −(j−1), λ / L 1).
Proof sketch. Recall from Theorem 3.7 that we need to solve the optimization problem
Ψα
K−+1X
i=1by(1)
i·w(1)
i||K++1X
j=1by(2)
j·w(2)
j
,
subject to y∈YK++K−,∀l, t, u :dY(y(l)
t, y(l)
u)≤ |t−u|,∀t, u:dY(y(1)
t, y(2)
u)≤(t−1) + ( u−1),
and with w(1)
i= Binom( i−1|K−, r),w(2)
j= Binom( j−1|K+, r).
73Letµ(1)
i=h(y(1)
i)andµ(2)
j=h(y(2)
j). Since we do not have any additional information about
hbeyond its ℓ1-sensitivity, we have to make the worst-case assumption that the µ(1)
i,µ(2)
jare
arbitrary vectors constrained by ∀l, t, u :||µ(l)
t−µ(l)
u||1≤L1|t−u|,∀t, u:||µ(1)
t−µ(2)
u||1≤
L1((t−1) + ( u−1)),
Thus, the optimization problem is equivalent to.
max
µ(1),µ(2)
Ψα(K−+1X
i=1Lap(· |µ(1)
i, λID/ L1)·w(1)
i||K++1X
j=1Lap(· |µ(2)
j, λID/ L1)·w(2)
j

subject to ∀l, t, u :||µ(l)
t−µ(l)
u||1≤ |t−u|,∀t, u:||µ(1)
t−µ(2)
u||1≤(t−1) + ( u−1).
In Appendix O, we rigorously show that the maximum is attained by collinear, equidistant vectors
along a single coordinate axis that leave no slack on the pairwise distance constraints. This then
allows us to marginalize out all remaining dimensions to obtain our guarantee in terms of univariate
Laplace densitities (see Appendix O).
M.2.3 Randomized response mechanism guarantee
Theorem M.3. LetBbe the randomized response mechanism |h−(1−V)|withh:Y→
{0,1},V∼Bernoulli( θ), and true response probability θ∈[0,1]. Let M=B◦Sbe the
corresponding subsampled mechanism, where Sis Poisson subsampling with rate r. Finally, let ≃Y
be the insertion/removal relation ≃±,Y. Then, for all x≃K+,K−,Xx′,Ψα(mx||mx′)is l.e.q.
max
τΨα((1−w(1))Bern( · |θ) +w(1)Bern(· |τ)||(1−w(2))Bern( · |θ) +w(2)Bern(· |1−τ))
subject to τ∈ {θ,1−θ}, and with w(1)= 1−(1−r)K−andw(2)= 1−(1−r)K+.
Proof sketch. Recall from Theorem 3.7 that we need to solve the optimization problem
Ψα
K−+1X
i=1by(1)
i·w(1)
i||K++1X
j=1by(2)
j·w(2)
j
,
subject to y∈YK++K−,∀l, t, u :dY(y(l)
t, y(l)
u)≤ |t−u|,∀t, u:dY(y(1)
t, y(2)
u)≤(t−1) + ( u−1),
and with w(1)
i= Binom( i−1|K−, r),w(2)
j= Binom( j−1|K+, r).
Letµ(1)
i=h(y(1)
i)andµ(2)
j=h(y(2)
j). Since we do not have any additional information about h
beyond it mapping to {0,1}, we have to make the worst-case assumption that the µ(1)
i, µ(2)
jare only
constrained by µ(1)
2=µ(2)
1.
Thus, the optimization problem is equivalent to.
max
µ(1),µ(2)
Ψα(K−+1X
i=1Bern(· |µ(1)
i)·w(1)
i||K++1X
j=1Bern(· |µ(2)
j)·w(2)
j

subject to µ(1)
1=µ(2)
1.
In Appendix O, we rigorously show that the maximum is attained whenever all µ(1)
iwithi >1are
simultaneously set to either 0or1, and all µ(2)
jwithj >1are set to the opposite value.
Note that this guarantee can be evaluated in O(1): We need to iterate over two possible values of τ,
and evaluating the corresponding Ψαrequires summing over two values z∈ {0,1}.
M.3 Tightness
Next, we prove tightness by constructing datasets and underlying functions hsuch that the corre-
sponding base mechanism Bexactly attains the different bounds under subsampling scheme S.
74M.3.1 Gaussian mechanism tightness
Theorem M.4. LetSbe Poisson subsampling with rate r∈[0,1]andθ∈[0,1]be some true
response probability. There exists a dataset space Xand a batch space (Y,Y)fulfilling the constraints
in Definition D.4, as well a pair of datasets x≃K+,K−,Xx′, and a function h:Y→RDwith
ℓ2-sensitivity L2, such that the corresponding subsampled Gaussian mechanism M=B◦Sfulfills
Ψα(mx||mx′) = Ψ α
K−+1X
i=1f(1)
i·Binom( i−1|K−, r)||K++1X
j=1f(2)
j·Binom( j−1|K+, r)
,
with univariate normal densities f(1)
i=N(· |(i−1), σ / L 2),f(2)
j=N(· | −(j−1), σ / L 2).
Proof. LetX=P(N). Consider an arbitrary x∈Xand select arbitrary deleted elements g⊆x,
with|g|=K−and arbitrary inserted elements g⊆X\x. Define x′=x\g−∪g+.
We now construct a counting function for hthat leads to the largest possible divergence under the
sensitivity constraint. We define function has follows:
h(y) =(i−1)·e1L2 if|g−∩y|=i−1
−(j−1)·e1L2if|g+∩y|=j−1
with first-component indicator vector e1∈RD.
By construction, PMxis a mixture distributions with K+ 1components, each corresponding to a size
of a subset of g−that is included in batch y. These cases each have probability Binom( i−1|K−, r)
under subsampling distributions PSx. Each component has distribution N(· |(i−1),e1L2, σ2ID).
Analogously, Pmx′is the other desired mixture of Gaussians.
As in our previous proof, we can now notice that the likelihood ratio in Ψαis constant in all but the
first dimension. We can thus marginalize out the remaining dimensions to obtain our result.
M.3.2 Laplace mechanism tightness
Theorem M.5. LetSbe Poisson subsampling with rate r∈[0,1]andθ∈[0,1]be some true
response probability. There exists a dataset space Xand a batch space (Y,Y)fulfilling the constraints
in Definition D.4, as well a pair of datasets x≃K+,K−,Xx′, and a function h:Y→RDwith
ℓ1-sensitivity L1, such that the corresponding subsampled Laplace mechanism M=B◦Sfulfills
Ψα(mx||mx′) = Ψ α
K−+1X
i=1f(1)
i·Binom( i−1|K−, r)||K++1X
j=1f(2)
j·Binom( j−1|K+, r)
,
with univariate Laplace densities f(1)
i= Lap( · |(i−1), λ / L 1),f(2)
j= Lap( · | −(j−1), λ / L 1).
Proof. The proof is identical to that of the tightness guarantee from Theorem M.4. We can construct
exactly the same counting function that indicates the number of inserted or removed element that
appear in a batch sampled from SxandSx′, respectively.
As in our previous proof, we can now notice that the likelihood ratio in Ψαis constant in all but the
first dimension. We can thus marginalize out the remaining dimensions to obtain our result.
M.3.3 Randomized response mechanism tightness
Theorem M.6. LetSbe Poisson subsampling with rate r∈[0,1]andθ∈[0,1]be some true
response probability. There exists a dataset space Xand a batch space (Y,Y)fulfilling the constraints
in Definition D.4, as well a pair of datasets x≃K+,K−,Xx′, and a function h:Y→0,1, such that
the corresponding subsampled randomized response mechanism M=B◦Sfulfills
Ψα(mx||m′
x)
= max
τΨα((1−w(1))Bern( · |θ) +w(1)Bern(· |τ)||(1−w(2))Bern( · |θ) +w(2)Bern(· |1−τ))
subject to τ∈ {θ,1−θ}, and with w(1)= 1−(1−r)K−andw(2)= 1−(1−r)K+.
75Proof. The following proof is largely identical to our randomized response tightness proof for
subsampling without replacement from Appendix I.3.
LetX=P(N). Consider an arbitrary x∈Xand select arbitrary deleted elements g⊆x, with
|g|=K−and arbitrary inserted elements g⊆X\x. Define x′=x\g−∪g+.
Assume w.l.o.g. that the divergence is maximized by τ=θ.
We now construct an indicator function h:Y→ {0,1}foraanda′that leads to the largest possible
divergence.
h(y) =

1ify∩(g−∪g+) =∅
1ify∩g−̸=∅
0otherwise.
By construction of h, the corresponding base mechanism pmf is
by(z) =

Bern( z|θ) ify∩(g−∪g+) =∅
Bern( z|θ) ify∩g−̸=∅
Bern( z|1−θ)otherwise.
Under the distribution of S(x), the first case occurs with probability (1−r)K−and the second case
occurs with probability 1−(1−r)K−. Under the distribution of S(x′), the first case occurs with
probability (1−r)K+and the second case occurs with probability 1−(1−r)K+. We thus have
mx(z) = (1 −w(1))Bern( z|θ) +w(1)Bern( z|θ),
mx′(z) = (1 −w(2))Bern( z|θ) +w(2)Bern( z|1−θ),
which exactly attains the desired divergence when τ=θis the optimal value.
M.4 Numerical evaluation
Evidently, we do not have a closed-form analytical expression for our tight mechanism-specific group
privacy bounds. However, we can evaluate them to arbitrary precision using standard techniques from
privacy accounting literature.
M.4.1 Gaussian mechanism
ADP. To evaluate the guarantee from Theorem 3.8, we can use Lemma 5from [ 10], which generalizes
an alternative characterization of privacy profiles from [ 74] to dominating pairs. Let P, Q be
the dominating pair of two univariate Gaussian mixtures. Define privacy loss random variables
LP,Q=p(Z)
q(Z)withZ∼PandLQ,P=q(Z)
p(Z)withZ∼Q. Then
Hα(p||q)≤Pr[LP,Q>log(α)]−αPr[LQ,P<−log(α)].
Because the privacy loss between the two Gaussian mixtures is monotonically increasing in z[8],
one can perform a change of variables via a binary search for a z∗such that log(p(z∗)
q(z∗))≈log(α). By
picking one of the two search boundaries, one can either over- or under-approximate the hockey stick
divergence (see, e.g., [8, 24]).
RDP via quadrature. To evaluate the guarantee for RDP, we can simply use numerical quadrature.
This can be done efficiently because we only need to integrate over univariate Gaussians. This
approach was already proposed and used in Abadi et al. [6]’s work on moments accounting.
RDP via expansion. For the special case of K−=KandK+= 0, one can also use multinomial
expansion (similar to prior work on RDP subsampling from [28–30]): We have KX
k=0wk· N(z|µk, σ2I)!α
=X
l0+···+lK=αα
l0, . . . , l K KY
k=0wlk
k! KY
k=0N(z|µk, σ2I)lk!
=X
l0+···+lK=αα
l0, . . . , l K KY
k=0wlk
k! KY
k=0N(z|µk, σ2I)lk/α!α
76Using quadratic expansion, we have
KY
k=0N(z|µk, σ2I)lk/α
=N 
z|X
klk
αµk, σ2I!
·exp 
−1
2σ2X
klk
α||µk||2
2!
·exp 
1
2σ2X
k||(lk
αµk)||2
2!
Since only the first factor depends on z, our problem reduces to computing the divergence
Ψα 
N 
z|X
klk
αµk, σ2I!
||N 
z|0, σ2I!
for different lk. This can be done in closed form, as shown in [7].
M.4.2 Laplace mechanism
ADP. Because the privacy loss is constant on (−∞,−K+), monotonically increasing on [−K+, K−]
and constant on (K−,∞), we can again use the same bisection method.
RDP. As with the Gaussian mechanism, we can evaluate the bound via univariate numerical
quadrature. Because the privacy loss is non-smooth at the component means {−K+,−K++
1, . . . , 0,1, . . . , K −}, we partition Rat these means and integrate over each interval separately.
M.4.3 Randomized response mechanism
The guarantee for randomized smoothing can be evaluated exactly in O(1). We just need to iterate
over the two options τ∈ {0,1}, and for each one evaluate the divergence on space {0,1}, which
only requires evaluating two fractions and two sums.
77N Tight mechanism-agnostic group privacy amplification
In this section, we apply the framework from [ 15], which we summarized in Appendix G.1, to
the group privacy setting. We then show the tightness of the resultant guarantees, using the same
proof strategy as in Section 5 of [ 15]. We then demonstrate that it is directly related to our tight
mechanism-specific guarantee through joint convexity. Finally, we derive a qualitatively similar
guarantee for RDP.
For this discussion, we focus on the special case where all of the Kgroup members collaboratively
agree to insert their data (K+=K, K −= 0) or delete their data (K+= 0, K−=K), so that
the partition induced by the maximal coupling remains interpretable. We define the corresponding
neighboring relation as
≃K±,X={(x, x′)∈X2|x⊂x′∧|x′|=|x|+K}∪{(x, x′)∈X2|x⊃x′∧|x′|=|x|−K}.(27)
In our experiments, we only evaluate the baseline for (K+=K, K −= 0) and(K+= 0, K−=K),
while we evaluate our method for all K++K−=Kand take the maximum. This evaluation favors
the baseline.
N.1 ADP guarantee
Proposition N.1. LetM=B◦S, where Sis Poisson subsampling with rate r. Let≃Ybe the
insertion/removal batch relation ≃±,Y. Then, for all x≃K±,Xx′and all ε≥0
Hexp(ε′)(mx||mx′)≤KX
k=1Binom( k|K, r)·δk
withε′= log(1 + (1 −(1−r)K)·(eε−1))and group privacy parameters
δk= max
y,y′Hexp(ε)(by||by′)s.t.dY(y, y′)≤k.
Proof. Case 1: Deletion. We first consider the case where Kelements are deleted, i.e., there is some
deleted set g⊆xof size Kwithg−∩x′=∅such that x′=x\g.
The partition induced by the maximal coupling9is
sx(y) = (1 −w)sx(y|A2) +wsx(y|A1)
sx′(y) = (1 −w)sx(y|A2) +wsx(y|A2),
where A2={y∈Y|y∩g=∅is the event that no element of gis sampled, A1is its complement,
andw= (1−(1−r)K) =PSx(A1). We use these indices for A2andA1because advanced joint
convexity will later reverse their order.
Applying advanced joint convexity (see Proposition G.1) and joint convexity shows that
Hexp(ε′)(mx||mx′)≤w·Hexp(ε)
X
y∈Yby·sx(y|A1)||X
y∈Yby·sx(y|A2)
. (28)
Next, we can bound this mixture divergence by constructing a coupling invoking Theorem 3.3 with
the special case of Ψα=Hexp(ε). For this, notice that
sx(y|A1) =1
w·r|y|·(1−r)|x|−|y|ify∈A1∧y⊆x
0 otherwise.
and
sx(y|A2) =sx′(y) =r|y|·(1−r)|x′|−|y|ify∈A2∧y⊆x′
0 otherwise.
9as can be seen by the fact that wis the total variation distance of sxandsx′, and that sx(y|A2)and
sx(y|A1)have disjoint support
78Coupling. We define a coupling γ:Y2→[0,1]that corresponds to the following generative process:
We first sample y(2)from sx(y|A2). We then sample from a truncated binomial distribution how
many elements kfrom group gshould be included. Given this k, we sample uniformly at random a
˜g⊆gfrom all size- ksubsets of gand let y(1)←y(2)∪˜g. Formally this is defined by
γ(y(1), y(2)) =(
sx(y(2)|A2)·1
w·Binom( |y(1)∩g| |K, r)· K
|y(1)∩g|−1under Condition N.2
0 otherwise.
Condition N.2. A tuple y(1)∈Y,y(2)∈Yfulfills this condition when there exists a ˜g⊆gwith
|˜g| ≥1such that y(1)=y(2)∪˜g.
Validity. Next, we verify the validity of this coupling. For every y(1), there is exactly one y(2)such
thatγ(y(1), y(2))>0, namely y(2)=y(1)\g′. Thus,
X
y(2)γ(y, y(2)) =sx(y\g|A2)·1
w·Binom( |y∩g| |K, r)·K
y∩g|−1
=r|y\g|·(1−r)|x′|−|y\g|·1
w·r|y∩g|·(1−r)K−|y∩g|
=sx(y|A1).
For every y(2), there are exactly K
k
batches y(1)such that γ(y(1), y(2))>0and|y(1)∩g=k|.
Thus,
X
y(1)γ(y(1), y) =KX
k=1K
k
sx(y|A2)·1
w·Binom( k|K, r)·K
k−1
=sx(y|A2)·1
w·KX
k=1Binom( k|K, r)
=sx(y|A2).
Now that we have proven the validity of the coupling, we can apply the optimal transport bound
(Theorem 3.3) to Eq. (28) in order to prove
Hexp(ε′)(mx||mx′)≤w·X
y(1),y(2)γ(y(1), y(2))δdY(y(1),y(2))
=w·KX
k=1K
k1
wBinom( k|K, r)K
k−1
·δk
=KX
k=1Binom( k|K, r)·δk.
Case 2: Insertion. In this case, the partition induced by the maximal coupling is
sx(y) = (1 −w)sx(y|A1) +wsx(y|A2)
sx′(y) = (1 −w)sx(y|A1) +wsx(y|A1),
which is identical to the previous partition, up to symmetry. The proof is identical, except for changes
in indexing.
Taking the maximum over both guarantees yields the result.
N.2 Tightness of ADP guarantee
Proposition N.3. LetSbe Poisson subsampling with rate r. Let≃Ybe the insertion/removal batch
relation ≃±,Y. Then, for all x≃K±,Xx′and all ε≥0, there exists a worst-case base mechanism B
79such that the corresponding subsampled mechanism M=B◦Sfulfills
Hexp(ε′)(mx||mx′) =KX
k=1Binom( k|K, r)·δk (29)
withε′= log(1 + (1 −(1−r)K)·(eε−1))and group privacy parameters
δk= max
y,y′Hexp(ε)(by||by′)s.t.dY(y, y′)≤k.
Proof. To show tightness of the bound, we notice that the boundPK
k=1Binom( k|K, r)·δkis
identical to the bound for subsampling with replacement from [ 15], except for the numeric value of
the weights in the weighted sum. We can thus use exactly the same proof strategy.
Assume w.l.o.g. that we are in the insertion case, i.e., there is some gof size Kwithg∩x=∅
andx′=x∪g. Consider an arbitrary εand define an arbitrary true response probability θ∈[0,1].
Further define the randomized membership base mechanism
B(y) =| 1[|y∩g|>0]−(1−V)|
withV∼Bern( θ). It is easy to verify [ 15] that δk=ψθ(ε) = max {θ−eε(1−p),0}. We thus have
for the r.h.s. of Eq. (29)
KX
k=1Binom( k|K, r)·δk=KX
k=1Binom( k|K, r)·ψθ(ε) :=w·ψθ(ε).
Because Poisson subsampling is a “natural subsampling”[ 15] scheme that only yields elements from
the dataset it is applied to, it follows from Lemma 12 of [15] that also
Hexp(ε′)(mx||mx′) =w·ψθ(ε).
N.3 Relation to tight mechanism-specific bound
In the following, we show that this mechanism-agnostic guarantee implicitly upper bounds our
tight mechanism-specific guarantee via joint convexity. Note that this is qualitatively different from
our discussion in Appendix G. There we showed, that the mechanism-agnostic guarantees can be
derived from mechanism-specific bounds that only use a binary partitioning of the batch space (unlike
the mechanism-specific guarante considered here). We show this result w.l.o.g. for K−= 0 and
K+=K.
Theorem N.4. LetB:Y→Zbe an arbtirary base mechanism. Let y(1)∈Y1and,y(2)∈YK+1
be arbitrary tuples of batches that fulfill ∀l, t, u :dY(y(l)
t, y(l)
u)≤ |t−u|, and∀t, u:dY(y(1)
t, y(2)
u)≤
(t−1) + ( u−1). Then, for α≥1
Hα′
by(1)
1||K+1X
j=1by(2)
j·Binom( j−1|K, r)
≤KX
k=1Binom( k|K, r)·δk(α)
withw= (1−(1−r)K),α′= 1 + w(α−1)and group privacy parameters
δk(α) = max
y,y′Hα(by||by′)s.t.dY(y, y′)≤k.
80Proof. We can apply joint convexity to show
Hα′
by(1)
1||K+1X
j=1by(2)
j·Binom( j−1|K, r)
 (30)
=Hα′
by(1)
1||(1−w)·by(2)
1+K+1X
j=2w·by(2)
j·1
w·Binom( j−1|K, r)
 (31)
=Hα′
by(1)
1||K+1X
j=2
(1−w)·by(2)
1+w·by(2)
j
·1
w·Binom( j−1|K, r)
 (32)
≤K+1X
j=21
w·Binom( j−1|K, r)·Hα′
by(1)
1||
(1−w)·by(2)
1+w·by(2)
j
(33)
The result then immediately follows from advanced joint convexity (see Proposition G.1) and joint
convexity.
N.4 RDP guarantee
For RDP, we can obtain a qualitatively similar guarantee by simply applying the known mechanism-
agnostic RDP subsampling guarantee for Poisson subsampling from [ 29,30] to each of the K
divergences (although we could also derive this RDP guarantee from scratch via optimal transport)
in Eq. (33) of the previous derivation.
Theorem N.5. LetM=B◦S, where Sis Poisson subsampling with rate r. Let≃Ybe the
insertion/removal batch relation ≃±,Y. Then, for all x≃K±,Xx′and all α >0
Λα(mx||mx′)≤KX
k=11
w·Binom( k|K, r)·2·αX
l=0α
l
wl(1−w)α−lζk(l)
withw= (1−(1−r)K)and group privacy parameters
ζk(l) = max
y,y′Λl(by||by′)s.t.dY(y, y′)≤k.
The factor 2in Theorem N.5 can be eliminated for distributions with particular symmetries (see
Theorem 5 in [ 29]) or bounded Pearson-Vajda χl-pseudo-divergence (see Theorem 8 in [ 30]). We thus
do not include the factor 2when using this amplification guarantee as a baseline in our experiments.
N.5 Asymptotic RDP guarantees
As mentioned in Section 3.1, our focus is on tight bounds that can be explicitly computed. However,
analyzing the asymptotic behavior of these bounds can provide a potentially useful high-level picture
of their behavior. As discussed in the previous section, and as can be seen from Eq. (33), Rényi
divergence in the group privacy setting is bounded by a weighted sum of Rényi divergences between
a single distribution and a mixture of two distributions. For the special case of additive Gaussian
mechanisms with global sensitivity L, this bound is equivalent (see Appendix A of [30]) to
KX
k=11
w·Binom( k|K, r)·2·Λα(N(0, σ)||(1−w)N(0, σ) +w·N(1, σ /(k·L))). (34)
Asymptotic bounds on Rényi divergences with one or two components have been derived in prior
work on privacy accounting [ 6,28,48]. We can apply these asymptotic bounds to each summand.
For instance (see Lemma 5 in [6]):
Proposition N.6. Abadi et al. [6]Letσ≥1andq≤1
16σ. Then, for any positive integer α≤
σ2ln
1
qσ
−1,
Λα(N(0, σ)||(1−q)N(0, σ) +q·N(1, σ))≤q2α(α−1)
(1−q)σ2+O(q3α3/ σ3).
81Applying Proposition N.6 to Eq. (34) yields the following asymptotic bound for RDP group privacy:
Theorem N.7. LetM=B◦S, where Sis Poisson subsampling with rate randBis an additive
gaussian mechanism with global sensitivity Lunder the insertion/removal relation ≃±. Consider
arbitrary datasets x≃K±,Xx′. Define weight w= (1−(1−r)K). Ifσ≥k·Landw≤1
16σ, then
it holds for any positive integer α≤σ2
k2·L2ln 1
wσ
−1that
Λα(mx||mx′)≤KX
k=11
w·Binom( k|K, r)·2·k2L2q2α(α−1)
(1−w)σ2+O(k3L3w3α3/ σ3).
Alternatively, one could apply the asymptotic bound from Theorem 38 from [ 48] to each summand.
If we were to instead consider group privacy under dataset-level substitutions, where each summand
would include a divergence between two mixtures with two components, we could instead use the
asymptotic bounds from Appendix C of [28].
82O Worst-case mixture components
O.1 Gaussian and Laplacian mixtures
We outline a self-contained and extendable proving strategy which we use to find dominat-
ing pairs of Gaussian and Laplacian mixtures given divergences of the form Ψα(P||Q) = R
RDf(P(x),−Q(x))dx, where fis (not necessarily strictly) convex and increasing in both ar-
guments. Our two main examples of the hockey stick divergence Ψα=Hαand (scaled and
exponentiated) Rényi divergence Ψα= Λαare special cases with f(x, y) = max {x+αy,0}and
f(x, y) =xα(−y)1−α, respectively. Throughout the subsection, we use M,Nto denote the sets of
means of the two mixtures P,Q. We start with two general lemmata before treating the Gaussian and
Laplacian mixture cases in particular. Together, they provide a constructive toolset to connect any
mixture pair with means (M, N )to a dominating mixture pair with means (M∗, N∗)via a path of
geometric transformations (M, N )7−→(M(1), N(1))7−→ ··· 7−→ (M∗, N∗): concretely, these are
• mirroring the means of the two mixtures onto opposite sides of a hyperplane, and
• pushing such hyperplane-separated means further away along the hyperplane normal.
In the first part of this section, we prove that the divergence can only stay equal or grow under
any such transformation. Afterwards, we construct an explicit path of transformations that maps
any Gaussian, as well as any Laplacian mixture onto a dominating pair which is feasible under the
pairwise distance constraints discussed in Appendix M.2.
Lemma O.1. Given p∈ {1,2}, consider two mixtures of the form PM(x) =PK
k=0wkρ(∥x−
µk∥p),QN(x) =PK
κ=0ωκρ(∥x−νκ∥p)with means in M:={µ0, . . . , µ K} ⊂RD,N:=
{ν0, . . . , ν K} ⊂RDand a decreasing ρ:R+
0→[0,1]. Consider all hyperplanes which contain
zero and are normal to L2-unit vectors ˆn∈ H p, where
(1)H1={σˆei|0≤i≤K, σ∈ {+,−}}∪{1√
2(σ1ˆei+σ2ˆej)|0≤i̸=j≤K, σ 1, σ2∈ {+,−}},
(2)H2=SD, the unit D-sphere,
and define the lower half-space R−
ˆn={x∈RD| 
xTˆn
<0}and upper half-space R+
ˆn={x∈
RD| 
xTˆn
>0}.
Consider the map
(·)′
ˆn:RD−→RD\R−
ˆn,x7−→x−1R−
ˆn(x)(2ˆnTx)ˆn
which mirror-reflects the lower into the upper half-space, and its image sets
M′
ˆn=RD\R−
ˆnandN′
−ˆn⊂RD\R+
ˆn.
The reflected pair of mixtures has equal or greater divergence:
Ψα
PM′
ˆn||QN′
−ˆn
≥Ψα(PM||QN).
Remark O.2.Lemma O.1 applies to Laplacian and Gaussian mixtures with p= 1 andp= 2,
respectively.
Proof. We will need the following lemma.
Lemma O.3. Given p∈ {1,2}, a hyperplane normal to ˆn∈ H p, and points x1,x2∈RD, we have
∥(x1)′
ˆn−(x2)′
ˆn∥p≤ ∥x1−x2∥pif(x1∈R+
ˆn∧x2∈R−
ˆn)∨(x1∈R−
ˆn∧x2∈R+
ˆn)
∥(x1)′
ˆn−(x2)′
ˆn∥p=∥x1−x2∥pelse.
Corollary O.4. If the sets M,Nare feasible under pairwise p-norm distance constraints, then so
areM′
ˆn,N′
−ˆn.
Proof of Lemma O.3. Ifsign(nTx1) =sign(nTx2), then (·)′
ˆnacts uniformly on both vectors and
the condition clearly holds. Else, assume w.l.o.g. that x2∈R−
ˆn. We start with the case p= 1.
83First, assume ˆn∈ {σˆei|0≤i≤K, σ 1∈ {+,−}}. Since (·)′
ˆnnow acts only on vector component
i, we can write ∥(x1)′
ˆn−(x2)′
ˆn∥1− ∥x1−x2∥1=||ˆeT
ix1| − |ˆeT
ix2|| − | ˆeT
ix1−ˆeT
ix2| ≤0by
the inverse triangle inequality.
Now assume instead that ˆn∈ {1√
2(σ1ˆei+σ2ˆej)|1≤i̸=j≤D, σ 1, σ2∈ {+1,−1}}.
Now, (·)′
ˆnacts only on vector components iandj. Thus, ∥(x1)′
ˆn−(x2)′
ˆn∥1− ∥x1−x2∥1=
∥πi,j[(x1)′
ˆn−(x2)′
ˆn]∥1− ∥π(i,j)[x1−x2]∥1where π(i,j)denotes projection onto the subspace
spanned by the basis vectors ˆei,ˆej. It is useful to write
∥πi,j[(x1)′
ˆn−(x2)′
ˆn]∥1= max
σ∈{−1,+1}D|σTπi,j[(x1)′
ˆn−(x2)′
ˆn]|
= max
σ∈{−1,+1}D|σTπi,j
x1−x2+ 2(ˆnTx2)ˆn
|.
The argument of the max function admits two cases. Either, σT(πi,jˆn) = 0 , in which case
|σTπi,j[(x1)′
ˆn−(x2)′
ˆn]|=|σTπi,j[x1−x2]|. In the other case, πi,jσ=±2√
2πi,jˆn. Then, by
the inverse triangle inequality,
|σTπi,j[(x1)′
ˆn−(x2)′
ˆn]|=2√
2±ˆnTx1∓ˆnTx2±2ˆnTx2=2√
2±ˆnTx1±ˆnTx2
=2√
2± 
|ˆnTx1| − |ˆnTx2|≤2√
2ˆnT(x1−x2)=σTπi,j[x1−x2].
For completeness, we also prove p= 2. By invariance of the scalar product under mirror reflection,
∥x′
1−x′
2∥2=xT
1x1+x′T
2x′
2−2xT
1x′
2=xT
1x1+xT
2x2−2xT
1x2+ 2(nTx2)(nTx1) =
∥x1−x2∥2+ 2(nTx2)(nTx1)≤ ∥x1−x2∥2.
We recall the notation introduced at the start of the section, Ψα(P||Q) =R
RDf(P(x),−Q(x))dx,
where we assume an integrand fthat is convex in both arguments. The statement of Lemma O.1 will
follow from the next lemma, which informally states that at any point xin the upper half-space, the
mirror-reflection of means contained in M−
ˆncauses an increase of the integrand f(PM(x),−QN(x))
atxwhich dominates the corresponding decrease at the mirror image point x′in the lower half-space.
Lemma O.5. Given a hyperplane normal to ˆn∈ H pas defined in Lemma O.1 as well as any point
x∈R+
ˆnalong with its mirror image x′=x−2 
xTˆnˆn∈R−
ˆn, the change of fsatisfies
h
f
PM′
ˆn(x),−QN′
−ˆn(x)
−f(PM(x),−QN(x))i
+h
f
PM′
ˆn(x′),−QN′
−ˆn(x′)
−f(PM(x′),−QN(x′))i
≥0.
Proof of Lemma O.5. We introduce the following notation,
P0(x):=X
µk∈M\R−
ˆnwkρ(∥x−µk∥p), Q 0(x):=X
νk∈N\R−
−ˆnωkρ(∥x−νκ∥p),
δP(x):=X
µk∈M∩R−
ˆnwkρ(∥x−µk∥p), δQ (x):=X
νk∈N∩R−
−ˆnωkρ(∥x−νκ∥p),
thus decomposing the densities into a part that stays fixed and a part that gets mirror-reflected. Using
Lemma O.3 and the monotonicity requirement on ρ, we can directly verify that
P0(x)≥P0(x′), δP (x)≤δP(x′), (35)
−Q0(x)≥ −Q0(x′),−δQ(x)≤ −δQ(x′). (36)
Using invariance of distances under simultaneous mirroring of both vectors, we rewrite the expression
of the lemma as
[f(P0(x) +δP(x′),−Q0(x)−δQ(x′))−f(P0(x) +δP(x),−Q0(x)−δQ(x))]
−[f(P0(x′) +δP(x′),−Q0(x′)−δQ(x′))−f(P0(x′) +δP(x),−Q0(x′)−δQ(x))]
The statement of the lemma follows from convexity of fin both arguments by Jensen’s inequality.
84We now proceed to prove Lemma O.1. The difference of divergences can be rewritten as
Ψα
PM′
ˆn||QN′
−ˆn
−Ψα(PM||QN)
=Z
RDh
f
PM′
ˆn(x),−QN′
−ˆn(x)
−f(PM(x),−QN(x))i
dx
=Z
R−
ˆnh
f
PM′
ˆn(x),−QN′
−ˆn(x)
−f(PM(x),−QN(x))i
dx
+Z
R+
ˆnh
f
PM′
ˆn(x),−QN′
−ˆn(x)
−f(PM(x),−QN(x))i
dx
=Z
R+
ˆnh
f
PM′
ˆn(x′),−QN′
−ˆn(x′)
−f(PM(x′),−QN(x′))i
+h
f
PM′
ˆn(x),−QN′
−ˆn(x)
−f(PM(x),−QN(x))i
dx
≥0
Apart from Lemma O.5, we used the fact that mirror reflection has a unit absolute Jacobian determi-
nant, and that the hyperplane, a null set, does not contribute to the integral.
Lemma O.1 shows that we can construct a dominating mixture by mirroring all means onto opposite
sides of a suitable hyperplane. This is exactly the condition under which the follow-up transform
discussed in the next lemma yields equal or greater divergence. We slightly change perspective and
consider the means of both mixtures as a joint vector. Given two sets of means M={µ0, . . . , µ K},
N={ν0, . . . , ν K}we define (in arbitrary ordering), µ= (µ0, . . . , µ K, ν0, . . . , ν K)∈ F ⊂
RD×(K+K)where Fdenotes the region feasible under the distance constraints. With this implicit
mapping (M, N )7→µbetween sets and vectors of means, we can treat the divergence as a function
Ψα:µ7→R
RD˜f(x,µ)dxwith integrand ˜f(x,µ):=f(PM(x),−Q(x)). Now we can state:
Lemma O.6. Forp∈ {1,2}, letˆn∈ H pbe a normal vector, M,Nwith corresponding vector µ
as above be two sets of means for which M∩R−
ˆnandN∩R−
−ˆnare empty (i.e., the hyperplane
separates the two sets), and let Ψαdenote either ΛαorHα.
Then, the normal directional derivatives of the divergence with respect to the means µlandνιare
nonnegative for all l∈ {1, . . . , K }, ι∈ {1, . . . ,K},
d(µl)
ˆnΨα(µ):= lim
ε→01
ε[Ψα((µ0, . . . , µ l+εˆn, . . . , ν K))−Ψα(µ)]≥0
d(νι)
−ˆnΨα(µ):= lim
ε→01
ε[Ψα((µ0, . . . , ν ι−εˆn, . . . , ν K))−Ψα(µ)]≥0.
In the case Ψα=Hα, the above expressions are instead defined in the sense of weak derivatives.
The lemma is quite intuitive: once both sets of means are already separated by a hyperplane, pushing
them apart in the normal direction, thereby increasing the margin to the hyperplane, never decreases
the divergence. As we will only ever use the directional derivatives within line integrals, the weak
sense in which the lemma holds for Ψα=Hαis sufficient for our purposes.
Proof of Lemma O.6. We first check that for all x∈RDandµ∈ F, the derivative ∂µ˜f(possibly in
the weak sense) exists and is dominated by an integrable function. In the case of Gaussian or Laplacian
mixtures and Ψα= Λα, existence of the derivative is clear. For Gaussian mixtures, the integrability
condition holds since ∂µ˜f=O(exp(−∥x∥2
2)), for Laplacian mixtures ∂µ˜f=O(exp(−∥x∥1))
since the privacy loss factor in the integrand eventually becomes constant. In the case Ψα=Hα,˜f
has a weak derivative ∂µ˜f=1f≥0∂µ(P−αQ), which agrees with its derivative except where the
latter is not defined (i.e., on the null set of means and xat the boundary of exact DP). Integrability
85follows again from ∂µ˜f=O(exp(−∥x∥1)). In the case of Ψα= Λα,
d(µl)
ˆnΨα(µ)
=Z
RDd(µl)
ˆn" KX
k=0wkρ(∥x−µk∥p)!α# KX
κ=0ωκρ(∥x−νκ∥p)!1−α
dx
=αwlZ
RDPM(x)
QN(x)α−1
d(µl)
ˆnρ(∥x−µl∥p)dx
=αwlZ
RDPM(x+µl)
QN(x+µl)α−1
d(µl)
ˆnρ(∥x∥p)dx
Consider x∈R+and its mirror image x′∈R−. By Lemma O.3 and the assumption that the hyper-
plane separates MandN,PM(x+µl)
QN(x+µl)=ρ(∥x+µl∥p)
ρ(∥x∥p)PM(x)
ρ(∥x+µl∥p)
ρ(∥x∥p)QN(x)=PM(x)
QN(x)≥PM(x′)
QN(x′)=PM(x′+µl)
QN(x′+µl). More-
over, also by Lemma O.3, ρ(∥x∥p) =ρ(∥x′∥p), and therefore d(µl)
ˆnρ(∥x∥p) =d(µl)
−ˆnρ(∥x′∥p) =
−d(µl)
ˆnρ(∥x′∥p).
Similarly, we observe how in
d(νι)
−ˆnΨα(µ)
=Z
RD KX
k=0wkρ(∥x−µk∥p)!α
d(νι)
−ˆn
 KX
κ=0ωκρ(∥x−νκ∥p)!1−α
dx
= (−1)(1−α)ωιZ
RDPM(x)
QN(x)α
d(νι)
ˆnρ(∥x−νι∥p)dx
= (α−1)ωιZ
RDPM(x+νι)
QN(x+νι)α
d(νι)
ˆnρ(∥x∥p)dx
the negative signs of −ˆnand(1−α)cancel and apply analogous reasoning thereafter.
The statement for Ψα= Λαnow follows in analogy to the proof of Lemma O.1 via Lemma O.5.
ForΨα=Hα, we find
d(µl)
ˆnΨα(µ) =wlZ
RD1{P(x)−αQ(x)≥0}d(µl)
ˆnρ(∥x−µl∥p)dx
=wlZ
RD1nPM(x+µl)
QN(x+µl)≥αod(µl)
ˆnρ(∥x∥p)dx
d(νι)
ˆnΨα(µ) =−wιZ
RD1{PM(x)−αQN(x)≥0}
−d(µl)
ˆnρ(∥x−νι∥p)
dx
=wιZ
RD1nPM(x+µl)
QN(x+µl)≥αod(µl)
ˆnρ(∥x∥p)dx
and can proceed by analogous reasoning from here on.
We are now equipped to construct the sequence of transformations taking two arbitrary sets M, N of
Gaussian or Laplacian mixture means to the means M∗, N∗of a dominating pair. We start with the
Gaussian case.
O.1.1 Dominating pair of Gaussian mixtures
Theorem O.7. LetΨα=HαorΨα= Λ α. Any pair of Gaussian mixtures with means satisfying
distance constraints of the form
µ0=ν0= 0 ∥µi−µj∥2≤ |i−j| ∀ 0≤i, j≤K, ∥νι−ντ∥2≤ |i−j| ∀ 0≤ι, τ≤ K,
is dominated by a mixture with means
µk=k·ˆe∀k∈ {0, . . . , K }, ν κ=−κ·ˆe∀κ∈ {0, . . . ,K}, withˆe∈RD,∥ˆe∥2= 1.
86Proof. We start by proving the following lemma.
Lemma O.8. Any pair of Gaussian mixtures with means at a fixed set of radii,
∥µk∥2=rk,∥νκ∥2=ρκ, r 0=ρ0= 0, r k, ρκ∈R+
0∀k∈ {1, . . . K }∀κ∈ {1, . . .K},
and satisfying the constraints of Theorem O.7 is dominated by a feasible pair with means at equal
radii that are collinear on diametral half-lines through zero, i.e.,
µk=rk·ˆe, ν κ=−ρκ·ˆe∀k∈ {0, . . . , K }∀κ∈ {0, . . . ,K} withˆe∈RD,∥ˆe∥2= 1.
Proof of Lemma O.8. Without loss of generality, we can pick as the collinearity direction from the
lemma ˆe=e1, the first canonical basis vector, since the divergence is rotation invariant. Pick any
orthogonal direction, say, the second basis vector e2. By Lemma O.1, we can mirror the two mixtures
onto opposite sides of the hyperplanes with normal vectors ˆe1andˆe2such that ˆeT
1µk≥0≥ˆeT
2µk
for all kandˆeT
1νκ≥0≥ˆeT
2νκfor all κ.
Now, consider a hyperplane with normal vector ˆn(θ) =ˆe1cos(θ) +ˆe2sin(θ),θ∈[0, π/2]. Intu-
itively, we let this hyperplane undergo a full rotation and “scoop up” all the means which are not in
the hyperplane normal to ˆe2, giving a new set of means which are. Formally, we find that by the above
sign condition, there is an angle θk∈[0, π/2]for every ksuch that sign(ˆn(θ)Tˆµk) =sign(θk−θ).
Namely, using π12to denote the projection onto the subspace spanned by vectors ˆe1andˆe2,
π12µk=∥π12µk∥2(sin(θk)ˆe1−cos(θk)ˆe2)). Consider the paths γk: [0, π/2]→RD, where
γk(θ) =1{θk−θ≥0}µk+1{θk−θ<0}((1−π12)µk+∥π12µk∥2(sin(θ)ˆe1−cos(θ)ˆe2))
and a sign-flipped construction with angles θκand curves ζκfor the means νκ. For the derivatives
along the curves, we find γ′
k(θ) =∥π12µk∥2ˆn(θ)andζ′
κ(θ) =−∥π12ζκ∥2n(θ). Also, by construc-
tion, ˆn(θ)Tˆγk(θ)≥0≥ˆn(θ)Tˆζκ(θ). Hence, the prerequisites for Lemma O.6 are fulfilled at every
θ∈[0, π/2]. By evaluating the path integral along these curves and invoking Lemma O.6, we find
that the divergence along the path M, N 7→˜M,˜Ncannot decrease:
Φα(P˜M||Q˜N)−Φα(PM||QN)
=Zπ/2
0KX
l=1d(µl)
ˆnΨα((γ1, . . . , γ K, ζ1, . . . , ζ K)(θ))
+KX
ι=1d(νι)
−ˆnΨα((γ1, . . . , γ K, ζ1, . . . , ζ K)(θ))dθ≥0
Clearly, the paths also preserve the radius of each mean. The final set of means ˜M=
{γ1(π/2), . . . , γ K(π2)},˜N={ζ1(π/2), . . . , ζ K(π2)}is contained in the hyperplane normal to
ˆe2. We can now simply repeat this procedure with all basis vectors orthogonal to ˆe1to find the set
from the lemma. Since it is collinear with the same radii as M, N , and the means M, N are feasible,
the new set is also feasible by the Cauchy-Schwarz inequality.
Since we can map any set of Gaussian mixture means onto one with the same radii that is collinear
without decreasing the divergence, we can from now on study the problem restricted to a single radial
dimension, using
Ψα
Rˆe:KY
k=0R+
0×KY
κ=0R+
0−→R,
(r0, . . . , r K, ρ0, . . . , ρ K)7−→Ψα KX
κ=0ωκN(−ρκˆe, σ2I)||KX
k=0wkN(rkˆe, σ2I)!
We can now state the next lemma which implies Theorem O.7.
Theorem O.9. (0,1, . . . , K, 0, . . . ,K)is a global maximizer of Ψα
Rˆeunder the constraints r0=
ρ0= 0,|ri−rj| ≤ |i−j| ∀i, j∈ {0, . . . , K },|ρι−ρτ| ≤ |ι−τ| ∀ι, τ∈ {0, . . . ,K}.
87Proof of Theorem O.9. To avoid clutter, we constrain ourselves to the case with only means µkand
a single ν0= 0, since the proof involving several νκis completely analogous. Consider the line
integral of the gradient
∇Ψα
R+
0ˆe:KY
k=0R+
0−→RK,(r0, . . . , r K)7−→ 
∂
∂r0Ψα
R+
0ˆe, . . . ,∂
∂rKΨα
R+
0ˆe!
between any feasible (r0, . . . , r K)and the point (0, . . . , K )along the connecting path
γr0,...,rK: [0,1]−→KY
k=0R+
0,
t7−→(r0, . . . , r K) +tv:= (r0, . . . , r K) +t[(0, . . . , K )−(r0, . . . , r K)].
First, observe that rk≤k∀k∈ {0, . . . , K }anywhere in the feasible region, since rk=Pk−1
j=0(rj+1−rj)≤Pk−1
j=0|rj+1−rj| ≤Pk−1
j=01 =k. This means that vis componentwise-
nonnegative and vanishes only if (r0, . . . , r K) = (0 , . . . , K ). By Lemma O.6, the gradient ∇Ψα
R+
0ˆe
is componentwise-nonnegative anywhere along γr0,...,rK. We may thus conclude that
Ψα
R+
0ˆe(0, . . . , K )−Ψα
R+
0ˆe(r0, . . . , r K)
=Z
γ(r0,...,rK)∇Ψα(r)dr=Z1
0∇Ψα(γ(t))Tv(t)dt≥0.
This concludes the proof of Theorem O.7.
O.1.2 Dominating pair of Laplacian mixtures
We also find an analogous result for Laplacian mixtures.
Theorem O.10. LetΨα=HαorΨα= Λ α. Any pair of Laplacian mixtures with means in
M={µ0, . . . , µ K}, N={ν0, . . . , ν K} ⊂RDsatisfying pairwise L1distance constraints
r0=ρ0= 0,∥µi−µj∥1≤ |i−j| ∀i, j∈ {0, . . . , K },∥νι−ντ∥1≤ |ι−τ| ∀ι, τ∈ {0, . . . ,K}.
is dominated by a pair for M∗, N∗of the form
µ∗
k=k·ˆe, ν∗
κ=−κ·ˆe∀k∈ {0, . . . , K }∀κ∈ {0, . . . ,K} withˆe=±ˆei,
where 1≤i≤Dsuch that ˆeiis the i-th canonical basis vector of RD.
Proof.
Lemma O.11. There is a dominating pair M∗,N∗located in diametral quadrants of RD: given the
component-wise sign function,
∃σ∈ {+,−}D:sign(µk) =σ=−sign(νκ)∀µk∈M∗, νκ∈N∗.
Proof. This is an immediate consequence of considering the canonical basis vectors as normal vectors
in Lemma O.1.
Lemma O.12. Forµk∈M,νκ∈N, define the offset vectors δµk:=µk−µk−1,δνκ:=νκ−νκ−1
for1≤k≤K,1≤κ≤ K. A dominating pair M∗,N∗has offset vectors located on diametral
simplices of the 1-sphere: ∃σ∈ {+1,−1}D:δµ∗
k∈Sσ,δν∗
κ∈S−σ, with Sσ:={x∈RD|
σTx= 1},∀k∈ {1, . . . , K }∀κ∈ {1, . . . ,K}.
88Proof. For any pair M, N of means not satisfying this condition, we will construct a new pair that
does and has at least equal divergence. By Lemma O.11, we can assume without generality loss
that∃σ(D)∈ {+1,−1}D:sign(µk) =σ(D)=−sign(νκ)∀µk∈M, ν κ∈N, where we put a
superscript (D)aboveσfor later reasons. At a later stage of the proof, we will invoke that shifting the
means along the basis vector directions with signs prescribed by σ(D)are positive almost anywhere
as a consequence of Lemma O.6.
It is useful to recast the optimization constraints in terms of the offset vectors: ∀k∈ {1, . . . , K }∀κ∈
{1, . . . ,K},
µ0=ν0= 0,∥δµk∥1= max
σ∈{−1,+1}D 
σTδµk
≤1,∥νκ∥1= max
σ∈{−1,+1}D 
σTδνκ
≤1,
where the constraints between non-ascending and non-neighboring index pairs are implied by the
symmetry and triangle inequality of the norm. For 0≤k≤K, and 0≤κ≤ K , setµ(0)
k:=µk,
ν(0)
κ:=νκ, and define (recursively for 1≤i≤D) the paths
γ(i)
k: [0,1]−→RD, γ(i)
k(t) =µ(i−1)
k+tkX
l=1
1−(σ(i)
l)Tδµ(i−1)
l
(σ(D))Tˆei
ˆei,
δµ(i−1)
l=µ(i−1)
l−µ(i−1)
l−1,σ(i)
l= arg max
σ∈{−1,+1}D,σTˆei=(σ(D))Tˆei
σTδµ(i−1)
l
, µ(i)
k=γ(i)
k(1),
ζ(i)
κ: [0,1]−→RD, ζ(i)
κ(t) =ν(i−1)
κ +tκX
ι=1
1−(σ(i)
ι)Tδν(i−1)
ι
−(σ(D))Tˆei
ˆei,
δν(i−1)
ι =ν(i−1)
ι−ν(i−1)
ι−1,σ(i)
ι= arg max
σ∈{−1,+1}D,σTˆei=−(σ(D))Tˆei
σTδν(i−1)
ι
, ν(i)
κ=ζ(i)
κ(1).
By construction,
δµ(i)
k=δµ(i−1)
k+
1−(σ(i)
k)Tδµ(i−1)
k
(σ(D))Tˆei
ˆei,
δν(i)
κ=δν(i−1)
κ +
1−(σ(i)
κ)Tδν(i−1)
κ
−(σ(D))Tˆei
ˆei.
We can easily check that δµ(i)
k∈Sσ(i)
k,δν(i)
κ∈Sσ(i)
κ, for1≤k≤K,1≤κ≤ K.
We can moreover verify that, based on the definitions of σ(i)
kandσ(i)
κ, the feasibility conditions
∥δµ(i−1)
k∥1≤1and∥δν(i−1)
κ∥1≤1imply ∥δµ(i)
k∥1= max σ∈{−1,+1}D
σTδµ(i)
k
≤1and
∥δν(i)
κ∥1= max σ∈{−1,+1}D
σTδν(i)
κ
≤1. Since, furthermore, µ(i)
0=µ0= 0,ν(i)
0=ν0= 0for
1≤i≤D, and M, N are feasible by assumption, all pairs of M(i):={µ(i)
0, . . . , µ(i)
K}, N(i):=
{ν(i)
0, . . . , ν(i)
K}are also feasible by induction.
Finally, the above simplex and feasibility properties together imply that ∀k∈ {1, . . . , K },∀κ∈
{1, . . .K},sign
ˆeT
iδµ(j)
k
= 
σ(D)Tˆeiandsign
ˆeT
iδν(j)
κ
=− 
σ(D)Tˆeiifj≥i. But this
means in particular that we can identify σ(D)
k=−σ(D)
κ=σ(D)for1≤k≤Kand1≤κ≤ K.
Putting everything together, we conclude that the pair M(D), N(D)obtained from M, N by con-
catenation of all paths is feasible and has offset vectors on diametral simplices, δµ(D)
k∈Sσ(D),
δν(D)
κ∈S−σ(D)∀k∈ {1, . . . , K },∀κ∈ {1, . . .K}. What is left to show is that M(D), N(D)has
at least the same divergence as M, N . To this end, define the product curves
(˜M(i)×˜N(i)): [0,1]−→R(K+K)×D, t7−→(γ(i)
0(t), . . . , γ(i)
K(t), ζ(i)
0(t), . . . , ζ(i)
K(t)),1≤i≤D
89connecting the endpoints (M(i−1), N(i−1))and(M(i), N(i)), and the image sets C(i):= (˜M(i)×
˜N(i))([0,1])⊂R(K+K)×D. The divergence difference is a sum of line integrals:
Ψα(M(D)||N(D))−Ψα(M||N) =DX
i=1Ψα(M(i)||N(i))−Ψα(M(i−1)||N(i−1))
=DX
i=1Z
C(i) KX
k=0d(µk)
ˆniΨα(˜M(i)||˜N(i)) +KX
κ=0d(νk)
−ˆniΨα(˜M(i)||˜N(i))!
ds
=DX
i=1Zt=1
t=0KX
k=0d(µk)
ˆniΨα(˜M(i)(t)||˜N(i)(t))kX
l=1
1−(σ(i)
l)Tδµ(i−1)
l
+KX
κ=0d(νk)
−ˆniΨα(˜M(i)(t)||˜N(i)(t))κX
ι=1
1−(σ(i)
ι)Tδν(i−1)
ι
dt≥0 :
At the start of the proof, we made the assumption without generality loss that ∃σ(D)∈
{+1,−1}D:sign(µk) =σ(D)=−sign(νκ)∀µk∈M, ν κ∈N. Therefore, the directional
derivatives d(µk)
ˆni,d(νκ)
−ˆnialong the curve directions ±ˆni=± 
(σ(D))Tˆeiˆeiare nonnegative. The
determinant factorsPk
l=1
1−(σ(i)
l)Tδµ(i−1)
l
and
1−(σ(i)
ι)Tδν(i−1)
ι
are nonnegative due to
the feasibility of M(i), N(i)∀i∈ {0, . . . , D }.
Lemma O.13. There is a dominating pair M∗,N∗withi∈ {1, . . . , D }andσ∈ {− ,+}such that
δµk=σˆei,δνκ=−σˆei∀k∈ {1, . . . , K }∀κ∈ {1, . . . ,K}.
Proof. By Lemma O.12, we may assume without generality loss that ∃σ∈ {+1,−1}D:δµk∈Sσ,
δνκ∈S−σ, with Sσ:={x∈RD|σTx= 1},∀k∈ {1, . . . , K }∀κ∈ {1, . . . ,K}.
The following curves will be useful. For 1≤i̸=j≤D,l∈ {1, . . . , D }define
γ(ijl)
k: [0,1]−→RD, γ(ijl)
k(t) =µkfork < l
µk+t(σTˆei)(ˆeT
iδµl)((σTˆej)ˆej−(σTˆei)ˆei)fork≥l
ζ(ijι)
κ: [0,1]−→RD, ζ(ijι)
κ(t) =νκforκ < ι
νκ+t(σTˆei)(ˆeT
iδνι)((σTˆej)ˆej−(σTˆei)ˆei)forκ≥ι.
By construction, γ(ijl)
k(0) = µk,ζ(ijι)
κ(0) = νκ,γ(ijl)
0(1) = 0 ,ζ(ijl)
0(1) = 0 ,γ(ijl)
k(1)−γ(ijl)
k−1(1) =
δµkfor1≤k̸=l≤K,ζ(ijι)
κ(1)−ζ(ijι)
κ−1(1) = δνκfor1≤κ̸=ι≤ K,

γ(ijl)
l(1)−γ(ijl)
l−1(1)T
ˆem=

0form=i
(ˆeT
iσ)δµT
lˆei+ (ˆeT
jσ)δµT
lˆejform=j
δµT
lˆemelse,
and

ζ(ijι)
ι(1)−ζ(ijι)
ι−1(1)T
ˆem=

0form=i
(−ˆeT
iσ)δνT
ιˆei+ (−ˆeT
jσ)δνT
ιˆejform=j
δνT
ιˆemelse.
In particular, this implies that the new pairs of sets (M(l):={γ(ijl)
0(1), . . . , γ(ijl)
K(1)}, N),
(M, N(ι):={ζ(ijι)
0(1), . . . , ζ(ijι)
K(1)})are feasible.
Assume that ∃l∈ {1, . . . , K }, m∈ {1, . . . , K }, i∈ {1, . . . , D }, j∈ {1, . . . , D }, i̸=
j: (δµT
lˆei)̸= 0∧(δµT
mˆej)} ̸= 0. Note that we include the possibility of l=m. We can
then assume without generality loss (by Lemma O.1) that the conditions of Lemma O.6 hold for
either ˆn+=1√
2(ˆ(σTˆej)ej−(σTˆei)ˆei)orˆn−=1√
2((σTˆei)ˆei−(σTˆej)ˆej). In the case of ˆn+,
consider the product curve
(˜M(l)×N): [0,1]−→RK+K×D, t7−→(γ(ijl)
0(t), . . . , γ(ijl)
K(t), ν0, . . . , ν K)
90and the image set C(l):= (˜M(l)×N)([0,1]). The divergence difference has the form
Ψα(M(l)||N)−Ψα(M||N) =Z
C(l) KX
k=0d(µk)
ˆn+Ψα(˜M(l)||N)!
ds
=Zt=1
t=0 KX
k=ld(µk)
ˆn+Ψα(˜M(l)(t)||N)!
√
2(σTˆei)(ˆeT
iδµl)dt≥0 :
By construction, the directional derivatives d(µk)
ˆn+Ψα(˜M(k)(t)||N)are nonnegative. Likewise, the
determinant term√
2(σTˆei)(ˆeT
iδµl)is nonnegative by the simplex condition together with feasibility
of(M, N ).
If the separability condition is fulfilled for ˆn−instead, we can repeat the argument with indices i↔j
swapped and index minstead of l.
An analogous argument holds if ∃ι∈ {1, . . . ,K}, π∈ {1, . . . ,K}, i∈ {1, . . . D}, j∈
{1, . . . , D }, i̸=j: (δνT
ιˆei)̸= 0∧(δνT
πˆej)} ̸= 0.
Theorem O.10 immediately follows from Lemma O.13 by induction.
O.2 Reduction of the divergence to a univariate integral
In the previous subsections, we showed that Ψα(N||M)is maximized by collinear and equidistant sets
of means. This allows to evaluate Ψα(N||M)through a one-dimensional integral via marginalization.
Recall (Theorem O.9). Note furthermore that in both cases, constraining the first element of either N
orMinto the origin incurs no generality loss due to the translation invariance of Ψα.
Being able to constrain the problem to a single dimension, we now show
Lemma O.14. In the collinear case, we may evaluate Ψαas the one-dimensional divergence Ψ1D
α
between two mixturesPK
k=0wkN(rk, σ2),PK
κ=0ωκN(−ρκ, σ2)of univariate Gaussians centered
around the means rkand−ρκ,
Ψα KX
κ=0ωκN(−ρκˆe, σ2I)||KX
k=0wkN(rkˆe, σ2I)!
= Ψ1D
α KX
κ=0ωκN(−ρκ, σ2)||KX
k=0wkN(rk, σ2)!
.
Proof. Without loss of generality, we may assume ˆeto be the indicator vector of the first component
due to rotation invariance of Ψα. Using bracketed superscripts (0)to indicate the first vector
component, and (1 :) to indicate the rest, we can use Fubini’s theorem to write
Ψα KX
κ=0ωκN(−ρκˆe, σ2I)||KX
k=0wkN(rkˆe, σ2I)!
=Z
RD"KX
κ=0ωkN(x| −ρκˆe, σ2I)#α"KX
k=0wkN(x|rkˆe, σ2I)#(1−α)
dx(0)dx(1:)
=Z
RD−1N(x(1:)|0, σ2I)dx(1:)Z
R"KX
κ=0ωkN(x(0)| −ρκ, σ2)#α"KX
k=0wkN(x(0)|rk, σ2)#(1−α)
dx(0)
= 1·Ψ1D
α KX
κ=0ωκN(−ρκ, σ2)||KX
k=0wkN(rk, σ2)!
.
The proof is analogous for the Laplacian mechanism.
91O.3 Randomized Response Proofs
The following two results (first for the Rényi divergence, second for the hockey stick divergence)
show that our (group) privacy guarantees for randomized response are given by the maximum of two
terms that can be evaluated in constant time.
Theorem O.15.
arg max
τ∈[0,1](K++1)+( K−+1)1X
z=0

K++1X
i=1w(1)
i(1− |z−τ(1)
i|)
α
·
K−+1X
j=1w(2)
j(1− |z−τ(2)
j|)
1−α

subject to
τ(1)
i∈ {θ,1−θ},∀i,
τ(1)
j∈ {θ,1−θ},∀j,
τ(1)
1=τ(2)
1,
with
w(1)
i= Binomial( i−1|K−, r),
w(2)
j= Binomial( j−1|K+, r),
is given by
arg max {Ψ (m˜τ(1)∥m˜τ(2)),Ψ (mˆτ(1)∥mˆτ(2))},
where
˜τ(1)
1= ˜τ(2)
1=:τ∈ {θ,1−θ}(symmetric ),
˜τ(1)
2,...,(K++1)= 1−τ,
˜τ(2)
2,...,(K−+1)=τ
and
ˆτ(1)
1= ˆτ(2)
1=:τ∈ {θ,1−θ}(symmetric ),
ˆτ(1)
2,...,(K++1)=τ,
ˆτ(2)
2,...,(K−+1)= 1−τ
Proof.
The strategy is to show that
(a)Any mixture pair (mτ(1), mτ(2))where mτ(1)has greater mass in (1−τ), i.e.,X
i:τ(1)
i=1−τw(1)
i≥X
j:τ(2)
j=1−τw(2)
j, is dominated by (m˜τ(1), m˜τ(2))
(b)Any mixture pair (mτ(1), mτ(2))where mτ(2)has greater mass in (1−τ), i.e.,X
i:τ(1)
i=1−τw(1)
i≤X
j:τ(2)
j=1−τw(2)
j, is dominated by (mˆτ(1), mˆτ(2))
Notation:
1X
z=0

K++1X
i=1w(1)
i(1− |z−τ(1)
i|)
α
·
K−+1X
j=1w(2)
j(1− |z−τ(2)
j|)
1−α
=1X
z=0f(x(z))g(y(z)),
where fstrictly convex, increasing, and gstrictly convex, decreasing.
Trivial case: θ=1
2, thus assume θ̸=1
2for the rest of the proof.
92𝜃𝜃
𝜏𝜏′0
01
1𝛿𝛿𝑥𝑥
𝛿𝛿�𝑥𝑥
(here: 𝜏𝜏)(here: 𝜏𝜏)𝜏𝜏11=𝜏𝜏12
𝜏𝜏
1−𝜃𝜃
𝜃𝜃 1−𝜃𝜃Figure 26: Visualization of δxandδx′. Color legend: The color “blue” refers to terms with superscript
(1), while “red” refers to those with (2).
Proof of (a):
Given: Pair of mixtures (mτ(1), mτ(2))such that w(1)
1−τ:=X
i:τ(1)
i=1−τw(1)
i≥X
j:τ(2)
j=1−τw(2)
j=:
w(2)
1−τ.
Further define w(1)
τ= 1−w(1)
1−τ, w(2)
τ= 1−w(2)
1−τ.
Define a newmixture via
τ′(1)
1=τ′(2)
1=τ,
τ′(1)
2...,K ++1= 1−τ,
τ′(2)
i=τ(2)
i,∀i.
Assume w.l.o.g. that τ0= max {θ,1−θ}, else swap roles of 0↔1in the argument.
Decompose x:x(z) =x0(z) +δx(z), where
x0(z) =w(1)
1−τ(1− |z−(1−τ)|) +w(1)
1(1− |z−τ|),i.e., “part that stays fixed”; see Fig. 26 ,
δx(z) = (w(1)
τ−w(1)
1)(1− |z−τ|),i.e., “part that relocates”; see Fig. 26 .
Similarly,
x′(z) =x′
0(z) +δx′(z),
and by construction,
x′
0(z) =x0(z),
δx′(z) =δx(1−z) (⋆)
We can assume w.l.o.g. τ0= max {θ,1−θ}=⇒δx(1)> δx(0) (⋆⋆)(else, swap 1↔0)
Then, θ̸=1
2, hence we can assume w(1)
τ> w(1)
1(else, m′≡min the first place).
Ψα(mτ′(1), mτ′(2))−Ψα(mτ(1), mτ(2))
(⋆)= [f(x0(0) + δx(1))−f(x0(0) + δx(0))]g(y(0)))−[f(x0(1) + δx(1))−f(x0(1) + δx(0))]g(y(1))
Then, using that fis strictly convex, we have
(⋆⋆)
> f′(x0(0) + δx(0))g(y(0))(δx(1)−δx(0))−f′(x0(1) + δx(0))g(y(1))(δx(1)−δx(0))
Where f′(x) =xα−1, and thus f′(x)g(y) = (α−1)
x
yα−1
= (α−1)"x0(0) + δx(0)
y(0)α−1
−x0(1) + δx(0)
y(1)α−1#
(δx(1)−δx(0))
= (α−1)
 
(1−w(1)
1−τ(1−τ) +w(1)
1−ττ
(1−w(2)
1−τ)(1−τ) +w(2)
1−ττ!α−1
− 
w(1)
1τ+ (1−w(1)
1)(1−τ)
(1−w(2)
1−τ)τ+w(2)
1−τ(1−τ)!α−1
(δx(1)−δx(0))
>0.
93𝜃𝜃
̃𝜏𝜏0
01
1𝛿𝛿�𝑦𝑦𝛿𝛿𝑦𝑦′
(here: 𝜏𝜏)𝜏𝜏′
1−𝜃𝜃
𝜃𝜃 1−𝜃𝜃(here: 𝜏𝜏)Figure 27: Visualization of δyandδy′. The color “blue” refers to terms with superscript (1), while
“red” refers to those with (2).
The last inequality follows from the following facts. Since we assume w(1)
τ> w(1)
1(else, m≡m′in
the first place), we can bound the second term by:
 
w(1)
1τ+ (1−w(1)
1)(1−τ)
(1−w(2)
1−τ)τ+w(2)
1−τ(1−τ)!α−1
< 
(1−w(1)
1−τ)τ+w1−τ(1−τ)
(1−w(2)
1−τ)τ+w(1)
1−τ(1−τ)≤1!α−1
(i)
Moreover, we have that the first term is bounded by
 
(1−w(1)
1−τ)(1−τ) +w(1)
1−ττ
(1−w(2)
1−τ)(1−τ) +w(2)
1−ττ!α−1
≥1(ii)
(strict >ifw(1)
1−τ> w(2)
1−τ). The conclusion follows from (i),(ii), and since WLOG τ >(1−τ).
We have shown so far:
Ψα(mτ′(1), mτ′(2))>Ψα(mτ(1), mτ(2)).
To complete the proof of (a), we show now that Ψα(m˜τ(1), m˜τ(2))>Ψα(mτ′(1), mτ′(2)).
Idea: Apply symmetric argument to means τ(2).
Since 1 = w(1)
τ+w(1)
1−τ=w(2)
τ+w(2)
1−τ, we have
w(2)
τ′=w(2)
τ≥w(1)
τ> w(1)
τ′,
where w(1)
τ′, w(2)
τ′are defined like w(1)
τ, w(2)
τbut for new means τ′.
Decompose y′:y′(z) =y′
0(z) +δy′(z), where
y′
0(z) =w(2)
τ(1− |z−τ|),i.e., “part that stays fixed”; see Fig. 27. ,
δy′(z) =w(2)
1−τ(1− |z−(1−τ)|),i.e., “part that relocates”; see Fig. 27.
We can assume w.l.o.g. that τ= max {θ,1−θ}, soδy′(0)> δy′(1).
Ψα(m˜τ(1), m˜τ(2))−Ψα(mτ′(1), mτ′(2))
=f(x′(0)) [g(y′
0(0) + δy′(1))−g(y′
0(0) + δy′(0))] + f(x′(1)) [g(y′
0(1) + δy′(0))−g(y′
0(1) + δy′(1))]
And using the strict convexity of fwe have
>[f(x′(1))g′(y′
0(1) + δy′(1))−f(x′(0))g′(y′
0(0) + δy′(1))] ( δy′(0)−δy′(1))
= (α−1)x′(0)
y′
0(0) + δy′(1)α
−x′(1)
y′
0(1) + δy′(1)α
(δy′(0)−δy′(1))
= (α−1)" 
w(1)
τ(1−τ) + (1 −w(1)
τ)τ
1−τ!α
− 
w(1)
ττ+ (1−w(1)
τ)(1−τ)
w(2)
ττ+ (1−w(2)
τ)(1−τ)!α#
·(δy′(0)−δy′(1))
>0.
94Proof of (b)is fully analogous.
This proves the theorem statement, since condition (a) or (b) is fulfilled for any mixture pair, and
hence any mixture pair is dominated by the argmax of the two mixture pairs stated in the theorem.
Theorem O.16.
arg max
τ∈[0,1](K++1)+( K−+1)1X
z=0

K++1X
i=1w(1)
i(1− |z−τ(1)
i|)
−eε
K−+1X
j=1w(2)
j(1− |z−τ(2)
j|)


subject to
τ(1)
i∈ {θ,1−θ},∀i,
τ(1)
j∈ {θ,1−θ},∀j,
τ(1)
1=τ(2)
1,
with
w(1)
i= Binomial( i−1|K−, r),
w(2)
j= Binomial( j−1|K+, r),
is given by
arg max {Ψ (m˜τ(1)∥m˜τ(2)),Ψ (mˆτ(1)∥mˆτ(2))},
where
˜τ(1)
1= ˜τ(2)
1=:τ∈ {θ,1−θ}(symmetric ),
˜τ(1)
2,...,(K++1)= 1−τ,
˜τ(2)
2,...,(K−+1)=τ
and
ˆτ(1)
1= ˆτ(2)
1=:τ∈ {θ,1−θ}(symmetric ),
ˆτ(1)
2,...,(K++1)=τ,
ˆτ(2)
2,...,(K−+1)= 1−τ
Proof sketch.
The strategy is to show that
(a)Any mixture pair (mτ(1), mτ(2))where mτ(1)has greater mass in (1−τ), i.e.,X
i:τ(1)
i=1−τw(1)
i≥X
j:τ(2)
j=1−τw(2)
j, is dominated by (m˜τ(1), m˜τ(2))
(b)Any mixture pair (mτ(1), mτ(2))where mτ(2)has greater mass in (1−τ), i.e.,X
i:τ(1)
i=1−τw(1)
i≤X
j:τ(2)
j=1−τw(2)
j, is dominated by (mˆτ(1), mˆτ(2))
Notation:
1X
z=0

K++1X
i=1w(1)
i(1− |z−τ(1)
i|)
−eε
K−+1X
j=1w(2)
j(1− |z−τ(2)
j|)

=1X
z=0f(x(z)−eεy(z)),
where f= [·]+is convex and differentiable anywhere except at 0.
Trivial case: θ=1
2, thus assume θ̸=1
2for the rest of the proof.
95Proof of (a):
Given: Pair of mixtures (mτ(1), mτ(2))such that w(1)
1−τ:=X
i:τ(1)
i=1−τw(1)
i≥X
j:τ(2)
j=1−τw(2)
j=:
w(2)
1−τ.
Further define w(1)
τ= 1−w(1)
1−τ, w(2)
τ= 1−w(2)
1−τ.
Define a newmixture via
τ′(1)
1=τ′(2)
1=τ,
τ′(1)
2...,K ++1= 1−τ,
τ′(2)
i=τ(2)
i,∀i.
Assume w.l.o.g. that τ0= max {θ,1−θ}, else swap roles of 0↔1in the argument.
Decompose x:x(z) =x0(z) +δx(z), where
x0(z) =w(1)
1−τ(1− |z−(1−τ)|) +w(1)
1(1− |z−τ|),i.e., “part that stays fixed”; see Fig. 26 ,
δx(z) = (w(1)
τ−w(1)
1)(1− |z−τ|),i.e., “part that relocates”; see Fig. 26 .
Similarly,
x′(z) =x′
0(z) +δx′(z),
and by construction,
x′
0(z) =x0(z),
δx′(z) =δx(1−z) (⋆)
We can assume w.l.o.g. τ0= max {θ,1−θ}=⇒δx(1)> δx(0) (⋆⋆)(else, swap 1↔0)
Then, θ̸=1
2, hence we can assume w(1)
τ> w(1)
1(else, m′≡min the first place).
Ψα(mτ′(1), mτ′(2))−Ψα(mτ(1), mτ(2))
(⋆)= [f(x0(0) + δx(1)−eεy(0))−f(x0(0) + δx(0)−eεy(0))]
−[f(x0(1) + δx(1)−eεy(1))−f(x0(1) + δx(0)−eεy(1))]g(y(1))
Assume for now that x0(0) + δx(0)−eεy(0)̸= 0̸=x0(1) + δx(0)−eεy(1).
(⋆⋆)
≥(f′(x0(0) + δx(0)−eεy(0))−f′(x0(1) + δx(0)−eεy(1))) ( δx(1)−δx(0))
=f′h
(1−w(1)
1−τ)(1−τ) +w(1)
1−ττ
−eε
(1−w(2)
1−τ)(1−τ) +w(2)
1−ττi
(δx(1)−δx(0))
−f′h
w(1)
1τ+ (1−w(1)
1)(1−τ)
−eε
(1−w(2)
1−τ)τ+w(2)
1−τ(1−τ)i
(δx(1)−δx(0))
≥f′h
(1−w(1)
1−τ)(1−τ) +w(1)
1−ττ
−eε
(1−w(2)
1−τ)(1−τ) +w(2)
1−ττi
(δx(1)−δx(0))
−f′h
(1−w(1)
1−τ)τ+w1−τ(1−τ)
−eε
(1−w(2)
1−τ)τ+w(2)
1−τ(1−τ)i
(δx(1)−δx(0))
≥0.
The second-to-last inequality follows from w(1)
τ> w(1)
1(else, m≡m′in the first place). The last
inequality follows from w(1)
1−τ> w(2)
1−τand the prior assumption that, WLOG, τ >1−τ.
Ifx0(0) + δx(0)−eεy(0)> x0(1) + δx(0)−eεy(1)andx0(1) + δx(0)−eεy(1) = 0 , then we
can arrive at the same conclusion by using any subderivative of fin[0,1]atx0(1) + δx(0)−eεy(1)
instead.
We have shown so far:
Ψα(mτ′(1), mτ′(2))≥Ψα(mτ(1), mτ(2)).
Continue in analogy to Theorem O.15.
96P Towards epoch-level subsampling analysis
Standard composition theorems assume that the outputs of composed mechanisms are conditionally
independent, meaning each output only depends on the previous outputs and the dataset (see, e.g.,
the proof of Proposition 1 in [ 7] and the proof of Theorem 27 in [ 10]). For this reason, one typically
considers subsampling schemes like Poisson subsampling or subsampling without replacement, which
yield independent batches in each iteration.
However, there may be scenarios where batches are not independent, such as when creating batches
by permuting a dataset and splitting it into equal sized chunks. Such correlated subsampling schemes
are appealing because one can, for instance, limit privacy leakage by ensuring that any element
appears in only one iteration per epoch when training a model. A downside of these corellated
subsampling schemes is that they may brake the conditional independence assumption of standard
compositions theorems.
There already exist approaches to analyzing compositions of correlated mechanisms, such as proba-
bilistically upper-bounding a mechanism’s privacy leakage with uncorellated mechanisms [ 75,24].
Furthermore, permutation-based batching has already been discussed in the context of convergence
guarantees for noisy SGD [ 38]. Nevertheless, this problem setting provides a great opportunity
to demonstrate that the utility of our conditional optimal transport framework extends beyond the
subsampling schemes that are typically discussed in amplification-by-subsampling literature.
P.1 Problem setting
For this example, we consider a non-adaptive composition of two mechanisms, where two batches are
created by permuting a dataset and splitting it in half. We assume that our dataset space is composed
of size 2Nsubsets of some finite, discrete set A, i.e.,X⊆ {x∈ P(A)| |x|= 2N}, and equipped
with substitution relation ≃∆. We further define a per-iteration batch space Ythat is composed of size
Nsubsets, i.e., Y={y⊆x|x∈X∧ |y|=N}, which is also equipped with substitution relation
≃∆. Finally, we assume a base mechanism B:Y→Zwith conditional density by:Z→R+that
maps from this batch space to some output space.
To apply our framework to epoch-level subsampling distributions, we define the composed batch
spaceY, which consists of equal-sized partitions of datasets in X, i.e.,
ˆY={(y1, y2)∈Y2
orig| ∃x∈X:y1˙∪y2=x}. (37)
On this composed batch space, we can now define our epoch-level subsampling scheme:
Definition P.1. The permute-and-partition subsampling scheme is the subsampling scheme S:X→
ˆYwith
sx((y1, y2)) =( 2N
N−1ify1∪y2=x
0 otherwise .
This definition follows from the fact that permuting-and-partitioning is equivalent to sampling a
batch of size Nwithout replacement for the first batch and using the remaining Nelements for the
second batch. We further consider the non-adaptively composed base mechanism ˆB:ˆY→Z2with
ˆB(y1,y2)= (By1, By2)and resultant joint density ˆb(y1,y2)=by1·by2.
P.2 Optimal transport without conditioning
As a baseline, we use Theorem 3.3, i.e., optimal transport without conditioning, to provide a Rényi-
DP bound for the composed, subsampled mechanism. This guarantee captures the intuition that by
permuting-and-partitioning, we only leak an elements’ private information once. Again, note we
prove this result for non-adaptive composition.
Theorem P.2. Assume a dataset space X⊆ {x∈ P(A)| |x|= 2N}, batch space Y={y⊆x|
x∈X∧ |y|=N}, and a base mechanism B:Y→Zthat is (α, ε)-Rényi-DP w.r.t. single-element
substitution relation ≃∆,Y. LetS:X→ˆYbe the permute-and-partition subsampling scheme defined
in Definition P .1. Let ˆBbe the composed base mechanism with ˆB(y1,y2)= (By1, By2). Then the
subsampled, composed mechanism ˆM=ˆB◦Sis also (α, ε)-DP w.r.t. single-element substitution
relation ≃∆,X.
97Proof. Consider an arbitrary pair of datasets x≃∆,X. By definition of the substitution relation, there
must be some a∈xand some a′∈x′such that x′=x\ {a} ∪ {a′}.
We can now define the following simple coupling between SxandSx′:
γ((y(1)
1, y(1)
2),(y(2)
1, y(2)
2)) =

 2N
N−1ifa∈y(1)
1∧y(2)
1=y(1)
1\ {a} ∪ {a′} ∧y(1)
2=y(2)
2 2N
N−1ifa∈y(1)
2∧y(2)
2=y(1)
2\ {a} ∪ {a′} ∧y(1)
1=y(2)
1
0 otherwise .
This coupling generates a pair of batch sequences by first applying permute-and-partition to original
dataset xand then replacing awitha′in the one batch it appears in. Because we only couple pairs
that are identical in one batch and differ by a substitution in the other batch, we have per Theorem 3.3
Ψ( ˆmx||ˆmx′)≤ max
(y(1)
1,y(1)
2),(y(2)
1,y(2)
2)∈ˆY2Ψ(by(1)
1·by(1)
2||by(2)
1·by(2)
2)
subject to (y(1)
1≃∆,Yy(2)
1)∧(y(1)
2=y(2)
2)∨(y(1)
2≃∆,Yy(2)
2)∧(y(1)
1=y(2)
1). Either way, one of
the factors is cancelled out when computing the likelihood ratio in the definition of Rényi-divergence
(see Eq. (7)). We thus have
Ψ( ˆmx||ˆmx′)≤ max
y(1)
1,y(2)
1∈Y2Ψ(by(1)
1||by(2)
1)
subject to y(1)
1≃∆,Yy(2)
1. The result then follows from the definition of Rényi-DP (see Definition 2.2).
P.3 Optimal transport with conditioning
Next, we use Theorem 3.4, i.e., optimal transport between conditional subsampling distributions, to
derive a stronger guarantee. Again, note we prove this result for non-adaptive composition. Note that
this result is similar in spirit to amplification by shuffling [ 76,75], but considers central differential
privacy of mechanisms operating on batches, instead of locally differentially private mechanisms
that operate on individual elements. Again, note that we do not claim to be the first to consider the
permute-and-partition scheme for composed mechanisms (see, e.g., [ 38]). It is just a nice showcase
for the versatility of our framework in analyzing different subsampling schemes.
For the following result and proof we will use the following indexing convention: y(1)
i,kis a batch
associated with the first mixture ˆmx, event Ai, and the kth iteration. Similarly, y(2)
j,kis a batch
associated with the second mixture ˆmx′, event Ej, and the kth iteration.
Theorem P.3. Assume a dataset space X⊆ {x∈ P(A)| |x|= 2N}, and corresponding batch
space Y={y⊆x|x∈X∧ |y|=N}, equipped with single-element substitution relation
≃∆,Y. LetS:X→ˆYbe the permute-and-partition subsampling scheme defined in Definition P .1,
and let B:Y→Zbe some base mechanism. Let ˆBbe the composed base mechanism with
ˆB(y1,y2)= (By1, By2), and ˆM=ˆB◦Sbe the subsampled, coposed mechanism. Then, for all
x≃∆,Xx′,
Ψα( ˆmx||ˆmx′)
≤ max
y(1)
1,1,y(1)
1,2,y(2)
1,1Ψα
by(1)
1,1·by(1)
1,2·1
2+by(1)
1,2·by(1)
1,1·1
2||by(2)
1,1·by(1)
1,2·1
2+by(1)
1,2·by(2)
1,1·1
2
subject to y(1)
1,1≃∆,Yy(2)
1,1.
Proof. By definition of the substitution relation, there must be some a∈xand some a′∈x′such
thatx′=x\ {a} ∪ {a′}.
For the original subsampling scheme Sxwe let A1be the event that aappears in the first batch and
A2be the event that aappears in the second batch. For the modified subsampling scheme Sx′we let
E1be the event that a′appears in the first batch and E2be the event that a′appears in the second
batch. We have PSx(A1) =PSx(A2) =PS′x(E1) =PS′x(E2) =1
2.
98One can sample from the distributions conditioned on A1orE1by first sampling uniformly at random
Nelements from the 2·N−1elements that are notaora′, and then using the remaining elements
as the first batch. Similarly, one can sample from the distributions conditioned on A2orE2by first
sampling uniformly at random Nelements from the 2·N−1elements that are notaora′, and then
using the remaining elements as the second batch.
We thus have
sx(y(1)
1|A1) =( 2N−1
N−1ify(1)
1∈A1
0 otherwisesx(y(1)
2|A2) =( 2N−1
N−1ify(1)
1∈A2
0 otherwise
and
sx′(y(2)
1|E1) =( 2N−1
N−1ify(1)
1∈E1
0 otherwisesx′(y(2)
2|E2) =( 2N−1
N−1ify(1)
1∈E2
0 otherwise
Next, we can define a coupling via
γ(y(1)
1, y(1)
2, y(2)
1, y(2)
2) =(
sx(y(1)
1|A1)if Condition P.4 is fulfilled
0 otherwise
Condition P.4. Batch tuples y(1)
1∈A1, y(1)
2∈A2, y(2)
1∈E1, y(2)
2∈E2fulfill Condition P.4 when
y(1)
1,1=y(1)
2,2, and y(1)
1,2=y(1)
2,1, and y(1)
1,2=y(2)
1,2, and y(1)
2,1=y(2)
2,1, and y(2)
1,1=y(2)
1,1\ {a} ∪ {a′}, and
y(2)
2,2=y(2)
2,2\ {a} ∪ {a′}.
In short: We sample uniformly at random a batch tuple (y(1)
1,1, y(1)
1,2)from A1. We then generate a
batch tuple from A2by permuting the A1tuple. We then generate a batch tuple from E2by replacing
awitha′in the A2tuple. We finally generate a batch tuple from E1by permuting the E2tuple.
Because for each possible value of a batch tuple there is only one combination of the other three
batch tuples such that γ(y)>0, and in this case γ(y) = 2N−1
N−1, this is a valid coupling.
The result then follows from Theorem 3.4 and the constraints imposed by Condition P.4.
Note that this result could be generalized to Kiterations: We can upper-bound the subsampled,
composed mechanism’s divergence by adversarially choosing a K-fold partition of x, constructing
a mixture with K(notK!) components, with each component corresponding to aappearing in a
specific batch, and finally constructing a modified mixture by replacing every occurence of awitha′.
P.4 Experimental Evaluation
Finally, we can compare our epoch-level amplification guarantees obtained via optimal transport
with and without conditioning. As an additional baseline, we use 2-fold composition of subsampling
without replacement with batch size 2. Note that, with the baseline, a modified element may appear in
0,1or2of the iterations. For the sake of this simple example, we consider output space Z=R, and
let base mechanism bbe the Gaussian mechanism f+N(0, σ)withf:Y→ {0,1}and univariate
standard deviation σ∈ {0.5,1.0,2.0,5.0}. By this construction we do not need to reason about f’s
sensitivity in determining the worst-case mixture components.
We make the following observation: For small σ, both epoch-level guarantees are almost identical and
outperform the without replacement guarantee. With increasing σ, subsampling without replacement
outperforms Theorem P.2 for some ranges of α. Theorem P.2, which is derived via conditional
optimal transport, however yields smaller ε.
The main takeaway of this example should be that (a) there is a benefit to using conditional optimal
transport to bound privacy in terms of mixtures and (b) conditional optimal transport can be used to
reason about schemes other than the typically considered Poisson subsampling, subsampling without
replacement, and subsampling with replacement.
99q / N = 0.01
101102
RDP order α101102RDPε(α)Without replacement
Theorem P.2
Theorem P.3q / N = 0.1
101102
RDP order α100101102RDPε(α)Without replacement
Theorem P.2
Theorem P.3
q / N = 0.2
101102
RDP order α10−1100101RDPε(α)Without replacement
Theorem P.2
Theorem P.3q / N = 0.5
101102
RDP order α10−210−1100RDPε(α)Without replacement
Theorem P.2
Theorem P.3
Figure 28: Comparison of our epoch-level permute-and-partition guarantees with (Theorem P.3)
and without (Theorem P.2) conditioning, as well as subsampling without replacement, for 2-fold
non-adaptive composition. The base mechanism is a Gaussian mechanism with f:Y→ {0,1}and
varying standard deviations σ. With increasing σ, Theorem P.3 and subsampling without replacement
become more similar, while Theorem P.3 consistently yields stronger guarantees.
Q Broader impact
Our work contributes towards provably protecting users, and specifically groups of users, from the
negative societal impact of privacy leakage. However, differential privacy may have negatively impact
other aspects of trustworthy machine learning, such as fairness or robustness. Also, training for
differentially private machine learning is often performed with 1< ε≤10. This is useful for relative
comparisons between models, but does not impose any meaningful constraints on absolute privacy
leakage (the probability of any event may increase by a factor of up to ≈22000 ) and may thus be
used to falsely advertise privacy.
100NeurIPS Paper Checklist
1.Claims
Question: Do the main claims made in the abstract and introduction accurately reflect the
paper’s contributions and scope?
Answer: [Yes]
Justification: We verify the generality of our proposed framework by formally deriving
various known and novel subsampling guarantees Appendices G to I and K to M. We
verify the benefit of using mechanism-specific guarantees and analyzing group privacy and
subsampling jointly through our experimental evaluation in Section 4.
Guidelines:
•The answer NA means that the abstract and introduction do not include the claims
made in the paper.
•The abstract and/or introduction should clearly state the claims made, including the
contributions made in the paper and important assumptions and limitations. A No or
NA answer to this question will not be perceived well by the reviewers.
•The claims made should match theoretical and experimental results, and reflect how
much the results can be expected to generalize to other settings.
•It is fine to include aspirational goals as motivation as long as it is clear that these goals
are not attained by the paper.
2.Limitations
Question: Does the paper discuss the limitations of the work performed by the authors?
Answer: [Yes]
Justification: We discuss limitations in Section 3.5. Our main contribution is a framework
for proving theoretic results, as such many of the points listed below do not apply.
Guidelines:
•The answer NA means that the paper has no limitation while the answer No means that
the paper has limitations, but those are not discussed in the paper.
• The authors are encouraged to create a separate "Limitations" section in their paper.
•The paper should point out any strong assumptions and how robust the results are to
violations of these assumptions (e.g., independence assumptions, noiseless settings,
model well-specification, asymptotic approximations only holding locally). The authors
should reflect on how these assumptions might be violated in practice and what the
implications would be.
•The authors should reflect on the scope of the claims made, e.g., if the approach was
only tested on a few datasets or with a few runs. In general, empirical results often
depend on implicit assumptions, which should be articulated.
•The authors should reflect on the factors that influence the performance of the approach.
For example, a facial recognition algorithm may perform poorly when image resolution
is low or images are taken in low lighting. Or a speech-to-text system might not be
used reliably to provide closed captions for online lectures because it fails to handle
technical jargon.
•The authors should discuss the computational efficiency of the proposed algorithms
and how they scale with dataset size.
•If applicable, the authors should discuss possible limitations of their approach to
address problems of privacy and fairness.
•While the authors might fear that complete honesty about limitations might be used by
reviewers as grounds for rejection, a worse outcome might be that reviewers discover
limitations that aren’t acknowledged in the paper. The authors should use their best
judgment and recognize that individual actions in favor of transparency play an impor-
tant role in developing norms that preserve the integrity of the community. Reviewers
will be specifically instructed to not penalize honesty concerning limitations.
3.Theory Assumptions and Proofs
101Question: For each theoretical result, does the paper provide the full set of assumptions and
a complete (and correct) proof?
Answer: [Yes]
Justification: Yes, we provide formal proofs for all theoretical results in Appendix E through
Appendix P. All theorems and lemmata state the underlying assumptions.
Guidelines:
• The answer NA means that the paper does not include theoretical results.
•All the theorems, formulas, and proofs in the paper should be numbered and cross-
referenced.
•All assumptions should be clearly stated or referenced in the statement of any theorems.
•The proofs can either appear in the main paper or the supplemental material, but if
they appear in the supplemental material, the authors are encouraged to provide a short
proof sketch to provide intuition.
•Inversely, any informal proof provided in the core of the paper should be complemented
by formal proofs provided in appendix or supplemental material.
• Theorems and Lemmas that the proof relies upon should be properly referenced.
4.Experimental Result Reproducibility
Question: Does the paper fully disclose all the information needed to reproduce the main ex-
perimental results of the paper to the extent that it affects the main claims and/or conclusions
of the paper (regardless of whether the code and data are provided or not)?
Answer: [Yes]
Justification: We fully describe our experimental setup in Appendix C. We further provide
an implementation with the supplementary material, which includes the needed environment,
code, configuration files, and plotting scripts.
Guidelines:
• The answer NA means that the paper does not include experiments.
•If the paper includes experiments, a No answer to this question will not be perceived
well by the reviewers: Making the paper reproducible is important, regardless of
whether the code and data are provided or not.
•If the contribution is a dataset and/or model, the authors should describe the steps taken
to make their results reproducible or verifiable.
•Depending on the contribution, reproducibility can be accomplished in various ways.
For example, if the contribution is a novel architecture, describing the architecture fully
might suffice, or if the contribution is a specific model and empirical evaluation, it may
be necessary to either make it possible for others to replicate the model with the same
dataset, or provide access to the model. In general. releasing code and data is often
one good way to accomplish this, but reproducibility can also be provided via detailed
instructions for how to replicate the results, access to a hosted model (e.g., in the case
of a large language model), releasing of a model checkpoint, or other means that are
appropriate to the research performed.
•While NeurIPS does not require releasing code, the conference does require all submis-
sions to provide some reasonable avenue for reproducibility, which may depend on the
nature of the contribution. For example
(a)If the contribution is primarily a new algorithm, the paper should make it clear how
to reproduce that algorithm.
(b)If the contribution is primarily a new model architecture, the paper should describe
the architecture clearly and fully.
(c)If the contribution is a new model (e.g., a large language model), then there should
either be a way to access this model for reproducing the results or a way to reproduce
the model (e.g., with an open-source dataset or instructions for how to construct
the dataset).
(d)We recognize that reproducibility may be tricky in some cases, in which case
authors are welcome to describe the particular way they provide for reproducibility.
In the case of closed-source models, it may be that access to the model is limited in
102some way (e.g., to registered users), but it should be possible for other researchers
to have some path to reproducing or verifying the results.
5.Open access to data and code
Question: Does the paper provide open access to the data and code, with sufficient instruc-
tions to faithfully reproduce the main experimental results, as described in supplemental
material?
Answer: [Yes]
Justification: We provide an implementation that includes the needed environment,
code, configuration files, and plotting scripts for reproducing our experimental results
at https://cs.cit.tum.de/daml/group-amplification.
Guidelines:
• The answer NA means that paper does not include experiments requiring code.
•Please see the NeurIPS code and data submission guidelines ( https://nips.cc/
public/guides/CodeSubmissionPolicy ) for more details.
•While we encourage the release of code and data, we understand that this might not be
possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not
including code, unless this is central to the contribution (e.g., for a new open-source
benchmark).
•The instructions should contain the exact command and environment needed to run to
reproduce the results. See the NeurIPS code and data submission guidelines ( https:
//nips.cc/public/guides/CodeSubmissionPolicy ) for more details.
•The authors should provide instructions on data access and preparation, including how
to access the raw data, preprocessed data, intermediate data, and generated data, etc.
•The authors should provide scripts to reproduce all experimental results for the new
proposed method and baselines. If only a subset of experiments are reproducible, they
should state which ones are omitted from the script and why.
•At submission time, to preserve anonymity, the authors should release anonymized
versions (if applicable).
•Providing as much information as possible in supplemental material (appended to the
paper) is recommended, but including URLs to data and code is permitted.
6.Experimental Setting/Details
Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
results?
Answer: [Yes]
Justification: We fully describe our experimental setup in Appendix C. Note that these
experiments only require numerical evaluation of different divergences, meaning there are
no involved data splits or optimizers.
Guidelines:
• The answer NA means that the paper does not include experiments.
•The experimental setting should be presented in the core of the paper to a level of detail
that is necessary to appreciate the results and make sense of them.
•The full details can be provided either with the code, in appendix, or as supplemental
material.
7.Experiment Statistical Significance
Question: Does the paper report error bars suitably and correctly defined or other appropriate
information about the statistical significance of the experiments?
Answer: [No]
Justification: Our experiments only require numerical evaluation of different divergences.
There are no typical sources of randomness like data splits or weight initializations that
could be visualized with error bars.
Guidelines:
103• The answer NA means that the paper does not include experiments.
•The authors should answer "Yes" if the results are accompanied by error bars, confi-
dence intervals, or statistical significance tests, at least for the experiments that support
the main claims of the paper.
•The factors of variability that the error bars are capturing should be clearly stated (for
example, train/test split, initialization, random drawing of some parameter, or overall
run with given experimental conditions).
•The method for calculating the error bars should be explained (closed form formula,
call to a library function, bootstrap, etc.)
• The assumptions made should be given (e.g., Normally distributed errors).
•It should be clear whether the error bar is the standard deviation or the standard error
of the mean.
•It is OK to report 1-sigma error bars, but one should state it. The authors should
preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis
of Normality of errors is not verified.
•For asymmetric distributions, the authors should be careful not to show in tables or
figures symmetric error bars that would yield results that are out of range (e.g. negative
error rates).
•If error bars are reported in tables or plots, The authors should explain in the text how
they were calculated and reference the corresponding figures or tables in the text.
8.Experiments Compute Resources
Question: For each experiment, does the paper provide sufficient information on the com-
puter resources (type of compute workers, memory, time of execution) needed to reproduce
the experiments?
Answer: [Yes]
Justification: Yes, we report the type and number of CPUs, as well as the number of workers
and allocated runtime Appendix C.2.
Guidelines:
• The answer NA means that the paper does not include experiments.
•The paper should indicate the type of compute workers CPU or GPU, internal cluster,
or cloud provider, including relevant memory and storage.
•The paper should provide the amount of compute required for each of the individual
experimental runs as well as estimate the total compute.
•The paper should disclose whether the full research project required more compute
than the experiments reported in the paper (e.g., preliminary or failed experiments that
didn’t make it into the paper).
9.Code Of Ethics
Question: Does the research conducted in the paper conform, in every respect, with the
NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines ?
Answer: [Yes]
Justification: The research in this paper conforms, in every respect, with the code of ethics.
Guidelines:
•The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
•If the authors answer No, they should explain the special circumstances that require a
deviation from the Code of Ethics.
•The authors should make sure to preserve anonymity (e.g., if there is a special consid-
eration due to laws or regulations in their jurisdiction).
10.Broader Impacts
Question: Does the paper discuss both potential positive societal impacts and negative
societal impacts of the work performed?
Answer: [Yes]
104Justification: Yes, we discuss both positive and negative broader impact in Appendix Q,
which we reference in our “Limitations, broader impact, and future work” section Sec-
tion 3.5.
Guidelines:
• The answer NA means that there is no societal impact of the work performed.
•If the authors answer NA or No, they should explain why their work has no societal
impact or why the paper does not address societal impact.
•Examples of negative societal impacts include potential malicious or unintended uses
(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
(e.g., deployment of technologies that could make decisions that unfairly impact specific
groups), privacy considerations, and security considerations.
•The conference expects that many papers will be foundational research and not tied
to particular applications, let alone deployments. However, if there is a direct path to
any negative applications, the authors should point it out. For example, it is legitimate
to point out that an improvement in the quality of generative models could be used to
generate deepfakes for disinformation. On the other hand, it is not needed to point out
that a generic algorithm for optimizing neural networks could enable people to train
models that generate Deepfakes faster.
•The authors should consider possible harms that could arise when the technology is
being used as intended and functioning correctly, harms that could arise when the
technology is being used as intended but gives incorrect results, and harms following
from (intentional or unintentional) misuse of the technology.
•If there are negative societal impacts, the authors could also discuss possible mitigation
strategies (e.g., gated release of models, providing defenses in addition to attacks,
mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
feedback over time, improving the efficiency and accessibility of ML).
11.Safeguards
Question: Does the paper describe safeguards that have been put in place for responsible
release of data or models that have a high risk for misuse (e.g., pretrained language models,
image generators, or scraped datasets)?
Answer: [NA]
Justification: We do not propose any new data or models that could be released.
Guidelines:
• The answer NA means that the paper poses no such risks.
•Released models that have a high risk for misuse or dual-use should be released with
necessary safeguards to allow for controlled use of the model, for example by requiring
that users adhere to usage guidelines or restrictions to access the model or implementing
safety filters.
•Datasets that have been scraped from the Internet could pose safety risks. The authors
should describe how they avoided releasing unsafe images.
•We recognize that providing effective safeguards is challenging, and many papers do
not require this, but we encourage authors to take this into account and make a best
faith effort.
12.Licenses for existing assets
Question: Are the creators or original owners of assets (e.g., code, data, models), used in
the paper, properly credited and are the license and terms of use explicitly mentioned and
properly respected?
Answer: [Yes]
Justification: We list the libraries that we use and/or extend to conduct our numerical
experiments in Appendix C.3, including version numbers and licenses. We cite the original
papers where applicable.
Guidelines:
• The answer NA means that the paper does not use existing assets.
105• The authors should cite the original paper that produced the code package or dataset.
•The authors should state which version of the asset is used and, if possible, include a
URL.
• The name of the license (e.g., CC-BY 4.0) should be included for each asset.
•For scraped data from a particular source (e.g., website), the copyright and terms of
service of that source should be provided.
•If assets are released, the license, copyright information, and terms of use in the
package should be provided. For popular datasets, paperswithcode.com/datasets
has curated licenses for some datasets. Their licensing guide can help determine the
license of a dataset.
•For existing datasets that are re-packaged, both the original license and the license of
the derived asset (if it has changed) should be provided.
•If this information is not available online, the authors are encouraged to reach out to
the asset’s creators.
13.New Assets
Question: Are new assets introduced in the paper well documented and is the documentation
provided alongside the assets?
Answer: [NA]
Justification: We do not release new assets.
Guidelines:
• The answer NA means that the paper does not release new assets.
•Researchers should communicate the details of the dataset/code/model as part of their
submissions via structured templates. This includes details about training, license,
limitations, etc.
•The paper should discuss whether and how consent was obtained from people whose
asset is used.
•At submission time, remember to anonymize your assets (if applicable). You can either
create an anonymized URL or include an anonymized zip file.
14.Crowdsourcing and Research with Human Subjects
Question: For crowdsourcing experiments and research with human subjects, does the paper
include the full text of instructions given to participants and screenshots, if applicable, as
well as details about compensation (if any)?
Answer: [NA]
Justification: This paper does not involve crowdsourcing nor research with human subjects.
Guidelines:
•The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
•Including this information in the supplemental material is fine, but if the main contribu-
tion of the paper involves human subjects, then as much detail as possible should be
included in the main paper.
•According to the NeurIPS Code of Ethics, workers involved in data collection, curation,
or other labor should be paid at least the minimum wage in the country of the data
collector.
15.Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
Subjects
Question: Does the paper describe potential risks incurred by study participants, whether
such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
approvals (or an equivalent approval/review based on the requirements of your country or
institution) were obtained?
Answer: [NA]
Justification: This paper does not involve crowdsourcing nor research with human subjects.
106Guidelines:
•The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
•Depending on the country in which research is conducted, IRB approval (or equivalent)
may be required for any human subjects research. If you obtained IRB approval, you
should clearly state this in the paper.
•We recognize that the procedures for this may vary significantly between institutions
and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
guidelines for their institution.
•For initial submissions, do not include any information that would break anonymity (if
applicable), such as the institution conducting the review.
107