Gated Inference Network: Inference and Learning
State-Space Models
Hamidreza Hashempoor
Seoul National University
Department of Electrical and Computer Engineering
hamidreza.hashemp@snu.ac.kr
Wan Choi
Seoul National University
Department of Electrical and Computer Engineering
wanchoi@snu.ac.kr
Abstract
This paper advances temporal reasoning within dynamically changing high-
dimensional noisy observations, focusing on a latent space that characterizes
the nonlinear dynamics of objects in their environment. We introduce the Gated
Inference Network (GIN), an efficient approximate Bayesian inference algorithm
for state space models (SSMs) with nonlinear state transitions and emissions. GIN
disentangles two latent representations: one representing the object derived from a
nonlinear mapping model, and another representing the latent state describing its
dynamics. This disentanglement enables direct state estimation and missing data
imputation as the world evolves. To infer the latent state, we utilize a deep extended
Kalman filter (EKF) approach that integrates a novel compact RNN structure to
compute both the Kalman Gain (KG) and smoothing gain (SG), completing the
data flow. This design results in a computational cost per step that is linearly
faster than EKF but introduces issues such as the exploding gradient problem.
To mitigate the exploding gradients caused by the compact RNN structure in our
model, we propose a specialized learning method that ensures stable training and
inference. The model is then trained end-to-end on videos depicting a diverse range
of simulated and real-world physical systems, and outperforms its counterparts
—RNNs, autoregressive models, and variational approaches— in state estimation
and missing data imputation tasks.
1 Introduction
A state-space model is a type of graphical model that effectively represents noise-afflicted data
[1]. Typically, the objective is to conduct inference, which involves obtaining accurate estimates of
the posterior distribution of latent states or noise-free measurements. In videos, inferring the state
space presents a complex challenge owing to the high dimensionality of noisy observations, which
only offer partial information about the states. Previous methods have proposed various inference
approaches such as sampling [ 2], variational inference [ 3], or belief propagation [ 4]. Within the
framework of a hidden Markov process, classical methods like the celebrated Kalman filter (KF) and
smoother [ 5,6], along with their extensions like EKF and UKF, [ 7,8] have been employed to address
the posterior inference problem. However, the reliance of these methods on accurate knowledge of
the underlying dynamics, coupled with computationally intensive matrix inversions, poses challenges
in scalability to high-dimensional latent spaces.
38th Conference on Neural Information Processing Systems (NeurIPS 2024).To address these issues, this paper distinguishes between the sensory observation and its dynamics by
disentangling two representations: a transformed observation wtobtained by mapping the original
sensory observation otthrough a nonlinear function modeled by neural networks, and the latent
state space xtdescribing the dynamics of wtat time step t. To infer high dimensional state space
(dynamics) xt, we introduce filtering and smoothing techniques that build upon classical EKF
updates but incorporate flexible function estimators without relying on a constrained graphical model.
We model temporal dynamics with a linearized Gaussian SSM, which is adapted to accommodate
complex dynamics. To address non-linearity and the multiplicity of dynamics, we learn multiple
transition and emission matrices, each modeling a unique dynamical scenario. Then, the weight
of each matrix during inference is determined by the past state xt−1through a neural network. To
prevent mode collapse and ensure the system’s ability to capture diverse dynamics, we introduce a
loss term proportional to the KL divergence of the transition matrices during training. This design
enables our model to handle various state scenarios, similar to approaches found in the switching
linear dynamics systems (SLDS) literature [ 9]. Unlike EKF, which requires precise characterization
and modeling of the underlying dynamics, we operate under the assumption that noise statistics and
the underlying physical dynamics of SSM are entirely unknown.
The main drawback of the EKF is that it takes O(n3)time per step, because we need to invert the
posterior covariance matrix with size of n. This makes the method slow to use. Moreover, we identify
the computation of the KG and SG in the (extended) KF as critical components that rely on noise
statistics and domain knowledge. In this paper, we efficiently model KG and SG using GRU cells,
bypassing the need for matrix inversion in the KF flow. Consequently, the GIN algorithm achieves
a time complexity of O(β2n2)per step, making it linearly faster than EKF. To capitalize on the
sparsity of the covariance matrix, we employ a convolutional approach that further reduces the size of
nrelative to β, where 0< β < 1. However, the nonlinear structure of GRU cells can lead to gradient
explosion [ 10], a phenomenon that occurs when the dynamics undergo significant changes as GRU
parameters traverse bifurcation points [ 11] during the learning process. To address this issue, we
propose a learning method based on an analysis of GRU cell dynamics. This method aims to prevent
parameter values from reaching bifurcation points by stabilizing the dynamics of GRU cells, thereby
addressing the issue of gradient explosion.
To summarize, our primary contribution is a novel algorithm designed for the recursive inference of
SSMs with arbitrary nonlinear (and possibly non-Gaussian) emission and transition models, with
high-dimensional noisy stimuli observation. This algorithm utilizes a linearized Gaussian dynamics
approach, with parameter estimation conducted through neural networks. This means that we can
apply the recursive Bayesian updates, akin to the Kalman filter and Kalman smoother. We introduce a
likelihood for inferring the states (dynamics) and another likelihood for inferring the high-dimensional
images (of video). The objective is maximized in a supervised manner, depending on the task. We
propose learning schemes for GRU cells to address issues related to gradient explosion and instability.
Finally, we introduce a loss term proportional to the KL divergence of the learned transition matrices
to prevent the system from becoming stuck in mode collapse.
To substantiate our claims, we conduct five experiments. First, we simulate a nonlinear dynamic
system using the pendulum sequence video, a common benchmark in this literature, to demonstrate
our model’s ability to infer both dynamics and images. Second, we introduce a more challenging
experiment of a simulated nonlinear double pendulum, where the video sequence is heavily distorted
with noise, showcasing our model’s resilience of dynamics estimation and image imputation to noisy
observations. Third, we present a switching dynamics irregular bouncing ball experiment to illustrate
our model’s ability to handle multiple dynamic scenarios. Fourth, we perform visual odometry using
the KITTI dataset, demonstrating the practical applicability of our methods in real-world scenarios.
Finally, we assess the effectiveness of our proposed gradient explosion handling scheme by evaluating
convergence across various simulation seeds.
2 Related Works
EKF and UKF represent early extensions of the original Kalman filter, allowing for nonlinear
transitions and emissions. These methods, categorized as model-based (MB) algorithms, rely on
precise knowledge and modeling of the underlying dynamics within a fully characterized SSM.
Consequently, the performance of these MB methods is heavily contingent on the accuracy of domain
knowledge and model assumptions. Recent approaches, such as BackpropKF [ 12] and SIN [ 13],
perform EKF in the latent state using deep encoders for feature extraction. However, they face similar
2Figure 1: Generated sequences from GIN in the irregular polygon environments. The videos are
shown as single images, with color intensity representing the incremental sequence index.
limitations as EKF, including computational complexity and scalability. To address these issues, a
common approach involves considering a diagonal covariance matrix in the KF flow as in [ 14] and
[15]. However, we aim to find a richer approximation to the posterior.
A significant body of work, including Variational Auto-Encoders (V AE) [ 3], Embed to Control
(E2C) [ 16], and Importance Weighted V AE (IWV AE) [ 17], integrates deep learning with variational
inference (VI), but lacks memory cells and recurrent structures for handling imputation tasks. To
address this, EM-based VI approaches like Structure V AE (SV AE) [ 18], Kalman V AE (KV AE) [ 19],
Disentangled V AE (DV AE) [ 20], Extended KV AE (EKV AE) [ 21], Robust V AE [ 22], and Markovian
V AE (MV AE) [ 23] use original KF equations for filtering and smoothing. However, they cannot
directly optimize states (dynamics), as noted in RKN [ 24] and CRU [ 25]. Classical memory networks
like LSTMs [ 26], GRUs [ 27], and simple RNNs [ 28] infer latent states but fail to provide insights
into uncertainties and dynamics.
LatentNet [ 29], KalmanNet [ 30] and SSI-SSM [ 31] utilize GRU in their structures for state updates,
similar to the parameterization used in the GIN. However, these models typically necessitate access
to complete or partial dynamics information, i.e. they are MB, and their reliance on vanilla GRU
cells can cause instability of the SSM. Liu et al. [ 32] proposes a disentanglement model for audio
data, which shares similarities with the GIN. However, their parameterization and objectives differ
from those of the GIN, and they do not utilize compact RNNs in their inference structure.
We cover the most relevant works in this section. A more detailed discussion, including a comprehen-
sive comparison of recent related works like System Identification (SI) with details of EM algorithm,
auto-regressive (AR) and SLDS models, is provided in Appendix A.8.3 and Table 7. This builds upon
the findings of the RKN with additional complements. We also conduct an empirical complexity
analysis in appendix A.8.2, to evaluate the computational efficiency of our method compared to the
discussed approaches. This analysis involved measuring the execution time per iteration using a clock
on the wall as the benchmark.
3 Background
Linear Gaussian state space models. Linear Gaussian state space models (LGSSMs) are
commonly employed to model vectors of observed time series, denoted as w= [w1, ...,wT].
LGSSMs excel in filtering and smoothing tasks. They model the first-order Markov process on the
state space x= [x1, ...,xT], which may also incorporate external control inputs u= [u1, ...,uT]
under the multivariate normality assumption of the state:
pγt(xt|xt−1,ut) =N(xt;Ftxt−1+Btut,Qt), p γt(wt|xt) =N(wt;Htxt,Rt). (1)
γtrepresents the parameters of the system at time t, encapsulating information from matrices
Ft,Bt,Ht,QtandRt, which correspond to the state transition, control, emission, process noise
covariance, and observation noise covariance, respectively. At each time step, the transition and
emission procedures are subject to distortion caused by process noise and observation noise, following
distributions of N(0,Qt)andN(0,Rt), respectively.
Filtering and smoothing algorithms. The goal of filtering is to infer the posterior dis-
tribution pγ1:t(xt|w1:t,u1:t), while, the smoothing aims to infer the smoothing distribution
pγ1:T(xt|w1:T,u1:T)given the whole observations. Without loss of generality, we drop the in-
put variable uin the rest of paper, while one can condition all of the distributions on the input
variable in the case of its existence. Considering the prior state parameterization pγ1:t(xt|w1:t−1) =
N(µt|t−1,Σt|t−1)and relying on [33], the filtering and smoothing parameterizations are as:
3𝑞𝑡−1
x𝑡−1
w𝑡−1𝑞𝑡
x𝑡
w𝑡𝑞𝑡+1
x𝑡+1
w𝑡+1…
…
……
…
…
o𝑡−1s𝑡−1 o𝑡 s𝑡o𝑡+1s𝑡+1Figure 2: Graphical model. Dashed nodes are
task dependent output.
𝑒(.) Transition Block 𝑑(.)𝒐1:𝑇 (𝒘1:𝑇,𝒓1:𝑇)(𝒙𝟏:𝑇|𝒘1:𝑇) {𝑠1:𝑇,𝑜1:𝑇}Figure 3: The GIN as a HW model for system
identification. By appropriate structure selection
fore(.)andd(.), the GIN can handle high di-
mensional observations. The relation between
the internal variables, wtandxt, is simulated by
the transition block.
pγ1:t(xt|w1:t) =N
µt|t−1+Kt[wt−Htµt|t−1],Σt|t−1−KtSfKT
t
=N 
µt|t,Σt|t
(2)
pγ1:T(xt|w1:T) =N
µt|t+Jt[µt+1|T−Ft+1µt|t],Σt|t+JtSsJT
t
=N(µt|T,Σt|T)(3)
Kt=Σt|t−1HT
t.
HtΣt|t−1HT
t+Rt−1,Jt=Σt|tFT
t+1Σ−1
t+1|t(4)
withSf= [HtΣt|t−1HT
t+Rt]andSs=
Σt+1|T−Σt+1|t
. In (4), KtandJtare KG and SG,
respectively. See appendix A.1 for a full derivation of filtering-smoothing distributions.
4 Gated Inference Network
The background section defines key elements for the GIN: original observations o1:T, task-dependent
output which can be either the original denoised-imputed observations o1:Tor physical system’s
states s1:T, transferred observations w1:T∈Rm×T, latent states (dynamics) x1:T∈Rn×T, noise
covariance of transferred observations R1:Twith diagonals r1:T∈Rm×T, noise covariance of states
process Q1:Twith diagonals q1:T∈Rn×T, and the parameters of the SSM γ1:T. We consider
the dimensions of the transferred observation and state at each time step to be mandn, respec-
tively. The states evolve through transition distribution pγ1:T(x1:T) =p(x1)QT
t=2pγt(xt|xt−1).
Eachwtis assumed to be drawn from noisy emission probability pγt(wt|xt), then the gen-
erative process is assumed to factorize as pγ1:T(x1:T,w1:T) = pγ1:T(x1:T)QT
t=1pγt(wt|xt).
This factorisation imposes emission conditional independence like wt⊥ ⊥(w−t,x−t)|xt, where
(w−t,x−t) = (w(1:t−1,t+1:T),x(1:t−1,t+1:T)). Common models that assume conditional indepen-
dence include linear dynamical systems, hidden Markov models, but also nonlinear SSMs with
higher-order Markov chains in latent space. Graphical model of the GIN is in figure 2, where output
(one of colored nodes) is generated, contingent upon the task. In all of our scenarios, the parameters
of the SSM, γ1:T, are completely unknown.
From SI perspective, the GIN operates similarly to a Hammerstein-Wiener (HW) model [ 34], employ-
ing non-linear transfer functions e(.)andd(.)(Figure 3). Leveraging encoder-decoder structures for
e(.)andd(.), the GIN conducts the transfer between original sensory observations o1:Tand lower-
dimensional representations w1:Tand task dependent output. The transition block in Figure 3 evolves
states using the proposed deep EKF approach, efficiently approximating filtering-smoothing distribu-
tions while ensuring system stability with the imposed constraint. Further details and formulations
are provided in the inference section. The transition block depicted in Figure 4.
5 Parameterization and Inference
Given original observations o1:Tand transferred observations w1:T, our aim is to infer
the latent states x1:T. To accomplish this, we seek to infer the marginal distributions
4Dynamic NetFilteringxt−1|w1:𝑡−1
෠F𝑡
෡H𝑡
Smoothingxt|w1:𝑡 w𝑡
xt|w1:𝑇 xt−1|w1:𝑇Dynamic NetFilteringxt|w1:𝑡
෠F𝑡+1
෡H𝑡+1
Smoothingxt+1|w1:𝑡+1 w𝑡+1
xt+1|w1:𝑇 xt|w1:𝑇
Dynamic NetFilteringxt−2|w1:𝑡−2
෠F𝑡−1
෡H𝑡−1
Smoothingxt−1|w1:𝑡−1w𝑡−1
xt−1|w1:𝑇 xt−2|w1:𝑇… …Figure 4: Transition block of figure 3 in details. In each time step, the last posterior xt−1|w1:t−1is
fed to the Dynamic Net to compute γt. In the filtering steps, by using the last posterior xt−1|w1:t−1
and the observation wt, the next posterior xt|w1:tis obtained. Having posterior xt|w1:tand the next
smoothing state xt+1|w1:T, applying smoothing for the current state is feasible so that the smoothing
statext|w1:Tis obtained.
pγ1:t(xt|w1:t)for the online inference approach (filtering) and pγ1:T(xt|w1:T)for the full in-
ference approach (smoothing). We introduce an advantageous prediction parameterization as
pγt(xt|xt−1,w1:t−1) =N(Ftxt−1,Qt), where xt−1is sampled from the last filtering distribu-
tion, pγ1:t−1(xt−1|w1:t−1). Then, we obtain the prior distribution at time t,pγ1:t(xt|w1:t−1) =
N(Ftµt−1|t−1,FtΣt−1|t−1FT
t+Qt) =N(µt|t−1,Σt|t−1), by marginalizing out xt−1fromR
pγt(xt|xt−1,w1:t−1)pγ1:t−1(xt−1|w1:t−1)dxt−1integration. The Gaussianity of pγ1:t(xt|w1:t−1)
results from the Gaussianity of prediction parameterization. After obtaining pγ1:t(xt|w1:t−1)and
observing wt, it is feasible to derive the filtering parameterization using equation (2). Once all
transferred observations w1:Tare available, backward induction can be employed to propagate to
previous states using the chain rule. This procedure, known as smoothing, is parameterized with (3).
These parameterizations provide valuable insights into two key aspects: 1) appropriately modeling
γusing neural networks, and 2) illustrating a tractable method to parameterize KG and SG and
construct distributions approximations. These approximations serve the basis for constructing output.
Learning γ.To handle multiple dynamic scenarios, we learn Ksets of state transition and emission
matrices ˇFkandˇHk, each representing a distinct dynamic status. These matrices are combined with
state-dependent coefficients αk(xt−1) as :
ˆFt=KX
k=1αk(xt−1)ˇFk,ˆHt=KX
k=1αk(xt−1)ˇHk. (5)
We model αk(xt−1)with a Kdimension softmax output neural network called the Dynamic Net . It
takes the last filtering state xt−1as input, containing the system’s history with lower noise distortion
than the transferred observations wt−1. This choice enhances noise robustness, demonstrated in our
experiments with time-correlated noise (See Appendix A.6).
In the graphical model shown in Figure 2, we observe two paths for belief propagation from xt−1to
xt. The first path, xt−1→xt, linked with ˆFt. The second path involves an intermediate variable
qt∼ N (0,Qt):xt−1→qt→xt. Since learned ˆFttransfers information from xt−1toxt, we
argue that it can capture effects similar to those of Qt, as both are intended to convey message
between xt−1andxt[1]. By incorporating ˆFtfrom equation (5) into the prior state distribution
described earlier as pγ1:t(xt|w1:t−1) =N(Ftµt−1|t−1,FtΣt−1|t−1FT
t+Qt), we can neglect the
Qtterm in the covariance, as its influence is accounted for by the learned ˆFt. There are two other
meaningful parameterizations for the process noise matrix. First involves direct parameterization
byxt−1using a neural network. Second approach is to parameterize it recursively using xt−1and
qt−1, resulting in a new graphical model with an edge from qt−1→qt(See Appendix A.2). Both
parameterizations are included in our results, presented in the appendix, to show their effectiveness.
Finally, the diagonal elements of the transferred observation noise vector rtare directly mapped
from the original observation space using the encoder function e(.)shown in Figure 3. The mapping
employs an activation function, elu+1, to handle the positivity of the diagonal elements.
Filtering and Smoothing Approximation. We consider GRUKGnetwork to approximate KG as:
ˆKt=ˆΣt|t−1ˆHT
tMtMT
t,Mt=GRUKG 
[Conv (ˆΣt|t−1),rt]
(6)
5ˆµt|t= ˆµt|t−1+ˆKt.[wt−ˆHtˆµt|t−1],ˆΣt|t=ˆΣt|t−1+ˆKt.[ˆHt.ˆΣt|t−1.ˆHT
T+Rt].ˆKT
t (7)
In Equation (6), Conv (.)represents a zero bias convolutional layer with pooling, employed to deal
with sparsity of covariance matrix and extract its relevant information while reducing its size. The [,]
symbol denotes the concatenation operator. Furthermore, the presence of a positive rtvector and the
consideration of the Cholesky factor, MtMT
tin (6), ensure the resulting covariance matrices maintain
positive definiteness. This parameterization construct a new filtering distribution qγ1:t(xt|w1:t) =
N(ˆµt|t,ˆΣt|t)that is an approximation of (2). Consequently, we consider the approximated prior
distribution as qγ1:t(xt|w1:t−1) =N(ˆFtˆµt−1|t−1,ˆFtˆΣt−1|t−1ˆFT
t) =N(ˆµt|t−1,ˆΣt|t−1), where
(ˆµt|t−1,ˆΣt|t−1)are used in (7).
After obtaining filtering states from qγ1:t(xt|w1:t), we use GRUSGnetwork to approximate SG in a
similar way we used GRUKGin (6) as:
ˆJt=ˆΣt|tˆFT
t+1NtNT
t,Nt=GRUSG 
Conv (ˆΣt+1|t)
(8)
ˆµt|T= ˆµt|t+ˆJt
ˆµt+1|T−ˆFt+1ˆµt|t
,ˆΣt|T=ˆΣt|t+ˆJt ˆΣt+1|T−ˆFt+1ˆΣt|tˆFT
t+1ˆJT
t(9)
where the first smoothing state is set to the last filtering state. The new smoothing distribution
qγ1:T(xt|w1:T) =N(ˆµt|T,ˆΣt|T)is an approximation of the exact smoothing distribution in (3). For
a GRU cell with an input size of iand a hidden state size of h, the computational complexity in
the forward pass is O(3h(h+i+ 3)) , which scales linearly with the input size [ 35]. Considering
Conv (Σ)∈Rβ2n2as the input of our GRU cells in (6) and (8) with β∈[0,1]as the pooling ratio,
the forward pass of GIN for one time step has a time complexity of O(3hβ2n2), where n≫h.
Compared with LGSSM matrix inversion time complexity of O(n3), GIN is faster by a factor of
n
3hβ2, which is crucial in high-dimensional regimes.
6 Fitting
In the state estimation task, the output from d(.)in figure 3 equals s, the physical system’s states.
However, in the imputation task, output of d(.)is same as osince the original observation is recon-
structed (see decoder structure for each task in A.8.1). The conditional distributions p(w1:T|o1:T)
andqγ1:T(x1:T|w1:T)are modeled using an encoder e(.)and smoothing parameterization, respec-
tively. Meanwhile, the conditional distributions p(s1:T|x1:T,w1:T,o1:T)andp(o1:T|x1:T,w1:T)are
represented by the decoder d(.)for the tasks of state estimation and imputation. These distributions
are modeled using multivariate Gaussian and Bernoulli distributions, respectively. Depending on
the characteristics of the observations and states, alternative likelihood distributions can also be em-
ployed. For instance, the beta likelihood for data in the unit interval, mixtures for multiple marginal
distributions, and the negative-binomial likelihood for positive count data (See appendix A.3).
Likelihood for Inferring States. The following theorem defines objective for inferring physical
system’s states. The proof is provided in appendix A.4.1.
Theorem 1. The lower bounded conditional log likelihood of the physical system’s states given
original images is determined as:
L(s1:T|o1:T) =1
NNX
i=1logp(s1:T|x(i)
1:T,w(i)
1:T,o1:T) =1
NNX
i=1TX
t=1logN
stdm(ˆµ(i)
t|T), dc(ˆΣ(i)
t|T)
(10)
where the dm(.)anddc(.)determines those parts of the decoder obtaining the state mean and variance.
Nsequences of (x(i)
1:T,w(i)
1:T)∼qγ1:T(x1:T,w1:T|o1:T)are sampled for Monte Carlo integration
estimation.
Likelihood for Inferring Images. For the imputation task, consider the ground truth as the
sequence of images o1:Twith the dimension of Do. The following theorem defines objective for
inferring images. See appendix A.4.2 for the proof.
6Theorem 2. The lower bound of log likelihood of the original images is:
L(o1:T) =1
NNX
i=1logp(o1:T|x(i)
1:T,w(i)
1:T) =1
NNX
i=1TX
t=1DoX
k=1o(k)
tlog 
dk(ˆµ(i)
t|T)
+ 
1−o(k)
t
log(1−dk(ˆµ(i)
t|T))
(11)
withNsequences of (x(i)
1:T,w(i)
1:T)∼qγ1:T(x1:T,w1:T|o1:T)for Monte Carlo integration estimation.
dk(.)defines the corresponding part of the decoder that maps the k-th pixel of otimage.
We use Wishart distribution as a prior for our covariance matrix of states in (10) and (11), which pushes
the covariance toward a scale of identity matrix. Such prior prevents getting high log-likelihood due
to the high uncertainty. We shrink this scale toward zero as time passes, as we expect the model to
finally perform with very little uncertainty, approaching deterministically.
Mode collapse handling. To address the issue of mode collapse, where the model becomes stuck
in the same state, we propose a loss term on (i, j)pair of transition matrices as follows:
lmc(i, j) =||ˇFi−Diag(mi)||2
F− ||ˇFi−ˇFj||2
F− ||ˇFi−Diag(mj)||2
F (12)
withmiandmjbeing distinct hyper parameter vectors, and ||.||Fis the Frobenius norm. The term
−1
2PK
i=1PK
j=1,j̸=ilmc(i, j)can be added into (10) and (11). This addition ensures that each ˇFi
captures a unique transition, distinct from others. From a statistical perspective, (12) represents
a term proportional to −KL 
pi(ˇF)||pj(ˇF).prij(ˇF)
+KL 
pi(ˇF)||prii(ˇF)
(See appendix A.5).
pi(ˇF)∼ MN n×n(ˇFi,I,I)andpj(ˇF)∼ MN n×n(ˇFj,I,I), are matrix normal distributions with
priors prii(ˇF)∼ MN n×n(Diag(mi),I,I)andprij(ˇF)∼ MN n×n(Diag(mj),I,I), respectively.
Gradient explosion handling. Training (10) and (11) with SGD can be disrupted by a gradient
explosion. Specifically, we limit the optimization in (10) and (11) subject to σ1(Uh)<2, where
σi(.)represents the i-th largest singular value and Uh∈Rh×hdenotes the weight matrix of the
hidden state h∈Rhwithhdimension in the GRU cell (see eq.(5) in [ 35] or (53) in appendix A.4.3).
Theorem 3. When σ1(Uh)<2, a GRU cell is locally stable at a fix point h∗=0.
We use Lyapunov stability and two lemmas for the proof of Theorem 3 in appendix A.4.3. Solving
(10) and (11) with SGD gives an updated ˆUhin each iteration that may not satisfy σ1(ˆUh)<2. We
offer two solutions to satisfy the constraint outlined in theorem 3. The first solution relies on the
spectral theorem, offering higher accuracy but with increased computational cost. Alternatively, the
second solution employs the Gershgorin circle theorem, providing lower accuracy but at a reduced
cost. Due to space limitations, we provide the details of the second solution in appendix A.4.5. For
the first solution, we modify ˆUhin three steps: (i) Decompose ˆUhby singular value decomposition
(SVD) such that ˆUh=WΛV . (ii) Replace the singular values of diagonal Λthat are greater than 2
with the threshold 2−δand obtain Λ=Diag(min(σ1,2−δ), ..., min (σh,2−δ)). (iii) Reconstruct
Uh←WΛV. Employing SVD approach, the cost of this solution is proportional to O(h3). In the
next theorem we show that constructed Uhis the optimum solution. The proof is in appendix A.4.4.
Theorem 4. The modified weight matrix Uhobtained from (iii) step above, is a solution of the
following optimization problem: minUh||ˆUh−Uh||2
F, s.t. σ1(Uh)<2−δ.
7 Evaluation and Experiments
The first two experiments are single pendulum and double pendulum, where the dynamics of the latter
one is more complicated. The third experiment is ball bouncing in irregular polygon to demonstrate
the ability of the GIN when it faces irregular environments with multiple underlying dynamics. The
fourth experiment covers visual odometry task for real world data. The last experiment shows the
effectiveness of theorems 3 and 4 for gradient explosion handling. Intuitive python code and training
algorithm are in appendix A.11. Detailed explanations regarding hyperparameter optimization,
network structure, and empirical solutions aimed at avoiding poor local minima are in appendix A.7.
Single Pendulum and Double Pendulum.
In the pendulum experiment, observations are the image sequences comprising 100 time
steps, each has the size of 24×24distorted with time correlated noise. We per-
form the filtering-smoothing by the GIN. In state estimation task, the log-likelihood and
7Table 1: Double (left) and single pendulum (middle) and polygon (left) state estimation results.
(s1, s2, s3, s4)are estimated position of the joints of double pendulum. For single pendulum and
polygon, (s1, s2)denotes the estimated single joint and ball position. sis sampled from eq. (10).
Model SEPos
s1SEPos
s3SEPos
s2SEPos
s4Log Likelihood
V AE 0.212 0.275 0.192 0.285 1.953 ±0.306
IW-V AE 0.203 0.251 0.201 0.266 2.113 ±0.391
V AE-RNN (LSTM) 0.154 0.147 0.134 0.152 4.053 ±0.565
V AE-RNN (GRU) 0.164 0.156 0.162 0.145 3.976 ±0.231
SV AE (LDS) 0.190 0.211 0.179 0.159 3.495 ±0.425
KV AE 0.193 0.188 0.178 0.149 3.679 ±0.101
EKV AE 0.171 0.159 0.151 0.162 3.801 ±0.116
MV AE 0.168 0.161 0.139 0.149 3.927 ±0.226
DeepAR 0.175 0.189 0.157 0.147 3.646 ±0.294
RKN 0.134 0.129 0.139 0.118 4.176 ±0.294
CRU 0.117 0.127 0.116 0.104 4.269 ±0.237
Encode-Decoder 0.291 0.284 0.342 0.317 1.877 ±0.427
AE-RNN (LSTM) 0.163 0.171 0.148 0.167 3.901 ±0.706
AE-RNN (GRU) 0.189 0.183 0.179 0.177 3.886 ±0.369
LGSSM filter 0.125 0.119 0.121 0.107 4.192 ±0.127
LGSSM smooth 0.109 0.111 0.104 0.101 4.231 ±0.154
GIN filter(n=2m) 0.105 0.099 0.109 0.099 4.524 ±0.105
GIN filter(n=3m) 0.083 0.081 0.088 0.079 4.829 ±0.151
GIN smooth (n=2m) 0.081 0.094 0.081 0.082 4.708 ±0.123
GIN smooth (n=3m) 0.069 0.073 0.075 0.067 4.977 ±0.168SEPos
s1SEPos
s2Log Likelihood
0.211 0.247 2.191 ±0.451
0.231 0.197 2.328 ±0.394
0.111 0.099 5.691 ±0.151
0.109 0.101 5.749 ±0.168
0.109 0.096 5.736 ±0.168
0.104 0.095 5.786 ±0.098
0.088 0.093 5.858 ±0.113
0.087 0.087 5.938 ±0.137
0.107 0.094 5.746 ±0.294
0.078 0.075 6.161 ±0.23
0.074 0.069 6.348 ±0.19
0.248 0.191 2.271 ±0.215
0.089 0.087 5.751 ±0.215
0.091 0.085 5.798 ±0.205
0.077 0.073 6.211 ±0.265
0.071 0.069 6.242 ±0.109
0.063 0.06 7.192 ±0.239
0.057 0.056 7.315 ±0.220
0.055 0.057 7.292 ±0.173
0.049 0.047 7.445 ±0.165SEPos
s1SEPos
s2Log Likelihood
0.769 0.782 2.094 ±0.392
0.777 0.764 2.117 ±0.475
0.447 0.411 3.157 ±0.122
0.439 0.415 3.188 ±0.091
0.424 0.438 3.229 ±0.112
0.434 0.439 3.194 ±0.073
0.340 0.429 3.276 ±0.064
0.310 0.401 3.305 ±0.069
0.447 0.434 3.071 ±0.106
0.314 0.437 3.324 ±0.039
0.294 0.378 3.366 ±0.039
0.969 0.914 1.984 ±0.384
0.349 0.319 3.331 ±0.124
0.351 0.429 3.267 ±0.089
0.448 0.312 3.171 ±0.365
0.327 0.317 3.544 ±0.029
0.203 0.208 4.125 ±0.146
0.198 0.199 4.254 ±0.187
0.186 0.198 4.227 ±0.048
0.154 0.147 4.342 ±0.051
Figure 5: Pendulum imputation. Rows from
up to down are the noise distorted ground truth,
observation with uninformed missing frames and
the imputation results of the GIN(smoothed).
Figure 6: D-pendulum imputation.Rows from
up to down are the noise distorted ground truth,
observation with uninformed missing frames and
the imputation results of the GIN(smoothed).
squared error (SE) of the estimated states are given in table 1. With n= 3 m(n
andmrepresenting state and transferred observation dimensions) as shown in Table 1,
Table 2: Image imputation task log likelihood for single pen-
dulum (left), double pendulum (middle) and polygon (right).
The approaches without good results are not included.
Model Single Pendulum Double Pendulum Irregular Polygon
V AE (informed) -36.751 ±7.227 -44.264 ±4.232
IW-V AE (informed) -34.241 ±5.421 -43.728 ±5.421
V AE-RNN (GRU) (informed) -14.243 ±0.328 -15.983 ±0.425 -16.483 ±0.425
SV AE (LDS) (informed smooth) -14.763 ±0.419 -16.978 ±0.551 -16.578 ±0.551
KV AE (informed smooth) -14.217 ±0.236 -15.917 ±0.294 -16.377 ±0.688
KV AE (unformed smooth) -39.260 ±5.399 -38.544 ±6.419
EKV AE (informed smooth) -12.897 ±0.524 -13.917 ±0.414 -15.916 ±0.292
EKV AE (unformed smooth) -29.246 ±3.328 -33.548 ±4.516
MKV AE (informed smooth) -12.723 ±0.428 -13.889 ±0.298 -15.698 ±0.344
MKV AE (unformed smooth) -21.524 ±1.003 -26.773 ±1.537 -31.634 ±2.816
DeepAR (informed) -14.019 ±0.486 -15.881 ±0.511 -19.322 ±0.418
RKN (informed) -12.782 ±0.016 -13.832 ±0.023 -16.267 ±0.313
RKN (unformed) -12.789 ±0.021 -13.891 ±0.031 -16.538 ±0.482
CRU (informed) -12.495 ±0.022 -13.668 ±0.038 -15.884 ±0.297
CRU (unformed) -12.554 ±0.029 -13.739 ±0.061 -15.972 ±0.394
Encoder-Decoder (informed) -64.569 ±9.146 -75.179 ±21.527
AE-RNN (GRU) (informed) -14.173 ±0.066 -16.013 ±0.346 -17.903 ±0.431
LGSSM(informed smooth) -12.395 ±0.048 -13.775 ±0.013 -15.831 ±0.215
GIN (informed smooth) -11.215 ±0.027 -12.584 ±0.021 -14.628 ±0.226
GIN (unformed smooth) -11.246 ±0.029 -12.651 ±0.019 -14.923 ±0.384intuitively states contain information
about position, velocity, and accelera-
tion, increasing the likelihood com-
pared to n= 2m, where only po-
sition and velocity are allocated to
states. For the imputation task, we
randomly remove half of the images
from the generated sequences and per-
form image imputation by predicting
the missing parts. The numerical re-
sults are in table 2 and imputed im-
ages are in figures 5 and 6. In table
2, the models with informed boolean
masks are aware of available and miss-
ing images, while uninformed masks
use a black image as input for missing
images. This encourages the model
to accurately infer the dynamics for
image generation.
For ablation study, first we compare
GIN with simple encoder-decoder
without latent parameterization, and
8then with LGSSM, where the GRU cells are omitted from the GIN structure and classic filtering-
smoothing equations are used instead. We also check the usefulness of filtering-smoothing parameter-
ization by replacing the GIN’s transition block with GRU and LSTM cells and directly parameterize
output distribution (like AE-RNN [ 36] and [ 37]). We compare various VI models, including V AE,
IWV AE, V AE-RNN [ 38] which utilizes V AEs with recurrent cells, and EM-based VI approaches
such as SV AE, KV AE, EKV AE and MV AE. Our comparison also encompasses DeepAR [ 39], an
AR model. Our thorough comparison, covering the CRU, RKN, a group of V AEs, and AR models,
enhances the depth of our analysis. The GIN consistently outperforms all other models. Additionally,
we provide results using the MSE metric to highlight the competitive prediction accuracy of our
approach (See appendix A.10).
Bouncing Ball In Irregular Polygon. To demonstrate the adaptability of the GIN, we
subjected it to a more complex environment. We generated 1000 sequences, each comprising
70 time steps, depicting a ball moving within an irregular polygon featuring random shapes.
s1s2
s1s2
s1s2
s1s2
1520253035s1p(gt135)=(s125)
35|70=24.91
35|70=22.83
35|70=29.15
05101520
p(gt145)=(s112)
45|70=11.86
45|70=8.14
45|70=8.09
GIN LGSSM KVAE05101520s2
p(gt235)=(s210)
35|70=10.07
35|70=12.51
35|70=8.64
GIN LGSSM KVAE05101520
p(gt245)=(s211)
45|70=10.73
45|70=14.11
45|70=15.25
Figure 7: State (position) estimation in irregular poly-
gon (6 edges) at 35-th and 45-th time steps. The upper
row shows the ground truth ball position in 35,39,42
and45-th time steps, respectively.The initial position and velocity of the ball
were randomized. No external forces acted
upon the ball, and collisions with the walls
were elastic. In addition to the aforemen-
tioned models, we include latent SLDS
structure from the SV AE approach for the
comparison. SLDS is particularly relevant
in scenarios such as this one, where sep-
arate dynamics for each state are consid-
ered, as seen when the ball bounces off the
wall. We exclude simple baselines, such as
encoder-decoder, V AE, and IW-V AE, from
the comparison due to their lack of compet-
itive performance. The numerical results
are in tables 1 and 2. In Figure 7, we il-
lustrate samples obtained from the trained
smoothing distributions of GIN, LGSSM,
and KV AE, showcasing their proximity to
the ground truth. For this demonstration,
we specifically select the 35th time step for
sampling, denoted as L(s35|o1:70). Here,
s1ands2represent the estimated xy posi-
tion of the ball within the polygon. Gener-
ating 20 frames with GIN in four different
irregular environments is shown in figure
1. We have created animated files that demonstrate both sequence generation and imputation tasks
within irregular polygons. Please visit: https://sites.google.com/view/ginneurips2024.
Visual Odometry of KITTI Dataset. We also evaluate the GIN with the higher dimensional
observations for the visual odometry task on the KITTI dataset [ 40]. This dataset consists of 11
separated image sequences with their corresponding labels. We use a feature extractor network
proposed by Zhou et al. in [ 41] to obtain the transferred observations of the GIN, i.e. ( w,r).
Additionally, we compare the results with AE-RNN(LSTM), AE-RNN(GRU), DeepVO [ 42] and
KV AE. The numerical results are in table 3, where the common evaluation scheme for the KITTI
dataset is exploited. The results of the KV AE degrades substantially as we have to reduce the size of
the transferred observation to prevent the complexity of matrix inversion. Sampling visualization
from smoothing state distribution are in appendix A.9.
Table 3: Comparison of model performance on KITTI dataset.
SeqAE-RNN(LSTM) AE-RNN(GRU) DeepVO KV AE LGSSM GIN
trel(%) rrel(◦)trel(%) rrel(◦)trel(%) rrel(◦)trel(%) rrel(◦)trel(%) rrel(◦)trel(%) rrel(◦)
03 8.99 4.55 9.34 3.81 8.49 6.89 12.14 4.38 7.51 3.98 6.98 3.27
04 11.88 3.44 12.36 2.89 7.19 6.97 13.17 4.73 9.12 2.64 9.14 2.28
05 8.96 3.43 10.02 3.43 2.62 3.61 11.47 5.14 6.11 3.21 4.38 2.51
06 9.66 2.8 10.99 3.22 5.42 5.82 10.93 3.98 6.70 3.51 6.14 2.90
07 9.83 5.48 13.70 6.52 3.91 4.60 12.73 4.68 6.59 3.49 7.21 2.98
10 13.58 3.49 13.37 3.25 8.11 8.83 14.79 10.91 9.32 2.90 8.37 2.59
mean 10.53 3.87 11.63 3.85 5.96 6.12 12.53 5.63 7.55 3.28 7.03 2.75
9Gradient Explosion Experiment. Table 4 lists the log likelihood and its standard deviation for
three experiments: single pendulum, double pendulum, and irregular polygon. These experiments
were trained under different settings for gradient explosion handling: the conventional Gradient
Clipping (GC), our first solution using Singular Value Decomposition (SVD), and our second solution
using the Gershgorin Circle Theorem (GCT). The table empirically demonstrates that our method
outperforms conventional gradient clipping. In this table, θrepresents the threshold for gradient
clipping as introduced in [ 10], and δis the threshold in our method that keeps the spectral radius less
than 2, i.e., σ1(Uh) +δ= 2. As shown in table 4, gradient clipping failed to train for high θ, while
our approach achieves lower perplexity and higher log likelihood, ensuring stability compared to
gradient clipping by constraining the GRU to be stable. We provide a comprehensive discussion on
theδvariable, including how to tune it in different environments and its impact on model performance,
in the appendix A.8.1.
Table 4: Gradient explosion handling: comparison between GC, SVD and GCT.
Single Pendulum Double Pendulum Irregular Polygon
Objective Success Objective Success Objective Success
SVDδ= 0.17.445±0.165 100 % 4.977 ±0.168 100 % 4.342 ±0.051 100 %
δ= 0.47.281±0.149 100 % 4.847 ±0.241 100 % 4.191 ±0.094 100 %
(Ours) δ= 0.77.127±0.197 100 % 4.692 ±0.237 100 % 4.019 ±0.214 100 %
δ= 1 6.935±0.271 100 % 4.471 ±0.341 100 % 3.839 ±0.207 100 %
GCTδ= 0.17.318±0.214 100 % 4.849 ±0.197 100 % 4.217 ±0.114 100 %
δ= 0.47.184±0.170 100 % 4.711 ±0.179 100 % 4.079 ±0.124 100 %
(Ours) δ= 0.76.981±0.283 100 % 4.562 ±0.193 100 % 3.957 ±0.117 100 %
δ= 1 6.787±0.321 100 % 4.291 ±0.281 100 % 3.672 ±0.176 100 %
GCθ= 5 7.221±0.254 100 % 4.765 ±0.349 100 % 4.172 ±0.274 100 %
θ= 10 7.301±0.495 60 % 4.834 ±0.592 50 % 4.222 ±0.570 50 %
θ= 15 7.331±1.141 20 % N/A 0 % N/A 0 %
θ= 20 N/A 0 % N/A 0 % N/A 0 %
8 Conclusion
This paper introduces the GIN for representation learning in high-dimensional SSMs. The data
flow is managed by Bayesian filtering-smoothing, and the use of GRU-based KG and SG networks
addresses computational issues, resulting in an efficient and numerically stable model. The GIN learns
system dynamics end-to-end, making it a high-performance model with strong system identification
capabilities. It also provides insightful uncertainty representations for predictions and outperforms
various counterparts, including generative models with variational inference, autoregressive models,
and other baselines.
9 Acknowledgments
We thank Yasin Abbasi-Yadkori for useful discussions and suggestions that contributed to this work.
Bibliography
[1]C. M. Bishop and N. M. Nasrabadi, Pattern recognition and machine learning . Springer, 2006,
vol. 4, no. 4.
[2]R. M. Neal et al. , “Mcmc using hamiltonian dynamics,” Handbook of markov chain monte
carlo , vol. 2, no. 11, p. 2, 2011.
[3]D. P. Kingma and M. Welling, “Auto-encoding variational bayes,” arXiv preprint
arXiv:1312.6114 , 2013.
[4] D. Koller and N. Friedman, Probabilistic graphical models: principles and techniques . MIT
press, 2009.
[5] R. E. Kalman, “A new approach to linear filtering and prediction problems,” 1960.
10[6]H. E. Rauch, F. Tung, and C. T. Striebel, “Maximum likelihood estimates of linear dynamic
systems,” AIAA journal , vol. 3, no. 8, pp. 1445–1450, 1965.
[7]E. A. Wan and R. Van Der Merwe, “The unscented kalman filter for nonlinear estimation,” in
Proceedings of the IEEE 2000 Adaptive Systems for Signal Processing, Communications, and
Control Symposium (Cat. No. 00EX373) . Ieee, 2000, pp. 153–158.
[8]L. Ljung, “Asymptotic behavior of the extended kalman filter as a parameter estimator for linear
systems,” IEEE Transactions on Automatic Control , vol. 24, no. 1, pp. 36–50, 1979.
[9]S. Linderman, M. Johnson, A. Miller, R. Adams, D. Blei, and L. Paninski, “Bayesian learning
and inference in recurrent switching linear dynamical systems,” in Artificial Intelligence and
Statistics . PMLR, 2017, pp. 914–922.
[10] R. Pascanu, T. Mikolov, and Y . Bengio, “On the difficulty of training recurrent neural networks,”
inInternational conference on machine learning . Pmlr, 2013, pp. 1310–1318.
[11] K. Doya et al. , “Bifurcations in the learning of recurrent neural networks 3,” learning (RTRL) ,
vol. 3, p. 17, 1992.
[12] T. Haarnoja, A. Ajay, S. Levine, and P. Abbeel, “Backprop kf: Learning discriminative de-
terministic state estimators,” in Advances in neural information processing systems , 2016, pp.
4376–4384.
[13] R. Krishnan, U. Shalit, and D. Sontag, “Structured inference networks for nonlinear state space
models,” in Proceedings of the AAAI Conference on Artificial Intelligence , vol. 31, no. 1, 2017.
[14] P. G. Chang, K. P. Murphy, and M. Jones, “On diagonal approximations to the extended kalman
filter for online training of bayesian neural networks,” in Continual Lifelong Learning Workshop
at ACML 2022 , 2022.
[15] M. Jones, T. R. Scott, M. Ren, G. F. Elsayed, K. Hermann, D. Mayo, and M. C. Mozer,
“Learning in temporally structured environments,” in The Eleventh International Conference on
Learning Representations , 2022.
[16] M. Watter, J. T. Springenberg, J. Boedecker, and M. Riedmiller, “Embed to control: A locally
linear latent dynamics model for control from raw images,” arXiv preprint arXiv:1506.07365 ,
2015.
[17] Y . Burda, R. Grosse, and R. Salakhutdinov, “Importance weighted autoencoders,” arXiv preprint
arXiv:1509.00519 , 2015.
[18] M. J. Johnson, D. K. Duvenaud, A. Wiltschko, R. P. Adams, and S. R. Datta, “Composing graph-
ical models with neural networks for structured representations and fast inference,” Advances in
neural information processing systems , vol. 29, 2016.
[19] M. Fraccaro, S. Kamronn, U. Paquet, and O. Winther, “A disentangled recognition and nonlinear
dynamics model for unsupervised learning,” arXiv preprint arXiv:1710.05741 , 2017.
[20] Y . Li and S. Mandt, “Disentangled sequential autoencoder,” arXiv preprint arXiv:1803.02991 ,
2018.
[21] A. Klushyn, R. Kurle, M. Soelch, B. Cseke, and P. van der Smagt, “Latent matters: Learning
deep state-space models,” Advances in Neural Information Processing Systems , vol. 34, 2021.
[22] F. Tonolini, N. Aletras, Y . Jiao, and G. Kazai, “Robust weak supervision with variational
auto-encoders,” in International Conference on Machine Learning . PMLR, 2023, pp. 34 394–
34 408.
[23] H. Zhu, C. Balsells-Rodas, and Y . Li, “Markovian gaussian process variational autoencoders,”
inInternational Conference on Machine Learning . PMLR, 2023, pp. 42 938–42 961.
[24] P. Becker, H. Pandya, G. Gebhardt, C. Zhao, C. J. Taylor, and G. Neumann, “Recurrent kalman
networks: Factorized inference in high-dimensional deep feature spaces,” in International
Conference on Machine Learning . PMLR, 2019, pp. 544–552.
11[25] M. Schirmer, M. Eltayeb, S. Lessmann, and M. Rudolph, “Modeling irregular time series with
continuous recurrent units,” in International Conference on Machine Learning . PMLR, 2022,
pp. 19 388–19 405.
[26] S. Hochreiter and J. Schmidhuber, “Long short-term memory,” Neural computation , vol. 9,
no. 8, pp. 1735–1780, 1997.
[27] K. Cho, B. Van Merriënboer, D. Bahdanau, and Y . Bengio, “On the properties of neural machine
translation: Encoder-decoder approaches,” arXiv preprint arXiv:1409.1259 , 2014.
[28] R. Wilson and L. Finkel, “A neural implementation of the kalman filter,” Advances in neural
information processing systems , vol. 22, pp. 2062–2070, 2009.
[29] I. Buchnik, G. Revach, D. Steger, R. J. Van Sloun, T. Routtenberg, and N. Shlezinger, “Latent-
kalmannet: Learned kalman filtering for tracking from high-dimensional signals,” IEEE Trans-
actions on Signal Processing , 2023.
[30] G. Revach, N. Shlezinger, X. Ni, A. L. Escoriza, R. J. van Sloun, and Y . C. Eldar, “Kalman-
net: Neural network aided kalman filtering for partially known dynamics,” arXiv preprint
arXiv:2107.10043 , 2021.
[31] D. Ruhe and P. Forré, “Self-supervised inference in state-space models,” arXiv preprint
arXiv:2107.13349 , 2021.
[32] T. Liu, K. A. Lee, Q. Wang, and H. Li, “Disentangling voice and content with self-supervision
for speaker recognition,” Advances in Neural Information Processing Systems , vol. 36, pp.
50 221–50 236, 2023.
[33] M. P. Deisenroth and H. Ohlsson, “A general perspective on gaussian filtering and smoothing:
Explaining current and deriving new algorithms,” in Proceedings of the 2011 American Control
Conference . IEEE, 2011, pp. 1807–1812.
[34] P. Gilabert, G. Montoro, and E. Bertran, “On the wiener and hammerstein models for power
amplifier predistortion,” in 2005 Asia-Pacific Microwave Conference Proceedings , vol. 2. IEEE,
2005, pp. 4–pp.
[35] J. Chung, C. Gulcehre, K. Cho, and Y . Bengio, “Empirical evaluation of gated recurrent neural
networks on sequence modeling,” arXiv preprint arXiv:1412.3555 , 2014.
[36] N. Srivastava, E. Mansimov, and R. Salakhudinov, “Unsupervised learning of video represen-
tations using lstms,” in International conference on machine learning . PMLR, 2015, pp.
843–852.
[37] H. Li, S. Yu, and J. Principe, “Causal recurrent variational autoencoder for medical time series
generation,” in Proceedings of the AAAI Conference on Artificial Intelligence , vol. 37, no. 7,
2023, pp. 8562–8570.
[38] J. Chung, K. Kastner, L. Dinh, K. Goel, A. C. Courville, and Y . Bengio, “A recurrent latent
variable model for sequential data,” Advances in neural information processing systems , vol. 28,
2015.
[39] D. Salinas, V . Flunkert, J. Gasthaus, and T. Januschowski, “Deepar: Probabilistic forecasting
with autoregressive recurrent networks,” International Journal of Forecasting , vol. 36, no. 3, pp.
1181–1191, 2020.
[40] A. Geiger, P. Lenz, and R. Urtasun, “Are we ready for autonomous driving? the kitti vision
benchmark suite,” in 2012 IEEE conference on computer vision and pattern recognition . IEEE,
2012, pp. 3354–3361.
[41] T. Zhou, M. Brown, N. Snavely, and D. G. Lowe, “Unsupervised learning of depth and ego-
motion from video,” in Proceedings of the IEEE conference on computer vision and pattern
recognition , 2017, pp. 1851–1858.
12[42] S. Wang, R. Clark, H. Wen, and N. Trigoni, “Deepvo: Towards end-to-end visual odometry
with deep recurrent convolutional neural networks,” in 2017 IEEE international conference on
robotics and automation (ICRA) . IEEE, 2017, pp. 2043–2050.
[43] K. Sohn, H. Lee, and X. Yan, “Learning structured output representation using deep conditional
generative models,” Advances in neural information processing systems , vol. 28, 2015.
[44] D. Angeli, E. D. Sontag, and Y . Wang, “A characterization of integral input-to-state stability,”
IEEE Transactions on Automatic Control , vol. 45, no. 6, pp. 1082–1097, 2000.
[45] R. A. Horn and C. R. Johnson, Matrix analysis . Cambridge university press, 2012.
[46] D. P. Kingma and J. Ba, “Adam: A method for stochastic optimization,” arXiv preprint
arXiv:1412.6980 , 2014.
[47] P. J. Werbos, “Backpropagation through time: what it does and how to do it,” Proceedings of
the IEEE , vol. 78, no. 10, pp. 1550–1560, 1990.
[48] J. L. Ba, J. R. Kiros, and G. E. Hinton, “Layer normalization,” arXiv preprint arXiv:1607.06450 ,
2016.
[49] J. M. Wang, D. J. Fleet, and A. Hertzmann, “Gaussian process dynamical models for human
motion,” IEEE transactions on pattern analysis and machine intelligence , vol. 30, no. 2, pp.
283–298, 2007.
[50] J. Ko and D. Fox, “Learning gp-bayesfilters via gaussian process latent variable models,”
Autonomous Robots , vol. 30, no. 1, pp. 3–23, 2011.
[51] R. Frigola, F. Lindsten, T. B. Schön, and C. E. Rasmussen, “Bayesian inference and learning
in gaussian process state-space models with particle mcmc,” Advances in neural information
processing systems , vol. 26, 2013.
[52] M. Schoukens and K. Tiels, “Identification of block-oriented nonlinear systems starting from
linear approximations: A survey,” Automatica , vol. 85, pp. 272–292, 2017.
[53] R. Li, S. John, and A. Solin, “Improving hyperparameter learning under approximate inference
in gaussian process models,” in International Conference on Machine Learning . PMLR, 2023,
pp. 19 595–19 615.
[54] N. Wahlström, T. B. Schön, and M. P. Deisenroth, “From pixels to torques: Policy learning with
deep dynamical models,” arXiv preprint arXiv:1502.02251 , 2015.
[55] E. Archer, I. M. Park, L. Buesing, J. Cunningham, and L. Paninski, “Black box variational
inference for state space models,” arXiv preprint arXiv:1511.07367 , 2015.
[56] M. Karl, M. Soelch, J. Bayer, and P. Van der Smagt, “Deep variational bayes filters: Unsu-
pervised learning of state space models from raw data,” arXiv preprint arXiv:1605.06432 ,
2016.
[57] C. Naesseth, S. Linderman, R. Ranganath, and D. Blei, “Variational sequential monte carlo,” in
International conference on artificial intelligence and statistics . PMLR, 2018, pp. 968–977.
[58] S. S. Rangapuram, M. W. Seeger, J. Gasthaus, L. Stella, Y . Wang, and T. Januschowski, “Deep
state space models for time series forecasting,” Advances in neural information processing
systems , vol. 31, 2018.
[59] V . Garcia Satorras, Z. Akata, and M. Welling, “Combining generative and discriminative models
for hybrid inference,” Advances in Neural Information Processing Systems , vol. 32, 2019.
13A Appendix
A.1 Filtering and Smoothing Parameterization
The Kalman filter operates through two iterative steps: prediction and update. In the prediction step,
the filter uses prior state information to make an estimate, while in the update step, it adjusts this
estimate based on new observations. Assuming normally distributed additive process and observation
noise, the filter can effectively perform these steps. During the prediction step, the filter employs
the transition matrix Ft+1to estimate the next priors pγ1:t+1(xt+1|w1:t) = (µt+1|t,Σt+1|t), which
represent the next state estimates without incorporating any new observations.
µt+1|t=Ft+1µt|t,and Σt+1|t=Ft+1Σt|tFT
t+1+Qt+1,and Qt+1=σ2
t+1I (13)
When a new observation is available, the Kalman filter proceeds to the second step, where it updates
the predicted prior using the new observation and the emission matrix Ht+1. This results in the next
posterior, (µt+1|t+1,Σt+1|t+1).
Kt+1=Σt+1|tHT
t+1 
Ht+1Σt+1|tHT
t+1+Rt+1−1, (14)
µt+1|t+1=µt+1|t+Kt+1(wt−Ht+1µt+1|t),Σt+1|t+1=Σt+1|t−Kt+1 
Ht+1Σt+1|tHT
t+1+Rt+1
Kt+1.
(15)
The entire observation update procedure can be viewed as a weighted mean between the next prior,
derived from the state update, and the new observation. This weighting is influenced by Qand
R, reflecting their inherent uncertainties. We derive the smoothing parameterization by leveraging
the Markov property, which states that xtis independent of future observations wt+1:Tgiven
xt+1. Although xt+1is unknown, there is a distribution over it. By conditioning on xt+1and then
marginalizing out, we can obtain xtconditioned on w1:T.
pγ1:T(xt|w1:T) =Z
pγ1:T(xt|xt+1,w1:T)pγ1:T(xt+1|w1:T)dxt+1
=Z
pγ1:t(xt|xt+1,w1:t,wt+1:T)pγ1:T(xt+1|w1:T)dxt+1(16)
By using induction and and smoothed distribution for t+ 1:
pγ1:T(xt+1|w1:T) =N(µt+1|T,Σt+1|T) (17)
we calculate the filtered two-slice distribution as follows:
.pγ1:t(xt,xt+1|w1:t) =N
µt|t
µt+1|t
,
Σt|tΣt|tFT
t+1
Ft+1Σt|tΣt+1|t
(18)
by using Gaussian conditioning we have:
pγ1:t(xt|xt+1,w1:t) =N(µt|t+Jt 
xt+1−Ft+1µt|t
,Σt|t−JtΣt+1|tJT
t) (19)
where Jt=Σt|tFt+1[Σt+1|t]−1. We calculate the smoothed distribution for tusing the rules of
iterated expectation and covariance:
µt|T=E
E[xt|xt+1,w1:T]|w1:T
=E
E[xt|xt+1,w1:t]|w1:T
=E
µt|t+Jt(xt+1−Ft+1µt|t)|w1:T
=µt|t+Jt(µt+1|T−Ft+1µt|t)(20)
14Σt|T=cov
E[xt|xt+1,w1:T]|w1:T
+E
cov[xt|xt+1,w1:T]|w1:T
=cov
E[xt|xt+1,w1:t]|w1:T
+E
cov[xt|xt+1,w1:t]|w1:T
=cov
µt|t+Jt(xt+1−Ft+1µt|t)|w1:T
+E
Σt|t−JtΣt+1|tJT
t|w1:T
=Jtcov
xt+1−Ft+1µt|t|w1:T
JT
t+Σt|t−JtΣt+1|tJT
t
=JtΣt+1|TJT
t+Σt|t−JtΣt+1|tJT
t
=Σt|t+Jt 
Σt+1|T−Σt+1|t
JT
t.(21)
A.2 Process Noise Matrix
As stated in (13), we can elaborate the process noise matrix at time tin more details
Qt=Σt|t−1−FtΣt−1|t−1FT
t=Σt|t−1−Ft
Σt−1|t−2−Kt−1[Ht−1Σt−1|t−2HT
t−1+Rt−1]−1KT
t−1
FT
t
(22)
combining (13) into (22) results in
Qt=Σt|t−1−Ft
[Ft−1Σt−2|t−2FT
t−1+Qt−1]
−Kt−1[Ht−1[Ft−1Σt−2|t−2FT
t−1+Qt−1]HT
t−1+Rt−1]−1KT
t−1
FT
t(23)
which is a function of Ft,Qt−1,Ft−1andHt−1. In the GIN, ˆFtandˆHtare learned by the Dynamic
Network with the input of xt−1. From (15), µt−1|t−1is derived as a function of both Ft−1and
Ht−1, meaning the learned ˆFtcarries the information of both Ht−1andFt−1. Therefore, one can
rewrite the equation (23) as
Qt=g
ˆFt 
µt−1|t−1
,Qt−1
,where ˆFt=Dynamic Net
µt−1|t−1 
Ht−1,Ft−1
(24)
where gis a nonlinear function mapping µt−1|t−1andQt−1toQtand the graphical model for such
choice of structure is in appendix figure 8b. It is possible to go one step further and simplify µt−1|t−1
more, as it has Σt−1|t−1term in (15), combining it with (13) results in:
µt−1|t−1=µt−1|t−2+ [Ft−1Σt−2|t−2FT
t−1+Qt−1]
HT
t−1 
Ht−1[Ft−1Σt−2|t−2FT
t−1+Qt−1]HT
t−1+Rt−1−1(wt−Ht−1µt−1|t−2)
(25)
indicating that not only Ft−1andHt−1, but also Qt−1is included in µt−1|t−1, meaning that Qtcan
be written solely as a function of µt−1|t−1and the graphical model for such choice is in figure 8a.
Qt=g
ˆFt 
µt−1|t−1
,where ˆFt=Dynamic Net
µt−1|t−1 
Ht−1,Ft−1,Qt−1
.(26)
We refer to gas the Q Network , which can be modeled either by an MLP, as shown in (26), or by a
recurrent network, as detailed in (24).
A.3 Output Distribution
In the case of grayscale images, each pixel yis either one or zero with the probability por1−p,
respectively, meaning that P(Y=y) =py(1−p)1−y. This probability equation can be rewritten in
the form of an exponential family as follows:
15𝑞𝑡−1
x𝑡−1
w𝑡−1𝑞𝑡
x𝑡
w𝑡𝑞𝑡+1
x𝑡+1
w𝑡+1…
…
……
…
…
o𝑡−1s𝑡−1 o𝑡 s𝑡o𝑡+1s𝑡+1(a) Without recurrent dependency on qtmodeled with
(26).
𝑞𝑡−1
x𝑡−1
w𝑡−1𝑞𝑡
x𝑡
w𝑡𝑞𝑡+1
x𝑡+1
w𝑡+1…
…
……
…
…
o𝑡−1s𝑡−1 o𝑡 s𝑡o𝑡+1s𝑡+1(b) With recurrent dependency on qtmodeled with
(24).
Figure 8: Graphical models for different parameterizations of the process noise.
fθ(y) =h(y).exp 
θ.y−ψ(θ)
→elog(py(1−p)1−y)=ey log (p
1−p)+log(1−p). (27)
By choosing θ=log(p
1−p)andψ(θ) =log(1−p)andh(y) = 1 , we can obtain p=1
1+e−θ. This
means that by considering θas the last layer of the decoder and applying a sigmoid layer, pis obtained
and one can optimize psuch that the likelihood is maximized as we did in in (11).
Similarly, consider xas the ground truth state, ˆxθas the estimated state, and θas the model variables.
The residual follows a Gaussian distribution: x= ˆxθ+ϵ∼ N(ˆxθ,ˆσθ), where ˆσθis the estimated
variance. Then, the negative log likelihood is given by (28) as we obtained it in(10).
−log(L)∝1
2log(ˆσθ) +(x−ˆxθ)2
2ˆσθ(28)
A.4 Proof of theorems
We restate the theorems for the ease of readability and then provide the proofs.
A.4.1 Proof of theorem 1
Theorem. The log likelihood of the states given the original observations is determined as:
L(s1:T|o1:T) =1
NNX
i=1logp(s1:T|x(i)
1:T,w(i)
1:T,o1:T) =1
NNX
i=1TX
t=1logN
stdm(ˆµ(i)
t|T), dc(ˆΣ(i)
t|T)
where the dm(.)anddc(.)determines those parts of the decoder that obtain the state mean and
variance, respectively. Nsequences of (x(i)
1:T,w(i)
1:T)∼qγ1:T(x1:T,w1:T|o1:T)are sampled for
Monte Carlo integration estimation.
16Proof.
logpγ1:T(s1:T|o1:T)
=Z
qϕ(x1:T,w1:T|o1:T,s1:T) logpγ1:T(s1:T,w1:T,x1:T|o1:T)
pγ1:T(x1:T,w1:T|s1:T,o1:T)dx1:Tdw1:T (29)
=Z
qϕ(x1:T,w1:T|o1:T,s1:T) logqϕ(x1:T,w1:T|o1:T,s1:T)
−qϕ(x1:T,w1:T|o1:T,s1:T) logqϕ(x1:T,w1:T|o1:T,s1:T)
+qϕ(x1:T,w1:T|o1:T,s1:T) logpγ1:T(s1:T,w1:T,x1:T|o1:T)
pγ1:T(x1:T,w1:T|s1:T,o1:T)dx1:Tdw1:T (30)
= KL 
qϕ(x1:T,w1:T|o1:T,s1:T)||pγ1:T(x1:T,w1:T|s1:T,o1:T)
+Z
qϕ(x1:T,w1:T|o1:T,s1:T) logpγ1:T(s1:T,w1:T,x1:T|o1:T)
qϕ(x1:T,w1:T|o1:T,s1:T)dx1:Tw1:T (31)
≥Eqϕ(x1:T,w1:T|o1:T,s1:T)
logpγ1:T(s1:T,w1:T,x1:T|o1:T)
qϕ(x1:T,w1:T|o1:T,s1:T)
(32)
=Eqϕ(x1:T,w1:T|o1:T,s1:T)
logpγ1:T(s1:T|w1:T,x1:T,o1:T).pγ1:T(w1:T,x1:T|o1:T)
qϕ(x1:T,w1:T|o1:T,s1:T)
(33)
≈Eqϕ(x1:T,w1:T|o1:T,s1:T)
logpγ1:T(s1:T|w1:T,x1:T,o1:T)
(34)
≈Eqγ1:T(x1:T,w1:T|o1:T)
logpγ1:T(s1:T|w1:T,x1:T,o1:T)
(35)
=Eqγ1:T(x1:T|w1:T).p(w1:T|o1:T)
logpγ1:T(s1:T|w1:T,x1:T,o1:T)
(36)
≈1
NNX
i=1logp(s1:T|x(i)
1:T,w(i)
1:T,o1:T),x(i)
1:T∼qγ1:T(x1:T|w(i)
1:T),w(i)
1:T∼p(w1:T|o1:T)(37)
=1
NNX
i=1TX
t=1logN
stdm(ˆµ(i)
t|T), dc(ˆΣ(i)
t|T)
(38)
=L(s1:T|o1:T). (39)
The inequality in (32) arises from the positivity of the Kullback-Leibler (KL) term. The approx-
imation in (34) results from assuming equality between the prior and the approximated posterior,
i.e.,pγ1:T(w1:T,x1:T|o1:T) =qϕ(x1:T,w1:T|o1:T,s1:T). This assumption is not very restrictive
as explained further in [ 43]. The approximation in (35) is coming from the equality assumption
ofqϕ(x1:T,w1:T|o1:T,s1:T)andqγ1:T(x1:T,w1:T|o1:T). This assumption implies that given the
original observation o1:T, our latent representation (x1:T,w1:T)is independent of the ground truth
states s1:T. In simpler terms, s1:Tis concealed within o1:T, allowing us to disregard s1:T. The
approximation in (37) is because of Monte Carlo integration estimation.
A.4.2 Proof of theorem 2
Theorem. The (lower bound of) log likelihood of the original images is:
L(o1:T) =1
NNX
i=1logp(o1:T|x(i)
1:T,w(i)
1:T) =1
NNX
i=1TX
t=1DoX
k=1o(k)
tlog 
dk(ˆµ(i)
t|T)
+ 
1−o(k)
t
log(1−dk(ˆµ(i)
t|T))
(40)
withNsequences of (x(i)
1:T,w(i)
1:T)∼qγ1:T(x1:T,w1:T|o1:T)for Monte Carlo integration estimation. dk(.)
defines the corresponding part of the decoder that maps the k-th pixel of otimage.
17Proof.
logpγ1:T(o1:T)
=Z
qγ1:T(x1:T,w1:T|o1:T) logpγ1:T(w1:T,x1:T,o1:T)
pγ1:T(x1:T,w1:T|o1:T)dx1:Tdw1:T (41)
=Z
qγ1:T(x1:T,w1:T|o1:T) logqγ1:T(x1:T,w1:T|o1:T)
−qγ1:T(x1:T,w1:T|o1:T) logqγ1:T(x1:T,w1:T|o1:T)
+qγ1:T(x1:T,w1:T|o1:T) logpγ1:T(w1:T,x1:T,o1:T)
pγ1:T(x1:T,w1:T|o1:T)dx1:Tdw1:T (42)
= KL 
qγ1:T(x1:T,w1:T|o1:T)||pγ1:T(x1:T,w1:T|o1:T)
+Z
qγ1:T(x1:T,w1:T|o1:T) logpγ1:T(w1:T,x1:T,o1:T)
qγ1:T(x1:T,w1:T|o1:Tdx1:Tw1:T (43)
≥Eqγ1:T(x1:T,w1:T|o1:T)
logpγ1:T(w1:T,x1:T,o1:T)
qγ1:T(x1:T,w1:T|o1:T)
(44)
=Eqγ1:T(x1:T,w1:T|o1:T)
logpγ1:T(o1:T|w1:T,x1:T).pγ1:T(w1:T,x1:T)
qγ1:T(x1:T,w1:T|o1:T)
(45)
≈Eqγ1:T(x1:T,w1:T|o1:T)
logpγ1:T(o1:T|w1:T,x1:T)
(46)
=Eqγ1:T(x1:T|w1:T).p(w1:T|o1:T)
logpγ1:T(o1:T|w1:T,x1:T)
(47)
≈1
NNX
i=1logp(o1:T|x(i)
1:T,w(i)
1:T),x(i)
1:T∼qγ1:T(x1:T|w(i)
1:T),w(i)
1:T∼p(w1:T|o1:T) (48)
=1
NNX
i=1TX
t=1DoX
k=1o(k)
tlog 
dk(ˆµ(i)
t|T)
+ 
1−o(k)
t
log(1−dk(ˆµ(i)
t|T)) (49)
=L(o1:T). (50)
The inequality in (44) arises from the positivity of the Kullback-Leibler (KL) term. The approxima-
tion in (46) results from assuming equality between the prior and the approximated posterior, i.e.,
pγ1:T(w1:T,x1:T) =qϕ(x1:T,w1:T|o1:T). Although it is feasible to optimize (44) directly, we found
out that by setting prior pγ1:T(x1:T,w1:T)equal to approximated posterior qγ1:T(x1:T,w1:T|o1:T),
more stable results with concise improvement are achieved from the numerical results (similar to
[19, 21, 43]). The approximation in (48) is because of Monte Carlo integration estimation.
A.4.3 Proof of theorem 3
First we provide a brief review on the GRU cell equations from [ 35]. Then we introduce two lemmas,
by which we can proof theorem 2.
GRU Cell Review. The GRU cell holds the following equations:
zt=Sigmoid (Uxzxt+Uzht−1), (51)
rt=Sigmoid (Uxrxt+Urht−1), (52)
ht=zt⊙ht−1+ (1−zt)⊙ˆht, (53)
ˆht=tanh(Uxhxt+Uh(rt⊙ht−1)) (54)
where xtandhtare the input and the hidden state vectors, respectively. Uxz,Uz,Uxr,Ur,Uxh
andUhare all weight matrices.
Lemma 1. A GRU cell has a fixed point at h∗=0, if the input variable xt=0.
Proof. After substituting xt=0andht−1=0into (51) and (52), the update gate ztand reset gate
rtare both1
2. Substituting these values along with x=0andht−1=0into (54) gives the candidate
18state ˆht=0. Finally, substituting ht−1=0,zt=1
2, and ˆht=0into (53) results in the new state
ht=0. Thus, ht=ht−1=0, indicating that GRU has a fixed point h∗=0.
Lemma 2. LetIbe an h×hidentity matrix, λi(.)shows the i-th largest absolute eigenvalue,
andA=1
4Uh+1
2I. When the spectral radius |λ1(A)|<1, a GRU cell with input xt=0. can be
approximated by the following linearized GRU near ht=0:
ht=Aht−1 (55)
and the fixed point h∗=0is locally stable.
Proof. By employing Taylor series expansion and linearizing htwith respect to ht−1atht−1=
xt=0,Ain (55) is obtain as1
4Uh+1
2I. Then, from (55) we get that ht=Ath0. Since At
is dependent on the t-th powers of the eigenvalues of A, the behavior of the linearized GRU is
determined by the eigenvalues of A. According to the Hartman-Grobman theorem, the behavior of a
dynamical system near a hyperbolic fixed point is homeomorphic to the behavior of the linearized
system. Therefore, when |λ1(A)|<1, the fixed point h∗=0becomes a hyperbolic fixed point.
Thus, a GRU cell can be approximated as ht=Ath0. Then, local stability is determined by the
spectral radius |λ1(A)|<1and then we have |ht−h0|t→∞=0and the fixed point h∗=0is
locally stable.
Theorem 3. When σ1(Uh)<2, a GRU cell is locally stable at a fix point h∗=0.
Proof. Relying on Lemma1 andLemma2 , we need to satisfy |λ1(1
4Uh+1
2I)|<1.|λ1(1
4Uh+
1
2I)|=|1
4λ1(Uh) +1
2|due to the properties of eigenvalues. From the triangle inequality we also
have|1
4λ1(Uh) +1
2| ≤1
4|λ1(Uh)|+1
2. Using Weyl’s inequality for its singular and eigenvalues, we
have|λ1(Uh)| ≤σ1(Uh)and therefore1
4|λ1(Uh)|+1
2≤1
4|σ1(Uh)|+1
2. Thus, we need to satisfy
1
4|σ1(Uh)|+1
2<1condition and conclude1
4|λ1(Uh)|+1
2≤1
4|σ1(Uh)|+1
2<1. This can be
achieved by σ1(Uh)<2.
The GRU cell is considered as a nonlinear dynamical system with ˙ht=f(ht,xt)model, where one
can drive ffrom (51)-(54). We have shown the conditions for local stability of ˙h=f(h,0)in the
last paragraph. Now we show ˙h=f(h,x)is locally stable if xt→0ast→ ∞ .
As we have the stability condition for ˙h=f(h,0), there exists V(h)that is a Lyapunov function for
this system such that:
V(h)≥0,and ˙V(h) =dV
dh.f(h,0)≤ −W(h) (56)
for a positive definite W(h). When the input variable xis not zero, the system equation becomes
˙h=f(h,x)and the derivative of V(h)becomes
˙V(h) =dV
dh.f(h,x) (57)
but for a small xt, we can write:
˙V(h)≤ −W(h) +ϵ, (58)
ϵ=|dV
dh.(f(h,x)−f(h,0))| (59)
andϵ→0asxt→0, utilizing Taylor series expansion of f(h,x)nearx=0[44]. Then, as xt→0,
for any ϵ≥0, there exists a Tsuch that for all t≥T,|xt|< ϵand therefore we have:
˙V(h)≤ −W(h) +ϵ, (60)
for sufficiently small ϵ,˙V(h)remains negative.
Therefore, we need to demonstrate that the inputs of the GRU cells in (6) and (8) approach 0as
t→ ∞ . As discussed in the main script, we apply a Wishart prior distribution on the covariance
matrices, guiding them towards a scaled identity matrix. Over time, this scale diminishes towards
zero, causing the covariance matrices—and consequently, the zero bias Conv( .)operators in (6) and
19(8)—to converge to 0ast→ ∞ . This implies that the system tends to behave deterministically
after prolonged observation, while the stability of the GRU cell is guaranteed. Informally, Theorem
3 requires us to asymptotically shrink the input covariance matrices of our GRU cells toward zero.
While this shrinkage is reasonable as we expect the system to behave deterministically in the long run,
it imposes a limitation on posterior inference. We acknowledge this as an open problem for future
research.
A.4.4 Proof of theorem 4
Theorem. The modified weight matrix Uhobtained from (iii) step above, is a solution of the following
optimization problem: minUh||ˆUh−Uh||2
F, s.t. σ1(Uh)<2−δ.
Proof. Relying on [45], due to the matrices properties we have:
hX
i=1
σi(ˆUh)−σi(Uh)2≤ ||ˆUh−Uh||2
F. (61)
Assuming that the first ssingular values of ˆUhare greater than 2, we havePh
i=1
σi(ˆUh)−
σi(Uh)
=Ps
i=1
σi(ˆUh)−(2−δ)
. According to (61), we need to show thatPs
i=1
σi(ˆUh)−
(2−δ)2is equal to its upper bound ||ˆUh−Uh||2
F, i.e. the optimum solution.
Using the singular value decomposition properties, we have ||ˆUh−Uh||2
F=||WΛV −WΛV||2
F=
||W(Λ−Λ)V||2
F=tr(V∗(Λ−Λ)W∗W(Λ−Λ)V) =tr(V∗(Λ−Λ)(Λ−Λ)V) =tr(VV∗(Λ−
Λ)(Λ−Λ)) =tr((Λ−Λ)(Λ−Λ)) =Ps
i=1
σi(ˆUh)−(2−δ)2.
A.4.5 Proof of theorem 5
Theorem. We can satisfy the constraint introduced in Theorem 3 by applying the Gershgorin circle
theorem as follows.
(i) In the i-th row of ˆUh, sum up the non diagonal elements as id=Ph
j=1,j̸=i|ˆUh(i, j)|. Do (i) for
the all rows.
(ii) For each ˆUh(i, i)assign a circle cluster centered at ˆUh(i, i)withidradius in the complex plane.
(iii) Merge the clusters which have intersection and repeat step (iii) until no cluster can be merged
any more. Finally the set of clusters C={C1, ...,Ck}with length of k≤his obtained.
(iv) Define the radius of Cjcluster as dCj=max(ˆUh(i, i)+id|∀ˆUh(i, i)∈ Cj). Calculate the radius
of all kclusters in step (iv).
(v) For each cluster Cj, if(ˆUh(i, i) +dCj|∀ˆUh(i, i)∈ Cj)>2, shift ˆUh(i, i)←(2−dCj−δ)for
a small δ. Otherwise, keep ˆUh(i, i)unchanged. Do step (v) for all clusters and their elements, i.e.
ˆUh(i, i).
These five steps, ensures the new ˆUhfollows the constraint introduced in Theorem 3 .
Proof. The five steps elaborated above are direct results of the generalized Gershgorin circle theorem.
This approach is faster than SVD method introduced in the paper, while it is not the best solution of
the optimization problem introduced in the Theorem 4 .
A.5 Discussion About KL Term of Mode Collapse
The term introduced in the mode collapse handling section is:
−KL 
pi(ˇF)||pj(ˇF).prij(ˇF)
+KL 
pi(ˇF)||prii(ˇF)
. (62)
Here pi(ˇF)∼ MN n×n(ˇFi,I,I)andpj(ˇF)∼ MN n×n(ˇFj,I,I), are matrix normal distribu-
tions with priors prii(ˇF)∼ MN n×n(Diag(mi),I,I)andprij(ˇF)∼ MN n×n(Diag(mj),I,I),
respectively. We can expand (62) as:
20=Z
pi(ˇF)
logpj(ˇF).prij(ˇF)
pi(ˇF)+ logpi(ˇF)
prii(ˇF)
dˇF (63)
=Z
pi(ˇF)
logpj(ˇF).prij(ˇF)
prii(ˇF)
dˇF (64)
=Z
pi(ˇF)
logpj(ˇF)
dˇF+Z
pi(ˇF)
logprij(ˇF)
dˇF−Z
pi(ˇF)
logprii(ˇF)
dˇF
(65)
Relying on [45], we can simplify each term in (65) as:
Z
pi(ˇF)
logpj(ˇF)
dˇF=−1
2h 
vec(ˇFi)−vec(ˇFj)T 
vec(ˇFi)−vec(ˇFj)
+tr(I)i
+const
(66)
=−1
2||ˇFi−ˇFj||2
F−1
2tr(I) +const (67)
Z
pi(ˇF)
logprij(ˇF)
dˇF=−1
2h 
vec(ˇFi)−vec(Diag(mj))T 
vec(ˇFi)−vec(Diag(mj))
+tr(I)i
+const
(68)
=−1
2||ˇFi−Diag(mj)||2
F−1
2tr(I) +const (69)
Z
pi(ˇF)
logprij(ˇF)
dˇF=−1
2h 
vec(ˇFi)−vec(Diag(mi))T 
vec(ˇFi)−vec(Diag(mi))
+tr(I)i
+const
(70)
=−1
2||ˇFi−Diag(mi)||2
F−1
2tr(I). (71)
Thus, we can rewrite (62) as:
1
2||ˇFi−Diag(mi)||2
F−1
2||ˇFi−Diag(mj)||2
F−1
2||ˇFi−ˇFj||2
F−1
2tr(I) +const (72)
which is half of (12) plus a constant.
A.6 Noise Generation Process
In our experiments, we use a time-correlated noise generation scheme to demonstrate the system’s
noise robustness. This method introduces a sequence of factors, ft, of the same length as the
data sequence, making the noise factors correlated over time. Let f0∼ U(0,1)andft+1=
min(max(0, ft+rt),1)withrt∼ U(−0.2,0.2), where f0is the initialized factor and Uis the
uniform distribution. Two thresholds, t1∼ U(0,0.25)andt2∼ U(0.75,1), are defined. Values of ft
less than t1are set to 0, values greater than t2are set to 1, and the remaining values are linearly scaled
within the range [0,1]. The original observation at time t,ot, is then given by ot=ftit+(1−ft)ipn
t,
where itis the true image at time tandipn
tis the pure noise generated for time t.
A.7 Hyperparameters and training
In all experiments, we used the Adam optimizer [ 46] on an NVIDIA GeForce GTX 1050 Ti with
16GB RAM. To ensure optimal hyperparameters, we conducted a grid search. We searched for the
initial learning rate in the range of 0.001to0.2with increments of 0.005, selecting the one that
yielded the highest log-likelihood. We chose an initial learning rate of 0.006with an exponential
decay rate of 0.9every 10 epochs. Backpropagation through time [ 47] was employed to compute
gradients, given the use of GRU cells in our structure. The gradients are applied to GRU cells with
the constraint explained in theorem 3, where we use the spectral theorem mentioned in the main script
. We applied the layer normalization technique [ 48] to stabilize the dynamics within the recurrent
structure and normalize the filter response. The Elu + 1 activation function was used to ensure the
positivity of the diagonal elements of the process noise and covariance matrices.
21Dynamics 
Network
𝐱0:𝑇−1|0:𝑇−1 Prediction(෠𝐅1:𝑇,෡𝐇1:𝑇)
(ෝ𝝁1:𝑇|0:𝑇−1 ,෡𝚺1:𝑇|0:𝑇−1 )𝐺𝑅𝑈𝐾𝐺Filtering Step𝒓1:𝑇 𝐌1:𝑇
𝒘1:𝑇
(ෝ𝝁1:𝑇|1:𝑇 ,෡𝚺1:𝑇|1:𝑇 )Smoothing Step
𝐺𝑅𝑈𝑆𝐺
(ෝ𝝁0:𝑇−1|0:𝑇−1 ,෡𝚺0:𝑇−1|0:𝑇−1 )𝐍1:𝑇
෡𝐇1:𝑇෠𝐅1:𝑇(ෝ𝝁1:𝑇|𝑇 ,෡𝚺1:𝑇|𝑇 )
Encoder𝒐1:𝑇 PredictionFiltering
(𝒓1:𝑇,𝒘1:𝑇)(ෝ𝝁1:𝑇|1:𝑇 ,෡𝚺1:𝑇|1:𝑇 )
Decoder{𝒐1:𝑇 ,𝒔1:𝑇 }
Smoothing(ෝ𝝁1:𝑇|𝑇 ,෡𝚺1:𝑇|𝑇 )GIN Cell
Conv
2D෡𝚺1:𝑇|0:𝑇−1 Conv
2D
(ෝ𝝁1:𝑇|0:𝑇−1 ,෡𝚺1:𝑇|0:𝑇−1 )෡𝚺1:𝑇|0:𝑇−1 
(ෝ𝝁1:𝑇|1:𝑇 ,෡𝚺1:𝑇|1:𝑇 )
(ෝ𝝁1:𝑇|0:𝑇−1 ,෡𝚺1:𝑇|0:𝑇−1 )Figure 9: Proposed detailed architecture.
To prevent the model from getting stuck in poor local minima, such as focusing excessively on
reconstruction rather than learning the dynamics obtained through filtering-smoothing, we find it
beneficial to employ two training techniques for end-to-end learning:
1-Generating time correlated noisy sequences as consecutive observations, forces the model to
learn the dynamics instead of focusing on reconstruction, e.g. figures 11 and 13 in appendix.
2-During the initial epochs, the system focuses on learning the auto-encoder and globally
learned parameters, such as ˇFkandˇHk, while excluding the Dynamic Net parameters
αt(xt−1). Afterwards, all parameters are jointly learned. This approach enables the system
to initially acquire good embeddings and meaningful latent vectors before integrating the
learning of Kdifferent dynamics variables.
In our experiments, we set K= 15 to accommodate the complexity of the latent space, with each
latent representing a unique dynamical scenario. Generally, parameter tuning is not challenging when
the GIN is sufficiently flexible, as it can learn to prune unused elements through the Dynamic Net .
A.8 Proposed architecture, qualitative comparison with the SOTA and empirical complexity
analysis
A.8.1 Architectures
The proposed detailed structure is shown in figure 9. To design the dynamic network, we use an MLP
with 60 hidden units and a ReLU activation function, and a softmax activation in the last layer. The
state mean, with a size of n, is the input to the dynamic network, which outputs kcoefficients. The
structures of the encoder and decoder are shown in Table 5. In this table, mrepresents the transferred
observation dimension, with various values considered in the results. For state estimation tasks, the
output size ( out) is 4, 4, 8 and 12 for the single-pendulum, bouncing ball, double-pendulum and
KITTI visual odometry experiments, respectively. For the imputation task, the number of hidden
units in the KG and SG networks is set to 40 and 30, respectively. The convolutional layer applied
over the covariance matrix has 8 filters with a kernel size of 5 and zero bias.
22Table 5: The structure of the encoder and decoder.
Encoder Decoder
ifstate estimation task :
6×6Conv, 12, max pooling 2×2, stride 2×2 sµ: fully connected: out, linear activation
LayerNormalizer() sΣ: fully connected, Elu + 1 zero bised
4×4Conv, 12, max pooling 2×2, stride 2×2 ifimputation task :
LayerNormalizer() fully connected: 144
fully connected: 40 6×6Trns Conv, 16, stride 4×4
w: fully connected: m, linear activation LayerNormalizer()
r: fully connected, Elu + 1 activation 4×4Trns Conv, 12, stride 2×2
LayerNormalizer()
oi:1×1Trns Conv, stride 1×1, softmax
Gradient Explosion Experiment.
Referring to table 4, higher values of δdeteriorate performance because the convergence speed of the
linearized GRU hidden state depends on σ1(Uh)(see Eq. (55) in the appendix), which is projected to
2−δ. Therefore, longer time dependencies in the data are eliminated for high δ. On the other hand,
smaller values of δclose to zero make the model more prone to noise [ 10]. Therefore, it is necessary
to tune an appropriate δwithin the range 0< δ < 2, which is much easier than tuning the unbounded
θ.
A.8.2 Empirical running times and parameters
We present the number of parameters for the utilized cell structures in our experiments and their
corresponding empirical running times for 1 epoch in Table 6. In the first row of each model structure,
we set the number of parameters approximately equal to our GIN to demonstrate the GIN’s superior
performance with the same parameter count. The extra running time of EM-variational approaches,
like KV AE, is due to the use of classic Bayesian equations, which significantly increase running
time for higher-dimensional observations. However, the GIN avoids this issue. The number of
parameters in the GIN is noticeably lower than in other memory cells, such as LSTM and GRU,
and EM-variational methods. This efficiency is achieved by converting high-dimensional sparse
covariance matrices into lower-dimensional covariance matrices using a convolutional operator.
A.8.3 Qualitative comparison of the GIN to recent related work.
Switching Linear Dynamical System models (SLDS) decompose complex, nonlinear time series
data into sequences of simpler, reusable dynamical modes. Fitting an SLDS to data enables us to
learn a flexible nonlinear generative model and parse data sequences into coherent discrete units.
[9] is a SLDS model that incorporates additional latent variables to switch among different linear
dynamics. However, this approach relies on Gibbs sampling for inferring the parameters, rendering it
impractical for large datasets due to scalability issues.
Auto-regressive state space models (ARSSMs) are a class of dynamic models commonly used in time
series analysis and forecasting. In these models, the evolution of a system over time is described by
a set of states, by observing all data. Auto-Regressive (AR) Hidden Markov Models (AR-HMM)
explain time series structures by defining a mapping from past observations to the current observation.
[39] presents an ARHMM approach where target values are used directly as inputs. However, this
reliance on target values makes the model more susceptible to noise.
Toward learning state space (system identification), a number of works including those by [ 49–
53] have proposed algorithms for learning Gaussian Process SSMs (GPSSMs) through maximum
likelihood estimation using the iterative EM algorithm. where filtering-smoothing with a set of fixed
parameters γis conducted (E step), and then updating the set of parameters γis performed such that
the obtained likelihood is maximized (M step). Frigola et al. [ 51] obtain sample trajectories from the
smoothing distribution and then, conditioned on this trajectory, conduct the M step for the model’s
parameters. In the context of System Identification (SI), the GIN is akin to a Hammerstein-Wiener
(HW) model [ 34], as it estimates system parameters directly from observations while transferring the
observations through nonlinear functions.
23Table 6: Empirical running times and parameters of experiments.
CellSingle Pend Double Pend Bouncing Ball Visual Odometry
Param T/E Param T/E Param T/E Param T/E
LSTM ( n=25) ∼18k ∼56s ∼18k ∼56s ∼18k ∼53s ∼45k ∼83s
LSTM ( n=50) ∼36k ∼70s ∼36k ∼71s ∼36k ∼68s ∼70k ∼95s
LSTM ( n=100) ∼76k ∼98s ∼76k ∼96s ∼76k ∼93s ∼120k ∼131s
GRU ( n=30) ∼18k ∼61s ∼18k ∼62s ∼18k ∼59s ∼42k ∼79s
GRU ( n=50) ∼27k ∼65s ∼27k ∼67s ∼27k ∼64s ∼53k ∼84s
GRU ( n=100) ∼57k ∼86s ∼57k ∼85s ∼57k ∼84s ∼90k ∼111s
V AE ( n=40) ∼12k ∼50s ∼13k ∼52s ∼12k ∼49s ∼29k ∼70s
IWV AE ( n=40) ∼13k ∼50s ∼13k ∼54s ∼11k ∼47s ∼30k ∼75s
V AE-RNN ( n=40) ∼24k ∼59s ∼25k ∼61s ∼24k ∼57s ∼49k ∼89s
SV AE ( n=40) ∼27k ∼67s ∼27k ∼69s ∼26k ∼65s ∼68k ∼149s
KV AE ( n=40) ∼25k ∼95s ∼25k ∼97s ∼25k ∼94s ∼62k ∼141s
KV AE ( n=60) ∼36k ∼114s ∼36k ∼111s ∼36k ∼115s ∼80k ∼165s
EKV AE ( n=40) ∼26k ∼98s ∼26k ∼99s ∼26k ∼94s ∼65k ∼145s
EKV AE ( n=60) ∼37k ∼116s ∼38k ∼113s ∼35k ∼112s ∼83k ∼170s
MKV AE ( n=40) ∼34k ∼112s ∼34k ∼110s ∼33k ∼105s ∼77k ∼153s
RKN ( n=100) ∼25k ∼57s ∼25k ∼58s ∼25k ∼56s ∼45k ∼79s
CRU ( n=100) ∼24k ∼55s ∼24k ∼55s ∼23k ∼54s ∼46k ∼78s
Encode-Decoder ( n=30) ∼10k ∼45s ∼10k ∼44s ∼9k ∼44s ∼21k ∼63s
LGSSM ( n=30) ∼12k ∼82s ∼12k ∼84s ∼12k ∼80s ∼30k ∼117s
LGSSM ( n=45) ∼15k ∼98s ∼15k ∼97s ∼15k ∼97s ∼36k ∼136s
GIN ( n=30) ∼18k ∼55s ∼18k ∼55s ∼18k ∼54s ∼42k ∼80s
GIN ( n=45) ∼25k ∼59s ∼25k ∼58s ∼25k ∼57s ∼48k ∼83s
In Table 7, we compare various algorithms to evaluate their ability to handle high-dimensional
observations, learn dynamics, estimate state accurately, provide uncertainty estimates while handling
noisy data, manage missing data, and perform direct optimization. Classic LGSSMs, such as the EKF
and UKF, rely on the linearization of transition and emission equations and apply classic Bayesian
updates over the linearized system with respect to the states. In other words, classic LGSSMs are
model-based. In contrast, the GIN uses a data-driven network to learn parameters, offering a different
approach from the traditional model-based methods.
Table 7: Learning the parameters in LGSSM is shown with ×/✓because general LGSSMs, e.g.
UKF and EKF, are not able to learn the parameters. However, in our setting and parameterization we
use a data driven-based network for obtaining (F,H)to make LGSSMs comparable with the GIN
for high dimensional observation experiments.
Model high-d learn dynamics missing-imputation state est uncertainty noise handling dir opt
LSTM [26] ✓ ✓ ✓ ✓ × ✓ ✓
GRU [27] ✓ ✓ ✓ ✓ × ✓ ✓
P2T [54] ✓ ✓ × ✓ × × ✓
E2C [16] ✓ ✓ × × ✓ × ×
BB-VI [55] × ✓ ✓ × ✓ ✓ ×
SIN [13] ✓ ✓ ✓ × ✓ ✓ ×
DVBF [56] ✓ ✓ ✓ × ✓ ✓ ×
VSMC [57] ✓ ✓ ✓ × ✓ ✓ ×
DSA [20] ✓ ✓ × × ✓ × ×
KV AE [19] × ✓ ✓ ✓ ✓ ✓ ×
EKV AE [21] × ✓ ✓ ✓ ✓ ✓ ×
MV AE [23] × ✓ ✓ ✓ ✓ ✓ ×
rSLSD [9] × × × ✓ ✓ × ×
DeepAR [39] × ✓ × ✓ ✓ × ✓
DSSM [58] × ✓ × ✓ ✓ × ✓
HybridGNN [59] × × ✓ ✓ × ✓ ✓
KalmanNet [30] × × ✓ ✓ × ✓ ✓
SSI [31] × × ✓ ✓ ✓ ✓ ✓
LGSSM × × /✓ ✓ ✓ ✓ ✓ ✓
GIN ✓ ✓ ✓ ✓ ✓ ✓ ✓
24A.9 Visualization and The Imputation
Graphical results of informed, uninformed and noisy observations for image imputation task for both
single and double pendulum experiments can be found in 10, 11, 12 and 13 figures. Inference for the
trained smoothing distribution of all experiments are in 14, 15, 16, , 17, 18, 19, 20, 21, 22, 23 and
24 figures, where we generated samples from the smoothing estimated states distribution, (st|o1:T).
Then we fit density on the generated samples. This visualization shows the effectiveness of the GIN
in reducing the uncertainty of the estimates compare to LGSSM and KV AE.
25Ground Truth
Observed Sequence
LGSSM(filter)
LGSSM(smooth)
GIN(filter)
GIN(smooth)
Ground Truth
Observed Sequence
LGSSM(filter)
LGSSM(smooth)
GIN(filter)
GIN(smooth)
Figure 10: Informed(left column) and uninformed(right column) image imputation task for the single
pendulum experiments.
Figure 11: Image imputation task for the single pendulum experiment exposed to the noisy observa-
tions, where the generated noise has correlation with the time. Each figure, beginning from top to
bottom, indicates the ground truth, noisy observation and the imputation results of the GIN.
26Ground Truth
Observed Sequence
LGSSM(filter)
LGSSM(smooth)
GIN(filter)
GIN(smooth)
Ground Truth
Observed Sequence
LGSSM(filter)
LGSSM(smooth)
GIN(filter)
GIN(smooth)
Figure 12: Informed(left column) and uninformed(right column) image imputation task for the double
pendulum experiments.
Figure 13: Image imputation task for the double pendulum experiment exposed to the noisy observa-
tions, where the generated noise has correlation with the time. Each figure, beginning from top to
bottom, indicates the ground truth, noisy observation and the imputation results of the GIN.
27GIN LGSSM KVAE0.20.40.60.81.01.2s1p(gt1100)=(s10.7)
mean=0.69
mean=0.93
mean=0.53
Figure 14: Inference for the single pendulum s1position at 100-th time step. Generated samples from
smoothened distribution, (s1100|o1:150), trained by the GIN, LGSSM and KV AE, respectively. The
dashed red line p(gt1100)is the ground truth state with distribution of δ(s1100−0.7). We calculate the
sample mean and fit a distribution on the samples for further visualization and comparison purpose.
GIN LGSSM KVAE0.20.40.60.81.01.2s2p(gt2100)=(s20.7)
mean=0.73
mean=0.91
mean=0.42
Figure 15: Inference for the single pendulum s2position at 100-th time step. Generated samples
from smoothened distribution, (s2100|o1:150), trained by the GIN, LGSSM and KV AE, respectively.
ଵ଴଴ ଵ଴଴
(a) GIN
ଵ଴଴ ଵ଴଴ (b) LGSSM
ଵ଴଴ ଵ଴଴ (c) KV AE
Figure 16: Generated samples from the trained smoothened joint distribution of the single pendulum
position, (s1, s2), at 100-th time step for the GIN, LGSSM and KV AE, respectively. The ground
truth is shown with a black point.
28GIN LGSSM KVAE0.2
0.00.20.40.60.8s1p(gt1100)=(s10.35)
mean=0.36
mean=0.38
mean=0.44
Figure 17: Inference for the double pendulum s1position at 100-th time step. Generated samples
from smoothened distribution, (s1100|o1:150), trained by the GIN, LGSSM and KV AE, respectively.
The dashed red line p(gt1100)is the ground truth state with distribution of δ(s1100−0.35).
GIN LGSSM KVAE0.2
0.00.20.40.60.8s2p(gt2100)=(s20.35)
mean=0.38
mean=0.28
mean=0.29
Figure 18: Inference for the double pendulum s2position at 100-th time step. Generated samples
from smoothened distribution, (s2100|o1:150), trained by the GIN, LGSSM and KV AE, respectively.
The dashed red line p(gt2100)is the ground truth state with distribution of δ(s2100−0.35).
ଵ଴଴ ଵ଴଴
(a) GIN
ଵ଴଴ ଵ଴଴ (b) LGSSM
ଵ଴଴ ଵ଴଴ (c) KV AE
Figure 19: Generated samples from the trained smoothened joint distribution of the double pendulum
first joint position, (s1, s2), at 100-th time step for the GIN, LGSSM and KV AE, respectively. The
ground truth is shown with a black point.
29GIN LGSSM KVAE0.60.81.01.21.4s3p(gt3100)=(s31)
mean=1.0
mean=0.94
mean=0.96
Figure 20: Inference for the double pendulum s3position at 100-th time step. Generated samples
from smoothened distribution, (s3100|o1:150), trained by the GIN, LGSSM and KV AE, respectively.
The dashed red line p(gt3100)is the ground truth state with distribution of δ(s3100−1).
GIN LGSSM KVAE0.4
0.2
0.00.20.4s4p(gt4100)=(s4)
mean=-0.01
mean=0.08
mean=0.1
Figure 21: Inference for the double pendulum s4position at 100-th time step. Generated samples
from smoothened distribution, (s4100|o1:150), trained by the GIN, LGSSM and KV AE, respectively.
ଵ଴଴ ଵ଴଴
(a) GIN
ଵ଴଴ ଵ଴଴ (b) LGSSM
ଵ଴଴ ଵ଴଴ (c) KV AE
Figure 22: Generated samples from the trained smoothened joint distribution of the double pendulum
second joint position, (s3, s4), at 100-th time step for the GIN, LGSSM and KV AE, respectively.
The ground truth is shown with a black point.
3060.0
57.5
55.0
52.5
50.0
47.5
45.0
42.5
40.0
s1p(gt1100)=(s1+50)
100|500=-50.12
100|500=-52.25
100|500=-43.99
GIN LGSSM KVAE0.02.55.07.510.012.515.017.520.0s2
p(gt1100)=(s110)
100|500=10.08
100|500=12.86
100|500=8.46
Figure 23: Inference for the visual odometry s1ands2positions at 100-th time step. Generated
samples from smoothened distribution, (s1100, s2100|o1:500), trained by the GIN, LGSSM and
KV AE, respectively. The dashed red line p(gt1100, gt2100)is the ground truth state with distribution
of(δ(s1100+ 50) , δ(s2100−10)).
A.10 MSE Results for The State Estimation and Estimated KG-SG
The MSE results for the single pendulum, double pendulum, and bouncing ball experiments are
shown in Tables 8 and 9 and 10. In addition to the dynamics equation (5), where the ˆFmatrix includes
the effects of the process noise, two other solutions introduced in Section 5 are included in the MSE
results. Parameterizing the process noise as in (24) with a GRU cell is indicated by GRU( Q), while
another parameterization, shown as MLP( Q), is done using (26).
31ଵ଴଴ ଵ଴଴(a) GIN
ଵ଴଴ ଵ଴଴ (b) LGSSM
ଵ଴଴ ଵ଴଴ (c) KV AE
Figure 24: Generated samples from the trained smoothened joint distribution of the visual odometry
joint position, (s1, s2), at 100-th time step for the GIN, LGSSM and KV AE, respectively. The ground
truth is shown with a black point.
A.11 Algorithms and python inference code
Algorithm Training the GIN
Input: Observations o1:T, last posteriors (ˆµ0:T−1|0:T−1,ˆΣ0:T−1|0:T−1)
(x0:T−1|0:T−1)=Sample ((ˆµ0:T−1|0:T−1,ˆΣ0:T−1|0:T−1))
α1:T=Dynamic Net (x0:T−1|0:T−1)
Obtain ˆF1:TandˆH1:Tby (5)
(ˆµ1:T|0:T−1,ˆΣ1:T|0:T−1)=Prediction (ˆµ0:T−1|0:T−1,ˆΣ0:T−1|0:T−1,ˆF1:T)
(w1:T,r1:T)=encoder (o1:T)
ˆK1:T=ˆΣ1:T|0:T−1ˆH1:TM1:TMT
1:T,M1:T=GRUKG(Conv(ˆΣ1:T|0:T−1),r1:T)
ˆJ1:T=ˆΣ1:T|1:TˆFT
1:TN1:TNT
1:T,N1:T=GRUSG(Conv(ˆΣ1:T|0:T−1))
(ˆµ1:T|1:T,ˆΣ1:T|1:T)=Filtering (ˆµ1:T|0:T−1,ˆΣ1:T|0:T−1,ˆK1:T,w1:T,ˆH1:T)
(ˆµ1:T|T,ˆΣ1:T|T)=Smoothing (ˆµ1:T|1:T,ˆΣ1:T|1:T,ˆJ1:T,ˆF1:T)
if(image imputation) then
o1:T=decoder (ˆµ1:T|T,ˆΣ1:T|T)
L(o1:T)= Lower bound likelihood (o1:T)by using (10)
end if
if(state estimation) then
s1:T=decoder (ˆµ1:T|T,ˆΣ1:T|T)
L(s1:T|o1:T)= Lower bound likelihood (s1:T)by using (11)
end if
Backward Propagation by updating GRU cells with the steps in Theorem 3 orTheorem 4 .
32Table 8: MSE for single pendulum experiment.
Model MSE
LSTM (units = 25, m= 15 ) 0.092 ±0.003
LSTM (units = 25, m= 20 ) 0.092 ±0.005
LSTM (units = 25, m= 40 ) 0.090 ±0.005
LSTM (units = 100, m= 15 ) 0.089 ±0.002
LSTM (units = 100, m= 20 ) 0.089 ±0.005
LSTM (units = 100, m= 40 ) 0.090 ±0.004
GRU (units = 30, m= 15 ) 0.095 ±0.006
GRU (units = 30, m= 20 ) 0.093 ±0.002
GRU (units = 30, m= 40 ) 0.094 ±0.005
GRU (units = 100, m= 15 ) 0.091 ±0.002
GRU (units = 100, m= 20 ) 0.092 ±0.004
GRU (units = 100, m= 40 ) 0.091 ±0.008
Model ˆF(Q) MLP(Q) GRU( Q)
LGSSM filter( m= 15 ,n= 30 ,K= 10 ) 0.089 ±0.009 0.088 ±0.005 0.088 ±0.006
LGSSM filter( m= 15 ,n= 30 ,K= 15 ) 0.088 ±0.011 0.087 ±0.007 0.086 ±0.004
LGSSM filter( m= 15 ,n= 45 ,K= 10 ) 0.085 ±0.004 0.084 ±0.007 0.084 ±0.009
LGSSM filter( m= 15 ,n= 45 ,K= 15 ) 0.084 ±0.005 0.083 ±0.004 0.082 ±0.004
LGSSM filter( m= 20 ,n= 40 ,K= 10 ) 0.084 ±0.009 0.082 ±0.014 0.082 ±0.011
LGSSM filter( m= 20 ,n= 40 ,K= 15 ) 0.083 ±0.012 0.081 ±0.005 0.080 ±0.014
LGSSM filter( m= 20 ,n= 60 ,K= 10 ) 0.079 ±0.005 0.078 ±0.012 0.076 ±0.009
LGSSM filter( m= 20 ,n= 60 ,K= 15 ) 0.077 ±0.006 0.075 ±0.011 0.074 ±0.008
LGSSM smooth( m= 15 ,n= 30 ,K= 10 ) 0.086 ±0.011 0.083 ±0.004 0.084 ±0.007
LGSSM smooth( m= 15 ,n= 30 ,K= 15 ) 0.085 ±0.012 0.084 ±0.008 0.083 ±0.012
LGSSM smooth( m= 15 ,n= 45 ,K= 10 ) 0.081 ±0.008 0.080 ±0.009 0.079 ±0.003
LGSSM smooth( m= 15 ,n= 45 ,K= 15 ) 0.081 ±0.014 0.078 ±0.007 0.077 ±0.011
LGSSM smooth( m= 20 ,n= 40 ,K= 10 ) 0.082 ±0.005 0.078 ±0.004 0.076 ±0.013
LGSSM smooth( m= 20 ,n= 40 ,K= 15 ) 0.080 ±0.003 0.076 ±0.006 0.074 ±0.010
LGSSM smooth( m= 20 ,n= 60 ,K= 10 ) 0.076 ±0.008 0.073 ±0.002 0.070 ±0.009
LGSSM smooth( m= 20 ,n= 60 ,K= 15 ) 0.073 ±0.013 0.071 ±0.011 0.068 ±0.013
GIN filter( m= 15 ,n= 30 ,K= 10 ) 0.078 ±0.013 0.076 ±0.005 0.075 ±0.004
GIN filter( m= 15 ,n= 30 ,K= 15 ) 0.078 ±0.014 0.075 ±0.009 0.074 ±0.012
GIN filter( m= 15 ,n= 45 ,K= 10 ) 0.074 ±0.010 0.073 ±0.008 0.072 ±0.009
GIN filter( m= 15 ,n= 45 ,K= 15 ) 0.073 ±0.015 0.074 ±0.011 0.071 ±0.005
GIN filter( m= 20 ,n= 40 ,K= 10 ) 0.072 ±0.005 0.072 ±0.008 0.070 ±0.002
GIN filter( m= 20 ,n= 40 ,K= 15 ) 0.071 ±0.007 0.071 ±0.004 0.071 ±0.009
GIN filter( m= 20 ,n= 60 ,K= 10 ) 0.067 ±0.009 0.066 ±0.005 0.065 ±0.006
GIN filter( m= 20 ,n= 60 ,K= 15 ) 0.065 ±0.013 0.064 ±0.009 0.063 ±0.010
GIN smooth( m= 15 ,n= 30 ,K= 10 ) 0.071 ±0.007 0.070 ±0.003 0.068 ±0.009
GIN smooth( m= 15 ,n= 30 ,K= 15 ) 0.070 ±0.008 0.068 ±0.011 0.068 ±0.007
GIN smooth( m= 15 ,n= 45 ,K= 10 ) 0.065 ±0.011 0.065 ±0.009 0.064 ±0.012
GIN smooth( m= 15 ,n= 45 ,K= 15 ) 0.064 ±0.008 0.066 ±0.007 0.063 ±0.009
GIN smooth( m= 20 ,n= 40 ,K= 10 ) 0.064 ±0.005 0.065 ±0.003 0.062 ±0.008
GIN smooth( m= 20 ,n= 40 ,K= 15 ) 0.063 ±0.004 0.064 ±0.011 0.063 ±0.007
GIN smooth( m= 20 ,n= 60 ,K= 10 ) 0.059 ±0.009 0.061 ±0.012 0.057 ±0.006
GIN smooth( m= 20 ,n= 60 ,K= 15 ) 0.058 ±0.005 0.057 ±0.009 0.056 ±0.004
33Table 9: MSE for double pendulum experiment.
Model MSE
LSTM (units = 50, m= 15 ) 0.172 ±0.012
LSTM (units = 50, m= 20 ) 0.166 ±0.009
LSTM (units = 50, m= 40 ) 0.167 ±0.011
LSTM (units = 100, m= 15 ) 0.164 ±0.006
LSTM (units = 100, m= 20 ) 0.162 ±0.009
LSTM (units = 100, m= 40 ) 0.159 ±0.010
GRU (units = 50, m= 15 ) 0.194 ±0.014
GRU (units = 50, m= 20 ) 0.189 ±0.013
GRU (units = 50, m= 40 ) 0.188 ±0.015
GRU (units = 100, m= 15 ) 0.173 ±0.009
GRU (units = 100, m= 20 ) 0.169 ±0.014
GRU (units = 100, m= 40 ) 0.166 ±0.018
Model ˆF(Q) MLP(Q) GRU( Q)
LGSSM filter( m= 15 ,n= 30 ,K= 10 ) 0.154 ±0.013 0.159 ±0.021 0.153 ±0.009
LGSSM filter( m= 15 ,n= 30 ,K= 15 ) 0.152 ±0.008 0.153 ±0.010 0.152 ±0.012
LGSSM filter( m= 15 ,n= 45 ,K= 10 ) 0.144 ±0.011 0.141 ±0.015 0.139 ±0.013
LGSSM filter( m= 15 ,n= 45 ,K= 15 ) 0.142 ±0.007 0.138 ±0.012 0.137 ±0.017
LGSSM filter( m= 20 ,n= 40 ,K= 10 ) 0.144 ±0.012 0.137 ±0.009 0.138 ±0.013
LGSSM filter( m= 20 ,n= 40 ,K= 15 ) 0.141 ±0.007 0.137 ±0.008 0.136 ±0.016
LGSSM filter( m= 20 ,n= 60 ,K= 10 ) 0.129 ±0.009 0.126 ±0.014 0.122 ±0.015
LGSSM filter( m= 20 ,n= 60 ,K= 15 ) 0.127 ±0.012 0.124 ±0.013 0.119 ±0.009
LGSSM smooth( m= 15 ,n= 30 ,K= 10 ) 0.147 ±0.009 0.148 ±0.014 0.144 ±0.015
LGSSM smooth( m= 15 ,n= 30 ,K= 15 ) 0.146 ±0.014 0.146 ±0.013 0.142 ±0.017
LGSSM smooth( m= 15 ,n= 45 ,K= 10 ) 0.139 ±0.017 0.136 ±0.009 0.133 ±0.017
LGSSM smooth( m= 15 ,n= 45 ,K= 15 ) 0.137 ±0.009 0.135 ±0.017 0.133 ±0.012
LGSSM smooth( m= 20 ,n= 40 ,K= 10 ) 0.136 ±0.014 0.131 ±0.022 0.132 ±0.011
LGSSM smooth( m= 20 ,n= 40 ,K= 15 ) 0.134 ±0.011 0.129 ±0.014 0.129 ±0.022
LGSSM smooth( m= 20 ,n= 60 ,K= 10 ) 0.123 ±0.019 0.116 ±0.016 0.115 ±0.013
LGSSM smooth( m= 20 ,n= 60 ,K= 15 ) 0.120 ±0.010 0.112 ±0.009 0.108 ±0.014
GIN filter( m= 15 ,n= 30 ,K= 10 ) 0.126 ±0.014 0.125 ±0.012 0.125 ±0.011
GIN filter( m= 15 ,n= 30 ,K= 15 ) 0.124 ±0.015 0.124 ±0.019 0.121 ±0.009
GIN filter( m= 15 ,n= 45 ,K= 10 ) 0.115 ±0.011 0.114 ±0.015 0.110 ±0.017
GIN filter( m= 15 ,n= 45 ,K= 15 ) 0.114 ±0.019 0.112 ±0.020 0.110 ±0.011
GIN filter( m= 20 ,n= 40 ,K= 10 ) 0.113 ±0.013 0.111 ±0.009 0.111 ±0.013
GIN filter( m= 20 ,n= 40 ,K= 15 ) 0.111 ±0.009 0.109 ±0.018 0.108 ±0.009
GIN filter( m= 20 ,n= 60 ,K= 10 ) 0.099 ±0.018 0.094 ±0.017 0.095 ±0.021
GIN filter( m= 20 ,n= 60 ,K= 15 ) 0.097 ±0.009 0.093 ±0.009 0.091 ±0.008
GIN smooth( m= 15 ,n= 30 ,K= 10 ) 0.115 ±0.011 0.116 ±0.009 0.113 ±0.017
GIN smooth( m= 15 ,n= 30 ,K= 15 ) 0.113 ±0.015 0.113 ±0.018 0.112 ±0.014
GIN smooth( m= 15 ,n= 45 ,K= 10 ) 0.105 ±0.009 0.101 ±0.014 0.101 ±0.015
GIN smooth( m= 15 ,n= 45 ,K= 15 ) 0.102 ±0.013 0.100 ±0.011 0.098 ±0.008
GIN smooth( m= 20 ,n= 40 ,K= 10 ) 0.101 ±0.008 0.098 ±0.010 0.094 ±0.015
GIN smooth( m= 20 ,n= 40 ,K= 15 ) 0.098 ±0.017 0.095 ±0.014 0.092 ±0.007
GIN smooth( m= 20 ,n= 60 ,K= 10 ) 0.086 ±0.013 0.081 ±0.008 0.079 ±0.009
GIN smooth( m= 20 ,n= 60 ,K= 15 ) 0.083 ±0.009 0.079 ±0.006 0.076 ±0.013
34Table 10: MSE for bouncing ball experiment.
Model MSE
LSTM (units = 50, m= 15 ) 3.724 ±0.195
LSTM (units = 50, m= 20 ) 3.698 ±0.127
LSTM (units = 50, m= 40 ) 3.684 ±0.152
LSTM (units = 100, m= 15 ) 3.476 ±0.191
LSTM (units = 100, m= 20 ) 3.39 ±0.282
LSTM (units = 100, m= 40 ) 3.28 ±0.249
GRU (units = 50, m= 15 ) 3.941 ±0.378
GRU (units = 50, m= 20 ) 3.725 ±0.491
GRU (units = 50, m= 40 ) 3.65 ±0.454
GRU (units = 100, m= 15 ) 3.631 ±0.392
GRU (units = 100, m= 20 ) 3.512 ±0.466
GRU (units = 100, m= 40 ) 3.389 ±0.286
Model ˆF(Q) MLP(Q) GRU( Q)
LGSSM filter( m= 15 ,n= 30 ,K= 10 ) 0.559 ±0.057 0.557 ±0.039 0.543 ±0.049
LGSSM filter( m= 15 ,n= 30 ,K= 15 ) 0.552 ±0.051 0.547 ±0.019 0.531 ±0.047
LGSSM filter( m= 15 ,n= 45 ,K= 10 ) 0.541 ±0.044 0.543 ±0.042 0.524 ±0.061
LGSSM filter( m= 15 ,n= 45 ,K= 15 ) 0.539 ±0.051 0.538 ±0.042 0.519 ±0.039
LGSSM filter( m= 20 ,n= 40 ,K= 10 ) 0.542 ±0.072 0.536 ±0.029 0.518 ±0.050
LGSSM filter( m= 20 ,n= 40 ,K= 15 ) 0.524 ±0.049 0.537 ±0.061 0.522 ±0.037
LGSSM filter( m= 20 ,n= 60 ,K= 10 ) 0.517 ±0.047 0.524 ±0.029 0.514 ±0.060
LGSSM filter( m= 20 ,n= 60 ,K= 15 ) 0.529 ±0.034 0.517 ±0.039 0.512 ±0.024
LGSSM smooth( m= 15 ,n= 30 ,K= 10 ) 0.485 ±0.029 0.483 ±0.019 0.475 ±0.028
LGSSM smooth( m= 15 ,n= 30 ,K= 15 ) 0.476 ±0.036 0.479 ±0.051 0.458 ±0.026
LGSSM smooth( m= 15 ,n= 45 ,K= 10 ) 0.479 ±0.042 0.471 ±0.045 0.468 ±0.058
LGSSM smooth( m= 15 ,n= 45 ,K= 15 ) 0.462 ±0.039 0.473 ±0.041 0.471 ±0.024
LGSSM smooth( m= 20 ,n= 40 ,K= 10 ) 0.469 ±0.021 0.475 ±0.043 0.451 ±0.034
LGSSM smooth( m= 20 ,n= 40 ,K= 15 ) 0.461 ±0.029 0.465 ±0.037 0.455 ±0.027
LGSSM smooth( m= 20 ,n= 60 ,K= 10 ) 0.460 ±0.038 0.452 ±0.014 0.442 ±0.058
LGSSM smooth( m= 20 ,n= 60 ,K= 15 ) 0.448 ±0.027 0.452 ±0.020 0.444 ±0.019
GIN filter( m= 15 ,n= 30 ,K= 10 ) 0.267 ±0.028 0.264 ±0.027 0.258 ±0.034
GIN filter( m= 15 ,n= 30 ,K= 15 ) 0.265 ±0.021 0.260 ±0.020 0.251 ±0.014
GIN filter( m= 15 ,n= 45 ,K= 10 ) 0.264 ±0.024 0.259 ±0.023 0.244 ±0.019
GIN filter( m= 15 ,n= 45 ,K= 15 ) 0.259 ±0.019 0.260 ±0.029 0.245 ±0.018
GIN filter( m= 20 ,n= 40 ,K= 10 ) 0.255 ±0.011 0.250 ±0.018 0.239 ±0.051
GIN filter( m= 20 ,n= 40 ,K= 15 ) 0.256 ±0.029 0.243 ±0.034 0.237 ±0.016
GIN filter( m= 20 ,n= 60 ,K= 10 ) 0.247 ±0.043 0.240 ±0.018 0.231 ±0.028
GIN filter( m= 20 ,n= 60 ,K= 15 ) 0.244 ±0.050 0.241 ±0.031 0.231 ±0.037
GIN smooth( m= 15 ,n= 30 ,K= 10 ) 0.148 ±0.011 0.146 ±0.012 0.139 ±0.014
GIN smooth( m= 15 ,n= 30 ,K= 15 ) 0.145 ±0.008 0.145 ±0.031 0.133 ±0.017
GIN smooth( m= 15 ,n= 45 ,K= 10 ) 0.140 ±0.015 0.139 ±0.008 0.130 ±0.028
GIN smooth( m= 15 ,n= 45 ,K= 15 ) 0.133 ±0.011 0.134 ±0.024 0.129 ±0.015
GIN smooth( m= 20 ,n= 40 ,K= 10 ) 0.121 ±0.014 0.118 ±0.008 0.110 ±0.016
GIN smooth( m= 20 ,n= 40 ,K= 15 ) 0.115 ±0.012 0.117 ±0.009 0.106 ±0.014
GIN smooth( m= 20 ,n= 60 ,K= 10 ) 0.115 ±0.013 0.110 ±0.018 0.099 ±0.008
GIN smooth( m= 20 ,n= 60 ,K= 15 ) 0.112 ±0.010 0.106 ±0.012 0.094 ±0.011
35To demonstrate the simplicity of our proposed GIN, we include intuitive inference code with Ten-
sorflow library. The code runs with Python 3.6+. The entire code to reproduce the experiments are
available in Github repository.
A.11.1 Python intuitive code.
1# Inference with !
2
3import tensorflow . keras as k
4import Prediction
5import Filtering
6import Smoothing
7import DynamicsNetwork
8import Encoder
9import Decoder
10import DataGen
11
12class GIN_CELL (k. layers . Layer ):
13 def __init__ (self , initial_states ):
14 self . mu_tm1_filt , self . Sigma_tm1_filt = initial_states
15 self . filter_states = [[ self . mu_tm1_filt , self . Sigma_tm1_filt ]]
16 def call (self , inputs ):
17 w_1 :T, r_1:T = inputs
18 for w_t , r_t in (w_1:T, r_1:T):
19 x_tm1_filt = sample ( self . mu_tm1_filt , self . Sigma_tm1_filt )
20 F_hat_t , H_hat_t = DynamicsNetwork ( x_tm1_filt )
21 mu_t_pri , Sigma_t_pri = Prediction ( F_hat_t , H_hat_t ,...
22 self . mu_tm1_filt , self . Sigma_tm1_filt )
23 mu_t_filt , Sigma_t_filt = Filtering ( mu_t_pri ,...
24 Sigma_t_pri , w_t , r_t , H_hat_t )
25 self . filter_states . append ([ mu_t_filt , Sigma_t_filt ])
26 self . mu_tm1_filt = x_t_filt
27 self . Sigma_tm1_filt = Sigma_t_filt
28 mu_1 : T_smooth , Sigma_1 : T_smooth = Smoothing ( F_hat_1 :T ,...
29 self . filter_states , Sigma_1 :T_pri ,)
30 return mu_1 : T_smooth , Sigma_1 : T_smooth
31
32class GIN (k. models . Model ):
33 def __init__ (self , initial_states ):
34 self . mu_0_filt , self . Sigma_0_filt = initial_states
35 self . GIN_CELL_OBJ = self . GIN_CELL ( self . x_0_filt , self .
Sigma_0_filt )
36 self . Encoder = Encoder
37 self . Decoder = Decoder
38
39 def call (self , o_1 :T):
40 w_1 :T, r_1:T = self . Encoder (o_1:T)
41 mu_1 : T_smooth , Sigma_1 : T_smooth = self . GIN_CELL_OBJ (w_1 :T, r_1
:T)
42 o_1 :T, s_1:T = self . Decoder ( mu_1 : T_smooth , Sigma_1 : T_smooth )
43 return o_1:T, s_1:T
44
45initial_states = mu_0_filt , Sigma_0_filt
46GIN_OBJ =GIN( initial_states )
47
48Data = DataGen ()
49o_1 :T, s_1:T = GIN_OBJ ( Data )
36NeurIPS Paper Checklist
1.Claims
Question: Do the main claims made in the abstract and introduction accurately reflect the
paper’s contributions and scope?
Answer: [Yes]
Justification: The claims we have made in abstract and introduction are elaborated and
achieved in the main paper.
2.Limitations
Question: Does the paper discuss the limitations of the work performed by the authors?
Answer: [Yes]
Justification: We discuss the limitations and assumptions necessary for Theorems 3 and
4. In the appendix, where we provide the proofs, we reiterate the requirements that the
algorithm must meet.
3.Theory Assumptions and Proofs
Question: For each theoretical result, does the paper provide the full set of assumptions and
a complete (and correct) proof?
Answer: [Yes]
Justification: The proofs of the mentioned theorems and mathematical claims are all provided
in appendix section. In the main text, we refer the readers to the proofs after introducing
each theorem-claim.
4.Experimental Result Reproducibility
Question: Does the paper fully disclose all the information needed to reproduce the main ex-
perimental results of the paper to the extent that it affects the main claims and/or conclusions
of the paper (regardless of whether the code and data are provided or not)?
Answer: [Yes]
Justification: All the required information for running the experiments are provided in the
supplementary materials and anonymous github repository.
5.Open access to data and code
Question: Does the paper provide open access to the data and code, with sufficient instruc-
tions to faithfully reproduce the main experimental results, as described in supplemental
material?
Answer: [Yes]
Justification: We provide instructions to synthesis the data and run the experiments. All
details are provided in anonymous github repository.
6.Experimental Setting/Details
Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
results?
Answer: [Yes]
Justification: We provide a detailed section in appendix to argue about network architecture,
hyper parameter optimization, experiment setting, etc.. This addresses the question you
asked.
Guidelines:
7.Experiment Statistical Significance
Question: Does the paper report error bars suitably and correctly defined or other appropriate
information about the statistical significance of the experiments?
Answer: [Yes]
37Justification: We include confidence interval in our numerical experiments to show the
reliability of the results. Initialization approaches are explained with details in the main
script.
8.Experiments Compute Resources
Question: For each experiment, does the paper provide sufficient information on the com-
puter resources (type of compute workers, memory, time of execution) needed to reproduce
the experiments?
Answer: [Yes]
Justification: We provide detailed configuration of our machines for running the experiments.
9.Code Of Ethics
Question: Does the research conducted in the paper conform, in every respect, with the
NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines ?
Answer: [Yes]
Justification: We are following all the ethics provided by NeurIPS.
10.Broader Impacts
Question: Does the paper discuss both potential positive societal impacts and negative
societal impacts of the work performed?
Answer: [NA]
Justification: We believe this work does not have negative impact on the social communities.
11.Safeguards
Question: Does the paper describe safeguards that have been put in place for responsible
release of data or models that have a high risk for misuse (e.g., pretrained language models,
image generators, or scraped datasets)?
Answer: [NA]
Justification: The paper poses no such risks.
12.Licenses for existing assets
Question: Are the creators or original owners of assets (e.g., code, data, models), used in
the paper, properly credited and are the license and terms of use explicitly mentioned and
properly respected?
Answer: [NA]
Justification: The paper does not use existing assets.
13.New Assets
Question: Are new assets introduced in the paper well documented and is the documentation
provided alongside the assets?
Answer: [NA]
Justification:
14.Crowdsourcing and Research with Human Subjects
Question: For crowdsourcing experiments and research with human subjects, does the paper
include the full text of instructions given to participants and screenshots, if applicable, as
well as details about compensation (if any)?
Answer: [NA]
Justification: The paper does not involve crowdsourcing nor research with human subjects.
15.Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
Subjects
Question: Does the paper describe potential risks incurred by study participants, whether
such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
approvals (or an equivalent approval/review based on the requirements of your country or
institution) were obtained?
Answer: [NA]
Justification: The paper does not involve crowdsourcing nor research with human subjects.
38