Faster Accelerated First-order Methods for Convex
Optimization with Strongly Convex Function
Constraints
Zhenwei Lin
Shanghai University of Finance and Economics
zhenweilin@163.sufe.edu.cn
Qi Deng∗
Antai College of Economics and Management
Shanghai Jiao Tong University
qdeng24@sjtu.edu.cn
Abstract
In this paper, we introduce faster accelerated primal-dual algorithms for minimizing
a convex function subject to strongly convex function constraints. Prior to our
work, the best complexity bound was O(1/ε), regardless of the strong convexity of
the constraint function. It is unclear whether the strong convexity assumption can
enable even better convergence results. To address this issue, we have developed
novel techniques to progressively estimate the strong convexity of the Lagrangian
function. Our approach, for the first time, effectively leverages the constraint strong
convexity, obtaining an improved complexity of O(1/√ε). This rate matches the
complexity lower bound for strongly-convex-concave saddle point optimization
and is therefore order-optimal. We show the superior performance of our meth-
ods in sparsity-inducing constrained optimization, notably Google’s personalized
PageRank problem. Furthermore, we show that a restarted version of the proposed
methods can effectively identify the optimal solution’s sparsity pattern within a
finite number of steps, a result that appears to have independent significance.
1 Introduction
In this paper, we are interested in the following convex function-constrained problem:
minx∈Rnf(x) s.t. gi(x)≤0,1≤i≤m, (1)
where f:Rn→Ris a convex continuous function and bounded from below and gi:Rn→R,
i= 1,2, . . . , m , are strongly convex continuous functions. An important application of this problem,
commonly encountered in statistics and engineering, involves the objective f(x)as a proximal-
friendly regularizer and gi(x)as a data-driven loss function used to gauge model fidelity.
To apply first-order methods for the above function-constrained problems, a common strategy
involves a double-loop procedure that repeatedly employs fast first-order methods, such as Nesterov’s
accelerated method, to solve specific strongly convex proximal subproblems. Popular methods among
this category include Augmented Lagrangian methods [ 18,33], level-set methods [ 21], penalty
methods [ 17]. When both f(x)andgi(x)are convex and smooth (or composite), it has been found
that these double-loop algorithms can attain an iteration complexity of O(1/ε)to achieve an ε-error
∗Corresponding author
38th Conference on Neural Information Processing Systems (NeurIPS 2024).in both the optimality gap and constraint violation. When the objective is strongly convex, the
complexity can be further improved to O(1/√ε)([33, 21]).
In contrast to these double-loop algorithms, single-loop algorithms remain popular due to their
simplicity in implementation. Along this research line, [32] developed a first-order algorithm based
on linearizing the augmented Lagrangian function, which obtains an iteration complexity of O(1/ε).
[34] extended the augmented Lagrangian method to stochastic function-constrained problems where
both objective and constraint exhibit an expectation form. Viewing (1)as a special case of the
min-max problem:
minx∈Rnmax y∈RmL(x,y) :=f(x) +Pm
i=1yigi(x),s.t.yi≥0, i= 1,2, . . . , m, (2)
[11] proposed to solve (1)and(2)by an accelerated primal-dual method (APD), which generalizes
the primal-dual hybrid gradient method [ 6] initially developed for saddle point optimization with
bilinear coupling term. Under mild conditions, APD achieves the best iteration complexity of O(1/ε)
for general convex constrained problem and a further improved complexity of O(1/√ε)when f(x)
is strongly convex. [ 4] proposed a unified constrained extrapolation method that can be applied to
both deterministic and stochastic constrained optimization problems.
Despite these recent progresses, to the best of our knowledge, all available algorithms are suboptimal
in the presence of strongly convex function constraints (1). Specifically, direct applications of previ-
ously discussed algorithms yield an O(1/ε)complexity, which is inferior to the O(1/√ε)optimal
bound for the strongly-convex-concave saddle point problem [ 22]. It is somewhat unsatisfactory that
the strong convexity of g(x)has not been found helpful in further algorithmic acceleration. The core
underlying issue arises from the dynamics of saddle point optimization: it is the strong convexity
ofL(·,y)that offers more potential acceleration advantages, yet the strong convexity of L(·,y)is
substantially harder to estimate than that of g(x). This difficulty is compounded by the interplay
between g(x)and the varying dual sequence {yk}. The challenge naturally leads us to question: Is
it possible to further improve the convergence rate of first-order methods for solving the strongly
convex constrained problem (1)?
Key intuitions We make an assumption that the minimizer of f(x)is infeasible for the function
constraint gi(x)≤0,1≤i≤m. If this assumption were not made, we would be dealing with an
unconstrained optimization problem that would not depend on g(x). This assumption also implies
that the optimal dual variables are non-zero, and as a result, the Lagrangian function is strongly
convex with respect to x. By leveraging the strong convexity, we can use more aggressive step sizes
and achieve faster convergence rates compared to other state-of-the-art algorithms.
Applications in sparsity-constrained optimization We consider the constrained Lasso-type prob-
lem, which minimizes a sparsity-inducing regularizer while explicitly ensuring data-driven error
remains controlled:
minx∈Rn∥x∥1s.t.g(x)≤0, (3)
where g(·)is a convex smooth loss term. A motivating application is the approximate personalized
PageRank problem [ 8], where g(x) =1
2⟨x, Qx⟩ − ⟨b,x⟩is strongly convex quadratic and Q
integrates the graph Laplacian with an identity matrix. Compared to the standard Lasso problem [ 30],
minx∈Rng(x)+λ∥x∥1,the constrained problem (3)offers enhanced control over the data fitting error.
This advantage, however, is counterbalanced by the challenge of dealing with a nonlinear constraint.
Besides concerns about the efficiency in solving (3), it is often desired to show the active set (or
sparsity) identification, namely, the nonzero patterns of the optimal solution x∗can be identified
by the solution sequence {xk}in a finite number of iterations. Identifying the embedded solution
structure within a broader context is referred to as the manifold identification problem [ 31,12].
Exploiting the sparsity pattern is particularly desirable in large-scale PageRank problems, as it could
result in significant runtime savings. For the regularized Lasso-type problem, it has been known
that proximal gradient methods (e.g. [ 14,19,24]) possess the finite active-set identification property.
Specifically, [ 24] introduced “active set complexity”, which is defined as the number of iterations
required before an algorithm is guaranteed to have reached the optimal manifold, and they proved
the proximal gradient method with constant stepsize can identify the optimal manifold in a finite
number of iterations. However, for the problem (3), it remains unclear whether first-order methods
can identify the sparsity pattern in finite time.
2Contributions We address the theoretical questions about strongly convex constrained optimization
and the application of sparse optimization. Our contributions are summarized as follows.
First, we present a new accelerated primal-dual algorithm with progressive strong convexity estimation
(APDPro) for solving problem (1). APDPro employs a novel strategy to estimate the lower bound of
the dual variables, which leads to a gradually refined estimated strong convexity modulus of L(·,y).
With additional cut constraints on the dual update, APDPro is able to separate the dual search space
from the origin point, which is critical for maintaining the desired strong convexity over the entire
solution path. With these two important ingredients, APDPro exhibits an O 
(∥x0−x∗∥+DY)/√ε
complexity bound to obtain an ε-error on the function value gap and constraint violation, where DY
is a known upper-bound of ∥y0−y∗∥. Moreover, we show that for the last iterate to have an εerror
(i.e.,∥xK−x∗∥2≤ε), APDPro requires a total iteration of O 
(∥x0−x∗∥+∥y0−y∗∥)/√ε
.
Both complexity results appear new in the literature for strongly convex-constrained optimization.
Second, we present a new restart algorithm (rAPDPro) which calls APDPro repeatedly with the input
parameters properly changing over time. Different from APDPro, rAPDPro dynamically adjusts the
iteration number of APDPro in each epoch based on the progressive strong convexity estimation. We
show that rAPDPro exhibits a complexity of O 
log(DX/√ε) +DY/√ε
to ensure ε-error in the
last iterate convergence where DXis the estimated diameter of the primal feasible domain. While
it is difficult to improve the overall O(1/√ε)bound, rAPDPro appears to be more advantageous
when DXandDYare the same order of ∥x0−x∗∥and∥y0−y∗∥, respectively, and DX≫DY.
In addition, we show that a similar restart strategy can further accelerate the standard APD. The
multistage-accelerated primal dual method (msAPD) obtains a comparable O(1/√ε)complexity of
APDPro without introducing additional cut constraint.
Third, we apply our proposed methods to the sparse learning problem (3). In view of the theoretical
analysis, all our methods converge at an O(1/√ε)rate, which is substantially better than the rates of
state-of-the-art first-order algorithms. Moreover, we conduct a new analysis to show that the restart
algorithm rAPDPro has the favorable feature of identifying the optimal sparsity pattern. Note that
such active-set/manifold identification is substantially more challenging to prove due to the coupling
of dual variables and constraint functions. To establish the desired property, we develop asymptotic
convergence of the dual sequence to the optimal solution, which can be of independent interest.
Outline Section 2 sets notations and assumptions for the later analysis. Section 3 presents the
APDPro algorithm and develops its stepsize rule and complexity rate. Section 4 presents the
restart APDPro (rAPDPro) algorithm. Section 5 applies our proposed methods for sparsity-inducing
optimization and shows the sparsity identification result for rAPDPro. Section 6 empirically examine
the convergence performance and sparsity identification of our proposed algorithms. Finally, we draw
the conclusion in Section 7. All the missing proofs are provided in the appendix sections.
2 Preliminaries
We use bold letters like xto represent vectors. Suppose x∈Rn,q≥1, we use ∥x∥q=
(Pn
i=1|x(i)|q)1/qto represent the lq-norm, where x(i)is the i-th element of x. For brevity, ∥x∥stands
forl2-norm. For a matrix A, we denote the matrix norm induced by 2-norm as ∥A∥= sup∥x∥≤1∥Ax∥.
The normal cone of Uatuis denoted as NU(u) :={v| ⟨v,x−u⟩ ≤0,∀x∈ U} . LetB(x, r)be
the closed ball centered at xwith radius r >0, i.e.,B(x, r) ={y| ∥y−x∥ ≤r}. We denote the
set of feasible solutions by XG:={x|gi(x)≤0,∀i∈[m]}and write the constraint function as
G(x) := [ g1(x), . . . , g m(x)]⊤. We assume each gi(x)is aµistrongly convex function, and denote
µ:= [µ1, . . . , µ m]⊤. Let [m] :={1, . . . , m }for integer m. We denote minimum and maximum
strongly convexity µ:= min j∈[m]{µj}, and ¯µ:= max j∈[m]{µj}and the vector of elements 0 by 0.
The Lagrangian function of problem (1) is given by L(x,y) :=f(x) +⟨y, G(x)⟩where y∈Rm
+.
Definition 1 (KKT condition) .We say that x∗satisfies the KKT condition of(1)if there exists a
Lagrangian multiplier vector y∗∈Rm
+such that 0∈∂xL(x∗,y∗)and⟨y∗, G(x∗)⟩= 0.
The KKT condition is necessary for optimality when a constraint qualification (CQ) holds at x∗. We
assume Slater’s CQ (Assumption 1) holds, which guarantees that an optimal solution is also a KKT
point [3].
Assumption 1. There exists a strictly feasible point ex∈Rnsuch that G(ex)<0.
3We use ˜xto denote a strictly feasible point throughout the paper. Moreover, we require Assumption 2
to circumvent any trivial solution.
Assumption 2. For any x∗
0∈argminx∈Rnf(x), there exists an i∈[m]such that gi(x∗
0)>0.
Remark 1. Assumption 2 is essential for our analysis. While verifying Assumption 2 can be indeed
challenging, it is achievable for the sparsity-inducing problem considered in our paper. In this
example, the solution x∗
0=0is the single minimizer of the sparsity penalty.
Next, we give several useful properties about the optimal solutions of problem (1). Please refer to
Appendix D.1 for the proof of Proposition 1 and Appendix D.2 for the proof of Proposition 2.
Proposition 1. Suppose Assumption 1 holds. Then, for any optimal solution x∗of problem (1), there
exists y∗∈Rmsuch that KKT condition holds. Moreover, y∗falls into set Y:=
y| ∥y∥1≤¯c	
,
where ¯c:=f(ex)−minx∈Rnf(x)
mini∈[m]{−gi(ex)}.
Proposition 2. Under Assumption 2, x∗is the unique solution of (1). Furthermore, set Y∗=
argmaxy∈Rm
+L(x∗,y)is convex and bounded.
In view of Assumption 2, Proposition 2, and closedness of the subdifferential set of proper con-
vex functions [ 2, Theorem 3.9], [ 27, Chapter 23], we know that dist(∂f(x∗),0)>0,where
dist(∂f(x∗),0) := min ξ∈∂f(x∗)∥ξ∥. Furthermore, we make the following assumption:
Assumption 3. Throughout the paper, suppose that a constant rsatisfying
dist(∂f(x∗),0)≥r >0, (4)
is known.
We give some important examples for which the lower bound rcan be estimated. Suppose f(x)is
a Lasso regularizer, i.e., f(x) =∥x∥1, then r= 1satisfies (4). More general, consider the group
Lasso regularizer, i.e., f(x) =PB
i=1pi∥x(i)∥, where x(i)∈RbiandPB
i=1bi=n,Bis the number
of blocks, then r= min i∈[B]{pi}when x∗̸=0. Another example is f(x) =c⊤x, then we have
r=∥c∥.
Remark 2. Condition (4)is similar to the bounded gradient assumption that has been used for
accelerating the convergence of the Frank-Wolfe algorithm. See Appendix B for more discussions.
When considering the Lipschitz continuity of function in Rn, even quadratic functions are not
Lipschitz continuous. However, the Lipschitz continuity of gi(x)is crucial for algorithm convergence.
Therefore, we define the bounded feasible region in the following proposition, with its proof provided
in Appendix D.3.
Proposition 3. LetX:=B ex,mini∈[m]2q
−2gi(x∗
i)
µi
, where x∗
i= argminx∈Rngi(x). Then under
Assumptions 1 and 2, we have x∗∈intX.
Assumption 4. There exist LX, LG>0such that
∥∇G(x)− ∇G(¯x)∥ ≤LX∥x−¯x∥,∀x,¯x∈ X, (5)
∥G(x)−G(¯x)∥ ≤LG∥x−¯x∥,∀x,¯x∈ X, (6)
where ∇G(x) := [∇g1(x),···,∇gm(x)]∈Rn×mandXis defined in Proposition 3.
The Lipschitz smoothness of the Lagrangian function with respect to the primal variable xis crucial for
the convergence of algorithms. Given that the dual variable yis bounded from above, and considering
the smoothness of the constraint functions, we can derive the smoothness of the Lagrangian function.
Combining (5) and the fact ∥y∥ ≤ ∥y∥1≤¯c,∀y∈ Y, we obtain that
∥∇G(x)y− ∇G(¯x)y∥ ≤LXY∥x−¯x∥ ∀x,¯x∈ X,∀y∈ Y, (7)
where LXY= ¯cLX. For set X,Y, we use DXandDYto denote their diameters, respectively, i.e.,
DX:= max x1,x2∈X∥x1−x2∥andDY:= max y1,y2∈Y∥y1−y2∥.
4Algorithm 1 Accelerated Primal- Dual Algorithm with Progressive St rong Convexity Estimation
(APDPro)
Require: τ0>0, σ0>0,x0∈ X,y0∈ Y, ρ0≥0, N > 0
1:Initialize: (x−1,y−1)←(x0,y0),¯x0←x0,σ−1←σ0, T0= 0
2:Set∆XY=1
2τ0D2
X+1
2σ0D2
Y
3:fork= 0,1, . . . , N do
4: Yk←
y∈Rm
+| ∥y∥1·µ≥ρk	TY,
5: zk←(1 +σk−1/σk)G(xk)−(σk−1/σk)G(xk−1)
6: yk+1←argminy∈Yk∥y−(yk+σkzk)∥2
7: xk+1←proxf,X(xk−τk∇G(xk)yk+1, τk)
8: Compute tk,¯xk+1←(Tk¯xk+tkxk+1)/(Tk+tk),Tk+1←Tk+tk
9: Update ρk+1←IMPROVE (xk,¯xk,σ0τk−1∆XY
σk−1,∆XY
Tk,ρk)
10: Update τk+1andσk+1depending on ρk+1
11:end for
12:Output: xN+1,yN+1
13:procedure IMPROVE (x,¯x,β,¯β,ρold)
14: Compute ρ=µ·max
r
∥∇G(x)∥+LX√2β−1,h
LX
rq¯β
2µ+r
L2
X¯β
2µr2+∥∇G(¯x)∥
ri−2
15: Setρnew= max {ρold, ρ}
16: return ρnew
17:end procedure
3 APD with progressive strong convexity estimation
We present the Accelerated Primal-Dual Algorithm with Progressive Strong Convexity Estimation
(APDPro) to solve problem (1). For problem (1), APDPro achieves the improved convergence rate
O(1/√ε)without relying on the uniform strong convexity assumption [ 11,22]. For the rest of this
paper, we denote proxf,X(x−ηz, η) := argminˆx∈Xf(ˆx) +⟨z,ˆx⟩+1
2η∥ˆx−x∥2as the proximal
mapping.
We describe APDPro in Algorithm 1. The main component of APDPro contains a dual ascent step
to update ykbased on the extrapolated gradient, followed by a primal proximal step to update xk.
Compared with standard APD [ 11], APDPro has two more steps. First, line 4 of Algorithm 1 applies
a novel cut constraint to separate the dual sequence {yk}from the origin, which allows us to leverage
the strong convexity of the Lagrangian function and hence obtain a faster rate of convergence than
APD. Second, to use the strong convexity more effectively, in line 9, we perform a progressive
estimation of the strong convexity by using the latest iterates xkand¯xk. Throughout the algorithm
process, we use a routine IMPROVE to construct a non-decreasing sequence {ρk}, which provides
increasingly refined lower bounds of the strong convexity of the Lagrangian function.
The IMPROVE step In order to estimate the strong convexity of the Lagrangian function, we
rely on the subdifferential separation (eq. (4)) to bound the dual variables. From the first-order
optimality condition in minimizing L(x,y∗)and the fact that x∗∈intX(Proposition 3), we have
0∈∂f(x∗) +∇G(x∗)y∗+NX(x∗) =∂f(x∗) +∇G(x∗)y∗.It follows from (4) that
r≤ ∥∇ G(x∗)y∗∥ ≤ ∥∇ G(x∗)∥ · ∥y∗∥ ≤ ∥y∗∥1∥∇G(x∗)∥, (8)
where the last inequality use the fact that ∥ · ∥ ≤ ∥ · ∥ 1. Note that the bound ∥y∗∥1≥r/∥∇G(x∗)∥
can not be readily used in the algorithm implementation because x∗is generally unknown. To resolve
this issue, we develop more concrete dual lower bounds by using the generated solution ˆxin the
proximity of x∗. As we will show in the analysis, APDPro keeps track of two primal sequences
{xk}and{¯xk}, for which we can establish bounds on ∥xk−x∗∥2and(y∗)⊤µ· ∥ˆx−x∗∥2/2,
respectively. This drives us to develop the following lower bound property, with the proof provided
in Appendix E.1.
Proposition 4. Suppose Assumption 4 holds. Let y∗∈ Y∗be a dual optimal solution.
1. Suppose that ∥ˆx−x∗∥2≤2β, then we have
∥y∗∥1≥h1(ˆx, β) :=r
∥∇G(ˆx)∥+LXp
2β−1. (9)
52. Suppose (y∗)⊤µ· ∥ˆx−x∗∥2≤2β, then we have
∥y∗∥1≥h2(ˆx, β) :=
LX
rq
β
2µ+r
L2
Xβ
2µr2+∥∇G(ˆx)∥
r−2
. (10)
Our next goal is to conduct the convergence analysis for APDPro in Theorem 1 and Corollary 1.
Complete proof details are provided in Appendix E.2 and E.3.
Theorem 1. Suppose for any y∗∈ Y∗,(y∗)⊤µ≥ρ0holds, and let the sequence {τk, σk, tk, ρk+1}
generated by Algorithm 1 satisfy:
tk+1(τ−1
k+1−ρk+1)≤tkτ−1
k, t k+1σ−1
k+1≤tkσ−1
k, L XY+L2
Gσk≤τ−1
k. (11)
Then, the set Ykis nonempty and Y∗⊆ Yk. Let∆(x,y) :=1
2τ0∥x−x0∥2+1
2σ0∥y−y0∥2,¯yK=
T−1
KPK−1
s=0tsys. The sequence {¯xk,xk,¯yk}generated by APDPro satisfies
tK−1τ−1
K−1
2TK∥x∗−xK∥2+L(¯xK,y∗)− L(x∗,¯yK)≤1
TK∆(x∗,y∗). (12)
Next, we develop more concrete complexity results in Corollary 1.
Corollary 1. Suppose that σk, τk, tksatisfy:
τ−1
0≥LXY+L2
Gσ0, tk=σk/σ0,
τk+1=τk/p
1 +ρk+1τk, σk+1=σkτk/τk+1(13)
Then we have
f(¯xK)−f(x∗)≤6
6+τ0˜ρK(K+1)K
1
2τ0∥x0−x∗∥2+D2
Y
2σ0
,
∥[G(¯xK)]+∥ ≤6
c∗(6+τ0˜ρK(K+1)K)
1
2τ0∥x0−x∗∥2+D2
Y
2σ0
,
1
2∥xK−x∗∥2≤3σ0
ˆρ2
Kτ2
0K2+9(σ0/τ0)∆(x∗,y∗).(14)
where c∗:= 
f(x∗)−minxf(x)
/mini∈[m]{−gi(ex)}>0,˜ρk= 2Pk
s=0ˆρss/ 
k(k+ 1)
and˜ρk
satisfy the following condition, ˆρk+1:=p
ˆρ2
kk2+ (3ρk+1ˆρk)k/(k+ 1),ˆρ1= 3p
ρ1/τ0.
Remark 3. In view of Corollary 1, APDPro obtains an iteration complexity of O(1/√˜ρKε), which
is substantially better than the O(1/ε)bound of APD [ 11] and ConEx [ 4] when the strong convexity
parameter ˜ρKis relatively large compared with ε.
Remark 4. Additionally, we argue that even when ˜ρK=O(ε),APDPro can obtain the
matching O(1/ε)bound of the state-of-the-art algorithms. Specifically, using the definition of
σk, τk, we can easily derive the monotonicity of {σk}. It follows from σk+1=τkσk/τk+1=
τkσk/ 
τk/√1 +ρk+1τk
≥σk,thatTk=Pk−1
s=0tk=σ−1
0Pk−1
s=0σk≥k. Using a sim-
ilar argument to that of Corollary 1, we obtain the bound f(¯xK)−f(x∗)≤ O (1/K)and
∥[G(¯xK)]+∥ ≤ O (1/K).
Remark 5. The implementation of APDPro requires knowing an upper bound on ∥y∗∥. When the
bound is unavailable, [ 11] developed an adaptive APD which still ensures the boundedness of dual
sequence via line search. Since our main goal of this paper is to exploit the lower-bound rather than
theupper bound of∥y∗∥, we leave the extension for the future work.
4 APDPro with a restart scheme
Note that in the worst case, APDPro exhibits an iteration complexity of O 
(DX+DY)/√ε
, which
has a linear dependence on the diameter. While the O(1/√ε)is optimal [ 25], it is possible to improve
the complexity with respect to the primal part from O 
DX/√ε
toO 
log 
DX/√ε
. To achieve
this goal, we propose a restart scheme (rAPDPro) that calls APDPro repeatedly and present the
details in Algorithm 2. Inspired by [ 16], we set the iteration number as a function of the estimated
strong convexity, detailed in the TERMINATE ITER procedure. For convenience in describing a
double-loop algorithm, we use superscripts for the number of epochs and subscripts for the number of
6Algorithm 2 Restarted APDPro (rAPDPro)
Require: ρ−1
N−1≥0,¯σ >0,ν0∈(0,1),δ∈(0,1),x−1
N−1,y−1
N−1, S
1:Compute ¯τ= (1−ν0) 
LXY+L2
G¯σ/δ−1
2:fors= 0,1, . . . , S do
3: τs
0= ¯τ, σs
0= ¯σ,(xs
−1,ys
−1)←(xs−1
Ns−1,ys−1
Ns−1),(xs
0,ys
0)←(xs−1
Ns−1,ys−1
Ns−1), ρs
0=ρs−1
Ns−1
4: Set∆XY=1
τs
0D2
X+1
2σs
0D2
Y, σs
−1←σs
0, Ts
0= 0, k= 0,ˆρs
0= 1, Ns=∞
5: while k < N sdo
6: Run line 4-10 of APDPro with index set (s, k)
7: Update Ns,ˆρs
k+1←TERMINATE ITER(ˆρs
k, ρs
k+1, s, k ),k←k+ 1
8: end while
9:end for
10:Output: xS
NS,yS
NS11:procedure TERMINATE ITER(ˆρold, ρ, s, k )
12: Compute ˆρnew=(
1
k+1p
ˆρ2
oldk2+ 3ρˆρoldk k > 1
3p
ρ/τ0 k= 1
13: Compute N=⌈max{6(ˆρnewτs
0)−1,√
2s·3√
2DY/ 
ˆρnewDXpτs
0σs
0
}⌉
14: return N,ˆρnew
15:end procedure
sub-iterations in parameters x,y, τ, σ , e.g., xS
1meaning the xoutput of first iterations at S-th epoch.
To avoid redundancy in the Algorithm 2, we call the APDPro iteration directly. Note that the notation
system here is identical to that of APDPro, with the only difference being the use of superscripts to
distinguish the number of epochs.
In Theorem 2, we show the overall convergence complexity of rAPDPro with the proof provided in
Appendix F.1.
Theorem 2. Let{xs
0}s≥0be the sequence generated by rAPDPro , then we have
∥xs
0−x∗∥2≤∆s≡D2
X·2−s,∀s≥0. (15)
As a consequence, rAPDPro will find a solution xS
0such that ∥xS
0−x∗∥2≤εfor any ε∈(0, D2
X)
in at most S:=
log2(D2
X/ε)
epochs. Moreover, The iteration number of rAPDPro to find xS
0such
that∥xS
0−x∗∥2≤εis bounded by
Tε:= 12
ϖ1τs
0+ 2l
log2DX√ε+ 1m
+ 6(√
2+2)
ϖ2√
τs
0σs
0
· DY√ε
, (16)
where ϖ1and ϖ2satisfyPS
s=0(ˆρs
Ns)−1= ( ϖ1)−1(S+ 1) andPS
s=0√
2s/ˆρs
Ns=
(ϖ2)−1PS
s=0√
2s, respectively.
Remark 6. The bound Tεdepends on ε,ϖ1andϖ2. Ifϖ1=O 
(−log2√ε)−1
orϖ2=O(√ε),
then we have Tε=∞, which implies that we can not guarantee ∥xs
0−x∗∥ ≤εat finite iterations.
Tε=∞implies that there exists an epoch with infinite sub-iterations. Hence, rAPDPro is reduced to
APDPro if we only consider that epoch.
Remark 7. Comparison of rAPDPro and APDPro involves a number of factors. In particular,
rAPDPro compares favorably against APDPro if∥x0−x∗∥=eΩ(√εlogDX). Moreover, the
complexity (16) can be slightly improved if DXis replaced by any tighter upper bound of ∥xs
0−x∗∥.
However, it is still unknown whether we can directly replace DXwith∥xs
0−x∗∥in(16).
Dual Convergence For dual variables, we establish asymptotic convergence to the optimal solution,
a key condition for developing the active-set identification in the later section. For ease in notation, it
is more convenient to label the generated solution as a whole sequence using a single subscript index:
x1,x2, . . . ,xN;y1,y2, . . . ,yN. Hence, we use the index system jand(s, k)interchangeably. Note
that{xs+1
0,ys+1
0}and{xs
Ns+1,ys
Ns+1}correspond to the same pair of points. We present the dual
asymptotic result in the following theorem, with the proof provided in Appendix F.2.
Theorem 3. Assume ¯τ−1>ρand choose ν0>0such that 1>infj≥0{σj−1/σj} ≥δ+ν0.We
have(x∗,y∗)satisfy the KKT condition, where y∗is any limit point of {yj}generated by rAPDPro .
7Remark 8. To establish the asymptotic convergence of the dual variable, we introduce an addi-
tional constant δ∈(0,1), which implies that the initial step size must meet a stricter requirement
than the convergence condition specified in Corollary 1. Since σs
k/σs
k−1=p1 +ρs
kτs
k,{ρs
k}
is bounded due to the boundedness of the dual variable, {τs
k}is monotonically decreasing, then
inf0≤k≤Ns{σs
k−1/σs
k} ≥(1 +ρ¯τ)−1/2. Hence, inequality, 1>infj≥0{σj−1/σj} ≥δ+ν0, is al-
ways satisfiable if we choose proper δ, ν0such that (1+ρ¯τ)−1/2≥δ+ν0. Furthermore, Assumption
(¯τ)−1>ρis mild. Since we always choose ¯σlarge enough in rAPDPro ,¯τcan be sufficiently small.
Remark 9. Both algorithms proposed previously require solving quadratic optimization with linear
constraints when updating dual variables, which may introduce implementation overheads when
the constraint number is high. Inspired by the multi-stage algorithm, we additionally propose an
algorithm (Multi-Stage APD, msAPD) that uses different step sizes in different stages and dynam-
ically adjusts the number of iterations in each stage by leveraging strong convexity, as detailed in
Appendix H.
5 Active-set identification in sparsity-inducing optimization
In this section, we apply our proposed algorithms to the aforementioned sparse learning problem:
minf(x),s.t.g(x)≤0,x=x(1)×. . .×x(B),x(i)∈Rni,1≤i≤B, (17)
where f(x) =PB
i=1pi∥x(i)∥is the group Lasso regularizer and g(x)is a strongly convex function.
We use x(i)to express the i-th block coordinates of x. The goal of this section is to show that rAPDPro
can identify the sparsity pattern of the optimal solution of (17) in a finite number of iterations.
In general, suppose that f(x)has a separable structure f(x) =PB
i=1fi(x(i)), we define the active
setA(x)forf(x)byA(x) :={i:∂fi(x(i))is not a singleton }.Forf(x) =PB
i=1pi∥x(i)∥, it
is easy to see that A(x)is the index set of the zero blocks: A(x∗) =
i:x∗
(i)=0	
. Next, we
describe one property for the optimal solution of (17) in Proposition 5 with the proof provided in
Appendix G.1.
Proposition 5. Under Assumptions 1 and 2, the KKT point for (17) is unique.
To identify the sparsity pattern (active set) of the optimal solution, it is common to assume the
existence of a non-degenerate optimal solution, which is stronger than the standard optimality
condition [ 24,29]. We say that x∗is non-degenerate if 0∈ri∂L(x∗,y∗) =ri(∂f(x∗)+∇g(x∗)y∗)
for the Lagrangian multiplier y∗, where ristands for the relative interior. More specifically, (x∗,y∗)
satisfies the block-wise optimality condition
(
−[∇g(x∗)y∗](i)=∇fi(x∗
(i)), ifi /∈ A(x∗),
−[∇g(x∗)y∗](i)∈int 
∂fi(x∗
(i))
,ifi∈ A(x∗).
Inspired by [ 24], we use the radius η:= min i∈A(x∗)
pi− ∥[∇g(x∗)y∗](i)∥	
, which describes the
certain distance between the gradient and "subdifferential boundary" of the active set. We demonstrate
in the following theorem that the optimal sparsity pattern is identified when the iterates fall in a
neighborhood dependent on η, with the proof provided in Appendix G.2.
Theorem 4. SetX:=B
˜x,mini∈[m]2q
−2gi(x∗
i)
µi+ζ
withζ >0and3LXY·(¯τ+(2LXY)−1)·ζ >
η¯τinrAPDPro , then we have there exists a epoch ˆS0such that x∗
(i)=xs
k(i), s≥ˆS0,∀k∈[Ns],∀i∈
A(x∗).
Remark 10. The active-set identification result is achieved using the optimality condition at the next
iterate xk+1
i. To ensure xk+1
i∈intX, we define an expanded region, which prevents cases where
the normal cone differs from {0}.
6 Numerical study
In this section, we examine the empirical performance of our proposed algorithms for solving the
sparse Personalized PageRank [ 8,9,23]. The constrained form of Personalized PageRank can be
80 1 2 3 4 5
1e41010
108
106
104
102
100
APD
Mirror-Prox
rAPDPro
msAPD
APD+restart
0 1 2 3 4 5
1e3109
107
105
103
101
APD
Mirror-Prox
rAPDPro
msAPD
APD+restart
0.0 0.5 1.0 1.5 2.0
1e5106
104
102
100
APD
Mirror-Prox
rAPDPro
msAPD
APD+restart
0 1 2 3 4 5
1e41010
108
106
104
102
APD
Mirror-Prox
rAPDPro
msAPD
APD+restart
0 1 2 3 4 5
1e31011
109
107
105
103
101
APD
Mirror-Prox
rAPDPro
msAPD
APD+restart
0.0 0.5 1.0 1.5 2.0
1e51011
109
107
105
103
APD
Mirror-Prox
rAPDPro
msAPD
APD+restartFigure 1: The first row describes the convergence to optimum, where the y-axis re-
ports log10((∥D1/2xk∥1− ∥D1/2x∗∥1)/∥D1/2x∗∥1)for rAPDPro, and log10((∥D1/2¯xk∥1−
∥D1/2x∗∥1)/∥D1/2x∗∥1)for APD, APD+restart, msAPD and Mirror-Prox ( x∗is computed by
MOSEK [ 1]). The second row describes feasibility violation, where y-axis reports the feasibility gap
log10(max{0, G(xk)})for rAPDPro, and log10(max{0, G(¯xk)})for APD, msAPD and Mirror-Prox.
Datasets (Left-Right order) correspond to bio-CE-HT, bio-CE-LC and econ-beaflw.
written as follows: minx∈Rn∥D1/2x∥1s.t.1
2⟨x, Qx⟩ −α⟨s, D−1/2x⟩ ≤b,where Q, D and
sare generated by graph. We implement both rAPDPro and msAPD. We skip APDPro as we
observe that the restart strategy consistently improves the algorithm performance. For comparison,
we consider the state-of-the-art accelerated primal-dual (APD) method [ 11], APD with restart
mechanism at fixed iterations (APD+restart) and Mirror-Prox [ 13]. 6 small to medium-scale datasets
from various domains in the Network Datasets [ 28] are selected in our experiments. All experiments
are implemented on Mac mini M2 Pro, 32GB. Due to the page limit, we only report results on three
datasets and leave more details in the last Appendix I.
We plot the relative function value gap |f(x)−f(x∗)|/|f(x∗)|and the feasibility violation
max{G(x),0}over the iteration number in Figure 1, respectively. Firstly, in terms of both op-
timality gap and constraint violation, the performance of rAPDPro and msAPD is significantly better
than that of APD, APD+restart and Mirror-Prox. Additionally, rAPDPro and msAPD often converge
to high-precision solutions. Secondly, based on the experimental results, it is indeed observed that
msAPD exhibits a periodic variation in convergence performance, which aligns with our algorithm
theory.
0 1 2 3 4 5
1e40.60.70.80.91.0
APD
Mirror-Prox
rAPDPro
msAPD
APD+restart
0 1 2 3 4 5
1e30.8750.9000.9250.9500.9751.000
APD
Mirror-Prox
rAPDPro
msAPD
apd+restart
0.0 0.5 1.0 1.5 2.0
1e50.60.70.80.9
APD
Mirror-Prox
rAPDPro
msAPD
APD+restart
Figure 2: The experimental results on active-set identification. Datasets (Left-Right order) correspond
to bio-CE-HT, bio-CE-LC and econ-beaflw. The x-axis reports the iteration number and the y-axis
reports accuracy in active-set identification.
Next, we examine the algorithm’s effectiveness in identifying sparsity patterns. We computed a nearly
optimal solution x∗from MOSEK. Note that x∗is a dense vector. For numerical consideration, we
truncate the coordinate values of x∗to zero if the absolute value is below 10−8and perform the
same truncation to all the generated solutions of the compared algorithms. Then we use (|A(x)∩
9A(x∗)|+|Ac(x)∩ Ac(x∗)|)/nto measure the accuracy of identifying the active set, where | · |
denotes the set cardinality. For rAPDPro, we consider the last iterate xkwhile for APD, msAPD
and Mirror-Prox, we plot the result on ¯xk, as these are the solutions where the convergence rates are
established. Figure 2 plots the experiment result, from which we observe that rAPDPro and msAPD
are highly effective in identifying the active set. Often, they are able to recognize the structure of
the active set within a small number of iterations. Overall, the experimental results show the great
potential of our proposed algorithms in identifying the sparsity structure and are consistent with our
theoretical analysis.
7 Conclusion
The key contribution of this paper is that we develop several new first-order primal-dual algorithms
for convex optimization with strongly convex constraints. Using some novel strategies to exploit the
strong convexity of the Lagrangian function, we substantially improve the best convergence rate from
O(1/ε)toO(1/√ε). In the application of constrained sparse learning problems, the experimental
study confirms the advantage of our proposed algorithms against state-of-the-art first-order methods
for constrained optimization. Moreover, we show that one of our proposed algorithms rAPDPro has
the favorable feature of identifying the sparsity pattern in the optimal solution. For future work, one
direction is to apply the adaptive strategy, such as line search, to our framework to deal with cases
when the dual bound is unavailable. Another interesting direction is to further exploit the active set
identification property in a general setting. For example, it would be interesting to incorporate our
algorithm with active constraint identification, which could be highly desirable when there are a large
number of constraints. It would also be interesting to consider a more general convex objective when
the proximal operator is not easy to compute.
Acknowledgement
This research is partially supported by the Major Program of National Natural Science Founda-
tion of China (Grant 72394360, 72394364), Natural Science Foundation of Shanghai (Grant No.
24ZR1421300). We sincerely thank all the reviewers for their valuable suggestions, which have
significantly improved the quality of our article.
References
[1]Mosek ApS. Mosek optimization toolbox for matlab. User’s Guide and Reference Manual,
Version , 4(1), 2019.
[2] Amir Beck. First-order methods in optimization . SIAM, 2017.
[3] Dimitri P. Bertsekas. Nonlinear programming . Athena Scientific, 1999.
[4]Digvijay Boob, Qi Deng, and Guanghui Lan. Stochastic first-order methods for convex and
nonconvex functional constrained optimization. Mathematical Programming , pages 1–65, 2022.
[5]Gábor Braun, Alejandro Carderera, Cyrille W Combettes, Hamed Hassani, Amin Karbasi,
Aryan Mokhtari, and Sebastian Pokutta. Conditional gradient methods. arXiv preprint
arXiv:2211.14103 , 2022.
[6]Antonin Chambolle and Thomas Pock. On the ergodic convergence rates of a first-order
primal–dual algorithm. Mathematical Programming , 159(1):253–287, 2016.
[7]Joseph C Dunn. Rates of convergence for conditional gradient algorithms near singular and
nonsingular extremals. SIAM Journal on Control and Optimization , 17(2):187–211, 1979.
[8]Kimon Fountoulakis, Farbod Roosta-Khorasani, Julian Shun, Xiang Cheng, and Michael W
Mahoney. Variational perspective on local graph clustering. Mathematical Programming ,
174:553–573, 2019.
10[9]Kimon Fountoulakis and Shenghao Yang. Open problem: Running time complexity of acceler-
atedℓ1-regularized pagerank. In Conference on Learning Theory , pages 5630–5632. PMLR,
2022.
[10] Dan Garber and Elad Hazan. Faster rates for the frank-wolfe method over strongly-convex sets.
InInternational Conference on Machine Learning , pages 541–549. PMLR, 2015.
[11] Erfan Yazdandoost Hamedani and Necdet Serhat Aybat. A primal-dual algorithm with line
search for general convex-concave saddle point problems. SIAM Journal on Optimization ,
31(2):1299–1329, 2021.
[12] Warren L Hare and Adrian S Lewis. Identifying active constraints via partial smoothness and
prox-regularity. Journal of Convex Analysis , 11(2):251–266, 2004.
[13] Niao He, Anatoli Juditsky, and Arkadi Nemirovski. Mirror prox algorithm for multi-term
composite minimization and semi-separable problems. Computational Optimization and Appli-
cations , 61(2):275–319, 2015.
[14] Franck Iutzeler and Jérôme Malick. Nonsmoothness in machine learning: specific structure,
proximal identification, and applications. Set-Valued and Variational Analysis , 28(4):661–678,
2020.
[15] Michel Journée, Yurii Nesterov, Peter Richtárik, and Rodolphe Sepulchre. Generalized power
method for sparse principal component analysis. Journal of Machine Learning Research , 11(2),
2010.
[16] Guanghui Lan. First-order and stochastic optimization methods for machine learning . Springer,
2020.
[17] Guanghui Lan and Renato DC Monteiro. Iteration-complexity of first-order penalty methods
for convex programming. Mathematical Programming , 138(1):115–139, 2013.
[18] Guanghui Lan and Renato DC Monteiro. Iteration-complexity of first-order augmented la-
grangian methods for convex programming. Mathematical Programming , 155(1):511–547,
2016.
[19] Sangkyun Lee, Stephen J Wright, and Léon Bottou. Manifold identification in dual averaging
for regularized stochastic online learning. Journal of Machine Learning Research , 13(6), 2012.
[20] Evgeny S Levitin and Boris T Polyak. Constrained minimization methods. USSR Computational
mathematics and mathematical physics , 6(5):1–50, 1966.
[21] Qihang Lin, Selvaprabu Nadarajah, and Negar Soheili. A level-set method for convex op-
timization with a feasible solution path. SIAM Journal on Optimization , 28(4):3290–3311,
2018.
[22] Tianyi Lin, Chi Jin, and Michael I Jordan. Near-optimal algorithms for minimax optimization.
InConference on Learning Theory , pages 2738–2779. PMLR, 2020.
[23] David Martínez-Rubio, Elias Wirth, and Sebastian Pokutta. Accelerated and sparse algorithms
for approximate personalized pagerank and beyond. arXiv preprint arXiv:2303.12875 , 2023.
[24] Julie Nutini, Mark Schmidt, and Warren Hare. “active-set complexity” of proximal gradient:
How long does it take to find the sparsity pattern? Optimization Letters , 13(4):645–655, 2019.
[25] Yuyuan Ouyang and Yangyang Xu. Lower complexity bounds of first-order methods for
convex-concave bilinear saddle-point problems. Mathematical Programming , 185(1):1–35,
2021.
[26] H. Robbins and D. Siegmund. A convergence theorem for non negative almost supermartingales
and some applications. In Jagdish S. Rustagi, editor, Optimizing Methods in Statistics , pages
233–257. Academic Press, 1971.
[27] R Tyrrell Rockafellar. Convex analysis , volume 18. Princeton university press, 1970.
11[28] Ryan A. Rossi and Nesreen K. Ahmed. The network data repository with interactive graph
analytics and visualization. In AAAI , 2015.
[29] Yifan Sun, Halyun Jeong, Julie Nutini, and Mark Schmidt. Are we there yet? manifold
identification of gradient-related proximal methods. In The 22nd International Conference on
Artificial Intelligence and Statistics , pages 1110–1119. PMLR, 2019.
[30] Robert Tibshirani. Regression shrinkage and selection via the lasso. Journal of the Royal
Statistical Society: Series B (Methodological) , 58(1):267–288, 1996.
[31] Stephen J Wright. Identifiable surfaces in constrained optimization. SIAM Journal on Control
and Optimization , 31(4):1063–1079, 1993.
[32] Yangyang Xu. First-order methods for constrained convex programming based on linearized
augmented lagrangian function. Informs Journal on Optimization , 3(1):89–117, 2021.
[33] Yangyang Xu. Iteration complexity of inexact augmented lagrangian methods for constrained
convex programming. Mathematical Programming , 185(1):199–244, 2021.
[34] Liwei Zhang, Yule Zhang, Jia Wu, and Xiantao Xiao. Solving stochastic optimization with
expectation constraints efficiently by a stochastic augmented lagrangian-type algorithm. IN-
FORMS Journal on Computing , 34(6):2989–3006, 2022.
12Appendix
A Limitations 14
B Comparison with Frank-Wolfe 14
C Auxiliary lemmas 14
D Proof details in Section 2 15
D.1 Proof of Proposition 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15
D.2 Proof of Proposition 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15
D.3 Proof of Proposition 3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15
E Convergence analysis of APDPro 16
E.1 Proof of Proposition 4 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16
E.2 Proof of Theorem 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16
E.3 Proof of Corollary 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19
F Convergence analysis of rAPDPro 20
F.1 Proof of Theorem 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20
F.2 Proof of Theorem 3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22
G Proof details for sparsity identification 23
G.1 Proof of Proposition 5 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24
G.2 Proof of Theorem 4 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24
H A multi-stage accelerated primal-dual algorithm 25
I Experiment details 27
Structure of the Appendix
The appendix is structured as follows: Appendix A introduces some limitations of our methods,
primarily concerning the application scenarios of our algorithm. Appendix B includes comparisons
between ours and some related Frank-Wolfe methods. We give some auxiliary lemmas in Appendix C,
which are very important for the proofs presented later. Appendix D, E, F and G present the proof
of conclusion in Section 2, 3, 4 and 5, respectively. Furthermore, Appendix H introduces a new
algorithm to obtain a convergence rate without complicated dual updating. Finally, Appendix I offers
more extensive details on our experiments.
13A Limitations
In this paper, we focus on the theoretical analysis of convex optimization. Although our proposed
algorithms for the convex optimization with strongly convex constraints can theoretically improve the
existing results from O(1/ε)toO(1/√ε). However, we still need to point out that our optimization
algorithm has the following limitations. One is the algorithm needs a lower bound on the norm
of sub-gradients of the objective function in the optimal solution, which may not be satisfied for
all functions. On the other hand, we require consistent smoothness of the constraints to ensure
convergence, and how to use the line search method to ensure convergence is a future direction.
B Comparison with Frank-Wolfe
We note that the strongly convex function constraint in (1)is a special case of a strongly convex set
constraint, as demonstrated in [ 15]. Over the strongly convex set, it has been shown that Frank-Wolfe
Algorithm (FW) can obtain convergence rates substantially better than the worst-case O(1/ε)rate.
Under the bounded gradient assumption, [ 7,20] show that FW obtains linear convergence over a
strongly convex set. Nevertheless, the uniform bounded gradient assumption appears to be stronger
than ours, as we only impose the lower boundedness assumption on the optimal solution x∗and allow
the objective to be non-differentiable. More recently, [ 10] shows that FW obtains an O(1/√ε)rate
when the gradient is the order of the square root of the function value gap. For more recent progress,
please refer to [ 5]. Despite the attractive convergence property, FW exhibits certain limitations when
applied to the general function constraints (1)addressed in this paper. Specifically, FW involves a
sequence of linear optimization problems throughout the iterations. While linear optimization over
certain strongly convex sets, such as ℓp-ball, admits a closed-form solution, there exists no efficient
routine to handle general function constraints explored in this paper.
C Auxiliary lemmas
The following three-point property is important in the convergence analysis.
Lemma 1. Letf:Rn→R∪{+∞}be a closed strongly convex function with modulus µ≥0. Give
¯x∈ X, where Xis a compact convex set and t≥0, letx+= argminx∈Xf(x) +t
2∥x−¯x∥2,then
for all x∈ X, we have
f(x) +t
2∥x−¯x∥2≥f(x+) +t+µ
2∥x+−x∥2+t
2∥x+−¯x∥2.
Proof. SinceXis a convex compact set, ϕ(x) :=IX(x)+f(x)+t
2∥x−¯x∥2is lower-semi-continuous
and(µ+t)-strongly convex, where IX(x) =0x∈ X
∞x/∈ X. Using the optimality ( 0∈ϕ(x+)) and
strong convexity, we have ϕ(x)≥ϕ(x+) +⟨0,x−x+⟩+t+µ
2∥x+−x∥2, for any x∈ X. This
immediately gives the desired relation.
The following result is adjusted from the classic supermartingale convergence theorem [ 26, Theorem
1]. We give proof for completeness.
Lemma 2. Let(Ω,F,P)be a probability space and F1⊂ F 2⊂ ··· be a sequence of sub- σ-algebras
ofF. For each j= 1,2,···, letaj, bjandcjbe non-negative Fn-measure random variables such
E[aj+1| Fj]≤aj−bj+cj, then we have limj→∞aj<∞exists andP∞
j=1bj<∞a.s. whenP∞
j=1cj<∞.
Proof. Define dj=aj−Pj−1
l=1(cl−bl)and for any ¯a >0, define t= inf{t:Pt
l=1cl>¯a}. If
j < t , we have
E[dj+1| Fj] =E[aj+1−Pj
l=1(cl−bl)| Fj](a)
≤aj−Pj−1
l=1(cl−bl) =:dj, (18)
where (a)holds by E[aj+1| Fj]≤aj+cj−bj, and hence
E[dmin{t,(j+1)}| Fj] =dtI{t≤j}+E[dj+1| Fj]I{t>j}(a)
≤dmin{t,j},
14where (a)holds by (18). Therefore, we have {dmin{t,(j+1)},Fj,1≤j≤ ∞} is a supermartingale.
Since
dmin{t,j}=amin{t,j}−Pmin{t,j}−1
l=1(cl−bl)(a)
≥ −Pmin{t,(j−1)}
l=1cl≥ −¯a,
holds for all j, where (a)holds by amin{t,j}, bl≥0. Then it follows from the martingale convergence
theorem that limj→∞dmin{t,j}exists and is finite a.s., i.e., limj→∞djexists and is finite on {t=
∞}={P∞
j=1cj≤¯a}. Since ¯ais arbitrary, we see that limj→∞djexists and is finite a.s. on
{P∞
j=1cj<∞}. By dj=aj−Pj−1
l=1(cl−bl), we have limj→∞ajexists and is finite andP∞
j=1bj<∞when{P∞
j=1cj<∞}.
D Proof details in Section 2
D.1 Proof of Proposition 1
Proof. Under Slater’s CQ, it is standard to show that any optimal solution x∗will also satisfy the
KKT condition. For example, one can refer to [3]. For any x∈ XG, we have
f(x) +⟨y∗, G(x)⟩ ≥f(x∗) +⟨y∗, G(x∗)⟩=f(x∗),
where the equality is from the complementary slackness. In view of the above result and the Slater’s
condition (i.e., G(˜x)<0), we have
f(˜x)> f(˜x) +⟨y∗, G(˜x)⟩ ≥f(x∗). (19)
Combining with fact ∥y∗∥1mini∈[m]
−gi(˜x)	
≤ −⟨y∗, G(˜x)⟩, then we have
∥y∗∥ ≤ ∥y∗∥1≤f(˜x)−f(x∗)
mini∈[m]{−gi(˜x)}= ¯c, (20)
where the last inequality is by f(x∗)≥minx∈Rnf(x).
D.2 Proof of Proposition 2
Proof. We prove the uniqueness property by contradiction. Suppose that there exist (x∗,y∗),(˜x∗,˜y∗)
satisfying the KKT condition, then from the complementary slackness, optimality of x∗and˜x∗, we
have
L(x∗,y∗) =f(x∗) =f(˜x∗) =L(˜x∗,˜y∗).
Moreover, we have L(˜x∗,˜y∗)≤ L(x∗,˜y∗)≤ L(x∗,y∗).Hence, we must have L(˜x∗,˜y∗) =
L(x∗,˜y∗). However, since Assumption 2 implies ˜y∗̸=0, the strongly convex function L(·,˜y∗)has
a unique optimizer. Therefore, we conclude that x∗=˜x∗.
Next, we show that the set of optimal dual variables for problem (1)is convex. Suppose that there
exist two optimal dual variables y∗
1andy∗
2for the unique primal variable x∗, both satisfying the KKT
condition, then we have ⟨y∗
1, G(x∗)⟩=⟨y∗
2, G(x∗)⟩= 0. This implies that any linear combination
ofy∗
1andy∗
2satisfy KKT condition, i.e., ⟨ay∗
1+by∗
2, G(x∗)⟩= 0,∀a, b. From Proposition 1, we
know any optimal dual variable falls into a bounded convex set Y. The intersection of two convex
sets is also a convex set. Hence, we complete our proof.
D.3 Proof of Proposition 3
Proof. From the strong convexity of gi(x), we have gi(x)≥gi(x∗
i) +µi
2∥x−x∗
i∥2,which implies
∥˜x−x∗
i∥2≤(gi(˜x)−gi(x∗
i))2
µi(a)
<−2gi(x∗
i)
µi,
∥x∗−x∗
i∥2≤(gi(x∗)−gi(x∗
i))2
µi≤−2gi(x∗
i)
µi,(21)
where (a)holds by gi(˜x)<0. In view of the triangle inequality and the above result, we have
∥˜x−x∗∥ ≤ ∥x∗
i−x∗∥+∥˜x−x∗
i∥<2q
−2gi(x∗
i)
µi.
Hence, x∗∈intB
˜x,mini∈[m]2q
−2gi(x∗
i)
µi
.
15E Convergence analysis of APDPro
E.1 Proof of Proposition 4
Proof. Using the triangle inequality and (5), we have
∥∇G(x∗)∥ − ∥∇ G(ˆx)∥ ≤ ∥∇ G(x∗)− ∇G(ˆx)∥ ≤LX∥ˆx−x∗∥.
Combining the above inequality and (8), we obtain
r
∥y∗∥1≤LX∥ˆx−x∗∥+∥∇G(ˆx)∥. (22)
Next, we develop more specific lower bounds on ∥y∥1. i). Inequality (9)can be easily verified since
we have ∥ˆx−x∗∥ ≤√2β. ii). Suppose (y∗)⊤µ· ∥ˆx−x∗∥2≤2β, then together with (22) we have
r
∥y∗∥1≤LXq
2β
(y∗)⊤µ+∥∇G(ˆx)∥ ≤LXq
2β
µ∥y∗∥1+∥∇G(ˆx)∥.
Note that the above inequality can be expressed as at2−bt−c≤0witht=∥y∗∥−1/2
1 ,a=r, b=
LXq
2β/µ andc=∥∇G(ˆx)∥. Standard analysis implies that t≤(b+√
b2+ 4ac)/2a, which gives
the desired bound (10).
E.2 Proof of Theorem 1
Proof. First, it is easy to verify by our construction that {Yk}is a monotone sequence: Y1⊇ Y 2⊇
. . .⊇ Yk. . .. Our goal is to show Y∗⊆ Ykholds for any k≥0by induction. Note that Y∗⊆ Y 0
immediately follows from our assumption that (y∗)⊤µ≥ρ0, for any y∗∈ Y∗. Suppose that
Y∗⊆ Ykholds for k= 0, . . . , K −1, we claim:
1. For any x∈ X andy∈ Y∗, we have
L(¯xK,y)− L(x,¯yK)≤1
TK∆(x,y)−tK−1τ−1
K−1
2TK∥x−xK∥2. (23)
2.Y∗⊆ YK.
Part 1. For k= 0,1,2, . . . , K −1, taking −⟨zk,·⟩andf(·) +⟨∇G(xk)yk+1,·⟩in Lemma 1, the
following relations
−⟨yk+1−y,zk⟩ ≤Ak+1, (24)
f(xk+1) +
yk+1,∇G(xk)⊤(xk+1−x)
≤f(x) +Bk+1, (25)
where
Ak+1≜1
2σk 
∥y−yk∥2− ∥y−yk+1∥2− ∥yk+1−yk∥2
, (26)
Bk+1≜1
2τk 
∥x−xk∥2− ∥x−xk+1∥2− ∥xk+1−xk∥2
, (27)
hold for any x∈ X andy∈T
0≤s≤kYs. The existence of such yfollows from our induction
hypothesis. Since y⊤
k+1G(·)isρk-strongly convex, we have

yk+1,∇G(xk)⊤(xk+1−x)
≥
yk+1,∇G(xk)⊤(xk+1−xk)
+⟨yk+1, G(xk+1)−G(x)⟩ − ⟨yk+1, G(xk+1)−G(xk)⟩+ρk
2∥x−xk∥2.
Combining this result and (25), we have
f(xk+1)−f(x) +⟨yk+1, G(xk+1)−G(x)⟩
≤Bk+1−
yk+1,∇G(xk)⊤(xk+1−xk)
+⟨yk+1, G(xk+1)−G(xk)⟩ −ρk
2∥x−xk∥2.(28)
On the other hand, by the definition of zk, we have
⟨y−yk+1,zk⟩
=⟨y−yk+1, G(xk)−G(xk+1)⟩+⟨y−yk+1, G(xk+1)⟩ (29)
+ (σk−1/σk)⟨y−yk, G(xk)−G(xk−1)⟩+ (σk−1/σk)⟨yk−yk+1, G(xk)−G(xk−1)⟩.
16Let us denote qk=G(xk)−G(xk−1)for brevity. Combining (24) and (29) yields
⟨y−yk+1, G(xk+1)⟩
≤Ak+1+⟨y−yk+1, G(xk+1)−G(xk)⟩ −(σk−1/σk)⟨y−yk,qk⟩ −(σk−1/σk)⟨yk−yk+1,qk⟩.
(30)
Putting (28) and (30) together, we have
L(xk+1,y)− L(x,yk+1)
≤Ak+1+Bk+1−
yk+1,∇G(xk)⊤(xk+1−xk)
+⟨yk+1, G(xk+1)−G(xk)⟩
+⟨y−yk+1,qk+1⟩ −(σk−1/σk)⟨y−yk,qk⟩+ (σk−1/σk)⟨yk+1−yk,qk⟩ −ρk
2∥x−xk∥2
≤Ak+1+Bk+1+LXY
2∥xk+1−xk∥2−ρk
2∥x−xk∥2
+⟨y−yk+1,qk+1⟩ −(σk−1/σk)⟨y−yk,qk⟩+ (σk−1/σk)⟨yk+1−yk,qk⟩,
where the last inequality is by Lipschitz smoothness of ⟨yk+1, G(·)⟩.
Next, we bound the term ⟨qk,yk+1−yk⟩by Young’s inequality, which gives
⟨yk+1−yk,qk⟩ ≤1
2σk−1∥yk+1−yk∥2+σk−1
2∥qk∥2, (31)
It follows from (31) andσk
2∥qk+1∥2≤L2
Gσk
2∥xk+1−xk∥2that
L(xk+1,y)− L(x,yk+1)
≤τ−1
k−ρk
2∥x−xk∥2−τ−1
k
2∥x−xk+1∥2+(σk−1/σk)σk−1
2∥qk∥2−σk
2∥qk+1∥2
+1
2σk 
∥y−yk∥2− ∥y−yk+1∥2
+⟨y−yk+1,qk+1⟩ −(σk−1/σk)⟨y−yk,qk⟩
−σ−1
k−(σk−1/σk)/σk−1
2∥yk+1−yk∥2+L2
Gσk
2∥xk+1−xk∥2−τ−1
k−LXY
2∥xk+1−xk∥2.(32)
Multiply both sides of the above relation by tkand sum up the result for k= 0,1, . . . , K −1. In
view of the parameter relation (11), we have
PK−1
k=0tk
L(xk+1,y)− L(x,yk+1)
(a)
≤t0(τ−1
0−ρ0)
2∥x−x0∥2−tK−1τ−1
K−1
2∥x−xK∥2−tK−1σK−1
2∥qK∥2
+t0σ−1
0
2∥y−y0∥2−tK−1σ−1
K−1
2∥y−yK∥2+tK−1⟨y−yK,qK⟩ −t0⟨y−y0,q0⟩
(b)
≤1
2τ0∥x−x0∥2+1
2σ0∥y−y0∥2−tK−1τ−1
K−1
2∥x−xK∥2(33)
where (a)usesq0=0andx−1=x0, and (b)holds by ρ0= 0,t0= 1and
tK−1⟨y−yK,qK⟩ ≤tK−1
2σK−1∥y−yK∥2+tK−1
2/σK−1∥qK∥2.
SinceL(x,y)is convex in xand linear in y, we have
TK
L(¯xK,y)− L(x,¯yK)
≤PK−1
k=0tk
L(xk+1,y)− L(x,yk+1)
, (34)
Combining (33) and (34), we obtain
TK
L(¯xK,y)− L(x,¯yK)
≤1
2τ0∥x−x0∥2−tK−1τ−1
K−1
2∥x−xK∥2+1
2σ0∥y−y0∥2. (35)
Dividing both sides by TK,we obtain the desired result (23).
Part 2. Next we show Y∗⊆ YK. Lety∗be any point in Y∗. Since (35) holds for any x∈ X and
y∈ ∩0≤k≤K−1Yk⊇ Y∗, we can place x=x∗,y=y∗∈ Y∗in (23) to obtain
tK−1τ−1
K−1
2TK∥x∗−xK∥2+L(¯xK,y∗)− L(x∗,¯yK)≤1
TK∆(x∗,y∗).
Moreover, the strong convexity of L(·,y∗)implies
L(¯xK,y∗)≥ L(x∗,y∗) +(y∗)⊤µ
2∥¯xK−x∗∥2≥ L(x∗,¯yK) +(y∗)⊤µ
2∥¯xK−x∗∥2.
17Applying the above two inequalities yields
(y∗)⊤µ
2∥¯xK−x∗∥2≤1
TK∆(x∗,y∗),1
2∥xK−x∗∥2≤τK−1σ0
σK−1∆(x∗,y∗). (36)
In view of (36) and Proposition 4, we have that
(y∗)Tµ≥µ∥y∗∥1=µmax
h1(xK,σ0τK−1∆XY
σK−1), h2(¯xK,∆XY
TK)	
:= ˆρK.
Moreover, since Y∗⊆ Y K−1, we have (y∗)Tµ≥ρK−1. Hence we have (y∗)Tµ≥ρKwhere
ρK= max {ˆρK, ρK−1}is the output of the IMPROVE procedure. Due to the construction of YK, we
immediately see that y∗∈ YK. This implies Y∗⊆ YKand completes our induction proof.
Next, we specify the stepsize selection in Lemma 3 and develop more concrete complexity results in
Corollary 1.
Lemma 3. Letˆρk+1:=√
ˆρ2
kk2+(3ρk+1ˆρk)k
k+1fork≥1andˆρ1= 3q
ρ1
τ0. Suppose σk, τksatisfy:
τ−1
0≥LXY+L2
Gσ0, τk+1=τk(1 +ρk+1τk)−1
2, σk+1=τkσk
τk+1. (37)
Then we have
1
τ2
k≥ˆρ2
k
9k2+1
τ2
0, Tk≥1 +τ0
6˜ρk(k+ 1)k,ˆρk≥min{ρ1,ˆρ1}, (38)
where ˜ρk= 2Pk
s=0ˆρss
k(k+1)fork≥1. Moreover, suppose ¯ρτ0≤2, where ¯ρ= ¯c·¯µ, then we have
σ2
k≤σ2
0(k+ 1)2. (39)
Proof. We first use induction to show that1
τ2
k≥ˆρ2
k
9k2+1
τ2
0. It is easy to see that1
τ2
k≥ˆρ2
k
9k2+1
τ2
0
holds for k= 1by the definition ˆρ1= 3p
ρ1/τ0andτ1=τ0(1+ρ1τ0)−1
2. Assume1
τ2
k≥ˆρ2
k
9k2+1
τ2
0
holds for all k= 0, . . . , K , then we have
1
τ2
K+1=1
τ2
K+ρK+1
τK
≥ˆρ2
K
9K2+1
τ2
0+ρK+1r
ˆρ2
K
9K2+1
τ2
0
≥ˆρ2
K
9K2+1
τ2
0+ρK+1ˆρKK
3
≥ˆρ2
K+1
9(K+ 1)2+1
τ2
0,(40)
which completes our induction. It follows from1
τ2
k≥ˆρ2
k
9k2+1
τ2
0and the relation among Tk, tk, σk, τk
that, for any k≥1
Tk=Pk−1
s=0ts= 1 +Pk−1
s=1ts≥1 +Pk−1
s=1σs
σ0= 1 +Pk−1
s=1τ0
τs≥1 +τ0Pk−1
s=1r
ˆρ2
ss2
9+1
τ2
0
>1 +τ0Pk−1
s=1ˆρss
3= 1 +τ0
6˜ρk(k+ 1)k.
(41)
Similarly, we use induction to prove
ˆρk≥min{ρ1,ˆρ1},∀k≥1. (42)
It is easy to find that ˆρ1≥min{ρ1,ˆρ1}. We assume that ˆρk≥min{ρ1,ˆρ1},∀k≥1holds for any
k= 1, . . . , K . Considering ˆρK+1, we have
ˆρK+1≥1
K+1q
ˆρ2
KK2+ 3ρ1ˆρKK
≥1
K+1q
(min{ρ1,ˆρ1})2K2+ 3ρ1·min{ρ1,ˆρ1}K≥min{ρ1,ˆρ1},
18which completes the induction. Moreover, we use induction to show σ2
k≤σ2
0(k+ 1)2. It is obvious
that the inequality holds for k= 0. Assume the inequality holds for all k= 0, . . . , K, then we have
σ2
K+1=σ2
K(1 +ρK+1τ0σ0
σK)
=σ2
K+ρK+1τ0σ0σK
≤σ2
0 
(K+ 1)2+ρK+1τ0(K+ 1)
≤σ2
0(K+ 2)2,(43)
where the last inequality use the relation ρk≤¯ρ,∀k, and ¯ρτ0≤2.
E.3 Proof of Corollary 1
Proof. First, we show that the sequences {τk, σk, tk, ρk}generated by APDPro satisfy the relation-
ship in (11) in Theorem 1. The first part of (11) can be derived using the monotonicity of {ρk}as
follows:
tk+1 
τ−1
k+1−ρk+1
=σ−1
0 
σk+1τk+1−σk+1ρk+1
=σ−1
0 
σkτkτ−2
k+1−σk+1ρk+1
=σ−1
0 
σk(1 +ρk+1τk)/τk−σk+1ρk+1
=σ−1
0 
σk/τk+ρk+1σk−σk+1ρk+1
≤tkτ−1
k
The second part of (11) can be easily verified using the parameters setting.
Next, we prove the last term in (11) by induction. Firstly, it easy to verify that for any σ0>0,
there exists τ0∈(0,(LXY+L2
Gσ0)−1]such that last term of (11) holds. Hence, when k= 0, the
last term of (11) is directly from the first term of (13). Suppose that the last term of (11) holds for
k= 0, . . . , K −1. From σK−1/σK=τK/τK−1≤1, we have
1
τK=σK
τK−1σK−1≥LXY
σK−1/σK+L2
GσK≥LXY+L2
GσK. (44)
Without loss of generality, place x=x∗,y=y+:= (∥y∗∥1+c∗)[G(¯xK)]+
∥[G(¯xK)]+∥in(23), and using
∥y∗∥1≤¯cin Proposition 1. It is easy to see ∥y+∥=∥y∗∥1+c∗≤¯c, and∥y+∥1≥ ∥y+∥=
∥y∗∥1+c∗≥ ∥y∗∥1,Hence, we conclude that y+∈ Yk,∀k≥0.
Now observe that L(¯xK,y∗)− L(x∗,y∗)≥0, which implies f(¯xK) +⟨y∗, G(¯xK)⟩ −f(x∗)≥0.
In view of ⟨y∗, G(¯xK)⟩ ≤ ⟨y∗,[G(¯xK)]+⟩ ≤ ∥y∗∥ · ∥[G(¯xK)]+∥, then we have
f(¯xK) +∥y∗∥ · ∥[G(¯xK)]+∥ −f(x∗)≥0. (45)
Moreover, it follows from ∥y∗∥1≥ ∥y∗∥that
L(¯xK,y+)− L(x∗,¯yK)≥ L(¯xK,y+)− L(x∗,y∗)
≥f(¯xK) + (∥y∗∥+c∗)∥[G(¯xK)]+∥ −f(x∗).(46)
Combining (45), (46) and (23), we obtain
max
c∗∥[G(¯xK)]+∥, f(¯xK)−f(x∗)	
≤1
TK 1
2τ0∥x0−x∗∥2+D2
Y
2σ0
, (47)
In view of the bound in (38) and the relation between τk, σk, we can get
τk
σk≤3
ˆρ2
kτ2
0k2+9σ0/τ0. (48)
In view of (47) and (38), we have
max
c∗∥[G(¯xK)]+∥, f(¯xK)−f(x∗)	
≤6
6+τ0˜ρK(K+1)K 1
2τ0∥x0−x∗∥2+D2
Y
2σ0
.
Combining (23) and (48) yields1
2∥xK−x∗∥2≤3σ0∆(x∗,y∗)/(ˆρ2
Kτ2
0K2+ 9σ0/τ0).
19F Convergence analysis of rAPDPro
F.1 Proof of Theorem 2
Proof. First, we show that the choice of τs
0= ¯τ, σs
0= ¯σ,∀s≥0satisfy the condition (13) in
Corollary 1: (τs
0)−1≥(1−ν0)(τs
0)−1=LXY+cL2
Gσs
0/δ≥LXY+cL2
Gσs
0.
Next, we show (15) holds by induction. Clearly, (15) holds for s= 0. Assume ∥xs
0−x∗∥2≤∆s
holds for s= 0, . . . , S −1. Then by Theorem 1, we have
∥xS
0−x∗∥2≤σS
0τS
NS
σS
NS
2
τS
0∆S+1
σS
0D2
Y
. (49)
In view of the first bound in (38) and the relation between τs
Ns, σs
Ns, we can get
τs
Ns
σs
Ns≤9
σs
0τs
0(ˆρNsNs)2. (50)
Combining (49) and (50) yields
∥xS
0−x∗∥2≤18
(ˆρNsτs
0Ns)2+9D2
Y
σs
0τs
0(ˆρNsNs)2.
Since the algorithm sets Ns=⌈max{6(ˆρNsτs
0)−1,√
2s·3√
2DY/ 
ˆρNsDXpτs
0σs
0
}⌉, it follows
that
18
(ˆρNsτs
0Ns)2≤18
(ˆρNsτs
0)2·(ˆρNsτs
0)2
36=1
2,
9D2
Y
σs
0τs
0(ˆρNsNs)2≤9D2
Y
σs
0τs
0ˆρ2
Ns·ˆρ2
Nsσs
0τs
0D2
X
18D2
Y2s=1
2·2−sD2
X=1
2∆S,
which implies the desired result (15).
Let the algorithm run for S=
log2(D2
X/ε)
epochs, then ∥xS
0−x∗∥2≤D2
X·2−S≤ε. The total
iteration number required by Algorithm 2 for attaining a solution xS
0such that ∥xS
0−x∗∥2≤εis
PS
s=0Ns≤PS
s=0n
6
ˆρs
Nsτs
0+3√
2DY
ˆρs
NsDX√
τs
0σs
0√
2s+ 1o
(a)=
6
ϖ1τs
0+ 1
(S+ 1) +3√
2DY
ϖ2DX√
τs
0σs
0PS
s=0√
2s
≤
12
ϖ1τs
0+ 2l
log2DX√ε+ 1m
+3√
2DY
ϖ2DX√
τs
0σs
0·√
2S+1−1√
2−1
≤
12
ϖ1τs
0+ 2l
log2DX√ε+ 1m
+3√
2DY(√
2+1)
ϖ2DX√
τs
0σs
0· √
2log2(D2
X/ε)+2−1
≤
12
ϖ1τs
0+ 2l
log2DX√ε+ 1m
+6DY(√
2+2)
ϖ2√
τs
0σs
0·1√ε,
where (a)holds byPS
s=0(ˆρs
Ns)−1= (ϖ1)−1(S+ 1) andPS
s=0√
2s/ˆρs
Ns= (ϖ2)−1PS
s=0√
2s.
Now, we give some proof details in dual convergence results. Let
Qj(x,y) :=(τj)−1−ρj
2∥x−xj∥2+1
2σj∥y−yj∥2+ (σj−1/σj)⟨yj−y, G(xj)−G(xj−1)⟩
+(σj−1/σj)
2/σj−1∥G(xj)−G(xj−1)∥2,
then we establish an important property about the solution sequence in the following lemma.
Lemma 4. Assume ¯τ−1>ρand choose ν0>0such that
1>inf
j≥0{σj−1/σj} ≥δ+ν0. (51)
Then there exists an ν1>0such that for any j≥0and any KKT point (x∗,˜y∗):
0≤tjQj(x∗,˜y∗)−tj+1Qj+1(x∗,˜y∗)−ν1tjh
1
2τj∥xj+1−xj∥2+1
2σj∥yj+1−yj∥2i
,
0< tjQj(x∗,˜y∗).
20Proof. First, we give some results that will be used repeatedly in the following. For notation
simplicity, we denote θj=σj−1/σj. In view of Lemma 3, and the parameter ergodic sequence
generated by rAPDPro, we have
(τs
k)−1, σs
k	
is monotonically increasing sequence in k,¯τ=
τs
0,¯σ=σs
0, ts
0= 1,∀s≥0, and there exist a ν3>0such that ¯σ+ν3≤σ:= min s{σs
Ns}. Now, for
rAPDPro, we claim that there exist ν1, ν2>0such that the following two conditions hold
1. For any j≥0, we have
min
1−δ,(τ−1
j−LXY−L2
Gσj)τj	
≥ν1>0, (52)
and
tjminn
τ−1
j−ρj,1
σj−δ
σj−1o
≥ν2>0. (53)
2. For any j≥0, we have
0≤tjQj(x∗,˜y∗)−tj+1Qj+1(x∗,˜y∗)−ν1tj 
(2τj)−1∥xj+1−xj∥2+(2σj)−1∥yj+1−yj∥2
.(54)
Part 1. We first consider two subsequent points xjandxj+1within the same epoch, and assume
j∼(s, k). Then, it follows from θs
k=σs
k−1/σs
kthat
(σs
k)−1−θs
kδ(σs
k−1)−1= (σs
k)−1−δ(σs
k)−1=1−δ
σs
k(51)
≥ν0
σs
k. (55)
Next, we use induction to show
1−ν0
τs
k≥LXY+L2
Gσs
kδ−1. (56)
When k= 0, inequality (56) degenerates as the definition of τs
0, σs
0. Suppose (56) holds for
k= 0,1, . . . , K −1. Then, from θs
K=σs
K−1/σs
K=τs
K/τs
K−1≤1, we have
(1−ν0)(τs
K)−1= (1−ν0)(τs
K−1θs
K)−1≥LXY
θs
K+L2
Gσs
K−1δ−1
θs
K≥LXY+L2
Gσs
Kδ−1,
which completes our induction proof. Hence, combining (55) and (56), we have
min
1−δ, 
(τs
k)−1−LXY−L2
Gσs
k/δ
τs
k	
≥ν0,∀k∈[Ns]. (57)
Furthermore, when switching to the next epoch (s→s+ 1) , we have
σs+1
0((σs+1
0)−1−θs+1
0δ/σs
Ns)(a)
≥σs+1
0((σs+1
0)−1−(σs
Ns)−1)(b)
≥1−σs+1
0σ−1= 1−¯σσ−1
((τs+1
0)−1−LXY−L2
Gδ−1σs+1
0)τs+1
0(c)
≥ν0τs+1
0=ν0¯τ,
(58)
where (a)holds by θs
0= 1,δ <1,(b)follows from (σs
Ns)−1≥σ−1. Hence, combining (55),(57)
and (58), we completes our proof of (52) by setting ν1= min {1−¯σσ−1, ν0¯τ, ν0}.
Since rAPDPro reset the stepsize periodically and {ts
k,(τs
k)−1}k∈[Ns]are two monotonically increas-
ing sequences, hence
inf
j≥0tj(τ−1
j−ρj)≥ts
0(¯τ−1−ρ) = ¯τ−1−ρ. (59)
Consider infk∈[Ns]ts
kσs
k(1−δσs
k/σs
k−1). Combining δ+ν0≤infk∈[Ns]{θs
k}, then
inf
k∈[Ns]ts
kσs
k(1−δσs
k
σs
k−1) = inf
k∈[Ns]ts
kσs
k(1−δ/θs
k)≥ν0¯σ. (60)
Furthermore, when switching to the next epoch (s→s+ 1) , we have
inf
s≥0ts+1
0σs+1
0(1−δσs+1
0(σs
Ns)−1) = ¯σ2inf
s≥0(¯σ−1−δ(σs
Ns)−1)≥¯σ(1−δ), (61)
where the last inequality holds by ¯σ=σs
0≤σs
Ns. Hence, it follows from (59),(60) and(61) that
there exist ν2= min {¯τ−1−ρ, ν0¯σ,¯σ(1−δ)}such (53) holds.
21Part 2. for any j≥0,we have
tj+1Qj+1(x∗,˜y∗)≤tj (τj)−1
2∥x∗−xj+1∥2+⟨G(xj+1)−G(xj),yj+1−˜y∗⟩
+ (2σj)−1∥˜y∗−yj+1∥2+σj
2∥G(xj+1)−G(xj)∥2
.(62)
Consider k∈ {0,1, . . . , N s}. Inequality (51) implies (11) holds (see proof of Corollary 1 in
Section E.3). Hence, for 0≤k≤Ns,we have
tj+1Qj+1(x∗,˜y∗)≤ts
k (τs
k)−1
2∥x∗−xs
k+1∥2+
G(xs
k+1)−G(xs
k),ys
k+1−˜y∗
+1
2σs
k∥˜y∗−ys
k+1∥2+σs
k
2δ∥G(xs
k+1)−G(xs
k)∥2 (63)
where jcorresponds to (s, k). Furthermore, consider switching to next epoch (s→s+ 1) . Since
ts
k(τs
k)−1is an increasing sequence in k,ρs+1
0>0, ts+1
0= 1, hence
ts
Ns(τs
Ns)−1≥ts+1
0(τs+1
0)−1−ρs+1
0ts+1
0,∀s≥0. (64)
Next, we have
ts
Ns
σs
Ns(a)=ts+1
0
σs+1
0, ts
Ns(b)
≥ts+1
0(c)=ts+1
0θs+1
0, ts
Nsσs
Ns(b)
≥ts+1
0σs+1
0(c)=ts+1
0σs+1
0θs+1
0, (65)
where (a)holds by the definition of ts
k=σs
k
σs
0,(b)holds by {ts
k, σs
k}is an increasing sequence in k,
and(c)holds by θs+1
0= 1. Hence, by (64) and (65), we have
tj+1Qj+1(x∗,˜y∗)≤ts
Ns 1
2τs
Ns∥x∗−xs+1
0∥2+σs
Ns
2∥G(xs+1
0)−G(xs
Ns)∥2
+1
2σs
Ns∥˜y∗−ys+1
0∥2+
G(xs+1
0)−G(xs
Ns),ys+1
0−˜y∗ (66)
where jcorresponds to (s, Ns). By putting (63) and (66) together, we complete the proof of (62).
Placing (x,y) = (x∗,˜y∗),(xk+1,yk+1) = (xj+1,yj+1)in(32) and multiplying tjon both sides,
we have
0≤tj[L(xj+1,˜y∗)− L(x∗,yj+1)]
≤tjτ−1
j−ρj
2∥x−xj∥2−τ−1
j
2∥x−xj+1∥2+θj
2δ/σj−1∥qj∥2−1
2δ/σj∥qj+1∥2
+ (2σj)−1 
∥y−yj∥2− ∥y−yj+1∥2
+⟨y−yj+1,qj+1⟩ −θj⟨y−yj,qj⟩
−σ−1
j−θjδ/σj−1
2∥yj+1−yj∥2+L2
G
2δ/σj∥xj+1−xj∥2−τ−1
j−LXY
2∥xj+1−xj∥2
≤tjQj(x∗,˜y∗)−tj+1Qj+1(x∗,˜y∗)−ν1tj[(2τj)−1∥xj+1−xj∥2+ (2σj)−1∥yj+1−yj∥2],
(67)
where the last inequality holds by (62) and (52). It follows from (53), σj−1/σj≤1and
⟨yj−˜y∗,qj⟩ ≥ −σj−1
2δ∥qj∥2−δ/σj−1
2∥˜y∗−yk∥2
that
tjQj(x∗,˜y∗)≥tj 
(2τj)−1∥x∗−xj∥2+ (2σj)−1∥˜y∗−yj∥2−δ
2σj−1∥yj−˜y∗∥2
≥ν2 1
2∥x∗−xj∥2+1
2∥yj−˜y∗∥2
>0.(68)
Combining (67) and (68), we complete our proof of (54).
F.2 Proof of Theorem 3
Proof. Since
(xj,yj)	
located in set X × Y is a bounded sequence, it must have a convergent
subsequence limn→∞(xjn,yjn) = ( x∗,y∗), where y∗is the limit point. We claim that limit
point (x∗,y∗)satisfies the KKT condition. Placing aj=tjQj(x∗,˜y∗),bj=ν1tj[(2τj)−1∥xj+1−
xj∥2+ (2σj)−1∥yj+1−yj∥2]andcj= 0 in Lemma 2. It follows from (54) in Lemma 4 that
aj≥0, bj>0. Hence, we haveP∞
j=0∥xj+1−xj∥2<∞,andP∞
j=0∥yj+1−yj∥2<∞, which
22implies limn→∞∥xjn−xjn+1∥2= 0andlimn→∞∥yjn−yjn+1∥2= 0. There are two different
cases for τjnwhen jn→ ∞ , and we discuss the value of Bjn+1in(25) decided by τjnin each of the
two cases below.
Case 1: τ−1
jn<∞. By the definition of Bjn+1in(27) andlimn→∞∥xjn−xjn+1∥2= 0, we have
Bjn+1≤ ∥x−xjn+1∥ · ∥xjn+1−xjn∥/τjnn→∞−→0.
Case 2: τ−1
jn=∞. It follows from (39) thatτ−1
jnincreases at order Θ(k), where jn∼(s, k). By (23),
we obtain ∥x−xjn∥decreases at order O(1/k)(jn∼(s, k)). Hence, combining limn→∞∥xjn−
xjn+1∥2= 0, we have Bjn+1≤1
τjn 
∥x−xjn+1∥∥xjn+1−xjn∥n→∞−→ 0. It follows from
limn→∞xjn=x∗,limn→∞Bjn+1= 0and (25) that
f(x∗) +⟨∇G(x∗)y∗,x∗⟩ ≤f(x) +⟨∇G(x∗)y∗,x⟩,∀x∈ X.
Hence, according to the first-order optimality condition, we have
0∈∂f(x∗) +∇G(x∗)y∗+NX(x∗). (69)
Next, we show the complementary slackness holds for (x∗,y∗). Since σ−1
jnhas an upper bound ¯σ−1,
∥y−yjn+1∥ ≤DY,limn→∞∥yjn−yjn+1∥2= 0and the definition of Ajn+1in(26), hence we
obtain Ajn+1≤1
σjn 
∥yjn−yjn+1∥∥y−yjn+1∥n→∞−→0.Combining above, limn→∞yjn=y∗
and(24), we have 0≤ −⟨ G(x∗),y∗⟩ ≤ −⟨ G(x∗),y⟩,∀y∈ Y. Moreover, due to the complementary
slackness, there exists an ˆy∗∈ Y∗⊆ Y such that −⟨G(x∗),ˆy∗⟩= 0. Hence, we must have
⟨G(x∗),y∗⟩= 0, which, together with (69), implies that (x∗,y∗)is KKT point.
G Proof details for sparsity identification
Our proof strategy of active-set identification in rAPDPro is similar to those in unconstrained
optimization [ 24]. Namely, we show that the optimal sparsity pattern is identified when the iterates
fall in a properly defined neighborhood dependent on η. The next lemma shows that the primal
and dual sequences indeed converge to the neighborhood of the optimal primal and dual solutions,
respectively, in a finite number of iterations.
Lemma 5. There exists an ˆS1such that
∥xs
0−x∗∥ ≤ ∥xˆS1
0−x∗∥and∥ys
0−y∗∥ ≤ ∥yˆS1
0−y∗∥,∀s≥ˆS1, (70)
where (x∗,y∗)is the unique solution of problem (17). Moreover, there exists an epoch ˆS0≥ˆS1such
that∀s≥ˆS0,we have
∥ys
k−y∗∥ ≤η
3∥∇g(x∗)∥,∥xs
k−x∗∥ ≤η
3LXYτs
k
τs
k+(2LXY)−1,∀k= 0,1, . . . N s. (71)
Proof. From Theorem 2 and 3, we have limj→∞(xj,yj) = (x∗,y∗), where jcorresponds to (s,0).
It implies that there exists an epoch ˆS1such that (70) holds.
It follows from (35) that∥xs
1−x∗∥ ≤p
σs
0τs
0/σs
1(∥xs
0−x∗∥2/τs
0+∥ys
0−y∗∥2/σs
0). Hence, in
order to prove ∥xs
1−x∗∥ ≤η
3LXY·τs
k
τs
k+(2LXY)−1, we need to prove
q
σs
0τs
0
σs
1(1
τs
0∥xs
0−x∗∥2+1
σs
0∥ys
0−y∗∥2)≤η
3LXYτs
1
τs
1+(2LXY)−1. (72)
From Corollary 1 and Theorem 2, 3, we know that the left hand side of (72) converges to 0and
right hand side of (72) is a positive constant. Hence, there exist a ˆS2such that (72) holds, which
implies (71) holds for k= 1, s=ˆS2. Now we use induction to prove, for ∀k∈[NˆS2], we have
 σˆS2
0τˆS2
k
σˆS2
k(1
τˆS2
0∥xˆS2
0−x∗∥2+1
σˆS2
0∥yˆS2
0−y∗∥2)1/2≤η
3LXYτˆS2
k
τˆS2
k+(2LXY)−1. (73)
23When k= 1, inequality (73) coincides with (72) withs=ˆS2. Now, assume (73) holds for k, we aim
to prove (73) holds for k+ 1. It follows from (35) that
∥xˆS2
k+1−x∗∥(a)
≤s
τˆS2
k+1
σˆS2
k+1·σˆS2
k
τˆS2
k·η
3LXY·τˆS2
k
τˆS2
k+(2LXY)−1(b)=η
3LXY·τˆS2
k+1
τˆS2
k+(2LXY)−1
(c)
≤η
3LXY·τˆS2
k+1
τˆS2
k+1+(2LXY)−1,
where (a)follows from induction, (b)holds by τˆS2
kσˆS2
k=τˆS2
k+1σˆS2
k+1and(c)holds by τˆS2
k+1≤τˆS2
k.
Hence, we complete our proof of (73). From Theorem 2, we have ∥xs
0−x∗∥2≤D2
X·2−s, which
implies that there exists a ˆS3=
2 log2
DX(η
3LXY·¯τ
¯τ+(2LXY)−1)−1	
such that ∥xˆS3
0−x∗∥ ≤
DX·√
2−ˆS3≤η
3LXY¯τ
¯τ+(2LXY)−1, which implies that ∥xs
0−x∗∥ ≤D2
X·2−s≤η
3LXY¯τ
¯τ+(2LXY)−1
holds for any s≥ˆS3.
It follows from the definition of ˆS1in(70) and stepsize will be reset at different epoch, then we
have (72) holds for s≥max{ˆS1,ˆS2}, which implies that (73) holds with substituting ˆS2as any
s≥max{ˆS1,ˆS2}. Furthermore, it follows from Theorem 3 that limj→∞yj=y∗, where j
corresponds to (s, k). Then there exists a ˆS4such that the first term in (71) holds. Hence, we can
obtain that there exist a ˆS0= max {ˆS1,ˆS2,ˆS3,ˆS4}such that (71) holds.
It is worth noting that the primal neighborhood defined by the second term of (71) is a bit different
from the fixed neighborhood in the standard analysis [ 24], which involves a constant stepsize. As
APDPro sets τs
k=O(1/k), both the point distance and neighborhood radius decay at the same
O(1/k)rate. Hence, we use a substantially different analysis to show the sparsity identification in
the constrained setting.
G.1 Proof of Proposition 5
Proof. The uniqueness of primal optimal solution x∗follows from Proposition 2. The KKT condition
(ensured by Slater’s CQ) implies
0∈∂f(x∗) +∇g(x∗)y∗. (74)
According to Assumption 2, we have x∗̸=0, hence Ac(x∗) ={1,2, . . . , B } \ A (x∗)̸=∅. In view
of (74), for any i∈ Ac(x), we have pix∗
(i)/∥x∗
(i)∥=−∇(i)g(x∗)y∗, which gives a unique y∗.
G.2 Proof of Theorem 4
Proof. It follows from the Lipschitz smoothness of g(·)and property (71) that for any s≥ˆS0, we
have 
∇g(xs
k)ys
k+1
(i)−
∇g(x∗)ys
k+1
(i)
≤∇g(xs
k)ys
k+1− ∇g(x∗)ys
k+1
≤LXYxs
k−x∗≤η
3τs
k
τs
k+(2LXY)−1, k= 0, . . . N s.(75)
Recall that the primal update has the following form
xs
k+1= argmin
x∈XnPB
i=1pi∥x(i)∥+
∇g(xs
k)ys
k+1,x
+1
2τs
k∥x−xs
k∥2o
.
Since τs
k/(τs
k+ (2LXY)−1)is monotonically increasing with respect to τs
k, for the strictly feasible
point ˜x, we have
∥xs
k+1−˜x∥(a)
≤η
3LXY·¯τ
¯τ+(2LXY)−1+∥x∗−˜x∥
(b)
< ζ+ min i∈[m]2q
−2gi(x∗
i)
µi,(76)
24where (a)holds by (71),¯τ≥τs
kand(b)follows from the definition of x∗,˜xandζ. Inequality (76)
implies that xs
k+1∈intX, and hence NX(xs
k+1) ={0}. In view of the optimality condition, we
have h
1
τs
k(xs
k−xs
k+1)− ∇g(xs
k)ys
k+1i
(i)∈pi∂∥[xs
k+1](i)∥,1≤i≤B. (77)
Our next goal is to show [xS
k+1](i)=x∗
(i)satisfies condition (77) fori∈ A(x∗). Placing x(i)=x∗
(i)
in
∇g(xS
k)yS
k+1+1
τs
k(x−xs
k)
(i), we have

∇g(xs
k)ys
k+1+1
τs
k(x∗−xs
k)
(i)
≤
∇g(xs
k)ys
k+1
(i)∥+∥1
τs
k(x∗
(i)−xs
k(i))
(a)
≤η
3τs
k
τs
k+(2LXY)−1+
∇g(x∗)ys
k+1
(i)+η
3(LXY)−1
τs
k+(2LXY)−1
(b)
≤η
3τs
k+2(2LXY)−1
τs
k+(2LXY)−1+ 1
+[∇g(x∗)y∗](i)
< η+[∇g(x∗)y∗](i)(c)
≤pi,∀i∈ A(x∗).(78)
In above, (a)follows from (71) and (75), (b)follows from
∥[∇g(x∗)yS
k+1](i)∥ − ∥ [∇g(x∗)y∗](i)∥ ≤ ∥yS
k+1−y∗∥∥∇g(x∗)∥ ≤η
3,
and(c)holds by the definition of η. Combining (77) and(78), we have A(x∗)⊆ A(xs
k+1), s≥
ˆS0,∀k∈[Ns], which completes our proof.
Table 1: Datasets description and parameter settings
dataset Node(n) Edge b α
bio-CE-HT 2617 3K -0.04 0.4
bio-CE-LC 1387 2K -0.05 0.4
econ-beaflw 502 53K -0.01 0.995
DD68 775 2K -0.005 0.4
DD242 1284 3K -0.05 0.4
peking-1 3341 13.2K -0.001 0.4
H A multi-stage accelerated primal-dual algorithm
Both the previous algorithms need to solve a complicated dual problem that involves a linear cut
constraint, posing a potential issue: the associated sub-problem might lack a closed-form solution.
To resolve this issue, we present the Multi-Stage Accelerated Primal-Dual Algorithm (msAPD) in
Algorithm 3, which obtains the same O(1/√ε)complexity without introducing a new cut constraint.
Our new method is a double-loop procedure for which an accelerated primal-dual algorithm with a
pending sub-iteration number (APDPi) is running in each stage. While both APDPi and APDPro
employ the IMPROVE step to estimate the dual lower bound, APDPi only relies on the lower bound
estimation to change the inner-loop iteration number adaptively, but not the stepsize selection.
We develop the convergence property of APDPi, which paves the path to proving our main theorem.
For the convergence analysis, it suffices to verify that the initial stepsize parameter τs
0, σs
0satisfy
assumptions in Theorem 5.
Theorem 5. Let{¯xs
k,¯ys
k}be the sequence generated by APDPi , then we have
L(¯xs
K,y∗)− L(x∗,¯ys
K)≤1
K∆s(x∗,y∗),1
2∥¯xs
K−x∗∥2≤1
(y∗)⊤µK∆s(x∗,y∗),(79)
where ∆s(x∗,y∗)≜1
2τs
0∥xs
0−x∗∥2+1
2σs
0∥ys
0−y∗∥2and(x∗,y∗)is a KKT point.
250.0 0.2 0.4 0.6 0.8 1.0
1e5107
105
103
101
APD
Mirror-Prox
rAPDPro
msAPD
APD+restart
0.0 0.2 0.4 0.6 0.8 1.0
1e51010
108
106
104
102
100
APD
Mirror-Prox
rAPDPro
msAPD
APD+restart
0.0 0.5 1.0 1.5 2.0
1e4106
104
102
100
APD
Mirror-Prox
rAPDPro
msAPD
APD+restart
0.0 0.2 0.4 0.6 0.8 1.0
1e51011
109
107
105
103
APD
Mirror-Prox
rAPDPro
msAPD
APD+restart
0.0 0.2 0.4 0.6 0.8 1.0
1e51011
109
107
105
103
101
APD
Mirror-Prox
rAPDPro
msAPD
APD+restart
0.0 0.5 1.0 1.5 2.0
1e41010
109
APD
Mirror-Prox
rAPDPro
msAPD
APD+restartFigure 3: The first row is the results of objective convergence to optimum, where the y-axis
reports log10((∥D1/2xk∥1− ∥D1/2x∗∥1)/∥D1/2x∗∥1)for rAPDPro, and log10((∥D1/2¯xk∥1−
∥D1/2x∗∥1)/∥D1/2x∗∥1)for APD, msAPD and Mirror-Prox. The second row is the results of
feasibility violation, where y-axis reports the feasibility gap log10(max{0, G(xk)})for rAPDPro,
andlog10(max{0, G(¯xk)})for APD, APD+restart msAPD and Mirror-Prox. Datasets (Left-Right
order) correspond to DD68, DD242 and peking-1.
Algorithm 3 Multi- Stage APD (msAPD)
Require: ¯x0∈ X,¯y0∈ Y,˜σ, S
1:Initialize: ρ0
0= 0
2:fors= 0, . . . , S do
3: Compute τs
0= 
LXY+L2
G˜σ·2s
2−1, σs
0= ˜σ·2s
2
4: (¯xs+1,¯ys+1, ρs+1
0)←APDP I(τs
0, σs
0,¯xs,¯ys, ρs
0, s)
5:end for
6:Output: ¯xS+1,¯yS+1
7:procedure APDP I(τs
0, σs
0,x0,y0, ρs
0, s)
8: Initialize: (x−1,y−1)←(x0,y0),¯x0=x0, k= 0, Ns=∞,∆XY=1
2τs
0D2
X+1
2σs
0D2
Y
9: while k < N sdo
10: zk←2G(xk)−G(xk−1)
11: yk+1←argminy∈Y∥y−(yk+σkzk)∥2
12: xk+1←proxf,X(xk−τs
0∇G(xk)yk+1, τs
0)
13: ¯xk+1←(k¯xk+xk+1)/(k+ 1),
14: ρs
k+1←IMPROVE (xk,¯xk,1
2D2
X,∆XY
k, ρs
k)
15: Compute Ns=⌈max4
ρs
k+1τs
0,D2
Y
ρs
k+1σs
0D2
X·2s+1	
⌉
16: k←k+ 1
17: end while
18: return ¯xNs,¯yNs, ρs
k
19:end procedure
Proof. The stepsize τs
k=τs
0, σs
k=σs
0are unchanged at one epoch, which implies that ρk+1= 0,
i.e.,(37) are satisfied. By the definition of τs
0andσs
0, we have (τs
0)−1=LXY+L2
G˜σ√
2s=
LXY+L2
Gσs
0,which means equality holds at the first term in (37).
Since gi(x)is a strongly convex function with modulus µi, then we have
L(¯xK,y∗)≥ L(x∗,y∗) +(y∗)⊤µ
2∥¯xK−x∗∥2,L(x∗,y∗)≥ L(x∗,¯yK).
Summing up the two inequalities above, we can get
L(¯xK,y∗)− L(x∗,¯yK)≥(y∗)⊤µ
2∥¯xK−x∗∥2. (80)
26Combining (79) and (80), we can obtain the second term of (79).
We show msAPD obtains an O(1/√ε)convergence rate, which matches the complexity of APDPro.
Theorem 6. Let{¯xs
0}be the sequence computed by msAPD . Then, we have
∥¯xs
0−x∗∥2≤∆s≡D2
X·2−s,∀s≥0. (81)
For any ε∈(0, D2
X),msAPD will find a solution ¯xs
0∈ X such that ∥¯xs
0−x∗∥2≤εin at most
log2D2
X/ε
epochs. Moreover, the overall iteration number performed by msAPD to find such a
solution is bounded by
Tε=
8LXY
ρ0
N0+ 2l
log2DX√ε+ 1m
+ (2 +√
2)
˜σL2
G+2D2
Y
ρ0
N0˜σD2
X
DX√ε.
Proof. We first show that (81) holds by induction. It is easy to verify that (81) holds for s= 0.
Assume ∥¯xs
0−x∗∥2≤∆s=D2
X·2−sholds for s= 0, . . . , S −1. By Theorem 5, we have
∥¯xS
0−x∗∥2≤1
(y∗)⊤µNS−1 2
τS−1
0∆S+1
σS−1
0D2
Y
.
As the algorithm sets NS−1=
max
4/(ρS−1
NS−1τS−1
0),2D2
Y/(ρS−1
NS−1σS−1
0∆S)	
, the following
inequalities hold:
2 
(y∗)⊤µNS−1τS−1
0−1≤2 
ρS−1
NS−1NS−1τS−1
0−1≤1
2,
D2
Y 
(y∗)⊤µNS−1σS−1
0−1≤D2
Y 
ρS−1
NS−1NS−1σS−1
0−1≤1
2∆S.
Putting these pieces together, we have ∥¯xS−x∗∥2≤1
2∆S+1
2∆S= ∆ S. Suppose the algorithm
runs for Sepochs to achieve the desired accuracy ε, i.e.,∥xS
0−x∗∥2≤D2
X·2−S≤ε. Then the
overall iteration number can be bounded by
PS
s=0Ns(a)
≤PS
s=0n
4
ρ0
N0τS−1
0+2D2
Y
ρ0
N0σS−1
0∆S+ 1o
(b)
≤PS
s=0n
4LXY
ρ0
N0+ 1
+
˜σL2
G+2D2
Y
ρ0
N0˜σD2
X√
2so
≤
8LXY
ρ0
N0+ 2l
log2DX√ε+ 1m
+ (2 +√
2)
˜σL2
G+2D2
Y
ρ0
N0˜σD2
X
DX√ε,
where (a)holds by ρs
NS≥ρ0
N0,∀s≥0,(b)follows from the definition of τs
0andσs
0.
Remark 11. Theorem 6 shows that msAPD obtains a worst-case complexity of O 
log(DX/√ε) +
(DX+D2
Y/DX)/√ε
, which is an upper bound of the complexity of rAPDPro (see Theorem 2). The
complexities of msAPD andrAPDPro match when DX= Ω(1) DY. Otherwise, rAPDPro appears
to be much better in terms of dependence on DX/√ε. On the other hand, msAPD has a simpler
subproblem, which does not involve an additional cut constraint on the dual update.
I Experiment details
We examine the empirical performance for solving sparse Personalized PageRank. Let G= (V, E)
be a connected undirected graph with nvertices. Denote the adjacency matrix of GbyA, that is,
Ai,j= 1ifi∼jand0otherwise. Let D= diag( d1, . . . , d n)be the matrix with the degrees {di}n
i=1
in its diagonal. Then the constrained form of Personalized PageRank can be written as follows:
min
x∈Rn∥D1/2x∥1s.t.1
2⟨x, Qx⟩ −α⟨s, D−1/2x⟩ ≤b, (82)
where Q=D−1/2 
D−1−α
2(D+A)
D−1/2,α∈(0,1),s∈∆nis a teleportation distribution
over the nodes of the graph Gandbis a pre-specific target level.
270.0 0.2 0.4 0.6 0.8 1.0
1e50.60.70.80.91.0
APD
Mirror-Prox
rAPDPro
msAPD
APD+restart
0.0 0.2 0.4 0.6 0.8 1.0
1e50.60.70.80.91.0
APD
Mirror-Prox
rAPDPro
msAPD
APD+restart
0.0 0.5 1.0 1.5 2.0
1e40.60.70.80.91.0
APD
Mirror-Prox
rAPDPro
msAPD
APD+restartFigure 4: The experimental results on active-set identification. Datasets (Left-Right order) correspond
to DD68, DD242 and peking-1. The x-axis reports the iteration number and the y-axis reports
accuracy in active-set identification.
Datasets We selected 6 small-to-median scale datasets from various domains in the Network
Datasets [ 28]. We skip large-scale networks as MOSEK struggles to achieve the optimal solution,
making it unsuitable for subsequent comparison of the optimality gap. We briefly describe these
datasets in Table 1. For more details, please refer to the network repository.
Parameter tuning For all experiments, we set r= min i∈[n]|di|,µ=λmin(Q)andLX=
λmax(Q), with λmin(·), λmax(·)denoting the smallest and largest eigenvalue, respectively. For
msAPD, we have made additional parameter adjustments. Based on our observations, due to a
small estimated strongly convex coefficient, msAPD could not switch to the next cycle searly
enough. To prevent msAPD from degrading to APD, we iterate according to the predefined number
of sub-iterations and manually switch to the next set of parameters. We divide τby√
2, multiply
σby√
2, and increase the number of sub-iterations in the next period by a factor of√
2. For all
experiments, we tune the stepsize τ, σ, γ from
0.0001,0.0005,0.001,0.005,0.01	
, where τ, σare
the initial stepsizes of rAPDPro, msAPD and APD, γis the constant stepsize of Mirror-Prox. All
algorithms start with the primal variables initialized as zero vectors and the dual variables initialized
as ones.
Additional experiment results Figure 3 and Figure 4 describe the convergence performance and
active set identification results on the last three datasets: DD68, DD242 and peking-1. Furthermore,
we report the time consumption for the Personalized PageRank problem in Table 2. The table
indicates that, although rAPDPro and msAPD require moderately complex computations to determine
the lower bound of the strong convexity parameter, the two methods still accelerate the algorithm’s
convergence and can significantly reduce the overall convergence time.
Table 2: Time summary when max{|f(x)−f(x∗)|/|f(x∗)|,max{G(x),0}} ≤ 10−3. All experi-
ments were conducted five times, and the results are reported as mean (standard deviation). ∗means
that upon completion of all iterations, the algorithms still fails to meet the criteria for both error
measures.
dataset APD APD+restart rAPDPro Mirror-Prox msAPD mosek
bio-CE-HT 187.15 (0.86)* 115.95 (1.04) 136.92 (0.92) 370.50 (1.80)* 77.21 (0.67) 0.21
bio-CE-LC 2.58 (0.16)* 0.65 (0.01) 0.44 (0.01) 4.74 (0.33)* 0.65 (0.03) 0.1
econ-beaflw 72.28 (0.59)* 87.12 (0.43)* 18.42 (0.44) 116.13 (1.15)* 66.70 (0.76) 0.16
DD242 43.29 (1.20)* 10.27 (0.39) 6.30 (0.08) 79.16 (0.60)* 10.33 (0.62) 0.16
DD68 36.55 (0.42)* 19.07 (0.66) 22.35 (0.75) 67.73 (1.39)* 15.69 (0.37) 0.24
peking-1 122.37 (2.99)* 11.55 (0.69) 4.86 (0.09) 243.45 (7.20)* 11.24 (0.15) 0.21
Nonetheless, we observe that Mosek achieves significantly faster computational efficiency for
small-scale problems than our algorithm. Therefore, we test the efficiency of rAPDPro on some
large-scale instances. For large-scale instances, we consider the following problem minx∈Rn∥x−
1∥1s.t.1
2x⊤Qix+c⊤
ix+di≤0, i= 1, . . . , m, where Qiare dense and positive definite matrix
and generated randomly and ciare generated randomly. Furthermore, we set proper dito make the
feasible region is non-empty. When n= 5000 andm > 10, MOSEK crashes on our computer, which
means we can not get x∗for calculating the optimality gap. Therefore, we report the time required
28for the algorithm to satisfy max{|f(x)−f(x∗)|/|f(x∗)|,max{G(x),0}} ≤ 10−3and the time
taken by the algorithm to complete 10,000 iterations. On this problem, results from small datasets
indicate that the performance of the 10,000-step algorithm should be sufficient to meet our specified
termination criteria.
Table 3: Comparison of computational time in seconds between rAPDPro and MOSEK
m rAPDPro MOSEK
8 24.612 50.38
10 53.997 67.99
12 392 -
29NeurIPS Paper Checklist
1.Claims
Question: Do the main claims made in the abstract and introduction accurately reflect the
paper’s contributions and scope?
Answer: [Yes]
Justification: We state the complete contributions in the Introduction section.
Guidelines:
•The answer NA means that the abstract and introduction do not include the claims
made in the paper.
•The abstract and/or introduction should clearly state the claims made, including the
contributions made in the paper and important assumptions and limitations. A No or
NA answer to this question will not be perceived well by the reviewers.
•The claims made should match theoretical and experimental results, and reflect how
much the results can be expected to generalize to other settings.
•It is fine to include aspirational goals as motivation as long as it is clear that these goals
are not attained by the paper.
2.Limitations
Question: Does the paper discuss the limitations of the work performed by the authors?
Answer: [Yes]
Justification: We discuss the limitations of our work in Appendix A.
Guidelines:
•The answer NA means that the paper has no limitation while the answer No means that
the paper has limitations, but those are not discussed in the paper.
• The authors are encouraged to create a separate "Limitations" section in their paper.
•The paper should point out any strong assumptions and how robust the results are to
violations of these assumptions (e.g., independence assumptions, noiseless settings,
model well-specification, asymptotic approximations only holding locally). The authors
should reflect on how these assumptions might be violated in practice and what the
implications would be.
•The authors should reflect on the scope of the claims made, e.g., if the approach was
only tested on a few datasets or with a few runs. In general, empirical results often
depend on implicit assumptions, which should be articulated.
•The authors should reflect on the factors that influence the performance of the approach.
For example, a facial recognition algorithm may perform poorly when image resolution
is low or images are taken in low lighting. Or a speech-to-text system might not be
used reliably to provide closed captions for online lectures because it fails to handle
technical jargon.
•The authors should discuss the computational efficiency of the proposed algorithms
and how they scale with dataset size.
•If applicable, the authors should discuss possible limitations of their approach to
address problems of privacy and fairness.
•While the authors might fear that complete honesty about limitations might be used by
reviewers as grounds for rejection, a worse outcome might be that reviewers discover
limitations that aren’t acknowledged in the paper. The authors should use their best
judgment and recognize that individual actions in favor of transparency play an impor-
tant role in developing norms that preserve the integrity of the community. Reviewers
will be specifically instructed to not penalize honesty concerning limitations.
3.Theory Assumptions and Proofs
30Question: For each theoretical result, does the paper provide the full set of assumptions and
a complete (and correct) proof?
Answer: [Yes]
Justification: We give all assumptions needed for the theorems we are proving, such as
Assumption 1, 2, 3 and 4, to ensure the conclusion is correct.
Guidelines:
• The answer NA means that the paper does not include theoretical results.
•All the theorems, formulas, and proofs in the paper should be numbered and cross-
referenced.
•All assumptions should be clearly stated or referenced in the statement of any theorems.
•The proofs can either appear in the main paper or the supplemental material, but if
they appear in the supplemental material, the authors are encouraged to provide a short
proof sketch to provide intuition.
•Inversely, any informal proof provided in the core of the paper should be complemented
by formal proofs provided in appendix or supplemental material.
• Theorems and Lemmas that the proof relies upon should be properly referenced.
4.Experimental Result Reproducibility
Question: Does the paper fully disclose all the information needed to reproduce the main ex-
perimental results of the paper to the extent that it affects the main claims and/or conclusions
of the paper (regardless of whether the code and data are provided or not)?
Answer: [Yes]
Justification: Our experimental reproduction scripts have been placed in the attachment.
Guidelines:
• The answer NA means that the paper does not include experiments.
•If the paper includes experiments, a No answer to this question will not be perceived
well by the reviewers: Making the paper reproducible is important, regardless of
whether the code and data are provided or not.
•If the contribution is a dataset and/or model, the authors should describe the steps taken
to make their results reproducible or verifiable.
•Depending on the contribution, reproducibility can be accomplished in various ways.
For example, if the contribution is a novel architecture, describing the architecture fully
might suffice, or if the contribution is a specific model and empirical evaluation, it may
be necessary to either make it possible for others to replicate the model with the same
dataset, or provide access to the model. In general. releasing code and data is often
one good way to accomplish this, but reproducibility can also be provided via detailed
instructions for how to replicate the results, access to a hosted model (e.g., in the case
of a large language model), releasing of a model checkpoint, or other means that are
appropriate to the research performed.
•While NeurIPS does not require releasing code, the conference does require all submis-
sions to provide some reasonable avenue for reproducibility, which may depend on the
nature of the contribution. For example
(a)If the contribution is primarily a new algorithm, the paper should make it clear how
to reproduce that algorithm.
(b)If the contribution is primarily a new model architecture, the paper should describe
the architecture clearly and fully.
(c)If the contribution is a new model (e.g., a large language model), then there should
either be a way to access this model for reproducing the results or a way to reproduce
the model (e.g., with an open-source dataset or instructions for how to construct
the dataset).
(d)We recognize that reproducibility may be tricky in some cases, in which case
authors are welcome to describe the particular way they provide for reproducibility.
31In the case of closed-source models, it may be that access to the model is limited in
some way (e.g., to registered users), but it should be possible for other researchers
to have some path to reproducing or verifying the results.
5.Open access to data and code
Question: Does the paper provide open access to the data and code, with sufficient instruc-
tions to faithfully reproduce the main experimental results, as described in supplemental
material?
Answer: [Yes]
Justification: Our experiments use entirely publicly available datasets, and we are committed
to making our code completely open source.
Guidelines:
• The answer NA means that paper does not include experiments requiring code.
•Please see the NeurIPS code and data submission guidelines ( https://nips.cc/
public/guides/CodeSubmissionPolicy ) for more details.
•While we encourage the release of code and data, we understand that this might not be
possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not
including code, unless this is central to the contribution (e.g., for a new open-source
benchmark).
•The instructions should contain the exact command and environment needed to run to
reproduce the results. See the NeurIPS code and data submission guidelines ( https:
//nips.cc/public/guides/CodeSubmissionPolicy ) for more details.
•The authors should provide instructions on data access and preparation, including how
to access the raw data, preprocessed data, intermediate data, and generated data, etc.
•The authors should provide scripts to reproduce all experimental results for the new
proposed method and baselines. If only a subset of experiments are reproducible, they
should state which ones are omitted from the script and why.
•At submission time, to preserve anonymity, the authors should release anonymized
versions (if applicable).
•Providing as much information as possible in supplemental material (appended to the
paper) is recommended, but including URLs to data and code is permitted.
6.Experimental Setting/Details
Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
results?
Answer: [Yes]
Justification: All details can be found in the paper and supplemental material.
Guidelines:
• The answer NA means that the paper does not include experiments.
•The experimental setting should be presented in the core of the paper to a level of detail
that is necessary to appreciate the results and make sense of them.
•The full details can be provided either with the code, in appendix, or as supplemental
material.
7.Experiment Statistical Significance
Question: Does the paper report error bars suitably and correctly defined or other appropriate
information about the statistical significance of the experiments?
Answer: [No]
32Justification: Since our algorithm is deterministic, our experimental results do not report
standard deviation correlation results, but we have experimented on a wide range of datasets
to demonstrate the robustness of our algorithm.
Guidelines:
• The answer NA means that the paper does not include experiments.
•The authors should answer "Yes" if the results are accompanied by error bars, confi-
dence intervals, or statistical significance tests, at least for the experiments that support
the main claims of the paper.
•The factors of variability that the error bars are capturing should be clearly stated (for
example, train/test split, initialization, random drawing of some parameter, or overall
run with given experimental conditions).
•The method for calculating the error bars should be explained (closed form formula,
call to a library function, bootstrap, etc.)
• The assumptions made should be given (e.g., Normally distributed errors).
•It should be clear whether the error bar is the standard deviation or the standard error
of the mean.
•It is OK to report 1-sigma error bars, but one should state it. The authors should
preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis
of Normality of errors is not verified.
•For asymmetric distributions, the authors should be careful not to show in tables or
figures symmetric error bars that would yield results that are out of range (e.g. negative
error rates).
•If error bars are reported in tables or plots, The authors should explain in the text how
they were calculated and reference the corresponding figures or tables in the text.
8.Experiments Compute Resources
Question: For each experiment, does the paper provide sufficient information on the com-
puter resources (type of compute workers, memory, time of execution) needed to reproduce
the experiments?
Answer: [Yes]
Justification: All experiments are run on Mac mini M2 Pro, 32GB.
Guidelines:
• The answer NA means that the paper does not include experiments.
•The paper should indicate the type of compute workers CPU or GPU, internal cluster,
or cloud provider, including relevant memory and storage.
•The paper should provide the amount of compute required for each of the individual
experimental runs as well as estimate the total compute.
•The paper should disclose whether the full research project required more compute
than the experiments reported in the paper (e.g., preliminary or failed experiments that
didn’t make it into the paper).
9.Code Of Ethics
Question: Does the research conducted in the paper conform, in every respect, with the
NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines ?
Answer: [Yes]
Justification: The code in submission is fully compliant with the NeurIPS code of Ethics.
Guidelines:
•The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
•If the authors answer No, they should explain the special circumstances that require a
deviation from the Code of Ethics.
33•The authors should make sure to preserve anonymity (e.g., if there is a special consid-
eration due to laws or regulations in their jurisdiction).
10.Broader Impacts
Question: Does the paper discuss both potential positive societal impacts and negative
societal impacts of the work performed?
Answer: [NA]
Justification:
Guidelines:
• The answer NA means that there is no societal impact of the work performed.
•If the authors answer NA or No, they should explain why their work has no societal
impact or why the paper does not address societal impact.
•Examples of negative societal impacts include potential malicious or unintended uses
(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
(e.g., deployment of technologies that could make decisions that unfairly impact specific
groups), privacy considerations, and security considerations.
•The conference expects that many papers will be foundational research and not tied
to particular applications, let alone deployments. However, if there is a direct path to
any negative applications, the authors should point it out. For example, it is legitimate
to point out that an improvement in the quality of generative models could be used to
generate deepfakes for disinformation. On the other hand, it is not needed to point out
that a generic algorithm for optimizing neural networks could enable people to train
models that generate Deepfakes faster.
•The authors should consider possible harms that could arise when the technology is
being used as intended and functioning correctly, harms that could arise when the
technology is being used as intended but gives incorrect results, and harms following
from (intentional or unintentional) misuse of the technology.
•If there are negative societal impacts, the authors could also discuss possible mitigation
strategies (e.g., gated release of models, providing defenses in addition to attacks,
mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
feedback over time, improving the efficiency and accessibility of ML).
11.Safeguards
Question: Does the paper describe safeguards that have been put in place for responsible
release of data or models that have a high risk for misuse (e.g., pretrained language models,
image generators, or scraped datasets)?
Answer: [NA]
Justification: [NA]
Guidelines:
• The answer NA means that the paper poses no such risks.
•Released models that have a high risk for misuse or dual-use should be released with
necessary safeguards to allow for controlled use of the model, for example by requiring
that users adhere to usage guidelines or restrictions to access the model or implementing
safety filters.
•Datasets that have been scraped from the Internet could pose safety risks. The authors
should describe how they avoided releasing unsafe images.
•We recognize that providing effective safeguards is challenging, and many papers do
not require this, but we encourage authors to take this into account and make a best
faith effort.
12.Licenses for existing assets
34Question: Are the creators or original owners of assets (e.g., code, data, models), used in
the paper, properly credited and are the license and terms of use explicitly mentioned and
properly respected?
Answer: [Yes]
Justification: The creators or original owners of assets are properly credited, and the license
and terms of use are explicitly mentioned and respected in the paper.
Guidelines:
• The answer NA means that the paper does not use existing assets.
• The authors should cite the original paper that produced the code package or dataset.
•The authors should state which version of the asset is used and, if possible, include a
URL.
• The name of the license (e.g., CC-BY 4.0) should be included for each asset.
•For scraped data from a particular source (e.g., website), the copyright and terms of
service of that source should be provided.
•If assets are released, the license, copyright information, and terms of use in the
package should be provided. For popular datasets, paperswithcode.com/datasets
has curated licenses for some datasets. Their licensing guide can help determine the
license of a dataset.
•For existing datasets that are re-packaged, both the original license and the license of
the derived asset (if it has changed) should be provided.
•If this information is not available online, the authors are encouraged to reach out to
the asset’s creators.
13.New Assets
Question: Are new assets introduced in the paper well documented and is the documentation
provided alongside the assets?
Answer: [Yes]
Justification: We provide a complete document of our code.
Guidelines:
• The answer NA means that the paper does not release new assets.
•Researchers should communicate the details of the dataset/code/model as part of their
submissions via structured templates. This includes details about training, license,
limitations, etc.
•The paper should discuss whether and how consent was obtained from people whose
asset is used.
•At submission time, remember to anonymize your assets (if applicable). You can either
create an anonymized URL or include an anonymized zip file.
14.Crowdsourcing and Research with Human Subjects
Question: For crowdsourcing experiments and research with human subjects, does the paper
include the full text of instructions given to participants and screenshots, if applicable, as
well as details about compensation (if any)?
Answer: [NA]
Justification: [NA]
Guidelines:
•The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
35•Including this information in the supplemental material is fine, but if the main contribu-
tion of the paper involves human subjects, then as much detail as possible should be
included in the main paper.
•According to the NeurIPS Code of Ethics, workers involved in data collection, curation,
or other labor should be paid at least the minimum wage in the country of the data
collector.
15.Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
Subjects
Question: Does the paper describe potential risks incurred by study participants, whether
such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
approvals (or an equivalent approval/review based on the requirements of your country or
institution) were obtained?
Answer: [NA]
Justification: [NA]
Guidelines:
•The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
•Depending on the country in which research is conducted, IRB approval (or equivalent)
may be required for any human subjects research. If you obtained IRB approval, you
should clearly state this in the paper.
•We recognize that the procedures for this may vary significantly between institutions
and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
guidelines for their institution.
•For initial submissions, do not include any information that would break anonymity (if
applicable), such as the institution conducting the review.
36