Online Convex Optimisation:
The Optimal Switching Regret for all Segmentations
Simultaneously
Stephen Pasteris
The Alan Turing Institute
London UK
spasteris@turing.ac.ukChris Hicks
The Alan Turing Institute
London UK
c.hicks@turing.ac.ukVasilios Mavroudis
The Alan Turing Institute
London UK
vmavroudis@turing.ac.uk
Mark Herbster
University College London
London UK
m.herbster@cs.ucl.ac.uk
Abstract
We consider the classic problem of online convex optimisation. Whereas the notion
of static regret is relevant for stationary problems, the notion of switching regret is
more appropriate for non-stationary problems. A switching regret is defined relative
to any segmentation of the trial sequence, and is equal to the sum of the static
regrets of each segment. In this paper we show that, perhaps surprisingly, we can
achieve the asymptotically optimal switching regret on every possible segmentation
simultaneously. Our algorithm for doing so is very efficient: having a space and
per-trial time complexity that is logarithmic in the time-horizon. Our algorithm
also obtains novel bounds on its dynamic regret: being adaptive to variations in the
rate of change of the comparator sequence.
1 Introduction
We consider the classic problem of online convex optimisation: a problem with numerous real-world
applications. In this problem we have an action set which is a bounded convex subset of some
euclidean space. On each trial we select an action from this set and then receive a convex function of
bounded gradient, which associates the action with a loss. The aim is to minimise the cumulative loss.
The static regret is defined as the cumulative loss of the algorithm minus that of the best constant
action in retrospect. It has been shown that the minimax static regret is Θ(√
T)where Tis the time
horizon, and that it is achieved by the classic mirror descent family of algorithms [ 2]. However,
in dynamic environments a more sensible notion of regret is the switching regret , which is defined
relative to any segmentation of the trial sequence and is equal to the sum of the static regrets over
all segments. Clearly, if the segmentation is known a-priori then the minimax switching regret is
Θ(P
k√Λk)where Λkis the length of the k-th segment, and it is obtained by running mirror descent
independently on each segment. Tracking algorithms , instead, attempt to bound the switching regret
on every possible segmentation of the trial sequence simultaneously. However, as far as we are aware,
the best such bound until now was O(P
kp
Λkln(T))which is a factor of O(p
ln(T))higher than
the optimal if we knew the segmentation a-priori. In this paper we (quite remarkably) get rid of
this factor: hence obtaining the asymptotically optimal switching regret of O(P
k√Λk)for every
possible segmentation simultaneously. Not only is our algorithm optimal, but it is also parameter-free
and efficient: having both a space and per-trial time complexity of O(ln(T)).
38th Conference on Neural Information Processing Systems (NeurIPS 2024).In fact, our algorithm RESETis a meta-algorithm which utilises any base algorithm for the online
convex optimisation problem at hand. Using online gradient descent [9] as our base algorithm gives
us the above O(P
k√Λk)switching regret bound. However, the constant under the Ois dependent
on the action set and the possible gradients. By choosing a more appropriate base algorithm that is
tailored to the specific problem we can achieve lower constant factors. In particular, when faced with
the classic problem of prediction with expert advice withNexperts, using Hedge [4] as our base
algorithm yields the asymptotically optimal O(ln(N)P
k√Λk)switching regret (a novel result in
itself).
We note that although, like strongly adaptive algorithms [ 3], we are adaptive to heterogeneous
segment lengths, we are not necessarily strongly adaptive: in that we do not bound the static regret
on any particular segment.
Whilst switching regret models discrete changes in the environment, a continuously changing envi-
ronment is better modeled by the notion of dynamic regret , which is the difference between the loss
of the algorithm and that of any comparator sequence of actions. It is known that algorithms exist
which bound the dynamic regret by O(p
(1 +P)T)where Pis the path length of the comparator
sequence. However, this bound is not adaptive to variations in the rate that the comparator sequence
is changing. RESET, with online gradient descent as the base algorithm, rectifies this: improving
the dynamic regret to O(P
kp
(1 +Pk)Λk)for any segmentation in which the path length in the
k-th segment is Pk. We note that this implies the O(P
k√Λk)bound on switching regret. However,
since we are forced to use online gradient descent as our base algorithm here, this result is not strictly
more general than our switching regret result.
Related works: Mirror descent was introduced in [ 2] to find minimisers of convex functions in
convex sets. The same algorithm, however, can also be applied to online convex optimisation: the
Hedge algorithm of [ 4] implementing a special case when the convex set is a simplex and the convex
functions are linear (the so-called experts problem). The O(√
T)static regret of Mirror descent
was shown to be optimal in [ 1]. The work [ 5] studied the non-stationary case in the experts setting:
modifying Hedge to give an algorithm Fixed share which takes a parameter Φand has a switching
regret of O(p
ΦTln(T/Φ))for any segmentation with Φsegments. One issue with Fixed share,
however, is that it does not adapt to heterogeneous segment lengths. In order to remedy this, [ 3]
gave a strongly adaptive algorithm which achieved a static regret of O(ln(T)√
Λ)on any segment of
length Λ. This was improved to O(p
ln(T)Λ)in [6]. The work [ 7] took parameters a, b∈Nand
achieved a static regret of O(p
(1 + ln( b/a))Λ) for any segment of length Λ∈[a, b]. However, this
still leads to a switching regret of O(P
kp
Λkln(T))for general segmentations. Our work finally
achieves the optimal O(P
k√Λk). The work [ 9] showed that gradient descent achieves a dynamic
regret of O(P√
T), which was improved to O(√
PT)in [8]. Our work dramatically improves on
this bound by being adaptive to variations in the rate of change of the comparator sequence.
Notation: LetNbe the set of natural numbers excluding 0. Given A∈Nwe define [A] :={a∈
N|a≤A}, we define ∆A:={a∈[0,1]A|P
i∈[A]ai= 1}, and we define ANto be the set of
natural numbers that are multiples of A. Given a predicate Pwe define JPK:= 0 ifPis false and
define JPK:= 1 ifPis true.
2 Problem and Results
In this section we introduce the online convex optimisation problem and state the results of this paper.
In particular we define and compare the notions of switching and dynamic regret, giving the bounds
obtained by our algorithm RESET. Another common notion of regret, not necessarily bounded by
RESET, is strongly adaptive regret which we discuss in Section 3.3.
2.1 Online Convex Optimisation
Here we describe the classic problem of online convex optimisation , which our algorithm RESET
solves. In this problem we have known bounded convex subsets X,Gof some euclidean space. We
define Lto be the set of all convex functions that map XintoRand whose sub-gradients lie in G.
The problem proceeds in Ttrials. On each trial t∈[T]the following happens:
21. We choose some action xt∈ X.
2. We receive some loss function ℓt∈ L.
Our aim is to minimise the cumulative loss:X
t∈[T]ℓt(xt).
Without loss of generality we shall assume that for all t∈[T]and all x∈ X we have ℓt(x)∈[0,1].
This is without loss of generality as both Xand the sub-gradients of ℓtare bounded and our algorithm
RESET, when using mirror descent as the base algorithm, is invariant to any constant addition to any
loss function. Also, without loss of generality, assume that Tis an integer power of two.
An example of online convex optimisation is prediction with expert advice . Here we have some
N∈Nand a set of Nexperts : where on each trial each expert is associated with a loss in [0,1]. On
each trial we must select an expert (incurring the loss associated with that expert) and then observe
the vector of losses for that trial. For this problem we choose X:= ∆ NandG:= [0,1]N. On each
trialtwe draw our expert from the probability vector xtand define the loss function ℓtto be the
linear function such that for all i∈[N]we have that ℓt(ei)(that is, the loss of the i-th basis element
ofRN) is the loss associated with expert ion trial t. Note that ℓt(xt)is our expected loss on trial t.
2.2 Switching Regret
We now define the notion of switching regret . Given any pair of trials q, s∈[T]withq≤swe define
thestatic regret on the segment of trials [q, s]by:
R(q, s) := max
x∗∈XsX
t=q(ℓt(xt)−ℓt(x∗))
which is the total loss incurred on the segment minus that which would have been obtained by always
choosing the best constant action in retrospect. A segmentation Sis defined as any sequence of the
form:
S=⟨σk|k∈[Φ + 1] ⟩ ⊆[T+ 1]
where:
σ1= 1 ; ∀k∈[Φ], σk+1> σk;σΦ+1=T+ 1.
Given such a segmentation S, we define, for all k∈[Φ], the k-thsegment ofSto be the set
[σk, σk+1−1], noting that the segments partition the set of trials [T]. The switching regret with
respect to such a segmentation Sis defined as:
R†(S) :=X
k∈[Φ]R(σk, σk+1−1)
which is the sum of the static regrets on each segment of S. Note that R†(S)is the total loss of
the algorithm minus that which would have been obtained by the best sequence of actions which is
constant over each segment of S. The following theorem establishes a lower bound on the switching
regret with respect to any fixed segmentation, even in the special case in which all the loss functions
are linear:
Theorem 2.1. For any segmentation:
S=⟨σk|k∈[Φ + 1] ⟩
and any algorithm for the online convex optimisation problem, there exists (except in trivial cases) a
sequence:
⟨ℓt|t∈[T]⟩ ⊆ L
of linear functions, in which:
R†(S)∈Ω
X
k∈[Φ]p
σk+1−σk

where the constant under the Ωis dependent only on XandG.
3Proof. Apply the static regret lower bound of [1] to each segment independently.
In this paper we develop an algorithm RESETwhich has an upper-bound that matches this lower
bound for every possible segmentation Ssimultaneously. RESETutilises any algorithm (called the
base algorithm ) for the online convex optimisation problem at hand. The base algorithm must take a
parameter Λ∈[T]and guarantee that R(1,Λ)∈ O(√
Λ)if it were used directly. We note that online
gradient descent [ 9] is always one such possibility. Computationally, to use online gradient descent,
we must be able to compute subgradients of the loss functions and euclidean projections into the set
X.
Theorem 2.2. Suppose γ∈Ris such that for all Λ∈[T], when the base algorithm is run with
parameter Λ, it is guaranteed that:
R(1,Λ)≤γ√
Λ.
Then for any segmentation:
S=⟨σk|k∈[Φ + 1] ⟩
RESETachieves a switching regret of:
R†(S)≤(cγ+d)X
k∈[Φ]p
σk+1−σk
where:
c:=√
2/(√
2−1) ; d:=p
8 ln(2) /(3−2√
2).
Proof. See Section 4.
Clearly, theorems 2.1 and 2.2 show that, for any fixed pair (X,G),RESEThas the asymptotically
optimal switching regret for every segmentation simultaneously. However, our result is stronger in
that if, for some family of pairs (X,G), the base algorithm has asymptotically optimal static regret
(for the entire family) then RESEThas the asymptotically optimal switching regret for the entire
family at once. An example is prediction with expert advice (described above) where utilising HEDGE
[4] as the base algorithm gives us γ∈ O(ln(N))which is asymptotically optimal (as proved in [ 1]).
RESET is also very efficient, as shown in the following theorem.
Theorem 2.3. Given that the base algorithm runs in a time of ξper trial and requires a space of ξ′,
RESEThas a per-trial time complexity of O(ξln(T))and space complexity of O(ξ′ln(T))
Proof. Immediate from the R ESET algorithm.
2.3 Dynamic Regret
Switching regret measures the performance of the algorithm against the best comparator sequence of
actions that is constant in each segment. Dynamic regret, on the other hand, measures the performance
of the algorithm against any comparator sequence. Specifically, given any sequence of actions:
E=⟨ϵt|t∈[T]⟩ ⊆ X
then the dynamic regret with respect to Eis defined as:
R∗(E) :=X
t∈[T](ℓt(xt)−ℓt(ϵt)).
To bound the dynamic regret of RESETwe introduce the following notion of path length . Specifically,
given the above sequence Eand trials q, s∈[T]withq≤s, the path length ofEin the segment
[q, s]is defined as:
P(E, q, s) =s−1X
t=q∥ϵt+1−ϵt∥2.
The current state of the art for dynamic regret is the algorithm ADER [8] which achieves a dynamic
regret of:
R∗(E)∈ Op
(1 +P(E,1, T))T
.
In this paper we significantly improve on this result, as shown in the following theorem.
4Theorem 2.4. When using online gradient descent [ 9] as the base algorithm, RESETachieves, for
any comparator sequence Eand any segmentation:
⟨σk|k∈[Φ + 1] ⟩
a dynamic regret of:
R∗(E)∈ O
X
k∈[Φ]p
(1 +P(E, σk, σk+1))(σk+1−σk)

where the constant under the Ois dependent only on XandG.
Proof. See Section 4
Note that, for any segmentation, the dynamic regret bound of RESETis asymptotically equal to that
of running ADER on each segment independently. To achieve this with ADER one would need to
know the specific segmentation a-priori. As for the switching regret, RESETachieves this for every
segmentation simultaneously. We note that our bound is a significant improvement on that of ADER
since it is adaptive to variation in the rate of change of the comparator sequence.
We note that, given a segmentation S=⟨σk|k∈[Φ + 1] ⟩, the switching regret R†(S)is equal
to the maximum dynamic regret R∗(E)across all sequences Ethat are constant in each segment.
For all k∈[Φ], the fact that such an Eis constant on [σk, σk+1−1]implies that the path length
P(E, σk, σk+1)is inO(1). This means that Theorem 2.4 implies the switching regret bound of
Theorem 2.2 up to a constant factor (dependent on γ,XandG). However, to obtain Theorem 2.4
we must use online gradient descent as our base algorithm. For some families of pairs (X,G)online
gradient descent is not asymptotically optimal for the entire family at once. An example is prediction
with expert advice, where Theorem 2.2 shows that we are asymptotically optimal for the entire family
at once when using HEDGE as the base algorithm. Hence, when concerned only with switching regret,
Theorem 2.2 is a stronger result.
3 The Algorithm
In this section we describe our algorithm RESET(Recursion over Segment Tree). We first introduce
the notation that we will use to describe the base algorithm.
3.1 The Base Algorithm
We now define the notation that we use to describe our base algorithm. The base algorithm utilises a
data-structure D(which contains the parameter) and is composed of the following three subrountines:
•Given Λ∈[T], the subroutine INITIALISE (Λ)returns the initial data-structure with parame-
terΛ.
•At the start of a trial, given the current data-structure D, the subroutine QUERY (D)returns
the output action of the base algorithm for that trial.
•At the end of a trial t, given the current data-structure Dand the loss function ℓt, the
subroutine U PDATE (D, ℓt)returns the updated data-structure (ready for the next trial).
The assumption in Theorem 2.2 implies the following. Suppose we have trials q, s∈[T]withs≥q,
and on each trial t∈[s, q]we do the following:
1. Ift=sthenDt←INITIALISE (q−s+ 1) .
2.wt←QUERY (Dt).
3.Dt+1←UPDATE (Dt, ℓt).
Then we have:
max
x∗∈XsX
t=q(ℓt(wt)−ℓt(x∗))≤γp
q−s+ 1. (1)
53.2 R ESET
We now introduce our algorithm R ESET. First let τ:= log2(T)and define the function
ψ:R×R×R×N→Rby:
ψ(ρ, a, b, Λ) :=ρexp(−ap
2 ln(2) /Λ)
ρexp(−ap
2 ln(2) /Λ) + (1 −ρ) exp(−bp
2 ln(2) /Λ).
The pseudocode of R ESET is given in Algorithm 1.
Algorithm 1 RESET
fori∈[τ]∪ {0}do
µi
1←1/2
Di
1←INITIALISE (2i)
end for
fort∈[T]do
fori∈[τ]∪ {0}do
wi
t←QUERY (Di
t)
end for
z0
t←w0
t
fori∈[τ]do
zi
t←µi
twi
t+ (1−µi
t)zi−1
t
end for
xt←zτ
t
fori∈[τ]∪ {0}do
ift∈2iNthen
µi
t+1←1/2
Di
t+1←INITIALISE (2i)
else
µi
t+1←ψ(µi
t, ℓt(wi
t), ℓt(zi−1
t),2i)
Di
t+1←UPDATE (Di
t, ℓt)
end if
end for
end for
We now describe RESET. We have a set of τ+ 1levels , where each level i∈[τ]∪ {0}hosts an
instance of the base algorithm, with parameter 2i. On each trial t, we denote the data-structure of
the base algorithm associated with level ibyDi
t. Each level also has an associated number in [0,1]
called the mixing weight . On each trial t, we denote the mixing weight associated with level ibyµi
t.
We note that the mixing weight µ0
tis not necessary.
We now describe the creation of the action xton trial t. Note first that each level i∈[τ]∪ {0}has an
associated action wi
twhich is defined as the output of QUERY (Di
t), so is the action selected by the
base algorithm for level ion trial t. We call these actions the base actions . The action xtis created
by the following recursive process. For each level iin order we construct an action zi
tcalled the
propagating action . This action is constructed by a convex combination of the preceding propagating
action zi−1
tand the base action wi
t. Specifically, we start by setting:
z0
t←w0
t
and then, for all levels i∈[τ], once zi−1
thas been constructed we set:
zi
t←µi
twi
t+ (1−µi
t)zi−1
t.
Finally, we output:
xt←zτ
t.
We now turn to the update at the end of trial t. For all levels i∈[τ]∪ {0}we have the following two
cases.
Ift∈2iNthen we set:
µi
t+1←1/2 ; Di
t+1←INITIALISE ( 2i)
6so that the mixing weight and instance of the base algorithm hosted by level iare reset. Note that the
parameter of the base algorithm is 2i. This is since it is reset every 2itrials.
On the other hand, if t /∈2iNthen we set:
µi
t+1←ψ(µi
t, ℓt(wi
t), ℓt(zi−1
t),2i) ; Di
t+1←UPDATE (Di
t, ℓt).
Note that the update of the mixing weight is based on the losses of wi
tandzi−1
t. Ifzi−1
thas a higher
loss than wi
t, in that the base action performs better than the lower-level propagating action, then the
mixing weight increases. This means that the weight of the base action, in the convex combination
forming the propagating action of level i, increases. If wi
thas a higher loss than zi−1
tthen the
opposite happens.
Figure 1 illustrates R ESET.
0123
0123
12345678
Figure 1: The R ESET algorithm with 8trials.
Left: The generation of the base actions and mixing weights. Purple numbers denote levels and black
numbers denote trials. Each segment (rectangle) in the figure runs an instance of the base algorithm
(generating the base actions). The mixing weights for each segment in the figure reset at the start of
each segment. Mixing weight updates are dependent on the segment length.
Right: The computation of the action xton trial t. Purple numbers denote levels. Blue balls denote
base actions, red balls denote mixing weights, and black balls denote propagating actions. The final
black arrow is the output xt.
3.3 Comparison to Strongly Adaptive Online Learner
RESEThas some similarities to the SAOL algorithm of [ 3]. Unlike RESET,SAOL isstrongly
adaptive , in that it bounds the static regret on any segment. Specifically, for any pair of trials
q, s∈[T]withq≤s, SAOL achieves:
R(q, s)∈ O
ln(T)p
q−s+ 1
.
This, however, leads to a switching regret bound that is a factor O(ln(T))off the optimal. This
additional factor was improved to O(p
ln(T))by [6].
Like RESET,SAOL hasτlevels and utilises a base algorithm which constructs, for every trial tand
level i, a base action wi
tin exactly the same way as RESET. It then generates, for each trial t, the
final action xtas a convex combination of the base actions. We note that in RESET, the action xtis
also a convex combination of the base actions, where for each level i∈[τ], the coefficient of wi
tis
equal to:
µi
tτY
j=i+1(1−µj
t).
The crucial difference between SAOL andRESETis that, whilst SAOL updates each coefficient in
the convex combination directly, the coefficients in RESETare updated by updating each mixing
weight directly. It is due to this, and the particular way that the mixing weights are updated, that
RESET attains, unlike SAOL, the optimal switching regret.
4 Analysis
Here we prove Theorem 2.2. We show how to modify this proof in order to prove Theorem 2.4 at the
end of this section. All lemmas stated in this section are proved in Appendix A.
7Choose any segmentation S=⟨σk|k∈[Φ+1] ⟩. We first define a comparator sequence ⟨ϵt|t∈[T]⟩
as follows. For all k∈[Φ]define the action:
˜ϵk:= argminx∗∈Xσk+1−1X
t=σkℓt(x∗)
and then, for all t∈[σk, σk+1−1], define ϵt:=˜ϵk. Note that:
R†(S) =X
t∈[T](ℓt(xt)−ℓt(ϵt)). (2)
In addition let α:= 2p
ln(2)/(√
2−1). With these definitions in hand we now begin the analysis.
4.1 Hedge
The updates for our mixing weights follow the classic algorithm HEDGE [4]. In particular, for each
leveli∈[τ]we maintain an instance of HEDGE (which restarts every 2itrials) with two experts . On
each trial t, the weight of the first expert is µi
tand the weight of the second is 1−µi
t. The loss of the
first expert is ℓt(wi
t)and the loss of the second is ℓt(zi−1
t). The action of the function ψis then to
update the weights according to the HEDGE algorithm. The following lemma is a classic result about
HEDGE .
Lemma 4.1. Given trials q, s∈[T]withq≤s, and a sequence ⟨(at, bt)|t∈[q, s]⟩such that for
allt∈[q, s]we have at, bt∈[0,1], and a sequence ⟨ρt|t∈[q, s]⟩defined recursively such that for
allt∈[q, s−1]we have:
ρq:= 1/2 ; ρt+1:=ψ(ρt, at, bt, s−q+ 1)
then we have:
sX
t=q(ρtat+ (1−ρt)bt)≤min(sX
t=qat,sX
t=qbt)
+p
2 ln(2)( s−q+ 1).
4.2 The Segment Tree
In this subsection we define the segment tree , which is the geometrical structure that our analysis
is based on. The segment tree is a full, balanced, binary tree Bwhose leaves are the elements of
[T]in order from left to right. Given any internal vertex v∈ B, let◁(v)and▷(v)be its left and
right child respectively. Given any vertex v∈ B, let◀(v)and▶(v)be its left-most and right-most
descendent respectively (noting that these are both elements of [T]). Let rbe the root of B. Given a
vertex v∈ B \ { r}, let↑(v)be the parent of v. Given a vertex v∈ B, leth(v)be equal to the height
ofv(that is, the height of the tree Bminus the depth of v, so that leaves have height 0).
Each vertex v∈ B represents the segment of trials [◀(v),▶(v)]. i.e. Each vertex represents a
segment in the left hand side of Figure 1 (when t= 8). We call a vertex v∈ Bstationary iff there
exists k∈[Φ]withσk≤◀(v)and▶(v)< σk+1. LetHbe the set of all stationary vertices. We call
a vertex v∈ B fundamental iff both:
•v∈ H .
•v=ror↑(v)/∈ H .
LetFbe the set of all fundamental vertices. We call a vertex v∈ Brelevant iff it is an ancestor of
a fundamental vertex. Let Abe the set of all relevant vertices. For all relevant vertices v∈ A we
define Q(v)to be the set of descendants of vthat are contained in F.
We have, from the algorithm, the following lemma about vertices in the segment tree:
Lemma 4.2. Given any vertex v∈ B we have:
▶(v)−◀(v) + 1 = 2h(v)
and:
µh(v)
◀(v)= 1/2 ; Dh(v)
◀(v)=INITIALISE ( 2h(v))
and for all t∈[◀(v),▶(v)−1]we have:
µh(v)
t+1=ψ
µh(v)
t, ℓt
wh(v)
t
, ℓt
zh(v)−1
t
,2h(v)
;Dh(v)
t+1=UPDATE
Dh(v)
t, ℓt
.
8Note that this lemma shows that for all v∈ B we run a single instance of both the base algorithm and
HEDGE over the segment [◀(v),▶(v)], as illustrated in Figure 1.
4.3 The Recursive Equations
We now derive the recursive equations that our analysis is based on. First note that for all v∈ F
there exists u∈ X such that ϵt=ufor all t∈[◀(v),▶(v)]. Hence, Lemma 4.2 and Equation (1),
and the fact that wh(v)
tis the output of Q UERY (Dh(v)
t), lead to the following lemma.
Lemma 4.3. For all v∈ F we have:
▶(v)X
t=◀(v)ℓt
wh(v)
t
≤▶(v)X
t=◀(v)ℓt(ϵt) +γp
2h(v).
Note that, from the algorithm and the convexity of the loss functions, we have, for all t∈[T]and all
v∈ B withh(v)̸= 0, that:
ℓt
zh(v)
t
≤µh(v)
tℓt
wh(v)
t
+
1−µh(v)
t
ℓt
zh(v)−1
t
.
So, by lemmas 4.2 and 4.1, we have the following lemma.
Lemma 4.4. For all vertices v∈ B withh(v)̸= 0we have:
▶(v)X
t=◀(v)ℓt
zh(v)
t
≤min

▶(v)X
t=◀(v)ℓt
wh(v)
t
,▶(v)X
t=◀(v)ℓt
zh(v)−1
t

+q
2 ln(2)2h(v).
Noting that z0
t=w0
tfor all t∈[T], lemmas 4.3 and 4.4 immediately imply the following recursive
equations. For all v∈ F we have:
▶(v)X
t=◀(v)ℓt
zh(v)
t
≤▶(v)X
t=◀(v)ℓt(ϵt) +
γ+p
2 ln(2)p
2h(v) (3)
and for all v∈ A \ F we have:
▶(v)X
t=◀(v)ℓt
zh(v)
t
≤▶(v)X
t=◀(v)ℓt
zh(v)−1
t
+q
2 ln(2)2h(v). (4)
4.4 Performing the Recursion
We now utilise equations (3)and(4)to perform the recursion. Specifically, we have the following
inductive hypothesis for vertices in A, which is proved by induction up the tree Bfrom the vertices
inFto the root. The reason it holds for vertices in Fcomes direct from Equation (3). For a vertex in
A \ F , once the inductive hypothesis has been shown to hold for both its children, it is then shown to
hold for the vertex itself by Equation (4). The inductive hypothesis is given in the following lemma.
Lemma 4.5. For all v∈ A we have:
▶(v)X
t=◀(v)ℓt(zh(v)
t)≤▶(v)X
t=◀(v)ℓt(ϵt) +X
q∈Q(v)
γ+p
2 ln(2)h(v)−h(q)X
k=0√
2−k
p
2h(q).
In particular, this inductive hypothesis holds for v=r. By Equation (2) this gives us the following.
Lemma 4.6. We have:
R†(S)≤(γ+α)X
q∈Fp
2h(q).
We now have a bound on the switching regret. It is, however, not yet written in terms of the
segment lengths. To write it in terms of the segment lengths we partition Finto a sequence of sets
⟨Fk|k∈[Φ]⟩such that, for all k∈[Φ], we define Fkto be equal to the set of all v∈ F such that
σk≤◀(v)and▶(v)< σk+1. We now have the following lemma.
9Lemma 4.7. For all k∈[Φ]we have:
X
v∈Fkp
2h(v)≤cp
σk+1−σk.
Combining lemmas 4.6 and 4.7 gives us:
R†(S)≤(γ+α)X
v∈Fp
2h(v)= (γ+α)X
k∈[Φ]X
v∈Fkp
2h(v)=c(γ+α)X
k∈[Φ]p
σk+1−σk
as required. This completes the proof of Theorem 2.2.
4.5 Dynamic Regret Analysis
We now prove Theorem 2.4. Let the base algorithm be online gradient descent as in [ 9]. Take any
segmentation ⟨ˆσj|j∈[Ψ + 1] ⟩and any comparator sequence E. Given any j∈[Ψ], note that we
can choose a natural number:
Nj≤1 +P(E,ˆσj,ˆσj+1)
and a sequence ⟨φj,i|i∈[Nj+ 1]⟩of trials such that φj,1= ˆσjandφj,Nj+1= ˆσj+1and for all
i∈[Nj], we have φj,i+1> φj,iand:
P(E, φj,i, φj,i+1)∈ O(1). (5)
Now concatenate the sequences ⟨φj,i|i∈[Nj]⟩for each j∈[Ψ]in order, to make a segmentation
⟨σk|k∈[Φ + 1] ⟩. Note that Equation (5) implies that for all k∈[Φ]we have:
P(E, σk, σk+1)∈ O(1). (6)
We now modify the analysis of the switching regret as follows. In the analysis of the switching regret
we defined a comparator sequence ⟨ϵt|t∈[T]⟩. In this analysis we instead define this comparator
sequence as equal to E. Using the segmentation ⟨σk|k∈[Φ + 1] ⟩, construct the segment tree and the
setsAandFas in the analysis of the switching regret. Since our base algorithm is gradient descent
we have, direct from [9], the following lemma.
Lemma 4.8. Suppose we have trials q, s∈[T]withs≥q, and on each trial t∈[s, q]we do the
following:
1. Ift=sthenDt←INITIALISE (q−s+ 1) .
2.wt←QUERY (Dt).
3.Dt+1←UPDATE (Dt, ℓt).
Then we have:sX
t=q(ℓt(wt)−ℓt(ϵt))∈ O
(1 +P(E, q, s))p
q−s+ 1
.
This lemma, along with Lemma 4.2 and Equation (6), gives us the following.
Lemma 4.9. For all v∈ F we have:
▶(v)X
t=◀(v)ℓt
wh(v)
t
≤▶(v)X
t=◀(v)ℓt(ϵt) +Op
2h(v)
.
This lemma is essentially identical to Lemma 4.3. Following the rest of the analysis of the switching
regret gives us:
R∗(E)∈ O
X
k∈[Φ]p
σk+1−σk
=O
X
j∈[Ψ]X
i∈[Nj]p
φj,i+1−φj,i
.
Since:X
i∈[Nj]p
φj,i+1−φj,i≤s
NjX
i∈[Nj](φj,i+1−φj,i) =q
Nj(ˆσj+1−ˆσj)
we have proved Theorem 2.4.
10Acknowledgements
Research funded by the Defence Science and Technology Laboratory (Dstl) which is an executive
agency of the UK Ministry of Defence providing world class expertise and delivering cutting-edge
science and technology for the benefit of the nation and allies. The research supports the Autonomous
Resilient Cyber Defence (ARCD) project within the Dstl Cyber Defence Enhancement programme.
References
[1]Jacob D. Abernethy, Alekh Agarwal, Peter L. Bartlett, and Alexander Rakhlin. A stochastic view
of optimal regret through minimax duality. ArXiv , abs/0903.5328, 2009.
[2]Charles E. Blair. Problem complexity and method efficiency in optimization (a. s. nemirovsky
and d. b. yudin). Siam Review , 27:264–265, 1985.
[3]Amit Daniely, Alon Gonen, and Shai Shalev-Shwartz. Strongly adaptive online learning. ArXiv ,
abs/1502.07073, 2015.
[4]Yoav Freund and Robert E. Schapire. A decision-theoretic generalization of on-line learning and
an application to boosting. In European Conference on Computational Learning Theory , 1997.
[5]Mark Herbster and Manfred K. Warmuth. Tracking the best expert. Machine Learning , 32:151–
178, 1995.
[6]Kwang-Sung Jun, Francesco Orabona, Stephen J. Wright, and Rebecca M. Willett. Improved
strongly adaptive online learning using coin betting. In International Conference on Artificial
Intelligence and Statistics , 2016.
[7]Yuanyu Wan, TU Wei-Wei, and Lijun Zhang. Strongly adaptive online learning over partial
intervals. Science China Information Sciences , 65, 2022.
[8]Lijun Zhang, Shiyin Lu, and Zhi-Hua Zhou. Adaptive online learning in dynamic environments.
ArXiv , abs/1810.10815, 2018.
[9]Martin A. Zinkevich. Online convex programming and generalized infinitesimal gradient ascent.
InInternational Conference on Machine Learning , 2003.
A Proofs
Here we prove, in order, all the lemmas in the analysis.
A.1 Lemma 4.1
Direct from [4] using only two experts, were, on each trial t, we have that:
• The loss of the first expert is atand the loss of the second is bt.
• The weight of the first expert is ρtand the weight of the second is 1−ρt.
A.2 Lemma 4.2
The equality:
▶(v)−◀(v) + 1 = 2h(v)
comes directly from the definition of h(v). We also have that:
◀(v)−1∈2h(v)N
and for all t∈[◀(v),▶(v)−1]we have:
t /∈2h(v)N.
Hence, by the algorithm, the lemma holds.
11A.3 Lemma 4.3
Note first that, since wh(v)
tis the output of QUERY (Dh(v)
t), Lemma 4.2 and Equation (1)immediately
give us:
max
x∗∈X▶(v)X
t=◀(v)
ℓt
wh(v)
t
−ℓt(x∗)
≤γp
2h(v). (7)
Since v∈ F we have that v∈ H so there exists k∈[Φ]withσk≤◀(v)and▶(v)< σk+1. This
implies that for all t∈[◀(v),▶(v)]we have t∈[σk, σk+1−1]so that ϵt:=˜ϵk. Hence, we have:
min
x∗∈X▶(v)X
t=◀(v)ℓt(x∗)≤▶(v)X
t=◀(v)ℓt(˜ϵk) =▶(v)X
t=◀(v)ℓt(ϵt).
Substituting into Equation (7) gives us the result.
A.4 Lemma 4.4
Consider Lemma 4.1. In this lemma choose q:=◀(v)ands:=▶(v). For all t∈[q, s]choose:
at:=ℓt
wh(v)
t
;bt:=ℓt
zh(v)−1
t
.
Then by Lemma 4.2 we have, for all t∈[q, s], that:
ρt=µh(v)
t
so that, by the algorithm and the convexity of the loss functions we have, for all t∈[q, s], that:
ℓt
zh(v)
t
≤µh(v)
tℓt
wh(v)
t
+
1−µh(v)
t
ℓt
zh(v)−1
t
=ρtat+ (1−ρt)bt
and hence, by Lemma 4.1, we have:
sX
t=qℓt
zh(v)
t
≤min(sX
t=qat,sX
t=qbt)
+p
2 ln(2)( s−q+ 1).
The result then follows from the fact that, by Lemma 4.2, we have s−q+ 1 = 2h(v).
A.5 Lemma 4.5
Fori, j∈N∪ {0}withj≥iwe define:
λj
i:=j−iX
k=0√
2−k
so our inductive hypothesis is that for all v∈ A we have:
▶(v)X
t=◀(v)ℓt
zh(v)
t
≤▶(v)X
t=◀(v)ℓt(ϵt) +X
q∈Q(v)
γ+λh(v)
h(q)p
2 ln(2)p
2h(q).
Ifv∈ F then, by the definition of F, we have Q(v) ={v}so the inductive hypothesis holds by
Equation (3). Now suppose we have some ˜v∈ A \ F . Note that, by the definition of F, we have
◁(˜v), ▷(˜v)∈ A so all that is left to prove the inductive hypothesis is to prove that, if the inductive
hypothesis holds for both v=◁(˜v)andv=▷(˜v), then it also holds for v= ˜v. So suppose that the
inductive hypothesis holds for v=◁(˜v)andv=▷(˜v). First note that:
▶(˜v)X
t=◀(˜v)ℓt
zh(˜v)−1
t
=▶(◁(˜v))X
t=◀(◁(˜v))ℓt
zh(◁(˜v))
t
+▶(▷(˜v))X
t=◀(▷(˜v))ℓt
zh(▷(˜v))
t
(8)
12and, by the definition of F, we have:
X
q∈Q(˜v)2h(q)= 2h(˜v)
so that:
X
q∈Q(˜v)p
2h(q)p
2h(q)−h(˜v)=p
2−h(˜v)X
q∈Q(˜v)2h(q)= 2h(˜v)p
2−h(˜v)=p
2h(˜v). (9)
Equations (4), (8) and (9), imply:
▶(˜v)X
t=◀(˜v)ℓt
zh(˜v)
t
≤▶(◁(˜v))X
t=◀(◁(˜v))ℓt
zh(◁(˜v))
t
+▶(▷(˜v))X
t=◀(▷(˜v))ℓt
zh(▷(˜v))
t
+p
2 ln(2)X
q∈Q(˜v)p
2h(q)p
2h(q)−h(˜v).
Applying the inductive hypothesis to the terms:
▶(◁(˜v))X
t=◀(◁(˜v))ℓt
zh(◁(˜v))
t
:▶(▷(˜v))X
t=◀(▷(˜v))ℓt
zh(▷(˜v))
t
and noting that Q(˜v) =Q(◁(˜v))∪ Q(▷(˜v))and for all q∈ Q(˜v)we have:
λh(˜v)
h(q)=λh(◁(˜v))
h(q)+p
2h(q)−h(˜v)=λh(▷(˜v))
h(q)+p
2h(q)−h(˜v)
shows the inductive hypothesis holds for v= ˜v. We have hence proved that the inductive hypothesis
holds for all v∈ A.
A.6 Lemma 4.6
For all q∈ Q(r)we have:
h(r)−h(q)X
k=0√
2−k≤∞X
k=0√
2−k=√
2/(√
2−1) = α/p
2 ln(2)
so, since r∈ A andQ(r) =F, Lemma 4.5 gives us:
▶(r)X
t=◀(r)ℓt(zh(r)
t)≤▶(r)X
t=◀(r)ℓt(ϵt) + (γ+α)X
q∈Fp
2h(q).
Since◀(r) = 1 ,▶(r) =Tand, by the algorithm, zh(r)
t=zτ
t=xtfor all t∈[T], we then have,
by Equation (2), that:
R†(S)≤(γ+α)X
q∈Fp
2h(q)
as required.
A.7 Lemma 4.7
First let:
ξ:= 1/(√
2−1).
We take the inductive hypothesis that for all non-empty finite sets Z ⊆N∪ {0}we have:
X
k∈Z√
2k≤ξsX
k∈Z2k (10)
13and we prove by induction on |Z|. In the case that |Z|= 1we have Z={i}for some i∈N∪ {0}
and hence:X
k∈Z√
2k=√
2i< ξ√
2i=ξsX
k∈Z2k
so the inductive hypothesis holds for |Z|= 1. Now suppose we have some j∈Nand that the
inductive hypothesis holds for |Z|=j. We now show that it holds for |Z|=j+ 1which will prove
that the inductive hypothesis holds always. Specifically, let i:= max Z, letZ′:=Z \ { i}and let
i′:= max Z′. Define:
y:= 2−iX
k∈Z′2k.
Note that:
X
k∈Z′2k≤i′X
k=02k<2i′+1≤2i
so that y <1and hence:p
1 +y−√y≥√
1 + 1−√
1 =√
2−1 = 1 /ξ
since the term on the left is monotonic decreasing with y. This implies that:
sX
k∈Z2k=s
2i+X
k∈Z′2k=√
2ip
1 +y≥√
2i√y+1
ξ
=sX
k∈Z′2k+√
2i
ξ
so that, by the inductive hypothesis (applied to the set Z′), we have:
sX
k∈Z2k≥1
ξX
k∈Z′√
2k+√
2i
ξ=1
ξX
k∈Z√
2k
so the inductive hypothesis holds for |Z|=j+1. We have hence proved that the inductive hypothesis
holds always.
Now note that, by the definition of F, we have:X
v∈Fk2h(v)=σk+1−σk. (11)
Assume, for contradiction, that there exists three distinct vertices v, v′, v′′∈ Fkwithh(v) =h(v′) =
h(v′′). Without loss of generality assume that vandv′′are the leftmost and rightmost of the three
vertices respectively. Also without loss of generality assume that v′is the right child of its parent
↑(v′). Then vmust either be equal to or lie to the left of the left child of ↑(v′)and hence:
◀(↑(v′))≥◀(v)≥σk
and
▶(↑(v′)) =▶(v′)< σk+1
so that ↑(v′)∈ H. But this contradicts the fact that v′∈ F.
We have hence shown that for any i∈[τ]∪ {0}there are at most two distinct vertices v, v′∈ Fk
withh(v) =h(v′) =i. This means that we can partition Fkinto two disjoint sets UkandVksuch
that for all i∈[τ]∪ {0}there exists at most one element vofUkwithh(v) =iand at most one
element v′ofVkwithh(v′) =i. By Equation (10) we then have:
X
v∈Ukp
2h(v)≤ξsX
v∈Uk2h(v);X
v∈Vkp
2h(v)≤ξsX
v∈Vk2h(v)
so that:X
v∈Fkp
2h(v)≤ξsX
v∈Uk2h(v)+ξsX
v∈Vk2h(v).
Noting that for all y, y′>0we have√y+√y′≤√
2√y+y′andc=ξ√
2, the above inequality,
along with Equation (11), gives us:
X
v∈Fkp
2h(v)≤csX
v∈Fk2h(v)=cp
σk+1−σk
as required.
14A.8 Lemma 4.8
Direct from [9].
A.9 Lemma 4.9
By lemmas 4.2 and 4.8 we immediately have that:
▶(v)X
t=◀(v)
ℓt
wh(v)
t
−ℓt(ϵt)
∈ O
(1 +P(E,◀(v),▶(v)))p
2h(v)
. (12)
Since v∈ F we have that there exists k∈[Φ]such that ◀(v)≥σkand▶(v)< σk+1. Hence, by
Equation (6) , we have that:
P(E,◀(v),▶(v))≤P(E, σk, σk+1)∈ O(1).
Substituting into Equation (12) gives us the result.
15NeurIPS Paper Checklist
1.Claims
Question: Do the main claims made in the abstract and introduction accurately reflect the
paper’s contributions and scope?
Answer: [Yes]
Justification: The main claims made in the abstract and introduction accurately reflect the
paper’s contributions and scope.
Guidelines:
•The answer NA means that the abstract and introduction do not include the claims
made in the paper.
•The abstract and/or introduction should clearly state the claims made, including the
contributions made in the paper and important assumptions and limitations. A No or
NA answer to this question will not be perceived well by the reviewers.
•The claims made should match theoretical and experimental results, and reflect how
much the results can be expected to generalize to other settings.
•It is fine to include aspirational goals as motivation as long as it is clear that these goals
are not attained by the paper.
2.Limitations
Question: Does the paper discuss the limitations of the work performed by the authors?
Answer: [NA]
Justification: Our algorithm always achieves the stated bounds on regret and time-complexity
and (when using the doubling trick) is parameter free.
Guidelines:
•The answer NA means that the paper has no limitation while the answer No means that
the paper has limitations, but those are not discussed in the paper.
• The authors are encouraged to create a separate "Limitations" section in their paper.
•The paper should point out any strong assumptions and how robust the results are to
violations of these assumptions (e.g., independence assumptions, noiseless settings,
model well-specification, asymptotic approximations only holding locally). The authors
should reflect on how these assumptions might be violated in practice and what the
implications would be.
•The authors should reflect on the scope of the claims made, e.g., if the approach was
only tested on a few datasets or with a few runs. In general, empirical results often
depend on implicit assumptions, which should be articulated.
•The authors should reflect on the factors that influence the performance of the approach.
For example, a facial recognition algorithm may perform poorly when image resolution
is low or images are taken in low lighting. Or a speech-to-text system might not be
used reliably to provide closed captions for online lectures because it fails to handle
technical jargon.
•The authors should discuss the computational efficiency of the proposed algorithms
and how they scale with dataset size.
•If applicable, the authors should discuss possible limitations of their approach to
address problems of privacy and fairness.
•While the authors might fear that complete honesty about limitations might be used by
reviewers as grounds for rejection, a worse outcome might be that reviewers discover
limitations that aren’t acknowledged in the paper. The authors should use their best
judgment and recognize that individual actions in favor of transparency play an impor-
tant role in developing norms that preserve the integrity of the community. Reviewers
will be specifically instructed to not penalize honesty concerning limitations.
3.Theory Assumptions and Proofs
Question: For each theoretical result, does the paper provide the full set of assumptions and
a complete (and correct) proof?
16Answer: [Yes]
Justification: All theorems are either referenced or proved.
Guidelines:
• The answer NA means that the paper does not include theoretical results.
•All the theorems, formulas, and proofs in the paper should be numbered and cross-
referenced.
•All assumptions should be clearly stated or referenced in the statement of any theorems.
•The proofs can either appear in the main paper or the supplemental material, but if
they appear in the supplemental material, the authors are encouraged to provide a short
proof sketch to provide intuition.
•Inversely, any informal proof provided in the core of the paper should be complemented
by formal proofs provided in appendix or supplemental material.
• Theorems and Lemmas that the proof relies upon should be properly referenced.
4.Experimental Result Reproducibility
Question: Does the paper fully disclose all the information needed to reproduce the main ex-
perimental results of the paper to the extent that it affects the main claims and/or conclusions
of the paper (regardless of whether the code and data are provided or not)?
Answer: [NA]
Justification: This paper does not include experiments.
Guidelines:
• The answer NA means that the paper does not include experiments.
•If the paper includes experiments, a No answer to this question will not be perceived
well by the reviewers: Making the paper reproducible is important, regardless of
whether the code and data are provided or not.
•If the contribution is a dataset and/or model, the authors should describe the steps taken
to make their results reproducible or verifiable.
•Depending on the contribution, reproducibility can be accomplished in various ways.
For example, if the contribution is a novel architecture, describing the architecture fully
might suffice, or if the contribution is a specific model and empirical evaluation, it may
be necessary to either make it possible for others to replicate the model with the same
dataset, or provide access to the model. In general. releasing code and data is often
one good way to accomplish this, but reproducibility can also be provided via detailed
instructions for how to replicate the results, access to a hosted model (e.g., in the case
of a large language model), releasing of a model checkpoint, or other means that are
appropriate to the research performed.
•While NeurIPS does not require releasing code, the conference does require all submis-
sions to provide some reasonable avenue for reproducibility, which may depend on the
nature of the contribution. For example
(a)If the contribution is primarily a new algorithm, the paper should make it clear how
to reproduce that algorithm.
(b)If the contribution is primarily a new model architecture, the paper should describe
the architecture clearly and fully.
(c)If the contribution is a new model (e.g., a large language model), then there should
either be a way to access this model for reproducing the results or a way to reproduce
the model (e.g., with an open-source dataset or instructions for how to construct
the dataset).
(d)We recognize that reproducibility may be tricky in some cases, in which case
authors are welcome to describe the particular way they provide for reproducibility.
In the case of closed-source models, it may be that access to the model is limited in
some way (e.g., to registered users), but it should be possible for other researchers
to have some path to reproducing or verifying the results.
5.Open access to data and code
17Question: Does the paper provide open access to the data and code, with sufficient instruc-
tions to faithfully reproduce the main experimental results, as described in supplemental
material?
Answer: [NA]
Justification: This paper does not include experiments.
Guidelines:
• The answer NA means that paper does not include experiments requiring code.
•Please see the NeurIPS code and data submission guidelines ( https://nips.cc/
public/guides/CodeSubmissionPolicy ) for more details.
•While we encourage the release of code and data, we understand that this might not be
possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not
including code, unless this is central to the contribution (e.g., for a new open-source
benchmark).
•The instructions should contain the exact command and environment needed to run to
reproduce the results. See the NeurIPS code and data submission guidelines ( https:
//nips.cc/public/guides/CodeSubmissionPolicy ) for more details.
•The authors should provide instructions on data access and preparation, including how
to access the raw data, preprocessed data, intermediate data, and generated data, etc.
•The authors should provide scripts to reproduce all experimental results for the new
proposed method and baselines. If only a subset of experiments are reproducible, they
should state which ones are omitted from the script and why.
•At submission time, to preserve anonymity, the authors should release anonymized
versions (if applicable).
•Providing as much information as possible in supplemental material (appended to the
paper) is recommended, but including URLs to data and code is permitted.
6.Experimental Setting/Details
Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
results?
Answer: [NA]
Justification: This paper does not include experiments.
Guidelines:
• The answer NA means that the paper does not include experiments.
•The experimental setting should be presented in the core of the paper to a level of detail
that is necessary to appreciate the results and make sense of them.
•The full details can be provided either with the code, in appendix, or as supplemental
material.
7.Experiment Statistical Significance
Question: Does the paper report error bars suitably and correctly defined or other appropriate
information about the statistical significance of the experiments?
Answer: [NA]
Justification: This paper does not include experiments.
Guidelines:
• The answer NA means that the paper does not include experiments.
•The authors should answer "Yes" if the results are accompanied by error bars, confi-
dence intervals, or statistical significance tests, at least for the experiments that support
the main claims of the paper.
•The factors of variability that the error bars are capturing should be clearly stated (for
example, train/test split, initialization, random drawing of some parameter, or overall
run with given experimental conditions).
•The method for calculating the error bars should be explained (closed form formula,
call to a library function, bootstrap, etc.)
18• The assumptions made should be given (e.g., Normally distributed errors).
•It should be clear whether the error bar is the standard deviation or the standard error
of the mean.
•It is OK to report 1-sigma error bars, but one should state it. The authors should
preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis
of Normality of errors is not verified.
•For asymmetric distributions, the authors should be careful not to show in tables or
figures symmetric error bars that would yield results that are out of range (e.g. negative
error rates).
•If error bars are reported in tables or plots, The authors should explain in the text how
they were calculated and reference the corresponding figures or tables in the text.
8.Experiments Compute Resources
Question: For each experiment, does the paper provide sufficient information on the com-
puter resources (type of compute workers, memory, time of execution) needed to reproduce
the experiments?
Answer: [NA]
Justification: This paper does not include experiments.
Guidelines:
• The answer NA means that the paper does not include experiments.
•The paper should indicate the type of compute workers CPU or GPU, internal cluster,
or cloud provider, including relevant memory and storage.
•The paper should provide the amount of compute required for each of the individual
experimental runs as well as estimate the total compute.
•The paper should disclose whether the full research project required more compute
than the experiments reported in the paper (e.g., preliminary or failed experiments that
didn’t make it into the paper).
9.Code Of Ethics
Question: Does the research conducted in the paper conform, in every respect, with the
NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines ?
Answer: [Yes]
Justification: This paper conforms to the code of ethics.
Guidelines:
•The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
•If the authors answer No, they should explain the special circumstances that require a
deviation from the Code of Ethics.
•The authors should make sure to preserve anonymity (e.g., if there is a special consid-
eration due to laws or regulations in their jurisdiction).
10.Broader Impacts
Question: Does the paper discuss both potential positive societal impacts and negative
societal impacts of the work performed?
Answer: [NA]
Justification: This work is theoretical in nature and we cannot foresee any societal impacts.
Guidelines:
• The answer NA means that there is no societal impact of the work performed.
•If the authors answer NA or No, they should explain why their work has no societal
impact or why the paper does not address societal impact.
•Examples of negative societal impacts include potential malicious or unintended uses
(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
(e.g., deployment of technologies that could make decisions that unfairly impact specific
groups), privacy considerations, and security considerations.
19•The conference expects that many papers will be foundational research and not tied
to particular applications, let alone deployments. However, if there is a direct path to
any negative applications, the authors should point it out. For example, it is legitimate
to point out that an improvement in the quality of generative models could be used to
generate deepfakes for disinformation. On the other hand, it is not needed to point out
that a generic algorithm for optimizing neural networks could enable people to train
models that generate Deepfakes faster.
•The authors should consider possible harms that could arise when the technology is
being used as intended and functioning correctly, harms that could arise when the
technology is being used as intended but gives incorrect results, and harms following
from (intentional or unintentional) misuse of the technology.
•If there are negative societal impacts, the authors could also discuss possible mitigation
strategies (e.g., gated release of models, providing defenses in addition to attacks,
mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
feedback over time, improving the efficiency and accessibility of ML).
11.Safeguards
Question: Does the paper describe safeguards that have been put in place for responsible
release of data or models that have a high risk for misuse (e.g., pretrained language models,
image generators, or scraped datasets)?
Answer: [NA]
Justification: This work is theoretical in nature and we cannot foresee any risks.
Guidelines:
• The answer NA means that the paper poses no such risks.
•Released models that have a high risk for misuse or dual-use should be released with
necessary safeguards to allow for controlled use of the model, for example by requiring
that users adhere to usage guidelines or restrictions to access the model or implementing
safety filters.
•Datasets that have been scraped from the Internet could pose safety risks. The authors
should describe how they avoided releasing unsafe images.
•We recognize that providing effective safeguards is challenging, and many papers do
not require this, but we encourage authors to take this into account and make a best
faith effort.
12.Licenses for existing assets
Question: Are the creators or original owners of assets (e.g., code, data, models), used in
the paper, properly credited and are the license and terms of use explicitly mentioned and
properly respected?
Answer: [NA]
Justification: This paper does not use existing assets.
Guidelines:
• The answer NA means that the paper does not use existing assets.
• The authors should cite the original paper that produced the code package or dataset.
•The authors should state which version of the asset is used and, if possible, include a
URL.
• The name of the license (e.g., CC-BY 4.0) should be included for each asset.
•For scraped data from a particular source (e.g., website), the copyright and terms of
service of that source should be provided.
•If assets are released, the license, copyright information, and terms of use in the
package should be provided. For popular datasets, paperswithcode.com/datasets
has curated licenses for some datasets. Their licensing guide can help determine the
license of a dataset.
•For existing datasets that are re-packaged, both the original license and the license of
the derived asset (if it has changed) should be provided.
20•If this information is not available online, the authors are encouraged to reach out to
the asset’s creators.
13.New Assets
Question: Are new assets introduced in the paper well documented and is the documentation
provided alongside the assets?
Answer: [NA]
Justification: This paper does not release new assets.
Guidelines:
• The answer NA means that the paper does not release new assets.
•Researchers should communicate the details of the dataset/code/model as part of their
submissions via structured templates. This includes details about training, license,
limitations, etc.
•The paper should discuss whether and how consent was obtained from people whose
asset is used.
•At submission time, remember to anonymize your assets (if applicable). You can either
create an anonymized URL or include an anonymized zip file.
14.Crowdsourcing and Research with Human Subjects
Question: For crowdsourcing experiments and research with human subjects, does the paper
include the full text of instructions given to participants and screenshots, if applicable, as
well as details about compensation (if any)?
Answer: [NA]
Justification: This paper does not involve crowdsourcing nor research with human subjects.
Guidelines:
•The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
•Including this information in the supplemental material is fine, but if the main contribu-
tion of the paper involves human subjects, then as much detail as possible should be
included in the main paper.
•According to the NeurIPS Code of Ethics, workers involved in data collection, curation,
or other labor should be paid at least the minimum wage in the country of the data
collector.
15.Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
Subjects
Question: Does the paper describe potential risks incurred by study participants, whether
such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
approvals (or an equivalent approval/review based on the requirements of your country or
institution) were obtained?
Answer: [NA]
Justification: This paper does not involve crowdsourcing nor research with human subjects.
Guidelines:
•The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
•Depending on the country in which research is conducted, IRB approval (or equivalent)
may be required for any human subjects research. If you obtained IRB approval, you
should clearly state this in the paper.
•We recognize that the procedures for this may vary significantly between institutions
and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
guidelines for their institution.
•For initial submissions, do not include any information that would break anonymity (if
applicable), such as the institution conducting the review.
21