Avoiding Undesired Future with Minimal Cost
in Non-Stationary Environments
Wen-Bo Du, Tian Qin, Tian-Zuo Wang, Zhi-Hua Zhou
National Key Laboratory for Novel Software Technology, Nanjing University, China
School of Artiﬁcial Intelligence, Nanjing University, China
{duwb, qint, wangtz, zhouzh}@lamda.nju.edu.cn
Abstract
Machine learning (ML) has achieved remarkable success in prediction tasks. In
many real-world scenarios, rather than solely predicting an outcome using an ML
model, the crucial concern is how to make decisions to prevent the occurrence of
undesired outcomes, known as the avoiding undesired future (AUF) problem. To
this end, a new framework called rehearsal learning has been proposed recently,
which works effectively in stationary environments by leveraging the inﬂuence
relations among variables. In real tasks, however, the environments are usually
non-stationary, where the inﬂuence relations may be dynamic , leading to the failure
of AUF by the existing method. In this paper, we introduce a novel sequential
methodology that effectively updates the estimates of dynamic inﬂuence relations,
which are crucial for rehearsal learning to prevent undesired outcomes in non-
stationary environments. Meanwhile, we take the cost of decision actions into
account and provide the formulation of AUF problem with minimal action cost
under non-stationarity. We prove that in linear Gaussian cases, the problem can be
transformed into the well-studied convex quadratically constrained quadratic pro-
gram (QCQP). In this way, we establish the ﬁrst polynomial-time rehearsal-based
approach for addressing the AUF problem. Theoretical and experimental results
validate the effectiveness and efﬁciency of our method under certain circumstances.
1 Introduction
Machine learning (ML) models have found extensive application in prediction tasks [ 25]. However,
in contrast to a sole emphasis on prediction, it is preferred in many real-world scenarios to further
explore effective decisions if the predicted outcomes are undesired. For instance, imagine that a
factory manager has trained an ML model on features X(e.g., economic indicators) to predict the
outcome Y(e.g., monthly sales). Suppose at the beginning of a month, Yis predicted to be undesired,
i.e., the predicted sales of the month are lower than expected. In this case, the manager usually wants
to take action by altering some intermediate variables Zduring the month to avoid this undesired
outcome happening, e.g., modifying the discount to attract more customers. The problem of how to
ﬁnd effective actions in such situations is known as avoiding undesired future (AUF) [63].
It is worth noting that AUF tasks often involve limited opportunities for interaction with the decision
environment [ 63]. For instance, in the aforementioned example, the factory manager can only adjust
the selling strategy once per month. Therefore, decision-making algorithms that depend on numerous
interactions, such as conventional reinforcement learning (RL) methods [ 4], are not well-suited for
the AUF problem [ 40]. Additionally, fundamentally vital decisions need to be made with human
judgment, and therefore, it is desired to enable human decision-makers to understand why and how
some actions can change the outcome. Due to these challenges, the structural relations among
variables, which contain ﬁne-grained information and are usually interpretable, are worth being
considered to make decisions [36, 40].
38th Conference on Neural Information Processing Systems (NeurIPS 2024).CorrelationInﬂuenceActionableCausationPredictionDecisionDiscoveryFigure 1: Relationship among correlation,
inﬂuence, and causation [63].Causation is such a type of structural relation [ 36], which
has been leveraged for some decision-making prob-
lems [ 5,24,42,43]. Although causal relations can assist
to some extent, identifying them is challenging and gen-
erally relies on some untestable assumptions [ 49,44,28].
Besides, causation should not be viewed as a prereq-
uisite for decision-making problems, as humans can
usually make good decisions without a thorough causal
understanding [ 63]. Recognizing that correlation used
in prediction is inadequate for decision-making whereas causation is too luxurious to be relied on,
Zhou [63] emphasized the necessity of an intermediate relation that is stronger than correlation but
less demanding than causation; this relation was subsequently called inﬂuence relation [64]. The
relationship among correlation ,inﬂuence , and causation is illustrated in Fig. 1.
Based on the inﬂuence relations, Qin et al. [40] developed the ﬁrst rehearsal learning framework,
which can effectively suggest good decision actions for the AUF problem in stationary environments.
In practice, however, the method by Qin et al. [40] may lose its power when different decision
actions are associated with different costs or when the decision environment is non-stationary where
quantitative inﬂuence relations can vary. For example, modifying the discount into different levels
results in different expenses, and the quantitative inﬂuence relation between pricing and sales can
change seasonally for products such as the coat. Besides, it is worth mentioning that exact solutions
are intractable with any polynomial-time algorithm when considering decisions on multiple variables
in the previous work [ 40], thus exploring more efﬁcient approaches is necessary for the decision-
suggestion problem in the AUF problem.
To tackle these issues, in this paper, we propose the AUF-MICNS approach for the AUF problem with
minimal cost in non-stationary environments. AUF-MICNS considers a multi-round decision-making
process where it suggests decisions and collects feedback data during and after each decision round.
Note that although multiple decision rounds are allowed, the limited number of rounds may still
render RL methods ineffective [ 40]. In contrast to Qin et al. [40], we consider the non-stationary
fact that inﬂuence relations may vary over decision rounds, and therefore, treating the round-wise
collected data as i.i.d. samples for determining the inﬂuence relations is inappropriate. To this end, we
present a sequential approach to maintain dynamic inﬂuence relations in non-stationary environments,
and further propose an online-ensemble-based [ 60] sequential algorithm to deal with the unknown
degree of non-stationarity. In addition, we design a cost function to quantify the costs of different
decision actions. The cost function takes into account not only (a) different unit costs associated
with different variables, but also (b) the distinct costs involved in altering a single variable to varying
extents. Further, we expect that the suggested decisions can efﬁciently avoid undesired outcomes
with a relatively high probability. Rather than using the sampling-based method that cannot be
solved with any polynomial-time algorithm [ 40], we reveal that ﬁnding decision suggestions for AUF
with minimal action cost can be modeled as a convex quadratically constrained quadratic program
(QCQP), which is solvable in polynomial time O(jVj3)with respect to the number of variables
jVj. Combining the parts above, we prove that our proposed approach can (a) accurately capture
the dynamic inﬂuence relations with errors bounded by an exponentially decreasing term, and (b)
efﬁciently suggest effective decision actions with minimal cost for the AUF problem.
Our main contributions are summarized as follows.
1.We try to tackle the AUF problem with minimal cost in non-stationary environments. Our modeling
approach considers, for the ﬁrst time, the decision action cost and the non-stationary fact that
inﬂuence relations can vary over time in the AUF problem.
2.We present a novel sequential methodology to maintain dynamic inﬂuence relations. Theoretical
results guarantee that the estimate error can be bounded by an exponentially decreasing term, as
well as a ﬁxed small value related to the problem difﬁculty.
3.We develop the AUF-MICNS algorithm, which is the ﬁrst polynomial time rehearsal-based
approach that can suggest effective decision actions for the formulated AUF problem. Our
experimental results validate the effectiveness and efﬁciency of the method.
Organization. In Sec. 2, we review basic concepts and introduce our notation. In Sec. 3, we provide
the formulation of AUF problem and provide the AUF-MICNS algorithm for solving the problem,
together with theoretical guarantees. In Sec. 4, we introduce some related studies. In Sec. 5, we show
the experimental results. At last, we discuss the limitations and conclude our work in Sec. 6.
2XZ3Y1Y2Z2Z1XZY(a) rehearsal graph G
XZ3Y1Y2z2Z1XZY (b)GRh(Z2=z2)
Xz3Y1Y2Z2Z1XZY(c)GRh(Z3=z3)
Xz3Y1Y2z2Z1XZY(d)GRh(Z2=z2;Z3=z3)
Figure 2: Fig. 2(a) is a rehearsal graph, and Fig. 2(b) Fig. 2(d) illustrate the corresponding alteration
graphs with different alterations. Note that when an alteration occurs to certain variables, all incoming
arrows to those variables are removed while other graph structures are maintained.
2 Preliminaries
A novel probabilistic graphical model called structural rehearsal model (SRM) is proposed by Qin
et al. [40] to characterize inﬂuence relations among variables in the AUF problem. The SRM consists
of a set of rehearsal graphs and corresponding structural equations fhGt;tigt(tdenotes the decision
round). The detailed deﬁnition of SRM is listed in Appendix B.1.
A rehearsal graph, denoted by G= (V;E), models the qualitative inﬂuence relations among variables.
Speciﬁcally, the vertices Vdenote the variable set of the AUF problem and the edges Edenote the
inﬂuence relation among vertices. There are two types of edges in the rehearsal graph, the directional
edgeX!Ymeans thatXinﬂuencesY, and the bi-directional edge X$Ymeans thatXandY
are mutually inﬂuenced. Additionally, the corresponding structural equations of variable Vjs can be
parameterized by
j;t;2
j;t	jVj
j=1tthat:
Vj;t:=fj
PAGt
j;j;t
+"j;t; (1)
whereVj2Vdenotes the j-th vertex in Gt,PAGt
j,fuju!VjinGtgrepresents the parents
ofVjinGt, and the noise "j;tfollows the distribution N(0;j2)for allt. Note that on one hand,
causal relations are not always necessary in real world decision-making problems [ 63]; on the other
hand, causal models are sometimes insufﬁcient for capturing the full scope of relationships between
variables. For instance, the pressure and the temperature within a ﬁxed volume of ideal gas are
mutually inﬂuenced, as changes in either one of them affect the other. Such bi-directional inﬂuence
relations are not well-represented by causal models, but can be naturally expressed by SRM [40].
Besides, ﬁnding suitable alterations is involved in addressing the AUF problem. An alteration 
means a decision action that is speciﬁed by human decision-makers, denoting by a set of vertex-value
pairs, e.g.,=fZ2=z2gin Fig. 2(b). Meanwhile, rehearsal operation, denoted as Rh(), represents
executing a certain alteration, which changes the original graph structure as illustrated in Fig. 2(b)-
Fig. 2(d). Speciﬁcally, rehearsal operation breaks original inﬂuence links that point into any vertices
contained in , and ﬁxes the values in to their associated vertices; while this operation maintains
inﬂuence relations among other vertices in the associated alteration graph G. Since alteration and
rehearsal operations are always considered together in the AUF problem, for simplicity, we will use
the term alteration exclusively throughout the paper, unless otherwise speciﬁed.
3 The proposed approach
This section is dedicated to addressing the aforementioned AUF problem. In Sec. 3.1, we provide the
probelm formulation. In Sec. 3.2, we propose the AUF-MICNS method for AUF. Later in Sec. 3.3,
theoretical results are provided to ensure the effectiveness of our approach.
3.1 Formulation
This paper focuses on suggesting decisions to avoid undesired futures when an undesired outcome
is predicted by an ML model. Since effective prediction models are widely applied in various
domains [ 25] and work well even in non-stationary environments [ 62], we consider the case that the
predictive ML model is always available and are not concerned about how to train it.
We formulate the AUF problem with minimal cost in non-stationary environments as a multi-round
online decision-making process, where the decision-maker should perform round-wise alterations to
3avoid undesired outcomes. In each decision round, there are two essential time points, the time that
the ML prediction is made, and the time just before the generation of the concerned outcome Y. As
separated by the two time points, the variables fall into three consecutive time segments: X,Z, and
Yas illustrated in Fig. 2(a). In t-th round, a decision-maker ﬁrst observes variables Xt=xt, and an
ML model provides a prediction ^Ytas the outcome subsequently. Denote the desired region of Ytas
S, if^Yt62S, the decision-maker would perform alterations on Zt(only once) based on the whole
historical data, and the true Ytwill occur after the alteration.
It is worth mentioning that in decision round t, two crucial concerns for making decisions are
(a) how to perform effective alterations that make Yt2S with high probability; and (b) how
to minimize the alteration cost as much as possible. For the former, we seek to ensure that
P(Yt2Sjt;xt;Rh(t)); wheretis the selected alteration, and is the expected probability
that the alteration can successfully avoid the undesired outcome. For the latter, we generalize a con-
tinuous cost function from the discrete cost measure [ 61] to quantify the cost for different alterations.
The cost function is deﬁned as the sum of the respective costs associated with each altered variable,
and follows the increasing marginal cost property (see Appendix B.2 for details) in economics [ 32],
properly measuring the alteration cost. Given the expectation that the future outcome will likely fall
intoSafter performing the alteration, the decision maker consistently prefers the alteration with the
least alteration cost. Thus, the AUF problem can be ideally formulated as follows in practice:
min
tX
Zi2twi
Zt
i Z0
i2
s.t.P(Yt2Sj#?
t;xt;Rh(t));(2)
wherewi>0represents the cost coefﬁcient for each intermediate variable Zi2Z,Zt
irepresents
the values of Ziafter alteration twhileZ0
iis the datum point that associates with the minimum
alteration cost relatively. Besides, #?
t= arg min#E"k# tkis the ideal estimation of tsincet
is not available in practice. Note that wis andZ0
is are user-speciﬁed because the cost of the same
decision alteration can vary for different decision-makers.
In the following, we focus on a basic but essential class of the AUF problem, where the structural
equationsftin Eq. (1) are linear but dynamic, the desired set Sin Eq. (2) is a convex polytope, and the
rehearsal graph Gis known and ﬁxed ( i.e.,Gt,G) for a convenient illustration. Let d2Rs;M2
RsjYj,j2RjPAG
jj1, dynamic structural equations and the desired region can be formulated as:
Vj;t:=T
j;tPAj;t+"j;t;S=n
y2RjYjjMydo
: (3)
Note that#?
tin Eq. (2) is usually not available as discussed later in Sec. 3.2.1, thus ﬁnding surrogate
estimations ^twith bounded error E"k^t tkis necessary. Noticing that the noise distributions for
"j;ts in Eq. (3) do not change over time, the variances of "j;ts can be estimated by various Bayesian
learning methods [ 6]. Thus, we mainly focus on estimating inﬂuence parameters j;ts in what follows,
and we usetto representfj;tgs only unless otherwise speciﬁed. Another challenge lies in how
to efﬁciently solve the optimization Eq. (2) under the probabilistic constraint, since the sampling
method used in the previous work has been proven to be time-consuming [ 40]. In Sec. 3.2, we
propose the AUF-MICNS algorithm to tackle the aforementioned two challenges. AUF-MICNS
can maintain the dynamic inﬂuence relations accurately and suggest alterations to avoid undesired
outcomes effectively, and the performance can be guaranteed by theoretical results in Sec. 3.3.
3.2 Our proposed AUF-MICNS algorithm
In this subsection, we propose the AUF-MICNS algorithm to address the AUF problem as formulated
in Eq. (2). AUF-MICNS consists of two components, inﬂuence maintenance and alteration suggestion.
We ﬁrst introduce the components respectively, then we discuss how to combine them together.
3.2.1 Dynamic inﬂuence maintenance
As illustrated in Eq. (2), the precondition for making effective decisions in the AUF problem lies
in the accurately estimated ts. Speciﬁcally, to accurately estimate the parameter vector j;t2t
int-th decision round, we would like to minimize the expected squared loss E"j
Vj >
j;tPAj2,
4whereVjis thej-th vertex in rehearsal graph, and PAjdenotes the parents of Vj. Ideally, according
to the law of large numbers (LLN), if we could obtain sufﬁcient i.i.d. samples in time t, we can
estimatej;tby minimizing the empirical error `j;t(j;t)as a substitute:
arg min
j;t1
2nnX
k=1
Vk
j;t >
j;tPAk
j;t2
; (4)
wherenis the number of samples that we can obtain in round t, and the superscript kmeans that it is
thek-th sample. It can be guaranteed in lemma C.3 that this estimation converges to the true value as
nincreases. However, in real-world cases, we can only obtain a single sample after each decision
round, so it is inappropriate to calculate the parameters as above, since the solution to Eq. (4) is far
from accurate in this data-limited situation, where the surrogate loss is:
^`j;t(j;t) =1
2
Vj;t j;t>PAj;t2
: (5)
Besides, mixing the round-wise selected fVj;t;PAj;tgT
t=1to estimate parameter j;tas the classic
empirical risk minimization (ERM) [ 34] methods do is inappropriate as well, because data selected in
different rounds possibly obeys different distributions in non-stationary environments. Fortunately, in
the ﬁeld of online learning [ 52,14,17], there exist many types of algorithms to estimate parameters
sequentially with limited samples. Online gradient descent (OGD) [ 65,47] is a typical class of online
learning algorithms, which takes advantage of the gradient descent idea to handle the round-wise
selected data. Once the selection of the step size (learning rate) in OGD is tailored to the varying
speed of the environment, i.e., employing a larger step size for rapid changes and a smaller one
for gradual changes, parameters can be effectively updated with limited data after each round. We
customize OGD for estimating quantitative inﬂuence relations ^j;t2tsequentially in Algorithm 1.
Algorithm 1 OGD-based estimator for ^j
Input: The step size 
1:Initialize ^
j;0with any point in domain B
2:fort= 1toTdo
3: Receive (PAj;t;Vj;t);Continue ifVj;t2t
4: Estimate gradient ^gj;t=
PA>
j;t^
j;t Vj;t
PAj;t
5: Update ^
j;t+1= Bh
^
j;t ^gj;ti
Output: estimatedf^
j;tgT
t=1By using the OGD-based approach
in Algorithm 1, we can obtain a se-
quence of estimates f^j;1;:::; ^j;Tg
forj2[jVj]. Roughly speaking, the
quality of the estimates heavily de-
pends on the choice of step size . If
we have full prior knowledge of the
non-stationarity degree, such as the
changing speed of the inﬂuence rela-
tions, we can pre-determine an opti-
mal step size ?to achieve favorable
estimates. However, in practical sce-
narios,?is not available, and the random choice of the step size leads to unstable estimators.
Since bad estimators of the inﬂuence relations will affect the accuracy of the estimated distribution
P(Yt2Sj ^t;xt;Rh(t)), which will further affect the effectiveness of the suggested decisions for
the AUF problem, thus the choice of the step size needs to be carefully considered.
Algorithm 2 Online-ensemble-based estimator for ^j
Input: base estimators’ number Nj, weight parameter 
1:Set a set of learning rates Hj=
iji= 1;:::;Nj	
2:Initialize weight vector w
t=1
Njfor each2Hj
3:Activate estimators Es for all2Hjby OGD with 
4:fort= 1toTdo
5: Receive
j;tfrom eachE
6: Output ^j;tasP
2Hjw
t
j;t
7: Update weights as
8:w
t+1=w
texp( ^`j;t(
j;t))P
2Hjw
texp( ^`j;t(
j;t))
9: Receive (PAj;t;Vj;t)and send to each E
Output: estimatedf^j;tgT
t=1To avoid this risk, we turn to use
online-ensemble [ 60] based methods.
Online ensemble is a type of algo-
rithm that combines the idea of en-
semble and sequential updating, main-
taining multiple base learners and en-
sembling them together. Speciﬁcally,
as illustrated in Algorithm 2, we main-
tainNjbase estimators with a weight
vectorw. After each round, all experts
update their estimates by the collected
data, and the weight vector wwill be
updated as well by different losses re-
lated to different experts. By ensem-
bling all experts with the weight w,
we can obtain the ﬁnal estimator.
53.2.2 Efﬁcient alteration suggestion
Int-th decision round, since we can obtain the estimation ^tfor truetby Algorithm 2, then we
substitute#?with ^tin Eq. (2). To suggest alterations efﬁciently and effectively, another crucial
aspect is ﬁnding ways to delineate the feasible domain of the probabilistic constraint in Eq. (2). We
ﬁrst present a supporting result in Lemma 3.1 as follows, which is needed in our method to ﬁnd the
alteration that can make Yt2S with an expected probability .
Lemma 3.1 (Qin et al., 2023) .Given xt,t, it holds that:
Yt=Axt+Bz
t+C"t;
where A;B;Care constant matrices of appropriate shapes based on t,"t= ["1;t;:::;"jVj;t]
N(0;), andz
tare intermediate variables with alteration .
Recall from Eq. (2) that we want to ﬁnd alterations that satisfy P(Yt2Pjt;xt;Rh(t)).
Recognizing that solving optimization with probabilistic constraint is generally intractable and the
previous sampling method is time-consuming, we attempt to construct a surrogate deterministic
constraint that can be handled efﬁciently to replace the probabilistic constraint. Fortunately, this idea
is feasible because Lemma 3.1 shows that once the alteration is selected, the randomness of Ytonly
arises from"t, since xthas been observed and A;B;Care constant matrices given t. Thus, the
probability density function (PDF) of Ytis available and we can directly analyze the PDF to ﬁnd
probability regions as in Prop. 3.2, which aids in constructing the surrogate deterministic constraint.
Proposition 3.2. The following probability region Psatisﬁes P(Yt2Pjt;xt;Rh(t)) =:
P=n
yt+ 
 1()CC>1
2ukuk21o
;
whereyt=Axt+Bz
t,uis an arbitrary point in the unit sphere in RjYtj, and 1()denotes the
quantile function of the 2distribution with degrees of freedom =jYtj.
The proof of Prop. 3.2 is provided in Appendix C.4. We raise the power of 1=2to the matrix
because it is always positive semi-deﬁnite since  1()0andCC>0(is the covariance
(a) Samples from Fyt
 (b) Probability region ^P
Figure 3: An example of estimated ^Pwith= 0:9matrix). In practical scenarios where is
not available, the estimation ^can be used
as replacements. Let Fytdenote the cu-
mulative distribution function (CDF) of Yt,
Fig. 3 illustrates a 2-dimensional example of
samples from Fyt, together with the estima-
tion of the associated region ^P. It illustrates
that^Pcan properly draw the probabilistic
region ofFytwith expected probability .
Moreover, recognizing that the desired region Sdeﬁned in Eq. (3) is a convex polytope, i.e.,
S=
y2RjYjjMyd	
, we utilize the deﬁned probability region Pin Prop. 3.2, and use
a deterministic constraint to replace the original probabilistic constraint in Eq. (2). In this case, the
alteration-suggestion method can be formulated as follows:
min
zt
t
zt
t z0
t>
W
zt
t z0
t
s.t.MAxt+MBzt
t+kMPk2;rowd;(6)
where P= 
 1()CC>1
2,kk2;rowmeans an operator that takes 2-norm for each row of
the matrix thus outputs a row-dimensional vector. The objective to be minimized is the vector
representation of the cost function as explained in Eq. (2), where W= diag(w1;:::;wjzt
tj)is
positive deﬁnite since the cost is non-negative, i.e.,wi>0for8i.
Note that Wis positive deﬁnite and the constraint is linearly associated with zt
t, thus Eq. (6) is a
convex QCQP, which can be cast as a second-order cone program [ 35,30]. Speciﬁcally, it can be
solved in polynomial time O(jZt
tj3L)by interior-point method [ 2], whereLis the iteration rounds
6for solving the QCQP and is not associated with jZt
tj. Meanwhile, constructing matrices A;B;C
needs an element-wise traverse thus O(jVj2)time and constructing the probability region Pas in
Prop. 3.2 runs under O(jVjjYj2)because of the matrix multiplication, so the whole running time of
alteration suggestion is O(jVj3)asjZt
tj= (jVj);jYj= (jVj)andLis a constant.
3.2.3 AUF-MICNS
Algorithm 3 AUF-MICNS
Input: sequential coming data fxt;zt;ytgT
t=1
1:Initializef^j;0gjVj
j=1for Algorithm 2
2:fort= 1toTdo
3: Select alteration tby solving Eq. (6)
4: Receive ytand sentfxt;zt
t;ytgto Algorithm 2
5: Updatef^j;tgjVj
j=1by Algorithm 2
Output: suggested alterations ftgT
t=1By combining the inﬂuence mainte-
nance step and the alteration sugges-
tion step, our proposed approach for
addressing the AUF problem with
minimal cost in non-stationary en-
vironments is formulated in Algo-
rithm 3, which attempts to avoid unde-
sired outcomes in each decision round.
Speciﬁcally, in t-th round, the algo-
rithm ﬁrst receive Xt=xt, then if
the predicted outcome ^Yt62S, the
algorithm performs the suggested alteration tonZtby solving Eq. (6). Subsequently, true Yt=yt
occurs, and the algorithm collects fxt;zt
t;ytgto update inﬂuence relations by Algorithm 2. By
using this algorithm, one can tackle the formulated AUF problem with the suggested alterations.
3.3 Theoretical results
In this subsection, we present the theoretical analysis of our proposed method. All proofs are given in
Appendix C. First, we can determine the dynamic inﬂuence relations in non-stationary environments
with theoretical guarantees. Speciﬁcally, by using Algorithm 1 to estimate j;t2t, the error gap
between the estimate and the true parameter value ( E"jk^j;t j;tk2) is proved to be bounded by
an exponentially decreasing term, as well as a ﬁxed value related to the choice of step size and the
inherent problem difﬁculty. It reveals that the performance of Algorithm 1 depends on the choice of
step sizeheavily, and is detailed in Thm. 3.3, where f`j;t()gT
t=1s are deﬁned in Eq. (4).
Theorem 3.3. Letj;t(j2[jVj]) denote the true parameter value of jin timet, and choose
j2(0;1=2Lj]as the step size used in Algorithm 1, then it can be bounded that:
E^j;t j;t2
.(1 jj)t
m^j;0 j;02
+jwithj=mj
jj2
+j2
j;
wherejandLjare the minimal and maximal eigenvalues of f`j;t()gT
t=1’s Hessian matrices, 2
upper-bounds the variance of ^gj;t,jmaxtkj;t+1 j;tkupper-bounds the varying speed of
the environment, and mis the longest continuously altered rounds of Vj, for most of the Vjs,m= 1.
In Thm. 3.3, it holds that jj2(0;1=2], which derives that (1 jj)2[1=2;1). This shows that
as time progresses, the OGD estimator ^j;twill gradually converge towards the true value j;tin the
expected sense. Speciﬁcally, (a) the convergence speed depends on the choice of the initial point ^j;0,
and is limited by the inherent difﬁculty of the problem implied in j=Lj; and (b) the convergence
result will suffer a jgap from the true value, depending on the varying speed of the environment
(j) and the choice of step size j. Ifjis appropriately chosen, the gap jwill be small, e.g., if all
hyperparameters are available and j6= 0, choosing?
j= minf1=2Lj;3p
2(mjpj)2
3gcan achieve
the smallest j. Meanwhile, the hyperparameter mappears in the bound according to the properties
of alterations shown in Fig. 2. If Vjis continuously altered in mrounds, all incoming arrows of Vj
will be removed and the parameters associated with the arrows will not be updated in those rounds.
Because only a part of vertices in Ztmight be altered in any rounds, m= 1holds for most of the Vjs.
In practice, we do not know exact parameters such as j, thus?is not pre-available. Recognizing
that the random choice of leads to unstable estimations, we turn to use Algorithm 2 to estimate
^j;ts. Though we do not know ?as well, by using the online-ensemble-based Algorithm 2, we can
get more stable estimations as guaranteed by the following regret bound in Prop. 3.4.
7Proposition 3.4. Assumef^`j;t()gT
t=1s are bounded for8i2Bandt2[T]; then for any 2Hj,
estimations ^j;ts from Algorithm 2 satisﬁes that
TX
t=1^`t
^j;t
 TX
t=1^`t 

j;t
Op
TlnNj
;
by choosing =p
lnNj=Tin Algorithm 2, where Njis the number of base-learners, 
j;tis the
estimation from any expert in expert setHjin Algorithm 2.
Prop. 3.4 shows that the cumulative loss of the estimation obtained by Algorithm 2 is comparable
with the best expert in Hj, thus by Thm. 3.3, though ^tmay be far from tat the ﬁrst few rounds, it
will converge towards t. Meanwhile, in some certain cases, the best step size ?
jin Thm. 3.3 can be
included inHjwithNj=O(logT)[60]. Due to these, Algorithm 2 provides more stable estimates
for the inﬂuence relations, which can further aid in making decisions to address the formulated AUF
problem. As to the decision-making processes, AUF-MICNS can suggest alterations with theoretical
guarantees. Speciﬁcally, the suggested alterations are guaranteed by Thm. 3.5.
Theorem 3.5. By using the suggested alterations tfrom Eq. (6), it can be guaranteed that:
P
Yt2Sj ^t;xt;Rh(t)
:
Thm. 3.5 illustrates that the suggested alterations tby the AUF-MICNS algorithm can effectively
avoid the undesired outcomes as the formulated AUF problem expects, under the distribution con-
ditioned on estimation ^trather than true t. Note that it is guaranteed in Thm. 3.3 and Prop. 3.4
that^tis not far from t. Meanwhile, we provide the experimental analysis in Sec. 5 to show that
P(Yt2Sjt;xt;Rh(t))holds practically. Besides, this method achieves a super-exponential
improvement over the time complexity of the previous method [40] as discussed in Sec. 3.2.2.
4 Related work
RL Methods. RL approaches have demonstrated success in numerous domains [ 51], particularly
in game-playing [ 33] and autonomous control [ 21]. However, the Markov Decision Process (MDP)
formalism in RL abstracts decision-making processes into states, actions, and rewards, potentially
overlooking useful ﬁne-grained structural information. While hybrid online and ofﬂine RL methods
have been introduced [ 48,37], they overlook ﬁne-grained structural information as well and require
large ofﬂine datasets in practice. Moreover, it is worth noting that a fundamental limitation of
applying RL to the AUF problem is that RL methods require a substantial number of interactions,
which may be too luxurious or simply not tolerated in many real-world applications.
Causality. Identifying causal systems from observational and interventional data has been exten-
sively studied [ 44,50,7,58,9], but these methods typically do not actively select interventions.
Furthermore, signiﬁcant research has focused on identifying causal structures or effects in interactive
environments [ 18,22,53,55,39,54,57,41], which predominantly aim to identify causal structures
or effects. To incorporate additional utilities for decision-making, causal bandits and causal RL
methods have been proposed to determine where to intervene [ 5,24,46,26,59,12,31]. The afore-
mentioned methods generally rely on causal modeling, which may be luxurious or restrictive in some
real-world decision-making cases [ 63,40]. As identifying causations rely on some strong restrictions
or assumptions, it is possible that we cannot ﬁnd a feasible alteration. Conversely, correlation, which
underpins most ML models, falls short of providing a solid foundation for making decisions. As a
middle ground between causation and correlation, the inﬂuence relations form a more practical basis
for decision-making [ 63]. Building on this concept, we employ the SRM developed by Qin et al. [40],
which can adapt to dynamically evolving decision systems. In particular, our approach incorporates
the context xtinto decision-making, and can sugggest decision alterations effectively even when the
parameters of the system are non-stationary and the actions come with varying associated costs.
Other related topics. Our approach builds upon several classic ML techniques. The action cost
measure employed in our method generalizes principles from cost-sensitive learning [ 13,61]. Ad-
ditionally, we adapt the online ensemble methodology [ 60] to update the SRM parameters. Online
emsemble framework has been used in several areas, such as online convex optimization [ 56], online
label shift [ 38], and reinforcement learning [ 27]. Further exploration and advancements in these
techniques hold the potential to enhance our approach as well.
80.00.10.20.30.40.50.60.70.8Success FrequencySuccess frequency and relative alteration cost
AUF-MICNS
QWZ23
DDPG
PPO
SAC
Desired 
0.00.20.40.60.81.01.21.4t t2 of estimations
MSE of different estimations
Online Ensemble
OGD with step size 0.002
OGD with step size 0.005
OGD with step size 0.025
1.41.51.61.71.81.9Value of (2)
NCT and (2)
NCT
True influence relation and the estimation
True Value (2)
NCT,t
Estimation (2)
NCT,t
0.0 0.2 0.4 0.6 0.8 1.0
Relative Alteration Cost0.00.10.20.30.40.50.60.70.8Success FrequencyAUF-MICNS
QWZ23
DDPG
PPO
SAC
Desired 
20 40 60 80 100
Round0.00.20.40.60.8t t2 of estimations
Online Ensemble
OGD with step size 1.000
OGD with step size 2.500
OGD with step size 5.000
20 40 60 80 100
Round0.60.70.80.91.01.1Value of (1)
CO2 and (1)
CO2
True Value (1)
CO2,t
Estimation (1)
CO2,t
Figure 4: Results of Market-managing data (row 1) and Bermuda data (row 2) respectively. Bars and
bands depict the standard deviations.
5 Experiments
We evaluate the proposed AUF-MICNS algorithm on two datasets and focus on four aspects including
(a) success frequency for Yt2S; (b) average alteration cost; (c) average executing time; and (d)
mean square error of the estimated parameters ^t. For each dataset, we repeat experiments with
100 rounds 20 times. The observational dataset size is set to 10. We compare our proposed method
with previous rehearsal learning approach (QWZ23 [ 40]), and we also compare with several classic
RL methods including DDPG [ 29], PPO [ 45], and SAC [ 15]. Experimental details and additional
experiments are listed in Appendix D.
Market-Managing Data. We abstract a dynamic SRM from a market-managing scenario, where a
manager of the market needs to make decisions to promote the total proﬁt (TPF) and the number of
customers (NCT). We consider variables that may affect TPF and NCT, the pricing for the product (P),
the pricing of the competitor market (E), the cost of raw materials (C), etc. We assume the manager
can alter two variables, P and C. There exist mutually inﬂuenced variables in the scenario: If P is
set to be small, then E will also be small to stay competitive on price; and vice versa. The sizes of
Xt,Zt, andYtare 2, 4, and 2 respectively. The parameters of the dynamic structural equations are
manually set according to the domain knowledge. For example, parameters associated with variable
C vary over time with a periodic term, i.e.,C;t=C(1 +asin(wt)). The feasible alteration values
are[ 3;3]for centralized P and C, associated with cost coefﬁcients 1:0and2:0respectively since
altering P is easier than C. We want to maintain high TPF and high NCT at the same time, so the
desired regionSis set to beS=fTPFs1,NCTs2,TPF+NCTs3g, and more than 80% of
the original data falls outside this range, as shown in Fig. 7(a).
Bermuda Data. This is an ecology dataset that records environment variables in Bermuda [ 10],
and the generation order of variables is available [ 3]. The sizes of Xt,Zt, andYtare 3, 7, and
1. The structural equations are obtained by ﬁtting linear models on normalized data [ 40], and we
manually add the varying trend, e.g., considering the annual increase in CO2emissions, we posit that
there is an increasing trend in the inﬂuence relation between temperature and CO2concentration,
i.e.,CO2;t=CO2;t(1 ae wt). We assume that 5 variables in Ztare actionable [ 1] and the
feasible alteration values are [ 1;1]for each of them with different cost coefﬁcients. The concerned
outcome Ytrepresents the net coral ecosystem calciﬁcation (NEC) in Bermuda. To make the coral
reef ecosystem healthy, a relatively large NEC is preferred, so the desired region Sis set to be
S=f0:5NEC2g, and more than 75% of the original data falls outside it, as shown in Fig. 7(b).
Fig. 4 shows the full experimental results. The desired probability is set to = 0:7. Two rows of
ﬁgures denote the results of the Market data and the Bermuda data respectively. Speciﬁcally, the ﬁrst
column of Fig. 4 shows that (a) the success frequency of making the concerned outcome Ytfalls into
the desired regionS; and (b) relative alteration cost among methods, i.e., the normalized cost among
different methods. The proposed AUF-MICNS algorithm outperforms other competitors in both
aspects. If we increase the interaction rounds T, RL methods can achieve satisfying performance,
e.g., DDPG achieves 0.6955 average success frequency when T= 4000 on the Market data.
9The second column of Fig. 4 shows the mean-square error of estimates for NCTin Market data
and estimates for CO2in Bermuda data respectively. The exponential convergence speed and the
convergence error ( j) in Thm. 3.3 are illustrated in these two ﬁgures. Speciﬁcally, for Market-
managing data, the online-ensemble-based sequential method can achieve a similar convergence
speed like OGD with = 0:025does whenT20, and it results in a smaller jas illustrated by the
enlarged part ( T40). For Bermuda data, OGD with = 2:5outperforms other step sizes, since
= 1:0converge slowly, and = 5:0suffers a notably bigger gap j. By using the online-ensemble-
based sequential method, we can obtain a comparable performance with the best step size = 2:5.
These results illustrate that our proposed method mitigates the risk substantially, as the inappropriate
choice ofwill affect the practicality of the estimation and ?is not available practically. Meanwhile,
the third column of Fig. 4 shows true parameter values and the estimates by the online-ensemble-based
method. The superscript (1)/(2)means the ﬁrst/second dimension of the associated parameter vector.
It shows that the error gap between ^j;tandj;tconverges to a small value rapidly, which guarantees
accurate estimates of the quantitative inﬂuence relations in possibly non-stationary environments.
Table 1: Average running time (s).
Dataset DDPG PPO SAC QWZ23 MICNS
Market 7.89 0.05 0.03 63.14 2.81
Bermuda 9.63 0.06 0.04 386.44 1.71At last, the average whole-executing time
of the 20-times experiments is recorded in
Table 1. We mainly focus on the compar-
ison between AUF-MICNS and QWZ23
since both of them maintain inﬂuence re-
lations other than purely suggesting deci-
sions. It shows that our proposed method is more time-efﬁcient than QWZ23.
6 Conclusion
Practically, different decision actions might correspond to different costs, and the inﬂuence relations
might vary over time in non-stationary environments. In this paper, we try to tackle the AUF problem
considering the aforementioned aspects. Speciﬁcally, we propose the AUF-MICNS algorithm that can
capture the dynamic inﬂuence relations in non-stationary environments and suggest actions based on
the inﬂuence relations. This method can suggest decision actions under polynomial time. Meanwhile,
theoretical results show that the suggested actions can effectively avoid the undesired outcomes
with probability larger than , and the suggested actions get more accurate as time progresses.
Experimental results validate the effectiveness and efﬁciency of our proposed method.
Our approach primarily focuses on scenarios where the inﬂuence relations among variables are linear
and is currently not applicable to non-linear cases. Additionally, selecting the hyperparameter in
existing frameworks remains a signiﬁcant challenge, as an inappropriate may lead to the failure
of solving Eq. (6). To address these limitations, we plan to develop methods that handle non-linear
cases and reduce sensitivity to the hyperparameter in future work.
Acknowledgements
This research was supported by Jiangsu Science Foundation Leading-edge Technology Program
(BK20232003), and National Postdoctoral Program for Innovative Talent (BX20240162). The authors
thank the anonymous reviewers for their helpful comments. We are also grateful to Long-Fei Li and
Lue Tao for discussions.
References
[1]Virginia Aglietti, Xiaoyu Lu, Andrei Paleyes, and Javier González. Causal Bayesian optimization. In
Proceedings of the 23rd International Conference on Artiﬁcial Intelligence and Statistics , pages 3155–3164,
2020.
[2]Erling D. Andersen, Cornelis Roos, and Tam’as Terlaky. On implementing a primal-dual interior-point
method for conic quadratic optimization. Math. Program. , 95(2):249–277, 2003.
[3]Andreas Andersson and Nicholas Bates. In situ measurements used for coral and reef-scale calciﬁcation
structural equation modeling including environmental and chemical measurements, and coral calciﬁcation
rates in bermuda from 2010 to 2012 (BEACON project), 2018. http://lod.bco-dmo.org/id/dataset/720788.
10[4]Kai Arulkumaran, Marc Peter Deisenroth, Miles Brundage, and Anil Anthony Bharath. Deep reinforcement
learning: A brief survey. IEEE Signal Processing Magazine , 34(6):26–38, 2017.
[5]Elias Bareinboim, Andrew Forney, and Judea Pearl. Bandits with unobserved confounders: A causal
approach. In Advances in Neural Information Processing Systems 28 , pages 1342–1350, 2015.
[6] C Bishop. Pattern Recognition and Machine Learning . Springer, 2006.
[7]Simon Buchholz, Goutham Rajendran, Elan Rosenfeld, Bryon Aragam, Bernhard Schölkopf, and Pradeep
Ravikumar. Learning linear causal representations from interventions under general nonlinear mixing. In
Advances in Neural Information Processing Systems 36 , page to appear, 2023.
[8]Nicolo Cesa-Bianchi and Gábor Lugosi. Prediction, Learning, and Games . Cambridge University Press,
2006.
[9]Wei Chen, Zhiyi Huang, Ruichu Cai, Zhifeng Hao, and Kun Zhang. Identiﬁcation of causal structure with
latent variables based on higher order cumulants. In The 38th AAAI Conference on Artiﬁcial Intelligence ,
pages 20353–20361, 2024.
[10] Travis A Courtney, Mario Lebrato, Nicholas R Bates, Andrew Collins, Samantha J De Putron, Rebecca
Garley, Rod Johnson, Juan-Carlos Molinero, Timothy J Noyes, Christopher L Sabine, et al. Environmental
controls on modern scleractinian coral and reef-scale calciﬁcation. Science Advances , 3(11):e1701356,
2017.
[11] Joshua Cutler, Dmitriy Drusvyatskiy, and Zaïd Harchaoui. Stochastic optimization under distributional
drift. Journal of Machine Learning Research , 24(147):1–56, 2023.
[12] Arnoud A. W. M. de Kroon, Danielle Belgrave, and Joris M. Mooij. Causal discovery for causal bandits
utilizing separating sets. CoRR , abs/2009.07916, 2020.
[13] Charles Elkan. The foundations of cost-sensitive learning. In Proceedings of the 17th International Joint
Conference on Artiﬁcial Intelligence , pages 973–978, 2001.
[14] Yoav Freund and Robert E. Schapire. A decision-theoretic generalization of on-line learning and an
application to boosting. Journal of Computer and System Sciences , 55(1):119–139, 1997.
[15] Tuomas Haarnoja, Aurick Zhou, Pieter Abbeel, and Sergey Levine. Soft actor-critic: Off-policy maximum
entropy deep reinforcement learning with a stochastic actor. In Proceedings of the 35th International
Conference on Machine Learning , pages 1861–1870, 2018.
[16] Trevor Hastie, Robert Tibshirani, Jerome H Friedman, and Jerome H Friedman. The elements of statistical
learning: Data mining, inference, and prediction . Springer, 2009.
[17] Elad Hazan. Introduction to online convex optimization. Foundations and Trends in Optimization , 2(3-4):
157–325, 2016.
[18] Yangbo He and Zhi Geng. Active learning of causal networks with intervention experiments and optimal
designs. Journal of Machine Learning Research , 9(Nov):2523–2547, 2008.
[19] Wassily Hoeffding. Probability inequalities for sums of bounded random variables. Journal of the American
Statistical Association , 58(301):13–30, 1963.
[20] Thomas Hofmann, Bernhard Schölkopf, and Alexander J Smola. Kernel methods in machine learning.
Annals of Statistics , 36(3):1171–1220, 2008.
[21] Bahare Kiumarsi, Kyriakos G. Vamvoudakis, Hamidreza Modares, and Frank L. Lewis. Optimal and
autonomous control using reinforcement learning: A survey. IEEE Transactions on Neural Networks and
Learning Systems , 29(6):2042–2062, 2018.
[22] Murat Kocaoglu, Alex Dimakis, and Sriram Vishwanath. Cost-optimal learning of causal graphs. In
Proceedings of the 34th International Conference on Machine Learning , pages 1875–1884, 2017.
[23] Kira Lancker and Martin F. Quaas. Increasing marginal costs and the efﬁciency of differentiated feed-in
tariffs. Energy Economics , 83:104–118, 2019.
[24] Finnian Lattimore, Tor Lattimore, and Mark D. Reid. Causal bandits: Learning good interventions via
causal inference. In Advances in Neural Information Processing Systems 29 , pages 1181–1189, 2016.
[25] Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. Deep learning. Nature , 521(7553):436–444, 2015.
11[26] Sanghack Lee and Elias Bareinboim. Characterizing optimal mixed policies: Where to intervene and what
to observe. In Advances in Neural Information Processing Systems 33 , pages 8565–8576, 2020.
[27] Long-Fei Li, Peng Zhao, and Zhi-Hua Zhou. Dynamic regret of adversarial linear mixture MDPs. In
Advances in Neural Information Processing Systems 36 , pages 60685–60711, 2023.
[28] Zihao Li, Hui Lan, Vasilis Syrgkanis, Mengdi Wang, and Masatoshi Uehara. Regularized deepiv with
model selection, 2024. URL https://arxiv.org/abs/2403.04236 .
[29] Timothy P. Lillicrap, Jonathan J. Hunt, Alexander Pritzel, Nicolas Heess, Tom Erez, Yuval Tassa, David
Silver, and Daan Wierstra. Continuous control with deep reinforcement learning. In Proceedings of the 4th
International Conference on Learning Representations , 2016.
[30] Miguel Sousa Lobo, Lieven Vandenberghe, Stephen Boyd, and Hervé Lebret. Applications of second-order
cone programming. Linear Algebra and its Applications , 284(1-3):193–228, 1998.
[31] Yangyi Lu, Amirhossein Meisami, and Ambuj Tewari. Causal bandits with unknown graph structure. In
Advances in Neural Information Processing Systems 34 , pages 24817–24828, 2021.
[32] N Gregory Mankiw. Principles of Economics . Cengage Learning, 9th edition, 2020.
[33] V olodymyr Mnih, Koray Kavukcuoglu, David Silver, Alex Graves, Ioannis Antonoglou, Daan Wierstra,
and Martin A. Riedmiller. Playing atari with deep reinforcement learning. CoRR , abs/1312.5602, 2013.
[34] Mehryar Mohri, Afshin Rostamizadeh, and Ameet Talwalkar. Foundations of Machine Learning . MIT
Press, 2nd edition, 2018.
[35] Yurii Nesterov and Arkadii Nemirovskii. Interior-point polynomial algorithms in convex programming .
SIAM, 1994.
[36] Judea Pearl. Causality: Models, Reasoning and Inference . Cambridge University Press, 2nd edition, 2009.
[37] Vitchyr H Pong, Ashvin V Nair, Laura M Smith, Catherine Huang, and Sergey Levine. Ofﬂine meta-
reinforcement learning with online self-supervision. In Proceedings of the 39th International Conference
on Machine Learning , pages 17811–17829, 2022.
[38] Yu-Yang Qian, Yong Bai, Zhen-Yu Zhang, Peng Zhao, and Zhi-Hua Zhou. Handling new class in online
label shift. In Proceedings of the 23rd IEEE International Conference on Data Mining , pages 1283–1288,
2023.
[39] Tian Qin, Tian-Zuo Wang, and Zhi-Hua Zhou. Budgeted heterogeneous treatment effect estimation. In
Proceedings of the 38th International Conference on Machine Learning , pages 8693–8702, 2021.
[40] Tian Qin, Tian-Zuo Wang, and Zhi-Hua Zhou. Rehearsal learning for avoiding undesired future. In
Advances in Neural Information Processing Systems 36 , pages 80517–80542, 2023.
[41] Tian Qin, Long-Fei Li, Tian-Zuo Wang, and Zhi-Hua Zhou. Tracking treatment effect heterogeneity in
evolving environments. Machine Learning , 113(6):3653–3673, 2024.
[42] Kangrui Ruan and Xuan Di. Learning human driving behaviors with sequential causal imitation learning.
InProceedings of the 36th AAAI Conference on Artiﬁcial Intelligence , pages 4583–4592, 2022.
[43] Kangrui Ruan, Junzhe Zhang, Xuan Di, and Elias Bareinboim. Causal imitation learning via inverse
reinforcement learning. In Proceedings of the 11th International Conference on Learning Representations ,
2022.
[44] Bernhard Schölkopf, Francesco Locatello, Stefan Bauer, Nan Rosemary Ke, Nal Kalchbrenner, Anirudh
Goyal, and Yoshua Bengio. Toward causal representation learning. Proceedings of the IEEE , 109(5):
612–634, 2021.
[45] John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov. Proximal policy
optimization algorithms. CoRR , abs/1707.06347, 2017.
[46] Rajat Sen, Karthikeyan Shanmugam, Alexandros G Dimakis, and Sanjay Shakkottai. Identifying best
interventions through online importance sampling. In Proceedings of the 34th International Conference on
Machine Learning , pages 3057–3066, 2017.
[47] Shai Shalev-Shwartz, Yoram Singer, and Nathan Srebro. Pegasos: Primal estimated sub-gradient solver for
SVM. In Proceedings of the 24th International Conference on Machine Learning , pages 807–814, 2007.
12[48] Yuda Song, Yifei Zhou, Ayush Sekhari, J Andrew Bagnell, Akshay Krishnamurthy, and Wen Sun. Hybrid
rl: Using both ofﬂine and online data can make RL efﬁcient. In Proceedings of the 11th International
Conference on Learning Representations , 2022.
[49] Peter Spirtes, Clark N Glymour, and Richard Scheines. Causation, Prediction, and Search . MIT Press,
2000.
[50] Chandler Squires, Anna Seigal, Salil S Bhate, and Caroline Uhler. Linear causal disentanglement via
interventions. In Proceedings of the 40th International Conference on Machine Learning , pages 32540–
32560, 2023.
[51] Richard S Sutton and Andrew G Barto. Reinforcement learning: An introduction . MIT Press, 2018.
[52] V . G. V ovk. Aggregating strategies. In Proceedings of the 3rd Annual Workshop on Computational
Learning Theory , pages 371–386, 1990.
[53] Tian-Zuo Wang, Xi-Zhu Wu, Sheng-Jun Huang, and Zhi-Hua Zhou. Cost-effectively identifying causal
effects when only response variable is observable. In Proceedings of the 37th International Conference on
Machine Learning , pages 10060–10069, 2020.
[54] Tian-Zuo Wang, Tian Qin, and Zhi-Hua Zhou. Estimating possible causal effects with latent variables via
adjustment. In Proceedings of the 40th International Conference on Machine Learning , pages 36308–36335,
2023.
[55] Tian-Zuo Wang, Tian Qin, and Zhi-Hua Zhou. Sound and complete causal identiﬁcation with latent
variables given local background knowledge. Artiﬁcial Intelligence , 322:103964, 2023.
[56] Yu-Hu Yan, Peng Zhao, and Zhi-Hua Zhou. Universal online learning with gradual variations: A multi-layer
online ensemble approach. In Advances in Neural Information Processing Systems 36 , pages 37682–37715,
2023.
[57] Jiaqi Zhang, Louis Cammarata, Chandler Squires, Themistoklis P Sapsis, and Caroline Uhler. Active
learning for optimal intervention design in causal models. Nature Machine Intelligence , pages 1–10, 2023.
[58] Jiaqi Zhang, Kristjan Greenewald, Chandler Squires, Akash Srivastava, Karthikeyan Shanmugam, and
Caroline Uhler. Identiﬁability guarantees for causal disentanglement from soft interventions. In Advances
in Neural Information Processing Systems 36 , page to appear, 2023.
[59] Junzhe Zhang and Elias Bareinboim. Near-optimal reinforcement learning in dynamic treatment regimes.
InAdvances in Neural Information Processing Systems 32 , pages 13401–13411, 2019.
[60] Peng Zhao, Yu-Jie Zhang, Lijun Zhang, and Zhi-Hua Zhou. Adaptivity and non-stationarity: Problem-
dependent dynamic regret for online convex optimization. Journal of Machine Learning Research , 25(98):
1–52, 2024.
[61] Zhi-Hua Zhou. Cost-sensitive learning. In International Conference on Modeling Decisions for Artiﬁcial
Intelligence , pages 17–18, 2011.
[62] Zhi-Hua Zhou. Open-environment machine learning. National Science Review , 9(8):nwac123, 2022.
[63] Zhi-Hua Zhou. Rehearsal: Learning from prediction to decision. Frontiers of Computer Science , 16(4):
1–3, 2022.
[64] Zhi-Hua Zhou. Rehearsal: Learning from prediction to decision. Keynote at the CCF Conference on AI,
Urumqi, China, 2023.
[65] Martin Zinkevich. Online convex programming and generalized inﬁnitesimal gradient ascent. In Proceed-
ings of the 20th International Conference on Machine Learning , pages 928–936, 2003.
13A Discussion
A.1 Discussion on the AUF-MICNS algorithm
Two crucial points should be discussed in this approach, i.e., (a) dynamic inﬂuence modeling; and (b) the
deﬁned cost function for alterations. For the former, we consider a linear case with additive noise, and for more
complicated scenarios than linear ones, one can modify the structural equations in Eq. (3) by using methods
such as the kernel method [ 20]. Note that Theorem 3.3 always holds as long as the new loss functions `j;t()s
are still-strongly convex and L-smooth in those cases, similar to Eq. (4). For the latter, we use a quadratic
cost function in this paper. Since the alteration cost is user-speciﬁed, in certain problems, if the quadratic
cost is not appropriate, one can replace it with any other convex functions under the increasing marginal cost
(IMC) property [ 32]. In those cases, the alteration selection method is a convex optimization as well, similar to
Eq. (6). It is worth noting that our work mainly focuses on cases where samples are rare, thus only user-speciﬁed
hyperparametersfwj;z0
jgj2[jVj]can be relied upon. If we can obtain a sufﬁcient number of halteration, costi
pairs, hyperparameters fwj;z0
jgj2[jVj]can be accurately estimated using quadratic ﬁtting techniques [16].
Additionally, for the probabilistic constraint in Eq. (2), if the noise is not assumed to be normal anymore,
one can analyze the CDF of the noise distribution to ﬁnd a new probability region with a similar approach.
This can further assist in constructing a substitute constraint. Moreover, there are instances where the feasible
domain of the constraint in Eq. (6) may not exist due to its stringent nature, e.g., one aims to completely avoid
undesired futures with 100% probability, or the desired region Sis not practically achievable. In such cases, the
decision-maker should consider verifying speciﬁed region Sor reducing hyperparameter to some extent.
Last but not least, though we mainly focus on the scenario where the graph structure is ﬁxed and known, i.e.,
Gt=G, however, our approach can be straightforwardly adapted to the case where Gt=Gbut unknown as
assumed in Qin et al. [40] as detailed in Appendix A.3. We also provide a simple comparable experiment on
Bermuda data in the setting of Qin et al. [40], as illustrated in Appendix D.1.
A.2 Comparation with causality
The SRM and Rh()operations are similar to their counterparts in causal inference but have different applicating
scenarios. The differences between rehearsal learning and causal learning are listed as follows:
1Most of the causal learning problems focus on structure or effect identiﬁcation, while the decision-
making process is not directly involved in the modeling. In contrast, rehearsal learning mainly focuses
on a class of decision-making problems that specializes in the goal of avoiding undesired future using
SRM-based modeling.
2Causal learning utilizes the SCM. In contrast, rehearsal learning uses the SRM (a new probabilistic
graphical model [ 40]) to model the inﬂuence relations between the variables toward addressing the
AUF problem. The modeling granularity of SRM is more ﬂexible, as the inﬂuence relationship can be
evolved, and mutually inﬂuenced. Speciﬁcally,
•Possible dynamic inﬂuence relationships. For instance, the inﬂuence relationship between pricing
and sales of coats can vary cyclically and trend-wise over time. Thus, a given price may result
in fewer sales during summer compared to winter. In addition, the coat’s style may gradually
become outdated, leading to reduced sales at the same price a year later compared to the present.
•Possible mutually inﬂuenced relationships. For instance, the ideal gas law states that the pressure
p, volumeV, amount of substance n, and absolute temperature Tobey the equation pV=nRT
(Ris the ideal gas constant). When a ﬁxed volume Vof an ideal gas is considered, with nandR
held constant, the pressure pand volumeVcan be represented as a pair of mutually inﬂuenced
variables within an SRM modeling.
A.3 Possible types of graph structures
There are four possible cases of the graph structure, speciﬁcally:
1Gtﬁxed, known. It’s the setting in our paper.
2Gtﬁxed, unknown. It’s the setting in Qin et al. [40]. Our method can be straightforwardly adapted
to this case. Technically, since the distribution P(G)is discrete, we can initialize and update the
probability mass function (PMF) P(G)in the same manner as Qin et al. [40]. Thus, when we want
to select decision alterations, the maintained PMF P(G)can be utilized to marginalize Gfrom
P(Y2SjG;). thereby the expectation of matrices A;B;Cin Eq. (6) can be obtained and used.
3Gtnot ﬁxed, known. Our method can be directly used because once the graph structure is known, Gis
not a stochastic component. Thus, matrices A;B;Cin Eq. (6) can be obtained in the same manner. It
14is worth noting that the changing graph structure will lead to the birth of new parameters at each round.
Therefore, though the method can be directly used in such case, establishing theoretical guarantees is
difﬁcult.
4Gtnot ﬁxed, unknown. In this case, neither norPGcan be accurately estimated as there is only one
sample per round. Thus, dealing with such a case may need to additional assumptions. For example,
consider there are a sufﬁcient number of samples per round. In this case, our method can model and
PGaccurately, thereby suggesting good decisions.
B Deﬁnitions
B.1 Details about Structural Rehearsal Models
In this section, we present full deﬁnitions and discussions for the Structural Rehearsal Model (SRM), which is a
probabilistic graphical model proposed by [40] to characterize the inﬂuence relations among variables.
Deﬁnition of the Rehearsal Graph
Deﬁnition B.1 (Mixed graph, [ 40]).LetG= (V;E)be a graph, where Vdenotes the vertices and Ethe edges.
Gis a mixed graph if for any distinct vertices u;v2V, there is at most one edge connecting them, and the edge
is either directional ( u!voru v) or bi-directional (u$v).
Deﬁnition B.2 (Bi-directional clique, [ 40]).A bi-directional clique C= (Vc;Ec)of a mixed graph G=
(V;E)is a complete subgraph induced by VcVsuch that any edge e2Ecis bi-directional. Cis maximal
if adding any other vertex does not induce a bi-directional clique.
Deﬁnition B.3 (Rehearsal graph, [ 40]).LetG= (V;E)be a mixed graph. Let fCigl
i=1denote all maximal
bi-directional cliques of G, whereCi= (Vc
i;Ec
i).Gis a rehearsal graph if and only if:
1.Vc
i\Vc
j=;for anyi6=j.
2.8i2[l], if there is any edge pointing from some u2VnVc
ito somev2Vc
i, then8v2Vc
i,u!v.
3.There exists a topological ordering for fCigl
i=1following the directions of directional edges between
Cis.
It can be found that the topological ordering for bi-directional cliques fCigl
i=1in the rehearsal graph reﬂects the
time order of the generation process of variables.
Discussion of the Structural Equations
In this paper, we present the deﬁnition of dynamic structural equations in Eq. (1), which provides a quantitative
computational formulation for the inﬂuence relations in non-stationary environments.
In fact, the structural equations are deﬁned among the bi-directional cliques fCigl
i=1as detailed in Qin et al.
[40]. Speciﬁcally, the dynamic structural equations can be denoted as t, which consists of the set of parameter
matricesfi;tgT
t=1and the covariance matrix iof each clique Ciin the rehearsal graph G. It is noteworthy
that the quantitative inﬂuence relationship of a directional edge A!BforA2Ca;B2Cbat timetis
modeled in the parameter matrix b;tsince the topological ordering for bi-directional cliques reﬂects the time
order of the generation process; while the quantitative inﬂuence relationship of a bi-directional edge D1$D2
forD1;D22Cdat timetis modeled in the covariance matrix dsince they are in the same bi-directional
clique which is viewed as happening in the same time.
We present a simpliﬁed version of the deﬁnition of dynamic structural equations in Eq. (1) for a convenient
presentation, which deﬁnes the dynamic structural equations on the variable level rather than the clique level.
Note that for each variable Vj2Ci, the associated parameter vectors fj;tgT
t=1can be directly found in
the corresponding parameter matrices fi;tgT
t=1; while the variance 2
jof each variable Vj2Cican be
derived from the corresponding covariance matrix iby marginalizing the desired dimension out, since the
marginalization operator for multi-normal distribution is available.
B.2 Increasing Marginal Cost with an Example
In this section, we introduce the increasing marginal cost (IMC) property. Increasing marginal cost (IMC), or
rising marginal cost, is an important property in microeconomics [ 23,32]. We ﬁrst present a famous example in
the ﬁeld of microeconomics, called Thirsty Thelma’s Lemonade Stand.
15Lemonade Stand is a business simulation game devised in 1973 by Bob Jamison under the Minnesota Educational
Computing Consortium. It offers players the experience of managing a lemonade stand across multiple rounds.
At the commencement of each round, players make decisions regarding their stock, pricing, and advertising
based on their current ﬁnancial standing. The outcomes in each round are determined by the player’s choices;
and are further inﬂuenced by random events like thunderstorms and street closures. After each round, a summary
of the current status of the player is provided, and the game concludes after 12 rounds. In this game, an essential
quantity is the total cost of lemonade per glass, which will increase in a quadratic way, as it has a linearly
increasing derivative (named the marginal cost) as shown in Fig. 5.
0 2 4 6 8 10
Quantity of Lemonade (glass per hour)02468101214Costs (dollars $)
T otal Cost Curve
Marginal Cost Curve
Figure 5: Thirsty Thelma’s Total-Cost and Marginal-Cost Curves
This phenomenon is commonly observed in real-world scenarios, and the upward slope of the total cost curve
reﬂects the property of the law of diminishing marginal product [ 32]. When Thirsty Thelma produces a small
quantity of lemonade, her workforce is limited, and much of her equipment remains idle. The ease of utilizing
these unused resources results in a substantial marginal product for an additional worker and a corresponding
small marginal cost for producing an extra glass of lemonade. In contrast, as she increases lemonade production,
her shop becomes crowded with workers, and most of her equipment is fully utilized. While additional workers
can contribute to increased production, they must operate in crowded conditions and may face delays in
equipment usage. Consequently, when the quantity of lemonade produced is already high, the marginal product
of an extra worker diminishes, leading to a signiﬁcant increase in the marginal cost of producing an extra glass
of lemonade. It is a famous and widely used example in the ﬁeld of microeconomics, and it has many similarities
with the AUF scenario. In our proposed cost-minimal AUF problem, when the decision-maker decides to alter
some variables in Zt, the cost associated with different alterations vary. For the same variable, the cost of altering
it from a datum point should have a similar shape to the total cost curve in Fig. 5, varying with an increasing
derivative. That is how we deﬁne the cost function in this paper. The cost function could be replaced by any
other convex function in different situations.
C Proofs
In this section, we provide proof for claims in the main text.
C.1 Proof for Proposition 3.2
Lemma C.1. Ifis a symmetric positive deﬁnite matrix, the following two sets are equivalent:
n
x:x> 1x1o
,n
x:x=1
2ujkuk21o
;
where xanduare vectors with a center at the origin of the coordinate system O.
Proof. AssumeP1=
x:x> 1x1	andP2=n
x:x=1
2ujkuk21o
. Then what we need to
prove is equivalent to:
(1) Points contained in P1have to be contained in P2.
(2) Points contained in P2have to be contained in P1.
For (1), it holds that x> 1x1, which is equivalent to ( 1
2x)>( 1
2x)1. Thus, let u= 1
2x, it
can be derived that x=1
2uwherekuk21, and (1) is proved.
For (2), we replace x> 1xwithx=1
2u, then it can be derived that:
x> 1x=u>1
2 11
2u=u>u1;
16which shows that points contained in P2are also contained in P1, so (2) is proved. In conclusion, the lemma is
proved.
Proposition 3.2. The following setPis a probability region that satisﬁes P(Yt2Pjt;xt;Rh(t)) =:
P=
yt+
 1()CC>1
2ukuk21
;
whereyt=Axt+Bz
t,uis an arbitrary point in the unit sphere in RjYtj, and 1()denotes the quantile
function of the 2distribution with degrees of freedom =jYtj.
Proof. Recall from Lemma 3.1 that:
"tN (0;);Yt=Axt+Bz
t+C"t:
From the property of multi-normal distributions, it holds that:
YtN
Axt+Bz
t;CC>
:
Letyt=Axt+Bz
t, then we normalize the distribution above, it can be derived that:

CC> 1
2(Yt yt)N (0;I):
So it can be derived that:
(Yt yt)>
CC> 1
(Yt yt)2
;
where the2distribution has the degrees of freedom =jYtj.
Let 1()denote the quantile function of the distribution 2
above, thenPcan be given as:
P=
: ( yt)>
CC> 1
( yt) 1()
;
which is equivalent to:
P=
: ( yt)>
 1()CC> 1
( yt)1
;
By lemma C.1, it is equivalent to:
P=
:=yt+
 1()CC>1
2ukuk21
;
whereyt=Axt+Bz
t, anduis an arbitrary point in the unit sphere in RjYtj.
C.2 Proof for Theorem 3.3
Lemma C.2 (Theorem 3 of Cutler et al. [11]).Consider a sequence of stochastic optimization problems
minft()indexed by time t2N. Let ^gtdenote the estimation for the gradient of ft, and?
tdenote the
minimizer of the L-smooth and -strongly convex function ft. Suppose it holds that maxt^gt2<1and
maxtEk?
t+1 ?
tk<1. Then the produced ftgT
t=0with iterates t+1= B(t ^gt) (B=Rjj)
and constant learning rate 1=2Lsatisﬁes:
Ekt ?
tk2.(1 )tk0 ?
0k2
|{z}
optimization+2
|{z}
noise+
2
|{z}
drift:
Lemma C.3 (Convergence of LSE) .Letj;tdenote the true parameter value of jin timet, and ^lse
j;tdenote
the estimation according to Eq. (4). For 8 >0,9n>0that holds:
E^lse
j;t j;t2
2 
Proof. LetPj;t=
PA1
j;t::: PAn
j;t>andvj;t=
V1
j;t;:::;Vn
j;t>. Then the optimization in Eq. (4) is
equivalent to:
arg min
j;tkvj;t Pj;tj;tk2
2:
17Since PAjrepresents the true parents of the generation process for variable Vj,Pj;tis guaranteed to have full
column rank. For8njPAjj, the solution to the optimization above is:
^lse
j;t=
P>
j;tPj;t 1
P>
j;tvj;t:
Because vj;t=Pj;tj;t+"jwhere"jN 
0;2
jIn
according to Eq. (3), we have:
^lse
j;t=j;t+
P>
j;tPj;t 1
P>
j;t"j:
Due to the linear combination property of the Gaussian distribution, it holds that:
^lse
j;t j;tN
0;2
j
P>
j;tPj;t 1
Thus, it can be derived that:
E^lse
j;t j;t2
2= tr
2
j
P>
j;tPj;t 1
=2
jjPAjjX
i=1i
is are eigenvalues of
P>
j;tPj;t 1
max2
jjPAjj=
P>
j;tPj;t 1
22
jjPAjj
Because 
P>
j;tPj;t 1
2P>
j;tPj;t
2 
P>
j;tPj;t 1P>
j;tPj;t
2= 1, we have:
E^lse
j;t j;t2
22
jjPAjjP>
j;tPj;t
2
2
jjPAjj2
PjPAjj
i=1i
is are eigenvalues ofP>
j;tPj;t
2
=2
jjPAjj2
tr 
P>
j;tPj;t=2
jjPAjj2
PjPAjj
i=1Pn
k=1p2
ik2
jjPAjj2
nminkPjPAjj
i=1p2
ik
So for8 >0,9n=2
jjPAjj2
 minkPjPAjj
i=1p2
ik 1
that holds E^lse
j;t j;t2
2 .
Lemma C.4 (Positive-deﬁnite Property) .Consider a set of m-dimensional vectors fvign
i=1,nm. If it
contains at least one set of basis vectors in space Rm, then the following matrix is positive-deﬁnite:
M=nX
i=1viv>
i
Proof. Letfukgm
k=1 fvign
i=1denote a set of basis vectors, and let x2Rmdenote an arbitrary m-
dimensional points in the same space as vis. Then it can be derived that:
x>Mx=nX
i=1
x>vi2
mX
k=1
x>uk2
>0;
because there at least exists one basis vector uhthat holds x>uh6= 0. SoMis positive-deﬁnite (thus Mis
full-rank).
Theorem 3.3. Denote the true parameter of jin timetasj;t(j2[jVj]) and choose j2(0;1=2Lj]as the
step size used in Algorithm 1, it can be bounded in Gthat:
E^j;t j;t2
.(1 jj)t
m^j;0 j;02
+jwithj=mj
jj2
+j2
j;
wherejandLjare the minimal and maximal eigenvalues of f`j;t()gT
t=1’s Hessian matrices respectively, 2
upper-bounds the variance of ^gj;tused in Algorithm 1, jmaxtkj;t+1 j;tkupper-bounds the varying
speed of the environment, and mis the longest continuously altered rounds of Vj, for most of the Vjs,m= 1.
18Proof. For Eq. (4), the Hessain matrix of `j;t()can be derived that:
Hj;t=r2`j;t=1
nnX
k=1PAk
j;tPAk
j;t>
SincenjPAjjandPAk
j;ts arendiscrete samples from a continuous distribution, so
PAk
j;t	n
k=1contains a
set of basis vectors in space RjPAjjwith probability 1. By Lemma C.4, fHj;tgT
t=1are positive-deﬁnite.
Letjdenote mint(Hj;t)andLjdenote maxt(Hj;t)respectively, thenf`j;t()gT
t=1are allLj-smooth
andj-strongly convex. By Lemma C.2 and consider alterations on Vj, estimationsn
^j;toT
t=1obtained from
Algorithm 1 hold that:
E^j;t ?
j;t2
.(1 jj)t=m^j;0 ?
j;02
+ 
m^j
jj!2
+j2
j;
where2upper-bounds the variance of ^gj;tused in Algorithm 1, ^jmaxtk?
j;t+1 ?
j;tkupper-bounds
the varying speed of the minimizer of `j;t, andmis the longest continuously altered rounds of Vj, for most of
theVjs,m= 1. This holds because m^jmmaxtk?
j;t+1 ?
j;tkmaxtPm
k=1k?
j;t+k ?
j;t+k 1k
maxtk?
j;t+m ?
j;tk. Note that if Vjis continuously altered mrounds, it can be viewed as its corresponding
parameters are updated per mrounds.
Besides, since ^lse
j;t,?
j;t+1in such case, let jmaxtk?
j;t+1 ?
j;tk, by Lemma C.3, it holds that
^j.j,^j;0 ?
j;02
.^j;0 j;02
,E?
j;t j;t2 ; and we have:
E^j;t j;t2
.E^j;t ?
j;t2
+E?
j;t j;t2
.(1 jj)t=m^j;0 j;02
+mj
jj2
+j2
j
C.3 Proof of Proposition 3.4
Lemma C.5 (Hoeffding, 1963) .LetXbe a random variable with aXb. Then, for any s2R,
ln Eh
esXi
sE[X] +s2(b a)2
8:
Proposition 3.4. Assumef`j;t()gT
t=1s are bounded for8i2B andt2[T]; then for any 2Hj, estimations
^j;ts from Algorithm 2 satisﬁes that
TX
t=1^`t
^j;t
 TX
t=1^`t 

j;t
Op
TlnNj
;
by choosing =p
lnNj=Tin Algorithm 2, where Njis the number of base-learners, 
j;tis the estimation
from any expert in expert setHjin Algorithm 2.
Proof. Following previous studies [8] (Theorem 2.2 and Exercise 2.5), we deﬁne:
L
t=tX
i=1^`j;i 

j;i
;andWt=X
2Hjw
1e L
t:
From the updating rule in Algorithm 2, it is easy to verify that:
w
t=w
1e L
t 1
P
2Hw
1e L
t 1; t2: (7)
First, it can be derived that:
lnWT= ln0
@X
2Hjw
1e L
T1
Aln
max
2Hjw
1e L
T
= min
2Hj
L
T+1
ln1
w
1
: (8)
19Next, the related quantity ln (Wt=Wt 1)can be bounded as follows when t2:
lnWt
Wt 1
= ln0
@P
2Hw
1e L
t
P
2Hjw
1e L
t 11
A
= ln0
@X
2Hj0
@w
1e L
t 1
P
2Hjw
1e L
t 1e ^`j;t(
j;t)1
A1
A
(7)= ln0
@X
2Hjw
te ^`j;t(
j;t)1
A:
Whent= 1, it holds that lnW1= lnP
2Hw
1e ^`j;1(
j;1)
, thus it can be derived that:
lnWT= lnW1+TX
t=2lnWt
Wt 1
=TX
t=1ln0
@X
2Hjw
te ^`j;t(
j;t)1
A
 X
2Hjw
t^`j;t 

j;t
+2c2
8(cis a constant as ^`j;t()is bounded)
 ^`j;t0
@X
2Hjw
t
j;t1
A+2c2
8= ^`j;t
^j;t
+2c2
8;
(9)
where the inequality in the second line is due to Lemma C.5, and the inequality in the second line is due to
Jensen’s inequality. By combining Eq. (8) and Eq. (9), it can be derived that:
TX
t=1^`j;t
^j;t
 min
2Hj TX
t=1^`j;t 

j;t
+1
ln1
w
1!
Tc2
8
Since we choose w
1=1
Njin Algorithm 2, thus for 2Hj, by choosing =p
lnNj=T, it holds that:
TX
t=1^`j;t
^j;t
 TX
t=1^`j;t 

j;t
.T+1
lnNj=Op
TlnNj
C.4 Proof for Theorem 3.5
Theorem 3.5. By using the suggested alterations from Eq. (6), it can be guaranteed that:
P
Yt2Sj ^t;xt;Rh(t)
:
Proof. Recall that Eq. (6) suggests alterations as follows:
min
zt
t
zt
t z0
t>
W
zt
t z0
t
s.t.MAxt+MBzt
t+kMPk2;rowd;
where P= 
 1()CC>1
2, andkk2;rowmeans an operator that takes 2-norm for each row of the matrix
thus outputs a row-dimensional vector. We omit the subscript 2of the norm in the following discussions.
20Letidenote thei-th row-vector of matrix MP andrdenote the row-dimension of MP , then it can be derived
that:
dMAxt+MBzt
t+kMPk2;row
=MAxt+MBzt
t+ 1k1k;;1krk>
MAxt+MBzt
t+sup
kuk1k1kkukcosh1;ui;;sup
kuk1krkkukcoshr;ui>
=MAxt+MBzt
t+sup
kuk1h1;ui;;sup
kuk1hr;ui>
= sup
kuk1MAxt+MBzt
t+MPu
= sup
kuk1M
yt+
 1()CC>1
2u
whereyt=Axt+Bzt
t. Recall from Prop. 3.2 that P=n
yt+ 
 1()CC>1
2uo
is the probability
region that satisﬁes P
Yt2Sj ^t;xt;Rh(t)
=(since A;B;Care generated from ^trather thant
in this case). Thus, Prop. 3.2 has been proved because (a) it has been derived that for 8yt2P it holds that
dMyt; and (b) the desired region Sdeﬁned in Eq. (3) is S=n
y2RjYjjMydo
.
D Experimental details
The experiments are done by using macOS Monterey, Apple M1 Pro. All algorithms are running under the same
environment.
D.1 Comparison experiment in the setting of Qin et al. [40]
We provide a comparison experiment in the setting of Qin et al. [40], whereGP(G)andP(G)are unknown.
Results on Bermuda data provided in the following table show that our approach exhibits a comparable
performance with the result under the scenario where Gt=G.
Success Frequency Cost Time (s)
Gt=G 0:7110:018 1:460:05 1:710:34
GtPG 0:6980:021 1:430:07 1:990:46
D.2 Market-Manage Data
In this section, we provide details about the Market-Manage data. The variables included in the generation
process are:
• Feature our: The feature used to predict the raw cost of our market;
• Feature cpt: The feature used to predict the raw cost of the competitor market;
• C our: The raw cost of our market;
• C cpt: The raw cost of the competitor market;
• P our: The product price of our market;
• P cpt: The product price of the competitor market;
• NCT: Customer numbers of our market;
• TPF: Total proﬁt of our market.
The rehearsal graph for the variables is illustrated in Fig. 6. The presumed actionable variables that can be altered
by the manager are C ourand P our. The hyperparameters associated with the cost function are set as Z0
Cour= 0:75,
wCour= 2:0; and Z0
Pour= 0:0,wPour= 1:0. The desired region Sis shown in Fig. 7(a). We shade dynamic edges
with red color.
21feature1
XtZtYtNCT
TPFfeature1CourPour
CcptPcptFigure 6: The rehearsal graph for market-manage data.
6
 4
 2
 0 2 4 6
Natural TPF Value4
3
2
1
01234Natural NCT Value
Original Y Distribution
Desired Region 
(a)Yin nature and region Sfor Market data
4
 3
 2
 1
 0 1 2 3
Natural NEC (Y) Value0.000.050.100.150.200.250.300.35Empirical CDF for YOriginal Y Distribution
Desired Region 
 (b)Yin nature and region Sfor Bermuda data
Figure 7: The desired regions Ss of two datasets.
D.3 Bermuda Data
In this section, we provide details about the Bermuda data. The Bermuda data is an environment dataset that
involves some environmental variables in Bermuda [10]. The variables included in the generation process are:
• Light: Light levels at the bottom;
• Temp: Temperature at the bottom;
• Sal: Sea surface salinity;
• DIC: Dissolved inorganic carbon of seawater;
• TA: Total alkalinity of seawater;
•
A: Saturation with respect to aragonite in seawater;
• Chla: Chlorophyll-a at sea surface;
• Nut: PC1 of NH 4, NiO 2+ NiO 3, SiO 4;
• pHsw: pH of seawater;
• CO 2: PCO2of seawater;
• NEC: Net ecosystem calciﬁcation.
22The rehearsal graph for the variables is illustrated in Fig. 8. The presumed actionable variables that can be
altered by the decision-maker are DIC, TA, 
A, Chla, and Nut according to Aglietti et al. [1], Qin et al. [40].
The hyperparameters associated with the cost function are set as Z0
DIC=Z0
TA=Z0

A=Z0
Chla=Z0
Nut= 0:0; and
wDIC= 10:0,wTA= 8:0,w
A= 3:0,wChla= 5:0,wNut= 10:0. The desired region Sis shown in Fig. 7(b).
We shade dynamic edges with red color.
Light
TempDIC
ΩANEC
SalTANutpHswCO2Chla
XtZtYt
Figure 8: The rehearsal graph for Bermuda data.
23NeurIPS Paper Checklist
1.Claims
Question: Do the main claims made in the abstract and introduction accurately reﬂect the paper’s
contributions and scope?
Answer: [Yes]
Justiﬁcation: Contributions of the paper are summarized in the abstract and listed in the last paragraph
of Sec. 1. Meanwhile, the scope is also introduced in Sec. 1.
Guidelines:
•The answer NA means that the abstract and introduction do not include the claims made in the
paper.
•The abstract and/or introduction should clearly state the claims made, including the contributions
made in the paper and important assumptions and limitations. A No or NA answer to this
question will not be perceived well by the reviewers.
•The claims made should match theoretical and experimental results, and reﬂect how much the
results can be expected to generalize to other settings.
•It is ﬁne to include aspirational goals as motivation as long as it is clear that these goals are not
attained by the paper.
2.Limitations
Question: Does the paper discuss the limitations of the work performed by the authors?
Answer: [Yes]
Justiﬁcation: The limitations of the work are discussed in the separate "Discussion" section in
Appendix A, as pointed out in the ﬁrst paragraph of Sec. 3.
Guidelines:
•The answer NA means that the paper has no limitation while the answer No means that the paper
has limitations, but those are not discussed in the paper.
• The authors are encouraged to create a separate "Limitations" section in their paper.
•The paper should point out any strong assumptions and how robust the results are to violations of
these assumptions (e.g., independence assumptions, noiseless settings, model well-speciﬁcation,
asymptotic approximations only holding locally). The authors should reﬂect on how these
assumptions might be violated in practice and what the implications would be.
•The authors should reﬂect on the scope of the claims made, e.g., if the approach was only tested
on a few datasets or with a few runs. In general, empirical results often depend on implicit
assumptions, which should be articulated.
•The authors should reﬂect on the factors that inﬂuence the performance of the approach. For
example, a facial recognition algorithm may perform poorly when image resolution is low or
images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide
closed captions for online lectures because it fails to handle technical jargon.
•The authors should discuss the computational efﬁciency of the proposed algorithms and how
they scale with dataset size.
•If applicable, the authors should discuss possible limitations of their approach to address problems
of privacy and fairness.
•While the authors might fear that complete honesty about limitations might be used by reviewers
as grounds for rejection, a worse outcome might be that reviewers discover limitations that
aren’t acknowledged in the paper. The authors should use their best judgment and recognize
that individual actions in favor of transparency play an important role in developing norms that
preserve the integrity of the community. Reviewers will be speciﬁcally instructed to not penalize
honesty concerning limitations.
3.Theory Assumptions and Proofs
Question: For each theoretical result, does the paper provide the full set of assumptions and a complete
(and correct) proof?
Answer: [Yes]
Justiﬁcation: Assumptions are listed in Eq. 3 (with its contexts), and in each Theorem/Proposition. All
proofs are given in Appendix C.
Guidelines:
• The answer NA means that the paper does not include theoretical results.
24• All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced.
• All assumptions should be clearly stated or referenced in the statement of any theorems.
•The proofs can either appear in the main paper or the supplemental material, but if they appear in
the supplemental material, the authors are encouraged to provide a short proof sketch to provide
intuition.
•Inversely, any informal proof provided in the core of the paper should be complemented by
formal proofs provided in appendix or supplemental material.
• Theorems and Lemmas that the proof relies upon should be properly referenced.
4.Experimental Result Reproducibility
Question: Does the paper fully disclose all the information needed to reproduce the main experimental
results of the paper to the extent that it affects the main claims and/or conclusions of the paper
(regardless of whether the code and data are provided or not)?
Answer: [Yes]
Justiﬁcation: The code and data for the main experimental results are provided in the supplemental
material. Dataset and experimental details are introduced in Sec. 5 and Appendix D.
Guidelines:
• The answer NA means that the paper does not include experiments.
•If the paper includes experiments, a No answer to this question will not be perceived well by the
reviewers: Making the paper reproducible is important, regardless of whether the code and data
are provided or not.
•If the contribution is a dataset and/or model, the authors should describe the steps taken to make
their results reproducible or veriﬁable.
•Depending on the contribution, reproducibility can be accomplished in various ways. For
example, if the contribution is a novel architecture, describing the architecture fully might sufﬁce,
or if the contribution is a speciﬁc model and empirical evaluation, it may be necessary to either
make it possible for others to replicate the model with the same dataset, or provide access to
the model. In general. releasing code and data is often one good way to accomplish this, but
reproducibility can also be provided via detailed instructions for how to replicate the results,
access to a hosted model (e.g., in the case of a large language model), releasing of a model
checkpoint, or other means that are appropriate to the research performed.
•While NeurIPS does not require releasing code, the conference does require all submissions
to provide some reasonable avenue for reproducibility, which may depend on the nature of the
contribution. For example
(a)If the contribution is primarily a new algorithm, the paper should make it clear how to
reproduce that algorithm.
(b)If the contribution is primarily a new model architecture, the paper should describe the
architecture clearly and fully.
(c)If the contribution is a new model (e.g., a large language model), then there should either be
a way to access this model for reproducing the results or a way to reproduce the model (e.g.,
with an open-source dataset or instructions for how to construct the dataset).
(d)We recognize that reproducibility may be tricky in some cases, in which case authors are
welcome to describe the particular way they provide for reproducibility. In the case of
closed-source models, it may be that access to the model is limited in some way (e.g.,
to registered users), but it should be possible for other researchers to have some path to
reproducing or verifying the results.
5.Open access to data and code
Question: Does the paper provide open access to the data and code, with sufﬁcient instructions to
faithfully reproduce the main experimental results, as described in supplemental material?
Answer: [Yes]
Justiﬁcation: The code and data for the main experimental results are provided in the supplemental
material. The dataset used in the experiments is also accessible from the link of the reference.
Guidelines:
• The answer NA means that paper does not include experiments requiring code.
•Please see the NeurIPS code and data submission guidelines ( https://nips.cc/public/
guides/CodeSubmissionPolicy ) for more details.
•While we encourage the release of code and data, we understand that this might not be possible,
so “No” is an acceptable answer. Papers cannot be rejected simply for not including code, unless
this is central to the contribution (e.g., for a new open-source benchmark).
25•The instructions should contain the exact command and environment needed to run to reproduce
the results. See the NeurIPS code and data submission guidelines ( https://nips.cc/public/
guides/CodeSubmissionPolicy ) for more details.
•The authors should provide instructions on data access and preparation, including how to access
the raw data, preprocessed data, intermediate data, and generated data, etc.
•The authors should provide scripts to reproduce all experimental results for the new proposed
method and baselines. If only a subset of experiments are reproducible, they should state which
ones are omitted from the script and why.
•At submission time, to preserve anonymity, the authors should release anonymized versions (if
applicable).
•Providing as much information as possible in supplemental material (appended to the paper) is
recommended, but including URLs to data and code is permitted.
6.Experimental Setting/Details
Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters,
how they were chosen, type of optimizer, etc.) necessary to understand the results?
Answer: [Yes]
Justiﬁcation: Dataset and experimental setting are introduced in the core of the paper (Sec. 5). The
full details are provided in Appendix D and the code contained in the supplemental material.
Guidelines:
• The answer NA means that the paper does not include experiments.
•The experimental setting should be presented in the core of the paper to a level of detail that is
necessary to appreciate the results and make sense of them.
• The full details can be provided either with the code, in appendix, or as supplemental material.
7.Experiment Statistical Signiﬁcance
Question: Does the paper report error bars suitably and correctly deﬁned or other appropriate informa-
tion about the statistical signiﬁcance of the experiments?
Answer: [Yes]
Justiﬁcation: Error bars and error bands are provided in Fig. 4. As introduced in the ﬁrst paragraph
of Sec. 5, we repeat the experiments 20 times (20 different random seeds).
Guidelines:
• The answer NA means that the paper does not include experiments.
•The authors should answer "Yes" if the results are accompanied by error bars, conﬁdence
intervals, or statistical signiﬁcance tests, at least for the experiments that support the main claims
of the paper.
•The factors of variability that the error bars are capturing should be clearly stated (for example,
train/test split, initialization, random drawing of some parameter, or overall run with given
experimental conditions).
•The method for calculating the error bars should be explained (closed form formula, call to a
library function, bootstrap, etc.)
• The assumptions made should be given (e.g., Normally distributed errors).
•It should be clear whether the error bar is the standard deviation or the standard error of the
mean.
•It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report
a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is
not veriﬁed.
•For asymmetric distributions, the authors should be careful not to show in tables or ﬁgures
symmetric error bars that would yield results that are out of range (e.g. negative error rates).
•If error bars are reported in tables or plots, The authors should explain in the text how they were
calculated and reference the corresponding ﬁgures or tables in the text.
8.Experiments Compute Resources
Question: For each experiment, does the paper provide sufﬁcient information on the computer
resources (type of compute workers, memory, time of execution) needed to reproduce the experiments?
Answer: [Yes]
Justiﬁcation: The time of execution is denoted in Table 1. Information on the computer resources is
introduced in the ﬁrst paragraph of Appendix D.
Guidelines:
26• The answer NA means that the paper does not include experiments.
•The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud
provider, including relevant memory and storage.
•The paper should provide the amount of compute required for each of the individual experimental
runs as well as estimate the total compute.
•The paper should disclose whether the full research project required more compute than the
experiments reported in the paper (e.g., preliminary or failed experiments that didn’t make it into
the paper).
9.Code Of Ethics
Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code
of Ethics https://neurips.cc/public/EthicsGuidelines ?
Answer: [Yes]
Justiﬁcation: The research conducted in the paper conforms with the NeurIPS Code of Ethics in every
respect.
Guidelines:
• The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
•If the authors answer No, they should explain the special circumstances that require a deviation
from the Code of Ethics.
•The authors should make sure to preserve anonymity (e.g., if there is a special consideration due
to laws or regulations in their jurisdiction).
10.Broader Impacts
Question: Does the paper discuss both potential positive societal impacts and negative societal impacts
of the work performed?
Answer: [Yes]
Justiﬁcation: The paper has discussed in Sec. 1 and Sec. 6 that our proposed algorithm could be used
to make decisions in certain cases, which may potentially lead to some positive societal impacts.
Guidelines:
• The answer NA means that there is no societal impact of the work performed.
•If the authors answer NA or No, they should explain why their work has no societal impact or
why the paper does not address societal impact.
•Examples of negative societal impacts include potential malicious or unintended uses (e.g.,
disinformation, generating fake proﬁles, surveillance), fairness considerations (e.g., deploy-
ment of technologies that could make decisions that unfairly impact speciﬁc groups), privacy
considerations, and security considerations.
•The conference expects that many papers will be foundational research and not tied to particular
applications, let alone deployments. However, if there is a direct path to any negative applications,
the authors should point it out. For example, it is legitimate to point out that an improvement in
the quality of generative models could be used to generate deepfakes for disinformation. On the
other hand, it is not needed to point out that a generic algorithm for optimizing neural networks
could enable people to train models that generate Deepfakes faster.
• The authors should consider possible harms that could arise when the technology is being used
as intended and functioning correctly, harms that could arise when the technology is being used
as intended but gives incorrect results, and harms following from (intentional or unintentional)
misuse of the technology.
•If there are negative societal impacts, the authors could also discuss possible mitigation strategies
(e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitor-
ing misuse, mechanisms to monitor how a system learns from feedback over time, improving the
efﬁciency and accessibility of ML).
11.Safeguards
Question: Does the paper describe safeguards that have been put in place for responsible release of
data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or
scraped datasets)?
Answer: [NA]
Justiﬁcation: This work focuses on the methodology level and poses no such risks, because the datasets
used in the paper are synthetic or have been used in previous academic articles.
Guidelines:
27• The answer NA means that the paper poses no such risks.
•Released models that have a high risk for misuse or dual-use should be released with necessary
safeguards to allow for controlled use of the model, for example by requiring that users adhere to
usage guidelines or restrictions to access the model or implementing safety ﬁlters.
•Datasets that have been scraped from the Internet could pose safety risks. The authors should
describe how they avoided releasing unsafe images.
•We recognize that providing effective safeguards is challenging, and many papers do not require
this, but we encourage authors to take this into account and make a best faith effort.
12.Licenses for existing assets
Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper,
properly credited and are the license and terms of use explicitly mentioned and properly respected?
Answer: [Yes]
Justiﬁcation: The dataset used in the experiment is properly cited including a URL in reference.
Meanwhile, the original papers of models used in the competitive experiment are properly cited.
Guidelines:
• The answer NA means that the paper does not use existing assets.
• The authors should cite the original paper that produced the code package or dataset.
• The authors should state which version of the asset is used and, if possible, include a URL.
• The name of the license (e.g., CC-BY 4.0) should be included for each asset.
•For scraped data from a particular source (e.g., website), the copyright and terms of service of
that source should be provided.
•If assets are released, the license, copyright information, and terms of use in the package should
be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for
some datasets. Their licensing guide can help determine the license of a dataset.
•For existing datasets that are re-packaged, both the original license and the license of the derived
asset (if it has changed) should be provided.
•If this information is not available online, the authors are encouraged to reach out to the asset’s
creators.
13.New Assets
Question: Are new assets introduced in the paper well documented and is the documentation provided
alongside the assets?
Answer: [Yes]
Justiﬁcation: The code and model introduced in the paper are well documented, and the documentation
is provided alongside the assets.
Guidelines:
• The answer NA means that the paper does not release new assets.
•Researchers should communicate the details of the dataset/code/model as part of their sub-
missions via structured templates. This includes details about training, license, limitations,
etc.
•The paper should discuss whether and how consent was obtained from people whose asset is
used.
•At submission time, remember to anonymize your assets (if applicable). You can either create an
anonymized URL or include an anonymized zip ﬁle.
14.Crowdsourcing and Research with Human Subjects
Question: For crowdsourcing experiments and research with human subjects, does the paper include
the full text of instructions given to participants and screenshots, if applicable, as well as details about
compensation (if any)?
Answer: [NA]
Justiﬁcation: The paper does not involve crowdsourcing nor research with human subjects.
Guidelines:
•The answer NA means that the paper does not involve crowdsourcing nor research with human
subjects.
•Including this information in the supplemental material is ﬁne, but if the main contribution of the
paper involves human subjects, then as much detail as possible should be included in the main
paper.
28•According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other
labor should be paid at least the minimum wage in the country of the data collector.
15.Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects
Question: Does the paper describe potential risks incurred by study participants, whether such
risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an
equivalent approval/review based on the requirements of your country or institution) were obtained?
Answer: [NA]
Justiﬁcation: The paper does not involve crowdsourcing nor research with human subjects.
Guidelines:
•The answer NA means that the paper does not involve crowdsourcing nor research with human
subjects.
•Depending on the country in which research is conducted, IRB approval (or equivalent) may be
required for any human subjects research. If you obtained IRB approval, you should clearly state
this in the paper.
•We recognize that the procedures for this may vary signiﬁcantly between institutions and
locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for
their institution.
• For initial submissions, do not include any information that would break anonymity (if applica-
ble), such as the institution conducting the review.
29