High Rank Path Development: an approach to
learning the filtration of stochastic processes
Jiajie Tao
Department of Mathematics
University College London
ucahjta@ucl.ac.ukHao Ni
Department of Mathematics
University College London
h.ni@ucl.ac.uk
Chong Liu∗
Institute of Mathematical Sciences
ShanghaiTech University
liuchong@shanghaitech.edu.cn
Abstract
Since the weak convergence for stochastic processes does not account for the
growth of information over time which is represented by the underlying filtration,
a slightly erroneous stochastic model in weak topology may cause huge loss in
multi-periods decision making problems. To address such discontinuities Aldous in-
troduced the extended weak convergence, which can fully characterise all essential
properties, including the filtration, of stochastic processes; however was considered
to be hard to find efficient numerical implementations. In this paper, we introduce
a novel metric called High Rank PCF Distance (HRPCFD) for extended weak con-
vergence based on the high rank path development method from rough path theory,
which also defines the characteristic function for measure-valued processes. We
then show that such HRPCFD admits many favourable analytic properties which
allows us to design an efficient algorithm for training HRPCFD from data and con-
struct the HRPCF-GAN by using HRPCFD as the discriminator for conditional time
series generation. Our numerical experiments on both hypothesis testing and genera-
tive modelling validate the out-performance of our approach compared with several
state-of-the-art methods, highlighting its potential in broad applications of synthetic
time series generation and in addressing classic financial and economic challenges,
such as optimal stopping or utility maximisation problems. Code is available at
https://github.com/DeepIntoStreams/High-Rank-PCF-GAN.git .
1 Introduction
A popular criterion for measuring the differences between two stochastic processes is the weak
convergence. In this framework, one views stochastic processes as path-valued random variables and
then defines the convergence for their laws, which are distributions on path space. However, this
viewpoint ignores the filtration of stochastic processes, which models the evolution of information,
and therefore such loss may have negative implications in multi-period optimisation problems. For
example, for the American option pricing task, even if the two underlying processes are stochastic
processes with very similar laws, the corresponding price of American options can be completely
different, see a toy example A.1 in Appendix A.1. To address this shortcoming of weak conver-
gence, D. Aldous [ 1] introduced the notion of extended weak convergence . The central object in
∗Corresponding author
38th Conference on Neural Information Processing Systems (NeurIPS 2024).this methodology is the so-called prediction process, which consists of conditional distributions
of the underlying process based on available information at different time beings, and therefore
reflects how the associated information flow (i.e., filtration) affects the prediction of the future
evolution of the underlying process as time varies. Instead of considering the laws of processes (i.e.,
distributions on path space) in weak convergence, one compares the laws of prediction processes,
which are distributions on the measure-valued path space, in extended weak convergence. Since
the knowledge of filtration is captured through taking conditional distributions, it was shown in
[3] the topology induced by extended weak convergence, which belongs to the so-called adapted
weak topologies2, fully characterise essential properties of stochastic processes and endow multi-
period optimisation problems with continuity, provided filtration is generated by the process itself.
Figure 1: The high-level illustration of the high rank path
development. Here the prediction process ˆXt:=P(X|Ft)
for all t∈[0, T],ΦˆXt(M1)is the PCF of the prediction
process and UM1,M2(ˆX)is the high rank development of the
patht7→ΦˆXt(M1)under the linear map M2.While the theoretical contributions to
adapted weak topologies flourish in
recent years (e.g., [ 3], [2], [4]), the
related work on numerics is still very
sparse because of the very complex
nature of these topologies. In this pa-
per, we propose a novel metric called
High Rank Path Characteristic Func-
tion (HRPCFD) which can metrise
the extended weak convergence, and,
more importantly, admits an efficient
implementation algorithm. The core
idea of this approach is built on top of
the unitary feature of Rd-valued paths
([18], [7]), which exploits the non-
commutativity and the group structure
of the unitary developments to encode
information on order of paths. Based
on the same consideration, Lou et al.
[19] introduced the Path Characteris-
tic Function (PCF) for stochastic pro-
cesses, which induces a computable distance (namely, PCFD) to metrise the weak convergence. As
extended weak convergence is defined in terms of laws of prediction processes which are measure-
valued stochastic processes, the scheme of PCF remains valid in adapted weak topologies as long
as one can construct a PCF of measure-valued paths. One of the main contributions of the present
work is to give such a suitable notion via the so-called high rank path development (see Figure 1
for illustration); moreover, we can show that the induced distance (called HRPCFD ) does not only
characterise the more complicated extended weak convergence, but also inherits almost all favourable
analytic properties of classical PCFD mentioned in [ 19]. Since the measure-valued paths take values
in an infinite dimensional nonlinear space, such a generalisation of the results in [ 19] fromRd-valued
paths to measure-valued paths is much technically involved and therefore significantly nontrivial.
On the numerical side, we design an efficient algorithm to train HRPCFD from data and construct
the HRPCF-GAN model with HRPCFD as the discriminator for time series generation. A key
computational challenge in applying distances based on extended weak topology is the accurate
and efficient estimation of the conditional probability measure. To address this issue, we have
implemented a sequence-to-sequence regression module that effectively resolves this bottleneck. Our
work is the first of its kind to apply the adapted weak topology for generative models on time series
generation. Moreover, to validate the effectiveness of our approach, we conduct experiments in (1)
hypothesis testing to classify different stochastic processes, and (2) conditional time series generation
to predict the future time series given the past time series. Our HRPCF-GAN can be viewed as a
natural generalisation of PCF-GAN [ 19] to the setting of extended weak convergence, so that the
data generated by HRPCF-GAN possesses not only a similar law but also a similar filtration with the
target model. The numerical experiments validate the out-performance of this new approach based
onHRPCFD compared with several state-of-the-art GAN models for time series generation in terms
of various test metrics.
2In general, any topology on the space of stochastic processes which can reflect the differences of associated
filtrations can be called an adapted weak topology.
2Related work. So far most of existing statistical and numerical methods for handling stochastic pro-
cesses (e.g., [ 9,16,19]) are based on weak convergence, and the results on numerical implementation
of adapted weak topologies are rather limited. The most relevant work is [ 21], whose theoretical
foundation roots in [ 5]. The present paper shares a similar philosophy with [ 21] in the sense that both
methods for defining metrics for extended weak convergence rely on the construction of a feature of
the measure-valued path by transforming it into a linear space-valued path. In contrast to [ 21], where
a measure-valued path is lifted to an infinite-dimensional Hilbert space, we reduce measure-valued
paths into matrix-valued paths through unitary development which allows us to apply the techniques
from [ 19] to design the algorithm. Another remarkable point is that in [ 21] one has to solve a large
family of PDEs to compute the distance, which can be avoided in the numerical estimation of the
HRPCFD proposed here. On the other hand, as Wasserstein distances can metrise weak convergence,
the so-called causal Wasserstein distances can be used to measure adapted weak topologies. One
related work is [ 22] which can be seen as an improved variant of the Sinkhorn divergence tailored to
sequential data. Note that the discriminator (i.e., causal Wasserstein metric) used in [ 22] is slightly
weaker than the HRPCFD, as the latter is actually equivalent to the bi-causal Wasserstein distance.
2 Preliminaries
2.1 Prediction Processes and Extended Weak Convergence
LetI={0, . . . , T }andX= (Xt)t∈Ibe anRd–valued stochastic process defined on a filtered
stochastic basis (ΩX,F,F= (Ft)t∈I,P)such that Xis adapted to the filtration F, i.e., Xtis
measurable with respect to Ftfor all t∈I. We call the five–tuple (ΩX,F,F, X,P)afiltered process ,
and denote it by X. Throughout this paper, we will use FPto denote the space of all ( Rd–valued)
filtered processes on the discrete time interval I, and assume that Fis the natural filtration in the
sense that for every t∈I,Ft=σ(X0, . . . , X t).
Since each discrete time path x∈(Rd)T+1can be uniquely extended to a piecewise linear path on
[0, T]by linear interpolation, we will not distinguish the product space (Rd)T+1and the subspace
X:={x: [0, T]→Rd:xis piecewise linear }ofC1-var([0, T],Rd)(the space of all continuous
functions in Rdwith bounded variation)3. Clearly each stochastic process Xcan be seen as X-valued
random variable, and therefore the law of X, denoted by PX=P◦X−1, belongs to P(X), the
space of probability measures on the path space X. Recall that a sequence of filtered processes
Xn= (Ωn,Fn,Fn, Xn,Pn)converges to a limit Xweakly or in the weak topology (in notation:
XnW− →X) if the laws PXn=Pn◦(Xn)−1converges to PXinP(X)weakly, i.e., for all continuous
and bounded functions f∈Cb(X), it holds that limn→∞EPn[f(Xn)] =EP[f(X)].
For each t∈I, we denote ˆXt:=P(X∈ ·|F t)as the (regular) conditional distribution of X
givenFt, which is a random measure taking values in P(X). We call this measure-valued process
ˆX= (ˆXt)t∈Itheprediction process of the filtered process X. By definition it is clear that the state
space of ˆXisP(X)T+1and, again, by a routine linear interpolation4, we can embed P(X)T+1into
ˆX={p: [0, T]→ P(X) :pis piecewise linear }. Thus the law of ˆX, denoted by PˆX=P◦ˆX−1,
belongs to P(ˆX)(the space of probability measures on the measure-valued path space ˆX), where ˆX
is endowed with the product topology and P(ˆX)is equipped with the corresponding weak topology.
Definition 2.1. •Two filtered processes X= (ΩX,F,F, X,P)andY= (ΩY,G,G, Y,Q)
are called synonymous if their prediction processes ˆXandˆYhave the same law in P(ˆX),
i.e.,PˆX=PˆY.
•A sequence of filtered processes Xn= (Ωn,Fn,Fn, Xn,Pn),n∈Nconverges to another
filtered process X= (ΩX,F,F, X,P)in the extended weak convergence if the law of
their prediction processes ˆXnconverges to the law of ˆXinP(ˆX)weakly, i.e., for all
continuous and bounded functions ˆf∈Cb(ˆX),limn→∞EPn[ˆf(ˆXn)] =EP[ˆf(ˆX)]. In
notation: XnEW− − − →X.
3This means that Xis equipped with the topology induced by the total variation norm.
4Forp0=t0,pt1, . . . ,ptN=T∈ P(X)andt∈[0, T], define pt=t−ti
ti+1−tipti+1+ti+1−t
ti+1−tipti.
3IfFn
0andF0are the trivial σ-algebra, then ˆXn
0=PXnandˆX0=PXare laws of XnandX
respectively, so that XnEW− − − →Xcertainly implies that XnW− →X. This implies that extended weak
convergence is stronger than weak convergence. Moreover, the extended weak convergence induces
the correct topology in multi-period decision making problems, as the next theorem (see [ 1,3])
shows.
Theorem 2.2. The extended weak convergence provides continuity for the value functions in multi-
period optimisation problems (e.g., optimal stopping problem, utility maximisation problem), as long
as the reward function is continuous and bounded.
Admittedly, the above notions related to extended weak convergence (e.g., the spaces ˆXandP(ˆX),
the weak convergence in P(ˆX)etc.) are rather abstract. Therefore, we provide some simple examples
in Appendix A.1 to explain these notions in a more transparent way. We refer readers to [ 1] and [ 3]
for more details on extended weak convergence.
2.2 Path Development and Path Characteristic Function (PCF)
In this subsection, we review some important notions and properties of Rd-valued path development
and characteristic function (PCF) for Rd-valued stochastic processes, which will be used later to
construct characteristic functions for measure-valued stochastic processes. More technical details
on PCF can be found in Appendix A.2. We also refer readers to [ 19] and [ 18] for a more detailed
discussion on this topic.
Form∈N, letCm×mbe the space of m×mcomplex matrices, Imdenote the identity matrix in
Cm×m, and∗be conjugate transpose. Write U(m)and u(m)for the Lie group of m×munitary
matrices and its Lie algebra, resp.:
U(m) ={A∈Cm×m:A∗A=Im},u(m) ={A∈Cm×m:A+A∗= 0}.
LetL(Rd,u(m))denote the space of linear mappings from Rdtou(m).
Definition 2.3. Letx∈C1-var([0, T],Rd)be a continuous path with bounded variation and M∈
L(Rd,u(m))be a linear map. The unitary feature of xunder Mis the solution y: [0, T]→U(m)
to the following equation:
dyt=ytM(dxt),y0=Im, (1)
where ytM(dxt)denotes the usual matrix product. We write UM(x) :=yT, i.e., the endpoint of the
solution path, and by an abuse of notation, also call it the unitary feature of x(under M).
The unitary feature is a special case of the path development , for which one may consider paths taking
values in any Lie group G. It is easy to see that for piecewise linear path x= (x0, . . . ,xT)∈ X, it
holdsUM(x) =QT
i=1exp(M(∆xi))for∆xi=xi−xi−1andexpdenotes the matrix exponential.
We now use the unitary feature to define the Path Characteristic Function (PCF) for Rd-valued
stochastic processes:
Definition 2.4. LetX= (ΩX,F,F, X,P)be a filtered process and PXbe its law. The Path
Characteristic Function (PCF) of Xis the map ΦX:S
m∈NL(Rd,u(m))→S
m∈NCm×mgiven by
ΦX(M) :=EP[UM(X)] =Z
XUM(x)PX(dx).
Remark 2.5. In the present work, we only consider the discrete-time processes defined on I=
0, . . . , T , and therefore the time index tappeared in the stochastic process Xtand its filtration Ftonly
takes values in 0, . . . , T . It is just a convention in the rough path community that one views a discrete
time path defined on I= 0, . . . , T as a piecewise linear path defined on the continuous time interval
[0, T]by a routine linear interpolation, because such identification may make some formulations and
computations easier (e.g., by doing so the unitary feature of a path can be formulated as the solution
of an ODE on [0, T]).
To distinguish ΦXfrom the so-called high rank PCF which will be defined in the next subsection, we
also call ΦXthe rank 1PCF. The next theorem (see [ 19, Theorem 3.2]) justifies why ΦXdefined in
Definition 2.4 is called PCF for path-valued random variables.
4Theorem 2.6 (Characteristicity of laws) .ForXandYtwo filtered processes, they have the same law
(i.e.,PX=PY) if and only if ΦX=ΦY.
The characteristicity of PCF allows us to define a novel distance on FPwhich metrises the weak
convergence (locally). This metric is called the PCF-based distance (PCFD), see [ 19, Definition 3.3].
Moreover, such PCFD possesses many nice analytic properties including boundedness ([ 19, Lemma
3.5]), Maximum Mean Discrepancy (MMD, [ 19, Proposition B.10]) among others, see [ 19, Section
3.2], which ensures the feasibility of using PCFD in numerical aspect.
Remark 2.7. Rigorously speaking, we need to add an additional time component to every Rd-valued
process X(i.e., consider ¯Xt= (t, X1
t, . . . , Xd
t)) to guarantee Theorem 2.6 holds true. We will
always implicitly use such time-augmentation throughout the whole paper and still write Xinstead
of¯Xfor simplicity of notations.
3 High Rank Path Development Embedding
We now want to construct a characteristic function for prediction processes and use it to metrise the ex-
tended weak convergence just like PCFD metrises the weak convergence. Since prediction processes
areˆX-valued random variables, we first need to find a suitable notion of unitary feature/development
for measure-valued paths.
3.1 High Rank Development of Prediction Processes
Given a filtered process X= (ΩX,F,F, X,P), remember that its prediction process ˆXsatisfies
ˆXt=P(X∈ ·|F t)fort∈I. Now, for a linear operators M∈ L(Rd,u(n))forn∈N, we take
the conditional expectation of UMagainst ˆXt=P(X∈ ·|F t)to obtain a Cn×n–valued stochastic
process ΦˆXt(M) =EP[UM(X)|Ft], t∈I.Then, for any M ∈ L (Cn×n,u(m))with some m∈N,
the unitary feature UM(t7→ΦˆXt(M))ofCn×n–valued path (t7→ΦˆXt(M))is well defined and
takes values in the unitary group U(m). We call each pair (M,M)∈ L(Rd,u(n))×L(Cn×n,u(m))
for(n, m)∈N2an admissible pair of unitary representations, and the set of all admissible pairs of
unitary representations is denoted by Aunitary .
Definition 3.1. For(M,M)∈ A unitary withM∈ L(Rd,u(n)),M ∈ L (Cn×n,u(m))andX=
(ΩX,F,F, X,P)a filtered process with its prediction process ˆX, we call
UM,M(ˆX) :=UM(t7→ΦˆXt(M)) (2)
the high rank development of the prediction process ˆXunder (M,M).
See Figure 1 for the schematic overview of the high rank development. From above we can see
that the construction of UM,M(ˆX)involves with taking finite dimensional path development in
Section 2.2 twice : first use the PCF under M∈ L(Rd,u(n))to transform each conditional distribution
P(X∈ ·|F t)into a matrix ΦˆXt(M), and then apply the unitary feature UM(·)to the resulting matrix-
valued path (t7→ΦˆXt(M))forM ∈ L (Cn×n,u(m)).
3.2 High Rank Path Characteristic Function
With the above notion of unitary feature of measure-valued paths, following Definition 2.4, we define
the high rank Path Characteristic Function (HRPCF) for filtered processes.
Definition 3.2. For a filtered process X= (ΩX,F,F, X,P)∈FP, the function
Φ2
X:Aunitary→∞[
m=1Cm×m; (M,M)7→EP[UM,M(ˆX)] =EP[UM(t7→EP[UM(X)|Ft])].(3)
is called the High Rank Path Characteristic Function of X(Abbreviation: HRPCF)5.
5We use the superscript “ 2” inΦ2
Xto emphasise that Φ2
Xis induced by taking usual path development twice.
5Φ2
Xis said to be a HRPCF for Xas it satisfies the following characteristicity of synonym for filtered
processes (see Definition 2.1). For a detailed proof please check the Appendix A.
Theorem 3.3 (Characteristicity of synonym) .Two filtered processes XandYare synonymous if and
only if they have the same high rank PCF , that is, Φ2
X(M,M) =Φ2
Y(M,M),∀(M,M)∈ A unitary.
3.3 A New Distance induced by High Rank PCF
In this subsection, we will use the second rank PCF to define a distance on FP, which can (locally)
characterize the extended weak convergence, as the classical PCFD introduced in subsection 2.2 can
metrise the weak topology on FP.
Definition 3.4. For two filtered processes XandY, let(M,M)be a random admissible pair in
Aunitary withM∈ L(Rd,u(n))for some n, andM∈ L(Cn×n,u(m))for some m. The High Rank
Path Characteristic Function-based distance, for short HRPCFD, between XandYwith respect to
PMandPMis defined by
HRPCFD2
M,M(X,Y) =Z Z
d2
HS(Φ2
X(M,M),Φ2
Y(M,M))PM(dM)PM(dM),
where dHS(·,·)denotes the Hilbert-Schmidt distance6onCm×m.
As previously mentioned in the introduction, the so-defined HRPCFD shares the same analytic
properties as the classical PCF, e.g., the separation of points, boundedness and the MMD property,
whose proof can be found in Appendix A. Moreover, it metrises a much stronger topology (the
extended weak convergence). as shown in the next theorem.
Theorem 3.5. Suppose (Xi)i∈NandXare filtered processes whose laws PXiandPXare supported
in a compact subset of X. ThenXiEW− − − →Xiff^HRPCFD (Xi,X)→0, where
^HRPCFD (Xi,X) :=∞X
j=1min{1,HRPCFD Mj,Mj(Xi,X)}
2j
where the sequence (Mj,Mj)j∈Nsatisfies that for any (n, m)∈N2there is a j∈Nsuch that
Mj∈ L(Rd,u(n))andMj∈ L(Cn×n,u(m))andPMj,PMjhave full supports for all j∈N.
We provide a concrete example in the last paragraph of Appendix A.1 to verify the fact that HRPCFD
really reflects the differences of filtrations via an explicit computation.
4 Methodology
In this section, let XandYbe two filtered processes with the law PX, PY∈ P(X), letX=
(xi)N
i=1∼PXandY= (yi)N
i=1∼PYbe sample paths.
4.1 Estimating conditional probability measure and HRPCF
A fundamental question is to estimate the conditional probability measure ˆXt=P(X∈ ·|F t)from
the finitely many data (xi)N
i=1, in particular the random variable ΦˆXt(M) =EP[UM(X)|Ft]for
anyM∈ L(Rd,u(n)). We solve this problem by conducting a regression. Fix Mwe learn a
sequence-to-sequence model FX
θ:Rd×(T+1)→Cn×n×(T+1), where the input and output pairs are
(X[0,T],UM(X[t,T])T
t=0). More specifically, we optimize the model parameters of FX
θby minimizing
the loss function:
RLoss (θ;x, M) =TX
t=0X
x∈Xd2
HS(FX
θ(x[0,T])t,UM(x[t,T])). (4)
It is worth noting that the choice of FX
θmust be autoregressive models to prevent information
leakage. A detailed pseudocode is shown in Algorithm 1. Then, we approximate Φ2
Xusing the trained
regression model FX
θfollowing the Algorithm 2. We denote by ˆΦ2
Xthe estimation of Φ2
X.
6ForA, B∈Cm×m,d2
HS(A, B) =tr((A−B)(A−B)∗).
64.2 Optimizing HRPCFD
In most empirical applications as we will show in Section 5, we employ HRPCFD as a discriminator
under the GAN setting. That is, we optimize the loss function supM,MHRPCFD2
M,M(X,Y).
We would approximate the pair of random variables (M,M)by discrete random variables
MK1=1
K1PK1
i=1MiandMK2=1
K2PK2
i=1Mi,parametrized by Mi∈ L(Rd,u(n))and
Mi∈ L(Cn×n,u(m)),K1, K2∈Nand optimize so-called Empirical HRPCFD
EHRPCFD2
MK1,MK2(X,Y) =1
K1K2K1X
i=1K2X
j=1d2
HS(ˆΦ2
X(Mi,Mj),ˆΦ2
Y(Mi,Mj)). (5)
In practice, the joint training on both MK1andMK2is computationally expensive and prone to
overfitting. We alleviate this problem by splitting the optimization procedure in the following three
steps: 1) Optimize (Mi)K1
i=1to maximize EPCFD2
MK1(X,Y) =1
K1PK1
i=1d2
HS(ΦX(Mi),ΦY(Mi))
(ΦX(M) =1
NPn
i=1UM(xi))[19, Section 3.3] , denote by M∗
K1= (M∗
i)K1
i=1the optimized linear
maps. 2) Train regression modules FX
θi, FY
θifor each M∗
iusing data sampled from PXandPY
respectively. 3) Optimize (Mi)K2
i=1to maximize EHRPCFD2
M∗
K1,MK2(X,Y).
The reason behind it is natural: the optimal set (M∗
i)K1
i=1captures the most relevant information that
discriminates the distribution PXfrom PY. This difference is reflected in the design of higher rank
expected path developments through regression models specifically trained for this purpose. Finally,
theHRPCFD based on (M∗
i)K1
i=1tends to be more significant among other choices of (Mi)K1
i=1,
making it a stronger discriminator.
4.3 HRPCF-GAN for conditional time series generation
Following [ 16,13], we consider the task of conditional time series generation to simulate the
law of the future path Xfuture :=X(p,T]given the past path Xpast:=X[0,p]from samples of
X. To this end, we propose the so-called HRPCF-GAN by leveraging the autoregressive gener-
ator and the trainable HRPCFD as the discriminator. See Figure 2 for the flowchart illustration.
Figure 2: Flowchart of HRPCF-GAN for learning
condition distribution P(Xfuture|Xpast).Conditional autoregressive generator To sim-
ulate future time series of length T−p, we
construct a generator Gθbased on the step-1
conditional generator gθfollowing [ 16]. This
generator, gθ:Xpast×Z →Rd, aims to produce
a random variable approximating P(Xt+1|Ft).
By applying gθinductively, we can simulate fu-
ture paths of arbitrary length. To address the
limitation of AR-RNN generator proposed in
[16], where P(Xt+1|Ft)depends solely on p-
lagged values of Xt, we incorporate an embed-
ding module. This module efficiently extracts
past path information into a low-dimensional
latent space. The output of this embedding mod-
ule, along with the noise vector, serves as the
input for gθto generate subsequent steps in the
fake time series. Further details of our proposed
generator are provided in Appendix B.2.
High Rank development discriminator To capture the conditional law, we use the HRPCFD as
the discriminator of joint law of (Xpast,Xfuture)under true and fake measures. Here the empirical
measures of MK1andMK2are model parameters of the discriminator, which are optimized by the
following maximization:
max
MK1,MK2EHRPCFD2
MK1,MK2(X[0,T],(X[0,p], Gθ(X[0,p], z))),
In principle, one can generate the fake data by the generator via Monte Carlo and apply the training
procedure outlined in Section 4.2 for training the generative model. However, it would be computa-
7tionally infeasible due to the need for recalibration of the regression module per generator update. To
enhance the training efficiency for the regression module under the fake measure, we use the gradient
descent method with efficient initialization obtained by the trained regression model under real data.
For each generator, the corresponding regression model parameters are then updated to minimize
the RLoss (Section 4.1) on a batch of newly generated samples by Gθ. The detailed algorithm is
described in Algorithm 3.
5 Numerical results
5.1 Hypothesis testing
To showcase the power of EHRPCFD in discriminating laws of stochastic processes, we use it as the
test statistic in the permutation test. Similar experiments have been done in [ 21,15]. By regarding the
permutation test as a decision rule, we assess its performance via computing its power (probability
of correctly rejecting the null hypothesis) and type-I error (probability of falsely rejecting the null
hypothesis). Similar to [ 15], we compare the law of 3-dimensional Brownian motion Bwith the
set of laws of 3-dimensional fractional Brownian motion BHwith Hurst parameter Hranging from
[0.4,0.6]. Details of the methodology and implementation can be found in Appendix C.1.
Baselines We compare the performance of HRPCFD with other test metrics including 1) the linear
and RBF signature MMDs [ 8,20] and its high-rank derivative, namely High Rank signature MMDs
[21]; 2) Classical vector MMDs; 3) PCFD [15, 19].
As shown in Table 1 of the test power, HRPCFD consistently outperforms other models, especially
when His close to 0.5. We do see an improvement from the vanilla PCFD by considering a stronger
topology. Furthermore, comparing HRPCFD and High Rank signature MMD, we observe a distinct
advantage for HRPCFD. This may be due to the challenge of capturing the conditional probability
measure, as High Rank signature MMD relies on linear regression for estimation, whereas we
obtained a better estimation using a non-linear approach. Additional test metrics such type-I error
and computational cost can be found in Appendix C.1.
Developments Signature MMDs Classical MMDs
H High Rank PCFD PCFD Linear RBF High Rank Linear RBF
0.4 1±0 1±0 0 .09±0.06 0 .97±0.03 0 .22±0.07 0 .05±0.04 0 .97±0.04
0.425 1±0 1±0 0 .1±0.05 0 .69±0.11 0 .14±0.10 0 .01±0.02 0 .58±0.10
0.45 0.97±0.04 0.99±0.02 0 .04±0.04 0 .15±0.05 0 .14±0.08 0 .06±0.05 0 .24±0.08
0.475 0.31±0.13 0 .06±0.02 0 .01±0.02 0 .04±0.02 0 .12±0.04 0 .01±0.02 0 .02±0.02
0.525 0.30±0.20 0 .08±0.02 0 .05±0.02 0 .07±0.04 0 .19±0.04 0 .08±0.04 0 .09±0.04
0.55 0.99±0.02 0 .95±0.03 0 .13±0.05 0 .17±0.04 0 .18±0.08 0 .06±0.06 0 .19±0.11
0.575 1±0 1±0 0 .07±0.02 0 .5±0.10 0 .14±0.10 0 .10±0.10 0 .48±0.15
0.6 1±0 1±0 0 .05±0.03 0 .75±0.05 0 .22±0.05 0 .06±0.06 0 .67±0.14
Table 1: Test power of the distances when h̸= 0.5in the form of mean ±std over 5 runs. After
careful grid search, we set optimal σ=√
0.05for the RBF signature MMD and classical RBF MMD,
whereas σ1=σ2= 1for High Rank signature MMD.
5.2 Generative modeling
To validate the effectiveness of our proposed HRPCF-GAN, we consider the task of learning the law
of future time series conditional on its past time series.
Dataset We benchmark our model on both synthetic and empirical datasets. 1) multivariate fractional
Brownian Motion (fBM) with Hurst parameter H= 1/4: this dataset exhibits non-Markovian
properties and high oscillation. 2) Stock dataset: We collected the daily log return of 5 representative
stocks in the U.S. market from 2010 to 2020, sourced from Yahoo Finance.
Baseline We compare the performance of HRPCF-GAN with well-known models for time-series
generation such as RCGAN [ 10] and TimeGAN [ 23]. Furthermore, we use PCFGAN [ 19] as
a benchmarking model to showcase the significant improvement by considering the higher rank
8Figure 3: Sample plots of the conditional distribution P(X|Ft)on fBM conditioned on the same
past path, using both true and GAN models (arranged from top to bottom). Each column represents
different t. The thick red /green line indicates the conditional mean of the future path estimated by
model simulated samples/true models. The shaded red area presents the region of ±stdof model
simulated samples, whereas the shaded area shown corresponds to the region of ±theoretical std.
development as the discriminator. For fairness, we use the same generator structure (LSTM-based)
for all these models.
Test metrics To assess the fidelity, usefulness, and diversity of synthetic time series, we consider 7
test metrics, including Auto-Correlation, Cross-Correlation, Discriminative Score, Sig- W1Distance,
and Conditional Expectation. For the stock dataset, we also consider a test metric based on American
option pricing. A detailed definition of these test metrics can be found in Appendix C.2.
We summarize in Table 2 the performance comparison between HRPCF-GAN and benchmarking
models. For both datasets, HRPCF-GAN consistently outperforms the other models. Focusing on
the fBM dataset, HRPCF-GAN achieves the lowest Auto-Correlation ( .082) and Cross-Correlation
(0.013), which is approximately 21.9%/72.3%lower than the second-best model, indicating better
performance in fitting the dynamics of the underlying process across time and feature dimensions.
We also observe strong evidence in capturing the conditional probability measure as HRPCFGAN
achieves the lowest Conditional Expectation score ( 1.693on fBM and 0.56on Stock). Furthermore,
we observe on average an improvement of 34%/14% of HRPCF-GAN with respect to PCFGAN
on fBM/Stock datasets respectively. The strong empirical results demonstrate the effectiveness of
considering high rank path development to capture the filtration of stochastic processes. Finally,
HRPCF-GAN attained the best estimation of an at-the-money American put option, which demon-
strates its potential usage for optimal stopping problems in finance. Sample plots from all models
conditioned on the same path are also shown in Figures 3, 6 and 7 for a qualitative analysis of
generative quality. For additional test metrics, we refer readers to Table 5.
Dataset Test Metrics RCGAN TimeGAN PCFGAN HRPCF-GAN
Auto-C. .105 ±.001 .459 ±.003 .125 ±.003 .082±.002
Cross-C. .051 ±.001 .092 ±.001 .047 ±.001 .013±.001
fBM Discriminative .207 ±.008 .480 ±.002 .265 ±.006 .151±.006
Sig-W1 .512±.006 .341 ±.011 .199 ±.004 .169±.009
Cond. Exp. 1.822 ±.023 2.265 ±.029 2.278 ±.033 1.693±.021
Auto-C. .239 ±.016 .228 ±.010 .198 ±.003 .189±.010
Cross-C. .067 ±.011 .056 ±.002 .055 ±.004 .053±.005
Stock Discriminative .134 ±.058 .020 ±.021 .028 ±.017 .016±.005
Sig-W1 .013±.002 .008 ±.001 .005 ±.001 .004±.002
Cond. Exp. .078 ±.003 .079 ±.001 .060 ±.001 .056±.002
Amer. Put .546 ±.318 .243 ±.411 .202 ±.020 .179±.006
Table 2: Performance comparison of HRPCF-GAN and baselines. The best for each task is shown in
bold. Each test metric is shown in the form of mean ±std over 5runs.
96 Conclusion and Future work
Conclusion: In this paper, we apply the unitary feature from rough path theory to define the CF
for measure-valued paths, which further induces a distance ( HRPCFD ) for metrising the extended
weak convergence. Theoretically, we prove the key properties of HRPCFD , such as characteristicity,
uniform boundedness, etc. Additionally, the numerical experiments validate the out-performance of
the approach based on HRPCFD compared with several state-of-the-art GAN models for tasks such
as hypothesis testing and synthetic time series generation.
Limitation and Future work: The suitable choice of network architecture for generating data is
crucial in the proposed HRPCF-GAN, which merits further investigation; in particular, it will be
interesting to understand how the network architecture impacts the filtration structure of the generated
stochastic process. Furthermore, there is room for further improvement on the estimation method of
conditional expectation in terms of accuracy and training stability. Possible routes include exploring
the interplay between the regression module and the generator.
Broader impacts: Our approach based on the extended weak convergence has the potential in
many important financial and economic applications, such as optimal stopping, utility maximisa-
tion and stochastic programming. Unlike classical methods built on top of parametric stochastic
differential equations, our non-parametric and data-driven method alleviates the risk of the model
mis-specification, providing better solution to complex, real-world multi-period decision making
problems. However, like other synthetic data generation models, it also poses risks of misuse, e.g.,
misrepresenting the synthetic data as real data.
Acknowledgments and Disclosure of Funding
HN is supported by the EPSRC under the program grant EP/S026347/1 and the Alan Turing Institute
under the EPSRC grant EP/N510129/1. HN extends her gratitude to Terry Lyons and Hang Lou
for insightful discussions. Moreover, HN is grateful to Jing Liu for her help with Figure 1. CL is
supported by the National Key Research and Development Program of China: Young Scientist Project
2023YFA1010900.
10References
[1]David Aldous. Weak convergence and the general theory of processes. Unpublished Monograph ,
1981.
[2]Julio Backhoff-Veraguas, Daniel Bartl, Mathias Beiglboeck, and Manu Eder. Adapted Wasser-
stein distances and stability in mathematical finance. Finance and Stochastics , 24, 2020.
[3]Julio Backhoff-Veraguas, Daniel Bartl, Mathias Beiglboeck, and Manu Eder. All adapted
topologies are equal. Probability Theory and Related Fields , 178(3), 2020.
[4]Daniel Bartl, Mathias Beiglboeck, and Gudmund Pammer. The Wasserstein spaces of stochastic
processes. arXiv:2104.14245 , 2021.
[5]Patric Bonnier, Chong Liu, and Harald Oberhauser. Adapted topologies and higher rank
signatures. The Annals of Applied Probability , 33(3), 2023.
[6]K. T. Chen. Integration of paths-a faithful representation of paths by noncommutative formal
power series. Trans. Amer. Math. Soc. , 89(2), 1958.
[7]Ilya Chevyrev and Terry Lyons. Characteristic functions of measures on geometric rough paths.
Annals of Probability , 44(6), 2016.
[8]Ilya Chevyrev and Harald Oberhauser. Signature moments to characterize laws of stochastic
processes. Journal of Machine Learning Research , 2022.
[9]Rama Cont, Mihai Cucuringu, Renyuan Xu, and Chao Zhang. TailGAN: Nonparametric
scenario generation for tail risk estimation. arXiv:2203.01664 , 2022.
[10] Cristóbal Esteban, Stephanie L. Hyland, and Gunnar Rätsch. Real-valued (medical) time series
generation with recurrent conditional GANs, 2017.
[11] Peter Friz and Nicolas Victoir. Multidimensional Stochastic Processes as Rough Paths . Cam-
bridge University Press, 2010.
[12] Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization, 2017.
[13] Daniel Levin, Terry Lyons, and Hao Ni. Learning from the past, predicting the statistics for the
future, learning an evolving system. arXiv preprint arXiv:1309.0260 , 2013.
[14] Mark Leznik, Arne Lochner, Stefan Wesner, and Jörg Domaschka. [sok] the great gan bake
off, an extensive systematic evaluation of generative adversarial network architectures for time
series synthesis. Journal of Systems Research , 2(1), 2022.
[15] Siran Li, Zijiu Lyu, Hao Ni, and Jiajie Tao. On the determination of path signature from its
unitary development, 2024.
[16] Shujian Liao, Hao Ni, Marc Sabate-Vidales, Lukasz Szpruch, Magnus Wiese, and Baoren Xiao.
Sig-Wasserstein GANs for conditional time series generation. Mathematical Finance , 34(2),
2024.
[17] Francis A. Longstaff and Eduardo S. Schwartz. Valuing american options by simulation: A
simple least-squares approach. The Review of Financial Studies , 14(1):113–147, 2001.
[18] Hang Lou, Siran Li, and Hao Ni. Path development network with finite-dimensional Lie group
representation. arXiv:2204.00740 , 2022.
[19] Hang Lou, Siran Li, and Hao Ni. PCF-GAN: generating sequential data via the characteristic
function of measures on the path space. Advances in Neural Information Processing Systems ,
36, 2023.
[20] Cristopher Salvi, Thomas Cass, James Foster, Terry Lyons, and Weixin Yang. The signature
kernel is the solution of a goursat pde. SIAM Journal on Mathematics of Data Science ,
3(3):873–899, January 2021.
11[21] Cristopher Salvi, Maud Lemercier, Chong Liu, Blanka Hovarth, Theodoros Damoulas, and
Terry Lyons. Higher order kernel mean embeddings to capture filtrations of stochastic processes.
Advances in Neural Information Processing Systems , 34:16635–16647, 2021.
[22] T. Xu, L. K. Wenliang, M. Munn, and B. Acciaio. Cot-gan: Generating sequential data via
causal optimal transport. Advances in Neural Information Processing Systems , 33:8798–8809,
2020.
[23] Jinsung Yoon, Daniel Jarrett, and Mihaela Van der Schaar. Time-series generative adversarial
networks. Advances in neural information processing systems , 32, 2019.
12A Examples and Proofs
A.1 Examples related to extended weak convergence
Prediction processes First let us give an explicit example for prediction processes of some simple
filtered processes. Consider the two processes Xn= (Ωn,Fn,Fn, Xn,Pn)andX= (Ω,F,F, X,P),
where
•Ωn={xn
1,xn
2},xn
1= (xn
1(0) = 1 ,xn
1(1) = 1 +1
n,xn
1(2) = 2) andxn
2= (xn
2(0) =
1,xn
2(1) = 1 −1
n,xn
2(2) = 0) ;
•Xn
t(xn
i) =xn
i(t)fort= 0,1,2andi= 1,2is the coordinate process on Ωn;
•Pn(xn
1) =Pn(xn
2) =1
2;
•Fn= (Fn
0,Fn
1,Fn
2)is the natural filtration generated by Xn:Fn
0={∅,Ωn}andFn
1=
Fn
2=σ(Xn
1, Xn
2)is the power set of Ωn,
and
•Ω ={x1,x2},x1= (x1(0) = 1 ,x1(1) = 1 ,x1(2) = 2) andx2= (x2(0) = 1 ,x2(1) =
1,x2(2) = 0) ;
•Xt(xn
i) =xi(t)fort= 0,1,2andi= 1,2is the coordinate process on Ω;
•P(x1) =P(x2) =1
2;
•F= (F0,F1,F2)is the natural filtration generated by X:F0=F1={∅,Ω}and
F2=σ(X1, X2)is the power set of Ω.
We plot the sample paths of XnandXin Fig. 4.
p= 0.5
p= 0.52
np= 1
p= 1p= 1p= 0.5
p= 0.5
Figure 4: Xn(left) converges to X(right) weakly, but the corresponding price of American options on Xn
cannot converge to the counterpart on X, see Example A.1 below. Therefore the usage of slightly erroneous
models in weak topology may cause significant loss in decision making problems. This example is taken from
[3] and [5].
From the above, it is straightforward to check that the prediction process ˆXnofXnis
ˆXn
0(xn
1) =ˆXn
0(xn
2) =Pn(Xn∈ ·|Fn
0) =PXn,
where PXnis the law of XnunderPn;
ˆXn
1(xn
1) =Pn(Xn∈ ·|Fn
1)(xn
1) =δxn
1,ˆXn
1(xn
2) =Pn(Xn∈ ·|Fn
1)(xn
2) =δxn
2,
where δxn
i(i= 1,2) denotes the Dirac measure at xn
i; and
ˆXn
2(xn
1) =Pn(Xn∈ ·|Fn
2)(xn
1) =δxn
1,ˆXn
2(xn
2) =Pn(Xn∈ ·|Fn
2)(xn
2) =δxn
2.
Consequently, it holds that the law of ˆXnsatisfies
PˆXn=Pn(ˆXn= (PXn, δxn
i, δxn
i)) =1
2, i= 1,2.
Similarly, the prediction process ˆXofXis
ˆX0(x1) =ˆX0(x2) =P(X∈ ·|F 0) =PX,
where PXis the law of XunderP;
ˆX1(x1) =P(X∈ ·|F 1)(x1) =PX,ˆX1(x2) =P(X∈ ·|F 1)(x2) =PX;
and
ˆX2(x1) =P(X∈ ·|F 2)(x1) =δx1,ˆX2(x2) =P(X∈ ·|F 2)(x2) =δx2.
so that the law of ˆXreads
PˆX=P(ˆX= (PX, PX, δxi)) =1
2, i= 1,2.
13Test functions for extended weak convergence ForI={0,1, . . . , T }and filtered process X∈FP
onI, the typical test functions for defining the extended weak convergence have the following form:
ˆf(ˆX) =F(EP[f0(X)|F0], . . . ,E[fT(X)|FT]),
where f0, . . . , f T∈Cb(X)are continuous bounded functions on the path space XandF∈
Cb(RT+1). For instance, for the filtered processes XnandXin the above example, we have T= 2,
and by choosing f0(x0, x1, x2) = 1 ,f1(x0, x1, x2) =x1+x2−2,f3(x0, x1, x2) = sin( x2−x1)
andF(y0, y1, y2) = exp( −|y1| −y2
2), in view of the facts that Fn
1=Fn
2are the power set of Ωn
(see the last paragraph), we obtain that for each n,
ˆf(ˆXn(xn
i)) = exp( −|EPn[Xn
1+Xn
2−2|Fn
1](xn
i)| −(EPn[sin(Xn
2−Xn
1)|Fn
2](xn
2))2)
= exp( −|xn
i(1) +xn
i(2)−2| −sin2(xn
i(2)−xn
i(1)))
= exp( −(1 +1
n)−sin2(1−1
n)), i= 1,2;
and therefore EPn[ˆf(ˆXn)] = exp( −(1 +1
n)−sin2(1−1
n)). On the other side, since F0=F1=
{∅,Ω}are trivial σ-algebra, for the prediction process ˆXofXwe have
ˆf(ˆX(xi)) = exp( −|EP[X1+X2−2|F1](xi)| −(EP[sin(X2−X1)|F2](x2))2)
= exp( −|EP[X1+X2−2]| −sin2(xi(2)−xi(1)))
= exp( −sin2(1)), i= 1,2
asEP[X1+X2−2] = 0 ; and therefore
EP[ˆf(ˆX)] = exp( −sin2(1)).
Clearly, as n→ ∞ , we have EPn[ˆf(ˆXn)] = exp( −(1+1
n)−sin2(1−1
n))→exp(−1−sin2(1))̸=
exp(−sin2(1)) =EP[ˆf(ˆX)], which shows that Xncannot converge to Xin the extended weak
convergence according to Definition 2.1, although it is easy to see that the laws of Xnconverges to
the law of Xin the weak topology.
In the example, while the unconditional law of the processes Xnconverges to X, weak convergence
fails to capture a key difference between the financial models XnandX. Specifically, if an agent
believes the market dynamics as in Xn, he/she always knows the outcome of the last day in advance,
granting a predictive advantage, whereas in the “fair” market X, the agent lacks this foresight.
This crucial difference in the observed information flow-" No knowledge ⇒Full knowledge ⇒
Full knowledge " forXnversus " No knowledge ⇒No knowledge ⇒Full knowledge " forX—is not
reflected in weak convergence alone.
Extended Weak Topology (EWT) is vital in this case, because it captures this difference through
the conditional distributions. For markets Xn, where the agent has full information on day 1, the
conditional distribution becomes a single Dirac measure, annihilating randomness. In contrast, X
retains genuine randomness at day 1, as reflected by a linear combination of Dirac measures. Since
EWT is based on conditional distributions, it effectively measures differences in information evolution
styles, ensuring continuity in multi-period decision-making as agents update their actions based on
continually evolving information.
Some important multi-periods optimisation problems The following multi-periods optimisation
problems are very important in financial and economic applications, whose value functions are, in
general, discontinuous with respect to the weak convergence, but continuous in the extended weak
topology.
Example A.1 (Optimal Stopping Problem) .Letg:I× X → Rbe a continuous and bounded
non-anticipative (i.e., for any t∈Iandx∈ X, the value of g(t,x)only depends on x0, . . . ,xt)
function. For each filtered process Xnwe set STn:={τ:Fn-stopping time }be the collection of all
stopping times with respect to the filtration Fnand similarly define STforX. Then the value function
vg(·)in the Optimal Stopping Problem (OSP) with the reward g(in the context of mathematical
finance, it is also called the price of American option) is defined by
vg(Xn) = sup
τ∈STnEPn[g(τ, Xn)], v g(X) = sup
τ∈STEP[g(τ, X)].
14IfXnEW− − − →X, then vg(Xn)→vg(X), whilst this continuity fails in the weak convergence: for the
processes XnandXconsidered as above (see Fig. 4) and the reward function g(t,x) :=xt, one has
XnW− →Xbut
lim
n→∞vg(Xn)̸=vg(X).
Indeed, since Xis a martingale with initial value 1, it is obvious that for any stopping time τ∈STit
always holds that EP[g(τ, X)] =EP[Xτ] = 1 which in turn implies that vg(X) = 1 ; on the other
hand, since the filtration of Xnsatisfies that Fn
1=Fn
2(i.e., the agent already knows everything at
day1), it is easy to check that τn
⋆= 21xn
1+1xn
2is the optimal Fn-stopping time for vg(Xn)and
consequently vg(Xn) =EPn[Xn
τn⋆] =1
2×2 +1
2×(1−1
n) =3
2−1
2nconverges to3
2̸= 0 = vg(X).
Example A.2 (Utility Maximisation Problem) .Letg:R→Rbe a continuous, bounded
and concave utility function. For each filtered process Xnwe set Λn:={φ= (φt)t=1,...,T :
φis predictable w.r.t. Fn}be the collection of all predictable strategies (i.e., φtisFn
t−1-measurable
for all t= 1, . . . , T ) with respect to the filtration Fnand similarly define ΛforX. Then the value
function ug(·)in the utility maximisation Problem with the utility function gis defined by
ug(Xn) = sup
φ∈ΛnEPn
g(ZT
0φtdXn
t)
, u g(X) = sup
φ∈ΛEP
g(ZT
0φtdXt)
,
whereRT
0φtdXt=PT
i=1φt(Xt−Xt−1)is the stochastic integral. If XnEW− − − →X, then ug(Xn)→
u(X), whilst this continuity fails in the weak convergence.
An example of HRPCF We still consider the example mentioned before (see the paragraph
Prediction processes and Fig. 4). In the previous discussions we have known that Xn→Xin the
weak convergence (i.e., the laws PXnconverges to the law PX), butXncannot converge to Xin the
extended weak convergence. Now we show that there exists an admissible pair (M,M)∈ A unitary
such that
lim
n→∞dHS(ΦX(M,M),ΦXn(M,M))̸= 0,
by an explicit calculation, which confirms that the HRPCFD does metrise the extended weak conver-
gence and therefore reflect the differences of filtrations of stochastic processes.
Now we pick a linear operator M∈ L(R2,u(1))7which is given by M(t, y) :=y(π
2i)∈u(1)⊂C,
where idenotes the imaginary unit in C. Since the prediction process ˆXofXis
ˆX0(x1) =ˆX0(x2) =P(X∈ ·|F 0) =PX,
where PXis the law of XunderP;
ˆX1(x1) =P(X∈ ·|F 1)(x1) =PX,ˆX1(x2) =P(X∈ ·|Fn
1)(x2) =PX;
and
ˆX2(x1) =P(X∈ ·|F 2)(x1) =δx1,ˆX2(x2) =P(X∈ ·|F 2)(x2) =δx2,
we can check that
EP[UM(X)|F0] =EP[UM(X)] =1
2(eπ
2i+e−π
2i) = 0 ,
EP[UM(X)|F1] =EP[UM(X)] =1
2(eπ
2i+e−π
2i) = 0 ,
and
EP[UM(X)|F2](x1) =UM(x1) =eπ
2i= i,
EP[UM(X)|F2](x2) =UM(x2) =e−π
2i=−i,
which shows that the C-valued process (EP[UM(X)|Ft])t=0,1,2satisfies that
(EP[UM(X)|Ft](x1))t=0,1,2= (0,0,i), (6)
and
(EP[UM(X)|Ft](x2))t=0,1,2= (0,0,−i). (7)
7Recall that in the unitary representation of a path xwe actually always consider the time-augmented version
(t,xt), so here the domain of Mfor real valued path xisR2.
15On the other hand, for every n∈N, we have
Pn[Xn∈ ·|Fn
0] =PXn,
Pn[Xn∈ ·|Fn
1](xn
1) =Pn[Xn∈ ·|Fn
2](xn
1) =δxn
1,
and
Pn[Xn∈ ·|Fn
1](xn
2) =Pn[Xn∈ ·|Fn
2](xn
1) =δxn
2,
which provides that
EPn[UM(Xn)|Fn
0] =1
2(e(1+1
n)πi
2+e−(1+1
n)πi
2),
EPn[UM(Xn)|Fn
1](xn
1) =EPn[UM(Xn)|Fn
2](xn
1) =UM(xn
1) =e(1+1
n)πi
2,
and
EPn[UM(Xn)|Fn
1](xn
2) =EPn[UM(Xn)|Fn
2](xn
2) =UM(xn
2) =e−(1+1
n)πi
2.
Therefore, the C-valued process (EPn[UM(Xn)|Fn
t])t=0,1,2satisfies that
(EPn[UM(Xn)|Fn
t](xn
1))t=0,1,2= (1
2(e(1+1
n)πi
2+e−(1+1
n)πi
2), e(1+1
n)πi
2, e(1+1
n)πi
2),(8)
and
(EPn[UM(Xn)|Fn
t](xn
2))t=0,1,2= (1
2(e(1+1
n)πi
2+e−(1+1
n)πi
2), e−(1+1
n)πi
2, e−(1+1
n)πi
2).(9)
By viewing CasR2and only consider the imaginary part of the above two processes
(EP[UM(X)|Ft])t=0,1,2in(6),(7)and(EPn[UM(Xn)|Fn
t])t=0,1,2in(8),(9), we may without loss
of generality assume that
(EP[UM(X)|Ft](x1))t=0,1,2= (0,0,1),(EP[UM(X)|Ft](x2))t=0,1,2= (0,0,−1)
and
(EPn[UM(Xn)|Fn
t](xn
1))t=0,1,2= (0,sin((1 +1
n)π
2),sin((1 +1
n)π
2)),
(EPn[UM(Xn)|Fn
t](xn
2))t=0,1,2= (0,−sin((1 +1
n)π
2),−sin((1 +1
n)π
2)).
Now, adding the additional time component to the above real valued paths, and choosing M ∈
L(R2,u(2)) via
M(
1
0
) =
0 1
−1 0
,M(
0
1
) =
0 i
i 0
,
we can easily verify that
UM((EP[UM(X)|Ft](x1))t=0,1,2) = exp( M(
1
0
)) exp( M(
1
1
))
̸= exp( M(
1
1
)) exp( M(
1
0
))
= lim
n→∞UM((EPn[UM(Xn)|Fn
t](xn
1))t=0,1,2),
and
UM((EP[UM(X)|Ft](x2))t=0,1,2) = exp( M(
1
0
)) exp( M(
1
−1
))
̸= exp( M(
1
−1
)) exp( M(
1
0
))
= lim
n→∞UM((EPn[UM(Xn)|Fn
t](xn
2))t=0,1,2),
16where expdenotes the matrix exponential on C2×2. From the above calculation, we can further
derive that
lim
n→∞EPn[UM((EPn[UM(Xn)|Fn
t])t=0,1,2)] =1
2exp(M(
1
1
)) exp( M(
1
0
))
+1
2exp(M(
1
−1
)) exp( M(
1
0
))
̸=1
2exp(M(
1
0
)) exp( M(
1
1
))
+1
2exp(M(
1
0
)) exp( M(
1
−1
))
=EP[UM((EP[UM(X)|Ft])t=0,1,2)],
because the matrix multiplication is non-commutative. Therefore,
lim
n→∞dHS(ΦX(M,M),ΦXn(M,M))̸= 0,
which coincides with our observation that Xncannot converge to Xfor the extended weak conver-
gence.
A.2 A Brief Introduction to Path Characteristic Functions
In this section we will summarise some crucial properties of the Path Characteristic Functions (PCF)
ofRd-valued stochastic processes which were obtained in [ 19] and [ 18], and briefly mention its
connection with the signature theory.
Recall that for x∈C1-var([0, T],Rd)andM∈ L(Rd,u(m)), the unitary feature UM(x)(also called
unitary path development) of xunder Mis defined to be yT∈U(m)withybeing the unique
solution to the following linear ODE driven by M(dxt):
dyt=ytM(dxt),y0=Im.
IfXis anRd-valued filtered process with sample paths in C1-var([0, T],Rd), then its path characteristic
function (PCF) is given by the expectation of the unitary feature of X:
ΦX(M) =EP[UM(X)]
where M∈ L(Rd,u(m)),m∈N.
It is easy to see that the PCF of stochastic processes is a natural generalisation of the classical
characteristic functions for Rd-valued random variables. Indeed, for an Rd-valued random variable
X, we may view it as a linear path from 0to1, i.e., Xt=tXfort∈[0,1]. Then, for m= 1, as the
1-dimensional unitary Lie algebra u(1)is simple the real vector space spanned by the imaginary unit
i, we know that every linear mapping M∈ L(Rd,u(1)) can be represented by
M(x) =⟨x, λ⟩i
for some λ∈Rdand⟨·,·⟩denotes the Eulidean inner product. In this case it holds that the unique
solution y(ω)to the ODE
dyt(ω) =yt(ω)M(dXt(ω)) =yt(ω)⟨X(ω), λ⟩idt,y0(ω) = 1
is simply yt(ω) = exp( t⟨X(ω), λ⟩i), which implies that UM(X(ω) =y1(ω) = exp( ⟨X(ω), λ⟩i)
and consequently
ΦX(M) =Z
UM(X(ω))P(dω) =EP[exp(⟨X, λ⟩i)],
which is exactly the classical characteristic function of Xevaluated at λ∈Rd.
Connections of PCF with the Signature Theory Given a continuous bounded variation path
x∈C1-var([0, T],Rd), its signature S(x)(see e.g. [ 6]) is given by a formal series in the (dual of the)
tensor algebra T((Rd)) =Q∞
n=0(Rd)⊗noverRd:
S(x) = (1 , S1(x), . . . , S n(x), . . .)
17where Sn(x) =Pd
i1,...,in=1R
0<t1<...<t n<1dxi1
t1. . . dxin
tnei1⊗. . .⊗ein∈(Rd)⊗n, where e1, . . . , e d
are the canonical basis of Rdand⊗denotes the tensor product. Thanks to the universal property
of the tensor algebra T((Rd)), every linear mapping M∈ L(Rd,u(m))can be lifted to an algebra
morphism ˜M:T((Rd))→Cm×m(where T((Rd))is equipped with the tensor product, and
Cm×mis endowed with the matrix multiplication). It can be shown that (see [ 18], [19]) the unitary
feature UM(x)is equal to the composition of ˜Mand the signature of x, i.e.,UM(x) =˜M(S(x)).
Moreover, the classical signature theory (see e.g. [ 7]) also tells that the signature S(x)belongs to
the character group of T((Rd))with respect to a specified Hopf algebra structure. This algebraic
property of signature together with the relation that UM(x) =˜M(S(x))does not only guarantees
thatUM(x)∈U(m)takes values in the unitary group, but also the universality of unitary features of
paths (see e.g. [19, Theorem A.8]):
Theorem A.3. •The linear functions on unitary features are stable under multiplication and
complex conjugation. More precisely, for any M1∈ L(Rd,u(m1)),M2∈ L(Rd,u(m2)),
L1∈ L(Cm1×m1,C)andL2∈ L(Cm2×m2,C), there exist an M3∈ L(Rd,u(m3)), a
L3∈ L(Cm3×m3,C), anM4∈ L(Rd,u(m4))and a L4∈ L(Cm4×m4,C)such that
L1(UM1(x))L2(UM2(x)) =L3(UM3(x)),
andL1(UM1(x)) =L4(UM4(x)).
•LetK ⊂C1-var([0, T],Rd)be a compact subset. For any continuous and bounded function
f:K →Cand any ε > 0, there is an m∗∈Nand finitely many M1, . . . , M N∈
L(Rd,u(m∗))as well as linear functionals L1, . . . , L N∈ L(U(m∗),C)such that
sup
x∈Kf(x)−NX
i=1Li(UMi(x))< ε.
Clearly, the second statement of the above theorem follows immediately from the first statement
together with the Stone-Weierstrass theorem for C-valued functions. Since the expectations of
continuous bounded functions determines the distributions on C1-var([0, T],Rd), as a corollary of
the universality theorem above, we obtain the following characteristicness of PCF as mentioned in
Theorem 2.6, see also [19, Theorem B.1].
Other Properties of the unitary features and PCF Besides the universality and the characteristic-
ness, in [ 19] and [ 15] one can find some other nice properties of the unitary featues and PCF, which
we will list below without proof:
1. Since UM(x)takes values in the unitary group U(m)ifM∈ L(Rd,u(m)), so the Hilbert-
Schmidt norm of the PCF ΦM(X)of any stochastic process X(with continuous bounded
variation sample paths) is always bounded by√m. In particular, ΦM(X)can be defined for
any stochastic process with no integrability requirement.
2.The unitary feature UM:C1-var([0, T],Rd)→U(m)is Lipschitz continuous with respect
to the bounded variation norm, see [19, Proposition B.6].
3.If the laws of stochastic processes satisfies enough integrability condition (namely their
expected signatures have infinite radius of convergence, see [ 7] for the definition), then one
can use a special subclass of linear mappings M∈ L(Rd,u(m))to determine the laws.
More explicitly, for PXandPYtwo laws of stochastic processes with enough integrability,
PX=PYif and only if ΦPX(M) =ΦPY(M)for all M∈ L(Rd,o(m))such that Monly
has possibly nonzero entries in Mijwith|i−j|= 1, where Mijdenotes the entry of M
at the i-th row and j-th column, and o(m)is the orthogonal Lie algebra. Thanks to the
significant sparsity, such M∈ L(Rd,o(m))is easy to be implemented in the numerical
application. See [15] for more details.
4.The PCF induces a metric which can (locally) characterise the weak convergence of the
laws of stochastic processes, which is called the PCFD (see [ 19, Theorem 3.8]). In fact the
HRPCFD defined in the present paper can be seen as a counterpart of PCFD in the extended
weak convergence.
18A.3 Proof of Theorem 3.3
In this section we prove Theorem 3.3 in a more general setting.
Definition A.4. For(M,M)∈ A unitary withM∈ L(Rd,u(n)),M ∈ L (Cn×n,u(m))andp∈ˆX
a measure-valued path, we call
UM,M(p) :=UM(t7→pM
t),pM
t=Φpt(M) =Z
XUM(x)pt(dx)
the high rank development of punder (M,M).
Definition A.5. Forµ∈ P(ˆX)a probability measure on the measure-valued path space ˆX, the
function
Φ2
µ:Aunitary→∞[
m=1Cm×m
(M,M)7→Z
p∈ˆXUM,M(p)µ(dp) =Z
p∈ˆXUM(t7→pM
t)µ(dp)
is called the high rank path characteristic function of µ(Abbreviation: HRPCF).
The next lemma is straightforward, but will be helpful for us to construct the characteristicity for laws
of measure-valued stochastic processes.
Lemma A.6. Let˜M= (Mj)k
j=1∈Lk
j=1L(Rd,u(j))for some k∈N, Then, there exists an
M∈ L(Rd,u(n))forn= (1 + 2 + . . .+k), such that for any measure–valued path p∈ˆXand for
anyt∈[0, T], one has
pM
t=Z
XUM(x)pt(dx)
=
R
XUM1(x)pt(dx)R
XUM2(x)pt(dx)
...R
XUMk(x)pt(dx)

∈Cn×n.
Proof. Given an ˜M= (Mj)k
j=1∈Lk
j=1L(Rd,u(j)), we define M:Rd→u(n)forn=
1 + 2 + . . .+kvia
M(x) =
M1(x)∈u(1)
M2(x)∈u(2)
...
Mk(x)∈u(k)
(10)
which is obviously a linear mapping due to the linearity of M1, . . . , M k.
For any Rd–valued path x∈ X, we know that its unitary feature UM(x)is the unique solution y
(evaluated at time T) to the linear differential equation
dyt=ytM(dxt),y0=In.
On the other hand, let ztbe a curve in U(n)defined by
zt=
z1(t)∈U(1)
z2(t)∈U(2)
...
zk(t)∈U(k)
,
where zj(t),j= 1, . . . , k is the unique solution to the linear differential equation
dyt=ytMj(dxt),y0=Ij.
19It is clear that zsatisfies that
dzt=
dz1(t)
dz2(t)
...
dzk(t)

=
z1(t)M1(dxt)
z2(t)M2(dxt)
...
zk(t)Mk(dxt)

=
z1(t)
z2(t)
...
zk(t)

M1(dxt)
M2(dxt)
...
Mk(dxt)

=ztM(dxt).
Hence, by the uniqueness of the solution to the differential equation dyt=ytM(dxt), and invoking
thatzj(T) =UMj(x)for all j= 1, . . . , k , we must have
UM(x) =zT=
UM1(x)
UM2(x)
...
UMk(x)
.
Now it follows immediately that
pM
t=Z
XUM(x)pt(dx)
=
R
XUM1(x)pt(dx)R
XUM2(x)pt(dx)
...R
XUMk(x)pt(dx)
.
Theorem 3.3 follows immediately from the next lemma by inserting µ=PˆXandν=PˆYfor
prediction processes ˆXandˆYof filtered processes XandY, respectively.
Lemma A.7. Letµandνbe two probability measures on measure–valued path space ˆX(that
is,µ, ν∈ P(ˆX)). Then µ=νif and only if for every admissible pair of unitary representations
(M,M)∈ A unitary , it holds that
Φ2
µ(M,M) =Φ2
ν(M,M).
Proof. Before we start a rigorous proof, let us first give an informal proof to provide some in-
tuition: For each measure-valued path p= (pt)t∈I∈ˆX, we first compute the PCF pM
t=R
XUM(x)pt(dx)∈U(m)for every t∈I, where M∈ L(Rd,u(m)). By doing so, the measure-
valued path pis transformed to a matrix-valued path pMinCm×m. Thanks to the characteristic
property of the PCF (see Theorem 2.6), each measure ptis represented by its PCF pM
t, therefore
we may study the matrix-valued path pMinstead of the measure-valued path p. Under such iden-
tification, the distributions µandνon the measure-valued path space ˆXcan be represented by the
push-forward measure pM
♯µandpM
♯νrespectively, which are distributions on the matrix-valued path
space. In other words, showing µ=νis equivalent to showing that pM
♯µ=pM
♯ν. But now using the
characteristic property of the PCF again, pM
♯µ=pM
♯νholds if and only if their PCF under linear
operator M ∈ L (Cm×m,u(n))coincide with each other, i.e., ΦpM
♯µ(M) =ΦpM
♯ν(M), and by
20definition one has ΦpM
♯µ(M) =Φ2
µ(M,M),ΦpM
♯ν(M) =Φ2
ν(M,M).
Now we provide the rigorous proof of the theorem. Obviously we only need to show the “if” part.
Step 1: By hypothesis, for any admissible pair of unitary representations (M,M)∈ A unitary with
M∈ L(Rd,u(n))andM ∈ L (Cn×n,u(m))we have
Φ2
µ(M,M) =Z
p∈ˆXUM(t7→pM
t)µ(dp) =Z
p∈ˆXUM(t7→pM
t)ν(dp) =Φ2
ν(M,M),
which means that Φ(p7→pM)♯(µ)(M) =Φ(p7→pM)♯(ν)(M), where the push-forward measures (p7→
pM)♯(µ)and(p7→pM)♯(ν)are probability measures on the Cn×n–valued path space.
In fact, if we fix an arbitrary n∈Nand an arbitrary M∈ L(Rd,u(n)), and let M ∈ L (Cn×n,u(m))
vary over all m∈N, we actually have the above equality Φ(p7→pM)♯(µ)(M) =Φ(p7→pM)♯(ν)(M)
for all M ∈ L (Rn,u(m)),m∈N. Therefore, by applying the characteristicity of PCF of measures
on finite dimensional vector space valued path spaces, see Theorem 2.6, we obtain that (p7→
pM)♯(µ) = (p7→pM)♯(ν)for any n∈Nand any M∈ L(Rd,u(n)).
Step 2: Fix an k∈Nand a sequence of operators ˜M= (Mj)k
j=1∈Lk
j=1L(Rd,u(j)). Let
n= 1 + 2 + . . .+k. By Lemma A.6 above, there exists an M∈ L(Rd,u(n))such that for any
p∈ˆX, one has
pM
t=Z
XUM(x)pt(dx)
=
R
XUM1(x)pt(dx)R
XUM2(x)pt(dx)
...R
XUMk(x)pt(dx)
.
Now we take an arbitrary partition {t1< t2< . . . < t N}of the time interval [0, T]. Since we
have shown in Step 1 that (p7→pM)♯(µ) = (p7→pM)♯(ν), that is, the law of Cn×n–valued
stochastic process pM
t=R
XUM(x)pt(dx),t∈[0, T]under µ∈ P(ˆX)coincides with its law under
ν∈ P(ˆX), we indeed have that the distributions of their marginals at t1, . . . , t Nare same, that is,
(p7→(pM
t1, . . . ,pM
tN))♯µ= (p7→(pM
t1, . . . ,pM
tN))♯ν∈ P((Cn×n)N).
Now, for each i= 1, . . . , N andj= 1, . . . , k , we pick arbitrary linear functions Lj(i)∈ L(Cj×j,R)
and continuous and bounded functions gi∈Cb(R), and use them to define a function ˜gi:Cn×n→R
fori= 1, . . . , N such that for any matrix A∈Cn×n(recall that n= 1 + 2 + . . .+k) written in the
form
A=
A1∈C1×1⋆ ⋆ ⋆
⋆ A 2∈C2×2⋆ ⋆
⋆ ⋆... ⋆
⋆ ⋆ ⋆ A k∈Ck×k
,
it holds that
˜gi(A) =gi◦kX
j=1Lj(i)◦Ai
.
Obviously each function ˜giis continuous and bounded.
Let˜g: (Cn×n)N→Rbe the continuous and bounded function such that ˜g(A1, . . . , AN) =QN
i=1˜gi(Ai)for every sequence ¯A= (A1, . . . , AN)∈(Cn×n)N. From the equality (p7→
(pM
t1, . . . ,pM
tN))♯µ= (p7→(pM
t1, . . . ,pM
tN))♯ν∈ P((Cn×n)N)it follows that
Z
˜g(¯A)(p7→(pM
t1, . . . ,pM
tN))♯µ(d¯A) =Z
˜g(¯A)(p7→(pM
t1, . . . ,pM
tN))♯ν(d¯A),
21which can be reformulated as
Z
ˆXNY
i=1gi kX
j=1Epti[Lj(i)◦ UMj]!
µ(dp) = (11)
Z
ˆXNY
i=1gi kX
j=1Epti[Lj(i)◦ UMj]!
ν(dp)
whereEpt[Lj(i)◦ UMj] =R
x∈XLj(i)◦ UMj(x)pt(dx).
Step 3: It is a well known fact (see e.g. [ 7]) that the vector space generated by all real-valued linear
functionals of unitary representations on the path space X, namely
C=span{L◦ UM:X →R:L∈ L(Cj×j,R), M∈ L(Rd,u(j)), j∈N},
is a sub-algebra in the space Cb(X)of continuous and bounded (real-valued) functions on Xwhich
separates the points. Moreover, by picking M0:Rd→u(1)to be the trivial representation (i.e.,
M0(x) = 0∈Cfor all x∈Rd) we see that for any path x∈ X,M0(x) = 1∈R. Therefore, by the
Giles’ Theorem ([ 8, Theorem 9]) it follows that the set Cis dense in Cb(X)related to the so called
strict topology8.
Now, fix arbitrary continuous and bounded functions fi∈Cb(X),i= 1, . . . , N . From the den-
sity of CinCb(X)one can find a sequence of unitary representations ˜M(k)= (M(k)
j)k
j=1∈Lk
j=1L(Rd,u(j)),k∈Ntogether with a sequence of linear operators (L(k)(i))k∈N,i= 1, . . . , N
with each Lk(i) = (L(k)
j(i))k
j=1∈Lk
j=1L(Cj×j,R)such that for every i= 1, . . . , N it holds that
fi= lim
k→∞kX
j=1L(k)
j(i)◦ UM(k)
j, (12)
where the convergence happens in the strict topology. Furthermore, since every probability measure
pti∈ P(X)(i= 1, . . . , N ) belongs to the topological dual of Cb(X)equipped with the strict
topology by the Giles’ theorem, invoking the relation (12) we actually obtain that for every i=
1, . . . , N ,
Epti[fi] =Z
Xfi(x)pti(dx) = lim
k→∞kX
j=1Epti[L(k)
j(i)◦ UM(k)
j].
Then, as a consequence of the result (11) obtained in Step 2, we can apply the bounded convergence
theorem to get that
Z
ˆXNY
i=1gi(Epti[fi])µ(dp) = lim
k→∞Z
ˆXNY
i=1gi kX
j=1Epti[L(k)
j(i)◦ UM(k)
j]!
µ(dp)
= lim
k→∞Z
ˆXNY
i=1gi kX
j=1Epti[L(k)
j(i)◦ UM(k)
j]!
ν(dp)
=Z
ˆXNY
i=1gi(Epti[fi])ν(dp). (13)
On the other hand, by the Urysohn’s lemma, for any i= 1, . . . , N , any positive number Ri>0, the
indicator function 1[−Ri,Ri]can be pointwise approximated by a sequence of [0,1]–valued continuous
functions (gℓ
i)ℓ∈N. Hence, by replacing the functions gibygℓ
iin(13) and then letting ℓ→ ∞ , using
the bounded convergence theorem we can derive that
Z
ˆXNY
i=11[−Ri,Ri](Epti[fi])µ(dp) =Z
ˆXNY
i=11[−Ri,Ri](Epti[fi])ν(dp)
8For the definition of the strict topology, see e.g. [8, Definition 8].
22or, equivalently,
Z
ˆXNY
i=11θ−1
fi([−Ri,Ri])(pti)µ(dp) =Z
ˆXNY
i=11θ−1
fi([−Ri,Ri])(pti)ν(dp) (14)
where θfi(pti) :=Epti[fi]denotes the evaluation map of fi∈Cb(X)against the measure pti.
Step 4: By the very definition of weak topology on P(X), its Borel σ–algebra is generated by
the sets of the form that θ−1
f([−R, R])forf∈Cb(X)andR > 0. Consequently, the Borel σ–
algebra on the product space P(X)Nis generated by the measurable rectangles of the form thatQN
i=1θ−1
fi([−Ri, Ri])forfi∈Cb(X)andRi>0. From Eq. (14) we know that
µ((pt1, . . . ,ptN)∈NY
i=1θ−1
fi([−Ri, Ri])) = ν((pt1, . . . ,ptN)∈NY
i=1θ−1
fi([−Ri, Ri]))
for all such measurable rectangles. Since the above equation holds for any partition {t1< . . . < t N}
of[0, T]and the laws of (continuous) stochastic processes are uniquely determined by their marginals
on finitely many time points, we can conclude that µ=νinP(ˆX)by a routine application of the
monotone class theorem.
Now, for filtered processes XandY, we note that the associated prediction processes ˆXandˆYare
stochastic processes taking values in P(X)which can be viewed as ˆX-valued random variable, which
in turn implies that their laws PˆXandPˆYare elements in P(ˆX). Hence, inserting µ=PˆXand
ν=PˆYinto the above Lemma A.7 we can easily deduce Theorem 3.3.
A.4 Properties of HRPCFD
In this section we will mainly prove the properties recorded in section 3.3.
First let us prove the property of HRPCFD on the separation of laws of prediction processes. To
achieve this we need the following useful continuity lemma.
Lemma A.8. For any fixed µ∈ P(ˆX), any fixed nandm, the mapping
(M,M)∈ L(Rd,u(n))× L(Cn×n,u(m))7→Φ2
µ(M,M)∈Cm×m
is continuous for the operator norm topology on L(Rd,u(n))× L(Cn×n,u(m))and the Hilbert–
Schmidt norm topology on Cm×m.
Proof. For admissible pairs (M,M)and(M′,M′)fromL(Rd,u(n))× L(Cn×n,u(m)), by the
definition of HRPCF we have
∥Φ2
µ(M,M)−Φ2
µ(M′,M′)∥HS=Z
p∈ˆXUM(t7→pM
t)µ(dp)−Z
p∈ˆXUM′(t7→pM′
t)µ(dp)
HS
≤Z
p∈ˆXUM(t7→pM
t)− UM′(t7→pM′
t)
HSµ(dp)
≤Z
p∈ˆXUM(t7→pM
t)− UM(t7→pM′
t)
HSµ(dp)
+Z
p∈ˆXUM(t7→pM′
t)− UM′(t7→pM′
t)
HSµ(dp).(15)
Let us first estimate the first integrand on the right hand side of (15). By [ 19, Proposition B.6] we
know that for each measure–valued path p∈ˆX, one has
∥UM(t7→pM
t)− UM(t7→pM′
t)∥HS≤ ∥M∥ op∥pM−pM′∥1-var,
where pM
t= Φpt(M) =R
XUM(x)pt(dx)andpM′
t= Φpt(M′) =R
XUM′(x)pt(dx)areCn×n–
valued paths. Since p∈ˆXis piecewise linear, these Cn×n–valued paths pM= (t7→Φpt(M))and
23pM′= (t7→Φpt(M′))are also piecewise linear, say, they are linear on time subintervals [ti, ti+1]
fori= 0, . . . , N −1. Then we indeed have
∥pM−pM′∥1-var=N−1X
i=0∥(pM−pM′)ti,ti+1∥HS≤2NX
i=0∥pM
ti−pM′
ti∥HS,
whence the estimates
∥UM(t7→pM
t)− UM(t7→pM′
t)∥HS≲∥M∥ opNX
i=0∥pM
ti−pM′
ti∥HS. (16)
Now we note that for each i= 0, . . . , N , we have
pM
ti−pM′
ti=Z
x∈XUM(x)pti(dx)−Z
x∈XUM′(x)pti(dx).
Recalling that for each Rd–valued path x∈ X , one has UM(x) =yM,x
T andUM′(x) =yM′,x
T ,
where yM,xandyM′,xare the unique solutions to the linear ODEs
dyM,x
t=yM,x
tM(dxt),yM,x
0=In
and
dyM′,x
t =yM′,x
tM′(dxt),yM′,x
0 =In
respectively, by the continuity of the flow of ODE (see e.g. [ 11, Theorem 3.15]), we obtain that for
anyx∈ X,
∥UM(x)− UM′(x)∥HS≤C(n,∥x∥1-var)∥M−M′∥op.
In particular, if ∥M′−M∥op→0, then for all x∈ X we have ∥UM(x)− UM′(x)∥HS→0. Then
because UMandUM′are unitary representations taking values in the compact group U(n), by
the dominated convergence theorem we have ∥pM
ti−pM′
ti∥HS→0as∥M′−M∥op→0for any
i= 0, . . . , N . As a result, in view of (16) we obtain that
∥M′−M∥op→0⇒ ∥U M(t7→pM
t)− UM(t7→pM′
t)∥HS→0
for all p∈ˆX. Then, as UMis a unitary representation taking values in the compact group U(m), by
the dominated convergence theorem again we have
∥M′−M∥op→0⇒Z
p∈ˆXUM(t7→pM
t)− UM(t7→pM′
t)
HSµ(dp)→0. (17)
Next we turn to bound the second integrand in (15), namely ∥UM(t7→pM′
t)− UM′(t7→pM′
t)∥HS.
Again, invoking that UM(t7→pM′
t) =yM,pM′
T andUM′(t7→pM′
t) =yM′,pM′
T are the unique
solutions (evaluated at T) to the linear ODEs
dyM,pM′
t =yM,pM′
t M(dpM′
t),yM,pM′
0 =Im
and
dyM′,pM′
t =yM′,pM′
t M′(dpM′
t),yM′,pM′
0 =Im
respectively, by the continuity of the flow of ODE, we obtain that for each p∈ˆX,
∥UM(t7→pM′
t)− UM′(t7→pM′
t)∥HS≤C(m,∥pM′∥1-var)∥M − M′∥op.
SinceUM′takes values in the compact group U(n), it is easy to see that for piecewise linear path
pM′
t=R
UM′(x)pt(dx)it holds that supM′∈L(Rd,u(n))∥pM′∥1-var<∞, which implies that for any
p∈ˆXand for any M′∈ L(Rd,u(n)),
∥M′− M∥ op→0⇒ ∥U M(t7→pM′
t)− UM′(t7→pM′
t)∥HS→0.
Again, since UMandUM′are unitary features with values in compact group U(m), by the dominated
convergence theorem we must have
Z
p∈ˆXUM(t7→pM′
t)− UM′(t7→pM′
t)
HSµ(dp)→0 (18)
24as long as ∥M′− M∥ op→0. Now, combining (18), (17) and (15) we can conclude that
∥Φ2
µ(M,M)−Φ2
µ(M′,M′)∥HS→0
as long as ∥M′−M∥op→0,∥M′− M∥ op→0, which is the desired continuity claim.
Now we are able to prove the first property of HRPCFD.
Theorem A.9 (Separation of points) .Letµ, ν∈ P(ˆX)be two distributions on measure–valued
path space such that µ̸=ν. Then there exists a pair of integers (n, m)∈N2such that for any
PM∈ P(L(Rd,u(n)))with full support and any PM∈ P(L(Cn×n,u(m)))with full support, one
has
HRPCFD M,M(µ, ν)>0.
In particular, for filtered processes XandY, if they are not synonymous, then with µ=PˆXand
ν=PˆYthere exists a pair of integers (n, m)∈N2such that for any PM∈ P(L(Rd,u(n)))with
full support and any PM∈ P(L(Cn×n,u(m)))with full support, one has
HRPCFD M,M(X,Y)>0.
Proof. Thanks to Lemma A.7, if µ̸=ν, then there must exist an admissible pair of unitary represen-
tations (M0,M0)∈ A unitary withM0∈ L(Rd,u(n))andM0∈ L(Cn×n,u(m))such that
Φ2
µ(M0,M0)̸=Φ2
ν(M0,M0).
Then, by the continuity result proved in Lemma A.8, there exists a δ >0such that for all M∈
L(Rd,u(n))and all M ∈ L (Cn×n,u(m))with∥M0−M∥op≤δand∥M0− M∥ op≤δ, it holds
that
dHS(Φ2
µ(M,M),Φ2
ν(M,M))>0.
LetB(M0, δ)⊂ L(Rd,u(n))andB(M0, δ)⊂ L(Cn×n,u(m))denote the ball centered at M0and
M0with radius δ(with respect to the operator norms) respectively. Then if PMandPMhave full
supports, we have PM(B(M0, δ))>0andPM(B(M0, δ))>0,which implies that
HRPCFD2
M,M(µ, ν) =Z Z
d2
HS(Φ2
µ(M,M),Φ2
ν(M,M))PM(dM)PM(dM)
≥Z
B(M0,δ)Z
B(M0,δ)d2
HS(Φ2
µ(M,M),Φ2
ν(M,M))PM(dM)PM(dM)
>0,
as claimed.
The boundedness of HRPCFD is easy to show by using the same arguments as in the proof of [ 19,
Lemma 3.5] for PCFD.
Lemma A.10. Letµ, ν∈ P(ˆX)be two distributions on measure–valued path space. Then for any
given integers (n, m)∈N2, for any PM∈ P(L(Rd,u(n)))and any PM∈ P(L(Cn×n,u(m))),
one has
HRPCFD M,M(µ, ν)≤2√m.
Proof. By the triangle inequality, we have
HRPCFD2
M,M(µ, ν) =Z Z
d2
HS(Φ2
µ(M,M),Φ2
ν(M,M))PM(dM)PM(dM)
≤Z Z
(∥Φ2
µ(M,M)∥HS+∥Φ2
ν(M,M)∥HS)2PM(dM)PM(dM).
SinceΦ2
µ(M,M) =R
p∈ˆXUM(t7→pM
t)µ(dp)andUMtakes values in U(m)such that ∥UM∥HS=p
tr(UMU∗
M) =p
tr(Im) =√m, we indeed have
∥Φ2
µ(M,M)∥HS≤Z
p∈ˆX∥UM(t7→pM
t)∥2
HSµ(dp)1
2
≤√m.
Similarly, it holds that ∥Φ2
ν(M,M)∥HS≤√m. Combining all above together we can deduce that
HRPCFD2
M,M(µ, ν)≤4m.
25Just like the classical PCFD (cf. [ 19, Proposition B.10]) we can also show that the HRPCFD is a
specific Maximum Mean Discrepancy (MMD). For the definition of MMD, we refer readers to [ 19,
Definition B.9].
Proposition A.11. For any (n, m)∈N2, any PM∈ P (L(Rd,u(n)))and any PM∈
P(L(Cn×n,u(m))), the HRPCFD with respect to PMandPMis an MMD with the kernel function
ˆκ:ˆX × ˆX →Rgiven by
ˆκ(p,˜p) =EPM⊗PM[⟨UM(t7→pM
t),UM(t7→˜pM
t)⟩HS]
=EPM⊗PM[tr(UM(pM⋆(˜pM)−1))]
where ⋆denotes the concatenation operator on paths and (˜pM)−1denotes the reverse of the path
t7→˜pM
t.
Proof. Forµ, ν∈ P(ˆX), it is easy to deduce that
HRPCFD2
M,M(µ, ν) =Z Z
∥Φ2
µ(M,M)−Φ2
ν(M,M)∥2
HSPM(dM)PM(dM)
=EPM⊗PM[∥Φ2
µ(M,M)∥2
HS] +EPM⊗PM[∥Φ2
ν(M,M)∥2
HS]
−2EPM⊗PM[⟨Φ2
µ(M,M),Φ2
ν(M,M)⟩HS].
Moreover, note that
EPM⊗PM[⟨Φ2
µ(M,M),Φ2
ν(M,M)⟩HS] =Z
⟨Z
UM(pM)µ(dp),Z
UM(˜pM)ν(d˜p)⟩HSd(PM⊗PM)
=Z Z
⟨UM(p),UM(˜pM)⟩HSµ(dp)⊗ν(d˜p)d(PM⊗PM)
=ZZ
⟨UM(p),UM(˜pM)⟩HSd(PM⊗PM)
µ(dp)⊗ν(d˜p),
where we used the Fubini’s theorem in the last equality. Therefore we actually obtain that for the
kernel
ˆκ(p,˜p) =EPM⊗PM[⟨UM(t7→pM
t),UM(t7→˜pM
t)⟩HS]
it holds that
HRPCFD2
M,M(µ, ν) =Z
ˆκ(p,˜p)µ(dp)⊗µ(d˜p)+Z
ˆκ(p,˜p)ν(dp)⊗ν(d˜p)−2Z
ˆκ(p,˜p)µ(dp)⊗ν(d˜p),
which implies that HRPCFD M,Mis a MMD with the kernel function ˆκ.
The last claim is obvious: for any p,˜p∈ˆX, one has, due to the fact that every A∈U(m)satisfies
A−1=A∗, that
κ(p,˜p) =EPM⊗PM[⟨UM(t7→pM
t),UM(t7→˜pM
t)⟩HS]
=EPM⊗PM[tr(UM(t7→pM
t)UM(t7→˜pM
t)∗)]
=EPM⊗PM[tr(UM(t7→pM
t)UM(t7→˜pM
t)−1)]
=EPM⊗PM[tr(UM(pM⋆(˜pM)−1))],
where we used the multiplicative property of the unitary features for Cn×n–valued paths pMand
˜pM, see also [19, Lemma A.5].
Now we will construct a metric from HRPCFD which can characterise the extended weak convergence
on precompact subset of FP.
Lemma A.12. Suppose that {(PMn, PMm)∈ P(L(Rd,u(n)))×P(L(Cn×n,u(m))) :n∈N, m∈
N}is a double sequence of distributions with full supports. After a re-numeration we label them as a
sequence ((PMj, PMj))j∈Nsuch that each (Mj,Mj)is a random admissibe pair in Aunitary . Then
the following defines a metric on P(ˆX):
^HRPCFD (µ, ν) =∞X
j=1min{1,HRPCFD Mj,Mj(µ, ν)}
2j.
26Proof. The symmetry and the triangle inequality are easy to check. We only need to show that
^HRPCFD (µ, ν) = 0 if and only µ=ν. The “if” part is trivial. Now suppose that ^HRPCFD (µ, ν) = 0
holds but µ̸=ν. Then by Theorem A.9 we know that there exists a pair of integers (n, m)∈N2
such that for any PM∈ P(L(Rd,u(n)))and any PM∈ P(L(Cn×n,u(m)))with full supports,
it holds that HRPCFD M,M(µ, ν)>0. So, let us pick some j∈Nsuch that (Mj,Mj)∈
P(L(Rd,u(n)))× P(L(Cn×n,u(m))), we must have HRPCFD Mj,Mj(µ, ν)>0, which implies
that^HRPCFD (µ, ν)≥min{1,HRPCFDMj,Mj(µ,ν)}
2j >0, a contradiction. Hence we obtain that the
so–defined ^HRPCFD (µ, ν)is really a metric.
Theorem A.13. Fix a sequence of random admissible pairs (Mj,Mj)j∈N⊂ A unitary such that for
every (n, m)∈N2there exists a j∈NwithMj∈ L(Rd,u(n))andMj∈ L(Cn×n,u(m))and
their distributions PMj∈ P(L(Rd,u(n)))andPMj∈ P(L(Cn×n,u(m)))are fully supported. Let
^HRPCFD be the metric defined as in Lemma A.12 via this sequence (Mj,Mj)j∈N.
1.LetK ⊂ FPbe a compact subset in the space FPof filtered processes equipped with
the topology induced by extended weak convergence. Then, for every sequence of filtered
processes (Xk= (Ωk,Fk,Fk, Xk,Pk))k∈N⊂ K andX= (Ω ,F,F, X,P))∈FP, we
have
XkEW− − − →X⇐⇒^HRPCFD (Xk,X)→0
ask→ ∞ .
2.LetK⊂ X be a compact subset. Let FP(K)be the space of all filtered pro-
cesses taking values in K. Then, for every sequence of filtered processes (Xk=
(Ωk,Fk,Fk, Xk,Pk))k∈N⊂FP(K)andX= (Ω,F,F, X,P))∈FP(K), we have
XkEW− − − →X⇐⇒^HRPCFD (Xk,X)→0
ask→ ∞ .
Proof. 1.First suppose that XkEW− − − →Xfor a sequence (Xk)k∈N⊂ K andX∈ K. Clearly,
for any sequence of piecewise linear measure-valued paths pk,k∈Nandp(which are
linear on each subinterval [i, i+ 1],i= 0, . . . , T −1) we have pk→pwith respect
to the product topology on ˆXimplies that for each fixed unitary representation M∈
L(Rd,u(n)), theCn×n–valued paths (pk)M= (R
UM(x)pk
t(dx))t∈[0,T]converges to
pM= (R
UM(x)pt(dx))t∈[0,T]with respect to the total variation norm as k→ ∞ . Then,
for every fixed unitary representation M ∈ L (Cn×n,u(m)), by the continuity of unitary
feature map UMrelative to the total variation norm (see e.g. [ 19, Proposition B.6]), we
haveUM(t7→(pk)M
t)→ UM(t7→pM
t)inCm×m(relative to the Hilbert–Schmidt norm)
ask→ ∞ . Hence, we actually have shown that the function p∈ˆX 7→ U M(t7→pM
t)∈
Cm×mis continuous and bounded for the product topology on ˆX. Now, as XkEW− − − →X
means that PˆXk→PˆXweakly in P(ˆX)ask→ ∞ , we indeed have for all (M,M)∈
Aunitary ,
lim
k→∞Z
UM(t7→pM
t)PˆXk(dp) =Z
UM(t7→pM
t)PˆX(dp),
that is, limk→∞∥Φ2
Xk(M,M)−Φ2
X(M,M)∥HS= 0. This observation together with
the boundedness of the HRPCFD (see Lemma A.10), allows us to apply the dominated
convergence theorem to derive that for every j∈None has
HRPCFD2
Mj,Mj(Xk,X)
=Z Z
d2
HS(Φ2
Xk(M,M),Φ2
X(M,M))PMj(dM)PMj(dM)→0
ask→ ∞ . Consequently, we can conclude that ^HRPCFD (Xk,X)→0ask→ ∞ .
Conversely, suppose that (Xk)k∈Nis a sequence of filtered processes in KandX∈FPsuch
thatlimk→∞^HRPCFD (Xk,X) = 0 . Since Kis compact, there is a subsequence of (Xk)k∈N
27(without loss of generality, assume this subsequence is the sequence itself) converging to
a limitY= (ΩY,G,G, Y,Q)∈ K in the extended weak topology. From the previous
argument we know that limk→∞^HRPCFD (Xk,Y) = 0 . Therefore, we actually obtain
that^HRPCFD (X,Y) = 0 . In view of Theorem A.9, the equality ^HRPCFD (X,Y) = 0
means that PˆX=PˆY, i.e.,XandYare synonymous. The above reasoning reveals that any
accumulation point Yof the sequence (Xk)k∈Nin the extended weak convergence coincides
withX. As a consequence, we have Xk→Xin the extended weak topology as k→ ∞ .
2.By [ 4, Theorem 1.7] the subspace FP(K)is precompact in FPfor the extended weak
topology, if K⊂ X is compact. Hence the claim follows immediately from the result
contained in the statement 1 with K=FP(K)(the closure of FP(K)with respect to the
extended weak convergence).
B Methodology and algorithm
B.1 Estimating the conditional probability measure
Algorithm 1 Training algorithm seq-to-seq regression model
Input: X- real data; B- batch size; ηr- learning rate for the regression module; d- path feature
dimension; l- lie degree; M∈Rd×dimul;T- path length; ηr- learning rate.
1:FX
θ←initialize
2:fori∈(1, . . . , iterr)do
3: Sample xfromXof size B
4: Uj,M(t)← U M(xj,[t,T])witht∈ {0, . . . , T }, j∈ {1, . . . , B }
5: RLoss (θ;x, M)←1
B(T+1)PT
t=0PB
j=1||FX
θ(xj,[0,T])t− Uj,M(t)||2
HS
6: θ←θ−ηr· ∇θ(RLoss (θ;x, M))
7:end for
8:return FX
θ∗ ▷Return the optimal model
Algorithm 2 Sampling algorithm to approximate Φ2
X
Input: FX
θ- regression module; X= (xj)N
j=1- data sampled from distribution PX;ηr- learning
rate for the regression module; d- path feature dimension; n, m - Lie degrees; M∈Rd×dimul
M ∈Rdimu(n)×dimu(m);T- path length.
1:ˆpˆX,M←zero matrix of length N×(T+ 1)
2:fort∈(0, . . . , T )do
3: forj∈(1, . . . , N )do
4: Uj,M, past(t)← U M(xj,[0,t])
5: ˆUj,M, future(t)←FX
θ(xj,[0,T])t
6: ˆpˆX,M
j,t← U j,M, past(t)∗ˆUj,M, future(t)
7: end for
8:end for
9:ˆΦ2
X(M,M)←1
NPN
j=1UM(ˆpˆX,M
j)
10:return ˆΦ2
X(M,M)
B.2 HRPCF-GAN
In this section, we provide the mathematical formulation of HRPCF-GAN for conditional time series
generation. Let X:= (Xt)T
t=1denote a Rd-valued time series of length Twith its distribution PX.
Suppose that we have i.i.d. samples X= (xi)ifrom PX. We are interested in generating synthetic
28future paths to approximate the conditional distribution of the future path Xfuture:=X(p,T]given the
past path Xfuture:=X[0,p]. For ease of notations, let Xpast:=Rd×pandXfuture=Rd×(T−p)denote
the space of the past path and future path, respectively.
Conditional generator One step generator gθ:Xpast×Z →Rd, which maps (xpast, zt)to samples
of the next time step via the following formula:
h= [Fθe(xpast)]p
o=Fθa(h, z)
Fθe:Xpast→ H is the sequence-to-sequence embedding module to extract the key information of
the path up to time tandFθaexhibits the autoregressive generator architecture. We denote by where
θ= (θe, θa)the generator’s parameter.
We then apply one step generator gθin a rolling window basis to generate future time series of length
T−p. More specifically, Gθ: (x[0:p],(zt)T
t=p+1)7→(ot)T
t=p+1, where we first set o0:p=x0:pand
for every t≥p,ot+1=gθ(ot−p:t, zt).
In the following, we summarise the training algorithm for HRPCF-GAN in Algorithm 3.
Algorithm 3 Training algorithm for HRPCF-GAN
Input: p- past path length; T- total path length; d- path feature dimension; X- real data; n- lie
degree for EPCFD; K1- number of linear maps; M∈RK1×d×dimu(n);m- lie degree for EHRPCFD;
K2- number of linear maps for EHRPCFD; M ∈RK2×dimu(n)×dimu(m);Gθ- generator; B- batch
size;z- noise dimension; iterrfrequency of regression module fine-tuning; ηg,ηd- generator and
discriminator learning rates.
1:# Vanilla PCFGAN training
2:while θ,Mnot converge do
3: Sample z∼ Nz×(T−q)(0,1)of size B, sample xfromXof size B
4: ˜x(p,T]←Gθ(x[0,p], z)
5: Loss(θ,M;x, z)←EPCFD2
M(x[0,T],(x[0,p],˜x(p,T]))
6: M←M−ηd· ∇M(−Loss(θ,M;x, z)) ▷Maximize the loss
7: θ←θ−ηg· ∇θ(Loss(θ,M;x, z)) ▷Minimize the loss
8:end while
9:# Regression training for real measure
10:fori∈(1, . . . , K 1)do
11: Freal
ιi←initialize
12: Train Freal
ιiusingXas described in Algorithm 1
13: Ffake
ηi←Freal
ιi▷Set as the initialization
14:end for
15:# High-Rank PCF-GAN training
16:while θ,Mnot converge do
17: Sample z∼ Nz×(T−q)(0,1)of size B, sample xfromXof size B
18: ˜x(p,T]←Gθ(x[0,p], z)
19: fori∈(1, . . . , K 1)do
20: fort∈(0, . . . , T )do
21: ˆpreal,Mi
i,t ← U Mi(x[0,t])∗Freal
ιi(x[0,T])
22: ˆpfake,Mi
i,t ← U Mi(x[0,t])∗Ffake
ιi((x[0,p],˜x(p,T]))
23: end for
24: end for
25: Loss(θ,M;x, z,M)←EHRPCFD2
M,M(x[0,T],(x[0,p],˜x(p,T]))▷Use Algorithm 2 and
Equation (5) with preal,Mi
i,t andpfake,Mi
i,t
26: M ← M − ηd· ∇M(−Loss(θ,M;x, z,M)) ▷Maximize the loss
27: θ←θ−ηg· ∇θ(Loss(θ,M;x, z,M))
28: Do the following every iter riterations:
29: ˜X←(x[0,p], Gθ(X[0,p], z))
30: Train Ffake
ηiusing ˜Xas described in Algorithm 1 for every i∈(1, . . . , K 1)
31:end while
29B.3 Hypothesis testing for stochastic processes
We provide the following two algorithms for training ERHPCFD for the permutation test and
computing the test power/Type 1 error of the permutation test, respectively.
Algorithm 4 Training algorithm for the permutation test
Input: X- samples from distribution µ;Y- samples from distribution ν;m > 0- sample size
ofX;n >0- sample size of Y;n- lie degree for EPCFD; K1- number of linear maps; M∈
RK1×d×dimu(n);m- lie degree for EHRPCFD; K2- number of linear maps for EHRPCFD; M ∈
RK2×dimu(n)×dimu(m);B- batch size; η- learning rate; iter 1,iter2- number of iterations.
1:# Vanilla PCFD optimization
2:foriter∈(1, . . . , iter1)do
3: sample x,yfromX,Yof size B
4: Loss(M;x,y)←EPCFD2
M(x[0,T],y[0,T])
5: M←M−η· ∇M(−Loss(M;x,y)) ▷Maximize the loss
6:end for
7:# Regression training for real measure
8:fori∈(1, . . . , K 1)do
9: FX
ιi, FY
ιi←initialize
10: Train FX
ιiusingXandMias described in Algorithm 1
11: Train FY
ιiusingYandMias described in Algorithm 1
12:end for
13:# High Rank PCFD optimization
14:foriter∈(1, . . . , iter2)do
15: sample x,yfromX,Yof size B
16: fori∈(1, . . . , K 1)do
17: fort∈(0, . . . , T )do
18: ˆpX,Mi
i,t← U Mi(x[0,t])∗FX
ιi(x[0,T])
19: ˆpY,Mi
i,t← U Mi(y[0,t])∗FY
ιi(y[0,T])
20: end for
21: end for
22: Loss(M;x,y,M)←EHRPCFD2
M,M(x[0,T],y[0,T])▷Use Algorithm 2 and Equation (5)
withpX,Mi
i,t andpY,Mi
i,t
23: M ← M − ηd· ∇M(−Loss(θ,M;x,y,M)) ▷Maximize the loss
24:end for
25:return M,M ▷Return learnt parameters
30Algorithm 5 Estimating the test power/Type-I error of the permutation test
Input: α∈(0,1)- significance level; N > 0- # of experiments; M > 0- # of permutations; X-
samples from distribution µ;Y- samples from distribution ν;m > 0- sample size of X;n >0-
sample size of Y;T- test statistic function; H0∈ {1,0}- whether the null hypothesis is true or false
(H0= 1ifµ=ν; otherwise H0= 0)
1:Z←Concatenate (X,Y)
2:num_rejections ←0
3:i←1
4:while i≤Ndo
5: T ← EmptyList
6: j←1
7: while j≤Mdo
8: σ∼Permutation( {1,2,···, m+n})
9: Tσ←T({Zσ(1),Zσ(2),···,Zσ(m)},{Zσ(m+1),···,Zσ(m+n)})
10: T.append (Tσ)
11: j←j+ 1
12: end while
13: ifT(X,Y)>(1−α)%quantile of Tthen
14: num_rejections ←num_rejections + 1
15: end if
16: i←i+ 1
17:end while
18:ratio←num_rejections / N
19:ifH0then
20: Type_I_error ←ratio
21: return Type_I_error
22:else
23: test_power ←ratio
24: return test_power
25:end if
C Numerical results
Code The code is written in Python 3.10.8 and Pytorch 1.11.0. The supplementary code is
available at https://github.com/DeepIntoStreams/High-Rank-PCF-GAN.git for ensuring
full reproducibility. The experiments were performed on a computational system running Ubuntu
22.04.2 LTS, comprising five Quadro RTX 8000 GPUs with 48GB of memory each. The experiments
are run on single GPU and the training time ranges from 30 minutes to 4 hours.
C.1 Hypothesis testing
Description The permutation test is a statistical method used to decide whether two measures µ, ν
are the same. The null hypothesis states H0:µ=νwhereas the alternative hypothesis H1:µ̸=ν.
Given a test metric Tand sample data X={x1, . . . ,xn},Y={y1, . . . ,ym}from µandν
respectively. We construct the following distribution
T:=
T(Zσ(1):σ(n),Zσ(m+1):σ(n+m))|σ∈Σn+m
.
where Z= (X,Y)andΣn+mis the permutation group of n+melements. Given the significance
levelα, we reject the null hypothesis if T(X,Y)>(1−α)%quantile of T.
Methodology For each H, we sample the training dataset Dtrain= (Btrain, BH
train)and optimize
the set (MK1,MK2)to maximize EHRPCFD2between the pair of measures, a detailed procedure
can be found in Algorithm 4. Then, we sample two independent sets DH0test= (BH
test,˜BH
test),DH1test=
(Btest, BH
test)and calculate the power and type-I error accordingly. We refer to Algorithm 5 for the
computation of test metrics.
31Figure 5: Distributions of EPCFD (left) and EHRPCFD (right) under H0andH1with Hurst parameter
H= 0.475. The distribution consists of 100runs under both hypotheses. For EPCFD, fix K1= 8
andn= 5. For High Rank PCFD fix K1= 1,n= 3,K2= 10 ,m= 13 .
Implementation details We provide the full details of the implementation of the numerical exper-
iment in Section 5.1. Adopting the notation in Algorithm 4, we fix n= 3,m= 13 ,K1= 1 and
K2= 10 , these values are chosen via hyper-parameter fine-tuning. The regression model consists of
a 2-layer LSTM module. The model’s parameter is optimized using Adam optimizer with learning
rates0.001(for regression) and 0.02(for EHRPCFD).
Additional numerical results We provide comprehensive tables for summarising the Type-I error
and the computational time involved in Section 5.1.
Developments Signature MMDs Classical MMDs
H High Rank PCFD PCFD Linear RBF High Rank Linear RBF
0.4 0.04±0.04 0 .04±0.04 0 .06±0.05 0 .04±0.04 0 .09±0.08 0 .07±0.06 0 .04±0.04
0.425 0.07±0.04 0 .08±0.07 0 .03±0.03 0 .04±0.04 0 .14±0.05 0 .01±0.02 0 .03±0.02
0.45 0.06±0.05 0 .08±0.02 0 .05±0.04 0 .02±0.03 0 .10±0.07 0 .04±0.04 0 .06±0.06
0.475 0.04±0.04 0 .02±0.04 0 .05±0.04 0 .07±0.06 0 .12±0.07 0 .05±0.04 0 .03±0.04
0.525 0.07±0.04 0 .09±0.07 0 .03±0.03 0 .04±0.02 0 .13±0.02 0 .02±0.02 0 .01±0.02
0.55 0.05±0.03 0 .03±0.04 0 .07±0.06 0 .05±0.05 0 .17±0.10 0 .05±0.04 0 .02±0.02
0.575 0.06±0.04 0 .04±0.04 0 .02±0.03 0 .06±0.07 0 .12±0.07 0 .06±0.02 0 .06±0.05
0.6 0.10±0.07 0 .06±0.04 0 .05±0.04 0 .05±0.04 0 .09±0.04 0 .06±0.05 0 .06±0.05
Table 3: Type-I error of the distances when H̸= 0.5in the form of mean ±std over 5 runs. For
PCFD, fix K1= 8andn= 5. For High Rank PCFD fix K1= 1,n= 3,K2= 10 ,m= 13 . For the
RBF signature MMD and classical RBF MMD, fix 2σ2= 0.1. For High Rank signature MMD, fix
σ1=σ2= 1.
Developments Signature MMDs Classical MMDs
High Rank PCFD PCFD Linear RBF High Rank Linear RBF
m=n Inference time (seconds)
10 3.17±0.02 2 .58±0.01 95 .12±0.21 122 .9±0.32 1214 .76±12.41 0 .13±0.01 0 .28±0.03
50 32.32±1.53 23 .14±1.04 402 .69±0.23 533 .43±0.33 − 0.56±0.04 1 .17±0.16
100 111.25±2.92 89 .13±2.19 1329 .73±0.57 1760 .18±0.29 − 1.16±0.04 2 .64±0.11
Mini-batch size Training time (seconds over 500 iterations)
1024 695.18±8.57 73 .51±6.21 − − − − −
Table 4: Inference time of the permutation test across different sample sizes ( m=n) and the training
time of High Rank PCFD and PCFD before conducting the permutation test. The result is in the form
of mean ±std over 5runs. For PCFD, fix K1= 8andn= 5. For High Rank PCFD fix K1= 1,
n= 3,K2= 10 ,m= 13 . For the RBF signature MMD and classical RBF MMD, fix 2σ2= 0.1.
Here fix h= 0.45.
32C.2 Generative modeling
Datasets construction (1)3-dimensional fractional Brownian motion: we simulate samples
using the publicly available Python package fbm. The total length of each sample is 11(counting a
fixed initial point). The training and test data consists of two independent sampled sets of size 10000 .
(2)Stock: we select 5 representative stocks in the U.S. market, namely, Apple, Lockheed Martin, J.P.
Morgan, Amazon, and P& G, and collect the daily return data from 2010 to 2020. The data collection
is done using the Python package yfinance. We then construct the dataset using a rolling-window
basis with length 10(two weeks in real time) and stride 2. Finally, we split the dataset into training
and test sets with a ratio of 0.8.
Baseline We compare the performance of HRPCF-GAN with well-known models for time-series
generation such as RCGAN [ 10] and TimeGAN [ 23]. Furthermore, we use PCFGAN [ 19] as
a benchmarking model to showcase the significant improvement by considering the higher rank
development as the discriminator. For fairness, we use the same generator structure (LSTM-based)
for all these models.
Conditional Generator The generator design is described in Appendix B.2. In particular, we
choose FθeandFθαto be two independent 2-layer LSTM modules. The first module takes the
past path and encodes the necessary information to the latent space. The final hidden and cell state
will be used as the input for the second LSTM module and the latent noise vector to produce the
output distribution of the next time step. Also, we use the auto-regressive to simulate the future path
recursively.
Implementation details The training procedure is described in Algorithm 3, we adopt the same
notation in this section. For both datasets, we set T= 10 andp= 5. We use the development layers
on the unitary matrix [ 18] to calculate the PCFD distance, in particular, we fix K1= 5,n= 5,
K2= 10 ,m= 13 for the discriminator design, these are obtained via hyper-parameter tuning. The
regression model consists of a 2-layer LSTM module. Finally, we use the ADAM optimizer [ 12],
to train both the generator and discriminator with learning rates 0.0001 and0.002respectively. We
fine-tune the regression every 500 generator optimization iterations. To improve the training stability
of GAN, we employed three techniques. Firstly, we applied a constant exponential decay rate of 0.97
to the learning rate for every 500 generator training iterations. Secondly, we clipped the norm of
gradients in both generator and discriminator to 10.
All benchmarking models are trained with 15000 training iterations. For HRPCF-GAN, we trained
the vanilla PCF-GAN with 10000 iterations then we switched to HRPCF discriminator and trained
the model for a further 5000 iterations.
Evaluation metrics We list here the test metrics we used for generative model assessment.
•Marginal score [ 16]: the average of Wasserstein distance of the marginal distribution between
real and fake data across each dimension.
•Auto-correlation score [ 16]: the l1norm of the difference in the ACF between real and fake
data
ACF (X, Y) :=TX
τ=1dX
i=1ˆC(τ;X(i))−ˆC(τ;Y(i)),
where ˆC(τ;X)is the empirical auto-correlation estimator of XtandXt+τ.
•Cross-correlation score [ 16]: the l1norm of the difference in the correlation between real
and fake data across each feature dimension.
Corr (X, Y) =TX
s,t=1dX
i,j=1ρ(X(i)
s, X(j)
t)−ρ(Y(i)
s, Y(j)
t),
where ρis the empirical correlation estimator.
•Discriminative score [ 23]: we train a post-hoc classifier to distinguish real data from fake
data. Lower the score (absolute difference between classification accuracy and 0.5), meaning
inability to classify, indicate better performance of the generative model.
33•Predictive score [ 23]: we train a sequence-to-sequence model to predict the latter part of
a time series given the first part, using generated data and real data, resp. The trained
models are then tested on the real data resp. The lower loss (|TSTR-TRTR|) means the better
resemblance of synthetic data to real data for the predictive task.
•SigW1score [ 16]: by embedding the time series to the signature space, we can approximate
theW1distance by the l2norm of the signature of the real and fake data.
SigW1(X, Y) =||EX[Sig(X[0,T])]−EY[Sig(Y[0,T])]||l2,
where Sig denotes the signature transform of a path.
•Conditional expectation score: we estimate the conditional expectation of the future path on
the fake measure via Monte Carlo and compute the averaged pairwise l2norm between real
data.
•Outgoing Nearest Neighbour Distance score [ 14]: the ONND calculates for each example
of real data the distance between the nearest generated data. This score tests the model’s
capability to capture the diversity of the target distribution.
•American put option score: we use Least-Square Monte Carlo method [ 17] to price an
at-the-money American put option using both real and generated data. We set the strike
dateT= 5days and risk-free rate r= 0.01. The score is computed as the average of l1
differences of the estimated price across each stock.
For each test metric, a lower value indicates better model performance. We provide the results on the
additional metrics in Table 5.
Dataset Test Metrics RCGAN TimeGAN PCFGAN HRPCF-GAN
Marginal .010 ±.000 .041 ±.000 .007 ±.000 .005±.000
fBM Predictive .456 ±.004 .686 ±.013 .474 ±.003 .446±.002
ONND .622±.002 .632±.002 .654 ±.002 .622±.002
Marginal (1+) 1.181 ±.144 .626 ±.137 .476 ±.146 .272±.122
Stock Predictive .010 ±.000 .009±.000 .009 ±.000 .009 ±.000
ONND .017 ±.001 .017 ±.000 .016±.000 .016 ±.000
Table 5: Performance comparison of High Rank PCF-GAN and baselines. The best for each task is
shown in bold. Each test metric is shown in the form of mean ±std over 5runs.
In all the numerical experiments of GAN training, we used a moderate matrix order ( l≤30) to
achieve satisfactory results. Specifically, our experiments were conducted on a single GPU, with the
training time for HRPCF-GAN ranging from 30 minutes to 4 hours. Although HRPCF-GAN takes
longer to train compared to other baselines, the total training time is kept at a manageable level, while
the HRPCF-GAN consistently delivers better performance. We summarize the computation time of
each of the models over 100 training iterations in Table 6.
Training Time (s) TimeGAN RCGAN PCF-GAN HRPCF-GAN
fBM 11.21 ±0.28 5.98 ±0.35 15.63 ±1.31 31.96 ±2.92
Stock 12.48 ±0.31 7.39 ±0.65 17.33 ±1.36 34.52 ±2.72
Table 6: Time measurement over 100 training iterations. The experiments are done using a single
Quadro RTX 8000 GPU; each experiment is repeated 5 times, with the mean and standard deviation
recorded.
34Figure 6: Sample plots from all models on fractional Brownian Motion conditioned on the same
past path. The thick red line indicates the conditional mean of future estimated by fake samples,
whereas the shaded red area presents the region of ±std. The thick green line corresponds to the
theoretical value for the future expectation and the shaded area shown corresponds to the region of
±theoretical std.
Figure 7: Sample plots from all models on Stock dataset conditioned on the same past path. The thick
red line indicates the conditional mean of future estimated by fake samples, whereas the shaded red
area presents the region of ±std.
35NeurIPS Paper Checklist
1.Claims
Question: Do the main claims made in the abstract and introduction accurately reflect the
paper’s contributions and scope?
Answer: [Yes]
Justification: In the abstract and introduction, we clearly state the main contributions of this
paper along with important assumptions and limitations.
Guidelines:
•The answer NA means that the abstract and introduction do not include the claims
made in the paper.
•The abstract and/or introduction should clearly state the claims made, including the
contributions made in the paper and important assumptions and limitations. A No or
NA answer to this question will not be perceived well by the reviewers.
•The claims made should match theoretical and experimental results, and reflect how
much the results can be expected to generalize to other settings.
•It is fine to include aspirational goals as motivation as long as it is clear that these goals
are not attained by the paper.
2.Limitations
Question: Does the paper discuss the limitations of the work performed by the authors?
Answer: [Yes]
Justification: See Limitation and Future work in Section 6.
Guidelines:
•The answer NA means that the paper has no limitation while the answer No means that
the paper has limitations, but those are not discussed in the paper.
• The authors are encouraged to create a separate "Limitations" section in their paper.
•The paper should point out any strong assumptions and how robust the results are to
violations of these assumptions (e.g., independence assumptions, noiseless settings,
model well-specification, asymptotic approximations only holding locally). The authors
should reflect on how these assumptions might be violated in practice and what the
implications would be.
•The authors should reflect on the scope of the claims made, e.g., if the approach was
only tested on a few datasets or with a few runs. In general, empirical results often
depend on implicit assumptions, which should be articulated.
•The authors should reflect on the factors that influence the performance of the approach.
For example, a facial recognition algorithm may perform poorly when image resolution
is low or images are taken in low lighting. Or a speech-to-text system might not be
used reliably to provide closed captions for online lectures because it fails to handle
technical jargon.
•The authors should discuss the computational efficiency of the proposed algorithms
and how they scale with dataset size.
•If applicable, the authors should discuss possible limitations of their approach to
address problems of privacy and fairness.
•While the authors might fear that complete honesty about limitations might be used by
reviewers as grounds for rejection, a worse outcome might be that reviewers discover
limitations that aren’t acknowledged in the paper. The authors should use their best
judgment and recognize that individual actions in favor of transparency play an impor-
tant role in developing norms that preserve the integrity of the community. Reviewers
will be specifically instructed to not penalize honesty concerning limitations.
3.Theory Assumptions and Proofs
Question: For each theoretical result, does the paper provide the full set of assumptions and
a complete (and correct) proof?
36Answer: [Yes]
Justification: We state the assumptions In the theorems and lemmas in Section 3 and
Appendix A, and provide the corresponding proof in Appendix A.
Guidelines:
• The answer NA means that the paper does not include theoretical results.
•All the theorems, formulas, and proofs in the paper should be numbered and cross-
referenced.
•All assumptions should be clearly stated or referenced in the statement of any theorems.
•The proofs can either appear in the main paper or the supplemental material, but if
they appear in the supplemental material, the authors are encouraged to provide a short
proof sketch to provide intuition.
•Inversely, any informal proof provided in the core of the paper should be complemented
by formal proofs provided in appendix or supplemental material.
• Theorems and Lemmas that the proof relies upon should be properly referenced.
4.Experimental Result Reproducibility
Question: Does the paper fully disclose all the information needed to reproduce the main ex-
perimental results of the paper to the extent that it affects the main claims and/or conclusions
of the paper (regardless of whether the code and data are provided or not)?
Answer: [Yes]
Justification: To ensure the reproducibility of our numerical results, we provide the peus-
docodes of all the main algorithms and the the implementation details in appendix C.
Guidelines:
• The answer NA means that the paper does not include experiments.
•If the paper includes experiments, a No answer to this question will not be perceived
well by the reviewers: Making the paper reproducible is important, regardless of
whether the code and data are provided or not.
•If the contribution is a dataset and/or model, the authors should describe the steps taken
to make their results reproducible or verifiable.
•Depending on the contribution, reproducibility can be accomplished in various ways.
For example, if the contribution is a novel architecture, describing the architecture fully
might suffice, or if the contribution is a specific model and empirical evaluation, it may
be necessary to either make it possible for others to replicate the model with the same
dataset, or provide access to the model. In general. releasing code and data is often
one good way to accomplish this, but reproducibility can also be provided via detailed
instructions for how to replicate the results, access to a hosted model (e.g., in the case
of a large language model), releasing of a model checkpoint, or other means that are
appropriate to the research performed.
•While NeurIPS does not require releasing code, the conference does require all submis-
sions to provide some reasonable avenue for reproducibility, which may depend on the
nature of the contribution. For example
(a)If the contribution is primarily a new algorithm, the paper should make it clear how
to reproduce that algorithm.
(b)If the contribution is primarily a new model architecture, the paper should describe
the architecture clearly and fully.
(c)If the contribution is a new model (e.g., a large language model), then there should
either be a way to access this model for reproducing the results or a way to reproduce
the model (e.g., with an open-source dataset or instructions for how to construct
the dataset).
(d)We recognize that reproducibility may be tricky in some cases, in which case
authors are welcome to describe the particular way they provide for reproducibility.
In the case of closed-source models, it may be that access to the model is limited in
some way (e.g., to registered users), but it should be possible for other researchers
to have some path to reproducing or verifying the results.
5.Open access to data and code
37Question: Does the paper provide open access to the data and code, with sufficient instruc-
tions to faithfully reproduce the main experimental results, as described in supplemental
material?
Answer: [Yes]
Justification: We provide open access to the data and submit the complete source code in
a compressed (zipped) file. We will make the codes publicly available when the paper is
published
Guidelines:
• The answer NA means that paper does not include experiments requiring code.
•Please see the NeurIPS code and data submission guidelines ( https://nips.cc/
public/guides/CodeSubmissionPolicy ) for more details.
•While we encourage the release of code and data, we understand that this might not be
possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not
including code, unless this is central to the contribution (e.g., for a new open-source
benchmark).
•The instructions should contain the exact command and environment needed to run to
reproduce the results. See the NeurIPS code and data submission guidelines ( https:
//nips.cc/public/guides/CodeSubmissionPolicy ) for more details.
•The authors should provide instructions on data access and preparation, including how
to access the raw data, preprocessed data, intermediate data, and generated data, etc.
•The authors should provide scripts to reproduce all experimental results for the new
proposed method and baselines. If only a subset of experiments are reproducible, they
should state which ones are omitted from the script and why.
•At submission time, to preserve anonymity, the authors should release anonymized
versions (if applicable).
•Providing as much information as possible in supplemental material (appended to the
paper) is recommended, but including URLs to data and code is permitted.
6.Experimental Setting/Details
Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
results?
Answer: [Yes]
Justification: We provide all the necessary details of experiments in Section 5 and Ap-
pendix C.
Guidelines:
• The answer NA means that the paper does not include experiments.
•The experimental setting should be presented in the core of the paper to a level of detail
that is necessary to appreciate the results and make sense of them.
•The full details can be provided either with the code, in appendix, or as supplemental
material.
7.Experiment Statistical Significance
Question: Does the paper report error bars suitably and correctly defined or other appropriate
information about the statistical significance of the experiments?
Answer: [Yes]
Justification: We report the error bars to all the numerical test metrics. See Section 5 and
Appendix C.
Guidelines:
• The answer NA means that the paper does not include experiments.
•The authors should answer "Yes" if the results are accompanied by error bars, confi-
dence intervals, or statistical significance tests, at least for the experiments that support
the main claims of the paper.
38•The factors of variability that the error bars are capturing should be clearly stated (for
example, train/test split, initialization, random drawing of some parameter, or overall
run with given experimental conditions).
•The method for calculating the error bars should be explained (closed form formula,
call to a library function, bootstrap, etc.)
• The assumptions made should be given (e.g., Normally distributed errors).
•It should be clear whether the error bar is the standard deviation or the standard error
of the mean.
•It is OK to report 1-sigma error bars, but one should state it. The authors should
preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis
of Normality of errors is not verified.
•For asymmetric distributions, the authors should be careful not to show in tables or
figures symmetric error bars that would yield results that are out of range (e.g. negative
error rates).
•If error bars are reported in tables or plots, The authors should explain in the text how
they were calculated and reference the corresponding figures or tables in the text.
8.Experiments Compute Resources
Question: For each experiment, does the paper provide sufficient information on the com-
puter resources (type of compute workers, memory, time of execution) needed to reproduce
the experiments?
Answer: [Yes]
Justification: We provide the computing resource information in Appendix C.
Guidelines:
• The answer NA means that the paper does not include experiments.
•The paper should indicate the type of compute workers CPU or GPU, internal cluster,
or cloud provider, including relevant memory and storage.
•The paper should provide the amount of compute required for each of the individual
experimental runs as well as estimate the total compute.
•The paper should disclose whether the full research project required more compute
than the experiments reported in the paper (e.g., preliminary or failed experiments that
didn’t make it into the paper).
9.Code Of Ethics
Question: Does the research conducted in the paper conform, in every respect, with the
NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines ?
Answer: [Yes]
Justification: We conducted this research in compliance with the NeurIPS Code of Ethics.
Guidelines:
•The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
•If the authors answer No, they should explain the special circumstances that require a
deviation from the Code of Ethics.
•The authors should make sure to preserve anonymity (e.g., if there is a special consid-
eration due to laws or regulations in their jurisdiction).
10.Broader Impacts
Question: Does the paper discuss both potential positive societal impacts and negative
societal impacts of the work performed?
Answer: [Yes]
Justification: We discuss both positive and negative impacts in Section 6.
Guidelines:
• The answer NA means that there is no societal impact of the work performed.
•If the authors answer NA or No, they should explain why their work has no societal
impact or why the paper does not address societal impact.
39•Examples of negative societal impacts include potential malicious or unintended uses
(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
(e.g., deployment of technologies that could make decisions that unfairly impact specific
groups), privacy considerations, and security considerations.
•The conference expects that many papers will be foundational research and not tied
to particular applications, let alone deployments. However, if there is a direct path to
any negative applications, the authors should point it out. For example, it is legitimate
to point out that an improvement in the quality of generative models could be used to
generate deepfakes for disinformation. On the other hand, it is not needed to point out
that a generic algorithm for optimizing neural networks could enable people to train
models that generate Deepfakes faster.
•The authors should consider possible harms that could arise when the technology is
being used as intended and functioning correctly, harms that could arise when the
technology is being used as intended but gives incorrect results, and harms following
from (intentional or unintentional) misuse of the technology.
•If there are negative societal impacts, the authors could also discuss possible mitigation
strategies (e.g., gated release of models, providing defenses in addition to attacks,
mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
feedback over time, improving the efficiency and accessibility of ML).
11.Safeguards
Question: Does the paper describe safeguards that have been put in place for responsible
release of data or models that have a high risk for misuse (e.g., pretrained language models,
image generators, or scraped datasets)?
Answer: [NA]
Justification: We use the synthetic data generated by fractional Brownian motion and
publicly available stock data from Yahoo Finance. There is no foreseeable risk of using
these data.
Guidelines:
• The answer NA means that the paper poses no such risks.
•Released models that have a high risk for misuse or dual-use should be released with
necessary safeguards to allow for controlled use of the model, for example by requiring
that users adhere to usage guidelines or restrictions to access the model or implementing
safety filters.
•Datasets that have been scraped from the Internet could pose safety risks. The authors
should describe how they avoided releasing unsafe images.
•We recognize that providing effective safeguards is challenging, and many papers do
not require this, but we encourage authors to take this into account and make a best
faith effort.
12.Licenses for existing assets
Question: Are the creators or original owners of assets (e.g., code, data, models), used in
the paper, properly credited and are the license and terms of use explicitly mentioned and
properly respected?
Answer: [Yes]
Justification: We cite the original paper that produced the code package and dataset in the
paper. See Section 5 and Appendix C.
Guidelines:
• The answer NA means that the paper does not use existing assets.
• The authors should cite the original paper that produced the code package or dataset.
•The authors should state which version of the asset is used and, if possible, include a
URL.
• The name of the license (e.g., CC-BY 4.0) should be included for each asset.
•For scraped data from a particular source (e.g., website), the copyright and terms of
service of that source should be provided.
40•If assets are released, the license, copyright information, and terms of use in the
package should be provided. For popular datasets, paperswithcode.com/datasets
has curated licenses for some datasets. Their licensing guide can help determine the
license of a dataset.
•For existing datasets that are re-packaged, both the original license and the license of
the derived asset (if it has changed) should be provided.
•If this information is not available online, the authors are encouraged to reach out to
the asset’s creators.
13.New Assets
Question: Are new assets introduced in the paper well documented and is the documentation
provided alongside the assets?
Answer: [Yes]
Justification: We submit the codes with the necessary documentation in the form of the
anonymized zip file.
Guidelines:
• The answer NA means that the paper does not release new assets.
•Researchers should communicate the details of the dataset/code/model as part of their
submissions via structured templates. This includes details about training, license,
limitations, etc.
•The paper should discuss whether and how consent was obtained from people whose
asset is used.
•At submission time, remember to anonymize your assets (if applicable). You can either
create an anonymized URL or include an anonymized zip file.
14.Crowdsourcing and Research with Human Subjects
Question: For crowdsourcing experiments and research with human subjects, does the paper
include the full text of instructions given to participants and screenshots, if applicable, as
well as details about compensation (if any)?
Answer: [NA]
Justification: Our paper does not involve crowdsourcing nor research with human subjects.
Guidelines:
•The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
•Including this information in the supplemental material is fine, but if the main contribu-
tion of the paper involves human subjects, then as much detail as possible should be
included in the main paper.
•According to the NeurIPS Code of Ethics, workers involved in data collection, curation,
or other labor should be paid at least the minimum wage in the country of the data
collector.
15.Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
Subjects
Question: Does the paper describe potential risks incurred by study participants, whether
such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
approvals (or an equivalent approval/review based on the requirements of your country or
institution) were obtained?
Answer: [NA]
Justification: Our paper does not involve crowdsourcing nor research with human subjects.
Guidelines:
•The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
•Depending on the country in which research is conducted, IRB approval (or equivalent)
may be required for any human subjects research. If you obtained IRB approval, you
should clearly state this in the paper.
41•We recognize that the procedures for this may vary significantly between institutions
and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
guidelines for their institution.
•For initial submissions, do not include any information that would break anonymity (if
applicable), such as the institution conducting the review.
42