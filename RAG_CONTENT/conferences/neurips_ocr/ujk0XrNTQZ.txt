DRAGO : Primal-Dual Coupled Variance Reduction
for Faster Distributionally Robust Optimization
Ronak Mehta1Jelena Diakonikolas2Zaid Harchaoui1
1University of Washington, Seattle2University of Wisconsin, Madison
Abstract
We consider the penalized distributionally robust optimization (DRO) problem
with a closed, convex uncertainty set, a setting that encompasses learning us-
ingf-DRO and spectral/ L-risk minimization. We present DRAGO , a stochastic
primal-dual algorithm that combines cyclic and randomized components with a
carefully regularized primal update to achieve dual variance reduction. Owing to
its design, DRAGO enjoys a state-of-the-art linear convergence rate on strongly
convex-strongly concave DRO problems with a fine-grained dependency on pri-
mal and dual condition numbers. The theoretical results are supported by numer-
ical benchmarks on regression and classification tasks.
1 Introduction
Contemporary machine learning research is increasingly exploring the phenomenon of distribution
shift, in which predictive models encounter differing data-generating distributions in training versus
deployment [Wiles et al., 2022]. A popular approach to learn under potential distribution shift is
distributionally robust optimization (DRO) of an empirical risk-type objective
min
w∈Wmax
q∈Qh
L0(w, q) :=Pn
i=1qiℓi(w)i
, (1)
where ℓi:Rd→Rdenotes the loss on training instance i∈[n] :={1, . . . , n }, and q=
(q1, . . . , q n)∈ Q is a vector of nweights for each example. The feasible set Q, often called
theuncertainty set , is a collection of possible instance-level reweightings arising from distributional
shifts between train and evaluation data, and is often chosen as a ball about the uniform vector
1/n= (1/n, . . . , 1/n)inf-divergence [Namkoong and Duchi, 2016, Carmon and Hausler, 2022,
Levy et al., 2020] or a spectral/ L-risk-based uncertainty set [Mehta et al., 2023].
We consider here the penalized version of (1), stated as
L(w, q) :=nX
i=1qiℓi(w)−νD(q∥1/n) +µ
2∥w∥2
2, (2)
where µ, ν≥0are regularization parameters and D(q∥1/n)denotes some statistical divergence
(such as the Kullback-Leibler (KL) or χ2-divergence) between the original weights 1/nand shifted
weights q. For clarity, we focus on the cases of µ, ν > 0, but also describe the modifications to
the methods, results, and proofs for cases in which µ= 0 orν= 0, in Appx. C.4. See Fig. 1 for
intuition on the relationship between the uncertainty set, divergence D, and hyperparameter ν.
Standard (1) and penalized (2) DRO objectives have seen an outpour of recent use in reinforcement
learning and control [Lotidis et al., 2023, Yang et al., 2023, Wang et al., 2023a, Yu et al., 2023,
Kallus et al., 2022, Liu et al., 2022] as well as creative applications in robotics [Sharma et al.,
2020], language modeling [Liu et al., 2021], sparse neural network training [Sapkota et al., 2023],
38th Conference on Neural Information Processing Systems (NeurIPS 2024).Figure 1: Visualization of Uncertainty Sets and Penalties. Each plot is a probability simplex in
n= 3 dimensions with the uncertainty set as the colored portion. The black dots are optimal dual
variables q⋆
ν:= arg maxq∈QPn
i=1qiℓi(w)−νD(q∥1/n)for a fixed w∈W. Asνdecreases, q⋆
ν
may shift toward the boundary of the uncertainty set. The combination of νandDdetermines an
“effective” uncertainty set, whose shape is given by the level sets of D. Our methods apply to both.
and defense against model extraction [Wang et al., 2023b]. However, even in a classical supervised
learning setup, current optimization algorithms for DRO have limitations in both theory and practice.
For context, we consider the large-scale setting in which the sample size nis high, and the training
loss on each example is accessed via a collection of nprimal first-order oracles {(ℓi,∇ℓi)}n
i=1.
Quantitatively, we measure the performance of algorithms by the runtime or global complexity of
elementary operations to reach within εof the minimum of ¯L(w) = max q∈QL(w, q), whereas
qualitatively, we consider the types of uncertainty sets that can be handled by the algorithm and
convergence analysis. Under standard assumptions, ¯Lis differentiable with gradient computed via
q⋆(w) = arg max
q∈QL(w, q),followed by ∇¯L(w) =Pn
i=1q⋆
i(w)∇ℓi(w) +µw. (3)
In the learning setting, we are interested in stochastic algorithms that can approximate this gradient
withb < n calls to the oracles. For uniformly randomly sampled i∈[n],nq⋆
i(w)∇ℓi(w) +µwis
an unbiased estimator of ∇¯L(w). However, computing q⋆
i(w)depends on the first step in (3) which
itself requires calling all noracles (see (2)), i.e., is no different than the cost of full batch gradient
descent. A direct minibatch stochastic gradient descent approach would approximate L(w,·)in the
first step of (3) with only bcalls to generate approximate weights ˆq(w). Because ˆq(w)̸=q⋆(w)in
general for b < n , these methods have non-vanishing bias, i.e., do notconverge [Levy et al., 2020].
This motivated research in DRO-specific stochastic algorithms with theoretical convergence guaran-
tees under particular assumptions (see Tab. 1 and Appx. B for details) [Namkoong and Duchi, 2016,
Levy et al., 2020, Carmon and Hausler, 2022]. While we highlight the dependence on sample size n
and suboptimality ε, the dependence on all constants is given in Tab. 1. For f-divergence-based un-
certainty sets in the standard oracle framework, several methods achieve a O(ε−2)complexity. Levy
et al. [2020] do so by proving uniform bias bounds, so that if bscales as O(ε−2), the convergence
guarantee is achieved. However, if the required batch size bexceeds the training set size n, then the
method reduces to the sub-gradient method, as we can see in Tab. 1. These sublinear rates typically
stem from two causes. The first is the adoption of a ”fully stochastic” perspective on the oracles,
wherein each oracle’s output is treated as an independent random sample drawn from a probability
distribution. The second is the non-smoothness of the objective, as we shall see below.
Variance reduction techniques, on the other hand, exploit the fact that the optimization algo-
rithm takes multiple passes through the same dataset, and achieve linear rates of the form
O((n+κℓ) log( ε−1))in empirical risk minimization when the objective is both smooth (i.e.,
has Lipschitz continuous gradient) and strongly convex and κℓis an associated condition number
[Johnson and Zhang, 2013, Defazio et al., 2014]. Assuming access to stronger oracles involving
constrained minimization and applying a variance reduction scheme, Carmon and Hausler [2022]
achieve O(nε−2/3+n3/4ε−1)forf-divergences as well, but do not obtain linear convergence due
to the second type of cause: the objective ∇¯Lisnon-smooth when ν= 0.
2Recently, Mehta et al. [2024] handled the ν > 0case for spectral risk uncertainty sets, and their
variance-reduced algorithm achieves a linear O((n+κQκℓ) ln(1 /ε))convergence guarantee (where
κQ≥1measures the “size” of the uncertainty set), but only with a lower bound of order Ω(n)on
the problem parameter ν. The challenge of this problem, considered from a general optimization
viewpoint beyond DRO, stems from the non-bilinearity of the coupled termPn
i=1qiℓi(w)and the
constraint thatPn
i=1qi= 1for probability vectors. If the coupled term was bilinear (i.e., of the form
q⊤AwforA∈Rn×d) and the constraints applied separately to each qi, then dual decomposition
techniques could be used. Qualitatively, algorithms and analyses often rely on particular uncertainty
sets; for example, Kumar et al. [2024] use duality arguments specific to the Kullback-Leibler uncer-
tainty set to create a primal-only minimization problem. See Appx. B for a detailed discussion of
related work from the ML and the optimization lenses. Given the interest from both communities,
we address whether a stochastic DRO algorithm can simultaneously 1) achieve a linear convergence
rate for any ν >0and 2) apply to many common uncertainty sets.
Contributions We propose DRAGO , a minibatch primal-dual algorithm for the penalized DRO prob-
lem (2) that achieves ε-suboptimality in
O "
n
b+κQL
µ+n
bs
nG2
µν#
ln1
ε!
(4)
iterations, where b∈ {1, . . . , n }is the minibatch size, κQ=nqmax:=nmax q∈Q,i∈[n]qimea-
sures the size of the uncertainty set, and GandLare the Lipschitz continuity parameters of ℓiand
∇ℓi, respectively. For commonly used parameters of uncertainty sets, nqmax is bounded above by
an absolute constant independent in n(see Prop. 3), so for d < n andb=n/d, we maintain an
O(n)per-iteration complexity (the dual dimensionality) while reducing the number of iterations to
O((d+nqmaxL/µ+dp
nG2/(µν))) ln (1 /ε)). Theoretically, the complexity bound we achieve
in (4) is the best one among current penalized DRO algorithms, delineating a clear dependence on
smoothness constants of the coupled term and strong convexity constants of the individual terms
in (2). Practically, DRAGO has a single hyperparameter and operates on any closed, convex un-
certainty set for which the map l7→arg maxq∈Q
q⊤l−νD(q∥1/n)	
is efficiently computable.
DRAGO is also of general conceptual interest as a stochastic variance-reduced primal-dual algorithm
for min-max problems. It delicately combines randomized and cyclic components, which effectively
address the varying dimensions of the two problems (see Sec. 2). The theoretical guarantees of the
algorithm are explained in Sec. 3. Numerical performance benchmarks are shown in Sec. 4.
2 The DRAGO Algorithm
We present here the Distributionally Robust Annular Gradient Optimizer ( DRAGO ). While similar
in spirit to a primal-dual proximal gradient method with a stochastic flavor, there are several inno-
vations that allow the algorithm to achieve its superior complexity guarantee. These include using
1) minibatch stochastic gradient estimates to improve the trade-off between the per-iteration com-
plexity and required number of iterations (especially when n≫d), 2) a combination of randomized
and cyclically updated components in the primal and dual gradient estimates, and 3) a novel regu-
larization term in the primal update which reduces variance in the gradient estimate (i.e., coupled
variance reduction). Here, we describe the algorithm in a manner that helps elucidate the upcoming
theoretical analysis (Sec. 3). On the other hand, in Appx. D, we present an alternate description of
DRAGO that is amenable to direct implementation in code.
Notation & Terminology Letψ:Rn→R∪ {+∞} be a proper, convex function such that
Q ⊆dom( ψ) :={q∈Rn:ψ(q)<+∞}. Letψhave a non-empty subdifferential for each q∈ Q,
and denote by ∇ψa map from q∈ Q to an arbitrary but consistently chosen subgradient in ∂ψ(q).
We denote the Bregman divergence generated by ψas∆ψ(q,¯q) =ψ(q)−ψ(¯q)− ⟨∇ ψ(¯q), q−¯q⟩.
We define the Bregman divergence in this way for purely technical reasons, to gracefully account
for cases such as computing ∆ψ(q,¯q)when ψis the negative entropy function and ¯qlies on the
boundary of the n-dimensional probability simplex. Finding a minimizer of (2) is equivalent to
finding a saddle-point (w⋆, q⋆)∈ W × Q which satisfies
max
q∈QL(w⋆, q) =L(w⋆, q⋆) = min
w∈WL(w, q⋆).
3Method Assumptions Uncertainty Set Runtime / Global Complexity (Big- ˜O)
Sub-Gradient MethodℓiisG-Lipschitz
∥w−w′∥2≤R(if included)
µ >0(if included)
∇ℓiisL-Lipschitz and ν >0(if included)Support Constrained
Support Constrained
Support Constrainednd·(GR)2ε−2
nd·G2µ−1ε−1
nd·µ−1 
L+µ+nG2/ν
log(1/ε)
LCVaR-SGD†
Lχ2-SGD†
Lχ2−pen-SGD†
[Levy et al., 2020]ℓiisG-Lipschitz and in [0, B]
∥w−w′∥2≤Rfor all w, w′∈W
ν >0(if included)θ-CVaR
ρ-ball in χ2-divergence
χ2-divergence penaltymin
n, B2θ−1ε−2	
d·(GR)2ε−2
min
n,(1 +ρ)B2ε−2	
d·(GR)2ε−2
min
n, B2ν−1ε−1	
d·(GR)2ε−2
BROO∗
BROO∗
[Carmon and Hausler, 2022]ℓiisG-Lipschitz
∥w−w′∥2≤Rfor all w, w′∈W
∇ℓiisL-Lipschitz (if included)1-ball in f-divergence
1-ball in f-divergencend·(GR)2/3ε−2/3+d(GR)2ε−2
nd·(GR)2/3ε−2/3+n3/4d 
GRε−1+L1/2Rε−1/2
LSVRG
LSVRG
[Mehta et al., 2023]ℓiisG-Lipschitz
∇ℓiisL-Lipschitz
µ >0,ν >0,κ:= (L+µ)/µSpectral Risk Measures ( νsmall)
Spectral Risk Measures ( ν≥Ω(nG2/µ))None
(n+κQκ)dlog(1/ε)
Prospect
Prospect
[Mehta et al., 2024]ℓiisG-Lipschitz
∇ℓiisL-Lipschitz
µ >0,ν >0,κ:= (L+µ)/µ, δ =G2/(µν)Spectral Risk Measures ( νsmall)
Spectral Risk Measures ( ν≥Ω(nG2/µ))n(n+d) max
nδ+κnqmax, n3δ2κ2, n3δ3	
log(1/ε)
(n+κQκ) (n+d)log(1 /ε)
DRAGO (Ours)ℓiisG-Lipschitz
∇ℓiisL-Lipschitz
µ >0,ν >0,b:=Batch SizeSupport Constrained n
d+κQL/µ+dp
nG2/(µν)
log(1/ε)
Table 1: Complexity Bounds of DRO Methods. Runtime or global complexity (i.e., the total num-
ber of elementary operations required to compute wsatisfying max q∈QL(w, q)− L(w⋆, q⋆)≤ε.
Throughout, we assume that each ℓiis convex and µ, ν≥0. The “Support Constrained” uncertainty
set refers to all closed, convex sets of probability mass vectors and any 1-strongly convex penalty.
This includes f-divergences and spectral risk measures, but not general Wasserstein balls.∗Bounds
hold in high probability.†Complexity is measured in our framework; see Appx. B for details.
We denote the Jacobian of ℓ:= (ℓ1, . . . , ℓ n)atwas∇ℓ(w)∈Rn×d. We refer to the gradient of
the coupled term q⊤ℓ(w)of (2) with respect to wandq(that is, ∇ℓ(w)⊤qandℓ(w)) as the primal
and dual gradients, respectively. In both the definition of the algorithm as well as the analysis, we
will consider a sequence of positive constants (at)t≥1with the additional values a0= 0. The partial
sums of this sequence will be denoted At=Pt
τ=0aτ. Here, trepresents the iteration counter while
the convergence rate will be proportional to A−1
t(see Sec. 3), so we wish for the sequence to grow
as fast as possible. As mentioned in Sec. 1, dis the primal dimension, nis the dual dimension as
well as the sample size, and bdenotes a batch size that divides nfor ease of presentation.
Algorithm Description We specify the algorithm by recursively defining a sequence of primal-dual
iterates {(wt, qt)t≥1}that achieve a particular convergence guarantee. First, we may assume that
0∈Wwithout loss of generality, so fix w0=0andq0=1/n. For any t≥1, we introduce
vP
t−1andvD
tas to-be-specified stochastic gradient estimates of the quantities ∇ℓ(wt−1)⊤qt−1and
ℓ(wt), respectively. We choose to update wtbefore qt, so that vP
t−1may depend only on the history
{(wτ, qτ}t−1
τ=0, whereas vD
tmay depend additionally on wtas well. Letting (Ct)t≥1and(ct)t≥1be
to-be-specified sequences of positive constants with C0=c0= 0, we employ primal-dual proximal
approach guided by the updates
wt:= arg min
w∈Wn
at
vP
t, w
+atµ
2∥w∥2
2+Ct−1µ
2∥w−wt−1∥2
2(5)
+ct−1µ
2t−2X
s=t−n/b∥w−ws∨0∥2
2o
(6)
qt:= arg max
q∈Qn
at
vD
t, q
−atνD(q∥q0)−At−1ν∆D(q, qt−1)o
. (7)
For the primal update, despite the non-standard term (6), wtcan be computed easily in closed form
whenW=Rd. Otherwise, retrieving wtrelies on computing an ℓ2-norm projection onto W. On
the other hand, the maximization (7) can often be solved exactly or to high accuracy using methods
specific to each uncertainty set; we describe these in detail in Appx. D.2. The randomized and
cyclic coordinate-wise components mentioned above are contained within the upcoming formulas
forvP
t−1andvD
t. After specifying these vectors, the constants (Ct, ct)will be chosen in the analysis
to recover the final algorithm.
4Next, we describe the computation of vP
t−1andvD
t, which will rely on quantities that are stored
by the algorithm along its iterations. We store three tables of values ˆℓt∈Rn,ˆqt∈Rn, and
ˆg∈Rn×d, which are approximations of ℓ(wt),qt, and∇ℓ(wt), respectively. Before explaining
how these tables are updated, consider the data indices {1, . . . , n }to be partitioned into n/bblocks,
written (B1, . . . , B n/b)forBK= (K−b+ 1, . . . , Kb ). On each iteration t, we randomly sample
independent block indices It, Jt∼Unif[ n/b]and define
vP
t−1= ˆg⊤
t−1ˆqt−1+at−1
at·n
bX
i∈BIt(qt−1,i∇ℓi(wt−1)−ˆqt−2,iˆgt−2,i) (8)
vD
t=ˆℓt+at−1
at·n
bX
j∈BJt(ℓj(wt)−ˆℓt−1,j)ej (9)
As for the tables of approximations, we update them on each iteration without suffering the
O(nd)computational cost of querying every first-order oracle (ℓ1,∇ℓ1), . . . , (ℓn,∇ℓn). We set
(ˆℓ0,ˆq0,ˆg0) = ( ℓ(w0), q0,∇ℓ(w0)), and for iteration t≥1update block Kt:= (n/b) mod t+ 1
via
(ˆℓt,k,ˆqt,k,ˆgt,k) =(
(ℓk(wt), qt,k,∇ℓk(wt)) ifk∈BKt
(ˆℓt−1,k,ˆqt−1,k,ˆgt−1,k) ifk /∈BKt
While qtin particular is always known by the algorithm, we use the approximation ˆqtwhich is pos-
sibly dual infeasible for every t≥1, but will approach qtastgrows large. Using this approximation
is essential to controlling the per-iteration time complexity, as described below. In addition, the de-
sign of (8) and (9) is grounded in the long line of work on incremental methods (both deterministic
and randomized). The table of past gradients updated cyclically resembles IAG [Blatt et al., 2007],
whereas the randomized component resembles methods such as SAGA [Defazio et al., 2014] and
stochastic PDHG [Chambolle et al., 2018]. The full algorithm description is given in Algorithm 1.
In the next section, we show that (at, Ct, ct)t≥0can be determined by a single hyperparameter.
Computational Complexity We also discuss the per-iteration time complexity and the global space
complexity of Algorithm 1, whereas the number of required iterations for ε-suboptimality is given
in the next section. We see that the per-iteration time complexity is O(n+bd), as we query b
first-order oracles in both the primal and dual updates and all other operations occur on n-length
ord-length vectors. While we need to employ O(nd)operations to compute ˆg⊤
t−1ˆqt−1in (8) when
t= 1, this quantity can be maintained with O(bd)operations in every subsequent iteration as only
brows of ˆqtandˆgtare editted in each iteration. For space complexity, we may consider storing
the entire gradient table ˆgtin memory, resulting in an O(nd)complexity. However, due to our
time complexity calculation, we may reduce the space complexity to O(n+bd)by storing only
wt−1, . . . , w t−n/band recomputing the relevant values of ˆgtin (8) in every iteration. Therefore, the
use of block-cyclic updates in the historical tables may significantly reduce the space complexity as
compared to randomized updates (as in Defazio et al. [2014]).
3 Theoretical Analysis
We provide the theoretical convergence rate and global complexity of DRAGO along with technical
highlights of the proof which may be of independent interest.
Convergence Analysis We measure suboptimality using the primal-dual gap :
γt:=L(wt, q⋆)− L(w⋆, qt)−µ
2∥wt−w⋆∥2
2−ν
2∥qt−q⋆∥2
2,
where the saddle point (w⋆, q⋆)exists under Asm. 1. Note that γt≥0, as it is the sum of non-
negative quantities
L(wt, q⋆)− L(w⋆, q⋆)−µ
2∥wt−w⋆∥2
2≥0andL(w⋆, q⋆)− L(w⋆, qt)−ν
2∥qt−q⋆∥2
2≥0.
To state the main result, define Etas the conditional expectation over (It, Jt)given (wt−1, qt−1)and
E1as the marginal expectation over the optimization trajectory. Consider the following assumptions.
5Algorithm 1 D istributionally Robust Annular Gradient Optimizer ( DRAGO )
Input: Sequence of constants (at, Ct, ct)t≥0, block size b∈ {1, . . . , n }, number of iterations T.
Initialize w0= 0d,q0=1/n,ˆℓ0=ℓ(w0),ˆg0=∇ℓ(w0), and ˆq0=q0.
fort= 1toTdo
Sample blocks ItandJtuniformly on [n/b], and define Kt=tmod ( n/b) + 1 .
Primal Update:
SetvP
t−1= ˆg⊤
t−1ˆqt−1+at−1n
atbP
i∈BIt(qt−1,i∇ℓi(wt−1)−ˆqt−2,iˆgt−2,i), update wtusing (5).
Update table (ˆℓt,k,ˆgt,k)to(ℓk(wt),∇ℓk(wt))ifk∈BKtor(ˆℓt−1,k,ˆgt−1,k)ifk /∈BKt.
Dual Update:
SetvD
t=ˆℓt+at−1n
atbP
j∈BJt(ℓj(wt)−ˆℓt−1,j)ej, update qtusing (7).
Update table ˆqt,ktoqt,kifk∈BKtorˆqt−1,kifk /∈BKt.
end for
return (wT, qT).
Assumption 1. Letℓ1, . . . , ℓ nbeG-Lipschitz continuous and L-smooth, in that for all i∈[n],
∥ℓi(w)−ℓi(w′)∥2≤G∥w−w′∥2and∥∇ℓi(w)− ∇ℓi(w′)∥2≤L∥w−w′∥2,
i.e., each ℓiisG-Lipschitz continuous and L-smooth with respect to ∥·∥2. Let µ > 0andν >0,
and let q7→D(q∥1n/n)be1-strongly convex with respect to ∥·∥2. Finally, Qis closed, convex, and
contains 1/n.
Regarding Asm. 1, an example of a loss function satisfying both Lipschitzness and smoothness
is given by the Huber loss used in robust statistics [Huber, 1981]. Another setting in which both
assumptions are satisfied is when the domain Wis compact, as smoothness will imply Lipschitz
continuity. Compactness is a common assumption when pursuing statistical guarantees such as
uniform convergence. As for the assumption of strong convexity, we describe modifications of the
algorithm when µ= 0orν= 0in Appx. C.4 along with corresponding changes in the analysis.
Theorem 2. For a constant α >0, define the sequence
a1= 1, a2= 4α,andat= (1 + α)at−1fort >2,
along with its partial sum At=Pt
τ=1aτ. Under Asm. 1, there is an absolute constant Csuch that
using the parameter
α=Cminb
n,µ
LκQ,b
nrµν
nG2
,
the iterates of Algorithm 1 satisfy:
TX
t=1atE1[γt] +ATµ
4E1∥wT−w⋆∥2
2+ATν
4E1∥qT−q⋆∥2
2≤nG2
ν∥w0−w1∥2
2.
We can compute a point (wT, qT)achieving an expected gap no more than εwith big- Ocomplexity
(n+bd)· 
n
b+LκQ
µ+n
bs
nG2
µν!
·ln1
ε
. (10)
By dividing the result of Thm. 2 by AT, we see that both the expected gap and expected distance-
to-optimum in the primal and dual sequences decay geometrically in T. By plugging in b=n/dwe
get the following runtime for Algorithm 1:
O 
nd+ndLκ Q
µ+n3/2ds
G2
µν!
ln1
ε
. (11)
6Note in particular the individual dependence on the condition numbers L/µ andnG2/(µν), as
opposed to the max-over-min-type condition numbers such as those achievable by generic primal-
dual or variational inequality methods (see Appx. B.3). The proof of Thm. 2 is provided in Appx. C,
along with a high-level overview in Appx. C.1. Our analysis relies on controlling atγtby bounding
atL(w⋆, qt)above and bounding atL(wt, q⋆)below. Key technical steps occur in the lower bound.
We first apply that w7→atq⊤
tℓ(w)is convex to produce a linear underestimator of the function
supported at wt, and use that wtis the minimizer of a strongly convex function, so
atL(w⋆, qt)≥atq⊤
tℓ(wt) +telescoping and non-positive terms
+at
∇ℓ(wt)⊤qt−vP
t, w⋆−wt
(12)
+ctµ
2t−2X
τ=t−n/b∥wt−wτ∨0∥2
2(13)
Note that the terms above will be negated when combining the upper and lower bounds. The labeled
terms are highly relevant in the analysis, with the second being non-standard. By expanding the
definition of vP
tand adding and subtracting wt−1, we write
at
∇ℓ(wt)⊤qt−vP
t, w⋆−wt
=at
∇ℓ(wt)⊤qt−ˆg⊤
t−1ˆqt−1, w⋆−wt
−nat−1
b(1 +η)X
i∈It⟨∇ℓi(wt−1)qt−1−ˆgt−2,iˆqt−2,i, w⋆−wt−1⟩
−nat−1
b(1 +η)X
i∈It⟨∇ℓi(wt−1)qt−1−ˆgt−2,iˆqt−2,i, wt−1−wt⟩.
When choosing the learning rate ηcorrectly, the first two terms will telescope in expecta-
tion (see Lem. 11). The third term, after applying Young’s inequality, requires controlling
1
bP
i∈It∥∇ℓi(wt−1)qt−1−ˆgt−2,iˆqt−2,i∥2
2in expectation, which we dub the “primal noise bound”
(Lem. 5). When we combine the upper and lower bounds, we get a similar inner prod-
uct term at
q⋆−qt, ℓ(wt)−vD
t
, and mirroring the arguments above, we encounter the term
1
bP
j∈Jt(ℓj(wt)−ˆℓt−1,j)2
2which also requires a “dual noise bound” (Lem. 6). Without loss of
generality, assume that the blocks are ordered such that
ˆℓt−1,i=ℓi(wt−1−K∨0)fori∈BK. (14)
By computing the conditional expectation Et[·] :=E[·|wt−1], we have that
Et
1
bX
j∈Jt(ℓj(wt)−ˆℓt−1,j)2
2
=1
nnX
i=1(ℓi(wt)−ˆℓt−1,i)2
2
=1
nn/bX
K=1X
i∈BK(ℓi(wt)−ℓi(wt−1−K∨0))2
2
≤G2b
nt−2X
τ=t−n/b∥wt−1−wτ∨0∥2
2,
where the second line follows from (14) and the third from G-Lipschitzness. This will telescope
with the second term introduced in (13), showing the importance of the regularization. The argument
follows similarly even when (14) does not hold, as the blocks can simply be “renamed” to achieve
the final bound. While the proof is technical, this core idea guides the analysis and the algorithm
design.
4 Experiments
In this section, we provide numerical benchmarks to measure DRAGO against baselines in terms
of evaluations of each component {(ℓi,∇ℓi)}n
i=1and wall clock time. We consider regression and
classification tasks. Letting (xi, yi)denote a feature-label pair, we have that each ℓirepresents the
70 50000 10000010−610−3100Suboptimality
yacht
0 50000 10000010−710−410−1
energy
0 50000 10000010−610−3100
concrete
0 1 210−610−3100
yacht
0 1 210−610−3100
energy
0 1 210−610−3100
concrete
0 50000 100000
First-Order Oracle Evaluations10−410−2100Suboptimality
acsincome
0 50000 100000
First-Order Oracle Evaluations10−610−3100
kin8nm
0 50000 100000
First-Order Oracle Evaluations10−710−410−1
power
0 5
Wall-Clock Time (Seconds)10−410−2100
acsincome
0 5
Wall-Clock Time (Seconds)10−610−3100
kin8nm
0 5
Wall-Clock Time (Seconds)10−710−410−1
power
SGD LSVRG Drago (b= 16 ) Drago (b=n/d) Drago (b= 1)Figure 2: Regression Benchmarks. In both panels, the y-axis measures the primal suboptimality
gap (15). Individual plots correspond to particular datasets. Left: Thex-axis displays the number of
individual first-order oracle queries to {(ℓi,∇ℓi)}n
i=1.Right: Thex-axis displays wall-clock time.
squared error loss or multinomial cross-entropy loss, given by
ℓi(w) :=1
2 
yi−x⊤
iw2andℓi(w) :=−x⊤
iwyi+ logX
y∈Yexp 
x⊤
iwy
,
respectively. In the latter case, we denote w= (w1, . . . , w C)∈RC×d, indicating multiclass clas-
sification with label set Y:={1, . . . , C }. We show results for the conditional value-at-risk (CVaR)
[Rockafellar and Royset, 2013] in this section, exploring the effect of sample size n, dimensionality
d, and regularization parameter νon optimization performance. The parameter νin particular has
interpretations both as a conditioning device (as it is inversely related to the smoothness constant of
w7→max q∈QL(w, q)and as a robustness parameter, as it controls the essential size of the uncer-
tainty set. Detailed experimental settings are contained in Appx. E, including additional experiments
with the χ2-divergence ball uncertainty set. The code to reproduce these experiments can be found
at https://github.com/ronakdm/drago.
We compare against baselines that can be used on the CVaR uncertainty set: distributionally robust
stochastic gradient descent (SGD) [Levy et al., 2020] and LSVRG [Mehta et al., 2023]. For SGD,
we use a batch size of 64 and for LSVRG we use the default epoch length of n. For DRAGO , we
investigate the variants in which bis set to 1andb=n/da priori, as well as cases when bis a tuned
hyperparameter. On the y-axis, we plot the primal gap
max q∈QL(wt, q)− L(w⋆, q⋆)
max q∈QL(w0, q)− L(w⋆, q⋆), (15)
where we approximate L(w⋆, q⋆)by running LBFGS [Nocedal and Wright, 1999] on the primal
objective until convergence. On the x-axis, we display either the exact number of calls to the first-
order oracles of the form (ℓi,∇ℓi)or the wall clock time in seconds. We fix µ= 1 but vary νto
study its role as a conditioning parameter, which is especially important as prior work establishes
different convergence rates for different values of ν(see Tab. 1).
4.1 Regression with Large Block Sizes
In this experiment, we consider six regression datasets, named yacht ( n= 244 , d= 6) [Tsanas and
Xifara, 2012], energy ( n= 614 , d= 8) [Baressi Segota et al., 2020], concrete ( n= 824 , d= 8)
[Yeh, 2006], acsincome ( n= 4000 , d= 202 ) [Ding et al., 2021], kin8nm ( n= 6553 , d= 8)
[Akujuobi and Zhang, 2017], and power ( n= 7654 , d= 4) [T¨ufekci, 2014]. In each case, there is a
univariate, real-valued output. Notice that most datasets, besides acsincome, are low-dimensional as
compared to their sample size. Thus, the default block size n/d becomes relatively large, imposing
an expensive per-iteration cost in terms of oracle queries. However, when the block size is high,
the stochastic gradient estimates in each iteration have lower variance and the table components are
updated more frequently, which could improve convergence in principle. The main question of this
80 100 200 300
First-Order Oracle Evaluations (K)10−510−310−1Suboptimality
ν=1.0
0 100 200 300
First-Order Oracle Evaluations (K)10−510−310−1
ν=0.01
0 100 200 300
First-Order Oracle Evaluations (K)10−510−310−1
ν=0.001
0 2 4
Wall-Clock Time (Seconds)10−210−1100
ν=1.0
0 2 4
Wall-Clock Time (Seconds)10−310−210−1100
ν=0.01
0 2 4
Wall-Clock Time (Seconds)10−410−310−210−1100
ν=0.001Figure 3: Text Classification Benchmarks. In all plots, the y-axis measures the normalized primal
(i.e., DRO risk) suboptimality gap, defined in (15). Columns represent a varying dual regularization
parameter ν. On the first three columns the x-axis measures the number of individual first-order
oracle queries to {(ℓi,∇ℓi)}n
i=1and the remaining three the x-axis displays wall-clock time. The
objective becomes ill-conditioned as νdecreases.
section is whether DRAGO efficiently manages this trade-off via the block size parameter b. Results
for gradient evaluations and wall clock time are on the left and right panels of Fig. 2, respectively.
Results The DRAGO variant for b=n/dis not included on the left plot, as the number of queries (al-
most 2,000 in the case of power) penalizes its performance heavily. Still, the same variant performs
best or near best on all datasets in terms of wall clock time (right plot). Thus, if the computation
of the queries is inexpensive enough, DRAGO can achieve the lowest suboptimality within a fixed
time budget. This is most striking in the case of kin8nm, in which DRAGO achieves 10−7primal
gap within 1 second, versus LSVRG which is only able to reach within 10−2of the minimum in
the same amount of time. We also experiment with tuning bto reach a balance between the cost
of queries and distance to optimum in the left plot with the b= 16 variant. In the datasets with
n≤1,000,DRAGO can match the performance of baselines with only b= 1, whereas in the larger
datasets, a batch size of 16is needed to be comparable.
4.2 Text Classification Under Ill-Conditioning
We consider a natural language processing example using the emotion dataset [Saravia et al., 2018],
which is a classification task consisting of six sentiment categories: sadness, anger, love, fear, joy,
and surprise. To featurize the text, we fine-tune a pre-trained BERT network [Devlin et al., 2019]
on a held-out set of 8,000 training examples to learn a vectorial representation. We then use a
disjoint subset of 8,000 training points and apply PCA to reduce them to 45-dimensional vectors.
Because of the six classes this results in d= 270 parameters to learn. To study the effect of
dual regularization, we consider ν∈ {1.0,0.01,0.001}. As νdecreases, the dual solution may
shift further from uniformity, and potentially increase the distributional robustness of the learned
minimizer. However, the objective can also become poorly conditioned, introducing a key trade-off
between optimization and statistical considerations when selecting ν. The results are in Fig. 3.
Results The run time required for LSVRG to make 500K gradient evaluations is too large to be
considered. We also observe that LSVRG is vulnerable to ill-conditioned objectives, as it is out-
performed by SGD for smaller values of νin terms of wall clock time. Within 4 seconds, DRAGO
can achieve close to a 10−5primal suboptimality gap while the gaps of SGD and LSVRG are 2 to
3 orders of magnitude larger in the same amount of time. We hypothesize that because the dual
variables in LSVRG are updated once every niterations, the primal gradient estimates may accrue
excessive bias. DRAGO withb=n/d, making ∼30individual first-order queries per iteration, is
performant in terms of oracle queries and wall clock time even as νdrops by 3 orders of magnitude.
5 Conclusion
We proposed DRAGO , a stochastic primal-dual algorithm for solving a host of distributionally robust
optimization (DRO) problems. The method achieves linear convergence without placing conditions
on the dual regularizer, and its empirical performance remains strong across varying settings of the
sample size n, dimension d, and the dual regularization parameter ν. The method combines ideas of
variance reduction, minibatching, and cyclic coordinate-style updates even though the dual feasible
set (a.k.a. the uncertainty set) is non-separable. Opportunities for future work include extensions to
non-convex settings and applications to min-max problems beyond distributional robustness, such
as missing data imputation and fully composite optimization.
9Acknowledgements This work was supported by NSF DMS-2023166, CCF-2019844, DMS-
2134012, NIH, IARPA 2022-22072200003, U. S. Office of Naval Research under award number
N00014-22-1-2348. Part of this work was done while R. Mehta and Z. Harchaoui were visiting the
Simons Institute for the Theory of Computing.
Broader Impact Distributionally robust optimization (DRO) within machine learning is heavily
motivated by problems in artificial intelligence (AI) safety, such as mitigating catastrophic perfor-
mance of models on minority groups or end-users. While this work is focused on theoretical and
algorithmic aspects of the problem, we intend to increase accessibility and scalability for down-
stream applications as well.
References
U. Akujuobi and X. Zhang. Delve: A Dataset-Driven Scholarly Search and Analysis System.
SIGKDD Explor. Newsl. , 19, 2017.
A. Alacaoglu and Y . Malitsky. Stochastic variance reduction for variational inequality methods. In
Conference on Learning Theory , pages 778–816. PMLR, 2022.
A. Alacaoglu, V . Cevher, and S. J. Wright. On the complexity of a practical primal-dual coordinate
method. arXiv preprint arXiv:2201.07684 , 2022.
S. Baressi Segota, N. Andelic, J. Kudlacek, and R. Cep. Artificial Neural Network for Predict-
ing Values of Residuary Resistance per Unit Weight of Displacement. Journal of Maritime &
Transportation Science , 57, 2020.
J. Blanchet, Y . Kang, and K. Murthy. Robust Wasserstein Profile Inference and Applications to
Machine Learning. Journal of Applied Probability , 56, 2019.
D. Blatt, A. O. Hero, and H. Gauchman. A Convergent Incremental Gradient Method with a Con-
stant Step Size. SIAM Journal on Optimization , 2007.
X. Cai, C. Song, S. Wright, and J. Diakonikolas. Cyclic Block Coordinate Descent With Variance
Reduction for Composite Nonconvex Optimization. In ICML , 2023.
X. Cai, A. Alacaoglu, and J. Diakonikolas. Variance reduced Halpern iteration for finite-sum mono-
tone inclusions. In ICLR , 2024.
Y . Carmon and D. Hausler. Distributionally Robust Optimization via Ball Oracle Acceleration. In
NeurIPS , 2022.
A. Chambolle, M. J. Ehrhardt, P. Richt ´arik, and C.-B. Schonlieb. Stochastic Primal-Dual Hybrid
Gradient Algorithm with Arbitrary Sampling and Imaging Applications. SIAM Journal on Opti-
mization , 28(4):2783–2808, 2018.
L. Condat. Fast projection onto the simplex and the ℓ1-ball. Mathematical Programming , 2016.
A. Defazio, F. Bach, and S. Lacoste-Julien. SAGA: A Fast Incremental Gradient Method With
Support for Non-Strongly Convex Composite Objectives. NeurIPS , 27, 2014.
J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova. BERT: Pre-training of deep bidirectional trans-
formers for language understanding. In Proceedings of the 2019 Conference of the North Amer-
ican Chapter of the Association for Computational Linguistics: Human Language Technologies ,
2019.
F. Ding, M. Hardt, J. Miller, and L. Schmidt. Retiring Adult: New Datasets for Fair Machine
Learning. In NeurIPS , volume 34. Curran Associates, Inc., 2021.
S. S. Du, G. Gidel, M. I. Jordan, and C. J. Li. Optimal Extragradient-Based Bilinearly-Coupled
Saddle-Point Optimization, 2022.
N. He, Z. Harchaoui, Y . Wang, and L. Song. Point Process Estimation with Mirror Prox Algorithms.
Applied Mathematics & Optimization , 2020.
10P. J. Huber. Robust statistics . Wiley New York, 1981.
R. Johnson and T. Zhang. Accelerating Stochastic Gradient Descent using Predictive Variance Re-
duction. In NeurIPS , volume 26, 2013.
N. Kallus, X. Mao, K. Wang, and Z. Zhou. Doubly Robust Distributionally Robust Off-Policy
Evaluation and Learning. In ICML , 2022.
D. Kovalev, A. Gasnikov, and P. Richt ´arik. Accelerated Primal-Dual Gradient Method for Smooth
and Convex-Concave Saddle-Point Problems with Bilinear Coupling. In NeurIPS , 2022.
D. Kuhn, P. M. Esfahani, V . A. Nguyen, and S. Shafieezadeh-Abadeh. Wasserstein Distributionally
Robust optimization: Theory and Applications in Machine Learning. Operations research &
management science in the age of analytics , 2019.
R. Kumar, K. A. Majmundar, D. M. Nagaraj, and A. Suggala. Stochastic Re-weighted Gradient
Descent via Distributionally Robust Optimization. TMLR , 2024.
D. Levy, Y . Carmon, J. Duchi, and A. Sidford. Large-Scale Methods for Distributionally Robust
Optimization. In NeurIPS , 2020.
C. J. Li, A. Yuan, G. Gidel, Q. Gu, and M. I. Jordan. Nesterov meets optimism: rate-optimal
separable minimax optimization. In ICML , 2023.
T. Lin, C. Jin, and M. I. Jordan. Near-Optimal Algorithms for Minimax Optimization. In COLT ,
2020.
E. Z. Liu, B. Haghgoo, A. S. Chen, A. Raghunathan, P. W. Koh, S. Sagawa, P. Liang, and C. Finn.
Just Train Twice: Improving Group Robustness without Training Group Information. In ICML ,
2021.
Z. Liu, Q. Bai, J. Blanchet, P. Dong, W. Xu, Z. Zhou, and Z. Zhou. Distributionally Robust Q-
Learning. In ICML , 2022.
K. Lotidis, N. Bambos, J. Blanchet, and J. Li. Wasserstein Distributionally Robust Linear-Quadratic
Estimation under Martingale Constraints. In AISTATS , 2023.
R. Mehta, V . Roulet, K. Pillutla, L. Liu, and Z. Harchaoui. Stochastic Optimization for Spectral
Risk Measures. In AISTATS , 2023.
R. Mehta, V . Roulet, K. Pillutla, and Z. Harchaoui. Distributionally Robust Optimization with Bias
and Variance Reduction. In ICLR , 2024.
H. Namkoong and J. C. Duchi. Stochastic Gradient Methods for Distributionally Robust Optimiza-
tion with f-divergences. In NeurIPS , 2016.
H. Namkoong and J. C. Duchi. Variance-based Regularization with Convex Objectives. In NeurIPS ,
2017.
J. Nocedal and S. J. Wright. Numerical Optimization . Springer, 1999.
B. Palaniappan and F. Bach. Stochastic Variance Reduction Methods for Saddle-Point Problems.
NeurIPS , 29, 2016.
R. T. Rockafellar and J. O. Royset. Superquantiles and Their Applications to Risk, Random Vari-
ables, and Regression. In Theory Driven by Influential Applications . Informs, 2013.
H. Sapkota, D. Wang, Z. Tao, and Q. Yu. Distributionally Robust Ensemble of Lottery Tickets
Towards Calibrated Sparse Network Training. In NeurIPS , 2023.
E. Saravia, H.-C. T. Liu, Y .-H. Huang, J. Wu, and Y .-S. Chen. CARER: Contextualized Affect
Representations for Emotion Recognition. In EMNLP , 2018.
V . D. Sharma, M. Toubeh, L. Zhou, and P. Tokekar. Risk-Aware Planning and Assignment for
Ground Vehicles using Uncertain Perception from Aerial Vehicles. In 2020 IEEE/RSJ IROS ,
2020.
11C. Song, S. J. Wright, and J. Diakonikolas. Variance reduction via primal-dual accelerated dual
averaging for nonsmooth convex finite-sums. In ICML , 2021.
C. Song, C. Y . Lin, S. Wright, and J. Diakonikolas. Coordinate Linear Variance Reduction for
Generalized Linear Programming. In NeurIPS , 2022.
A. Tsanas and A. Xifara. Accurate Quantitative Estimation of Energy Performance of Residential
Buildings Using Statistical Machine Learning Tools. Energy and Buildings , 49, 2012.
P. T¨ufekci. Prediction of Full Load Electrical Power Output of a Base Load Operated Combined
Cycle Power Plant using Machine Learning Methods. International Journal of Electrical Power
& Energy Systems , 60, 2014.
S. Wang, N. Si, J. Blanchet, and Z. Zhou. A Finite Sample Complexity Bound for Distributionally
Robust Q-learning. In AISTATS , 2023a.
Z. Wang, L. Shen, T. Liu, T. Duan, Y . Zhu, D. Zhan, D. Doermann, and M. Gao. Defending against
Data-Free Model Extraction by Distributionally Robust Defensive Training. In NeurIPS , 2023b.
O. Wiles, S. Gowal, F. Stimberg, S.-A. Rebuffi, I. Ktena, K. D. Dvijotham, and A. T. Cemgil. A
fine-grained analysis on distribution shift. In ICLR , 2022.
G. Xie, L. Luo, Y . Lian, and Z. Zhang. Lower Complexity Bounds for Finite-Sum Convex-Concave
Minimax Optimization Problems. In ICML , 2020.
J. Yang, S. Zhang, N. Kiyavash, and N. He. A Catalyst Framework for Minimax Optimization. In
NeurIPS , 2020.
Z. Yang, Y . Guo, P. Xu, A. Liu, and A. Anandkumar. Distributionally Robust Policy Gradient for
Offline Contextual Bandits. In AISTATS , 2023.
I. Yeh. Analysis of Strength of Concrete Using Design of Experiments and Neural Networks. Jour-
nal of Materials in Civil Engineering , 18, 2006.
Y . Yu, T. Lin, E. V . Mazumdar, and M. Jordan. Fast Distributionally Robust Learning with Variance-
Reduced Min-Max Optimization. In AISTATS , 2022.
Z. Yu, L. Dai, S. Xu, S. Gao, and C. P. Ho. Fast Bellman Updates for Wasserstein Distributionally
Robust MDPs. In NeurIPS , 2023.
J. Zhang, M. Hong, and S. Zhang. On lower iteration complexity bounds for the convex concave
saddle point problems. Mathematical Programming , 194, 2022.
12Appendix
Appx. A contains all notation introduced throughout the paper. Appx. B discusses convergence rate
comparisons in detail with contemporary work. The full convergence analysis of DRAGO is given
in Appx. C. A description of the algorithm amenable to implementation is given in Appx. D,
whereas experimental settings are described in detail within Appx. E.
Table of Contents
A Notation 14
B Comparisons to Existing Literature 15
B.1 Directly Using Gradient Descent . . . . . . . . . . . . . . . . . . . . . . . . . 15
B.2 Distributionally Robust Optimization (DRO) . . . . . . . . . . . . . . . . . . . 15
B.3 Primal-Dual Saddle Point Algorithms . . . . . . . . . . . . . . . . . . . . . . . 17
C Convergence Analysis of DRAGO 21
C.1 Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21
C.2 Technical Lemmas . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23
C.3 Proof of Main Result . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29
C.4 Modification for Unregularized Objectives . . . . . . . . . . . . . . . . . . . . 40
D Implementation Details 44
D.1 Algorithm Description . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44
D.2 Solving the Maximization Problem . . . . . . . . . . . . . . . . . . . . . . . . 44
E Experimental Details 48
E.1 Datasets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48
E.2 Hyperparameter Selection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48
E.3 Compute Environment . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49
E.4 Additional Experiments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49
F NeurIPS Paper Checklist 51
13A Notation
Symbol Description
n Sample size, or number of loss functions.
d Dimensionality of primal variables.
W ⊆RdPrimal feasible set, which is closed and convex.
Q ∈∆nUncertainty set, or dual feasible set, which is closed and convex.
Here, ∆n={p∈[0,1]n:Pn
i=1pi= 1}.
q0 The uniform vector q0=1/n= (1/n, . . . , 1/n). Used as a dual initialization.
D(q∥q0)A statistical divergence between q∈ Q andq0, which is
1-strongly convex in its first argument with respect to ∥·∥2.
ℓLoss function ℓ:W → Rn, which is differentiable
in each component on an open set O ⊆Rdsuch that W ⊆ O .
µ≥0 Primal regularization constant.
ν≥0 Dual regularization constant.
L(w, q) Objective function L(w, q) :=q⊤ℓ(w)−νD(q∥q0) +µ
2∥w∥2
2.
(w⋆, q⋆)Saddle point of L, which satisfies
L(w⋆, q)≤ L(w⋆, q⋆)≤ L(w, q⋆)for all (w, q)∈ W × Q .
[n] Index set [n] ={1, . . . , n }.
qmax The value max q∈Q∥q∥∞.
κQ The condition number κQ=nqmax≥1.
GLipschitz continuity constant of each ℓifori∈[n],
for which |ℓi(w)−ℓi(w′)| ≤G∥w−w′∥2.
LLipschitz continuity constant of each ∇ℓifori∈[n],
for which ∥∇ℓi(w)− ∇ℓi(w′)∥2≤L∥w−w′∥2.
∇ℓ(w) Jacobian matrix of ℓ:Rd→Rnatw(shape = n×d).
(at) Sequence of positive constants that weigh the average gap criterion.
(At)Sequence of partial sums of (at), orAt=Pt
s=1as. The convergence
rate will be given by A−1
t, so we have atincrease geometrically.
b Batch or block size.
M Number of blocks n/b.
(wt, qt)t≥0 Sequence of primal and dual iterates.
ej Thej-th standard basis vector ej∈ {0,1}n.
ˆℓt Loss table, which approximates ℓ(wt)∈Rn.
ˆgt Gradient table, which approximates ∇ℓ(wt)∈Rn×d.
ˆqt Weight table, which approximates qt∈ Q.
Et[·] Shorthand for E[·|Ht−1], i.e., expectation conditioned on history Ht−1=σ 
(Is, Js)}t−1
s=1
.
Table 2: Notation used throughout the paper.
14B Comparisons to Existing Literature
In this appendix, we compare our work to existing literature along two axes: 1) distributional robust
optimization (DRO), and 2) primal-dual algorithms for saddle-point problems. In the first cate-
gory, we are primarily concerned with questions of practical and statistical interest, such as which
uncertainty sets can be used, how the size of the uncertainty set affects the convergence rate, and
what assumptions are needed on the distribution of losses. In the second category, we discuss com-
putational complexity under various assumptions such as smoothness and strong convexity of the
objective.
B.1 Directly Using Gradient Descent
In the penalized case, we add that the objective w7→max q∈QL(w, q)is(L+µ+nG2
ν)-smooth
when the losses ℓiareG-Lipschitz continuous and L-smooth. For this reason, we may consider
simply applying full-batch gradient descent to this objective, which is included in our comparisons.
To see why this smoothness condition holds, define h(l) := max q∈Q
q⊤l−νD(q∥1/n)	
, so that
when q7→D(q∥1/n)is1-strongly convex with respect to ∥·∥2
2, it holds that ∇his(1/ν)-Lipschitz
continuous with respect to ∥·∥2
2, and that ∇h(l)is non-negative and sums to one (i.e. is a probability
mass function on [n]). Then, by the chain rule, for any w1, w2∈W, we have that
∇ℓ(w1)⊤∇h(ℓ(w1))− ∇ℓ(w2)⊤∇h(ℓ(w2))
2
≤∇ℓ(w1)⊤(∇h(ℓ(w1))− ∇h(ℓ(w2)))
2+(∇ℓ(w1)− ∇ℓ(w2))⊤∇h(ℓ(w2))
2]
≤nG
ν∥ℓ(w1)−ℓ(w2)∥2+L∥w1−w2∥2
≤nG2
ν+L
∥w1−w2∥2.
Thus, when referring to the gradient descent on w7→max q∈QL(w, q) =h(ℓ(w)) +µ
2∥w∥2
2, we
reference the smoothness constant
L+µ+nG2
ν
.
B.2 Distributionally Robust Optimization (DRO)
Examples of DRO Problems Our problem
min
w∈Wmax
q∈Qh
L(w, q) :=q⊤ℓ(w)−νD(q∥1/n) +µ
2∥w∥2
2i
(16)
accommodates several settings of interest across machine learning. For example, f-DRO with pa-
rameter ρ[Namkoong and Duchi, 2016, Carmon and Hausler, 2022] results by defining the uncer-
tainty set and penalty as
Q=Q(ρ) :=n
q:Df(q∥1/n)≤ρ
no
andD(q∥1/n) =Df(q∥1/n),
where Df(q∥p) =Pn
i=1pif(qi/pi)denotes an f-divergence generated by f(which is always
well-defined when pi=1/n). Common examples include the Kullback-Leibler (KL) divergence,
generated by fKL(x) =−xlogxand the χ2-divergence generated by fχ2(x) = ( x−1)2. Spectral
risk measures [Mehta et al., 2023] are parametrized by an n-length vector σ= (σ1, . . . , σ n)such
that0≤σ1≤. . .≤σnandPn
i=1σi= 1. The penalty in that setting may also be in the form of an
f-divergence [Mehta et al., 2024], so that
Q=Q(σ) := conv ( {permutations of σ)})andD(q∥1/n) =Df(q∥1/n),
where conv (·)denotes the convex hull. The most notable example of such an uncertainty set is the
θ-conditional value-at-risk, or CVaR [Rockafellar and Royset, 2013], wherein the largest θnvalues
ofσare set to 1/(nθ)and the remaining are set to zero (with a fractional component if θnis not an
integer). Finally, Wasserstein-DRO [Kuhn et al., 2019, Blanchet et al., 2019, Yu et al., 2022] with
parameter δtypically sets the uncertainty set to be a δ-ball{Q:Wc(Q, P n)≤δ}in Wasserstein
distance, where Qis a probability measure, Pnis the empirical measure of the training data, and
15Wcis the Wasserstein distance associated to cost function c. This differs from f-DRO and spectral
risk minimization because in the latter settings, the “shifted” distribution Qis assumed to remain on
the same natoms as before, so that it may simply be specified by a probability vector q∈[0,1]n
(resp. Pnby1/n). However, as shown by Yu et al. [2022], Wasserstein-DRO can be reformulated
into a problem of the form (16) if the following conditions are satisfied: 1) the loss is of a generalized
linear model ℓi(w) = Ψ( ⟨w, xi⟩, yi)with feature-label pair (xi, yi)and discrepancy function Ψ, 2)
the cost function c((x, y),(x′, y′))is of the form ∥x−x′∥2+β|y−y′|forβ > 0, and 3) the
function Ψis Lipschitz continuous with known constant.
Comparison of DRO Approaches The performance of classical and recent algorithms designed
for the problems above is detailed in Tab. 3. The rightmost column displays the oracle complexity ,
meaning the number of queries to individual/component loss functions {(ℓi,∇ℓi)}as a function of
the desired suboptimality ε. The desiderata in the large-scale setting is to decouple the contribution
of the sample size nand the condition number in smooth, strongly convex settings ( µ > 0and
L <∞) or the quantity 1/εin non-smooth or non-strongly convex settings. For readability, we
encode dependence on nin red and dependence on 1/εin blue within Tab. 3. In certain cases, such
as in the sub-gradient method, the dependence on nis understood as part of a smoothness constant.
Similarly, because qmax is of order 1/nin the best case and 1in the worst case, we interpret κQto
play the role of a condition number that measures the size of the uncertainty set. That being said, κQ
is upper bounded by a constant independent of nin common cases. We collect examples of these
results below.
Proposition 3. In(16) ifQis chosen to be the CVaR uncertainty set with tail probability θ, then
κQ≤1
θ. IfQis chosen to be the χ2-DRO uncertainty set with radius ρ, then κQ≤√1 +ρ.
Proof. For the θ-CV AR, we have that qi∈[0,1/(nθ)]for all i∈[n]. Thus,
nqi≤1
θfor all i= 1, . . . , n.
For the χ2-DRO uncertainty set, we have by direct computation that
n∥q−1/n∥2
2≤ρ
n⇐⇒ ∥ q∥2
2≤1 +ρ
n2.
This implies that for any i∈[n], we have that q2
i≤(1 +ρ)/n2which implies that
nqi≤p
1 +ρ,
the result as desired.
The closest comparison to our setting is that of LSVRG [Mehta et al., 2023] and Prospect [Mehta
et al., 2024]. Including DRAGO , these methods all achieve linear convergence on (16), under the
assumption of strongly convex regularization in the primal objective. However, both LSVRG and
Prospect demand a stringent lower bound of Ω(nG2/µ)on the dual regularization parameter νto
achieve this rate, which essentially matches ours in this regime (asp
nG2/(µν)reduces to a con-
stant). When this condition does not hold, however, LSVRG does not have a convergence guarantee
while Prospect underperforms against the sub-gradient method. Furthermore, while Propsect has a
single hyperparameter, LSVRG must search over both a learning rate and an epoch length. DRAGO ,
on the other hand, is the only method that achieves unconditional linear convergence and fully cap-
tures the dependence on the dual regularization parameter ν, which is a smoothness measure of the
objective max qL(·, q).
Moving to methods that are not linearly convergent, Levy et al. [2020] consider a variant of mini-
batch SGD that solves the maximization problem within the mini-batch itself. In Tab. 3, we include
a term min{n, b(ε)}, where b(ε)denotes a required batch size. This is because Levy et al. [2020]
measures complexities in terms of calls to first-order oracles for a loss summed across an arbitrary
batch size. Thus, our comparison relies on multiplying the required batch size with the number of
iterations required for a desired suboptimality (see Levy et al. [2020, Theorem 2], for example).
In the setting in which there is a fixed training set of size n, we incorporate this requirement on
the batch size in the complexity bound, to account for the case in which the theoretically required
batch size grows so large that it exceeds the full batch size itself. Indeed, as commented by Carmon
16and Hausler [2022], when the uncertainty set is large (i.e. θis small for CVaR and ρis large for
χ2-divergence), the method may underperform against the sub-gradient method. This is true of
methods such as in Mehta et al. [2024] and ours that depend on κQ≤n. This indicates that across
DRO settings, increased uncertainty set sizes can bring the performance of incremental methods
arbitrarily close to that of the full-batch sub-gradient method. Finally, notice that DRAGO also has a
dependence on the batch size bin Tab. 3. While it would appear that b= 1would minimize oracle
complexity, we describe in the next section how bcan be chosen to minimize global complexity,
which includes the cost of each oracle call as a function of the primal dimension d. Because of
the diversity of settings, a coarser measure such as first-order oracle evaluations may be sufficient
to compare methods along the DRO axis; we use the finer-grained global complexity to compare
methods along the axis of saddle-point algorithms.
B.3 Primal-Dual Saddle Point Algorithms
For context, both (1) and (2) are coupled min-max problems with primal-dual variables (w, q). Ob-
serve that the coupled term in the objective (depending on both wandq) is not bilinear in general.
Such objectives have received much less attention in the optimization literature on primal-dual meth-
ods than their bilinearly-coupled counterparts. For the bilinear setting, methods such as stochastic
Chambolle-Pock-style algorithms [He et al., 2020, Song et al., 2021] use stochastic variance-reduced
updates, and in particular, employ coordinate-style updates of a single dual variable per iteration.
To illustrate the advantage of these updates, notice that the primal and dual dimensions are dandn,
respectively. When nis significantly larger than d, and assuming that each (ℓi,∇ℓi)call comes at
anO(d)cost, updating the dual variables at O(n)cost every iteration becomes the primary compu-
tational bottleneck. Coordinate-style updates can eliminate this dependence, but apply only when
the dual feasible set Qdecomposes as Q1×. . .× Q n, i.e., is separable .
There is a long line of work on variance-reduced algorithms for general stochastic optimization
problems [Johnson and Zhang, 2013, Defazio et al., 2014, Palaniappan and Bach, 2016, Cai et al.,
2023] and structured and/or bilinearly coupled min-max problems [Yang et al., 2020, Song et al.,
2021, Du et al., 2022, Kovalev et al., 2022, Alacaoglu et al., 2022]. However, few of these results
directly apply to (2) due to non-bilinearity and non-separability of the dual feasible set. These issues
motivated work on reformulating common DRO problems as bilinearly coupled min-max problems
in Song et al. [2022]. However, the guarantees obtained in Song et al. [2022] are of the order O(ε−1).
Another viewpoint is that (2) can be written as a monotone variational inequality (VI) problem for
the operator F(w, q) = (∇wℓ(w)⊤q+µw,−ℓ(w) +ν∇qD(q∥1/n))∈Rd+n, where we assumed
1-smoothness of Dfor ease of presentation. Under our assumptions, this operator is min{µ, ν}-
strongly monotone and max
nG2, L	
-Lipschitz continuous, and VI algorithms such as mirror-
prox, Popov’s method, and variance-reduced methods like Alacaoglu and Malitsky [2022], Cai et al.
[2024] can be used. However, the max-over-min dependence on the individual Lipschitz constants
and strong convexity constants is unfavorable compared to the individual condition numbers ob-
served in (4). If Fis called directly, the global complexity will be n2because qisn-dimensional
along with nin the condition number. A finite sum approach could improve dependence on the
number of oracle calls, but the global complexity would still be n2due to the non-separability of the
dual feasible set and again the n-dimensional dual variables.
To summarize the points above and in order to make comparisons among methods for general min-
max problems, we first collect aspects of (16) that make it a highly specialized problem in this
regard. The major points include:
1. The objective has a finite-sum structure, in that it can be written asPn
i=1fi(w, q), where
fi(w, q) :=qiℓi(w)−νD(q∥1/n) +µ
2∥w∥2
2.
2. The dimension of the dual variable qis equal to n, the number of functions in the sum
(i.e. the sample size), and could be much larger than d.
3. The dual regularizer q7→D(q∥1/n)is not necessarily smooth. This encompasses common
statistical divergences such as the Kullback Leibler (KL).
4. The dual feasible set Qis non-separable, as any feasible dual iterate must sum to 1.
For discussions in which linear convergence is a pre-requisite, it is typically assumed that (w, q)7→
L(w, q)is a smooth map, and finer-grained results depend on the individual Lipschitz continuity
17parameters of w7→ ∇ wL(w, q),q7→ ∇ qL(w, q),w7→ ∇ qL(w, q), and q7→ ∇ wL(w, q). To make
the regularized DRO setting of (16) comparable to classical and contemporary saddle-point methods,
we make the additional assumption in this section that the (rescaled) χ2-divergence penalty is used,
so that D(q∥1/n) =1
2∥q−1/n∥2
2and we may compute the smoothness constants as
∥∇wL(w, q)− ∇ wL(w′, q)∥2≤(L+µ)∥w−w′∥2
∥∇wL(w, q)− ∇ wL(w, q′)∥2=∇ℓ(w)⊤(q−q′)
2≤√nG∥q−q′∥2
∥∇qL(w, q)− ∇ qL(w, q′)∥2≤ν∥q−q′∥2(17)
∥∇qL(w, q)− ∇ qL(w′, q)∥2=∥ℓ(w)−ℓ(w′)∥2≤√nG∥w−w′∥2(18)
∇(w,q)L(w, q)− ∇ (w,q)L(w′, q′)
2≤((L+µ)∨ν+√nG)√
2∥(w, q)−(w′, q′)∥2.(19)
In making this assumption, however, we emphasize that our results do not depend on (17),(18),
and(19) being true . We assume here that calls to the oracles (ℓi,∇wℓi)costO(d)operations while
calls to ∇qLcostO(n)operations, making the total O(n+d). This per-iteration complexity is a
subtlety of DRO which is essential to recognize when comparing methods. With DRAGO , we also
have a batch size parameter b, setting the complexity to O(n+bd). By tuning b, we may achieve
improvements in terms of global complexity over standard primal-dual methods. Results comparing
linearly convergent methods in terms of the global complexity of elementary operations are given
in Tab. 4. The table contains a “half-life” column, which is the constant τmultiplied with log(1/ε)
when describing the number of iterations needed to reach ε-suboptimality as τlog(1/ε). Before
comparisons, observe that the optimal batch size for DRAGO isb=n/d, in the sense that the global
number of arithmetic operations is of order
nLκQ
µ+nds
nG2
µν
This is an improvement over setting b= 1, in which case the same number is
(n+d)LκQ
µ+n(n+d)s
nG2
µν
Next, the most comparable and recent setting is that of Li et al. [2023]. Notice that DRAGO is able
to improve by a factor of don theL
µterm, as long as κQ=O(1).
While less comparable, we mention known lower bounds for completeness. In terms of lower
bounds, since (16) enjoys a particular structure, such as decomposability into so-called marginal
terms νD(q∥1/n)andµ
2∥w∥2
2and a coupled termq⊤ℓ(w), we are not necessarily constrained by
the more general lower bounds of Zhang et al. [2022] and Xie et al. [2020]. For example, the prox-
imal incremental first-order (PIFO) model of Xie et al. [2020] assumes that we observe first-order
information from a single component in the sum; in DRAGO , using a batch size of n/d is required
to achieve the desired improvement. Zhang et al. [2022], on the other hand, do not treat the finite
sum class of problems considered here. Furthermore, we still list the per-iteration cost as O(n+d)
because a single PIFO call to the dual gradient is of size n.
18Method Assumptions Uncertainty Set Runtime / Global Complexity (Big- ˜O)
Sub-Gradient MethodℓiisG-Lipschitz
∥w−w′∥2≤R(if included)
µ >0(if included)
∇ℓiisL-Lipschitz and ν >0(if included)Support Constrained
Support Constrained
Support Constrainednd·(GR)2ε−2
nd·G2µ−1ε−1
nd·µ−1 
L+µ+nG2/ν
log(1/ε)
LCVaR-SGD†
Lχ2-SGD†
Lχ2−pen-SGD†
[Levy et al., 2020]ℓiisG-Lipschitz and in [0, B]
∥w−w′∥2≤Rfor all w, w′∈W
ν >0(if included)θ-CVaR
ρ-ball in χ2-divergence
χ2-divergence penaltymin
n, B2θ−1ε−2	
d·(GR)2ε−2
min
n,(1 +ρ)B2ε−2	
d·(GR)2ε−2
min
n, B2ν−1ε−1	
d·(GR)2ε−2
BROO∗
BROO∗
[Carmon and Hausler, 2022]ℓiisG-Lipschitz
∥w−w′∥2≤Rfor all w, w′∈W
∇ℓiisL-Lipschitz (if included)1-ball in f-divergence
1-ball in f-divergencend·(GR)2/3ε−2/3+d(GR)2ε−2
nd·(GR)2/3ε−2/3+n3/4d 
GRε−1+L1/2Rε−1/2
LSVRG
LSVRG
[Mehta et al., 2023]ℓiisG-Lipschitz
∇ℓiisL-Lipschitz
µ >0,ν >0,κ:= (L+µ)/µSpectral Risk Measures ( νsmall)
Spectral Risk Measures ( ν≥Ω(nG2/µ))None
(n+κQκ)dlog(1/ε)
Prospect
Prospect
[Mehta et al., 2024]ℓiisG-Lipschitz
∇ℓiisL-Lipschitz
µ >0,ν >0,κ:= (L+µ)/µ, δ =G2/(µν)Spectral Risk Measures ( νsmall)
Spectral Risk Measures ( ν≥Ω(nG2/µ))n(n+d) max
nδ+κnqmax, n3δ2κ2, n3δ3	
log(1/ε)
(n+κQκ) (n+d)log(1 /ε)
DRAGO (Ours)ℓiisG-Lipschitz
∇ℓiisL-Lipschitz
µ >0,ν >0,b:=Batch SizeSupport Constrained n
d+κQL/µ+dp
nG2/(µν)
log(1/ε)
Table 3: Replicate of Tab. 1.
19Method Assumptions Half-Life Per-Iteration Cost
Sub-Gradient MethodL+µ
µ+nG2
µνnd
Minimax-APPA
[Lin et al., 2020](L+µ)∨ν+√nG√µνnd
Lower Bound
[Xie et al., 2020]Finite Sum
Single component oracle
May not be decomposablen+(L+µ)∨ν+√nG
min{µ,ν}n+d
Lower Bound
[Zhang et al., 2022]May not be decomposable
May not be finite sumq
L+µ
µ+nG2
µνnd
AG-OG with Restarts
[Li et al., 2023]L
µ∨q
nG2
µνnd
Drago ( b= 1)
Drago ( b=n/d)
Drago ( b=n)D(·∥1/n)need
not be smoothLκQ
µ+nq
nG2
µν
LκQ
µ+dq
nG2
µν
LκQ
µ+q
nG2
µνn+d
n
nd
Table 4: Complexity of Primal-Dual Saddle Point Methods. Half-life (defined as τsuch that a
linearly convergent method requires O(τlog(1/ε)) iterations to achieve ε-suboptimality) and per-
iteration cost of linearly convergent optimization algorithms. The global number of arithmetic oper-
ations (under the assumption that (ℓi,∇wℓi)costs O(d)operations and ∇qLcosts O(n)operations)
required to achieve a point (w, q)satisfying L(w, q⋆)− L(w⋆, q)≤εcan be computed by multi-
plying the last two columns. The “Assumptions” column contains changes to the assumptions that
eachℓiisL-smooth and that D(·∥1/n)isν-smooth.
20C Convergence Analysis of DRAGO
This section provides the convergence analysis for DRAGO . We first recall the quantities of interest
and provide an alternate description of the algorithm that is useful for understanding the analysis.
A high-level overview is given in Appx. C.1, and the remaining subsections comprise steps of the
proof.
C.1 Overview
See Tab. 2 for a reference on notation used throughout the proof, which will also be introduced as it
appears. Define q0=1/nand recall the objective
L(w, q) :=q⊤ℓ(w)−νD(q∥q0) +µ
2∥w∥2
2. (20)
By strong convexity of w7→max qL(w, q)with respect to ∥·∥2and strong concavity of q7→
minwL(w, q)with respect to ∥·∥2, a primal-dual solution pair (w⋆, q⋆)is guaranteed to exist and is
unique, and thus we define
w⋆= arg min
w∈Wmax
q∈QL(w, q)andq⋆= arg max
q∈Qmin
w∈WL(w, q).
In other words, we have that max q∈QL(w⋆, q) =L(w⋆, q⋆) = min w∈WL(w, q⋆). We proceed to
describe the algorithm, the optimality criterion, and the proof outline.
Algorithm Description First, we describe two sequences of parameters that are used to weigh
various terms in the primal and dual updates. The parameters are set in the analysis, and the version
of the algorithm in Appx. D is a description with these values plugged in. However, we keep them
as variables in this section to better describe the logic of the proof.
Specifically, let (at)t≥1be a sequence of positive numbers and define a0= 0 in addition. Denote
At=PT
s=1as. These will become the averaging sequence that will aggregate successive gaps
γt(see (27)) into the return valuePT
t=1atγt, which will be upper bounded by a constant in T(in
expectation). We also define another similar sequence (ct)t≥1, and define Ct=At−(n/b−1)ctfor
batch size b. We assume for simplicity that bdivides n. When all constants are set, the algorithm will
reduce to that given in Algorithm 1. We have one hyperparameter α >0, which may be interpreted
as a learning rate.
Using initial values w0= 0andq0=1/n, initialize the tables ˆℓ0=ℓ(w0)∈Rn,ˆg0=∇ℓ(w0)∈
Rn×d, and ˆq0=q0∈Rn. In addition, partition the [n]sample indices into M:=n/bblocks of
sizeb, orB1, . . . , B MwithBK:= ((K−1)b+ 1, . . . , Kb )forK∈[M]. We can set the averaging
sequence according to the following scheme:
a1= 1, a2= 4α,andat= (1 + α)at−1fort >2.
The initial value a2= 4αis a slight modification for theoretical convenience, and the algorithm
operates exactly as in Appx. D in practice. In order to retrieve the Appx. D version, we simply
replace the condition above with at= (1 + α)at−1fort≥2.
Consider iterate t∈ {1, . . . , T }. We sample a random block Ituniformly from [M]and compute
the primal update.
δP
t:=1
bX
i∈BIt(qt−1,i∇ℓi(wt−1)−ˆqt−2,iˆgt−2,i) (21)
vP
t:= ˆg⊤
t−1ˆqt−1+nat−1
atδP
t (22)
wt:= arg min
w∈Wat
vP
t, w
+atµ
2∥w∥2
2+Ct−1µ
2∥w−wt−1∥2
2+ct−1µ
2t−2X
s=t−n/b∥w−ws∨0∥2
2
(23)
21We see that Ct−1+ct−1(n/b−1) = At−1, so the inner objective of the update (23) is Atµ-
strongly convex (as the one in (26) is Atν-strongly concave). Note that when n/b < 1, we simply
treat the method as not including the additional regularization termct−1µ
2Pt−2
s=t−n/b∥w−ws∨0∥2
2.
Proceeding, we then modify the loss and gradient table. The loss update has to occur between the
primal and dual updates to achieve control over the variation in the dual update (see Appx. C.2).
Define Kt=tmod M+ 1as the (deterministic) block to be updated, and set
(ˆℓt,k,ˆgt,k) =(
(ℓk(wt),∇ℓk(wt)) ifk∈BKt
(ˆℓt−1,k,ˆgt−1,k) otherwise.
Define ejto be the j-th standard basis vector. Then, sample a random block Jtuniformly from [M]
compute
δD
t:=1
bX
j∈BJt(ℓj(wt)−ˆℓt−1,j)ej (24)
vD
t:=ˆℓt+nat−1
atδD
t (25)
qt:= arg max
q∈Qat
vD
t, q
−atνD(q∥q0)−At−1ν∆D(q, qt−1). (26)
Notice the change in indices between (21) and (25), which accounts for the update in the loss table
that occurs in between. Finally, we must update the remaining table. Set
ˆqt,k=qt,k ifk∈BKt
ˆqt−1,k otherwise.
We define the random variable Ht:={(Is, Js)}t
s=1as the history of blocks selected at all times up
to and including t, and define Et[·]to be the conditional expectation operator given Ht−1. In other
words, Etintegrates the randomness {(Is, Js)}T
s=t. Accordingly E1[·]is the marginal expectation
of the entire random process. We may now describe the optimality criterion.
Proof Outline Construct the gap function
γt=at
L(wt, q⋆)− L(w⋆, qt)−µ
2∥wt−w⋆∥2
2−ν
2∥qt−q⋆∥2
2
(27)
and aim to bound E1hPt
s=1γsi
by a constant. Throughout the proof, we will use a free parameter
α, with update rule
at≤min 
1 +α
4
at−1, αA t−1,4α(n/b−1)2Ct−1	
. (28)
Because we will search for αdown to an absolute constant, we will often swap 
1 +α
4
for(1 +α)
for readability. We assume the right-hand side of (28) holds in Step 1 andStep 2 . We then select α
to satisfy this condition (and all others) in Step 3 below. The proof occurs in five steps total.
1. Lower bound the dual suboptimality atL(w⋆, qt).
2. Upper bound the primal suboptimality atL(wt, q⋆), and combine both to derive a bound on
the gap function for t≥2.
3. Derive all conditions on the learning rate constant αand batch size b.
4. Bound γ1and sum γtovertfor aT-step progress bound.
5. Bound the remaining non-telescoping terms to complete the analysis.
We begin with a section of technical lemmas that will not only be useful in various areas of the
proof but also capture the main insights that allow the method to achieve the given rate. Given these
lemmas, the main proof occurs in Appx. C.3 and otherwise follows standard structure.
22C.2 Technical Lemmas
This section contains a number of lemmas that describe common structures in the analysis of quan-
tities in the primal and dual. Lem. 4 bounds cross terms that arise when there are inner products
between the primal-dual iterates and their gradient estimates. Lem. 5 and Lem. 6 are respectively
the primal and dual noise bounds, constructed to control the variation of the terms δP
tandδD
tap-
pearing in (21). Finally, Lem. 10 exploits the cyclic style updates of the ˆqttable to bound the term
∥ˆqt−1−qt−2∥2
2which is used in the primal noise bound.
Cross Term Bound Both of the estimates of the gradient of the coupled term q⊤ℓ(w)with respect
to the primal and dual variables share a similar structure (see (22) and compare to (29)). They
are designed to achieve a particular form of telescoping, with a remaining squared term that can
be controlled by case-specific techniques. This can be observed within Lem. 4. In the sequel, we
will refer to a sequence of random vectors (ut)t≥1asadapted to Ht, where Ht={(Is, Js)}t
s=1
is the history of random blocks. This simply means that ut, when conditioned on Ht−1, is only a
function of the current random block (It, Jt). Similarly, conditioned on Ht−1, we have that ut−1is
not random. In the language of probability theory, {σ(Ht)}t≥1forms a filtration and utisσ(Ht)-
measurable, but this terminology is not necessary for understanding the results.
Lemma 4 (Cross Term Bound) .Let(xt)t≥1,(yt)t≥1, and (ˆyt)t≥1denote random sequences of Rm-
valued vectors, and let x⋆∈Rmbe a vector. Denote by Itbe the index of a uniform random block
[M].
vt:= ˆyt−1+nat−1
at1
bX
i∈BIt(yt−1,i−ˆyt−2,i) (29)
Finally, let (xt, yt,ˆyt)t≥1adapted to Ht(as defined above). Then, for any positive constant γ >0,
atEt[⟨yt−vt, x⋆−xt⟩]≤atEt[⟨yt−ˆyt−1, x⋆−xt⟩]−at−1⟨yt−1−ˆyt−2, x⋆−xt−1⟩
+n2a2
t−1
2γEt1
bP
i∈BIt(yt−1,i−ˆyt−2,i)2
2+γ
2Et∥xt−xt−1∥2
2.
Proof. By plugging in the value of vtand using x⋆−xt=x⋆−xt−1+xt−1−xt, we have that
atEt[⟨yt−vt, x⋆−xt⟩] =atEt[⟨yt−ˆyt−1, x⋆−xt⟩]−nat−1Et
*
1
bX
i∈BIt(yt−1−ˆyt−2), x⋆−xt+

=atEt[⟨yt−ˆyt−1, x⋆−xt⟩]−at−1⟨yt−1−ˆyt−2, x⋆−xt−1⟩
+nat−1Et
*
1
bX
i∈BIt(yt−1−ˆyt−2), xt−xt−1+

≤atEt[⟨yt−ˆyt−1, x⋆−xt⟩]−at−1⟨yt−1−ˆyt−2, x⋆−xt−1⟩
+n2a2
t−1
2γEt1
bP
i∈BIt(yt−1,i−ˆyt−2,i)2
2+γ
2Et∥xt−xt−1∥2
2,
where the final step follows from Young’s inequality with parameter γ.
In the primal case, we have that vt=vP
t,yt=∇ℓ(wt)⊤qt,ˆyt= ˆg⊤
tˆqt, and xt=wt. In the dual
case, we have that vt=vD
t,yt=ℓ(wt),ˆyt=ˆℓt+1, and xt=qt. The next few lemmas control the
third term appearing in Lem. 4 for the specific case of the primal and dual sequences.
Noise Term Bounds Next, we proceed to control the δP
tandδD
tby way of Lem. 5 and Lem. 6.
As discussed in Sec. 3, a key step in the convergence proof is establishing control over these terms.
Define π(t, i)to satisfy ˆqt,i=qπ(t,i),iandˆgt,i=∇ℓi(wπ(t,i)), that is, the time index of the last
update of table element ion or before time t. This notation is used to write the table values such as
ˆqtin terms of past values of the iterates (e.g., qt).
23Lemma 5 (Primal Noise Bound) .When t≥2, we have that
EtδP
t2
2≤3qmax
nnX
i=1qt−1,i∥∇ℓi(wt−1)− ∇ℓi(w⋆)∥2
2
+3qmax
nnX
i=1qπ(t−2,i),i∇ℓi(wπ(t−2,i))− ∇ℓi(w⋆)2
2
+3G2
n∥qt−1−ˆqt−2∥2
2 (30)
Proof. By definition, we have that
EtδP
t2
2=Et1
bP
i∈BIt∇ℓi(wt−1)qt−1,i−ˆgt−2,iˆqt−2,i2
2
=1
b2EtP
i∈BIt∇ℓi(wt−1)qt−1,i−ˆgt−2,iˆqt−2,i2
2
≤1
bEthP
i∈BIt∥∇ℓi(wt−1)qt−1,i−ˆgt−2,iˆqt−2,i∥2
2i
=1
nnX
i=1∥∇ℓi(wt−1)qt−1,i−ˆgt−2,iˆqt−2,i∥2
2,
where we use that Itis drawn uniformly over n/b. Continuing again with the term above, we have
1
nnX
i=1∥∇ℓi(wt−1)qt−1,i−ˆgt−2,iˆqt−2,i∥2
2
=1
nnX
i=1∥(∇ℓi(wt−1)− ∇ℓi(w⋆))qt−1,i−(ˆgt−2,i− ∇ℓi(w⋆))ˆqt−2,i+ (qt−1,i−ˆqt−2,i)∇ℓi(w⋆)∥2
2
≤3
nnX
i=1
qt−1,i2∥∇ℓi(wt−1)− ∇ℓi(w⋆)∥2
2+ ˆq2
t−2,i∥ˆgt−2,i− ∇ℓi(w⋆)∥2
2
+ (qt−1,i−ˆqt−2,i)2∥∇ℓi(w⋆)∥2
2
≤3
nnX
i=1
qmaxqt−1,i∥∇ℓi(wt−1)− ∇ℓi(w⋆)∥2
2+qmaxˆqt−2,i∥ˆgt−2,i− ∇ℓi(w⋆)∥2
2
+ (qt−1,i−ˆqt−2,i)2G2
.
where we use that ∥∇ℓi(w⋆)∥2
2≤G2because every ℓiisG-Lipschitz with respect to ∥·∥2
2, and that
qi≤qmax= max q∈Q∥q∥∞. This completes the proof.
The corresponding dual noise bound in Lem. 6 follows similarly, using cyclic updates in the loss
table.
Lemma 6 (Dual Noise Bound) .Fort≥2,
EtδD
t2
2≤G2
nt−2X
τ=t−n/b∥wt−1−wτ∨0∥2
2.
24Proof. Then, we may exploit the coordinate structure of the noise term to write
EtδD
t2
2=Et1
bX
j∈BJt(ℓj(wt−1)−ˆℓt−1,j)ej2
2
=1
b2 
EtX
j∈BJt(ℓj(wt−1)−ˆℓt−1,j)ej2
2
+Et
X
j̸=k(ℓj(wt−1)−ˆℓt−1,j)(ℓk(wt−1)−ˆℓt−1,k)⟨ej, ek⟩
!
=1
b2EtX
j∈BJt(ℓj(wt−1)−ˆℓt−1,j)ej2
2
=1
b2EtX
j∈BJt|ℓj(wt−1)−ˆℓt−1,j|2
≤1
bnnX
i=1|ℓi(wt−1)−ˆℓt−1,i|2
≤G2
nt−2X
τ=t−n/b∥wt−1−wτ∨0∥2
2.
The red term is zero because j̸=k. The sum in the last line has n/b−1terms because our order
of updates forces one of the blocks of the ˆℓt−1vector to have values equal to wt−1before defining
δD
t.
Controlling the Recency of the Loss Table In this section, we bound the ∥qt−1−ˆqt−2∥2
2term
appearing in the primal noise bound Lem. 5. Controlling this term is essential to achieving the
correct rate, as we comment toward the end of this section.
Recall that the [n]indices are partitioned into blocks (B1, . . . , B M)forM:=n/b, where bis
assumed to divide n. For any t≥1, we first decompose
nX
i=1(qt,i−ˆqt−1,i)2=MX
K=1X
i∈BK(qt,i−ˆqt−1,i)2,
and analyze block-by-block. Our goal is to be able to count this quantity in terms of ∥qt−qt−1∥2
2terms. The main result is given in Lem. 10, which is built up in the following lemmas. Consider a
block index K∈[M]. Define the number tK=M⌊(t−K)/M⌋+Kwhen t−1≥Kand and
tK= 0otherwise.
Lemma 7. It holds that
X
i∈BK(qt,i−ˆqt−1,i)2≤X
i∈BK(t−tK)tX
s=tK+1(qs,i−qs−1,i)2.
Proof. We define tKto be the earliest time index τon or before t−1when block Kofqτwas used
to update ˆqτ. When t−1< K , then tK= 0. When t−1≥K, we can compute this number
25tK=M⌊[(t−1)−(K−1)]/M⌋+K=M⌊(t−K)/M⌋+K. Then, write
X
i∈BK(qt,i−ˆqt−1,i)2=X
i∈BK(qt,i−qtK,i)2
=X
i∈BK tX
s=tK+1qs,i−qs−1,i!2
≤X
i∈BK(t−tK)tX
s=tK+1(qs,i−qs−1,i)2,
where the last line follows by Young’s inequality.
While we will not be able to cancel these terms on every iterate, we will be able to when aggregating
over time and then redistributing them. Recall (at)t≥1as described in Appx. C.1. Indeed, by
summing across iterations, we see that
TX
t=1atnX
i=1(qt,i−ˆqt−1,i)2≤TX
t=1atMX
K=1X
i∈BK(t−tK)tX
s=tK+1(qs,i−qs−1,i)2.
We can start by swapping the first two sums and only considering the values of tthat are greater
than or equal to K.
TX
t=1atMX
K=1X
i∈BK(t−tK)tX
s=tK+1(qs,i−qs−1,i)2
=MX
K=1K−1X
t=1atX
i∈BK(t−tK)tX
s=tK+1(qs,i−qs−1,i)2+MX
K=1TX
t=KatX
i∈BK(t−tK)tX
s=tK+1(qs,i−qs−1,i)2
=MX
K=1K−1X
t=1atX
i∈BKttX
s=1(qs,i−qs−1,i)2
| {z }
S0+MX
K=1TX
t=KatX
i∈BK(t−tK)tX
s=tK+1(qs,i−qs−1,i)2
| {z }
S1,
(31)
where we use in the last line that tK= 0when t < K . We handle the terms S0andS1separately.
In either case, we have to match the sums over Kand over iin order to create complete vectors,
as opposed to differences between coordinates. We also maintain the update rules of the sequence
(at)t≥1that will be used in the proof.
Lemma 8. Assume that α≤1
Mandat≤(1 +α)at−1. It holds that S0as defined in (31) satisfies
S0≤eM(M−1)
2M−1X
t=1at∥qt−qt−1∥2
2.
26Proof. Write
S0=MX
K=1K−1X
t=1atX
i∈BKttX
s=1(qs,i−qs−1,i)2by definition
=M−1X
t=1tatMX
K=t+1X
i∈BKtX
s=1(qs,i−qs−1,i)2swap sums over Kandt
=M−1X
t=1tattX
s=1MX
K=t+1X
i∈BK(qs,i−qs−1,i)2move sum over s
≤M−1X
t=1tattX
s=1MX
K=1X
i∈BK(qs,i−qs−1,i)2MX
K=t+1(·)≤MX
K=1(·)
=M−1X
t=1tattX
s=1∥qs−qs−1∥2
2MX
K=1X
i∈BK(·) =nX
i=1(·)
=M−1X
s=1 M−1X
t=stat!
∥qs−qs−1∥2
2swap sums over sandt
≤M−1X
s=1 M−1X
t=st(1 +α)t−sas!
∥qs−qs−1∥2
2at≤(1 +α)at−1
≤M−1X
s=1as(1 +α)M M−1X
t=st!
∥qs−qs−1∥2
2t−s≤M
≤M−1X
s=1eas M−1X
t=st!
∥qs−qs−1∥2
2α≤1
M=⇒(1 +α)M≤e
≤M−1X
s=1eas M−1X
t=1t!
∥qs−qs−1∥2
2M−1X
t=s(·)≤M−1X
t=1(·)
=eM(M−1)
2M−1X
s=1as∥qs−qs−1∥2
2,
the result as desired.
Thus, S0contributes about M3of such terms over the entire trajectory, which can be viewed as an
initialization cost. Next, we control S1.
Lemma 9. Assume that α≤1
Mandat≤(1 +α)at−1. It holds that S1as defined in (31) satisfies
S1≤2e2M2TX
t=1at∥qt−qt−1∥2
2.
27Proof. We can reparametrize tin terms of r=t−K, which will help in reasoning with tK. Define
rK=M⌊r/M⌋+K, and let
S1=MX
K=1T−KX
r=0ar+KX
i∈BK(r+K−rK)r+KX
s=rK+1(qs,i−qs−1,i)2by definition and r=t−K
≤MMX
K=1T−KX
r=0ar+KX
i∈BKr+KX
s=rK+1(qs,i−qs−1,i)2(r−M⌊r/M⌋)≤M
≤MMX
K=1T−KX
r=0(1 +α)KarX
i∈BKr+KX
s=rK+1(qs,i−qs−1,i)2at≤(1 +α)at−1
≤eMMX
K=1T−KX
r=0arX
i∈BKr+KX
s=rK+1(qs,i−qs−1,i)2K≤Mandα≤1
M
=eMT−2X
r=0armin{T−r,M}X
K=1X
i∈BKr+KX
s=rK+1(qs,i−qs−1,i)2swap sums over randK
≤eMT−2X
r=0armin{T−r,M}X
K=1X
i∈BKmin{r+M,T}X
s=M⌊r/M⌋+1(qs,i−qs−1,i)2r+KX
s=rK+1(·)≤min{r+M,T}X
s=M⌊r/M⌋+1(·)
=eMT−2X
r=0armin{r+M,T}X
s=M⌊r/M⌋+1min{T−r,M}X
K=1X
i∈BK(qs,i−qs−1,i)2move sum over s
≤eMT−2X
r=0armin{r+M,T}X
s=M⌊r/M⌋+1MX
K=1X
i∈BK(qs,i−qs−1,i)2min{T−r,M}X
K=1(·)≤MX
K=1(·)
=eMT−2X
r=0armin{r+M,T}X
s=M⌊r/M⌋+1∥qs−qs−1∥2
2MX
K=1X
i∈BK(·) =nX
i=1(·)
≤eMT−2X
r=0min{r+M,T}X
s=M⌊r/M⌋(1 +α)r−sas∥qs−qs−1∥2
2at≤(1 +α)at−1
≤e2MT−2X
r=0min{r+M,T}X
s=M⌊r/M⌋as∥qs−qs−1∥2
2r−s≤Mandα≤1
M
≤2e2M2T−1X
s=1as∥qs−qs−1∥2
2.
The last line follows because the inner sumPmin{r+M,T}
s=M⌊r/M⌋as∥qs−qs−1∥2
2can be thought of as a
sliding window of size at most 2Mcentered at r, which essentially repeats each element in the sum
2Mtimes at most.
In either case, the contribution over the entire trajectory is order M2= (n/b)2terms. Combining
the bounds for S0andS1yields the following.
Lemma 10. Letting M=n/bbe the number of blocks. Assume that α≤1
Mandat≤(1+α)at−1.
We have that
TX
t=1atnX
i=1(qt,i−ˆqt−1,i)2≤3e2M2TX
t=1at∥qt−qt−1∥2
2.
28Proof. Use Lem. 7 to achieve (31) and apply Lem. 8 and Lem. 9 on each term to get
TX
t=1atnX
i=1(qt,i−ˆqt−1,i)2≤eM(M−1)
2M−1X
t=1at∥qt−qt−1∥2
2+ 2e2M2TX
t=1at∥qt−qt−1∥2
2
≤3e2M2TX
t=1at∥qt−qt−1∥2
2,
completing the proof.
We close this subsection with comments on how Lem. 10 can be used. The term EtδD
t2
2is
multiplied in (36) by a factorna2
t−1G2
µCt−1. Thus, if we apply Lem. 10 when redistributing over time a
term∥qt−1−qt−2∥2
2which will be multiplied by a factor (ignoring absolute constants) of
na2
t−1G2
µCt−1·M2=n3a2
t−1G2
b2µCt−1.
In order to cancel such a term, we require the use of −At−1ν
2∥qt−qt−1∥2
2. We can reserve half to
be used up by (49), and be left with the condition
n3a2
t−1G2
b2µCt−1≤At−1ν⇐⇒ α2≤b2
n2µν
2nG2,
as we have applied that at−1≤2αCt−1andat−1≤αAt−1. Thus, this introduces a dependence of
ordern
bq
nG2
µνonα, which propagates to the learning rate α. We now proceed to the main logic of
the convergence analysis.
C.3 Proof of Main Result
C.3.1 Lower Bound on Dual Objective
We first quantify the gap between L(w⋆, qt)andL(w⋆, q⋆)by providing a lower bound in expecta-
tion on L(w⋆, qt), given in Lem. 11. As in Lem. 5, recall the notation π(t, i)to satisfy ˆqt,i=qπ(t,i),i
andgt,i=∇ℓi(wπ(t,i)), that is, the time index of the last update of table element ion or before time
t, with π(t, i) = 0 fort≤0.
Lemma 11. Assume that α≤µ/(24eLκQ). Then, for t≥2, we have that:
−Et[atL(w⋆, qt)]
≤ −atEt[q⊤
tℓ(wt)]−at
2LnX
i=1qt,iEt∥∇ℓi(wt)− ∇ℓi(w⋆)∥2
2
+at−1
4LnX
i=1qt−1,i∥∇ℓi(wt−1)− ∇ℓi(w⋆)∥2
2+nX
i=1aπ(t−2,i)
4Lqπ(t−2,i),i∇ℓi(wπ(t−2,i)− ∇ℓi(w⋆))2
2
+6nαa t−1G2
µ∥qt−1−ˆqt−2∥2
2
−atEt
∇ℓ(wt)⊤qt−ˆg⊤
t−1ˆqt−1, w⋆−wt
+at−1
∇ℓ(wt−1)⊤qt−1−ˆg⊤
t−2ˆqt−2, w⋆−wt−1
−atµ
2Et∥wt∥2
2+atνEt[D(qt||q0)]−µAt
2Et∥w⋆−wt∥2
2
−µCt−1
4∥wt−wt−1∥2
2+µCt−1
2∥w⋆−wt−1∥2
2
−ct−1µ
2t−2X
τ=t−n/bEt∥wt−wτ∨0∥2
2+ct−1µ
2t−2X
τ=t−n/b∥w⋆−wτ∨0∥2
2.
29Proof. We use convexity and smoothness (1), then add and subtract (2) elements from the primal
update, and finally use the definition of the proximal operator (3) with the optimality of wtfor the
problem that defines it.
atL(w⋆, qt) :=atq⊤
tℓ(w⋆) +atµ
2∥w⋆∥2
2−atνD(qt||q0)
(1)
≥atq⊤
tℓ(wt) +at
∇ℓ(wt)⊤qt, w⋆−wt
+at
2LnX
i=1qt,i∥∇ℓi(wt)− ∇ℓi(w⋆)∥2
2
+atµ
2∥w⋆∥2
2−νD(qt||q0)
(2)=atq⊤
tℓ(wt) +at
∇ℓ(wt)⊤qt−vP
t, w⋆−wt
+at
vP
t, w⋆−wt
+atµ
2∥w⋆∥2
2−atνD(qt||q0) +at
2LnX
i=1qt,i∥∇ℓi(wt)− ∇ℓi(w⋆)∥2
2
+µCt−1
2∥w⋆−wt−1∥2
2−µCt−1
2∥w⋆−wt−1∥2
2(32)
+ct−1µ
2t−2X
τ=t−n/b∥w⋆−wτ∨0∥2
2−ct−1µ
2t−2X
τ=t−n/b∥w⋆−wτ∨0∥2
2
(3)
≥atq⊤
tℓ(wt) +at
∇ℓ(wt)⊤qt−vP
t, w⋆−wt
| {z }
cross term+at
vP
t, wt−wt
|{z}
=0
+atµ
2∥wt∥2
2−atνD(qt||q0) +at
2LnX
i=1qt,i∥∇ℓi(wt)− ∇ℓi(w⋆)∥2
2
+µCt−1
2∥wt−wt−1∥2
2−µCt−1
2∥w⋆−wt−1∥2
2 (33)
+ct−1µ
2t−2X
τ=t−n/b∥wt−wτ∨0∥2
2−ct−1µ
2t−2X
τ=t−n/b∥w⋆−wτ∨0∥2
2
+µAt
2∥w⋆−wt∥2
2. (34)
Next, we are able to use Lem. 4 with vt=vP
t,yt=∇ℓ(wt)⊤qt,ˆyt= ˆg⊤
tˆqt,xt=wt,x⋆=w⋆, and
γ=µCt−1/2which yields that
atEt
∇ℓ(wt)⊤qt−vP
t, w⋆−wt
≤atEt
∇ℓ(wt)⊤qt−ˆg⊤
t−1ˆqt−1, w⋆−wt
−at−1
∇ℓ(wt−1)⊤qt−1−ˆg⊤
t−2ˆqt−2, w⋆−wt−1
+n2at−12
µCt−1Eth1
bP
i∈It∇ℓi(wt−1)qt−1,i−gt−2,iˆqt−2,i2
2i
| {z }
Et∥δP
t∥2
2+µCt−1
4Et∥wt−wt−1∥2
2.
(35)
Then, apply Lem. 5 to achieve
EtδP
t2
2≤3qmax
nnX
i=1qt−1,i∥∇ℓi(wt−1)− ∇ℓi(w⋆)∥2
2
+3qmax
nnX
i=1qπ(t−2,i),i∇ℓi(wπ(t−2,i))− ∇ℓi(w⋆)2
2
+3G2
n∥qt−1−ˆqt−2∥2
2(36)
30In the following, the blue terms indicate what changes from line to line. Combine the previous two
steps to collect all terms for the lower bound. That is, apply (34) to write
Et[atL(w⋆, qt)]
:=atq⊤
tℓ(w⋆) +atµ
2∥w⋆∥2
2−atνD(qt||q0)
≥atq⊤
tℓ(wt) +Et[at
∇ℓ(wt)⊤qt−vP
t, w⋆−wt
] +at
2LnX
i=1qt,i∥∇ℓi(wt)− ∇ℓi(w⋆)∥2
2
+atµ
2∥wt∥2
2−atνD(qt||q0) +µAt
2∥w⋆−wt∥2
2
+µCt−1
2∥wt−wt−1∥2
2−µCt−1
2∥w⋆−wt−1∥2
2
+ct−1µ
2t−2X
τ=t−n/b∥wt−wτ∨0∥2
2−ct−1µ
2t−2X
τ=t−n/b∥w⋆−wτ∨0∥2
2,
then apply (35) to the blue term above to write
Et[atL(w⋆, qt)]
≥atq⊤
tℓ(wt) +at
2LnX
i=1qt,i∥∇ℓi(wt)− ∇ℓi(w⋆)∥2
2
−n2at−12
µCt−1Et∇ℓit−1(wt−1)qt−1,it−1−gt−2,it−1ˆqt−2,it−12
2(37)
+atEt
∇ℓ(wt)⊤qt−ˆg⊤
t−1ˆqt−1, w⋆−wt
−at−1
∇ℓ(wt−1)⊤qt−1−ˆg⊤
t−2ˆqt−2, w⋆−wt−1
+atµ
2∥wt∥2
2−atνD(qt||q0) +µAt
2∥w⋆−wt∥2
2
+µCt−1
4∥wt−wt−1∥2
2−µCt−1
2∥w⋆−wt−1∥2
2
+ct−1µ
2t−2X
τ=t−n/b∥wt−wτ∨0∥2
2−ct−1µ
2t−2X
τ=t−n/b∥w⋆−wτ∨0∥2
2.
Finally, apply (36) to the term (37) to achieve
≥atq⊤
tℓ(wt) +at
2LnX
i=1qt,i∥∇ℓi(wt)− ∇ℓi(w⋆)∥2
2
−3κQa2
t−1
µCt−1nX
i=1qt−1,i∥∇ℓi(wt−1)− ∇ℓi(w⋆)∥2
2−3κQa2
t−1
µCt−1nX
i=1qπ(t−2,i),i∇ℓi(wπ(t−2,i)− ∇ℓi(w⋆))2
2
−3nG2a2
t−1
µCt−1∥qt−1−ˆqt−2∥2
2
+atEt
∇ℓ(wt)⊤qt−ˆg⊤
t−1ˆqt−1, w⋆−wt
−at−1
∇ℓ(wt−1)⊤qt−1−ˆg⊤
t−2ˆqt−2, w⋆−wt−1
+atµ
2∥wt∥2
2−atνD(qt||q0) +µAt
2∥w⋆−wt∥2
2
+µCt−1
4∥wt−wt−1∥2
2−µCt−1
2∥w⋆−wt−1∥2
2
+ct−1µ
2t−2X
τ=t−n/b∥wt−wτ∨0∥2
2−ct−1µ
2t−2X
τ=t−n/b∥w⋆−wτ∨0∥2
2.
31Next, we apply at−1≤2αCt−1andα≤µ
24eLκQto achieve:
3nG2a2
t−1
µCt−1≤6nG2αat−1
µ,
3κQa2
t−1
µCt−1≤at−1
4L,
3κQa2
t−1
µCt−1≤aπ(t−2,i)
4L,∀i∈[n]
For terms that contain π(t−2, i), we recall that π(t−2, i)can be at most n/btimesteps behind
t−2, so we have that
at−1≤
1 +1
n/bn/b
at−n/b≤eat−n/b≤eaπ(t−2,i).
We use here that at≤(1 +α
4)at−1and impose the conditionα
4≤b
nin the rate. Substituting this
back into the lower bound achieves the desired claim.
C.3.2 Upper Bound on Gap Criterion
Next, we quantify the gap between L(wt, q⋆)andL(w⋆, q⋆)by upper bounding atL(wt, q⋆), as
given in Lem. 12. When combined with the lower bound Lem. 11, we may then control the gap.
Lemma 12. Fort≥2, we have that:
atL(wt, q⋆)≤atq⋆⊤(ℓ(wt)−vD
t) +atµ
2∥wt∥2
2+At−1ν∆D(q⋆, qt−1)
+atqt⊤vD
t−atνD(qt||q0)−At−1ν∆D(qt, qt−1)−Atν∆D(q⋆, qt).
Proof. We add and subtract (1) terms in the dual update step and apply the definition of the proximal
operator (2) with Bregman divergence, and the optimality of qtfor the maximization problem that
defines it.
atL(wt, q⋆) :=atq⋆⊤ℓ(wt)−atνD(q⋆||q0) +atµ
2∥wt∥2
2
(1)=atq⋆⊤(ℓ(wt)−vD
t) +atµ
2∥wt∥2
2+At−1ν∆D(q⋆, qt−1))
+atq⋆⊤vD
t−atνD(q⋆||q0)−At−1ν∆D(q⋆, qt−1))
(2)
≤atq⋆⊤(ℓ(wt)−vD
t) +atµ
2∥wt∥2
2+At−1ν∆D(q⋆, qt−1))
+atqt⊤vD
t−atνD(qt||q0)−At−1ν∆D(qt, qt−1)−Atν∆D(q⋆, qt).
We can combine the upper bound from Lem. 12 and lower bound from Lem. 11 in Lem. 13. We
identify telescoping terms in blue and non-positive terms in red. The green term is canceled after
aggregation across time t. This bound, like before applies for t≥2.
32Lemma 13. Assume that α≤µ/(24eLκQ). For t >2, we have that:
Et[γt] =Eth
at(L(wt, q⋆)− L(w⋆, qt)−atµ
2∥wt−w⋆∥2
2−atν
2∥qt−q⋆∥2
2i
≤atEt
(q⋆−qt)⊤(ℓ(wt)−ˆℓt)
−at−1(q⋆−qt−1)⊤(ℓ(wt−1)−ˆℓt−1) (38)
+At−1ν∆D(q⋆, qt−1)−AtνEt[∆D(q⋆, qt)] (39)
−at
2LEt"nX
i=1qt,i∥∇ℓi(wt)− ∇ℓi(w⋆)∥2
2#
(40)
+at−1
4LnX
i=1qt−1,i∥∇ℓi(wt−1)− ∇ℓi(w⋆)∥2
2+nX
i=1aπ(t−2,i)
4Lqπ(t−2,i),i∇ℓi(wπ(t−2,i)− ∇ℓi(w⋆))2
2
(41)
−atEt
∇ℓ(wt)⊤qt−ˆg⊤
t−1ˆqt−1, w⋆−wt
+at−1
∇ℓ(wt−1)⊤qt−1−ˆg⊤
t−2ˆqt−2, w⋆−wt−1
(42)
+6nG2αat−1
µ∥qt−1−ˆqt−2∥2
2 (43)
−µAt
2Et∥w⋆−wt∥2
2+µCt−1
2∥w⋆−wt−1∥2
2+ct−1µ
2t−2X
τ=t−n/b∥w⋆−wτ∨0∥2
2(44)
+nat−1αG2
νt−3X
τ=t−n/b∥wt−1−wτ∨0∥2
2−ct−1µ
2t−2X
τ=t−n/bEt∥wt−wτ∨0∥2
2(45)
+nat−1αG2
ν∥wt−1−wt−2∥2
2−µCt−1
4Et∥wt−wt−1∥2
2(46)
−atµ
2Eth
∥wt−w⋆∥2
2i
−atν
2Et∥qt−q⋆∥2
2−At−1ν
2Et[∆D(qt, qt−1)]. (47)
Fort= 2, the above holds with the addition of the termν
4∥q1−q0∥2
2+nG2
ν∥w0−w1∥2
2.
33Proof. First, combine Lem. 11 and Lem. 12 to write:
Et[γt] =Eth
at(L(wt, q⋆)− L(w⋆, qt)−atµ
2∥wt−w⋆∥2
2−atν
2∥qt−q⋆∥2
2i
≤Et
at(q⋆−qt)⊤(ℓ(wt)−vD
t)
| {z }
cross term
+Et[At−1ν∆D(q⋆, qt−1)−Atν∆D(q⋆, qt)]
−Et"
at
2LnX
i=1qt,i∥∇ℓi(wt)− ∇ℓi(w⋆)∥2
2#
+at−1
4LnX
i=1qt−1,i∥∇ℓi(wt−1)− ∇ℓi(w⋆)∥2
2+nX
i=1aπ(t−2,i)
4Lqπ(t−2,i),i∇ℓi(wπ(t−2,i)− ∇ℓi(w⋆))2
2
+6nG2αat−1
µ∥qt−1−ˆqt−2∥2
2
−atEt
∇ℓ(wt)⊤qt−ˆg⊤
t−1ˆqt−1, w⋆−wt
+at−1
∇ℓ(wt−1)⊤qt−1−ˆg⊤
t−2ˆqt−2, w⋆−wt−1
−µAt
2Et∥w⋆−wt∥2
2+µCt−1
2∥w⋆−wt−1∥2
2+ct−1µ
2t−2X
τ=t−n/b∥w⋆−wτ∨0∥2
2
−µCt−1
4Et∥wt−wt−1∥2
2−At−1νEt[∆D(qt, qt−1)]
−atµ
2Eth
∥wt−w⋆∥2
2i
−ct−1µ
2t−2X
τ=t−n/bEt∥wt−wτ∨0∥2
2−atν
2Eith
∥qt−q⋆∥2
2i
.
Bound the cross term identified above. In the case that t= 2, use Lem. 4 with vt=vD
t,yt=ℓ(wt),
ˆyt+1=ˆℓt,xt=qt,x⋆=q⋆, and γ=νAt−1=νwhich yields that
atEt
(q⋆−q2)⊤(ℓ(w2)−vD
2)
≤a2E2
(q⋆−q2)⊤(ℓ(wt)−ˆℓ2)
−a1(q⋆−q1)⊤(ℓ(w1)−ˆℓ1)
+ν
4E2
∥q1−q0∥2
2
+n2
νE21
bP
j∈Jt(ℓj(w1)−ˆℓ1,j)ej2
2, (48)
where the fourth term above can be bounded as
n2
νE21
bP
j∈Jt(ℓj(w1)−ˆℓ1,j)ej2
2≤nb
ν1
bPb
j=1(ℓj(w1)−ˆℓ1,j)ej2
2≤nG2
ν∥w1−w0∥2
2.
Using the definition of the update, we have that ∥w1−w0∥2
2= (1/µ2)∇ℓ(w0)⊤q02
2. In the case
thatt >2, use Lem. 4 as above but instead with γ=νAt−2which yields that
atEt
(q⋆−qt)⊤(ℓ(wt)−vD
t)
≤atEt
(q⋆−qt)⊤(ℓ(wt)−ˆℓt)
−at−1(q⋆−qt−1)⊤(ℓ(wt−1)−ˆℓt−1)
+At−2ν
4Et
∥qt−qt−1∥2
2
+n2a2
t−1
At−2νEt1
bP
j∈Jt(ℓj(wt−1)−ˆℓt−1,j)ej2
2| {z }
Et∥δD
t∥2
2. (49)
We may then apply Lem. 6 and at−1≤αAt−2to get that
n2a2
t−1
At−2νEtδD
t2
2≤nat−1αG2
νt−2X
τ=t−n/b∥wt−1−wτ∨0∥2
2. (50)
We may use strong convexity to get theAt−2ν
4Et
∥qt−qt−1∥2
2
term to cancel with
−At−1ν
2∆D(qt, qt−1)and that At−2≤At−1to complete the proof.
34C.3.3 Determining Constants
In this section, we provide derivations that determine the values of the constant ctthat allow for
cancellation of errors. We slightly adjust the notation in this subsection, in that we assume that for
some η >0
at≤(1 +η)at−1
and determine ηsuch that (28) is satisfied. We will see that ηis simply a constant factor away from
α, so the resulting condition we actually be on α. The latter is given formally in Lem. 14. We
assume here that n/b≥2, which is taken as an assumption of Thm. 2.
In the statement of Lem. 13, the lines above (43) will telescope without additional conditions.
For (44), we set ct=at/mfor some parameter m. Note that this condition does not need to
be checked when n/b < 1, as the additional sum term over τwill not be included in the update.
Counting all the terms that will appear when matched on the index t−1, we have the condition that
−at−1
4−At−1+Ct−1+t+n/b−1X
s=t+1as/m≤0.
The first term result from the “good term” −at−1µ
4∥wt−1−w⋆∥2
2from the bottom. The rightmost
term above results because as∥w⋆−wτ∨0∥2
2will have τ=t−1when s∈ {t+1, . . . , t +n/b−1}.
We will begin by requiring that require that at≤(1 +β)at−1for all tand some β >0, and then
determine βbelow. The condition reads as
4n/b−4 +m
4mat−1≥(1 +β)2
mn/b−2X
s=0(1 +β)sat−1,
which can be summed and represented as
(4n/b−4 +m)
4≥(1 +β)2(1 +β)n/b−1−1
β.
Rearranging and taking a logarithm on both sides, this is the same as
lnβ(4n/b−4 +m)
4(1 + β)2+ 1
≥(n/b−1) log(1 + β). (51)
Next, using the inequality2x
2+x≤ln(1 + x)withx=β(4n/b−4+m)
4(1+β)2 which holds for all x≥0, we
have
lnβ(4n/b−4 +m)
4(1 + β)2+ 1
≥2β(4n/b−4+m)
4(1+β)2
2 +β(4n/b−4+m)
4(1+β)2=2β(4n/b−4 +m)
8(1 + β)2+β(4n/b−4 +m)(52)
We can also apply the upper bound ln(x+ 1)≤xwithx=β(which also holds for any x≥0) to
write
(n/b−1) log(1 + β)≤(n/b−1)β,
which means that (51) will be satisfied (using (52)) if
2β(4n/b−4 +m)
8(1 + β)2+β(4n/b−4 +m)≥(n/b−1)β (53)
⇐⇒n/b−1 +m/4
n/b−1≥(1 +β)2+ (β/2)(n/b−1 +m/4). (54)
35In order to satisfy the inequality, substitute m= 4cβ(n/b−1)2for some c >0to be determined
and assume that β≤1
n/b−1, so that β(n/b−1)≤1. The LHS reads as
n/b−1 +m/2
n/b−1= 1 + cβ(n/b−1).
The RHS can be upper-bounded as
(1 +β)2+ (β/2)(n/b−1 +m/4) = (1 + β)2+ (β/2)(n/b−1 +cβ(n/b−1)2)
≤1 +β(2 +β) +β(n/b−1)1 +c
2,
which makes the inequality satisfied when
c≥24 + 2 β
n/b−1+ 1
,
so we can set c= 16 . We now have the flexibility to control β, and the telescoping of (44) is
achieved. For (45), set β=α
4and pass the condition of β≤1/(n/b−1)ontoα, which maintains
the rate (and is already satisfied when α≤b
nandn≥2). Then, we can achieve
natαG2
ν≤µat−1
m=µat−1
4α(n/b−1)2
by requiring that α≤b√µν
4n3/2G, which achieves the telescoping of (45). Finally, to address (46), we
may satisfy it if
natαG2
ν≤µCt−1
4
which we can achieve by incorporating the condition at≤4α(n/b−1)2Ct−1into the update of
at, becausenatαG2
ν≤µat
mby the previous condition on α. Having chosen ct, we are prepared to
produce a learning rate parameter ηto capture all conditions on αin one, as given in Lem. 14.
Lemma 14. For all t≥1, we have the following.
•Setting ct=at/[16α(n/b−1)2]implies that at≤2αCt.
•Using the update scheme
a2= 4ηa1,andat= (1 + η)at−1fort >2,
when
η=1
4min(
b
32n,µ
24eLκQ,b
ns
nG2
µν)
.
we have that (28) holds.
Proof. Noting that m= 16α(n/b−1)2we confirm that
Ct≥At−1/2
⇐⇒ At−1
16α(n/b−1)at≥At−1/2
⇐⇒
1−1
16α(n/b−1)
at≥ −At−1/2
⇐⇒ 21
16α(n/b−1)−1
at≤At−1.
This condition is satisfied when α≤1
32(n/b−1), so we incorporate α≤b
32ninto the rate, implying
thatat≤2αCt. This concludes the proof of the first bullet point.
36Next, we show that at≤(1+α/4)at−1will imply that at≤αAt−1, which is the second part of (28).
First, we define a2=αa1as an initialization (which also satisfies a2≤(1+α/4)a1when α≤4/3),
and show inductively that if at−1≤αAt−2, then at≤(1 +α/4)at−1=⇒at≤αAt−1. In the
base case, A1=a1, so the condition a2=αa1satisfies a2≤αA1. Next, fixing tand assuming
that 1) at−1≤αAt−2and 2) that at≤(1 +α/4)at−1, we have that
αAt−1=α(at−1+At−2)≥(α+ 1)at−1≥at,
the desired result. Finally, we consider the condition at≤4α(n/b−1)2Ct−1, the third part of (28).
We wish to show that the following inequality holds:
at≤4α(n/b−1)2Ct−1= 4α(n/b−1)2
At−1−1
4α(n/b−1)at−1
= 4α(n/b−1)2
at−1+At−2−1
4α(n/b−1)at−1
which is implied by the inequality
at≤4α(n/b−1)2
at−1+ (1/α)at−1−1
4α(n/b−1)at−1
= 4(n/b−1)2
α+ 1−1
4(n/b−1)
at−1.
When n/b≥2, we have that (1 + α/4)≤4(n/b−1)2
α+ 1−1
4(n/b−1)
, so we require that
b≤n/2. Thus, our final updates are given by
a2= 4ηa1≤(1 +η)a1andat= (1 + η)at−1fort >2.
Because each condition was satisfied when using at= (1+ α/4)at−1, we define η=α/4to achieve
the claimed result.
C.3.4 Bound on Sum of Successive Gaps
Lem. 15 is an upper estimate for the expected sum of the gap function over Titerates. Recall
thatE1[·]the full expectation over {(It, Jt)}T
t=1. The green term is a quantity that remain as an
initialization term, whereas the blue terms have to be bounded from above. The terms directly
below the blue terms account for all of the “negative π(t−1, i)” terms are not yet used up by the
telescoping in lines (39), (40), and (41), and there are in fact between 1andncopies of those terms
in each iteration, even though we will use only 1.
Lemma 15 (Progress Bound) .Assume that
α≤minb
32n,µ
24eLκQ,b
36e2nrµν
nG2
.
37For any T≥1, we have that
E0"TX
t=1γt#
≤nG2
νµ2∇ℓ(w0)⊤q02
2
+aTE0h
(q⋆−qT)⊤(ℓ(wT)−ˆℓT)i
(55)
−aTE0
∇ℓ(wT)⊤qT−ˆg⊤
T−1ˆqT−1, w⋆−wT
(56)
−nX
i=1(n−T+π(T−1, i))aπ(T−1,i)
4LE0h
qπ(T−1,i)∇ℓi(wπ(T−1,i))− ∇ℓi(w⋆)2
2i
(57)
+6nG2α
µE0TX
t=1at−1∥qt−1−ˆqt−2∥2
2−TX
t=1At−1ν
2E0[D(qt∥qt−1)] (58)
−aT
2LnX
i=1E0h
qT,i∥∇ℓi(wT)− ∇ℓi(w⋆)∥2
2i
−µAT
2E0h
∥w⋆−wT∥2
2i
(59)
−µaT−1
2[16α(n/b−1)]T−2X
τ=T−⌈n/b⌉E0h
∥wT−wτ∨0∥2
2i
(60)
−ATνE0[D(q⋆∥qT)] (61)
−TX
t=1atµ
4E∥wt−w⋆∥2
2−TX
t=1atν
2E0∥qt−q⋆∥2
2. (62)
Proof. We proceed by first deriving an upper bound on γ1, the gap function for t= 1. Note that w1
is non-random, as a0= 0implies that v0=∇ℓ(w0). Using that w1is the optimum for the proximal
operator that defines it, the upper bound can be written as
a1L(w1, q⋆)≤a1q⋆⊤(ℓ(w1)−ˆℓ1) +a1µ
2∥w1∥2
2+a1q1⊤ˆℓ1−a1νD(q1||q0)−A1ν∆D(q⋆, q1),
where we use that ˜ℓ1=ˆℓ1. For the lower bound, use a similar argument to Lem. 11 to achieve
a1L(w⋆, q1)≥a1q⊤
1ℓ(w1) +a1
∇ℓ(w1)⊤q1− ∇ℓ(w0)⊤q0, w⋆−w1
+a1µ
2∥w1∥2
2
−a1νD(q1||q0) +a1
2LnX
i=1q1,i∥∇ℓi(w1)− ∇ℓi(w⋆)∥2
2+µA1
2∥w⋆−w1∥2
2,
where we use that vP
0=∇ℓ(w0)⊤q0. We combine them to get
γ1≤a1(q⋆−q1)⊤(ℓ(w1)−ˆℓ1)−a1
∇ℓ(w1)⊤q1− ∇ℓ(w0)⊤q0, w⋆−w1
−a1
2LnX
i=1q1,i∥∇ℓi(w1)− ∇ℓi(w⋆)∥2
2−µA1
2∥w⋆−w1∥2
2−A1ν∆D(q⋆, q1)
−a1µ
2∥w1−w⋆∥2
2−a1ν
2∥q1−q⋆∥2
2,
where the last two terms are the result of the additional quadratic slack terms in γ1. All of
the terms from the display above will be telescoped. Thus, we apply Lem. 13 and collect
the unmatched terms from the t≥2one-step bound (using that A0= 0 ). The term (57)
can be viewed as counting the remainder of (40) after it has telescoped some but not all terms
aπ(T−1,i)
4LE0h
qπ(T−1,i)∇ℓi(wπ(T−1,i))− ∇ℓi(w⋆)2
2i
across iterations.
38C.3.5 Completing the Proof
We use similar techniques as before to bound the remaining terms from the T-step progress bound
given in Lem. 15. We may now prove the main result.
Theorem 2. For a constant α >0, define the sequence
a1= 1, a2= 4α,andat= (1 + α)at−1fort >2,
along with its partial sum At=Pt
τ=1aτ. Under Asm. 1, there is an absolute constant Csuch that
using the parameter
α=Cminb
n,µ
LκQ,b
nrµν
nG2
,
the iterates of Algorithm 1 satisfy:
TX
t=1atE1[γt] +ATµ
4E1∥wT−w⋆∥2
2+ATν
4E1∥qT−q⋆∥2
2≤nG2
ν∥w0−w1∥2
2.
We can compute a point (wT, qT)achieving an expected gap no more than εwith big- Ocomplexity
(n+bd)· 
n
b+LκQ
µ+n
bs
nG2
µν!
·ln1
ε
. (10)
Proof. We first apply Lem. 15, and proceed to bound the inner product terms (55) and (56). Apply
Young’s inequality with parameter νAT−1/2to get
aTE0h
(q⋆−qT)⊤(ℓ(wT)−ˆℓT)i
≤νAT−1
4E0∥q⋆−qT∥2
2+a2
T
νAT−1E0∥ℓ(wT)−ˆℓT∥2
2
≤νAT−1
4E0∥q⋆−qT∥2
2+a2
TG2
νAT−1T−2X
τ=T−n/bE0∥wT−wτ∨0∥2
2
≤νAT−1
4E0∥q⋆−qT∥2
2+aTαG2
νT−2X
τ=T−n/bE0∥wT−wτ∨0∥2
2.
The left-hand term will be canceled by (61) by applying strong concavity (leaving behind
−νAT−1
4E0∥q⋆−qT∥2
2) and the right-hand term (because of the condition α≤√µν
4n3/2G) will be
canceled by (60). Next, consider (56). By Young’s inequality with parameter µAT−1/2, we have
−aTE0
∇ℓ(wT)⊤qT−ˆg⊤
T−1ˆqT−1, w⋆−wT
≤a2
T
µAT−1E0∇ℓ(wT)⊤qT−ˆg⊤
T−1ˆqT−12
2+µAT−1
4E0∥w⋆−wT∥2
2
≤aTα
µE0∇ℓ(wT)⊤qT−ˆg⊤
T−1ˆqT−12
2+µAT−1
4E0∥w⋆−wT∥2
2,
where the second term will be canceled by (59). For the remaining term,
E0∇ℓ(wT)⊤qT−ˆg⊤
T−1ˆqT−12
2
≤E0(∇ℓ(wT)−ℓ(w⋆))⊤qT+∇ℓ(w⋆)⊤(qT−ˆqT−1) + (∇ℓ(w⋆)−ˆgT−1)⊤ˆqT−12
2
≤3E0(∇ℓ(wT)− ∇ℓ(w⋆))⊤qT2
2+ 3E0∇ℓ(w⋆)⊤(qT−ˆqT−1)2
2+ 3E0(∇ℓ(w⋆)−ˆgT−1)⊤ˆqT−12
2
≤3σnnX
i=1E0h
qT,i∥∇ℓi(wT)− ∇ℓi(w⋆)∥2
2i
+ 3nG2E0∥qT−ˆqT−1∥2
2+ 3σnnX
i=1E0h
ˆqT−1,i∥∇ℓi(w⋆)−ˆgT−1,i∥2
2i
39We may add the middle term above to (58), so that the remaining term to bound is
6nG2α
µT+1X
t=1at−1E0∥qt−1−ˆqt−2∥2
2−TX
t=1At−1ν
2E0[∆D(qt, qt−1)].
To show that this quantity is non-negative, we use that a0= 0and Lem. 10 (recalling that M=n/b
to see that
6nG2α
µE0T+1X
t=1at∥qt−ˆqt−1∥2
2≤18e2n3G2α
b2µE0T+1X
t=1at−1∥qt−qt−1∥2
2≤18e2n3G2α2
b2µE0TX
t=1At−1∥qt−qt−1∥2
2,
which will cancel with the rightmost term in (58) provided that α≤b
36e2npµν
nG2. Thus, plugging
the previous displays into Lem. 15, we have that
E0"TX
t=1γt#
≤n2G2
νµ2∇ℓ(w0)⊤q02
2
+3aTσnα
2µnX
i=1E0h
qT,i∥∇ℓi(wT)− ∇ℓi(w⋆)∥2
2i
−aT
2LnX
i=1E0h
qT,i∥∇ℓi(wT)− ∇ℓi(w⋆)∥2
2i
+3σnaTα
2µnX
i=1E0h
qπ(T−1,i),i∇ℓi(w⋆)− ∇ℓi(wπ(T−1,i))2
2i
−nX
i=1(n−T+π(T−1, i))aπ(T−1,i)
4LE0h
qπ(T−1,i)∇ℓi(wπ(T−1,i))− ∇ℓi(w⋆)2
2i
−TX
t=1atµ
4E0∥wt−w⋆∥2
2−TX
t=1atν
4E0∥qt−q⋆∥2
2
−AT−1µ
4E0∥wT−w⋆∥2
2−AT−1ν
4E0∥qT−q⋆∥2
2.
The black lines will cancel given our conditions on α. Substituting the definition of γtand
moving the final non-positive terms on the last line, that is,(AT−1+aT)µ
4E0∥wT−w⋆∥2
2and
(AT−1+aT)ν
4E0∥qT−q⋆∥2
2to the left-hand side achieves the claim.
C.4 Modification for Unregularized Objectives
For completeness, we describe a modification of DRAGO for unregularized objectives, or (2) when
µ≥0andν≥0. The analysis follows similarly to the previous subsections (regarding the µ, ν > 0
case), and we highlight the steps that differ in this subsection by presenting a slightly different upper
bound on the gap criterion based on the modified primal and dual updates. This will result a different
update for the sequence (at)t≥1, subsequently affecting the rate.
C.4.1 Overview
The modified algorithm is nearly identical to Algorithm 1, except that the dual and primal updates
can be written as
qt:= arg max
q∈Qat
vD
t, q
−atνD(q∥q0)−(νAt−1+ν1)∆D(q, qt−1) (63)
and
wt:= arg min
w∈Wat
vP
t, w
+atµ
2∥w∥2
2+Ct−1µ+µ1
2∥w−wt−1∥2
2+ct−1µ+µ2
2t−2X
s=t−n/b∥w−ws∨0∥2
2,
(64)
respectively, and µ1, µ2, ν1≥0are to-be-set hyperparameters. When ν >0, we may set ν1= 0,
and when µ >0, we may set µ1=µ2= 0, which recover the Algorithm 1 updates exactly. While
40we may set ν1= 1 when it is positive (and similarly for µ1andµ2), they may be set to different
values in order to balance the terms appearing in the rate below. As in Appx. C.1, we wish to upper
bound the expectation of the quantity
γt=at
L(wt, q⋆)− L(w⋆, qt)−µ
2∥wt−w⋆∥2
2−ν
2∥qt−q⋆∥2
2
(65)
which is still non-negative in the case of µ= 0 orν= 0. By using an appropriate averaging
sequence (at)t≥1and defining AT=PT
t=1at, we upper boundPT
t=1atE0[γt](see Thm. 2) by
a constant value independent of T. Recall that the batch size is denoted by b. As we derive in
Appx. C.4.3, our final update on the (at)sequence is
at= min(
Ct−1µ+µ1
12enqmaxL,
1 +b
n
at−1,b
32np
(At−1ν+ν1) min{Ct−1µ+µ1, ct−1µ+µ2}√nG)
.
Observe that when µ= 0, we set at=µ1
12enqmaxLto achieve a O(1/t)rate. We omit proofs in this
subsection as they follow with the exact same steps as the corresponding lemmas in the strongly
convex-strongly concave setting (which we point to for each result).
C.4.2 Upper Bound on Gap Criterion
Following the steps of Appx. C.3.1 and Appx. C.3.2, we will first derive lower and upper bounds on
Et[atL(w⋆, qt)]andatL(wt, q⋆)and combine them to upper bound atEt[γt]. Recalling that Et[·]
denotes the condition expectation given (wt−1, qt−1), and we can then take the marginal expectation
to upper bound atE0[γt]. The following lower bound is analogous to Lem. 11 and follows the exact
same proof technique.
Lemma 16. Fort≥2, assuming that at≤Ct−1µ+µ1
12enqmaxLandat≤(1 +b/n)at−1, we have that:
−Et[atL(w⋆, qt)]
≤ −atEt[q⊤
tℓ(wt)]−at
2LnX
i=1qt,iEt∥∇ℓi(wt)− ∇ℓi(w⋆)∥2
2+atµ
2∥wt∥2
2
+at−1
4LnX
i=1qt−1,i∥∇ℓi(wt−1)− ∇ℓi(w⋆)∥2
2+nX
i=1aπ(t−2,i)
4Lqπ(t−2,i),i∇ℓi(wπ(t−2,i)− ∇ℓi(w⋆))2
2
+3nG2a2
t−1
Ct−1µ+µ1∥qt−1−ˆqt−2∥2
2
−atEt
∇ℓ(wt)⊤qt−ˆg⊤
t−1ˆqt−1, w⋆−wt
+at−1
∇ℓ(wt−1)⊤qt−1−ˆg⊤
t−2ˆqt−2, w⋆−wt−1
+atνEt[D(qt||q0)]−Atµ+µ1+µ2
2Et∥w⋆−wt∥2
2
−Ct−1µ+µ1
4∥wt−wt−1∥2
2+Ct−1µ+µ1
2∥w⋆−wt−1∥2
2
−ct−1µ+µ2
2t−2X
τ=t−n/bEt∥wt−wτ∨0∥2
2+ct−1µ+µ2
2t−2X
τ=t−n/b∥w⋆−wτ∨0∥2
2.
Similarly, following the same steps as Lem. 12, one can derive the following upper bound.
Lemma 17. Fort≥2, we have that:
atL(wt, q⋆)≤atq⋆⊤(ℓ(wt)−vD
t) + (At−1ν+ν1)∆D(q⋆, qt−1)
+atqt⊤vD
t−atνD(qt||q0)−(At−1ν+ν1)∆D(qt, qt−1)−(Atν+ν1)∆D(q⋆, qt).
By combining Lem. 17 and Lem. 16, we can upper bound the quantity
Et[at(L(wt, q⋆)− L(w⋆, qt)]. Consequently, the following result follows the same steps as
Lem. 13. As before, we identify telescoping terms in blue, non-positive terms in red, where green
term is bounded after aggregation across time t.
41Lemma 18. Assume that at−1≤Ct−1µ+µ1
12eLnq maxandat≤(1 +b/n)at−1. For t >2, we have that:
Et[γt] =Eth
at(L(wt, q⋆)− L(w⋆, qt)−atµ
2∥wt−w⋆∥2
2−atν
2∥qt−q⋆∥2
2i
≤atEt
(q⋆−qt)⊤(ℓ(wt)−ˆℓt)
−at−1(q⋆−qt−1)⊤(ℓ(wt−1)−ˆℓt−1) (66)
+(At−1ν+ν1)∆D(q⋆, qt−1)−(Atν+ν1)Et[∆D(q⋆, qt)] (67)
−at
2LEt"nX
i=1qt,i∥∇ℓi(wt)− ∇ℓi(w⋆)∥2
2#
(68)
+at−1
4LnX
i=1qt−1,i∥∇ℓi(wt−1)− ∇ℓi(w⋆)∥2
2+nX
i=1aπ(t−2,i)
4Lqπ(t−2,i),i∇ℓi(wπ(t−2,i)− ∇ℓi(w⋆))2
2
(69)
−atEt
∇ℓ(wt)⊤qt−ˆg⊤
t−1ˆqt−1, w⋆−wt
+at−1
∇ℓ(wt−1)⊤qt−1−ˆg⊤
t−2ˆqt−2, w⋆−wt−1
(70)
+3nG2a2
t−1
Ct−1µ+µ1∥qt−1−ˆqt−2∥2
2(71)
−Atµ+µ1+µ2(n/b−1)
2Et∥w⋆−wt∥2
2+µ1
2∥w⋆−wt−1∥2
2+ct−1µ+µ2
2t−2X
τ=t−n/b∥w⋆−wτ∨0∥2
2
(72)
+na2
t−1G2
At−2ν+ν1t−3X
τ=t−n/b∥wt−1−wτ∨0∥2
2−ct−1µ+µ2
2t−2X
τ=t−n/bEt∥wt−wτ∨0∥2
2(73)
+na2
t−1G2
At−2ν+ν1∥wt−1−wt−2∥2
2−Ct−1µ+µ1
4Et∥wt−wt−1∥2
2(74)
−atµ
2∥wt−w⋆∥2
2−atν
2Et∥qt−q⋆∥2
2−At−1ν+ν1
2Et[∆D(qt, qt−1)]. (75)
Fort= 2, the above holds with the addition of the termnG2
ν+ν1∥w1−w0∥2
2and without any term
including At−2in the denominator.
We then select constants to achieve the desired telescoping in each line of Lem. 18.
C.4.3 Determining Constants
We now select the constants (µ1, µ2, ν1), and the sequences (at)and(ct)to complete the main part
of the analysis.
In the statement of Lem. 18, the lines above (71) will telescope without additional conditions.
For (72), we set ct=at/mfor some parameter m(just as in Appx. C.3.3). Note that this con-
dition does not need to be checked when n/b < 1, as the additional sum term over τwill not be
included in the update. Counting all the terms that will appear when matched on the index t−1, we
have the condition that
µ
−at−1
4−At−1+Ct−1+t+n/b−1X
s=t+1as/m

| {z }
≤0+−(µ1+µ2(n/b−1)) + µ1+ (n/b−1)µ2| {z }
=0≤0,
where the first underbrace is non-positive based on the choice of mselected in Appx. C, and the
equality is satisfied for all values of µ1andµ2. Lines (73) and (74) yield the conditions
na2
tG2
At−1ν+ν1≤Ct−1µ+µ1
4andna2
tG2
At−1ν+ν1≤ct−1µ+µ2
2. (76)
42for the telescoping to be achieved, which can equivalently be rewritten as
at≤r
(At−1ν+ν1)(Ct−1µ+µ1)
4nG2andat≤r
(At−1ν+ν1)(ct−1µ+µ2)
2nG2(77)
These can be accomplished by setting
at≤p
(At−1ν+ν1) min{Ct−1µ+µ1, ct−1µ+µ2}
2√nG.
We must also handle the term3nG2a2
t−1
Ct−1µ+µ1∥qt−1−ˆqt−2∥2
2. By the argument of Lem. 10 using a2
t
instead of at, we have that when summing over t, we have that
TX
t=13nG2a2
t
µt∥qt−ˆqt−1∥2
2≤3nG2
Ct−1µ+µ1·3e4M2TX
t=1a2
t∥qt−qt−1∥2
2
≤512nG2M2
Ct−1µ+µ1TX
t=1a2
t∥qt−qt−1∥2
2
where M=n/bis the number of blocks, and the e4term appears from the squared constants (as
opposed to e2). Using that we will sum the non-positive termsPT
t=1At−1νEt[∆D(qt, qt−1,]), so
that the final condition needed to cancel this term is
512nG2M2
Ct−1µ+µ1a2
t≤At−1ν+ν1
2
which can also be rewritten as
at≤1
32Mr
(At−1ν+ν1)(Ct−1µ+µ1)
nG2
Thus, combining the previous conditions, our final update on the (at)sequence is
at= min(
Ct−1µ+µ1
12enqmaxL,
1 +b
n
at−1,b
32np
(At−1ν+ν1) min{Ct−1µ+µ1, ct−1µ+µ2}√nG)
,
as alluded to in Appx. C.4.1.
43D Implementation Details
In this section, we provide additional background on implementing DRAGO in practice. This in-
volves a description of the algorithm amenable for direct translation into code and procedures for
computing the dual proximal mapping for common uncertainty sets and penalties. We assume in
this section that W=Rdand provide multiple options for the uncertainty set Q.
D.1 Algorithm Description
The full algorithm is given in Algorithm 2. We first describe the notation. Recall that M=n/b, or
the number of blocks. We partition [n]into(B1, . . . , B M), where each BKdenotes a b-length list
of contiguous indices. For any matrix u∈Rn×m(including m= 1), we denote by u[BK]∈Rb×m
the rows of ucorresponding to the indices in BK. Finally, for a vector s∈Rb, we denote by seBK
the vector that contains skin indices k∈BK, and has zeros elsewhere. Next, we comment on
particular aspects regarding the implementation version as compared to Algorithm 1 (Sec. 2).
• We store two versions of each table, specifically ˆℓ,ˆℓ1∈Rn,ˆg1,ˆg2∈Rn×d, and ˆq1,ˆq2∈
Rn. For any iterate t, these variables are meant to store ˆℓt,ˆℓt−1∈Rn,ˆgt−1,ˆgt−2∈Rn×d,
andˆqt−1,ˆqt−2∈Rn.
• The quantities ˆgagg∈Rdandˆwagg∈Rdare introduced as to not recompute the sums in
the primal update on each iteration (which would cost O(nd)operations). Instead, these
aggregates are updated using O(bd)operations.
• The loss and gradient tables are not updated immediately after the primal update. However,
the values that fill the tables are computed, and the update occurs at the end of the loop.
This is because ˆℓ[BKt]is used to fill ˆℓ1[BKt]at the end of the loop, we we must maintain
knowledge of ˆℓ[BKt]temporarily.
• While the proximal operator is specified for the primal in the case of W=Rd, the proximal
operator for the dual os computed by a subroutine DualProx , which we describe in the next
subsection.
D.2 Solving the Maximization Problem
As discussed in Appx. B, the primary examples of DRO uncertainty sets Qare balls in f-divergence
(specifically, KL and χ2) and spectral risk measure sets. For the penalty D, it is also common to
usef-divergences. We review these concepts in this section and provide recipes for computing the
maximization problem.
f-Divergences We first recall the definition of f-divergences used throughout this section.
Definition 19. Letf: [0,∞)7→R∪{+∞}be a convex function such that f(1) = 0 ,f(x)is finite
forx > 0, and limx→0+f(x) = 0 . Let qand¯qbe two probability mass functions defined on n
atoms. The f-divergence from qto¯qgenerated by this function fis given by
Df(q∥¯q) :=nX
i=1fqi
¯qi
¯qi,
where we define 0f(0/0) := 0 . For any isuch that ¯qi= 0butqi>0, we define Df(q∥¯q) =: + ∞.
The two running examples we use are the χ2-divergence generated by fχ2(x) =x2−1and the
KL divergence generated by fKL(x) =xlnxon(0,∞)and define 0 ln 0 = 0 . For any convex set
X ⊆Rk, we also introduce the convex indicator function
ιX(x) :=0ifx∈ X
1otherwise.
In either of the two cases below, we select the penalty D(q∥1/n) = Df(q∥1/n)to be an f-
divergence. Denote in addition f∗as the Fenchel conjugate of f.
44Algorithm 2 DRAGO : Implementation Version
Input: Learning rate parameter α >0, batch size b∈ {1, . . . , n }, number of iterations T.
Initialization:
w←0dandq←1/n
ˆℓ←ℓ(w),ˆℓ1←ℓ(w),ˆg1← ∇ℓ(w),ˆg2← ∇ℓ(w),ˆq1←qandˆq2←q
ˆwK←wforK∈ {1, . . . , M }forM=n/b
ˆgagg←ˆg⊤
1ˆq1andˆwagg←PM
K=1ˆwK
¯β= 1/[16α(1 +α)(n/b−1)2]ifn/b > 1and0otherwise
fort= 1toTdo
Sample blocks ItandJtuniformly on [n/b]and compute Kt=tmod ( n/b) + 1
βt←(1−(1 +α)1−t)/(α(1 +α))
Primal Update:
g←[∇ℓi(w)]i∈BIt∈Rb×dandvP←ˆgagg+1
1+αδP.
w←1
(1+βt) 
(βt−¯β(M−1))w+¯β( ˆwagg−ˆwKt)−vP/µ
ˆwagg←ˆwagg+w−ˆwKtandˆwKt←w
Compute Loss and Gradient Table Updates:
(lt, gt)←[ℓk(w),∇ℓk(w)]k∈BKt∈Rb×Rb×d
Dual Update:
l←[ℓj(w)]j∈BJt∈Rb
δD←M(l−ˆℓ1[Jt])andvD←ˆℓ+ (l−ˆℓ[BKt])eBKt+1
1+αδDeBJt
q←DualProx( q, vD, βt) = arg max¯q∈Q
vD,¯q
−νD(¯q∥1n/n)−βtν∆D(¯q, q)	
Update All Tables:
ˆg2[BKt]←ˆg1[BKt]andˆg1[BKt]←gt
ˆℓ1[BKt]←ˆℓ[BKt]andˆℓ[BKt]←lt
ˆq2[BKt]←ˆq1[BKt]andˆq1[BKt]←q[BKt]
ˆgagg←ˆgagg+ ˆg1[BKt]⊤ˆq1[BKt]−ˆg2[BKt]⊤ˆq2[BKt]
end for
return (w, q).
D.2.1 Spectral Risk Measure Uncertainty Sets
As in Appx. B, the spectral risk measure uncertainty set is defined by a set of non-decreasing, non-
negative weights σ= (σ1, . . . , σ n)that sum to one. Our uncertainty set is given by
Q=Q(σ) := conv ( {permutations of σ)}),
and we use Dfhas the penalty for either fχ2orfKL. The set Q(σ)is referred to the permutahedron
onσ. In this case, the maximization problem can be dualized and solved via the following result.
Proposition 20. [Mehta et al., 2024, Proposition 3] Let l∈Rnbe a vector and πbe a permutation
that sorts its entries in non-decreasing order, i.e., lπ(1)≤. . .≤lπ(n). Consider a function fstrictly
convex with strictly convex conjugate defining a divergence Df. Then, the maximization over the
permutahedron subject to the shift penalty can be expressed as
max
q∈Q(σ)
q⊤l−νDf(q∥1n/n)	
= min
z∈Rn
z1≤...≤znnX
i=1gi(z;l), (78)
where we define gi(z;l) :=σiz+ν
nf∗ 
(lπ(i)−z)/ν
.The optima of both problems, denoted
zopt(l) = arg min
z∈Rn
z1≤...≤znnX
i=1gi(z;l), qopt= arg max
q∈Q(σ)q⊤l−νDf(q∥1n/n),
45are related as qopt(l) =∇(νDf(·∥1n/n))∗(l−zopt
π−1(l)),that is,
qopt
i(l) =1
n[f∗]′
1
ν(li−zopt
π−1(i)(l))
. (79)
As described in Mehta et al. [2024, Appendix C], the minimization problem (78) is an exact instance
of isotonic regression and can be solved efficiently with the pool adjacent violators (PA V) algorithm.
D.2.2 Divergence-Ball Uncertainty Sets
Another common uncertainty set format is a ball in f-divergence, or
Q=Q(ρ) :=
q∈Rn:Df(q∥1/n)≤ρ, q≥0,and1⊤q= 1	
.
We describe the case of the rescaled χ2-divergence in particular, in which the feasible set is an
ℓ2-ball intersected with the probability simplex. Given a vector l∈Rn, we aim to compute the
mapping
l7→ arg max
q∈Pn
1
2∥q−1/n∥2
2≤ρ⟨l, q⟩ −ν
2∥q−1/n∥2
2, (80)
wherePn:=
q∈Rn:q≥0,1⊤q= 1	
denotes the n-dimensional probability simplex. We apply
a similar approach to Namkoong and Duchi [2017], in which we take a partial dual of the problem
above. Indeed, note first that for any q∈ Pn, we have that1
2∥q−1n/n∥2
2=1
2∥q∥2
2−1
2n. Thus,
the optimal solution to (80) can be computed by solving
max
q∈Pnmin
λ≥0⟨l, q⟩ −ν
2∥q∥2
2−λ1
2∥q∥2
2−ρ−1
2n
,
or equivalently, by strong duality via Slater’s condition, solving
max
λ≥0
f(λ) := ( ν+λ) min
q∈Pn1
2∥q−l/(ν+λ)∥2
2−λ
ρ+1
2n
−1
2(ν+λ)∥l∥2
2
.
Notice that evaluation of the outer objective itself requires Euclidean projection onto the probability
simplex as a subroutine, after which the maximization problem can be computed via the bisection
method, as it is a univariate concave maximization problem over a convex set. In order to determine
which half to remove in the bisection search, we also compute the derivative of λ7→f(λ), which is
given by
f′(λ) :=1
2qopt(λ)2
2−ρ−1
2n,
where qopt(λ)achieves the minimum in minq∈Pn1
2∥q−l/(ν+λ)∥2
2for a fixed λ≥0. For pro-
jection onto the probability simplex, we apply Algorithm 1 from Condat [2016], which is a solution
relying on sorting the projected vector. The overall method consists of three steps.
1.Sorting: Projection onto the simplex relies on sorting the vector l/(ν+λ)on each eval-
uation. However, because l/(ν+λ)varies from evaluation to evaluation simply by mul-
tiplying by a positive scalar, we may pre-sort land use the same sorted indices on each
evaluation of (f(λ), f′(λ))listed below.
2.Two-Pointer Search: We find the upper and lower limits for λby initializing λmin= 0
andλmax= 1, and repeatedly making the replacement (λmin, λmax)←(λmax,2λmax)
untilf′(λmax)<−εfor some tolerance ε >0. This, along with f′(λmin)> εindicates
that the optimal value of λlies within (λmin, λmax). For any λwith|f′(λ)|< ε, we return
the associated qopt(λ)as the solution.
3.Binary Search: Finally, we repeatedly evaluate f′(λ)forλ= (λmin+λmax)/2. If
f′(λ)> ε, we set λmin←λ, whereas if f′(λ)<−ε, then we set λmax←λ. We
terminate when λmax−λmin< εor|f′(λ)|< ε.
46The parameter εis set to 10−10in our experiments. Note that the same procedure can be used to com-
pute the dual proximal operator in Algorithm 1. In particular, when ∆D((, q), qt−1) =1
2∥q−qt∥2
2,
which is true when Dis the χ2-divergence, then
qt= arg max
q∈Pn
1
2∥q−1/n∥2
2≤ρ
n⟨l+νβtqt, q⟩ −ν(1 +βt)
2∥q−1/n∥2
2,
which is a particular case of (80), and hence can be solved using the exact same procedure. The
runtime of this subroutine is O(nlogn+nlog(1/ε)), accounting for both the initial sorting at
O(nlogn)cost, and the O(log(1 /ε))iterations of the exponential and binary searches. Each itera-
tion requires a linear scan of nelements at cost O(n).
Hardware Acceleration Finally, note that the computations in Appx. D.2 and Appx. D.2.2 involve
primitives such as sorting, linear scanning through vectors, and binary search. Due to their serial
nature (as opposed to algorithms that rely on highly parallelizable operations such as matrix multi-
plication), we also utilize just-in-time compilation on the CPU via the Numba package for increased
efficiency.
47Dataset d n Task Source
yacht 6 244 Regression UCI
energy 8 614 Regression UCI
concrete 8 824 Regression UCI
kin8nm 8 6,553 Regression OpenML
power 4 7,654 Regression UCI
acsincome 202 4,000 Regression Fairlearn
emotion 270 8,000 Multiclass Classification Hugging Face
Table 5: Dataset attributes such as sample size n, parameter dimension d, and sources.
E Experimental Details
We describe details of the experimental setup, including datasets, compute environment, and hyper-
paramater tuning. We largely maintain the benchmarks of Mehta et al. [2023].
E.1 Datasets
The sample sizes, dimensions, and source of the datasets are summarized in Tab. 5. The tasks
associated with each dataset are listed below.
(a)yacht : predicting the residuary resistance of a sailing yacht based on its physical attributes
Tsanas and Xifara [2012].
(b)energy : predicting the cooling load of a building based on its physical attributes Baressi Segota
et al. [2020].
(c)concrete : predicting the compressive strength of a concrete type based on its physical and chem-
ical attributes Yeh [2006].
(d)kin8nm : predicting the distance of an 8 link all-revolute robot arm to a spatial endpoint [Aku-
juobi and Zhang, 2017].
(e)power : predicting net hourly electrical energy output of a power plant given environmental
factors [T ¨ufekci, 2014].
(f)acsincome : predicting income of US adults given features compiled from the American Com-
munity Survey (ACS) Public Use Microdata Sample (PUMS) [Ding et al., 2021].
(g)emotion : predicting the sentiment of sentence in the form of six emotions. Each input is a
segment of text and we use a BERT neural network Devlin et al. [2019] as an initial feature
map. This representation is fine-tuned using 2 epochs on a random half (8,000 examples) of
the original emotion dataset, and then applied to the remaining half. We then apply principle
components analysis (PCA) to reduce the dimension of each vector to 45.
E.2 Hyperparameter Selection
We fix a minibatch size of 64SGD and an epoch length of N=nfor LSVRG. In practice, the
regularization parameter µand shift cost νare tuned by a statistical metric, i.e. generalization error
as measured on a validation set.
For the tuned hyperparameters, we use the following method. Let k∈ {1, . . . , K }be a seed that
determines algorithmic randomness. This corresponds to sampling a minibatch without replacement
for SGD and SRDA and a single sampled index for LSVRG. Letting Lk(η)denote the average
value of the training loss of the last ten passes using learning rate ηand seed k, the quantity L(η) =
1
KPK
k=1Lk(η)was minimized to select η. The learning rate ηis chosen in the set {1×10−4,3×
10−4,1×10−3,3×10−3,1×10−2,3×10−2,1×10−1,3×10−1,1×100,3×100}, with two orders
of magnitude lower numbers used in acsincome due to its sparsity. We discard any learning rates
that cause the optimizer to diverge for any seed.
480 50000 10000010−810−510−2Suboptimality
yacht
0 50000 10000010−610−3100
energy
0 50000 10000010−510−2
concrete
0 1 210−610−3100
yacht
0 1 210−810−510−2
energy
0 110−510−2
concrete
0 50000 100000
First-Order Oracle Evaluations10−210−1100Suboptimality
kin8nm
0 50000 100000
First-Order Oracle Evaluations10−210−1100
power
0 200000 400000
First-Order Oracle Evaluations10−1100
emotion
0 5
Wall-Clock Time (Seconds)10−510−2
kin8nm
0 5
Wall-Clock Time (Seconds)10−610−3100
power
0 20
Wall-Clock Time (Seconds)10−510−2
emotion
SGD Drago (b= 16 ) Drago (b=n/d) Drago (b= 1)Figure 4: Benchmarks on the χ2Uncertainty Set. In both panels, the y-axis measure the primal
suboptimality gap, defined in (15). Individual plots correspond to particular datasets. Left: The
x-axis displays the number of individual first-order oracle queries to {(ℓi,∇ℓi)}n
i=1.Right: The
x-axis displays wall-clock time.
E.3 Compute Environment
Experiments were run on a CPU workstation with an Intel i9 processor, a clock speed of 2.80GHz, 32
virtual cores, and 126G of memory. The code used in this project was written in Python 3 using the
Numba packages for just-in-time compilation. Run-time experiments were conducted without CPU
parallelism. The algorithms are primarily written in PyTorch and support automatic differentiation.
E.4 Additional Experiments
We explore the sensitivity of the results to alterations of the objective and algorithm hyperparame-
ters.
Sensitivity to Uncertainty Set Choice In Sec. 4, we mainly show performance on spectral risk-
based uncertainty sets, in particular the conditional value-at-risk (CVaR). In this section, we also
consider f-divergence ball-based uncertainty sets, with the procedure described in Appx. D.2.2.
As in Namkoong and Duchi [2017], we use a radius that is inversely proportional to the sample
size, namely ρ=1
n, and the strong convexity-strong concavity parameter µ=ν= 1. In Fig. 4,
we demonstrate the performance of DRAGO withb= 1,b= 16 (as chosen heuristically), and
b=n/d. We compare against the biased stochastic gradient descent, which can be defined using
oracle to compute the optimal dual variables given a vector of losses; however, note that LSVRG is
designed only for spectral risk measures, so the method does not apply in the divergence ball setting.
We observe that the optimization performance across both regression and multi-class classification
tasks are qualitatively similar to that seen in Fig. 2 nad Fig. 3. The b= 1 variant performs well on
smaller datasets ( n≤1,000), whereas the b= 16 heuristic generally does not dominate in terms of
gradient evaluations or wall time. While the number of gradient evaluations is significantly larger
for the b=n/dvariant, implementation techniques such as just-in-time complication (see Appx. D)
allow for efficient computation, resulting in better overall optimization performance as a function of
wall time.
Sensitivity to Batch Size In Fig. 5, we consider the datasets with the largest ratio of ntod(hence
the largest theoretically prescribed batch size) and assess the performance of DRAGO with smaller
batch sizes. For both datasets, we have that in magnitude, n/d≈1000 . Intuitively, the smaller batch
size methods would perform better in terms of oracle queries but the large batch methods would be
more performant in terms of wall time. With only a batch size of b= 64 , this variant of DRAGO
generally matches the best-performing setting when viewed from either oracle calls or direct wall
time. This is approximately 16×smaller than the n/d benchmark, indicating that tuning the batch
size can significantly reduce the memory overhead of the algorithm while increasing speed.
490 50 100 150 20010−810−610−410−2100kin8nm
µ=1.0,ν=1.0
0 50 100 150 200
µ=10.0,ν=1.0
0 50 100 150 200
µ=1.0,ν=10.0
0 50 100 150 200
µ=10.0,ν=10.0
0 50 100 150 200
First-Order Oracle Evaluations (K)10−810−610−410−2100power
0 50 100 150 200
First-Order Oracle Evaluations (K)
0 50 100 150 200
First-Order Oracle Evaluations (K)
0 50 100 150 200
First-Order Oracle Evaluations (K)
0 20 40 6010−810−610−410−2100kin8nm
µ=1.0,ν=1.0
0 20 40 60
µ=10.0,ν=1.0
0 20 40 60
µ=1.0,ν=10.0
0 20 40 60
µ=10.0,ν=10.0
0 20 40 60
Wall-Clock Time (Seconds)10−810−610−410−2100power
0 20 40 60
Wall-Clock Time (Seconds)
0 20 40 60
Wall-Clock Time (Seconds)
0 20 40 60
Wall-Clock Time (Seconds)
Drago (b= 1024 ) Drago (b= 256 ) Drago (b= 64 ) Drago (b= 16 ) Drago (b= 4) Drago (b= 1)Figure 5: DRAGO on varying batch sizes and strong convexity parameters. Each row indicates a
dataset, where as each column denotes the CVaR objective with the given regularization parameters.
Top Rows: Thex-axis displays the number of individual first-order oracle queries to {(ℓi,∇ℓi)}n
i=1.
Bottom Rows: Thex-axis displays wall-clock time.
50F NeurIPS Paper Checklist
1.Claims
Question: Do the main claims made in the abstract and introduction accurately reflect the
paper’s contributions and scope?
Answer: [Yes]
Justification: Sec. 3 for direct theoretical claims and Appx. B for detailed comparisons to
other work.
Guidelines:
• The answer NA means that the abstract and introduction do not include the claims
made in the paper.
• The abstract and/or introduction should clearly state the claims made, including the
contributions made in the paper and important assumptions and limitations. A No or
NA answer to this question will not be perceived well by the reviewers.
• The claims made should match theoretical and experimental results, and reflect how
much the results can be expected to generalize to other settings.
• It is fine to include aspirational goals as motivation as long as it is clear that these
goals are not attained by the paper.
2.Limitations
Question: Does the paper discuss the limitations of the work performed by the authors?
Answer: [Yes]
Justification: See Sec. 1 and Sec. 5 for general points, whereas Sec. 4 mentions specific
cases of algorithm performance. The assumptions made are otherwise standard.
Guidelines:
• The answer NA means that the paper has no limitation while the answer No means
that the paper has limitations, but those are not discussed in the paper.
• The authors are encouraged to create a separate ”Limitations” section in their paper.
• The paper should point out any strong assumptions and how robust the results are to
violations of these assumptions (e.g., independence assumptions, noiseless settings,
model well-specification, asymptotic approximations only holding locally). The au-
thors should reflect on how these assumptions might be violated in practice and what
the implications would be.
• The authors should reflect on the scope of the claims made, e.g., if the approach was
only tested on a few datasets or with a few runs. In general, empirical results often
depend on implicit assumptions, which should be articulated.
• The authors should reflect on the factors that influence the performance of the ap-
proach. For example, a facial recognition algorithm may perform poorly when image
resolution is low or images are taken in low lighting. Or a speech-to-text system might
not be used reliably to provide closed captions for online lectures because it fails to
handle technical jargon.
• The authors should discuss the computational efficiency of the proposed algorithms
and how they scale with dataset size.
• If applicable, the authors should discuss possible limitations of their approach to ad-
dress problems of privacy and fairness.
• While the authors might fear that complete honesty about limitations might be used by
reviewers as grounds for rejection, a worse outcome might be that reviewers discover
limitations that aren’t acknowledged in the paper. The authors should use their best
judgment and recognize that individual actions in favor of transparency play an impor-
tant role in developing norms that preserve the integrity of the community. Reviewers
will be specifically instructed to not penalize honesty concerning limitations.
3.Theory Assumptions and Proofs
Question: For each theoretical result, does the paper provide the full set of assumptions and
a complete (and correct) proof?
51Answer: [Yes]
Justification: This is done for every theoretical statement.
Guidelines:
• The answer NA means that the paper does not include theoretical results.
• All the theorems, formulas, and proofs in the paper should be numbered and cross-
referenced.
• All assumptions should be clearly stated or referenced in the statement of any theo-
rems.
• The proofs can either appear in the main paper or the supplemental material, but if
they appear in the supplemental material, the authors are encouraged to provide a
short proof sketch to provide intuition.
• Inversely, any informal proof provided in the core of the paper should be comple-
mented by formal proofs provided in appendix or supplemental material.
• Theorems and Lemmas that the proof relies upon should be properly referenced.
4.Experimental Result Reproducibility
Question: Does the paper fully disclose all the information needed to reproduce the main
experimental results of the paper to the extent that it affects the main claims and/or conclu-
sions of the paper (regardless of whether the code and data are provided or not)?
Answer: [Yes]
Justification: Appx. D contains detailed descriptions of experimental details and code with
an associated environment and quickstart guide is provided.
Guidelines:
• The answer NA means that the paper does not include experiments.
• If the paper includes experiments, a No answer to this question will not be perceived
well by the reviewers: Making the paper reproducible is important, regardless of
whether the code and data are provided or not.
• If the contribution is a dataset and/or model, the authors should describe the steps
taken to make their results reproducible or verifiable.
• Depending on the contribution, reproducibility can be accomplished in various ways.
For example, if the contribution is a novel architecture, describing the architecture
fully might suffice, or if the contribution is a specific model and empirical evaluation,
it may be necessary to either make it possible for others to replicate the model with
the same dataset, or provide access to the model. In general. releasing code and data
is often one good way to accomplish this, but reproducibility can also be provided via
detailed instructions for how to replicate the results, access to a hosted model (e.g., in
the case of a large language model), releasing of a model checkpoint, or other means
that are appropriate to the research performed.
• While NeurIPS does not require releasing code, the conference does require all sub-
missions to provide some reasonable avenue for reproducibility, which may depend
on the nature of the contribution. For example
(a) If the contribution is primarily a new algorithm, the paper should make it clear
how to reproduce that algorithm.
(b) If the contribution is primarily a new model architecture, the paper should describe
the architecture clearly and fully.
(c) If the contribution is a new model (e.g., a large language model), then there should
either be a way to access this model for reproducing the results or a way to re-
produce the model (e.g., with an open-source dataset or instructions for how to
construct the dataset).
(d) We recognize that reproducibility may be tricky in some cases, in which case au-
thors are welcome to describe the particular way they provide for reproducibility.
In the case of closed-source models, it may be that access to the model is limited in
some way (e.g., to registered users), but it should be possible for other researchers
to have some path to reproducing or verifying the results.
5.Open access to data and code
52Question: Does the paper provide open access to the data and code, with sufficient instruc-
tions to faithfully reproduce the main experimental results, as described in supplemental
material?
Answer: [Yes]
Justification: The code is made public at https://github.com/ronakdm/drago.
Guidelines:
• The answer NA means that paper does not include experiments requiring code.
• Please see the NeurIPS code and data submission guidelines ( https://nips.cc/
public/guides/CodeSubmissionPolicy ) for more details.
• While we encourage the release of code and data, we understand that this might not
be possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not
including code, unless this is central to the contribution (e.g., for a new open-source
benchmark).
• The instructions should contain the exact command and environment needed to run to
reproduce the results. See the NeurIPS code and data submission guidelines ( https:
//nips.cc/public/guides/CodeSubmissionPolicy ) for more details.
• The authors should provide instructions on data access and preparation, including how
to access the raw data, preprocessed data, intermediate data, and generated data, etc.
• The authors should provide scripts to reproduce all experimental results for the new
proposed method and baselines. If only a subset of experiments are reproducible, they
should state which ones are omitted from the script and why.
• At submission time, to preserve anonymity, the authors should release anonymized
versions (if applicable).
• Providing as much information as possible in supplemental material (appended to the
paper) is recommended, but including URLs to data and code is permitted.
6.Experimental Setting/Details
Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
results?
Answer: [Yes]
Justification: See Appx. D and Appx. E for implementation and experiment details.
Guidelines:
• The answer NA means that the paper does not include experiments.
• The experimental setting should be presented in the core of the paper to a level of
detail that is necessary to appreciate the results and make sense of them.
• The full details can be provided either with the code, in appendix, or as supplemental
material.
7.Experiment Statistical Significance
Question: Does the paper report error bars suitably and correctly defined or other appropri-
ate information about the statistical significance of the experiments?
Answer: [Yes]
Justification: Training curves and hyperparameter selection experiments are averaged over
multiple seeds, but error bars are not shown to make the plots visible.
Guidelines:
• The answer NA means that the paper does not include experiments.
• The authors should answer ”Yes” if the results are accompanied by error bars, confi-
dence intervals, or statistical significance tests, at least for the experiments that support
the main claims of the paper.
• The factors of variability that the error bars are capturing should be clearly stated (for
example, train/test split, initialization, random drawing of some parameter, or overall
run with given experimental conditions).
53• The method for calculating the error bars should be explained (closed form formula,
call to a library function, bootstrap, etc.)
• The assumptions made should be given (e.g., Normally distributed errors).
• It should be clear whether the error bar is the standard deviation or the standard error
of the mean.
• It is OK to report 1-sigma error bars, but one should state it. The authors should prefer-
ably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of
Normality of errors is not verified.
• For asymmetric distributions, the authors should be careful not to show in tables or
figures symmetric error bars that would yield results that are out of range (e.g. negative
error rates).
• If error bars are reported in tables or plots, The authors should explain in the text how
they were calculated and reference the corresponding figures or tables in the text.
8.Experiments Compute Resources
Question: For each experiment, does the paper provide sufficient information on the com-
puter resources (type of compute workers, memory, time of execution) needed to reproduce
the experiments?
Answer: [Yes]
Justification: Yes, as written in Appx. E.
Guidelines:
• The answer NA means that the paper does not include experiments.
• The paper should indicate the type of compute workers CPU or GPU, internal cluster,
or cloud provider, including relevant memory and storage.
• The paper should provide the amount of compute required for each of the individual
experimental runs as well as estimate the total compute.
• The paper should disclose whether the full research project required more compute
than the experiments reported in the paper (e.g., preliminary or failed experiments
that didn’t make it into the paper).
9.Code Of Ethics
Question: Does the research conducted in the paper conform, in every respect, with the
NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines ?
Answer: [Yes]
Justification: NA
Guidelines:
• The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
• If the authors answer No, they should explain the special circumstances that require a
deviation from the Code of Ethics.
• The authors should make sure to preserve anonymity (e.g., if there is a special consid-
eration due to laws or regulations in their jurisdiction).
10.Broader Impacts
Question: Does the paper discuss both potential positive societal impacts and negative
societal impacts of the work performed?
Answer: [Yes]
Justification: It is written after the main text of the paper.
Guidelines:
• The answer NA means that there is no societal impact of the work performed.
• If the authors answer NA or No, they should explain why their work has no societal
impact or why the paper does not address societal impact.
• Examples of negative societal impacts include potential malicious or unintended uses
(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
(e.g., deployment of technologies that could make decisions that unfairly impact spe-
cific groups), privacy considerations, and security considerations.
54• The conference expects that many papers will be foundational research and not tied
to particular applications, let alone deployments. However, if there is a direct path to
any negative applications, the authors should point it out. For example, it is legitimate
to point out that an improvement in the quality of generative models could be used to
generate deepfakes for disinformation. On the other hand, it is not needed to point out
that a generic algorithm for optimizing neural networks could enable people to train
models that generate Deepfakes faster.
• The authors should consider possible harms that could arise when the technology is
being used as intended and functioning correctly, harms that could arise when the
technology is being used as intended but gives incorrect results, and harms following
from (intentional or unintentional) misuse of the technology.
• If there are negative societal impacts, the authors could also discuss possible mitiga-
tion strategies (e.g., gated release of models, providing defenses in addition to attacks,
mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
feedback over time, improving the efficiency and accessibility of ML).
11.Safeguards
Question: Does the paper describe safeguards that have been put in place for responsible
release of data or models that have a high risk for misuse (e.g., pretrained language models,
image generators, or scraped datasets)?
Answer: [No]
Justification: Generative and related large-scale models are not used in this work.
Guidelines:
• The answer NA means that the paper poses no such risks.
• Released models that have a high risk for misuse or dual-use should be released with
necessary safeguards to allow for controlled use of the model, for example by re-
quiring that users adhere to usage guidelines or restrictions to access the model or
implementing safety filters.
• Datasets that have been scraped from the Internet could pose safety risks. The authors
should describe how they avoided releasing unsafe images.
• We recognize that providing effective safeguards is challenging, and many papers do
not require this, but we encourage authors to take this into account and make a best
faith effort.
12.Licenses for existing assets
Question: Are the creators or original owners of assets (e.g., code, data, models), used in
the paper, properly credited and are the license and terms of use explicitly mentioned and
properly respected?
Answer: [Yes]
Justification: NA
Guidelines:
• The answer NA means that the paper does not use existing assets.
• The authors should cite the original paper that produced the code package or dataset.
• The authors should state which version of the asset is used and, if possible, include a
URL.
• The name of the license (e.g., CC-BY 4.0) should be included for each asset.
• For scraped data from a particular source (e.g., website), the copyright and terms of
service of that source should be provided.
• If assets are released, the license, copyright information, and terms of use in the
package should be provided. For popular datasets, paperswithcode.com/
datasets has curated licenses for some datasets. Their licensing guide can help
determine the license of a dataset.
• For existing datasets that are re-packaged, both the original license and the license of
the derived asset (if it has changed) should be provided.
55• If this information is not available online, the authors are encouraged to reach out to
the asset’s creators.
13.New Assets
Question: Are new assets introduced in the paper well documented and is the documenta-
tion provided alongside the assets?
Answer: [Yes]
Justification: Documented code is provided.
Guidelines:
• The answer NA means that the paper does not release new assets.
• Researchers should communicate the details of the dataset/code/model as part of their
submissions via structured templates. This includes details about training, license,
limitations, etc.
• The paper should discuss whether and how consent was obtained from people whose
asset is used.
• At submission time, remember to anonymize your assets (if applicable). You can
either create an anonymized URL or include an anonymized zip file.
14.Crowdsourcing and Research with Human Subjects
Question: For crowdsourcing experiments and research with human subjects, does the pa-
per include the full text of instructions given to participants and screenshots, if applicable,
as well as details about compensation (if any)?
Answer: [NA]
Justification: Human participants are not used.
Guidelines:
• The answer NA means that the paper does not involve crowdsourcing nor research
with human subjects.
• Including this information in the supplemental material is fine, but if the main contri-
bution of the paper involves human subjects, then as much detail as possible should
be included in the main paper.
• According to the NeurIPS Code of Ethics, workers involved in data collection, cura-
tion, or other labor should be paid at least the minimum wage in the country of the
data collector.
15.Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
Subjects
Question: Does the paper describe potential risks incurred by study participants, whether
such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
approvals (or an equivalent approval/review based on the requirements of your country or
institution) were obtained?
Answer: [NA]
Justification: No IRM approvals were needed for this work.
Guidelines:
• The answer NA means that the paper does not involve crowdsourcing nor research
with human subjects.
• Depending on the country in which research is conducted, IRB approval (or equiva-
lent) may be required for any human subjects research. If you obtained IRB approval,
you should clearly state this in the paper.
• We recognize that the procedures for this may vary significantly between institutions
and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
guidelines for their institution.
• For initial submissions, do not include any information that would break anonymity
(if applicable), such as the institution conducting the review.
56