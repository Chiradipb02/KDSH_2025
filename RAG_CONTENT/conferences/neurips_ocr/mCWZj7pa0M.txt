Exact Gradients for Stochastic Spiking Neural
Networks Driven by Rough Signals
Christian Holberg
Department of Mathematics
University of Copenhagen
c.holberg@math.ku.dkCristopher Salvi
Department of Mathematics
Imperial College London
c.salvi@imperial.ac.uk
Abstract
We introduce a mathematically rigorous framework based on rough path theory
to model stochastic spiking neural networks (SSNNs) as stochastic differential
equations with event discontinuities (Event SDEs) and driven by càdlàg rough
paths. Our formalism is general enough to allow for potential jumps to be present
both in the solution trajectories as well as in the driving noise. We then identify a
set of sufficient conditions ensuring the existence of pathwise gradients of solution
trajectories and event times with respect to the network’s parameters and show
how these gradients satisfy a recursive relation. Furthermore, we introduce a
general-purpose loss function defined by means of a new class of signature kernels
indexed on càdlàg rough paths and use it to train SSNNs as generative models.
We provide an end-to-end autodifferentiable solver for Event SDEs and make its
implementation available as part of the diffrax library. Our framework is, to
our knowledge, the first enabling gradient-based training of SSNNs with noise
affecting both the spike timing and the network’s dynamics.
1 Introduction
Stochastic differential equations exhibiting event discontinuities (Event SDEs) and driven by noise
processes with jumps are an important modelling tool in many areas of science. One of the most
notable examples of such systems is that of stochastic spiking neural networks (SSNNs). Several
models for neuronal dynamics have been proposed in the computational neuroscience literature with
thestochastic leaky integrate-and-fire (SLIF) model being among the most popular choices [ 19,56].
In its simplest form, given some continuous input current iton[0, T], the dynamics of a single SLIF
neuron consist of an Ornstein-Uhlenbeck process describing the membrane potential as well as a
threshold for spike triggering and a resetting mechanism [ 33]. In particular, between spikes, the
dynamics of the membrane potential vtis given by the following SDE
dvt=µ(it−vt)dt+σdB t, (1)
where µ >0is a parameter and Btis a standard Brownian motion. The neuron spikes whenever the
membrane potential vhits the threshold ψ >0upon which vis reset to 0. Alternatively, one can
model the spike times as a Poisson process with intensity λ:R→R+depending on the membrane
potential vt. A common choice is λ(v) = exp(( v−ψ)/β)[50, 26, 27, 24].
A notorious issue for calibrating Event SDEs such as SSNNs is that the implicitly defined event
discontinuities, e.g., the spikes, make it difficult to define derivatives of the solution trajectories and
of the event times with respect to the network’s parameters using classical calculus rules. This issue
is exacerbated when the dynamics are stochastic in which case the usual argument relying on the
implicit function theorem, used for instance in [6, 25], is no longer valid.
38th Conference on Neural Information Processing Systems (NeurIPS 2024).1.1 Contributions
In this paper, we introduce a mathematically rigorous framework to model SSNNs as SDEs with
event discontinuities and driven by càdlàg rough paths, without any prior knowledge of the timing of
events. The mathematical formalism we adopt is that of rough path theory [38], a modern branch
of stochastic analysis providing a robust solution theory for stochastic dynamical systems driven by
noisy, possibly discontinuous, rough signals . Although Brownian motion is a prototypical example,
these signals can be far more irregular (or rougher) than semimartingales [17, 16, 39].
Equipped with this formalism, we proceed to identify sufficient conditions under which the solution
trajectories and the event times are differentiable with respect to the network’s parameters and obtain
a recursive relation for the exact pathwise gradients in Theorem 3.2. This is a strict generalization
of the results presented in [ 6] and [ 25] which only deal with ordinary differential equations (ODEs).
Furthermore, we define Marcus signature kernels as extensions of continuous signature kernels [ 52]
to càdlàg rough paths and show their characteristicness. We then make use of this class of kernels
indexed on discontinuous trajectories to define a general-purpose loss function enabling the training
of SSNNs as generative models. We provide an end-to-end autodifferentiable solver for Event SDEs
(Algorithm 1) and make its implementation available as part of the diffrax library [28].
Our framework is, to our knowledge, the first allowing for gradient-based training of a large class of
SSNNs where a noise process can be present in both the spike timing and the network’s dynamics. In
addition, we believe this work is the first enabling the computation of exact gradients for classical
SNNs whose solutions are approximated via a numerical solver (not necessarily based on a Euler
scheme). In fact, previous solutions are based either on surrogate gradients [ 46] or follow an optimise-
then-discretise approach deriving adjoint equations [ 56], the latter yielding exact gradients only in the
scenario where solutions are available in closed form and not approximated via a numerical solver.1
Finally, we discuss how our results lead to bioplausible learning algorithms akin to e-prop [2].
2 Related work
Neural stochastic differential equations (NSDEs) The intersection between differential equations
and deep learning has become a topic of great interest in recent years. A neural ordinary differential
equation (NODE) is an ODE of the form dyt=fθ(yt)dtstarted at y0∈Reusing a parametric
Lipschitz vector field fθ:Re→Re, usually given by a neural network [ 5]. Similarly, a neural
stochastic differential equation (NSDE) is an SDE of the form dyt=µθ(yt)dt+σθ(yt)dBtdriven
by a d-dimensional Brownian motion B, started at y0∈Re, and with parametric vector field
µθ:Re→Reandσθ:Re→Re×dthat are Lip1and Lip2+ϵcontinuous respectively2. Rough path
theory offers a way of treating ODEs, SDEs, and more generally differential equations driven by
signals or arbitrary (ir)regularity, under the unified framework of rough differential equations (RDEs)
[44, 22]. For an account on applications of rough path theory to machine learning see [4, 14, 51].
Training techniques for NSDEs Training a NSDE amounts to minimising over model parameters
an appropriate notion of statistical divergence between a distribution of continuous trajectories
generated by the NSDE and an empirical distribution of observed sample paths. Several approaches
have been proposed in the literature, differing mostly in the choice of discriminating divergence. SDE-
GANs, introduced in [ 29], use the 1-Wasserstein distance to train a NSDE as a Wasserstein-GAN [ 1].
Latent SDEs [ 36] train a NSDE with respect to the KL divergence via variational inference and can be
interpreted as variational autoencoders. In [ 23] the authors propose to train NSDEs non-adversarially
using a class of maximum mean discrepancies (MMD) endowed with signature kernels [ 30,52].
Signature kernels are a class of characteristic kernels indexed on continuous paths that have received
increased attention in recent years thanks to their efficiency for handling path-dependent problems
[35,54,10,53,9,48,41]. For a treatment of this topic we refer the interested reader to [ 4, Chapter 2].
These kernels are not applicable to sample trajectories of SSNNs because of the lack of continuity.
Backpropagation through NSDEs Once a choice of discriminator has been made, training NSDEs
amounts to perform backpropagation through the SDE solver. There are several ways to do this. The
1The point here is actually a little more subtle. It is in fact possible to obtain exact gradients using the adjoint
method as long as one uses reversible (or adjoint) solvers in the forward pass.
2These are standard regularity conditions to ensure existence and uniqueness of a strong solution.
2first option is simply to backpropagate through the solver’s internal operations. This method is known
asdiscretise-then-optimise ; it is generally speaking fast to evaluate and produces accurate gradients,
but it is memory-inefficient, as every internal operation of the solver must be recorded. A second
approach, known as optimise-then-discretise , computes gradients by deriving a backwards-in-time
differential equation, the adjoint equation , which is then solved numerically by another call to the
solver. Not storing intermediate quantities during the forward pass enables model training at a
memory cost that is constant in depth. Nonetheless, this approach produces less accurate gradients
and is usually slower to evaluate because it requires recalculating the forward solutions to perform the
backward pass. A third way of backpropagating through NDEs is given by algebraically reversible
solvers , offering both memory and accuracy efficiency. We refer to [28] for further details.
Differential equations with events Many systems are not adequately modelled by continuous
differential equations because they experience jump discontinuities triggered by the internal state of
the system. Examples include a bouncing ball or spiking neurons. Such systems are often referred
to as (stochastic) hybrid systems [21,37]. When the differential equation is an ODE, there is a rich
literature on sensitivity analysis aimed at computing derivatives using the implicit function theorem
[11,12]. If, additionally, the vector fields describing the hybrid system are neural networks, [ 6] show
that NODEs solved up until first event time can be implemented as autodifferentiable blocks and [ 25]
derive the corresponding adjoint equations. Nonetheless, none of these works cover the more general
setting of SDEs. The only work, we are familiar with, dealing with sensitivity analysis in this setting
is [47], although focused on the problem of optimal control.
Training techniques for SNNs Roughly speaking, these works can be divided into two strands. The
first, usually referred to as backpropagation through time (BPTT), starts with a Euler approximation
of the SNN and does backpropagation by unrolling the computational graph over time; it then
uses surrogate gradients as smooth approximations of the gradients of the non-differentiable terms.
[58,46,40]. This approach is essentially analogous to discretise-then-optimise where the backward
pass uses custom gradients for the non-differentiable terms. The second strand computes exact
gradients of the spike times using the implicit function theorem. These results are equivalent to
optimise-then-discretise and can be used to define adjoint equations as in [ 56] or to derive forward
sensitivities [ 34]. However, we note that, unless solution trajectories and spike times of the SNN
are computed exactly, neither method provides the actual gradients of the implemented solver.
Furthermore, the BPTT surrogate gradient approach only covers the Euler approximation whereas
many auto-differentiable differential equation solvers are available nowadays, e.g. in diffrax .
Finally, there is a lot of interest in developing bioplausible learning algorithms where weights can be
updated locally and in an online fashion. Notable advances in this direction include [ 2,57]. To the
best of our knowledge, none of these works cover the case of stochastic SNNs where the neuronal
dynamics are modeled as SDEs instead of ODEs.
3 Stochastic spiking neural networks as Event SDEs
We shall in this paper be concerned with SDEs where solution trajectories experience jumps triggered
by implicitly defined events, dubbed Event SDEs . The prototypical example that we come back to
throughout is the SNN model composed of SLIF neurons. Here the randomness appears both in the
inter-spike dynamics as well as in the firing mechanism. To motivate the general definitions and
concepts we start with an informal introduction of SSNNs.
3.1 Stochastic spiking neural networks
To achieve a more bioplausible model of neuronal behaviour, one can extend the simple deterministic
LIF model by adding two types of noise: a diffusion term in the differential equation describing
inter-spike behaviour [ 33] and stochastic firing [ 50,27]. That is, the potential is modelled by eq. (1).
Instead of firing exactly when the membrane potential hits a set threshold, we model the spike times
(event times) by an inhomogenous Poisson process with intensity λ:Re→R+which is assumed
to be bounded by some constant C > 0. This can be phrased as an Event SDE (note that this is
essentially the reparameterisation trick) by introducing the additional state variable stsatisfying
dst=λ(vt−)dt, s 0= log u
3where u∼Unif(0,1). The neuron spikes whenever sthits0from below at which point the membrane
potential is reset to a resting level and we sample a new initial condition for st. We can denote this
first spike time by τ1and repeat the procedure to generate a sequence of spike times τ1< τ2< ... In
practice, we reinitialize statlogu−αfor some α >0. It can then be shown that
P(t < τ n+1|Fτn) = min
1,exp
α−Zt
τnλ(vt−)dt
fort∈[τn, τn+1).
It follows that τn+1−τn≥α/C a.s., i.e. αcontrols the refractory period after spikes, a large value
indicating a long resting period.
We can then build a SSNN by connecting such SLIF neurons in a network. In particular, apart from
the membrane potential, we now also model the input current of each neuron as affected by the other
neurons in the network. Let K≥1denote the total number of neurons. We model neuron k∈[K]
be the three dimensional vector yk= (vk, ik, sk)the dynamic of which in between spikes is given by
dvk
t=µ1 
ik
t−vk
t
dt+σ1dBk
t, dik
t=−µ2ik
tdt+σ2dBk
t, dsk
t=λ(vk
t;ξ)dt, (2)
where Bkis a standard two-dimensional Brownian motion, σ= (σ1, σ2)∈R2×2,µ= (µ1, µ2)∈
R2, and λ(·;ξ) :R→R+is an intensity function. As before, neuron kfires (or spikes) whenever
skhits zero from below. Apart from resetting the membrane potential, this event also causes spikes
to propagate through the network in a such a way that a spike in neuron kwill increment the input
current of neuron jbywkj. Here w∈RK×Kis a matrix of weights representing the synaptic
weights in the neural network. If one is only interested in specific network architectures such as, e.g.,
feed-forward, this can be achieved by fixing the appropriate entries in wat 0.
As presented here, there is no way to model information coming into the network. But this would
only require a minor change. Indeed, by adding a suitable control term to eq. (2) we can model all
relevant scenarios. Since this does not change the theory in any meaningful way (the general theory
in Appendix B covers RDEs so an extra smooth control is no issue), we only discuss the more simple
model given without any additional input currents.
3.2 Model definition
Definition 3.1 (Event SDE) .LetN∈Nbe the number of events. Let y0∈Rebe an initial condition.
Letµ:Re→Reandσ:Re→Re×dbe the drift and diffusion vector fields. Let E:Re→Rand
T:Re→Rebe an event and transition function respectively. We say that 
y,(τn)N
n=1
is a solution
to the Event SDE parameterised by (y0, µ, σ,E,T, N)ifyT=yN
T,
yt=NX
n=0yn
t1[τn,τn+1)(t), τ n= inf
t > τ n−1:E(yn−1
t) = 0	
, (3)
withE(yn
τn)̸= 0and
dy0
t=µ(y0
t)dt+σ(y0
t)dBt,started at y0
0=y0, (4)
dyn
t=µ(yn
t)dt+σ(yn
t)dBt,started at yn
τn=T 
yn−1
τn
, (5)
where Btis ad-dimensional Brownian motion and (4), (5) are Stratonovich SDEs.
In words, we initialize the system at y0, evolve it using (4)until the first time τ1at which an event
happens E(y0
τ1) = 0 . We then transition the system according to y1
τ1=T 
y0
τ1−
and evolve it
according to (5)until the next event is triggered. We note that Definition 3.1 can be generalised to
multiple event and transition functions. Also, the transition function can be randomised by allowing
it to have an extra argument u∼Unif([0,1]). As part of the definition we require that there are only
finitely many events and that an event is not immediately triggered upon transitioning.
Existence of strong solutions to Event SDEs driven by continuous semimartingales has been studied
in [31, Theorem 5.2] and [ 32]. Under sufficient regularity of µandσ, a unique solution to (4)exists.
We need the following additional assumptions:
Assumption 3.1.There exists c > 0such that for all s∈(0, T)anda∈imTit holds that
inf{t > s :E(yt) = 0}> cwhere ytis the solution to 4 started at ys=a
4Assumption 3.2.It holds that T(kerE)∩ E=∅.
Assumptions 3.1 and 3.2 simply ensure that an event cannot be triggered immediately upon tran-
sitioning. This holds in most settings of interest. For example, for the usual deterministic LIF
neuron imT= 0andkerE= 1and the duration of the refractory period is directly linked to cin
Assumption 3.1.
Theorem 3.1 (Theorem 5.2, [ 31]).Under Assumptions 3.1-3.2 and with µ∈Lip1andσ∈Lipγfor
γ >2, there exists a unique solution (y,(τn)N
n=1)to the Event SDE of Definition 3.1.
The definitions and results of this section can be extended to differential equations driven by random
rough paths, and in particular, to cases where the driving noise exhibits jumps. In the latter case, it
is important to note that the resulting Event SDE will exhibit two types of jumps: the ones given
apriori by the driving noise and the ones that are implicitly defined through the solution (what we
callevents ). In fact, we develop the main theory of Event RDEs in Appendix A in the more general
setting of RDEs driven by càdlàg rough paths. The rough path formalism enables a unified treatment
of differential equations driven by noise signals of arbitrary (ir-)regularity, and makes all proofs
simple and systematic. In particular, it allows us to handle cases where the diffusion term is driven by
a finite activity Lévy process (e.g, a homogeneous Poisson processes highly relevant in the context of
SNNs).
3.3 Backpropagation
We are interested in optimizing a continuously differentiable loss function Lwhose input is the
solution of a parameterised Event SDE. As for Neural ODEs, the vector fields, µ, σ, and the event
and transition functions E,T, might depend on some learnable parameters θ. We can move the
parameters θof the Event RDE inside the initial condition y0by augmenting the dynamics with the
additional state variable θtsatisfying dθt= 0andθ0=θ. Thus, as long as we can compute gradients
with respect to y0, these will include gradients with respect to such parameters. We then require the
gradients ∂y0L, if they exist. For this, we need to be able to compute the Jacobians ∂yn
t:=∂y0yn
tof
the inter-event flows associated to the dynamics of yn
tand the derivatives ∂τn:=∂y0τn. We assume
that the event and transition functions EandTare continuously differentiable.
Apriori, it is not clear under what conditions such quantities exist and even less how to compute them.
This shall be the focus of the present section. We will need the following running assumptions.
Assumption 3.3.σ(T(y))− ∇T (y)σ(y) = 0 for all y∈kerE.
Assumption 3.4.∇E(y)σ(y) = 0 for all y∈kerE.
Assumption 3.5.∇E(y)µ(y)̸= 0for all y∈kerE.
Assumption 3.4 and 3.5 ensure that the event times are differentiable. Intuitively, they state that the
event condition is hit only by the drift part of the solution. Assumption 3.4 holds for example if the
event functions depend only on a smooth part of the system. Assumption 3.3 is what allows us to
differentiate through the event transitions.
Theorem 3.2. Let Assumptions 3.1-3.5 be satisfied and (y,(τn)N
n=1)the solution to the Event SDE
parameterized by (y0, µ, σ,E,T, N). Then, almost surely, for any n∈[N], the derivatives ∂τnand
the Jacobians ∂yn
texist and admit the following recursive expressions
∂τn=−∇E(yn−1
τn)∂yn−1
τn
∇E(yn−1τn)µ(yn−1τn)(6)
∂yn
t= (∂ynτnyn
t)
∇T(yn−1
τn)∂yn−1
τn− 
µ(yn
τn)− ∇T (yn−1
τn)µ(yn−1
τn)
∂τn
. (7)
where ∂yn
tand∂τnare the total derivatives of yt
nandτnwith respect to the initial condition y0,
∂ynτnyn
tdenotes the partial derivative of the flow map of eq. (5)with respect to its initial condition,
and∇T ∈ Re×eand∇E ∈ R1×eare the Jacobians of TandE.
Remark 3.1.If the diffusion term is absent we recover the gradients in [ 6]. In this case, the
assumptions of the theorem are trivially satisfied. Note however, that the result, as stated here, is
slightly different since we are considering repeated events.
Remark 3.2.The recursive nature of (6)-(7)suggest a way to update gradients in an online fashion
by computing the forward sensitivity along with the state of the Event SDE. In traditional machine
5learning applications (e.g. NDEs) forward mode automatic differentiation is usually avoided due
to the fact that the output dimension tends to be orders of magnitude smaller than the number of
parameters [28]. However, for (S)SNNs this issue can be partly avoided as discussed in Section 4.4.
Returning now to the SSNN model introduced in Section 3.1 we find that it is an Event SDE with K
different event functions given by Ek(y) =skand corresponding transition functions given by
Tk(y) = 
T1
k(y1), . . . ,TK
k(yK)
where Tj
k(yj) = ( vj, ij+wkj, sj)ifj̸=kandTk
k(yk) = ( vk−vreset, ik,logu−α)where
vreset>0is a constant determining by what amount the membrane potential is reset. The addition of
the constant α >0controlling the refractory period ensures that Assumption 3.2 and 3.2 are satisfied.
Stochastic firing smooths out the event triggering so that Assumption 3.5 and 3.4 hold. Finally, one
can check that the combination of constant diffusion terms and the given transition functions satisfies
Assumptions 3.3. Note that setting vk
texactly to 0 upon spiking would break Assumption 3.3. If one
is interested in such a resetting mechanism it suffices to pick a diffusion term σ1(yk)that satisfies
σ(0) = 0 . To sum up, solutions (in the sense of Def. 3.1) of the SSNNs exist and are unique. In
addition, the trajectories and spike times are almost surely differentiable satisfying (6) and (7).
3.4 Numerical solvers
Theorem 3.2 gives an expression for the gradients of the event times as well as the Event SDE
solution. In practice, analytical expressions for gradients are often not available and one has to resort
to numerical solvers. Three solutions suggest themselves:
1.There are multiple autodifferentiable differential equation solvers (such as diffrax [28])
that provide differentiable numerical approximations of the flows ∂ynτnyn
t. We shall
write SDESolve (y0, µ, σ, s, t )for a generic choice of such a solver. Furthermore, if
RootFind (y0, f)is a differentiable root finding algorithm (here f: (y, t)7→Rshould be dif-
ferentiable in both arguments and RootFind (y0, f)returns t∗∈Rsuch that f(y0, t∗) = 0 ),
then we can define a differentiable map E:y07→y∗by
t∗=RootFind (y0,E(SDESolve (·, µ, σ, s, ·))), y∗=SDESolve (y0, µ, σ, s, t∗).
Consequently, EventSDESolve (y0, µ, σ,E,T, N)can be implemented as subsequent com-
positions of T ◦E(see Algorithm 1). This is a discretise-then-optimise approach [28].
2.Alternatively, one can use the formulas (6)and(7)directly as a replacement of the derivatives.
This is the approach taken in e.g. [ 6]. To be precise, one would replace all the derivatives of
the flow map (terms of the sort ∂yn
τnyn
t) with the derivatives of the given numerical solver.
This approach is a solution between discretise-then-optimise and optimise-then-discretise.
3.Finally, one could apply the adjoint method (or optimise-then-discretise) as done for de-
terministic SNNs in [ 56] by deriving the adjoint equations. These adjoint equations define
another SDE with jumps which is solved backwards in time. Between events the dynamics
are exactly as in the continuous case so one just needs to specify the jumps of the adjoint
process. This can be done by referring to (6) and (7).
Remark 3.3.One thing to be careful of with the discretise-then-optimise approach is that the SDE
solver will compute time derivatives in the backward pass, although the modelled process is not time
differentiable. Assumptions 3.4 and 3.3 should in principle guarantee that these derivatives cancel out
(see Appendix B), yet this might not necessarily happen at the level of the numerical solver because of
precision issues. This is essentially due to the fact that approximate solutions provided by numerical
solvers are in general not flows . Thus, when the path driving the diffusion term is very irregular, the
gradients can become unstable. In practice we found this could be fixed by setting the gradient with
respect to time of the driving Brownian motion to 0and picking a step size sufficiently small.
Remark 3.4.In the context of SNNs, Algorithm 1 is actually a version of exact backpropagation
through time (BPTT) of the unrolled numerical solution. Contrary to popular belief, this illustrates
that one can compute exact gradients of numerical approximations of SNNs without the need to resort
to surrogate gradient functions. Of course, this does not alleviate the so-called dead neuron problem .
However, this ceases to be a problem when stochastic firing is introduced. In fact, surrogate gradients
can be related to stochastic firing mechanisms and expected gradients [20].
6Remark 3.5.One the one hand, the EventSDESolve algorithm as presented here scales poorly in the
number of events since it requires doing a full SDESolve and an additional RootFind each time an
event occurs. This problem becomes especially prevalent for SSNNs with a large number of neurons
since in this case an event is triggered every time a single neuron spikes and the inter-spike SDE that
needs to be solved is high-dimensional. On the other hand, there are multiple ways to mitigate this
issue. Firstly, one could relax the root-finding step and simply trigger a spike as soon as e≥0and
take this as the spike time. For the backward pass one could then solve the adjoint equations (for
which you need need to store the spike times in the forward pass). The resulting algorithm would be
similar to the one derived in [55] for deterministic SNNs. Secondly, for special architectures such
as a feed-forward network, given the spikes from the previous layer, one could solve the EventSDE
for each neuron in the current layer independently of all other neurons. This would imply that a
forward (or backward) pass of the entire SSNN scales as O(KS)where Sis the cost of the forward
(or backward) pass of a single neuron and Kis the number of neurons.
Algorithm 1 EventSDESolve
Input y0, µ, σ,E,T, N, t 0,∆t, T
1:y←y0
2:n←0
3:e← E(y)
4:while n < N andt0< T do
5: while e <0do ▷We assume for simplicity that e≤0
6: y0←y
7: y←SDESolveStep (y0, µ, σ, t 0,∆t)
8: t0←t0+ ∆t
9: e← E(y) ▷Update value of event function
10: end while
11: t∗
n+1←RootFind (y0,E(SDESolveStep (·, µ, σ, t 0−∆t,·))) ▷Find exact event time
12: y∗
n+1←SDESolveStep (y0, µ, σ, t 0−∆t, t∗
n+1) ▷Compute state at event time
13: y← T(y∗
n+1) ▷Apply transition function
14: n←n+ 1
15:end while
Return (t∗
n)n≤N,y
4 Training stochastic spiking neural networks
4.1 A loss function based on signature kernels for càdlàg paths
To train SSNNs we will adopt a similar technique as in [ 23], where the authors propose to train
NSDEs non-adversarially using a class of maximum mean discrepancies (MMD) endowed with
signature kernels [ 52] indexed on spaces of continuous paths as discriminators. However, as we
mentioned in the introduction, classical signature kernels are not directly applicable to the setting
of SSNNs as the solution trajectories not continuous. To remedy this issue, in Appendix C, we
generalise signature kernels to Marcus signature kernels indexed on discontinuous (or càdlàg) paths.
We note that our numerical experiments only concern learning from spike trains, which are càdlàg
paths of bounded variation. Yet, the Marcus signature kernel defined in Appendix C can handle more
general càdlàg rough paths.
The main idea goes as follows. If xis a càdlàg path, one can define the Marcus signature S(x)in
the spirit of Marcus SDEs [ 42,43] as the signature of the Marcus interpolation ofx. The general
construction is given in Appendix A. The Marcus signature kernel is defined as the inner product
k(x, y) =⟨S(x), S(y)⟩of Marcus signatures S(x), S(y)of two càdlàg paths x, y. As stated in the
first part of Theorem C.1, this kernel is characteristic on regular Borel measures supported on compact
sets of càdlàg paths. In particular, this implies that the resulting maximum mean discrepancy (MMD)
dk(µ, ν)2=Ex,x′∼µk(x, x′)−2Ex,y∼µ×νk(x, x′) +Ey,y′∼νk(y, y′)
satisfies the property dk(µ, ν)2= 0⇐⇒ µ=νfor any two compactly supported measures µ, ν.
Nonetheless, characteristicness ceases to hold when one considers measures on càdlàg paths that
are not compactly supported. In [ 8] the authors address this issue for continuous paths by using the
7so-called robust signature . They introduce a tensor normalization Λensuring that the range of the
robust signature Λ◦Sremains bounded. The robust signature kernel is then defined as the inner
product kΛ(x, y) =⟨Λ◦S(x),Λ◦S(y)⟩. This normalization can be applied analogously to the
Marcus signature resulting in a robust Marcus signature kernel . In the second part of Theorem C.1,
we prove characteristicness of kΛfor possibly non-compactly supported Borel measures on càdlàg
paths. The resulting MMD is denoted by dkΛ.
There are several ways of evaluating signature kernels. The most naive is to simply truncate the
signatures at some finite level and then take their inner product. Another amounts to solve a path-
dependent wave equation [52]. Our experiments are compatible with both of these methods.
Given a collection of observed càdlàg trajectories {xi}m
i=1∼µtruesampled from an underlying
unknown target measure µtrue, we can train an Event SDE by matching the generated càdlàg trajec-
tories{yi}n
i=1∼µθusing an unbiased empirical estimator of dk(ordkΛ), i.e. minimising over the
parameters θof the Event SDE the following loss function
L=1
m(m−1)X
j̸=ik(xi, xj)−2
mnX
i,jk(xi, yj) +1
n(n−1)X
j̸=ik(yi, yj).
In the context of SSNNs, the observed and generated trajectories xi’s and yi’s correspond to spike
trains, which are càdlàg paths of bounded variation.
4.2 Input current estimation
The first example is the simple problem of estimating the constant input current c >0based on a
sample of spike trains in the single SLIF neuron model,
dvt=µ(c−vt)dt+σdB t, ds t=λ(vt)dt,
where λ(v) = exp(5( v−1),µ= 15 andσvaries. Throughout we fix the true c= 1.5and set
vreset = 1.4andα= 0.03. We run stochastic gradient descent for 1500 steps for two choices of the
diffusion constant σ. The loss function is the signature kernel MMD between a simulated batch and
the sample of spike trains.3. The test loss is the mean absolute error between the first three average
spike times. Results are given in Fig. 1. For additional details regarding the experiments, we refer to
Appendix E.
In all cases backpropagation through Algorithm 1 is able to learn the underlying input current after
around 600 steps up to a small estimation error. In particular, the convergence is fastest for the largest
sample size and the true cis recovered for both levels of noise.
4.3 Synaptic weight estimation
Next we consider the problem of estimating the weight matrix in a feed-forward SSNN with input
dimension 4, 1 hidden layer of dimension 16, and output dimension 2. The rest of the parameters are
fixed throughout. We run stochastic gradient descent for 1500 steps with a batch size of 128 and for a
sample size of 256,512, and 1024 respectively. Learning rate is decreased from 0.003to0.001after
1000 steps. The results are given in Fig. 2 in Appendix E. For a sample size of 512and1024 we are
able to reach a test loss of practically 0, that is, samples from the learned model and the underlying
model are more or less indistinguishable. Also, in all cases the estimated weight matrix approaches
the true weight matrix. Interestingly, for the largest sample size, the model reaches the same test loss
as the model trained on a sample size of 512, but their estimated weight matrices differ significantly.
4.4 Online learning
In the case of SSNNs, equations (6)-(7)lead to a formula for the forward sensitivity where any
propagation of gradients between neurons only happens at spike times and only between connected
neurons (see Proposition D.1). Since the forward sensitivities are computed forward in time together
with the solution of the SNN, gradients can be updated online as new data appears. As a result,
between spikes of pre-synaptic neurons, we can update the gradient flow of the membrane potential
3For simplicity we only compute an approximation of the true MMD by truncating the signatures at depth 3
and taking the average across the batch/sample size.
80 250 500 750 1000 1250 150001234Test lossσ= 0.25
Sample size
16
32
64
128
0 250 500 750 1000 1250 15000.60.81.01.21.4cσ= 0.25
0 250 500 750 1000 1250 1500
Step01234Test lossσ= 0.5
Sample size
16
32
64
128
0 250 500 750 1000 1250 1500
Step0.60.81.01.21.4cσ= 0.5Figure 1: Test loss and cestimate across four sample sizes and for two levels of noise σ. On the left: MAE for
the three first average spike times on a hold out test set. On the right: estimated value of cat the current step.
and input current of each neuron using information exclusively from that neuron. For general network
structures and loss functions, however, this implies that each neuron needs to store on the order of
K2gradient flows (one for each weight in the network).
On the other hand, if the adjacency matrix of the weight matrix forms a directed acyclic graph (DAG),
three-factor Hebbian learning rules like those in [ 57,2] are easily derived from Proposition D.1. For
simplicity, consider the SNN consisting of deterministic LIF neurons and let Nk
tdenote the spike
train of neuron k, i.e., Nk
tis càdlàg path equal to the number of spikes of neuron kat time t. We
letτk(t)(orτkfor short) denote the last spike of neuron kbefore time t. We shall assume that the
instantaneous loss function Ltdepends only on the most recent spike times τ1, . . . , τK. Then,
∂wjkLt=∂τkLtajk
τk
µ1(vk
τk−ik
τk)
where ajk
tis the eligibility trace and the first term can be viewed as a global modulator , that is, a
top-down learning signal propagating the error from the output neurons.4The eligibility trace satisfies
dajk
t=µ1
bjk
t−ajk
t
dt+vresetajk
t
µ1(ik
t−vk
t)dNk
t, dbjk
t=−µ2bjk
t+dNj
t,
where the dNterms are to be understood in the Riemann-Stieltjes sense. In other words, the eligibility
trace can be updated exclusively from the activity of the pre- and post-synaptic neurons. We note
the similarity to the results derived in [ 2] only our result gives the exact gradients with no need to
introduce surrogate gradient functions. A similar equation for deterministic SNNs was derived in
[49] (see, in particular, Chapter 5). For general network structures one can use the eligibility traces as
proxies for the the true derivatives ∂wijτk.
5 Conclusion
We introduced a mathematical framework based on rough path theory to model SSNNs as SDEs
exhibiting event discontinuities and driven by càdlàg rough paths. After identifying sufficient
4Note that in the case of stochastic SNNs this term is not necessarily well-defined since semi-martingales are
in general not differentiable wrt. time.
9conditions for differentiability of solution trajectories and event times, we obtained a recursive
relation for the pathwise gradients in Theorem 3.2, generalising the results presented in [ 6] and
[25] which only deal with the case of ODEs. Next, we introduced Marcus signature kernels as
extensions of continuous signature kernels from [ 52] to càdlàg rough paths and used them to define
a general-purpose loss function on the space of càdlàg rough paths to train SSNNs where noise is
present in both the spike timing and the network’s dynamics. Based on these results, we also provided
an end-to-end autodifferentiable solver for SDEs with event discontinuities (Algorithm 1) and made
its implementation available as part of the diffrax repository. Finally, we discussed how our results
lead to bioplausible learning algorithms akin to e-prop [2] but in the context of spike time gradients.
The primary objective of the paper was to lay out the theoretical foundations of gradient-based
learning with stochastic SNNs. Although we provided an initial implementation, which is well-suited
for low dimensional examples, a robust version that scales to a high number of neurons is beyond the
scope of the paper. Examples that require a much higher number of neurons than the two examples
already discussed will be hard to handle with the discretize-then-optimize approach for the reasons
given in Remark 3.5.
We think there are still many interesting research directions left to explore. For instance, it would be
of interest to implement the adjoint equations or to use reversible solvers and compare the results.
Similarly, since our Algorithm 1 differs from the usual approach with surrogate gradients even
in the deterministic setting, questions remain on how these methods compare for training SNNs.
Furthermore, it would be interesting to understand to what extent the inclusion of different types
of driving noises in the dynamics of SSNNs would be beneficial for learning tasks compared to
deterministic SNNs. Finally, it remains to be seen whether the discussion in Section 4.4 could lead to
a bio-plausible learning algorithm with comparable performance to state-of-the-art backpropagation
methods and implementable on neuromorphic hardware.
Acknowledgements . Christian Holberg gratefully acknowledges financial support from Novo Nordisk
Foundation through Grant NNF20OC0062958 and from Independent Research Fund Denmark |
Natural Sciences through Grant 9040-00215B.
References
[1]Martin Arjovsky, Soumith Chintala, and Léon Bottou. Wasserstein generative adversarial
networks. In International conference on machine learning , pages 214–223. PMLR, 2017.
[2]Guillaume Bellec, Franz Scherr, Anand Subramoney, Elias Hajek, Darjan Salaj, Robert Leg-
enstein, and Wolfgang Maass. A solution to the learning dilemma for recurrent networks of
spiking neurons. Nature communications , 11(1):3625, 2020.
[3]Alain Berlinet and Christine Thomas-Agnan. Reproducing kernel Hilbert spaces in probability
and statistics . Springer Science & Business Media, 2011.
[4]Thomas Cass and Cristopher Salvi. Lecture notes on rough paths and applications to machine
learning. arXiv preprint arXiv:2404.06583 , 2024.
[5]Ricky TQ Chen, Yulia Rubanova, Jesse Bettencourt, and David K Duvenaud. Neural ordinary
differential equations. Advances in neural information processing systems , 31, 2018.
[6]Ricky TQ Chen, Brandon Amos, and Maximilian Nickel. Learning neural event functions for
ordinary differential equations. In International Conference on Learning Representations , 2020.
[7]Ilya Chevyrev and Peter K Friz. Canonical rdes and general semimartingales as rough paths.
The Annals of Probability , 47(1):420–463, 2019.
[8]Ilya Chevyrev and Harald Oberhauser. Signature moments to characterize laws of stochastic
processes. Journal of Machine Learning Research , 23(176):1–42, 2022.
[9]Nicola Muca Cirone, Maud Lemercier, and Cristopher Salvi. Neural signature kernels as infinite-
width-depth-limits of controlled resnets. In International Conference on Machine Learning ,
pages 25358–25425. PMLR, 2023.
10[10] Thomas Cochrane, Peter Foster, Varun Chhabra, Maud Lemercier, Terry Lyons, and Cristopher
Salvi. Sk-tree: a systematic malware detection algorithm on streaming trees via the signature
kernel. In 2021 IEEE international conference on cyber security and resilience (CSR) , pages
35–40. IEEE, 2021.
[11] Sebastien Corner, Corina Sandu, and Adrian Sandu. Modeling and sensitivity analysis method-
ology for hybrid dynamical system. Nonlinear Analysis: Hybrid Systems , 31:19–40, 2019.
[12] Sebastien Corner, Adrian Sandu, and Corina Sandu. Adjoint sensitivity analysis of hybrid
multibody dynamical systems. Multibody System Dynamics , 49:395–420, 2020.
[13] Christa Cuchiero, Francesca Primavera, and Sara Svaluto-Ferro. Universal approximation
theorems for continuous functions of c \adl\ag paths and l \’evy-type signature models. arXiv
preprint arXiv:2208.02293 , 2022.
[14] Adeline Fermanian, Terry Lyons, James Morrill, and Cristopher Salvi. New directions in the
applications of rough path theory. IEEE BITS the Information Theory Magazine , 2023.
[15] Peter Friz and Atul Shekhar. General rough integration, lévy rough paths and a lévy–kintchine-
type formula. Annals of probability: An official journal of the Institute of Mathematical
Statistics , 45(4):2707–2765, 2017.
[16] Peter K Friz and Martin Hairer. A course on rough paths . Springer, 2020.
[17] Peter K Friz and Nicolas B Victoir. Multidimensional stochastic processes as rough paths:
theory and applications , volume 120. Cambridge University Press, 2010.
[18] Peter K Friz and Huilin Zhang. Differential equations driven by rough paths with jumps. Journal
of Differential Equations , 264(10):6226–6301, 2018.
[19] Wulfram Gerstner and Werner M Kistler. Spiking neuron models: Single neurons, populations,
plasticity . Cambridge university press, 2002.
[20] Julia Gygax and Friedemann Zenke. Elucidating the theoretical underpinnings of surrogate
gradient learning in spiking neural networks. arXiv preprint arXiv:2404.14964 , 2024.
[21] Thomas A Henzinger. The theory of hybrid automata. In Proceedings 11th Annual IEEE
Symposium on Logic in Computer Science , pages 278–292. IEEE, 1996.
[22] Melker Höglund, Emilio Ferrucci, Camilo Hernández, Aitor Muguruza Gonzalez, Cristopher
Salvi, Leandro Sánchez-Betancourt, and Yufei Zhang. A neural rde approach for continuous-
time non-markovian stochastic control problems. In ICML Workshop on New Frontiers in
Learning, Control, and Dynamical Systems , 2023.
[23] Zacharia Issa, Blanka Horvath, Maud Lemercier, and Cristopher Salvi. Non-adversarial training
of neural sdes with signature kernel scores. Advances in Neural Information Processing Systems ,
2023.
[24] Hyeryung Jang and Osvaldo Simeone. Multisample online learning for probabilistic spiking
neural networks. IEEE Transactions on Neural Networks and Learning Systems , 33(5):2034–
2044, 2022.
[25] Junteng Jia and Austin R Benson. Neural jump stochastic differential equations. Advances in
Neural Information Processing Systems , 32, 2019.
[26] Danilo Jimenez Rezende and Wulfram Gerstner. Stochastic variational learning in recurrent
spiking networks. Frontiers in computational neuroscience , 8:38, 2014.
[27] Hiroshi Kajino. A differentiable point process with its application to spiking neural networks.
InInternational Conference on Machine Learning , pages 5226–5235. PMLR, 2021.
[28] Patrick Kidger. On Neural Differential Equations . PhD thesis, University of Oxford, 2021.
[29] Patrick Kidger, James Foster, Xuechen Li, Harald Oberhauser, and Terry Lyons. Neural sdes as
infinite-dimensional gans. arXiv preprint arXiv:2102.03657 , 2021.
11[30] Franz J Király and Harald Oberhauser. Kernels for sequentially ordered data. Journal of
Machine Learning Research , 20(31):1–45, 2019.
[31] Jaroslav Krystul and HAP Blom. Generalised stochastic hybrid processes as strong solutions of
stochastic differential equations. Hybridge report D , 2, 2005.
[32] Jaroslav Krystul, Henk AP Blom, and Arunabha Bagchi. Stochastic differential equations on
hybrid state spaces. Stochastic Hybrid Systems , 24(15-45):170, 2006.
[33] Petr Lansky and Susanne Ditlevsen. A review of the methods for signal estimation in stochastic
diffusion leaky integrate-and-fire neuronal models. Biological cybernetics , 99(4-5):253–262,
2008.
[34] Jane H Lee, Saeid Haghighatshoar, and Amin Karbasi. Exact gradient computation for spiking
neural networks via forward propagation. In International Conference on Artificial Intelligence
and Statistics , pages 1812–1831. PMLR, 2023.
[35] Maud Lemercier, Cristopher Salvi, Theodoros Damoulas, Edwin Bonilla, and Terry Lyons.
Distribution regression for sequential data. In International Conference on Artificial Intelligence
and Statistics , pages 3754–3762. PMLR, 2021.
[36] Xuechen Li, Ting-Kam Leonard Wong, Ricky TQ Chen, and David K Duvenaud. Scalable
gradients and variational inference for stochastic differential equations. In Symposium on
Advances in Approximate Bayesian Inference , pages 1–28. PMLR, 2020.
[37] John Lygeros and Maria Prandini. Stochastic hybrid systems: a powerful framework for
complex, large scale applications. European Journal of Control , 16(6):583–594, 2010.
[38] Terry J Lyons. Differential equations driven by rough signals. Revista Matemática Iberoameri-
cana , 14(2):215–310, 1998.
[39] Terry J Lyons, Michael Caruana, and Thierry Lévy. Differential equations driven by rough
paths . Springer, 2007.
[40] Gehua Ma, Rui Yan, and Huajin Tang. Exploiting noise as a resource for computation and
learning in spiking neural networks. Patterns , 4(10), 2023.
[41] Georg Manten, Cecilia Casolo, Emilio Ferrucci, Søren Wengel Mogensen, Cristopher Salvi,
and Niki Kilbertus. Signature kernel conditional independence tests in causal discovery for
stochastic processes. arXiv preprint arXiv:2402.18477 , 2024.
[42] Steven Marcus. Modeling and analysis of stochastic differential equations driven by point
processes. IEEE Transactions on Information theory , 24(2):164–172, 1978.
[43] Steven I Marcus. Modeling and approximation of stochastic differential equations driven by
semimartingales. Stochastics: An International Journal of Probability and Stochastic Processes ,
4(3):223–245, 1981.
[44] James Morrill, Cristopher Salvi, Patrick Kidger, and James Foster. Neural rough differential
equations for long time series. In International Conference on Machine Learning , pages
7829–7838. PMLR, 2021.
[45] Krikamol Muandet, Kenji Fukumizu, Bharath Sriperumbudur, Bernhard Schölkopf, et al. Kernel
mean embedding of distributions: A review and beyond. Foundations and Trends ®in Machine
Learning , 10(1-2):1–141, 2017.
[46] Emre O Neftci, Hesham Mostafa, and Friedemann Zenke. Surrogate gradient learning in spiking
neural networks: Bringing the power of gradient-based optimization to spiking neural networks.
IEEE Signal Processing Magazine , 36(6):51–63, 2019.
[47] Ali Pakniyat and Peter E Caines. On the stochastic minimum principle for hybrid systems. In
2016 IEEE 55th Conference on Decision and Control (CDC) , pages 1139–1144. IEEE, 2016.
[48] Alexandre Pannier and Cristopher Salvi. A path-dependent pde solver based on signature
kernels. arXiv preprint arXiv:2403.11738 , 2024.
12[49] Christian Pehle. Adjoint equations of spiking neural networks . PhD thesis, Universität Heidel-
berg, 2021.
[50] Jean-Pascal Pfister, Taro Toyoizumi, David Barber, and Wulfram Gerstner. Optimal spike-
timing-dependent plasticity for precise action potential firing in supervised learning. Neural
computation , 18(6):1318–1348, 2006.
[51] Cristopher Salvi. Rough paths, kernels, differential equations and an algebra of functions on
streams . PhD thesis, University of Oxford, 2021.
[52] Cristopher Salvi, Thomas Cass, James Foster, Terry Lyons, and W. Y . The signature kernel is
the solution of a Goursat PDE. SIAM Journal on Mathematics of Data Science , 3(3):873–899,
2021.
[53] Cristopher Salvi, Maud Lemercier, Thomas Cass, Edwin V Bonilla, Theodoros Damoulas, and
Terry J Lyons. Siggpde: Scaling sparse gaussian processes on sequential data. In International
Conference on Machine Learning , pages 6233–6242. PMLR, 2021.
[54] Cristopher Salvi, Maud Lemercier, Chong Liu, Blanka Horvath, Theodoros Damoulas, and
Terry Lyons. Higher order kernel mean embeddings to capture filtrations of stochastic processes.
Advances in Neural Information Processing Systems , 34:16635–16647, 2021.
[55] Bernhard Schölkopf and Alexander J Smola. Learning with kernels: support vector machines,
regularization, optimization, and beyond . MIT press, 2002.
[56] Timo C Wunderlich and Christian Pehle. Event-based backpropagation can compute exact
gradients for spiking neural networks. Scientific Reports , 11(1):12829, 2021.
[57] Mingqing Xiao, Qingyan Meng, Zongpeng Zhang, Di He, and Zhouchen Lin. Online training
through time for spiking neural networks. Advances in neural information processing systems ,
35:20717–20730, 2022.
[58] Friedemann Zenke and Tim P V ogels. The remarkable robustness of surrogate gradient learning
for instilling complex function in spiking neural networks. Neural computation , 33(4):899–925,
2021.
13Appendix
The appendix is structured as follows. Section A covers the basic concepts of càdlàg rough paths
based on [ 7] extended with a few of our own definitions and results. It culminates with the definition
of Event RDEs which can be viewed as generalizations of Event SDEs. Section B covers the proof of
the main result, Theorem 3.2, but in the setting of Event RDEs as well as some preliminary technical
lemmas needed for the proof. Section C gives a brief overview of the main concepts in kernel learning
and presents our results on Marcus signature kernels along with their proofs. Section D derives the
forward sensitivities of a SSNN. Finally, Section E covers all the technical details of the simulation
experiments that were not discussed in the main body of the paper.
A Càdlàg rough paths
Marcus integration developed in [ 7] preserves the chain rule and thus serves as an analog to
Stratonovich integration for semi-martingales with jump discontinuities. In particular, it allows
to define a canonical lift under which càdlàg semi-martingales are a.s. geometric rough paths and
many of the results from the continuous case, such as universal limit theorems and stability results,
carry over under suitably defined metrics.We briefly review some of the important concepts here by
following the same setup as in [7].
LetC([0, T], E)andD([0, T], E)be the space of continuous and càdlàg paths respectively on
[0, T]with values in a metric space (E, d). For p≥1, letCp([0, T], E)andDp([0, T], E)be the
corresponding subspaces of paths with finite p-variation. For any N≥1, Let GN(Rd)be the
step-Nfree nilpotent Lie group over Rdendowed with the Carnot-Carathéodory metric d. Let
ΩC
p(Rd) := Cp([0, T], G⌊p⌋(Rd))andΩD
p(Rd) := Dp([0, T], G⌊p⌋(Rd))be the space of weakly
geometric continuous and càdlàg p-rough paths respectively with the homogeneous p-variation metric
dp(x,y) = max
1≤k≤⌊p⌋sup
D⊂[0,T] X
Dd(xti,ti+1,yti,ti+1)p
k!k
p
.
Define the log-linear path function
ϕ:GN(Rd)×GN(Rd)→C([0,1], GN(Rd))
(a,b)7→exp((1 − ·) loga+·logb).
where logandexpare the (truncated) tensor logarithm and exponential maps on GN(Rd). IfN= 1,
thenGN(Rd)∼=R⊕Rdandϕ(a, b)t= (1,(1−t)a+tb)is a straight line connecting atobin unit
time. For any x∈D([0, T], GN(Rd))we can construct a continuous path ˆx∈C([0, T], GN(Rd))
by adding fictitious time and interpolating through the jumps using the log-linear path function
according to the following definition.
Definition A.1 (Marcus interpolation) .LetN≥1. Forx∈D([0, T], GN(Rd)), letτ1, τ2, . . . , τ m
be the jump times of xordered such that d(xτ1−,xτ1)≥d(xτ2−,xτ2)≥ ··· ≥ d(xτm−,xτm),
where 0≤m≤ ∞ is the number of jumps. Let (rk)be a sequence of positive scalars rk>0such
thatr=Pm
k=1rk<+∞. Define the discontinuous reparameterisation η: [0, T]→[0, T+r]by
η(t) =t+mX
k=1rk1{τk≤t}.
The Marcus augmentation xM∈C([0, T+r], GN(Rd))ofxis the path
xM
s=xt, ifs=η(t)for some t∈[0, T],
ϕ(xτk−,xτk)(s−η(τk−))/rk, ifs∈[η(τk−), η(τk))for1≤k < m + 1.
The Marcus interpolation ˆx∈C([0, T], GN(Rd))ofxis the path ˆx=xM◦ηrwhere ηr(t) =
t(T+r)/Tis a reparameterisation from [0, T]to[0, T+r]. We can recover xfromˆxviax=ˆx◦ηx
by considering the reparameterisation ηx=η−1
r◦η.
Once the Marcus interpolation is defined we can state what we mean by a solution to a differential
equation driven by a geometric càdlàg rough path.
14Definition A.2 (Marcus RDE) .Letx∈ΩD
p(Rd)andf= (f1, . . . , f d)beLipγvector fields on Re
withγ > p . For an initial condition a∈Re, letˆy∈Cp([0, T],Re)be the solution to the classical
RDE driven by the Marcus interpolation ˆx∈ΩC
p(Rd)
dˆyt=f(ˆyt)dˆxt,ˆy0=a.
Define the solution y∈Dp([0, T],Re)to the Marcus RDE
dyt=f(yt)⋄dxt, y 0=a (8)
to be y= ˆy◦ηx, where ηxis the reparameterisation introduced in Definition A.1.
A.1 Metrics on the space of càdlàg rough paths
Chevyrev and Friz [7]introduce a metric αponΩD
p(Rd)with respect to which 1) geometric càdlàg
rough paths can be approximated with a sequence of continuous paths [ 7, Section 3.2] and 2) the
solution map (y0,x)7→(x, y)of the Marcus RDE (8) is locally Lipschitz continuous [ 7, Theorem
3.13].
We write Λfor the set of increasing bijections from [0, T]to itself. For a λ∈Λwe let |λ|=
supt∈[0,T]|λ(t)−t|. We first define the Skorokhod metric as well as a Skorokhod version of the
usual p-variation metric.
Definition A.3. Forp≥1andx,y∈Dp([0, T], E), we define
σ∞(x,y) = inf
λ∈Λmax(
|λ|,sup
t∈[0,T]d((x◦λ)t,yt))
,
σp(x,y) = inf
λ∈Λmax{|λ|, dp(x◦λ,y)}.
It turns out that the topology induced by σpis too strong. In particular, it is not possible to approximate
paths with jump discontinuities with a sequence of continuous paths (see Section 3.2 in [ 7]). For
x∈ΩD
p(Rd)andf= (f1, . . . , f d)a family of vector fields in Lipγ−1(Re)with γ > p , let
Φf(y, s, t ;x)denote the solution to the Marcus RDE dyt=f(yt)⋄dxtinitialized at ys=yand
evaluated at time t. We define the set
Jf=n
((a, b),(a′, b′))|a,a′∈G⌊p⌋(Re),Φf(b,0,1;ϕ(a,a′)) =b′o
.
and, on it, the path function
ϕf((a, b),(a′, b′))t= (ϕ(a,a′),Φf(b,0,1;ϕ(a,a′)t)).
Finally, we let Df
p([0, T], G⌊p⌋(Rd)×Re)be the space of càdlàg paths z= (x, y)onG⌊p⌋(Rd)×Re
of bounded p-variation such that (zt−,zt)∈Jffor all jump times tofz. To keep notation simple,
we shall write Df
pwhen this does not cause any confusion. Naturally, if yis the solution to the
Marcus RDE dyt=f(yt)⋄dxt, we have (x, y)∈Df
p. For a z= (x, y)∈Df
pwe may define the
Marcus interpolation by interpolating the jumps using ϕf. Let ˆzδdenote this interpolation but with
rkreplaced by δrkforδ >0and similarly for ˆxδwithx∈ΩD
p(Rd).
Definition A.4. Forf= (f1, . . . , f d)a family of vector fields in Lipγ−1(Re)withγ > p , let
z,z′∈Df
pwithz= (x, y)andz′= (x′, y′)and define
αp(x,x′) = lim
δ→0σp(ˆxδ,ˆx′δ),
αp(z,z′) = lim
δ→0σp(ˆzδ,ˆz′δ).
Remark A.1.It is proven in [ 7] that in both cases the limit in αpexists, is independent of the choice
ofrk, and that it is indeed a metric on ΩD
p(Rd)resp. Df
p.
Theorem A.1 (Theorem 3.13 + Proposition 3.18, [ 7]).Letf= (f1, . . . , f d)be a family of vector
fields in Lipγ−1(Re)withγ > p . Then,
151. The solution map
Re×(ΩD
p(Rd), αp)→(Df
p, αp)
(y0,x)7→z= (x, y)
of the Marcus RDE dyt=f(yt)⋄dxtinitialized at y0∈Reis locally Lipschitz.
2. On sets of bounded p-variation, the solution map
Re×(ΩD
p(Rd), σ∞)→(Dp([0, T],Re), σ∞)
(y0,x)7→y
of the Marcus RDE dyt=f(yt)⋄dxtinitialized at y0∈Reis continuous.
Now, let C1
0(Rd)be the space of absolutely continuous functions on Rd.
Definition A.5. We define the space of geometric càdlàg p-rough paths ΩD
0,p(Rd)as the closure of
C1
0(Rd)inΩD
p(Rd)under the metric αp.
Remark A.2.A càdlàg semi-martingale x∈Dp([0, T],Rd)can be canonically lifted to a geometric
càdlàg p-rough path, with p∈[2,3), by enhancing it with its two-fold iterated Marcus integrals, i.e.
xs,t= (1, xs,t,Z
s,t(xs−xu)⊗ ⋄dxu)∈G2(Rd)
where the integral is defined in a similar spirit to Definition A.2 (see, for example, [ 18] for more
information). The solution to the corresponding Marcus RDE agrees a.s. with the solution to the
usual càdlàg Marcus SDE which, in turn, if xhas a.s. continuous sample paths, agrees a.s. with the
solution to the Stratonovich SDE. See, e.g., Proposition 4.16 in [7].
A.2 Signature
The extended tensor algebra over Rdis given by
T  
Rd
=∞Y
n=0 
Rd⊗n
equipped with the usual addition +and tensor multiplication ⊗. An element a∈T  
Rd
is
a formal series of tensors a= (a0,a1, . . .)such that an∈(Rd)⊗n. We define the projections
πn:T  
Rd
→(Rd)⊗ngiven by πn(a) =an. Let ˜T((Rd))be the subset of T((Rd))such that
theπ0(a) = 1 for all a∈˜T((Rd)). Finally, we define the set of group-like elements,
G(∗)=n
a∈˜T  
Rd
|πn(a)∈GN 
Rd
for all n≥0o
Definition A.6. Letp≥1andx∈ΩD
p(Rd). The signature of xis the path S(x) : [0, T]7→G(∗)
such that, for each N≥0,
dS(x)N
t=S(x)N
t⊗ ⋄dxt, S(x)N
0=1∈GN 
Rd
. (9)
Remark A.3.Uniqueness and existence of the signature follow from the continuous analog. Indeed,
by definition, (9) is equivalent to a continuous linear RDE.
Remark A.4.The signature, as defined here, is also known as the minimal jump extension of xand
was first introduced in [ 15]. It was further explored in [ 13] where it was also shown that it acts as a
universal feature map.
In the continuous case, it is well known that the signature characterizes paths up to tree-like equiv-
alence . Two continuous paths x,yare said to be tree-like equivalent if there exists a continuous
non-negative map h: [0, T]→R+such that h(0) = h(T)and
∥xs,t−ys,t∥ ≤h(s) +h(t)−2 inf
u∈[s,t]h(u).
This can be generalized to càdlàg paths in the following way. We say that two càdlàg paths x,y
are tree-like equivalent, or x∼ty, if their their Marcus interpolations (see Def. A.1), ˆxandˆy,
are tree-like equivalent. It is straightforward to check that this indeed is an equivalence relation on
ΩD
p(Rd). Perhaps more interestingly, we obtain the following result. For ease of notation we shall
henceforth mean S(x)Twhen omitting the subscript from the signature.
16Proposition A.1. Letp≥1. The map S(·) : ΩD
p(Rd)→G(∗)is injective up to tree-like equivalence,
i.e.,S(x) =S(y)iffx∼ty.
Proof. The result follows from the continuous case upon realizing that S(x) =S(ˆx)and analogously
fory.
A.3 Young pairing
In many cases, given a geometric càdlàg rough path x∈ΩD
0,p(Rd)withp∈[2,3)and a path
h∈D1([0, T],Re)of bounded variation one is interested in constructing a new rough path y∈
ΩD
0,p(Rd+e)such that the first level of yis given by y= (x, h). In the continuous case this can be
done by using the level two information x2andR
dh⊗dhto fill in the corresponding terms in y2
and using the well-defined Young cross-integrals to fill in the rest. The resulting level 2 rough path is
called the Young pairing ofxandhand we will denote it by y=P(x, h). The canonical example
to keep in the mind is when ht=t, that is, we want to augment the rough path with an added time
coordinate (see Def. A.8). In the càdlàg case one needs to be more careful in defining the appropriate
Marcus lift.
Definition A.7 (Definition 3.21 [ 7]).Letx∈ΩD
0,p(Rd)withp≥1andh∈D1([0, T],Re). Define
the path z= (x, h)and the corresponding Marcus lift ˆz= (ˆx,ˆh). The Young pairing of xandhis
thep-rough path P(x, h)∈ΩD
p(Rd+e)such that
P(x, h) =P(ˆx,ˆh)◦ηz
where P(ˆx,ˆh)is the usual Young pairing of a continuous rough path and a continuous bounded
variation path (see Def. 9.27 in [17]).
We can then construct the time augmented rough path as the rough path obtained by the Young pairing
with the simple continuous bounded variation path ht=t. It turns out that this pairing is continuous
as a map from ΩD
0,p(Rd)toΩD
0,p(Rd+1).
Definition A.8. Letx∈ΩD
0,p(Rd). The time augmented version of xis the unique rough path
˜x∈ΩD
0,p(Rd+1)obtained by the Young pairing P(x, h)ofxwith the continuous bounded variation
pathht=t.
Proposition A.2. Letp∈[1,3). Then, the map x7→˜xis continuous and injective as a map from
ΩD
0,p(Rd)toΩD
0,p(Rd+1).
Proof. LetX= ΩD
0,p(Rd)be a metric space when equipped with αp. Fixx∈ X and let xnbe a
sequence of absolutely continuous paths converging in Xtox. We shall first show that ˜xnthen
converges to ˜x. Since xndoes not have any jumps and any reparameterisation of xnis still absolutely
continuous, we may assume that
αp(x, xn) = lim
δ→0dp(ˆxδ, xn)→0
forn→ ∞ . Define z= (x, h)andˆzd= (ˆxδ,ˆhδ)the Marcus interpolation with ηx,δthe reparam-
eterisation such that z=ˆzδ◦ηx,δ. Furthermore, let P(x, h)be the Young pairing of xandh. By
definition,
αp(P(x, h), P(xn, h)) = lim
δ→0σp
P(ˆxδ,ˆhδ), P(xn, h)
≤lim
δ→0dp
P(ˆxδ,ˆhδ), P(xn, h)
≤lim
δ→0C
dp(ˆxδ, xn) +d1(ˆhδ, h)
→0
forn→ ∞ where Cis just some generic constant depending only on p. The last inequality follows
from 9.32 in [ 17]. Thus, if y∈ X is such that αp(x,y)< ϵ, we can choose another sequence ynof
absolutely continuous paths and N≥1large enough so that
αp(P(x, h), P(y, h))≤2ϵ+αp(P(xn, h), P(yn, h)),
17αp(xn, yn)≤2ϵ
for all n≥N. By Remark 3.6 in [ 7], we then have that, up to choosing a large N,dp(xn, yn)≤ϵ
for all n≥Nand therefore, once more appealing to Theorem 9.32 in [17],
αp(P(xn, h), P(yn, h))≤2Cϵ.
In conclusion, αp(P(x, h), P(y, h))≤2(1 + C)ϵwhich proves the result.
Injectivity follows from [13].
A.4 Event RDEs
The results of Section 3.3 hold in more generality. In fact, we can define Event RDEs similar to
Definition 3.1 where the inter-event dynamics are given by Marcus RDEs driven by càdlàg rough
paths. Utilizing the correspondence between solutions to Marcus RDEs and Marcus SDEs, it then
follows that the results in the main body of the paper are a special case of the results given below.
Definition A.9 (Event RDE) .Letp≥1andN∈Nbe the number of events. Let x∈ΩD
p(Rd)and
f= (f1, . . . , f d)be a family of LipγonRewithγ > p . LetE:Re→RandT:Re→Rebe an
event and transition function respectively. We say that 
y,(τn)N
n=1
is a solution to the Event RDE
parameterised by (y0,x, f,E,T, N)ifyT=yN
T,
yt=NX
n=0yn
t1[τn,τn+1)(t), τ n= inf
t > τ n−1:E(yn−1
t−) = 0	
, (10)
withE(yn
τn)̸= 0and
dy0
t=f(y0
t)⋄dxt,started at y0
0=y0, (11)
dyn
t=f(yn
t)⋄dxt,started at yn
τn=T 
yn−1
τn−
. (12)
Existence and uniqueness of solutions to Event RDEs is proven in the same way as for Event SDEs.
Indeed, under the usual assumption that the vector fields fareLipγ, forγ > p , a unique solution
to(11) exists. In fact, the solution map ys×(s, t)7→ytis a diffeomorphism for every fixed
0≤s < t≤T(see, e.g., Theorem 3.13 in [ 7]). It follows that we can iteratively define a unique
sequence of solutions yn∈Dp([tn, T],Rd). Finally, as mentioned in Remark A.2, if the driving
rough path xis the Marcus lift of a semi-martingale, the inter-event solutions agree almost surely
with the solutions to the corresponding Marcus SDE.
Theorem A.2. Under Assumptions 3.1-3.2, there exists a unique solution (y,(τn)N
n=1)to the Event
RDE of Definition A.9. Furthermore, if xis the Marcus lift of a Brownian motion, the solution
coincides almost surely with the solution to the corresponding Event SDE as given in Def. 3.1.
Hence, the Event SDEs considered in the main text are special cases of Event RDEs driven by the
Marcus lift of a Brownian motion. Yet, the more general formulation of Event RDEs allows to treat,
using the same mathematical machinery of rough path theory a much larger family of driving noises
such as fractional Brownian motion or even smooth controls. Also, since the driving rough path
is allowed to be càdlàg, the model class given by Def. A.9 includes cases where the inter-event
dynamics are given by Marcus SDEs driven by general semi-martingales.
B Proof of Theorem 3.2
The proof of Theorem 3.2 presented below covers the case where (y,(τn)N
n=1)is the solution to an
Event RDE. Throughout we consider vector fields µ∈Lip1, σ∈Lip2+ϵand specialise to Event
RDEs where the inter-event dynamics are given by
dyn
t=µ(yn
t)dt+σ(yn
t)⋄dxt, (13)
where x∈ΩD
p(Rd). The notation above deserves some clarification. One can define the vector field
f= (µ, σ)and the Young pairing ˜xtofxandht=t. Assuming µ∈Lip2+ϵwe can then view yn
tas
the unique solution to the Marcus RDE
dyn
t=f(yn
t)⋄˜xt.
18Alternatively, if one is not ready to impose the added regularity on the drift µ, one can view 13
as a RDE with drift as in Ch. 12 in [ 17]. To accommodate this more general case where the path
driving the diffusion term might be 1) càdlàg and 2) is not restricted to be the rough path lift of a
semi-martingale, we shall need the following two additional assumptions:
Assumption B.1.For any n∈[N], there exists a non-empty interval In= (τn−δn, τn+δn)such
thatxis continuous over In. In other words, the càdlàg rough path x, does not jump in small intervals
around the event times (τn).
Assumption B.2.For all 0≤n≤Nwe define sn=τn−δn/2andtn=τn+1+δn+1/2. It holds
thatx∈ΩD
0,p([sn, tn],Rd), i.e.,xis a geometric p-rough path on the intervals [sn, tn].
Remark B.1.Note that Assumption B.1 trivially holds if xis continuous. Otherwise, it is enough to
assume, e.g., that xis the Marcus lift of a finite activity Lèvy process. Furthermore, by the properties
of the metric αp, ifxis the canonical Marcus lift of a semi-martingale x∈Dp([s, t],Rd−1), then
there exists a sequence (xm)of piece-wise linear paths xm∈C1
0([0, T],Rd−1)such that
αp,[sn,tn](xm,x)→0asm→ ∞ a.s.
See, e.g. [ 7, Example 4.21]. The setting of Section 3.3 is therefore a special case of the setting
considered here and Theorem 3.2 follows from the proof below.
We shall need two technical lemmas for the proof of 3.2
Lemma B.1. Assume that Assumptions 3.1-3.5 and B.1-B.2 are satisfied. Then, there exists an open
ballB0⊂Osuch that the following holds:
1. For all a∈B0,|τ(a)|=N.
2. For any n∈[N], the maps
B0∋a7→
τn(a), yn−1
τn(a)(a)
are continuous.
3.For the sequence (xm)as given in Assumption B.2 and (ym,(τm
n)N
n=1)the corresponding
Event RDE solution, for all n∈[N], it holds that
lim
m→∞sup
a∈B0
|τm
n(a)−τn(a)|+ym,n−1
τmn(a)(a)−yn−1
τn(a)(a)
= 0.
Proof. Recall that Φ(y, s, t ;x)is the solution map or flow of the differential equation
dyu=f(yu)⋄d˜xu, y s=y
evaluated at time t. The first step will be to prove continuity at y0. In particular, let ym
0∈O
approach y0formgoing to infinity and denote the solutions to the corresponding Event RDEs by
ym,(τm
n)Nm
n=1
. We claim that limm→∞Nm=Nand
lim
m→∞τm
n=τn,lim
m→∞ym,n−1
τmn=yn
τn.
To see this, note that, by Theorem A.1, there exists a sequence λm∈Λof continuous reparameterisa-
tions such that |λm| →0and
sup
(s,t)∈∆T|Φ(y0, s, t;x)−Φ(ym
0, λm(s), λm(t);x)| →0 (14)
form→ ∞ . Note, furthermore, that Φ(ym
0, s, t;x◦λm) = Φ( ym
0, λm(s), λm(t);x)for all (s, t)∈
∆T. We let
˜ym,(˜τm
n)Nm
n=1
be the solution to the Event RDE where (y0,x)is replaced by (ym
0,x◦
λm). It suffices to prove that, for all 1≤n≤N,
lim
m→∞˜τm
n=τn,lim
m→∞˜ym,n−1
˜τmn=yn
τn. (15)
Indeed, since ˜τm
n=λ−1
m(τm
n)and|λm| →0, it then follows that τm
n→τnform→ ∞ . Furthermore,
we have ˜ym,n−1
˜τmn=ym,n−1
τmn.
19We shall proof (15) using an inductive argument. We have that
y0
t= Φ(y0,0, t;x),∀t∈[0, τ1],
˜ym,0
t= Φ(ym
0,0, t;x◦λm),∀t∈[0,˜τm
1].
Now fix some 0< ϵ < δ 1where δ1is given in Assumption B.1. Note that |E(y0
t)|>0for all
t∈[0, τ1−ϵ]and therefore, by (14), it follows that there exists an m0∈Nsuch that, for all m≥m0,
inf
t∈[0,τ1−ϵ]|E(Φ(ym
0,0, t;x◦λm))|>0
so that ˜τm
1≥τ1−ϵ. Next, for some small 0< η < ϵ , Assumption 3.4 and the Mean Value Theorem
imply the existence of a+
η=r+
ηy0
τ1−(1−r+
η)y0
τ1+η, and a−
η=r−
ηy0
τ1−η+ (1−r−
η)y0
τ1with
r+
η, r−
η∈(0,1)such that
E 
y0
τ1+η
=E 
y0
τ1
+∇E(a+
η)Zτ1+η
τ1µ(y0
s)dys,
E 
y0
τ1−η
=E 
y0
τ1
− ∇E (a−
η)Zτ1
τ1−ηµ(y0
s)dys,
But then, by Assumption 3.5 and the fact that E(y0
τ1) = 0 , forηsmall enough, E(y0
τ1+η)andE(y0
τ1−η)
must lie on different sides of 0. Assumption B.1 and eq. (14) then yield the existence of a m1≥m0
such that ˜τm
1≤τ1+η≤τ1+ϵandinft∈[0,τ1+η]|E(˜ym,0
t)|>0for all m≥m1. It follows that
˜τm
1→τ1. Finally, note that
˜ym,0
˜τm
1−y0
τ1≤˜ym,0
˜τm
1−y0
˜τm
1+y0
˜τm
1−y0
τ1.
Another application of (14) shows that the first term on the right hand side goes to 0 for m→ ∞ and
second term vanishes by Assumption B.1.
To prove the inductive step, assume that (15) holds for i≤n. For all t∈[τn, τn+1]it holds that
˜ym,n
t= Φ
T
˜ym,n−1
˜τmn
,˜τm
n, t;x◦λm
, yn
t= Φ 
T 
yn−1
τn
, τn, t;x
and, since ˜ym,n−1
˜τmn→yn−1
τn,˜τm
n→τn, andTis continuous,
lim
m→∞sup
t∈[τn,T]Φ
T
˜ym,n−1
˜τmn
,˜τm
n, t;x◦λm
−Φ 
T 
yn−1
τn
, τn, t;x= 0
whence the same argument as above proves that (15) also holds for n+ 1. This completes the proof
of the claim.
Now, by continuity at y0, it follows that there exists some small r >0such that for all a∈Br(y0)
it holds that |τ(a)|=Nandτn(a)∈(τn−δn/2, τn+δn/2)for all n∈[N]where δnis as in
Assumption B.1. Furthermore, since Assumption 3.1-3.5 and B.1-B.2 still hold for a∈Br(y0), the
same argument as above can be applied to show that τn(a)andyn−1
τn(a)(a)are continuous at a. This
proves parts 1 and 2.
To prove part 3 we employ a similar induction argument to the one above. First, note that, by Theorem
A.1, there exists a constant C >0not depending on xsuch that
αp,[0,t0] 
ym,0(a), y0(a)
≤Cαp,[0,t0](xm,x).
Since the latter term does not depend on yand goes to 0 for mgoing to infinity, we find that
lim
m→∞sup
a∈Br(y0)αp,[0,t1] 
ym,0(a), y0(a)
= 0. (16)
Recall, yδ,0(a)is the continuous path obtained by the Marcus interpolation with δrkinstead of rk
and similarly for ym,δ,0(a). Note that ym,δ,0(a) =ym,0(a)by continuity. Letting τm
1(a)andτδ
1(a)
denote the first event time of ym,0(a)andyδ,0(a)respectively, we have, for all m∈N
sup
a∈Br(x0)|τm
1(a)−τ1(a)| ≤ sup
a∈Br(y0)lim
δ→0 τm
1(a)−τδ
1(a)+τδ
1(a)−τ1(a)
.
20Now, let B0=Br(y0). Since τ1(a)∈(τ1−δ1/2, τ1+δ1/2)for all a∈B0andxis continuous over
this interval, it follows thatτδ
1(a)−τ1(a)goes to 0 as δ→0for each a∈B0. Furthermore, by
definition of the metric αp, eq. (16), and the fact that ym,0
0(a) =a=y0
0(a), for each a∈B0, a similar
argument as the one employed in the beginning of the proof then shows that |τm
1(a)−τδ
1(a)| →0as
δ→0and, thus, limm→∞supa∈B0|τm
1(a)−τ1(a)|= 0. Finally, starting from the inequalityym,0
τm
1(a)(a)−y0
τ1(a)(a)≤ym,0
τm
1(a)(x)−yδ,0
τδ
1(a)(a)+yδ,0
τδ
1(a)(a)−y0
τ1(a)(a)
and taking the limit as δ→0and then the supremum over x∈B0on both sides, we can argue in
exactly the same way to show that part 3 holds for n= 1. We can then argue by induction, just as in
the first part of the proof, to show that it holds for all subsequent event times as well. Thus, the set
B0satisfies all the stated requirements.
Lemma B.2. Let Assumption B.1 hold and xmbe as in Assumption B.2. Then, for all n∈[N]and
p′> p,
lim
m→∞dp′,[s,t](xm,x) = 0 ,for any τn−δn/2≤s < t≤τn+δn/2.
Proof. Fix some n∈[N],p′> pandτn−δn/2≤s < t≤τn+δn/2. Note that, for any continuous
reparameterisation λ∈Λ,m∈N, and δ >0, it holds that
dp′,[s,t](xm,x)≤dp′,[s,t](xm, xm◦λ) +dp′,[sn,tn](xm◦λ,ˆxδ) +dp′,[s,t](ˆxδ,x),
where ˆxδis the Marcus interpolation of xover the interval [sn, tn]. Taking the infimum over λ∈Λ
and the limit as δ→0on both sides, we obtain
dp′,[s,t](xm,x)≤αp′,[sn,tn](xm,x) + lim
δ→0dp′,[s,t](ˆxδ,x).
The first term on the right hand side goes to 0 as m→ ∞ by Assumption B.2. Furthermore, since, by
Assumption B.1, xis continuous on (τn−δn, τn+δn), it follows that d∞,[s,t](ˆxδ,x)goes to 0 for
δ→ ∞ . But the result then follows from Proposition 8.15 and Lemma 8.16 in [17].
Proof of Theorem 3.2. Step 1: Assume that x∈C1([0, T],Rd−1). By [ 17, Theorem 4.4], the
Jacobian ∂y0
texists and satisfies (7)for all t∈[0, τ1). We shall prove that relations (6)and(7)
hold for all n∈[N]by induction. Thus, assume that ∂yk
tand∂τkexist for all t∈[τk, τk+1)and
k≤n−1and satisfy the stated relations. To emphasise the dependence on the initial condition, we
will sometimes use the notation yn=yn(y0)andτn=τn(y0)for the solution of the Event RDE
started at y0. We want to show that, for arbitrary h∈Re, the following limits
lim
ϵ→0τϵ
n−τn
ϵand lim
ϵ→0yn,ϵ
t−yn
t
ϵfort∈[τn, τn+1)
exist and satisfy the stated expressions, where τϵ
n=τn(y0+hϵ)andyn,ϵ=yn(y0+hϵ).
For any ϵ >0, because Eis continuously differentiable, the Mean Value Theorem implies that there
exists cϵ∈Reon the line connecting yn−1
τntoyn−1
τϵnand another c′
ϵ∈Reon the line connecting
yn−1,ϵ
τϵntoyn−1
τϵnsuch that
E 
yn−1
τn
=E
yn−1
τϵn
+∇E(cϵ)
yn−1
τn−yn−1
τϵn
=E
yn−1
τϵn
+∇E(cϵ) 
µ(yn−1
τn)(τn−τϵ
n) +σ 
yn−1
τn
(xτn−xτϵn) +o(|τn−τϵ
n|)
,
E
yn−1,ϵ
τϵn
=E
yn−1
τϵn
+∇E(c′
ϵ)
yn−1,ϵ
τϵn−yn−1
τϵn
=E
yn−1
τϵn
+∇E(c′
ϵ) 
ϵ 
∂yn−1
τn
h+o(ϵ)
,
where the last equality follows from the induction hypothesis. We have E(yn−1
τn) = 0 = E(yn−1,ϵ
τϵn).
Thus, by rearranging, we find that
τϵ
n−τn
ϵ=−∇E(yn−1
τn)∂yn−1
τnh
∇E(yn−1τn)
µ(yn−1τn) +σ(yn−1τn)xτn−xτϵn
τn−τϵn+o(1)
=−∇E(yn−1
τn)∂yn−1
τnh
∇E(yn−1τn)µ(yn−1τn)+o(1)
21where the second equality follows from Assumptions 3.4 and 3.5.
Assume for now that τϵ
n< τn. By another application of the Mean Value Theorem, there exists
cϵ∈Reon the line connecting yn−1
τntoyn−1
τϵnsuch that
yn,ϵ
τn−yn
τn=yn,ϵ
τn− T 
yn−1
τn
=yn,ϵ
τn− T
yn−1
τϵ
n
− ∇T (cϵ)(yn−1
τn−yn−1
τϵ
n)
=yn,ϵ
τϵn+µ(yn,ϵ
τn)(τn−τϵ
n) +σ 
yn,ϵ
τn
(xτn−xτϵn)− T
yn−1
τϵn
− ∇T (cϵ) 
µ(yn−1
τn)(τn−τϵ
n) +σ 
yn−1
τn
(xτn−xτϵn) +o(|τn−τϵ
n|)
=T
yn−1,ϵ
τϵn
− T
yn−1
τϵn
+ 
µ(yn,ϵ
τn)− ∇T (cϵ)µ(yn−1
τn)
(τn−τϵ
n)
+ 
σ(yn
τn)− ∇T (cϵ)σ(yn−1
τn)
(xτn−xτϵn) +o(|τn−τϵ
n|)
Therefore
yn,ϵ
τn−yn
τn
ϵ=∇T(yn−1
τn)∂yn−1
τnh+ 
µ(yn
τn)− ∇T (yn−1
τn)µ(yn−1
τn)
∂τnh+o(1)
where we used Assumption 3.3, the chain rule and the existence of ∂τn. Finally, for any t∈(τn, τn+1],
equation (7)follows from the fact that we can write yn
t= Φ( yn
s, s, t, x )for all τn≤s < t . In
particular, by the chain rule, we find that
∂yn
t=
∂ynsΦ(yn
s, s, t)∂yn
s
s=τn=∂ynτnyn
t[∂yn
s]s=τn.
Step 2: Consider now the general case of x∈Ωp(Re)and let (ym,(τm
nm)Nmnm)denote the solution
to the Event RDE where xis replaced by the piece-wise linear approximation xm. With ∂yn,m
tand
∂τm
ndenoting the corresponding derivatives, we saw in the previous step that both exist and satisfy
(6)-(7). We let Rn
tandρndenote the right hand side of (7)and(6)respectively. This step consists of
proving that, for n∈[N]andt∈(τn, tn),
lim
m→∞{|τm
n−τn|+|ym,n
t−yn
t|}= 0 (17)
and for some open ball B0around y0
lim
m→∞sup
a∈B0{|∂τm
n(a)−ρn(a)|+∥∂ym,n
t(a)−Rn
t(a)∥}= 0. (18)
By Lemma B.1 and continuity of Twe have that T(ym,n−1
τmn)converges to T(yn−1
τn)andτm
n
converges to τnasm→+∞. Then, because yn
t= Φ(T(yn−1
τn), τn, t;x)andym,n
t =
Φ(T(ym,n−1
τmn), τm
n, t;xm), equation (17) follows from, Lemma B.2 and Corollary 11.16 in [ 17].
In fact, since B0was constructed in Lemma B.1 in such a way that τn(a)< tnfor all a∈B0we
also get that
lim
m→∞sup
a∈B0∂yn
τn(a)(a)Φ
yn
τn(a)(a), τn(a), t;x
−∂ym,n
τmn(a)(a)Φ
ym,n
τmn(a)(a), τm
n(a), t;xm= 0.
by the same corollary in [17]. Thus, to prove (18), it suffices to show that, for all n∈ {1, ..., N},
lim
m→∞sup
a∈B0∂ym,n−1
τmn(a)(a)−Rn−1
τn(a)(a)= 0.
We shall prove it using another inductive argument starting with n= 1. In this case it suffices to
show that
lim
m→∞sup
a∈B0∥∂aΦ (a,0, τ1(a);x)−∂aΦ (a,0, τm
1(a);xm)∥= 0.
By [7, Theorem 3.3] we know that the above holds if τm
1(a)andτ1(a)are replaced by τ1+δ1/2.
Now let Φ−1be the reverse of the flow map Φ, that is,
Φ−1(a1, s, t;x) =a0⇔Φ(a0, s, t;x) =a1.
22From Lemma B.1 it follows that y0
τ1(a)(a) = Φ−1(y0
t0(a), τ1(a), t0;x)and, for mlarge enough,
ym,0
τm
1(a)(a) = Φ−1(ym,0
t0(a), τm
1(a), t0;xm). But the result then follows from Lemma B.2 and [ 17,
Corollary 11.16]. To prove the inductive step, assume that (18) holds for all i≤n−1. Again, by
inspecting (6) and (7) and using the inductive assumption, one finds that it is enough to show that
lim
m→∞sup
a∈B0∂yn−1
τn−1Φ
yn−1
τn−1, τn−1, τn;x
−∂ym,n−1
τm
n−1Φ
ym,n−1
τm
n−1, τm
n−1, τm
n;xm= 0,
where we suppressed the dependence on afor notational simplicity. This is done exactly as for y0
and completes the proof of Step 2.
Step 3: The third and final step is to combine Step 1 and 2 to finish the proof. So far we have
proven that 1) the theorem holds for continuous paths of bounded variation and 2) (τm
n, ym,n
t)
converges to (τn, yn
t)and(∂τm
n(a), ∂ym,n
t(a))converges uniformly to (ρn(a), Rn
t(a))overa∈B0
for all t∈(τn, tn)andn∈[N]. From these results it immediately follows that (τn(a), yn
t(a))is
differentiable at a=y0with derivatives given by (ρn(y0), Rt(y0))for all t∈(τn, tn). What is left
to show then, is that this also holds for all other t. But this follows immediately from the chain rule
upon realizing that, for any τn< s < τ n+δn/2< t < τ n+1,
yn
t= Φ(yn
s, s, t;x)⇒∂yn
t=∂ynsΦ(yn
s, s, t;x)Rn
s(y0) =Rn
t(y0).
C Kernel methods
We give here a brief outline of some of the most central concepts related to kernel methods. For
a more in-depth introduction we refer the reader to [ 45,55,3]. LetXbe a topological space. We
shall in this paper only be concerned with positive definite kernels, that is, symmetric functions
k:X × X → Rfor which the Gram matrix is positive definite. To such a kernel one may associate a
feature map X →RXsuch that x7→kx=k(x,·). A reproducing kernel Hilbert space (RKHS) is a
Hilbert space H ⊂RXsuch that the evaluation functionals, evx:f7→f(x), are bounded for each
x∈ X. For all positive definite kernels there is a unique RKHS H ⊂RXsuch that f(x) =⟨kx, f⟩H
for all f∈ H andx∈ X. This is also known as the reproducing property . Furthermore, with H
denoting the linear span of {kx|x∈ X} , it holds that ¯H=H, i.e., His dense in H. Two important
properties of kernels are characteristicness anduniversality .
Definition C.1. Letk:X × X → Rbe a positive definite kernel. Denote by Hthe linear span
of{kx|x∈ X} and let F ⊂RXbe a topological vector space containing Hand such that the
inclusion map ι:H→ F is continuous.
•We say that kis universal to Fif the embedding of ι:H→ F is dense.
•We say that kis characteristic to F′if the embedding µ:F′→H′,D7→D|His injective
Remark C.1.This definition is the one used in [ 8] and is more general then the one usually encountered.
Note that in many cases (all the cases considered here, in fact) F′will contain the set of probability
measures on Xin which case kbeing characteristic implies that the kernel mean embedding µ7→
EX∼µkX(·)is injective.
Remark C.2.Often times, instead of starting with the kernel function kand then obtaining the RKHS,
one starts with a feature map F:X → H into a RKHS and then defines the kernel as the inner
product in that Hilbert space, i.e., k(x, y) =⟨F(x), F(y)⟩H. In such cases, it makes sense to ask
whether there are equivalent notions of Fbeing universal and characteristic. This is indeed the case
and the definition is almost the same as above. We refer to Definition 6 in [ 8] for a precise statement.
C.1 Marcus signature kernel
The definition of the signature kernel requires an initial algebraic setup. Let ⟨·,·⟩1be the Euclidean
inner product on Rd. Denote by ⊗the standard outer product of vector spaces. For any n∈N,
we denote by ⟨·,·⟩non(Rd)⊗nthe canonical Hilbert-Schmidt inner product defined for any a=
(a1, . . . , a n)andb= (b1, . . . , b n)in(Rd)⊗nas⟨a,b⟩n=Qn
i=1⟨ai, bi⟩1. The inner product ⟨·,·⟩n
23on(Rd)⊗ncan then be extended by linearity to an inner product ⟨·,·⟩on˜T((Rd))defined for any
a= (1, a1, . . .)andb= (1, b1, . . .)in˜T((Rd))as⟨a,b⟩= 1 +P∞
n=1⟨an, bn⟩n.
To begin with, let X=D1([0, T],Rd). Ifx∈ X is càdlàg path, we can define the Marcus signature
in the spirit of Marcus SDEs [ 42,43] as the signature of the Marcus interpolation ofx. This
interpolation, denoted by ˆx, is the continuous path on [0, T]obtained from xby linearly traversing
the jumps of xover added fictitious time r >0and then reparameterising so that the path runs over
[0, T]instead of [0, T+r]. The general construction is given in Appendix A. If xis continuous, x
andˆxcoincide; thus, without any ambiguity, we can define the Marcus signature S(x)of a general
bounded variation càdlàg path as the tensor series described above, but replacing xwithˆx(see also
the definition in A.2).
Since the signature is invariant to certain reparameterisations (Proposition A.1), it is not an injective
map. Injectivity is a crucial property required to ensure characteristicness of the resulting signature
kernel that we will introduce next. One way of overcome this issue is to to augment a path xwith
a time coordinate resulting in the path ˜x= (x, t)5. The Marcus signature kernel is then naturally
defined as the map k:X × X → Rsuch that k(x, y) =⟨S(˜x), S(˜y)⟩for any x, y∈ X. As stated in
Theorem C.1, this kernel is universal on compact subsets K⊂ X and, equivalently, characteristic to
the space of regular Borel measures on K. However, these properties do not generalize to the whole
space Cb(X,R)of bounded continuous functions from XtoR.
In [8] the authors address this issue in the case of continuous paths by introducing the so-called robust
signature . They define a tensor normalization as a continuous injective map
Λ :˜T  
Rd
→n
a∈˜T  
Rd
| ∥a∥ ≤Ro
for some R >0and such that Λ(a) = (a0, λ(a)a1, λ(a)2a2, . . .)for some λ:˜T  
Rd
→(0,∞).
Now, let p∈[1,3)and take C1
0(Rd)to be the space of absolutely continuous functions on Rd.
Recall that ΩD
0,p(Rd)is the closure of C1
0(Rd)inΩD
p(Rd)under the metric αp. Throughout we let
X= ΩD
0,p(Rd)be a metric space equipped with αp. Naturally, we can then define the signature
kernel on Xbyk(x,y) =⟨S(˜x), S(˜y)⟩and, similarly, the robust signature kernel kΛ(x,y) =
⟨Λ(S(˜x)),Λ(S(˜y))⟩where Λis a tensor normalisation.
Theorem C.1. Letp≥1,Λa tensor normalization, and K⊂ X compact under αp. Then,
(i)The signature kernel kis universal to F=C(K,R)equipped with the uniform topology
and characteristic to the dual F′, the space of regular Borel measures on K.
(ii)The robust signature kernel kΛis universal to F=Cb(X,R)equipped with the strict
topology and characteristic to the dual F′, the space of all finite Borel measures on X.
Proof of Theorem C.1. Part(i)follows directly from the proof of Proposition 3.6 in [ 13]. For part
(ii)we shall proof that the feature map F= Λ◦Sis universal and characteristic. The result
then follows from Proposition 29 in [ 8]. We start by defining P=X/∼twhere the equivalence
relation ∼tis defined in Appendix A.2. We equip Pwith the topology induced by the embedding
S:P → ˜T((Rd+1)). By Proposition A.1, Fis a continuous and injective map from Pinto a
bounded subset of ˜T((Rd+1)). Thus, H={⟨ℓ, F⟩ |ℓ∈T((Rd+1))′}is a subset of Fthat separates
points. Furthermore, since Ftakes values in the set of group-like elements, His a subalgebra of F
(under the shuffle product). It then follows from Theorem 7 and Theorem 9 in [ 8] that Fis universal
and characteristic. The fact that F′is the space of all finite Borel measures on Xis part (iii) of
Theorem 9 in the same paper. Finally, as per Appendix A.3, the map x7→˜xis a continuous and
injective embedding of XintoPfrom which the result then follows.
Withdkdenoting the MMD for a given kernel k:X ×X → R, the following is a direct consequence
of Theorem C.1.
Corollary C.1. Letp≥1,Λa tensor normalization, and K⊂ X compact under αp. Then, dkis a
metric on M(K)anddkΛis a metric on M(X).
5Ifxis a càdlàg rough path, this is done via a Young pairing which results in a càdlàg p-rough path, ˜x, where
the first level is given by (xt, t). For more information, we refer to Appendix A.3.
24D Forward sensitivities for SLIF network
In the general SSNN model, Theorem 3.2 gives the following result.
Proposition D.1. Fix some weight wij∈w, a neuron k∈[K]and let Gk
tdenote the gradient of
(vk, ik)wrt.wijat time t. Furthermore, define γ:{0,1} →R2such that γ0= (µ1,−µ2)wlk,
γ1= (µ1,0)vreset , and let Γ∈R2×2be the drift matrix in the inter-spike SDE of (vk, ik). Then,
Gk
t=eΓ(t−s) 
Gk
s−γδlk∂wijs+δilδjke2
, (19)
where en∈R2is the n’th unit vector, lis the neuron in Pak∪ {k}with the most recent spike time
before t, and we denote this spike time by s. Iftis a spike time of neuron kit therefore follows that
∂wijt=λ(vk
tprev)∂wijtprev−Rt
tprev∇λ(vk
r)eT
1Gk
rdr
λ(vk
t), (20)
where tprev is the previous spike time of neuron k. In the case of a deterministic SNN, formula (20)
is replaced by
∂wijt=−eT
1Gk
t
µ1(ik
t−vk
t). (21)
Proof. Throughout we fix some t >0and let s < t denote most recent event time preceding twithl
the index of the neuron firing at time s. We define the process dwt= 0dtwithw0=wijand with a
slight abuse of notation we shall write yk
t= (vk
t, ik
t, sk
t, wt). We will leave out the event index nfor
notational simplicity. Since yk
tdepends on ysonly through yk
sand∇Tlis block diagonal, a direct
consequence of eq. (7) is
Gk
t= (I0)∂yksyk
t 
∇Tl
j(yk
s−)∂wijyk
s−− 
µ(yk
s)− ∇Tk
l(yk
s−)µ(yk
s−)
∂wijs
where µ(v, i, s, w ) = ( µ1(i−v),−µ2i, λ(v),0). Ifl∈Pak∪ {k}, then Tk
l=idand therefore
Gk
t= (I0)∂yksyk
t∂wijyk
s. One can then reapply the formula above until l∈Pak∪ {k}. By the
flow property, it follows that we may assume without loss of generality that l∈Pak∪ {k}. This
leaves us with two cases. We define zk
t= (vk
t, ik
t)so that (I0)∂yksyk
t=∂zkszk
tand∂wijzk
t=Gk
t.
Furthermore, let a=δilδjk.
Case 1, l∈Pak:In this case Tk
l(v, i, s, w ) = (v, i+aw+ (1−a)c, s, w )where cis a constant. As
a result
∂zkszk
t∇Tk
l(yk
s−)∂yk
s−=∂zkszk
tGk
t+a∂ikszk
t,
∂zkszk
t 
µ(yk
s)− ∇Tk
l(yk
s−)µ(yk
s−)
=∂zkszk
tγ0,
In total,
Gk
t=∂zkszk
t 
Gk
t−γ0∂wijs+ae2
.
Case 2, l=k:In this case Tk
l(v, i, s, w ) = (v−vreset, i,logu−α, w)so that
∂zkszk
t∇Tk
l(yk
s−)∂yk
s−=∂zkszk
tGk
t,
∂zkszk
t 
µ(yk
s)− ∇Tk
l(yk
s−)µ(yk
s−)
=∂zkszk
tγ1,
and, thus,
Gk
t=∂zkszk
tGk
t−∂zkszk
tγ0∂wijs.
Note that zk
tis an Ornstein-Uhlenbeck process initialized at zk
sand with drift and diffusion matrices
Γ =
−µ1µ1
0−µ2
,Σ =
σ10
0σ2
.
As a result, we can directly compute ∂zkszk
t=e(t−s)Γ. This proves that eq. (19) holds. Eq. (20) then
follows directly from (6) and the fact that Ek(y) =sk.
25From this the results of Section 4.4 follow since the terms ∂wijsvanish whenever sis the spike time
of a neuron lthat is not a descendant of neuron j. Thus, equation (19) only includes terms depending
on the activity of the pre- and post-synaptic neuron. In particular, there is no need to store the gradient
pathGk
tfor each combination of neuron kand synapse ij, but each neuron only needs to keep track
of the paths for its incoming synapses. This reduces the memory requirements from the order of K3
to only K2(which is needed anyway to store the weight matrix). In general, the gradient paths can
be approximated by simply omitting the terms ∂wijs.
E Experiments
E.1 Input current estimation
6For each combination of sample size and σwe sample a data set of spike trains using Algorithm 1
withN= 3, i.e., up until the first three spikes are generated. We use diffrax to solve the inter-Event
SDE with a step size of 0.01and the numerical solver is the simple Euler-Maruyama method. We then
sample an initial guess c∼Unif([0.5,2.5])and run stochastic gradient descent using the approach
described in 4.1. That is, for each step, we generate a batch of the same size as the sample size
and use dkto compare the generated batch to the data. For each step we also compare the absolute
error between the average spike time of the first three spikes of the generated sample to a hold a
out test set of the same size as the sample. We use the RMSProp algorithm with a decay rate of 0.7
and a momentum of 0.3 which we found to work well in practice. The learning rate is 0.001. The
experiment was run locally on CPU with an Apple M1 Pro chip with 8 cores and 32 GB of ram. The
entire experiment took approximately 3-6 hours to run. For the exact details of this experiment we
refer to the notebook snnax/notebooks/single_neuron.ipynb in the supplementary material.
E.2 Synaptic weight estimation
As above, for each sample size D∈ {256,512,1024}we sample a data set of spike trains using
Algorithm 1 with T= 1and with the same differential equation solver setup as above. Thus, in this
case, the number of spikes varies across each sample path. The parameters are chosen as follows:
•vreset = 1.2
•λ(v) = exp(5( v−1)
•µ= (6,5)
•σ=I2/4
For each sample size the data was generated using the same randomly sampled weight matrix w
which represents a feed-forward network of the dimensions described in Section 4 and which was
constructed as follows: for the weight matrix from layer lto layer l+ 1, say wl, we sample each
entry from Unif([0.5,1.5])and then normalize by 3/Klwhere Klis the number of neurons in layer l.
The normalisation makes sure that the spike rate for the neurons in each layer is appropriate.
For each data set (each sample size) we then train a spiking neural net of the same network structure
to match the observed spike trains. This is done using stochastic gradient descent with a batch size of
B= 128 and by computing dkon a generated batch and a batch sampled from the data set at each
step. In order to avoid local minimums7we match the number of spikes between the generated spike
trains and the ones sampled from the data set. Also, we sample from the data set without replacement
so that we loop through the whole data set every D/B steps. We run RMSProp for 1500 steps with a
momentum of 0.3 and a learning rate of 0.003 for the first 1000 steps and 0.001 for the last 500 steps.
This experiment was run in the cloud using Azure AI Machine Learning Studio on a NVIDIA Tesla
V100 GPU with 6 cores and 112 GB of RAM. The entire experiment took around 12-16 hours to run.
For the exact details we refer to the notebook snnax/notebooks/spiking_neural_net.ipynb
in the supplementary material.
6For an updated version of some of the experiments and a general implementation of SSNNs in diffrax we
refer to github.com/cholberg/snnax.
7Note that the loss landscape is inherently discontinuous since whenever the parameters are altered in such a
way that an additional spike appears, the expected signature will jump.
260 250 500 750 1000 1250 1500
Step1020304050Test loss
0 250 500 750 1000 1250 1500
Step0.280.300.320.340.360.38/bardblˆwstep−wtrue/bardbl
Sample size
256
512
1024Figure 2: We estimate the synaptic weights wacross three different sample sizes using the signature kernel
MMD truncated at depth 3 and stochastic gradient descent with a batch size of 128. On the left we report the
loss on a hold out test set. On the right is the mean absolute error between the entries of the currently estimated
weight matrix ˆwstepand the true weight matrix wtrue.
NeurIPS Paper Checklist
1.Claims
Question: Do the main claims made in the abstract and introduction accurately reflect the
paper’s contributions and scope?
Answer: [Yes]
Justification: The claims are clearly stated in Section 1.1 which also references where to
find the key results.
Guidelines:
•The answer NA means that the abstract and introduction do not include the claims
made in the paper.
•The abstract and/or introduction should clearly state the claims made, including the
contributions made in the paper and important assumptions and limitations. A No or
NA answer to this question will not be perceived well by the reviewers.
•The claims made should match theoretical and experimental results, and reflect how
much the results can be expected to generalize to other settings.
•It is fine to include aspirational goals as motivation as long as it is clear that these goals
are not attained by the paper.
2.Limitations
Question: Does the paper discuss the limitations of the work performed by the authors?
Answer: [Yes]
Justification: There is a dedicated section (Section 5) clearly discussing what is lacking and
what can be explored in future work.
Guidelines:
•The answer NA means that the paper has no limitation while the answer No means that
the paper has limitations, but those are not discussed in the paper.
• The authors are encouraged to create a separate "Limitations" section in their paper.
•The paper should point out any strong assumptions and how robust the results are to
violations of these assumptions (e.g., independence assumptions, noiseless settings,
model well-specification, asymptotic approximations only holding locally). The authors
should reflect on how these assumptions might be violated in practice and what the
implications would be.
•The authors should reflect on the scope of the claims made, e.g., if the approach was
only tested on a few datasets or with a few runs. In general, empirical results often
depend on implicit assumptions, which should be articulated.
27•The authors should reflect on the factors that influence the performance of the approach.
For example, a facial recognition algorithm may perform poorly when image resolution
is low or images are taken in low lighting. Or a speech-to-text system might not be
used reliably to provide closed captions for online lectures because it fails to handle
technical jargon.
•The authors should discuss the computational efficiency of the proposed algorithms
and how they scale with dataset size.
•If applicable, the authors should discuss possible limitations of their approach to
address problems of privacy and fairness.
•While the authors might fear that complete honesty about limitations might be used by
reviewers as grounds for rejection, a worse outcome might be that reviewers discover
limitations that aren’t acknowledged in the paper. The authors should use their best
judgment and recognize that individual actions in favor of transparency play an impor-
tant role in developing norms that preserve the integrity of the community. Reviewers
will be specifically instructed to not penalize honesty concerning limitations.
3.Theory Assumptions and Proofs
Question: For each theoretical result, does the paper provide the full set of assumptions and
a complete (and correct) proof?
Answer: [Yes]
Justification: Rigorous proofs are provided in Appendix B and the assumptions are an
integral part of the paper.
Guidelines:
• The answer NA means that the paper does not include theoretical results.
•All the theorems, formulas, and proofs in the paper should be numbered and cross-
referenced.
•All assumptions should be clearly stated or referenced in the statement of any theorems.
•The proofs can either appear in the main paper or the supplemental material, but if
they appear in the supplemental material, the authors are encouraged to provide a short
proof sketch to provide intuition.
•Inversely, any informal proof provided in the core of the paper should be complemented
by formal proofs provided in appendix or supplemental material.
• Theorems and Lemmas that the proof relies upon should be properly referenced.
4.Experimental Result Reproducibility
Question: Does the paper fully disclose all the information needed to reproduce the main ex-
perimental results of the paper to the extent that it affects the main claims and/or conclusions
of the paper (regardless of whether the code and data are provided or not)?
Answer: [Yes]
Justification: We clearly describe the main algorithm used in both experiments (Algorithm 1)
as well as the experimental setups. Additionally, the code is provided in the supplementary
material with clear instructions on how to setup the correct environment.
Guidelines:
• The answer NA means that the paper does not include experiments.
•If the paper includes experiments, a No answer to this question will not be perceived
well by the reviewers: Making the paper reproducible is important, regardless of
whether the code and data are provided or not.
•If the contribution is a dataset and/or model, the authors should describe the steps taken
to make their results reproducible or verifiable.
•Depending on the contribution, reproducibility can be accomplished in various ways.
For example, if the contribution is a novel architecture, describing the architecture fully
might suffice, or if the contribution is a specific model and empirical evaluation, it may
be necessary to either make it possible for others to replicate the model with the same
dataset, or provide access to the model. In general. releasing code and data is often
one good way to accomplish this, but reproducibility can also be provided via detailed
28instructions for how to replicate the results, access to a hosted model (e.g., in the case
of a large language model), releasing of a model checkpoint, or other means that are
appropriate to the research performed.
•While NeurIPS does not require releasing code, the conference does require all submis-
sions to provide some reasonable avenue for reproducibility, which may depend on the
nature of the contribution. For example
(a)If the contribution is primarily a new algorithm, the paper should make it clear how
to reproduce that algorithm.
(b)If the contribution is primarily a new model architecture, the paper should describe
the architecture clearly and fully.
(c)If the contribution is a new model (e.g., a large language model), then there should
either be a way to access this model for reproducing the results or a way to reproduce
the model (e.g., with an open-source dataset or instructions for how to construct
the dataset).
(d)We recognize that reproducibility may be tricky in some cases, in which case
authors are welcome to describe the particular way they provide for reproducibility.
In the case of closed-source models, it may be that access to the model is limited in
some way (e.g., to registered users), but it should be possible for other researchers
to have some path to reproducing or verifying the results.
5.Open access to data and code
Question: Does the paper provide open access to the data and code, with sufficient instruc-
tions to faithfully reproduce the main experimental results, as described in supplemental
material?
Answer: [Yes]
Justification: Code is provided in the supplementary material. The two main experiments can
be reproduced by running the two notebooks in the snnax folder as referenced in Appendix
E.
Guidelines:
• The answer NA means that paper does not include experiments requiring code.
•Please see the NeurIPS code and data submission guidelines ( https://nips.cc/
public/guides/CodeSubmissionPolicy ) for more details.
•While we encourage the release of code and data, we understand that this might not be
possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not
including code, unless this is central to the contribution (e.g., for a new open-source
benchmark).
•The instructions should contain the exact command and environment needed to run to
reproduce the results. See the NeurIPS code and data submission guidelines ( https:
//nips.cc/public/guides/CodeSubmissionPolicy ) for more details.
•The authors should provide instructions on data access and preparation, including how
to access the raw data, preprocessed data, intermediate data, and generated data, etc.
•The authors should provide scripts to reproduce all experimental results for the new
proposed method and baselines. If only a subset of experiments are reproducible, they
should state which ones are omitted from the script and why.
•At submission time, to preserve anonymity, the authors should release anonymized
versions (if applicable).
•Providing as much information as possible in supplemental material (appended to the
paper) is recommended, but including URLs to data and code is permitted.
6.Experimental Setting/Details
Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
parameters, how they were chosen, type of optimiser, etc.) necessary to understand the
results?
Answer: [Yes]
Justification: We provide the most important aspects in Section 4. The full details are given
in Appendix E.
29Guidelines:
• The answer NA means that the paper does not include experiments.
•The experimental setting should be presented in the core of the paper to a level of detail
that is necessary to appreciate the results and make sense of them.
•The full details can be provided either with the code, in appendix, or as supplemental
material.
7.Experiment Statistical Significance
Question: Does the paper report error bars suitably and correctly defined or other appropriate
information about the statistical significance of the experiments?
Answer: [No]
Justification: We did not prioritise running multiple iterations of the experiments since the
main contributions are of a more theoretical nature.
Guidelines:
• The answer NA means that the paper does not include experiments.
•The authors should answer "Yes" if the results are accompanied by error bars, confi-
dence intervals, or statistical significance tests, at least for the experiments that support
the main claims of the paper.
•The factors of variability that the error bars are capturing should be clearly stated (for
example, train/test split, initialization, random drawing of some parameter, or overall
run with given experimental conditions).
•The method for calculating the error bars should be explained (closed form formula,
call to a library function, bootstrap, etc.)
• The assumptions made should be given (e.g., Normally distributed errors).
•It should be clear whether the error bar is the standard deviation or the standard error
of the mean.
•It is OK to report 1-sigma error bars, but one should state it. The authors should
preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis
of Normality of errors is not verified.
•For asymmetric distributions, the authors should be careful not to show in tables or
figures symmetric error bars that would yield results that are out of range (e.g. negative
error rates).
•If error bars are reported in tables or plots, The authors should explain in the text how
they were calculated and reference the corresponding figures or tables in the text.
8.Experiments Compute Resources
Question: For each experiment, does the paper provide sufficient information on the com-
puter resources (type of compute workers, memory, time of execution) needed to reproduce
the experiments?
Answer: [Yes]
Justification: This information is also given in Appendix E.
Guidelines:
• The answer NA means that the paper does not include experiments.
•The paper should indicate the type of compute workers CPU or GPU, internal cluster,
or cloud provider, including relevant memory and storage.
•The paper should provide the amount of compute required for each of the individual
experimental runs as well as estimate the total compute.
•The paper should disclose whether the full research project required more compute
than the experiments reported in the paper (e.g., preliminary or failed experiments that
didn’t make it into the paper).
9.Code Of Ethics
Question: Does the research conducted in the paper conform, in every respect, with the
NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines ?
30Answer: [Yes]
Justification: We have reviewed and made sure that our paper conforms with the code of
ethics.
Guidelines:
•The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
•If the authors answer No, they should explain the special circumstances that require a
deviation from the Code of Ethics.
•The authors should make sure to preserve anonymity (e.g., if there is a special consid-
eration due to laws or regulations in their jurisdiction).
10.Broader Impacts
Question: Does the paper discuss both potential positive societal impacts and negative
societal impacts of the work performed?
Answer: [NA]
Justification: The work in the paper is of a theoretical nature and there are no clear links to
immediate applications with broader societal impacts.
Guidelines:
• The answer NA means that there is no societal impact of the work performed.
•If the authors answer NA or No, they should explain why their work has no societal
impact or why the paper does not address societal impact.
•Examples of negative societal impacts include potential malicious or unintended uses
(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
(e.g., deployment of technologies that could make decisions that unfairly impact specific
groups), privacy considerations, and security considerations.
•The conference expects that many papers will be foundational research and not tied
to particular applications, let alone deployments. However, if there is a direct path to
any negative applications, the authors should point it out. For example, it is legitimate
to point out that an improvement in the quality of generative models could be used to
generate deepfakes for disinformation. On the other hand, it is not needed to point out
that a generic algorithm for optimizing neural networks could enable people to train
models that generate Deepfakes faster.
•The authors should consider possible harms that could arise when the technology is
being used as intended and functioning correctly, harms that could arise when the
technology is being used as intended but gives incorrect results, and harms following
from (intentional or unintentional) misuse of the technology.
•If there are negative societal impacts, the authors could also discuss possible mitigation
strategies (e.g., gated release of models, providing defenses in addition to attacks,
mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
feedback over time, improving the efficiency and accessibility of ML).
11.Safeguards
Question: Does the paper describe safeguards that have been put in place for responsible
release of data or models that have a high risk for misuse (e.g., pretrained language models,
image generators, or scraped datasets)?
Answer: [NA]
Justification:
Guidelines:
• The answer NA means that the paper poses no such risks.
•Released models that have a high risk for misuse or dual-use should be released with
necessary safeguards to allow for controlled use of the model, for example by requiring
that users adhere to usage guidelines or restrictions to access the model or implementing
safety filters.
•Datasets that have been scraped from the Internet could pose safety risks. The authors
should describe how they avoided releasing unsafe images.
31•We recognize that providing effective safeguards is challenging, and many papers do
not require this, but we encourage authors to take this into account and make a best
faith effort.
12.Licenses for existing assets
Question: Are the creators or original owners of assets (e.g., code, data, models), used in
the paper, properly credited and are the license and terms of use explicitly mentioned and
properly respected?
Answer: [Yes]
Justification: We have followed the citation guidelines for referencing diffrax which is
the main asset used for the current work.
Guidelines:
• The answer NA means that the paper does not use existing assets.
• The authors should cite the original paper that produced the code package or dataset.
•The authors should state which version of the asset is used and, if possible, include a
URL.
• The name of the license (e.g., CC-BY 4.0) should be included for each asset.
•For scraped data from a particular source (e.g., website), the copyright and terms of
service of that source should be provided.
•If assets are released, the license, copyright information, and terms of use in the
package should be provided. For popular datasets, paperswithcode.com/datasets
has curated licenses for some datasets. Their licensing guide can help determine the
license of a dataset.
•For existing datasets that are re-packaged, both the original license and the license of
the derived asset (if it has changed) should be provided.
•If this information is not available online, the authors are encouraged to reach out to
the asset’s creators.
13.New Assets
Question: Are new assets introduced in the paper well documented and is the documentation
provided alongside the assets?
Answer: [NA]
Justification:
Guidelines:
• The answer NA means that the paper does not release new assets.
•Researchers should communicate the details of the dataset/code/model as part of their
submissions via structured templates. This includes details about training, license,
limitations, etc.
•The paper should discuss whether and how consent was obtained from people whose
asset is used.
•At submission time, remember to anonymize your assets (if applicable). You can either
create an anonymized URL or include an anonymized zip file.
14.Crowdsourcing and Research with Human Subjects
Question: For crowdsourcing experiments and research with human subjects, does the paper
include the full text of instructions given to participants and screenshots, if applicable, as
well as details about compensation (if any)?
Answer: [NA]
Justification:
Guidelines:
•The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
•Including this information in the supplemental material is fine, but if the main contribu-
tion of the paper involves human subjects, then as much detail as possible should be
included in the main paper.
32•According to the NeurIPS Code of Ethics, workers involved in data collection, curation,
or other labor should be paid at least the minimum wage in the country of the data
collector.
15.Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
Subjects
Question: Does the paper describe potential risks incurred by study participants, whether
such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
approvals (or an equivalent approval/review based on the requirements of your country or
institution) were obtained?
Answer: [NA]
Justification:
Guidelines:
•The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
•Depending on the country in which research is conducted, IRB approval (or equivalent)
may be required for any human subjects research. If you obtained IRB approval, you
should clearly state this in the paper.
•We recognize that the procedures for this may vary significantly between institutions
and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
guidelines for their institution.
•For initial submissions, do not include any information that would break anonymity (if
applicable), such as the institution conducting the review.
33