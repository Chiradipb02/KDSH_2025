Approximation-Aware Bayesian Optimization
Natalie Maus
University of Pennsylvania
nmaus@seas.upenn.eduKyurae Kim
University of PennsylvaniaGeoff Pleiss
University of British Columbia
Vector Institute
David Eriksson
MetaJohn P. Cunningham
Columbia UniversityJacob R. Gardner
University of Pennsylvania
Abstract
High-dimensionalBayesianoptimization(BO)taskssuchasmoleculardesignoften
require>10,000functionevaluationsbeforeobtainingmeaningfulresults. While
methods like sparse variational Gaussian processes (SVGPs) reduce computational
requirements in these settings, the underlying approximations result in suboptimal
dataacquisitionsthatslowtheprogressofoptimization. Inthispaperwemodify
SVGPstobetteralignwiththegoalsofBO:targetinginformeddataacquisitionrather
than global posterior fidelity. Using the framework of utility-calibrated variational
inference,weunifyGPapproximationanddataacquisitionintoajointoptimization
problem, thereby ensuring optimal decisions under a limited computational budget.
Our approach can be used with any decision-theoretic acquisition function and
isreadilycompatible withtrustregion methodslikeTuRBO. We deriveefficient
joint objectives for the expected improvement and knowledge gradient acquisition
functionsforstandardandbatchBO.OurapproachoutperformsstandardSVGPs
on high-dimensional benchmark tasks in control and molecular design.
1 Introduction
Bayesianoptimization(BO;Frazier,2018;Garnett,2023;Jonesetal.,1998;Mockus,1982;Shahriari
etal.,2015)castsoptimizationasasequentialdecision-makingproblem. ManyrecentsuccessesofBO
have involved complex and high-dimensional problems. In contrast to “classic” low-dimensional BO
problems—where expensive black-box function evaluations far exceeded computational costs—these
modern problems necessitate tens of thousands of function evaluations, and it is often the complexity
and dimensionality of the search space that makes optimization challenging, rather than a limited
evaluationbudget(Erikssonetal.,2019;GriffithsandHernández-Lobato,2020;Mausetal.,2022,
2023;Stantonetal.,2022). Becauseofthesescenarios,BOisenteringaregimewherecomputational
costsare becominga primarybottleneck(Maddox etal.,2021; Mauset al.,2023;Moss etal.,2023;
Vakili et al., 2021), as the Gaussian process (GP; Rasmussen and Williams, 2005) surrogate models
that underpin most of Bayesian optimization scale cubically with the number of observations.
In this new regime, we require scalable GP approximations, an area that has made tremendous
progress over the last decade. In particular, sparse variational Gaussian processes (SVGP; Hensman
et al., 2013; Quiñonero-Candela and Rasmussen, 2005; Titsias, 2009) have seen an increase in
use(GriffithsandHernández-Lobato,2020;Maddoxetal.,2021;Mausetal.,2022,2023;Stanton
et al., 2022; Tripp et al., 2020; Vakili et al., 2021), but many challenges remain to effectively deploy
SVGPs for large-budget BO. In particular, the standard SVGP training objective is not aligned
with the goals of black-box optimization. SVGPs construct an inducing point approximation that
maximizes the standard variational evidence lower bound (ELBO; Jordan et al., 1999), yielding a
posteriorapproximation 𝑞∗(𝑓)thatmodelsallobserveddata(Matthewsetal.,2016;Mossetal.,2023).
However,theoptimalposteriorapproximation 𝑞∗issuboptimalforthedecision-makingtasksinvolved
38th Conference on Neural Information Processing Systems (NeurIPS 2024).in BO (Lacoste–Julien et al., 2011). In BO, we do not care about posterior fidelity at the majority
ofpriorobservations;rather,weonlycareaboutthefidelityofdownstreamfunctionsinvolvingthe
posterior, such as the expected utility. To illustrate this point intuitively, consider using the common
expectedimprovement(EI;Jonesetal.,1998)acquisitionfunctionforselectingnewobservations.
MaximizingtheELBOmightresultinaposteriorapproximationthatmaintainsfidelityfortraining
examples in regions of virtually zero EI, thus wasting “approximation budget.”
To solve this problem, we focus on the deep connections between statistical decision theory (Robert,
2001;Wasserman,2013,§12)andBayesianoptimization(Garnett,2023,§6-7),whereacquisition
maximizationcan beviewed asmaximizing posterior-expected utility. Following thisperspective,
we leverage the utility-calibrated approximate inference framework (Jaiswal et al., 2020, 2023;
Lacoste–Julien et al., 2011), and solve the aforementioned problem through a variational bound (Blei
etal.,2017;Jordanetal.,1999)–the(log) expectedutilitylowerbound( EULBO)—ajointfunction
of the decision (the BO query) and the posterior approximation (the SVGP). When optimized
jointly, the EULBOautomatically yields the approximately optimal decision through the minorize-
maximize principle (Lange, 2016). The EULBOis reminiscent of the standard variational ELBO
(Jordan et al., 1999), and can indeed be viewed as a standard ELBO for a generalized Bayesian
inferenceproblem(Bissirietal.,2016;Knoblauchetal.,2022),whereweseektoapproximatethe
utility-weighted posterior. This work represents the first application of utility-calibrated approximate
inference towards BO despite its inherent connection with utility maximization.
The benefits of our proposed approach are visualized in Fig. 1. Furthermore, it can be applied
to acquisition function that admits a decision-theoretic interpretation, which includes the popular
expectedimprovement(EI;Jonesetal.,1998)andknowledgegradient(KG;Wuetal.,2017)acquisition
functions, and is trivially compatible with local optimization techniques like TuRBO (Eriksson et al.,
2019) for high-dimensional problems. We demonstrate that our joint SVGP/acquisition optimization
approachyieldssignificantimprovementsacrossnumerousBayesianoptimizationbenchmarks. Asan
added benefit, our approach can simplify the implementation and reduce the computational burden of
complex(decision-theoretic)acquisitionfunctionslikeKG.Wedemonstrateanovelalgorithmderived
from our joint optimization approach for computing and optimizing the KG that expands recent work
on one-shot KG (Balandatet al., 2020) and variational GP posterior refinement(Maddox et al.,2021).
Overall, our contributions are summarized as follows:
∙We propose utility-calibrated variational inference of SVGPs in the context of large-budget BO.
∙Westudythisframeworkintwospecialcasesusingtheutilityfunctionsoftwocommonacquisition
functions: EI and KG. For each, we derive tractable EULBOexpressions that can be optimized.
∙For KG, we demonstrate that the computation of the EULBOtakes only negligible additional
work over computing the standard ELBO by leveraging an online variational update. Thus, as a
byproduct of optimizing the EULBO, optimizing KG becomes comparable to the cost of the EI.
∙We extend this framework to be capable of running in batch mode, by introducing q-EULBO
analogs of q-KG and q-EI as commonly used in practice (Wilson et al., 2018).
∙We demonstrate the effectiveness of our proposed method against standard SVGPs trained with
ELBO maximization on high-dimensional benchmark tasks in control and molecular design,
where the dimensionality and evaluation budget go up to 256 and 80k, respectively.
2 Background
Noisy Black-Box Optimization. Noisy black-box optimization refers to problems of the form:
maximize 𝒙∈𝒳𝐹(𝒙),where 𝒳⊂ℝ𝑑is some compact domain, 𝐹∶𝒳→𝒴is some objective
function, and we assume that only zeroth-order information of 𝐹is available. More formally, for
some𝑖∈ℕ>0, we assume that observations of the objective function (𝒙𝑖,𝑦𝑖=ˆ𝐹(𝒙𝑖))have been
corrupted by independently and identically distributed (i.i.d.) Gaussian noise ˆ𝐹(𝒙𝑖)≜𝐹(𝒙𝑖)+𝜖,
where𝜖∼𝒩(0,𝜎2
n). The noise variance 𝜎2
nis also unknown.
Bayesian optimization. Bayesian Optimization (BO) is and iterative approach to noisy black-box
optimization that iterates the following steps: ❶At each step 𝑡≥0, we use a set of observations
𝒟𝑡= {(𝒙𝑖,𝑦𝑖=ˆ𝐹(𝒙𝑖))}𝑛𝑡
𝑖=1ofˆ𝐹to fit a surrogate supervised model 𝑓∈ℱ. Typically, ℱis taken
to be the sample space of a Gaussian process such that the function-valued posterior distribution
2ELBO fit (m=4)
 ELBO EULBO (Ours)
Data True function Inducing points GP mean EI (approx) EI (exact)Figure 1: (Left.)Fitting an SVGP model with only 𝑚=4inducing points sacrifices modeling areas
ofhighEI(fewdatapointsatright)becausetheELBOfocusesonlyonglobaldataapproximation
(left data) and is ignorant of the downstream decision making task. (Middle.) Because of this,
(normalized)EIwiththeSVGPmodelpeaksinanincorrectlocationrelativetotheexactposterior.
(Right.)UpdatingtheGPfitandselectingacandidatejointlyusingthe EULBO(ourmethod)resultsin
candidate selection much closer to the exact model.
𝜋(𝑓∣𝒟)forms a distribution over surrogate models at step 𝑡.❷The posterior is then used to
form a decision problem where we choose which point we should evaluate next, 𝒙𝑡+1=𝛿𝛼(𝒟𝑡), by
maximizing an acquisition function 𝛼∶𝒳→ℝas
𝛿𝛼(𝒟𝑡)≜argmax
𝒙∈𝒳𝛼(𝒙;𝒟𝑡). (1)
❸After selecting 𝒙𝑡+1,ˆ𝐹isevaluated to obtainthe new datapoint (𝒙𝑡+1,𝑦𝑡+1=ˆ𝐹(𝒙𝑡+1)). This is
then added to the dataset, forming 𝒟𝑡+1=𝒟𝑡∪(𝒙𝑡+1,𝑦𝑡+1)to be used in the next iteration.
Utility-BasedAcquisitionFunctions. Manycommonlyusedacquisitionfunctions,includingEI
and KG, can be expressed as posterior-expected utility functions
𝛼(𝒙;𝒟)≜∫𝑢(𝒙,𝑓;𝒟)𝜋(𝑓∣𝒟)d𝑓, (2)
where𝑢(𝒙,𝑓;𝒟)∶𝒳×ℱ→ℝis some utility function associated with 𝛼(Garnett, 2023, §6-7). In
statistical decision theory, posterior-expected utility maximization policies such as 𝛿𝛼are known as
Bayespolicies . Theseareimportantbecause,foragivenutilityfunction,theyattaincertainnotionsof
statistical optimality such as Bayes optimality and admissibility (Robert, 2001, §2.4; Wasserman,
2013, §12). However, this only holds true if we can exactly compute Eq. (2) over the posterior. Once
approximate inference is involved, making optimal Bayes decisions becomes challenging.
SparseVariationalGaussianProcesses. Whilethe 𝒪(𝑛3)complexityofexactGaussianprocess
model selection and inference is not necessarily a roadblock in the traditional regression setting
with10,000-50,000training examples, BO amplifies the scalability challenge by requiring us to
sequentially train or update manylarge scale GPs as we iteratively acquire more data.
To address this, sparse variational GPs (SVGP; Hensman et al., 2013; Titsias, 2009) have become
commonly used in high-throughput Bayesian optimization. SVGPs modify the original GP prior
from𝑝(𝑓)to𝑝(𝑓∣𝒖)𝑝(𝒖), where we assume the latent function 𝑓is “induced” by a finite set of
inducing values 𝒖=(𝑢1,…,𝑢𝑚)∈ℝ𝑚located at inducing points 𝒛𝑖∈𝒳for𝑖=1,…,𝑚. Inference
isdonethroughvariationalinference(Bleietal.,2017;Jordanetal.,1999),wheretheposteriorofthe
inducing points is approximated using 𝑞𝝀(𝒖)=𝒩(𝒖;𝝀=(𝒎,𝑺))and that of the latent functions
with𝑞(𝑓∣𝒖)=𝑝(𝑓∣𝒖). Here, the variational parameters 𝒎and𝑺are defined as the learned mean
andcovarianceofthevariationaldistribution 𝑞𝝀(𝒖). Itisstandardpracticetodefine 𝝀=(𝒎,𝑺)so
that𝝀can be used as shorthand to represent all of the trainable variational parameters. As is typical
in the BO literature, we use the subscript 𝝀∈Λto denote that the distribution denoted as 𝑞contains
trainable parameters in 𝝀.
Forapositivedefinitekernelfunction 𝑘∶𝒳×𝒳→ℝ>0,theresultingELBOobjective,whichcan
be computed in a closed form (Hensman et al., 2013), is then
ℒELBO(𝝀;𝒟𝑡)≜𝔼𝑞𝜆(𝑓)[∑𝑛𝑡
𝑖=1log𝓁(𝑦𝑖∣𝑓(𝒙𝑖))]
−DKL(𝑞𝜆(𝒖),𝑝(𝒖)), (3)
where 𝓁(𝑦𝑖∣𝑓(𝒙𝑖)) =𝒩(𝑦𝑖∣𝑓(𝒙𝑖),𝜎𝜖)is a Gaussian likelihood. The marginal variational
approximation can be computed as
𝑞𝜆(𝑓)=∫𝑞𝝀(𝑓,𝒖)d𝒖=∫𝑝(𝑓∣𝒖)𝑞𝜆(𝒖)d𝒖
3such that the point-wise function evaluation on some 𝒙∈𝒳is
𝑞𝜆(𝑓(𝒙))=𝒩(
𝑓(𝒙);𝜇𝑓(𝒙)≜𝑲𝒙𝒁𝑲−1
𝒁𝒁𝒎, 𝜎2
𝑓(𝒙)≜˜𝑘𝒙𝒙+𝒌⊤
𝒙𝒁𝑲−1
𝒁𝒁𝑺𝑲−1
𝒁𝒁𝒌𝒁𝒙)
,(4)
with˜𝑘𝒙𝒙≜𝑘(𝒙,𝒙)−𝒌𝒙𝒁𝑲−1
𝒁𝒁𝒌⊤
𝒁𝒙, the vector𝒌𝒁𝒙∈ℝ𝑚is formed as [𝒌𝒁𝒙]𝑖=𝑘(𝒛𝑖,𝒙), and the
matrix𝑲𝒁𝒁∈ℝ𝑚×𝑚isformedas [𝑲𝒁𝒁]𝑖𝑗=𝑘(𝒛𝑖,𝒛𝑗). Additionally,theGPlikelihoodandkernel
contain hyperparameters, which we denote as 𝜽∈Θ, and we collectively denote the set of inducing
point locations as 𝒁=(𝒛1,…,𝒛𝑚)∈𝒳𝑚. We therefore denote the ELBO as ℒELBO(𝝀,𝒁,𝜽;𝒟𝑡).
3 Approximation-Aware Bayesian Optimization
WhenSVGPsareusedinconjunctionwithBO(Maddoxetal.,2021;Mossetal.,2023)atiteration
𝑡≥0, acquisition functions of the form of Eq. (2) are naïvely approximated as
𝛼(𝒙;𝒟)≈∫𝑢(𝒙,𝑓;𝒟𝑡)𝑞𝝀(𝑓)d𝑓,
where𝑞𝝀(𝑓)is the approximate SVGP posterior given by Eq. (4). The acquisition policy implied by
this approximation contains two separate optimization problems:
𝒙𝑡+1=argmax
𝒙∈𝒳∫𝑢(𝒙,𝑓;𝒟𝑡)𝑞𝝀∗
ELBO(𝑓)d𝑓and𝝀∗
ELBO=argmax
𝝀∈ΛℒELBO(𝝀;𝒟𝑡).(5)
Treating these optimization problems separately creates an artificial bottleneck that results in
suboptimaldataacquisitiondecisions. Intuitively, 𝝀∗
ELBOischosentofaithfullymodelallobserved
data(Matthewsetal.,2016;Mossetal.,2023),withoutregardforhowtheresultingmodelperformsat
selecting thenextfunction evaluation in theBOloop. Foran illustrationof this, see Figure 1. Instead,
weproposeamodificationtoSVGPsthatcouplestheposteriorapproximationanddataacquisition
through a joint problem of the form:
(𝒙𝑡+1,𝝀∗)=argmax
𝝀∈Λ,𝒙∈𝒳ℒEULBO(𝝀,𝒙;𝒟𝑡). (6)
Thisresultsin 𝒙𝑡+1directlyapproximatingasolutiontoEq.(2),wherethe expectedutilitylower-
bound(EULBO) is an ELBO-like objective function derived below.
3.1 Expected Utility Lower-Bound
ConsideranacquisitionfunctionoftheformofEq.(2),wheretheutility 𝑢∶𝒳×ℱ→ℝ>0isstrictly
positive. Wecanderiveasimilarvariationalformulationoftheacquisitionfunctionmaximization
problem following Lacoste–Julien et al. (2011). That is, given any distribution 𝑞𝝀indexed by𝝀∈Λ
and considering theSVGPprioraugmentation 𝑝(𝑓)→𝑝(𝑓∣𝒖)𝑝(𝒖), theacquisition function canbe
lower-bounded through Jensen’s inequality as
log𝛼(𝒙;𝒟𝑡)=log ∫𝑢(𝒙,𝑓;𝒟𝑡)𝜋(𝑓∣𝒟𝑡)d𝑓
=log ∫𝑢(𝒙,𝑓;𝒟𝑡)𝜋(𝑓,𝒖∣𝒟𝑡)𝑞𝝀(𝑓,𝒖)
𝑞𝝀(𝑓,𝒖)d𝑓d𝒖
=log ∫𝑢(𝒙,𝑓;𝒟𝑡)𝓁(𝒟𝑡∣𝑓)𝑝(𝑓∣𝒖)𝑝(𝒖)𝑞𝝀(𝒖)𝑝(𝑓∣𝒖)
𝑞𝝀(𝒖)𝑝(𝑓∣𝒖)d𝑓d𝒖−log𝑍
≥∫log(𝑢(𝒙,𝑓;𝒟𝑡)𝓁(𝒟𝑡∣𝑓)𝑝(𝒖)
𝑞𝝀(𝒖))𝑝(𝑓∣𝒖)𝑞𝝀(𝒖)d𝑓d𝒖−log𝑍, (7)
where𝑍is a normalizing constant. A restriction on 𝑢comes from the inequality in Eq. (7), where the
utility needs to be strictly positive. This means that non-strictly positive utilities need to be modified
tobeincorporatedintothisframework. (Seetheexamplesby Kuśmierczyketal.,2019.) Also,notice
that the derivation is reminiscent of expectation-maximization (Dempster et al., 1977) and variational
lower bounds (Jordan et al., 1999). That is, through the minorize-maximize principle (Lange, 2016),
maximizingthelowerboundwithrespectto 𝒙and𝝀approximatelysolvestheoriginalproblemof
maximizing the posterior-expected utility.
4ExpectedUtilityLower-Bound. Uptoaconstantandrearrangingterms,maximizingEq.(7)is
equivalent to maximizing
ℒEULBO(𝝀,𝒙;𝒟𝑡)≜𝔼𝑝(𝑓∣𝒖)𝑞𝜆(𝒖)[log𝓁(𝒟𝑡∣𝑓)+log𝑝(𝒖)−log𝑞𝜆(𝒖)+log𝑢(𝒙,𝑓;𝒟𝑡)]
=𝔼𝑞𝜆(𝑓)[∑𝑛𝑡
𝑖=1log𝓁(𝑦𝑖∣𝑓)]
−DKL(𝑞𝝀(𝒖),𝑝(𝒖))+𝔼𝑞𝜆(𝑓)log𝑢(𝒙,𝑓;𝒟𝑡)
=ℒELBO(𝝀;𝒟𝑡)+𝔼𝑞𝝀(𝑓)log𝑢(𝒙,𝑓;𝒟𝑡), (8)
whichisthejointobjectivefunctionalludedtoinEq.(6). Wemaximize EULBOtoobtain(𝒙𝑡+1,𝝀∗)=
argmax𝒙∈𝒳,𝝀∈ΛℒEULBO(𝒙,𝝀), where𝒙𝑡+1corresponds our next BO “query”.
From Eq. (8), the connection between the EULBOand ELBO is obvious: the EULBOis now “nudging”
theELBOsolutiontowardhighutilityregions. Analternativeperspectiveisthatweareapproximating
ageneralized posterior weighted by the utility (Table. 1 by Knoblauch et al., 2022; Bissiri et al.,
2016). Furthermore,Jaiswaletal.(2020,2023)provethattheresultingactionssatisfyconsistency
guarantees under assumptions typical in such results for variational inference (Wang and Blei, 2019).
Hyperparameters and Inducing Point Locations. For the hyperparameters 𝜽and inducing point
locations𝒁, we use the marginal likelihood to perform model selection, which is common practice in
BO (Shahriari et al., 2015, §V.A). (Optimizing over 𝒁was popularized by Snelson and Ghahramani,
2005.) Following suit, we also optimize the EULBOas a function of 𝜽and𝒁as
maximize
𝝀,𝒙,𝜽,𝒁{ℒEULBO(𝝀,𝒙,𝜽,𝒁;𝒟𝑡)≜ ℒELBO(𝝀,𝒁,𝜽;𝒟𝑡)+𝔼𝑞𝝀(𝑓)log𝑢(𝒙,𝑓;𝒟𝑡)}.
WeemphasizeherethattheSVGP-associated parameters 𝝀,𝜽,𝒁havegradientsthat aredetermined
bybothterms above. Thus, the expected log-utility term 𝔼𝑓∼𝑞𝝀(𝑓)log𝑢(𝒙,𝑓;𝒟𝑡)simultaneously
results in acquisition of 𝒙𝑡+1and directly influences the underlying SVGP regression model.
3.2 EULBOfor Expected Improvement (EI)
The EI acquisition function can be expressed as a posterior-expected utility, where the underlying
“improvement” utility function is given by the difference between the objective value of the query,
𝑓(𝒙), and the current best objective value 𝑦∗
𝑡=max𝑖=1,…,𝑡{𝑦𝑖∣𝑦𝑖∈𝒟𝑡}:
𝑢EI(𝒙,𝑓;𝒟𝑡)≜ReLU(𝑓(𝒙)−𝑦∗
𝑡),(EI; Jones et al., 1998) (9)
whereReLU(𝑥)≜max(𝑥,0). Unfortunately,thisutilityisnotstrictlypositivewhenever 𝑓(𝒙)≤𝑦∗.
Thus, we cannot immediately plug 𝑢EIinto the EULBO. While it is possible to add a small positive
constant to 𝑢EIand make it strictly positive as done by Kuśmierczyk et al. (2019), this results in a
looser Jensen gap in Eq. (7), which could be detrimental. This also introduces the need for tuning the
constant, which is not straightforward. Instead, we define the following “soft” EI utility:
𝑢SEI(𝒙,𝑓;𝒟𝑡)≜softplus(𝑓(𝒙)−𝑦∗
𝑡),
where the ReLU in Eq. (9) is replaced with softplus(𝑥)≜log(1+exp(𝑥)).softplus(𝑥)converges
totheReLUinbothextremesof 𝑥→±∞. Thus,𝑢SEIwillbehavecloselyto 𝑢EI,whilebeingslightly
more explorative due to positivity.
Computingthe EULBOanditsderivativesnowrequiresthecomputationof 𝔼𝑓∼𝑞𝝀(𝑓)log𝑢SEI(𝒙,𝑓;𝒟𝑡),
which, unlike EI, does not have a closed-form. However, since the utility function only depends
on the function values of 𝑓, the expectation can be efficiently computed to high precision through
one-dimensional Gauss-Hermite quadrature. Crucially, the expensive 𝐾−1
𝑧𝑧𝑚and𝐾−1
𝑧𝑧𝑆𝐾−1
𝑧𝑧solves
that dominate both the asymptotic and practical running time of both the ELBO and the EULBO are
fixedacrossthelogutilityevaluationsneededbyquadrature. Becausequadratureonlydependson
theseprecomputedmoments, theadditionalworknecessaryduetolackingaclosedformsolutionis
negligible: Gauss-Hermite quadrature converges extremely quickly in the number of quadrature sites,
and only requires on the order of 10 or so of these post-solve evaluations to achieve near machine
precision.
3.3 EULBOfor Knowledge Gradient (KG)
Although non-trivial, the KG acquisition is also a posterior-expected utility, where the underlying
utilityfunction isgiven bythe maximumpredictive meanvalueanywhereinthe inputdomain after
5conditioning on a new observation (𝒙,𝑦)∈𝒳×𝒴:
𝑢KG(𝒙,𝑦;𝒟𝑡)≜max
𝒙′∈𝒳𝔼[𝑓(𝒙′)∣𝒟𝑡∪{(𝒙,𝑦)}].(KG; Frazier, 2009; Garnett, 2023)
Notethattheutilityfunctionasdefinedaboveisnotnon-negative: themaximumpredictivemeanofa
Gaussianprocesscanbenegative. Forthisreason,theutilityfunctioniscommonly(andoriginally,
e.g.Frazier, 2009, Eq. 4.11) written in the literature as the difference between the new maximum
mean after conditioning on (𝒙,𝑦)and the maximum mean beforehand:
𝑢KG(𝒙,𝑦;𝒟𝑡)≜max
𝒙′∈𝒳𝔼[𝑓(𝒙′)∣𝒟𝑡∪{(𝒙,𝑦)}]−𝜇+
𝑡,
where𝜇+
𝑡≜max𝒙′′∈𝒳𝐸[𝑓(𝒙′′)∣𝒟𝑡]
. Notethat𝜇+
𝑡playstheroleofasimpleconstantasitdepends
on neither𝒙nor𝑦. Similarly to the EI acquisition, this utility is still not strictly positive, and we thus
define its “softplus-ed” variant:
𝑢SKG(𝒙,𝑦;𝒟𝑡)≜softplus(𝑢KG(𝒙,𝑦;𝒟𝑡)−𝑐+).
Here,𝑐+acts as𝜇+
𝑡by making𝑢KGpositive as often as possible. This is particularly important when
the GP predictive mean is negative as a consequence of the objective values being negative. One
naturalchoiceofconstantisusing 𝜇+
𝑡;however,wefindthatsimplychoosing 𝑐+=𝑦+
𝑡workswell
and is more computationally efficient. Here, 𝑦+
𝑡is the highest value of 𝑦𝑡(the highest objective value
observed so far).
One-Shot KG EULBO.TheEULBOusing𝑢SKGresults in an expensive nested optimization problem.
Toaddressthis,weuseanapproachsimilartotheone-shotknowledgegradientmethodofBalandat
et al. (2020). For clarity, we will define the reparameterization function
𝑦𝝀(𝒙;𝜖𝑖)≜𝜇𝑞𝜆(𝒙)+𝜎𝑞𝜆(𝒙)𝜖𝑖,
where, for an i.i.d. sample 𝜖𝑖∼𝒩(0,1), computing 𝑦𝑖=𝑦𝝀(𝒙,𝜖𝑖)is equivalent to sampling
𝑦𝑖∼𝒩(𝜇𝑞𝜆(𝒙),𝜎𝑞𝜆(𝒙))
. This enables the use of the reparameterization gradient estimator (Kingma
andWelling,2014;Rezendeet al.,2014;TitsiasandLázaro-Gredilla, 2014). Now, noticethat theKG
acquisition function can be approximated through Monte Carlo as
𝛼KG(𝒙;𝒟)≈1
𝑆𝑆∑
𝑖=1𝑢KG(𝒙,𝑦𝝀(𝒙;𝜖𝑖);𝒟𝑡)=1
𝑆𝑆∑
𝑖=1max
𝒙′𝔼[𝑓(𝒙′)∣𝒟𝑡∪{𝒙,𝑦𝝀(𝒙;𝜖𝑖)}],
where, for 𝑖= 1,…,𝑆,𝜖𝑖∼𝒩(0,1)are i.i.d. The one-shot KG approach absorbs the nested
optimization over 𝒙′into a simultaneous joint optimization over 𝒙and a mean maximizer for each of
the S samples, 𝒙′
1,...,𝒙′
𝑆such thatmax𝒙𝛼KG(𝒙;𝒟𝑡)≈max𝒙,𝒙′
1,...,𝒙′
𝑆𝛼1-KG(𝒙;𝒟),where
𝛼1-KG(𝒙;𝒟𝑡)≜1
𝑆𝑆∑
𝑖=1𝑢1-KG(𝒙,𝒙′
𝑖,𝑦𝝀(𝒙;𝜖𝑖);𝒟𝑡)=1
𝑆𝑆∑
𝑖=1𝔼[𝑓(𝒙′
𝑖)∣𝒟𝑡∪{𝒙,𝑦𝝀(𝒙;𝜖𝑖)}],
Evidently, thereisnolonger aninneroptimization problemover 𝒙′. To estimatethe 𝑖thterm ofthis
sum, we draw a sample of the objective value of 𝒙,𝑦𝝀(𝒙;𝜖𝑖), and condition the model on this sample.
We then compute the new posterior predictive mean at 𝒙′
𝑖. After summing, we compute gradients
with respect to both the candidate 𝒙and the mean maximizers 𝒙′
1,...,𝒙′
𝑆. Again, we use the “soft”
version of one-shot KG in our EULBOoptimization problem:
𝑢1-SKG(𝒙,𝒙′,𝑦;𝒟𝑡)=softplus(𝔼[𝑓(𝒙′)∣𝒟𝑡∪{(𝒙,𝑦)}]−𝑐+),
wherethisutilityfunctioniscruciallyafunctionofboth 𝒙andafreeparameter 𝒙′. Aswith𝛼1-KG,
maximizing the EULBOcan be set up as a joint optimization problem:
maximize
𝒙,𝒙′
1,...,𝒙′
𝑆,𝝀,𝒁,𝜽ℒELBO(𝝀,𝒁,𝜽)+1
𝑆𝑆∑
𝑖=1log𝑢1-SKG(𝒙,𝒙′
𝑖,𝑦𝝀(𝒙;𝜖𝑖);𝒟𝑡)(10)
EfficientKG- EULBOComputation. Thecomputationtimeofthenon-ELBOterminEq.(10)is
dominated by having to compute 𝔼[𝑓(𝒙′
𝑖)∣𝒟𝑡∪{(𝒙,𝑦𝝀(𝒙;𝜖𝑖))}]𝑆-times. Notice that we only need
to compute an updated posterior predictive mean, and can ignore predictive variances. For this,
we can leverage the online updating strategy of Maddox et al. (2021). In particular, the predictive
mean can be updated in 𝒪(𝑚2)time using a simple Cholesky update. The additional 𝒪(𝑆𝑚2)cost of
computing the EULBOis therefore amortized by the original 𝒪(𝑚3)cost of computing the ELBO.
63.4 Extension to q-EULBO for Batch Bayesian Optimization
TheEULBOcan be extended to support batch Bayesian optimization by using the Monte Carlo batch
mode analogs of utility functions as discussed e.g.by Balandat et al. (2020); Wilson et al. (2018).
Given a set of candidates 𝑿=(𝒙1,...,𝒙𝑞)∈𝒳𝑞, the𝑞-EI utility function is given by:
𝑢𝑞-EI(𝑿,𝒇;𝒟𝑡)≜max
𝑗=1...𝑞ReLU(𝑓(𝒙𝑗)−𝑦∗
𝑡)(q-EI; Balandat et al., 2020; Wilson et al., 2018)
This utility can again be softened as:
𝑢𝑞-SEI(𝑿,𝒇;𝒟𝑡)≜max
𝑗=1…𝑞softplus(𝑓(𝒙𝑗)−𝑦∗
𝑡)
Because this is now a 𝑞-dimensional integral, Gauss-Hermite quadrature is no longer applicable.
However, we can apply Monte Carlo as
𝔼𝑞𝝀(𝑓)log𝑢𝑞-SEI(𝑿,𝒇;𝒟𝑡)≈1
𝑆𝑆∑
𝑖=1max
𝑗=1...𝑞softplus(𝑦𝝀(𝒙;𝜖𝑖)−𝑦∗
𝑡).
As done in the BoTorch software package (Balandat et al., 2020), we observe that fixing the set of
base samples 𝜖1,...,𝜖𝑆during each BO iteration results in better optimization performance at the cost
ofnegligible q-EULBO bias. Now,optimizingthe q-EULBO isdoneoverthefullsetof 𝑞candidates(𝒙1,...,𝒙𝑞)jointly, as well as the GP hyperparameters, inducing points, and variational parameters.
KnowledgeGradient. TheKGversionofthe EULBOcanbesimilarlyextended. Theexpectedlog
utility term in the maximization problem Eq. (10) becomes:
maximize
𝒙1,...,𝒙𝑞,𝒙′
1,...,𝒙′
𝑆,𝝀,𝒁,𝜽ℒELBO(𝝀,𝒁,𝜽)+1
𝑆𝑆∑
𝑖=1max
𝑗=1..𝑞log𝑢1-SKG(𝒙𝑗,𝒙′
𝑖,𝑦𝝀(𝒙;𝜖𝑖);𝒟𝑡),
resulting in a similar analog to q-KG as described by Balandat et al. (2020).
3.5 Optimizing the EULBO
Optimizing the ELBO for SVGPs is known to be challenging (Galy-Fajou and Opper, 2021; Terenin
etal.,2024)astheoptimizationlandscapefortheinducingpointsisnon-convex,multi-modal,and
non-smooth. Naturally,these are alsochallenges for EULBO; wefound thatcare must betaken when
implementing and initializing the EULBOmaximization problem. In this subsection, we outline some
key ideas, while a detailed description with pseudocode is presented in Appendix A.
Initialization and Warm-Starting. We warm-start the EULBOmaximization procedure by solving
the conventional two-step scheme in Eq. (5): At each BO iteration, we obtain the “warm” initial
valuesfor(𝝀,𝒁,𝜽)byoptimizingthestandardELBO.Then,weusethistomaximizetheconventional
acquisition function corresponding to the chosen utility function 𝑢(the expectation of 𝑢over𝑞𝝀(𝑓)),
which provides the warm-start initialization for 𝒙.
Alternating MaximizationScheme. To optimize ℒEULBO(𝒙,𝝀,𝒁,𝜽), wealternate between opti-
mizing over the query 𝒙and the SVGP parameters 𝝀,𝒁,𝜽. We find this block-coordinate descent
scheme to be more stable and robust than jointly updating all parameters, though the reason why this
is more stable than jointly optimizing all parameters requires further investigation.
4 Experiments
We evaluate EULBO-based SVGPs on a number of benchmark BO tasks, described in detail in
Section 4.1. These tasks include standard low-dimensional BO problems, e.g., the 6D Hartmann
function, as well as 7 high-dimensional and high-throughput optimization tasks.
Baselines. We compare EULBOto several baselines withthe main goal ofachievinga high reward
usingasfewfunctionevaluationsaspossible. OurprimarypointofcomparisonisELBO-basedSVGPs.
We consider two approaches for inducing point locations: 1. optimizing inducing point locations via
theELBO(denoted as ELBO),2.placingtheinducingpoints usingthestrategyproposedbyMoss
et al. (2023) at each stage of ELBO optimization (denoted as Moss et al. ). The latter offers improved
BO performance over standard ELBO-SVGP in BO settings, yet—unlike our method—it exclusively
7Figure 2: Optimization results on the 8 considered tasks. We compare all methods for both
standardBOand TuRBO-basedBO(onalltasksexceptHartmann). Eachline/shadedregionrepresents
the mean/standard error over 20 runs See subsection B.1 for additional molecule results.
targets inducing point placement and does not affect variational parameters or hyperparameters of the
model. Inaddition,wecomparetoBOusingexactGPsusing 2,000functionevaluationsastheuse
of exact GP is intractable beyond this point due to the need to repeatedly fit models.
Acquisition Functions and BO algorithms. ForEULBO, we test the versions based on both the
Expected Improvement (EI) and Knowledge Gradient (KG) acquisition functions as well as the
batch variant. We test the baseline methods using EI only. On high-dimensional tasks (tasks with
dimensionalityabove10),werun EULBOandbaselinemethodswithstandardBOandwithtrustregion
Bayesianoptimization( TuRBO)(Erikssonetal.,2019). Forthelargesttasks(Lasso,Molecules)we
use acquisition batch size of 20 ( 𝑞=20), and batch size 1 ( 𝑞=1) for all others.
Implementation Details and Hyperparameters. Code to reproduce all results in the paper
is available at https://github.com/nataliemaus/aabo . We implement EULBOand baseline
methodsusingtheGPyTorch(Gardneretal.,2018)andBoTorch(Balandatetal.,2020)packages. For
allmethods,weinitializeusingasetof100datapointssampleduniformlyatrandominthesearch
space. We use the same trust region hyperparameters as in (Eriksson et al., 2019). In Appendix B.1,
we also evaluate an additional initialization strategy for the molecular design tasks. This alternative
initialization matches prior work in using 10,000molecules from the GuacaMol dataset Brown et al.
(2019) rather than the details we used above for consistency across tasks, but does achieve higher
overall performance.
4.1 Tasks
Hartmann6D. ThewidelyusedHartmann benchmarkfunction(SurjanovicandBingham,2013).
LunarLander. Thegoalofthistaskistofindanoptimal 12-dimensionalcontrolpolicythatallows
an autonomous lunar lander to consistently land without crashing. The final objective value we
optimize is the reward obtained by the policy averaged over a set of 50 random landing terrains. For
this task, we use the same controller setup used by Eriksson et al. (2019).
Rover.TherovertrajectoryoptimizationtaskintroducedbyWangetal.(2018)consistsoffinding
a60-dimensional policy that allows a rover to move along some trajectory while avoiding a set of
obstacles. We use the same obstacle set up as in Maus et al. (2023).
8Figure 3: Ablation study measuring the impact of EULBOoptimization on various SVGP
parameters. At each BO iteration, we use the standard ELBO objective to optimize the SVGP
hyperparameters, variational parameters, and inducing point locations. We then refine some subset of
these parameters by further optimizing them with respect to the EULBOobjective.
Lasso DNA. We optimize the 180−dimensional DNA task from the LassoBench library (Šehić
et al., 2022) of benchmarks based on weighted LASSO regression (Gasso et al., 2009).
Molecular design tasks (x4). We select four challenging tasks from the Guacamol benchmark
suite of molecular design tasks (Brown et al., 2019): Osimertinib MPO, Fexofenadine MPO, Median
Molecules 1, and Median Molecules 2. We use the SELFIES-VAE introduced by Maus et al. (2022)
to enable continuous 256dimensional optimization.
4.2 Optimization Results
InFigure2,weplottherewardofthebestpointfoundbytheoptimizerafteragivennumberoffunction
evaluations. Errorbarsshowthestandarderrorofthemeanover 20replicateruns. EULBOwithTuRBO
outperforms the other baselines with TuRBO. Similarly, EULBOwith standard BO outperforms the
other standard BO baselines. One noteworthy observation is that neither acquisition function appears
to consistently outperform the other. However, EULBO-SVGP almost always dominates ELBO-SVGP
and often requires a small fraction of the number of oracle calls to achieve comparable performance.
These results suggest that coupling data acquisition with approximate inference/model selection
results in significantly more sample-efficient optimization.
4.3 Ablation Study
While the results in Fig. 2 demonstrate that EULBO-SVGP improves the BO performance it is not
immediatelycleartowhatextentjointoptimizationmodifiestheposteriorapproximationbeyondwhat
isobtainedby standardELBOoptimization. Tothatend,in Fig.3werefineanELBO-SVGP model
withvaryingdegreesofadditional EULBOoptimization. AteveryBOiterationwebeginbyobtaininga
SVGPmodel(wherethevariationalparameters,inducingpointlocations,andGPhyperparametersare
all obtained by optimizing the standard ELBO objective). We then refine some subset of parameters
(eithertheinducingpoints,thevariationalparameters,theGPhyperparameters,oralloftheabove)
through additional optimization with respect to the EULBOobjective. Interestingly, we find that tasks
respond differently to the varying levels of EULBOrefinement. In the case of Lasso DNA, there is not
muchofadifferencebetween EULBOrefinementonallparametersversusrefinementonthevariational
parametersalone. Ontheotherhand,theperformanceonMedianMolecules2isclearlydominatedby
refinement on all parameters. Nevertheless, we see that EULBOis always beneficial, whether applied
to all parameters or some subset.
5 Related Work
Scaling Bayesian Optimization to the Large-Budget Regime. BO has traditionally been confined
to the small-budget optimization regime with a few hundred objective evaluations at most. However,
recent interest in high-dimensional optimization problems has demonstrated the need to scale BO
to large data acquisition budgets. For problems with ∼103data acquisitions, Hernández-Lobato
et al. (2017); Snoek et al. (2015); Springenberg et al. (2016) consider Bayesian neural networks
(BNN;Neal, 1996),McIntireetal.(2016)useSVGP,andWangetal.(2018) turntoensembles of
9subsampledGPs. Forproblemswith ≫103acquisitions,SVGPhasbecomethe defactoapproach
to alleviate computational complexity (Griffiths and Hernández-Lobato, 2020; Maus et al., 2022,
2023; Stanton et al., 2022; Tripp et al., 2020; Vakili et al., 2021). As in this paper, many works
have proposed modifications to SVGP to improve its performance in BO applications. Moss et al.
(2023) proposed an inducing point placement based on a heuristic modification of determinantal
point processes (Kulesza and Taskar, 2012), which we used for initialization, while Maddox et al.
(2021)proposedamethodforafastonlineupdatestrategyforSVGPs,whichweutilizefortheKG
acquisition strategy.
Utility-Calibrated Approximate Inference. The utility-calibrated VI objective was first proposed
by Lacoste–Julien et al. (2011), where they used a coordinate ascent algorithm to maximize it.
Sincethen,variousextensionshavebeenproposed: Kuśmierczyketal.(2019)leverageblack-box
variational inference (Ranganath et al., 2014; Titsias and Lázaro-Gredilla, 2014); Morais and Pillow
(2022) use expectation-propagation (EP; Minka, 2001); Abbasnejad et al. (2015) employ importance
sampling; Cobb et al. (2018) and Li and Zhang (2023) derive a specific variant for BNNs; and (Wei
et al., 2021) derive a specific variant for GP classification. Closest to our work is the GP-based
recommendation model learning algorithm by Abbasnejad et al. (2013), which sparsifies an EP-based
GP approximation by maximizing a utility similar to those used in BO.
6 Limitations and Discussion
The main limitation of our proposed approach is increased computational cost. While EULBO-SVGP
still retains the 𝑂(𝑚3)computational complexity of standard SVGP, our practical implementation
requires a warm-start: first fitting SVGP with the ELBOloss and then maximizing the acquisition
functionbeforejointlyoptimizingwiththe EULBOloss. Furthermore, EULBOoptimizationcurrently
requires multiple tricks such as clipping and block-coordinate updates. In future work, we aim
to develop a better understanding of the EULBOgeometry in order to develop developing more
stable, efficient, and easy-to-use EULBOoptimization schemes. Nevertheless, our results in Section 4
demonstratethattheadditionalcomputationof EULBOyieldssubstantialimprovementsinBOdata-
efficiency, a desirable trade-off in many applications. Moreover, EULBO-SVGP is modular, and
our experiments capture a fraction of its potential use. It can be applied to any decision-theoretic
acquisitionfunction,anditislikelycompatiblewithnon-standardBayesianoptimizationproblems
such as cost-constrained BO (Snoek et al., 2012), causal BO (Aglietti et al., 2020), and many more.
More importantly, our paper highlights a new avenue for research in BO, where surrogate modeling,
approximate inference, and data selection are jointly determined from a unified objective. Extending
this idea to GP approximations beyond SVGP and acquisition functions beyond EI/KG may yield
further improvements, especially in the increasingly popular high-throughput BO setting.
10Acknowledgments and Disclosure of Funding
The authors thank the anonymous reviewers for suggestions that improved the quality of the work.
N. Maus was supported by the National Science Foundation Graduate Research Fellowship; K. Kim
wassupportedbyagiftfromAWSAItoPennEngineering’sASSETCenterforTrustworthyAI;G.
PleisswassupportedbyNSERCandtheCanadaCIFARAIChairprogram;J.P.Cunninghamwas
supportedbytheGatsbyCharitableFoundation(GAT3708),theSimonsFoundation(542963),the
NSFAIInstituteforArtificialandNaturalIntelligence(ARNI:NSFDBI2229929),andtheKavli
Foundation; J. R. Gardner was supported by NSF awards IIS-2145644 and DBI-2400135.
References
EhsanAbbasnejad,JustinDomke,andScottSanner. Loss-calibratedMonteCarloactionselection. In
ProceedingsoftheAAAIConferenceonArtificialIntelligence ,volume29of AAAI.AAAIPress,
March 2015. ( page 10)
M. Ehsan Abbasnejad, Edwin V. Bonilla, and Scott Sanner. Decision-theoretic sparsification for
Gaussianprocesspreferencelearning.In MachineLearningandKnowledgeDiscoveryinDatabases ,
volume 13717 of LNCS, pages 515–530, Berlin, Heidelberg, 2013. Springer. ( page 10)
Virginia Aglietti, Xiaoyu Lu, Andrei Paleyes, and Javier González. Causal Bayesian optimization. In
ProceedingsoftheInternationalConferenceonArtificialIntelligenceandStatistics ,volume108of
PMLR, pages 3155–3164. JMLR, June 2020. ( page 10)
Maximilian Balandat, Brian Karrer, Daniel R. Jiang, Samuel Daulton, Benjamin Letham, An-
drew Gordon Wilson, and Eytan Bakshy. BoTorch: A framework for efficient Monte-Carlo
Bayesian optimization. In Advances in Neural Information Processing Systems , volume 33, pages
21524–21538. Curran Associates, Inc., 2020. ( pages 2, 6, 7, 8, 16 )
P. G. Bissiri, C. C. Holmes, and S. G. Walker. A general framework for updating belief distributions.
Journal of the Royal Statistical Society Series B: Statistical Methodology , 78(5):1103–1130, 2016.
(pages 2, 5)
DavidM.Blei,AlpKucukelbir,andJonD.McAuliffe. Variationalinference: Areviewforstatisticians.
Journal of the American Statistical Association , 112(518):859–877, April 2017. ( pages 2, 3)
NathanBrown,MarcoFiscato,MarwinH.S.Segler,andAlainC.Vaucher. Guacamol: Benchmarking
models for de novo molecular design. Journal of Chemical Information and Modeling , 59(3):
1096–1108, Mar 2019. ( pages 8, 9)
Adam D. Cobb, Stephen J. Roberts, and Yarin Gal. Loss-Calibrated Approximate Inference in
Bayesian Neural Networks. arXiv Preprint arXiv:1805.03901, arXiv, May 2018. ( page 10)
A.P.Dempster,N.M.Laird,andD.B.Rubin. Maximumlikelihoodfromincompletedataviathe
EMalgorithm. JournaloftheRoyalStatisticalSociety: SeriesB(Methodological) ,39(1):1–22,
September 1977. ( page 4)
DavidEriksson,MichaelPearce,JacobGardner,RyanDTurner,andMatthiasPoloczek. Scalable
globaloptimizationvialocalBayesianoptimization. In AdvancesinNeuralInformationProcessing
Systems, volume 32, pages 5496–5507. Curran Associates, Inc., 2019. ( pages 1, 2, 8 )
PeterIFrazier. Knowledge-gradientmethodsforstatisticallearning . PhDthesis,PrincetonUniversity
Princeton, 2009. ( page 6)
Peter I Frazier. A tutorial on Bayesian optimization. arXiv Preprint arXiv:1807.02811, ArXiv, 2018.
(page 1)
Théo Galy-Fajou and Manfred Opper. Adaptive inducing points selection for Gaussian processes.
arXiv Preprint arXiv:2107.10066, arXiv, 2021. ( page 7)
Jacob Gardner, Geoff Pleiss, Kilian Q. Weinberger, David Bindel, and Andrew G. Wilson. GPyTorch:
Blackboxmatrix-matrixGaussianprocessinferencewithGPUacceleration. In AdvancesinNeural
Information Processing Systems , volume 31, pages 7576–7586. Curran Associates, Inc., 2018.
(pages 8, 16 )
Roman Garnett. Bayesian Optimization . Cambridge University Press, Cambridge, United Kingdom ;
New York, NY, 2023. ( pages 1, 2, 3, 6 )
11GillesGasso,AlainRakotomamonjy,andStéphaneCanu. Recoveringsparsesignalswithacertain
family of nonconvex penalties and DC programming. IEEE Transactions on Signal Processing , 57
(12):4686–4698, 2009. ( page 9)
Ryan-Rhys Griffiths and José Miguel Hernández-Lobato. Constrained Bayesian optimization for
automatic chemical design using variational autoencoders. Chemical Science , 11(2):577–586,
2020. (pages 1, 10 )
JamesHensman,NicoloFusi,andNeilD.Lawrence. Gaussianprocessesforbigdata. In Proceedings
of the Conference on Uncertainty in Artificial Intelligence , pages 282–290. AUAI Press, 2013.
(pages 1, 3)
José Miguel Hernández-Lobato, James Requeima, Edward O. Pyzer-Knapp, and Alán Aspuru-Guzik.
ParallelanddistributedThompsonsamplingforlarge-scaleacceleratedexplorationofchemical
space. In Proceedings of the International Conference on Machine Learning , volume 70 of PMLR,
pages 1470–1479. JMLR, July 2017. ( page 9)
Prateek Jaiswal, Harsha Honnappa, and Vinayak A. Rao. Asymptotic consistency of loss-calibrated
variational Bayes. Stat, 9(1):e258, 2020. ( pages 2, 5)
Prateek Jaiswal, Harsha Honnappa, and Vinayak Rao. On the statistical consistency of risk-sensitive
bayesian decision-making. In Advances in Neural Information Processing Systems , volume 36,
pages 53158–53200. Curran Associates, Inc., December 2023. ( pages 2, 5)
MartinJankowiak,GeoffPleiss,andJacobR.Gardner. Parametricgaussianprocessregressors. In
Proceedings of the 37th International Conference on Machine Learning , ICML’20. JMLR.org,
2020. (page 19)
DonaldR.Jones,MatthiasSchonlau,andWilliamJ.Welch. Efficientglobaloptimizationofexpensive
black-box functions. Journal of Global Optimization , 13(4):455–492, 1998. ( pages 1, 2, 5 )
Michael I. Jordan, Zoubin Ghahramani, Tommi S. Jaakkola, and Lawrence K. Saul. An introduction
to variational methods for graphical models. Machine Learning , 37(2):183–233, 1999. ( pages 1, 2,
3, 4)
DiederikP.KingmaandJimmyBa. Adam: AMethodforStochasticOptimization. In Proceedings
of the International Conference on Learning Representations , San Diego, California, USA, 2015.
(pages 15, 16 )
Diederik P. Kingma and Max Welling. Auto-encoding variational Bayes. In Proceedings of the
International Conference on Learning Representations , Banff, AB, Canada, April 2014. ( page 6)
JeremiasKnoblauch,JackJewson,andTheodorosDamoulas. Anoptimization-centricviewonBayes’
rule: Reviewingandgeneralizingvariationalinference. JournalofMachineLearningResearch ,23
(132):1–109, 2022. ( pages 2, 5)
Alex Kulesza and Ben Taskar. Determinantal point processes for machine learning. Foundations and
Trends®in Machine Learning , 5(2–3):123–286, 2012. ( page 10)
Tomasz Kuśmierczyk, Joseph Sakaya, and Arto Klami. Variational Bayesian decision-making for
continuous utilities. In Advances in Neural Information Processing Systems , volume 32, pages
6395–6405. Curran Associates, Inc., 2019. ( pages 4, 5, 10 )
Simon Lacoste–Julien, Ferenc Huszár, and Zoubin Ghahramani. Approximate inference for the
loss-calibrated Bayesian. In Proceedings of the International Conference on Artificial Intelligence
and Statistics , volume 15 of PMLR, pages 416–424. JMLR, June 2011. ( pages 2, 4, 10 )
Kenneth Lange. MM Optimization Algorithms . Society for Industrial and Applied Mathematics,
Philadelphia, 2016. ( pages 2, 4)
BolianLi andRuqi Zhang. Long-tailed Classificationfrom aBayesian-decision-theoryPerspective.
arXiv Preprint arXiv:2303.06075, arXiv, 2023. ( page 10)
Wesley J Maddox, Samuel Stanton, and Andrew G Wilson. Conditioning sparse variational Gaussian
processes for online decision-making. In Advances in Neural Information Processing Systems ,
volume 34, pages 6365–6379. Curran Associates, Inc., 2021. ( pages 1, 2, 4, 6, 10 )
Alexander G. de G. Matthews, James Hensman, Richard Turner, and Zoubin Ghahramani. On
sparsevariationalmethodsandtheKullback-Leiblerdivergencebetweenstochasticprocesses. In
Proceedings of the International Conference on Artificial Intelligence and Statistics , volume 51 of
PMLR, pages 231–239. JMLR, May 2016. ( pages 1, 4)
12NatalieMaus,HaydnJones,JustonMoore,MattJ.Kusner,JohnBradshaw,andJacobGardner. Local
latent space Bayesian optimization over structured inputs. In Advances in Neural Information
Processing Systems , volume 35, pages 34505–34518, December 2022. ( pages 1, 9, 10 )
Natalie Maus, Kaiwen Wu, David Eriksson, and Jacob Gardner. Discovering many diverse solutions
withBayesianoptimization.In ProceedingsoftheInternationalConferenceonArtificialIntelligence
and Statistics , volume 206, pages 1779–1798. PMLR, April 2023. ( pages 1, 8, 10 )
Mitchell McIntire, Daniel Ratner, and Stefano Ermon. Sparse Gaussian Processes for Bayesian
Optimization. In ProceedingsoftheConferenceonUncertaintyinArtificialIntelligence ,Jersey
City, New Jersey, USA, 2016. AUAI Press. ( page 9)
ThomasP.Minka. Expectationpropagationforapproximatebayesianinference. In Proceedingsof
the Conference on Uncertainty in Artificial Intelligence , pages 362–369, San Francisco, CA, USA,
2001. Morgan Kaufmann Publishers Inc. ( page 10)
Jonas Mockus. The Bayesian approach to global optimization. In System Modeling and Optimization ,
pages 473–481. Springer, 1982. ( page 1)
Michael J. Morais and Jonathan W. Pillow. Loss-calibrated expectation propagation for approximate
Bayesian decision-making. Technical Report arXiv:2201.03128, arXiv, January 2022. ( page 10)
HenryB.Moss,SebastianW.Ober,andVictorPicheny. InducingpointallocationforsparseGaussian
processesinhigh-throughputBayesianoptimisation. In ProceedingsoftheInternationalConference
on Artificial Intelligence and Statistics , volume 206 of PMLR, pages 5213–5230. JMLR, April
2023. (pages 1, 4, 7, 10, 16, 17, 18 )
Radford M. Neal. Bayesian Learning for Neural Networks , volume 118 of Lecture Notes in Statistics .
Springer New York, New York, NY, 1996. ( page 9)
JoaquinQuiñonero-CandelaandCarlEdwardRasmussen. Aunifyingviewofsparseapproximate
Gaussian process regression. Journal of Machine Learning Research , 6(65):1939–1959, 2005.
(page 1)
Rajesh Ranganath, Sean Gerrish, and David Blei. Black box variational inference. In Proceedings of
theInternationalConferenceonArtificialIntelligenceandStatistics ,volume33of PMLR,pages
814–822. JMLR, April 2014. ( page 10)
Carl Edward Rasmussen and Christopher K. I. Williams. Gaussian Processes for Machine Learning .
The MIT Press, November 2005. ( page 1)
Danilo Jimenez Rezende, Shakir Mohamed, and Daan Wierstra. Stochastic backpropagation and
approximate inference in deep generative models. In Proceedings of the International Conference
on Machine Learning , volume 32 of PMLR, pages 1278–1286. JMLR, June 2014. ( page 6)
Christian P. Robert. The Bayesian Choice: From Decision-Theoretic Foundations to Computational
Implementation . Springer Texts in Statistics. Springer, New York Berlin Heidelberg, 2. ed edition,
2001. (pages 2, 3)
Bobak Shahriari, Kevin Swersky, Ziyu Wang, Ryan P Adams, and Nando De Freitas. Taking the
human out of the loop: A review of Bayesian optimization. Proceedings of the IEEE , 104(1):
148–175, 2015. ( pages 1, 5)
Edward Snelson and Zoubin Ghahramani. Sparse Gaussian processes using pseudo-inputs. In
Advances in Neural Information Processing Systems , volume 18, pages 1257–1264. MIT Press,
2005. (page 5)
Jasper Snoek, Hugo Larochelle, and Ryan P Adams. Practical Bayesian optimization of machine
learning algorithms. Advances in neural information processing systems , 25:2951–2959, 2012.
(page 10)
Jasper Snoek, Oren Rippel, Kevin Swersky, Ryan Kiros, Nadathur Satish, Narayanan Sundaram,
Mostofa Patwary, Mr Prabhat, and Ryan Adams. Scalable Bayesian optimization using deep neural
networks. In Proceedings of the International Conference on Machine Learning , volume 37 of
PMLR, pages 2171–2180. JMLR, June 2015. ( page 9)
Jost Tobias Springenberg, Aaron Klein, Stefan Falkner, and Frank Hutter. Bayesian Optimization
withRobustBayesianNeuralNetworks. In AdvancesinNeuralInformationProcessingSystems ,
volume 29, pages 4134–4142. Curran Associates, Inc., 2016. ( page 9)
13Samuel Stanton, Wesley Maddox, Nate Gruver, Phillip Maffettone, Emily Delaney, Peyton Greenside,
and Andrew Gordon Wilson. Accelerating Bayesian optimization for biological sequence design
withdenoisingautoencoders. In ProceedingsoftheInternationalConferenceonMachineLearning ,
volume 162 of PMLR, pages 20459–20478. JMLR, June 2022. ( pages 1, 10 )
Sonja Surjanovic and Derek Bingham. Virtual library of simulation experiments: Test functions and
datasets, 2013. ( page 8)
Alexander Terenin, David R. Burt, Artem Artemev, Seth Flaxman, Mark van der Wilk, Carl Edward
Rasmussen, and Hong Ge. Numerically stable sparse Gaussian processes via minimum separation
using cover trees. Journal of Machine Learning Research , 25(26):1–36, 2024. ( page 7)
Michalis Titsias. Variational learning of inducing variables in sparse gaussian processes. In
ProceedingsoftheInternationalConferenceonArtificialIntelligenceandStatistics ,volume5of
PMLR, pages 567–574. JMLR, April 2009. ( pages 1, 3)
Michalis Titsias and Miguel Lázaro-Gredilla. Doubly stochastic variational Bayes for non-conjugate
inference. In Proceedings of the International Conference on Machine Learning , volume 32 of
PMLR, pages 1971–1979. JMLR, June 2014. ( pages 6, 10 )
AustinTripp,ErikDaxberger,andJoséMiguelHernández-Lobato. Sample-efficientoptimization
in the latent space of deep generative models via weighted retraining. In Advances in Neural
InformationProcessingSystems ,volume33,pages11259–11272.CurranAssociates,Inc.,2020.
(pages 1, 10 )
Sattar Vakili, Henry Moss, Artem Artemev, Vincent Dutordoir, and Victor Picheny. Scalable
ThompsonsamplingusingsparseGaussianprocessmodels. In AdvancesinNeuralInformation
Processing Systems , volume 34, pages 5631–5643, 2021. ( pages 1, 10 )
KenanŠehić,AlexandreGramfort,JosephSalmon,andLuigiNardi. Lassobench: Ahigh-dimensional
hyperparameter optimization benchmark suite for LASSO. In Proceedings of the International
Conference on Automated Machine Learning , volume 188 of PMLR, pages 2/1–24. JMLR, 25–27
Jul 2022. ( page 9)
YixinWangandDavidM.Blei. FrequentistconsistencyofvariationalBayes. JournaloftheAmerican
Statistical Association , 114(527):1147–1161, July 2019. ( page 5)
Zi Wang, Clement Gehring, Pushmeet Kohli, and Stefanie Jegelka. Batched large-scale bayesian
optimization in high-dimensional spaces. In Proceedings of the International Conference on
Artificial Intelligence and Statistics , volume 84 of PMLR, pages 745–754. JMLR, March 2018.
(pages 8, 9)
Larry Wasserman. All of statistics: a concise course in statistical inference . Springer Science &
Business Media, 2013. ( pages 2, 3)
Yadi Wei, Rishit Sheth, and Roni Khardon. Direct loss minimization for sparse Gaussian processes.
InProceedingsoftheInternationalConferenceonArtificialIntelligenceandStatistics ,volume130
ofPMLR, pages 2566–2574. JMLR, March 2021. ( page 10)
JamesWilson,FrankHutter,andMarcDeisenroth. MaximizingacquisitionfunctionsforBayesian
optimization. In AdvancesinNeuralInformationProcessingSystems ,pages9884–9895.Curran
Associates, Inc., 2018. ( pages 2, 7)
Jian Wu, Matthias Poloczek, Andrew G Wilson, and Peter Frazier. Bayesian optimization with
gradients. In Advancesin NeuralInformation ProcessingSystems , volume30,pages5267–5278.
Curran Associates, Inc., 2017. ( page 2)
14A Implementation Details
We will now provide additional details on the implementation. For the implementation, we treat
the SVGP parameters, such as the variational parameters 𝝀, inducing point locations 𝒁, and
hyperparameters 𝜽, equally. Therefore, for clarity, we will collectively denote them as 𝒘=(𝝀,𝒁,𝜽)
suchthat𝒘∈𝒲 ≜Λ×𝒳𝑚×Θ,andtheresultingSVGPvariationalapproximationas 𝑞𝒘. Then,
the ELBO and EULBO are equivalently denoted as follows:
ℒELBO(𝒘;𝒟)≜ ℒELBO(𝝀,𝒁,𝜽;𝒟)
ℒEULBO(𝒙,𝒘;𝒟𝒙,𝒟𝒘)≜𝔼𝑓∼𝑞𝒘(𝑓)log𝑢(𝒙,𝑓;𝒟𝒙)+ℒELBO(𝒘;𝒟𝒘).
Also,noticethatthe ℒEULBOseparatelydenotethedatasettobepassedtotheutilityandtheELBO.
(Setting 𝒟𝑡=𝒟𝒘=𝒟𝒙retrieves the original formulation in Eq. (8).)
Alternating Updates We perform block-coordinate ascent on the EULBO by alternating between
maximizing over 𝒙as𝒘. Using vanilla gradient descent, the 𝒙-update is equivalent to
𝒙←𝒙+𝛾𝒙∇𝒙ℒEULBO(𝒙,𝒘;𝒟)=𝒙+𝛾𝒙∇𝒙𝔼𝑓∼𝑞𝒘(𝑓)log𝑢(𝒙,𝑓;𝒟),
where𝛾𝒙isthestepsize. Ontheotherhand,forthe 𝒘-update,wesubsamplethedatasuchthatwe
optimize the ELBO over a minibatch 𝑆 ⊂𝒟of size𝐵=|𝑆|as
𝒘←𝒘+𝛾𝒘∇𝒘ℒEULBO(𝒙,𝒘;𝑆,𝒟)=𝒘+𝛾𝒘∇𝒘(𝔼𝑓∼𝑞𝒘(𝑓)log𝑢(𝒙,𝑓;𝒟)+ℒELBO(𝒘;𝑆)),
where𝛾𝒘isthestepsize. Naturally,the 𝒘-updateisstochasticduetominibatching,whilethe 𝒙-update
is deterministic. In practice, we leverage the Adam update rule (Kingma and Ba, 2015) instead of
simple gradient descent. Together with gradient clipping, this alternating update scheme is much
more robust than jointly updating (𝒙,𝒘).
Algorithm 1: EULBO Maximization Policy
Input:SVGP parameters 𝒘0=(𝝀0,𝒁0,𝜽0), Dataset 𝒟𝑡, BO utility function 𝑢,
Output: BO query𝒙𝑡+1
1
⊳Compute Warm-Start Initializations
2𝒘←argmax𝒘∈𝒲ℒELBO(𝒘;𝒟𝑡)with𝒘0as initialization.
3𝒙←argmax𝒙∈𝒳∫𝑢(𝒙,𝑓;𝒟𝑡)𝑞𝒘(𝑓)d𝑓
4
⊳Maximize EULBO
5repeat
⊳Update posterior approximation 𝑞𝒘
6Fetch minibatch 𝑆from𝒟𝑡
7Compute𝒈𝒘←∇𝒘ℒEULBO(𝒙,𝒘;𝑆,𝒟𝑡)
8Clip𝒈𝒘with threshold 𝐺clip
9𝒘←AdamStep𝛾𝒘(𝒘,𝒈𝒘)
10
⊳Update BO query 𝒙
11Compute𝒈𝒙←∇𝒙ℒEULBO(𝒙,𝒘;𝑆,𝒟𝑡)
12Clip𝒈𝒙with threshold 𝐺clip
13𝒙←AdamStep𝛾𝒙(𝒙,𝒈𝒙)
14𝒙←proj𝒳(𝒙)
15untiluntil converged
16𝒙𝑡+1←𝒙
17
OverviewofPseudocode. Thecompletehigh-levelviewofthealgorithmispresentedinAlgorithm1,
exceptfortheacquisition-specificdetails. AdamStep𝛾(𝒙,𝒈)appliestheAdamstepsizerule(Kingma
andBa,2015)tothecurrentlocation 𝒙withthegradientestimate 𝒈andthestepsize 𝛾. Inpractice,
Adamisa“stateful”optimizer,whichmaintainstwoscalar-valuedstatesforeachscalarparameter.
For this, we re-initialize the Adam states at the beginning of each BO step.
15Initialization. In the initial BO step 𝑡= 0, we initialize 𝒁0with the DPP-based inducing point
selection strategy of Moss et al. (2023). For the remaining SVGP parameters 𝝀0and𝜽0, we used the
defaultinitializationofGPyTorch(Gardneretal.,2018). FortheremainingBOsteps 𝑡>0,weuse𝒘
from the previous BO step as the initialization 𝒘0of the current BO step.
Warm-Starting. Duetothenon-convexityandmulti-modalityofboththeELBOandtheacquisition
function, it is critical to appropriately initialize the EULBO maximization procedure. As mentioned
inSection3.5,towarm-starttheEULBOmaximizationprocedure,weusetheconventional2-step
scheme Eq. (5), where we maximize the ELBO and then maximize the acquisition function. For
ELBOmaximization,weapplyAdam(KingmaandBa,2015)withthestepsizesetas 𝛾𝑤untilthe
convergencecriteria(describedbelow)aremet. Foracquisitionfunctionmaximization,weinvokethe
highly optimized BoTorch.optimize.optimize_acqf function (Balandat et al., 2020).
MinibatchSubsamplingStrategy. Ascommonlydone,weusethereshufflingsubsamplingstrategy
wherethedataset 𝒟𝑡isshuffledandpartitionedintominibatchesofsize 𝐵. Thenumberofminibatches
constitutes an “epoch.” The dataset is reshuffled/repartitioned after going through a full epoch.
ConvergenceDetermination. ForbothmaximizingtheELBOduringwarm-startingandmaximizing
theEULBO,wecontinueoptimizationuntilwestopmakingprogressorexceed 𝑘epochsnumberof
epochs. That is if the ELBO/EULBO function value fails to make progress for 𝑛failnumber of steps.
Table 1: Configurations of Hyperparameters used for the Experiments
Hyperparameter Value Description
𝛾𝒙 0.001ADAM stepsize for the query 𝒙
𝛾𝒘 0.01ADAM stepsize for the SVGP parameters 𝒘
𝐵 32Minibatch size
𝐺clip 2.0Gradient clipping threshold
𝑘epochs 30Maximum number of epochs
𝑛fail 3Maximum number of failure to improve
𝑚 100Number of inducing points
𝑛0=|𝒟0| 100Number of observations for initializing BO
# quad. 20Number of Gauss-Hermite quadrature points
optimize_acqf: restarts 10
optimize_acqf: raw_samples 256
optimize_acqf: batch_size 1∕20Depends on task; see details in Section 4
Hyperparameters. The hyperparameters used in our experiments are organized in Table 1. For
the full-extent of the implementation details and experimental configuration, please refer to the
supplementary code.
16B Additional Plots
We provide additional results and plots that were omitted from the main text.
B.1 Additional Results on Molecule Tasks
In Fig. 4, we provide plots on additional results that are similar to those in Fig. 2. On three of the
moleculetasks,weuse10,000randommoleculesfromtheGuacaMoldatasetasinitialization. Thisis
more consistent with what has been done in previous works and achieves better overall optimization
performance.
Figure4: Additionaloptimizationresultsonthreemoleculetasksusing10,000randommolecules
fromthe GuacaMoldataset asinitialization . Each line/shadedregion representsthe mean/standard
error over 20 runs. We count oracle calls starting afterthese initialization evaluations for all methods.
B.2 Separate Plots for BO and TuRBOResults
Inthissection,weprovideadditionalplotsseparatingoutBOand TuRBOresultstomakevisualization
easier.
Figure 5: BO-only optimization results of Fig. 2 . We compare EULBO-SVGP, ELBO-SVGP,
ELBO-SVGPwithDPPinducingpointplacement(Mossetal.,2023),andexactGPs. Thesearea
subset of the same results shown in Fig. 2. Each line/shaded region represents the mean/standard
error over 20 runs.
17Figure 6: TuRBO-only optimization results of Fig. 2 . We compare EULBO-SVGP, ELBO-SVGP,
ELBO-SVGPwithDPPinducingpointplacement(Mossetal.,2023),andexactGPs. Thesearea
subset of the same results shown in Fig. 2. Each line/shaded region represents the mean/standard
error over 20 runs.
B.3 Effect of Number of Inducing Points
For theresults withapproximate-GPs in Section4, we used 𝑚=100inducing points. In Fig. 7,we
evaluate the effect of using a larger number of inducing points ( 𝑚= 1024) for EULBO-SVGP and
ELBO-SVGP.
0 5000 10000 15000 20000
Number of Oracle Calls0.34
0.33
0.32
0.31
0.30
0.29
Mean Reward
Lasso DNA
TuRBO (EULBO EI) w/ 1024 inducing points
TuRBO (EULBO EI)
TuRBO (ELBO EI) w/ 1024 inducing points
TuRBO (ELBO EI)
Figure 7: Ablating the number of inducing points used by EULBO-SVGP and ELBO-SVGP .
AsinFig.2,wecomparerunning TuRBOwith EULBO-SVGPandwithELBO-SVGPusing 𝑚=100
inducing points used for both methods. We add two additional curves for TuRBOwith EULBO-SVGP
andTuRBOwith ELBO-SVGP using 𝑚=1024inducing points. Each line/shaded region represents
the mean/standard error over 20 runs.
Fig. 7 shows that the number of inducing points has limited impact on the overall performance of
TuRBO, and EULBO-SVGP outperforms ELBO-SVGP regardless of the number of inducing points
used.
18B.4 Effect of GP Objective
TheresultsinSection4usedastandardSVGPobjective. Inthissection,weevaluatetheeffectofusing
an alternative objective: the parametric Gaussian process regressor (PPGPR; Jankowiak et al., 2020)
objective. PPGPRdiffersfrom thestandard SVGPobjective inthat thevariationalapproximation is
optimized to maximize the predictive accuracy instead of matching the posterior.
0 5000 10000 15000 20000
Number of Oracle Calls0.34
0.33
0.32
0.31
0.30
0.29
Mean Reward
Lasso DNA
TuRBO (EULBO EI) PPGPR
TuRBO (EULBO EI)
TuRBO (ELBO EI) PPGPR
TuRBO (ELBO EI)
Figure 8: Effect of using the PPGPR objective instead of the SVGP objective for EULBO-EI
andELBO-EI .AsinFig.2,wecomparerunning TuRBOwith EULBO-EIandwithELBO-EIusing
an SVGP model for both methods. We add two additional curves for TuRBOwith EULBO-EI with a
PPGPR model, and TuRBOwith ELBO-EI using a PPGPR model. Each line/shaded region represents
the mean/standard error over 20 runs.
Wecomparethechoiceofobjective(PPGPRvsSVGP)inFig.8andobservethattheobjectivehas
limited impact on the overall performance of TuRBO. In particular, EULBO-EI outperforms ELBO-EI
regardless of the GP objective.
19C Compute Resources
Table 2: Internal Cluster Setup
Type Model and Specifications
System Topology 20 nodes with 2 sockets each with 24 logical threads (total 48 threads)
Processor 1 Intel Xeon Silver 4310, 2.1 GHz (maximum 3.3 GHz) per socket
Cache 1.1 MiB L1, 30 MiB L2, and 36 MiB L3
Memory 250 GiB RAM
Accelerator 1 NVIDIA RTX A5000 per node, 2 GHZ, 24GB RAM
Type of Compute and Memory. All results in the paper required the use of GPU workers (one
GPU per run of each method on each task). The majority of runs were executed on an internal
cluster,wheredetailsareshowninTable2,whereeachnodewasequippedwithanNVIDIARTX
A5000 GPU. In addition, we used cloud compute resources for a short period leading up to the
subsmissionof thepaper. Weused40 RTX4090GPU workersfrom runpod.io ,where eachGPU
hadapproximately24GBofGPUmemory. Whileweused24GBGPUsforourexperiments,each
run of our experiments only requires approximately 15 GB of GPU memory.
Execution Time. Each optimization run for non-molecule tasks takes approximately one day to
finish. Since we run the molecule tasks out to a much larger number of function evaluations than
other tasks ( 80000total function evaluations for each molecule optimization task), each molecule
optimization task run takes approximately 2days of execution time. With all eight tasks, ten methods
run,and20runscompletedpermethod,resultsinFig.2include 1600totaloptimizationruns( 800
for molecule tasks and 800for non-molecule tasks). Additionally, the two added curves in each
plot in Fig. 3 required 160additional runs ( 120for molecule tasks and 40for non-molecule task).
Completingalloftherunsneededtoproducealloftheresultsinthispaperthereforerequiredroughly
2680total GPU hours.
Compute Resources Used During Preliminary Investigations. In addition to the computational
resourcesrequiredtoproduceexperimentalresultsinthepaperdiscussedabove,wespentapproximately
500hours of GPU time on preliminary investigations. This was done on the aforementioned internal
cluster shown in Table 2.
D Wall-clock Run Times
In Table 3, we provide average wall-clock run times of different methods on the Lasso DNA
optimization task.
Table3: Averagewall-clockruntimesforonefullrunofTuRBO
on the Lasso DNA task. We compare the average wall-clock
runtimeofTuRBOonallTuRBOmethodsfromFigure2. Note
that we do not include the wall clock run time for TuRBO with
ExactEI here becauseweonlyran this methodout to 2koracle
calls (rather than the full budget of 20k oracle calls).
Method Wall-clock Run Time in Minutes
EULBO EI 267.30 ±2.53
EULBO KG 296.95 ±1.31
ELBO EI 184.40 ±0.59
Moss et al. 20203 EI 194.32 ±0.77
20NeurIPS Paper Checklist
1.Claims
Question: Dothemainclaimsmadeintheabstractandintroductionaccuratelyreflectthe
paper’s contributions and scope?
Answer: [Yes]
Justification: All stated claims are backed-up with results in Section 4 and the stated
focus/scopeofthepaperaccuratelyreflectswhatisdiscussedthroughouttherestofthepaper.
Guidelines:
•TheanswerNAmeansthattheabstractandintroductiondonotincludetheclaimsmade
in the paper.
•The abstract and/or introduction should clearly state the claims made, including the
contributionsmadeinthepaperandimportantassumptionsandlimitations. ANoor
NA answer to this question will not be perceived well by the reviewers.
•The claims made should match theoretical and experimental results, and reflect how
much the results can be expected to generalize to other settings.
•Itisfinetoincludeaspirationalgoalsasmotivationaslongasitisclearthatthesegoals
are not attained by the paper.
2.Limitations
Question: Does the paper discuss the limitations of the work performed by the authors?
Answer: [Yes]
Justification: See Section 6.
Guidelines:
•The answer NA means that the paper has no limitation while the answer No means that
the paper has limitations, but those are not discussed in the paper.
•The authors are encouraged to create a separate "Limitations" section in their paper.
•Thepapershouldpointoutanystrongassumptionsandhowrobusttheresultsareto
violations of these assumptions (e.g., independence assumptions, noiseless settings,
modelwell-specification,asymptoticapproximationsonlyholdinglocally). Theauthors
should reflect on how these assumptions might be violated in practice and what the
implications would be.
•Theauthorsshouldreflectonthescopeoftheclaimsmade,e.g.,iftheapproachwas
only tested on a few datasets or with a few runs. In general, empirical results often
depend on implicit assumptions, which should be articulated.
•Theauthorsshouldreflectonthefactorsthatinfluencetheperformanceoftheapproach.
Forexample,afacialrecognitionalgorithmmayperformpoorlywhenimageresolution
is low or images are taken in low lighting. Or a speech-to-text system might not be
used reliably to provide closed captions for online lectures because it fails to handle
technical jargon.
•The authors should discuss the computational efficiency of the proposed algorithms
and how they scale with dataset size.
•Ifapplicable,theauthorsshoulddiscusspossiblelimitationsoftheirapproachtoaddress
problems of privacy and fairness.
•While the authors might fear that complete honesty about limitations might be used by
reviewersasgroundsforrejection,aworseoutcomemightbethatreviewersdiscover
limitations that aren’t acknowledged in the paper. The authors should use their best
judgmentandrecognizethatindividualactionsinfavoroftransparencyplayanimportant
role in developing norms that preserve the integrity of the community. Reviewers will
be specifically instructed to not penalize honesty concerning limitations.
3.Theory Assumptions and Proofs
Question: For each theoretical result, does the paper provide the full set of assumptions and
a complete (and correct) proof?
Answer: [NA] .
21Justification: This work does not contain a formal theoretical analysis.
Guidelines:
•The answer NA means that the paper does not include theoretical results.
•All the theorems, formulas, and proofs in the paper should be numbered and cross-
referenced.
•Allassumptionsshouldbeclearlystatedorreferenced inthestatementofanytheorems.
•The proofs can either appear in the main paper or the supplemental material, but if
they appear in the supplemental material, the authors are encouraged to provide a short
proof sketch to provide intuition.
•Inversely,anyinformalproofprovidedinthecoreofthepapershouldbecomplemented
by formal proofs provided in appendix or supplemental material.
•Theorems and Lemmas that the proof relies upon should be properly referenced.
4.Experimental Result Reproducibility
Question: Doesthepaperfullydisclosealltheinformationneededtoreproducethemain
experimentalresultsofthepapertotheextentthatitaffectsthemainclaimsand/orconclusions
of the paper (regardless of whether the code and data are provided or not)?
Answer: [Yes] .
Justification: We provide detailed explanation of how our method works in Section 3 and all
additionalrequireddetailstoreproduceresultsinSection4andAppendixA.Additionally,
we have included a link to a public GitHub repository containing all of the source code used
intheworkinSection4. Thissourcecodeallowsanyreadertorunourcodetoreproduce
all results in the paper. Additionally, the README in the repository provides detailed
instructions to make setting up the proper environment and running the code easy for users.
Guidelines:
•The answer NA means that the paper does not include experiments.
•Ifthepaperincludesexperiments,aNoanswertothisquestionwillnotbeperceivedwell
bythereviewers: Makingthepaperreproducibleisimportant,regardlessofwhether
the code and data are provided or not.
•Ifthecontributionisadatasetand/ormodel,theauthorsshoulddescribethestepstaken
to make their results reproducible or verifiable.
•Dependingonthecontribution,reproducibilitycanbeaccomplishedinvariousways.
Forexample, ifthecontributionisanovelarchitecture, describingthearchitecturefully
might suffice, or if the contribution is a specific model and empirical evaluation, it may
be necessary to either make it possible for others to replicate the model with the same
dataset, or provide access to the model. In general. releasing code and data is often
one good way to accomplish this, but reproducibility can also be provided via detailed
instructionsfor howtoreplicatethe results,accessto ahostedmodel (e.g.,inthe case
ofalargelanguagemodel),releasingofamodelcheckpoint,orothermeansthatare
appropriate to the research performed.
•While NeurIPS does not require releasing code, the conference does require all
submissions to provide some reasonable avenue for reproducibility, which may depend
on the nature of the contribution. For example
(a)Ifthecontributionisprimarilyanewalgorithm,thepapershouldmakeitclearhow
to reproduce that algorithm.
(b)If the contribution is primarily a new model architecture, the paper should describe
the architecture clearly and fully.
(c)If the contribution is a new model (e.g., a large language model), then there should
eitherbeawaytoaccessthismodelforreproducingtheresultsorawaytoreproduce
themodel(e.g.,withanopen-sourcedatasetorinstructionsforhowtoconstructthe
dataset).
(d)Werecognizethatreproducibilitymaybetrickyinsomecases,inwhichcaseauthors
are welcome to describe the particular way they provide for reproducibility. In the
case of closed-source models, it may be that access to the model is limited in some
way(e.g.,toregisteredusers),butitshouldbepossibleforotherresearcherstohave
some path to reproducing or verifying the results.
225.Open access to data and code
Question: Doesthepaperprovideopenaccesstothedataandcode,withsufficientinstructions
tofaithfullyreproducethemainexperimentalresults,asdescribedinsupplementalmaterial?
Answer: [Yes] Replace by [Yes] , [No] , or [NA] .
Justification: We have included a link to a public GitHub repository containing all of the
source code used in the work in Section 4. This source code allows any reader to run our
code to reproduce all results in the paper. Additionally, the README in the repository
providesdetailedinstructionstomakesettinguptheproperenvironmentandrunningthe
code easy for users.
Guidelines:
•The answer NA means that paper does not include experiments requiring code.
•Please see the NeurIPS code and data submission guidelines ( https://nips.cc/
public/guides/CodeSubmissionPolicy ) for more details.
•While we encourage the release of code and data, we understand that this might not be
possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not
includingcode,unlessthisiscentraltothecontribution(e.g.,foranewopen-source
benchmark).
•The instructions should contain the exact command and environment needed to run
to reproduce the results. See the NeurIPS code and data submission guidelines
(https://nips.cc/public/guides/CodeSubmissionPolicy ) for more details.
•The authors should provide instructions on data access and preparation, including how
to access the raw data, preprocessed data, intermediate data, and generated data, etc.
•The authors should provide scripts to reproduce all experimental results for the new
proposed method and baselines. If only a subset of experiments are reproducible, they
should state which ones are omitted from the script and why.
•At submission time, to preserve anonymity, the authors should release anonymized
versions (if applicable).
•Providing asmuch informationas possiblein supplementalmaterial(appended tothe
paper) is recommended, but including URLs to data and code is permitted.
6.Experimental Setting/Details
Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
results?
Answer: [Yes]
Justification: All chosen hyper-parameters and implementation details are stated in section 4
and Appendix A.
Guidelines:
•The answer NA means that the paper does not include experiments.
•Theexperimentalsettingshouldbepresentedinthecoreofthepapertoalevelofdetail
that is necessary to appreciate the results and make sense of them.
•The fulldetails canbe provided eitherwith thecode, in appendix,or as supplemental
material.
7.Experiment Statistical Significance
Question: Doesthepaperreporterrorbarssuitablyandcorrectlydefinedorotherappropriate
information about the statistical significance of the experiments?
Answer: [Yes]
Justification: Onallplots,weplotthemeantakenovermultiplerandomrunsandinclude
error bars to show the standard error over the runs.
Guidelines:
•The answer NA means that the paper does not include experiments.
23•Theauthorsshouldanswer"Yes"iftheresultsareaccompaniedbyerrorbars,confidence
intervals,orstatisticalsignificancetests,atleastfortheexperimentsthatsupportthe
main claims of the paper.
•The factors of variability that the error bars are capturing should be clearly stated (for
example, train/testsplit,initialization,randomdrawingofsomeparameter,oroverall
run with given experimental conditions).
•The method for calculating the error bars should be explained (closed form formula,
call to a library function, bootstrap, etc.)
•The assumptions made should be given (e.g., Normally distributed errors).
•Itshouldbeclearwhethertheerrorbaristhestandarddeviationorthestandarderrorof
the mean.
•It is OK to report 1-sigma error bars, but one should state it. The authors should
preferablyreporta2-sigmaerrorbarthanstatethattheyhavea96%CI,ifthehypothesis
of Normality of errors is not verified.
•For asymmetric distributions, the authors should be careful not to show in tables or
figuressymmetricerrorbarsthatwouldyieldresultsthatareoutofrange(e.g. negative
error rates).
•If error bars are reported in tables or plots, The authors should explain in the text how
they were calculated and reference the corresponding figures or tables in the text.
8.Experiments Compute Resources
Question: Foreachexperiment,doesthepaperprovidesufficientinformationonthecomputer
resources(typeofcomputeworkers,memory,timeofexecution)neededtoreproducethe
experiments?
Answer: [Yes]
Justification: See Appendix C.
Guidelines:
•The answer NA means that the paper does not include experiments.
•Thepapershouldindicatethetypeofcomputeworkers CPUorGPU,internalcluster,
or cloud provider, including relevant memory and storage.
•Thepapershouldprovidetheamountofcomputerequiredforeachoftheindividual
experimental runs as well as estimate the total compute.
•The paper should disclose whether the full research project required more compute
than the experiments reported in the paper (e.g., preliminary or failed experiments that
didn’t make it into the paper).
9.Code Of Ethics
Question: Does the research conducted in the paper conform, in every respect, with the
NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines ?
Answer: [Yes]
Justification: We have read the NeurIPS Code of Ethics and made sure to adhere to them in
all aspects.
Guidelines:
•The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
•Ifthe authorsanswer No, theyshould explainthe specialcircumstances thatrequire a
deviation from the Code of Ethics.
•The authors should make sure to preserve anonymity (e.g., if there is a special
consideration due to laws or regulations in their jurisdiction).
10.Broader Impacts
Question: Does the paper discuss both potential positive societal impacts and negative
societal impacts of the work performed?
Answer: [No] .
Justification: The paper is methodological, where the considered algorithm does not
immediately pose societal risks.
24Guidelines:
•The answer NA means that there is no societal impact of the work performed.
•If the authors answer NA or No, they should explain why their work has no societal
impact or why the paper does not address societal impact.
•Examplesofnegativesocietalimpactsincludepotentialmaliciousorunintendeduses
(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
(e.g.,deploymentoftechnologiesthatcouldmakedecisionsthatunfairlyimpactspecific
groups), privacy considerations, and security considerations.
•The conference expects that many papers will be foundational research and not tied
toparticularapplications,letalonedeployments. However,ifthereisadirectpathto
any negative applications, the authors should point it out. For example, it is legitimate
topointoutthatanimprovementinthequalityofgenerativemodelscouldbeusedto
generate deepfakes for disinformation. On the other hand, it is not needed to point out
thatagenericalgorithmforoptimizingneuralnetworkscouldenablepeopletotrain
models that generate Deepfakes faster.
•The authors should consider possible harms that could arise when the technology is
being used as intended and functioning correctly, harms that could arise when the
technologyisbeingusedasintendedbutgivesincorrectresults,andharmsfollowing
from (intentional or unintentional) misuse of the technology.
•Iftherearenegativesocietalimpacts,theauthorscouldalsodiscusspossiblemitigation
strategies (e.g., gated release of models, providing defenses in addition to attacks,
mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
feedback over time, improving the efficiency and accessibility of ML).
11.Safeguards
Question: Does the paper describe safeguards that have been put in place for responsible
release of data or models that have a high risk for misuse (e.g., pretrained language models,
image generators, or scraped datasets)?
Answer: [NA] .
Justification: The paper does not use data with potential societal concerns.
Guidelines:
•The answer NA means that the paper poses no such risks.
•Releasedmodelsthathaveahighriskformisuseordual-useshouldbereleasedwith
necessary safeguards to allow for controlled use of the model, for example by requiring
thatusersadheretousageguidelinesorrestrictionstoaccessthemodelorimplementing
safety filters.
•Datasets that have been scraped from the Internet could pose safety risks. The authors
should describe how they avoided releasing unsafe images.
•Werecognizethatprovidingeffectivesafeguardsischallenging,andmanypapersdo
not require this, but we encourage authors to take this into account and make a best
faith effort.
12.Licenses for existing assets
Question: Arethecreatorsororiginalownersofassets(e.g.,code,data,models),usedin
thepaper,properlycreditedandarethelicenseandtermsofuseexplicitlymentionedand
properly respected?
Answer: [Yes]
Justification: All creators of assets used to produce our results are cited in Section 4. All
assets used are open source software or models.
Guidelines:
•The answer NA means that the paper does not use existing assets.
•The authors should cite the original paper that produced the code package or dataset.
•Theauthorsshouldstatewhichversionoftheassetisusedand,ifpossible,includea
URL.
•The name of the license (e.g., CC-BY 4.0) should be included for each asset.
25•For scraped data from a particular source (e.g., website), the copyright and terms of
service of that source should be provided.
•If assets are released, the license, copyright information, and terms of use in the
package should be provided. For popular datasets, paperswithcode.com/datasets
hascuratedlicensesforsomedatasets. Theirlicensingguidecanhelpdeterminethe
license of a dataset.
•Forexistingdatasetsthatarere-packaged,boththeoriginallicenseandthelicenseof
the derived asset (if it has changed) should be provided.
•Ifthisinformationisnotavailableonline,theauthorsareencouragedtoreachouttothe
asset’s creators.
13.New Assets
Question: Arenewassetsintroducedinthepaperwelldocumentedandisthedocumentation
provided alongside the assets?
Answer: [NA] .
Justification: The paper does not introduce new assets.
Guidelines:
•The answer NA means that the paper does not release new assets.
•Researchers should communicate the details of the dataset/code/model as part of their
submissions via structured templates. This includes details about training, license,
limitations, etc.
•Thepapershoulddiscusswhetherandhowconsentwasobtainedfrompeoplewhose
asset is used.
•At submission time, remember to anonymize your assets (if applicable). You can either
create an anonymized URL or include an anonymized zip file.
14.Crowdsourcing and Research with Human Subjects
Question: For crowdsourcing experiments and research with human subjects, does the paper
includethefulltextofinstructionsgiventoparticipantsandscreenshots,ifapplicable,as
well as details about compensation (if any)?
Answer: [NA] .
Justification: The paper does not involve human participants.
Guidelines:
•The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
•Including this information in the supplemental material is fine, but if the main
contribution of the paper involves human subjects, then as much detail as possible
should be included in the main paper.
•According to the NeurIPS Code of Ethics, workersinvolvedin data collection, curation,
or other labor should be paid at least the minimum wage in the country of the data
collector.
15.InstitutionalReviewBoard(IRB)ApprovalsorEquivalentforResearchwithHuman
Subjects
Question: Doesthepaperdescribepotentialrisksincurredbystudyparticipants,whether
such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
approvals(oranequivalentapproval/reviewbasedontherequirementsofyourcountryor
institution) were obtained?
Answer: [NA] .
Justification: The paper does not involve live participants.
Guidelines:
•The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
26•Dependingonthecountryinwhichresearchisconducted,IRBapproval(orequivalent)
mayberequiredforanyhumansubjectsresearch. IfyouobtainedIRBapproval,you
should clearly state this in the paper.
•Werecognizethattheproceduresforthismayvarysignificantlybetweeninstitutions
and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
guidelines for their institution.
•For initial submissions, do not include any information that would break anonymity (if
applicable), such as the institution conducting the review.
27