Understanding Representation of Deep Equilibrium
Models from Neural Collapse Perspective
Haixiang Sun
ShanghaiTech University
sunhx@shanghaitech.edu.cnYe Shi∗
ShanghaiTech University
shiye@shanghaitech.edu.cn
Abstract
Deep Equilibrium Model (DEQ), which serves as a typical implicit neural network,
emphasizes their memory efficiency and competitive performance compared to
explicit neural networks. However, there has been relatively limited theoretical
analysis on the representation of DEQ. In this paper, we utilize the Neural Collapse
(NC) as a tool to systematically analyze the representation of DEQ under both
balanced and imbalanced conditions. NCis an interesting phenomenon in the
neural network training process that characterizes the geometry of class features
and classifier weights. While extensively studied in traditional explicit neural
networks, theNCphenomenon has not received substantial attention in the context
of implicit neural networks. We theoretically show that NCexists in DEQ under
balanced conditions. Moreover, in imbalanced settings, despite the presence of
minority collapse, DEQ demonstrated advantages over explicit neural networks.
These advantages include the convergence of extracted features to the vertices of a
simplex equiangular tight frame and self-duality properties under mild conditions,
highlighting DEQ’s superiority in handling imbalanced datasets. Finally, we vali-
date our theoretical analyses through experiments in both balanced and imbalanced
scenarios.
1 Introduction
Recently, there has been significant research on implicitly-defined layers in neural networks [ 1,2,
3,6,9,20,21,49], where the output is implicitly mapped from the input under certain conditions.
These layers embed interpretability and introduce inductive bias [ 26] into black-box neural networks,
demonstrating superior performance compared to existing explicit layers.
Among these implicit networks, the Deep Equilibrium Model (DEQ) is a memory-efficient archi-
tecture that represents all hidden layers as the equilibrium point of a nonlinear fixed-point equation.
Due to the absence of a closed-form solution in its forward process, DEQ can be viewed as having an
infinite number of layers during iteration as long as the threshold is set low enough, enhancing its
ability to fit input data. Consequently, its representational capacity is relatively stronger compared to
a single-layer network structure. This phenomenon explains why DEQ has achieved state-of-the-art
results in classification tasks compared to existing architectures like ResNet. For instance, it has been
successfully applied to language tasks and image classification tasks, reaching state-of-the-art perfor-
mance. Additionally, DEQ can be applied in various domains and integrated with numerous other
models, including inverse problems [ 19], Neural ODEs [ 11], diffusion models [ 24,43], Gaussian
processes [17], and more.
However, recent research reveals a phenomenon called Neural Collapse ( NC) concerning the learned
deep representations across datasets in image classification tasks [ 42]. Under theNCregime, the last-
∗Corresponding author.
38th Conference on Neural Information Processing Systems (NeurIPS 2024).layer feature of each sample in neural networks collapses to their within-class mean, and the classifier
vector converges to a simplex Equiangular Tight Frame (ETF). Theoretical analyses [ 10,40,51]
indicate that under the Unconstrained Features Mode (UFM) condition, specific features H0can
be isolated from the entire network, known as the layer-peeled model [ 14]. In this scenario, Neural
Collapse (NC) is observed under certain conditions, suggesting that NCis agnostic to the backbone
of feature extraction. Moreover, since NCmeasures the degree of proximity between features of
the same category, an imbalanced dataset can exert a more negative influence on the performance
ofNC. For instance, classes with fewer samples may not separate well and could converge in the
same direction, leading to what is known as Minority Collapse [14]. Thus, theNCmetric serves as a
valuable indicator of a model’s behavior in the context of imbalanced datasets.
The reasons behind the superior performance of DEQ still lack theoretical proof and comprehensive
quantitative analysis. Additionally, to the best of our knowledge, no prior work has integrated DEQ
with imbalanced scenarios. In our study, we integrate DEQ with layer-peeled models, add constraints
with respect to weights WDEQ, and consider the results of fixed-point iteration as the output of
DEQ. Therefore, we analyze the performance of NCin DEQ by continuously deriving the lower
bound of the loss function under certain constraints, allowing us to assess how NCmanifests in
the training performance of the network. Similarly, we apply the same operations to explicit neural
networks for comparison. Our results show that DEQ performs similarly to explicit neural networks
under balanced settings. We further extend the dataset to imbalanced conditions and analyze the NC
performance in DEQ, explaining why DEQ tends to outperform explicit neural networks under mild
conditions. We systematically analyze performance in terms of feature convergence, distance to the
Simplex ETF, and the parallel relationship between extracted features and classifier weights. These
analyses uncover the reasons behind the superior performance of DEQ compared to explicit neural
networks during training. Additionally, the experimental results in both balanced and imbalanced
scenarios validate our theoretical analyses.
Our main contributions are:
•We systematically analyzed the representation of DEQ from the NCperspective and com-
pared their performance with explicit neural networks. Our theoretical analysis shows that
both DEQ and explicit neural networks exhibit the NCphenomenon in balanced datasets.
•Under imbalanced settings, we theoretically proved the convergence of extracted features to
the vertices of a simplex ETF and alignment with classifier weights under certain conditions,
demonstrating DEQ’s advantages over explicit neural networks under some mild conditions.
•Experimental results on Cifar-10 and Cifar-100 validated our theoretical findings for distin-
guishing the differences between DEQ and explicit neural networks.
2 Background and related works
We consider a classification task with Kclasses. Let nkdenote the number of training samples in
each classk, andN=K/summationtext
k=1nkrepresent the total number of training samples. A traditional neural
network can be expressed as a mapping:
ψ(x) =Wϕ(x) +b, (1)
whereϕ(x) :Rin×N→RD×Nis the feature extraction, W∈RK×Dandb∈RKare the classifiers
and bias in the last layer, respectively. For simplicity, we consider the bias-free case and omit the
termb. Besides, we will denote H=ϕ(x)in later sections.
2.1 Deep Equilibrium Models
There have been numerous neural network architectures designed for various practical tasks from
different perspectives [ 17,32,38,39,48]. DEQ, a typical implicit network [ 13,52], incorporates
unrolling methods [ 12,41], which are devised for training arbitrarily deep networks by integrating all
the network layers into one [3, 4, 5, 35, 36, 58].
2Letfθ(z,x)represent a DEQ layer with input xparameterized by θ. Whenz⋆reaches the equilibrium
point, it satisfies:
gθ(z⋆,x)≜fθ(z⋆,x)−z⋆= 0. (2)
The forward procedure mostly employs the Broyden solver [7] for iterative solving:
zt+1=zt−B−1
tgθ(zt,x), (3)
whereB−1
trefers to the approximation of inverse matrix ∇−1
zgθ(zt,x), as well as the same parameter
θshared across iterations. However, the solution can be quite unstable, and efforts have been made
to enhance stability and robustness [ 34,44,55,56]. Especially, regarding the computation of the
inverse matrix, it can be expanded in the form of a Neumann series [ 18,60]. Besides, accelerating
and stabilizing the backward procedure is also an important issue in DEQ [15].
2.2 Neural Collapse NC
The phenomenon of NCwas initially uncovered by [ 42], which is considered an intriguing regularity
in neural network training with many elegant geometric properties [ 50,61,66]. When the model is at
the terminal phase of training (TPT), or more precisely, achieves zero training error, the within-class
means of features and the classifier vectors converge to the vertices of a simplex Equiangular Tight
Frame (ETF) on a balanced dataset.
Definition 2.1. (Simplex Equiangular Tight Frame) A collection of points si∈RD,i= 1,2,···,K,
is said to be a simplex equiangular tight frame if
S=α/radicalbigg
K
K−1P/parenleftig
IK−1
K1K1T
K/parenrightig
, (4)
whereαis a non-zero scalar, S= [s1,···,sk]∈RD×K,IK∈RK×Kis the identity matrix, 1Kis
the ones vector, and P∈RD×K(D≥K)is a partial orthogonal matrix such that PTP=IK.
NCincorporates the following four properties of the last-layer features and classifiers in deep learning
training on balanced datasets:
NC1:Variability collapse: The feature within-class converges to a unique vector, i.e., for any
sampleiin the same class k, its feature hk,isatisfies∥hk,i−¯hk∥→ 0,k∈[k], with the training
procedure.
NC2:Convergence to simplex ETF: The mean value h⋆of optimal features for each class collapses
to the vertices of the simplex ETF.
NC3:Convergence to self-duality: The class means and the classifier weights mutually converge:
W⋆
∥W∥=H⋆
∥H∥.
NC4:Nearest Neighbor: The classifier determines the class based on the Euclidean distances among
the feature vector and the classifier weights.
2.3 Layer-peeled model under balanced and imbalanced conditions
Current studies often focus on the case where only the last-layer features and classifier are learnable
without considering the layers in the backbone network under the assumption of Unconstrained
Features Mode (UFM) [ 66], which can also be referred to as the Layer-peeled Model [ 14,28]. First,
we define the feasible set of parameters:
C=/braceleftigg
wk,hk,i|1
KK/summationdisplay
k=1∥wk∥2≤EW,1
KK/summationdisplay
k=11
nknk/summationdisplay
i=1∥hk,i∥2≤EH/bracerightigg
. (5)
Definition 2.2. (Layer-peeled Model) When HandWare the last layer classifier and weights
respectively, then the optimization process of the neural network can be reformulated as:
min
W,H1
NK/summationdisplay
k=1nk/summationdisplay
i=1L(Whk,i,yk)s.t.wk,hk,i∈C, (6)
whereEHandEWare two predefined values, Nrefers to the total number of samples.
3InputNeural Networks
Logits 𝐻0Classifier 𝑾
𝑧0𝒙𝑊𝐸𝑋𝐻
𝑧∗
𝑧∗=𝑓(𝐻0;𝑊𝐷𝐸𝑄)Equilibrium Solver…Image
EncoderExplicit
DEQFigure 1: Illustration of feature extraction. After extracting feature maps H0, further features Hor
z⋆can be obtained by passing through an explicit neural network or DEQ. The final step involves
the classifier to obtain predicted logits. To ensure a fair comparison, we standardize the backbone
network and its output H0across all conditions.
It should be noted that all the loss functions Lanalyzed in our study are cross-entropy, as most current
research focuses on this widely used deep learning classification loss function [ 23,31]. And though
the optimization program is nonconvex; however, it can generally be mathematically tractable for
analysis. Besides, experiments with unregularized loss function and randomly initialized gradient
descent typically converge to non-collapse global minimizers [51].
Under UFM, mostNCstudies are based on 1-2 conventional layers of weights, However, there is also
work [ 10,51] that extends it to analyze Mlinear layers. Additionally, various studies have revealed
additional characteristics of NC, such as its impact on generalization [ 16,25,27,61], its influence
on feature learning [ 45], global optimality of the network [ 64,66] and others. Therefore, NCis a
very efficient tool to analyze the performance of neural networks.
Imbalanced learning However,NC will not occur under imbalanced settings generally. This
phenomenon arises due to the imbalance in sample quantities, leading to challenges in adequately
fitting features for certain classes. This is commonly referred to as minority collapse [8,14]. As the
degree of imbalance increases, it is expected that classifiers for minority classes converge. When
Minority Collapse occurs, the neural network predicts equal probabilities for all minority classes,
regardless of the input.
To enhance learning performance in imbalanced scenarios [ 62] and mitigate the effects of minority
collapse, several methods have been proposed. [ 14] introduced convex relaxation, modifying a loss
function [ 57], and incorporating a regularization term [ 37]. The reweighted approach is also widely
applied, with some studies measuring it based on sample quantities [ 47,59]. Additionally, adaptive
techniques such as AutoBalance [ 33] have been introduced, which incorporates a bilevel optimization
framework, along with logit balance [46, 54, 63, 65].
3 Comparison under balanced setting
In this section, we first analyze the NCphenomenon in DEQ under balanced settings. As illustrated
in Figure 1, after completing the initial feature extraction, we further examine the feature Hobtained
respectively by explicit neural networks and DEQ to reveal the NCphenomenon.
3.1NCin Explicit Neural Networks
Building upon (6), we analyze NCin explicit neural networks by considering the following con-
strained optimization problem during training:
min
W,W EX,H01
NK/summationdisplay
k=1n/summationdisplay
i=1L(WW EXh0
k,i,yk)
s.t.∥WEX∥F≤EH;wk,hk,i∈C,(7)
4where eachnkis set tonunder the balanced setting, WEXrepresents the subsequent network weights.
For ease of comparison with DEQ, we assume that the final feature is represented as H=WEXH0.
Traditional neural network structures are nonconvex, making them challenging to analyze due to their
highly interactive nature. Employing the layer-peeled model alleviates the difficulty of NCanalysis.
3.2NCin Deep Equilibrium models
Building upon recent investigations into the NCphenomenon, we embrace the layer-peeled model,
where the last-layer features h=ϕ(x)(equilibrium points in DEQ z⋆) as unconstrained optimization
variables. Accordingly, we add the following constraints to enforce NCin DEQ:
CDEQ≜/braceleftbig
z⋆,WDEQ|z⋆=f(H0;WDEQ),∥WDEQ∥F≤EH/bracerightbig
. (8)
Compared to explicit layers, the active parameter in Deep Equilibrium models is WDEQ, hence
imposing restrictions on it to align with the same feasible space. Then the formulation of DEQ with
NCbecomes:
min
W,W DEQ,z⋆,H01
NK/summationdisplay
k=1nk/summationdisplay
i=1L(Wz⋆,yk)
s.t.wk,hk,i∈C;z⋆,WDEQ∈C DEQ.(9)
No matter whether under DEQ or explicit neural networks, these constraints must be imposed. This
is because when these constraints are satisfied and the loss function reaches its lower bound, the
NCphenomenon is guaranteed. In our theoretical analysis, we assume that the DEQ is linear, that
is,z⋆=fixed-point (fθ(x),z) =∞/summationtext
i=0Wi
DEQx. Detailed analysis incorporating these constraints is
provided in Appendix B.
The following theorem elucidates the specific scenarios in which the NCphenomenon occurs. For a
fair comparison, we assume that the extracted features H0of the image encoder are the same in the
derivation.
Theorem 3.1. (Feature collapse of explicit fully connected layers and implicit deep equilibrium
models under balanced setting) Suppose (7) and (9) reaches its minimal, then
NC1: For∀k= 1,2,···,Kand∀i= 1,2,···,n:
WEXh0
k,i=WEXh0
k,
where h0
k=/summationtext
i∈τ(k)h0
k,i. Similarly, if the model is DEQ, then
f(h0
k,i;WDEQ) =f(h0
k;WDEQ).
NC2: The classifier aligns to the Simplex ETF , regardless of whether explicit neural network and
DEQ are applied:
WWT=/radicalbig
EW/EHWW EXH0
=/radicalbig
EW/EHWf(H0;WDEQ)
=KEW
K−1/parenleftbigg
1K−1
K1K1T
K/parenrightbigg
.
NC3: For∀k= 1,2,···,K, the feature aligns to the weights:
WEXh0
k∝Wk.
In DEQ cases:
f(h0
k;WDEQ)∝Wk.
The theorem demonstrates that when the network training reaches its limit, i.e., when the loss function
reaches its minimum, the NCphenomenon emerges regardless of whether the chosen network is
DEQ or explicit neural network. Besides, in certain scenarios, the lower bound of the loss function
for DEQ is relatively smaller compared to explicit neural networks. More detailed proofs are in
Appendix Section B.
54 Comparison under imbalanced setting
In this section, we analyze the performance differences between DEQ and explicit neural network on
imbalanced datasets. We observe that, unlike in balanced scenarios, as long as certain conditions are
met, the advantages of DEQ over explicit neural network become more pronounced on imbalanced
datasets. And we provide theoretical evidence to support this phenomenon.
Suppose the total number of classes is K, withKAbeing the number of majority classes and
KB=K−KAbeing the number of minority classes. Each majority class has nAsamples, and
each minority class has nBsamples. The total number of samples is given by N=KAnA+KBnB.
Note thatnA>nBwith no requirement for KAto be greater than KB. We first start with the loss
function, which can be partitioned into two components as follows:
min
W,˜W,H0KAnA
NKA/summationdisplay
k=1nA/summationdisplay
i=1L(W˜WH0,yk) +KBnB
NKB/summationdisplay
k=KA+1nB/summationdisplay
i=1L(W˜WH0,yk),
s.t. ˜W∈{C EXorCDEQ},wk,hk,i∈C,(10)
where ˜Wrepresents the weights of Deep Equilibrium Models WDEQand explicit neural network
WEX. To analyze theNCphenomenon, we present the results in the following theorem:
Theorem 4.1. (Neural Collapse under imbalanced settings on explicit neural networks and deep
equilibrium models)
When the loss function reaches the minimum, then
NC1: For∀k= 1,2,···,Kand∀i= 1,2,···,n:
WEXh0
k,i=WEXh0
k,
where h0
k=/summationtext
i∈τ(i)h0
k,i. Similarly, if the model is DEQ, then
f(h0
k,i;WDEQ) =f(h0
k;WDEQ).
NC2: Not exists, but the results of explicit neural network and DEQ can be compared:
Here we denote/parenleftbig
h0
k/parenrightbigTh0
k′=mk,k′andSis aK-Simplex ETF , if
EH<2Sij−mij<1
1−EH
is satisfied, the following inequality
/vextenddouble/vextenddouble/vextenddouble/parenleftbig
WEXH0/parenrightbigT/parenleftbig
WEXH0/parenrightbig
−S/vextenddouble/vextenddouble/vextenddouble
F>/vextenddouble/vextenddoublefT(H0;WDEQ)f(H0;WDEQ)−S/vextenddouble/vextenddouble
F
holds.
NC3: Similarly asNC2, though it does not exist, the results can still be compared, when
EH
Ew+EH+EH(1−EH)<2
is satisfied, then the cosine distance satisfies:
cos (f(hk;WDEQ),wk)/cos (WEXhk,wk)>1.
The detailed proof is in Appendix Section C.
Besides, the conclusion regarding the loss function is quite similar to that of Theorem B.3 under
balanced settings. As analyzed in (43) and (44) in the Appendix, the lower bound of the loss function
in DEQ is still lower than that in explicit neural network, where the performance of learned features
is more evident in Figure 2, where we use t-SNE [ 53] and Gram matrix of features to describe the
performance of two models. Although the phenomenon of NC2andNC3does not exist, we have
discovered in Theorem 4.1 that under mild conditions, DEQ is superior in terms of NCcompared to
6Explicit NN DEQ(a) t-SNE results.
Explicit NN DEQ (b) Visualization of the Gram matrix HHT.
Figure 2: Under the imbalanced setting for CIFAR-10 with KA= 3andR= 10 , the disparity in the
learned features between Explicit Neural Networks (left) and DEQ (right).
explicit neural network. Notably, the conditions are easy to satisfy since EHis generally very small
in practice.
A crucial insight is that since DEQ undergoes multiple rounds of parameter adjustments for learning,
it can be viewed as having an infinite number of layers, thus possessing greater representational
capacity. As the network deepens, the iterative process of forward fixed-point may not necessarily
reach the lowest threshold. Therefore, DEQ exhibits a certain degree of generalization for features
in the minority class. Given the substantial feature differences among classes under an imbalanced
dataset, the learned features by DEQ may demonstrate better adaptability to unseen categories.
Consequently, compared to explicit neural network, DEQ tends to enhance performance.
Besides, due to the repeated iterations in solving the fixed-point iteration for some samples in the
minority class with a small sample size, the model somewhat engages in multiple learning iterations
for the features of samples in this class. This mitigates the impact of imbalanced samples to some
extent. However, despite some improvements compared to the explicit neural network, DEQ still faces
the issue of minority collapse. This conclusion is further validated in our subsequent experiments.
Besides, to further discuss the situation of the dataset in terms of the degree of imbalance, we derived
the following proposition:
Proposition 4.2. DenoteR=KAnA/N. When the number of samples in the majority class becomes
extremely large, i.e., R→1, the features of the two kinds of classes will become:
Majority classes:
WEXh0
k,i=WEXh0
k,
f(h0
k,i;WDEQ) =f(h0
k;WDEQ),
where 1≤k≤KAandi∈π(k). Each feature collapses to KA-Simplex ETF .
Minority classes:
wk=0,
WEXh0
k,i=f(h0
k,i;WDEQ) =0,
whereKA+ 1≤k≤Kandi∈π(k).
Here,π(k)refers to the samples that belong to the class k.
This situation is equivalent to having a balanced dataset in the majority class, while the minority
class, due to its extremely small sample size, contributes almost nothing. In such an extreme scenario,
theNCperformance of DEQ and the fully connected layer is nearly indistinguishable similar to
Theorem 3.1. Both collapse on majority classes, resulting in a lack of learning features from minority
classes meeting the results of (51) and (52). This aligns with the findings in [ 14], where they provide
more specific bounds on the ratio KA/KBin their Theorem 5.
5 Experiments
In this section, we empirically conducted experiments to validate the correctness of the proposed
theorems. Initially, we implemented DEQ on a balanced dataset and compared its NCperformance
70 25 50 75 100
Epoch406080Accuracy
0 25 50 75 100
Epoch024NC1
0 25 50 75 100
Epoch0.20.40.60.8NC2
0 25 50 75 100
Epoch0.20.40.6NC3ResNet-18 DEQ(a) Balanced dataset
0 25 50 75 100
Epoch2025303540Accuracy
0 25 50 75 100
Epoch2
02468log1
0 25 50 75 100
Epoch0.70.80.92
0 25 50 75 100
Epoch0.60.81.01.23
ResNet-18 DEQ (b) Imbalanced dataset with KA=KB= 5,R= 100
Figure 3: Comparison of accuracy and NCphenomenon in training Cifar-10 dataset
with that of ResNet. Subsequently, for imbalanced datasets, we tested varying degrees of imbalance
by manipulating the quantities of nAandnB, as well as KAandKB. The experimental results
showed that, on imbalanced datasets, DEQ outperformed Explicit Neural Networks. This finding
is consistent with the results reported in [ 4]. All experiments were implemented using PyTorch on
NVIDIA Tesla A40 48GB.
5.1 Experiment setup
Without loss of generality, since any traditional neural network can be formulated as a DEQ, we use
ResNet18 [ 22] as the backbone architecture here. As discussed earlier, to utilize the fixed point z⋆
learned by DEQ as the extracted feature, we formulate the last ResNet block into a DEQ format, while
maintaining the remaining structure identical to ResNet. As mentioned in [ 5], training with DEQ can
lead to instability issues. This is especially noticeable as training progresses, where some samples
struggle to converge to a fixed point. To address this, in accordance with their setting, we implement
the solver with a threshold ϵset to 10−3and introduce an early stopping mechanism. If convergence
is not achieved within T >20iterations, we terminate the fixed-point iteration. Additionally, when
facing problematic samples during fixed-point solving, we skip them to ensure training stability.
During training, we set the learning rate to 1×10−4and utilize stochastic gradient descent with a
momentum of 0.9and weight decay of 5×10−4. BothEWandEHare set to 0.01. The training
phase for each network consists of 100 epochs, with a batch size of 128. In this context, accuracy is
assessed by averaging the results from the last 10 epochs and computing their standard deviation.
5.2 Performance under balanced conditions
Table 1: Comparison of accuracy under balanced set-
tings of Cifar-10 and Cifar-100
Cifar-10 Cifar-100
Explicit NN 93.05±0.17 64.35±0.20
DEQ 93.23±0.13 64.77±0.36By using the settings in (7) and (9), we
compared the performance of DEQ and Ex-
plicit NN on Cifar-10 [ 30] and Cifar-100
[29] for validation, as shown in Figure 3(a).
TheirNCperformances remain compara-
ble, i.e., DEQ achieves results similar to
Explicit NN, corroborating the findings of
Theorem 3.1. As for accuracy, from the
results in the first column of Table 1, it can be observed that DEQ’s accuracy is higher than that
of the explicit layer, which aligns with Theorem B.3. However, the increase is only marginal due
to the fact that the coefficients EHandEWact as scaling factors. Therefore, compared to explicit
neural network, DEQ finds it challenging to achieve a significantly lower loss and, consequently, a
substantial improvement. Moreover, Explicit NN performs well in fitting balanced datasets, so the
accuracy of DEQ does not experience a significant boost in this context.
8Here, we manually set the number of epochs to 100to avoid potential instability issues with DEQ
as training deepens. This is because DEQ can be challenging to reach the TPT (Terminal Phase of
Training). As the number of parameters increases, achieving fixed-point convergence becomes more
difficult, and even parameter explosion may occur. Under the current vanilla design, it is challenging
to avoid such instability. Therefore, for a fair comparison, we apply the same training settings to
both the implicit DEQ and the explicit neural network. The results in Figure 5 indicate that the
test performance at 100 epochs is not significantly different from that at TPT. Since DEQ shares
the same backbone as the corresponding explicit neural network, it can still demonstrate better NC
performance after reaching TPT in these cases.
Table 2: Test Accuracy on Cifar-10 and Cifar-100 Dataset with KA= 3
Cifar-10 Cifar-100
R 10 50 100 10 50 100
Explicit NNoverall 72.57±0.25 44.32±0.23 32.14±0.81 41.41±0.56 28.18±0.42 23.43±0.92
majority 96.40±0.32 96.80±0.29 91.67±0.61 73.03±0.62 74.53±0.55 73.46±0.56
minority 62.36±0.12 21.83±0.20 6.64±0.99 27.86±0.39 8.31±0.38 1.99±1.06
DEQoverall 73.84±0.72 46.08±1.06 34.18±1.28 43.72±0.60 30.46±1.27 24.78±1.93
majority 96.68±0.87 96.63±0.98 93.33±1.36 74.16±0.82 73.63±0.95 74.89±0.88
minority 64.06±0.66 24.42±1.32 8.83±1.08 30.67±0.53 11.96±1.66 3.31±2.45
5.3 Performance under imbalanced conditions
We conducted experiments with varying configurations with different numbers of majority and
minority classes and imbalance degrees. Assume the numbers of majority and minority classes
are(KA,KB)with corresponding sample sizes (nA,nB), the imbalance degree is denoted as
R=nA/nB.We considered different setups for majority and minority class quantities, such as
(3,7),(5,5), and (7,3). Additionally, we varied the ratio of sample quantities Rbetween majority
and minority classes with values of 10,50and100. We also tested the phenomenon of NCand
accuracy on the Cifar-10 and Cifar-100 datasets, which own a total of 5000 images for each class.
Specifically, when R= 100 and(KA,KB) = (3,7)for Cifar-10, the number of samples for all
classes is (5000,5000,5000,50,50,50,50,50,50,50).
The results for (KA,KB) = (3,7)are shown in Table 2, where the test dataset owns the same
distribution as the training dataset. We use “overall", “majority", and “minority" to represent the
results across all categories, the majority class, and the minority class, respectively. We contrasted the
difference in the training outcomes between the Explicit Neural Network and DEQ, and the superior
performance of DEQ compared to Explicit Neural Network confirms DEQ’s higher learning potential.
This suggests that DEQ can achieve a lower bound on its loss function. The experimental results
indicate that DEQ consistently outperforms explicit neural network in accuracy during imbalanced
training, aligning with Theorem 4.1. Specifically, we present the outcomes for (KA,KB) = (5,5)
withR= 100 are depicted in Figure 3(b). The results strongly corroborate Theorem 4.1, affirming
DEQ exhibits the same NC1phenomenon as an explicit neural network under these conditions.
However, DEQ outperforms the explicit neural network in terms of NC2andNC3. Additional
experimental results with different parameters are detailed in Appendix Section D.
In addition to the stability considerations discussed in Section 5.2, we refrain from training for an
extensive number of epochs due to the imbalance in the samples of the training set. This is because
excessive learning rounds might cause the network parameters to predominantly capture information
from the majority class, resulting in overfitting its features. This, in turn, diminishes the generalization
of learning features from other classes, leading to marginal improvements in accuracy on the test set.
As depicted in Figure 3(b), the model has already converged at this point. Moreover, limiting the
number of training epochs helps to avoid the gradual instability in the learning process of DEQ.
6 Conclusion
In this study, we have systematically analyzed the representation of Deep Equilibrium Models (DEQ)
and explicit neural networks under both balanced and imbalanced conditions using the phenomenon
of Neural Collapse ( NC). Our theoretical analysis demonstrated that NCis present in DEQ under
9balanced conditions. Furthermore, in imbalanced settings, DEQ exhibited notable advantages over
explicit neural networks, such as the convergence of extracted features to the vertices of a simplex
equiangular tight frame and self-duality properties under mild conditions. These findings highlight
the superior performance of DEQ in handling imbalanced datasets. Our experimental results in both
balanced and imbalanced scenarios validate the theoretical insights. The current analysis is limited to
simple imbalanced scenarios and the linear structure of DEQ models. Future work will expand on
this foundation by exploring more general imbalanced scenarios and extending the analysis to more
complex forms of DEQ models.
Acknowledgement
This work was supported by NSFC (No.62303319), Shanghai Sailing Program (22YF1428800),
Shanghai Local College Capacity Building Program (23010503100), ShanghaiTech AI4S Initiative
SHTAI4S202404, Shanghai Frontiers Science Center of Human-centered Artificial Intelligence
(ShangHAI), MoE Key Laboratory of Intelligent Perception and Human-Machine Collaboration
(ShanghaiTech University) and Shanghai Engineering Research Center of Intelligent Vision and
Imaging.
References
[1]A. Agrawal, B. Amos, S. Barratt, S. Boyd, S. Diamond, and Z. Kolter. Differentiable convex
optimization layers. In Advances in Neural Information Processing Systems , 2019.
[2]Brandon Amos and J Zico Kolter. Optnet: Differentiable optimization as a layer in neural
networks. In International Conference on Machine Learning , pages 136–145. PMLR, 2017.
[3]Shaojie Bai, J. Zico Kolter, and Vladlen Koltun. Deep equilibrium models. In Advances in
Neural Information Processing Systems (NeurIPS) , 2019.
[4]Shaojie Bai, Vladlen Koltun, and J. Zico Kolter. Multiscale deep equilibrium models. In
Advances in Neural Information Processing Systems (NeurIPS) , 2020.
[5]Shaojie Bai, Vladlen Koltun, and J. Zico Kolter. Stabilizing equilibrium models by jacobian
regularization. In International Conference on Machine Learning (ICML) , 2021.
[6]Mathieu Blondel, Quentin Berthet, Marco Cuturi, Roy Frostig, Stephan Hoyer, Felipe Llinares-
López, Fabian Pedregosa, and Jean-Philippe Vert. Efficient and modular implicit differentiation.
Advances in neural information processing systems , 35:5230–5242, 2022.
[7]Charles G Broyden. A class of methods for solving nonlinear simultaneous equations. Mathe-
matics of computation , 19(92):577–593, 1965.
[8]Kaidi Cao, Colin Wei, Adrien Gaidon, Nikos Arechiga, and Tengyu Ma. Learning imbalanced
datasets with label-distribution-aware margin loss. Advances in neural information processing
systems , 32, 2019.
[9]Ricky TQ Chen, Yulia Rubanova, Jesse Bettencourt, and David K Duvenaud. Neural ordinary
differential equations. Advances in neural information processing systems , 31, 2018.
[10] Hien Dang, Tan Nguyen, Tho Tran, Hung Tran, and Nhat Ho. Neural collapse in deep linear
network: From balanced to imbalanced data. arXiv preprint arXiv:2301.00437 , 2023.
[11] Shutong Ding, Tianyu Cui, Jingya Wang, and Ye Shi. Two sides of the same coin: Bridging
deep equilibrium models and neural ODEs via homotopy continuation. Advances in Neural
Information Processing Systems , 36, 2024.
[12] Justin Domke. Generic methods for optimization-based modeling. In Artificial Intelligence and
Statistics , pages 318–326. PMLR, 2012.
[13] Laurent El Ghaoui, Fangda Gu, Bertrand Travacca, Armin Askari, and Alicia Tsai. Implicit
deep learning. SIAM Journal on Mathematics of Data Science , 3(3):930–958, 2021.
[14] Cong Fang, Hangfeng He, Qi Long, and Weijie J Su. Exploring deep neural networks via
layer-peeled model: Minority collapse in imbalanced training. Proceedings of the National
Academy of Sciences , 118(43):e2103091118, 2021.
10[15] Samy Wu Fung, Howard Heaton, Qiuwei Li, Daniel McKenzie, Stanley Osher, and Wotao
Yin. Jfb: Jacobian-free backpropagation for implicit networks. In Proceedings of the AAAI
Conference on Artificial Intelligence , volume 36, pages 6648–6656, 2022.
[16] Tomer Galanti, András György, and Marcus Hutter. On the role of neural collapse in transfer
learning. arXiv preprint arXiv:2112.15121 , 2021.
[17] Tianxiang Gao, Xiaokai Huo, Hailiang Liu, and Hongyang Gao. Wide neural networks as
gaussian processes: Lessons from deep equilibrium models. arXiv preprint arXiv:2310.10767 ,
2023.
[18] Zhengyang Geng, Xin-Yu Zhang, Shaojie Bai, Yisen Wang, and Zhouchen Lin. On training
implicit models. Advances in Neural Information Processing Systems , 34:24247–24260, 2021.
[19] Davis Gilton, Gregory Ongie, and Rebecca Willett. Deep equilibrium architectures for inverse
problems in imaging. IEEE Transactions on Computational Imaging , 7:1123–1133, 2021.
[20] Stephen Gould, Richard Hartley, and Dylan Campbell. Deep declarative networks. IEEE
Transactions on Pattern Analysis and Machine Intelligence , 44(8):3988–4004, 2021.
[21] Fangda Gu, Heng Chang, Wenwu Zhu, Somayeh Sojoudi, and Laurent El Ghaoui. Implicit
graph neural networks. Advances in Neural Information Processing Systems , 33:11984–11995,
2020.
[22] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image
recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition ,
pages 770–778, 2016.
[23] Gao Huang, Zhuang Liu, Laurens Van Der Maaten, and Kilian Q Weinberger. Densely connected
convolutional networks. In Proceedings of the IEEE conference on computer vision and pattern
recognition , pages 4700–4708, 2017.
[24] Yuhao Huang, Qingsong Wang, Akwum Onwunta, and Bao Wang. Efficient score matching with
deep equilibrium layers. In The Twelfth International Conference on Learning Representations ,
2024.
[25] Like Hui, Mikhail Belkin, and Preetum Nakkiran. Limitations of neural collapse for understand-
ing generalization in deep learning. arXiv preprint arXiv:2202.08384 , 2022.
[26] Arthur Jacot, Franck Gabriel, and Clément Hongler. Neural tangent kernel: Convergence and
generalization in neural networks. Advances in neural information processing systems , 31,
2018.
[27] Jiachen Jiang, Jinxin Zhou, Peng Wang, Qing Qu, Dustin Mixon, Chong You, and Zhihui Zhu.
Generalized neural collapse for a large number of classes. arXiv preprint arXiv:2310.05351 ,
2023.
[28] Vignesh Kothapalli. Neural collapse: A review on modelling principles and generalization.
Transactions on Machine Learning Research , 2023.
[29] Alex Krizhevsky and Geoffrey Hinton. Learning multiple layers of features from tiny images.
Technical Report 0, University of Toronto, Toronto, Ontario, 2009.
[30] Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton. Cifar-10 (canadian institute for advanced
research). URL http://www. cs. toronto. edu/kriz/cifar. html , 5(4):1, 2010.
[31] Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. Deep learning. nature , 521(7553):436–444,
2015.
[32] Jaehoon Lee, Yasaman Bahri, Roman Novak, Samuel S Schoenholz, Jeffrey Pennington,
and Jascha Sohl-Dickstein. Deep neural networks as gaussian processes. arXiv preprint
arXiv:1711.00165 , 2017.
[33] Mingchen Li, Xuechen Zhang, Christos Thrampoulidis, Jiasi Chen, and Samet Oymak. Au-
tobalance: Optimized loss functions for imbalanced data. Advances in Neural Information
Processing Systems , 34:3163–3177, 2021.
[34] Mingjie Li, Yisen Wang, and Zhouchen Lin. Cerdeq: Certifiable deep equilibrium model. In
International Conference on Machine Learning , pages 12998–13013. PMLR, 2022.
11[35] Zenan Ling, Longbo Li, Zhanbo Feng, YIXUAN ZHANG, Feng Zhou, Robert C Qiu, and
Zhenyu Liao. Deep equilibrium models are almost equivalent to not-so-deep explicit models
for high-dimensional gaussian mixtures. In Forty-first International Conference on Machine
Learning , 2024.
[36] Zenan Ling, Xingyu Xie, Qiuhao Wang, Zongpeng Zhang, and Zhouchen Lin. Global conver-
gence of over-parameterized deep equilibrium models. In International Conference on Artificial
Intelligence and Statistics , pages 767–787. PMLR, 2023.
[37] Xuantong Liu, Jianfeng Zhang, Tianyang Hu, He Cao, Yuan Yao, and Lujia Pan. Inducing neural
collapse in deep long-tailed learning. In International Conference on Artificial Intelligence and
Statistics , pages 11534–11544. PMLR, 2023.
[38] Jonathan Lorraine, Paul Vicol, and David Duvenaud. Optimizing millions of hyperparameters
by implicit differentiation. In International conference on artificial intelligence and statistics ,
pages 1540–1552. PMLR, 2020.
[39] Song Mei, Andrea Montanari, and Phan-Minh Nguyen. A mean field view of the landscape of
two-layer neural networks. Proceedings of the National Academy of Sciences , 115(33):E7665–
E7671, 2018.
[40] Dustin G Mixon, Hans Parshall, and Jianzong Pi. Neural collapse with unconstrained features.
arXiv preprint arXiv:2011.11619 , 2020.
[41] Vishal Monga, Yuelong Li, and Yonina C Eldar. Algorithm unrolling: Interpretable, efficient
deep learning for signal and image processing. IEEE Signal Processing Magazine , 38(2):18–44,
2021.
[42] Vardan Papyan, XY Han, and David L Donoho. Prevalence of neural collapse during the
terminal phase of deep learning training. Proceedings of the National Academy of Sciences ,
117(40):24652–24663, 2020.
[43] Ashwini Pokle, Zhengyang Geng, and J Zico Kolter. Deep equilibrium approaches to diffusion
models. Advances in Neural Information Processing Systems , 35:37975–37990, 2022.
[44] Zaccharie Ramzi, Pierre Ablin, Gabriel Peyré, and Thomas Moreau. Test like you train in
implicit deep learning. arXiv preprint arXiv:2305.15042 , 2023.
[45] Akshay Rangamani, Marius Lindegaard, Tomer Galanti, and Tomaso A Poggio. Feature learning
in deep classifiers through intermediate neural collapse. In International Conference on Machine
Learning , pages 28729–28745. PMLR, 2023.
[46] Jiawei Ren, Cunjun Yu, Xiao Ma, Haiyu Zhao, Shuai Yi, et al. Balanced meta-softmax for long-
tailed visual recognition. Advances in neural information processing systems , 33:4175–4186,
2020.
[47] Mengye Ren, Wenyuan Zeng, Bin Yang, and Raquel Urtasun. Learning to reweight examples
for robust deep learning. In International conference on machine learning , pages 4334–4343.
PMLR, 2018.
[48] Pengzhen Ren, Yun Xiao, Xiaojun Chang, Po-Yao Huang, Zhihui Li, Xiaojiang Chen, and Xin
Wang. A comprehensive survey of neural architecture search: Challenges and solutions. ACM
Computing Surveys (CSUR) , 54(4):1–34, 2021.
[49] Haixiang Sun, Ye Shi, Jingya Wang, Hoang Duong Tuan, H Vincent Poor, and Dacheng Tao.
Alternating differentiation for optimization layers. arXiv preprint arXiv:2210.01802 , 2022.
[50] Christos Thrampoulidis, Ganesh Ramachandra Kini, Vala Vakilian, and Tina Behnia. Imbalance
trouble: Revisiting neural-collapse geometry. Advances in Neural Information Processing
Systems , 35:27225–27238, 2022.
[51] Tom Tirer and Joan Bruna. Extended unconstrained features model for exploring deep neural
collapse. In International Conference on Machine Learning , pages 21478–21505. PMLR, 2022.
[52] Russell Tsuchida, Suk Yee Yong, Mohammad Ali Armin, Lars Petersson, and Cheng Soon
Ong. Declarative nets that are equilibrium models. In International Conference on Learning
Representations , 2022.
[53] Laurens van der Maaten and Geoffrey Hinton. Visualizing data using t-sne. Journal of Machine
Learning Research , 9(86):2579–2605, 2008.
12[54] Yuchao Wang, Jingjing Fei, Haochen Wang, Wei Li, Tianpeng Bao, Liwei Wu, Rui Zhao, and
Yujun Shen. Balancing logit variation for long-tailed semantic segmentation. In Proceedings of
the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 19561–19573,
2023.
[55] Colin Wei and J Zico Kolter. Certified robustness for deep equilibrium models via interval
bound propagation. In International Conference on Learning Representations , 2022.
[56] Ezra Winston and J Zico Kolter. Monotone operator equilibrium networks. Advances in neural
information processing systems , 33:10718–10728, 2020.
[57] Liang Xie, Yibo Yang, Deng Cai, and Xiaofei He. Neural collapse inspired attraction–repulsion-
balanced loss for imbalanced learning. Neurocomputing , 527:60–70, 2023.
[58] Xingyu Xie, Qiuhao Wang, Zenan Ling, Xia Li, Guangcan Liu, and Zhouchen Lin. Opti-
mization induced equilibrium networks: An explicit optimization perspective for understand-
ing equilibrium models. IEEE Transactions on Pattern Analysis and Machine Intelligence ,
45(3):3604–3616, 2022.
[59] Yibo Yang, Shixiang Chen, Xiangtai Li, Liang Xie, Zhouchen Lin, and Dacheng Tao. Inducing
neural collapse in imbalanced learning: Do we really need a learnable classifier at the end of
deep neural network? Advances in Neural Information Processing Systems , 35:37991–38002,
2022.
[60] Zonghan Yang, Tianyu Pang, and Yang Liu. A closer look at the adversarial robustness of deep
equilibrium models. Advances in Neural Information Processing Systems , 35:10448–10461,
2022.
[61] Can Yaras, Peng Wang, Zhihui Zhu, Laura Balzano, and Qing Qu. Neural collapse with
normalized features: A geometric analysis over the riemannian manifold. Advances in neural
information processing systems , 35:11547–11560, 2022.
[62] Yifan Zhang, Bingyi Kang, Bryan Hooi, Shuicheng Yan, and Jiashi Feng. Deep long-tailed
learning: A survey. IEEE Transactions on Pattern Analysis and Machine Intelligence , 2023.
[63] Zhisheng Zhong, Jiequan Cui, Yibo Yang, Xiaoyang Wu, Xiaojuan Qi, Xiangyu Zhang, and
Jiaya Jia. Understanding imbalanced semantic segmentation through neural collapse. In
Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages
19550–19560, 2023.
[64] Jinxin Zhou, Xiao Li, Tianyu Ding, Chong You, Qing Qu, and Zhihui Zhu. On the optimization
landscape of neural collapse under mse loss: Global optimality with unconstrained features. In
International Conference on Machine Learning , pages 27179–27202. PMLR, 2022.
[65] Jianggang Zhu, Zheng Wang, Jingjing Chen, Yi-Ping Phoebe Chen, and Yu-Gang Jiang. Bal-
anced contrastive learning for long-tailed visual recognition. In Proceedings of the IEEE/CVF
Conference on Computer Vision and Pattern Recognition , pages 6908–6917, 2022.
[66] Zhihui Zhu, Tianyu DING, Jinxin Zhou, Xiao Li, Chong You, Jeremias Sulam, and Qing
Qu. A geometric analysis of neural collapse with unconstrained features. In A. Beygelzimer,
Y . Dauphin, P. Liang, and J. Wortman Vaughan, editors, Advances in Neural Information
Processing Systems , 2021.
13Appendix Contents
A Evaluation metrics of NC 14
B Proof under balanced setting 15
B.1 Problem definition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15
B.2NCanalysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17
B.2.1NCproof in Explicit neural networks . . . . . . . . . . . . . . . . . . . . 17
B.2.2NCproof in DEQ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18
C Proof under imbalanced learning 20
C.1 Lower bound of the loss function . . . . . . . . . . . . . . . . . . . . . . . . . . . 20
C.2NCAnalysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23
D More experiments 26
A Evaluation metrics of NC
Followed by the settings of [51] and [10], the measurement of NCare set as follow:
Lethk≜1
nk/summationtextnk
i=1hk,irepresent the average of all features within class kand theseKclasses
collectively constitute the average matrix ¯H= [h1,···,hK]. Besides, The global average is
defined as hG≜1
K/summationtextK
i=1hk. Subsequently, the within-class and between-class covariances can be
calculated as:
ΣW≜1
NK/summationdisplay
k=1nk/summationdisplay
i=1(hk,i−hk)(hk,i−hk)T,
ΣB≜1
KK/summationdisplay
k=1(hk−¯hG)(hk−¯hG)T.(11)
NC1measures the variation of features with-in the same class:
NC1 =1
Ktr/parenleftig
ΣWΣ†
B/parenrightig
, (12)
where Σ†
Bdenotes the pseudo-inverse of ΣB.
NC2measures similarity between the mean of learned last-layer features ¯Hand the structure of
Simplex ETF:
NC2 =/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble¯HT¯H
∥¯HT¯H∥F−1
K−1(IK−1
K1K1T
K)/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble
F. (13)
NC3measures similarity of the last-layer feature ¯Hand weights of classifier W:
NC3 =/vextenddouble/vextenddouble/vextenddouble/vextenddoubleW
∥W∥F−¯H
∥¯H∥F/vextenddouble/vextenddouble/vextenddouble/vextenddouble. (14)
Additionally, it is worth noting that all above NCcriteria are exclusively based on the training set.
This is because our focus is solely on analyzing learning performance on imbalanced datasets, and
generalization is not a primary concern.
14B Proof under balanced setting
B.1 Problem definition
As different layers in the neural network introduce complexity, the optimization problem is non-
convex, and KKT conditions do not guarantee global optimality. Therefore, we consider applying
inequality relaxation to the joint optimization problem, obtaining a lower bound for the loss function.
By determining the conditions under which the equality holds, we can derive the requirements for the
NCphenomenon. This analysis assumes a balanced setting, where all #τ(k) =n1=n2=···=
nK=N/K .
We considered the fully connected layers (explicit) and Deep Equilibrium Models (implicit) under
the balanced settings respectively, and then derived the detailed proof.
(Fully Connected Layers)
min
W,W EX,H1
NK/summationdisplay
k=1nk/summationdisplay
i=1L(WW EXh0
k,i,yk)
s.t.hk,i=WEXh0
k,i,
∥WEX∥F≤EH,
1
KK/summationdisplay
k=1∥wk∥2≤EW,
1
KK/summationdisplay
k=11
nknk/summationdisplay
i=1∥hk,i∥2≤EH,(Deep Equilibrium Models)
min
W,W DEQ,z⋆
k,i1
NK/summationdisplay
k=1nk/summationdisplay
i=1L(Wz⋆,yk)
s.t.z⋆
k,i=f(h0
k,i;WDEQ),
∥WDEQ∥F≤EH,
1
KK/summationdisplay
k=1∥wk∥2≤EW,
1
KK/summationdisplay
k=11
nknk/summationdisplay
i=1∥z⋆
k,i∥2≤EH.
Note that here n1=n2=···=nk=n, andfrepresents the form of Linear DEQ, where we will
usef(x;WDEQ) =∞/summationtext
i=1Wi
DEQxfor representation in the following proofs.
In a classification task, cross-entropy loss L(Whk,i,yk)is regarded as the final loss function.
Drawing inspiration from [ 14], our initial efforts revolve around organizing and simplifying the log
function to distinguish the logit in class kfrom other classes.
First consider the following lemma:
Lemma B.1. Let there be Kvariablesδ1,δ2,···,δK, and the logit of each variable δksatisfies the
inequality:
log/parenleftigg
δk/k/summationdisplay
k=1δk/parenrightigg
≤M1
logδk−1
K−1K/summationdisplay
k′̸=klogδk
+M2, (15)
whereM1andM2are predefined constants.
Proof. Split the sum in the denominator and sequentially introduce weights for each term. Here,
defineKcoefficients such that their sum is 1. Therefore, we have:
C1
C1+C2+C3+···+C3/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
K−1= 1, (16)
15that isC3=C2
(K−1)(C1+C2). Therefore, by Jensen’s inequality, we can derive:
log/parenleftigg
δk/K/summationdisplay
k′=1δk′/parenrightigg
= logδk−log/parenleftiggK/summationdisplay
k′=1δk′/parenrightigg
= logδk−log
C1
C1+C2(C1+C2)δk
C1+C3K/summationdisplay
k′̸=kδk′
C3

≤logδk−C1
C1+C2log/parenleftbigg(C1+C2)δk
C1/parenrightbigg
−C3K/summationdisplay
k′̸=klogδk′
C3
=M1
logδk−1
K−1K/summationdisplay
k′̸=klogδk′
+M2,(17)
whereM1=C2
C1+C2andM2=C2
C1+C2logC3−C1
C1+C2log/parenleftbiggC1+C2
C1/parenrightbigg
. Therefore the
lemma is proved.
Remark B.2.WhenC2/C1=1
K−1exp/parenleftigg
logδk−1
K−1K/summationtext
k′̸=klogδk′/parenrightigg
, the right term of the
inequality in lemma B.1 reaches its maximum.
Proof. LetM=M1/parenleftigg
logδk−1
K−1K/summationtext
k′̸=klogδk′/parenrightigg
+M2in Lemma B.1. Then, upon computing
the derivatives of C1andC2, we obtain:
∂M
∂C1=1
(C1+C2)2/parenleftbigg
−C2M−M2
M1+C2log(K−1)C2
C1/parenrightbigg
∂M
∂C2=1
(C1+C2)2/parenleftbigg
C1M−M2
M1−C1log(K−1)C2
C1/parenrightbigg
.(18)
Combining these two equations yields the conclusion.
Next, we substitute the result of each logit into the lemma B.1, from which we can derive:
L=−1
NK/summationdisplay
k=1n/summationdisplay
i=1yk,ilogexp(wT
k,ihi)
K/summationtext
k′=1exp(wT
k′,ihi)
≥C1
(C1+C2)N(K−1)n/summationdisplay
i=1
/parenleftiggK/summationdisplay
k=1hk,i/parenrightiggT/parenleftiggK/summationdisplay
k=1wk/parenrightigg
−KK/summationdisplay
k=1hT
k,iwk
+C4
=C1K
(C1+C2)N(K−1)K/summationdisplay
k=1n/summationdisplay
i=1(¯hi−hk,i)Twk+C4
≥C1
(C1+C2)N(K−1)/parenleftigg
−K
2K/summationdisplay
k=1n/summationdisplay
i=1∥¯hi−hk,i∥2/C5−C5N
2K/summationdisplay
k=1∥wk∥2/parenrightigg
+C4,(19)
where the second inequality applies Mean Inequalities, and C4=C2
N(C1+C2)logC3−
C1
N(C1+C2)log/parenleftbiggC1+C2
C1/parenrightbigg
. For convenience, we denote ˜L=−K
2K/summationtext
k=1n/summationtext
i=1∥¯hi−hk,i∥2/C5−
16C5N
2K/summationtext
k=1∥wk∥2. As the corresponding constraints have already been added in (6), specifically the
constraintK/summationtext
k=1∥wk∥2≤EW, our focus shifts to discussing the situation concerning the first term.
Since it represents the features of the final layer, we separately explore the differences in its extraction
when using DEQ and fully connected layers. First suppose the extracted feature by the backbone is
h0.
B.2NCanalysis
We separately discuss the representation of NCin the cases of Explicit NN and DEQ, and compare
the lower bounds of the loss function.
B.2.1NCproof in Explicit neural networks
For convenience, we assume there is only one layer in the feature extractor, that is, h=WEXh0,
then the first term in ˜Lbecomes:
−K
2K/summationdisplay
k=1n/summationdisplay
i=1∥¯hi−hk,i∥2=−K
2K/summationdisplay
k=1n/summationdisplay
i=1∥WEX(¯h0
i−h0
k,i)∥2
≥−K
4K/summationdisplay
k=1n/summationdisplay
i=1/parenleftig
∥WEX∥2
F+∥¯h0
i−h0
k,i∥2/parenrightig
.(20)
Substituting them into the loss function (19), we can observe that:
˜L≥−NK
4C5∥WEX∥2
F−K
4C5K/summationdisplay
k=1n/summationdisplay
i=1∥¯h0
i−h0
k,i∥2−C5NK
2EW
=−K2
4C5n/summationdisplay
i=11
KK/summationdisplay
k=1/parenleftig
∥h0
k,i∥2−∥¯h0
i∥2/parenrightig
−NK
4C5∥WEX∥2
F−C5NK
2EW
≥−KN
4C5EH−C5KN
2EW+K2
4C5n/summationdisplay
i=1∥¯h0
i∥2−NK
4C5EH.(21)
To acquire the lower bound of the loss function, we assign the value C5=/radicalbig
EH/EW, the lower
bound becomes:
infLEX=−C1K
(C1+C2)(K−1)/radicalbig
EWEH+C4. (22)
Furthermore, the condition ∥¯h0
i∥2= 0 should also be satisfied, indicating that the average of the
features for the i-th sample,1
KK/summationtext
k=1h0
k,i, is equal to zero.
The satisfaction conditions for the inequalities include the following:
• In Eq. (19): The first inequality becomes equality when
(C1+C2)hT
k,iwk
C1=hT
k,iwk′
C3, (23)
that is,
hT
k,iwk=hT
k,iwk′+ log/parenleftbiggC1(K−1)
C2/parenrightbigg
. (24)
The second inequality is reduced to equality when ¯hi−hk,i=−C5wk.
• In Eq. (20):∥WEX∥2
F=K/summationtext
k=1nk/summationtext
i=1∥¯h0
i−h0
k,i∥2.
17•In Eq. (21): When the following condition1
KK/summationtext
k=1∥wk∥2=EWand∥WEX∥2
F=
1
KK/summationtext
k=1nk/summationtext
i=1∥h0
k,i∥2=EHholds, the inequality was reduced to equality.
Since∥¯h0
i∥2= 0, it follows that∥¯hi∥2=∥WEX¯h0
i∥2= 0. Combined with the condition
1
KK/summationtext
k=1∥wk∥2=EWand1
KK/summationtext
k=1nk/summationtext
i=1∥hk,i∥2=EH, therefore, hk=hk,i, for∀k, that is,NC1is
proved.
Consequently, hk,i=C5wk, demonstrating the validity of NC3.
ForNC2, since
/radicalbig
EH/EW∥wk∥2=hkwk=hkwk′+ log/parenleftigC1(K−1)
C2/parenrightig
=WEXh0
kWk′+ log/parenleftigC1(K−1)
C2/parenrightig
,
/radicalbig
EH/EW∥wk′∥2=hk′wk′=hk′wk+ log/parenleftigC1(K−1)
C2/parenrightig
=WEXh0
k′Wk+ log/parenleftigC1(K−1)
C2/parenrightig(25)
holds, by the equality conditions, ∥wk∥2=∥wk′∥2=EW.
Further,K/summationtext
k=1hkwk′=K/summationtext
k=1WEXh0
kwk′= 0, ashkwk=√EWEH, sohkwk′=−√EWEH
N−1.
Therefore, theNC2condition satisfies:
WWT=/radicalbig
EW/EHWH =KEW
K−1/parenleftbigg
1K−1
k1K1T
K/parenrightbigg
. (26)
B.2.2NCproof in DEQ
In the blocks for feature extraction, DEQ can be referred as a mapping from the features by backbone
to the output h0→h⋆, which can be directly solved using the implicit equation:
h⋆=f(WDEQ;h0) =∞/summationdisplay
i=1Wi
DEQh0. (27)
Similar as the explicit case, start with the term:
−K
2K/summationdisplay
k=1n/summationdisplay
i=1∥¯hi−hk,i∥2=K
2K/summationdisplay
k=1n/summationdisplay
i=1/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble∞/summationdisplay
j=0Wj
DEQ(¯h0
i−h0
k,i)/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
. (28)
Since the Neumann series can be regarded as a recursive procedure, denote Gj
k,i=j/summationtext
j′=0Wj′
DEQ(¯h0
i−
h0
k,i)(j= 0,1,···,∞), thereforeGj
k,i=WDEQGj−1
k,i+ (¯h0
i−h0
k,i).
−K
2K/summationdisplay
k=1n/summationdisplay
i=1/vextenddouble/vextenddoubleGj
k,i/vextenddouble/vextenddouble2=K
2K/summationdisplay
k=1n/summationdisplay
i=1/vextenddouble/vextenddouble/vextenddoubleW DEQGj−1
k,i+ (¯h0
i−h0
k,i)/vextenddouble/vextenddouble/vextenddouble2
≥−K
2K/summationdisplay
k=1n/summationdisplay
i=1/vextenddouble/vextenddoubleW DEQGj−1
k,i/vextenddouble/vextenddouble2−K
2K/summationdisplay
k=1n/summationdisplay
i=1/vextenddouble/vextenddouble/vextenddouble¯h0
i−h0
k,i/vextenddouble/vextenddouble/vextenddouble2
≥−K
4K/summationdisplay
k=1n/summationdisplay
i=1/parenleftig
∥W DEQ∥2
F+/vextenddouble/vextenddoubleGj−1
k,i/vextenddouble/vextenddouble2/parenrightig
−K
2K/summationdisplay
k=1n/summationdisplay
i=1/vextenddouble/vextenddouble/vextenddouble¯h0
i−h0
k,i/vextenddouble/vextenddouble/vextenddouble2
F.(29)
Continuing the recursion, we can obtain:
−1
2∥Gj
k,i∥2≥−/parenleftbigg1
2/parenrightbiggj+1/vextenddouble/vextenddoubleG0
k,i/vextenddouble/vextenddouble2−/parenleftbigg
1−1
2j/parenrightbigg/vextenddouble/vextenddoubleh0
i−h0
k,i/vextenddouble/vextenddouble2−/parenleftbigg1
2−1
2j+1/parenrightbigg
∥WDEQ∥2
F.(30)
18So, whenj→∞ ,
−K
2K/summationdisplay
k=1n/summationdisplay
i=1/vextenddouble/vextenddoubleG0
k,i/vextenddouble/vextenddouble2=K
2K/summationdisplay
k=1n/summationdisplay
i=1/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble∞/summationdisplay
j=0Wj
DEQ(¯h0
i−h0
k,i)/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
≥−KK/summationdisplay
k=1n/summationdisplay
i=1/parenleftbigg/vextenddouble/vextenddoubleh0
i−h0
k,i/vextenddouble/vextenddouble2−1
2∥WDEQ∥2
F/parenrightbigg
.(31)
Therefore, use a similar proof as a fully connected layer,
˜L≥−K
C5K/summationdisplay
k=1n/summationdisplay
i=1/vextenddouble/vextenddoubleh0
i−h0
k,i/vextenddouble/vextenddouble2−NK
2C5∥WDEQ∥2
F−C5NK
2EW
=−K
C5n/summationdisplay
i=1/parenleftigg
1
K2K/summationdisplay
k=1∥h0
k,i∥2−∥¯h0
i∥2/parenrightigg
−NK
2C5∥WDEQ∥2
F−C5NK
2EW
≥−NK
C5EH−C5NK
2EW+K2
C5n/summationdisplay
i=1∥¯h0
i∥2−NK
2C5EH.(32)
SetC5=/radicalbig
EH/EW, the loss bound of the loss function becomes:
infLDEQ=−2C1K
(C1+C2)(K−1)/radicalbig
EWEH+C4. (33)
In comparison with the lower bound of the loss function (22), it is evident that the loss function of
the DEQ layer is significantly lower than that of the explicit neural network. Since the models are
identical, according to Remark B.2, the values of C1andC2are nearly the same. This observation
highlights the relatively stronger potential of DEQ compared to Explicit Neural Networks.
Also, the satisfaction conditions for the inequalities in DEQ settings include the following:
• In Eq. (19): The first inequality becomes equality when
(C1+C2)hT
k,iwk
C1=hT
k,iwk′
C3, (34)
that is,
hT
k,iwk=hT
k,iwk′+ log/parenleftbiggC1(K−1)
C2/parenrightbigg
. (35)
The second inequality is reduced to equality when ¯hi−hk,i=−C5wk. This condition is
quite similar to explicit fully connected layers.
• In Eq. (29):
The first inequality:
WDEQGj−1
k,i=¯h0
i−h0
k,i, (36)
and the second inequality
∥WDEQ∥2
F=/vextenddouble/vextenddouble/vextenddoubleGj−1
k,i/vextenddouble/vextenddouble/vextenddouble2
. (37)
•In Eq. (32): When the following condition1
KK/summationtext
k=1∥wk∥2=EWand∥WDEQ∥2=
1
KK/summationtext
k=1nk/summationtext
i=1∥hk,i∥2=EHholds, the inequality was reduced to equality.
To summarize, DEQs are proposed for the memory-saving properties, as the forward passes can
leverage any black-box root solvers [ 3,5]. However, in terms of forward inference, explicit neural
networks have limited learning capacity for data representation since they involve direct expressions
computed in a single pass and backward propagation. In contrast, DEQ, lacking a direct explicit form,
19requires multiple rounds of parameter adjustments for learning. In each iteration, DEQ introduces
input data in a sequential manner, allowing more adjustment space for learning parameters specific to
the input. Therefore, to compare the two loss functions, we can derive the following theorem:
Theorem B.3. DEQ achieves a lower bound on the loss function compared to explicit neural network
under balanced datasets:
infLDEQ=−2C1K
K−1/radicalbig
EWEH+C2,
while the lower bound of loss function of explicit neural network remains:
infLEX=−C1K
K−1/radicalbig
EWEH+C2,
whereC1andC2are two given constants.
Under the balanced dataset, the sample distribution of each class within each batch is relatively
even. Therefore, during the fixed-point iteration process, both DEQ and explicit neural network can
learn the features of each class relatively well, without showing significant differences. Besides,
from a numerical perspective, the penalties EWandEHare generally not set to very large values,
especially smaller than 1, so the difference between the two lower bounds in Theorem B.3 may not
be substantial. Besides, as analyzed in Remark B.2, we can set C2in this two equations as identical,
and once the propotion of logits in the explicit neural network is greater than the DEQ, the lower
bound of loss function in DEQ is lower.
C Proof under imbalanced learning
C.1 Lower bound of the loss function
Consider the loss function:
L=KAnA
NKA/summationdisplay
k=1nA/summationdisplay
i=1L(Wh,yk)
/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
LA+KBnB
NKB/summationdisplay
k=KA+1nB/summationdisplay
i=1L(Wh,yk)
/bracehtipupleft /bracehtipdownright/bracehtipdownleft /bracehtipupright
LB. (38)
First analyze the loss in the majority class LAand introduce each term in the loss function. Suppose
sampleibelongs to category k, where 1≤k≤KA, i.e.,kis a majority class.
By applying Jensen’s inequalities, we can derive:
−log/parenleftigg
exp(hT
k,iwk)
/summationtextK
k′=1exp(hT
k,iwk′)/parenrightigg
=−hT
k,iwk+ log/parenleftigg
C1exp/parenleftbigghT
k,iwk
C1/parenrightbigg
+C2KA/summationdisplay
k′̸=kexp/parenleftbigghT
k,iwk′
C2/parenrightbigg
+C3K/summationdisplay
k′=KA+1exp/parenleftbigghT
k,iwk′
C3/parenrightbigg/parenrightigg
≥(C1−1)hT
k,iwk+C2KA/summationdisplay
k′̸=khT
k,iwk′+C3K/summationdisplay
k′=KA+1hT
k,iwk′+const
=C0C4/parenleftigg
1
KAKA/summationdisplay
k′=1hT
k,iwk′−hT
k,iwk/parenrightigg
+C0C5/parenleftigg
1
KBK/summationdisplay
k′=KA+1hT
k,iwk′−hT
k,iwk/parenrightigg
+const
=C0C4/parenleftbig
hT
k,iwA−hT
k,iwk/parenrightbig
+C0C5/parenleftbig
hT
k,iwB−hT
k,iwk/parenrightbig
+const.(39)
Here the value of const is −C1logC1−(kA−1)C2logC2−KBC3logC3. Besides, wA=
1
KAKA/summationtext
k′=1wk′andwB=1
KBK/summationtext
k′=KA+1wk′represent the mean values of the weights in majority and
minority classes, respectively.
20To ensure the equality conditions hold, suppose there are three adaptive constants a > 0,
b > 0,c > 0. DenoteC1=a
a+ (KA−1)b+KBc,C2=b
a+ (KA−1)b+KBc, and
C3=c
a+ (KA−1)b+KBc. Additionally, to ensure C4+C5= 1 , introduce a constant
C0=KAb+KBc
a+ (KA−1)b+KBc, thusC4=KAb
KAb+KBcandC5=KBc
KAb+KBc.
After aggregating each term in the loss function, we obtain:
1
KAnAKA/summationdisplay
k=1nA/summationdisplay
i=1L(Wh,yk)
≥1
KAnAKA/summationdisplay
k=1nA/summationdisplay
i=1C4/parenleftig
hT
k,iwA−hT
k,iwk/parenrightig
+C5/parenleftig
hT
k,iwB−hT
k,iwk/parenrightig
+const
=1
KAKA/summationdisplay
k=1hT
k(C4wA+C5wB−wk) +const,(40)
where hk=1
nAnB/summationtext
i=1hk,i.
Subsequently, consider the lower bound of
KA/summationdisplay
k=1hT
k(C4wA+C5wB−wk)≥−C6
2KA/summationdisplay
k=1∥hk∥2−KA/summationdisplay
k=11
2∥C4wA+C5wB−wk∥2/C6.(41)
Note that this inequality (41) is reduced to equality only when the following equality holds:
C4wA+C5wB−wk=C6hk, (42)
where 1≤k≤KA.
Continuing the analysis of inequality (41), the first term on the right-hand side can be bounded as:
Case 1: (Explicit fully connected layers)
−KA/summationdisplay
k=1∥hk∥2=−KA/summationdisplay
k=1∥WEXh0
k∥2
≥−1
2/parenleftigg
KA∥WEX∥F+KA/summationdisplay
k=1∥h0
k∥2/parenrightigg
≥−1
2/parenleftigg
KA∥WEX∥F+KA/summationdisplay
k=11
nknk/summationdisplay
i=1∥h0
k,i∥2/parenrightigg
≥−KAEH.(43)
Case 2: (Deep Equilibrium Models)
−KA/summationdisplay
k=1∥hk∥2=−KA/summationdisplay
k=1/vextenddouble/vextenddouble(I−WDEQ)−1h0
k/vextenddouble/vextenddouble2
≥−1
2
KA∞/summationdisplay
j=0∥WDEQ∥j
F+KA/summationdisplay
k=1∥hk∥2

≥−1
2
KA∞/summationdisplay
j=0Ej
H+KA/summationdisplay
k=11
nknk/summationdisplay
i=1∥hk,i∥2

≥−1
2/parenleftbigg1
1−EH+EH/parenrightbigg
.(44)
21Compared the lower bound of explicit neural network and DEQ, we can find that:
/parenleftigg
−KA/summationdisplay
k=1∥hk∥2/parenrightigg
DEQ</parenleftigg
−KA/summationdisplay
k=1∥hk∥2/parenrightigg
EX
for allEH̸= 1.
We now shift our attention to the second term (Ref. Eq [82-83] in [14]):
−1
KAKA/summationdisplay
k=1∥C4wA+C5wB−wk∥2
=−1
KAKA/summationdisplay
k=1∥wk∥2+2
KAKA/summationdisplay
k=1wT
k(C4wA+C5wB)−∥C4wA+C5wB∥2
=−1
KAKA/summationdisplay
k=1∥wk∥2+ 2C2
5wT
AwB+C4(2−C4)∥wA∥2−C5∥wB∥2
=−1
KAKA/summationdisplay
k=1∥wk∥2+1
KAK/summationdisplay
k=KA+1∥wk∥2+C4(2−C4)/vextenddouble/vextenddouble/vextenddouble/vextenddoublewA+C2
5
C4(2−C4)wB/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
−/parenleftbigg
C2
5+C2
5
C4(2−C4)/parenrightbigg
∥wB∥2
≥−K
KAEW+/parenleftbigg1
KR−C2
5−C4
5
C4(2−C4)/parenrightbigg
∥wB∥2+1
KAK/summationdisplay
k=KA+1∥wk−wB∥2
+C4(2−C4)/vextenddouble/vextenddouble/vextenddouble/vextenddoublewA+C2
5
C4(2−C4)wB/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
,(45)
whereKR=KA/KBdenotes the ratio of the number of majority classes to minority classes.
In summary, the lower bound of loss function (40) could be simplified as:
LA=1
KAnAKA/summationdisplay
k=1nA/summationdisplay
i=1L(Whk,i,yk)
≥1
KAKA/summationdisplay
k=1hT
k(C4wA+C5wB−wk) +const
≥−C6
2KAKA/summationdisplay
k=1∥hk∥2−1
2KAKA/summationdisplay
k=1∥C4wA+C5wB−wk∥2/C6+const
≥C6
2KAM−KEW
2C6KA+1
2C6/parenleftbigg
1
KR−C2
5−C4
5
C4(2−C4)/parenrightbigg
∥wB∥2
+C4(2−C4)
C6/vextenddouble/vextenddouble/vextenddouble/vextenddoublewA+C2
5
C4(2−C4)wB/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
+1
2C6KAK/summationdisplay
k=KA+1∥wk−wB∥2+const,(46)
whereM=−KAEHif the network is a fully connected layer and M=−KA
2/parenleftig
1
1−EH+EH/parenrightig
if
the network is a Deep Equilibrium Model.
22Similarly, the loss function w.r.t the minority classes is bounded as:
LB=1
KBnBKB/summationdisplay
k=1nB/summationdisplay
i=1L(Whk,i,yk)
=1
KBKB/summationdisplay
k=1hT
k(C4wA+C5wB−wk) +const
≥−C6
2KBKB/summationdisplay
k=1∥hk∥2−1
2KBKB/summationdisplay
k=1∥C4wA+C5wB−wk∥2/C6+const
≥C6
2KBM−KEW
2C6KB+1
2C6/parenleftbigg
KR−C2
5−C4
5
C4(2−C4)/parenrightbigg
∥wA∥2
+C5(2−C5)
C6/vextenddouble/vextenddouble/vextenddouble/vextenddoubleC2
4
C5(2−C5)wA+wB/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
+1
2C6KBKA/summationdisplay
k=1∥wk−wA∥2+const.(47)
The inequality reduces to equality when the constraints in Care treated as equalities, achieving the
upper bound. Additionally, the following equalities must hold:
C4wA+C5wB−wk=C6hk, (48)
whereKA+ 1≤k≤K.
IfKR= 1, i.e., the number of majority classes is equal to the number of minority classes, the results
of (46) and (47) are totally equivalent.
Therefore, without loss of generality, assuming KA>KB, the lower bound of the loss function (38)
can be simplified to:
L=LA+LB
≥C6M
2/parenleftig1
KA+1
KB/parenrightig
+1
2C6KBKA/summationdisplay
k=1∥wk−wA∥2+1
2C6KAKB/summationdisplay
k=1∥wk−wB∥2
+C4(2−C4)
2C6/vextenddouble/vextenddouble/vextenddouble/vextenddoublewA+C2
5
C4(2−C4)wB/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
+C5(2−C5)
2C6/vextenddouble/vextenddouble/vextenddouble/vextenddoubleC2
4
C5(2−C5)wA+wB/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
+1
2C6/parenleftbigg
1
KR−C2
5−C4
5
C4(2−C4)/parenrightbigg
∥wB∥2+1
2C6/parenleftbigg
KR−C2
5−C4
5
C4(2−C4)/parenrightbigg
∥wA∥2+const.(49)
C.2NCAnalysis
As analyzed in (43) and (44), when it reaches the minimal value, each hk,i=hkfor∀k=
1,2···,KA. Similarly, this holds for minority class with KA+ 1≤k≤K. This implies that, in an
imbalanced scenario, both DEQ and fully connected layer exhibit feature collapse, i.e., NC1is still
present.
As we need to calculate the lower bound of the loss function, it is essential to minimize the terms
LA+LBas much as possible.
Therefore, consider the gradient with respect to wkfor majority class and wkfor minority class,
respectively. First compute the case with 1≤k≤KA.
∂L
∂wk=1
C6KB/parenleftbigg
1−1
KA/parenrightbigg
(wk−wA) +C4(2−C4)
C6KA/parenleftbigg
wA+C2
5
C4(2−C4)wB/parenrightbigg
+C2
4
KAC6/parenleftbiggC2
4
C5(2−C5)wA+wB/parenrightbigg
+1
KAC6/parenleftbigg
KR−C2
5−C4
5
C4(2−C4)/parenrightbigg
wA= 0.(50)
23So, we can derive that
/parenleftbigg
KR−1
KB/parenrightbigg
wk+1
1−C2
4wB
+/parenleftbigg1
KB+C4(2−C4) +C4
4
C5(2−C5)−C2
5−C2
5
C4(2−C4)/parenrightbigg
wA= 0.(51)
One important note here is that when the proportion of majority class samples approaches infinity,
i.e.,C4→1, we have1
1−C2
4→0. In this scenario, the weights wkbelonging to the majority class
are almost exclusively related to wA, and have little dependence on the average of the minority class
wB, which validates the results of Proposition 4.2.
Similarly, if KA+ 1≤k≤K, the following equality will hold to ensure optimality of wkin
minority classes of (49):
/parenleftbigg1
KR−1
KA/parenrightbigg
wk+1
1−C2
5wA
+/parenleftbigg1
KA+C5(2−C5) +C4
5
C4(2−C4)−C2
4−C2
4
C5(2−C5)/parenrightbigg
wB= 0.(52)
Next, we consider the conditions for the validity in NC2andNC3, then compare the performance of
DEQ and explicit neural network.
Therefore, for the majority class 1≤k≤KA, suppose it reaches its minimum value, recall the
condition (42), and combined with (51), we can derive:
C6hT
khk′=/parenleftbigg
C4+KBCA
KA−1/parenrightbigg
wT
Ahk′+/parenleftbigg
C5+KB
(KA−1)(1−C2
4)/parenrightbigg
wT
Bhk′. (53)
Similarly, for the minority class KA+ 1≤k≤K, combine (48) with (52), we obtain:
C6hT
khk′=/parenleftbigg
C4+KA
(KB−1)(1−C2
5)/parenrightbigg
wT
Ahk′+/parenleftbigg
C5+KACB
KB−1/parenrightbigg
wT
Bhk′. (54)
In the above two equations, k′= 1,2,···,K. And we denote the coefficient of wAin Eq. (51) and
the coefficient of wBin Eq. (52) as CAandCBrespectively for simplicity. After this deviation, we
can find that both of the coefficients of wT
Ahk′andwT
Bhk′are constants.
It can be obviously concluded that NC2andNC3do not hold under imbalanced dataset conditions.
However, we can still compare the numerical differences between them under DEQ and fully
connected layer. By adaptively specifying parameters C4andC5, we can denote (h0
k)Th0
k′=mk,k′.
Thus, by considering all the equality conditions in (46), we can measure the distance from the features
to the Simplex ETF.
C6hT
k′hk=C4hT
k′wA+C5hT
k′wB−hT
k′wk. (55)
Case 1: (Explicit fully connected layers)
C6(h0
k′)Thk=C4WEX(h0
k′)TwA+C5WEX(h0
k′)TwB−WEX(h0
k′)Twk
=WEX/parenleftig
C4hT
k′wA+C5hT
k′wB−hT
k′wk/parenrightig
≤1
2∥WEX∥F+1
2/vextenddouble/vextenddouble/vextenddoubleC4hT
k′wA+C5hT
k′wB−hT
k′wk/vextenddouble/vextenddouble/vextenddouble
=EH+1
2M.(56)
Case 2: (Deep Equilibrium Models)
24C6(h0
k′)Thk=C4(I−WDEQ)−1(h0
k′)TwA+C5(I−WDEQ)−1(h0
k′)TwB
−(I−WDEQ)−1(h0
k′)Twk
= (I−WDEQ)−1/parenleftig
C4hT
k′wA+C5hT
k′wB−hT
k′wk/parenrightig
≤1
2∥(I−WDEQ)−1∥F+1
2/vextenddouble/vextenddouble/vextenddoubleC4hT
k′wA+C5hT
k′wB−hT
k′wk/vextenddouble/vextenddouble/vextenddouble
=1
2(1−EH)+1
2M.(57)
Therefore, to compare these two models, we consider the case when the distance of these two models
from the Simplex ETF is minimized. We denote each element in the Simplex ETF as sijand compare
the differences between them. When the distance of DEQ is relatively smaller than that of explicit
neural network, we can obtain:
/vextendsingle/vextendsingle/vextendsingle/vextendsingle1
2(1−EH)+1
2m−s/vextendsingle/vextendsingle/vextendsingle/vextendsingle</vextendsingle/vextendsingle/vextendsingle/vextendsingle1
2EH+1
2m−s/vextendsingle/vextendsingle/vextendsingle/vextendsingle. (58)
For simplicity, we only consider the subscripts of sandm, and denote 1=1
2(1−EH)+1
2m−s
and 2=1
2EH+1
2m−s. We then classify and discuss their magnitudes.
•1>0,2>0:
Since1
2(1−EH)>EH, there is a contradiction! Therefore, it does not hold.
•1>0,2<0:
1
2(1−EH)+1
2m−s<0,1
2EH+1
2m−s>0, which means1
2(1−EH)<EH. And that is
a contradiction!
•1<0,2>0:
Since1
2(1−EH)+1
2m−s>0,1
2EH+1
2m−s<0, we have
EH<2s−m<1
1−EH.
Besides, by the inequality (58), we have1
2EH+1
2(1−EH)<2s−m. Then find the
intersection, we obtain that:
1
2EH+1
2(1−EH)<2s−m<1
1−EH.
•1<0,2<0:
Since1
2(1−EH)+1
2m−s<0and1
2EH+1
2m−s<0, it implies that1
2(1−EH)>EH
always holds.
Therefore, we only need to ensure that
2s−m>min/braceleftbigg
EH,1
1−EH/bracerightbigg
.
Combining these four cases and finding their intersection, we conclude that when the inequality
EH<2s−m<1
1−EH(59)
is satisfied, the performance of DEQ is better than that of explicit neural network.
As forNC3, consider the cosine distance with the feature hkandwk.
25Case 1: (Explicit fully connected layers)
cos(hk,wk)EX=hT
kwk
∥wk∥∥hk∥
=WEX/parenleftbig
h0
k/parenrightbigTwk
∥wk∥∥WEXh0
k∥
≥2WEX/parenleftbig
h0
k/parenrightbigTwk
∥wk∥2+1
2∥WEX∥2+1
2∥h0
k∥
≥2EH/parenleftbig
h0
k/parenrightbigTwk
EW+EH.(60)
Case 2: (Deep Equilibrium Model)
Very similarly,
cos(hk,wk)DEQ=hT
kwk
∥wk∥∥hk∥
=(I−WDEQ)/parenleftbig
h0
k/parenrightbigTwk
∥wk∥∥(I−WDEQ)−1h0
k∥
≥2 (I−WDEQ)/parenleftbig
h0
k/parenrightbigTwk
∥wk∥2+1
2∥(I−WDEQ)∥2+1
2∥h0
k∥
≥4EH/parenleftbig
h0
k/parenrightbigTwk
1 + 2(EW+EH)(1−EH).(61)
If the performance of DEQ is better than explicit neural network, then we have
cos(hk,wk)DEQ/cos(hk,wk)exp>1,
which is equivalent to
EH
Ew+EH+EH(1−EH)<2. (62)
In summary, though DEQ does not completely mitigate the issue of minority collapse, it shows
significant improvement compared to explicit neural network under some conditions that are relatively
easy to satisfy in the manifestation of the NCphenomenon.
D More experiments
In this section, we provide more experimental results, including the NCphenomena of Explicit NN
and DEQ, and the training results under other imbalanced conditions.
Table 3: Test Accuracy on Cifar-10 and Cifar-100 Dataset with KA= 5
Cifar-10 Cifar-100
R 10 50 100 10 50 100
Explicit NNoverall 80.73±0.48 63.08±0.87 44.86±1.43 52.62±0.86 41.62±0.68 37.33±2.29
majority 94.18±0.56 91.02±0.89 89.32±0.79 74.10±1.03 73.94±0.25 74.24±1.13
minority 67.80±0.35 35.14±0.65 0.40±3.86 31.10±0.70 9.30±1.10 0.42±3.04
DEQoverall 81.36±1.03 65.03±1.90 46.09±1.77 53.31±0.98 44.07±2.04 39.11±2.46
majority 93.14±1.81 90.88±2.83 90.20±0.85 72.90±1.65 75.98±1.75 75.79±0.96
minority 69.58±0.66 39.18±1.46 1.26±4.93 33.72±0.79 12.16±3.75 2.42±5.89
26Table 4: Test Accuracy on Cifar-10 and Cifar-100 Dataset with KA= 7
Cifar-10 Cifar-100
R 10 50 100 10 50 100
Explicit NNoverall 83.17±0.40 66.91±0.39 53.27±0.81 59.11±0.84 51.71±1.02 50.72±0.60
majority 89.09±0.36 80.90±0.57 75.12±0.74 71.93±0.65 72.20±0.66 72.46±0.58
minority 69.37±0.49 34.26±0.30 2.30±1.01 29.20±0.92 3.90±1.29 0.00±0.00
DEQoverall 83.78±1.85 69.47±1.86 56.74±0.98 60.51±0.88 52.99±1.86 51.79±0.92
majority 88.98±1.99 82.91±2.22 78.81±0.67 72.90±1.19 72.99±0.98 73.98±0.66
minority 71.65±1.63 38.12±1.61 5.20±1.91 31.13±0.83 6.33±2.35 0.00±0.00
0 20 40 60 80 100
Epoch2022242628Accuracy
0 20 40 60 80 100
Epoch4
2
0246log1
0 20 40 60 80 100
Epoch0.8250.8500.8750.9000.9252
0 20 40 60 80 100
Epoch0.60.81.01.23
ResNet-18 DEQ
Figure 4: Accuracy and NCphenomenon on imbalanced dataset with KA= 3,KB= 7,R= 100
270 20 40 60 80 100
Epoch304050Accuracy
0 20 40 60 80 100
Epoch2
0246log1
0 20 40 60 80 100
Epoch0.60.70.80.92
0 20 40 60 80 100
Epoch0.40.60.81.01.23
ResNet-18 DEQFigure 5: Accuracy and NCphenomenon on imbalanced dataset with KA= 7,KB= 3,R= 100
281.Claims
Question: Do the main claims made in the abstract and introduction accurately reflect the
paper’s contributions and scope?
Answer: [Yes]
Justification: As stated in the abstract and introduction, this paper is the first to analyze
the representation of the Deep Equilibrium Model from the perspective of Neural Collapse,
accurately reflecting the key contributions and scope.
Guidelines:
•The answer NA means that the abstract and introduction do not include the claims
made in the paper.
•The abstract and/or introduction should clearly state the claims made, including the
contributions made in the paper and important assumptions and limitations. A No or
NA answer to this question will not be perceived well by the reviewers.
•The claims made should match theoretical and experimental results, and reflect how
much the results can be expected to generalize to other settings.
•It is fine to include aspirational goals as motivation as long as it is clear that these goals
are not attained by the paper.
2.Limitations
Question: Does the paper discuss the limitations of the work performed by the authors?
Answer: [Yes]
Justification: The limitation analysis is provided in the Conclusion.
Guidelines:
•The answer NA means that the paper has no limitation while the answer No means that
the paper has limitations, but those are not discussed in the paper.
• The authors are encouraged to create a separate "Limitations" section in their paper.
•The paper should point out any strong assumptions and how robust the results are to
violations of these assumptions (e.g., independence assumptions, noiseless settings,
model well-specification, asymptotic approximations only holding locally). The authors
should reflect on how these assumptions might be violated in practice and what the
implications would be.
•The authors should reflect on the scope of the claims made, e.g., if the approach was
only tested on a few datasets or with a few runs. In general, empirical results often
depend on implicit assumptions, which should be articulated.
•The authors should reflect on the factors that influence the performance of the approach.
For example, a facial recognition algorithm may perform poorly when image resolution
is low or images are taken in low lighting. Or a speech-to-text system might not be
used reliably to provide closed captions for online lectures because it fails to handle
technical jargon.
•The authors should discuss the computational efficiency of the proposed algorithms
and how they scale with dataset size.
•If applicable, the authors should discuss possible limitations of their approach to
address problems of privacy and fairness.
•While the authors might fear that complete honesty about limitations might be used by
reviewers as grounds for rejection, a worse outcome might be that reviewers discover
limitations that aren’t acknowledged in the paper. The authors should use their best
judgment and recognize that individual actions in favor of transparency play an impor-
tant role in developing norms that preserve the integrity of the community. Reviewers
will be specifically instructed to not penalize honesty concerning limitations.
3.Theory Assumptions and Proofs
Question: For each theoretical result, does the paper provide the full set of assumptions and
a complete (and correct) proof?
Answer: [Yes]
29Justification: The assumptions and proofs are provided in appendix B and C.
Guidelines:
• The answer NA means that the paper does not include theoretical results.
•All the theorems, formulas, and proofs in the paper should be numbered and cross-
referenced.
•All assumptions should be clearly stated or referenced in the statement of any theorems.
•The proofs can either appear in the main paper or the supplemental material, but if
they appear in the supplemental material, the authors are encouraged to provide a short
proof sketch to provide intuition.
•Inversely, any informal proof provided in the core of the paper should be complemented
by formal proofs provided in appendix or supplemental material.
• Theorems and Lemmas that the proof relies upon should be properly referenced.
4.Experimental Result Reproducibility
Question: Does the paper fully disclose all the information needed to reproduce the main ex-
perimental results of the paper to the extent that it affects the main claims and/or conclusions
of the paper (regardless of whether the code and data are provided or not)?
Answer: [Yes]
Justification: These details are provided in Section 5.1 - Experiment setup.
Guidelines:
• The answer NA means that the paper does not include experiments.
•If the paper includes experiments, a No answer to this question will not be perceived
well by the reviewers: Making the paper reproducible is important, regardless of
whether the code and data are provided or not.
•If the contribution is a dataset and/or model, the authors should describe the steps taken
to make their results reproducible or verifiable.
•Depending on the contribution, reproducibility can be accomplished in various ways.
For example, if the contribution is a novel architecture, describing the architecture fully
might suffice, or if the contribution is a specific model and empirical evaluation, it may
be necessary to either make it possible for others to replicate the model with the same
dataset, or provide access to the model. In general. releasing code and data is often
one good way to accomplish this, but reproducibility can also be provided via detailed
instructions for how to replicate the results, access to a hosted model (e.g., in the case
of a large language model), releasing of a model checkpoint, or other means that are
appropriate to the research performed.
•While NeurIPS does not require releasing code, the conference does require all submis-
sions to provide some reasonable avenue for reproducibility, which may depend on the
nature of the contribution. For example
(a)If the contribution is primarily a new algorithm, the paper should make it clear how
to reproduce that algorithm.
(b)If the contribution is primarily a new model architecture, the paper should describe
the architecture clearly and fully.
(c)If the contribution is a new model (e.g., a large language model), then there should
either be a way to access this model for reproducing the results or a way to reproduce
the model (e.g., with an open-source dataset or instructions for how to construct
the dataset).
(d)We recognize that reproducibility may be tricky in some cases, in which case
authors are welcome to describe the particular way they provide for reproducibility.
In the case of closed-source models, it may be that access to the model is limited in
some way (e.g., to registered users), but it should be possible for other researchers
to have some path to reproducing or verifying the results.
5.Open access to data and code
Question: Does the paper provide open access to the data and code, with sufficient instruc-
tions to faithfully reproduce the main experimental results, as described in supplemental
material?
30Answer: [Yes]
Justification: We will release the code once the paper is accepted.
Guidelines:
• The answer NA means that paper does not include experiments requiring code.
•Please see the NeurIPS code and data submission guidelines ( https://nips.cc/
public/guides/CodeSubmissionPolicy ) for more details.
•While we encourage the release of code and data, we understand that this might not be
possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not
including code, unless this is central to the contribution (e.g., for a new open-source
benchmark).
•The instructions should contain the exact command and environment needed to run to
reproduce the results. See the NeurIPS code and data submission guidelines ( https:
//nips.cc/public/guides/CodeSubmissionPolicy ) for more details.
•The authors should provide instructions on data access and preparation, including how
to access the raw data, preprocessed data, intermediate data, and generated data, etc.
•The authors should provide scripts to reproduce all experimental results for the new
proposed method and baselines. If only a subset of experiments are reproducible, they
should state which ones are omitted from the script and why.
•At submission time, to preserve anonymity, the authors should release anonymized
versions (if applicable).
•Providing as much information as possible in supplemental material (appended to the
paper) is recommended, but including URLs to data and code is permitted.
6.Experimental Setting/Details
Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
results?
Answer: [Yes]
Justification: These details are provided in Section 5.1 - Experiment setup.
Guidelines:
• The answer NA means that the paper does not include experiments.
•The experimental setting should be presented in the core of the paper to a level of detail
that is necessary to appreciate the results and make sense of them.
•The full details can be provided either with the code, in appendix, or as supplemental
material.
7.Experiment Statistical Significance
Question: Does the paper report error bars suitably and correctly defined or other appropriate
information about the statistical significance of the experiments?
Answer: [Yes]
Justification: The standard deviation in our experimental results (Table 1-4) shows the
statistical significance.
Guidelines:
• The answer NA means that the paper does not include experiments.
•The authors should answer "Yes" if the results are accompanied by error bars, confi-
dence intervals, or statistical significance tests, at least for the experiments that support
the main claims of the paper.
•The factors of variability that the error bars are capturing should be clearly stated (for
example, train/test split, initialization, random drawing of some parameter, or overall
run with given experimental conditions).
•The method for calculating the error bars should be explained (closed form formula,
call to a library function, bootstrap, etc.)
• The assumptions made should be given (e.g., Normally distributed errors).
31•It should be clear whether the error bar is the standard deviation or the standard error
of the mean.
•It is OK to report 1-sigma error bars, but one should state it. The authors should
preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis
of Normality of errors is not verified.
•For asymmetric distributions, the authors should be careful not to show in tables or
figures symmetric error bars that would yield results that are out of range (e.g. negative
error rates).
•If error bars are reported in tables or plots, The authors should explain in the text how
they were calculated and reference the corresponding figures or tables in the text.
8.Experiments Compute Resources
Question: For each experiment, does the paper provide sufficient information on the com-
puter resources (type of compute workers, memory, time of execution) needed to reproduce
the experiments?
Answer: [Yes]
Justification: The computer resources are provided in Section 5.1 - Experiment setup.
Guidelines:
• The answer NA means that the paper does not include experiments.
•The paper should indicate the type of compute workers CPU or GPU, internal cluster,
or cloud provider, including relevant memory and storage.
•The paper should provide the amount of compute required for each of the individual
experimental runs as well as estimate the total compute.
•The paper should disclose whether the full research project required more compute
than the experiments reported in the paper (e.g., preliminary or failed experiments that
didn’t make it into the paper).
9.Code Of Ethics
Question: Does the research conducted in the paper conform, in every respect, with the
NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines ?
Answer: [Yes]
Justification: Our research conformed with the NeurIPS Code of Ethics.
Guidelines:
•The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
•If the authors answer No, they should explain the special circumstances that require a
deviation from the Code of Ethics.
•The authors should make sure to preserve anonymity (e.g., if there is a special consid-
eration due to laws or regulations in their jurisdiction).
10.Broader Impacts
Question: Does the paper discuss both potential positive societal impacts and negative
societal impacts of the work performed?
Answer: [NA]
Justification: Our paper primarily focuses on theoretical research in machine learning,
comparing two typical neural network algorithms, with no relevance to societal impacts.
Guidelines:
• The answer NA means that there is no societal impact of the work performed.
•If the authors answer NA or No, they should explain why their work has no societal
impact or why the paper does not address societal impact.
•Examples of negative societal impacts include potential malicious or unintended uses
(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
(e.g., deployment of technologies that could make decisions that unfairly impact specific
groups), privacy considerations, and security considerations.
32•The conference expects that many papers will be foundational research and not tied
to particular applications, let alone deployments. However, if there is a direct path to
any negative applications, the authors should point it out. For example, it is legitimate
to point out that an improvement in the quality of generative models could be used to
generate deepfakes for disinformation. On the other hand, it is not needed to point out
that a generic algorithm for optimizing neural networks could enable people to train
models that generate Deepfakes faster.
•The authors should consider possible harms that could arise when the technology is
being used as intended and functioning correctly, harms that could arise when the
technology is being used as intended but gives incorrect results, and harms following
from (intentional or unintentional) misuse of the technology.
•If there are negative societal impacts, the authors could also discuss possible mitigation
strategies (e.g., gated release of models, providing defenses in addition to attacks,
mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
feedback over time, improving the efficiency and accessibility of ML).
11.Safeguards
Question: Does the paper describe safeguards that have been put in place for responsible
release of data or models that have a high risk for misuse (e.g., pretrained language models,
image generators, or scraped datasets)?
Answer: [NA]
Justification: Our paper uses standard CIFAR-10 and CIFAR-100 datasets, which do not
involve such issues.
Guidelines:
• The answer NA means that the paper poses no such risks.
•Released models that have a high risk for misuse or dual-use should be released with
necessary safeguards to allow for controlled use of the model, for example by requiring
that users adhere to usage guidelines or restrictions to access the model or implementing
safety filters.
•Datasets that have been scraped from the Internet could pose safety risks. The authors
should describe how they avoided releasing unsafe images.
•We recognize that providing effective safeguards is challenging, and many papers do
not require this, but we encourage authors to take this into account and make a best
faith effort.
12.Licenses for existing assets
Question: Are the creators or original owners of assets (e.g., code, data, models), used in
the paper, properly credited and are the license and terms of use explicitly mentioned and
properly respected?
Answer: [Yes]
Justification: The datasets CIFAR-10 and CIFAR-100 are cited properly. Other assets are
not applied in this paper.
Guidelines:
• The answer NA means that the paper does not use existing assets.
• The authors should cite the original paper that produced the code package or dataset.
•The authors should state which version of the asset is used and, if possible, include a
URL.
• The name of the license (e.g., CC-BY 4.0) should be included for each asset.
•For scraped data from a particular source (e.g., website), the copyright and terms of
service of that source should be provided.
•If assets are released, the license, copyright information, and terms of use in the
package should be provided. For popular datasets, paperswithcode.com/datasets
has curated licenses for some datasets. Their licensing guide can help determine the
license of a dataset.
33•For existing datasets that are re-packaged, both the original license and the license of
the derived asset (if it has changed) should be provided.
•If this information is not available online, the authors are encouraged to reach out to
the asset’s creators.
13.New Assets
Question: Are new assets introduced in the paper well documented and is the documentation
provided alongside the assets?
Answer: [NA]
Justification: This paper does not introduce new assets.
Guidelines:
• The answer NA means that the paper does not release new assets.
•Researchers should communicate the details of the dataset/code/model as part of their
submissions via structured templates. This includes details about training, license,
limitations, etc.
•The paper should discuss whether and how consent was obtained from people whose
asset is used.
•At submission time, remember to anonymize your assets (if applicable). You can either
create an anonymized URL or include an anonymized zip file.
14.Crowdsourcing and Research with Human Subjects
Question: For crowdsourcing experiments and research with human subjects, does the paper
include the full text of instructions given to participants and screenshots, if applicable, as
well as details about compensation (if any)?
Answer: [NA]
Justification: Our paper does not involve crowdsourcing nor research with human subjects.
Guidelines:
•The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
•Including this information in the supplemental material is fine, but if the main contribu-
tion of the paper involves human subjects, then as much detail as possible should be
included in the main paper.
•According to the NeurIPS Code of Ethics, workers involved in data collection, curation,
or other labor should be paid at least the minimum wage in the country of the data
collector.
15.Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
Subjects
Question: Does the paper describe potential risks incurred by study participants, whether
such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
approvals (or an equivalent approval/review based on the requirements of your country or
institution) were obtained?
Answer: [NA]
Justification: Our paper does not involve crowdsourcing nor research with human subjects.
Guidelines:
•The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
•Depending on the country in which research is conducted, IRB approval (or equivalent)
may be required for any human subjects research. If you obtained IRB approval, you
should clearly state this in the paper.
•We recognize that the procedures for this may vary significantly between institutions
and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
guidelines for their institution.
•For initial submissions, do not include any information that would break anonymity (if
applicable), such as the institution conducting the review.
34