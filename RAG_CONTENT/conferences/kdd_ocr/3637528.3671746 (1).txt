Joint Auction in the Online Advertising Market
Zhen Zhang∗
zhangzhen2023@ruc.edu.cn
Gaoling School of Artificial Intelligence,
Renmin University of China
Beijing, ChinaWeian Li∗
weianli927@gmail.com
School of Software,
Shandong University
Jinan, ChinaYahui Lei
leiyahui@meituan.com
Meituan Inc.
Beijing, China
Bingzhe Wang
Zhicheng Zhang
{wbz2022,mzhangzhicheng}@ruc.edu.cn
Gaoling School of Artificial Intelligence,
Renmin University of China
Beijing, ChinaQi Qi†
qi.qi@ruc.edu.cn
Gaoling School of Artificial Intelligence,
Renmin University of China
Beijing, ChinaQiang Liu
Xingxing Wang
{liuqiang43,wangxingxing04}@
meituan.com
Meituan Inc.
Beijing, China
Abstract
Online advertising is a primary source of income for e-commerce
platforms. In the current advertising pattern, the oriented targets
are the online store owners who are willing to pay extra fees to
enhance the position of their stores. On the other hand, brand
suppliers are also desirable to advertise their products in stores to
boost brand sales. However, the currently used advertising mode
cannot satisfy the demand of both stores and brand suppliers si-
multaneously. To address this, we innovatively propose a joint
advertising model termed “Joint Auction”, allowing brand suppliers
and stores to collaboratively bid for advertising slots, catering to
both their needs. However, conventional advertising auction mech-
anisms are not suitable for this novel scenario. In this paper, we
propose JRegNet, a neural network architecture for the optimal
joint auction design, to generate mechanisms that can achieve the
optimal revenue and guarantee (near-)dominant strategy incentive
compatibility and individual rationality. Finally, multiple experi-
ments are conducted on synthetic and real data to demonstrate
that our proposed joint auction significantly improves platform’s
revenue compared to the known baselines.
CCS Concepts
•Applied computing →Online auctions; Online shopping ;•
Computing methodologies →Neural networks.
Keywords
Joint auction, Neural network, JRegNet
∗Both authors contribute equally to this research.
†Corresponding author.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
KDD ’24, August 25–29, 2024, Barcelona, Spain
©2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 979-8-4007-0490-1/24/08
https://doi.org/10.1145/3637528.3671746ACM Reference Format:
Zhen Zhang, Weian Li, Yahui Lei, Bingzhe Wang, Zhicheng Zhang, Qi Qi,
Qiang Liu, and Xingxing Wang. 2024. Joint Auction in the Online Advertising
Market. In Proceedings of the 30th ACM SIGKDD Conference on Knowledge
Discovery and Data Mining (KDD ’24), August 25–29, 2024, Barcelona, Spain.
ACM, New York, NY, USA, 12 pages. https://doi.org/10.1145/3637528.3671746
1 Introduction
Advertising is a primary source of income for internet companies
such as Google, Amazon, and Facebook, bringing in significant
amounts of revenue and supporting the development and prosperity
of the internet. One widely-used method for assigning advertising
positions is sponsored search auction, where advertisers submit bids
to the platform, which then executes preset auction mechanisms to
decide on advertising positions and charged fees. The monetization
efficiency of advertising traffic directly affects the development of
internet companies. How to improve the monetization efficiency of
advertising has become a core research issue for enterprises.
In the context of e-commerce platform as an example, such as
Instacart, when an inquiry arrives, the platform returns a list of
stores that sell the related products (as shown in Figure 1(a)). Stores
can pay extra advertising fees to compete for higher positions in
the list. From the perspective of brand suppliers, they also have a
strong desire to enhance their exposure in order to drive up brand
sales. Nevertheless, the current advertising model does not consider
brand suppliers as advertisers, which causes that the platform may
lose a portion of potential revenue from brand suppliers.
Motivated by this phenomenon and to further increase platform
revenue, we set up a novel online advertisement model called “joint
advertising” catering for the demand of brand suppliers, as shown in
Figure 1(b). In this joint advertising model, both stores and brands
participate in the auction, a sponsored advertising item is con-
tributed by a bundle consisting of a store and a brand supplier, and
we name the auction as “joint auction”. In contrast to the traditional
advertising auction, joint auction not only provides the chance for
brand suppliers to boost brand sales but also enhance the revenue
of platform since it now charges for both stores and brand suppli-
ers. In addition, joint advertising also benefits for users, because
it directly presents the searched products rather than the related
stores. Therefore, the joint advertising scenario essentially aligns
4362
KDD ’24, August 25–29, 2024, Barcelona, Spain Zhen Zhang et al.
View details
 Sparkling Ice 
Peach Zero
(a) Traditional advertising (b) Joint advertisingView all 20 items
JointOcean
Spray
Diet
64 oz
$4.69Sparkling 
Ice Peach 
Zero
17 fl oz
$1.79
Crystal
Light
Pink
10 ct
$4.69
Gatora
de Zero
Lemon
28 fl oz
$3.39
Monster
Energy
Zero
16 oz
$3.29View details Ocean Spray Diet 
Cran Pineapple
64 oz
$4.69
Store
BrandStoreBrand
View all 20+ items
Sparkling 
Ice Peach 
Zero
17 fl oz
$1.69
17 fl oz
$1.69
17 fl oz
$1.79
Sparkling Ice 
Peach ZeroView details
milksugar fr ee drinks Cart · 0Cart · 0 sugar fr ee drinks Cart · 0Cart · 0
Non-participation
in the auctionPlatform
revenue          Platform
revenue                  
Advertising
payment         Advertising
payment        Advertising
payment         
Figure 1: An Example of the Traditional Advertising Model and Joint Advertising Model.
with the vested interests of multiple stakeholders, including plat-
forms, brands, and users, which achieves a triple-win. Joint auction
enriches the practicability of traditional auction theory, potentially
exerting a significant impact in both academia and industry.
However, from the perspective of mechanism design, the new
model of joint auction also brings new technical challenges. For
example, how to overcome the dependency of bundle bids and how
to decide the payments of two parties within a bundle. It leads that
most of the classic and common-used mechanisms may not apply
for the joint advertising. Compared to the difficulties encountered
in theory, in recent years, with the rapid development of machine
learning, the concept of automated mechanism design has been
proposed in computing the optimal mechanism [ 7,8,22]. However,
the current neural network architectures are not suitable for joint
auctions, mainly due to that they do not deal with the allocation of
bundles. Therefore, how to deal with the problem of designing the
optimal joint auctions is deserved to be investigated.
1.1 Main Contributions
The advertising system’s most pivotal technology is its sales mech-
anism. The industry has seen significant maturity in the traditional
advertising auction mechanism, with most studies emphasizing
revenue enhancement through the introduction of innovative vari-
ations to existing frameworks. Our study uniquely presents a prac-
tical and revenue-boosting advertising sales model known as the
“joint auction”. Nonetheless, many standard and widely-used mech-
anisms may not be applicable to this novel joint advertising model.
To identify the optimal mechanisms that are both dominant strat-
egy incentive compatible (DSIC) and individually rational (IR), we
introduce JRegNet, a neural network architecture to generate the
optimal satisfactory mechanisms. Subsequently, we validate our
proposed architecture through numerous experiments on both syn-
thetic and real-world datasets. These experiments demonstrate the
superior performance of the generated mechanisms compared to
established baselines. In summary, our primary contributions are
as follows:
Joint auctions. In this paper, we introduce a novel joint ad-
vertising model that satisfies the marketing requirements of both
stores and brands simultaneously, leading to an increase in revenue.
Within this framework, we present the innovative “joint auction”mechanism, where both stores and brand suppliers submit bids
and compete for advertising slots. A distinct feature of the joint
auction is to display a bundled advertisement consisting of a store
and a brand within a single advertising slot, rather than a single
advertiser. However, not all stores and brands can form such a bun-
dle, as it is based on an established sales relationship. To design
an optimal joint auction, we frame it as a learning problem and
employ automated mechanism design techniques to generate the
optimal mechanism.
JRegNet. To overcome the technical challenges in finding op-
timal joint auctions, we introduce an innovative neural network
architecture called Joint Regret Network (JRegNet). This archi-
tecture leverages the concept of regret to generate mechanisms
that not only adhere to the IR and DSIC conditions but also max-
imize revenue. Importantly, JRegNet is capable of addressing the
unique challenges posed by joint auctions, which are not effec-
tively handled by current popular neural network architectures
(e.g., [7, 11, 22]):
(1)Joint relationship graph. Not all stores and brands can
be combined into bundles, and the joint auction relationship can
vary depending on different search queries within the same auc-
tion scenario. To tackle this issue, JRegNet incorporates the joint
relationship graph of stores and brands as an input. This relation-
ship graph plays a crucial role throughout all stages of JRegNet,
influencing the formation of bundles.
(2)Implementation of bundle constraints. Joint auctions
impose certain constraints on bundles, such as limiting each ad-
vertising slot to a single bundle and vice versa. To address these
constraints, JRegNet initially computes an initial allocation proba-
bility matrix for the bundles. Subsequently, it employs two softmax
functions to ensure compliance with the bundle constraints.
(3)Correlated bids of different bundles. Since the advertising
slot is ultimately allocated to a bundle, from the perspective of
bundles, bids are dependent due to the potential presence of a single
store or brand in multiple bundles. JRegNet deals with the problem
of correlated bids by directly incorporating the independent bids
of each store and brand at the input stage. This approach allows
JRegNet to directly calculate the allocation probabilities of bundles
based on these independent bids, rather than relying on the bids of
bundles themselves within the neural network.
4363Joint Auction in the Online Advertising Market KDD ’24, August 25–29, 2024, Barcelona, Spain
(4)Calculation of separate payment. Determining the pay-
ment for each bidder within a bundle can be a sophisticated problem,
especially when the mechanism assigns a bundle to a specific slot.
To solve this challenge, JRegNet introduces a parameter that scales
the total expected value of each bidder based on the advertiser’s
allocation probability matrix (which is calculated by the bundle’s
allocation probability matrix) and defines the scaled value as the
payment. This parameter is optimized through training, while en-
suring the condition of IR for all bidders.
1.2 Related Work
Traditional auction mechanisms have found extensive application
within the advertising auction domain. The classic Myerson auc-
tion [ 20] endeavors to maximize revenue in the single-parameter
setting, which can apply to sponsored advertising directly. On the
other hand, Vickrey-Clarke-Groves (VCG) mechanism [ 4,13,27]
is engineered to maximize social welfare of advertisers and does
not depend on prior distributions, while keeping IR and DSIC.
In recent two decades, generalized second price (GSP) auction
[2,10,12,19,26] is the most popular mechanism in industry, owing
to its simplicity and comprehensibility. In pursuit of augmenting
revenue of GSP, numerous researchers contribute to studying the
variants of GSP. Lahaie and Pennock [ 17] introduce the concept
of “squashing” to GSP, which assesses bidder rankings using a
compression score during the allocation phase. Thompson and
Leyton-Brown [ 25] integrate the idea of “squashing” and “reserve
price” into GSP. Roberts et al .[23] propose a mechanism that ranks
bidders based on the discrepancy between their bids and the reserve
price. Charles et al .[3] conduct an exhaustive investigation into the
impact of the squashing factor on revenue and CTR. However, as
far as we know, except the VCG mechanism, all the other common
mechanisms may not be applicable to the context of joint auctions
(e.g., difficulty to define the equilibrium of GSP or dependent bids
making Myerson auction invalid). In this paper, we design a novel
mechanism for the joint auctions, while maintaining DSIC and IR,
and yielding the optimal revenue.
With the development of the field of machine learning, the ap-
proach of “automated mechanism design” (AMD) [ 5,6,24] is pro-
posed for auction design, particularly for multi-item auctions. Dif-
ferent from the theoretical methods, AMD focuses more on using
the techniques of machine learning to compute the approximate
optimal auction mechanisms [ 1,9,16]. As a milestone work of AMD,
Dütting et al . [8] model the problem of truthful auction design into
a mathematical programming, transferring DSIC condition into the
constraints on regrets and come up with the first neural network
framework, RegretNet, which can achieve the optimal revenue.
Later, there have been many works that extend RegretNet to handle
different constraints and objectives, such as budget constraints [ 11],
fairness objective [ 15] and human preferences [ 21]. Rahme et al .
[22] propose a permutation-equivariant architecture, Equivariant-
Net, for designing the symmetric auctions. A transformer-based
neural network architecture, CITransNet, catering for the contex-
tual auctions is investigate by Duan et al . [7]. Ivanov et al . [14]
modify the loss function and propose the RegretFormer architec-
ture based on attention layers. Most existing results of AMD are
under the assumptions that one item is allocated to at most onebidder and the bids on different items and from different bidders
are independent, which are not suitable for joint auction, since one
item is assigned to a bundle (consisting of two bidders) and the
bids of different bundles are dependent. Additionally, in the same
joint auction scenario, the joint auction relationship varies across
different search queries, making it difficult for the existing AMD
architecture to be applied to joint auction scenarios. Our proposed
architecture, JRegNet, can overcome these difficulties and generate
the near-optimal revenue in the joint auction.
2 Joint Auction Design
In this section, we first formally introduce the model of joint auction.
Then, we transfer the optimal mechanism design problem into a
learning problem.
2.1 Joint Auction
In the context of joint auctions, whenever a user searches for a
keyword, the platform returns an interface containing 𝐾advertising
slots, where each advertising slot displays the information of an
advertising bundle consisting of a store and a brand. Denote by 𝛼𝑘
the CTR of the 𝑘-th slot for any 𝑘∈{1,...,𝐾}. W.l.o.g., we assume
that1>𝛼1≥···≥𝛼𝐾>0.
There are𝑚stores and𝑛brands participating in a joint auction.
For store𝑖∈𝑀={1,...,𝑚}and brand𝑗∈𝑁={1,...,𝑛}, we
define an indicator, 1𝑖𝑗, to represent whether store 𝑖and brand
𝑗can form a bundle. Specifically, 1𝑖𝑗=1means that store 𝑖and
brand𝑗have a cooperative relationship. Moreover, we use a matrix
to demonstrate the bundle relationship between all stores and all
brands, where each entity is an indicator defined on a pair of store
and brand (see Figure 2 as an example). Within the same joint
auction scenario, the joint auction relationship in the matrix varies
across different search query samples.
Figure 2: The bundle relationship between stores and brands.
We use different beverage icons to represent different brands,
and an edge linking a store and a brand means that there is a
sales relationship between the two.
For each store 𝑖(or brand𝑗), the value for each click is denoted
by𝑣𝑖·(or𝑣·𝑗) which is private information of store 𝑖(or brand𝑗).
Suppose𝑣𝑖·(or𝑣·𝑗) is drawn from a commonly known distribution
over the domain set 𝑉𝑖·(or𝑉·𝑗). The value profile can be expressed
as𝒗=(𝑣1·,...,𝑣𝑚·,𝑣·1,...,𝑣·𝑛)∈V, where V=𝑉1·×···×𝑉𝑚·×
𝑉·1×···×𝑉·𝑛. Additionally, we use 𝒗−𝑖·to stand for the value profile
except for store 𝑖, i.e., 𝒗−𝑖·=(𝑣1·,...,𝑣(𝑖−1)·,𝑣(𝑖+1)·,...,𝑣·𝑛). The
similar notations also can be defined on brand 𝑗. Since the store
(or brand) may have a strategic bidding, we exploit 𝑏𝑖·(or𝑏·𝑗) to
represent the bid price. Similarly, denote 𝒃,𝒃−𝑖·and𝒃·−𝑗by the
related bid profiles.
4364KDD ’24, August 25–29, 2024, Barcelona, Spain Zhen Zhang et al.
In the setting of the joint auction, an auction mechanism, M(𝑔,𝑝),
comprises two parts: the allocation rule 𝑔and payment rule 𝑝. In
detail,𝑔= (𝑔𝑖·)𝑖∈𝑀,(𝑔·𝑗)𝑗∈𝑁where𝑔𝑖·(or𝑔·𝑗):V→R+∪{0}
represents the expected CTR the store 𝑖(or brand𝑗) can derive.
That is,𝑔𝑖·(𝒃)=Í𝐾
𝑘=1𝑠𝑖·𝑘(𝒃)𝛼𝑘, where𝑠𝑖·𝑘(𝒃)indicates the prob-
ability that store 𝑖is assigned to 𝑘-th slot. The payment rule 𝑝= (𝑝𝑖·)𝑖∈𝑀,(𝑝·𝑗)𝑗∈𝑁means that how much the store 𝑖or brand𝑗
needs to charge. Different from the conventional advertising auc-
tions, in a joint auction, each slot can be allocated to at most one
bundle, and each bundle can get at most one slot. In other words,
one store and one brand form a bundle to be displayed in a slot.
Each store𝑖(or brand𝑗) aims to maximize its own utility, which
is defined in a quasi-linear form, i.e., 𝑢𝑖·(𝑣𝑖·;𝒃)=𝑣𝑖·(𝑔𝑖·(𝒃))−
𝑝𝑖·(𝒃), for all𝑖∈𝑀(the utility of brand 𝑗has the similar form).
In this paper, we focus on the mechanisms satisfying dominant
strategy incentive compatibility and individual rationality. Roughly
speaking, dominant strategy incentive compatibility guarantees
that for any bidder, truthful bid can bring the maximum utility, i.e.,
Definition 1 (DSIC). A joint auction is dominant strategy incen-
tive compatible if any store 𝑖’s (or brand 𝑗’s) utility is maximized by
reporting truthfully no matter what the others report. In other words,
it holds that
𝑢𝑖·(𝑣𝑖·;(𝑣𝑖·,𝒃−𝑖·))≥𝑢𝑖·(𝑣𝑖·;(𝑏𝑖·,𝒃−𝑖·)),
for all𝑖∈𝑀,𝑣𝑖·∈𝑉𝑖·,𝑏𝑖·∈𝑉𝑖·,𝒃−𝑖·∈V−𝑖·,and
𝑢·𝑗(𝑣·𝑗;(𝑣·𝑗,𝒃−·𝑗))≥𝑢·𝑗(𝑣·𝑗;(𝑏·𝑗,𝒃−·𝑗)),
for all𝑗∈𝑁,𝑣·𝑗∈𝑉·𝑗,𝑏·𝑗∈𝑉·𝑗,𝒃−·𝑗∈V−·𝑗.
Individual rationality means that any participant of auction can
get a non-negative utility, defined as follows,
Definition 2 (IR). A joint auction is ex-post individually rational
if any store𝑖(or brand𝑗) receives a nonzero utility when participating
truthfully, i.e.,
𝑢𝑖·(𝑣𝑖·;(𝑣𝑖·,𝒃−𝑖·))≥ 0,∀𝑖∈𝑀,∀𝑣𝑖·∈𝑉𝑖·,∀𝒃−𝑖·∈V−𝑖·,
and
𝑢·𝑗(𝑣·𝑗;(𝑣·𝑗,𝒃−·𝑗))≥ 0,∀𝑗∈𝑁,∀𝑣·𝑗∈𝑉·𝑗,∀𝒃−·𝑗∈V−·𝑗.
In a joint auction which is DSIC and IR, the expected revenue
of platform is equal to the total payment of all stores and brands,
defined as
𝑟𝑒𝑣:=E𝒗∼𝐹𝑚∑︁
𝑖=1𝑝𝑖·(𝒗)+𝑛∑︁
𝑗=1𝑝·𝑗(𝒗)
,
where𝐹is the joint distribution of all stores’ and brands’ values.
Optimal joint auction design aims to find an auction mechanism
that maximizes the expected revenue while satisfying the DSIC and
IR conditions.
2.2 Joint Auction Design as a Learning Problem
We formulate the problem of designing the optimal joint auction as a
learning problem. First, to satisfy the DSIC condition, we introduce
the concept of ex-post regret. Fixed others’ bids, the ex-post regret
for store𝑖(similar definition for brand 𝑗) is the highest increase on
utility that she can obtain by misreporting, i.e.,
𝑟𝑔𝑡𝑖·(𝒗)=E𝑣∼𝐹[max
𝑣′
𝑖·∈𝑉𝑖·𝑢𝑖·(𝑣𝑖·;(𝑣′
𝑖·,𝒗−𝑖·))−𝑢𝑖·(𝑣𝑖·;𝒗)].Thus, an auction mechanism satisfies the DSIC condition if and
only if𝑟𝑔𝑡𝑖·(𝒗)=0and𝑟𝑔𝑡·𝑗(𝒗)=0are fulfilled, for all stores and
brands. Moreover, we can formulate the problem of designing the
optimal joint auction as a constrained optimization:
min
(𝑔,𝑝)∈M−E𝑣∼𝐹[𝑚∑︁
𝑖=1𝑝𝑖·(𝒗)+𝑛∑︁
𝑗=1𝑝𝑗(𝒗)] (1)
s.t.𝑟𝑔𝑡𝑖·(𝒗)=0, 𝑖=1,...,𝑚,
𝑟𝑔𝑡·𝑗(𝒗)=0, 𝑗=1,...,𝑛 .
whereMis the set of all joint auction mechanisms that satisfy
IR. Due to the complex constraints, this optimization is generally
intractable to solve [ 5,6]. To solve this optimization problem, we
parameterize the auction mechanisms as M𝑤(𝑔𝑤,𝑝𝑤)⊆M(𝑔,𝑝)
through parameter 𝑤∈R𝑑(where𝑑is the dimension of parameters
𝑤). Then, we move to compute the mechanism M𝑤(𝑔𝑤,𝑝𝑤)which
maximizes the expected revenue: E𝑣∼𝐹[Í𝑚
𝑖=1𝑝𝑤
𝑖·(𝒗)+Í𝑛
𝑗=1𝑝𝑤
·𝑗(𝒗)]
and satisfies DSIC and IR, by optimizing the parameters 𝑤.
Given a sampleL, consisting of 𝐿value profiles drawn from the
joint distribution 𝐹, the empirical ex-post regret of store 𝑖(similar
notation for brand 𝑗) for the mechanism M𝑤(𝑔𝑤,𝑝𝑤)is estimated
by:
c𝑟𝑔𝑡𝑖·(𝑤)=1
𝐿𝐿∑︁
𝑙=1[max
𝑣′
𝑖·∈𝑉𝑖·𝑢𝑤
𝑖·(𝑣(𝑙)
𝑖·;(𝑣′
𝑖·,𝒗(𝑙)
−𝑖·))
−𝑢𝑤
𝑖·(𝑣(𝑙)
𝑖·;𝒗(𝑙))]. (2)
Rewrite the constrained optimization (1) into:
min
𝑤∈R𝑑𝑤−1
𝐿𝐿∑︁
𝑙=1[𝑚∑︁
𝑖=1𝑝𝑤
𝑖·(𝒗(𝑙))+𝑛∑︁
𝑗=1𝑝𝑤
·𝑗(𝒗(𝑙))] (3)
s.t.c𝑟𝑔𝑡𝑖·(𝑤)=0, 𝑖=1,...,𝑚,
c𝑟𝑔𝑡·𝑗(𝑤)=0, 𝑗=1,...,𝑛 .
In addition, through the network architecture, we ensure the IR
condition and we will describe it in detail in Section 3.1.
3 JRegNet
In this section, after modeling the optimal joint auction design
as a learning problem, we propose a neural network architecture
called Joint Regret Network (JRegNet) for the optimal joint auction
design.
3.1 The JRegNet Architecture
In this subsection, we introduce the network architecture of JReg-
Net designed for joint auction settings, as shown in Figure 3. The
JRegNet architecture consists of two parts: the allocation network
encoding allocation rules and the payment network encoding pay-
ment rules. The outputs of both networks are used to calculate the
utility of bidders, the revenue, the regret, and the loss function value
of the entire network. Next, we introduce the main components of
JRegNet in detail.
Input and output of JRegNet. In JRegNet, the neural network
takes 1𝑖𝑗,𝑒𝑖·𝑘and𝑒·𝑗𝑘as inputs, defined as:
𝑒𝑖·𝑘=𝛼𝑘𝑏𝑖·,∀𝑖∈𝑀,∀𝑘∈{1,...,𝐾},
𝑒·𝑗𝑘=𝛼𝑘𝑏·𝑗,∀𝑗∈𝑁,∀𝑘∈{1,...,𝐾},(4)
4365Joint Auction in the Online Advertising Market KDD ’24, August 25–29, 2024, Barcelona, Spain
'  
reshape 
  
 
   
 
 
  
  
  
  
 
 
  
 
 
   
   
  
 
 reshape
 Store bidders
Brand biddersAdvertising slots
  Getting the input of JRegNet Input layer
Computing the allocation probability matrix A of bundles Hidden layer
Conversion of A to SAllocation  Network
Payment  Network
Input layer Hidden layer Output layer
Computing the payment matrix POutput layer
  
  OutputOutput
C
R 
 
Joint relationship
graph
Joint relationship
graph
Figure 3: The JRegNet architecture, including the allocation network part and the payment network part, for a setting of 𝑚
stores,𝑛brands,𝐾advertising slots, and 𝑄bundles of stores and brands.
where𝑒𝑖·𝑘and𝑒·𝑗𝑘represent the expected bid for store 𝑖and brand
𝑗on slot𝑘, respectively.{1𝑖𝑗}𝑖∈𝑀,𝑗∈𝑁represents the joint rela-
tionship matrix between stores and brands. Because the joint rela-
tionship varies across different search request samples, even under
the same joint auction scenario (i.e., the same stores and brands),
JRegNet takes{1𝑖𝑗}𝑖∈𝑀,𝑗∈𝑁as one of the inputs. In JRegNet, to
adapt to the joint auction settings, the allocation network firstly
outputs the allocation probability matrix 𝐴of bundles. Matrix 𝐴
contains the allocation probabilities for each bundle consisting of
a store and a brand on each advertising slot. After obtaining the
matrix𝐴, the allocation network then outputs the corresponding
allocation probability matrix 𝑆of bidders. Matrix 𝑆contains the
allocation probabilities for each store and brand on each advertising
slot. Afterwards, the payment network outputs the payment matrix
𝑃of all bidders. Matrix 𝑃contains the payments of each store bidder
and brand bidder.
Computing the allocation probability matrix 𝐴of bun-
dles. To calculate the allocation probability matrix 𝑆of bidders,
we need to firstly calculate the allocation probability matrix 𝐴of
bundles, because we need to implement several constraints through
𝐴. And then, 𝑆is computed based on 𝐴. Besides, matrix 𝐴can be
used to allocate advertising slots to bundles consisting of stores
and brands. The input for this part is matrices 𝐶and𝑅obtained
through forward propagation, as shown by the yellow and purple
neurons in Figure 3. We use 𝑄to represent the total number of
bundles, where bundle 𝑞∈{1,...,𝑄}corresponds to a row-by-row
traversal of all the entries in the matrix consisting of 1𝑖𝑗, with the
bundle corresponding to the 𝑞-th entry with value 1. The alloca-
tion probability of bundle 𝑞on slot𝑘in the allocation probability
matrix𝐴is defined as 𝑎𝑞𝑘. In our model, the output matrix 𝐴mustsatisfy two constraints: (a), each advertising slot can only be as-
signed to one bundle, i.e.,Í𝑄
𝑞=1𝑎𝑞𝑘≤1,∀𝑘∈{1,...,𝐾}, and (b),
each bundle can be assigned to at most one advertising slot, i.e.,Í𝐾
𝑘=1𝑎𝑞𝑘≤1,∀𝑞∈{1,...,𝑄}. We enforce constraints (a) and (b)
by designing the allocation probability matrix 𝐴as a bi-stochastic
matrix. To construct 𝐴as a bi-stochastic matrix, some operations
are required on 𝐶and𝑅. The matrix 𝐶is column-normalized to
matrix ˜𝐶and the matrix 𝑅is row-normalized to matrix ˜𝑅, where
the normalization is achieved by the softmax function. Because in
joint auction settings, a specific bundle consisting of a store and
a brand may not be assigned to any advertising slot, we include a
dummy neuron for each bundle in the normalization of the softmax
function. The outputs of dummy neurons represent the probabilities
of bundles not being assigned any advertising slot. The entries in
matrices ˜𝐶and ˜𝑅are defined as ˜𝑐𝑞𝑘and˜𝑟𝑞𝑘, respectively. Then, we
compute allocation probability of each bundle in the matrix 𝐴by:
𝑎𝑞𝑘=min{˜𝑐𝑞𝑘,˜𝑟𝑞𝑘},∀𝑞∈{1,...,𝑄},∀𝑘∈{1,...,𝐾+1}. According
to Lemma 1, the matrix 𝐴constructed in this way is a bi-stochastic
matrix. The specific formula for computing the allocation probabil-
ity matrix𝐴is:
𝑎𝑞𝑘=𝜑𝐵𝑆
𝑞𝑘(𝐶,𝑅)=min(
𝑒𝑐𝑞𝑘
Í𝑄
𝑡=1𝑒𝑐𝑡𝑘,𝑒𝑟𝑞𝑘
Í𝐾+1
𝑡=1𝑒𝑟𝑞𝑡)
,
where𝑒𝑐𝑞𝑘
Í𝑄
𝑡=1𝑒𝑐𝑡𝑘and𝑒𝑟𝑞𝑘Í𝐾+1
𝑡=1𝑒𝑟𝑞𝑡are the row normalization of 𝑐𝑞𝑘and
the column normalization of 𝑟𝑞𝑘, respectively, and the index 𝐾+1
corresponds to the situation where the bundle is not allocated any
advertising slot. This part can be found in Figure 3.
4366KDD ’24, August 25–29, 2024, Barcelona, Spain Zhen Zhang et al.
Lemma 1 ([ 8]).The matrix𝜑𝐵𝑆
𝑞𝑘(𝑐,𝑟)is bi-stochastic∀𝑐,𝑟∈R𝑄𝐾.
For any bi-stochastic matrix 𝑎∈[0,1]𝑄𝐾,∃𝑐,𝑟∈R𝑄𝐾for which
𝑎=𝜑𝐵𝑆
𝑞𝑘(𝑐,𝑟).
Conversion of allocation probability matrix 𝐴to allocation
probability matrix 𝑆.In allocation probability matrix 𝑆of bidders,
the allocation probabilities of store 𝑖and brand𝑗on slot𝑘are
denoted as𝑠𝑖·𝑘and𝑠·𝑗𝑘, respectively. After obtaining the allocation
probability matrix 𝐴of bundles, the allocation probabilities in 𝑆are
computed through:
𝑠𝑖·𝑘=Í
𝑞∈𝑄𝑖·𝑎𝑞𝑘,∀𝑘∈{1,...,𝐾},
𝑠·𝑗𝑘=Í
𝑞∈𝑄·𝑗𝑎𝑞𝑘,∀𝑘∈{1,...,𝐾},
where𝑄𝑖·and𝑄·𝑗denote the sets of all bundles that include store
𝑖and brand𝑗, respectively, i.e., the allocation probability of store 𝑖
on slot𝑘is the sum of the allocation probabilities on slot 𝑘for all
bundles that include store 𝑖and the calculation of the allocation
probability of brand 𝑗on slot𝑘is similar to this.
Computing the payment matrix 𝑃.After obtaining the alloca-
tion probability matrix 𝑆of bidders, we propagate it to the payment
network to calculate the payment matrix 𝑃, as shown in Figure 3. In
the matrix𝑃∈𝑅𝐼+𝐽
≥0, the first𝑚rows and the last 𝑛rows represent
the payments for stores and brands, respectively. The payments
of store𝑖and brand𝑗in𝑃are denoted as 𝑝𝑖·and𝑝·𝑗, respectively.
The payments in 𝑃are computed through:
 
𝑝𝑖·=˜𝑝𝑖·Í𝐾
𝑘=1𝑠𝑖·𝑘𝑒𝑖·𝑘
,∀𝑖∈𝑀,
𝑝·𝑗=˜𝑝·𝑗Í𝐾
𝑘=1𝑠·𝑗𝑘𝑒·𝑗𝑘
,∀𝑗∈𝑁.
where ˜𝑝𝑖·∈[0,1]and ˜𝑝·𝑗∈[0,1]are the normalization factors
calculated by the sigmoid function, as shown by the green squares
in Figure 3. Under the condition of satisfying DSIC, because of
˜𝑝𝑖·∈[0,1], and the utility of the store 𝑢𝑖·=Í𝐾
𝑘=1𝑠𝑖·𝑘𝑒𝑖·𝑘−𝑝𝑖·, the
utility of each store must be greater than or equal to zero, satisfying
IR. The proof of IR for brand is similar.
3.2 Training of JRegNet
In this subsection, we introduce the training process of JRegNet,
which includes converting the objective function, dividing training
samples, finding the optimal misreports, and updating the model
parameters and the Lagrange multipliers.
Conversion from constrained optimization problems to
unconstrained optimization problems. In order to train JRegNet,
we firstly need an objective function. The constrained optimization
objective is shown in (3). We use the augmented Lagrangian method
over the space of the neural network parameters 𝑤to transform
the constrained optimization problem into an unconstrained opti-
mization problem, so that we can obtain the following objectivefunction:
C𝜌(𝑤;𝝀)=−1
𝐿𝐿∑︁
ℓ=1𝑚∑︁
𝑖=1𝑝𝑤
𝑖·
𝒗(ℓ)
+𝑛∑︁
𝑗=1𝑝𝑤
·𝑗
𝒗(ℓ)
+𝑚∑︁
𝑖=1𝜆𝑖·c𝑟𝑔𝑡𝑖·(𝑤)+𝑛∑︁
𝑗=1𝜆·𝑗c𝑟𝑔𝑡·𝑗(𝑤)
+𝜌
2𝑚∑︁
𝑖=1(c𝑟𝑔𝑡𝑖·(𝑤))2+𝜌
2𝑛∑︁
𝑗=1(c𝑟𝑔𝑡·𝑗(𝑤))2,
where 𝝀∈R𝑛is the Lagrange multiplier and 𝜌>0is the penalty
factor.
After obtaining the objective function required for training, we
need to divide the samples in order to train JRegNet.
Division of training samples. The training sample Lis ran-
domly divided into minibatches of size 𝐵. We use𝑇to represent
the total number of iterations. For each iteration 𝑡∈{1,...,𝑇}, we
sample a minibatch L𝑡, which is denoted by L𝑡={𝑣(1),...,𝑣(𝐵)}
and input it into JRegNet for training, until all the minibatches in
this partition have been used. Afterwards, the training samples L
are randomly partitioned again into new minibatches of size 𝐵. The
above process is repeated until all iterations have been completed.
Afterwards, during training, to calculate the regret in C𝜌(𝑤;𝝀),
we need to find the optimal misreports that maximize the regret.
Finding the optimal misreports. To calculate the optimal mis-
reports, we use the method of gradient ascent. For each minibatch,
the misreport 𝑣′(ℓ)
𝑖·or𝑣′(ℓ)
·𝑗is calculated, for each store 𝑖or brand𝑗
and each valuation profile ℓ, by taking multiple gradient ascents,
and all the misreports are maintained to initialize the misreports in
the next epoch. The formula for gradient ascent is as follows:
 
𝑣′(ℓ)
𝑖·=𝑣′(ℓ)
𝑖·+𝛾∇𝑣′
𝑖·h
𝑢𝑤
𝑖·
𝑣(ℓ)
𝑖·;
𝑣′
𝑖·,𝒗(ℓ)
−𝑖·i𝑣′
𝑖·=𝑣′(ℓ)
𝑖·,
𝑣′(ℓ)
·𝑗=𝑣′(ℓ)
·𝑗+𝛾∇𝑣′
·𝑗h
𝑢𝑤
·𝑗
𝑣(ℓ)
·𝑗;
𝑣′
·𝑗,𝒗(ℓ)
−·𝑗i𝑣′
·𝑗=𝑣′(ℓ)
·𝑗,
for some𝛾>0.
Updating the model parameters and the Lagrange multipli-
ers.Afterwards, we can calculate the value of 𝐶𝜌(𝑤;𝝀)to perform
backpropagation and update the neural network parameters 𝑤to
minimize𝐶𝜌(𝑤;𝝀). In addition, during the training process of the
model, the update of the Lagrange multipliers is performed every
fixed number of iterations:
𝜆𝑡+1
𝑖·=𝜆𝑡
𝑖·+𝜌𝑡f𝑟𝑔𝑡𝑖· 𝑤𝑡+1,∀𝑖∈𝑀,
𝜆𝑡+1
·𝑗=𝜆𝑡
·𝑗+𝜌𝑡f𝑟𝑔𝑡·𝑗 𝑤𝑡+1,∀𝑗∈𝑁,
where𝑡represents the number of iterations, and f𝑟𝑔𝑡𝑖·(𝑤)and
f𝑟𝑔𝑡·𝑗(𝑤)represents the empirical regret calculated on the mini-
batch𝑆𝑡based on (2). The updates of the model parameters and
the Lagrange multipliers are performed alternately. The specific
and complete algorithm process of training JRegNet is shown in
Algorithm 1.
For fixed 𝝀𝑡, the gradient of 𝐶𝜌w.r.t.𝑤can be written as:
4367Joint Auction in the Online Advertising Market KDD ’24, August 25–29, 2024, Barcelona, Spain
Algorithm 1 JRegNet Training
1:Input: MinibatchesL1,...,L𝑇of size B
2:Parameters:∀𝑡∈{1,...,𝑇},𝜌𝑡>0,𝛾>0,𝜂>0,Γ∈N,𝑇∈
N,𝐻∈N
3:Initialize:𝑤0∈R𝑑,𝜆0∈R𝑚+𝑛
4:for𝑡=0to𝑇do
5: Receive minibatch L𝑡={𝑣(1),...,𝑣(𝐵)}
6: Initialize misreport 𝑣′(ℓ)
𝑖·∈𝑉𝑖·,𝑣′(ℓ)
·𝑗∈𝑉·𝑗,∀ℓ∈
{1,...,𝐵},𝑖∈𝑀,𝑗∈𝑁
7: for𝑟=0toΓdo
8:∀ℓ∈{1,...,𝐵},𝑖∈𝑀,𝑗∈𝑁:
9:𝑣′(ℓ)
𝑖·=𝑣′(ℓ)
𝑖·+𝛾∇𝑣′
𝑖·h
𝑢𝑤
𝑖·
𝑣(ℓ)
𝑖·;
𝑣′
𝑖·,𝒗(ℓ)
−𝑖·i𝑣′
𝑖·=𝑣′(ℓ)
𝑖·
10:𝑣′(ℓ)
·𝑗=𝑣′(ℓ)
·𝑗+𝛾∇𝑣′
·𝑗h
𝑢𝑤
·𝑗
𝑣(ℓ)
·𝑗;
𝑣′
·𝑗,𝒗(ℓ)
−·𝑗i𝑣′
·𝑗=𝑣′(ℓ)
·𝑗
11: end for
12: Compute regret gradient: ∀ℓ∈[𝐵],𝑖∈𝑀,𝑗∈𝑁:
13:𝑔𝑡
ℓ,𝑖·=∇𝑤h
𝑢𝑤
𝑖·
𝑣(ℓ)
𝑖·;
𝑣′(ℓ)
𝑖·,𝒗(ℓ)
−𝑖·
−𝑢𝑤
𝑖·
𝑣(ℓ)
𝑖·;𝒗(ℓ)i𝑤=𝑤𝑡
14:𝑔𝑡
ℓ,·𝑗=∇𝑤h
𝑢𝑤
·𝑗
𝑣(ℓ)
·𝑗;
𝑣′(ℓ)
·𝑗,𝒗(ℓ)
−·𝑗
−𝑢𝑤
·𝑗
𝑣(ℓ)
·𝑗;𝒗(ℓ)i𝑤=𝑤𝑡
15: Compute Lagrangian gradient using (8) and update 𝑤𝑡:
16:𝑤𝑡+1←𝑤𝑡−.𝜂∇𝑤C𝜌𝑡 𝑤𝑡,𝜆𝑡
17: Update Lagrange multipliers once in 𝐻iterations:
18: if𝑡is a multiple of 𝐻then
19: 𝜆𝑡+1
𝑖·←𝜆𝑡
𝑖·+𝜌𝑡f𝑟𝑔𝑡𝑖· 𝑤𝑡+1,∀𝑖∈𝑀
20: 𝜆𝑡+1
·𝑗←𝜆𝑡
·𝑗+𝜌𝑡f𝑟𝑔𝑡·𝑗 𝑤𝑡+1,∀𝑗∈𝑁
21: else
22: 𝝀𝑡+1←𝝀𝑡
23: end if
24:end for
∇𝑤C𝜌 𝑤;𝝀𝑡=−1
𝐵𝐵∑︁
ℓ=1𝑚∑︁
𝑖=1∇𝑤𝑝𝑤
𝑖·
𝒗(ℓ)
+𝑛∑︁
𝑗=1∇𝑤𝑝𝑤
·𝑗
𝒗(ℓ)
+𝐵∑︁
ℓ=1𝑚∑︁
𝑖=1𝜆𝑡
𝑖·𝑔ℓ,𝑖·+𝑛∑︁
𝑗=1𝜆𝑡
·𝑗𝑔ℓ,·𝑗
+𝜌𝐵∑︁
ℓ=1𝑚∑︁
𝑖=1f𝑟𝑔𝑡𝑖·(𝑤)𝑔ℓ,𝑖·+𝑛∑︁
𝑗=1f𝑟𝑔𝑡·𝑗(𝑤)𝑔ℓ,·𝑗,
where
 
𝑔ℓ,𝑖·=∇𝑤h
max𝑣′
𝑖·∈𝑉𝑖·𝑢𝑤
𝑖·
𝑣(ℓ)
𝑖·;
𝑣′
𝑖·,𝒗(ℓ)
−𝑖·
−𝑢𝑤
𝑖·
𝑣(ℓ)
𝑖·;𝒗(ℓ)i
,
𝑔ℓ,·𝑗=∇𝑤h
max𝑣′
·𝑗∈𝑉·𝑗𝑢𝑤
·𝑗
𝑣(ℓ)
·𝑗;
𝑣′
·𝑗,𝒗(ℓ)
−·𝑗
−𝑢𝑤
·𝑗
𝑣(ℓ)
·𝑗;𝒗(ℓ)i
.
4 Experiments
In this section, empirical experiments are conducted in order to
evaluate the joint advertising model and the effectiveness of JReg-
Net. Our experiments are run on a compute cluster with NVIDIA
Graphics Processing Unit (GPU) cores.Baseline methods. We compare JRegNet with the following
baselines:
•RegretNet [8], a neural network architecture for near DSIC
mechanism design in the traditional advertising auction set-
tings (only include stroes) which can achieve the optimal
revenue.
•Independent Regret Network (IRegNet), a neural network
architecture for the optimal mechanism design in the ad-
vertising auction settings, where both stores and brands are
independent candidates, competing for different slots. I.e.,
each slot either displays a store advertising or a brand ad-
vertising (this scenario does not exist in reality).
•VCG [ 4,13,27], a classic mechanism satisfying DSIC and IR.
In our experiments, we apply VCG mechanism to the joint
advertising settings directly.
Note that, while implementing the RegretNet, the bidders are
only the stores. For other mechanisms, the bidders are both stores
and brands. Other attributes for all mechanisms are the same.
Evaluation. To assess the performance of each method, we
utilize the average empirical ex-post regret of all bidders: c𝑟𝑔𝑡:=
1
𝑛+𝑚(Í𝑚
𝑖=1c𝑟𝑔𝑡𝑖·+Í𝑛
𝑗=1c𝑟𝑔𝑡·𝑗), the empirical revenue: 𝑟𝑒𝑣:=1
𝐿Í𝐿
ℓ=1hÍ𝑚
𝑖=1𝑝𝑤
𝑖·
𝑣(ℓ)
+Í𝑛
𝑗=1𝑝𝑤
·𝑗
𝑣(ℓ)i
and the empirical social wel-
fare:𝑠𝑤:=1
𝐿Í𝐿
ℓ=1Í𝑚
𝑖=1Í𝐾
𝑘=1𝑠(ℓ)
𝑖·𝑘𝛼𝑘𝑣(ℓ)
𝑖·+Í𝑛
𝑗=1Í𝑘
𝑘=1𝑠(ℓ)
·𝑗𝑘𝛼𝑘𝑣(ℓ)
·𝑗
.
4.1 Synthetic Data
Implementation details. We create training sets and the test sets
for each experiment. In the training sets, the size 𝐵of minibatches
is128and the numbers of minibatches and iterations are 5000 and
200000, respectively. In the test sets, the size of minibatches is 128
and the number of minibatches is 100. Thus, the size of the training
sampleLis640000 and the size of the testing sample is 12800.
In all synthetic data experiments, the joint relationship matrix
{1𝑖𝑗}𝑖∈𝑀,𝑗∈𝑁between stores and brands is randomly generated for
each search request sample. Furthermore, within a search request
sample, if a store (or brand) has no joint relationship with any brand
(or store), we default its bid to be zero, since such stores (or brands)
cannot form a bundle to be displayed.
In the testing of JRegNet, for each bidder, we perform gradient
ascent on the 100different initial misreports for 2000 iterations, to
obtain 100empirical regrets. Then, we take the maximum value of
these 100empirical regrets as the empirical regret of this bidder.
All experimental results of RegretNet, IRegNet and JRegNet are
obtained by taking the average of 3different runs on the testing
samples.
The comparison between JRegNet and the baselines. To
demonstrate the superiority of the joint advertising model and
the effectiveness of JRegNet, we conduct comparative experiments
between mechanism generated by JRegNet and baselines in the
following settings:
(A)3stores, 4brands and 1advertising slot with CTR 𝜶=(0.7).
The value of each store and brand is independently drawn
from𝑈[0,1].
(B)3stores, 5brands and 3advertising slots with CTRs 𝜶=
(0.5,0.3,0.15). The value of each store and brand is indepen-
dently drawn from 𝑈[0,1].
4368KDD ’24, August 25–29, 2024, Barcelona, Spain Zhen Zhang et al.
MethodA: 3×4×1
rev sw rgtB: 3×5×3
rev sw rgtC: 3×5×5
rev sw rgtD: 4×5×3
rev sw rgt
RegretNet 0.305 0.453 <0.001 0.298 0.399 <0.001 0.302 0.403 <0.001 0.370 0.488 <0.001
IRegNet 0.469 0.540 <0.001 0.536 0.651 <0.001 0.551 0.680 <0.001 0.583 0.690 <0.001
VCG 0.433 0.908− 0.445 1.154− 0.400 1.256− 0.602 1.232−
JRegNet 0.509†0.741 <0.001 0.641†0.955 <0.001 0.660†1.007 <0.001 0.676†1.005 <0.001
Table 1: The results of experiments for Settings A to D. “ †” indicates that the revenue has a significant improvement over other
methods in paired t-test at 𝑝<0.05level.
MethodUniform Normal Lognormal
rev sw rgt rev sw rgt rev sw rgt
RegretNet 0.298 0.399 <0.001 0.307 0.412 <0.001 0.276 0.390 <0.001
IRegNet 0.536 0.651 <0.001 0.496 0.583 <0.001 0.501 0.626 <0.001
VCG 0.445 1.154− 0.492 1.045− 0.433 1.099−
JRegNet 0.641†0.955 <0.001 0.674†0.949 <0.001 0.612†0.945 <0.001
Table 2: The results of experiments for different value distributions. The setting is 3stores and 5brands with 3advertising slots.
“†” indicates that the revenue has a significant improvement over other methods in paired t-test at 𝑝<0.05level.
MethodE1
rev sw ruE2
rev sw ruE3
rev sw ru
VCG 28.641 51.172− 23.931 59.340− 28.262 58.257−
JRegNet40.666†48.510 0.020 45.874†56.193 0.015 45.920†55.502 0.015
43.329†49.066 0.445 49.005†57.070 0.402 48.867†56.421 0.868
GSP 40.764 51.172 1.117 44.206 59.340 1.083 44.765 58.257 1.039
Table 3: The results of experiments for real data on the test set. In experiments E1 to E3, we train JRegNet using the data from
Figures 5(a) to 5(c) respectively, and test JRegNet and the baseline methods using the corresponding data in Figure 6. There are
two groups of experimental data in JRegNet section, where the first row with a very small 𝑟𝑢is compared with VCG, and the
second row is used for comparison with GSP. “ †” indicates that the revenue has a significant improvement over other methods
in paired t-test at 𝑝<0.05level.
(C)3stores, 5brands and 5advertising slots with CTRs 𝜶=
(0.5,0.3,0.15,0.1,0.03). The value of each store and brand is
independently drawn from 𝑈[0,1].
(D)4stores, 5brands and 3advertising slots with CTRs 𝜶=
(0.5,0.3,0.15). The value of each store and brand is indepen-
dently drawn from 𝑈[0,1].
We show the results of experiments under Settings A to D in
Table 1. First, regarding to all mechanisms generated by the methods
of automated mechanism design, the mechanisms generated by
JRegNet achieve a significantly higher revenue, compared to the
mechanisms generated by RegretNet and IRegNet, when the regret
is less than 0.001. This demonstrates that the joint advertising model
can derive more revenue than the traditional model. Additionally,
as shown in Table 1, if we focus on the joint advertising settings,
we can find that JRegNet can also obtain a significantly higher
revenue than VCG, despite experiencing a measure of social welfare
loss. It implies, for revenue, the good performance of mechanisms
generated by JRegNet and the effectiveness of JRegNet.
To further evaluate the joint advertising model and the perfor-
mance of JRegNet, we execute the experiments under the settingwith different distributions, CTRs and numbers of advertisement
slots.
Different value distributions. To verify the performance and
stability of our proposed mechanism under different value distri-
butions, we repeat experiments in three different value distribu-
tions on setting B. The value of each store and brand is indepen-
dently drawn from three different distributions: Uniform distri-
bution,𝑈[0,1]; Normal distribution 𝑁(0.5,0.0256)and𝑣∈[0,1];
Lognormal distribution 𝐿𝑁(0.1,1.44)and𝑣∈[0,1].
It can be seen from the experimental results in Table 2 that for
three different value distributions, JRegNet achieves the signifi-
cantly highest revenue, compared to RegretNet, IRegNet and VCG
mechanism. This demonstrates the stability and robustness of our
mechanisms, when facing the different value distributions.
Different CTRs of slots. Based on the Setting B, we adjust
the values of CTRs and repeatedly run all mechanisms in the fol-
lowing three settings: B1. CTRs, 𝜶=(0.4,0.3,0.15); B2. CTRs,
𝜶=(0.5,0.4,0.15); B3. CTRs, 𝜶=(0.5,0.4,0.25). The experimental
results are shown in Figure 4(a) of Appendix A.1.
From Figure 4 (a), it can be seen that as the CTR increases, the
JRegNet’s revenue also increases, and the impact of changing the
4369Joint Auction in the Online Advertising Market KDD ’24, August 25–29, 2024, Barcelona, Spain
CTR on the first slot is greater than the impact of changing the
CTR on the last slot. For all settings in Figure 4 (a), the mechanisms
generated by JRegNet all realize the highest revenue. This proves
that even for different CTRs, JRegNet can still generate mechanisms
that perform well in the joint advertising settings.
Different numbers of advertisement slots. Based on the
Setting D, we increase or decrease the number of advertisement
slots to evaluate the performance of our mechanisms. The adjusted
settings are described as follows: Setting D1. two advertising slots
with CTRs 𝜶=(0.5,0.3); Setting D2. four advertising slots with
CTRs 𝜶=(0.5,0.3,0.15,0.1); Setting D3. five advertising slots with
CTRs 𝜶=(0.5,0.3,0.15,0.1,0.03). The curves of revenue as the
number of advertising slots changing are shown in Figure 4 (b) of
Appendix A.1.
From Figure 4 (b), the mechanisms generated by JRegNet per-
form best among all mechanisms, which demonstrates that our
mechanism can be suitable for the settings with different num-
bers of slots. In addition, the revenue derived by our mechanism
strictly increases, with the increase on the number of slots. This
phenomenon is not appeared on all mechanisms we execute.
4.2 Real-World Dataset
We train and evaluate our model using real online auction log data
from Meituan, an e-commerce platform. Each user search query
corresponds to one advertising auction. In the real scenario, after
the recall, rough ranking, and fine ranking stages, the advertising
system selects about 10bundles as auction candidates and picks
up at most 10stores and at most 10brands from candidates. Then,
platform runs an auction mechanism to allocate at most 5slots. This
is the real scenario currently being tested by the online e-commerce
platform. Therefore, we focus on the setting with 10stores, 10
brands and 5slots. Due to the variable number of advertisers in the
original data, we trim or pad some data records to ensure that we
have 10stores and 10brands in each auction sample. The padding
operation is accomplished by adding advertisers whose value per
click is 0. We use 6912 real samples for testing. The log data features
we use primarily include the bid and id of each store and brand,
the joint relationship between stores and brands, and the predicted
CTR of each advertising slot.
In addition, using regret alone to measure DSIC is no longer
applicable due to the different value function distributions between
real data and simulated data. For the real joint auction data and our
simulated data, there is a significant difference in the magnitude of
bidders’ utilities. If we simply use a fixed regret threshold, it will
not accurately measure the degree of DSIC. Therefore, we use 𝑟𝑢:=
1
𝐿Í𝐿
ℓ=1hÍ𝑚
𝑖=1𝑟𝑔𝑡(ℓ)
𝑖·+Í𝑛
𝑗=1𝑟𝑔𝑡(ℓ)
·𝑗
/Í𝑚
𝑖=1𝜇(ℓ)
𝑖·+Í𝑛
𝑗=1𝜇(ℓ)
·𝑗i
to
assess DSIC where 𝑟𝑔𝑡𝑖·:=max𝑣′
𝑖·∈𝑉𝑖·𝑢𝑖·(𝑣𝑖·;(𝑣′
𝑖·,𝒗−𝑖·))−𝑢𝑖·(𝑣𝑖·;𝒗)
(similar definition for brand 𝑗). The meaning of 𝑟𝑢is the ratio of util-
ity growth obtained from misreporting to the utility from reporting
truthfully. For GSP, we employ an enumeration method [ 18] during
the testing phase to get the misreport, where the misreport is equal
to𝛽𝑣, with𝛽∈{0,0.1,0.2,0.3,..., 1.9}. We use the misreport that
can obtain the maximum utility from this set to calculate the GSP’s
regret.
We train JRegNet with real data from three distinct time peri-
ods, and for each time period, we test them using data from threedifferent time points respectively. In Figures 5 and 6 of Appendix
A.2, we show the detailed number of real search query samples
used for training and testing JRegNet. In Table 3, we present the
performance of JRegNet, VCG, and GSP on the test set across all
real data experiments, where GSP is the mechanism initially used
online by Meituan in the joint auction scenario.
From Table 3, it can be seen that in all real data experiments,
JRegNet can achieve significantly higher revenue than VCG at a
very small𝑟𝑢and JRegNet can also achieve significantly higher
revenue than GSP when their 𝑟𝑢are close, and all the paired t-test
is at the level of 𝑝<0.05. These real data experiments demon-
strate the effectiveness of JRegNet in real joint auction scenarios.
Furthermore, it should be noted that GSP does not satisfy DSIC,
which leads to increased complexity in advertisers’ bidding strate-
gies and difficulty to predict the equilibrium of GSP in joint auction
scenario. In the experiment, the revenue of the GSP is calculated
under the assumption that advertisers bid truthfully. However, in
the equilibrium state, advertisers’ bids are lower than their true
values. Therefore, the actual revenue of GSP is lower than what is
presented in the table. But since the equilibrium of GSP in the joint
auction scenario is difficult to calculate, we choose to use an upper
bound.
JRegNet can work in real-world scenarios. If we use a server
with 1GPU and 32CPUs to run this real setting, it will take about 2
to4hours to run 30000 iterations of training. However, the training
of the JRegNet architecture can be performed offline. Therefore, al-
though offline training may be relatively slow, invoking the trained
JRegNet neural network model for forward propagation to obtain
allocation and payment matrices is very fast (around 1to3mil-
liseconds per search query sample), which does not affect online
deployment and decision-making.
5 Conclusions
In this paper, we propose a novel joint advertising model where
stores and brands participate in a joint auction to jointly bid for
advertising slots. To design the optimal joint auction mechanisms
satisfying DSIC and IR, we propose JRegNet, a neural network
architecture for generating the optimal joint auctions. We also
conduct multiple experiments to demonstrate the superiority of
mechanisms generated by JRegNet, compared to the baselines.
In the future, an interesting direction is to apply joint auction
to other scenarios such as live streaming sales, different brand
collaborations, and so on.
Acknowledgments
This work was supported by the Fundamental Research Funds for
the Central Universities, and the Research Funds of Renmin Uni-
versity of China (No. 22XNKJ07), Meituan Inc. Fund, and Major
Innovation & Planning Interdisciplinary Platform for the “Double-
First Class” Initiative, Renmin University of China. The work was
partially done at Engineering Research Center of Next-Generation
Intelligent Search and Recommendation, Ministry of Education,
Beijing Key Laboratory of Big Data Management and Analysis
Methods, Gaoling School of Artificial Intelligence, Renmin Univer-
sity of China. We would like to thank Wanzhi Zhang for helpful
comments and discussions.
4370KDD ’24, August 25–29, 2024, Barcelona, Spain Zhen Zhang et al.
References
[1]Maria-Florina Balcan, Avrim Blum, Jason D Hartline, and Yishay Mansour. 2008.
Reducing mechanism design to algorithm design via machine learning. J. Comput.
System Sci. 74, 8 (2008), 1245–1270.
[2]Ioannis Caragiannis, Christos Kaklamanis, Panagiotis Kanellopoulos, and Maria
Kyropoulou. 2011. On the efficiency of equilibria in generalized second price
auctions. In Proceedings of the 12th ACM conference on Electronic commerce. 81–90.
[3]Denis Charles, Nikhil R Devanur, and Balasubramanian Sivan. 2016. Multi-score
position auctions. In Proceedings of the Ninth ACM International Conference on
Web Search and Data Mining. 417–425.
[4]Edward H Clarke. 1971. Multipart pricing of public goods. Public choice (1971),
17–33.
[5]Vincent Conitzer and Tuomas Sandholm. 2002. Complexity of mechanism design.
InProceedings of the Eighteenth conference on Uncertainty in artificial intelligence.
103–110.
[6]Vincent Conitzer and Tuomas Sandholm. 2004. Self-interested automated mech-
anism design and implications for optimal combinatorial auctions. In Proceedings
of the 5th ACM Conference on Electronic Commerce. 132–141.
[7]Zhijian Duan, Jingwu Tang, Yutong Yin, Zhe Feng, Xiang Yan, Manzil Zaheer,
and Xiaotie Deng. 2022. A context-integrated transformer-based neural network
for auction design. In International Conference on Machine Learning. PMLR, 5609–
5626.
[8]Paul Dütting, Zhe Feng, Harikrishna Narasimhan, David Parkes, and Sai Srivatsa
Ravindranath. 2019. Optimal auctions through deep learning. In International
Conference on Machine Learning. PMLR, 1706–1715.
[9]Paul Dütting, Felix Fischer, Pichayut Jirapinyo, John K Lai, Benjamin Lubin, and
David C Parkes. 2015. Payment rules through discriminant-based classifiers.
[10] Benjamin Edelman, Michael Ostrovsky, and Michael Schwarz. 2007. Internet
advertising and the generalized second-price auction: Selling billions of dollars
worth of keywords. American economic review 97, 1 (2007), 242–259.
[11] Zhe Feng, Harikrishna Narasimhan, and David C Parkes. 2018. Deep learning for
revenue-optimal auctions with budgets. In Proceedings of the 17th International
Conference on Autonomous Agents and Multiagent Systems. 354–362.
[12] Renato D Gomes and Kane S Sweeney. 2009. Bayes-Nash equilibria of the general-
ized second price auction. In Proceedings of the 10th ACM conference on Electronic
Commerce. 107–108.
[13] Theodore Groves. 1973. Incentives in teams. Econometrica: Journal of the Econo-
metric Society (1973), 617–631.[14] Dmitry Ivanov, Iskander Safiulin, Igor Filippov, and Ksenia Balabaeva. 2022.
Optimal-er auctions through attention. Advances in Neural Information Processing
Systems 35 (2022), 34734–34747.
[15] Kevin Kuo, Anthony Ostuni, Elizabeth Horishny, Michael J Curry, Samuel Dooley,
Ping-yeh Chiang, Tom Goldstein, and John P Dickerson. 2020. Proportionnet:
Balancing fairness and revenue for auction design with deep learning. arXiv
preprint arXiv:2010.06398 (2020).
[16] Sébastien Lahaie. 2011. A kernel-based iterative combinatorial auction. In Pro-
ceedings of the AAAI Conference on Artificial Intelligence, Vol. 25. 695–700.
[17] Sébastien Lahaie and David M Pennock. 2007. Revenue analysis of a family of
ranking rules for keyword auctions. In Proceedings of the 8th ACM Conference on
Electronic Commerce. 50–56.
[18] Guogang Liao, Xuejian Li, Ze Wang, Fan Yang, Muzhi Guan, Bingqi Zhu,
Yongkang Wang, Xingxing Wang, and Dong Wang. 2022. NMA: Neural
Multi-slot Auctions with Externalities for Online Advertising. arXiv preprint
arXiv:2205.10018 (2022).
[19] Brendan Lucier, Renato Paes Leme, and Éva Tardos. 2012. On revenue in the
generalized second price auction. In Proceedings of the 21st international conference
on World Wide Web. 361–370.
[20] Roger B Myerson. 1981. Optimal auction design. Mathematics of operations
research 6, 1 (1981), 58–73.
[21] Neehar Peri, Michael Curry, Samuel Dooley, and John Dickerson. 2021. Pref-
erencenet: Encoding human preferences in auction design with deep learning.
Advances in Neural Information Processing Systems 34 (2021), 17532–17542.
[22] Jad Rahme, Samy Jelassi, Joan Bruna, and S Matthew Weinberg. 2021. A
permutation-equivariant neural network architecture for auction design. In Pro-
ceedings of the AAAI conference on artificial intelligence, Vol. 35. 5664–5672.
[23] Ben Roberts, Dinan Gunawardena, Ian A Kash, and Peter Key. 2016. Ranking
and tradeoffs in sponsored search auctions. ACM Transactions on Economics and
Computation (TEAC) 4, 3 (2016), 1–21.
[24] Tuomas Sandholm and Anton Likhodedov. 2015. Automated design of revenue-
maximizing combinatorial auctions. Operations Research 63, 5 (2015), 1000–1025.
[25] David RM Thompson and Kevin Leyton-Brown. 2013. Revenue optimization
in the generalized second-price auction. In Proceedings of the fourteenth ACM
conference on Electronic commerce. 837–852.
[26] Hal R Varian. 2007. Position auctions. international Journal of industrial Organi-
zation 25, 6 (2007), 1163–1178.
[27] William Vickrey. 1961. Counterspeculation, auctions, and competitive sealed
tenders. The Journal of finance 16, 1 (1961), 8–37.
4371Joint Auction in the Online Advertising Market KDD ’24, August 25–29, 2024, Barcelona, Spain
A Additional Experimental Information
A.1 Detailed Experiment Results for Different
CTRs and Different Numbers of
Advertisement Slots.
The results of experiments on the settings of different CTRs and
different numbers of advertisement slots are shown in Figure 4.
The detailed information about the experiment results is shown in
Table 4 and Table 5, respectively.
(a)
(b)
Figure 4: The results of experiments on the settings of differ-
ent CTRs (a) and different numbers of advertisement slots
(b). In all results, the regrets are less than 0.001.
A.2 Real-World Data Experiment
The number of real search query samples used for training JRegNet
is shown in Figure 5, and the number used for testing is shown in
Figure 6.
(a)
(b)
(c)
Figure 5: The number of real search query samples used for
training JRegNet. The horizontal axis is the generation time
of the search query samples. In this figure, all search query
samples are obtained from logs of the year 2023. Within
settings E1 to E3, we use data from (a) to (c) to train JRegNet,
respectively.
4372KDD ’24, August 25–29, 2024, Barcelona, Spain Zhen Zhang et al.
MethodB1: 3×5×3
rev sw rgtB: 3×5×3
rev sw rgtB2: 3×5×3
rev sw rgtB3: 3×5×3
rev sw rgt
RegretNet 0.251 0.340 <0.001 0.298 0.399 <0.001 0.314 0.428 <0.001 0.317 0.433 <0.001
IRegNet 0.469 0.572 <0.001 0.536 0.651 <0.001 0.584 0.712 <0.001 0.613 0.758 <0.001
VCG 0.372 1.019− 0.445 1.154− 0.474 1.266− 0.470 1.361−
JRegNet 0.562†0.841 <0.001 0.641†0.955 <0.001 0.687†1.041 <0.001 0.725†1.108 <0.001
Table 4: The results of experiments for different CTRs (Settings B1, B, B2 and B3). “ †” indicates that the revenue has a significant
improvement over other methods in paired t-test at 𝑝<0.05level.
MethodD1: 4×5×2
rev sw rgtD: 4×5×3
rev sw rgtD2: 4×5×4
rev sw rgtD3: 4×5×5
rev sw rgt
RegretNet 0.363 0.470 <0.001 0.370 0.488 <0.001 0.372 0.491 <0.001 0.372 0.494 <0.001
IRegNet 0.537 0.615 <0.001 0.583 0.690 <0.001 0.603 0.728 <0.001 0.604 0.732 <0.001
VCG 0.579 1.079− 0.602 1.232− 0.599 1.329− 0.593 1.354−
JRegNet 0.620†0.900 <0.001 0.676†1.005 <0.001 0.693†1.062 <0.001 0.704†1.076 <0.001
Table 5: The results of experiments for different number of advertising slots (Settings D1, D, D2 and D3). “ †” indicates that the
revenue has a significant improvement over other methods in paired t-test at 𝑝<0.05level.
09.24 09.25 09.26 10.18 10.19 10.20 11.26 11.27 11.28
Date22002250230023502400Number of search query samples
T est E1
T est E2
T est E3
Figure 6: The number of real search query samples used for testing JRegNet and baseline methods. In this figure, all search query
samples are obtained from logs of the year 2023. For settings E1 to E3, we take three days of real data for testing, respectively.
4373