Scalable Graph Learning for your Enterprise
Hema Raghavan
hema@kumo.ai
Kumo.AI., Inc.
Mountain View, California, USA
Abstract
Much of the world’s most valued data is stored in relational databases
and data warehouses, where the data is organized into many tables
connected by primary-foreign key relations. However, building
machine learning models using this data is both challenging and
time consuming. The core problem is that no machine learning
method is capable of learning on multiple tables interconnected
by primary-foreign key relations. Current methods can only learn
from a single table, so the data must first be manually joined and
aggregated into a single training table, the process known as feature
engineering. Feature engineering is slow, error prone and leads to
suboptimal models. At Kumo.ai we have worked with researchers
worldwide to develop an end-to-end deep representation learning
approach to directly learn on data laid out across multiple tables
[1]. We name our approach Relational Deep Learning (RDL). The
core idea is to view relational databases as a temporal, heteroge-
neous graph, with a node for each row in each table, and edges
specified by primary-foreign key links. Message Passing Graph
Neural Networks can then automatically learn across the graph to
extract representations that leverage all input data, without any
manual feature engineering. Our relational deep learning method
to encode graph structure into low-dimensional embeddings brings
several benefits: (1) automatic learning from the entire data spread
across multiple relational tables (2) no manual feature engineering
as the system learns optimal embeddings for a target problem; (3)
state-of-the-art predictive performance.
Figure 1: Predictive SQL
Furthermore, we have found that once the graph is constructed,
almost all machine learning problems in enterprises can be reduced
to node prediction or link prediction problems. This observation
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for third-party components of this work must be honored.
For all other uses, contact the owner/author(s).
KDD ’24, August 25–29, 2024, Barcelona, Spain
©2024 Copyright held by the owner/author(s).
ACM ISBN 979-8-4007-0490-1/24/08
https://doi.org/10.1145/3637528.3672501led us to create predictive SQL (pSQL), a powerful and expressive
language that has a SQL like syntax that a data scientist can use
to define a predictive problem on the graph1. pSQL has been suc-
cessfully used by several enterprises to iterate quickly on graph
learning for problems ranging from recommender systems, market-
ing and sales to fraud and abuse. Figure 1 shows three examples of
predictive problems on a simple 3 table schema.
Building such a distributed system for GNN training and infer-
ence poses several interesting algorithmic and data processing chal-
lenges, which we address by innovative machine learning methods
and careful algorithm/architecture codesign. Figure 2 showcases
the Kumo Architecture. Kumo has a graph engine that indexes the
graph edges in a data structure that enables fast graph sampling.
A column store is used to index node attribures. The Kumo archi-
tecture scales to graphs with over 50B entities. We will also talk
about how we have built Kumo to be compliant from a security and
privacy standpoint as well as provide sufficient explainability for a
business to have confidence in the model. Kumo has already been
successfully deployed at several major companies2.
The team at Kumo also leads three open source initiatives to
further research in this area- Pytorch Geometeric3[2] is an open
source graph learning framework used by researchers worldwide.
We have also worked with the research community to develop
Pytorch Frame [ 3] - a tabular deep learning framework to handle
complex tabular data. Pytorch Frame enables modular implemen-
tations of tabular models and allows external foundation models
to be incorporated to handle complex columns (e.g., LLMs for text
columns). Additionally Kumo, has worked with several academic
partners to develop RelBench4, a set of benchmark datasets - from
discussions on Stack Exchange to book reviews on the Amazon
Product Catalog. RelBench also has an implementation of Relational
Deep Learning based on Pytorch Frame.
CCS Concepts
•Information systems →Data management systems; •Com-
puting methodologies →Artificial intelligence.
Keywords
Declarative machine leaning; Graph Neural Networks; Deep learn-
ing; Foundation Models
ACM Reference Format:
Hema Raghavan. 2024. Scalable Graph Learning for your Enterprise. In
Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery
and Data Mining (KDD ’24), August 25–29, 2024, Barcelona, Spain. ACM, New
York, NY, USA, 2 pages. https://doi.org/10.1145/3637528.3672501
1https://docs.kumo.ai/docs/predictive-query
2https://kumo.ai/resources/case-studies
3https://pyg.org/
4https://relbench.stanford.edu/
4737
KDD ’24, August 25–29, 2024, Barcelona, Spain Hema Raghavan
Figure 2: Kumo Architecture
Biography
Hema Raghavan is Vice President of Engineering and Co-founder of
Kumo.AI where she is responsible for developing the AI technology
to help Kumo users build better ML models. Previously, Raghavan
was Senior Director of Engineering at LinkedIn where she led aglobally distributed diverse team that built AI and ML solutions
for fueling LinkedIn’s growth. Her team was responsible for the
algorithms behind People You May Know and for notifications that
fueled LinkedIn’s growth. She has also worked as a Research Staff
Member at IBM T.J Watson and a Scientist at Yahoo! Raghavan
received her PhD in Computer Science from the University of Mas-
sachusetts, Amherst in Information Retrieval and thereafter started
her industry career in Yahoo Labs. Her experience spans a breadth
of applications of AI from Search, Advertising, Question Answer-
ing and Recommendation Systems. She has published in several
conferences like WWW, SIGIR, ACL and COLING.
References
[1]Matthias Fey, Weihua Hu, Kexin Huang, Jan Eric Lenssen, Rishabh Ranjan, Joshua
Robinson, Rex Ying, Jiaxuan You, and Jure Leskovec. 2023. Relational Deep Learn-
ing: Graph Representation Learning on Relational Databases. arXiv:2312.04615
[2]Matthias Fey and Jan E. Lenssen. 2019. Fast Graph Representation Learning with
PyTorch Geometric. In ICLR Workshop on Representation Learning on Graphs and
Manifolds.
[3]Weihua Hu, Yiwen Yuan, Zecheng Zhang, Akihiro Nitta, Kaidi Cao, Vid Kocijan,
Jure Leskovec, and Matthias Fey. 2024. PyTorch Frame: A Modular Framework for
Multi-Modal Tabular Learning. arXiv preprint arXiv:2404.00776 (2024).
4738