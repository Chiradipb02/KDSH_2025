Fairness in Streaming Submodular Maximization
Subject to a Knapsack Constraint
Shuang Cui
lakers@mail.ustc.edu.cn
School of Computer Science and
Technology, University of Science and
Technology of China
Hefei, Anhui, ChinaKai Han∗
hankai@suda.edu.cn
School of Computer Science and
Technology, Soochow University
Suzhou, Jiangsu, ChinaShaojie Tang
shaojie.tang@utdallas.edu
The University of Texas at Dallas
Richardson, Texas, United States
Feng Li
fli@sdu.edu.cn
School of Computer Science and 
Technology, Shandong University /
Key Laboratory of Computing Power 
Network and Information Security, 
Ministry of Education, Qilu 
University of Technology
Qingdao / Jinan, Shandong, ChinaJun Luo
junluo@ntu.edu.sg
Nanyang Technological University
Singapore
ABSTRACT
Submodular optimization has been identified as a powerful tool for
many data mining applications, where a representative subset of
moderate size needs to be extracted from a large-scale dataset. In
scenarios where data points possess sensitive attributes such as age,
gender, or race, it becomes imperative to integrate fairness measures
into submodular optimization to mitigate bias and discrimination.
In this paper, we study the fundamental problem of fair submodular
maximization subject to a knapsack constraint and propose the first
streaming algorithm for it with provable performance guarantees
for both monotone and non-monotone submodular functions. As a
byproduct, we also propose a streaming algorithm for submodular
maximization subject to a partition matroid and a knapsack con-
straint, significantly improving the performance bounds achieved
by previous work. We conduct extensive experiments on real-world
applications such as movie recommendation, image summariza-
tion, and maximum coverage in social networks. The experimental
results strongly demonstrate the superiority of our proposed algo-
rithms in terms of both fairness and utility.
CCS CONCEPTS
•Information systems →Data stream mining; •Theory of
computation→Approximation algorithms analysis.
∗Corresponding author: Kai Han
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
KDD ’24, August 25–29, 2024, Barcelona, Spain
©2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 979-8-4007-0490-1/24/08
https://doi.org/10.1145/3637528.3671778KEYWORDS
data stream mining, fairness, submodular maximization, streaming
algorithm
ACM Reference Format:
Shuang Cui, Kai Han, Shaojie Tang, Feng li, and Jun Luo. 2024. Fairness in
Streaming Submodular Maximization Subject to a Knapsack Constraint. In
Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery
and Data Mining (KDD ’24), August 25–29, 2024, Barcelona, Spain. ACM, New
York, NY, USA, 12 pages. https://doi.org/10.1145/3637528.3671778
1 INTRODUCTION
Data mining applications usually need to extract a representative
subset with moderate size from a large-scale dataset. Submodular
optimization theory has been identified as a powerful tool for this
task, especially when the underlying dataset obeys the “diminishing
returns” property. This can be seen from the fact that a lot of studies
have applied submodular optimization into numerous data mining
applications including social media marketing [ 8,39,40,47,49,67],
feature selection [ 3,4,9,45,72,76], information gathering [ 51],
document summarization [ 16,53,57–60,74], movie recommenda-
tion [5, 24, 36, 65], image summarization [29, 63, 70], and so on.
However, recent studies have found that data summaries gener-
ated by traditional submodular optimization algorithms may exhibit
bias and discrimination concerning sensitive attributes such as age,
gender, or race, which can be a crucial problem in some domains like
voting, hiring, criminal justice, and higher education [ 25,26,71]. To
address this problem, Celis et al . [14] introduced fairness constraints
into submodular maximization problems, ensuring that the selected
data should represent each sensitive attribute equitably. Formally,
assuming that each element 𝑢in the ground dataset Nis assigned
a unique group from the set {1,...,ℎ}, Celis et al . [14] defined a
set𝐴⊆N to be fair if it satisfies ∀𝑡∈[ℎ]:ℓ𝑡≤|𝐴∩N𝑡|≤𝑢𝑡for
the given lower and upper bounds ℓ𝑡,𝑢𝑡∈Z≥0(∀𝑡∈[ℎ]), where
N𝑡denotes the set of all elements in group 𝑡. Subsequently, several
514
KDD ’24, August 25–29, 2024, Barcelona, Spain Shuang Cui, Kai Han, Shaojie Tang, Feng Li, and Jun Luo
studies have adopted this fairness model and proposed fair submod-
ular maximization algorithms under different constraints, including
cardinality constraint [26] and matroid constraint [25, 37].
However, to the best of our knowledge, no previous studies
have considered the fundamental problem of fairsubmodular max-
imization subject to a knapsack constraint (abbreviated as the FSK
problem). This gap in the literature is significant as the FSK problem
is pertinent to many real-world scenarios. For example, in multi-
winner voting and participatory budgeting [ 10,11,14,33,34,41,
46,66], some items/projects with different costs need to be selected
under a budget constraint, while the projects may belong to various
categories such as educational projects, elderly-care initiatives, and
suburban development. Since different categories involve different
people’s interests, it is crucial to consider fairness in this scenario.
It is also noted that the traditional problem of submodular max-
imization under a knapsack constraint (without considering the
fairness issue) has been extensively studied (e.g., [ 1,27,28,35,50,
54,55]), and most of these studies concentrate on the offline set-
ting where one has full access to the whole dataset. However, in
many applications for “big data”, the overwhelming scale of the
underlying dataset makes it infeasible to store all data in mem-
ory and hence the offline submodular optimization algorithms no
longer work. To address this issue, a few studies try to address the
problem of streaming submodular maximization under a knapsack
constraint [ 21,38,42–44,75,77]. Unfortunately, these studies still
neglect the fairness issue, and it is highly non-trivial (if possible) to
adapt them to address the fair submodular maximization problem.
Based on the above observations, this paper aims to fill the gap in
the existing studies by proposing the first streaming algorithm with
provable performance bounds for the problem of fair submodular
maximization subject to a knapsack constraint.
1.1 Challenges and Techniques
As aforementioned, the existing algorithms for fair submodular max-
imization can only handle cardinality or matroid constraints [ 14,25,
26,37,71]. Since the cardinality constraint and matroid constraint
are both special cases of a 1-extendable system constraint [ 61], and a
knapsack constraint can only be modeled as a𝑐𝑚𝑎𝑥
𝑐𝑚𝑖𝑛-extendable sys-
tem constraint with 𝑐𝑚𝑖𝑛=min𝑒∈N𝑐(𝑒)and𝑐𝑚𝑎𝑥=max𝑒∈N𝑐(𝑒)
where𝑐(𝑒)denotes the cost of the element 𝑒[32], directly applying
the existing algorithms to our FSK problem cannot lead to any per-
formance guarantee. Even for a 1-extendable system constraint (i.e.,
matroid), El Halabi et al . [25] have proved that it is impossible to
design a fair memory-efficient streaming algorithm with a provable
approximation ratio, so they only provide streaming algorithms
where the fairness lower bounds (i.e., {𝑙𝑡:𝑡∈[ℎ]}) can be violated
by a factor of 1/2. Therefore, we follow [ 25] to allow that the fair-
ness lower bounds can be violated by the same factor of 1/2in this
paper.
In fact, the FSK problem is challenging even if there are only
fairness upper bounds (i.e., {𝑢𝑡:𝑡∈ [ℎ]}) when𝑙𝑡=0for all
𝑡∈[ℎ]. In this case, the FSK problem degenerates into the prob-
lem of streaming submodular maximization subject to a partition
matroid and a knapsack constraint (abbreviated as the SMK prob-
lem), which still has not been well studied. To our knowledge, only
Cui et al . [21] have provided a streaming algorithm to address theSMK problem, but their approximation ratio deteriorates as the
size of the maximum feasible solution increases, which is far from
satisfactory.
To address the above challenges, we propose a novel approach
to address the FSK problem as follows. In the first step, we scan the
data stream once to construct a small “reserved dataset” using a
small portion of the budget 𝐵, such that the reserved dataset has
exactly 2⌊𝑙𝑡/2⌋≈𝑙𝑡elements for each 𝑡∈[ℎ]but has no perfor-
mance guarantee on the objective function value. Then, we use the
leftover budget to construct another dataset that has guaranteed
performance on the objective function value but only satisfies the
fairness upper bounds {𝑢𝑡:𝑡∈[ℎ]}. To achieve this, we propose
a novel steaming algorithm for the SMK problem, which achieves
much better performance bounds than the previous work in [ 21].
Finally, the two generated datasets mentioned above are combined
together to produce a solution satisfying both the (relaxed) fairness
constraint and the budget constraint. The major difficulty behind
this approach is about deriving the performance guarantees on the
approximation ratio and time/space complexities, because neither
of the aforementioned two datasets is generated using the total
budget. To bypass this difficulty, we leverage some specific tricks in-
cluding random sampling to ensure the quality of the final solution.
More details can be found in Section 4.
1.2 Our Contributions
In this study, we propose two novel streaming algorithms to address
the FSK and SMK problems, respectively. The main contributions
of our paper can be summarized as follows:
•We propose a two-pass streaming algorithm dubbed FairK-
napStream for the FSK problem, achieving the approxima-
tion ratios of1
12−𝜖and1
40+16√
2−𝜖for monotone and non-
monotone submodular functions, respectively. The query
complexity and space complexity of FairKnapStream isO(𝑛𝑘)
andO(𝑘), respectively, where 𝑘is the size of the maximum
feasible solution to the FSK problem. To the best of our
knowledge, FairKnapStream is the first attempt on FSK, as
no previous studies have proposed any offline or streaming
algorithm to address the FSK problem, no matter the objec-
tive submodular function is monotone or non-monotone.
•As a byproduct, we propose a one-pass streaming algorithm
dubbed MatKnapStream for the SMK problem, which achieves
approximation ratios of1
6(1+𝜖)and1
(10+4√
2)(1+𝜖)for mono-
tone and non-monotone submodular functions, respectively.
The query complexity and space complexity of MatKnap-
Stream areO(𝑛𝑘)andO(𝑘), respectively. Note that MatK-
napStream significantly improves the streaming algorithm
proposed in Cui et al . [21] with an approximation ratio of
1−1/ℎ
(3+2 log2𝑘)(2+ℎ)+3(where the integer ℎ>2is an input pa-
rameter), because the ratio of Cui et al . [21] is no more than
1/42 even for a small 𝑘such as 2.
•We conduct extensive experiments using several real-world
applications including movie recommendation, image sum-
marization, and maximum coverage in social networks. The
experimental results demonstrate that our proposed algo-
rithms fully satisfy the fairness constraints, while achieving
515Fairness in Streaming Submodular Maximization
Subject to a Knapsack Constraint KDD ’24, August 25–29, 2024, Barcelona, Spain
similar performance on utility compared to the state-of-the-
art streaming algorithms for knapsack and/or 𝑞-system con-
straints such as [21, 38].
Due to the space limit, we defer the detailed proofs of most
lemmas and theorems to Appendix A, while only providing some
intuitions and key ideas for them in the main text.
2 RELATED WORK
2.1 Fair Submodular Maximization
Several studies [ 13–15,17,18,25,26,37] have adopted the same
fairness model as our work. Celis et al . [14] investigated the fair sub-
modular maximization problem subject to a cardinality constraint 𝑘,
and they provided a tight (1−1/𝑒)-approximation under the offline
setting using a continuous greedy algorithm. Subsequently, El Hal-
abi et al . [26] studied the same problem as that in [ 14] under the
streaming setting, and proposed a 1/4-approximation algorithm for
a monotone submodular function using O(𝑘)memory consumption
and two oracle queries per element. Moreover, for non-monotone
objective functions, El Halabi et al . [26] proved that it is impossible
to achieve an approximation ratio better than 1−max𝑡∈[ℎ]ℓ𝑡
|N𝑡|
under sublinear space complexity. More recently, El Halabi et al .
[25] considered the problem of fair monotone submodular maxi-
mization under a more general matroid constraint, and proved that
it is impossible to design a multi-pass, memory-efficient streaming
algorithm with a provable approximation ratio. They also proposed
a two-pass streaming algorithm with an approximation ratio of
1/11.656, but relaxing the fairness lower bounds by a factor of 1/2.
Besides, there exist several studies (e.g., [ 68,69,71,78]) consider-
ing some special cases or variations of the fairness model adopted
in [13–15,17,18,25,26,37]. A representative work among them
is [71], in which the fairness model has identical lower and up-
per bounds for each group (i.e., ℓ𝑡=𝑢𝑡for all𝑡∈[ℎ]), and they
designed a streaming algorithm with 1/2-approximation under a
cardinality constraint.
To the best of our knowledge, no previous studies have inves-
tigated the problem of fair submodular maximization subject to a
knapsack constraint under any fairness model.
2.2 Submodular Maximization Subject to a
Knapsack Constraint
Without considering the fairness issue, a lot of studies have investi-
gated the problem of submodular maximization with a knapsack
constraint. The pioneering work [ 73] in this line achieved an approx-
imation ratio of 0.357for monotone submodular functions. Most
of the subsequent studies (e.g., [ 1,7,27,28,35,50,54,55]) focused
on designing offline algorithms for monotone or non-monotone
submodular functions, until recently there appeared some algo-
rithms under the streaming setting [ 38,42–44,75,77]. Among
these streaming algorithms, the best approximation ratios achieved
for monotone and non-monotone submodular functions are 1/2
(achieved by [38]), and 1/4.7(achieved by [21]), respectively.
3 PROBLEM DEFINITION
Given a finite ground set Nwith|N|=𝑛, a non-negative submod-
ular function 𝑓(·)is defined as follows:Definition 3.1 (Submodular Function). A set function 𝑓:2N↦→
R≥0is submodular if it satisfies ∀𝑋,𝑌⊆ N :𝑓(𝑋)+𝑓(𝑌) ≥
𝑓(𝑋∪𝑌)+𝑓(𝑋∩𝑌). The function 𝑓(·)is called monotone if
𝑓(𝑋)≤𝑓(𝑌)for all𝑋⊆𝑌⊆N, otherwise it is non-monotone.
In this paper, we allow 𝑓(·)to be either monotone or non-
monotone. Following the existing work such as [ 24–26,64], we as-
sume that𝑓(·)is normalized, i.e., 𝑓(∅)=0. We assume that each ele-
ment𝑒∈N has a cost𝑐(𝑒)and define the function 𝑐(𝑆)=Í
𝑒∈𝑆𝑐(𝑒)
for any𝑆⊆N . To facilitate the comparison with the existing stud-
ies, we follow [ 5,21,38,75] to assume that the costs of elements in
Nare normalized such that ∀𝑒∈N:𝑐(𝑒)≥1. For convenience, we
define the marginal gain of any𝑒∈N with respect to any 𝐴⊆N
as𝑓(𝑒|𝐴)=𝑓(𝐴∪{𝑒})−𝑓(𝐴). We also denote the set {1,...,𝑖}as
[𝑖]for any natural number 𝑖, and denote the maximum cardinality
of any feasible solution to our problem as 𝑘.
We assume that each element 𝑒∈N is assigned a unique group
number from the set {1,...,ℎ}. We useN𝑡to denote the set of all
elements of group 𝑡inNand use𝑔(𝑒)to denote the group number
assigned to any element 𝑒∈N . Given a set of fairness bounds
{(ℓ𝑡,𝑢𝑡):𝑡∈[ℎ]}and a budget 𝐵, we define the problem of fair
submodular maximization subject to a knapsack constraint
(abbreviated as the FSK problem) as:
max{𝑓(𝐴):𝐴⊆N∧𝑐(𝐴)≤𝐵∧∀𝑡∈[ℎ]:ℓ𝑡≤|𝐴∩N𝑡|≤𝑢𝑡}
We study the FSK problem under the streaming setting, where all
elements inNarrive sequentially in an arbitrary order. Without
loss of generality, we assume that 𝑐(𝑒)≤𝐵for every𝑒∈N, as
any element 𝑒with𝑐(𝑒)>𝐵can be immediately removed when it
arrives. Throughout this paper, we denote an optimal solution to
the FSK problem as 𝑂.
4 ALGORITHMS
In this section, we propose our FairKnapStream algorithm (i.e.,
Algorithm 2, introduced in Sec. 4.2) for the FSK problem, which
invokes two key procedures FairStream (i.e., Algorithm 1, intro-
duced in Sec. 4.1 and MatKnapStream (i.e., Algorithm 3, introduced
in Sec. 4.3). As explained in Sec. 1.1, FairStream creates a scalable
and fair “reserved dataset”, which forms part of our final solution
to ensure that the (relaxed) fairness lower bounds are satisfied,
while MatKnapStream generates a set satisfying both the knapsack
constraint and the fairness upper bounds. Our main algorithm FairK-
napStream for the FSK problem manages to combine the datasets
output by FairStream andMatKnapStream together to generate
the final solution with a provable performance ratio.
4.1 The FairStream Algorithm
In this section, we introduce the procedure FairStream, as shown
by Algorithm 1. Algorithm 1 reads the data stream in a single pass
and performs the following operations: for each 𝑡∈[ℎ], it picks
ℓ𝑡elements with the lowest costs, and then adds these elements
into a set𝐿. Obviously, 𝐿is the one with the lowest cost and the
least number of elements among all feasible solutions to the FSK
problem. Then, Algorithm 1 samples the feasible set 𝐿to construct
two disjoint sets 𝐿1and𝐿2in a balanced way, i.e., ∀𝑡∈[ℎ]:|𝐿1∩
N𝑡|=|𝐿2∩N𝑡|=⌊ℓ𝑡/2⌋.
516KDD ’24, August 25–29, 2024, Barcelona, Spain Shuang Cui, Kai Han, Shaojie Tang, Feng Li, and Jun Luo
Algorithm 1: FairStream
1𝐴𝑡←∅ for each𝑡∈[ℎ];
2while there is an incoming element 𝑒do
3 if|𝐴𝑔(𝑒)|<ℓ𝑡then
4𝐴𝑔(𝑒)←𝐴𝑔(𝑒)∪{𝑒}
5 else
6 if𝑐(𝑒)<max𝑎∈𝐴𝑔(𝑒)𝑐(𝑎)then
7 Add𝑒to𝐴𝑔(𝑒)and then pop the element 𝑎with
the largest value of 𝑐(𝑎)in𝐴𝑔(𝑒);
8𝐿←Ð
𝑡∈[ℎ]𝐴𝑡;𝐿1←∅;𝐿2←∅;
9foreach𝑡∈[ℎ]do
10 Randomly select 2⌊ℓ𝑡/2⌋elements from 𝐿∩N𝑡and
divide them evenly into 𝐿1and𝐿2;
11return𝐿1,𝐿2;
The purpose of generating 𝐿1or𝐿2is to insert them into some
candidate solutions generated by MatKnapStream (introduced in
Sec. 4.3) to ensure that the (relaxed) fairness lower bounds are sat-
isfied. Note that 𝐿1or𝐿2does not have any performance guarantee
on the objective function value. In fact, they are generated in a way
to ensure that the total cost of the elements in them is as small
as possible, such that we have sufficient leftover budget to call
MatKnapStream to get some candidate solutions with good perfor-
mance ratios. However, since MatKnapStream cannot use the total
budget, we need to carefully analyze the quantitative relationships
between𝑂,𝐿1,𝐿2(as done by Lemmas 4.1-4.2) to ensure that the
objective function values of the candidate solutions generated by
MatKnapStream are comparable to that of the optimal solution 𝑂,
which uses the total budget. So we introduce Lemmas 4.1-4.2 in the
sequel:
Lemma 4.1. The set𝐿generated in Line 8 of Algorithm 1 satisfies:
•For any𝑡∈[ℎ], we have|𝑂∩N𝑡|≥|𝐿∩N𝑡|and𝑐(𝑂∩N𝑡)≥
𝑐(𝐿∩N𝑡), which means
|(𝑂\𝐿)∩N𝑡|≥|(𝐿\𝑂)∩N𝑡|and
𝑐((𝑂\𝐿)∩N𝑡)≥𝑐((𝐿\𝑂)∩N𝑡). (1)
•For any𝑡∈[ℎ], we have
∀𝑒∈(𝑂\𝐿)∩N𝑡,𝑣∈𝐿∩N𝑡:𝑐(𝑒)≥𝑐(𝑣) (2)
Lemma 4.2. We can divide the set 𝑂\(𝐿1∪𝐿2)into two disjoint
set𝑂1and𝑂2such that
•𝑐(𝑂2∪(𝑂∩𝐿1))≤𝐵−𝑐(𝐿2)
•𝑐(𝑂1∪(𝑂∩𝐿2))≤𝐵−𝑐(𝐿1)
Proof. Due to Eqn (1), we can get a subset 𝑂2⊆𝑂\(𝐿1∪𝐿2)
such that∀𝑡∈[ℎ]:|𝑂2∩N𝑡|=|(𝐿1\𝑂)∩N𝑡|. Let𝑂1=(𝑂\
(𝐿1∪𝐿2))\𝑂2, then for any 𝑡∈[ℎ], we have
|𝑂1∩N𝑡|=|(𝑂\(𝐿1∪𝐿2))∩N𝑡|−|𝑂2∩N𝑡|
=|(𝑂\(𝐿1∪𝐿2))∩N𝑡|−|(𝐿1\𝑂)∩N𝑡|
≥|((𝐿1∪𝐿2)\𝑂)∩N𝑡|−|(𝐿1\𝑂)∩N𝑡|=|(𝐿2\𝑂)∩N𝑡|Algorithm 2: FairKnapStream
1𝐿1,𝐿2←FairStream();
2for𝑥=1,2in parallel do
3𝑇𝑥←MatKnapStream(𝐵−𝑐(𝐿𝑥));
4for𝑥=1,2do
5𝑇′𝑥←𝑇𝑥;
6 for𝑒∈𝐿𝑥do
7 if|𝑇′𝑥∩N𝑔(𝑒)|<𝑢𝑔(𝑒)then
8 𝑇′𝑥←𝑇′𝑥∪{𝑒};
9𝑇′′𝑥←𝑇′𝑥;
10 for𝑒∈𝐿𝑥mod 2+1do
11 if|𝑇′′𝑥∩N𝑔(𝑒)|<ℓ𝑔(𝑒)∧𝑐(𝑇′′𝑥∪{𝑒})<𝐵then
12 if𝑓(𝑒|𝑇′′𝑥)≥0then𝑇′′𝑥←𝑇′′𝑥∪{𝑒};
13return𝑇∗←arg max𝐴∈{𝑇′′
1,𝑇′′
2,𝐿1∪𝐿2}𝑓(𝐴)
Combining the above with Eqn (2), we get for every 𝑡∈[ℎ]
𝑐(𝑂1∩N𝑡)≥𝑐((𝐿2\𝑂)∩N𝑡)and
𝑐(𝑂2∩N𝑡)≥𝑐((𝐿1\𝑂)∩N𝑡),
which implies 𝑐(𝑂1)≥𝑐(𝐿2\𝑂)and𝑐(𝑂2)≥𝑐(𝐿1\𝑂).
Then we can derive
𝐵≥𝑐(𝑂)=𝑐(𝑂\(𝐿1∪𝐿2))+𝑐(𝑂∩(𝐿1∪𝐿2))
=𝑐(𝑂1)+𝑐(𝑂2)+𝑐(𝑂∩(𝐿1∪𝐿2))
≥𝑐(𝐿2\𝑂)+𝑐(𝑂2)+𝑐(𝑂∩(𝐿1∪𝐿2))
=𝑐(𝐿2\𝑂)+𝑐(𝑂2)+𝑐(𝑂∩𝐿1)+𝑐(𝑂∩𝐿2)
=𝑐(𝐿2)+𝑐(𝑂2∪(𝑂∩𝐿1)).
Similarly, we can derive 𝐵−𝑐(𝐿1)≥𝑐(𝑂1∪(𝑂∩𝐿2)).Combining
all above then the lemma follows. □
4.2 The FairKnapStream Algorithm
In this section, we introduce our main algorithm FairKnapStream for
the FSK problem, as shown by Algorithm 2. FairKnapStream first
callFairStream to get two datasets 𝐿1,𝐿2with small costs (Line 1),
and then call the MatKnapStream procedure using the leftover
budget𝐵−𝑐(𝐿𝑥)(𝑥∈{1,2}) to get two candidate solutions 𝑇1and
𝑇2(Lines 2-3). Note that the MatKnapStream procedure can be
any streaming algorithm for the problem of submodular maximiza-
tion subject to a partition matroid and a knapsack constraint (i.e.,
SMK problem) with a provable performance ratio. To maintain flu-
ency, we defer the description of our MatKnapStream algorithm to
Sec. 4.3. Afterwards, for each 𝑥∈{1,2},FairKnapStream inserts as
many elements as possible from 𝐿𝑥into𝑇𝑥to obtain the candidate
solution𝑇′𝑥(Lines 4-8), such that 𝑇′𝑥satisfies the (relaxed) fairness
lower bounds without violating the knapsack constraint.
Technically, the theoretical performance bounds of FairKnap-
Stream can be derived by using 𝑇′
1and𝑇′
2. In Lines 10-12, we im-
prove the practical performance of FairKnapStream by inserting
more elements from 𝐿1∪𝐿2into𝑇′
1and𝑇′
2without violating the
knapsack constraint and fairness constraint, resulting in two new
candidate solutions 𝑇′′
1and𝑇′′
2. Finally, FairKnapStream returns
the best on among {𝑇′′
1,𝑇′′
2,𝐿1∪𝐿2}as the final solution (Line 13).
517Fairness in Streaming Submodular Maximization
Subject to a Knapsack Constraint KDD ’24, August 25–29, 2024, Barcelona, Spain
Thanks to the design of FairStream and Lemma 4.2, we can
prove that the sets 𝑇𝑥:𝑥∈{1,2}generated by MatKnapStream in
Lines 2-3 of FairKnapStream can be used to provide an upper bound
of the objective function value of the optimal solution 𝑂, as shown
by the following lemma:
Lemma 4.3. Suppose that MatKnapStream achieves𝛽-approximation
to the SMK problem. For any 𝑥∈{1,2}, we have
•∀𝑡∈[ℎ]:|𝑇𝑥∩N𝑡|≤𝑢𝑡,
•𝑐(𝑇𝑥)≤𝐵−𝑐(𝐿𝑥),
•𝑓(𝑇1)≥𝑓(𝑂1∪(𝑂∩𝐿2))
(1+𝜖)𝛽,𝑓(𝑇2)≥𝑓(𝑂2∪(𝑂∩𝐿1))
(1+𝜖)𝛽,
which implies 𝑓(𝑇1)+𝑓(𝑇2)≥𝑓(𝑂)
(1+𝜖)𝛽.
Proof. The first three properties are immediately derived by
the Lemma 4.2 and the properties of MatKnapStream. Then by
submodularity and the definition of 𝑂1and𝑂2in Lemma 4.2, we
can get
𝑓(𝑇1)+𝑓(𝑇2)≥𝑓(𝑂1∪(𝑂∩𝐿2)∪𝑂2∪(𝑂∩𝐿1))
(1+𝜖)𝛽
=𝑓((𝑂∩(𝐿1∪𝐿2))∪(𝑂\(𝐿1∪𝐿2)))
(1+𝜖)𝛽=𝑓(𝑂)
(1+𝜖)𝛽,
which completes the proof. □
Moreover, since all the elements in 𝐿𝑥can be added into 𝑇′𝑥with-
out violating the knapsack constraint, and 𝐿𝑥satisfies the fairness
lower bounds by a factor of 1/2due to Lines 9-10 of Algorithm 1,
we can get:
Lemma 4.4. For any𝑥∈{1,2}, we have𝑐(𝑇′𝑥)≤𝐵and∀𝑡∈[ℎ]:
⌊ℓ𝑡/2⌋≤|𝑇′𝑥∩N𝑡|≤𝑢𝑡.
For monotone submodular functions, Lemma 4.3 is sufficient to
derive the approximation ratio of FairKnapStream, because we have
max{𝑓(𝑇′′
1),𝑓(𝑇′′
2)}≥ max{𝑓(𝑇1),𝑓(𝑇2)}due to𝑇𝑥⊆𝑇′′𝑥. How-
ever, for non-monotone submodular functions, this may not be true
because inserting the elements from 𝐿1∪𝐿2into𝑇𝑥(∀𝑥∈{1,2})
may decrease the function value of 𝑇𝑥. Fortunately, since the ele-
ments in𝐿1∪𝐿2are generated by random sampling due to Lines 9-10
ofFairStream, we can prove that adding them into 𝑇𝑥(∀𝑥∈{1,2})
would not cause significant harm to 𝑓(𝑇𝑥)(shown by Lemmas 4.5-
4.6). Combining these results, we can get the performance bounds
ofFairKnapStream, as shown by Theorem 4.7.
Lemma 4.5 (Buchbinder et al . [12] ).Given a ground set N
and any non-negative submodular function 𝑧(·)defined on 2N, we
haveE[𝑧(𝑌)]≥( 1−𝑝)𝑧(∅)if𝑌is a random subset of Nsuch that
each element inNappears in𝑌with probability of at most 𝑝(not
necessarily independently).
Lemma 4.6. For any𝑥∈{1,2}, we have𝑓(𝑇′𝑥)≥𝑓(𝑇𝑥)if the
objective function is monotone and E[𝑓(𝑇′𝑥)]≥ 1/2·𝑓(𝑇𝑥)if the
objective function is non-monotone.
Proof. For any𝑥∈ {1,2}, we show that the set 𝑇′𝑥\𝑇𝑥of
elements added to 𝑇′𝑥at Lines 4-8 of Algorithm 2 contains each
element of𝐿with a probability of at most 1/2. By the construction
of𝐿1and𝐿2at Lines 9-10 of Algorithm 1, we have for any group 𝑡
and any𝑒∈𝐿∩N𝑡:
Pr(𝑒∈(𝑇′
𝑥\𝑇𝑥)∩N𝑡)≤Pr(𝑒∈𝐿𝑥∩N𝑡)=1
2·2⌊ℓ𝑡/2⌋
|𝐿∩N𝑡|=⌊ℓ𝑡/2⌋
ℓ𝑡≤1/2.
We define two non-negative submodular functions 𝑧1and𝑧2as
follows:𝑧𝑥(𝐴)=𝑓(𝐴∪𝑇𝑥)for all𝐴⊆𝐿and𝑥∈{1,2}. Then by
applying Lemma 4.5, we can get
E[𝑓(𝑇′
𝑥)]=E[𝑧𝑥(𝑇′
𝑥\𝑇𝑥)]≥ 1/2·𝑧𝑥(∅)=1/2·𝑓(𝑇𝑥)
if the objective function is non-monotone. When the objective
function is monotone, we can immediately get 𝑓(𝑇′𝑥)≥𝑓(𝑇𝑥)due
to𝑇𝑥⊆𝑇′𝑥. The lemma then follows. □
Theorem 4.7. Suppose MatKnapStream achieves𝛽-approximation
to the SMK problem using O(𝑘)oracle queries per element and O(𝑘)
memory consumption. Then FairKnapStream can return a solution 𝑇∗
to the FSK problem satisfying: (1) 𝑓(𝑇∗)≥𝑓(𝑂)
2(1+𝜖)𝛽(resp.E[𝑓(𝑇∗)]≥
𝑓(𝑂)
4(1+𝜖)𝛽) when the objective function is monotone (resp. non-monotone);
(2)𝑐(𝑇∗)≤𝐵; and (3)∀𝑡∈[ℎ]:⌊𝑙𝑡/2⌋≤|𝑇∗∩N𝑡|≤𝑢𝑡.
To achieve the above bounds, FairKnapStream takes two passes over
the stream, usingO(𝑘)oracle queries per element and O(𝑘)memory.
Proof. We only need to analyze the complexity of FairKnap-
Stream since other parts of the theorem can be directly proven
by combining Lemma 4.4, Lemma 4.6 and the fact that 𝑓(𝑇′𝑥)≤
𝑓(𝑇′′𝑥)≤𝑓(𝑇∗).
FairStream algorithm reads one pass over the data stream, uses
O(𝑘)memory, and doesn’t incur any oracle queries. MatKnap-
Stream algorithm reads one pass over the data stream, while using
O(𝑘)oracle queries per element and O(𝑘)memory. Lines 4-12 of
FairKnapStream use at mostO(𝑘)oracle queries andO(𝑘)memory.
Combining all the above, the theorem follows. □
We will show in Sec. 4.3 that 𝛽=1
6(1+𝜖)(resp.𝛽=1
(10+4√
2)(1+𝜖))
for monotone (resp. non-monotone) submodular functions. So we
immediately get:
Corollary 1. For the FSK problem, FairKnapStream can achieve
an approximation ratio of1
12−𝜖(resp.1
40+16√
2−𝜖) when the objective
function is monotone (resp. non-monotone).
4.3 The MatKnapStream Algorithm
In this section, we present our MatKnapStream algorithm (i.e., Al-
gorithm 3) to address the SMK problem. MatKnapStream takes
as input a parameter 𝜏∈ [𝑓(𝑀)
(1+𝜖)𝜆𝐵,𝑓(𝑀)
𝜆𝐵]to control the cost-
effectiveness ratio (i.e., “density”) of the selected elements, where
𝑀denotes an optimal solution to the SMK problem, i.e.,
𝑀= arg max
𝑐(𝐴)≤𝐵∧∀𝑡∈[ℎ]:|𝐴∩N𝑡|≤𝑢𝑡𝑓(𝐴),
and𝜆is a constant to be determined later. This implies that we
assume that 𝑓(𝑀)is known. This assumption can be easily removed
using a geometric search trick, as explained in Appendix B.
Suppose that the elements in the stream are {𝑒1,𝑒2,···,𝑒𝑛}
(listed according to their arriving order). MatKnapStream main-
tains|𝑄|candidate solutions {𝑆𝑖,𝑥:𝑥∈𝑄}for each incoming
element𝑒𝑖, where𝑄={1}(resp.𝑄={1,2}) for monotone (resp.
non-monotone) submodular functions. When an element 𝑒𝑖in the
stream arrives, we try to identify a subset 𝐼of𝑄such that it is
possible to add 𝑒𝑖into𝑆𝑖−1,𝑥:𝑥∈𝐼to increase its function value
518KDD ’24, August 25–29, 2024, Barcelona, Spain Shuang Cui, Kai Han, Shaojie Tang, Feng Li, and Jun Luo
Algorithm 3: MatKnapStream (with pre-access to 𝜏)
Input: threshold𝜏∈[𝑓(𝑀)
(1+𝜖)𝜆𝐵,𝑓(𝑀)
𝜆𝐵]and number 𝛼>1
1if𝑓(·)is monotone then𝑄={1};
2else𝑄={1,2};
3𝑆0,𝑥←∅ for each𝑥∈𝑄;𝑒∗←null;
4while there is an incoming element 𝑒𝑖do
5 if𝑢𝑔(𝑒𝑖)>0∧𝑓({𝑒𝑖})>𝑓({𝑒∗})then
6𝑒∗←𝑒𝑖;
7𝐼←∅;𝑆𝑖,𝑥←𝑆𝑖−1,𝑥and𝐸𝑥←null for each 𝑥∈𝑄;
8 for𝑥∈𝑄do
9 if𝑓(𝑒𝑖|𝑆𝑖−1,𝑥)≥𝜏·𝑐(𝑒𝑖)then
10 if|𝑆𝑖−1,𝑥∩N𝑔(𝑒𝑖)|<𝑢𝑔(𝑒𝑖)then
11 if𝑐(𝑆𝑖−1,𝑥∪{𝑒𝑖})≤𝐵then
12 𝐼←𝐼∪{𝑥};𝐸𝑥=true
13 else
14 𝑣𝑖,𝑥←arg min𝑒∈𝑆𝑖−1,𝑥∩N𝑔(𝑒𝑖)𝑓(𝑒|𝑆<𝑒
𝑖−1,𝑥);
15 if𝑓(𝑒𝑖|𝑆𝑖−1,𝑥)≥𝛼·𝑓(𝑣𝑖,𝑥|𝑆<𝑣𝑖,𝑥
𝑖−1,𝑥)then
16 if𝑐(𝑆𝑖−1,𝑥\{𝑣𝑖,𝑥}∪{𝑒𝑖})≤𝐵then
17 𝐼←𝐼∪{𝑥};𝐸𝑥=false
18𝑥∗←arg max𝑥∈𝐼𝑓(𝑒𝑖|𝑆𝑖−1,𝑥);
19 if𝐸𝑥∗=truethen𝑆𝑖,𝑥∗←𝑆𝑖−1,𝑥∗∪{𝑒𝑖};
20 else𝑆𝑖,𝑥∗←𝑆𝑖−1,𝑥∗\{𝑣𝑖,𝑥∗}∪{𝑒𝑖};
21return𝑆∗←arg max𝐴∈{𝑆𝑛,1,𝑆𝑛,2,𝑒∗}𝑓(𝐴);
without violating any constraint. Specifically, we decide whether
𝑥∈𝐼for each𝑥∈𝑄according to the following cases:
(1)If the density of 𝑒𝑖is poor (i.e., 𝑓(𝑒𝑖|𝑆𝑖−1,𝑥)/𝑐(𝑒𝑖)<𝜏, then
𝑥∉𝐼(Line 9).
(2)If𝑆𝑖−1,𝑥∪{𝑒𝑖}does not violate any constraint, then 𝑥∈𝐼
(Lines 10-12).
(3)If𝑆𝑖−1,𝑥\{𝑣𝑖,𝑥}∪{𝑒𝑖}does not violate any constraint, where
𝑣𝑖,𝑥is the element in 𝑆𝑖−1,𝑥with the minimum marginal gain,
and adding𝑒𝑖into𝑆𝑖−1,𝑥can bring a marginal gain being at
least𝛼times of that of 𝑣𝑖,𝑥, then𝑥∈𝐼(Lines 14-17).
After identifying 𝐼,MatKnapStream greedily picks 𝑥∗∈𝐼(Line 18)
and then add 𝑒𝑖into𝑆𝑖−1,𝑥to generate 𝑆𝑖,𝑥. For Case (3) described
above,𝑣𝑖,𝑥is also deleted from 𝑆𝑖,𝑥as an “exchange” of 𝑒𝑖. After all
the𝑛elements in the stream are processed using the above process,
MatKnapStream returns the best one among {{𝑒∗},𝑆𝑛,𝑥:𝑥∈𝑄}
as the final solution, where 𝑒∗is the singleton element with the
maximum function value (Line 21).
Next, we analyze the performance of MatKnapStream. We will
first provide the performance analysis for non-monotone submod-
ular functions and defer the analysis for monotone submodular
functions to Sec. 4.3.3, because the latter is simpler. For clarity, we
divide our main performance analysis into two distinct cases, as
shown by Sec. 4.3.1 and Sec. 4.3.2, respectively.
In our performance analysis, we use 𝑆<𝑒𝑗
𝑖,𝑥to denote the ele-
ments in𝑆𝑖,𝑥that arrived in the stream before 𝑒𝑗, i.e.,𝑆<𝑒𝑗
𝑖,𝑥=
𝑆𝑖,𝑥∩{𝑒1,···,𝑒𝑗}for any𝑖,𝑗∈[𝑛]and any𝑥∈𝑄. So we have𝑆<𝑒𝑗
𝑖+1,𝑥⊆𝑆<𝑒𝑗
𝑖,𝑥because any element removed from 𝑆𝑖,𝑥is never
added back in our algorithm.
4.3.1 Case One: In this case, MatKnapStream never encounters
an element violating the knapsack constraint in Line 11 or Line 16.
Let𝑈1=Ð
𝑖∈[𝑛]𝑆𝑖,1and𝑈2=Ð
𝑖∈[𝑛]𝑆𝑖,2. Since𝑈1and𝑈2are
disjoint, we can use submodularity to get an upper bound on the
objective function value of 𝑀, i.e.,:
𝑓(𝑈1∪𝑀)+𝑓(𝑈2∪𝑀)≥𝑓(𝑀), (3)
Next, we try to find some upper bounds of 𝑓(𝑈𝑖∪𝑀):𝑖∈{1,2}.
For each𝑥∈{1,2}, we use𝑀𝜏,𝑥(resp.𝑀𝑣,𝑥) to denote the set of
elements in 𝑀that are ever considered by Line 9 (resp. Line 15)
but failed to pass the test conditions in these lines. Therefore, each
element𝑒𝑖∈𝑀\𝑈1must belong to one of the following three
categories:
(1)𝑒𝑖∈𝑀𝜏,1, i.e.,𝑒𝑖fails to pass the density test in Line 9. This
implies:
𝑓(𝑒𝑖|𝑈1)≤𝑓(𝑒𝑖|𝑆𝑖−1,1)<𝜏·𝑐(𝑒𝑖)
(2)𝑒𝑖∈𝑀𝑣,1, i.e.,𝑒𝑖fails to pass the test condition on marginal
gain in Line 15. This implies:
𝑓(𝑒𝑖|𝑈1)≤𝑓(𝑒𝑖|𝑆𝑖−1,1)<𝛼·𝑓(𝑣𝑖,1|𝑆<𝑣𝑖,1
𝑖−1,1)
(3)𝑒𝑖∈𝑀∩𝑈2, i.e.,𝑒𝑖is included in 𝑆𝑖,1due to the greedy rule
in Line 18. This implies:
𝑓(𝑒𝑖|𝑈1)≤𝑓(𝑒𝑖|𝑆𝑖−1,1)≤𝑓(𝑒𝑖|𝑆𝑖−1,2)
Note that similar reasoning also applies to the elements in 𝑀\
𝑈2. Combining these results, we can derive the upper bounds of
𝑓(𝑀∪𝑈𝑖):𝑖∈{1,2}as follows:
Lemma 4.8. By submodularity, we have:
𝑓(𝑀∪𝑈1)≤𝑓(𝑀𝜏,1|𝑈1)+𝑓(𝑀∩𝑈2|𝑈1)+𝑓(𝑀𝑣,1|𝑈1)+𝑓(𝑈1)
𝑓(𝑀∪𝑈2)≤𝑓(𝑀𝜏,2|𝑈2)+𝑓(𝑀∩𝑈1|𝑈2)+𝑓(𝑀𝑣,2|𝑈2)+𝑓(𝑈2)
Now we proceed to bound the additive factors in the R.H.S. of
the above equations. First, using the fact that each element in 𝑀𝜏,𝑥
has a density less than 𝜏∈[𝑓(𝑀)
(1+𝜖)𝜆𝐵,𝑓(𝑀)
𝜆𝐵], we can get
Lemma 4.9. For each𝑥∈{1,2},𝑓(𝑀𝜏,𝑥|𝑈𝑥)≤𝑓(𝑀)
𝜆.
Proof.
𝑓(𝑀𝜏,𝑥|𝑈𝑥)≤∑︁
𝑒𝑖∈𝑀𝜏,𝑥𝑓(𝑒𝑖|𝑈𝑥)≤∑︁
𝑒𝑖∈𝑀𝜏,𝑥𝑓(𝑒𝑖|𝑆𝑖−1,)
<∑︁
𝑒𝑖∈𝑀𝜏,𝜏·𝑐(𝑒𝑖)≤𝜏𝐵=𝑓(𝑀)
𝜆,
where the first and second inequalities are due to submodularity.
□
Next, we try to bound 𝑓(𝑀𝑣,𝑥|𝑈𝑥):𝑥∈ {1,2}. According
to submodularity and Line 15 of Algorithm 3, the marginal gain
of any element 𝑒𝑖∈𝑀𝑣,𝑥with respect to 𝑈𝑥is not much better
than𝑓(𝑣𝑖,𝑥|𝑆<𝑣𝑖,𝑥
𝑖−1,𝑥)(i.e, the marginal gain of 𝑣𝑖,𝑥with respect
to𝑆𝑖−1,𝑥), where𝑣𝑖,𝑥is the element with the minimum marginal
gain among all the elements in 𝑆𝑖−1,𝑥at the moment that 𝑒𝑖arrives.
Moreover, we can prove that the marginal gains of such elements
519Fairness in Streaming Submodular Maximization
Subject to a Knapsack Constraint KDD ’24, August 25–29, 2024, Barcelona, Spain
𝑣𝑖,𝑥:𝑖∈[𝑛]are non-decreasing when 𝑖gets larger (as shown by
Lemma 4.10), because they can only be replaced by elements with
larger marginal gains. This implies that the elements in 𝑆𝑛,𝑥have
the largest marginal gains. Meanwhile, we can also prove that 𝑆𝑛,𝑥
has more elements than 𝑀𝑣,𝑥for each group 𝑡∈[ℎ](as shown by
Lemma 4.11). Based on all these results and submodularity, we can
use𝑓(𝑆𝑛,𝑥)to bound𝑓(𝑀𝑣,𝑥|𝑈𝑥), as shown by Lemma 4.12.
Lemma 4.10. For any𝑡∈ [ℎ]and𝑥∈ {1,2}, we must have
min𝑒∈𝑆𝑖,𝑥∩N𝑡𝑓(𝑒|𝑆<𝑒
𝑖,𝑥)is non-decreasing as 𝑖∈[𝑛]increases.
Proof. Recall that𝑆<𝑒𝑗
𝑖,𝑥=𝑆𝑖∩{𝑒1,𝑒2,···,𝑒𝑗−1}for any𝑒𝑗∈
𝑆𝑖(𝑖,𝑗∈[𝑛])and𝑥∈{1,2}. Then, it follows that 𝑆<𝑒𝑗
𝑖+1,𝑥⊆𝑆<𝑒𝑗
𝑖,𝑥
since any element 𝑒∈{𝑒1,𝑒2,···,𝑒𝑗−1}(i.e., an element already
arrived) can only be removed from the candidate solution with the
increasing of 𝑖according to Line 20 of Algorithm 3. Therefore, by
submodularity, 𝑓(𝑒𝑗|𝑆<𝑒𝑗
𝑖,𝑥)must be non-decreasing as 𝑖∈ [𝑛]
increases.
Moreover, we note that the newly added element 𝑒𝑖to the candi-
date solution satisfies the condition 𝑓(𝑒𝑖|𝑆<𝑒𝑖
𝑖,𝑥)=𝑓(𝑒𝑖|𝑆𝑖−1,𝑥)≥
𝛼·min𝑒∈𝑆𝑖−1,𝑥∩N𝑔(𝑒𝑖)𝑓(𝑒|𝑆<𝑒
𝑖−1,𝑥)where𝛼>1.
Combining all of the above, the lemma follows. □
Lemma 4.11. For any𝑡∈[ℎ]and𝑥∈{1,2}, we have|𝑀𝑣,𝑥∩
N𝑡|≤|𝑆𝑛,𝑥∩N𝑡|.
Proof. Consider a fixed 𝑡∈[ℎ]and𝑥∈{1,2}. If|𝑆𝑛,𝑥∩N𝑡|=𝑢𝑡,
the lemma follows, as |𝑀∩N𝑡| ≤𝑢𝑡. Otherwise, Line 15 has
never been executed for such 𝑡and𝑥due to Line 10, implying
𝑀𝑣,𝑥∩N𝑡=∅. Combining all of the above, the lemma follows. □
Lemma 4.12. For any𝑥∈{1,2}, we have𝑓(𝑀𝑣,𝑥|𝑈𝑥)≤𝛼·
𝑓(𝑆𝑛,𝑥).
Proof. By applying submodularity and the definition of 𝑀𝑣,𝑥,
we can conclude
𝑓(𝑀𝑣,𝑥|𝑈𝑥)≤∑︁
𝑒𝑖∈𝑀𝑣,𝑥𝑓(𝑒𝑖|𝑈𝑥)≤∑︁
𝑒𝑖∈𝑀𝑣,𝑥𝑓(𝑒𝑖|𝑆𝑖−1,𝑥)
<∑︁
𝑒𝑖∈𝑀𝑣,𝑥𝛼·𝑓(𝑣𝑖,𝑥|𝑆<𝑣𝑖,𝑥
𝑖−1,𝑥)
=𝛼∑︁
𝑒𝑖∈𝑀𝑣,𝑥min
𝑒∈𝑆𝑖−1,𝑥∩N𝑔(𝑒𝑖)𝑓(𝑒|𝑆<𝑒
𝑖−1,𝑥)
≤𝛼∑︁
𝑒𝑖∈𝑀𝑣,𝑥min
𝑒∈𝑆𝑛,𝑥∩N𝑔(𝑒𝑖)𝑓(𝑒|𝑆<𝑒
𝑛,𝑥)
=𝛼∑︁
𝑡∈[ℎ]∑︁
𝑒𝑖∈𝑀𝑣,𝑥∩N𝑡min
𝑒∈𝑆𝑛,𝑥∩N𝑔(𝑒𝑖)𝑓(𝑒|𝑆<𝑒
𝑛,𝑥)
=𝛼∑︁
𝑡∈[ℎ]∑︁
𝑒𝑖∈𝑀𝑣,𝑥∩N𝑡min
𝑒∈𝑆𝑛,𝑥∩N𝑡𝑓(𝑒|𝑆<𝑒
𝑛,𝑥)
=𝛼∑︁
𝑡∈[ℎ]|𝑀𝑣,𝑥∩N𝑡|min
𝑒∈𝑆𝑛,𝑥∩N𝑡𝑓(𝑒|𝑆<𝑒
𝑛,𝑥),
where𝑣𝑖,𝑥is defined at Line 14 of Algorithm 3; the last inequality
is due to Lemma 4.10. By applying Lemma 4.11, we can get
∑︁
𝑡∈[ℎ]|𝑀𝑣,𝑥∩N𝑡|min
𝑒∈𝑆𝑛,𝑥∩N𝑡𝑓(𝑒|𝑆<𝑒
𝑛,𝑥)≤∑︁
𝑡∈[ℎ]|𝑆𝑛,𝑥∩N𝑡|min
𝑒∈𝑆𝑛,𝑥∩N𝑡𝑓(𝑒|𝑆<𝑒
𝑛,𝑥)
=∑︁
𝑡∈[ℎ]∑︁
𝑒′∈𝑆𝑛,𝑥∩N𝑡min
𝑒∈𝑆𝑛∩N𝑡𝑓(𝑢|𝑆<𝑒
𝑛,𝑥)
≤∑︁
𝑡∈[ℎ]∑︁
𝑒′∈𝑆𝑛,𝑥∩N𝑡𝑓(𝑒′|𝑆<𝑒′
𝑛,𝑥)=𝑓(𝑆𝑛,𝑥).
Combining all of the above, the lemma follows. □
Next, we try to use 𝑓(𝑆𝑛,𝑥)to bound𝑓(𝑈𝑥)for each𝑥∈{1,2}.
According to Lines 14-20 of Algorithm 3, any element 𝑣𝑖,𝑥in𝑈𝑥\𝑆𝑛,𝑥
must have a marginal gain at least 𝛼times smaller than that of 𝑒𝑖
with respect to 𝑆𝑥
𝑖−1. Therefore, the utility loss of dropping 𝑣𝑖,𝑥can
be well compensated by the utility gain of adding 𝑒𝑖(as shown by
Lemma 4.13). With this result, we can use submodularity to provide
an upper bound of 𝑓(𝑈𝑥)(as shown by Lemma 4.14).
Lemma 4.13. For any element 𝑣𝑖,𝑥removed from 𝑆𝑖,𝑥by Algorithm
3, we have𝑓(𝑆𝑖,𝑥)−𝑓(𝑆𝑖−1,𝑥)≥(𝛼−1)𝑓(𝑣𝑖,𝑥|𝑆<𝑣𝑖,𝑥
𝑖−1,𝑥)≥0.
Lemma 4.14. For any𝑥∈{1,2}, we have𝑓(𝑈𝑥)≤𝛼
𝛼−1·𝑓(𝑆𝑛,𝑥).
Finally, we can use 𝑆𝑛,𝑥to bound𝑓(𝑀∩𝑈𝑥|𝑈𝑧)based on the
greedy rule in Line 18 of Algorithm 3, and get
Lemma 4.15. For any𝑥,𝑧∈{1,2}and𝑥≠𝑧, we have𝑓(𝑀∩𝑈𝑥|
𝑈𝑧)≤𝑓(𝑆𝑛,𝑥)
𝛼−1+𝑓(𝑆𝑛,𝑥)and𝑓(𝑀∩𝑈𝑧|𝑈𝑥)≤𝑓(𝑆𝑛,𝑧)
𝛼−1+𝑓(𝑆𝑛,𝑧).
By combining the above lemmas, we immediately get the ap-
proximation ratio of MatKnapStream under case one:
Lemma 4.16. When case one happens, the solution 𝑆∗returned by
Algorithm 3 satisfies (1−2
𝜆)𝑓(𝑀)≤2𝛼2+2𝛼
𝛼−1𝑓(𝑆∗).
4.3.2 Case Two: In this case, MatKnapStream must encounter an
element violating the knapsack constraint in Line 11 or Line 16.
In this case, we can easily get the quantitative relationship be-
tween𝑀and𝑆∗as follows:
Lemma 4.17. If some element 𝑒𝑡fails to pass the test condition in
Line 11 or Line 16 of Algorithm 3 for certain 𝑆𝑡−1,𝑥(𝑥∈{1,2}), then
the solution 𝑆∗returned by Algorithm 3 satisfies 𝑓(𝑆∗)≥𝑓(𝑀)
2(1+𝜖)𝜆.
Proof. We have
𝑓(𝑆𝑡−1,𝑥)+𝑓(𝑒𝑡)=∑︁
𝑒𝑖∈𝑆𝑡−1,𝑥𝑓(𝑒𝑖|𝑆<𝑒𝑖
𝑡−1,𝑥)+𝑓(𝑒𝑡)
≥∑︁
𝑒𝑖∈𝑆𝑖−1,𝑥𝑓(𝑒𝑖|𝑆<𝑒𝑖
𝑖−1,𝑥)+𝑓(𝑒𝑡)=∑︁
𝑒𝑖∈𝑆𝑡−1,𝑥𝑓(𝑒𝑖|𝑆𝑖−1,𝑥)+𝑓(𝑒𝑡)
≥∑︁
𝑒𝑖∈𝑆𝑡−1,𝑥𝜏·𝑐(𝑒𝑖)+𝜏·𝑐(𝑒𝑡)=𝜏∑︁
𝑒𝑖∈𝑆𝑡−1,𝑥∪{𝑒𝑡}𝑐(𝑒𝑖)
>𝜏𝐵=𝑓(𝑀)
(1+𝜖)𝜆,
where the first inequality is due to submodularity. Then, due to
𝑓(𝑒𝑡)≤𝑓(𝑒∗)≤𝑓(𝑆∗)and𝑓(𝑆𝑡−1,𝑥)≤𝑓(𝑆𝑡,𝑥)≤···≤𝑓(𝑆𝑛,𝑥)≤
𝑓(𝑆∗)(as shown by Lemma 4.13), the lemma holds. □
Combining Lemma 4.16 and Lemma 4.17, we can immediately get
the approximation ratio of Algorithm 3, as shown by Theorem 4.18.
Besides, the complexity of our approach is presented in Theorem
4.19.
520KDD ’24, August 25–29, 2024, Barcelona, Spain Shuang Cui, Kai Han, Shaojie Tang, Feng Li, and Jun Luo
Theorem 4.18. By setting𝜆=5+2√
2and𝛼=1+√
2, Algorithm
3 can achieve an approximation ratio of1
(10+4√
2)(1+𝜖)≥1
10+4√
2−𝜖
for the non-monotone SMK problem.
Theorem 4.19. MatKnapStream takes one pass over the data
stream, usingO(𝑘)oracle queries per element and O(𝑘)memory
consumption.
Proof. For each incoming element, the algorithm incurs at most
O(|𝑆𝑖−1,𝑥|)oracle queries according to Line 14 and maintains at
most two candidate solutions. The theorem then follows by using
|𝑆𝑖−1,𝑥|≤𝑘. □
4.3.3 Improved Approximation Ratio for Monotone Submodular
Functions. Note that monotone submodular functions are special
cases of the non-monotone ones. So all the performance analysis
described above also applies to monotone submodular functions
and can be further simplified and improved. Therefore, we can get
stronger performance bounds than Lemma 4.16 under case one as
follows:
Lemma 4.20. When the objective function is monotone and case
one happens, the solution 𝑆∗returned by Algorithm 3 satisfies (1−
1
𝜆)𝑓(𝑀)≤𝛼2
𝛼−1𝑓(𝑆∗).
Under case two, Lemma 4.17 still holds for monotone submodular
functions. Combining Lemma 4.20 and Lemma 4.17, we can get an
improved approximation ratio of MatKnapStream for monotone
submodular functions:
Theorem 4.21. By setting𝜆=3and𝛼=2, Algorithm 3 can
achieve an approximation ratio of1
6(1+𝜖)≥1
6−𝜖for the monotone
SMK problem.
5 EXPERIMENTS
In this section, we empirically evaluate the performance of our
FairKnapStream algorithm in several real-world applications. To
the best of our knowledge, our FairKnapStream algorithm is the
first to address the FSK problem, and the existing algorithms for fair
submodular maximization cannot output a feasible solution to our
problem. Therefore, we adopt several state-of-the-art streaming
algorithms for submodular maximization with knapsack and/or
𝑞-system constraints as the baselines, with the purpose of demon-
strating that FairKnapStream can achieve good performance on
utility even compared to these algorithms without fairness consid-
erations. Specifically, our implemented algorithms include:
•FairKnapStream: Our Algorithm 2.
•SmkStream [38]: The state-of-the-art streaming algorithm
for submodular maximization with a knapsack constraint.
•MultiplexGreedy [21]: The state-of-the-art streaming algo-
rithm for submodular maximization with knapsack and 𝑞-
system constraints. By setting 𝑞=1, this algorithm can
partially satisfy the fairness constraint by outputting a solu-
tion satisfying the upper bounds {𝑢𝑡:𝑡∈[ℎ]}.
•RandomStream: A simple heuristic that adds each incoming
element into the current solution with a probability of 1/2
without violating the knapsack constraint.We use two metrics in our experiments: (1) Utility (i.e., the objective
function value); and (2) The number of violations of the fairness
constraint, defined as
violation(𝐴)=∑︁
𝑡∈[ℎ]max{|𝐴∩N𝑡|−𝑢𝑡,ℓ𝑡−|𝐴∩N𝑡|,0},
where𝐴is any solution output by the implemented algorithms. Note
that this metric is also adopted by [ 25,26] to measure the degree to
which the fairness constraint is breached. All our experiments are
conducted on a Linux server with Intel Xeon Gold 6126 @ 2.60GHz
CPU and 256GB memory1. For each of the implemented algorithms,
the parameter 𝜖for accuracy (if any) is set to 0.1.
In our experiments, we consider several real-world applications
including movie recommendation, image summarization, and max-
imum coverage in social networks, as elaborated below:
5.1 Movie recommendation
This application has also been considered in previous studies includ-
ing [ 2,6,19,21–23,30,31,36,62]. In this application, there is a set
Nof movies, each labeled with a genre, and we aim to recommend
a list of high-quality and diverse movies to a user based on the
ratings from similar users. Each movie 𝑢∈N is associated with
a 25-dimensional feature vector 𝑞𝑢calculated from user ratings.
Following [ 1,8,29,30,36,62], we define the utility of any 𝑆⊆N
as a non-monotone submodular function:
𝑓(𝑆)=∑︁
𝑢∈𝑆∑︁
𝑣∈N𝑠𝑢,𝑣−∑︁
𝑢∈𝑆∑︁
𝑣∈𝑆𝑠𝑢,𝑣,
where we use 𝑠𝑢,𝑣=𝑒−𝜆dist(𝑞𝑢,𝑞𝑣)to measure the similarity be-
tween movies 𝑢and𝑣. Following [ 36],dist(𝑞𝑢,𝑞𝑣)is the Euclidean
distance between 𝑞𝑢and𝑞𝑣and𝜆is set to 0.2. The cost 𝑐(𝑢)of
any movie𝑢is defined to be proportional to 10−𝑟𝑢, where𝑟𝑢
denotes the rating of movie 𝑢(ranging from 0 to 10), and the
costs of all movies are normalized such that the average movie
cost is 2. Thus, movies with higher ratings have smaller costs,
and we requireÍ
𝑢∈𝑆𝑐(𝑢) ≤𝐵to ensure that the movies in 𝑆
have high ratings. Moreover, we also consider the fairness con-
straint that the number of movies in 𝑆labeled by each genre 𝑡
satisfies the upper bound 𝑢𝑡=⌈1.2·𝐵·|N𝑡|/|N|⌉ and lower bound
ℓ𝑡=⌈0.8·Budget·|N𝑡|/|N|⌉ . In the experiments, we use the Movie-
Lens dataset [ 6,36] which contains 1,793 movies from three genres
“Adventure”, “Animation” and “Fantasy”.
5.2 Image Summarization
This application has also been considered in previous studies includ-
ing [8,23,29,38,62], where the goal is to select a representative set
𝑆of images from a ground set N. The objective function is defined
as a monotone submodular function denoting the “coverage” of 𝑆,
i.e.,
𝑓(𝑆)=∑︁
𝑢∈Nmax
𝑣∈𝑆𝑠𝑢,𝑣,
where𝑠𝑢,𝑣is the cosine similarity between image 𝑢and image
𝑣. Following [ 38,62], the cost𝑐(𝑢)of any image 𝑢is chosen in
proportional to the standard deviation of its pixel intensities, such
that we assign higher costs to images with higher contrast and
lower costs to blurry images. The costs of all images are normalized
such that the average cost is 2. In addition, we also consider the
1The code is available at: https://github.com/cuilakers/KDD2024-FairKnapStream.
521Fairness in Streaming Submodular Maximization
Subject to a Knapsack Constraint KDD ’24, August 25–29, 2024, Barcelona, Spain
(a)Movie Recommendation     
  (f) Maximum Coverage in Social Networks10 100Utility
Budget535545555565
10 100Utility
Budget 10 100Utility
Budget
010203040
10 100Fainess Violations
Budget020406080
10 100Fainess Violations
Budget0306090
10 100Fainess Violations
Budget1.2x105
8x104
4x104
03x104
2x104
1x104
0
(b)Image Summarization (c)Maxim um Coverage in Social Networks
(d)Movie Recommendation (e)Image Summarization
Figure 1: Experimental Results
fairness constraint that the number of images in 𝑆belonging to
any category 𝑡satisfies the upper bound 𝑢𝑡=⌈1.2·𝐵·|N𝑡|
|N|⌉and
lower bound ℓ𝑡=⌈0.8·𝐵·|N𝑡|
|N|⌉. Following [ 8,29,38], we randomly
select 600images from the CIFAR-10 dataset [ 52] in the categories
of airplane, automobile or bird to construct N.
5.3 Maximum Coverage in Social Networks
This application has also been considered in previous studies in-
cluding [ 5,19,20,24–26,71,79]. Given a social network 𝐺=(N,𝐸),
we need to identify a subset of seed nodes 𝑆⊆N that can influence
a large number of users within a budget 𝐵, as formulated by
max{𝑓(𝑆)=|∪𝑢∈𝑆𝑁(𝑢)|:𝑐(𝑆)≤𝐵},
where𝑁(𝑢)={𝑣:(𝑢,𝑣)∈𝐸}denotes the neighbors of 𝑢and𝑓(·)
is a monotone submodular function. Following [ 39,48], each node
𝑢∈N is associated with a non-negative cost 𝑐({𝑢})=1+√︁
𝑑(𝑢),
where𝑑(𝑢)represents the out-degree of 𝑢, and the costs of all nodes
are normalized such that the average cost is 1. We assume thatNis
partitioned into 5disjoint groupsN1,N2,...,N5according to user’s
properties such as ages and political leanings, and we consider the
fairness constraint that the number of nodes in 𝑆belonging to any
group𝑡satisfies the upper bound 𝑢𝑡=⌈1.2·𝐵·|N𝑡|
|N|⌉and the
lower bound ℓ𝑡=⌈0.8·𝐵·|N𝑡|
|N|⌉. In our experiments, we use the
Epinions [56] dataset containing 131,828 nodes and 841,372 edges.
5.4 Experimental Results
In Figure 1, we plot the utilities and fairness violations of the im-
plemented algorithms when the budget varies. The utility achieved
by our FairKnapStream algorithm, as depicted in Figure 1 (a)-(c), is
comparable to, and in some cases, even surpasses that of the baselinealgorithms designed for submodular maximization under knapsack
and/or𝑞-system constraints. Meanwhile, as depicted in Figure 1
(d)-(f), our FairKnapStream algorithm consistently adheres to the
fairness constraint (i.e., strictly satisfying all the fairness bounds
{(𝑙𝑡,𝑢𝑡):𝑡∈ [ℎ]}throughout the experiments. In contrast, all
baseline algorithms significantly violate fairness, highlighting their
ineffectiveness in solving the FSK problem. In summary, the exper-
imental results demonstrate that our FairKnapStream algorithm
can ensure fairness without sacrificing performance on utility, com-
pared to the state-of-the-art streaming algorithms for submodular
maximization with knapsack and/or 𝑞-system constraints.
6 CONCLUSION
We have proposed the first streaming algorithm with provable per-
formance bounds for fair submodular maximization subject to a
knapsack constraint, and have also proposed an improved stream-
ing algorithm for submodular maximization subject to a partition
matroid constraint and a knapsack constraint. The superiorities
of our approaches have been demonstrated both theoretically and
experimentally.
ACKNOWLEDGMENTS
Kai Han’s work is partially supported by the National Natural Sci-
ence Foundation of China (NSFC) under Grant No. 62172384. Feng
Li’s work is supported by NSFC under Grant 62072278, Open Project
of Key Laboratory of Computing Power Network and Information
Security, Ministry of Education, Qilu University of Technology
(Shandong Academy of Sciences) under Grant 2023ZD007. The
work of Shuang Cui is done under the guidance of his supervisor:
Kai Han.
522KDD ’24, August 25–29, 2024, Barcelona, Spain Shuang Cui, Kai Han, Shaojie Tang, Feng Li, and Jun Luo
REFERENCES
[1]Georgios Amanatidis, Federico Fusco, Philip Lazos, Stefano Leonardi, and Rebecca
Reiffenhäuser. 2020. Fast adaptive non-monotone submodular maximization
subject to a knapsack constraint. In Advances in Neural Information Processing
Systems (NeurIPS).
[2]Georgios Amanatidis, Federico Fusco, Philip Lazos, Stefano Leonardi, and Rebecca
Reiffenhäuser. 2022. Fast adaptive non-monotone submodular maximization
subject to a knapsack constraint. Journal of Artificial Intelligence Research (JAIR)
74 (2022), 661–690.
[3]Magda Amiridi, Nikos Kargas, and Nicholas D Sidiropoulos. 2021. Information-
theoretic feature selection via tensor decomposition and submodularity. IEEE
Transactions on Signal Processing 69 (2021), 6195–6205.
[4]Girija Attigeri, MM Manohara Pai, and Radhika M Pai. 2019. Feature selection us-
ing submodular approach for financial big data. Journal of Information Processing
Systems 15, 6 (2019), 1306–1325.
[5]Dmitrii Avdiukhin, Slobodan Mitrović, Grigory Yaroslavtsev, and Samson Zhou.
2019. Adversarially robust submodular maximization under knapsack constraints.
InACM SIGKDD International Conference on Knowledge Discovery and Data
Mining (KDD). 148–156.
[6]Ashwinkumar Badanidiyuru, Amin Karbasi, Ehsan Kazemi, and Jan Vondrák.
2020. Submodular maximization through barrier functions. In Advances in Neural
Information Processing Systems (NeurIPS).
[7]Ashwinkumar Badanidiyuru and Jan Vondrák. 2014. Fast algorithms for maxi-
mizing submodular functions. In ACM-SIAM Symposium on Discrete Algorithms
(SODA). 1497–1514.
[8]Eric Balkanski, Adam Breuer, and Yaron Singer. 2018. Non-monotone submodular
maximization in exponentially fewer iterations. In Advances in Neural Information
Processing Systems (NeurIPS). 2359–2370.
[9]Wei-Xuan Bao, Jun-Yi Hang, and Min-Ling Zhang. 2022. Submodular feature
selection for partial label learning. In ACM Knowledge Discovery and Data Mining
(SIGKDD). 26–34.
[10] Xiaohui Bei, Shengxin Liu, Chung Keung Poon, and Hongao Wang. 2022. Candi-
date selections with proportional fairness constraints. Autonomous Agents and
Multi-Agent Systems 36 (2022), 1–32.
[11] Robert Bredereck, Piotr Faliszewski, Ayumi Igarashi, Martin Lackner, and Pi-
otr Skowron. 2018. Multiwinner elections with diversity constraints. In AAAI
Conference on Artificial Intelligence (AAAI), Vol. 32.
[12] Niv Buchbinder, Moran Feldman, Joseph Naor, and Roy Schwartz. 2014. Sub-
modular maximization with cardinality constraints. In ACM-SIAM Symposium
on Discrete Algorithms (SODA). 1433–1452.
[13] Elisa Celis, Vijay Keswani, Damian Straszak, Amit Deshpande, Tarun Kathuria,
and Nisheeth Vishnoi. 2018. Fair and diverse DPP-based data summarization. In
International Conference on Machine Learning (ICML). 716–725.
[14] L Elisa Celis, Lingxiao Huang, and Nisheeth K Vishnoi. 2018. Multiwinner voting
with fairness constraints. In International Joint Conference on Artificial Intelligence
(IJCAI) . 144–151.
[15] L Elisa Celis, Damian Straszak, and Nisheeth K Vishnoi. 2018. Ranking with
Fairness Constraints. In International Colloquium on Automata, Languages, and
Programming (ICALP).
[16] Yllias Chali, Moin Tanvee, and Mir Tafseer Nayeem. 2017. Towards abstractive
multi-document summarization using submodular function-based framework,
sentence compression and merging. In International Joint Conference on Natural
Language Processing (IJCNLP). 418–424.
[17] Flavio Chierichetti, Ravi Kumar, Silvio Lattanzi, and Sergei Vassilvitskii. 2017.
Fair clustering through fairlets. In Advances in Neural Information Processing
Systems (NeurIPS), Vol. 30.
[18] Flavio Chierichetti, Ravi Kumar, Silvio Lattanzi, and Sergei Vassilvtiskii. 2019.
Matroids, matchings, and fairness. In International Conference on Artificial Intelli-
gence and Statistics (AISTATS). 2212–2220.
[19] Shuang Cui, Kai Han, and He Huang. 2024. Deletion-Robust Submodular Maxi-
mization with Knapsack Constraints. In AAAI Conference on Artificial Intelligence
(AAAI), Vol. 38. 11695–11703.
[20] Shuang Cui, Kai Han, Jing Tang, and He Huang. 2023. Constrained Subset
Selection from Data Streams for Profit Maximization. In International World Wide
Web Conferences (WWW). 1822–1831.
[21] Shuang Cui, Kai Han, Jing Tang, He Huang, Xueying Li, and Zhiyu Li. 2022.
Streaming Algorithms for Constrained Submodular Maximization. In Interna-
tional Conference on Measurement and Modeling of Computer Systems (SIGMET-
RICS).
[22] Shuang Cui, Kai Han, Jing Tang, He Huang, Xueying Li, and Aakas Zhiyuli.
2023. Practical parallel algorithms for submodular maximization subject to
a knapsack constraint with nearly optimal adaptivity. In AAAI Conference on
Artificial Intelligence (AAAI), Vol. 37. 7261–7269.
[23] Shuang Cui, Kai Han, Tianshuai Zhu, Jing Tang, Benwei Wu, and He Huang.
2021. Randomized Algorithms for Submodular Function Maximization with a
𝑘-System Constraint. In International Conference on Machine Learning (ICML).
2222–2232.[24] Paul Dütting, Federico Fusco, Silvio Lattanzi, Ashkan Norouzi-Fard, and Morteza
Zadimoghaddam. 2022. Deletion robust submodular maximization over matroids.
InInternational Conference on Machine Learning (ICML) . 5671–5693.
[25] Marwa El Halabi, Federico Fusco, Ashkan Norouzi-Fard, Jakab Tardos, and Jakub
Tarnawski. 2023. Fairness in streaming submodular maximization over a matroid
constraint. In International Conference on Machine Learning (ICML). 9150–9171.
[26] Marwa El Halabi, Slobodan Mitrović, Ashkan Norouzi-Fard, Jakab Tardos, and
Jakub M Tarnawski. 2020. Fairness in streaming submodular maximization:
Algorithms and hardness. In Advances in Neural Information Processing Systems
(NeurIPS) .
[27] Alina Ene and Huy L Nguyen. 2019. A Nearly-Linear Time Algorithm for Sub-
modular Maximization with a Knapsack Constraint. In International Colloquium
on Automata, Languages and Programming (ICALP), Vol. 132. 53.
[28] Salman Fadaei, MohammadAmin Fazli, and MohammadAli Safari. 2011. Maxi-
mizing non-monotone submodular set functions subject to different constraints:
Combined algorithms. Operations Research Letters 39, 6 (2011), 447–451.
[29] Matthew Fahrbach, Vahab Mirrokni, and Morteza Zadimoghaddam. 2019. Non-
monotone submodular maximization with nearly optimal adaptivity and query
complexity. In International Conference on Machine Learning (ICML). 1833–1842.
[30] Moran Feldman, Christopher Harshaw, and Amin Karbasi. 2017. Greed Is Good:
Near-Optimal Submodular Maximization via Greedy Optimization. In Conference
on Learning Theory (COLT). 758–784.
[31] Moran Feldman, Christopher Harshaw, and Amin Karbasi. 2020. Simultane-
ous greedys: A swiss army knife for constrained submodular maximization.
arXiv:2009.13998 (2020).
[32] Moran Feldman, Christopher Harshaw, and Amin Karbasi. 2023. How do you
want your greedy: Simultaneous or repeated? Journal of Machine Learning
Research (JMLR) 24 (2023), 72–1.
[33] Till Fluschnik, Piotr Skowron, Mervin Triphaus, and Kai Wilker. 2019. Fair
knapsack. In AAAI Conference on Artificial Intelligence (AAAI), Vol. 33. 1941–
1948.
[34] Ashish Goel, Anilesh K Krishnaswamy, Sukolsak Sakshuwong, and Tanja Aita-
murto. 2019. Knapsack voting for participatory budgeting. ACM Transactions on
Economics and Computation (TEAC) 7, 2 (2019), 1–27.
[35] Anupam Gupta, Aaron Roth, Grant Schoenebeck, and Kunal Talwar. 2010. Con-
strained non-monotone submodular maximization: Offline and secretary algo-
rithms. In Conference on Web and Internet Economics (WINE). 246–257.
[36] Ran Haba, Ehsan Kazemi, Moran Feldman, and Amin Karbasi. 2020. Streaming
Submodular Maximization under a 𝑘-Set System Constraint. In International
Conference on Machine Learning (ICML).
[37] Marwa El Halabi, Jakub Tarnawski, Ashkan Norouzi-Fard, and Thuy-Duong
Vuong. 2023. Fairness in Submodular Maximization over a Matroid Constraint.
arXiv preprint arXiv:2312.14299 (2023).
[38] Kai Han, Shuang Cui, Tianshuai Zhu, Enpei Zhang, Benwei Wu, Zhizhuo Yin,
Tong Xu, Shaojie Tang, and He Huang. 2021. Approximation Algorithms for
Submodular Data Summarization with a Knapsack Constraint. In International
Conference on Measurement and Modeling of Computer Systems (SIGMETRICS).
[39] Chris Harshaw, Moran Feldman, Justin Ward, and Amin Karbasi. 2019. Sub-
modular maximization beyond non-negativity: Guarantees, fast algorithms, and
applications. In International Conference on Machine Learning (ICML). 2634–2643.
[40] Jason Hartline, Vahab Mirrokni, and Mukund Sundararajan. 2008. Optimal
marketing strategies over social networks. In International World Wide Web
Conferences (WWW). 189–198.
[41] D Ellis Hershkowitz, Anson Kahng, Dominik Peters, and Ariel D Procaccia. 2021.
District-fair participatory budgeting. In AAAI Conference on Artificial Intelligence
(AAAI), Vol. 35. 5464–5471.
[42] Chien-Chung Huang, Naonori Kakimura, and Yuichi Yoshida. 2020. Streaming
Algorithms for Maximizing Monotone Submodular Functions Under a Knapsack
Constraint. Algorithmica 82 (2020), 1006–1032.
[43] Chien-Chung Huang and Naonori Kakimura. 2018. Multi-pass streaming al-
gorithms for monotone submodular function maximization. arXiv preprint
arXiv:1802.06212 (2018).
[44] Chien-Chung Huang and Naonori Kakimura. 2021. Improved streaming al-
gorithms for maximizing monotone submodular functions under a knapsack
constraint. Algorithmica 83, 3 (2021), 879–902.
[45] Rishabh Iyer, Ninad Khargonkar, Jeff Bilmes, and Himanshu Asnani. 2021. Gen-
eralized submodular information measures: Theoretical properties, examples,
optimization algorithms, and applications. IEEE Transactions on Information
Theory 68, 2 (2021), 752–781.
[46] Pallavi Jain, Krzysztof Sornat, Nimrod Talmon, and Meirav Zehavi. 2021. Par-
ticipatory Budgeting with Project Groups. In International Joint Conference on
Artificial Intelligence (IJCAI). 276–282.
[47] Tianyuan Jin, Yu Yang, Renchi Yang, Jieming Shi, Keke Huang, and Xiaokui
Xiao. 2021. Unconstrained submodular maximization with modular costs: Tight
approximation and application to profit maximization. In International Conference
on Very Large Data Bases (VLDB). 1756–1768.
[48] Ehsan Kazemi, Shervin Minaee, Moran Feldman, and Amin Karbasi. 2021. Regu-
larized submodular maximization at scale. In International Conference on Machine
523Fairness in Streaming Submodular Maximization
Subject to a Knapsack Constraint KDD ’24, August 25–29, 2024, Barcelona, Spain
Learning (ICML). 5356–5366.
[49] David Kempe, Jon Kleinberg, and Éva Tardos. 2003. Maximizing the spread of
influence through a social network. In ACM SIGKDD International Conference on
Knowledge Discovery and Data Mining (KDD). 137–146.
[50] Samir Khuller, Anna Moss, and Joseph Seffi Naor. 1999. The budgeted maximum
coverage problem. Information Processing Letters (IPL) 70, 1 (1999), 39–45.
[51] Andreas Krause and Carlos Guestrin. 2011. Submodularity and its applications
in optimized information gathering. ACM Transactions on Intelligent Systems and
Technology (TIST) 2, 4 (2011), 1–20.
[52] Alex Krizhevsky, Geoffrey Hinton, et al .2009. Learning multiple layers of features
from tiny images. (2009).
[53] Alex Kulesza, Ben Taskar, et al .2012. Determinantal point processes for machine
learning. Foundations and Trends in Machine Learning 5, 2–3 (2012), 123–286.
[54] Ariel Kulik, Hadas Shachnai, and Tami Tamir. 2013. Approximations for mono-
tone and nonmonotone submodular maximization with knapsack constraints.
Mathematics of Operations Research 38, 4 (2013), 729–739.
[55] Jon Lee, Vahab S Mirrokni, Viswanath Nagarajan, and Maxim Sviridenko. 2010.
Maximizing nonmonotone submodular functions under matroid or knapsack
constraints. SIAM Journal on Discrete Mathematics (SIDMA) 23, 4 (2010), 2053–
2078.
[56] Jure Leskovec and Andrej Krevl. 2014. SNAP Datasets: Stanford Large Network
Dataset Collection. https://snap.stanford.edu/data
[57] Jingxuan Li, Lei Li, and Tao Li. 2011. Mssf: a multi-document summarization
framework based on submodularity. In International Conference on Research on
Development in Information Retrieval (SIGIR). 1247–1248.
[58] Jingxuan Li, Lei Li, and Tao Li. 2012. Multi-document summarization via sub-
modularity. Applied Intelligence 37 (2012), 420–430.
[59] Hui Lin and Jeff Bilmes. 2011. A class of submodular functions for document
summarization. In Annual Meeting of the Association for Computational Linguistics
(ACL). 510–520.
[60] Hui Lin and Jeff Bilmes. 2012. Learning mixtures of submodular shells with
application to document summarization. In Conference on Uncertainty in Artificial
Intelligence (UAI). 479–490.
[61] Julián Mestre. 2006. Greedy in approximation algorithms. In European Symposium
on Algorithms. 528–539.
[62] Baharan Mirzasoleiman, Ashwinkumar Badanidiyuru, and Amin Karbasi. 2016.
Fast constrained submodular maximization: Personalized data summarization. In
International Conference on Machine Learning (ICML). 1358–1367.
[63] Baharan Mirzasoleiman, Amin Karbasi, and Andreas Krause. 2017. Deletion-
robust submodular maximization: Data summarization with “the right to be
forgotten”. In International Conference on Machine Learning (ICML) . 2449–2458.
[64] Slobodan Mitrovic, Ilija Bogunovic, Ashkan Norouzi-Fard, Jakub M Tarnawski,
and Volkan Cevher. 2017. Streaming robust submodular maximization: A par-
titioned thresholding approach. In Advances in Neural Information Processing
Systems (NeurIPS).
[65] Sofia Maria Nikolakaki, Alina Ene, and Evimaria Terzi. 2021. An efficient frame-
work for balancing submodularity and cost. In ACM SIGKDD International Con-
ference on Knowledge Discovery and Data Mining (SIGKDD). 1256–1266.
[66] Deval Patel, Arindam Khan, and Anand Louis. 2021. Group Fairness for Knapsack
Problems. In International Conference on Autonomous Agents and MultiAgent
Systems (AAMAS). 1001–1009.
[67] Binghui Peng. 2021. Dynamic influence maximization. In Advances in Neural
Information Processing Systems (NeurIPS), Vol. 34. 10718–10731.
[68] Shaojie Tang and Jing Yuan. 2023. Beyond submodularity: a unified framework
of randomized set selection with group fairness constraints. Journal of Combina-
torial Optimization 45, 4 (2023), 102.
[69] Shaojie Tang, Jing Yuan, and Twumasi Mensah-Boateng. 2023. Achieving long-
term fairness in submodular maximization through randomization. arXiv preprint
arXiv:2304.04700 (2023).
[70] Sebastian Tschiatschek, Rishabh K Iyer, Haochen Wei, and Jeff A Bilmes. 2014.
Learning mixtures of submodular functions for image collection summarization.
InAdvances in Neural Information Processing Systems (NeurIPS), Vol. 27.
[71] Yanhao Wang, Francesco Fabbri, and Michael Mathioudakis. 2021. Fair and
representative subset selection from data streams. In International World Wide
Web Conferences (WWW). 1340–1350.
[72] Kai Wei, Yuzong Liu, Katrin Kirchhoff, Chris Bartels, and Jeff Bilmes. 2014. Sub-
modular subset selection for large-scale speech training data. In IEEE International
Conference on Acoustics, Speech and Signal Processing (ICASSP). 3311–3315.
[73] Laurence A Wolsey. 1982. Maximising real-valued submodular functions: Primal
and dual heuristics for location problems. Mathematics of Operations Research 7,
3 (1982), 410–425.
[74] Keshou Wu, Lei Li, Jingxuan Li, and Tao Li. 2013. Ontology-enriched multi-
document summarization in disaster management using submodular function.
Information Sciences 224 (2013), 118–129.
[75] Grigory Yaroslavtsev, Samson Zhou, and Dmitrii Avdiukhin. 2020. “bring your
own greedy”+ max: Near-optimal 1/2-approximations for submodular knapsack.
InInternational Conference on Artificial Intelligence and Statistics (AISTATS). 3263–
3274.[76] Baosheng Yu, Meng Fang, Dacheng Tao, and Jie Yin. 2016. Submodular asymmet-
ric feature selection in cascade object detection. In AAAI Conference on Artificial
Intelligence (AAAI), Vol. 30.
[77] Qilian Yu, Li Xu, and Shuguang Cui. 2018. Streaming algorithms for news and
scientific literature recommendation: Monotone submodular maximization with
a𝑑-knapsack constraint. IEEE Access 6 (2018), 53736–53747.
[78] Jing Yuan and Shaojie Tang. 2023. Group fairness in non-monotone submodular
maximization. Journal of Combinatorial Optimization 45, 3 (2023), 88.
[79] Guangyi Zhang, Nikolaj Tatti, and Aristides Gionis. 2022. Coresets remem-
bered and items forgotten: submodular maximization with deletions. In IEEE
International Conference on Data Mining (ICDM).
A OMITTED PROOFS
A.1 Proof of Lemma 4.13
Proof. According to Line 14-20 of Algorithm 3, we have
𝑓(𝑆𝑖,𝑥)−𝑓(𝑆𝑖−1,𝑥)=𝑓(𝑆𝑖−1,𝑥\{𝑣𝑖,𝑥}∪{𝑒𝑖})−𝑓(𝑆𝑖−1,𝑥)
=𝑓(𝑒𝑖|𝑆𝑖−1,𝑥\{𝑣𝑖,𝑥})+𝑓(𝑆𝑖−1,𝑥\{𝑣𝑖,𝑥})−𝑓(𝑆𝑖−1,𝑥)
=𝑓(𝑒𝑖|𝑆𝑖−1,𝑥\{𝑣𝑖,𝑥})− 𝑓(𝑆𝑖−1,𝑥)−𝑓(𝑆𝑖−1,𝑥\{𝑣𝑖,𝑥})
=𝑓(𝑒𝑖|𝑆𝑖−1,𝑥\{𝑣𝑖,𝑥})−𝑓(𝑣𝑖,𝑥|𝑆𝑖−1,𝑥\{𝑣𝑖,𝑥})
≥𝑓(𝑒𝑖|𝑆𝑖−1,𝑥)−𝑓(𝑣𝑖,𝑥|𝑆𝑖−1,𝑥\{𝑣𝑖,𝑥})
≥𝑓(𝑒𝑖|𝑆𝑖−1,𝑥)−𝑓(𝑣𝑖,𝑥|𝑆<𝑣𝑖,𝑥
𝑖−1,𝑥)
≥(𝛼−1)𝑓(𝑣𝑖,𝑥|𝑆<𝑣𝑖,𝑥
𝑖−1,𝑥)≥0,
where the first and second inequalities are due to submodularity
and the fact that 𝑆<𝑣𝑖,𝑥
𝑖−1,𝑥⊆𝑆𝑖−1,𝑥\{𝑣𝑖,𝑥}; the last inequality is due
to the fact that the marginal gain of any element previously added
into the candidate solution is non-negative, a consequence of the
positive threshold 𝜏used in Line 9 of Algorithm 3. □
A.2 Proof of Lemma 4.14
Proof. By applying Lemma 4.13 along with submodularity, we
can derive
𝑓(𝑈𝑥)−𝑓(𝑆𝑛,𝑥)≤∑︁
𝑣𝑖,𝑥∈𝑈𝑥\𝑆𝑛,𝑥𝑓(𝑣𝑖,𝑥|𝑆𝑛,𝑥)
≤∑︁
𝑣𝑖,𝑥∈𝑈𝑥\𝑆𝑛,𝑥𝑓(𝑣𝑖,𝑥|𝑆<𝑣𝑖,𝑥
𝑖−1,𝑥)
≤∑︁
𝑣𝑖,𝑥∈𝑈𝑥\𝑆𝑛,𝑥𝑓(𝑆𝑖,𝑥)−𝑓(𝑆𝑖−1,𝑥)
𝛼−1
=∑︁
𝑖∈[𝑛]𝑓(𝑆𝑖,𝑥)−𝑓(𝑆𝑖−1,𝑥)
𝛼−1
=𝑓(𝑆𝑛,𝑥)−𝑓(𝑆0,𝑥)
𝛼−1≤𝑓(𝑆𝑛,𝑥)
𝛼−1(4)
□
A.3 Proof of Lemma 4.15
Proof. For the element 𝑒𝑖∈𝑀∩𝑈2, we must have 𝑓(𝑒𝑖|𝑈1)≤
𝑓(𝑒𝑖|𝑆𝑖−1,1)≤𝑓(𝑒𝑖|𝑆𝑖−1,2)due to the greedy rule in Line 18 of
Algorithm 3.
By submodularity, we have
𝑓(𝑀∩𝑈2|𝑈1)≤∑︁
𝑒𝑖∈𝑀∩𝑈2𝑓(𝑒𝑖|𝑈1)
≤∑︁
𝑒𝑖∈𝑀∩𝑈2𝑓(𝑒𝑖|𝑆𝑖−1,1)≤∑︁
𝑒𝑖∈𝑀∩𝑈2𝑓(𝑒𝑖|𝑆𝑖−1,2)
 
524KDD ’24, August 25–29, 2024, Barcelona, Spain Shuang Cui, Kai Han, Shaojie Tang, Feng li, and Jun Luo
Algorithm 4: MatKnapStream (without pre-access to 𝜏)
Input: number𝜆>1;
1𝑄∗←∅;
2while there is an incoming element 𝑒do
3 if𝑓({𝑒})>𝑓(𝑄∗)then𝑄∗←{𝑒};
4 Γ←{( 1+𝜖)𝑧:𝑧∈Z∧𝑓(𝑄∗)
(1+𝜖)𝜆𝐵≤(1+𝜖)𝑧≤𝑓(𝑒)
𝑐(𝑒)};
5 Delete any existing copy of Algorithm 3 whose
𝜏∉[𝑓(𝑄∗)
(1+𝜖)𝜆𝐵,𝑓(𝑄∗)];
6 foreach𝜏′∈Γdo
7 Create a new copy of Algorithm 3 by setting 𝜏=𝜏′
if such a copy does not exist;
8 Pass𝑒to the copy of Algorithm 3 get the current
best solution 𝑄𝜏′from the copy;
9 if𝑓(𝑄𝜏′)>𝑓(𝑄∗)then𝑄∗←𝑄𝜏′;
10return𝑄∗
≤∑︁
𝑒𝑖∈𝑈2𝑓(𝑒𝑖|𝑆𝑖−1,2),
where the last inequality is due to the positive threshold 𝜏at Line 9
of Algorithm 3. Furthermore, we can use submodularity and Eqn. (4)
to get∑︁
𝑒𝑖∈𝑈2\𝑆𝑛,2𝑓(𝑒𝑖|𝑆𝑖−1,2)+∑︁
𝑒𝑖∈𝑆𝑛,2𝑓(𝑒𝑖|𝑆𝑖−1,2)
≤∑︁
𝑒𝑖∈𝑈2\𝑆𝑛,2𝑓(𝑒𝑖|𝑆<𝑒𝑖
𝑖−1,2)+∑︁
𝑒𝑖∈𝑆𝑛,2𝑓(𝑒𝑖|𝑆<𝑒𝑖
𝑛,2)
≤𝑓(𝑆𝑛,2)
𝛼−1+𝑓(𝑆𝑛,2).
By combining all of the above and applying similar reasoning to
𝑓(𝑀∩𝑈1|𝑈2), we can conclude the lemma. □
A.4 Proof of Lemma 4.16
Proof. Combining Lemma 4.8-4.15, we have
𝑓(𝑀∪𝑈1)≤𝛼
𝛼−1𝑓(𝑆𝑛,1)+𝑓(𝑀)
𝜆+𝛼·𝑓(𝑆𝑛,1)+𝛼
𝛼−1𝑓(𝑆𝑛,2)
≤𝛼2+𝛼
𝛼−1𝑓(𝑆∗)+𝑓(𝑀)
𝜆
Similarly, we can derive 𝑓(𝑀∪𝑈2)≤𝛼2+𝛼
𝛼−1𝑓(𝑆∗)+𝑓(𝑀)
𝜆. Com-
bining these results with Eqn. (3), we finally obtain:
𝑓(𝑀)≤2𝛼2+2𝛼
𝛼−1𝑓(𝑆∗)+2
𝜆𝑓(𝑀)The lemma is concluded by rearranging the inequality above. □
A.5 Proof of Lemma 4.20
Proof. Combining Lemma 4.8-4.15 and the fact that 𝑈2=∅
when the objective function is monotone, we have
𝑓(𝑀∪𝑈1)≤𝛼
𝛼−1𝑓(𝑆𝑛,1)+𝑓(𝑀)
𝜆+𝛼·𝑓(𝑆𝑛,1)
≤𝛼2
𝛼−1𝑓(𝑆∗)+𝑓(𝑀)
𝜆.
Since the objective function is monotone, we have 𝑓(𝑀∪𝑈1)≥
𝑓(𝑀), which competes the proof. □
BMATKNAPSTREAM WITHOUT PRE-ACCESS
TO𝜏
Theorem B.1. The solution returned by Algorithm 4 is at least
as good as the solution returned by Algorithm 3 with 𝜏=𝜏∗, where
𝜏∗∈[𝑓(𝑀)
(1+𝜖)𝜆𝐵,𝑓(𝑀)
𝜆𝐵].
Proof. Let’s denote 𝑣as the first element in the stream that
satisfies the condition𝑓({𝑣})
𝑐(𝑣)>𝑓(𝑀)
𝜆𝐵. The existence of such an
element𝑣is guaranteed since𝑓(𝑀)
𝑐(𝑀)≥𝑓(𝑀)
𝐵>𝑓(𝑀)
𝜆𝐵, given that
𝜆>1.
Our first claim is that after processing the arrival of 𝑣, Algorithm
4 creates a copy of Algorithm 3 using 𝜏=𝜏∗, and this copy would
not be deleted. This can be explained as follows:
𝜏∗≥𝑓(𝑀)
(1+𝜖)𝜆𝐵≥𝑓(𝑄∗𝑣)
(1+𝜖)𝜆𝐵,
𝜏∗≤𝑓(𝑀)
𝜆𝐵<𝑓({𝑣})
𝑐(𝑣)≤𝑓({𝑣})≤𝑓(𝑄∗
𝑣),
where𝑓(𝑄∗𝑣)is the value of 𝑓(𝑄∗)after processing 𝑣. This implies
that𝜏∗∈Γmust be created and the copy with 𝜏=𝜏∗should not be
deleted by Line 5.
Our second claim is that all elements arriving before 𝑣are not
eligible to be added to the candidate solutions maintained by the
copy using𝜏=𝜏∗. Specifically, for every element 𝑒arriving before
𝑣, we have:
𝑓(𝑒|𝑆)
𝑐(𝑒)≤𝑓({𝑒})
𝑐(𝑒)<𝑓({𝑣})
𝑐(𝑣)for any𝑆⊆N.
Therefore, without meeting the threshold requirement (Line 9 of
Algorithm 3), 𝑒is discarded by the copy of Algorithm 3 with 𝜏=𝜏∗.
Combining all the above reasoning, we can conclude that the
solution returned by Algorithm 4 is at least as good as that returned
by Algorithm 3 with 𝜏=𝜏∗, thus completing the proof. □
 
525