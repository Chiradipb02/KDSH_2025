Learning Causal Networks from Episodic Data
Osman Mian◦
osman.mian@cispa.de
CISPA Helmholtz Center for
Information Security
Saarbrücken, GermanySarah Mameche◦
sarah.mameche@cispa.de
CISPA Helmholtz Center for
Information Security
Saarbrücken, GermanyJilles Vreeken
vreeken@cispa.de
CISPA Helmholtz Center for
Information Security
Saarbrücken, Germany
ABSTRACT
In numerous real-world domains, spanning from environmental
monitoring to long-term medical studies, observations do not arrive
in a single batch but rather over time in episodes. This challenges the
traditional assumption in causal discovery of a single, observational
dataset, not only because each episode may be a biased sample
of the population but also because multiple episodes could differ
in the causal interactions underlying the observed variables. We
address these issues using notions of context switches and episodic
selection bias, and introduce a framework for causal modeling
of episodic data. We show under which conditions we can apply
information-theoretic scoring criteria for causal discovery while
preserving consistency. To in practice discover the causal model
progressively over time, we propose the Continent algorithm
which, taking inspiration from continual learning, discovers the
causal model in an online fashion without having to re-learn the
model upon arrival of each new episode. Our experiments over a
variety of settings including selection bias, unknown interventions,
and network changes showcase that Continent works well in
practice and outperforms the baselines by a clear margin.
CCS CONCEPTS
•Mathematics of computing →Causal networks; Informa-
tion theory; •Theory of computation →Online algorithms .
KEYWORDS
Causal Discovery, Continual Learning, Selection Bias
ACM Reference Format:
Osman Mian, Sarah Mameche, and Jilles Vreeken. 2024. Learning Causal
Networks from Episodic Data. In Proceedings of the 30th ACM SIGKDD
Conference on Knowledge Discovery and Data Mining (KDD ’24), August
25–29, 2024, Barcelona, Spain. ACM, New York, NY, USA, 12 pages. https:
//doi.org/10.1145/3637528.3671999
1 INTRODUCTION
Determining causality is of fundamental interest throughout the
sciences [ 30]. As controlled experiments are often not feasible, the
◦Both authors contributed equally to this research.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
KDD ’24, August 25–29, 2024, Barcelona, Spain
©2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 979-8-4007-0490-1/24/08
https://doi.org/10.1145/3637528.3671999𝑆+:
warm
𝑆−:
cold
0 50 100 1500102030
𝑋2: ozone (𝜇𝑔
𝑚3)𝑋1:
temperature (◦𝐶)𝐸1: November
𝐸2: February
𝐸3: June
𝐸4: October
Figure 1: Cause 𝑋1and effect 𝑋2[29] measured in episodes
over time(𝐸1-𝐸4). Each episode comes from an underlying
season(𝑆+,𝑆−), and an unknown context, here Switzerland.
question of how to do so given observational data alone is gaining
increased attention. Classical algorithms for discovering causal
networks assume as their starting point a single, homogeneous
dataset sampled from a single, stationary distribution [6, 30, 39].
However, a more realistic setting is one where we obtain obser-
vations in batches over time. Not only does this mean that we need
to learn and update our causal hypothesis over time, but each batch
likely contains samples from a specific time period or subpopulation,
resulting in a biased distribution. Even the collective data distribu-
tion over allsuch episodes is often not identically distributed since
the causal interactions could differ across domains.
To motivate the episodic setting and illustrate its challenges, con-
sider an example in environmental monitoring where we measure
two markers 𝑋1:temperature and𝑋2:ozone concentration at differ-
ent times of the year. Suppose we obtain monthly measurements,
resulting in episodes {𝐸1,...𝐸 4}at timepoints{𝑡1,...𝑡4}as shown
in Fig. 1. In our example taken from the Tübingen cause-effect
pairs [ 29],𝑋1is considered the cause of 𝑋2and the overall data
suggest a roughly linear trend of the causal mechanism relating
them. Considering a winter month such as 𝐸1(blue) on its own
would however suggest that both variables are uncorrelated. Only
when including the summer month 𝐸3(yellow) do we obtain a com-
plete picture. In this example, there is a high-temperature season 𝑆+
(circle) as well as a low-temperature season 𝑆−(star), and episodes
coming from only one such season offer a biased picture.
This simplistic example suggests that combining all episodes is
a good practice to remove seasonal bias. This however can lead to
its own set of issues. Consider a dataset that stems from a differ-
ent geographical region or context, where due to local measuring
devices noise levels are different, or even the underlying causal
relationship changes. For instance, a phenomenon known as ozone
suppression [ 42] creates a situation where ozone levels are no longer
 
2224
KDD ’24, August 25–29, 2024, Barcelona, Spain Osman Mian, Sarah Mameche, and Jilles Vreeken
positively correlated with temperature. As ozone suppression only
occurs above a certain temperature threshold, it is not visible in
the data obtained in Switzerland shown in Fig. 1 but could affect
a dataset𝐸5from a region with exceptionally high temperatures.
Overall, whereas episodes 𝐸1−𝐸4should be combined to remove
seasonal bias, combining samples from different contexts 𝐸1−𝐸5
obscures context-specific causal relationships [44].
While recent work in causal discovery considers different con-
texts [ 28,40,44], it neither addresses episodes nor allows for struc-
tural changes in the causal model across contexts. In contrast, we
propose a causal modeling framework for episodes with selection
bias where an unknown number of causal networks underlie the
data-generating process. We show that in principle, we can use a
consistent scoring criterion for causal discovery in this setting so
long as we observe sufficiently many episodes.
From a practical perspective, existing algorithms for causal dis-
covery [ 6,27,30] start from a single batch of data and hence would
need to relearn the causal model whenever a new episode arrives.
This is clearly computationally impractical; rather, it would be de-
sirable for a domain expert to gain preliminary insights into the
causal relationships based on some earlier episodes and perenially
update these as new data becomes available.
Given these limitations, we develop the Continent algorithm
for discovering causal models over episodic data, more specifi-
cally multiple fully directed causal networks over a set of contexts.
Taking inspiration from continual learning, we hereby avoid fully
re-learning the causal model upon the arrival of each episode but
learn it in an online fashion. We propose a strategy to update
the causal hypothesis as new episodes arrive, using distribution
matching and an information-theoretic perspective of causality,
and show that our updating strategy is consistent. We show in
experiments that Continent discovers causal networks reliably
from data with episodic selection bias, under interventions, as well
as with structural changes in causal networks. Not only does it
compare favorably to its competitors, but only Continent is able
to learn the causal model adaptively over time. It can also address
an experimental setting where we assign a new, unseen episode to
one of the causal networks inferred from previous episodes.
Contributions. To summarize our main contributions, we
•introduce a causal modeling framework for episodic data,
•show under which conditions we can use an information-
theoretic consistent scoring criterion to identify a set of
causal networks underlying such data,
•develop the practical approach Continent to learn such
causal networks in a continual fashion,
•confirm in experiments that Continent works in practice.
We structure our exposition according to the above, first introduc-
ing notation and preliminaries, then introducing our causal model
and practical algorithm, and concluding with an experimental eval-
uation and discussion.
2 PRELIMINARIES
First, we outline our problem setting and review causal modeling
techniques for independent and identically distributed (i.i.d.) data.2.1 Notation and Problem Setting
Throughout our work, we consider a batch setting where we ob-
tain observations as a sequence of datasets {𝐸0,...,𝐸𝑁}at time-
points{𝑡0,...,𝑡𝑁}, and refer to dataset 𝐸𝑖at time𝑡𝑖as an episode.
We denote the dataset that combines all episodes up to time 𝑡𝑖as
𝐷𝑁=∪𝑁
𝑖=1𝐸𝑖.In each episode, we observe a fixed set of continuous
random variables 𝑋={𝑋1,...,𝑋𝑀}with distribution 𝑃(𝑋).
Episodes can belong to different domains or environments, which
we call contexts denoted by{𝐶0,...,𝐶𝑅}. Each episode 𝐸𝑖is a mem-
ber of a unique context 𝐶𝑟, which we write as 𝐶(𝐸𝑖), and we write
𝑋𝑟,𝑃𝑟to refer to variables, resp. distributions, in the 𝑟th context.
Novel to our work is that we neither know how many contexts 𝑅
exist nor which context 𝐶(𝐸𝑖)each episode comes from.
In addition to coming from different contexts, episodes are not
necessarily i.i.d. but rather could preferentially include samples
from a certain subpopulation 𝑆. To illustrate, consider the warm
season𝑆+in Fig. 1. Episode 𝐸3exhibits selection bias in that it
only includes i.i.d. samples from this season. We can represent 𝑆+
through a binary variable 𝑆with values 𝑆=◦,𝑆=∗, with the
interpretation that samples 𝑆=◦are observed, 𝑆=∗are missing
from𝐸3, so that it follows a biased distribution. In general, we
consider a categorical variable 𝑆with values{𝑠1,...,𝑠𝐾}modeling
subpopulations of 𝑃(𝑋), so that each episode results from selecting
an unknown population 𝑠𝑘and sampling from 𝑃(𝑋|𝑆=𝑠𝑘). As
we could obtain multiple episodes from the same subpopulation,
for example repeated monthly episodes over multiple years, we do
not assume the number 𝐾≤𝑁to be known a priori.
In this episodic setting, we want to discover how many and
which causal models there are.
Problem Statement (Informal). Given datasets{𝐸0,...,𝐸𝑁}
where each episode 𝐸𝑖is generated from the causal model in an un-
known context 𝐶𝑟and by conditioning on an unknown value 𝑠𝑘of𝑆,
we want to discover the set of causal models over 𝑋.
Before we address this problem, we take a step back to address
causal discovery in an i.i.d. setting and introduce the concepts and
assumptions that we build on.
2.2 Causal Discovery
For now, consider the case of a single context without selection bias.
We can specify a causal model over the variables 𝑋by a directed
acyclic graph (DAG) 𝐺=(𝑋,𝐸)with node set 𝑋and edges(𝑖,𝑗)∈𝐸
whenever the variable 𝑋𝑖is a cause of 𝑋𝑗[30]. To denote the set
of direct causes of 𝑋𝑗we write pa𝑗where we leave 𝐺implicit.
Together with the network structure in 𝐺, we assume a structural
causal model over the variables, where each effect is generated from
its causes through a causal function or mechanism 𝑓𝑗,
𝑋𝑗=𝑓𝑗(pa𝑗,𝑁𝑗)
where𝑁𝑗is a noise variable implicit in 𝐺with𝑁𝑗⊥⊥𝑋𝑗.
A causal model is identifiable when we can determine it uniquely
from an observational distribution [ 30]. In general, identifiability
of the causal DAG 𝐺is only possible under additional assumptions.
Hence, we assume causal sufficiency, which states that no latent
variable jointly causes any of the observed variables, as well as the
causal Markov andfaithfulness conditions, which together imply
 
2225Learning Causal Networks from Episodic Data KDD ’24, August 25–29, 2024, Barcelona, Spain
that edge separations in the graphical model 𝐺correspond to inde-
pendence constraints in the observed distribution 𝑃. Under these
assumptions, it is well known that identifiability holds up to the
Markov Equivalence Class (MEC) of 𝐺[10].
Identification of causal directions beyond the MEC is possible
using additional information about how the system reacts to inter-
ventions [ 11,22,44]. In the absence of such information, we need to
make additional assumptions, such as restricting the functional de-
pendencies 𝑓to nonlinear functions with additive noise [ 5,12,25].
As an example of this approach, a family of methods build on the
algorithmic framework of causation [ 14] and derive consistent scor-
ing criteria that can be used for causal discovery within a given
class of functional models. This is the approach we will follow here.
2.3 Information-theoretic Causal Discovery
The algorithmic model of causation [ 14] reasons about the complex-
ity of causal mechanisms in describing the observed data. To this
end, it uses the concept of Kolmogorov complexity. Kolmogorov
complexity defines, for binary strings 𝑥∈{0,1}∗, the length 𝐾(𝑥)
of the shortest binary program 𝑥∗that outputs 𝑥and halts. The Kol-
mogorov complexity 𝐾(𝑃)over a distribution 𝑃defines the length
of the shortest program 𝑝∗that approximates 𝑃up to precision 𝑞
on a universal Turing machine Ugiven input⟨𝑥,𝑞⟩[18],
𝐾(𝑃)=min
𝑝∗∈{0,1}∗{|𝑝∗|:U⟨𝑥,𝑞⟩−𝑃(𝑥)|≤1
𝑞}.
Using Kolmogorov complexity, we can state the centerpiece of
the algorithmic view of causal networks, namely the Algorithmic
Markov Condition (AMC) [14].
Algorithmic Markov Condition. The AMC postulates that causal
mechanisms correspond to programs that encode the observed
distributions most concisely in terms of Kolmogorov complexity.
More precisely, it assumes that each causal mechanism 𝑓𝑗for a
given𝑋𝑗can be described by a program 𝑝𝑗that independently
generates the distribution 𝑃(𝑋𝑗|pa𝑗). The AMC posits that the
complexity of the overall distribution 𝑃(𝑋)corresponds to the
summed complexities over these independent programs,
𝐾(𝑃(𝑋))+=𝑀∑︁
𝑗=1𝐾 𝑃(𝑋𝑗|pa𝑗)(1)
which holds up to a constant, i.e. the complexities can differ by that
of a program with constant length.
Causal Discovery using the AMC. Kolmogorov complexity cannot
be computed for arbitrary programs [ 18], but can be approximated
from above via Minimum Description Length (MDL) [ 9] for a fixed
model class. Eq. (1)is therefore commonly stated for a flexible class
of functions, such as non-parametric regression models.
In detail, MDL defines a description length 𝐿of𝑋together with
its optimal causal model 𝐺∗, given by
𝐿(𝑋;𝐺∗)=𝐿(𝐺∗)+∑︁
𝑋𝑗∈𝐺∗(𝑋𝑗|pa𝑗,𝐺∗). (2)
The score𝐿(𝑋;𝐺)is given by the length, in bits, of first encoding
the model itself and then encoding the data under the model. Specif-
ically,𝐿(𝐺)encodes the network structure of 𝐺and the functional
relationships 𝑓𝑗using a model class of choice with MDL score 𝐿(𝑓𝑗).The remaining term poses according to the causal factorization
and describes each variable 𝑋𝑗from its causal parents pa𝑗. Using𝐿,
Eq.(1)suggests estimating the causal model as the one minimizing
the overall description length 𝐿(𝑋;𝐺).
Various instantiations of 𝐿exist, addressing, for example, the
bivariate [ 24] and multivariate case [ 27], latent confounding [ 16],
and interventional data [ 21,22,26]. Throughout this work, we
assume a given score 𝐿that decomposes as in Eq. 2 and is consistent
in the sense that it allows estimating a DAG 𝐺∼𝐺∗that is Markov
equivalent to 𝐺∗in the limit, lim𝑛→∞𝑃(ˆ𝐺∼𝐺∗)=1for i.i.d. data
with sample size 𝑛. We refer to Mian et al . [27] for definitions of 𝐿
in a multivariate setting and a consistent algorithm for discovering
𝐺in from an i.i.d. data distribution. As consistency results and
practical algorithms have only been explored in the i.i.d. case [ 27]
or interventional data [22, 26], we turn to episodic data here.
3 THEORY
In this section, we introduce our causal model for episodic data.
3.1 Causal Model
Our causal model comprises a set of causal DAGs G={𝐺1,...,𝐺𝑅}
over a common set of variables 𝑋∪{𝑆}, where𝑋are measured,
continuous random variables of interest, and 𝑆is an unmeasured
categorical variable with values 𝑆={𝑠1,...,𝑠𝐾}. Each DAG 𝐺𝑟is
a causal model over 𝑋𝑟, i.e., it describes the causal relationships
in all episodes from a given context 𝐶𝑟. The additional variable 𝑆
models that certain observations may be missing in each episode.
To do so, we extend upon a missingness framework commonly
used to handle selection bias [ 2,35]. To explain, consider the 𝑛th
observation, where we represent 𝑆using a one-hot encoding,
 𝑋(𝑛)
1,...,𝑋(𝑛)
𝑀,𝑠(𝑛)
1,...,𝑠(𝑛)
𝐾
where we suppress the dependency on the context to avoid clutter.
Above,𝑋(𝑛)is associated to indicators 𝑠𝑘where𝑠𝑘=1if𝑋(𝑛)is
observed, else 𝑠𝑘=0if it is missing in a distribution 𝑘. We obtain𝐾
biased distributions 𝑃(𝑋|𝑆=𝑠𝑘)of which episodes are subsamples.
Exactly which samples are observed could depend on 𝑋; in Fig. 1,
for instance, 𝑆+=◦holds for the temperature range 𝑋1≥10. In
general, we assume that any unknown mechanism assigns 𝑆,
𝑆=𝑔(𝑋,𝑁𝑠), 𝑁𝑠⊥⊥𝑆 ,
where𝑔maps each sample to an assignment of 𝑆using input 𝑋,
which is noisy through 𝑁𝑠. We therefore include 𝑆in the causal
model together with edges 𝑋𝑗→𝑆for all𝑋𝑗, and assume that 𝑆is
a sink node. We include a node 𝑆𝑟in𝐺𝑟in each𝐶𝑟with the same 𝐾
for simplicity, although our framework can be extended to include
a dependency 𝐾𝑟. We assume causal sufficiency over 𝑋𝑟∪{𝑆}.
To summarize, our causal model is the following.
Assumption 3.1 (Causal model with contexts and selection). Our
causal model is given by a set of DAGs G={𝐺1,...,𝐺𝑅}over
𝑋∪{𝑆}from a finite number of contexts 𝑅such that in context 𝐶𝑟,
each observed variable 𝑋𝑗is generated as
𝑋𝑟
𝑗=𝑓𝑟
𝑗(pa𝑟
𝑗,𝑁𝑟
𝑗), 𝑁𝑟
𝑗⊥⊥𝑋𝑟
𝑗,
 
2226KDD ’24, August 25–29, 2024, Barcelona, Spain Osman Mian, Sarah Mameche, and Jilles Vreeken
where pa𝑟
𝑗denote the causal parents of 𝑋𝑟
𝑗in𝐺𝑟and𝑁𝑟
𝑗is an
independent noise term. The latent variable 𝑆is generated as
𝑆𝑟=𝑔𝑟(𝑋𝑟
𝑗,𝑁𝑟
𝑠), 𝑁𝑟
𝑠⊥⊥𝑆𝑟.
The above describes an unbiased generating process where each
variable𝑋𝑗is a function of its causal parents pa𝑗and noise𝑁𝑗.
In addition, the mechanism 𝑔with noise𝑁𝑠generates𝑆. This
generating process happens independently in each context.
We assume that episodes result from conditioning on a specific
value of the unobserved selection variable.
Assumption 3.2 (Episodic data). Under the causal model in As-
sumption 3.1, after generating an unbiased distribution 𝑃𝑟(𝑋,𝑆)
from the DAG 𝐺𝑟in each context 𝐶𝑟, all episodes 𝐸coming from
context𝐶(𝐸)=𝐶𝑟have distribution 𝑃𝑟(𝑋|𝑆=𝑠𝑘)for some
specific𝑠𝑘∈{𝑠1,...,𝑠𝐾}.
With no assumption on the selection mechanism 𝑔, number of
contexts𝑅, or number of selection regions 𝐾, our model can en-
compass general cases of episodic data. This invariably also makes
it more challenging to discover the causal model from data. To do
so, we first state the algorithmic Markov condition for our model.
Postulate 3.3 (Algorithmic Markov Condition). Under Assump-
tions 3.1 and 3.2, a set of causal DAGs G={𝐺1,...,𝐺𝑅}is only
admissible as the causal hypothesis over 𝑋and𝑆if
𝐾 𝑃 𝑋∪{𝑆}+=𝑅∑︁
𝑟=1𝑀∑︁
𝑗=1𝐾 𝑃𝑟(𝑋𝑗|pa𝑗)+𝐾(𝑃𝑟(𝑆|𝑋))
+=𝐾 𝑃(𝑋)+𝐾 𝑃(𝑆|𝑋)
where+=holds up to an additive constant.
As𝑆is not included in any parent set, we can in principle consider
the complexity of, and hence causal structure over, 𝑋independently
of the complexity of 𝑆. This motivates the idea of using a consistent
scoring criterion to find the causal structure over 𝑋in each context.
As a complication, we hereby need to discover the number of
contexts. Suppose we obtained data 𝐷𝑛accumulated over 𝑛episodes.
There could be any number 𝑅of different causal models, with 1≤
𝑅≤𝑛. Thus, we need to consider any partition of our samples into
𝑅disjoint sets, which we write as Π(𝐷𝑛)={𝑋1,...𝑋𝑅}. In each
set, we propose discovering the causal DAG using the consistent
score𝐿(𝑋𝑟;𝐺), and overall find the partition minimizing this score.
To summarize, our objective is as follows.
Problem Statement. Given variables 𝑋and data𝐷𝑛over𝑛
episodes, we aim to discover the partition Π(𝐷𝑛)of𝐷𝑛into contexts
and the causal model ˆ𝐺𝑟in each context minimizing
min
Π(𝐷)|Π(𝐷)|∑︁
𝑟=1min
𝐺𝑟𝐿(𝑋𝑟;𝐺𝑟). (3)
where we write 𝑋𝑟for the data in the 𝑟-th set of Π(𝐷).
This leaves us with two questions; first, ensuring that the above
is a consistent way of identifying the causal model, and second,
how to efficiently minimize it in practice.3.2 Asymptotic Guarantees
We first want to establish conditions under which 𝐿can be used in
a consistent way to discover the causal DAGs in all contexts.
This revolves around whether the biased distributions in each
episode eventually allow us to estimate the relevant distributions
in Postulate 3.3 in an unbiased way so that we can apply Eq. (3).
That is, estimation of each causal mechanism should not depend on
the selection variable. We hence make the following assumption.
Assumption 3.4 (Ignorability). Under the causal model in As-
sumption 3.1 and given 𝐷𝑁over𝑁episodes, in each context 𝐶𝑟,
we assume the following ignorability of selection bias,
𝑋𝑟
𝑗⊥⊥𝑆𝑟|Z𝑟
for each𝑋𝑟
𝑗and conditioning set Z𝑟⊆𝑋𝑟\{𝑋,
𝑗𝑆𝑟}.
Examples of when the above holds are cases known as Missing
At Random (MAR) or Missing Completely At Random (MCAR)
[2,3,35], for example, when a biased 𝑃(𝑋|𝑆=𝑠𝑘)is a uniform
sample from the population 𝑃(𝑋). A more realistic case is the one
in Fig. 1 where the selection mechanism depends on temperature
𝑋1. We can see that episodes from the cold season 𝑃(𝑋|𝑆=∗)
indeed do not allow an unbiased view of the causal mechanism,
however once we obtain enough episodes from both 𝑆−,𝑆+then
ignorability holds. More generally, we ensure via Assumption 3.4
that we eventually obtain enough samples from the support of 𝑋.
With this, we can show that an MDL-based score 𝐿can be used
for causal discovery with unknown contexts.
Theorem 3.5 (Consistency of 𝐿in the episodic setting). For the
causal model in Assumption 3.1 and given data 𝐷𝑛over𝑛episodes as
in Assumption 3.2, under Assumption 3.4, a consistent scoring criterion
𝐿that decomposes as in Eq. 2 remains consistent,
lim
|𝐷𝑛|→∞𝑃(ˆ𝐺𝑟∼𝐺∗
𝑟)=1 for all𝑟∈{1,...,𝑅}.
However, this does not make it obvious how to apply 𝐿in practice.
First, note that the result relies on enough episodes being observed
so that selection is ignorable, that is, we did not yet address how
to deal with non-ignorable selection at each time point when we
only observed a subset of episodes. Second, even when observing
enough episodes, searching over the space of DAGs to minimize 𝐿
as in Eq. 3 is prohibitive even for a single causal model due to the
super-exponential search space over DAGs [ 6]. While there exist
greedy algorithms to do so, such as the MDL-based Globe , applying
such methods to any partition of the data with an unknown number
of contexts is not favorable as it could violate the i.i.d. assumption
required for these methods. To address these issues, we propose an
algorithm for causal discovery over episodic data in the following.
4 ALGORITHM
In this section, we introduce our algorithm Continent.
4.1 Overview
To motivate our algorithm setup, let us revisit our motivating ex-
ample in Fig. 1 showing episodes obtained in winter 𝐸1, spring𝐸2,
summer𝐸3, and autumn 𝐸4. We consider a fixed number of seasons,
here𝑆+,𝑆−. All episodes 𝐸1-𝐸4shown come from a context 𝐶1but
any number of future episodes could arrive from a different 𝐶2.
 
2227Learning Causal Networks from Episodic Data KDD ’24, August 25–29, 2024, Barcelona, Spain
Algorithm 1: Continent(𝐸,A,T)
input : episodes𝐸arriving over time, residual test T,
causal discovery algorithm Awith score𝐿
output: causal model G={𝐺1,...𝐺𝑅}
1G←{}
2𝜏←0
3while a new episode 𝐸𝑖arrives do
4 G←Update(G,𝐸𝑖,A,T)
5𝜏←𝜏+1
6 if𝜏≥𝜏maxthen
7 G←Merge(G,A,T)
8𝜏←0
9 end
10end
11G←Merge(G,A)
12return G
Given a learnerAfor greedy DAG search with a consistent scor-
ing criterion 𝐿, we aim to discover the underlying causal DAG 𝐺1
over𝐸1-𝐸4, and possibly add a causal model 𝐺2if future episodes
from a different 𝐶2arrive. ApplyingAto all episodes at each time
point is not only impractical, but may also not be consistent given
that selection bias is not ignorable until all episodes arrive. In-
stead, we propose an algorithm Continent that maintains plau-
sible causal models G={𝐺1,...,𝐺𝑅}at each time 𝑡𝑖and uses a
strategy for updating Gwhen a new episode 𝐸𝑖+1arrives.
Model Updating. In our example, say that we obtained episodes
𝐸1-𝐸3and the current causal model is G={𝐺1}. As we already
observed episodes from both seasons 𝑆+resp.𝑆−we likely already
learned an unbiased model 𝐺1. As the autumn episode 𝐸4arrives,
we want to assign it to 𝐺1without re-learning the causal model
from scratch. To this end, we propose using a two-sample testing
procedureTto decide whether a given episode matches an existing
causal model. Here, after checking with Tthat𝐸1-𝐸4can be stacked
we combine the data 𝐸1-𝐸4and keep the model 𝐺1as is.
On the other hand, say episode 𝐸5from a different context 𝐶2
arrives1andTdecides that it does not match any current causal
model. Then we apply the learner Ato learn a new model 𝐺2over
𝐸5and add it to our set of models, G={𝐺1,𝐺2}.
Note that the above assumes that we already learned an unbiased
causal model over the available episodes. We also need to consider
the case where a causal model is biased, such that we need to update
it after merging data from multiple episodes.
Model Merging. Say that we observed episodes 𝐸1-𝐸2to learn
a causal model 𝐺0. From the winter seasons 𝑆−alone, it appears
that𝑋1,𝑋2are uncorrelated, hence 𝐺0is biased. When 𝐸3from
summer season 𝑆+arrives, we need to merge the data to the previous
episodes and learn a new model 𝐺1.
To do this, we attempt merging data over multiple episodes at
regular time intervals. We again apply Tto check whether a merge
is possible, and if so, check whether merging any two causal models
1This could be e.g. readings obtained from a different geographical region where causal
mechanism between 𝑋1and𝑋2is different/non-existent.Algorithm 2: TestResidualEq(𝐺𝑟,𝐸𝑖,𝐷,T)
input : causal model 𝐺, episode𝐸𝑖, data𝐷, residual testT
output: test result
1foreach𝑋𝑗with parent set Zin𝐺do
2𝑝𝑗←T.Test(𝐻0:𝑃𝐷(𝑋𝑗|Z)≡𝑃𝑖(𝑋𝑗|Z);𝛼)
3end
4p←T.Correct({𝑝1,...𝑝𝑀})
5ifT.Significant(p)return True else return False
results in an improved model, judging by our score 𝐿. As stacking
may be sufficient when we already gained sufficient evidence for a
candidate model, in practice, we attempt merging at regular time
intervals using a pre-specified tolerance parameter 𝜏max.
Combining the model updating and model merging described
above, we have our proposed approach, Continent .
Continent .We show the pseudocode of Continent in Alg. 1.
We maintain a set of models Gthroughout, where we associate
each𝐺∈Gto a dataset 𝐷of episodes, initially empty (Line 1).
As new episodes arrive, we update Gat each time step using
theUpdate function (Line 4). In short, it checks using hypothesis
testing whether a new episode 𝐸𝑖matches the data 𝐷under an
existing model, in which case we stack the datasets 𝐸𝑖and𝐷; else
we applyAto𝐸𝑖to discover a new model 𝐺𝑖which we add to G.
We show our hypothesis test in Alg. 2, and Update in the appendix.
After a pre-specified number of episodes, we attempt merging
existing models (Line 7), with a tolerance parameter 𝜏keeping
track of the time since a merge last happened (Line 8). In essence,
Merge performs pairwise comparison of models 𝐺,𝐺′. If appro-
priate, it learns a new model 𝐺∪after pooling the resp. datasets
𝐷,𝐷′of the pair. During the algorithm, we only allow such a merge
ifTmarks the residual distributions of 𝐷,𝐷′as compatible, for
which we again apply our hypothesis test in Alg. 2. We include the
pseudocode for Merge in Appendix B.
Our alternation of updating and merging continues as long as
new episodes arrive. We conclude with a final merge (Line 11).
Compared to merge steps throughout our algorithm which we
protect byT, we consider all remaining possible merges of model
pairs𝐺,𝐺′in this step given that no more episodes arrive (Line 11).
4.2 Consistency
Naturally, we want to make sure that our adaptive strategy is con-
sistent. At any time point 𝑡𝑖, however, we only have access to a
subset of the episodes so that ignorability in Assumption 3.4 un-
likely holds, and hence any causal model inferred using Amay be
incorrect. Nevertheless, we need to avoid merging episodes with
different underlying models. We now show that we can do so with-
out knowing the true models. To do so, we assume a hypothesis
testTtesting
𝐻0:𝑃1(𝑋𝑗|Z)≡𝑃2(𝑋𝑗|Z)
for a given variable 𝑋𝑗, conditioning set Zand two datasets 𝑃1,𝑃2.
Given any causal DAG, we test 𝐻0for each variable given its es-
timated parent set and include a multiple testing correction, as
 
2228KDD ’24, August 25–29, 2024, Barcelona, Spain Osman Mian, Sarah Mameche, and Jilles Vreeken
shown in Alg. 2. We can show that our updating strategy protected
by this test is consistent under the following condition.
Assumption 4.1 (Detectable selection) .We assume that selection
detectable for a variable 𝑋𝑗and pair of contexts 𝐶𝑟,𝐶′𝑟meaning
𝑃𝑟(𝑋𝑗|pa𝑗)≠𝑃𝑟′(𝑋𝑗|pa𝑗)
⇒𝑃𝑟(𝑋𝑗|pa𝑗,𝑆=𝑠𝑘)≠𝑃𝑟′(𝑋𝑗|pa𝑗,𝑆=𝑠𝑘)
holds for each value 𝑠𝑘of𝑆.
Unlike ignorability in Assumption 3.4 which requires full inde-
pendence of the causal mechanism and selection mechanism, that
is, ensures that we can estimate the causal mechanism for each
variable in a fully unbiased way, Assumption 4.1 only requires that
distribution differences of 𝑃(𝑋)hold also in the biased distribution
𝑃(𝑋|𝑆=𝑠𝑘). Given that the latter are subsamples of the overall
distribution, this is reasonable in practice. With this, we can show
that our updating strategy is consistent.
Theorem 4.2 (Consistency of updating using T).With discrepancy
testTwe will never merge a new episode 𝐸𝑖+1with a set ˆ𝑋𝑟from an
incorrect context where 𝐶(𝐸𝑖+1)≠𝐶(𝐸)for some𝐸∈ˆ𝑋𝑟.
This shows that our updating step is safe in the sense that we
always discover subsets of the correct contexts. When we observed
all episodes, we can also recover the exact sets of contexts if ignor-
ability holds, based on Thm. 3.5.
Corollary 4.3 (Consistency of Continent ).Given a consistent
DAG search algorithm Aand score𝐿, under assumption 3.4 our
algorithm is consistent, so that
lim
|𝐷𝑛|→∞𝑃(ˆ𝐺𝑟∼𝐺𝑟∗)=1 for all𝑟∈{1...,𝑅}
holds after we obtain 𝑛episodes𝐷𝑛and perform the merge step.
As the final step in this section, we address practical considera-
tions around our algorithm.
4.3 Instantiation
We conclude this section by giving details on the components of
Continent .
Causal Discovery Algorithm A.We assume a score-based causal
discovery algorithm Athat allows discovering a causal DAG 𝐺
from an i.i.d. dataset 𝐷. While in principle, this could be any score-
based method with a consistent scoring criterion 𝐿decomposing
according to Eq. (2), we use an MDL-based approach in our practical
instantiation as it allows for a principled way for model comparison.
We instantiateAwith Globe [27] which is an efficient algorithm
for discovering causal networks. It models causal functions through
non-parametric multivariate regression with additive noise.
Residual TestT.Our method can also work together with any
hypothesis testTfor differences in conditional distributions under
a causal model. As Globe models causal functions through non-
parametric spline regression, a natural choice is testing residual
distributions under a given model for equality. As we apply a test
per each variable, we perform Bonferroni correction to obtain a
𝑝-value from the test results {𝑝1,...,𝑝𝑀}. Unless otherwise stated,
we apply the non-parametric Kolmogorov-Smirnov [ 1,38] test in
our evaluations.5 RELATED WORK
Discovering causal models that faithfully describe the interactions
between variables of interest given observational data alone is an
actively studied problem and finds applications in almost all areas of
science. Approaches to do so typically fall into the categorizations
of constraint-based methods, such as PC [ 30], or score-based meth-
ods, such as GES [ 6,34]. As these approaches discover a Markov
Equivalence Class (MEC) of the causal DAG [ 10], recent approaches
study under which assumptions we can determine causal directions
beyond the MEC. One line of work does so by constraining the
functional model [ 5,33], such as LiNGAM [ 37] which assumes lin-
ear non-Gaussian models. Another branch of work builds on the
algorithmic model of causality [ 14], such as Globe [27]. However,
the examples given up to this point assume an i.i.d. data distribution
where a single causal network can capture the causal interactions,
and where neither selection bias nor contexts exist.
Selection Bias. Missingness is a well-studied problem in statistical
inference and in particular, many approaches exist for correcting
for missingness and selection bias [ 4,8,43]; see Little and Rubin
[19] for an overview. Only very recent work studies assumptions
foridentifying whether selection bias holds in a given dataset [ 17].
Our perspective is different as we are interested in adapting causal
discovery to the presence of missingness. An important line of work
studies recoverability [3,31] from selection bias in causal discovery,
modeled through unobserved sink node 𝑆in the causal graph. We
also adopt this model here using multiple missingness regions, and
in addition consider the presence of multiple contexts in the form
of varying causal mechanisms.
Different Contexts. A wealth of recent literature studies causal
discovery from different environments, experimental regimes, or
contexts [ 13,20,40,44]; prominent examples include the constraint-
based JCI framework [ 28], additive noise model based multi-group
Lingam [36], and score-based approaches [ 7,21,22,26] for discov-
ering causal DAGs from multi-context data. While studies of latent
confounding in such data exist [ 23], latent selection remains under-
explored. In particular, existing work assumes that each context is
an identically distributed (i.i.d.) sample with fixed causal model. We
make this setting more general in that we obtain biased samples
from each context, which need to be combined to result in i.i.d. data.
To our knowledge, we are the first to allow a different causal model
with episodical bias in different contexts, and also address the algo-
rithmic challenges associated with discovering causal networks in
an online fashion.
To demonstrate how classical and environment-based causal
discovery approaches fare with episodical selection bias in practice,
we next compare them against Continent.
6 EVALUATION
Since to the best of our knowledge, there is no specific algorithm
designed for causal discovery from continually arriving episodic
data, we look at the nearest possible modifications of existing al-
gorithms for comparison. As baseline we compare to Globe [27],
Resit [33] and Ges[6,34]. We modify these algorithms as follows
— we first learn a causal network over each individual incoming
 
2229Learning Causal Networks from Episodic Data KDD ’24, August 25–29, 2024, Barcelona, Spain
00.20.40.60.8100.20.40.60.81
×××
×××
ShdSid Continent
Globe
Ges
Lingam
Resit
Jci-P
c
00.20.40.60.81F1Continent Globe Ges
Resit Lingam Jci-P
c
Figur e2:Normalize dShd andSid[Left, Closer toorigin
isbetter ]and Orientation F1[Right, Higher isbetter ]for
netw orks learne doverepiso dicdata with selection bias.
00.20.40.60.8100.20.40.60.81
××××××
ShdSid Continent
Globe
Ges
Resit
Lingam
Jci-P
c
00.20.40.60.81F1Continent Globe Ges
Resit Lingam Jci-P
c
Figur e3:Normalize dShd andSid[Left, Closer toorigin isbet-
ter]andOrientation F1[Right, Higher isbetter ]fornetw orks
learne doverepiso dicdata with unkno wninter ventions.
episo deofdata, andthen take aunion overtheedges. This iscor-
rect,under theassumption underlying each ofthese appr oaches,
that each episo decomes fromthesame causal netw ork[26].We
also compar etomulti-envir onment causal disco veryappr oaches
such astheJCI-frame work[28]using thePcalgorithm [39],aswell
asMulti-Gr oupLingam (Lingam )[36].Thelatter twoapproaches,
however,requirethatallepiso desareavailable tolearn acausal net-
work.Hence ,weprovide allepiso desinonegotothese approaches.
This constitutes anadvantage astheycanlearn fromcomplete data.
Tomeasur ethequality ofthepredicte dcausal structur eswe
usetheStructural Hamming Distance (Shd)[15],theStructural
Inter vention Distance (Sid)[32],aswellastheOrientation- F1score
overlearne dnetw orks. Shd counts thenumb erofedges wher ethe
predicte dcausal netw orkdiffers fromthetrue causal netw ork,Sid
counts pairs ofvariables forwhich inter vention estimation differs
acrosspredicte dresp.true causal netw orkandtheF1scoreallows
ustoseehowaccurately edges areoriente dinthelearne dnetw ork.
Next,wediscuss results overbothsynthetic andreal-w orld data.
6.1 Synthetic Data
Foreach oftheproposedexperiment setups, wegenerate random
graphs using Erdős-Rényi modelfornetw orksizes𝑑={5,10,15},
andgenerate data foreffectsusing functions ofthefollowing form,
𝑋𝑖=Í
𝑥∈𝑝𝑎𝑖𝑓(𝑥)+N𝑖,wher e𝑓(𝑥)iseither apolynomial function
oracombination ofsine andcosine functions define dovereach
parent𝑥∈𝑝𝑎𝑖of𝑋𝑖,andN𝑖iseither Gaussian orUniform. For
each graph/function combination, wegenerate atotal of10,00012345678910010203040
𝑒Shd𝑑=5𝑑=10
𝑑=15
12345678910010203040
𝑒Shd
Figur e4:[Lowerisbetter ]Change inShd overincreasing
numb erofepiso des𝑒fordata with selection bias (left) and
unkno wninter ventions (right) forgraph sizes𝑑={5,10,15}.
123456789100123456
𝑒Mo
delCount𝑑=5𝑑=10
𝑑=15
123456789100123456
𝑒Mo
delCount
Figur e5:ModelCount overincreasing episo des𝑒fordata
with selection bias (left) anddata with (unkno wn)inter ven-
tions (right) forgraphs ofsize𝑑={5,10,15}.Ther eare1resp.
3true underlying models for bias resp. intervention cases.
samples andthen split them into 10episo desofsize1000 each.
Wetransmit these episo destoeach algorithm oneatatime.After
each episo de,wenote theupdatedcausal netw orkforeach ofthe
metho ds.AsJci-P candLingam areprovidedallepiso destogether ,
weonly measur eperformance overthefinal netw ork.
Primarily ,weinvestigate thefollowing questions.
Q1CanContinent reliably disco vercausal netw orks when the
incoming episo descome fromthesame underlying causal
netw ork?
Q2HowwelldoesContinent perform when episo descontain
unkno wninter ventions?
Q3CanContinent identify causal netw orks fromepiso dicdata
containing different causal mechanisms?
Q4HowdoesContinent ’sperformance change overtime as
episo desarriv e?
AsContinent isdesigne dwithout theassumption that each
data comes fromthesame underlying causal netw ork,ittherefore
maintains alistofcandidate netw orks forgroups ofepiso des.For
comparability toother approaches, weforceContinent topredict
asingle causal netw orkforcases𝑄1and𝑄2bytaking aunion over
theedges incandidate models[26].Wefurther provide ananalysis
oftheindividually learne dcausal netw orks forevaluation in𝑄3.
Werelease allourcodeanddata forresear chpurp oses2.Next,we
showresults foreach ofthefour questions.
2https://eda.rg.cispa.io/prj/continent/
 
2230KDD ’24, August 25–29, 2024, Barcelona, Spain Osman Mian, Sarah Mameche, and Jilles Vreeken
Experiment Nodes Shd Sid F1
Interventions5 0.23 0.15 0.68
10 0.25 0.34 0.54
15 0.29 0.50 0.43
Mechanism
Changes5 0.21 0.15 0.74
10 0.26 0.38 0.64
15 0.36 0.65 0.41
Table 1: Normalized Shd [Lower is better], normalized Sid
[Lower is better] and Orientation F1[Higher is better] for
networks predicted by Continent for held-out episodes for
interventional data as well as mechanism changes.
Q1. Identical Networks. We first test all methods on the cases
where each incoming episode comes from the same underlying
causal network, both for i.i.d. as well as selection bias. Interesting
for us is the latter where episodes can contain selection bias. We
generate this case by choosing a variable at random from our dataset
and sorting the entire data over that variable before splitting the
data into episodes and transmitting it. We show the results for this
in Fig 2 where we see that Continent shows superior performance
to the competition. Continent not only discovers causal network
structurally closer to the ground truth, but also clearly performs
well when orienting the edges as can be seen by the F1score in
Fig. 2. This shows that Continent performs well under selection
bias. We provide the results for i.i.d. data in the appendix.
Q2. Interventions. After our sanity check using i.i.d. data and
dominant performance over data with selection bias, we level up
the difficulty by introducing episodes that contain interventions.
To do so, we generate 3datasets. The first dataset is observational,
whereas for the other two, we select a subset of at most log2(𝑑)
variables and perform a 𝑑𝑜-intervention [ 30] on that subset, before
generating the data. This gives us data sampled from three different
distributions. We further split each of these datasets into episodes
before transmitting them. We never provide information about
these interventions to any of the methods beforehand.
We show the results of this experiment in Fig. 3, where we see
that while Globe degrades slightly, Continent’s performance
does not degrade compared to the setup in 𝑄1.Continent , in fact,
continues to clearly outperform the competition.
Q3. Changing Mechanisms. As the next challenging step, we in-
troduce episodes containing different causal networks/mechanisms
over the same variables. This rules out using any of our competitors
as they can not handle such data. To evaluate Continent in this
setting, we additionally generate a hold-out set of episodes that we
do not learn over. Once Continent has learned over the training
episodes, we try to predict the causal network for hold-out episodes,
without learning it explicitly, using the existing learned models.
We do so by simply taking the model that compresses this hold-out
episode best (Eq. (1)) and comparing the predicted network to the
ground truth. We show the results in Table. 1 where we observe
thatContinent continues to perform well overall for 𝑑=5,10,
and at least structurally for 𝑑=15. We see that for this challenging00.20.40.60.8100.20.40.60.81
××××
××
ShdSidContinent
Globe
Ges
Resit
Lingam
Jci-P
c
00.20.40.60.81F1Continent Globe
Ges Resit
Lingam Jci-P
c
Figur e6:Normalize dShd andSid[Left, Closer toorigin is
better ]andOrientation F1[Right, Higher isbetter ]fornet-
works learne dReged Lung cancer gene expression dataset.
setting with changing mechanisms, Continent canfindareason-
able skeleton (lowerShd)butconflicting mechanisms cause itto
getedgedirections wrongmoreoften (higher Sid).Nevertheless,
weseethatContinent’s performance doesnotdegrade massiv ely
compar edtoprevious settings, eveninthischallenging case.
Q4.Performance overtime.Wemeasur ehowtheindividual mod-
elspresent inside Continent evolveovertime.Tothat end, we
showhowtheShd (Fig. 4)aswellasthemodelcount (Fig. 5)pro-
gresses aswereceivenewepiso des.Forthecase ofShd,wefindthat
Continent always ends upwith alowerShd atthefinal episo de,
than theoneitstarts with, thiseffectismoreprofound fornetw orks
ofsize𝑑=15than𝑑=5asitmight behardertoidentify thecorrect
netw orkoveralarger numb erofvariables inthebeginning. We
seethatContinent isable toimpr oveasthenumb erofepiso des
increase.Fordata with selection bias, weseethatContinent keeps
onaverage 2models throughout thelearning asshowninFig.5.
Moreinter estingly Continent ends upconv erging toalmost 3
modelsforinter ventional data asshowninFig.5,which isexactly
theactual numb erofdiffer entnetw orks present acrossepiso des.
6.2 Lung cancer gene expression data
After measuring theefficacy ofourapproach using synthetic data,
weturn to(pseudo) real-w orldReged dataset [41]containing 20,000
samples over500variables forlung cancer gene-e xpressions. We
split thesamples into tennon-o verlapping episo desandconsider
twonon-o verlapping netw orks ofsizes𝑑=5,15within theground
truth networkandrunatotal of10experiments asfollows.First, we
randomly chooseasubset of5episo des,merge them andintroduce
selection bias overthestacke ddata akin to𝑄2,beforesplitting
itback. Weshowtheresults forReged 5intheappendix andfor
Reged 15inFig.6wher eonce again Continent comes outontop.
7DISCUSSION AND CONCLUSION
Ourinter estinthisworkisdetermining causality when data arriv es
progressiv elyovertime inmultiple episo des,each representing sub-
samples ofthepopulation orsubregions ofthedata that needto
bepooledtogether toavoidbias. Atthesame time,weaddressthat
thecausal relationships may notbestationar yovertime,andtreat
episo desfromdiffer entconte xtsunder aseparate causal model.
Toaddressthissetting, weproposeacausal modeloverasetof
latent conte xtsleading toasetofdiffer entcausal netw orks, aswell
 
2231Learning Causal Networks from Episodic Data KDD ’24, August 25–29, 2024, Barcelona, Spain
as model episodic bias through a hidden selection variable. We
show that information-theoretic scoring criteria remain consistent
for this model in the limit if we obtain sufficiently many episodes
so that selection bias becomes ignorable. To address the more re-
alistic setting where episodes arrive one by one over time with
non-ignorable selection bias, we propose the Continent algorithm
to learn the causal model adaptively over time. It maintains a set of
causal networks over all episodes and incorporates new episodes
into the model, using a residual testing strategy to avoid combining
episodes from different contexts.
Our experimental results show that our method performs reliably
in the presence of selection bias, under unknown interventions, and
even when different causal models underlie the data-generating
process, which to our knowledge no existing methods can address.
Future directions of our work include addressing non-ignorability
further by using correction or extrapolation techniques, and ad-
dressing practical considerations such as the instantiation choices.
REFERENCES
[1]KOLMOGOROV AN. 1933. Sulla determinazione empirica di una legge didis-
tribuzione. Giorn Dell’inst Ital Degli Att 4 (1933), 89–91.
[2]Elias Bareinboim and Judea Pearl. 2012. Controlling Selection Bias in Causal
Inference. In AISTATS, Vol. 22. PMLR, 100–108.
[3]Elias Bareinboim, Jin Tian, and Judea Pearl. 2014. Recovering from Selection Bias
in Causal and Statistical Inference. AAAI 28, 1 (2014).
[4]P Boeken, Noud de Kroon, Mathijs de Jong, Joris M. Mooij, and Onno Zoeter.
2023. Correcting for selection bias and missing response in regression using
privileged information. In UAI. PMLR, 195–205.
[5]Peter Bühlmann, Jonas Peters, Jan Ernest, et al .2014. CAM: Causal additive
models, high-dimensional order search and penalized regression. Annals Stat. 42,
6 (2014), 2526–2556.
[6]David Maxwell Chickering. 2002. Optimal structure identification with greedy
search. JMLR 3 (2002), 507–554.
[7]Daniel Eaton and Kevin Murphy. 2007. Exact Bayesian structure learning from
uncertain interventions. In AISTATS. PMLR, 107–114.
[8]Arthur Gretton, Alex Smola, Jiayuan Huang, Marcel Schmittfull, Karsten Borg-
wardt, and Bernhard Schölkopf. 2008. Covariate Shift by Kernel Mean Matching.
InDataset Shift in Machine Learning. The MIT Press.
[9] Peter Grünwald. 2007. The Minimum Description Length Principle. MIT Press.
[10] Alain Hauser and Peter Bühlmann. 2013. Jointly interventional and observational
data: Estimation of interventional Markov equivalence classes of directed acyclic
graphs. J. R. Statist. Soc. B 77 (03 2013).
[11] Alain Hauser and Peter Bühlmann. 2014. Two optimal strategies for active
learning of causal models from interventional data. International Journal of
Approximate Reasoning 55, 4 (jun 2014), 926–939.
[12] Patrik Hoyer, Dominik Janzing, Joris M Mooij, Jonas Peters, and Bernhard
Schölkopf. 2009. Nonlinear causal discovery with additive noise models. In
NeurIPS, Vol. 21. Curran.
[13] Amin Jaber, Murat Kocaoglu, Karthikeyan Shanmugam, and Elias Bareinboim.
2020. Causal discovery from soft interventions with unknown targets: Charac-
terization and learning. Advances in neural information processing systems 33
(2020).
[14] D. Janzing and B. Schölkopf. 2010. Causal Inference Using the Algorithmic
Markov Condition. IEEE TIT 56, 10 (2010), 5168–5194.
[15] Markus Kalisch and Peter Bühlmann. 2007. Estimating high-dimensional directed
acyclic graphs with the PC-algorithm. JMLR 8, Mar (2007), 613–636.
[16] David Kaltenpoth and Jilles Vreeken. 2019. We Are Not Your Real Parents: Telling
Causal from Confounded using MDL. In SDM. SIAM, 199–207.
[17] David Kaltenpoth and Jilles Vreeken. 2023. Identifying Selection Bias from
Observational Data. AAAI (2023), 8177–8185.[18] M. Li and P. Vitányi. 2009. An Introduction to Kolmogorov Complexity and its
Applications. Springer.
[19] Roderick Little and Donald Rubin. 2019. Statistical Analysis with Missing Data,
Third Edition. (04 2019). https://doi.org/10.1002/9781119482260
[20] Sara Magliacane, Thijs van Ommen, Tom Claassen, Stephan Bongers, Philip
Versteeg, and Joris M Mooij. 2018. Domain Adaptation by Using Causal Inference
to Predict Invariant Conditional Distributions. In NIPS, Vol. 31.
[21] Sarah Mameche, David Kaltenpoth, and Jilles Vreeken. 2022. Discovering Invari-
ant and Changing Mechanisms from Data. In KDD. ACM, 1242–1252.
[22] Sarah Mameche, David Kaltenpoth, and Jilles Vreeken. 2023. Learning Causal
Mechanisms under Independent Changes. In NeurIPS.
[23] Sarah Mameche, Jilles Vreeken, and David Kaltenpoth. 2024. Identifying Con-
founding from Causal Mechanism Shifts. In International Conference on Artificial
Intelligence and Statistics. PMLR, 4897–4905.
[24] Alexander Marx and Jilles Vreeken. 2019. Identifiability of Cause and Effect using
Regularized Regression. In KDD. ACM.
[25] Alexander Marx and Jilles Vreeken. 2021. Formally Justifying MDL-based Infer-
ence of Cause and Effect. arXiv preprint arXiv:2105.01902 (2021).
[26] Osman Mian, Michael Kamp, and Jilles Vreeken. 2023. Information-theoretic
causal discovery and intervention detection over multiple environments. In
AAAI-23.
[27] Osman Mian, Alexander Marx, and Jilles Vreeken. 2021. Discovering fully ori-
ented causal networks. In AAAI.
[28] Joris M Mooij, Sara Magliacane, and Tom Claassen. 2016. Joint causal inference
from multiple contexts. JMLR 21 (2016).
[29] Joris M. Mooij, J. Peters, Dominik Janzing, Jakob Zscheischler, and Bernhard
Scholkopf. 2014. Distinguishing Cause from Effect Using Observational Data:
Methods and Benchmarks. ArXiv abs/1412.3773 (2014).
[30] Judea Pearl. 2009. Causality: Models, Reasoning and Inference (2nd ed.). Cambridge
University Press.
[31] Judea Pearl. 2012. A solution to a class of selection bias problems. (2012).
[32] Jonas Peters and Peter Bühlmann. 2015. Structural intervention distance for
evaluating causal graphs. Neural computation 27, 3 (2015), 771–799.
[33] Jonas Peters, Joris M. Mooij, Dominik Janzing, and Bernhard Schölkopf. 2014.
Causal Discovery with Continuous Additive Noise Models. JMLR 15 (2014).
[34] Joseph Ramsey, Madelyn Glymour, Ruben Sanchez-Romero, and Clark Glymour.
2017. A million variables and more: the Fast Greedy Equivalence Search algorithm
for learning high-dimensional graphical causal models, with an application to
functional magnetic resonance images. J. Data Sci. Anal. (2017).
[35] Donald B. Rubin. 1976. Inference and missing data. Biometrika 63, 3 (1976),
581–592.
[36] Shohei Shimizu. 2012. Joint estimation of linear non-Gaussian acyclic models.
Neurocomputing 81 (2012).
[37] Shohei Shimizu, Patrik O. Hoyer, Aapo Hyvärinen, and Antti Kerminen. 2006. A
Linear Non-Gaussian Acyclic Model for Causal Discovery. JMLR 7 (2006).
[38] Nickolay Smirnov. 1948. Table for estimating the goodness of fit of empirical
distributions. The annals of mathematical statistics 19, 2 (1948), 279–281.
[39] Peter Spirtes, Clark N Glymour, Richard Scheines, and David Heckerman. 2000.
Causation, prediction, and search. MIT Press.
[40] Chandler Squires, Yuhao Wang, and Caroline Uhler. 2020. Permutation-based
causal structure learning with unknown intervention targets. In UAI. PMLR,
1039–1048.
[41] Alexander Statnikov, Sisi Ma, Mikael Henaff, Nikita Lytkin, Efstratios Efstathiadis,
Eric R. Peskin, and Constantin F. Aliferis. 2015. Ultra-Scalable and Efficient
Methods for Hybrid Observational and Experimental Local Causal Pathway
Discovery. JMLR 16 (2015), 3219–3267.
[42] Allison L. Steiner, Adam J. Davis, Sanford Sillman, Robert C. Owen, Anna M.
Michalak, and Arlene M. Fiore. [n. d.]. Observed suppression of ozone forma-
tion at extremely high temperatures due to chemical and biophysical feedbacks.
Proceedings of the National Academy of Sciences ([n. d.]).
[43] Masashi Sugiyama, Matthias Krauledat, and Klaus-Robert Müller. 2007. Covariate
Shift Adaptation by Importance Weighted Cross Validation. J. Mach. Learn. Res.
8 (dec 2007), 985–1005.
[44] Kun Zhang, Biwei Huang, Jiji Zhang, Clark Glymour, and Bernhard Schölkopf.
2017. Causal discovery from nonstationary/heterogeneous data: Skeleton estima-
tion and orientation determination. In IJCAI.
 
2232KDD ’24, August 25–29, 2024, Barcelona, Spain Osman Mian, Sarah Mameche, and Jilles Vreeken
A THEORY
We provide the technical details of our results in the following.
For ease of exposition, we separate out the case of a single context with one causal model in Thm. 3.5 and show it first.
Lemma A.1 (Consistency of 𝐿for a single causal model). Assume a causal model in Assumption 3.1 with one context 𝐶,𝑅=1, and true causal
DAG𝐺∗in𝐶. Given data 𝐷𝑛over𝑛episodes from 𝐶as in Assumption 3.2, under Assumption 3.4, a consistent scoring criterion 𝐿that decomposes
as in Eq. 2 remains consistent,
lim𝑛→∞𝑃(ˆ𝐺∼𝐺∗)=1.
Proof.
In the underlying causal model in assumption 3.1 with 𝑅=1, consider data 𝐷∗𝑛from the true causal DAG 𝐺∗over𝑋∪{𝑆}where𝑆is
observed. By consistency of 𝐿, we know that
lim
|𝐷∗𝑛|→∞𝑃(𝐺∗∼arg min
𝐺𝐿(𝑋∪{𝑆};𝐺))=1.
Using that𝐿is decomposable as in Eq. 2, we can write
min
𝐺𝐿(𝑋∪{𝑆};𝐺)=min
𝐺(𝑋,𝑆)
𝐿(𝐺(𝑋,𝑆))+𝑀∑︁
𝑗=1𝐿(𝑋𝑗|pa𝑗(𝐺))+𝐿(𝑆|𝑋)
=min
𝐺(𝑋)
𝐿(𝐺(𝑋))+𝑀∑︁
𝑗=1𝐿(𝑋𝑗|pa𝑗(𝐺))
+min
𝐺(𝑆|𝑋)
𝐿(𝐺(𝑆|𝑋))+𝐿(𝑆|𝑋)
= min
𝐺(𝑋)𝐿(𝑋;𝐺(𝑋))+ min
𝐺(𝑆|𝑋)𝐿(𝑆;𝐺(𝑆|𝑋))).
Above, we separated the graph structure 𝐺into two subgraphs: 𝐺(𝑋)over𝑋, and𝐺(𝑆|𝑋)which includes 𝑆as well as all edges towards it.
We can do so as 𝑆is a sink node and 𝐿is decomposable. Hence, when 𝑆is observed, the subgraph 𝐺(𝑋)can be identified with our objective
by construction. As 𝑆is unobserved, however, we only access data 𝐷𝑛over𝑛episodes inducing a biased distribution ˜𝑋. In that case, assume
we obtain a different minimiser ˜𝐺=min𝐺(˜𝑋)𝐿(˜𝑋;𝐺)with ˜𝐺≁𝐺∗and𝐿(˜𝑋;˜𝐺)<𝐿(𝑋;𝐺∗). Then for at least one 𝑋𝑗,pa𝑗(˜𝐺)≠pa𝑗(𝐺∗).
Due to ignorabiliy in Assumption 3.4, ˜𝑋𝑗⊥⊥𝑆|Zholds for the conditioning sets Z1=˜pa𝑗(˜𝐺)andZ2=˜pa𝑗(𝐺∗), therefore𝑆does not affect
the local score for ˜𝑋𝑗given either conditioning set. That is, 𝐿(˜𝑋𝑗|˜pa𝑗(𝐺∗))=𝐿(𝑋𝑗|pa𝑗(𝐺∗))<𝐿(𝑋𝑗|pa𝑗(˜𝐺))=𝐿(˜𝑋𝑗|˜pa𝑗(˜𝐺)), which
contradicts that ˜𝐺is a minimizer. Therefore, we also have
lim
|𝐷𝑛|→∞𝑃(𝐺∗∼arg min
𝐺𝐿(𝑋;𝐺))=1.
□
With this, we move to our full causal model with multiple contexts. For ease of access, we restate our objective in Eq. (3),
 ˆΠ(𝐷),ˆ𝐺=min
Π(𝐷)|Π(𝐷)|∑︁
𝑟=1min
𝐺𝑟𝐿(𝑋𝑟;𝐺𝑟).
Theorem A.2 (Consistency of 𝐿for multiple causal models). For the causal model in Assumption 3.1 and given data 𝐷𝑛over𝑛episodes as in
Assumption 3.2, under Assumption 3.4, a consistent scoring criterion 𝐿that decomposes as in Eq. 2 remains consistent,
lim
|𝐷𝑛|→∞𝑃(ˆ𝐺𝑟∼𝐺∗
𝑟)=1 for all𝑟∈{1,...,𝑅}.
Proof. First, assume the number of contexts 𝑅and the context 𝐶(𝐸)that each episode 𝐸belongs to is known. That is, for the data 𝐷=𝐷𝑁
over all episodes, we know the true partitioning Π(𝐷)={𝑋1,...,𝑋𝑅}into disjoint, non-empty subsets 𝑋𝑟⊆𝐷such that∪𝑟𝑋𝑟=𝐷and
each𝑋𝑟is generated from a fixed causal model 𝐺𝑟in the𝑟th context. Due to independent data generation from each 𝐺𝑟, we can apply
Lemma A.1 separately in each context and obtain
lim
|𝐷|→∞𝑃(𝐺∗
1,...𝐺∗
𝑅∼min
𝐺1,...𝐺𝑅𝑅∑︁
𝑟=1𝐿(𝑋𝑟;𝐺𝑟(𝑋)))=lim
|𝐷|→∞𝑃(𝐺∗
1,...𝐺∗
𝑅∼min
𝐺1,...𝐺𝑅𝑅∑︁
𝑟=1𝐿(𝑋𝑟,𝑆𝑟;𝐺𝑟(𝑋)))=1.
Left to show is the case where 𝑅andΠ(𝐷)are unknown. We compare
•the true model G∗={𝐺∗
1,...,𝐺∗
𝑅∗}and subsets Π∗(𝐷)={𝑋∗1,...,𝑋∗𝑅∗}, and
•the estimated model ˆG={ˆ𝐺1,..., ˆ𝐺ˆ𝑅}and subsets ˆΠ(𝐷)={ˆ𝑋1,..., ˆ𝑋ˆ𝑅}minimizing Eq. 3 with score 𝐿(ˆG)=Íˆ𝑅
𝑟=1𝐿(ˆ𝑋𝑟;ˆ𝐺𝑟(ˆ𝑋𝑟)).
For contradiction, assume that there is no exact correspondence between the true and estimated models, more precisely, that for at least one
context𝑟with true model 𝑋∗𝑟and𝐺∗𝑟there is no other 𝑟′so that ˆ𝑋𝑟′=𝑋∗𝑟and ˆ𝐺𝑟′∼𝐺∗𝑟. We can distinguish the following cases,
 
2233Learning Causal Networks from Episodic Data KDD ’24, August 25–29, 2024, Barcelona, Spain
(1)Case𝑋∗𝑟=ˆ𝑋𝑟′for some𝑟′≠𝑟: then also ˆ𝐺𝑟′∼𝐺∗𝑟by Lemma A.1 as 𝑋∗𝑟is a dataset from a single context 𝑟, which however
contradicts the above assumption.
(2)Case𝑋∗𝑟⊂ˆ𝑋𝑟′for some𝑟′≠𝑟: Then the set 𝑋∗𝑟is wrongly included under the incorrect model ˆ𝐺𝑟′. Then the decomposition of
Eq. 3 will contain a suboptimal likelihood term
𝐿(𝑋∗𝑟|ˆ𝐺𝑟′)=𝑀∑︁
𝑗=1𝐿(𝑋∗𝑟
𝑗|pa𝑟
𝑗(ˆ𝐺𝑟′)).
Using that𝐿is decomposable, we can replace the above term in the decomposition of 𝐿as follows (keeping all other terms the same),
(a) if𝐺∗𝑟∈ˆG, we can replace 𝐿(𝑋∗𝑟|ˆ𝐺𝑟′)with𝐿(𝑋∗𝑟|𝐺∗𝑟).
(b)if𝐺∗𝑟∉ˆG, we can replace 𝐿(𝑋∗𝑟|ˆ𝐺𝑟′)with the full cost 𝐿(𝑋∗𝑟;𝐺∗𝑟)as the likelihood component dominates over 𝐿(𝐺∗𝑟)in the limit
of samples, as shown in Mian et al. [27].
In both cases, we can replace ˆGbyˆG∪{𝐺∗𝑟}and ˆΠ(𝐷)by{ˆ𝑋1,..,𝑋∗𝑟,ˆ𝑋𝑟′,..,ˆ𝑋ˆ𝑅}where we separate 𝑋∗𝑟and ˆ𝑋𝑟′and keep all other
parts the same, resulting in a favorable model, contradicting that it is the minimizer of Eq. 3.
(3)Case𝑋⊂ˆ𝑋𝑟′for some𝑟′≠𝑟and for a set 𝑋⊂𝑋∗𝑟,𝑋≠∅: This means that a non-empty subset of 𝑋∗𝑟is included under the incorrect
DAG, in which case we can apply the same argument as in case (2).
We can disregard the case 𝑋∗𝑟∩ˆ𝑋𝑟′=∅for all𝑟′as then𝑋∗𝑟is not covered by the partition.
Thus, ˆ𝑅=𝑅∗and each ˆ𝑋𝑟=𝑋∗𝑟and𝐺𝑟∼ˆ𝐺𝑟(up to permuting the indices). □
Next, we justify our updating and merging strategy in the presence of selection bias.
Theorem A.3 (Consistency of model updating using T).Given a set of causal DAGs ˆG={ˆ𝐺1,..., ˆ𝐺ˆ𝑅}and subsets ˆΠ(𝐷)={ˆ𝑋1,..., ˆ𝑋ˆ𝑅}
over episodes∪𝑟ˆ𝑋𝑟={𝐸1,...,𝐸𝑖}. With discrepancy test Twe will never merge a new episode 𝐸𝑖+1with a set ˆ𝑋𝑟from an incorrect context.
Proof. We need to show that with a merge protected by T, a merge of 𝐸𝑖+1with any set ˆ𝑋𝑟can only occur if 𝐶(𝐸𝑖′)=𝐶(𝐸𝑖+1)for all
𝑖′≤𝑖. For induction on the time step 𝑖, consider the following cases,
(1)For the base case is 𝑖=2, assume𝐶(𝐸1)≠𝐶(𝐸2). We need to show that Tnever merges 𝐸1,𝐸2from𝐶1,𝐶2From our causal model,
we know there is at least one variable in 𝐺∗
1,𝐺∗
2s.t.
𝑃(𝑋1
𝑗|pa1
𝑗)≠𝑃(𝑋2
𝑗|pa2
𝑗)
From Cor. 4.5 in MSS, this implies that also for any conditioning set Z,
𝑃(𝑋1
𝑗|Z1)≠𝑃(𝑋2
𝑗|Z2)
that is, we have a distribution shift even when Adiscovers an incorrect DAG ˆ𝐺1. Left to show is that it holds also for the biased
distributions
𝑃(𝑋1
𝑗|Z1,𝑆=𝑠𝑘)≠𝑃(𝑋2
𝑗|Z2,𝑆=𝑠𝑘′)
which holds under detectable selection. Hence, our test 𝑇will detect the difference for 𝑋𝑗given enough data from 𝐸1,𝐸2and reject
merging.
(2)For the induction step, we can assume that 𝐶(𝐸𝑖′)=𝐶(𝐸𝑖′′)for all𝑖′,𝑖′′, and apply the above pairwise argument to 𝐸𝑖+1and each𝐸𝑖′.
Corollary A.4 (Consistency of model merging). Given a consistent DAG search algorithm Aand score𝐿,Continent is consistent under
Assumption 3.4, so that
lim
|𝐷𝑛|→∞𝑃(ˆ𝐺𝑟∼𝐺𝑟∗)=1 for all𝑟∈{1,...,𝑅}.
Proof. Consider the estimated model ˆG={ˆ𝐺1,..., ˆ𝐺ˆ𝑅}and subsets ˆΠ(𝐷)={ˆ𝑋1,..., ˆ𝑋ˆ𝑅}that we obtain with Continent at time step 𝑛.
By the previous theorem, we know that episodes from different contexts were not merged incorrectly, ˆ𝑋𝑟⊆𝑋∗𝑟′for some𝑟′for each𝑟
where ˆ𝑅≤𝑅, which we write shorthand as ˆΠ(𝐷)⊆Π∗(𝐷). In case ˆ𝑅<𝑅, we need to consider any remaining merges among sets in ˆ𝑋𝑟. If
the assumptions of Thm. 3.5 hold, then we can use
min
Π(𝐷),ˆΠ(𝐷)⊆Π(𝐷)|Π(𝐷)|∑︁
𝑟=1min
𝐺𝑟𝐿(𝑋𝑟;𝐺𝑟).
The above will be minimized for Π∗(𝐷)and ˆ𝐺𝑟∼𝐺𝑟∗for each𝑟as it considers a subset of the partitions that Thm. 3.5 considers. Hence
minimizing 𝐿is a consistent way to discover the remaining merges. □
 
2234KDD ’24, August 25–29, 2024, Barcelona, Spain Osman Mian, Sarah Mameche, and Jilles Vreeken
B ALGORITHM
In this section, we include the pseudocode of the components of Continent .
Algorithm 3: Update(G,𝐸,A,T)
input : episode𝐸,
causal model G,
causal discovery algorithm Awith score𝐿,
residual testT
output: updated causal model G
1accepted←False
2foreach𝐺𝑟over data𝐷inGdo
3 ifTestResidualEq(𝐺𝑟,𝐸,𝐷,T)then
4 accepted←True
5𝐷←𝐷.stackData(𝐸)
6 end
7end
8ifnotaccepted then
9𝐺←A .Learn(𝐸)
10 G=G∪{𝐺}
11end
12return G
Algorithm 4: Merge(G,A,T)
input : causal model G,
causal discovery algorithm Awith score𝐿,
residual testT
output: updated causal model G
1repeat
2 foreach𝐺over data𝐷inGdo
3𝐷★←𝐷
4𝐺★←𝐺
5𝐿★←𝐺.Score(𝐷)
6 foreach𝐺′over data𝐷′inGnot seen yet do
7 ifnotTestResidualEq(𝐺′,𝐷,𝐷′,T)continue;
8 𝐷∪=𝐷∪𝐷′
9 𝐺∪←A .Learn(𝐷∪)
10 𝐿∪←𝐺∪.Score(𝐷∪)
11 ifTestScoreDiff (𝐿∪,𝐿★)then
12 𝐷★←𝐷∪
13 𝐿★←𝐿∪
14 𝐺★←𝐺∪
15 end
16 end
17 if𝐺★is not𝐺then
18 replace corresponding 𝐺,𝐺′with𝐺∪inG
19 end
20 end
21until convergence ;
22return G
 
2235