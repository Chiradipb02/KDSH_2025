Retrieval-Augmented Hypergraph for Multimodal Social Media
Popularity Prediction
Zhangtao Cheng
Jienan Zhang
Xovee Xu
zhangtao.cheng@outlook.com
eroicazjn@outlook.com
xovee@live.com
University of Electronic Science and
Technology of China
Chengdu, Sichuan, ChinaGoce Trajcevski
gocet25@iastate.edu
Iowa State University
Ames, Iowa, U.S.A.Ting Zhong
Fan Zhou‚àó
zhongting@uestc.edu.cn
fan.zhou@uestc.edu.cn
University of Electronic Science and
Technology of China
Chengdu, Sichuan, China
Kash Institute of Electronics and
Information Industry
Kashgar, Xinjiang, China
ABSTRACT
Accurately predicting the popularity of multimodal user-generated
content (UGC) is fundamental for many real-world applications
such as online advertising and recommendation. Existing ap-
proaches generally focus on limited contextual information within
individual UGCs, yet overlook the potential benefit of exploiting
meaningful knowledge in relevant UGCs. In this work, we pro-
pose RAGTrans, an aspect-aware retrieval-augmented multi-modal
hypergraph transformer that retrieves pertinent knowledge from
a multi-modal memory bank and enhances UGC representations
via neighborhood knowledge aggregation on multi-model hyper-
graphs. In particular, we initially retrieve relevant multimedia in-
stances from a large corpus of UGCs via the aspect information and
construct a knowledge-enhanced hypergraph based on retrieved
relevant instances. This allows capturing meaningful contextual
information across the data. We then design a novel bootstrapping
hypergraph transformer on multimodal hypergraphs to strengthen
UGC representations across modalities via customizing a propa-
gation algorithm to effectively diffuse information across nodes
and edges. Additionally, we propose a user-aware attention-based
fusion module to comprise the enriched UGC representations for
popularity prediction. Extensive experiments on real-world social
media datasets demonstrate that RAGTrans outperforms state-of-
the-art popularity prediction models across settings.
CCS CONCEPTS
‚Ä¢Information systems ‚ÜíRetrieval tasks and goals; ‚Ä¢Social
and professional topics ‚ÜíUser characteristics .
‚àóCorresponding author.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain
¬©2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 979-8-4007-0490-1/24/08
https://doi.org/10.1145/3637528.3672041KEYWORDS
Multimedia popularity, hypergraph, retrieval augmentation.
ACM Reference Format:
Zhangtao Cheng, Jienan Zhang, Xovee Xu, Goce Trajcevski, Ting Zhong,
and Fan Zhou. 2024. Retrieval-Augmented Hypergraph for Multimodal
Social Media Popularity Prediction. In Proceedings of the 30th ACM SIGKDD
Conference on Knowledge Discovery and Data Mining (KDD ‚Äô24), August
25‚Äì29, 2024, Barcelona, Spain. ACM, New York, NY, USA, 11 pages. https:
//doi.org/10.1145/3637528.3672041
1 INTRODUCTION
With the proliferation of multimodal user-generated content (UGC)
including images, texts and micro-videos on social media platforms
like TikTok, Triller and Instagram, predicting UGC popularity has
become crucial for many real-world applications. For example, rec-
ommender systems could leverage popularity forecasts to formulate
effective marketing strategies; governments can utilize popularity
prediction to identify potential public opinion crises and address
them preemptively, avoiding reputation and economic losses [ 49];
etc. Predicting multimodal social media popularity offers diverse
benefits, from helping users navigate information overload to im-
proving downstream applications such as online advertising [ 30],
social recommender systems [ 23,46], and rumor detection [ 35,58].
As an important application, multimodal social media popularity
prediction (MSMPP) aims to estimate the future popularity of UGC
based on multimodal features [ 48]. Much effort has been devoted
to this area, following two main paradigms: (1) Feature engineering-
based methods prioritize the design of hand-crafted UGC features,
including those extracted from user profiles [ 57], images [ 27,37]
and time series [ 40], for directly predicting popularity through well-
designed functions. However, a key limitation of these approaches
is their dependence on time-consuming manual feature engineering
and substantial expert knowledge, constraining their applicability.
(2)Deep learning-based methods demonstrate promising capabilities
in extracting useful patterns directly from UGCs without extensive
engineering, achieving substantial performance improvements by
learning UGC representations, including both uni-modal [ 32,54] as
well as more comprehensive multimodal representations [60, 64].
Despite the promising results, prior works explore representa-
tion learning only on egocentric UGC, overlooking the benefit of
 
445
KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain Zhangtao Cheng, et al.
6.675.326.51
3.703.583.32123456789PopularityCategory:Lovedogs12345678910User: 1
(a) Popularity distribution under the same user and category.
Predictor
Prior Works
PopularityPredictor
Our Work
Memory BankRetriever
RetrievedInstances
(b) Prior works vs.Ours.
4.47%3.12%2.98%4.12%3.29% (c) A preliminary experiment.
Figure 1: Motivation of this work. (a) Example of popularity
distribution under the same user or category from a Flickr
dataset. (b) Prior works mainly use an egocentric UGC for
prediction. In contrast, our model retrieves relevant UGCs as
an indicator to guide prediction. (c) Comparison between a
baseline and the one adding relevant instances. Lower values
indicate better performance.
exploiting the useful knowledge from relevant UGCs. However, in
real-world social media, follower distributions vary across source
users. Thus, even for identical UGCs, social feedback can differ
greatly depending on the viewing user group [ 24]. Fig. 1(a) shows
an example of how UGCs posted by different users or in distinct
categories tend to exhibit significant differences in popularity dis-
tribution. Consequently, modeling just a single UGC in isolation
provides limited knowledge, yielding erroneous predictions due to
the failure to fully capture diverse popularity distributions.
In contrast, humans have the ability to learn by observation,
i.e., the capacity to master skills by observing relevant subjects
rather than attempting to memorize every subject [ 21,41], which
motivates us to improve multimodal social media modeling with
retrieved UGCs. As shown in Fig. 1(b), we are specifically interested
in designing a retrieval-augmented pipeline. This pipeline searches
relevant data instances from the UGC memory bank to generate
informative knowledge. The relevant instances act as strong signals
and indicators that facilitate popularity prediction. Fig. 1(c) presents
a preliminary observation that can further validate our hypothe-
sis. We select 20 data instances from the same user or category in
the Flickr dataset, and use the sum of all features as model input.
The results suggest that relevant instances can provide valuable
information to strengthen model‚Äôs prediction capability. However,
generating expressive knowledge through relevant UGCs for en-
hancing MSMPP is largely unexplored. Retrieving relevant UGCs
from the memory bank and then exploiting meaningful knowl-
edge through relevant instances is non-trivial, primarily due to two
major challenges.C1:Calculating the similarity between the target UGC and rele-
vant instances is complicated, as it requires evaluating multimodal
similarities to identify Top- ùêænearest instances. Existing retrieval
methods focus on encoding and retrieving single-modal knowl-
edge [ 31,36], and hence cannot make use of multimodal data and
their complex correlations. Moreover, UGCs posted on the social
platforms typically contain a substantial amount of noise, includ-
ing discrepancies between textual and visual content, as well as
incomplete modal information.
C2:The correlations between the target UGC and retrieved in-
stances are typically high-order. As shown in Fig. 1(a), significant
popularity intervals are observed within the same user or category,
which suggests a stronger relationship between two distinct UGCs
posted even by the same user or belonging to the same category.
However, existing methods that directly utilize summation or atten-
tion operations [ 39,50] to model neighborhood knowledge from
relevant instances fail to model the complex high-order correlations
between the target UGC and relevant instances.
To address the limitations of prior studies, we present a retrieval-
augmented framework for enhancing MSMPP. Our core idea is
to leverage the aspect information of UGCs (e.g., category, source
user, content topic) and hypergraphs for multimodal retrieval and
knowledge augmentation. The aspect information of UGCs helps
explicitly discriminate relevant correlations among various UGC
types, improving retrieval performance. The underlying intuition
is that UGCs with similarities generally exhibit a higher degree
of shared aspect information. Besides, a hypergraph can connect
more than two vertices via different hyperedges [ 4], making it well-
suited for modeling interrelations among relevant data instances.
With this design, hyperedges directly associate multiple vertices
by representing UGC aspect information in an explicit manner.
Moreover, different hyperedges share common vertices, enabling
the modeling of high-order relations between the target UGC and
relevant instances through vital shared attributes.
To this end, we propose RAGTrans, a novel aspect-aware
Retrieval Augmented multi-modal hyperGraph Transformer
framework for enhancing MSMPP. Technically, we reformulate the
popularity prediction process in a principled retrieve-and-predict
manner. We construct a UGC memory bank that encodes the vi-
sual content, textual content and the aspect information of UGCs
with a collection of reference <image, text, aspect> triplets. Specif-
ically, the aspect information involves attribute-level and modal
semantic-level information in UGCs, i.e., user, category, topic, tex-
tual and visual semantic. During retrieval, we treat each UGC in
the memory bank as documents and the target UGC as a query. Re-
trieving relevant instances could be modeled as a query-document
matching problem. We leverage searching techniques and rank-
ing functions (e.g., BM25 [ 45]) to identify the most informative
instances via calculating the similarity scores among their aspect
information. During prediction, with the aspect information, we
connect all relevant instances via different aspect-level hyperedges
and then construct multi-modal hypergraphs to effectively express
high-order similar correlations among relevant instances. We also
design a bootstrapping hypergraph transformer to extend the infor-
mation aggregation to the multimodal information mixture, where
the intra- and inter-modal propagations are designed to capture the
respective intra- and inter-modal correlations. Finally, the model
 
446Retrieval-Augmented Hypergraph for Multimodal Social Media Popularity Prediction KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain
can easily exploit the user-aware cross-attention mechanism to
adaptively select the more important and suitable characteristics
within UGCs, thus obtaining complementary fused features en-
compassing multimodal semantics and user-level information for
popularity prediction. Following are our main contributions:
‚Ä¢We propose RAGTrans, pioneering an aspect-aware retrieval
augmented pipeline that bridges target multimodal UGCs and
relevant instances to enhance the MSMPP task.
‚Ä¢We propose a bootstrapping hypergraph transformer that extends
information aggregation to the multimodal mixture. Intra-modal
and inter-modal propagations are designed to capture correla-
tions within and across modalities as well as fine-grained and
aligned UGC representations.
‚Ä¢We conduct extensive experiments on real-world multimodal
datasets to evaluate RAGTrans. The results demonstrate that
RAGTrans can effectively learn multimodal representations from
visual and textual UGC modalities, and achieve up to a 20% gain
over strong baseline approaches on the ICIP dataset. The code
for reproducing the results is available at https://github.com/CZ-
TAO12/RAGTrans.
2 RELATED WORK
2.1 Popularity Prediction.
Predicting the popularity of UGCs in social media is an impor-
tant problem for various social and recommendation applications
[10,61,62,66]. Traditional feature-engineering based methods fo-
cus on identifying and incorporating hand-crafted UGC features
into machine learning methods. [ 27] found that image content and
social cues (e.g., the number of followers) are beneficial for popu-
larity prediction. In [ 5], the authors considered both low-level and
high-level image features for popularity prediction. Methods like
CNN and SVM were used in [ 6,29] to extract image latent visual
features. [ 15] analyzed the relationships between visual sentiments
and image popularity, and then utilized visual sentiments and user
features to predict the popularity scores of social images. Nonethe-
less, these models rely on the quality of extracted image features
and often require extensive domain knowledge. Also, the extracted
features are hard to be generalized to new domains.
More recently, deep learning-based methods focus on model
architecture designs for modeling different data modalities and
fusing them. UHAN [ 64] designs an user-guided attention network
composed of VGGNet and LSTM to merge the visual and textual
features for predicting popularity. DTCN [ 54] integrates ResNet and
LSTM to jointly extract neighboring temporal context and periodic
temporal context among sequential content. MMVED [ 60] is based
on a variational framework that designs a multimodal variational
encoder-decoder for micro-video popularity prediction. MGC [ 42]
and MHF [ 42] both utilize attention-based mechanisms to learn
multimodal UGC data. However, relevant instances contain crucial
evidence for guiding the popularity prediction, and existing works
have failed to capture meaningful knowledge in relevant UGCs.
Our work represents the first step in extending existing methods
by retrieving relevant instances to enhance the representations of
the target UGC and reason analogously about its popularity score.2.2 Hypergraph Neural Network.
For graph-structured data in the real-world scenarios (e.g., social
networks [ 9,13], urban computing [ 26] and protein structure [ 59]),
graph neural networks express tremendous capacity to model graph-
structured data. Graph convolutional network (GCN) [ 28,59] is a
classical GNN-based framework, which typically performs approxi-
mate spectral graph convolution to capture neighborhood structural
information of each node in a graph. However, structural interac-
tions in graph-structured data usually exist as many-to-many and
high-order relations. Therefore, simple GNNs are incapable of de-
picting such set-like relations. A hypergraph [4] generalizes the
edges of a graph into hyperedges, capable to connect an arbitrary
number of nodes, which, in turn, provide a natural way to express
high-order (set-like) relations. HGNN [ 14] is the first work to ex-
tend graph convolution to hypergraph for capturing the high-order
correlations. DHGNN [ 25] constructs a dynamic hypergraph neural
network with two modules: dynamic hypergraph construction and
hypergrpah convolution, to model evolution relations among differ-
ent nodes in the hypergraph. Other variants of hypergraph neural
networks (cf. [ 1]), incorporate diverse hypergraph structures, such
as dynamic[ 25], heterogeneous[ 47], and motif-based[ 63] structures.
We propose to use hypergraphs to represent complex higher-
order correlations between the target UGC and retrieved instances.
For each UGC and its surrounding hyperedges, as well as the aspect
information from its corresponding node, we obtain expressive
representations via our designed hypergraph transformers.
3 METHODOLOGY
As discussed in Sec. 1, using relevant data instances in the memory
bank as a kind of auxiliary knowledge is beneficial for accurate
prediction of UGC popularity [ 39]. In this section, we retrieve var-
ious relevant data instances according to a relevance metric for a
given target instance. We aim to use the auxiliary information to
help multimodal social media popularity prediction in a unified
hypergraph-based framework. After introducing preliminary def-
initions, we proceed to describe the details of RAGTrans‚Äôs three
main modules. A visual overview of RAGTrans is shown in Fig. 2.
Problem Definition. LetC={ùëê1,¬∑¬∑¬∑,ùëêùëÅ}denote the collection of
user-generated content (UGC) on social media, where ùëÅis number
of UGC. For each UGC ùëêùëñ, we have its multimodal content such as
textual descriptions (ùë°)and visual images ( ùë£). We aim to learn ùëêùëñ‚Äôs
multimodal representations ùíõùëñ={ùíõùë£
ùëñ,ùíõùë°
ùëñ,ùíõùë¢
ùëñ}, where ùíõùë£
ùëñ,ùíõùë°
ùëñandùíõùë¢
ùëñ
denote visual, textual and user representations, respectively. For
the ground-truth popularity ùë¶ùëñfor contentùëêùëñ, it is measured as total
interactions of users to ùëêùëñin the future, e.g., # reshares, # likes, and
# comments. Therefore, given a new content ùëêùëñof a userùë¢ùëñ, the
task of multimedia social media popularity prediction (MSMPP) is to
forecast the future popularity ùë¶ùëñvia multimodal features ùíõùëñ.
Hypergraph. Hypergraph is composed of hyperedges that can
be used to connect more than two nodes, representing high-order
relations among nodes. A hypergraph can be formulated as G=
{V,E}, whereVis the node set and Eis the hyperedge set. The
hyperedgeEcan be represented using an incidence matrix A‚àà
{0,1}|V|√ó|E|, where each entry Aùë£ùúñis set to 1 if the hyperedge ùúñ
involves the vertex ùë£, 0 otherwise. In the work, Vis constructed by
 
447KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain Zhangtao Cheng, et al.
Sierras Tongue out TuesdayHypergraph Incidence MatrixA<latexit sha1_base64="a2wa7UweXqi9BEdyt6CqZgKfvfQ=">AAACzXicjVHLTsJAFD3UF+ILdemmkZi4IsVgdIm6cScm8ohATFsGmNBXplMTgrj1B9zqbxn/QP/CO2NJVGJ0mrZnzr3nzNx7ncjjsbSs14wxN7+wuJRdzq2srq1v5De36nGYCJfV3NALRdOxY+bxgNUklx5rRoLZvuOxhjM8U/HGLRMxD4MrOYpYx7f7Ae9x15ZEXbd9Ww6c3vhkcpMvWEVLL3MWlFJQQLqqYf4FbXQRwkUCHwwBJGEPNmJ6WijBQkRcB2PiBCGu4wwT5EibUBajDJvYIX37tGulbEB75RlrtUunePQKUprYI01IeYKwOs3U8UQ7K/Y377H2VHcb0d9JvXxiJQbE/qWbZv5Xp2qR6OFY18Cppkgzqjo3dUl0V9TNzS9VSXKIiFO4S3FB2NXKaZ9NrYl17aq3to6/6UzFqr2b5iZ4V7ekAZd+jnMW1A+KpXLx8LJcqJymo85iB7vYp3keoYJzVFEj7wCPeMKzcWEkxp1x/5lqZFLNNr4t4+EDR+6Tbg==</latexit>Visual Encoder
Textual Encoderzv,l1
<latexit sha1_base64="JP2gppW+t/pS2Qvj7ttlTVeWZEo=">AAAC2nicjVHLSsNAFD2Nr1pfVXHlJlgEF1ISqeiy6MZlBfuAtpYknbaheZFMCjV0407c+gNu9YPEP9C/8M6YglpEJyQ5c+49Z+beawaOHXFNe80oc/MLi0vZ5dzK6tr6Rn5zqxb5cWixquU7ftgwjYg5tseq3OYOawQhM1zTYXVzeC7i9RELI9v3rvg4YG3X6Ht2z7YMTlQnv9NyDT4we8nNpJPok+tkdOhMcp18QStqcqmzQE9BAemq+PkXtNCFDwsxXDB44IQdGIjoaUKHhoC4NhLiQkK2jDNMkCNtTFmMMgxih/Tt066Zsh7thWck1Rad4tAbklLFPml8ygsJi9NUGY+ls2B/806kp7jbmP5m6uUSyzEg9i/dNPO/OlELRw+nsgabagokI6qzUpdYdkXcXP1SFSeHgDiBuxQPCVtSOe2zKjWRrF301pDxN5kpWLG30twY7+KWNGD95zhnQe2oqJeKx5elQvksHXUWu9jDAc3zBGVcoIIqeSd4xBOelZZyq9wp95+pSibVbOPbUh4+ALAKmDw=</latexit>zv,l2
<latexit sha1_base64="3TleVmhB5K+Mpvzo4f5+0JMhsuM=">AAAC2nicjVHLSsNAFD2Nr1pfUXHlJlgEF1LSUtFl0Y3LCvYBbS1JOm1D8yKZFGroxp249Qfc6geJf6B/4Z0xglpEJyQ5c+49Z+beawaOHXFdf8koc/MLi0vZ5dzK6tr6hrq5VY/8OLRYzfIdP2yaRsQc22M1bnOHNYOQGa7psIY5OhPxxpiFke17l3wSsI5rDDy7b1sGJ6qr7rRdgw/NfnI97Sal6VUyPnSmua6a1wu6XNosKKYgj3RVffUZbfTgw0IMFwweOGEHBiJ6WihCR0BcBwlxISFbxhmmyJE2pixGGQaxI/oOaNdKWY/2wjOSaotOcegNSalhnzQ+5YWExWmajMfSWbC/eSfSU9xtQn8z9XKJ5RgS+5fuM/O/OlELRx8nsgabagokI6qzUpdYdkXcXPtSFSeHgDiBexQPCVtS+dlnTWoiWbvorSHjrzJTsGJvpbkx3sQtacDFn+OcBfVSoVguHF2U85XTdNRZ7GIPBzTPY1Rwjipq5J3gAY94UtrKjXKr3H2kKplUs41vS7l/B7JymD0=</latexit>zv,lp
<latexit sha1_base64="Lkos4cN+2mbcQgnkVxmE4dfVQBw=">AAAC2nicjVHLSsNAFD2Nr1pfUXHlJlgEF1JSqeiy6MZlBfuAtpYknbaheZFMCjV0407c+gNu9YPEP9C/8M6YglpEJyQ5c+49Z+beawaOHXFdf80oc/MLi0vZ5dzK6tr6hrq5VYv8OLRY1fIdP2yYRsQc22NVbnOHNYKQGa7psLo5PBfx+oiFke17V3wcsLZr9D27Z1sGJ6qj7rRcgw/MXnIz6STB5DoZHTqTXEfN6wVdLm0WFFOQR7oqvvqCFrrwYSGGCwYPnLADAxE9TRShIyCujYS4kJAt4wwT5EgbUxajDIPYIX37tGumrEd74RlJtUWnOPSGpNSwTxqf8kLC4jRNxmPpLNjfvBPpKe42pr+ZernEcgyI/Us3zfyvTtTC0cOprMGmmgLJiOqs1CWWXRE3175UxckhIE7gLsVDwpZUTvusSU0kaxe9NWT8TWYKVuytNDfGu7glDbj4c5yzoHZUKJYKx5elfPksHXUWu9jDAc3zBGVcoIIqeSd4xBOelZZyq9wp95+pSibVbOPbUh4+AEexmHs=</latexit>zv,li
<latexit sha1_base64="MNUC2+WLN+z5A89WnxviBXVmBOw=">AAAC2nicjVHLSsNAFD2Nr1pfVXHlJlgEF1JSUXQpunFZwWqh1TJJp3Vw8iCZCBq6cSdu/QG3+kHiH+hfeGeMoBbRCUnOnHvPmbn3upEUiXKcl4I1Mjo2PlGcLE1Nz8zOlecXjpMwjT3e8EIZxk2XJVyKgDeUUJI3o5gz35X8xL3Y1/GTSx4nIgyO1FXET33WD0RPeEwR1SkvtX2mzt1edj3oZGJwll2uy0GpU644VccsexjUclBBvuph+RltdBHCQwofHAEUYQmGhJ4WanAQEXeKjLiYkDBxjgFKpE0pi1MGI/aCvn3atXI2oL32TIzao1MkvTEpbaySJqS8mLA+zTbx1Dhr9jfvzHjqu13R3829fGIVzon9S/eZ+V+drkWhhx1Tg6CaIsPo6rzcJTVd0Te3v1SlyCEiTuMuxWPCnlF+9tk2msTUrnvLTPzVZGpW7708N8WbviUNuPZznMPgeKNa26xuHW5WdvfyURexjBWs0Ty3sYsD1NEg7wwPeMST1bZurFvr7iPVKuSaRXxb1v07NtmYdA==</latexit>zv,li+1
<latexit sha1_base64="totUHI/wPiQucmxBH+OdvBQ8VtA=">AAAC3HicjVHLSsNAFD2N7/qKunDhJlgEQSmJVHQpunGpYB9Q25KkUx3Mi2RS0NCdO3HrD7jV7xH/QP/CO2MKahGdkOTMufecuXeuE3k8Eab5WtDGxicmp6ZnirNz8wuL+tJyLQnT2GVVN/TCuOHYCfN4wKqCC481opjZvuOxunN1JOP1PosTHgZn4jpiLd++CHiPu7YgqqOvnvu2uHR62c2gk/Eta9DO+tveoNjRS2bZVMsYBVYOSsjXSai/4BxdhHCRwgdDAEHYg42EniYsmIiIayEjLibEVZxhgCJpU8pilGETe0XfC9o1czagvfRMlNqlUzx6Y1Ia2CBNSHkxYXmaoeKpcpbsb96Z8pS1XdPfyb18YgUuif1LN8z8r072ItDDvuqBU0+RYmR3bu6SqluRlRtfuhLkEBEncZfiMWFXKYf3bChNonqXd2ur+JvKlKzcu3luindZJQ3Y+jnOUVDbKVuV8u5ppXRwmI96GmtYxybNcw8HOMYJqqr+RzzhWWtrt9qddv+ZqhVyzQq+Le3hA2uJmOQ=</latexit>‚Ä¶‚Ä¶ev,l1
<latexit sha1_base64="FQ2LR+nHsXNOMwagIVyIZ8B+/0M=">AAAC2XicjVHLSsNAFD2Nr1pf9bFzEyyCCymJVHRZdOOygn1AW0uSTtvQvEgmhRq6cCdu/QG3+kPiH+hfeGdMQS2iE5KcOfeeM3PvNQPHjrimvWaUufmFxaXscm5ldW19I7+5VYv8OLRY1fIdP2yYRsQc22NVbnOHNYKQGa7psLo5PBfx+oiFke17V3wcsLZr9D27Z1sGJ6qT32m5Bh+YvYRNrpPRoTPpJPqkky9oRU0udRboKSggXRU//4IWuvBhIYYLBg+csAMDET1N6NAQENdGQlxIyJZxhglypI0pi1GGQeyQvn3aNVPWo73wjKTaolMcekNSqtgnjU95IWFxmirjsXQW7G/eifQUdxvT30y9XGI5BsT+pZtm/lcnauHo4VTWYFNNgWREdVbqEsuuiJurX6ri5BAQJ3CX4iFhSyqnfValJpK1i94aMv4mMwUr9laaG+Nd3JIGrP8c5yyoHRX1UvH4slQon6WjzmIXezigeZ6gjAtUUCXvGzziCc9KU7lV7pT7z1Qlk2q28W0pDx83spgT</latexit>ev,l3
<latexit sha1_base64="BSDS0onGG1RywuUkQwxiS5EkHV4=">AAAC2XicjVHLSsNAFD2Nr1pf8bFzEyyCCympVnRZdOOygn1AW0uSTttgXiSTQg1duBO3/oBb/SHxD/QvvDOmoBbRCUnOnHvPmbn3moFjR1zXXzPKzOzc/EJ2Mbe0vLK6pq5v1CI/Di1WtXzHDxumETHH9liV29xhjSBkhms6rG5en4l4fcjCyPa9Sz4KWNs1+p7dsy2DE9VRt1quwQdmL2Hjq2S474w7yeG4o+b1gi6XNg2KKcgjXRVffUELXfiwEMMFgwdO2IGBiJ4mitARENdGQlxIyJZxhjFypI0pi1GGQew1ffu0a6asR3vhGUm1Rac49Iak1LBLGp/yQsLiNE3GY+ks2N+8E+kp7jaiv5l6ucRyDIj9SzfJ/K9O1MLRw4mswaaaAsmI6qzUJZZdETfXvlTFySEgTuAuxUPCllRO+qxJTSRrF701ZPxNZgpW7K00N8a7uCUNuPhznNOgdlAolgpHF6V8+TQddRbb2MEezfMYZZyjgip53+ART3hWmsqtcqfcf6YqmVSziW9LefgAPHSYFQ==</latexit>ev,l2
<latexit sha1_base64="4FBShcABWuzq/zDQiX1PyNpEsWQ=">AAAC2XicjVHLSsNAFD2Nr1pf8bFzEyyCCylpqeiy6MZlBfuAtpYknbaheZFMCjV04U7c+gNu9YfEP9C/8M4YQS2iE5KcOfeeM3PvNQPHjriuv2SUufmFxaXscm5ldW19Q93cqkd+HFqsZvmOHzZNI2KO7bEat7nDmkHIDNd0WMMcnYl4Y8zCyPa9Sz4JWMc1Bp7dty2DE9VVd9quwYdmP2HTq2R86Ey7SWnaVfN6QZdLmwXFFOSRrqqvPqONHnxYiOGCwQMn7MBARE8LRegIiOsgIS4kZMs4wxQ50saUxSjDIHZE3wHtWinr0V54RlJt0SkOvSEpNeyTxqe8kLA4TZPxWDoL9jfvRHqKu03ob6ZeLrEcQ2L/0n1m/lcnauHo40TWYFNNgWREdVbqEsuuiJtrX6ri5BAQJ3CP4iFhSyo/+6xJTSRrF701ZPxVZgpW7K00N8abuCUNuPhznLOgXioUy4Wji3K+cpqOOotd7OGA5nmMCs5RRY28r/GARzwpLeVGuVXuPlKVTKrZxrel3L8DOhOYFA==</latexit>et!v,l1
<latexit sha1_base64="mEu2FxFiywdHPUim6Z5Qni2WiXs=">AAAC33icjVHLSsNAFD3GV31H3ekmWAQXUhKp6LLoxqWCVaGtZRKnNjQvkkmhhIA7d+LWH3CrfyP+gf6Fd8YU1CI6IcmZc+85M/deO/LcRJjm65g2PjE5NV2amZ2bX1hc0pdXzpIwjR1ed0IvjC9slnDPDXhduMLjF1HMmW97/NzuHcr4eZ/HiRsGp2IQ8ZbPrgO34zpMENXW15o+E127k/H8MhNGU4RGf9vL25mVt/WyWTHVMkaBVYAyinUc6i9o4gohHKTwwRFAEPbAkNDTgAUTEXEtZMTFhFwV58gxS9qUsjhlMGJ79L2mXaNgA9pLz0SpHTrFozcmpYFN0oSUFxOWpxkqnipnyf7mnSlPebcB/e3CyydWoEvsX7ph5n91shaBDvZVDS7VFClGVucULqnqiry58aUqQQ4RcRJfUTwm7CjlsM+G0iSqdtlbpuJvKlOycu8UuSne5S1pwNbPcY6Cs52KVa3snlTLtYNi1CWsYwNbNM891HCEY9TJ+waPeMKzxrRb7U67/0zVxgrNKr4t7eED8DiaQg==</latexit>et!v,l2
<latexit sha1_base64="Ihtf19ON22lp3JHDwHBVXf0Kcjk=">AAAC33icjVHLSsNAFD3GV31X3ekmWAQXUtKi6LLoxmUF2wpWyyRO7dC8SCZCCQV37sStP+BW/0b8A/0L74wj+EB0QpIz595zZu69buyLVDrO84g1OjY+MVmYmp6ZnZtfKC4uNdMoSzze8CI/So5dlnJfhLwhhfT5cZxwFrg+b7n9fRVvXfIkFVF4JAcxPw3YRSi6wmOSqE5xpR0w2XO7OR+e5dJuy8i+3PSHnbw67BRLTtnRy/4JKgaUYFY9Kj6hjXNE8JAhAEcISdgHQ0rPCSpwEBN3ipy4hJDQcY4hpkmbURanDEZsn74XtDsxbEh75ZlqtUen+PQmpLSxTpqI8hLC6jRbxzPtrNjfvHPtqe42oL9rvAJiJXrE/qX7yPyvTtUi0cWurkFQTbFmVHWeccl0V9TN7U9VSXKIiVP4nOIJYU8rP/psa02qa1e9ZTr+ojMVq/aeyc3wqm5JA658H+dP0KyWK1vl7cOtUm3PjLqAVaxhg+a5gxoOUEeDvK9wjwc8Wsy6tm6s2/dUa8RolvFlWXdv8pmaQw==</latexit>et!v,l3
<latexit sha1_base64="/OJ3kz6latQm5DJ9NI6bZhTfRqM=">AAAC33icjVHLSsNAFD3GV62vqjvdBIvgQkrqA12KblxWsLZga5lMpxpMMiGZCBIK7tyJW3/Arf6N+Af6F94ZU/CB6IQkZ86958zce93I9xLlOC9D1vDI6Nh4YaI4OTU9M1uamz9OZBpzUefSl3HTZYnwvVDUlad80YxiwQLXFw33Yl/HG5ciTjwZHqmrSLQDdhZ6PY8zRVSntNgKmDp3e5non2bKbilpX675/U620e+Uyk7FMcv+Cao5KCNfNVl6RgtdSHCkCCAQQhH2wZDQc4IqHETEtZERFxPyTFygjyJpU8oSlMGIvaDvGe1OcjakvfZMjJrTKT69MSltrJBGUl5MWJ9mm3hqnDX7m3dmPPXdrujv5l4BsQrnxP6lG2T+V6drUehhx9TgUU2RYXR1PHdJTVf0ze1PVSlyiIjTuEvxmDA3ykGfbaNJTO26t8zEX02mZvWe57kp3vQtacDV7+P8CY7XK9XNytbhZnl3Lx91AUtYxirNcxu7OEANdfK+xgMe8WQx68a6te4+Uq2hXLOAL8u6fwf0+ppE</latexit>‚Ä¶‚Ä¶zv,l+11
<latexit sha1_base64="n8cGBTaXIpXzu8KnVX0ERKmfFIw=">AAAC23icjVHLSsNAFD3Gd31VBTdugkUQlJJIRZeiG5cKVgVbyySd1mBeJJNCjV25E7f+gFv9H/EP9C+8M05BLaITkpw5954zc+91Yt9LhWW9DhnDI6Nj4xOThanpmdm54vzCSRplicurbuRHyZnDUu57Ia8KT/j8LE44CxyfnzpX+zJ+2uFJ6kXhsejGvB6wdui1PJcJohrFpVrAxKXTyq97jdzuXeSdDX/d7jWKJatsqWUOAluDEvQ6jIovqKGJCC4yBOAIIQj7YEjpOYcNCzFxdeTEJYQ8FefooUDajLI4ZTBir+jbpt25ZkPaS89UqV06xac3IaWJVdJElJcQlqeZKp4pZ8n+5p0rT3m3Lv0d7RUQK3BJ7F+6fuZ/dbIWgRZ2VA0e1RQrRlbnapdMdUXe3PxSlSCHmDiJmxRPCLtK2e+zqTSpql32lqn4m8qUrNy7OjfDu7wlDdj+Oc5BcLJZtivlraNKaXdPj3oCy1jBGs1zG7s4wCGq5H2DRzzh2agbt8adcf+ZagxpzSK+LePhA6CZmJg=</latexit>zv,l+12
<latexit sha1_base64="ZxsSlrgkq2zg5Z8BmhpHdSvHYXA=">AAAC23icjVHLSsNAFD3GV62vqODGTbAIglKSUtGl6MZlBWsLbS1JOm2DeZFMChq7cidu/QG3+j/iH+hfeGdMQS2iE5KcOfeeM3PvtULXibmuv04ok1PTM7O5ufz8wuLSsrqyeh4HSWSzqh24QVS3zJi5js+q3OEuq4cRMz3LZTXr8ljEawMWxU7gn/GrkLU8s+c7Xcc2OVFtdb3pmbxvddPrYTstDS/Swa67YwzbakEv6nJp48DIQAHZqgTqC5roIICNBB4YfHDCLkzE9DRgQEdIXAspcREhR8YZhsiTNqEsRhkmsZf07dGukbE+7YVnLNU2neLSG5FSwxZpAsqLCIvTNBlPpLNgf/NOpae42xX9rczLI5ajT+xfulHmf3WiFo4uDmQNDtUUSkZUZ2cuieyKuLn2pSpODiFxAncoHhG2pXLUZ01qYlm76K0p428yU7Bib2e5Cd7FLWnAxs9xjoPzUtEoF/dOy4XDo2zUOWxgE9s0z30c4gQVVMn7Bo94wrPSUm6VO+X+M1WZyDRr+LaUhw+jApiZ</latexit>zv,l+1i
<latexit sha1_base64="JHk5JvNbNyvBSha4v4UMpM/RPiw=">AAAC23icjVHLSsNAFD3GV62vqODGTbAIglISqeiy6MalgtVCrSWJUzs0L5JJocau3Ilbf8Ct/o/4B/oX3hlT8IHohCRnzr3nzNx7ncjjiTDNlxFtdGx8YrIwVZyemZ2b1xcWT5IwjV1Wc0MvjOuOnTCPB6wmuPBYPYqZ7TseO3W6+zJ+2mNxwsPgWPQj1vTty4C3uWsLolr68plvi47Tzq4GrYwPzrPeprdhDVp6ySybahk/gZWDEvJ1GOrPOMMFQrhI4YMhgCDswUZCTwMWTETENZERFxPiKs4wQJG0KWUxyrCJ7dL3knaNnA1oLz0TpXbpFI/emJQG1kgTUl5MWJ5mqHiqnCX7m3emPOXd+vR3ci+fWIEOsX/phpn/1claBNrYVTVwqilSjKzOzV1S1RV5c+NTVYIcIuIkvqB4TNhVymGfDaVJVO2yt7aKv6pMycq9m+emeJO3pAFb38f5E5xsla1KefuoUqru5aMuYAWrWKd57qCKAxyiRt7XeMAjnrSmdqPdancfqdpIrlnCl6XdvwMnoJjQ</latexit>zv,l+1i+1
<latexit sha1_base64="toukYzcLmhiuA6Vnkl7rn3mnmdI=">AAAC3XicjVHLSsNAFD2N73fUjeAmWARBKYlUdFl041LBVqGtJYnTdmheJJNCDXXnTtz6A271d8Q/0L/wzhjBB6ITMnPm3HvOzJ3rRB5PhGk+F7SR0bHxicmp6ZnZufkFfXGploRp7LKqG3phfObYCfN4wKqCC4+dRTGzfcdjp07vQMZP+yxOeBiciEHEmr7dCXibu7YgqqWvNHxbdJ12djlsZXzTGp5n/S2P1pZeNEumGsZPYOWgiHwchfoTGrhACBcpfDAEEIQ92Ejoq8OCiYi4JjLiYkJcxRmGmCZtSlmMMmxiezR3aFfP2YD20jNRapdO8eiPSWlgnTQh5cWE5WmGiqfKWbK/eWfKU95tQKuTe/nECnSJ/Uv3kflfnaxFoI09VQOnmiLFyOrc3CVVryJvbnyqSpBDRJzEFxSPCbtK+fHOhtIkqnb5traKv6hMycq9m+emeJW3pAZb39v5E9S2S1a5tHNcLlb281ZPYhVr2KB+7qKCQxyhSt5XuMcDHrWWdq3daLfvqVoh1yzjy9Du3gBcsJlA</latexit>zv,l+1p
<latexit sha1_base64="BU/p6c1+hXgJLuyRisBN2/oP6eM=">AAAC23icjVHLSsNAFD2N7/qqCm7cBIsgKCWRii5FNy4r2FbQWiZxqsG8SCaFGrtyJ279Abf6P+If6F94Z5yCD0QnJDlz7j1n5t7rxL6XCst6KRhDwyOjY+MTxcmp6ZnZ0tx8I42yxOV1N/Kj5MhhKfe9kNeFJ3x+FCecBY7Pm87lnow3uzxJvSg8FL2YtwJ2Hnodz2WCqHZp8SRg4sLp5Ff9dh73T/Puur9m99ulslWx1DJ/AluDMvSqRaVnnOAMEVxkCMARQhD2wZDScwwbFmLiWsiJSwh5Ks7RR5G0GWVxymDEXtL3nHbHmg1pLz1TpXbpFJ/ehJQmVkgTUV5CWJ5mqnimnCX7m3euPOXdevR3tFdArMAFsX/pBpn/1claBDrYVjV4VFOsGFmdq10y1RV5c/NTVYIcYuIkPqN4QthVykGfTaVJVe2yt0zFX1WmZOXe1bkZ3uQtacD293H+BI2Nil2tbB5Uyzu7etTjWMIyVmmeW9jBPmqok/c1HvCIJ6Nl3Bi3xt1HqlHQmgV8Wcb9Ozh/mNc=</latexit>zv,l1
<latexit sha1_base64="JP2gppW+t/pS2Qvj7ttlTVeWZEo=">AAAC2nicjVHLSsNAFD2Nr1pfVXHlJlgEF1ISqeiy6MZlBfuAtpYknbaheZFMCjV0407c+gNu9YPEP9C/8M6YglpEJyQ5c+49Z+beawaOHXFNe80oc/MLi0vZ5dzK6tr6Rn5zqxb5cWixquU7ftgwjYg5tseq3OYOawQhM1zTYXVzeC7i9RELI9v3rvg4YG3X6Ht2z7YMTlQnv9NyDT4we8nNpJPok+tkdOhMcp18QStqcqmzQE9BAemq+PkXtNCFDwsxXDB44IQdGIjoaUKHhoC4NhLiQkK2jDNMkCNtTFmMMgxih/Tt066Zsh7thWck1Rad4tAbklLFPml8ygsJi9NUGY+ls2B/806kp7jbmP5m6uUSyzEg9i/dNPO/OlELRw+nsgabagokI6qzUpdYdkXcXP1SFSeHgDiBuxQPCVtSOe2zKjWRrF301pDxN5kpWLG30twY7+KWNGD95zhnQe2oqJeKx5elQvksHXUWu9jDAc3zBGVcoIIqeSd4xBOelZZyq9wp95+pSibVbOPbUh4+ALAKmDw=</latexit>zv,l2
<latexit sha1_base64="3TleVmhB5K+Mpvzo4f5+0JMhsuM=">AAAC2nicjVHLSsNAFD2Nr1pfUXHlJlgEF1LSUtFl0Y3LCvYBbS1JOm1D8yKZFGroxp249Qfc6geJf6B/4Z0xglpEJyQ5c+49Z+beawaOHXFdf8koc/MLi0vZ5dzK6tr6hrq5VY/8OLRYzfIdP2yaRsQc22M1bnOHNYOQGa7psIY5OhPxxpiFke17l3wSsI5rDDy7b1sGJ6qr7rRdgw/NfnI97Sal6VUyPnSmua6a1wu6XNosKKYgj3RVffUZbfTgw0IMFwweOGEHBiJ6WihCR0BcBwlxISFbxhmmyJE2pixGGQaxI/oOaNdKWY/2wjOSaotOcegNSalhnzQ+5YWExWmajMfSWbC/eSfSU9xtQn8z9XKJ5RgS+5fuM/O/OlELRx8nsgabagokI6qzUpdYdkXcXPtSFSeHgDiBexQPCVtS+dlnTWoiWbvorSHjrzJTsGJvpbkx3sQtacDFn+OcBfVSoVguHF2U85XTdNRZ7GIPBzTPY1Rwjipq5J3gAY94UtrKjXKr3H2kKplUs41vS7l/B7JymD0=</latexit>zv,lp
<latexit sha1_base64="Lkos4cN+2mbcQgnkVxmE4dfVQBw=">AAAC2nicjVHLSsNAFD2Nr1pfUXHlJlgEF1JSqeiy6MZlBfuAtpYknbaheZFMCjV0407c+gNu9YPEP9C/8M6YglpEJyQ5c+49Z+beawaOHXFdf80oc/MLi0vZ5dzK6tr6hrq5VYv8OLRY1fIdP2yYRsQc22NVbnOHNYKQGa7psLo5PBfx+oiFke17V3wcsLZr9D27Z1sGJ6qj7rRcgw/MXnIz6STB5DoZHTqTXEfN6wVdLm0WFFOQR7oqvvqCFrrwYSGGCwYPnLADAxE9TRShIyCujYS4kJAt4wwT5EgbUxajDIPYIX37tGumrEd74RlJtUWnOPSGpNSwTxqf8kLC4jRNxmPpLNjfvBPpKe42pr+ZernEcgyI/Us3zfyvTtTC0cOprMGmmgLJiOqs1CWWXRE3175UxckhIE7gLsVDwpZUTvusSU0kaxe9NWT8TWYKVuytNDfGu7glDbj4c5yzoHZUKJYKx5elfPksHXUWu9jDAc3zBGVcoIIqeSd4xBOelZZyq9wp95+pSibVbOPbUh4+AEexmHs=</latexit>zv,li
<latexit sha1_base64="MNUC2+WLN+z5A89WnxviBXVmBOw=">AAAC2nicjVHLSsNAFD2Nr1pfVXHlJlgEF1JSUXQpunFZwWqh1TJJp3Vw8iCZCBq6cSdu/QG3+kHiH+hfeGeMoBbRCUnOnHvPmbn3upEUiXKcl4I1Mjo2PlGcLE1Nz8zOlecXjpMwjT3e8EIZxk2XJVyKgDeUUJI3o5gz35X8xL3Y1/GTSx4nIgyO1FXET33WD0RPeEwR1SkvtX2mzt1edj3oZGJwll2uy0GpU644VccsexjUclBBvuph+RltdBHCQwofHAEUYQmGhJ4WanAQEXeKjLiYkDBxjgFKpE0pi1MGI/aCvn3atXI2oL32TIzao1MkvTEpbaySJqS8mLA+zTbx1Dhr9jfvzHjqu13R3829fGIVzon9S/eZ+V+drkWhhx1Tg6CaIsPo6rzcJTVd0Te3v1SlyCEiTuMuxWPCnlF+9tk2msTUrnvLTPzVZGpW7708N8WbviUNuPZznMPgeKNa26xuHW5WdvfyURexjBWs0Ty3sYsD1NEg7wwPeMST1bZurFvr7iPVKuSaRXxb1v07NtmYdA==</latexit>zv,li+1
<latexit sha1_base64="totUHI/wPiQucmxBH+OdvBQ8VtA=">AAAC3HicjVHLSsNAFD2N7/qKunDhJlgEQSmJVHQpunGpYB9Q25KkUx3Mi2RS0NCdO3HrD7jV7xH/QP/CO2MKahGdkOTMufecuXeuE3k8Eab5WtDGxicmp6ZnirNz8wuL+tJyLQnT2GVVN/TCuOHYCfN4wKqCC481opjZvuOxunN1JOP1PosTHgZn4jpiLd++CHiPu7YgqqOvnvu2uHR62c2gk/Eta9DO+tveoNjRS2bZVMsYBVYOSsjXSai/4BxdhHCRwgdDAEHYg42EniYsmIiIayEjLibEVZxhgCJpU8pilGETe0XfC9o1czagvfRMlNqlUzx6Y1Ia2CBNSHkxYXmaoeKpcpbsb96Z8pS1XdPfyb18YgUuif1LN8z8r072ItDDvuqBU0+RYmR3bu6SqluRlRtfuhLkEBEncZfiMWFXKYf3bChNonqXd2ur+JvKlKzcu3luindZJQ3Y+jnOUVDbKVuV8u5ppXRwmI96GmtYxybNcw8HOMYJqqr+RzzhWWtrt9qddv+ZqhVyzQq+Le3hA2uJmOQ=</latexit>‚Ä¶‚Ä¶ev,l1
<latexit sha1_base64="FQ2LR+nHsXNOMwagIVyIZ8B+/0M=">AAAC2XicjVHLSsNAFD2Nr1pf9bFzEyyCCymJVHRZdOOygn1AW0uSTtvQvEgmhRq6cCdu/QG3+kPiH+hfeGdMQS2iE5KcOfeeM3PvNQPHjrimvWaUufmFxaXscm5ldW19I7+5VYv8OLRY1fIdP2yYRsQc22NVbnOHNYKQGa7psLo5PBfx+oiFke17V3wcsLZr9D27Z1sGJ6qT32m5Bh+YvYRNrpPRoTPpJPqkky9oRU0udRboKSggXRU//4IWuvBhIYYLBg+csAMDET1N6NAQENdGQlxIyJZxhglypI0pi1GGQeyQvn3aNVPWo73wjKTaolMcekNSqtgnjU95IWFxmirjsXQW7G/eifQUdxvT30y9XGI5BsT+pZtm/lcnauHo4VTWYFNNgWREdVbqEsuuiJurX6ri5BAQJ3CX4iFhSyqnfValJpK1i94aMv4mMwUr9laaG+Nd3JIGrP8c5yyoHRX1UvH4slQon6WjzmIXezigeZ6gjAtUUCXvGzziCc9KU7lV7pT7z1Qlk2q28W0pDx83spgT</latexit>ev,l3
<latexit sha1_base64="BSDS0onGG1RywuUkQwxiS5EkHV4=">AAAC2XicjVHLSsNAFD2Nr1pf8bFzEyyCCympVnRZdOOygn1AW0uSTttgXiSTQg1duBO3/oBb/SHxD/QvvDOmoBbRCUnOnHvPmbn3moFjR1zXXzPKzOzc/EJ2Mbe0vLK6pq5v1CI/Di1WtXzHDxumETHH9liV29xhjSBkhms6rG5en4l4fcjCyPa9Sz4KWNs1+p7dsy2DE9VRt1quwQdmL2Hjq2S474w7yeG4o+b1gi6XNg2KKcgjXRVffUELXfiwEMMFgwdO2IGBiJ4mitARENdGQlxIyJZxhjFypI0pi1GGQew1ffu0a6asR3vhGUm1Rac49Iak1LBLGp/yQsLiNE3GY+ks2N+8E+kp7jaiv5l6ucRyDIj9SzfJ/K9O1MLRw4mswaaaAsmI6qzUJZZdETfXvlTFySEgTuAuxUPCllRO+qxJTSRrF701ZPxNZgpW7K00N8a7uCUNuPhznNOgdlAolgpHF6V8+TQddRbb2MEezfMYZZyjgip53+ART3hWmsqtcqfcf6YqmVSziW9LefgAPHSYFQ==</latexit>ev,l2
<latexit sha1_base64="4FBShcABWuzq/zDQiX1PyNpEsWQ=">AAAC2XicjVHLSsNAFD2Nr1pf8bFzEyyCCylpqeiy6MZlBfuAtpYknbaheZFMCjV04U7c+gNu9YfEP9C/8M4YQS2iE5KcOfeeM3PvNQPHjriuv2SUufmFxaXscm5ldW19Q93cqkd+HFqsZvmOHzZNI2KO7bEat7nDmkHIDNd0WMMcnYl4Y8zCyPa9Sz4JWMc1Bp7dty2DE9VVd9quwYdmP2HTq2R86Ey7SWnaVfN6QZdLmwXFFOSRrqqvPqONHnxYiOGCwQMn7MBARE8LRegIiOsgIS4kZMs4wxQ50saUxSjDIHZE3wHtWinr0V54RlJt0SkOvSEpNeyTxqe8kLA4TZPxWDoL9jfvRHqKu03ob6ZeLrEcQ2L/0n1m/lcnauHo40TWYFNNgWREdVbqEsuuiJtrX6ri5BAQJ3CP4iFhSyo/+6xJTSRrF701ZPxVZgpW7K00N8abuCUNuPhznLOgXioUy4Wji3K+cpqOOotd7OGA5nmMCs5RRY28r/GARzwpLeVGuVXuPlKVTKrZxrel3L8DOhOYFA==</latexit>et!v,l1
<latexit sha1_base64="mEu2FxFiywdHPUim6Z5Qni2WiXs=">AAAC33icjVHLSsNAFD3GV31H3ekmWAQXUhKp6LLoxqWCVaGtZRKnNjQvkkmhhIA7d+LWH3CrfyP+gf6Fd8YU1CI6IcmZc+85M/deO/LcRJjm65g2PjE5NV2amZ2bX1hc0pdXzpIwjR1ed0IvjC9slnDPDXhduMLjF1HMmW97/NzuHcr4eZ/HiRsGp2IQ8ZbPrgO34zpMENXW15o+E127k/H8MhNGU4RGf9vL25mVt/WyWTHVMkaBVYAyinUc6i9o4gohHKTwwRFAEPbAkNDTgAUTEXEtZMTFhFwV58gxS9qUsjhlMGJ79L2mXaNgA9pLz0SpHTrFozcmpYFN0oSUFxOWpxkqnipnyf7mnSlPebcB/e3CyydWoEvsX7ph5n91shaBDvZVDS7VFClGVucULqnqiry58aUqQQ4RcRJfUTwm7CjlsM+G0iSqdtlbpuJvKlOycu8UuSne5S1pwNbPcY6Cs52KVa3snlTLtYNi1CWsYwNbNM891HCEY9TJ+waPeMKzxrRb7U67/0zVxgrNKr4t7eED8DiaQg==</latexit>et!v,l2
<latexit sha1_base64="Ihtf19ON22lp3JHDwHBVXf0Kcjk=">AAAC33icjVHLSsNAFD3GV31X3ekmWAQXUtKi6LLoxmUF2wpWyyRO7dC8SCZCCQV37sStP+BW/0b8A/0L74wj+EB0QpIz595zZu69buyLVDrO84g1OjY+MVmYmp6ZnZtfKC4uNdMoSzze8CI/So5dlnJfhLwhhfT5cZxwFrg+b7n9fRVvXfIkFVF4JAcxPw3YRSi6wmOSqE5xpR0w2XO7OR+e5dJuy8i+3PSHnbw67BRLTtnRy/4JKgaUYFY9Kj6hjXNE8JAhAEcISdgHQ0rPCSpwEBN3ipy4hJDQcY4hpkmbURanDEZsn74XtDsxbEh75ZlqtUen+PQmpLSxTpqI8hLC6jRbxzPtrNjfvHPtqe42oL9rvAJiJXrE/qX7yPyvTtUi0cWurkFQTbFmVHWeccl0V9TN7U9VSXKIiVP4nOIJYU8rP/psa02qa1e9ZTr+ojMVq/aeyc3wqm5JA658H+dP0KyWK1vl7cOtUm3PjLqAVaxhg+a5gxoOUEeDvK9wjwc8Wsy6tm6s2/dUa8RolvFlWXdv8pmaQw==</latexit>et!v,l3
<latexit sha1_base64="/OJ3kz6latQm5DJ9NI6bZhTfRqM=">AAAC33icjVHLSsNAFD3GV62vqjvdBIvgQkrqA12KblxWsLZga5lMpxpMMiGZCBIK7tyJW3/Arf6N+Af6F94ZU/CB6IQkZ86958zce93I9xLlOC9D1vDI6Nh4YaI4OTU9M1uamz9OZBpzUefSl3HTZYnwvVDUlad80YxiwQLXFw33Yl/HG5ciTjwZHqmrSLQDdhZ6PY8zRVSntNgKmDp3e5non2bKbilpX675/U620e+Uyk7FMcv+Cao5KCNfNVl6RgtdSHCkCCAQQhH2wZDQc4IqHETEtZERFxPyTFygjyJpU8oSlMGIvaDvGe1OcjakvfZMjJrTKT69MSltrJBGUl5MWJ9mm3hqnDX7m3dmPPXdrujv5l4BsQrnxP6lG2T+V6drUehhx9TgUU2RYXR1PHdJTVf0ze1PVSlyiIjTuEvxmDA3ykGfbaNJTO26t8zEX02mZvWe57kp3vQtacDV7+P8CY7XK9XNytbhZnl3Lx91AUtYxirNcxu7OEANdfK+xgMe8WQx68a6te4+Uq2hXLOAL8u6fwf0+ppE</latexit>‚Ä¶‚Ä¶zv,l+11
<latexit sha1_base64="n8cGBTaXIpXzu8KnVX0ERKmfFIw=">AAAC23icjVHLSsNAFD3Gd31VBTdugkUQlJJIRZeiG5cKVgVbyySd1mBeJJNCjV25E7f+gFv9H/EP9C+8M05BLaITkpw5954zc+91Yt9LhWW9DhnDI6Nj4xOThanpmdm54vzCSRplicurbuRHyZnDUu57Ia8KT/j8LE44CxyfnzpX+zJ+2uFJ6kXhsejGvB6wdui1PJcJohrFpVrAxKXTyq97jdzuXeSdDX/d7jWKJatsqWUOAluDEvQ6jIovqKGJCC4yBOAIIQj7YEjpOYcNCzFxdeTEJYQ8FefooUDajLI4ZTBir+jbpt25ZkPaS89UqV06xac3IaWJVdJElJcQlqeZKp4pZ8n+5p0rT3m3Lv0d7RUQK3BJ7F+6fuZ/dbIWgRZ2VA0e1RQrRlbnapdMdUXe3PxSlSCHmDiJmxRPCLtK2e+zqTSpql32lqn4m8qUrNy7OjfDu7wlDdj+Oc5BcLJZtivlraNKaXdPj3oCy1jBGs1zG7s4wCGq5H2DRzzh2agbt8adcf+ZagxpzSK+LePhA6CZmJg=</latexit>zv,l+12
<latexit sha1_base64="ZxsSlrgkq2zg5Z8BmhpHdSvHYXA=">AAAC23icjVHLSsNAFD3GV62vqODGTbAIglKSUtGl6MZlBWsLbS1JOm2DeZFMChq7cidu/QG3+j/iH+hfeGdMQS2iE5KcOfeeM3PvtULXibmuv04ok1PTM7O5ufz8wuLSsrqyeh4HSWSzqh24QVS3zJi5js+q3OEuq4cRMz3LZTXr8ljEawMWxU7gn/GrkLU8s+c7Xcc2OVFtdb3pmbxvddPrYTstDS/Swa67YwzbakEv6nJp48DIQAHZqgTqC5roIICNBB4YfHDCLkzE9DRgQEdIXAspcREhR8YZhsiTNqEsRhkmsZf07dGukbE+7YVnLNU2neLSG5FSwxZpAsqLCIvTNBlPpLNgf/NOpae42xX9rczLI5ajT+xfulHmf3WiFo4uDmQNDtUUSkZUZ2cuieyKuLn2pSpODiFxAncoHhG2pXLUZ01qYlm76K0p428yU7Bib2e5Cd7FLWnAxs9xjoPzUtEoF/dOy4XDo2zUOWxgE9s0z30c4gQVVMn7Bo94wrPSUm6VO+X+M1WZyDRr+LaUhw+jApiZ</latexit>zv,l+1i
<latexit sha1_base64="JHk5JvNbNyvBSha4v4UMpM/RPiw=">AAAC23icjVHLSsNAFD3GV62vqODGTbAIglISqeiy6MalgtVCrSWJUzs0L5JJocau3Ilbf8Ct/o/4B/oX3hlT8IHohCRnzr3nzNx7ncjjiTDNlxFtdGx8YrIwVZyemZ2b1xcWT5IwjV1Wc0MvjOuOnTCPB6wmuPBYPYqZ7TseO3W6+zJ+2mNxwsPgWPQj1vTty4C3uWsLolr68plvi47Tzq4GrYwPzrPeprdhDVp6ySybahk/gZWDEvJ1GOrPOMMFQrhI4YMhgCDswUZCTwMWTETENZERFxPiKs4wQJG0KWUxyrCJ7dL3knaNnA1oLz0TpXbpFI/emJQG1kgTUl5MWJ5mqHiqnCX7m3emPOXd+vR3ci+fWIEOsX/phpn/1claBNrYVTVwqilSjKzOzV1S1RV5c+NTVYIcIuIkvqB4TNhVymGfDaVJVO2yt7aKv6pMycq9m+emeJO3pAFb38f5E5xsla1KefuoUqru5aMuYAWrWKd57qCKAxyiRt7XeMAjnrSmdqPdancfqdpIrlnCl6XdvwMnoJjQ</latexit>zv,l+1i+1
<latexit sha1_base64="toukYzcLmhiuA6Vnkl7rn3mnmdI=">AAAC3XicjVHLSsNAFD2N73fUjeAmWARBKYlUdFl041LBVqGtJYnTdmheJJNCDXXnTtz6A271d8Q/0L/wzhjBB6ITMnPm3HvOzJ3rRB5PhGk+F7SR0bHxicmp6ZnZufkFfXGploRp7LKqG3phfObYCfN4wKqCC4+dRTGzfcdjp07vQMZP+yxOeBiciEHEmr7dCXibu7YgqqWvNHxbdJ12djlsZXzTGp5n/S2P1pZeNEumGsZPYOWgiHwchfoTGrhACBcpfDAEEIQ92Ejoq8OCiYi4JjLiYkJcxRmGmCZtSlmMMmxiezR3aFfP2YD20jNRapdO8eiPSWlgnTQh5cWE5WmGiqfKWbK/eWfKU95tQKuTe/nECnSJ/Uv3kflfnaxFoI09VQOnmiLFyOrc3CVVryJvbnyqSpBDRJzEFxSPCbtK+fHOhtIkqnb5traKv6hMycq9m+emeJW3pAZb39v5E9S2S1a5tHNcLlb281ZPYhVr2KB+7qKCQxyhSt5XuMcDHrWWdq3daLfvqVoh1yzjy9Du3gBcsJlA</latexit>zv,l+1p
<latexit sha1_base64="BU/p6c1+hXgJLuyRisBN2/oP6eM=">AAAC23icjVHLSsNAFD2N7/qqCm7cBIsgKCWRii5FNy4r2FbQWiZxqsG8SCaFGrtyJ279Abf6P+If6F94Z5yCD0QnJDlz7j1n5t7rxL6XCst6KRhDwyOjY+MTxcmp6ZnZ0tx8I42yxOV1N/Kj5MhhKfe9kNeFJ3x+FCecBY7Pm87lnow3uzxJvSg8FL2YtwJ2Hnodz2WCqHZp8SRg4sLp5Ff9dh73T/Puur9m99ulslWx1DJ/AluDMvSqRaVnnOAMEVxkCMARQhD2wZDScwwbFmLiWsiJSwh5Ks7RR5G0GWVxymDEXtL3nHbHmg1pLz1TpXbpFJ/ehJQmVkgTUV5CWJ5mqnimnCX7m3euPOXdevR3tFdArMAFsX/pBpn/1claBDrYVjV4VFOsGFmdq10y1RV5c/NTVYIcYuIkPqN4QthVykGfTaVJVe2yt0zFX1WmZOXe1bkZ3uQtacD293H+BI2Nil2tbB5Uyzu7etTjWMIyVmmeW9jBPmqok/c1HvCIJ6Nl3Bi3xt1HqlHQmgV8Wcb9Ozh/mNc=</latexit>zv,l1
<latexit sha1_base64="JP2gppW+t/pS2Qvj7ttlTVeWZEo=">AAAC2nicjVHLSsNAFD2Nr1pfVXHlJlgEF1ISqeiy6MZlBfuAtpYknbaheZFMCjV0407c+gNu9YPEP9C/8M6YglpEJyQ5c+49Z+beawaOHXFNe80oc/MLi0vZ5dzK6tr6Rn5zqxb5cWixquU7ftgwjYg5tseq3OYOawQhM1zTYXVzeC7i9RELI9v3rvg4YG3X6Ht2z7YMTlQnv9NyDT4we8nNpJPok+tkdOhMcp18QStqcqmzQE9BAemq+PkXtNCFDwsxXDB44IQdGIjoaUKHhoC4NhLiQkK2jDNMkCNtTFmMMgxih/Tt066Zsh7thWck1Rad4tAbklLFPml8ygsJi9NUGY+ls2B/806kp7jbmP5m6uUSyzEg9i/dNPO/OlELRw+nsgabagokI6qzUpdYdkXcXP1SFSeHgDiBuxQPCVtSOe2zKjWRrF301pDxN5kpWLG30twY7+KWNGD95zhnQe2oqJeKx5elQvksHXUWu9jDAc3zBGVcoIIqeSd4xBOelZZyq9wp95+pSibVbOPbUh4+ALAKmDw=</latexit>zv,l2
<latexit sha1_base64="3TleVmhB5K+Mpvzo4f5+0JMhsuM=">AAAC2nicjVHLSsNAFD2Nr1pfUXHlJlgEF1LSUtFl0Y3LCvYBbS1JOm1D8yKZFGroxp249Qfc6geJf6B/4Z0xglpEJyQ5c+49Z+beawaOHXFdf8koc/MLi0vZ5dzK6tr6hrq5VY/8OLRYzfIdP2yaRsQc22M1bnOHNYOQGa7psIY5OhPxxpiFke17l3wSsI5rDDy7b1sGJ6qr7rRdgw/NfnI97Sal6VUyPnSmua6a1wu6XNosKKYgj3RVffUZbfTgw0IMFwweOGEHBiJ6WihCR0BcBwlxISFbxhmmyJE2pixGGQaxI/oOaNdKWY/2wjOSaotOcegNSalhnzQ+5YWExWmajMfSWbC/eSfSU9xtQn8z9XKJ5RgS+5fuM/O/OlELRx8nsgabagokI6qzUpdYdkXcXPtSFSeHgDiBexQPCVtS+dlnTWoiWbvorSHjrzJTsGJvpbkx3sQtacDFn+OcBfVSoVguHF2U85XTdNRZ7GIPBzTPY1Rwjipq5J3gAY94UtrKjXKr3H2kKplUs41vS7l/B7JymD0=</latexit>zv,lp
<latexit sha1_base64="Lkos4cN+2mbcQgnkVxmE4dfVQBw=">AAAC2nicjVHLSsNAFD2Nr1pfUXHlJlgEF1JSqeiy6MZlBfuAtpYknbaheZFMCjV0407c+gNu9YPEP9C/8M6YglpEJyQ5c+49Z+beawaOHXFdf80oc/MLi0vZ5dzK6tr6hrq5VYv8OLRY1fIdP2yYRsQc22NVbnOHNYKQGa7psLo5PBfx+oiFke17V3wcsLZr9D27Z1sGJ6qj7rRcgw/MXnIz6STB5DoZHTqTXEfN6wVdLm0WFFOQR7oqvvqCFrrwYSGGCwYPnLADAxE9TRShIyCujYS4kJAt4wwT5EgbUxajDIPYIX37tGumrEd74RlJtUWnOPSGpNSwTxqf8kLC4jRNxmPpLNjfvBPpKe42pr+ZernEcgyI/Us3zfyvTtTC0cOprMGmmgLJiOqs1CWWXRE3175UxckhIE7gLsVDwpZUTvusSU0kaxe9NWT8TWYKVuytNDfGu7glDbj4c5yzoHZUKJYKx5elfPksHXUWu9jDAc3zBGVcoIIqeSd4xBOelZZyq9wp95+pSibVbOPbUh4+AEexmHs=</latexit>zv,li
<latexit sha1_base64="MNUC2+WLN+z5A89WnxviBXVmBOw=">AAAC2nicjVHLSsNAFD2Nr1pfVXHlJlgEF1JSUXQpunFZwWqh1TJJp3Vw8iCZCBq6cSdu/QG3+kHiH+hfeGeMoBbRCUnOnHvPmbn3upEUiXKcl4I1Mjo2PlGcLE1Nz8zOlecXjpMwjT3e8EIZxk2XJVyKgDeUUJI3o5gz35X8xL3Y1/GTSx4nIgyO1FXET33WD0RPeEwR1SkvtX2mzt1edj3oZGJwll2uy0GpU644VccsexjUclBBvuph+RltdBHCQwofHAEUYQmGhJ4WanAQEXeKjLiYkDBxjgFKpE0pi1MGI/aCvn3atXI2oL32TIzao1MkvTEpbaySJqS8mLA+zTbx1Dhr9jfvzHjqu13R3829fGIVzon9S/eZ+V+drkWhhx1Tg6CaIsPo6rzcJTVd0Te3v1SlyCEiTuMuxWPCnlF+9tk2msTUrnvLTPzVZGpW7708N8WbviUNuPZznMPgeKNa26xuHW5WdvfyURexjBWs0Ty3sYsD1NEg7wwPeMST1bZurFvr7iPVKuSaRXxb1v07NtmYdA==</latexit>zv,li+1
<latexit sha1_base64="totUHI/wPiQucmxBH+OdvBQ8VtA=">AAAC3HicjVHLSsNAFD2N7/qKunDhJlgEQSmJVHQpunGpYB9Q25KkUx3Mi2RS0NCdO3HrD7jV7xH/QP/CO2MKahGdkOTMufecuXeuE3k8Eab5WtDGxicmp6ZnirNz8wuL+tJyLQnT2GVVN/TCuOHYCfN4wKqCC481opjZvuOxunN1JOP1PosTHgZn4jpiLd++CHiPu7YgqqOvnvu2uHR62c2gk/Eta9DO+tveoNjRS2bZVMsYBVYOSsjXSai/4BxdhHCRwgdDAEHYg42EniYsmIiIayEjLibEVZxhgCJpU8pilGETe0XfC9o1czagvfRMlNqlUzx6Y1Ia2CBNSHkxYXmaoeKpcpbsb96Z8pS1XdPfyb18YgUuif1LN8z8r072ItDDvuqBU0+RYmR3bu6SqluRlRtfuhLkEBEncZfiMWFXKYf3bChNonqXd2ur+JvKlKzcu3luindZJQ3Y+jnOUVDbKVuV8u5ppXRwmI96GmtYxybNcw8HOMYJqqr+RzzhWWtrt9qddv+ZqhVyzQq+Le3hA2uJmOQ=</latexit>‚Ä¶‚Ä¶ev,l1
<latexit sha1_base64="FQ2LR+nHsXNOMwagIVyIZ8B+/0M=">AAAC2XicjVHLSsNAFD2Nr1pf9bFzEyyCCymJVHRZdOOygn1AW0uSTtvQvEgmhRq6cCdu/QG3+kPiH+hfeGdMQS2iE5KcOfeeM3PvNQPHjrimvWaUufmFxaXscm5ldW19I7+5VYv8OLRY1fIdP2yYRsQc22NVbnOHNYKQGa7psLo5PBfx+oiFke17V3wcsLZr9D27Z1sGJ6qT32m5Bh+YvYRNrpPRoTPpJPqkky9oRU0udRboKSggXRU//4IWuvBhIYYLBg+csAMDET1N6NAQENdGQlxIyJZxhglypI0pi1GGQeyQvn3aNVPWo73wjKTaolMcekNSqtgnjU95IWFxmirjsXQW7G/eifQUdxvT30y9XGI5BsT+pZtm/lcnauHo4VTWYFNNgWREdVbqEsuuiJurX6ri5BAQJ3CX4iFhSyqnfValJpK1i94aMv4mMwUr9laaG+Nd3JIGrP8c5yyoHRX1UvH4slQon6WjzmIXezigeZ6gjAtUUCXvGzziCc9KU7lV7pT7z1Qlk2q28W0pDx83spgT</latexit>ev,l3
<latexit sha1_base64="BSDS0onGG1RywuUkQwxiS5EkHV4=">AAAC2XicjVHLSsNAFD2Nr1pf8bFzEyyCCympVnRZdOOygn1AW0uSTttgXiSTQg1duBO3/oBb/SHxD/QvvDOmoBbRCUnOnHvPmbn3moFjR1zXXzPKzOzc/EJ2Mbe0vLK6pq5v1CI/Di1WtXzHDxumETHH9liV29xhjSBkhms6rG5en4l4fcjCyPa9Sz4KWNs1+p7dsy2DE9VRt1quwQdmL2Hjq2S474w7yeG4o+b1gi6XNg2KKcgjXRVffUELXfiwEMMFgwdO2IGBiJ4mitARENdGQlxIyJZxhjFypI0pi1GGQew1ffu0a6asR3vhGUm1Rac49Iak1LBLGp/yQsLiNE3GY+ks2N+8E+kp7jaiv5l6ucRyDIj9SzfJ/K9O1MLRw4mswaaaAsmI6qzUJZZdETfXvlTFySEgTuAuxUPCllRO+qxJTSRrF701ZPxNZgpW7K00N8a7uCUNuPhznNOgdlAolgpHF6V8+TQddRbb2MEezfMYZZyjgip53+ART3hWmsqtcqfcf6YqmVSziW9LefgAPHSYFQ==</latexit>ev,l2
<latexit sha1_base64="4FBShcABWuzq/zDQiX1PyNpEsWQ=">AAAC2XicjVHLSsNAFD2Nr1pf8bFzEyyCCylpqeiy6MZlBfuAtpYknbaheZFMCjV04U7c+gNu9YfEP9C/8M4YQS2iE5KcOfeeM3PvNQPHjriuv2SUufmFxaXscm5ldW19Q93cqkd+HFqsZvmOHzZNI2KO7bEat7nDmkHIDNd0WMMcnYl4Y8zCyPa9Sz4JWMc1Bp7dty2DE9VVd9quwYdmP2HTq2R86Ey7SWnaVfN6QZdLmwXFFOSRrqqvPqONHnxYiOGCwQMn7MBARE8LRegIiOsgIS4kZMs4wxQ50saUxSjDIHZE3wHtWinr0V54RlJt0SkOvSEpNeyTxqe8kLA4TZPxWDoL9jfvRHqKu03ob6ZeLrEcQ2L/0n1m/lcnauHo40TWYFNNgWREdVbqEsuuiJtrX6ri5BAQJ3CP4iFhSyo/+6xJTSRrF701ZPxVZgpW7K00N8abuCUNuPhznLOgXioUy4Wji3K+cpqOOotd7OGA5nmMCs5RRY28r/GARzwpLeVGuVXuPlKVTKrZxrel3L8DOhOYFA==</latexit>et!v,l1
<latexit sha1_base64="mEu2FxFiywdHPUim6Z5Qni2WiXs=">AAAC33icjVHLSsNAFD3GV31H3ekmWAQXUhKp6LLoxqWCVaGtZRKnNjQvkkmhhIA7d+LWH3CrfyP+gf6Fd8YU1CI6IcmZc+85M/deO/LcRJjm65g2PjE5NV2amZ2bX1hc0pdXzpIwjR1ed0IvjC9slnDPDXhduMLjF1HMmW97/NzuHcr4eZ/HiRsGp2IQ8ZbPrgO34zpMENXW15o+E127k/H8MhNGU4RGf9vL25mVt/WyWTHVMkaBVYAyinUc6i9o4gohHKTwwRFAEPbAkNDTgAUTEXEtZMTFhFwV58gxS9qUsjhlMGJ79L2mXaNgA9pLz0SpHTrFozcmpYFN0oSUFxOWpxkqnipnyf7mnSlPebcB/e3CyydWoEvsX7ph5n91shaBDvZVDS7VFClGVucULqnqiry58aUqQQ4RcRJfUTwm7CjlsM+G0iSqdtlbpuJvKlOycu8UuSne5S1pwNbPcY6Cs52KVa3snlTLtYNi1CWsYwNbNM891HCEY9TJ+waPeMKzxrRb7U67/0zVxgrNKr4t7eED8DiaQg==</latexit>et!v,l2
<latexit sha1_base64="Ihtf19ON22lp3JHDwHBVXf0Kcjk=">AAAC33icjVHLSsNAFD3GV31X3ekmWAQXUtKi6LLoxmUF2wpWyyRO7dC8SCZCCQV37sStP+BW/0b8A/0L74wj+EB0QpIz595zZu69buyLVDrO84g1OjY+MVmYmp6ZnZtfKC4uNdMoSzze8CI/So5dlnJfhLwhhfT5cZxwFrg+b7n9fRVvXfIkFVF4JAcxPw3YRSi6wmOSqE5xpR0w2XO7OR+e5dJuy8i+3PSHnbw67BRLTtnRy/4JKgaUYFY9Kj6hjXNE8JAhAEcISdgHQ0rPCSpwEBN3ipy4hJDQcY4hpkmbURanDEZsn74XtDsxbEh75ZlqtUen+PQmpLSxTpqI8hLC6jRbxzPtrNjfvHPtqe42oL9rvAJiJXrE/qX7yPyvTtUi0cWurkFQTbFmVHWeccl0V9TN7U9VSXKIiVP4nOIJYU8rP/psa02qa1e9ZTr+ojMVq/aeyc3wqm5JA658H+dP0KyWK1vl7cOtUm3PjLqAVaxhg+a5gxoOUEeDvK9wjwc8Wsy6tm6s2/dUa8RolvFlWXdv8pmaQw==</latexit>et!v,l3
<latexit sha1_base64="/OJ3kz6latQm5DJ9NI6bZhTfRqM=">AAAC33icjVHLSsNAFD3GV62vqjvdBIvgQkrqA12KblxWsLZga5lMpxpMMiGZCBIK7tyJW3/Arf6N+Af6F94ZU/CB6IQkZ86958zce93I9xLlOC9D1vDI6Nh4YaI4OTU9M1uamz9OZBpzUefSl3HTZYnwvVDUlad80YxiwQLXFw33Yl/HG5ciTjwZHqmrSLQDdhZ6PY8zRVSntNgKmDp3e5non2bKbilpX675/U620e+Uyk7FMcv+Cao5KCNfNVl6RgtdSHCkCCAQQhH2wZDQc4IqHETEtZERFxPyTFygjyJpU8oSlMGIvaDvGe1OcjakvfZMjJrTKT69MSltrJBGUl5MWJ9mm3hqnDX7m3dmPPXdrujv5l4BsQrnxP6lG2T+V6drUehhx9TgUU2RYXR1PHdJTVf0ze1PVSlyiIjTuEvxmDA3ykGfbaNJTO26t8zEX02mZvWe57kp3vQtacDV7+P8CY7XK9XNytbhZnl3Lx91AUtYxirNcxu7OEANdfK+xgMe8WQx68a6te4+Uq2hXLOAL8u6fwf0+ppE</latexit>‚Ä¶‚Ä¶zv,l+11
<latexit sha1_base64="n8cGBTaXIpXzu8KnVX0ERKmfFIw=">AAAC23icjVHLSsNAFD3Gd31VBTdugkUQlJJIRZeiG5cKVgVbyySd1mBeJJNCjV25E7f+gFv9H/EP9C+8M05BLaITkpw5954zc+91Yt9LhWW9DhnDI6Nj4xOThanpmdm54vzCSRplicurbuRHyZnDUu57Ia8KT/j8LE44CxyfnzpX+zJ+2uFJ6kXhsejGvB6wdui1PJcJohrFpVrAxKXTyq97jdzuXeSdDX/d7jWKJatsqWUOAluDEvQ6jIovqKGJCC4yBOAIIQj7YEjpOYcNCzFxdeTEJYQ8FefooUDajLI4ZTBir+jbpt25ZkPaS89UqV06xac3IaWJVdJElJcQlqeZKp4pZ8n+5p0rT3m3Lv0d7RUQK3BJ7F+6fuZ/dbIWgRZ2VA0e1RQrRlbnapdMdUXe3PxSlSCHmDiJmxRPCLtK2e+zqTSpql32lqn4m8qUrNy7OjfDu7wlDdj+Oc5BcLJZtivlraNKaXdPj3oCy1jBGs1zG7s4wCGq5H2DRzzh2agbt8adcf+ZagxpzSK+LePhA6CZmJg=</latexit>zv,l+12
<latexit sha1_base64="ZxsSlrgkq2zg5Z8BmhpHdSvHYXA=">AAAC23icjVHLSsNAFD3GV62vqODGTbAIglKSUtGl6MZlBWsLbS1JOm2DeZFMChq7cidu/QG3+j/iH+hfeGdMQS2iE5KcOfeeM3PvtULXibmuv04ok1PTM7O5ufz8wuLSsrqyeh4HSWSzqh24QVS3zJi5js+q3OEuq4cRMz3LZTXr8ljEawMWxU7gn/GrkLU8s+c7Xcc2OVFtdb3pmbxvddPrYTstDS/Swa67YwzbakEv6nJp48DIQAHZqgTqC5roIICNBB4YfHDCLkzE9DRgQEdIXAspcREhR8YZhsiTNqEsRhkmsZf07dGukbE+7YVnLNU2neLSG5FSwxZpAsqLCIvTNBlPpLNgf/NOpae42xX9rczLI5ajT+xfulHmf3WiFo4uDmQNDtUUSkZUZ2cuieyKuLn2pSpODiFxAncoHhG2pXLUZ01qYlm76K0p428yU7Bib2e5Cd7FLWnAxs9xjoPzUtEoF/dOy4XDo2zUOWxgE9s0z30c4gQVVMn7Bo94wrPSUm6VO+X+M1WZyDRr+LaUhw+jApiZ</latexit>zv,l+1i
<latexit sha1_base64="JHk5JvNbNyvBSha4v4UMpM/RPiw=">AAAC23icjVHLSsNAFD3GV62vqODGTbAIglISqeiy6MalgtVCrSWJUzs0L5JJocau3Ilbf8Ct/o/4B/oX3hlT8IHohCRnzr3nzNx7ncjjiTDNlxFtdGx8YrIwVZyemZ2b1xcWT5IwjV1Wc0MvjOuOnTCPB6wmuPBYPYqZ7TseO3W6+zJ+2mNxwsPgWPQj1vTty4C3uWsLolr68plvi47Tzq4GrYwPzrPeprdhDVp6ySybahk/gZWDEvJ1GOrPOMMFQrhI4YMhgCDswUZCTwMWTETENZERFxPiKs4wQJG0KWUxyrCJ7dL3knaNnA1oLz0TpXbpFI/emJQG1kgTUl5MWJ5mqHiqnCX7m3emPOXd+vR3ci+fWIEOsX/phpn/1claBNrYVTVwqilSjKzOzV1S1RV5c+NTVYIcIuIkvqB4TNhVymGfDaVJVO2yt7aKv6pMycq9m+emeJO3pAFb38f5E5xsla1KefuoUqru5aMuYAWrWKd57qCKAxyiRt7XeMAjnrSmdqPdancfqdpIrlnCl6XdvwMnoJjQ</latexit>zv,l+1i+1
<latexit sha1_base64="toukYzcLmhiuA6Vnkl7rn3mnmdI=">AAAC3XicjVHLSsNAFD2N73fUjeAmWARBKYlUdFl041LBVqGtJYnTdmheJJNCDXXnTtz6A271d8Q/0L/wzhjBB6ITMnPm3HvOzJ3rRB5PhGk+F7SR0bHxicmp6ZnZufkFfXGploRp7LKqG3phfObYCfN4wKqCC4+dRTGzfcdjp07vQMZP+yxOeBiciEHEmr7dCXibu7YgqqWvNHxbdJ12djlsZXzTGp5n/S2P1pZeNEumGsZPYOWgiHwchfoTGrhACBcpfDAEEIQ92Ejoq8OCiYi4JjLiYkJcxRmGmCZtSlmMMmxiezR3aFfP2YD20jNRapdO8eiPSWlgnTQh5cWE5WmGiqfKWbK/eWfKU95tQKuTe/nECnSJ/Uv3kflfnaxFoI09VQOnmiLFyOrc3CVVryJvbnyqSpBDRJzEFxSPCbtK+fHOhtIkqnb5traKv6hMycq9m+emeJW3pAZb39v5E9S2S1a5tHNcLlb281ZPYhVr2KB+7qKCQxyhSt5XuMcDHrWWdq3daLfvqVoh1yzjy9Du3gBcsJlA</latexit>zv,l+1p
<latexit sha1_base64="BU/p6c1+hXgJLuyRisBN2/oP6eM=">AAAC23icjVHLSsNAFD2N7/qqCm7cBIsgKCWRii5FNy4r2FbQWiZxqsG8SCaFGrtyJ279Abf6P+If6F94Z5yCD0QnJDlz7j1n5t7rxL6XCst6KRhDwyOjY+MTxcmp6ZnZ0tx8I42yxOV1N/Kj5MhhKfe9kNeFJ3x+FCecBY7Pm87lnow3uzxJvSg8FL2YtwJ2Hnodz2WCqHZp8SRg4sLp5Ff9dh73T/Puur9m99ulslWx1DJ/AluDMvSqRaVnnOAMEVxkCMARQhD2wZDScwwbFmLiWsiJSwh5Ks7RR5G0GWVxymDEXtL3nHbHmg1pLz1TpXbpFJ/ehJQmVkgTUV5CWJ5mqnimnCX7m3euPOXdevR3tFdArMAFsX/pBpn/1claBDrYVjV4VFOsGFmdq10y1RV5c/NTVYIcYuIkPqN4QthVykGfTaVJVe2yt0zFX1WmZOXe1bkZ3uQtacD293H+BI2Nil2tbB5Uyzu7etTjWMIyVmmeW9jBPmqok/c1HvCIJ6Nl3Bi3xt1HqlHQmgV8Wcb9Ozh/mNc=</latexit>‚Ä¶‚Ä¶zt,l1
<latexit sha1_base64="D+TqEgOQvKoMA2eagxLaeJwdzZQ=">AAAC2XicjVHLSsNAFD2Nr1pf9bFzEyyCCymJVHRZdOOygn1AW0uSTtvQvEgmQhu6cCdu/QG3+kPiH+hfeGdMQS2iE5KcOfeeM3PvNQPHjrimvWaUufmFxaXscm5ldW19I7+5VYv8OLRY1fIdP2yYRsQc22NVbnOHNYKQGa7psLo5PBfx+g0LI9v3rvgoYG3X6Ht2z7YMTlQnv9NyDT4we8l40kn0yXXCD51JJ1/Qippc6izQU1BAuip+/gUtdOHDQgwXDB44YQcGInqa0KEhIK6NhLiQkC3jDBPkSBtTFqMMg9ghffu0a6asR3vhGUm1Rac49IakVLFPGp/yQsLiNFXGY+ks2N+8E+kp7jaiv5l6ucRyDIj9SzfN/K9O1MLRw6mswaaaAsmI6qzUJZZdETdXv1TFySEgTuAuxUPCllRO+6xKTSRrF701ZPxNZgpW7K00N8a7uCUNWP85zllQOyrqpeLxZalQPktHncUu9nBA8zxBGReooEreYzziCc9KU7lV7pT7z1Qlk2q28W0pDx9lU5gm</latexit>zt,l2
<latexit sha1_base64="Ghm9vyujTc04e+6aEoqnNPMtXyo=">AAAC2XicjVHLSsNAFD2Nr1pf8bFzEyyCCylpqeiy6MZlBfuAtpYknbaheZFMhDZ04U7c+gNu9YfEP9C/8M4YQS2iE5KcOfeeM3PvNQPHjriuv2SUufmFxaXscm5ldW19Q93cqkd+HFqsZvmOHzZNI2KO7bEat7nDmkHIDNd0WMMcnYl445qFke17l3wcsI5rDDy7b1sGJ6qr7rRdgw/NfjKZdpPS9Crhh860q+b1gi6XNguKKcgjXVVffUYbPfiwEMMFgwdO2IGBiJ4WitARENdBQlxIyJZxhilypI0pi1GGQeyIvgPatVLWo73wjKTaolMcekNSatgnjU95IWFxmibjsXQW7G/eifQUdxvT30y9XGI5hsT+pfvM/K9O1MLRx4mswaaaAsmI6qzUJZZdETfXvlTFySEgTuAexUPCllR+9lmTmkjWLnpryPirzBSs2Ftpbow3cUsacPHnOGdBvVQolgtHF+V85TQddRa72MMBzfMYFZyjihp5T/CARzwpLeVGuVXuPlKVTKrZxrel3L8DZ7qYJw==</latexit>zt,li
<latexit sha1_base64="RQEeer1klLuRct8zEJxdgWw5qV4=">AAAC2XicjVHLSsNAFD2N7/qKj52bYBFcSEmlokvRjUsFWwttLUk6bYfmRTIR2tCFO3HrD7jVHxL/QP/CO2MKahGdkOTMufecmXuvHbo8Fqb5mtOmpmdm5+YX8otLyyur+tp6NQ6SyGEVJ3CDqGZbMXO5zyqCC5fVwohZnu2yK7t/KuNXNyyKeeBfikHImp7V9XmHO5YgqqVvNjxL9OxOOhy1Uj66TsWeO2rpBbNoqmVMglIGCsjWeaC/oIE2AjhI4IHBhyDswkJMTx0lmAiJayIlLiLEVZxhhDxpE8pilGER26dvl3b1jPVpLz1jpXboFJfeiJQGdkgTUF5EWJ5mqHiinCX7m3eqPOXdBvS3My+PWIEesX/pxpn/1claBDo4UjVwqilUjKzOyVwS1RV5c+NLVYIcQuIkblM8Iuwo5bjPhtLEqnbZW0vF31SmZOXeyXITvMtb0oBLP8c5Car7xVK5eHBRLhyfZKOexxa2sUvzPMQxznCOCnkP8YgnPGt17Va70+4/U7VcptnAt6U9fADr25he</latexit>zt,li+1
<latexit sha1_base64="g1vCgBy4N+J8QydX8gZCk2TFBmo=">AAAC23icjVHLSsNAFD3G9zsquHETLIKglEQquiy6calgVWhrSdJpO5gXyUSoMSt34tYfcKv/I/6B/oV3xghqEZ2Q5My595yZe68TeTwRpvkypA2PjI6NT0xOTc/Mzs3rC4snSZjGLqu5oRfGZ46dMI8HrCa48NhZFDPbdzx26lzsy/jpJYsTHgbHoh+xpm93A97hri2IaunLDd8WPaeTXeWtjG9Y+XkmNr28pZfMsqmWMQisApRQrMNQf0YDbYRwkcIHQwBB2IONhJ46LJiIiGsiIy4mxFWcIccUaVPKYpRhE3tB3y7t6gUb0F56Jkrt0ikevTEpDayRJqS8mLA8zVDxVDlL9jfvTHnKu/Xp7xRePrECPWL/0n1m/lcnaxHoYFfVwKmmSDGyOrdwSVVX5M2NL1UJcoiIk7hN8Ziwq5SffTaUJlG1y97aKv6qMiUr926Rm+JN3pIGbP0c5yA42SpblfL2UaVU3StGPYEVrGKd5rmDKg5wiBp5X+MBj3jSmtqNdqvdfaRqQ4VmCd+Wdv8OIDqYzg==</latexit>zt,lp
<latexit sha1_base64="o/yYy+ZBLFLi9HXCuC4QM6tMQN8=">AAAC2XicjVHLSsNAFD2Nr1pf8bFzEyyCCympVHRZdOOygn1AW0uSTtvQvEgmQhu6cCdu/QG3+kPiH+hfeGdMQS2iE5KcOfeeM3PvNQPHjriuv2aUufmFxaXscm5ldW19Q93cqkV+HFqsavmOHzZMI2KO7bEqt7nDGkHIDNd0WN0cnot4/YaFke17V3wUsLZr9D27Z1sGJ6qj7rRcgw/MXjKedJJgcp3wQ2fSUfN6QZdLmwXFFOSRroqvvqCFLnxYiOGCwQMn7MBARE8TRegIiGsjIS4kZMs4wwQ50saUxSjDIHZI3z7tminr0V54RlJt0SkOvSEpNeyTxqe8kLA4TZPxWDoL9jfvRHqKu43ob6ZeLrEcA2L/0k0z/6sTtXD0cCprsKmmQDKiOit1iWVXxM21L1VxcgiIE7hL8ZCwJZXTPmtSE8naRW8NGX+TmYIVeyvNjfEubkkDLv4c5yyoHRWKpcLxZSlfPktHncUu9nBA8zxBGReooEreYzziCc9KU7lV7pT7z1Qlk2q28W0pDx/8rJhl</latexit>et,l1
<latexit sha1_base64="S70sNzlV/PnnQ4x63aDyEUBVTTA=">AAAC13icjVHLSsNAFD2Nr1pfsS7dBIvgQkoiFV0W3bisYB/S1pKk0zY0L5KJWEpxJ279Abf6R+If6F94Z0xBLaITkpw5954zc++1QteJua6/ZpS5+YXFpexybmV1bX1D3czX4iCJbFa1AzeIGpYZM9fxWZU73GWNMGKmZ7msbg1PRbx+zaLYCfwLPgpZ2zP7vtNzbJMT1VHzLc/kA6s3ZpOOcTXm++6koxb0oi6XNguMFBSQrkqgvqCFLgLYSOCBwQcn7MJETE8TBnSExLUxJi4i5Mg4wwQ50iaUxSjDJHZI3z7tminr0154xlJt0ykuvREpNeySJqC8iLA4TZPxRDoL9jfvsfQUdxvR30q9PGI5BsT+pZtm/lcnauHo4VjW4FBNoWREdXbqksiuiJtrX6ri5BASJ3CX4hFhWyqnfdakJpa1i96aMv4mMwUr9naam+Bd3JIGbPwc5yyoHRSNUvHwvFQon6SjzmIbO9ijeR6hjDNUUCXvGzziCc/KpXKr3Cn3n6lKJtVs4dtSHj4AiVCXBQ==</latexit>et,l2
<latexit sha1_base64="7x3C506QyR+T5pLCrNGALCTT0qY=">AAAC13icjVHLSsNAFD2Nr1pfsS7dBIvgQkpSKrosunFZwT6k1ZKk0zY0L5KJWEpxJ279Abf6R+If6F94Z0xBLaITkpw5954zc++1QteJua6/ZpS5+YXFpexybmV1bX1D3czX4yCJbFazAzeImpYZM9fxWY073GXNMGKmZ7msYQ1PRLxxzaLYCfxzPgrZpWf2fafn2CYnqqPm257JB1ZvzCad0tWY77uTjlrQi7pc2iwwUlBAuqqB+oI2ughgI4EHBh+csAsTMT0tGNAREneJMXERIUfGGSbIkTahLEYZJrFD+vZp10pZn/bCM5Zqm05x6Y1IqWGXNAHlRYTFaZqMJ9JZsL95j6WnuNuI/lbq5RHLMSD2L9008786UQtHD0eyBodqCiUjqrNTl0R2Rdxc+1IVJ4eQOIG7FI8I21I57bMmNbGsXfTWlPE3mSlYsbfT3ATv4pY0YOPnOGdBvVQ0ysWDs3KhcpyOOott7GCP5nmICk5RRY28b/CIJzwrF8qtcqfcf6YqmVSzhW9LefgAi7aXBg==</latexit>et,l3
<latexit sha1_base64="w6jBJRtaC7ySQEHcDtohevnrtuw=">AAAC13icjVHLSsNAFD2Nr1pfsS7dBIvgQkqqFV0W3bisYB/S1pKk0zaYF8lELKG4E7f+gFv9I/EP9C+8M6agFtEJSc6ce8+ZufeagWNHXNdfM8rM7Nz8QnYxt7S8srqmrufrkR+HFqtZvuOHTdOImGN7rMZt7rBmEDLDNR3WMK9ORLxxzcLI9r1zPgpYxzUGnt23LYMT1VXzbdfgQ7OfsHF3/zLhu864qxb0oi6XNg1KKSggXVVffUEbPfiwEMMFgwdO2IGBiJ4WStARENdBQlxIyJZxhjFypI0pi1GGQewVfQe0a6WsR3vhGUm1Rac49Iak1LBNGp/yQsLiNE3GY+ks2N+8E+kp7jaiv5l6ucRyDIn9SzfJ/K9O1MLRx5GswaaaAsmI6qzUJZZdETfXvlTFySEgTuAexUPCllRO+qxJTSRrF701ZPxNZgpW7K00N8a7uCUNuPRznNOgvlcslYsHZ+VC5TgddRab2MIOzfMQFZyiihp53+ART3hWLpRb5U65/0xVMqlmA9+W8vABjhyXBw==</latexit>zt,l+11
<latexit sha1_base64="S2eu8si6wdwZT+mLfl8Es8W4mYE=">AAAC23icjVHLSsNAFD2Nr1pfVcGNm2ARBKUkUtFl0Y3LCvYBbS1JOm2DeZFMhBq7cidu/QG3+j/iH+hfeGdMQS2iE2Zy5tx7zsydawaOHXFNe80oU9Mzs3PZ+dzC4tLySn51rRb5cWixquU7ftgwjYg5tseq3OYOawQhM1zTYXXz8kTE61csjGzfO+fDgLVdo+/ZPdsyOFGd/EbLNfjA7CXXo4uE7zm7+qiT0MwXtKImhzoJ9BQUkI6Kn39BC134sBDDBYMHTtiBgYi+JnRoCIhrIyEuJGTLOMMIOdLGlMUowyD2ktY+7Zop69FeeEZSbdEpDs2QlCq2SeNTXkhYnKbKeCydBfubdyI9xd2G9DdTL5dYjgGxf+nGmf/ViVo4ejiSNdhUUyAZUZ2VusTyVcTN1S9VcXIIiBO4S/GQsCWV43dWpSaStYu3NWT8TWYKVuytNDfGu7glNVj/2c5JUNsv6qXiwVmpUD5OW53FJrawQ/08RBmnqKBK3jd4xBOelbZyq9wp95+pSibVrOPbUB4+AJqHmJY=</latexit>zt,l+12
<latexit sha1_base64="38EXLUEbq0H7d8YpA3Q3lP/IGTk=">AAAC23icjVHLSsNAFD2N7/qqCm7cBIsgKCUpFV2KblxWsK2gtUziVIN5kUyEGrtyJ279Abf6P+If6F94Z5yCD0QnJDlz7j1n5t7rxL6XCst6KRhDwyOjY+MTxcmp6ZnZ0tx8M42yxOUNN/Kj5NBhKfe9kDeEJ3x+GCecBY7PW87Froy3LnmSelF4IHoxbwfsLPS6nssEUZ3S4nHAxLnTza/6J7lY99fsfiev9julslWx1DJ/AluDMvSqR6VnHOMUEVxkCMARQhD2wZDScwQbFmLi2siJSwh5Ks7RR5G0GWVxymDEXtD3jHZHmg1pLz1TpXbpFJ/ehJQmVkgTUV5CWJ5mqnimnCX7m3euPOXdevR3tFdArMA5sX/pBpn/1claBLrYUjV4VFOsGFmdq10y1RV5c/NTVYIcYuIkPqV4QthVykGfTaVJVe2yt0zFX1WmZOXe1bkZ3uQtacD293H+BM1qxa5VNvZr5e0dPepxLGEZqzTPTWxjD3U0yPsaD3jEk9E2boxb4+4j1ShozQK+LOP+HZzomJc=</latexit>zt,l+1i
<latexit sha1_base64="iRGyB/+tOIg0sE+BCKeBSENaSI8=">AAAC23icjVHLSsNAFD3G9zsquHETLIKglEQquiy6calgVWhrSdJpO5gXyUSoMSt34tYfcKv/I/6B/oV3xghqEZ2Q5My595yZe68TeTwRpvkypA2PjI6NT0xOTc/Mzs3rC4snSZjGLqu5oRfGZ46dMI8HrCa48NhZFDPbdzx26lzsy/jpJYsTHgbHoh+xpm93A97hri2IaunLDd8WPaeTXeXnmdj0Nqy8lfG8pZfMsqmWMQisApRQrMNQf0YDbYRwkcIHQwBB2IONhJ46LJiIiGsiIy4mxFWcIccUaVPKYpRhE3tB3y7t6gUb0F56Jkrt0ikevTEpDayRJqS8mLA8zVDxVDlL9jfvTHnKu/Xp7xRePrECPWL/0n1m/lcnaxHoYFfVwKmmSDGyOrdwSVVX5M2NL1UJcoiIk7hN8Ziwq5SffTaUJlG1y97aKv6qMiUr926Rm+JN3pIGbP0c5yA42SpblfL2UaVU3StGPYEVrGKd5rmDKg5wiBp5X+MBj3jSmtqNdqvdfaRqQ4VmCd+Wdv8OH86Yzg==</latexit>zt,l+1i+1
<latexit sha1_base64="Y7uG/XzKYd6tzeM+5AqwaFk1vkQ=">AAAC3XicjVHLSsNAFD2Nr1pfVTeCm2ARBKUkouiy6MZlBfuAWkuSTtvBvEgmgoa6cydu/QG3+jviH+hfeGdMwQeiEzJz5tx7zsyda4cuj4VhvOS0sfGJyan8dGFmdm5+obi4VI+DJHJYzQncIGraVsxc7rOa4MJlzTBilme7rGGfH8p444JFMQ/8E3EZsrZn9X3e444liOoUV049SwzsXno1PEvFlrtpDjspl3OxZJQNNfSfwMxACdmoBsVnnKKLAA4SeGDwIQi7sBDT14IJAyFxbaTERYS4ijMMUSBtQlmMMixiz2nu066VsT7tpWes1A6d4tIfkVLHOmkCyosIy9N0FU+Us2R/806Vp7zbJa125uURKzAg9i/dKPO/OlmLQA/7qgZONYWKkdU5mUuiXkXeXP9UlSCHkDiJuxSPCDtKOXpnXWliVbt8W0vFX1WmZOXeyXITvMlbUoPN7+38CerbZXOnvHu8U6ocZK3OYxVr2KB+7qGCI1RRI+9rPOART1pHu9FutbuPVC2XaZbxZWj371d6mT4=</latexit>zt,l+1p
<latexit sha1_base64="NG2RyuBAbOx3vljpkKJuIkeUOYY=">AAAC23icjVHLSsNAFD2Nr1pfVcGNm2ARBKUkUtFl0Y3LCvYBbS1JOm2DeZFMhBq7cidu/QG3+j/iH+hfeGdMQS2iE5KcOfeeM3PvNQPHjrimvWaUqemZ2bnsfG5hcWl5Jb+6Vov8OLRY1fIdP2yYRsQc22NVbnOHNYKQGa7psLp5eSLi9SsWRrbvnfNhwNqu0ffsnm0ZnKhOfqPlGnxg9pLr0UXC95xdfdRJglEnX9CKmlzqJNBTUEC6Kn7+BS104cNCDBcMHjhhBwYieprQoSEgro2EuJCQLeMMI+RIG1MWowyD2Ev69mnXTFmP9sIzkmqLTnHoDUmpYps0PuWFhMVpqozH0lmwv3kn0lPcbUh/M/VyieUYEPuXbpz5X52ohaOHI1mDTTUFkhHVWalLLLsibq5+qYqTQ0CcwF2Kh4QtqRz3WZWaSNYuemvI+JvMFKzYW2lujHdxSxqw/nOck6C2X9RLxYOzUqF8nI46i01sYYfmeYgyTlFBlbxv8IgnPCtt5Va5U+4/U5VMqlnHt6U8fAAwdZjV</latexit>‚Ä¶‚Ä¶ev!t,l1
<latexit sha1_base64="ypGAoJVA9OsHhElK8MtObYTP9MQ=">AAAC3nicjVHLSsNAFD2Nr1pfVVfiJlgEF1ISqeiy6MZlBfuAttYknbbBvEgmhRKKO3fi1h9wq58j/oH+hXfGFNQiOiHJmXPvOTP3XjNw7Ihr2mtGmZmdm1/ILuaWlldW1/LrG7XIj0OLVS3f8cOGaUTMsT1W5TZ3WCMImeGaDqub16ciXh+yMLJ974KPAtZ2jb5n92zL4ER18lst1+ADs5ewcSfRx5fJsMV9le87406+oBU1udRpoKeggHRV/PwLWujCh4UYLhg8cMIODET0NKFDQ0BcGwlxISFbxhnGyJE2pixGGQax1/Tt066Zsh7thWck1Rad4tAbklLFLml8ygsJi9NUGY+ls2B/806kp7jbiP5m6uUSyzEg9i/dJPO/OlELRw/HsgabagokI6qzUpdYdkXcXP1SFSeHgDiBuxQPCVtSOemzKjWRrF301pDxN5kpWLG30twY7+KWNGD95zinQe2gqJeKh+elQvkkHXUW29jBHs3zCGWcoYIqed/gEU94Vq6UW+VOuf9MVTKpZhPflvLwAXc3mhg=</latexit>ev!t,l2
<latexit sha1_base64="kEcFSHxnyx1lNvJviaB3bahQON0=">AAAC3nicjVHLSsNAFD2Nr1pfVVfiJlgEF1LSUtFl0Y3LCvYBba1JOm1D8yKZFEoo7tyJW3/ArX6O+Af6F94ZU1CL6IQkZ86958zcew3ftkKuaa8pZW5+YXEpvZxZWV1b38hubtVCLwpMVjU92wsahh4y23JZlVvcZg0/YLpj2KxuDM9EvD5iQWh57iUf+6zt6H3X6lmmzonqZHdajs4HRi9mk05cnFzFoxb3VH5oTzrZnJbX5FJnQSEBOSSr4mVf0EIXHkxEcMDgghO2oSOkp4kCNPjEtRETFxCyZJxhggxpI8pilKETO6Rvn3bNhHVpLzxDqTbpFJvegJQq9knjUV5AWJymyngknQX7m3csPcXdxvQ3Ei+HWI4BsX/pppn/1YlaOHo4kTVYVJMvGVGdmbhEsivi5uqXqjg5+MQJ3KV4QNiUymmfVakJZe2it7qMv8lMwYq9meRGeBe3pAEXfo5zFtSK+UIpf3RRypVPk1GnsYs9HNA8j1HGOSqokvcNHvGEZ+VauVXulPvPVCWVaLbxbSkPH3mjmhk=</latexit>ev!t,l3
<latexit sha1_base64="LI1+zXwOPtk31755qTtyZDhFhYY=">AAAC3nicjVHLSsNAFD2Nr1pfVVfiJlgEF1JSreiy6MZlBfuAttYknbaheZFMCiUUd+7ErT/gVj9H/AP9C++MKahFdEKSM+fec2buvYZvWyHXtNeUMjM7N7+QXswsLa+srmXXN6qhFwUmq5ie7QV1Qw+Zbbmswi1us7ofMN0xbFYzBmciXhuyILQ895KPfNZy9J5rdS1T50S1s1tNR+d9oxuzcTs+HF/Fwyb3VL5vj9vZnJbX5FKnQSEBOSSr7GVf0EQHHkxEcMDgghO2oSOkp4ECNPjEtRATFxCyZJxhjAxpI8pilKETO6Bvj3aNhHVpLzxDqTbpFJvegJQqdknjUV5AWJymyngknQX7m3csPcXdRvQ3Ei+HWI4+sX/pJpn/1YlaOLo4kTVYVJMvGVGdmbhEsivi5uqXqjg5+MQJ3KF4QNiUykmfVakJZe2it7qMv8lMwYq9meRGeBe3pAEXfo5zGlQP8oVi/uiimCudJqNOYxs72KN5HqOEc5RRIe8bPOIJz8q1cqvcKfefqUoq0Wzi21IePgB8D5oa</latexit>‚Ä¶‚Ä¶zt,l1
<latexit sha1_base64="D+TqEgOQvKoMA2eagxLaeJwdzZQ=">AAAC2XicjVHLSsNAFD2Nr1pf9bFzEyyCCymJVHRZdOOygn1AW0uSTtvQvEgmQhu6cCdu/QG3+kPiH+hfeGdMQS2iE5KcOfeeM3PvNQPHjrimvWaUufmFxaXscm5ldW19I7+5VYv8OLRY1fIdP2yYRsQc22NVbnOHNYKQGa7psLo5PBfx+g0LI9v3rvgoYG3X6Ht2z7YMTlQnv9NyDT4we8l40kn0yXXCD51JJ1/Qippc6izQU1BAuip+/gUtdOHDQgwXDB44YQcGInqa0KEhIK6NhLiQkC3jDBPkSBtTFqMMg9ghffu0a6asR3vhGUm1Rac49IakVLFPGp/yQsLiNFXGY+ks2N+8E+kp7jaiv5l6ucRyDIj9SzfN/K9O1MLRw6mswaaaAsmI6qzUJZZdETdXv1TFySEgTuAuxUPCllRO+6xKTSRrF701ZPxNZgpW7K00N8a7uCUNWP85zllQOyrqpeLxZalQPktHncUu9nBA8zxBGReooEreYzziCc9KU7lV7pT7z1Qlk2q28W0pDx9lU5gm</latexit>zt,l2
<latexit sha1_base64="Ghm9vyujTc04e+6aEoqnNPMtXyo=">AAAC2XicjVHLSsNAFD2Nr1pf8bFzEyyCCylpqeiy6MZlBfuAtpYknbaheZFMhDZ04U7c+gNu9YfEP9C/8M4YQS2iE5KcOfeeM3PvNQPHjriuv2SUufmFxaXscm5ldW19Q93cqkd+HFqsZvmOHzZNI2KO7bEat7nDmkHIDNd0WMMcnYl445qFke17l3wcsI5rDDy7b1sGJ6qr7rRdgw/NfjKZdpPS9Crhh860q+b1gi6XNguKKcgjXVVffUYbPfiwEMMFgwdO2IGBiJ4WitARENdBQlxIyJZxhilypI0pi1GGQeyIvgPatVLWo73wjKTaolMcekNSatgnjU95IWFxmibjsXQW7G/eifQUdxvT30y9XGI5hsT+pfvM/K9O1MLRx4mswaaaAsmI6qzUJZZdETfXvlTFySEgTuAexUPCllR+9lmTmkjWLnpryPirzBSs2Ftpbow3cUsacPHnOGdBvVQolgtHF+V85TQddRa72MMBzfMYFZyjihp5T/CARzwpLeVGuVXuPlKVTKrZxrel3L8DZ7qYJw==</latexit>zt,li
<latexit sha1_base64="RQEeer1klLuRct8zEJxdgWw5qV4=">AAAC2XicjVHLSsNAFD2N7/qKj52bYBFcSEmlokvRjUsFWwttLUk6bYfmRTIR2tCFO3HrD7jVHxL/QP/CO2MKahGdkOTMufecmXuvHbo8Fqb5mtOmpmdm5+YX8otLyyur+tp6NQ6SyGEVJ3CDqGZbMXO5zyqCC5fVwohZnu2yK7t/KuNXNyyKeeBfikHImp7V9XmHO5YgqqVvNjxL9OxOOhy1Uj66TsWeO2rpBbNoqmVMglIGCsjWeaC/oIE2AjhI4IHBhyDswkJMTx0lmAiJayIlLiLEVZxhhDxpE8pilGER26dvl3b1jPVpLz1jpXboFJfeiJQGdkgTUF5EWJ5mqHiinCX7m3eqPOXdBvS3My+PWIEesX/pxpn/1claBDo4UjVwqilUjKzOyVwS1RV5c+NLVYIcQuIkblM8Iuwo5bjPhtLEqnbZW0vF31SmZOXeyXITvMtb0oBLP8c5Car7xVK5eHBRLhyfZKOexxa2sUvzPMQxznCOCnkP8YgnPGt17Va70+4/U7VcptnAt6U9fADr25he</latexit>zt,li+1
<latexit sha1_base64="g1vCgBy4N+J8QydX8gZCk2TFBmo=">AAAC23icjVHLSsNAFD3G9zsquHETLIKglEQquiy6calgVWhrSdJpO5gXyUSoMSt34tYfcKv/I/6B/oV3xghqEZ2Q5My595yZe68TeTwRpvkypA2PjI6NT0xOTc/Mzs3rC4snSZjGLqu5oRfGZ46dMI8HrCa48NhZFDPbdzx26lzsy/jpJYsTHgbHoh+xpm93A97hri2IaunLDd8WPaeTXeWtjG9Y+XkmNr28pZfMsqmWMQisApRQrMNQf0YDbYRwkcIHQwBB2IONhJ46LJiIiGsiIy4mxFWcIccUaVPKYpRhE3tB3y7t6gUb0F56Jkrt0ikevTEpDayRJqS8mLA8zVDxVDlL9jfvTHnKu/Xp7xRePrECPWL/0n1m/lcnaxHoYFfVwKmmSDGyOrdwSVVX5M2NL1UJcoiIk7hN8Ziwq5SffTaUJlG1y97aKv6qMiUr926Rm+JN3pIGbP0c5yA42SpblfL2UaVU3StGPYEVrGKd5rmDKg5wiBp5X+MBj3jSmtqNdqvdfaRqQ4VmCd+Wdv8OIDqYzg==</latexit>zt,lp
<latexit sha1_base64="o/yYy+ZBLFLi9HXCuC4QM6tMQN8=">AAAC2XicjVHLSsNAFD2Nr1pf8bFzEyyCCympVHRZdOOygn1AW0uSTtvQvEgmQhu6cCdu/QG3+kPiH+hfeGdMQS2iE5KcOfeeM3PvNQPHjriuv2aUufmFxaXscm5ldW19Q93cqkV+HFqsavmOHzZMI2KO7bEqt7nDGkHIDNd0WN0cnot4/YaFke17V3wUsLZr9D27Z1sGJ6qj7rRcgw/MXjKedJJgcp3wQ2fSUfN6QZdLmwXFFOSRroqvvqCFLnxYiOGCwQMn7MBARE8TRegIiGsjIS4kZMs4wwQ50saUxSjDIHZI3z7tminr0V54RlJt0SkOvSEpNeyTxqe8kLA4TZPxWDoL9jfvRHqKu43ob6ZeLrEcA2L/0k0z/6sTtXD0cCprsKmmQDKiOit1iWVXxM21L1VxcgiIE7hL8ZCwJZXTPmtSE8naRW8NGX+TmYIVeyvNjfEubkkDLv4c5yyoHRWKpcLxZSlfPktHncUu9nBA8zxBGReooEreYzziCc9KU7lV7pT7z1Qlk2q28W0pDx/8rJhl</latexit>et,l1
<latexit sha1_base64="S70sNzlV/PnnQ4x63aDyEUBVTTA=">AAAC13icjVHLSsNAFD2Nr1pfsS7dBIvgQkoiFV0W3bisYB/S1pKk0zY0L5KJWEpxJ279Abf6R+If6F94Z0xBLaITkpw5954zc++1QteJua6/ZpS5+YXFpexybmV1bX1D3czX4iCJbFa1AzeIGpYZM9fxWZU73GWNMGKmZ7msbg1PRbx+zaLYCfwLPgpZ2zP7vtNzbJMT1VHzLc/kA6s3ZpOOcTXm++6koxb0oi6XNguMFBSQrkqgvqCFLgLYSOCBwQcn7MJETE8TBnSExLUxJi4i5Mg4wwQ50iaUxSjDJHZI3z7tminr0154xlJt0ykuvREpNeySJqC8iLA4TZPxRDoL9jfvsfQUdxvR30q9PGI5BsT+pZtm/lcnauHo4VjW4FBNoWREdXbqksiuiJtrX6ri5BASJ3CX4hFhWyqnfdakJpa1i96aMv4mMwUr9naam+Bd3JIGbPwc5yyoHRSNUvHwvFQon6SjzmIbO9ijeR6hjDNUUCXvGzziCc/KpXKr3Cn3n6lKJtVs4dtSHj4AiVCXBQ==</latexit>et,l2
<latexit sha1_base64="7x3C506QyR+T5pLCrNGALCTT0qY=">AAAC13icjVHLSsNAFD2Nr1pfsS7dBIvgQkpSKrosunFZwT6k1ZKk0zY0L5KJWEpxJ279Abf6R+If6F94Z0xBLaITkpw5954zc++1QteJua6/ZpS5+YXFpexybmV1bX1D3czX4yCJbFazAzeImpYZM9fxWY073GXNMGKmZ7msYQ1PRLxxzaLYCfxzPgrZpWf2fafn2CYnqqPm257JB1ZvzCad0tWY77uTjlrQi7pc2iwwUlBAuqqB+oI2ughgI4EHBh+csAsTMT0tGNAREneJMXERIUfGGSbIkTahLEYZJrFD+vZp10pZn/bCM5Zqm05x6Y1IqWGXNAHlRYTFaZqMJ9JZsL95j6WnuNuI/lbq5RHLMSD2L9008786UQtHD0eyBodqCiUjqrNTl0R2Rdxc+1IVJ4eQOIG7FI8I21I57bMmNbGsXfTWlPE3mSlYsbfT3ATv4pY0YOPnOGdBvVQ0ysWDs3KhcpyOOott7GCP5nmICk5RRY28b/CIJzwrF8qtcqfcf6YqmVSzhW9LefgAi7aXBg==</latexit>et,l3
<latexit sha1_base64="w6jBJRtaC7ySQEHcDtohevnrtuw=">AAAC13icjVHLSsNAFD2Nr1pfsS7dBIvgQkqqFV0W3bisYB/S1pKk0zaYF8lELKG4E7f+gFv9I/EP9C+8M6agFtEJSc6ce8+ZufeagWNHXNdfM8rM7Nz8QnYxt7S8srqmrufrkR+HFqtZvuOHTdOImGN7rMZt7rBmEDLDNR3WMK9ORLxxzcLI9r1zPgpYxzUGnt23LYMT1VXzbdfgQ7OfsHF3/zLhu864qxb0oi6XNg1KKSggXVVffUEbPfiwEMMFgwdO2IGBiJ4WStARENdBQlxIyJZxhjFypI0pi1GGQewVfQe0a6WsR3vhGUm1Rac49Iak1LBNGp/yQsLiNE3GY+ks2N+8E+kp7jaiv5l6ucRyDIn9SzfJ/K9O1MLRx5GswaaaAsmI6qzUJZZdETfXvlTFySEgTuAexUPCllRO+qxJTSRrF701ZPxNZgpW7K00N8a7uCUNuPRznNOgvlcslYsHZ+VC5TgddRab2MIOzfMQFZyiihp53+ART3hWLpRb5U65/0xVMqlmA9+W8vABjhyXBw==</latexit>zt,l+11
<latexit sha1_base64="S2eu8si6wdwZT+mLfl8Es8W4mYE=">AAAC23icjVHLSsNAFD2Nr1pfVcGNm2ARBKUkUtFl0Y3LCvYBbS1JOm2DeZFMhBq7cidu/QG3+j/iH+hfeGdMQS2iE2Zy5tx7zsydawaOHXFNe80oU9Mzs3PZ+dzC4tLySn51rRb5cWixquU7ftgwjYg5tseq3OYOawQhM1zTYXXz8kTE61csjGzfO+fDgLVdo+/ZPdsyOFGd/EbLNfjA7CXXo4uE7zm7+qiT0MwXtKImhzoJ9BQUkI6Kn39BC134sBDDBYMHTtiBgYi+JnRoCIhrIyEuJGTLOMMIOdLGlMUowyD2ktY+7Zop69FeeEZSbdEpDs2QlCq2SeNTXkhYnKbKeCydBfubdyI9xd2G9DdTL5dYjgGxf+nGmf/ViVo4ejiSNdhUUyAZUZ2VusTyVcTN1S9VcXIIiBO4S/GQsCWV43dWpSaStYu3NWT8TWYKVuytNDfGu7glNVj/2c5JUNsv6qXiwVmpUD5OW53FJrawQ/08RBmnqKBK3jd4xBOelbZyq9wp95+pSibVrOPbUB4+AJqHmJY=</latexit>zt,l+12
<latexit sha1_base64="38EXLUEbq0H7d8YpA3Q3lP/IGTk=">AAAC23icjVHLSsNAFD2N7/qqCm7cBIsgKCUpFV2KblxWsK2gtUziVIN5kUyEGrtyJ279Abf6P+If6F94Z5yCD0QnJDlz7j1n5t7rxL6XCst6KRhDwyOjY+MTxcmp6ZnZ0tx8M42yxOUNN/Kj5NBhKfe9kDeEJ3x+GCecBY7PW87Froy3LnmSelF4IHoxbwfsLPS6nssEUZ3S4nHAxLnTza/6J7lY99fsfiev9julslWx1DJ/AluDMvSqR6VnHOMUEVxkCMARQhD2wZDScwQbFmLi2siJSwh5Ks7RR5G0GWVxymDEXtD3jHZHmg1pLz1TpXbpFJ/ehJQmVkgTUV5CWJ5mqnimnCX7m3euPOXdevR3tFdArMA5sX/pBpn/1claBLrYUjV4VFOsGFmdq10y1RV5c/NTVYIcYuIkPqV4QthVykGfTaVJVe2yt0zFX1WmZOXe1bkZ3uQtacD293H+BM1qxa5VNvZr5e0dPepxLGEZqzTPTWxjD3U0yPsaD3jEk9E2boxb4+4j1ShozQK+LOP+HZzomJc=</latexit>zt,l+1i
<latexit sha1_base64="iRGyB/+tOIg0sE+BCKeBSENaSI8=">AAAC23icjVHLSsNAFD3G9zsquHETLIKglEQquiy6calgVWhrSdJpO5gXyUSoMSt34tYfcKv/I/6B/oV3xghqEZ2Q5My595yZe68TeTwRpvkypA2PjI6NT0xOTc/Mzs3rC4snSZjGLqu5oRfGZ46dMI8HrCa48NhZFDPbdzx26lzsy/jpJYsTHgbHoh+xpm93A97hri2IaunLDd8WPaeTXeXnmdj0Nqy8lfG8pZfMsqmWMQisApRQrMNQf0YDbYRwkcIHQwBB2IONhJ46LJiIiGsiIy4mxFWcIccUaVPKYpRhE3tB3y7t6gUb0F56Jkrt0ikevTEpDayRJqS8mLA8zVDxVDlL9jfvTHnKu/Xp7xRePrECPWL/0n1m/lcnaxHoYFfVwKmmSDGyOrdwSVVX5M2NL1UJcoiIk7hN8Ziwq5SffTaUJlG1y97aKv6qMiUr926Rm+JN3pIGbP0c5yA42SpblfL2UaVU3StGPYEVrGKd5rmDKg5wiBp5X+MBj3jSmtqNdqvdfaRqQ4VmCd+Wdv8OH86Yzg==</latexit>zt,l+1i+1
<latexit sha1_base64="Y7uG/XzKYd6tzeM+5AqwaFk1vkQ=">AAAC3XicjVHLSsNAFD2Nr1pfVTeCm2ARBKUkouiy6MZlBfuAWkuSTtvBvEgmgoa6cydu/QG3+jviH+hfeGdMwQeiEzJz5tx7zsyda4cuj4VhvOS0sfGJyan8dGFmdm5+obi4VI+DJHJYzQncIGraVsxc7rOa4MJlzTBilme7rGGfH8p444JFMQ/8E3EZsrZn9X3e444liOoUV049SwzsXno1PEvFlrtpDjspl3OxZJQNNfSfwMxACdmoBsVnnKKLAA4SeGDwIQi7sBDT14IJAyFxbaTERYS4ijMMUSBtQlmMMixiz2nu066VsT7tpWes1A6d4tIfkVLHOmkCyosIy9N0FU+Us2R/806Vp7zbJa125uURKzAg9i/dKPO/OlmLQA/7qgZONYWKkdU5mUuiXkXeXP9UlSCHkDiJuxSPCDtKOXpnXWliVbt8W0vFX1WmZOXeyXITvMlbUoPN7+38CerbZXOnvHu8U6ocZK3OYxVr2KB+7qGCI1RRI+9rPOART1pHu9FutbuPVC2XaZbxZWj371d6mT4=</latexit>zt,l+1p
<latexit sha1_base64="NG2RyuBAbOx3vljpkKJuIkeUOYY=">AAAC23icjVHLSsNAFD2Nr1pfVcGNm2ARBKUkUtFl0Y3LCvYBbS1JOm2DeZFMhBq7cidu/QG3+j/iH+hfeGdMQS2iE5KcOfeeM3PvNQPHjrimvWaUqemZ2bnsfG5hcWl5Jb+6Vov8OLRY1fIdP2yYRsQc22NVbnOHNYKQGa7psLp5eSLi9SsWRrbvnfNhwNqu0ffsnm0ZnKhOfqPlGnxg9pLr0UXC95xdfdRJglEnX9CKmlzqJNBTUEC6Kn7+BS104cNCDBcMHjhhBwYieprQoSEgro2EuJCQLeMMI+RIG1MWowyD2Ev69mnXTFmP9sIzkmqLTnHoDUmpYps0PuWFhMVpqozH0lmwv3kn0lPcbUh/M/VyieUYEPuXbpz5X52ohaOHI1mDTTUFkhHVWalLLLsibq5+qYqTQ0CcwF2Kh4QtqRz3WZWaSNYuemvI+JvMFKzYW2lujHdxSxqw/nOck6C2X9RLxYOzUqF8nI46i01sYYfmeYgyTlFBlbxv8IgnPCtt5Va5U+4/U5VMqlnHt6U8fAAwdZjV</latexit>‚Ä¶‚Ä¶ev!t,l1
<latexit sha1_base64="ypGAoJVA9OsHhElK8MtObYTP9MQ=">AAAC3nicjVHLSsNAFD2Nr1pfVVfiJlgEF1ISqeiy6MZlBfuAttYknbbBvEgmhRKKO3fi1h9wq58j/oH+hXfGFNQiOiHJmXPvOTP3XjNw7Ihr2mtGmZmdm1/ILuaWlldW1/LrG7XIj0OLVS3f8cOGaUTMsT1W5TZ3WCMImeGaDqub16ciXh+yMLJ974KPAtZ2jb5n92zL4ER18lst1+ADs5ewcSfRx5fJsMV9le87406+oBU1udRpoKeggHRV/PwLWujCh4UYLhg8cMIODET0NKFDQ0BcGwlxISFbxhnGyJE2pixGGQax1/Tt066Zsh7thWck1Rad4tAbklLFLml8ygsJi9NUGY+ls2B/806kp7jbiP5m6uUSyzEg9i/dJPO/OlELRw/HsgabagokI6qzUpdYdkXcXP1SFSeHgDiBuxQPCVtSOemzKjWRrF301pDxN5kpWLG30twY7+KWNGD95zinQe2gqJeKh+elQvkkHXUW29jBHs3zCGWcoYIqed/gEU94Vq6UW+VOuf9MVTKpZhPflvLwAXc3mhg=</latexit>ev!t,l2
<latexit sha1_base64="kEcFSHxnyx1lNvJviaB3bahQON0=">AAAC3nicjVHLSsNAFD2Nr1pfVVfiJlgEF1LSUtFl0Y3LCvYBba1JOm1D8yKZFEoo7tyJW3/ArX6O+Af6F94ZU1CL6IQkZ86958zcew3ftkKuaa8pZW5+YXEpvZxZWV1b38hubtVCLwpMVjU92wsahh4y23JZlVvcZg0/YLpj2KxuDM9EvD5iQWh57iUf+6zt6H3X6lmmzonqZHdajs4HRi9mk05cnFzFoxb3VH5oTzrZnJbX5FJnQSEBOSSr4mVf0EIXHkxEcMDgghO2oSOkp4kCNPjEtRETFxCyZJxhggxpI8pilKETO6Rvn3bNhHVpLzxDqTbpFJvegJQq9knjUV5AWJymyngknQX7m3csPcXdxvQ3Ei+HWI4BsX/pppn/1YlaOHo4kTVYVJMvGVGdmbhEsivi5uqXqjg5+MQJ3KV4QNiUymmfVakJZe2it7qMv8lMwYq9meRGeBe3pAEXfo5zFtSK+UIpf3RRypVPk1GnsYs9HNA8j1HGOSqokvcNHvGEZ+VauVXulPvPVCWVaLbxbSkPH3mjmhk=</latexit>ev!t,l3
<latexit sha1_base64="LI1+zXwOPtk31755qTtyZDhFhYY=">AAAC3nicjVHLSsNAFD2Nr1pfVVfiJlgEF1JSreiy6MZlBfuAttYknbaheZFMCiUUd+7ErT/gVj9H/AP9C++MKahFdEKSM+fec2buvYZvWyHXtNeUMjM7N7+QXswsLa+srmXXN6qhFwUmq5ie7QV1Qw+Zbbmswi1us7ofMN0xbFYzBmciXhuyILQ895KPfNZy9J5rdS1T50S1s1tNR+d9oxuzcTs+HF/Fwyb3VL5vj9vZnJbX5FKnQSEBOSSr7GVf0EQHHkxEcMDgghO2oSOkp4ECNPjEtRATFxCyZJxhjAxpI8pilKETO6Bvj3aNhHVpLzxDqTbpFJvegJQqdknjUV5AWJymyngknQX7m3csPcXdRvQ3Ei+HWI4+sX/pJpn/1YlaOLo4kTVYVJMvGVGdmbhEsivi5uqXqjg5+MQJ3KF4QNiUykmfVakJZe2it7qMv8lMwYq9meRGeBe3pAEXfo5zGlQP8oVi/uiimCudJqNOYxs72KN5HqOEc5RRIe8bPOIJz8q1cqvcKfefqUoq0Wzi21IePgB8D5oa</latexit>‚Ä¶‚Ä¶zt,l1
<latexit sha1_base64="D+TqEgOQvKoMA2eagxLaeJwdzZQ=">AAAC2XicjVHLSsNAFD2Nr1pf9bFzEyyCCymJVHRZdOOygn1AW0uSTtvQvEgmQhu6cCdu/QG3+kPiH+hfeGdMQS2iE5KcOfeeM3PvNQPHjrimvWaUufmFxaXscm5ldW19I7+5VYv8OLRY1fIdP2yYRsQc22NVbnOHNYKQGa7psLo5PBfx+g0LI9v3rvgoYG3X6Ht2z7YMTlQnv9NyDT4we8l40kn0yXXCD51JJ1/Qippc6izQU1BAuip+/gUtdOHDQgwXDB44YQcGInqa0KEhIK6NhLiQkC3jDBPkSBtTFqMMg9ghffu0a6asR3vhGUm1Rac49IakVLFPGp/yQsLiNFXGY+ks2N+8E+kp7jaiv5l6ucRyDIj9SzfN/K9O1MLRw6mswaaaAsmI6qzUJZZdETdXv1TFySEgTuAuxUPCllRO+6xKTSRrF701ZPxNZgpW7K00N8a7uCUNWP85zllQOyrqpeLxZalQPktHncUu9nBA8zxBGReooEreYzziCc9KU7lV7pT7z1Qlk2q28W0pDx9lU5gm</latexit>zt,l2
<latexit sha1_base64="Ghm9vyujTc04e+6aEoqnNPMtXyo=">AAAC2XicjVHLSsNAFD2Nr1pf8bFzEyyCCylpqeiy6MZlBfuAtpYknbaheZFMhDZ04U7c+gNu9YfEP9C/8M4YQS2iE5KcOfeeM3PvNQPHjriuv2SUufmFxaXscm5ldW19Q93cqkd+HFqsZvmOHzZNI2KO7bEat7nDmkHIDNd0WMMcnYl445qFke17l3wcsI5rDDy7b1sGJ6qr7rRdgw/NfjKZdpPS9Crhh860q+b1gi6XNguKKcgjXVVffUYbPfiwEMMFgwdO2IGBiJ4WitARENdBQlxIyJZxhilypI0pi1GGQeyIvgPatVLWo73wjKTaolMcekNSatgnjU95IWFxmibjsXQW7G/eifQUdxvT30y9XGI5hsT+pfvM/K9O1MLRx4mswaaaAsmI6qzUJZZdETfXvlTFySEgTuAexUPCllR+9lmTmkjWLnpryPirzBSs2Ftpbow3cUsacPHnOGdBvVQolgtHF+V85TQddRa72MMBzfMYFZyjihp5T/CARzwpLeVGuVXuPlKVTKrZxrel3L8DZ7qYJw==</latexit>zt,li
<latexit sha1_base64="RQEeer1klLuRct8zEJxdgWw5qV4=">AAAC2XicjVHLSsNAFD2N7/qKj52bYBFcSEmlokvRjUsFWwttLUk6bYfmRTIR2tCFO3HrD7jVHxL/QP/CO2MKahGdkOTMufecmXuvHbo8Fqb5mtOmpmdm5+YX8otLyyur+tp6NQ6SyGEVJ3CDqGZbMXO5zyqCC5fVwohZnu2yK7t/KuNXNyyKeeBfikHImp7V9XmHO5YgqqVvNjxL9OxOOhy1Uj66TsWeO2rpBbNoqmVMglIGCsjWeaC/oIE2AjhI4IHBhyDswkJMTx0lmAiJayIlLiLEVZxhhDxpE8pilGER26dvl3b1jPVpLz1jpXboFJfeiJQGdkgTUF5EWJ5mqHiinCX7m3eqPOXdBvS3My+PWIEesX/pxpn/1claBDo4UjVwqilUjKzOyVwS1RV5c+NLVYIcQuIkblM8Iuwo5bjPhtLEqnbZW0vF31SmZOXeyXITvMtb0oBLP8c5Car7xVK5eHBRLhyfZKOexxa2sUvzPMQxznCOCnkP8YgnPGt17Va70+4/U7VcptnAt6U9fADr25he</latexit>zt,li+1
<latexit sha1_base64="g1vCgBy4N+J8QydX8gZCk2TFBmo=">AAAC23icjVHLSsNAFD3G9zsquHETLIKglEQquiy6calgVWhrSdJpO5gXyUSoMSt34tYfcKv/I/6B/oV3xghqEZ2Q5My595yZe68TeTwRpvkypA2PjI6NT0xOTc/Mzs3rC4snSZjGLqu5oRfGZ46dMI8HrCa48NhZFDPbdzx26lzsy/jpJYsTHgbHoh+xpm93A97hri2IaunLDd8WPaeTXeWtjG9Y+XkmNr28pZfMsqmWMQisApRQrMNQf0YDbYRwkcIHQwBB2IONhJ46LJiIiGsiIy4mxFWcIccUaVPKYpRhE3tB3y7t6gUb0F56Jkrt0ikevTEpDayRJqS8mLA8zVDxVDlL9jfvTHnKu/Xp7xRePrECPWL/0n1m/lcnaxHoYFfVwKmmSDGyOrdwSVVX5M2NL1UJcoiIk7hN8Ziwq5SffTaUJlG1y97aKv6qMiUr926Rm+JN3pIGbP0c5yA42SpblfL2UaVU3StGPYEVrGKd5rmDKg5wiBp5X+MBj3jSmtqNdqvdfaRqQ4VmCd+Wdv8OIDqYzg==</latexit>zt,lp
<latexit sha1_base64="o/yYy+ZBLFLi9HXCuC4QM6tMQN8=">AAAC2XicjVHLSsNAFD2Nr1pf8bFzEyyCCympVHRZdOOygn1AW0uSTtvQvEgmQhu6cCdu/QG3+kPiH+hfeGdMQS2iE5KcOfeeM3PvNQPHjriuv2aUufmFxaXscm5ldW19Q93cqkV+HFqsavmOHzZMI2KO7bEqt7nDGkHIDNd0WN0cnot4/YaFke17V3wUsLZr9D27Z1sGJ6qj7rRcgw/MXjKedJJgcp3wQ2fSUfN6QZdLmwXFFOSRroqvvqCFLnxYiOGCwQMn7MBARE8TRegIiGsjIS4kZMs4wwQ50saUxSjDIHZI3z7tminr0V54RlJt0SkOvSEpNeyTxqe8kLA4TZPxWDoL9jfvRHqKu43ob6ZeLrEcA2L/0k0z/6sTtXD0cCprsKmmQDKiOit1iWVXxM21L1VxcgiIE7hL8ZCwJZXTPmtSE8naRW8NGX+TmYIVeyvNjfEubkkDLv4c5yyoHRWKpcLxZSlfPktHncUu9nBA8zxBGReooEreYzziCc9KU7lV7pT7z1Qlk2q28W0pDx/8rJhl</latexit>et,l1
<latexit sha1_base64="S70sNzlV/PnnQ4x63aDyEUBVTTA=">AAAC13icjVHLSsNAFD2Nr1pfsS7dBIvgQkoiFV0W3bisYB/S1pKk0zY0L5KJWEpxJ279Abf6R+If6F94Z0xBLaITkpw5954zc++1QteJua6/ZpS5+YXFpexybmV1bX1D3czX4iCJbFa1AzeIGpYZM9fxWZU73GWNMGKmZ7msbg1PRbx+zaLYCfwLPgpZ2zP7vtNzbJMT1VHzLc/kA6s3ZpOOcTXm++6koxb0oi6XNguMFBSQrkqgvqCFLgLYSOCBwQcn7MJETE8TBnSExLUxJi4i5Mg4wwQ50iaUxSjDJHZI3z7tminr0154xlJt0ykuvREpNeySJqC8iLA4TZPxRDoL9jfvsfQUdxvR30q9PGI5BsT+pZtm/lcnauHo4VjW4FBNoWREdXbqksiuiJtrX6ri5BASJ3CX4hFhWyqnfdakJpa1i96aMv4mMwUr9naam+Bd3JIGbPwc5yyoHRSNUvHwvFQon6SjzmIbO9ijeR6hjDNUUCXvGzziCc/KpXKr3Cn3n6lKJtVs4dtSHj4AiVCXBQ==</latexit>et,l2
<latexit sha1_base64="7x3C506QyR+T5pLCrNGALCTT0qY=">AAAC13icjVHLSsNAFD2Nr1pfsS7dBIvgQkpSKrosunFZwT6k1ZKk0zY0L5KJWEpxJ279Abf6R+If6F94Z0xBLaITkpw5954zc++1QteJua6/ZpS5+YXFpexybmV1bX1D3czX4yCJbFazAzeImpYZM9fxWY073GXNMGKmZ7msYQ1PRLxxzaLYCfxzPgrZpWf2fafn2CYnqqPm257JB1ZvzCad0tWY77uTjlrQi7pc2iwwUlBAuqqB+oI2ughgI4EHBh+csAsTMT0tGNAREneJMXERIUfGGSbIkTahLEYZJrFD+vZp10pZn/bCM5Zqm05x6Y1IqWGXNAHlRYTFaZqMJ9JZsL95j6WnuNuI/lbq5RHLMSD2L9008786UQtHD0eyBodqCiUjqrNTl0R2Rdxc+1IVJ4eQOIG7FI8I21I57bMmNbGsXfTWlPE3mSlYsbfT3ATv4pY0YOPnOGdBvVQ0ysWDs3KhcpyOOott7GCP5nmICk5RRY28b/CIJzwrF8qtcqfcf6YqmVSzhW9LefgAi7aXBg==</latexit>et,l3
<latexit sha1_base64="w6jBJRtaC7ySQEHcDtohevnrtuw=">AAAC13icjVHLSsNAFD2Nr1pfsS7dBIvgQkqqFV0W3bisYB/S1pKk0zaYF8lELKG4E7f+gFv9I/EP9C+8M6agFtEJSc6ce8+ZufeagWNHXNdfM8rM7Nz8QnYxt7S8srqmrufrkR+HFqtZvuOHTdOImGN7rMZt7rBmEDLDNR3WMK9ORLxxzcLI9r1zPgpYxzUGnt23LYMT1VXzbdfgQ7OfsHF3/zLhu864qxb0oi6XNg1KKSggXVVffUEbPfiwEMMFgwdO2IGBiJ4WStARENdBQlxIyJZxhjFypI0pi1GGQewVfQe0a6WsR3vhGUm1Rac49Iak1LBNGp/yQsLiNE3GY+ks2N+8E+kp7jaiv5l6ucRyDIn9SzfJ/K9O1MLRx5GswaaaAsmI6qzUJZZdETfXvlTFySEgTuAexUPCllRO+qxJTSRrF701ZPxNZgpW7K00N8a7uCUNuPRznNOgvlcslYsHZ+VC5TgddRab2MIOzfMQFZyiihp53+ART3hWLpRb5U65/0xVMqlmA9+W8vABjhyXBw==</latexit>zt,l+11
<latexit sha1_base64="S2eu8si6wdwZT+mLfl8Es8W4mYE=">AAAC23icjVHLSsNAFD2Nr1pfVcGNm2ARBKUkUtFl0Y3LCvYBbS1JOm2DeZFMhBq7cidu/QG3+j/iH+hfeGdMQS2iE2Zy5tx7zsydawaOHXFNe80oU9Mzs3PZ+dzC4tLySn51rRb5cWixquU7ftgwjYg5tseq3OYOawQhM1zTYXXz8kTE61csjGzfO+fDgLVdo+/ZPdsyOFGd/EbLNfjA7CXXo4uE7zm7+qiT0MwXtKImhzoJ9BQUkI6Kn39BC134sBDDBYMHTtiBgYi+JnRoCIhrIyEuJGTLOMMIOdLGlMUowyD2ktY+7Zop69FeeEZSbdEpDs2QlCq2SeNTXkhYnKbKeCydBfubdyI9xd2G9DdTL5dYjgGxf+nGmf/ViVo4ejiSNdhUUyAZUZ2VusTyVcTN1S9VcXIIiBO4S/GQsCWV43dWpSaStYu3NWT8TWYKVuytNDfGu7glNVj/2c5JUNsv6qXiwVmpUD5OW53FJrawQ/08RBmnqKBK3jd4xBOelbZyq9wp95+pSibVrOPbUB4+AJqHmJY=</latexit>zt,l+12
<latexit sha1_base64="38EXLUEbq0H7d8YpA3Q3lP/IGTk=">AAAC23icjVHLSsNAFD2N7/qqCm7cBIsgKCUpFV2KblxWsK2gtUziVIN5kUyEGrtyJ279Abf6P+If6F94Z5yCD0QnJDlz7j1n5t7rxL6XCst6KRhDwyOjY+MTxcmp6ZnZ0tx8M42yxOUNN/Kj5NBhKfe9kDeEJ3x+GCecBY7PW87Froy3LnmSelF4IHoxbwfsLPS6nssEUZ3S4nHAxLnTza/6J7lY99fsfiev9julslWx1DJ/AluDMvSqR6VnHOMUEVxkCMARQhD2wZDScwQbFmLi2siJSwh5Ks7RR5G0GWVxymDEXtD3jHZHmg1pLz1TpXbpFJ/ehJQmVkgTUV5CWJ5mqnimnCX7m3euPOXdevR3tFdArMA5sX/pBpn/1claBLrYUjV4VFOsGFmdq10y1RV5c/NTVYIcYuIkPqV4QthVykGfTaVJVe2yt0zFX1WmZOXe1bkZ3uQtacD293H+BM1qxa5VNvZr5e0dPepxLGEZqzTPTWxjD3U0yPsaD3jEk9E2boxb4+4j1ShozQK+LOP+HZzomJc=</latexit>zt,l+1i
<latexit sha1_base64="iRGyB/+tOIg0sE+BCKeBSENaSI8=">AAAC23icjVHLSsNAFD3G9zsquHETLIKglEQquiy6calgVWhrSdJpO5gXyUSoMSt34tYfcKv/I/6B/oV3xghqEZ2Q5My595yZe68TeTwRpvkypA2PjI6NT0xOTc/Mzs3rC4snSZjGLqu5oRfGZ46dMI8HrCa48NhZFDPbdzx26lzsy/jpJYsTHgbHoh+xpm93A97hri2IaunLDd8WPaeTXeXnmdj0Nqy8lfG8pZfMsqmWMQisApRQrMNQf0YDbYRwkcIHQwBB2IONhJ46LJiIiGsiIy4mxFWcIccUaVPKYpRhE3tB3y7t6gUb0F56Jkrt0ikevTEpDayRJqS8mLA8zVDxVDlL9jfvTHnKu/Xp7xRePrECPWL/0n1m/lcnaxHoYFfVwKmmSDGyOrdwSVVX5M2NL1UJcoiIk7hN8Ziwq5SffTaUJlG1y97aKv6qMiUr926Rm+JN3pIGbP0c5yA42SpblfL2UaVU3StGPYEVrGKd5rmDKg5wiBp5X+MBj3jSmtqNdqvdfaRqQ4VmCd+Wdv8OH86Yzg==</latexit>zt,l+1i+1
<latexit sha1_base64="Y7uG/XzKYd6tzeM+5AqwaFk1vkQ=">AAAC3XicjVHLSsNAFD2Nr1pfVTeCm2ARBKUkouiy6MZlBfuAWkuSTtvBvEgmgoa6cydu/QG3+jviH+hfeGdMwQeiEzJz5tx7zsyda4cuj4VhvOS0sfGJyan8dGFmdm5+obi4VI+DJHJYzQncIGraVsxc7rOa4MJlzTBilme7rGGfH8p444JFMQ/8E3EZsrZn9X3e444liOoUV049SwzsXno1PEvFlrtpDjspl3OxZJQNNfSfwMxACdmoBsVnnKKLAA4SeGDwIQi7sBDT14IJAyFxbaTERYS4ijMMUSBtQlmMMixiz2nu066VsT7tpWes1A6d4tIfkVLHOmkCyosIy9N0FU+Us2R/806Vp7zbJa125uURKzAg9i/dKPO/OlmLQA/7qgZONYWKkdU5mUuiXkXeXP9UlSCHkDiJuxSPCDtKOXpnXWliVbt8W0vFX1WmZOXeyXITvMlbUoPN7+38CerbZXOnvHu8U6ocZK3OYxVr2KB+7qGCI1RRI+9rPOART1pHu9FutbuPVC2XaZbxZWj371d6mT4=</latexit>zt,l+1p
<latexit sha1_base64="NG2RyuBAbOx3vljpkKJuIkeUOYY=">AAAC23icjVHLSsNAFD2Nr1pfVcGNm2ARBKUkUtFl0Y3LCvYBbS1JOm2DeZFMhBq7cidu/QG3+j/iH+hfeGdMQS2iE5KcOfeeM3PvNQPHjrimvWaUqemZ2bnsfG5hcWl5Jb+6Vov8OLRY1fIdP2yYRsQc22NVbnOHNYKQGa7psLp5eSLi9SsWRrbvnfNhwNqu0ffsnm0ZnKhOfqPlGnxg9pLr0UXC95xdfdRJglEnX9CKmlzqJNBTUEC6Kn7+BS104cNCDBcMHjhhBwYieprQoSEgro2EuJCQLeMMI+RIG1MWowyD2Ev69mnXTFmP9sIzkmqLTnHoDUmpYps0PuWFhMVpqozH0lmwv3kn0lPcbUh/M/VyieUYEPuXbpz5X52ohaOHI1mDTTUFkhHVWalLLLsibq5+qYqTQ0CcwF2Kh4QtqRz3WZWaSNYuemvI+JvMFKzYW2lujHdxSxqw/nOck6C2X9RLxYOzUqF8nI46i01sYYfmeYgyTlFBlbxv8IgnPCtt5Va5U+4/U5VMqlnHt6U8fAAwdZjV</latexit>‚Ä¶‚Ä¶ev!t,l1
<latexit sha1_base64="ypGAoJVA9OsHhElK8MtObYTP9MQ=">AAAC3nicjVHLSsNAFD2Nr1pfVVfiJlgEF1ISqeiy6MZlBfuAttYknbbBvEgmhRKKO3fi1h9wq58j/oH+hXfGFNQiOiHJmXPvOTP3XjNw7Ihr2mtGmZmdm1/ILuaWlldW1/LrG7XIj0OLVS3f8cOGaUTMsT1W5TZ3WCMImeGaDqub16ciXh+yMLJ974KPAtZ2jb5n92zL4ER18lst1+ADs5ewcSfRx5fJsMV9le87406+oBU1udRpoKeggHRV/PwLWujCh4UYLhg8cMIODET0NKFDQ0BcGwlxISFbxhnGyJE2pixGGQax1/Tt066Zsh7thWck1Rad4tAbklLFLml8ygsJi9NUGY+ls2B/806kp7jbiP5m6uUSyzEg9i/dJPO/OlELRw/HsgabagokI6qzUpdYdkXcXP1SFSeHgDiBuxQPCVtSOemzKjWRrF301pDxN5kpWLG30twY7+KWNGD95zinQe2gqJeKh+elQvkkHXUW29jBHs3zCGWcoYIqed/gEU94Vq6UW+VOuf9MVTKpZhPflvLwAXc3mhg=</latexit>ev!t,l2
<latexit sha1_base64="kEcFSHxnyx1lNvJviaB3bahQON0=">AAAC3nicjVHLSsNAFD2Nr1pfVVfiJlgEF1LSUtFl0Y3LCvYBba1JOm1D8yKZFEoo7tyJW3/ArX6O+Af6F94ZU1CL6IQkZ86958zcew3ftkKuaa8pZW5+YXEpvZxZWV1b38hubtVCLwpMVjU92wsahh4y23JZlVvcZg0/YLpj2KxuDM9EvD5iQWh57iUf+6zt6H3X6lmmzonqZHdajs4HRi9mk05cnFzFoxb3VH5oTzrZnJbX5FJnQSEBOSSr4mVf0EIXHkxEcMDgghO2oSOkp4kCNPjEtRETFxCyZJxhggxpI8pilKETO6Rvn3bNhHVpLzxDqTbpFJvegJQq9knjUV5AWJymyngknQX7m3csPcXdxvQ3Ei+HWI4BsX/pppn/1YlaOHo4kTVYVJMvGVGdmbhEsivi5uqXqjg5+MQJ3KV4QNiUymmfVakJZe2it7qMv8lMwYq9meRGeBe3pAEXfo5zFtSK+UIpf3RRypVPk1GnsYs9HNA8j1HGOSqokvcNHvGEZ+VauVXulPvPVCWVaLbxbSkPH3mjmhk=</latexit>ev!t,l3
<latexit sha1_base64="LI1+zXwOPtk31755qTtyZDhFhYY=">AAAC3nicjVHLSsNAFD2Nr1pfVVfiJlgEF1JSreiy6MZlBfuAttYknbaheZFMCiUUd+7ErT/gVj9H/AP9C++MKahFdEKSM+fec2buvYZvWyHXtNeUMjM7N7+QXswsLa+srmXXN6qhFwUmq5ie7QV1Qw+Zbbmswi1us7ofMN0xbFYzBmciXhuyILQ895KPfNZy9J5rdS1T50S1s1tNR+d9oxuzcTs+HF/Fwyb3VL5vj9vZnJbX5FKnQSEBOSSr7GVf0EQHHkxEcMDgghO2oSOkp4ECNPjEtRATFxCyZJxhjAxpI8pilKETO6Bvj3aNhHVpLzxDqTbpFJvegJQqdknjUV5AWJymyngknQX7m3csPcXdRvQ3Ei+HWI4+sX/pJpn/1YlaOLo4kTVYVJMvGVGdmbhEsivi5uqXqjg5+MQJ3KF4QNiUykmfVakJZe2it7qMv8lMwYq9meRGeBe3pAEXfo5zGlQP8oVi/uiimCudJqNOYxs72KN5HqOEc5RRIe8bPOIJz8q1cqvcKfefqUoq0Wzi21IePgB8D5oa</latexit>{
<latexit sha1_base64="Ea9rONy/Fm9TFBd5e15HfgLppmA=">AAACxXicjVHLSsNAFD2Nr1pfVZdugkVwVVKp6LLoQpdV7APaIsl0WofmxWRSKEX8Abf6a+If6F94Z0xBLaITkpw5954zc+/1Yl8kynFec9bC4tLySn61sLa+sblV3N5pJlEqGW+wyI9k23MT7ouQN5RQPm/HkruB5/OWNzrX8daYy0RE4Y2axLwXuMNQDARzFVHX3eltseSUHbPseVDJQAnZqkfFF3TRRwSGFAE4QijCPlwk9HRQgYOYuB6mxElCwsQ57lEgbUpZnDJcYkf0HdKuk7Eh7bVnYtSMTvHplaS0cUCaiPIkYX2abeKpcdbsb95T46nvNqG/l3kFxCrcEfuXbpb5X52uRWGAU1ODoJpiw+jqWOaSmq7om9tfqlLkEBOncZ/ikjAzylmfbaNJTO26t66Jv5lMzeo9y3JTvOtb0oArP8c5D5pH5Uq1fHxVLdXOslHnsYd9HNI8T1DDJepokPcAj3jCs3VhBZayxp+pVi7T7OLbsh4+AHV/j+4=</latexit>‚á•L
<latexit sha1_base64="TTcI94gkiMJPo5U9RgPuzgdDjQ0=">AAACy3icjVHLSsNAFD3GV62vqks3wSK4KqlUdFl040Khgn1AWySZTuvQvMhMhFpd+gNu9b/EP9C/8M6YglpEJyQ5c+45d+be68W+kMpxXmes2bn5hcXcUn55ZXVtvbCx2ZBRmjBeZ5EfJS3PldwXIa8roXzeihPuBp7Pm97wRMebNzyRIgov1Sjm3cAdhKIvmKuIanWUCLi0z64KRafkmGVPg3IGishWLSq8oIMeIjCkCMARQhH24ULS00YZDmLiuhgTlxASJs5xjzx5U1JxUrjEDuk7oF07Y0Pa65zSuBmd4tObkNPGLnki0iWE9Wm2iacms2Z/yz02OfXdRvT3slwBsQrXxP7lmyj/69O1KPRxZGoQVFNsGF0dy7Kkpiv65vaXqhRliInTuEfxhDAzzkmfbeORpnbdW9fE34xSs3rPMm2Kd31LGnD55zinQWO/VK6UDi4qxepxNuoctrGDPZrnIao4RQ11M8dHPOHZOrekdWvdfUqtmcyzhW/LevgAUHmSPQ==</latexit>{
<latexit sha1_base64="Ea9rONy/Fm9TFBd5e15HfgLppmA=">AAACxXicjVHLSsNAFD2Nr1pfVZdugkVwVVKp6LLoQpdV7APaIsl0WofmxWRSKEX8Abf6a+If6F94Z0xBLaITkpw5954zc+/1Yl8kynFec9bC4tLySn61sLa+sblV3N5pJlEqGW+wyI9k23MT7ouQN5RQPm/HkruB5/OWNzrX8daYy0RE4Y2axLwXuMNQDARzFVHX3eltseSUHbPseVDJQAnZqkfFF3TRRwSGFAE4QijCPlwk9HRQgYOYuB6mxElCwsQ57lEgbUpZnDJcYkf0HdKuk7Eh7bVnYtSMTvHplaS0cUCaiPIkYX2abeKpcdbsb95T46nvNqG/l3kFxCrcEfuXbpb5X52uRWGAU1ODoJpiw+jqWOaSmq7om9tfqlLkEBOncZ/ikjAzylmfbaNJTO26t66Jv5lMzeo9y3JTvOtb0oArP8c5D5pH5Uq1fHxVLdXOslHnsYd9HNI8T1DDJepokPcAj3jCs3VhBZayxp+pVi7T7OLbsh4+AHV/j+4=</latexit>‚á•L
<latexit sha1_base64="TTcI94gkiMJPo5U9RgPuzgdDjQ0=">AAACy3icjVHLSsNAFD3GV62vqks3wSK4KqlUdFl040Khgn1AWySZTuvQvMhMhFpd+gNu9b/EP9C/8M6YglpEJyQ5c+45d+be68W+kMpxXmes2bn5hcXcUn55ZXVtvbCx2ZBRmjBeZ5EfJS3PldwXIa8roXzeihPuBp7Pm97wRMebNzyRIgov1Sjm3cAdhKIvmKuIanWUCLi0z64KRafkmGVPg3IGishWLSq8oIMeIjCkCMARQhH24ULS00YZDmLiuhgTlxASJs5xjzx5U1JxUrjEDuk7oF07Y0Pa65zSuBmd4tObkNPGLnki0iWE9Wm2iacms2Z/yz02OfXdRvT3slwBsQrXxP7lmyj/69O1KPRxZGoQVFNsGF0dy7Kkpiv65vaXqhRliInTuEfxhDAzzkmfbeORpnbdW9fE34xSs3rPMm2Kd31LGnD55zinQWO/VK6UDi4qxepxNuoctrGDPZrnIao4RQ11M8dHPOHZOrekdWvdfUqtmcyzhW/LevgAUHmSPQ==</latexit>User embedding
(b) Aspect-aware UGC RetrievalMulti-Head Cross-AttentionLinearAdd&Norm
Multi-Head Hypergraph AttentionMulti-Head Hypergraph AttentionFeed ForwardAdd&NormFeed ForwardAdd&Norm
CategoryÔºöC98Img-SemanticÔºöI66User IDÔºöU13Text-TopicÔºöT22
UGC Memory BankRelevant UGC SearchTarget UGC For Prediction
Retrieved K Relevant UGC HypergraphConstructAspect-aware Hypergraph(c) Bootstrapping Hypergraph Transformer(a) Overall framework of RAGTrans(d) User-aware FusionUser-aware FusionNon-Linear LayersBootstrapping Hypergraph Transformer
Aspect InformationAspect  Informationzv
<latexit sha1_base64="9m5rda49F82lGExzqab6gYJwT88=">AAAC13icjVHLSsNAFD2Nr1pfsS7dBIvgqiRS0WXRjcsK9iFtLUk6raF5kUyKtRR34tYfcKt/JP6B/oV3xhTUIjohM2fOvefM3LlW6Dox1/XXjDI3v7C4lF3OrayurW+om/laHCSRzap24AZRwzJj5jo+q3KHu6wRRsz0LJfVrcGJiNeHLIqdwD/no5C1PbPvOz3HNjlRHTXfsgK3G488WsY3k8vxcNJRC3pRl0ObBUYKCkhHJVBf0EIXAWwk8MDggxN2YSKmrwkDOkLi2hgTFxFyZJxhghxpE8pilGESO6C5T7tmyvq0F56xVNt0ikt/REoNu6QJKC8iLE7TZDyRzoL9zXssPcXdRrRaqZdHLMcVsX/pppn/1YlaOHo4kjU4VFMoGVGdnbok8lXEzbUvVXFyCIkTuEvxiLAtldN31qQmlrWLtzVl/E1mClbs7TQ3wbu4JTXY+NnOWVDbLxql4sFZqVA+TludxTZ2sEf9PEQZp6igSt7XeMQTnpUL5Va5U+4/U5VMqtnCt6E8fAA4A5e5</latexit>
zt
<latexit sha1_base64="+ocKXPlvqXnaK8QSMWJojkFHw9U=">AAAC13icjVHLSsNAFD2Nr1pfsS7dBIvgqiRS0WXRjcsK9iFtLUk6raF5kUzEGoo7cesPuNU/Ev9A/8I7YwS1iE7IzJlz7zkzd64Vuk7Mdf0lp8zMzs0v5BcLS8srq2vqerERB0lks7oduEHUssyYuY7P6tzhLmuFETM9y2VNa3Qk4s1LFsVO4J/ycci6njn0nYFjm5yonlrsWIHbj8ceLen15Dzlk55a0su6HNo0MDJQQjZqgfqMDvoIYCOBBwYfnLALEzF9bRjQERLXRUpcRMiRcYYJCqRNKItRhknsiOYh7doZ69NeeMZSbdMpLv0RKTVskyagvIiwOE2T8UQ6C/Y371R6iruNabUyL49Yjgti/9J9Zv5XJ2rhGOBA1uBQTaFkRHV25pLIVxE3175UxckhJE7gPsUjwrZUfr6zJjWxrF28rSnjrzJTsGJvZ7kJ3sQtqcHGz3ZOg8Zu2aiU904qpeph1uo8NrGFHernPqo4Rg118r7CAx7xpJwpN8qtcveRquQyzQa+DeX+HTNBl7c=</latexit>InputRetrievalAspect-aware UGC RetrievalPopularityGv
<latexit sha1_base64="GYDpojjSRGaK9ZExXhaduTk199I=">AAAC1HicjVHLSgMxFD0dX7U+WnXpZrAIrspUFF2KLnSpYGvBR8mkqQ7Oi0xGKLUrcesPuNVvEv9A/8KbmIJaRDPMzMm559zk3uunYZApz3stOGPjE5NTxenSzOzcfLmysNjMklxy0eBJmMiWzzIRBrFoqECFopVKwSI/FCf+9Z6On9wImQVJfKx6qTiP2GUcdAPOFFHtSvksYuqKs7C/P7jo3wzalapX88xyR0HdgirsOkwqLzhDBwk4ckQQiKEIh2DI6DlFHR5S4s7RJ04SCkxcYIASeXNSCVIwYq/pe0m7U8vGtNc5M+PmdEpIrySni1XyJKSThPVpronnJrNmf8vdNzn13Xr0922uiFiFK2L/8g2V//XpWhS62DY1BFRTahhdHbdZctMVfXP3S1WKMqTEadyhuCTMjXPYZ9d4MlO77i0z8Tej1Kzec6vN8a5vSQOu/xznKGiu1+obtc2jjerOrh11EctYwRrNcws7OMAhGmbmj3jCs9N0bp075/5T6hSsZwnflvPwAfnylgs=</latexit>Gt
<latexit sha1_base64="+jZWX2z/TeC5cB7IW9IJRXlQz5s=">AAAC1HicjVHLSsNAFD3G97NVl26CRXBVEqnoUnShSwVbBatlMk5raF5MJoLErsStP+BWv0n8A/0L74wj+EB0QpIz555zZ+69QRaFufK85yFneGR0bHxicmp6ZnauUp1faOVpIblo8jRK5XHAchGFiWiqUEXiOJOCxUEkjoL+jo4fXQqZh2lyqK4ycRqzXhJ2Q84UUZ1qpR0zdcFZVO4Ozko16FRrXt0zy/0JfAtqsGs/rT6hjXOk4CgQQyCBIhyBIafnBD48ZMSdoiROEgpNXGCAKfIWpBKkYMT26duj3YllE9rrnLlxczololeS08UKeVLSScL6NNfEC5NZs7/lLk1Ofbcr+gc2V0yswgWxf/k+lP/16VoUutg0NYRUU2YYXR23WQrTFX1z91NVijJkxGl8TnFJmBvnR59d48lN7bq3zMRfjFKzes+ttsCrviUN2P8+zp+gtVb3G/X1g0Zta9uOegJLWMYqzXMDW9jDPppm5vd4wKPTcq6dG+f2XeoMWc8ivizn7g31MJYJ</latexit>¬ØZt
<latexit sha1_base64="rqSa767xZaRCYiHuDD2oDXnYMuU=">AAAC2XicjVHLSsNAFD2Nr1pf9bFzEyyCq5JKRZdFNy4r2Ae2VSZxWoN5MZkINXThTtz6A271h8Q/0L/wzhhBLaITkpw5954zc++1I8+NpWW95IyJyanpmfxsYW5+YXGpuLzSjMNEOLzhhF4o2jaLuecGvCFd6fF2JDjzbY+37MsDFW9dcRG7YXAshxHv+WwQuH3XYZKos+Ja12Yi7fpMXtj99GQ0Ok3l6KxYssqWXuY4qGSghGzVw+IzujhHCAcJfHAEkIQ9MMT0dFCBhYi4HlLiBCFXxzlGKJA2oSxOGYzYS/oOaNfJ2ID2yjPWaodO8egVpDSxSZqQ8gRhdZqp44l2Vuxv3qn2VHcb0t/OvHxiJS6I/Uv3mflfnapFoo89XYNLNUWaUdU5mUuiu6Jubn6pSpJDRJzC5xQXhB2t/OyzqTWxrl31lun4q85UrNo7WW6CN3VLGnDl5zjHQXO7XKmWd46qpdp+Nuo81rGBLZrnLmo4RB0N8r7GAx7xZHSMG+PWuPtINXKZZhXflnH/DhJimG8=</latexit>¬ØZv
<latexit sha1_base64="cvMqA/ZbcODxg0FAwU7EBhp53yM=">AAAC2XicjVHLSsNAFD2N7/qqj52bYBFclVQquhTduFSwtthqmaTTGpoXk0mhhi7ciVt/wK3+kPgH+hfeGVNQi+iEJGfOvefM3HvtyHNjaVmvOWNicmp6ZnYuP7+wuLRcWFk9j8NEOLzqhF4o6jaLuecGvCpd6fF6JDjzbY/X7N6Ritf6XMRuGJzJQcQvfdYN3I7rMElUq7DetJlImz6T13YnvRgOr9L+sFUoWiVLL3MclDNQRLZOwsILmmgjhIMEPjgCSMIeGGJ6GijDQkTcJVLiBCFXxzmGyJM2oSxOGYzYHn27tGtkbEB75RlrtUOnePQKUprYIk1IeYKwOs3U8UQ7K/Y371R7qrsN6G9nXj6xEtfE/qUbZf5Xp2qR6GBf1+BSTZFmVHVO5pLorqibm1+qkuQQEadwm+KCsKOVoz6bWhPr2lVvmY6/6UzFqr2T5SZ4V7ekAZd/jnMcnO+UypXS7mmleHCYjXoWG9jENs1zDwc4xgmq5H2DRzzh2WgYt8adcf+ZauQyzRq+LePhAxckmHE=</latexit>zu
<latexit sha1_base64="fKjW28jPXwbSsXAqoWiQ8FpGAcY=">AAAC13icjVHLSsNAFD2Nr1pfsS7dBIvgqiRS0WXRjcsK9iFtLUk6raF5kUzEGoo7cesPuNU/Ev9A/8I7YwS1iE7IzJlz7zkzd64Vuk7Mdf0lp8zMzs0v5BcLS8srq2vqerERB0lks7oduEHUssyYuY7P6tzhLmuFETM9y2VNa3Qk4s1LFsVO4J/ycci6njn0nYFjm5yonlrsWIHbj8ceLen15DxNJj21pJd1ObRpYGSghGzUAvUZHfQRwEYCDww+OGEXJmL62jCgIySui5S4iJAj4wwTFEibUBajDJPYEc1D2rUz1qe98Iyl2qZTXPojUmrYJk1AeRFhcZom44l0Fuxv3qn0FHcb02plXh6xHBfE/qX7zPyvTtTCMcCBrMGhmkLJiOrszCWRryJurn2pipNDSJzAfYpHhG2p/HxnTWpiWbt4W1PGX2WmYMXeznITvIlbUoONn+2cBo3dslEp751UStXDrNV5bGILO9TPfVRxjBrq5H2FBzziSTlTbpRb5e4jVcllmg18G8r9OzWil7g=</latexit>K<latexit sha1_base64="o9ThN7FTs0pfNry5nFdi8nxm+bY=">AAAC0XicjVHLSgMxFD0dX7W+qi7dDBbBVZmRii6LbgQ3Fe0DapWZNK1D50UmI5RSELf+gFv9KfEP9C+8iVNQi2iGSU7OveckN9eNfS+RlvWaM2Zm5+YX8ouFpeWV1bXi+kYjiVLBeJ1FfiRarpNw3wt5XXrS561YcCdwfd50B8cq3rzlIvGi8EIOY94JnH7o9TzmSKKuLt3I7ybDgJbR6fi6WLLKlh7mNLAzUEI2alHxBZfoIgJDigAcISRhHw4S+tqwYSEmroMRcYKQp+McYxRIm1IWpwyH2AHNfdq1MzakvfJMtJrRKT79gpQmdkgTUZ4grE4zdTzVzor9zXukPdXdhrS6mVdArMQNsX/pJpn/1alaJHo41DV4VFOsGVUdy1xS/Srq5uaXqiQ5xMQp3KW4IMy0cvLOptYkunb1to6Ov+lMxao9y3JTvKtbUoPtn+2cBo29sl0p759VStWjrNV5bGEbu9TPA1Rxghrq5C3wiCc8G+fG0Lgz7j9TjVym2cS3YTx8AD6WlWU=</latexit>V<latexit sha1_base64="eYrZ43qB3Dxn2VRHDVpZQKsuUOU=">AAAC0XicjVHLSsNAFD2Nr1pfVZdugkVwVRKp6LLoxmVF+4C2SpJOa+jkwWQilFIQt/6AW/0p8Q/0L7wzpqAW0QmZOXPuPWfmznVj7ifSsl5zxtz8wuJSfrmwsrq2vlHc3GokUSo8VvciHomW6ySM+yGrS19y1ooFcwKXs6Y7PFXx5i0TiR+Fl3IUs27gDEK/73uOJOqq40a8l4wCWsaNyXWxZJUtPcxZYGeghGzUouILOughgocUARhCSMIcDhL62rBhISauizFxgpCv4wwTFEibUhajDIfYIc0D2rUzNqS98ky02qNTOP2ClCb2SBNRniCsTjN1PNXOiv3Ne6w91d1GtLqZV0CsxA2xf+mmmf/VqVok+jjWNfhUU6wZVZ2XuaT6VdTNzS9VSXKIiVO4R3FB2NPK6TubWpPo2tXbOjr+pjMVq/ZelpviXd2SGmz/bOcsaByU7Ur58LxSqp5krc5jB7vYp34eoYoz1FAnb4FHPOHZuDBGxp1x/5lq5DLNNr4N4+EDWMGVcA==</latexit>Q<latexit sha1_base64="o3x4lcBa6YGzuEhuWJEvV14dl6Q=">AAAC0XicjVHLSgMxFD0dX7W+qi7dDBbBVZlKRZdFNy5btA+oVWbStA6dF5mMMJSCuPUH3OpPiX+gf+FNnIJaRDNMcnLuPSe5uU7kubG0rNecMTe/sLiUXy6srK6tbxQ3t1pxmAjGmyz0QtFx7Jh7bsCb0pUe70SC277j8bYzOlXx9i0XsRsGFzKNeM+3h4E7cJktibq6dEKvH6c+LePG5LpYssqWHuYsqGSghGzUw+ILLtFHCIYEPjgCSMIebMT0dVGBhYi4HsbECUKujnNMUCBtQlmcMmxiRzQPadfN2ID2yjPWakanePQLUprYI01IeYKwOs3U8UQ7K/Y377H2VHdLaXUyL59YiRti/9JNM/+rU7VIDHCsa3CppkgzqjqWuST6VdTNzS9VSXKIiFO4T3FBmGnl9J1NrYl17eptbR1/05mKVXuW5SZ4V7ekBld+tnMWtA7KlWr5sFEt1U6yVuexg13sUz+PUMMZ6miSt8AjnvBsnBupcWfcf6YauUyzjW/DePgATNyVaw==</latexit>X<latexit sha1_base64="JIIFpdQpxeLz1p7Vpg8uht5buQA=">AAACzXicjVHLSsNAFD2Nr1pfVZdugkVwVRJRdFl0484K9oFtkSSdtqF5MZkIpdatP+BWf0v8A/0L74xTUIvohCRnzr3nzNx73STwU2FZrzljbn5hcSm/XFhZXVvfKG5u1dM44x6reXEQ86brpCzwI1YTvghYM+HMCd2ANdzhmYw3bhlP/Ti6EqOEdUKnH/k933MEUdft0BEDtzduTm6KJatsqWXOAluDEvSqxsUXtNFFDA8ZQjBEEIQDOEjpacGGhYS4DsbEcUK+ijNMUCBtRlmMMhxih/Tt066l2Yj20jNVao9OCejlpDSxR5qY8jhheZqp4plyluxv3mPlKe82or+rvUJiBQbE/qWbZv5XJ2sR6OFE1eBTTYliZHWedslUV+TNzS9VCXJIiJO4S3FO2FPKaZ9NpUlV7bK3joq/qUzJyr2nczO8y1vSgO2f45wF9YOyfVg+ujwsVU71qPPYwS72aZ7HqOAcVdTIO8IjnvBsXBiZcWfcf6YaOa3ZxrdlPHwAfqWThQ==</latexit>X<latexit sha1_base64="JIIFpdQpxeLz1p7Vpg8uht5buQA=">AAACzXicjVHLSsNAFD2Nr1pfVZdugkVwVRJRdFl0484K9oFtkSSdtqF5MZkIpdatP+BWf0v8A/0L74xTUIvohCRnzr3nzNx73STwU2FZrzljbn5hcSm/XFhZXVvfKG5u1dM44x6reXEQ86brpCzwI1YTvghYM+HMCd2ANdzhmYw3bhlP/Ti6EqOEdUKnH/k933MEUdft0BEDtzduTm6KJatsqWXOAluDEvSqxsUXtNFFDA8ZQjBEEIQDOEjpacGGhYS4DsbEcUK+ijNMUCBtRlmMMhxih/Tt066l2Yj20jNVao9OCejlpDSxR5qY8jhheZqp4plyluxv3mPlKe82or+rvUJiBQbE/qWbZv5XJ2sR6OFE1eBTTYliZHWedslUV+TNzS9VCXJIiJO4S3FO2FPKaZ9NpUlV7bK3joq/qUzJyr2nczO8y1vSgO2f45wF9YOyfVg+ujwsVU71qPPYwS72aZ7HqOAcVdTIO8IjnvBsXBiZcWfcf6YaOa3ZxrdlPHwAfqWThQ==</latexit>
U13C98T22I66Gv
<latexit sha1_base64="GYDpojjSRGaK9ZExXhaduTk199I=">AAAC1HicjVHLSgMxFD0dX7U+WnXpZrAIrspUFF2KLnSpYGvBR8mkqQ7Oi0xGKLUrcesPuNVvEv9A/8KbmIJaRDPMzMm559zk3uunYZApz3stOGPjE5NTxenSzOzcfLmysNjMklxy0eBJmMiWzzIRBrFoqECFopVKwSI/FCf+9Z6On9wImQVJfKx6qTiP2GUcdAPOFFHtSvksYuqKs7C/P7jo3wzalapX88xyR0HdgirsOkwqLzhDBwk4ckQQiKEIh2DI6DlFHR5S4s7RJ04SCkxcYIASeXNSCVIwYq/pe0m7U8vGtNc5M+PmdEpIrySni1XyJKSThPVpronnJrNmf8vdNzn13Xr0922uiFiFK2L/8g2V//XpWhS62DY1BFRTahhdHbdZctMVfXP3S1WKMqTEadyhuCTMjXPYZ9d4MlO77i0z8Tej1Kzec6vN8a5vSQOu/xznKGiu1+obtc2jjerOrh11EctYwRrNcws7OMAhGmbmj3jCs9N0bp075/5T6hSsZwnflvPwAfnylgs=</latexit>Gt
<latexit sha1_base64="+jZWX2z/TeC5cB7IW9IJRXlQz5s=">AAAC1HicjVHLSsNAFD3G97NVl26CRXBVEqnoUnShSwVbBatlMk5raF5MJoLErsStP+BWv0n8A/0L74wj+EB0QpIz555zZ+69QRaFufK85yFneGR0bHxicmp6ZnauUp1faOVpIblo8jRK5XHAchGFiWiqUEXiOJOCxUEkjoL+jo4fXQqZh2lyqK4ycRqzXhJ2Q84UUZ1qpR0zdcFZVO4Ozko16FRrXt0zy/0JfAtqsGs/rT6hjXOk4CgQQyCBIhyBIafnBD48ZMSdoiROEgpNXGCAKfIWpBKkYMT26duj3YllE9rrnLlxczololeS08UKeVLSScL6NNfEC5NZs7/lLk1Ofbcr+gc2V0yswgWxf/k+lP/16VoUutg0NYRUU2YYXR23WQrTFX1z91NVijJkxGl8TnFJmBvnR59d48lN7bq3zMRfjFKzes+ttsCrviUN2P8+zp+gtVb3G/X1g0Zta9uOegJLWMYqzXMDW9jDPppm5vd4wKPTcq6dG+f2XeoMWc8ivizn7g31MJYJ</latexit>
Figure 2: The structure of the proposed RAGTrans model. (a) The overall framework of RAGTrans, which consists of aspect-
aware UGC retrieval, bootstrapping hypergraph transformer, and user-aware fusion. (b) The detailed process of aspect-aware
UGC retrieval, introducing search engine techniques to calculate similarity scores. (c) The structure of bootstrapping hypergraph
transformer, designed to capture intra- and inter-modal correlations. (d) The detailed structure of user-aware fusion layer.
the nearest instances of the target UGC in the memory bank, and
Edenotes the aspect information of UGCs (e.g., user, category).
3.1 Aspect-aware UGC Retrieval
We expect to retrieve relevant data instances of the target UGC
and obtain meaningful auxiliary knowledge for guiding the target
popularity prediction. First, we construct our UGC memory bank
Bthat consists of visual content, textual content and the aspect
information of massive UGCs with a collection of reference <image,
text, aspect> triplets. To use this resource, we design a retrieval
module to retrieve Top- ùêænearest <image, text, aspect> triplets from
the memory bank. These retrieved data instances have relations
with the target UGC, determined by calculating similarity scores
using the aspect information. The aspect information involves dif-
ferent aspects of characteristics, such as attribute-level (i.e., user,
category and topic) and modal semantic-level information (i.e., tex-
tual and visual semantic), to reflect the finer-grained content in
UGCs, enabling a finer-grained assessment of relevance. The de-
tailed construction process of the aspect information is summarized
in Appendix A.4. With such designs, leveraging the aspect infor-
mation to distinguish relevant instances offers a means to mitigate
discrepancies between textual and visual content, and enhance re-
trieval performance. Specifically, the retrieval module is inspired
by document retrieval, which allows us to effectively obtain rele-
vant instances from the memory bank via aspect information-based
retrieval operations. Following this insight, when there comes a
request for predicting ùëêùëû, we can abstract data instance ùëêùëûinto a
‚Äúdocument‚Äù, each aspect information of the instance is regarded asa ‚Äúterm‚Äù and then employ search engine techniques1to retrieve
the nearest data instances in the large memory bank B.
Specifically, we use xùëû={ùë•ùëû
ùëì|ùëì=1,¬∑¬∑¬∑,F}to represent the
feature of aspect information in the target UGC ùëêùëûas the query,
whereùë•ùëû
ùëìrepresents the feature value of ùëì-th field andFdenotes
the number of feature fields. First, we implement a boolean query
operation to retrieve instances that contain at least one common
feature value with the target instance ùëêùëû. Next, we use a general
search mechanism to calculate relevant score ùëÖfor each data in-
stance filtered from the whole data space w.r.t. the target content
ùëêùëû. Then we select ùêænearest samples from the whole data sample
space. Afterward, the ranking function, e.g., BM25 [ 45], is used to
calculate the similarity scores ùëÖ(xùëû,xùê∑)between the query xùëûand
a document xùê∑in the UGC memory bank:
ùëÖ(xùëû,xùê∑)=F‚àëÔ∏Å
ùëì=1IDF(ùë•ùëû
ùëì)TF
ùë•ùëû
ùëì,xùê∑
¬∑(ùëò1+1)
TF
ùë•ùëû
ùëì,xùê∑
+ùëò1¬∑(1‚àíùëè+ùëè¬∑|xùê∑|
avgdl),(1)
whereùëò1andùëèare free parameters, and avgdl indicates the average
document length. The document length is defined as the number
of features in UGC‚Äôs aspect information, so all documents have
the same lengthF,|xùê∑|
avgdl=1. We note TF(ùë•ùëû
ùëì,xùê∑)is the feature
ùë•ùëû
ùëì‚Äôs term frequency in xùê∑. Ifùë•ùëû
ùëìis a single value feature, then
TF(ùë•ùëû
ùëì,xùê∑)is either 1 or 0 according to whether there is a match
ofùë•ùëû
ùëìinxùê∑. Ifùë•ùëû
ùëìhave multiple feature values, we calculate the
1https://github.com/elastic/elasticsearch
 
448Retrieval-Augmented Hypergraph for Multimodal Social Media Popularity Prediction KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain
Jaccard similarity as the term frequency:
TF
ùë•ùëû
ùëì,xùê∑
=ùë•ùëû
ùëì‚à©ùë•ùê∑
ùëì
ùë•ùëû
ùëì‚à™ùë•ùê∑
ùëì, ùë•ùê∑
ùëó‚ààxùê∑, (2)
where|¬∑|denotes the size of a set. IDF is defined as:
IDF(ùë•ùëû
ùëì)=logN‚àíN(ùë•ùëû
ùëì)+0.5
N(ùë•ùëû
ùëì)+0.5, (3)
whereNis the number of all data samples in the memory bank,
andN(ùë•ùë°ùëû)represents the number of filtered data samples that have
the same feature value ùë•ùëû
ùëìin theùëì-th field. Common features are
penalized by the IDF term to be less important than rare features.
After the retrieving based on BM25, the Top- ùêædata instancesCRùëû=
{ùëêùëü1ùëû,¬∑¬∑¬∑,ùëêùëüùêæùëû}can be readily obtained. Each retrieved instance ùëêùëüùëñùëû
contains the <image, text, aspect> triplets.
3.2 Bootstrapping Hypergraph Transformer
Hypergraph [ 4] can represent cross-instance high-order relations
via hyperedges, providing a natural way to connect different rele-
vant instances via aspect-aware hyperedges and distill neighbor-
hood knowledge to assist the inference process on the target UGC.
However, UGCs typically consisted of images and texts express
users‚Äô feelings and opinions. Different modalities will provide di-
verse information to attract viewers‚Äô attention and resulting in dif-
ferent contributions to the popularity of the UGC. It is essential to
learn effective and expressive UGC multimodal representations that
contain rich intra-modal and inter-modal correlations for assisting
inference on the target UGC. However, existing hypergraph-based
models, e.g., HGNN [ 14] and DHGNN [ 25], are not suitable for
multimodal scenarios. They follow a naive strategy for merging
isolated uni-modal hypergraphs into a single one through concate-
nation operations. Since node features propagate on the unimodal
hypergraph independently, the learned representations underrate
the inherent heterogeneity across multiple data modalities and are
insufficient to handle inter-modal correlations.
In order to bridge the isolated unimodal propagations, we design
a bootstrapping hypergraph transformer (BHT), to dig into multi-
modal high-order neighborhood knowledge as well as extracting
intra- and inter-relations of multiple data modalities. Intra-relation
shows the influence level of neighbors‚Äô characteristics on the target
instance in the uni-modality, while inter-relation implies that UGC‚Äôs
popularity towards different modalities may correlate. Therefore,
BHT extends the node feature aggregation into the multimodal
information mixture that contains three stages: intra-modal propa-
gation, inter-modal propagation, and feed-forward network.
Aspect-aware Multimodal Hypergraph Construction. The result-
ing instances setCRùëûis transformed into a hypergraph Gùëû=
{Vùëû,Eùëû}of the target instance ùëêùëû, where each data instance forms
a node, i.e.,Vùëû=CRùëû. Each feature in the aspect information of
ùëêùëûconstructs a hyperedge to connect involved retrieved instances
for representing relevant high-order relations between the target
UGC and retrieved instances. For example, two UGCs within the
same user and category have a stronger relevant correlations thandifferent categories posted by the same user. Moreover, for multi-
modal content of UGCs, we transform the hypergraph Gùëûto one
uni-modal hypergraph Gùëöùëûfor each modality ùëö‚ààM ={ùë°,ùë£},
whereùë°andùë£denote visual and textual modality, respectively. For
each nodeùëû, it has corresponding uni-modal feature ùíõùëöùëû‚ààRùëë. The
details of modal feature extraction is presented in Appendix A.
Intra-modal Propagation. BHT first propagates on the uni-modal
hypergraph to capture intra-modal neighborhood knowledge,
which is composed of node-to-hyperedge and hyperedge-to-node
propagations. For the node-to-hyperedge propagation, given a query
UGCùëêùëû, visual modal representations ùíÅùë£ùëû={ùíõùë£ùëû,ùíõùëü1,ùë£
ùëû,¬∑¬∑¬∑,ùíõùëüùêæ,ùë£
ùëû}of
hypergraphGùë£ùëûand hypergraph incidence matrix Aùë£‚ààR(ùêæ+1)√óF,
anùëô-th layer of BHT calculates Fhyperedge representations
ùë¨ùë£,ùëô
ùëû={ùíÜùë£,ùëô
ùëû,1,¬∑¬∑¬∑,ùíÜùë£,ùëô
ùëû,F}as follows:
ùíÜùë£,ùëô
ùëû,ùëó=‚àëÔ∏Å
ùëõùëû,ùëò‚ààùëíùë£
ùëû,ùëó
ùõºùëóùëòWùë£
ùëßùíõùë£,ùëô‚àí1
ùëû,ùëò
, (4)
where Wùë£ùëßdenotes learnable parameters. The superscript ùëôrepre-
sents the layer of BHT and ùõºùëóùëòdenotes the attention coefficient of
nodeùëõùëû,ùëòin the hyperedge ùëíùë£
ùëû,ùëó. In order to bridge the intra-modal
and inter-modal propagation, we inject the information of the inter-
modal propagation into the attention coefficient ùõºùëóùëò, which can
be considered as an influence gate to ensure that only the most
influential and informative messages from modality ùë£can be passed
through modality ùë°. The attention scores are calculated as follows:
ùõºùëóùëò=exp
ùúé
¬Æaùëáùëéùëßh
ùíõùë£,ùëô‚àí1
ùëû,ùëò‚äô¬ØùíÜùë£,ùëô
ùëû,ùëói
√ç
ùë£ùëû,ùúÅ‚ààùëíùëû,ùëóexp
ùúé
¬Æaùëáùëéùëßh
ùíõùë£,ùëô‚àí1
ùëû,ùúÅ,ùíõùë°,ùëô‚àí1
ùëû,ùúÅi
‚äô¬ØùíÜùë£,ùëô
ùëû,ùëó, (5)
where¬Æaùëéùëß‚ààRùëëis a weight vector, ¬ØùíÜùë£,ùëô
ùëû,ùëó={ùíõùë£,ùëô
ùëû,ùúÅ|ùë£ùëû,ùúÅ‚ààùëíùë£
ùëû,ùëó}is the av-
erage of the cluster, and [ùíõùë£,ùëô‚àí1
ùëû,ùúÅ,ùíõùë°,ùëô‚àí1
ùëû,ùúÅ]‚ààR2√óùëëdenotes the concate-
nation operation.‚äôis the Hadamard product. ùúéis the LeakyReLU
activation function.
For the hyperedge-to-node propagation, we update presentations
ùíÅùë£,ùëô‚àí1
ùëû via hyperedge features ùë¨ùë£,ùëô
ùëû:
zùë£,ùëô
ùëû,ùëò=‚àëÔ∏Å
ùëíùëû,ùëó‚ààùëõùë£
ùëû,ùëò
ùõΩùëòùëóWùë£
ùëíùíÜùë£,ùëô
ùëû,ùëó
(6)
ùõΩùëòùëó=exp
ùúé
¬Æaùëáùëéùëíh
ùíõùë£,ùëô‚àí1
ùëû,ùëó‚äôùíÜùë£,ùëô
ùëû,ùëòi
√ç
ùëíùëû,ùúÅ‚ààùëõùë£
ùëû,ùëòexp
ùúé
¬Æaùëáùëéùëí
ùíõùë£,ùëô‚àí1
ùëû,ùëò‚äôh
ùíÜùë£,ùëô
ùëû,ùúÅ,ùíÜùë°,ùëô
ùëû,ùúÅi,
where zùë£,ùëô
ùëû,ùëòdenotes updated representations of node ùëõùë£
ùëû,ùëòand
¬Æaùëéùëí‚ààRùëëis a weight vector. ùõΩùëòùëórepresents the attention score
of hyperedge ùëíùëû,ùëóthat connects to node ùë£ùëû,ùëò.
Inter-modal Propagation. Inspired by the advantages of prefix
tuning [ 34] and corresponding analysis in [ 19], BHT re-constructs
the information propagation process into prefix-guided multimodal
information propagation to pre-reduce the modality heterogeneity
and captures cross-modal interactions, which distills textual infor-
mation fromGùë°ùëûtoGùë£ùëû. The propagation process from Gùë°ùëûtoGùë£ùëûin
 
449KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain Zhangtao Cheng, et al.
the inter-modal propagation can be defined as:
ùíÜùë°‚Üíùë£,ùëô
ùëû,ùëó=
ùõº‚Ä≤
ùëóùëòWùë°
ùëßùíõùë°,ùëô‚àí1
ùëû,ùëò
, (7)
ùõº‚Ä≤
ùëóùëò=exp
ùúé
¬Æaùëáùëéùëßh
ùíõùë°,ùëô‚àí1
ùëû,ùëò‚äô¬ØùíÜùë£,ùëô
ùëû,ùëói
√ç
ùë£ùëû,ùúÅ‚ààùëíùëû,ùëóexp
ùúé
¬Æaùëáùëéùëßh
ùíõùë£,ùëô‚àí1
ùëû,ùúÅ,ùíõùë°,ùëô‚àí1
ùëû,ùúÅi
‚äô¬ØùíÜùë£,ùëô
ùëû,ùëó,
whereùõº‚Ä≤
ùëóùëòdenotes the attention coefficient of the textual node ùëõùë°
ùëû,ùëò
in the visual hyperedge ùëíùë£
ùëû,ùëó, representing a cross-modal interaction.
Especially, above formulas denote the information propagation of
textual nodes to visual hyperedges. Then hyperedge-to-node from
Gùë°ùëûtoGùë£ùëûcan be defined as:
zùë°‚Üíùë£,ùëô
ùëû,ùëò=‚àëÔ∏Å
ùëíùëû,ùëó‚ààùëõùë£
ùëû,ùëò
ùõΩ‚Ä≤
ùëòùëóWùë°
ùëíùíÜùë°‚Üíùë£,ùëô
ùëû,ùëó
(8)
ùõΩ‚Ä≤
ùëòùëó=exp
ùúé
¬Æaùëáùëéùëíh
ùíõùë£,ùëô‚àí1
ùëû,ùëó‚äôùíÜùë°‚Üíùë£,ùëô
ùëû,ùëòi
√ç
ùëíùëû,ùúÅ‚ààùëõùë£
ùëû,ùëòexp
ùúé
¬Æaùëáùëéùëí
ùíõùë£,ùëô‚àí1
ùëû,ùëò‚äôh
ùíÜùë£,ùëô
ùëû,ùúÅ,ùíÜùë°,ùëô
ùëû,ùúÅi,
whereùõΩ‚Ä≤
ùëòùëódenotes the attention coefficient of the cross-modal inter-
action. The prefix-guided interaction mechanism prepares a scalar
factor to downweight the original attention and redistribute re-
mainder attention for textual modality. Such procedures allow our
model to pre-reduce the modality heterogeneity. We also use multi-
head attention to expand the model‚Äôs representation subspaces and
stabilize the learning process of self-attention [ 50]. In this mod-
ule, we consider endowing our BHT with the capability of jointly
attending multi-dimensional dependencies among nodes and hy-
peredges within aspect-aware hypergraphs. To achieve this, we
extend BHT into multi-head hypergraph transformer, which per-
forms head-specific attentive operations in parallel. This extension
can be summarized as follows: ùíÅùë£,ùëô
ùëû,‚Ñé=HBT‚Ñé
ùíÅùë£,ùëô‚àí1
ùëû,Gùë£ùëû
,ùíÅùë£,ùëô
ùëû=
Aggregate
ùíÅùë£,ùëô
ùëû,‚Ñéùêª
‚Ñé=1, where Aggregate(¬∑)denotes the concatena-
tion operation. ùêªdenotes the number of attention head in the BHT.
Feed-forward Network (FFN). To alleviate modal heterogeneity
and obtain fine-grained representations including intra- and inter-
modal correlations, we merge the corresponding output features of
the prefix-guided interaction module. Inspired by [ 16] that shows
how FFN layer captures task-specific textual patterns, we propose
to merge textual hidden states into the visual ones. Given the output
of theùëô-th hyperedge-to-node propagation layer, FFN calculation
FNN(Zùë£,ùëô)is modified as:
ùíÅùë£,ùëô
ùëû=ReLU
ùíÅùë£,ùëô
ùëûW1+b1+ùíÅùë°‚Üíùë£,ùëô
ùëû W3
W2+b2,
¬ØZùë£,ùëô
ùëû=LN
FFN
ùíÅùë£,ùëô
ùëû
+ùíÅùë£,ùëô‚àí1
ùëû
. (9)
LN[2] is the layer-normalization operation. By merging textual and
visual representations into the FFN calculation, RAGTrans aligns
the description of the two data modalities. The calculation process
of¬ØZùë°,ùëô
ùëûis same with ¬ØZùë£,ùëô
ùëû.
3.3 User-Aware Fusion
Since different modalities have different importance for predicting
popularity, and different users have diverse tastes for generating
specific textual and visual information in their UGCs (this is eventrue for the same user), we proposed a user-aware fusion module
based on the cross-attention mechanism to automatically select
more suitable and important parts in UGC, and in return obtain
complementary fused features. Given the output of the final BHT
layer ‚Äì i.e., ¬ØZùë°,ùëô
ùëûand¬ØZùë£,ùëô
ùëû‚Äì we first concatenate two representations
from BHT‚Äôs output with the corresponding user embedding U‚àà
RùëÅùë¢‚ààùëëùë¢, and then obtain two new representations: ùëª=¬ØZùë°,ùëô
ùëû‚à•Uand
ùëΩ=¬ØZùë£,ùëô
ùëû‚à•U. The two representations are modeled to contain high-
order neighborhood knowledge, user-lever information, and inter-
and intra-modal correlations. They are projected into ùëëdimension
as a query. We use both visual and textual representations as key
and value and feed them into a user-aware fusion layer:
ATT(ùë∏,ùë≤,V)=softmaxùë∏ùë≤ùëá
‚àö
ùëë
ùëΩ,
ùëø=ATT
([ùëΩ‚à•ùëª]W)ùëæùëÑ,(ùëΩ‚ä§‚à•ùëª‚ä§)‚ä§ùëæùêæ,(ùëΩ‚ä§‚à•ùëª‚ä§)‚ä§ùëæùëâ
,(10)
where W‚ààR2(ùëë+ùëëùë¢)√ó(ùëë+ùëëùë¢)is a learnable parameter matrix,
ùëø‚ààRùëë+ùëëùë¢,ùëª,ùëΩ‚ààR2√ó(ùëë+ùëëùë¢)denote output, textual, and visual
representations, respectively. WùëÑ,Wùêæ,Wùëâdenote the query, key,
and value projection matrices, respectively. The final popularity is
made by fully-connected layers. We use mean squared error (MSE)
as the optimization loss.
Table 1: Statistics of three datasets
Dataset #UGC
# User #Train #Val # Test V T
SMPD 305,613
38,312 244,491 30,561 30,561 2,048 384
ICIP 20,337 17,302 16,271 2,033 2,033 2,048 384
WeChat 14,758 18,743 11,808 1,475 1,475 128 128
4 EXPERIMENTS
We now report our experimental results to verify the effectiveness
of RAGTrans and address the following research questions:
‚Ä¢RQ1: How does our proposed RAGTrans perform on three
datasets compared with state-of-the-art baselines?
‚Ä¢RQ2: How do different components in RAGTrans contribute to
the overall performance?
‚Ä¢RQ3: How do the key hyperparameters influence the perfor-
mance of our RAGTrans?
‚Ä¢RQ4: How does the incorporation of retrieval knowledge en-
hance RAGTrans‚Äôs prediction performance?
4.1 Experimental Settings
4.1.1 Datasets. We evaluate RAGTrans on three real-world multi-
media datasets: SMPD [ 55], ICIP [ 38], and WeChat [ 52]. The detailed
statistics of datasets are shown in Table 1. Each dataset is randomly
split into training (80%), validation (10%), and test (10%) sets. V,T
denote the dimension of visual and textual features, respectively.
‚Ä¢SMPD [55] is a benchmark dataset with multi-faceted informa-
tion, which is collected from Flickr‚Äôs online streams and records
various social media information from November 2015 to March
2016. SMPD includes user profiles, photo-sharing records, images,
and textual descriptions. In this dataset, the popularity is defined
as the number of views of each photo.
 
450Retrieval-Augmented Hypergraph for Multimodal Social Media Popularity Prediction KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain
‚Ä¢ICIP [38] dataset records the engagement scores of each Flickr
image over a period of 30 days, which contains users‚Äô and photos‚Äô
social features, such as users‚Äô groups, image titles, and descrip-
tions. Similarly, the popularity is the number of photo views.
‚Ä¢WeChat dataset [ 52] is collected from the WeChat platform,
which tracks WeChat videos over a period of 15 days and records
users‚Äô interactive behaviors on each video. Furthermore, the
dataset contains videos‚Äô attributes (e.g., posted time, tags, visual,
textual, and acoustic features) and users‚Äô interactive character-
istics (e.g., stay time, like, comment, click-avatar, and forward).
Following previous work [ 7], the popularity is computed by the
mean operation for four popularity indicators: the numbers of
comments, likes, reshares, and avatar clicks.
In addition, to suppress the large variations among different
UGCs, e.g., view counts of UGC generally vary from zero to millions,
we employ a logarithmic function to normalize popularity scores
for all datasets [ 27,56]:ùë¶=log2ùëü/ùëë+1, whereùë¶denotes the
normalized popularity scores, ùëüis the final view count, ùëëis the
number of days since the UGC was posted, and the addition 1is
used to avoid zeros in the logarithm.
4.1.2 Baseline. To evaluate model superiority, we compare RAG-
Trans with 13 strong baselines, which can be divided into three
groups: (1) Feature engineering :SVR [27] employs support vector re-
gression for popularity prediction, which only considers the visual
information of different UGCs. Hyfea [29] is a feature-engineering
model, which designs hand-craft features and then selects a well-
performed model via CatBoost. MFTM [22] combines LightGBM
and TabNet to capture intricate semantic relationships among dif-
ferent modal content. (2) Deep learning methods :DTCN [54] con-
siders both neighboring temporal context and periodic temporal
context by the temporal attention mechanism. UHAN [64] designs
a user-guided hierarchical attention to merge both textual and vi-
sual features under the guidance of user embeddings. MMVED
[60] designs a multimodal VAE to encode the input modalities to a
low-dimensional stochastic embedding. MGC [42] designs a text-
guided attention network to learn multimodal UGC data. MHF [51]
constructs a hierarchical fusion framework to learn multimodal fea-
tures (i.e., image and text) for image popularity prediction. CBAN
[11] is to integrate positive attention and negative attention to
model relevant and irrelevant information across different modali-
ties.JAB [53] assess the impact of a post‚Äôs title on its popularity
while controlling for the time of posting by an attention-based
model. MASSL [65] constructs a multimodal variational encoder-
decoder framework for the popularity prediction. (3) Hypergraph
methods :HGNN [14] introduces graph convolution to hypergraph
and designs a hyperedge convolution operation to model the data
high-order correlations. DHGNN [25] designs a dynamic hyper-
graph neural network that is composed of two modules: dynamic
hypergraph construction and hypergraph convolution.
4.1.3 Implementation Details. All models are tuned to the best per-
formance according to the early stopping strategy when validation
errors are not declined for 10 consecutive epochs. For experimental
results, we run each model on each dataset five times and report the
mean performance. For RAGTrans, model parameters are updatedby Adam optimizer and the learning rate is set to 0.001. Further-
more, on SMPD and ICIP datasets, we use pre-trained ResNet to
capture the visual features and employ pre-trained sentence-BERT
[44] to model the textual features. The dimension of visual and tex-
tual features is 2048 and 384, respectively. For the WeChat dataset,
we use preprocessed data features. The layer of BHT is 2, and di-
mension of user embedding is 256. The batch size is 128 and the
attention head number ùêªis selected from{1,2,4,8,16}. Since these
two baselines (HGNN, DHGNN) cannot be directly applied to the
multimodal popularity prediction task, we made several adaptions
to them. Specifically, model each UGC‚Äôs category as a hyperedge
and each UGC as a node in the hypergraph. For multimodal features,
we use a concatenation operation to fuse them.
4.1.4 Evaluation Metric. Following [ 54,64], we have chosen two
commonly used types of evaluation metrics from the perspective
of correlation and precision: Spearman ranking correlation (SRC),
mean absolute error (MAE) and mean squared errors (MSE). SRC
is used to reflect the ranking correlation between ground-truth
popularityùë¶and predicted popularity ÀÜùë¶. Higher SRC scores mean
better model performance. In addition, we utilize MAE and MSE to
compute the average prediction error.
4.2 Overall Performance (RQ1)
The results from comparing RAGTrans with the baselines on the
multimodal social media popularity prediction task are reported in
Table 2 and we have the following observations:
(O1): Our RAGTrans consistently outperforms all competitive base-
lines on three datasets under all evaluation metrics. Notably, our
model achieves 25.11%, 20.65%, and 22.96% relative gains in terms
of MSE, MAE, and SRC on the ICIP dataset, respectively. These
experimental results verify the significance of the improvement by
RAGTrans. Compared to all baselines, RAGTrans generates more
accurate popularity trends, due to its retrieval-augmented strategy.
Specifically, RAGTrans effectively retrieves relevant UGC instances
and captures expressive knowledge from retrieved instances to
guide prediction. Bootstrapping hypergraph transformer facilitates
enriched corss-modal high-order relationships between the target
UGC and retrieved instances, which further boosts the performance.
(O2): The gaps between feature models and other baselines are
relatively small, and in some cases feature models even outperform
deep learning models, indicating that deep learning models are
not always superior to feature methods. However, its performance
heavily relies on hand-crafted features, which are labor intensive
and challenging to generalize to new scenarios. This finding is
supported by the results of feature models on the SMPD dataset.
(O3): RAGTrans outperforms deep-learning models by a consider-
able margin. We attribute the performance deficiency to the inher-
ent incapability of above baselines in effectively exploit crucial clues
in pertinent UGCs to guide the target predictions. Moreover, HGNN
and DHGNN utilize hypergraph to model cross-modal correlations
from multi-modal UGCs, leading to performance improvements. In
contrast, RAGTrans decouples the high-order correlations between
the target UGC and relevant instances via aspect-aware hyperedges,
and captures intra- and inter-modal correlations via the multimodal
mixture. The huge performance gap strongly shows the effective-
ness of bootstrapping hypergraph transformer in RAGTrans.
 
451KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain Zhangtao Cheng, et al.
Table 2: Performance comparison on three real-world datasets. The best results are in bold font and the second underlined .
Lower values of MSE and MAE, and higher values of SRC, indicate better performance.
Dataset Metric SVR Hyfea
MFTM DT
CN UHAN MMVED MGC MHF CBAN JAB MASSL HGNN DHGNN RAGT
rans Improv.
SMPDMSE 4.9886 4.9297
6.3697 4.2523 3.8471 6.3672 5.5216
3.9297 5.6673 6.1882 13.8925 5.1770 5.0450 3.2763 14.83%‚Üë
MAE 1.6749 1.6623
1.9590 1.4998 1.4833 1.9607 1.8489
1.5433 1.9058 1.9359 3.1133 1.6061 1.5836 1.3396 9.68%‚Üë
SRC 0.5312 0.5518
0.3479 0.5432 0.5541 0.2610 0.3228
0.5419 0.1285 0.2353 0.3037 0.4371 0.4698 0.5859 5.73%‚Üë
ICIPMSE 2.0942 1.9813
1.6268 2.8361 2.7492
1.9831 1.7706 1.8736 3.6143 1.8606 1.8359 1.6711 1.6493 1.2351 25.11%‚Üë
MAE 1.0552 0.9935
0.8923 1.3432 1.2824
1.0796 1.0117 0.9132 1.3897 0.9289 0.8809 0.9093 0.9010 0.7149 20.65%‚Üë
SRC 0.3723 0.3641
0.4349 0.3893 0.3981
0.2606 0.3906 0.4041 0.1294 0.3057 0.3937 0.4423 0.4556 0.5914 22.96%‚Üë
WeChatMSE 2.9551 2.8655
2.8104 3.6921 3.5925
2.9950 2.9450 2.8351 2.9325 2.9654
3.8951 2.9452 2.9031 2.7928 1.49%‚Üë
MAE 3.2072 3.1073
3.0670 3.4432 3.3132
3.2151 3.1954 3.0543 3.0945 3.1185
3.1294 3.1753 3.1048 2.9898 2.11%‚Üë
SRC 0.0900 0.1054 0.0794 0.0821 0.0835
0.0911 0.0891 0.1019 0.0706 0.0280 0.0529 0.0939 0.0958 0.1147 8.88%‚Üë
Table 3: Ablation study of RAGTrans.
Module
VariantSMPD ICIP
MSE SRC MSE SRC
RAGT
rans All 3.2763 0.5859 1.2351 0.5914
UGC Retrie
val w/o RM 5.5216 0.3228 1.6706 0.3966
BHT
Modulew/GU 4.9555 0.4083 1.4983 0.4238
w/GC 5.0322 0.3745 1.5324 0.4112
w/o
FFN 3.9106 0.4883 1.3787 0.4937
Hyp
erGAT 4.2481 0.4268 1.4152 0.4587
User- A
ware
Fusionw/oU 4.9092 0.4143 1.6419 0.4214
w/o
Attn 3.8496 0.5045 1.3211 0.5270
4.3 Ablation Study (RQ2)
To gain insights into the major components of RAGTrans, we con-
duct ablation study on UGC retrieval module, BHT module, and
user-aware fusion module. Table 3 shows ablation results.
4.3.1 Effectiveness of UGC retrieval. We first explore the effect
of UGC retrieval and verify our motivation for the retrieval-
augmented MSMPP. We design a variant model without the UGC
retrieval module (w/o RM). Based on the results in Table 3, we find
that removing the retrieval module would impair prediction perfor-
mance. It demonstrates that retrieving relevant UGC instances in
the memory bank can provide meaningful knowledge for guiding
prediction and enhancing the model‚Äôs generalization.
4.3.2 Effectiveness of BHT module. We explore the effect of hy-
pergraph structures. We compare the performance of the model
when we solely use user-level hypergraph (w/ GU) and solely use
the category-level hypergraph (w/ GC). As shown in Table 3, we
can observe that using GUorGCseverely decrease the prediction
performance. This result shows that a large hypergraph contain-
ing all UGCs will inject many data noises and lead to suboptimal
performance. It further confirms the presence of high-order correla-
tions between the target UGC and relevant instances stored in the
memory bank. Moreover, we compare the performance without the
feed-forward network (w/o FFN) or with a standard HyperGAT net-
work. The results indicate that both methods harm the prediction
performance, and capturing intra- and inter-modal correlations is
helpful to obtain expressive UGC representations.
4.3.3 Effectiveness of user-aware fusion module. We build two vari-
ants that without user embedding Uor without fusion attention
3.253.353.45
SMPD
2.702.853.00
ICIP
1 2 4 8161.201.241.28
WeChatMSE(a) Number of ùêª
/uni00000014/uni00000013/uni00000013 /uni00000015/uni00000013/uni00000013 /uni00000016/uni00000013/uni00000013 /uni00000017/uni00000013/uni00000013 /uni00000018/uni00000013/uni00000013/uni00000014/uni00000011/uni00000013/uni00000014/uni00000011/uni00000018/uni00000015/uni00000011/uni00000013/uni00000015/uni00000011/uni00000018/uni00000016/uni00000011/uni00000013/uni00000016/uni00000011/uni00000018/uni00000017/uni00000011/uni00000013/uni00000017/uni00000011/uni00000018/uni00000018/uni00000011/uni00000013
/uni00000036/uni00000030/uni00000033/uni00000027 /uni0000003a/uni00000048/uni00000026/uni0000004b/uni00000044/uni00000057 /uni0000002c/uni00000026/uni0000002c/uni00000033/uni00000030/uni00000036/uni00000028 (b) Number of ùêæ
Figure 3: Sensitivity Analysis of RAGTrans on three datasets.
(a) Attention head ùêªin BHT. (b) Retrieved instances ùêæ.
mechanism. The results indicate that fusion attention mechanism
can reduce redundant aggregation of multimodal representations
and alleviate negative effects from irrelevant information. In ad-
dition, when we remove user embeddings, the model also suffers
from a performance drop. This result verifies the effectiveness of
our design to inject user information to assist feature fusion.
4.4 Hyper-parameter Analysis (RQ3)
Fig. 3 shows the sensitivity analysis of the RAGTrans parameters.
4.4.1 Multi-head ùêªof BHT. Fig. 3 (a) shows the effect of the multi-
head number ùêªof BHT for values{1,2,4,8,16}. As can be seen, the
performance of RAGTrans initially improves as ùêªincreases, and
then declines when ùêªis larger, yielding ùêª=4 as appropriate value.
4.4.2 Number of retrieved instances ùêæ.Our first observation is that
utilizing neighborhood knowledge through the retrieval operation
would enhance model performance ‚Äì in comparison to the variant
model w/o RM. Retrieval of more data instances boosts the perfor-
mance of RAGTrans and delivers the best results until ùêæ=300.
When including more data instances ( ùêæ>300), the performance of
the model starts to decrease. We speculate that this is due to the
introduction of noise (irrelevant UGCs) into the model.
4.5 Case Study (RQ4)
4.5.1 Model generalizability. We show the prediction errors of our
model, along with the two best-performing baselines (UHAN and
HyFea), in Fig. 4. We randomly selected 10 data instances from the
SMPD test set, posted by cold start users who have uploaded fewer
 
452Retrieval-Augmented Hypergraph for Multimodal Social Media Popularity Prediction KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain
HyFeaUHANRAGTrans
Figure 4: Visualization of model prediction on the SMPD dataset. Top row: error between model prediction scores and ground
truth of HyFea, UHAN, and RAGTrans. The higher the bar, the greater the error. Middle row: error threshold (red cross indicates
prediction error greater than 0.5; green tick indicates prediction error lower than 0.5. Bottom row: different UGCs.
/uni00000014/uni00000013/uni00000013/uni00000008 /uni0000001c/uni00000013/uni00000008 /uni0000001b/uni00000013/uni00000008 /uni0000001a/uni00000013/uni00000008 /uni00000019/uni00000013/uni00000008 /uni00000018/uni00000013/uni00000008
/uni0000000b/uni00000044/uni0000000c/uni00000003/uni00000036/uni00000030/uni00000033/uni00000027/uni00000013/uni00000011/uni00000019/uni00000013/uni00000011/uni0000001b/uni00000014/uni00000011/uni00000013/uni00000014/uni00000011/uni00000015/uni00000014/uni00000011/uni00000017/uni00000014/uni00000011/uni00000019/uni00000030/uni00000024/uni00000028
/uni00000014/uni00000013/uni00000013/uni00000008 /uni0000001c/uni00000013/uni00000008 /uni0000001b/uni00000013/uni00000008 /uni0000001a/uni00000013/uni00000008 /uni00000019/uni00000013/uni00000008 /uni00000018/uni00000013/uni00000008
/uni0000000b/uni00000045/uni0000000c/uni00000003/uni0000002c/uni00000026/uni0000002c/uni00000033/uni00000014/uni00000011/uni00000013/uni00000014/uni00000011/uni00000015/uni00000014/uni00000011/uni00000017/uni00000014/uni00000011/uni00000019/uni00000014/uni00000011/uni0000001b/uni00000015/uni00000011/uni00000013
/uni00000013/uni00000008/uni00000010/uni00000018/uni00000008/uni00000010/uni00000014/uni00000013/uni00000008/uni00000010/uni00000014/uni00000018/uni00000008/uni00000010/uni00000015/uni00000013/uni00000008
/uni00000013/uni00000008/uni00000010/uni00000018/uni00000008/uni00000010/uni00000014/uni00000013/uni00000008/uni00000010/uni00000014/uni00000018/uni00000008/uni00000010/uni00000015/uni00000013/uni00000008/uni00000010/uni00000015/uni00000018/uni00000008/uni00000010/uni00000016/uni00000013/uni00000008/uni00000010/uni00000016/uni00000018/uni00000008
/uni0000002c/uni00000050/uni00000053/uni00000055/uni00000052/uni00000059/uni00000048/uni00000003/uni0000002a/uni00000044/uni0000004c/uni00000051
/uni0000002b/uni0000005c/uni00000049/uni00000048/uni00000044 /uni00000038/uni0000002b/uni00000024/uni00000031 /uni00000030/uni0000002b/uni00000029 /uni00000035/uni00000024/uni0000002a/uni00000037/uni00000055/uni00000044/uni00000051/uni00000056 /uni0000002b/uni0000005c/uni00000049/uni00000048/uni00000044 /uni00000038/uni0000002b/uni00000024/uni00000031 /uni00000030/uni0000002b/uni00000029 /uni00000035/uni00000024/uni0000002a/uni00000037/uni00000055/uni00000044/uni00000051/uni00000056
Figure 5: The effect of training set proportion on SMPD and
ICIP datasets. The bars represent MAE values and the poly-
lines denote the performance degradation gain.
than three UGCs. We can observe that only two prediction errors
of HyFea are lower than 0.5, and only three prediction errors of
UHAN are lower than 0.5. For our RAGTrans, there are six UGCs‚Äô
prediction errors lower than 0.5. Also, RAGTrans exhibits better
prediction results on the images that have complex background,
which shows that capturing rich and meaningful knowledge from
retrieved relevant instances in the memory bank is beneficial for
assisting prediction. The results also indicate that employing the
retrieval-augmented strategy improves the model generalizability
and enhances the prediction performance on newly emerged UGCs.
4.5.2 Model robustness. We investigate the robustness of our
model and three best performed baselines (hyfea, UHAN and MHF)
by using different portions of the training set. The results are shown
in Fig. 5. It is noticeable that the performance of feature engineering
method (Hyfea) shows little sensitivity to the size of the training set,
while RAGTrans experiences a slight decrease but remains superior
to Hyfea. This suggests that Hyfea heavily depends on the quality
of hand-crafted UGC features and exhibits limited generalization
across different datasets. We can also observe that the performance
of deep learning baselines deteriorates significantly when using
less training data, as opposed to RAGTrans‚Äôs slight decrease. This
indicates that RAGTrans mitigates the impact of dataset size by
capturing meaningful knowledge from retrieved instances and im-
proving UGC representations through the multimodal hypergraph
aggregation of intra- and inter-modal neighborhood information.
It also shows better robustness of RAGTrans compared to baselines
when training data are limited.
4.5.3 Analysis of retrieved instances. We randomly select three
UGCs in the test set to visualize top-3 retrieved instances in the
Figure 6: Examples of retrieved Top-3 nearest UGCs.
memory bank. As shown in Fig. 6, retrieved instances have associ-
ated visual content and textual descriptions with the target UGC,
verifying the effectiveness of the aspect-aware retrieval.
5 CONCLUSION
In this work, we take a pioneering step to design a retrieval-
augmented strategy for enhancing UGCs and proposed RAGTrans ‚Äì
an aspect-aware retrieval augmented multi-modal hypergraph
transformer to reformulate the prediction process in a retrieve-and-
predict format. First, we design a aspect-aware retrieval module
to obtain relevant instances. Second, we extend hypergraph atten-
tion network into bootstrapping hypergraph transformer to jointly
mine intra- and inter-modal information. Finally, a user-aware fu-
sion module is used to obtain fine-grained aligned representations.
Extensive experimental results on three datasets demonstrate the
effectiveness of our RAGTrans. As part of the future work, we will
attempt to incorporate temporal dynamics in the UGC prediction.
6 ACKNOWLEDGMENTS
This work was supported by National Natural Science Foundation
of China (Grant No.62176043 and No.62072077) and Kashgar Science
and Technology Bureau (Grant No.KS2023025).
 
453KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain Zhangtao Cheng, et al.
REFERENCES
[1]Alessia Antelmi, Gennaro Cordasco, Mirko Polato, Vittorio Scarano, Carmine
Spagnuolo, and Dingqi Yang. 2023. A Survey on Hypergraph Representation
Learning. Comput. Surveys (2023).
[2]Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton. 2016. Layer normaliza-
tion. arXiv preprint arXiv:1607.06450 (2016).
[3]David M Blei, Andrew Y Ng, and Michael I Jordan. 2003. Latent dirichlet allocation.
Journal of machine Learning research 3, Jan (2003), 993‚Äì1022.
[4]Alain Bretto. 2013. Hypergraph theory. An introduction. Mathematical Engineer-
ing. Cham: Springer (2013).
[5]Ethem F Can, H√ºseyin Oktay, and R Manmatha. 2013. Predicting retweet count
using visual cues. In International Conference on Information and Knowledge
Management (CIKM). 1481‚Äì1484.
[6]Spencer Cappallo, Thomas Mensink, and Cees GM Snoek. 2015. Latent factors
of visual popularity prediction. In ACM International Conference on Multimedia
(MM). 195‚Äì202.
[7]Jingyuan Chen, Xuemeng Song, Liqiang Nie, Xiang Wang, Hanwang Zhang, and
Tat-Seng Chua. 2016. Micro tells macro: Predicting the popularity of micro-videos
via a transductive model. In ACM International Conference on Multimedia (MM).
898‚Äì907.
[8]Justin Cheng, Lada Adamic, P Alex Dow, Jon Michael Kleinberg, and Jure
Leskovec. 2014. Can cascades be predicted?. In International Conference on World
Wide Web (WWW). 925‚Äì936.
[9]Zhangtao Cheng, Joojo Walker, Ting Zhong, and Fan Zhou. 2022. Modeling multi-
view interactions with contrastive graph learning for collaborative filtering. In
2022 International Joint Conference on Neural Networks (IJCNN). IEEE, 1‚Äì8.
[10] Zhangtao Cheng, Wenxue Ye, Leyuan Liu, Wenxin Tai, and Fan Zhou. 2023.
Enhancing Information Diffusion Prediction with Self-Supervised Disentangled
User and Cascade Representations. In International Conference on Information
and Knowledge Management (CIKM). 3808‚Äì3812.
[11] Tsun-hin Cheung and Kin-man Lam. 2022. Crossmodal bipolar attention for
multimodal classification on social media. Neurocomputing 514 (2022), 1‚Äì12.
[12] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT:
Pre-training of Deep Bidirectional Transformers for Language Understanding. In
North American Chapter of the Association for Computational Linguistics (NAACL) .
4171‚Äì4186.
[13] Wenqi Fan, Yao Ma, Qing Li, Yuan He, Eric Zhao, Jiliang Tang, and Dawei Yin.
2019. Graph neural networks for social recommendation. In The world wide web
conference (WWW). 417‚Äì426.
[14] Yifan Feng, Haoxuan You, Zizhao Zhang, Rongrong Ji, and Yue Gao. 2019. Hy-
pergraph neural networks. In AAAI Conference on Artificial Intelligence (AAAI),
Vol. 33. 3558‚Äì3565.
[15] Francesco Gelli, Tiberio Uricchio, Marco Bertini, Alberto Del Bimbo, and Shih-Fu
Chang. 2015. Image popularity prediction in social media using sentiment and
context features. In ACM International Conference on Multimedia (MM). 907‚Äì910.
[16] Mor Geva, Roei Schuster, Jonathan Berant, and Omer Levy. 2021. Transformer
Feed-Forward Layers Are Key-Value Memories. In Conference on Empirical Meth-
ods in Natural Language Processing (EMNLP). 5484‚Äì5495.
[17] Kai Han, Yunhe Wang, Hanting Chen, Xinghao Chen, Jianyuan Guo, Zhenhua
Liu, Yehui Tang, An Xiao, Chunjing Xu, Yixing Xu, et al .2022. A survey on vision
transformer. IEEE transactions on pattern analysis and machine intelligence 45, 1
(2022), 87‚Äì110.
[18] John A Hartigan, Manchek A Wong, et al .1979. A k-means clustering algorithm.
Applied statistics 28, 1 (1979), 100‚Äì108.
[19] Junxian He, Chunting Zhou, Xuezhe Ma, Taylor Berg-Kirkpatrick, and Graham
Neubig. 2022. Towards a Unified View of Parameter-Efficient Transfer Learning.
InInternational Conference on Learning Representations (ICLR).
[20] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep residual
learning for image recognition. In Computer Vision and Pattern Recognition (CVPR).
770‚Äì778.
[21] Nicola J Hodges, A Mark Williams, Spencer J Hayes, and Gavin Breslin. 2007.
What is modelled during observational learning? Journal of sports sciences 25, 5
(2007), 531‚Äì545.
[22] Chih-Chung Hsu, Chia-Ming Lee, Xiu-Yu Hou, and Chi-Han Tsai. 2023. Gra-
dient Boost Tree Network based on Extensive Feature Analysis for Popularity
Prediction of Social Posts. In ACM International Conference on Multimedia (MM).
9451‚Äì9455.
[23] Zheng Hu, Satoshi Nakagawa, Liang Luo, Yu Gu, and Fuji Ren. 2023. Celebrity-
aware Graph Contrastive Learning Framework for Social Recommendation. In
International Conference on Information and Knowledge Management (CIKM).
793‚Äì802.
[24] Liya Ji, Chan Ho Park, Zhefan Rao, and Qifeng Chen. 2023. Neural Image Popu-
larity Assessment with Retrieval-augmented Transformer. In ACM International
Conference on Multimedia (MM). 2427‚Äì2436.
[25] Jianwen Jiang, Yuxuan Wei, Yifan Feng, Jingxuan Cao, and Yue Gao. 2019. Dy-
namic Hypergraph Neural Networks. In International Joint Conference on Artificial
Intelligence (IJCAI). 2635‚Äì2641.[26] Guangyin Jin, Yuxuan Liang, Yuchen Fang, Zezhi Shao, Jincai Huang, Junbo
Zhang, and Yu Zheng. 2023. Spatio-temporal graph neural networks for predictive
learning in urban computing: A survey. IEEE Transactions on Knowledge and
Data Engineering (TKDE) (2023).
[27] Aditya Khosla, Atish Das Sarma, and Raffay Hamid. 2014. What makes an image
popular?. In The Web Conference (WWW). 867‚Äì876.
[28] Thomas N. Kipf and Max Welling. 2017. Semi-Supervised Classification with
Graph Convolutional Networks. In International Conference on Learning Repre-
sentations (ICLR).
[29] Xin Lai, Yihong Zhang, and Wei Zhang. 2020. Hyfea: winning solution to so-
cial media popularity prediction for multimedia grand challenge 2020. In ACM
International Conference on Multimedia (MM). 4565‚Äì4569.
[30] Himabindu Lakkaraju and Jitendra Ajmera. 2011. Attention prediction on social
media brand pages. In International Conference on Information and Knowledge
Management (CIKM). 2157‚Äì2160.
[31] Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin,
Naman Goyal, Heinrich K√ºttler, Mike Lewis, Wen-tau Yih, Tim Rockt√§schel,
et al.2020. Retrieval-augmented generation for knowledge-intensive nlp tasks.
Advances in Neural Information Processing Systems (Neurips) 33 (2020), 9459‚Äì9474.
[32] Liuwu Li, Runwei Situ, Junyan Gao, Zhenguo Yang, and Wenyin Liu. 2017. A hy-
brid model combining convolutional neural network with xgboost for predicting
social media popularity. In ACM International Conference on Multimedia (MM).
1912‚Äì1917.
[33] Xianming Li and Jing Li. 2023. Angle-optimized text embeddings. arXiv preprint
arXiv:2309.12871 (2023).
[34] Xiang Lisa Li and Percy Liang. 2021. Prefix-Tuning: Optimizing Continuous
Prompts for Generation. In Conference on Empirical Methods in Natural Language
Processing (EMNLP). 4582‚Äì4597.
[35] Leyuan Liu, Junyi Chen, Zhangtao Cheng, Wenxin Tai, and Fan Zhou. 2023.
Towards Trustworthy Rumor Detection with Interpretable Graph Structural
Learning. In International Conference on Information and Knowledge Management
(CIKM). 4089‚Äì4093.
[36] Alexander Long, Wei Yin, Thalaiyasingam Ajanthan, Vu Nguyen, Pulak Purkait,
Ravi Garg, Alan Blair, Chunhua Shen, and Anton van den Hengel. 2022. Retrieval
augmented classification for long-tail visual recognition. In Computer Vision and
Pattern Recognition (CVPR). 6959‚Äì6969.
[37] Philip J McParlane, Yashar Moshfeghi, and Joemon M Jose. 2014. " Nobody comes
here anymore, it‚Äôs too crowded"; Predicting Image Popularity on Flickr. In ACM
International Conference on Multimedia (MM). 385‚Äì391.
[38] Alessandro Ortis, Giovanni Maria Farinella, and Sebastiano Battiato. 2019. Pre-
diction of social image popularity dynamics. In Image Analysis and Processing
(ICIAP). 572‚Äì582.
[39] Nicolas Papernot and Patrick McDaniel. 2018. Deep k-nearest neighbors: Towards
confident, interpretable and robust deep learning. arXiv preprint arXiv:1803.04765
(2018).
[40] Henrique Pinto, Jussara M Almeida, and Marcos A Gon√ßalves. 2013. Using early
view patterns to predict the popularity of youtube videos. In Web Search and
Data Mining (WSDM). 365‚Äì374.
[41] David Premack and Guy Woodruff. 1978. Does the chimpanzee have a theory of
mind? Behavioral and brain sciences 1, 4 (1978), 515‚Äì526.
[42] Yang Qian, Wang Xu, Xiao Liu, Haifeng Ling, Yuanchun Jiang, Yidong Chai,
and Yezheng Liu. 2022. Popularity prediction for marketer-generated content: A
text-guided attention neural network for multi-modal feature fusion. Information
Processing & Management 59, 4 (2022), 102984.
[43] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh,
Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark,
et al.2021. Learning transferable visual models from natural language supervision.
InInternational Conference on Machine Learning (ICML). 8748‚Äì8763.
[44] Nils Reimers and Iryna Gurevych. 2019. Sentence-BERT: Sentence Embeddings
using Siamese BERT-Networks. In EMNLP. Association for Computational Lin-
guistics (ACL), 3980‚Äì3990.
[45] Stephen E Robertson, Steve Walker, Susan Jones, Micheline M Hancock-Beaulieu,
Mike Gatford, et al .1995. Okapi at TREC-3. Nist Special Publication Sp 109 (1995),
109.
[46] Lifeng Sun, Xiaoyan Wang, Zhi Wang, Hong Zhao, and Wenwu Zhu. 2016. Social-
aware video recommendation for online social groups. IEEE Transactions on
Multimedia 19, 3 (2016), 609‚Äì618.
[47] Xiangguo Sun, Hongzhi Yin, Bo Liu, Hongxu Chen, Jiuxin Cao, Yingxia Shao,
and Nguyen Quoc Viet Hung. 2021. Heterogeneous hypergraph embedding for
graph classification. In ACM International Conference on Web Search and Data
Mining (WSDM). 725‚Äì733.
[48] Gabor Szabo and Bernardo A Huberman. 2010. Predicting the popularity of
online content. Commun. ACM 53, 8 (2010), 80‚Äì88.
[49] Alexandru Tatar, Marcelo Dias De Amorim, Serge Fdida, and Panayotis Anto-
niadis. 2014. A survey on predicting the popularity of web content. Journal of
Internet Services and Applications 5, 1 (2014), 1‚Äì20.
[50] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
Aidan N Gomez, ≈Åukasz Kaiser, and Illia Polosukhin. 2017. Attention is all
you need. Conference on Neural Information Processing Systems (NIPS) 30 (2017).
 
454Retrieval-Augmented Hypergraph for Multimodal Social Media Popularity Prediction KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain
[51] Jing Wang, Shuo Yang, Hui Zhao, and Yue Yang. 2023. Social media popular-
ity prediction with multimodal hierarchical fusion model. Computer Speech &
Language 80 (2023), 101490.
[52] WeChat. 2021. 2021 China University Computer Contest‚ÄîWeChat Big Data
Challenge. https://algo.weixin.qq.com/2021/problem-description.
[53] Evan Weissburg, Arya Kumar, and Paramveer S Dhillon. 2022. Judging a book
by its cover: Predicting the marginal impact of title on Reddit post popularity. In
AAAI Conference on Web and Social Media, Vol. 16. 1098‚Äì1108.
[54] Bo Wu, Wen-Huang Cheng, Yongdong Zhang, Qiushi Huang, Jintao Li, and Tao
Mei. 2017. Sequential Prediction of Social Media Popularity with Deep Temporal
Context Networks. In International Joint Conference on Artificial Intelligence
(IJCAI). 3062‚Äì3068.
[55] Bo Wu, Wen-Huang Cheng, Peiye Liu, Bei Liu, Zhaoyang Zeng, and Jiebo Luo.
2019. SMP Challenge: An Overview of Social Media Prediction Challenge 2019.
InACM International Conference on Multimedia (MM).
[56] Bo Wu, Wen-Huang Cheng, Yongdong Zhang, and Tao Mei. 2016. Time matters:
Multi-scale temporalization of social media popularity. In ACM International
Conference on Multimedia (MM). 1336‚Äì1344.
[57] Bo Wu, Tao Mei, Wen-Huang Cheng, and Yongdong Zhang. 2016. Unfolding
temporal dynamics: Predicting social media popularity using multi-scale temporal
decomposition. In AAAI Conference on Artificial Intelligence (AAAI), Vol. 30.
[58] Lianwei Wu, Yuan Rao, Xiong Yang, Wanzhen Wang, and Ambreen Nazir. 2021.
Evidence-aware hierarchical interactive attention networks for explainable claim
verification. In International Joint Conference on Artificial Intelligence (IJCAI).
1388‚Äì1394.
[59] Zonghan Wu, Shirui Pan, Fengwen Chen, Guodong Long, Chengqi Zhang, and
S Yu Philip. 2020. A comprehensive survey on graph neural networks. IEEE
Transactions on Neural Networks and Learning Systems (TNNLS) 32, 1 (2020), 4‚Äì24.
[60] Jiayi Xie, Yaochen Zhu, and Zhenzhong Chen. 2021. Micro-video Popularity
Prediction via Multimodal Variational Information Bottleneck. IEEE Transactions
on Multimedia (2021).
[61] Xovee Xu, Fan Zhou, Kunpeng Zhang, and Siyuan Liu. 2022. CCGL: Contrastive
cascade graph learning. IEEE Transactions on Knowledge and Data Engineering
(TKDE) 35, 5 (2022), 4539‚Äì4554.
[62] Xovee Xu, Fan Zhou, Kunpeng Zhang, Siyuan Liu, and Goce Trajcevski. 2021.
CasFlow: Exploring hierarchical structures and propagation uncertainty for
cascade prediction. IEEE Transactions on Knowledge and Data Engineering (TKDE)
35, 4 (2021), 3484‚Äì3499.
[63] Junliang Yu, Hongzhi Yin, Jundong Li, Qinyong Wang, Nguyen Quoc Viet Hung,
and Xiangliang Zhang. 2021. Self-supervised multi-channel hypergraph convolu-
tional network for social recommendation. In The Web Conference. 413‚Äì424.
[64] Wei Zhang, Wen Wang, Jun Wang, and Hongyuan Zha. 2018. User-guided
hierarchical attention network for multi-modal social image popularity prediction.
InThe Web Conference (WWW). 1277‚Äì1286.
[65] Zhuoran Zhang, Shibiao Xu, Li Guo, and Wenke Lian. 2022. Multi-modal Varia-
tional Auto-Encoder Model for Micro-video Popularity Prediction. In International
Conference on Communication and Information Processing. 9‚Äì16.
[66] Fan Zhou, Xovee Xu, Goce Trajcevski, and Kunpeng Zhang. 2021. A survey of
information cascade analysis: Models, predictions, and recent advances. ACM
Computing Surveys (CSUR) 54, 2 (2021), 1‚Äì36.
A FEATURE EXTRACTION
The multimodal user-generated content in this work is composed
of visual data (image) and textual data (text descriptions). For vi-
sual and textual modalities, we use pre-trained ResNet-50 [ 20] and
Sentence-BERT [ 44] to extract image and text description represen-
tations, respectively. In addition, existing feature-based methods
had demonstrated that user features (e.g., age and gender) are pre-
dictive for popularity prediction [ 8]. Therefore, we extract userfeatures to improve prediction performance. Notably, our RAG-
Trans can effortlessly adapt to alternative pre-trained visual (i.e.,
CLIP [ 43] and VIT [ 17]) and language models (i.e., Bert [ 12] and
AnglE [33]).
A.1 Visual Modality
For visual knowledge, they can intuitively reflect UGC semantics
and attract users‚Äô attention. Given a set of images I={ùêº1,...,ùêºùëÅ},
we use pre-trained ResNet-50 to extract visual representations ùíÅùë£=
{ùíõùë£
1,..., ùíõùë£
ùëÅ}‚ààRùëÅ√óùëë. Specifically, the calculation process can be
defined as:
ùíõùë£
ùëñ=ResNet(ùêºùëñ). (11)
A.2 Textual Modality
For textual knowledge, they provide valuable UGC descriptions
along with the visual content. Given a set of UGC descriptions
Te={Te1,..., TeùëÅ}, we employ pre-trained Sentence-BERT [ 44]
to extract textual representations ùíÅùë°={ùíõùë°
1,..., ùíõùë°
ùëÅ}‚ààRùëÅ√óùëëas
follows:
ùíõùë°
ùëñ=Sentence-BERT(Teùëñ). (12)
A.3 User Embedding
To customize users‚Äô identities and capture users‚Äô divergent influ-
ences, we describe a user ùë¢with a learnable embedding vector
u‚ààRùëëùë¢, whereùëëùë¢denotes the adjustable vector dimension. Particu-
larly, all user embedding vectors formulate a user embedding matrix,
which can be seen as an embedding look-up table: U={u1...uùëÅùë¢}.
HereùëÅùë¢is the number of users. Note that the user embedding ma-
trixUis regarded as the initial state of users and can be dynamically
updated via the label of the studied UGC in an end-to-end fashion.
A.4 Aspect Information Construction
For features xùëñ={ùë•ùëñ
ùëì|ùëì=1,...,F}in the aspect information
of data instance ùëêùëñin Section 4.1, we design four types of UGC
aspect information (i.e., user ID, category, text topic and image
semantic) and employ search engine techniques to retrieve the
ùêænearest data instances of the target. For image semantics, we
use clustering operation (i.e., k-means clustering [ 18]) to partition
the visual features ùíÅùë£intoKùë£clusters in which each observation
belongs to the cluster with the nearest mean (cluster centroid),
serving as a prototype of the cluster. Specifically, Kùë£clusters denote
Kùë£types of image semantics. For text topics, we employ the topic
model Latent Dirichlet allocation (LDA) [ 3] as the topic clustering
tool to obtainKùë°text topics. For the remaining attributes, they are
collected from the original data source.
 
455