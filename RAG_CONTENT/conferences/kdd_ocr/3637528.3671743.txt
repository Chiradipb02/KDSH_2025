Diffusion-Based Cloud-Edge-Device Collaborative Learning for
Next POI Recommendations
Jing Long
jing.long@uq.edu.au
The University of Queensland
Brisbane, AustraliaGuanhua Ye
g.ye@bupt.edu.cn
Beijing University of Posts and
Telecommunications
Beijing, ChinaTong Chen
tong.chen@uq.edu.au
The University of Queensland
Brisbane, Australia
Yang Wang
yangwang@hfut.edu.cn
Hefei University of Technology
Hefei, ChinaMeng Wang
eric.mengwang@gmail.com
Hefei University of Technology
Hefei, ChinaHongzhi Yin*
h.yin1@uq.edu.au
The University of Queensland
Brisbane, Australia
Abstract
The rapid expansion of Location-Based Social Networks (LBSNs)
has highlighted the importance of effective next Point-of-Interest
(POI) recommendations, which leverage historical check-in data
to predict users’ next POIs to visit. Traditional centralized deep
neural networks (DNNs) offer impressive POI recommendation
performance but face challenges due to privacy concerns and lim-
ited timeliness. In response, on-device POI recommendations have
been introduced, utilizing federated learning (FL) and decentral-
ized approaches to ensure privacy and recommendation timeliness.
However, these methods often suffer from computational strain on
devices and struggle to adapt to new users and regions. This paper
introduces a novel collaborative learning framework, Diffusion-
Based Cloud-Edge-Device Collaborative Learning for Next POI
Recommendations (DCPR), leveraging the diffusion model known
for its success across various domains. DCPR operates with a cloud-
edge-device architecture to offer region-specific and highly person-
alized POI recommendations while reducing on-device computa-
tional burdens. DCPR minimizes on-device computational demands
through a unique blend of global and local learning processes. Our
evaluation with two real-world datasets demonstrates DCPR’s su-
perior performance in recommendation accuracy, efficiency, and
adaptability to new users and regions, marking a significant step
forward in on-device POI recommendation technology.
CCS Concepts
•Information systems →Recommender systems.
*Corresponding author.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
KDD ’24, August 25–29, 2024, Barcelona, Spain
©2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 979-8-4007-0490-1/24/08
https://doi.org/10.1145/3637528.3671743Keywords
Point-of-Interest Recommendations; On-Device POI Recommenda-
tions; Diffusion Models
ACM Reference Format:
Jing Long, Guanhua Ye, Tong Chen, Yang Wang, Meng Wang, and Hongzhi
Yin*. 2024. Diffusion-Based Cloud-Edge-Device Collaborative Learning
for Next POI Recommendations. In Proceedings of the 30th ACM SIGKDD
Conference on Knowledge Discovery and Data Mining (KDD ’24), August
25–29, 2024, Barcelona, Spain. ACM, New York, NY, USA, 11 pages. https:
//doi.org/10.1145/3637528.3671743
1 Introduction
The emergence of Location-Based Social Networks (LBSNs), such as
Foursquare and Weeplace, has improved the way we interact with
our surroundings. These platforms, accumulating vast amounts of
historical check-in data, have become fertile ground for developing
Point-of-Interest (POI) recommendation systems. Given the power-
ful computational capabilities of servers, centralized deep neural
networks (DNNs) based on graph embedding [ 18,41,48] and atten-
tion mechanisms [ 20,26] demonstrate impressive performance in
POI recommendations. Unfortunately, due to increasing concerns
regarding privacy and the location-sensitive nature of POI recom-
mendations, users are becoming increasingly cautious and even
reluctant to upload their check-in data, thereby impacting the rec-
ommendation quality [ 25,52]. Apart from this, recommendations in
centralized services are computed upon request and then transmit-
ted to user devices, making the service timeliness highly dependent
on network quality [ 24]. Thus, on-device POI recommendations
have emerged, aimed at mitigating the limitations of centralized
paradigms [ 50]. That is, each user locally hosts a lightweight rec-
ommendation model that generates personalized recommendations
without sharing sensitive data, which also warrants responsiveness.
Being a widely recognized approach under this paradigm, feder-
ated learning (FL) based POI recommendations (e.g., [ 10]) centrally
collect and aggregate locally trained models, as well as redistribut-
ing the aggregated model to all users. However, all users sharing
the same model may hurt the minority groups and impair the rec-
ommendation quality of these users. To achieve a higher degree
of personalization, instead of aggregating all user models, some
federated POI recommenders [ 13,33,36,43] group similar users
 
2026
KDD ’24, August 25–29, 2024, Barcelona, Spain Jing Long et al.
and perform aggregation within groups. Further remedy is pro-
posed in decentralized POI recommenders [ 23,24], where users can
directly engage in collaborative learning with their neighbors in a
device-to-device manner, allowing more personalization of learned
on-device models. Unfortunately, the aforementioned federated and
decentralized frameworks suffer from two major limitations. On the
one hand, they require full device engagement during training or
updating, whether in collaboration with the cloud or other devices,
which heavily burdens on-device computational resources. On the
other hand, they face challenges in transferability, as they must
learn patterns for new users and regions from the ground up.
To this end, we propose a fast-adapting on-device POI recommen-
dation framework, namely Diffusion-Based Cloud-Edge-Device Col-
laborative Learning for Next POI Recommendations (DCPR). DCPR
adopts the diffusion model as its primary building block, which
has drawn significant attention due to its substantial success in
various fields like computer vision (CV), natural language process-
ing (NLP), sequential recommendations, and others [ 1,17,32,45].
Leveraging its advantages in distributed generation and diverse
representations, we believe the diffusion model is highly suitable
to bridge the above gap. More intuitively, the proposed framework
consists of three layers, including cloud server, edge server, and
device. Initially, a centrally hosted global diffusion model is trained
to learn category-level movement patterns. Since the training data
(i.e., category sequences) does not involve sensitive geographical
locations, it is easily collected in LBSNs.
Subsequently, the well-trained global model is sent to all region-
specific edge servers, and endowed with the ability to capture
region-specific preferences. This is achieved by each region-specific
edge server modifying the global model with POI sequences in this
region. The training data for each region comes from published de-
identified check-in sequences. Finally, each edge server distributes
the region-specific model to all users within this region, which is
further fine-tuned locally by personal data. To avoid impairing the
inherent generation capabilities of the region-specific model, an
additional patch model is inserted and updated with personal data
to reflect the user’s personal preferences. An acceleration is further
adopted to speed up the inference process, which is a significant
drawback of the standard diffusion model. With the cloud-edge-
device architecture, DCPR significantly reduces the burden of the
on-device computational resource, having capabilities to provide
POI recommendations effectively and efficiently. Meanwhile, such
progressively personalized architecture is highly transferable as it
can rapidly adapt to new regions and new users. In a nutshell, we
summarize our contributions as follows:
•To the best of our knowledge, we are the first to bridge
the gap between the diffusion model and on-device POI
recommendations and propose a fast-adapting on-device
POI recommendation framework, namely DCPR, aimed at
providing personalized POI recommendations efficiently.
•DCPR consists of three layers including cloud server, edge
server, and device, where the latter is progressively built
on the former, and thus, it can fit new regions and users
quickly. To speed up the on-device inference process, we fur-
ther design an acceleration strategy, significantly reducing
inference time.•We evaluate DCPR with two real-world datasets, and demon-
strate its effectiveness. The experimental results highlight
superior accuracy, efficiency, and transferability.
2 Preliminaries
In this section, we list key notations used throughout this paper,
outline our primary task, and introduce the standard diffusion
model.
2.1 Notations
We denote the sets of users 𝑢, POIs𝑝and categories 𝑐asU,P,C,
respectively. Each POI 𝑝∈P is associated with a category tag (e.g.,
entertainment or restaurant) 𝑐𝑝∈Cand coordinates(𝑙𝑜𝑛𝑝,𝑙𝑎𝑡𝑝).
Definition 1: Check-in Sequence. A check-in activity of a
user indicates a user 𝑢∈ U has visited POI 𝑝∈ P at times-
tamp𝑡. By sorting a user’s check-ins chronologically, a check-in
sequence contains 𝑀𝑢consecutive POIs visited by a user 𝑢, denoted
byX(𝑢)={𝑝1,𝑝2,...,𝑝𝑀𝑢}. Each personal check-in sequence X(𝑢)
is stored on the corresponding personal device.
Definition 2: Category Sequence. A category sequence substi-
tutes all POIs in the check-in sequence X(𝑢)with their associated
category tags, indicated as X𝑐(𝑢)={𝑐1,𝑐2,...,𝑐𝑀𝑢}.
Definition 3: Global POI Category Sequence Dataset. The
global semantic dataset D𝑔={X𝑐𝑧}𝑍
𝑧=1consists of𝑍anonymized
categorical sequences. The global POI category sequence dataset is
stored on the cloud server.
Definition 4: Region. A region 𝑟refers to a geographic seg-
ment providing additional context about the POIs it encompasses.
We do not assume specific region division methods, although we
adopt𝑘-means clustering [ 27] to derive a set of regions Rfollowing
[23]. Other predefined functional regions, such as city districts or
suburbs, can also work in our proposed framework.
Definition 5: Region-Specific Dataset. The region-specific
datasetD𝑟={X𝑣}𝑉𝑟
𝑣=1for a region 𝑟includes𝑉𝑟anonymized check-
in sequences. Each region possesses its unique dataset, encompass-
ing check-in activities exclusively within region 𝑟. Each region-
specific datasetD𝑟is stored on a region-based edge server.
2.2 Task: On-Device Next POI Recommendation
With the cloud-edge-device architecture, DCPR owns a cloud server
and multiple edge servers where each region is assigned an edge
server. Then, the functions of cloud server, edge server, and user
device are as follows:
•Cloud Server. The cloud server initially develops a global
diffusion network Θ𝑔with the global dataset D𝑔. Subse-
quently, Θ𝑔is sent to all region-specific edge servers.
•Edge Server. After receiving the global network Θ𝑔, each
region-specific edge server modifies it with the region’s
check-in sequences D𝑟. The edge server then distributes
the customized region-specific model Θ𝑟to all users within
the region.
•User Device. Each user𝑢receive the region-specific model
Θ𝑟and further refine it to create a personalized model Θ𝑢
with personal data X𝑢.
 
2027Diffusion-Based Cloud-Edge-Device Collaborative Learning for Next POI Recommendations KDD ’24, August 25–29, 2024, Barcelona, Spain
Global Data
Personal DataSent to each region-
specific edge server
and initialize
trainable parameters
Region-
Specifc Data
Patch Model
Distributed to each user in the region
and initialize the patch modelCloud Server
User DeviceModel Parameters Category Embeddings POI Embeddings
Edge Server
Figure 1: The overview of our proposed DCPR.
Under this construction, we aim to develop a performant local
model for each user, capable of providing a ranked list of potential
POIs for the next visit.
2.3 Standard Diffusion Model
Before introducing our model, we briefly describe the standard dif-
fusion model as the preliminary knowledge. The Diffusion Phase
progressively transforms the initial representation 𝑥0into pure
Gaussian noise via a Markov Chain (𝑥0→𝑥1→𝑥2→...→
𝑥𝑡−1→𝑥𝑡→...→𝑥𝑇−1→𝑥𝑇), where𝑇denotes the maximum
diffusion step. More specifically, the relationship between 𝑥𝑡and
𝑥𝑡−1is formulated as:
𝑥𝑡=√︁
1−𝛽𝑡𝑥𝑡−1+𝛽𝑡𝜖, (1)
where𝜖∼N( 0,𝐼)which is a standard normal distribution, and 𝛽𝑡
controls noise level at the diffusion step 𝑡. Recall that the diffusion
process aims to make 𝑥0converge towards a standard normal distri-
bution,𝛽𝑡increases with the growth of 𝑡. Normally, the value of 𝛽𝑡
is generated from a pre-defined noise schedule, while common noise
schedules include square-root schedule [ 17], cosine schedule [ 11],
and linear schedule [ 29]. In this paper, we adopt the square-root
schedule, and 𝛽𝑡is defined as:
𝛽𝑡=√︁
𝑡/𝑇+𝑤, (2)
where𝑤is a small constant corresponding to the starting noise
level. Inspired by [ 11],𝑥𝑡can also be derived directly from the
original target category embedding 𝑥0, where the relationship is
defined as:
𝑥𝑡=√︁
𝛼𝑡𝑥0+√︁
1−𝛼𝑡𝜖, (3)where𝜖∼N( 0,𝐼)and
√︁
𝛼𝑡=𝑡Ö
𝑠=1𝛼𝑠, (4)
where𝛼𝑠=1−𝛽𝑠. In this way, a vast amount of training samples
are obtained to train a network Θ, having the capability to estimate
the original presentation 𝑥0given its noised version 𝑥𝑡.
TheReverse Phase denoises the pure Gaussian noise 𝑥𝑇to
approximate the initial representation 𝑥0in an iterative manner
(𝑥𝑇→𝑥𝑇−1→...→𝑥𝑡→𝑥𝑡−1→...→𝑥1→𝑥0), which
is precisely opposite to the diffusion process. Formally, 𝑥𝑡−1is
obtained from 𝑥𝑡by:
𝑥𝑡−1=√𝛼𝑡(1−𝛼𝑡−1)𝑥𝑡+√𝛼𝑡−1(1−𝛼𝑡)ˆ𝑥0+(1−𝛼𝑡)(1−𝛼𝑡−1)𝜖
1−𝛼𝑡,
(5)
where ˆ𝑥0=Θ(𝑥𝑡), and𝜖∼N( 0,𝐼).
3 Methodology
In this section, we formally introduce the design of DCPR, with an
overview provided in Figure 1. The framework consists of three
stages: (1) Development of a Global Diffusion Model: This
stage involves creating a model adept at encapsulating category-
level inclinations on the cloud server. (2) Training of Region-
Specific Models: The global model is tailored to each region by
incorporating check-in sequences pertinent to that region on the
region-specific edge server, thereby creating models attuned to
regional dynamics. (3) Local Finetuning for Personalization: In
the final stage, the region-specific models undergo local refinement
 
2028KDD ’24, August 25–29, 2024, Barcelona, Spain Jing Long et al.
to generate personalized models. This ensures highly accurate and
tailored on-device POI recommendations for individual users.
Selecting the diffusion model as the backbone in our proposed
framework for on-device POI recommendations is driven by two
key considerations. Firstly, the diffusion model’s architecture excels
at managing complex data [ 11], an essential feature for POI rec-
ommendations that demand a thorough grasp of the nuanced and
dynamic aspects of POI sequences. This alignment greatly enhances
the model’s generalization capabilities across different scenarios,
leading to precise recommendations. Secondly, the diffusion model’s
strengths in distributed generation and its capability to effectively
capture a wide range of representations make it uniquely suited
to swiftly and accurately adapt to new regions and user profiles,
benefiting its transferability.
3.1 Global Diffusion Model
The proposed framework begins with the training of a global diffu-
sion model on the cloud server, aimed at learning the patterns of
category-level movements.
3.1.1 Diffusion Phase. Formally, the global diffusion model is de-
signed to construct the next category embedding e𝑐
𝑀+1from Pure
Gaussian noise 𝑥𝑇, where𝑥𝑇∼N( 0,𝐼), conditional on the histori-
cal category sequence X𝑐={𝑐1,𝑐2,...,𝑐𝑀}. Here, the next category
embedding e𝑐
𝑀+1is also known as the initial target representation
𝑥0. Following the standard diffusion algorithm, we progressively
add noise into the target category embedding 𝑥0through the dif-
fusion phase, and represent the noise-altered target category at
step𝑡as𝑥𝑡. This process is leveraged to generate samples for train-
ing a network Θ𝑔, which takes as input the noised target category
representation 𝑥𝑡and the category sequence X𝑐. The output is the
estimated target category representation ˆ𝑥0, aiming to approximate
the true target category embedding 𝑥0. The comprehensive design
of the network Θ𝑔will be introduced in the following section. Since
the task of the proposed DCPR is to offer on-device POI recommen-
dations, the global network Θ𝑔serves merely as a semi-finished
model and does not engage in the reverse phase (inference) solely.
We will describe the personal inference process later.
3.1.2 Attention-based Network. As previously mentioned, the core
objective of the network is to reconstruct the target category em-
bedding𝑥0given its noised representation 𝑥𝑡and the historical
category sequence X𝑐, denoted as:
ˆ𝑥0=Θ𝑔(𝑥𝑡,X𝑐), (6)
where ˆ𝑥0denotes the estimated representation of 𝑥0. Here, we
employ an attention-based neural network as the core mechanism
for the proposed network. This approach has been proven effective
in centralized POI recommendation frameworks [ 26,40], capturing
connections between consecutive check-in activities. Specifically,
we use𝑋𝑐=[e𝑐1,e𝑐2,...,e𝑐𝑀]∈R𝑀×𝑑to denote the embedding
of the category sequence. Then, we combine the noised target
representation with each category embedding e𝑐𝑚∈𝑋𝑐:
𝑧𝑐𝑚=e𝑐𝑚+𝜆(𝑥𝑡+e𝑡), (7)where e𝑡represents the embedding of the corresponding diffu-
sion/reverse step created by following [ 35], and𝜆is a hyperpa-
rameter, indicating the level of noise incorporation. Then, the self-
attention mechanism is adopted to enhance the revised sequence
embedding𝑍𝑐=[𝑧𝑐1,𝑧𝑐2,...,𝑧𝑐𝑀]∈R𝑀×𝑑. Given three parameters
𝑊𝑄,𝑊𝐾,𝑊𝑉∈R𝑑×𝑑, the final embedded sequence 𝐸∈R𝑀×𝑑is
defined as follows:
𝐸=𝑆𝑜𝑓𝑡𝑚𝑎𝑥(𝑄𝐾𝑇
√
𝑑)·𝑉, (8)
where𝑄=𝑍𝑐𝑊𝑄,𝐾=𝑍𝑐𝑊𝐾,𝑉=𝑍𝑐𝑊𝑉. To this end, the estimated
representation is defined as:
ˆ𝑥0=𝑆𝑢𝑚(𝐸𝑇), (9)
where𝑆𝑢𝑚(·)is the sum of the last dimension. Then, we utilize the
cross-entropy loss for model optimization:
L𝐶𝐸(ˆ𝑥0,𝑥0)=−©­
«𝑙𝑜𝑔𝜎(ˆ𝑥𝑇
0·𝑥0)−1
|𝑌−|∑︁
𝑒𝑛∈𝑌−𝑙𝑜𝑔𝜎(ˆ𝑥𝑇
0·e𝑛)ª®
¬,
(10)
where the symbol·denotes the inner product, 𝑌−consists of mul-
tiple negative embeddings for each positive sample where e𝑛≠𝑥0,
and𝜎(·)is the sigmoid function.
3.2 Region-Specific Models
As of now, we have developed a proficiently trained global network
Θ𝑔. This model is set to undergo further modifications to cater to
POI recommendations. A tailored model is established for each
region on the corresponding edge server, driven by two key factors.
Firstly, region-specific attributes, such as POI-level details and pre-
cise geographical data, are potentially redundant or even disruptive
when applied outside their respective regions. Secondly, consider-
ing that the region-specific model is intended for deployment on
user devices, the storage of embeddings for all POIs, rather than
just those within a specific region, poses an unnecessary load on
the device’s resources.
For each region 𝑟, after receiving the pre-trained global network
Θ𝑔, the edge server freezes its parameters and injects trainable
parameters, mainly containing the yet-to-be-trained embeddings
of all POIs within the region 𝑟. We use Θ𝑟to indicate the combined
network and Θ′
𝑟to denote the trainable parameters. Given that each
POI is linked to a specific category and representative category em-
beddings are already established, we initialize each POI embedding
with its corresponding category embedding. This strategy infuses
category-level insights and contributes to a more efficient training
process. The novel structure ensures that the frozen parameters
maintain the integrity and performance of the global model, which
has been trained on a vast dataset. Simultaneously, the trainable
parameters leverage this robust foundation to adapt flexibly to the
unique characteristics and requirements of different regions.
The network Θ𝑟, similar to the global model, undergoes training
via a diffusion process. Specifically, given a POI sequence X=
{𝑝1,𝑝2,...,𝑝𝑀}and the target POI 𝑝𝑀+1, the diffusion algorithm
add noise to the target POI embedding e𝑀+1, also denoted as 𝑥0,
referring to the original representation. This process results in the
creation of a noised POI representation 𝑥𝑡, where𝑡denotes the
specific step in the diffusion process. In this way, valuable samples
 
2029Diffusion-Based Cloud-Edge-Device Collaborative Learning for Next POI Recommendations KDD ’24, August 25–29, 2024, Barcelona, Spain
can be obtained to train the region-specific network Θ𝑟, which
takes the noised target POI representation 𝑥𝑡and the POI sequence
X. The output is the estimated target POI representation ˆ𝑥0, aiming
to approximate the true target POI embedding 𝑥0.
The approach utilized by the region-specific network Θ𝑟exhibits
a nuanced divergence from the global network Θ𝑔, as detailed in
3.1.2. This variation stems from adaptations in both the underlying
task requirements and the architectural design of the network. A
pivotal element in this modified approach is the integration of
both category and POI embeddings for each POI in the check-in
sequence, rather than relying exclusively on category embeddings.
This integration is operationalized by revising Equation 7 as follows:
𝑧𝑚=𝑒𝑝𝑚+𝛾𝑒𝑐𝑚+𝜆(𝑥𝑡+𝑑𝑡). (11)
Similar to𝜆,𝛾serves as a hyperparameter, modulating the influence
of category embeddings. This alteration ensures a more compre-
hensive representation by amalgamating the distinct yet comple-
mentary information from both category and POI embeddings.
An additional modification is to introduce the spatiotemporal
correlations of the check-in sequence in its final embedding 𝐸ob-
tained by Equation 8. Capturing spatiotemporal correlations in POI
sequences is essential for delivering personalized and contextu-
ally relevant POI recommendations, enabling systems to accurately
predict user preferences based on the intricate patterns of their
movements and timings. Specifically, we encode the spatiotemporal
gaps between two check-ins 𝑝𝑎and𝑝𝑏viaeΔ
𝑎𝑏∈R𝑑:
eΔ
𝑎𝑏=Δ𝑠
𝑎𝑏×eΔ𝑠+Δ𝑡
𝑎𝑏×eΔ𝑡 (12)
where eΔ𝑠andeΔ𝑡are two unit embeddings to represent a specific
amount of spatial (e.g., one kilometer) or time (e.g., one hour) differ-
ence,Δ𝑠
𝑎𝑏andΔ𝑡
𝑎𝑏are the true spatiotemporal differences of 𝑝𝑎and
𝑝𝑏(e.g., 10 kilometers and 5 hours). On this basis, the embedding
of the trajectory spatiotemporal relation matrix is Δ∈R𝑀×𝑀:
Δ=𝑒Δ′
11𝑒Δ′
12... 𝑒Δ′
1𝑀
𝑒Δ′
21𝑒Δ′
22... 𝑒Δ′
2𝑀
... ... ... ...
𝑒Δ′
𝑀1𝑒Δ′
𝑀2... 𝑒Δ′
𝑀𝑀(13)
where𝑒Δ′
𝑎𝑏is the element-wise sum of eΔ
𝑎𝑏. To this end, we com-
bine the embedded sequence and spatiotemporal differences by
modifying Equation 8:
𝐸=𝑆𝑜𝑓𝑡𝑚𝑎𝑥(𝑄𝐾𝑇+Δ√
𝑑)·𝑉. (14)
Recall that partial parameters of Θ𝑟are frozen, its updates are
defined as:
Θ′
𝑟=Θ′
𝑟−𝜇𝜕L𝐶𝐸(Θ𝑟(𝑥𝑡,X),𝑥0)
𝜕Θ′
𝑟, (15)
where𝜇denotes the learning rate. Please note that we do not per-
form the reverse phase (inference) on the edge server and Θ𝑟is
directly distributed to all users within this region.
3.3 Local Finetuning and Inference
Although the region-specific model can provide POI recommenda-
tions for all users within this region, a limitation arises from the
model’s bias toward active users within the same region, which
can compromise overall performance. To mitigate this, there isan initiative to fine-tune the region-specific model locally using
personal data. The most straightforward method would involve
updating the entire network with local data. Nevertheless, consid-
ering the vast number of parameters in the region-specific model,
adapting the entire network is not a feasible option. An alternative
approach proposes fine-tuning only a subset of parameters. This
method, however, has its limitations, as it leads to a performance
bottleneck due to the problematic interplay between stable and
variable vectors, which disrupts the original feature representation.
Hence, inspired by [ 47], we adopt patch-learning for on-device fine-
tuning. This involves integrating an additional patch model into the
region-specific network. This patch model undergoes modifications
during the local diffusion phase, enabling it to effectively capture
user-specific preferences.
Formally, for each user 𝑢, we introduce a Multi-Layer Perceptron
Θ𝑢, aimed to modify the reconstructed ˆ𝑥0presentation returned by
Θ𝑟:
ˆ𝑥0←Θ𝑢(Θ𝑟(𝑥𝑡,X)). (16)
Then, we repeat the region-specific diffusion phase locally with
personal data to train the user-specific MLP while freezing all pa-
rameters of Θ𝑟:
Θ𝑢=Θ𝑢−𝜇𝜕L𝐶𝐸(ˆ𝑥0,𝑥0)
𝜕Θ𝑢, (17)
where𝜇denotes the learning rate. Note that the design of MLP can
be adapted to the capacity of the user device. In this work, the MLP
with 3hidden layers, all having 𝑑units, is utilized. To this end, we
have described the whole design of DCPR and its optimization is
summarized in Algorithm 1.
With the region-specific model Θ𝑟and personal patch model
Θ𝑢, the reverse algorithm, as detailed in Section 2.3, is capable
of producing a ranked list of POIs for the next movement of the
user𝑢. Intuitively, the reverse phase begins with sampling the
fully noised target item 𝑥𝑇from a standard Gaussian distribution
N(0,𝐼). The denoising process then proceeds iteratively, where
𝑥𝑡−1is obtained from 𝑥𝑡under the guidance of ˆ𝑥0which is returned
byΘ𝑢(Θ𝑟(𝑥𝑡,X𝑐)). Once the final target POI representation 𝑥0
is reached, we map it into the discrete POI index space for final
recommendations. To accomplish this, we first compute the score
of each of𝐻candidate POIs by:
𝛼(𝑝ℎ)=𝑥𝑇
0·𝑒𝑝ℎ. (18)
Then, we rank all scores in descending for final recommendations.
A primary limitation of the standard diffusion model lies in its
sluggish generation speed, attributed to the iterative processing
required in the reverse phase from 𝑥𝑇to𝑥0to produce the final rep-
resentation. This issue is further exacerbated when this processing
is executed on-device, due to the restricted computational resources
available. To address this challenge, we adopt and adapt the novel
sampling technique introduced by [ 34]. This technique significantly
reduces the number of sampling steps, thereby markedly improv-
ing the efficiency of the generation process. Specifically, instead of
performing the reverse process on all steps from 𝑥𝑇to𝑥0, we only
perform it on{𝑥T𝑆,𝑥T𝑆−1,...,𝑥T1,𝑥T0}, where[T𝑆,T𝑆−1,...,T1,T0]is
an arithmetic and decreasing sub-sequence of [𝑇,𝑇−1,...,1,0]. On
this basis, the relationship between 𝑥T𝑠and𝑥T𝑠−1is changed, which
 
2030KDD ’24, August 25–29, 2024, Barcelona, Spain Jing Long et al.
Algorithm 1 Cloud-Edge-Device Collaborative Training of DCPR.
/*Global model - on the cloud server*/
1:Initialize Θ𝑔;
2:for(𝑐𝑀+1,X𝑐)∈D𝑔do
3:repeat
4:𝑥0←e𝑐𝑀+1;
5:𝑡∼𝑈(0,𝑇);
6:𝑥𝑡←√𝛼𝑡𝑥0+√1−𝛼𝑡𝜖,𝜖∼N( 0,𝐼);
7: ˆ𝑥0←Θ𝑔(𝑥𝑡,X𝑐);
8: Θ𝑔←Θ𝑔−𝜇𝜕L𝐶𝐸(ˆ𝑥0,𝑥0)
𝜕Θ𝑔;
9:until convergence
10:end for
/*Region-specific model - on the edge server*/
11:for𝑟∈Rdo{in parallel} ⊲Each region has an edge server
12: Receive Θ𝑔and initialize Θ′
𝑟;
13: Obtain Θ𝑟by combining Θ𝑔andΘ′
𝑟;
14: for(𝑝𝑀+1,X)∈D𝑟do
15: repeat
16:𝑥0←e𝑝𝑀+1;
17:𝑡∼𝑈(0,𝑇);
18:𝑥𝑡←√𝛼𝑡𝑥0+√1−𝛼𝑡𝜖,𝜖∼N( 0,𝐼);
19: ˆ𝑥0←Θ𝑟(𝑥𝑡,X);
20: Θ′
𝑟=Θ′
𝑟−𝜇𝜕L𝐶𝐸(ˆ𝑥0,𝑥0)
𝜕Θ′
𝑟;
21: until convergence
22: end for
23:end for
/*Personal model - on the user side*/
24:for𝑢∈Udo{in parallel}
25: Receive Θ𝑟and initialize Θ𝑢;
26: for(𝑝𝑀+1,X)∈X𝑢do
27: repeat
28:𝑥0←e𝑝𝑀+1;
29:𝑡∼𝑈(0,𝑇);
30:𝑥𝑡←√𝛼𝑡𝑥0+√1−𝛼𝑡𝜖,𝜖∼N( 0,𝐼);
31: ˆ𝑥0←Θ𝑢(Θ𝑟(𝑥𝑡,X));
32: Θ𝑢←Θ𝑢−𝜇𝜕L𝐶𝐸(ˆ𝑥0,𝑥0)
𝜕Θ𝑢;
33: until convergence
34: end for
35:end for
is defined as:
𝑥T𝑠−1=√︃
𝛼T𝑠−1(𝑥T𝑠−√1−𝛼𝑡ˆ𝑥0√
𝛼T𝑠)+√︃
1−𝛼T𝑠−1ˆ𝑥0. (19)
To this end, the reverse step 𝑇𝑅can be set to any positive integer
which is less than the maximum diffusion step 𝑇.
4 Experiments
In this section, we perform comprehensive experiments with two
real-world datasets to evaluate the effectiveness and efficiency of
the proposed DCPR. The comparative analysis includes two cate-
gories of baselines: centralized POI recommendation systems and
on-device POI recommenders. Specifically, our investigation seeks
to address the following research questions:RQ1: How does the DCPR perform compared with state-of-the-art
POI recommendation methods?
RQ2: How efficient (i.e., model size and time complexity) is the pro-
posed DCPR compared with other on-device POI recommenders?
RQ3: Is the proposed DCPR efficiently transferable to new regions
and new users?
RQ4: What is the impact of DCPR’s key hyperparameters?
Table 1: Dataset statistics.
Foursquare Weeplace
#users 7,507 4,560
#POIs 80,962 44,194
#categories 436 625
#check-ins 1,214,631 923,600
#check-ins per user 161.80 202.54
4.1 Datasets and Evaluation Protocols
We adopt two real-world datasets to evaluate our proposed DCPR,
namely Foursquare [ 6] and Weeplace [ 22]. Both datasets include
users’ check-in histories in the cities of New York, Los Angeles,
and Chicago. Additionally, in this work, each city is divided into
5regions by applying k-means clustering which is discussed in
Section 2. Following [ 2,16], users and POIs with less than 10 in-
teractions are removed. Table 1 summarizes the statistics of the
two datasets. For each dataset, we derive all category sequences
from check-in activities and regard those category sequences as
the global training data D𝑔. Then, 50%of the POI sequences within
each region 𝑟acts as the corresponding region-specific training
dataD𝑟, while the rest is employed for the training, testing and
validation of on-device models.
For evaluation, we adopt the leave-one-out protocol which is
widely used in previous works [ 38,39,53]. That is, for each of the
on-device check-in sequences, the last check-in POI is for testing,
the second last POI is for validation, and all others are for train-
ing. It is worth noting that, for each category sequence in D𝑔, we
remove the last two check-in activities for rigorous experiments.
In addition, the maximum sequence length is set to 200. For each
ground truth, instead of ranking all e-commerce products [ 15], we
only pair it with 200 unvisited and nearest POIs within the same
region of the sequence as the candidates for ranking. The rationale
is, different from e-commerce products [ 15,31], in the scenario
of POI recommendations that are location-sensitive, users seldom
travel between two POIs consecutively that are far away from each
other [18, 24, 51].
On this basis, we leverage two ranking metrics, namely Hit Ratio
at Rank𝑘(HR@𝑘) and Normalized Discounted Cumulative Gain
at Rank𝑘(NDCG@𝑘) [42] where HR@ 𝑘only measures the times
that the ground truth is present on the top- 𝑘list, while NDCG@ 𝑘
cares whether the ground truth can be ranked as highly as possible.
For hyperparameters, we set the maximum diffusion step 𝑇to
1024, the reverse inference step 𝑇𝑅to16,𝛾to0.7,𝜆to0.003, the
learning rate 𝜇to0.002, the dimension size to 64, the dropout to 0.2,
the batch size to 16, and the maximum training epoch is set to 200.
 
2031Diffusion-Based Cloud-Edge-Device Collaborative Learning for Next POI Recommendations KDD ’24, August 25–29, 2024, Barcelona, Spain
Table 2: Recommendation performance comparison with baselines.
Foursquare Weeplace
HR@5 NDCG@5 HR@10 NDCG@10 HR@5 NDCG@5 HR@10 NDCG@10
MF 0.0847 0.0607 0.0965 0.0661 0.1042 0.0599 0.1316 0.0889
LSTM 0.1939 0.1195 0.2782 0.1668 0.2156 0.1322 0.3251 0.1549
STAN 0.2987 0.1776 0.4327 0.2598 0.3141 0.1819 0.4663 0.2876
DRAN 0.3114 0.1802 0.4345 0.2655 0.3165 0.1843 0.4775 0.2974
Diff-POI 0.3228 0.1840 0.4585 0.2838 0.3281 0.1921 0.4933 0.2994
LLRec 0.2648 0.1447 0.3549 0.1884 0.3008 0.1839 0.3751 0.2329
DCCL 0.2679 0.1486 0.3723 0.1969 0.3118 0.1868 0.3925 0.2353
PREFER 0.2858 0.1746 0.3723 0.2251 0.3009 0.1783 0.3914 0.2367
DCLR 0.3136 0.1887 0.4406 0.2740 0.3124 0.1857 0.4357 0.2797
MAC 0.3030 0.1826 0.4520 0.2780 0.3187 0.1974 0.4852 0.2829
DCPR 0.3272 0.1922 0.4623 0.2913 0.3337 0.1978 0.5082 0.3063
4.2 Baselines
We compare DCPR with both the centralized and on-device POI
recommenders:
Centralized POI Recommenders:
•MF[21]: It is a classic centralized POI recommendation sys-
tem based on user-item matrix factorization.
•LSTM [12]: This recurrent neural network can capture short-
term and long-term dependencies in sequential data.
•STAN [26]: It learns explicit spatiotemporal correlations of
check-in trajectories via a bi-attention approach.
•DRAN [40]: It is a GNN-based method that leverages a dis-
entangled representation-enhanced attention network for
next POI recommendation
•Diff-POI [30]: It is a diffusion-based model that samples
from the posterior distribution that reflects the user’s geo-
graphical preference.
On-Device POI Recommenders:
•LLRec [37]: It utilizes the teacher-student training strategy
to obtain the compressed model that can be deployed locally.
•DCCL [47]: It compresses and deployes a well-trained model
on-device, which is further finetuned locally with personal
data.
•PREFER [10]: This federated POI recommendation par-
adigm allows the server to collect and aggregate locally
trained models, as well as redistribute the federated model.
•DCLR [24]: This decentralized collaborative learning frame-
work allows locally trained models to share knowledge be-
tween homogeneous neighbors by model aggregation.
•MAC [23]: It is designed to collaboratively train local mod-
els with heterogeneous neighbors by comparing their soft
decisions on a public reference dataset.
4.3 Recommendation Effectiveness (RQ1)
The performance comparison among all the POI recommenders is
summarized in Table 2, where we observe the following findings.
LSTM outshines MF on both datasets, owing to its adept handling
of sequential check-in activities’ short-term and long-term depen-
dencies. Furthermore, STAN, which leverages spatiotemporal cor-
relations in check-in activities with the attention mechanism, bothconsecutive and non-consecutive, surpasses LSTM in accuracy. Ad-
vancing further, DRAN melds a Graph Neural Network (GNN) with
an attention mechanism, leading to more refined POI embeddings
and thus outperforming STAN in terms of accuracy.
Most notably, Diff-POI, employing the robust generality of the
diffusion model, sets a new benchmark for state-of-the-art accuracy
in this domain. While these centralized models show prowess, our
method remains highly competitive. The centralized models, trained
across multiple cities, often grapple with the noise in knowledge
transfer between cities, which can detract from their performance.
In contrast, our approach excels in personalization in regions and
personals to learn more expressive models, thereby offering tailored
and efficient recommendations.
In the meantime, DCPR outperforms all on-device POI recom-
menders on both datasets in terms of all metrics. It begins by point-
ing out the shortcomings of LLRec, which ranks lowest in terms
of performance. This is primarily due to its training process that
omits all personal data, leading to a disregard for individual user
preferences. In contrast, DCCL attempts to enhance its model by
incorporating personal data. However, it still does not reach the
pinnacle of accuracy, primarily due to its suboptimal model design.
The analysis then shifts focus to collaborative learning frameworks
such as PREFER, DCLR, and MAC, acknowledging their notable
improvements in accuracy. The proposed DCPR stands out for more
accurate recommendations. Furthermore, it surpasses other models
in recommendation efficiency, demonstrated through its compact
on-device model size and reduced computational time complexity.
These aspects, along with their implications, are set to be elaborated
and explored in greater detail in the subsequent section.
4.4 Recommendation Efficiency (RQ2)
To assess the recommendation efficiency of the proposed DCPR,
concerning all on-device POI recommenders, we record recommen-
dation accuracy (HR@10 on Weeplace), on-device model size (in
megabytes), on-device training time (in seconds), and on-device
inference time (in milliseconds), for the latent dimensions 𝑑∈
{8,16,32,64,128,256,512}. Please note personal models in LLRec
are not trained or updated locally, leading to the lack of on-device
training time. The summarized results are shown in Figure 2.
 
2032KDD ’24, August 25–29, 2024, Barcelona, Spain Jing Long et al.
8 16 32 64 128 256 512
d0.200.250.300.350.400.450.50HR@10LLRec
DCCL
PREFER
DCLR
MAC
DCPR
8 16 32 64 128 256 512
d01020304050607080Model Size (mb)LLRec
DCCL
PREFER
DCLR
MAC
DCPR
8 16 32 64 128 256 512
d05001000150020002500300035004000Training Time (s)DCCL
PREFER
DCLR
MAC
DCPR
8 16 32 64 128 256 512
d0102030405060Inference Time (ms)LLRec
DCCL
PREFER
DCLR
MAC
DCPR
Figure 2: Recommendation Efficiency.
8 16 32 64 128 256 512 1024
TR0100200300400500Inference Time (ms)Foursquare
Weepalce
8 16 32 64 128 256 512 1024
TR0.450.460.470.480.490.500.51HR@10
Foursquare
Weepalce
Figure 3: Effectiveness of Acceleration Strategy.
4.4.1 On-Device Memory Efficiency. Here, it is noticeable that the
average model sizes of both MAC and DCPR are significantly
smaller compared to other on-device recommendation systems.
This efficiency is attributed to their design, which allows the user
device to store only those POI embeddings that are pertinent.
4.4.2 On-Device Time Efficiency. DCPR’s efficiency is further high-
lighted by its minimal reliance on the computational capabilities
of local devices, proved by the least on-device training time of
DCPR. Regarding inference time, DCPR effectively overcomes the
constraints of the standard reverse algorithm, resulting in similar
inference time compared with other on-device models. To further
prove the effectiveness of the acceleration strategy, we fix the di-
mension size to 64, and record the recommendation accuracy and
inference time for various 𝑇𝑅∈{8,16,32,64,128,256,512,1024},
where𝑇𝑅=1024 means no acceleration is employed. The results
are shown in Figure 3, where we can observe that the acceler-
ation mechanism significantly reduces the inference time while
maintaining the recommendation accuracy. More specifically, as 𝑇𝑅
increases, there is a generally upward trend in both inference time
and accuracy. However, the accuracy converges when 𝑇𝑅exceeds
16. Meanwhile, the inference time keeps rising with more reverse
steps. Thus, 𝑇𝑅is set to 16, offering high accuracy without exces-
sively prolonging inference time. To conclude, considering the factTable 3: Recommendation Transferability.
Foursquare Weeplace
Time (s) HR@10 Time (s) HR@10
DCPR 4143 0.4487 2824 0.4916
DCPR-T 5708 0.4252 4685 0.4709
that DCPR surpasses all other on-device frameworks in recommen-
dation accuracy, it is a more effective and efficient solution in the
landscape of on-device POI recommenders.
4.5 Recommendation Transferability (RQ3)
As indicated in Section 4.4.2, the on-device training time for DCPR
is significantly shorter compared to other on-device POI recommen-
dation frameworks, while still maintaining high recommendation
accuracy. More importantly, the training and updating process for
individual user models within DCPR does not interfere with other
user models, region-specific models, or the global model, under-
scoring DCPR’s effective adaptability to new users.
To evaluate DCPR’s transferability to new regions, we record the
averaged training time (in seconds) of all region-specific models,
and recommendation accuracy (HR@10 on Weeplace) after directly
applying each of them to personal check-in sequences in the region
without local fine-tuning. For comparison, we introduced DCPR-T, a
variant where each region-specific model is retrained from scratch,
not leveraging the well-trained global model. Similar to DCPR, we
record the averaged training time and recommendation accuracy of
DCPR-T. The results, shown in Table 3, reveal that DCPR, with the
support of the global model, achieves faster convergence and supe-
rior recommendation accuracy compared to DCPR-T. Furthermore,
the training of region-specific models does not impact each other or
the global model, affirming DCPR’s capacity for efficient adaption
to new regions. In summary, DCPR’s unique cloud-edge-device ar-
chitecture enables efficient transferability to new users and regions,
a feature that distinguishes it from other POI recommendation
systems.
4.6 Hyperparameter Sensitivity (RQ4)
In this section, we first illustrate the effect of three hyperparameters
on the recommendation accuracy of DCPR including 𝛾that controls
the injection level of category embedding to POI embedding in
Equation 11, 𝜆that controls the noise level added to POI embedding
in Equation 11, and the averaged check-in numbers 𝑁𝐶on the
region. The results are shown in Figure 4.
Impact of𝛾.We experiment on 𝛾∈{0,0.1,0.3,0.5,0.7,0.9,1}.
The lowest accuracy is obtained if all region-specific model is
trained solely without well-trained category embeddings in the
global model ( 𝛾=0), showing the significance of the cloud-edge-
device architecture. Therefore, the recommendation accuracy in-
creases with the increase of 𝛾. However, the accuracy will decline
if knowledge from the frozen category embedding in the global
model has an excessive proportion ( 𝛾>0.7).
Impact of 𝜆.Recommendation accuracy is recorded for 𝜆∈
{0,0.001,0.003,0.005,0.007,0.009,0.01}. The best performance is
observed when 𝜆=0.003for both datasets, highlighting a delicate
 
2033Diffusion-Based Cloud-Edge-Device Collaborative Learning for Next POI Recommendations KDD ’24, August 25–29, 2024, Barcelona, Spain
00.1 0.3 0.5 0.7 0.9 1
0.440.450.460.470.480.490.500.51HR@10
Foursquare
Weepalce
00.001 0.003 0.005 0.007 0.009 0.01
0.440.460.480.50
Foursquare
Weepalce
100 500 1000 1500 2000 2500
NC0.250.300.350.400.450.50
Foursquare
Weepalce
Figure 4: Hyperparameter Sensitivity.
balance. Excessive noise compromises POI embeddings, while in-
sufficient noise fails to introduce the necessary diversity into POI
recommendations.
Impact of𝑁𝐶.𝑁𝐶is evaluated in{100,500,1000,1500,2000,2500}.
Usually, the recommendation accuracy benefits from higher check-
in numbers. In this study, accuracy stabilizes once 𝑁𝐶exceeds
1000, indicating that the proposed DCPR is capable of delivering
high-performance recommendations without requiring an exten-
sive volume of check-ins.
5 Related Work
This section reviews recent literature on related areas including
centralized models for POI recommendation, on-device frameworks
for POI recommendation, and diffusion models.
5.1 Next POI Recommendation
To help people discover attractive places by analyzing user-POI in-
teractions, early works mainly focused on matrix factorization [ 21]
and Markov chains [ 7,53]. The introduction of recurrent neural
network (RNN) models marked a significant advancement, show-
casing their ability to understand the spatiotemporal dynamics in
POI sequences [ 4,5,14,18,49]. Additionally, models employing
attentive neural networks [ 3,26,46,49] have adopted self-attention
mechanisms to meticulously analyze the spatiotemporal context of
sequential check-in behaviors. Then, graph neural networks (GNN)
based models [ 8,9,18,40] took a step further by integrating graph-
augmented POI sequences, which capitalized on collaborative sig-
nals from semantically similar POIs and unveiled sequential trends,
thereby outperforming RNN-based approaches in terms of accuracy.
Then, Diff-POI [ 30], by leveraging the powerful generality of the
diffusion model, establishes a new standard for cutting-edge accu-
racy in the field. These approaches, however, predominantly rely on
cloud-based infrastructure, which brings the need for substantial
cloud computing capabilities. In contrast, DCPR introduces a fast-
adapting on-device POI recommendation framework, emphasizing,
recommendation accuracy, efficiency, and model transferability.
5.2 On-Device POI Recommendation
On-device frameworks effectively address many limitations of cloud-
based learning in POI recommendations. Federated learning [ 10],
a key approach in this context, aggregates locally trained models
and shares a unified model with users. However, this can result
in the long-tail problem, where less active users get subpar rec-
ommendations. Some federated POI recommenders [ 33,43] tackle
this by grouping users with similar interests, and decentralizedsystems [ 23,24] allow nearby devices to collaborate, enhancing
personalization. Despite this, these methods demand extensive de-
vice engagement and intra-device communication, raising concerns
about privacy and Transferability. An alternative approach [37] is
using pre-trained, compressed models on devices with anonymized
data for privacy, but this compromises accuracy due to the lack of
personalized data and limited model adaptability. Some systems
[28,44] try to fine-tune with local data, yet they underperform com-
pared to centralized systems. Although this method can quickly
adapt to new users, it compromises recommendation quality and
struggles to adjust to new regions. Our work introduces a diffusion
model-based system, deploying a well-trained model to users for
local fine-tuning and achieving high-quality recommendations.
5.3 Diffusion Models
Diffusion models have revolutionized generative tasks across fields
like computer vision (CV), natural language processing (NLP), and
others [ 1,17,32,45], with Denoising Diffusion Probabilistic Mod-
els (DDPMs) [ 11] excelling in creating high-quality images. To
improve efficiency, Denoising Diffusion Implicit Models (DDIMs)
[34] reduce sampling steps with minimal impact on diversity. De-
spite their ability to generate diverse images, controlling the output
remains a challenge. Addressing this, text-conditional diffusion
models [ 1,32] have emerged, using text encoders to guide image
generation by integrating textual and image representations dur-
ing the diffusion process. These works [ 17,19,30] also extend the
diffusion model to sequence-to-sequence tasks, including NLP and
sequential recommendations, by training networks to reconstruct
targets from noised inputs. Yet, their application in on-device POI
recommendation systems is novel. This study pioneers the use of
diffusion models for on-device POI recommendations, harnessing
their generative capabilities to deliver transferable, accurate, and
efficient recommendations, marking a significant advancement in
personalized and location-based services.
6 Conclusion
In conclusion, this work has successfully developed and evaluated
the Diffusion-Based Cloud-Edge-Device Collaborative Learning
(DCPR) framework, a pioneering approach to on-device POI rec-
ommendations. By integrating the diffusion model’s strengths in
generating diverse and distributed representations, DCPR effec-
tively addresses the limitations of existing centralized and collab-
orative learning systems, particularly in terms of computational
efficiency, and the capacity for personalization. Furthermore, the
novel cloud-edge-device architecture ensures DCPR’s transferabil-
ity to new regions and users. Experimental results with two real-
world datasets have validated DCPR’s effectiveness, showcasing its
potential to significantly enhance the quality and accessibility of
POI recommendations.
Acknowledgments
This work is supported by Australian Research Council under the
streams of Future Fellowship (Grant No. FT210100624), Discovery
Early Career Researcher Award (Grants No. DE230101033), Discov-
ery Project (Grants No.DP240101108 and No.DP240101814).
 
2034KDD ’24, August 25–29, 2024, Barcelona, Spain Jing Long et al.
References
[1]Omri Avrahami, Dani Lischinski, and Ohad Fried. 2022. Blended diffusion for
text-driven editing of natural images. In Proceedings of the IEEE/CVF Conference
on Computer Vision and Pattern Recognition. 18208–18218.
[2]B. Chang, Y. Park, D. Park, S. Kim, and J. Kang. 2018. Content-Aware Hierarchical
Point-of-Interest Embedding Model for Successive POI Recommendation. In
Twenty-Seventh International Joint Conference on Artificial Intelligence IJCAI-18.
[3]Tong Chen, Hongzhi Yin, Hongxu Chen, Rui Yan, Quoc Viet Hung Nguyen, and
Xue Li. 2019. Air: Attentional intention-aware recommender systems. In 2019
IEEE 35th International Conference on Data Engineering (ICDE). IEEE, 304–315.
[4]Tong Chen, Hongzhi Yin, Quoc Viet Hung Nguyen, Wen-Chih Peng, Xue Li, and
Xiaofang Zhou. 2020. Sequence-aware factorization machines for temporal pre-
dictive analytics. In 2020 IEEE 36th International Conference on Data Engineering
(ICDE). IEEE, 1405–1416.
[5]Tong Chen, Hongzhi Yin, Guanhua Ye, Zi Huang, Yang Wang, and Meng Wang.
2020. Try this instead: Personalized and interpretable substitute recommendation.
InProceedings of the 43rd international ACM SIGIR conference on research and
development in information retrieval. 891–900.
[6]Z. Chen, H. Cao, H. Wang, F. Xu, and Y. Li. 2020. Will You Come Back / Check-in
Again? Understanding Characteristics Leading to Urban Revisitation and Re-
check-in. Proceedings of the ACM on Interactive Mobile Wearable and Ubiquitous
Technologies (2020).
[7]C. Cheng, H. Yang, M. R. Lyu, and I. King. 2013. Where You Like to Go Next:
Successive Point-of-Interest Recommendation.. In International Joint Conference
on Artificial Intelligence.
[8]Xinyi Gao, Tong Chen, Yilong Zang, Wentao Zhang, Quoc Viet Hung Nguyen,
Kai Zheng, and Hongzhi Yin. 2023. Graph condensation for inductive node
representation learning. arXiv preprint arXiv:2307.15967 (2023).
[9]Xinyi Gao, Wentao Zhang, Tong Chen, Junliang Yu, Hung Quoc Viet Nguyen, and
Hongzhi Yin. 2023. Semantic-aware node synthesis for imbalanced heterogeneous
information networks. In Proceedings of the 32nd ACM International Conference
on Information and Knowledge Management. 545–555.
[10] Y. Guo, F. Liu, Z. Cai, H. Zeng, and N. Xiao. 2021. PREFER: Point-of-interest
REcommendation with efficiency and privacy-preservation via Federated Edge
leaRning. Proceedings of the ACM on Interactive Mobile Wearable and Ubiquitous
Technologies 5, 1 (2021), 1–25.
[11] Jonathan Ho, Ajay Jain, and Pieter Abbeel. 2020. Denoising diffusion probabilistic
models. Advances in neural information processing systems 33 (2020), 6840–6851.
[12] S. Hochreiter and J. Schmidhuber. 1997. Long Short-Term Memory. Neural
Computation 9, 8 (1997), 1735–1780.
[13] Mubashir Imran, Hongzhi Yin, Tong Chen, Quoc Viet Hung Nguyen, Alexander
Zhou, and Kai Zheng. 2023. ReFRS: Resource-efficient federated recommender
system for dynamic and diversified user preferences. ACM Transactions on
Information Systems 41, 3 (2023), 1–30.
[14] F. Jie, L. Yong, Z. Chao, F. Sun, and D. Jin. 2018. DeepMove: Predicting Human
Mobility with Attentional Recurrent Networks. In the 2018 World Wide Web
Conference.
[15] W. Krichene and S. Rendle. 2020. On Sampled Metrics for Item Recommendation.
InKDD ’20: The 26th ACM SIGKDD Conference on Knowledge Discovery and Data
Mining.
[16] Ranzhen Li, Yanyan Shen, and Yanmin Zhu. 2018. Next Point-of-Interest Rec-
ommendation with Temporal and Multi-level Context Attention. 2018 IEEE
International Conference on Data Mining (ICDM) (2018), 1110–1115.
[17] Xiang Li, John Thickstun, Ishaan Gulrajani, Percy S Liang, and Tatsunori B
Hashimoto. 2022. Diffusion-lm improves controllable text generation. Advances
in Neural Information Processing Systems 35 (2022), 4328–4343.
[18] Yang Li, Tong Chen, Yadan Luo, Hongzhi Yin, and Zi Huang. 2021. Discovering
collaborative signals for next POI recommendation with iterative Seq2Graph
augmentation. In IJCAI. 1491–1497.
[19] Zihao Li, Aixin Sun, and Chenliang Li. 2023. DiffuRec: A Diffusion Model for
Sequential Recommendation. arXiv preprint arXiv:2304.00686 (2023).
[20] D. Lian, Y. Wu, Y. Ge, X. Xie, and E. Chen. 2020. Geography-Aware Sequential
Location Recommendation. In KDD ’20: The 26th ACM SIGKDD Conference on
Knowledge Discovery and Data Mining.
[21] D. Lian, C. Zhao, X. Xie, G. Sun, E. Chen, and Y. Rui. 2014. GeoMF: joint geo-
graphical modeling and matrix factorization for point-of-interest recommendation.
ACM.
[22] X. Liu, Y. Liu, K. Aberer, and C. Miao. 2013. Personalized point-of-interest
recommendation by mining users’ preference transition. In Acm International
Conference on Conference on Information & Knowledge Management.
[23] Jing Long, Tong Chen, Quoc Viet Hung Nguyen, Guandong Xu, Kai Zheng, and
Hongzhi Yin. 2023. Model-Agnostic Decentralized Collaborative Learning for
On-Device POI Recommendation. In Proceedings of the 46th International ACM
SIGIR Conference on Research and Development in Information Retrieval. 423–432.
[24] Jing Long, Tong Chen, Quoc Viet Hung Nguyen, and Hongzhi Yin. 2023. Decen-
tralized collaborative learning framework for next POI recommendation. ACM
Transactions on Information Systems 41, 3 (2023), 1–25.[25] Jing Long, Tong Chen, Guanhua Ye, Kai Zheng, Nguyen Quoc Viet Hung, and
Hongzhi Yin. 2024. Physical Trajectory Inference Attack and Defense in Decen-
tralized POI Recommendation. arXiv preprint arXiv:2401.14583 (2024).
[26] Y. Luo, Q. Liu, and Z. Liu. 2021. STAN: Spatio-Temporal Attention Network for
Next Location Recommendation.
[27] J. Macqueen. 1967. Some methods for classification and analysis of multivariate
observations. Proc. Symp. Math. Statist. and Probability, 5th 1 (1967).
[28] Nattaya Mairittha, Tittaya Mairittha, and Sozo Inoue. 2020. Improving activity
data collection with on-device personalization using fine-tuning. In Adjunct
Proceedings of the 2020 ACM International Joint Conference on Pervasive and
Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium
on Wearable Computers. 255–260.
[29] Alexander Quinn Nichol and Prafulla Dhariwal. 2021. Improved denoising diffu-
sion probabilistic models. In International Conference on Machine Learning. PMLR,
8162–8171.
[30] Yifang Qin, Hongjun Wu, Wei Ju, Xiao Luo, and Ming Zhang. 2023. A Diffusion
Model for POI Recommendation. ACM Transactions on Information Systems 42, 2
(Nov. 2023), 1–27. https://doi.org/10.1145/3624475
[31] Liang Qu, Huaisheng Zhu, Ruiqi Zheng, Yuhui Shi, and Hongzhi Yin. 2021. Im-
gagn: Imbalanced network embedding via generative adversarial graph networks.
InProceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &
Data Mining. 1390–1398.
[32] Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen.
2022. Hierarchical text-conditional image generation with clip latents, 2022. URL
https://arxiv. org/abs/2204.06125 7 (2022).
[33] J. Rao, S. Gao, M. Li, and Q. Huang. 2021. A privacy-preserving framework for
location recommendation using decentralized collaborative machine learning.
Transactions in GIS (2021).
[34] Jiaming Song, Chenlin Meng, and Stefano Ermon. 2020. Denoising diffusion
implicit models. arXiv preprint arXiv:2010.02502 (2020).
[35] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all
you need. Advances in neural information processing systems 30 (2017).
[36] Hao Wang, Yanmei Fu, Qinyong Wang, Hongzhi Yin, Changying Du, and Hui
Xiong. 2017. A location-sentiment-aware recommender system for both home-
town and out-of-town users. In Proceedings of the 23rd ACM SIGKDD international
conference on knowledge discovery and data mining. 1135–1143.
[37] Q. Wang, H. Yin, T. Chen, Z. Huang, and Nqv Hung. 2020. Next Point-of-Interest
Recommendation on Resource-Constrained Mobile Devices. In WWW ’20: The
Web Conference 2020.
[38] Q. Wang, H. Yin, Z. Hu, D. Lian, H. Wang, and Z. Huang. 2018. Neural Memory
Streaming Recommender Networks with Adversarial Training. (2018), 2467–
2475.
[39] Q. Wang, H. Yin, H. Wang, Qvh Nguyen, and L. Cui. 2019. Enhancing Col-
laborative Filtering with Generative Augmentation. In the 25th ACM SIGKDD
International Conference.
[40] Zhaobo Wang, Yanmin Zhu, Haobing Liu, and Chunyang Wang. 2022. Learning
Graph-based Disentangled Representations for Next POI Recommendation. In
Proceedings of the 45th International ACM SIGIR Conference on Research and
Development in Information Retrieval (, Madrid, Spain,) (SIGIR ’22). Association
for Computing Machinery, New York, NY, USA, 1154–1163. https://doi.org/10.
1145/3477495.3532012
[41] Zhaobo Wang, Yanmin Zhu, Qiaomei Zhang, Haobing Liu, Chunyang Wang,
and Tong Liu. 2021. Graph-enhanced Spatial-temporal Network for Next POI
Recommendation. ACM Transactions on Knowledge Discovery from Data (TKDD)
(2021).
[42] M. Weimer, A. Karatzoglou, Q. V. Le, and A. J. Smola. 2007. CoFiRank - Maximum
Margin Matrix Factorization for Collaborative Ranking. In Neural Information
Processing Systems.
[43] A Xw, A Mn, A Jc, B Lc, and C Kl. 2020. A group preference-based privacy-
preserving POI recommender system. ICT Express 6, 3 (2020), 204–208.
[44] Yikai Yan, Chaoyue Niu, Renjie Gu, Fan Wu, Shaojie Tang, Lifeng Hua, Chengfei
Lyu, and Guihai Chen. 2022. On-Device Learning for Model Personalization
with Large-Scale Cloud-Coordinated Domain Adaption. In Proceedings of the 28th
ACM SIGKDD Conference on Knowledge Discovery and Data Mining. 2180–2190.
[45] Ling Yang, Zhilong Zhang, Yang Song, Shenda Hong, Runsheng Xu, Yue Zhao,
Wentao Zhang, Bin Cui, and Ming-Hsuan Yang. 2023. Diffusion models: A
comprehensive survey of methods and applications. Comput. Surveys 56, 4 (2023),
1–39.
[46] Song Yang, Jiamou Liu, and Kaiqi Zhao. 2022. GETNext: Trajectory Flow Map
Enhanced Transformer for Next POI Recommendation. In Proceedings of the 45th
International ACM SIGIR Conference on Research and Development in Information
Retrieval (Madrid, Spain) (SIGIR ’22). Association for Computing Machinery, New
York, NY, USA, 1144–1153. https://doi.org/10.1145/3477495.3531983
[47] Jiangchao Yao, Feng Wang, Kunyang Jia, Bo Han, Jingren Zhou, and Hongxia
Yang. 2021. Device-Cloud Collaborative Learning for Recommendation (KDD
’21). Association for Computing Machinery, New York, NY, USA, 3865–3874.
https://doi.org/10.1145/3447548.3467097
 
2035Diffusion-Based Cloud-Edge-Device Collaborative Learning for Next POI Recommendations KDD ’24, August 25–29, 2024, Barcelona, Spain
[48] Hongzhi Yin and Bin Cui. 2016. Spatio-temporal recommendation in social media.
Springer.
[49] Hongzhi Yin, Bin Cui, Zi Huang, Weiqing Wang, Xian Wu, and Xiaofang Zhou.
2015. Joint modeling of users’ interests and mobility patterns for point-of-interest
recommendation. In Proceedings of the 23rd ACM international conference on
Multimedia. 819–822.
[50] Hongzhi Yin, Liang Qu, Tong Chen, Wei Yuan, Ruiqi Zheng, Jing Long, Xin
Xia, Yuhui Shi, and Chengqi Zhang. 2024. On-Device Recommender Systems: A
Comprehensive Survey. arXiv preprint arXiv:2401.11441 (2024).
[51] Wei Yuan, Hongzhi Yin, Fangzhao Wu, Shijie Zhang, Tieke He, and Hao Wang.
2023. Federated unlearning for on-device recommendation. In Proceedings of theSixteenth ACM International Conference on Web Search and Data Mining. 393–401.
[52] Shijie Zhang, Hongzhi Yin, Tong Chen, Zi Huang, Quoc Viet Hung Nguyen,
and Lizhen Cui. 2022. Pipattack: Poisoning federated recommender systems for
manipulating item promotion. In Proceedings of the Fifteenth ACM International
Conference on Web Search and Data Mining. 1415–1423.
[53] Bolong Zheng, Kai Zheng, Xiaokui Xiao, Han Su, Hongzhi Yin, Xiaofang Zhou,
and Guohui Li. 2016. Keyword-aware continuous knn query on road networks.
In2016 IEEE 32Nd international conference on data engineering (ICDE). IEEE,
871–882.
 
2036