Optimizing Long-tailed Link Prediction in Graph Neural
Networks through Structure Representation Enhancement
Yakun Wang
Ant Group
Beijing, China
feika.wyk@antgroup.comDaixin Wang
Ant Group
Beijing, China
daixin.wdx@antgroup.comHongrui Liu
Ant Group
Beijing, China
liuhongrui.lhr@antgroup.com
Binbin Hu∗
Ant Group
Hangzhou, China
bin.hbb@antfin.comYingcui Yan
Ant Group
Shanghai, China
yanyingcui.yyc@antgroup.comQiyang Zhang
Ant Group
Shanghai, China
buxie.zqy@antgroup.com
Zhiqiang Zhang
Ant Group
Hangzhou, China
lingyao.zzq@antfin.com
ABSTRACT
Link prediction, as a fundamental task for graph neural networks
(GNNs), has boasted significant progress in varied domains. Its
success is typically influenced by the expressive power of node
representation, but recent developments reveal the inferior perfor-
mance of low-degree nodes owing to their sparse neighbor con-
nections, known as the degree-based long-tailed problem. Will the
degree-based long-tailed distribution similarly constrain the efficacy
of GNNs on link prediction? Unexpectedly, our study reveals that
only a mild correlation exists between node degree and predictive
accuracy, and more importantly, the number of common neighbors
between node pairs exhibits a strong correlation with accuracy.
Considering node pairs with less common neighbors, i.e.,tail node
pairs, make up a substantial fraction of the dataset but achieve
worse performance, we propose that link prediction also faces the
long-tailed problem. Therefore, link prediction of GNNs is greatly
hindered by the tail node pairs. After knowing the weakness of
link prediction, a natural question is how can we eliminate the
negative effects of the skewed long-tailed distribution on common
neighbors so as to improve the performance of link prediction? To-
wards this end, we introduce our long-tailed framework (LTLP),
which is designed to enhance the performance of tail node pairs on
link prediction by increasing common neighbors. Two key modules
in LTLP respectively supplement high-quality edges for tail node
pairs and enforce representational alignment between head and
tail node pairs within the same category, thereby improving the
∗Corresponding author.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
KDD ’24, August 25–29, 2024, Barcelona, Spain
©2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 979-8-4007-0490-1/24/08
https://doi.org/10.1145/3637528.3671864performance of tail node pairs. Empirical results across five datasets
confirm that our approach not only achieves SOTA performance
but also greatly reduces the performance bias between the head and
tail. These findings underscore the efficacy and superiority of our
framework in addressing the long-tailed problem in link prediction.
CCS CONCEPTS
•Computing methodologies →Knowledge representation
and reasoning.
KEYWORDS
Link Prediction, Long-tailed, Structure Enhancement, Graph Neural
Networks
ACM Reference Format:
Yakun Wang, Daixin Wang, Hongrui Liu, Binbin Hu, Yingcui Yan, Qiyang
Zhang, and Zhiqiang Zhang. 2024. Optimizing Long-tailed Link Prediction
in Graph Neural Networks through Structure Representation Enhancement.
InProceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery
and Data Mining (KDD ’24), August 25–29, 2024, Barcelona, Spain. ACM, New
York, NY, USA, 11 pages. https://doi.org/10.1145/3637528.3671864
1 INTRODUCTION
Link prediction, as one of the cornerstone tasks within the realm of
graph neural networks (GNNs), has been deployed in various appli-
cations such as personalized recommendation [ 8,10,38,41], drug
molecule design [ 12,31], and supply chain optimization [ 36]. Re-
cently, several works [ 8,17,29,32,38] have achieved impressive per-
formance on link prediction, which can be approximately divided
into two distinct approaches: node-centric and edge-centric. Node-
centric methods, such as GCN-based [ 9,15,39] and GraphSAGE-
based [ 7], focus on learning representations from individual nodes
in node pairs, with the intuition that nodes with similar features
or residing in similar network neighborhoods are more likely to
form connections. Conversely, edge-centric approaches, as illus-
trated in works like [ 4,18,26,40,42,46], adeptly capitalize on
the intricate structural information inherent within subgraphs (i.e.
3222
KDD ’24, August 25–29, 2024, Barcelona, Spain Yakun Wang et al.
common neighbors, paths, and closed triangles), thereby garnering
increased focus. Synthesizing insights from both approaches, the
performance of link prediction is typically affected by the quality
of node representation and the structural information between the
node pair.
Despite the expressive power of these link prediction approaches,
recent studies reveal that the performance of GNNs is always com-
promised by the long-tailed distribution of node degree, where
low-degree nodes always exhibit inferior performance on classifi-
cation compared with high-degree (head) nodes [ 21,22,44]. Given
the importance of node representation for link prediction, the un-
derwhelming performance of tail node pairs inspires a fundamental
question: will the degree-based long-tailed distribution similarly con-
strain the efficacy of GNNs on link prediction? As the first contribu-
tion of this study, we present experiments to assess the relationship
between node degree and accuracy in Fig. 1 (a)&(c)&(e) (more de-
tails can be seen in Sec. 3.2). Surprisingly, we discover that the
degree, or more specifically the degree sum of node pairs, only
presents a weak or even negligible correlation with accuracy. This
unexpectedly mild correlation means that GNNs may not be as
heavily influenced by the limitations in node representation when
it comes to link prediction, and more importantly, it implies that
there may be other underlying factors having a more pronounced
impact on the link prediction capabilities of GNNs. This insight
paves the way for novel strategies to enhance GNN models for link
prediction.
Inspired by previous edge-centric methods, we propose that
some specific structural information between the concerned node
pairs could have an influence on the performance of link predic-
tion. Towards this end, we investigate the correlation between the
number of common neighbors, one of structural information that
is extensively leveraged on link prediction [ 1,2,40], and accuracy.
Our empirical analysis, as illustrated in Fig. 1 (b)&(d)&(f), unveils a
significant correlation between the number of common neighbors
and accuracy for both node-centric and edge-centric methods, and
more importantly, the number of common neighbors exhibits a
pronounced long-tailed distribution pattern. Therefore, link predic-
tion also faces a similar long-tailed problem in terms of common
neighbors, that node pairs with more common neighbors, i.e.,head
node pairs, achieve better results, while a majority of node pairs
with less common neighbors, i.e.,tail node pairs, achieve worse
results. As a result, the tail node pairs, which make up a substan-
tial fraction but have insufficient structural information, greatly
harm the overall performance of GNN on link prediction. So one
natural question arises: how can we eliminate the negative effects
of the skewed long-tailed distribution on common neighbors so as to
improve the performance of link prediction?
Inspired by the strong correlation between the number of com-
mon neighbors and link prediction accuracy, we propose to increase
the common neighbors of tail node pairs to improve their perfor-
mance. Intuitively, increasing common neighbors can be achieved
by integrating new edges into the existing edge set, but it remains
unknown how to effectively control the quality of these additional
edges in case of introducing negative samples. To address this prob-
lem, we propose our plug-in Long-Tailed Link Prediction (LTLP)
framework, which is flexible with most GNN-based link predictionbackbones. It consists of two primary modules: The Subgraph En-
hancement Module ( SEM) is engineered to generate high-quality re-
lationships, harnessing a mechanism wherein the prediction score,
in concert with its variance throughout the training epochs, is
jointly deployed to sift through and refine a pre-defined candidate
relationships. These additional relationships remarkably increase
the common neighbors of tail node pairs and simultaneously avoid
introducing negative node pairs. As a result, it can effectively im-
prove the performance of tail node pairs on link prediction. The
Representation Enhancement Module (REM) further complements
the SEM module to learn a more concentrated representation for
narrowing the representational disparity across all samples. It there-
fore reduces the performance gap between head node pairs and
tail node pairs. Extensive experiments across various datasets and
different backbones validate the effectiveness of LTLP, especially
on tail node pairs.
In summary, the contributions of our work are three-fold:
•We discover that link prediction faces the long-tailed problem
in terms of common neighbors rather than degrees like in node
classifications, where node pairs with more common neighbors
achieve better results. This discovery reveals the performance
bottleneck of link prediction lying in tail node pairs and inspires
a new path for further improving the existing link prediction
methods.
•Owing to the strong correlation between the number of common
neighbors and accuracy, we propose our plug-in long-tail link
prediction framework (LTLP) to increase the common neighbors
of tail node pairs for improving their performance, wherein the
SEM module and REM module collectively filter out high-quality
edges and achieve more concentrated representation.
•Extensive experiments validate that LTLP not only achieves su-
perior overall performance but also reduces the performance gap
between head node pairs and tail node pairs. The observations
therefore demonstrate LTLP effectively augments the structural
information by increasing common neighbors.
2 RELATED WORK
2.1 Link Prediction
Link prediction has been achieved significant success across vari-
ous domains [ 3]. Among them, heuristic approaches [ 1,2,13,45]
assess the likelihood of connections between nodes by the variant
of common neighbors and paths. Due to the expressive power of
Graph Neural Networks (GNNs), GNN-based approaches [ 8,23,25]
have achieved SOTA performance. These methods are generally
categorized into two categories: node-centric and edge-centric, de-
pending on their use of subgraph structural features. Node-centric
methods [ 7,33,34] represent nodes by gathering neighborhood
information and independently combining the representations of
node pairs. Despite their successes, these approaches often neglect
the structural information connecting the nodes. Conversely, edge-
centric methods emphasize strategies by modeling the structural
information within subgraphs. For instance, SEAL [ 42] leverages
node labeling to capture structural information, PaGNN [ 35] and
NBFNet [ 46] automatically learn subgraph features with broadcast
and aggregation operations. BUDDY [ 4] represents with subgraph
3223Optimizing Long-tailed Link Prediction in Graph Neural Networks through Structure Representation Enhancement KDD ’24, August 25–29, 2024, Barcelona, Spain
(a) Cora Degree Analysis
 (b) Cora CNs Analysis
(c) CiteSeer Degree Analysis
 (d) CiteSeer CNs Analysis
(e) Pubmed Degree Analysis
 (f) Pubmed CNs Analysis
Figure 1: The correlation between the link prediction accu-
racy and different measures, i.e. degrees and common neigh-
bors (CNs), by using GCN and SEAL.
sketching and Neo-GNNs are identified by modeling the informa-
tion of common neighbors. CFLP [ 43] investigates the impact of
structural information from a causal perspective and deals with
counterfactual samples. NCNC [ 29] introduces structural features
to guide MPNN’s representation pooling and boost model perfor-
mance by completing the common neighbor structure caused by
graph incompleteness. However, existing link prediction methods
treat all node pairs uniformly but ignore the inherent long-tailed
problem in link prediction, resulting in tail node pairs, making up a
substantial fraction but achieving much poorer performance than
head node pairs.
2.2 Long-Tailed Methods in GNNs
Given its ubiquity and innate challenges, the long-tailed problem
in GNNs has also attracted significant attention. Firstly, in node-
level long-tailed approaches, works like [ 21,22,44] build on the
observation that nodes with fewer degrees, i.e. tail nodes, perform
poorly, aiming to enhance the representation of tail nodes with the
help of head nodes. Taking Tail-GNN as an example, this approach
learns a transition matrix to bridge the gap between tail and head
nodes, thereby enriching the representational capacity of tail nodes.
Furthermore, SOLT-GNN [ 20] first states that the graph-level task
also faces the long-tailed problem in terms of the graph size. Thus
they employ knowledge transfer to narrow the representational gap
between head and tail graphs. In link prediction, some works [ 19,
27] focus on link prediction fairness but are limited to dividing nodepairs into groups based on a predefined attribute, like gender, and
aim to increase performance balance among groups. By contrast,
we focus on a general scenario to improve the overall performance
of link prediction by enhancing the structural information of tail
node pairs.
3 PRELIMINARY AND DATA ANALYSIS
In this section, we initially formalize the task of link prediction.
Next, we conduct comprehensive data analysis on three bench-
mark datasets, which illustrate the number of common neighbors
rather than the degree is much more correlated with link prediction
accuracy. Ultimately, we uncover the long-tailed problem in link
prediction, which has inspired the design of our framework.
3.1 Link Prediction Preliminary
LetG=(V,E)be an undirected graph, with the node set V=
{𝑣1,𝑣2,𝑣3,...,𝑣𝑁}and the edge setE={(𝑢,𝑣)|𝑢,𝑣∈V} . Then the
adjacency matrix A∈R𝑁×𝑁of graphGis binary for simplicity
where A𝑢𝑣=1if there is a connection between nodes 𝑢and𝑣, i.e.,
(𝑢,𝑣)∈E , otherwise, A𝑢𝑣=0.N𝑣={𝑢|(𝑢,𝑣)∈E} represents the
set of neighbors of node 𝑣, and the common neighbors between node
𝑢and node𝑣can be formalized as C𝑢,𝑣=N𝑢ÑN𝑣.𝑑𝑣=Í
𝑢A𝑢𝑣
is denoted as the node degree of node 𝑣. Further, we define the
node pair degree(𝑢,𝑣)as the sum of degree of individual nodes, i.e.,
𝑑𝑢,𝑣=𝑑𝑢+𝑑𝑣. Additionally, each node 𝑣∈V is associated with an
𝑓-dimension feature vector x𝑣∈R𝑓.
Graph Neural Networks (GNNs) learn node representation by
leveraging an iterative aggregation function to harness the infor-
mation from neighbors. The representation of node 𝑣at the𝑙-th
layer can be formalized as follows:
𝒉(𝑙)
𝑣=𝜎(𝒉(𝑙−1)
𝑣,𝜙({𝒉(𝑙−1)
𝑢|𝑢∈N𝑣})), (1)
where 𝒉0𝑣=x𝑣,𝜎(·)combines the representation of node 𝑣and its
neighborsN𝑣of the𝑙-th layer,𝜙(·)is the aggregation function for
effectively leveraging the information of neighbors.
For both node-centric and edge-centric approaches, GNN-based
link prediction aims to learn a function F(𝑢,𝑣|G)to estimate the
probability of whether a link exists between the node pair (𝑢,𝑣).
Formally, the prediction function F(·) can be expressed as:
F(𝑢,𝑣|G)=f(𝒛(𝐿)
𝑢,𝑣),
𝒛(𝐿)
𝑢,𝑣=Ψ(𝒉(𝐿)
𝑣,𝒉(𝐿)
𝑢),(2)
where the function f:R𝑚→R, which is commonly realized by the
inner product or a trainable multi-layer MLP, maps an 𝑚-dimension
output vector 𝒛(𝐿)
𝑢,𝑣to a scalar ranging from 0 to 1, representing the
predicted probability of an edge existing between the two nodes.
Here, 𝒛(𝐿)
𝑢,𝑣∈R𝑚represents an 𝑚-dimension hidden representation
of the sample(𝑢,𝑣), and is obtained by another function Ψ:R𝑚×
R𝑚→R, with the input 𝒉(𝐿)
𝑢and 𝒉(𝐿)
𝑣∈R𝑚being the output of
an𝐿-layer GNN. The objective of link prediction is to accurately
estimate the predicted probability by F, and therefore the objective
function is
min
𝜃∑︁
((𝑢,𝑣),𝑦𝑢,𝑣)∈O 𝑡𝑟𝑎𝑖𝑛L(F(𝑢,𝑣|G),𝑦𝑢,𝑣), (3)
3224KDD ’24, August 25–29, 2024, Barcelona, Spain Yakun Wang et al.
whereO𝑡𝑟𝑎𝑖𝑛 is the training set consisting of the node pair (𝑢,𝑣)
and its label 𝑦𝑢,𝑣, andL(·) is defined as the cross-entropy function
following previous link prediction works [ 42,43,46]. Without loss
of generality, we set the label 𝑦𝑢,𝑣=1if the edge(𝑢,𝑣)is in the
edge setE; otherwise𝑦𝑢,𝑣=0.
3.2 Data Analysis
As stated before, the long-tailed problem of node degree has made
the representations of tail nodes underrepresented, leading to un-
satisfactory performance in node classification. Therefore, we first
investigate whether such degree-biased distribution will constrain
the efficacy of GNNs on link prediction. To achieve this, we conduct
experiments on three benchmark datasets, i.e.,Cora [ 15], CiteSeer
[15], and Pubmed [ 15]. In each dataset, we use the training node
pairs to train two widely used link prediction models respectively of
node-centric and edge-centric approaches, namely GCN and SEAL.
Then we partition the test node pairs into ten uniform buckets
based on the ascending order of the node pair degree 𝑑𝑢,𝑣. Finally,
we report the averaged link prediction accuracy and the number
of samples of each bucket. Results on Cora, Citeseer, Pubmed are
respectively visualized in Fig. 1(a), (c), (e). We can observe that both
GCN and SEAL display few correlation between the link prediction
accuracy and the degree.
Then we continue to investigate the correlation between the
number of common neighbors, one of the structural information
that is extensively leveraged in link prediction, and the link pre-
diction accuracy. We once again divide the test node pairs into ten
buckets based on the number of their common neighbors. The link
prediction accuracy and number of samples on each bucket using
GCN and SEAL are reported in Fig. 1(b), (d), (f), respectively for
Cora, Citeseer, Pubmed. Surprisingly, we observe a strong correla-
tion between accuracy and the number of common neighbors on
three benchmark datasets for both GCN and SEAL models. The
more common neighbors they have, the higher the accuracy is.
Furthermore, we observe that the number of common neighbors
exhibits a long-tailed distribution that a large fraction of node pairs
have few common neighbors. Consequently, in light of this discov-
ery, link prediction also faces serious long-tailed problem regarding
the common neighbors, which means that the structural informa-
tion of tail node pairs is insufficient, thereby having a much worse
performance compared to head node pairs. How can we eliminate
the negative effects of the skewed long-tailed distribution on com-
mon neighbors so as to improve the performance of tail node pairs
is critically important.
4 MODEL FRAMEWORK
In this section, we introduce our proposed Long-Tailed Link Predic-
tion (LTLP) framework, which is designed to augment the structural
information of tail node pairs in an effort to improve their perfor-
mance on link prediction. It is achieved by increasing common
neighbors of node pairs within tail samples1. Specifically, as il-
lustrated in Fig. 2, the LTLP framework comprises two primary
1We refer to the following expression of tail node pairs as tail samples in short in link
prediction.modules: Structure Enhancement Module (SEM) and Representa-
tion Enhancement Module (REM). The SEM is designed to gener-
ate high-quality relationships, harnessing a mechanism wherein
the prediction score, in concert with its variance throughout the
training epochs, is jointly deployed to sift through and refine pre-
generated candidate relationships. These filtered additional rela-
tionships increase the common neighbors of the tail while avoiding
introducing noisy edges, thereby enhancing their representations.
To complement SEM, we propose REM to further narrow the rep-
resentational disparity between the head and tail samples, which
produces a more concentrated representation across all the samples
within the same class.
4.1 Structure Enhancement Module
In an effort to bolster the number of common neighbors among
tail samples, a straightforward strategy is to integrate new edge
relationshipsE𝑓into the existing edge set E. However, negative
node pairs are easily introduced. Towards this end, we design three
sub-modules, where the Candidate Set Generator module efficiently
generates a candidate edge set and the subsequent Score Filtering
module and Variance Filtering module collectively filter out the
high-quality edge relationships. Such relationships increase com-
mon neighbors and are believed to improve the performance of tail
samples on link prediction.
4.1.1 Candidate Set Generator. Considering a connected graph,
the candidate edge set for the tail sample (𝑢,𝑣)that helps for in-
creasing common neighbors can be constructed by pairing any
other nodes in the node set V. Therefore, for 𝑀tail samples, the
generation of the candidate edge set takes (𝑁×𝑀)time. In light
of the potentially overwhelming number of nodes within a graph,
such an exhaustive approach places a substantial demand on the
computational resources, which is infeasible and can greatly bur-
den the downstream stages. Inspired by the observations in Sec.
3.2, which highlights a notable correlation between the number
of common neighbors shared by a pair of nodes and the accuracy
of link prediction, we advocate for a more selective approach in
constructing the candidate edge set. Specifically, we propose that
the edge candidates should be restricted to those that can increase
common 1-order neighbors. Mathematically, for any link prediction
sample(𝑢,𝑣), the candidate edge set E𝑜is constructed as:
E𝑜=Ø
((𝑢,𝑣),𝑦𝑢,𝑣)∈O{(𝑢,𝑖)|𝑖∈N𝑣}∪{(𝑣,𝑗)|𝑗∈N𝑢}, (4)
whereOis the dataset consisting of the node pair (𝑢,𝑣)and its label
𝑦𝑢,𝑣. Clearly, this method significantly reduces the computational
overhead and enhances the efficiency of the subsequent filtering
operation performed by the SVF module. In Sec. 3.2, we experiment
to show that only considering the common 1-order neighbors still
exhibits a significant performance gain across various datasets.
4.1.2 Score Filtering Module. With the candidate edge set, judi-
cious selection becomes imperative; otherwise, negative samples
would be introduced to the edge set, thereby harming the perfor-
mance on link prediction. An effective approach to filter negative
samples would be simply incorporating the most confidently pre-
dicted candidate edges into the existing edge set E. Toward this, we
train a link prediction model F(𝑢,𝑣|G)in advance and then infer
3225Optimizing Long-tailed Link Prediction in Graph Neural Networks through Structure Representation Enhancement KDD ’24, August 25–29, 2024, Barcelona, Spain
Figure 2: Overview of our proposed LTLP framework.
the linking probability 𝑝𝑢,𝑣=F(𝑢,𝑣|G)of each candidate edge
(𝑢,𝑣)within the setE𝑜. Candidate edges that yield a predictive
probability satisfying 𝑝𝑢,𝑣≥𝜖are selected for adding the score
filtering edge setE𝑠, where𝜖is a pre-defined threshold. Here, the
threshold𝜖is always determined by the optimal AUC threshold of
the validated set.
Despite the wide deployment of the score-based filtering strategy,
we present experiments to show that it could lead to the unexpected
incorporation of many false positives, thereby introducing noisy
information into the graph. Specifically, we train a link prediction
model Neo-GNN on the Cora dataset [ 15] following [ 5,16,46],
where we randomly sample 85% of the data for training, 5% for
validation, and the rest 10% for test. Then we aim to investigate the
discriminative ability of positive samples with negative samples
of varying difficulty levels. The larger the difficulty level is, the
higher the probability the negative samples are incorrectly pre-
dicted byF(𝑢,𝑣|G). To achieve this, we create different sets of
negative samples, each corresponding to a distinct difficulty level.
For difficultly level 𝑆=𝑠, we generate a set 𝑁𝑒𝑔𝑠by pairing node 𝑢
belonging to each positive sample (𝑢,𝑣)with𝑠randomly chosen
candidate negative nodes 𝑗, simultaneously ensuring that 𝑗∉N𝑢.
From these candidates, we select the negative sample (𝑢,𝑗)that
yields the highest predictive score as per the model. We record the
trend of label error rate 𝑅𝑙𝑒𝑟=|{(𝑢,𝑗)∈𝑁𝑒𝑔 𝑠|𝑝𝑢,𝑗≥𝜖}|
|𝑁𝑒𝑔 𝑠|across training
epochs. Here, 𝑅𝑙𝑒𝑟represents the proportion of negative samples
that were incorrectly scored above the threshold 𝜖, suggesting they
are false positives. Clearly, from Fig. 3 (a) we can observe that for
negative samples of the highest difficulty level (green line), there
are approximately 80% samples are incorrectly predicted. Therefore,
if we were to indiscriminately accept all high-scoring predictions
above the threshold, it would inevitably lead to a significant influx
of noisy edges into the graph, thereby hindering the link prediction.
This trend sheds light on the limitations of the score filtering mod-
ule and informs the necessity and urgency of additional filtering
strategies for maintaining accuracy.
4.1.3 Variance Filtering Module. Inspired by previous works that
utilize the variance of score to identify incorrectly predicted sam-
ples [ 6,14], we hypothesize that incorporating the variance of score
across epochs can also effectively filter the false positives that are
incorrectly predicted by the score filtering module. Intuitively, the
variance reflects the stability of predictions during training, and
therefore, the negative samples with the highest difficulty level
are inclined to exhibit higher variance in their scores compared toother negative samples and the true positive samples. In order to
differentiate between positive and negative samples, we introduce
the concept of normalized variance, which is the variance of the
scores normalized by their mean value. This normalization means
that negative samples with lower scores will have a proportionally
higher normalized variance compared to positive samples, even if
the absolute variances are similar. Mathematically, for each can-
didate edge(𝑢,𝑣)during the𝑡-th epoch, the normalized variance
V𝑢,𝑣(𝑡)of the score across 5 training epochs is defined as follows:
V𝑢,𝑣(𝑡)=1
¯𝑝𝑢,𝑣(𝑡)vut
1
55∑︁
𝑖=1 𝑝𝑢,𝑣(𝑡−𝑖)−¯𝑝𝑢,𝑣(𝑡)2,
¯𝑝𝑢,𝑣(𝑡)=1
55∑︁
𝑖=1𝑝𝑢,𝑣(𝑡−𝑖),(5)
where𝑝𝑢,𝑣(𝑖)represents the predictive probability of F(𝑢,𝑣|G)in
the𝑖-th epoch. To validate the efficacy of our proposed normalized
variance for filtering false negatives, we replicate the experimental
setup laid out in Sec. 4.1.2, focusing on the separability between
positive samples and negative samples of different levels of difficulty.
We first visualized the trend of the median variance within each
set of negative samples as well as the set of positive samples across
epochs in Fig. 3 (b). We can clearly observe that the median variance
is consistently lower than that of negative samples, particularly for
those at the highest difficulty level. It indicates that the normalized
variance can indeed serve as a reliable indicator to separate true
positives from false negatives. Subsequently, we display the trend of
label error rate 𝑅𝑙𝑒𝑟for each set of negative samples after discarding
those with the 60% lowest variance. The results are visualized in
Fig. 3 (c). which depicts a significant improvement in the reduction
of false positives when the variance-based filtering criterion is
applied in conjunction with score-based filtering. Remarkably, for
the negative samples at the highest difficulty level (denoted by
the green line), we observe a substantial decrease in the number
of false positives, with a reduction rate approaching 30%. These
findings validate our hypothesis that incorporating a variance-
based filtering step can significantly filter the false negatives by
reducing label error rates, especially for those samples where the
model’s predictions are highly variable and less reliable.
In light of the effectiveness of the normalized variance in identi-
fying the false negatives, we propose to incorporate the variance
filtering module into the score filtering module. Both modules col-
lectively filter the true positive edges from the candidate set E𝑜
for increasing common neighbors. Specifically, with the filtered
3226KDD ’24, August 25–29, 2024, Barcelona, Spain Yakun Wang et al.
(a) Comparing of 𝑅𝑙𝑒𝑟
 (b) Comparing of Variance
 (c) Comparing of 𝑅𝑙𝑒𝑟after Varince filtering
Figure 3: Analysis of positive and negative samples on Cora dataset. 𝑆denote the difficult level, (V𝑢,𝑣|𝑣∈N𝑢)𝑚𝑑means the median
normalized variance of each epoch on set (𝑢,𝑣)|𝑣∈N𝑢),𝑅𝑙𝑒𝑟is the label error ratio.
candidate edge setE𝑓and the edge setEof the given graphG, we
expand the edge set Eas follows:
E𝑛𝑒𝑤=E∪E𝑓,
E𝑓={(𝑢,𝑣)∈E𝑠|V𝑢,𝑣≥𝜏𝑠𝑣𝑓},
E𝑠={(𝑢,𝑣)∈E𝑜|𝑝𝑢,𝑣≥𝜏},(6)
where𝑝𝑢,𝑣andV𝑢,𝑣are obtained by the predictive result of F(𝑢,𝑣|G)
in the final training epoch, the threshold 𝜏for score filtering module
is determined by the optimal AUC threshold on the validation set,
and the threshold 𝜏𝑠𝑣𝑓for variance filtering module is obtained to
ensure top𝑘% edges inE𝑠with the smallest variance are chosen.
4.2 Representation Enhancement Module
In light of the inferior performance of tail samples revealed in
Sec. 3.2, we additionally incorporate a representation enhancement
module into our model to further enhance the tail samples for link
prediction. This module is engineered to narrow the representa-
tional disparity between head samples and tail samples, thereby
producing a more concentrated representation across all the sam-
ples within the same class.
Technically, given the enhanced graph G𝑛𝑒𝑤=(V,E𝑛𝑒𝑤)with
the expanded edge E𝑛𝑒𝑤 by Eq. 6, for each training node pair
((𝑢,𝑣),𝑦𝑢,𝑣)∈O𝑡𝑟𝑎𝑖𝑛 , we first get its hidden representation 𝒛𝑢,𝑣
using a GNN-based link prediction model following Eq. 2. Note
that both node-centric and edge-centric methods link prediction
function can be used here for obtainin 𝑧𝑢,𝑣and our experiments
demonstrate that our proposed method is flexible and effective to
these backbones.
Building upon these representations, we then define a unique
class center 𝑐𝑢,𝑣in the𝑚-dimensional space for each class of sam-
ples—positive and negative. Specifically, this entails assigning a
shared centroid for all positive samples, while simultaneously al-
locating a common centroid for all negative samples. We aim to
narrow the representation disparity across all the samples within
the same class, thereby producing a more concentrated represen-
tation. To achieve this, we propose the following regularization of
representation enhancement loss Lreas:
Lre=∑︁
((𝑢,𝑣),𝑦𝑢,𝑣)∈O 𝑡𝑟𝑎𝑖𝑛||𝒛𝑢,𝑣−𝑐𝑢,𝑣||2
2, (7)
Following [ 30,42,43], we apply the cross-entropy loss as our task
loss for link prediction. Consequently, we optimize the following
objective function to learn a link prediction model:Algorithm 1 Training Pipeline of Our Framework
Input: GraphG=(V,E), Link Prediction Model: F(𝑢,𝑣|G)
Output: Model:F(𝑢,𝑣|G)
1:/** Model Pre-Training **/
2:Update model parameters using Eq. 3
3:Memorize parameters states of the model in the last five epoch
4:/** Candidate set Generating **/
5:Generate candidate edge set E𝑜by Eq. 4
6:Scoring pairs inE𝑜by pre-trained model and calculate variance
through the last five epoch models with Eq. 5
7:FilteringE𝑓←E 0by scores and variance defined in Eq. 6
8:Obtain enhancedG𝑛𝑒𝑤with(V,EÐE𝑓)
9:/** Model Continue-Training **/
10:forepoch<T do
11: Update model on enhanced G𝑛𝑒𝑤with Eq. 8.
12:end for
L=𝜑∗Lce+(1−𝜑)∗L re, (8)
where𝜑is the hyperparameter to control the ratio between the
task lossLce(·)and the regularization term Lre(·).
4.3 Complexity Analysis
As depicted in Alg. 1, the overall training pipeline of LTLP includes
two distinct training phases: the pre-training phase and the con-
tinued training phase, followed by a candidate edge set generator
stage. The time complexity of training one epoch for both the pre-
training Ω𝑝(V,E)and continued training Ω𝑐(V,E)phase aligns
with that of the baseline model Ω𝑏(V,E), and the time complexity
of this two distinct training phases in LTLP is about 2×Ω𝑏(V,E).
Additionally, during the candidate set generator stage, we retain
and utilize the models from the last five epochs for score infer-
ring. For small datasets wherein training the model takes multiple
epochs, the score inferring takes almost no time. For large dataset
wherein training only a few epochs leads to convergence, consid-
ering this stage does not involve back-propagation, the associated
time complexity can be nearly expressed as 5×Ω𝑏(V,E)/2. Con-
sequently, the total time complexity of our framework is at most
4.5×Ω𝑏(V,E)than the baseline, exhibiting a linear relationship.
3227Optimizing Long-tailed Link Prediction in Graph Neural Networks through Structure Representation Enhancement KDD ’24, August 25–29, 2024, Barcelona, Spain
Table 1: The statistics of the datasets.
Dataset Nodes Edges Avg. Degree Density
Cora 2,708 5,278 3.9 0.14%
CiteSeer 3,327 4,676 2.74 0.084%
Pubmed 18,717 44,327 4.5 0.025%
OGB-Collab 235,868 1,285,465 5.45 0.0046%
OGB-PPA 576,289 30,326,273 52.62 0.018%
5 EXPERIMENT
5.1 Experiment Setup
5.1.1 Datasets. We evaluate the effectiveness of our framework on
five benchmark datasets of varying sizes, including Cora, CiteSeer,
Pubmed [37], OGB-Collad, and OGB-PPA [11]. Detailed statistical
information about these datasets is provided in Table 1. Since no
official training and testing sets are given in Cora, CiteSeer, and
Pubmed, we follow [ 5,16,46] to randomly split 85% of the data as
the training set, 5% as the validation set, and 10% as the test set in
datasets. For the OGB dataset (i.e. OGB-Collab and OGB-PPA), we
follow the official data-splitting standards in [ 11] to get the training,
validation, and test data.
5.1.2 Evaluation Metrics. In our study, we adapt the widely used
metrics consistent with previous works [ 24,28,38,43] in link pre-
diction. For datasets such as Cora, CiteSeer, and Pubmed, we utilize
the Area Under the ROC Curve (AUC) as the evaluation criterion
which aligns with the standard practice in [ 26,30,42]. For the
OGB dataset, we employ the official Hits metric (i.e. OGB-Collab:
Hits@50, OGB-PPA: Hits@100) for evaluation.
Additionally, to verify the improvement on tail samples, we
introduce tailored metrics that quantify the performance for both
the head and tail samples, as well as gauge the disparity therein.
Firstly, we divide the test set O𝑡𝑒𝑠𝑡into two sample groups: the
head samplesOℎ
𝑡𝑒𝑠𝑡and tail samplesO𝑡
𝑡𝑒𝑠𝑡, where the head samples
Oℎ
𝑡𝑒𝑠𝑡are those samples with one or more common neighbors, while
the remaining is considered as tail samples O𝑡
𝑡𝑒𝑠𝑡. We then assess
the average accuracy on head samples as 𝐴𝑐𝑐ℎand tail samples
as𝐴𝑐𝑐𝑡as commonly used in related works [ 20,27], considering
the average score 𝐴𝑐𝑐𝑚𝑒𝑎𝑛=(𝐴𝑐𝑐ℎ+𝐴𝑐𝑐𝑡)/2as well as the bias
B=𝑉𝑎𝑟(𝐴𝑐𝑐ℎ,𝐴𝑐𝑐𝑡)as evaluation metrics.
5.1.3 Baselines. We benchmark our model (LTLP) against a range
of prevalent link prediction approaches as well as approaches specif-
ically tailored for long-tailed issues, listed as follows:
•Heuristic methods: We select Common Neighbours (CN) and
Adamic-Adar (AA) for comparison.
•Node-centric approaches: We adopt two well-recognized node-
centric approaches: GCN and GraphSAGE.
•Edge-centric approaches: SEAL and Neo-GNN are selected as
exemplars of edge-centric link prediction approaches, with a
strong track record of effectiveness in this domain.
•Long-Tailed learning: For a comprehensive comparison, we adopt
TailGNN, a typical method in tail-node learning, for link pre-
diction by concatenating node representations that have been
rectified by TailGNN.Note that all baseline methods are implemented using their offi-
cial codes on GitHub. LTLP is constructed using the Neo-GNN as
the backbone for most experiments. We also demonstrate LTLP’s
flexibility with node-centric approach GCN by referring to Sec.
5.3.1. More detailed implementations are in the appendix A.1.
5.2 Experiment Results
5.2.1 Results on Overall Performance. We first report the results
on overall performance in Table 2. From the results, we have the
following observations and analysis:
•Across the majority of datasets, our proposed method (LTLP) con-
sistently outstrips the baseline approaches. which underscores
the superiority of our method in enhancing the overall perfor-
mance of link prediction.
•Seal and NeoGNN always yield better results compared to other
baseline methods, which demonstrates the criticality of modeling
the node representations and the structure between the node
pairs simultaneously in link prediction.
•Heuristic methods perform poorly in most cases which demon-
strates the significance to learn the linking patterns automatically
from data.
5.2.2 Results on Head and Tail Samples. Furthermore, we evaluate
the capability of our method, LTLP, in handling long-tailed issues
here. We divide the test node pairs into head and tail sample groups
according to the definitions in Sec. 5.1.1. We then report the accu-
racy metric on these two groups separately, in a manner consistent
with the methodologies presented in [ 20,27,44]. The results in
Table 3 reveal that in all datasets, LTLP can achieve the best or
second-best performance on head samples compared with baseline
methods. More importantly, in all datasets, our method LTLP can
significantly outperform all baseline methods in tail samples, which
demonstrates LTLP’s efficacy in amplifying the representation of
tail samples. Moreover, smaller bias in all datasets also proves that
LTLP effectively narrows the performance disparity between head
and tail samples, further corroborating its ability to address the
challenge of the long-tailed problem in link prediction.
In summary, our method can greatly improve the overall perfor-
mance of link prediction, especially on tail samples compared with
state-of-the-art link prediction methods. This result aligns with
our prior analysis that addressing the long-tailed problem in link
prediction by structure and representation enhancement is very
critical and valuable for link prediction.
5.3 Model Analysis
5.3.1 Flexibility. As our prior analysis indicated in Sec. 3.2, link
prediction approaches, neither node-centric nor edge-centric, com-
monly exhibit the long-tailed issue in terms of common neighbors.
So we further conduct experiments based on a node-centric ap-
proach, i.e. GCN, and another edge-centric approach, i.e. NCNC, to
demonstrate our framework’s flexibility. Following the aforemen-
tioned experiment setting, we report both the overall performance
and the accuracy on head and tail samples. As illustrated in Table 4,
our framework 𝐿𝑇𝐿𝑃𝐺𝐶𝑁 and𝐿𝑇𝐿𝑃𝑁𝐶𝑁𝐶 boost the performance
of both overall and tail samples compared with GCN and NCNC.
Consequently, our framework is effective in alleviating the long-tail
3228KDD ’24, August 25–29, 2024, Barcelona, Spain Yakun Wang et al.
Table 2: Performance comparison (% ±𝜎) across seven baselines on five datasets. We use bold to indicate the best performance
and underline for the second-best.
Datasets CN AA GCN SAGE SEAL Neo-GNN Tail-GNN LTLP
Cora 73.45±0.00 73.63±0.00 91.80±0.54 90.44±0.79 91.14±1.24 89.10±0.43 87.95±1.08 93.16±0.00
CiteSeer 68.13±0.00 66.91±0.00 88.91±1.16 85.54±0.84 88.63±0.63 90.96±0.30 84.40±1.18 92.89±0.16
Pubmed 64.09±0.00 64.94±0.00 96.32±0.14 89.93±0.19 97.43±0.21 95.73±0.32 94.17±0.58 96.90±0.23
OGB-Collab 50.06±0.00 53.00±0.00 47.01±0.79 48.60±0.46 54.37±0.02 57.52±0.37 5.76±0.22 61.23±1.15
OGB-PPA 27.65±0.00 32.45±0.00 16.98±1.33 13.93±2.38 48.15±4.17 49.13±0.60 >24h 51.91±2.09
Table 3: Accuracy performance on Head and Tail Samples,
as well as their Mean and Bias, with preference for Higher
Values in Head, Tail, and Mean, and Lower Values in Bias.
The best results are denoted in bold, and the second-best in
underline.
Datasets GCN Neo-GNN Tail-GNN LTLP
CoraHead 0.9659 0.9739 0.9521 0.9957
Tail 0.7838 0.7669 0.7657 0.8585
Mean 0.8749 0.8704 0.8589 0.9271
Bias 0.0082 0.0107 0.0086 0.0047
CiteSeerHead 0.9928 0.9865 0.9731 0.9939
Tail 0.7857 0.7385 0.7148 0.8429
Mean 0.8892 0.8625 0.8440 0.9184
Bias 0.0100 0.01538 0.0160 0.0059
PubmedHead 0.9807 0.9920 0.9826 0.9892
Tail 0.9000 0.8924 0.8548 0.9302
Mean 0.9404 0.9423 0.9192 0.9607
Bias 0.0016 0.0024 0.0041 0.0009
OGB-CollabHead 0.9934 0.9975 0.9072 0.9976
Tail 0.9093 0.9023 0.8136 0.9124
Mean 0.9514 0.9499 0.8604 0.9550
Bias 0.0017 0.0022 0.0021 0.0018
OGB-PPAHead 0.9856 0.9929 >24h 0.9919
Tail 0.9700 0.9476 >24h 0.9770
Mean 0.9778 0.9702 >24h 0.9844
Bias 6e-5 0.0005 >24h 5e-5
problem for both node-level and edge-level models and achieving
remarkable performance.
5.3.2 Ablation Study. Our framework consists of two primary mod-
ules: the Subgraph Enhancement Module and the Representation
Enhancement Module. To validate the effectiveness of the two mod-
ules, we compare LTLP with LTLP 𝑤𝑜/𝑟and LTLP𝑤𝑜/𝑠𝑟on three
datasets, where LTLP 𝑤𝑜/𝑠𝑟do not contain both of the two modules,
LTLP𝑤𝑜/𝑟do not contain the Representation Enhancement Module.
The result in Fig. 4, reveals that both modules contribute to the
performance improvement but the Subgraph Enhancement Module
can bring a more significant improvement.
We further go into more detail on the Subgraph Enhancement
Module, which consists of two submodules: the candidate edge
generation and the score-variance filtering submodule. To evalu-
ate the effectiveness of generating candidate common neighborsTable 4: Performance comparison based on GCN and NCNC
backbone. Bold results represent the best.
Datasets AUC Head Tail Bias
Cora𝐺𝐶𝑁 0.9180 0.9659 0.7838 0.0082
𝐿𝑇𝐿𝑃𝐺𝐶𝑁 0.9398 0.9596 0.8436 0.0033
𝑁𝐶𝑁𝐶 0.9742 0.9786 0.9097 0.0012
𝐿𝑇𝐿𝑃𝑁𝐶𝑁𝐶 0.9793 0.9701 0.9317 0.0004
CiteSeer𝐺𝐶𝑁 0.8891 0.9928 0.7857 0.0100
𝐿𝑇𝐿𝑃𝐺𝐶𝑁 0.9124 0.9875 0.8026 0.0085
𝑁𝐶𝑁𝐶 0.9741 1.0 0.9001 0.0024
𝐿𝑇𝐿𝑃𝑁𝐶𝑁𝐶 0.9778 1.0 0.9121 0.0019
Pubmed𝐺𝐶𝑁 0.9632 0.9807 0.9000 0.0016
𝐿𝑇𝐿𝑃𝐺𝐶𝑁 0.9713 0.9765 0.9144 0.0009
𝑁𝐶𝑁𝐶 0.9913 0.9944 0.9502 0.0005
𝐿𝑇𝐿𝑃𝑁𝐶𝑁𝐶 0.9929 0.9928 0.9560 0.0003
using one-hop neighbors, we use a random mechanism denoted as
LTLP𝑟𝑛𝑑, where candidate common neighbors are randomly gen-
erated. We also conduct experiments by using only a score-based
filtering approach, denoted as LTLP 𝑠. The results are shown in Fig.
4 which demonstrate that both submodules yield better results.
(a) Ablation studies within LTLP
 (b) Ablation studies within SEM module
Figure 4: Ablation studies within LTLP and SEM module.
5.3.3 Parameters Analysis. We conduct the parameter sensitivity
analysis on 𝐾and𝜑on Cora. The results are shown in Fig. 5. The
hyper-parameter K, represents the ratio of edges maintained after
the score-variance filtering mechanism. From the results, we find
that the increase of 𝐾before the value of 0.6is very essential be-
cause it can involve many common neighbors of high confidence.
However, further increasing 𝐾will harm the model’s performance,
especially on the tail samples’ performance due to the involvement
3229Optimizing Long-tailed Link Prediction in Graph Neural Networks through Structure Representation Enhancement KDD ’24, August 25–29, 2024, Barcelona, Spain
of false common neighbors. Additionally, the combination of repre-
sentation enhancement loss and cross-entropy loss yields the best
results when 𝜑=0.7, and the model is robust to the value of 𝜑.
5.3.4 Sparsity Analysis. To assess the efficacy of our method LTLP
in sparse graph scenarios, we create sparse graph conditions by
applying edge downsampling to existing graphs. Specifically, we
continue to downsample the training graphs based on the settings
outlined in Sec.5.1.1 on the Cora dataset. As illustrated in Table 5
where the sampling ratio ( 𝑆) represents the proportion of edges we
randomly undersample to mimic varying levels of graph sparsity.
Our approach, LTLP, consistently outperforms Neo-GNN in terms
of the overall AUC and the accuracy of tail samples under various
levels of sparsity.
Table 5: Performance comparison on the sparse graphs gen-
erated by downsampling edges on the Cora dataset, where
𝑆represents the downsampling ratio, 𝑂𝑣𝑒𝑟𝑎𝑙𝑙 indicates the
AUC on overall samples, and 𝑇𝑎𝑖𝑙denotes the accuracy of tail
samples.
Methods 𝑆=0.1𝑆=0.3𝑆=0.5𝑆=0.7𝑆=0.9
Neo-GNN𝑂𝑣𝑒𝑟𝑎𝑙𝑙 0.8795 0.8932 0.8980 0.8982 0.8998
𝑇𝑎𝑖𝑙 0.8093 0.8143 0.8055 0.7906 0.7878
LTLP𝑂𝑣𝑒𝑟𝑎𝑙𝑙 0.8904 0.9031 0.9149 0.9232 0.9271
𝑇𝑎𝑖𝑙 0.8336 0.8309 0.8452 0.8571 0.8663
5.3.5 Case Study. To provide a more intuitive understanding of
how LTLP performs and generates the common neighbors by in-
troducing candidate edges, we conduct a case study on the Cora
dataset. Consider an original graph shown in Fig. 6 (a), where the
ground-truth label between node 1846 and node 1867 is 1. We sim-
ulate a scenario where a portion of the edges is masked (i.e. 50%),
thereby creating a sparser, masked graph for training the Neo-GNN
model. As shown in Fig. 6 (b). The prediction result of Neo-GNN is
wrong because of the weak structural correlation between the node
pair. We then introduce more structure information into the masked
graph to form the structure enhanced graph by LTLP. As despite
in Fig. 6 (c), we find that all of the previous common neighbors
are restored by LTLP and LTLP adds one more common neighbor
which has the same label with node 1846 and node 1867, resulting
in a correct prediction result.
(a) The impact of k%
 (b) The impact of 𝜑
Figure 5: Hyper-parameters analysis on Cora dataset.
Figure 6: Case study on Cora dataset.
6 CONCLUSION AND FUTURE WORK
In this paper, we uncover and define the long-tailed problem in link
prediction based on common neighbors. To alleviate the problem,
we introduce a novel framework LTLP that enhances the represen-
tation of tail samples by supplementing common neighbors through
integrating high-quality candidate edges. Moreover, we further con-
strain the representations of tail samples by pushing closer to the
category center. Comparative experiments across multiple datasets
against various baselines affirm that our method not only outper-
forms baselines in overall performance but also achieves more
substantial improvements on tail samples, thereby substantiating
the efficacy of our design. In summary, our work makes a notable
contribution to the understanding of the long-tailed problem in link
prediction and provides a direction for its further optimization.
Our method is relatively straightforward and effective and fu-
ture work will delve deeper into the long-tailed problem in link
prediction across more complex structures.
3230KDD ’24, August 25–29, 2024, Barcelona, Spain Yakun Wang et al.
REFERENCES
[1]Lada A Adamic and Eytan Adar. 2003. Friends and neighbors on the web. Social
networks, 211–230.
[2]Albert-László Barabási and Réka Albert. 1999. Emergence of scaling in random
networks. science, 509–512.
[3]Shaosheng Cao, Wei Lu, and Qiongkai Xu. 2015. Grarep: Learning graph rep-
resentations with global structural information. In Proceedings of the 24th ACM
international on conference on information and knowledge management. 891–900.
[4]Benjamin Paul Chamberlain, Sergey Shirobokov, Emanuele Rossi, Fabrizio Frasca,
Thomas Markovich, Nils Hammerla, Michael M Bronstein, and Max Hansmire.
2023. Graph Neural Networks for Link Prediction with Subgraph Sketching. In
ICLR.
[5]Tim R Davidson, Luca Falorsi, Nicola De Cao, Thomas Kipf, and Jakub M Tomczak.
2018. Hyperspherical variational auto-encoders. arXiv preprint arXiv:1804.00891
(2018).
[6]Jingtao Ding, Yuhan Quan, Quanming Yao, Yong Li, and Depeng Jin. 2020. Simplify
and robustify negative sampling for implicit collaborative filtering. In NeurIPS.
1094–1105.
[7]Will Hamilton, Zhitao Ying, and Jure Leskovec. 2017. Inductive representation
learning on large graphs. In NeurIPS.
[8]Xiangnan He, Kuan Deng, Xiang Wang, Yan Li, Yongdong Zhang, and Meng
Wang. 2020. Lightgcn: Simplifying and powering graph convolution network for
recommendation. In SIGIR. 639–648.
[9]Xiangnan He, Kuan Deng, Xiang Wang, Yan Li, Yongdong Zhang, and Meng
Wang. 2020. Lightgcn: Simplifying and powering graph convolution network for
recommendation. In SIGIR. 639–648.
[10] Binbin Hu, Chuan Shi, Wayne Xin Zhao, and Philip S Yu. 2018. Leveraging
meta-path based context for top-n recommendation with a neural co-attention
model. In SIGKDD. 1531–1540.
[11] Weihua Hu, Matthias Fey, Marinka Zitnik, Yuxiao Dong, Hongyu Ren, Bowen
Liu, Michele Catasta, and Jure Leskovec. 2020. Open graph benchmark: Datasets
for machine learning on graphs. In NeurIPS. 22118–22133.
[12] Vassilis N Ioannidis, Da Zheng, and George Karypis. 2020. Few-shot link predic-
tion via graph neural networks for covid-19 drug-repurposing. ICML (2020).
[13] Leo Katz. 1953. A new status index derived from sociometric analysis. Psychome-
trika, 39–43.
[14] Alex Kendall and Yarin Gal. 2017. What uncertainties do we need in bayesian
deep learning for computer vision? NeurIPS 30 (2017).
[15] Thomas N Kipf and Max Welling. 2016. Semi-supervised classification with graph
convolutional networks. In ICLR.
[16] Thomas N Kipf and Max Welling. 2016. Variational graph auto-encoders. arXiv
preprint arXiv:1611.07308 (2016).
[17] Ajay Kumar, Shashank Sheshar Singh, Kuldeep Singh, and Bhaskar Biswas. 2020.
Link prediction techniques, applications, and performance: A survey. Physica A:
Statistical Mechanics and its Applications (2020), 124289.
[18] Juanhui Li, Harry Shomer, Haitao Mao, Shenglai Zeng, Yao Ma, Neil Shah, Jiliang
Tang, and Dawei Yin. 2024. Evaluating graph neural networks for link prediction:
Current pitfalls and new benchmarking. NeurIPS 36 (2024).
[19] Yanying Li, Xiuling Wang, Yue Ning, and Hui Wang. 2022. Fairlp: Towards fair
link prediction on social network graphs. In AAAI, Vol. 16. 628–639.
[20] Zemin Liu, Qiheng Mao, Chenghao Liu, Yuan Fang, and Jianling Sun. 2022. On
size-oriented long-tailed graph classification of graph neural networks. In WWW.
1506–1516.
[21] Zemin Liu, Trung-Kien Nguyen, and Yuan Fang. 2021. Tail-gnn: Tail-node graph
neural networks. In SIGKDD. 1109–1119.
[22] Zemin Liu, Wentao Zhang, Yuan Fang, Xinming Zhang, and Steven CH Hoi. 2020.
Towards locality-aware meta-learning of tail node embeddings on networks. In
CIKM. 975–984.
[23] Linyuan Lü and Tao Zhou. 2011. Link prediction in complex networks: A survey.
Physica A: statistical mechanics and its applications (2011), 1150–1170.[24] Abhay Singh, Qian Huang, Sijia Linda Huang, Omkar Bhalerao, Horace He, Ser-
Nam Lim, and Austin R Benson. 2021. Edge proposal sets for link prediction.
arXiv preprint arXiv:2106.15810 (2021).
[25] Ben Taskar, Ming-Fai Wong, Pieter Abbeel, and Daphne Koller. 2003. Link
prediction in relational data. In NeurIPS.
[26] Komal Teru, Etienne Denis, and Will Hamilton. 2020. Inductive relation prediction
by subgraph reasoning. In ICML. 9448–9457.
[27] Ruijia Wang, Xiao Wang, Chuan Shi, and Le Song. 2022. Uncovering the Structural
Fairness in Graph Contrastive Learning. NeurIPS 35 (2022), 32465–32473.
[28] Xiyuan Wang, Haotong Yang, and Muhan Zhang. 2023. Neural Common Neighbor
with Completion for Link Prediction. arXiv preprint arXiv:2302.00890 (2023).
[29] Xiyuan Wang, Haotong Yang, and Muhan Zhang. 2024. Neural common neighbor
with completion for link prediction. (2024).
[30] Yakun Wang, Binbin Hu, Shuo Yang, Meiqi Zhu, Zhiqiang Zhang, Qiyang Zhang,
Jun Zhou, Guo Ye, and Huimei He. 2024. Not All Negatives AreWorth Attending to:
Meta-Bootstrapping Negative Sampling Framework for Link Prediction. WSDM
(2024).
[31] Yuyang Wang, Jianren Wang, Zhonglin Cao, and Amir Barati Farimani. 2022.
Molecular contrastive learning of representations via graph neural networks.
Nature Machine Intelligence (2022), 279–287.
[32] Yu Wang, Tong Zhao, Yuying Zhao, Yunchao Liu, Xueqi Cheng, Neil Shah, and
Tyler Derr. 2024. A Topological Perspective on Demystifying GNN-Based Link
Prediction Performance. (2024).
[33] Zonghan Wu, Shirui Pan, Fengwen Chen, Guodong Long, Chengqi Zhang, and
S Yu Philip. 2020. A comprehensive survey on graph neural networks. IEEE
transactions on neural networks and learning systems (2020), 4–24.
[34] Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka. 2018. How powerful
are graph neural networks?. In ICLR.
[35] Shuo Yang, Binbin Hu, Zhiqiang Zhang, Wang Sun, Yang Wang, Jun Zhou,
Hongyu Shan, Yuetian Cao, Borui Ye, Yanming Fang, et al .2021. Inductive
Link Prediction with Interactive Structure Learning on Attributed Graph. In
ECML PKDD. 383–398.
[36] Shuo Yang, Zhiqiang Zhang, Jun Zhou, Yang Wang, Wang Sun, Xingyu Zhong,
Yanming Fang, Quan Yu, and Yuan Qi. 2021. Financial risk analysis for SMEs
with graph-based supply chain mining. In IJCAI. 4661–4667.
[37] Zhilin Yang, William Cohen, and Ruslan Salakhudinov. 2016. Revisiting semi-
supervised learning with graph embeddings. In ICML. 40–48.
[38] Rex Ying, Ruining He, Kaifeng Chen, Pong Eksombatchai, William L Hamilton,
and Jure Leskovec. 2018. Graph convolutional neural networks for web-scale
recommender systems. In SIGKDD. 974–983.
[39] Rex Ying, Ruining He, Kaifeng Chen, Pong Eksombatchai, William L Hamilton,
and Jure Leskovec. 2018. Graph convolutional neural networks for web-scale
recommender systems. In SIGKDD. 974–983.
[40] Seongjun Yun, Seoyoon Kim, Junhyun Lee, Jaewoo Kang, and Hyunwoo J Kim.
2021. Neo-gnns: Neighborhood overlap-aware graph neural networks for link
prediction. NeurIPS, 13683–13694.
[41] Xiaoling Zang, Binbin Hu, Jun Chu, Zhiqiang Zhang, Guannan Zhang, Jun Zhou,
and Wenliang Zhong. 2023. Commonsense Knowledge Graph towards Super
APP and Its Applications in Alipay. In SIGKDD. 5509–5519.
[42] Muhan Zhang and Yixin Chen. 2018. Link prediction based on graph neural
networks. In NeurIPS.
[43] Tong Zhao, Gang Liu, Daheng Wang, Wenhao Yu, and Meng Jiang. 2022. Learning
from counterfactual links for link prediction. In ICML. 26911–26926.
[44] Wenqing Zheng, Edward W Huang, Nikhil Rao, Sumeet Katariya, Zhangyang
Wang, and Karthik Subbian. 2021. Cold brew: Distilling graph node representa-
tions with incomplete or missing neighborhoods. arXiv preprint arXiv:2111.04840
(2021).
[45] Tao Zhou, Linyuan Lü, and Yi-Cheng Zhang. 2009. Predicting missing links via
local information. The European Physical Journal B, 623–630.
[46] Zhaocheng Zhu, Zuobai Zhang, Louis-Pascal Xhonneux, and Jian Tang. 2021.
Neural bellman-ford networks: A general graph neural network framework for
link prediction. In NeurIPS. 29476–29490.
3231Optimizing Long-tailed Link Prediction in Graph Neural Networks through Structure Representation Enhancement KDD ’24, August 25–29, 2024, Barcelona, Spain
A APPENDIX
A.1 LTLP Configuration and Baseline Settings
Our LTLP framework is based on the Neo-GNN architecture, which
includes three layers of GCN and a hidden dimension of 256. More
detailed configurations are in the following Neo-GNN code. In our
experiments, the baseline models primarily rely on open-source
frameworks and github. The reproducible code for each baseline is
available as below:
(1) CN/AA: https://github.com/facebookresearch/SEAl_OGB/
blob/main/utils.py
(2) GCN/SAGE: https://github.com/pyg-team/pytorch_geometric
/blob/master/examples/link_pred.py
(3) SEAL: https://github.com/facebookresearch/SEAL_OGB
(4) Neo-GNN: https://github.com/seongjunyun/Neo-GNNs
(5) Tail-GNN: https://github.com/shuaiOKshuai/Tail-GNN
(6) NCNC: https://github.com/GraphPKU/NeuralCommonNeighbor
Table 6: Parameters setting in LTLP across datastes. 𝑒𝑝𝑜𝑐ℎ 1
means iteration epochs in the pretraining stage and 𝑒𝑝𝑜𝑐ℎ 2
is in continued training stage.
Dataset K𝜑𝑒𝑝𝑜𝑐ℎ 1𝑒𝑝𝑜𝑐ℎ 2batchsize
Cora 0.6 0.7 120 50 1024
CiteSeer 0.4 0.6 120 70 1024
Pubmed 0.8 0.2 60 60 1024
OGB-Collab 0.6 0.6 100 30 1024
OGB-PPA 0.4 0.2 100 50 1024
(a) CNS distribution on Cora
 (b) CNS distribution on CiteSeer
(c) CNS distribution on Pubmed
Figure 7: The distribution of common neighbors (CNS) in the
original graph and enhanced graph.A.2 Parameters and Environments
The optimal hyperparameters are determined through grid search
on the validation set, which mainly includes K and 𝜑. K controls
the ratio of variance-based sample filtering, and 𝜑regulates the
emphasis placed on the two loss functions. Additionally, there are
other training parameters, such as batch size, and epochs for both
the pre-training and continued training phases of LTLP, with spe-
cific settings for each dataset detailed in Table 6. As for the training
environment, all experiments in this paper are performed with a
Tesla V100 GPU(32GB).
A.3 Visualization on Structure Enhancement
Building upon the analysis of the correlation between the accuracy
of link prediction and common neighbors. Consequently, we pro-
ceed to examine the distribution shift of common neighbors before
and after structure enhancement. We plot the distribution of com-
mon neighbors in both the original graph and the enhanced graph
by edge addition. The findings shown in Fig. 7 indicate that by aug-
menting common neighbors through the structure enhancement
module, a significant number of tail samples are transformed into
head samples, which in turn introduces the structural information
within the subgraph and improves the precision.
A.4 Data Analysis on OGB Datasets
We also conduct data analysis on the large-scale OGB datasets (i.e.
OGB-collab, OGB-PPA), employing the same setup as described
in Sec. 3.2 and using the classic model SEAl as the baseline. As
illustrated in Fig. 8, the results align with those presented in Sec.
3.2, in terms of both the distribution of samples and the correlation
with accuracy. This analysis further substantiates that the definition
of long-tailed link prediction is associated with common neighbors
rather than degrees.
(a) OGB-Collab Degree Analysis
 (b) OGB-Collab CNs Analysis
(c) OGB-PPA Degree Analysis
 (d) OGB-PPA CNs Analysis
Figure 8: The correlation between the link prediction accu-
racy and different measures, i.e. degrees and common neigh-
bors (CNs), by using SEAL.
3232