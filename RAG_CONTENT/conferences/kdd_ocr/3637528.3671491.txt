Workshop on Deep Learning and Large Language Models for
Knowledge Graphs (DL4KG)
Mehwish Alam
Telecom Paris,
Institut Polytechnique de Paris
Paris, France
mehwish.alam@telecom-paris.frDavide Buscaldi
Laboratoire d’Informatique
de Paris Nord
Paris, France
buscaldi@lipn.frMichael Cochez
Computer Science,
Vrije Universiteit Amsterdam
Elsevier discovery lab
Amsterdam, The Netherlands
m.cochez@vu.nl
Genet Asefa Gesese
FIZ Karlsruhe, Leibniz Instiute for
Information Infrastructure
Karlsruhe, Germany
genet-asefa.gesese@fiz-karlsruhe.deFrancesco Osborne
The Open University
Milton Keynes, United Kingdom
francesco.osborne@open.ac.ukDiego Reforgiato Recupero
University of Cagliari,
Cagliari, Italy
diego.reforgiato@unica.it
Abstract
The use of Knowledge Graphs (KGs) which constitute large net-
works of real-world entities and their interrelationships, has grown
rapidly. A substantial body of research has emerged, exploring the
integration of deep learning (DL) and large language models (LLMs)
with KGs. This workshop aims to bring together leading researchers
in the field to discuss and foster collaborations on the intersection
of KG and DL/LLMs.
CCS Concepts
•Computing methodologies →Machine learning; Artificial
intelligence.
Keywords
Artificial Intelligence, Deep Learning, Large Language Models,
Knowledge Graphs
ACM Reference Format:
Mehwish Alam, Davide Buscaldi, Michael Cochez, Genet Asefa Gesese,
Francesco Osborne, and Diego Reforgiato Recupero. 2024. Workshop on
Deep Learning and Large Language Models for Knowledge Graphs (DL4KG).
InProceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery
and Data Mining (KDD ’24), August 25–29, 2024, Barcelona, Spain. ACM, New
York, NY, USA, 2 pages. https://doi.org/10.1145/3637528.3671491
1 Introduction
Knowledge Graphs (KGs) have recently gained attention due to
their ability to represent structured and interlinked information
and provide support for a variety of Artificial Intelligence (AI) tech-
niques. KGs represent knowledge in the form of relations between
entities, referred to as facts, typically grounded in formal onto-
logical models. Such machine-readable formats enable AI systems
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for third-party components of this work must be honored.
For all other uses, contact the owner/author(s).
KDD ’24, August 25–29, 2024, Barcelona, Spain
©2024 Copyright held by the owner/author(s).
ACM ISBN 979-8-4007-0490-1/24/08
https://doi.org/10.1145/3637528.3671491to make decisions using clear and verifiable data. Consequently,
KGs have become essential elements in systems like web search
engines, recommendation platforms, and chatbots. Several meth-
ods for generating Embeddings from KGs have been proposed and
many applications of such techniques have been presented. These
embedding techniques are typically based on translational, factor-
ization, or random walk-based methods. Other approaches skip the
embedding step and apply neural network approaches directly onto
the graph (e.g., graph convolutional networks).
On the other hand, Large Language Models (LLMs) have revolu-
tionized the landscape of AI. They are widely utilized for various
Natural Language Processing (NLP) tasks such as natural language
understanding, question answering, translation, and so on. How-
ever, LLMs also suffer from some significant drawbacks. First, they
are trained on general-purpose data and thus have lower perfor-
mance in domain-specific tasks and in low-resource languages. Sec-
ondly, they often reflect societal biases present in their training data,
which can result in biased outcomes. Third, LLMs sometimes pro-
duce inaccurate or made-up information, termed “hallucinations".
Finally, understanding the decision-making process of LLMs is chal-
lenging and their outputs may lack consistency. A potential solution
to all these problems is to explore the interplay between LLMs and
KGs, since KGs can provide factual information that humans can
model, verify, and correct. This would thus boost the LLM’s domain-
specific reasoning, enhance interpretability, and mitigate biases and
hallucinations. On the other hand, LLMs can aid in this process by
generating and refining KG content. Combining LLMs with KGs
presents a powerful synergy that enhances the capabilities of AI
across various tasks. LLMs, such as GPT-3, excel in understanding
and generating human-like text, while knowledge graphs organize
structured information about entities and their relationships. When
integrated, they offer a robust approach to problem-solving in di-
verse domains such as information enrichment, question answering,
content generation, semantic understanding, and customized task
solutions.
2 Topics of Interest
DL4KG revolves around the following topics:
6704
KDD ’24, August 25–29, 2024, Barcelona, Spain Mehwish Alam et al.
•LLMs and Knowledge Graphs
–Knowledge Base Construction using LLMs
–Knowledge Graphs to improve the quality of LLMs
–Question Answering exploiting LLMs and Knowledge
Graphs (such as Retrieval Augmented Generation)
–Hybrid LLMs-KG models (cross-attention, joint training,...)
–Knowledge-Based fact-checking for LLMs
•New approaches for combining Deep Learning, LLMs, and
Knowledge Graphs
–Methods for generating Knowledge Graph (node) embed-
dings
–Temporal Knowledge Graph Embeddings
–KGs for interoperability and Explainability
–Recommender Systems leveraging Knowledge Graphs
–Link Prediction and completing KGs
–Ontology Learning and Matching exploiting Knowledge
Graph-Based Embeddings
–Knowledge Graph-Based Sentiment Analysis
–Natural Language Understanding/Machine Reading
–Question Answering exploiting Knowledge Graphs and
Deep Learning
–Approximate query answering on knowledge graphs
–Trend Prediction based on Knowledge Graphs Embeddings
–Learning Representations from Graphs (Graph Neural Net-
works, Graph Convolutional Networks, etc.)
•Applications of combining Deep Learning, LLMs and Knowl-
edge Graphs
–Domain Specific Applications (e.g., Scholarly, Biomedical,
Cultural Heritage, etc.)
–Applications in industry 4.0.
–Applying to real-world scenarios
3 Workshop Format
A half-day workshop is planned, with attendance expected to reach
40 people based on previous workshops’ attendance, though the
number could be higher due to the broad reach of the KDD confer-
ence. The program starts with a 30-minute keynote followed by a
15-minute discussion. After that, the participants will have a chance
to present accepted full papers with a 20 minute slot - 25 minutes
in total (including questions). Short papers will have a shorter time
slot for presenting their work. There is also a dedicated website
for the workshop that will be kept updated with the workshop pro-
gram, contacts, background information, and relevant pictures of
the event. The reviewing process is single-blinded. For each paper,
3 reviews will be required to make a judgment. A meta-review will
be provided in case of any disagreements between the reviewers.
4 Workshop Organizers
Mehwish Alam is an associate professor at Telecom Paris, Insti-
tute Polytechnique de Paris. The focus of her research is Machine
Learning/Deep Learning, KGs, Graph Mining, and NLP.
Davide Buscaldi has been an Associate Professor at the LIPN,USPN,
since September 2012, where he is a member of the RCLN (Knowl-
edge Resources and Natural Language) team. He is also an Assistant
Professor at Ecole Polytechnique, DaScim team, where he teachesdeep learning and NLP. He also sits in the scientific board of LabEx-
EFL (http://www.labex-efl.com) and the Human Language Tech-
nologies chapter of the French Association for Artificial Intelligence.
Michael Cochez is an Assistant Professor in Artificial Intelligence
at Vrije Universiteit Amsterdam since September 2019. In 2016, he
received his PhD degree from the university of Jyväskylä in Fin-
land, after which he worked at the Fraunhofer Institute for Applied
Information Technology FIT. His current research interests revolve
around combining symbolic (especially KGs) information with sub-
symbolic machine learning approaches.
Genet Asefa Gesese is a Post-doctoral Researcher at FIZ-Karlsruhe.
Her research interests include Machine/Deep Learning, Knowledge
Graph, and NLP. She received her Ph.D. in Computer Science from
Karlsruhe Institute of Technology (KIT) and FIZ Karlsruhe, Ger-
many, in 2023, focusing on the topic of leveraging literals for knowl-
edge graph embedding.
Francesco Osborne is Research Fellow at the Knowledge Media
Institute, The Open University (UK), where he leads the Scholarly
Knowledge Mining team. He has authored more than 120 peer-
reviewed publications in the field of Artificial Intelligence, Infor-
mation Extraction, Science of Science, Semantic Web, and Research
Analytics.
Diego Reforgiato Recupero is a Full Professor at the Depart-
ment of Mathematics and Computer Science of the University of
Cagliari, Italy. He is a member of the Semantic Technology Labo-
ratory of the National Council of Research. He is the co-director
of the Semantic Web Laboratory at the University of Cagliari and
founder and director of the Human-Robot Interaction laboratory at
the University of Cagliari.
5 Program Committee
The workshop has the following program committee members.
•Maribel Acosta, Technical University of Munich, Germany
•Mary Ann Tan, FIZ Karlsruhe, Germany
•Achim Rettinger, University of Trier, Germany.
•Femke Ongenae, Ghent University, Belgium.
•Peter Bloem, VU Amsterdam, the Netherlands.
•Finn Arup Nielsen, Technical University of Denmark, Den-
mark.
•Basil Ell, Bielefeld University, Germany
•Angelo Salatino, The Open University, UK
•Ernesto Jiménez-Ruiz, University of London, UK
•Valerio Bellandi, University of Milan, Italy
•Catia Pesquita, University of Lisbon, Portugal
•Cassia Trojahn, IRIT, France
6705