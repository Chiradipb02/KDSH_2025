Unifying Evolution, Explanation, and Discernment: A Generative
Approach for Dynamic Graph Counterfactuals
Bardh Prenkaj‚àó
Technical University of Munich
Munich, GermanyMario Villaiz√°n-Vallelado
University of Valladolid
Telef√≥nica Research and Development
Valladolid, Spain
Tobias Leemann‚àó
University of T√ºbingen
T√ºbingen, GermanyGjergji Kasneci
Technical University of Munich
Munich, Germany
ABSTRACT
We present GRACIE (Graph Recalibration and Adaptive Counter-
factual Inspection and Explanation), a novel approach for gen-
erative classification and counterfactual explanations of dynami-
cally changing graph data. We study graph classification problems
through the lens of generative classifiers. We propose a dynamic,
self-supervised latent variable model that updates by identifying
plausible counterfactuals for input graphs and recalibrating de-
cision boundaries through contrastive optimization. Unlike prior
work, we do not rely on linear separability between the learned
graph representations to find plausible counterfactuals. Moreover,
GRACIE eliminates the need for stochastic sampling in latent spaces
and graph-matching heuristics. Our work distills the implicit link
between generative classification and loss functions in the latent
space, a key insight to understanding recent successes with this
architecture. We further observe the inherent trade-off between va-
lidity and pulling explainee instances towards the central region of
the latent space, empirically demonstrating our theoretical findings.
In extensive experiments on synthetic and real-world graph data,
we attain considerable improvements, reaching ‚àº99%validity when
sampling sets of counterfactuals even in the challenging setting of
dynamic data landscapes.
CCS CONCEPTS
‚Ä¢Computing methodologies ‚ÜíKnowledge representation
and reasoning; Semi-supervised learning settings; ‚Ä¢Mathe-
matics of computing ‚ÜíComputing most probable explanation ;‚Ä¢
Computer systems organization ‚ÜíNeural networks.
KEYWORDS
Counterfactual Explainability; Dynamic Graphs; Graph Neural Net-
works; Graph Autoencoders
‚àóThese authors contributed equally. Corresponding: bardh.prenkaj@tum.de
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain
¬©2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 979-8-4007-0490-1/24/08
https://doi.org/10.1145/3637528.3671831ACM Reference Format:
Bardh Prenkaj, Mario Villaiz√°n-Vallelado, Tobias Leemann, and Gjergji
Kasneci. 2024. Unifying Evolution, Explanation, and Discernment: A Gen-
erative Approach for Dynamic Graph Counterfactuals. In Proceedings of
the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining
(KDD ‚Äô24), August 25‚Äì29, 2024, Barcelona, Spain. ACM, New York, NY, USA,
12 pages. https://doi.org/10.1145/3637528.3671831
1 INTRODUCTION
Graphs offer an intuitive framework to model the relationships,
interactions, and dependencies that govern modern society. Due
to their unique expressivity, they drive research in domains such
as recommendations in social networks [ 13] and transaction fraud
detection [ 20]. These are pressing problems. For instance, dam-
ages due to online fraud have more than doubled in the recent
two years and are expected to reach a record-high of 48bn$ this
year [ 37], such that better detection strategies are in high demand.
Graphs are most suitable to model relationships involving tangible
users, IP addresses, and other elements [ 8] that dictate this issue‚Äôs
complexity.
However, progress in domains such as fraud detection is sub-
stantially complicated by the dynamic and adversarial nature of
the observed data: the application of fraud detection techniques
also triggers adaptations in fraud tactics aimed specifically at evad-
ing detection [ 20]. Such dynamic data landscapes require constant
updates of models.
Concurrently, the need for explainability has been widely ac-
knowledged for system safety [ 7], scientific discovery [ 22], and
even compliance with legal requirements [ 40], which is particularly
important in financial applications. Regulations like GDPR [ 9] and
the proposed AI Act [ 10] emphasize the demand for models that
perform well and provide interpretable and actionable insights into
their predictions. Counterfactual explanations [ 40] have emerged
as a key element in meeting these regulatory requirements, as they
shed light on model decisions by presenting alternative scenarios
that would result in different outcomes. In summary, a multitude
of pressing problems in both science and the economy (1)can be
modeled intuitively through graphs, (2)evolve dynamically over
time, and (3)require some form of explainability.
However, recent research [ 29] has highlighted a significant chal-
lenge when considering the dynamic and ever-changing nature of
the data that models interact with. Data continuously undergoes
changes and distribution shifts, which may warrant updates of
 
2420
KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain Bardh Prenkaj, Mario Villaiz√°n-Vallelado, Tobias Leemann, and Gjergji Kasneci
the prediction models and can greatly impact the robustness, rele-
vance, and validity of counterfactual explanations [ 28,39]. Existing
solutions have yet to adequately address the complex interaction
between robust counterfactuals and the dynamic nature of data
landscapes, a recently overlooked problem. As this holds for graphs,
we present a powerful method for combining inference and coun-
terfactual explanation for constantly evolving graph data.
To cope with distributional shift, we leverage the capabilities
of generative classifiers, which have been attributed to increased
robustness in prior work [ 34]. These classifiers model the full class-
conditional probability, i.e., ùëù(ùíô|ùë¶)for an input ùíôand each class ùë¶,
and predict the class with the highest likelihood using Bayes‚Äô The-
orem. Learning such a model with variational inference techniques
results in GRACIE (Graph Recalibration and Adaptive Counter-
factual Inspection and Explanation), a novel approach for genera-
tive classification and counterfactual explanations of dynamically
changing graph data. GRACIE learns to produce counterfactuals
from the underlying prediction model. Then, by exploiting its gen-
erative classification properties, decide how to discern between
factuals and counterfactuals. This drives the search for counter-
factual candidates in a self-supervised and principled manner. In
successive steps, factuals and counterfactuals are used to recalibrate
the decision boundary and to embody distribution shifts in time.
Unlike previous work, we do not assume that the learned graph
representations are linearly separable to produce valid counter-
factuals [ 33]. Additionally, we exploit the learned latent space to
search for counterfactuals, thus eliminating the need to sample
estimated edge probabilities on the embedded instances [ 25] and
graph-matching heuristics [ 24], known for their NP-hardness [ 23].
Specifically, we go beyond the related literature by making the
following contributions:
(1)Generative Classification For Graph Data. Drawing from
promising results of the robustness of generative classifiers,
we propose a novel model for the generative classification
of graph data.
(2)Theoretic Analysis and Insights. We formalize the prob-
lem and derive a proposition that links the generative classi-
fication objective to the reconstruction loss of autoencoders
and distances in the latent space. This allows for efficient
classification with latent variable models and serves as an
intuitive explanation for prior work‚Äôs successes.
(3)Online Counterfactual Method. We propose GRACIE, a
novel, dynamic, and self-adapting approach for generative
classification and counterfactual generation of temporally
evolving graph data, leveraging the power of class-related
Variational Graph Autoencoders (VGAEs).
(4)Empirical Analysis. We conduct extensive experiments on
synthetic and real-world graph data, demonstrating GRA-
CIE‚Äôs significant improvement in generative classification
and counterfactual generation, particularly under dataset
shifts. We will publicly release our code online.
2 RELATED WORK
Recently, deep learning relying on GNNs has been beneficial in
solving graph-based prediction tasks, such as anomaly detection,
link prediction [ 41], and protein-protein interaction predictions[35]. Despite their remarkable performance, GNNs are black boxes,
making them unsuitable for high-impact and high-risk scenarios.
The literature has proposed several post-hoc explainability methods
to understand what is happening under the hood of the prediction
models. Specifically, counterfactual explainability is useful to un-
derstand how modifications in the input lead to different outcomes.
Similarly, a recent field in Graph Counterfactual Explainability
(GCE) has emerged [ 32] that aims at producing counterfactuals for
graphs. We provide the reader with an example that helps clarify
a counterfactual example in graphs. Suppose we have a network
of cryptocurrency transactions where nodes are traders and con-
nections represent digital currency transfers from one trader to
another. Assume that trader ùë¢sends a large amount of crypto to
ÀÜùë¢, a high-risk and flagged trader. A fraud detection system might
alert a user ùë¢about restricting their account to minimal transfers
for a designated period due to possible fraud suspicion reasons.
A counterfactual explanation of ùë¢‚Äôs account flagging would be if
ùë¢had refrained from transferring cryptos to ÀÜùë¢‚Äôs account, then ùë¢‚Äôs
account would not have been flagged as suspicious. Generally, GCE
methods can be search- [ 1,11], heuristic- (among others, [ 4]), and
learning-based approaches (among others, [ 24,27,31]). While all
the above methods provide counterfactuals in graphs, none of them
is specialized to cope with evolving graphs in time, which adds
complexity to finding valid and time-adaptable counterfactuals.
The problem of aligning counterfactual explanations in the pres-
ence of distributional drifts has become a relevant subject of study
[14]. However, recent work has shown that counterfactuals are still
fragile and can become invalidated when data points are deleted
[29]. The authors identify influential data points whose deletion
at timeùë°+ùõøensures that previously generated counterfactuals at
timeùë°become obsolete.
To the best of our knowledge, the only work that tackles the
problem of updating invalid counterfactuals in a timely fashion
is [33]. The authors represent graphs of the two opposite classes
by closely aligning graph representations of the same class while
pushing away those of the opposite. When drift distributions occur,
they update the learned representations by calibrating their model
and fitting a linear regressor, which also considers the similarity
of graphs, to separate the newly learned graph representations.
However, this work cannot tackle non-linearly separable represen-
tations, leading the explainer to fail to find valid counterfactuals. To
address this, we propose a novel generative graph counterfactual
explainer that separates the factual and counterfactual spaces while
maintaining faithful representations of both classes over time.
Here, we propose to learn robust class representations and lever-
age generative classification to determine the class of never-seen-
before graphs when the distributional drifts happen, and the deci-
sion boundary of the underlying predictor cannot be trusted. This
helps our method adapt its learned representations self-supervisedly.
3 PROBLEM STATEMENT AND MOTIVATION
Preliminary. A temporal graph ùê∫ùëñcan be defined as a sequence
of graphs{ùê∫ùë°0
ùëñ,...,ùê∫ùë°ùëö
ùëñ}whereùëá={ùë°0,...ùë°ùëö}is a set of discrete
snapshots. Here ùê∫ùë°0
ùëñcan be considered as the base graph structure
which mutates in time into ùê∫ùë°ùëó
ùëñ‚ààG‚àÄùëó‚àà[1,ùëö]whereGis the
 
2421Unifying Evolution, Explanation, and Discernment: A Generative Approach for Dynamic Graph Counterfactuals KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain
Graph at cur r ent timeGraph at pr e vious timeCor r e ct oracle de cision b oundar yOld oracle de cision b oundar yPotential counterfactual asso ciationCor r e ct counterfactual asso ciationOld counterfactual asso ciationGraph mo v ement fr om    to  Class 0Class 1
Class 0Class 1
Figure 1: Counterfactuals require updates in temporal graph
problems. (left) The decision boundary of the oracle Œ¶trained
on the data at time ùë°correctly associates graph ùê∫ùë°
2as the coun-
terfactual of ùê∫ùë°
1, satisfying Eq. 1. (right) As drifts occur, graph
ùê∫ùë°
1transitions to ùê∫ùë°+1
1, crossing the previous (dashed line)
decision boundary. Consequently, ùê∫ùë°+1
2cannot be a counter-
factual for ùê∫ùë°+1
1. A new decision boundary must reflect the
changes (bold full line) to maintain counterfactual validity.
dataset of all graphs. Each graph is generally a tuple (ùëø,ùë®)where
ùëø‚ààRùëõ√óùëërepresents the node feature vectors and ùë®‚ààRùëõ√óùëõis the
adjacency matrix s.t. ùëõis the node number.
Motivation. In this paper, we address the challenge of counterfac-
tual1validity amid data distributional shifts over time. We provide
the reader with an example in Fig. 1 to showcase how counter-
factuals get invalidated when distribution drifts happen [ 29]. We
illustrate six temporal graphs on two snapshots, ùë°andùë°+1. Let
us assume we have 2D representations of these graphs for visu-
alization clarity. Let us consider a specialized explainer, denoted
asŒ©. At snapshot, ùë°,Œ©needs to explain the underlying predictor
(oracle) Œ¶, trained on data from the same snapshot. Œ¶generally
has a specific decision boundary depicted by the bold separation
line. At this point, Œ©successfully generates a valid counterfactual,
ùê∫ùë°
2, for the input ùê∫ùë°
1, instead ofùê∫ùë°
3since the distance between ùê∫ùë°
2
andùê∫ùë°
1is smaller than that of ùê∫ùë°
3andùê∫ùë°
1. As time progresses to
ùë°+1, data distribution shifts may invalidate Œ¶‚Äôs previous decision
boundary, indicated by the bold dashed line. Therefore, Œ¶will fail to
accurately reflect the true data separation ‚Äì e.g., see how ùê∫ùë°+1
1gets
misclassified because it has altered its true class w.r.t. the previous
snapshotùë°. At snapshot ùë°+1, it is crucial to observe that the coun-
terfactual for ùê∫1cannot beùê∫2since they now belong to the same
true class. Instead, now, ùê∫ùë°+1
ùëòwould be a counterfactual for ùê∫ùë°+1
1,
since it crosses the ‚Äútrue decision boundary‚Äù ‚Äì bold separation line
‚Äì unkown to Œ¶. Recognizing the unreliability of Œ¶‚Äôs predictions in
successive snapshots, we advocate for a robust mechanism that
dynamically updates counterfactuals, ensuring their validity amid
data distribution drifts.
1ùê∫‚Ä≤is a counterfactual of ùê∫if their predictions are different according to an underlying
predictor (oracle) Œ¶[40].Problem formalization. Given a black-box oracle Œ¶:G‚ÜíY , a
counterfactual for ùê∫ùë°
ùëñis produced by maximizing the objective
EŒ¶ ùê∫ùë°
ùëñ=arg max
ùê∫ùë°
ùëó‚ààGùëÉùë°
ùëêùëì
ùê∫ùë°
ùëóùê∫ùë°
ùëñ,Œ¶ ùê∫ùë°
ùëñ,¬¨Œ¶ ùê∫ùë°
ùëñ
(1)
whereùëÉùëêùëìdenotes the probability of ùê∫ùë°
ùëóbeing a valid in-distribution
counterfactual for an adequate description of the original graph ùê∫ùë°
ùëñ
and the class Œ¶(ùê∫ùë°
ùëñ), where¬¨Œ¶(ùê∫ùë°
ùëñ)indicates any other2class from
the one predicted for ùê∫ùë°
ùëñ. Notice that the counterfactual produced
for each graph ùê∫ùë°
ùëñrefers to the same snapshot ùë°.
Within the probabilistic framework, expressed in Eq. 1, prior
work [ 33] focused on discriminative models leading to preliminary
promising results. In this work, we shift towards a generative classi-
fication perspective which allows us to dynamically update invalid
counterfactuals without relying on Œ¶‚Äôs outdated classifications.
4 A GENERATIVE CLASSIFICATION
PERSPECTIVE
This section studies generative classifiers for robust inference under
distribution shifts. Moreover, we formally link the generative clas-
sification objective to the reconstruction loss and norms in latent
variable models, which allows for efficient inference using VGAEs.
Generative Classification. Generative classifiers (GCs, e.g., Ng
and Jordan [26]) are a form of probabilistic models that perform
classification through modeling the full joint distribution of features
ùíôand class labels ùë¶. In contrast to discriminative models, which
only model ùëù(ùë¶|ùíô), they explicitly represent ùëù(ùíô|ùë¶)and predict
the most likely label ÀÜùë¶via the Chain (or Product) Rule, i.e.,
ÀÜùë¶=argmax
ùë¶‚ààYùëù(ùíô,ùë¶)=argmax
ùë¶‚ààYùëù(ùíô|ùë¶)ùëù(ùë¶)=
=argmax
ùë¶‚ààYlogùëù(ùíô|ùë¶)+logùëù(ùë¶).(2)
In prior work, GCs have been attested to superior generalization ca-
pabilities over discriminative classifiers (DCs) under dataset shifts
[34,38], accurately calibrated posteriors [ 3], and increased adver-
sarial robustness [ 21]. A probabilistic model is required to model
the class conditional densities. In this work, we rely on Variational
Graph Autoencoders [17].
Variational Graph Autoencoders (VGAEs). We consider the fol-
lowing generative model where the graphs ùê∫are generated from
factored latent representation ùíõ=
ùíõùë£1,..., ùíõùë£ùëõ
, and the true class
labelùë¶:
ùëù(ùê∫|ùë¶)=‚à´
ùíõ‚ààZùëù(ùê∫|ùíõ,ùë¶)ùëù(ùíõ|ùë¶)ùëëùëß (3)
To represent ùëù(ùê∫|ùë¶), we use a single VGAE for each class ùë¶‚ààY,
which is dependent on the class where each node has a latent vector
and then define
ùëùùúÉùë¶(ùê∫|ùíõ,ùë¶)=ùëùùúÉùë¶(ùë®,ùëø|ùíõ,ùë¶)
=ùëùùúÉùë¶(ùëø|ùë®,ùíõ,ùë¶)ùëùùúÉùë¶(ùë®|ùíõ,ùë¶)(4)
where first the edges (or their probabilities) ùë®are computed and
the node features ùëøare reconstructed subsequently. Each decoder
2The provided formulation supports multi-class classification problems. For simplicity,
we concentrate on binary classification only.
 
2422KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain Bardh Prenkaj, Mario Villaiz√°n-Vallelado, Tobias Leemann, and Gjergji Kasneci
depends on parameters ùúÉùë¶for the respective class ùë¶. The respective
joint distributions are modeled through probabilistic neural net-
works. We discuss the full parametrization of the generative model
in Sec. A. We let
ùëù(ùíõ)=√ñ
ùë£ùëñùëù ùíõùë£ùëñ=√ñ
ùë£ùëñN ùíõùë£ùëñ;0,ùë∞(5)
be an isotropic Gaussian prior. Such a latent variable model can be
learned using standard variational approximation techniques. In
variational techniques, the intractable inference density ùëû(ùíõ|ùê∫,ùë¶)
required for optimization is approximated through a parametric
distribution family element. If this family is expressive enough, e.g.,
it contains the actual density of the data-generating process, the
variational model will converge to the true likelihood [ 16]. In the
graph setting, we let ùëû(ùíõ|ùëø,ùë®,ùë¶)be a factorized representation,
ùëûùúëùë¶(ùíõ|ùê∫,ùë¶)=√ñ
ùë£ùëñùëûùúëùë¶ ùíõùë£ùëñùê∫,ùë¶(6)
and specifically model ùëû ùëßùë£ùëñùê∫,ùë¶=N ùëßùë£ùëñùùÅùë£ùëñ,ùõæ2ùë∞,
ùùÅ=
ùùÅùë£1,..., ùùÅùë£ùëõ
=GCNùúëùë¶(ùê∫)is a matrix of mean vectors com-
puted by a Graph Convolutional Network (GCN) with parameters
ùúëùë¶, whereùõæ2>0is a fixed hyperparameter.
As in Kipf and Welling [17], we train VGAEs for each of the
classes by optimizing the parameters ùúÉandùúëin the objective
ELBOùë¶ ùúÉùë¶,ùúëùë¶=E
ùëûùúëùë¶(ùíõ|ùê∫,ùë¶)
logùëùùúÉùë¶(ùê∫|ùíõ,ùë¶)
‚àíKLh
ùëûùúëùë¶(ùíõ|ùê∫,ùë¶)ùëù(ùíõ)i(7)
where KL[ùëû(¬∑)||ùëù(¬∑)]is the Kullback-Leibler divergence between
ùëû(¬∑)andùëù(¬∑). Through maximization of the ELBO, we obtain opti-
mal parameters, which we denote by

ùúÉ‚àó
ùë¶,ùúë‚àó
ùë¶
=argmax
ùúÉùë¶,ùúëùë¶ELBOùë¶ ùúÉùë¶,ùúëùë¶‚àÄùë¶‚ààY (8)
Having obtained a generative latent variable model of a specific
classùë¶according to Eq. 8, we can now exploit its power to per-
form generative classification. If the variational family is expressive
enough, i.e., it actually covers the true data-generating distribution,
the ELBO converges to the logarithm of the true class-conditional
probability logùëù(ùê∫|ùë¶). Therefore, we can use the generative mod-
els to compare different class probabilities and perform generative
classification. Instead of maximizing the ELBO, we can equivalently
minimize the negative ELBO, which has a surprisingly interpretable
form in the variational model supposed in this work, as distilled in
the following proposition:
Proposition 1 (Comparing Distance-Augmented Reconstruc-
tion Losses performs Implicit GC). If the density model in Eqs.
(4)-(6)is sufficiently expressive, i.e., it covers the true data generating
process, computing
ÀÜùë¶=argmin
ùë¶‚ààY1
2
E
ùëûùúë‚àóùë¶(ùíõ|ùê∫,ùë¶)"‚à•ùëîùúÉ‚àóùë¶(ùíõ)‚àíùê∫‚à•2
2
ùúé2#
+‚à•ùëìùúë‚àóùë¶(ùê∫)‚à•2
2
‚àílogùëù(ùë¶),
is equivalent to performing generative classification for an input graph
ùê∫, whereùëìùúë‚àóandùëîùúô‚àóare graph encoding and decoding networks,
respectively.We provide the reformulation of the ELBO in Sec. A and proof
of the proposition in Sec. B. From the above proposition, we see
that adding the reconstruction loss3and the distance from the
origin of the latent representation while compensating for the prior
class probability implicitly performs generative classification. The
above result comes with several implications. First, once we have a
trained variational model, we can perform efficient classification by
simply embedding the samples with the respective autoencoders
and computing the reconstruction loss and latent norm. Second,
our proposition might explain prior work‚Äôs [ 33] success in using
autoencoders to represent the data distributions and leveraging the
reconstruction loss. In the remainder of this work, we will show
that the performance can be substantially improved by continuing
on the path set out through our theoretic considerations.
5 METHOD
Here, we present GRACIE, namely Graph Recalibration and Adaptive
Counterfactual Inspection and Explanation. GRACIE4is a counter-
factual explanation method that leverages Œ¶at the initial snapshot
ùë°0to acquire insights into the underlying data distribution and iden-
tify valid counterfactual instances. Importantly, GRACIE achieves
this without relying on potentially outdated decision boundaries for
snapshotsùë°ùëñ+1>ùë°ùëñ. We omit the time superscript in the formulas
to enhance clarity, except when necessary.
Training. To untap the generative classification capabilities, we
need to obtain a latent variable model for a specific class ùë¶by op-
timizing the ELBO as in Eq. 8. In binary classification problems,
GRACIE relies on two VGAEs, Œ©0,Œ©1:G‚ÜíG , corresponding to
the negative and positive classes. They are responsible for learn-
ing the representation of each class separately. In this way, each
VGAE intuitively constructs an embedding space that is limited to
instances that belong to the same input distribution since, at ùë°0, we
feedùê∫ùëñ‚ààGtoŒ©ùë¶s.t.ùë¶=Œ¶(ùê∫ùëñ). The encoder of the VGAEs is a
2-layered GCN. Differently from [ 17], we rely on the Graph Atten-
tion Network decoder proposed in [ 15] to modelùëùùúÉùë¶(ùë®|ùíõ,ùë¶), and
thus reconstruct the adjacency matrix. Note that the encoder and
the decoder have different parameters ùúÉùë¶,ùúëùë¶, which depend on ùë¶.
Maximizing the ELBO in Eq. 8 can be equivalently expressed
as the minimization of the following objective function, assuming
that we have equal priors:
‚àíELBOùë¶ ùúÉùë¶,ùúëùë¶‚àùLùëüùëíùëê+Lùëëùëñùë†ùë°
‚àù1
2
E
ùëûùúëùë¶(ùíõ|ùê∫)||ùëîùúÉùë¶(ùíõ)‚àíùê∫||2
2
ùúé2
+||ùëìùúëùë¶(ùê∫)||2
2(9)
We refer interested readers to the derivation of this term in Appen-
dix A. By optimizing Eq. 9 for each VGAE, we learn to correctly
reconstruct the input graphs via Lùëüùëíùëêand maintain the embeddings
close to the center of the latent space via Lùëëùëñùë†ùë°.
Unlike other works in graph autoencoders [ 12,15], we recon-
struct the node features and the graph topology. Thus, we ensure
that the latent space of each VGAE correctly represents the distin-
guishing edges instead of just the node features of the graphs.
3We write‚à•ùê∫‚àíùê∫‚Ä≤‚à•2
2for graphsùê∫=(ùëø,ùë®),ùê∫‚Ä≤=(ùëø‚Ä≤,ùë®‚Ä≤)as a shorthand for
‚à•ùë®‚àíùë®‚Ä≤‚à•2
2+‚à•ùëø‚àíùëø‚Ä≤‚à•2
2.
4https://github.com/bardhprenkaj/HANSEL
 
2423Unifying Evolution, Explanation, and Discernment: A Generative Approach for Dynamic Graph Counterfactuals KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain
123456712345671234567...1234567
D ata at time
Figure 2: Search for top- ùëòcounterfactual candidates at infer-
ence time. ùê∫ùë°‚àóis mapped to ùíõ=ùëìùúë‚àó
1‚àíÀÜùë¶(ùê∫ùë°‚àó)and pulled towards
the center ( ùíõ‚àó=ùúÜùíõ). Other graphs ùê∫ùë°
1,...,ùê∫ùë°ùëõalso mapped to
the latent space of ùëìùúë‚àó
1‚àíÀÜùë¶. Based on prior learned embedding
(circles), class 1‚àíÀÜùë¶instances move closer to the center, while
the same class ÀÜùë¶instances shift away (rectangles). Triangles
denote counterfactual candidates closest to ùíõ‚àó.
Inference and Counterfactual Generation. Having obtained the
latent variable model, we can perform inference according to Propo-
sition 1. For a never-seen-before instance, ùê∫ùë°‚àós.t.ùë°>0, we first
compute the most likely class ÀÜùë¶by evaluating the reconstruction
loss and the latent norm for each class-specific VGAE. In this way,
we can assign ùê∫ùë°‚àóto class ÀÜùë¶, and use Œ©1‚àíÀÜùë¶as the VGAE to find
counterfactual candidates. In more detail, we use the encoder of
Œ©1‚àíÀÜùë¶to compute ùíõ=ùëûùúô‚àó
1‚àíÀÜùë¶ ùê∫ùë°‚àó, i.e., the latent representation for
ùê∫ùë°‚àó. Now, since our goal is to pull the representations as close to the
center of the latent space as possible, we can go inside the learned
region by setting ùíõ‚àó=ùúÜùíõ, whereùúÜ‚àà(0,1). Notice that as the prob-
ability for class 1‚àíÀÜùë¶increases as we approach the center, GRACIE
refines its search space for suitable counterfactuals. Now, we map
the rest of the instances in snapshot ùë°into the same latent space
ofŒ©1‚àíÀÜùë¶and find the top- ùëòclosest representations to ùíõ‚àó. Since ùíõ‚àó
lies near the center of the latent space, the found counterfactuals
should also be close by. In this way, the top- ùëòcounterfactuals are
expected to be reliable since they share the same characteristics
of the instances in ùë°‚àí1thatŒ©1‚àíÀÜùë¶has learned to represent. Fig. 2
illustrates the search for counterfactuals.
Dynamic update. In snapshots ùë°>ùë°0, we do not rely on Œ¶‚Äôs
predictions since they might not represent the reality of the new
data (see Fig. 1). Instead, we use the learned representation of the
VGAEs. As described above, at inference, for each graph ùê∫ùë°‚àó, we find
ùëòcandidate counterfactuals close to the center of the Œ©1‚àíÀÜùë¶with
the generatively predicted class ÀÜùë¶. We can use these counterfactuals
to update Œ©1‚àíÀÜùë¶, andùê∫ùë°‚àóto update Œ©ÀÜùë¶. In this way, both VGAEs
reflect their representations according to the changes in the data.
In the next snapshots, GRACIE is fully unsupervised, relying only
on its generative classification power to search for counterfactuals
and recalibrate the VGAEs representations. We also update logùëù(ùë¶)
according to the classifications in the current snapshot for each
graph and counterfactuals found, such that the classification in the
next snapshots can reflect potential shifts in the class priors.6 EXPERIMENTS
6.1 Datasets, hyperparameters, and evaluation
Datasets. We test GRACIE on a synthetic dataset, namely Dyn-
TreeCycles, generated according to [ 30], and four real datasets,
namely DBLP-Coauthors [ 5], BTCAlpha, BTC-OTC [ 19], and Bo-
nanza [ 6]. We extend TreeCycles [ 42] by introducing the time di-
mension, allowing graphs to evolve in time and potentially change
their class, and name it DynTreeCycles (DTC). DBLP-Coauthors
(DBLP) is a dataset of graphs representing coauthor relationships
where the edge weights indicate the number of collaborations be-
tween two authors in a particular year. We use BTCAlpha (BTC- ùõº)
to have an initial investigation for our fraud detection example.
The dataset is a network of who-trust-whom traders on the Bitcoin
Alpha platform, where each trader expresses a trust score ranging
from -10 to +10 on other platform members. BTC-OTC (BTC- ùõΩ)
is a similar dataset to BTC- ùõºbased on the Bitcoin OTC platform.
Bonanza (BNZ) is a marketplace where users can buy/sell goods.
After a purchase, buyers and sellers can rate each other (+1, 0, -1).
All datasets have binary classes. Sec. C provides more details.
Evaluation metrics. We use Validity and Graph Edit Distance
(GED) [32] as evaluation metrics. Since we return a list of counter-
factuals for each input graph, we evaluate GRACIE by reporting
values of these metrics @1,..., @ùëò.
Given a graph ùê∫and a set of counterfactual candidates G‚Ä≤, Va-
lidity@k measures the correctness of counterfactuals up to the k-th
position. Validity (i.e., Validity@1) assesses whether an individual
counterfactual graph ùê∫‚Ä≤at position 1 inG‚Ä≤is a correct counter-
factual of the input graph ùê∫(i.e., 1[Œ¶(ùê∫)‚â†Œ¶(ùê∫‚Ä≤)]). Validity@k
extends this assessment, defined as in Eq. 10.
Validity(ùê∫,G‚Ä≤,ùëò)=max
ùëñ‚àà[1,ùëò]1
Œ¶(ùê∫)‚â†Œ¶(G‚Ä≤
ùëñ)
(10)
In simpler terms, Validity@k is 1 if at least one counterfactual up
to the k-th position in G‚Ä≤is a correct counterfactual of the input
graphùê∫. We expect the more counterfactuals we sample from the
latent space, the higher the Validity@k is (see Sec. 6.3).
GED measures the structural difference between ùê∫and its coun-
terfactualùê∫‚Ä≤. It calculates the distance based on a set of actions
ùëù1,ùëù2,...,ùëùùëõ‚ààP(ùê∫,ùê∫‚Ä≤), representing paths to transform ùê∫into
ùê∫‚Ä≤. These paths involve adding or removing vertices or edges, with
each actionùëùùëñassociated with a cost ùúî(ùëùùëñ). We prefer the one closer
to the original instance ùê∫when comparing two counterfactual ex-
amples. Given ùê∫and a set of counterfactuals G‚Ä≤, GED@k is the
average GED of all ùëòcounterfactual candidates, as shown in Eq. 11.
GED(ùê∫,G‚Ä≤,ùëò)=1
ùëòùëò‚àëÔ∏Å
ùëó=1
min
{ùëù1,...,ùëù ùëõ}‚ààP(ùê∫,G‚Ä≤
ùëó)ùëõ‚àëÔ∏Å
ùëñ=1ùúî(ùëùùëñ)
(11)
Fair training/evaluation policy. We split the data using a 90:10
train-test ratio. For each method, we report averages on 10-fold
cross-validation. All methods share the same folds and portion of
the train-test sets on each fold. We use omniscient oracles for each
dataset to model the ground truth at each snapshot. This guarantees
that the methods are evaluated on the real classes.
Baselines. We compare against the only time-dependent approach
in the literature, namely DyGRACE [ 33]. For completeness, we
 
2424KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain Bardh Prenkaj, Mario Villaiz√°n-Vallelado, Tobias Leemann, and Gjergji Kasneci
Table 1: Average of Validity@1 (the higher, the better) on
10-fold cross-validations for all snapshots in each dataset.
Bold values indicate the best-performing approach; under-
lined is the second best; ‚Ä†indicates partial results due
to non-convergence on some time steps; √óindicates non-
convergence at alla.
D
TC DBLP BTC- ùõºBTC-ùõΩ BNZ
BDDS 0.465 0.381 0.360‚Ä†0.235
0.136
MEG 0.250 0.209√ó 0.260
0.120‚Ä†
CLEAR 0.458 0.024 0.214 0.125 0.000
G-CounteRGAN 0.507 0.256 0.236√ó 0.404
D
yGRACE 0.525
0.307 0.232 0.000‚Ä†0.232
GRA
CIE 0.600 0.442 0.440 0.284 0.441
aThe criterion of non-convergence is to fail to produce at least one counterfactual
within 14 days of execution on an HPC SGE Cluster of 6 nodes with 360 cumulative
cores, 1.2Tb of RAM, and two GPUs (i.e., one Nvidia A30 and one A100).
adapt CLEAR [ 24] and G-CounteRGAN [ 25], two recent genera-
tive and time-unaware graph counterfactual explainers. We also
compare against a heuristic- and a learning-based method, namely
BDDS [ 1] and MEG [ 27], respectively. We train the explainers5on
the first snapshot and use them to produce counterfactuals in the
other snapshot without further updates on their learned weights.
Hyperparameters. We obtain the best hyperparameters for GRA-
CIE via Bayesian optimization. We set the learning rate to 10‚àí3; the
batch size to 64for DTC and DBLP, to 24for BTC-ùõºand BTC-ùõΩ, and
1for BNZ;ùúÜ=0.5; the replace rate for the autoencoder to 0.1; the
mask rate to 0.5; the number of attention heads to 16[15]. We set
the number of epochs for DTC to 200and100for the other datasets.
We setùëò=50for DTC and ùëò=10for the others. Sec. D shows the
hyperparameter search spaces and the best choice for all methods.
6.2 Results
Table 1 shows the average Validity@1 over 10-fold cross-validations
for all snapshots in each dataset. GRACIE is the best overall with
an average improvement of 14.3%, 16%, 22.2%, 9.23%, and 3.76%
on, respectively, DTC, DBLP, BTC- ùõº, BTC-ùõΩ, and BNZ over the
second-best performing strategy. We first conduct a Friedman Test
to show that GRACIE has, statistically and significantly, the best
performance across the board. Here, we obtain a test statistic equal
to15.920with a p-value of .0071. Since the p-value is less than .05,
we can reject the null hypothesis that the average Validity@1 scores
across all datasets are the same for all methods. Then, we perform
a Bonferroni-Dunn post-hoc test where the control explainer is
GRACIE. The corrected p-value, according to Bonferroni, is .05/5=
.01, where 5is the number of comparisons (i.e., GRACIE vs. BDDS,
GRACIE vs. MEG, etc.). The test suggests that GRACIE is statistically
and significantly different (better) across the board (see Table 2).
Fig. 3 shows the Validity@1 and GED@1 of all methods in different
snapshots. GRACIE reaches an average improvement per snapshot
of as much as 23.1%, 73.3%, 120.6%, 36.2%, and 115.7% in DTC, DBLP,
BTC-ùõº, BTC-ùõΩ, and BNZ, respectively, in Validity@1 over the SoA.
5BDDS is not trained. It perturbs the input graph until it finds a counterfactual.Table 2: P-values produced by the Dunn post-hoc test (with
and without the Bonferroni correction) where the control
explainer is GRACIE.
GRA
CIE
w/o
Bonferroni
(p-value.05)w/ Bonferroni
(p-value.01)
BDDS 2.472√ó10‚àí63.708√ó10‚àí5
MEG 1.784√ó10‚àí152.676√ó10‚àí14
G-CounteRGAN 1.090√ó10‚àí51.635√ó10‚àí4
CLEAR 9.354√ó10‚àí131.403√ó10‚àí11
D
yGRACE 2.014√ó10‚àí63.021√ó10‚àí5
Assessing counterfactuals in synthetic scenarios with subtle distri-
butional variations. DTC is a synthetic scenario where the distribu-
tional shifts are not evident. Here, GRACIE has better Validity@1
than the SoA on 3/4 snapshots. CLEAR and G-CounteRGAN sample
from the learned edge probabilities, and do not guarantee break-
ing cycles when going from a cyclic graph to a tree. They have a
Validity@1 of‚àº0.5on all snapshots since they produce complete
stochastic graphs and valid counterfactuals when the input instance
is a tree. This inherent drawback of producing complete graphs
causes these methods to have large GED@1. Only MEG has oscilla-
tory Validity@1, which does not surpass the search-based baseline
BDDS. Lastly, as expected, BDDS has the lowest GED@1 since it
specifically optimizes to minimize it.
Counterfactual performance on real-world datasets. In DBLP, GRA-
CIE outperforms the second-best, BDDS, on 8/11 snapshots. Dy-
GRACE has compelling results for the first snapshot but cannot
discern factuals from counterfactuals in later stages, lacking be-
hind GRACIE of a factor of ‚àº2in snapshots 7-10. Additionally,
while GRACIE‚Äôs Validity@1 has a non-decreasing trend, DyGRACE
plummets, favoring closer counterfactuals to the original graph
despite this major drop. We argue that having valid counterfac-
tuals is more important than being closer to the original graph
without crossing the decision boundary. CLEAR fails to produce
valid counterfactuals, defaulting to returning the original instance,
which accounts for a GED@1 of zero. G-CounteRGAN has a high
standard error in Validity@1, making it the least reliable explainer.
We argue that image-based convolutional operations adopted as
in G-CounteRGAN make it unsuitable for real-world scenarios
with complex topologies. MEG shows drastically fluctuating per-
formances in Validity@1, suggesting that DBLP suffers extremely
from data distribution shifts. Additionally, with each passing snap-
shot, MEG overshoots on the other side of Œ¶‚Äôs decision boundary,
translating into an increasing trend in terms of GED@1.
Interestingly, in BTC- ùõºand BTC-ùõΩ, the edge directionality is a
challenging representation task for GCNs (also noticed in [ 36]). Nev-
ertheless, GRACIE can represent the edges‚Äô directionality, reporting
the best Validity@1 on all snapshots. In BTC- ùõº, G-CounteRGAN
has a random zig-zag trend on Validity@1, attributed to spurious
learning of the edge probabilities on which counterfactuals are
sampled. CLEAR has the best GED@1 among the competitors, al-
though it is the worst in producing valid counterfactuals. Notice
that GRACIE becomes better at producing valid counterfactuals
(upward Validity@1 trend) and can also search for more similar
 
2425Unifying Evolution, Explanation, and Discernment: A Generative Approach for Dynamic Graph Counterfactuals KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain
GRA CI EG-CounteRGAND y GRA CEBDDSCLEARMEG0.001230.20.40.60.8V alidity@1D T C
401230.00.10.20.30.40.5BT C-
100123456789DBLP
0.00.10.20.30.40.50.6
1311120123456789100.00.10.20.30.40.50.6BT C-
01234Snapshot050100150200
012345678910Snapshot0100200300400500
3012GED@1Snapshot101210
012345678910111213Snapshot1012310100.00.20.40.60.8
01234BNZ
Snapshot0020040060080010001200
1234
Figure 3: Average Validity@1 (the higher, the better ) and GED@1 (the lower, the better ) on 10-fold cross-validation.
ones w.r.t. the original graph (non-increasing GED@1 trend). Notice
that BDDS does not produce results for all snapshots since it fails
to converge its search space. Lastly, G-CounteRGAN considers the
adjacency matrix a black-and-white image, which does not produce
valid results. Moreover, the plain image convolution operations do
not consider the real topology of the graph, which is node-invariant.
Rather, they consider each node as a fixed pixel in a grid, making
its GED@1 extremely high compared to the SoA.
BTC-ùõΩis the only dataset where DyGRACE cannot produce valid
counterfactuals in the first snapshot. On the other snapshots, it does
not converge within 14 days of execution. After careful examination,
we believe that the training set of the linear regression used to sepa-
rate the factual from counterfactuals is too resource-demanding (i.e.,
a Cartesian product on the learned graph representations), exceed-
ing 13 TB of memory. G-CounteRGAN exceeds 64 TB of memory
due to its flattened downstream linear layers after the convolution
operations. We invite the reader to appreciate this dataset‚Äôs com-
plexity since SoA approaches cannot reach a Validity@1 of more
than‚àº0.3in many snapshots. Nevertheless, GRACIE‚Äôs Validity@1
trend leads us to believe that the two VGAEs tend to become ex-
perts in correctly representing the two classes after a while (e.g.,
cold-start). We will investigate this in future works.
In BNZ, GRACIE has the steadiest performance similar to the
second-best, G-CounteRGAN, outperforming it on all snapshots
and presenting half the GED@1. Interestingly, DyGRACE has the
best Validity@1 in the first snapshot ‚Äì better than GRACIE. Nev-
ertheless, it fails to adapt to the data distribution drift in the next
snapshots by not producing valid counterfactual candidates. No-
tice that DyGRACE‚Äôs GED@1 is zero since its default behavior is
to return the original graph if it cannot return a counterfactual.
Moreover, by analyzing the Validity@1 and GED@1 trends for GRA-
CIE, DyGRACE, and G-CounteRGAN, as expected, we can state
that they are directly proportionate. For instance, when GED@1
increases, the Validity@1 does so for GRACIE (see snapshots 0-2).
Contrarily, when GED@1 decreases, the Validity@1 decreases for
G-CounteRGAN. MEG does not converge on many snapshots, and
CLEAR fails to explain Œ¶, defaulting to produce the original graph.
0.33040506070
Pulling factorGED@1
0.50.70.90.30.20.30.40.5V alidity@1Pulling factor0.60.70.8
0.50.70.9Figure 4: Validity@1 and GED@1 vs. the pulling factor ùúÜ.
6.3 Ablation studies
ùúÜ‚Äôs impact on validity and recourse cost: unveiling counterfac-
tual trade-offs. Fig. 4 illustrates Validity@1 and GED@1 when the
pulling parameter ùúÜchanges on DBLP. As expected from the the-
oretical observations in Sec. 5, the lower the pulling factor, the
better the chances of finding valid counterfactuals, but the farther
they are w.r.t. the original graph. Contrarily, the higher the pulling
factor, the lower the validity, and the nearer the counterfactuals
(see dashed lines). In other words, for a graph ùê∫‚àówith generated
classification ÀÜùë¶and its latent representation ùíõ‚àó=ùúÜùëìùúë‚àó¬¨ùë¶(ùê∫), when
ùúÜ‚Üí0the pulling factor makes ùíõ‚àógo towards the center of the
space. This pulling phenomenon aids ùíõ‚àóin finding neighboring
instances that have a high chance of being valid counterfactuals
sinceùëìùúë‚àó¬¨ùë¶is specialized for their representation. Contrarily, the
instances most distant to ùíõ‚àó, which is now mapped near the center,
are likely to be invalid counterfactuals (cf. Proposition 1). Thus, they
get discarded in the ‚Äúupdate‚Äù policy. While we prefer to achieve
a higher validity in finding counterfactuals, ùúÜis a parameter that
permits users to define the trade-off between counterfactual-factual
discernment and generation cost (notice the upward Validity@1
and GED@1 trends when ùúÜ‚Üí0).
Valid counterfactual sampling in the latent representation space.
Fig. 5 illustrates the trend of the Validity@k on 10-fold cross-
validations. Here, we illustrate box plots that indicate the distribu-
tion of the performances for a specific ùëòaggregated for all snapshots.
 
2426KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain Bardh Prenkaj, Mario Villaiz√°n-Vallelado, Tobias Leemann, and Gjergji Kasneci
BT C-
12345678910Numb er of counterfactual candidates
12345678910D T CV alidity@k0.00.20.40.60.81.0
DBLP
12345678910Numb er of counterfactual candidatesNumb er of counterfactual candidates
Numb er of counterfactual candidates
BT C-
1234567891012345678910Numb er of counterfactual candidatesBNZ
Figure 5: Validity (averages on 10-fold cross-validations) trend over all snapshots grouped on the top- ùëòcounterfactual candidates.
Numb er of counterfactual candidatesBT C-
Numb er of counterfactual candidatesBT C-2010
2011
20132011V alidity@k
Figure 6: Validity trend on the top- ùëòsampled counterfactuals
expanded for BTC- ùõºand BTC-ùõΩ. The dashed lines illustrate
those snapshots representing the inliers in the box plots of
Fig. 5. The filled lines are outliers for a specific ùëò.
The plots show that GRACIE benefits from sampling multiple coun-
terfactual candidates, thus leading to consistently better results.
The sampling trend indicates a clear improvement from Validity@1
to Validity@k. Interestingly, in BTC- ùõºand BTC-ùõΩ, Validity@k is
influenced by outlier scores for particular snapshots, as illustrated
via diamonds. We noticed that the training set of several folds in
the first portions of the monitoring time contains ego networks
with similar structures but different edge weights labeled as fraud
and genuine users. In this way, these similar graphs were used to
train the two VGAEs, which learn a similar representation of both
classes, making it difficult to separate them and correctly update the
counterfactuals in successive snapshots. Fig. 6 expands the box-plot
view for BTC- ùõºand BTC-ùõΩof Fig. 5. Here, we show the average
Validity@k for each snapshot expressed in years. The dashed lines
illustrate those years where the average Validity is an inlier w.r.t. to
the box plots of Fig. 5. Meanwhile, full lines show those values for
eachùëòthat are outliers. Notice that there is a one-to-one correspon-
dence with the diamonds (outliers) in Fig. 5 and the highlighted lines
in Fig. 6 for BTC- ùõºand BTC-ùõΩ. For instance, in BTC- ùõº, notice how
the Validity@ ùëòin 2013 is normal until ùëò‚àà{9,10}. Interestingly,
in BTC-ùõΩ, 2011 is an outlier for ùëò‚àà[3,10]. Verifying the validity
trend for 2011, we notice that it is the lowest across the board. This
makes us believe that the graphs of the two classes do not have
emphasizing and distinguishable topological characteristics w.r.t.
the other years (snapshots).
6.4 Qualitative Inspection
Fig. 7 illustrates the difference in adjacency matrices between 8
randomly chosen instances from the test set in DTC and their corre-
sponding valid counterfactuals in each snapshot. In each adjacency
10Snapshots
1232345678Figure 7: (best viewed in color) Valid counterfactuals pro-
duced by GRACIE on 8 randomly chosen graphs in the test
set (columns) in DTC for each snapshot.
matrix, we color with white if the edge is neither in the input in-
stance nor in the counterfactual candidate; with redthe removal
of the edge from the original input; with green an addition of the
edge in the counterfactual; and with black an edge both in the input
instance and the counterfactual. This pictorial briefly overviews the
most preeminent edge operations (i.e., adding or removing edges)
and the GED@1 between the original graph and its counterfactual.
For example, a method with a lower GED@1 exposes an overall
blacker image board since there are fewer perturbations on the
original graph. A green-dominated sub-block indicates generating
non-existing edges, while one dominated by red means many re-
moved edges. GRACIE exposes a mixture of the three colors, which
suggests that it supports all three edge perturbation operations. We
are aware that the counterfactuals shown here exhibit many edge
perturbation operations (also supported by the GED@1 in Fig. 3)
due to GRACIE‚Äôs learning procedure. Recall from Sec. 5 that each
VGAE learns to represent graphs of the same class. At inference,
for a graphùê∫‚àówith predicted class ÀÜùë¶(see Proposition. 1), GRACIE
searches for the counterfactuals in the latent space of the VGAE
responsible for representing the opposite class 1‚àíÀÜùë¶. As shown
in Fig. 2,ùê∫‚àógets mapped into ùíõand then pulled inwards to ùíõ‚àó,
shifting the real representation towards the center of the latent
space. Here, the nearest counterfactuals do not necessarily have the
lowest GED w.r.t. ùê∫‚àósince we prioritize producing valid counter-
factuals ratherthan closer ones. Notice that one can use the pulling
factorùúÜto engender counterfactuals with lower GED@1 (see Fig.
4). We will investigate how to optimize for GED (a non-convex
and non-differentiable function) to jointly find valid and similar
counterfactuals for a given input graph in future works.
 
2427Unifying Evolution, Explanation, and Discernment: A Generative Approach for Dynamic Graph Counterfactuals KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain
GRA CI E v s BDDS
a)
e )
c)
d)
b )
0123
Figure 8: (best viewed in color) Qualitative illustration of the difference between the counterfactual candidates produced by
GRACIE and BDDS on all snapshots (rows) on 10%randomly chosen graphs of the test set (columns) in DTC. Each element in
the illustration represents the adjacency matrix of the graphs. We zoom in on three scenarios: a), c), and e) both explainers
produce valid counterfactuals, b) GRACIE fails, and d) BDDS fails.
Since GRACIE and BDDS expose the most similar behavior on
average on all datasets (see Table 1), we decided to directly com-
pare them to understand which is their generation behaviors. Fig.
8 showcases a comparative view of counterfactual candidates gen-
erated by GRACIE and BDDS on DTC. For visualization clarity, we
chose here to represent only 10%of randomly selected graphs from
the test set in the entire dataset. Each image sub-block represents
an adjacency matrix of the produced counterfactual candidate. The
visual encoding employs colors to highlight differences between
the counterfactual outputs of the two explainers. Common edges
shared by both counterfactuals are shaded in black, symbolizing
consensus between the methods. Additionally, edges exclusively
generated by BDDS and not by GRACIE are colored in orange. On
the other hand, edges solely engendered by GRACIE, but not BDDS,
are depicted in blue. The illustration also accounts for graphs where
neither explainer produces a valid counterfactual; these instances
remain blank image sub-blocks within the visualization. Further-
more, instances wherein only one explainer successfully generates
a counterfactual are represented by single-colour adjacency ma-
trices. For instance, a matrix entirely orange implies that GRACIE
fails to produce valid counterfactuals for that instance.
In contrast, a fully blue matrix shows that BDDS fails to gener-
ate viable counterfactuals. Note that GRACIE performs more edge
operations than BDDS (i.e., notice the higher concentration of blue
in the adjacency matrices, as supported by the GED trend in Fig. 3).
Oppositely, BDDS exposes fewer edges in total (i.e., the sum of black
and orange edges vs the sum of black and blue for GRACIE). This
phenomenon is due to BDDS‚Äôs underlying oblivious bidirectional
search mechanism, which tries to add/remove edges at each itera-
tion until it reaches a valid counterfactual until a maximum number
of iterations is reached. This visualization effectively highlights thedifferences between GRACIE and BDDS in producing counterfac-
tual candidates across the specified datasets and instances, offering
insights into their strengths and weaknesses.
7 CONCLUSION
We presented GRACIE, one of the first generative approaches to
address dynamic counterfactual explainability in the context of
temporal graphs. GRACIE leverages VGAEs, self-supervisedly, to
learn class representations and adapt to data distribution shifts that
might invalidate counterfactuals in time. Unlike other approaches,
GRACIE does not assume linear separatability between the latent
representations. We performed extensive experiments on one syn-
thetic and four real-world dynamic graph datasets, with an im-
provement of‚àº13.1%in producing more valid counterfactuals than
SoA approaches. We demonstrated that exploiting the pulling factor
aligns with our intuition that the center of the latent space of the
VGAEs should be used to find valid counterfactuals, maintaining
a good trade-off with the similarity with the input. We also illus-
trated that sampling more candidates near the latent representation
produces valid counterfactuals.
In the future, we will explore multi-class problems and the ability
of GRACIE to generalize, simultaneously producing valid never-
seen-before counterfactuals for multiple classes. Another avenue
for investigation is to improve the class representations via more
potent generative models. Lastly, we will incorporate uncertainty in
determining valid counterfactuals during their search in the latent
space. A possible direction could be to rely on hyperbolic spaces
and exploit their intrinsic uncertainty modeling.
 
2428KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain Bardh Prenkaj, Mario Villaiz√°n-Vallelado, Tobias Leemann, and Gjergji Kasneci
REFERENCES
[1]Carlo Abrate and Francesco Bonchi. 2021. Counterfactual graphs for explainable
classification of brain networks. In Proc. of the 27th ACM SIGKDD Conference on
Knowledge Discovery & Data Mining. 2495‚Äì2504.
[2]Uri Alon and Eran Yahav. 2021. On the Bottleneck of Graph Neural Networks
and its Practical Implications. In 9th International Conference on Learning Repre-
sentations, ICLR 2021, Virtual Event, Austria, May 3-7, 2021. OpenReview.net.
[3]Lynton Ardizzone, Radek Mackowiak, Carsten Rother, and Ullrich K√∂the. 2020.
Training normalizing flows with the information bottleneck for competitive
generative classification. Advances in Neural Information Processing Systems 33
(2020), 7828‚Äì7840.
[4]Mohit Bajaj, Lingyang Chu, Zi Yu Xue, Jian Pei, Lanjun Wang, Peter Cho-Ho
Lam, and Yong Zhang. 2021. Robust counterfactual explanations on graph neural
networks. Advances in Neural Information Processing Systems 34 (2021), 5644‚Äì
5655.
[5]Austin R Benson, Rediet Abebe, Michael T Schaub, Ali Jadbabaie, and Jon Klein-
berg. 2018. Simplicial closure and higher-order link prediction. Proc. of the
National Academy of Sciences 115, 48 (2018), E11221‚ÄìE11230.
[6]Tyler Derr, Cassidy Johnson, Yi Chang, and Jiliang Tang. 2019. Balance in
signed bipartite networks. In Proc. of the 28th ACM International Conference on
Information and Knowledge Management. 1221‚Äì1230.
[7]Finale Doshi-Velez and Been Kim. 2017. Towards a rigorous science of inter-
pretable machine learning. arXiv preprint arXiv:1702.08608 (2017).
[8]Yingtong Dou, Zhiwei Liu, Li Sun, Yutong Deng, Hao Peng, and Philip S Yu. 2020.
Enhancing graph neural network-based fraud detectors against camouflaged
fraudsters. In Proc. of the 29th ACM international conference on information &
knowledge management. 315‚Äì324.
[9]European Union. 2016. Regulation (EU) 2016/679 of the European Parliament
and of the Council. Official Journal of the European Union (2016).
[10] European Union. 2023. Laying Down Harmonised Rules on Artificial Intelligence
(Artificial Intelligence Act) and Amending Certain Union Legislative Acts. Official
Journal of the European Union (2023).
[11] L. Faber, A. K. Moghaddam, and R. Wattenhofer. 2020. Contrastive Graph Neural
Network Explanation. In Proc. of the 37th Graph Repr. Learning and Beyond
Workshop at ICML 2020. Int. Conf. on Machine Learning, 28.
[12] Shaohua Fan, Xiao Wang, Chuan Shi, Emiao Lu, Ken Lin, and Bai Wang. 2020.
One2multi graph autoencoder for multi-view graph clustering. In proceedings of
the web conference 2020. 3070‚Äì3076.
[13] Wenqi Fan, Yao Ma, Qing Li, Yuan He, Eric Zhao, Jiliang Tang, and Dawei Yin.
2019. Graph neural networks for social recommendation. In The world wide web
conference. 417‚Äì426.
[14] Johannes Haug and Gjergji Kasneci. 2021. Learning parameter distributions to
detect concept drift in data streams. In 2020 25th International Conference on
Pattern Recognition (ICPR). IEEE, 9452‚Äì9459.
[15] Zhenyu Hou, Xiao Liu, Yukuo Cen, Yuxiao Dong, Hongxia Yang, Chunjie Wang,
and Jie Tang. 2022. Graphmae: Self-supervised masked graph autoencoders.
InProc. of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data
Mining. 594‚Äì604.
[16] Diederik P Kingma, Max Welling, et al .2019. An introduction to variational
autoencoders. Foundations and Trends¬Æ in Machine Learning 12, 4 (2019), 307‚Äì392.
[17] Thomas N Kipf and Max Welling. 2016. Variational graph auto-encoders. In
NeurIPS Workshop on Bayesian Deep Learning.
[18] Thomas N. Kipf and Max Welling. 2017. Semi-Supervised Classification with
Graph Convolutional Networks. In 5th International Conference on Learning
Representations, ICLR 2017, Toulon, France, April 24-26, 2017, Conference Track
Proc. OpenReview.net.
[19] Srijan Kumar, Bryan Hooi, Disha Makhija, Mohit Kumar, Christos Faloutsos, and
VS Subrahmanian. 2018. Rev2: Fraudulent user prediction in rating platforms.
InProc. of the Eleventh ACM International Conference on Web Search and Data
Mining. 333‚Äì341.
[20] Eren Kurshan and Hongda Shen. 2020. Graph computing for financial crime
and fraud detection: Trends, challenges and outlook. International Journal of
Semantic Computing 14, 04 (2020), 565‚Äì589.
[21] Yingzhen Li, John Bradshaw, and Yash Sharma. 2019. Are generative classi-
fiers more robust to adversarial attacks?. In International Conference on Machine
Learning. PMLR, 3804‚Äì3814.
[22] Zelong Li, Jianchao Ji, and Yongfeng Zhang. 2022. From Kepler to Newton:
Explainable AI for Science Discovery. In ICML 2022 2nd AI for Science Workshop .
[23] Lorenzo Livi and Antonello Rizzi. 2013. The graph matching problem. Pattern
Analysis and Applications 16 (2013), 253‚Äì283.
[24] Jing Ma, Ruocheng Guo, Saumitra Mishra, Aidong Zhang, and Jundong Li. 2022.
CLEAR: Generative Counterfactual Explanations on Graphs. In Advances in
Neural Information Processing Systems, Alice H. Oh, Alekh Agarwal, Danielle
Belgrave, and Kyunghyun Cho (Eds.).[25] Daniel Nemirovsky, Nicolas Thiebaut, Ye Xu, and Abhishek Gupta. 2022. Coun-
teRGAN: Generating counterfactuals for real-time recourse and interpretability
using residual GANs. In Proc. of the Thirty-Eighth Conference on Uncertainty
in Artificial Intelligence, UAI 2022, 1-5 August 2022, Eindhoven, The Netherlands ,
Vol. 180. PMLR, 1488‚Äì1497.
[26] Andrew Ng and Michael Jordan. 2001. On discriminative vs. generative classi-
fiers: A comparison of logistic regression and naive bayes. Advances in neural
information processing systems 14 (2001).
[27] Danilo Numeroso and Davide Bacciu. 2021. Meg: Generating molecular coun-
terfactual explanations for deep graph networks. In 2021 International Joint
Conference on Neural Networks (IJCNN). IEEE, 1‚Äì8.
[28] Martin Pawelczyk, Klaus Broelemann, and Gjergji. Kasneci. 2020. On Counter-
factual Explanations under Predictive Multiplicity. In Proc. of the 36th Conference
on Uncertainty in Artificial Intelligence (UAI). PMLR, 809‚Äì818.
[29] Martin Pawelczyk, Tobias Leemann, Asia Biega, and Gjergji Kasneci. 2023. On
the Trade-Off between Actionable Explanations and the Right to be Forgotten.
InProc. of the Eleventh International Conference on Learning Representations.
[30] Mario Alfonso Prado-Romero, Bardh Prenkaj, and Giovanni Stilo. 2023. Devel-
oping and Evaluating Graph Counterfactual Explanation with GRETEL. In Proc.
of the Sixteenth ACM International Conference on Web Search and Data Mining.
1180‚Äì1183.
[31] Mario Alfonso Prado-Romero, Bardh Prenkaj, and Giovanni Stilo. 2024. Robust
Stochastic Graph Generator for Counterfactual Explanations. In Proc. of the AAAI
Conference on Artificial Intelligence, Vol. 38. 21518‚Äì21526.
[32] Mario Alfonso Prado-Romero, Bardh Prenkaj, Giovanni Stilo, and Fosca Giannotti.
2024. A Survey on Graph Counterfactual Explanations: Definitions, Methods,
Evaluation, and Research Challenges. ACM Comput. Surv. 56, 7 (apr 2024).
[33] Bardh Prenkaj, Mario Villaizan-Vallelado, Tobias Leemann, and Gjergji Kasneci.
2023. Adapting to Change: Robust Counterfactual Explanations in Dynamic Data
Landscapes. arXiv:2308.02353 [cs.LG]
[34] Christian Raymond and Giuseppe Riccardi. 2007. Generative and discriminative
algorithms for spoken language understanding. In Interspeech 2007-8th Annual
Conference of the International Speech Communication Association.
[35] Manon R√©au, Nicolas Renaud, Li C Xue, and Alexandre MJJ Bonvin. 2023.
DeepRank-GNN: a graph neural network framework to learn patterns in protein‚Äì
protein interfaces. Bioinformatics 39, 1 (2023), btac759.
[36] Emanuele Rossi, Bertrand Charpentier, Francesco Di Giovanni, Fabrizio Frasca,
Stephan G√ºnnemann, and Michael M Bronstein. 2024. Edge directionality im-
proves learning on heterophilic graphs. In Learning on Graphs Conference. PMLR,
25‚Äì1.
[37] Statista. 2023. Value of e-commerce losses to online payment fraud worldwide
from 2020 to 2023. https://www.statista.com/statistics/1273177/ecommerce-
payment-fraud-losses-globally/.
[38] Ilkay Ulusoy and Christopher M Bishop. 2006. Comparison of generative and
discriminative techniques for object detection and classification. In Toward
Category-Level Object Recognition. Springer, 173‚Äì195.
[39] Sohini Upadhyay, Shalmali Joshi, and Himabindu Lakkaraju. 2021. Towards
Robust and Reliable Algorithmic Recourse. In Advances in Neural Information
Processing Systems (NeurIPS), Vol. 34.
[40] Sandra Wachter, Brent Mittelstadt, and Chris Russell. 2017. Counterfactual
explanations without opening the black box: Automated decisions and the GDPR.
Harv. JL & Tech. 31 (2017), 841.
[41] Xuemei Wei, Yezheng Liu, Jianshan Sun, Yuanchun Jiang, Qifeng Tang, and Kun
Yuan. 2022. Dual subgraph-based graph neural network for friendship prediction
in location-based social networks. ACM Transactions on Knowledge Discovery
from Data (TKDD) (2022).
[42] Z. Ying, D. Bourgeois, J. You, M. Zitnik, and J. Leskovec. 2019. Gnnexplainer: Gen-
erating explanations for graph neural networks. Advances in neural information
processing systems 32 (2019).
A DECOMPOSITION OF THE ELBO
Letùê∫=(ùë®,ùëø)‚ààA√óX , whereA‚äÇRùëõ√óùëõrepresents possible
adjacency matrices and X‚äÇRùëõrepresents possible node features.
Letùíõ‚ààZ‚äÇ Rùëòbe a latent representation, where usually ùëõ‚â´ùëò.
Note that we can construct a mapping from graphs Gto a Euclidean
spaceX, so the above results also apply where ùê∫is a graph. Let ùëùùúÉ
be the distribution induces by the generative decoder ùëîùúÉ:Z‚ÜíX
with parameters ùúÉandùëûùúëbe the distribution induces by the encoder
ùëìùúë:X‚ÜíZ with parameters ùúë. We can derive the following lower
bound on the posterior probability, which is known as the evidence
 
2429Unifying Evolution, Explanation, and Discernment: A Generative Approach for Dynamic Graph Counterfactuals KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain
lower bound (ELBO)
logùëù(ùê∫)=log‚à´
ZùëùùúÉ(ùê∫,ùíõ)ùëëùíõ
=log‚à´
Zùëûùúë(ùíõ|ùê∫)
ùëûùúë(ùíõ|ùê∫)ùëùùúÉ(ùê∫,ùíõ)ùëëùíõ
=logEùëûùúë(ùíõ|ùê∫)ùëùùúÉ(ùê∫,ùíõ)
ùëûùúë(ùíõ|ùê∫)
‚â•Eùëûùúë(ùíõ|ùê∫)
logùëùùúÉ(ùê∫,ùíõ)
ùëûùúë(ùíõ|ùê∫)
=Eùëûùúë(ùíõ|ùê∫)
logùëùùúÉ(ùê∫|ùíõ)ùëùùúÉ(ùíõ)
ùëûùúë(ùíõ|ùê∫)
=Eùëûùúë(ùíõ|ùê∫)[logùëùùúÉ(ùê∫|ùíõ)]+Eùëûùúë(ùíõ|ùê∫)[logùëùùúÉ(ùíõ)]
‚àíEùëûùúë(ùíõ|ùê∫)
logùëûùúë(ùíõ|ùê∫)
BLùëüùëíùëê+Lùëëùëñùë†ùë°‚àíLùë¢ùëõùëêùëíùëüùë°BELBOùúô,ùúÉ(ùê∫)(12)
We now plug in the proposed parametric densities:
ùëùùúÉ(ùíõ)‚àºN( ùíõ;0,ùë∞)
ùëùùúÉ(ùë®|ùíõ)‚àºN( ùë®;ùëîùúÉ(ùíõ),ùúé2ùë∞)
ùëùùúÉ(ùëø|ùë®,ùíõ)‚àºN( ùëø;‚ÑéùúÉ(ùë®,ùíõ),ùúé2ùë∞)
ùëûùúë(ùíõ|ùê∫)‚àºN( ùíõ;ùëìùúë(ùê∫),ùõæ2ùë∞)(13)
In our problem setup, we specifically have
ùëìùúë(ùê∫)=GCNùúëùë¶(ùê∫) (14)
andùëîùúÉis defined for each element (ùë£ùëñ,ùë£ùëó)via
ùëîùúÉ(ùíõ)ùë£ùëñ,ùë£ùëó=ùê¥ùúÉ(ùëßùëñ)‚ä§ùê¥ùúÉ(ùëßùëó) (15)
whereùê¥ùúÉis a mapping and ‚ÑéùúÉis again defined through a GCN (or
any NN), i.e.,
‚ÑéùúÉ(ùë®,ùíõ)=GCNùúÉ(ùë®,ùíõ) (16)
We can condense
logùëùùúÉ(ùê∫|ùíõ)=logùëùùúÉ(ùë®|ùíõ)+logùëùùúÉ(ùëø|ùë®,ùíõ)
=‚àí1
2Eùëûùúë(ùíõ|ùê∫)"
‚à•ùëîùúÉ(ùíõ)‚àíùë®‚à•2
2
ùúé2#
‚àí1
2Eùëûùúë(ùíõ|ùê∫)"
‚à•‚ÑéùúÉ(ùë®,ùíõ)‚àíùëø‚à•2
2
ùúé2#
‚àíùëô+ùëö
2(log 2ùúã+logùúé2)
=‚àí1
2Eùëûùúë(ùíõ|ùê∫)"
‚à•ùëî‚Ä≤
ùúÉ(ùíõ)‚àíùê∫‚à•2
2
ùúé2#
‚àíùëô+ùëö
2(log 2ùúã+logùúé2)(17)
Instead of writing the two-step decoding process, we will now
introduceùëî‚Ä≤
ùúÉ(ùíõ)which denotes the entire stochastic generating
process such that ùê∫=(ùë®,ùëø)=ùëî‚Ä≤
ùúÉ(ùíõ), and denote the sum of the
two error norms‚à•ùëî‚Ä≤
ùúÉ(ùíõ)‚àíùê∫‚à•2
2=‚à•ùëîùúÉ(ùíõ)‚àíùë®‚à•2
2+‚à•‚ÑéùúÉ(ùë®,ùíõ)‚àíùëø‚à•2
2
This results in
Lùëüùëíùëê=‚àí1
2Eùëûùúë(ùíõ|ùê∫)"
‚à•ùëî‚Ä≤
ùúÉ(ùíõ)‚àíùê∫‚à•2
2
ùúé2#
‚àíùëô+ùëö
2(log 2ùúã+logùúé2)(18)
Lùëëùëñùë†ùë°=‚àíCE[ùëûùúë(ùíõ|ùê∫)),ùëùùúÉ(ùíõ)]
=‚àíDKL[ùëûùúë(ùíõ|ùê∫)),ùëùùúÉ(ùíõ)]‚àíùêª[ùëûùúë(ùíõ|ùê∫))]
=Eùëûùúë(ùíõ|ùê∫)"
‚à•ùíõ‚à•2
2
2#
‚àíùëò
2log 2ùúã=‚àíùëò
2
log 2ùúã+ùõæ2
‚àí1
2‚à•ùëìùúë(ùê∫)‚à•2
2
(19)‚àíLùë¢ùëõùëêùëíùëüùë° =Eùëûùúë(ùíõ|ùê∫)"
‚à•ùíõ‚àíùëìùúë(ùê∫)‚à•2
2
2ùúé2#
+ùëò
2log 2ùúã+1
2log|ùõæ2I|
=ùëò
2
log 2ùúã+1+logùõæ2
=const.
(20)
In summary, the log probability can be approximated by
ELBOùúô,ùúÉ(ùê∫)‚àùLùëëùëñùë†ùë°+Lùëüùëíùëê
‚àù‚àí1
2 
Eùëûùúë(ùíõ|ùê∫)"
‚à•ùëîùúÉ(ùíõ)‚àíùê∫‚à•2
2
ùúé2#
+‚à•ùëìùúë(ùê∫)‚à•2
2!
(21)
In summary, we assign a high likelihood to samples encoded close
to the center and have good reconstruction.
B GENERATIVE CLASSIFICATION WITH
VGAES
In classification problems, we attempt to predict the class ÀÜùë¶‚ààY
with the highest posterior probability. If we have a class conditional
distribution model, we can reformulate the terms to arrive at the
following formulation:
ÀÜùë¶=argmax
ùë¶‚ààYùëù(ùë¶|ùê∫)=argmax
ùë¶‚ààYùëù(ùê∫|ùë¶)ùëù(ùë¶)
ùëù(ùê∫)
=argmax
ùë¶‚ààYlogùëù(ùê∫|ùë¶)+logùëù(ùë¶)(22)
Suppose we now have a converged conditional density model with
class-dependent decoders ùëîùúÉùë¶and encoders ùëìùúëùë¶such that we can
compute logùëù(ùê∫|ùë¶)as in Eqn. 22 (we basically add the condition
onùë¶to all the terms). If the density model is expressive enough,
i.e., it covers the ground truth distribution, maximizing the ELBO
results in a likelihood that represents the true likelihood [ 16]. We
then have
ELBOùúô‚àó,ùúÉ‚àó(ùê∫|ùë¶)=logùëù(ùê∫|ùë¶) (23)
whereùúô‚àó,ùúÉ‚àóare the maximizing parameters of the ELBO. Plugging
in the results, we obtain
ÀÜùë¶=argmax
ùë¶‚ààYlogùëù(ùê∫|ùë¶)+ùëê=argmax
ùë¶‚ààYELBOùúô‚àó,ùúÉ‚àó(ùê∫|ùë¶)+ùëê
=argmax
ùë¶‚ààY‚àí1
2
E
ùëûùúë‚àó(ùíõ|ùê∫,ùë¶)"‚à•ùëîùúÉ‚àóùë¶(ùíõ)‚àíùê∫‚à•2
2
ùúé2#
+‚à•ùëìùúë‚àóùë¶(ùê∫)‚à•2
2
+ùëê
=argmin
ùë¶‚ààY1
2
E
ùëûùúë‚àó(ùíõ|ùê∫,ùë¶)"‚à•ùëîùúÉ‚àóùë¶(ùíõ)‚àíùê∫‚à•2
2
ùúé2#
+‚à•ùëìùúë‚àóùë¶(ùê∫)‚à•2
2
‚àíùëê,
(24)
whereùëê=logùëù(ùë¶).
C DATASETS
Here, we provide details on the datasets used to assess the perfor-
mance of GRACIE. Table 3 illustrates the their characteristics.
DynTree-Cycles (DTC) contains cyclic (1) and acyclic (0) graphs, and
it is an established benchmark dataset for graph counterfactuals [ 4].
We extend this dataset by introducing the time dimension, allowing
graphs to evolve in time and potentially change their class, and
name it DynTree-Cycles (DTC). We repeat the dataset generation
in [32] at each time step. In this way, a particular graph ùê∫ùë°
ùëñcan
change its structure in ùë°+1and remain in the same class or move
to the opposite one. This emulates a synthetic process of tracing
the evolution of the graphs in the dataset according to time. Here,
 
2430KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain Bardh Prenkaj, Mario Villaiz√°n-Vallelado, Tobias Leemann, and Gjergji Kasneci
Table 3: Statistics of the datasets.
D
TC DBLP BTC- ùõº BTC-ùõΩ BNZ
#
of time steps 4 10 13 5 5
# of instances per time step 2,000 739 756 310 500
Avg # of nodes 28 13.54 82.29 12.38 39.86
Avg # of edges 27.62 41.91 152.12 27.09 251.42
Max # of nodes 28 148 278 349 382
Avg (out) node degree 1.97 4.12 3.62 2.46 5.19
# of classes 2 2 2 2 2
Class distribution at ùë°0 46.5 : 53.5 75.5 : 24.5 78.2 : 21.8 81.7: 18.3 55.8 : 44.2
Graph type undirected undirected directed directed directed
we guarantee that the number of instances per snapshot is the
same. All the instances in the dataset contain the same number
of nodes and are connected graphs. Notice that the dataset has a
balanced distribution between its two classes, making it conducive
for learning-based explainers. However, its average node degree of
1.97suggests the graphs are sparsely connected, challenging GCNs
to capture intricate relationships between the nodes.
Additionally, notice that this dataset poses a difficult scenario
since explainers need to learn both edge additions/removal oper-
ations given the duality aspect of the instances. In other words,
explainers need to learn how to remove edges to pass from a cyclic
graph to an acyclic graph and how to add edges to pass from a tree
to a cyclic graph. Although the dataset poses a difficult scenario for
most learning-based approaches ‚Äì see Table 1 ‚Äì GRACIE does not
need to learn how to add or cut edges for an input graph. GRACIE‚Äôs
two-class representations and its neighboring mechanism permits
us to search for counterfactual candidates entirely in the latent
space.
DBLP-Coauthors (DBLP) consists of graphs representing authors,
where edges denote co-authorship relationships and edge weights
signify the number of collaborations in a given year. We focus on
the time frame[2000,2010]and consider ego-networks of authors
with at least ten collaborations in 2000. To trace the ego-network
evolution from 2000 to2010, we propagate ego-networks from the
previous year whenever an author has no collaborations in a spe-
cific yearùë°. Ego networks are labeled 1if the central node has an
impactful network in a particular year ùë°w.r.t. the other instances;
otherwise, we assign a 0. Here the graphs exhibit a notably higher
average node degree of 4.12, implying denser interconnectivity
between nodes. This characteristic may present challenges in han-
dling the complexity of interrelated features and distinguishing
relevant patterns. Additionally, the graphs are, on average, big-
ger than in DTC which makes the GCNs harder to learn effective
node representations due to the ‚Äúrepresentational clash‚Äù of their
receptive field [2].
BTCAlpha (BTC- ùõº) and BTC-OTC (BTC- ùõΩ)link to our initial fraud de-
tection example and consist of who-trust-whom networks of traders
on the Bitcoin Alpha and Bitcoin OTC platforms, respectively. Since
Bitcoin users are anonymous, there is a need to maintain a record
of users‚Äô reputations to prevent transactions with fraudulent and
risky users. Members of the platforms rate others on a scale of -10
(total distrust) to +10 (total trust). For each year ùë°in the dataset,
we trace the connected components of the graph at time step ùë°and
label each one with 1if it contains more ‚Äúfraudulent" ratings than
trustworthy ones; otherwise, with 0. It is interesting to notice thatthe graphs in this dataset are directed (i.e., asymmetric adjacency
matrices), which might hamper [ 18] the performances of the graph
convolution layers in the VGAEs (see BTC- ùõΩin Fig. 3 and 6).
Bonanza (BNZ). The Bonanza website is similar to eBay and Amazon
Marketplace in that users create an account to buy or sell various
goods. After a buyer purchases a product from a seller, both can
provide a rating about the other along with a short comment. At the
time of collection, Bonanza was using a rating scale of Positive (+1),
Neutral (0), and Negative (-1) to rate another user after a transaction.
For each year ùë°in the dataset, we trace the connected components
of the ego-network of each seller and label with 1if it contains at
least ten good reviews (i.e., the ratings‚Äô sum of its induced edges is
‚â•10); otherwise, with 0.
D HYPERPARAMETER SETTINGS
We rely on Bayesian optimization to obtain the best parameters for
GRACIE and DyGRACE. We do the hyperparameter optimization
only on the first time step ùë°0with objective function Validity@1.
For GRACIE, we use the search spaces in Table 4. For DyGRACE,
we use the hyperparameters in Table 5.
Table 4: The hyperparameter search spaces and best choice
for each dataset for GRACIE.
Hyp
erparameter Search spaceBest Choice
D
TC DBLP BTC- ùõºBTC-ùõΩBNZ
Learning
rate{10‚àí4,10‚àí3,10‚àí2,10‚àí1} 10‚àí310‚àí310‚àí310‚àí310‚àí3
Batch size {1,2,4,8,16,24,32,64} 64 64 24 24 1
Epochs [50,350] with a step of 50 200 100 100 100 100
ùëò [10,100] with a step of 10 50 10 10 10 10
Table 5: The hyperparameter search spaces and best choice
for each dataset for DyGRACE.
Hyp
erparameter Search spaceBest Choice
D
TC DBLP BTC- ùõºBTC-ùõΩBNZ
Learning
rate{10‚àí4,10‚àí3,10‚àí2,10‚àí1} 10‚àí310‚àí410‚àí110‚àí110‚àí3
Batch size {1,2,4,8,16,24,32,64} 24 24 4 4 1
Encoder out. dim. [1,8] 2 4 4 4 2
Epochs [10,300] with a step of 100 20 150 100 100 100
ùëò [5,50]with a step of 5 50 10 10 10 10
We follow the suggestion of [ 32] to set the hyperparameters for
the time-unrelated strategies (i.e., CLEAR, G-CounteRGAN, and
MEG). For CLEAR, we set the epochs to 50,ùõº=0, the dropout to
0.1,ùúÜùëêùëìùëí=0.1,ùúÜùëòùëô=0.1,ùúÜùë†ùëñùëö=0.1, learning rate to 10‚àí3, and
weight decay to 10‚àí5. For G-CounteRGAN, we set the number of
training iterations to 250, the number of discriminator steps to 3, the
number of generator steps to 2, and the binarization threshold to 0.5.
For MEG, we set a maximum of 10steps to perturb the adjacency
matrix of the input graphs. We set the number of episodes to 10, the
learning rate to 10‚àí4, the batch size to 1since it can only perturb
one graph at a time, ùõæ=0.95, and polyak to 0.995. Finally, we derive
the input dimension MEG requires as ùëõ2whereùëõis the maximum
number of nodes in a dataset.
 
2431