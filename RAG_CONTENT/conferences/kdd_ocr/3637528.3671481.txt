KDD workshop on Evaluation and Trustworthiness of
Generative AI Models
Yuan Ling
Amazon
Seattle, WA, USAShujing Dong
Amazon
Irvine, CA, USAYarong Feng
Amazon
Seattle, WA, USA
Zongyi (Joe) Liu
Amazon
Seattle, WA, USAGeorge Karypis
Univ. of Minnesota / Amazon
Santa Clara, CA, USAChandan K Reddy
Virginia Tech / Amazon
Arlington, VA, USA
ABSTRACT
The KDD workshop on Evaluation and Trustworthiness of Gen-
erative AI Models aims to address the critical need for reliable
generative AI technologies by exploring comprehensive evalua-
tion strategies. This workshop will delve into various aspects of
assessing generative AI models, including Large Language Models
(LLMs) and diffusion models, focusing on trustworthiness, safety,
bias, fairness, and ethical considerations. With an emphasis on
interdisciplinary collaboration, the workshop will feature invited
talks, peer-reviewed paper presentations, and panel discussions to
advance the state of the art in generative AI evaluation.
CCS CONCEPTS
•Computing methodologies →Artificial intelligence.
KEYWORDS
Generative AI models, Trustworthiness, Evaluation metrics, Bias
and fairness, Cross-modal evaluation, Ethical considerations in AI
ACM Reference Format:
Yuan Ling, Shujing Dong, Yarong Feng, Zongyi (Joe) Liu, George Karypis,
and Chandan K Reddy. 2024. KDD workshop on Evaluation and Trustwor-
thiness of Generative AI Models. In Proceedings of the 30th ACM SIGKDD
Conference on Knowledge Discovery and Data Mining (KDD ’24), August
25–29, 2024, Barcelona, Spain. ACM, New York, NY, USA, 2 pages. https:
//doi.org/10.1145/3637528.3671481
1 INTRODUCTION
The landscape of machine learning and artificial intelligence has
been profoundly reshaped by the advent of Generative AI Models
and their applications, such as ChatGPT [ 15], GPT-4 [ 17], Sora [ 16],
and etc. Generative AI includes Large Language Models (LLMs)
such as GPT [ 3], Claude [ 2], Flan-T5 [ 5], Falcon [ 1], Llama [ 22],
etc., and generative diffusion models [ 9,10,14,18–20]. These mod-
els have not only showcased unprecedented capabilities but also
catalyzed transformative shifts across numerous fields. Concur-
rently, there is a burgeoning interest in the comprehensive evalua-
tion of Generative AI models, as evidenced by pioneering efforts
Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for third-party components of this work must be honored.
For all other uses, contact the owner/author(s).
KDD ’24, August 25–29, 2024, Barcelona, Spain
©2024 Copyright held by the owner/author(s).
ACM ISBN 979-8-4007-0490-1/24/08.
https://doi.org/10.1145/3637528.3671481in research benchmarks and frameworks for LLMs like Prompt-
Bench [ 24], BotChat [ 7], OpenCompass [ 6], MINT [ 23], and oth-
ers [4,8,11]. Despite these advancements, the quest to accurately
assess the trustworthiness, safety, and ethical congruence of Gen-
erative AI Models continues to pose significant challenges [ 13,21].
This underscores an urgent need for developing robust evaluation
frameworks that can ensure these technologies are reliable and can
be seamlessly integrated into society in a beneficial manner. Our
workshop is dedicated to fostering interdisciplinary collaboration
and innovation in this vital area, focusing on the development of
new datasets, metrics, methods, and models that can advance our
understanding and application of Generative AI.
2 WORKSHOP DETAILS
•Title: KDD workshop on Evaluation and Trustworthiness
of Generative AI Models
•Website: https://genai-evaluation-kdd2024.github.io/genai-
evalution-kdd2024/
3 TOPIC OF THE WORKSHOP
This workshop aims to serve as a pivotal platform for discussing
the forefront of Generative AI trustworthiness and evaluation ad-
vancements. Generative AI models, such as Large Language Models
(LLMs) and Diffusion Models have revolutionized various domains,
underscoring the critical need for reliable Generative AI technolo-
gies. As these models increasingly influence decision-making pro-
cesses, establishing robust evaluation metrics and methods becomes
paramount. Our objective is to delve into diverse evaluation strate-
gies to enhance Generative AI models reliability across applications.
The workshop topics include, but are not limited to:
•Holistic Evaluation: Covering datasets, metrics, and method-
ologies.
•Trustworthiness in Generative AI Models:
–Truthfulness: Counteracting misinformation, hallucina-
tion, inconsistency, sycophancy in responses, adversarial
factuality.
–Ensuring Safety and Security: privacy concerns, prevent-
ing harmful and toxicity content.
–Addressing Bias and Fairness.
–Ethical Considerations: social norm alignment, compli-
ance with values, regulations and laws.
–Privacy: privacy awareness and privacy leakage.
–Enhancing misuse resistance, explainability, and robust-
ness.
6729
KDD ’24, August 25–29, 2024, Barcelona, Spain Yuan Ling, Shujing Dong, Yarong Feng, Zongyi (Joe) Liu, George Karypis, and Chandan K Reddy
•User-Centric Assessment.
•Multi-perspective Evaluation: Emphasizing logical reason-
ing, knowledge depth, problem-solving, and user alignment.
•Cross-Modal Evaluation: Integrating text, image, audio, etc.
The workshop is designed to convene researchers from the
realms of machine learning, data mining, and beyond, fostering the
interdisciplinary exploration into Generative AI trustworthiness
and evaluation. By featuring a blend of invited talks, presentations
of peer-reviewed papers, and panel discussions, this workshop aims
to facilitate exchanges of insights and foster collaborations across
research and industry sectors. Participants from diverse fields such
as Data Mining, Machine Learning, Natural Language Processing
(NLP), and Information Retrieval are encouraged to share knowl-
edge, debate challenges, and explore synergies, thereby advancing
the state of the art in Generative AI technologies.
4 TARGET AUDIENCE
Possible list of attendees:
•A broad spectrum of researchers dealing with machine learn-
ing / data mining / NLP tasks involving Generative AI.
•Non-CS academic researchers working with application-
specific datasets and challenges with Generative AI.
•Industry practitioners.
•Policy makers.
•Government agencies.
•Non-profit organizations.
5 WORKSHOP PREVIOUSLY HELD AT KDD
AtKDD2023, we organized Multimodal KDD 2023 workshop [ 12]
(https://multimodal-kdd-2023.github.io/), which drew a large,
engaged audience (75-80 participants). The success of our 2023
workshop underscores our commitment to advancing the dialogue
on cross-modal evaluation, encompassing the integration of diverse
data types such as text, images, and audio. This year’s focus con-
tinues on the trajectory of exploring and enhancing the evaluation
paradigms for Generative AI models, demonstrating our ongoing
dedication to contributing meaningful advancements to the KDD
community.
•Previously held workshop at KDD: KDD2023 - Multi-
modal KDD 2023 workshop: https://multimodal-kdd-2023.
github.io/
•Attendance: 75-80 participants
6 ORGANIZERS
Yuan Ling, senior scientist at Amazon.
Shujing Dong, applied scientist at Amazon.
Yarong Feng, applied scientist at Amazon.
Zongyi (Joe) Liu, principal computer vision scientist at Amazon.
George Karypis, Senior Principal Scientist at AWS AI and a Dis-
tinguished McKnight University Professor and an ADC Chair of
Digital Technology at the Department of Computer Science & En-
gineering at the University of Minnesota.
Chandan Reddy, Professor in the Department of Computer Sci-
ence at Virginia Tech and Amazon Scholar.REFERENCES
[1]Ebtesam Almazrouei, Hamza Alobeidli, Abdulaziz Alshamsi, Alessandro Cappelli,
Ruxandra Cojocaru, Merouane Debbah, Etienne Goffinet, Daniel Heslow, Julien
Launay, Quentin Malartic, Badreddine Noune, Baptiste Pannier, and Guilherme
Penedo. 2023. Falcon-40B: an open large language model with state-of-the-art
performance. (2023).
[2]Anthropic. 2023. Model Card and Evaluations for Claude Models. https://www-
files.anthropic.com/production/images/Model-Card-Claude-2.pdf. Accessed:
2023-12-05.
[3]Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan,
Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda
Askell, et al .2020. Language models are few-shot learners. Advances in neural
information processing systems 33 (2020), 1877–1901.
[4]Yupeng Chang, Xu Wang, Jindong Wang, Yuan Wu, Linyi Yang, Kaijie Zhu, Hao
Chen, Xiaoyuan Yi, Cunxiang Wang, Yidong Wang, et al .2023. A survey on
evaluation of large language models. ACM Transactions on Intelligent Systems
and Technology (2023).
[5]Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William
Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Albert Web-
son, Shixiang Shane Gu, Zhuyun Dai, Mirac Suzgun, Xinyun Chen, Aakanksha
Chowdhery, Sharan Narang, Gaurav Mishra, Adams Yu, Vincent Zhao, Yanping
Huang, Andrew Dai, Hongkun Yu, Slav Petrov, Ed H. Chi, Jeff Dean, Jacob Devlin,
Adam Roberts, Denny Zhou, Quoc V. Le, and Jason Wei. 2022. Scaling Instruction-
Finetuned Language Models. https://doi.org/10.48550/ARXIV.2210.11416
[6]OpenCompass Contributors. 2023. Opencompass: A universal evaluation plat-
form for foundation models. GitHub repository (2023).
[7]Haodong Duan, Jueqi Wei, Chonghua Wang, Hongwei Liu, Yixiao Fang, Songyang
Zhang, Dahua Lin, and Kai Chen. 2023. BotChat: Evaluating LLMs’ Capabilities
of Having Multi-Turn Dialogues. arXiv preprint arXiv:2310.13650 (2023).
[8]Mingqi Gao, Xinyu Hu, Jie Ruan, Xiao Pu, and Xiaojun Wan. 2024. LLM-based
NLG Evaluation: Current Status and Challenges. arXiv preprint arXiv:2402.01383
(2024).
[9]Jonathan Ho, Ajay Jain, and Pieter Abbeel. 2020. Denoising Diffusion Probabilistic
Models. arXiv:2006.11239 [cs.LG]
[10] Jonathan Ho and Tim Salimans. 2022. Classifier-Free Diffusion Guidance.
arXiv:2207.12598 [cs.LG]
[11] Percy Liang, Rishi Bommasani, Tony Lee, Dimitris Tsipras, Dilara Soylu, Michi-
hiro Yasunaga, Yian Zhang, Deepak Narayanan, Yuhuai Wu, Ananya Kumar, et al .
2022. Holistic evaluation of language models. arXiv preprint arXiv:2211.09110
(2022).
[12] Yuan Ling, Fanyou Wu, Shujing Dong, Yarong Feng, George Karypis, and Chan-
dan K Reddy. 2023. International Workshop on Multimodal Learning-2023 Theme:
Multimodal Learning with Foundation Models. In Proceedings of the 29th ACM
SIGKDD Conference on Knowledge Discovery and Data Mining. 5868–5869.
[13] Yang Liu, Yuanshun Yao, Jean-Francois Ton, Xiaoying Zhang, Ruocheng Guo Hao
Cheng, Yegor Klochkov, Muhammad Faaiz Taufiq, and Hang Li. 2023. Trustworthy
LLMs: a Survey and Guideline for Evaluating Large Language Models’ Alignment.
arXiv preprint arXiv:2308.05374 (2023).
[14] Alex Nichol, Prafulla Dhariwal, Aditya Ramesh, Pranav Shyam, Pamela Mishkin,
Bob McGrew, Ilya Sutskever, and Mark Chen. 2022. GLIDE: Towards Photo-
realistic Image Generation and Editing with Text-Guided Diffusion Models.
arXiv:2112.10741 [cs.CV]
[15] OpenAI 2023. ChatGPT. https://chat.openai.com/, Accessed: 2023-04-20.
[16] OpenAI. 2024. Sora: Creating video from text. https://openai.com/sora. Accessed:
2024-02-24.
[17] OpenAI and etc. 2023. GPT-4 Technical Report. arXiv:2303.08774 [cs.CL]
[18] William Peebles and Saining Xie. 2023. Scalable Diffusion Models with Trans-
formers. arXiv:2212.09748 [cs.CV]
[19] Dustin Podell, Zion English, Kyle Lacey, Andreas Blattmann, Tim Dockhorn,
Jonas Müller, Joe Penna, and Robin Rombach. 2023. SDXL: Improving Latent
Diffusion Models for High-Resolution Image Synthesis. arXiv:2307.01952 [cs.CV]
[20] Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Björn
Ommer. 2022. High-Resolution Image Synthesis with Latent Diffusion Models.
arXiv:2112.10752 [cs.CV]
[21] Lichao Sun, Yue Huang, Haoran Wang, Siyuan Wu, Qihui Zhang, Chujie Gao,
Yixin Huang, Wenhan Lyu, Yixuan Zhang, Xiner Li, et al .2024. Trustllm: Trust-
worthiness in large language models. arXiv preprint arXiv:2401.05561 (2024).
[22] Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yas-
mine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhos-
ale, et al .2023. Llama 2: Open foundation and fine-tuned chat models. arXiv
preprint arXiv:2307.09288 (2023).
[23] Xingyao Wang, Zihan Wang, Jiateng Liu, Yangyi Chen, Lifan Yuan, Hao Peng,
and Heng Ji. 2023. Mint: Evaluating llms in multi-turn interaction with tools and
language feedback. arXiv preprint arXiv:2309.10691 (2023).
[24] Kaijie Zhu, Qinlin Zhao, Hao Chen, Jindong Wang, and Xing Xie. 2023. Prompt-
bench: A unified library for evaluation of large language models. arXiv preprint
arXiv:2312.07910 (2023).
6730