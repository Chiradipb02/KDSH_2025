Toward Structure Fairness in Dynamic Graph Embedding: A
Trend-aware Dual Debiasing Approach
Yicong Li∗
The Education University of Hong
Kong
Hong Kong SAR, China
University of Technology Sydney
Australia
lyicong@eduhk.hk
yicong.li@student.uts.edu.auYu Yang∗†
The Hong Kong Polytechnic
University
Hong Kong SAR, China
cs-yu.yang@polyu.edu.hkJiannong Cao
The Hong Kong Polytechnic
University
Hong Kong SAR, China
jiannong.cao@polyu.edu.hk
Shuaiqi Liu
The Hong Kong Polytechnic
University
Hong Kong SAR, China
shuaiqi.liu@connect.polyu.hkHaoran Tang
The Hong Kong Polytechnic
University
Hong Kong SAR, China
haoran.tang@connect.polyu.hkGuandong Xu†
The Education University of Hong
Kong
Hong Kong SAR, China
University of Technology Sydney
Australia
gdxu@eduhk.hk
guandong.xu@uts.edu.au
ABSTRACT
Recent studies successfully learned static graph embeddings that
are structurally fair by preventing the effectiveness disparity of
high- and low-degree vertex groups in downstream graph mining
tasks. However, achieving structure fairness in dynamic graph em-
bedding remains an open problem. Neglecting degree changes in
dynamic graphs will significantly impair embedding effectiveness
without notably improving structure fairness. This is because the
embedding performance of high-degree and low-to-high-degree
vertices will significantly drop close to the generally poorer em-
bedding performance of most slightly changed vertices in the long-
tail part of the power-law distribution. We first identify biased
structural evolutions in a dynamic graph based on the evolving
trend of vertex degree and then propose FairDGE, the first struc-
turally Fair Dynamic Graph Embedding algorithm. FairDGE learns
biased structural evolutions by jointly embedding the connection
changes among vertices and the long-short-term evolutionary trend
of vertex degrees. Furthermore, a novel dual debiasing approach
is devised to encode fair embeddings contrastively, customizing
debiasing strategies for different biased structural evolutions. This
innovative debiasing strategy breaks the effectiveness bottleneck of
embeddings without notable fairness loss. Extensive experiments
demonstrate that FairDGE achieves simultaneous improvement in
the effectiveness and fairness of embeddings.
∗Having equal contribution with the first author.
†Corresponsing authors.
This work is licensed under a Creative Commons Attribution
International 4.0 License.
KDD ’24, August 25–29, 2024, Barcelona, Spain
©2024 Copyright held by the owner/author(s).
ACM ISBN 979-8-4007-0490-1/24/08.
https://doi.org/10.1145/3637528.3671848CCS CONCEPTS
•Information systems →Data mining.
KEYWORDS
Dynamic graph embedding; Structural fairness; Degree fairness;
Debiased learning; Structural evolution
ACM Reference Format:
Yicong Li, Yu Yang, Jiannong Cao, Shuaiqi Liu, Haoran Tang, and Guandong
Xu. 2024. Toward Structure Fairness in Dynamic Graph Embedding: A
Trend-aware Dual Debiasing Approach. In Proceedings of the 30th ACM
SIGKDD Conference on Knowledge Discovery and Data Mining (KDD ’24),
August 25–29, 2024, Barcelona, Spain. ACM, New York, NY, USA, 12 pages.
https://doi.org/10.1145/3637528.3671848
1 INTRODUCTION
Graph embedding has achieved great success in many applications,
such as recommendation [ 15], social inference [ 32], risk assessment
[31], etc. Many of these applications are human-centered, where
fairness matters a lot [ 23]. For example, recommending jobs unbi-
asedly, making every demographic have the same opportunities,
ensuring algorithmic credit scoring for lending does not uninten-
tionally favor certain ethnic or age groups, providing equitable
access and connectivity in transportation networks, etc. This drives
the research on fair graph embeddings.
Fair graph embedding aims to learn low-dimension vertex/edge
representations that will not make disparate treatment or impacts
to vertices/edges in downstream graph mining tasks [ 12]. Disparate
treatment, which is direct discrimination, intentionally treats ver-
tices/edges differently based on sensitive attributes [ 2]. Disparate
impact is indirect discrimination, where algorithms perform much
worse on vertices/edges with sensitive attributes and/or connectiv-
ity than on others [2].
 
1701
KDD ’24, August 25–29, 2024, Barcelona, Spain Yicong Li et al.
Existing works successfully learn fair embeddings for static
graphs. Some studies employed adversarial training [ 7], fairness
regularizations [ 9,10,30], resampling [ 36,50], or graph argumen-
tation [ 47] to make sensitive vertex attributes transparent to the
embeddings, thus eliminating disparate treatment or impacts to
sensitive attributes. Other studies [ 13,17,35,39] learned static
graph embeddings that are structurally fair by preventing the ef-
fectiveness disparity of high- and low-degree vertex groups (i.e.,
disparate impact) in downstream graph mining tasks, given that
vertex degrees of real-world graphs usually follow a long-tailed
power-law distribution [1].
Despite the success of learning fair embeddings for static graphs,
achieving structure fairness in dynamic graph embedding remains
an open problem. Naively re-training the above structurally fair
static graph embedding methods from scratch at each timestamp
fails to deal with the evolving bias caused by structural changes in
dynamic graphs [ 6,14]. As the graph structure evolves, a minority
of lower-degree vertices (Tail) may become higher-degree vertices
(Head) by actively forming edges with other vertices, while most
tail vertices may change slightly. If the model prioritizes fairness
by reducing head and tail vertices’ effectiveness disparity without
considering their evolutionary patterns, the performance of head
and tail-to-head vertices will significantly drop close to generally
poorer embedding performance of most slightly altered vertices in
the long-tail part of the power-law distribution. Such performance
degradation is empirically demonstrated in Section B of the Ap-
pendix. As a result, the effectiveness of learned structurally fair
embeddings in downstream tasks is questionable.
In this paper, we study a critical but overlooked problem of learn-
ing structurally fair dynamic graph embeddings that are highly
effective in downstream graph mining tasks. To achieve this goal,
we are confronted with two major challenges. (1) Learning biased
structural evolution over time. The structural evolution of head
and tail-to-head vertices leaves more linkage-changing information
than fluctuation tail vertices, giving rise to the structure bias in
the embeddings. Such structure bias changes as the graph evolves,
and not all structural evolutions bias embeddings. It is critical to
learn biased structural evolution for later debiasing. (2) Debiasing
properly to achieve fairness without sacrificing or even improv-
ing embedding effectiveness. Debiasing unbiased structural evolu-
tion impairs embedding effectiveness without notably improving
fairness. Structurally fair embedding algorithms should customize
debiasing strategies for different biased structural evolutions such
that the effectiveness of embedding is not greatly sacrificed.
In light of these challenges, we first identify three biased struc-
tural evolutions in a dynamic graph based on the evolutionary trend
of vertex degree, i.e., Fluctuation-at-Tail (FaT), Tail-to-Head (T2H),
andStarting-from-Head (SfH), then innovatively propose FairDGE,
a structurally Fair Dynamic Graph Embedding algorithm. To learn
biased structural evolution over time, FairDGE jointly embeds the
connection changes among vertices and the long-short-term evolu-
tionary trend of vertex degrees by an intermedia training task that
classifies the identified biased structural evolutions. Next, we devise
a dual debiasing approach for FairDGE to encode fair embeddings
that are highly effective in downstream tasks. It first debiases the
embeddings via contrastive learning, bringing closer the embed-
dings with identical biased structural evolutions and penalizingthose with different ones. Thanks to the theoretical proof in [ 39],
the embedding performance of the FaT vertices will be much im-
proved, resulting in a smaller performance gap with T2H and SfH
vertex groups. Meanwhile, we minimize the effectiveness disparity
of embeddings of T2H and SfH vertex groups, which are in the head
of the power-law distribution and with high performance, to boost
fairness further. Consequently, FairDGE breaks the effectiveness
bottleneck of embeddings with almost no fairness loss.
Our contributions are highlighted as follows:
•A new problem. To the best of our knowledge, we are the
first to study the structure fairness problem in dynamic graph
embedding and identify three biased structural evolutions
that are Fluctuation-at-Tail (FaT), Tail-to-Head (T2H), and
Starting-from-Head (SfH).
•A new and effective approach. We propose FairDGE, a
novel dynamic graph embedding algorithm, that learns bi-
ased structural evolutions and then uses a newly devised
dual debiasing method for encoding structurally fair embed-
dings that are highly effective in downstream graph mining
tasks.
•Extensive experiments. The experimental results demon-
strate that FairDGE achieves simultaneous improvement in
the effectiveness and fairness of embeddings.
2 PROBLEM FORMULATION
In this section, we give the definition of dynamic graphs and for-
mulate the problem of structurally fair dynamic graph embedding.
Firstly, we define a dynamic graph as a snapshot graph sequence.
Definition 1. A Dynamic Graph. A dynamic graphG=(V,E)
=(G1,G2,...,G𝑇)is a sequence of directed or undirected snapshot
graphsG𝑡, whereG𝑡=(V𝑡,E𝑡)is a static graph at time 𝑡∈{1,2,...,𝑇}.
V𝑡is a subset of the vertex set V={𝑣1,𝑣2,...,𝑣|V|}. An edge𝑒𝑡
𝑖,𝑗=
(𝑣𝑡
𝑖,𝑣𝑡
𝑗)∈E𝑡represents the connection between vertices 𝑣𝑡
𝑖and𝑣𝑡
𝑗in
G𝑡, where𝑣𝑡
𝑖,𝑣𝑡
𝑗∈V𝑡andE𝑡is a subset of the edge set E.
Similar to the existing work [ 7,17,39], we adopt statistical parity
proposed in [ 8] as the fairness metric, as in Definition 2. In other
words, the smaller the intergroup performance disparity, the better
the fairness.
Definition 2. Fairness Metric. Given𝑞mutually exclusive ver-
tex groups{𝐺1,...,𝐺𝑞}and𝐺1Ð...Ð𝐺𝑞=V, fairness is achieved
whenP(ℎ𝑣|𝑣∈𝐺1)=...=P(ℎ𝑣|𝑣∈𝐺𝑞), whereP(·) indicates the
performance of 𝑣’s embedding ℎ𝑣in a downstream task.
Dynamic graph embedding aims to learn low-dimensional rep-
resentations (i.e., embeddings) for every vertex that preserves its
dynamic connectivity changes. The learned embedding should be
highly effective in downstream graph mining tasks such as high
classification accuracy, small regression errors, high hit rate in rec-
ommendation, etc. Achieving structure fairness in dynamic graph
embeddings requires the embeddings learned from different struc-
tural evolution groups to perform similarly in downstream graph
mining tasks. To this end, we give the formal problem formulation
of structurally fair dynamic graph embedding in Definition 3.
 
1702Toward Structure Fairness in Dynamic Graph Embedding: A Trend-aware Dual Debiasing Approach KDD ’24, August 25–29, 2024, Barcelona, Spain
Definition 3. Structurally Fair Dynamic Graph Embed-
ding. Given a dynamic graph G=(V,E)=(G1,G2,...,G𝑇), the ver-
texVis divided into 𝑞mutually exclusive vertex groups {𝐺1,...,𝐺𝑞}
based on their structural evolution patterns, which is, 𝐺1Ð...Ð𝐺𝑞=
V. The objective is to learn a mapping function 𝑓:𝑣↦→ℎ𝑣∈R𝑑𝑖𝑚
for∀𝑣∈V such that the representation ℎ𝑣preserves the structural
evolution of𝑣in terms of dynamic connectivity changes between 𝑣and
other vertices inVover time, achieves high performance in down-
stream graph mining tasks, and satisfies the fairness requirement
defined in Definition 2, where 𝑑𝑖𝑚 is a positive integer indicating the
dimension of ℎ𝑣.
3 IDENTIFYING BIASED STRUCTURE
EVOLUTIONS OF DYNAMIC GRAPHS
In this section, we introduce intuitions for identifying the biased
structural evolution of dynamic graphs and explain the fairness
implications for dynamic graph embeddings.
The degree of a vertex represents the number of other vertices
connected to it, which indicates its neighborhood structures. As the
graph structure evolves, the connections among vertices change
accordingly, causing vertices’ degrees to vary. Therefore, degree
change is capable of approximating the vertex’s neighborhood
structure evolution over time.
Vertex degrees of real-world graphs usually follow a long-tailed
power-law distribution [ 1]. High- and low-degree vertices are in the
head and tail parts of the distribution, respectively. When the vertex
degree changes as the graph structure evolves, several evolution
patterns will be identified based on the evolving trend of degrees,
including Fluctuation-at-Tail (FaT), Tail-to-Head (T2H), Head-to-Tail
(H2T), and Fluctuation-at-Head (FaH). FaT is defined as the vertex
degree being always lower than a given degree threshold 𝜃in a
time period𝑡. In other words, the vertex fluctuates at the tail during
𝑡. FaH is the opposite in which the vertex’s degree remains above
𝜃. T2H is defined as the degree of a vertex changes from below 𝜃to
above𝜃during𝑡. The T2H vertex’s degree is initially below 𝜃but
becomes above 𝜃during𝑡.
We conducted a statistical analysis on six months of data in
the Amazon Books dataset containing 64,425vertices and 217,163
edges. Two snapshot graphs are constructed using data from the
first three and the last three months. The head and tail groups are
divided by a degree threshold of 10to identify the evolving trend
of degrees across snapshot graphs. The results in Table 1 show
that the above-identified evolving trend of degrees approximately
follows the long-tailed power-law distribution as 90.67%vertices
fluctuate at the tail with slight connection changes while only 9.33%
vertices’ neighborhood structures vary a lot. This makes dynamic
graph embedding algorithms exhibit structure unfairness [ 17,35,
39], favoring highly active structural evolutions (i.e., T2H, H2T, and
FaH) too much yet discriminating inactive ones (i.e., FaT). Thus,
we call them the biased structural evolutions of the dynamic graph.
Learning structurally fair dynamic graph embeddings is essential
and has wide real-world applications, as presented in Section A of
the Appendix.
In the next section, we will present our structurally fair dynamic
graph embedding algorithm to learn the above-identified structuralevolution patterns for encoding debiased embeddings toward struc-
ture fairness. Since the number of vertices in H2T and FaH is small,
we combine them in a single group called Start-from-Head (SfH) in
the rest of this paper. The detailed annotation approach of FaT, T2H,
and SfH is presented in the Appendix D. As for complex structural
evolution patterns such as first rising and then falling, first falling
and then rising, etc., we leave them to future work.
Table 1: Statistics on the evolutionary trend of vertex degrees.
FaT T2H H2T FaH
SnapshotsG1G2G1G2G1G2G1G2
A
vg. Degree 1.171
0.936 0.869
9.345 16.362
3.447 29.594
23.237
Std.
Degree 1.414
1.000 1.732
13.153 9.849
2.646 23.979
20.396
V
ertex Ratio 90.67% 7.02% 1.45% 0.86%
4 STRUCTURALLY FAIR DYNAMIC GRAPH
EMBEDDING ALGORITHM
In this section, we present the details of the FairDGE algorithm
to learn structurally fair dynamic graph embeddings. The symbol
notations are listed in Table 7 in the Appendix.
4.1 Overall Framework of FairDGE
The overall framework of FairDGE is presented in Figure 1. FairDGE
consists of two modules that are trained jointly. We design a trend-
aware structural evolution learning module to embed the connec-
tion changes among vertices as well as the evolving trend of the
corresponding degrees. An intermedia training task that classifies
the identified biased structural evolutions (i.e., FaT, T2H, and SfH)
is employed to supervise the learning of structural evolutions.
Another dual debiasing module is devised to encode structurally
fair embeddings. It customizes debiasing strategies for FaT, T2H,
and SfH vertex groups, respectively. In particular, we first debias
the embeddings via contrastive learning, bringing closer the em-
beddings with identical biased structural evolution and penalizing
those with different ones. Hence, the embedding performance of
FaT vertices will be significantly improved and close to that of T2H
and SfH. Then, we minimize the effectiveness disparity of T2H and
SfH vertices’ embeddings in downstream tasks to boost fairness
further and simultaneously avoid dragging their embedding effec-
tiveness down by FaT vertices with relatively lower performance.
4.2 Embedding Trend-aware Structural
Evolutions in Dynamic Graphs
We present the details of the trend-aware structural evolution learn-
ing module to embed the FaT, T2H, and SfH vertices in a dynamic
graph, solving the first challenges identified in Section 1.
4.2.1 Learning Evolving Trend of Degrees. Calculating the degree
difference between the first and last timestamp to measure the trend
will lose a lot of information about short-term changes. We first
model the degree of vertex 𝑣across the snapshot graph sequence
(G1,G2,...,G𝑇)as a time series, denoting as 𝑑𝑒𝑔(𝑣)∈R𝑇. Then, we
devise a long-short-term trend encoder to learn the comprehensive
varying patterns of 𝑑𝑒𝑔(𝑣), including long-term evolving trends
and short-term fluctuation patterns.
 
1703KDD ’24, August 25–29, 2024, Barcelona, Spain Yicong Li et al.
𝒢!𝒢"𝒢#…GNNDynamicgraphs𝒢$𝒗𝑑𝑒𝑔𝑟𝑒𝑒𝑇Short-termTrendEncoder𝒅(𝒗)Long-termTrendEncoder𝒅)(𝒗)𝒉𝒗∈ℝ𝒅𝒊𝒎𝒉𝒗𝒔𝒕𝒓①Trend-aware Structural Evolution Learning
𝓛𝒇𝒂𝒊𝒓𝒫𝑻𝟐𝑯𝒫𝑺𝒇𝑯②Dual Debiasing for Encoding Structurally Fair Embeddings…𝓗𝓥∈ℝ|𝓥|×𝒅𝒊𝒎𝒉𝒗𝒅𝒉𝒗𝒅+⊕𝒫𝑭𝒂𝑻𝒅(𝒗)𝒅)(𝒗)	𝒉𝑻𝟐𝑯𝒉𝑭𝒂𝑻𝒉𝑺𝒇𝑯ContrastiveLearningamong the embeddingsof𝑻𝟐𝑯,𝑭𝒂𝑻and𝑺𝒇𝑯vertices.DownstreamTaskMLP
𝓛*𝒐𝒏𝒕𝒓𝒂𝒔𝒕𝓛𝑫𝑺𝒉𝒗𝒅𝒆𝒈GRU⊕Linear＋𝓛𝒄𝒍𝒂𝒔𝒔DynamicGraphEmbeddingBackbone
Degreetrend…𝓗𝒗{𝟎,…,𝑻}…𝓗𝒗𝒔𝒕𝒓
Figure 1: Overall framework of FairDGE.
Specifically, we employ a 3-layer Gate Recurrent Unit (GRU) as
the long-term trend encoder, denoting as ˆ𝑑(𝑣), to learn the long-
term evolving patterns of 𝑑𝑒𝑔(𝑣)as follows:
ℎˆ𝑑
𝑣=ˆ𝑑(𝑣)=𝐺𝑅𝑈(𝑒𝑥𝑝𝑎𝑛𝑑(𝑑𝑒𝑔(𝑣))) (1)
where𝑒𝑥𝑝𝑎𝑛𝑑(𝑑𝑒𝑔(𝑣))expands the dimension of 𝑑𝑒𝑔(𝑣)from𝑇×1
to𝑇×𝑑𝑖𝑚by duplication.
To capture and embed the short-term fluctuation patterns of
degrees, we employ a 1-d Convolutional Neural Network (CNN)
as the short-term trend encoder 𝑑(𝑣). 1-d CNN has a good ability
to capture the local differences of degrees at several adjacent time
points, especially salient degrees [34].
ℎ𝑑
𝑣=𝑑(𝑣)=𝐶𝑁𝑁(𝑑𝑒𝑔(𝑣)) (2)
We set the kernel’s size and padding to 3 and 1, respectively. There-
fore,ℎ𝑑𝑣keeps the same dimension as ℎˆ𝑑𝑣.
Lastly, we fuse ℎ𝑑𝑣andℎˆ𝑑𝑣to obtain the trend embedding of 𝑑𝑒𝑔(𝑣)
by a stack-mean operation as shown below.
ℎ𝑑𝑒𝑔
𝑣=𝑚([ℎ𝑑
𝑣⊕ℎˆ𝑑
𝑣]) (3)
whereℎ𝑑𝑒𝑔
𝑣is the trend embedding of 𝑑𝑒𝑔(𝑣),⊕is a stack operator
for two embeddings, and 𝑚(·)is the mean operation.
4.2.2 Embedding Structural Evolutions. Embedding the connection
changes among vertices, noting as the structural evolutions, in
the snapshot graph sequence (G1,G2,...,G𝑇)is a typical dynamic
graph embedding problem, which has been well studied [ 22,26,44–
46,49]. Since it is not the main focus of this study and many existing
algorithms [ 5,22,26,44–46,49] are capable of being directly applied,
we use a graph neural network (GNN) to embed the snapshot graph
at each timestamp and then employ a GRU to learn the sequential
changing pattern across the snapshot graph sequence and obtain
structural evolution embeddings.
H𝑠𝑡𝑟
V=𝐺𝑅𝑈(𝐺𝑁𝑁(G1,G2,...,G𝑇))) (4)
whereH𝑠𝑡𝑟
Vis the embedding of all vertices in the dynamic graph.We treat this as a dynamic graph embedding backbone that any
existing dynamic graph embedding algorithms can be plugged in
and learn the structural evolution embeddings.
4.2.3 Learning Trend-aware Structural Evolutions via An Interme-
dia Trend Classification Task. To embed the trend-aware structural
evolutions, we fuse the degree-trend embedding of ℎ𝑑𝑒𝑔
𝑣and the
structural evolution embedding ℎ𝑠𝑡𝑟𝑣for every vertex 𝑣, as shown
in Eq. (5) where ℎ𝑠𝑡𝑟𝑣comes fromH𝑠𝑡𝑟
Vfor𝑣∈V,[.;.]is a concate-
nation operation and 𝑔(.)is a linear layer.
ℎ𝑣=𝑔([ℎ𝑑𝑒𝑔
𝑣;ℎ𝑠𝑡𝑟
𝑣]) (5)
We leverage an intermedia training task to better train ℎ𝑣for
retaining the biased structural evolutions FaT, T2H, and SfH. A
two-layer Multi-Layer Perceptron (MLP) is employed to encode
the representation, followed by a softmax function to forecast the
probability of vertex 𝑣belonging to one of the biased structural
evolutions, i.e., FaT, T2H, or SfH,
ℎ𝑆𝑓𝐻,𝑇 2𝐻,𝐹𝑎𝑇
𝑣 =𝑀𝐿𝑃(ℎ𝑣) (6)
ℎ𝑣,𝑦=𝑠𝑜𝑓𝑡𝑚𝑎𝑥(𝑅𝑒𝐿𝑈(ℎ𝑆𝑓𝐻,𝑇 2𝐻,𝐹𝑎𝑇
𝑣)) (7)
whereℎ𝑣,𝑦indicates the probability of vertex 𝑣that belongs to a
class𝑦∈𝑌={SfH, T2H, FaT}. Lastly, we employ a cross-entropy
loss to train ℎ𝑣andℎ𝑆𝑓𝐻,𝑇 2𝐻,𝐹𝑎𝑇
𝑣 , which is
L𝑐𝑙𝑎𝑠𝑠=−∑︁
𝑣∈V𝑙𝑜𝑔exp(ℎ𝑣,𝑦𝑣)
Í𝑌
𝑦=1exp(ℎ𝑣,𝑦)(8)
ℎ𝑣,𝑦𝑣is a one-hot vector indicating the ground truth biased struc-
tural evolutions of 𝑣, which is manually labeled from the historical
data for training. It is fine to set a threshold of head and tail degrees
to annotate FaT, T2H, and SfH. However, finding a golden standard
to determine the threshold is sometimes difficult due to the am-
biguous degree boundary of head and tail vertices. We devise an
alternative method, as Algorithm 1 in the Appendix, to annotate
FaT, T2H, and SfH based on the slope of degree evolving trends.
 
1704Toward Structure Fairness in Dynamic Graph Embedding: A Trend-aware Dual Debiasing Approach KDD ’24, August 25–29, 2024, Barcelona, Spain
4.3 Dual Debiasing for Encoding Structurally
Fair Embeddings
We devise a dual debiasing module that customizes debiasing strate-
gies for FaT, T2H, and SfH vertices to encode structurally fair em-
beddings, overcoming the second challenge. The idea is to make the
embedding performance of SfH and T2H vertices high and close
while improving the embedding performance of FaT vertices as
much as possible to narrow the gap with that of SfH and T2H,
eventually achieving structure fairness without sacrificing or even
improving embedding effectiveness.
R. Wang et al. [ 39] had theoretically and empirically proved that
contrastive learning will improve the tail vertex’s performance and
alleviate the performance gap between the head and tail vertex
groups, eventually improving fairness. Inspired by this, we employ
contrastive learning to debias the embedding of FaT, T2H, and SfH
vertices. Specifically, for each vertex 𝑣, we randomly select two
vertices𝑣+and𝑣−fromVto form a positive pair (𝑣,𝑣+)and a
negative one(𝑣,𝑣−)in which𝑣and𝑣+are in the same structural
evolution group but 𝑣and𝑣−are not. The objective is to make
the embeddings of the positive pairs as close as possible and the
representations of the negative pairs as far away as possible, bring-
ing closer the embeddings with identical structural evolutions and
penalizing those with different ones. A contrast loss is proposed in
Eq. (9) to achieve this goal, where ℎ𝑣,ℎ𝑣+,ℎ𝑣−are the embeddings
of vertex𝑣,𝑣+and𝑣−, respectively.
L𝑐𝑜𝑛𝑡𝑟𝑎𝑠𝑡 =−𝑙𝑜𝑔𝑒𝑥𝑝(𝑠𝑖𝑚(ℎ𝑣,ℎ𝑣+))/𝜏
𝑒𝑥𝑝(𝑠𝑖𝑚(ℎ𝑣,ℎ𝑣+)
𝜏)+Í
𝑣−∈V−𝑒𝑥𝑝(𝑠𝑖𝑚(ℎ𝑣,ℎ𝑣−)
𝜏)(9)
𝑠𝑖𝑚(ℎ𝑣,ℎ𝑣+)is measuring the cosine similarity between ℎ𝑣andℎ𝑣+.
𝜏is a scaling parameter. V−is a set of negative vertices with dif-
ferent structural evolutions from 𝑣. Thanks to contrastive learning,
the embedding performance of FaT vertices will improve, resulting
in a smaller performance disparity with T2H and SfH vertices.
Additionally, we alleviate the effectiveness disparity of T2H and
SfH vertices’ embeddings in downstream tasks for a second debias-
ing, facilitated by a fairness loss for the embeddings of T2H and SfH
vertices in Eq. (10). This loss minimizes the performance disparity
of T2H and SfH vertices in downstream tasks, imposing statistical
parity as defined in Def. 2. Eventually, statistical parity equalizes
outcomes across T2H and SfH vertices [8, 17].
L𝑓𝑎𝑖𝑟=||L𝐷𝑆(𝐻𝑇2𝐻
V)−L𝐷𝑆(𝐻𝑆𝑓𝐻
V)||2 (10)
𝐻𝑇2𝐻
Vand𝐻𝑆𝑓𝐻
Vare the final learned embeddings of T2H and SfH
vertices, respectively. ||·|| 2denotes the ℓ2norm.L𝐷𝑆(·)is a loss
function of the downstream tasks, which depends on the actual
applications. Notablely, FaT vertices are excluded from the second
debiasing, avoiding dragging down the performance of T2H and
SfH vertices.
Following [ 18], we employ the link prediction as the downstream
task in this paper. That is
L𝐷𝑆=−|V|∑︁
𝑣|E𝑣|∑︁
𝑒𝑥𝑒·𝑙𝑜𝑔𝑝𝑒+(1−𝑥𝑒)·𝑙𝑜𝑔(1−𝑝𝑒) (11)
E𝑣is an edge set of 𝑣for training, which contains positive edges 𝑒∈
E𝑣linking vertex 𝑣and the same number of negative edges that doTable 2: Stastics of datasets.
Dataset #
User #
Item #
Vertex #
Edges Dens. #
Snapshots
Amazon
Books 4,054 17,651 21,705 72,317 0.1% 5
Mo
vieLens 2,342 5,579 7,921 477,419 3.65% 15
Go
odReads 16,701 20,823 37,524 1,084,781 0.3% 15
not connect to 𝑣.𝑝𝑒is a learned edge existence probability computed
by inputting the final embeddings to a Fermi-Dirac decoder [20].
Lastly, we jointly minimize all the loss items mentioned above
withℓ2andℓ1regularization of model parameters Θ,
L=𝛾1L𝐷𝑆+𝛾2L𝑐𝑙𝑎𝑠𝑠+𝛾3L𝑐𝑜𝑛𝑡𝑟𝑎𝑠𝑡+𝛾4L𝑓𝑎𝑖𝑟+||Θ||2+||Θ||1(12)
where𝛾1,𝛾2,𝛾3,𝛾4are loss hyperparameters, controlling the pro-
portion of different components in the loss function. FairDGE will
gradually achieve the best trade-off between fairness and model
utility in the downstream tasks when jointly optimizing the loss.
5 EXPERIMENTS
We conduct extensive experiments to validate the embedding effec-
tiveness of FairDGE in terms of performance and fairness.
5.1 Experiment Settings
5.1.1 Datasets. The experiments are respectively conducted on
small-, medium- and large-scale real-world datasets including Ama-
zon Books, MovieLens and GoodReads. In the Amazon Books dataset,
the user-book interactions from 09 Aug 2006 to 12 Aug 2007 are
selected. For the MovieLens dataset, we use the 10M movie ratings
from 07 Jan 2001 to 07 Jan 2003. The GoodReads dataset is from
an online book community website, and we select the Children’s
books from 1 Jan 2013 to 30 Dec 2015. The detailed information of
datasets is presented in Table 2.
5.1.2 Baseline Methods. To comprehensively benchmark our pro-
posed FairDGE, we carefully select eight baseline methods for per-
formance comparison. Following are the detailed descriptions of
the selected baseline methods.
Graph learning methods:
•GCN [ 11]: GCN adopts the graph convolutions to learn the
graph embeddings.
•GAT [ 37]: GAT leverages masked self-attentional layers to
specify different weights to different vertices in a neighbor-
hood.
Dynamic graph learning methods:
•MPNN-LSTM [ 21]: MPNN-LSTM proposes an LSTM-based
message passing mechanism to model the vertices evolution
in the dynamic graphs.
•EvolveGCN [ 22]: EvolveGCN combines the graph convo-
lutional network model with an RNN to capture temporal
dynamics in a graph sequence.
Fair graph learning methods:
•FairGNN [ 7]: FairGNN effectively mitigates the impact of
sensitive attributes in graph data by incorporating fairness
constraints during training.
•FairVGNN [ 41]: FairVGNN is an extension of the FairGNN
model that includes a variational graph autoencoder to learn
 
1705KDD ’24, August 25–29, 2024, Barcelona, Spain Yicong Li et al.
latent representations and generate fair and diverse outputs
in graph data.
•DegFairGNN [ 17]: DegFairGNN is a fair graph neural net-
work to alleviate the structure bias problem using an equal
opportunity fair loss.
•TailGNN [ 16]: TailGNN proposes transferable neighborhood
translation aiming at closing the performance disparity be-
tween head and tail vertices.
5.1.3 Evalution Metrics of Performance. We adopt the top 𝑘Hit
Rate (HR@𝑘), top𝑘Precision (PREC@ 𝑘), and top𝑘Normalized Dis-
counted Cumulative Gain (NDCG@ 𝑘) as the performance metrics
of the recommendation tasks.
•HR@𝑘calculates the recall ratio of the prediction list,
𝐻𝑅@𝑘=#𝐻𝑖𝑡𝑠 @𝑘
|𝑝𝑜𝑠|(13)
where|𝑝𝑜𝑠|is the number of all positive items. #𝐻𝑖𝑡𝑠@𝑘is
the number of top 𝑘prediction list hit to the positive items.
•PREC@𝑘measures the precision of the prediction list,
𝑃𝑅𝐸𝐶 @𝑘=Í
𝑢∈𝑈𝑝𝑟𝑒𝑑𝑘(𝑢)Ñ𝑝𝑜𝑠(𝑢)Í
𝑢∈𝑈𝑝𝑟𝑒𝑑𝑘(𝑢)(14)
where𝑈is the user set, 𝑝𝑟𝑒𝑑𝑘(𝑢)is the top𝑘prediction list
for user𝑢, and𝑝𝑜𝑠(𝑢)is𝑢’s positive item list.
•NDCG@𝑘calculates the normalized ranking of the recall
ratio of the prediction list,
𝑁𝐷𝐶𝐺 @𝑘=1
|𝑝𝑜𝑠||𝑝𝑜𝑠|∑︁
𝑖1
𝑙𝑜𝑔2(𝑝𝑘
𝑖+1)(15)
where𝑝𝑘
𝑖is item𝑖’s ranking in the top 𝑘prediction list.
5.1.4 Evaluation Metrics of Fairness. We adopt the commonly used
ranking discrepancy metrics to quantitatively evaluate fairness.
In particular, we set 𝑘∈𝐾={1,5,10,15,20,40,60,80,100}and
calculate the average Hit Ratio Difference (rHR) and Normalized
Discounted Difference (rND) as fairness metric [43].
•Hit Ratio Difference (rHR) calculates the difference be-
tween the T2H items’ ratio in the top 𝑘∈𝐾candidates and
that in the overall ranking. A similar ratio, leading to less
rHR, denotes more fairness. Mathematically,
𝑟𝐻𝑅 =1
𝑍𝐾∑︁
𝑘|𝑇2𝐻𝑘|
𝑘−|𝑇2𝐻|
|V|(16)
where|𝑇2𝐻𝑘|denotes the number of T2H vertices in the top
𝑘candidate list and|V|presents the total number of vertices
in the dynamic graph. Given |V|and|𝑇2𝐻|,𝑍is the highest
possible value of rHR for normalization.
•Normalized Discounted Difference (rND) calculates the
difference between the T2H items’ ranking order in the top
𝑘∈𝐾candidates and that in the overall ranking. The smaller
the rND, the better the fairness.
𝑟𝑁𝐷 =1
𝑍𝐾∑︁
𝑘1
𝑙𝑜𝑔2𝑘|𝑇2𝐻𝑘|
𝑘−|𝑇2𝐻|
|V|(17)5.2 Performance and Fairness Comparison
To validate the effectiveness of our proposed FairDGE, we split the
Amazon Books, MovieLens, and GoodReads datasets into 5, 15, and
15 snapshots for training and testing, respectively. We regard each
user’s last interacted item as the test data. We run our FairDGE and
all baselines five times with different random seeds and report the
mean and the standard deviation (Std) results in Table 3. Std values
are shown magnified by a factor of 10 to save space.
FairDGE performs best on all three datasets, outperforming base-
line methods of 1.98% - 36.46% in recommendations, and achieves
the smallest fairness scores, especially on the rND metric. The
smaller the rHR and rND scores, the better the fairness. GCN and
GAT always obtain the worst performance among these baselines
because they are simple static graph neural networks and fail to
embed the structural evolutions. Although EvolveGCN also gets
worse performance on the Amazon Books dataset, it performs well
on the MovieLens dataset because the Amazon Books dataset is
too sparse for EvolveGCN to learn abundant evolution information
via the recurrent architecture. Thanks to generative adversarial
network structures, FairGNN and FairVGNN are the best baselines
in both recommendation performance and fairness, but they still
perform much worse than our FairDGE.
Another observation is that better fairness performance is ob-
tained when equipping the baseline methods with our fairness loss
L𝑓𝑎𝑖𝑟, especially rND. This demonstrates that our fairness loss
effectively pushes the T2H vertices to get more exposure in the
recommendation candidate list, especially to display in the high
ranking. At the same time, their recommended performance only
dropped slightly, and some even increased. This demonstrates that
the dual debiasing approach makes FairDGE successfully overcome
the second challenge.
5.3 Ablation Study of FairDGE
To study the contributions of each module to performance and fair-
ness, we conducted the ablation study on the Amazon Books dataset
as shown in Table 4. We compare the {HR, NDCG, PREC}@{10,15,20}
and rHR and rND scores to reveal the performance of recommenda-
tion and fairness regarding different variants of FairDGE. The Dec.
and Inc. columns denote the comparison with FairDGE about the
average decreasing percentage performance scores and the average
increasing percentage fairness scores, respectively. The higher the
fairness scores, the more discrepancy between the disadvantaged
and advantaged vertices, resulting in unfairness.
In Table 4, the first row of variants is our proposed FairDGE,
achieving the best performance and fairness scores. The second
row is FairDGE without the fairness loss L𝑓𝑎𝑖𝑟. The performance
decreases by 38.13%, and fairness increases by 17.12%, indicating
that both performance and fairness become worse when removing
the fairness loss. This validates that our fairness loss not only im-
proves the fairness but also breaks the effectiveness bottleneck and
results in better performance.
The third row in Table 4 is FairDGE without the intermedia
training tasks of classifying the biased structural evolutions, which
differentiates the FaT, T2H, and SfHvertex groups. This module in-
fluences the most minor performance of the downstream task, but it
contributes much to fairness because this classification module aims
 
1706Toward Structure Fairness in Dynamic Graph Embedding: A Trend-aware Dual Debiasing Approach KDD ’24, August 25–29, 2024, Barcelona, Spain
Table 3: FairDGE compares with 8 baselines on performance and fairness.
Datasets Amazon
Books Mo
vieLens Go
odReads
BaselinesPerformance
(↑) Fairness
(↓) Performance
(↑) Fairness
(↓) Performance
(↑) Fairness
(↓)
HR@20
NDCG@20 PREC@20 rHR
rND HR@20
NDCG@20 PREC@20 rHR
rND HR@20
NDCG@20 PREC@20 rHR
rND
GCN 0.0726±0.034
0.0285±0.016 0.0036±0.002 0.1557±0.003
0.2614±0.014 0.0904±0.047
0.0420±0.029 0.0045±0.002 0.3265±0.020
0.5433±0.222 0.0641±0.071
0.0255±0.031 0.0032±0.003 0.3708±0.004
0.6865±0.027
w/L𝑓
𝑎𝑖𝑟 0.0799±0.051
0.0313±0.027 0.0040±0.003 0.1550±0.003
0.2568±0.020 0.0769±0.105
0.0347±0.041 0.0038±0.005 0.3207±0.027
0.5720±0.157 0.0767±0.002
0.0309±0.001 0.0038±0.000 0.3703±0.001
0.6651±0.021
GA
T 0.0655±0.010
0.0261±0.004 0.0033±0.001 0.1559±0.010
0.2715±0.047 0.1109±0.011
0.0492±0.003 0.0055±0.000 0.3568±0.002
0.6109±0.021 0.0771±0.015
0.0296±0.004 0.0038±0.001 0.3839±0.003
0.6403±0.010
w/L𝑓
𝑎𝑖𝑟 0.0654±0.003
0.0253±0.002 0.0033±0.000 0.1552±0.003
0.2658±0.009 0.0821±0.050
0.0348±0.025 0.0041±0.002 0.3549±0.009
0.6038±0.076 0.0789±0.004
0.0302±0.001 0.0039±0.001 0.3838±0.001
0.6402±0.013
MPNN-LSTM 0.1308±0.037
0.0514±0.018 0.0065±0.002 0.1553±0.007
0.2615±0.062 0.0359±0.013
0.0124±0.005 0.0018±0.001 0.3434±0.025
0.5947±0.045 0.0340±0.056
0.0128±0.022 0.0017±0.003 0.3683±0.028
0.6729±0.050
w/L𝑓
𝑎𝑖𝑟 0.1330±0.036
0.0520±0.018 0.0066±0.002 0.1553±0.006
0.2607±0.039 0.0404±0.022
0.0135±0.003 0.0020±0.001 0.3431±0.041
0.5932±0.050 0.0403±0.014
0.0153±0.003 0.0020±0.001 0.3679±0.010
0.6651±0.041
Ev
olveGCN 0.0526±0.024
0.0208±0.011 0.0026±0.002 0.1555±0.010
0.2630±0.093 0.1707±0.012
0.0586±0.017 0.0085±0.000 0.3544±0.050
0.5332±0.083 0.0648±0.096
0.0279±0.001 0.0033±0.005 0.3192±0.038
0.5549±0.031
w/L𝑓
𝑎𝑖𝑟 0.0504±0.050
0.0199±0.026 0.0025±0.003 0.1552±0.004
0.2584±0.008 0.1574±0.088
0.0556±0.027 0.0079±0.004 0.3531±0.013
0.5261±0.049 0.0628±0.110
0.0252±0.042 0.0032±0.006 0.3162±0.045
0.5448±0.202
Fair
GNN 0.1792±0.006
0.0816±0.047 0.0090±0.001 0.1547±0.006
0.2546±0.019 0.1782±0.014
0.0713±0.032 0.0089±0.000 0.3787±0.067
0.6719±0.028 0.0695±0.001
0.0242±0.001 0.0034±0.000 0.5149±0.000
0.7096±0.003
w/L𝑓
𝑎𝑖𝑟 0.1855±0.071
0.0877±0.038 0.0093±0.004 0.1537±0.008
0.2515±0.048 0.1809±0.017
0.0737±0.017 0.0091±0.001 0.3750±0.051
0.6405±0.139 0.0749±0.005
0.0267±0.004 0.0037±0.001 0.5148±0.074
0.7049±0.008
Fair
VGNN 0.1743±0.127
0.0830±0.075 0.0087±0.006 0.1543±0.006
0.2516±0.139 0.1385±0.194
0.0782±0.322 0.0069±0.010 0.3472±0.038
0.5811±0.247 0.0846±0.033
0.0329±0.006 0.0043±0.002 0.4481±0.120
0.6399±0.411
w/L𝑓
𝑎𝑖𝑟 0.1712±0.139
0.0816±0.093 0.0087±0.008 0.1539±0.004
0.2453±0.067 0.1281±0.088
0.1035±0.069 0.0064±0.005 0.3375±0.017
0.5683±0.223 0.0850±0.020
0.0339±0.021 0.0042±0.001 0.4425±0.139
0.6023±0.251
DegFair
GNN 0.1692±0.005
0.0774±0.018 0.0085±0.001 0.1601±0.012
0.3172±0.009 0.1205±0.052
0.0481±0.014 0.0060±0.003 0.3612±0.004
0.6685±0.105 0.0526±0.018
0.0201±0.008 0.0024±0.003 0.4659±0.053
0.6592±0.0027
w/L𝑓
𝑎𝑖𝑟 0.1778±0.029
0.0818±0.050 0.0089±0.002 0.1590±0.008
0.3103±0.024 0.1208±0.015
0.0480±0.012 0.0060±0.001 0.3606±0.016
0.6615±0.094 0.0517±0.019
0.0202±0.006 0.0026±0.001 0.4654±0.019
0.6579±0.022
T
ailGNN 0.1289±0.005
0.0631±0.103 0.0088±0.020 0.1543±0.005
0.2578±0.028 0.1887±0.075
0.0928±0.033 0.0095±0.004 0.3754±0.026
0.6564±0.098 0.0836±0.022
0.0341±0.007 0.0042±0.001 0.5086±0.042
0.6086±0.059
w/L𝑓
𝑎𝑖𝑟 0.1316±0.061
0.0654±0.086 0.0082±0.017 0.1541±0.005
0.2517±0.062 0.1924±0.038
0.0946±0.025 0.0096±0.002 0.3692±0.034
0.6191±0.163 0.0773±0.017
0.0319±0.017 0.0039±0.001 0.5082±0.056
0.6072±0.051
FairDGE 0.2006±0.033
0.0894±0.012 0.0100±0.002 0.1487±0.004
0.2061±0.031 0.2626±0.049
0.1330±0.039 0.0131±0.002 0.3189±0.020
0.1824±0.103 0.1029±0.016
0.0383±0.012 0.0052±0.001 0.3087±0.033
0.3503±0.006
Impr
ovement 8.18%
1.98% 7.91% 3.27%
15.98% 36.46%
28.50% 36.33% 0.56%
65.32% 21.11%
12.30% 21.09% 2.37%
35.69%
Table 4: Ablation study of variants on both performance and fairness. ¬means the variant without the following module.
Performance(↑) Fairness(↓)
V
ariants HR@{10,15,20} NDCG@{10,15,20} PREC@{10,15,20} De
c. rHR rND Inc.
FairDGE 0.1256 0.1690 0.2025 0.0704 0.0823 0.0903 0.0126 0.0113 0.0101 - 0.1489 0.2075 -
FairDGE¬
L𝑓𝑎𝑖𝑟 0.0730 0.1068 0.1396 0.0391 0.0483 0.0562 0.0073 0.0071 0.0070 38.13% 0.1551 0.2699 17.12%
FairDGE¬
L𝑐𝑙𝑎𝑠𝑠 0.0940 0.1325 0.1672 0.0490 0.0595 0.0679 0.0094 0.0088 0.0084 23.49% 0.1536 0.2605 14.35%
FairDGE¬
L𝑐𝑜𝑛𝑡𝑟𝑎𝑠𝑡 0.0646 0.1024 0.1342 0.0334 0.0437 0.0513 0.0065 0.0068 0.0067 42.92% 0.1552 0.2728 17.85%
FairDGE¬ Deg 0.0681 0.0932 0.1199 0.0361 0.0429 0.0493 0.0068 0.0062 0.0060 45.02% 0.1524 0.2282 6.16%
FairDGE¬ GRU 0.0456 0.0681 0.0856 0.0254 0.0315 0.0357 0.0046 0.0045 0.0043 60.93% 0.1568 0.2792 19.93%
to separate disadvantaged vertices from all vertices, contributing
to the following fairness treatment.
FairDGE¬L𝑐𝑜𝑛𝑡𝑟𝑎𝑠𝑡 denotes a variant without contrastive learn-
ing in the dual debiasing. The results show that contrastive learning
contributes most in FairDGE to both downstream task performance
and fairness because it assists in bringing closer the embeddings
with identical biased structural evolution and penalizing those with
different ones, further proving the effectiveness of contrastive learn-
ing on structural fairness.
The next variant is removing the degree evolving trend learn-
ing module introduced in Section 4.2.1 from the FairDGE, which
contributes to the second-best performance but slightly influences
fairness. It is because the supervised classification of biased struc-
tural evolutions takes more effort in bias detection, but degree
evolving trend learning is more about the dynamic graph embed-
ding backbone for biased structural evolution learning, which limits
its influence on performance and fairness.
The last variant is FairDGE without dynamic structural evo-
lution modeling, which is the GRU layers in the dynamic graph
embedding backbone. This variant models the data statically and
will not differentiate the biased structural evolutions. Obviously, it
performs the worst, demonstrating that dealing with the evolving
bias caused by structural changes in dynamic graphs is essential,
and our FairDGE solves this problem very well. In summary, each
module of FairDGE is indispensable and contributes to performance
and fairness to varying degrees.
5.4 Hyperparameter Study
To study the influence of different hyperparameters on performance
and fairness, we conducted hyperparameter studies on the Ama-
zon Books dataset to test different numbers of snapshots, different
model dimensions, different head/tail ratio percentages, and dif-
ferent number of time-sliding windows. For each hyperparameter
(a) Snapshots numbers
 (b) Model dimensions
(c) Head/tail ratios
 (d) No. of time-sliding windows
Figure 2: Results of hyperparameter testing.
study, we present the average scores after five runs for a fair com-
parison. The x-axis of Figure 2 denotes different hyperparameters.
The left y-axis displays HR@10 and HR@20 to illustrate the per-
formance trend in recommendation tasks, while the right y-axis
exhibits the inversed fairness scores (1/rHR and 1/rND) for conve-
nient visualization. This maintains a consistent interpretation for
both sides of metrics, where higher hit rates and higher inversed
fairness scores indicate better performance and fairness.
Due to the page limit, we also report the additional hyperparam-
eter testing on loss hyperparameters in Section E.2 of the Appendix.
 
1707KDD ’24, August 25–29, 2024, Barcelona, Spain Yicong Li et al.
5.4.1 Different Number of Snapshots. To reveal the influence of the
number of snapshots on performance and fairness, we report the
trend of performance and fairness in Figure 2a. The larger the num-
ber of snapshots, the shorter the time period within each snapshot.
We observe a slight decrease in the performance trend as the num-
ber of snapshots increases. The reason is that the increased number
of snapshots results in sparser snapshot graphs as the number of
edges in the snapshot graph decreases. Eventually, the snapshot
graph will become sparse, containing rare edge information and
deteriorating the performance of each snapshot. Additionally, we
use GRU in the dynamic graph embedding backbone, which is not
good at capturing long-term temporal evolutions. This also causes
the performance to drop with increasing snapshots. Fortunately,
leveraging more advanced dynamic graph embedding algorithms
in the backbone, which widely exist in the community, could solve
this problem and further improve the performance of our FairDGE.
From a fairness perspective, more snapshots allow us to obtain
finer granular data for capturing the structure evolution in the dy-
namic graph, helping FairDGE accurately train the degree-evolving
trend module to capture change across the evolution snapshots
better. Consequently, this benefits our model in effectively identify-
ing different biased vertex groups, eventually improving fairness.
Lastly, the performance and fairness trends reverse as the number
of snapshots increases, consistent with the widely accepted notion
that performance and fairness tend to be a trade-off.
5.4.2 Different Dimensions. Figure 2b illustrates the variations in
performance and fairness as the dimension of embeddings varies
in{8,16,32,64,128}. HR@{10,20} exhibits notably low values at
the dimension of 8 but experiences a steep increase after 32. Sub-
sequently, the performance reaches its peak at 64. Regarding the
fairness scores, it initially performs poorly at the lowest dimension
but reaches the best when the dimension of embeddings is 64. How-
ever, when the dimension is 128, the fairness scores decrease and
become the second-best due to over-training. As a result, we select
a default dimension setting of 64 for all the experiments.
5.4.3 Different head/tail ratio percentages. We vary the head ver-
tex group ratio ranges from 10% to 40% and test the impacts on
FairDGE’s performance and fairness. Interestingly, we observe that
the performance remains consistent across different head/tail ra-
tios in Figure 2c, highlighting the stability and reliability of our
proposed FairDGE algorithm. Although there is a slight peak at a
20% head vertex split ratio, the overall performance remains unaf-
fected. In contrast, fairness consistently improves with higher head
vertex split ratios. By analyzing the proportions of T2H, FaT, and
SfH under different head vertex split ratios, we reveal the principle
behind this fairness trend. Higher head vertex split ratios result
in fewer T2H vertices, reducing the number of vertices used for
fairness comparison.
5.4.4 Different number of time-sliding windows. We conduct this
experiment to discuss the performance and fairness changing trend
if there is a time sliding window to narrow the focusing degree
changing range. Figure 2d reveals the performance and fairness
changing with the number of time-sliding windows. The time slid-
ing window length is the overall 𝑇timestamps. Similarly, if there
are{1,2,4,8}sliding windows and the number of timestamps is
(a) Training loss w.r.t epoch
 (b) Training time w.r.t data ratio
Figure 3: Convergence and scalability of FairDGE.
(a) GCN
 (b) FairDGE
Figure 4: Effectiveness of fairness loss L𝑓𝑎𝑖𝑟.
fixed to 8, each time sliding window contains {8,4,2,1}snapshots,
respectively. The figure shows that the performance and fairness in-
crease as the number of sliding windows grows to 4. As the number
of time-sliding windows increases to 8, the model becomes static
with 1 snapshot per time-sliding window, resulting in the worst
performance and fairness.
5.5 Convergence and Scalability
The convergence curve of training FairDGE on the entire Amazon
Books dataset is presented in Figure 3a, showing that FairDGE
converges at approximately 60 epochs. The x-axis represents the
number of training epochs, while the y-axis represents the training
loss. Additionally, we test the scalability of FairDGE by randomly
selecting {20%, 40%, 60%, 80%, 100%} percentages of the training
data from the Amazon Books dataset to train FairDGE and report
the average training time per epoch in Figure 3b. As the volume
of training data increases, FairDGE’s training time grows almost
linearly, demonstrating that FairDGE has good scalability.
5.6 Effectiveness Analysis of Fairness
In this section, we first discuss the effectiveness of fairness loss
L𝑓𝑎𝑖𝑟on the T2H and SfH vertex groups and then reveal the supe-
riority of capturing structural evolution for debiasing against the
conventional high- and low-degree-based fairness.
5.6.1 Effectiveness of Fairness Loss L𝑓𝑎𝑖𝑟on The T2H and SfH Vertex
Groups. To demonstrate the effectiveness of our proposed fairness
lossL𝑓𝑎𝑖𝑟on the disadvantage group (T2H ) and advantage group
(SfH), we analyze the embedding performance in downstream tasks.
The closer the performance of T2H and SfH vertex groups, the
better the fairness. Specifically, we compare the HR@20 scores
of all the biased vertex groups with and without the fairness loss
L𝑓𝑎𝑖𝑟 on GCN and FairDGE. The results are shown in Figure 4,
where the x-axis denotes whether the fairness loss is used and the
 
1708Toward Structure Fairness in Dynamic Graph Embedding: A Trend-aware Dual Debiasing Approach KDD ’24, August 25–29, 2024, Barcelona, Spain
(a) GCN.
 (b) GAT.
Figure 5: Effectiveness of debiasing structural evolutions.
Table 5: Fairness of debiasing structural evolutions.
rHR (↓) rND (↓)
GCN w/o Fairness 0.1559 0.2627
w/ Degree Fairness 0.1553 (0.4%↓)0.2578 (2%↓)
w/L𝑓𝑎𝑖𝑟 0.1547 (0.8%↓)0.2551 (3%↓)
GAT w/o Fairness 0.1569 0.2765
w/ Degree Fairness 0.1557 (0.8%↓)0.2711 (2%↓)
w/L𝑓𝑎𝑖𝑟 0.1550 (1.2%↓)0.2649 (4%↓)
y-axis represents the HR@20 scores for performance comparison.
In each result set, the two bars represent the HR@20 scores of
T2H andSfH, respectively. We observe that, without L𝑓𝑎𝑖𝑟, GCN
exhibits a significant performance gap between T2H andSfH, and
the performance is much close after equipping L𝑓𝑎𝑖𝑟. A similar
phenomenon is observed in FairDGE. This indicates that the fairness
lossL𝑓𝑎𝑖𝑟effectively narrows the performance gap between the
T2H andSfHvertex groups, thereby improving fairness.
5.6.2 Effectiveness of Capturing Structural Evolution for Debiasing
against Degree Fairness. Degree fairness prevents the performance
disparity of head- and tail-degree vertex groups. To further vali-
date that capturing structural evolution for debiasing is better than
static degree fairness, We divide vertices into head- and tail-degree
vertex groups to train GCN and GAT with fairness loss L𝑓𝑎𝑖𝑟and
compare the performance with GCN and GAT trained on the T2H
and SfH vertex groups. The results in Figure 5 and Table 5 validate
that capturing structural evolution to debias dynamic graph embed-
ding is capable of achieving fairness without sacrificing and even
improving embedding performance, which degree fairness cannot.
These results also demonstrate that our debiasing method can be
used as a general fairness plug-in, enabling existing dynamic graph
embedding algorithms to achieve structural fairness.
6 RELATED WORK
6.1 Toward Fairness in Static Graph Learning
Although learning structurally fair dynamic graph embedding re-
mains an under-explored area, several studies have successfully
learned fair embeddings for static graphs [ 40], eliminating disparate
treatment or impacts to sensitive graph attributes and structures.
To deal with the sensitive graph attributes, various methodologies,
such as adversarial learning [ 7,41], resampling techniques [ 36,50],
and fair-aware loss constraints [ 9,10], have been developed to
mitigate bias and promote fairness. Specifically, [ 7,41] adopts ad-
versarial learning to make the discriminators ambiguous about thesensitive feature distinguish, resulting in a fair graph neural net-
work to treat different biased groups equally. To alleviate bias, [ 24]
resamples the vertices to balance the distribution of the sensitive
features. Some studies [ 9,10] propose adding fair constraints to the
loss for learning fair graph representations. However, none of them
address structure fairness, e.g., degree fairness, in graph learning.
To address the bias introduced by the graph structure, early work
revealed that the long-tail distribution of vertex degree caused fair-
ness issues due to the poor embedding performance of tail vertices
[16,19]. Few-shot learning [ 42,48], contrastive learning [ 39], re-
sample [ 38,50], data augmentation [ 47] approaches were proposed
to narrow the performance gap between head and tail vertices. Tail-
GNN [ 16] and Meta-Tail2vec [ 19] are the representative works that
improve the expressivity of GNN on tail vertices, which surpris-
ingly improves the fairness. Recently, DegFairGNN [ 17] defined
the degree fairness problem in static graph learning for the first
time and proposed a fairness constraint to debias the imbalanced
degrees of vertices. However, none of the existing studies account
for the problem of structure fairness in dynamic graph learning.
Our work fills this research gap.
6.2 Toward Fairness on Dynamic Euclidean Data
Fairness is a critical problem in many scenarios where time and
dynamics matter, including dynamic allocation [ 28], job prediction
[27], and so on. Therefore, some research works [ 27,28,36] alle-
viate the bias by dynamic solutions, including Markov Decision
Processes (MDPs) [ 51], adaptive threshold policy [ 29] and so on.
The main research solutions cover fairness accumulation across
timestamps [ 28] and long-term fairness increment [ 36]. However,
research on fair graph learning or graph embeddings in dynamic
scenarios, e.g., dynamic graph embedding [ 33], is scarce. Different
from the above-mentioned approaches that isolate the fairness for
each timestamp, our study takes into account the evolving trend
of vertices’ degrees and incorporates graph structural evolution to
learn fair representations in dynamic graphs.
7 CONCLUSION
In this paper, we investigate the structure fairness problem in dy-
namic graph embedding for the first time. We empirically validate
that structural evolutions in a dynamic graph approximately follow
a long-tailed power-law distribution. This makes dynamic graph
embedding algorithms exhibit structure unfairness. We innovatively
propose a structurally Fair Dynamic Graph Embedding algorithm,
namely FairDGE, which first learns trend-aware structural evolu-
tions and then encodes structurally fair embeddings by a novel
dual debiasing approach. FairDGE can be used as a general fairness
plug-in, enabling existing dynamic graph learning algorithms to
generate structurally fair embeddings.
ACKNOWLEDGEMENT
This work was partially conducted at the Research Institute for
Artificial Intelligence of Things (RIAIoT) at PolyU. It is supported by
the Hong Kong Research Grants Council (RGC) under the Theme-
based Research Scheme with Grant No. T43-513/23-N and T41-
603/20-R, and under Research Impact Fund with Grant No. R5034-
18. This work is also supported by the Australian Research Council
(ARC) under Grant No. DP220103717, and LE220100078.
 
1709KDD ’24, August 25–29, 2024, Barcelona, Spain Yicong Li et al.
REFERENCES
[1]Albert-László Barabási and Réka Albert. 1999. Emergence of scaling in random
networks. science 286, 5439 (1999), 509–512.
[2]Solon Barocas and Andrew D Selbst. 2016. Big data’s disparate impact. California
law review (2016), 671–732.
[3]Derrick Blakely, Jack Lanchantin, and Yanjun Qi. 2021. Time and space complexity
of graph convolutional networks. Accessed on: Dec 31 (2021), 2021.
[4]Ines Chami, Zhitao Ying, Christopher Ré, and Jure Leskovec. 2019. Hyperbolic
graph convolutional neural networks. In Advances in Neural Information Process-
ing Systems. 4869–4880.
[5]Hongxu Chen, Yicong Li, Xiangguo Sun, Guandong Xu, and Hongzhi Yin. 2021.
Temporal meta-path guided explainable recommendation. In Proceedings of the
14th ACM international conference on web search and data mining. 1056–1064.
[6]Enyan Dai, Wei Jin, Hui Liu, and Suhang Wang. 2022. Towards robust graph
neural networks for noisy graphs with sparse labels. In Proceedings of the Fifteenth
ACM International Conference on Web Search and Data Mining. 181–191.
[7] Enyan Dai and Suhang Wang. 2021. Say no to the discrimination: Learning fair
graph neural networks with limited sensitive attribute information. In Proceedings
of the 14th ACM International Conference on WSDM. 680–688.
[8]Cynthia Dwork, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Richard
Zemel. 2012. Fairness through awareness. In Proceedings of the 3rd innovations in
theoretical computer science conference. 214–226.
[9]Zuohui Fu, Yikun Xian, Ruoyuan Gao, Jieyu Zhao, Qiaoying Huang, Yingqiang
Ge, Shuyuan Xu, Shijie Geng, Chirag Shah, Yongfeng Zhang, et al .2020. Fairness-
aware explainable recommendation over knowledge graphs. In Proceedings of
the 43rd International ACM SIGIR. 69–78.
[10] Yingqiang Ge, Juntao Tan, Yan Zhu, Yinglong Xia, Jiebo Luo, Shuchang Liu,
Zuohui Fu, Shijie Geng, Zelong Li, and Yongfeng Zhang. 2022. Explainable
fairness in recommendation. In Proceedings of the 45th International ACM SIGIR.
681–691.
[11] Thomas N Kipf and Max Welling. 2016. Semi-supervised classification with graph
convolutional networks. arXiv preprint arXiv:1609.02907 (2016).
[12] Jon Kleinberg, Jens Ludwig, Sendhil Mullainathan, and Ashesh Rambachan. 2018.
Algorithmic fairness. In Aea papers and proceedings, Vol. 108. American Economic
Association 2014 Broadway, Suite 305, Nashville, TN 37203, 22–27.
[13] Öykü Deniz Köse and Yanning Shen. 2021. Fairness-aware node representation
learning. arXiv preprint arXiv:2106.05391 (2021).
[14] Haoyang Li and Lei Chen. 2023. EARLY: Efficient and Reliable Graph Neural
Network for Dynamic Graphs. Proceedings of the ACM on Management of Data 1,
2 (2023), 1–28.
[15] Yicong Li, Xiangguo Sun, Hongxu Chen, Sixiao Zhang, Yu Yang, and Guandong
Xu. 2024. Attention Is Not the Only Choice: Counterfactual Reasoning for Path-
Based Explainable Recommendation. IEEE TKDE (mar 2024), 1–14.
[16] Zemin Liu, Trung-Kien Nguyen, and Yuan Fang. 2021. Tail-GNN: Tail-Node
Graph Neural Networks. In Proceedings of the 27th ACM SIGKDD Conference on
Knowledge Discovery & Data Mining. 1109–1119.
[17] Zemin Liu, Trung Kien Nguyen, and Yuan Fang. 2023. On generalized degree
fairness in graph neural networks.(2023). In Proceedings of the 37th AAAI. 7–14.
[18] Zheyuan Liu, Chunhui Zhang, Yijun Tian, Erchi Zhang, Chao Huang, Yanfang
Ye, and Chuxu Zhang. 2023. Fair Graph Representation Learning via Diverse
Mixture of Experts. In The Web Conference.
[19] Zemin Liu, Wentao Zhang, Yuan Fang, Xinming Zhang, and Steven CH Hoi. 2020.
Towards locality-aware meta-learning of tail node embeddings on networks. In
Proceedings of the 29th ACM CIKM. 975–984.
[20] Maximillian Nickel and Douwe Kiela. 2017. Poincaré embeddings for learning
hierarchical representations. NeurIPS 30 (2017).
[21] George Panagopoulos, Giannis Nikolentzos, and Michalis Vazirgiannis. 2021.
Transfer graph neural networks for pandemic forecasting. In Proceedings of the
AAAI Conference on Artificial Intelligence, Vol. 35. 4838–4845.
[22] Aldo Pareja, Giacomo Domeniconi, Jie Chen, Tengfei Ma, Toyotaro Suzumura,
Hiroki Kanezashi, Tim Kaler, Tao Schardl, and Charles Leiserson. 2020. Evolvegcn:
Evolving graph convolutional networks for dynamic graphs. In Proceedings of
the AAAI conference on artificial intelligence, Vol. 34. 5363–5370.
[23] Manish Raghavan. 2021. The Societal Impacts of Algorithmic Decision-Making.
Ph. D. Dissertation. Cornell University.
[24] Tahleen Rahman, Bartlomiej Surma, Michael Backes, and Yang Zhang. 2019.
Fairwalk: towards fair graph embedding. In IJCAI. 3289–3295.
[25] Michael Rotman and Lior Wolf. 2021. Shuffling recurrent neural networks. In
Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 35. 9428–9435.
[26] Aravind Sankar, Yanhong Wu, Liang Gou, Wei Zhang, and Hao Yang. 2020.
Dysat: Deep neural representation learning on dynamic graphs via self-attention
networks. In Proceedings of the 13th international conference on WSDM. 519–527.
[27] Sebastian Scher, Simone Kopeinik, Andreas Trügler, and Dominik Kowald. 2023.
Modelling the long-term fairness dynamics of data-driven targeted help on job
seekers. Scientific Reports 13, 1 (2023), 1727.
[28] Tareq Si Salem, Georgios Iosifidis, and Giovanni Neglia. 2022. Enabling long-term
fairness in dynamic resource allocation. Proceedings of the ACM on Measurementand Analysis of Computing Systems 6, 3 (2022), 1–36.
[29] Sean R Sinclair, Siddhartha Banerjee, and Christina Lee Yu. 2022. Sequential
fair allocation: Achieving the optimal envy-efficiency tradeoff curve. ACM
SIGMETRICS Performance Evaluation Review 50, 1 (2022), 95–96.
[30] Weihao Song, Yushun Dong, Ninghao Liu, and Jundong Li. 2022. Guide: Group
equality informed individual fairness in graph neural networks. In Proceedings
of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining.
1625–1634.
[31] Xiangguo Sun, Hong Cheng, Hang Dong, Bo Qiao, Si Qin, and Qingwei Lin. 2023.
Counter-Empirical Attacking based on Adversarial Reinforcement Learning for
Time-Relevant Scoring System. IEEE TKDE (2023).
[32] Xiangguo Sun, Hong Cheng, Bo Liu, Jia Li, Hongyang Chen, Guandong Xu,
and Hongzhi Yin. 2023. Self-supervised hypergraph representation learning for
sociological analysis. IEEE TKDE (2023).
[33] Haoran Tang, Shiqing Wu, Guandong Xu, and Qing Li. 2023. Dynamic graph
evolution learning for recommendation. In Proceedings of the 46th international
acm sigir conference on research and development in information retrieval. 1589–
1598.
[34] Wensi Tang, Guodong Long, Lu Liu, Tianyi Zhou, Jing Jiang, and Michael Blu-
menstein. 2020. Rethinking 1d-cnn for time series classification: A stronger
baseline. arXiv preprint arXiv:2002.10061 (2020), 1–7.
[35] Xianfeng Tang, Huaxiu Yao, Yiwei Sun, Yiqi Wang, Jiliang Tang, Charu Aggarwal,
Prasenjit Mitra, and Suhang Wang. 2020. Investigating and mitigating degree-
related biases in graph convoltuional networks. In ACM CIKM. 1435–1444.
[36] Zeyu Tang, Yatong Chen, Yang Liu, and Kun Zhang. 2023. Tier Balancing: Towards
Dynamic Fairness over Underlying Causal Factors. In International Conference
on Learning Representations (ICLR).
[37] Petar Veličković, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro
Liò, and Yoshua Bengio. 2018. Graph Attention Networks. In ICLR.
[38] Haohui Wang, Baoyu Jing, Kaize Ding, Yada Zhu, and Dawei Zhou. 2023. Charac-
terizing Long-Tail Categories on Graphs. arXiv preprint arXiv:2305.09938 (2023).
[39] Ruijia Wang, Xiao Wang, Chuan Shi, and Le Song. 2022. Uncovering the Struc-
tural Fairness in Graph Contrastive Learning. Advances in Neural Information
Processing Systems 35 (2022), 32465–32473.
[40] Xiangmeng Wang, Qian Li, Dianer Yu, Qing Li, and Guandong Xu. 2024. Re-
inforced path reasoning for counterfactual explainable recommendation. IEEE
Transactions on Knowledge and Data Engineering (2024).
[41] Yu Wang, Yuying Zhao, Yushun Dong, Huiyuan Chen, Jundong Li, and Tyler
Derr. 2022. Improving fairness in graph neural networks via mitigating sensi-
tive attribute leakage. In Proceedings of the 28th ACM SIGKDD Conference on
Knowledge Discovery and Data Mining. 1938–1948.
[42] Han Wu, Jie Yin, Bala Rajaratnam, and Jianyuan Guo. 2022. Hierarchical Re-
lational Learning for Few-Shot Knowledge Graph Completion. In The Eleventh
International Conference on Learning Representations.
[43] Ke Yang and Julia Stoyanovich. 2017. Measuring fairness in ranked outputs. In
Proceedings of the 29th international conference on scientific and statistical database
management. 1–6.
[44] Yu Yang, Jiannong Cao, Milos Stojmenovic, Senzhang Wang, Yiran Cheng, Chun
Lum, and Zhetao Li. 2021. Time-capturing dynamic graph embedding for tempo-
ral linkage evolution. IEEE TKDE 35, 1 (2021), 958–971.
[45] Yu Yang, Hongzhi Yin, Jiannong Cao, Tong Chen, Quoc Viet Hung Nguyen,
Xiaofang Zhou, and Lei Chen. 2023. Time-aware dynamic graph embedding for
asynchronous structural evolution. IEEE TKDE (2023).
[46] Jiaxuan You, Tianyu Du, and Jure Leskovec. 2022. ROLAND: graph learning
framework for dynamic graphs. In Proceedings of the 28th ACM SIGKDD Confer-
ence on Knowledge Discovery and Data Mining. 2358–2366.
[47] Junliang Yu, Hongzhi Yin, Xin Xia, Tong Chen, Lizhen Cui, and Quoc Viet Hung
Nguyen. 2022. Are graph augmentations necessary? simple graph contrastive
learning for recommendation. In ACM SIGIR. 1294–1303.
[48] Chuxu Zhang, Huaxiu Yao, Chao Huang, Meng Jiang, Zhenhui Li, and Nitesh V
Chawla. 2020. Few-shot knowledge graph completion. In Proceedings of the AAAI
conference on artificial intelligence, Vol. 34. 3041–3048.
[49] Mengqi Zhang, Shu Wu, Xueli Yu, Qiang Liu, and Liang Wang. 2022. Dynamic
graph neural networks for sequential recommendation. IEEE Transactions on
Knowledge and Data Engineering 35, 5 (2022), 4741–4753.
[50] Hong Zhao, Shunxin Guo, and Yaojin Lin. 2021. Hierarchical classification of
data with long-tailed distributions via global and local granulation. Information
Sciences 581 (2021), 536–552.
[51] Matthieu Zimmer, Claire Glanois, Umer Siddique, and Paul Weng. 2021. Learning
fair policies in decentralized cooperative multi-agent reinforcement learning. In
International Conference on Machine Learning. PMLR, 12967–12978.
 
1710Toward Structure Fairness in Dynamic Graph Embedding: A Trend-aware Dual Debiasing Approach KDD ’24, August 25–29, 2024, Barcelona, Spain
APPENDIX
A AN APPLICATION OF FAIR DYNAMIC
GRAPH EMBEDDING
Learning fair embeddings for dynamic graphs is essential and has
wide real-world applications. Taking user-item recommendations
as an example, suppose we merely train a recommendation model
without considering the fairness between head (popular) and tail
(unpopular) groups of items in the long-tailed power-law distri-
bution. A handful of head (popular) items will easily dominate
the models, leading to a much higher probability of being recom-
mended than the tail (unpopular) ones. As a result, the variety of
items recommended to users is greatly reduced. Degree fair static
graph embedding solves this issue by minimizing the performance
disparity of head and tail items, making them have approximately
equal probability of being recommended. However, not all tail (un-
popular) items deserve the same recommendation probability as the
head (popular) ones. Some tail items are of poor quality and users
usually dislike them. If the model recommends these low-quality
items to users as frequently as it recommends high-quality items,
it will seriously impair the quality of service. Therefore, we ar-
gue that only a subset of high-quality tail items deserves the same
recommendation probability as the head (popular) items. These
high-quality tail items will gradually be liked by users and become
popular. In other words, they gradually move from tail to head.
This phenomenon is also observed in the Amazon Book dataset, as
the statistics of tail-to-head (T2H) vertices in Table 1 in Section 3.
Making T2H items have a similar recommendation probability as
the head ones can increase their exposure and shorten their time
to become popular. We abstract this as a structure fairness problem
in dynamic graph embedding.
B PERFORMANCE DEGRADATION OF
EXISTING STRUCTURAL FAIRNESS
METHODS IN DYNAMIC GRAPH
EMBEDDING
Given that the vertex degree of real-world graphs usually follows
a long-tailed power-law distribution, existing structural fairness
methods prevent the performance disparity of high- and low-degree
vertex groups in downstream graph mining tasks without consid-
ering the evolving trend of degree. When applying the structural
fairness methods in dynamic graph embedding, the tail-to-head
vertices will be treated as head ones. Due to the limited connection
information carried by the tail vertices, their embedding perfor-
mance is usually much worse than that of the head (including
tail-to-head) vertices and is difficult to boost. When the model min-
imizes the performance disparity between tail and head vertices to
achieve fairness, the performance of head vertices will significantly
drop close to the generally poorer embedding performance of the
tail vertices.
Our FairDGE first debiases the embeddings via contrastive learn-
ing, increasing the performance of fluctuation-at-tail (FaT) vertices
and resulting in a smaller performance gap with tail-to-head (T2H)
and starting-from-head (SfH) vertices. In addition, we eliminate
the performance disparity of T2H and SfH vertices’ embeddings
in downstream tasks for a second debiasing. Notably, FaT verticesTable 6: HR@20 of existing structural fairness against trend-
aware fairness in dynamic graph embedding.
w/ Degree fairness w/L𝑓𝑎𝑖𝑟
MPNN-LSTM 0.1285 0.1297
FairDGE 0.2010 0.2025
are excluded from the second debiasing so that they can pursue the
best performance in downstream tasks and avoid dragging down
the performance of T2H and SfH vertices. By making the embed-
ding performance of SfH and T2H vertices high and close while
improving the embedding performance of FaT vertices as much as
possible to narrow the gap with that of SfH and T2H, our approach
successfully achieves structure fairness without sacrificing or even
improving embedding effectiveness.
We conduct an experiment on the Amazon Books dataset to em-
pirically demonstrate the performance degradation of head (includ-
ing tail-to-head) vertices when applying existing degree fairness
methods in dynamic graph embedding. We set a degree threshold
of 4 to determine the head and tail vertices and annotate the FaT,
T2H, and SfH vertices in dynamic graphs. We first train MPNN-
LSTM [ 21], which is a dynamic graph embedding method, and
FairDGE on head- and tail-degree vertex groups and report the
HR@20 scores in the column of w/ Degree fairness in Table 6. Next,
we train MPNN-LSTM and FairDGE with our designed fairness
lossL𝑓𝑎𝑖𝑟in Eq. (10) on FaT, T2H, and SfH groups. The HR@20
scores are shown in the column of w/ L𝑓𝑎𝑖𝑟in Table 6. The HR@20
scores of both MPNN-LSTM and FairDGE with traditional degree
fairness are lower than that of using our proposed fairness approach
which considers the evolving trend of degrees in the dynamic graph.
This validates the performance degradation when applying existing
structural fairness methods in dynamic graph embedding.
C SYMBOL DESCRIPTIONS
Table 7 is the symbol description used in this manuscript.
Table 7: Symbol descriptions.
Symb
ols Descriptions
G𝑡=(
V𝑡,E𝑡)Static
snapshot graph, vertex set, edge set at time 𝑡
G=(V,E) D
ynamic graph, vertex set, edge set
ℎ∈H A
representation vector (embedding)
H𝑇2𝐻
VT
ail-to-head vertex representations
H𝑆𝑓𝐻
VStarting-fr
om-head vertex representations
𝑡∈𝑇 Timestamps
𝑞 The
number of vertex groups
𝑑𝑖𝑚 Repr
esentation dimensions
⊕ Stack
operator
𝜛 Head/tail
ratio threshold
𝑑(·) Short-term
trend encoder
ˆ𝑑(·) Long-term
trend encoder
𝑑𝑒𝑔(·) Degr
ee of vertex
𝑦∈𝑌 Lab
els of biased structural evolution
(𝑣,𝑣+) Positiv
e vertex pair from same structural evolution group
(𝑣,𝑣−) Negativ
e vertex pair from different structural evolution groups
L𝑐𝑙𝑎𝑠𝑠 Classification
loss
L𝑐𝑜𝑛𝑡𝑟𝑎𝑠𝑡 Contrastiv
e loss
L𝐷𝑆 Do
wnstream task loss
L𝑓𝑎𝑖𝑟 Fairness
loss
𝛾1,𝛾2,𝛾3,𝛾4 Loss
hyperparameters
||Θ||1,||Θ||2ℓ1,ℓ2norm
of model parameters
𝑝𝑒 Pr
obability of edge 𝑒existing
𝑘 T
op𝑘prediction list
 
1711KDD ’24, August 25–29, 2024, Barcelona, Spain Yicong Li et al.
D ANNOTATING ALGORITHM FOR FAT, T2H,
AND SFH
We devise a slope-based algorithm in Algorithm 1, identifying the
degree evolving trend to annotate FaT, T2H, and SfH. 𝜌is set to 0
in our experiments.
Algorithm 1 Slope-based Annotation Algorithm
Input: Vertex setV, timestamp range 𝑇, head/tail ratio threshold 𝜛, degree
variation threshold 𝜌.
Output: Label set𝑌forV, where𝑦∈{𝐹𝑎𝑇,𝑇 2𝐻,𝑆𝑓𝐻}is the label of
structural evolution for vertex 𝑣∈𝑉.
head_num =|V|×𝜛
head_group = sort(deg( V))[:head_num]
forvertex𝑣inVdo
if𝑣𝑡in head_group then
𝑦𝑣=𝑆𝑓𝐻 ;
else
𝑎𝑟𝑔𝑚𝑎𝑥(𝑑𝑒𝑔(𝑣𝑇))//Find the time when 𝑣has the biggest degree;
𝑎𝑟𝑔𝑚𝑖𝑛(𝑑𝑒𝑔(𝑣𝑇))//Find the time when 𝑣has the smallest de-
gree;
if𝑎𝑟𝑔𝑚𝑎𝑥(𝑑𝑒𝑔(𝑣𝑇))−𝑎𝑟𝑔𝑚𝑖𝑛(𝑑𝑒𝑔(𝑣𝑇))>𝜌then
𝑦𝑣=𝑇2𝐻;
else
𝑦𝑣=𝐹𝑎𝑇;
end if
end if
end for
return𝑌
E EXPERIMENTS
E.1 Experiment Configurations and
Implementation Details
To ease reproductivity, we provide the experiment configurations
and implementation details of FairDGE.
For all fair graph learning baselines, including FairGNN, Fair-
VGNN, DegFairGNN, and TailGNN, we adopted the source code
released by the authors in GitHub and incorporated them into our
code framework. The GCN and GAT models are implemented by
theHGCN [4] framework, and the Euclidean space version is used.
For MPNN-LSTM and EvolveGCN, we adopted the implementation
in the PyTorch Geometric Temporal library. The hidden layer version
of EvolveGCN is used in the experiments. The default parameters
are employed for all baseline methods, but we tune the learning
rate for each baseline to get the best results.
Our proposed method, FairDGE, is implemented by PyTorch. The
learning rate is set to 5e-4 after parameter searching. The model
dimensions are set the same for FairDGE and all baselines, enabling
a fair comparison. The number of GNN layers in FairDGE is set
to 2. In addition to benchmarking the performance of FairDGE
against the original version of the baselines, we added our fair
lossL𝑓𝑎𝑖𝑟to each baseline and further validated the effectiveness
of the fair loss. FairGNN and FairVGNN train a discriminator to
eliminate the performance diversity between the advantaged and
disadvantaged sensitive group of vertices. We align their methods
to train the discriminator for SfH, T2H, and FaT. Since DegFairGNNTable 8: Different loss hyperparameters.
Performance
(↑) Fairness
(↓)
HR@20 NDCG@20 PREC@20 rHR rND
𝛾1(
L𝐷𝑆)0.25 0.2025 0.0903 0.0101 0.1489 0.2075
0.75 0.2037 0.0911 0.0102 0.1545 0.2548
2.5 0.2188 0.1009 0.0109 0.1548 0.2610
𝛾2(
L𝐶𝑙𝑎𝑠𝑠)0.25 0.2025 0.0903 0.0101 0.1489 0.2075
0.75 0.2077 0.0928 0.0104 0.1548 0.2627
2.5 0.2203 0.1013 0.0110 0.1537 0.2472
𝛾3(
L𝑐𝑜𝑛𝑡𝑟𝑎𝑠𝑡)0.25 0.2025 0.0903 0.0101 0.1489 0.2075
0.75 0.2052 0.0915 0.0103 0.1541 0.2551
2.5 0.2181 0.1038 0.0109 0.1561 0.2711
𝛾4(
L𝑓𝑎𝑖𝑟)0.25 0.2025 0.0903 0.0101 0.1489 0.2075
0.75 0.2198 0.1019 0.0110 0.1543 0.2551
2.5 0.2205 0.1004 0.0110 0.1535 0.2447
and TailGNN We use each user’s last interacted item in both datasets
as the test data.
E.2 Additional Hyperparameter Study
Additional hyperparameter testing on loss hyperparameters is pre-
sented in this section. The results reported in Table 8 test the impact
of different loss hyperparameters 𝛾1,𝛾2,𝛾3,𝛾4in Eq. (12) on the per-
formance and fairness scores on the Amazon Book dataset. Specifi-
cally, we respectively tune 𝛾1,𝛾2,𝛾3, and𝛾4from{0.25,0.75,2.5}.
At each round, we only tune one and fix the remaining three to
0.25. For example, when tuning 𝛾1from{0.25,0.75,2.5}, we fix
𝛾2=𝛾3=𝛾4=0.25. Results in Table 8 demonstrate that FairDGE is
not sensitive to 𝛾on both performance and fairness. When all the
𝛾are 0.25, the results are the best on the fairness score.
F COMPLEXITY ANALYSIS
FairDGE consists of two modules, i.e., trend-aware structural evo-
lution learning and dual debiasing for encoding structurally fair
embeddings. We analyze the computational complexity of each
module, respectively.
Trend-aware structural evolution learning consists of long-short-
term degree trend encoding, structural evolution embedding, and a
bias classification task. The computational complexity is 𝑂(𝑚𝑎𝑥(𝐿·
|V|2,|𝑇|·𝑑𝑖𝑚2
ℎ𝑖𝑑+|𝑇|·𝑑𝑖𝑚ℎ𝑖𝑑·𝑑𝑖𝑚))according to [ 3,25].|V|
is the number of vertices, 𝐿is the number of GNN layers, |𝑇|is
the number of snapshots of the dynamic graph G,𝑑𝑖𝑚ℎ𝑖𝑑is the
hidden dimension of GRU and 𝑑𝑖𝑚 is the representation dimension
of our model. Since |𝑇| ≪ |V| and𝐿≪ |V| , the overall com-
plexity of trend-aware structural evolution learning is 𝑂(|V|2),
approximately.
In the dual debiasing module, contrastive learning with nega-
tive sampling is first employed. Its computational complexity is
𝑂(|V|2). The complexity of the followed fairness loss and the link
prediction task are both 𝑂(|E|) . Therefore, the complexity of the
dual debiasing module is 𝑂(𝑚𝑎𝑥(|V|2,|E|)) .
Since the FairDGE trained in end-to-end manner, the overall
computational complexity is 𝑂(𝑚𝑎𝑥(|V|2,|E|)) .
 
1712