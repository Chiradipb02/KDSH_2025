MulSTE: A Multi-view Spatio-temporal Learning Framework with
Heterogeneous Event Fusion for Demand-supply Prediction
Li Lin
Southeast University
Nanjing, China
linli321@seu.edu.cnZhiqiang Lu
Southeast University
Nanjing, China
lu_zhiqiang@seu.edu.cnShuai Wang∗
Southeast University
Nanjing, China
shuaiwang@seu.edu.cnYunhuai Liu
Peking University
Beijing, China
yunhuai.liu@pku.edu.cn
Zhiqing Hong
Rutgers University
Piscataway, USA
zhiqing.hong@rutgers.eduHaotian Wang
JD Logistics
Beijing, China
wanghaotian18@jd.comShuai Wang
Southeast University
Nanjing, China
shuaiwang_iot@seu.edu.cn
Abstract
Recently, integrated warehouse and distribution logistics systems
are widely used in E-commerce industries to adjust to constantly
changing customer demands. It makes the prediction of purchase
demand and delivery supply capacity a crucial problem to stream-
line operations and improve efficiency. The interaction between
such demand and supply not only relies on their economic relation-
ships but also on consumer psychology caused by daily events, such
as epidemics, promotions, and festivals. Although existing studies
have made great efforts in the joint prediction of demand and supply
considering modeling the demand-supply interactions, they seldom
refer to the impacts of diverse events. In this work, we propose
MulSTE, a Multi-view Spatio-Temporal learning framework with
heterogeneous Event fusion. Firstly, an Event Fusion Representa-
tion (EFR) module is designed to fuse the textual, numerical, and
categorical heterogeneous information for emergent and periodic
events. Secondly, a Multi-graph Adaptive Convolution Recurrent
Network (MGACRN) is developed as the spatio-temporal encoder
(ST-Encoder) to capture the evolutional features of demand, supply,
and events. Thirdly, the Event Gated Demand-Supply Interaction
Attention (EGIA) module is designed to model the demand-supply
interactions during events. The evaluations are conducted on two
real-world datasets collected from JD Logistics and public web-
sites. The experimental results show that our method outperforms
state-of-the-art baselines in various metrics.
CCS Concepts
•Information systems →Spatial-temporal systems.
∗Shuai Wang is the corresponding author.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
KDD ’24, August 25–29, 2024, Barcelona, Spain
©2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 979-8-4007-0490-1/24/08
https://doi.org/10.1145/3637528.3672030Keywords
Demand-supply Prediction, Event Representation, Graph Neural
Network, Spatio-temporal Graphs
ACM Reference Format:
Li Lin, Zhiqiang Lu, Shuai Wang, Yunhuai Liu, Zhiqing Hong, Haotian Wang,
and Shuai Wang. 2024. MulSTE: A Multi-view Spatio-temporal Learning
Framework with Heterogeneous Event Fusion for Demand-supply Predic-
tion. In Proceedings of the 30th ACM SIGKDD Conference on Knowledge
Discovery and Data Mining (KDD ’24), August 25–29, 2024, Barcelona, Spain.
ACM, New York, NY, USA, 12 pages. https://doi.org/10.1145/3637528.3672030
1 Introduction
Recently, warehouse-distribution integration (WDI) [ 14] is a new
logistics mode. It provides a combination of capabilities, speed,
accountability, and accuracy in warehouse and distribution op-
erations, which requires the ability to predict future demand for
logistics resources and the flexible adjustment of supply capacity.
The demand-supply balance is the goal many enterprises strive to
achieve, while the complicated interactions between demand and
supply make it a hard issue. In real-world scenarios, the relationship
between demand and supply is vulnerable to diverse daily events
(such as epidemics, promotions, festivals., etc.).
Fig. 1 shows how the purchase demand and delivery supply in-
teract with each other in a WDI system considering the impacts of
events with heterogeneous data, which can be divided into emer-
gent events and periodic events. Specifically, the WDI system di-
vides a city into various service regions and establishes a delivery
station for each region. Each delivery station is responsible to guar-
antee the packages arrive on time, where each package corresponds
to a user’s order in the E-commerce platform. This process exhibits
a dynamic balance between demand and supply. However, during
daily events, consumers’ purchase demand grows when their hoard-
ing intent is stimulated by emergent events or when the prices are
attractive during promotions. And when the delivery supply capac-
ity is far behind the demand, the increasing delay of distribution
would prevent consumers buy more goods on the platform. Be-
sides, the spatial relations of different regions vary a lot, e.g. the
transportation distance, connectivity, economic functions and user
profiles. Therefore, it is critical to predict the purchase demand and
delivery supply for each region to guide the resource distribution
of WDI systems under diverse events.
 
1781
KDD ’24, August 25–29, 2024, Barcelona, Spain Li Lin et al.
Emergent Events Periodic Events
Textual Type
 Numerical Type Categorical Type
&
Events with Heterogeneous Data 
Users
Region iE-commerce 
WDI Delivery Station Warehouse
Distance -aware
 Neighbor -aware
 Type -similarity
 Crowd -similarityRegional Relations 
Online Purchase Demand Offline Delivery Supply
Orders Packages
Impact Direction
Purchase Demand
 Delivery Supply
Figure 1: Demand-supply-event relations across regions in
E-commerce WDI scenario.
The prediction of demand and supply has attracted attention
from researchers in many fields, such as traffics [ 5,26], labor mar-
kets [ 10], and e-commerce [ 23,31]. These studies deal with the
auto-regressive demand and supply sequences independently, fo-
cus on supply-demand gap prediction, or jointly predict demand
and supply as a multi-task problem without considering the change-
able interaction between demand and supply caused by daily events.
There are also several studies investigating the impacts of events
on demand prediction. They focus on demand prediction during a
specific event [ 21] or leverage the daily embedding based on world
events to forecast users’ behavior on e-commerce platforms [ 15].
However, how to understand the interaction between demand and
supply during diverse events is still an open issue.
To fill in the gap, we aim to design a joint prediction framework
of purchase demand and delivery supply for E-commerce goods
considering the event impacts. Due to diverse events consisting of
heterogeneous data, i.e. text, numeric, and categories, which affect
the evolution of demand and supply separately, and the spatio-
temporal interactions between them. Thus, solving the problem of
demand-supply prediction under events faces the following chal-
lenges: (i) Unified representation learning for events with het-
erogeneous data. Heterogeneous event data describe varied daily
events, including semantics, severity, trigger time, and frequency
of events. It is challenging to capture the unified representation of
all events and further adapt the information to the demand-supply
prediction task. (ii) Extracting the spatio-temporal relations
of demand, supply, and events. Different temporal dependency
patterns are exhibited by both demand and supply at various time
periods, i.e. emergent, periodic, and normal periods. Additionally,
inter-regional relations may have varying degrees of relative im-
portance when modeling demand, supply, and event data.
To address these challenges, we propose MulSTE1, a multi-view
spatio-temporal learning framework with heterogeneous event fu-
sion for demand-supply prediction. It follows the Encoder-Decoder
framework for sequential forecasting, which consists of two key
components: (i) Event Fusion Representation. It is designed
to conduct a unified representation learning fusing heterogeneous
event data (EFR). For textual events, we first fine-tune a pre-trained
language model and then apply it to produce semantic embeddings
1Our implementation is available at https://github.com/mulste-kdd2024/MulSTE.of daily events. For numerical and categorical events, we straightly
use a linear embedding layer to capture the information about
the severity, trigger time, and frequency. (ii) Multiple Spatio-
temporal Encoders. To construct the spatio-temporal relationship
of purchase demand, delivery supply, and events, we design three
parallel encoders following the gated recurrent units (GRU) form.
We name the basic cell with Multi-graph Adaptive Convolution Re-
current Unit (MGACRU). In MGACRU, we adopt the Multi-graph
Adaptive Convolution (MGAC) module to the gating mechanism,
acting as the update and reset gates by capturing the spatial features
in each time step of history sequences. While the temporal features
can be recurrently modeled by connected MGACRUs. Besides, to
further model the demand-supply interactions, we design an Event
Gated Demand-Supply Interaction Attention (EGIA) module com-
posed of a self-attention to model the demand-supply correlations
and a cross-attention to model the event-related interactions of
demand and supply. Finally, for the decoders, we use two fully
connected layers to transmit the interacted demand and supply
representations from spatio-temporal encoders into multi-step pre-
dictions concurrently. In summary, our key contributions are as
follows:
•To the best of our knowledge, we are the first to jointly
predict demand and supply under events. It considers the
influence of heterogeneous events on the joint prediction of
demand and supply, especially the effects on the demand-
supply interactions.
•A novel multi-graph adaptive convolution recurrent net-
work is designed to capture the spatio-temporal relations of
demand, supply, and events, with the multi-graph adaptive
convolution module acting as the update and reset gates. The
Event Gated Demand-Supply Interaction Attention module
is introduced to handle the diversified influence of events
on demand-supply interactions.
•We evaluate MulSTE on two real-world datasets in Shanghai
and Zhengzhou from JD Logistics, including 353 delivery
stations, 25.7 million users, 339.24 million orders, and 31
periodic event categories. For emergent events, 13.13 thou-
sand news titles are collected from public webs. Experiments
show that the performance of MulSTE outperforms the state-
of-the-art methods by 24.50%and12.68%improvement in
demand and supply on average.
2 Related Work
2.1 Demand and Supply Prediction
The prediction of demand and supply is a widely studied problem
that has various applications. Some studies have made concerns
about user-level purchase behavior predictions [ 12,13], platform-
level [ 23] and city-level purchase demand prediction [ 31]. Besides E-
commerce applications, demand prediction is also an important task
in many other fields, such as talent market [ 10], bike-sharing [ 19],
ride-hailing [ 5,26,35], multi-transportation [ 34,44], and first-
aid [28]. We noticed that there are only a few demand-supply joint
prediction works [ 5,10,26] and the study [ 10] is the only one using
the interactive information of demand and supply to realize simul-
taneously prediction of demand and supply, but it cannot cope with
 
1782MulSTE: A Multi-view Spatio-temporal Learning Framework with Heterogeneous Event Fusion for Demand-supply Prediction KDD ’24, August 25–29, 2024, Barcelona, Spain
2021-01 2021-022021-03 2021-04 2021-05 2021-06 2021-07 2021-08 2021-09
Date0102030405060Emergent Event IndicatorsIndicator1
Indicator2
0200040006000800010000
Demand/Supply VolumeDemand
Supply
spring festivalmid-year promotion
(a) Normal+Periodic
2022-01 2022-022022-03 2022-04 2022-05 2022-06 2022-07 2022-08 2022-09
Date0102030405060Emergent Event IndicatorsIndicator1
Indicator2
0200040006000800010000
Demand/Supply VolumeDemand
Supply
spring festivalmid-year promotion (b) Normal+Periodic+Emergent
Figure 2: The purchase demand and delivery supply over time
when periodic events occur (a), and when periodic and emergent
events occur (b)2.
0
100020003000400050006000700080009000
Demand0500100015002000250030003500SupplyEmergent
Periodic
Normal(a) Event types
0
10002000300040005000600070008000900010000
Demand0200040006000800010000SupplyRegion 0
Region 1
Region 2 (b) Regions
Figure 3: The demand-supply distribution for different
event types (a), and for different regions (b).
the occurrence of events and the spatio-temporal information. Re-
cently, some works in traffic scenarios have combined graph neural
networks (e.g., GCN [ 16], GAT [ 25], etc.) with sequential meth-
ods to capture spatio-temporal relationship. Graph WaveNet [ 33],
MTGNN [ 32] combine the GNN with temporal convolutional net-
work structure, while DCRNN [ 18], AGCRN [ 1], DGCRN [ 17], T-
GCN [ 41] combine the GCN with recurrent neural networks, only a
few works exploit fixed/static multi-view graph structures [ 9,38] to
model diverse spatial relationships. However, we aim to make the
joint prediction of both demand and supply, where the interactions
of demand and supply become a critical challenge.
2.2 Time Series Prediction under Events
Research on time series prediction under events is diverse corre-
sponding to varied event data types. Some studies focus on mod-
eling time series without incorporating external event data. They
apply the Bayesian meta-learning techniques to capture traffic flow
dynamics [ 39,40]. In many scenarios, external knowledge about
events would prompt the understanding of time-series forecasting.
Some researchers leverage textual event data from Tweets or Wiki
to apply the semantic information to assist in predicting urban
traffic flow and E-commerce consumer demand [ 8,15]. Besides,
daily event statistics, like the infectivity index during Covid-19
can be employed to aid in predicting E-commerce consumer de-
mand [ 36]. The categorical event data are also commonly used to
capture abnormal patterns of the time series and facilitate predic-
tion [ 6,21,27] by leveraging the effects of different types of events.
However, the studies considering only a single data type of event
have some limitations, such as the lack of spatial granularity in tex-
tual data, the lack of semantics in numerical data, and the inability
of categorical data to reflect event evolution. Therefore, it is crucial
to make a fusion of heterogeneous event data to better understand
the influence of such events.
3 Preliminaries and Definitions
3.1 Data Investigation
We collect demand and supply data in Shanghai and Zhengzhou
from JDL, one of the most popular E-commerce and logistics com-
panies in WDI mode. A total of 339.24 million orders in 353 delivery
stations and 25.7 million users are covered in the datasets. Three
types of events are considered in this work: public health emergen-
cies (Covid-19), festivals, and promotions. For textual events, we
extracted the descriptions of from news websites3and obtained
13.13 thousand news text titles. Besides the textual data, we alsogather the numerical emergent event data from the statistical webs4.
For periodic events, we collect 31 events including 20 festivals and
11 promotions recorded by the JD public webs5.
As shown in Fig. 2, there are demand-supply time series in Shang-
hai from 1/1 to 8/31 in 2021 and 2022. Fig. 2a shows that demand
and supply are usually consistent during normal scenarios. Even
when periodic events happen, there is a slight delay in the sup-
ply curve compared to the demand, it is still acceptable to learn
the subtle demand-supply fluctuation. However, when considering
the emergent events, as shown in Fig. 2b, we find the temporary
increase of supply cannot satisfy the surging demand and would
result in a decrease in purchase demand. We further analyze the dis-
tributions of demand-supply values under different event types and
regions, as shown in Fig. 3. We find that during emergencies, the
demand-supply values more easily exceed expectations and the val-
ues vary in different regions. It motivates us to construct multi-view
graphs to describe the relations of regions from the perspectives of
distance, connectivity, type-similarity, and crowd-similarity.
3.2 Definitions
Definition 1 (Multi-view Graph). Given a city, which is di-
vided into𝑁service regions (delivery stations), we define the multi-
view graph set 𝐺∗=∪n
𝐺(𝑙)o
. Each graph 𝐺(𝑙)=(𝑉,𝑈(𝑙),𝐴(𝑙)),𝑙∈
{1,...,𝐿}, where𝑉is the set of regions and 𝐴(𝑙)∈𝑅|𝑉|×|𝑉|is the ad-
jacency matrix of 𝑙𝑡ℎgraph,𝐿is the total number of views to represent
the static spatial relationships of different regions.
Definition 2 (Demand and Supply Seqence). In the time step
𝑡, the purchase demand 𝑑𝑡and delivery supply 𝑠𝑡are defined as the
order counts of requests and deliveries respectively. Then the demand
sequence𝐷and supply sequence 𝑆over𝑁regions can be represented
as𝐷={𝑑1,𝑑2,...,𝑑𝑇}and𝑆={𝑠1,𝑠2,...,𝑠𝑇}, where𝑑𝑡,𝑠𝑡∈𝑅𝑁,
𝑇is the length of the sequence.
Definition 3 (Event Seqence). The heterogeneous event se-
quence is defined as textual type 𝐸𝑢=
𝑒𝑢
1,𝑒𝑢
2,...,𝑒𝑢
𝑇	, numerical
type𝐸𝑛=
𝑒𝑛
1,𝑒𝑛
2,...,𝑒𝑛
𝑇	, categorical type 𝐸𝑐=
𝑒𝑐
1,𝑒𝑐
2,...,𝑒𝑐
𝑇	,
where𝑒𝑢
𝑡∈S𝑀represents the 𝑀pieces of text containing emergent
event in time step 𝑡,𝑒𝑛
𝑡∈R𝑁represents the number of emergent
2Indicators are the number of outbreak locations (Indicator1, ×100), risk locations
(Indicator2,×10) of Covid-19.
3https://www.shanghai.gov.cn/, https://www.zhengzhou.gov.cn/
4https://wsjkw.sh.gov.cn/, https://wjw.zhengzhou.gov.cn/
5https://www.jd.com/
 
1783KDD ’24, August 25–29, 2024, Barcelona, Spain Li Lin et al.
event locations over 𝑁regions in time step 𝑡,𝑒𝑐
𝑡∈Z𝐶represents the
periodic event category with 𝐶dimensions in time step 𝑡.
Definition 4 (Problem: Joint Prediction of Future Demand–
Supply Seqence under Events). Given the previous sequences
of demand, supply: 𝐷𝑝={𝑑1,𝑑2,...,𝑑𝑇},𝑆𝑝={𝑠1,𝑠2,...,𝑠𝑇},
and events: 𝐸𝑢𝑝=
𝑒𝑢
1,𝑒𝑢
2,...,𝑒𝑢
𝑇	,𝐸𝑛𝑝=
𝑒𝑛
1,𝑒𝑛
2,...,𝑒𝑛
𝑇	,𝐸𝑐𝑝=
𝑒𝑐
1,𝑒𝑐
2,...,𝑒𝑐
𝑇	
, as well as the multi-view graph: 𝐺∗=𝐺(𝑖|𝑖∈[1,𝑚]).
The target of joint prediction of the future demand-supply sequence un-
der events is to train a parametric model F𝜃to produce future demand
and supply sequences with length 𝑙′,𝐷𝑓={𝑑𝑇+1,𝑑𝑇+2,...,𝑑𝑇+𝑙′},
𝑆𝑓={𝑠𝑇+1,𝑠𝑇+2,...,𝑠𝑇+𝑙′}:
(𝐷𝑓;𝑆𝑓)=F𝜃
𝐷𝑝;𝑆𝑝;𝐸(𝑢,𝑛,𝑐)
𝑝 ;𝐺∗
(1)
where𝜃is the parameter set of F.
4 Methodology
The framework of MulSTE is given in Fig. 4. Our model follows
the Encoder-Decoder framework for sequence learning, which con-
tains three key components: (i) Event Fusion Representation
(Sec. 4.2) to conduct a unified fusing representation for hetero-
geneous event data. (ii) Multiple Spatio-temporal Encoders
(Sec. 4.3) to construct the complex spatio-temporal relationship of
demand, supply, and events, also their interactions. (iii) Multi-step
Demand-Supply Decoder (Sec. 4.4) to produce future demand
and supply sequences based on the spatio-temporal representations.
4.1 Data Preprocessing
4.1.1 Multi-view Graph Construction. We construct multi-view
graphs to describe the static regional relations following the method
in [35], which can be divided into the following four parts.
Distance-aware graph. By calculating the distance between
two regions, we build a distance-aware graph 𝐺(𝑑)=(𝑉,𝑈(𝑑),𝐴(𝑑)).
Each edge𝑢(𝑑)
𝑖𝑗∈𝑈(𝑑)represents the spatial distance between re-
gions𝑟𝑖and𝑟𝑗.
Neighbor-aware graph. To account for the neighboring corre-
lation between regions, we build a neighbor-aware graph 𝐺(𝑛)=
(𝑉,𝑈(𝑛),𝐴(𝑛)), In𝐺(𝑛), the edge𝑢(𝑛)
𝑖𝑗∈𝑈(𝑛)indicates whether
𝑟𝑖and𝑟𝑗are neighboring regions with boolean value.
Type-similarity graph. To capture function similarity among
regions, a fully connected undirected graph 𝐺(𝑡)=(𝑉,𝑈(𝑡),𝐴(𝑡))
is built, named type-similarity graph. Its edge 𝑢(𝑡)
𝑖𝑗∈𝑈(𝑡)is com-
puted with 𝑐𝑜𝑠(T(𝑟𝑖),T(𝑟𝑗)). Here,𝑐𝑜𝑠()is the cosine function,
and the functionT(·) denotes the function-type properties of
a given region, which refers to the number, size, distance of 9
type zones (industrial, office building, residential, professional mar-
ket, commercial-residential mixed (mainly residential), mixed area
(mainly commercial), school, township, and commercial).
Crowd-similarity graph. We utilize region-level aggregated
user profiles, named crowd properties, to build the fully connected
undirected graph 𝐺(𝑐)=(𝑉,𝑈(𝑐),𝐴(𝑐)), named crowd-similarity
graph. Its edge 𝑢(𝑐)
𝑖𝑗∈𝑈(𝑐)is computed with 𝑐𝑜𝑠(C(𝑟𝑖),C(𝑟𝑗)).
Here,𝑐𝑜𝑠()is the cosine function, and the function C(·) denotes
the crowd properties of a given region, such as the statistics of
gender, age, education, registration time, and so on.4.1.2 Demand, Supply, and Event Sequences Processing. We use
a sliding window with a size of 𝑇+𝑙′, where𝑇denotes the his-
tory length, and 𝑙′denotes the future length for targets. For each
timestep in event sequences, it is a set of heterogeneous event data
(𝑒𝑢
𝑡,𝑒𝑛
𝑡,𝑒𝑐
𝑡). Specifically, the textual type 𝑒𝑢
𝑡∈S𝑀represents the 𝑀
pieces of text describing emergent events, numerical type 𝑒𝑛
𝑡∈R𝑁
represents the counts of emergent events in 𝑁different regions,
categorical type 𝑒𝑐
𝑡∈Z𝐶represents the periodic event category
with𝐶dimensions.
4.2 Event Fusion Representation
The Event Fusion Representation (EFR) module as shown in Fig. 5
aims to provide a unified representation for heterogeneous event
data, containing textual, numerical, and categorical data.
4.2.1 Textual Events Learning. For textual emergent events, the
pre-trained language model, MacBERT [ 3], is to capture the seman-
tic information by fine-tuning it on event descriptions in earlier
days (textual data details are provided in Appendix A.2). For each
sentence, we use the tokenizer combined in MacBERT from Hug-
gingFace6to generate the tokens. Then a 𝑀𝐿𝑃 layer makes a binary
classification of whether the news is emergent event-related based
on the semantic embedding. After that, a fine-tuned MacBERT
with the ability to recognize emergent event-related news is ob-
tained. Then the model parameters are frozen and conveyed to the
demand-supply prediction work for multiple cities. We take the
last hidden state corresponding to the special token [CLS] for each
piece of news in textual input 𝑒𝑢
𝑡∈S𝑀to represent the semantic
information of each whole news title at time step 𝑡as follows:
𝐸𝑝
𝑡←𝐵𝐸𝑅𝑇𝑓[CLS](𝑇𝑜𝑘𝑒𝑛𝑠𝑒𝑢
𝑡) (2)
where𝐸𝑝
𝑡is the piece-level textual semantic embedding at time
step𝑡,𝐵𝐸𝑅𝑇𝑓is the frozen BERT initialized by fine-tuned parame-
ters,𝑇𝑜𝑘𝑒𝑛𝑠𝑒𝑢
𝑡is the tokens converted from predicting-task news
titles𝑒𝑢
𝑡at time step 𝑡. Then, we use the 𝑆𝑜𝑓𝑡𝑚𝑎𝑥 to calculate the
weighted sum of time-step level semantic representation:
𝛽𝑙𝑎𝑏𝑒𝑙 =1←−𝑆𝑜𝑓𝑡𝑚𝑎𝑥(𝑀𝐿𝑃(𝐸𝑝
𝑡))
𝐸𝑢
𝑡=𝑀∑︁
𝑖=1𝛽𝑖⊙(𝐸𝑝
𝑡)𝑖(3)
where𝛽is the weights of 𝐸𝑝
𝑡,𝑀𝐿𝑃 is the classification head in fine-
tuned MacBERT, 𝑀is the max number of news pieces in one time
step,𝐸𝑢
𝑡∈𝑅𝑑ℎis the time-step level textual semantic embedding.
4.2.2 Numerical and Categorical Events Learning. For numerical
type data which exhibit spatio-temporal characteristics and reflect
the severity of emergent events in different regions, we introduce a
simple fully connected layer to expand the raw input 𝑒𝑛
𝑡to match
the dimension of the hidden state 𝐸𝑛
𝑡∈𝑅𝑁×𝑑ℎ. For categorical type
data (day of week, day of month, day of year, festival type) which
reveal the time and frequency of demand-supply changes triggered
by periodic events, we convert them to the same dimension as the
hidden state using the linear Embedding layer. Then, we performed
6https://huggingface.co/hfl/chinese-bert-wwm-ext
 
1784MulSTE: A Multi-view Spatio-temporal Learning Framework with Heterogeneous Event Fusion for Demand-supply Prediction KDD ’24, August 25–29, 2024, Barcelona, Spain
Time𝐷1
𝑒2𝑢𝑒2𝑛𝑒2𝑐EGIA
FC
𝑑2𝐷2MGACRU
FC
𝑠2𝑆2MGACRU
EFRMGACRU
𝐸2𝐹𝑠𝑛𝐷𝑇
𝑒1𝑢𝑒1𝑛𝑒1𝑐EGIA
𝑑1MGACRU
FC
𝑠1𝑆1MGACRU
EFRMGACRU
𝐸1𝐹𝑠𝑛
𝑒𝑇𝑢𝑒𝑇𝑛𝑒𝑇𝑐EGIA
FC
𝑑𝑇MGACRU
FC
𝑠𝑇𝑆𝑇MGACRU
EFRMGACRU
𝐸𝑇𝐹𝑠𝑛…
…
…
…FC
Crowd -similarity graph Constr. 
𝐺(𝑐)
Demand Data 
𝐷=𝑑1,𝑑2,⋯,𝑑𝑇Demand Sequence: 
Supply Data 
𝑆=𝑠1,𝑠2,⋯,𝑠𝑇Supply Sequence: 
Numerical type Textual Type
Emergent Event Data Textual Event Sequence: 
𝐸𝑢=𝑒1𝑢,𝑒2𝑢,⋯,𝑒𝑇𝑢
Numerical Event Sequence: 
𝐸𝑛=𝑒1𝑛,𝑒2𝑛,⋯,𝑒𝑇𝑛Categorical Type
Periodic Event Data
& Periodic Event Sequence: 
𝐸𝑐=𝑒1𝑐,𝑒2𝑐,⋯,𝑒𝑇𝑐Supply ST Encoder
Event ST Encoder
𝐺(𝑑)Distance -aware graph Constr.
𝐺(𝑛)Neighbor -aware graph Constr.Demand ST Encoder
ℎ0𝐷𝐼 ℎ1𝐷ℎ1𝐷𝐼ℎ𝑇−1𝐷𝐼ℎ2𝐷ℎ2𝐷𝐼ℎ𝑇𝐷
ℎ𝑇𝐷𝐼
ℎ1𝑆ℎ1𝑆𝐼ℎ𝑇−1𝑆𝐼 ℎ2𝑆ℎ2𝑆𝐼ℎ𝑇𝑆ℎ𝑇𝑆𝐼
ℎ0𝑆𝐼
ℎ0𝐸ℎ1𝐸ℎ2𝐸ℎ𝑇𝐸
Type -similarity graph Constr.
𝐺(𝑡)Multi -view Graph Construction (Sec. 4.1.1)
Demand, Supply, and Event Sequences Processing (Sec. 4.1.2)Multiple Spatio -temporal Encoders (Sec. 4.3)
Event Fusion 
Representation  
(Sec. 4.2)
Multi -step Demand -Supply Decoder (Sec. 4.4)Demand Predictions
𝑑𝑇+1𝑑𝑇+2𝑑𝑇+𝑙…
FC
FCDemand FC Output layerSupply Predictions
𝑠𝑇+1𝑠𝑇+2𝑠𝑇+𝑙…
Supply FC Output layer
ℎ𝑇𝐷𝐸
ℎ𝑇𝑆𝐸𝐻𝑇𝐷
𝐻𝑇𝑆
Concat Concat
Figure 4: The framework of our work, consisting of four main components: 1) data preprocessing, 2) event fusion representation,
3) multiple spatio-temporal encoders for representation learning, and 4) the multi-step demand-supply decoder for predictions.
element-wise addition of the four type embeddings to obtain 𝐸𝑐
𝑡∈
𝑅𝑑ℎat time step 𝑡.
Finally, we execute spatio-temporal alignment through element-
wise addition to get the event fusion representation:
𝐸𝐹𝑠𝑛
𝑡=𝐸𝑢
𝑡+𝐸𝑛
𝑡+𝐸𝑐
𝑡 (4)
4.3 Multiple Spatio-temporal Encoders
We design three parallel encoders for demand, supply, and events
separately to capture their complex spatio-temporal relations. Each
encoder incorporates a unified graph-based recurrent network
based on MGACRU as shown in Fig. 6, which is a GRU-based cell
that integrates the Multi-Graph Adaptive Convolution (MGAC), to
recurrently aggregate historical demand or supply representation
and historical event representation from the EFR module.
4.3.1 Multi-Graph Adaptive Convolution.
(i) Predefined multi-view graph convolution adaptive weight-
ing. For the pre-defined multi-view graph 𝐺∗, which ensembles 𝐿
graph views, we design 𝐿independent GCN layers correspondingly:
𝑍(𝑙)
𝑡=
𝐼𝑁+𝐷−1
2𝐴(𝑙)𝐷−1
2
𝑋𝑧
𝑡Θ(𝑙)+𝑏(𝑙),𝑙∈{1,...,𝐿}(5)
Single news titleC …
…
…𝑇𝑇1𝑇𝑇2 𝑇𝑇N
E[CLS]E1 E2 EN
[CLS] Tok1 Tok2 TokNFine- tuning
EFR
EFR EFRAdapting to prediction tasks
Single news titleC …
…
…Bert𝑇𝑇1𝑇𝑇2 𝑇𝑇N
E[CLS]E1 E2 EN
[CLS] Tok1 Tok2 TokN
Classification
HeadSpace- temporal Alignment
Emergent Events Rep. Periodic Events Rep.
Embedding 
Layer… …
Numerical type Textual Type Categorical Type
Time Emergent Event Data Periodic Event Data
& 𝑒𝑒𝑡𝑡𝑢𝑢𝑒𝑒𝑡𝑡𝑛𝑛𝑒𝑒𝑡𝑡𝑐𝑐
𝑓𝑓Fine -tuning 
News
Emergent Event Data 𝑒𝑒1𝑢𝑢𝑒𝑒1𝑛𝑛𝑒𝑒1𝑐𝑐𝑒𝑒𝑇𝑇𝑢𝑢𝑒𝑒𝑇𝑇𝑛𝑛𝑒𝑒𝑇𝑇𝑐𝑐𝐸𝐸𝑡𝑡𝐹𝐹𝐹𝐹𝑛𝑛𝐸𝐸𝑇𝑇𝐹𝐹𝐹𝐹𝑛𝑛𝐸𝐸1𝐹𝐹𝐹𝐹𝑛𝑛
𝐸𝐸𝑡𝑡𝑝𝑝𝐸𝐸𝑡𝑡𝑢𝑢
𝐸𝐸𝑡𝑡𝑛𝑛𝐸𝐸𝑡𝑡𝑐𝑐
𝐸𝐸𝑡𝑡𝑤𝑤𝐸𝐸𝑡𝑡𝑚𝑚
𝐸𝐸𝑡𝑡𝑦𝑦𝐸𝐸𝑡𝑡𝑓𝑓 𝐸𝐸𝑓𝑓
Initialization
TransferFrozen BERT BERT
FCMLP 
Layers
Softmax
ClassificationHeadLoss
Figure 5: Process of Event Fusion Representation.where𝐴(𝑙)is the adjacent matrix, 𝐷is the degree matrix, 𝐼𝑁is the
identity matrix, Θ(𝑙)and𝑏(𝑙)are learnable parameters.
Then adaptive weighting is designed to measure different de-
grees of relative importance to demand, supply, and events for
predefined relationships. The attention weights of 𝑙𝑡ℎview graph
can be formulated as:
𝛼(𝑙)=𝑒𝑥𝑝(𝑊𝑝[𝑍(𝑙)
𝑡]+𝑏𝑝)
Í𝐿
𝑖=1𝑒𝑥𝑝(𝑊𝑝[𝑍(𝑖)
𝑡]+𝑏𝑝)(6)
where𝛼(𝑙)∈𝑅𝑁represents the 𝑁regions’ attention weights of
𝑙𝑡ℎview graph, 𝑊𝑝,𝑏𝑝are learnable parameters.
Further, we incorporate all the 𝐿graph views by the adaptive
weighting of the graph convolution results as 𝑍𝑝
𝑡=Í𝐿
𝑙=1𝛼(𝑙)⊙
𝑍(𝑙),𝑙∈{1,...,𝐿}, where⊙is element-wise multiplication.
(ii) Adaptive node aggregation graph-structured learning.
To adaptively capture the graph information that the predefined
multi-view graph cannot contain, we construct an adaptive graph
𝐺𝑓=(𝑉,𝑈𝑓,e𝐴𝑓). The normalized adjacent matrix e𝐴𝑓is data-
adaptive to discover the hidden spatial relationships, requiring no
prior knowledge, and can be learned through stochastic gradient
descent. We first randomly initialize a learnable parameter 𝑀𝑓∈
𝑅𝑁×𝑑ℎfor all nodes, where each row of 𝑀𝑓represents the structure
embedding of a node, 𝑑ℎrepresents the dimension of node structure
embedding. According to the nodes’ similarity, we can define the
normalized adjacent matrix e𝐴𝑓as:
e𝐴𝑓=Softmax(Relu(𝑀𝑓𝑀𝑓𝑇)) (7)
where the𝑅𝑒𝑙𝑢 is used to eliminate weak connections, and the
𝑆𝑜𝑓𝑡𝑚𝑎𝑥 is utilized to normalize the adaptive graph. Then the
adaptive graph node embedding aggregation can be formulated as:
𝑍𝑓
𝑡=e𝐴𝑓𝑋𝑧
𝑡𝑊𝑓+𝑏𝑓 (8)
where𝑍𝑓
𝑡∈𝑅𝑁×𝑑ℎis the adaptive graph node embedding at time
step𝑡,𝑁is the nodes number, 𝑑ℎis the dimension of graph node
embedding, and 𝑊𝑓,𝑏𝑓are the learnable parameters.
 
1785KDD ’24, August 25–29, 2024, Barcelona, Spain Li Lin et al.
ℎ𝑇𝑇
Time… …
… …ℎ1
MGACRUℎ0
𝑋𝑋1MGACRUℎ𝑇𝑇−1
𝑋𝑋𝑇𝑇ℎ𝑡𝑡−1MGACRU ℎ𝑡𝑡
𝑟𝑟𝑡𝑡𝑢𝑢𝑡𝑡
𝑍𝑍𝑡𝑡𝑢𝑢
Concat
Concat𝜎𝜎𝜎𝜎
tanh1-
u-MGAC
r-MGAC𝑍𝑍𝑡𝑡𝑟𝑟
𝑋𝑋𝑡𝑡
Adaptive 
Weighting
MLP
MLPPre-definedConcat 𝑍𝑍𝑡𝑡𝑔𝑔
𝑍𝑍𝑡𝑡𝑏𝑏𝑍𝑍𝑡𝑡𝑝𝑝
𝐻𝐻𝑡𝑡𝑏𝑏MGAC (ii) Adaptive Node Aggregation Graph- structured Learning
(i) Predefined Multi- view Graph 
Convolution Adaptive WeightingConcat
𝑍𝑍𝑡𝑡𝑍𝑍𝑡𝑡𝑔𝑔
𝑍𝑍𝑡𝑡𝑏𝑏𝑍𝑍𝑡𝑡𝑝𝑝𝑍𝑍𝑡𝑡𝑓𝑓
ConcatFC 𝑋𝑋𝑡𝑡𝑧𝑧
MLP
MLP𝐻𝐻𝑡𝑡𝑏𝑏 (iii) Non -graph- structured Bias Learning
Figure 6: Illustration of MGACRU.
(iii) Non-graph-structured bias learning. We concat the pre-
defined multi-view graph convolution adaptive weighting output
𝑍𝑝
𝑡and the adaptive node aggregation output 𝑍𝑓
𝑡to generate the
graph-structured relationship embedding 𝑍𝑔
𝑡.
However, the graph-structured relationship captured may not
cover all the inter-regional relations. Inspired by D2STGNN [ 22], we
use𝑍𝑔
𝑡passed back to an MLP branch to obtain 𝐻𝑏
𝑡, then compute
the differential matrix between 𝑋𝑧
𝑡and𝐻𝑏
𝑡, passing forward to the
other MLP branch to achieve non-graph-structured bias learning.
𝐻𝑏
𝑡=𝜎(𝑍𝑔
𝑡𝑊𝑏1+𝑏𝑏1)
𝑍𝑏
𝑡=𝜎((𝑋𝑧
𝑡−𝐻𝑏
𝑡)𝑊𝑏2+𝑏𝑏2)(9)
where𝐻𝑏
𝑡∈𝑅𝑁×𝑑ℎ,𝑍𝑏
𝑡∈𝑅𝑁×𝑑ℎrepresent the embedding trans-
formed into the input space and the bias information. 𝑊𝑏1,𝑏𝑏1,𝑊𝑏2,
𝑏𝑏2are the learnable parameters.
Finally, we get the output of MGAC as: 𝑍𝑡=[𝑍𝑔
𝑡||𝑍𝑏
𝑡]𝑊+𝑏
where𝑍𝑡∈𝑅𝑁×𝑑ℎ,𝑊and𝑏are learnable parameters, and each
row in𝑍𝑡is the sequence embedding of one region at time 𝑡.
4.3.2 Multi-Graph Adaptive Convolution Recurrent Network. We
use GRU [ 2] as the basic structure in MGACRU by adjusting the
update and reset gates with u-MGAC and r-MGAC as follows:
𝑍𝑢
𝑡=u-MGAC([𝑋𝑡||ℎ𝑡−1],𝐺∗)
𝑢𝑡=𝜎(𝑍𝑢
𝑡𝑊𝑢+𝑏𝑢)
𝑟𝑡=𝜎(𝑍𝑢
𝑡𝑊𝑟+𝑏𝑟)
𝑍𝑟
𝑡=r-MGAC([𝑋𝑡||(𝑟𝑡⊙ℎ𝑡−1)],𝐺∗)
𝑐𝑡=𝑡𝑎𝑛ℎ(𝑍𝑟
𝑡𝑊𝑐+𝑏𝑐)
ℎ𝑡=𝑢𝑡⊙ℎ𝑡−1+(1−𝑢𝑡)⊙𝑐𝑡(10)
EGIA
𝜎𝜎1-
ℎ𝑡𝑡𝐷𝐷𝐼𝐼
ℎ𝑡𝑡𝑆𝑆𝐼𝐼�ℎ𝑡𝑡𝐷𝐷
�ℎ𝑡𝑡𝑆𝑆
�ℎ𝑡𝑡𝐸𝐸
Time
𝑬𝑬𝑮𝑮𝑮𝑮𝑮𝑮𝟏𝟏EGIA EGIA…
…
𝑬𝑬𝑮𝑮𝑮𝑮𝑮𝑮𝒕𝒕 𝑬𝑬𝑮𝑮𝑮𝑮𝑮𝑮𝑻𝑻ℎ𝑡𝑡𝐷𝐷
ℎ𝑡𝑡𝑆𝑆ℎ𝑡𝑡𝐸𝐸ℎ𝑡𝑡𝐷𝐷𝐼𝐼
ℎ𝑡𝑡𝑆𝑆𝐼𝐼QKV
QKVℎ1𝐸𝐸ℎ1𝐷𝐷ℎ1𝐷𝐷𝐼𝐼
ℎ1𝑆𝑆ℎ1𝑆𝑆𝐼𝐼ℎ𝑇𝑇𝐸𝐸ℎ𝑇𝑇𝐷𝐷ℎ𝑇𝑇𝐷𝐷𝐼𝐼
ℎ𝑇𝑇𝑆𝑆ℎ𝑇𝑇𝑆𝑆𝐼𝐼…
…
… …
ConcatSplitSelf-
Attention
Cross -
Attention
Figure 7: Illustration of EGIA structure.where𝑋𝑡∈𝑅𝑁×𝐹,ℎ𝑡∈𝑅𝑁×𝑑ℎare the sequence input and hidden
state output of MGACRU at time step 𝑡,||denotes the concatenation
operation,𝑢𝑡and𝑟𝑡are hidden states of update gate and reset gate
at time step 𝑡.𝑊𝑢,𝑊𝑟,𝑊𝑐,𝑏𝑢,𝑏𝑟,𝑏𝑐are trainable parameters.
4.3.3 Event Gated Demand-Supply Interaction Attention. To model
the interrelation between demand and supply under event impact,
we design the Event Gated Demand-Supply Interaction Attention
module (EGIA). The detailed structure is shown in Fig.7. Firstly, we
compute the self-attention of demand-supply as follows:
ˆℎ𝐷
𝑡||ˆℎ𝑆
𝑡=Softmax([ℎ𝐷
𝑡||ℎ𝑆
𝑡]𝑊𝑄
1([ℎ𝐷
𝑡||ℎ𝑆
𝑡]𝑊𝐾
1)𝑇
√︁
𝑑𝑘)[ℎ𝐷
𝑡||ℎ𝑆
𝑡]𝑊𝑉
1(11)
where ˆℎ𝐷
𝑡and ˆℎ𝑆
𝑡are interacted representations for demand and
supply respectively. Secondly, we compute the event impacts via
cross-attention as follows:
ˆℎ𝐸
𝑡=Softmax(ℎ𝐸
𝑡𝑊𝑄
2([ℎ𝐷
𝑡||ℎ𝑆
𝑡]𝑊𝐾
2)𝑇
√︁
𝑑𝑘)[ℎ𝐷
𝑡||ℎ𝑆
𝑡]𝑊𝑉
2(12)
ˆℎ𝐸
𝑡is calculated to fuse demand and supply depending on both
responses to the event. Finally, we utilize the event gate to control
the proportion of the above two attention:
ℎ𝐷𝐼
𝑡=𝜎(ℎ𝐸
𝑡)⊙ˆℎ𝐸
𝑡+(1−𝜎(ℎ𝐸
𝑡))⊙ ˆℎ𝐷
𝑡
ℎ𝑆𝐼
𝑡=𝜎(ℎ𝐸
𝑡)⊙ˆℎ𝐸
𝑡+(1−𝜎(ℎ𝐸
𝑡))⊙ ˆℎ𝑆
𝑡(13)
Then we get the demand-supply interaction enhanced demand,
supply, and event Encoders as shown in Fig. 4 formulated as:
ℎ𝐷
𝑡=MGACRU(𝐷𝑡,ℎ𝐷𝐼
𝑡−1,𝐺∗)
ℎ𝑆
𝑡=MGACRU(𝑆𝑡,ℎ𝑆𝐼
𝑡−1,𝐺∗)
ℎ𝐸
𝑡=MGACRU(𝐸𝐹𝑠𝑛
𝑡,ℎ𝐸
𝑡−1,𝐺∗)(14)
And EGIA can be formulated as:
ℎ𝐷𝐼
𝑡,ℎ𝑆𝐼
𝑡=EGIA(ℎ𝐷
𝑡⊕𝐷𝑡,ℎ𝑆
𝑡⊕𝑆𝑡,ℎ𝐸
𝑡⊕𝐸𝐹𝑠𝑛
𝑡) (15)
where𝐷𝑡and𝑆𝑡are the demand and supply representations ob-
tained from the parallel Spatio-temporal encoders. 𝐸𝐹𝑠𝑛
𝑡represents
the event fusion representation obtained from the EFR module at
time step𝑡.⊕represents the residual connection [11].
4.4 Multi-step Demand-Supply Decoder
Finally, we concatenate the interacted demand output ℎ𝐷𝐼
𝑇and sup-
ply outputℎ𝑆𝐼
𝑇from the last EGIA in Equation (15), respectively
along with the demand-related event representation ℎ𝐷𝐸
𝑇=ℎ𝐸
𝑇𝑊𝑒1+
𝑏𝑒1and supply-related event representation ℎ𝑆𝐸
𝑇=ℎ𝐸
𝑇𝑊𝑒2+𝑏𝑒2
transformed from the last output ℎ𝐸
𝑇of the Event Encoder in Equa-
tion (14), to get the final demand representation 𝐻𝐷
𝑇=[ℎ𝐷𝐼
𝑇||ℎ𝐷𝐸
𝑇]
and supply representation 𝐻𝑆
𝑇=[ℎ𝑆𝐼
𝑇||ℎ𝑆𝐸
𝑇]for multi-step predic-
tion. We can directly obtain the demand and supply prediction for
the next𝑙′steps of all nodes by applying two linear transformations.
Then the L1 loss is chosen as our training objective:
L𝜃=LD+LS=Í𝑇+𝑙′
𝑡=𝑇+1𝐷𝑡−𝐷𝑡′+Í𝑇+𝑙′
𝑡=𝑇+1𝑆𝑡−𝑆𝑡′(16)
where𝐷𝑡and𝑆𝑡are the ground truth of demand and supply. And
𝐷𝑡′,𝑆𝑡′are the predicted ones.
 
1786MulSTE: A Multi-view Spatio-temporal Learning Framework with Heterogeneous Event Fusion for Demand-supply Prediction KDD ’24, August 25–29, 2024, Barcelona, Spain
Table 1: Dataset statistics, “#” represents the COUNT operation.
City Time span # Orders # Stations # Users # Emerg. Event # News titles # Periodic event categories
SH 2021/1/1–2022/8/31 273.02M 282 19.19M 180,302 8,067 31 (20 festivals + 11 promotions)
ZZ 2021/1/1–2022/12/31 66.22M 71 6.51M 30,399 5,060 31 (20 festivals + 11 promotions)
Table 2: Overall comparison in two various-scale cities. Bold: Best, underline : Second best (Same in below table).
ModelsShanghai (SH) Zhengzhou (ZZ)
Demand Supply Demand Supply
MAE RMSE sMAPE MAE RMSE sMAPE MAE RMSE sMAPE MAE RMSE sMAPE
HI 418.61 762.14 23.93% 423.84 687.77 31.07% 354.63 769.31 24.54% 387.33 696.21 29.92%
ARIMA 370.32 771.25 21.59% 362.07 646.82 25.80% 337.13 637.30 24.86% 326.13 628.30 26.40%
SVR 401.52 785.01 23.91% 408.10 699.79 26.27% 279.01 507.79 22.14% 301.25 516.86 25.24%
GWN 303.46 538.42 17.42% 303.33 499.04 22.16% 185.68 349.02 15.59% 195.84 347.10 18.96%
MTGNN 317.39 560.10 18.44% 304.33 506.04 21.47% 202.78 380.90 16.41% 216.92 389.94 21.11%
DCRNN 330.32 579.67 19.33% 343.88 546.18 22.97% 216.42 384.27 18.56% 252.83 447.91 22.67%
AGCRN 204.19 375.08 12.05% 201.62 337.21 16.20% 158.10 306.61 13.39% 163.66 289.22 17.41%
Transformer 461.18 684.76 29.11% 486.80 678.28 31.05% 378.16 556.32 32.36% 408.15 590.70 34.86%
Informer 270.53 497.47 15.36% 202.67 352.96 17.30% 156.73 314.15 12.60% 151.79 282.10 16.12%
Fedformer 267.84 471.66 16.64% 319.09 541.63 23.95% 240.53 420.31 20.98% 254.06 422.59 23.01%
PatchTST 331.57 576.78 19.43% 342.60 564.20 24.85% 229.12 406.25 19.24% 273.35 492.53 24.08%
GRU 312.73 555.34 18.20% 326.56 532.29 22.42% 195.93 361.53 16.44% 229.61 410.97 21.62%
DLinear 348.39 602.69 20.25% 339.17 552.63 23.77% 267.40 455.59 22.27% 294.24 512.46 25.34%
TimesNet 323.30 580.34 19.04% 317.72 539.26 23.62% 233.50 407.47 19.71% 274.71 495.64 23.91%
DeepSD (-e) 321.50 562.79 18.94% 308.99 499.60 20.88% 239.27 408.89 19.78% 240.63 430.54 20.82%
DeepSD (e) 328.78 569.32 19.34% 307.14 497.18 20.82% 243.75 411.64 20.17% 238.81 427.52 21.25%
DH-GEM (r) 460.50 683.60 29.07% 472.43 661.88 30.36% 378.57 558.77 32.37% 385.89 564.01 33.81%
DH-GEM (s) 453.18 673.60 28.75% 468.88 658.03 30.21% 377.97 554.15 32.33% 385.09 560.31 33.68%
MulSTE 160.11 279.27 10.64% 197.84 334.97 15.36% 105.46 190.06 10.59% 111.75 199.74 14.06%
Table 3: Model performance evaluation across event types.
Models TypeDemand Supply
MAE RMSE sMAPE MAE RMSE sMAPE
SHAGCRNemergent 245.13 600.32 13.73% 258.05 453.10 21.91%
periodic 176.57 349.87 10.64% 179.64 313.79 11.75%
normal 128.12 215.15 9.00% 123.48 194.47 8.55%
Informeremergent 330.41 783.72 17.88% 259.43 482.03 23.71%
periodic 219.54 488.45 12.73% 174.36 319.48 11.44%
normal 181.50 339.59 11.75% 128.16 209.46 8.85%
MulSTEemergent 195.75 389.92 12.76% 259.05 441.69 20.76%
periodic 136.49 237.82 9.15% 158.95 283.30 10.65%
normal 111.72 200.13 7.95% 123.11 198.33 8.62%
ZZAGCRNemergent 186.17 446.21 16.29% 243.62 480.81 34.57%
periodic 176.79 397.09 13.51% 150.44 282.33 11.81%
normal 115.01 206.26 11.13% 123.02 205.52 10.96%
Informeremergent 183.79 457.54 14.80% 220.30 478.52 32.69%
periodic 178.65 420.01 13.06% 148.49 305.10 11.13%
normal 107.41 196.04 10.24% 103.22 179.47 9.03%
MulSTEemergent 126.84 228.48 13.53% 157.87 271.73 28.79%
periodic 103.37 199.06 9.34% 104.33 197.33 8.95%
normal 91.56 166.80 9.67% 89.32 159.00 8.82%
5 Evaluations
5.1 Experimental Setup
5.1.1 Datasets. We conduct experiments on real-world datasets
from two cities, Shanghai (SH) and Zhengzhou (ZZ), containingregional relation data, demand-supply data, and event data. The
dataset statistics are shown in Table 1 (details in Appendix A.2).
Each time step is set as one day. We use the history 𝑇=7time steps
to predict the next future 𝑙′=7time steps. We split the dataset into
training, validation, and test sets randomly with 7:2:1 split ratio.
5.1.2 Parameter Settings. We implement MulSTE and baselines
with Pytorch 1.10.1 in Python 3.7.12 environment and train the
model with 24 GB memory and a Tesla P40 GPU. The max number
of training epochs is 300, the number of early stop epochs is 50, and
the batch size is 4. We use the Adam optimizer to accelerate the
training process, and the learning rate is initialized as 0.001 with
150 steps, then decayed to 0.0001. The hidden dimension is set to
64, and the number of MGACRU layers in MulSTE is set to 1.
5.1.3 Metrics. We deploy Mean Absolute Error (MAE), Root Mean
Square Error (RMSE), and Symmetric Mean Absolute Percentage
Error (sMAPE). Detailed metrics are provided in Appendix A.3.
5.1.4 Baselines. For extensive experiments, we compare MulSTE
with the following baselines. (i) Classic time series prediction
models (i.e., HI [ 4], ARIMA [ 29], SVR [ 7]) are the traditional
models based on statistics or machine learning. (ii) Graph-based
spatio-temporal prediction models (i.e., Graph WaveNet [ 33],
MTGNN [ 32], DCRNN [ 18], AGCRN [ 1]) combine graph neural
networks with sequential methods to capture the spatio-temporal
relationship. (iii) Transformer-based prediction models (i.e.,
Transformer [ 24], Informer [ 42], Fedformer [ 43], PatchTST [ 20])
 
1787KDD ’24, August 25–29, 2024, Barcelona, Spain Li Lin et al.
Demand Supply0255075100125150175200225250275MAE
MulSTE
w/o Bias
w/o Ada
w/o Mulw/o Sem
w/o Per
w/o_Inter
w/o_Atten
(a) MAE
Demand Supply050100150200250300350400450RMSE
MulSTE
w/o Bias
w/o Ada
w/o Mulw/o Sem
w/o Per
w/o_Inter
w/o_Atten (b) RMSE
Demand Supply0.02.55.07.510.012.515.017.520.022.5sMAPE(%)
MulSTE
w/o Bias
w/o Ada
w/o Mulw/o Sem
w/o Per
w/o_Inter
w/o_Atten (c) sMAPE
Figure 8: Ablation study in Shanghai.
Demand Supply0255075100125150175200MAE
MulSTE
w/o Bias
w/o Ada
w/o Mulw/o Sem
w/o Per
w/o_Inter
w/o_Atten
(a) MAE
Demand Supply050100150200250300350RMSE
MulSTE
w/o Bias
w/o Ada
w/o Mulw/o Sem
w/o Per
w/o_Inter
w/o_Atten (b) RMSE
Demand Supply0.02.55.07.510.012.515.017.520.022.5sMAPE(%)
MulSTE
w/o Bias
w/o Ada
w/o Mulw/o Sem
w/o Per
w/o_Inter
w/o_Atten (c) sMAPE
Figure 9: Ablation study in Zhengzhou.
utilize Transformer to model sequential dependency. (iv) Other
well-known Seq2Seq models (i.e., GRU [ 2], DLinear [ 37], Times-
Net [ 30]) use recurrent unit, linear transformation, or 2D-variations
to model temporal sequences. (v) Demand-supply jointly pre-
diction models (i.e., DeepSD(-e), DeepSD(e) [ 26], DH-GEM (-s),
DH-GEM (-r) [ 10]) are to predict supply-demand gap or predict
demand and supply simultaneously. We study DeepSD (-e) which
omits the event block, DeepSD (e) which maintains the event block,
to verify the effectiveness of the DeepSD in demand-supply predic-
tion under events. Meanwhile, DH-GEM (-s) which substitutes the
heterogeneous graph to homogeneous graph, DH-GEM (-r) which
removes the graph structures, are adapted to our scenario to predict
demand and supply concurrently.
5.2 Overall Performance
5.2.1 Overall Comparison. The average results of MAE, RMSE,
sMAPE of demand and supply in two cities are shown in Table 2.
We observe that our model has the best overall performance com-
pared with all baselines. We found that AGCRN, MTGNN, and
Graph WaveNet perform better than DCRNN, which proves the ef-
fectiveness of adaptive graph learning. AGCRN has the second-best
performance on the Shanghai dataset, on which the performance
of MulSTE achieves 19.61% and 2.57% improvement in demand
and supply compared with AGCRN. Informer performs slightly
worse than our model on the Zhengzhou dataset, on which the
performance of MulSTE achieves 29.39% and 22.79% improvement
in demand and supply compared with Informer. Compared to the
baselines solving the demand-supply joint prediction. We find that
MulSTE can efficiently capture the event effects on demand-supply
interactions, with a significant superiority over DeepSD(e), which
also models the event impacts on demand and supply. In addition,
DH-GEM performs better than Transformer even if the graph struc-
ture is removed in DH-GEM (-r). It demonstrates the necessity of
demand-supply interaction design. However, due to DH-GEM ne-
glecting the spatio-temporal characteristics of demand and supply,
even if we replace the original heterogeneous graph with an adap-
tive spatio-temporal homograph, the effect of DH-GEM (-s) is stillworse than MulSTE. It further reflects that the interaction module
of MulSTE can extract better demand and supply representation.
5.2.2 Event Types Comparison. To evaluate the model performance
under different event types, we conducted tests on samples with
emergent events, samples with periodic events, and samples with
no events. The results are presented in Table 3. Notably, our model
outperformed baselines significantly in the Zhengzhou dataset, ir-
respective of the event type. In the Shanghai dataset, our model’s
demand prediction performance outperformed all baselines signifi-
cantly. However, in supply prediction, the MAE for emergent events
and the sMAPE for normal events are slightly weaker compared to
the best baseline. It is mainly attributed to that emergent events like
Covid-19 would cause supply paralysis and then result in a decrease
in purchase demand, while MulSTE prefers to balance out the error
rate of demand and supply prediction tasks. The minor gap can be
effectively compensated by adjusting the supply-demand loss ratio
as in Sec. 5.4. We further verify the generalizability of our model in
various event-related scenarios. More results are in Appendix A.4.
5.3 Ablation Study
Fig. 8 and Fig. 9 show the results of the ablation study in Shanghai
and Zhengzhou datasets. When removing textual emergent or cate-
gorical periodic event representations, the performance decreases
significantly. It confirms the effectiveness of event fusion represen-
tations. We further compare MulSTE with other three variants: w/o
Bias (removing the bias learning), w/o Ada (removing the adaptive
graph node aggregation), and w/o Mul (removing the predefined
multi-view graph adaptive weighting). The results demonstrate that
the design of multi-view graphs effectively represents the actual
prior knowledge of regional relations. Moreover, adaptive graph
learning can also capture hidden regional information as a comple-
ment to empirical graphs, while bias learning also has the ability to
8 16 32 64 128
Dimension150170190210230250270290310MAE
1011121314151617181920
sMAPE (%)
Demand MAE
Supply MAEDemand sMAPE
Supply sMAPE
(a) Shanghai
8 16 32 64 128
Dimension100110120130140150160170180190200210MAE
1011121314151617181920
sMAPE (%)
Demand MAE
Supply MAEDemand sMAPE
Supply sMAPE (b) Zhengzhou
Figure 10: Effect of different embedding sizes.
1:9 3:7 5:5 7:3 9:1
Loss Ratio130150170190210230250270290310MAE
91011121314151617181920
sMAPE (%)
Demand MAE
Supply MAEDemand sMAPE
Supply sMAPE
(a) Shanghai
1:9 3:7 5:5 7:3 9:1
Loss Ratio90100110120130140150160170MAE
91011121314151617181920
sMAPE (%)
Demand MAE
Supply MAEDemand sMAPE
Supply sMAPE (b) Zhengzhou
Figure 11: Effect of different demand and supply loss ratios.
 
1788MulSTE: A Multi-view Spatio-temporal Learning Framework with Heterogeneous Event Fusion for Demand-supply Prediction KDD ’24, August 25–29, 2024, Barcelona, Spain
capture non-graph relationships to a certain extent. Moreover, we
analyze the contribution of EGIA by (i) removing it from encoders
(w/o Inter) and (ii) concatenating the demand and supply hidden
state as interaction information (w/o Atten). It can be seen that
the performances of w/o EGIA and w/o Atten drop significantly,
which demonstrates the effectiveness of the design of event-related
interaction modeling in MulSTE.
5.4 Parameter Sensitivity
Fig. 10 shows the results when adjusting the hidden size 𝑑ℎ. The
performance improved and then decreased with the increase in
hidden size, and the best size is 64. Fig. 11 shows the performance
comparison under different loss ratios. It confirms that the joint
prediction of demand and supply still has to face the multi-task
trade-off issue. We simply set it to 1 : 1 in our experiments.
5.5 Effect of Attention Weights
To investigate how important is each view of graphs to learn the
spatial relations, we visualize the attention weights 𝛼(𝑙)among
multi-view graphs in u-MGAC and r-MGAC by KDE density curves
on the Shanghai dataset. Fig. 12 shows the weight distributions of
regional graphs for learning representations of demand, supply, and
event separately. r-MGAC determines how much of the previous
hidden state should be forgotten, while u-MGAC determines how
much of the new input should be used to update the hidden state.
We can find that (i) for supply representation, the crowd-similarity
graph gets a significantly high weight when learning long-term
information while the type-similarity graph wins a relatively high
weight in short-term learning, (ii) for demand representation, the
weight distributions are nearly contrary between u-MGAC and
r-MGAC, which reveals that multi-view regional graphs contribute
oppositely in long-short term encoding. (iii) for event representa-
tion, the type-similarity graph is important in both u-MGAC and
r-MGAC. It is interesting to observe that the impact of events on
regions is strongly correlated to their function properties.
5.6 Effect of Adaptive Graph
To demonstrate the effectiveness of the adaptive adjacent matrix
𝑀𝑓𝑀𝑓𝑇in the adaptive graph of MGAC, we draw the heat map
of the adaptive adjacency matrix in Fig. 13 on Shanghai dataset,
consisting of 282 regions. Although multi-view graphs describe
regional relations from different aspects, the adaptive adjacency
matrix can further reflect the statistical correlation of regions auto-
matically. We select the key regions with high weights in Fig. 13b
and map them to the delivery stations in Fig. 13a with the blue heat
map. It is interesting to find that the key regions in the adaptive
matrix are in strong agreement with high-risk areas (red heat map
in Fig. 13a) to the emergent event (Covid-19). It reveals that the
adaptive graph can learn the event-related information of regions.
6 Conclusion
In this work, we study the problem of joint prediction of purchase
demand and delivery supply under events with heterogeneous data.
To address the challenges of complex spatio-temporal interaction of
demand and supply under the diverse impacts of events with hetero-
geneous data, we propose MulSTE. Evaluation results on real-world
0.1
0.00.10.20.30.40.50.60.70.80.91.0
Weights0510152025KDE DensityDistance-aware Graph
Neighbor-aware Graph
Type-similarity Graph
Crowd-similarity Graph(a) u-MGAC for demand
0.1
0.00.10.20.30.40.50.60.70.80.91.0
Weights0102030405060708090KDE DensityDistance-aware Graph
Neighbor-aware Graph
Type-similarity Graph
Crowd-similarity Graph (b) u-MGAC for supply
0.1
0.00.10.20.30.40.50.60.70.80.91.0
Weights051015202530KDE DensityDistance-aware Graph
Neighbor-aware Graph
Type-similarity Graph
Crowd-similarity Graph
(c) u-MGAC for event
0.1
0.00.10.20.30.40.50.60.70.80.91.0
Weights0510152025KDE DensityDistance-aware Graph
Neighbor-aware Graph
Type-similarity Graph
Crowd-similarity Graph (d) r-MGAC for demand
0.1
0.00.10.20.30.40.50.60.70.80.91.0
Weights0102030405060KDE DensityDistance-aware Graph
Neighbor-aware Graph
Type-similarity Graph
Crowd-similarity Graph
(e) r-MGAC for supply
0.1
0.00.10.20.30.40.50.60.70.80.91.0
Weights0102030405060708090KDE DensityDistance-aware Graph
Neighbor-aware Graph
Type-similarity Graph
Crowd-similarity Graph (f) r-MGAC for event
Figure 12: Attention weight distribution of Shanghai.
(a) Shanghai Map
070140 210 280
Region_no070140210280Region_no
0.00.20.40.60.8 (b) Adaptive Adjacent Matrix
Figure 13: Important region discovery for events in Shanghai.
datasets show that our model outperforms other state-of-the-art
models significantly, achieving at least 24.50%, 12.68%improvement
in demand and supply on average. In the future, we further expect
to extend our model to address event-aware forecasting problems
in various fields beyond E-commerce.
Acknowledgments
This work was supported in part by National Science and Technol-
ogy Major Project 2021ZD0114200, Natural Science Foundation of
Jiangsu Province under Grant BK20230815, National Natural Sci-
ence Foundation of China under Grant 61925202, Jiangsu Provincial
Key Research and Development Program under Grant BE2022065-1,
BE2022065-3.
 
1789KDD ’24, August 25–29, 2024, Barcelona, Spain Li Lin et al.
References
[1]Lei Bai, Lina Yao, Can Li, Xianzhi Wang, and Can Wang. 2020. Adaptive graph
convolutional recurrent network for traffic forecasting. Advances in neural
information processing systems 33 (2020), 17804–17815.
[2]Junyoung Chung, Caglar Gulcehre, Kyunghyun Cho, and Yoshua Bengio. 2014.
Empirical evaluation of gated recurrent neural networks on sequence modeling.
InNIPS 2014 Workshop on Deep Learning, December 2014.
[3]Yiming Cui, Wanxiang Che, Ting Liu, Bing Qin, Shijin Wang, and Guoping Hu.
2020. Revisiting Pre-Trained Models for Chinese Natural Language Processing. In
Findings of the Association for Computational Linguistics: EMNLP 2020. 657–668.
[4]Yue Cui, Jiandong Xie, and Kai Zheng. 2021. Historical inertia: A neglected but
powerful baseline for long sequence time-series forecasting. In Proceedings of
the 30th ACM International Conference on Information & Knowledge Management.
2965–2969.
[5]Neema Davis, Gaurav Raina, and Krishna Jagannathan. 2020. Grids versus graphs:
Partitioning space for improved taxi demand-supply forecasts. IEEE Transactions
on Intelligent Transportation Systems 22, 10 (2020), 6526–6535.
[6]Daizong Ding, Mi Zhang, Xudong Pan, Min Yang, and Xiangnan He. 2019. Mod-
eling extreme events in time series prediction. In Proceedings of the 25th ACM
SIGKDD International Conference on Knowledge Discovery & Data Mining. 1114–
1122.
[7]Harris Drucker, Christopher J Burges, Linda Kaufman, Alex Smola, and Vladimir
Vapnik. 1996. Support vector regression machines. Advances in neural information
processing systems 9 (1996).
[8]Aniekan Essien, Ilias Petrounias, Pedro Sampaio, and Sandra Sampaio. 2021. A
deep-learning model for urban traffic flow prediction with traffic events mined
from twitter. World Wide Web 24, 4 (2021), 1345–1368.
[9]Xu Geng, Yaguang Li, Leye Wang, Lingyu Zhang, Qiang Yang, Jieping Ye, and
Yan Liu. 2019. Spatiotemporal multi-graph convolution network for ride-hailing
demand forecasting. In Proceedings of the AAAI conference on artificial intelligence,
Vol. 33. 3656–3663.
[10] Zhuoning Guo, Hao Liu, Le Zhang, Qi Zhang, Hengshu Zhu, and Hui Xiong. 2022.
Talent Demand-Supply Joint Prediction with Dynamic Heterogeneous Graph
Enhanced Meta-Learning. In Proceedings of the 28th ACM SIGKDD Conference on
Knowledge Discovery and Data Mining. 2957–2967.
[11] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep residual
learning for image recognition. In Proceedings of the IEEE conference on computer
vision and pattern recognition. 770–778.
[12] Chao Huang, Jiashu Zhao, and Dawei Yin. 2021. Purchase intent forecasting with
convolutional hierarchical transformer networks. In 2021 IEEE 37th International
Conference on Data Engineering (ICDE). IEEE, 2488–2498.
[13] Xuanwen Huang, Yang Yang, Ziqiang Cheng, Shen Fan, Zhongyao Wang, Juren
Li, Jun Zhang, and Jingmin Chen. 2021. How Powerful are Interest Diffusion
on Purchasing Prediction: A Case Study of Taocode. In Proceedings of the 44th
International ACM SIGIR Conference on Research and Development in Information
Retrieval. 1308–1317.
[14] Huiling Jian, Chuanlei Wang, and Xiaocheng Jiang. 2021. Integrated Operation
Mode of Warehousing and Distribution in the O2O Environment. In The Inter-
national Conference on Artificial Intelligence and Logistics Engineering. Springer,
161–170.
[15] Dan Kalifa, Uriel Singer, Ido Guy, Guy D Rosin, and Kira Radinsky. 2022. Lever-
aging World Events to Predict E-Commerce Consumer Demand under Anomaly.
InProceedings of the Fifteenth ACM International Conference on Web Search and
Data Mining. 430–438.
[16] Thomas N. Kipf and Max Welling. 2017. Semi-Supervised Classification with
Graph Convolutional Networks. In International Conference on Learning Repre-
sentations. https://openreview.net/forum?id=SJU4ayYgl
[17] Fuxian Li, Jie Feng, Huan Yan, Guangyin Jin, Fan Yang, Funing Sun, Depeng Jin,
and Yong Li. 2021. Dynamic graph convolutional recurrent network for traffic
prediction: Benchmark and solution. ACM Transactions on Knowledge Discovery
from Data (TKDD) (2021).
[18] Yaguang Li, Rose Yu, Cyrus Shahabi, and Yan Liu. 2018. Diffusion Convolutional
Recurrent Neural Network: Data-Driven Traffic Forecasting. In International
Conference on Learning Representations.
[19] Junming Liu, Leilei Sun, Qiao Li, Jingci Ming, Yanchi Liu, and Hui Xiong. 2017.
Functional zone based hierarchical demand prediction for bike system expansion.
InProceedings of the 23rd ACM SIGKDD International Conference on Knowledge
Discovery and Data Mining. 957–966.
[20] Yuqi Nie, Nam H Nguyen, Phanwadee Sinthong, and Jayant Kalagnanam. 2022.
A Time Series is Worth 64 Words: Long-term Forecasting with Transformers. In
The Eleventh International Conference on Learning Representations.
[21] Huiling Qin, Songyu Ke, Xiaodu Yang, Haoran Xu, Xianyuan Zhan, and Yu Zheng.
2021. Robust spatio-temporal purchase prediction via deep meta learning. In
Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 35. 4312–4319.
[22] Zezhi Shao, Zhao Zhang, Wei Wei, Fei Wang, Yongjun Xu, Xin Cao, and Chris-
tian S Jensen. 2022. Decoupled dynamic spatial-temporal graph neural network
for traffic forecasting. arXiv preprint arXiv:2206.09112 (2022).[23] Jiatu Shi, Huaxiu Yao, Xian Wu, Tong Li, Zedong Lin, Tengfei Wang, and Binqiang
Zhao. 2021. Relation-aware meta-learning for e-commerce market segment de-
mand prediction with limited records. In Proceedings of the 14th ACM International
Conference on Web Search and Data Mining. 220–228.
[24] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all
you need. Advances in neural information processing systems 30 (2017).
[25] Petar Veličković, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro
Liò, and Yoshua Bengio. 2018. Graph Attention Networks. In International Confer-
ence on Learning Representations. https://openreview.net/forum?id=rJXMpikCZ
[26] Dong Wang, Wei Cao, Jian Li, and Jieping Ye. 2017. DeepSD: Supply-demand
prediction for online car-hailing services using deep neural networks. In 2017
IEEE 33rd international conference on data engineering (ICDE). IEEE, 243–254.
[27] Zhaonan Wang, Renhe Jiang, Hao Xue, Flora D Salim, Xuan Song, and Ryosuke
Shibasaki. 2022. Event-aware multimodal mobility nowcasting. In Proceedings of
the AAAI Conference on Artificial Intelligence, Vol. 36. 4228–4236.
[28] Zhaonan Wang, Tianqi Xia, Renhe Jiang, Xin Liu, Kyoung-Sook Kim, Xuan Song,
and Ryosuke Shibasaki. 2021. Forecasting Ambulance Demand with Profiled
Human Mobility via Heterogeneous Multi-Graph Neural Networks. In 2021 IEEE
37th International Conference on Data Engineering (ICDE). IEEE, 1751–1762.
[29] Billy M Williams and Lester A Hoel. 2003. Modeling and forecasting vehicular
traffic flow as a seasonal ARIMA process: Theoretical basis and empirical results.
Journal of transportation engineering 129, 6 (2003), 664–672.
[30] Haixu Wu, Tengge Hu, Yong Liu, Hang Zhou, Jianmin Wang, and Mingsheng
Long. 2022. TimesNet: Temporal 2D-Variation Modeling for General Time Series
Analysis. In The Eleventh International Conference on Learning Representations.
[31] Tongwen Wu, Yu Yang, Yanzhi Li, Huiqiang Mao, Liming Li, Xiaoqing Wang, and
Yuming Deng. 2021. Representation Learning for Predicting Customer Orders.
InProceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &
Data Mining. 3735–3744.
[32] Zonghan Wu, Shirui Pan, Guodong Long, Jing Jiang, Xiaojun Chang, and Chengqi
Zhang. 2020. Connecting the dots: Multivariate time series forecasting with graph
neural networks. In Proceedings of the 26th ACM SIGKDD international conference
on knowledge discovery & data mining. 753–763.
[33] Zonghan Wu, Shirui Pan, Guodong Long, Jing Jiang, and Chengqi Zhang. 2019.
Graph wavenet for deep spatial-temporal graph modeling. In Proceedings of the
28th International Joint Conference on Artificial Intelligence. 1907–1913.
[34] Junchen Ye, Leilei Sun, Bowen Du, Yanjie Fu, Xinran Tong, and Hui Xiong. 2019.
Co-prediction of multiple transportation demands based on deep spatio-temporal
neural network. In Proceedings of the 25th ACM SIGKDD International Conference
on Knowledge Discovery & Data Mining. 305–313.
[35] Haitao Yuan, Guoliang Li, Zhifeng Bao, and Ling Feng. 2021. An effective joint pre-
diction model for travel demands and traffic flows. In 2021 IEEE 37th International
Conference on Data Engineering (ICDE). IEEE, 348–359.
[36] Yuan Yuan, Muzhi Guan, Zhilun Zhou, Sundong Kim, Meeyoung Cha, Depeng Jin,
and Yong Li. 2021. Disruption in chinese e-commerce during covid-19. Frontiers
in Computer Science 3 (2021), 668711.
[37] Ailing Zeng, Muxi Chen, Lei Zhang, and Qiang Xu. 2023. Are transformers
effective for time series forecasting?. In Proceedings of the AAAI conference on
artificial intelligence, Vol. 37. 11121–11128.
[38] Mingyang Zhang, Tong Li, Yong Li, and Pan Hui. 2021. Multi-view joint graph
representation learning for urban region embedding. In Proceedings of the Twenty-
Ninth International Conference on International Joint Conferences on Artificial
Intelligence. 4431–4437.
[39] Xin Zhang, Yanhua Li, Xun Zhou, Oren Mangoubi, Ziming Zhang, Vincent Filardi,
and Jun Luo. 2021. DAC-ML: Domain Adaptable Continuous Meta-Learning
for Urban Dynamics Prediction. In 2021 IEEE International Conference on Data
Mining (ICDM). IEEE, 906–915.
[40] Yingxue Zhang, Yanhua Li, Xun Zhou, and Jun Luo. 2020. cST-ML: Continuous
spatial-temporal meta-learning for traffic dynamics prediction. In 2020 IEEE
International Conference on Data Mining (ICDM). IEEE, 1418–1423.
[41] Ling Zhao, Yujiao Song, Chao Zhang, Yu Liu, Pu Wang, Tao Lin, Min Deng, and
Haifeng Li. 2019. T-gcn: A temporal graph convolutional network for traffic
prediction. IEEE transactions on intelligent transportation systems 21, 9 (2019),
3848–3858.
[42] Haoyi Zhou, Shanghang Zhang, Jieqi Peng, Shuai Zhang, Jianxin Li, Hui Xiong,
and Wancai Zhang. 2021. Informer: Beyond efficient transformer for long se-
quence time-series forecasting. In Proceedings of the AAAI conference on artificial
intelligence, Vol. 35. 11106–11115.
[43] Tian Zhou, Ziqing Ma, Qingsong Wen, Xue Wang, Liang Sun, and Rong Jin.
2022. Fedformer: Frequency enhanced decomposed transformer for long-term
series forecasting. In International Conference on Machine Learning. PMLR, 27268–
27286.
[44] Xian Zhou, Yanyan Shen, Yanmin Zhu, and Linpeng Huang. 2018. Predicting
multi-step citywide passenger demands using attention-based neural networks.
InProceedings of the Eleventh ACM international conference on web search and
data mining. 736–744.
 
1790MulSTE: A Multi-view Spatio-temporal Learning Framework with Heterogeneous Event Fusion for Demand-supply Prediction KDD ’24, August 25–29, 2024, Barcelona, Spain
A APPENDIX
A.1 Mathematical Notations
The key mathematical notations are listed in Table 4.
A.2 Data Details
Taking Shanghai as an example, we provide specific examples of
original data, as shown in Table 5, categorized into five types: order
data, delivery station data, user data, emergent event data, news
data, and periodic event data.
For the news data, we crawled the dates, news sources, and news
titles from the important news website of the Shanghai Municipal
People’s Government, as illustrated in Fig. 14. For the Fine-tuning
stage (2020/1/1-2020/12/31), we labeled the news using a keyword
filtering and manual review approach. The chosen base keywords
were epidemic, lockdown, resumption, masks, etc., and it’s worth
noting that these keywords can be replaced based on different
events. A label of 1 indicates that the news title is related to this
emergent event, while a label of 0 indicates no relevance to this
emergent event. Consequently, we obtained the limited labeled
news titles during the Fine-tuning stage as depicted in Fig. 5. Miss-
ing news filling tricks are also applied in the Adapting to prediction
tasks stage to cope with the different number of news at each time
step and facilitate conversion into tensors.
A.3 Metrics
We deploy three metrics Mean Absolute Error (MAE), Root Mean
Square Error (RMSE), and Symmetric Mean Absolute Percentage Er-
ror (sMAPE) suitable to measure the performance of the predictive
model.
𝑀𝐴𝐸 =1
𝑛𝑛∑︁
𝑖=1|𝑦𝑖−ˆ𝑦𝑖|
𝑅𝑀𝑆𝐸 =vt
1
𝑛𝑛∑︁
𝑖=1(𝑦𝑖−ˆ𝑦𝑖)2
𝑠𝑀𝐴𝑃𝐸 =1
𝑛𝑛∑︁
𝑖=1|𝑦𝑖−ˆ𝑦𝑖|
(|𝑦𝑖|+|ˆ𝑦𝑖|)/2(17)A.4 Additional Experimental Results
To further verify the generalizability of our model in various sce-
narios, we evaluate MulSTE on a filtered sub-dataset named NE by
omitting all samples that happen under emergent events, aiming to
know whether MulSTE can accurately predict the demand-supply
sequences when no emergent events happen. Similarly, we filtered
all samples related to emergent events to construct the sub-dataset
PE. We adopt two different evaluating approaches: retraining (RT)
and direct inference (DI) where RT needs to train another MulSTE
model on the given sub-dataset and DI directly use the trained Mul-
STE on the raw dataset to make inference on the two sub-datasets.
The experimental results are shown in Table 6. It demonstrates that
on NE sub-datasets, MulSTE outperforms all baselines with a signif-
icant margin whenever we use the re-trained model or directly infer
on the pre-trained one. However, when evaluating the models on
PE sub-datasets, a few metrics show a slight weakness of MulSTE
compared with Informer and AGCRN. For example, when predict-
ing the supply volume on the Shanghai PE sub-dataset, AGCRN has
a comparable performance compared with MulSTE either through
RT or DI. Whether the spatial or temporal information makes more
contributions to the overall performance is also a question hard to
answer. Factually, although MulSTE may not achieve the best per-
formance in some specific evaluation settings, it still wins second
place compared with others. It confirms that our proposed MulSTE
is competent in generalized situations, even using direct inference
without further training.
Figure 14: News Web of Shanghai Municipal People’s Gov-
ernment.
Table 4: Key mathematical notations.
Notation Definition Notation Definition
𝐺∗The multi-view graph ℎ𝐷
𝑡The hidden state of demand at time step 𝑡
𝑁 The number of regions ℎ𝑆
𝑡 The hidden state of supply at time step 𝑡
𝑑𝑡 The purchase demand at time step 𝑡 ℎ𝐸
𝑡 The hidden state of event at time step 𝑡
𝑠𝑡 The delivery supply at time step 𝑡 ℎ𝐷𝐼
𝑡The hidden state of interacted demand at time step 𝑡
𝑒𝑢
𝑡 The textual type events at time step 𝑡ℎ𝑆𝐼
𝑡The hidden state of interacted supply at time step 𝑡
𝑒𝑛
𝑡 The numerical type events at time step 𝑡ℎ𝐷𝐸
𝑇The final demand-related event representation
𝑒𝑐
𝑡The categorical type events at time step 𝑡ℎ𝑆𝐸
𝑇The final supply-related event representation
𝐷𝑡 The demand representation at time step 𝑡𝐻𝐷
𝑇The final demand representation
𝑆𝑡 The supply representation at time step 𝑡𝐻𝑆
𝑇The final supply representation
𝐸𝐹𝑠𝑛
𝑡The event fusion representation at time step 𝑡LD The loss of demand prediction task
𝜃 The model parameter set of MulSTE LS The loss of supply prediction task
𝑇 The length of previous sequence L𝜃 The loss of joint prediction task
𝑙 The length of future sequence 𝑑ℎ The dimension of hidden state
 
1791KDD ’24, August 25–29, 2024, Barcelona, Spain Li Lin et al.
Table 5: Data Details.
Original Data Attribute Example
Order DataOrder_ID JD*********9544
Purchase timestamp 2022/3/7 22:25
Delivery timestamp 2022/3/8 9:15
Region ID 26
User ID User_0
Delivery Station DataRegion ID 26
Name Shanghai Guchuan Delivery Station
Location 121.3921◦𝐸,31.2523◦𝑁
Scope POLYGON ((121.3844 31.2604, ...., 121.3844 31.2604))
Types (counts, areas, distances) Type0: 2, 0.2924, 0.1518; ... ; Type8: 5, 0.2345, 0.1976
User DataUser ID User_0
Region ID 26
Gender ****
Age ****
. . . . . . . . . . . .
Purchasing power ****
Promotion sensitivity ****
Emergent Event DataDate 2022/3/7
Outbreak location Address上海市/徐汇区/漕溪北路/1200号
(No. 1200, Caoxi North Road, Xuhui District, Shanghai)
coordinates 121.4356◦𝐸,31.1818◦𝑁
Risk area location Address上海市/嘉定区/马陆镇/宝安公路/3705弄/1号
(No. 1, Lane 3705, Bao’an Road, Malu Town, Jiading District, Shanghai)
coordinates 121.2680◦𝐸,31.3248◦𝑁
News DataDate 2022/3/13
News Source 解放日报 (JIEFANG DAILY)
News title上海进一步强化疫情防控措施市民非必要不离沪
(Shanghai further strengthens epidemic prevention and control measures;
citizens do not leave Shanghai unless necessary.)
Label 1 - emergent event related
Periodic Event DataDate 2022/6/18
Day of Week Saturday
Festival Type Mid-year Promotion
Table 6: Model effectiveness validation in the simulation of non-emergent and prolonged-emergent scenarios.
Type ModelsRT DI
Demand Supply Demand Supply
MAE RMSE sMAPE MAE RMSE sMAPE MAE RMSE sMAPE MAE RMSE sMAPE
SHNEAGCRN 203.59 420.70 12.22% 136.52 208.98 9.03% 150.65 298.10 9.86% 127.83 201.04 8.64%
Informer 211.53 415.00 12.63% 135.18 206.65 9.04% 192.22 411.38 12.07% 128.46 206.83 8.68%
MulSTE 139.19 265.06 8.78% 112.17 178.76 7.54% 113.50 204.07 7.86% 117.79 188.08 8.13%
PEAGCRN 190.69 284.16 13.10% 277.11 465.13 23.80% 245.13 600.32 13.73% 258.05 453.10 21.91%
Informer 182.11 281.47 12.37% 276.99 483.69 25.31% 330.41 783.72 17.88% 259.43 482.03 23.71%
MulSTE 181.17 262.78 13.61% 278.28 462.67 23.90% 195.75 389.92 12.76% 259.05 441.69 20.76%
ZZNEAGCRN 187.36 423.56 13.78% 148.60 279.44 11.71% 148.03 332.71 12.34% 134.99 248.57 11.10%
Informer 200.57 440.16 13.93% 128.64 240.11 10.54% 147.04 345.92 11.80% 127.24 255.75 10.04%
MulSTE 109.87 199.40 10.71% 107.81 202.46 9.27% 97.80 184.26 9.52% 95.21 175.92 8.61%
PEAGCRN 316.59 624.98 23.63% 281.36 463.60 34.45% 186.17 446.21 16.29% 243.62 480.81 34.57%
Informer 307.85 632.21 22.39% 264.02 442.96 34.76% 183.79 457.54 14.80% 220.30 478.52 32.69%
MulSTE 250.51 496.86 21.77% 282.38 438.00 34.77% 126.84 228.48 13.53% 157.87 271.73 28.79%
 
1792