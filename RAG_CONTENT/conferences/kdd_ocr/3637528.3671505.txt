NL2Code- Reasoning and Planning with LLMs for Code
Development
Ye Xing
Microsoft
Boston, USA
yexing@microsoft.comJun Huan
Amazon
Seattle, USA
lukehuan@amazon.comWee Hyong Tok
Microsoft
Redmond, USA
weetok@microsoft.comCong Shen
University of
Virginia
Charlottesville, USA
cong@virginia.eduJohannes Gehrke
Microsoft
Redmond, USA
johannes@microsoft.com
Katherine Lin
Microsoft
Redmond, USA
katlin@microsoft.comArjun Guha
Northeastern
University
Boston, USA
a.guha@northeastern.eduOmer Tripp
Amazon
Seattle, USA
omertrip@amazon.comMurali Krishna
Ramanathan
Amazon
Seattle, USA
mkraman@amazon.com
ABSTRACT
There is huge value in making software development more pro-
ductive with AI. An important component of this vision is the
capability to translate natural language to a programming language
("NL2Code") and thus to significantly accelerate the speed at which
code is written.
This workshop gathers researchers, practitioners, and users from
industry and academia that are working on NL2Code, specifically on
the problem of using large language models to convert statements
posed in a human language to a formal programming language.
CCS CONCEPTS
•Software and its engineering →Software creation and man-
agement; Software notations and tools.
KEYWORDS
LLMs, code creation, copilot, generative AI
ACM Reference Format:
Ye Xing, Jun Huan, Wee Hyong Tok, Cong Shen, Johannes Gehrke, Kather-
ine Lin, Arjun Guha, Omer Tripp, and Murali Krishna Ramanathan. 2024.
NL2Code- Reasoning and Planning with LLMs for Code Development. In
Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery
and Data Mining (KDD ’24), August 25–29, 2024, Barcelona, Spain. ACM, New
York, NY, USA, 2 pages. https://doi.org/10.1145/3637528.3671505
1 INTRODUCTION
Generative AI has tremendous potential to change the way we work
and to empower everyone to achieve more, as many researchers and
practitioner have observed. One of these areas is the use of genera-
tive AI to translate from natural language to a formal programming
language to generate code.
Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for third-party components of this work must be honored.
For all other uses, contact the owner/author(s).
KDD ’24, August 25–29, 2024, Barcelona, Spain
©2024 Copyright held by the owner/author(s).
ACM ISBN 979-8-4007-0490-1/24/08.
https://doi.org/10.1145/3637528.3671505One possible use case pioneered by Github CoPilot is the idea
of an AI pair programmer who works side-by-side with you, like
a traditional pairing programmer, who you can ask questions and
who will help you to write your code.
LLMs are the science base of current NL2Code technology; they
are trained on vast amounts of code, available in GitHub and other
code repositories, and they seemingly learn to understand the struc-
ture of code and the semantics of programming languages.
Innovation in the area of NL2Code continues rapidly, driven by
varying levels of coding expertise and business needs. The NL2code
workshop provides a premier forum for researchers and practition-
ers in related fields to present the latest progress on this exciting
topic. This workshop plans to cover at least the following aspects
of NL2Code:
•Translating NL to code(e.g. NL2Java, NL2Python). This en-
ables them to be able to troubleshoot bug, identify best prac-
tices for programming, and more.
•For database users, they mainly use NL for query generation
to enable customers to get from natural language to the
SQL queries that can be executed against the data store (e.g.
NL2SQL, NL2KQL and more).
•For legacy code base, there is a strong demand to auto-
matically modernize the code base using refactoring or re-
implementation. For example, getting from a natural lan-
guage query to migrate repo originally developed in Java 8
to Java 17.
•For business users, they will like to use NL to Domain specific
languages, that helps them automate common business tasks.
For example, getting from a natural language query to a
Business Intelligence (BI) dashboard.
There are many challenges in basic research in order to support
those use-cases. Below we single out two important directions:
reasoning and planning with LLM.
Planning is a critical component for applying LLMs to code
development. There are many tools that have been developed in
the past to assist code development. Examples include tools for test
case generation, tools for security risk identification from source
code, and tools for runtime performance bottleneck analysis. How
6745
KDD ’24, August 25–29, 2024, Barcelona, Spain Ye Xing et al.
to combine the tools together to accomplish a complex task is a
very important research direction.
Reasoning is at the core of planning. The inputs to the reason-
ing process are multifaceted. Common ones include the source code
and error logs for code generation and debugging. Additional infor-
mation could be gained through static analysis of the code, such as
abstract syntax tree (AST), a tree representation of the structure of
the source code. Yet another source of information is the runtime
profiler, where information regarding where the runtime is spent
is collected. There are many advanced reasoning techniques in the
code development domain. Notable examples include self-debug
and flow-engineering.
Over the past two years, both established tech companies and
new startups have been aggressively developing NL2Code tools
with significant customer success. For example, GitHub Copilot has
been used by over more than one million developers, and it has
been adopted by tens of thousands of organizations. As another
example Amazon Q is Amazon’s flagship genAI product for code
development. Amazon Q generates code and tests, and it debugs.
The multistep planning and reasoning capabilities enable Amazon
Q transform and implement new code from user request.
2 PROGRAM SKETCH (HALF-DAY)
The workshop will be a half-day workshop, consisting of keynotes,
interactive discussions, a panel, lightning talk, and poster/demo
session. We will be inviting expert speakers from Big Tech, startups,
and universities. Speakers will include successful industry and
academic practitioners that have demonstrated AI leadership in
both academia and industry.
•Keynote 1 - Delivered by AI leader Shuyin Zhao,VP from
Github.
•Keynote 2 - Delivered by AI leader Alex Watson from Gre-
tel.ai.
•Keynote 3 - Delivered by professor Xiangyu Zhang from
Purdue University.
•5-mins Lightning talk - Selected talks from paper submis-
sion (each 5 mins).
•Q&A Panel: A panel consisting of experts with complimen-
tary background: industry, academia, and funding agency
will share their view on the trends of the NL2Code work in
academia and research, and stimulate thinking on how we
can drive innovation for NL2Code research and applications.
•Poster and demo: Selected posters and demo from paper
submission. Please see the appendix for details on paper
submission.
3 WORKSHOP ORGANIZERS
Ye Xing is a Principal Machine Learning Engineer Manager at Mi-
crosoft. Ye is leading an AI team in Microsoft security organization,
to develop and deliver NL2KQL product, one of the key features on
Microsoft Copilot of Security.
Jun (Luke) Huan is a Principal Scientist at AWS AI. He has pub-
lished more than 200 peer-reviewed papers in leading conferences
and journals. He was a recipient of the NSF Faculty Early Career
Development Award in 2009. Before joining AWS, he worked atBaidu research as a distinguished scientist and the head of Baidu
Big Data Laboratory. He founded StylingAI Inc., an AI start-up, and
worked as the CEO and Chief Scientist in 2019-2021.
Wee Hyong Tok is Partner Director, Microsoft, working on Data
and AI products. Prior to his current role, Wee Hyong was Head
of AI Labs, where he led a global team of data scientists to deliver
cutting-edge ML/AI solutions. Wee Hyong led AI strategy and in-
novation and co-founded the AI for Earth Engineering and Data
science team.
Cong Shen is an Assistant Professor at the University of Virginia.
His current research focuses on in-context learning, LLM, rein-
forcement learning, and federated learning. He also has extensive
industry experience, having worked for Qualcomm Research, Spi-
derCloud Wireless, Silvus Technologies, and Xsense.ai, in various
full-time and consulting roles.
Johannes Gehrke is a Technical Fellow at Microsoft, working
on AI for the Microsoft Copilots, and he is the head of machine
learning for the Intelligent Communications and Conversations
Cloud (IC3), which powers Microsoft Teams. Before he joined Mi-
crosoft, he was the Tisch University Professor in the Department
of Computer Science at Cornell University where he graduated 25
PhD students.
Katherine Lin Lin is a Principal Applied Scientist Manager at
Microsoft, where she leads the scientist team for Azure SQL organi-
zation. Her team is dedicated to developing end-to-end production
quality AI solutions that enhance service efficiency and improve
customer experience. They focus on advancing AI in several key
areas, including Copilots, AIOps, and autonomous databases.
Arjun Guha is an Associate Professor at Northeastern Univer-
sity and Visiting Professor at Roblox Research. His current research
focuses on the development of LLMs trained on code. He is part of
the leadership of the BigCode Project, which is developing open
Code LLMs such as StarCoder and StarCoder2.
Omer Tripp is a Principal Scientist at AWS. At AWS, Omer led
the science work powering Amazon CodeGuru. Omer currently
leads research on state-of-the-art techniques that bring together
traditional code transformation tools and generative AI to perform
automated code transformations as part of the Q Code Transforma-
tion feature.
Murali Krishna Ramanathan is a Principal Applied Scientist
at AWS. Previously, he was affiliated with Uber, IISc, Bangalore
and Coverity Inc. He has designed and implemented several novel
program analysis tools for detecting software bugs. He received his
PhD in Computer Science from Purdue University.
4 ACKNOWLEDGMENTS
We will like to thank Jie Tang, for working with the organizing
team to provide inputs for the workshop.
6746