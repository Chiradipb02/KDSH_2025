Extreme Meta-Classification for Large-Scale Zero-Shot Retrieval
Sachin Yadav∗†‡
t-sacyadav@microsoft.com
Microsoft Research
Bengaluru, IndiaDeepak Saini∗
desaini@microsoft.com
Microsoft
Redmond, USAAnirudh Buvanesh∗
t-abuvanesh@microsoft.com
Microsoft Research
Bengaluru, India
Bhawna Paliwal
bhawna@microsoft.com
Microsoft Research
Bengaluru, IndiaKunal Dahiya
kunalsdahiya@gmail.com
Indian Institute of Technology
Delhi, IndiaSiddarth Asokan‡
sasokan@microsoft.com
Microsoft Research
Bengaluru, India
Yashoteja Prabhu
yprabhu@microsoft.com
Microsoft Research
Bengaluru, IndiaJian Jiao
Jian.Jiao@microsoft.com
Microsoft
Redmond, USAManik Varma
manik@microsoft.com
Microsoft Research
Bengaluru, India
Abstract
We develop accurate and efficient solutions for large-scale retrieval
tasks where novel (zero-shot ) items can arrive continuously at a
rapid pace. Conventional Siamese-style approaches embed both
queries and items through a small encoder and retrieve the items
lying closest to the query. While this approach allows efficient addi-
tion and retrieval of novel items, the small encoder lacks sufficient
capacity for the necessary world knowledge in complex retrieval
tasks. The extreme classification approaches have addressed this
by learning a separate classifier for each item observed in the train-
ing set which significantly increases the representation capacity
of the model. Such classifiers outperform Siamese approaches on
observed items, but cannot be trained for novel items due to data
and latency constraints. To bridge these gaps, this paper develops:
(1) A new algorithmic framework , EMMETT, which efficiently
synthesizes classifiers on-the-fly for novel items, by relying on
the readily available classifiers for observed items; (2) A new algo-
rithm , IRENE, which is a simple and effective instance of EMMETT
that is specifically suited for large-scale deployments, and (3) A new
theoretical framework for analyzing the generalization perfor-
mance in large-scale zero-shot retrieval which guides our algorithm
and training related design decisions. Comprehensive experiments
are conducted on a wide range of retrieval tasks which demonstrate
that IRENE improves the zero-shot retrieval accuracy by up to 15%
points in Recall@10 when added on top of leading encoders. Addi-
tionally, on an online A/B test in a large-scale ad retrieval task in
a major search engine, IRENE improved the ad click-through rate
by 4.2%. Lastly, we validate our design choices through extensive
∗Equal technical contribution.†Sachin Yadav led the project.
‡Corresponding authors are S. Yadav (sachinyadav7024@gmail.com) and S. Asokan
(sasokan@microsoft.com)
This work is licensed under a Creative Commons Attribution
International 4.0 License.
KDD ’24, August 25–29, 2024, Barcelona, Spain
©2024 Copyright held by the owner/author(s).
ACM ISBN 979-8-4007-0490-1/24/08
https://doi.org/10.1145/3637528.3672046ablative experiments. The source code for IRENE is available at
https://aka.ms/irene.
CCS Concepts
•Computing methodologies →Supervised learning by clas-
sification.
Keywords
extreme classification, large-scale retrieval, zero-shot retrieval, spon-
sored search advertising
ACM Reference Format:
Sachin Yadav, Deepak Saini, Anirudh Buvanesh, Bhawna Paliwal, Kunal
Dahiya, Siddarth Asokan, Yashoteja Prabhu, Jian Jiao, and Manik Varma.
2024. Extreme Meta-Classification for Large-Scale Zero-Shot Retrieval. In
Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery
and Data Mining (KDD ’24), August 25–29, 2024, Barcelona, Spain. ACM, New
York, NY, USA, 10 pages. https://doi.org/10.1145/3637528.3672046
1 Introduction
Large-scale retrieval involves retrieving the items relevant to a
query from a pool of hundreds of millions of candidate items. Such
tasks frequently arise in modern-day web applications such as web
search [ 5], computational advertising [ 2], product recommenda-
tion [ 8], and so on. To optimize user satisfaction, the retrieved
results need to be highly relevant to the query and delivered in
real-time, typically within milliseconds. Additionally, due to the
exponential growth of digital content, novel items get introduced
into these systems in vast quantities daily, which need to be swiftly
processed and inserted into the candidate pool to ensure up-to-date
results. This paper aims to develop highly accurate and efficient
solutions for problems of large-scale text-based retrieval with novel
items (also referred to as zero-shot items). Note that this scenario is
different from the one considered in [ 13,39] where the task itself
is zero-shot.
A widely used technique for large-scale retrieval is dense re-
trieval [ 45] where both queries and items are represented as em-
beddings in a shared low-dimensional space such that the items
relevant to a query are positioned closer to it than the irrelevant
3657
KDD ’24, August 25–29, 2024, Barcelona, Spain Sachin Yadav et al.
ones. The relevant items, typically few in number, are then retrieved
in almost real-time using scalable Approximate Nearest Neighbour
Search (ANNS) indices [ 36]. The accuracy of retrieved results de-
pends on the quality of the derived query and item representations.
Typical dense retrievers are based on a Siamese encoder archi-
tecture which uses a common deep neural encoder to derive both
query and item representations from their raw text inputs [ 20,40].
Usually, a small and efficient encoder is utilized to reduce the rep-
resentation latencies, which enables large-scale deployments and
quick insertion of novel items. However, a small encoder often
lacks the capacity to model the complexity inherent in retrieval
tasks [ 12]. For instance, item descriptions frequently contain named
entities, numbers, model numbers, and ambiguous phrases with
issues of synonymy and polysemy whose resolution requires ex-
tensive world knowledge that cannot be contained within a small
encoder [ 38]. As a result, the representations from these approaches
are inferior and degrade the retrieval performance.
Recently, Extreme Classification (XC) methods have emerged as
promising alternatives for large scale retrieval. Leading extreme
classifiers augment a small Siamese encoder with a massive linear
classifier layer at its output which significantly boosts the model
capacity [ 9,10]. Each item observed in the training set is endowed
with its own classifier, which absorbs the world knowledge perti-
nent to the item when trained from the historical click logs. During
retrieval, a query is first passed through the encoder and then pro-
jected onto its relevant items by applying classifiers. When there
are enough clicked query samples for training, the classifier-based
item representations can be more precise than the text-restricted
representations from a small encoder. However, zero-shot retrieval
is not supported, as classifiers cannot be trained for novel items
with no clicked samples. Even if we could, learning new classifiers
from scratch is time-consuming and delays the representation of
novel items, making the candidate pool outdated.
This paper addresses the limitations of the existing approaches
on large-scale zero-shot retrieval. Our primary research question
is:How to construct accurate representations for novel items
without significant computational overhead in large-scale re-
trieval tasks?
We propose a novel algorithmic framework, Extre MeMETa-
classifica Tion (EMMETT), as an answer to this question. EMMETT
extends conventional Extreme Classification to zero-short scenarios.
Often in large-scale retrieval tasks, millions of observed items with
associated user-clicked queries are available for training from his-
torical logs. This leads to two key insights that underpin EMMETT’s
design:
First, ignoring any significant shifts in item distribution, extreme
classifiers trained for a million observed items are likely to contain
most of the world knowledge required for any novel item in a
distilled and readily usable form. With this intuition, EMMETT
builds a pipeline with two main modules: (1) A classifier selector
(S) module, which takes a novel item as input and rapidly shortlists
a few observed item classifiers that are most informative for it,
by using efficient filtering techniques, and (2) A meta-classifier
generator (G) module, which combines these shortlisted classifiers
to synthesize a novel item’s classifier with minimal latency. We call
such a classifier derived from other classifiers as a meta-classifier.
Second, a million observed items can also serve as a large number
3
EXTREME CLASSIFIER BASE
ENCODER<latexit sha1_base64="8jd+0BBFEqTLtCRWVMGmV4U6wtA=">AAAEj3icnVNLb9QwEHbbBUp4tXDkYlGtxGGpdrcvQCqqhFrBBQp9Ss2qcpzJxlrHTu1J2zTKz+AKv4t/g5NdqQ1demCkKDPjbx7+xhOkUljsdn/PzM617t1/MP/Qe/T4ydNnC4vPD63ODIcDrqU2xwGzIIWCAxQo4Tg1wJJAwlEw+lidH52DsUKrfcxTGCRsqEQkOEPnOvEThrHlptguTxeWusvdWuhtpTdRlshEdk8X55Qfap4loJBLZm3BDAouofT8zELK+IgN4QThEi9EiPFmv8uTTmXGIIYxbq44e1AMQSeAJm9EFSyxNk+CkrbrDhsZDZwpPagg1dk0SFET406cK6SRNu5TSGvvtDId98c4mZqq8hgb2WZ/FhNmchM2vRFTPA/0ZZOBDKO3g0KoNENQfNxVlEmKmlYjoaEwwFHmlHHuuMwYuqZ5zAzj6EbneX4dW+yJMHQUx6durFKfZSJLnJokTIWuu1r+q2woGDfCje5mUT/O0xhUCopJzHvj6Xvtna9f9t/TPSlCsPQN7a916PftnUrrduiuti7WGSvrXvsmL4Bay5qXtq/ggo+bLvwrMDoUNpUstyOR2rJoe21KfQvuIashxoXPAn0ONzBlsZpieQsWgNQXDVh/GqyRLdYG78A2Ul5juw5b3YOlKerCV9okTFpxBeWU+1zj3FuV8m5IpDUqjfCvZG5De3/v423lsL/cW19e+7a6tPVusqvz5CV5RV6THtkgW+QT2SUHhBNNfpCf5FdrsbXR+tDaGkNnZyYxL0hDWp//AFO0jgU=</latexit>E
<latexit sha1_base64="s3G8fdJDjUK1j+dKV3JYdWxRrIQ=">AAAEonicnVNLb9NAEN62AUp4pXCEw4oSiUOokvTBQ6pUCVEhDtDSp4SjaL2exKvuw90dN3UtX/g1XOHf8G9YJ5Fa09ADI1memf3msd/shIkUDtvt33PzC7Vbt+8s3q3fu//g4aPG0uNDZ1LL4YAbaexxyBxIoeEABUo4TiwwFUo4Ck/el+dHZ2CdMHofswR6ig21GAjO0Lv6jWeBYhiHYX5U0E0a5EGo8lHRD0DKoOg3ltsr7bHQ60pnqiyTqez0lxZ0EBmeKtDIJXMuZxYFl1DUg9RBwvgJG8I3hHMciQjjzW6bq1ZpxiCGMW6ueruXD8EoQJtVonKmnMtUWNBm2bKrZLRwqk2vhJRnsyD5mCt/4l0RHRjrP4107J1VpuX/GKuZqUqPdQNX7c+hYjazUdU7YJpnoTmvMpDi4E0vFzpJETSfdDVIJUVDyynRSFjgKDPKOPdcpgx90zxmlnH006zXg3FsvieiyFMc9/2kpTlNRaq8qhTTke9uLP9VNhKMW+FHd7VoEGdJDDoBzSRmncn0683tL5/339E9KSJw9BXtrrfo1w/bpdZu0R3jfKw3Vjfqzau8ABojx7w0Aw0jPmk6Dy7Amki4RLLMnYjEFXmz3qQ0cODfth5inAcsNGdwBVPkawkW12AhSDOqwLqzYJVssbF4A7aS8hLb9tjyHixJ0OSBNlYx6cQFFDPuc4nzb1XKmyEDY1AbhH8l8xva+XsfryuH3ZXOxsr67try1tvpri6Sp+Q5eUk65DXZIh/JDjkgnHwnP8hP8qv2ovaptlvbm0Dn56YxT0hFasEfPmWVLQ==</latexit>W={w }CLASSIFIERS
CLASSIFIER  SELECTOR<latexit sha1_base64="D3JMKSFRXOXtjU8PaKr5MYgwi1s=">AAAEj3icnVNLb9QwEHbpAiW8WjhysahW4rBUu9sXIBVVQlRwgUKfUrOqHGeysepHak/aplF+Blf4XfwbnN2V2tClB0aKMjP+5uFvPFEmhcNu9/fMndnW3Xv35x4EDx89fvJ0fuHZvjO55bDHjTT2MGIOpNCwhwIlHGYWmIokHEQnH+rzgzOwThi9i0UGA8WGWiSCM/Suo1AxTDmT5U51PL/YXeqOhN5UehNlkUxk+3hhVoex4bkCjVwy50pmUXAJVRDmDjLGT9gQjhAu8FzEmG70u1x1ajMFMUxxY9nbg3IIRgHaohFVMuVcoaKKtusOXSOjhVNtBjWkPpsGKUfE+BPvimlirP800pF3WpmO/2OqpqaqPdYlrtmfQ8VsYeOmN2GaF5G5aDKQY/JmUAqd5Qiaj7tKcknR0HokNBYWOMqCMs49lzlD3zRPmWUc/eiCIBzFljsijj3F6bEfqzSnuciVV5ViOvbdjeS/ysaCcSv86K4XDdMiS0FnoJnEojeeftDe+vpl9x3dkSIGR1/T/mqHfv+4VWvdDt02zsd6Y3ktaF/nBdAYOeKlHWo45+Omy/ASrImFyyQr3InIXFW2gzaloQP/kPUQ0zJkkTmDa5iqXMmwugGLQJrzBqw/DdbIlhqLt2AbKa+wXY+t78GyDE0ZamMVk05cQjXlPlc4/1alvB2SGIPaIPwrmd/Q3t/7eFPZ7y/11pZWv60sbr6d7OoceUFeklekR9bJJvlEtske4cSQH+Qn+dVaaK233rc2x9A7M5OY56Qhrc9/ACoOjfs=</latexit>S
META-CLASSIFIER  GENERATOR
<latexit sha1_base64="l9yRR6waelDBNTPAfcWwHHdL97o=">AAAEj3icnVNLb9QwEHbbBUp4tXDkYlGtxGGpstsXIBVVQhS4QKFPqVmtHGeyserYqT1pm0b5GVzhd/FvcHZXakOXHhgpysz4m4e/8YSZFBZ9//fM7Fzrzt178/e9Bw8fPX6ysPj0wOrccNjnWmpzFDILUijYR4ESjjIDLA0lHIYn7+vzwzMwVmi1h0UG/ZQNlYgFZ+hcx0HKMOFMlh+rwcKSv+yPhN5UuhNliUxkZ7A4p4JI8zwFhVwya0tmUHAJlRfkFjLGT9gQjhEu8FxEmGz2fJ52ajMBMUxwc8XZ/XIIOgU0RSOqZKm1RRpWtF13aBsZDZwq3a8h9dk0SDkixp04V0RjbdynkI6808p03B+TdGqq2mNsbJv9WUyZKUzU9MZM8SLUF00Gcoxf90uhshxB8XFXcS4palqPhEbCAEdZUMa54zJn6JrmCTOMoxud5wWj2HJXRJGjOBm4sUp9mos8dWqaMhW57kbyX2UjwbgRbnTXiwZJkSWgMlBMYtEdT99rb3/9sveW7koRgaWvaG+tQ79/2K41v0N3tHWxzlhZ99rXeQHUWo54aQcKzvm46TK4BKMjYTPJCnsiMluVba9NaWDBPWQ1xKQMWKjP4BqmKlczrG7AQpD6vAHrTYM1siXa4C3YRsorrO+w9T1YlqEuA6VNyqQVl1BNuc8Vzr1VKW+HxFqj0gj/SuY2tPv3Pt5UDnrL3fXltW+rS1tvJrs6T56TF+Ql6ZINskU+kR2yTzjR5Af5SX61FlsbrXetrTF0dmYS84w0pPX5D/hnje8=</latexit>GAUXILLIARY INFORMATION + METADATA + …
NOVEL ITEMS MADE AVAILABLE  AT INFERENCE TIMEMETA-CLASSIFIER OF NOVEL ITEM
CLASSIFIER SELECTOR<latexit sha1_base64="D3JMKSFRXOXtjU8PaKr5MYgwi1s=">AAAEj3icnVNLb9QwEHbpAiW8WjhysahW4rBUu9sXIBVVQlRwgUKfUrOqHGeysepHak/aplF+Blf4XfwbnN2V2tClB0aKMjP+5uFvPFEmhcNu9/fMndnW3Xv35x4EDx89fvJ0fuHZvjO55bDHjTT2MGIOpNCwhwIlHGYWmIokHEQnH+rzgzOwThi9i0UGA8WGWiSCM/Suo1AxTDmT5U51PL/YXeqOhN5UehNlkUxk+3hhVoex4bkCjVwy50pmUXAJVRDmDjLGT9gQjhAu8FzEmG70u1x1ajMFMUxxY9nbg3IIRgHaohFVMuVcoaKKtusOXSOjhVNtBjWkPpsGKUfE+BPvimlirP800pF3WpmO/2OqpqaqPdYlrtmfQ8VsYeOmN2GaF5G5aDKQY/JmUAqd5Qiaj7tKcknR0HokNBYWOMqCMs49lzlD3zRPmWUc/eiCIBzFljsijj3F6bEfqzSnuciVV5ViOvbdjeS/ysaCcSv86K4XDdMiS0FnoJnEojeeftDe+vpl9x3dkSIGR1/T/mqHfv+4VWvdDt02zsd6Y3ktaF/nBdAYOeKlHWo45+Omy/ASrImFyyQr3InIXFW2gzaloQP/kPUQ0zJkkTmDa5iqXMmwugGLQJrzBqw/DdbIlhqLt2AbKa+wXY+t78GyDE0ZamMVk05cQjXlPlc4/1alvB2SGIPaIPwrmd/Q3t/7eFPZ7y/11pZWv60sbr6d7OoceUFeklekR9bJJvlEtske4cSQH+Qn+dVaaK233rc2x9A7M5OY56Qhrc9/ACoOjfs=</latexit>S
META-CLASSIFIER GENERATOR<latexit sha1_base64="l9yRR6waelDBNTPAfcWwHHdL97o=">AAAEj3icnVNLb9QwEHbbBUp4tXDkYlGtxGGpstsXIBVVQhS4QKFPqVmtHGeyserYqT1pm0b5GVzhd/FvcHZXakOXHhgpysz4m4e/8YSZFBZ9//fM7Fzrzt178/e9Bw8fPX6ysPj0wOrccNjnWmpzFDILUijYR4ESjjIDLA0lHIYn7+vzwzMwVmi1h0UG/ZQNlYgFZ+hcx0HKMOFMlh+rwcKSv+yPhN5UuhNliUxkZ7A4p4JI8zwFhVwya0tmUHAJlRfkFjLGT9gQjhEu8FxEmGz2fJ52ajMBMUxwc8XZ/XIIOgU0RSOqZKm1RRpWtF13aBsZDZwq3a8h9dk0SDkixp04V0RjbdynkI6808p03B+TdGqq2mNsbJv9WUyZKUzU9MZM8SLUF00Gcoxf90uhshxB8XFXcS4palqPhEbCAEdZUMa54zJn6JrmCTOMoxud5wWj2HJXRJGjOBm4sUp9mos8dWqaMhW57kbyX2UjwbgRbnTXiwZJkSWgMlBMYtEdT99rb3/9sveW7koRgaWvaG+tQ79/2K41v0N3tHWxzlhZ99rXeQHUWo54aQcKzvm46TK4BKMjYTPJCnsiMluVba9NaWDBPWQ1xKQMWKjP4BqmKlczrG7AQpD6vAHrTYM1siXa4C3YRsorrO+w9T1YlqEuA6VNyqQVl1BNuc8Vzr1VKW+HxFqj0gj/SuY2tPv3Pt5UDnrL3fXltW+rS1tvJrs6T56TF+Ql6ZINskU+kR2yTzjR5Af5SX61FlsbrXetrTF0dmYS84w0pPX5D/hnje8=</latexit>GAUXILLIARY INFORMATION + METADATA + …NOVEL ITEMS MADE AVAILABLE AT INFERENCE TIMEMETA-CLASSIFIER OF NOVEL ITEM
BASE EXTREME CLASSIFIER 
LEARNT CLASSIFIERS<latexit sha1_base64="wWwImdIigkUEz0hUVSI9l9PU0Zo=">AAAEjnicnVNZb9QwEHbbBUq4WnjkxaJaiYel2t0eHFJFJUTVJyj0FGRVOc5kY9VHak/aplH+Ba/wv/g3OLsrtaFLHxgpysz4m8PfeKJMCofd7u+Z2bnWnbv35u8HDx4+evxkYfHpgTO55bDPjTT2KGIOpNCwjwIlHGUWmIokHEYnH+rzwzOwThi9h0UGA8WGWiSCM/Sub6FimEZReVgdLyx1l7sjoTeV3kRZIhPZOV6c02FseK5AI5fMuZJZFFxCFYS5g4zxEzaE7wgXeC5iTDf6Xa46tZmCGKa4seLtQTkEowBt0YgqmXKuUFFF23WDrpHRwqk2gxpSn02DlCNe/Il3xTQx1n8a6cg7rUzH/zFVU1PVHusS1+zPoWK2sHHTmzDNi8hcNBnIMXkzKIXOcgTNx10luaRoaD0RGgsLHGVBGeeey5yhb5qnzDKOfnJBEI5iy10Rx57i9NhPVZrTXOTKq0oxHfvuRvJfZWPBuBV+dNeLhmmRpaAz0Exi0RtPP2hvff60947uShGDo69of61Dv37cqrVuh+4Y52O9sbIetK/zAmiMHPHSDjWc83HTZXgJ1sTCZZIV7kRkrirbQZvS0IF/x3qIaRmyyJzBNUxVrmZY3YBFIM15A9afBmtkS43FW7CNlFfYrsfW92BZhqYMtbGKSScuoZpynyucf6tS3g5JjEFtEP6VzG9o7+99vKkc9Jd768trX1aXNt9OdnWePCcvyEvSI6/JJtkmO2SfcKLJD/KT/GottNZbG633Y+jszCTmGWlIa/sPUOqNiQ==</latexit>W
LEARNT ENCODER
<latexit sha1_base64="8jd+0BBFEqTLtCRWVMGmV4U6wtA=">AAAEj3icnVNLb9QwEHbbBUp4tXDkYlGtxGGpdrcvQCqqhFrBBQp9Ss2qcpzJxlrHTu1J2zTKz+AKv4t/g5NdqQ1demCkKDPjbx7+xhOkUljsdn/PzM617t1/MP/Qe/T4ydNnC4vPD63ODIcDrqU2xwGzIIWCAxQo4Tg1wJJAwlEw+lidH52DsUKrfcxTGCRsqEQkOEPnOvEThrHlptguTxeWusvdWuhtpTdRlshEdk8X55Qfap4loJBLZm3BDAouofT8zELK+IgN4QThEi9EiPFmv8uTTmXGIIYxbq44e1AMQSeAJm9EFSyxNk+CkrbrDhsZDZwpPagg1dk0SFET406cK6SRNu5TSGvvtDId98c4mZqq8hgb2WZ/FhNmchM2vRFTPA/0ZZOBDKO3g0KoNENQfNxVlEmKmlYjoaEwwFHmlHHuuMwYuqZ5zAzj6EbneX4dW+yJMHQUx6durFKfZSJLnJokTIWuu1r+q2woGDfCje5mUT/O0xhUCopJzHvj6Xvtna9f9t/TPSlCsPQN7a916PftnUrrduiuti7WGSvrXvsmL4Bay5qXtq/ggo+bLvwrMDoUNpUstyOR2rJoe21KfQvuIashxoXPAn0ONzBlsZpieQsWgNQXDVh/GqyRLdYG78A2Ul5juw5b3YOlKerCV9okTFpxBeWU+1zj3FuV8m5IpDUqjfCvZG5De3/v423lsL/cW19e+7a6tPVusqvz5CV5RV6THtkgW+QT2SUHhBNNfpCf5FdrsbXR+tDaGkNnZyYxL0hDWp//AFO0jgU=</latexit>EFigure 1: An overview of our proposed Extre MeMETa-
classifica Tion (EMMETT) framework. Given an extreme
classification base (encoder Eand classifiers W), EMMETT
consists of two modules, where (a) the classifier selector Sre-
trieves the most informative classifiers for a novel item, and
(b) the meta-classifier generator Gcombines the selected
classifiers and other meta-data to create the meta-classifier.
of samples for optimally training the EMMETT modules. With a
careful loss design, each observed item can be treated as a proxy for
a zero-shot item which yields a massive training set for zero-shot
retrieval. Training EMMETT on such a dataset can ensure robust
generalization on novel items. We theoretically and empirically
validate this claim in Sections 5and7, respectively.
Figure 1presents the architectural overview of EMMETT. EM-
METT is a generic framework where different choices for the two
modules and the training strategy can potentially yield algorithms
with varying accuracy and efficiency trade-offs, which also presents
ample opportunities for future research explorations.
In this paper, we develop one such algorithmic instantiation of
the EMMETT framework, named IRENE, for Improved REtrieval
ofNovel it Ems. Given a generic Siamese encoder augmented with
extreme classifiers on observed items, IRENE is designed to add
meta-classifier functionality to this base with minimal effort. The
IRENE selects the classifiers associated with observed items by
means of an efficient ANNS-search. The item representations are
derived from the base Siamese encoder itself. This avoids training
an additional module thus reducing the training and deployment
efforts, but can also add noisy classifiers to the shortlist. To effec-
tively filter the noise, combine the useful knowledge and synthesize
meta-classifiers, IRENE trains a separate meta-classifier generator
model that is based on a transformer architecture. Given the short-
list of the selected classifiers, the meta-classifier synthesis is highly
efficient, requiring a forward pass over the single-layer transformer
(cf. Section 7). IRENE training freezes the Siamese encoder and
extreme classifiers, and only trains the generator using a weighted
one-vs-all classification loss. Both novel item representation and re-
trieval are real-time and require few milliseconds in IRENE. Figure
2depicts the IRENE architecture.
3658Extreme Meta-Classification for Large-Scale Zero-Shot Retrieval KDD ’24, August 25–29, 2024, Barcelona, Spain
Theoretical analysis is a crucial tool which can guide the design
of robust and effective machine learning systems. For this purpose,
we develop a novel theoretical framework for analyzing the gener-
alization performance in large-scale zero-shot retrieval. It is based
on a key insight that, given a dense retriever that outputs calibrated
query-item relevance scores, the zero-shot retrieval task is equiv-
alent to a binary classification task with a query-item pair as our
data sample. This equivalence allows us to leverage and further
extend the theoretical ideas from traditional binary classification
literature. Our results in Section 5show that (1) One-vs-All loss
in IRENE leads to strong zero-shot generalization performance by
reducing the variance in the training loss, (2) Freezing extreme clas-
sifiers during IRENE avoids overfitting and is therefore crucial for
robust zero-shot generalization, (3) Number of observed items and
the Generator’s complexity also affect the zero-shot generalization.
These results are also validated empirically in Section 7.
In summary, this paper makes the following key contributions:
(1)Anovel and generic algorithmic framework , EMMETT, for
learning accurate representations of novel items, thus improv-
ing the zero-shot retrieval performance.
(2)Anovel and efficient algorithm , IRENE, that can be added
to any Siamese encoder and is well-suited for large-scale real-
world applications.
(3)Anovel theoretical framework for analyzing the generaliza-
tion performance in large-scale zero-shot retrieval.
(4)Comprehensive experimental validation demonstrating that
IRENE can offer up to 15%gains in terms of Recall @10 with
minimal overheads, in zero-shot retrieval on diverse (varying
in their scale and application) benchmark datasets.
(5)Online A/B tests on a large-scale Sponsored Search application
in a major search engine which shows that IRENE can improve
ad click rate by 4%thereby demonstrating its real-world utility.
The source code for IRENE in available at https://aka.ms/irene.
The project page is https://aka.ms/emmett.
2 Related Work
This section provides a comprehensive review of the past literature
that is pertinant to our work. It presents the different classes of
approaches available for retrieval and highlights their scalability,
accuracy and zero-shot capabilities.
Traditional statistical approaches: Traditional approaches to
large-scale retrieval, including TF-IDF [ 19] and BM25 [ 30], relied
on measuring the co-occurrences of terms in a query text and an
item text. These methods utilized inverted term indices for efficient
item search which scaled well and allowed rapid insertion of novel
items. However, they lacked the ability to understand the context of
the inputs. ZestXML [ 14], a recent method for large-scale zero-shot
retrieval, extended the term-matching to also account for seman-
tic correlations between the terms which improved the retrieval
performance. Nevertheless, these traditional methods have been
largely superseded by semantic matching techniques using deep
networks, which offer superior accuracy.
Siamese-encoder approaches: These approaches employ deep
neural encoders to embed both query and item texts into a shared,
low-dimensional representation space. Leading approaches such as
DPR [ 20], ANCE [ 40], MACLR [ 41], RocketQA [ 29] and NGAME [ 10],utilize a transformer-based encoder. ANCE, RocketQA and NGAME
also implement advanced negative-mining strategies for robust en-
coder training. MACLR leverages self-supervised learning based
on an inverse cloze task for pre-training. In these approaches, in-
corporating a novel item is efficient and requires just a single en-
coder pass over their raw features. However, to maintain real-time
response rates, these methods are constrained to use a small trans-
former, which degrades retrieval accuracy due to lack of world
knowledge necessary for large-scale retrieval. Recent works like
ColBERT [ 23] and Semsup-XC [ 1] modify the Siamese architecture
to permit token-level interactions between the query and item texts
which improves retrieval accuracy. However, this enhancement
also increases inference latency, making these models less suitable
for practical deployments. Semsup-XC also relies on web-scraped
meta-data to boost zero-shot performance, which can be expensive.
Extreme classification approaches : These approaches learn one-
vs-all classifiers to represent each observed item in the training
set [ 11,12,15,16,22,25,27,32,44]. These are highly accurate,
offer low inference latencies and have been successfully applied
to a wide range of large-scale retrieval tasks including document
tagging [ 4], product-to-product recommendation [ 18,21], and spon-
sored search [ 9,10]. Unfortunately, most of these approaches do
not have support for zero-shot items.
Among these, the most relevant to our work is DEXA [ 12]. DEXA
learns a small set of classifiers, one classifier per cluster of items to
improve the retrieval performance. DEXA can be viewed as a naive
version of EMMETT with an inferior architecture and training loss,
and is significantly outperformed by IRENE (see Section 6).
Other zero-shot retrieval approaches: Several approaches have
been proposed for zero-shot multi-label retrieval such as ESZSL [ 31],
COSTA [ 26], LAF [ 24]etc.These works consider a few thousand
labels (items) and typically do not scale to million items.
Over the past year, large language model based zero-shot re-
trieval is also gaining popularity [ 33]. These models are expensive
and are not yet demonstrated for large-scale retrieval.
The works in [ 13,39] study a different zero-shot setting where
the task itself is novel with no available relevance signals for model
training. They propose techniques based on domain transfer as so-
lutions. Unlike these works, our setting assumes that abundant click
data is available as relevance signals and focusses on leveraging
them to improve the retrieval with zero-shot items.
3 Extreme Meta-classification
In this section, we introduce EMMETT , our proposed Extre Me
METa-classifica Tion framework for improving zero-shot retrieval
by means of incorporating the knowledge present in the learnt
classifiers of observed items.
3.1 Preliminaries
We describe the notation and background that is necessary for
the rest of this section. Consider queries Xdrawn from the space
X, which are mapped to items Zdrawn from the item space Z.
During training, we have access to Ndata points{Xi}N
i=1andL
observed items{Zℓ}L
ℓ=1. Each data-item pair is associated with a
labelyiℓ={0,1}, which is 1 when the item is relevant to the input
query, and 0 when the item is irrelevant to the query.
3659KDD ’24, August 25–29, 2024, Barcelona, Spain Sachin Yadav et al.
Dense retrieval (DR) algorithms consider a deep feature encoder E
that projects the data samples and items to the space of d-dimensional
encoder representations, denoted as x=E(X)andz=E(Z),
respectively, both E(Z),E(X)belonging to Rd. The query and
observed-item sets in this encoder space are represented as X=
{xi}N
i=1, andZ={zℓ}L
ℓ=1, respectively. In Siamese DR algorithms,
both query and item representations share the same encoder space.
Items are retrieved for a given query, typically using approximate
nearest neighbor search (ANNS), based on the similarity score x⊤
izℓ.
Extreme classification (XC) algorithms are built on the intuition
that classifier-based item representations can surpass the perfor-
mance of encoder-representations. In XC, each item zℓis repre-
sented by a 1-vs-all classifier wℓ, collectively denoted as W=
{wℓ}L
ℓ=1. These are trained using triplet-based [ 10] or cross-entropy-
based [ 17] losses atop the encoder representation. The similarity
score is calculated between the query representation and the classi-
fiers (x⊤
iwℓ). Thus, the XC module comprises an encoder and a set
of learned classifiers (E,W). While effective in retrieving observed
items, these methods face challenges in retrieving novel items.
3.2 The EMMETT Framework
We propose EMMETT, an extreme meta-classification frame-
work for zero-shot generalization in the retrieval setting. The EM-
METT framework is designed to develop highly accurate and effi-
cient retrieval models capable of handling novel item retrieval dur-
ing inference. Existing XC models, despite their accuracy through
classifier-based approaches built atop encoder representations, suf-
fer from high data and resource requirement and therefore, and do
not generalize to the zero-shot setting.
The EMMETT framework considers training data XandZ, a
base extreme classifier (E,W), comprising the encoder Eand
observed-item classifiers W, and a set of novel items Zn={zℓ}Ln
ℓ=1
made available at inference time, EMMETT includes two modules:
•Classifier Selector S: This module selects the most informative
set of classifiers from the base XC model for a novel item z∈Zn
introduced at inference time.
•Meta-classifier Generator G: This module combines the clas-
sifiers selected by S, and other auxiliary information (such as
the encoder representation z) to create the meta classifier uasso-
ciated with item z.
EMMETT offers flexibility in its implementation through a vari-
ety of design choices, such as the, base XC framework, choice of
encoder architecture and training methods. The classifier selector’s
Sdesign involves choosing a selection algorithm and determining
the number of classifiers to select. An ideal selection algorithm
should choose informative classifiers, taking into account factors
such as named entities, numbers, ambiguous phrases, synonyms, etc.
Since the task of classifier selection can be viewed as retrieval, any
existing retrieval methods can be used. In the context of EMMETT
we prioritize efficient classifier selection and quick incorporation
of novel items. The generator’s Gdesign must take into considera-
tion model complexity (which we discuss in Section 5), ensuring it
effectively incorporates the selected classifiers and potential auxil-
iary data to learn the meta-classifier uwithout overfitting. Another
component of EMMETT is in designing loss functions for towardszero-shot generalization, and choosing appropriate training strate-
gies, such as end-to-end, modular, etc.
Figure 1 provides a visual illustration of these three components.
EMMETT enables interpreting existing XC models’ zero-shot gen-
eralizability. For example, in DEXA [ 12], given a novel item, its
classifier can be selected based on cluster assignment, and then
summed with its encoder representation. Similarly, in NGAME [ 10],
the classifier selector is an indicator function, which returns a clas-
sifier only for the observed items. NGAME’s decision tree, along
with its encoder representation and classifier, can be viewed as its
generator block. DEXA’s and NGAME’s relatively poorer zero-shot
generalization can be attributed to their simplistic SandGarchi-
tectures. An additional reason why these models perform poorly
on novel items can traced back to their loss functions, which are
not tailored for zero-shot performance.
In Section 4, we present IRENE, a specific instance of EMMETT
designed for zero-shot generalization. This includes a thoughtful
design of classifier selector and generator modules, considering
training strategies, deployment ease, new item incorporation at
inference, and loss functions prioritizing zero-shot performance.
Theoretical analysis of IRENE’s effectiveness is detailed in Sec-
tion 5.
4 The IRENE Extreme Meta-Classifier
We now present the IRENE algorithm, our proposed approach for
Improved REtrieval of Novel it Ems with extreme meta-classification.
IRENE is adaptable to any XC framework. Specifically, we utilize
a 6-layer DistilBERT encoder, trained with state-of-the-art, com-
putationally efficient algorithms such as NGAME [ 10], ANCE [ 40],
MACLR [ 41], and DPR [ 20]. Given a real-world application such
as product-to-product recommendations, document tagging, or
matching user queries to advertiser keywords appropriate feature
encoders may be chosen. After training, the encoder Eand the
observed-item classifiers Wremain fixed through subsequent stages.
The learnt classifiers are accessible via a lookup function Clfbased
on the items’ encoder representations, i.e.,wℓ=Clf(zℓ).
The classifier selector S, for any item zℓ, either observed or
novel, retrieves Kclassifiers of related items using an ANNS index
built on the item representations E(Zs), served via approaches
such as DiskANN [ 36]. The selection is based on a maximum inner
product search (MIPS) between the novel item, and observed items
arg maxK{z⊤
ℓzo;∀zo∈Z}. The complexity of these approaches
has typically been shown to be logarithmic in the number of items,
i.e.,O(logL). The choice of K, a key hyper-parameter, balances
model capacity and complexity, which we formalize in Section 5
and validate in Section 7. Empirically, we found K≈3to work well.
The meta-classifier generator Gϕϕϕis based on a transformer ar-
chitecture, inspired by their capability to be universal approxima-
tors [ 43] and their success in learning embeddings in few-shot
scenarios [ 42]. While the transformer layers are capable of han-
dling a variety of input embeddings, in IRENE, the input sequence
consists of the selected classifiers and the novel item’s encoder rep-
resentation and is passed through self-attention and linear blocks.
In particular, the meta classifier is given by uℓ=Gϕϕϕ(zℓ,S(zℓ))
and each layer can be expressed as as:
Linear (Self-Attention (zℓ+tenc,w1
ℓ+tclf,w2
ℓ+tclf, . . . )),(1)
3660Extreme Meta-Classification for Large-Scale Zero-Shot Retrieval KDD ’24, August 25–29, 2024, Barcelona, Spain
2
ENCODER<latexit sha1_base64="8jd+0BBFEqTLtCRWVMGmV4U6wtA=">AAAEj3icnVNLb9QwEHbbBUp4tXDkYlGtxGGpdrcvQCqqhFrBBQp9Ss2qcpzJxlrHTu1J2zTKz+AKv4t/g5NdqQ1demCkKDPjbx7+xhOkUljsdn/PzM617t1/MP/Qe/T4ydNnC4vPD63ODIcDrqU2xwGzIIWCAxQo4Tg1wJJAwlEw+lidH52DsUKrfcxTGCRsqEQkOEPnOvEThrHlptguTxeWusvdWuhtpTdRlshEdk8X55Qfap4loJBLZm3BDAouofT8zELK+IgN4QThEi9EiPFmv8uTTmXGIIYxbq44e1AMQSeAJm9EFSyxNk+CkrbrDhsZDZwpPagg1dk0SFET406cK6SRNu5TSGvvtDId98c4mZqq8hgb2WZ/FhNmchM2vRFTPA/0ZZOBDKO3g0KoNENQfNxVlEmKmlYjoaEwwFHmlHHuuMwYuqZ5zAzj6EbneX4dW+yJMHQUx6durFKfZSJLnJokTIWuu1r+q2woGDfCje5mUT/O0xhUCopJzHvj6Xvtna9f9t/TPSlCsPQN7a916PftnUrrduiuti7WGSvrXvsmL4Bay5qXtq/ggo+bLvwrMDoUNpUstyOR2rJoe21KfQvuIashxoXPAn0ONzBlsZpieQsWgNQXDVh/GqyRLdYG78A2Ul5juw5b3YOlKerCV9okTFpxBeWU+1zj3FuV8m5IpDUqjfCvZG5De3/v423lsL/cW19e+7a6tPVusqvz5CV5RV6THtkgW+QT2SUHhBNNfpCf5FdrsbXR+tDaGkNnZyYxL0hDWp//AFO0jgU=</latexit>E
<latexit sha1_base64="W75NzjTU//i9mWmbuDJM2V7fQRc=">AAAEkHicnVNLb9NAEN62AUp4teXIZUUViUOonPRBQaooQlSIAxT6lHAUrdeTeNV9uLvjtq7lv8EV/hb/hnUSqTUNPTCS5ZnZbx77zU6USuEwCH7PzM417ty9N3+/+eDho8dPFhaXDp3JLIcDbqSxxxFzIIWGAxQo4Ti1wFQk4Sg6eV+dH52BdcLofcxT6Ck21GIgOEPvCsMijFRxUfZFWPYXloOVYCT0ptKZKMtkIrv9xTkdxoZnCjRyyZwrmEXBJZTNMHOQMn7ChvAd4QLPRYzJVjfgql2ZCYhhglur3u4VQzAK0Oa1qIIp53IVlbSlGCaultHCqTa9ClKdTYMUI2b8iXfFdGCs/zTSkXdambb/Y6Kmpqo81g1cvT+HitncxnXvgGmeR+aizkCGg81eIXSaIWg+7mqQSYqGVjOhsbDAUeaUce65zBj6pnnCLOPoZ9dshqPYYk/Esac46fu5SnOaiUx5VSmmY9/dSP6rbCwYt8KP7nrRMMnTBHQKmknMO+PpN1s7Xz7vv6F7UsTg6EvaXW/Tbx92Ki1o013jfKw3Vjeareu8ABojR7y0Qg3nfNx0EV6CNbFwqWS5OxGpK4tWs0Vp6MC/ZD3EpAhZZM7gGqYs1lIsb8AikOa8ButOg9WyJcbiLdhayits4LHVPViaoilCbaxi0olLKKfc5wrn36qUt0MGxqA2CP9K5je08/c+3lQOuyudjZX1r2vL268nuzpPnpHn5AXpkFdkm3wku+SAcJKSH+Qn+dVYamw23jbejaGzM5OYp6QmjU9/ALIEjpc=</latexit>{xi}
<latexit sha1_base64="TZ0sMw6r5rvk2KOSBIZT99ShK4I=">AAAElXicnVNLb9NAEN62gZbwaAsHDlxWVJE4hCpJHzykSpWAihMt9CnhKFqvx/Gq+3B3x21dy7+EK/wo/g3rJFJrGnpgJMszs9889pudMJXCYafze2Z2rnHv/vzCg+bDR4+fLC4tPz1yJrMcDrmRxp6EzIEUGg5RoIST1AJToYTj8PRDdX58DtYJow8wT6Gv2FCLWHCG3jVYWgyKIFTFVTkIQMqgHCytdFY7I6G3le5EWSET2Rssz+kgMjxToJFL5lzBLAouoWwGmYOU8VM2hO8Il3ghIky2eh2u2pWZgBgmuLXm7X4xBKMAbV6LKphyLldhSVuKYeJqGS2cadOvINXZNEgxosefeFdEY2P9p5GOvNPKtP0fEzU1VeWxLnb1/hwqZnMb1b0x0zwPzWWdgQzjt/1C6DRD0HzcVZxJioZWg6GRsMBR5pRx7rnMGPqmecIs4+gH2GwGo9hiX0SRpzgZ+OFKc5aJTHlVKaYj391I/qtsJBi3wo/uZtEgydMEdAqaScy74+k3Wzu7Xw7e030pInD0Ne1ttOm3TzuV1mnTPeN8rDfWNputm7wAGiNHvLQCDRd83HQRXIE1kXCpZLk7Fakri1azRWngwD9nPcSkCFhozuEGpizWUyxvwUKQ5qIG602D1bIlxuId2FrKa2zHY6t7sDRFUwTaWMWkE1dQTrnPNc6/VSnvhsTGoDYI/0rmN7T79z7eVo56q93N1Y2v6yvb7ya7ukBekJfkFemSN2SbfCZ75JBwkpEf5Cf51Xje2Gp8bOyMobMzk5hnpCaN3T/xgJAY</latexit>{z }EXTREME CLASSIFIER BASE<latexit sha1_base64="+z5Q57CJaHMdsotAULmv0FEdodU=">AAAEnnicnVPbbtQwEHXbBcpy28ILEi8W1UpFWqrs9sJFqlQJteIFWuhVIquV48xurDp2ak/aplH4Gl7hf/gbnOxKbejSB0aKcmZ85uIZT5BIYdHzfs/MzjXu3L03f7/54OGjx09aC08PrU4NhwOupTbHAbMghYIDFCjhODHA4kDCUXDyoTw/OgNjhVb7mCXQj9lIiaHgDJ1p0Hq+5McMI8tNvlV0KhwE+VHxatBa9Ja9SuhN0J2ARTKR3cHCnPJDzdMYFHLJrM2ZQcElFE0/tZAwfsJG8A3hAs9FiNFGz+Nxp1QjEKMIN1ac3s9HoGNAk9W8chZbm8VBQdtVtbWIBk6V7peU8mwaJa/65E6cKaRDbdynkFbWaWk67o9RPDVUaTF2aOv1WYyZyUxYtw6Z4lmgL+odSHH4tp8LlaQIio+rGqaSoqblhGgoDHCUGWWcu16mDF3RPGKGcXSTbDb9yjffE2HoWhwN3JSlPk1FGjsYx0yFrrpK/ittKBg3wo3uelI/ypIIVAKKScy64+k329s7n/ff0z0pQrD0Ne2tdejXre0SeR26q63zdcrKerN9vS+AWsuqL21fwTkfF537l2B0KGwiWWZPRGKLvN1sU+pbcO9ajTDKfRboM7jGKfLVBIsbtACkPq/RetNotWiRNngLtxbyius5bnkPliSoc19pEzNpxSUUU+5zxXNvVcrbKUOtUWmEfwVzG9r9ex9vgsPecnd9ee3L6uLmu8muzpMX5CVZIl3yhmySj2SXHBBOvpMf5Cf51aCN7canxs6YOjsz8XlGatI4/gNjb5NO</latexit>(E,W)OBSERVED QUERIESOBSERVED ITEMSOBSERVED-ITEM CLASSIFIER SET
<latexit sha1_base64="qrxvk2DBCbPJ5mc8ozN7L8rvXp0=">AAAEmnicnVPbbtNAEN22AYq5pcAbPKyoIvEQKie9cJEqVSAqEBIUeouEo2i9nsSrrnfd3XFb1/K/8Ap/xN+wTiK1pqEPjGR5ZvbMZc/shKkUFn3/99z8QuPGzVuLt707d+/df9BcenhgdWY47HMttemFzIIUCvZRoIReaoAloYTD8OhddX54AsYKrfYwT6GfsJESQ8EZOteg+ThIGMZhWPRKukmDojcQQTloLvsr/ljoVaUzVZbJVHYGSwsqiDTPElDIJbO2YAYFl1B6QWYhZfyIjeA7whmeigjjza7Pk3ZlxiBGMW6uOrtfjEAngCavRRUssTZPwpK2qlZtLaOBY6X7FaQ6mwUpxhy5E+eK6FAb9ymkY++sMm33xziZmaryGDu09f4sJszkJqp7h0zxPNRndQYyHL7qF0KlGYLik66GmaSoaTUdGgkDHGVOGeeOy4yha5rHzDCOboqeF4xji10RRY7ieOAmLPVxJrLEqUnCVOS6G8t/lY0E40a40V0uGsR5GoNKQTGJeWcyfa+1/eXz3hu6K0UElr6g3fU2/fZ+u9L8Nt3R1sU6Y3XDa13mBVBrOealFSg45ZOmi+AcjI6ETSXL7ZFIbVm0vBalgQX3ptUI4yJgoT6BS5iyWEuxvAILQerTGqw7C1bLFmuD12BrKS+wvsNW92BpiroIlDYJk1acQznjPhc491alvB4y1BqVRvhXMrehnb/38apy0F3pbKysf11b3no93dVF8oQ8I89Jh7wkW+QD2SH7hJNz8oP8JL8aTxtvGx8bnybQ+blpzCNSk8beH4F6kWw=</latexit>X={Xi}
<latexit sha1_base64="+pZdXnKiqj8cTn2zH3w9YiQruIo=">AAAEn3icnVNLb9QwEHbpAiW8WjghLoZqJQ5Lld0+eEiVKiEKp7LQJyWrlePMbqw6dmpP2qZRxK/hCr+Hf4Ozu1IbuvTASFFmxt88/I0nTKWw6Pu/Z27MNm7euj13x7t77/6Dh/MLj/aszgyHXa6lNgchsyCFgl0UKOEgNcCSUMJ+ePSuOt8/AWOFVjuYp9BL2FCJgeAMnas//yRIGMZhWByWfU3XaVAc9gOQMij784v+kj8SelVpT5RFMpFuf2FWBZHmWQIKuWTWFsyg4BJKL8gspIwfsSF8QzjDUxFhvN7xedKqzBjEMMb1ZWf3iiHoBNDktaiCJdbmSVjSZtWvrWU0cKx0r4JUZ9MgxYgod+JcER1o4z6FdOSdVqbl/hgnU1NVHmMHtt6fxYSZ3ER174Apnof6rM5AhoPXvUKoNENQfNzVIJMUNa1GRCNhgKPMKePccZkxdE3zmBnG0Y3S84JRbLEtoshRHPfdmKU+zkSWODVJmIpcdyP5r7KRYNwIN7rLRYM4T2NQKSgmMW+Pp+81Nz9t7byl21JEYOlL2llt0S/vNyvNb9Guti7WGctrXvMyL4BayxEvzUDBKR83XQTnYHQkbCpZbo9Easui6TUpDSy4h62GGBcBC/UJXMKUxUqK5RVYCFKf1mCdabBatlgbvAZbS3mB9R22ugdLU9RFoLRJmLTiHMop97nAubcq5fWQgdaoNMK/krkNbf+9j1eVvc5Se21p9fPK4sabya7OkafkOXlB2uQV2SAfSZfsEk6+kx/kJ/nVeNb40NhqdMfQGzOTmMekJo2vfwC9hZOg</latexit>Zo={Z }<latexit sha1_base64="s3G8fdJDjUK1j+dKV3JYdWxRrIQ=">AAAEonicnVNLb9NAEN62AUp4pXCEw4oSiUOokvTBQ6pUCVEhDtDSp4SjaL2exKvuw90dN3UtX/g1XOHf8G9YJ5Fa09ADI1memf3msd/shIkUDtvt33PzC7Vbt+8s3q3fu//g4aPG0uNDZ1LL4YAbaexxyBxIoeEABUo4TiwwFUo4Ck/el+dHZ2CdMHofswR6ig21GAjO0Lv6jWeBYhiHYX5U0E0a5EGo8lHRD0DKoOg3ltsr7bHQ60pnqiyTqez0lxZ0EBmeKtDIJXMuZxYFl1DUg9RBwvgJG8I3hHMciQjjzW6bq1ZpxiCGMW6ueruXD8EoQJtVonKmnMtUWNBm2bKrZLRwqk2vhJRnsyD5mCt/4l0RHRjrP4107J1VpuX/GKuZqUqPdQNX7c+hYjazUdU7YJpnoTmvMpDi4E0vFzpJETSfdDVIJUVDyynRSFjgKDPKOPdcpgx90zxmlnH006zXg3FsvieiyFMc9/2kpTlNRaq8qhTTke9uLP9VNhKMW+FHd7VoEGdJDDoBzSRmncn0683tL5/339E9KSJw9BXtrrfo1w/bpdZu0R3jfKw3Vjfqzau8ABojx7w0Aw0jPmk6Dy7Amki4RLLMnYjEFXmz3qQ0cODfth5inAcsNGdwBVPkawkW12AhSDOqwLqzYJVssbF4A7aS8hLb9tjyHixJ0OSBNlYx6cQFFDPuc4nzb1XKmyEDY1AbhH8l8xva+XsfryuH3ZXOxsr67try1tvpri6Sp+Q5eUk65DXZIh/JDjkgnHwnP8hP8qv2ovaptlvbm0Dn56YxT0hFasEfPmWVLQ==</latexit>W={w }
SELF-ATTENTION LAYER
LINEAR LAYERMETA-CLASSIFIER GENERATOR<latexit sha1_base64="l9yRR6waelDBNTPAfcWwHHdL97o=">AAAEj3icnVNLb9QwEHbbBUp4tXDkYlGtxGGpstsXIBVVQhS4QKFPqVmtHGeyserYqT1pm0b5GVzhd/FvcHZXakOXHhgpysz4m4e/8YSZFBZ9//fM7Fzrzt178/e9Bw8fPX6ysPj0wOrccNjnWmpzFDILUijYR4ESjjIDLA0lHIYn7+vzwzMwVmi1h0UG/ZQNlYgFZ+hcx0HKMOFMlh+rwcKSv+yPhN5UuhNliUxkZ7A4p4JI8zwFhVwya0tmUHAJlRfkFjLGT9gQjhEu8FxEmGz2fJ52ajMBMUxwc8XZ/XIIOgU0RSOqZKm1RRpWtF13aBsZDZwq3a8h9dk0SDkixp04V0RjbdynkI6808p03B+TdGqq2mNsbJv9WUyZKUzU9MZM8SLUF00Gcoxf90uhshxB8XFXcS4palqPhEbCAEdZUMa54zJn6JrmCTOMoxud5wWj2HJXRJGjOBm4sUp9mos8dWqaMhW57kbyX2UjwbgRbnTXiwZJkSWgMlBMYtEdT99rb3/9sveW7koRgaWvaG+tQ79/2K41v0N3tHWxzlhZ99rXeQHUWo54aQcKzvm46TK4BKMjYTPJCnsiMluVba9NaWDBPWQ1xKQMWKjP4BqmKlczrG7AQpD6vAHrTYM1siXa4C3YRsorrO+w9T1YlqEuA6VNyqQVl1BNuc8Vzr1VKW+HxFqj0gj/SuY2tPv3Pt5UDnrL3fXltW+rS1tvJrs6T56TF+Ql6ZINskU+kR2yTzjR5Af5SX61FlsbrXetrTF0dmYS84w0pPX5D/hnje8=</latexit>G<latexit sha1_base64="ibGhoC5KywrEXU0h/Quh9yuFa20=">AAAEjnicnVNZb9NAEN62AYq5UnjkZUUViYdQJenBIVVUQlR9gkJPgaNovZ7Eq+7h7o7bupb/Ba/wv/g3rJNIrWnoAyNZnpn95thvdqJUCoedzu+5+YXGnbv3Fu8HDx4+evykufT00JnMcjjgRhp7HDEHUmg4QIESjlMLTEUSjqKTD9X50RlYJ4zexzyFvmIjLYaCM/Sub2GkiqwcFLocNJc7K52x0JtKd6osk6nsDpYWdBgbninQyCVzrmAWBZdQBmHmIGX8hI3gO8IFnosYk81eh6t2ZSYgRglurnq7X4zAKECb16IKppzLVVTSlmKYuFpGC6fa9CtIdTYLUox58SfeFdOhsf7TSMfeWWXa/o+Jmpmq8lg3dPX+HCpmcxvXvUOmeR6ZizoDGQ7f9Auh0wxB80lXw0xSNLSaCI2FBY4yp4xzz2XG0DfNE2YZRz+5IAjHscWeiGNPcTLwU5XmNBOZ8qpSTMe+u7H8V9lYMG6FH931omGSpwnoFDSTmHcn0w9a258/7b+je1LE4Ogr2ltv068ftyut06a7xvlYb6xuBK3rvAAaI8e8tEIN53zSdBFegjWxcKlkuTsRqSuLVtCiNHTg37EeYVKELDJncA1TFmspljdgEUhzXoP1ZsFq2RJj8RZsLeUVtuOx1T1YmqIpQm2sYtKJSyhn3OcK59+qlLdDhsagNgj/SuY3tPv3Pt5UDnsr3Y2V9S9ry1tvp7u6SJ6TF+Ql6ZLXZIvskF1yQDjR5Af5SX41mo2Nxmbj/QQ6PzeNeUZq0tj5A2qejc0=</latexit>unMETA-CLASSIFIER OF THE NOVEL ITEM
ENCODER
<latexit sha1_base64="tJ53AxhGh46KVe7jEth+40wVv7A=">AAAEh3icnVNLb9NAEN62AVrzauHIZUUViUMoSfqgIFUqQlScoNCnwFG0Xo/jVffh7o7bulZ+Alf4bfwb1kmk1jT0wEiWZ2a/eew3O1EmhcN2+/fM7Fzjzt178wvB/QcPHz1eXHpy6ExuORxwI409jpgDKTQcoEAJx5kFpiIJR9HJ++r86AysE0bvY5FBT7GBFongDL1r71tf9xeX2yvtkdCbSmeiLJOJ7PaX5nQYG54r0Mglc65kFgWXMAzC3EHG+AkbwHeECzwXMaZb3TZXrcpMQQxS3Fr1dq8cgFGAtqhFlUw5V6hoSJuKYepqGS2catOrINXZNEg5IsSfeFdME2P9p5GOvNPKtPwfUzU1VeWxLnH1/hwqZgsb170J07yIzEWdgRyTzV4pdJYjaD7uKsklRUOrUdBYWOAoC8o491zmDH3TPGWWcfQjC4JwFFvuiTj2FKd9P05pTnORK68qxXTsuxvJf5WNBeNW+NFdLxqmRZaCzkAziUVnPP2gufP50/5buidFDI6+pN31Fv36YafS2i26a5yP9cbqRtC8zgugMXLESzPUcM7HTZfhJVgTC5dJVrgTkblh2QyalIYO/APWA0zLkEXmDK5hhuVahsMbsAikOa/ButNgtWypsXgLtpbyCtv22OoeLMvQlKE2VjHpxCUMp9znCuffqpS3QxJjUBuEfyXzG9r5ex9vKofdlc7GyvqXteXtN5NdnSfPyHPygnTIa7JNPpJdckA4GZAf5Cf51VhovGpsNDbH0NmZScxTUpPGuz8BNYpR</latexit>ZnNOVEL ITEM<latexit sha1_base64="8jd+0BBFEqTLtCRWVMGmV4U6wtA=">AAAEj3icnVNLb9QwEHbbBUp4tXDkYlGtxGGpdrcvQCqqhFrBBQp9Ss2qcpzJxlrHTu1J2zTKz+AKv4t/g5NdqQ1demCkKDPjbx7+xhOkUljsdn/PzM617t1/MP/Qe/T4ydNnC4vPD63ODIcDrqU2xwGzIIWCAxQo4Tg1wJJAwlEw+lidH52DsUKrfcxTGCRsqEQkOEPnOvEThrHlptguTxeWusvdWuhtpTdRlshEdk8X55Qfap4loJBLZm3BDAouofT8zELK+IgN4QThEi9EiPFmv8uTTmXGIIYxbq44e1AMQSeAJm9EFSyxNk+CkrbrDhsZDZwpPagg1dk0SFET406cK6SRNu5TSGvvtDId98c4mZqq8hgb2WZ/FhNmchM2vRFTPA/0ZZOBDKO3g0KoNENQfNxVlEmKmlYjoaEwwFHmlHHuuMwYuqZ5zAzj6EbneX4dW+yJMHQUx6durFKfZSJLnJokTIWuu1r+q2woGDfCje5mUT/O0xhUCopJzHvj6Xvtna9f9t/TPSlCsPQN7a916PftnUrrduiuti7WGSvrXvsmL4Bay5qXtq/ggo+bLvwrMDoUNpUstyOR2rJoe21KfQvuIashxoXPAn0ONzBlsZpieQsWgNQXDVh/GqyRLdYG78A2Ul5juw5b3YOlKerCV9okTFpxBeWU+1zj3FuV8m5IpDUqjfCvZG5De3/v423lsL/cW19e+7a6tPVusqvz5CV5RV6THtkgW+QT2SUHhBNNfpCf5FdrsbXR+tDaGkNnZyYxL0hDWp//AFO0jgU=</latexit>E
<latexit sha1_base64="PofVNpTlvGKFV3cHn8ee8gBa9jQ=">AAAEiXicnVNtT9RAEF7gVCy+gH70y0ZyCSYn6R0vEhISIkr8pCgckNgL2W6n181td8vuFCjN/Qa/6k/z37i9uwQqJx+cpOnM7DMv+8xOmElh0fd/z8zONR48fDT/2Ft48vTZ88WlF8dW54ZDl2upzWnILEihoIsCJZxmBlgaSjgJB3vV+ckFGCu0OsIig17K+krEgjN0ru6HleDqzdnisr/qj4TeVdoTZZlM5OBsaU4FkeZ5Cgq5ZNaWzKDgEoZekFvIGB+wPnxHuMJLEWGy0/F52qrMBEQ/wZ01Z/fKPugU0BS1qJKl1hZpOKTNlGFiaxkNnCvdqyDV2TRIOaLEnThXRGNt3KeQjrzTyrTcH5N0aqrKY2xs6/1ZTJkpTFT3xkzxItRXdQZyjLd6pVBZjqD4uKs4lxQ1rYZBI2GAoywo49xxmTN0TfOEGcbRDc3zglFseSiiyFGcnLmBSn2eizx1apoyFbnuRvJfZSPBuBFudLeLBkmRJaAyUExi0R5P32vuf/l8tE0PpYjA0re0s9Gi3z7uV5rfogfaulhnrG16zdu8AGotR7w0AwWXfNx0GVyD0ZGwmWSFHYjMDsum16Q0sOCesOpjUgYs1BdwCzMs1zMc3oGFIPVlDdaZBqtlS7TBe7C1lDdY32Gre7AsQ10GSpuUSSuuYTjlPjc491alvB8Sa41KI/wrmdvQ9t/7eFc57qy2N1c3vq4v776f7Oo8eUVekxXSJu/ILvlEDkiXcCLID/KT/GosNNqNrcb2GDo7M4l5SWrS2PsDZSyKsA==</latexit>D(x)
ANNS OVER<latexit sha1_base64="TZ0sMw6r5rvk2KOSBIZT99ShK4I=">AAAElXicnVNLb9NAEN62gZbwaAsHDlxWVJE4hCpJHzykSpWAihMt9CnhKFqvx/Gq+3B3x21dy7+EK/wo/g3rJFJrGnpgJMszs9889pudMJXCYafze2Z2rnHv/vzCg+bDR4+fLC4tPz1yJrMcDrmRxp6EzIEUGg5RoIST1AJToYTj8PRDdX58DtYJow8wT6Gv2FCLWHCG3jVYWgyKIFTFVTkIQMqgHCytdFY7I6G3le5EWSET2Rssz+kgMjxToJFL5lzBLAouoWwGmYOU8VM2hO8Il3ghIky2eh2u2pWZgBgmuLXm7X4xBKMAbV6LKphyLldhSVuKYeJqGS2cadOvINXZNEgxosefeFdEY2P9p5GOvNPKtP0fEzU1VeWxLnb1/hwqZnMb1b0x0zwPzWWdgQzjt/1C6DRD0HzcVZxJioZWg6GRsMBR5pRx7rnMGPqmecIs4+gH2GwGo9hiX0SRpzgZ+OFKc5aJTHlVKaYj391I/qtsJBi3wo/uZtEgydMEdAqaScy74+k3Wzu7Xw7e030pInD0Ne1ttOm3TzuV1mnTPeN8rDfWNputm7wAGiNHvLQCDRd83HQRXIE1kXCpZLk7Fakri1azRWngwD9nPcSkCFhozuEGpizWUyxvwUKQ5qIG602D1bIlxuId2FrKa2zHY6t7sDRFUwTaWMWkE1dQTrnPNc6/VSnvhsTGoDYI/0rmN7T79z7eVo56q93N1Y2v6yvb7ya7ukBekJfkFemSN2SbfCZ75JBwkpEf5Cf51Xje2Gp8bOyMobMzk5hnpCaN3T/xgJAY</latexit>{z }
<latexit sha1_base64="HSy9GJUWwRnKshgFTundDji1EPM=">AAAEinicnVNLb9NAEN62AYop0MKRy4oqEodQJekDCqpUCag4QaFPCUfVej2Ol+zD3R23da38B67wz/g3rJNIrWnogZEsz8x+89hvdqJMCoft9u+Z2bnGnbv35u8HDxYePnq8uPTk0JnccjjgRhp7HDEHUmg4QIESjjMLTEUSjqLBu+r86AysE0bvY5FBT7G+FongDL3rMJSxQXeyuNxeaY+E3lQ6E2WZTGT3ZGlOh7HhuQKNXDLnSmZRcAnDIMwdZIwPWB++IVzguYgx3eq2uWpVZgqin+LWqrd7ZR+MArRFLapkyrlCRUPaVAxTV8to4VSbXgWpzqZByhEn/sS7YpoY6z+NdOSdVqbl/5iqqakqj3WJq/fnUDFb2LjuTZjmRWQu6gzkmLzulUJnOYLm466SXFI0tJoGjYUFjrKgjHPPZc7QN81TZhlHP7UgCEex5Z6IY09xeuInKs1pLnLlVaWYjn13I/mvsrFg3Ao/uutFw7TIUtAZaCax6IynHzR3Pn/af0P3pIjB0Ze0u96iXz/sVFq7RXeN87HeWN0Imtd5ATRGjnhphhrO+bjpMrwEa2LhMskKNxCZG5bNoElp6MC/Yd3HtAxZZM7gGmZYrmU4vAGLQJrzGqw7DVbLlhqLt2BrKa+wbY+t7sGyDE0ZamMVk05cwnDKfa5w/q1KeTskMQa1QfhXMr+hnb/38aZy2F3pbKysf1lb3t6c7Oo8eUaekxekQ16RbfKR7JIDwsl38oP8JL8aC41uY7PxdgydnZnEPCU1abz/AxXGi8o=</latexit>...
<latexit sha1_base64="wuCVbo2LUoN6/Lg4rBvuf/5MgWM=">AAAEjnicnVNZb9NAEN62AUq4WnjkZUUViYdQOenBIVVUQlR9gkLpIXCI1utxvOoe7u64qWvlX/AK/4t/wzqJ1JqGPjCS5ZnZb479ZifKpHAYBL/n5hcat27fWbzbvHf/wcNHS8uPD53JLYcDbqSxxxFzIIWGAxQo4TizwFQk4Sg6eVedH52BdcLoL1hk0FNsoEUiOEPv+hpGqhyO+vp7p7+0EqwGY6HXlc5UWSFT2esvL+gwNjxXoJFL5lzJLAouYdQMcwcZ4ydsAN8QznEoYky3ugFX7cpMQQxS3Frzdq8cgFGAtqhFlUw5V6hoRFuKYepqGS2catOrINXZLEg55sWfeFdME2P9p5GOvbPKtP0fUzUzVeWxLnH1/hwqZgsb170J07yIzHmdgRyTV71S6CxH0HzSVZJLioZWE6GxsMBRFpRx7rnMGfqmecos4+gn12yG49hyX8Sxpzjt+6lKc5qLXHlVKaZj391Y/qtsLBi3wo/uatEwLbIUdAaaSSw6k+k3WzsfP3x5Q/eliMHRF7S70aaf3+9UWtCme8b5WG+sbTZbV3kBNEaOeWmFGoZ80nQZXoA1sXCZZIU7EZkbla1mi9LQgX/HeoBpGbLInMEVzKhcz3B0DRaBNMMarDsLVsuWGos3YGspL7GBx1b3YFmGpgy1sYpJJy5gNOM+lzj/VqW8GZIYg9og/CuZ39DO3/t4XTnsrnY2Vzc+ra9sv57u6iJ5Sp6R56RDXpJtskv2yAHhRJMf5Cf51VhqbDa2Gm8n0Pm5acwTUpPG7h/BGY1m</latexit>w1n<latexit sha1_base64="Sks8y2N6YsQwqQiDubzOTt+dzow=">AAAEjnicnVNZb9NAEN62AYq5WnjkZUUViYdQJenBIVVUQlR9gkLpIXCI1utJvOoe7u64qWv5X/AK/4t/wzqJ1JqGPjCS5ZnZb479ZidKpXDYbv+em19o3Lp9Z/FucO/+g4ePlpYfHzqTWQ4H3EhjjyPmQAoNByhQwnFqgalIwlF08q46PzoD64TRXzBPoafYUIuB4Ay962sYqWJU9vX3bn9ppb3aHgu9rnSmygqZyl5/eUGHseGZAo1cMucKZlFwCWUQZg5Sxk/YEL4hnONIxJhsddtctSozATFMcGvN271iCEYB2rwWVTDlXK6ikjYVw8TVMlo41aZXQaqzWZBizIs/8a6YDoz1n0Y69s4q0/J/TNTMVJXHuoGr9+dQMZvbuO4dMM3zyJzXGchw8KpXCJ1mCJpPuhpkkqKh1URoLCxwlDllnHsuM4a+aZ4wyzj6yQVBOI4t9kUce4qTvp+qNKeZyJRXlWI69t2N5b/KxoJxK/zorhYNkzxNQKegmcS8M5l+0Nz5+OHLG7ovRQyOvqDdjRb9/H6n0totumecj/XG2mbQvMoLoDFyzEsz1DDik6aL8AKsiYVLJcvdiUhdWTSDJqWhA/+O9RCTImSROYMrmLJYT7G8BotAmlEN1p0Fq2VLjMUbsLWUl9i2x1b3YGmKpgi1sYpJJy6gnHGfS5x/q1LeDBkYg9og/CuZ39DO3/t4XTnsrnY2Vzc+ra9sv57u6iJ5Sp6R56RDXpJtskv2yAHhRJMf5Cf51VhqbDa2Gm8n0Pm5acwTUpPG7h/FOo1n</latexit>w2n<latexit sha1_base64="hErtj/s4b47Q+wTYsCnuknRT/qU=">AAAEjnicnVNZb9NAEN62AYq5UnjkZUUViYdQJenBIVVUQlSVkKDQU+AQrdeTeNU93N1xU9fKv+AV/hf/hnUSqTUNfWAkyzOz3xz7zU6USuGw1fo9N79Qu3X7zuLd4N79Bw8f1ZceHzqTWQ4H3EhjjyPmQAoNByhQwnFqgalIwlF08q48PzoD64TR+5in0FVsoEVfcIbe9TWMVDEc9fT3D736cmulNRZ6XWlPlWUyld3e0oIOY8MzBRq5ZM4VzKLgEkZBmDlIGT9hA/iGcI5DEWOy2Wlx1SzNBMQgwc1Vb3eLARgFaPNKVMGUc7mKRrShGCauktHCqTbdElKezYIUY178iXfFtG+s/zTSsXdWmab/Y6Jmpio91vVdtT+HitncxlVvn2meR+a8ykCG/VfdQug0Q9B80lU/kxQNLSdCY2GBo8wp49xzmTH0TfOEWcbRTy4IwnFssSfi2FOc9PxUpTnNRKa8qhTTse9uLP9VNhaMW+FHd7VomORpAjoFzSTm7cn0g8b2p4/7b+ieFDE4+oJ21pv0y/vtUms16a5xPtYbqxtB4yovgMbIMS+NUMOQT5ouwguwJhYulSx3JyJ1o6IRNCgNHfh3rAeYFCGLzBlcwYyKtRRH12ARSDOswDqzYJVsibF4A7aS8hLb8tjyHixN0RShNlYx6cQFjGbc5xLn36qUN0P6xqA2CP9K5je0/fc+XlcOOyvtjZX1z2vLW6+nu7pInpJn5Dlpk5dki+yQXXJAONHkB/lJftXqtY3aZu3tBDo/N415QipS2/kDLIKNgA==</latexit>wKn
<latexit sha1_base64="HSy9GJUWwRnKshgFTundDji1EPM=">AAAEinicnVNLb9NAEN62AYop0MKRy4oqEodQJekDCqpUCag4QaFPCUfVej2Ol+zD3R23da38B67wz/g3rJNIrWnogZEsz8x+89hvdqJMCoft9u+Z2bnGnbv35u8HDxYePnq8uPTk0JnccjjgRhp7HDEHUmg4QIESjjMLTEUSjqLBu+r86AysE0bvY5FBT7G+FongDL3rMJSxQXeyuNxeaY+E3lQ6E2WZTGT3ZGlOh7HhuQKNXDLnSmZRcAnDIMwdZIwPWB++IVzguYgx3eq2uWpVZgqin+LWqrd7ZR+MArRFLapkyrlCRUPaVAxTV8to4VSbXgWpzqZByhEn/sS7YpoY6z+NdOSdVqbl/5iqqakqj3WJq/fnUDFb2LjuTZjmRWQu6gzkmLzulUJnOYLm466SXFI0tJoGjYUFjrKgjHPPZc7QN81TZhlHP7UgCEex5Z6IY09xeuInKs1pLnLlVaWYjn13I/mvsrFg3Ao/uutFw7TIUtAZaCax6IynHzR3Pn/af0P3pIjB0Ze0u96iXz/sVFq7RXeN87HeWN0Imtd5ATRGjnhphhrO+bjpMrwEa2LhMskKNxCZG5bNoElp6MC/Yd3HtAxZZM7gGmZYrmU4vAGLQJrzGqw7DVbLlhqLt2BrKa+wbY+t7sGyDE0ZamMVk05cwnDKfa5w/q1KeTskMQa1QfhXMr+hnb/38aZy2F3pbKysf1lb3t6c7Oo8eUaekxekQ16RbfKR7JIDwsl38oP8JL8aC41uY7PxdgydnZnEPCU1abz/AxXGi8o=</latexit>...SELECTED CLASSIFIERSCLASSIFIER SELECTOR<latexit sha1_base64="D3JMKSFRXOXtjU8PaKr5MYgwi1s=">AAAEj3icnVNLb9QwEHbpAiW8WjhysahW4rBUu9sXIBVVQlRwgUKfUrOqHGeysepHak/aplF+Blf4XfwbnN2V2tClB0aKMjP+5uFvPFEmhcNu9/fMndnW3Xv35x4EDx89fvJ0fuHZvjO55bDHjTT2MGIOpNCwhwIlHGYWmIokHEQnH+rzgzOwThi9i0UGA8WGWiSCM/Suo1AxTDmT5U51PL/YXeqOhN5UehNlkUxk+3hhVoex4bkCjVwy50pmUXAJVRDmDjLGT9gQjhAu8FzEmG70u1x1ajMFMUxxY9nbg3IIRgHaohFVMuVcoaKKtusOXSOjhVNtBjWkPpsGKUfE+BPvimlirP800pF3WpmO/2OqpqaqPdYlrtmfQ8VsYeOmN2GaF5G5aDKQY/JmUAqd5Qiaj7tKcknR0HokNBYWOMqCMs49lzlD3zRPmWUc/eiCIBzFljsijj3F6bEfqzSnuciVV5ViOvbdjeS/ysaCcSv86K4XDdMiS0FnoJnEojeeftDe+vpl9x3dkSIGR1/T/mqHfv+4VWvdDt02zsd6Y3ktaF/nBdAYOeKlHWo45+Omy/ASrImFyyQr3InIXFW2gzaloQP/kPUQ0zJkkTmDa5iqXMmwugGLQJrzBqw/DdbIlhqLt2AbKa+wXY+t78GyDE0ZamMVk05cQjXlPlc4/1alvB2SGIPaIPwrmd/Q3t/7eFPZ7y/11pZWv60sbr6d7OoceUFeklekR9bJJvlEtske4cSQH+Qn+dVaaK233rc2x9A7M5OY56Qhrc9/ACoOjfs=</latexit>S
ENCODER
<latexit sha1_base64="tJ53AxhGh46KVe7jEth+40wVv7A=">AAAEh3icnVNLb9NAEN62AVrzauHIZUUViUMoSfqgIFUqQlScoNCnwFG0Xo/jVffh7o7bulZ+Alf4bfwb1kmk1jT0wEiWZ2a/eew3O1EmhcN2+/fM7Fzjzt178wvB/QcPHz1eXHpy6ExuORxwI409jpgDKTQcoEAJx5kFpiIJR9HJ++r86AysE0bvY5FBT7GBFongDL1r71tf9xeX2yvtkdCbSmeiLJOJ7PaX5nQYG54r0Mglc65kFgWXMAzC3EHG+AkbwHeECzwXMaZb3TZXrcpMQQxS3Fr1dq8cgFGAtqhFlUw5V6hoSJuKYepqGS2catOrINXZNEg5IsSfeFdME2P9p5GOvNPKtPwfUzU1VeWxLnH1/hwqZgsb170J07yIzEWdgRyTzV4pdJYjaD7uKsklRUOrUdBYWOAoC8o491zmDH3TPGWWcfQjC4JwFFvuiTj2FKd9P05pTnORK68qxXTsuxvJf5WNBeNW+NFdLxqmRZaCzkAziUVnPP2gufP50/5buidFDI6+pN31Fv36YafS2i26a5yP9cbqRtC8zgugMXLESzPUcM7HTZfhJVgTC5dJVrgTkblh2QyalIYO/APWA0zLkEXmDK5hhuVahsMbsAikOa/ButNgtWypsXgLtpbyCtv22OoeLMvQlKE2VjHpxCUMp9znCuffqpS3QxJjUBuEfyXzG9r5ex9vKofdlc7GyvqXteXtN5NdnSfPyHPygnTIa7JNPpJdckA4GZAf5Cf51VhovGpsNDbH0NmZScxTUpPGuz8BNYpR</latexit>ZnAUXILIARY INFORMATION  FOR META CLASSIFIER<latexit sha1_base64="8jd+0BBFEqTLtCRWVMGmV4U6wtA=">AAAEj3icnVNLb9QwEHbbBUp4tXDkYlGtxGGpdrcvQCqqhFrBBQp9Ss2qcpzJxlrHTu1J2zTKz+AKv4t/g5NdqQ1demCkKDPjbx7+xhOkUljsdn/PzM617t1/MP/Qe/T4ydNnC4vPD63ODIcDrqU2xwGzIIWCAxQo4Tg1wJJAwlEw+lidH52DsUKrfcxTGCRsqEQkOEPnOvEThrHlptguTxeWusvdWuhtpTdRlshEdk8X55Qfap4loJBLZm3BDAouofT8zELK+IgN4QThEi9EiPFmv8uTTmXGIIYxbq44e1AMQSeAJm9EFSyxNk+CkrbrDhsZDZwpPagg1dk0SFET406cK6SRNu5TSGvvtDId98c4mZqq8hgb2WZ/FhNmchM2vRFTPA/0ZZOBDKO3g0KoNENQfNxVlEmKmlYjoaEwwFHmlHHuuMwYuqZ5zAzj6EbneX4dW+yJMHQUx6durFKfZSJLnJokTIWuu1r+q2woGDfCje5mUT/O0xhUCopJzHvj6Xvtna9f9t/TPSlCsPQN7a916PftnUrrduiuti7WGSvrXvsmL4Bay5qXtq/ggo+bLvwrMDoUNpUstyOR2rJoe21KfQvuIashxoXPAn0ONzBlsZpieQsWgNQXDVh/GqyRLdYG78A2Ul5juw5b3YOlKerCV9okTFpxBeWU+1zj3FuV8m5IpDUqjfCvZG5De3/v423lsL/cW19e+7a6tPVusqvz5CV5RV6THtkgW+QT2SUHhBNNfpCf5FdrsbXR+tDaGkNnZyYxL0hDWp//AFO0jgU=</latexit>E
Figure 2: The IRENE extreme meta-classifier. IRENE comprises (a) A base extreme classifier encoder and the classifiers trained
via a standard algorithm; (b) A classifier selector S, which, given the encoder representation of a novel item Zn, retrieves K
classifiers based on an approximate nearest neighbor search (ANNS), and (c) A transformer-based meta-classifier generator G.
The meta-classifier unofZnis computed as given in Equation (1).
where wℓ∈S (zℓ),tencandtclfare learnable type embeddings that
distinguish between encoder and classifier inputs. The transformer
layer is capable of learning correlations between the classifiers and
the encoder representation, yields superior meta-classifiers over
methods that consider naive weighted summation for the generator
(cf. Section 7). The computational complexity is O
(K+1)2d2
for
the self attention layer [ 37], andO((K+1)d)for the linear layer.
Figure 2 illustrates the modules present in the IRENE framework.
4.1 IRENE: Training and Inference
In this section, we outline the training strategy for IRENE. Firstly,
weassume that the representation encoder E, and the set of
observed-item classifiers W={wℓ}L
ℓ=1are made available to
us apriori, and remain fixed. With these components (E,W), the
ANNS index is constructed over the encoder representations of the
observed items Z. Classifier selection is as described in Section 4.
IRENE’s meta-classifier training employs a binary cross-entropy
loss reformulated for zero-shot performance. In particular, to simu-
late novel items at training time, given an observed item zℓ, instead
of using the item’s own classifier wℓ, the meta-classifier uℓ, derived
from the selected classifiers, is utilized. That is, an observed item
its trained with its selected neighboring classifiers and not its own.
The original targets yiℓremain unchanged. The loss is given by:
LG=X
xi∈XX
zℓ∈Z
Cyiℓln(σ(x⊤
iuℓ))+(1−yiℓ)ln(1−σ(x⊤
iuℓ))
(2)
whereσ(·)is the sigmoid function, uℓ=Gϕϕϕ(zℓ,S(zℓ)),x=E(X),
andCis the weight for misclassified positive query-item pairs.
This weight addresses the imbalance between positive and negative
query-item pairs in standard XC settings, as misclassifying positives
significantly impacts performance. [ 7]. We link the likelihood of en-
countering positive-pairs to zero-shot generalization performance
in Section 5.
To facilitate training, the loss is approximated using standard
negative mining strategies, with the positive, and negative-mined
items associated with a query represented by Z+
o,iandZ−
o,i, respec-
tively. The modified loss is then given by
LG=X
xi∈XX
zℓ∈Zo,i
Cyiℓln(σ(x⊤
iuℓ) )+(1−yiℓ)ln(1−σ(x⊤
iuℓ) )
,(3)
where Zo,i=Z+
o,i∪Z−
o,iincludes both positive items and mined
negative items associated with query xi.Inference : An Approximate Nearest Neighbor Search (ANNS) in-
dexAis constructed over the item representations to facilitate
zero-shot inference. This index encompasses either solely novel
item representations for zero-shot inference or a combination of
observed and novel items for generalized zero-shot inference. Thus,
Ais built over{zℓ|zℓ∈ZT}, where ZTrepresents the set of items
at inference, either ZnorZ∪Zn.
During inference, the embedding of a query Tis calculated as
xT=E(XT)∈Rdwith XTbeing the query text. To retrieve rele-
vant items for xT,Ais queried using xT. The computational com-
plexity of IRENE’s inference is Ω(E+dlog (|Z|+|Zn|)), where Eis
the cost of encoder E. IRENE is designed to seamlessly incorporate
new items by calculating their representations and adding them to
the ANNS index [ 35] as and when novel they arrive in the system.
This feature is particularly advantageous for applications like spon-
sored search, where novel items are frequently introduced. In such
scenarios, re-training the model with a large volume of items can be
resource-intensive, making IRENE a viable and efficient solution.
5 Theoretical Guarantees
Prior to evaluating the experimental efficacy of IRENE, we establish
theoretical guarantees for the zero-shot generalization of EMMETT,
with a specific focus on the case of IRENE. To simplify our anal-
ysis, we represent data samples as query-item pairs, s= (x,z).
The dataset S={s}is formed through two potential approaches.
The most straightforward method involves randomly selecting N
queries and items from the respective distributions XandZ, pairing
them to create ˜S={si=(xi,zi)|i=1,2, . . .N}. Alternatively, con-
sidering all possible query-item pairings from XandZ(as defined in
Section 3.1), results in S={(xi,zℓ)|i=1,2, . . .N, ℓ=1,2, . . .L},
meaning, sis drawn from the Cartesian product space X×Z . The
dataset is indexed by j=L(i−1)+ℓ,j=1,2, . . .M=NL. In
this context, the extreme (meta) classification problem becomes
binary, with target values yinY, whereyj=1indicates a pos-
itive association between item zℓand the query xi. Within the
XC setting, it is well known that negatively associated pairs are
significantly more likely to occur than positive ones. We assume
that any set Scontains at most κpositively associated pairs. We
also assume norm bounds on the encoder representations of the
queries, and the learnt classifiers, i.e.,max x∈E (X)∥x∥2≤Band
max w∈W∥w∥2≤W, respectively.
3661KDD ’24, August 25–29, 2024, Barcelona, Spain Sachin Yadav et al.
In assessing the generalization performance of EMMETT, we
recall the concepts of empirical and true risks. Given a function
f(·), and a chosen loss function, the empirical risk over a dataset S,
and the true risk are defined as:
ˆR=1
MMX
j=1
sj∼Sloss (f(sj),yj)andR=Es∼X×Z [loss (f(s),y)],
respectively. For our analysis, we use the weighted binary cross-
entropy loss, Cyln(f)+(1−y)ln(1−f).We assume that the function
fbelongs to the class F.
The generalizability of a model is indicated by the difference
between empirical and true risks. This deviation depends on both
data and the model. The model’s influence is typically quantified us-
ing the Rademacher complexity R[28] of the function class F. This
complexity can be evaluated empirically over the dataset (known as
the empirical Rademacher complexity ˆRS(F)), or across all datasets
of size M, given by RM(F)=ESfˆRS(F)g
. Data dependence is
often highlighted by bounding the risk deviation using the McDi-
armid inequality [ 28]. The following theorem bounds the deviation
of the true risk from the empirical risk.
Theorem 1. (Generalization performance of EMMETT) Let
RandˆRdenote the true and empirical risk, respectively, and ˆRSdenote
the empirical Rademacher complexity over set S. Let p≪1be the
probability that a query-item pair is positively associated (i.e., yj=1),
andqdenote the probability that a set S,|S|=Mhas at most κ
positive pairs. Then, with probability at least 1−δ,δ∈(2q,1), we
have the following generalization bound:
R≤ˆR+ˆRS(F)+3*....
,q+vut
ln
2
δ−2q
2M+////
-,where (4)
q≤exp(
−2M
1−p−κ
M2)
. (5)
Proof. The detailed proof is provided in Appendix A of the
Supplementary Document. We summarize the proof here. Without
loss of generality, we redefine the loss to have the target labels
yj∈{−1 ,1}, giving rise to the following form of the loss:
д(s,y)=loss (f(s),y)=1−y
2
f(s)−C1+y
2
f(s).
We then define the function Φ(S)as follows
Φ(S)=sup
f∈F(
E[д(s,y)]−ˆEf
д(sj,yj)g )
.
By means of an extended McDiarmid inequality (that accounts for
the positive-negative sample imbalances) [28], we get
Pr (Φ(S)−ES[Φ(S)]≥ϵ)≤2q+2 exp(
−2M(ϵ−q)2)
=δ
⇒ϵ=q+vut
ln
2
δ−2q
2M.Given the inequality ES[Φ(S)]≤2RM(loss◦F )=2ˆRS(F)[28],
substituting for δinto the first equation, and simplifying, we get
R≤ˆR+ˆRS(F)+3q+3vut
ln
2
δ−2q
2M.
To bound q, we bound the probability that the set Scontains at
least M−κpositively associated pairs by means of the Hoeffding
inequality, which completes the proof of Theorem 1. □
Theorem 1 sheds light on the generalizability of new items in
XC meta classifiers. Consistent with standard findings, we note that
generalization gap is inversely related to the dataset size, M. Fur-
thermore, the choice of dataset Sover ˜Sreveals distinct advantages
when considering the probabilities pandq. Specifically, a 1-vs-all
setting, wherein we consider the Cartesian product space of queries
and items, will lead to better overall performance. Further, for suf-
ficiently small κand sufficiently large M, we have q≈exp{−2M}.
We also observe a direct correlation between generalization, and
the complexity of the function class F. In scenarios where Fcor-
responds to the class of meta-classifier generators, the associated
Rademacher complexity is detailed in the following lemma:
Lemma 2. (Rademacher complexity of the IRENE genera-
tor) LetFbe the class of functions defined in the IRENE algorithm,
comprising pre-determined encoder representations and classifiers, a
given classifier selector that outputs Kclassifiers, andG, the meta-
classifier generator. Then, the Rademacher complexity of Fcan be
bounded as follows:
ˆRS(F)≤O
B∥M∥2p
dln(K+1)
, (6)
where x∈RdandM∈Rd×1is the weight matrix associated with
the linear layer.
Proof. The detailed proof is provided in Appendix A of the
Supplementary Document and follows by repeated application of
Talagrand’s lemma [28]:
ˆRS(F)≤BˆRS(F1)
≤B∥M∥2ˆRS(F2)
≤B∥M∥2p
dln(K+1)ˆRS(F3)
≤O
B∥M∥2p
dln(K+1)
,
whereF3=Clf(S(zℓ)),F2=SelfAttn .(F3)andF1=MF2+b.□
Lemma 2 yields several critical insights. Firstly, for a given XC
base (consisting of an encoder and classifiers), the complexity of
the meta-classifier increases logarithmically with K. This creates
a balancing act: using a single classifier may result in inadequate
model capacity, but increasing Kincreases model complexity, poten-
tially degrading performance, and slowing down training. Ablation
experiments presented in Section 7 validate this claim. Secondly,
the complexity of the meta-classifier generator is independent of L,
indicating that the model effectively scales in generalizing to novel
labels. This scalability is attributed to the classifiers being fixed
during the generator’s training. The subsequent corollary discusses
the Rademacher complexity of the function class Fwhen the XC
classifiers and the generator Gare updated concurrently.
3662Extreme Meta-Classification for Large-Scale Zero-Shot Retrieval KDD ’24, August 25–29, 2024, Barcelona, Spain
Corollary 3. (Rademacher complexity of the IRENE gen-
erator with trainable classifier ) LetFbe the class of functions
defined in the IRENE algorithm as in Lemma 2. Let the classifier set
Wbe trainable over the meta-classifier loss. Then, the Rademacher
complexity ofFcan be bounded as follows:
ˆRS(F)≤O *
,B2Wr
L
M∥M∥2p
dln(K+1)+
-. (7)
This result is obtained by combining Lemma 2 with an extension
of Theorem 3 present in Awasthi et al . [3]. Training classifiers
via the meta-classifier loss incurs a complexity in the order of√
L. For the sake of completeness, we present the extension of
Theorem 3 present in Awasthi et al . [3], relevant to the XC setting,
with the model trained on Ndata points ˜X, and the loss defined
over classifiers W.
The following Lemma bounds the Rademcacher complexity of
the XC classifier class:
Lemma 4. (Rademacher complexity of the XC classifiers )
(extension of Awasthi et al . [3], Theorem 3) LetFbe the class of
linear classifiers defined over the seen-item set Zsin the classical XC
setting (cf. Section 3.1), i.e., F={⟨x,wℓ⟩|ℓ=1,2, . . . , L}. Then, the
Rademacher complexity of Fcan be bounded as ˆRS(F)≤LBW√
N,
where|X|=Nis the Cardinality of the training set.
The proof is provided in Appendix A of the Supplementary Doc-
ument. As expected, the complexity of the XC classifier, particularly
in terms of generalizing to unseen labels, increases linearly with
the number of labels. This is because the classifier’s learning de-
pends on the query-item pairs available during training. Therefore,
as novel items arrive, additional data is necessary for accurately
learning the classifiers.
These findings underscore the effectiveness of the meta-classifier-
based EMMETT framework in achieving zero-shot generalization.
They also validate the design choices implemented in the IRENE
generator and algorithm, which contribute to a model with favor-
able model complexity. We now proceed to provide experimental ev-
idence to support the IRENE algorithm, complemented by ablation
studies. These studies elucidate our design decisions, connecting
them to the theoretical bounds established earlier.
6 Experimental Results
Datasets: We validate the performance of IRENE across a diverse
set of datasets spanning multiple applications, and label space sizes
(cf. Table 1). For LF-AmazonTitles-1.3M and LF-Wikipedia-500K, we
use the experimental setup reported in Bhatia et al . [6], while for LF-
AOL-270K and LF-WikiHierarchy-550K, we refer to [ 7]. We create
the zero-shot versions of these datasets by randomly partitioning
the set of items into observed and novel using a 90-10 split ratio [ 34].
Baselines: We demonstrate IRENE’s efficacy by comparing its per-
formance when built atop leading dense retrieval encoders such as
NGAME [ 10], ANCE [ 40], MACLR [ 41], and DPR [ 20]. We also com-
pare against competitive zero-shot XC methods such as SemSup-
XC [1], ZestXML [14].
IRENE’s Training Procedure : Given a base encoder E, the clas-
sifiers Ware trained using a one-versus-all BCE loss formulation
similar to Renée [ 17]. However, unlike Renée, where the encoderTable 1: A summary of the datasets, and their corresponding
applications, used in evaluating IRENE.
Dataset Application Type Feature Type
LF-AOL-270K Query Completion Short-Text
LF-Wikipedia-500K Category Annotation Long-Text
LF-WikiHierarchy-550K Taxonomy Completion Short-Text
LF-AmazonTitles-1.3M Product Recommendation Short-Text
KeywordPrediction-10M Sponsored Search Short-Text
and classifiers are trained jointly, we train only a single output-
side transformer layer jointly with the classifiers. Subsequently,
IRENE’s meta-classifier generator block ( G) is trained using the
hyper-parameters K=3andD=1for results reported in Table 2.
Ablations on the choice of KandDare provided in Section 7.
Additional details on dataset creation and statistics, and detailed
training procedures are provided in Appendices B and C, respec-
tively, of the Supplementary Document.
Evaluation Setting and Metrics : Following [ 1,14] we consider
two settings: (i): zero-shot retrieval on novel items and (ii): gen-
eralized zero-shot retrieval on the combined set of observed and
novel items. We report performance on metrics such as Precision@ k
(P@k), and Recall@ k(R@k) at different truncation levels k.
Results on Benchmark Datasets:
Table 2 presents comparisons of the zero-shot and generalized
zero-shot performance of IRENE against the baselines. When added
atop different encoders, IRENE consistently improves the perfor-
mance in both the zero-shot (+1.5 to +40% in P@1 and +1 to +45% in
R@10) and generalized evaluation settings (+1 to +29% in P@1 and
+1 to +15% in R@10). IRENE shows larger gains on datasets such as
LF-AOL-270K and LF-WikiHierarchy-550K where queries and their
associated items have higher lexical dissimilarity. While modelling
such relations can be challenging for small encoders, they neverthe-
less function as effective neighbour selectors, thereby identifying
relevant classifiers for combining via IRENE’s meta classifier gener-
ator. This is particularly visible in the case of MACLR, where IRENE
improves P@1 by nearlly 40% in zero-shot on LF-WikiHierarchy-
550K. IRENE’s consistent gains over a wide range of applications
on different encoders show the value of the information introduced
by classifiers and emphasize the versatility of our approach.
When compared to zero-shot XC methods such as SemSup-XC,
IRENE attains higher P@1 in the zero-shot setting (+10.31%) while
being approximately 350 times more efficient than SemSup-XC at
inference (cf. Table 3). These gains across various baselines establish
the modularity of IRENE which can be used as a plug-and-play mod-
ule atop any dense retriever to obtain more accurate representation
for novel items for diverse recommendation applications.
Case-study on Sponsored Search: In the application of sponsored
search, accurately matching user queries to billions of advertiser bid
keywords presents a formidable challenge, exacerbated by varying
bid amounts based on relevance and semantic relationship of the
match. We demonstrate IRENE’s efficacy by conducting offline ex-
periments and online A/B tests on live search engine traffic. IRENE
trained on the KeywordPrediciton-10M dataset was used to obtain
representations for 100M novel keywords which were found to be
4% more accurate than those obtained from leading dense retrievers
3663KDD ’24, August 25–29, 2024, Barcelona, Spain Sachin Yadav et al.
Table 2: Comparison of zero-shot and generalized zero-shot accuracies of IRENE when applied to various baseline encoder
frameworks. On average, IRENE improves P@1 by 10.1% and R@10 by 11.9% in the zero-shot setting. In the generalized setting
IRENE boosts P@1 by 15.5% and R@10 by 11.5%. The best-performing algorithm amongst each pair of base encoder and its
IRENE variant are indicated in boldfaced.
ModelLF-AOL-270K-10 LF-WikiHierarchy-550K-10 LF-AmazonTitles-1.3M-10 LF-Wikipedia-500K-10
Zero-Shot Generalized Zero-Shot Generalized Zero-Shot Generalized Zero-Shot Generalized
P@1 R@10 P@1 R@10 P@1 R@10 P@1 R@10 P@1 R@10 P@1 R@10 P@1 R@10 P@1 R@10
NGAME 30.90 54.20 20.16 38.27 46.01 58.66 66.19 27.08 30.42 36.44 45.14 30.25 46.96 65.27 81.86 69.58
NGAME+IRENE 36.47 59.57 35.11 52.30 69.29 80.40 91.33 40.09 31.56 38.83 47.77 31.49 44.91 67.79 78.99 69.27
ANCE 33.43 67.84 22.63 49.72 43.06 56.28 68.76 25.89 22.38 30.72 27.65 17.31 30.67 58.91 42.91 43.39
ANCE+IRENE 36.84 67.82 30.84 51.75 66.54 82.10 90.72 39.74 22.75 32.72 36.78 22.34 41.59 71.59 71.39 63.46
MACLR 11.31 18.24 9.26 7.52 30.37 35.47 59.44 14.31 21.93 28.59 27.50 15.99 39.56 68.53 46.59 46.62
MACLR+IRENE 34.32 61.29 30.40 44.71 69.45 81.43 88.81 38.37 21.56 28.77 31.49 18.85 44.64 73.05 70.52 62.82
DPR 30.38 53.82 19.71 37.99 44.84 59.29 65.19 26.73 31.10 40.98 38.18 26.93 42.90 71.20 51.54 61.84
DPR+IRENE 36.80 60.22 35.07 52.57 69.65 80.01 89.52 39.84 30.49 40.31 43.08 29.25 42.19 70.50 70.39 66.71
TF-IDF 13.74 28.05 6.61 9.90 22.79 21.44 64.50 10.88 8.12 24.15 16.33 20.40 11.53 23.89 15.07 14.79
Zest-XML 9.34 25.91 26.34 26.57 13.97 17.48 68.86 22.13 5.42 5.58 41.36 22.87 2.62 14.73 60.16 45.15
SemSup-XC 26.27 36.31 26.12 23.92 57.45 46.81 90.51 28.37 11.28 11.68 25.13 15.21 46.60 57.08 54.20 38.08
DEXA 21.68 41.85 25.09 46.76 54.83 66.89 76.18 36.17 28.83 35.19 48.19 30.89 42.76 67.37 67.98 65.86
Table 3: Comparison of inference time (in ms) on a single
V100 GPU for the LF-AmazonTitles-1.3M-10 dataset. This in-
cludes (i) generating the representation of an unseen item
(Representation Time/ Rep. Time), and (ii) retrieving rele-
vant items for a given query (Retrieval Time). Compared to
dual encoder methods like NGAME and DEXA, IRENE adds
no latency overhead, with the representation time increas-
ing by 0.4 milliseconds. However, IRENE is about 350 times
faster than SemSup-XC, which aggregate token-level simi-
larities between queries and documents to obtain the scores.
MethodRep. Time (ms)↓Retrieval Time (ms)↓
(per item) (per query)
NGAME 0.08 0.43
SemSup-XC N/A 151.51
DEXA 0.48 0.43
NGAME + IRENE 0.54 0.43
in production, when evaluated in terms of the R@100 metric. In live
deployment, IRENE was found to increase the click-through rate
(ad clicks obtained per unit query) and decrease the quick-back rate
(fraction of users who quickly closed the ad) by 4.2% and 0.9%, re-
spectively. In IRENE a novel keyword can be encoded in under 1ms
and the approach demonstrates a 13% increase in good keyword
predictions, as ascertained by expert judges. To handle potential
distribution shifts that could occur in such dynamic settings, we
can continually grow the base extreme classifier set by adding new
item classifiers into it, as and when they receive clicks. Please refer
to Appendix E of the Supplementary Document for detailed studies
on IRENE’s application to sponsored search.
IRENE’s Computational Cost: Table 3 presents comparisons on
the time taken for generating representations for a novel item and
retrieving the relevant items given a query. When incorporating a
novel item, NGAME performs a forward pass over a 6-layer Distil-
BERT. DEXA incurs an additional cost of an ANNS search over
the cluster centroids. IRENE, on the other hand, incurs additional
costs from the classifier selector Sand meta-classifier generator
G, which involves an ANNS search over the set of observed itemsand a forward pass through a one-layer encoder respectively. The
representation generation step was executed on a single NVIDIA
Tesla V100 GPU for each method, while the ANNS search was
carried out on a 96-core CPU machine.
While being efficient at inference, IRENE’s classifier selector ( S)
and meta-classifier generator ( G) incur minimal training costs. On
a single NVIDIA Tesla V100 GPU, the training time for the NGAME
encoder on the LF-AmazonTitles-1.3M-10 dataset was 83 hours and
training IRENE on top of the NGAME encoder took only 6 hours.
7 Ablations
We perform ablation experiments to evaluate the impact of vari-
ous design choices within the components of the meta-classifier
generator (G) and the classifier selector (S ) in IRENE.
Meta-classifier Generator G:Table 4 shows the effect of increas-
ing the number of layers in IRENE’s meta-classifier generator block
(G). Increasing the number of layers from 1 to 2 improves zero-shot
P@1 by about 1%. However, in increasing G’s depth to 4, the perfor-
mance plateaus, which could be attributed to overfitting associated
with increased complexity of G. Additionally, we try out simpler
alternatives, namely sum and weighted sum. IRENE performs better
than these simpler alternatives by 24% P@1 in zero-shot evaluation
underscoring the significance of IRENE’s attention-based meta-
classifier generator.
Classifier Selector S:We we evaluate the effect of changing K,
the number of observed items retrieved by S, given an ANNS-based
S, on zero-shot performance. From the results presented in Table 4,
we observe that increasing Kbeyond 3 causes the performance to
initially plateau. Subsequently, increasing Kto 20 brings about a
decrease in performance. This is consistent with observations made
in Section 5, wherein smaller Kyield a tighter generalization bound
(and therefore, superior performance), as derived in Lemma 2.
Inputs to the Meta-classifier Generator G:Keeping the classi-
fier selectorSand meta-classifier generator Garchitecture fixed,
the inputs passed to Gwere changed to encoder representations z
of the selected observed items, instead of their classifiers wℓ. IRENE
with classifiers wℓof the selected observed items yields superior
3664Extreme Meta-Classification for Large-Scale Zero-Shot Retrieval KDD ’24, August 25–29, 2024, Barcelona, Spain
Table 4: Ablation study on meta-classifier generator G
and classifier selector Scomponent in NGAME+IRENE
on LF-WikiHierarchy-550K-10 dataset for zero-shot evalu-
ation. The depth Ddenotes the number of layers in the
transformer-based meta-classifier generator S, while Kde-
notes the numbers of neighbors selected by S. We observe
that that smaller values for K∈{2,3,6}and D∈{1,2}yield
superior results. We observe that setting D=1and K=3
works reasonably well, balancing performance and the com-
putational overhead in learning meta-classier generators.
Ablations P@1↑P@5↑R@10↑
IRENE ( D=1,K=3) 69.29 38.81 80.40Generator (G)D=2,K=3 70.36 39.06 80.39
D=4,K=3 70.71 39.11 80.27
Gas Sum, K=3 45.49 25.46 59.01
Gas wt. Sum, K=3 46.39 25.88 59.29Sele
ctor (S) D=1,K=1 68.98 38.56 80.11
D=1,K=2 69.34 38.74 80.25
D=1,K=6 69.99 39.12 80.79
D=1,K=20 69.07 38.57 79.80
Table 5: Performance comparison of NGAME and
NGAME+IRENE as the percentage of novel items (Novel
Ratio) in the WikiHierarchy dataset is varied from 10%
to 40%. While NGAME exhibits a significant decrease,
NGAME+IRENE is relatively more resilient.
Novel RatioNGAME NGAME+IRENE
P@1↑P@5↑R@10↑P@1↑P@5↑R@10↑
10% 66.19 59.25 27.08 91.33 86.67 40.09
20% 65.29 58.22 26.66 89.37 85.29 39.33
30% 63.59 57.12 26.09 89.50 84.64 38.48
40% 60.12 53.47 24.45 87.64 82.59 36.99
performance, with a significant margin of 4% on P@1. This un-
derscores the value of leveraging high-capacity classifiers of the
selected items, which contain beneficial information for represent-
ing a novel item.
Detailed discussions regarding these ablations are present in
Appendix D on the Supplementary Document.
Ratio of Novel Items: As we vary the percentage of novel items
in the LF-WikiHierarchy-550K dataset from 10% to 40%, We observe
that NGAME+IRENE is relatively more resilient to changes in the
ratio of novel items, in comparison to the base NGAME algorithm.
These results are summarized in Table 5.
Adapting to Few-Shot Scenarios - IRENE-OneShot: A plethora
of algorithms have been proposed to address few-shot scenarios,
with a particular emphasis on mitigating catastrophic learning. We
study the extreme case of this where only a single ground truth
query is revealed for an item. IRENE can be seamlessly extended
to utilize the additional data available for such one-shot items by
enhancing its classifier selector S. IRENE leverages the revealedTable 6: Performance evaluation of (NGAME+) IRENE-
OneShot, an extension for one-shot retrieval. One randomly
selected query is made available to all algorithms for the
novel items, and evaluation is done solely on the one-shot
items. NGAME-retrained involves training NGAME method
from scratch on the original training corpus along with the
revealed queries for previously unseen items. Even with
a significant training overhead for the NGAME-retrained
model (∼82 hours on LF-AmazonTitles-1.3M-10 and ∼43
hours on LF-Wikipedia-500K-10), IRENE consistently out-
performs the NGAME-retrained model by 1-2% across all
metrics without incurring any additional training overhead.
This is achieved by incorporating the new queries into the
classifier selector (at inference time) to refine the shortlist.
MethodLF-AmazonTitles-1.3M-10 LF-Wikipedia-500K-10
P@1 P@5 R@10 P@1 P@5 R@10
NGAME-retrained 30.55 15.39 36.48 47.37 15.33 66.37
SemSup-XC-OneShot 13.96 6.98 19.76 46.25 13.77 57.04
IRENE-OneShot 31.92 16.67 39.72 47.90 15.79 68.69
query of the one-shot item to fetch the nearest classifiers alongside
the item itself. A max-voting strategy is then employed to improve
the selection of observed classifiers over scenarios where only the
item text is considered for this purpose. This variant is denoted
as IRENE-OneShot. Remarkably, IRENE-OneShot can exploit the
revealed data to improve the prediction accuracy without having
the need to fine-tune the base model. To provide a comprehensive
defense against catastrophic forgetting, we explore a theoretical
baseline where NGAME is trained on a consolidated dataset com-
prising the initial training data for observed items and the data made
available for the one-shot items. Even when compared to this ideal
and optimal baseline, IRENE-OneShot was found to be superior in
terms of P@1 by about 1%. Further, compared to Semsup-XC, which
finetunes its encoder on the revealed data, IRENE-OneShot was at
least 10% better in R@10. These results highlight the effectiveness
of IRENE-OneShot, showcasing its capability to surpass models that
fine-tune their encoders with revealed data, all the while preserving
the base encoder, and reducing latency and complexity (cf. Table 6).
8 Conclusions
In this paper, we studied the problem of large-scale zero-shot re-
trieval and developed techniques to efficiently and accurately rep-
resent novel items. We proposed a new algorithmic framework,
EMMETT, for learning accurate meta-classifiers for novel items.
EMMETT is a generic framework wherein different architectural
choices and the training strategies can potentially yield algorithms
with varying accuracy and efficiency trade-offs, presenting ample
opportunities for future research explorations. We also developed
a new algorithm, IRENE, that is simple, practically deployable and
can significantly boost the performance of any Siamese encoder
with minimal overheads. Finally, we developed a novel theoretical
framework for analyzing the generalization performance in large-
scale zero-short retrieval. Comprehensive empirical validation and
online A/B tests in Sponsored Search application on a major search
engine demonstrated the utility of IRENE and EMMETT.
3665KDD ’24, August 25–29, 2024, Barcelona, Spain Sachin Yadav et al.
References
[1]P. Aggarwal, A. Deshpande, and K. Narasimhan. 2023. SemSup-XC: Semantic
Supervision for Zero and Few-shot Extreme Classification. In ICML.
[2]R. Agrawal, A. Gupta, Y. Prabhu, and M. Varma. 2013. Multi-label learning
with millions of labels: Recommending advertiser bid phrases for web pages. In
WWW.
[3] P. Awasthi, N. Frank, and M. Mohri. 2020. Adversarial Learning Guarantees for
Linear Hypotheses and Neural Networks. In Proceedings of the 37th International
Conference on Machine Learning, Vol. 119. 431–441. https://proceedings.mlr.
press/v119/awasthi20a.html
[4]R. Babbar and B. Schölkopf. 2017. DiSMEC: Distributed Sparse Machines for
Extreme Multi-label Classification. In WSDM.
[5]P. Bajaj, D. Campos, N. Craswell, L. Deng, J. Gao, X. Liu, R. Majumder, A. McNa-
mara, B. Mitra, T. Nguyen, M. Rosenberg, X. Song, A. Stoica, S. Tiwary, and T.
Wang. 2018. MS MARCO: A Human Generated MAchine Reading COmprehen-
sion Dataset. arXiv:1611.09268 [cs.CL]
[6]K. Bhatia, K. Dahiya, H. Jain, A. Mittal, Y. Prabhu, and M. Varma. 2016. The ex-
treme classification repository: Multi-label datasets and code. http://manikvarma.
org/downloads/XC/XMLRepository.html
[7]A. Buvanesh, R. Chand, J. Prakash, B. Paliwal, M. Dhawan, N. Madan, D. Hada, V.
Jain, S. Mehta, Y. Prabhu, M. Gupta, R. Ramjee, and M. Varma. 2024. Enhancing
Tail Performance in Extreme Classifiers by Label Variance Reduction. In The
Twelfth International Conference on Learning Representations. https://openreview.
net/forum?id=6ARlSgun7J
[8]W.-C. Chang, D. Jiang, H.-F. Yu, C. H. Teo, J. Zhang, K. Zhong, K. Kolluri, Q. Hu,
N. Shandilya, V. Ievgrafov, J. Singh, and I. S. Dhillon. 2021. Extreme Multi-label
Learning for Semantic Matching in Product Search. In Proceedings of the 27th
ACM SIGKDD Conference on Knowledge Discovery & Data Mining. 2643–2651.
[9]K. Dahiya, A. Agarwal, D. Saini, K. Gururaj, J. Jiao, A. Singh, S. Agarwal, P. Kar,
and M. Varma. 2021. SiameseXML: Siamese Networks meet Extreme Classifiers
with 100M Labels. In ICML.
[10] K. Dahiya, N. Gupta, D. Saini, A. Soni, Y. Wang, K. Dave, J. Jiao, K. Gururaj, P. Dey,
A. Singh, D. Hada, V. Jain, B. Paliwal, A. Mittal, S. Mehta, R. Ramjee, S. Agarwal,
P. Kar, and M. Varma. 2023. NGAME: Negative Mining-aware Mini-batching for
Extreme Classification. In WSDM.
[11] K. Dahiya, D. Saini, A. Mittal, A. Shaw, K. Dave, A. Soni, H. Jain, S. Agarwal, and
M. Varma. 2021. DeepXML: A Deep Extreme Multi-Label Learning Framework
Applied to Short Text Documents. In WSDM.
[12] K. Dahiya, S. Yadav, S. Sondhi, D. Saini, S. Mehta, J. Jiao, S. Agarwal, P. Kar, and M.
Varma. 2023. Deep encoders with auxiliary parameters for extreme classification.
InKDD.
[13] L. Gao, X. Ma, J. Lin, and J. Callan. 2023. Precise Zero-Shot Dense Retrieval with-
out Relevance Labels. In Proceedings of the 61st Annual Meeting of the Association
for Computational Linguistics (Volume 1: Long Papers). 1762–1777.
[14] N. Gupta, S. Bohra, Y. Prabhu, S. Purohit, and M. Varma. 2021. Generalized
Zero-Shot Extreme Multi-label Learning. In Proceedings of the ACM SIGKDD
Conference on Knowledge Discovery and Data Mining.
[15] N. Gupta, P. H. Chen, H.-F. Yu, Cho-J. Hsieh, and I. S. Dhillon. 2022. ELIAS:
End-to-End Learning to Index and Search in Large Output Spaces. In NeurIPS.
[16] H. Jain, V. Balasubramanian, B. Chunduri, and M. Varma. 2019. Slice: Scalable
Linear Extreme Classifiers trained on 100 Million Labels for Related Searches. In
WSDM.
[17] V. Jain, J. Prakash, D. Saini, J. Jiao, R. Ramjee, and M. Varma. 2023. Renée: End-to-
end training of extreme classification models. Proceedings of Machine Learning
and Systems (2023).
[18] T. Jiang, D. Wang, L. Sun, H. Yang, Z. Zhao, and F. Zhuang. 2021. LightXML:
Transformer with Dynamic Negative Sampling for High-Performance Extreme
Multi-label Text Classification. In AAAI.
[19] K. S. Jones. 2021. A statistical interpretation of term specificity and its application
in retrieval. J. Documentation 60 (2021), 493–502. https://api.semanticscholar.
org/CorpusID:2996187
[20] V. Karpukhin, B. Oguz, S. Min, P. Lewis, L. Wu, S. Edunov, D. Chen, and W.-T.
Yih. 2020. Dense Passage Retrieval for Open-Domain Question Answering. In
EMNLP.
[21] S. Khandagale, H. Xiao, and R. Babbar. 2020. Bonsai: diverse and shallow trees
for extreme multi-label classification. ML(2020).[22] S. Kharbanda, A. Banerjee, E. Schultheis, and R. Babbar. 2022. CascadeXML:
Rethinking Transformers for End-to-end Multi-resolution Training in Extreme
Multi-label Classification. In NeurIPS.
[23] O. Khattab and M. Zaharia. 2020. Colbert: Efficient and effective passage search
via contextualized late interaction over bert. In SIGIR.
[24] Y. Liu, X. Gao, and L. Gao, Q. Han. J. Shao. 2020. Label-activating framework for
zero-shot learning. In Neural Networks, Vol. 121. 1–9.
[25] T. K. R. Medini, Q. Huang, Y. Wang, V. Mohan, and A. Shrivastava. 2019. Extreme
Classification in Log Memory using Count-Min Sketch: A Case Study of Amazon
Search with 50M Products. In NeurIPS.
[26] T. Mensink, E. Gavves, and C. G. M. Snoek. 2014. COSTA: Co-Occurrence Statistics
for Zero-Shot Classification. In CVPR.
[27] A. Mittal, N. Sachdeva, S. Agrawal, S. Agarwal, P. Kar, and M. Varma. 2021.
ECLARE: Extreme Classification with Label Graph Correlations. In WWW.
[28] M. Mohri, A. Rostamizadeh, and A. Talwalkar. 2012. Foundations of Machine
Learning. MIT Press.
[29] Y. Qu, Y. Ding, J. Liu, K. Liu, R. Ren, W. X. Zhao, D. Dong, H. Wu, and H. Wang.
2021. RocketQA: An Optimized Training Approach to Dense Passage Retrieval
for Open-Domain Question Answering.
[30] S. Robertson and H. Zaragoza. 2009. The Probabilistic Relevance Framework:
BM25 and Beyond. Foundations and Trends in Information Retrievals 3, 4 (April
2009), 333–389. https://doi.org/10.1561/1500000019
[31] B. Romera-Paredes and P. H. S. Torr. 2015. An Embarrassingly Simple Approach
to Zero-shot Learning. In ICML.
[32] D. Saini, A.K. Jain, K. Dave, J. Jiao, A. Singh, R. Zhang, and M. Varma. 2021. GalaXC:
Graph Neural Networks with Labelwise Attention for Extreme Classification. In
WWW.
[33] T. Shen, G. Long, X. Geng, C. Tao, T. Zhou, and D. Jiang. 2023. Large Language
Models are Strong Zero-Shot Retriever. arXiv:2304.14233
[34] D. Simig, F. Petroni, P. Yanki, K. Popat, C. Du, S. Riedel, and M. Yazdani. 2022.
Open Vocabulary Extreme Classification Using Generative Models. In Findings
of the Association for Computational Linguistics: ACL 2022. 1561–1583. https:
//aclanthology.org/2022.findings-acl.123
[35] Aditi Singh, Suhas Jayaram Subramanya, Ravishankar Krishnaswamy, and Har-
sha Vardhan Simhadri. 2021. FreshDiskANN: A Fast and Accurate Graph-Based
ANN Index for Streaming Similarity Search. arXiv:2105.09613 [cs.IR]
[36] J. J. Subramanya, F. Devvrit, H. V. Simhadri, R. Krishnawamy, and R. Kadekodi.
2019. DiskANN: Fast accurate billion-point nearest neighbor search on a single
node. Advances in Neural Information Processing Systems 32 (2019).
[37] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, L. Kaiser,
and I. Polosukhin. 2017. Attention is All you Need. In Advances in Neural Infor-
mation Processing Systems, Vol. 30. https://proceedings.neurips.cc/paper_files/
paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf
[38] L. Wang, N. Yang, and F. Wei. 2023. Query2doc: Query Expansion with Large
Language Models. In Proceedings of the 2023 Conference on Empirical Methods in
Natural Language Processing (EMNLP), Houda Bouamor, Juan Pino, and Kalika
Bali (Eds.). 9414–9423. https://doi.org/10.18653/v1/2023.emnlp-main.585
[39] J. Xin, C. Xiong, A. Srinivasan, A. Sharma, D. Jose, and P. Bennett. 2022. Zero-Shot
Dense Retrieval with Momentum Adversarial Domain Invariant Representations.
InFindings of the Association for Computational Linguistics: ACL 2022. 4008–4020.
[40] L. Xiong, C. Xiong, Y. Li, K.-F. Tang, J. Liu, P. Bennett, J. Ahmed, and A. Overwijk.
2021. Approximate nearest neighbor negative contrastive learning for dense text
retrieval. In ICLR.
[41] Y. Xiong, W.-C. Chang, C.-J. Hsieh, H.-F. Yu, and I. Dhillon. 2021. Extreme
Zero-Shot Learning for Extreme Text Classification. arXiv:2112.08652 [cs.LG]
[42] Han-Jia Ye, Hexiang Hu, De-Chuan Zhan, and Fei Sha. [n. d.]. Few-Shot Learn-
ing via Embedding Adaptation With Set-to-Set Functions. In Proceedings of the
IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR).
[43] C. Yun, S. Bhojanapalli, A. Singh Rawat, S. Reddi, and S. Kumar. 2020. Are
Transformers universal approximators of sequence-to-sequence functions?. In
International Conference on Learning Representations. https://openreview.net/
forum?id=ByxRM0Ntvr
[44] J. Zhang, W. C. Chang, H. F. Yu, and I. Dhillon. 2021. Fast multi-resolution
transformer fine-tuning for extreme multi-label text classification. In NeurIPS.
[45] W. X. Zhao, J. Liu, R. Ren, and J.-R. Wen. 2023. Dense Text Retrieval based on
Pretrained Language Models: A Survey. ACM Trans. Inf. Syst. (2023).
3666