PSMC: Provable and Scalable Algorithms for Motif Conductance
Based Graph Clustering
Longlong Lin
College of Computer and Information
Science, Southwest University
Chongqing, China
longlonglin@swu.edu.cnTao Jia
College of Computer and Information
Science, Southwest University
Chongqing, China
tjia@swu.edu.cnZeli Wang
Chongqing University of Posts and
Telecommunications
Chongqing, China
zlwang@cqupt.edu.cn
Jin Zhao
School of Computer Science and
Technology, HuaZhong University of
Science and Technology
Wuhan, China
zjin@hust.edu.cnRong-Hua Li
Shenzhen Institute of Technology
Shenzhen, China
Beijing Institute of Technology
Beijing, China
lironghuabit@126.com
ABSTRACT
Higher-order graph clustering aims to partition the graph using fre-
quently occurring subgraphs (i.e., motifs), instead of the lower-order
edges, as the atomic clustering unit, which has been recognized as
the state-of-the-art solution in ground truth community detection
and knowledge discovery. Motif conductance is one of the most
promising higher-order graph clustering models due to its strong
interpretability. However, existing motif conductance based graph
clustering algorithms are mainly limited by a seminal two-stage
reweighting computing framework, needing to enumerate all mo-
tif instances to obtain an edge-weighted graph for partitioning.
However, such a framework has two-fold vital defects: (1) It can
only provide a quadratic bound for the motif with three vertices,
and whether there is provable clustering quality for other motifs is
still an open question. (2) The enumeration procedure of motif in-
stances incurs prohibitively high costs against large motifs or large
dense graphs due to combinatorial explosions. Besides, expensive
spectral clustering or local graph diffusion on the edge-weighted
graph also makes existing methods unable to handle massive graphs
with millions of nodes. To overcome these dilemmas, we propose a
Provable and Scalable MotifConductance algorithm PSMC, which
has a fixed andmotif-independent approximation ratio for any motif.
Specifically, PSMC first defines a new vertex metric Motif Resident
based on the given motif, which can be computed locally. Then, it
iteratively deletes the vertex with the smallest motif resident value
very efficiently using novel dynamic update technologies. Finally, it
outputs the locally optimal result during the above iterative process.
To further boost efficiency, we propose several effective bounds to
estimate the motif resident value of each vertex, which can greatly
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
KDD ’24, August 25–29, 2024, Barcelona, Spain
©2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 979-8-4007-0490-1/24/08
https://doi.org/10.1145/3637528.3671666reduce computational costs. Empirical results on real-life and syn-
thetic demonstrate that our proposed algorithms achieve 3.2 ∼32
times speedup and improve the quality by at least 12 times than
the state-of-the art baselines.
CCS CONCEPTS
•Mathematics of computing →Graph algorithms.
KEYWORDS
Higher-order Graph Clustering; Motif Conductance
ACM Reference Format:
Longlong Lin, Tao Jia, Zeli Wang, Jin Zhao, and Rong-Hua Li. 2024. PSMC:
Provable and Scalable Algorithms for Motif Conductance Based Graph
Clustering. In Proceedings of the 30th ACM SIGKDD Conference on Knowledge
Discovery and Data Mining (KDD ’24), August 25–29, 2024, Barcelona, Spain.
ACM, New York, NY, USA, 11 pages. https://doi.org/10.1145/3637528.3671666
1 INTRODUCTION
Graph clustering is a fundamental problem in machine learning
and enjoys numerous applications, including image segmentation
[50], anomaly detection [ 24], parallel computing [ 12], and graph
representation learning [ 11,32,66,68]. Therefore, many traditional
graph clustering models have been proposed in the literature, such
as null model based (e.g., modularity [ 46]), edge cut based (e.g., ratio
cut or normalized cut [ 58]), and subgraph cohesiveness based (e.g.,
k-core or k-truss [ 9]). Informally, these models partition all vertices
into several clusters, satisfying the vertices within the same cluster
have more edges than the vertices in different clusters [54].
Nevertheless, these traditional graph clustering models ignore
the significant motif connectivity patterns (i.e., small frequently
occurring subgraphs), which are regarded as indispensable for mod-
eling and understanding the higher-order organization of complex
networks [ 45,64]. Unlike dyadic edges, each motif (involves more
than two nodes) indicates the unique interaction behavior among
vertices and represents some particular functions. To name a few,
the triangle is the stable relationship cornerstone of social networks
[36,52]. Cycles hint at some money laundering events in financial
markets [ 35]. Feed-forward loops are basic transcription units in
 
1793
KDD ’24, August 25–29, 2024, Barcelona, Spain Longlong Lin, Tao Jia, Zeli Wang, Jin Zhao, and Rong-Hua Li
genetic networks [ 44]. As a consequence, adopting such mesoscopic
level motif as the atomic clustering unit has been recognized as the
state-of-the-art (SOTA) solution in ground truth community detec-
tion and knowledge discovery [ 13,52,62]. Such clustering methods
are typically named higher-order graph clustering, which aims at
capturing the higher-order community structures with dense mo-
tifs instead of edges [ 4]. This paper focuses on higher-order graph
clustering on massive graphs with millions of nodes. Thus, perfect
solutions must be highly scalable and utility.
Numerous higher-order graph clustering models have been pro-
posed in the literature [ 2,4,55] (Section 5). Perhaps, the most rep-
resentative and effective model is the motif conductance due to its
strong interpretability and solid theoretical foundation [ 4] (Section
2.1). To be specific, motif conductance is the variant of conductance
(conductance is an edge-based clustering model [ 21,23,70]), which
indicates the ratio of the number of motif instances going out the
cluster to the number of motif instances within the cluster. As a
result, smaller motif conductance implies better higher-order clus-
tering quality [ 4,56,65,72,73]. However, identifying the result with
the smallest motif conductance raises significant challenges due to
its NP-hardness [ 4]. Therefore, many approximate or heuristic algo-
rithms have been proposed to either improve the clustering quality
or reduce the computational costs. For example, the Science paper
[4] proposed a seminal two-stage reweighting framework. In the
first stage, the input graph Gis transformed into an edge-weighted
graphGM, in which the weight of each edge eis the number of
motif instances eparticipates in. In the second stage, the traditional
spectral clustering is used to partition GM. However, such a seminal
framework can only obtain provable clustering qualities for the
motif consisting of three vertices [ 4]. Thus, whether the motif with
four or more vertices (such motifs are more realistic [ 47,67]) has a
provable clustering quality is still an open question. On top of that,
the framework has to enumerate all motif instances in advance and
computes the eigenvector of normalized Laplacian matrix of GM,
resulting in prohibitively high time and space costs (Section 2.2).
To improve the efficiency, some local graph diffusion algorithms
are proposed to replace the eigenvector calculation with various
random walk distributions (e.g., Personalized PageRank and higher-
order markov chain) (Section 2.2). However, these algorithms are
heuristic, and their clustering qualities are heavily dependent on
many hard-to-tune parameters and seeding strategies. So, their per-
formance is unstable and in most cases very poor, as demonstrated
in our experiments. Recently, Huang et al. [ 31] pointed out that
almost all existing solutions are limited by the above two-stage
reweighting framework, and then they proposed an adaptive sam-
pling method to estimate the weights of the edges for reducing
the computational time. However, this adaptive sampling method
introduces randomness, leading to inaccurate results. Therefore,
obtaining provable and scalable algorithms for motif conductance
remains a challenging task.
To overcome the above limitations, we propose a Provable and
Scalable MotifConductance algorithm PSMC. Since the purpose
of optimizing motif conductance is to obtain target clusters rather
than to obtain the intermediate edge-weighted graph GM, it is not
necessary to blindly spend much time on getting precise GM. In-
stead, we deeply analyze the functional form of motif conductance(Lemma 3) and iteratively optimize motif conductance starting from
each vertex. Specifically, we first define a new vertex metric Mo-
tif Resident (Definition 4), which can be computed locally. Then,
PSMC iteratively deletes the vertex with the smallest motif resident
value very efficiently using novel dynamic update technologies. Fi-
nally, PSMC returns the cluster with the smallest motif conductance
during the above iterative process. As a consequence, PSMC is to
integrate the computation and partition of edge-weighted graph
GMin an iterative algorithm, thus eliminating the need for expen-
sive spectral clustering or local graph diffusion. Besides, we also
theoretically prove that PSMC has a fixed andmotif-independent
approximation ratio (Theorem 3). In other words, PSMC can out-
put a fixed approximation ratio for any given motif, which solves
the open question posed by the previous two-stage reweighting
framework. Particularly, when the given motif has three vertices,
PSMC improves the well-known quadratic bound (Table 1). On the
other hand, the motif resident of vertex uimplicitly depends on
the number of motif instances uparticipates in, causing PSMC also
indirectly calculates all motif instances. To further boost efficiency,
we develop several effective bounds to estimate the motif resident
of each vertex via the well-known Turan Theorem [ 57] and colorful
h-star degree [ 22]. We highlight our main contributions as follows.
A Novel Computing Framework with Accuracy Guarantee.
We introduce a provable and scalable motif conductance algorithm,
called PSMC, based on the proposed vertex metric Motif Resident.
PSMC has two striking features. One is that it is a novel high-order
graph clustering framework by integrating the computation and
partition of edge-weighted graph in an iterative algorithm, reducing
the computational costs. The other is that it can output a fixed and
motif-independent approximation ratio for any given motif, while
the existing SOTA frameworks cannot.
Several Effective Optimization Strategies. To further boost ef-
ficiency, we develop several dynamic update technologies to in-
crementally maintain the motif resident of each vertex when its
neighbor is deleted, without recomputing the motif resident from
scratch. Besides, with the help of Turan Theorem and colorful h-star
degree, several effective bound estimation strategies are proposed
to obtain a better trade-off between efficiency and accuracy.
Extensive Experiments. We conduct extensive experiments on
nine datasets (five real-world graphs and four synthetic graphs)
and eight competitors to evaluate the scalability and effectiveness
of our proposed solutions. These empirical results show that our
algorithms achieve 3.2 ∼32 times speedup and improve the quality
by at least 12 times than baselines. Besides, our algorithms realize
up to an order of magnitude memory reduction when contrasted
with baselines.
2 PRELIMINARIES
2.1 Problem Formulation
Given an unweighted and undirected graph G(V,E)1, we use Vand
Eto represent the vertex set and the edge set of G, respectively.
We denote|V|=n(resp.|E|=m) as the number of vertices (resp.
edges) of G. Let GS(S,ES)be the induced subgraph induced by
1For simplicity, we consider the unweighted and undirected graph in this work, while
our proposal can be easily extended to the weighted or directed graphs.
 
1794PSMC: Provable and Scalable Algorithms for Motif Conductance Based Graph Clustering KDD ’24, August 25–29, 2024, Barcelona, Spain
V.S.
4 edge cuts
3 motif cuts5 edge cuts
2 motif cutsEdgeTriangle
Figure 1: Illustration of the traditional edge-based conduc-
tance and the motif conductance on a synthetic graph. There
are 47 edges and 60 triangles. The blue dotted line indicates
the optimal cut when the motif is an edge and the corre-
sponding conductance is4
min{42,52}. The green dotted line
represents the optimal cut when the motif is a triangle and
the corresponding triangle conductance is2
min{116,64}. Motif
conductance is more likely to preserve motif instances com-
pared with edge-based conductance.
SiffS⊆VandES={(u,v)∈E|u,v∈S}. We use NS(v)=
{u∈S|(u,v)∈E}to denote the neighbors of vinS. We use Mto
denote the use-initiated query motif, which is a frequently occurring
interaction pattern (i.e., significant subgraph) in complex networks.
For simplicity, GS∈Mmeans that GSis an instance of M. Namely,
GS∈MiffGSis isomorphic to M2. We let k(M)be the order of
M, which is the number of vertices involved in M. For example, an
edge is a second-order motif and a triangle is a three-order motif.
Following existing research work [ 20,55,65], unless otherwise
stated, we also take clique as the motif by default in this paper. A
high-level definition of higher-order graph clustering is as follows.
Definition 1 (higher-order graph clustering). For an un-
weighted and undirected graph G(V,E)and a motif M, the problem
of the higher-order graph clustering aims to find a high-quality cluster
C⊆Vhas the following properties: (1) GCcontains many instances
ofM; (2) there are few motif instances that cross GCandGV\C.
Based on the intuition of Definition 1, we use the most represen-
tative and effective motif conductance [4,56,65,72,73] to measure
the clustering quality of an identified cluster C.
Definition 2 (motif conductance). For an unweighted and
undirected graph G(V,E)and a motif M, the motif conductance of
Cis defined as ϕM(C)=cutM(C)
min{volM(C),volM(V\C)}.
cutM(C)=|{GS∈M|S∩C,∅,S∩(V\C),∅}| (1)
volM(C)=X
u∈C|{GS∈M|u∈S}| (2)
Where cutM(C)is the number of motif instance with at least
one vertex in Cand at least one vertex in V\C, andvolM(C)(resp.
volM(V\C)) is the number of the motif instance the vertices in C
(resp. V\C) participate in. When Mis an edge, the motif conduc-
tance degenerates into classic conductance [ 21,23,40]. Thus, edges
that do not participate in any motif instances do not contribute to
2G(V1,E1)andG(V2,E2)are isomorphic if there exists a bijection f:V1→V2such
that (u,v)∈E2iff(f(u),f(v))∈E2.the motif conductance. Namely, a cluster with many edges but few
motif instances may also have poor motif conductance. Therefore,
motif conductance has strong interpretability and can improve the
quality of the resulting cluster by focusing on the particular mo-
tifs that are important higher-order structures of a given network
[4]. Figure 1 shows the difference between the traditional edge-
based conductance and the motif conductance. Note that we have
ϕM(C)=ϕM(V\C)by Definition 2.
Problem Statement. Given an unweighted and undirected graph
G(V,E)and a motif M, the goal of motif conductance based graph
clustering is to find a vertex subset S∗⊆V, satisfying volM(S∗)≤
volM(V\S∗)andϕM(S∗)≤ϕM(S)for any S⊆V.ϕ∗
Mstands for
ϕM(S∗)for brevity.
2.2 Existing Solutions and Their Shortcomings
In this subsection, we review several SOTA motif conductance
algorithms, which can be roughly divided into two categories: seed-
free global clustering and seed-dependent local clustering.
2.2.1 Seed-free global clustering. Seed-free global clustering iden-
tifies the higher-order clusters by calculating the eigenvector of the
normalized Laplacian matrix of the edge-weighted graph GM, in
which the weight of each edge e∈GMis the number of motif in-
stances eparticipates in. For example, Benson et al. [ 4] proposed the
following two-stage higher-order spectral clustering (HSC ). Specif-
ically, HSC first obtains the normalized Laplacian matrix Lby
enumerating motif instances. Then, HSC computes the eigenvector
xof the second smallest eigenvalue of Lto execute the sweep pro-
cedure. Namely, it sorts all entries in xsuch that x1≤x2≤...≤xn
and outputs S=arg minϕ(Si), in which Si={x1,x2, ...,xi}. The
following theorems are important theoretical basis of HSC.
Theorem 1 ([ 4]).Given a graph G(V,E)and a motif M, for any
S⊆V, we have
ϕM(S)=ϕGM(S), i f k (M)=3
ϕGM(S)−P
mi∈MI(|mi∩S|=2 )P
u∈SDuu,i f k (M)=4(3)
WhereϕGM(S)is the edge-based conductance of Sin terms of the
weighted graphGMandI(.)is the indicator function. Note that when
k(M)>4, the relationship between ϕM(S)andϕGM(S)is unclear.
Theorem 2 (Cheeger ineqality [ 4]).Given a graph G(V,E)
and a motif Mwith k(M)=3, let Sbe the vertex subset returned
by HSC, we have ϕ∗
M≤ϕM(S)≤2q
ϕ∗
M, in whichϕ∗
Mis the optimal
motif conductance.
Discussions. Note that HSC can only derive the Cheeger inequality
for motifs consisting of three vertices. However, it has not been
proven whether there is quality guarantee for motifs with four or
more vertices. On top of that, since HSC needs to enumerate motif
instances in advance and calculate the eigenvector of L, its time
complexity is O(k(δ
2)k−2m)+O(n3)and space complexity is O(n2)
[4], resulting in poor scalability.
2.2.2 Seed-dependent local clustering. Seed-dependent local clus-
tering executes the local graph diffusion from the given seed vertex
qto identify higher-order clusters. Higher-order markov chain
based random walk [ 61] and Personalized PageRank based random
 
1795KDD ’24, August 25–29, 2024, Barcelona, Spain Longlong Lin, Tao Jia, Zeli Wang, Jin Zhao, and Rong-Hua Li
Table 1: A comparison of motif conductance based graph clustering. ϕ∗
M∈(0,1]is the smallest motif conductance value. k=
k(M)is the order of M.δis the degeneracy and is often very small in real-life graphs [39]. tmaxandbare the maximum iteration
number and motif volum parameter of HOSPLOC. ϵis the error tolerance of MAPPR to execute forward push. PSMC+ isPSMC
with estimate strategies proposed in Section 3.3. ×represents the corresponding method has no accuracy guarantee.
Methods Accuracy Guarantee Time Complexity Space Complexity Remark
HSC [4]O(q
ϕ∗
M)fork=3O(k(δ
2)k−2m)+O(n3)O(n2)Eigenvector-based
×fork>3
HOSPLOC [72, 73] × O(tmax2bk
(ϕ∗
M)2klog3km) O(nk) Higher-order Markov Chain-based
MAPPR [65] × O(k(δ
2)k−2m)+O(log1
ϵ
ϵ) O(n2) Personalized PageRank-based
PSMC (This paper) O(1/2+1/2ϕ∗
M)for any k O(k(δ
2)k−2m) O(m+n) Motif Resident -based
PSMC+ (This paper) × O(km ) O(m+n) Motif Resident -based
walk [ 59,60] are two well-known local graph diffusion methods.
The former uses state transition tensors to simulate the long-term
dependence of states. The latter models a random walk with restart
over the edge-weighted graph GM. Based on these backgrounds,
Zhou et al. [ 72,73] and Yin et al. [ 65] proposed HOSPLOC and
MAPPR to obtain higher-order clusters, respectively. To be spe-
cific, they first compute the probability distribution πat the end
of the corresponding graph diffusion (i.e.,truncated higher-order
markov random walk or Personalized PageRank random walk), and
lety=πD−1. Then, they run the sweep procedure. Namely, it
sorts all non-zero entries in ysuch thaty1≥y2≥...≥ysup (y)
(sup (y)is the number of the non-zero entries in y), and outputs
S=arg minϕ(Si), in which Si={y1,y2, ...,yi}.
Discussions. Since seed-dependent local clustering methods aim
to identify the higher-order clusters to which the given seed vertex
qbelongs, they only have locally-biased Cheeger-like quality for
the motif consisting of three vertices [ 65,72,73]. Namely, seed-
dependent local clustering methods do not give the theoretical gap
toϕ∗
M. Besides, their clustering qualities are heavily dependent on
many hard-to-tune parameters and seeding strategies. Practically,
their performance is unstable and even find degenerate solutions,
as demonstrated in our experiments.
2.2.3 The Shortcomings of Existing Solutions. Table 1 summarizes
the above SOTA motif conductance algorithms for comparison. By
Table 1, we know that the complexities of our solutions are lower
than the baselines. This is because baselines need to enumerate all
motif instances in advance, and then execute the expensive spectral
clustering or local graph diffusion. However, we are to integrate the
enumeration and partitioning in an iterative algorithm, which can
greatly reduce computational costs. On top of that, our PSMC can
output O(1/2+1/2ϕ∗
M)accuracy guarantee for any size of motif,
while baselines cannot. Note that although the proposed PSMC+
has no accuracy guarantee (the practical performance of PSMC+
is comparable to the baselines in our empirical results), it has the
excellent property of near-linear time complexity, which is vital for
dealing with massive graphs with millions of nodes.
3 PSMC: THE PROPOSED SOLUTION
In this section, we devise a Provable and Scalable MotifConductance
algorithm PSMC, which aims to output a high-quality cluster. Itis important to highlight that PSMC has the capability to provide
fixed andmotif-independent approximation ratio for any motif. This
significant feature addresses and resolves the open problem raised
by [4]. Then, we propose novel dynamic update technologies and
effective bounds to further boost efficiency of PSMC.
3.1 The PSMC Algorithm
Recall that our problem is to obtain a higher-order cluster rather
than to obtain the intermediate edge-weighted graph GM, thus it
is not necessary to blindly spend much time on getting precise
GM. Based on in-depth observations, we reformulate motif conduc-
tance and propose a novel computing framework, which iteratively
optimized motif conductance starting from each vertex. Before de-
scribing our proposed algorithms, several useful definitions are
stated as follows.
Definition 3 (Motif Degree). Given an unweighted and undi-
rected graph G(V,E)and a motif Mwith k=k(M), the motif degree
ofuis defined as M(u)=|{GS∈M|u∈S}|. For a positive integer
1≤j≤k, we letMC
j(u)=|{GS∈M|u∈S,|C∩S|=j}|.
Definition 4 (motif resident). Given an unweighted and undi-
rected graph G(V,E), a motif Mwith k=k(M), and a vertex sub-
setS, the motif resident of u∈Sw.r.t. GSis defined as MrS(u)=
M(u)+MS
k(u)−MS
1(u)
M(u).
Based on these definitions, we develop PSMC with three-stage
computing framework (Algorithm 1). In Stage 1, we compute the
motif resident value for each vertex (Lines 1-7). In Stage 2, we
iteratively remove the vertex with the smallest motif resident (Lines
8-11). Such an iterative deletion process is referred to as a peeling
process. In Stage 3, we output the result with the smallest motif
conductance during the peeling process (lines 12-13). Next, we
prove that this simple PSMC algorithm can produce the high-quality
cluster with fixed andmotif-independent approximation ratio.
Lemma 1 (Monotonicity). Given an unweighted and undirected
graph G(V,E), a motif Mwithk=k(M), and two vertex subset Sand
H, we have MH
k(u)≥MS
k(u)andMH
1(u)≤MS
1(u)ifu∈S⊆H.
Lemma 2. Given an unweighted and undirected graph G(V,E), a
motifMwith k=k(M), and a vertex subset S, we have cutM(S\
{u})=cutM(S)−MS
1(u)+MS
k(u).
 
1796PSMC: Provable and Scalable Algorithms for Motif Conductance Based Graph Clustering KDD ’24, August 25–29, 2024, Barcelona, Spain
Algorithm 1 P rovable and Scalable MotifConductance (PSMC )
Input: A graph G(V,E)and a motif Mwith k=k(M)
Output : A higher-order cluster ˆSwith fixed and motif-
independent approximation ratio
1:MI←all the motif instances of M
2:Initializing the motif degree M(u)=0 for any u∈V
3:foreach motif instance mi∈MIdo
4: foreach edge (u,v)∈mido
5: M(u)+ =1;M(v)+ =1
6:i←1;Si←V;MSi
k(u)=M(u)andMSi
1(u)=0 for u∈Si
7:MrSi(u)←M(u)+MSi
k(u)−MSi
1(u)
M(u)for any u∈Si
8:while Si,∅do
9: u←arg min{MrSi(u)|u∈Si}
10: i←i+1
11: Si←Si−1\{u}
12:ˆS← arg min
S∈{S1,S2, ...,Sn}{ϕM(S)|volM(S)≤volM(V\S)}
13:return ˆS
LetдM(S)=(P
u∈SM(u)−cutM(S))/(P
u∈SM(u))and assume that
the larger of дM(S), the better the quality of S. LetHSbe the optimal
vertex set for дM(.). That is,дM(HS)≥дM(S)for any vertex subset
S⊆V. The following two lemmas are key theoretical basis of PSMC.
Lemma 3 (Reformulation of Motif Conductance). Given an
unweighted and undirected graph G(V,E), a motif Mwithk=k(M),
and a vertex subset S, we haveϕM(S)=1−дM(S)ifvolM(S)≤
volM(V\S).
Lemma 4. Given an unweighted and undirected graph G(V,E), a
motifMwith k=k(M), we have MrHS(u)≥дM(HS)for any u∈HS.
Implications of Lemma 3 and Lemma 4. SinceдM(HS)≥дM(S)
for any S⊆V, Lemma 3 indicates that ϕM(HS)=ϕM(S∗)where S∗is
our optimal vertex set. This is because that S∗satisfiesvolM(S∗)≤
volM(V\S∗), thus the condition of volM(S)≤volM(V\S)in Lemma
3 is always true for our problem. Please see Problem Statement in
Section 2.1 for details. Meanwhile, Lemma 4 indicates that the motif
resident of any vertex u∈HSw.r.tHSis at leastдM(HS). Namely, the
motif resident of any vertex in S∗w.r.t S∗is at least 1−ϕ∗
M. Based
on these implications, we can derive the following theorem to local
a cluster with fixed andmotif-independent approximation ratio.
Theorem 3. Algorithm 1 can identify a higher-order cluster with
motif conductance 1/2+1/2ϕ∗
M.
Proof. According to the definitions of cutM(C),M(u), andMC
j(u),
we know that M(u)=kP
j=1MC
j(u)andcutM(C)=P
u∈Ck−1P
j=11
jMC
j(u).
LetHSis the optimal vertex set for дM(.). In Lines 8-11, Algorithm
1 executes the peeling process. That is, in each round, it greedily
deletes the vertex with the smallest motif resident. Consider the
round twhen the first vertex vofHSis deleted. Let Vtbe the vertex
set from the beginning of round t.HSis the subset of Vtbecausev
is the first deleted vertex of HS. This implies that min
u∈VtMrVt(u)=MrVt(v)=M(v)+MVt
k(v)−MVt
1(v)
M(v)≥M(v)+MHS
k(v)−MHS
1(v)
M(v)=MrHS(v)≥
дM(HS)according to Lemma 4 and Lemma 1. Therefore, for any
u∈Vt, we haveM(u)+MVt
k(u)−MVt
1(u)
M(u)≥дM(HS). Furthermore,
дM(Vt)=P
u∈VtM(u)−cutM(Vt)
P
u∈VtM(u)=P
u∈Vt(M(u)−k−1P
j=11
jMVt
j(u))
P
u∈VtM(u)(4)
=P
u∈Vt(k−1P
j=2(1−1
j)MVt
j(u)+MVt
k(u))
P
u∈VtM(u)≥P
u∈Vt(k−1P
j=21
2MVt
j(u)+MVt
k(u))
P
u∈VtM(u)(5)
=P
u∈Vt(k−1P
j=2MVt
j(u)+2·MVt
k(u))
2P
u∈VtM(u)=P
u∈Vt(M(u)+MVt
k(u)−MVt
1(u))
2P
u∈VtM(u)(6)
≥1
2P
u∈VtдM(HS)·M(u)
P
u∈VtM(u)=1
2дM(HS). (7)
Since Algorithm 1 maintains the optimal solution during the peel-
ing process in Lines 12-13, ϕM(ˆS)=1−дM(ˆS)≤1−дM(Vt)≤
1−дM(HS)
2due to Lemma 3. On the other hand, According to the defi-
nition of HS, we know that дM(HS)≥дM(S∗), in which S∗is the vertex
set with optimal motif conductance. Thus, ϕM(ˆS)≤1−дM(HS)
2≤
1−дM(S∗)
2=1−1−ϕM(S∗)
2. Namely,ϕM(ˆS)≤1/2+1/2ϕM(S∗). As
a result, Algorithm 1 can identify a higher-order cluster with motif
conductance 1 /2+1/2ϕ∗
M. □
3.2 Dynamic Update of Motif Resident
The computational challenge of Algorithm 1 is how to incrementally
maintain MrSiin Line 9 and ϕM(Si)in Line 12 when a vertex uis
removed. Note that since ϕM(Si)=1−дM(Si)by Lemma 3, we
can maintain ϕM(Si)by maintaining дM(Si). We propose efficient
dynamic update technologies to solve the challenge as follows.
Lemma 5. For the current search space Si, if a vertex u∈Siis
removed, for any v∈NSi(u)andSi+1=Si\{u}, we have the
following equation:
MrSi+1(v)=MrSi(v)−MSi
k(u,v)+MSi
2(u,v)
M(u)(8)
дM(Si+1)=volM(Si)дM(Si)−MrSi(u)M(u)
volM(Si)−M(u)(9)
WhereMSi
k(u,v)=|{GS∈M|(u,v)∈GS,|Si∩S|=k}|and
MSi
2(u,v)=|{GS∈M|(u,v)∈GS,|Si∩S|=2}|. That is MSi
k(u,v)
(resp.,MSi
2(u,v)) is the number of motif instances containing the
edge (u,v)with exactly k(resp., 2) vertices in Si.
Based on Lemma 5, Algorithm 1 can incrementally update the
motif resident for each vertex when its neighbor is removed. The
time complexity of Algorithm 1 is analyzed as follows.
Theorem 4. The worse-case time complexity of Algorithm 1 is
O(k(δ/2)k−2m).kis the order of M.δis the degeneracy and is often
very small in real-world graphs (Table 2).
 
1797KDD ’24, August 25–29, 2024, Barcelona, Spain Longlong Lin, Tao Jia, Zeli Wang, Jin Zhao, and Rong-Hua Li
3.3 Lower and Upper Bounds of Motif Resident
According to the definitions of MrS(.)andдM(.), we can know that
the initial MrS1(u)=2 for any vertex u∈S1andдM(S1)=1. Thus,
by Equation 8 and Equation 9, we further know that the bottleneck
of Algorithm 1 is how to quickly obtain the motif degree M(u),
MSi
k(u,v)andMSi
2(u,v). Inspired by this, we propose effective
lower and upper bounds to estimate them, which can be computed
locally. Specifically, let NSu,NSSuv, and NSV\S
uvbe the neighbor
subgraph induced by N(u),NS(u)∩NS(v), and NV\S(u)∩NV\S(v),
respectively. We have M(u)andMSi
k(u,v)(resp.,MSi
2(u,v)) are the
number of (k−1)-cliques in NSuand the number of (k−2)-cliques
inNSSiuv(resp., NSV\Siuv), respectively. Therefore, the estimate of
M(u),MSi
k(u,v)andMSi
2(u,v)becomes to estimate the number of
cliques in the corresponding subgraph.
3.3.1 Lower Bounds. For convenience, we use NSto specify which
neighbor subgraph is adopted, i.e., NSu,NSSiuv, and NSV\Siuv. The
following Theorem is one of the most important results in extremal
graph theory, which can be used to estimate the number of cliques.
Theorem 5 (Turan Theorem [ 57] ).For any subgraph NS, if
2E(N S )
|V(N S )|(|V(N S )|−1 )>1−1
r−1, then NScontains a r-clique.
According to Theorem 5, we have the following facts.
Fact 1. LetD=2E(N S )
|V(N S )|(|V(N S )|−1 )andr=⌊1
1−D⌋+1, we
have: (1) M(u)≥r
k−1
ifNS=NSu; (2)MSi
k(u,v)≥r
k−2
if
NS=NSSiuv; (3)MSi
2(u,v)≥r
k−2
ifNS=NSV\Siuv.
The well-known graph theory expert Paul Erdos proposed the
following tighter theorem to further expand the Turan Theorem.
Theorem 6. [14] For any subgraph NS, if2E(N S )
|V(N S )|(|V(N S )|−1 )>
1−1
r−1, then NScontains at least (|V(N S )|
r−1)r−2r-cliques.
Lethis an integer and Ai={C1
i,C2
i, ...,C(r
h)
i}be the h-clique
set obtained from the i-thr-clique of Theorem 6, in which i∈
{1,2, ..., (|V(N S )|
r−1)r−2}. Since two r-cliques have at most r−1 com-
mon vertices,|Ai∩Aj|≤r−1
h
. According to the inclusion-exclusion
principle [ 5] and let t=(|V(N S )|
r−1)r−2, we have|tS
i=1Ai|≥tP
i=1|Ai|−
P
1≤i<j≤t|Ai∩Ai|≥tr
h
−t
2r−1
h
. So, we have the following facts.
Fact 2. LetD=2E(N S )
|V(N S )|(|V(N S )|−1 ),r=⌊1
1−D⌋+1, and t=
(|V(N S )|
r−1)r−2, we have: (1) M(u)≥tr
k−1
−t
2r−1
k−1
ifNS=NSu;
(2)MSi
k(u,v)≥tr
k−2
−t
2r−1
k−2
ifNS=NSSiuv; (3)MSi
2(u,v)≥
tr
k−2
−t
2r−1
k−2
ifNS=NSV\Siuv.
In a nutshell, we can obtain the lower bounds of M(u),MSi
k(u,v)
andMSi
2(u,v)according to Fact 1 and Fact 2.
3.3.2 Upper Bounds. Gao et al. proposed the concept of colorful
h-star degree csdh(u), which can be computed in O(h|N(u)|)time.
Specifically, csdh(u)is the number of colorful h-stars centered on u,
in which a colorful h-star is a star with hvertices having different
u
vuu
u u u v v(a) Colorful h -stars
(b) Colorful (h-2)-wedgesFigure 2: Colorful h-stars and colorful ( h−2)-wedges.
colors (Figure 2 (a)). Since each vertex in h-clique must have a
different color, we can obtain csdh(u)≥M(u)ifh=k(M). For
estimating MSi
k(u,v)andMSi
2(u,v), we propose a novel concept
of colorful (h−2)-wedge degree cwdS
h(u,v)w.r.t. the vertex set S.
cwdS
h(u,v)is the number of colorful (h−2)-wedges of Swith uand
vas endpoints (there may be no edge between uandv), in which a
colorful (h−2)-wedge of Sis a set of h−2 wedges (a wedge is a path
with three nodes) such that all vertices are in Sand having different
colors (Figure 2 (b)). Assume that (u,v)is an edge and hc(u,v)is
anyh-clique containing the edge (u,v), we know that each vertex in
hc(u,v)must have a different color. Thus, cwdSi
h(u,v)≥MSi
k(u,v)
andcwdV\Si
h(u,v)≥MSi
2(u,v)ifh=k(M).
So far we have obtained the upper and lower bounds of M(u),
MSi
k(u,v)andMSi
2(u,v), which can be computed and updated in
near-linear time by the dynamic programming. Therefore, we di-
rectly take the average of their upper and lower bounds as the
corresponding estimated value.
4 EXPERIMENTAL EVALUATION
4.1 Experimental Setup
Datasets. Our solutions are evaluated on five real-world graphs
with ground-truth clusters3, which are widely used benchmarks for
higher-order graph clustering [ 4,16,29]. Besides, we also use four
types of synthetic graphs to test the scalability and the effectiveness
of our solutions: LFR[37],PLC [28],ER[15], and BA[3], which can
be generated by the well-known NetworkX Python package [ 25].
Note that they can be used to simulate the degree distributions,
communities, and small-world properties in the real world.
Competitors. The following SOTA baselines are implemented for
comparison. (1) Traditional graph clustering: SC[1],Louvain [7]
andKCore [49]; (2) Cohesive subgraph based higher-order graph
clustering: HD[16,27,53]; (3) Modularity based higher-order graph
clustering: HM[2,29]; (4) Motif conductance based higher-order
graph clustering: HSC [4],MAPPR [65], and HOSPLOC [72,73].
PSMC is our proposed Algorithm 1 and PSMC+ isPSMC with bound
estimation strategies in Section 3.3.
Parameters and Implementations. Unless specified otherwise,
we take the default parameters of these baselines in our experiments.
Since both HOSPLOC andMAPPR take a seed vertex as input, to be
more reliable, we randomly select 50 vertices as seed vertices and
report the average runtime and quality. Following previous work
3All datasets can be downloaded from http://snap.stanford.edu/
 
1798PSMC: Provable and Scalable Algorithms for Motif Conductance Based Graph Clustering KDD ’24, August 25–29, 2024, Barcelona, Spain
Table 2: Dataset statistics. δis the degeneracy.
Dataset|V| | E|δ Description
Amazon 334,863 925,872 6 Co-purchase
DBLP 317,080 1,049,866 113 Collaboration
Youtube 1,134,890 2,987,624 51 Social network
LiveJ 3,997,962 34,681,189 360 Social network
Orkut 3,072,441 117,185,083 253 Social network
LFR[37] 103∼107103∼1073∼5 Synthetic network
PLC [28] 103∼107103∼1073∼5 Synthetic network
ER[15] 103∼107103∼1075∼11 Synthetic network
BA[3] 103∼107103∼1073∼5 Synthetic network
[20,55,65], we also limit ourselves to the representative k-clique
motif to illustrate the main patterns observed. All experiments
are conducted on a Linux server with an Intel(R) Xeon(R) E5-2683
v3@2.00GHZ CPU and 256GB RAM running CentOS 6.10.
4.2 Efficiency Testing
Since the objective functions of traditional graph clustering (e.g., SC
[1],Louvain [7] and KCore [49]), cohesive subgraph based higher-
order graph clustering (e.g., HD[16,27,53]), and modularity based
higher-order graph clustering (e.g., HM[2,29]) are different from
the motif conductance studied in this work, it is meaningless and
unnecessary to compare their efficiency.
Exp-1: Runtime of different motif conductance algorithms
with varying k(M).The runtime of HSC, MAPPR, HOSPLOC, PSMC
andPSMC+ with varying k(M)on five real-world networks is de-
tailed in Figure 3. Note that we do not report the empirical results
for LiveJ and Orkut on k(M)=6. This is because we cannot obtain
the results of baselines (i.e., MAPPR, HOSPLOC, and HSC) within 7
days. By Figure 3, we have: (1) PSMC+ is consistently faster than
other methods. This is because PSMC+ non-trivially adopts the
technologies of Turan Theorem, colorful h-star degree, and colorful
(h−2)-wedge degree to estimate the motif resident with near-
linear time (Table 1). (2) PSMC is the runner-up on four of the five
networks. The efficiency of PSMC can be attributed to its novel
computing framework (i.e., integrating the enumeration and parti-
tioning in an iterative algorithm). However, MAPPR, HOSPLOC, and
HSC depend on the weight graph GMobtained by enumerating the
motif instances, which increases exponentially with the size of the
motif (Table 1). In particular, PSMC achieves the speedups of 3.2 ∼32
times over HSC. For example, on DBLP and k(M)=3,PSMC takes
9 seconds to obtain the result, while HSC takes 292 seconds. (3) The
runtime of all methods increases with increasing k(M)except for
HSC on Amazon and Youtube. This is because when k(M)increases,
we need more time to count/estimate motif instances. However, for
HSC, a possible explanation is that the weighted graph GMgets
smaller as k(M)increases, resulting in very little time spent in the
spectral clustering stage of the two-stage reweighting method [ 4].
(4) The sparser the graph (i.e., the smaller the δ), the faster our
algorithms (i.e., PSMC andPSMC+). For example, our algorithms
are faster on Youtube compared to DBLP, despite Youtube having
more vertices and more edges (Table 2). This is because Youtubehas a smaller δ(Table 2). These results give preliminary evidence
that the proposed solutions are indeed high efficiency in practice.
Exp-2: Scalability testing on synthetic graphs. Extensive syn-
thetic graphs are generated to further test the scalability of our
solutions. Figure 4 only presents the results when the given motif
is a triangle, with comparable trends across other motifs. By Figure
4, we know that PSMC andPSMC+ scale near-linear with respect to
the graph size. However, the runtime of other baselines fluctuates
greatly as the graph size increases. This is because their time com-
plexity is nonlinear depending on n, or even is n3forHSC (Table 1).
These results indicate that our algorithms have excellent scalability
over massive graphs while the baselines do not.
Exp-3: Memory overhead comparison. Figure 5 displays the
memory overhead of the evaluated algorithms when the motif is a
triangle, with comparable trends across other motifs. As excepted,
our porposed PSMC and PSMC+ are consistently less than other
baselines on all datasets and realize up to an order of magnitude
memory reduction on most cases. This advantage can be attributed
to their novel computing framework, which only need to maintain
some simple data structures, such as motif resident of each vertex
(Algorithm 1). Note that PSMC+ is slightly worse than PSMC. This
is because PSMC+ needs to maintain more intermediate variables to
estimate motif resident (Section 3.3). On the other hand, HSC and
MAPPR exhibit comparable memory overheads, while HOSPLOC
has the worst performance. This is because HOSPLOC requires stor-
ing the expensive state transition tensor (the worst space is O(n3))
to calculate the vertex ordering required by the sweep procedure.
Similarly, HSC andMAPPR need to store the edge-weighted graph
GMto calculate this vertex ordering (Section 2.2). These results
affirm the memory efficiency of our algorithms.
4.3 Effectiveness Testing
Effectiveness Metric. We use the F1-Score metric to measure how
“close" each detected cluster Cis to the ground-truth one. Note that
since F1-Score is the harmonic mean of precision and recall, the
larger the F1-Score, the better the quality of C[4,16,29]. Besides, we
also use motif conductance ( MCfor short) calculated by Definition 2
to evaluate the quality of the identified community. The smaller the
value of the MC(C), the better the partition of community C. We also
report the size of the identified community for completeness. Note
that we do not report traditional edge-based metric (e.g., density,
conductance) because they are mainly used to measure the quality
of communities with edges as atomic clustering units (Section 1).
Exp-4: Effectiveness of various graph clustering methods. Ta-
ble 3 only reports these results when the given motif is a triangle,
with analogous trends observed across other motifs. For motif con-
ductance (MC for short) metric, we have: (1) PSMC outperforms
other methods on four of the five datasets (on Youtube, PSMC+ is
the champion and PSMC is the runner-up). In particular, PSMC is
167, 12, 20, and 41 times better than HSC on Amazon, Youtube, LiveJ,
and Orkut, respectively. This is because PSMC can find clusters with
near-liner approximation ratio, while HSC has quadratic bound (Ta-
ble 1). (2) PSMC+ outperforms MAPPR andHOSPLOC on four of the
five datasets. This is because MAPPR andHOSPLOC are heuristic
and have no guarantee of clustering quality (Table 1). However,
PSMC+ is built on top of PSMC, so even if PSMC+ has no theoretical
 
1799KDD ’24, August 25–29, 2024, Barcelona, Spain Longlong Lin, Tao Jia, Zeli Wang, Jin Zhao, and Rong-Hua Li
3 4 5 6
k()
0255075100125150175200/uni00000035/uni00000058/uni00000051/uni00000057/uni0000004c/uni00000050/uni00000048/uni00000003/uni0000000b/uni00000056/uni00000048/uni00000046/uni00000052/uni00000051/uni00000047/uni00000056/uni0000000c
MAPPR
HOSPLOC
HSC
PSMC
PSMC+
(a) Amazon
3 4 5 6
k()
0500100015002000250030003500/uni00000035/uni00000058/uni00000051/uni00000057/uni0000004c/uni00000050/uni00000048/uni00000003/uni0000000b/uni00000056/uni00000048/uni00000046/uni00000052/uni00000051/uni00000047/uni00000056/uni0000000c
MAPPR
HOSPLOC
HSC
PSMC
PSMC+ (b) DBLP
3 4 5 6
k()
50100150200250300350400/uni00000035/uni00000058/uni00000051/uni00000057/uni0000004c/uni00000050/uni00000048/uni00000003/uni0000000b/uni00000056/uni00000048/uni00000046/uni00000052/uni00000051/uni00000047/uni00000056/uni0000000c
MAPPR
HOSPLOC
HSC
PSMC
PSMC+ (c) Youtube
3 4 5
k()
050000100000150000200000/uni00000035/uni00000058/uni00000051/uni00000057/uni0000004c/uni00000050/uni00000048/uni00000003/uni0000000b/uni00000056/uni00000048/uni00000046/uni00000052/uni00000051/uni00000047/uni00000056/uni0000000c
MAPPR
HOSPLOC
HSC
PSMC
PSMC+ (d) LiveJ
3 4 5
k()
0100000200000300000400000500000600000/uni00000035/uni00000058/uni00000051/uni00000057/uni0000004c/uni00000050/uni00000048/uni00000003/uni0000000b/uni00000056/uni00000048/uni00000046/uni00000052/uni00000051/uni00000047/uni00000056/uni0000000c
MAPPR
HOSPLOC
HSC
PSMC
PSMC+ (e) Orkut
Figure 3: Runtime (seconds) of different motif conductance algorithms with varying k(M).
Table 3: Effectiveness of various graph clustering methods. The best and second-best results in each metric are marked in bold
and underlined , respectively. Note that there is no clear evidence to suggest whether a larger or smaller community size is
better. We are simply presenting the community size objectively to provide an intuitive experience.
Mo
delAmazon DBLP Youtube LiveJ Orkut
MC
F1-Score Size MC F1-Score Size MC F1-Score Size MC F1-Score Size MC F1-Score Size
SC
0.704 0.226 80793 0.467 0.103 47891 0.773 0.061 38849 0.315 0.306 408010 0.499 0.020 476537
Louvain 0.007 0.431
239 0.071 0.230 232 0.467 0.013 7480 0.071 0.277 2412 0.074 0.225
33
KCore 0.109 0.138 497 0.018 0.273 114 0.470 0.095 845 0.035 0.313 377 0.141 0.165 15706
HD
0.269 0.182 30852 0.013 0.242
309 0.419 0.074 1239 0.011 0.125 7700 0.128 0.076 114187
HM 0.007 0.494 528
0.048 0.301 237 0.146 0.022 1999 0.016 0.120 674 0.082 0.248 96
HSC
0.067 0.488 10 0.055 0.239 427 0.074 0.102 18 0.002 0.358 93
0.125 0.215 6
MAPPR 0.015 0.457 175 0.115 0.339 28796 0.132 0.116 15810 0.102 0.257 307740 0.104 0.233 1343943
HOSPLOC 0.062 0.467 90 0.260 0.283 414 0.103 0.128 434 0.266 0.342 3586 0.381 0.237 44651
PSMC 4∗10−40.511 74991 7∗10−120.382 141
0.006 0.202 21342 1∗10−40.413 12458 0.003
0.312 1368793
PSMC+ 0.012 0.317 138098 0.064 0.353 87846 0.000 0.138 229147
0.097 0.326 88385 0.483 0.232 231334
103
104
105
106
107
/uni00000051050100150200250300350/uni00000035/uni00000058/uni00000051/uni00000057/uni0000004c/uni00000050/uni00000048/uni0000000b/uni00000056/uni00000048/uni00000046/uni00000052/uni00000051/uni00000047/uni00000056/uni0000000c
MAPPR
HOSPLOC
HSC
PSMC
PSMC+
(
a)LFR
103
104
105
106
107
/uni000000510200040006000800010000120001400016000/uni00000035/uni00000058/uni00000051/uni00000057/uni0000004c/uni00000050/uni00000048/uni0000000b/uni00000056/uni00000048/uni00000046/uni00000052/uni00000051/uni00000047/uni00000056/uni0000000c
MAPPR
HOSPLOC
HSC
PSMC
PSMC+ (
b)PLC
103
104
105
106
107
/uni0000005102004006008001000/uni00000035/uni00000058/uni00000051/uni00000057/uni0000004c/uni00000050/uni00000048/uni0000000b/uni00000056/uni00000048/uni00000046/uni00000052/uni00000051/uni00000047/uni00000056/uni0000000c
MAPPR
HOSPLOC
HSC
PSMC
PSMC+
(
c)ER
103
104
105
106
107
/uni000000510100200300400500600/uni00000035/uni00000058/uni00000051/uni00000057/uni0000004c/uni00000050/uni00000048/uni0000000b/uni00000056/uni00000048/uni00000046/uni00000052/uni00000051/uni00000047/uni00000056/uni0000000c
MAPPR
HOSPLOC
HSC
PSMC
PSMC+ (
d)BA
Figure 4: Scalability testing on synthetic graphs.
guarantee, it can still get good quality in practice. For F1-Score
metric, we have: (1) PSMC consistently outperforms other methods
(including HDandHM). (2) SC,Louvain, and KCore have poor F1-
Scores on most cases. This is because they are traditional clustering
methods which cannot capture higher-order structural information
for graph clustering. For Size metric, on average, the community
sizes found by different algorithms from largest to smallest are
SC,PSMC+, MAPPR, HD,PSMC, HM, Louvain, HOSPLOC, HSC, and
KCore. Our algorithm PSMC returns the community size that is
ranked in the middle, so it tends to find communities of moderate
Amazon DBLP Youtube LiveJ Orkut0100101102103104105/uni00000030/uni00000048/uni00000050/uni00000052/uni00000055/uni0000005c/uni00000003/uni00000032/uni00000059/uni00000048/uni00000055/uni0000004b/uni00000048/uni00000044/uni00000047/uni00000003/uni0000000b/uni00000030/uni00000025/uni0000000cHOSPLOC HSC MAPPR PSMC PSMC+Figur
e 5: Memory overhead on real-world graphs (excluding
the size of the graph itself).
size. However, other baselines either find the community that is
too large or too small, leading to poor interpretability. Thus, these
results give clear evidence that our solutions can indeed find higher
quality clusters when contrasted with baselines.
Exp-5: Quality of various motif conductance algorithms. Fig-
ure 6 depicts the quality of different motif conductance algorithms
with varying k(M)on real-world graphs. We have the following
observations: (1) PSMC always outperforms other methods under
different k(M). Besides, PSMC is almost stable with increasing k(M),
while other methods have no obvious change trend with increasing
k(M). (2)PSMC+ andHOSPLOC fluctuates greatly as k(M)increases.
However, PSMC+ performs well in synthetic graphs (see Figure 7
for details). One possible explanation is that as k(M)increases, the
actual effect of estimation bounds in PSMC+ depends on the type
of network (e.g. real-world graphs have poor pruning effects, while
synthetic graphs have good pruning effects). Moreover, we also
 
1800PSMC: Provable and Scalable Algorithms for Motif Conductance Based Graph Clustering KDD ’24, August 25–29, 2024, Barcelona, Spain
3 4 5 6
k()
0.00.20.40.60.8/uni00000030/uni00000052/uni00000057/uni0000004c/uni00000049/uni00000003/uni00000026/uni00000052/uni00000051/uni00000047/uni00000058/uni00000046/uni00000057/uni00000044/uni00000051/uni00000046/uni00000048
MAPPR
HOSPLOC
HSC
PSMC
PSMC+
(a) Amazon
3 4 5 6
k()
0.00.10.20.30.40.5/uni00000030/uni00000052/uni00000057/uni0000004c/uni00000049/uni00000003/uni00000026/uni00000052/uni00000051/uni00000047/uni00000058/uni00000046/uni00000057/uni00000044/uni00000051/uni00000046/uni00000048
MAPPR
HOSPLOC
HSC
PSMC
PSMC+ (b) DBLP
3 4 5 6
k()
0.00.20.40.60.81.0/uni00000030/uni00000052/uni00000057/uni0000004c/uni00000049/uni00000003/uni00000026/uni00000052/uni00000051/uni00000047/uni00000058/uni00000046/uni00000057/uni00000044/uni00000051/uni00000046/uni00000048
MAPPR
HOSPLOC
HSC
PSMC
PSMC+ (c) Youtube
3 4 5
k()
0.000.050.100.150.200.25/uni00000030/uni00000052/uni00000057/uni0000004c/uni00000049/uni00000003/uni00000026/uni00000052/uni00000051/uni00000047/uni00000058/uni00000046/uni00000057/uni00000044/uni00000051/uni00000046/uni00000048
MAPPR
HOSPLOC
HSC
PSMC
PSMC+ (d) LiveJ
3 4 5
k()
0.00.20.40.60.81.0/uni00000030/uni00000052/uni00000057/uni0000004c/uni00000049/uni00000003/uni00000026/uni00000052/uni00000051/uni00000047/uni00000058/uni00000046/uni00000057/uni00000044/uni00000051/uni00000046/uni00000048
MAPPR
HOSPLOC
HSC
PSMC
PSMC+ (e) Orkut
Figure 6: Quality of various motif conductance algorithms with varying k(M)on real-world graphs.
103
104
105
106
107
/uni000000510.00.20.40.60.81.0/uni00000030/uni00000052/uni00000057/uni0000004c/uni00000049/uni00000003/uni00000026/uni00000052/uni00000051/uni00000047/uni00000058/uni00000046/uni00000057/uni00000044/uni00000051/uni00000046/uni00000048
MAPPR
HOSPLOC
HSC
PSMC
PSMC+
(a)LFR
103
104
105
106
107
/uni000000510.00.10.20.30.40.50.60.70.8/uni00000030/uni00000052/uni00000057/uni0000004c/uni00000049/uni00000003/uni00000026/uni00000052/uni00000051/uni00000047/uni00000058/uni00000046/uni00000057/uni00000044/uni00000051/uni00000046/uni00000048
MAPPR
HOSPLOC
HSC
PSMC
PSMC+ (b)PLC
103
104
105
106
107
/uni000000510.00.20.40.60.81.0/uni00000030/uni00000052/uni00000057/uni0000004c/uni00000049/uni00000003/uni00000026/uni00000052/uni00000051/uni00000047/uni00000058/uni00000046/uni00000057/uni00000044/uni00000051/uni00000046/uni00000048
MAPPR
HOSPLOC
HSC
PSMC
PSMC+
(c)ER
103
104
105
106
107
/uni000000510.00.10.20.30.40.50.6/uni00000030/uni00000052/uni00000057/uni0000004c/uni00000049/uni00000003/uni00000026/uni00000052/uni00000051/uni00000047/uni00000058/uni00000046/uni00000057/uni00000044/uni00000051/uni00000046/uni00000048
MAPPR
HOSPLOC
HSC
PSMC
PSMC+ (d)BA
Figure 7: Quality of various motif conductance algorithms
on synthetic graphs.
report these qualities on extensive synthetic graphs. As shown in
Figure 7, PSMC+ outperforms other methods in most cases. Besides,
PSMC is runner up and slightly worse than PSMC+. However, the
performance of MAPPR, HOSPLOC, and HSC vary significantly de-
pending on the dataset. For example, MAPPR <HOSPLOC <HSC
onLFRsynthetic graphs, but HSC <MAPPR <HOSPLOC onBA
synthetic graphs, where A>Bmeans Ahas larger motif conduc-
tance. These results indicate that our algorithms can identify higher
quality clusters than the baselines on real-world&synthetic graphs.
5 RELATED WORK
Traditional Graph Clustering. Graph clustering has received
much cattention over past decades [ 17,18]. Modularity [ 34,46,
51] and conductance [ 21,23,26,40,58] are two representative
models to evaluate the clustering quality of the identified cluster.
Informally, they aim to optimize the difference or ratio of edges
between the internal and external of the cluster. However, finding
the cluster with optimal modularity or conductance is NP-hard
[21,46]. Thus, many heuristic or approximate algorithms have
been proposed in the literature. For example, the heuristic algorithm
Louvain was proposed to iteratively optimize modularity in a greedy
manner [ 6,7].Fiedler vector-based spectral clustering algorithm
can output a cluster with a quadratic factor of optimal conductance
[40]. Recently, some polynomial solvable cohesive subgraph models
also have been proposed to partition the graph, which are to only
optimize the internal denseness of the identified cluster. Notableexamples include average-degree densest subgraph, k-core, and
k-truss [ 9]. However, these traditional methods mainly focus on
the internal or external lower-order edges of the cluster, resulting in
that cannot capture higher-order structural information for graph
clustering. Besides simple graphs, more complex graphs has also
been explored. For example, the graph clustering on attribute graphs
[63,71], heterogeneous information networks [ 10,33], and temporal
networks [ 41–43,69,74]. Obviously, these methods are orthogonal
to our work.
Higher-order Graph Clustering. In addition to the motif conduc-
tance studied in this paper [ 4], other higher-order graph clustering
models also have been proposed in the literature. For example, mo-
tif modularity was proposed to extend the traditional modularity by
optimizing the difference between the fraction of motif instances
within the cluster and the fraction in a random network preserving
the same degree of vertices [ 2,29]. Higher-order densest subgraph
model was proposed where the density is defined as the number of
motif instances divided by the size of vertices [ 16,27,53]. Li et al.
proposed an edge enhancement approach to overcome the hyper-
graph fragmentation issue appearing in the seminal reweighting
framework [ 38]. Unfortunately, they are still essentially optimiz-
ing the objective function for traditional lower-order clustering.
Besides simple graphs, higher-order graph clustering on more com-
plicated networks also have been studied, such as heterogeneous
information networks [ 8], labeled networks [ 20,48], multi-layer
networks [ 30], dynamic networks [ 19]. Clearly, these methods on
complicated networks are orthogonal to our work.
6 CONCLUSION
We first propose a simple butprovable algorithm PSMC for motif
conductance based graph clustering. Most notably, PSMC can output
the result with fixed andmotif-independent approximation ratio,
which solves the open question posed by the seminal two-stage
reweighting framework. We then devise novel dynamic update
technologies and effective bounds to further boost efficiency of
PSMC. Finally, empirical results on real-life and synthetic datasets
demonstrate the superiority of the proposed algorithms on both
clustering accuracy and running time.
7 ACKNOWLEDGMENTS
The work was supported by (i) the National Natural Science Foun-
dation of China under Grant Nos. 62072205 and 61932004, (ii) NSFC
Grants U2241211, 62072034, (iii) China Postdoctoral Science Foun-
dation under Grant 2023T00325, (iv) Fundamental Research Funds
for the Central Universities under Grant SWU-KQ22028. Zeli Wang
and Rong-Hua Li are the corresponding authors of this paper.
 
1801KDD ’24, August 25–29, 2024, Barcelona, Spain Longlong Lin, Tao Jia, Zeli Wang, Jin Zhao, and Rong-Hua Li
REFERENCES
[1]Noga Alon and Vitali D Milman. 1985. λ1, isoperimetric inequalities for graphs,
and superconcentrators. Journal of Combinatorial Theory, Series B 38, 1 (1985),
73–88.
[2]Alex Arenas, Alberto Fernandez, Santo Fortunato, and Sergio Gomez. 2008. Motif-
based communities in complex networks. Journal of Physics A: Mathematical and
Theoretical 41, 22 (2008), 224001.
[3]Albert-László Barabási and Réka Albert. 1999. Emergence of scaling in random
networks. science 286, 5439 (1999), 509–512.
[4]Austin R Benson, David F Gleich, and Jure Leskovec. 2016. Higher-order organi-
zation of complex networks. Science 353, 6295 (2016), 163–166.
[5]Andreas Björklund, Thore Husfeldt, and Mikko Koivisto. 2009. Set Partitioning
via Inclusion-Exclusion. SIAM J. Comput. 39, 2 (2009), 546–563.
[6]Vincent D. Blondel, Jean-Loup Guillaume, and Renaud Lambiotte. 2023. Fast
unfolding of communities in large networks: 15 years later. CoRR abs/2311.06047
(2023).
[7]Vincent D Blondel, Jean-Loup Guillaume, Renaud Lambiotte, and Etienne Lefeb-
vre. 2008. Fast unfolding of communities in large networks. Journal of statistical
mechanics: theory and experiment 2008, 10 (2008), P10008.
[8]Aldo G. Carranza, Ryan A. Rossi, Anup Rao, and Eunyee Koh. 2020. Higher-order
Clustering in Complex Heterogeneous Networks. In KDD. 25–35.
[9]Lijun Chang and Lu Qin. 2019. Cohesive Subgraph Computation Over Large
Sparse Graphs. In Proceedings of ICDE. 2068–2071.
[10] Lu Chen, Yunjun Gao, Yuanliang Zhang, Christian S. Jensen, and Bolong Zheng.
2019. Efficient and Incremental Clustering Algorithms on Star-Schema Heteroge-
neous Graphs. In ICDE. 256–267.
[11] Wei-Lin Chiang, Xuanqing Liu, Si Si, Yang Li, Samy Bengio, and Cho-Jui Hsieh.
2019. Cluster-GCN: An Efficient Algorithm for Training Deep and Large Graph
Convolutional Networks. In KDD. 257–266.
[12] Karen D. Devine, Erik G. Boman, and George Karypis. 2006. Partitioning and
Load Balancing for Emerging Parallel Applications and Architectures. In Parallel
Processing for Scientific Computing. 99–126.
[13] Alexandre Duval and Fragkiskos D. Malliaros. 2022. Higher-order Clustering
and Pooling for Graph Neural Networks. In CIKM. 426–435.
[14] P Erdos. 1969. On the number of complete subgraphs and circuits contained in
graphs. Casopis Pest. Mat. 94 (1969), 290–296.
[15] Paul Erdos, Alfréd Rényi, et al .1960. On the evolution of random graphs. Publ.
Math. Inst. Hung. Acad. Sci 5, 1 (1960), 17–60.
[16] Yixiang Fang, Kaiqiang Yu, Reynold Cheng, Laks V. S. Lakshmanan, and Xuemin
Lin. 2019. Efficient Algorithms for Densest Subgraph Discovery. Proc. VLDB
Endow. 12, 11 (2019), 1719–1732.
[17] Santo Fortunato. 2010. Community detection in graphs. Physics Reports 486, 3-5
(2010), 75–174.
[18] Santo Fortunato and Darko Hric. 2016. Community detection in networks: A
user guide. CoRR abs/1608.00163 (2016).
[19] Dongqi Fu, Dawei Zhou, and Jingrui He. 2020. Local Motif Clustering on Time-
Evolving Graphs. In KDD. 390–400.
[20] Dongqi Fu, Dawei Zhou, Ross Maciejewski, Arie Croitoru, Marcus Boyd, and Jin-
grui He. 2023. Fairness-Aware Clique-Preserving Spectral Clustering of Temporal
Graphs. In WWW. 3755–3765.
[21] Sainyam Galhotra, Amitabha Bagchi, Srikanta Bedathur, Maya Ramanath, and
Vidit Jain. 2015. Tracking the Conductance of Rapidly Evolving Topic-Subgraphs.
Proc. VLDB Endow. 8, 13 (2015), 2170–2181.
[22] Sen Gao, Rong-Hua Li, Hongchao Qin, Hongzhi Chen, Ye Yuan, and Guoren
Wang. 2022. Colorful h-star Core Decomposition. In ICDE.
[23] David F. Gleich and C. Seshadhri. 2012. Vertex neighborhoods, low conductance
cuts, and good seeds for local community methods. In KDD5.
[24] Manish Gupta, Jing Gao, Yizhou Sun, and Jiawei Han. 2012. Integrating commu-
nity matching and outlier detection for mining evolutionary community outliers.
InKDD. 859–867.
[25] Aric A. Hagberg, Daniel A. Schult, and Pieter J. Swart. 2008. Exploring Network
Structure, Dynamics, and Function using NetworkX. In Proceedings of the 7th
Python in Science Conference. 11 – 15.
[26] Yue He, Longlong Lin, Pingpeng Yuan, Ronghua Li, Tao Jia, and Zeli Wang. 2024.
CCSS: Towards conductance-based community search with size constraints.
Expert Systems with Applications 250 (2024), 123915.
[27] Yizhang He, Kai Wang, Wenjie Zhang, Xuemin Lin, and Ying Zhang. 2023. Scaling
Up k-Clique Densest Subgraph Detection. Proc. ACM Manag. Data 1, 1 (2023),
69:1–69:26.
[28] Petter Holme and Beom Jun Kim. 2002. Growing scale-free networks with tunable
clustering. Physical review E 65, 2 (2002), 026107.
[29] Ling Huang, Hong-Yang Chao, and Guangqiang Xie. 2020. MuMod: A Micro-
Unit Connection Approach for Hybrid-Order Community Detection. In AAAI.
107–114.
[30] Ling Huang, Chang-Dong Wang, and Hongyang Chao. 2021. HM-Modularity:
A Harmonic Motif Modularity Approach for Multi-Layer Network Community
Detection. IEEE Trans. Knowl. Data Eng. 33, 6 (2021), 2520–2533.[31] Shixun Huang, Yuchen Li, Zhifeng Bao, and Zhao Li. 2021. Towards Efficient
Motif-based Graph Partitioning: An Adaptive Sampling Approach. In ICDE. 528–
539.
[32] Zengfeng Huang, Shengzhong Zhang, Chong Xi, Tang Liu, and Min Zhou. 2021.
Scaling Up Graph Neural Networks Via Graph Coarsening. In KDD. 675–684.
[33] Xun Jian, Yue Wang, and Lei Chen. 2020. Effective and Efficient Relational
Community Detection and Search in Large Dynamic Heterogeneous Information
Networks. Proc. VLDB Endow. 13, 10 (2020), 1723–1736.
[34] Junghoon Kim, Siqiang Luo, Gao Cong, and Wenyuan Yu. 2022. DMCS : Density
Modularity based Community Search. In SIGMOD. 889–903.
[35] Brian James Kloostra, Chaitanya Dalvi, and Brookton Noah Behm. 2009. Sys-
tem and method for analyzing and dispositioning money laundering suspicious
activity alerts. US Patent App. 12/258,784.
[36] Christine Klymko, David F. Gleich, and Tamara G. Kolda. 2014. Using Triangles
to Improve Community Detection in Directed Networks. CoRR abs/1404.5874
(2014).
[37] Andrea Lancichinetti, Santo Fortunato, and János Kertész. 2009. Detecting the
overlapping and hierarchical community structure in complex networks. New
journal of physics 11, 3 (2009), 033015.
[38] Pei-Zhen Li, Ling Huang, Chang-Dong Wang, and Jian-Huang Lai. 2019. EdMot:
An Edge Enhancement Approach for Motif-aware Community Detection. In KDD.
479–487.
[39] Ronghua Li, Sen Gao, Lu Qin, Guoren Wang, Weihua Yang, and Jeffrey Xu Yu.
2020. Ordering Heuristics for k-clique Listing. Proc. VLDB Endow. 13, 11 (2020),
2536–2548.
[40] Longlong Lin, Ronghua Li, and Tao Jia. 2023. Scalable and Effective Conductance-
Based Graph Clustering. In AAAI. 4471–4478.
[41] Longlong Lin, Pingpeng Yuan, Rong-Hua Li, and Hai Jin. 2022. Mining Diversified
Top-$r$r Lasting Cohesive Subgraphs on Temporal Networks. IEEE Trans. Big
Data 8, 6 (2022), 1537–1549.
[42] Longlong Lin, Pingpeng Yuan, Rong-Hua Li, Jifei Wang, Ling Liu, and Hai Jin.
2022. Mining Stable Quasi-Cliques on Temporal Networks. IEEE Trans. Syst. Man
Cybern. Syst. 52, 6 (2022), 3731–3745.
[43] Longlong Lin, Pingpeng Yuan, Rong-Hua Li, Chun-Xue Zhu, Hongchao Qin, Hai
Jin, and Tao Jia. 2024. QTCS: Efficient Query-Centered Temporal Community
Search. Proc. VLDB Endow. 17, 6 (2024), 1187–1199.
[44] Shmoolik Mangan and Uri Alon. 2003. Structure and function of the feed-forward
loop network motif. Proceedings of the National Academy of Sciences 100, 21 (2003),
11980–11985.
[45] R. Milo, S. Shen-Orr, S. Itzkovitz, N. Kashtan, D. Chklovskii, and U. Alon. 2002.
Network motifs: simple building blocks of complex networks. Science (2002).
[46] Mark EJ Newman and Michelle Girvan. 2004. Finding and evaluating community
structure in networks. Physical review E 69, 2 (2004), 026113.
[47] Pedro Ribeiro, Pedro Paredes, Miguel E. P. Silva, David Aparício, and Fernando
M. A. Silva. 2022. A Survey on Subgraph Counting: Concepts, Algorithms, and
Applications to Network Motifs and Graphlets. ACM Comput. Surv. 54, 2 (2022),
28:1–28:36.
[48] Ahmet Erdem Sariyüce. 2021. Motif-driven Dense Subgraph Discovery in Directed
and Labeled Networks. In WWW. 379–390.
[49] S. B. Seidman. 1983. Network structure and minimum degree. Social Networks 5,
3 (1983), 269–287.
[50] Jianbo Shi and Jitendra Malik. 1997. Normalized Cuts and Image Segmentation.
InCVPR. 731–737.
[51] Hiroaki Shiokawa, Yasuhiro Fujiwara, and Makoto Onizuka. 2013. Fast Algorithm
for Modularity-Based Graph Clustering. In AAAI. AAAI Press, 1170–1176.
[52] Konstantinos Sotiropoulos and Charalampos E. Tsourakakis. 2021. Triangle-
aware Spectral Sparsifiers and Community Detection. In KDD, Feida Zhu,
Beng Chin Ooi, and Chunyan Miao (Eds.). 1501–1509.
[53] Bintao Sun, Maximilien Danisch, T.-H. Hubert Chan, and Mauro Sozio. 2020.
KClist++: A Simple Algorithm for Finding k-Clique Densest Subgraphs in Large
Graphs. Proc. VLDB Endow. 13, 10 (2020), 1628–1640.
[54] Luca Trevisan. 2017. Lecture notes on graph partitioning, expanders and spec-
tral methods. University of California, Berkeley, https://people. eecs. berkeley.
edu/luca/books/expanders-2016. pdf (2017).
[55] Charalampos E. Tsourakakis. 2015. The K-clique Densest Subgraph Problem. In
WWW. 1122–1132.
[56] Charalampos E. Tsourakakis, Jakub Pachocki, and Michael Mitzenmacher. 2017.
Scalable Motif-aware Graph Clustering. In WWW. 1451–1460.
[57] P Turan. 1941. On an extremal problem in graph theory. Mat. Fiz. Lapok 48, 137
(1941), 436–452.
[58] Ulrike Von Luxburg. 2007. A tutorial on spectral clustering. Statistics and
computing 17, 4 (2007), 395–416.
[59] Sibo Wang, Renchi Yang, Xiaokui Xiao, Zhewei Wei, and Yin Yang. 2017. FORA:
Simple and Effective Approximate Single-Source Personalized PageRank. In KDD.
505–514.
[60] Zhewei Wei, Xiaodong He, Xiaokui Xiao, Sibo Wang, Shuo Shang, and Ji-Rong
Wen. 2018. TopPPR: Top-k Personalized PageRank Queries with Precision Guar-
antees on Large Graphs. In SIGMOD. 441–456.
 
1802PSMC: Provable and Scalable Algorithms for Motif Conductance Based Graph Clustering KDD ’24, August 25–29, 2024, Barcelona, Spain
[61] Li Wen and Michael K. Ng. 2014. "On the limiting probability distribution of a
transition probability tensor. Linear and Multilinear Algebra 62, 3 (2014), 362–385.
[62] Feng Xia, Shuo Yu, Chengfei Liu, Jianxin Li, and Ivan Lee. 2022. CHIEF: Clustering
With Higher-Order Motifs in Big Networks. IEEE Trans. Netw. Sci. Eng. 9, 3 (2022),
990–1005.
[63] Renchi Yang, Jieming Shi, Yin Yang, Keke Huang, Shiqi Zhang, and Xiaokui Xiao.
2021. Effective and Scalable Clustering on Massive Attributed Graphs. In WWW.
3675–3687.
[64] Ömer Nebil Yaveroğlu, Noël Malod-Dognin, Darren Davis, Zoran Levnajic, Vuk
Janjic, Rasa Karapandza, Aleksandar Stojmirovic, and Nataša Pržulj. 2014. Re-
vealing the hidden language of complex networks. Scientific reports 4, 1 (2014),
4547.
[65] Hao Yin, Austin R. Benson, Jure Leskovec, and David F. Gleich. 2017. Local
Higher-Order Graph Clustering. In KDD. 555–564.
[66] Zhitao Ying, Jiaxuan You, Christopher Morris, Xiang Ren, William L. Hamilton,
and Jure Leskovec. 2018. Hierarchical Graph Representation Learning with
Differentiable Pooling. In NeurIPS. 4805–4815.
[67] Shuo Yu, Yufan Feng, Da Zhang, Hayat Dino Bedru, Bo Xu, and Feng Xia. 2020.
Motif discovery in networks: A survey. Comput. Sci. Rev. (2020).[68] Shengzhong Zhang, Zengfeng Huang, Haicang Zhou, and Ziang Zhou. 2020. SCE:
Scalable Network Embedding from Sparsest Cut. In kdd. 257–265.
[69] Yifei Zhang, Longlong Lin, Pingpeng Yuan, and Hai Jin. 2022. Significant En-
gagement Community Search on Temporal Networks. In DASFAA. 250–258.
[70] Yilin Zhang and Karl Rohe. 2018. Understanding Regularized Spectral Clustering
via Graph Conductance. In NeurIPS. 10654–10663.
[71] Chen Zhe, Aixin Sun, and Xiaokui Xiao. 2019. Community Detection on Large
Complex Attribute Network. In KDD. 2041–2049.
[72] Dawei Zhou, Si Zhang, Mehmet Yigit Yildirim, Scott Alcorn, Hanghang Tong,
Hasan Davulcu, and Jingrui He. 2017. A Local Algorithm for Structure-Preserving
Graph Cut. In KDD. 655–664.
[73] Dawei Zhou, Si Zhang, Mehmet Yigit Yildirim, Scott Alcorn, Hanghang Tong,
Hasan Davulcu, and Jingrui He. 2021. High-Order Structure Exploration on
Massive Graphs: A Local Graph Clustering Perspective. ACM Trans. Knowl.
Discov. Data 15, 2 (2021), 18:1–18:26.
[74] Chunxue Zhu, Longlong Lin, Pingpeng Yuan, and Hai Jin. 2022. Discovering Co-
hesive Temporal Subgraphs with Temporal Density Aware Exploration. Journal
of Computer Science and Technology (2022).
 
1803