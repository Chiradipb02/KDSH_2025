SLADE: Detecting Dynamic Anomalies in Edge Streams without
Labels via Self-Supervised Learning
Jongha Lee
KAIST
Seoul, Republic of Korea
jhsk777@kaist.ac.krSunwoo Kim
KAIST
Seoul, Republic of Korea
kswoo97@kaist.ac.krKijung Shin
KAIST
Seoul, Republic of Korea
kijungs@kaist.ac.kr
Abstract
To detect anomalies in real-world graphs, such as social, email,
and financial networks, various approaches have been developed.
While they typically assume static input graphs, most real-world
graphs grow over time, naturally represented as edge streams. In
this context, we aim to achieve three goals: (a) instantly detecting
anomalies as they occur, (b) adapting to dynamically changing
states, and (c) handling the scarcity of dynamic anomaly labels.
In this paper, we propose SLADE (Self-supervised Learning for
Anomaly Detection in Edge Streams) for rapid detection of dynamic
anomalies in edge streams, without relying on labels. SLADE detects
the shifts of nodes into abnormal states by observing deviations in
their interaction patterns over time. To this end, it trains a deep neu-
ral network to perform two self-supervised tasks: (a) minimizing
drift in node representations and (b) generating long-term interac-
tion patterns from short-term ones. Failure in these tasks for a node
signals its deviation from the norm. Notably, the neural network
and tasks are carefully designed so that all required operations can
be performed in constant time (w.r.t. the graph size) in response to
each new edge in the input stream. In dynamic anomaly detection
across four real-world datasets, SLADE outperforms nine compet-
ing methods, even those leveraging label supervision. Our code and
datasets are available at https://github.com/jhsk777/SLADE.
CCS Concepts
•Information systems →Data mining; Social networks.
Keywords
Edge Stream; Anomaly Detection; Self-supervised Learning
ACM Reference Format:
Jongha Lee, Sunwoo Kim, and Kijung Shin. 2024. SLADE: Detecting Dynamic
Anomalies in Edge Streams without Labels via Self-Supervised Learning. In
Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery
and Data Mining (KDD ’24), August 25–29, 2024, Barcelona, Spain. ACM, New
York, NY, USA, 12 pages. https://doi.org/10.1145/3637528.3671845
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
KDD ’24, August 25–29, 2024, Barcelona, Spain
©2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 979-8-4007-0490-1/24/08
https://doi.org/10.1145/3637528.36718451 Introduction
The evolution of web technologies has dramatically enhanced hu-
man life. Platforms such as email and social networks have made
people communicating with diverse individuals and accessing help-
ful information easier. Additionally, e-commerce has enabled people
to engage in economic activities easily. However, as convenience
has increased, many problems have emerged, such as financial
crimes, social media account theft, and spammer that exploited it.
Many graph anomaly detection techniques [ 26,28] have been
developed for tackling these problems. These techniques involve
representing the interactions between users as a graph, thereby
harnessing the connectivity between users to effectively identify
anomalies. However, graph anomaly detection in real-world sce-
narios poses several challenges, as discussed below.
C1) Time Delay in Detection:C1) Time Delay in Detection:C1) Time Delay in Detection:C1) Time Delay in Detection:C1) Time Delay in Detection:C1) Time Delay in Detection:C1) Time Delay in Detection:C1) Time Delay in Detection:C1) Time Delay in Detection:C1) Time Delay in Detection:C1) Time Delay in Detection:C1) Time Delay in Detection:C1) Time Delay in Detection:C1) Time Delay in Detection:C1) Time Delay in Detection:C1) Time Delay in Detection:C1) Time Delay in Detection: While most graph anomaly detec-
tion methods assume static input graphs, real-world graphs evolve
over time with continuous interaction events. In response to con-
tinuous interaction events, it is important to quickly identify anom-
alies. Delaying the detection of such anomalies can lead to increas-
ing harm to benign nodes as time passes. However, employing static
graph-based methods repeatedly on the entire graph, whenever an
interaction event occurs, inevitably leads to significant delays due
to the substantial computational expenses involved. To mitigate
delays, it is necessary to model continuous interaction events as
edge streams and employ incremental computation to assess the ab-
normality of each newly arriving edge with detection time constant
regardless of the accumulated data size.
Many studies [ 4,12] have developed anomaly detection methods
for edge streams, leveraging incremental computation. However, as
these methods are designed to target specific anomaly types (e.g.,
burstiness), lacking learning-based components, they are often
limited in capturing complex ones deviating from targeted types.
C2) Dynamically Changing States:C2) Dynamically Changing States:C2) Dynamically Changing States:C2) Dynamically Changing States:C2) Dynamically Changing States:C2) Dynamically Changing States:C2) Dynamically Changing States:C2) Dynamically Changing States:C2) Dynamically Changing States:C2) Dynamically Changing States:C2) Dynamically Changing States:C2) Dynamically Changing States:C2) Dynamically Changing States:C2) Dynamically Changing States:C2) Dynamically Changing States:C2) Dynamically Changing States:C2) Dynamically Changing States: In web services, users can
exhibit dynamic states varying over time. That is, a user’s behavior
can be normal during one time period but abnormal during another.
For example, a normal user’s account can be compromised and
then manipulated to disseminate promotional messages. As a result,
the user’s state transitions from normal to abnormal. Such a user
can be referred to as a dynamic anomaly, and detecting dynamic
anomalies presents a greater challenge compared to the relatively
easier task of identifying static anomalies.
Addressing this challenge can be facilitated by tracking the evo-
lution of node characteristics over time, and to this end, dynamic
node representation learning methods [ 29,39] can be employed.
However, existing dynamic node representation learning meth-
ods require label information for the purpose of anomaly detection,
which is typically scarce, as elaborated in the following paragraph.
 
1506
KDD ’24, August 25–29, 2024, Barcelona, Spain Jongha Lee, Sunwoo Kim, and Kijung Shin
C3) Lack of Anomaly Labels:C3) Lack of Anomaly Labels:C3) Lack of Anomaly Labels:C3) Lack of Anomaly Labels:C3) Lack of Anomaly Labels:C3) Lack of Anomaly Labels:C3) Lack of Anomaly Labels:C3) Lack of Anomaly Labels:C3) Lack of Anomaly Labels:C3) Lack of Anomaly Labels:C3) Lack of Anomaly Labels:C3) Lack of Anomaly Labels:C3) Lack of Anomaly Labels:C3) Lack of Anomaly Labels:C3) Lack of Anomaly Labels:C3) Lack of Anomaly Labels:C3) Lack of Anomaly Labels: Deep neural networks, such as graph
neural networks, have proven effective in detecting complex anom-
alies within graph-structured data. However, they typically rely on
label supervision for training, which can be challenging to obtain,
especially for dynamic anomalies. Assuming the absence of anom-
aly labels, various unsupervised training techniques [ 10,24] have
been developed for anomaly detection in static graphs.
However, to the best of our knowledge, existing methods cannot
simultaneously address all three challenges. They either lack the
ability to detect dynamic anomalies, lack incremental detection
suitable for edge streams, or rely on labels.
In this work, we propose SLADE (Self-supervised Learning for
Anomaly Detection in Edge Streams) to simultaneously tackle all
three challenges. Its objective is to incrementally identify dynamic
anomalies in edge streams, without relying on any label supervision.
To achieve this, SLADE learns dynamic representations of nodes
over time, which capture their long-term interaction patterns, by
training a deep neural network to perform two self-supervised tasks:
(a) minimizing drift in the representations and (b) generating long-
term interaction patterns from short-term ones. Poor performance
on these tasks for a node indicates its deviation from its interac-
tion pattern, signaling a potential transition to an abnormal state.
Notably, our careful design ensures that all required operations are
executed in constant time (w.r.t. the graph size) in response to each
new edge in the input stream. Our experiments involving dynamic
anomaly detection by 9 competing methods across 4 real-world
datasets confirm the strengths of SLADE, outlined below:
•Unsupervised: We propose SLADE to detect complex dynamic
anomalies in edge streams, without relying on label supervision.
•Effective: In dynamic anomaly detection, SLADE shows an av-
erage improvement of 12.80% and 4.23% (in terms of AUC) com-
pared to the best-performing (in each dataset) unsupervised and
supervised competitors, respectively.
•Constant Inference Speed: We show both theoretically and
empirically that, once trained, SLADE requires a constant amount
time per edge for dynamic anomaly detection in edge streams.
2 Related Work
In this section, we provide a concise review of graph-based anomaly
detection methods, categorized based on the nature of input graphs.
2.1 Anomaly Detection in CTDGs
Acontinuous-time dynamic graph (CTDG) is a stream of edges
accompanied by timestamps, which we also term an edge stream.
Unsupervised Anomaly Detection in CTDGs:Unsupervised Anomaly Detection in CTDGs:Unsupervised Anomaly Detection in CTDGs:Unsupervised Anomaly Detection in CTDGs:Unsupervised Anomaly Detection in CTDGs:Unsupervised Anomaly Detection in CTDGs:Unsupervised Anomaly Detection in CTDGs:Unsupervised Anomaly Detection in CTDGs:Unsupervised Anomaly Detection in CTDGs:Unsupervised Anomaly Detection in CTDGs:Unsupervised Anomaly Detection in CTDGs:Unsupervised Anomaly Detection in CTDGs:Unsupervised Anomaly Detection in CTDGs:Unsupervised Anomaly Detection in CTDGs:Unsupervised Anomaly Detection in CTDGs:Unsupervised Anomaly Detection in CTDGs:Unsupervised Anomaly Detection in CTDGs: The majority of
unsupervised anomaly detection techniques applied to CTDGs aim
to identify specific anomaly types. Sedanspot [ 12] focuses on de-
tecting (a) bursts of activities and (b) bridge edges between sparsely
connected parts of the input graph. MIDAS [ 4] aims to spot bursts of
interactions within specific groups, and F-FADE [ 6] is effective for
identifying sudden surges in interactions between specific pairs of
nodes and swift changes in the community memberships of nodes.
Lastly, AnoGraph [ 5] spots dense subgraph structures along with
the anomalous edges contained within them. These methods are
generally efficient, leveraging incremental computation techniques.
Nonetheless, as previously mentioned, many of these approacheslack learnable components and thus may encounter challenges in
identifying complex anomaly patterns, i.e., deviations from normal
patterns in various aspects that may not be predefined.
Representation Learning in CTDGs:Representation Learning in CTDGs:Representation Learning in CTDGs:Representation Learning in CTDGs:Representation Learning in CTDGs:Representation Learning in CTDGs:Representation Learning in CTDGs:Representation Learning in CTDGs:Representation Learning in CTDGs:Representation Learning in CTDGs:Representation Learning in CTDGs:Representation Learning in CTDGs:Representation Learning in CTDGs:Representation Learning in CTDGs:Representation Learning in CTDGs:Representation Learning in CTDGs:Representation Learning in CTDGs: Representation learning in
CTDGs involves maintaining and updating representations of nodes
in response to each newly arriving edge, capturing evolving pat-
terns of nodes over time. To this end, several neural-network archi-
tectures have been proposed. JODIE [ 20] utilizes recurrent-neural-
network (RNN) modules to obtain dynamic node representations.
Dyrep [ 34] combines a deep temporal point process [ 1] with RNNs.
TGAT [ 39] leverages temporal encoding and graph attention [ 36]
to incorporate temporal information during neighborhood aggrega-
tion. Based on temporal smoothness, DDGCL [ 33] learns dynamic
node representations by contrasting those of the same nodes in
two nearby temporal views. TGN [ 29] utilizes a memory module
to capture and store long-term patterns. This module is updated
using an RNN for each node, providing representations that encom-
pass both temporal and spatial characteristics. Many subsequent
studies [ 37,38] have also adopted memory modules. Assuming a
gradual process where memories for nodes do not show substan-
tial disparities before and after updates, DGTCC [ 13] contrasts
memories before and after updates for training.
For the purpose of anomaly detection, dynamic node represen-
tations can naturally be used as inputs for a classifier, which is
trained in a supervised manner using anomaly labels. Recently,
more advanced anomaly detection methods based on representa-
tion learning in CTDGs have been proposed. SAD [ 32] combines a
memory bank with pseudo-label contrastive learning, which, how-
ever, requires anomaly labels for training.
2.2 Anomaly Detection in Other Graph Models
In this subsection, we introduce anomaly detection approaches
applied to other graph models.
Anomaly Detection in Static Graphs:Anomaly Detection in Static Graphs:Anomaly Detection in Static Graphs:Anomaly Detection in Static Graphs:Anomaly Detection in Static Graphs:Anomaly Detection in Static Graphs:Anomaly Detection in Static Graphs:Anomaly Detection in Static Graphs:Anomaly Detection in Static Graphs:Anomaly Detection in Static Graphs:Anomaly Detection in Static Graphs:Anomaly Detection in Static Graphs:Anomaly Detection in Static Graphs:Anomaly Detection in Static Graphs:Anomaly Detection in Static Graphs:Anomaly Detection in Static Graphs:Anomaly Detection in Static Graphs: Many approaches [ 10,11,
23] have been developed for anomaly detection in a static graph,
which does not contain any temporal information. Among them, we
focus on those leveraging graph self-supervised learning, which ef-
fectively deals with the absence of anomaly labels. ANEMONE [ 14]
contrasts node representations obtained from (a) features alone
and (b) both graph topology and features, identifying nodes with
substantial differences as anomalies. DOMINANT [ 10] aims to re-
construct graph topology and attributes, using a graph-autoencoder
module, and anomalies are identified based on reconstruction error.
These approaches assume a static graph, and their extensions to
dynamic graphs are not trivial, as node representations need to
evolve over time to accommodate temporal changes.
Anomaly Detection in DTDGs:Anomaly Detection in DTDGs:Anomaly Detection in DTDGs:Anomaly Detection in DTDGs:Anomaly Detection in DTDGs:Anomaly Detection in DTDGs:Anomaly Detection in DTDGs:Anomaly Detection in DTDGs:Anomaly Detection in DTDGs:Anomaly Detection in DTDGs:Anomaly Detection in DTDGs:Anomaly Detection in DTDGs:Anomaly Detection in DTDGs:Anomaly Detection in DTDGs:Anomaly Detection in DTDGs:Anomaly Detection in DTDGs:Anomaly Detection in DTDGs: Adiscrete-time dynamic graph
(DTDG) corresponds to a sequence of graphs occurring at each time
instance, also referred to as a graph stream. Formally, a DTDG is a
set
G1,G2,···,G𝑇	
whereG𝑡=
V𝑡,E𝑡	
is the graph snapshot
at time𝑡, andV𝑡andE𝑡are node- and edge-set in G𝑡, respectively
[15]. Several methods have been developed for detecting anom-
alies, with an emphasis on anomalous edges, in a DTDG, which is
a sequence of graphs at each time instance. Netwalk [ 40] employs
random walks and autoencoders to create similar representations
for nodes that frequently interact with each other. Then, it identifies
 
1507SLADE: Detecting Dynamic Anomalies in Edge Streams without Labels via Self-Supervised Learning KDD ’24, August 25–29, 2024, Barcelona, Spain
interactions between nodes with distinct representations as anoma-
lous. AddGraph [ 41] constructs node representations through an
attentive combination of (a) short-term structural patterns within
the current graph (and a few temporally-adjacent graphs) captured
by a graph neural network (spec., GCN [ 18]) and (b) long-term
patterns captured by an RNN (spec., GRU [ 7]). These node repre-
sentations are then employed to evaluate the anomalousness of
edges. Instead, transformers [ 35] are employed in TADDY [ 25] to
acquire node representations that capture both global and local
structural patterns. Note that these methods designed for DTDGs
are less suitable for time-critical applications when compared to
those for designed CTDGs, as discussed in Section 3. Moreover,
technically, these methods are trained to distinguish edges and non-
edge node pairs, while our proposed method contrasts long-term
and short-term patterns for training.
3 Problem Description
In this section, we introduce notations and, based on them, define
the problem of interest, dynamic node anomaly detection in CTDGs.
Notations:Notations:Notations:Notations:Notations:Notations:Notations:Notations:Notations:Notations:Notations:Notations:Notations:Notations:Notations:Notations:Notations: A continuous-time dynamic graph (CTDG) G=(𝛿1,𝛿2,
···) is a stream (i.e., continuous sequence) of temporal edges with
timestamps. Each temporal edge 𝛿𝑛=(𝑣𝑖,𝑣𝑗,𝑡𝑛)arriving at time 𝑡𝑛
is directional from the source node𝑣𝑖to the destination node 𝑣𝑗. The
temporal edges are ordered chronologically, i.e., 𝑡𝑛≤𝑡𝑛+1holds for
each𝑛∈{1,2,···}. We denote byV(𝑡)=Ð
(𝑣𝑖,𝑣𝑗,𝑡𝑛)∈G∧𝑡𝑛≤𝑡{𝑣𝑖,𝑣𝑗}
the temporal set of nodes arriving at time 𝑡or earlier.
Problem Description:Problem Description:Problem Description:Problem Description:Problem Description:Problem Description:Problem Description:Problem Description:Problem Description:Problem Description:Problem Description:Problem Description:Problem Description:Problem Description:Problem Description:Problem Description:Problem Description: We consider a CTDG G=(𝛿1,𝛿2,···),
where each temporal edge 𝛿𝑛=(𝑣𝑖,𝑣𝑗,𝑡𝑛)indicates a behavior
of the source node 𝑣𝑖towards the destination node 𝑣𝑗at time𝑡𝑛.
That is, the source node represents the “actor” node. We aim to ac-
curately classify the current dynamic status of each node, which is
either normal orabnormal. We address this problem in an unsuper-
vised setting. That is, we do not have access to the dynamic states
of any nodes at any time as input. In our experimental setups, the
ground-truth dynamic states are used only for evaluation purposes.
Real-world Scenarios:Real-world Scenarios:Real-world Scenarios:Real-world Scenarios:Real-world Scenarios:Real-world Scenarios:Real-world Scenarios:Real-world Scenarios:Real-world Scenarios:Real-world Scenarios:Real-world Scenarios:Real-world Scenarios:Real-world Scenarios:Real-world Scenarios:Real-world Scenarios:Real-world Scenarios:Real-world Scenarios: Due to its substantial impact, this prob-
lem has been explored in many previous studies [ 20,29,34,39],
but in supervised settings. For instance, in web services, a normal
user’s account can be compromised and then exploited to circulate
promotional messages. In such a case, the user’s state transitions
from normal to abnormal. Detecting such transitions promptly is
crucial to minimize the inconvenience caused by the dissemination
of promotional messages.
Why CTDGs?:Why CTDGs?:Why CTDGs?:Why CTDGs?:Why CTDGs?:Why CTDGs?:Why CTDGs?:Why CTDGs?:Why CTDGs?:Why CTDGs?:Why CTDGs?:Why CTDGs?:Why CTDGs?:Why CTDGs?:Why CTDGs?:Why CTDGs?:Why CTDGs?: Anomaly detection methods designed for DTDGs
(refer to Section 2.2) process input on a per-graph basis, where
edges need to be aggregated over time to form a graph. Thus, they
are susceptible to delays in predicting the current state of nodes
upon the arrival of an edge. In theory, methods designed for static
graphs can be applied to our problem by re-running them when-
ever a new edge arrives. However, this straightforward application
makes their time complexity per edge (super-)linear in the graph
size, causing notable delays. However, CTDG-based methods, in-
cluding our proposed one, process the arriving edge, whenever it
arrives, typically with constant time complexity regardless of the ac-
cumulated graph size. As discussed in Section 1, this highlights theadvantages of CTDG-based methods in time-critical applications,
including (dynamic) anomaly detection.
Comparison with Edge Anomaly Detection:Comparison with Edge Anomaly Detection:Comparison with Edge Anomaly Detection:Comparison with Edge Anomaly Detection:Comparison with Edge Anomaly Detection:Comparison with Edge Anomaly Detection:Comparison with Edge Anomaly Detection:Comparison with Edge Anomaly Detection:Comparison with Edge Anomaly Detection:Comparison with Edge Anomaly Detection:Comparison with Edge Anomaly Detection:Comparison with Edge Anomaly Detection:Comparison with Edge Anomaly Detection:Comparison with Edge Anomaly Detection:Comparison with Edge Anomaly Detection:Comparison with Edge Anomaly Detection:Comparison with Edge Anomaly Detection: In many scenar-
ios, the dynamic state of an actor node can be equated with the
anomalousness (or maliciousness) of its behavior. In other words,
an actor node is assumed to be in the abnormal state if and only
if it performs anomaly (or malicious) behavior. In such cases, this
task shares some similarities with detecting anomalous edges. How-
ever, it should be noticed that the predicted current node states are
used for predicting the anomalousness of future interactions (see
Section 4.3) rather than assessing the anomalousness of interac-
tions that have already occurred. Hence, for effective dynamic node
anomaly detection, it is important to consider node-wise behavioral
dynamics over time.
4 Proposed Method: SLADE
In this section, we present SLADE (Self-supervised Learning for
Anomaly Detection in Edge Streams), our proposed method for
unsupervised dynamic anomaly detection in CTDGs.
The underlying intuition is that nodes in the normal state tend
to exhibit structurally and temporally similar interaction patterns
over time [ 2,3], while those in the abnormal state do not because
repeating similar abnormal actions increases the risk of detection.
Motivated by this idea, we consider two key assumptions:
•A1. Stable Long-Term Interaction Patterns: Nodes in the
normal state tend to repetitively engage in similar interactions
over a long-term period. This stable long-term interaction pattern
exhibits minimal variation within short-time intervals.
•A2. Potential for Restoration of Patterns: It would be feasible
to accurately regenerate the long-term interaction patterns of the
nodes in the normal state using recent interaction information.
They account for both structural and temporal aspects of normal
nodes. While A1focuses on temporal aspects, A2takes a further
step by specifying the extent of structural similarities over time.
Upon these assumptions, SLADE employs two self-supervised
tasks for training its model (i.e., deep neural network) for maintain-
ing and updating a dynamic representation of each node, which we
expect to capture its long-term interaction pattern.
•S1. Temporal Contrast: This aims to minimize drift in dynamic
node representations over short-term periods (related to A1).
•S2. Memory Generation: This aims to accurately generate dy-
namic node representations based only on recent interactions
(related to A2).
By being trained for S1andS2, the model is expected to learn
normal interaction patterns satisfying A1andA2. Once the model
is trained, SLADE identifies nodes for which the model performs
poorly on S1andS2, as these nodes potentially deviate from pre-
sumed normal interaction patterns.
Specifically, to obtain dynamic representations, SLADE employs
neural networks in combination with memory modules (see Sec-
tion 4.1). The memories (i.e, stored information), which reflect the
normal patterns of nodes, are updated and regenerated to minimize
our self-supervised losses related to S1andS2(see Section 4.2).
Lastly, these dynamic representations are compared with their past
values and momentary representations to compute anomaly scores
 
1508KDD ’24, August 25–29, 2024, Barcelona, Spain Jongha Lee, Sunwoo Kim, and Kijung Shin
𝒔𝑗
𝒔𝑙Previous memory 𝒔𝑖’
Message 𝒎𝑖Current memory 𝒔𝑖
Generated memory ො𝒔𝑖
Recent neighbors aggregationTGATMemory Updater
Memory GeneratorTemporal Contrast Memory Generation
Previous memory 𝒔𝑖’
Current memory 𝒔𝑖
Generated memory ො𝒔𝑖
Anomaly score( 𝑣𝑖, 𝑡)
(c) Self -supervised Learning (d) Anomaly Scoring𝑣𝑙𝑣𝑗
𝑣𝑘𝑣𝑖𝑡𝑖𝑗
𝑡𝑘𝑖𝑡𝑖𝑙(a) Input Edge Stream…
𝑣𝑖𝑡𝑖𝑗𝑣𝑗
𝑣𝑖𝑡12𝑣1𝑣2
𝑡23𝑣2𝑣3
Raw message 𝒓𝑖Cosine Similarity
𝑣𝑖𝑣𝑗
Interaction𝑣1…𝑣𝑖𝑣𝑗
Memory module
Memory masking
𝒔𝑘𝑣𝑖MLPGRU
(b) Query at time t
Figure 1: Overview of SLADE, whose objective is to measure the anomaly score of a query node at any time. For each newly
arriving edge, SLADE updates the memory vector of each endpoint using GRU. Given a query node, SLADE masks the memory
vector of the node and approximately regenerates it based on its recent interactions using TGAT. Then, it measures the anomaly
score of the query node based on the similarities (1) between previous and current memory vectors (related to S1) and (2)
between current and generated memory vectors (related to S2). SLADE aims to maximize these similarities for model training.
for nodes (see Section 4.3). The overview of SLADE is visually pre-
sented in Figure 1, and the following subsections provide detailed
descriptions of each of its components.
4.1 Core Modules of SLADE
In order to incrementally compute the dynamic representation of
each node, SLADE employs three core modules:
•Memory Module: These time-evolving parameter vectors rep-
resent the long-term interaction patterns of each node, i.e., how
a node’s interaction has evolved over time.
•Memory Updater: This neural network captures evolving char-
acteristics of nodes’ interaction patterns. It is employed to update
the memory (i.e., stored information).
•Memory Generator: This neural network is used to generate
the memory of a target node from its recent interactions.
Below, we examine the details of each module in order.
Memory Module:Memory Module:Memory Module:Memory Module:Memory Module:Memory Module:Memory Module:Memory Module:Memory Module:Memory Module:Memory Module:Memory Module:Memory Module:Memory Module:Memory Module:Memory Module:Memory Module: InSLADE, the dynamic representation of each
node, which represents its long-term interaction patterns, is stored
and updated in a memory module introduced by Rossi et al . [29] .
Specifically, the memory module consists of a memory vector 𝒔𝑖
for each node 𝑣𝑖, and each 𝒔𝑖captures the interactions of the node
𝑣𝑖up to the current time. When each node 𝑣𝑖first emerges in the
input CTDG, 𝒔𝑖is initialized to a zero vector. As 𝑣𝑖participates in
interactions, 𝒔𝑖is continuously updated by the memory updater,
described in the following subsection.
Memory Updater:Memory Updater:Memory Updater:Memory Updater:Memory Updater:Memory Updater:Memory Updater:Memory Updater:Memory Updater:Memory Updater:Memory Updater:Memory Updater:Memory Updater:Memory Updater:Memory Updater:Memory Updater:Memory Updater: Whenever a node participates in a new inter-
action, the memory updater gradually updates its memory vector,
aiming to represent its stable long-term interaction pattern. First,
each interaction is transformed into raw messages [ 29]. Each raw
message consists of the encoded time difference between the most
recent appearance of one endpoint and the present time, along with
the memory vector of the other endpoint. For instance, upon the
arrival of a temporal edge (𝑣𝑖,𝑣𝑗,𝑡𝑖𝑗)at time𝑡𝑖𝑗, with𝑣𝑖and𝑣𝑗having memory vectors 𝒔′
𝑖and𝒔′
𝑗, respectively, the raw messages
for the source and destination nodes are created as follows:
𝒓𝑖=[𝒔′
𝑗||𝜙(𝑡𝑖𝑗−𝑡−
𝑖)],𝒓𝑗=[𝒔′
𝑖||𝜙(𝑡𝑖𝑗−𝑡−
𝑗)], (1)
where||denotes a concatenate operator, and 𝑡−
𝑖denotes the time
of the last interaction of 𝑣𝑖before the interaction time 𝑡𝑖𝑗. Follow-
ing [9], as the time encoding function 𝜙(·), we use
𝜙(𝑡′)=𝑐𝑜𝑠
𝑡′·[𝛼−0
𝛽||𝛼−1
𝛽||···||𝛼−𝑑𝑡−1
𝛽]
, (2)
where·denotes the inner product, and 𝑑𝑡denotes the dimension
of encoded vectors. Scalars 𝛼,𝛽and𝑑𝑡are hyperparameters.
Then, the raw message 𝒓𝑖is converted to a message 𝒎𝑖, employ-
ing an MLP and then used to update from 𝒔′
𝑖to𝒔𝑖, as follows:
𝒔𝑖=GRU(𝒎𝑖,𝒔′
𝑖)where 𝒎𝑖=MLP(𝒓𝑖). (3)
Here 𝒔𝑖is the memory vector for node 𝑣𝑖after time𝑡𝑖𝑗, persisting
until a new interaction involving node 𝑣𝑖occurs (see Section 6.2
(RQ5) for exploration of alternatives to GRU [ 7]). We also maintain
𝒔′
𝑖(i.e., the previous value of the memory vector) for its future usage.
Memory Generator:Memory Generator:Memory Generator:Memory Generator:Memory Generator:Memory Generator:Memory Generator:Memory Generator:Memory Generator:Memory Generator:Memory Generator:Memory Generator:Memory Generator:Memory Generator:Memory Generator:Memory Generator:Memory Generator: The memory generator aims to restore the
memory vectors, which represent existing long-term interaction
patterns, based on short-term interactions. The generated vectors
are used for training and anomaly scoring, as described later.
The first step of generation is to (temporarily) mask the memory
vector of a target node at current time 𝑡to a zero vector. Then, the
memory vectors of its at most 𝑘latest (1-hop) neighbors and the
corresponding time information of their latest interactions are used
as inputs of an encoder. As the encoder, we employ TGAT [ 39],
which attends more to recent interactions (see Section 6.2 (RQ5)
for exploration of alternatives). That is, for a target node 𝑣𝑖and the
 
1509SLADE: Detecting Dynamic Anomalies in Edge Streams without Labels via Self-Supervised Learning KDD ’24, August 25–29, 2024, Barcelona, Spain
current time 𝑡, we generate its memory vector as follows:
ˆ𝒔𝑖=MultiHeadAttention (𝒒,K,V),where 𝒒=𝜙(𝑡−𝑡),
andK=V=
s𝑛1||𝜙(𝑡−𝑡′
𝑛1),···,s𝑛𝑘||𝜙(𝑡−𝑡′
𝑛𝑘)
.
Here{𝑛1,...,𝑛𝑘}denote the indices of the neighbors of the target
node𝑣𝑖,{𝑡′𝑛1,...,𝑡′𝑛𝑘}denote the timestamps of the most recent in-
teractions with them before 𝑡, and ˆs𝑖denotes the generated memory
vector of𝑣𝑖at𝑡. As the memory vector has been masked, only time
information is used for query component 𝒒.
4.2 Training Objective and Procedure
For the proposed temporal contrast task (S1) and memory genera-
tion task (S2), SLADE is trained to minimize two loss components:
•Temporal Contrast Loss: It encourages the agreement between
previous and updated memory vectors.
•Memory Generation Loss: It encourages the similarity between
retained and generated memory vectors.
Below, we describe each self-supervised loss component and then
the entire training process in greater detail.
Temporal Contrast Loss:Temporal Contrast Loss:Temporal Contrast Loss:Temporal Contrast Loss:Temporal Contrast Loss:Temporal Contrast Loss:Temporal Contrast Loss:Temporal Contrast Loss:Temporal Contrast Loss:Temporal Contrast Loss:Temporal Contrast Loss:Temporal Contrast Loss:Temporal Contrast Loss:Temporal Contrast Loss:Temporal Contrast Loss:Temporal Contrast Loss:Temporal Contrast Loss: ForS1, we aim to minimize drift in
dynamic node representations within short time intervals. For the
memory vector 𝒔𝑖of each node 𝑣𝑖, we use the previous memory
vector 𝒔′
𝑖as the positive sample and the memory vectors of the
other nodes as negative samples. Specifically, for each interaction
at time𝑡of𝑣𝑖, we aim to minimize the following loss:
ℓ𝑐(𝑣𝑖,𝑡)=−logexp(𝑠𝑖𝑚(𝒔𝑖(𝑡+),𝒔′
𝑖(𝑡+)))
Í|V(𝑡+)|
𝑘=1exp(𝑠𝑖𝑚(𝒔𝑖(𝑡+),𝒔𝑘(𝑡+))), (4)
where 𝒔𝑖(𝑡+)is the current memory vector 𝒔𝑖right after processing
the interaction at 𝑡(denoted as𝑡+to distinguish it from 𝑡right before
processing the interaction), 𝒔′
𝑖(𝑡+)is the previous memory vector,
and𝑠𝑖𝑚is the cosine similarity function, i.e., 𝑠𝑖𝑚(𝒖,𝒗)=∥𝒖·𝒗∥
∥𝒖∥·∥𝒗∥.
Memory Generation Loss:Memory Generation Loss:Memory Generation Loss:Memory Generation Loss:Memory Generation Loss:Memory Generation Loss:Memory Generation Loss:Memory Generation Loss:Memory Generation Loss:Memory Generation Loss:Memory Generation Loss:Memory Generation Loss:Memory Generation Loss:Memory Generation Loss:Memory Generation Loss:Memory Generation Loss:Memory Generation Loss: ForS2, we aim to accurately generate
dynamic node representations from recent interactions (i.e., short-
term patterns). For each node 𝑣𝑖, we expect its generated memory
vector ˆ𝒔𝑖to be matched well with the (temporally masked) memory
vector 𝒔𝑖, relative to other memory vectors. Specifically, for each
interaction at time 𝑡of𝑣𝑖, we aim to minimize the following loss:
ℓ𝑔(𝑣𝑖,𝑡)=−logexp(𝑠𝑖𝑚(ˆ𝒔𝑖(𝑡+),𝒔𝑖(𝑡+)))
Í|V(𝑡+)|
𝑘=1exp(𝑠𝑖𝑚(ˆ𝒔𝑖(𝑡+),𝒔𝑘(𝑡+))), (5)
where 𝒔𝑖(𝑡+)is the current memory vector 𝒔𝑖after processing the
interaction at 𝑡, and ˆ𝒔𝑖(𝑡+)is the generated memory vector ˆ𝒔𝑖. We
propose a novel self-supervised learning task that encourages a
model to learn the normal temporal pattern of data.
Batch Processing for Efficient Training:Batch Processing for Efficient Training:Batch Processing for Efficient Training:Batch Processing for Efficient Training:Batch Processing for Efficient Training:Batch Processing for Efficient Training:Batch Processing for Efficient Training:Batch Processing for Efficient Training:Batch Processing for Efficient Training:Batch Processing for Efficient Training:Batch Processing for Efficient Training:Batch Processing for Efficient Training:Batch Processing for Efficient Training:Batch Processing for Efficient Training:Batch Processing for Efficient Training:Batch Processing for Efficient Training:Batch Processing for Efficient Training: For computational ef-
ficiency, we employ batch processing for training SLADE, which
has been commonly used [ 29,32,39]. That is, instead of process-
ing a single edge at a time, multiple edges are fed into the model
simultaneously. To this end, a stream of temporal edges is divided
into batches of a fixed size in chronological order. Consequently,
memory updates take place at the batch level, and for these updates,
the model uses only the interaction information that precedes the
current batch. Note that a single node can be engaged in multipleinteractions within a single batch, leading to multiple raw mes-
sages for the node. To address this, SLADE aggregates the raw
messages into one raw message using mean pooling and continues
with the remaining steps of memory update. In order for the tem-
poral contrast in Eq. (4)reflects A1, which emphasizes minimizing
the difference between memory vectors before and after an update
within a “short” time span, the batch size should not be excessively
large. Therefore, it is crucial to establish an appropriate batch size,
taking both this and efficiency into consideration.
Final Training Objective:Final Training Objective:Final Training Objective:Final Training Objective:Final Training Objective:Final Training Objective:Final Training Objective:Final Training Objective:Final Training Objective:Final Training Objective:Final Training Objective:Final Training Objective:Final Training Objective:Final Training Objective:Final Training Objective:Final Training Objective:Final Training Objective: For each batch 𝐵with temporal edges
E𝐵, the overall temporal contrast loss is defined as follows:
L𝑐=1
|E𝐵|∑︁
(𝑣𝑖,𝑣𝑗,𝑡)∈E𝐵𝜔𝑐𝑠ℓ𝑐(𝑣𝑖,𝑡)+𝜔𝑐𝑑ℓ𝑐(𝑣𝑗,𝑡), (6)
where𝜔𝑐𝑠and𝜔𝑐𝑑are hyperparameters for weighting each source
node and each destination node, respectively. Similarly, the overall
memory generation loss for𝐵is defined as follows:
L𝑔=1
|E𝐵|∑︁
(𝑣𝑖,𝑣𝑗,𝑡)∈E𝐵𝜔𝑔𝑠ℓ𝑔(𝑣𝑖,𝑡)+𝜔𝑔𝑑ℓ𝑔(𝑣𝑗,𝑡), (7)
where𝜔𝑔𝑠and𝜔𝑔𝑑hyperparameters for weighting each source
node and each destination node, respectively.
The final lossLfor𝐵is the sum of both losses, i.e., L=L𝑐+L𝑔.
Note that, since anomaly labels are assumed to be unavailable,
SLADE is trained with the assumption that the state of all nodes
appearing in the training set is normal, irrespective of their actual
states. However, SLADE still can learn normal patterns effectively,
given that they constitute the majority of the training data, as
discussed for various types of anomalies in Section 5.1.
4.3 Anomaly Scoring
After being trained, SLADE is able to measure the anomaly score
of any node at any given time point. SLADE measures how much
each node deviates from A1andA2by computing the temporal
contrast score and the memory generation score, which are
based on A1andA2, respectively. Below, we describe each of them.
Temporal Contrast Score:Temporal Contrast Score:Temporal Contrast Score:Temporal Contrast Score:Temporal Contrast Score:Temporal Contrast Score:Temporal Contrast Score:Temporal Contrast Score:Temporal Contrast Score:Temporal Contrast Score:Temporal Contrast Score:Temporal Contrast Score:Temporal Contrast Score:Temporal Contrast Score:Temporal Contrast Score:Temporal Contrast Score:Temporal Contrast Score: This score is designed to detect anoma-
lous nodes that deviate from A1, and to this end, it measures the ex-
tent of abrupt changes in the long-term interaction pattern. Specif-
ically, the temporal contrast score 𝑠𝑐𝑐(𝑣𝑖,𝑡)of a node𝑣𝑖at time𝑡
(spec., before processing any interaction at 𝑡) is defined as the cosine
distance between its current and previous memory vectors:
𝑠𝑐𝑐(𝑣𝑖,𝑡)=1−𝑠𝑖𝑚(𝒔𝑖(𝑡),𝒔′
𝑖(𝑡)). (8)
Memory Generation Score:Memory Generation Score:Memory Generation Score:Memory Generation Score:Memory Generation Score:Memory Generation Score:Memory Generation Score:Memory Generation Score:Memory Generation Score:Memory Generation Score:Memory Generation Score:Memory Generation Score:Memory Generation Score:Memory Generation Score:Memory Generation Score:Memory Generation Score:Memory Generation Score: In order to identify anomalous nodes
deviating from A2, this score measures the degree of deviation of
short-term interaction patterns from long-term interaction patterns.
Specifically, the memory generation score 𝑠𝑐𝑔(𝑣𝑖,𝑡)of a node𝑣𝑖at
time𝑡is defined as the cosine distance between its current and
generated memory vectors:
𝑠𝑐𝑔(𝑣𝑖,𝑡)=1−𝑠𝑖𝑚(ˆ𝒔𝑖(𝑡),𝒔𝑖(𝑡)). (9)
Final Score:Final Score:Final Score:Final Score:Final Score:Final Score:Final Score:Final Score:Final Score:Final Score:Final Score:Final Score:Final Score:Final Score:Final Score:Final Score:Final Score: The final anomaly score is a combination of both
scores, i.e., the final score𝑠𝑐(𝑣𝑖,𝑡)of a node𝑣𝑖at time𝑡is defined as
𝑠𝑐(𝑣𝑖,𝑡)=(𝑠𝑐𝑐(𝑣𝑖,𝑡)+𝑠𝑐𝑔(𝑣𝑖,𝑡))/4, (10)
 
1510KDD ’24, August 25–29, 2024, Barcelona, Spain Jongha Lee, Sunwoo Kim, and Kijung Shin
where it is normalized to fall within the range of [0,1]. Nodes in
the normal state will have scores closer to 0, while those in the
abnormal state will have scores closer to 1.
Note that in our notation, 𝑠𝑐(𝑣𝑖,𝑡)denotes the anomaly score
before observing or processing any interaction at time 𝑡, if such
an interaction exists. We use this score to measure the potential
abnormality of node 𝑣𝑖’s current state and also that of its subsequent
action (which can occur at time 𝑡or later).
5 Discussion and Analysis
In this section, we discuss how SLADE deals with various types of
anomalies. Then, we analyze the time complexity of SLADE.
5.1 Discussion on Anomaly Types
Below, we discuss how SLADE can detect anomalies of various
types, without any prior information about the types. In Section 6.2
(RQ4), we empirically confirm its effectiveness for all these types.
T1) Hijacked Anomalies:T1) Hijacked Anomalies:T1) Hijacked Anomalies:T1) Hijacked Anomalies:T1) Hijacked Anomalies:T1) Hijacked Anomalies:T1) Hijacked Anomalies:T1) Hijacked Anomalies:T1) Hijacked Anomalies:T1) Hijacked Anomalies:T1) Hijacked Anomalies:T1) Hijacked Anomalies:T1) Hijacked Anomalies:T1) Hijacked Anomalies:T1) Hijacked Anomalies:T1) Hijacked Anomalies:T1) Hijacked Anomalies: This type involves a previously nor-
mal user’s account being compromised at some point, exhibiting
malicious behaviors that deviate from the user’s normal pattern.
SLADE, motivated by such anomalies, contrasts short-term and
long-term interaction patterns to spot them, as discussed above.
T2) New or Rarely-interacting Anomalies:T2) New or Rarely-interacting Anomalies:T2) New or Rarely-interacting Anomalies:T2) New or Rarely-interacting Anomalies:T2) New or Rarely-interacting Anomalies:T2) New or Rarely-interacting Anomalies:T2) New or Rarely-interacting Anomalies:T2) New or Rarely-interacting Anomalies:T2) New or Rarely-interacting Anomalies:T2) New or Rarely-interacting Anomalies:T2) New or Rarely-interacting Anomalies:T2) New or Rarely-interacting Anomalies:T2) New or Rarely-interacting Anomalies:T2) New or Rarely-interacting Anomalies:T2) New or Rarely-interacting Anomalies:T2) New or Rarely-interacting Anomalies:T2) New or Rarely-interacting Anomalies: Many deep learning-
based detection models struggle with anomalies involving (1) newly
introduced or (2) rarely interacting nodes due to limited data for
learning their normal behaviors. SLADE assigns a higher anomaly
score (both contrast and generation scores) to such nodes because
their memory vectors undergo substantial changes until their long-
term patterns are established. We find it advantageous to pay atten-
tion to such nodes because, in some of the real-world datasets we
used, including Wikipedia, Bitcoin-alpha, and Bitcoin-OTC, new
and rarely interacting nodes are more likely to engage in anomalous
actions than those with consistent interactions.1
T3) Consistent Anomalies:T3) Consistent Anomalies:T3) Consistent Anomalies:T3) Consistent Anomalies:T3) Consistent Anomalies:T3) Consistent Anomalies:T3) Consistent Anomalies:T3) Consistent Anomalies:T3) Consistent Anomalies:T3) Consistent Anomalies:T3) Consistent Anomalies:T3) Consistent Anomalies:T3) Consistent Anomalies:T3) Consistent Anomalies:T3) Consistent Anomalies:T3) Consistent Anomalies:T3) Consistent Anomalies: SLADE can also effectively identify
anomalies exhibiting interaction patterns that are consistent over
time but deviating from those of normal nodes. Due to the limited
capacity (i.e., expressiveness) of the neural networks used in it,
SLADE prioritizes learning prevalent patterns (i.e., those of normal
nodes) over less common abnormal ones. As a result, this can lead
to a violation of A2, causing SLADE to assign high anomaly scores,
especially memory generation scores, to such nodes.
5.2 Complexity Analysis
We analyze the time complexity of SLADE “in action” after be-
ing trained. Specifically, we examine the cost of (a) updating the
memory in response to a newly arrived edge, and (b) calculating
anomaly scores for a query node.
Memory Update:Memory Update:Memory Update:Memory Update:Memory Update:Memory Update:Memory Update:Memory Update:Memory Update:Memory Update:Memory Update:Memory Update:Memory Update:Memory Update:Memory Update:Memory Update:Memory Update: Given a newly arriving edge, SLADE updates
the memory vector of each endpoint using GRU. The total time com-
plexity is dominated by that of GRU, which is O(𝑑𝑠2+𝑑𝑠𝑑𝑚)[30],
where𝑑𝑠and𝑑𝑚indicate the dimensions of memory vectors and
messages respectively.
Anomaly Scoring:Anomaly Scoring:Anomaly Scoring:Anomaly Scoring:Anomaly Scoring:Anomaly Scoring:Anomaly Scoring:Anomaly Scoring:Anomaly Scoring:Anomaly Scoring:Anomaly Scoring:Anomaly Scoring:Anomaly Scoring:Anomaly Scoring:Anomaly Scoring:Anomaly Scoring:Anomaly Scoring: Given a query node, SLADE first aims to gener-
ate its memory vector using TGAT with input being a zero-masked
1We suspect that new or inactive accounts are typically used to perform anomalous
actions since the cost of being suspended is low for such accounts.memory of the query node and the memory vectors of its at most
𝑘most recent neighbors. Thus, the time complexity of obtaining
generated memory is O(𝑘𝑑𝑠2)[42] if we assume, for simplicity,
that the embedding dimension of the attention layers is the same
as the dimension 𝑑𝑠of the memory vectors. Then, SLADE com-
putes the similarities (a) between the current memory and previous
memory vectors and (b) between current and generated memory
vectors, takingO(𝑑𝑠2)time. As a result, the overall time complexity
ofSLADE for anomaly scoring of a node is O(𝑘𝑑𝑠2).
The time complexity for both tasks is O(𝑘𝑑𝑠2+𝑑𝑠𝑑𝑚), which
isconstant with respect to the graph size (i.e., the numbers of
accumulated nodes and edges). If we assume that anomaly scoring
(for each endpoint) is performed whenever each edge arrives, the
total complexity becomes linear in the number of accumulated
edges, as confirmed empirically in Section 6.2 (RQ2).
6 Experiments
In this section, we review our experiments for answering the fol-
lowing research questions:
•RQ1) Accuracy: How accurately does SLADE detect anomalies,
compared to state-of-the-art competitors?
•RQ2) Speed: Does SLADE exhibit detection speed constant with
respect to the graph size?
•RQ3) Ablation Study: Does every loss and score component of
SLADE contribute to its performance?
•RQ4) Type Analysis: CanSLADE accurately detect various
types of anomalies discussed in Section 5.1?
•RQ5) Structural Variants: How effective is SLADE’s model
architecture compared to other alternatives?
6.1 Experiment Details
In this subsection, we describe datasets, baseline methods, and eval-
uation metrics that are used throughout our experiments. Then, we
clarify the implementation details of the proposed method SLADE.
Datasets:Datasets:Datasets:Datasets:Datasets:Datasets:Datasets:Datasets:Datasets:Datasets:Datasets:Datasets:Datasets:Datasets:Datasets:Datasets:Datasets: We assess the performance of SLADE on four real-world
datasets: two social networks (Wikipedia and Reddit [ 20]) and two
online financial networks (Bitcoin-alpha and Bitcoin-OTC [ 19]).
The Wikipedia dataset records edits made by users on Wikipedia
pages. In this context, when a user is banned after a specific edit, the
user’s dynamic label is marked as abnormal. The Reddit dataset con-
sists of posts made by users on subreddits. The user’s dynamic label
indicates whether the user is banned after the specific post. The
Bitcoin-alpha and Bitcoin-OTC datasets are fundamentally struc-
tured as trust-weighted signed networks. Within these datasets,
Bitcoin alpha or OTC members assign ratings to other members,
ranging from -10 (total distrust) to +10 (complete trust). We uti-
lize these ratings with temporal information to identify anomalous
nodes and assign dynamic labels to users. Further details of the
dataset processing and the statistics are provided in Appendix A.
Across all datasets, we assess the performance of our method and
the baseline models by utilizing the final 15% of the dataset in
chronological order as the test set.
Baselines Methods and Evaluation Metric.:Baselines Methods and Evaluation Metric.:Baselines Methods and Evaluation Metric.:Baselines Methods and Evaluation Metric.:Baselines Methods and Evaluation Metric.:Baselines Methods and Evaluation Metric.:Baselines Methods and Evaluation Metric.:Baselines Methods and Evaluation Metric.:Baselines Methods and Evaluation Metric.:Baselines Methods and Evaluation Metric.:Baselines Methods and Evaluation Metric.:Baselines Methods and Evaluation Metric.:Baselines Methods and Evaluation Metric.:Baselines Methods and Evaluation Metric.:Baselines Methods and Evaluation Metric.:Baselines Methods and Evaluation Metric.:Baselines Methods and Evaluation Metric.: We extensively com-
pareSLADE with several baseline methods capable of anomaly de-
tection in CTDGs under inductive settings (i.e., without further opti-
mization for test sets). For four rule-based methods (SedanSpot [ 12],
 
1511SLADE: Detecting Dynamic Anomalies in Edge Streams without Labels via Self-Supervised Learning KDD ’24, August 25–29, 2024, Barcelona, Spain
MIDAS-R [ 4], F-FADE [ 6], Anoedge-l [ 5]), since they do not require
any representation learning process, we evaluate their performance
in test sets without model training. For five neural network-based
models (JODIE [ 20], Dyrep [ 34], TGAT [ 39], TGN [ 29], SAD [ 32]),
we train each model by using train sets and do hyperparameter
tuning with validation sets. At last, we evaluate them by using
test sets. At this point, excluding SAD, neural network-based mod-
els follow the previous approach of training the encoder through
link prediction-based self-supervised learning and subsequently
training the classifier with labels through supervised learning. In
scenarios where a model requires node or edge features, but these
attributes are absent from the dataset, the model uses zero vectors
as substitutes. A detailed description of these baselines is provided
in Online Appendix C. To quantify the performance of each model,
we use Area Under ROC (AUC) as an evaluation metric. For extra
results in terms of Average Precision (AP), refer to Online Appendix
D.1.
Implementation Details:Implementation Details:Implementation Details:Implementation Details:Implementation Details:Implementation Details:Implementation Details:Implementation Details:Implementation Details:Implementation Details:Implementation Details:Implementation Details:Implementation Details:Implementation Details:Implementation Details:Implementation Details:Implementation Details: In our experiments, we use two ver-
sions of our method, SLADE andSLADE-HP. For SLADE, as label
utilization is not possible in its original setting, we do not conduct
hyperparameter tuning on the validation dataset split. Instead, we
use the same hyperparameter combination across all datasets. We
adopt a batch size of 100and an initial learning rate of 3×10−6.
we also fix a memory dimension to 256, a message dimension to
128, and a max number of most recent neighbors (node degree) to
20. For the loss function, we set 𝜔𝑐𝑠=1,𝜔𝑐𝑑=1,𝜔𝑔𝑠=0.1, and
𝜔𝑔𝑑=0.1across all datasets. We train the model on the training
set for 10 epochs and then evaluate its performance on the test set.
Another version of SLADE isSLADE-HP, where we tune the
hyperparameters of SLADE by using the validation split of each
dataset, just as we tune the hyperparameters of “all” baseline meth-
ods, including the rule-based ones. Refer to Appendix B.4 for details
regarding the hyperparameter search space of SLADE-HP.
For the baseline methods, we assess the performance on the test
set using two hyperparameter settings: (a) those recommended by
the authors, and (b) those leading to the best validation performance
for each specific dataset. Subsequently, we conduct a performance
evaluation on the test set using these two distinct settings and
report the best-performing outcome.
The reported results have been obtained by averaging across
10 separate runs, each with different random initializations of the
models. A further description of the implementation and hyperpa-
rameters of SLADE and baselines are provided in Appendix B.
6.2 Experimental Results
RQ1) Accuracy:RQ1) Accuracy:RQ1) Accuracy:RQ1) Accuracy:RQ1) Accuracy:RQ1) Accuracy:RQ1) Accuracy:RQ1) Accuracy:RQ1) Accuracy:RQ1) Accuracy:RQ1) Accuracy:RQ1) Accuracy:RQ1) Accuracy:RQ1) Accuracy:RQ1) Accuracy:RQ1) Accuracy:RQ1) Accuracy: As shown in Table 1, SLADE andSLADE-HP
significantly outperform other baseline methods in most of the
datasets. There are two notable observations in this analysis.
First, regarding the unsupervised learning competitors (i.e., SedanS-
pot, MIDAS, F-FADE, and Anoedge-l), SLADE consistently outper-
forms them across all datasets, achieving performance gains of
up to 20.44% (in the Reddit dataset) compared to the second-best
performing unsupervised model. This result demonstrates that real-
world anomalies exhibit complex patterns hard to be fully captured
by fixed rule-based approaches. As a result, the necessity for more
intricate representation models becomes evident.Table 1: AUC (in %) in the detection of dynamic anomaly
nodes. The first four methods are rule-based models, and the
others are based on representation learning. For each dataset,
the best and the second-best performances are highlighted in
boldface and underlined, respectively. In most cases, SLADE
andSLADE-HP perform best, even when compared to models
that rely on label information. For results in terms of Average
Precision (AP), refer to Online Appendix D.1.
Metho
d Wikip
edia Reddit Bitcoin-alpha Bitcoin-OTC
Se
danSpot [12] 82.88±1.54
58.97±1.85 69.09±0.76 71.71±0.73
MIDAS [4] 62.92±3.53
59.94±0.95 64.57±0.11 62.16±1.99
F-FADE [6] 44.88±0.00
49.79±0.05 53.57±0.00 51.12±0.00
Anoedge-l [5] 47.38±0.32
48.47±0.46 62.52±0.24 65.99±0.19
JODIE
[20] 85.75±0.17
61.47±0.58 73.53±1.26 69.13±0.96
Dyrep [34] 85.68±0.34
63.42±0.62 73.30±1.51 70.76±0.70
TGAT [39] 83.24±1.11
65.12±1.65 71.67±0.90 68.33±1.23
TGN [29] 87.47±0.22
67.16±1.03 69.90±0.99 76.23±0.23
SAD
[32] 86.15±0.63
68.45±1.27 68.56±3.17 64.67±4.97
SLADE 87.75±0.68 72.19±0.60 76.32±0.28
75.80±0.19
SLADE-HP 88.68±0.39
75.08±0.50 76.92±0.36 77.18±0.27
Figure 2: AUC (in %) when varying the test start ratio. For
learning-based methods, temporal edges preceding the test
start ratio in the dataset are employed for training. If vali-
dation is needed, the last 10% of the training set is used for
validation. Note that SLADE performs best in most cases.
Second, interestingly, while SLADE does not utilize any label
information, even for hyperparameter tuning, it still outperforms
all supervised baseline models, on all datasets except for the Bit-
coinOTC dataset. This result implies that the patterns of nodes in
the normal state in real-world graphs closely adhere to A1andA2,
andSLADE effectively captures such patterns. Furthermore, it is
evident that measuring the extent to which nodes deviate from the
patterns provides crucial information for anomaly detection.
In addition, we measure the performances of the considered
methods while varying the proportion of the training split (or equiv-
alently the test split). Specifically, we utilize the first T%of the
edges as a train set and assess each model by using the remaining
(100−T) %of edges. We refer to Tas a test start ratio. As shown
in Figure 2, SLADE outperforms all baseline methods in most of
the settings, across various test start ratios. Moreover, as seen in
the performances of SLADE between the 40% and 80% ratios in
 
1512KDD ’24, August 25–29, 2024, Barcelona, Spain Jongha Lee, Sunwoo Kim, and Kijung Shin
Figure 3: The left figure shows the linear increase of the
running time of SLADE with respect to the number of edges
in the Reddit dataset. The right figure shows the trade-off
between detection speed and accuracy (with standard devia-
tions) in the Wikipedia dataset provided by the competing
methods. The baseline methods with AUC scores below 60%
are excluded from consideration to enhance the clarity of per-
formance differences between the methods. SLADE exhibits
constant processing time per edge (as proven in Section 5.2),
offering the best trade-off between speed and accuracy. For a
training-time comparison, refer to Online Appendix D.2.
Table 2: Comparison of AUC (in %) of SLADE and its variants
that use a subset of the proposed components (i.e., tempo-
ral contrast lossL𝑐, memory generation loss L𝑔, temporal
contrast score 𝑠𝑐𝑐, and memory generation score 𝑠𝑐𝑔).SLADE
with all components performs the best overall, showing the
effectiveness of each.
L𝑐L𝑔𝑠
𝑐𝑐𝑠𝑐𝑔 Wikipedia Reddit Bitcoin-alpha Bitcoin-OTC
✓ -✓ -
85.69±1.17 48.89±1.53 76.38±0.48
73.87±0.23
-✓ -✓ 87.57±0.35
61.77±0.12 74.84±0.40 75.80±0.26
✓ ✓ ✓ - 87.42±1.06 48.51±1.56 76.45±0.52 74.10±0.25
✓ ✓ -✓ 84.64±0.75 71.33±0.56
75.24±3.50 75.70±0.21
✓
✓ ✓ ✓ 87.75±0.68 72.19±0.60 76.32±0.28 75.80±0.19
the Wikipedia dataset, using just half of the dataset leads to only a
marginal performance degradation (spec., 3.2%).
RQ2) Speed in Action:RQ2) Speed in Action:RQ2) Speed in Action:RQ2) Speed in Action:RQ2) Speed in Action:RQ2) Speed in Action:RQ2) Speed in Action:RQ2) Speed in Action:RQ2) Speed in Action:RQ2) Speed in Action:RQ2) Speed in Action:RQ2) Speed in Action:RQ2) Speed in Action:RQ2) Speed in Action:RQ2) Speed in Action:RQ2) Speed in Action:RQ2) Speed in Action: To empirically demonstrate the theoretical
complexity analysis in Section 5.2, we measure the running time of
SLADE “in action” after being trained on the Reddit dataset while
varying the number of edges. Anomaly scoring is performed (for
each endpoint) only when each edge arrives. As depicted in the
left subplot of Figure 3, the running time of SLADE is linear in the
number of edges, being aligned with our analysis.
Additionally, we compare the running time and AUC scores of
SLADE with those of all considered methods. As shown in the
right plot of Figure 3, while SLADE is about 1.99×slower than
SedanSpot, which is the most accurate rule-based approach, SLADE
demonstrates a significant improvement of 5.88% in AUC scores,
compared to SedanSpot. Furthermore, SLADE is about 4.57×faster
than TGN, which is the second most accurate following SLADE.
RQ3) Ablation Study:RQ3) Ablation Study:RQ3) Ablation Study:RQ3) Ablation Study:RQ3) Ablation Study:RQ3) Ablation Study:RQ3) Ablation Study:RQ3) Ablation Study:RQ3) Ablation Study:RQ3) Ablation Study:RQ3) Ablation Study:RQ3) Ablation Study:RQ3) Ablation Study:RQ3) Ablation Study:RQ3) Ablation Study:RQ3) Ablation Study:RQ3) Ablation Study: The ablation study is conducted across the
four datasets to analyze the necessity of the used self-supervised
losses (Eq (4)and Eq (5)) and two anomaly detection scores (Eq (8)
and Eq (9)). To this end, we utilize several variants of SLADE, where
certain scores or self-supervised losses are removed from SLADE.
As evident from Table 2, SLADE, which uses all the proposed self-
supervised losses and scores, outperforms its variants in most of
the datasets (Wikipedia, Reddit, and Bitcoin-OTC). Moreover, even
in the Bitcoin-alpha dataset, the performance gap between SLADETable 3: AUC (in %) in the detection of dynamic anomaly
nodes in the two synthetic datasets. Since anomalies are in-
jected only into the test sets, the comparison is limited to
unsupervised methods. F-FADE, which consistently achieves
an AUC value below 0.5, is omitted from the table. For results
of Average Precision (AP), refer to Online Appendix D.1.
Dataset Se
danSpot [12] MIDAS [4] Anoedge-l [5] SLADE
Synthetic-Hijack 77.13±2.21 81.80±1.26
58.87±2.47 98.08±1.02
Synthetic-Ne
w 78.05±1.68 82.63±0.07
61.86±2.41 98.38±1.09
and the best-performing variant is within the standard deviation
range. Notably, the generation score greatly contributes to accurate
anomaly detection in most of the dataset, providing an empirical
performance gain of up to 48.81% (on the Reddit dataset).
RQ4) Type Analysis:RQ4) Type Analysis:RQ4) Type Analysis:RQ4) Type Analysis:RQ4) Type Analysis:RQ4) Type Analysis:RQ4) Type Analysis:RQ4) Type Analysis:RQ4) Type Analysis:RQ4) Type Analysis:RQ4) Type Analysis:RQ4) Type Analysis:RQ4) Type Analysis:RQ4) Type Analysis:RQ4) Type Analysis:RQ4) Type Analysis:RQ4) Type Analysis: We demonstrate the effectiveness of SLADE
in capturing various types of anomalies discussed in Section 5.1.
To this end, we create synthetic datasets by injecting anomalies to
the Email-EU [ 27] dataset, which consists of emails between users
in a large European research institution. Specifically, we create
anomalies that repetitively send spam emails to random recipients
within a short time interval, mimicking spammers, and based on
the timing of spamming, we have two different datasets:
•Synthetic-Hijack: Accounts of previously normal users start
disseminating spam emails after being hijacked at a certain time
point and continue their anomalous actions. We further catego-
rize each anomaly as Type T1 during its initial 20 interactions
after being hijacked, and as Type T3 after that.
•Synthetic-New: New anomalous users appear and initiate spread-
ing spam emails from the beginning and continue their anoma-
lous actions. We further categorize each anomaly as Type T2
during its first 20 interactions, and as Type T3 afterward.
In them, all anomalies are injected only into the test set (i.e., final
10%of the dataset in chronological order), ensuring that they remain
unknown to the model during training. Consequently, the task
involves detecting these anomalies in an unsupervised manner, and
SLADE is compared only with the unsupervised baseline methods.
As shown in Table 3, SLADE performs best, achieving perfor-
mance gains up to 19.9% in the Synthetic-Hijack dataset and 19.06%
in the Synthetic-New dataset. These results reaffirm the limitations
of traditional unsupervised methods in capturing anomalies beyond
their targeted types. In contrast, as it can learn normal patterns from
data,SLADE successfully identifies various types of anomalies.
Furthermore, we provide qualitative analysis of how SLADE as-
signs scores to the normal and anomalies of each type. Figures 4(a)
and (b) show that SLADE clearly separates anomaly score distribu-
tions of all anomaly types (T1, T2, and T3) from the distribution
of the normal ones. Figure 4(c) shows that the anomaly scores of
hijacked anomalies (T1) increase shortly after being hijacked. Fig-
ure 4(d) shows that SLADE successfully assigns high anomaly scores
to new or rarely interacting anomalies (T2). Consistent anomalies
(T3) receive high anomaly scores in both cases.
RQ5) Structural Variants:RQ5) Structural Variants:RQ5) Structural Variants:RQ5) Structural Variants:RQ5) Structural Variants:RQ5) Structural Variants:RQ5) Structural Variants:RQ5) Structural Variants:RQ5) Structural Variants:RQ5) Structural Variants:RQ5) Structural Variants:RQ5) Structural Variants:RQ5) Structural Variants:RQ5) Structural Variants:RQ5) Structural Variants:RQ5) Structural Variants:RQ5) Structural Variants: There are two major neural network
components in SLADE: (1) GRU [8], which updates the memory
of each node, and (2) TGAT [39], which generates the memory
of a target node. To demonstrate the effectiveness of each module
in dynamic anomaly detection in edge stream, we compare the
 
1513SLADE: Detecting Dynamic Anomalies in Edge Streams without Labels via Self-Supervised Learning KDD ’24, August 25–29, 2024, Barcelona, Spain
Figure 4: (a) and (b) show the distribution of anomaly scores
assigned by SLADE to instances of each node type in the two
synthetic datasets (visualization is based on Gaussian kernel
density estimation). (c) and (d) show the anomaly scores at
each time period. Note that in all figures, SLADE clearly
distinguishes anomalies from normal nodes. For results from
several baseline methods, refer to Online Appendix D.3.
performances of SLADE and its several variants where the memory
updater and the memory generator are replaced by other neural
network architectures.
•SLADE-MLP (Instead of GRU): In this variant, we use an MLP
instead of the GRU module to update the memory of each node.
Specifically, the memory update procedure (Eq (3) in the main
paper) is replaced by 𝒔𝑖=MLP([𝒎𝑖||𝒔𝑖]).Note that in this vari-
ant,𝒎𝑖and𝒔𝑖are treated as if they are independent, and thus it
cannot capture the temporal dependency between them.
•SLADE-GAT (Instead of TGAT): This variant calculates atten-
tion scores based only on the currently given memory informa-
tion, as follows:
ˆ𝒔𝑖=MultiHeadAttention (𝒒,K,V),𝒒=𝒔𝑖, (11)
K=V=
𝒔𝑛1,...,𝒔𝑛𝑘
,
where{𝑛1,...,𝑛𝑘}denote the indices of the neighbors of the tar-
get node𝑣𝑖. Note that this variant cannot incorporate temporal
information in its attention mechanism.
•SLADE-SUM (Instead of TGAT): In this variant, we use a mod-
ified temporal graph sum [29] for message passing, as follows:
ˆ𝒔𝑖=W2([¯𝒔𝑖||𝜙(𝑡−𝑡)]), (12)
¯𝒔𝑖=ReLU(𝑘∑︁
𝑗=1W1(𝒔𝑛𝑗||𝜙(𝑡−𝑡′
𝑛𝑗))),
where W1,W2∈R𝑑𝑠×2𝑑𝑠,{𝑛1,...,𝑛𝑘}denote the indices of the
neighbors of the target node 𝑣𝑖,{𝑡′𝑛1,...,𝑡′𝑛𝑘}denote the times
of the most recent interactions with them, and the weights of
each linear layer are denoted as W1andW2, respectively. NoteTable 4: Comparison of AUC (in %) of SLADE and its struc-
tural variants. For each dataset, the best and the second-best
performances are highlighted in boldface and underlined,
respectively. Across all datasets, SLADE consistently demon-
strated the best or second-best performance compared to the
other variants.
Metho
d Wikip
edia Reddit Bitcoin-alpha Bitcoin-OTC
SLADE-MLP 85.97±1.17
55.35±3.34 74.68±1.35 75.42±0.65
SLADE-GA
T86.86±0.44
67.15±1.85 75.67±0.57 74.24±0.25
SLADE-SUM 88.43±0.44 70.89±0.53 75.84±0.26 75.42±0.15
SLADE 87.75±0.68 72.19±0.60
76.32±0.28 75.80±0.19
that this variant does not use any attention mechanism i.e., all
neighbors are treated with equal importance.
We compare the performances of SLADE and the above three
variants, utilizing the same hyperparameter settings as the original
SLADE. As shown in Table 4, SLADE achieves the best performance
in three out of four datasets. This result demonstrates the effective-
ness of GRU and TGAT, i.e., the importance of modeling temporal
dependency in memory update and temporal attention in memory
generation. Specifically, SLADE-MLP and SLADE-GAT consistently
underperform SLADE andSLADE-SUM, demonstrating the impor-
tance of utilizing temporal information and temporal dependency
in detecting dynamic anomalies. While SLADE-SUM outperforms
SLADE in the Wikipedia dataset, its performance gain is marginal,
falling within the standard deviation.
Extra Experimental Results in Online Appendix [21]:Extra Experimental Results in Online Appendix [21]:Extra Experimental Results in Online Appendix [21]:Extra Experimental Results in Online Appendix [21]:Extra Experimental Results in Online Appendix [21]:Extra Experimental Results in Online Appendix [21]:Extra Experimental Results in Online Appendix [21]:Extra Experimental Results in Online Appendix [21]:Extra Experimental Results in Online Appendix [21]:Extra Experimental Results in Online Appendix [21]:Extra Experimental Results in Online Appendix [21]:Extra Experimental Results in Online Appendix [21]:Extra Experimental Results in Online Appendix [21]:Extra Experimental Results in Online Appendix [21]:Extra Experimental Results in Online Appendix [21]:Extra Experimental Results in Online Appendix [21]:Extra Experimental Results in Online Appendix [21]: We ex-
plore more baselines, including (a) neural networks trained through
link-prediction-based self-supervised learning and (b) anomaly-
detection methods based on DTDGs and static graphs. We also
use a transportation network dataset for evaluation. We further
investigate (a) robustness to anomalies in training, (b) training with
label supervision, (c) learnable time encoding, (d) anomalies with
camouflage, and (e) dynamic heterogeneous graphs.
7 Conclusion
We proposed SLADE, a novel self-supervised method for dynamic
anomaly detection in edge streams, with the following strengths:
•SLADE does not rely on any label supervision while being able
to capture complex anomalies (Section 4).
•SLADE outperforms state-of-the-art anomaly detection methods
in the task of dynamic anomaly detection in edge streams. SLADE
achieves a performance improvement of up to 12.80% and 4.23%
compared to the best-performing unsupervised and supervised
baseline methods, respectively (Section 6.2).
•SLADE demonstrates a constant time complexity per edge, which
is theoretically supported (Section 5.2).
Acknowledgements
This work was supported by Institute of Information & Communications
Technology Planning & Evaluation (IITP) grant funded by the Korea gov-
ernment (MSIT) (No. 2022-0-00157, Robust, Fair, Extensible Data-Centric
Continual Learning) (No. RS-2019-II190075, Artificial Intelligence Graduate
School Program (KAIST)).
 
1514KDD ’24, August 25–29, 2024, Barcelona, Spain Jongha Lee, Sunwoo Kim, and Kijung Shin
References
[1]Odd Aalen, Ornulf Borgan, and Hakon Gjessing. 2008. Survival and event history
analysis: a process point of view. Springer Science & Business Media.
[2]Ashton Anderson, Ravi Kumar, Andrew Tomkins, and Sergei Vassilvitskii. 2014.
The dynamics of repeat consumption. In WWW.
[3]Austin R Benson, Ravi Kumar, and Andrew Tomkins. 2018. Sequences of sets. In
KDD.
[4]Siddharth Bhatia, Bryan Hooi, Minji Yoon, Kijung Shin, and Christos Faloutsos.
2020. Midas: Microcluster-based detector of anomalies in edge streams. In AAAI.
[5]Siddharth Bhatia, Mohit Wadhwa, Kenji Kawaguchi, Neil Shah, Philip S Yu, and
Bryan Hooi. 2023. Sketch-Based Anomaly Detection in Streaming Graphs. In
KDD.
[6]Yen-Yu Chang, Pan Li, Rok Sosic, MH Afifi, Marco Schweighauser, and Jure
Leskovec. 2021. F-fade: Frequency factorization for anomaly detection in edge
streams. In WSDM.
[7]Kyunghyun Cho, Bart Van Merriënboer, Caglar Gulcehre, Dzmitry Bahdanau,
Fethi Bougares, Holger Schwenk, and Yoshua Bengio. 2014. Learning phrase
representations using RNN encoder-decoder for statistical machine translation.
InEMNLP.
[8]Junyoung Chung, Caglar Gulcehre, KyungHyun Cho, and Yoshua Bengio. 2014.
Empirical evaluation of gated recurrent neural networks on sequence modeling.
InNeurIPS, Deep Learning and Representation Learning Workshop.
[9]Weilin Cong, Si Zhang, Jian Kang, Baichuan Yuan, Hao Wu, Xin Zhou, Hanghang
Tong, and Mehrdad Mahdavi. 2022. Do We Really Need Complicated Model
Architectures For Temporal Networks?. In ICLR.
[10] Kaize Ding, Jundong Li, Rohit Bhanushali, and Huan Liu. 2019. Deep anomaly
detection on attributed networks. In SDM.
[11] Kaize Ding, Qinghai Zhou, Hanghang Tong, and Huan Liu. 2021. Few-shot
network anomaly detection via cross-network meta-learning. In WWW.
[12] Dhivya Eswaran and Christos Faloutsos. 2018. Sedanspot: Detecting anomalies
in edge streams. In ICDM.
[13] Jin Huang, Wentai Zhu, Jing Xiao, Tian Lu, and Weihao Yu. 2022. Dynamic Graph
Representation Based on Temporal and Contextual Contrasting. In ACAI.
[14] Ming Jin, Yixin Liu, Yu Zheng, Lianhua Chi, Yuan-Fang Li, and Shirui Pan. 2021.
Anemone: Graph anomaly detection with multi-scale contrastive learning. In
CIKM.
[15] Seyed Mehran Kazemi, Rishab Goel, Kshitij Jain, Ivan Kobyzev, Akshay Sethi,
Peter Forsyth, and Pascal Poupart. 2020. Representation learning for dynamic
graphs: A survey. Journal of Machine Learning Research 21, 1 (2020), 2648–2720.
[16] Shima Khoshraftar, Aijun An, and Nastaran Babanejad. 2022. Temporal graph
representation learning via maximal cliques. In Big Data.
[17] Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic opti-
mization. In ICLR.
[18] Thomas N Kipf and Max Welling. 2017. Semi-supervised classification with graph
convolutional networks. In ICLR.
[19] Srijan Kumar, Francesca Spezzano, VS Subrahmanian, and Christos Faloutsos.
2016. Edge weight prediction in weighted signed networks. In ICDM.
[20] Srijan Kumar, Xikun Zhang, and Jure Leskovec. 2019. Predicting dynamic em-
bedding trajectory in temporal interaction networks. In KDD.
[21] Jongha Lee, Sunwoo Kim, and Kijung Shin. 2024. Online Appendix for SLADE.
(2024). https://github.com/jhsk777/SLADE-Online-Appendix
[22] Jure Leskovec, Jon Kleinberg, and Christos Faloutsos. 2007. Graph evolution:
Densification and shrinking diameters. ACM Transactions on Knowledge Discovery
from Data 1, 1 (2007), 2–es.
[23] Jundong Li, Harsh Dani, Xia Hu, and Huan Liu. 2017. Radar: Residual analysis
for anomaly detection in attributed networks.. In IJCAI.
[24] Yixin Liu, Zhao Li, Shirui Pan, Chen Gong, Chuan Zhou, and George Karypis.
2021. Anomaly detection on attributed networks via contrastive self-supervised
learning. IEEE Transactions on Neural Networks and Learning Systems 33, 6 (2021),
2378–2392.
[25] Yixin Liu, Shirui Pan, Yu Guang Wang, Fei Xiong, Liang Wang, Qingfeng Chen,
and Vincent CS Lee. 2021. Anomaly detection in dynamic graphs via transformer.
IEEE Transactions on Knowledge and Data Engineering (2021).
[26] Xiaoxiao Ma, Jia Wu, Shan Xue, Jian Yang, Chuan Zhou, Quan Z Sheng, Hui Xiong,
and Leman Akoglu. 2021. A comprehensive survey on graph anomaly detection
with deep learning. IEEE Transactions on Knowledge and Data Engineering (2021).
[27] Ashwin Paranjape, Austin R Benson, and Jure Leskovec. 2017. Motifs in temporal
networks. In WSDM.
[28] Tahereh Pourhabibi, Kok-Leong Ong, Booi H Kam, and Yee Ling Boo. 2020. Fraud
detection: A systematic literature review of graph-based anomaly detection
approaches. Decision Support Systems 133 (2020), 113303.
[29] Emanuele Rossi, Ben Chamberlain, Fabrizio Frasca, Davide Eynard, Federico
Monti, and Michael Bronstein. 2020. Temporal Graph Networks for Deep Learning
on Dynamic Graphs. In ICML 2020 Workshop on Graph Representation Learning.
[30] Michael Rotman and Lior Wolf. 2021. Shuffling recurrent neural networks. In
AAAI.
[31] Kartik Sharma, Mohit Raghavendra, Yeon Chang Lee, Srijan Kumar, et al .2022.
Representation Learning in Continuous-Time Dynamic Signed Networks. arXive-prints (2022), arXiv–2207.
[32] Sheng Tian, Jihai Dong, Jintang Li, Wenlong Zhao, Xiaolong Xu, Bowen Song,
Changhua Meng, Tianyi Zhang, Liang Chen, et al .2023. SAD: Semi-Supervised
Anomaly Detection on Dynamic Graphs. In IJCAI.
[33] Sheng Tian, Ruofan Wu, Leilei Shi, Liang Zhu, and Tao Xiong. 2021. Self-
supervised representation learning on dynamic graphs. In CIKM.
[34] Rakshit Trivedi, Mehrdad Farajtabar, Prasenjeet Biswal, and Hongyuan Zha. 2019.
Dyrep: Learning representations over dynamic graphs. In ICLR.
[35] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all
you need. In NeurIPS.
[36] Petar Velickovic, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro
Lio, Yoshua Bengio, et al. 2018. Graph attention networks. In ICLR.
[37] Xuhong Wang, Ding Lyu, Mengjian Li, Yang Xia, Qi Yang, Xinwen Wang, Xin-
guang Wang, Ping Cui, Yupu Yang, Bowen Sun, et al .2021. Apan: Asynchronous
propagation attention network for real-time temporal graph embedding. In SIG-
MOD.
[38] Yiwei Wang, Yujun Cai, Yuxuan Liang, Henghui Ding, Changhu Wang, Siddharth
Bhatia, and Bryan Hooi. 2021. Adaptive data augmentation on temporal graphs.
InNeurIPS.
[39] Da Xu, Chuanwei Ruan, Evren Korpeoglu, Sushant Kumar, and Kannan Achan.
2020. Inductive representation learning on temporal graphs. In ICLR.
[40] Wenchao Yu, Wei Cheng, Charu C Aggarwal, Kai Zhang, Haifeng Chen, and
Wei Wang. 2018. Netwalk: A flexible deep embedding approach for anomaly
detection in dynamic networks. In KDD.
[41] Li Zheng, Zhenpeng Li, Jian Li, Zhao Li, and Jun Gao. 2019. AddGraph: Anomaly
Detection in Dynamic Graph Using Attention-based Temporal GCN.. In IJCAI.
[42] Tongya Zheng, Xinchao Wang, Zunlei Feng, Jie Song, Yunzhi Hao, Mingli Song,
Xingen Wang, Xinyu Wang, and Chun Chen. 2023. Temporal Aggregation
and Propagation Graph Neural Networks for Dynamic Representation. IEEE
Transactions on Knowledge and Data Engineering (2023).
A APPENDIX: Dataset Details
A.1 Real-world Datasets
We use 4 real-world datasets for a dynamic anomaly detection task;
two social network datasets (Wikipedia and Reddit [ 20])2and two
financial network datasets (Bitcoin-alpha and Bitcoin-OTC [ 19])3.
Basic descriptive statistics of each dataset are provided in Table 5.
Below, we provide a detailed description of each dataset.
In Wikipedia and Reddit datasets, which are social networks
between users, a user’s dynamic label at time 𝑡indicates the user’s
state at time 𝑡. Specifically, if a user is banned by administrators
at time𝑡, the label of the user at time 𝑡is marked as abnormal.
Otherwise, the user has a label of normal. Note that these labels are
inherently given in the original datasets.
Bitcoin-alpha and Bitcoin-OTC datasets are temporal weighted-
signed networks between users. Here, the weight of each directional
edge indicates how much the source user trusts the destination user.
Specifically, for each edge, its weight, which lies between -10 (total
distrust) to +10 (total trust) is given, together with the time of the
interaction. Note that, in our experiments, the edge weights are
utilized to create ground-truth dynamic labels, and they are not
included in the inputs for the anomaly detection methods. While
the used social networks inherently contain dynamic node states
(i.e., banned), such information of an individual user is not pro-
vided in this case. Therefore, we assign a dynamic label to each
node according to the weights of the interactions the node is in-
volved in. Note that since the overall Bitcoin transaction systems
are anonymized, it is not reliable to determine the state of a user
according to a single interaction.
Hence, to obtain reliable labels, we adopt a two-stage labeling
process: for each user, first, we define the (1) overall state of the
2http://snap.stanford.edu/jodie/#datasets
3https://snap.stanford.edu/data
 
1515SLADE: Detecting Dynamic Anomalies in Edge Streams without Labels via Self-Supervised Learning KDD ’24, August 25–29, 2024, Barcelona, Spain
Table 5: Statistics of datasets used in our experiments. The count of anomalies refers to the number of edges where the dynamic
state of the actor node is abnormal, and the ratio represents the proportion of these abnormal edges in relation to the total
number of edges.
Wikip
edia Reddit Bitcoin-alpha Bitcoin-OTC Synthetic-Hijack Synthetic-New
#
Nodes 9,227 10,984 3,783 5,881 986 996
# Edges 157,474 672,447 24,186 35,592 333,200 333,200
# Features 172 172 0 0 0 0
# anomalies 217 366 874 2,568 3,290 3,290
anomalies ratio 0.14% 0.05% 3.61% 7.22% 0.99% 0.99%
anomaly type post ban edit ban unreliable user unreliable user spammer spammer
user, then define (2) the dynamic state of the user based on the
overall state. We further describe this process.
(1):Defining overall state: For each user, if the sum of the scores
a user has received throughout the entire edge stream is smaller
than zero, the overall state of the user is decided to be abnormal.
Otherwise, the overall state of the user is labeled as normal.
(2):Defining dynamic state: For each user that has the normal
overall state, the dynamic label of the user is assumed to be
always normal. Conversely, for each user that has the abnormal
overall state, when the user becomes the destination node of a
negative-weighted interaction (i.e., receiving a negative trust
score from other users), the dynamic label of the user at the
corresponding interaction time is assumed to be abnormal.
Otherwise, if a user receives a positive trust score from another
user, we assume the dynamic label of the user at that time is
assumed to be normal. Note that these created dynamic node
labels are utilized as ground-truth dynamic node labels.
As mentioned above, the weight of each edge determines the
label of a destination node, not a source node4. Regarding node
and edge features, all of the used baseline neural network-based
anomaly detection models require feature information of nodes and
edges. On the other hand, in Bitcoin-alpha and -OTC datasets, such
information is not given. Following prior works [16, 31] that used
such models in the corresponding datasets, we utilize zero vectors
for node and edge features of such datasets.
Regarding data splits, for all the datasets, we fix the chronological
split with 70 % for training, 15% for validation, and the last 15 %
for testing, which is a common setting that is widely used in many
existing works [29, 32, 39].
A.2 Semi-Synthetic Datasets
Next, we describe the details of the Synthetic-Hijack and Synthetic-
New datasets, which we utilize in Section 6.2. These datasets are
variants of the real-world email communication dataset: Email-
EU [22]. Nodes indicate users, and an edge (𝑣𝑖,𝑣𝑗,𝑡)indicates an
email between users 𝑣𝑖and𝑣𝑗at time𝑡. Since the dataset does not
have ground-truth anomalous interactions, we inject anomalies
discussed in Section 5.1 (T1, T2, and T3). To this end, we first
choose the time interval where interactions have actively occurred
(spec., interactions occur within (4.06×107,4.54×107)timestamp)
since our method and baselines can easily detect anomalies that
are injected in the later timestamp than 4.54×107. Then, we set
the timestamp region where the last 10%(in chronicle order) inter-
actions occur as an evaluation region. After, we select candidate
accounts to perform anomalous actions:•Synthetic-Hijack: Randomly select 10 nodes ( ≈1%of the nor-
mal nodes) from nodes that are normal before the final 10% of
the dataset and do not appear in the evaluation region.
•Synthetic-New: Make 10 new nodes ( ≈1%of the normal nodes)
that have never appeared before the evaluation region.
Subsequently, we inject anomalies equivalent to approximately 1%
of the total normal interactions into the evaluation region (see the
next paragraph for details). Each of these anomalous actions is
represented as temporal edge (𝑣𝑘,𝑣𝑙,𝑡𝑚), where at time 𝑡𝑚, the
anomalous source node 𝑣𝑘from the selected candidates sends a
spam email to some normal node 𝑣𝑙. In this case, the dynamic label
of the node 𝑣𝑘at time𝑡𝑚is anomalous.
We further elaborate on how we make each anomalous edge. We
consider the characteristics of spammers. We assume that spam-
mers tend to target an unspecified majority with multiple spam
emails in a short time interval. Based on this assumption, (1) we
sample a timestamp 𝑡in the evaluation region uniformly at random,
(2) pick one anomalous node from the candidate pool, regarding
it as the source node, (3) randomly choose 10 normal nodes as
destinations, and (4) make 10 edges by joining the selected source
node with each selected destination nodes. (5) Lastly, we assign
each edge a timestamp 𝑡±𝛼, where𝛼is sampled uniformly at
random from[0,300]. This process ((1) - (5)) is repeated until we
have approximately 1% of anomalies relative to the total normal
interactions for the Synthetic-Hijack and Synthetic-New.
B Appendix: Implementation Details
B.1 Experiments Environment
We conduct all experiments with NVIDIA RTX 3090 Ti GPUs (24GB
VRAM), 256GB of RAM, and two Intel Xeon Silver 4210R Processors.
B.2 Details of Baselines in Main Experiments
As mentioned in Section 6.1, we tune most hyperparameters of
each baseline method by conducting a full grid search on the vali-
dation set of each dataset. For other hyperparameters, we strictly
follow the setting provided in their official code, because it leads
to better results than grid searches. The selected hyperparameter
combination of each model is reported in Table 6.
Rule-based Methods. Hyperparameter search space of each rule-
based method is as below:
•Sedanspot: sample size among (5000,10000,20000), number of
random walkers among (100,200,300), and restart probability
among(0.1,0.5,0.9)
4For the sake of consistency with other datasets, the directions are reversed in the
Bitcoin datasets, enabling the scoring and evaluation to be performed for source nodes.
 
1516KDD ’24, August 25–29, 2024, Barcelona, Spain Jongha Lee, Sunwoo Kim, and Kijung Shin
Table 6: Hyperparameter settings for all baseline methods of main experiments and SLADE on each dataset.
Metho
d Wikip
edia Reddit Bitcoin-alpha Bitcoin-OTC
Se
danSpot
(sample size, # random walkers, restart probability)(5000,200,0.9)
(20000,100,0.9) ( 20000,100,0.9) ( 5000,200,0.5)
MIDAS
(number of hash functions, CMS size, decay factor)(3,1024,0.1)
(3,1024,0.5) ( 4,256,0.9) ( 2,256,0.9)
F-FADE
(batch size, memory size, embedding size)(100,100,100)
(300,200,200) ( 100,400,100) ( 100,100,100)
Anoedge-l
(edge threshold, bucket size, decay factor)(50,128,0.5)
(50,64,0.1) ( 50,128,0.9) ( 50,128,0.5)
JODIE
(pr
etraining batch size, batch size, node degree)(300,300,20)
(200,100,10) ( 200,100,10) ( 200,100,10)
Dyrep
(pretraining batch size, batch size, node degree)(200,200,10)
(200,100,20) ( 200,100,10) ( 100,300,20)
TGAT
(pretraining batch size, batch size, node degree)(200,100,20)
(200,100,20) ( 200,100,20) ( 300,300,10)
TGN
(pretraining batch size, batch size, node degree)(200,100,20)
(200,100,10) ( 200,100,10) ( 200,100,10)
SAD
(batch size, anomaly alpha, supervised alpha)(100,0.1,0.01)
(256,0.1,0.0005) ( 300,0.001,0.001) ( 200,0.01,0.1)
SLADE
(
batch size,𝜔𝑔𝑠,𝜔𝑔𝑑)(100,0.1,0.1)
(100,0.1,0.1) ( 100,0.1,0.1) ( 100,0.1,0.1)
SLADE-HP
(batch size,𝜔𝑔𝑠,𝜔𝑔𝑑)(300,10,10)
(100,0.1,1) ( 300,1,10) ( 300,10,1)
Table 7: Hyperparameter settings for rule-based baseline
methods and SLADE in type analysis.
Metho
d Synthetic-(
∗)
Se
danSpot
(sample size, # random walkers, restart probability)(10000,50,0.15)
MID
AS
(number of hash functions, CMS size, decay factor)(2,1024,0.5)
F-F
ADE
(batch size, memory size, embedding size)(100,100,100)
Ano
edge-l
(edge threshold, bucket size, decay factor)(50,32,0.9)
SLADE
(
batch size,𝜔𝑔𝑠,𝜔𝑔𝑑)(100,0.1,0.1)
•MIDAS-R: number of hash functions among (2,3,4), CMS size
among(256,512,1024) , and decay factor among (0.1,0.5,0.9)
•F-FADE: batch size among (100,200,300), limited memory size
among(100,200,400), and embedding size among (100,200,300)
•Anoedge-l: edge threshold among (25,50,100), bucket size among
(64,128,256), and restart probability among (0.1,0.5,0.9)
Neural Network-based Methods. We train all models with the
Adam [ 17] optimizer. The hyperparameter search space of each
neural network-based method is as below:
•JODIE: self-supervised batch size among (100, 200, 300), super-
vised batch size among (100,200,300), and degree among (10,20)
•Dyrep: self-supervised batch size among (100, 200, 300), super-
vised batch size among (100,200,300), and degree among (10,20)
•TGAT: self-supervised batch size among (100, 200, 300), super-
vised batch size among (100,200,300), and degree among (10,20)•TGN: self-supervised batch size among (100, 200, 300), supervised
batch size among(100,200,300), and degree among (10,20)
•SAD: batch size among (100,200,300), anomaly alpha among
(0.1,0.01,0.001)for deviation loss, and supervised alpha among
(0.1,0.01,0.001) for supervised loss
B.3 Details of Baseline Methods in Type
Analysis Experiments
We use hyperparameter settings from previous studies or combina-
tions for good performance on our main experiments. The selected
hyperparameter setting of each model is reported in Table 7.
B.4 Detailed Hyperparameters of SLADE and
SLADE-HP
We train both SLADE andSLADE-HP using the Adam optimizer,
with a learning rate of 3×10−6and a weight decay of 10−4. We fix
the dropout probability and the number of attention heads in TGAT
to 0.1 and 2, respectively. In addition, we fix the scaling scalar of
temporal encoding (Eq (2) in the main paper) to 𝛼=10,𝛽=25.6,
the weight of each loss in L𝑐(Eq (7) in the main paper) to 𝜔𝑐𝑠=
𝜔𝑐𝑑=1, and the dimension of a time encoding to 256, which is
equivalent to the memory dimension. As mentioned in Section 6.1 of
the main paper, we tune several hyperparameters of SLADE-HP on
the validation set of each dataset, as we tune the hyperparameters
of all baselines. The search space is as follows:
•SLADE-HP: batch size among (100,200,300), the weight in mem-
ory generation loss L𝑔for a source node ( 𝜔𝑔𝑐) among(0.1,1,10),
and for a destination node ( 𝜔𝑔𝑑) among(0.1,1,10).
Our final hyperparameter settings for SLADE andSLADE-HP are
also reported in Table 6.
 
1517