Causal Machine Learning for Cost-Effective Allocation of
Development Aid
Milan Kuzmanovic
mkuzma96@gmail.com
ETH Zurich
Zurich, SwitzerlandDennis Frauen
frauen@lmu.de
Munich Center for Machine Learning & LMU Munich
Munich, Germany
Tobias Hatt
hatt.tob@gmail.com
ETH Zurich
Zurich, SwitzerlandStefan Feuerriegel
feuerriegel@lmu.de
Munich Center for Machine Learning & LMU Munich
Munich, Germany
ABSTRACT
The Sustainable Development Goals (SDGs) of the United Nations
provide a blueprint of a better future by “leaving no one behind”,
and, to achieve the SDGs by 2030, poor countries require immense
volumes of development aid. In this paper, we develop a causal
machine learning framework for predicting heterogeneous treat-
ment effects of aid disbursements to inform effective aid allocation.
Specifically, our framework comprises three components: (i) a bal-
ancing autoencoder that uses representation learning to embed
high-dimensional country characteristics while addressing treat-
ment selection bias; (ii) a counterfactual generator to compute
counterfactual outcomes for varying aid volumes to address small
sample-size settings; and (iii) an inference model that is used to
predict heterogeneous treatment–response curves. We demonstrate
the effectiveness of our framework using data with official develop-
ment aid earmarked to end HIV/AIDS in 105 countries, amounting
to more than USD 5.2 billion. For this, we first show that our frame-
work successfully computes heterogeneous treatment–response
curves using semi-synthetic data. Then, we demonstrate our frame-
work using real-world HIV data. Our framework points to large
opportunities for a more effective aid allocation, suggesting that
the total number of new HIV infections could be reduced by up to
3.3% (∼50,000 cases) compared to the current allocation practice.
CCS CONCEPTS
•Applied computing →Life and medical sciences; •Informa-
tion systems→Data mining ;•Computing methodologies →
Causal reasoning and diagnostics.
KEYWORDS
causal machine learning, heterogeneous treatment effects, treat-
ment effect estimation, development aid, medicine
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
KDD ’24, August 25–29, 2024, Barcelona, Spain
©2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 979-8-4007-0490-1/24/08
https://doi.org/10.1145/3637528.3671551ACM Reference Format:
Milan Kuzmanovic, Dennis Frauen, Tobias Hatt, and Stefan Feuerriegel. 2024.
Causal Machine Learning for Cost-Effective Allocation of Development Aid.
InProceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery
and Data Mining (KDD ’24), August 25–29, 2024, Barcelona, Spain. ACM, New
York, NY, USA, 12 pages. https://doi.org/10.1145/3637528.3671551
1 INTRODUCTION
The Sustainable Development Goals (SDGs) by the United Nations
define a global framework to achieve a better and more sustainable
future for the people and the planet [ 39]. The SDGs list various
targets that should be met by 2030 (e.g., ending the HIV/AIDS
epidemic, eliminating hunger). Here, a central principle of the SDGs
is that of “leaving no one behind” : it is the unequivocal aim of the
United Nations to improve conditions for all parts of society and
across all countries, including developing countries [41].
An important driver of progress towards the SDGs, especially for
developing countries, is the provision of development aid [ 27,38].
Development aid, also called official development assistance (ODA),
supports developing countries through various activities funded
by donor institutions (e.g., foreign governments, national develop-
ment agencies, development banks, philanthropic organizations).
ODA pools immense financial resources from donor institutions
worldwide. For instance, in 2021, ODA amounted to USD 178.9
billion [ 28]. However, current aid allocation practices mostly rely
on human judgment and decision heuristics [ 26,30,36], and can
thus result in inefficient allocation [ 14]. Given that ODA budgets
are limited, as well as current challenges (e.g., the Russian invasion
of Ukraine, climate change, etc.), a cost-efficient use of development
aid is of great need.
In this paper, we aim to predict the effectiveness of develop-
ment aid, so that practitioners can then identify cost-effective al-
locations. For this, we develop a novel, causal machine learning
framework for predicting the effect of aid disbursements on SDG
outcomes called CG-CT (counterfactual generator for continuous
treatments ). Specifically, we predict heterogeneous treatment effects
of aid disbursements as a continuous treatment while additionally
controlling for various confounders. Our framework is different
from existing methods and carefully tailored to our setting. Specifi-
cally, our CG-CT is designed to simultaneously address continuous
treatments, high-dimensional covariates (country characteristics),
5283
KDD ’24, August 25–29, 2024, Barcelona, Spain Milan Kuzmanovic, Dennis Frauen, Tobias Hatt, & Stefan Feuerriegel
treatment selection bias, and small sample-size settings. This al-
lows us to predict the heterogeneous aid effect across different
countries, that is, individualized treatment–response curves. In our
setting, we also refer to the latter as aid–response curves. Further,
our framework is data-efficient: the different components operate
on a low-dimensional covariate space and polynomial regression
together with data augmentation. This is a crucial difference of
our framework from common baselines that build upon neural
networks (e.g., [5, 33]).
We show the effectiveness of our CG-CT in various experiments.
For this, we use data from a collaboration with the Organisation for
Economic Co-operation and Development (OECD), an intergovern-
mental organization tasked with monitoring and coordinating the
development aid activities of different donors. For our experiments,
we focus on official development aid earmarked to end HIV/AIDS
in 105 countries. This choice is motivated by the fact that (i) the
HIV epidemic is a major cause of death [ 37,42,46], and (ii) ODA
committed to ending HIV/AIDS pools extensive resources (e.g.,
more than USD 106 billion since 2002) [ 29]. The results demon-
strate the potential of our machine learning framework to inform
more effective aid allocations for achieving progress towards the
SDGs.
Our main contributions are as follows:1
(1)We study the problem of predicting heterogeneous treatment
effects of development aid on SDG outcomes, thereby inform-
ing the effective allocation of development aid.
(2)We develop a novel causal machine learning framework ( CG-CT )
for this purpose. We further show that state-of-the-art methods
are outperformed by our CG-CT.
(3)We demonstrate our CG-CT framework using real-world data
from the HIV epidemic, where it pinpoints a large potential
for reducing the number of new HIV infections over current
practice.
2 RELATED WORK
Development aid: To inform aid allocations, the effectiveness
of aid has been subject to extensive analyses (see supplements in
our GitHub repository for details). One literature stream builds
upon experiments (e.g., [ 7,8]). However, experiments involving
development aid are costly and limited to micro-level analyses
(e.g., a small geographic area and not across multiple countries). A
different literature stream uses observational data (e.g., [ 6,25]), yet
these works make strong modeling assumptions (e.g., the treatment
effect is linear in the aid volume, the effectiveness of aid cannot
vary across countries but the effectiveness is instead identical for
all countries, etc.). Moreover, the true treatment effect is typically
underestimated due to the nature of the modeling approach [ 6,
25], and, therefore, estimates can merely serve as a lower bound.
Importantly, all of the above works estimate the average effect of
aid across countries but without considering the heterogeneity in
the aid effect across countries. However, to inform aid allocations of
decision-makers, methods are needed to predict the heterogeneous
treatment effect of aid for a specific country of interest.
1Data and code that supports the findings of our study is made publicly available via a
GitHub repository at: https://github.com/mkuzma96/CG-CTTo predict the treatment effect of aid under between-country
heterogeneity, existing research has also applied standard machine
learning methods (e.g., LASSO regression [ 18]). Here, the benefit of
machine learning is that it should generalize well across multiple
countries and thus also allow for accurate predictions of treatment
effects for out-of-sample data points. Yet, standard machine learn-
ing methods can give unreliable predictions of treatment effects
in the presence of treatment selection bias [ 34]. For example, if
wealthy countries generally receive low volumes of development
aid, predicting the treatment effect of large aid volumes for wealthy
countries might be unreliable due to the limited number of data
points. Hence, treatment selection bias can create covariate shifts in
the observational data that preclude reliable estimation of treatment
effects in some covariate domains. Such covariate shifts are also
present in our data around development aid and macroeconomic
variables (see supplements in our GitHub repository for an analysis
of aid-dependent covariate shifts). To address this issue, we develop
a tailored causal machine learning framework for predicting het-
erogeneous treatment effects of development aid under treatment
selection bias.
Causal machine learning: Recent advances in machine learn-
ing allow for predicting heterogeneous treatment effects from ob-
servational data [ 1,10]. This has, among others, enabled new appli-
cations in health (e.g., [ 23,24]). Here, the prime focus is to reliably
predict treatment effects despite different challenges (e.g., confound-
ing bias, treatment selection bias). This is also the reason why naïve
methods (e.g., standard machine learning models) for predicting
treatment effects can be unreliable [34].
As an example, let us assume that economic activity positively af-
fects an SDG outcome, but negatively affects the volume of received
aid. Then, failing to control for GDP (gross domestic product) per
capita when predicting the effect of aid on the SDG outcome could
lead to the wrong conclusion that a smaller volume of aid improves
the SDG outcome (an instance of confounding bias). Moreover, even
if we control for GDP per capita, observational data is likely to have
a limited number of observations of large aid volumes in wealthy
countries, thus precluding reliable estimation of treatment effects
of large aid volumes for wealthy countries (an instance of treatment
selection bias). To this end, it is crucial to address these problems
when predicting treatment effects.
To predict heterogeneous treatment effects, many custom meth-
ods based on machine learning have been proposed for binary treat-
ments (such as, e.g., causal forests) [ 2,15,20,34,48]. In contrast,
we are interested in predicting the effect of continuous treatments,
which is also known as predicting a heterogeneous dose-response
curve (in our setting, we call it later treatment-response curve
or aid-response curve). However, there are only a few works for
continuous treatments and heterogeneous treatment effects (e.g.,
generalized propensity score (GPS), DRNet, SCIGAN) [ 5,16,33]. Im-
portantly, all of these methods have caveats when simultaneously
addressing continuous treatments, high-dimensional covariates,
treatment selection bias, and small sample-size settings (see the
overview in supplements in our GitHub repository).
5284Causal Machine Learning for Cost-Effective Allocation of Development Aid KDD ’24, August 25–29, 2024, Barcelona, Spain
3 METHODS
3.1 Problem setup
We consider the following cross-sectional setting with 𝑖=1,...,𝑛
countries. (1) Let 𝑌𝑖∈Y⊆ Rdenote the outcome in country 𝑖.
In our case, this is the relative reduction in the HIV infection rate
compared to the previous year. However, without loss of generality,
one could also use our framework for other SDG outcomes (e.g.,
prevalence of undernourishment, human poverty indices, tuber-
culosis incidence). (2) Let 𝐴𝑖∈A⊆ R+denote the continuous
treatment, which, in our case, is the volume of development aid
that is allocated to a country. (3) Let 𝑋𝑖∈X⊆ R𝑝refer to the
additional covariates that capture country characteristics and act
as potential confounders. To make inferences, we have access to
observational data on past aid disbursements earmarked to the SDG
outcome (here: HIV infection rate). We refer to the observational
data byD={(𝑦𝑖,𝑎𝑖,𝑥𝑖)}𝑛
𝑖=1. For brevity, we omit the index 𝑖unless
explicitly needed.
We formalize our task using the Rubin-Neyman potential out-
comes framework [ 32]. Specifically, we define outcomes as follows.
For every treatment 𝑎∈A, we denote the potential outcome by
𝑌(𝑎)∈Y . It gives the SDG outcome if, hypothetically, aid volume 𝑎
would have been allocated to a country. However, the fundamental
problem of causal inference is that we observe only one potential
outcome; that is, the observational data includes only one 𝑌(𝑎)for
a single value 𝐴=𝑎. In terms of terminology, the observed out-
come is also called the factual outcome, while all other unobserved
potential outcomes are called counterfactual outcomes. Note that,
in our setting with continuous treatments, we have infinitely many
counterfactual outcomes. The causal structure of our problem setup
is shown in Figure 1 (note that we do not assume that covariates
are mutually independent, but rather use the illustration to show
that covariates are potential confounders).
X 2
Y AX 1X 3
X p...
Figure 1: Causal structure of our problem setup. Our aim is to
predict the effect of development aid ( 𝐴) on the reduction in
the HIV infection rate ( 𝑌), while controlling for various coun-
try characteristics such as socioeconomic, macroeconomic,
and health-related covariates ( 𝑋1,𝑋2,...,𝑋𝑝) as potential con-
founders. We have a cross-sectional setting without time
dependencies.
Our aim is to predict the heterogeneous treatment effect, i.e., the
expected potential outcome for a given treatment value conditioned
on covariates. Formally, the heterogeneous treatment effect is defined
by
𝜇(𝑎,𝑥):=E[𝑌(𝑎)|𝑋=𝑥], (1)
where𝑥is the given value for the covariates. We further introduce
the so-called treatment–response curve : it refers to the function𝜇(𝑎,𝑥)for varying volumes of development aid, 𝑎, while the coun-
try characteristics, 𝑥, are kept fixed. In our case, we also call it
“aid–response curve”. In order to unbiasedly estimate 𝜇(𝑎,𝑥)from
observational dataD, we make the following assumptions to ensure
identifiability of the treatment effects.
Assumptions. (i) Consistency: 𝑌=𝑌(𝑎)if𝐴=𝑎; (ii) Positivity:
0<𝑝(𝐴=𝑎|𝑋=𝑥)<1,∀𝑎∈A, if𝑝(𝑥)>0; (iii) Ignorability:
𝑌(𝑎)⊥⊥𝐴|𝑋=𝑥,∀𝑎∈A.
The above assumptions are the standard for identifiability of
treatment effects from observational data [ 17,31] . Consistency
from Assumption (i) ensures that the observed outcomes are real-
izations of potential outcomes given observed treatment. Positivity
from Assumption (ii) ensures that all treatments are possible on the
entire covariate space. Ignorability from Assumption (iii) is often
referred to as “no hidden confounders” assumption, meaning that
all variables that affect both treatment 𝐴and potential outcomes
𝑌(𝑎)are measured in the covariates 𝑋. Under Assumptions (i)–(iii),
we have that 𝜇(𝑎,𝑥):=E[𝑌(𝑎)|𝑋=𝑥]=E[𝑌|𝐴=𝑎,𝑋=𝑥].
Hence, we can estimate 𝜇(𝑎,𝑥)from observational data Dby learn-
ing a function 𝑓:A×X→Y using machine learning. (In the
supplements in our GitHub repository, we provide several sec-
ondary analyses where we provide empirical results to validate the
above assumptions.)
Our task is subject to three main challenges, which we briefly
summarize in the following. (1) There is a comparatively large set of
country characteristics that we need to control for in order to adjust
for confounding. However, as a result, having a high-dimensional
covariate space leads to higher estimation variance (see Supple-
ment A for an overview of all control variables). (2) Treatment se-
lection bias can be present in observational data, which means that
treatment–response estimates in some covariate domains might
be unreliable due to a limited number of observed data points (see
supplements in our GitHub repository for an analysis of covariate
distributions for different development aid volumes). (3) There is
only a comparatively small set of countries receiving aid because of
which the sample size 𝑛with observed outcomes is naturally small.
To obtain reliable estimates despite the aforementioned challenges,
we develop a tailored method in the following called counterfactual
generator for continuous treatments (CG-CT).
3.2 Data
We use the following data: (1) Outcome variable 𝑌represents the
relative reduction in the HIV infection rate (i.e., the annual number
of new infections per 1,000 uninfected in the population) compared
to the previous year. The data are obtained from UN SDG indicator
database [ 43]. (2) Treatment 𝐴represents the official development
aid volume in USD millions per annum earmarked to end HIV in
each country. The data are obtained from OECD CRS database [ 29].
(3) Covariates 𝑋represent control variables that capture different
country characteristics with regard to socioeconomic, macroeco-
nomic, and health-related dimensions. Examples are: gross domestic
product (GDP) per capita, GDP growth, population size, maternal
mortality, infant mortality, school enrollment, etc. The complete
list of covariates is given in Supplement A. The data are obtained
from the World Bank database [47].
5285KDD ’24, August 25–29, 2024, Barcelona, Spain Milan Kuzmanovic, Dennis Frauen, Tobias Hatt, & Stefan Feuerriegel
We use the data from 105 countries that are recipients of de-
velopment aid earmarked towards ending the HIV epidemic. The
sample covers a population of more than 4.3 billion people (around
half of the world’s population). We predict the country-specific
aid–response curves for the year 2017. The reason is that some
of the data are made public by international organizations only
with a time lag after the actual data collection (e.g., maternal mor-
tality). For learning, we use data from the previous year, that is,
2016. This ensures that all performance evaluations are conducted
using out-of-sample observations from 2017. Later, we also conduct
robustness checks with other time frames (see supplements in our
GitHub repository).
3.3 Causal machine learning framework
To learn treatment–response curves for our HIV setting, we de-
velop the following causal machine learning framework which we
callcounterfactual generator for continuous treatments (CG-CT ).
CG-CT is tailored so that it can handle continuous treatments
and deal with the unique challenges of our problem setup (i.e.,
high-dimensional covariates in the form of country characteris-
tics, treatment selection bias, small sample size). CG-CT comprises
three components: (1) a balancing autoencoder aimed at embed-
ding high-dimensional country characteristics while simultane-
ously addressing treatment selection bias; (2) a counterfactual gen-
erator to compute counterfactual outcomes for varying volumes of
aid to address the small sample-size setting; and (3) an inference
model which is a (causal) machine learning model used to predict
treatment–response curves from observational data. The idea be-
hind components (1) and (2) is to perform a data augmentation that
generates synthetic data points under our causal graph, which, in
turn, helps in predicting the treatment–response curves in compo-
nent (3), despite the small sample-size setting. Below, we present
the three components of our CG-CT (see Figure 2). Pseudocode is
in Supplement C.
Component (1): Balancing autoencoder. The balancing autoencoder
maps the original high-dimensional covariate space X∈R𝑝onto a
representation space Z∈R𝑟with𝑟<𝑝. The aim is to: (i) reduce the
dimension of the covariate space while preserving ignorability (i.e.,
confounder control), and (ii) address treatment selection bias. For
this, we use representation learning [ 3] to learn a representation
𝜙:X → Z that preserves the original covariate information
in a lower-dimensional space while being non-predictive of the
treatment𝐴. Therefore, we learn our balancing autoencoder by
minimizing the loss function
L=1
𝑛𝑁∑︁
𝑖=11
𝑝𝑥𝑖−ˆ𝑥𝑖2
2
|                 {z                 }
=L𝑥−𝜃1
𝑛𝑁∑︁
𝑖=1𝑎𝑖−ˆ𝑎𝑖2
2
|              {z              }
=L𝑎, (2)
whereL𝑥is the reconstruction loss (i.e., the mean squared er-
ror in predicting covariates 𝑋using the representation 𝑍) with
ˆ𝑥𝑖=𝑔𝑥(ˆ𝑧𝑖)and𝑔𝑥:Z→X (i.e.,𝑔𝑥is the inverse of 𝜙),L𝑎is
treatment prediction loss (i.e., the mean squared error in predicting
the treatment 𝐴using the representation 𝑍) with ˆ𝑎𝑖=𝑔𝑎(ˆ𝑧𝑖)and
𝑔𝑎:Z→A ,𝑝is the dimension of the covariate space, and 𝜃>0
1Balancing autoencoderA
Counterfactual generator 3Inference modelX XA
zGRL^
^ ^Y 1
Y 2
Y nA 1
A 2
A nX 1
X 2
X n1Y 1
Y 2
Y nA 1
A 2
A nZ 1
Z 2
Z n2^
^
^Y 1
Y 2
Y nA 1
A 2
A nZ 1
Z 2
Z n^
^
^
Y 1,1 A 1,1 Z 1^
Y 1,2 A 1,2 Z 1
Y n,m A n,m Z n^^~
~
~ ~~~3~ ^
Amax
A i,1~A i,2 A i,m~ ~
2Z^
wi,1* wi,2 wi,m
Y
Y i,1 Y i,2 Y i,m~ ~ ~* *Covariates (macro indicators)
Representation
Treatment (development aid)
Outcome (SDG target)
Gradient reversal layerRandom treatment 
Counterfactual outcome Optimal weights Treatment-response curve
X
Z
A
Y
A
w
Y
GRL~
~^
*AminFigure 2: Overview of our machine learning framework. The
aim of our CG-CT is to predict heterogeneous treatment ef-
fects of aid disbursements on SDG outcomes. For this, our
CG-CT proceeds along three components. In the first compo-
nent, country characteristics (e.g., socioeconomic, macroeco-
nomic, or health-related controls) are embedded in a lower
dimension using a balancing autoencoder. Here, we also ad-
dress treatment selection bias by learning a representation
of covariates that is not predictive of the treatment (imple-
mented via gradient reversal layer). In the second component,
counterfactual outcomes are generated for varying treatment
values, and then combined with the observational data. In the
third component, an inference model is used together with
the previous data to learn a relationship between outcome
(𝑌) and treatment ( 𝐴) for a given representation of covariates
(𝑍). This gives the treatment–response curve.
is a trade-off parameter. We discuss both the reconstruction loss
and the treatment prediction loss in the following.
The reconstruction loss L𝑥enforces the invertibility of the rep-
resentation that would allow to reconstruct the original covariates
from the representation. When 𝜙is an invertible mapping, then the
ignorability assumption holds with respect to the representation
as well, i.e., 𝑌(𝑎)⊥⊥𝐴|𝑋=⇒𝑌(𝑎)⊥⊥𝐴|𝑍=𝜙(𝑋)(see [ 49]).
Hence, enforcing invertibility is important because it ensures that
the original covariate information is preserved in a way that the
representation can be used to control for confounding.
The treatment prediction loss L𝑎(with a negative sign) aims
to reduce treatment selection bias by ensuring that the learned
representation of covariates is not predictive of the treatment. In
the presence of treatment selection bias, there can be a strong de-
pendence between covariates and treatment. This often results in
having covariate domains where certain levels of treatment are
rarely observed in observational data, which means that hetero-
geneous treatment effects cannot be reliably estimated in these
domains. One approach to deal with this problem is to learn a
balanced representation of covariates that is not predictive of the
treatment, thereby removing the association between treatment and
the respective representation of covariates. This domain adaptation
technique was applied for categorical treatments, with treatment
prediction loss being cross-entropy loss (see [ 4]). While previous
work was focused on binary and not continuous treatments, it
has been shown that domain adaptation for continuously indexed
5286Causal Machine Learning for Cost-Effective Allocation of Development Aid KDD ’24, August 25–29, 2024, Barcelona, Spain
domains can be implemented via an 𝐿2-loss [ 45]. Hence, we im-
plement a similar domain adaptation approach as in [ 4], i.e., using
adversarial learning with gradient reversal layer (GRL) [ 13], but
adapt it to our setting with continuous treatment where our L𝑎is
set to the𝐿2-loss.
Thus, the balancing autoencoder produces a low-rank represen-
tation of covariates ˆ𝑍=ˆ𝜙(𝑋)(where ˆ𝜙is the representation 𝜙
learned from data) which aims to (i) preserve the original covari-
ate information by minimizing the reconstruction loss L𝑥, and
(ii) remove the association between covariates and treatment by
maximizing treatment prediction loss L𝑎. This allows us to use ˆ𝑍
as control variables to adjust for confounding while simultaneously
addressing treatment selection bias.
Component (2): Counterfactual generator. The counterfactual gener-
ator computes counterfactual outcomes for varying treatments and
covariates (i.e., for varying aid volumes and varying country char-
acteristics). Here, the aim is to address the missing counterfactual
outcomes in observational data and improve the predictions by
combining the observational data with additional counterfactual
outcomes. Our approach for counterfactual generation is motivated
by results from earlier research in machine learning [ 5]. However,
different from [ 5], we refrain from using a generative adversarial
network (GAN), due to the small sample size and the poor fit as a
result; instead, we develop a custom approach.
We compute the counterfactual outcomes by weighting data
points from the observational data. Specifically, for a given treat-
ment ˜𝑎, covariate representation ˆ𝑧, and data ˆD={(𝑦𝑖,𝑎𝑖,ˆ𝑧𝑖)}𝑛
𝑖=1
(i.e., the observational data Dafter applying the balancing autoen-
coder), we compute the optimal weights by solving the following
optimization problem
𝑤∗=arg min
𝑤∈R𝑛ˆ𝑧−ˆ𝑍𝑇
mat𝑤2
2+𝛼∥𝑤∥𝑠s.t. 𝐴𝑇
vec𝑤=˜𝑎, (3)
where ˆ𝑍matis an𝑛×𝑟matrix with rows being covariate represen-
tations from the observational data ˆ𝑧1,..., ˆ𝑧𝑛,𝐴vecis a vector of
treatments𝑎1,...,𝑎𝑛from the observational data, and 𝑠is the order
of the norm (here: 𝑠=1). After computing optimal weights 𝑤∗,
these are then used to compute the counterfactual outcome ˜𝑦for
treatment ˜𝑎and covariate representation ˆ𝑧by weighting outcome
values from the observational data, i.e., ˜𝑦=𝑌𝑇vec𝑤∗.
The idea behind the counterfactual generator is to reweight
the observational data to create a “synthetic twin” of a data point
(𝑦𝑖,𝑎𝑖,ˆ𝑧𝑖)under our causal graph. In our CG-CT , a synthetic twin
then has the following two properties: (i) the treatment of the syn-
thetic twin equals some desired treatment ˜𝑎for which we want
to generate the counterfactual outcome; and (ii) the covariate rep-
resentation of the synthetic twin ˜𝑧should resemble the covariate
representation ˆ𝑧𝑖of the data point (while addressing treatment
selection bias). By computing 𝑤∗using the observational data and
Eq.(3), we generate the synthetic twin (˜𝑦,˜𝑎,˜𝑧). Then, since the
synthetic twin and the data point ideally differ only with respect to
the value of the treatment, we can use the outcome of the twin ˜𝑦
as a prediction for the counterfactual outcome for the data point
with covariate representation ˆ𝑧𝑖if the treatment value was ˜𝑎. As
such, we can add the data point (˜𝑦,˜𝑎,ˆ𝑧𝑖)and increase the size of
our observational data.The benefit of generating counterfactual outcomes is that we
gain access to additional (counterfactual) outcome–treatment pairs,
which can improve precision in predicting treatment–response
curves. Notwithstanding, counterfactual generation procedure can-
not provide ground-truth counterfactual outcomes, but rather pre-
dictions of counterfactual outcomes based on the observational
data. Hence, to achieve performance gains, the counterfactual gen-
erator has to be sufficiently precise such that the error reduction
when predicting treatment–response curves with additional coun-
terfactual data outweighs the error in predicting counterfactual
outcomes during counterfactual generation.
We implement the counterfactual generator by generating 𝑚
counterfactual outcome–treatment pairs for each data point in
the observational data. Specifically, for each country 𝑖, with corre-
sponding covariate representation ˆ𝑧𝑖, we first sample 𝑚treatment
values{˜𝑎𝑖𝑗}𝑚
𝑗=1uniformly from the interval [𝐴min,𝐴max]. Then,
for each treatment ˜𝑎𝑖𝑗and corresponding ˆ𝑧𝑖, we compute the op-
timal weights 𝑤∗
𝑖𝑗using the observational data and Eq. (3), and,
then, we generate the counterfactual outcome ˜𝑦𝑖𝑗. As a result, the
counterfactual generator is used to augment the observational data
with𝑚·𝑛counterfactual outcome–treatment pairs to improve the
precision in predicting treatment–response curves.
Component (3): Inference model. The inference model is used to pre-
dict treatment–response curves from given data by learning a func-
tion𝑓:A×Z→Y . This is the final step in CG-CT after applying
the balancing autoencoder and the counterfactual generator to the
observational data. In principle, any machine learning regression
method can be used as an inference model; however, our focus is
on the prediction of treatment effects of a continuous treatment.
Hence, as inference model, we use a model from the causal ma-
chine learning literature that is aimed at predicting the effect of
a continuous treatment, namely, the generalized propensity score
(GPS) [ 16]. We have chosen the GPS as we expect it to be more
robust in small sample size settings due to its parsimonious struc-
ture as compared to deep learning-based causal machine learning
methods (e.g., the dose-response network (DRNet) [ 33]). We later
evaluate other inference models (see supplements in our GitHub
repository) and thereby confirm empirically that our choice of the
GPS is preferred.
The GPS involves a two-step estimation procedure. In the first
step, the conditional distribution of the treatment given covariates
(in our case, it is the covariate representation, as the inference
model is applied after the balancing autoencoder) is modeled under
the assumption of a Gaussian distribution, i.e.,
𝐴𝑖|𝑍𝑖∼𝑁(𝛽0+𝛽1𝑍1𝑖+...+𝛽𝑟𝑍𝑟𝑖;𝜎2), (4)
where𝑟is the size of the covariate representation space. Once the
estimates ˆ𝛽0,ˆ𝛽1,..., ˆ𝛽𝑟,ˆ𝜎are obtained (e.g., via maximum likeli-
hood estimation), they are used to compute the estimates of GPS
as follows:
ˆ𝑅𝑖=1√
2𝜋ˆ𝜎2exp
−1
2ˆ𝜎2 𝐴𝑖−ˆ𝛽0−ˆ𝛽1𝑍𝑖1−...−ˆ𝛽𝑟𝑍𝑖𝑟2
.(5)
In the second step, the heterogeneous treatment–response curves
are estimated by using a 2nd-degree polynomial regression given
by
𝑌𝑖=𝛼0+𝛼1𝐴𝑖+𝛼2𝐴2
𝑖+𝛼3𝑅𝑖+𝛼4𝑅2
𝑖+𝛼5𝐴𝑖𝑅𝑖. (6)
5287KDD ’24, August 25–29, 2024, Barcelona, Spain Milan Kuzmanovic, Dennis Frauen, Tobias Hatt, & Stefan Feuerriegel
Hence, the full GPS model is estimated by obtaining parameter
estimates ˆ𝛽GPS=(ˆ𝛽0,ˆ𝛽1,..., ˆ𝛽𝑟),ˆ𝜎GPSand ˆ𝛼GPS=(ˆ𝛼0,ˆ𝛼1,..., ˆ𝛼5).
Why is the GPS able to predict treatment–response curves in
small sample-size settings? Recall that the GPS is highly parsimo-
nious: the first step has 𝑟+2parameters, and the second step has 6
parameters, which amounts to only 𝑟+8parameters to be estimated.
In our case, we have 𝑝=14covariates, and the covariate represen-
tation space 𝑟is lower than 𝑝by construction (see the range for the
representation layer size of CG-CT in supplements in our GitHub
repository). Hence, the GPS can be estimated well in our setting.
This is a crucial difference of our framework from common base-
lines that build upon neural networks or other machine learning
models (e.g., [5, 33]).
3.4 Experimental details
Semi-synthetic data. To assess the effectiveness of our CG-CT in
predicting treatment–response curves, we need to evaluate pre-
diction performance on counterfactual outcomes (and not only on
factual outcomes). Because counterfactual outcomes are unobserv-
able in the real-world data, we follow common practice in machine
learning [ 5,33] and make use of semi-synthetic data where “ground-
truth” counterfactual outcomes are known. Formally, we simulate
semi-synthetic data as given in Supplement B.
Baselines. We use the following baselines: (i) linear model (LM)
of varying order with regularization term (i.e., linear regression,
LASSO regression, or ridge regression); (ii) artificial neural network
(ANN) for non-linearities; (iii) generalized propensity score (GPS)
[16]; (iv) dose-response networks (DRNet) [ 33]; and (v) SCIGAN
[5].
Baselines (i)–(ii) are standard machine learning models. While
they are applicable to our setting, these baselines are not tailored
for treatment effect estimation and, therefore, do notaddress causal
aspects such as treatment selection bias. Baselines (iii)–(v) are from
the causal machine learning literature representing state-of-the-
art benchmarks focused on predicting the effect of continuous
treatment. Of note, there are other methods that deal with treatment
effect estimation (e.g., causal forests), yet with a focus on binary
andnotoncontinuous treatments [ 2,15,20,34,48]. Hence, these
methods are not applicable to our setting.
Performance metrics. In our experiments, we evaluate the perfor-
mance of CG-CT in two ways: (i) counterfactual outcome pre-
diction using semi-synthetic data, i.e., performance in predicting
treatment–response curves; and (ii) factual outcome prediction
using real-world data.
For (i), we follow prior literature [ 33] and use the mean integrated
squared error (MISE) given by
MISE =1
𝑛𝑛∑︁
𝑖=1∫𝐴max
𝑎=𝐴min 𝑦𝑖(𝑎)−ˆ𝑦𝑖(𝑎)2d𝑎, (7)
where𝑦𝑖(𝑎)is the respective outcome given aid volume 𝑎,ˆ𝑦𝑖(𝑎)
is the predicted outcome given aid volume 𝑎, and the interval
[𝐴min,𝐴max]is the observed interval of development aid in real-
world data. The MISE has the advantage that we benchmark the
performance across a range of different aid volumes [𝐴min,𝐴max].
Formally, we compute the inner integral of MISE using Rombergintegration with 64 equally spaced samples of development aid on
the interval[𝐴min,𝐴max].
For (ii), we use the root mean squared error. Note that we use
the RMSE for real-world data (as opposed to the MISE), since the
performance must be computed using a single outcome (as opposed
to the complete treatment–response curve).
Implementation. We used Python 3.7 and PyTorch 1.7. The training
is done in batches for a given number of epochs. We use Adam [ 21]
with learning rate 𝜂for optimization. Hyperparameter tuning is
performed via cross-validation with 80/20 split (see supplements in
our GitHub repository for details). The performance is reported as
mean±standard deviation (averaged over 10 runs).
Decision-making problem. In order to understand the potential down-
stream impact of our framework and how it can support aid allo-
cation in practice, we introduce the following decision-making
problem. We study a hypothetical setting where an aid allocation
under budget constraints should be identified that minimizes the
total annual number of new HIV infections across countries. The
idea is that such an analysis should identify countries in need of
development aid to not fall behind. Reassuringly, we emphasize that
the suggested allocation should not be interpreted as an optimal
allocation due to various idiosyncrasies in practice, but rather as
illustrative for how our framework can help decision-making in
identifying needs and funding gaps.
Formally, we solve the following decision-making problem:
[𝑎1,...,𝑎𝑛]∗=arg min
𝑎𝑖∈[0,𝐿]
𝑖=1,...,𝑛𝑛∑︁
𝑖=1 1−ˆ𝑦𝑖(𝑎𝑖,𝑥𝑖)𝑟𝑖𝑝𝑖s.t.𝑛∑︁
𝑖=1𝑎𝑖≤𝐵,
where𝐿is the bound for aid allocation to a single country, ˆ𝑦𝑖(𝑎𝑖,𝑥𝑖)
is the predicted relative reduction in the HIV infection rate (pre-
dicted by our CG-CT for given aid volume 𝑎𝑖and given country
characteristics 𝑥𝑖),𝑟𝑖is the HIV infection rate for a given coun-
try from the previous year, 𝑝𝑖is the population size in a given
country, and 𝐵is the available budget. In our analysis, we set 𝐵to
the total observed volume of aid allocated in the current year. We
bound the disbursement, 𝑎𝑖for𝑖=1,...,𝑛 , to a single country to
the range[0,𝐿]with𝐿=𝐴max+ˆ𝜎𝐴, where𝐴maxis the maximal
value of observed aid for a single country, and ˆ𝜎𝐴is the estimated
standard deviation for the aid variable 𝐴. We do this to prevent
overly large extrapolation when providing estimates of aid effects
using ˆ𝑦𝑖(𝑎𝑖,𝑥𝑖). In our implementation, we solve the optimization
problem using sequential least squares programming [22].
4 RESULTS
4.1 Results for semi-synthetic data
We make a few important observations based on the results of our
experiments with semi-synthetic data (see Figure 3a). First, CG-CT
is the best-performing method in predicting treatment–response
curves. We observe that the square root of MISE for the best baseline
(GPS) is 0.205±0.000. In contrast, for our CG-CT , it is 0.158±
0.024. Hence, our method reduces the prediction error by at least
23% compared to the baselines. This shows that our CG-CT is a
superior method for predicting heterogeneous treatment–response
curves in our HIV setting. Second, we observe a large estimation
error and a large variance for SCIGAN (i.e., 11.443 ±9.303), which
5288Causal Machine Learning for Cost-Effective Allocation of Development Aid KDD ’24, August 25–29, 2024, Barcelona, Spain
is a state-of-the-art method that has been shown to have superior
performance over both DRNet and GPS [ 5]. However, SCIGAN
is based on generative adversarial networks (GANs), which may
have poor fit in small sample size settings. Given that in our case,
we have a sample of 105 countries (and thus much smaller than
experiments in [ 5]), it is not surprising that SCIGAN has challenges
in our HIV setting.
4.2 Results for real-world data
We now apply our machine learning framework CG-CT to real-
world HIV data. Here, the main purpose is to demonstrate the
applicability of our method (rather than performance benchmark-
ing). The reason is that ground-truth treatment effects are absent
in real-world data, and, therefore, the performance in predicting
treatment–response curves can no longer be evaluated.
We compare our CG-CT against baselines that produce treat-
ment effects, i.e., GPS, DRNet, and SCIGAN (see Figure 3b). This
was done intentionally to prevent the advantages of more flexi-
ble methods that directly optimize their performance against fac-
tual outcome prediction and, thus, to ensure a fair comparison.
Importantly, our results confirm that the baselines for predicting
treatment-response curves are consistently outperformed by our
CG-CT . In particular, we show an improvement of at least 5% in
RMSE. We again observe a large RMSE for SCIGAN along with
a large variance (i.e., 3.430 ±2.393), which can be attributed to
challenges of fitting a GAN in a small sample setting.
We also report the performance of standard machine learning
methods in the following. However, these have the advantage of be-
ing designed for factual outcome prediction (whereas our method is
designed for predicting treatment effects), and, therefore, we expect
ourCG-CT to achieve a somewhat similar performance. Here, the
RMSE for the standard machine learning baselines is 0.078 ±0.000
(for LM) and 0.083 ±0.003 (for ANN). Our CG-CT achieves 0.076
±0.002, which is an improvement of 2.56%. Hence, our framework
outperforms the standard machine learning baselines as well.
We use CG-CT to predict aid–response curves for different coun-
tries in 2017 (see Figure 3c). The aid–response curves can be used
by public decision-makers to answer ‘what if?’ questions; that is,
how potential changes in aid volumes would change the expected
reduction in HIV infection rates. Overall, we see a clear pattern:
development aid is predicted to have a positive effect on the reduc-
tion in HIV infection rates. This is expected as such a relation was
empirically confirmed in retrospective studies [ 25]. Importantly,
however, we observe considerable between-country heterogeneity
in the predicted aid–response curves. For example, the observed aid
for Mozambique (in orange) is USD 402 million, and the expected
reduction in HIV infection rate predicted by our CG-CT is 6.94%.
Here, an increase in development aid of USD 50 million would re-
sult in expected reduction in the HIV infection rate by 7.76%. In
contrast, the observed aid for Congo (in red) is USD 145 million,
and the expected reduction in the HIV infection rate predicted by
ourCG-CT is 4.15%. Here, an increase in development aid of USD
50 million would result in expected reduction in the HIV infection
rate by 4.29%. Hence, an increase in development aid by USD 50 mil-
lion is predicted to have a stronger impact in Mozambique than in
Congo. Moreover, we note that our predicted aid–response curvespredict a reduction in HIV infection rates even in the absence of
aid, albeit of different magnitude across countries. This can be ex-
pected as reductions can also be driven by country characteristics
and other trends (e.g., domestic financing to end the HIV epidemic,
growing disease awareness, etc.). In sum, the aid–response curves
may help public decision-makers when allocating aid by informing
them about the expected effect of a particular aid allocation on HIV
infection rates across countries.
(a)
SCIGAN DRNet GPS ANN LM CG-CT (ours)0.100.150.200.25MISE
11.443
0.281
0.2050.234
0.209
0.158 (b)
SCIGAN DRNet GPS CG-CT (ours)0.060.070.080.09RMSE3.43
0.098
0.08
0.076
(c)
450 500 550 600 6506810121416
300 350 400 450 50046810
0 50 100 1500246
50 100 150 200 250246
0 50 1001234567
0 50 100 150 200246
Development aid (in USD millions)Relative reduction in HIV infection rate (in %)South Africa
Mozambique
Burundi
Congo, Dem. Rep.
India
Indonesia
Observed aid
Figure 3: Results for predicted aid–response curves. (a)Re-
sults from the experiments with semi-synthetic data. (b)Re-
sults from the experiments with real-world data. (c)Predic-
tions for aid–response curves in six example countries. The
predicted aid–response curves for the remaining countries
are provided in supplements in our GitHub repository. Ver-
tical dashed line denotes the actual volume of development
aid as observed in 2017. The 𝑥-axis is set to 𝐴obs±ˆ𝜎𝐴(with
a cut-off at zero to prevent negative values for Burundi and
India), where 𝐴obsis the observed development aid and ˆ𝜎𝐴is
the estimated standard deviation of development aid in 2017.
4.3 Potential for more effective aid allocation
We now provide insights into how our framework can inform the
decision-making around aid allocation. Our decision-making prob-
lem seeks to determine an aid allocation that minimizes the total
annual number of new HIV infections across all countries under
a budget constraint (see Methods for details). Here, we use the
predicted aid–response curves as input, which provide predictions
of the expected reduction in the HIV infection rate compared to the
previous year for a given aid volume and given country character-
istics. We use real-world HIV data from the year 2017. Specifically,
to limit the overall available volume of development aid, we set
the budget constraint to the observed total volume of aid allocated
in the year 2017. For evaluation, we compare (i) the expected an-
nual number of new HIV infections under our suggested allocation
against (ii) the expected annual number of new HIV infections un-
der current allocation practice. To account for variation, we report
bootstrapped [9] confidence intervals.
5289KDD ’24, August 25–29, 2024, Barcelona, Spain Milan Kuzmanovic, Dennis Frauen, Tobias Hatt, & Stefan Feuerriegel
Our results (see Figure 4a) show that the expected number of new
HIV infections under the current allocation is 1.49 ±0.02 million.
For our suggested allocation, the expected number of new HIV
infections is 1.44±0.04 million. The reduction amounts to 3.3% ±
1.8%. This corresponds to ∼50,000 fewer cases (i.e., 48,925 ±26,779).
As a robustness check for our modeling, we note that the expected
number of new HIV infections predicted by our framework for
the observed aid allocation (i.e., 1.49 million new HIV infections)
matches the actual number of new HIV infections observed in the
data (Figure 4a, gray dotted line). This again corroborates that our
framework provides precise outcome predictions.
We further compare aid volumes under current aid allocation
vs. the allocation suggested by our CG-CT (see Figure 4b). Impor-
tantly, our framework identifies countries with higher needs for
aid than before. For example, our framework suggests increasing
aid for Zambia by USD 366 million and for Nigeria by USD 329
million. Overall, our framework suggests increasing aid disburse-
ments in several countries in Southeast Africa (e.g., South Africa,
Mozambique, Tanzania, Zambia). Furthermore, our machine learn-
ing framework targets more aid towards non-African countries,
which have previously not received large amounts of aid in the past
despite having a comparatively large annual number of new HIV
infections (e.g., India, Brazil). In sum, our findings demonstrate the
effectiveness of our CG-CT to inform cost-efficient allocation of
development aid that maximizes progress towards ending the HIV
epidemic.
(a)
Current allocation Suggested allocation1.351.401.451.501.55HIV infections worldwide (in millions)1.49
1.44Observed: 1.49
3.3%
(~50,000 cases) (b)
<-300-200-1000100200>300Suggested vs. observed aid (in USD millions)
Figure 4: Suggested vs. current aid allocation. (a)Reduction
in the expected number of new HIV infections worldwide
under the suggested allocation vs. the current allocation of
development aid. (b)Change in the aid volume between the
suggested and the current aid allocation (in USD millions).
Gray: countries that were not aid recipients in 2017.
4.4 Robustness checks
In order to further validate our CG-CT , we perform several addi-
tional analyses. (1) We visually inspect the covariate representations
learned by the balancing autoencoder using t-SNE [ 44] and isomap
[35]. The visualizations are shown in supplements in our GitHub
repository. We observe that the balancing autoencoder induces
homogeneity of the covariate representation with respect to treat-
ments, thereby successfully addressing treatment selection bias.
(2) We perform a sensitivity analysis of our CG-CT with respect to
the balancing parameter 𝜃(from the balancing autoencoder) and the
number of generated counterfactual outcomes per country 𝑚(from
the counterfactual generator). We observe that the results remainrobust when varying these hyperparameters (see supplements in
our GitHub repository). (3) We examine how CG-CT behaves when
other (causal) machine learning methods (i.e., LM, ANN, DRNet) are
used as the inference model instead of GPS. Here, we find that our
CG-CT leads to consistent performance improvements over the
baselines across different inference models (see supplements in our
GitHub repository). Moreover, the results show that the choice of
GPS is preferred. (4) We perform an ablation study where we toggle
the balancing autoencoder and the counterfactual generator on/off.
We observe that the performance gains by our CG-CT are a result
of combining the balancing autoencoder with the counterfactual
generator (see supplements in our GitHub repository). This demon-
strates the importance of our methodological innovations. (5) We
repeat the ablation study with other inference models for which we
now toggle the balancing autoencoder and the counterfactual gen-
erator on/off. Again, we see clear performance improvements when
combining both components (see supplements in our GitHub repos-
itory). This confirms that balancing autoencoder and counterfactual
generator are important for obtaining precise treatment–response
curves in our setting.
We perform several analyses to examine the validity of the un-
derlying assumptions for identifiability of treatment effects, namely,
positivity and ignorability, as well as the robustness to the potential
violation of the latter. (1) We first show the estimated probability of
aid volumes for different countries, where we observe that the range
of aid volumes over which we optimize allocation does not lead to
severe extrapolation (see supplements in our GitHub repository).
(2) We examine the robustness of the predicted treatment effect of
aid when adding other covariates that were not included in country
characteristics. Here, we focus on past values of development aid,
past values of HIV infection rate, past aid volumes of neighboring
countries, and past HIV infection rates of neighboring countries,
which allows us to control for additional temporal dynamics and
spillover effects between countries. We find that the effect remains
robust, indicating that our set of country characteristics is sufficient
to address potential confounding effects of these covariates (see
supplements in our GitHub repository). (3) We perform a causal
sensitivity analysis to check the robustness of our method regard-
ing violations of the ignorability assumption, that is, unobserved
confounding. We use a state-of-the-art method [ 11,12,19] to check
that our predicted treatment–response curves remain stable under
small violations of the ignorability assumption (see supplements
in our GitHub repository). In other words, even in a hypothetical
case of unobserved confounding, our results remain robust, and
one cannot explain away the predicted treatment effect.
To show robustness of our results in a different time frame, we
perform an analysis where we use HIV data from the year 2015
for learning and from the year 2016 for evaluation. We observe
that the conclusions of our analysis remain consistent and that
the baselines are outperformed by our CG-CT (see supplements
in our GitHub repository). We also experimented with multi-year
data for learning; however, this did not lead to significant out-of-
sample performance improvements. Here, one explanation is that
allocation practices are subject to changes over time (e.g., changes
in priorities, changes in programs, funding mix) [50].
5290Causal Machine Learning for Cost-Effective Allocation of Development Aid KDD ’24, August 25–29, 2024, Barcelona, Spain
5 DISCUSSION
Strengths: Our data-efficient CG-CT is tailored to our setting
where it offers several strengths for predicting heterogeneous treat-
ment effects. While there are numerous methods in the literature for
binary treatments (e.g., causal forests) [ 2,15,20,34,48], there are
comparatively few for continuous treatments [ 5,16,33]. Different
from existing methods, our CG-CT is designed to simultaneously
address continuous treatments, high-dimensional covariates (coun-
try characteristics), treatment selection bias, and a small sample-
size setting. Here, our framework shows a superior performance in
predicting aid–response curves. For example, in our experiments
with semi-synthetic data, our CG-CT outperforms both standard
machine learning methods (i.e., the linear model and the artificial
neural network) and common baselines for predicting heteroge-
neous treatment–response curves [ 5,16,33] by at least 23%. Our
ablation studies (see supplements in our GitHub repository) show
that our performance improvements are largely attributed to our
combination of the balancing autoencoder and the counterfactual
generator as effective levers to address the above challenges. Finally,
our framework is data-efficient: the different components operate
on a low-dimensional covariate space and polynomial regression
together with data augmentation. This is a crucial difference of
our framework from common baselines that build upon neural net-
works (e.g., [ 5,33]). To this end, we foresee future applications of
ourCG-CT in other decision-making settings.
Limitations: As any other work, ours is not free of limitations,
which provide interesting opportunities for future research. First,
the standard challenge when predicting treatment effects from ob-
servational data is that counterfactual outcomes are not observable
[32]. This is not unique to our framework but is inherent to es-
sentially all methods from the literature [ 5,33], which then make
mathematical assumptions to infer treatment effects. Notwithstand-
ing, conducting a randomized controlled trial as the gold standard
for estimating treatment effects is costly and may thus be consid-
ered infeasible for our problem setup. Here, our proposed frame-
work based on machine learning using observational data offers
a scalable approach that relies on the standard assumptions for
identifiability of treatment effects from the literature. While relying
on these assumptions is a limitation, we have conducted several
analyses to examine their validity in our setting and demonstrate
robustness of our results under potential violations (see supple-
ments in our GitHub repository). Second, there are other factors
that may drive aid allocations in practice. Examples are sanctions
(e.g., as in Afghanistan in 2021) or political aims (e.g., prioritizingspecific regions or activities). Nevertheless, our framework is useful
in such situations as it promotes transparency by informing about
needs and funding gaps. This is especially relevant as development
financing transitions towards bilateral negotiations about aid vol-
umes between donors and recipients. Finally, we emphasize that
our objective is not to coordinate aid disbursements at the level of
individual funding bodies. This would require a tactical model to
account for operational constraints, expertise, coordination, and
other idiosyncratic aspects of individual aid activities, because of
which such a model would not be meaningful in practice. Instead,
we fulfill a direct need in practice [ 30] by informing allocations of
development aid on a global scale.
Impact: Our framework shows large untapped potential for
making progress towards ending the HIV epidemic through cost-
efficient aid allocation. Of note, our framework is not only appli-
cable to the HIV epidemic but essentially to all other SDG targets.
Thereby, our work supports public decision-makers in making im-
portant progress towards the SDGs. This is especially relevant due
to ongoing challenges (e.g., the Russian invasion of Ukraine, global
warming, etc.), necessitating a more cost-efficient use of resources.
Finally, our framework has the potential for even more general
applications beyond the SDGs, since it can be relevant for many
decision-making problems from public policy, where data avail-
ability is a common challenge. Examples include financial policy
where interest rates must be set to balance different economic out-
comes, or public health measures from the COVID-19 pandemic
with the aim to reduce infection rates. Such applications of our
CG-CT would present both a strong potential for social impact, as
well as promising areas for further research.
Deployment: The current framework presented in this paper
is the result of a collaboration with the Organisation for Economic
Co-operation and Development (OECD), an intergovernmental orga-
nization coordinating development aid activities of different donors.
The SDG Financing Lab of the OECD has been tasked with develop-
ing dashboards around machine learning models, such as ours, that
make data-driven insights available to decision-makers. Here, we
report performance based on computational experiments (rather
than from post-launch) due to two reasons. (i) Aid allocation fol-
lows a multi-year process from goal setting to shifting funding, so
that real-world evidence on SDG outcomes is only available with a
significant delay. (ii) Aid allocation follows a human-in-the-loop
process, making it difficult to use post-launch data to isolate human
judgment from the recommendations of our framework. Hence,
we opted for a numerical evaluation to offer timely results and
demonstrate broad applicability.
5291KDD ’24, August 25–29, 2024, Barcelona, Spain Milan Kuzmanovic, Dennis Frauen, Tobias Hatt, & Stefan Feuerriegel
REFERENCES
[1]Alaa, Ahmed M. and van der Schaar, Mihaela. 2018. Limits of estimating heteroge-
neous treatment effects: Guidelines for practical algorithm design. International
Conference on Machine Learning (2018).
[2]Susan Athey, Julie Tibshirani, and Stefan Wager. 2019. Generalized random
forests. The Annals of Statistics 47, 2 (2019), 1148–1178.
[3]Bengio, Yoshua and Courville, Aaron and Vincent, Pascal. 2013. Representation
learning: A review and new perspectives. IEEE Transactions on Pattern Analysis
and Machine Intelligence (2013).
[4]Ioana Bica, Alaa, Ahmed, M., James Jordon, and Mihaela van der Schaar. 2020.
Estimating counterfactual treatment outcomes over time through adversarially
balanced representations. International Conference on Learning Representations
(2020).
[5]Ioana Bica, James Jordon, and Mihaela van der Schaar. 2020. Estimating the
effects of continuous-valued interventions using generative adversarial networks.
Advances in Neural Information Processing Systems (2020).
[6]Kassandra Birchler and Katharina Michaelowa. 2016. Making aid work for
education in developing countries: An analysis of aid effectiveness for primary
education coverage and quality. International Journal of Educational Development
48 (2016), 37–52.
[7]Esther Duflo, Pascaline Dupas, Michael Kremer, and Samuel Sinei. 2006. Education
and HIV/AIDS prevention: Evidence from a randomized evaluation in Western
Kenya. (The World Bank) (2006).
[8]Duflo, Esther, and Michael Kremer. 2003. Use of randomization in the evaluation
of development effectiveness. World Bank Operations Evaluation Department
(OED) Conference on Evaluation and Development Effectiveness 15 (2003).
[9]Bradley Efron. 1992. Bootstrap methods: Another look at the jackknife. In
Breakthroughs in Statistics. Springer, New York, 569–593.
[10] Stefan Feuerriegel, Dennis Frauen, Valentyn Melnychuk, Jonas Schweisthal, Kon-
stantin Hess, Alicia Curth, Stefan Bauer, Niki Kilbertus, Isaac S Kohane, and
Mihaela van der Schaar. 2024. Causal machine learning for predicting treatment
outcomes. Nature Medicine 30, 4 (2024), 958–968.
[11] Dennis Frauen, Fergus Imrie, Alicia Curth, Valentyn Melnychuk, Stefan Feuer-
riegel, and Mihaela van der Schaar. 2024. A neural framework for generalized
causal sensitivity analysis. International Conference on Learning Representation
(2024).
[12] Dennis Frauen, Valentyn Melnychuk, and Stefan Feuerriegel. 2023. Sharp bounds
for generalized causal sensitivity analysis. Advances in Neural Information Pro-
cessing Systems (2023).
[13] Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo
Larochelle, François Laviolette, Mario Marchand, and Victor Lempitsky. 2016.
Domain-adversarial training of neural networks. The Journal of Machine Learning
Research 17, 1 (2016), 2096–2030.
[14] Global Burden of Disease Health Financing Collaborator Network. 2020. Health
sector spending and spending on HIV/AIDS, tuberculosis, and malaria, and
development assistance for health: progress towards Sustainable Development
Goal 3. The Lancet 396, 10252 (2020), 693–724.
[15] Hatt, Tobias and Feuerriegel, Stefan. 2021. Estimating average treatment effects
via orthogonal regularization. ACM International Conference on Information &
Knowledge Management (2021).
[16] Keisuke Hirano and Guido W. Imbens. 2004. The propensity score with con-
tinuous treatments. In Applied Bayesian Modeling and Causal Inference from
Incomplete-Data Perspectives. John Wiley & Sons, Ltd, Chichester, UK, 73–84.
[17] Guido Imbens and Donald B. Rubin. 2015. Casual inference for statistics, social,
and biomedical sciences: An introduction. Cambridge University Press, New York.
[18] Johannes Jakubik and Stefan Feuerriegel. 2022. Data-driven allocation of devel-
opment aid toward Sustainable Development Goals: Evidence from HIV/AIDS.
Production and Operations Management 31, 6 (2022), 2739–2756.
[19] Andrew Jesson, Alyson Douglas, Peter Manshausen, Nicolai Meinshausen, Philip
Stier, Yarin Gal, and Uri Shalit. 2022. Scalable sensitivity and uncertainty analysis
for causal-effect estimates of continuous-valued interventions. In NeurIPS.
[20] Johansson, Fredrik and Shalit, Uri and Sontag, David. 2016. Learning representa-
tions for counterfactual inference. International Conference on Machine Learning
(2016).
[21] Diederik P. Kingma and Jimmy Ba. 2015. Adam: A Method for Stochastic Opti-
mization. International Conference on Learning Representations (2015).
[22] Dieter Kraft. 1988. A software package for sequential quadratic programming.
German Aerospace Center – Institute for Flight Mechanics (1988).[23] Mathias Kraus, Stefan Feuerriegel, and Maytal Saar-Tsechansky. 2023. Data-
driven allocation of preventive care with application to diabetes mellitus type II.
Manufacturing & Service Operations Management (2023).
[24] Ruoqi Liu, Lai Wei, and Ping Zhang. 2021. A deep learning framework for drug
repurposing via emulating clinical trials on real-world patient data. Nature
Machine Intelligence 3, 1 (2021), 68–75.
[25] Musharavati Ephraim Munyanyi, Sefa Awaworyi Churchill, and Ahmed Skali.
2020. Foreign Aid and Development Goals: Revisiting the Evidence. In Moving
from the Millennium to the Sustainable Development Goals, Jenner and Awaworyi
Churchill (Eds.). Springer, Singapore, 181–197.
[26] OECD. 2009. Managing Aid: Practices of DAC Member Countries. https://www.
oecd.org/dac/peer-reviews/managingaidpracticesofdacmembercountries.htm
[27] OECD. 2018. Development Co-operation Report 2018: Joining Forces to Leave No
One Behind. https://www.oecd.org/social/development-co-operation-report-
20747721.htm
[28] OECD. 2021. Official Development Assistance (ODA). https:
//www.oecd.org/dac/financing-sustainable-development/development-
finance-standards/official-development-assistance.htm
[29] OECD. 2023. Creditor Reporting System (CRS). https://stats.oecd.org/Index.
aspx?DataSetCode=crs1
[30] OECD. 2023. The SDG Financing Lab. https://sdg-financing-lab.oecd.org/about
[31] Judea Pearl. 2009. Causality: Models, Reasoning, and Inference (2 ed.). Cambridge
University Press, Cambridge.
[32] Rubin, Donald B. 2005. Causal Inference Using Potential Outcomes: Design,
Modeling, Decisions. Journal of the American Statistical Association 100, 469
(2005), 322–331.
[33] Patrick Schwab, Lorenz Linhardt, Stefan Bauer, Joachim M. Buhmann, and Walter
Karlen. 2020. Learning counterfactual representations for estimating individual
dose-response curves. Proceedings of the AAAI Conference on Artificial Intelligence
(2020).
[34] Uri Shalit, Fredrik D. Johansson, and David Sontag. 2017. Estimating individual
treatment effect: generalization bounds and algorithms. International Conference
on Machine Learning (2017). http://proceedings.mlr.press/v70/shalit17a.html
[35] Tenenbaum, Joshua B. and Silva, Vin de and Langford, John C. 2000. A global
geometric framework for nonlinear dimensionality reduction. Science 290, 5500
(2000), 2319–2323.
[36] Malte Toetzke, Nicolas Banholzer, and Stefan Feuerriegel. 2022. Monitoring
global development aid with machine learning. Nature Sustainability 5 (2022),
533–541.
[37] UNAIDS. 2023. Global HIV & AIDS statistics: Fact sheet. https://www.unaids.
org/en/resources/fact-sheet
[38] United Nations. 2014. World Investment Report 2014: Investing in the SDGs: an
action plan. https://unctad.org/system/files/official-document/wir2014_en.pdf
[39] United Nations. 2015. Take Action for the Sustainable Development Goals.
https://www.un.org/sustainabledevelopment/sustainable-development-goals/
[40] United Nations. 2017. SDG Indicators. https://unstats.un.org/sdgs/indicators/
indicators-list/
[41] United Nations. 2018. The Sustainable Development Goals Report. https:
//unstats.un.org/sdgs/report/2018/
[42] United Nations. 2023. Goal 3: Ensure healthy lives and promote well-being for
all at all ages. https://www.un.org/sustainabledevelopment/health/
[43] United Nations. 2023. SDG Indicators Database. https://unstats.un.org/sdgs/
dataportal/database
[44] G. E. van der Maaten L. J. P. and Hinton. 2008. Visualizing data using t-SNE.
Journal of Machine Learning Research 9, 11 (2008), 2579–2605.
[45] Hao Wang and He, Hao and Katabi, Dina. 2020. Continuously indexed domain
adaptation. International Conference on Machine Learning (2020).
[46] WHO. 2020. The top 10 causes of death. https://www.who.int/news-room/fact-
sheets/detail/the-top-10-causes-of-death
[47] World Bank. 2023. World Bank Open Data. https://data.worldbank.org/
[48] Yoon, Jinsung and Jordon, James and van der Schaar, Mihaela. 2018. GANITE:
Estimation of individualized treatment effects using generative adversarial nets.
International Conference on Learning Representations (2018).
[49] Yao Zhang, Alexis Bellot, and Mihaela van der Schaar. 2020. Learning Over-
lapping Representations for the Estimation of Individualized Treatment Effects.
International Conference on Artificial Intelligence and Statistics (2020).
[50] Carlos Ávila, Dejan Loncar, Peter Amico, and Paul de Lay. 2013. Determinants
of government HIV/AIDS financing: a 10-year trend analysis from 125 low- and
middle-income countries. BMC Public Health 13 (2013), 673.
5292Causal Machine Learning for Cost-Effective Allocation of Development Aid KDD ’24, August 25–29, 2024, Barcelona, Spain
A OVERVIEW OF MODEL VARIABLES
Ending the HIV epidemic is an important target of the SDG frame-
work (Goal 3, Target 3.3.1) [ 40]. In 2017, there were 35.9 million
people living with HIV globally, with 1.7 million new infections and
800,000 HIV-related deaths [ 37]. Moreover, HIV has caused more
than 40 million deaths since the beginning of the epidemic [ 37],
and it continues to be one of the leading causes of death, especially
in low-income countries [ 46]. Overall, large HIV infection rates
(i.e., the annual number of new HIV infections per 1,000 uninfected
people in the population) are observed in Southern and Eastern
Africa (see Figure S1a). Countries with a particularly large num-
ber of new HIV infections per year are, for example, South Africa
(∼337,000), Mozambique ( ∼125,000), Tanzania ( ∼100,000), Nigeria
(∼94,000) and Zambia ( ∼73,000) (see Figure S1a, subplot). To this
end, the HIV epidemic presents a major threat to global public
health.
(a)
012345>6HIV infection rate
South
AfricaMozamb. Tanzania Nigeria Zambia0100200300HIV infections (in 1000s)
(b)
0100200300400500Development aid (in USD millions)
Kenya South
AfricaTanzania Mozamb. Uganda0200400600Development aid (in USD millions)
Figure S1: Overview of HIV infections and aid disbursements.
(a)HIV infection rate (i.e., the annual number of new HIV
infections per 1,000 uninfected people in the population) per
country in 2017. The subplot in the bottom-left corner shows
five countries with the largest number of new HIV infections
in 2017. (b)Volume of HIV development aid in USD millions,
in 2017. The subplot in the bottom-left corner shows five
countries that were the largest recipients of development aid
earmarked to end the HIV epidemic in 2017. Gray: countries
that were not aid recipients in 2017.
Development aid is important for achieving the goal of ending
the HIV epidemic, especially in developing countries that have
limited domestic financing. In 2017, development aid committed to
ending the HIV epidemic amounted to more than USD 5.2 billion.
Large volumes of aid were allocated to African countries (see Fig-
ure S1b). In particular, countries such as Kenya (USD 560 million),
South Africa (USD 530 million), and Tanzania (USD 482 million)
have received particularly large aid volumes (see Figure S1b, sub-
plot).Table S1 lists all variables that are used in our analysis: (i) the
outcome variable, (ii) the treatment variable, and (iii) the country
characteristics as covariates. Here, we have intentionally included
a wide range of socioeconomic, macroeconomic, and health-related
country characteristics in order to control for potential confounding
when predicting the aid–response curves. The choice for most of
the covariates (e.g., GDP per capita, population, school enrollment,
etc.) was motivated by previous work on aid effectiveness [ 6,18,25].
Table S1: Overview of model variables. The variables are
grouped by: relative reduction in HIV infection rate (out-
come ), development aid (treatment ), and country character-
istics (covariates ). Reported are also summary statistics (SD:
standard deviation). GDP per capita is reported as purchasing
power parity (PPP) adjusted values.
V
ariable Mean SD Median Min Max
Outcome
variable
Relative reduction in HIV infection rate (in %) 3.26 7.85 2.94−50.00 17.30
T
reatment variable
Development aid (in USD millions) 50.121 112.858 6.348 0.003 559.897
Countr
y characteristics
GDP per capita PPP (in USD thousands) 8.87 6.79 7.26 0.77 30.45
GDP growth (in %) 3.81 3.53 3.82−5.07 26.68
Foreign direct investment (in USD billions) 3.29 8.75 0.89−7.40 68.89
Consumer price index - inflation (in %) 7.75 18.72 4.38−1.54 187.85
Unemployment (in %) 7.83 6.23 5.65 0.14 27.04
Population (in millions) 41.66 135.75 11.98 0.38 1338.68
Fertility (number of births per woman) 3.25 1.33 2.85 1.26 7.00
Maternal mortality (number of deaths per 100,000 live births) 241.21 259.08 144.00 2.00 1150.00
Infant mortality (number of deaths per 1,000 live births) 30.95 20.36 26.60 2.70 87.30
Life expectancy (in years) 68.50 6.90 69.51 52.95 79.91
School enrolment ratio (primary education) 1.04 0.13 1.03 0.68 1.45
Prevalence of undernourishment (in % of population) 13.91 11.65 9.10 2.50 58.70
Access to electricity (in % of population) 73.83 29.83 90.30 4.20 100.00
Incidence of tuberculosis (number of cases per 100,000 people) 162.29 158.96 99.00 5.20 738.00
The above data have a small ratio of missing values (around
3.5%), mostly present in a few country characteristics (e.g., school
enrollment, inflation). We imputed the missing values using the
𝑘-nearest neighbors algorithm. Furthermore, due to varying scales
in country characteristics, we standardize the covariate data prior
to the analysis using a min-max scaler (i.e., scale the data to [0,1]
interval by deducting the minimal value and, subsequently, dividing
by the difference between the maximal and the minimal value).
B SEMI-SYNTHETIC DATA
In order to assess the effectiveness of our CG-CT in predicting
treatment–response curves, we need to evaluate prediction per-
formance on counterfactual outcomes (and not only on factual
outcomes). Because counterfactual outcomes are unobservable in
the real-world data, we follow common practice in machine learn-
ing [ 5,33] and make use of semi-synthetic data where “ground-
truth” counterfactual outcomes are known. Formally, we simulate
semi-synthetic data where covariates, treatment, and relationships
between variables are based on the real-world data in order to reflect
our HIV setting. We simulate: (i) semi-synthetic data with simu-
lated outcomes based on real-world HIV data in year 2016 (used
for learning); and (ii) semi-synthetic data with simulated outcomes
based on real-world HIV data in year 2017 (used for evaluation).
Formally, we proceed as follows. First, using real-world HIV
data in year 2016, we compute the parameters in a linear regres-
sion of relative reduction in HIV infection rate (our outcome) on
5293KDD ’24, August 25–29, 2024, Barcelona, Spain Milan Kuzmanovic, Dennis Frauen, Tobias Hatt, & Stefan Feuerriegel
development aid (our treatment) and country characteristics (our
covariates), including interaction terms between development aid
and country characteristics. The estimated parameters (intercept
ˆ𝑐, treatment effect ˆ𝛼, covariates effects ˆ𝛽1,..., ˆ𝛽𝑝, and interaction
effects ˆ𝛾1,..., ˆ𝛾𝑝) are used as ground-truth effects. We then leverage
the respective ground-truth effects to compute the “pseudo-mean”
of an outcome for each country 𝑖=1,...,𝑛 via
𝜇𝑖=ˆ𝑐+ˆ𝛼𝑎𝑖+𝑝∑︁
𝑗=1 ˆ𝛽𝑗𝑥𝑖𝑗+ˆ𝛾𝑗𝑎𝑖𝑗𝑥𝑖𝑗. (8)
We normalize the pseudo-means {𝜇𝑖}𝑛
𝑖=1using a min-max scaler
and thereby obtain {ˆ𝜇𝑖}𝑛
𝑖=1. Afterwards, we induce a non-linearity
by taking the square root, i.e., ˜𝜇𝑖=√︁
ˆ𝜇𝑖. Finally, we simulate the
outcomes via
˜𝑦𝑖=˜𝜇𝑖+𝜖𝑖, (9)
where𝜖𝑖∼𝑁(0,0.012)is Gaussian noise.
Depending on whether we use the semi-synthetic data for learn-
ing or evaluation, we make the following adaptations. For semi-
synthetic data (i) that we use for learning, we simulate 105 data
points (for 105 countries with respective covariates/country char-
acteristics) with factual outcomes that are simulated as above by
using the observed volumes of development aid (treatment). For
semi-synthetic data (ii) that we use for evaluation, we simulate
counterfactual outcomes by using varying volumes of develop-
ment aid on the observed interval [𝐴min,𝐴max]instead of observed
treatment𝑎𝑖in Eq. (8)and without noise 𝜖𝑖. Because there are in-
finitely many counterfactual outcomes that constitute a treatment–
response curve for a continuous treatment, we simulate outcomes
for 64 equally spaced aid volumes on the interval [𝐴min,𝐴max],
which are then used for evaluation (see below). As a result, the
dataset for evaluation counts 64·105data points. In sum, the afore-
mentioned procedure allows us to simulate ground-truth treatment–
response curves that we use to evaluate the performance of our
CG-CT.
The above procedure for obtaining semi-synthetic data is de-
signed to reflect the real-world setting of allocating aid earmarked
to end the HIV epidemic. Importantly, we retain the following main
characteristics of the real-world data: (i) the same covariates; (ii) the
same sample size; (iii) the same treatment interval; and (iv) ground-
truth effects that are based on estimates of treatment effects from
real-world HIV data and thus reflect observed relationships (here,
the linear regression coefficients are used as proxies). We add non-
linearity as we expect that ground-truth effects of aid in real-world
HIV settings are characterized by non-linearities [18].C PSEUDOCODE
CG-CT combines three components – i.e., the balancing autoen-
coder, the counterfactual generator, and the inference model – in
order to provide predictions of treatment–response curves. The
learning algorithm for our CG-CT is given in Algorithm 1. First,
the balancing autoencoder is applied to the observational data
D={(𝑦𝑖,𝑎𝑖,𝑥𝑖)}𝑛
𝑖=1to obtain ˆD={(𝑦𝑖,𝑎𝑖,ˆ𝑧𝑖)}𝑛
𝑖=1. Then, by us-
ing the counterfactual generator with ˆD, we generate additional
𝑚outcome–treatment pairs for each ˆ𝑧𝑖, thus adding 𝑚·𝑛new
data points that represent counterfactual outcomes (i.e., the syn-
thetic twins). This provides the final data that is used for predicting
treatment–response curves, i.e., ˜D=
(𝑦𝑖,𝑎𝑖,ˆ𝑧𝑖)∪({ ˜𝑦𝑖𝑗,˜𝑎𝑖𝑗}𝑚
𝑗=1,ˆ𝑧𝑖)	𝑛
𝑖=1.
In the third step, we use the inference model (i.e., GPS) to predict
treatment–response curves from data ˜D. For computational rea-
sons, Algorithm 1 makes use of batch learning for a given number
of epochs.
Algorithm 1 Learning algorithm for CG-CT
Input: DataD={(𝑦𝑖,𝑎𝑖,𝑥𝑖)}𝑛
𝑖=1; loss functionsL,L𝑥, andL𝑎; hyperparameters 𝜂,𝜃,𝑟,𝑚,
𝛼, and𝑠; network architecture with weights 𝑊𝜙,𝑊𝑔𝑥,𝑊𝑔𝑎
Output: Optimal representation 𝜙∗with weights 𝑊∗
𝜙, and estimated weights of the GPS model
ˆ𝛽GPS,ˆ𝛼GPS, and ˆ𝜎GPS
1:repeat ⊲Component 1: Balancing autoencoder
2: Randomly sample mini-batch of size 𝑏fromD
3: Compute𝑔1=∇𝑊𝜙1
𝑏𝑏Í
𝑖=1L𝑥(𝑔𝑥(𝜙(𝑥𝑖)),𝑥𝑖)
4: Compute𝑔2=∇𝑊𝜙1
𝑏𝑏Í
𝑖=1L𝑎(𝑔𝑎(𝜙(𝑥𝑖)),𝑎𝑖)
5: Compute𝑔3=∇𝑊𝑔𝑥1
𝑏𝑏Í
𝑖=1L𝑥(𝑔𝑥(𝜙(𝑥𝑖)),𝑥𝑖)
6: Compute𝑔4=∇𝑊𝑔𝑎1
𝑏𝑏Í
𝑖=1L𝑎(𝑔𝑎(𝜙(𝑥𝑖)),𝑎𝑖)
7: Update weights𝑊𝜙←𝑊𝜙−𝜂(𝑔1−𝜃𝑔2),
𝑊𝑔𝑥←𝑊𝑔𝑥−𝜂𝑔3,
𝑊𝑔𝑎←𝑊𝑔𝑎−𝜂𝜃𝑔 4
8:until convergence
9:Output the optimal representation 𝜙∗with weights𝑊∗
𝜙
10: Use𝑊∗
𝜙to embed covariates in D, and obtain ˆD={(𝑦𝑖,𝑎𝑖,ˆ𝑧𝑖)}𝑛
𝑖=1with ˆ𝑧𝑖=𝜙∗(𝑥𝑖)
11: for(𝑦𝑖,𝑎𝑖,ˆ𝑧𝑖)∈ ˆDdo ⊲Component 2: Counterfactual generator
12: Randomly sample 𝑚treatment values{˜𝑎𝑖𝑗}𝑚
𝑗=1uniformly from the interval
[𝐴min,𝐴max]
13: for𝑗=1,...,𝑚 do
14: Compute𝑤∗
𝑖𝑗using Eq. (3) for 𝑥=ˆ𝑧𝑖and˜𝑎=˜𝑎𝑖𝑗
15: Compute ˜𝑦𝑖𝑗=𝑌𝑇vec𝑤∗
𝑖𝑗
16: end for
17: return{(˜𝑦𝑖𝑗,˜𝑎𝑖𝑗)}𝑚
𝑗=1
18: end for
19: return counterfactual outcomes
({˜𝑦𝑖𝑗,˜𝑎𝑖𝑗}𝑚
𝑗=1,ˆ𝑧𝑖)	𝑛
𝑖=1
20: Add
({˜𝑦𝑖𝑗,˜𝑎𝑖𝑗}𝑚
𝑗=1,ˆ𝑧𝑖)	𝑛
𝑖=1toˆD, and obtain ˜D=ˆD∪
({˜𝑦𝑖𝑗,˜𝑎𝑖𝑗}𝑚
𝑗=1,ˆ𝑧𝑖)	𝑛
𝑖=1
21: Estimate the GPS model on ˜Das in [16] ⊲Component 3: Inference model
22: Output the estimated coefficients of the GPS model: ˆ𝛽GPS,ˆ𝜎GPS, and ˆ𝛼GPS
5294