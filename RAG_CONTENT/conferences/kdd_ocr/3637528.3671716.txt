Unsupervised Heterogeneous Graph Rewriting Attack via Node
Clustering
Haosen Wang
haosenwang97@163.com
Southeast University;
Zhejiang Lab
ChinaCan Xu
East China Normal University
Shanghai, ChinaChenglong Shi
Southeast University
Nanjing, China
Pengfei Zheng
Zhejiang Lab
Hanzhou, ChinaShiming Zhang
University of Science and Technology
of China
Hefei, ChinaMinhao Cheng
Pennsylvania State University
Philadelphia, PA, USA
Hongyang Chen∗
Zhejiang Lab
Hangzhou, China
hongyang@zhejianglab.com
ABSTRACT
Self-supervised learning (SSL) has become one of the most popular
learning paradigms and has achieved remarkable success in the
graph field. Recently, a series of pre-training studies on heteroge-
neous graphs (HGs) using SSL have been proposed considering the
heterogeneity of real-world graph data. However, verification of the
robustness of heterogeneous graph pre-training is still a research
gap. Most existing researches focus on supervised attacks on graphs,
which are limited to a specific scenario and will not work when
labels are not available. In this paper, we propose a novel unsu-
pervised heterogeneous graph rewriting attack via node clustering
(HGAC) that can effectively attack HG pre-training models without
using labels. Specifically, a heterogeneous edge rewriting strategy
is designed to ensure the rationality and concealment of the attacks.
Then, a tailored heterogeneous graph contrastive learning (HGCL)
is used as a surrogate model. Moreover, we leverage node clustering
results of the clean HGs as the pseudo-labels to guide the optimiza-
tion of structural attacks. Extensive experiments exhibit powerful
attack performances of our HGAC on various downstream tasks
(i.e., node classification, node clustering, metapath prediction, and
visualization) under poisoning attack and evasion attack.
CCS CONCEPTS
•Computing methodologies →Semantic networks ;Unsuper-
vised learning; Network algorithms; Unsupervised learning; •
Networks→Network algorithms.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
KDD ’24, August 25–29, 2024, Barcelona, Spain
©2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 979-8-4007-0490-1/24/08
https://doi.org/10.1145/3637528.3671716KEYWORDS
Heterogeneous Graph Neural Network, Adversarial Attack, Graph
Contrastive Learning
ACM Reference Format:
Haosen Wang, Can Xu, Chenglong Shi, Pengfei Zheng, Shiming Zhang,
Minhao Cheng, and Hongyang Chen. 2024. Unsupervised Heterogeneous
Graph Rewriting Attack via Node Clustering. In Proceedings of the 30th ACM
SIGKDD Conference on Knowledge Discovery and Data Mining (KDD ’24),
August 25–29, 2024, Barcelona, Spain. ACM, New York, NY, USA, 12 pages.
https://doi.org/10.1145/3637528.3671716
1 INTRODUCTION
Heterogeneous graphs (HGs) and heterogeneous information net-
works (HINs) are prevalent in the real world, offering a robust means
to model multiple objects and intricate semantic relationships in-
cluding academic networks [ 5,34], social media networks [ 2,25],
and cybersecurity networks [ 19,33]. Heterogeneous graph neural
networks (HGNNs) have garnered substantial research attention,
demonstrating remarkable success in applications like recommenda-
tion [ 4,38,39], fraud detection [ 19,20], and drug discovery [ 18,24].
While the majority of existing HGNNs operate within the (semi-)
supervised paradigm, relying heavily on labeled data, the process of
annotating high-quality labels is both expensive and labor-intensive.
Recently, self-supervised learning (SSL) on HGs, commonly referred
to as heterogeneous graph pre-training, has emerged as a promising
research avenue. This approach mines supervised signals from the
data itself, alleviating the label dependence issue. Furthermore, the
pre-trained representations obtained from self-supervised HGNNs
prove directly applicable to various downstream tasks, such as node
classification, node clustering, and link prediction. This applica-
bility is achieved with a simple and cost-effective linear model or
machine learning algorithm.
Despite the popularity of graph neural networks, recent works
have pointed out the vulnerability of both supervised homoge-
neous and heterogeneous graph neural network models against
3057
KDD ’24, August 25–29, 2024, Barcelona, Spain Haosen Wang, et al.
Figure 1: Examples of different attack rules on a HG.
adversarial attacks [ 12,47,56]. However, with the growing im-
portance of unsupervised graph pre-training in the field of graph
representation learning, the exploration of adversarial attacks on
graph pre-training techniques is still in its early stages. Zhang et al .
[48] proposes an unsupervised graph attack using contrastive loss
back-propagation. While it demonstrates excellent attack perfor-
mance for graph contrastive learning models, its application to
heterogeneous graph pre-training is not straightforward due to
data heterogeneity.
In this paper, we present the first study on the unsupervised
adversarial attack of heterogeneous graph pre-training. To tackle
this non-trivial task, we face two key challenges.
(1)How to design reasonable and unnoticeable adversarial attacks
for HGs? Compared to homogeneous graphs, the edges of HGs are
more intricate and semantically rich. Unregulated structural attacks
may violate real-world common sense. For example, in Figure 1(a),
unrestrained modifications would lead to glaring irrationalities:
paper P1 having no authors, paper P2 belonging to two different
subjects, and paper P4 not being presented at any conference. Such
noticeable attacks can be easily detected and filtered out by simple
rules. Therefore, adversarial attacks on HGs must be both reason-
able and covert.
(2)How to generate effective adversarial attacks for HGs in an un-
supervised manner? The adversary’s goal is to contaminate the orig-
inal HG data, degrading the performance of various downstream
tasks without relying on labels for estimating attack performance.
While CLGA [ 48] flips edges with the largest gradients of the ad-
jacency matrix based on the gradient ascent principle, producing
structural perturbations, these gradients are coarse-grained and
insufficient for achieving optimal attack effects. It is essential to
mine supervised signals from data to guide the generation of attacks
effectively.
To overcome these challenges, we introduce a novel unsuper-
vised approach Heterogeneous Graph Rewriting Attack via Node
Clustering (HGAC). For the first challenge, we leverage a heteroge-
neous edge rewriting strategy instead of adding/removing edges. As
illustrated in Figure 1, we delete some existing heterogeneous edges
(P1-A2, P2-S1, and P4-C2) and reconnect their corresponding target
nodes (P1, P2, and P4) to other auxiliary nodes (A2, S2, and C2). This
tailored strategy maintains realistic rationality while preserving ba-
sic properties of HG, such as the number of edges and total degrees
of the graphs. For the second challenge, we compute gradients of
all heterogeneous edges via contrastive learning and construct a
set of candidate edges based on gradient ranking. To deal with thelack of supervision signal, we use the clean HG to produce node
clustering labels, treated as pseudo-labels. The adversarial attack’s
optimization objective is then set to minimize the consistency of
node clustering results for the attacked HG with pseudo-labels.
Therefore, these pseudo-labels serve as supervised signals guid-
ing the selection of final disturbed edges from the candidate set
to generate effective attacks. Extensive experiments demonstrate
that HGAC outperforms other attacks with a big margin in four
types of downstream tasks: node classification, node clustering,
metapath prediction, and visualization, where HGAC could achieve
14.93%∼24.50% and 57.71%∼86.88% average performance degrada-
tion in node classification and node clustering tasks respectively
on Aminer dataset.
Our main contributions are summarized as follows:
•To our best knowledge, this is the first attempt to research
the unsupervised adversarial attack for heterogeneous graph pre-
training. Our attack model can infect pre-trained node representa-
tions in an unsupervised manner, thus interfering with the perfor-
mance of various downstream applications.
•We propose a heterogeneous edge rewriting strategy to main-
tain the rationality and stealthiness of attacks and leverage the
node clustering results as pseudo-labels to guide the optimization
of structural modification.
•Extensive experiments on four public datasets show that our
model exhibits strong attack performance in four downstream tasks
under poisoning attack and evasion attack.
2 RELATED WORK
2.1 Heterogeneous Graph Neural Network
Heterogeneous graph neural networks (HGNNs) have become a
research hotspot, aiming at learning node representations on het-
erogeneous graphs [ 5,5,9,22,27,40,45]. For example, HetGNN
[45] leverages BiLSTM to aggregate the features from the same
type of neighbors by sampling with the random walk. RGCN [ 27]
employs type-specific adjacent matrices to model the complex rela-
tionships between different nodes from different categories. HAN
[34] designs node-level and semantic-level attentions to capture
hierarchical semantics hidden in graphs’ heterogeneity. HGT [ 9]
proposes a transformer-based frame tailored for web-scale het-
erogeneous graph data. However, the above methods depend on
high-quality labeled data for training.
2.2 Heterogeneous Graph Pre-training
Due to the great success of self-supervised learning (SSL) on homo-
geneous graph pre-training [ 41,54], gradually emerging research
on heterogeneous graph pre-training. Heterogeneous graph con-
trastive learning (HGCL) is a major paradigm, that learns node
representations by maximizing/minimizing the similarity between
these positive/negative pairs [23, 26, 42, 53].
For example, HDGI [ 26] maximizes the mutual information be-
tween local and global representations obtained from HAN [ 34].
HeCo [ 35] constructs network schema and meta-path views to learn
local and high-order information by cross-view contrast. HeGCL
[29] constructs metapath and outlines views to capture semantic
and structural features. In addition to the contrastive paradigm, the
generative-based SSL paradigm is also promising on heterogeneous
3058Unsupervised Heterogeneous Graph Rewriting Attack via Node Clustering KDD ’24, August 25–29, 2024, Barcelona, Spain
graphs. HGMAE [ 32] learns node representation by reconstructing
metapath-based edges, node attributes, and positional features.
2.3 Adversarial Attack on Graph Neural
Network
With the success of graph neural networks in various fields, graph
adversarial attacks [ 12,30] have attracted increasing research in-
terest from researchers. They aim to degrade the performances of
GNNs by changing the graph structures (e.g., adding edges and
dropping edges) or modifying node features. Adversarial attacks
against GNNs can be categorized as poisoning attacks and evasion
attacks according to the stage of attack that occurs. Poisoning at-
tacks happen during the model training phase. For example, Nettack
[55] perturbs both the node features and edges to pollute graph data.
Metattack [ 56] modifies edges based on meta-gradients. Evasion
attacks add perturbation during the testing stage, which can use
gradient descent [37] and reinforcement learning [21] to optimize
the perturbation of graph structures. In addition to modifying the
nodes and structures in the original graph, some studies [ 3,31,51]
have proposed the graph node injection attack (GIA) focuses on
a more practical scenario. [ 31] first proposes a single node injec-
tion attack. [ 3] points out that the flexibility of GIA damages the
homophily of the graph and designs a Harmonious Adversarial
Objective (HAO) to enforce GIA to retain the homophily of the orig-
inal graph. Consequently, defense models against injection attacks
[43,46,50] have emerged gradually. For example, Yuan et al. [ 43]
propose a denoise masked auto-encoder to remove edges that are
connected with attacked nodes for reconstructing cleaner graph
structures.
Inspired by the success of adversarial attacks on homogeneous
graph neural networks (GNNs), some studies paid attention to the
adversarial robustness of HGNNs. 𝛼Cyber [ 7] proposes a node
injection attack on heterogeneous graphs of the detection of An-
droid malware. RoHe [ 47] summarizes that the vulnerabilities of
HGNN stemmed from the perturbation enlargement effect and
soft attention mechanism, and proposes robust HGNNs. Never-
theless, it generates targeted attacks by using FGSM to attack a
surrogate homogeneous GCN, which ignores the data’s heterogene-
ity. HetePR-BCD [ 15] introduces a constraint mechanism to gen-
erate semantic-aware structural attacks in heterogeneous graphs.
Shang et al. [ 28] propose edge attention-guided transferable attack
methods towards heterogeneous HGNNs.
However, most of the existing attack models belong to the super-
vised paradigm, which rely on labels to guide attacks. They failed to
attack unsupervised GNN models. At present, a few studies focus
on this research gap. Bojchevski et al. [ 1] propose an unsuper-
vised method to attack graph embedding models via random walks.
CLGA [ 48] designs an unsupervised poisoning attack toward graph
contrastive learning methods by flipping the edges with the largest
gradients. Unfortunately, the above methods are tailored for ho-
mogeneous graphs and are not suitable for the complex semantic
relationships of heterogeneous graphs.
3 PRELIMINARY
Before introducing our framework, we first introduce the definition
of heterogeneous graph and graph adversarial attacks.Definition 1. Heterogeneous Graph . A heterogeneous graph
(HG) is defined as G=(V,E,A,R), whereVandEare sets of
nodes and edges.Gassociated with a node type mapping function
𝜙:V→A and an edge type mapping function 𝜑:E→R , where
AandRrepresent sets of object and link types, and |A+R| >2.
Definition 2. Metapath . Metapath is a path that connects dif-
ferent types of nodes with distinct types of edges in the form of
𝑇1𝑟1−→𝑇2𝑟2−→...𝑟𝑙−→𝑇𝑙+1(abbreviated as 𝑇1𝑇2···𝑇𝑙+1), where
𝑇𝑖∈A and𝑟𝑖∈R.
Definition 3. Self-supervised learning on Heterogeneous
Graphs . Given a heterogeneous graph G, the goal is to train a
self-supervised heterogeneous graph model 𝑓:V→R𝑑without
utilizing any labels. 𝑓projects nodes into node representations
𝐻∈R|V|×𝑑, which are expected to contain both structural and
semantic information from Gand are general-purpose for various
downstream tasks, such as node classification and node clustering.
In this paper, we only focus on nodes of the target type (e.g., paper
and movie).
Threat model. Given a self-supervised heterogeneous graph
model𝑓and an HGG, the graph adversarial attacker asks to slightly
modify the original HG G=(V,E,A,R)intoeG=(eV,eE,A,R).
The modified HG eGis used to pollute 𝑓, resulting in degraded
performance for downstream tasks (e.g., the accuracy of node clas-
sification decreases). In this paper, we only focus on structure-based
adversarial attacks because not all HGs have node features.
4 METHODOLOGY
In this section, we propose HGAC, a novel unsupervised adversarial
attack for HGs, and its overall architecture is depicted in Figure 2.
First, we design a heterogeneous graph contrastive learning (HGCL)
as the surrogate model. Then, we utilize the gradients obtained
from surrogate HGCL to construct the candidate sets of structural
perturbations and learn the final attacks from them. Finally, we
leverage the negative cross-entropy between node clustering results
of clean and attacked HGs as the training objective.
4.1 Surrogate Heterogeneous Graph Contrast
Learning
Heterogeneous graph contrastive learning (HGCL) is the most com-
mon paradigm of heterogeneous graph pre-training. Thus, we de-
sign a HGCL as the surrogate model. The heterogeneous graph
G=(V,E,A,R)can be rewritten as G=(𝐴𝑟1,𝐴𝑟2,···,𝐴𝑟|R|;𝑋),
where𝐴𝑟1,𝐴𝑟2,···,𝐴𝑟|R|denotes the adjacency matrices of differ-
ent edge types, 𝑋denotes the feature matrix of the target node.
Take Figure 2(a) as an example, there are three adjacency matrices
𝐴𝑟1∈R𝑁𝑃×𝑁𝐴,𝐴𝑟2∈R𝑁𝑃×𝑁𝑆, and𝐴𝑟3∈R𝑁𝑃×𝑁𝐶corresponding
to three types of edges (P-A, P-S, and P-C), where 𝑁𝑃,𝑁𝐴,𝑁𝑆, and
𝑁𝐶denote the number of four types of nodes, respectively.
As shown in Figure 2(a), our surrogate HGCL consists of three
main modules: data augmentation, the shared encoder for HG, and
contrastive loss.
Given a HGG=(𝐴𝑟1,𝐴𝑟2,···,𝐴𝑟|R|;𝑋), we produce two aug-
mented viewsG(1)=(𝐴(1)
𝑟1,𝐴(1)
𝑟2,···,𝐴(1)
𝑟|R|;𝑋)andG(2)=(𝐴(2)
𝑟1,
𝐴(2)
𝑟2,···,𝐴(2)
𝑟|R|;𝑋)by stochastic dropping of heterogeneous edges.
The augmentation strategies about node features are discarded
3059KDD ’24, August 25–29, 2024, Barcelona, Spain Haosen Wang, et al.
Figure 2: The overall framework of our proposed HGAC.
because they will interfere with the reliability of the gradients of
heterogeneous edges.
Then, following previous works [ 13,35,42], we leverage metapath-
specific GCN and semantic-level attention as the encoder of HGs.
The adjacency matrices {𝐴P1,𝐴P2,···,𝐴P𝑚}of multiple metap-
aths can be obtained by the product of the adjacency matrices of
corresponding heterogeneous edges, where 𝑚represents the num-
ber of metapaths. Take the metapath PAP (paper-author-paper)
as an example, 𝐴𝑃𝐴𝑃=𝐴𝑟1·𝐴⊤𝑟1,𝑟1=P-A, and𝐴𝑟1∈R𝑁𝑃×𝑁𝐴.
Given a node 𝑖and a metapathP𝑛∈{P 1,P2,···P𝑚}, the learn-
ing process of node representation is defined as: ℎP𝑛
𝑖=1
𝑑𝑖+1𝑥𝑖+
Í
𝑗∈NP𝑛
𝑖1√︃
(𝑑𝑖+1)(𝑑𝑗+1)𝑥𝑗, whereNP𝑛
𝑖denotes the neighbor set
of node𝑖based on metapath P𝑛,𝑑𝑖and𝑥𝑖are the degree and
features of node 𝑖, respectively. After obtaining representations
for node𝑖from different metapaths {P1,P2,···P𝑚}, we leverage
the semantic-level attention to integrate them: ℎ𝑖=Í𝑀
𝑛=1𝛽𝑛·
ℎP𝑛
𝑖, 𝛽𝑛=exp(𝛼𝑛)Í𝑀
𝑖=1exp(𝛼𝑖),𝛼𝑛=1
|𝑉|Í
𝑖∈𝑉q⊤·tanh
WℎP𝑛
𝑖+b
,
where W∈R𝑑×𝑑andb∈R𝑑×1are learnable parameters, qis the
semantic-level attention vector, 𝛽𝑛denotes the important weight of
metapathP𝑛,𝑉denotes the set of target nodes, and ℎ𝑖is the final
node representation of node 𝑖.Finally, contrastive loss is used as the optimization goal that
enforces the representations of the positive node pairs in different
views to be close and the negative node pairs to be distant. Refer to
the recent study [35], our contrastive loss is defined as follows:
L𝑐𝑜=1
|𝑉|∑︁
𝑖∈𝑉−logÍ
𝑗∈P𝑖exp
sim
𝑧(1)
𝑖,𝑧(2)
𝑗
/𝜏
Í
𝑘∈{P𝑖∪N𝑖}exp
sim
𝑧(1)
𝑖,𝑧(2)
𝑘
/𝜏,(1)
where sim(·,·)is the cosine similarity function, 𝜏represents the
temperature coefficient, P𝑖andN𝑖denote the positive samples and
negative samples of node 𝑖, respectively. 𝑧(1)
𝑖=𝑀𝐿𝑃(ℎ(1)
𝑖)and
𝑧(2)
𝑖=𝑀𝐿𝑃(ℎ(2)
𝑖), where𝑀𝐿𝑃(·)is a two-layer fully-connected
network with ELU non-linear function that projects the node rep-
resentations into another latent space. To capture local context
characteristics, the positive sample selection strategy is applied.
Concretely, two nodes are positive sample pairs if many metapaths
exist between them. This is not the focus of this paper, implemen-
tation details can be found in [35].
4.2 Candidate Edge Perturbations based on
Gradient
To attack the pre-trained representations in an unsupervised man-
ner, we adapt gradient ascent to maximize of contrastive loss of
3060Unsupervised Heterogeneous Graph Rewriting Attack via Node Clustering KDD ’24, August 25–29, 2024, Barcelona, Spain
the surrogate model. Specifically, the loss will be increased both
by deleting existing edges with minimum gradients and by adding
non-existing edges with maximum gradients. Referring to previous
research [ 10,16,48], we can calculate the gradients 𝐺𝐴𝑟of the
adjacent matrix for each relation 𝑟∈Ras follows:
𝐺𝐴𝑟=Δ(1)
𝑟+Δ(2)
𝑟, (2)
Δ(1)
𝑟=𝜕L𝑐𝑜
𝜕𝐴(1)
𝑟=𝜕L𝑐𝑜
𝜕𝐻(1)𝜕𝑓
𝐴(1)
1,𝐴(1)
2,···,𝐴(1)
𝑚;𝑋
𝜕𝐴(1)
𝑟, (3)
Δ(2)
𝑟=𝜕L𝑐𝑜
𝜕𝐴(2)
𝑟=𝜕L𝑐𝑜
𝜕𝐻(2)𝜕𝑓
𝐴(2)
1,𝐴(2)
2,···,𝐴(2)
𝑚;𝑋
𝜕𝐴(1)
𝑟, (4)
where𝐻(1)and𝐻(2)are the representation matrices of target nodes
from two augmented views, respectively. Then, we can acquire the
gradients (i.e., ˆ𝐺𝐴𝑟and ˇ𝐺𝐴𝑟) of existent edges and inexistent edges
in𝐴𝑟byˆ𝐺𝐴𝑟=𝐺𝐴𝑟⊙𝐴𝑟and ˇ𝐺𝐴𝑟=𝐺𝐴𝑟⊙(1−𝐴𝑟), where⊙
denotes the element-wise product.
Although the gradients of the edges reflect their importance
to some extent, the attack model using only gradient is prone to
the problem of local optimization. Therefore, to make use of the
gradient information and facilitate further processing, we try to
construct candidate sets of deleted edges and candidate sets of
added edges based on the gradients.
Given the attack ratio 𝛿, there are𝛿∗|E𝑟|edges that should
be rewritten in each adjacency matrix 𝐴𝑟, whereE𝑟denotes the
set of edges of type 𝑟. As shown in Figure 2(b), we first sort edges
in ascending order based on the gradient value in ˆ𝐺𝐴𝑟and add
top-ranked edges to 𝑆𝑑𝑒𝑙𝑟. The size of the corresponding candidate
set𝑆𝑑𝑒𝑙𝑟of deleted edges is 𝛿∗|E𝑟|∗𝐾𝑑𝑒𝑙, where𝐾𝑑𝑒𝑙is a hyper-
parameter. For each deleted edge, we will reconnect another auxil-
iary node to its target node. Analogously, for each target node 𝑖that
needs to be reconnected, we sort inexistent edges in descending
order based on the gradient value in the 𝑖-th row of ˇ𝐺𝐴𝑟and add top-
ranked inexistent edges to the candidate set 𝑆𝑎𝑑𝑑
𝑟,𝑖of added edges
for node𝑖. The size of 𝑆𝑎𝑑𝑑
𝑟,𝑖is𝐾𝑎𝑑𝑑which represents the number
of candidate neighbors for node 𝑖and is also a hyper-parameter.
4.3 Learnable Heterogeneous Edge Rewriting
via Node Clustering
In this subsection, we attempt to learn the optimal structural attack
from candidate sets of edge perturbations.
Edge deleting learner. Given the edge relation 𝑟and candidate
set𝑆𝑑𝑒𝑙𝑟of deleted edges, we employ multi-layer perceptrons (MLP)
to calculate the probability 𝑤𝑟,𝑑𝑒𝑙
𝑖,𝑗that each edge 𝑒𝑟
𝑖,𝑗∈𝑆𝑑𝑒𝑙𝑟will be
deleted:
𝑤𝑟,𝑑𝑒𝑙
𝑖,𝑗=𝑀𝐿𝑃𝑑𝑒𝑙
𝑟(ℎ𝑖||ℎ𝑟
𝑗), (5)
whereℎ𝑖is the pre-trained representation of target node 𝑖obtained
from the surrogate model, ℎ𝑟
𝑗denotes the representation of auxiliary
node𝑗,||denotes the concatenation operation, 𝑀𝐿𝑃𝑑𝑒𝑙𝑟(·)contains
an input layer, a nonlinear activation function ReLU, and an output
layer of dimension 1. Our surrogate model only outputs represen-
tations of target nodes, so we produce representations of auxiliary
nodes by aggregating heterogeneous neighbor nodes, which canbe formulated as:
ℎ𝑟
𝑗=∑︁
𝑣∈N𝑟
𝑗𝜎(𝑊𝑟·ℎ𝑣+𝑏𝑟), (6)
where𝑊𝑟∈R𝑑×𝑑and𝑏𝑟∈R𝑑×1are learnable parameters, N𝑟
𝑗
denotes the first-order neighbors of node 𝑗connected by relation 𝑟,
and𝜎denotes the ReLU function.
Finally, we sort candidate edges 𝑒𝑟
𝑖,𝑗∈𝑆𝑑𝑒𝑙𝑟in descending order
based on𝑤𝑟,𝑑𝑒𝑙
𝑖,𝑗and select Top 𝛿∗|E𝑟|edges as the final deleted
edges.
Edge adding learner. After determining which edges have been
deleted, we need to reconnect the other auxiliary nodes to their
corresponding target nodes. Given a deleted edge 𝑒𝑖,𝑗and set𝑆𝑎𝑑𝑑
𝑟,𝑖
of candidate added edges of target node 𝑖, we again utilize MLP
and heterogeneous neighbor aggregation to learn the probability
that each candidate added edge 𝑒𝑟
𝑖,𝑘∈𝑆𝑎𝑑𝑑
𝑟,𝑖is selected:𝑤𝑟,𝑎𝑑𝑑
𝑖,𝑘=
𝑀𝐿𝑃𝑎𝑑𝑑𝑟(ℎ𝑖||ℎ𝑟
𝑘)andℎ𝑟
𝑘=Í
𝑣∈N𝑟
𝑘𝜎(𝑊𝑟·ℎ𝑣+𝑏𝑟). Then, we adopt
the Gumbel-Softmax [ 11] to sample a candidate edge from the set
𝑆𝑎𝑑𝑑
𝑟,𝑖according to probabilities as the reconnected edge for node 𝑖:
g𝑟
𝑖=GumbelSoftmax(𝑤𝑟,𝑎𝑑𝑑
𝑖), (7)
where𝑤𝑟,𝑎𝑑𝑑
𝑖∈R𝐾𝑎𝑑𝑑×1denotes the probability vector and its
𝑘-th column is 𝑤𝑟,𝑎𝑑𝑑
𝑖,𝑘.g𝑟
𝑖is a one-hot vector that is differentiable
because of the reparameterization trick. The edge 𝑒𝑟
𝑖,𝑘will be added
if the element of 𝑘-th column of g𝑟
𝑖is 1.
Optimization objective. We innovatively leverage the node clus-
tering results to measure the performances of attacks. Intuitively,
the effective attack will lead to a large distribution shift of node
clusters. Based on this intuition, we optimize the structural attacks
by minimizing the consistency of the node clustering results of
the attacked HG eGand the clean HGG. The process is shown in
Figure 2(c). Specifically, we utilize the MLP with softmax function
to produce the node cluster assignment matrices CandeCofGand
eG, respectively. They are formulated as follows:
C=𝑠𝑜𝑓𝑡𝑚𝑎𝑥(𝑀𝐿𝑃𝑐𝑙𝑢𝑠𝑡𝑒𝑟(𝐻)),eC=𝑠𝑜𝑓𝑡𝑚𝑎𝑥(𝑀𝐿𝑃𝑐𝑙𝑢𝑠𝑡𝑒𝑟(e𝐻)),
(8)
where C∈R|𝑉|×𝜆,eC∈R|𝑉|×𝜆, and𝜆denotes the number of
clusters.𝐻ande𝐻are node representation matrices of GandeG,
respectively, which are both generated by the encoder in the surro-
gate model. The encoder is already pre-trained and its parameters
are frozen. The optimization objective is computed as the negative
cross-entropy between the two node cluster assignment matrices:
L𝑎𝑡𝑡𝑎𝑐𝑘 =∑︁
𝑖∈𝑉𝜆∑︁
𝑐=1C𝑐
𝑖logeC𝑐
𝑖, (9)
where C𝑐
𝑖denotes the weight that node 𝑖belongs to cluster 𝑐. After
the optimization is complete, we can get the final attacked HG. It
can be used to attack heterogeneous graph pre-training models
following the process in Figure 2(d), thereby degrading the perfor-
mances of various downstream applications.
3061KDD ’24, August 25–29, 2024, Barcelona, Spain Haosen Wang, et al.
5 EXPERIMENTS
5.1 Experimental Setup
Datasets. We utilize four benchmark datasets to evaluate all mod-
els, including ACM [ 49], Aminer [ 8], Freebase [ 17], and IMDB [ 5].
Detailed statistics of these datasets are summarized in Appendix B.
Baselines. We compare HGAC with the unsupervised attack CLGA
[48] and a random attack strategy by randomly rewriting hetero-
geneous edges. To evaluate the attack performances, we employ
three supervised HGNNs: HAN [ 34], RGCN [ 27], HGT [ 9]. More-
over, there are six unsupervised HGNNs: DMGI [ 23], HDMI [ 13],
HDGI [ 26], HGCML [ 36], HGMAE [ 32], and HeCo [ 35]. Among
unsupervised HGNN methods, DMGI, HDMI, HDGI, HGCML, and
HeCo are contrastive models, HGMAE is a generative model.
Implementation Details. For our proposed surrogate model, we
employ a 1-layer GCN to encode each metapath-based sub-graph
and train the model using the Adam [ 14] optimizer. We leverage grid
search to tune the learning rate from 1e-3 to 1e-5, the temperature
coefficient𝜏from 0.5 to 0.8 with intervals of 0.1, the augmentation
ratio from 0.3 to 0.8 with intervals of 0.1, dropout on semantic-
level attention from 0.0 to 0.5 with intervals of 0.05, and the node
dimension from {64, 128, 256, 512}. For the structural perturbation
optimization, we tune the number of clusters 𝜆and𝐾𝑑𝑒𝑙from {5,
10,15, 20, 25, 30}, 𝐾𝑎𝑑𝑑from 1 to 5 with intervals of 1, and the
learning rate from 1e-3 to 1e-5. The default attack ratio 𝛿is 0.1. For
all baselines, we further tune their hyper-parameters based on the
open code and default settings to obtain optimal performance. All
the experiments are conducted on a single Tesla V100 GPU with
80G memory. We provide the cost of HGAC in Appendix B, the
algorithmic flowchart of HGAC in Appendix C, and the table of
symbol interpretation in Appendix D. Our code is available at1.
5.2 Experimental Result
Node Classification. For node representations obtained from un-
supervised HGNNs, we leverage a linear classifier for fine-tuning.
Following previous studies [ 32,35,42], we select 20, 40, and 60
labeled nodes per class as the training set, and choose 1000 nodes
each for validation and test sets. The evaluation metric is Macro-F1.
As Table 1 illustrates, our proposed HGAC achieves the best
attack performances in both the poisoning and the evasive attack
modes. For instance, HGAC’s poisoning attack resulted in an av-
erage performance degradation of 16.30% ∼27.49% on the Freebase
dataset. All supervised and unsupervised HGNN models are signifi-
cantly degraded by HGAC, demonstrating the great transferability
of our model. Moreover, CLGA performs poorly and is sometimes
inferior to the random strategy. We regard the underlying reason
for this result as that it is difficult to generate effective attacks
against HGs using only gradient information.
Node Clustering. In this task, we utilize the K-means algorithm
for clustering and employ normalized mutual information (NMI)
and adjusted rand index (ARI) as the evaluation metrics.
In Table 2, we can observe that HGAC shows the strongest attack
performances across all models and datasets. For instance, under
HGAC’s poisoning attack, the ARI performance of the HDMI on
the ACM, AMiner, Freebase, and IMDB datasets decreased by 46.6%,
1https://github.com/senllh/HGAC/tree/main46.4%, 99.1%, and 41.3%, respectively. This proves the effectiveness
of our attack model in disrupting node clustering tasks.
Metapath prediction. Since most existing pre-trained models
for heterogeneous graphs only generate representations for target
nodes, they are not able to directly perform the link prediction
task. To address this gap, we introduce a metapath prediction task
designed to ascertain whether two target nodes share common
neighbors (auxiliary nodes), effectively serving as a nuanced form
of second-order link prediction. Technically, we utilize the 2-layer
MLP with Softmax as the classifier, which is trained by the cross-
entropy function and negative sampling. The dataset is divided into
training, validation, and testing sets with ratios of 0.2, 0.4, and 0.4,
respectively. The evaluation metric is the area under curve (AUC).
Reported results are the average of running 10 runs.
Table 3 demonstrates that HGAC substantially surpasses other
attack methodologies in performance. For instance, within the ACM
dataset, neither random nor CLGA strategies significantly affect
performance. In contrast, our HGAC method induces a performance
decline of 6.76% and 11.15% under poisoning and evasive attacks,
respectively.
Visualization. We visualize the learned representations of tar-
get nodes by five HG pre-training models under different attacks,
showing how attacks affect the node representation distribution.
Owing to space limitations, the visualization is confined to the ACM
dataset. We employ the poisoning attack mode and utilize t-SNE
for dimensionality reduction.
Figure 5 reveals that the node representation distributions under
random and CLGA attacks do not significantly deviate from the
distributions of clean node representations. In contrast, the HGAC
attack leads to considerable overlap among different classes of
nodes, making them challenging to distinguish. Furthermore, in
the case of the HDMI and HeCo models, the distinct dense clusters
of nodes from the same class are fragmented into multiple chunks.
These findings further verify the efficacy of the HGAC attack on
unsupervised HG pre-training models.
Ablation study. To verify the importance of key modules of HGAC,
we introduce two variants for HGAC: w/o Candidate, which removes
the candidate sets of deleted edges and added edges and instead
learns the final structural perturbation from entire original struc-
tures; w/o Cluster, which removes the optimization objective based
on clustering and instead uses only values of gradients to determine
structural attacks. We report the node classification results with 60
labeled nodes per class for ACM and IMDB datasets in Table 4. The
experimental results show that HGAC significantly outperforms
two variants, demonstrating the importance of two key modules.
Specifically, the candidate edge sets informed by gradients facilitate
the identification of important structures and substantially ease the
training difficulty of the model. Moreover, it is difficult to achieve
effective attacks relying only on the gradients of adjacency matri-
ces, and our tailored guidance signals derived from node clustering
are essential.
Impact of the attack ratio. We select three models and observe
their performances on the node classification task across various
attack ratios, 𝛿, and report their Macro-F1 scores with 20 labeled
nodes per class for the ACM and IMDB datasets in Figure 4. The
results demonstrate that HGAC consistently and significantly out-
performs the baselines, notably at lower attack ratios.
3062Unsupervised Heterogeneous Graph Rewriting Attack via Node Clustering KDD ’24, August 25–29, 2024, Barcelona, Spain
Table 1: Node classification performance under different attacks. The best results of poisoning and evasive attacks are highlighted
inredandblue, respectively. " ↓(%)" represents the percentage of average performance degradations compared to clean data.
Dataset Attack model Attack Type Split HAN HGT RGCN DMGI HDMI HDGI HGCML HGMAE HeCo ↓(%)
ACMClean -20 86.57±2.3 75.06±1.7 76.21±1.9 91.17±0.4 89.63±0.6 89.32±0.9 89.52±0.8 90.66±0.6 88.56±0.8 -
40 88.91±1.2 75.49±1.4 76.91±1.4 90.81±0.3 89.03±0.4 89.30±1.2 89.31±0.5 90.15±0.7 87.61±0.5 -
60 88.87±0.8 77.94±2.2 78.29±2.6 91.08±0.5 90.59±0.7 90.19±0.7 90.44±0.6 91.59±0.5 89.04±0.5 -
RandomPoisoning20 86.10±1.4 71.74±1.5 69.17±1.5 87.86±0.3 89.37±0.5 88.06±0.7 88.71±1.5 89.53±1.4 86.46±0.6 2.54
40 88.34±2.3 67.40±2.4 71.58±2.7 87.02±0.3 87.64±0.4 87.60±0.6 87.90±1.7 90.02±1.5 83.22±0.6 3.45
60 88.51±2.1 71.63±1.3 73.38±2.2 87.40±0.3 89.82±0.4 89.30±0.6 89.42±1.2 89.91±1.7 87.09±0.5 2.74
Evasive20 80.49±0.7 68.29±1.7 71.62±2.0 90.89±0.4 86.84±0.3 85.95±0.8 87.16±1.8 83.96±1.4 84.67±0.5 4.74
40 80.91±1.5 68.85±0.9 71.35±2.7 90.83±0.3 84.90±0.2 83.24±0.6 85.83±2.3 83.90±1.8 83.32±0.4 5.71
60 83.64±1.1 69.36±1.4 74.60±1.4 90.48±0.5 87.61±0.3 85.34±0.4 87.65±1.6 85.08±1.1 85.86±0.3 4.87
CLGAPoisoning20 83.52±1.2 73.91±1.9 69.17±2.9 90.32±0.4 89.27±0.4 87.15±0.5 86.51±1.3 87.95±1.3 86.18±0.7 2.93
40 85.14±1.9 72.70±0.8 73.39±1.3 90.68±0.2 90.22±0.4 88.11±0.3 86.07±1.4 87.54±1.3 86.36±0.7 2.23
60 83.97±1.7 77.73±1.6 76.42±1.9 90.14±0.2 90.13±0.3 88.79±0.4 88.13±0.9 88.82±0.9 88.05±0.5 2.01
Evasive20 81.15±0.5 74.91±2.3 69.33±2.1 90.43±0.5 89.05±0.3 86.85±0.6 87.49±1.6 86.67±1.5 86.40±0.5 3.14
40 83.97±0.9 75.14±1.4 71.36±2.5 90.46±0.4 89.52±0.4 86.30±0.6 87.10±1.5 87.00±1.6 85.54±0.6 2.72
60 80.93±1.0 77.82±1.9 77.11±1.8 90.29±0.3 90.57±0.3 87.16±0.4 89.28±1.2 87.86±1.7 87.18±0.3 2.52
HGACPoisoning20 76.18±0.6 70.93±2.0 65.98±2.4 78.56±0.8 76.23±0.4 82.48±0.5 80.41±1.4 84.91±1.5 76.02±0.8 10.94
40 84.48±0.9 62.97±1.7 68.44±2.1 80.21±0.6 75.07±1.3 84.70±1.1 80.85±1.7 84.18±1.1 76.91±0.6 10.25
60 80.72±0.8 66.05±1.7 71.58±1.7 81.03±0.5 76.33±1.1 82.63±0.9 82.43±0.8 85.86±1.0 73.99±0.7 11.09
Evasive20 69.51±0.7 67.38±1.0 63.77±2.5 77.80±0.6 75.58±0.6 75.32±0.4 77.15±1.8 72.20±0.7 76.68±0.5 15.62
40 74.93±0.4 64.29±2.4 65.62±1.8 77.53±0.7 75.74±0.5 75.51±0.2 78.06±1.9 73.74±0.9 77.60±0.3 14.73
60 67.10±0.6 68.15±1.5 68.06±1.9 78.45±0.4 75.42±0.4 74.29±0.3 80.39±1.0 74.37±1.0 78.28±0.3 15.67
AminerClean -20 55.49±3.5 58.90±3.1 51.73±3.5 59.25±2.3 63.11±1.0 59.24±0.9 65.42±1.4 72.26±0.7 70.66±1.2 -
40 60.73±2.4 63.81±2.7 55.42±2.2 62.41±2.2 67.34±1.1 64.30±0.8 68.85±1.2 76.46±1.1 72.69±0.8 -
60 61.48±1.7 64.25±2.3 55.07±1.6 61.47±2.6 66.52±0.7 61.42±1.0 68.69±1.2 75.09±0.6 73.88±1.0 -
RandomPoisoning20 52.13±3.9 52.61±3.7 47.64±3.4 56.77±2.6 59.03±1.4 56.20±1.7 63.54±1.7 65.44±0.9 60.50±1.4 7.59
40 55.90±2.8 53.07±3.0 51.59±2.5 60.19±2.4 66.65±1.2 59.39±1.1 65.67±1.3 67.11±1.5 68.73±1.2 7.32
60 56.18±2.5 54.53±2.8 52.35±2.0 59.84±2.7 64.02±1.0 59.88±1.3 65.25±1.1 69.37±0.8 67.64±0.9 6.37
Evasive20 53.38±3.2 53.77±3.5 46.28±2.6 55.46±2.9 58.00±0.9 54.12±1.2 64.11±0.9 62.38±0.8 68.19±1.1 7.64
40 58.24±2.1 55.39±3.3 50.11±2.4 59.62±2.1 65.91±1.5 59.55±1.4 67.62±1.5 67.45±1.5 72.37±0.7 8.14
60 58.86±1.4 55.87±2.0 51.84±1.5 57.91±2.5 63.43±0.6 57.64±0.9 67.30±1.3 68.25±0.6 74.60±0.8 5.61
CLGAPoisoning20 53.25±3.6 50.42±3.8 47.20±3.2 55.17±3.1 61.27±1.3 57.44±1.3 64.92±1.4 71.74±1.0 63.12±1.5 5.85
40 57.41±2.9 56.21±2.6 52.46±2.4 58.53±2.9 66.78±0.8 62.58±1.2 68.43±1.2 74.87±1.4 69.58±0.9 4.11
60 58.06±1.7 55.40±2.2 52.81±2.0 58.05±2.9 65.93±0.9 59.67±1.5 68.15±1.0 76.02±1.0 70.63±1.4 3.75
Evasive20 54.36±3.0 55.64±3.2 49.29±2.7 55.87±2.1 60.71±1.6 56.25±1.1 64.58±1.2 70.60±1.1 68.55±1.2 3.81
40 56.72±2.1 57.71±2.2 54.15±1.9 61.22±2.6 65.36±1.4 60.89±1.0 66.86±1.2 75.31±1.6 72.31±1.0 3.29
60 57.89±1.5 56.67±2.4 53.37±1.6 60.32±2.4 65.07±1.2 58.70±1.1 67.01±1.0 76.43±0.5 73.04±1.2 3.00
HGACPoisoning20 50.44±4.3 45.32±3.5 44.63±3.2 44.29±2.7 50.83±0.9 29.91±0.6 52.31±1.5 58.09±0.8 52.56±1.0 24.50
40 52.70±2.8 49.45±2.1 48.25±2.4 46.60±2.6 59.81±1.2 34.81±1.2 55.74±1.4 65.46±1.0 58.17±1.4 21.27
60 54.55±1.9 50.57±2.3 47.55±2.3 49.44±2.5 60.33±1.6 33.84±0.8 56.17±1.3 63.72±0.7 61.37±1.3 19.64
Evasive20 50.92±3.7 47.28±2.6 45.60±2.6 49.71±2.7 53.11±0.7 42.53±0.9 51.60±1.4 57.16±0.6 62.85±0.7 18.36
40 51.38±2.1 52.88±2.0 47.28±2.0 51.48±3.2 60.93±0.9 50.37±0.7 57.93±1.2 62.97±0.9 68.86±0.9 14.93
60 53.03±1.4 52.15±1.9 46.94±1.9 50.97±2.8 58.61±1.3 48.20±1.3 58.41±1.2 62.47±0.5 69.43±1.2 15.16
FreebaseClean -20 53.59±3.1 54.82±2.4 58.27±2.2 55.81±1.0 55.01±0.6 54.36±0.4 56.41±0.6 61.05±0.5 56.70±0.5 -
40 58.11±2.8 56.33±3.0 57.96±2.1 51.47±1.9 54.10±0.9 58.89±0.6 54.59±0.5 63.71±0.7 61.26±0.9 -
60 56.57±2.5 55.42±2.7 57.93±1.8 53.24±1.1 51.26±0.6 53.77±0.2 55.25±0.5 62.53±0.5 56.50±0.4 -
RandomPoisoning20 52.41±3.5 50.51±2.6 55.04±2.5 47.29±1.4 53.02±1.8 45.61±0.8 49.74±0.6 53.46±0.7 54.76±1.1 9.50
40 56.20±2.4 53.28±3.5 55.26±2.7 45.66±2.2 52.72±0.4 48.75±0.9 48.23±0.7 58.42±1.0 58.60±2.3 8.16
60 55.58±2.8 55.77±2.7 55.34±2.0 48.83±2.0 50.87±0.3 47.60±1.1 53.19±0.4 56.92±0.8 58.92±1.5 4.14
Evasive20 50.88±3.3 53.98±2.9 54.95±2.1 52.35±1.5 53.53±0.6 50.16±0.5 53.44±0.5 55.37±0.6 52.86±0.5 5.70
40 54.15±3.0 54.52±3.2 52.49±2.3 48.72±2.6 54.65±0.7 55.04±0.8 53.68±0.7 61.05±0.6 61.16±0.6 3.71
60 53.29±2.5 54.15±2.1 52.20±2.1 52.06±2.1 50.86±0.2 49.79±0.3 54.32±0.5 60.21±0.7 58.80±0.4 3.03
CLGAPoisoning20 53.07±2.6 32.25±2.0 54.52±2.4 49.77±1.3 53.02±1.8 45.73±0.8 51.40±0.4 53.40±0.4 55.14±0.7 12.64
40 57.83±2.7 36.94±2.4 56.76±2.8 48.11±1.6 52.70±0.3 48.88±0.6 50.97±0.6 58.25±0.6 59.69±1.6 10.04
60 55.27±2.1 48.33±2.7 53.98±2.7 51.56±1.5 50.87±0.3 47.81±0.9 51.77±0.5 57.33±0.6 55.22±0.9 6.51
Evasive20 50.70±2.8 34.44±2.6 57.27±2.6 52.12±1.0 56.35±0.4 54.52±0.7 54.84±0.6 52.92±0.8 54.74±0.8 7.78
40 53.58±2.5 35.26±2.5 55.33±2.6 49.80±1.7 54.67±0.3 55.20±1.8 54.39±0.3 57.46±1.1 58.82±1.5 8.16
60 52.92±2.3 49.41±2.5 52.84±2.2 52.37±1.4 50.99±0.5 51.80±1.4 53.95±0.5 58.96±0.9 54.50±1.0 4.73
HGACPoisoning20 50.17±3.0 21.71±3.2 52.92±2.4 39.57±1.2 37.09±0.8 34.16±1.3 41.44±0.7 50.74±0.8 50.42±0.7 27.49
40 52.79±2.7 26.24±2.6 54.64±2.1 38.62±1.7 40.71±1.1 43.82±0.8 42.16±0.5 55.16±0.9 52.73±0.5 22.74
60 51.04±2.1 41.30±2.1 52.33±1.7 41.49±1.3 43.74±0.9 42.11±0.6 45.32±0.6 55.80±0.9 51.12±0.5 16.30
Evasive20 49.56±2.6 24.96±2.5 53.53±2.3 42.28±1.4 49.22±0.6 48.54±0.5 44.48±0.5 49.02±0.7 50.34±0.4 20.02
40 50.37±2.0 26.29±2.8 52.75±2.1 42.75±1.8 51.05±0.7 52.12±0.2 48.21±0.8 54.85±0.8 59.63±0.2 15.39
60 50.98±2.4 44.49±2.6 52.79±1.8 44.83±1.6 48.39±0.6 47.83±0.3 48.74±0.8 55.78±0.7 55.89±0.4 10.56
IMDBClean -20 40.32±1.3 40.89±2.3 43.07±2.1 41.66±0.7 44.96±0.5 44.60±0.4 43.81±0.7 44.85±0.8 47.76±0.6 -
40 42.64±1.5 44.23±1.8 44.57±2.5 44.09±0.6 44.77±0.4 41.23±0.3 45.26±0.6 46.23±1.2 46.35±0.5 -
60 46.10±1.4 43.61±1.4 43.74±2.0 47.15±0.3 48.71±0.4 46.84±0.4 47.63±0.6 49.42±0.8 49.90±0.7 -
RandomPoisoning20 36.85±1.7 36.79±2.8 38.63±2.3 38.50±1.6 44.96±1.4 44.06±1.6 43.30±0.9 38.76±1.3 43.04±1.0 6.70
40 39.84±1.8 39.14±2.0 40.23±2.5 39.85±1.8 44.77±1.6 42.51±1.4 44.69±1.3 39.38±0.7 45.73±0.9 5.73
60 45.42±1.8 38.11±2.1 40.75±2.1 44.82±1.3 48.71±1.2 45.45±1.7 47.22±0.8 41.95±1.8 46.75±1.3 6.16
Evasive20 39.45±1.5 40.46±2.4 40.84±2.4 41.83±0.9 40.09±1.3 43.52±1.3 41.85±1.0 43.67±0.8 45.99±0.8 3.80
40 41.17±2.0 43.23±1.7 44.22±2.3 43.94±1.7 43.38±1.5 43.73±1.1 44.06±1.3 42.70±2.5 45.31±1.5 1.73
60 44.34±1.6 41.35±1.5 41.33±2.0 46.41±1.0 46.08±1.0 44.92±1.2 46.68±1.2 46.20±0.8 45.36±1.0 4.95
CLGAPoisoning20 40.29±1.8 40.40±2.1 38.68±2.5 37.50±1.6 43.58±1.5 44.95±0.7 42.71±0.6 42.93±0.4 43.33±1.4 4.98
40 41.24±1.4 38.82±1.6 42.22±2.1 38.85±1.5 43.69±1.8 41.63±1.2 44.20±0.6 42.96±1.9 45.05±1.9 5.41
60 39.91±1.7 43.52±1.5 43.11±1.9 43.82±1.1 46.59±1.6 47.04±0.8 46.75±1.1 43.42±1.0 48.43±1.5 3.80
Evasive20 40.01±1.5 41.19±2.2 40.50±2.3 41.78±1.4 39.16±0.9 43.59±1.1 43.24±0.5 40.24±0.8 45.59±1.2 4.64
40 41.83±1.7 41.70±1.7 42.90±2.0 42.44±1.7 43.38±1.4 40.71±0.9 44.91±0.9 44.95±2.0 44.24±1.1 3.22
60 44.85±1.9 38.52±1.1 43.77±1.6 45.93±1.6 46.39±0.8 45.46±1.3 46.69±1.0 48.85±1.0 45.48±1.2 4.22
HGACPoisoning20 32.23±1.6 27.89±2.9 38.83±2.3 36.86±1.3 36.89±1.3 39.35±1.0 37.38±1.1 36.58±1.2 38.46±1.4 16.88
40 38.06±1.6 31.21±2.1 39.37±2.2 38.02±1.6 39.09±1.4 38.52±0.8 38.56±0.7 37.02±1.2 37.56±1.0 16.08
60 38.17±1.7 21.72±1.7 39.91±1.7 38.83±1.4 45.08±0.9 40.68±1.4 41.13±1.4 37.36±1.1 41.88±0.9 18.68
Evasive20 38.39±1.5 26.34±2.4 39.21±2.0 39.94±1.4 38.93±1.3 38.48±1.2 36.74±1.2 36.02±1.0 39.53±0.8 16.19
40 40.90±1.8 30.08±1.9 39.54±1.8 42.26±1.5 41.41±1.5 39.63±1.2 39.25±0.6 41.38±0.5 43.35±0.7 11.22
60 42.26±1.4 22.42±1.3 40.16±1.6 43.86±1.2 43.56±1.0 39.95±1.5 40.42±0.9 43.25±0.6 43.40±0.7 15.95
3063KDD ’24, August 25–29, 2024, Barcelona, Spain Haosen Wang, et al.
Table 2: Node clustering performance under different attacks.
Dataset Attack model Attack Type Metrics DMGI HDMI HDGI HGCML HGMAE HeCo ↓(%)
ACMClean -NMI 56.49 57.91 55.37 58.72 64.57 50.49 -
ARI 51.06 54.75 52.85 55.18 67.85 49.73 -
RandomPoisoningNMI 48.45 43.87 56.60 50.11 53.94 49.19 12.05
ARI 41.01 38.52 53.87 47.67 52.81 42.95 16.47
EvasiveNMI 54.59 46.29 45.56 52.38 43.47 52.94 14.07
ARI 48.14 45.27 45.20 50.75 44.37 52.08 13.76
CLGAPoisoningNMI 59.42 62.79 54.47 56.44 50.35 57.08 0.87
ARI 57.65 67.13 49.11 54.60 48.75 54.96 -0.23
EvasiveNMI 56.47 62.27 49.72 54.09 42.86 49.94 8.21
ARI 51.03 65.10 48.02 52.74 60.17 49.15 1.57
HGACPoisoningNMI 36.14 36.45 46.73 47.24 50.62 41.67 24.65
ARI 32.07 29.25 36.04 41.31 49.81 35.32 32.47
EvasiveNMI 39.19 23.57 28.56 42.83 27.46 37.72 41.98
ARI 37.86 28.37 24.10 37.17 23.56 36.07 43.54
AminerClean -NMI 30.37 17.56 19.06 31.08 32.06 36.91 -
ARI 26.15 5.04 13.99 25.51 26.84 34.37 -
RandomPoisoningNMI 13.26 11.04 15.85 19.43 17.01 32.01 34.99
ARI 10.70 6.99 15.51 16.90 2.11 22.37 43.46
EvasiveNMI 16.54 25.53 16.90 24.28 27.42 23.38 19.75
ARI 14.87 8.70 12.49 21.42 25.86 20.81 21.04
CLGAPoisoningNMI 14.72 17.83 17.83 22.15 28.08 25.24 24.66
ARI 10.93 8.92 8.92 19.62 22.92 7.66 40.13
EvasiveNMI 15.25 25.81 18.04 25.74 30.05 35.44 10.00
ARI 14.04 14.15 11.53 19.46 30.43 26.34 12.09
HGACPoisoningNMI 4.18 3.59 3.16 5.54 5.71 7.48 82.24
ARI 3.56 2.70 3.43 4.39 2.79 0.44 86.88
EvasiveNMI 7.33 3.42 6.02 6.78 20.81 26.28 57.71
ARI 4.82 2.36 2.41 5.17 15.82 22.55 59.72
FreebaseClean -NMI 16.41 16.53 16.66 16.88 17.18 16.14 -
ARI 16.13 17.47 17.38 17.61 17.94 16.90 -
RandomPoisoningNMI 15.22 16.08 10.54 16.19 11.70 13.96 16.14
ARI 15.08 16.45 13.09 17.22 11.96 16.13 13.05
EvasiveNMI 15.59 16.14 13.26 16.45 13.13 9.81 15.45
ARI 15.34 17.00 15.43 17.03 14.88 9.65 13.63
CLGAPoisoningNMI 15.61 16.36 11.39 16.52 12.39 14.54 13.02
ARI 15.47 17.11 13.94 17.46 13.70 16.79 8.66
EvasiveNMI 15.89 16.14 18.69 16.34 9.27 10.24 13.26
ARI 15.61 17.00 14.10 17.15 9.66 11.35 17.94
HGACPoisoningNMI 1.32 0.05 0.16 4.42 8.95 2.10 82.97
ARI 0.97 0.15 0.25 5.39 8.45 1.82 83.53
EvasiveNMI 12.75 13.60 12.93 13.88 9.69 7.38 29.63
ARI 13.43 14.33 14.24 14.64 10.82 7.25 27.77
IMDBClean -NMI 2.15 2.07 2.66 2.54 2.76 2.72 -
ARI 1.51 1.79 1.43 2.27 2.62 2.44 -
RandomPoisoningNMI 2.46 2.67 2.71 2.62 0.37 2.85 8.19
ARI 1.63 1.55 1.63 2.18 0.75 1.69 21.81
EvasiveNMI 2.78 2.44 2.49 2.14 1.25 1.91 12.68
ARI 1.84 3.92 1.45 1.76 0.84 1.53 5.97
CLGAPoisoningNMI 2.01 2.10 2.65 2.65 2.50 2.86 0.87
ARI 1.44 1.85 1.44 2.39 2.38 1.29 10.53
EvasiveNMI 1.95 1.33 2.27 2.40 1.24 2.69 20.27
ARI 1.36 1.94 1.03 2.13 0.86 1.21 29.27
HGACPoisoningNMI 0.27 0.84 0.18 0.58 0.16 0.25 84.70
ARI 0.12 1.05 0.06 0.33 -0.07 -0.13 88.72
EvasiveNMI 0.46 0.96 0.20 0.89 0.75 0.46 75.03
ARI 0.35 1.07 -0.04 0.71 0.68 -1.14 86.48
Table 3: Metapath prediction performance under different
attacks.
Dataset Attack model Attack Type DMGI HDMI HDGI HGCML HGMAE HeCo ↓(%)
ACMClean - 95.72 93.66 93.01 95.34 95.35 97.57 -
RandomPoisoning 94.11 93.51 93.10 94.85 96.17 96.61 0.40
Evasive 96.48 90.55 89.83 92.49 92.47 94.93 2.44
CLGAPoisoning 95.54 94.02 92.85 94.70 95.40 95.93 0.39
Evasive 93.41 93.45 93.28 91.92 94.47 96.81 1.28
HGACPoisoning 87.71 92.42 91.38 90.12 90.45 79.97 6.76
Evasive 84.56 88.41 85.28 85.74 83.70 79.32 11.15
AminerClean - 92.25 91.41 88.89 91.66 94.25 96.09 -
RandomPoisoning 84.39 82.33 87.43 90.27 90.64 95.04 4.41
Evasive 90.82 90.29 85.92 89.42 92.86 94.45 1.95
CLGAPoisoning 86.47 84.87 87.82 90.85 92.56 95.16 3.03
Evasive 91.55 89.62 86.69 90.31 93.68 95.58 1.28
HGACPoisoning 76.34 78.27 84.20 88.33 88.20 93.28 8.28
Evasive 88.16 83.98 83.45 87.67 87.33 94.49 5.31
FreebaseClean - 91.35 90.47 90.46 92.28 96.57 91.68 -
RandomPoisoning 85.16 86.59 75.33 86.47 96.23 89.46 6.07
Evasive 88.44 89.92 87.03 88.62 97.10 89.50 2.21
CLGAPoisoning 85.86 86.61 77.54 87.30 96.07 90.71 5.20
Evasive 87.73 89.85 88.52 88.17 97.34 90.24 1.98
HGACPoisoning 81.60 79.84 76.72 82.59 95.06 89.52 8.59
Evasive 84.85 86.37 85.05 85.22 96.12 83.05 5.82
IMDBClean - 74.89 83.28 80.50 81.82 87.06 88.25 -
RandomPoisoning 71.75 80.02 81.98 79.54 82.67 87.15 2.56
Evasive 74.68 74.52 76.11 80.33 75.52 85.02 5.97
CLGAPoisoning 72.06 83.04 79.74 80.41 85.46 84.98 2.04
Evasive 74.50 75.82 77.68 80.86 77.03 87.90 4.43
HGACPoisoning 66.88 67.49 78.82 76.72 83.70 85.23 7.45
Evasive 72.53 71.27 70.40 78.48 72.51 79.93 10.22Table 4: Ablation study.
Dataset Attack model Attack Type DMGI HDMI HDGI HGCML HGMAE HeCo
ACMw/o CandidatePoisoning 86.45±0.4 88.99±0.8 85.50±0.6 88.37±0.5 89.99±0.3 88.09±0.9
Evasive 88.53±0.6 84.41±0.5 81.09±0.7 86.82±0.8 81.84±0.7 84.64±0.5
w/o ClusterPoisoning 88.42±0.5 86.15±0.7 85.62±0.6 87.42±0.9 86.56±0.7 91.18±0.3
Evasive 89.76±0.6 87.12±0.4 84.35±0.9 85.38±0.8 86.65±0.4 86.87±0.5
HGACPoisoning 81.03±0.5 76.33±1.1 82.63±0.9 82.43±0.8 85.86±1.0 73.99±0.7
Evasive 78.45±0.4 75.42±0.4 74.29±0.3 80.39±1.0 74.37±1.0 78.28±0.3
IMDBw/o CandidatePoisoning 44.34±0.7 44.29±0.4 46.50±0.4 44.62±0.5 40.59±0.5 43.53±0.8
Evasive 44.41±0.5 45.34±0.5 46.28±0.5 44.33±0.7 46.52±1.3 46.41±0.6
w/o ClusterPoisoning 41.06±1.2 44.10±0.4 43.52±0.8 43.72±0.9 40.52±0.8 45.95±0.6
Evasive 44.66±1.0 43.00±1.5 45.23±0.7 45.18±0.8 49.24±0.6 47.07±0.7
HGACPoisoning 38.83±1.4 45.08±0.9 40.68±1.4 41.13±1.4 37.36±1.1 41.88±0.9
Evasive 43.86±1.2 43.56±1.0 39.95±1.5 40.42±0.9 43.25±0.6 43.40±0.7
Table 5: Performances of supervised homogeneous graph
attacks.
Dataset Attack model Attack Type DMGI HDMI HDGI HGCML HGMAE HeCo
ACMPGDPoisoning 89.27±0.5 88.53±0.6 88.61±0.9 89.37±0.8 89.18±0.5 88.44±1.2
Evasive 89.26±0.6 87.35±0.7 85.76±0.5 86.40±0.6 86.62±0.9 85.42±0.4
MettackPoisoning 88.11±0.5 89.39±0.7 87.95±0.6 87.62±0.9 88.38±0.7 88.31±0.3
Evasive 89.47±0.9 87.61±0.7 86.49±1.3 85.83±0.5 84.78±0.4 85.91±0.8
PGAPoisoning 86.51±0.8 87.27±0.7 87.60±0.6 87.62±1.1 88.72±0.9 86.56±1.0
Evasive 87.38±0.9 87.44±0.5 85.49±0.6 85.23±0.8 86.15±0.8 84.37±0.7
HGACPoisoning 81.03±0.5 76.33±1.1 82.63±0.9 82.43±0.8 85.86±1.0 73.99±0.7
Evasive 78.45±0.4 75.42±0.4 74.29±0.3 80.39±1.0 74.37±1.0 78.28±0.3
IMDBPGDPoisoning 44.29±0.5 46.05±0.4 46.61±0.8 46.87±0.6 42.45±0.4 47.36±1.2
Evasive 45.77±0.5 46.50±0.9 45.38±0.5 46.45±0.4 47.53±0.8 45.14±0.5
MettackPoisoning 43.96±1.2 46.48±0.9 45.22±0.4 46.80±0.9 42.30±0.6 46.59±0.7
Evasive 45.76±1.3 47.02±1.1 45.12±1.0 46.91±0.6 47.67±0.4 45.74±0.9
PGAPoisoning 43.83±0.7 46.37±0.6 45.61±1.2 46.63±0.8 42.07±0.9 46.58±0.9
Evasive 45.42±0.9 46.21±0.7 44.94±0.8 46.32±1.0 47.15±0.7 45.43±01.0
HGACPoisoning 38.83±1.4 45.08±0.9 40.68±1.4 41.13±1.4 37.36±1.1 41.88±0.9
Evasive 43.86±1.2 43.56±1.0 39.95±1.5 40.42±0.9 43.25±0.6 43.40±0.7
Figure 3: Degree distribution comparison.
Compared with the performance of supervised homogeneous
graph attacks. At present, supervised homogeneous graph attacks
have made considerable progress. We select three baselines (i.e.,
PGD [ 37], Mettack [ 44], PGA [ 52]) to attack HG pre-training mod-
els and report their results in Table 5. We can observe that their
performances are significantly worse than our HGAC.
Degree distribution comparison. To demonstrate that HGAC’s
attacks are unnoticeable, we visualized node degree distributions
of the clean graph and attacked graphs in the ACM dataset. Results
can be found in Figure 3. The results show that HGAC has the
smallest difference in degree distribution from the clean map. Also,
Random and CLGA generate many isolated nodes, while HGAC
does not have such a problem.
Different optimization objectives. In addition to node clustering,
metapath prediction and node similarity also seem to be used as
optimization objectives. For the metapath prediction, we use the
pre-trained node representations obtained from the attacked HG eG
to predict metapath instances of the clean HG Gand maximize the
cross-entropy loss. For node similarity, we optimize the structural
attacks by minimizing the similarity of pre-trained node represen-
tations of the attacked HG eGand the clean HGG. We report the
3064Unsupervised Heterogeneous Graph Rewriting Attack via Node Clustering KDD ’24, August 25–29, 2024, Barcelona, Spain
Table 6: Performance comparison of three optimization ob-
jectives. "MP" denotes metapath prediction. "NS" denotes
node similarity. "CL" denotes the node clustering.
Dataset Models Objective Attack modelNode Classification Node clustering MP
20 40 60 NMI ARI AUC
ACMDMGIMPPoisoning 86.27 86.24 85.00 48.79 39.07 93.19
Evasive 85.49 87.11 86.24 51.13 42.47 92.60
NSPoisoning 78.18 83.86 80.78 40.06 34.34 91.49
Evasive 83.86 86.72 85.27 50.54 42.06 92.37
ClPoisoning 78.56 80.21 81.03 36.14 32.07 87.71
Evasive 77.80 77.53 78.45 39.19 37.86 84.56
HDMIMPPoisoning 76.86 86.03 85.41 39.80 31.20 94.66
Evasive 78.14 79.48 80.53 37.33 30.07 88.95
NSPoisoning 87.32 89.61 90.33 47.82 40.15 94.86
Evasive 79.67 78.29 80.25 42.24 43.58 88.87
ClPoisoning 76.23 75.07 76.33 36.45 29.25 92.42
Evasive 75.58 75.74 75.42 23.57 28.37 88.41
HeCoMPPoisoning 88.81 87.56 89.03 42.33 36.37 94.71
Evasive 83.70 82.67 83.64 38.68 37.66 95.11
NSPoisoning 82.93 79.59 88.04 43.15 37.18 95.07
Evasive 80.86 81.36 80.48 30.13 32.76 94.08
ClPoisoning 76.02 76.91 73.99 41.67 35.32 79.97
Evasive 76.68 77.60 78.28 37.72 36.07 79.32
IMDBDMGIMPPoisoning 39.48 40.13 39.54 2.08 2.30 68.09
Evasive 40.21 41.84 45.37 1.97 2.20 72.12
NSPoisoning 38.68 38.44 43.65 1.51 1.44 67.25
Evasive 41.03 42.76 45.40 1.89 1.63 74.56
ClPoisoning 36.86 38.02 38.83 0.27 0.12 66.88
Evasive 39.94 42.26 43.86 0.46 0.35 72.53
HDMIMPPoisoning 40.18 42.99 46.57 2.23 2.50 80.77
Evasive 38.29 41.62 45.31 1.07 1.41 79.74
NSPoisoning 39.76 40.82 45.38 1.26 2.91 79.35
Evasive 38.21 42.03 45.88 0.90 1.24 72.86
ClPoisoning 36.89 39.09 45.08 0.84 1.05 67.49
Evasive 38.93 41.41 43.56 0.96 1.07 71.27
HeCoMPPoisoning 44.68 42.22 43.52 2.71 1.89 85.29
Evasive 43.70 43.65 43.31 2.47 2.71 84.22
NSPoisoning 41.89 41.21 41.08 0.53 0.84 85.31
Evasive 42.75 44.55 45.55 0.25 -0.93 80.33
ClPoisoning 38.46 37.56 41.88 0.25 -0.13 85.23
Evasive 39.53 43.35 43.40 0.46 -1.14 79.93
Figure 4: Performance of different models under various
attack ratios 𝛿.
experimental results in Table 6. We can observe that the use of
node clustering as an optimization objective achieves consistent
superiority in three downstream tasks.
Hyper-parameter sensitivity. In this subsection, we investigate
the sensitivity of three main hyper-parameters: the size of candidate
sets of deleted edges and added edges, 𝐾𝑑𝑟𝑜𝑝 and𝐾𝑎𝑑𝑑, and the
number of clusters 𝜆. We conduct node classification under HGAC’s
poisoning attack on ACM and Freebased datasets. Figure 6(a) shows
the Ma-F1 values of the HDMI model with 20 labeled nodes per class.
In addition, Figure 6(b) reports the performances of six benchmark
models with an increasing number of clusters. Specifically, HGAC
achieves the optimal attack ability on the ACM dataset with 𝐾𝑑𝑟𝑜𝑝
and𝐾𝑎𝑑𝑑set at 2 and 20, respectively, and on the Freebase dataset
at settings of 4 and 25. In general, a high 𝐾𝑎𝑑𝑑is usually beneficial.
For𝜆, the optimal setting is between 15 and 25.
Figure 5: Visualization of the pre-trained representations of
paper nodes on ACM under different attacks.
Figure 6: Hyper-parameter analysis.
6 CONCLUSION
This paper proposes an unsupervised heterogeneous graph rewrit-
ing attack via node clustering, named HGAC. This is the first work
to attack heterogeneous graph pre-training in the unsupervised
paradigm. HGAC regards the node clustering results as attack guid-
ance signals and produces reasonable and inconspicuous attacks by
the heterogeneous edge rewriting strategy. Extensive experiments
on four datasets, four downstream tasks, and two attack modes
demonstrate the effectiveness of HGAC.
ACKNOWLEDGEMENT
This work was supported in part by the National Key Research and
Development Program of China (2023YFB4502400) and the National
Natural Science Foundation of China under Grant 62271452.
3065KDD ’24, August 25–29, 2024, Barcelona, Spain Haosen Wang, et al.
REFERENCES
[1]Aleksandar Bojchevski and Stephan Günnemann. 2019. Adversarial attacks on
node embeddings via graph poisoning. In International Conference on Machine
Learning. PMLR, 695–704.
[2]Feng Chen and Daniel B Neill. 2014. Non-parametric scan statistics for event
detection and forecasting in heterogeneous social media graphs. In Proceedings
of the 20th ACM SIGKDD international conference on Knowledge discovery and
data mining. 1166–1175.
[3]Yongqiang Chen, Han Yang, Yonggang Zhang, Kaili Ma, Tongliang Liu, Bo Han,
and James Cheng. 2022. Understanding and Improving Graph Injection Attack
by Promoting Unnoticeability. In The Tenth International Conference on Learning
Representations, ICLR 2022, Virtual Event, April 25-29, 2022. https://openreview.
net/forum?id=wkMG8cdvh7-
[4]Shaohua Fan, Junxiong Zhu, Xiaotian Han, Chuan Shi, Linmei Hu, Biyu Ma, and
Yongliang Li. 2019. Metapath-guided heterogeneous graph neural network for
intent recommendation. In Proceedings of the 25th ACM SIGKDD international
conference on knowledge discovery & data mining. 2478–2486.
[5]Xinyu Fu, Jiani Zhang, Ziqiao Meng, and Irwin King. 2020. MAGNN: Metapath
Aggregated Graph Neural Network for Heterogeneous Graph Embedding. In
Proceedings of The Web Conference 2020 (Taipei, Taiwan) (WWW ’20). Association
for Computing Machinery, New York, NY, USA, 2331–2341. https://doi.org/10.
1145/3366423.3380297
[6]Jiayan Guo, Lun Du, Wendong Bi, Qiang Fu, Xiaojun Ma, Xu Chen, Shi Han,
Dongmei Zhang, and Yan Zhang. 2023. Homophily-oriented heterogeneous
graph rewiring. In Proceedings of the ACM Web Conference 2023. 511–522.
[7]Shifu Hou, Yujie Fan, Yiming Zhang, Yanfang Ye, Jingwei Lei, Wenqiang Wan,
Jiabin Wang, Qi Xiong, and Fudong Shao. 2019. 𝛼cyber: Enhancing robustness of
android malware detection system against adversarial attacks on heterogeneous
graph based model. In Proceedings of the 28th ACM international conference on
information and knowledge management. 609–618.
[8]Binbin Hu, Yuan Fang, and Chuan Shi. 2019. Adversarial learning on heteroge-
neous information networks. In Proceedings of the 25th ACM SIGKDD International
Conference on Knowledge Discovery & Data Mining. 120–129.
[9]Ziniu Hu, Yuxiao Dong, Kuansan Wang, and Yizhou Sun. 2020. Heterogeneous
Graph Transformer. In WWW ’20: The Web Conference 2020, Taipei, Taiwan, April
20-24, 2020. ACM / IW3C2, 2704–2710. https://doi.org/10.1145/3366423.3380027
[10] Yeonjun In, Kanghoon Yoon, and Chanyoung Park. 2023. Similarity Preserving
Adversarial Graph Contrastive Learning. In Proceedings of the 29th ACM SIGKDD
Conference on Knowledge Discovery and Data Mining (KDD ’23). Association for
Computing Machinery, New York, NY, USA, 867–878. https://doi.org/10.1145/
3580305.3599503
[11] Eric Jang, Shixiang Gu, and Ben Poole. 2017. Categorical Reparameterization
with Gumbel-Softmax. In 5th International Conference on Learning Representa-
tions, ICLR 2017, Toulon, France, April 24-26, 2017, Conference Track Proceedings.
OpenReview.net. https://openreview.net/forum?id=rkE3y85ee
[12] Wei Jin, Yaxin Li, Han Xu, Yiqi Wang, and Jiliang Tang. 2020. Adversarial
attacks and defenses on graphs: A review and empirical study. arXiv preprint
arXiv:2003.00653 10, 3447556.3447566 (2020).
[13] Baoyu Jing, Chanyoung Park, and Hanghang Tong. 2021. HDMI: High-Order
Deep Multiplex Infomax. In Proceedings of the Web Conference 2021 (Ljubljana,
Slovenia) (WWW ’21). Association for Computing Machinery, New York, NY,
USA, 2414–2424. https://doi.org/10.1145/3442381.3449971
[14] Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic opti-
mization. ICLR.
[15] Udesh Kumarasinghe, Mohamed Nabeel, Kasun De Zoysa, Kasun Gunawardana,
and Charitha Elvitigala. 2022. HeteroGuard: Defending Heterogeneous Graph
Neural Networks against Adversarial Attacks. In 2022 IEEE International Confer-
ence on Data Mining Workshops (ICDMW). IEEE, 698–705.
[16] Qing Li, Ziyue Wang, and Zehao Li. 2023. PAGCL: An unsupervised graph
poisoned attack for graph contrastive learning model. Future Generation Computer
Systems 149 (2023), 240–249.
[17] Xiang Li, Danhao Ding, Ben Kao, Yizhou Sun, and Nikos Mamoulis. 2021. Leverag-
ing meta-path contexts for classification in heterogeneous information networks.
In2021 IEEE 37th International Conference on Data Engineering (ICDE). IEEE,
912–923.
[18] Zhe Li, Xinyi Tu, Yuping Chen, and Wenbin Lin. 2023. HetDDI: a pre-trained
heterogeneous graph neural network model for drug–drug interaction prediction.
Briefings in Bioinformatics 24, 6 (2023), bbad385.
[19] Can Liu, Li Sun, Xiang Ao, Jinghua Feng, Qing He, and Hao Yang. 2021. Intention-
aware heterogeneous graph attention networks for fraud transactions detection.
InProceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &
Data Mining. 3280–3288.
[20] Zhiwei Liu, Yingtong Dou, Philip S Yu, Yutong Deng, and Hao Peng. 2020. Al-
leviating the inconsistency problem of applying graph neural network to fraud
detection. In Proceedings of the 43rd international ACM SIGIR conference on re-
search and development in information retrieval. 1569–1572.[21] Yao Ma, Suhang Wang, Tyler Derr, Lingfei Wu, and Jiliang Tang. 2021. Graph
Adversarial Attack via Rewiring. In Proceedings of the 27th ACM SIGKDD Con-
ference on Knowledge Discovery & Data Mining (Virtual Event, Singapore) (KDD
’21). Association for Computing Machinery, New York, NY, USA, 1161–1169.
https://doi.org/10.1145/3447548.3467416
[22] Qiheng Mao, Zemin Liu, Chenghao Liu, and Jianling Sun. 2023. HINormer:
Representation Learning On Heterogeneous Information Networks with Graph
Transformer. In Proceedings of the ACM Web Conference 2023, WWW 2023, Austin,
TX, USA, 30 April 2023 - 4 May 2023. ACM, 599–610. https://doi.org/10.1145/
3543507.3583493
[23] Chanyoung Park, Donghyun Kim, Jiawei Han, and Hwanjo Yu. 2020. Unsu-
pervised Attributed Multiplex Network Embedding. Proceedings of the AAAI
Conference on Artificial Intelligence 34, 04, 5371–5378. https://doi.org/10.1609/
aaai.v34i04.5985
[24] Jiajie Peng, Yuxian Wang, Jiaojiao Guan, Jingyi Li, Ruijiang Han, Jianye Hao,
Zhongyu Wei, and Xuequn Shang. 2021. An end-to-end heterogeneous graph
representation learning-based framework for drug–target interaction prediction.
Briefings in bioinformatics 22, 5 (2021).
[25] Yiyue Qian, Yiming Zhang, Yanfang Ye, Chuxu Zhang, et al .2021. Distilling
meta knowledge on heterogeneous graph for illicit drug trafficker detection
on social media. Advances in Neural Information Processing Systems 34 (2021),
26911–26923.
[26] Yuxiang Ren, Bo Liu, Chao Huang, Peng Dai, Liefeng Bo, and Jiawei Zhang. 2019.
Heterogeneous deep graph infomax. arXiv preprint arXiv:1911.08538 (2019).
[27] Michael Sejr Schlichtkrull, Thomas N. Kipf, Peter Bloem, Rianne van den Berg,
Ivan Titov, and Max Welling. 2018. Modeling Relational Data with Graph Convo-
lutional Networks. In The Semantic Web - 15th International Conference, ESWC
2018, Heraklion, Crete, Greece, June 3-7, 2018, Proceedings (Lecture Notes in Com-
puter Science, Vol. 10843). Springer, 593–607. https://doi.org/10.1007/978-3-319-
93417-4_38
[28] Yu Shang, Yudong Zhang, Jiansheng Chen, Depeng Jin, and Yong Li. 2023. Trans-
ferable Structure-based Adversarial Attack of Heterogeneous Graph Neural Net-
work. In Proceedings of the 32nd ACM International Conference on Information
and Knowledge Management. 2188–2197.
[29] Gen Shi, Yifan Zhu, Jian K. Liu, and Xuesong Li. 2023. HeGCL: Advance
Self-Supervised Learning in Heterogeneous Graph-Level Representation. IEEE
Transactions on Neural Networks and Learning Systems (2023), 1–12. https:
//doi.org/10.1109/TNNLS.2023.3273255
[30] Lichao Sun, Yingtong Dou, Carl Yang, Kai Zhang, Ji Wang, S Yu Philip, Lifang He,
and Bo Li. 2022. Adversarial attack and defense on graph data: A survey. IEEE
Transactions on Knowledge and Data Engineering (2022).
[31] Shuchang Tao, Qi Cao, Huawei Shen, Junjie Huang, Yunfan Wu, and Xueqi
Cheng. 2021. Single Node Injection Attack against Graph Neural Networks. In
CIKM ’21: The 30th ACM International Conference on Information and Knowledge
Management, Virtual Event, Queensland, Australia, November 1 - 5, 2021. ACM,
1794–1803. https://doi.org/10.1145/3459637.3482393
[32] Yijun Tian, Kaiwen Dong, Chunhui Zhang, Chuxu Zhang, and Nitesh V Chawla.
2023. Heterogeneous graph masked autoencoders. In Proceedings of the AAAI
Conference on Artificial Intelligence, Vol. 37. 9997–10005.
[33] Li Wang, Peipei Li, Kai Xiong, Jiashu Zhao, and Rui Lin. 2021. Modeling hetero-
geneous graph network on fraud detection: a community-based framework with
attention mechanism. In Proceedings of the 30th ACM international conference on
information & knowledge management. 1959–1968.
[34] Xiao Wang, Houye Ji, Chuan Shi, Bai Wang, Yanfang Ye, Peng Cui, and Philip S.
Yu. 2019. Heterogeneous Graph Attention Network. In The World Wide Web
Conference, WWW 2019, San Francisco, CA, USA, May 13-17, 2019. ACM, 2022–
2032. https://doi.org/10.1145/3308558.3313562
[35] Xiao Wang, Nian Liu, Hui Han, and Chuan Shi. 2021. Self-Supervised Heteroge-
neous Graph Neural Network with Co-Contrastive Learning. In Proceedings of the
27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining (Virtual
Event, Singapore) (KDD ’21). Association for Computing Machinery, New York,
NY, USA, 1726–1736. https://doi.org/10.1145/3447548.3467415
[36] Zehong Wang, Qi Li, Donghua Yu, Xiaolong Han, Xiao-Zhi Gao, and Shigen Shen.
2023. Heterogeneous graph contrastive multi-view learning. In Proceedings of
the 2023 SIAM International Conference on Data Mining (SDM). SIAM, 136–144.
[37] Kaidi Xu, Hongge Chen, Sijia Liu, Pin-Yu Chen, Tsui-Wei Weng, Mingyi Hong,
and Xue Lin. 2019. Topology Attack and Defense for Graph Neural Networks:
An Optimization Perspective. In Proceedings of the Twenty-Eighth International
Joint Conference on Artificial Intelligence, IJCAI 2019, Macao, China, August 10-16,
2019. 3961–3967. https://doi.org/10.24963/ijcai.2019/550
[38] Surong Yan, Haosen Wang, Yixiao Li, Chunqi Wu, Long Han, Chenglong Shi, and
Ruilin Guo. 2023. Metapath-guided dual semantic-aware filtering for HIN-based
recommendation. The Journal of Supercomputing (2023), 1–31.
[39] Surong Yan, Haosen Wang, Yixiao Li, Yuan Zheng, and Long Han. 2021. Attention-
aware metapath-based network embedding for HIN based recommendation.
Expert Systems with Applications 174 (2021), 114601.
[40] Xiaocheng Yang, Mingyu Yan, Shirui Pan, Xiaochun Ye, and Dongrui Fan. 2023.
Simple and Efficient Heterogeneous Graph Neural Network. In Thirty-Seventh
3066Unsupervised Heterogeneous Graph Rewriting Attack via Node Clustering KDD ’24, August 25–29, 2024, Barcelona, Spain
AAAI Conference on Artificial Intelligence, AAAI 2023, Thirty-Fifth Conference on
Innovative Applications of Artificial Intelligence, IAAI 2023, Thirteenth Symposium
on Educational Advances in Artificial Intelligence, EAAI 2023, Washington, DC,
USA, February 7-14, 2023. AAAI Press, 10816–10824. https://doi.org/10.1609/
AAAI.V37I9.26283
[41] Yuning You, Tianlong Chen, Yongduo Sui, Ting Chen, Zhangyang Wang,
and Yang Shen. 2020. Graph Contrastive Learning with Augmentations.
InAdvances in Neural Information Processing Systems 33: Annual Confer-
ence on Neural Information Processing Systems 2020, NeurIPS 2020, Decem-
ber 6-12, 2020, virtual. https://proceedings.neurips.cc/paper/2020/hash/
3fe230348e9a12c13120749e3f9fa4cd-Abstract.html
[42] Jianxiang Yu and Xiang Li. 2023. Heterogeneous Graph Contrastive Learning
with Meta-path Contexts and Weighted Negative Samples. In Proceedings of the
2023 SIAM International Conference on Data Mining (SDM). SIAM, 37–45.
[43] Xiangchi Yuan, Chunhui Zhang, Yijun Tian, Yanfang Ye, and Chuxu Zhang. 2023.
Mitigating Severe Robustness Degradation on Graphs. In The Twelfth International
Conference on Learning Representations.
[44] Haoxi Zhan and Xiaobing Pei. 2021. Black-box Gradient Attack on Graph Neural
Networks: Deeper Insights in Graph-based Attack and Defense. abs/2104.15061
(2021). https://arxiv.org/abs/2104.15061
[45] Chuxu Zhang, Dongjin Song, Chao Huang, Ananthram Swami, and Nitesh V.
Chawla. 2019. Heterogeneous Graph Neural Network. In Proceedings of the 25th
ACM SIGKDD International Conference on Knowledge Discovery & Data Mining
(Anchorage, AK, USA) (KDD ’19). Association for Computing Machinery, New
York, NY, USA, 793–803. https://doi.org/10.1145/3292500.3330961
[46] Chunhui Zhang, Yijun Tian, Mingxuan Ju, Zheyuan Liu, Yanfang Ye, Nitesh V.
Chawla, and Chuxu Zhang. 2023. Chasing All-Round Graph Representation
Robustness: Model, Training, and Optimization. In The Eleventh International
Conference on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023.
[47] Mengmei Zhang, Xiao Wang, Meiqi Zhu, Chuan Shi, Zhiqiang Zhang, and Jun
Zhou. 2022. Robust heterogeneous graph neural networks against adversarial
attacks. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 36.
4363–4370.
[48] Sixiao Zhang, Hongxu Chen, Xiangguo Sun, Yicong Li, and Guandong Xu. 2022.
Unsupervised graph poisoning attack via contrastive loss back-propagation. In
Proceedings of the ACM Web Conference 2022. 1322–1330.
[49] Jianan Zhao, Xiao Wang, Chuan Shi, Zekuan Liu, and Yanfang Ye. 2020. Net-
work schema preserving heterogeneous information network embedding. In
International joint conference on artificial intelligence (IJCAI).
[50] Kai Zhao, Qiyu Kang, Yang Song, Rui She, Sijie Wang, and Wee Peng Tay. 2023.
Adversarial Robustness in Graph Neural Networks: A Hamiltonian Approach.
InAdvances in Neural Information Processing Systems 36: Annual Conference on
Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA,
December 10 - 16, 2023.
[51] Qinkai Zheng, Xu Zou, Yuxiao Dong, Yukuo Cen, Da Yin, Jiarong Xu, Yang Yang,
and Jie Tang. 2021. Graph Robustness Benchmark: Benchmarking the Adversarial
Robustness of Graph Machine Learning. In Proceedings of the Neural Information
Processing Systems Track on Datasets and Benchmarks 1, NeurIPS Datasets and
Benchmarks 2021, December 2021, virtual.
[52] Guanghui Zhu, Mengyu Chen, Chunfeng Yuan, and Yihua Huang. [n. d.]. Sim-
ple and Efficient Partial Graph Adversarial Attack: A New Perspective. IEEE
Transactions on Knowledge and Data Engineering ([n. d.]).
[53] Yanqiao Zhu, Yichen Xu, Hejie Cui, Carl Yang, Qiang Liu, and Shu Wu. 2021.
Structure-aware hard negative mining for heterogeneous graph contrastive learn-
ing. arXiv preprint arXiv:2108.13886 (2021).
[54] Yanqiao Zhu, Yichen Xu, Feng Yu, Qiang Liu, Shu Wu, and Liang Wang. 2021.
Graph Contrastive Learning with Adaptive Augmentation. In WWW ’21: The
Web Conference 2021, Virtual Event / Ljubljana, Slovenia, April 19-23, 2021. ACM /
IW3C2, 2069–2080. https://doi.org/10.1145/3442381.3449802
[55] Daniel Zügner, Amir Akbarnejad, and Stephan Günnemann. 2018. Adversarial
attacks on neural networks for graph data. In Proceedings of the 24th ACM SIGKDD
international conference on knowledge discovery & data mining. 2847–2856.
[56] Daniel Zügner and Stephan Günnemann. 2019. Adversarial Attacks on Graph
Neural Networks via Meta Learning. In 7th International Conference on Learning
Representations, ICLR 2019, New Orleans, LA, USA, May 6-9, 2019.
A THE COST OF HGAC
We report the number of parameters, memory, and time cost of
HGAC in table 7.
B DETAILS OF DATASET
We describe the details of the datasets in Table 8.Table 7: The cost of HGAC. “P” denotes "parameters", "S"
denotes "surrogate", "A" denotes "attack".
P of S P of A Memory of S Memory of A Time per epoch Total time
ACM 887K 55K 2.26G 0.77G 2.25s 3.08min
Aminer 18570K 88K 24.01G 8.16G 27.41s 28.35min
Freebase 3322K 59K 10.47G 8.63G 23.95s 19.22min
IMDB 1039K 21k 1.98G 0.44G 5.87s 7.62min
Table 8: The statistics of the benchmark datasets.
Dataset Node Relations Metapaths Target Classes
ACMpaper (P): 4019
author (A): 7167
subject (S): 60P-A:13407
P-S: 4019PAP
PSPpaper 3
AMinerpaper (P): 6564
author(A): 13329
reference (R): 35890P-A:18007
P-R: 58831PAP
PRPpaper 3
Freebasemovie (M): 3492
actor (A): 33401
direct (D): 2502
writer (W): 4459M-A:65341
M-D: 3762
M-W: 6414MAM
MDM
MWMmovie 3
IMDBmovie (M): 4661
actor (A): 5841
direct (D): 2270M-A: 13983
M-D: 4661MAM
MDMmovie 3
C SYMBOL INTERPRETATION
The symbol interpretation is reported in table 9.
Algorithm 1: Overview of proposed HGAC
Input: Heterogeneous graph G=(V,E,A,R); Surrogate model; Threat model.
1Initialize parameters with random weights
2 repeat
3 // Train surrogate model
4 Generate two augmented graphs G(1)andG(2);
5 EncodeG(1)andG(2)via HGNN;
6 Optimize the surrogate model via contrastive loss L𝑐𝑜by Eq. (1);
7 Compute gradients 𝐺𝐴𝑟by Eq. (2) to Eq. (4);
8 untilL𝑐𝑜converges;
9 repeat
10 // Train threat model
11 Obtain deleted and adding edge candidate sets 𝑆𝑑𝑒𝑙𝑟and𝑆𝑎𝑑𝑑
𝑟,𝑖by top-ranking 𝐺𝐴𝑟;
12 Obtain deleted edges by edge deleting learner;
13 Obtain adding edges by edge adding learner;
14 Optimize the threat model using L𝑎𝑡𝑡𝑎𝑐𝑘by Eq. (9);
15 untilL𝑎𝑡𝑡𝑎𝑐𝑘converges;
Output: The final attacked graph eG
D ALGORITHMIC FLOWCHART
We provide the algorithmic flowchart in Algorithmic 1.
E ADDITIONAL EXPERIMENTS
E.1 Node classification performance under
different training ratios
To make our results more convincing, we added additional experi-
ments to explore the effect of the size of the training set on robust-
ness. We adjusted the training dataset’s ratio in the range of 0.1 to
0.5, fixed the validation set’s ratio is 0.2, and used the remainder as
the test set. The attack mode is set to poisoning. The experimental
results are shown in Table 10. We observed the robustness of the
defender baselines has no significant correlation with the size of
the training set.
3067KDD ’24, August 25–29, 2024, Barcelona, Spain Haosen Wang, et al.
Table 10: Node classification performance under different
training ratios. The best results are bolded.
Dataset Pre-training models Attack model 0.1 0.2 0.3 0.4 0.5
ACMDMGIClean 90.86 91.67 90.52 90.66 90.87
Random 87.06 88.59 87.52 88.19 88.57
CLGA 88.93 89.84 89.44 88.54 89.99
HGAC 82.93 83.29 82.26 81.42 82.81
HDMIClean 91.18 91.45 91.53 91.10 91.43
Random 88.50 88.98 88.05 87.52 88.33
CLGA 89.21 88.53 89.19 88.43 88.85
HGAC 78.36 77.22 76.15 76.61 78.28
HeCoClean 88.12 89.21 88.53 88.08 89.36
Random 85.10 86.59 84.65 85.57 86.44
CLGA 88.54 88.83 87.98 88.45 89.28
HGAC 73.72 74.79 75.59 73.88 75.09
IMDBDMGIClean 44.33 47.18 48.67 49.52 48.68
Random 42.70 44.75 46.72 76.37 45.77
CLGA 41.71 45.66 44.31 46.46 45.53
HGAC 40.15 42.82 42.69 42.81 42.41
HDMIClean 45.54 35.25 44.60 44.51 45.33
Random 43.45 41.99 40.50 41.96 41.43
CLGA 43.72 43.83 42.41 42.98 42.75
HGAC 39.81 41.03 38.46 37.98 38.27
HeCoClean 47.58 48.25 46.47 48.34 46.87
Random 44.70 42.14 43.89 43.92 43.82
CLGA 44.39 41.71 41.06 42.59 42.44
HGAC 40.25 39.39 38.35 41.43 37.88
Table 11: The impact of the number of GCN layers on attack
performances. " 𝐿" represents the number of GCN layers. "MP"
represents the metapath prediction.
Dataset Models 𝐿 Attack modelNode Classification Node clustering MP
20 40 60 NMI ARI AUC
ACMDMGI1Poisoning 78.56 80.21 81.03 36.14 32.07 87.71
Evasive 77.80 77.53 78.45 39.19 37.86 84.56
2Poisoning 79.51 81.75 82.22 42.17 36.30 89.23
Evasive 79.36 80.04 80.96 41.78 39.63 86.48
3Poisoning 80.39 83.05 82.45 44.10 40.53 90.84
Evasive 81.54 83.74 83.24 43.28 40.79 88.34
HDMI1Poisoning 76.23 75.07 76.33 36.45 29.25 92.42
Evasive 75.58 75.74 75.42 23.57 28.37 88.41
2Poisoning 77.58 76.47 77.35 37.22 31.03 92.71
Evasive 77.03 76.27 76.11 25.45 31.93 89.76
3Poisoning 78.42 78.86 78.14 39.51 33.29 92.90
Evasive 78.38 78.80 78.18 27.17 34.29 89.46
HeCo1Poisoning 76.02 76.91 73.99 41.67 35.32 79.97
Evasive 76.68 77.60 78.28 37.72 36.07 79.32
2Poisoning 79.43 79.74 78.48 44.75 38.29 82.55
Evasive 78.27 79.28 78.62 39.53 39.06 83.73
3Poisoning 80.27 82.44 80.52 46.35 41.64 84.14
Evasive 81.37 82.09 80.71 40.60 40.18 85.36
IMDBDMGI1Poisoning 36.89 39.09 45.08 0.84 1.05 67.49
Evasive 38.93 41.41 43.56 0.96 1.07 71.27
2Poisoning 37.25 39.54 45.43 1.17 1.12 68.25
Evasive 39.47 42.52 44.66 1.40 1.27 71.73
3Poisoning 38.35 40.14 46.39 1.28 1.23 70.42
Evasive 40.67 40.81 44.94 1.63 1.39 71.60
HDMI1Poisoning 36.89 39.09 45.08 0.84 1.05 67.49
Evasive 38.93 41.41 43.56 0.96 1.07 71.27
2Poisoning 37.45 40.23 45.66 1.12 1.38 69.71
Evasive 39.12 42.65 46.27 1.34 1.29 74.62
3Poisoning 37.80 40.74 46.04 1.45 1.72 71.25
Evasive 39.76 43.39 46.11 1.57 1.38 75.76
HeCo1Poisoning 38.46 37.56 41.88 0.25 -0.13 85.23
Evasive 39.53 43.35 43.40 0.46 -1.14 79.93
2Poisoning 39.57 41.21 42.08 0.43 0.21 85.92
Evasive 40.14 43.95 44.34 0.39 -0.12 80.64
3Poisoning 40.27 41.69 42.72 0.67 0.44 86.41
Evasive 40.72 44.52 44.85 0.51 0.27 80.55
Table 12: The impact of homophily ratio on attack perfor-
mances. "HR" represents the homophily ratio. " ↓(%)" repre-
sents the percentage of average performance degradations
compared to clean data.
Dataset ACM Aminer Freebase IMDB
Metapaths PAP PSP PAP PRP MAM MDM MWM MAM MDM
HR (%) 80.85 63.93 95.95 86.10 69.19 83.02 64.29 43.56 56.53
Avg HR (%) 72.39 91.02 72.17 50.05
↓(%) of node classification 10.25∼15.67 15.16∼24.50 10.56∼27.49 11.22∼18.68
↓(%) of node clustering 24.65∼43.54 57.71∼86.88 27.77∼83.53 75.03∼88.72
↓(%) of metapath prediction 6.76∼11.15 5.31∼8.28 5.82∼8.59 7.45∼10.22Table 9: The table of symbol interpretation.
Symbol Interpretation
G Heterogeneous graph
V The set of nodes
E The set of edges
A The sets of node types
R The sets of edge types
eG The attacked heterogeneous graph
𝑋 The feature matrix of the target nodes
𝑥𝑖 Node feature of node 𝑖
𝑟 The type of edge
𝐴𝑟 Adjacency matrix for edge type 𝑟
(1),(2) Two augmented views
G(1),G(2)The different augmented views of G
{P1,P2,···P𝑚} The metapaths
{𝐴P1,𝐴P2,···,𝐴P𝑚} Adjacency matrix based on metapath
𝑑𝑖 The degree of node 𝑖
NP𝑛
𝑖The neighbor set of node 𝑖based on metapathP𝑛
q The semantic-level attention vector
𝛽𝑛 The important weight of metapath P𝑛
𝐻 The learned node representation matrix
ℎ𝑖 The learned node representation of node 𝑖
P𝑖 The positive samples of node 𝑖
N𝑖 The negative samples of node 𝑖
𝑀𝐿𝑃(·) A two-layer fully-connected network
𝑧𝑖 The representation of node 𝑖projected by𝑀𝐿𝑃(·)
𝐺𝐴𝑟The gradients of the adjacent matrix for relation 𝑟
ˆ𝐺𝐴𝑟Existent edges in 𝐴𝑟
ˇ𝐺𝐴𝑟Inexistent edges in 𝐴𝑟
𝛿 The attack ratio
𝑆𝑑𝑒𝑙𝑟The candidate set of deleted edges of type 𝑟
𝑆𝑎𝑑𝑑
𝑟,𝑖The candidate set of added edges of type 𝑟for node𝑖
𝑒𝑟
𝑖,𝑗The edge with type 𝑟between node𝑖and𝑗
𝑤𝑟,𝑑𝑒𝑙
𝑖,𝑗The probability that edge 𝑒𝑟
𝑖,𝑗will be deleted.
𝑤𝑟,𝑎𝑑𝑑
𝑖,𝑘The probability that edge 𝑒𝑟
𝑖,𝑗will be added.
CeC The node cluster assignment matrices of GandeG
L The loss function
|| The concatenation operation
𝜎 The ReLU function
W,𝑊𝑟 The learnable weight matrices
b,𝑏𝑟 The learnable bias
E.2 The impact of the number of GCN layers
We show the experimental results for GCNs with the different 
number of layers in Table 11. The results show that the attack 
performances are best when the GCN is 1 layer. And  the attack 
performances decrease as the number of layers increases.
E.3 The impact of graph homophily on HGAC
Refer to [6], we calculated the graph homophily of various datasets 
by measuring the homophily ratio of each metapath subgraph. And, 
we reported the attack performances with different homophily 
ratios. Results can be found in Table 12. The results show that the 
attack performances have no significant correlation with graph 
homophily.
3068