VertiMRF: Differentially Private Vertical Federated Data Synthesis
Fangyuan Zhao
Xi’an Jiaotong University
Xi’an, China
zfy1454236335@stu.xjtu.edu.cnZitao Li
Alibaba Group
Bellevue, United States
zitao.l@alibaba-inc.comXuebin Ren
Xi’an Jiaotong University
Xi’an, China
xuebinren@mail.xjtu.edu.cn
Bolin Ding
Alibaba Group
Bellevue, United States
bolin.ding@alibaba-inc.comShusen Yang∗
Xi’an Jiaotong University
Xi’an, China
shusenyang@mail.xjtu.edu.cnYaliang Li∗
Alibaba Group
Bellevue, United States
yaliang.li@alibaba-inc.com
Abstract
Data synthesis is a promising solution to share data for various
downstream analytic tasks without exposing raw data. However,
without a theoretical privacy guarantee, a synthetic dataset would
still leak some sensitive information in raw data. As a countermea-
sure, differential privacy is widely adopted to safeguard data syn-
thesis by strictly limiting the released information. This technique
is advantageous yet presents significant challenges in the vertical
federated setting, where data attributes are distributed among dif-
ferent data parties. The main challenge lies in maintaining privacy
while efficiently and precisely reconstructing the correlation be-
tween attributes. In this paper, we propose a novel algorithm called
VertiMRF, designed explicitly for generating synthetic data in the
vertical setting and providing differential privacy protection for
all information shared from data parties. We introduce techniques
based on the Flajolet-Martin (FM) sketch for encoding local data
satisfying differential privacy and estimating cross-party marginals.
We provide theoretical privacy and utility proof for encoding in
this multi-attribute data. Collecting the locally generated private
Markov Random Field (MRF) and the sketches, a central server can
reconstruct a global MRF, maintaining the most useful information.
Two critical techniques introduced in our VertiMRF are dimension
reduction and consistency enforcement, preventing the noise of FM
sketch from overwhelming the information of attributes with large
domain sizes when building the global MRF. These two techniques
allow flexible and inconsistent binning strategies of local private
MRF and the data sketching module, which can preserve informa-
tion to the greatest extent. We conduct extensive experiments on
four real-world datasets to evaluate the effectiveness of VertiMRF.
End-to-end comparisons demonstrate the superiority of VertiMRF.
∗Both are corresponding authors of this research. Work was done while the first author
was an intern at Alibaba Group.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
KDD ’24, August 25–29, 2024, Barcelona, Spain
©2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 979-8-4007-0490-1/24/08
https://doi.org/10.1145/3637528.3671771CCS Concepts
•Security and privacy →Privacy-preserving protocols.
Keywords
Vertical Federated Learning, Differential Privacy, Data Synthesis
ACM Reference Format:
Fangyuan Zhao, Zitao Li, Xuebin Ren, Bolin Ding, Shusen Yang, and Yaliang
Li. 2024. VertiMRF: Differentially Private Vertical Federated Data Synthesis.
InProceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery
and Data Mining (KDD ’24), August 25–29, 2024, Barcelona, Spain. ACM, New
York, NY, USA, 12 pages. https://doi.org/10.1145/3637528.3671771
1 Introduction
With the increasing stringency of data privacy regulations such as
the European General Data Protection Regulation (GDPR) [ 52] and
the California Consumer Privacy Act [ 40], data privacy has become
a significant concern for various data analysis tasks. Following this
trend, data synthesis has emerged as a promising technique. For the
tabular data domain, the synthesis algorithms aim to generate and
release synthetic data that preserves the statistical characteristics
of the original data, allowing for diverse data analysis tasks to be
conducted without access to the original real data from individuals.
Coupled with differential privacy (DP) [ 10,43,61,63] techniques,
the synthetic data can provide theoretical privacy guarantees for
arbitrary individual records in the original datasets. Compared with
other DP algorithms for specific analytic tasks, DP data synthesis
can support an unlimited number of unrestricted downstream tasks
without additional privacy loss other than the one occurring during
data synthesis [ 17]. The main challenge emerges when ensuring
DP while generating synthetic data of high quality. A growing
body of academic research [ 2,4,5,11,19,34,35,42,54,60–62] has
focused on improving the trade-off between privacy and utility of
DP synthetic data and already obtained promising results. However,
these studies primarily focus on the centralized setting, assuming
that the raw data has already been collected by a trusted curator.
To realize the value of data at the furthest level, multiple data par-
ties may want to cooperate on some tasks for more comprehensive
and accurate information. If such cooperation is achieved with-
out sharing data directly, the setting is generally called federated
learning (FL) [ 20,28,59]. A relatively well-studied scenario in FL is
that data parties have data with the same set of attributes but from
different groups of individuals. This scenario is called horizontal
federated learning (HFL) because the local dataset can be obtained
4431
KDD ’24, August 25–29, 2024, Barcelona, Spain Fangyuan Zhao, Zitao Li, Xuebin Ren, Bolin Ding, Shusen Yang, and Yaliang Li
by splitting a virtual global dataset by individuals [ 36]. Under such
a setting, several studies have focused on DP data synthesis un-
der the horizontally distributed [ 48] and local DP settings [ 44].
Nevertheless, another attractive but challenging case is when data
parties have data from the same set of individuals but on different
attributes [ 16,29,30,32]. Symmetrically, this setting is called ver-
tical federated learning (VFL) as local datasets can be derived by
dividing a global dataset by attributes. VFL techniques attract the
attention of many medical or fintech companies [ 55] because their
model accuracy can be boosted by more comprehensive informa-
tion brought by VFL. In this paper, we focus on data synthesis in
the VFL setting as it has great potential in various aspects.
1) It facilitates the cross-party data analysis. Simply combining the
synthetic data generated independently by the multiple parties
loses the statistical property of cross-party attributes. However,
when a VFL data synthesis algorithm that accurately captures the
cross-party correlation is available, any downstream correlation
analysis can be done efficiently once the synthetic data is ready. 2) It
enable validating or tuning general VFL algorithms under controllable
privacy risk. For example, VFL tasks often involve substantial costs
for hyperparameter tuning among multi-parties, due to the strict
limitations of cross-party data access. Releasing a synthetic dataset
that preserves the statistical characteristics of the original data can
help select optimal hyper-parameters before model training.
Despite the great potential, there are following challenges that
hinder the practical applications.
C1: Information loss when estimating cross-party attribute correla-
tions. Unlike algorithms in the central setting that can access all data
attributes, VFL synthesis algorithms that can faithfully generate
data in global-view must have components to estimate the corre-
lation of the cross-party attributes, either explicitly or implicitly.
However, such estimation must suffer information loss because of
either the distillation of raw data or added randomness for privacy.
C2: Composing and trade-off the intra-party and cross-party informa-
tion. It is known that statistics estimated in the central DP setting
can have higher accuracy than the same ones obtained in the dis-
tributed DP settings. Although the intuitive idea following this is
to utilize as much information as possible that does not rely on
cross-party cooperation, how to effectively and efficiently combine
and balance this information with estimated cross-party correlation
information remains to be explored.
C3: Curse of dimensionality. In VFL settings, a record may contain
multiple attributes that distributed among multiple parties, each
attribute with large domain size. In this case, there are multiple
cross-party attribute combinations to estimate, which would intro-
duce overwhelming noises and huge communication costs.
Although there are a few works on DP data synthesis under the
vertical setting, they still have limitations related to the challenges
above. DistDiffGen [ 38] is a two-party DP data synthesis framework.
It falls short of handling C1 and C3 because it relies on a given
taxonomy tree requiring strong prior knowledge and is tailored
to classification tasks only. VertiGAN [ 18] adapts the DP-WGAN
approach to vertical setting [ 18]. However, the GAN-based models
are proven to be not suitable for synthesizing tabular data with DP,
which indicates that C1 and C2 still hinder its practical application.
DPLT [ 50] utilizes a latent tree model to capture the correlation
among cross-party attributions. However, its application is limitedby C3 because it is designed for datasets with binary attributes
and suffers from the huge communication and computation costs
incurred by the complicated cryptography protocol.
To handle the challenges, we propose VertiMRF for generating
high-quality synthetic data with differential privacy guarantees in
the VFL setting with multiple data parties and a semi-honest central
server. Our key observation is that the central DP data synthesis
can achieve great performance in terms of privacy-utility trade-off,
and the cross-party statistic estimation is necessary but may un-
avoidably be less accurate. Thus, VertiMRF adapts, combines, and
balances these two components. VertiMRF adapts PrivMRF [ 4] to
capture and share differentially private intra-party attribute statis-
tic information. We then design special protocols to let the data
parties encode and the server decode the cross-party attribute corre-
lation information. With both intra-party and cross-party attribute
correlation information, the server can reconstruct a global MRF
for full-view data synthesis. Our key contributions assembled in
VertiMRF are summarized as follows:
•We propose a communication efficient and differentially private
vertical data synthesis framework VertiMRF. VertiMRF merges
a sequence of strategies that allow an untrusted server to con-
struct a global Markov Random Field by merging and balancing
differential private encoded information.
•We incorporate a novel Flajolet-Martin (FM) sketch based ap-
proach to estimating cross-party multi-attribute marginals. This
approach is a key component of VertiMRF to estimate cross-party
correlations with relatively low error while protecting privacy.
Theoretical privacy guarantee and error analysis are provided.
•We design two critical techniques into VertiMRF to prevent the
noise of FM-sketch from obscuring the useful information of
attributes with large domain sizes when building the global MRF,
including a dimension reduction technique to tune the granulari-
ties of attributes while preserving the statistical information and
a consistency enforcement technique to maintain the consistency
among frequencies of different granularities.
•We conduct empirical validation on four real-world datasets. The
end-to-end comparison results demonstrate the superiority of our
approach to the baseline algorithms. Furthermore, the impact and
effectiveness of each component of our approach are validated
by ablation studies.
2 Preliminaries
2.1 Differential Privacy
Differential privacy is a rigorous privacy notion that quantifies the
privacy loss of algorithms by analyzing the statistical difference
between the algorithm outputs on neighboring datasets differing
on only one record.
Definition 1 (Differential Privacy [ 10]).A randomized mechanism
Msatisfies(𝜖,𝛿)-DP if for any neighboring datasets 𝐷,𝐷′that
differ on only one record, their outputs fall in any 𝑅⊂𝑅𝑎𝑛𝑔𝑒(M)
with probability 𝑃𝑟[M(𝐷)⊆𝑅]≤exp(𝜖)𝑃𝑟[M(𝐷′)⊆𝑅]+𝛿.
2.2 DP Flajolet-Martin Sketch
Flajolet-Martin (FM) Sketch is a probabilistic data structure for
multi-set cardinality estimation with DP guarantee. It is constructed
4432VertiMRF: Differentially Private Vertical Federated Data Synthesis KDD ’24, August 25–29, 2024, Barcelona, Spain
by hashing each element in a multi-set to an integer by a hash
functionHwith a key𝜉. The hashed integers are then independent
geometric random variables with the parameter𝛾
1+𝛾if𝜉is sampled
from a large set uniformly. Note that, the duplicated elements in
the multi-set are mapped to the same integer. The cardinality 𝑘can
be estimated as 𝑘=(1+𝛾)𝛼where𝛼denotes the maximum of the
observed integer after hashing.
The FM sketch-based cardinality estimation is widely used due to
its appealing property that the sketch structure is mergeable. That
is, given two different multi-set X1andX2and their corresponding
FM sketches 𝛼1and𝛼2, then the cardinality of their union X1∪
X2can be simply estimated as (1+𝛾)max(𝛼1,𝛼2). Based on this
and the inclusion-exclusion principle, i.e., X1∩X 2=X2∪X2,
the cardinality of the intersection of two multi-sets can also be
estimated. Recent studies [ 8,47] have demonstrated that FM-sketch
can preserve DP under certain conditions. Specifically, if inserting
𝑘𝑝=1
𝑒𝜖−1phantom elements into the multi-set and ensuring the
maximum of the geometric random variables is lower bounded by
⌈log1+𝛾1
1−𝑒−𝜖⌉, then the process of selecting the maximum of these
random variables ensures 𝜖-DP. The DP FM-sketching algorithm is
detailed in Algorithm 2 in Appendix A.
2.3 DP Data Synthesis
Let𝐷be a set of data tuples {𝑥(1),...,𝑥(𝑛)}. Each tuple consists
of values of a set of attributes A={𝐴1,...,𝐴𝑑}. Each attribute
𝐴𝑗,∀𝑗∈[𝑑]has domain size 𝑢𝑗. Without loss of generality, we
denote the domain of 𝐴𝑗as[𝑢𝑗]≜{1,...,𝑢𝑗}. With𝑀⊂A,𝑥(𝑙)
𝑀
denotes the values of tuple 𝑥(𝑙)on an attribute set 𝑀. Let𝑇𝑀be the
counts of occurrences of all possible value tuples of attributes 𝑀in
𝐷. That is,𝑇𝑀is a vector of lengthÎ
𝐴𝑗∈𝑀𝑢𝑗and each element is
defined as
𝑇𝑀[v]=∑︁
𝑙∈[𝑛]I(𝑥(𝑙)
𝑀=v),∀v∈Ö
𝐴𝑗∈𝑀[𝑢𝑗] (1)
𝑇𝑀is referred as the contingency histogram of𝑀.
Data synthesis focuses on generating a dataset ˆ𝐷given𝐷such
that ideally∀𝑀⊆A,ˆ𝑇𝑀≈𝑇𝑀. A key challenge of DP data syn-
thesis is to circumvent the curse of dimensionality incurred by a
large𝑑. As𝑑increases, the error of 𝑇Agrows exponentially, as DP
noise has to be added to each count of the contingency histogram.
To address this challenge, there have been works [ 4,34,35,60,62]
that propose to utilize low-way marginal distributions to approxi-
mate the high-way distribution without losing much correlations
among the attributes. Among these, PrivMRF [ 4], utilizing Markov
Random Field (MRF) to model the attribute correlations, shows the
state-of-the-art performance. PrivMRF consists of four phases:
•Phases 1: Generate attribute graph. PrivMRF starts by gen-
erating an attribute graph Gthrough greedily linking up each
attribute pair(𝐴𝑖,𝐴𝑗)in the descending order of noisy R-scores:
𝑅(𝐴𝑖,𝐴𝑗)=𝑛
2𝑃𝑟[𝐴𝑖,𝐴𝑗]−𝑃𝑟[𝐴𝑖]·𝑃𝑟[𝐴𝑗]1+N( 0,𝜎2
𝑅).(2)
•Phases 2: Choose candidate marginal set. PrivMRF samples a
set of candidate marginals Ufrom the cliques of triangulated G
and ensure each marginal 𝑀∈U satisfies that𝑛Î
𝐴𝑖∈𝑀𝑢𝑖≤𝜃·𝑔,where𝑔denotes the expected absolute value of the noise to be
injected into each count of 𝑇𝑀.
•Phases 3: Initialize the marginal set. FromU, PrivMRF selects
the most highly correlated marginal for each attribute to consti-
tute an initialized marginal set S, which is used to estimate the
parameters Θof the MRF. Θis a real vector where each element
corresponds to an entry in a contingency histogram 𝑇𝑀,∀𝑀∈S.
The MRF models the distribution of arbitrary tuple 𝑥as:
𝑃𝑟[𝑥]∝Ö
𝑀∈Sexp(Θ𝑀[𝑥𝑀]) (3)
where Θ𝑀denotes the sub-vector of Θcorresponding to 𝑀, and
Θ𝑀[𝑥𝑀]is the element corresponding to 𝑥𝑀.
•Phases 4: Refine the marginal set. PrivMRF proceeds to refine
the marginal setSby inserting marginals that cannot be accu-
rately inferred by the MRF and iteratively refine the estimation
of MRF.
3 Differentially Private Vertical Data Synthesis
We provide the problem definition of DP data synthesis in the
vertical setting and an overview of our solution in this section.
3.1 Problem Definition
We consider a system constituted by 𝑚data parties and an untrusted
central server orchestrating the overall process. Each data party
P𝑖,∀𝑖∈[𝑚], possesses users’ data 𝐷𝑖={𝑥(1)
A𝑖,...,𝑥(𝑛)
A𝑖}with a
subset of attributes A𝑖⊂A . We assume that the user’s data has
been aligned across these 𝑚data parties by some record ID (e.g.,
social security number and phone number) with some private set
intersection method [ 6,9,22]. That is,𝑥(𝑙)
A𝑖and𝑥(𝑙)
A𝑗are data tuples
of a same individual 𝑙but on different attributes. The aligned data
is a common setting with the vertical tasks [ 7,15,31,58]. Virtually
speaking, there is a global dataset 𝐷=(𝐷1|...|𝐷𝑚)with attributes
A=∪𝑖∈[𝑚]A𝑖if all data parties’ data can be merged.
Adversary model. We consider the central server to be honest but
curious, which would execute the protocol honestly but try his best
to infer the private information of the input dataset. However, we
assume that none of data parties is interested in colluding with
the server because privacy regulations prevent data parties from
doing so. We consider the adversary outside the system as all the
third-party data analysts who aim to infer some private information
from the synthetic dataset and the intermediate results carried out
in the communication between data parties and the server.
Our goal. Our work aims to generate a collection of synthetic data ˆ𝐷
with attributesA, which follows the data distribution as the virtual
global dataset 𝐷as closely as possible while protecting the privacy.
3.2 Overview of Our Solution
With the known private data synthesis algorithms, such as PrivMRF,
each client can publish their local private data; then a full-view
synthetic data can be derived by composing the data of different at-
tributes together. Despite this straightforward idea, the cross-party
attribute correlations are completely lost. Thus, we need to solve
the following three problems when improving the synthetic data
utility while preserving data privacy: 1) How to estimate cross-
party attribute correlations with comparable utility and provable
4433KDD ’24, August 25–29, 2024, Barcelona, Spain Fangyuan Zhao, Zitao Li, Xuebin Ren, Bolin Ding, Shusen Yang, and Yaliang Li
Optimize 𝚯 OptMRF
Parameterized as 𝚯 Centralserver
Local party 2Local party 1
Estimate 𝚯 Phase 5InitMRFGraphComLocMRFLocEncPhase 6Phase 4Phase 3Phase 2Phase 1
Infer with 𝚯 Synthesis
LocMRFLocEncPhase 1Phase 2
ID𝑨𝟏…𝑨𝟒1…ID𝑨𝟓…𝑨𝟖1…Attr𝑴𝟏𝑨𝟏𝑀$……𝑨𝟒𝑀&Attr𝑴𝟐𝑨𝟓𝑀(……𝑨𝟖𝑀)
Figure 1: Workflow of VertiMRF
mem.𝐴!𝐈"!"𝐈"#"𝐈"$"mem.𝐴#𝐈"!%𝐈"#%DPFM𝑴𝒊𝜶"!"𝜶"#"𝜶"$"𝑴𝒋𝜶𝑣1𝑗𝜶𝑣2𝑗𝑛	−	|𝐈"!"∩𝐈"!%||𝐈"#"∪𝐈"$"∪𝐈"#%|max𝑇'[𝑣(!,𝑣(#]	=estimate=inclusion-exclusionDPFMDPFMDPFMDPFMLocEncCarEstCentralserver Figure 2: LocEnc and CarEst.
privacy guarantee? 2) How to merge and tradeoff the intra-party
and cross-party attribute correlations estimated with different es-
timation errors while preserving as more useful information as
possible? 3) How to tackle the curse of dimensionality, i.e., the
overwhelming noises, when domain sizes of attributes are large?
By solving the three problems, we propose VertiMRF , a novel
DP data synthesis approach. As shown in Figure 1 and Algorithm 1,
VertiMRF can be divided into the following six phases:
•Phase 1: Each partyP𝑖constructs a local Markov Random Field
MRF𝑖to capture the correlation among local attributes A𝑖. Besides,
P𝑖preserves the inner results, including the local attribute graph
G𝑖and the marginal set S𝑖(sub-procedure LocMRF).
•Phase 2: Each partyP𝑖encodes local dataset with attributes
A𝑖via differentially private FM sketch. Both the codes M𝑖and
{MRF𝑖,G𝑖,S𝑖}are sent to the server (sub-procedure LocEnc).
•Phase 3: The server generates a global attribute graph Gby
combining received disjoint local attribute graphs {G𝑖|𝑖∈[𝑚]}.
In the combining, server links up cross-party attribute pairs with
higher R-scores estimated over the encoded attributes {𝑀𝑖,𝑖∈
[𝑚]}. (sub-procedure GraphCom).
•Phase 4: The server initializes a marginal set Sby taking the
union of the received local marginal set {S𝑖|𝑖∈[𝑚]}. Based on
S, the parameter Θof the global MRF is initialized with each
contingency histogram 𝑇𝑀,∀𝑀∈Sinferred from the received
local MRFs (sub-procedure InitMRF).
•Phase 5: The server selects a set of cross-party marginals S𝑐
from the cliques of G. Based on theS𝑐,Θis further optimized.
In the optimization, each contingency histogram 𝑇𝑀,∀𝑀∈S𝑐is
estimated over the encoded attributes (sub-procedure OptMRF).
•Phase 6: The server generates synthetic data by sampling from
the data distribution approximated by the global MRF.
In what follows, we show the solution for Phase 1-2 in Section 4
which describes the DP information sharing approaches of each
local party. Then we describe Phase 3-6 in Section 5, presenting
how to use the shared DP information to construct a global MRF.
4 Differentially Private Information Sharing
Based on our security setting and DP’s resistance to post-processing,
the key to satisfying privacy protection is to ensure differential
privacy guarantee for all the information shared from local parties,
which are the outputs of LocMRF inPhase 1 andLocEnc Phase 2
(in brackets Figure 1). Thus, we introduce the algorithms for LocMRFAlgorithm 1 VertiMRF
Input: The partitioned dataset 𝐷={𝐷𝑖,𝑖∈[𝑚]}, domain([𝑢1]×
...×[𝑢𝑑]), maximal clique size 𝜏, total privacy budget (𝜖,𝛿)is
divided as𝜖0=𝜖
2𝑚,𝛿0=𝛿
2𝑚,𝜖1=𝜖
2,𝛿1=𝛿
2.
Output: Synthesized data ˆ𝐷.
1:Each local partyP𝑖:
(a). constructs local MRF:{MRF𝑖,G𝑖,S𝑖}← LocMRF(𝐷𝑖,𝜏,𝜖 0,𝛿0).
2:Each local partyP𝑖:
(a). encodes local attributes: M𝑖←LocEnc(𝐷𝑖,A𝑖,𝜖1,𝛿1).
(b). sendsM𝑖and{MRF𝑖,G𝑖,S𝑖}to server.
3:Central server:
(a). generates global graph: G←GraphCom({G𝑖,M𝑖|𝑖∈[𝑚]}).
4:Central server:
(a). initializes marginal set: S←Ð𝑚
𝑖=1{S𝑖}.
(b). initializes parameter Θof the global MRF based on S.
5:Central server:
(a). selects cross-party marginals S𝑐from triangulatedG.
(b). optimizes Θbased onS𝑐.
6:Central server:
(a). samples ˆ𝐷based on the optimized global MRF.
andLocEnc (together with its closely paired CarEst ), providing
bases of the following synthesis steps.
4.1 Local PrivMRF in Phase 1
Each local partyP𝑖directly applies the PrivMRF approach to con-
struct MRF𝑖. As shown in Section 2.3, there would be inner results
generated when constructing MRF𝑖, including the attribute graph
G𝑖and the refined marginal set S𝑖. Apart from MRF𝑖, bothG𝑖and
S𝑖should also be preserved and sent to the central server. Notably,
because the maximal clique size for the global MRF is always lim-
ited to control the complexity of the attribute graph, the maximal
clique size of each local MRF should also be limited. The maximal
local clique size for each MRF𝑖is set as𝜏′≤𝜏
𝑚·¯𝑢2, with ¯𝑢=Í
𝑗𝑢𝑗
𝑑
and𝜏is threshold of the clique size for global MRF. The constructed
MRF𝑖captures the correlations among the local attributes.
4.2 Sketch-based LocEnc and CarEst
As explained in Section 2.2, FM sketch can be used to estimate the
cardinality of a multi-set. And the estimation process can easily
satisfy DP by incorporating phantom elements and bounding the
maximum value of the hashed geometric variables. Building on
4434VertiMRF: Differentially Private Vertical Federated Data Synthesis KDD ’24, August 25–29, 2024, Barcelona, Spain
this idea, we design our sketch-based LocEnc andCarEst . Figure 2
visualizes the rationale of both sketch-based LocEnc andCarEst.
Sketch-based LocEnc .Each data partyP𝑖encodes the membership
information of local attribute 𝐴𝑗using an FM sketch. This infor-
mation, denoted as
I𝑣𝑗
1,...,I𝑣𝑗
𝑢𝑗
, consists of 𝑢𝑗ID sets. Each set
I𝑣𝑗
𝑖contains the IDs of records 𝑥with𝑥(𝐴𝑗)=𝑣𝑗
𝑖. The sketch-based
LocEnc involves two main procedures: the generation of hash keys
and the generation of sketches.
Due to privacy concern, hash keys should be collaboratively
generated by data parties and kept unknown to the central server.
There are multiple secure multi-party computation (SMC) proto-
cols can be applied to achieve this, such as the Diffie-Hellman
protocol [ 23], which allows multiple parties to negotiate a random
number securely even if the central server is semi-honest [23].
Next, each party encodes the membership information of lo-
cal attributes using DPFM (Algorithm 2) algorithm with the gen-
erated hash key 𝜉. Specifically, for the membership information
{I𝑣𝑗
1,...,I𝑣𝑗
𝑢𝑗}of attribute𝐴𝑗∈A𝑖, partyP𝑖applies the DPFM algo-
rithm to each I𝑣𝑗
𝑖with a given privacy budget 𝜖′. This generates a DP
FM sketch tuple(𝛼𝑣𝑗
1,...,𝛼𝑣𝑗
𝑢𝑗)for𝐴𝑗∈A𝑖. Considering all local
attributes, partyP𝑖composes a tuple set {(𝛼𝑣𝑗
1,...,𝛼𝑣𝑗
𝑢𝑗)|𝐴𝑗∈A𝑖}.
To enhance utility, this process is repeated 𝑡times, and partyP𝑖
sends𝑡tuple sets(
M(ℎ)
𝑖≜( 
𝛼(ℎ)
𝑣𝑗
1,...,𝛼(ℎ)
𝑣𝑗
𝑢𝑗!𝐴𝑗∈A𝑖)ℎ∈[𝑡])
to the server.
Sketch-based CarEst .As mentioned in Section 2.2, the FM sketch
enables us to estimate the cardinality of the intersection of multi-
ple sets using the inclusion-exclusion principle. This property can
be extended to the DP FM sketch, allowing the central server to
estimate the contingency histogram of a marginal.
After receiving all sketches from data parties, the central server
aggregates them into 𝑡sets of sketch tuples
(
M(ℎ)≜( 
𝛼(ℎ)
𝑣𝑗
1,...,𝛼(ℎ)
𝑣𝑗
𝑢𝑗!
|𝑗∈[𝑑])
|ℎ∈[𝑡])
.
For each𝑙-way marginal 𝑀=(𝐴1,...,𝐴𝑙), the estimation of the
contingency histogram 𝑇𝑀involves estimating the cardinality of
the intersection setÑ𝑙
𝑖=1I𝑣(𝑖)for each(𝑣(1),...,𝑣(𝑙))∈Î𝑙
𝑖=1[𝑢𝑖].
Here, I𝑣(𝑖)represents the membership information of attribute
𝐴𝑖with value 𝑣(𝑖). Using the inclusion-exclusion principle (i.e.,
Ñ𝑙
𝑖=1I𝑣(𝑖)=Ð𝑙
𝑖=1I𝑣(𝑖)), the cardinality ofÑ𝑙
𝑖=1I𝑣(𝑖)can be deter-
mined by calculating the cardinality ofÐ𝑙
𝑖=1I𝑣(𝑖), whereXdenotes
the complementary set of X. Thus, estimating the cardinality of
an intersection is transformed into estimating the cardinality of
the complementary set of a union. The basic approach to estimateÐ𝑙
𝑖=1I𝑣(𝑖)is as follows: first, estimateÐ𝑙
𝑖=1I𝑣(𝑖)using the merge-
able property of sketches, and then subtract this estimate from a
DP sanitized data number ˆ𝑛.
For eachM(ℎ)among all𝑡sketch sets, the sketch of I𝑣(𝑖)can be
estimated by max
𝛼(ℎ)
𝑣𝑖
𝑗|𝑗∈[𝑢𝑖],𝑣𝑖
𝑙≠𝑣(𝑖)
. Here,𝛼(ℎ)
𝑣𝑖
𝑗representsthe sketch corresponding to attribute 𝐴𝑖with value𝑣𝑖
𝑗. Furthermore,
the sketch ofÐ𝑗
𝑖=1I𝑣(𝑖)can be estimated by
max
max
𝛼(ℎ)
𝑣𝑖
𝑗|𝑗∈[𝑢𝑖],𝑣𝑖
𝑗≠𝑣(𝑖)
|𝐴𝑖∈𝑀
.
After obtaining 𝑡estimates of the sketch ofÐ𝑗
𝑖=1I𝑣(𝑖), a more stable
and accurate estimate 𝛼can be obtained by taking the harmonic
mean. Furthermore, since the above sketch estimation process in-
volves max operations onÍ𝑙
𝑖=1(𝑢𝑖−1)sketches, each of which
introduces𝑘𝑝phantom elements as shown in Section 2.2, there
should beÍ𝑙
𝑖=1(𝑢𝑖−1)
·𝑘𝑝phantom elements taken into ac-
count in total. By subtracting those phantom elements,Ð𝑙
𝑖=1I𝑣(𝑖)
can be estimated by (1+𝛾)𝛼−Í𝑙
𝑖=1(𝑢𝑖−1)
·𝑘𝑝. Finally, the car-
dinality ofÑ𝑙
𝑖=1I𝑣(𝑖)can be obtained by subtracting the estimatedÐ𝑙
𝑖=1I𝑣(𝑖)from a DP sanitized data number ˆ𝑛and ensuring the
non-negativity.
Theorem 2 (Privacy Analysis). Suppose the FM sketch 𝛼(ℎ)
𝑣𝑖
𝑗
for value𝑣𝑖
𝑗of attribute𝐴𝑖is generated with 𝜖′-DP in theℎ-th run.
Then, the sketch-based LocEnc method in Algorithm ??guarantees
(4𝜖′√︁
𝑡𝑑log(1/𝛿),𝛿)-DP for all𝛿<1.
Theorem 3 (Error Analysis). Let𝑀={𝐴1,...,𝐴𝑙}be an𝑙-
way marginal, ˆ𝑇𝑀be the contingency histogram of 𝑀estimated using
sketch-based CarEst with privacy parameter (𝜖,𝛿)and distribution
parameter𝛾. For each v∈Î𝑙
𝑖=1[𝑢𝑖], the following inequality holds:
|ˆ𝑇𝑀[v]−𝑇𝑀[v]|
𝑇𝑀[v]≤𝛾·(𝑛
𝑇𝑀[v]−1)+ˆ𝑁+𝐶
𝑇𝑀[v], (4)
with a probability of at least 1−𝛽. Here, ˆ𝑁represents the Laplacian
noise added to the data number 𝑛, and𝐶=𝑂(log1/2(1/𝛿)log1/4(1/𝛽)
𝜖′).
Due to space limitation, proofs are shown in Appendix C. As
stated in Theorem 3, the relative error tends to be larger when the
proportion of 𝑇𝑀[v]in𝑛decreases or when 𝑇𝑀[v]decreases.
4.3 Privacy and Communication Cost
Overall Privacy Analysis. As shown in Algorithm 1, LocMRF on
all𝑚parties consumes(𝑚·𝜖
2𝑚,𝑚·𝛿
2𝑚)-DP. As stated in Theorem 2,
the remaining(𝜖
2,𝛿
2)-DP is allocated for encoding the 𝑑attributes
for𝑡iterations in LocEnc . According to the sequential composition
property of DP, we can conclude that VertiMRF satisfies(𝜖,𝛿)-DP.
Communication Cost. There is one communication round be-
tween each partyP𝑖and the central server in VertiMRF. The com-
munication includes encoded attributes M𝑖and the local MRF
information{MRF𝑖,S𝑖,G𝑖}. For sketch-based LocEnc ,M𝑖contains
𝑡Í
𝐴𝑗∈A𝑖𝑢𝑗sketches. MRF𝑖is parameterized by a vector Θwith
lengthÍ
𝑀∈𝑆𝑖Î
𝐴𝑗∈𝑀𝑢𝑗, controlled by the maximal clique size 𝜏′
for each local MRF. G𝑖is represented by a(|A𝑖|×|A𝑖|)-dimensional
adjacent matrix, with |A𝑖|<𝑑. The information in S𝑖, which con-
tains several attribute tuples, can be ignored in terms of communi-
cation costs. Considering a total of 𝑚parties, the communication
cost of VertiMRF is𝑂(𝑡𝑑¯𝑢)+𝑂(𝑑2)+𝑂(𝑚𝜏′). Here ¯𝑢=Í
𝑗𝑢𝑗
𝑑.
4435KDD ’24, August 25–29, 2024, Barcelona, Spain Fangyuan Zhao, Zitao Li, Xuebin Ren, Bolin Ding, Shusen Yang, and Yaliang Li
5 MRF Generation in Central Server
After receiving local MRFs and encoded attributes Mfrom all parties,
the process of the central server can be divided into the following
phases: generating the global attribute graph (Phase 3), initializing
the marginal set thereby estimating the MRF parameter (Phase 4),
refining the marginal set thereby optimizing the MRF parameter
(Phase 5) and finally sampling the synthetic data (Phase 6).
5.1 GraphCom in Phase 3
Since the local attribute graphs are disjoint and each one accurately
represents the correlation among a subset of attributes, a basic
approach to creating a global attribute graph is to combine the
disjoint graphs by linking up certain cross-party attribute pairs.
However, there are two constraints (CSTR) that must be satisfied
when selecting such cross-party attribute pairs, denoted as (𝐴𝑖,𝐴𝑗):
•CSTR1:(𝐴𝑖,𝐴𝑗)should exhibit strong correlation.
•CSTR2: The domain size of maximal cliques in the resulting at-
tribute graph should not exceed a predefined threshold value 𝜏.
To satisfy CSTR1, the central server estimates the R-score [ 4]
𝑅(𝐴𝑖,𝐴𝑗)for each cross-party attribute pair (𝐴𝑖,𝐴𝑗)with CarEst
approach introduced in Section 4 over the received encoded at-
tributesM:𝑅(𝐴𝑖,𝐴𝑗) ≈ˆ𝑛
2ˆ𝑇(𝐴𝑖,𝐴𝑗)
ˆ𝑛−ˆ𝑇𝐴𝑖
ˆ𝑛·ˆ𝑇𝐴𝑖
ˆ𝑛1,where ˆ𝑇de-
notes the estimated contingency histogram. As explained in Sec-
tion 2.3, attribute pairs with higher R-scores indicate stronger cor-
relation. After the estimation, the server sorts all attribute pairs in
descending order based on their estimated R-scores and greedily
connects them in the global attribute graph.
For CSTR2, whenever a link between cross-party attributes is
added toG, the server checks the domain size of the maximal clique
in the triangulated Gto ensure it does not exceed 𝜏.𝜏is always
set empirically to strike the tradeoff between the model utility and
computation complexity. A larger 𝜏enables more flexible marginal
selection but incur high computational efficiency. According to
our observation,[105,5×106]is an suitable range for 𝜏. If CSTR2
is satisfied, the process of adding links continues. This process
continues until it is no longer possible to satisfy CSTR2.
5.2 InitMRF in Phase 4
After generating the global attribute graph, the next step is to con-
struct the global MRF, which essentially is to learn a parameter
vector Θon a marginal setSby reducing the inferring error of Θ
onS. However, unlike the centralized setting, the central server in
the vertical setting lacks access to the raw data, it is not practical to
compute sufficiently accurate correlations over the received noisy
information to select the representative marginals to constitute S.
More severely, the true value of the contingency histograms are
unavailable to compute the inferring error of Θ. Therefore, it is
essential to select marginals that can be accurately estimated based
on the DP shared information of local parties. With the observation
that local MRFs can estimate their marginals with relative low error,
we take the union of the local marginal sets as the initialized S,
that isS=∪𝑚
𝑖=1S𝑖and take the local MRFinferred contingency
histograms∪𝑚
𝑖=1{MRF𝑖(𝑀)|∀𝑀∈S𝑖}as the ground truth of contin-
gency histograms, where MRF𝑖(𝑀)refers to the inferred result ofMRF𝑖on𝑀. Based on this ground truth and the initialized S, the
server initializes the global MRF.
5.3 OptMRF in Phase 5
After initialization, the encoded correlation in the local MRFs has
already been transferred to the global MRF. However, the correla-
tion among cross-party attributes has not been characterized by
the global MRF. To address this, the central server further refines S
by inserting cross-party marginals whose contingency histograms
can be estimated using the CarEst approach over the encoded local
attributesM. To minimize noise, we mainly select the low-way
cross-party marginals denoted as S𝑐. Specifically, the average count
in each cell of 𝑇𝑀of each marginal 𝑀∈S𝑐is controlled to be larger
than a threshold 𝑑𝑐, as given byˆ𝑛Î
𝐴𝑖∈𝑀|𝑢𝑖|≥𝑑𝑐, where𝑑𝑐controls
the error of the estimation of CarEst , which is also set empirically.
The optimization of Θinvolves multiple rounds. In each round, the
server randomly samples several cross-party marginals from S𝑐
and optimize Θmainly on the ones with significant inferring error,
as measured by the L1 distance between the inferred histograms of
the global MRF and the true values estimated using CarEst over
the encoded attributes M. Once the global MRF is constructed, the
synthetic data can be sampled from the global MRF [4].
6 Dimension Reduction and Consistency
While Phase 1 - 5 with details introduced in Section 4 and Sec-
tion 5 can seemly compose a complete algorithm for differentially
private vertical data synthesis, it still suffers the curse of dimen-
sionality when dealing with attributes with large domain sizes. A
straightforward idea is tuning the granularity of attributes. With
a coarser granularity, the LocEnc-CarEst can have smaller rela-
tive errors, but the LocMRF and global MRF becomes inferior to its
best performance with more fine-grained granularity. Thus, config-
uring different granularities for those parts can be an alternative
improvement. However, there are two issues for this inconsistent
granularity solution: 1) how to reduce dimension while keeping
as much information as possible; 2) how to enforce consistency
between the frequencies of different granularities.
6.1 Dimension Reduction
The basic idea is to approximate the high-dimensional distributions
using low-dimensional ones. According to the joint distribution for-
mula, when considering (𝐴,𝐵)as a marginal for estimation, where
𝑋and𝑌are the binned versions of 𝐴and𝐵respectively, the high-
dimensional marginal distribution can be estimated as
𝑃𝑟[𝐴,𝐵]≈∑︁
(𝑋,𝑌)𝑃𝑟[𝑋,𝑌]·𝑃𝑟[𝐴|𝑋]·𝑃𝑟[𝐵|𝑌]. (5)
Here,𝑃𝑟[𝑋,𝑌]represents the low-dimensional distribution over
the binned attributes, while 𝑃𝑟[𝐴|𝑋]and𝑃𝑟[𝐵|𝑌]are referred to as
value distributions and are also low-dimensional. Figure 3 provides
a visualization of our dimension reduction technique.
Inspired by this, we conduct equal-width binning for each at-
tribute of large domain size and preserve the value distribution in
each bin. Since value distributions contain statistical information
of attributes, Laplacian mechanism with noise scale1
𝜖′is applied to
protect each element of value distributions, where 𝜖′is the privacy
4436VertiMRF: Differentially Private Vertical Federated Data Synthesis KDD ’24, August 25–29, 2024, Barcelona, Spain
!𝑇(",$)𝑇(&,')CarEstHisRechigh-dim attrs!𝑇(&,')low-dim attrsBinning
Figure 3: Instantiation of Dimension Reduction.
budget. When computing the high-dimensional marginal distri-
bution, the proposed CarEst is applied over the binned attributes
and outputs a low-dimensional marginal distribution, based on
which and the preserved value distributions, the original marginal
distribution can be recovered according to Equation (5) (HisRec).
6.2 Consistency Enforcement
As discussed in Section 5.3, estimating contingency histograms
for intra-party and cross-party marginals in the marginal set Sis
vital for constructing the global MRF. Intra-party marginals are
estimated using local MRFs, while cross-party marginals are esti-
mated using CarEst . Nevertheless, variations in the sources of
randomness can cause inconsistencies between the estimated his-
tograms from local MRFs and CarEst for specific attribute sets. To
this end, we propose a two-step technique to ensure consistency
when estimating marginals. Before the two-steps, the estimated
contingency histograms are transformed into marginal distribu-
tions. After enforcing consistency, distributions are transformed
back to contingency histograms to optimize the global MRF.
Step 1: consistency. Letˆ𝑇𝑀1denote an marginal estimated by
CarEst ande𝑇𝑀2be an marginal estimated by LocMRF . The goal is to
ensure the consistency of ˆ𝑇𝑀1ande𝑇𝑀2on their common attributes
𝐴=𝑀1∩𝑀2. Following the method in [ 41], the basic idea is to first
establish an agreement on the marginal 𝑇𝐴of𝐴, i.e., taking the arith-
metic mean 𝑇𝐴[a]=Í
v𝐴=𝑎ˆ𝑇𝑀1[v]+Í
v𝐴=𝑎e𝑇𝑀2[v]
2,∀a∈Î
𝐴𝑗∈𝐴[𝑢𝑗]
with v𝐴denoting the value of von𝐴, and then update both ˆ𝑇𝑀1
ande𝑇𝑀2to be consistent with 𝑇𝐴by distributing the difference with
𝑇𝐴equally among all affected cells in ˆ𝑇𝑀1ande𝑇𝑀2.
Step 2: validation. After the consistency, the marginal may be-
come invalid (i.e., some probability estimations are negative, and
the sum does not equal to 1). To this end, we set the negative num-
bers to 0 and conduct normalization to validate the distribution.
The challenge emerges when we need to keep consistency and vali-
dation of marginals simultaneously, one operation may invalidate
the effect produced by another one. We iterate the two operations
multiple times to ensure the consistency and validation.
7 Experiments
In this section, we conduct end-to-end comparisons of VertiMRF to
baseline methods and validate its robust advantage under different
VFL settings.
7.1 Experiment settings
Datasets. We evaluate our algorithms on four widely used datasets [ 4,
35,60] in Table 1. NLTCS [ 33] collects 21,574 records from a study
on health status of older adults. Adult [ 3] contains 45,222 instances
obtained from IPUMS. BR2000 [ 46] consists of 38,000 records fromTable 1: Characteristics of Datasets
Dataset Records Attrs Dom. Dom. Size Attr. Split
NLTCS 21574 16 2 ≈6×1048&8
Adult 45222 15 2-42 ≈4×10148&7
BR2000 38000 13 2-21 ≈3×1097&6
Fire 305119 15 2-46 ≈1×10158&7
population Census in Brazil. Fire [ 45] includes 305,119 records of
fire unit responses to calls in San Francisco.
Metrics. We evaluate the performance based on two metrics [ 4,60,
62].𝑙-way TVD (𝑙∈{3,4}) is measured by computing the average
Total Variation Distance (TVD) between raw and synthetic data
across 300 sampled marginals from synthetic data, repeating the
process 10 times. Misclassification Rate is obtained by training
SVM classifiers using synthetic data to predict specific attributes
based on others. Using 80%raw data for synthesis and classifier
training, the misclassification rate is assessed via a test set (remain-
ing20%).
Compared methods.1We compare four methods. VertiGAN [18]
employs a partitioned GAN with a multi-output global genera-
tor and multiple local discriminators which are trained with DP-
SGD [ 1].Centralized refers to PrivMRF [ 4] in the centralized set-
ting. VertiMRF-FO &VertiMRF-FM are based on our proposed
VertiMRF framework, with one equipped with Frequency Oracle
based LocEnc approach (shown in Appendix B) and the other with
sketch-based LocEnc approach.
Parameter setting. In our experiments, we use default values for
VertiMRF-FM, setting the repetition number of the DP FM sketch
to𝑡=2000 and𝛿=1/𝑛. The network structure of VertiGAN
follows the configuration described in the original paper [ 18] and
the privacy is tracked with RDP [ 37]. For all datasets except NLTCS,
we set the binning number to 𝑏=4. As for the privacy budget
allocation, we allocate 40%toLocMRF ,40%toLocEnc (with 10%of
the40%used to generate a noisy data count ˆ𝑛), and the rest 20%for
sanitizing value distributions in the binning procedure. By default,
our algorithms are validated in a two-party setting, the attribute
distribution on the two parties is shown in the "Attr. Split" row of
Table 1, e.g., "8&7" means that 8attributes are assigned to one party
and other 7attributes are assigned to the other one.
7.2 End to End Comparisons
Comparison on 𝑙-way TVD. Figure 4 compares the methods based
on the average TVD of the 3-way and 4-way marginals. As shown,
VertiMRF-FM andVertiMRF-FO consistently produce smaller TVD
than Verti-GAN regardless of privacy cost or dataset. This demon-
strates the superiority of VertiMRF. Additionally, VertiMRF-FM out-
performs VertiMRF-FO across all cases, indicating that the sketch-
based LocEnc andCarEst can provide more accurate estimation of
the cross-party marginals compared to the FO-based approaches.
It is worth noting that VertiGAN consistently yields significantly
1In addition, we encountered the DPLT approach [ 50], which utilizes a latent tree
structure to capture attribute correlations. Despite our diligent efforts to replicate
DPLT, we faced ambiguity regarding data synthesis from the constructed tree. As a
result, we have chosen not to include DPLT in our comparison.
4437KDD ’24, August 25–29, 2024, Barcelona, Spain Fangyuan Zhao, Zitao Li, Xuebin Ren, Bolin Ding, Shusen Yang, and Yaliang Li
0.4 0.8 1.6 3.20.000.25 3-way TVD
NLTCS
0.4 0.8 1.6 3.20.250.50
Adult
0.4 0.8 1.6 3.20.00.5
BR2000
0.4 0.8 1.6 3.20.00.5
Fire
0.4 0.8 1.6 3.20.00.5 4-way TVD
NLTCS
0.4 0.8 1.6 3.20.250.500.75
Adult
0.4 0.8 1.6 3.20.00.5
BR2000
0.4 0.8 1.6 3.20.00.5
Fire
Privacy budgetVertiMRF-FM VertiMRF-FO VertiGAN Centralized
Figure 4:𝑙-way TVD vs. privacy budget 𝜖on four datasets.
0.4 0.8 1.6 3.20.20.4
NLTCS, Y = outside
0.4 0.8 1.6 3.20.20.4
NLTCS, Y = bathing
0.4 0.8 1.6 3.20.250.50
NLTCS, Y = money
0.4 0.8 1.6 3.20.20.4
NLTCS, Y = traveling
0.4 0.8 1.6 3.20.250.50
Adult, Y = marital
0.4 0.8 1.6 3.20.20.4
Adult, Y = race
0.4 0.8 1.6 3.20.20.4
Adult, Y = capital gain
0.4 0.8 1.6 3.20.20.4
Adult, Y = incomeMisclassfication  Rate
Privacy budgetVertiMRF-FM VertiMRF-FO VertiGAN Centralized
Figure 5: SVM misclassification rate vs. privacy budget 𝜖on NLTCS and Adult datasets.
3-way 4-way 5-way
 NLTCS0.00.10.2TVD
3-way 4-way 5-way
Adult0.00.5m=2m=4m=8m=d
Figure 6: Impact of party number 𝑚(𝜖=0.8).
larger TVD results. This can be attributed to the fact that GAN-
based data synthesis methods are not well-suited for synthesiz-
ing tabular data, as discussed in previous studies [ 4,35]. Further-
more, the advantages of Centralized over VertiMRF-FM become
more prominent in datasets with larger domain sizes, such as adult,
BR2000, and Fire. Although VertiMRF-FM performs closely to Cen-
tralized on NLTCS when 𝜖is larger, the difference becomes more
pronounced in the other three datasets due to their larger domain
sizes. This aligns with our analysis in Theorem 3. A larger domain
size leads to smaller average count in a contingency histogram,
thereby deriving a larger estimation error of CarEst.Comparison on SVM classification. Figure 5 presents the aver-
age misclassification rates of the SVM classifiers trained on the
synthetic data. VertiMRF-FM consistently outperforms other ver-
tical methods. Misclassification rates of VertiGAN are as high as
40% even when 𝜖=3.2, which is significantly larger than both
VertiMRF-FM andVertiMRF-FO methods. Additionally, the advan-
tages of centralized over VertiMRF-FM are magnified as the domain
size of the dataset increases. These findings align with results shown
in Figure 4, illustrating the effectiveness of VertiMRF-FM and the
negative impact of large domain sizes.
Impact of the number of parties. We examine the impact of the
party number 𝑚on the utility of synthetic data. Figure 6 compares
the TVD obtained under different settings of 𝑚on NLTCS and
Adult datasets with 𝜖=0.8. In the experiments, 𝑚=𝑑indicates
that the𝑑attributes are distributed to dparties, with each party
having one distinct attribute. The results demonstrate that as 𝑚
increases, the TVD results also increase. This is primarily because
when attributes are partitioned to more parties, LocMRF with high
precision contributes less to the global MRF. In such cases, the
LocEnc andCarEst procedures dominate the errors.
4438VertiMRF: Differentially Private Vertical Federated Data Synthesis KDD ’24, August 25–29, 2024, Barcelona, Spain
Table 2: 3-way TVD under different attribute distributions
Splitters Params. VertiMRF-FM VertiMRF-FO VertiGAN
Importance0.1 0.0583 (±0.005) 0.234(±0.023) 0.426 (±0.027)
1 0.0667 (±0.021) 0.249 (±0.017) 0.430 (±0.056)
10 0.0589 (±0.006) 0.257 (±0.019) 0.458 (±0.081)
100 0.0648 (±0.007) 0.266 (±0.022) 0.465 (±0.068)
Correlation0 0.0735 (±0.007) 0.261(±0.027) 0.436 (±0.034)
0.3 0.0524 (±0.006) 0.296 (±0.024) 0.416 (±0.031)
0.6 0.0684 (±0.006) 0.272 (±0.023) 0.438 (±0.038)
1.0 0.0678 (±0.009) 0.281 (±0.034) 0.401 (±0.042)
Table 3: Communication cost and computation time
Dataset Methods Commu. costCompu. time
per party server
AdultVertiMRF-FM (𝑡=2000) 15Mb 23.1min 67min
VertiMRF-FM
(𝑡=2000,𝑡ℎ𝑟𝑒𝑎𝑑𝑠 =40)4.9Mb 4.1min 67min
VertiMRF-FM (𝑡=8000) 22Mb 93min 67min
VertiMRF-FO 18Mb 2.5min 67min
VertiGAN 112Mb 8.3min 10s
Centralized - - 16min
Impact of different attribute distributions. We calibrate the im-
portance and correlation of attributes from different data parties
based on the attribute splitters proposed for VFL tasks in Vert-
ibench [ 57], thereby evaluating the impact of varying attribute
distributions on algorithm performance. Table 2 summarizes the
resulting 3-way TVD results, i.e., mean and standard deviation
across 5 independent runs, under different parameter settings for
each algorithm on NLTCS dataset. As shown, the superiority of
VertiMRF-FM on other baseline algorithms is significant and sta-
ble with respect to different splitting strategies. Furthermore, the
TVD results for all algorithms fluctuate within a narrow range as
parameters𝛼and𝛽vary, indicating that the performance of these
algorithms is robust against variations in feature splits.
Communication and computation cost. Table 3 compares the
communication costs and computation time of the four methods on
Adult. As analyzed in Section 4.3 and Appendix B, the communica-
tion overhead of VertiMRF-FM is expected to be smaller than that
ofVertiMRF-FO when𝑡¯𝑢<𝑛. Consistent with our analysis, we
observe that the overhead of VertiMRF-FM is smaller than that of
VertiMRF-FO when𝑡¯𝑢<𝑛with𝑡=2000 but larger when 𝑡¯𝑢>𝑛
with𝑡=8000. The communication in VertiGAN involves sending
gradients of local generators to the server and the updated model
to local parties. The overall communication cost depends on the
model size and the number of communication rounds.
In terms of computation time, when using the sketch-based
LocEnc , each local party needs to perform 𝑡𝑛hash mappings, whereas
the FO-based LocEnc only requires 𝑛|𝐴𝑖|perturbations. Since 𝑡>>
|𝐴𝑖|, the FO-based LocEnc requires less computation time. The hash
mappings can be accelerated by parallel computation since they
run independently. By introducing 40parallel threads, the compu-
tation time can be significantly reduced. On the server side, the
computation time is nearly identical for both VertiMRF-FM andVertiMRF-FO. That’s because apart from CarEst , both methods
execute identical computations on the server side. Whether it is
FO-based CarEst or sketch-based CarEst , the computation pro-
cess solely involves simple calculations and does not significantly
affect the computation time. In VertiGAN, each party generates
fake data and computes model gradients, while the server aggre-
gates and broadcasts the updated model. Therefore, the most time
consumption occurs at the local party.
8 Related Work
We review related work from the following two perspectives.
DP data synthesis. There have been plenty of approaches [ 13,
17,24,25,27,35,44] to generate synthetic data with DP guaran-
tee, which can be categorized into GAN-based [ 2,11,61], game-
based [ 12,14,51], and marginal-based approaches [ 4,34,35,60,62].
Among them, the marginal-based ones tend to perform best, aiming
to approximate the joint distribution of high-dimensional data with
multiple low-way marginals. For example, PrivBayes [ 60] utilizes
the Bayesian network to select low-way marginals to approximate
a high-dimensional distribution. PrivMRF [ 4] applies a Markov
Random Field to model the data distribution, enabling flexible se-
lection of low-way marginals. Without learning a graph structure,
PrivSyn [ 62] greedily searches numerous low-way marginals to
represent and synthesize the dataset directly. Despite high utility,
these approaches cannot be directly extended to VFL settings.
Private vertical data synthesis. There are several works [ 18,
38,39,50] on the private data synthesis under vertical setting.
Among those works, some are based on the privacy model of k-
anonymity [ 49], which is vulnerable to various privacy attacks [ 21,
56]. A few works [ 18,38,50] explore DP data synthesis under
vertical settings. For instance, [ 38] proposes a two-party DP data
synthesis framework tailored for classification tasks. [ 50] utilizes a
latent tree model to capture the cross-party correlations on datasets
with binary attributes. DP-WGAN is also adapted to the vertical set-
ting [ 18] to generate synthetic data but performs poorly on tabular
data. To the best of our knowledge, we are the first work applicable
to the multi-party and high-dimensional data context.
9 Conclusion
We have presented VertiMRF, a novel differentially private algo-
rithm to generate synthetic data in the vertical federated setting. In
particular, VertiMRF has each party share a local MRF and multiple
DP FM-sketches of local attributes, based on that, the central server
can build an MRF to approximate global data distribution without
access to the raw data and violation of DP. Additionally, we also
provided two techniques tailored for datasets with large attribute
domain sizes. Finally, we empirically demonstrate the superiority
ofVertiMRF on four real world datasets.
Acknowledgments
This work was supported in part by the National Key Research and
Development Program of China under Grants 2022YFA1004100, and
2020YFA0713900; in part by the National Natural Science Founda-
tion of China under Grants 62172329, U21A6005, 61772410, 61802298;
in part by the Science and Technology Plan Project of Henan
province under Grant 232102211007.
4439KDD ’24, August 25–29, 2024, Barcelona, Spain Fangyuan Zhao, Zitao Li, Xuebin Ren, Bolin Ding, Shusen Yang, and Yaliang Li
References
[1]M. Abadi, A. Chu, I. Goodfellow, H. B. McMahan, I. Mironov, K. Talwar, and
L. Zhang. Deep learning with differential privacy. In Proc. CCS, pages 308–318,
2016.
[2]N. C. Abay, Y. Zhou, M. Kantarcioglu, B. Thuraisingham, and L. Sweeney. Privacy
preserving synthetic data release using deep learning. In Proc. ECML PKDD 2018,
pages 510–526. Springer, 2019.
[3] A. Asuncion and D. Newman. Uci machine learning repository, 2007.
[4]K. Cai, X. Lei, J. Wei, and X. Xiao. Data synthesis via differentially private markov
random fields. Proc. VLDB Endow., 14(11):2190–2202, 2021.
[5]D. Chen, T. Orekondy, and M. Fritz. Gs-wgan: A gradient-sanitized approach for
learning differentially private generators. Proc. NeurIPS, 33:12673–12684, 2020.
[6]H. Chen, K. Laine, and P. Rindal. Fast private set intersection from homomorphic
encryption. In Proc. CCS, pages 1243–1255, 2017.
[7]W. Chen, G. Ma, T. Fan, Y. Kang, Q. Xu, and Q. Yang. Secureboost+: A high
performance gradient boosting tree framework for large scale vertical federated
learning. arXiv preprint arXiv:2110.10927, 2021.
[8]C. Dickens, J. Thaler, and D. Ting. Order-invariant cardinality estimators are
differentially private. In Proc. NeurIPS, pages 15204–15216, 2022.
[9]C. Dong, L. Chen, and Z. Wen. When private set intersection meets big data: an
efficient and scalable protocol. In Proc. CCS, pages 789–800, 2013.
[10] C. Dwork, F. McSherry, K. Nissim, and A. Smith. Calibrating noise to sensitivity
in private data analysis. In Proc. TCC, pages 265–284. Springer, 2006.
[11] L. Frigerio, A. S. de Oliveira, L. Gomez, and P. Duverger. Differentially private
generative adversarial networks for time series, continuous, and discrete open
data. In Proc. IFIP SEC, pages 151–164. Springer, 2019.
[12] M. Gaboardi, E. J. G. Arias, J. Hsu, A. Roth, and Z. S. Wu. Dual query: Practical
private query release for high dimensional data. In Proc. ICML, pages 1170–1178.
PMLR, 2014.
[13] C. Ge, S. Mohapatra, X. He, and I. F. Ilyas. Kamino: Constraint-aware differentially
private data synthesis. arXiv preprint arXiv:2012.15713, 2020.
[14] M. Hardt, K. Ligett, and F. McSherry. A simple and practical algorithm for
differentially private data release. In Proc. NeurIPS, 2012.
[15] S. Hardy, W. Henecka, H. Ivey-Law, R. Nock, G. Patrini, G. Smith, and B. Thorne.
Private federated learning on vertically partitioned data via entity resolution and
additively homomorphic encryption. arXiv preprint arXiv:1711.10677, 2017.
[16] Y. Hu, D. Niu, J. Yang, and S. Zhou. FDML: A collaborative machine learning
framework for distributed features. In Proc. SIGKDD, KDD ’19, page 2232–2240,
New York, NY, USA, 2019. Association for Computing Machinery.
[17] Y. Hu, F. Wu, Q. Li, Y. Long, G. Garrido, C. Ge, B. Ding, D. Forsyth, B. Li, and
D. Song. Sok: Privacy-preserving data synthesis. In Proc. S&P, pages 2–2, 2023.
[18] X. Jiang, Y. Zhang, X. Zhou, and J. Grossklags. Distributed gan-based privacy-
preserving publication of vertically-partitioned data. Proc. PET, 2:236–250, 2023.
[19] J. Jordon, J. Yoon, and M. Van Der Schaar. Pate-gan: Generating synthetic data
with differential privacy guarantees. In Proc. ICLR, 2018.
[20] P. Kairouz, H. B. McMahan, B. Avent, A. Bellet, M. Bennis, A. N. Bhagoji,
K. Bonawitz, Z. Charles, G. Cormode, R. Cummings, et al. Advances and open
problems in federated learning. Foundations and Trends® in Machine Learning,
14(1–2):1–210, 2021.
[21] D. Kifer. Attacks on privacy and definetti’s theorem. In Proc. SIGMOD, pages
127–138, 2009.
[22] V. Kolesnikov, R. Kumaresan, M. Rosulek, and N. Trieu. Efficient batched oblivious
prf with applications to private set intersection. In Proc. CCS, pages 818–829,
2016.
[23] H. Krawczyk. Hmqv: A high-performance secure diffie-hellman protocol. In Proc.
CRYPTO, pages 546–566. Springer, 2005.
[24] H. Li, L. Xiong, and X. Jiang. Differentially private synthesization of multi-
dimensional data using copula functions. In Advances in database technology:
proceedings. International conference on extending database technology, volume
2014, page 475. NIH Public Access, 2014.
[25] H. Li, L. Xiong, L. Zhang, and X. Jiang. Dpsynthesizer: differentially private data
synthesizer for privacy preserving data sharing. In Proc. VLDB Endow., volume 7,
page 1677. NIH Public Access, 2014.
[26] N. Li, M. Lyu, D. Su, and W. Yang. Differential privacy: From theory to practice.
Springer, 2017.
[27] N. Li, Z. Zhang, and T. Wang. Dpsyn: Experiences in the nist differential privacy
data synthesis challenges. arXiv preprint arXiv:2106.12949, 2021.
[28] Z. Li, B. Ding, L. Yao, Y. Li, X. Xiao, and J. Zhou. Performance-based pricing for
federated learning via auction. Proc. VLDB Endowment, 17(6):1269–1282, 2024.
[29] Z. Li, B. Ding, C. Zhang, N. Li, and J. Zhou. Federated matrix factorization with
privacy guarantee. Proc. VLDB Endow., 15(4):900–913, dec 2021.
[30] Z. Li, T. Wang, and N. Li. Differentially private vertical federated clustering. Proc.
VLDB Endow., 16(6):1277–1290, 2023.
[31] Y. Liu, Y. Kang, X. Zhang, L. Li, Y. Cheng, T. Chen, M. Hong, and Q. Yang.
A communication efficient collaborative learning framework for distributed
features. arXiv preprint arXiv:1912.11187, 2019.
[32] Y. Liu, Y. Liu, Z. Liu, Y. Liang, C. Meng, J. Zhang, and Y. Zheng. Federated forest.
IEEE Transactions on Big Data, (01):1–1, 2020.[33] K. G. Manton. National long-term care survey: 1982, 1984, 1989, 1994, 1999, and
2004. Inter-university Consortium for Political and Social Research, 2010.
[34] R. McKenna, G. Miklau, and D. Sheldon. Winning the nist contest: A scalable
and general approach to differentially private synthetic data. arXiv preprint
arXiv:2108.04978, 2021.
[35] R. McKenna, D. Sheldon, and G. Miklau. Graphical-model based estimation and
inference for differential privacy. In Proc. ICML, pages 4435–4444. PMLR, 2019.
[36] B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Arcas.
Communication-efficient learning of deep networks from decentralized data.
InProc. AISTATS, pages 1273–1282. PMLR, 2017.
[37] I. Mironov. Rényi differential privacy. In Proc. CSF, pages 263–275. IEEE, 2017.
[38] N. Mohammed, D. Alhadidi, B. C. Fung, and M. Debbabi. Secure two-party
differentially private data release for vertically partitioned data. IEEE transactions
on dependable and secure computing, 11(1):59–71, 2013.
[39] N. Mohammed, B. C. Fung, and M. Debbabi. Anonymity meets game theory:
secure data integration with malicious participants. The VLDB Journal, 20:567–
588, 2011.
[40] S. L. Pardau. The california consumer privacy act: Towards a european-style
privacy regime in the united states. J. Tech. L. & Pol’y, 23:68, 2018.
[41] W. Qardaji, W. Yang, and N. Li. Priview: practical differentially private release of
marginal contingency tables. In Proc. SIGMOD, pages 1435–1446, 2014.
[42] X. Ren, L. Shi, W. Yu, S. Yang, C. Zhao, and Z. Xu. Ldp-ids: Local differential
privacy for infinite data streams. In Proc. SIGMOD, pages 1064–1077, 2022.
[43] X. Ren, S. Yang, C. Zhao, J. McCann, and Z. Xu. Belt and brace: When federated
learning meets differential privacy. arXiv preprint arXiv:2404.18814, 2024.
[44] X. Ren, C.-M. Yu, W. Yu, S. Yang, X. Yang, J. A. McCann, and S. Y. Philip. Lopub:
high-dimensional crowdsourced data publication with local differential privacy.
IEEE Transactions on Information Forensics and Security, 13(9):2151–2166, 2018.
[45] D. Ridgeway, M. F. Theofanos, T. W. Manley, and C. Task. Challenge design and
lessons learned from the 2018 differential privacy challenges. Technical report,
Technical Report NIST Technical Note 2151„ 2021.
[46] S. Ruggles, K. Genadek, G. Ronald, G. Josiah, and M. Sobek. Ipums usa: Version
6.0. Technical report, Minneapolis: University of Minnesota, 2015.
[47] A. Smith, S. Song, and A. Guha Thakurta. The flajolet-martin sketch itself
preserves differential privacy: Private counting with minimal space. In Proc.
NeurIPS, pages 19561–19572, 2020.
[48] S. Su, P. Tang, X. Cheng, R. Chen, and Z. Wu. Differentially private multi-party
high-dimensional data publishing. In Proc. ICDE, pages 205–216, 2016.
[49] L. Sweeney. k-anonymity: A model for protecting privacy. International journal
of uncertainty, fuzziness and knowledge-based systems, 10(05):557–570, 2002.
[50] P. Tang, X. Cheng, S. Su, R. Chen, and H. Shao. Differentially private publication of
vertically partitioned data. IEEE transactions on dependable and secure computing,
18(2):780–795, 2019.
[51] G. Vietri, G. Tian, M. Bun, T. Steinke, and S. Wu. New oracle-efficient algorithms
for private synthetic data release. In Proc. ICML, pages 9765–9774. PMLR, 2020.
[52] P. Voigt and A. Von dem Bussche. The eu general data protection regulation (gdpr).
A Practical Guide, 1st Ed., Cham: Springer International Publishing, 10(3152676):10–
5555, 2017.
[53] T. Wang, B. Ding, J. Zhou, C. Hong, Z. Huang, N. Li, and S. Jha. Answering
multi-dimensional analytical queries under local differential privacy. In Proc.
SIGMOD, pages 159–176, 2019.
[54] T. Wang, X. Yang, X. Ren, W. Yu, and S. Yang. Locally private high-dimensional
crowdsourced data release based on copula functions. IEEE Transactions on
Services Computing, 15(2):778–792, 2019.
[55] WeBank. Webank use case. https://www.fedai.org/cases/a-case-of-traffic-
violations-insurance-using-federated-learning/, 2022.
[56] R. C.-W. Wong, A. W.-C. Fu, K. Wang, and J. Pei. Minimality attack in privacy
preserving data publishing. In Proc. VLDB Endow., pages 543–554, 2007.
[57] Z. Wu, J. Hou, and B. He. Vertibench: Advancing feature distribution diversity in
vertical federated learning benchmarks. arXiv preprint arXiv:2307.02040, 2023.
[58] C. Xie, P.-Y. Chen, C. Zhang, and B. Li. Improving privacy-preserving verti-
cal federated learning by efficient communication with admm. arXiv preprint
arXiv:2207.10226, 2022.
[59] Y. Xie, Z. Wang, D. Gao, D. Chen, L. Yao, W. Kuang, Y. Li, B. Ding, and J. Zhou.
Federatedscope: A flexible federated learning platform for heterogeneity. Proc.
VLDB Endow., 16(5):1059–1072, 2023.
[60] J. Zhang, G. Cormode, C. M. Procopiuc, D. Srivastava, and X. Xiao. Privbayes:
Private data release via bayesian networks. ACM Transactions on Database
Systems (TODS), 42(4):1–41, 2017.
[61] X. Zhang, S. Ji, and T. Wang. Differentially private releasing via deep generative
model (technical report). arXiv preprint arXiv:1801.01594, 2018.
[62] Z. Zhang, T. Wang, N. Li, J. Honorio, M. Backes, S. He, J. Chen, and Y. Zhang.
Privsyn: Differentially private data synthesis. In Proc. USENIX Security, pages
929–946, 2021.
[63] F. Zhao, X. Ren, S. Yang, Q. Han, P. Zhao, and X. Yang. Latent dirichlet alloca-
tion model training with differential privacy. IEEE Transactions on Information
Forensics and Security, 16:1290–1305, 2020.
4440VertiMRF: Differentially Private Vertical Federated Data Synthesis KDD ’24, August 25–29, 2024, Barcelona, Spain
A Pseudo-code of DP FM-sketching algorithm
Here is the pseudo-code of the DP FM-sketching algorithm dis-
cussed in Section 2.2.
Algorithm 2 DPFM
Input: Multi-setX={𝑥1,...,𝑥𝑛}, domain[𝑢], distribution param-
eter𝛾, privacy budget 𝜖′, hash key𝜉∼𝑈𝑛𝑖𝑓𝑜𝑟𝑚(𝑅).
Output: DP FM-sketch 𝛼forX.
1:𝑘𝑝←⌈1
𝑒𝜖′−1⌉,𝛼𝑚𝑖𝑛←⌈log1+𝛾1
1−𝑒−𝜖′⌉
2:𝛼𝑝←max{𝑌1,...,𝑌𝑘𝑝}where𝑌𝑖∼𝐺𝑒𝑜𝑚𝑒𝑡𝑟𝑖𝑐(𝛾
1+𝛾),∀𝑖≤𝑘𝑝
3:𝛼X←max{H𝜉(𝑥𝑗)},∀𝑥𝑗∈X.
4:return max
𝛼X,𝛼𝑝,𝛼𝑚𝑖𝑛	
B Frequency Oracle based LocEnc and CarEst
We use the widely known Frequency Oracle (FO) protocol, called the
Generalized Random Response technique (GRR) [ 53], to implement
a baseline for LocEnc.
FO-based LocEnc .Each partyP𝑖employs GRR to encode the local
dataset. Specifically, for each local attribute 𝐴𝑗∈A𝑖, a value𝑣(𝑗)
is perturbed to an arbitrary 𝑣′
(𝑗)∈[𝑢𝑗]with probabilities:
𝑃𝑟h
𝑣′
(𝑗)=𝑣i
= 
𝑒𝜖′
𝑒𝜖′+𝑢𝑗−1, 𝑣=𝑣(𝑗)
1
𝑒𝜖′+𝑢𝑗−1, 𝑣≠𝑣(𝑗)(6)
Here,𝜖′denotes LDP level preserved by the GRR technique for each
attribute. After applying GRR to each user’s data value in the local
dataset𝐷𝑖, we obtain a perturbed version e𝐷𝑖. The partition of e𝐷𝑖
restricted to 𝐴𝑗, denoted asM𝑗, is taken as the encoded attribute of
𝐴𝑗. Subsequently, the encoded local attributes M𝑖={M𝑗,∀𝐴𝑗∈
A𝑖}are reported to the central server.
FO-based CarEst .After receiving the reported encoded attributes
M={M𝑗|𝑗∈[𝑑]}, the central server can estimate the contin-
gency histogram of any arbitrary marginal. For an 𝑙-way marginal
𝑀=(𝐴1,...,𝐴𝑙), we obtain a noisy contingency histogram ˆ𝑇𝑀by
counting the occurrences of each value tuple v=(𝑣(1),...,𝑣(𝑙))∈Î𝑙
𝑖=1[𝑢𝑖]fromM. However, relying solely on this estimation can
introduce considerable bias. To mitigate this issue, a commonly
employed technique is to utilize a transition probability matrix 𝑃to
overcome the bias, which would then produce an unbiased estimate.
As shown in Equation (6), different attributes are encoded inde-
pendently in LocEnc procedure. So each tuple v=(𝑣(1),...,𝑣(𝑙))
can be encoded as arbitrary v′=(𝑣′
(1),...,𝑣′
(𝑙))with probability
𝑃𝑟[v→v′]=Î
𝐴𝑖∈𝑀𝑃𝑟h
𝑣(𝑖)→𝑣′
(𝑖)i
.Since there areÎ
𝐴𝑖∈𝑀𝑢𝑖
possible values for vin total, we can construct a Î
𝐴𝑖∈𝑀𝑢𝑖× Î
𝐴𝑖∈𝑀𝑢𝑖-dimensional probability matrix 𝑃to establish the tran-
sition relationship between 𝑇𝑀and the noisy ˆ𝑇𝑀. That is𝑃·𝑇𝑀=
E[ˆ𝑇𝑀], where the expectation accounts for the randomness of GRR.
Therefore,𝑇𝑀can be estimated as 𝑃−1·ˆ𝑇𝑀, where the existence of
𝑃−1is guaranteed by the positive definite property of the matrix.
Furthermore, it can be shown that
E[𝑃−1·ˆ𝑇𝑀]=𝑃−1·E[ˆ𝑇𝑀]=𝑃−1·𝑃·𝑇𝑀=𝑇𝑀.This implies that 𝑃−1·ˆ𝑇𝑀is an unbiased estimator of 𝑇𝑀.
Privacy Analysis We notice that GRR achieves unbounded DP [ 26]
which considers the neighboring dataset by replacing one record.
It has been shown that any algorithm satisfying 𝜖unbounded DP
also satisfies 2𝜖bounded DP, where bounded DP considers neigh-
boring datasets obtained by adding or removing a single record. In
this paper, we consider bounded DP for consistency. Thus, given
𝜖′, each perturbation in Equation (6) should satisfy𝜖′
2-DP. The
privacy guarantee of the FO-based LocEnc procedure can be ob-
tained by applying the sequential composition of DP, resulting
in an overall privacy guarantee of 𝑑𝜖′/2, where𝑑represents the
number of attributes in each record. However, Lemma 1 demon-
strates that Rényi Differential Privacy (RDP) [ 37] provides an alter-
native bound for the composition of multiple DP algorithms, that is
(4𝜖′
2√︁
2𝑑log(1/𝛿),𝛿)-DP, where 0<𝛿<1andlog(1/𝛿)≥𝑛(𝜖′
2)2.
To obtain the tighter bound, we take the minimum between the
two bounds, that is minn
𝑑𝜖′/2,2𝜖′√︁
2𝑑log(1/𝛿)o
with a tolerance
probability of 𝛿. Here,𝛿=0when the minimum taking 𝑑𝜖′/2.
Lemma 1 (DP Composition based on RDP). Let𝑓be the compo-
sition of𝑛mechanisms that satisfies 𝜖-DP, then for each 0<𝛿<1
with log(1/𝛿)≥𝑛𝜖2,𝑓satisfies(4𝜖√︁
2𝑛log 1/𝛿,𝛿)-DP.
Communication cost of VertiMRF-FO. Same as VertiMRF-FM,
there is only one communication round between each party P𝑖and
the central server in VertiMRF-FO . The communication includes
encoded attributesM𝑖and the local MRF information {MRF𝑖,S𝑖,G𝑖}.
The only difference between the communication contents of VertiMRF-
FMandVertiMRF-FO isM𝑖. For FO-based LocEnc ,M𝑖contains
a noisy version of local dataset. the communication cost can be
bounded by 𝑂(𝑛𝑑). Therefore, considering a total of 𝑚parties, the
communication cost of VertiMRF-FO is𝑂(𝑛𝑑)+𝑂(𝑑2)+𝑂(𝑚𝜏′).
C Proofs of Theorems
C.1 Proof of Theorem 2
Proof. Let𝐷and𝐷′be neighboring datasets satisfying 𝐷∇𝐷′=
𝑋𝑖𝑑=n
𝑣1
𝑖𝑑,...,𝑣𝑑
𝑖𝑑o
, where𝑖𝑑denotes the record-index of 𝑋𝑖𝑑,𝑣𝑗
𝑖𝑑is
the corresponding attribute value of 𝐴𝑗. Let𝑓be the sketch-based
LocEnc algorithm which maps 𝑡hash keys and input dataset to 𝑡
set of sketch tuples
(
M(ℎ)≜(
M(ℎ)
𝑗≜ 
𝛼(ℎ)
𝑣𝑗
1,...,𝛼(ℎ)
𝑣𝑗
𝑢𝑗!
|𝑗∈[𝑑])
|ℎ∈[𝑡])
.
where𝛼(ℎ)
𝑣𝑗
𝑖denotes the sketch of the ID set for 𝐴𝑗=𝑣𝑗
𝑖generated
with the hash key 𝜉ℎ.
We first calculate the privacy cost when applying a hash key
𝜉ℎto the overall input dataset and returning sketch tuples M(ℎ).
M(ℎ)has𝑑sketch tuples andÍ𝑑
𝑖=1𝑢𝑖sketches in total. Since 𝑋𝑖𝑑
can only take one value 𝑣𝑗
𝑖𝑑of each attribute 𝐴𝑗, then there should
also be one sketch 𝛼(ℎ)
𝑣𝑗
𝑖𝑑inM(ℎ)
𝑗may be different for 𝐷and𝐷′.
Therefore, according to the definition of RDP, it holds that
4441KDD ’24, August 25–29, 2024, Barcelona, Spain Fangyuan Zhao, Zitao Li, Xuebin Ren, Bolin Ding, Shusen Yang, and Yaliang Li
exp
(𝜆−1)𝐷𝜆 𝑓(𝐷,𝜉ℎ)|𝑓(𝐷′,𝜉ℎ)
(7)
=∑︁
M(ℎ)𝑃𝑟[M(ℎ)]𝜆𝑃𝑟′[M(ℎ)]1−𝜆(8)
=∞∑︁
𝛼(ℎ)
𝑣1
𝑖𝑑=0...∞∑︁
𝛼(ℎ)
𝑣𝑑
𝑖𝑑=0{[𝑃𝑟[𝛼(ℎ)
𝑣1
𝑖𝑑]Ö
1<𝑖≤𝑑𝑃𝑟[𝛼(ℎ)
𝑣𝑖
𝑖𝑑|{𝛼(ℎ)
𝑣𝑡
𝑖𝑑,𝑡<𝑖}]]𝜆·(9)
[𝑃𝑟′[𝛼(ℎ)
𝑣1
𝑖𝑑]Ö
1<𝑖≤𝑑𝑃𝑟′[𝛼(ℎ)
𝑣𝑖
𝑖𝑑|{𝛼(ℎ)
𝑣𝑡
𝑖𝑑,𝑡<𝑖}]]1−𝜆}· (10)
∑︁
M(ℎ)
¬[𝑃𝑟[M(ℎ)
¬|®𝛼]]𝜆[𝑃𝑟′[M(ℎ)
¬|®𝛼]]1−𝜆
|                                               {z                                               }
=1(11)
where the second equality follows the joint distribution formula,
®𝛼≜{𝛼(ℎ)
𝑣𝑖
𝑖𝑑,1≤𝑖≤𝑑}andM(ℎ)
¬denotes other sketches in M(ℎ)
besides®𝛼.
Now consider term 𝑃𝑟
𝛼(ℎ)
𝑣𝑖
𝑖𝑑|
𝛼(ℎ)
𝑣𝑡
𝑖𝑑,𝑡<𝑖
, there are two cases:
•∀𝑡,𝛼(ℎ)
𝑣𝑖
𝑖𝑑≠𝛼(ℎ)
𝑣𝑡
𝑖𝑑. In such case, since H𝜉map distinct elements to
independent variables and the 𝑘𝑝phantom elements are inde-
pendently sampled, then 𝛼(ℎ)
𝑣𝑖
𝑖𝑑is independent of 𝛼(ℎ)
𝑣𝑡
𝑖𝑑,∀𝑡. That
indicates
𝑃𝑟
𝛼(ℎ)
𝑣𝑖
𝑖𝑑|
𝛼(ℎ)
𝑣𝑡
𝑖𝑑,𝑡<𝑖
=𝑃𝑟
𝛼(ℎ)
𝑣𝑖
𝑖𝑑
.
•∃𝑡,𝑠.𝑡.,𝛼(ℎ)
𝑣𝑖
𝑖𝑑=𝛼(ℎ)
𝑣𝑡
𝑖𝑑. In such case, it should hold that 𝛼(ℎ)
𝑣𝑖
𝑖𝑑≥
H𝜉ℎ(𝑖𝑑). That indicates
𝑃𝑟
𝛼(ℎ)
𝑣𝑖
𝑖𝑑|
𝛼(ℎ)
𝑣𝑡
𝑖𝑑,𝑡<𝑖
=𝑃𝑟′
𝛼(ℎ)
𝑣𝑖
𝑖𝑑|
𝛼(ℎ)
𝑣𝑡
𝑖𝑑,𝑡<𝑖
.
The left side of above Equation is the probability that 𝛼(ℎ)
𝑣𝑖
𝑖𝑑is
the maximal among all elements in the set of hashed record ids
and sampled geometric random variables on 𝐷. Since we have
known thatH𝜉ℎ(𝑖𝑑)is not or not the only one maximal element
in the set, then we can just consider other hashed ids and sampled
variables. The ids are same for 𝐷and𝐷′and each of the variables
are i.i.d sampled from the same distribution, which can easily
derive the equality of above equation.
W.l.o.g., we assume there are 𝑠terms

𝑃𝑟
𝛼(ℎ)
𝑣𝑗
𝑖𝑑|
𝛼(ℎ)
𝑣𝑡
𝑖𝑑,𝑡<𝑗
,(𝑑−𝑠+1)≤𝑗≤𝑑
that satisfy the second case. Then, Equation (7) can be bounded by:
exp
(𝜆−1)𝐷𝜆 𝑓(𝐷,𝜉ℎ)|𝑓(𝐷′,𝜉ℎ)
(12)
=∞∑︁
𝛼(ℎ)
𝑣1
𝑖𝑑=0...∞∑︁
𝛼(ℎ)
𝑣𝑑−𝑠
𝑖𝑑=0"𝑑−𝑠Ö
𝑖=1𝑃𝑟[𝛼(ℎ)
𝑣𝑖
𝑖𝑑]#𝜆
·"𝑑−𝑠Ö
𝑖=1𝑃𝑟′[𝛼(ℎ)
𝑣𝑖
𝑖𝑑]#1−𝜆
(13)
=𝑑−𝑠Ö
𝑖=1 
∞∑︁
𝛼(ℎ)
𝑣𝑖
𝑖𝑑=0
𝑃𝑟[𝛼(ℎ)
𝑣𝑖
𝑖𝑑]𝜆
𝑃𝑟′[𝛼(ℎ)
𝑣𝑖
𝑖𝑑]1−𝜆 
|                                             {z                                             }
𝑡𝑒𝑟𝑚(𝑖)(14)Theorem 2.5 in [ 47] demonstrates a statistical bound of 𝜖′under DP
framework. According to the definition of RDP and the translation
with DP, it holds that 𝑡𝑒𝑟𝑚(𝑖)≤exp[(𝜆−1)(2𝜆(𝜖′)2)]. Then we
can derive that
exp
(𝜆−1)𝐷𝜆 𝑓(𝐷,𝜉ℎ)|𝑓(𝐷′,𝜉ℎ)
(15)
≤exp[(𝜆−1)(2(𝑑−𝑠)𝜆(𝜖′)2)]≤ exp[(𝜆−1)(2𝑑𝜆(𝜖′)2)](16)
So far, we have proved that applying one hash key to map the
overall input data satisfies (𝜆,2𝑑𝜆(𝜖′)2)-RDP in a single run. Next,
according to the sequential composition theorem of RDP [ 37],
LocEnc algorithm involving 𝑡runs of the FM sketch generation
process should satisfy (𝜆,2𝑡𝑑𝜆(𝜖′)2)-RDP, which can be further
translated to(4𝜖√︁
𝑡𝑑log(1/𝛿),𝛿)-DP,∀𝛿<1if setting𝛼≥2.□
C.2 Proof of Theorem 3
Our proof is based on a lemma [ 47] that bounds the error of the
cardinality estimated by the DPFM algorithm shown in Algorithm 2.
Lemma 2. Let𝑘𝐹𝑀be the estimated cardinality by Algorithm 2
with inputs 𝛾,𝜖,𝛿,𝛽∈(0,1), using𝑡=100√
log(1/𝛽)
𝛾2 repeats, then
for each multi-setX⊂𝑢, it holds that
|X|
1+𝛾−𝑂≤𝑘𝐹𝑀≤(1+𝛾)·|X|+𝐶 (17)
with probability at least 1−𝛽, where𝐶=𝑂(log1/2(1/𝛿)log1/4(1/𝛽)
𝜖).
Proof. We first bound each cardinality ˆ𝑇𝑀[v]estimated by FM
sketch. As shown in Section 4.2, we compute each ˆ𝑇𝑀[v]using the
inclusion-exclusion principle and the mergeable property of sketch,
that is|𝐴∩𝐵|=ˆ𝑛−|¯𝐴∪¯𝐵|, where ˆ𝑛denotes the noisy data number
sanitized by adding a Laplacian noise ˆ𝑁. Combining with lemma 2,
we can derive that
−𝛾𝑛+(1+𝛾)𝑇𝑀[v]+ ˆ𝑁−𝐶≤ˆ𝑇𝑀[v]≤𝛾
1+𝛾𝑛+𝑇𝑀[v]
1+𝛾+ˆ𝑁+𝐶
(18)
By subtracting 𝑇𝑀[v]for both sides of Equation 18, we can obtain
that:
−𝛾𝑛+𝛾𝑇𝑀[v]+ˆ𝑁−𝐶≤ˆ𝑇𝑀[v]−𝑇𝑀[v]≤𝛾
1+𝛾𝑛−𝛾𝑇𝑀[v]
1+𝛾+ˆ𝑁+𝐶(19)
By taking the absolute value for both sides and dividing them by
𝑇𝑀[v], we can derive that
|ˆ𝑇𝑀[v]−𝑇𝑀[v]|
𝑇𝑀[v](20)
≤max𝛾
1+𝛾(𝑛
𝑇𝑀[v]−1)+ˆ𝑁+𝐶
𝑇𝑀[v],𝛾(𝑛
𝑇𝑀[v]−1)−ˆ𝑁−𝐶
𝑇𝑀[v]
(21)
≤𝛾(𝑛
𝑇𝑀[v]−1)+ˆ𝑁+𝐶
𝑇𝑀[v]. (22)
According to Lemma 2, the above bound holds with probability
1−𝛽, and𝐶=𝑂(log1/2(1/𝛿)log1/4(1/𝛽)
𝜖). □
4442