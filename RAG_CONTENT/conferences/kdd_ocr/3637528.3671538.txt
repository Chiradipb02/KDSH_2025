CHILI: Ch emically-I nformed L arge-scale I norganic
Nanomaterials Dataset for Advancing Graph Machine Learning
Ulrik Friis-Jensen∗
University of Copenhagen
Department of Chemistry
Copenhagen, Denmark
University of Copenhagen
Department of Computer Science
Copenhagen, Denmark
ufj@chem.ku.dkFrederik L. Johansen∗
University of Copenhagen
Department of Computer Science
Copenhagen, Denmark
University of Copenhagen
Department of Chemistry
Copenhagen, Denmark
frjo@di.ku.dkAndy S. Anker
Technical University of Denmark
Dept. of Energy Conversion & Storage
Lyngby, Denmark
University of Oxford
Department of Chemistry
Oxford, United Kingdom
ansoan@dtu.dk
Erik B. Dam
University of Copenhagen
Department of Computer Science
Copenhagen, Denmark
erikdam@di.ku.dkKirsten M. Ø. Jensen
University of Copenhagen
Department of Chemistry
Copenhagen, Denmark
kirsten@chem.ku.dkRaghavendra Selvan
University of Copenhagen
Department of Computer Science
Copenhagen, Denmark
raghav@di.ku.dk
ABSTRACT
Advances in graph machine learning (ML) have been driven by
applications in chemistry, as graphs have remained the most ex-
pressive representations of molecules. This has led to progress
within both fields, as challenging chemical data has helped improve
existing methods and to develop new ones. While early graph ML
methods focused primarily on small organic molecules, more re-
cently, the scope of graph ML has expanded to include inorganic
materials. Modelling the periodicity and symmetry of inorganic
crystalline materials poses unique challenges, which existing graph
ML methods are unable to immediately address. Moving to inor-
ganic nanomaterials further increases complexity as the scale of
number of nodes within each graph can be broad (10 to105).
In addition, the bulk of existing graph ML focuses on charac-
terising molecules and materials by predicting target properties
with graphs as input. The most exciting applications of graph ML
will be in their generative capabilities, in order to explore the vast
chemical space from a data-driven perspective. Currently, gener-
ative modelling of graphs is not at par with other domains such
as images or text, as generating chemically valid molecules and
materials of varying properties is not straightforward.
In this work, we invite the graph ML community to address these
open challenges by presenting two new chemically-informed large-
scale inorganic ( CHILI ) nanomaterials datasets. These datasets con-
tain nanomaterials of different scales and properties represented as
graphs of varying sizes. The first dataset is a medium-scale dataset
(with overall >6M nodes, >49M edges) of mono-metallic oxide nano-
materials generated from 12 selected crystal types ( CHILI-3K ). This
∗Both authors contributed equally to this research.
This work is licensed under a Creative Commons Attribution
International 4.0 License.
KDD ’24, August 25–29, 2024, Barcelona, Spain
©2024 Copyright held by the owner/author(s).
ACM ISBN 979-8-4007-0490-1/24/08.
https://doi.org/10.1145/3637528.3671538dataset has a narrower chemical scope focused on an interesting
part of chemical space with a lot of active research. The second is a
large-scale dataset (with overall >183M nodes, >1.2B edges) of nano-
materials generated from experimentally determined crystal struc-
tures ( CHILI-100K ). The crystal structures used in CHILI-100K are
obtained from a curated subset of the Crystallography Open Data-
base (COD) and has a broader chemical scope covering database
entries for 68 metals and 11 non-metals. We define 11 property pre-
diction tasks covering node-, edge-, and graph- level tasks that span
classification and regression. In addition we also define structure
prediction tasks, which are of special interest for nanomaterial re-
search. We benchmark the performance of a wide array of baseline
methods starting with simple baselines to multiple off-the-shelf
graph neural networks. Based on these benchmarking results, we
highlight areas which need future work to achieve useful perfor-
mance for applications in (nano) materials chemistry. To the best
of our knowledge, CHILI-3K andCHILI-100K are the first open-
source nanomaterial datasets of this scale – both on the individual
graph level and of the dataset as a whole – and the only nanomate-
rials datasets with high structural and elemental diversity.1
CCS CONCEPTS
•Applied computing →Chemistry; •Computing method-
ologies→Neural networks ; Supervised learning by classification;
Supervised learning by regression; Machine learning; •Theory
of computation→Graph algorithms analysis ;Data modeling;
Data integration .
KEYWORDS
Nanomaterials; Graphs; Graph Neural Network; Atomic Structure;
Chemistry; Scattering; X-ray; Neutron; Datasets; Deep Learning;
Machine Learning
1The datasets and benchmarking scripts are open-source, and available at https://
github.com/UlrikFriisJensen/CHILI.
4962
KDD ’24, August 25–29, 2024, Barcelona, Spain Ulrik Friis-Jensen et al.
ACM Reference Format:
Ulrik Friis-Jensen, Frederik L. Johansen, Andy S. Anker, Erik B. Dam, Kirsten
M. Ø. Jensen, and Raghavendra Selvan. 2024. CHILI: Chemically- Informed
Large-scale Inorganic Nanomaterials Dataset for Advancing Graph Machine
Learning. In Proceedings of the 30th ACM SIGKDD Conference on Knowledge
Discovery and Data Mining (KDD ’24), August 25–29, 2024, Barcelona, Spain.
ACM, New York, NY, USA, 12 pages. https://doi.org/10.1145/3637528.3671538
1 INTRODUCTION
Graph machine learning (ML) has been applied to chemistry for
more than 50 years [ 47], and describing molecules as chemical
graphs goes back as far as 1874 [ 12]. A big part of why tasks in
chemistry are so relevant for graph ML is that chemical structures,
such as molecules, can be expressively represented using graphs,
where atoms are encoded as nodes with local attributes and chemi-
cal bonds as edges with neighbourhood attributes [36].
The recent advancements in deep learning methods [ 53,70] have
also impacted graph ML. The class of deep learning methods that
have evolved to tackle non-Euclidean data can be viewed within the
geometric deep learning paradigm [ 9,69]. Specifically, the class of
graph convolutional networks (GCNs) and graph neural networks
(GNNs) have shown widespread applications on graph-structured
data [ 39,49]. Several key developments in graph deep learning were
specifically driven by applications on chemical graphs [ 22,28,61].
The primary focus of the graph ML community has been in mod-
elling organic molecules [ 82,86]. Numerous studies have focused on
predicting target properties of such molecules based on their atomic
structure, posited as node- or graph- level tasks [ 5,8,14,28,40,72].
The inverse task of obtaining structures corresponding to desired
properties has been studied to a lesser extent [ 20,56]. This is due to
the inherent challenges of performing generative modelling in the
space of graphs. While recent classes of methods such as denoising
diffusion probabilistic models [ 38] are showing potential for smaller
molecules [ 81,93], the task of scaling these models to larger, and
more diverse, molecular graphs remains an open challenge.
The drive to develop novel materials with applications in batter-
ies or catalysts for renewable energy storage has lead to new interest
in inorganic crystalline materials, i.e materials with periodic atomic
order [ 39,77]. A special case of such materials are nanocrystals,
where the crystal dimensions are on the nanoscale. Modelling such
materials pose new and interesting challenges that are unlike those
encountered in organic chemistry applications [ 1]. Capturing the
periodicity and symmetry of crystalline materials are not easily
dealt with using existing graph ML methods [ 14,15,19,29,88].
This gets even more complex for nanomaterials where the scale
of obtained graphs span a broad range of atoms, between 10to
105[11].
In this paper, we invite the graph ML community to bridge
the divide between existing methods to meet the complexity of
large-scale inorganic materials chemistry. To this end, we make the
following contributions:
(1)Present a chemically-informed approach to generate large-scale
graph datasets of nanomaterials.
(2) Provide two novel nanomaterial graph datasets.
(3) Outline an array of property- and structure- prediction tasks.
(4)Perform comprehensive benchmark experiments for the pro-
posed tasks.
Figure 1: High-level schematic showing the five stages in-
volved in the creation of the CHILI -datasets: (1) Querying and
cleaning CIFs. (2) Extraction of crystal unit cells. (3) Expan-
sion of unit cells into supercells and subsequent centering. (4)
Cutting of nanoparticles into different sizes and padding of
edge environments following the described rules, conversion
into graphs with node- and edge- features. (5) Generation of
graph-level properties from CIF (crystal type, crystal system,
spacegroup, etc.) and simulation of scattering data.
An overview of our data-generating pipeline is illustrated in
Figure 1. The data generation pipeline takes any source of crystallo-
graphic information files (CIFs) (a file format containing symmetry
and positional information) and creates graphs of finite nanoparti-
cles with variable sizes. We thus assume the structure of nanoparti-
cles to be the cutouts of larger crystals, whether constructed manu-
ally or from a structural database. This is an approximation, as we
do not take into account e.g. surface relaxation and size-dependent
defects in the atomic structure. Each graph gets assigned relevant
chemical labels, as well as simulated scattering data associated
with each nanoparticle. The scattering data is simulated using De-
byeCalculator [ 45]. Using this generation pipeline we provide two
nanomaterial graph datasets, CHILI-3K andCHILI-100K.
The CHILI-3K dataset consists of 3,180graphs representing
mono-metallic oxide nanomaterials generated from 12different
well known crystal structures, which are known to be taken by nu-
merous materials. The resulting dataset captures a narrow chemical
subspace that is of considerable interest due to their environmental,
medical and catalytic applications [ 18,26,52]. The second dataset,
CHILI-100K , consists of 104,408graphs generated by curating ex-
perimentally determined structures from the Crystallography Open
Database (COD) [ 31]. This dataset has a broader chemical scope as
it contains datapoints for materials consisting of combinations of
68 metals and 11 non-metals, thus spanning a much wider range
of different crystal structures. While the CHILI-3K is classified as
4963CHILI: Ch emically-I nformed L arge-scale I norganic Nanomaterials Dataset for Advancing Graph Machine Learning KDD ’24, August 25–29, 2024, Barcelona, Spain
a medium-scale dataset (with >6M nodes, >49M edges in total),
theCHILI-100K dataset is classified as a large-scale dataset (with
>183M nodes, >1.2B edges in total) according to the Open Graph
Benchmark (OGB) criteria [ 39]. The two CHILI datasets are, to the
best of our knowledge, the first open-source nanomaterial datasets
of this scale. Together, we hope these two datasets will foster novel
methodological contributions at the intersection of graph ML and
large-scale inorganic materials chemistry.
1.1 Introduction to Material Structure
In this section, we present a short primer about material structure
for an ML audience. Details presented in this section are relevant to
the datasets presented in this work, but are not essential in using the
datasets themselves. We, however, hope these domain knowledge
descriptions will enable ML methods that address relevant open
problems within materials chemistry.
Materials chemistry is concerned with the study of the synthesis,
structure and properties of materials. The objective is to design
materials with improved properties and better performance, or
to achieve equivalent performance using cheaper elements or ele-
ments with a smaller environmental impact. One important focus
in materials chemistry is crystalline materials, which at the atomic
level can be described using an infinitely repeating arrangement
of a small number of atoms, called the unit cell (see Figure 2 for
examples). The unit cell is defined by the cell edges (𝑎, 𝑏, 𝑐)and
the cell angles ( 𝛼,𝛽and𝛾). The specific relations between the cell
edges and angles determines which of the seven crystal systems
the unit cell belongs to [ 85]. The position of the atoms in the unit
cell of a material are specified using fractional coordinates, which
are coordinates that are relative to the shape and size of the unit
cell. The arrangement of atoms in the unit cell can be described
by the asymmetric unit, which is the smallest repeating unit in the
structure, and the space group, which is a classification based on
the symmetry operations applied to the asymmetric unit. There
are230space groups, which are numbered from lowest to highest
symmetry [ 85]. Some configurations of specific element types at
specific positions are frequently observed and are therefore well-
described in literature. These typical configurations are referred to
as crystal types [85].
Nanomaterials are in many ways similar to crystalline materials,
but instead of the infinitely repeating unit cells, nanomaterials have
a finite size with at least one dimension at the nanoscale. In this
work we use nanomaterials to refer to nanoparticles, which are
nanomaterials with all 3 dimensions at the nanoscale and often
of spherical shape. The unit cell still describes the local structure
of a nanomaterial, but the full particle needs to be constructed to
describe the shape and surface of the nanomaterial. The atomic
positions in nanomaterials are often specified using absolute coor-
dinates, which are coordinates in a physical coordinate system with
arbitrary origin (we use the geometric centre of the nanomaterial).
2CHILI DATASETS
TheCHILI datasets are generated following the approach shown
in Figure 1 as outlined in Section 1. For a more detailed description
of the graph generation see Appendix A.3 and A.4. Code for down-
loading the datasets is available in Appendix A.5. The summary
Zincblende Spinel Wurtzite
Caesium  Chloride Fluorite Cadmium  Chloride Cadmium  Iodide Antifluorite
Rhenium  Trioxide Rutile Rock  Salt Nickel  ArsenideFigure 2: The unit cells of the 12 crystal types present in
theCHILI-3K dataset. For all shown structures, copper (Cu)
is the metal. The unit cells are visualized using VESTA [ 64]
with the polyhedral style. The unit cells are shown from the
standard orientation of a crystal shape, which is one of the 7
view options in VESTA.
statistics of the datasets are shown in Table 1 and the content of
the datasets are described in the following sections.
2.1 CHILI-3K
The CHILI-3K dataset contains nanomaterial graphs generated
from mono-metal oxides, which are a class of inorganic materials
with a single metallic element chemically coordinated, or bonded, to
oxygen atoms in the structure. They are often studied for their many
interesting applications [ 18,26,52]. The unit cells in CHILI-3K are
constructed based on 12 of the crystal types described in West et
al. [85], which are known to be formed by mono-metal oxides. The
unit cells of the 12 crystal types are visualized in Figure 2. The CIF
construction is described in Appendix A.1.
TheCHILI-3K dataset contains 53 metallic elements and only 1
non-metallic element, oxygen. All structures contain oxygen and
one metal chosen from the 53 options as coloured blue in the peri-
odic table in Figure 3. Every combination of crystal type and metal
is used, regardless of whether the specific element is stable in those
particular crystal types. This is done with the intention for the
CHILI-3K dataset to achieve complete coverage of the well defined
points in this chemical subspace, leading to a total of 636 unique
CIFs.
2.2 CHILI-100K
TheCHILI-100K dataset consists of nanomaterial graphs generated
from a subset of inorganic materials from COD [ 31]. The subset
includes materials which contains any of the 68 metals and 11
non-metals shown in orange in Figure 3. COD was queried for both
purely metallic phases and phases including combinations of metals
and non-metals, like metal oxides. Materials containing elements
not included in the shown selection were removed. For simplicity,
only materials with unit-cell volumes smaller than 1,000Å3were
used in order to avoid the inclusion of e.g. metal organic frameworks
and larger inorganic coordination complexes. The result of the COD
4964KDD ’24, August 25–29, 2024, Barcelona, Spain Ulrik Friis-Jensen et al.
Table 1: Overview of key summary statistics for the two proposed CHILI datasets. (*) indicates the total number of edges; two
for each unique atom-atom pair.
Dataset# of graphs # of nodes # of edges* Generation time
Total Train Validation Test Min Median Max Total Min Median Max Total Total Mean
CHILI-3K 3,180 2,544 318 318 7 1,377 14,793 6,959,085 7 7,212 118,258 49,624,440 02h51m29s 16.18s
CHILI-100K 104,408 83,526 10,441 10,441 2 1,054 21,427 183,398,463 2 5,336 413,762 1,251,841,365 68h25m12s 11.80s
11
H1
2
He18
23
Li4
Be2 CHILI-3K
MetalNon-
metalCHILI-100K
MetalNon-
metal5
B13
6
C14
7
N15
8
O16
9
F17
10
Ne
311
Na12
Mg13
Al14
Si15
P16
S17
Cl18
Ar
419
K20
Ca21
Sc3
22
Ti4
23
V5
24
Cr6
25
Mn7
26
Fe8
27
Co9
28
Ni10
29
Cu11
30
Zn12
31
Ga32
Ge33
As34
Se35
Br36
Kr
537
Rb38
Sr39
Y40
Zr41
Nb42
Mo43
T c44
Ru45
Rh46
Pd47
Ag48
Cd49
In50
Sn51
Sb52
T e53
I54
Xe
655
Cs56
Ba57-7172
Hf73
T a74
W75
Re76
Os77
Ir78
Pt79
Au80
Hg81
Tl82
Pb83
Bi84
Po85
At86
Rn
787
Fr88
Ra89-103104
Rf105
Db106
Sg107
Bh108
Hs109
Mt110
Ds111
Rg112
Cn113
Nh114
Fl115
Mc116
Lv117
T s118
Og
657
La58
Ce59
Pr60
Nd61
Pm62
Sm63
Eu64
Gd65
Tb66
Dy67
Ho68
Er69
Tm70
Yb71
Lu
789
Ac90
Th91
Pa92
U93
Np94
Pu95
Am96
Cm97
Bk98
Cf99
Es100
Fm101
Md102
No103
Lr
Figure 3: The periodic table with each element colored
depending on if they are included in CHILI-3K (blue),
CHILI-100K (orange) or none of them (light grey). The shade
of the colors indicate whether the element is considered a
metal (bright) or a non-metal (muted).
query was saved as COD IDs in a csv file, which can be found in
the GitHub repository2.
The corresponding, downloaded CIFs were cleaned for issues
that caused the CIF to be unreadable or could potentially impact
the further analysis. From the original query to COD we obtain
61,794COD IDs, which reduces to 20,882usable CIFs after cleaning.
The specific choices used to clean COD to obtain CHILI-100K are
reported in Appendix A.2.
TheCHILI-100K dataset is intended to mimic the data distribu-
tion of real world materials. However, we want to emphasize that
there is an inherent bias with using a database comprising experi-
mental materials. This bias is towards known materials, which are
stable and easier to synthesize, but it does not cover all possible
materials in the chosen chemical subspace. This is especially im-
portant to consider when tasked with generating novel materials
using CHILI-100K.
2.3 Data structure
The data objects follow standard graph data structure common in
graph ML comprising node features as x, edges specified in the co-
ordinate (COO) format as edge_index , edge features as edge_attr
and the graph labels stored in a dictionary y. Taking inspiration
from molecular graph datasets, like QM9 [ 67,68], the atomic po-
sitions are not given with the other node features, but instead as
separate attributes for the absolute atomic coordinates, pos_abs ,
and the fractional atomic coordinates, pos_frac . Different target
properties that are of interest for inorganic chemistry are gener-
ated for both the datasets and included to be either used as target
variables or conditioning inputs. A detailed overview of the data
2https://github.com/UlrikFriisJensen/CHILI/blob/main/generation/COD_subset_IDs.csvstructure with all the input and target properties is presented in
Table 2.
2.4 Dataset statistics
With the assumption that the true atomic structure of nanomaterials
can be approximated using the unit cell of the crystalline material,
it is meaningful to consider the distribution of crystal systems
in the proposed datasets. The 7 crystal systems are a high level
description of the symmetry present in the crystalline material,
going from triclinic (lowest symmetry) to cubic (highest symmetry).
The distribution of crystal systems in the CHILI datasets are shown
in Figure 4a. From this it is clear that CHILI-3K only has the 4 crystal
systems with the highest symmetry present and that the cubic
system is over-represented with almost 60 % of the data. However,
this imbalance matches the crystal systems of the crystal types, as
defined in West et al. [ 85]. The CHILI-100K dataset consists of all
7 crystal systems, but they are not equally distributed. The most
represented crystal system is orthorhombic, with about 25 % of
the data, and the least represented crystal system is triclinic, with
around 7 % of the data. As the data was not selected from COD based
on the crystal systems, we can assume that the real distribution of
crystal systems in inorganic materials is roughly the same as we
observe here.
It is also interesting to look at the distribution of number of
unique elements in the nanomaterials in the two datasets, as this
can be used as an additional way of determining structural diversity
in the dataset. From Figure 4b we see that CHILI-3K only contains
nanomaterials with 2 elements, as it was constructed in this way.
ForCHILI-100K the number of elements range from 1 to 7, with
most nanomaterials having between 2 and 4 elements.
As we are dealing with nanomaterials that have a finite size, it is
also relevant to look at the distribution of sizes in the two datasets.
Referring to Figure 4c, we observe that while some nanoparticles
match the specified generation size precisely, most structures ap-
pear larger. This comes from the non-metals coordinated to the
metallic particle core. Note as well, that the larger structural diver-
sity in CHILI-100K constitutes to a smoother size distribution than
that of CHILI-3K.
3 RELATED WORK
The intersection of chemistry and graph ML is an active area of
research that has resulted in several interesting data sources, meth-
ods, and research directions. A short review of these are presented
in this section.
3.1 Data sources
Graph datasets: Graph datasets can vary a lot depending on the
domain the graphs are from, their scales, and the types of tasks
they are designed to be used for. The OGB benchmark contains a
4965CHILI: Ch emically-I nformed L arge-scale I norganic Nanomaterials Dataset for Advancing Graph Machine Learning KDD ’24, August 25–29, 2024, Barcelona, Spain
Table 2: Overview of the CHILI data structure. Level 1 names are inherited from the PyTorch Geometric [ 23]Data class, with the
posargument being split into pos_frac and pos_abs . The ydictionary contains relevant chemical attributes which can be used
as prediction targets or as inputs for structure generation tasks.
NameShape DescriptionLevel 1 Level 2
x [n_atoms, 4] Node feature matrix. [atomic_number, atomic_radius (Å),atomic_weight, electron_affinity (eV)]
edge_index [2, n_bonds] Graph connectivity in sparse coordinate (COO) format.
edge_attr [n_bonds, 1] Edge feature matrix. [distance (Å)]
ycrystal_type — Name of the crystal type or "Unknown".
space_group_symbol — Space group symbol of the unit cell in Hermann-Mauguinn/international notation.
space_group_number — Space group number of the unit cell.
crystal_system — Name of the crystal system.
crystal_system_number — Logit corresponding to the crystal system from lowest to highest symmetry.
atomic_species [n_atomic_species] Unique atom number matrix.
n_atomic_species — Number of unique atomic species in the nanoparticle.
np_size — Diameter of the nanoparticle measured in Ångströms (1 Å = 10−10m).
n_atoms — Number of atoms in the nanoparticle.
n_bonds — Number of “bonds" in the nanoparticle.
cell_params [6] Cell parameter matrix. The cell parameters are [a (Å),b(Å),c(Å),𝛼(°),𝛽(°),𝛾(°)].
unit_cell_node_feat [unit_cell_n_atoms, 4] Node feature matrix for the unit cell.
unit_cell_edge_index [2, unit_cell_n_bonds] Graph connectivity in COO format.
unit_cell_edge_feat [unit_cell_n_bonds, 1] Edge feature matrix.
unit_cell_pos_abs [unit_cell_n_atoms, 3] Node position matrix (absolute coordinates) for the unit cell.
unit_cell_pos_frac [unit_cell_n_atoms, 3] Node position matrix (fractional coordinates) for the unit cell.
unit_cell_n_atoms — Number of atoms in the unit cell.
unit_cell_n_bonds — Number of “bonds" in the unit cell.
nd [2, 580] Simulated neutron diffraction (ND) from the nanoparticle.
xrd [2, 580] Simulated X-ray diffraction (XRD) from the nanoparticle.
nPDF [2, 6000] Simulated neutron pair distribution function (PDF) from the nanoparticle.
xPDF [2, 6000] Simulated X-ray pair distribution function (PDF) from the nanoparticle.
sans [2, 300] Simulated small-angle neutron scattering (SANS) from the nanoparticle.
saxs [2, 300] Simulated small-angle X-ray scattering (SAXS) from the nanoparticle.
pos_frac [n_atoms, 3] Node position matrix (fractional coordinates).
pos_abs [n_atoms, 3] Node position matrix (absolute coordinates).
Triclinic Orthorhombic Trigonal Cubic
Monoclinic T etragonal Hexagonal0%10%20%30%40%50%60%Percentage of dataseta)Dataset
CHILI-3K CHILI-100K
1 2 3 4 5 6 7
# of elements0%10%20%30%40%50%60%70%80%90%100%Percentage of datasetb)
6 70.00%0.10%0.20%0.30%0.40%0.50%0.60%Dataset
CHILI-3K CHILI-100K
0 10 20 30 40 50 60
Nanoparticle size (Å)0.000.050.100.150.200.25Densityc)Dataset
CHILI-3K CHILI-100K
Figure 4: a) Distribution of crystal systems in the CHILI-3K dataset (blue) and the CHILI-100K dataset (orange). b) Distribution of
the number of unique elements in each structure for the CHILI-3K dataset (blue) and the CHILI-100K dataset (orange). The inset
plot shows 6 and 7 elements at a more appropriate y-axis scale. c) Distribution of the size of the generated nanoparticles for the
CHILI-3K dataset (blue) and the CHILI-100K dataset (orange).
broad overview of existing graph datasets [ 39], with single- and
multi- graph datasets being the two high-level types. The former
consists of a single large graph, like knowledge graphs [ 76] and
social networks [ 55], which then has nodes and edges split into
training, validation and test sets. These datasets are primarily in-
tended for transductive learning such as node- or edge-level predic-
tion tasks [ 49]. Multi-graph datasets consists of many, often small,
graphs. These could be molecular graphs [ 68] or protein-protein in-
teraction graphs [ 94], which are then split into training, validation
and test set at the graph level. These kinds of datasets are mostly
used for inductive learning at the graph-level, but both node- and
edge-level tasks are feasible too [35].Molecular graph datasets: As molecules can be easily repre-
sented using graphs, datasets consisting of molecular graphs have
played an important part in the development of GNNs [ 22,28]. A
wide variety of molecular graph datasets exists for many differ-
ent purposes, as seen in QM9 [ 67,68] which is focused on density
functional theory (DFT) calculated molecular properties, ZINC [ 74],
which is focused on drug discovery, and MoleculeNet [ 86], which is
a benchmark collection of molecular graph datasets within quantum
chemistry, physical chemistry, biophysics and physiology.
Structural databases: The structural databases in chemistry
mainly contain crystal structures solved from crystallography ex-
periments, and in some cases also synthetic crystal structures,
4966KDD ’24, August 25–29, 2024, Barcelona, Spain Ulrik Friis-Jensen et al.
which are stored in CIFs [ 10]. A wide variety of structural databases
exists today, with some of the most widely used being the Cam-
bridge Structural Database (CSD) [ 34], the Inorganic Crystallogra-
phy Structure Database (ICSD) [ 92], the COD [ 21,31–33,62,63,66,
78, 79] and the Materials Project (MP) [42].
Material graph datasets: The representation of materials are
similar to molecules in many ways, but differ in two critical aspects.
Firstly, unlike molecules, materials feature diverse bonding types
across varying scales. This makes the translation of the atoms in a
material into nodes and edges less trivial. Secondly, materials are pe-
riodic and often described only as their smallest repeating unit – the
unit cell – and a set of symmetry operations called the spacegroup.
Material graphs are, therefore, of similar scale as molecular graphs,
but with added periodicity through the edges. Recently material
graphs have garnered more interest with the growing popularity
of MP [ 42], the publication of the Open Quantum Materials Data-
base (OQMD) [ 50] and the Open Catalyst datasets: OC20 [ 13] and
OC22 [ 77]. The primary focus with these datasets has been in the
discovery of new catalysts and energy storage materials [ 17,54,93],
approximating DFT with ML [ 46] and most recently foundational
models for materials [4].
Nanomaterial graph datasets: Nanomaterials are distinguished
from other materials by their finite and small size, which invali-
dates the assumption of long-range periodicity. Thus, to properly
describe a nanomaterial, all atoms must be explicitly defined, which
significantly increases the scale of a nanomaterial graphs compared
to molecules and materials. Nanomaterials can be further catego-
rized into nanoclusters – nanomaterials with a size of < 1nm and up
to 100-150 atoms – and nanoparticles – nanomaterials with a size
between 1 and 100 nm and upwards of 10’s - 100’s of thousands of
atoms – [ 11,91]. To our knowledge, only a few nanomaterial graph
datasets exist in the literature. We only know of one nanocluster
graph dataset from Fung et al [ 25] (data from [ 24]) with 20,000
configurations of 10 to 13 platinum atoms. We also know of some
non-graph datasets related to nanomaterials, like the dataset from
Manna et al. [ 58] with 63,015 DFT relaxed nanoclusters from 55
different elements and the dataset from Barnard et al. [ 3] with 425
silver nanoparticles ranging in size from 13 to 2947 atoms.
3.2 Graph ML tasks
Material property prediction: Predicting material properties
using graph ML is an inductive learning task that necessitates gen-
eralization of learnt behaviour at node- and graph- levels to unseen
chemical graphs [ 35]. There have been several attempts at feature-
engineering as a means to do so; as this would circumvent the
need for graph representations [ 30,43,44,83]. These methods use
descriptors from the materials that are agnostic to the arrangement
of atoms within them. They rely solely on attributes such as stoi-
chiometry, elemental statistics, electronic structure and the ionic
compound. For instance, an ML framework for formation energy
prediction using a total of 145 attributes including those mentioned
above was proposed in Ward et al. [ 84]. Other studies consider
the periodic crystal structures of the materials and expand upon
the principles of crystallography to derive periodic graphs which
gives insights into material properties [ 16,57,71,88]. Some salient
examples include the crystal graph convolution network [ 88], thataims to capture atom interactions across the cell boundaries by
using multi-edge graphs, and the atomistic line GNN [ 16], that
considers not only the distances between neighboring atoms but
also the angles at which they are arranged within the crystal lat-
tice. These models have been shown to perform well on predicting
several structure properties, including formation energies. Still,
to our knowledge, only few attempts have been made to model
properties associated with materials that lack long-range order;
like nanomaterials, clusters, as well as amorphous- and disordered
materials [2, 25].
Inverse materials design: Using graph ML for materials de-
sign poses a more challenging task than property prediction tasks.
In this setting, the structure, or a set of potential structures, of a
material that match desired properties or functions are explored.
Latent variable models are used to this end, as they can be used in
generative settings while respecting any conditioning inputs like
the atomic composition of the material, catalytic ability, stability
or structural characteristics such as those derived from X-ray and
neutron diffraction experiments [ 1]. Xie et al., for instance, employ
a crystal-diffusion variational autoencoder to generate stable crys-
tal structures [ 87]. They encode materials into a lower-dimensional
latent space, from where a property predictor network predicts
attributes such as composition and lattice parameters and trans-
lates them into crystal structures by applying them to randomly
initialized unit cell structures. A GNN is then used to optimize the
atomic positions until reaching equilibrium. In a similar manner,
Merchant et al. investigates the use of GNNs for the purpose of
discovering new crystal structures in their recent work [ 60]. The
iterative training process of these specific GNNs, known as Graph
Networks for Materials Exploration, includes filtering potential
structures according to initial predictions and then validating en-
ergy computations with DFT. When it comes to inverse design for
nanomaterials on the other hand, little progress has been made.
Recently however, some advancements have been achieved in de-
termining the atomic structure of nanomaterials using scattering
data. Specifically, Kjær et al. introduce DeepStruc [ 51], a conditional
variational autoencoder that is capable of determining the atomic
structures of a subset of mono-metallic nanoparticles directly from
their pair distribution functions (PDFs) derived from total scatter-
ing data. DeepStruc successfully determines structures from PDFs
originating from seven distinct structure types. This is achieved on
both simulated and experimental PDFs.
Significance of graph ML in materials chemistry: Advanc-
ing the understanding and development of materials requires intri-
cate simulations and predictions that encompass everything from
atomic configurations to crystal systems and their dynamic be-
haviour under varying conditions. Classifying atomic identities,
such as atomic numbers, plays a crucial role, allowing researchers to
simulate hypothetical materials or modify existing ones to optimise
specific properties, including vacancies and substituted atomic sites
(doping), which can greatly alter their functionality depending on
the physical conditions [ 6]. Equally critical is the classification of
crystal systems and space groups, which supports high-throughput
screening by providing essential data for accurate simulations and
aiding in the exploration of chemical spaces. This classification
becomes especially important when identifying the physical con-
ditions under which materials undergo phase transitions [ 6,75].
4967CHILI: Ch emically-I nformed L arge-scale I norganic Nanomaterials Dataset for Advancing Graph Machine Learning KDD ’24, August 25–29, 2024, Barcelona, Spain
Table 3: Trainable parameters in the GNN backbone. Note:
The final linear layers are not included, as these add a task-
specific number of trainable parameters consistent across all
models.
Model Parameters (k) Model Parameters (k)
GCN 2.37 GraphUNet 5.61
PMLP 2.36 GIN 7.58
GraphSAGE 4.64 EdgeCNN 42.37
GAT 4.92
The exact relationship between the structure of a nanoparticle and
its properties is highly complex, which is why determining the
precise positions of atoms within a material is a formidable task.
Being able to accurately predict the positions of atoms within the
materials, however, is fundamental for the design of a material with
desirable properties [ 6]. Scattering data, such as SAXS, XRD and
PDF provide valuable information about the arrangement of atoms
within the materials [ 7], and so if these signals can be successfully
used to guide the generation of nanoparticles, this could accelerate
the discovery of novel materials.
4 EXPERIMENTS AND BENCHMARKING
To characterise the two CHILI datasets across different experiments
we perform a selection of classification-, regression- and structure
generation- tasks. For each task, we also report simpler baselines
like random prediction, most frequent class (MFC), and mean pre-
diction, wherever appropriate. We use a range of off-the-shelf GNN
models as backbone networks and add an additional linear layer
as the last layer to predict the appropriate number of classes or
regression targets. The GNN backbone models are ordered by their
model complexity, which we measure as the number of trainable
parameters and show in Table 3.
•GCN: We use a two-layer Graph Convolutional Network
(GCN) [ 49] with a hidden layer size of 32 and a learning rate
of 0.01, optimized using Adam [48].
•PMLP: The propagational multi-layer perceptron (PMLP) [ 90]
model uses GCN hyperparameters.
•GraphSAGE: The GraphSAGE [ 35] model uses the default
mean aggregator and the same hyperparameters as the GCN.
•GAT: The graph attention network (GAT) [ 80] model em-
ploys a GATConv convolution with a hidden layer size of 64,
using GCN default hyperparameters for the rest.
•GraphUNet: The graph U-Net [ 27] with a pooling ratio of 0.5
and a depth of 2 uses GCN hyperparameters due to memory
constraints.
•GIN: The graph isomorphism network (GIN) [ 89], specifi-
cally the GIN-0 variant with 𝜖fixed to 0, uses GCN hyperpa-
rameters.
•EdgeCNN: We use a 4-layer EdgeCNN [ 83] with a hidden
layer size of 64, retaining GCN hyperparameters.
Experimental set-up: The hyperparameters for the GNN back-
bone models were chosen based on the reported values from the
respective papers. When the hyperparameters were not reported,
we used the default values of the GCN [ 49]. Each experiment was re-
peated three times with different seeds, an early stopping with a pa-
tience of 50epochs was used, and a global training-time constraintTable 4: Overview of task setups. Node-level tasks use a GNN
layer matching class/target size. Edge-level tasks predict edge
distances via dot product of node features. Graph-level tasks
summarize with mean, sum, and max pooling. Generative
tasks normalize data, and an MLP outputs atom coordinates
with error propagation restricted by a ground truth mask.
Classification task Level # of classes
atomic_number Node 118
crystal_system_number Graph 7
space_group_number Graph 230
Regression task Level Target size
pos_abs (position) Node 3
edge_attr (distance) Edge 1
saxs Graph 300
sans Graph 300
xrd Graph 580
nd Graph 580
xPDF Graph 6000
nPDF Graph 6000
Structure generation task max # atoms
saxs→unit_cell_pos_frac 20
xrd→unit_cell_pos_frac 20
xPDF→unit_cell_pos_frac 20
saxs→pos_abs 200
xrd→pos_abs 200
xPDF→pos_abs 200
of one hour per experiment was used to limit the computational
costs.
The complete CHILI-3K dataset was used in each experiment,
whereas a comparable subset of 2975 samples from the CHILI-100K
dataset was used. The sub-sampling procedure was stratified based
oncrystal_system_number, resulting in each of the 7 classes be-
ing represented equally within the subset. All the models were
implemented in Pytorch [ 65], and Pytorch-Geometric [ 23] was
used for the graph ML portions.
Property prediction tasks: We propose three types of classifi-
cation tasks for predicting: atom, crystal system and space group.
The eight regression tasks for predicting: atom position, distance
and six variations of scattering data from the nanomaterials (SAXS,
SANS, XRD, ND, xPDF, nPDF).
Structure generation tasks: To the best of our knowledge, no
existing GNN models can be applied directly to the task of generat-
ing structures taking the available properties in the CHILI -datasets
as input. We propose two simple formulations of the generative
tasks, where the models receive one of the scattering data as in-
put and is tasked with predicting (1) the fractional coordinates
of the unit cell associated with that discrete particle and (2) the
absolute atomic coordinates of the discrete particles. As a further
simplification, note that, we ignore the prediction of any other node
attributes.
Metrics: For evaluating the classification tasks, we use the
weighted F1-score. For the regression tasks we use the mean abso-
lute error (MAE) on the 3D positions for pos_abs and mean squared
error (MSE) for edge_attr-, saxs-, xrd- and xPDF.
5 RESULTS AND DISCUSSION
We next present the results for the different tasks described in Ta-
ble 4. An overview of results on both CHILI datasets for all the
4968KDD ’24, August 25–29, 2024, Barcelona, Spain Ulrik Friis-Jensen et al.
Table 5: Overview of property prediction benchmark experiments on the CHILI-3K and CHILI-100K datasets. All experiments
were repeated 3 times with different seeds, early stopping with a patience of 50 epochs and a maximum training time of 1 hour.
Random: random class prediction, MFC: Most Frequent Class. Models are reported in increasing order of complexity measured
in terms of the number of trainable parameters in the GNN backbone.
Task type Classification Regression
Task level Node Graph Node Edge Graph
Target atomic_num. crystal_system_num. space_group_num. pos_abs edge_attr saxs xrd xPDF
Metric Weighted F1-score ( ↑) Pos. MAE ( ↓) MSE ( ↓)CHILI-3KRandom 0.016± 0.000 0.191± 0.008 0.009± 0.008 —
— — — —
MFC 0.461 0.440 0.108 — — — — —
Mean — — — 16.575 0 .265 0 .037 0 .017 0.008
GCN [49] 0.496± 0.001 0.367± 0.127 0.099± 0.019 16.575± 0.000 0.056± 0.006 0.008± 0.000 0.010± 0.000 0.012± 0.000
PMLP [90] 0.461± 0.000 0.440± 0.036 0.135± 0.006 16.575± 0.000 0.359± 0.017 0.022± 0.025 0.010± 0.000 0.012± 0.000
GraphSAGE [35] 0.491± 0.004 0.422± 0.037 0.151± 0.045 16.575± 0.000 0.055± 0.002 0.008± 0.001 0.010± 0.000 0.012± 0.000
GAT [80] 0.461± 0.000 0.504± 0.076 0.113± 0.013 16.575± 0.000 0.342± 0.117 0.008± 0.000 0.010± 0.000 0.029± 0.030
GraphUNet [27] 0.552± 0.079 0.431± 0.014 0.095± 0.036 14.765± 0.395 0.055± 0.001 0.008± 0.000 0.010± 0.000 0.012± 0.000
GIN [89] 0.587± 0.002 0.438± 0.004 0.125± 0.026 16.575± 0.000 0.464± 0.005 0.008± 0.000 Unstable Unstable
EdgeCNN [83] 0.632± 0.009 0.657± 0.196 0.733± 0.207 16.575± 0.000 0.015± 0.001 0.006± 0.004 0.008± 0.001 0.011± 0.000CHILI-100KRandom 0.015± 0.000 0.168± 0.014 0.002± 0.001 —
— — — —
MFC 0.192 0.046 0.010 — — — — —
Mean — — — 16.336 0 .307 0 .038 0 .021 0.007
GCN [49] 0.275± 0.002 0.069± 0.023 0.043± 0.001 16.336± 0.000 0.090± 0.002 0.010± 0.000 0.009± 0.000 0.014± 0.000
PMLP [90] 0.191± 0.000 0.124± 0.036 0.047± 0.012 16.336± 0.000 0.486± 0.014 0.003± 0.000 0.008± 0.001 0.013± 0.000
GraphSAGE [35] 0.195± 0.007 0.061± 0.019 0.044± 0.002 16.337± 0.000 0.064± 0.001 0.011± 0.002 0.018± 0.014 0.037± 0.026
GAT [80] 0.192± 0.000 0.110± 0.029 0.044± 0.001 16.336± 0.000 0.252± 0.003 0.009± 0.000 0.108± 0.172 0.013± 0.000
GraphUNet [27] 0.287± 0.004 0.068± 0.006 0.043± 0.000 14.824± 0.315 0.085± 0.002 0.009± 0.000 0.009± 0.000 0.013± 0.000
GIN [89] 0.336± 0.005 0.069± 0.040 0.043± 0.000 16.336± 0.000 0.491± 0.038 0.009± 0.000 0.009± 0.000 0.013± 0.000
EdgeCNN [83] 0.572± 0.017 0.072± 0.047 0.158± 0.035 16.336± 0.000 0.030± 0.001 0.007± 0.009 0.006± 0.000 0.012± 0.000
property prediction tasks are reported in Table 5, and for the struc-
ture generation tasks in Table 6. High-level trends observed for
each task type are outlined next. Note that the methods in Table 5
are sorted in increasing order of their complexity measured as the
number of trainable parameters in the GNN-backbone (See Table 3)
Classification: The naive predictors (random, MFC values) pro-
vide a useful baseline when comparing the more sophisticated
GNN-based methods. In a majority of the scenarios, across the
three classification tasks and the two datasets, the GNN-based meth-
ods do better than these naive baseline methods. In some cases the
GNN-based methods end up in a local minimum matching the naive
baselines, such as PMLP and GAT predicting only the most frequent
atom (Oxygen) in the atomic_num task. In the instances where the
GNN methods end up trapped in local minima or perform worse
than the naive baselines, it could be explained by factors such as
sub-optimal hyperparameters and limited training time.
For the CHILI-3K dataset, EdgeCNN [ 83] which is the most com-
plex model in terms of the number of parameters, consistently
outperforms the other GNN-based methods across all the three
classification tasks. This is an interesting trend which points to the
usefulness of learning and aggregating features along the edges.
This is in contrast to using node attributes along with the existing
edge attributes as done with GCN [49] and GAT [80].
TheCHILI-100K dataset which is more challenging compared
to the CHILI-3K dataset is reflected in the poor performance in all
classification tasks by bulk of the GNN-based methods. In particular,
crystal_system_number classification appears to be challenging
for all the models.
Regression: Regression tasks are generally more difficult for
deep learning models, due to factors such as incorrectly tunedbias parameters [ 41]. Furthermore, the specific regression tasks
formulated in these benchmarking tasks are more complex than the
classification ones. This additional complexity could be due to the
globalness of the prediction tasks, the dimensionality of the predic-
tions, and a lack of informative features in the input. The difficulty
of these regression tasks is reflected across the board, including
both CHILI datasets, where the mean prediction seems to perform
comparable to the GNN methods. The pos_abs task in particular is
very difficult with only the GraphUNet model managing to escape
the local minima of predicting all positions to be in the origin of
the coordinate system, which here coincides with the geometric
center of the nanomaterials.
For the regression of scattering data ( saxs,xrd,xPDF ), the per-
formance trends of the GNN-based models are slightly better. Meth-
ods like EdgeCNN [ 83] again shows better performance compared
to other methods. It is important to note that in the materials chem-
istry community the focus typically is not on estimating scattering
data from material graphs. This is primarily because the scatter-
ing data can easily be simulated, as demonstrated with the CHILI -
datasets, using open-source software such as DebyeCalculator [ 45].
Consequently, the primary use of scattering data lies in the inverse
task, such as using experimental scattering data to infer the atomic
structure of the material. This being said, there is still potential
value in accurately modelling scattering data from material graphs,
particularly in the pursuit of discovering new materials. By do-
ing so, researchers can explore the intricate relationship between
structure and scattering data, facilitating data-driven approaches
to material design.
Structure generation: The inverse materials design task is
simplified as the prediction of pos_abs andunit_cell_pos_frac
4969CHILI: Ch emically-I nformed L arge-scale I norganic Nanomaterials Dataset for Advancing Graph Machine Learning KDD ’24, August 25–29, 2024, Barcelona, Spain
Table 6: Overview of structure generation benchmark ex-
periments on the CHILI-3K and CHILI-100K datasets. All ex-
periments were repeated 3 times with different seeds, early
stopping with a patience of 50 epochs and a maximum train-
ing time of 1 hour.
TaskCHILI-3K CHILI-100K
MAE (↓)
saxs→unit_cell_pos_frac 0.053± 0.009 0.198± 0.003
xrd→unit_cell_pos_frac 0.008± 0.002 0.191± 0.000
xPDF→unit_cell_pos_frac 0.014± 0.002 0.193± 0.001
saxs→pos_abs 1.539± 0.007Å 2.783± 0.002Å
xrd→pos_abs 1.894± 0.014Å 2.779± 0.006Å
xPDF→pos_abs 1.952± 0.052Å 2.780± 0.008Å
features in the structure generation task. Reliable estimates of these
two target variables can then be used to generate structures.
For both CHILI-3K andCHILI-100K , the structure generation
task show moderate errors across all different types of scattering
data, as reported in Table 6. The structure generation model gen-
erally performs better on the CHILI-3K dataset. The discrepancy
between the two CHILI datasets reflects the broader structural di-
versity present in the more complex CHILI-100K dataset.
Structure generation with the unit_cell_pos_frac target yields
better reconstructions of the unit cell fractional coordinates. No-
tably on CHILI-3K , MAE values drop as low as 0.008using xrd.
This outcome is expected, particularly on CHILI-3K , where the unit
cell positions of each structure are tightly constrained, ranging
from 0to1, and the unit cells themselves are mutually very distinct,
which reduces the structure generation task to a form of classifica-
tion into the 12 crystal systems visualized in Figure 2. Even then,
a moderately higher MAE using saxs is to be expected. This is
primarily because of the nature of SAXS data, which inherently
lacks information on the unit cell parameters. The slightly higher
MAE on CHILI-100K is due to the presence of moderately more
irregular unit cells.
6 CONCLUSION
In this work we have presented a chemically-informed approach
to generate large-scale graph datasets of nanomaterials. Using
this approach we have provided two novel nanomaterial graph
datasets: the medium-scale CHILI-3K dataset from mono-metal
oxides with a wide range of interesting applications, and the large-
scale CHILI-100K dataset from an experimental materials database
with high structural diversity.
The two CHILI datasets were benchmarked on 11 property pre-
diction tasks using naive baselines and 7 off-the-shelf GNN models.
The results show that all property prediction tasks are tractable,
but also difficult enough that none of the off-the-shelf models are
able to achieve usable performance for chemical applications. The
EdgeCNN model performs best in general, which could be attributed
to the layer architecture or that it has the most trainable param-
eters. Some tasks, like atomic_number classification and pos_abs
regression, shows a tendency for the models getting stuck in local
minima. We therefore think that future work that focus on these
tasks would be of high impact.
The datasets were also benchmarked on 6 structure prediction
tasks using a simple property-to-structure model. The results showthat, in a simplified setup, these tasks are tractable and harder to
solve for discrete particles than the crystalline unit cells. This high-
lights the need for more work to address the challenges related to
generation of variable size graphs and to achieve sub-Ångström po-
sitional precision, which would be useful for chemical applications.
Limitations: Both CHILI datasets assume that a discrete nanopar-
ticle can be approximated using the unit cell from the crystalline
material. This is not entirely physical, but we find it to be an accept-
able trade-off for not having to relax all nanoparticles using DFT,
which would require significant expertise and additional compute
resources.
Because of the way that CHILI-3K is constructed, the fractional
atomic positions in the unit cells are identical across structures in
each of crystal type subsets. Models trained for unit_cell_pos_frac
prediction tasks should therefore not be validated only on this
dataset. We do not expect and have not observed any effects of this
on the other tasks.
The data in CHILI-100K is generated from a database of experi-
mental materials, which has an inherent bias towards easily synthe-
sized and stable crystalline materials. The data does, therefore, not
cover all parts of the relevant chemical space equally and does not
account for potential differences in stability between crystalline-
and nanomaterials. This is especially important to consider if the
CHILI-100K dataset is used for generating novel nanomaterials.
The benchmark experiments were performed with limited hyper-
parameter tuning. The specific performance obtained by the GNN
methods could be improved further by meticulous hyperparameter
tuning or including additional tuning of the network architecture.
Open challenges and future work: The prediction of 3D coor-
dinates in chemical systems is an open problem in the chemistry and
ML literature. This includes the chemical validity of the prediction
and the consideration that the relative positions compared to the
whole molecule or (nano) material are often more important than
the absolute positions. We think the CHILI datasets can be an im-
portant contribution here with the multitude of complex positional
data and the associated scattering data, which can be used as input
signals, or measures for prediction quality.
Generative modelling of graphs with variable number of nodes
and/or edges is also an open problem in the graph ML literature.
Solving this could revolutionise the field of generative graph ML,
and thus also helping materials chemistry. One of the key lim-
itations of the current state-of-the-art is the lack of datasets to
facilitate scalability of graph generative models. We hope that the
CHILI datasets can be an important contribution to this end.
ACKNOWLEDGMENTS
This work is part of a project that has received funding from the
European Research Council (ERC) under the European Union’s
Horizon 2020 Research and Innovation Programme (grant agree-
ment No. 804066). We are grateful for funding from University of
Copenhagen through the Data Plus program.
The authors also acknowledge participants of the Geilo Winter
School on Graphs and Applications (Norway, 2024) for stress-testing
an early subset of the data.
4970KDD ’24, August 25–29, 2024, Barcelona, Spain Ulrik Friis-Jensen et al.
REFERENCES
[1]Andy S. Anker, Emil T. S. Kjær, Erik B. Dam, Simon J. L. Billinge, Kirsten M. Ø.
Jensen, and Raghavendra Selvan. 2020. Characterising the atomic structure
of mono-metallic nanoparticles from x-ray scattering data using conditional
generative models. In Proceedings of the 16th International Workshop on Mining
and Learning with Graphs (MLG).
[2]Suvo Banik, Debdas Dhabal, Henry Chan, Sukriti Manna, Mathew Cherukara,
Valeria Molinero, and Subramanian K. R. S. Sankaranarayanan. 2023. CEGANN:
Crystal Edge Graph Attention Neural Network for multiscale classification of
materials environment. npj Computational Materials 9, 1 (2023). https://doi.org/
10.1038/s41524-023-00975-z
[3]Amanda Barnard, Baichuan Sun, Benyamin Motevalli Soumehsaraei, and George
Opletal. 2017. Silver Nanoparticle Data Set. https://doi.org/10.25919/
5d22d20bc543e
[4]Ilyes Batatia, Philipp Benner, Yuan Chiang, Alin M. Elena, Dávid P. Kovács,
Janosh Riebesell, Xavier R. Advincula, Mark Asta, William J. Baldwin, Noam
Bernstein, Arghya Bhowmik, Samuel M. Blau, Vlad Cărare, James P. Darby,
Sandip De, Flaviano Della Pia, Volker L. Deringer, Rokas Elijošius, Zakariya
El-Machachi, Edvin Fako, Andrea C. Ferrari, Annalena Genreith-Schriever, Ja-
nine George, Rhys E. A. Goodall, Clare P. Grey, Shuang Han, Will Handley,
Hendrik H. Heenen, Kersti Hermansson, Christian Holm, Jad Jaafar, Stephan
Hofmann, Konstantin S. Jakob, Hyunwook Jung, Venkat Kapil, Aaron D. Kaplan,
Nima Karimitari, Namu Kroupa, Jolla Kullgren, Matthew C. Kuner, Domantas
Kuryla, Guoda Liepuoniute, Johannes T. Margraf, Ioan-Bogdan Magdău, Angelos
Michaelides, J. Harry Moore, Aakash A. Naik, Samuel P. Niblett, Sam Walton
Norwood, Niamh O’Neill, Christoph Ortner, Kristin A. Persson, Karsten Reuter,
Andrew S. Rosen, Lars L. Schaaf, Christoph Schran, Eric Sivonxay, Tamás K.
Stenczel, Viktor Svahn, Christopher Sutton, Cas van der Oord, Eszter Varga-
Umbrich, Tejs Vegge, Martin Vondrák, Yangshuai Wang, William C. Witt, Fabian
Zills, and Gábor Csányi. 2024. A foundation model for atomistic materials chem-
istry. (2024). https://doi.org/10.48550/arXiv.2401.00096
[5]Ilyes Batatia, David P Kovacs, Gregor Simm, Christoph Ortner, and Gábor Csányi.
2022. MACE: Higher order equivariant message passing neural networks for
fast and accurate force fields. Advances in Neural Information Processing Systems
(NeurIPS) (2022).
[6]Bharat Bhushan and David Luo. 2010. Nanomaterials, Nanotechnologies and
Design: An Introduction for Engineers and Architects. Butterworth-Heinemann.
https://doi.org/10.1016/B978-0-7506-8149-0.X0001-3
[7]Simon J. L. Billinge and Igor Levin. 2007. The Problem with Determining Atomic
Structure at the Nanoscale. Science 316, 5824 (2007), 561–565. https://doi.org/10.
1126/science.1135080
[8]Giorgos Bouritsas, Fabrizio Frasca, Stefanos Zafeiriou, and Michael M. Bronstein.
2023. Improving Graph Neural Network Expressivity via Subgraph Isomorphism
Counting. IEEE Transactions on Pattern Analysis and Machine Intelligence 45, 1
(2023), 657–668. https://doi.org/10.1109/TPAMI.2022.3154319
[9]Michael M. Bronstein, Joan Bruna, Yann LeCun, Arthur Szlam, and Pierre Van-
dergheynst. 2017. Geometric Deep Learning: Going beyond Euclidean data. IEEE
Signal Processing Magazine 34, 4 (2017), 18–42. https://doi.org/10.1109/MSP.2017.
2693418
[10] I.D. Brown. 1996. CIF (Crystallographic Information File). A standard for crys-
tallographic data interchange. Journal of Research of the National Institute of
Standards and Technology 101, 3 (1996), 341. https://doi.org/10.6028/jres.101.035
[11] L. E. Brus, P. F. Szajowski, W. L. Wilson, T. D. Harris, S. Schuppler, and P. H. Citrin.
1995. Electronic Spectroscopy and Photophysics of Si Nanocrystals: Relationship
to Bulk c-Si and Porous Si. Journal of the American Chemical Society 117, 10
(1995), 2915–2922. https://doi.org/10.1021/ja00115a025
[12] Cayley. 1874. LVII. On the mathematical theory of isomers. The London, Edin-
burgh, and Dublin Philosophical Magazine and Journal of Science 47, 314 (1874),
444–447. https://doi.org/10.1080/14786447408641058
[13] Lowik Chanussot, Abhishek Das, Siddharth Goyal, Thibaut Lavril, Muhammed
Shuaibi, Morgane Riviere, Kevin Tran, Javier Heras-Domingo, Caleb Ho, Weihua
Hu, Aini Palizhati, Anuroop Sriram, Brandon Wood, Junwoong Yoon, Devi Parikh,
C. Lawrence Zitnick, and Zachary Ulissi. 2021. Open Catalyst 2020 (OC20)
Dataset and Community Challenges. ACS Catalysis 11, 10 (2021), 6059–6072.
https://doi.org/10.1021/acscatal.0c04525
[14] Chi Chen, Weike Ye, Yunxing Zuo, Chen Zheng, and Shyue Ping Ong. 2019.
Graph Networks as a Universal Machine Learning Framework for Molecules and
Crystals. Chemistry of Materials 31, 9 (2019), 3564–3572. https://doi.org/10.1021/
acs.chemmater.9b01294
[15] Jiucheng Cheng, Chunkai Zhang, and Lifeng Dong. 2021. A geometric-
information-enhanced crystal graph network for predicting properties of materi-
als.Communications Materials 2, 1 (2021). https://doi.org/10.1038/s43246-021-
00194-3
[16] Kamal Choudhary and Brian DeCost. 2021. Atomistic Line Graph Neural Network
for improved materials property predictions. npj Computational Materials 7, 1
(2021). https://doi.org/10.1038/s41524-021-00650-1[17] Kamal Choudhary, Daniel Wines, Kangming Li, Kevin F. Garrity, Vishu Gupta,
Aldo H. Romero, Jaron T. Krogel, Kayahan Saritas, Addis Fuhr, Panchapakesan
Ganesh, Paul R. C. Kent, Keqiang Yan, Yuchao Lin, Shuiwang Ji, Ben Blaiszik,
Patrick Reiser, Pascal Friederich, Ankit Agrawal, Pratyush Tiwary, Eric Beyerle,
Peter Minch, Trevor David Rhone, Ichiro Takeuchi, Robert B. Wexler, Arun
Mannodi-Kanakkithodi, Elif Ertekin, Avanish Mishra, Nithin Mathew, Mitchell
Wood, Andrew Dale Rohskopf, Jason Hattrick-Simpers, Shih-Han Wang, Luke
E. K. Achenie, Hongliang Xin, Maureen Williams, Adam J. Biacchi, and Francesca
Tavazza. 2024. JARVIS-Leaderboard: a large scale benchmark of materials design
methods. npj Computational Materials 10, 1 (2024). https://doi.org/10.1038/
s41524-024-01259-w
[18] Mir Sayed Shah Danish, Arnab Bhattacharya, Diana Stepanova, Alexey
Mikhaylov, Maria Luisa Grilli, Mahdi Khosravy, and Tomonobu Senjyu. 2020. A
Systematic Review of Metal Oxide Applications for Energy and Environmental
Sustainability. Metals 10, 12 (2020), 1604. https://doi.org/10.3390/met10121604
[19] Kishalay Das, Bidisha Samanta, Pawan Goyal, Seung-Cheol Lee, Satadeep Bhat-
tacharjee, and Niloy Ganguly. 2023. CrysGNN : Distilling pre-trained knowl-
edge to enhance property prediction for crystalline materials.. In Proceedings
of the AAAI Conference on Artificial Intelligence, Vol. 37. 7323–7331. https:
//doi.org/10.1609/aaai.v37i6.25892
[20] Nicola De Cao and Thomas Kipf. 2018. MolGAN: An implicit generative model
for small molecular graphs. ICML 2018 workshop on Theoretical Foundations and
Applications of Deep Generative Models (2018).
[21] Robert T. Downs and Michelle Hall-Wallace. 2003. The American Mineralogist
crystal structure database. American Mineralogist 88 (2003), 247–250.
[22] David K Duvenaud, Dougal Maclaurin, Jorge Iparraguirre, Rafael Bombarell,
Timothy Hirzel, Alan Aspuru-Guzik, and Ryan P Adams. 2015. Convolutional
Networks on Graphs for Learning Molecular Fingerprints. In Advances in Neural
Information Processing Systems, Vol. 28.
[23] Matthias Fey and Jan Eric Lenssen. 2019. Fast Graph Representation Learning
with PyTorch Geometric. ICLR 2019 Workshop on Representation Learning on
Graphs and Manifolds (2019).
[24] Victor Fung and De-en Jiang. 2017. Exploring Structural Diversity and Fluxional-
ity of Ptn (n = 10–13) Clusters from First-Principles. The Journal of Physical Chem-
istry C 121, 20 (2017), 10796–10802. https://doi.org/10.1021/acs.jpcc.6b11968
[25] Victor Fung, Jiaxin Zhang, Eric Juarez, and Bobby G. Sumpter. 2021. Benchmark-
ing graph neural networks for materials chemistry. npj Computational Materials
7, 1 (2021). https://doi.org/10.1038/s41524-021-00554-0
[26] Sharanabasava V. Ganachari, Leena Hublikar, Jayachandra S. Yaradoddi, and
Shivalingayya S. Math. 2019. Metal Oxide Nanomaterials for Environmental
Applications. 2357–2368. https://doi.org/10.1007/978-3-319-68255-6_196
[27] Hongyang Gao and Shuiwang Ji. 2019. Graph U-nets. In International Conference
on Machine Learning (ICML).
[28] Justin Gilmer, Samuel S. Schoenholz, Patrick F. Riley, Oriol Vinyals, and George E.
Dahl. 2017. Neural Message Passing for Quantum Chemistry. In Proceedings of
the 34th International Conference on Machine Learning, Vol. 70. 1263–1272.
[29] Sheng Gong, Keqiang Yan, Tian Xie, Yang Shao-Horn, Rafael Gomez-Bombarelli,
Shuiwang Ji, and Jeffrey C Grossman. 2023. Examining graph neural networks
for crystal structures: limitations and opportunities for capturing periodicity.
Science Advances (2023). https://doi.org/10.1126/sciadv.adi3245
[30] Rhys E. A. Goodall and Alpha A. Lee. 2020. Predicting materials properties with-
out crystal structure: deep representation learning from stoichiometry. Nature
Communications 11, 1 (2020). https://doi.org/10.1038/s41467-020-19964-7
[31] Saulius Gražulis, Daniel Chateigner, Robert T. Downs, A. F. T. Yokochi, Miguel
Quirós, Luca Lutterotti, Elena Manakova, Justas Butkus, Peter Moeck, and Armel
Le Bail. 2009. Crystallography Open Database – an open-access collection of
crystal structures. Journal of Applied Crystallography 42, 4 (2009), 726–729.
https://doi.org/10.1107/S0021889809016690
[32] Saulius Gražulis, Adriana Daškevič, Andrius Merkys, Daniel Chateigner, Luca
Lutterotti, Miguel Quirós, Nadezhda R. Serebryanaya, Peter Moeck, Robert T.
Downs, and Armel Le Bail. 2011. Crystallography Open Database (COD): an open-
access collection of crystal structures and platform for world-wide collaboration.
Nucleic Acids Research 40, D1 (2011), D420–D427. https://doi.org/10.1093/nar/
gkr900
[33] Saulius Gražulis, Andrius Merkys, Antanas Vaitkus, and Mykolas Okulič-
Kazarinas. 2015. Computing stoichiometric molecular composition from crys-
tal structures. Journal of Applied Crystallography 48, 1 (2015), 85–91. https:
//doi.org/10.1107/S1600576714025904
[34] Colin R. Groom, Ian J. Bruno, Matthew P. Lightfoot, and Suzanna C. Ward.
2016. The Cambridge Structural Database. Acta Crystallographica Section B
Structural Science, Crystal Engineering and Materials 72, 2 (2016), 171–179. https:
//doi.org/10.1107/S2052520616003954
[35] Will Hamilton, Zhitao Ying, and Jure Leskovec. 2017. Inductive representation
learning on large graphs. Advances in Neural Information Processing Systems
(NeurIPS) (2017).
[36] William L. Hamilton. 2020. Graph Representation Learning. Synthesis Lectures
on Artificial Intelligence and Machine Learning 14, 3 (2020), 1–159. https://doi.
org/10.1007/978-3-031-01588-5
4971CHILI: Ch emically-I nformed L arge-scale I norganic Nanomaterials Dataset for Advancing Graph Machine Learning KDD ’24, August 25–29, 2024, Barcelona, Spain
[37] Ask Hjorth Larsen, Jens Jørgen Mortensen, Jakob Blomqvist, Ivano E Castelli,
Rune Christensen, Marcin Dułak, Jesper Friis, Michael N Groves, Bjørk Ham-
mer, Cory Hargus, Eric D Hermes, Paul C Jennings, Peter Bjerre Jensen, James
Kermode, John R Kitchin, Esben Leonhard Kolsbjerg, Joseph Kubal, Kristen Kaas-
bjerg, Steen Lysgaard, Jón Bergmann Maronsson, Tristan Maxson, Thomas Olsen,
Lars Pastewka, Andrew Peterson, Carsten Rostgaard, Jakob Schiøtz, Ole Schütt,
Mikkel Strange, Kristian S Thygesen, Tejs Vegge, Lasse Vilhelmsen, Michael
Walter, Zhenhua Zeng, and Karsten W Jacobsen. 2017. The atomic simulation
environment—a Python library for working with atoms. Journal of Physics: Con-
densed Matter 29, 27 (2017), 273002. https://doi.org/10.1088/1361-648X/aa680e
[38] Jonathan Ho, Ajay Jain, and Pieter Abbeel. 2020. Denoising Diffusion Probabilistic
Models. In Advances in Neural Information Processing Systems, Vol. 33. 6840–6851.
[39] Weihua Hu, Matthias Fey, Marinka Zitnik, Yuxiao Dong, Hongyu Ren, Bowen
Liu, Michele Catasta, and Jure Leskovec. 2020. Open Graph Benchmark: Datasets
for Machine Learning on Graphs. In Advances in Neural Information Processing
Systems, Vol. 33. 22118–22133.
[40] Md Shamim Hussain, Mohammed J. Zaki, and Dharmashankar Subramanian. 2022.
Global Self-Attention as a Replacement for Graph Convolution. In Proceedings
of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining.
https://doi.org/10.1145/3534678.3539296
[41] Christian Igel and Stefan Oehmcke. 2023. Remember to Correct the Bias When
Using Deep Learning for Regression! KI - Künstliche Intelligenz 37, 1 (2023),
33–40. https://doi.org/10.1007/s13218-023-00801-0
[42] Anubhav Jain, Shyue Ping Ong, Geoffroy Hautier, Wei Chen, William Davidson
Richards, Stephen Dacek, Shreyas Cholia, Dan Gunter, David Skinner, Gerbrand
Ceder, and Kristin A. Persson. 2013. Commentary: The Materials Project: A
materials genome approach to accelerating materials innovation. APL Materials
1, 1 (2013). https://doi.org/10.1063/1.4812323
[43] Dipendra Jha, Logan Ward, Arindam Paul, Wei-keng Liao, Alok Choudhary, Chris
Wolverton, and Ankit Agrawal. 2018. ElemNet: Deep Learning the Chemistry
of Materials From Only Elemental Composition. Scientific Reports 8, 1 (2018).
https://doi.org/10.1038/s41598-018-35934-y
[44] Dipendra Jha, Logan Ward, Zijiang Yang, Christopher Wolverton, Ian Foster, Wei-
keng Liao, Alok Choudhary, and Ankit Agrawal. 2019. IRNet: A General Purpose
Deep Residual Regression Framework for Materials Discovery. In Proceedings of
the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data
Mining. https://doi.org/10.1145/3292500.3330703
[45] Frederik L. Johansen, Andy S. Anker, Ulrik Friis-Jensen, Erik B. Dam, Kirsten
M. Ø. Jensen, and Raghavendra Selvan. 2024. A GPU-Accelerated Open-Source
Python Package for Calculating Powder Diffraction, Small-Angle-, and Total
Scattering with the Debye Scattering Equation. Journal of Open Source Software
(2024). https://doi.org/10.21105/joss.06024
[46] Jong Hyun Jung, Prashanth Srinivasan, Axel Forslund, and Blazej Grabowski.
2023. High-accuracy thermodynamic properties to the melting point from ab
initio calculations aided by machine-learning potentials. npj Computational
Materials 9, 1 (2023). https://doi.org/10.1038/s41524-022-00956-8
[47] Peter C. Jurs. 1971. Machine Intelligence Applied to Chemical Systems: A
Graph Theoretical and Learning Machine Study of Second-Order Effects in
Low Resolution Mass Spectra. Applied Spectroscopy 25, 4 (1971), 483–488.
https://doi.org/10.1366/000370271779950102
[48] Diederik P. Kingma and Jimmy Ba. 2015. Adam: A Method for Stochastic Opti-
mization. In International Conference on Learning Representations (ICLR).
[49] Thomas N Kipf and Max Welling. 2017. Semi-Supervised Classification with
Graph Convolutional Networks. In International Conference on Learning Repre-
sentations (ICLR).
[50] Scott Kirklin, James E Saal, Bryce Meredig, Alex Thompson, Jeff W Doak, Murata-
han Aykol, Stephan Rühl, and Chris Wolverton. 2015. The Open Quantum Materi-
als Database (OQMD): assessing the accuracy of DFT formation energies. npj Com-
putational Materials 1, 1 (2015). https://doi.org/10.1038/npjcompumats.2015.10
[51] Emil T. S. Kjær, Andy S. Anker, Marcus N. Weng, Simon J. L. Billinge, Raghavendra
Selvan, and Kirsten M. Ø. Jensen. 2023. DeepStruc: towards structure solution
from pair distribution function data using deep generative models. Digital
Discovery 2, 1 (2023), 69–80. https://doi.org/10.1039/D2DD00086E
[52] S. Laurent, S. Boutry, and R.N. Muller. 2018. Metal Oxide Particles and Their
Prospects for Applications. 3–42. https://doi.org/10.1016/B978-0-08-101925-
2.00001-2
[53] Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. 2015. Deep learning. Nature
521, 7553 (2015), 436–444. https://doi.org/10.1038/nature14539
[54] Kin Long Kelvin Lee, Carmelo Gonzales, Marcel Nassar, Matthew Spellings,
Mikhail Galkin, and Santiago Miret. 2023. MatSciML: A Broad, Multi-Task Bench-
mark for Solid-State Materials Modeling. In AI for Accelerated Materials Design -
NeurIPS 2023 Workshop.
[55] Jure Leskovec and Julian Mcauley. 2012. Learning to Discover Social Circles in
Ego Networks. In Advances in Neural Information Processing Systems, Vol. 25.
Curran Associates, Inc.
[56] Meng Liu, Keqiang Yan, Bora Oztekin, and Shuiwang Ji. 2021. GraphEBM: Molec-
ular Graph Generation with Energy-Based Models. In Energy Based Models Work-
shop - ICLR 2021.[57] Steph-Yves Louis, Yong Zhao, Alireza Nasiri, Xiran Wang, Yuqi Song, Fei Liu, and
Jianjun Hu. 2020. Graph convolutional neural networks with global attention for
improved materials property prediction. Physical Chemistry Chemical Physics 22,
32 (2020), 18141–18148. https://doi.org/10.1039/D0CP01474E
[58] Sukriti Manna, Yunzhe Wang, Alberto Hernandez, Peter Lile, Shanping Liu, and
Tim Mueller. 2023. A database of low-energy atomically precise nanoclusters.
Scientific Data 10, 1 (2023). https://doi.org/10.1038/s41597-023-02200-4
[59] Łukasz Mentel. 2023. mendeleev - A Python package with properties of chemical
elements, ions, isotopes and methods to manipulate and visualize periodic table.
[60] Amil Merchant, Simon Batzner, Samuel S. Schoenholz, Muratahan Aykol, Gowoon
Cheon, and Ekin Dogus Cubuk. 2023. Scaling deep learning for materials discov-
ery. Nature 624, 7990 (2023), 80–85. https://doi.org/10.1038/s41586-023-06735-9
[61] Christian Merkwirth and Thomas Lengauer. 2005. Automatic Generation of
Complementary Descriptors with Molecular Graph Networks. Journal of Chemi-
cal Information and Modeling 45, 5 (2005), 1159–1168. https://doi.org/10.1021/
ci049613b
[62] Andrius Merkys, Antanas Vaitkus, Justas Butkus, Mykolas Okulič-Kazarinas, Vis-
valdas Kairys, and Saulius Gražulis. 2016. COD::CIF::Parser: an error-correcting
CIF parser for the Perl language. Journal of Applied Crystallography 49, 1 (2016),
292–301. https://doi.org/10.1107/S1600576715022396
[63] Andrius Merkys, Antanas Vaitkus, Algirdas Grybauskas, Aleksandras Konoval-
ovas, Miguel Quirós, and Saulius Gražulis. 2023. Graph isomorphism-based
algorithm for cross-checking chemical and crystallographic descriptions. Journal
of Cheminformatics 15, 1 (2023). https://doi.org/10.1186/s13321-023-00692-1
[64] Koichi Momma and Fujio Izumi. 2008. VESTA: a three-dimensional visualization
system for electronic and structural analysis. Journal of Applied Crystallography
41, 3 (2008), 653–658. https://doi.org/10.1107/S0021889808012016
[65] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory
Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Des-
maison, Andreas Kopf, Edward Yang, Zachary DeVito, Martin Raison, Alykhan
Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, and Soumith
Chintala. 2019. PyTorch: An Imperative Style, High-Performance Deep Learning
Library. In Advances in Neural Information Processing Systems, Vol. 32.
[66] Miguel Quirós, Saulius Gražulis, Saul ˙e Girdzijauskait ˙e, Andrius Merkys, and
Antanas Vaitkus. 2018. Using SMILES strings for the description of chemical
connectivity in the Crystallography Open Database. Journal of Cheminformatics
10, 1 (2018). https://doi.org/10.1186/s13321-018-0279-6
[67] Raghunathan Ramakrishnan, Pavlo O. Dral, Matthias Rupp, and O. Anatole
von Lilienfeld. 2014. Quantum chemistry structures and properties of 134 kilo
molecules. Scientific Data 1, 1 (2014). https://doi.org/10.1038/sdata.2014.22
[68] Lars Ruddigkeit, Ruud van Deursen, Lorenz C. Blum, and Jean-Louis Reymond.
2012. Enumeration of 166 Billion Organic Small Molecules in the Chemical
Universe Database GDB-17. Journal of Chemical Information and Modeling 52, 11
(2012), 2864–2875. https://doi.org/10.1021/ci300415d
[69] F. Scarselli, M. Gori, Ah Chung Tsoi, M. Hagenbuchner, and G. Monfardini. 2009.
The Graph Neural Network Model. IEEE Transactions on Neural Networks 20, 1
(2009), 61–80. https://doi.org/10.1109/TNN.2008.2005605
[70] Jürgen Schmidhuber. 2015. Deep learning in neural networks: An overview.
Neural Networks 61 (2015), 85–117. https://doi.org/10.1016/j.neunet.2014.09.003
[71] Jonathan Schmidt, Love Pettersson, Claudio Verdozzi, Silvana Botti, and Miguel
A. L. Marques. 2021. Crystal graph attention networks for the prediction of stable
materials. Science Advances 7, 49 (2021). https://doi.org/10.1126/sciadv.abi7948
[72] Kristof Schütt, Pieter-Jan Kindermans, Huziel Enoc Sauceda Felix, Stefan Chmiela,
Alexandre Tkatchenko, and Klaus-Robert Müller. 2017. Schnet: A continuous-
filter convolutional neural network for modeling quantum interactions. Advances
in Neural Information Processing Systems (NeurIPS) (2017).
[73] J. C. Slater. 1964. Atomic Radii in Crystals. The Journal of Chemical Physics 41,
10 (1964), 3199–3204. https://doi.org/10.1063/1.1725697
[74] Teague Sterling and John J. Irwin. 2015. ZINC 15 – Ligand Discovery for Everyone.
Journal of Chemical Information and Modeling 55, 11 (2015), 2324–2337. https:
//doi.org/10.1021/acs.jcim.5b00559
[75] Daisuke Takagi, Kazuki Ishizaki, Toru Asahi, and Takuya Taniguchi. 2023. Molec-
ular screening for solid–solid phase transitions by machine learning. Digital
Discovery 2 (2023), 1126–1133. Issue 4. https://doi.org/10.1039/D3DD00034F
[76] Thiviyan Thanapalasingam, Emile van Krieken, Peter Bloem, and Paul Groth.
2023. IntelliGraphs: Datasets for Benchmarking Knowledge Graph Generation.
(2023). https://doi.org/10.48550/arXiv.2307.06698
[77] Richard Tran, Janice Lan, Muhammed Shuaibi, Brandon M. Wood, Siddharth
Goyal, Abhishek Das, Javier Heras-Domingo, Adeesh Kolluru, Ammar Rizvi,
Nima Shoghi, Anuroop Sriram, Félix Therrien, Jehad Abed, Oleksandr Voznyy,
Edward H. Sargent, Zachary Ulissi, and C. Lawrence Zitnick. 2023. The Open
Catalyst 2022 (OC22) Dataset and Challenges for Oxide Electrocatalysts. ACS
Catalysis 13, 5 (2023), 3066–3084. https://doi.org/10.1021/acscatal.2c05426
[78] Antanas Vaitkus, Andrius Merkys, and Saulius Gražulis. 2021. Validation of
the Crystallography Open Database using the Crystallographic Information
Framework. Journal of Applied Crystallography 54, 2 (2021), 661–672. https:
//doi.org/10.1107/S1600576720016532
4972KDD ’24, August 25–29, 2024, Barcelona, Spain Ulrik Friis-Jensen et al.
[79] Antanas Vaitkus, Andrius Merkys, Thomas Sander, Miguel Quirós, Paul A.
Thiessen, Evan E. Bolton, and Saulius Gražulis. 2023. A workflow for de-
riving chemical entities from crystallographic data and its application to the
Crystallography Open Database. Journal of Cheminformatics 15, 1 (2023).
https://doi.org/10.1186/s13321-023-00780-2
[80] Petar Veličković, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro
Liò, and Yoshua Bengio. 2018. Graph Attention Networks. In International Con-
ference on Learning Representations (ICLR). https://doi.org/10.17863/CAM.48429
[81] Clement Vignac, Igor Krawczuk, Antoine Siraudin, Bohan Wang, Volkan Cevher,
and Pascal Frossard. 2023. DiGress: Discrete Denoising diffusion for graph
generation. In The Eleventh International Conference on Learning Representations.
[82] Yuyang Wang, Zijie Li, and Amir Barati Farimani. 2023. Graph Neural Networks
for Molecules. 21–66. https://doi.org/10.1007/978-3-031-37196-7_2
[83] Yue Wang, Yongbin Sun, Ziwei Liu, Sanjay E Sarma, Michael M Bronstein, and
Justin M Solomon. 2019. Dynamic graph CNN for learning on point clouds. ACM
Transactions on Graphics (tog) (2019). https://doi.org/10.1145/3326362
[84] Logan Ward, Ankit Agrawal, Alok Choudhary, and Christopher Wolverton. 2016.
A general-purpose machine learning framework for predicting properties of
inorganic materials. npj Computational Materials 2, 1 (2016). https://doi.org/10.
1038/npjcompumats.2016.28
[85] Anthony R West. 2014. Solid State Chemistry and its Applications (2 ed.). John
Wiley & Sons.
[86] Zhenqin Wu, Bharath Ramsundar, Evan N Feinberg, Joseph Gomes, Caleb
Geniesse, Aneesh S Pappu, Karl Leswing, and Vijay Pande. 2018. Molecu-
leNet: a benchmark for molecular machine learning. Chemical science (2018).
https://doi.org/10.1039/C7SC02664A
[87] Tian Xie, Xiang Fu, Octavian-Eugen Ganea, Regina Barzilay, and Tommi S.
Jaakkola. 2022. Crystal Diffusion Variational Autoencoder for Periodic Material
Generation. In International Conference on Learning Representations (ICLR).
[88] Tian Xie and Jeffrey C. Grossman. 2018. Crystal Graph Convolutional Neural
Networks for an Accurate and Interpretable Prediction of Material Properties.
Physical Review Letters 120, 14 (2018). https://doi.org/10.1103/PhysRevLett.120.
145301
[89] Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka. 2019. How Powerful
are Graph Neural Networks?. In International Conference on Learning Representa-
tions (ICLR).
[90] Chenxiao Yang, Qitian Wu, Jiahua Wang, and Junchi Yan. 2023. Graph Neural
Networks are Inherently Good Generalizers: Insights by Bridging GNNs and
MLPs. In International Conference on Learning Representations (ICLR).
[91] Ruo Xi Yang, Caitlin A. McCandler, Oxana Andriuc, Martin Siron, Rachel Woods-
Robinson, Matthew K. Horton, and Kristin A. Persson. 2022. Big Data in a
Nano World: A Review on Computational, Data-Driven Design of Nanomaterials
Structures, Properties, and Synthesis. ACS Nano 16, 12 (2022), 19873–19891.
https://doi.org/10.1021/acsnano.2c08411
[92] D. Zagorac, H. Müller, S. Ruehl, J. Zagorac, and S. Rehme. 2019. Recent develop-
ments in the Inorganic Crystal Structure Database: theoretical crystal structure
data and related features. Journal of Applied Crystallography 52, 5 (2019), 918–925.
https://doi.org/10.1107/S160057671900997X
[93] Claudio Zeni, Robert Pinsler, Daniel Zügner, Andrew Fowler, Matthew Horton,
Xiang Fu, Sasha Shysheya, Jonathan Crabbé, Lixin Sun, Jake Smith, Bichlien
Nguyen, Hannes Schulz, Sarah Lewis, Chin-Wei Huang, Ziheng Lu, Yichi Zhou,
Han Yang, Hongxia Hao, Jielan Li, Ryota Tomioka, and Tian Xie. 2023. MatterGen:
a generative model for inorganic materials design. (2023). https://doi.org/10.
48550/arXiv.2312.03687
[94] Marinka Zitnik and Jure Leskovec. 2017. Predicting multicellular function through
multi-layer tissue networks. Bioinformatics 33, 14 (2017), i190–i198. https:
//doi.org/10.1093/bioinformatics/btx252
A DATA GENERATION
A.1 CIF construction
We constructed CIFs based on crystal types described by West
et al.[ 85] using the ase.spacegroup.crystal function from the
atomic simulation environment (ASE)[ 37]. Crystal types are de-
fined by their fractional atomic positions and spacegroups. Unit
cell parameters for each material were estimated using values from
West et al. [ 85] and fitted linear functions relating these parameters
to the sum of atomic radii of the elements. CIF generation code is
available here .
A.2 Crystallography Open Database query
CIFs from the Crystallography Open Database (COD) [ 21,31–33,
62,63,66,78,79] were queried using code found here and cleanedusing code found here. The ase.io.read function from ASE [ 37]
was used to load CIFs. Known issues that were fixed included gen-
eration loop errors, filling empty columns with 0’s, and correcting
syntax errors like non-closed parentheses. Files with missing parts
or uncommon errors were removed. We increased floating-point
precision to five decimal places to avoid periodicity errors and
corrected misinterpreted elemental symbols due to capitalization
issues, removing files without metallic elements.
A.3 Nanomaterial graph generation
We detail the graph generation of the CHILI datasets as outlined
in Figure 1 (steps 3 and 4). Nanoparticles were generated using
thegenerate_nanoparticles utility from DebyeCalculator [ 45]
found here . This approximates nanoparticles as cutouts from crys-
talline materials.
Step 3: CIFs were read with ASE [ 37], and unit cells expanded
into supercells, ensuring a padding of at least 5 Ångströms (Å)
beyond the largest nanoparticle diameter. Supercells were centered
on the most central metal atom. Atom connectivity was determined
using estimated interaction neighborhoods, defined as 125% of
atomic radii from the Mendeleev package [ 59] (Data from Slater et
al. [73]). In cases with no overlaps, 110% of the smallest unit cell
distance was used.
Step 4: Metallic cores were identified by metal atoms within the
given radius from the origin. Non-metals were included if within
the radius or if their interaction neighborhood overlapped with the
metallic core. Nanoparticles with radii of 5, 10, 15, 20, and 25 Å
were generated.
A.4 Scattering data simulation
Scattering data simulation (step 5 in Figure 1) was performed using
DebyeCalculator [ 45].saxs andsans were calculated using the iq
function, and xrd,nd,xPDF , and nPDF using the _get_all function,
with parameters shown in Table 7.
Table 7: DebyeCalculator parameters used for simulation of
scattering data.
Parameter saxs/sans xrd/nd xPDF/nPDF
qmin 0 1 1
qmax 3 30 30
qstep 0.01 0.05 0.05
biso 0.3 0.3 0.3
rmin — — 0
rmax — — 60
rstep — — 0.01
A.5 Downloading the dataset
The code snippet demonstrates how to import the CHILI dataset
class and download CHILI-3K andCHILI-100K
1# Importing the CHILI dataset class :
2from benchmark . dataset_class import CHILI
3# Download CHILI -3K:
4data_3K = CHILI ( root ="./", dataset = "CHILI -3K" )
5# Download CHILI -100 K:
6data_100K = CHILI ( root = "./" , dataset = "CHILI -100 K" )
4973