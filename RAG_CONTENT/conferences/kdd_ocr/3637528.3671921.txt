Dynamic Hotel Pricing at Online Travel Platforms: A Popularity
and Competitiveness Aware Demand Learning Approach
Fanwei Zhu∗
zhufanwei@zju.edu.cn
Hangzhou City University
Hangzhou, ChinaWendong Xiao∗
xunxiao.xwd@alibaba-inc.com
Alibaba Group
Hangzhou, ChinaYao Yu
sichen.yy@alibaba-inc.com
Alibaba Group
Hangzhou, China
Zemin Liu
liu.zemin@zju.edu.cn
Zhejiang University
Hangzhou, ChinaZulong Chen
zulong.czl@alibaba-inc.com
Alibaba Group
Hangzhou, ChinaWeibin Cai
wcai17@syr.edu
Syracuse University
Syracuse, USA
Abstract
Dynamic pricing, which suggests the optimal prices based on the
dynamic demands, has received considerable attention in academia
and industry. On online hotel booking platforms, room demand
fluctuates due to various factors, notably hotel popularity and com-
petition. In this paper, we propose a dynamic pricing approach with
popularity and competitiveness-aware demand learning. Specif-
ically, we introduce a novel demand function that incorporates
popularity and competitiveness coefficients to comprehensively
model the price elasticity of demand. We develop a dynamic de-
mand prediction network that focuses on learning these coefficients
in the proposed demand function, enhancing the interpretability
and accuracy of price suggestion. The model is trained in a multi-
task framework that effectively leverages the correlations of de-
mands among groups of similar hotels to alleviate data sparseness
in room-level occupancy prediction. Comprehensive experiments
conducted on real-world datasets validate the superiority of our
method over state-of-the-art baselines in both demand prediction
and dynamic pricing. Our model has been successfully deployed on
a popular online travel platform, serving tens of millions of users
and hoteliers.
CCS Concepts
•Computing methodologies →Neural networks; •Applied
computing→Forecasting.
Keywords
Dynamic Pricing, Occupancy Prediction, Multi-task Learning
ACM Reference Format:
Fanwei Zhu, Wendong Xiao, Yao Yu, Zemin Liu, Zulong Chen, and Weibin
Cai. 2024. Dynamic Hotel Pricing at Online Travel Platforms: A Popularity
∗Co-first authors with equal contribution.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
KDD ’24, August 25–29, 2024, Barcelona, Spain
©2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 979-8-4007-0490-1/24/08
https://doi.org/10.1145/3637528.3671921and Competitiveness Aware Demand Learning Approach. In Proceedings of
the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining
(KDD ’24), August 25–29, 2024, Barcelona, Spain. ACM, New York, NY, USA,
11 pages. https://doi.org/10.1145/3637528.3671921
1 Introduction
Dynamic pricing [ 14] is a pricing strategy that determines the
optimal prices of products or services based on the dynamic de-
mands and market conditions. It has received considerable attention
from different communities and is widely applied in various real-
world industrial scenarios such as airlines, tourism and hospitality
[3, 11, 33, 42].
In the hospitality industry, online travel platforms (e.g., book-
ing.com, Fliggy1) have emerged as the popular channels for book-
ing hotels. Dynamic pricing plays an important role in revenue
management and operation optimization on these platforms. As
shown in Fig. 1, when a user submits a query (e.g., <FlyZoo Hotel,
check-in=10-09, check-out=10-10 >), the online booking platform
provides available rooms that match the query. The listed prices
for each room-type on different nights (referred to as room-night )
could be different, determined by the dynamic pricing algorithm.
Generally, the dynamic hotel pricing process involves two ma-
jor steps: (1) the hoteliers set an acceptable price range for each
room-type on the platform, and (2) the platform’s pricing system de-
termines the optimal price in this range that maximizes the expected
revenue, considering the potential demands. Appropriately pricing
the rooms based on a thorough understanding of demand or occu-
pancy can achieve better supply-demand matching and improve
the overall revenue of the platforms. However, due to the demand
uncertainty and dynamics, the optimal prices of room-types are
changing overtime, making dynamic hotel pricing a particularly
challenging task for online booking platforms.
Prior work. Existing researches on dynamic pricing mainly fall
into two categories: model-driven approaches [ 5,7,32] and data-
driven approaches. Model-driven methods explicitly establish de-
mand functions to model the relationship between selling price
and room occupancy, and derive optimal prices by maximizing
revenue based on their demand functions. While straightforward,
these approaches heavily depend on accurate demand curve es-
timation, which can be challenging in the hospitality industry
1http://www.fliggy.com, one of the most popular online travel platform in China.
4641
KDD ’24, August 25–29, 2024, Barcelona, Spain Fanwei Zhu et al.
due to factors like seasonality and competition. Data-driven ap-
proaches [ 38,41,42] directly estimate future demands using rele-
vant features for optimal price learning. While flexible in incorpo-
rating various factors, these methods often suffer from data sparsity
issues, as many rooms only have reservations on specific days and
prices tend to fall within a narrow range.
Present work. In this paper, we attempt to bridge the model-driven
and data-driven approaches by an end-to-end demand modeling
and learning framework, leveraging the strengths of both while
avoiding their limitations.
In particular, we propose a Popularity and Competitiveness-
Aware neural Network (PCANet) for demand learning and dynamic
pricing. On the one hand, we propose a novel demand function
that comprehensively models the demand dynamics, and allows
us to directly obtain the optimal price with revenue maximization
pricing strategy. Beyond the price-elasticity of demand considered
by existing approaches [ 43,44], we further identify two important
factors affecting the demand and incorporate the popularity-demand
relation (i.e., how a hotel’s demand is affected by its popularity) and
competitiveness-demand relationship (i.e., how demand is affected
by the competitions among peer hotels) in a novel demand model.
On the other hand, inspired by learning ability of data-driven
methods, we develop a popularity and competitiveness-aware de-
mand learning network that exploits complex features for optimal
pricing. Unlike existing methods that directly regress the occu-
pancy from data, PCANet consists of two representation learning
modules: one for popularity coefficient prediction and the other
for competitiveness coefficient prediction. As such, we can avoid
blindly learning of occupancy from the statistics and thus improv-
ing the accuracy and interpretability of price suggestion.
Moreover, by learning these two coefficients, we can effectively
tackle the data sparsity problem in hotel occupancy prediction
using multi-task learning. In particular, the competitiveness and
popularity of hotels within a similar group exhibit strong correla-
tion: Competition mainly arises among rooms that share the same
submarket, and popularity of rooms is similar within each group. As
a result, we can utilize the group-level demand learning task which
has relatively abundant samples, to enhance room-level demand
learning.
FlyZoo	Hotel
M
	
	
Check-in:	10-22						Check-out:	10-23
	
								
1-night	stay
FlyZoo	Hotel
M
	
	
Check-in:	10-09						Check-out:	10-10
	
								
1-night	stay
Figure 1: Lists of rooms on two different nights returned by
Fliggy mobile APP.Contributions. The main contributions of this work are three-fold.
•We comprehensively investigate the underlying causes of demand
dynamics on online travel platforms, and propose a novel demand
model that explicitly captures the price-demand, popularity-
demand and competitiveness-demand relationships for inter-
pretable hotel pricing (Sect. 3).
•We develop a novel demand learning network PCANet with
meticulously designed popularity and competitiveness represen-
tation modules, with using the group-level occupancy prediction
as auxiliary task, for more accurate occupancy prediction in hotel
dynamic pricing (Sect. 4).
•Extensive experiments on real-world datasets demonstrate the
superiority of our method in both demand estimation and dy-
namic pricing. We have successfully deployed PCANet in the
dynamic pricing system at Fliggy, serving millions of users and
hoteliers on the platform (Sect. 5).
2 Related work
Dynamic pricing has been widely researched and used in various
domains [ 8,12,28,29,33,41], including retail, airline and travel
industry. Existing works on dynamic pricing can be categorized
into two branches: model-driven anddata-driven.
Model-driven approaches apply revenue maximization strate-
gies on pre-defined demand functions that illustrate how demand
changes in response to price fluctuates [ 4,5,7,16,40]. For in-
stance, Aviv et al. [5] propose a Bayesian updating mechanism for
learning market conditions in a continuous-time pricing model.
Bertsimas et al. [7] instead consider dynamic pricing in a non-
Bayesian setting, determining the optimal price through dynamic
programming algorithms applied to a linear demand model. Data-
driven approaches [ 9,23,33], on the other hand, adopt machine
leaning techniques to predict the optimal price based on various
demand-influencing factors. For instance, Shukla et al. [33] develop
a deep learning model for airline ancillaries, estimating customer
purchase probability and suggesting optimal prices accordingly.
Wen et al. [39] investigate pricing problem of Airbnb Experiences
in search settings, employing a regression model to learn item
value distributions and determine optimal prices by aggregating
best prices from various search contexts. Bastani et al. [6] propose a
multi-stage dynamic pricing model for retail sales, utilizing various
factors for pricing decisions across different sales phases.
In the context of online hotel reservation platforms, most re-
searches follow a two-stage learning framework involving occu-
pancy prediction and subsequent price prediction. For instance, Ye
et al. [41] use a Gradient Boosting Machine (GBM) [ 18] to predict
booking probability for Airbnb shared rooms and regress optimal
prices with a demand-enhanced pricing model. Zhang et al. [42]
employ a seq2seq model [ 34] to predict the future occupancy based
on the hotel features and statistics, then regress suggested prices
using a DNN model. However, these two-stage regression models
may suffer from the data sparsity and error accumulation, which
would hurt the overall performance of pricing system.
In contrast, we propose an end-to-end occupancy prediction
network that flexibly integrates various features to learn the popu-
larity and competitiveness coefficients in the demand function. By
4642Dynamic Hotel Pricing at Online Travel Platforms: A Popularity and Competitiveness Aware Demand Learning Approach KDD ’24, August 25–29, 2024, Barcelona, Spain
focusing on these coefficients rather than blindly predicting occu-
pancy, our approach improves prediction accuracy and effectively
addresses data sparsity through multi-task learning. Two most rele-
vant work are PEM [ 43] and CANDY [ 44]. While PEM also relies on
solving the demand function for optimal pricing, it only considers
price elasticity of demand on hotel occupancy modeling, unlike our
approach which investigates the inherent causes of price elasticity
and introduce a more accurate and interpretable demand function,
allowing for direct determination of the optimal price. CANDY fo-
cuses on a different stage of dynamic pricing, i.e., adjustment stage.
It takes the suggested prices of PEM as input and conducts dynamic
price adjustment based on a causality-driven model to characterize
the causal effect of different price adjustment on occupancy. Our
approach can also serve as the pre-setting stage of CANDY that
generates prices for further adjustments and explanation.
3 Dynamic pricing Problem
In dynamic hotel pricing scenario, different hotels send the infor-
mation of their room-types (e.g., size, inventory) and an acceptable
price range to the third-party online booking platforms; the plat-
forms would recommend a selling price in that range for each
specific room-night based on the predicted demand at that night,
with the goal of maximizing the overall revenue. Formally, let 𝑃𝑡𝑟
denote the selling price of room-type 𝑟at night𝑡, and𝑂𝑡𝑟=𝐹(𝑃𝑡𝑟)
be a demand function between the selling price 𝑃𝑡𝑟and the corre-
sponding occupancy 𝑂𝑡𝑟. The optimal price 𝑃𝑡∗𝑟of room-type 𝑟on
night𝑡is the one yields the maximal revenue 𝑃𝑡𝑟·𝑂𝑡𝑟, formulated as
𝑃𝑡∗
𝑟=arg max
𝑃𝑡𝑟𝑃𝑡
𝑟·𝑂𝑡
𝑟,s.t.𝑙𝑡
𝑟≤𝑃𝑡
𝑟≤ℎ𝑡
𝑟, (1)
where𝑙𝑡𝑟andℎ𝑡𝑟are respectively the lowest and highest values in
the price range set by the hoteliers. For simplicity, we will also use
room to refer room-type when the context is clear.
3.1 Demand model
According to Eq. 1, an accurate demand function 𝑂𝑡𝑟=𝐹(𝑃𝑡𝑟)is the
key to the success of dynamic pricing. To capture the sensitivity of
occupancy change to price change, an elastic demand function that
defines the occupancy of a room-night 𝑂𝑡𝑟as a function 𝐹(𝑃𝑡𝑟,𝛿𝑡𝑟)
of the selling price 𝑃𝑡𝑟and its price elasticity coefficient 𝛿𝑡𝑟is pro-
posed in PEM [ 43]. However, the elastic demand model lacks of a
clear explanation of price elasticity and its influence on demand
dynamics.
In this work, we investigate the underlying causes of price elas-
ticity and derive a more accurate and interpretable demand function.
Specifically, we observe that (1) The demand for a hotel room is
not only influenced by its own price, but also affected by the prices
of its substitutes or competitors. For example, discount on a hotel
room would drive higher demand for it, and meanwhile lead to
the lower occupancy for its competitors. (2) Demand fluctuation
is highly related to the popularity change of a hotel. For example,
hot spring resorts are more popular in winter than summer, and
business hotels are more popular on weekday than weekend.
Therefore, we propose to explicitly model the impact of competi-
tiveness andpopularity of room-nights on the price elasticity witha novel demand function, defined as
𝑂𝑡
𝑟=¯𝑂𝑟·𝑒𝛼𝑡
𝑟·𝑃𝑡
𝑟+¯𝑃𝑟/𝑃𝑡
𝑟·𝛽𝑡
𝑟, (2)
where𝛼𝑡𝑟is the competitiveness coefficient, 𝛽𝑡𝑟is the popularity
coefficient, ¯𝑂𝑟and ¯𝑃𝑟are respectively the historical benchmark of
occupancy and price (e.g., the average occupancy and selling price
in recent one week), which can be obtained from the statistics.
In this equation, the first term reflects the inverse correlation
between occupancy fluctuation and price sensitivity (i.e., more
competitive hotels are less sensitive to price change), and the second
term accounts for the natural growth or decrease in demand caused
by the change of popularity. The intuition behind the demand
function and a more comprehensive explanation can be found in
Appendix A.
By concretely depicting the impact of popularity and compet-
itiveness on price elasticity, our demand model significantly en-
hances the accuracy and interpretability of demand estimation as
we empirically validate in Sect. 5.
3.2 Pricing strategy
Given the demand model, the optimal price that maximizes the
expected revenue can be determined using Eq. 1. While the elastic
demand model requires sampling a set of prices to find the best one,
our demand model allows for direct determination of the optimal
price by solving the demand function. Specifically, the expected
revenue𝐸(𝑃𝑡𝑟)at the price 𝑃𝑡𝑟is calculated as
𝐸(𝑃𝑡
𝑟)=𝑃𝑡
𝑟·𝑂𝑡
𝑟=𝑃𝑡
𝑟·¯𝑂𝑟·𝑒𝛼𝑡
𝑟·𝑃𝑡
𝑟+¯𝑃𝑟·𝛽𝑡
𝑟. (3)
Since the demand model is continuous and the expected revenue is
unimodal, the optimal price that maximizes the expected revenue
can be obtained by equating the derivative of 𝐸(𝑃𝑡𝑟)to zero [25],
𝜕𝐸(𝑃𝑡𝑟)
𝜕𝑃𝑡𝑟=(1+𝛼𝑡
𝑟·𝑃𝑡
𝑟)·¯𝑂𝑟·𝑒𝛼𝑡
𝑟·𝑃𝑡
𝑟=0. (4)
Eq. 4 has a unique solution as the demand function is concave,
given by𝑃𝑡∗𝑟=−1
𝛼𝑡𝑟. It is worth noting that although the optimal
price is represented as a function of the competitiveness coefficient
𝛼𝑡𝑟, the value of 𝛼𝑡𝑟is correlated with 𝛽𝑡𝑟as we will see in Sect. 4.
Consequently, the optimal price can be directly determined once
the coefficients of the demand function are learned.
In summary, the dynamic pricing strategy with the proposed
demand model has two distinct advantages. Firstly, by explicitly
modeling the competitiveness and popularity coefficients, we can
avoid blindly learning of occupancy from the statistics, and thus
improving the accuracy and interpretability of demand estimation.
Secondly, the direct determination of the optimal price based on the
demand function mitigates the possibility of suboptimal solutions,
leading to more efficient and accurate pricing compared to two-
stage regression models.
4 PCANet for demand learning
We now present a popularity and competitiveness aware neural
network to learn the demand function with unknown parameters
(e.g.,𝛼𝑡𝑟and𝛽𝑡𝑟) in an end-to-end occupancy prediction framework.
4643KDD ’24, August 25–29, 2024, Barcelona, Spain Fanwei Zhu et al.
4.1 Motivation and Overall framework
As discussed in Sect. 1, directly regressing a demand curve based
on the historical price and occupancy may suffer from the data
sparsity issue. Our demand model brings us opportunity to address
this issue through multi-task learning of the competitiveness and
popularity coefficients. On the one hand, the popularity of a group
of similar rooms tends to be similar. For example, rooms in all hot
spring resorts are generally popular in winter. On the other hand,
the competition mainly arises among similar rooms in a group of
hotels sharing the same sub-market. For example, superior rooms
of hotels in certain business district are competitors for each other.
Therefore, to learn the competitiveness and popularity coefficients
of a room, the reservations of similar rooms can be leveraged to
alleviate the data sparseness and enhance the model learning.
Specifically, we propose to (1) classify hotel-rooms into groups
such that rooms in each group are competitors that share the same
sub-market and exhibit similar popularity dynamics, and (2) develop
a multi-task demand learning network using group-level occupancy
prediction to assist room-level occupancy prediction.
Room-group identification. To identify the similar and compet-
ing rooms, we first cluster the hotels based on their basic features
such as category, location, stars etc., with𝑘-means clustering algo-
rithm. Hotels in any group are similar in terms of their features,
and thus have similar popularity. Next, we partition all the rooms in
a hotel-group into different room-groups based on a set of business
rules (e.g., prices in a same range, similar room size, etc.) such that
rooms in one group have similar competitiveness.
Overview of PCANet. The overall architecture of PCANet is il-
lustrated in Fig. 2. It consists of three modules: the Popularity
Representation Module (PRM), Competitiveness Representation
Module (CRM) and Occupancy Prediction Module (OPM). Partic-
ularly, in the multi-task framework, PRM has two copies to learn
the room popularity vector p𝑡𝑟and group popularity vector p𝑡𝑔sepa-
rately; CRM in the room task consists of two sub-modules, internal-
and external- competitiveness Representation modules (i.e., ICRM
and ECRM), to learn the room competitiveness vector c𝑡𝑟, while in
group task, the group competitiveness vector c𝑡𝑔is obtained through
ECRM only. The static and contextual features of rooms or groups
are also transformed into embedding vectors, v𝑟orv𝑔, and con-
catenated with the competitiveness vector and popularity vector.
The OPM is designed to learn the correlations between group-level
vectors and room-level vectors and generate the competitiveness
and popularity coefficients 𝛼𝑡𝑟,𝛽𝑡𝑟for room occupancy prediction
and𝛼𝑡𝑔,𝛽𝑡𝑔for group occupancy prediction.
We will elaborate the detailed design of each module in the
following sections.
4.2 Competitiveness Representation Module
The competitiveness representation module is designed to model
how the competitiveness of rooms (or groups) affects their demand.
Forroom-level demand learning, we identify two types of com-
petitiveness to comprehensively model the demand dynamics:
•Internal competitiveness. Similar rooms in a platform compete
with each other, and thus the demand of a room would be affected
MLP MLPMLP  with  activation
G
MLP MLPMLP  with  activation
SB SB
SB
ECRM
 PRM ECRM PRM ICRM
competitive  
features...
statistical  
features...
static  &  contextual  
features...
statistical  
features...
competitive  
features......Embedding  layer
static  &  contextual  
features...Embedding  layerRoom-level  occupancy Group-level  occupancy
Figure 2: The overall framework of PCANet. The input con-
sists of four types of features: static features (i.e., room char-
acteristics like rating and type), statistical features (i.e., se-
quences of statistics like historical sales and clicks), competi-
tive features (i.e., prices of competing rooms), and contextual
features (i.e., real-time information such as current date and
holiday status). These features are transformed into dense
vectors using an embedding layer and are utilized by differ-
ent modules within the model.
by its competitiveness within the competing group. Internal com-
petitiveness models the competitiveness of a room w.r.t. a group
of competing rooms on a platform.
•External competitiveness. A hotel room may appear on different
platforms with varying prices; its demand on a specific platform
would be affected by the prices listed on other platforms. Exter-
nal competitiveness models such price-competitiveness across
platforms.
Forgroup-level demand learning, as there is no competitions be-
tween different room-groups (e.g., rooms of business hotels v.s.
rooms of resort hotels), the demand of a room-group is unlikely to
be affected by that of other groups. Therefore, the competitiveness
of a room-group only consists of its external competitiveness.
The sub-modules, ICRM and ECRM, for internal and external
competitiveness learning are shown in Fig. 3 (a) and (b).
ICRM. Given a room 𝑟, we first retrieve a group of similar rooms
of𝑟,i.e., the room-group 𝑟belongs to, according to the above-
mentioned room-group identification stage. Subsequently, as shown
in Fig. 3(a), a heterogeneous room-price graph with two types of
nodes, i.e., price and room, are constructed based on reservation
data of these rooms in the recent 30days. Specifically, each edge
between a room node and a price node is weighted, indicating how
many times the room was reserved at the connecting price. For each
specific price, as its connections to rooms are sparse, we group the
continuous price into several intervals (e.g., $100-$150, $150-$200)
and represent each price interval as one single node.
In the room-price graph, we can conclude: (1) Rooms that are
frequently connected by the same price nodes are more similar in
price competitiveness; (2) Prices with more connections to the room
nodes are more competitive. Thus, we apply metapath2vec [ 15]
4644Dynamic Hotel Pricing at Online Travel Platforms: A Popularity and Competitiveness Aware Demand Learning Approach KDD ’24, August 25–29, 2024, Barcelona, Spain
by utilizing metapaths room-price-room and price-room-price, to
generate the price-competitiveness representations for room and
price nodes, respectively. Given the input selling price 𝑃𝑡𝑟of room
𝑟, the price-competitiveness z𝑡𝑟of𝑟is the embedding of the price
node𝑃𝑡𝑟if𝑃𝑡𝑟is in the graph, or the average representation of the
two most similar price nodes if 𝑃𝑡𝑟does not match any price node
in the graph.
Finally, to model the distinct quality of each room in the compet-
ing group, we transform the values of some differential features (e.g.,
room size, rating) into low-dimension quality vector q𝑡𝑟, and con-
catenate it with price-competitiveness vector z𝑡𝑟as the the internal
competitiveness representation, i.e.,i𝑡𝑟=z𝑡𝑟⊕q𝑡𝑟.
ECRM. The external competitiveness representation module is
deployed in both room and group tasks.
The input of ECRM in room-level task includes the differences
between our selling price and the prices listed on other platforms.
Specifically, for a room 𝑟, we obtain its highest prices, lowest prices,
and average prices in different time spans (e.g., in recent 30 days,
15 days, and 7 days) from two popular online booking platforms
Meituan [ 1] and Ctrip [ 2]. The difference between each of these
prices and our price is then calculated as input. We adopt Factor-
ization Machines (FM) [ 30] to obtain cross combination of these
features and capture the second order feature interactions, and
output the concatenation of their representations h𝑡𝑟. As the data
obtained from other platform may contain some noise, we addi-
tionally apply a selector block SB(·)on top of FM layer to filter the
harmful noises. The final representation of external competitiveness
e𝑡𝑟is thus formalized as
e𝑡
𝑟=SB(h𝑡
𝑟)=h𝑡
𝑟⊙sigmoid(W1h𝑡
𝑟+b) (5)
where⊙denotes the element-wise product, W1andbare learnable
parameters.
Forgroup-level task, the ECRM is designed to capture the general
external competitiveness e𝑡𝑔of a room-group 𝑔. Thus, it takes the
average of the price differences of all rooms in the group as input.
The process of the module is the same as in room-level task, where
it evaluates the external competitiveness of the room-group as a
whole.
Finally, the overall competitiveness of room 𝑟is represented
as the concatenation of its internal and external competitiveness
vectors: c𝑡𝑟=i𝑡𝑟⊕e𝑡𝑟, and the competitiveness of room-group 𝑔is
its external competitiveness vector: c𝑡𝑔=e𝑡𝑔.
4.3 Popularity Representation Module
The popularity representation module is designed to capture the
popularity of rooms (or room-groups) from a set of statistical fea-
tures, illustrated in Fig. 3(c).
Forroom-level popularity learning, the input statistical features of
room𝑟include the sequence of its daily sales S𝑟=(...,𝑠𝑡𝑟,...), se-
quence of daily clicks C𝑟=(...,𝑐𝑡𝑟,...), sequence of daily searches
E𝑟=(...,𝑒𝑡𝑟,...), and sequence of historical booking prices B𝑟=
(...,𝑏𝑡𝑟,...), where𝑡denotes the day of the statistics. For group-
level popularity learning, the statistics of a group is the summation
over the room statistics. For example, in the group sales sequence
S𝑔=(...,𝑠𝑡𝑔,...),𝑠𝑡𝑔is the summation of 𝑠𝑡𝑟for all room 𝑟belonging
to group𝑔.From these statistics, we capture two types of popularity:
•Short-term popularity that influenced by events or market trends
over a short period. For instance, a big sport event would simulate
short-term local demand.
•Long-term popularity that shaped by seasonal variations in de-
mand. For instance, hot spring hotels are consistently popular
during the winter season due to increased demand.
We will elaborate how to represent these popularity in the context
of room-level tasks, with the group-level process being the same.
Short-term Popularity Representation. To capture the short-
term popularity of room type 𝑟, we consider these statistics in
the recent 30days. As illustrated in Fig. 3(c), we apply two one-
dimensional convolutions with different kernel sizes to capture the
combined features of all the sequences and exploit the underlying
local patterns in different time spans. The max pooling of different
local popularity patterns are then concatenated as the final short-
term popularity vector u𝑡𝑟.
Long-term Popularity Representation. To model the long-term
popularity trends, we observe that the cyclical popularity have
different temporal patterns. For example, the popularity trend of
business hotels is in week-level granularity, being more popular
on weekdays than weekends; while for hot spring resorts, it is
inyear-level granularity, with higher popularity during winters
than summers. Therefore, we propose to learn the popularity repre-
sentations at different temporal granularity, including week-level,
month-level and year-level granularity.
Popularity trends at different temporal granularity. To discover week-
level popularity trend, we consider the historical statistics in re-
cent 180days. Firstly, each element in the original statistical se-
quences is attached with an indicator 𝑤𝑡∈ {1,..., 7}, indicat-
ing the corresponding day of week (DOW) of day 𝑡(i.e., Mon,
..., Sun). For instance, the sales sequence is now represented as
S𝑊𝑟=(...,(𝑠𝑡𝑟,𝑤𝑡),...)where(𝑠𝑡𝑟,𝑤𝑡)means the DOW of sales 𝑠𝑡𝑟
is𝑤𝑡.Secondly, we compute a new set of sequences in a week-level
granularity where each element indicates the proportion of some
kind statistic variables on each DOW. For example, we can obtain a
week-level sales sequence ˜S𝑊𝑟=(˜𝑠1𝑟,..., ˜𝑠7𝑟)with 7 elements; each
˜𝑠𝑖𝑟denotes the percentage of sales on all 𝑖-th day of week,
˜𝑠𝑖
𝑟=Í
𝑡Í
𝑤𝑡=𝑖𝑠𝑡𝑟Í
𝑡Í
𝑤𝑡∈{1,...,7}𝑠𝑡𝑟. (6)
We do the same transformation for all the input statistics to obtain
the week-level sequences ˜S𝑊𝑟,˜C𝑊𝑟,˜E𝑊𝑟,˜B𝑊𝑟and concatenate them
into a week-level statistical matrix W𝑟∈R4×7.
Similarly, we obtain a month-level statistical matrix M𝑟∈R4×31
from statistics in recent 365 days, and a year-level matrix Y𝑟∈
R4×12from statistics in recent 1095 days. In the month-level ma-
trix, each element M𝑟[𝑖,𝑗]indicates the percentage of a statistical
variable𝑖on all𝑗-th day of month (DOM), e.g.,𝑗=1means the
1stday of a month. In the year-level matrix, each element Y𝑟[𝑖,𝑗]
indicates percentage of variable 𝑖in all𝑗-th month of year (MOY),
e.g.,Y𝑟[2,1]denotes the percentage of total clicks on January over
all the 1095 days. Each matrix captures the popularity of historical
dates from the statistics at one certain granularity.
4645KDD ’24, August 25–29, 2024, Barcelona, Spain Fanwei Zhu et al.
Max
Pooling
Conv1D
Embedding  
Layer
current  
dateMWYEmbedding  Layer
id
historical  
datesroom  id/
group  id......
...Month-Aware  
Attention Week-Aware  
Attention
Year-Aware  
AttentionV
VK
K
KQQQConcatenate
short-term  statistics long-term  statisticsMax
Pooling
Conv1D
Conv1DConv1D
1 2 31 30......
...
...
...Month
1 2 7 6......
...
...
...Week
1 2 12 11......
...
...
...Year.........V
XMXWXY
ywm.........Differential  features44
321
12
63
Room-Price  GraphMetapath2Vec
Embedding  layer ...
Similar  rooms  of  r
......
Price  differences  on  
other  platforms(a)  Internal  Competitiveness  Representation  ModuleSB
Embedding  Layer...
FM  Layer
(b)  External  Competitiveness  Representation  Module (c)  Popularity  Representation  Module  (PRM)
Figure 3: Detailed design of competitiveness representation and popularity representation modules in PCANet.
Time-aware attention layers. Now, to comprehensively model the
long-term popularity of room 𝑟on current date 𝑡, we design three
time-aware attention layers, to deal with the day-, week- and month-
level popularity trends, respectively. The basic idea is to find the
similar dates for 𝑡in the historical dates at different time granularity,
i.e., DOM, DOW, MOY, and attentively leverage the popularity
trends of those dates to model the popularity of 𝑡.
Specifically, the input date is represented in the form of <DOM,
DOW, MOY >,e.g., date 2024.01.01 is represented as a triplet <1st,
Mon, Jan >, which is concatenated with the room id and trans-
formed into three 𝑑-dimensional vectors t𝑀𝑟∈R𝑑,t𝑊𝑟∈R𝑑, and
t𝑌𝑟∈R𝑑through an embedding layer. The dates of the historical
statistics are also represented in terms of DOM, DOW, and MOY.
That is, we obtain a DOM vector m=[1,2,..., 31]⊤, DOW vector
w=[1,2,..., 7]⊤, and MOY vector y=[1,2,..., 12]⊤to represent
all historical dates at different time granularity. Each of these vec-
tors is concatenated with the room id, and transformed into dense
embeddings, i.e.,K𝑀𝑟∈R𝑑×31,K𝑊𝑟∈R𝑑×7,K𝑌𝑟∈R𝑑×12. Similarly,
the statistics matrices are also transformed into dense embeddings,
denoted as X𝑀𝑟∈R𝑑×31,X𝑊𝑟∈R𝑑×7,X𝑌𝑟∈R𝑑×12.
Next, each attention layer takes the embedding of current date,
historical dates and the statistics matrix in one granularity as Query,
Key and Value, respectively, to capture the correlation between
current date and statistics of historical dates in that time-granularity
and generate the corresponding popularity representation. More
precisely, let X𝑖𝑟,t𝑖𝑟andK𝑖𝑟be the statistics matrix, embedding of
current date and historical dates in certain time-granularity 𝑖, the
corresponding popularity vector l𝑖𝑟is calculated as
l𝑖
𝑟=Att(t𝑖
𝑟,K𝑖
𝑟,X𝑖
𝑟)=W𝑉X𝑖
𝑟·SoftMax(W𝑄t𝑖
𝑟·W𝐾(K𝑖
𝑟)⊤),(7)
where W𝑄,W𝐾andW𝑉are learnable parameter matrices. The
popularity vectors from all attention layers are concatenated as the
long-term popularity representation: l𝑡𝑟=l𝐷𝑟⊕l𝑊𝑟⊕l𝑀𝑟.
Finally, the long-term popularity l𝑡𝑟is concatenated with short-
term popularity vector u𝑡𝑟to represent the overall popularity of the
room𝑟at night𝑡:p𝑡𝑟=u𝑡𝑟⊕l𝑡𝑟. Similarly, the overall popularity of
room-group 𝑔at night𝑡is:p𝑡𝑔=u𝑡𝑔⊕l𝑡𝑔.4.4 Occupancy Prediction Module
In the occupancy prediction module, the room-level coefficients 𝛼𝑡𝑟
and𝛽𝑡𝑟, and group-level coefficients 𝛼𝑡𝑔and𝛽𝑡𝑔, are simultaneously
learned in a multi-task occupancy prediction framework based on
the popularity and competitiveness vectors of room 𝑟and group
𝑔. The occupancy ˆ𝑂𝑡𝑟and ˆ𝑂𝑡𝑔is then calculated using the proposed
demand function (Eq. 2).
Since the popularity and competitiveness coefficients are cor-
related to some extent, i.e., popular hotel-rooms are more com-
petitive among their peers and vice versa, we introduce MLP lay-
ers to exploit the correlation between the popularity and com-
petitiveness representations. Moreover, a selector blocker SB(·)
is applied to select the useful parameters and avoid harmful pa-
rameter interference. For example, the input of the last MLP layer
with an activation function for predicting 𝛼𝑡𝑟isx⊕MLP(c𝑡𝑟⊕v𝑟),
where x=SB(MLP(p𝑡𝑟⊕v𝑟)). The activation function in the MLP
is designed to ensure the optimal price ˆ𝑃𝑡𝑟=−1
𝛼𝑡𝑟in the price
range set by the hotelier. For example, suppose the price range
is{0.8¯𝑃𝑟,1.2¯𝑃𝑟}, where ¯𝑃𝑟is the average selling price, then the
activation function in occupancy prediction module can be set as
𝛼𝑡𝑟=−(5×sigmoid(𝛼𝑡
𝑟))/12−5/6
¯𝑃𝑟to ensure 0.8¯𝑃𝑟≤ˆ𝑃𝑡𝑟≤1.2¯𝑃𝑟.
Across different tasks, we design a novel gating network to tackle
the negative transfer issue [ 27] and improve the efficiency of joint
learning. Specifically, as similar rooms in a group usually have
similarity popularity, the gating network calculates fusing weights
based on the similarity of room popularity p𝑡𝑟and group popularity
p𝑡𝑔. Selector block is also applied on top of p𝑡𝑟andp𝑡𝑔to select useful
features in the gating fusion.
4.5 Model Training
Our model is trained in the multi-task framework with the objective
of minimizing the total loss of hotel-group occupancy prediction
and room occupancy prediction. Given 𝑛historical price and occu-
pancy tuples of room-level transactions 𝑇𝑟={(𝑃𝑡
𝑟𝑖,𝑂𝑡
𝑟𝑖)}𝑛
𝑖=1and𝑚
tuples of group-level transactions 𝑇𝑔={(𝑃𝑡
𝑔𝑗,𝑂𝑡
𝑔𝑗)}𝑚
𝑗=1where𝑃𝑡𝑔∗
(or𝑂𝑡𝑔∗) is the average price (or total occupancy) of all rooms in
4646Dynamic Hotel Pricing at Online Travel Platforms: A Popularity and Competitiveness Aware Demand Learning Approach KDD ’24, August 25–29, 2024, Barcelona, Spain
room-group 𝑔, the overall loss is constructed over room-level predic-
tion loss𝐻𝛿(𝑂𝑡
𝑟𝑖,ˆ𝑂𝑡
𝑟𝑖)and group-level prediction loss 𝐻𝛿(𝑂𝑡
𝑔𝑗,ˆ𝑂𝑡
𝑔𝑗),
L=𝑛∑︁
𝑖=1𝐻𝛿(𝑂𝑡
𝑟𝑖,ˆ𝑂𝑡
𝑟𝑖)+𝜆𝑚∑︁
𝑗=1𝐻𝛿(𝑂𝑡
𝑔𝑗,ˆ𝑂𝑡
𝑔𝑗), (8)
where𝜆is a hyper-parameter to balance the two tasks, and 𝐻𝛿(𝑂∗,ˆ𝑂∗)
is the huber loss [24] with hyperparameter 𝛿∈𝑅+, defined as
𝐻𝛿(𝑂∗,ˆ𝑂∗)=(1
2(𝑂∗−ˆ𝑂∗)2, if(𝑂∗−ˆ𝑂∗)≤𝛿;
𝛿(𝑂∗−ˆ𝑂∗)−1
2𝛿2,otherwise.(9)
5 EXPERIMENTS
In this section, we conduct extensive experiments on two real-world
datasets to answer the following research questions: (Q1) How do
the hyper-parameters in PCANet affect the performance? (Q2)
How does PCANet perform in occupancy prediction and dynamic
pricing? (Q3) How does each component of PCANet contribute to
the overall performance? (Q4) Can PCANet effectively model the
popularity and competitiveness in the demand function? (Q5) How
does our dynamic pricing strategy perform in live hotel booking
services?
5.1 Offline evaluation
5.1.1 Datasets. As there is no other public dataset for hotel pricing,
following the same way as in previous works [ 43,44], we construct
the datasets with recent hotel reservation data collected from Fliggy
Mobile APP for offline evaluation. We retrieve the hotel reserva-
tion data of major Chinese cities during two distinct periods and
construct the corresponding datasets: Fliggy-H and Fliggy-L.
•Fliggy-H is constructed based on the reservation records in a high-
booking season from 2022.08.30 to 2022.10.07. As one biggest
public holiday in China, the National Day of China, falls in this
period, there is a higher demand for traveling and hotel booking.
•Fliggy-L is constructed based on the reservation records in a
low-booking season from 2022.11.05 to 2022.12.13. There is no
public holidays or big events during this period, so hotel demand
is relatively low.
In each dataset, the reservations in the first 30 days are employed
as the training set to predict the occupancy and suggest prices for
the next 7 days. The details of datasets are summarized in Table 1.
We have released our datasets2to facilitate further research.
Table 1: Summary of datasets.
DatasetsT
raining T
esting
#
Hotels # Rooms # Reservations #
Hotels # Rooms # Reservations
F
liggy-H 0.113M
0.231M 322.48M 0.016M
0.023M 0.144M
F
liggy-L 0.101M
0.203M 315.57M 0.014M
0.018M 0.110M
5.1.2 Baselines. We compare PCANet with two groups of base-
lines, i.e., demand prediction and dynamic pricing, to evaluate the
effectiveness of our approach in both demand modeling and price
recommendation.
Demand prediction baselines. To evaluate our demand func-
tion for occupancy prediction, we compare PCANet with four gen-
eral time series forecasting models: SARIMA [37],Prophet [35],
2https://tianchi.aliyun.com/dataset/159383DeepAR [31], and TFT [26], and two hotel occupancy prediction
methods: DeepSeq [42] and PEM [43].
•SARIMA [37] combines autoregressive and moving average mod-
els for seasonal time series forecasting.
•Prophet [35] is a time series forecasting model designed to handle
the features of business time series including seasonality, trend
changes, and holiday effects.
•DeepAR [31] is a probabilistic time series forecasting method
based on auto-regressive recurrent network.
•TFT [26] combines recurrent layers with self-attention layers to
learn temporal relationships at different scales.
•DeepSeq [42] integrates DeepFM [ 20] and Seq2Seq [ 34] models
to learn feature interactions in the sequence for occupancy re-
gression.
•PEM [43] proposes an elastic demand function for hotel occu-
pancy prediction, and designs a price elasticity learning network
based on different affecting factors.
Dynamic pricing baselines. For price suggestion, we compare
our dynamic pricing strategy with two model-based pricing meth-
ods: GBDT [17] and PEM [43], and two price regression models:
DNN [42] and Airbnb [41].
•GBDT-based demand curve [17] suggests the optimal prices based
on a demand curve generated with GBDT model.
•PEM [43] develops a price-elasticity model for occupancy pre-
diction and suggests the optimal price based on the predicted
occupancy and the recent demands and prices.
•DNN-based pricing [42] adopts a DNN model to regress the sug-
gested price for a certain room at a specific date from the input
features.
•Airbnb pricing [41] uses a customized regression model to suggest
the price for Airbnb listing-nights and applies personalized logic
to optimize the suggestion.
Implementation details of PCANet and the baselines are provided
in Appendix B.
5.1.3 Evaluation metrics. We adopt two common metrics MAPE [ 13]
and WAPE [ 36] for the evaluation of occupancy prediction, where
lower value indicates better accuracy.
•𝑀𝐴𝑃𝐸 =1
𝑁Í𝑛
𝑖=1|(𝑂𝑖−ˆ𝑂𝑖)/𝑂𝑖|measures the percentage error
of the predicted occupancy in relation to the actual values.
•𝑊𝐴𝑃𝐸 =Í𝑁
𝑖=1(|𝑂𝑖−ˆ𝑂𝑖)|/Í𝑁
𝑖=1(|𝑂𝑖|)weights the error by adding
the total occupancy to make it more reasonable when the total
occupancy is low.
To evaluate the pricing strategy, we adopt the same metrics
employed in hotel dynamic pricing works [ 41,42]: Price Decrease
Recall (PDR), Price Increase Recall (PIR), and Booking Regret (BR).
•𝑃𝐷𝑅 measures the degree that the suggested prices are lower
than the listing prices for non-booked rooms. Higher PDR value
indicates a pricing strategy would help improve the competitive-
ness of unsold room-nights.
•𝑃𝐼𝑅measures the degree that the suggested prices are higher than
the listing prices for booked rooms. Higher PIR means higher
profits for those booked room-nights.
•𝐵𝑅measures the closeness between the suggested prices and the
booked prices. Lower BR value would help earn more trust from
hoteliers.
4647KDD ’24, August 25–29, 2024, Barcelona, Spain Fanwei Zhu et al.
As each of PDR and PIR focuses on one specific type (booked, or
non-booked) of rooms, we also define a metric 𝑃𝑅𝐹1=2·𝑃𝐷𝑅·𝑃𝐼𝑅
𝑃𝐷𝑅+𝑃𝐼𝑅to
comprehensively measure the overall revenue gain of the booking
platform in our evaluation.
In practice, there is always trade-off among these metrics [ 41],
e.g., a pricing strategy that suggests lower prices can often improve
PDR but hurt BR. Therefore, we will expect a pricing strategy to
achieve a good balance between increasing the overall revenue of
the platform and maintaining business trust from hoteliers.
5.1.4 Effect of hyper-parameters (Q1). We evaluate the impact of
two key parameters on the performance of PCANet with Fliggy-
L by only varying one specific parameter and keeping all other
parameters the same.
Effect of𝜆in multi-task loss. Table 2 shows the effect of 𝜆in
Eq.(8)which balances the group task and room task. As illustrated,
the performance of both occupancy prediction and dynamic pricing
generally improves when 𝜆decreases from 0.6to0.5, but it drops
afterwards. Thus, 𝜆is set to 0.5in the following experiments.
Effect of different number of hotel-groups. Intuitively, the
number of hotel-groups, i.e.,𝑘in the𝑘-means clustering algorithm
used for identifying similar hotels, should be closely related to the
number of business districts |𝐵𝐷|in a city. Let 𝑘=𝜔·|𝐵𝐷|, and we
vary𝜔from 0.9to1.1with an increment of 0.05to determine the
best value of 𝑘. As shown in Table 3, PCANet performs best when
𝜔=1. Thus, we set 𝑘as the number of districts in a city.
Table 2: Effect of 𝜆.
𝜆 MAPE↓PRF1↑BR↓
0.60 44.68 42.40 9.16
0.55 44.66 42.43 9.15
0.50 44.65 42.69 9.15
0.45 44.69 42.53 9.15
0.40 44.78 42.44 9.15Table 3: Effect of 𝜔.
𝜔 MAPE↓PRF1↑BR↓
0.90 44.81 42.13 9.21
0.95 44.78 42.25 9.21
1.00 44.65 42.69 9.15
1.05 44.71 42.53 9.16
1.10 44.84 42.38 9.17
* The values of WMAPE and PDR, PIR are omitted in the tables as they have
the same trends as MAPE and PRF1.
We also investigate the potential dependency between 𝜆and𝜔
by jointly tuning them, and we observe no significant correlation
or interaction between these two parameters.
5.1.5 Performance comparison (Q2). The performance comparison
of demand prediction and dynamic pricing with corresponding
baselines are shown in Tables 4 and 5, respectively. The best results
are highlighted in bold.
For occupancy prediction, PCANet outperforms its baselines in
both general time series forecasting and hotel occupancy prediction.
In particular, PCANet achieves better performance than TFT, the
SOTA method for general time series forecasting, and outperforms
PEM, the strongest baseline for occupancy prediction, in both MAPE
and WAPE. These results validate the effectiveness of our demand
function and the multi-task learning network in demand prediction.
For dynamic pricing, PCANet achieves the best trade-offs be-
tween increasing the overall revenue and maintaining business
trust. Specifically, PCANet significantly improves all the baselines
on the first three metrics, and can still achieve quite good scores
in BR. Its BR score is approaching Airbnb which directly regresses
the booking prices and thus naturally has the best BR values. InTable 4: Accuracy comparison on demand prediction.
Metho
dF
liggy-L F
liggy-H
MAPE↓W
APE↓MAPE↓W
APE↓
SARIMA 48.82 49.78 49.95 52.35
Pr
ophet 49.91 58.85 51.80 64.54
De
epAR 44.65 45.77 47.53 48.92
TFT 44.69 45.58 47.66 48.34
De
epSeq 44.70 45.81 47.66 48.60
PEM 44.47 45.08 47.34 48.18
PCANet 43.82 44.65 46.52 47.81
contrast, although Airbnb is slightly better in BR (e.g., 1.55%im-
provement than PCANet on Fliggy-L), its performance on other
metrics are much worse (e.g., 11.5%drop than PCANet on Fliggy-L)
mainly due to its inaccurate booking probability estimation. The
results demonstrate the superiority of our pricing strategy with
demand modeling.
Table 5: Performance comparison on pricing strategy.
Metho
dF
liggy-L F
liggy-H
PDR↑PIR↑PR-F1↑BR↓PDR↑PIR↑PR-F1↑BR↓
GBD
T 74.86 26.58 39.23 14.22 72.09 24.62 36.70 16.43
DNN 73.73 28.42 41.03 9.27 72.55 26.78 39.12 13.31
Airbnb 75.91 25.15 37.78 9.01 72.33 24.01 36.05 12.99
PEM 76.55 28.61 41.65 9.10 73.52 26.88 39.37 13.24
PCANet 78.71 29.29 42.69 9.15 74.80 27.58 40.30 13.12
5.1.6 Ablation study. We conduct an ablation study with Fliggy-L
to investigate the contribution of each key module and loss. We
compare PCANet with five variants: (1) without ICRM (Var1); (2)
without ECRM (Var2); (3) without PRM (Var3); (4) without group-
level demand learning task (Var4); (5) without gating network in
the multi-task learning (Var5).
The results illustrated in Table 6 verify that all the components
and losses are essential in both occupancy prediction and dynamic
pricing. Specifically, we have the following observations: (1) ICRM,
ECRM, and PRM modules significantly contribute to overall per-
formance improvement, with PRM being the most influential com-
ponent. Notably, PRM is one major enhancement over PEM [ 43]
and the results validate the necessity of PRM. (2) Omitting the
group-level task results in a 1.7%decrease in WAPE for occupancy
prediction and a decrease of 3.44%in PRF1 and 4.26%in BR for dy-
namic pricing, demonstrating the importance of multi-task learning
and the correlation between group-level and room-level tasks. (3)
Removal of the gating network in the multi-task occupancy predic-
tion module leads to a slight degradation in performance across all
metrics, verifying the necessity of tackling negative transfer issue
in multi-objective learning.
5.1.7 Interpretability Analysis (Q4). To further demonstrate the in-
terpretability of our approach, we visualize the competitiveness and
popularity vectors learned by PCANet, and reveal their connections
to the raw features.
Concretely, we randomly select 1000 rooms on our platform
to validate the effectiveness of their popularity representation p𝑡∗
learned by PCANet. We reduce the dimensions of these vectors
using PCA algorithm [ 22] and visualize them in Fig. 4(a). As il-
lustrated, these popularity vectors projected in the 2D embedding
space exhibit four distinct clusters, implying that there exist four
room-groups with different popularity in the 1000 rooms.
4648Dynamic Hotel Pricing at Online Travel Platforms: A Popularity and Competitiveness Aware Demand Learning Approach KDD ’24, August 25–29, 2024, Barcelona, Spain
To verify whether rooms in different groups have different pop-
ularity, we examine the popularity-related statistics (e.g., sales, # of
clicks) of the rooms in each group on the same date 𝑡and list the
average values (with standard deviation) for each group in Table 7.
It clearly shows that the popularity of four room-groups are quite
different in terms of the statistic features. For example, the average
searches of group A is only 56while that of group C is 702.8.
(a) Scatter diagram of p𝑡
∗.
 (b) Pairwise similarity of c𝑡
∗.
Figure 4: Visualization of competitiveness and popularity
learned by PCANet.
Table 6: Results for ablation study of PCANet.
MAPE↓W
APE↓PDR↑PIR↑PRF1↑BR↓
V
ar1 44.75 45.82 77.78 28.89 42.12 9.23
V
ar2 43.88 45.34 78.25 27.92 41.16 9.31
V
ar3 45.33 53.41 72.29 25.48 37.69 11.28
V
ar4 44.54 44.83 78.13 28.04 41.27 9.54
V
ar5 43.98 45.01 78.66 29.02 42.40 9.20
PCANet 43.82 44.65 78.71 29.29 42.69 9.15
For competitiveness analysis, we randomly select 6 rooms from a
competing group (denoted by 𝑟1,...,𝑟 6) and visualize the pair-wise
similarity of their competitiveness vectors c𝑡∗using a heatmap in
Fig. 4(a), where darker color indicates higher inner-product simi-
larity. We also compare the competitiveness vectors of these rooms
with their competitiveness-related features (e.g., year of decoration,
room size, rating score, etc.) summarized in Table 8, and validate the
effectiveness of competitiveness vectors. For example, from Table 8,
we can infer that 𝑠𝑖𝑚(𝑟1,𝑟2)>𝑠𝑖𝑚(𝑟1,𝑟6)as all the features of
𝑟1and𝑟2are quite similar while 𝑟1and𝑟6are distinct in many
features. Consistently, the competitiveness vector of 𝑟1is more
similar to that of 𝑟2compared to 𝑟6as visualized in Fig. 4(b).
5.2 Online A/B Test
With the success in offline experiments, we deploy PCANet in
the live environment of Fliggy hotel booking system to serve real
traffic since October 2021. Details regarding system deployment
are provided in Appendix B.
Table 7: Popularity features.
Sales #
Clicks #
Searches
A1.19± 0.02 7.73± 0.06 56.0± 0.05
B1.36± 0.06 30.09±0.06 179.0±0.05
C2.13± 0.05 125.83± 0.02 702.8± 0.03
D 1.7± 0.05 54.8± 0.08 198.8±0.05Table 8: Competitiveness features.
r1 r2 r3 r4 r5 r6
De
coration Year 2018 2018 2019 2018 2017 2021
Ro
om Size (𝑚2) 50 60 20 18 25 28
Rating
Score 4.7 4.9 4.9 4.7 4.4 4.5
Price
(CNY) 166 170 188 149 220 281
In our online experiments, we compare PCANet with a previ-
ously running baseline: GBDT-based demand curve, and evaluate
the online results with a common metric in e-commerce industry:
Gross Merchandise Volumn (GMV). In our scenario, GMV mea-
sures the total revenue of rooms sold on the platform over a certain
period:𝐺𝑀𝑉 =Í
𝑖∈𝑁𝑃𝑖·𝐹(𝑃𝑖), where𝑃𝑖is the selling price of
room𝑖,𝐹(𝑃𝑖)is the number of rooms sold at 𝑃𝑖, and𝑁denotes the
number of all rooms sold on the platform. We run our experiments
for two weeks and Fig. 5 shows the improvement of PCANet over
the baseline in each day. On average, PCANet achieves a significant
improvement of 11.39%in GMV over the baseline system, which
verifies the superiority of PCANet on hotel dynamic pricing.
Figure 5: Performance improvement in online tests.
6 Conclusion
In this paper, we study the unique challenges in hotel pricing and
propose a novel demand function that captures the sophisticated
relationship between the price and occupancy. A popularity and
competitiveness aware neural network (PCANet) is developed to
learn the demand function for recommending optimal prices. More-
over, we identify the groups of hotels with similar demand dy-
namics and use group-level occupancy prediction as auxiliary task
to alleviate the data sparsity issue of room-level occupancy pre-
diction. Extensive experiments on real-world datasets show that
PCANet outperforms the state-of-the-art methods for both occu-
pancy prediction and dynamic pricing. Furthermore, PCANet has
been successfully deployed as dynamic pricing strategy at the on-
line hotel booking platform of Fliggy, serving tens of millions of
users and hoteliers.
Acknowledgments
This work is partially supported by the Zhejiang Provincial Natu-
ral Science Foundation (No. LY24F020013) and Alibaba Innovative
Research Program. The authors would like to acknowledge the
Supercomputing Center of Hangzhou City University and Zhejiang
Provincial Engineering Research Center for Real-Time SmartTech
in Urban Security Governance, for their support of the advanced
computing resources.
4649KDD ’24, August 25–29, 2024, Barcelona, Spain Fanwei Zhu et al.
References
[1] [n. d.]. https://www.meituan.com/. Accessed July 4, 2022.
[2] [n. d.]. https://www.ctrip.com/. Accessed July 4, 2022.
[3]Belqasem Aljafari, Pandia Rajan Jeyaraj, Aravind Chellachi Kathiresan, and
Sudhakar Babu Thanikanti. 2023. Electric vehicle optimum charging-discharging
scheduling with dynamic pricing employing multi agent deep neural network.
Computers and Electrical Engineering 105 (2023), 108555.
[4]Victor F Araman and René Caldentey. 2009. Dynamic pricing for nonperishable
products with demand learning. Operations research 57, 5 (2009), 1169–1188.
[5]Yossi Aviv and Amit Pazgal. 2002. Pricing of short life-cycle products through
active learning. Under revision for Management Science (2002), 1–32.
[6]Hamsa Bastani, David Simchi-Levi, and Ruihao Zhu. 2022. Meta dynamic pricing:
Transfer learning across experiments. Management Science 68, 3 (2022), 1865–
1881.
[7]Dimitris Bertsimas and Georgia Perakis. 2006. Dynamic pricing: A learning
approach. In Mathematical and computational models for congestion charging.
45–79.
[8]Lisi Chen, Shuo Shang, Bin Yao, and Jing Li. 2020. Pay Your Trip for Traffic
Congestion: Dynamic Pricing in Traffic-Aware Road Networks. AAAI 34, 01
(2020), 582–589.
[9]Ningyuan Chen and Ming Hu. 2023. Data-Driven Revenue Management: The
Interplay of Data, Model, and Decisions. Service Science (2023).
[10] Tianqi Chen, Tong He, Michael Benesty, Vadim Khotilovich, Yuan Tang, Hyunsu
Cho, Kailong Chen, et al .2015. Xgboost: extreme gradient boosting. R package
version 0.4-2 1, 4 (2015), 1–4.
[11] S. Choi and A. S. Mattila. 2004. Hotel revenue management and its impact on
customers’ perceptions of fairness. Revenue and Pricing Management 2 (2004),
303.
[12] Byung Do Chung, Jiahan Li, Tao Yao, Changhyun Kwon, and Terry L. Friesz. 2012.
Demand Learning and Dynamic Pricing under Competition in a State-Space
Framework. IEEE Transactions on Engineering Management 59, 2 (2012), 240–249.
[13] Arnaud De Myttenaere, Boris Golden, Bénédicte Le Grand, and Fabrice Rossi.
2016. Mean absolute percentage error for regression models. Neurocomputing
192 (2016), 38–48.
[14] Arnoud V. Den Boer. 2015. Dynamic pricing and learning: Historical origins,
current research, and new directions. Surveys in Operations Research and Man-
agement Science 20, 1 (2015), 1–18.
[15] Yuxiao Dong, Nitesh V Chawla, and Ananthram Swami. 2017. metapath2vec:
Scalable representation learning for heterogeneous networks. In SIGKDD. 135–
144.
[16] Juan-Carlos Ferrer, Diego Oyarzún, and Jorge Vera. 2012. Risk averse retail
pricing with robust demand forecasting. International Journal of Production
Economics 136, 1 (2012), 151–160.
[17] J.H. Friedman. 1999. Stochastic Gradient Boosting. Technical Report. Stanford
University.
[18] Jerome H Friedman. 2001. Greedy function approximation: a gradient boosting
machine. Annals of statistics (2001), 1189–1232.
[19] Victor Gomez and Agustin Maravall. 2000. Automatic modeling methods for
univariate series. A course in time series analysis (2000), 171–201.
[20] Huifeng Guo, Ruiming Tang, Yunming Ye, Zhenguo Li, and Xiuqiang He. 2017.
DeepFM: a factorization-machine based neural network for CTR prediction. arXiv
preprint arXiv:1703.04247 (2017).
[21] Sepp Hochreiter and Jürgen Schmidhuber. 1997. Long short-term memory. Neural
computation 9, 8 (1997), 1735–1780.
[22] Harold Hotelling. 1933. Analysis of a complex of statistical variables into principal
components. Journal of Educational Psychology 24 (1933), 498–520.
[23] Junhao Hua, Ling Yan, Huan Xu, and Cheng Yang. 2021. Markdowns in E-
Commerce Fresh Retail: A Counterfactual Prediction and Multi-Period Optimiza-
tion Approach. In SIGKDD. 3022–3031.
[24] Peter J. Huber. 1964. Robust Estimation of a Location Parameter. The Annals of
Mathematical Statistics 35, 1 (1964), 73 – 101.
[25] N. Bora Keskin and Assaf Zeevi. 2014. Dynamic Pricing with an Unknown De-
mand Model: Asymptotically Optimal Semi-Myopic Policies. Operations Research
62, 5 (2014), 1142–1167.
[26] Bryan Lim, Sercan Ö Arık, Nicolas Loeff, and Tomas Pfister. 2021. Temporal fusion
transformers for interpretable multi-horizon time series forecasting. International
Journal of Forecasting 37, 4 (2021), 1748–1764.
[27] Emilio Soria Olivas, Jos David Mart Guerrero, Marcelino Martinez-Sober,
Jose Rafael Magdalena-Benedito, L Serrano, et al .2009. Handbook of research on
machine learning applications and trends: Algorithms, methods, and techniques:
Algorithms, methods, and techniques. IGI global.
[28] Huashuai Qu, Ilya O. Ryzhov, and Michael C. Fu. 2013. Learning logistic demand
curves in business-to-business pricing. In 2013 Winter Simulations Conference
(WSC). 29–40. https://doi.org/10.1109/WSC.2013.6721405
[29] Rupal Rana and Fernando S. Oliveira. 2014. Real-time dynamic pricing in a
non-stationary environment using model-free reinforcement learning. Omega
47 (2014), 116–126.[30] Steffen Rendle. 2010. Factorization machines. In ICDM. 995–1000.
[31] David Salinas, Valentin Flunkert, Jan Gasthaus, and Tim Januschowski. 2020.
DeepAR: Probabilistic forecasting with autoregressive recurrent networks. Inter-
national Journal of Forecasting 36, 3 (2020), 1181–1191.
[32] Alper Şen and Alex X Zhang. 2009. Style goods pricing with demand learning.
European Journal of Operational Research 196, 3 (2009), 1058–1075.
[33] Naman Shukla, Arinbjörn Kolbeinsson, Ken Otwell, Lavanya Marla, and Kartik
Yellepeddi. 2019. Dynamic Pricing for Airline Ancillaries with Customer Context.
InSIGKDD. 2174–2182.
[34] Ilya Sutskever, Oriol Vinyals, and Quoc V Le. 2014. Sequence to sequence learning
with neural networks. NeurIPS 27 (2014).
[35] Sean J. Taylor and Benjamin Letham. 2017. Forecasting at Scale. PeerJ Prepr. 5
(2017), e3190.
[36] Chris Tofallis. 2015. A better measure of relative prediction accuracy for model
selection and model estimation. Journal of the Operational Research Society 66, 8
(2015), 1352–1362.
[37] Rex Nelson Warren. 2017. Occupancy forecasting methods and the use of ex-
pert judgement in hotel revenue management. Ph. D. Dissertation. Iowa State
University.
[38] Larry Weatherford and Sheryl E. Kimes. 2003. A comparison of forecasting
methods for hotel revenue management. International Journal of Forecasting 19
(2003), 401–415.
[39] Jiawei Wen, Hossein Vahabi, and Mihajlo Grbovic. 2019. Revenue Maximization
of Airbnb Marketplace using Search Results. arXiv preprint arXiv:1911.05887
(2019).
[40] Yu Xiong, Gendao Li, and Kiran Jude Fernandes. 2010. Dynamic pricing model
and algorithm for perishable products with fuzzy demand. Applied Stochastic
Models in Business and Industry 26, 6 (2010), 758–774.
[41] Peng Ye, Julian Qian, Jieying Chen, Chen-Hung Wu, Yitong Zhou, Spencer De
Mars, Frank Yang, and Li Zhang. 2018. Customized Regression Model for Airbnb
Dynamic Pricing. In SIGKDD, Yike Guo and Faisal Farooq (Eds.). 932–940.
[42] Qing Zhang, Liyuan Qiu, Huaiwen Wu, Jinshan Wang, and Hengliang Luo. 2019.
Deep Learning Based Dynamic Pricing Model for Hotel Revenue Management.
InICDM Workshops. 370–375.
[43] Fanwei Zhu, Wendong Xiao, Yao Yu, Ziyi Wang, Zulong Chen, Quan Lu, Zemin
Liu, Minghui Wu, and Shenghua Ni. 2022. Modeling Price Elasticity for Occupancy
Prediction in Hotel Dynamic Pricing. In CIKM. 4742–4746.
[44] Ruitao Zhu, Wendong Xiao, Yao Yu, Yizhi Yu, Zhenzhe Zheng, Ke Bu, Dong
Li, and Fan Wu. 2023. CANDY: A Causality-Driven Model for Hotel Dynamic
Pricing. In CIKM. 3616–3625.
Appendix
A Explanation of Demand Function
The proposed popularity and competitive aware demand function
(Eq. 2) is driven by two intuitions: Firstly, the price-elasticity of
demand for a room-night is inversely related to its competitiveness.
For example, the occupancy of more competitive hotels tends to be
less sensitive to price change. To capture this effect, the first term of
the equation incorporates the competitiveness-demand relationship
by regulating the price with the competitiveness coefficient 𝛼𝑡𝑟. Con-
sidering that the demand change in response to price change typi-
cally follows an exponential distribution [ 23] and fluctuates around
a benchmark occupancy, we define the demand as ¯𝑂𝑟·𝑒𝛼𝑡
𝑟·𝑃𝑡
𝑟, where
𝛼𝑡𝑟<0.Secondly, the demand for a room-night naturally increases
with rising popularity and decreases with declining popularity. The
second term of the equation incorporates such popularity-demand
relationship with the popularity coefficient 𝛽𝑡𝑟, where𝛽𝑡𝑟>0in-
dicates growth in popularity and 𝛽𝑡𝑟<0indicates a decrease in
popularity. Moreover, as the popularity-demand relationship can
be artificially affected by significant price adjustments (e.g., a big
discount on a room 𝑃𝑡𝑟≪¯𝑃𝑟temporarily boosting its popularity),
we multiply 𝛽𝑡𝑟by¯𝑃𝑟
𝑃𝑡𝑟to effectively capture such phenomena.
4650Dynamic Hotel Pricing at Online Travel Platforms: A Popularity and Competitiveness Aware Demand Learning Approach KDD ’24, August 25–29, 2024, Barcelona, Spain
Training	data
Offline	training
Online	serving
Data	processing
Tensorflow
PCANet
Request	parsing
Feature	construction
Dynamic	pricing
request
optimal	price
TPP
MaxCompute	platform
search	logs
click	logs
booking	logs 
...
Figure 6: Deployment and workflow of PCANet in hotel book-
ing system at Fliggy.
B Implementation and Deployment
Implementation. In PCANet, the embedding size of all features
is set to 16, and the dimension of popularity and competitiveness
vectors is set to 32. The popularity representation model uses one-
dimensional convolution with different kernel size to capture the
combined features of multiple short-term statistical sequences. The
number of filters is {32,16}, kernel size is set to 3 and 5, and strides
is 1. The window size of the maxpooling operation is (3,2). The oc-
cupancy prediction module for each task contains two MLP layers;
the number of hidden nodes in each MLP layer is {512,256}and
{128,1}respectively. For training, dropout rate is 0.2, 𝛿=1and
𝜆=0.5. For GDBT, we use the algorithm implemented by eXtreme
Gradient Boosting (XGBoost) [ 10] where the number of trees and
the max tree length in GBDT is set to 500 and 6 respectively; For
SARIMA, we adopt the x13-auto-arima version [ 19] of the algorithm.
The neural network used in DeepAR and TFT is one-layer LSTM
[21] with 40 and 16 hidden cells respectively, number of heads inthe multi-head attention layer of TFT is set to 2. The regression
module of Airbnb is a three-layer MLP (number of hidden nodes:
128,32,1). The other parameters of baselines are set as suggested
in the original papers.
System deployment. As shown in Fig. 6, during the offline train-
ingphases, we collect the system logs (e.g., search logs, clicks log,
etc.) to construct the training datasets. These logs are stored on the
MaxCompute platform, a big data computation platform developed
by Alibaba Group. Given the large scale of the training data, we
conduct a distributed implementation using TensorFlow to train
our model. In TensorFlow parameter-server architecture, we used
5 parameter servers along with 50 workers. Each parameter server
has 6 CPU cores with 32 GB memory, which stores part of parame-
ters. Each worker, which is equipped with 6 CPU cores and 32 GB
memory, is responsible for fetching part of training samples, calcu-
lating the gradients of parameters and transmitting these gradients
to parameter servers. With the parameter-server architecture, the
training of PCANet can be finished within 2 hours.
Atonline serving, the backend of hotel booking system periodi-
cally sends pricing requests to TPP, a personalized online service
platform in Alibaba Group. TPP first parses these requests to get the
IDs of hotels and rooms that require pricing. The relevant features
of the specific hotels and rooms are then retrieved and input into the
dynamic pricing model to generate the optimal price, which is then
send back to the system. The average response time of the dynamic
pricing service is less than 10ms, which satisfies the requirements
of online environment at Fliggy.
4651