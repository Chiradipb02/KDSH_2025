Divide and Denoise: Empowering Simple Models for Robust
Graph Semi-Supervised Learning against Label Noise
Kaize Ding*
Northwestern University
Evanston, IL, USA
kaize.ding@northwestern.eduXiaoxiao Ma
Macquarie University
Sydney, Australia
xiaoxiao.ma2@hdr.mq.edu.au
Yixin Liu
Monash University
Melbourne, Australia
yixin.liu@monash.eduShirui Pan
Griffith University
Gold Coast, Australia
s.pan@griffith.edu.au
ABSTRACT
Graph neural networks (GNNs) based on message passing have
achieved remarkable performance in graph machine learning. By
combining it with the power of pseudo labeling, one can further
push forward the performance on the task of semi-supervised node
classification. However, most existing works assume that the train-
ing node labels are purely noise-free, while this strong assump-
tion usually does not hold in practice. GNNs will overfit the noisy
training labels and the adverse effects of mislabeled nodes can be
exaggerated by being propagated to the remaining nodes through
the graph structure, exacerbating the model failure. Worse still, the
noisy pseudo labels could also largely undermine the model’s relia-
bility without special treatment. In this paper, we revisit the role of
(1) message passing and (2) pseudo labels in the studied problem
and try to address two denoising subproblems from the model archi-
tecture and algorithm perspective, respectively. Specifically, we first
develop a label noise propagation-free GNN that discards the cou-
pled message-passing scheme. Despite its simple architecture, this
learning backbone prevents overfitting to noisy labels and also in-
herently avoids the noise propagation issue. Moreover, we propose
a novel reliable graph pseudo labeling algorithm that can effectively
leverage the knowledge of unlabeled nodes while mitigating the
adverse effects of noisy pseudo labels. Based on those novel designs,
we can attain exceptional effectiveness and efficiency in solving the
studied problem. We conduct extensive experiments on benchmark
datasets for semi-supervised node classification with different lev-
els of label noise and show new state-of-the-art performance. The
code is available at https://github.com/DND-NET/DND-NET.
CCS CONCEPTS
•Mathematics of computing →Graph algorithms; •Comput-
ing methodologies →Neural networks.
∗Kaize Ding is the corresponding author.
Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for third-party components of this work must be honored.
For all other uses, contact the owner/author(s).
KDD ’24, August 25–29, 2024, Barcelona, Spain
©2024 Copyright held by the owner/author(s).
ACM ISBN 979-8-4007-0490-1/24/08.
https://doi.org/10.1145/3637528.3671798KEYWORDS
Graph Neural Networks, Noisy Labels, Semi-Supervised Learning
ACM Reference Format:
Kaize Ding*, Xiaoxiao Ma, Yixin Liu, and Shirui Pan. 2024. Divide and
Denoise: Empowering Simple Models for Robust Graph Semi-Supervised
Learning against Label Noise. In Proceedings of the 30th ACM SIGKDD
Conference on Knowledge Discovery and Data Mining (KDD ’24), August
25–29, 2024, Barcelona, Spain. ACM, New York, NY, USA, 11 pages. https:
//doi.org/10.1145/3637528.3671798
1 INTRODUCTION
Graph Neural Networks (GNNs) have recently emerged as a power-
ful tool in the field of machine learning, offering a novel approach
to processing data structured as graphs [ 1,6,16,21,49]. In general,
most prevailing GNNs [ 21,52] follow the message-passing scheme
and learn the representation of each node by iteratively transform-
ing and propagating/aggregating the information within its neigh-
borhoods. Benefiting from such a powerful mechanism, node rep-
resentations obtained by GNNs encode rich structure knowledge,
which can be effectively used for solving various downstream tasks,
such as node classification [ 21], graph classification [ 51], link pre-
diction [41], and anomaly detection [30].
Among different graph machine learning tasks, semi-supervised
node classification is a representative one, aiming at predicting the
labels for the unlabeled nodes given a partially labeled graph [ 21],
Though GNNs can implicitly leverage unlabeled data through pass-
ing the messages along the graph structure, the lack of supervision
signals is still a major bottleneck for improving the performance of
GNNs [ 8–10]. More recently, researchers also propose to incorpo-
rate additional supervision signals by applying the idea of pseudo
labeling [ 25] to the graph domain. Therefore, those methods are
able to combine the key advantages of: (1) Message Passing; and (2)
Pseudo Labeling during the learning process, yielding promising
outcomes, as evidenced in various studies [7, 8, 14, 26, 42].
Despite the success of the existing endeavors on semi-supervised
node classification, their efficacy could be easily undermined when
severe label noise is presented in the data. Similar to other neural
models, GNNs tend to overfit noisy labels due to the memorization
effect [ 13,46]. Though recent works on graph label denoising [ 5,27,
34] have been proposed to tackle this problem, we argue that this
problem has not been well investigated and addressed so far. More
specifically, the two key factors (i.e., message passing and pseudo
 
574
KDD ’24, August 25–29, 2024, Barcelona, Spain Kaize Ding, Xiaoxiao Ma, Yixin Liu, and Shirui Pan
labels) instead play a destructive role when facing noisy labels, and
how to address this issue remains underexplored. Hence, we divide
the studied problem into two denoising subproblems, each of which
corresponds to a critical research question:
•How can we circumvent noise propagation caused by mes-
sage passing? Though message-passing in GNNs is a key mech-
anism for capturing the graph structural knowledge, such a cou-
pled design may in turn bring severe challenges for GNNs when
learning with noisy labels. Specifically, the noisy supervision
signals from the training labels will be easily propagated along
the graph topology [ 5], corrupting the learning process of the
remaining nodes in the graph and largely deteriorating the model
generalization capability [ 33]. However, existing graph label de-
noising methods do not explicitly handle the noise propagation
issue and still adopt conventional GNNs as their learning back-
bone. Hence, it is imperative to develop a new GNN architecture
that is robust to label noise and, more importantly, the noise
propagation issue.
•How can we mitigate computed noisy pseudo labels? For the
problem of semi-supervised node classification, though pseudo
labeling has shown to be empirically effective in improving model
performance, its effectiveness largely relies on the quality of the
obtained pseudo labels [ 7,8,28]. In practice, pseudo labels could
be quite noisy, especially under the setting where the training
labels are not clean. The current approaches often rely on setting
heuristic thresholds to choose pseudo labels with high confidence.
This process demands careful tuning of hyperparameters and
often lacks good generalizability. Therefore, the main challenge
in effectively using pseudo labels is to cope with the noisy pseudo
labels by leveraging the knowledge inherent in the graph itself.
In this paper, we propose a new robust graph learning approach
DnD-Net, which is simple yet effective for solving the problem of
semi-supervised node classification in the presence of noisy labels.
To address the subproblem 1, we focus on the architecture aspect
and develop a label noise propagation-free GNN based on a simple
neural network that decouples the transformation and propaga-
tion operations in conventional message passing. By equipping it
with our neighbor proximity alignment module, this new learning
backbone is not only able to eliminate the noise propagation issue
of conventional GNNs when facing noisy labels, but also prevent
the model from overfitting to noisy training labels. Moreover, to
deal with the subproblem 2 , we dive into the algorithm aspect and
further propose a reliable graph pseudo labeling algorithm that can
effectively leverage the knowledge of unlabeled data while mitigat-
ing the detrimental effects of those inaccurate pseudo labels. Our
denoising algorithm first performs semantic-preserving data aug-
mentation to avoid semantic perturbations, then the contribution
of each pseudo label will be adaptively adjusted by neighbor uncer-
tainties. By solving the two aforementioned subproblems with our
novel denoising designs, we derive a new approach that achieves
superior effectiveness on the studied problem with a simple archi-
tecture. To summarize, our contributions are three-fold:
•Architecture : We develop a new GNN learning backbone that is
inherently robust to learning with noisy labels on graphs. With
just a simple architecture, this new model inherently addresses
the label noise memorization and propagation issues.•Algorithm : We propose a new reliable graph pseudo labeling
algorithm that can effectively leverage the knowledge of unla-
beled nodes while mitigating the adverse effects of noisy pseudo
labels by exploiting the graph prior knowledge.
•Evaluation : We conduct extensive experiments across different
datasets and evaluation settings, which demonstrate the superi-
ority of our approach over the state-of-the-art methods.
2 RELATED WORK
Semi-Supervised Node Classification. Semi-supervised node
classification is an essential task in graph machine learning, with
broad applications in social networks [ 16], cybersecurity [ 43], and
protein analysis [ 15]. In recent years, GNNs have demonstrated
significant potential in semi-supervised node classification, attain-
ing state-of-the-art performance across diverse datasets and do-
mains [ 4,16,21,22,31,40,44]. However, due to the sparsity of
labels, it is crucial to leverage the knowledge from unlabeled sam-
ples with GNNs. An effective solution is to assign pseudo labels
to unlabeled nodes based on well-crafted strategies. For instance,
Self-Training [ 26] augments the labeled node set by incorporating
the nodes with the most confident pseudo labels. M3S [ 38] further
introduces a self-supervised learning paradigm for pseudo labeling.
PTA [ 12] employs label propagation to generate pseudo labels and
uses adaptive weighted loss to adjust the impact of pseudo-labeled
nodes. Another solution to leverage unlabeled samples is consis-
tency training. For example, GRAND [ 14] employs a consistency
regularized loss to minimize the distance of node representations
between two augmented views of unlabeled nodes. Meta-PN [ 8] is
a simple network architecture equipped with a novel meta-learning
algorithm, which can adaptively generate informative pseudo la-
bels on unlabeled nodes to improve the model performance. More
recent works [ 7,31] try to solve the problem of semi-supervised
node classification with extremely few labeled data.
Graph Label Denoising. However, the efficacy of GNNs may
be compromised in the presence of noisy training labels [ 32]. To
tackle the label noise problem, recent efforts [ 3,5,27,34] intro-
duce various novel techniques to enhance the robustness of GNNs
against noisy labels. For example, D-GNN [ 32] employs backward
loss correction to alleviate the influence of noisy labels, whereas
UnionNET [ 27] utilizes label aggregation to estimate node-level
class probability distributions. LPM [45] uses label propagation to
create pseudo labels, and NRGNN [ 5] further proposes to refine the
graph structure to improve the quality of prediction. Pi-GNN [ 13]
utilizes pairwise interactions between nodes to explicitly adjust
the similarity of node embeddings during training. RTGNN [ 34]
introduces self-reinforcement based on the memorization effects
of neural networks and incorporates cross-view consistency regu-
larization to explicitly control label noise for robust GNN training.
ERASE [ 3] is a two-stage decoupled label propagation method to
provide denoised labels and semantic labels with graph structural
prior. With the decoupled label propagation, the model can learn the
error-resilient node representations via estimating precise coding
rate reduction. Different from the existing methods, in this paper,
we not only develop a new GNN backbone that is inherently robust
to label noise, but also explicitly tackle the unreliable pseudo labels
by proposing the reliable graph pseudo labeling algorithm.
 
575Divide and Denoise: Empowering Simple Models for Robust Graph Semi-Supervised Learning against Label Noise KDD ’24, August 25–29, 2024, Barcelona, Spain
3 PRELIMINARIES
For generality, we focus on static attributed graphs in this paper. An
static attributed graph consisting of 𝑁nodes is formally represented
byG=(V,E,X), whereV={𝑣1,𝑣2,...,𝑣𝑁}andE⊆V×V
denote the set of nodes and edges respectively. X∈R𝑁×𝐷are the
node attributes, and the attributes of each node are in R𝐷.Y∈
R𝑁×𝐶denotes the node labels from 𝐶classes. Let A∈{0,1}𝑁×𝑁
be the adjacency matrix of graph G, with A𝑖𝑗=1if and only if
(𝑣𝑖,𝑣𝑗)∈E . The input graph can also be represented as G=(A,X).
Problem Definition 1.Semi-Supervised Node Classification with
Noisy Labels. Given an attributed graph G=(V,E,X), in which
each node in the labeled training sets 𝑣𝑖∈V𝐿is provided a noisy
label y𝑖. We aim to learn a model based on the noisy labeled nodes
V𝐿and unlabeled nodes V𝑈, which can accurately predict the
label y𝑖for each of the unlabeled nodes 𝑣𝑖∈V𝑈.
In order to learn expressive node representations from an at-
tributed graph, graph neural networks (GNNs) are usually adopted
as the learning backbone due to their powerful learning capabil-
ity. In general, GNNs follow the message-passing scheme, which
computes the node representations by recursively propagating and
transforming node features from local neighborhoods. Briefly, a
GNN layer can be defined as:
h𝑙
N𝑖=Prop𝑙
{h𝑙−1
𝑗|∀𝑗∈N𝑖∪𝑣𝑖}
,
h𝑙
𝑖=Tran𝑙
h𝑙−1
𝑖,h𝑙
N𝑖
,(1)
where h𝑙
𝑖is the node representation of node 𝑖at layer𝑙andN𝑖is
the set of neighboring nodes of 𝑣𝑖.Prop(·)andTran(·)are two
key functions (i.e., propagation and transformation) of GNNs that
have a series of possible implementations [16, 21].
Having the prediction of each node p𝑖and the (clean) training
node label𝑦𝑖, we can train the node classifier by optimizing the
cross-entropy loss:
LCE=−∑︁
𝑣𝑖∈V𝐿𝐶∑︁
𝑐=1y𝑐
𝑖logp𝑐
𝑖. (2)
For the problem of semi-supervised node classification, incorpo-
rating the knowledge of unlabeled data via pseudo labeling (e.g.,
graph self-training and graph consistency training) has been shown
as an effective way to improve the model capability. After comput-
ing the pseudo labels ˜y𝑖for unlabeled nodes 𝑣𝑖∈V𝑈, we can
further derive another cross-entropy loss to jointly train the node
classifier:
LPL=−∑︁
𝑣𝑖∈V𝑈𝐶∑︁
𝑐=1˜y𝑐
𝑖logp𝑐
𝑖. (3)
Though the problem of semi-supervised node classification has
been well advanced by state-of-the-art graph pseudo labeling meth-
ods, their efficacy largely deteriorates when noisy labels are pre-
sented. In this case, both the training labels and pseudo labels may
contain severe noises that hamper the learning process.
4 DIVIDE AND DENOISE (DND-NET)
In this section, we introduce our proposed approach DnD-Net that
can achieve robust semi-supervised node classification performanceagainst noisy labels. We first rethink the roles of message passing
andpseudo labels in this problem and argue that two subproblems
need to be addressed: (1) the noise propagation issue of learning
GNNs with noisy labels; and (2) the noisy pseudo labels generated
based on unlabeled data. To tackle these issues, we build our model
with two novel components: a label noise-resistant graph neural
network (detailed in Section 4.1), and a reliable graph pseudo label-
ing algorithm (detailed in Section 4.2). Having this model, we are
able to achieve robust semi-supervised node classification in the
presence of noisy labels, as shown in Figure 1.
4.1 Noise Propagation-Free GNNs
It is noteworthy that most GNNs are based on the coupled message-
passing architecture that couples the feature transformation and
propagation steps in each layer. We argue that this architecture
is not robust to label noise due to the noise propagation issue.
Specifically, the noisy supervision signals from the training labels
will be easily propagated along the graph topology, corrupting the
learning process of the remaining nodes in the graph and largely
deteriorating the model generalization capability.
Feature Propagation then Transformation. To develop a new
GNN architecture that is robust to noisy labels, we propose to fol-
low a decoupled architecture [ 12,22] that first performs feature
propagation and then trains a multi-layer perceptron (MLP) classi-
fier with the propagated node features. This architecture inherently
eliminates the noise propagation issue since there is no propagation
step during the model training.
However, even though simply decoupling feature propagation
and transformation can address the noise propagation issue, the
learned node representations are not expressive enough due to the
lack of global structural knowledge [ 8,22,24]. Directly increasing
the propagation steps is undesirable since it will cause the over-
smoothing problem [ 2,29]. To better capture high-order structural
knowledge without losing focus on the local neighborhoods, we
propose to leverage Personalized PageRank (PPR) to propagate
node features:
X(𝑙+1)=(1−𝛼)˜AX(𝑙)+𝛼X(0), (4)
where𝛼∈ (0,1]is the restart probability and ˜Ais the normal-
ized adjacency matrix with self-loop. We denote X=X𝐿as the
propagated feature matrix with 𝐿propagation steps. Based on the
propagated node features that encode rich high-order structural
knowledge, we can directly train a simple neural network 𝑓𝜽(·)
such as MLP to efficiently learn expressive node representations
meanwhile circumventing the error propagation issue.
Neighbor Proximity Alignment. Though the noise propagation
issue can be addressed by using the decoupled architecture, such a
model still cannot explicitly mitigate the noisy label memorization
effects, leading to poor performance when the label noise ratio is
high (as depicted in Figure ??). To counter this issue, we propose
aneighbor proximity alignment loss to regularize the MLP-based
node classifier 𝑓𝜽(·). Our main assumption is that the propagated
node feature similarity before training the node classifier with noisy
labels is a strong indicator of the label correlations.
Specifically, we first compute the similarities between each node
𝑣𝑖and its local neighbors based on the propagated node features X.
 
576KDD ’24, August 25–29, 2024, Barcelona, Spain Kaize Ding, Xiaoxiao Ma, Yixin Liu, and Shirui Pan
𝑓𝜽
Pseudo LabelingLoss	𝓛𝐏𝐋Neighbor Proximity AlignmentLoss 𝓛𝐍𝐏𝐀Cross-EntropyLoss	𝓛𝐂𝐄High-orderFeature Propagation MLP Classifier
Input GraphPropagatedNode Features 𝐗$
Adaptive Data AugmentationNeighbor UncertaintyEstimationShared Parameter
… 
𝑓𝜽Prediction	𝐏&Prediction 𝐏$
… Pseudo Label
Reweighting 𝑤!𝐗&Predictions on Feature Similarity Graph
Figure 1: Overview of the proposed framework DnD-Net. On the left, DnD-Net first performs high-order feature propagation
to generate augmented features. The propagated node features will be fed to an MLP-based node classifier to make predictions,
which will be further regularized by the neighbor proximity alignment loss. Lastly, reliable graph pseudo labeling is added to
leverage unlabeled data while combating noisy pseudo labels. Figure best viewed in color.
Our goal is to enforce prediction consistency by leveraging graph
knowledge. More specifically, for a pair of neighboring nodes 𝑣𝑖
and𝑣𝑗, their predictions p𝑖andp𝑗should be close if 𝑠𝑖,𝑗is high,
regardless of their given or predicted labels ˆ𝑦𝑖and ˆ𝑦𝑗. This would
prevent the model from overfitting to the noisy labels, even if either
(or both) ˆ𝑦𝑖andˆ𝑦𝑗are incorrect. Formally, our neighbor proximity
alignment loss can be formulated as follows:
LNPA=∑︁
𝑣𝑖∈V𝐿𝐷KL©­
«𝜎p𝑖
𝜏
∥∑︁
𝑣𝑗∈N𝑖ˆ𝑠𝑖,𝑗·𝜎p𝑗
𝜏ª®
¬, (5)
where𝐷KLis the KL-divergence loss to measure the difference
between two distributions and 𝜏is the temperature. We set 𝜏=2
throughout our experiments. We normalize the similarity value
ˆ𝑠𝑖,𝑗=𝑠𝑖,𝑗/Í
𝑣𝑘∈N𝑖𝑠𝑖,𝑘, so that the second term of the KL-divergence
loss remains a probability distribution. We set the self-similarity
𝑠𝑖,𝑖=0so that it does not dominate the normalized similarity.
4.2 Reliable Graph Pseudo Labeling
For the problem of semi-supervised node classification, leveraging
the knowledge of unlabeled nodes is always imperative due to the
shortage of supervision signals. In this work, we follow the suc-
cess of graph pseudo labeling and use consistency training [ 14,19]
to leverage the knowledge of unlabeled nodes. In general, consis-
tency training performs data augmentations on each unlabeled
example and encourages consistency between the predicted class
distributions from different augmented views. However, existing
graph consistency training methods have two shortcomings as fol-
lows: (1) on the one hand, existing methods usually adopt heuristic
graph data augmentations (e.g., edge dropping, and node masking),
which could in turn perturb the original semantic meaning of the
nodes [ 11,50], rendering the obtained pseudo labels less reliable;
(2) on the other hand, though graph pseudo labeling is empirically
effective for solving this problem, its reliability could be largelyundermined if the noisy pseudo labels are not well handled, espe-
cially when the training labels are also noisy. Hence, our reliable
graph pseudo labeling algorithm targets those two issues and tries
to improve the model reliability through two aspects:
Pseudo Labeling with Semantic-Preserving Data Augmenta-
tion. To perform consistency training with semantic-preserving
graph data augmentation, we first adopt the propagated node fea-
tures as a weakly augmented view and introduce an adaptive data
augmentation module to synthesize a strongly augmented view
of each node, denoted as ˜x, by injecting learnable feature noise to
each node. Formally, ˜xcan be expressed as:
˜x=¯x+𝛾⊙sign(¯x)⊙ 𝝐, (6)
where𝛾is a hyperparameter for controlling the amount of the added
noise, sign(·)is the sign function, and ⊙denotes the Hadamard
product. 𝝐is the learnable noise matrix initialized as 𝝐∼N( 0,Σ)
and the value of each item is updated along the model training
process.
Given the two augmented views, we can promptly compute
the predicted class distribution of each node, i.e., p𝑖and ˜p𝑖, upon
the augmented node features. Then we take the prediction 𝑞𝑖=
arg max(p𝑖)from the weakly augmented view as the pseudo label
and enforce the cross-entropy loss against the model prediction ˜p𝑖
on the strongly-augmented view following Eq. (3) as:
LPL=−∑︁
𝑣𝑖∈V𝑈𝐶∑︁
𝑐=1𝑞𝑖log˜p𝑐
𝑖. (7)
Pseudo Label Reweighting with Neighbor Uncertainty. So far
we have enhanced our model capability by introducing the afore-
mentioned loss, with the primary goal of improving the predictive
consistency of various augmentations applied to unlabeled nodes.
However, not all the pseudo labels are equally informative and
the inclusion of unreliable pseudo labels could hamper the perfor-
mance, especially in cases where the labeled data itself is noisy.
In the realm of existing semi-supervised learning methods, it is
 
577Divide and Denoise: Empowering Simple Models for Robust Graph Semi-Supervised Learning against Label Noise KDD ’24, August 25–29, 2024, Barcelona, Spain
common practice to employ a fixed threshold for selecting confi-
dent pseudo-labeled data [ 37,48]. Such a heuristic approach largely
relies on hyperparameter tuning and it struggles to consistently
deliver satisfactory performance across different datasets.
To resolve this problem, we propose a new approach to calibrate
the pseudo labeling loss, i.e., Eq. (11), by assessing the neighbor
uncertainty associated with each pseudo-labeled node. Consider-
ing the pseudo labels could be unreliable, our model tries to esti-
mate uncertainty through the consideration of neighboring nodes,
disregarding the pseudo label of the node itself. Specifically, our
uncertainty estimation method is based on the consensus among
neighbors’ predictions. The underlying intuition is that if the net-
work predicts the same class for the neighboring nodes, we could
consider the derived pseudo-labels more reliable (low uncertainty).
Otherwise, if neighbors’ predictions mostly disagree with each
other, the obtained pseudo-labels should be considered unreliable
(high uncertainty).
Therefore, we can assess the reliability of each pseudo label by
computing the entropy of the averaged prediction ˆp𝑖from neigh-
bors’ outputs. More formally, given a target node 𝑣𝑖, we first obtain
the weighted class distribution vector ˆp𝑖through weighted voting
among its neighbors:
ˆp𝑖=∑︁
𝑣𝑗∈N𝑖ˆ𝑠𝑖,𝑗p𝑗. (8)
Then we compute the entropy of the aggregated neighbor predic-
tions ˆp𝑖as:
H(ˆp𝑖)=−𝐶∑︁
𝑐=1ˆp𝑐
𝑖logˆp𝑐
𝑖, (9)
where𝐶is the number of node classes. We further re-scale the
Entropy by its maximum as ˆH(ˆp𝑖)=H(ˆp𝑖)
log𝐶. From the normalized
entropy value ˆH(ˆp𝑖), we obtain the final weight 𝑤for the node 𝑣𝑖
as:
𝑤𝑖=exp
−ˆH(ˆp𝑖)
. (10)
Based upon the learned label weights 𝑤𝑖, we can further reweight
the pseudo labeling loss by adding the weight into Eq. (7):
LPL=−∑︁
𝑣𝑖∈V𝑈𝐶∑︁
𝑐=1𝑤𝑖𝑞𝑖log˜p𝑐
𝑖, (11)
such that more importance will be assigned to those pseudo-labels
with low neighbor uncertainty and less importance will be assigned
to those pseudo-labels with high neighbor uncertainty. In this case,
the pseudo labels will be more reliable by considering the uncer-
tainty of neighboring nodes rather than the node itself.
4.3 Model Learning
Learning Objective. By having the aforementioned learning losses,
we can derive the final learning loss of our model as:
L=LCE+𝜆1LNPA+𝜆2LPL, (12)
where coefficients 𝜆1and𝜆2controls the contribution of the last
two losses. Note that we extend the LNPA on both labeled and
pseudo-labeled nodes for better performance in the experiments.
We summarize our algorithm in Algorithm 1 at Appendix A.Complexity Analysis. The major computational cost of our method
stems from the feature propagation and classifier training. Specifi-
cally, with𝐿steps of propagation, the cost for noise propagation-
free representation learning is O(𝑁𝑀𝐿)given a graph with 𝑁nodes
and𝑀. Note that propagation can be completed during the pre-
processing stage, incurring no additional costs for model training.
During each training iteration, the cost of the MLP-based classi-
fier isO(𝑁𝐾𝐷+𝑁𝐾𝐶), where𝐾is the dimensionality of the MLP
layer. For loss computation, the cost of LNPAisO(𝑀𝐶), while the
cost ofLCEandLPLisO(𝑁𝐶+𝑀𝐶)in total. After ignoring the
smaller terms, the overall training time complexity of DnD-Net is
O(𝑁𝐾(𝐷+𝐶)+𝑀𝐶).
5 EXPERIMENTS
In this section, we perform an extensive empirical evaluation for
our approach DnD-Net on various experimental scenarios. We will
introduce the details in the following subsections.
5.1 Experimental Settings
Evaluation Datasets. We evaluate our method on five widely
used node classification benchmarks: Cora-ML [23],PubMed [35],
CiteSeer [35],Coauthor CS [36], and ogbn-arxiv [20]. Cora-ML,
CiteSeer, PubMed, and ogbn-arxiv are four widely used citation
networks, while Coauthor CS is a co-authorship graph based on
Microsoft Academic Graph. On Cora-ML, CiteSeer, PubMed, and
Coauthor CS, we following the previous study and use 5%of labeled
nodes per class for training, 20%labeled nodes for validation, and
leave the rest for testing. For the large-scale dateset ogbn-arxiv, we
follow [ 3] by using the default data split provided by OGB [ 20] and
corrupt the labels in the training set only. To mitigate randomness,
we run the experiments on each dataset for 20times (5 times on
ogbn-arxiv) and report the average accuracy and standard devi-
ation. More details and statistics of datasets are summarized in
Appendix B.1.
Label Noise Generation. Since all the datasets do not inherently
contain noisy labels, we manually injected two types of label noise
into these datasets following [ 5,17]: (1) Uniform Noise: the labels
are flipped with a certain probability 𝑝to other classes in a uniform
manner; (2) Pair Noise: the labels possess a probability of 𝑝for
being switched to their corresponding pair class. For each type of
label noise, we run the evaluation with different values of 𝑝.
Baselines. We compare our method with 10state-of-the-art semi-
supervised node classification baselines, which can be further cat-
egorized as: graph neural networks including GCN [21] and
SGC [44];graph pseudo labeling methods including GRAND [14]
andPTA [12]; and graph label denoising methods including Co-
teaching [18],T-Revision [47],NRGNN [5],RTGNN [34],PI-
GNN [13], and ERASE [3]. Note that Co-teaching and T-Revision
are originally proposed for the classification of image data with
label noise. For a fair comparison and to enable both methods for
handling label noise on graph data, we apply GCN as the encoder
while keeping the denoising algorithms the same as the original
paper. A summary of the baselines and our model’s implementation
details are provided in Appendix B.2 and B.3, respectively.
 
578KDD ’24, August 25–29, 2024, Barcelona, Spain Kaize Ding, Xiaoxiao Ma, Yixin Liu, and Shirui Pan
Table 1: Node classification performance w.r.t. accuracy. The best and runner-up results are in bold and underline , respectively.
Dataset Metho
ds Clean
LabelsUniform
Noise Pair Noise
20%
40% 60% 20%
30% 40%
Cora-ML GCN 83.94±1.29 76.03±2.29
73.13±3.26 50.24±3.38 82.07±0.98
75.73±1.13 66.65±1.02
SGC 82.91±1.22 76.45±1.45
75.93±1.43 55.62±2.20 82.42±1.43 78.46±3.11 68.79±3.04
GRAND 85.34±1.35 76.57±7.14
74.10±3.50 30.83±12.45 82.10±1.58
76.39±2.78 67.95±3.05
PT
A 84.15±1.34 80.90±2.22 74.01±2.99
55.76±4.44 82.16±1.37
76.78±2.01 68.63±3.54
Co-teaching 76.32±6.22 71.21±6.99
63.34±7.82 47.14±8.32 71.43±6.31
66.19±3.88 59.22±6.79
T
-Revision 83.96±1.20 75.74±2.55
66.92±4.02 44.56±4.50 78.20±1.97
71.40±2.97 63.67±5.50
NRGNN 80.58±2.09 76.75±2.03
75.99±1.72 62.52±5.40 81.09±2.12
76.15±3.16 67.54±4.46
RT
GNN 80.13±1.79 74.06±2.73
66.68±7.12 55.47±3.43 78.05±2.25
72.39±4.25 63.23±3.42
Pi-GNN 80.94±1.29 78.19±1.61
73.70±2.25 56.65±6.00 79.48±1.20
74.50±2.25 66.09±3.10
ERASE 81.70±1.19 75.43±2.80
69.48±3.26 49.75±3.11 78.47±1.66
74.91±1.73 66.83±3.41
DnD-Net (
ours) 85.58±0.96 83.88±1.87
79.14±2.54 63.56±6.15 84.72±1.29
80.47±2.03 75.18±3.95
CiteSe
er GCN 70.65±1.35 64.82±2.71
58.32±3.12 39.85±3.44 65.08±2.70
60.63±3.63 58.69±3.75
SGC 71.62±1.43 65.71±2.11
60.53±2.39 42.92±3.20 67.13±2.87
62.18±3.02 59.96±3.30
GRAND 72.13±1.22 61.43±6.35
41.22±11.90 35.28±6.13 65.59±2.44
61.04±3.59 60.02±4.60
PT
A 71.44±1.27 66.65±2.31
59.91±2.78 42.18±3.70 65.86±2.65
62.06±3.32 59.34±3.21
Co-teaching 65.72±4.30 60.93±3.77
53.03±5.69 37.93±6.29 58.94±4.84
55.20±3.79 55.01±3.20
T
-Revision 72.49±1.22 66.15±1.64
59.07±3.96 40.04±3.75 64.12±3.53
54.00±3.48 50.95±2.71
NRGNN 70.77±1.43 66.89±2.15
62.68±3.85 47.31±6.34 67.58±2.51
66.48±2.56 64.07±4.47
RT
GNN 68.57±1.57 64.30±3.22
60.05±5.44 38.73±6.68 64.20±2.78
61.61±2.74 56.83±6.00
Pi-GNN 72.99±1.31 66.85±2.03
65.99±3.67 48.15±5.76 69.64±2.29
66.75±2.09 65.07±2.92
ERASE 73.55±0.99 72.45±1.21 69.58±4.63 55.07±7.91 72.13±2.62 69.47±3.74 66.46±5.87
DnD-Net (
ours) 75.57±1.14 74.30±1.20
70.85±2.17 58.35±5.37 73.98±1.22
71.36±2.31 70.26±2.82
PubMe
d GCN 82.89±0.44 81.87±0.74
62.59±5.66 37.27±6.64 77.81±0.91
70.94±2.04 63.24±2.21
SGC 79.34±0.87 78.42±0.86
76.22±1.51 59.07±4.94 73.76±1.06
70.47±1.58 66.10±1.80
GRAND 82.80±0.24 82.11±0.63
76.34±1.68 51.74±6.58 81.48±0.79
77.46±2.24 69.40±3.23
PT
A 82.51±0.36 81.15±0.46
79.89±1.19 58.90±5.82 79.32±0.53
76.86±0.78 75.52±1.40
Co-teaching 81.09±14.38 78.97±13.89
70.76±14.58 44.90±10.60 77.76±13.66
73.80±15.51 65.74±12.40
T
-Revision 85.55±0.32 83.57±0.49 78.49±1.14
50.25±5.87 81.95±0.59 78.48±0.98 70.58±2.72
NRGNN 78.49±2.22 75.89±3.48
71.76±6.10 54.38±7.50 74.75±4.15
71.93±4.52 65.92±5.71
RT
GNN 75.00±0.85 77.66±1.02
74.67±1.83 57.02±6.53 77.27±1.18
76.06±1.54 70.03±3.04
Pi-GNN 83.76±0.37 82.63±0.60
78.85±1.13 61.97±6.37 80.66±0.73
76.43±1.15 68.29±1.94
ERASE 80.82±0.64 79.92±0.67
77.33±0.89 58.33±5.33 78.09±0.97
75.15±1.18 70.32±1.99
DnD-Net (
ours) 84.02±0.44 84.26±0.45
80.73±1.34 65.63±5.12 82.33±0.56
79.29±1.13 78.45±2.39
Coauthor
CS GCN 92.42±0.20 91.45±0.27
90.53±0.41 88.41±1.15 89.79±0.75
86.56±1.55 76.12±2.81
SGC 92.50±0.17 92.12±0.23 90.68±0.47 87.66±0.69 90.72±0.53
87.25±1.30 76.79±2.10
GRAND 92.63±0.14 91.36±0.19
89.02±0.62 80.98±6.00 91.30±0.46
87.87±1.63 70.16±3.63
PT
A 92.16±0.22 91.92±0.66
88.68±1.29 82.61±1.82 91.42±0.56 87.69±1.62
78.59±2.64
Co-teaching 89.97±1.96 89.71±1.31
87.05±2.25 82.02±3.38 86.71±2.92
82.56±3.29 71.12±6.25
T
-Revision 92.17±0.21 89.72±0.67
84.86±1.68 70.52±6.46 86.29±2.74
79.64±4.19 70.42±4.81
NRGNN 91.15±0.63 90.63±0.66
90.18±1.03 88.79±1.06 87.54±1.87
84.39±2.41 72.43±4.45
RT
GNN 88.26±0.57 88.00±0.53
87.74±0.62 86.68±1.04 85.02±1.51
80.07±2.27 69.48±2.72
Pi-GNN 90.77±0.31 90.34±0.33
89.27±0.66 87.56±1.23 89.35±0.61
86.35±1.49 76.93±2.95
ERASE 91.10±0.30 90.83±0.38
90.51±0.61 88.46±0.83 90.03±0.72
87.79±1.15 75.16±2.20
DnD-Net (
ours) 92.71±0.25 92.14±0.27
90.94±0.52 90.00±0.63 91.99±0.47
88.44±1.13 80.97±1.32
5.2 Evaluation Results
Overall Performance. We evaluate the performance of our pro-
posed method against the baseline methods under three settings:
(1) data with clean labels; (2) labels corrupted with uniform noise;
and (3) labels corrupted with pair noise. From the semi-supervised
node classification results (w.r.t. accuracy in percent ±standard
deviation) in Table 1, we have the following observations:
•The results show that DnD-Net outperforms the baselines under
all cases giving different types and rates of label noise. Specifi-
cally, as more training labels are corrupted, causing performance
degradation across all methods as expected, our model maintains
its superiority in making accurate predictions compared to the
baseline methods.
•Both graph pseudo labeling methods and graph label denoising
methods show better robustness than GCN, however, they only
achieve similar performance with SGC under high label noiseratios, mainly because of the noise propagation issue and unreli-
able pseudo labels. Our approach addresses those two issues by
using the proposed label noise propagation-free GNN and reli-
able graph pseudo labeling algorithm, yielding superior model
robustness.
•Despite that our approach DnD-Net is not specifically designed
for the standard semi-supervised node classification task with
clean labels, it still achieves the best performance compared to
different baselines under the clean label setting, which offers
more flexible usage in practice.
Evaluation on Low-Resource Setting. We further study the ef-
fectiveness of our approach under the low-resource setting where
the training data has low label ratios. We compare our method with
several competitive baselines (Co-teaching, NRGNN, T-Revision,
PI-GNN, and ERASE) on datasets with 1%,2%,3%,4%, and 5%of
labeled training nodes. Note that the noise ratio is set to 20%for all
 
579Divide and Denoise: Empowering Simple Models for Robust Graph Semi-Supervised Learning against Label Noise KDD ’24, August 25–29, 2024, Barcelona, Spain
1%2%3%4%5%405060708090
Label RateAccuracy (%)DND-NETPI-GNNNRGNNCo-teachingT-RevisionERASE
(a) Cora-ML - Uniform Noise
1%2%3%4%5%25354555657585
Label RateAccuracy (%)DND-NETPI-GNNNRGNNCo-teachingT-RevisionERASE (b) Cora-ML - Pair Noise
1%2%3%4%5%253545556575
Label RateAccuracy (%)DND-NETPI-GNNNRGNNCo-teachingT-RevisionERASE
(c) CiteSeer - Uniform Noise
1%2%3%4%5%3040506070Label RateAccuracy (%)DND-NETPI-GNNNRGNNCo-teachingT-RevisionERASE (d) CiteSeer - Pair Noise
Figure 2: Results with different label rates.
Table 2: Performance comparison on ogbn-arxiv.
ogbn-ar
xivUniform
Noise Pair Noise
20%
40% 60% 20%
30% 40%
GCN 50.4±1.0
50.0±0.8 45.5±1.2 52.0±0.6
51.4±0.6 50.2±1.2
Co-teaching 50.9±0.7
50.8±0.1 50.0±0.6 50.8±0.5
50.1±0.4 46.6±0.8
T-Revision 52.5±0.4
53.9±0.2 49.5±2.1 22.9±7.5
20.3±2.9 19.9±6.6
Pi-GNN 54.6±5.8
53.4±4.3 53.1±3.8 51.8±2.7
49.2±3.2 48.4±6.3
ERASE 67.1±1.3 62.6±1.5 57.1±1.9 67.9±1.2 65.7±1.3 53.4±2.1
DnD-Net 67.5±1.5
65.9±1.1 59.7±2.3 68.2±1.9
66.2±2.0 53.8±1.5
the label ratios. The results on Cora-ML and CiteSeer are shown in
Figure 2. From the results, we can observe that our approach con-
stantly outperforms baseline methods with lower ratios of labeled
data used for training.
Evaluation on Large-Scale Dataset. To demonstrate the effec-
tiveness andefficiency of our approach on large-scale datasets, we
first evaluate the performance of different models on ogbn-arxiv
and show the results in Table 2. Note that RTGNN and NRGNN ex-
perience out-of-memory issues on ogbn-axriv. Overall, our method
achieves an averaged 2%performance improvement compared to
the best-performing baselines ERASE. Such a superior performance
underscores that our model design is more robust against label noise
than the state-of-the-art methods without the loss of scalability.
We further showcase the efficiency of our method by comparison
with baseline methods concerning training time and memory cost.
We unify the hyperparameters of model architectures and perform
the efficiency study on ogbn-arxiv with 40% of uniform noise. The
comparisons of clock time per training epoch and total memory
usage are shown in Figure 3. We omit the memory usage of Pi-GNN
since it is larger than 20 GB. From the figure, we can witness that
our model achieves the best performance with lower memory cost
and training time compared to the majority of baselines.
5.3 Ablation Study
To investigate the contribution of each important component for
combating noisy labels and justify our architectural design choice,
10−1100101102103
Clock time / epoch (s)4752576267Accuracy (%)GCN
SGC
PTA
GRAND
T-Revision
Co-teaching
Pi-GNN
ERASE
DND-NET(a) Accuracy w.r.t. clock time per epoch
1 2 3 4
Memory usage (×103 MB)4752576267Accuracy (%)GCN
SGC
PTA
GRAND
T-Revision
Co-teaching
ERASE
DND-NET (b) Accuracy w.r.t. memory usage
Figure 3: Computational costs on ogbn-arxiv.
20%40%60%506070809080.873.554.483.076.060.582.074.457.383.979.163.6Uniform NoiseAccuracy (%)20%30%40%65758580.776.568.083.478.472.982.577.968.584.780.575.2Pair NoiseBasew/o PLw/o RWDND-NET
(a) Cora-ML
20%40%60%4555657567.465.548.073.668.657.369.668.654.774.370.958.4Uniform NoiseAccuracy (%)20%30%40%65707572.469.268.073.170.669.472.870.369.074.071.470.3Pair NoiseBasew/o PLw/o RWDND-NET
(b) CiteSeer
Figure 4: Ablation study on Cora-ML and CiteSeer.
we compare our complete model with its three variants, each of
which is derived by removing one key design in the proposed ap-
proach. Specifically, Base represents the basic decoupled model that
excludes any other components, and w/o PL is the variant without
the entire reliable graph pseudo labeling algorithm. Moreover, we
include another variant w/o RW that only excludes pseudo label
reweighting but keeps the consistency training. We report the ac-
curacy results of each variant on two datasets (Cora and CiteSeer)
in Figure 4 and have the following observations:
•The classification accuracy will decrease when any one of the
components is removed, which reveals the significance of our
novel designs. The performance difference between DnD-Net and
w/o PL shows that our reliable graph pseudo labeling algorithm
plays an important role in improving the model robustness. Also,
the superior performance of w/o PL over Base demonstrates the
effectiveness of neighbor proximity alignment for preventing
overfitting.
•The variant w/o RW performs behind w/o PL, which is an inter-
esting observation showing that the noisy pseudo labels without
special treatment, largely undermine the model performance.
Compared to w/o RW, the complete model achieves better perfor-
mance and we attribute such performance gain to the necessity
 
580KDD ’24, August 25–29, 2024, Barcelona, Spain Kaize Ding, Xiaoxiao Ma, Yixin Liu, and Shirui Pan
0102030405050607080#StepsAccuracy (%)Noise Rate 20%Noise Rate 40%Noise Rate 60%
(a) Cora-ML - Uniform Noise
0102030405070758085#StepsAccuracy (%)Noise Rate 20%Noise Rate 30%Noise Rate 40% (b) Cora-ML - Pair Noise
0102030405040506070#StepsAccuracy (%)Noise Rate 20%Noise Rate 40%Noise Rate 60%
(c) CiteSeer - Uniform Noise
0102030405060657075#StepsAccuracy (%)Noise Rate 20%Noise Rate 30%Noise Rate 40% (d) CiteSeer - Pair Noise
Figure 5: Results with different feature propagation steps.
of reweighting the pseudo labels based on the consensus among
neighbors’ predictions to adjust the pseudo labeling loss.
5.4 Further Analysis
Analysis on Propagation Steps. The steps of feature propaga-
tion determine the expressiveness of the node features for model
training. With the propagation step increasing, the model is able
to better capture global structural knowledge. In this study, we
vary the number of steps from 1to50on Cora-ML and CiteSeer
datasets to investigate how the propagation step impacts the model
performance. From Figure 5, we see that increasing the propagation
step from 1to about 10using our feature propagation leads to huge
improvement under different label noise settings, and the perfor-
mance tends to be stable afterward. It validates that PPR-based
feature propagation can capture high-order structural knowledge
meanwhile avoiding the oversmoothing issue. We further discuss
the impact of 𝛼in Eq. (4) in Appendix B.4.
Sensitivity to 𝜆1and𝜆2.In Eq. (12),𝜆1and𝜆2determines the
weights ofLNPAandLPLon unlabeled nodes. From Figure 6, we
conclude that moderate values for 𝜆1and𝜆2can lead to better
performance. In addition, DnD-Net is more sensitive to the selec-
tion of𝜆1(corresponding to LNPA), whereas𝜆2has less impact
on performance. A similar analysis on CiteSeer dataset is given in
Appendix B.4.
Representation Visualization. We further visualize the node
representations learned by our model DnD-Net and ERASE (the
best-performing baseline) using t-SNE [ 39] to show the model ex-
pressiveness. From Figure 7, we can witness that the learned node
representations from our approach have much clearer inter-class
boundaries and better cohesion within each class. The main reason
is that our proposed learning backbone is able to capture high-order
structural knowledge and regularize the node representations us-
ing the structural knowledge, leading to better robustness in the
λ1 0123
λ20
1
2
3Accuracy (%)
7880828486(a) 20% Uniform Noise
λ1 0123
λ20
1
2
3Accuracy (%)
5055606570 (b) 60% Uniform Noise
λ1 0123
λ20
1
2
3Accuracy (%)
7478828690
(c) 20% Pair Noise
λ1 0123
λ20
1
2
3Accuracy (%)
747678808284 (d) 30% Pair Noise
Figure 6: Sensitivity to 𝜆1and𝜆2on Cora-ML.
Noise Rate: 40%Noise Rate: 60%
(a)DnD-Net - Uniform Noise
Noise Rate: 40%Noise Rate: 60% (b) ERASE - Uniform Noise
Noise Rate: 30%Noise Rate: 40%
(c)DnD-Net - Pair Noise
Noise Rate: 30%Noise Rate: 40% (d) ERASE - Pair Noise
Figure 7: Visualization of node embeddings on Cora-ML.
presence of noisy labels. The visualization results on CiteSeer are
included in Appendix B.4.
6 CONCLUSION
Graph neural networks have achieved remarkable performance in
semi-supervised node classification, especially when combining the
power of pseudo labeling. However, their effectiveness largely dete-
riorates in the presence of noisy labels, due to the noise propagation
of message passing and the unreliability of pseudo labels. This pa-
per proposes a new solution that tackles the two problems from
both the model architecture and algorithm perspectives, reviving
the utility of message passing and pseudo labels in the problem of
semi-supervised node classification with noisy labels. Specifically,
we develop a label-noise robust GNN equipped with a reliable graph
pseudo labeling algorithm, which can attain both effectiveness and
efficiency when solving the studied problem. Extensive experiments
demonstrate its state-of-the-art performance in semi-supervised
node classification with varying levels of label noise.
 
581Divide and Denoise: Empowering Simple Models for Robust Graph Semi-Supervised Learning against Label Noise KDD ’24, August 25–29, 2024, Barcelona, Spain
REFERENCES
[1]Joan Bruna, Wojciech Zaremba, Arthur Szlam, and Yann LeCun. 2014. Spectral
networks and locally connected networks on graphs. In ICLR.
[2]Deli Chen, Yankai Lin, Wei Li, Peng Li, Jie Zhou, and Xu Sun. 2020. Measuring
and relieving the over-smoothing problem for graph neural networks from the
topological view. In AAAI.
[3]Ling-Hao Chen, Yuanshuo Zhang, Taohua Huang, Liangcai Su, Zeyi Lin, Xi Xiao,
Xiaobo Xia, and Tongliang Liu. 2023. ERASE: Error-Resilient Representation
Learning on Graphs for Label Noise Tolerance. arXiv preprint arXiv:2312.08852
(2023).
[4]Eli Chien, Jianhao Peng, Pan Li, and Olgica Milenkovic. 2021. Adaptive Universal
Generalized PageRank Graph Neural Network. In ICLR.
[5]Enyan Dai, Charu Aggarwal, and Suhang Wang. 2021. NRGNN: Learning a Label
Noise-Resistant Graph Neural Network on Sparsely and Noisily Labeled Graphs.
InKDD.
[6]Kaize Ding, Jundong Li, Rohit Bhanushali, and Huan Liu. 2019. Deep anomaly
detection on attributed networks. In SDM.
[7]Kaize Ding, Elnaz Nouri, Guoqing Zheng, Huan Liu, and Ryen White. 2024.
Toward robust graph semi-supervised learning against extreme data scarcity.
TNNLS (2024).
[8]Kaize Ding, Jianling Wang, James Caverlee, and Huan Liu. 2022. Meta Propagation
Networks for Graph Few-shot Semi-supervised Learning. In AAAI.
[9]Kaize Ding, Jianling Wang, Jundong Li, Kai Shu, Chenghao Liu, and Huan Liu.
2020. Graph prototypical networks for few-shot learning on attributed networks.
InCIKM.
[10] Kaize Ding, Yancheng Wang, Yingzhen Yang, and Huan Liu. 2023. Eliciting
structural and semantic global knowledge in unsupervised graph contrastive
learning. In AAAI.
[11] Kaize Ding, Zhe Xu, Hanghang Tong, and Huan Liu. 2022. Data augmentation
for deep graph learning: A survey. SIGKDD Explorations (2022).
[12] Hande Dong, Jiawei Chen, Fuli Feng, Xiangnan He, Shuxian Bi, Zhaolin Ding, and
Peng Cui. 2021. On the Equivalence of Decoupled Graph Convolution Network
and Label Propagation. In TheWebConf.
[13] Xuefeng Du, Tian Bian, Yu Rong, Bo Han, Tongliang Liu, Tingyang Xu, Wen-
bing Huang, and Junzhou Huang. 2021. PI-GNN: A Novel Perspective on Semi-
Supervised Node Classification against Noisy Labels. TMLR (2021).
[14] Wenzheng Feng, Jie Zhang, Yuxiao Dong, Yu Han, Huanbo Luan, Qian Xu, Qiang
Yang, Evgeny Kharlamov, and Jie Tang. 2020. Graph random neural networks
for semi-supervised learning on graphs. In NeurIPS.
[15] Alex Fout, Jonathon Byrd, Basir Shariat, and Asa Ben-Hur. 2017. Protein Interface
Prediction using Graph Convolutional Networks. In NeurIPS.
[16] Will Hamilton, Zhitao Ying, and Jure Leskovec. 2017. Inductive representation
learning on large graphs. In NeurIPS.
[17] Bo Han, Quanming Yao, Tongliang Liu, Gang Niu, Ivor W Tsang, James T Kwok,
and Masashi Sugiyama. 2020. A survey of label-noise representation learning:
Past, present and future. arXiv preprint arXiv:2011.04406 (2020).
[18] Bo Han, Quanming Yao, Xingrui Yu, Gang Niu, Miao Xu, Weihua Hu, Ivor Tsang,
and Masashi Sugiyama. 2018. Co-teaching: Robust Training of Deep Neural
Networks with Extremely Noisy Labels. In NeurIPS.
[19] Cole Hawkins, Vassilis N Ioannidis, Soji Adeshina, and George Karypis. 2021.
Scalable consistency training for graph neural networks via self-ensemble self-
distillation. arXiv preprint arXiv:2110.06290 (2021).
[20] Weihua Hu, Matthias Fey, Marinka Zitnik, Yuxiao Dong, Hongyu Ren, Bowen
Liu, Michele Catasta, and Jure Leskovec. 2020. Open graph benchmark: Datasets
for machine learning on graphs. In NeurIPS, Vol. 33. 22118–22133.
[21] Thomas N. Kipf and Max Welling. 2017. Semi-Supervised Classification with
Graph Convolutional Networks. In ICLR.
[22] Johannes Klicpera, Aleksandar Bojchevski, and Stephan Günnemann. 2019. Pre-
dict then propagate: Graph neural networks meet personalized pagerank. In
ICLR.
[23] Johannes Klicpera, Aleksandar Bojchevski, and Stephan Günnemann. 2019. Com-
bining Neural Networks with Personalized PageRank for Classification on Graphs.
InICLR.
[24] Johannes Klicpera, Stefan Weißenberger, and Stephan Günnemann. 2019. Diffu-
sion improves graph learning. In NeurIPS.[25] Dong-Hyun Lee et al .2013. Pseudo-label: The simple and efficient semi-
supervised learning method for deep neural networks. In ICML Workshop.
[26] Qimai Li, Zhichao Han, and Xiao-Ming Wu. 2018. Deeper insights into graph
convolutional networks for semi-supervised learning. In AAAI.
[27] Yayong Li, Jie Yin, and Ling Chen. 2021. Unified robust training for graph neural
networks against label noise. In PAKDD.
[28] Hongrui Liu, Binbin Hu, Xiao Wang, Chuan Shi, Zhiqiang Zhang, and Jun Zhou.
2022. Confidence may cheat: Self-training on graph neural networks under
distribution shift. In TheWebConf.
[29] Meng Liu, Hongyang Gao, and Shuiwang Ji. 2020. Towards deeper graph neural
networks. In KDD.
[30] Yixin Liu, Kaize Ding, Qinghua Lu, Fuyi Li, Leo Yu Zhang, and Shirui Pan. 2023.
Towards self-interpretable graph-level anomaly detection. In NeurIPS, Vol. 36.
[31] Yixin Liu, Kaize Ding, Jianling Wang, Vincent Lee, Huan Liu, and Shirui Pan.
2023. Learning strong graph neural networks with weak information. In KDD.
[32] Hoang NT, Choong Jin, and Tsuyoshi Murata. 2019. Learning Graph Neural
Networks with Noisy Labels. In ICLR LLD Workshop.
[33] Giorgio Patrini, Alessandro Rozza, Aditya Krishna Menon, Richard Nock, and
Lizhen Qu. 2017. Making deep neural networks robust to label noise: A loss
correction approach. In CVPR.
[34] Siyi Qian, Haochao Ying, Renjun Hu, Jingbo Zhou, Jintai Chen, Danny Z Chen,
and Jian Wu. 2023. Robust Training of Graph Neural Networks via Noise Gover-
nance. In WSDM.
[35] Prithviraj Sen, Galileo Namata, Mustafa Bilgic, Lise Getoor, Brian Galligher, and
Tina Eliassi-Rad. 2008. Collective classification in network data. AI Magazine
(2008).
[36] Oleksandr Shchur, Maximilian Mumme, Aleksandar Bojchevski, and Stephan
Günnemann. 2018. Pitfalls of Graph Neural Network Evaluation. In NeurIPS
Relational Representation Learning Workshop.
[37] Kihyuk Sohn, David Berthelot, Nicholas Carlini, Zizhao Zhang, Han Zhang,
Colin A Raffel, Ekin Dogus Cubuk, Alexey Kurakin, and Chun-Liang Li. 2020.
Fixmatch: Simplifying semi-supervised learning with consistency and confidence.
InNeurIPS.
[38] Ke Sun, Zhouchen Lin, and Zhanxing Zhu. 2020. Multi-stage self-supervised
learning for graph convolutional networks on graphs with few labeled nodes. In
AAAI.
[39] Laurens Van der Maaten and Geoffrey Hinton. 2008. Visualizing data using t-SNE.
JMLR (2008).
[40] Petar Veličković, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro
Lio, and Yoshua Bengio. 2017. Graph attention networks. arXiv preprint
arXiv:1710.10903 (2017).
[41] Jianling Wang, Kaize Ding, Liangjie Hong, Huan Liu, and James Caverlee. 2020.
Next-item recommendation with sequential hypergraphs. In SIGIR.
[42] Song Wang, Yushun Dong, Kaize Ding, Chen Chen, and Jundong Li. 2023. Few-
shot node classification with extremely weak supervision. In WSDM.
[43] Yanling Wang, Jing Zhang, Shasha Guo, Hongzhi Yin, Cuiping Li, and Hong
Chen. 2021. Decoupling representation learning and classification for gnn-based
anomaly detection. In SIGIR. 1239–1248.
[44] Felix Wu, Amauri Souza, Tianyi Zhang, Christopher Fifty, Tao Yu, and Kilian
Weinberger. 2019. Simplifying graph convolutional networks. In ICML.
[45] Jun Xia, Haitao Lin, Yongjie Xu, Lirong Wu, Zhangyang Gao, Siyuan Li, and
Stan Z Li. 2021. Towards robust graph neural networks against label noise. (2021).
[46] Xiaobo Xia, Tongliang Liu, Bo Han, Chen Gong, Nannan Wang, Zongyuan Ge,
and Yi Chang. 2021. Robust early-learning: Hindering the memorization of noisy
labels. In ICLR.
[47] Xiaobo Xia, Tongliang Liu, Nannan Wang, Bo Han, Chen Gong, Gang Niu, and
Masashi Sugiyama. 2019. Are anchor points really indispensable in label-noise
learning?. In NeurIPS.
[48] Qizhe Xie, Zihang Dai, Eduard Hovy, Thang Luong, and Quoc Le. 2020. Unsuper-
vised data augmentation for consistency training. In NeurIPS.
[49] Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka. 2019. How powerful
are graph neural networks?. In ICLR.
[50] Han Yue, Chunhui Zhang, Chuxu Zhang, and Hongfu Liu. 2022. Label-invariant
augmentation for semi-supervised graph classification. In NeurIPS.
[51] Jiaqi Zeng and Pengtao Xie. 2020. Contrastive self-supervised learning for graph
classification. arXiv preprint arXiv:2009.05923 (2020).
[52] Hao Zhu and Piotr Koniusz. 2020. Simple spectral graph convolution. In ICLR.
 
582KDD ’24, August 25–29, 2024, Barcelona, Spain Kaize Ding, Xiaoxiao Ma, Yixin Liu, and Shirui Pan
A ALGORITHM
The overall training algorithm of DnD-Net is summarized in Algo-
rithm 1.
B EXPERIMENTAL DETAILS
B.1 Datasets
We evaluate DnD-Net on five real-world benchmark datasets for
node classification tasks, including Cora-ML, CiteSeer, PubMed,
Coauthor CS, and ogbn-arxiv [ 20,23,35,36]. The Statistics of
datasets are summarized in Table 3. The details are introduced
as follows:
•Cora-ML [23] is a citation network wherein each node corre-
sponds to a machine learning paper categorized into 7 research
topics, and each edge denotes a citation between papers. The
node features consist of bag-of-words representations of the doc-
uments.
•CiteSeer [35] is a citation network comprising six types of ma-
chine learning papers: Agents, AI, DB, IR, ML, and HCI. Nodes
represent papers, and edges signify citation relationships. The
features are bag-of-words of the papers.
•PubMed [35] constitutes a citation network sourced from the
PubMed database. In this network, nodes correspond to papers
discussing three types of diabetes, and edges denote citations
among them. The node features are high-frequency bag-of-words
representations of the publications.
•Coauthor CS [36] is a coauthorship network sourced from the
Microsoft Academic Graph. In this network, each node represents
an author, and each edge signifies a co-authorship relationship
between two authors. The features are bag-of-words embeddings
of the keywords in papers, while the labels denote the research
directions of the authors.
•ogbn-arxiv is a citation network containing Computer Science
arXiv papers. In ogbn-arxiv, individual nodes represent papers,
and edges denote citation relationships between two papers. The
features consist of word embeddings derived from the titles and
abstracts of papers, while the labels encompass 40 subject areas
of the papers.
B.2 Baselines
We compare our method with 10state-of-the-art baselines, the
details of each method are listed below.
•GCN [21] is the graph convolutional neural network. It applies
low-pass filters to derive graph signals for node classification.
•SGC [44] simplifies GCN by taking simple propagation steps
followed by standard logistic regression for classification.
•GRAND [14] uses a consistency regularized training scheme
to enforce the classifier makes aligned predictions on multiple
graph data augmentations.
•PTA [12] is a propagation then training method based on label
propagation. It adopts an adaptive weighing strategy to weigh the
loss introduced by pseudo-labeled nodes based on the normalized
adjacency matrix and training iterations.
•Co-teaching [18] engages a collaborative teacher-student model
where each network excludes a percentage of nodes with high
losses for the training of the other.•T-Revision [47] learns a noise transition matrix by exploiting
data points similar to anchor points and then corrects the predic-
tions upon the learned transition matrix.
•NRGNN [5] involves two asymmetric GCNs for label noise re-
sistance. It aims to extract and disseminate accurate signals on
the graph through edge prediction and pseudo-label mining.
•RTGNN [34] introduces self-reinforcement based on the memo-
rization effects of neural networks and consistency regularization
across different views to explicitly govern label noise for robust
training of GNN.
•PI-GNN [13] takes the direct edges between nodes as an extra
supervision signal to regularize the node classification model for
robust node classification.
•ERASE [3] employs label denoising propagation and label se-
mantic propagation as two stages to learn semantic labels, and
maximizes the error-resilient coding rate reduction between the
whole dataset and each class for label noise tolerance.
Algorithm 1: The training algorithm of DnD-Net
Input: Feature matrix X; Adjacency matrix A; Training
label Y𝐿.
Parameters: Propagation step 𝐿; Restart Probability 𝛼;
Temperature 𝜏; Trade-off coefficients 𝛾1,𝛾2
/* Pre-processing */
1Calculate X←propagation(X,A;𝐿,𝛼)via Eq. (4)
/* Model Training */
2Initialize model parameters
3while not converged do
4 for𝑣𝑖∈Vdo
5 Calculate p𝑖=𝑓(x𝑖)with MLP-based node classifier
6 end
7 ComputeLCEvia Eq. (2)
8 ComputeLNPAvia Eq. (5)
9 for𝑣𝑖∈V𝑈do
10 Calculate ˜x𝑖via Eq. (6)
11 Calculate ˜p𝑖=𝑓(˜x𝑖)with MLP-based node classifier
12 Calculate ˆp𝑖,H(ˆp𝑖), and𝑤𝑖via Eq. (8)-(10)
13 end
14 ComputeLPLvia Eq. (11)
15 Compute overall loss Lvia Eq. (12)
16 Update the parameters of 𝑓(·)via gradient descent
17end
Table 3: The statistics of the graph benchmark datasets.
Dataset #Nodes #Edges Features Classes
Cora-ML 2,810 7,981 2,879 7
CiteSeer 3,327 4,732 3,703 6
PubMed 19,717 44,338 500 3
Coauthor CS 18,333 81,894 6,805 15
ogbn-arxiv 169,343 1,166,243 128 40
 
583Divide and Denoise: Empowering Simple Models for Robust Graph Semi-Supervised Learning against Label Noise KDD ’24, August 25–29, 2024, Barcelona, Spain
λ1 0123
λ20
1
2
3Accuracy (%)
50556065707580
(a) 20% Uniform Noise
λ1 0123
λ20
1
2
3Accuracy (%)
4550556065 (b) 60% Uniform Noise
λ1 0123
λ20
1
2
3Accuracy (%)
6065707580
(c) 20% Pair Noise
λ1 0123
λ20
1
2
3Accuracy (%)
4050607080 (d) 30% Pair Noise
Figure 8: Sensitivity to 𝜆1and𝜆2on CiteSeer.
B.3 Implementation Details
Hyperparameters. In our implementation, we set the default train-
ing epochs to 200with early stopping. The MLP-based classifier
contains two layers. Adam with an initial learning of 0.002and
weight decay of 5𝑒-4is utilized as the optimizer for training. We set
the batch size as 10240 on ogbn-arxiv dataset. For the rest hyperpa-
rameters, we conduct 200rounds of random search to choose the
best performing setting, in which all hyperparameters are searched
together. The search space comprises:
•Restart probability 𝛼:{0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9}
•Propagation steps 𝐿: an integer between [1,50]
•Trade-off coefficient 𝜆1: a float between[0.1,3]
•Trade-off coefficient 𝜆2: a float between[0.1,3]
•MLP’s dimensionality 𝐾:{64,128,256}
Computing environment. We implement the proposed methods
with PyTorch 1.12.1 and PyTorch Geometric 2.1.0. All experiments
are conducted on a Linux server with an Intel Xeon E-2288G CPU
and two Quadro RTX 6000 GPUs (24GB memory each).
B.4 Additional Results
Sensitivity to 𝜆1and𝜆2.We further conduct parameter analysis
of𝜆1and𝜆2on CiteSeer dataset, and the results are displayed in
Figure 8. Our observations align with the discussion in Section 5.4:
1)𝜆1exerts a greater influence on performance, and 2) the model
prefers a moderate value for these hyper-parameters.Sensitivity to 𝛼.The restart probability 𝛼in Eq. (4)determines
the proportion of target node information in the propagated fea-
tures. Intuitively, a larger 𝛼preserves more information about the
node itself and vice versa. We vary 𝛼from 0.1to0.9and depict
the performance changes in Figure 9. It is obvious that the denois-
ing performance is better given smaller 𝛼s, which indicates that
preserving more information from neighbors contributes to more
robust learning against label noise.
Representation Visualization. In addition to Cora-ML, we also
visualize the node embeddings on CiteSeer to compare our method
and ERASE. Similar to Cora-ML, nodes in different classes are better
separated in the embedding space of DnD-Net.
0.10.30.50.70.92540557085Accuracy (%)20%40%60%<latexit sha1_base64="wEI8JztgPf6N92x6CusVkC/0LZg=">AAAB7XicbVBNS8NAEJ3Ur1q/qh69LBbBU0mkqMeiF48V7Ae0oUy2m3btZhN2N0IJ/Q9ePCji1f/jzX/jts1BWx8MPN6bYWZekAiujet+O4W19Y3NreJ2aWd3b/+gfHjU0nGqKGvSWMSqE6BmgkvWNNwI1kkUwygQrB2Mb2d++4kpzWP5YCYJ8yMcSh5yisZKrR6KZIT9csWtunOQVeLlpAI5Gv3yV28Q0zRi0lCBWnc9NzF+hspwKti01Es1S5COcci6lkqMmPaz+bVTcmaVAQljZUsaMld/T2QYaT2JAtsZoRnpZW8m/ud1UxNe+xmXSWqYpItFYSqIicnsdTLgilEjJpYgVdzeSugIFVJjAyrZELzll1dJ66LqXVZr97VK/SaPowgncArn4MEV1OEOGtAECo/wDK/w5sTOi/PufCxaC04+cwx/4Hz+AI5vjyE=</latexit>↵
(a) Cora-ML - Uniform Noise
0.10.30.50.70.925405570Accuracy (%)20%40%60%<latexit sha1_base64="wEI8JztgPf6N92x6CusVkC/0LZg=">AAAB7XicbVBNS8NAEJ3Ur1q/qh69LBbBU0mkqMeiF48V7Ae0oUy2m3btZhN2N0IJ/Q9ePCji1f/jzX/jts1BWx8MPN6bYWZekAiujet+O4W19Y3NreJ2aWd3b/+gfHjU0nGqKGvSWMSqE6BmgkvWNNwI1kkUwygQrB2Mb2d++4kpzWP5YCYJ8yMcSh5yisZKrR6KZIT9csWtunOQVeLlpAI5Gv3yV28Q0zRi0lCBWnc9NzF+hspwKti01Es1S5COcci6lkqMmPaz+bVTcmaVAQljZUsaMld/T2QYaT2JAtsZoRnpZW8m/ud1UxNe+xmXSWqYpItFYSqIicnsdTLgilEjJpYgVdzeSugIFVJjAyrZELzll1dJ66LqXVZr97VK/SaPowgncArn4MEV1OEOGtAECo/wDK/w5sTOi/PufCxaC04+cwx/4Hz+AI5vjyE=</latexit>↵ (b) CiteSeer - Uniform Noise
0.10.30.50.70.94555657585Accuracy (%)20%30%40%<latexit sha1_base64="wEI8JztgPf6N92x6CusVkC/0LZg=">AAAB7XicbVBNS8NAEJ3Ur1q/qh69LBbBU0mkqMeiF48V7Ae0oUy2m3btZhN2N0IJ/Q9ePCji1f/jzX/jts1BWx8MPN6bYWZekAiujet+O4W19Y3NreJ2aWd3b/+gfHjU0nGqKGvSWMSqE6BmgkvWNNwI1kkUwygQrB2Mb2d++4kpzWP5YCYJ8yMcSh5yisZKrR6KZIT9csWtunOQVeLlpAI5Gv3yV28Q0zRi0lCBWnc9NzF+hspwKti01Es1S5COcci6lkqMmPaz+bVTcmaVAQljZUsaMld/T2QYaT2JAtsZoRnpZW8m/ud1UxNe+xmXSWqYpItFYSqIicnsdTLgilEjJpYgVdzeSugIFVJjAyrZELzll1dJ66LqXVZr97VK/SaPowgncArn4MEV1OEOGtAECo/wDK/w5sTOi/PufCxaC04+cwx/4Hz+AI5vjyE=</latexit>↵
(c) Cora-ML - Pair Noise
0.10.30.50.70.93545556575Accuracy (%)20%30%40%<latexit sha1_base64="wEI8JztgPf6N92x6CusVkC/0LZg=">AAAB7XicbVBNS8NAEJ3Ur1q/qh69LBbBU0mkqMeiF48V7Ae0oUy2m3btZhN2N0IJ/Q9ePCji1f/jzX/jts1BWx8MPN6bYWZekAiujet+O4W19Y3NreJ2aWd3b/+gfHjU0nGqKGvSWMSqE6BmgkvWNNwI1kkUwygQrB2Mb2d++4kpzWP5YCYJ8yMcSh5yisZKrR6KZIT9csWtunOQVeLlpAI5Gv3yV28Q0zRi0lCBWnc9NzF+hspwKti01Es1S5COcci6lkqMmPaz+bVTcmaVAQljZUsaMld/T2QYaT2JAtsZoRnpZW8m/ud1UxNe+xmXSWqYpItFYSqIicnsdTLgilEjJpYgVdzeSugIFVJjAyrZELzll1dJ66LqXVZr97VK/SaPowgncArn4MEV1OEOGtAECo/wDK/w5sTOi/PufCxaC04+cwx/4Hz+AI5vjyE=</latexit>↵ (d) CiteSeer - Pair Noise
Figure 9: Sensitivity to 𝛼.
Noise Rate: 40%Noise Rate: 60%
(a)DnD-Net - Uniform Noise
Noise Rate: 40%Noise Rate: 60% (b) ERASE - Uniform Noise
Noise Rate: 30%Noise Rate: 40%
(c)DnD-Net - Pair Noise
Noise Rate: 30%Noise Rate: 40% (d) ERASE - Pair Noise
Figure 10: Visualization of node embeddings on CiteSeer.
 
584