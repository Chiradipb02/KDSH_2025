RelKD 2024: The Second International Workshop on
Resource-Efficient Learning for Knowledge Discovery
Chuxu Zhang∗
Brandeis University
Waltham, Massachusetts, USA
chuxuzhang@brandeis.eduDongkuan (DK) Xu
North Carolina State University
Raleigh, North Carolina, USA
dxu27@ncsu.eduKaize Ding
Northwestern University
Evanston, Illinois, USA
kaize.ding@northwestern.edu
Jundong Li
University of Virginia
Charlottesville, Virginia, USA
jl6qk@virginia.eduMojan Javaheripi
Microsoft Research
Redmond, Washington, USA
mojavaheripi@microsoft.comSubhabrata Mukherjee
Hippocratic AI
San Francisco, California, USA
subhabrata.mukherjee.ju@gmail.com
Nitesh V. Chawla
University of Notre Dame
Notre Dame, Indiana, USA
nchawla@nd.eduHuan Liu
Arizona State University
Tempe, Arizona, USA
huanliu@asu.edu
ABSTRACT
Modern machine learning techniques, particularly deep learning,
have showcased remarkable efficacy across numerous knowledge
discovery and data mining applications. However, the advancement
of many of these methods is frequently impeded by resource con-
straint challenges in many scenarios, such as limited labeled data
(data-level), small model size requirements in real-world computing
platforms (model-level), and efficient mapping of the computations
to heterogeneous target hardware (system-level). Addressing all
these factors is crucial for effectively and efficiently deploying devel-
oped models across a broad spectrum of real-world systems, includ-
ing large-scale social network analysis, recommendation systems,
and real-time anomaly detection. Therefore, there is a critical need
to develop efficient learning techniques to address the challenges
posed by resource limitations, whether from data, model/algorithm,
or system/hardware perspectives. The proposed international work-
shop on " Resource- Efficient Learning for Knowledge Discovery
(RelKD 2024)" will provide a great venue for academic researchers
and industrial practitioners to share challenges, solutions, and fu-
ture opportunities of resource-efficient learning.
ACM Reference Format:
Chuxu Zhang, Dongkuan (DK) Xu, Kaize Ding, Jundong Li, Mojan Javaheripi,
Subhabrata Mukherjee, Nitesh V. Chawla, and Huan Liu. 2024. RelKD 2024:
The Second International Workshop on Resource-Efficient Learning for
Knowledge Discovery. In Proceedings of the 30th ACM SIGKDD Conference
on Knowledge Discovery and Data Mining (KDD ’24), August 25–29, 2024,
Barcelona, Spain. ACM, New York, NY, USA, 2 pages. https://doi.org/10.1145/
3637528.3671487
∗The main contact organizer
Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for third-party components of this work must be honored.
For all other uses, contact the owner/author(s).
KDD ’24, August 25–29, 2024, Barcelona, Spain
©2024 Copyright held by the owner/author(s).
ACM ISBN 979-8-4007-0490-1/24/08.
https://doi.org/10.1145/3637528.36714871 TOPICS, RELEVANCE TO KDD, AUDIENCE
The goal of this workshop is to provide a platform for addressing
the challenges that emerge when contemporary machine learning
methods, such as deep learning and large-scale foundation models,
confront resource constraints, such as limited labeled data, con-
strained computing devices, and restricted power/energy budgets.
The workshop will center on machine learning techniques utilized
in knowledge discovery and data science applications, with a focus
on efficient learning from three angles: data, algorithm/model, and
system/hardware. The topics of interest will include:
•Data-efficient learning: Self-supervised/unsupervised learning,
semi/weakly-supervised learning, few-shot learning, and their
applications to various data modalities (e.g., graph, user behavior,
text, web, image, time series) and data science problems (e.g.,
social media, healthcare, recommendation, finance, multimedia).
•Algorithm/model-efficient learning: neural network pruning
& quantization & acceleration, sparse learning, neural network
compression, knowledge distillation, neural architecture search,
and their applications on various data science problems.
•System/hardware-efficient learning: Neural network-hardware
co-design, real-time and energy-efficient learning system design,
hardware accelerators for machine learning, and their applica-
tions on various data science problems.
KDD has been dedicated to the discovery of novel theories, mod-
els, and algorithms for various problems in data science, business,
medicine, and engineering. This workshop is highly related to
KDD, as it concentrates on addressing challenges and employ-
ing techniques to enhance both the effectiveness and efficiency
of contemporary machine learning theories, models, algorithms,
and systems across diverse real-world knowledge discovery and
data mining applications. The organizers believe related topics are
of high interest to the community, and the workshop can raise
researchers’/practitioners’ awareness to study resource-efficient
learning problems. For example, in KDD 2023, many accepted pa-
pers focused on improving effectiveness and efficiency and modern
machine learning techniques via data/algorithm/model-level de-
sign. The target audiences of this workshop include both academic
6749
KDD ’24, August 25–29, 2024, Barcelona, Spain Chuxu Zhang et al.
9:00 Opening remark
9:00-9:30 Invited talk 1
9:30-10:00 Invited talk 2
10:00-10:30 Spotlight paper presentations
10:30-11:00 Poster and social session (break)
11:00-11:30 Invited talk 3
11:30-12:00 Invited talk 4
12:00-1:00 Panel talk and discussion
1:00 Closing remark
Table 1: Tentative 4-hour workshop program.
researchers and industrial practitioners who are either new to or
intrigued by resource-efficient learning, along with those engaged
in related research. We anticipate drawing a diverse audience from
various research and engineering disciplines, encompassing data
mining, machine learning, deep learning, machine learning systems,
and algorithm-hardware co-design.
2 PROGRAM SKETCH
We aim to develop a comprehensive program comprising (a) invited
talks; (b) paper submissions, posters, and presentations; and (c)
panel discussions. The tentative 4 hour workshop program is shown
in Table 1. The estimated number of attendees is more than 50.
•Invited talks: The workshop will feature three keynote presen-
tations. We will invite esteemed researchers who specialize in
various domains of resource-efficient learning. Each talk will
leave some time for Q&A.
•Paper submissions, posters, and presentations: The workshop will
welcome paper submissions. Following a rigorous peer-review
process, accepted papers will be presented as posters during
the coffee break and social session. Additionally, a few selected
papers will be given spotlight presentations.
•Panel talk and discussion: The workshop will include a panel talk
and discussion session to explore the research, challenges, and
opportunities within resource-efficient learning. Panelists will
comprise both talents and experts in relevant research areas.
It is noteworthy that our workshop stands as the sole instance
at KDD dedicated to resource-efficient learning, uniting re-
searchers and practitioners with aligned interests. This workshop
is different from workshops such as the Data-Efficient Machine
Learning Workshop at KDD’21, since our workshop will cover di-
verse topics of resource-efficient learning in data, model/algorithm,
and system/hardware angles. It will also target various data science
applications of resource-efficient learning. We will advertise our
workshop through the website, mailing lists (e.g., KDD mailing
list), and social media (e.g., Twitter). Given its strong relevance to
KDD and comprehensive coverage of both established and emerg-
ing themes in resource-efficient learning across data, model, and
system levels, we anticipate significant interest from attendees.
3 PAST WORKSHOP EDITION
We successfully organized the first international workshop on
resource-efficient learning for knowledge discovery at KDD 2023
(RelKD 2023). In this workshop, we invited three keynote speak-
ers and four experts for panel talk and discussion. The workshop
accepted about 10 research papers, all of which were presented asposters, with 3 chosen for spotlight oral presentations. Approxi-
mately 50 attendees participated in the workshop throughout the
entire event.
4 ORGANIZERS
Chuxu Zhang is an Assistant Professor of CS at the Brandeis Uni-
versity. His research lies in the intersection of artificial intelligence,
graph machine learning, and societal applications. He has over 100
papers in major AI venues such as ICML, NeurIPS, ICLR, and KDD.
He is the recipient of the NSF CAREER Award (2024) and best paper
(candidate) awards in CIKM 2021 and WWW 2019.
Dongkuan (DK) Xu is an Assistant Professor in the CS Department
at NC State. His research is fundamentally grounded in advancing
Artificial General Intelligence, particularly the automated planning,
reliable reasoning, and efficient computing of generative AI systems.
He has been honored with the Microsoft Accelerating Foundation
Models Research Award 2024 and the Best Paper Award of ICCCN
2023. DK’s research has been published repeatedly in top confer-
ences and journals in AI, NLP, CV, Hardware, and other fields.
Kaize Ding is an Assistant Professor in the Department of Sta-
tistics and Data Science at Northwestern University. His research
interests are generally in data mining, machine learning, and natu-
ral language processing. His work has been published in top-tier
venues (e.g., AAAI, EMNLP, KDD, NeurIPS, and TheWebConf), and
has been recognized with several prestigious awards, including the
AAAI New Faculty Highlights, SDM Best Posters Award, Best Paper
Award at the Trustworthy Learning on Graphs workshop, etc.
Mojan Javaheripi is a Senior Researcher at Microsoft GenAI Re-
search, working on "Physics of Language Models". Her focus is
on enhancing small language models through new data sources,
training regimens, and model architectures. Her research has been
published in top-tier venues including NeurIPS, CVPR, DAC, IC-
CAD, CCS, and NDSS. Mojan’s research has been recognized by
the 2019 Qualcomm Innovation Fellowship.
Subhabrata Mukherjee is the co-founder and chief scientist at
Hippocratic AI. His research is focused on aligning large founda-
tion models to human reasoning, preferences, and safety. He was
selected as a semi-finalist (100 innovators under 35 globally) in the
2022 edition of MIT Tech Review (TR35) for his work on efficient
AI. He received the 2018 SIGKDD Doctoral Dissertation Runner-up
Award for his thesis on credibility analysis and misinformation.
Jundong Li is an Assistant Professor at the University of Virginia
with appointments in Departments of ECE and CS, and School of
Data Science. His research interests are generally in data mining and
machine learning. He has published over 150 papers in high-impact
venues (such as KDD, WWW, NeurIPS), with over 10,000 citations.
He has won several prestigious awards, including SIGKDD 2022
Best Research Paper Award, NSF CAREER Award, JP Morgan Chase
Faculty Research Award, and Cisco Faculty Research Award.
Nitesh V. Chawla is the Frank M. Freimann Professor of Computer
Science and Engineering at the University of Notre Dame. His re-
search focuses on artificial intelligence, data science, and network
science. He is a fellow of ACM, IEEE, AAAS, and AAAI.
Huan Liu is a Professor of Computer Science at Arizona State Uni-
versity. His research focuses on developing computational methods
for data mining, machine learning, and social computing. He is a
fellow of AAAI, AAAS, ACM, and IEEE.
6750