Domain -Driven LLM Development:   
Insights into RAG and Fine -Tuning Practices  
José Cassio dos Santos Junior   
 Amazon Web Services  
Seattle, WA , USA  
 jcsantos@amazon.com  Rachel Hu  
 CambioML Corp   
 San Jose, CA , USA 
 rachel@cambioml.com  Richard Song  
 Epsilla  
 Jersey City, NJ , USA  
 richard@epsilla.com
Yunfei Bai† 
 Amazon Web Services  
Seattle, WA , USA  
 byunfei@amazon.com  
Abstract  
To improve Large Language Model (LLM) performance on 
domain specific applications, ML developers often leverage  
Retrieval Augmented Generation (RAG) and LLM Fine -Tuning. 
RAG extends the capabilities of LLMs to specific domains or an 
organization's internal knowledge base, without the need to 
retrain the model. On the other hand, Fine -Tuning approach 
updates LLM weights with domain -specific data to improve 
performance on specific tasks. The fine -tuned model is 
particularly effective to systematically learn new comprehensive 
knowledge in a specific domain that is not covered by the LLM 
pre-training. This tutorial walks through the RAG and Fine -
Tuning techniques, discusses the insights of their advantages 
and limitations, and provides best practices of adopting the 
methodolog ies for the LLM tasks and  use cases. The hands -on 
labs demonstrate the advanced techniques to optimize the RAG 
and fine-tuned LLM  architecture that handle s domain specific 
LLM tasks. The labs in the tutorial are designed by using a set of 
open -source python libraries to implement the RAG and fine-
tuned LLM  architecture . 
CCS C oncepts  
• Compute Methodologies → Artificial Intelligence   
Keywords  
Retrieval Augmented Generation, Large Language Model, Fine 
Tuning, Generative Artificial Intelligence  
ACM Reference format:  
José Cassio dos Santos Junior , Rachel Hu, Richard Song and Yunfei Bai . 
2024. Domain -Driven LLM Development: Insights into RAG and Fine -
Tuning Practices . In Proceedings of  30th ACM SIGKDD Conference o n 
Knowledge Discovery and Data Mining (KDD ’24), August 25 -29, 2024,  Barcelona, Spain.  ACM, New York, NY, USA, 2 pages.  
https://doi.org/10.1145/ 3637528.3671445  
Summary  of the Tutorial  
RAG and  LLM Fine-Tuning are popular approaches  in building 
LLM applications . In this tutorial we examine the advantages 
and disadvantages  between RAG and fine-tuned LLM  in 
complexity, transparency, cost -effectiveness, time efficiency, and 
accuracy. We also explore how to combine the two methods in a 
common LLM pipeline for the domain -specific text generation , 
question -answer and text summarization task s.  
Lab 1: Advanced Techniques in RAG . In this lab, we explore 
multi -phase optimization techniques to enhance RAG's accuracy 
and relevance. The initial RAG struggles with indexing, retrieval, 
and response generation. Pre -Retrieval Optimization employs 
advanced chunking and indexing strategies, including semantic 
chunking and hypothetical question  generation. Retrieval 
Optimization refines user queries and improves retrieval 
methods, combining keyword s and semantic searches with 
hybrid techniques. Post -retrieval optimization focuses on 
reranking documents by relevance using heuristic methods and 
models, along  with prompt compression and context 
condensation. Additionally, Graph RAG uses LLM -generated 
knowledge graphs for better reasoning across documents, while 
Agentic RAG supports complex, multi -document analysis. We 
demonstrate  and experiment  these optimization  techniques  for a 
domain -specific question -answer task in the lab to achieve 
precise, relevant responses.  
Lab 2: LLM Fine-Tuning . This lab focuses on fine  tuning LLM 
using labeled datasets and human/AI feedback to adjust model 
weights for better performance in specific domains. Fine -Tuning 
allows smaller, domain -specific models to outperform larger 
general -purpose  models . The Continuous Fine -Tuning process 
involves Supervised Fine Tuning (SFT) with human -annotated 
data, followed by human and AI validation, and enhancements 
via Reinforcement Learning from Human and AI Feedback 
(RLHF/RLAIF). Integrating fine -tuned LLMs in a RAG pipeline 
enhances performance by utilizing the most relevant data and 
learning domain -specific knowledge. In this lab , we first 
generate synthetic data from domain -specific documents, then † Corresponding Author  
Permission to make digital or hard copies of all or part of this work for personal 
or classroom use is granted without fee provided that copies are not made or 
distributed for profit or commercial advantage and that copies bear this notice 
and the full citation on the first page. Copyrights for third -party components of 
this work must be honored. For all other uses, contact the Owner/ Author.  
KDD ’24, August 25 –29, 2024, Barcelona, Spain  
© 2024 Copyright is held by the owner/author(s).  
ACM ISBN 979-8-4007-0490-1/24/08.  https://doi.org/10.1145/ 3637528.3671445  
 
6416
KDD’24, August 25 -29, 2024, Barcelona , Spain  José Cassio dos Santos Junior, Rachel Hu, Richard Song, & Yunfei Bai  
 
 
 instructively fine -tune a small LLM for the question -answer task 
previously experimented in Lab 1. 
Lab 3: RAG  and Fine -Tuned Model  Benchmarking .  This lab 
evaluates the performance of  RAG , fine-tuned LLM , and a 
combined architecture  on domain -specific question -answer and 
summariz ation tasks . We test these approaches using a 
consistent datasets and performance metrics. Initial metric 
outcomes guide the decision on whether either approach meets 
the expected performance. If so, we further estimate  the costs 
associated with each approach, and conduct ROI analysis to 
determine the most cost -performant  solution.  
In this hands -on tutorial, we examine the benefits and drawbacks 
of RAG and LLM Fine -Tuning . With  experiments and detailed  
discussions on  the RAG  pipeline, fi ne-tuned LLM , their 
combined use , and assessment of performance and cost -
effectiveness, we demonstrate the best practices  to optimize  the 
architecture of RAG and fine-tuned LLM  for multiple domain -
specific tasks.   
Presenters Biography   
José Cassio dos Santos Junior  A member of the Amazon 
Machine Learning University team. He is responsible for 
Curriculum Development for Advanced Modules. As a previous 
Senior Data Scientist on the AWS LATAM Professional Services 
Data Science team, he was responsible for experiments and MVP 
engagements with important clients in the Brazilian market. 
Cassio has over 20 years of experience working as a software 
engineer. As a business process management expert, he 
participated in BPO projects for more than 7 years. Cass also has 
more than 10 years of teaching experience at colleges and acting 
as instructor for Linux certification preparation and Microsoft 
Innovation Center bootcamps. He holds a Master’s degree in 
Computer Engineering, a Bachelor’s degree in Physics, and a 
Bachelor’s degree in Business Administration, specialized in IT 
Quantitative Methods.  
Rachel Hu  The Co -founder & CEO of CambioML, which builds 
open -source libraries to prepare high quality data for RAG and 
LLM finetuning. Previously she was an Applied Scientist at AWS 
AI, an ML instructor at Amazon Machine Learning University, 
and a speaker at top conferences including KDD, NVIDIA GTC, 
AWS re:Invent, MLOps Summit, etc. Rachel co -authored Dive 
into Deep Learning (D2L.ai), an open -source interactive textbook 
adopted by over 500 universities around the world. Rachel 
received her master degree of statistics from University of 
California, Berkeley, and bachelor of Math from University of 
Waterloo, Canada.  
Richard Song  The Co-Founder and CEO of Epsilla Inc, a one -
stop RAGaaS platform for building production ready LLM 
applications. With a background in big data, vector graph 
databases, and high  performance  computing, Richard helps 
customers build production -ready RAG systems connected with 
large scale proprietary data. Richard holds a Master’s degree in 
Computer Science from Cornell University.  
Yunfei Bai  A Senior Solutions Architect at Amazon Web 
Services. With over 15 years ’ experience on AI/ML, Data Science and Analytics, Yunfei helps AWS customers adopt AI/ML and 
Generative AI services to deliver business results. Prior to AWS, 
he worked in various roles including product manager and 
solution consultant in multiple industries, designed and 
delivered AI/ML and data analytics solutions that overcome 
complex technical challenges and drive strategic objectives. 
Yunfei has a PhD in Electronic and Electrical Engineering. He 
has published research papers and blog posts, and serves as a 
journal reviewer.  
References  
[1] Patrick Lewis,  Ethan Perez,  Aleksandra Piktus,  Fabio Petroni,  Vladimir 
Karpukhin,  Naman Goyal,  Heinrich Küttler,  Mike Lewis,  Wen -tau Yih,  Tim 
Rocktäschel,  Sebastian Riedel,  Douwe Kiela.  2020.  Retrieval -Augmented 
Generation for Knowledge -Intensive NLP Tasks.  arXiv:2005.11401 [cs.LG]   
[2] Parth Sarthi,  Salman Abdullah,  Aditi Tuli,  Shubh Khanna,  Ann 
Goldie,  Christopher D. Manning.  2024.  RAPTOR: Recursive Abstractive 
Processing for Tree -Organized Retrieval.  arXiv:2401.18059  [cs.LG]  
[3] Weijia Shi,  Sewon Min,  Michihiro Yasunaga,  Minjoon Seo,  Rich James,  Mike 
Lewis,  Luke Zettlemoyer,  Wen -tau Yih.  2023.  REPLUG: Retrieval -
Augmented Black -Box Language Models.  arXiv:2301.12652 [cs.LG]   
[4] Zhuyun Dai,  Vincent Y. Zhao,  Ji Ma,  Yi Luan,  Jianmo Ni,  Jing Lu,  Anton 
Bakalov,  Kelvin Guu,  Keith B. Hall,  Ming -Wei Chang. 2022.  Promptagator: 
Few-shot Dense Retrieval From 8 Examples.  arXiv: 2209.11755 [cs.LG]   
[5] Michael Glass,  Gaetano Rossiello,  Md Faisal Mahbub Chowdhury,  Ankita 
Rajaram Naik,  Pengshan Cai,  Alfio Gliozzo.  2022.  Re2G: Retrieve, Rerank, 
Generate.  arXiv: 2207.06300 [cs.LG]   
[6] Peng Shi,  Rui Zhang,  He Bai,  Jimmy Lin.  2022.  XRICL: Cross -lingual 
Retrieval -Augmented In -Context Learning for Cross -lingual Text -to-SQL 
Semantic Parsing.   arXiv: 2210.13693 [cs.LG]   
[7] Huiqiang Jiang,  Qianhui Wu,  Chin -Yew Lin,  Yuqing Yang,  Lili Qiu.  2023.  
Llmlingua: Compressing prompts for accelerated inference of large language 
models.  arXiv: 2310.05736 [cs.LG]   
[8] Huaixiu Steven Zheng,  Swaroop Mishra,  Xinyun Chen,  Heng -Tze Cheng,  Ed 
H. Chi,  Quoc V Le,  Denny Zhou.  2023.  Take a Step Back: Evoking Reasoning 
via Abstraction in Large Language Models.   arXiv: 2310.06117 [cs.LG]   
[9] Liang Wang,  Nan Yang,  Furu Wei.  2023.  Query2doc: Query Expansion with 
Large Language Models.  arXiv: 2303.07678  [cs.LG]   
[10] Xinbei Ma,  Yeyun Gong,  Pengcheng He,  Hai Zhao,  Nan Duan. 2023.  Query 
Rewriting for Retrieval -Augmented Large Language Models.  arXiv: 
2305.14283 [cs.LG]    
[11] Luyu Gao,  Xueguang Ma,  Jimmy Lin,  Jamie Callan.  2022.  Precise Zero -Shot 
Dense Retrieval without Relevance Labels.  arXiv: 2212.10496 [cs.LG]  
[12] Zackary Rackauckas.  2024.  RAG -Fusion: a New Take on Retrieval -
Augmented Generation.  arXiv: 2402.03367 [cs.LG]  
[13] Xiao Liu,  Kaixuan Ji,  Yicheng Fu,  Weng Lam Tam,  Zhengxiao Du,  Zhilin 
Yang,  Jie Tang.  2021.  P -Tuning v2: Prompt Tuning Can Be Comparable to 
Fine-tuning Universally Across Scales and Tasks.  arXiv: 2110.07602 [cs.LG]  
[14] Angels Balaguer, Vinamra Benara, Renato Cunha, Roberto Estevão, Todd 
Hendry, Daniel Holstein, Jennifer Marsman, Nick Mecklenburg, Sara Malvar, 
Leonardo O. Nunes, Rafael Padilha, Morris Sharp, Bruno Silva, Swati Sharma, 
Vijay Aski, Ranveer Chandra.  2024.  RAG vs Fine -tuning: Pipelines, 
Tradeoffs, and a Case Study on Agriculture.  arXiv: 2401.08406 [cs.LG]  
[15] Heydar Soudani, Evangelos Kanoulas, Faegheh Hasibi.  2024.  Fine Tuning vs. 
Retrieval Augmented Generation for Less Popular Knowledge.  arXiv: 
2403.01432 [cs.LG]  
[16] Oded Ovadia, Menachem Brief, Moshik Mishaeli, Oren Elisha.  2024.  Fine -
Tuning or Retrieval? Comparing Knowledge Injection in LLMs. arXiv: 
2312.05934 [cs.LG]  
[17] Shamane Siriwardhana,  Rivindu Weerasekera,  Elliott Wen,  Suranga 
Nanayakkara.  2021.  Fine -tune the Entire RAG Architecture (including DPR 
retriever) for Question -Answering.  arXiv: 2106.11517 [cs.LG]  
[18] Tianjun Zhang,  Shishir G. Patil,  Naman Jain,  Sheng Shen,  Matei Zaharia,  Ion 
Stoica,  Joseph E. Gonzalez.  2024.  RAFT: Adapting Language Model to 
Domain Specific RAG.  arXiv: 2403.10131 [cs.LG]  
[19] Shicheng Xu,  Liang Pang,  Mo Yu,  Fandong Meng,  Huawei Shen,  Xueqi 
Cheng,  Jie Zhou. 2024.  Unsupervised Information Refinement Training of 
Large Language Models for Retrieval -Augmented Generation.  arXiv: 
2402.18150 [cs.LG]  
[20] Mandar Kulkarni,  Praveen Tangarajan,  Kyung Kim,  Anusua Trivedi.  2024.  
Reinforcement Learning for Optimizing RAG for Domain Chatbots.  arXiv: 
2401.06800 [cs.LG]  
6417