Tackling Instance-Dependent Label Noise with Class Rebalance
and Geometric Regularization
Shuzhi Cao∗
School of Computer Science and Technology & Shaanxi
Provincial Key Laboratory of Big Data Knowledge
Engineering, Xi’an Jiaotong University
Xi’an, China
cao309615@gmail.comJianfei Ruan∗
School of Computer Science and Technology & Shaanxi
Provincial Key Laboratory of Big Data Knowledge
Engineering, Xi’an Jiaotong University
Xi’an, China
jianfei.ruan@hotmail.com
Bo Dong†
School of Distance Education & Shaanxi Provincial Key
Laboratory of Big Data Knowledge Engineering, Xi’an
Jiaotong University
Xi’an, China
dong.bo@xjtu.edu.cnBin Shi
School of Computer Science and Technology & Ministry of
Education Key Lab For Intelligent Networks and Network
Security, Xi’an Jiaotong University
Xi’an, China
shibin@xjtu.edu.cn
ABSTRACT
In label-noise learning, accurately identifying the transition ma-
trix is crucial for developing statistically consistent classifiers. This
task is complicated by instance-dependent noise, which introduces
identifiability challenges in the absence of stringent assumptions.
Existing methods use neural networks to estimate the transition
matrix by initially extracting confident clean instances. However,
this extraction process is hindered by severe inter-class imbalance
and a bias toward selecting unambiguous intra-class instances,
leading to a distorted understanding of noise patterns. To tackle
these challenges, our paper introduces a Class Rebalance and Geo-
metric Regularization-based Framework (CRGR). CRGR employs
a smoothed, noise-tolerant reweighting mechanism to equilibrate
inter-class representation, thereby mitigating the risk of model over-
fitting to dominant classes. Additionally, recognizing that instances
with similar characteristics often exhibit parallel noise patterns, we
propose that the transition matrix should mirror the similarity of
the feature space. This insight promotes the inclusion of ambiguous
instances in training, serving as a form of geometric regularization.
Such a strategy enhances the model’s ability to navigate diverse
noise patterns and strengthens its generalization capabilities. By ad-
dressing both inter-class and intra-class biases, CRGR offers a more
balanced and robust classification model. Extensive experiments on
both synthetic and real-world datasets demonstrate CRGR’s superi-
ority over existing state-of-the-art methods, significantly boosting
∗Both authors contributed equally to this research.
†Corresponding Author
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
KDD ’24, August 25–29, 2024, Barcelona, Spain
©2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 979-8-4007-0490-1/24/08
https://doi.org/10.1145/3637528.3671707classification accuracy and showcasing its effectiveness in handling
instance-dependent noise.
CCS CONCEPTS
•Computing methodologies →Machine learning.
KEYWORDS
Instance-dependent label noise, Class rebalance, Geometric regu-
larization, Confident clean instance
ACM Reference Format:
Shuzhi Cao, Jianfei Ruan, Bo Dong, and Bin Shi. 2024. Tackling Instance-
Dependent Label Noise with Class Rebalance and Geometric Regularization.
InProceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery
and Data Mining (KDD ’24), August 25–29, 2024, Barcelona, Spain. ACM, New
York, NY, USA, 11 pages. https://doi.org/10.1145/3637528.3671707
1 INTRODUCTION
Deep learning methods have excelled in various computer vision
tasks, such as image classification [ 25,34] and object detection
[12,27,47], among others. Despite their success, these methods
heavily rely on extensive, fully labeled datasets, which are costly
to obtain due to the required expertise for accurate labeling. A
common workaround involves sourcing large-scale training data via
mobile crowdsourcing [ 16,42] or online queries [ 3]. Nonetheless,
these techniques tend to introduce label noise into the datasets
[7,43], which can significantly impair the generalization capabilities
of deep learning models. The susceptibility of these models to noisy
data, due to their complex architectures and strong fitting abilities,
highlights the importance of developing robust algorithms that can
effectively handle label noise.
Recent methods for addressing label noise can be categorized
into heuristic approaches [ 19,20,24,33,36,37,45] and statistically
consistent algorithms [ 6,7,39,40,43,44]. Heuristic approaches,
based on empirical techniques like selecting presumably clean data
[14,19,20,36,37,45], label correction [ 22,31,33], or integrating
extra regularization constraints [ 24,32], may offer practical efficacy.
However, these methods lack theoretical guarantees and may not
 
211
KDD ’24, August 25–29, 2024, Barcelona, Spain Shuzhi Cao, Jianfei Ruan, Bo Dong, and Bin Shi
/uni0000001b /uni00000017 /uni00000019 /uni0000001c /uni00000016 /uni00000015 /uni00000018 /uni00000013 /uni00000014 /uni0000001a
/uni00000026/uni0000004f/uni00000044/uni00000056/uni00000056/uni00000003/uni0000002c/uni00000051/uni00000047/uni00000048/uni0000005b/uni00000013/uni00000014/uni00000013/uni00000013/uni00000013/uni00000015/uni00000013/uni00000013/uni00000013/uni00000016/uni00000013/uni00000013/uni00000013/uni00000017/uni00000013/uni00000013/uni00000013/uni00000018/uni00000013/uni00000013/uni00000013/uni00000031/uni00000058/uni00000050/uni00000045/uni00000048/uni00000055/uni00000003/uni00000052/uni00000049/uni00000003/uni0000002c/uni00000051/uni00000056/uni00000057/uni00000044/uni00000051/uni00000046/uni00000048/uni00000026/uni00000052/uni00000051/uni00000049/uni0000004c/uni00000047/uni00000048/uni00000051/uni00000057/uni00000003/uni00000026/uni0000004f/uni00000048/uni00000044/uni00000051/uni00000003/uni0000002c/uni00000051/uni00000056/uni00000057/uni00000044/uni00000051/uni00000046/uni00000048 /uni00000024/uni00000050/uni00000045/uni0000004c/uni0000004a/uni00000058/uni00000052/uni00000058/uni00000056/uni00000003/uni0000002c/uni00000051/uni00000056/uni00000057/uni00000044/uni00000051/uni00000046/uni00000048
(a)
/uni00000024/uni00000050/uni00000045/uni0000004c/uni0000004a/uni00000058/uni00000052/uni00000058/uni00000056/uni00000003/uni0000002c/uni00000051/uni00000056/uni00000057/uni00000044/uni00000051/uni00000046/uni00000048 /uni00000026/uni00000052/uni00000051/uni00000049/uni0000004c/uni00000047/uni00000048/uni00000051/uni00000057/uni00000003/uni00000026/uni0000004f/uni00000048/uni00000044/uni00000051/uni00000003/uni0000002c/uni00000051/uni00000056/uni00000057/uni00000044/uni00000051/uni00000046/uni00000048 (b)
Figure 1: (a) exhibits the imbalanced inter-class distribution
of confident clean instances in CIFAR-10. (b) visualizes the
distributions of the confident clean and ambiguous instances
to show the intra-class selection bias problem by using the
T-SNE technique.
converge to an optimal classifier [ 26,40]. Conversely, statistically
consistent algorithms aim to model label noise directly, estimating
a transition matrix 𝑇(𝒙)∈R𝑐×𝑐, where𝑐represents the number of
classes, and𝑇𝑖𝑗(𝒙)=𝑃(¯𝑌=𝑗|𝑌=𝑖,𝑋=𝒙)represents the probabil-
ity of an instance with true label 𝑖being mislabeled as noisy label
𝑗, given its features 𝒙. This matrix allows for the inference of clean
class posterior probabilities from noisy ones, thereby constructing
a consistent classifier.
To simplify the form of 𝑇(𝒙), some researchers present class-
conditional noise (CCN) model [ 26,40,44], which assumes a con-
stant mislabeling probability across instances within a class, i.e.,
𝑃(¯𝑌=𝑗|𝑌=𝑖,𝑋=𝒙)=𝑃(¯𝑌=𝑗|𝑌=𝑖). However, this label noise
model does not take into account the impact of instance features on
noisy labels, making it difficult to describe real-world noise patterns.
To mitigate this issue, instance-dependent noise (IDN) [ 5,6,39,43]
is proposed, which accounts for variability in mislabeling probabil-
ities among instances, even within the same class, based on their
true class and specific features. This paper primarily focuses on
IDN due to its broader practical relevance and realism.
Estimating𝑇(𝒙)under IDN conditions is challenging due to its
reliance on instance-specific features, leading to a wide array of
potential matrix configurations. Unlike CCN, IDN lacks the conve-
nience of using anchor points [ 30,40] for fixed matrix estimation.
Researchers have tried to circumvent this complexity by introduc-
ing restrictive assumptions like part-dependent noise [ 39], confi-
dence scores [ 2], or noise bounds [ 9], but these solutions often com-
promise practical utility. To mitigate reliance on such assumptions,
recent advancements [ 6,43] employ neural networks to adaptively
fit transition matrix 𝑇(𝒙), using a subset of confident clean instances
as a learning foundation without extra assumptions. Methods such
as distillation [ 9], early-stop strategies [ 1], and small-loss-based
techniques [ 14] have been used to gather these instances. How-
ever, these methods tend to select clear-cut instances from easily
identifiable categories [ 20,37], leading to two main challenges: (1)
Inter-class imbalance: As Figure 1a shows, there exists a signif-
icant disparity in the number of confident clean instances across
classes, causing model overfitting to overrepresented classes. (2)
Intra-class selection bias: Figure 1b illustrates the selection ofeasily identifiable instances as confident clean ones, ignoring am-
biguous instances near the decision boundaries. This leads to an
inadequate representation of complex noise generation patterns.
These issues pose challenges to current state-of-the-art approaches
[6,43] that utilize neural networks to fit 𝑇(𝒙), as they directly train
the neural network on such biased extracted instances, leading to a
skewed classifier.
To tackle these issues, we propose a novel label noise learn-
ing method, CRGR. Our first solution targets the imbalance in
the inter-class distribution of extracted instances. We propose a
smoothed noise-tolerant reweighting strategy that equalizes the
neural network’s exposure to noise generation patterns across dif-
ferent classes. The second solution draws inspiration from psy-
chological and physiological studies [ 10,28], which suggest that
instances sharing similar features are more likely to be mislabeled
into the same class and vice versa. This observation guides us to
posit that𝑇(𝒙)should mirror the similarity of the feature space, en-
suring that the similarity relation between instances in the feature
space aligns consistently with those in the transition matrix space.
This insight leads us to further include ambiguous instances in the
training process as geometric regularization, aiding the network in
grasping complex noise dynamics. In summary, CRGR refines the
neural network’s training and enhances its capacity to depict noise
patterns, leading to a more equitable and robust classifier. The main
contributions are shown as follows:
•We propose a novel label noise learning method, CRGR,
which enhances the neural network’s capacity to depict com-
prehensive noise patterns by solving both the inter-class
imbalance and intra-class selection bias problems among the
extracted confident clean instances, ultimately resulting in a
more equitable and robust classifier.
•In this paper, we first propose a novel smoothed noise-tolerant
reweighting strategy that equalizes the network’s exposure
to noise patterns in each class to balance inter-class rep-
resentation. Subsequently, recognizing that instances with
similar features often exhibit parallel noise patterns, we pro-
pose that the transition matrix should mirror the similarity
of the feature space. This insight guides us to leverage the
characteristic information of ambiguous instances and incor-
porate them into training as geometric regularization. These
two enhancements improve the model’s ability to depict
complex noise patterns, eliminating both the inter-class and
intra-class fitting bias.
•Extensive experiments on both synthetic and real-world
datasets demonstrate that CRGR outperforms existing state-
of-the-art methods in handling IDN.
The remainder of the paper is organized as follows: Section 2
reviews related work. Section 3 describes preliminary concepts and
notations. Section 4 details the proposed method. Section 5 presents
experimental results. Finally, Section 6 concludes the paper.
2 RELATED WORK
In this section, we provide a concise overview of the relevant liter-
ature pertaining to label noise models and learning with IDN.
Label noise models. The label noise model depicts the genera-
tion of noisy labels. In general, label noise models are commonly
 
212Tackling Instance-Dependent Label Noise with Class Rebalance and Geometric Regularization KDD ’24, August 25–29, 2024, Barcelona, Spain
categorized into class-conditional noise (CCN) [ 7,26,30,40,44]
and instance-dependent noise (IDN) [ 5,6,9,39,43]. CCN consid-
ers that an instance’s noisy label is exclusively related to its true
class. Specifically, CCN ignores the effect of instance features on
noisy labels and assumes that all instances in the same class share
the same noise generation patterns. As a result, all the instances
belonging to the same class have a fixed probability of being misla-
beled as another class. In contrast, IDN considers the probability of
mislabeling to vary among instances, even within the same class,
depending on their true class and specific features. Comparatively,
IDN is more realistic [ 5,39] since humans always assign labels to
instances based on their unique features. For example, during the
annotation process, fuzzy photos with less information are more
likely to be mislabeled. Despite the realism of the IDN model, learn-
ing with IDN is formidable since the transition matrix 𝑇(𝒙), which
plays an essential role in building statistically consistent classifiers,
is unidentifiable under IDN without extra assumptions.
Learning with IDN. Existing IDN-based label noise learning
methods can be classified into two categories: heuristic approaches
[14,20,22,31,36,37,45] and statistically consistent algorithms
[6,7,30,39,40,43,44]. Heuristic approaches utilize empirical tech-
niques, such as selecting presumably clean data [ 14,19,20,36,37,
45], label correction [ 22,33], or adding extra regularization con-
straints [ 24,32] to mitigate the adverse effects of label noise. While
these approaches may empirically work well, their performance
ceiling remains limited as they lack theoretical guarantees and may
not converge to the ideal classifier that would result from using
accurately labeled data. Driven by this concern, the development
of statistically consistent algorithms has emerged, aiming to build
consistent classifiers. In this pursuit, the estimation of the transition
matrix𝑇(𝒙)plays a crucial role. Under IDN, 𝑇(𝒙)is unidentifiable
without extra constraints, hence, to uniquely ascertain the 𝑇(𝒙),
several extra assumptions have been proposed. For instance, [ 39]
hypothesizes that the noise of an instance depends only on its parts;
[2] necessitates additional confident scores, and [ 9] studies a spe-
cial case of IDN where the noise rate has an upper bound. While
these methods partially address the matrix estimation problem,
their practical application is impeded by the heavy dependence on
assumptions. To eliminate these assumptions, recent advancements
like [ 6,43] employ extra neural networks to adaptively fit 𝑇(𝒙).
These approaches leverage a subset of confident clean instances as
a foundation for learning noise patterns without extra presupposi-
tions, enhancing their applicability and performance. Despite these
advantages, these approaches encounter two significant challenges.
First, the imbalanced inter-class distributions of extracted instances
lead the neural network to overfit classes with more instances and
overlook others. Second, current methods tend to select clean-cut
intra-class instances as extracted instances and neglect ambiguous
instances. This selection bias poses a challenge for the network to
learn intricate noise patterns, leading to a skewed classifier. As a re-
sult, how to effectively handle IDN remains a challenging problem.
3 PRELIMINARIES
In this section, we first present the definition of label noise learning,
followed by systematic formulations of the transition matrix and
confident clean instances.Problem setting. Let𝐷be the distribution of a pair of random
variables(𝑋,𝑌)∈X×Y , where𝑋denotes the random variable of
instances and 𝑌is the corresponding clean labels. Moreover, X∈R𝑑
is defined as the feature space, and Y={1,2,...,𝑐}is the label
space, where 𝑑and𝑐stand for the dimension of the feature space
and the number of classes, respectively. In the task of classification,
given an instance 𝒙∈X, our goal is to predict its true label 𝑦∈Y.
However, in real-world scenarios, collecting large-scale training
data through crowdsourcing or online queries inevitably introduces
label noise. Therefore, we define ¯𝐷as the distribution of noisy
instances(𝑋,¯𝑌)∈X× ¯Y, where ¯𝑌denotes the variable of noisy
labels. In IDN, only a noisy training dataset ¯D={𝒙𝑖,¯𝑦𝑖}𝑛
𝑖=1with
𝑛instances that independently drawn from the distribution ¯𝐷are
available.
Transition matrix. The transition matrix 𝑇(𝒙)∈T depicts
the generation of the noisy label of instance 𝒙, whereT∈R𝑐×𝑐
stands for the transition matrix space, and the 𝑖𝑗-th entry of the
matrix, i.e., 𝑇𝑖𝑗(𝒙)=𝑃(¯𝑌=𝑗|𝑌=𝑖,𝑋=𝒙), represents the prob-
ability that an instance 𝒙belongs to the true class 𝑌=𝑖and is
mislabeled as the noisy class ¯𝑌=𝑗. In fact, the clean class pos-
terior𝑃(𝑌|𝒙)=[𝑃(𝑌=1|𝑋=𝒙),...,𝑃(𝑌=𝑐|𝑋=𝒙)]⊤can be
inferred from the noisy class posterior 𝑃(¯𝑌|𝒙)=[𝑃((¯𝑌=1|𝑋=
𝒙),...,𝑃((¯𝑌=𝑐|𝑋=𝒙)]⊤and the transition matrix 𝑇(𝒙), i.e.,
𝑃(¯𝑌|𝒙)=𝑇(𝒙)𝑃(𝑌|𝒙). By learning with noisy instances, the noisy
class posterior 𝑃(¯𝑌|𝒙)can be directly estimated. As a result, once
𝑇(𝒙)is identified, constructing statistically consistent classifiers
becomes a straightforward task. Nevertheless, 𝑇(𝒙)is unidentifi-
able under IDN without extra assumptions, making it a non-trivial
task to construct the statistically consistent classifier.
Confident clean instances. Clean instances are indispensable
for training the transition network 𝑇(𝒙;𝜃)that fits the transition
matrix𝑇(𝒙). However, in real-world scenarios, obtaining even a
small number of clean instances can be a difficult task. When clean
data is unavailable, it is necessary to automatically extract a sub-
set of instances with confident true labels, i.e., confident clean
instances, from the noisy data. Current off-the-shelf extraction ap-
proaches include techniques like the distillation method [ 9,43],
sample sieve approach [ 8], small-loss based methods [ 14,45], and
early-stop strategies [ 1,18,38]. In this paper, we directly employ
the distillation method [ 9] to extract the confident clean instances.
4 METHOD
This section provides an in-depth examination of CRGR, which
enhances the neural network’s capacity to depict noise patterns
by addressing both inter-class imbalance and intra-class selection
bias issues among the extracted instances, leading to a more equi-
table and robust classifier. Specifically, we first extract a subset of
confident clean instances as training instances (Section 4.1). Sec-
ondly, we propose a novel smoothed noise-tolerant reweighting
technique (Section 4.2) to calibrate the imbalanced inter-class dis-
tribution of the extracted instances. Subsequently, by maintaining
the consistency of similarity relations between instances in the
feature space and those in the transition matrix space, we include
the ambiguous instances in the training framework as a geometric
regularization, which assists the transition network in simulating
the complex noise generation patterns (Section 4.3). Finally, with
 
213KDD ’24, August 25–29, 2024, Barcelona, Spain Shuzhi Cao, Jianfei Ruan, Bo Dong, and Bin Shi
the well-trained transition network, we employ the F-Correction
[30] paradigm to obtain a consistent classifier (Section 4.4).
4.1 Confident Clean Instance Extraction
Confident clean instances, defined as instances with clean labels,
are indispensable for transition network training. However, in real-
world scenarios, acquiring even a small number of clean instances
is challenging. Motivated by this fact, some empirical techniques
[1,9,18,38] have attempted to extract clean instances from noisy
data automatically. In this paper, we employ an off-the-shelf distil-
lation method [ 9] to extract a subset of confident clean instances
D𝑐𝑙𝑒𝑎𝑛 =
𝒙𝒊,¯𝑦𝑖,𝑦∗
𝑖	𝑛𝑐
𝑖=1, where𝑦∗represents the estimated la-
tent clean label, and 𝑛𝑐denotes the number of extracted instances.
Specifically, for each instance 𝒙in the noisy training data ¯D, we
first calculate its corresponding noisy class posterior 𝑃(¯𝑌|𝒙)=
[𝑃(¯𝑌=1|𝑋=𝒙),...,𝑃(¯𝑌=𝑐|𝑋=𝒙)]⊤and then select the in-
stances that satisfies 𝑚𝑎𝑥
𝑃(¯𝑌|𝒙)	
>1+𝜌𝑚𝑎𝑥
2as confident clean
instances, while considering the remaining instances as ambiguous
instances, where 𝜌𝑚𝑎𝑥 is a pre-defined threshold. Simultaneously,
𝑦∗=argmax¯𝑦∈{1,2,...,𝑐}𝑃(¯𝑌=¯𝑦|𝒙)is taken as the estimated latent
clean label. According to the above criteria, the original noisy train-
ing data ¯Dis divided into confident clean instances D𝑐𝑙𝑒𝑎𝑛 and
ambiguous instances D𝑎𝑚𝑏𝑖𝑔 , i.e., ¯D=D𝑐𝑙𝑒𝑎𝑛∪D𝑎𝑚𝑏𝑖𝑔 . With the
extracted confident clean instances, we can train the transition net-
work𝑇(𝒙;𝜃). Specifically, the transition network is optimized by
minimizing the empirical risk on the inferred noisy label 𝒚∗·𝑇(𝒙;𝜃)
and its ground-truth noisy label ¯𝒚. The empirical risk is formulated
as follows:
R(𝜃)=−1
𝑛𝑐𝑛𝑐∑︁
𝑖=1¯𝒚𝒊log(𝒚∗
𝒊·𝑇(𝒙𝒊;𝜃)), (1)
where ¯𝒚𝒊∈R1×𝑐and𝒚∗
𝒊∈R1×𝑐denotes the noisy label ¯𝑦𝑖and the
clean label𝑦∗
𝑖in one-hot vector form, respectively.
4.2 Class Rebalance
Despite the fact that the transition network 𝑇(𝒙;𝜃)can be trained
by minimizing the risk formulated by Eq.(1), there remains a signif-
icant problem with this direct optimization approach. Specifically,
considering the severely imbalanced inter-class distribution of the
extracted confident clean instances, directly minimizing the risk in
Eq.(1) inevitably leads the neural network to overfit the classes with
more instances and overlook others. As a consequence, the transi-
tion network develops a skewed understanding of noise generation
patterns, and thus its generalization ability is greatly degraded.
To tackle this issue, we propose a novel smoothed noise-tolerant
reweighting technique to calibrate the imbalanced inter-class dis-
tribution. By assigning different weights to different instances, we
transform the empirical risk in Eq.(1) into a cost-sensitive risk
[11, 13], which is illustrated as follows:
R𝑤𝑒𝑖𝑔ℎ𝑡𝑒𝑑(𝜃)=−1
𝑛𝑐𝑛𝑐∑︁
𝑖=1𝑤(𝒙𝒊)¯𝒚𝒊log (𝒚∗
𝒊·𝑇(𝒙𝒊;𝜃),(2)
where𝑤(𝒙)represents the weight corresponding to the instance 𝒙.
In general, greater weight should be given to the class with fewer ex-
tracted instances to equalize the imbalanced inter-class distribution.
However, under IDN, the estimated latent clean label 𝑦∗may not beconsistent with its clean label. As a result, directly using the inverse
class frequency [ 17,35] to weight instances may lead the transition
network to erroneously concentrate on misestimated labels. To
mitigate this issue, we use the clean class posterior 𝑃(𝑌=𝑦∗|𝒙)to
evaluate the confidence degree of the estimated latent clean label
𝑦∗and assign different weights to various instances based on their
label confidence. Based on this criterion, we determine the weight
𝑤(𝑥)as follows:
𝑤(𝒙)= 
𝑛𝑐Í𝑛𝑐
𝑖=11[𝑦∗
𝑖=𝑦∗],if𝑃(𝑌=𝑦∗|𝒙)≥𝑤𝑚𝑎𝑥,
√︃𝑛𝑐Í𝑛𝑐
𝑖=11[𝑦∗
𝑖=𝑦∗],if𝑃(𝑌=𝑦∗|𝒙)<𝑤𝑚𝑎𝑥,(3)
where 1[·]is the indicator function, and 𝑤𝑚𝑎𝑥 is a self-adaptive
coefficient, which is defined as follows:
𝑤𝑚𝑎𝑥=1
𝑛𝑐𝑛𝑐∑︁
𝑖=1𝑃(𝑌=𝑦∗
𝑖|𝑋=𝒙𝒊), (4)
As previously demonstrated, we directly employ the inverse class
frequency to weight the instances whose clean class posterior ex-
ceeds the threshold 𝑤𝑚𝑎𝑥. In the case of instances whose clean
class posterior is less than the threshold, we utilize the smoothed
form of the inverse square root of the class frequency to weight
these instances to prevent the latent overfitting problem. Hence, by
optimizing the weighted risk in Eq.(2), we equalize the transition
network’s exposure to noise generation patterns in each class to
overcome the overfitting problem, leading to class rebalance.
4.3 Geometric Regularization
Existing approaches tend to extract easily identifiable instances
within each class as confident clean instances and neglect ambigu-
ous instances lying around the decision boundary. Consequently,
the transition network is unable to capture the intricate noise pat-
terns since it does not encounter any ambiguous instances dur-
ing the training process. To tackle this issue, we consider leverag-
ing the information of ambiguous instances D𝑎𝑚𝑏𝑖𝑔 to guide the
network training. Specifically, inspired by the evidence [ 10,28]
that instances with similar characteristics often exhibit parallel
noise patterns, we propose that the transition matrix 𝑇(𝒙)should
mirror the similarity of the feature space, i.e., keeping the simi-
larity relation between instances in the feature space consistent
with those in the transition matrix space. This insight leads to
the inclusion of ambiguous instances in training as the geometric
regularization. Specifically, we use 𝑑X(𝒙𝒊,𝒙𝒋)=||𝒙𝒊−𝒙𝒋||2and
𝑑T(𝑇(𝒙𝒊),𝑇(𝒙𝒋))=||𝑇(𝒙𝒊)−𝑇(𝒙𝒋)||2to measure the similarity
between the instances 𝒙𝒊and𝒙𝒋in feature and transition matrix
spaces, respectively, where ||·|| 2represents the ℓ2norm of a vector.
Following the property that 𝑇(𝒙)should mirror the similarity of
the feature space, we claim that the distance between instances in
the feature and transition matrix space should be proportional and
thus have the following relationship:
𝑑X(𝒙𝒊,𝒙𝒋)=𝜅·𝑑T(𝑇(𝒙𝒊),𝑇(𝒙𝒋)), (5)
where𝜅∈Ris a constant scaling factor, XandTdenote the fea-
ture and transition matrix spaces, respectively. Considering com-
putational efficiency, we only calculate the distance between the
 
214Tackling Instance-Dependent Label Noise with Class Rebalance and Geometric Regularization KDD ’24, August 25–29, 2024, Barcelona, Spain
instance 𝒙and the center of each class to measure its global similar-
ity relations. Specifically, let 𝜇𝑖(𝑖∈{1,...,𝑐})denotes the center
of class𝑖, which can be estimated using confident clean instances
as follows:
𝜇𝑖=Í
(𝒙𝒋,𝑦∗
𝑗)∈D 𝑐𝑙𝑒𝑎𝑛𝒙𝒋· 1(𝑦∗
𝑗=𝑖)
Í
(𝒙𝒋,𝑦∗
𝑗)∈D 𝑐𝑙𝑒𝑎𝑛1(𝑦∗
𝑗=𝑖). (6)
We define vectors 𝑆X(𝒙)=[𝑑X(𝒙,𝝁1),...,𝑑X(𝒙,𝝁𝒄)]and𝑆T(𝒙)=
[𝑑T(𝑇(𝒙),𝑇(𝝁1)),...,𝑑T(𝑇(𝒙),𝑇(𝝁𝒄))]to reflect global similarity
relations of 𝒙and use the transition network’s prediction 𝑇(𝒙;𝜃)to
approximate its ground truth. Following Eq.(5), 𝜅·𝑆T(𝒙)should be
consistent with 𝑆X(𝒙). To eliminate the effect of scale discrepancy,
we minimize the difference between the normalized 𝑆X(𝒙)and
𝑆T(𝒙), offering a geometric regularization as follows:
R𝑟𝑒𝑔𝑢𝑙𝑎𝑟(𝜃)=−1
𝑛𝑛∑︁
𝑖=1||𝑆X(𝒙𝒊)
||𝑆X(𝒙𝒊)||2−𝑆T(𝒙𝒊)
||𝑆T(𝒙𝒊)||2||2. (7)
Finally, the overall objective function can be expressed as Eq.(8),
where𝛼is the hyperparameter to balance R𝑤𝑒𝑖𝑔ℎ𝑡𝑒𝑑 andR𝑟𝑒𝑔𝑢𝑙𝑎𝑟 .
min
𝜃L(𝜃)=R𝑤𝑒𝑖𝑔ℎ𝑡𝑒𝑑(𝜃)+𝛼R𝑟𝑒𝑔𝑢𝑙𝑎𝑟(𝜃). (8)
By minimizing the overall objective function mentioned above,
the parameter 𝜃of the transition network 𝑇(𝑥)can be learned.
4.4 Classifier Training
By optimizing the overall objective function in Eq.(8), the transi-
tion network 𝑇(𝒙;𝜃)is well trained. Our ultimate goal is to ob-
tain a classifier 𝑓(𝒙;𝜔)parameterized by 𝜔that can predict the
clean class posterior of the input instance 𝒙, i.e.,𝑃(𝑌|𝒙)=𝑓(𝒙;𝜔).
Specifically, the noisy class posterior 𝑃(¯𝑌|𝒙)can be inferred as
𝑃(¯𝑌|𝒙)=𝑇(𝒙)𝑃(𝑌|𝒙). Here, we approximate 𝑇(𝒙)and𝑃(𝑌|𝒙)by
using𝑇(𝒙;𝜃)and𝑓(𝒙;𝜔), respectively, where 𝜃is a fixed param-
eter and𝜔is a trainable parameter. Furthermore, we use them to
approximate 𝑃(¯𝑌|𝒙)and calculate the cross-entropy loss between
the inferred noisy class posterior and the given noisy label to learn
the parameter 𝜔of the classifier 𝑓(𝒙;𝜔)as follows:
min𝜔R(𝜔)=−1
𝑛𝑛∑︁
𝑖=1¯𝒚𝒊log(𝑓(𝒙𝒊;𝜔)·𝑇(𝒙𝒊;𝜃)), (9)
In conclusion, the details of CRGR are summarized in Algorithm 1
with a visual representation shown in Figure 2.
5 EXPERIMENTS
In this section, we conduct comprehensive experiments on both syn-
thetic and real-world instance-dependent noisy datasets to verify
the effectiveness and superiority of the proposed CRGR method.
5.1 Experiment Setup
Datasets We conduct extensive experiments on synthetic noisy
datasets, namely SVHN, CIFAR-10 andCIFAR-100, as well as on a
real-world noisy dataset Clothing-1M, to verify the effectiveness
of the proposed CRGR method. SVHN consists of 10 classes of
images with 73,257 training instances and 26,032 test instances of
varying sizes. CIFAR-10 andCIFAR-100 contain 10 and 100 classes
respectively, and both datasets have 50k training images and 10k
test images of size 32×32. As for the real-world dataset, Clothing-1MAlgorithm 1 CRGR
Input: Noisy training dataset ¯D={𝒙𝒊,¯𝑦𝑖}𝑛
𝑖=1
1:Warm up the classifier 𝑓(𝒙;𝜔)with an early-stop strategy and
divide ¯Dinto confident clean instances D𝑐𝑙𝑒𝑎𝑛 and ambiguous
instancesD𝑎𝑚𝑏𝑖𝑔 .
2:while𝑒𝑝𝑜𝑐ℎ≤𝑀𝑎𝑥 -𝐸𝑝𝑜𝑐ℎ do
3: Calculate the riskR𝑤𝑒𝑖𝑔ℎ𝑡𝑒𝑑(𝜃)shown in Eq.(2) and the risk
R𝑟𝑒𝑔𝑢𝑙𝑎𝑟(𝜃)shown in Eq.(7).
4: Minimize the overall objective function shown in Eq.(8) to
learn the parameter 𝜃of the transition network;
5:end while
6:Fix the learned 𝜃and optimize the classifier 𝑓(𝒙;𝜔)by mini-
mizing the risk shown in Eq.(9).
Output: The classifier 𝑓(𝒙;𝜔)
is a large-scale image dataset with 1M training images containing
noisy labels collected through crowdsourcing and online queries,
and 10k images with clean labels for testing.
Algorithm 2 Instance-dependent Label Noise Generation
Input: Clean instancesD={𝒙𝒊,𝑦𝑖}𝑛
𝑖=1; Noise rate 𝜏.
1:Sample instance flip rates 𝑞∈ R𝑛from the truncated normal
distributionN(𝜏,0.12,[0,1]);
2:Independently sample 𝑤1,𝑤2,...,𝑤𝑐from the standard normal
distributionN(0,12);
3:for𝑖=0to ndo
4:𝑝=𝒙𝒊×𝑤𝑦𝑖; // generate instance-dependent flip rates
5:𝑝𝑦𝑖=−∞; // control the diagonal entry of the instance-
dependent transition matrix
6:𝑝=𝑞𝑖×𝑠𝑜𝑓𝑡𝑚𝑎𝑥(𝑝); // make the sum of the off-diagonal
entries of the 𝑦𝑖-th row equal to 𝑞𝑖
7:𝑝𝑦𝑖=1−𝑞𝑖; // set the diagonal entry to be 1−𝑞𝑖
8: Randomly choose a label from the label space according to
probabilities 𝑝as the noisy label ¯𝑦𝑖;
9:end for
Output: Noisy instances ¯D={𝒙𝒊,¯𝑦𝑖}𝑛
𝑖=1
IDN generation In our experiments, we utilize the follow-
ing commonly used instance-dependent label noise generation ap-
proach (see Algorithm 2) to generate synthetic noisy datasets. To
be specific, given the clean instances D={𝒙𝒊,𝑦𝑖}𝑛
𝑖=1and noise
rate𝜏, we first sample instance flip rates (noise rates) 𝑞∈ R𝑛
from the truncated normal distribution N(𝜏,0.12,[0,1])for each
instance, where the average flip rate is set as 𝜏. Subsequently, we
independently sample parameters 𝑤1,𝑤2,...,𝑤𝑐from the standard
normal distribution N(0,12)for generating instance-dependent
label noise, where the dimensionality of each parameter is 𝑑×𝑐,
𝑑denotes the dimensionality of the instance and 𝑐stands for the
number of classes. With the sampled parameter 𝑤𝑖𝑖∈{1,2,...,𝑐},
we generate instance-dependent flip rates for all the instances that
belonging to the class 𝑌=𝑖. Specifically, for the instance 𝑥𝑖with
clean label𝑦𝑖, its noisy label is only related to the 𝑦𝑖-th row of the
transition matrix. We use vector 𝑝to represent the 𝑦𝑖-th row of the
transition matrix. To calculate 𝑝for each instance, in steps 4-7, we
first use parameter 𝑤𝑖and the feature 𝑥𝑖to initialize 𝑝=𝒙𝒊×𝑤𝑦𝑖,
 
215KDD ’24, August 25–29, 2024, Barcelona, Spain Shuzhi Cao, Jianfei Ruan, Bo Dong, and Bin Shi
Noisy Training Data
Dog
Wolf
…Distillation MethodSoftmaxBackbone Network
Transition Network
Geometric Regularization
Figure 2: The overview of CRGR.
Table 1: Means and standard deviations (percentage) of classification accuracy on CIFAR-10 with different label noise levels.
Method IDN-10% IDN-20% IDN-30% IDN-40% IDN-50%
CE 74.31±0.39 68.11±0.81 59.63±0.98 49.56±1.57 39.22±2.79
Co-teaching+ 73.95±0.98 70.25±1.27 64.36±1.49 47.11±2.31 39.26±2.98
JoCoR 76.21±0.47 73.56±0.51 68.21±0.49 53.69±3.21 43.22±4.09
T-Revision 77.72±0.31 75.31±0.43 73.51±0.55 57.92±1.02 50.10±2.76
CCR 74.47±0.19 68.47±0.32 65.46±0.29 56.07±0.89 48.05±1.49
VolMinNet 80.02±0.23 76.73±0.31 72.02±0.44 65.83±0.97 49.96±1.21
PTD 78.36±0.43 76.69±0.39 72.04±0.45 58.32±1.32 42.69±2.99
BLTM 80.01±0.34 79.58±0.23 73.17±1.02 64.78±1.92 56.49±3.69
MEIDTM 79.37±0.39 70.65±0.47 62.43±0.41 52.98±1.23 42.97±2.92
CRGR 81.51±0.57 80 .01±0.51 77 .01±1.75 68 .28±4.06 60 .86±3.18
and then we set the diagonal entry 𝑝𝑦𝑖=1−𝑞𝑖while making the
sum of the off-diagonal entries of 𝑦𝑖-th row equal to 𝑞𝑖. Finally,
according to the probabilities 𝑝, we randomly choose noisy labels
for all the instances to generate synthetic noisy datasets. For all
the experiments on synthetic datasets, we split the images into
the training set and validation set according to the ratio of 4:1 and
conducted five repeated experiments with different seeds to ensure
the experimental results are dependable.
Implementation details. We use ResNet-34 [ 15] as the back-
bone network for all the experiments on synthetic noisy datasets
and ResNet-50 [ 15] for the experiments on real-world noisy dataset
Clothing-1M. For the transition network, while maintaining the
overall architecture of the backbone network, we modify the last
linear layer to accommodate the specific shape of the transition
matrix. For all the experiments, we first use the early-stop strategy
[1,38] to warm up the backbone network for five epochs on the
noisy dataset and then extract confident clean instances with the
pre-defined threshold 𝜌𝑚𝑎𝑥=0.3. Subsequently, we use the SGD
[4] optimizer with a momentum of 0.9, a batch size of 128, and an
initial learning rate of 0.01 to train the transition network. Finally,
we fix the well-trained transition network to learn the parametersof the classification network. In this stage, the classification net-
work is trained using the Adam [ 21] optimizer with a weight decay
1×10−4, a batch size of 128, and a learning rate 5×10−7. For a fair
comparison, it is worth noting that we do not use any data aug-
mentation techniques in all the experiments. All the experiments
documented in this paper are executed using PyTorch [ 29] on two
GPUs (NVIDIA RTX 3090) functioning in parallel.
Comparison methods. To demonstrate the superiority of the
proposed CRGR method, we compare it with the following ap-
proaches: (1) CE, which trains the classifier directly on the noisy
dataset with the standard cross-entropy loss and is considered as
baseline; (2) Co-teaching+ [ 45], which simultaneously develops
two neural networks to select small-loss instances with prediction
disagreement for network training; (3) JoCoR [ 36], which adopts a
joint training method with co-regularization; (4) T-Revision [ 40],
which first initializes transition matrix by exploiting instances that
are similar to anchor points and then introducing a slack variable
to modify the initial estimator; (5) CCR [ 7], which estimates the
transition matrix under a forward-backward cycle-consistency reg-
ularization and constructs the classifier; (6) VolMinNet [ 26], which
solves label noise learning by optimizing the volume of the sim-
plex formed by the columns of the transition matrix; (7) PTD [ 39],
 
216Tackling Instance-Dependent Label Noise with Class Rebalance and Geometric Regularization KDD ’24, August 25–29, 2024, Barcelona, Spain
Table 2: Means and standard deviations (percentage) of classification accuracy on SVHN with different label noise levels.
Method IDN-10% IDN-20% IDN-30% IDN-40% IDN-50%
CE 90.27±0.41 89.69±0.53 85.99±0.97 65.24±1.69 48.76±4.12
Co-teaching+ 92.96±0.77 91.65±0.81 85.77±1.98 56.33±1.77 42.68±3.38
JoCoR 88.57±0.54 80.26±0.67 77.52±0.99 65.86±1.92 47.52±3.82
T-Revision 92.84±0.33 92.33±0.71 83.16±0.88 73.60±1.45 66.91±4.49
CCR 92.64±0.39 90.46±0.57 88.69±0.93 76.84±1.85 70.24±2.01
VolMinNet 93.89±0.21 93.23±0.53 78.37±0.49 69.21±0.99 56.91±3.09
PTD 94.71±0.57 94.33±0.66 91.11±0.89 90.32±1.44 53.65±4.32
BLTM 94.35±0.42 91.55±1.29 89.78±3.58 83.71±3.99 70.41±6.53
MEIDTM 91.74±0.65 85.52±0.72 79.71±1.64 66.22±3.12 60.76±4.22
CRGR 95.12±0.33 94 .59±0.88 93 .23±1.13 91 .35±1.99 77 .58±4.24
Table 3: Means and standard deviations (percentage) of classification accuracy on CIFAR-100 with different label noise levels.
IDN-10% IDN-20% IDN-30% IDN-40% IDN-50%
CE 46.45±0.29 41.51±0.55 38.71±1.76 30.01±0.98 27.81±1.86
Co-teaching+ 49.05±0.58 43.21±1.33 41.55±1.01 38.11±0.95 30.09±2.55
JoCoR 49.31±0.27 43.55±0.77 40.11±0.92 37.21±1.82 31.02±2.34
T-Revision 47.74±0.54 43.31±0.91 36.19±1.56 29.25±1.33 25.23±1.19
CCR 45.28±0.19 40.72±0.24 34.68±0,58 28.53±0.97 27.08±1.22
VolMinNet 49.17±0.32 47.02±0.27 43.11±0.94 38.62±1.41 29.88±1.88
PTD 44.77±0.49 41.39±0.68 36.77±1.97 30.59±1.37 26.87±2.26
BLTM 44.65±1.13 42.09±0.61 37.85±1.14 33.23±0.61 27.73±1.07
MEIDTM 45.21±0.99 41.14±0.51 34.55±1.78 29.58±1.99 26.25±2.06
CRGR 51.03±0.67 48 .94±0.27 44 .91±2.15 39 .76±1.68 32 .04±2.25
which approximates the IDN by exploiting part-dependent label
noise; (8) BLTM [ 43], which estimates the IDN transition matrix
using a deep neural network; (9) MEIDTM [ 6], which proposes a
manifold-regularized technique to facilitate the estimation of the
IDN transition matrix and finally construct a consistent classifier.
5.2 Experimental Results
In this subsection, We conclude the experimental results from the
following three aspects:
(1) How are the results on the synthetic noisy datasets?
Table 1, 2 and 3 demonstrate the classification accuracy on syn-
thetic noisy datasets CIFAR-10, SVHN, and CIFAR-100, respectively,
where the best classification results are emphasized in bold. These
results indicate that CRGR outperforms current state-of-the-art
methods in tackling IDN. Specifically, compared with the previous
approaches, CRGR outperforms the former by a margin of 4.37%,
7.17%, and 2.16% on the datasets CIFAR-10, SVHN, and CIFAR-100respectively. Additionally, as the noise rate increases, CRGR re-
veals its superiority, outperforming the second-best method by an
average margin of 1.21% and 4.19% under IDN-10% and IDN-50%,
exhibiting its robustness under the extreme noise rate.
(2) How are the results on the real-world dataset? To evalu-
ate the performance of CRGR in real-world scenarios, we conduct
experiments on the real-world noisy dataset Clothing-1M. The clas-
sification accuracy is exhibited in Table 4. The results show that
CRGR surpasses all comparison methods and achieves the best clas-
sification accuracy, demonstrating its effectiveness and superiority
in practical applications.
(3) How well are the inter-class imbalance and intra-class
selection bias problems solved? We conduct experiments on
the synthetic CIFAR-10 dataset with a 50% noise rate to evaluate
CRGR’s performance on different classes and instances. As shown
in Figure 4, compared with the base method, CRGR improves the
classification accuracy by 5.25% and 27.16% on the classes with the
most and the least extracted instances, respectively, reducing the
 
217KDD ’24, August 25–29, 2024, Barcelona, Spain Shuzhi Cao, Jianfei Ruan, Bo Dong, and Bin Shi
Table 4: Classification accuracy on the Clothing-1M dataset.
Methods CE Co-teaching+ JoCoR CCR T-Revision VolMinNet PTD BLTM MEIDTM CRGR
Accuracy(%) 68.64 66.37 70.39 71.85 70.82 72.38 71.53 73.09 73.57 74.29
/uni00000014/uni00000013/uni00000008 /uni00000015/uni00000013/uni00000008 /uni00000016/uni00000013/uni00000008 /uni00000017/uni00000013/uni00000008 /uni00000018/uni00000013/uni00000008
/uni00000031/uni00000052/uni0000004c/uni00000056/uni00000048/uni00000003/uni00000035/uni00000044/uni00000057/uni00000048/uni00000018/uni00000018/uni00000019/uni00000013/uni00000019/uni00000018/uni0000001a/uni00000013/uni0000001a/uni00000018/uni0000001b/uni00000013/uni00000037/uni00000048/uni00000056/uni00000057/uni00000003/uni00000024/uni00000046/uni00000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c/uni00000003/uni0000000b/uni00000008/uni0000000c
/uni00000026/uni00000035/uni0000002a/uni00000035
/uni0000005a/uni00000012/uni00000052/uni00000003/uni00000055/uni00000048
/uni0000005a/uni00000012/uni00000052/uni00000003/uni00000055/uni0000005a
/uni00000045/uni00000044/uni00000056/uni00000048
(a)
/uni00000014/uni00000013/uni00000008 /uni00000015/uni00000013/uni00000008 /uni00000016/uni00000013/uni00000008 /uni00000017/uni00000013/uni00000008 /uni00000018/uni00000013/uni00000008
/uni00000031/uni00000052/uni0000004c/uni00000056/uni00000048/uni00000003/uni00000035/uni00000044/uni00000057/uni00000048/uni00000019/uni00000018/uni0000001a/uni00000013/uni0000001a/uni00000018/uni0000001b/uni00000013/uni0000001b/uni00000018/uni0000001c/uni00000013/uni0000001c/uni00000018/uni00000037/uni00000048/uni00000056/uni00000057/uni00000003/uni00000024/uni00000046/uni00000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c/uni00000003/uni0000000b/uni00000008/uni0000000c
/uni00000026/uni00000035/uni0000002a/uni00000035
/uni0000005a/uni00000012/uni00000052/uni00000003/uni00000055/uni00000048
/uni0000005a/uni00000012/uni00000052/uni00000003/uni00000055/uni0000005a
/uni00000045/uni00000044/uni00000056/uni00000048 (b)
/uni00000014/uni00000013/uni00000008 /uni00000015/uni00000013/uni00000008 /uni00000016/uni00000013/uni00000008 /uni00000017/uni00000013/uni00000008 /uni00000018/uni00000013/uni00000008
/uni00000031/uni00000052/uni0000004c/uni00000056/uni00000048/uni00000003/uni00000035/uni00000044/uni00000057/uni00000048/uni00000016/uni00000013/uni00000016/uni00000018/uni00000017/uni00000013/uni00000017/uni00000018/uni00000018/uni00000013/uni00000037/uni00000048/uni00000056/uni00000057/uni00000003/uni00000024/uni00000046/uni00000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c/uni00000003/uni0000000b/uni00000008/uni0000000c
/uni00000026/uni00000035/uni0000002a/uni00000035
/uni0000005a/uni00000012/uni00000052/uni00000003/uni00000055/uni00000048
/uni0000005a/uni00000012/uni00000052/uni00000003/uni00000055/uni0000005a
/uni00000045/uni00000044/uni00000056/uni00000048 (c)
/uni00000013/uni00000011/uni00000013 /uni00000013/uni00000011/uni00000014 /uni00000013/uni00000011/uni00000015 /uni00000013/uni00000011/uni00000016 /uni00000013/uni00000011/uni00000017 /uni00000013/uni00000011/uni00000018
/uni00000017/uni00000018/uni00000018/uni00000013/uni00000018/uni00000018/uni00000019/uni00000013/uni00000019/uni00000018/uni0000001a/uni00000013/uni0000001a/uni00000018/uni0000001b/uni00000013/uni0000001b/uni00000018/uni00000037/uni00000048/uni00000056/uni00000057/uni00000003/uni00000024/uni00000046/uni00000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c/uni00000003/uni0000000b/uni00000008/uni0000000c
 /uni0000002c/uni00000027/uni00000031/uni00000010/uni00000014/uni00000013/uni00000008
/uni0000002c/uni00000027/uni00000031/uni00000010/uni00000015/uni00000013/uni00000008
/uni0000002c/uni00000027/uni00000031/uni00000010/uni00000016/uni00000013/uni00000008/uni0000002c/uni00000027/uni00000031/uni00000010/uni00000017/uni00000013/uni00000008
/uni0000002c/uni00000027/uni00000031/uni00000010/uni00000018/uni00000013/uni00000008 (d)
Figure 3: Illustration of the ablation study of each component and the hyper-parameter sensitivity. Figure 3a-3c demonstrate
the ablation studies on synthetic noisy datasets CIFAR-10, SVHN, and CIFAR-100 with different noise rates, respectively. Figure
3d illustrates the classification accuracy with various values of hyper-parameter 𝛼onCIFAR-10 noisy dataset with different
noise rates.
Majority Class Minority Class
Class02040Accuracy (%)
Confident Clean Instance Ambiguous Instance
Instance020406080Accuracy (%)base CRGR base CRGR
Figure 4: An illustration of classification accuracy on dif-
ferent classes and instances, where the base method repre-
sents the method that trains transition network on biased
extracted instances with cross-entropy loss. Majority and
minority classes denote the classes with the most and least
extracted instances, respectively.
gap between them. Analogously, CRGR improves the classification
accuracy on confident clean instances and ambiguous instances by
6.05% and 9.08%, respectively, narrowing the gap by 3.03%. These
results indicate that CRGR effectively mitigates both inter-class
and intra-class fitting bias, leading to a more equitable and robust
classifier.
5.3 Ablation Study
In this subsection, we first conduct ablation experiments to inves-
tigate the effect of reweighting technique and geometric regular-
ization on the proposed method. Then we discuss the selection of
hyperparameters 𝛼and𝜌𝑚𝑎𝑥.
Effect of reweighting technique and geometric regulariza-
tion. In this paper, we utilize a smoothed noise-tolerant reweightingtechnique to calibrate the inter-class imbalance and incorporate am-
biguous instances into the training framework by adding geometric
regularization. Ablation experiments are conducted to assess the in-
dividual contributions of the reweighting technique and geometric
regularization in enhancing the performance of the classifier. Specif-
ically, we use ’w/o rw’ and ’w/o re’ to indicate the approach that
does not apply the reweighting methodology and geometric reg-
ularization respectively. The method directly trains the transition
network on the biased extracted instances without any improve-
ments is used as the base method. We compare the classification
accuracy of different methods on synthetic datasets with different
noise rates, and the corresponding results are shown in Figure 3a
- 3c. The results show that either removing the reweighting tech-
nique (w/o rw) or geometric regularization (w/o re) degrades the
performance of the classifier. At the same time, the basic method
(base), which removes both of the above improvements, exhibits the
worst performance. These observations collectively demonstrate
the effectiveness of both the reweighting technique and geometric
regularization in constructing a more robust classifier.
The selection of hyperparameters 𝛼and𝜌𝑚𝑎𝑥.To investigate
the influence of the hyperparameter 𝛼on the proposed method,
we conduct experiments on the synthetic noisy dataset CIFAR-10
with various values of 𝛼under noise rates from 10% to 50%. The
corresponding results are shown in Figure 3d. The findings indicate
that the classification accuracy is not sensitive to 𝛼when the noise
rate is low, but it is sensitive when the noise rate is high. At the
same time, with the increase of 𝛼, the classification accuracy first
rises and then declines, achieving the best value when 𝛼is set as
0.3. Therefore, we set 𝛼=0.3in all the experiments.
Meanwhile, we use the distillation method in [ 6] to extract the
confident clean instances. According to [ 6], once𝜌𝑚𝑎𝑥 is selected
as the upper bound of the noise rate, the distilled confident clean
 
218Tackling Instance-Dependent Label Noise with Class Rebalance and Geometric Regularization KDD ’24, August 25–29, 2024, Barcelona, Spain
instances’ inferred latent clean labels are identical to the Bayes
optimal labels. Hence, the clean labels can be accurately identified.
However, when the noise rate is high, the number of distilled confi-
dent clean instances drops. Therefore, we should trade-off between
the number of distilled instances and distillation accuracy. [6] has
provided sufficient evidence that 𝜌𝑚𝑎𝑥=0.3is reasonable for distil-
lation. Specifically, they set the hyperparameter 𝜌𝑚𝑎𝑥 to 0.1, 0.2, 0.3,
0.4, 0.5, and 0.6, respectively, and calculate the instance-dependent
transition matrix approximation error under different thresholds on
the CIFAR-10 dataset with IDN-30% noise rate. When the threshold
𝜌𝑚𝑎𝑥 is set as 0.3, the error achieves the minimum value. Therefore,
following their conclusion, we set 𝜌𝑚𝑎𝑥=0.3in all the experiments
in this paper.
6 CONCLUSION AND LIMITATION
Conclusion. In this paper, we propose a novel label noise learning
framework called CRGR, which addresses both inter-class imbal-
ance and intra-class selection bias issues inherent in confident clean
instances, ultimately leading to a more equitable and robust clas-
sifier. Specifically, we introduce a novel smoothed, noise-tolerant
reweighting technique that equalizes the network’s exposure to
noise patterns across different classes, thereby calibrating the imbal-
anced inter-class distribution. Additionally, based on evidence that
similar instances tend to exhibit comparable noise patterns, we posit
that𝑇(𝒙)should mirror the similarity of the feature space. This
insight leads to the inclusion of ambiguous instances in training,
serving as geometric regularization. Such regularization aids the
model in overcoming intra-class selection bias and understanding
complex noise patterns. Extensive experiments on both synthetic
and real-world datasets demonstrate that CRGR outperforms cur-
rent state-of-the-art methods, showcasing its superiority.
Limitation. One major limitation of our study is that the use
of Euclidean distance to measure similarity relations between in-
stances in both feature and transition matrix spaces. However,
Euclidean distance may not be an ideal indicator, as the high-
dimensional space may be embedded in a manifold. In the future,
we will employ geodesic distance to measure the similarity between
instances, thereby more effectively grasping their underlying re-
lationships and contributing to the development of a more robust
classifier.
ACKNOWLEDGMENTS
This research was partially supported by the National Key Re-
search and Development Project of China No. 2021ZD0110700, the
Key Research and Development Project in Shaanxi Province No.
2022GXLH-01-03, and the National Science Foundation of China
under Grant Nos. 62037001 and 62250009.
REFERENCES
[1]Yingbin Bai, Erkun Yang, Bo Han, Yanhua Yang, Jiatong Li, Yinian Mao, Gang
Niu, and Tongliang Liu. 2021. Understanding and improving early stopping for
learning with noisy labels. Advances in Neural Information Processing Systems 34
(2021), 24392–24403.
[2]Antonin Berthon, Bo Han, Gang Niu, Tongliang Liu, and Masashi Sugiyama. 2021.
Confidence scores make instance-dependent label-noise learning possible. In
International conference on machine learning. PMLR, 825–836.
[3]Avrim Blum, Adam Kalai, and Hal Wasserman. 2003. Noise-tolerant learning,
the parity problem, and the statistical query model. Journal of the ACM (JACM)
50, 4 (2003), 506–519.[4]Léon Bottou. 2010. Large-scale machine learning with stochastic gradient descent.
InProceedings of COMPSTAT’2010: 19th International Conference on Computational
StatisticsParis France, August 22-27, 2010 Keynote, Invited and Contributed Papers.
Springer, 177–186.
[5]Pengfei Chen, Junjie Ye, Guangyong Chen, Jingwei Zhao, and Pheng-Ann Heng.
2021. Beyond class-conditional assumption: A primary attempt to combat
instance-dependent label noise. In Proceedings of the AAAI Conference on Artificial
Intelligence, Vol. 35. 11442–11450.
[6]De Cheng, Tongliang Liu, Yixiong Ning, Nannan Wang, Bo Han, Gang Niu, Xinbo
Gao, and Masashi Sugiyama. 2022. Instance-dependent label-noise learning with
manifold-regularized transition matrix estimation. In Proceedings of the IEEE/CVF
Conference on Computer Vision and Pattern Recognition. 16630–16639.
[7]De Cheng, Yixiong Ning, Nannan Wang, Xinbo Gao, Heng Yang, Yuxuan Du,
Bo Han, and Tongliang Liu. 2022. Class-Dependent Label-Noise Learning with
Cycle-Consistency Regularization. Advances in Neural Information Processing
Systems 35 (2022), 11104–11116.
[8]Hao Cheng, Zhaowei Zhu, Xingyu Li, Yifei Gong, Xing Sun, and Yang Liu. 2021.
Learning with Instance-Dependent Label Noise: A Sample Sieve Approach. In
International Conference on Learning Representations.
[9]Jiacheng Cheng, Tongliang Liu, Kotagiri Ramamohanarao, and Dacheng Tao. 2020.
Learning with bounded instance and label-dependent label noise. In International
conference on machine learning. PMLR, 1789–1799.
[10] Uri Cohen, SueYeon Chung, Daniel D Lee, and Haim Sompolinsky. 2020. Sep-
arability and geometry of object manifolds in deep neural networks. Nature
communications 11, 1 (2020), 746.
[11] Yin Cui, Menglin Jia, Tsung-Yi Lin, Yang Song, and Serge Belongie. 2019. Class-
balanced loss based on effective number of samples. In Proceedings of the IEEE/CVF
conference on computer vision and pattern recognition. 9268–9277.
[12] Tausif Diwan, G Anirudh, and Jitendra V Tembhurne. 2023. Object detection
using YOLO: Challenges, architectural successors, datasets and applications.
multimedia Tools and Applications 82, 6 (2023), 9243–9275.
[13] Charles Elkan. 2001. The foundations of cost-sensitive learning. In International
joint conference on artificial intelligence, Vol. 17. Lawrence Erlbaum Associates
Ltd, 973–978.
[14] Bo Han, Quanming Yao, Xingrui Yu, Gang Niu, Miao Xu, Weihua Hu, Ivor Tsang,
and Masashi Sugiyama. 2018. Co-teaching: Robust training of deep neural net-
works with extremely noisy labels. Advances in neural information processing
systems 31 (2018).
[15] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep residual
learning for image recognition. In Proceedings of the IEEE conference on computer
vision and pattern recognition. 770–778.
[16] Danula Hettiachchi, Vassilis Kostakos, and Jorge Goncalves. 2022. A survey on
task assignment in crowdsourcing. ACM Computing Surveys (CSUR) 55, 3 (2022),
1–35.
[17] Chen Huang, Yining Li, Chen Change Loy, and Xiaoou Tang. 2016. Learning deep
representation for imbalanced classification. In Proceedings of the IEEE conference
on computer vision and pattern recognition. 5375–5384.
[18] Huaxi Huang, Hui Kang, Sheng Liu, Olivier Salvado, Thierry Rakotoarivelo,
Dadong Wang, and Tongliang Liu. 2023. Paddles: Phase-amplitude spectrum
disentangled early stopping for learning with noisy labels. In Proceedings of the
IEEE/CVF International Conference on Computer Vision. 16719–16730.
[19] Lu Jiang, Zhengyuan Zhou, Thomas Leung, Li-Jia Li, and Li Fei-Fei. 2018. Mentor-
net: Learning data-driven curriculum for very deep neural networks on corrupted
labels. In International conference on machine learning. PMLR, 2304–2313.
[20] Nazmul Karim, Mamshad Nayeem Rizve, Nazanin Rahnavard, Ajmal Mian, and
Mubarak Shah. 2022. Unicon: Combating label noise through uniform selection
and contrastive learning. In Proceedings of the IEEE/CVF Conference on Computer
Vision and Pattern Recognition. 9676–9686.
[21] Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic opti-
mization. arXiv preprint arXiv:1412.6980 (2014).
[22] Jan Kremer, Fei Sha, and Christian Igel. 2018. Robust active label correction. In
International conference on artificial intelligence and statistics. PMLR, 308–316.
[23] Alex Krizhevsky and Geoffrey Hinton. 2009. Learning multiple layers of features
from tiny images. Technical Report. Citeseer.
[24] Mingchen Li, Mahdi Soltanolkotabi, and Samet Oymak. 2020. Gradient descent
with early stopping is provably robust to label noise for overparameterized neural
networks. In International conference on artificial intelligence and statistics. PMLR,
4313–4324.
[25] Shutao Li, Weiwei Song, Leyuan Fang, Yushi Chen, Pedram Ghamisi, and Jon Atli
Benediktsson. 2019. Deep learning for hyperspectral image classification: An
overview. IEEE Transactions on Geoscience and Remote Sensing 57, 9 (2019),
6690–6709.
[26] Xuefeng Li, Tongliang Liu, Bo Han, Gang Niu, and Masashi Sugiyama. 2021.
Provably end-to-end label-noise learning without anchor points. In International
conference on machine learning. PMLR, 6403–6413.
[27] Li Liu, Wanli Ouyang, Xiaogang Wang, Paul Fieguth, Jie Chen, Xinwang Liu, and
Matti Pietikäinen. 2020. Deep learning for generic object detection: A survey.
International journal of computer vision 128 (2020), 261–318.
 
219KDD ’24, August 25–29, 2024, Barcelona, Spain Shuzhi Cao, Jianfei Ruan, Bo Dong, and Bin Shi
[28] Stephen E Palmer. 1977. Hierarchical structure in perceptual representation.
Cognitive psychology 9, 4 (1977), 441–474.
[29] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory
Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al .2019.
Pytorch: An imperative style, high-performance deep learning library. Advances
in neural information processing systems 32 (2019).
[30] Giorgio Patrini, Alessandro Rozza, Aditya Krishna Menon, Richard Nock, and
Lizhen Qu. 2017. Making deep neural networks robust to label noise: A loss
correction approach. In Proceedings of the IEEE conference on computer vision and
pattern recognition. 1944–1952.
[31] Daiki Tanaka, Daiki Ikami, Toshihiko Yamasaki, and Kiyoharu Aizawa. 2018.
Joint optimization framework for learning with noisy labels. In Proceedings of
the IEEE conference on computer vision and pattern recognition. 5552–5560.
[32] Arash Vahdat. 2017. Toward robustness against label noise in training deep
discriminative neural networks. Advances in neural information processing systems
30 (2017).
[33] Kai Wang, Xiangyu Peng, Shuo Yang, Jianfei Yang, Zheng Zhu, Xinchao Wang,
and Yang You. 2022. Reliable label correction is a good booster when learning
with extremely noisy labels. arXiv preprint arXiv:2205.00186 (2022).
[34] Wei Wang, Yujing Yang, Xin Wang, Weizheng Wang, and Ji Li. 2019. Development
of convolutional neural network and its application in image classification: a
survey. Optical Engineering 58, 4 (2019), 040901–040901.
[35] Yu-Xiong Wang, Deva Ramanan, and Martial Hebert. 2017. Learning to model
the tail. Advances in neural information processing systems 30 (2017).
[36] Hongxin Wei, Lei Feng, Xiangyu Chen, and Bo An. 2020. Combating noisy labels
by agreement: A joint training method with co-regularization. In Proceedings of
the IEEE/CVF conference on computer vision and pattern recognition. 13726–13735.
[37] Qi Wei, Haoliang Sun, Xiankai Lu, and Yilong Yin. 2022. Self-filtering: A noise-
aware sample selection for label noise with confidence penalization. In European
Conference on Computer Vision. Springer, 516–532.
[38] Xiaobo Xia, Tongliang Liu, Bo Han, Chen Gong, Nannan Wang, Zongyuan Ge,
and Yi Chang. 2020. Robust early-learning: Hindering the memorization of noisy
labels. In International conference on learning representations.
[39] Xiaobo Xia, Tongliang Liu, Bo Han, Nannan Wang, Mingming Gong, Haifeng
Liu, Gang Niu, Dacheng Tao, and Masashi Sugiyama. 2020. Part-dependent label
noise: Towards instance-dependent label noise. Advances in Neural Information
Processing Systems 33 (2020), 7597–7610.
[40] Xiaobo Xia, Tongliang Liu, Nannan Wang, Bo Han, Chen Gong, Gang Niu, and
Masashi Sugiyama. 2019. Are anchor points really indispensable in label-noise
learning? Advances in neural information processing systems 32 (2019).
[41] Tong Xiao, Tian Xia, Yi Yang, Chang Huang, and Xiaogang Wang. 2015. Learning
from massive noisy labeled data for image classification. In Proceedings of the
IEEE conference on computer vision and pattern recognition. 2691–2699.
[42] Yan Yan, Rómer Rosales, Glenn Fung, Ramanathan Subramanian, and Jennifer
Dy. 2014. Learning from multiple annotators with varying expertise. Machine
learning 95 (2014), 291–327.
[43] Shuo Yang, Erkun Yang, Bo Han, Yang Liu, Min Xu, Gang Niu, and Tongliang
Liu. 2022. Estimating instance-dependent bayes-label transition matrix using a
deep neural network. In International Conference on Machine Learning. PMLR,
25302–25312.
[44] Yu Yao, Tongliang Liu, Bo Han, Mingming Gong, Jiankang Deng, Gang Niu, and
Masashi Sugiyama. 2020. Dual t: Reducing estimation error for transition matrix
in label-noise learning. Advances in neural information processing systems 33
(2020), 7260–7271.
[45] Xingrui Yu, Bo Han, Jiangchao Yao, Gang Niu, Ivor Tsang, and Masashi Sugiyama.
2019. How does disagreement help generalization against label corruption?. In
International Conference on Machine Learning. PMLR, 7164–7173.
[46] Netzer Yuval. 2011. Reading digits in natural images with unsupervised feature
learning. In Proceedings of the NIPS Workshop on Deep Learning and Unsupervised
Feature Learning.
[47] Zhong-Qiu Zhao, Peng Zheng, Shou-tao Xu, and Xindong Wu. 2019. Object
detection with deep learning: A review. IEEE transactions on neural networks and
learning systems 30, 11 (2019), 3212–3232.A APPENDIX
A.1 Details of Datasets
•SVHN [46]: The SVHN (Street View House Numbers) dataset
consists of a large collection of color digit images extracted
from Google Street View images. SVHN has 10 classes of
images in total, with 73,257 training instances and 26,032 test
instances of varying sizes.
•CIFAR-10 and CIFAR-100 [23]: Both the CIFAR-10 and CIFAR-
100 datasets were created by the Canadian Institute for Ad-
vanced Research, with images were collected from various
sources covering a wide range of object categories. The
CIFAR-10 and CIFAR-100 datasets each contain 60,000 R GB
images, divided into 50,000 training images and 10,000 test
images. Each image has a resolution of 32×32pixels. CIFAR-
10 consists of 10 object classes, including airplanes, automo-
biles, birds, cats, deer, dogs, frogs, horses, ships, and trucks.
On the other hand, CIFAR-100 contains 100 object classes,
covering a wider range of fine-grained categories, such as
different breeds of dogs, flowers, and household objects.
•Clothing-1M [41]: Clothing-1M is a large-scale RGB image
dataset with 1M training images with noisy labels and 10k im-
ages with clean labels for testing. Clothing-1M has 14 classes
in and all the training images are collected from online shop-
ping websites. Without expert annotation, the labels of the
training images are assigned automatically based on their
surrounding environment, leading to label noise. The clean
images are manually annotated to ensure their labels are
accurate for testing the classifier’s performance.
A.2 Experimental Results of Ablation Study
In the main text, we have conducted ablation experiments to il-
lustrate the contributions of both the reweighting technique and
geometric regularization in improving the classifier’s performance.
However, due to space limitations, we only provided illustrations
using figures. In this supplementary material, more detailed results,
including means and standard deviations of classification accuracy
from the ablation experiments on CIFAR-10, SVHN, and CIFAR-
100, are shown in Table 5, 6 and 7, respectively. Specifically, we
use ’w/o re’ and ’w/o rw’ to indicate the approaches that do not
apply geometric regularization and reweighting methodology, re-
spectively, and use the method that directly trains the transition
network on the biased extracted instances without any improve-
ments as the base method. The results show that either removing
the reweighting technique (w/o rw) or geometric regularization
(w/o re) degrades the performance of the classifier. At the same time,
the base method, which removes both of the above improvements,
exhibits the worst performance. These observations collectively
demonstrate the effectiveness of both the reweighting technique
and geometric regularization in constructing a more robust classi-
fier.
 
220Tackling Instance-Dependent Label Noise with Class Rebalance and Geometric Regularization KDD ’24, August 25–29, 2024, Barcelona, Spain
Table 5: Means and standard deviations (percentage) of classification accuracy on CIFAR-10 with different IDN levels.
IDN-10% IDN-20% IDN-30% IDN-40% IDN-50%
base 80.01±1.34 79.08±0.23 73.17±1.02 64.78±3.92 56.49±3.69
w/o re 80.66±0.31 79.65±0.37 75.28±3.38 66.84±4.49 58.76±2.67
w/o rw 80.21±0.42 79.31±0.53 76.32±2.47 68.22±4.39 59.42±2.89
CRGR 81.51±0.57 80 .01±0.51 77 .01±1.75 68 .28±4.06 60 .86±3.18
Table 6: Means and standard deviations (percentage) of classification accuracy on SVHN with different IDN levels.
IDN-10% IDN-20% IDN-30% IDN-40% IDN-50%
base 94.35±0.42 91.55±4.19 89.78±3.58 83.71±4.60 70.41±6.53
w/o re 94.65±0.51 92.83±1.37 90.82±2.69 89.12±3.50 72.37±3.37
w/o rw 94.45±0.62 93.32±1.53 91.57±2.78 85.49±3.29 75.09±3.09
CRGR 95.12±0.33 94 .59±0.89 93 .23±1.13 91 .35±1.99 77 .58±6.25
Table 7: Means and standard deviations (percentage) of classification accuracy on CIFAR-100 with different IDN levels.
IDN-10% IDN-20% IDN-30% IDN-40% IDN-50%
base 44.65±1.14 42.09±0.61 37.85±1.18 33.23±0.60 27.73±1.07
w/o re 49.28±1.51 47.19±2.16 42.95±2.02 37.65±1.09 31.63±0.87
w/o rw 49.90±1.42 46.67±1.53 43.26±1.78 38.58±0.89 31.89±1.09
CRGR 51.03±0.67 48 .94±0.27 44 .91±2.15 39 .76±1.54 32 .04±2.25
 
221