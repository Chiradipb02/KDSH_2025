Fast Multidimensional Partial Fourier Transform with
Automatic Hyperparameter Selection
Yong-chan Park
Seoul National University
Seoul, Republic of Korea
wjdakf3948@snu.ac.krJongjin Kim
Seoul National University
Seoul, Republic of Korea
j2kim99@snu.ac.krU Kang
Seoul National University
Seoul, Republic of Korea
ukang@snu.ac.kr
Abstract
Given a multidimensional array, how can we optimize the compu-
tation process for a part of Fourier coefficients? Discrete Fourier
transform plays an overarching role in various data mining tasks.
Recent interest has focused on efficiently calculating a small part
of Fourier coefficients, exploiting the energy compaction prop-
erty of real-world data. Current methods for partial Fourier trans-
form frequently encounter efficiency issues, yet the adoption of
pre-computation techniques within the PFT algorithm has shown
promising performance. However, PFT still faces limitations in
handling multidimensional data efficiently and requires manual
hyperparameter tuning, leading to additional costs.
In this paper, we propose Auto-MPFT (Automatic Multidimen-
sional Partial Fourier Transform), which efficiently computes a
subset of Fourier coefficients in multidimensional data without the
need for manual hyperparameter search. Auto-MPFT leverages mul-
tivariate polynomial approximation for trigonometric functions,
generalizing its domain to multidimensional Euclidean space. More-
over, we present a convex optimization-based algorithm for auto-
matically selecting the optimal hyperparameter of Auto-MPFT. We
provide a rigorous proof for the explicit reformulation of the origi-
nal optimization problem of Auto-MPFT, demonstrating the process
that converts it into a well-established unconstrained convex opti-
mization problem. Extensive experiments show that Auto-MPFT
surpasses existing partial Fourier transform methods and optimized
FFT libraries, achieving up to 7.6 √óincrease in speed without sacri-
ficing accuracy. In addition, our optimization algorithm accurately
finds the optimal hyperparameter for Auto-MPFT, significantly
reducing the cost associated with hyperparameter search.
CCS Concepts
‚Ä¢Theory of computation ‚ÜíNumeric approximation algo-
rithms.
Keywords
Partial Fourier transform; Fast Fourier transform
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain
¬©2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 979-8-4007-0490-1/24/08
https://doi.org/10.1145/3637528.3671667ACM Reference Format:
Yong-chan Park, Jongjin Kim, and U Kang. 2024. Fast Multidimensional
Partial Fourier Transform with Automatic Hyperparameter Selection. In
Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery
and Data Mining (KDD ‚Äô24), August 25‚Äì29, 2024, Barcelona, Spain. ACM, New
York, NY, USA, 12 pages. https://doi.org/10.1145/3637528.3671667
1 Introduction
Discrete Fourier transform (DFT) is a central algorithm in many
data mining tasks, including anomaly detection [ 15,22,23,31], la-
tent pattern extraction [ 21,25,33], and image processing [ 8,18,27].
Recently, there has been a growing interest in efficiently calculating
only a part of Fourier coefficients by leveraging the energy com-
paction property of data. A majority of real-world data, such as
time series, image, and video, have a very compact representation
in the frequency domain. As an illustration, Figure 1 visualizes the
Fourier coefficients of natural images from ImageNet, where the
coefficients are mostly equal to zero except in a few low-frequency
parts. This indicates that one can gain significant computational
benefits by focusing only on the part of non-zero coefficients and
skipping the computation of unnecessary coefficients.
However, many existing methods for partial Fourier transform,
such as Goertzel algorithm [ 6,13], Subband DFT [ 14,26], and
Pruned FFT [ 2,16,17,28,30], suffer from low efficiency. Compared
to the classic fast Fourier transform (FFT) computing the full coeffi-
cients, these methods outperform FFT only when the output has a
much smaller size than the input, limiting their usage in practice. A
recent work [ 20] proposes PFT, which leverages pre-computation
techniques for partial Fourier transform, and raises the performance
to a level that it can replace FFT in practical applications. However,
the effectiveness of PFT is constrained by two major limitations.
First, PFT is specialized for one-dimensional data, so it does not op-
erate efficiently for multidimensional data. Although it is possible
to apply PFT to each axis of multidimensional data, we theoretically
and experimentally show that this approach is less efficient than
algorithms specifically designed for multidimensional data. Second,
PFT requires a manual hyperparameter tuning every time the size
of the input or output changes. This leads to an extra cost of the
method, especially when the data are multidimensional, because in
that case the search space of the hyperparameter is also huge.
In this paper, we propose Auto-MPFT (Automatic Multidimen-
sional Partial Fourier Transform), a fast and accurate algorithm
that computes partial Fourier coefficients of multidimensional data
without necessity for manual hyperparameter search. Auto-MPFT
approximates a set of trigonometric factors in DFT using multivari-
ate polynomials. Polynomial approximation enables Auto-MPFT to
significantly reduce the computational cost by efficiently processing
 
2328
KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain Yong-chan Park, Jongjin Kim, and U Kang
Figure 1: Examples of input images and their Fourier maps,
where the Fourier coefficients are shown as log-amplitudes.
Except for a few low-frequency parts (around the center), the
Fourier coefficients are predominantly close to zero.
multidimensional data with matrix multiplications and multidimen-
sional FFTs. Furthermore, we propose a convex optimization-based
algorithm for automatically selecting the optimal hyperparame-
ter of Auto-MPFT. The key of our method is to approximate the
complicated constraint function in Auto-MPFT by deriving an ex-
plicit reformulation of the constraint function based on Chebyshev
approximation [ 7]. We prove that it leads to an unconstrained con-
vex optimization problem, which is efficiently solved by Newton‚Äôs
method. Extensive experiments show that Auto-MPFT outperforms
the state-of-the-art partial Fourier transform methods as well as op-
timized FFT libraries, Intel MKL and FFTW, achieving a remarkable
increase in speed without compromising accuracy. We also show
that our convex optimization-based algorithm successfully finds
the optimal hyperparameter of Auto-MPFT, significantly reducing
the extra cost due to the hyperparameter search.
We summarize our contributions as follows:
‚Ä¢Algorithm. We present Auto-MPFT, an efficient method that
computes a part of Fourier coefficients of multidimensional data.
‚Ä¢Automatic hyperparameter selection. We propose a convex
optimization-based algorithm for automatic selection of the opti-
mal hyperparameter of Auto-MPFT.
‚Ä¢Performance. We experimentally show that Auto-MPFT outper-
forms the state-of-the-art baselines without sacrificing accuracy.
We provide the source code and datasets used in our paper at
https://github.com/snudatalab/Auto-MPFT/ .
2 Related Works
We present an overview of different methods for computing partial
Fourier coefficients, comparing them to our Auto-MPFT.
Fast Fourier transform. Fast Fourier transform (FFT) [ 5,9,19]
is an efficient algorithm for rapidly computing the discrete Fourier
transform (DFT), reducing the computational complexity from
ùëÇ(ùëÅ2)toùëÇ(ùëÅlogùëÅ), whereùëÅis an input size. While there are
specialized algorithms for the partial Fourier transform, it is note-
worthy that the FFT, designed for computing full coefficients, often
proves to be a superior choice. This preference is due to the fact
that FFT is a well-established and highly optimized algorithm over
the years, making it not only straightforward to implement but alsofrequently outperforming specialized algorithms for partial Fourier
transform. We conduct comprehensive theoretical and experimental
comparisons between our proposed Auto-MPFT and FFT. Specifi-
cally, we show that Auto-MPFT significantly outperforms the FFT
by an order of magnitude of speedup with comparable accuracy.
Goertzel algorithm. Goertzel algorithm [ 6,13] is an early
method for computing partial Fourier coefficients. It essentially
mimics the process of computing individual coefficients one by one,
entailing a computational complexity of ùëÇ(ùëÄùëÅ)forùëÄcoefficients
in an input of size ùëÅ. This indicates that Goertzel algorithm be-
comes advantageous over FFT only when the number of coefficients
ùëÄis less than logùëÅ. Although a few variants aimed at improving
the Goertzel algorithm have been proposed [ 4], their performance
gains are limited to a small constant factor. Consequently, these
improvements do not significantly alter the algorithm‚Äôs overall effi-
ciency. Thus, the Goertzel algorithm is less favorable in scenarios
where a considerable number of coefficients is required.
Subband DFT. Subband DFT [ 14,26] breaks down the input
data into smaller sub-blocks and efficiently approximates a part
of Fourier coefficients by eliminating sub-blocks with low energy
contributions, resulting in ùëÇ(ùëÅ+ùëÄlogùëÅ)time complexity. Despite
the computational advantages, Subband DFT suffers from low accu-
racy, consistently showing a large relative error of around 10‚àí1[14].
While Subband DFT may offer computational benefits, its accuracy
limitation makes it less suitable for applications demanding precise
and reliable results. Note that Auto-MPFT enables the evaluation
of Fourier coefficients with arbitrary numerical precision.
Pruned FFT. Pruned FFT [ 2,16,17,28,30] is a modification
of the standard FFT, designed for computing a subset of Fourier
coefficients. In this method, operations in a flow graph are pruned
by removing those that do not influence the specified range in
the frequency domain, achieving ùëÇ(ùëÅlogùëÄ)time cost. However,
the pruning strategy does not result in significant computational
savings because it leads to increased complexity in maintaining the
accuracy of the desired frequency range. Moreover, it is noteworthy
that the standard FFT is significantly more optimized than Pruned
FFT. In comparison to Pruned FFT, our Auto-MPFT is highly efficient
as it directly leverages the standard FFT as a subroutine.
PFT. PFT [ 20] is the current state-of-the-art method for partial
Fourier transform. The method uses a polynomial approximation
technique for efficient computations of DFT, reducing the time
complexity to ùëÇ(ùëÅ+ùëÄlogùëÄ). However, there are two downsides to
the method. First, PFT is designed specifically for one-dimensional
inputs, making it less effective when applied to multidimensional
data. For example, Figure 2 compares the application of PFT and
Auto-MPFT to a two-dimensional input of size ùëÜ√óùëÜ, where the goal
is to efficiently compute ùëá√óùëálow-frequency coefficients. Because
a multidimensional DFT is equivalent to applying multiple one-
dimensional DFTs for each dimension, one can use multiple PFTs
for each axis as in Figure 2. However, this approach requires
ùëÜ¬∑(ùëÜ+ùëálogùëá)+ùëá¬∑(ùëÜ+ùëálogùëá)‚àºùëÜ2+ùëÜùëálogùëá
costs, while Auto-MPFT conducts the same computation with only
ùëÜ2+ùëá2logùëá2‚àºùëÜ2+ùëá2logùëá
operations (see Section 3.3 for the proof), which is a significant
computational gain since ùëá‚â™ùëÜ.
 
2329Fast Multidimensional Partial Fourier Transform with Automatic Hyperparameter Selection KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain
PFT
axis=1PFT
axis=2
Auto-MPFT (proposed)
Figure 2: Comparison between PFT and Auto-MPFT for a
two-dimensional input. While PFT is applied for each axis,
Auto-MPFT is applied only once for the entire input and
therefore requires much fewer operations.
Another disadvantage of PFT is its reliance on a manual hyper-
parameter search. Given an input of size ùëÅ, a user must choose
an appropriate divisor ùëùofùëÅto use the PFT algorithm. The over-
all performance of the algorithm varies greatly depending on the
value ofùëù, making it crucial to choose the optimal ùëù. However,
PFT does not provide an option to automatically find the optimal
value, so in the worst case, one may need to go through trial and
error for all divisors of ùëÅ. The situation becomes even worse when
the input is multidimensional because the search space grows ex-
ponentially with dimension. Note that Auto-MPFT addresses this
problem by automatically finding the optimal value of ùëùusing a
convex optimization-based algorithm, significantly reducing the
extra cost due to the hyperparameter search.
3 Proposed Method
We propose Auto-MPFT, an efficient algorithm for partial Fourier
transform of multidimensional data with automatic hyperparameter
selection. The main challenges and our approaches are as follows:
(1)How can we efficiently compute partial Fourier coeffi-
cients in multidimensional DFT? We carefully modify the
Cooley-Tukey algorithm to find a set of smooth twiddle factors
in multidimensional DFT. We then approximate the twiddle
factors using multivariate polynomials. This technique decom-
poses the computation of partial Fourier coefficients into matrix
multiplications and multidimensional FFTs of small sub-blocks
of the input, achieving significantly less time cost (Section 3.1).
(2)How can we automatically find the optimal hyperparam-
eter of Auto-MPFT? The optimal hyperparameter is the value
that minimizes the time complexity of Auto-MPFT. However,
we find that the constraint function of such an optimization
problem cannot be expressed as an explicit form. We tackle this
issue by reformulating the constraint function via Chebyshev
approximation and deriving an unconstrained convex optimiza-
tion problem. This approach allows us to efficiently find the
optimal hyperparameter using well-established numerical anal-
ysis such as Newton‚Äôs method (Sections 3.2 and 3.3).
3.1 Multidimensional Partial Fourier Transform
We describe our proposed method in detail. The key ideas of Auto-
MPFT for efficient computation of partial Fourier coefficients areas follows: (1) in the configuration phase, Auto-MPFT uses pre-
computation techniques via multivariate polynomial approxima-
tion of trigonometric functions in DFT. Moreover, it automatically
finds the optimal hyperparameter and calculates the degree of the
approximation polynomial (Algorithm 1). (2) In the computation
phase, Auto-MPFT utilizes batch matrix multiplication and FFT
algorithms optimized for multidimensional data types, which al-
lows Auto-MPFT to yield theoretically and experimentally superior
results compared to existing methods (Algorithm 2).
For a positive integer ùúà, letùúîùúà‚âîùëí‚àí2ùúãùëñ/ùúàbe theùúà-th primitive
root of unity and[ùúà]‚âî{0,1,¬∑¬∑¬∑,ùúà‚àí1}. Given aùê∑-dimensional
arrayùìê=(ùëéùíè)‚ààCùëÅ1√ó¬∑¬∑¬∑√óùëÅùê∑, the DFT of it is defined as follows:
ÀÜùëéùíé=‚àëÔ∏Å
ùíè‚àà√é
ùëë[ùëÅùëë]ùëéùíè√ñ
ùëëùúîùëöùëëùëõùëë
ùëÅùëë(1‚â§ùëë‚â§ùê∑), (1)
where ùíè=(ùëõ1,¬∑¬∑¬∑,ùëõùê∑),ùíé=(ùëö1,¬∑¬∑¬∑,ùëöùê∑)‚ààZùê∑are input and
output indices, respectively. Our goal is to compute the Fourier
coefficients ÀÜùëéùíéforùíébelonging to the ùê∑-dimensional box
BùùÅ,ùë¥:=√ñ
ùëë[ùúáùëë‚àíùëÄùëë,ùúáùëë+ùëÄùëë],
where ùùÅ=(ùúá1,¬∑¬∑¬∑,ùúáùê∑),ùë¥=(ùëÄ1,¬∑¬∑¬∑,ùëÄùê∑)‚ààZùê∑are the center
and radii of the box, respectively. We call the ùê∑-dimensional box
BùùÅ,ùë¥a ‚Äútarget range.‚Äù Now assume that for each ùëë=1,¬∑¬∑¬∑,ùê∑,
we haveùëÅùëë=ùëùùëëùëûùëë, whereùëùùëë,ùëûùëë>1. Let ùíë=(ùëù1,¬∑¬∑¬∑,ùëùùê∑)‚àà
Zùê∑andùíí=(ùëû1,¬∑¬∑¬∑,ùëûùê∑) ‚ààZùê∑. The Cooley-Tukey algorithm
[9] decomposes the summation (1) with ùíè=ùíí‚äôùíå+ùíç, where
ùíå‚àà√é
ùëë[ùëùùëë],ùíç‚àà√é
ùëë[ùëûùëë], and‚äôis the element-wise product:
ÀÜùëéùíé=‚àëÔ∏Å
ùíå,ùíçùëéùíí‚äôùíå+ùíç√ñ
ùëëùúîùëöùëë(ùëûùëëùëòùëë+ùëôùëë)
ùëÅùëë
=‚àëÔ∏Å
ùíå,ùíçùëéùíí‚äôùíå+ùíç√ñ
ùëëùúîùëöùëëùëôùëë
ùëÅùëëùúîùëöùëëùëòùëëùëùùëë.(2)
Following the trick ùúîùëöùëëùëôùëë
ùëÅùëë=ùúîùëöùëë(ùëôùëë‚àíùëûùëë/2)
ùëÅùëë¬∑ùúîùëöùëë
2ùëùùëëfrom [ 20], we
rewrite (2) as follows:
ÀÜùëéùíé=‚àëÔ∏Å
ùíå,ùíçùëéùíí‚äôùíå+ùíç√ñ
ùëëùúîùëöùëë(ùëôùëë‚àíùëûùëë/2)
ùëÅùëëùúîùëöùëëùëòùëëùëùùëëùúîùëöùëë
2ùëùùëë. (3)
Note that|ùëôùëë|<ùëûùëëand|ùëôùëë‚àíùëûùëë/2|<ùëûùëë/2, so the twiddle factors
{ùúîùëöùëë(ùëôùëë‚àíùëûùëë/2)
ùëÅùëë}is less oscillatory compared to {ùúîùëöùëëùëôùëë
ùëÅùëë}, which
allows a more accurate approximation via polynomials. To apply
polynomial approximation for the set {ùúîùëöùëë(ùëôùëë‚àíùëûùëë/2)
ùëÅùëë}, we provide
the following definitions. Let ‚à•¬∑‚à•ùëÖbe the uniform norm restricted
to a setùëÖ‚äÜR, that is,‚à•ùëì‚à•ùëÖ‚âîsup{|ùëì(ùë•)|:ùë•‚ààùëÖ}andùëÉùõºbe the
set of polynomials on Rof degree less than ùõº.
Definition 3.1. Given a positive integer ùõºand a non-zero real
numberùúâ, we definePùõº,ùúâas the best polynomial approximation to
ùëíùúãùëñùë•of degree less than ùõºwith the restriction |ùë•|‚â§|ùúâ|:
Pùõº,ùúâ:=arg min
ùëÉ‚ààùëÉùõº‚à•ùëÉ(ùë•)‚àíùëíùúãùëñùë•‚à•|ùë•|‚â§|ùúâ|,
andPùõº,ùúâ‚âî1whenùúâ=0. ‚ñ°
The uniqueness and existence of such polynomials are proved
in [29]. For the computation of the best polynomial approxima-
tion, we use the Chebyshev approximation algorithm [ 10]. We opt
to use the Chebyshev polynomials due to their solid theoretical
foundations, including their widespread application in achieving
optimal approximations with respect to the uniform norm and their
contribution to the derivation of an error bound of Auto-MPFT
 
2330KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain Yong-chan Park, Jongjin Kim, and U Kang
as we will describe in Section 3.2. Further investigation into other
types of orthogonal polynomials could provide valuable insights
and potentially improve the accuracy and efficiency of our proposed
method, which we leave as an interesting future work.
Definition 3.2. Given a tolerance ùúñ>0and a positive integer
ùëü, we defineùúâ(ùúñ,ùëü)to be the scope about the origin such that the
exponential function ùëíùúãùëñùë•can be approximated by a polynomial of
degree less than ùëüwith approximation bound ùúñ:
ùúâ(ùúñ,ùëü):=sup{ùúâ‚â•0 :‚à•Pùëü,ùúâ(ùë•)‚àíùëíùúãùëñùë•‚à•|ùë•|‚â§ùúâ‚â§ùúñ}.
We express the best polynomial as Pùëü,ùúâ(ùúñ,ùëü)(ùë•)=√ç
ùëó‚àà[ùëü]ùë§ùúñ,ùëü,ùëóùë•ùëó,
whereùë§ùúñ,ùëü,ùëóis theùëó-th coefficient of the polynomial. ‚ñ°
Given a tolerance ùúñ>0, assume that we found a positive integer
ùëüùëëthat satisfies ùúâ(ùúñ,ùëüùëë) ‚â•ùëÄùëë/ùëùùëëfor eachùëë(the algorithm for
findingùëüùëëis demonstrated in Section 3.2). Then, for ùúáùëë‚àíùëÄùëë‚â§
ùëöùëë‚â§ùúáùëë+ùëÄùëë, we decompose the twiddle factor ùúîùëöùëë(ùëôùëë‚àíùëûùëë/2)
ùëÅùëë
intoùúîùúáùëë(ùëôùëë‚àíùëûùëë/2)
ùëÅùëëùúî(ùëöùëë‚àíùúáùëë)(ùëôùëë‚àíùëûùëë/2)
ùëÅùëëand approximate the second
term by the polynomial Pùëüùëë,ùúâ(ùúñ,ùëüùëë)(‚àí2(ùëöùëë‚àíùúáùëë)(ùëôùëë‚àíùëûùëë/2)/ùëÅùëë).
Becauseùúâ(ùúñ,ùëüùëë)‚â•ùëÄùëë/ùëùùëë, the approximation is valid for all ùëöùëë
such that|ùëöùëë‚àíùúáùëë| ‚â§ |ùëÅùëë
2(ùëôùëë‚àíùëûùëë/2)¬∑ùëÄùëë
ùëùùëë|=|ùëûùëë
2ùëôùëë‚àíùëûùëë¬∑ùëÄùëë|, so in
particular,|ùëöùëë‚àíùúáùëë|‚â§ùëÄùëë. Thus, we approximate (3) as follows:
ÀÜùëéùíé‚âà‚àëÔ∏Å
ùíã,ùíå,ùíçùëé(ùíå)
ùíç√ñ
ùëëùëè(ùëë)
ùëóùëëùëôùëëùúîùëöùëëùëòùëëùëùùëë((ùëöùëë‚àíùúáùëë)/ùëùùëë)ùëóùëëùúîùëöùëë
2ùëùùëë,(4)
where ùíã‚àà√é
ùëë[ùëüùëë],ùíå‚àà√é
ùëë[ùëùùëë],ùíç‚àà√é
ùëë[ùëûùëë], and
ùìê(ùíå):=(ùëé(ùíå)
ùíç=ùëéùíí‚äôùíå+ùíç)‚ààCùëû1√ó¬∑¬∑¬∑√óùëûùê∑,
ùêµ(ùëë):=(ùëè(ùëë)
ùëóùëëùëôùëë=ùúîùúáùëë(ùëôùëë‚àíùëûùëë/2)
ùëÅùëëùë§ùúñ,ùëüùëë,ùëóùëë(1‚àí2ùëôùëë/ùëûùëë)ùëóùëë)‚ààCùëüùëë√óùëûùëë.
In (4), the innermost summation√ç
ùíçùëé(ùíå)
ùíç√é
ùëëùëè(ùëë)
ùëóùëëùëôùëëcan be written
as a sequential ùëë-mode product
ùìê(ùíå)√ó1ùêµ(1)√ó2¬∑¬∑¬∑√óùê∑ùêµ(ùê∑). (5)
Note that there are a total of ùê∑!parenthesizations to compute (5).
We precompute the optimal parenthesization in the configuration
phase when(ùëµ,ùë¥,ùùÅ,ùúñ)is given, so that we can bypass the paren-
thesization problem in the computation phase. Let us denote the
result of (5) by ùìí(ùíå):=(ùëê(ùíå)
ùíã)‚ààCùëü1√ó¬∑¬∑¬∑√óùëüùê∑. For each ùíã, the opera-
tion√ç
ùíåùëê(ùíå)
ùíã√é
ùëëùúîùëöùëëùëòùëëùëùùëëis aùê∑-dimensional DFT of size√é
ùëëùëùùëë. Let
ÀÜùëê(ùíã)
ùíébe the Fourier coefficients of ùëê(ùíå)
ùíãwith respect to ùíå. Then, we
obtain the following estimation of ÀÜùëéùíé:
ÀÜùëéùíé‚âà‚àëÔ∏Å
ùíãÀÜùëê(ùíã)
ùíé√ñ
ùëë((ùëöùëë‚àíùúáùëë)/ùëùùëë)ùëóùëëùúîùëöùëë
2ùëùùëë. (6)
The full computation is outlined in Algorithms 1 and 2.
3.2 Automatic Hyperparameter Selection
We propose a convex optimization-based algorithm for selecting the
optimal hyperparameter of Auto-MPFT. The key idea is to convert
the original optimization problem of Auto-MPFT (Problem 1) into
an unconstrained convex optimization problem (Problem 2) by
carefully approximating the constraint function.Algorithm 1: Configuration phase of Auto-MPFT
input : Input size ùëµ, output descriptors ùë¥andùùÅ, and
toleranceùúñ
output: Configuration results ùêµ(ùëë),ùëùùëë,ùëûùëë,ùëüùëëfor allùëë, and
optimal parenthesization
1forùëë=1,2,¬∑¬∑¬∑,ùê∑do
2 Find the solution ùëüùëëof Problem 2 by Newton‚Äôs method
3 Find the nearest divisor ùëùùëëofùëÅùëëtoùëù(ùëüùëë)
4ùëûùëë‚ÜêùëÅùëë/ùëùùëë
5ùëüùëë‚Üê‚åäùëüùëë‚åã
6ùêµ(ùëë)[ùëô,ùëó]‚Üêùúîùúáùëë(ùëô‚àíùëûùëë/2)
ùëÅùëëùë§ùúñ,ùëüùëë,ùëó(1‚àí2ùëô/ùëûùëë)ùëó
7end
8Find the optimal parenthesization of Equation (5).
Algorithm 2: Computation phase of Auto-MPFT
input : Array ùíÇof size√é
ùëëùëÅùëë, output descriptors ùë¥andùùÅ,
and configuration results in Algorithm 1
output: Array ÀÜùíÇof Fourier coefficients of ùíÇforBùùÅ,ùë¥
1ùê¥(ùíå)[ùíç]‚Üêùëéùíí‚äôùíå+ùíçforùíå‚àà√é
ùëë[ùëùùëë]andùíç‚àà√é
ùëë[ùëûùëë]
2ùê∂(ùíå)‚Üêùê¥(ùíå)√ó1ùêµ(1)√ó2¬∑¬∑¬∑√óùê∑ùêµ(ùê∑)forùíå‚àà√é
ùëë[ùëùùëë]
3ÀÜùê∂(ùíã)[¬∑]‚Üê FFT(ùê∂(¬∑)[ùíã])forùíã‚àà√é
ùëë[ùëüùëë]
4forùíé‚ààBùùÅ,ùë¥do
5 ÀÜùíÇ[ùíé]‚Üê√ç
ùíãÀÜùê∂(ùíã)[ùíé]√é
ùëë((ùëöùëë‚àíùúáùëë)/ùëùùëë)ùëóùëëùúîùëöùëë
2ùëùùëë
6end
3.2.1 Building an Optimization Problem. Recall that the optimal
hyperparameter is given by the minimizer of the time complexity
of Auto-MPFT. Thus, we first need to derive the time cost function
of our proposed method. Following convention, we consider only
the computation phase for a time cost because the configuration
phase contains only data-independent processes. For simplicity,
we use the following notations: ùëÅ=√é
ùëëùëÅùëë, ùëÄ=√é
ùëëùëÄùëë, ùëù=√é
ùëëùëùùëë, ùëû=√é
ùëëùëûùëë, andùëü=√é
ùëëùëüùëë,whereùëë=1,2,¬∑¬∑¬∑,ùê∑.
The estimation (4) involves matrix multiplications (5) for each
ùíå‚àà√é
ùëë[ùëùùëë]. Without loss of generality, we assume that the opti-
mal parenthesization is given in the order √ó1,√ó2,¬∑¬∑¬∑,√óùê∑, which
requiresùëÇ(ùëü1ùëû1¬∑¬∑¬∑ùëûùê∑+ùëü1ùëü2ùëû2¬∑¬∑¬∑ùëûùê∑+¬∑¬∑¬∑+ùëü1¬∑¬∑¬∑ùëüùê∑ùëûùê∑)opera-
tions. Then, the total cost of computing ùìí(ùíå)for all ùíåis given by
ùëÇ(ùëùùëûùëü)=ùëÇ(ùëÅùëü)since
ùëù(ùëü1ùëû1¬∑¬∑¬∑ùëûùê∑+ùëü1ùëü2ùëû2¬∑¬∑¬∑ùëûùê∑+¬∑¬∑¬∑+ùëü1¬∑¬∑¬∑ùëüùê∑ùëûùê∑)
=ùëùùëûùëü
ùëü2¬∑¬∑¬∑ùëüùê∑+ùëûùëü
ùëû1ùëü3¬∑¬∑¬∑ùëüùê∑+¬∑¬∑¬∑+ùëûùëü
ùëû1¬∑¬∑¬∑ùëûùê∑‚àí1
‚â§ùëùùëûùëü(1+1/2+¬∑¬∑¬∑+ 1/2ùê∑‚àí1)<2ùëùùëûùëü,
forùëüùëë‚â•1andùëûùëë‚â•2. We next perform ùëüFFTs of size ùëùto calculate
ÀÜùëê(ùíã)
ùíé, which takes ùëÇ(ùëüùëùlogùëù)time. The remaining computation (6)
requiresùëÇ(ùëü)operations for each ùíé, giving anùëÇ(ùëÄùëü)running time.
Hence, the time cost of Auto-MPFT can be written as
ùëÇ((ùëÅ+ùëùlogùëù+ùëÄ)ùëü). (7)
 
2331Fast Multidimensional Partial Fourier Transform with Automatic Hyperparameter Selection KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain
Now let us consider the objective function (7) for each dimension
ùëë=1,2,¬∑¬∑¬∑,ùê∑. Recall that ùëÅùëëandùëÄùëëare input and output size
descriptors, respectively, ùëùùëëis a positive divisor of ùëÅùëë, andùëüùëëis the
number of approximating terms depending on given tolerance ùúñ.
Unfortunately, the variables ùëùùëëandùëüùëëtake discrete integer values,
precluding directly using the continuous optimization methods.
Moreover, the constraint that ùëùùëëdividesùëÅùëëresults in an irregular
domain ofùëùùëëdepending on the value of ùëÅùëë. To tackle these prob-
lems, we slightly relax the constraints, extending the domain of
ùëùùëëandùëüùëëto the positive real numbers and discarding the neces-
sity thatùëùùëëdividesùëÅùëë. This leads to the following optimization
problem (from now on we omit the subscript ùëëfor brevity):
Problem 1. GivenùëÅ,ùëÄ‚ààN, andùúñ>0,
argmin
ùëù,ùëü>0(ùëÅ+ùëùlogùëù+ùëÄ)ùëü
ùë†.ùë°. ùúâ(ùúñ,ùëü)‚â•ùëÄ/ùëù ‚ñ°
The challenge of this optimization problem is mainly due to the
functionùúâ, which cannot be expressed in an explicit form. Thus, we
propose reformulating the problem into an unconstrained convex
optimization problem by approximating the constraint function.
3.2.2 Approximating Error. The main idea of our optimization pro-
cess is to approximate the constraint function ùúâ(ùúñ,ùëü)in Problem 1
and derive an explicit reformulation of the optimization problem.
Given a tolerance 0<ùúñ<1, denote
ùëü‚àó=min{ùëü‚ààN:ùúâ(ùúñ,ùëü)‚â•ùëÄ/ùëù}, (8)
andùëê=ùúâ(ùúñ,ùëü‚àó) ‚â•ùëÄ/ùëù. Consider the best polynomial approxi-
mation toùëíùëêùúãùëñùë•on|ùë•|‚â§1(this is equivalent to approximating
ùëíùúãùëñùë•on|ùë•| ‚â§ùëê), and its Taylor series ùëíùëêùúãùëñùë•=√ç
ùëõ‚â•0(ùëêùúãùëñùë•)ùëõ/ùëõ!.
For a non-negative integer ùëõ, theùëõ-th power of ùë•can be written
as follows [ 7]:ùë•ùëõ=1
2ùëõ‚àí1 ùëáùëõ(ùë•)+ ùëõ
1ùëáùëõ‚àí2(ùë•)+ ùëõ
2ùëáùëõ‚àí4(ùë•)+¬∑¬∑¬∑,
whereùëáùëõ(ùë•)is the Chebyshev polynomial of degree ùëõ(for evenùëõ,
the coefficient of ùëá0(ùë•)is divided by 2). Then, we have
ùëíùëêùúãùëñùë•=‚àëÔ∏Å
ùëõ‚â•0(ùëêùúãùëñùë•)ùëõ
ùëõ!=‚àëÔ∏Å
ùëõ‚â•0(ùëêùúãùëñ)ùëõ
ùëõ!1
2ùëõ‚àí1‚åäùëõ/2‚åã‚àëÔ∏Å
ùëò=0ùëõ
ùëò
ùëáùëõ‚àí2ùëò(ùë•).
Dropping the ùëáùëõ‚àí2ùëòterms forùëõ‚àí2ùëò‚â•ùëügives the Chebyshev
approximation of degree less than ùëü. LetùúÇ(ùëü)be the maximum
error of the approximation, so that ùúâ(ùúÇ(ùëü),ùëü)=ùëê. Explicitly,
ùúÇ(ùëü)‚âîmax
|ùë•|‚â§1‚àëÔ∏Å
ùëõ‚àí2ùëò‚â•ùëü(ùëêùúãùëñ)ùëõ
ùëõ!1
2ùëõ‚àí1ùëõ
ùëò
ùëáùëõ‚àí2ùëò(ùë•).
Substituting ùëõ‚Üêùëõ+2ùëò, we can rewrite this as
ùúÇ(ùëü)=max
|ùë•|‚â§1‚àëÔ∏Å
ùëõ‚â•ùëü‚àëÔ∏Å
ùëò‚â•02ùëñùëõùëêùúã
2ùëõ+2ùëò(‚àí1)ùëò
ùëò!(ùëõ+ùëò)!ùëáùëõ(ùë•).
We may express the involved terms using the Bessel function [ 1],
ùêΩùëõ(ùë§)=√ç
ùëò‚â•0(‚àí1)ùëò
ùëò!(ùëõ+ùëò)! ùë§
2ùëõ+2ùëò,whereùëõis a non-negative integer
andùë§‚ààR, which implies ùúÇ(ùëü)=max|ùë•|‚â§1√ç
ùëõ‚â•ùëü2ùëñùëõùêΩùëõ(ùëêùúã)ùëáùëõ(ùë•).
We now assume that the number ùëüof approximating terms has a
certain lower bound, namely ùëü‚â•ùëêùúã‚àí1. This is a reasonable
assumption due to the following lemma:
Lemma 1. Givenùë§>0, the sequence ùëõ‚Ü¶‚ÜíùêΩùëõ(ùë§)is strictly
decreasing for ùëõ‚â•ùë§‚àí1and converges to zero as ùëõtends to‚àû.‚ñ°Proof. Letùúàbe an integer such that ùúà‚â•ùë§‚àí1. We should show
thatùêΩùúà+1(ùë§)<ùêΩùúà(ùë§)holds. Since the Bessel function satisfies the
recurrence relation
ùêΩùëõ(ùë§)=2(ùëõ+1)
ùë§ùêΩùëõ+1(ùë§)‚àíùêΩùëõ+2(ùë§),‚àÄùëõ‚â•0, (9)
the inequality is equivalent to ùêΩùúà+1(ùë§)<2(ùúà+1)
ùë§ùêΩùúà+1(ùë§)‚àíùêΩùúà+2(ùë§),
or
ùêΩùúà+2(ùë§)<2(ùúà+1)
ùë§‚àí1
ùêΩùúà+1(ùë§).
ReplacingùêΩùúà+1(ùë§)using the recurrence relation again yields
ùêΩùúà+3(ùë§)<2(ùúà+2)
ùë§‚àí1
2(ùúà+1)
ùë§‚àí1
ùêΩùúà+2(ùë§).
In general, we obtain the following equivalent condition:
ùêΩùúà+ùë†+1(ùë§)<ùëÄùë†¬∑ùêΩùúà+ùë†(ùë§),
whereùëÄ0=1andùëÄùë†=2(ùúà+ùë†)
ùë§‚àí1
ùëÄùë†‚àí1forùë†‚â•1. A simple induction
shows thatùëÄùë†‚â•1for allùë†because
ùëÄùë†=2(ùúà+ùë†)
ùë§‚àí1
ùëÄùë†‚àí1‚â•2(ùúà+1)
ùë§‚àí1
ùëÄùë†‚àí1‚â•2‚àí1
ùëÄùë†‚àí1‚â•1
provided that ùëÄùë†‚àí1‚â•1. Thus, it is sufficient to prove that there
exists an integer ùë†‚â•0such thatùêΩùúà+ùë†+1(ùë§)<ùêΩùúà+ùë†(ùë§). Now
ùêΩùëõ(ùë§)=1
ùëõ!ùë§
2ùëõ‚àëÔ∏Å
ùëò‚â•0ùëõ!
ùëò!(ùëõ+ùëò)!
‚àíùë§2
4ùëò
‚àº1
ùëõ!ùë§
2ùëõ
forùëõ‚â´ùë§2, hence
ùêΩùúà+ùë†+1(ùë§)
ùêΩùúà+ùë†(ùë§)‚àº1
ùúà+ùë†+1ùë§
2
<1
for sufficiently large ùë†. This completes the proof. ‚ñ°
In other words, the condition ùëü‚â•ùëêùúã‚àí1together with Lemma 1
ensures that the magnitude |2ùëñùëõùêΩùëõ(ùëêùúã)|of coefficients in the Cheby-
shev approximation gap strictly decreases. Thus, we can estimate
the extreme points of the function ùë•‚Ü¶‚Üí√ç
ùëõ‚â•ùëü2ùëñùëõùêΩùëõ(ùëêùúã)ùëáùëõ(ùë•)by
the extreme points ùë•ùëòof the dominant term ùëáùëü(ùë•):
ùë•ùëò=cos(ùëòùúã/ùëü), ùëò=0,1,¬∑¬∑¬∑,ùëü.
Furthermore, it is easy to check that the magnitude of extrema
of√ç
ùëõ‚â•ùëü2ùëñùëõùêΩùëõ(ùëêùúã)ùëáùëõ(ùë•)peaks at around ùë•=0, which implies
ùúÇ(ùëü)‚âà|√ç
ùëõ‚â•ùëü2ùëñùëõùêΩùëõ(ùëêùúã)ùëáùëõ(ùë•‚åäùëü/2‚åã)|, or
ùúÇ(ùëü)‚âà(√ç
ùëõ‚â•ùëü2ùëñùëõùêΩùëõ(ùëêùúã)cos(ùúãùëõ/2)ùëü: even√ç
ùëõ‚â•ùëü2ùëñùëõùêΩùëõ(ùëêùúã)cos(ùúãùëõ(ùëü‚àí1)/2ùëü)ùëü: odd(10)
usingùëáùëõ(cosùúÉ)=cos(ùëõùúÉ). Our next goal is to prove that ùúÇ(ùëü)is
bounded above as in Lemma 2. We then use the upper bound to
derive an approximate relation between the parameters ùëùandùëü.
Lemma 2. Ifùëü‚â•2, the approximation error function ùúÇ(ùëü)satisfies
ùúÇ(ùëü)‚â§ùëà(ùëü)‚âî2‚àö
17
4‚àí‚àöùëíùê∂ùëü
ùëü!ùëí‚àíùê∂2
ùëü+1(ùê∂=ùëêùúã/2). ‚ñ°
Proof. See Supplement A.1. ‚ñ°
 
2332KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain Yong-chan Park, Jongjin Kim, and U Kang
3.2.3 Finding a Relation Between ùëùandùëü.Assume that an integer
ùëü0‚â•2satisfies the equation ùëà(ùëü0)=ùúñ. Then
ùúÇ(ùëü0)‚â§ùëà(ùëü0)=ùúñ=ùúÇ(ùëü‚àó),
where the last equality holds since ùúâ(ùúñ,ùëü‚àó)=ùëê=ùúâ(ùúÇ(ùëü‚àó),ùëü‚àó). Note
thatùúÇ(ùëü)is non-decreasing by definition, so ùëü‚àó‚â§ùëü0. This implies
that solving the equation
ùëà(ùëü)=ùúñ (11)
and rounding down the solution ÀÜùëü‚ààRgives an estimate of ùëü‚àó‚àº‚åäÀÜùëü‚åã.
Unfortunately, (11) does not have an algebraic solution due to the
presence of factorial term. To address this problem, we employ the
fixed-point iteration method to compute an approximate solution of
the equation. Specifically, we consider ùëàto be a function of ùê∂and
find an implicit expression of ùëüwith respect to ùê∂. By this technique,
we can derive an approximate relation ùëù(ùëü)which denotes the value
ofùëùdepending on ùëü. Lettingùõº=4‚àí‚àöùëí
2‚àö
17, we write (11) as follows:
ùê∂ùëü
ùõºùëü!ùëí‚àíùê∂2
ùëü+1=ùúñ‚áê‚áíùê∂ùëü=ùõºùúñùëü!¬∑ùëíùê∂2
ùëü+1‚áê‚áíùê∂=(ùõºùúñùëü!)1
ùëüùëíùê∂2
ùëü(ùëü+1).
Defineùëì(ùë•)‚âî(ùõºùúñùëü!)1
ùëüùëíùë•2
ùëü(ùëü+1)forùë•‚ààR. Then, the problem be-
comes computing a fixed point of ùëì. Sinceùëì‚Ä≤(ùë•)=(ùõºùúñùëü!)1/ùëü
ùëü(ùëü+1)2ùë•ùëíùë•2
ùëü(ùëü+1),
we haveùëì‚Ä≤(0)=0. Moreover, ùëì‚Ä≤(ùê∂)=2ùê∂
ùëü(ùëü+1)ùëì(ùê∂)=2ùê∂2
ùëü(ùëü+1)pro-
vided thatùê∂is a fixed point of ùëì. It follows from ùê∂‚â§(ùëü+1)/2and
ùëü‚â•2thatùëì‚Ä≤(ùê∂)=2ùê∂2
ùëü(ùëü+1)‚â§(ùëü+1)2
2ùëü(ùëü+1)=ùëü+1
2ùëü‚â§3
4.Becauseùëì‚Ä≤(ùë•)is
non-decreasing for ùë•‚â•0, there exist ùêø<1andùõø>0such that
|ùëì‚Ä≤(ùë•)|‚â§ùêø,‚àÄùë•‚àà(‚àíùõø,ùê∂+ùõø).This implies that ùëìis a contraction
mapping function on (‚àíùõø,ùê∂+ùõø), so the fixed-point iteration
ùê∂0‚àà(‚àíùõø,ùê∂+ùõø), ùê∂ùëõ+1=ùëì(ùê∂ùëõ), ùëõ=0,1,2,¬∑¬∑¬∑
converges to the unique fixed point ùê∂by the Banach fixed-point
theorem [ 3]. We setùê∂0=0and estimate ùê∂by the result of the
second iteration of the algorithm:
ùê∂‚àºùê∂2=ùëì(ùëì(0))=ùëì((ùõºùúñùëü!)1
ùëü)=(ùõºùúñùëü!)1
ùëüùëí1
ùëü(ùëü+1)(ùõºùúñùëü!)2/ùëü
.
We now assume that ùëê‚àºùëÄ/ùëù, which is reasonable due to the
definition of ùëü‚àóin (8). This leads to the following approximate
relation between the parameters ùëùandùëü:
ùëù‚àºùëÄ
ùëê=ùúãùëÄ
2ùê∂‚àí1‚àºùúãùëÄ
2(ùõºùúñùëü!)‚àí1
ùëüùëí‚àí1
ùëü(ùëü+1)(ùõºùúñùëü!)2/ùëü
.
3.2.4 Convexity of the Objective Function. We have shown that the
parameterùëùcan be expressed in terms of ùëüwith the relation,
ùëù(ùëü)‚âîùúãùëÄ
2(ùõºùúñùëü!)‚àí1
ùëüùëí‚àí1
ùëü(ùëü+1)(ùõºùúñùëü!)2/ùëü
, ùõº=4‚àí‚àöùëí
2‚àö
17. (12)
By employing this relation, we reduce the objective function of
Problem 1 into a functional form dependent on only ùëü, removing
the inequality constraint:
Problem 2. GivenùëÅ,ùëÄ‚ààN, andùúñ>0,
argmin
ùëü‚â•1(ùëÅ+ùëù(ùëü)logùëù(ùëü)+ùëÄ)ùëü ‚ñ°
In the following theorem, we prove that the objective function in
this problem is convex for ùëü‚â•1. Consequently, Problem 2 becomes
an unconstrained convex optimization problem.Theorem 3. The objective function ùëü‚Ü¶‚Üí(ùëÅ+ùëù(ùëü)logùëù(ùëü)+ùëÄ)ùëü
of Problem 2 is convex for ùëü‚â•1. ‚ñ°
Proof. See Supplement A.2. ‚ñ°
The convexity of the objective function guarantees the conver-
gence of second-order optimization techniques such as Newton‚Äôs
method. After the optimal solution ùëü‚àóthat minimizes the objective
function is found, we use the function ùëù(ùëü)to approximate the
optimalùëù‚àó=ùëù(ùëü‚àó)and select the nearest divisor of ùëÅtoùëù‚àó, which
replaces the manual selection process. The automatic configuration
phase of Auto-MPFT is outlined in Algorithm 1.
3.3 Theoretical Analysis
We present theoretical analysis on the time and space complexities
of Auto-MPFT and its approximation bound.
3.3.1 Time Complexity. In Section 3.2.1, we have already seen that
the time cost of Auto-MPFT can be expressed as ùëÇ((ùëÅ+ùëùlogùëù+
ùëÄ)ùëü). Note that ùëÅ=√é
ùëëùëÅùëëis an input size, ùëÄ=√é
ùëëùëÄùëëis an
output size, ùëù=√é
ùëëùëùùëë, andùëü=√é
ùëëùëüùëë, whereùëùùëëis a divisor of ùëÅùëë
andùëüùëëis an approximation order given a tolerance ùúñ. However, the
values ofùëùandùëüin the above time cost are internally determined
by the configuration phase (Algorithm 1). As a result, users cannot
directly find out these values, making it inconvenient to use the
time cost function. To address this limitation, we transform the
time cost into a functional form that depends only on ùëÅ,ùëÄ, andùúñ,
which are the inputs of Auto-MPFT. We first present the following
two lemmas and employ them for the proof of Theorem 6.
Lemma 4. For eachùëë=1,2,¬∑¬∑¬∑,ùê∑, we have the asymptotic equa-
tionùëüùëë=ùëÇ(log(1/ùúñ)). ‚ñ°
Proof. Recall that by Equation (11), we have the following as-
ymptotic equation between ùúñandùëüùëë:
ùúñ‚àºùëà(ùëüùëë)=2‚àö
17
4‚àí‚àöùëíùê∂ùëüùëë
ùëüùëë!ùëí‚àíùê∂2
ùëüùëë+1.
Then there exist ùêµ1,ùêµ2>0such that for sufficiently large ùëüùëë,
ùúñ<ùêµ1¬∑ùê∂ùëüùëë
ùëüùëë!ùëí‚àíùê∂2
ùëüùëë+1<ùêµ1¬∑ùê∂ùëüùëë
ùëüùëë!<ùêµ2
ùëíùëüùëë.
It follows that ùëíùëüùëë<ùêµ2/ùúñ, and thusùëüùëë=ùëÇ(log(1/ùúñ)). ‚ñ°
Lemma 5. IfùëÅùëëisùëèùëë-smooth for some ùëèùëë‚â•2(that is, none of
prime factors of ùëÅùëëis greater than ùëèùëë) and 1‚â§ùëÄùëë‚â§ùëÅùëë, then there
exists a divisor ùëùùëëofùëÅùëësatisfyingùëùùëë=Œò(ùëÄùëë). ‚ñ°
Proof. Following the proof of Theorem 3 of [ 20], we prove that
there exists a divisor ùëùùëëofùëÅùëësuch thatùëÄùëë/‚àöÔ∏Å
ùëèùëë‚â§ùëùùëë<‚àöÔ∏Å
ùëèùëëùëÄùëë.
Suppose that none of ùëÅùëë‚Äôs divisors belongs to [ùëÄùëë/‚àöÔ∏Å
ùëèùëë,‚àöÔ∏Å
ùëèùëëùëÄùëë).
Let1=ùëù1<ùëù2<¬∑¬∑¬∑<ùëùùëõ=ùëÅùëëbe the enumeration of all
positive divisors of ùëÅùëëin increasing order. It is clear that ùëù1<‚àöÔ∏Å
ùëèùëëùëÄùëëandùëÄùëë/‚àöÔ∏Å
ùëèùëë<ùëùùëõsinceùëèùëë‚â•2and1‚â§ùëÄùëë‚â§ùëÅùëë. Then,
there exists an ùëñ‚àà {1,2,¬∑¬∑¬∑,ùëõ‚àí1}so thatùëùùëñ<ùëÄùëë/‚àöÔ∏Å
ùëèùëëand
ùëùùëñ+1‚â•‚àöÔ∏Å
ùëèùëëùëÄùëë. SinceùëÅùëëisùëèùëë-smooth and ùëùùëñ<ùëÅùëë, at least one
of2ùëùùëñ,3ùëùùëñ,¬∑¬∑¬∑,ùëèùëëùëùùëñmust be a divisor of ùëÅùëë. However, this is a
contradiction because we have ùëùùëñ+1/ùëùùëñ>(‚àöÔ∏Å
ùëèùëëùëÄùëë)(ùëÄùëë/‚àöÔ∏Å
ùëèùëë)‚àí1=
ùëèùëë, so none of 2ùëùùëñ,3ùëùùëñ,¬∑¬∑¬∑,ùëèùëëùëùùëñcan be a divisor of ùëÅùëë, which
completes the proof. ‚ñ°
 
2333Fast Multidimensional Partial Fourier Transform with Automatic Hyperparameter Selection KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain
Theorem 6. Forùëë=1,2,¬∑¬∑¬∑,ùê∑, letùëÅùëëbeùëèùëë-smooth for some
ùëèùëë‚â•2. Then the time complexity of Auto-MPFT has an asymptotic
upper bound ùëÇ((ùëÅ+ùëÄlogùëÄ)(log(1/ùúñ))ùê∑). ‚ñ°
Proof. It follows that ùëüùëë=ùëÇ(log(1/ùúñ))by Lemma 4, which
gives an upper bound for ùëü=√é
ùëëùëüùëë=ùëÇ((log(1/ùúñ))ùê∑). Using
Lemma 5, we can find a divisor ùëùùëëofùëÅùëësuch thatùëùùëë=Œò(ùëÄùëë)for
allùëë, resulting in ùëù=√é
ùëëùëùùëë=Œò(√é
ùëëùëÄùëë)=Œò(ùëÄ). Replacing ùëù
andùëüin the original upper bound of the time complexity yields
ùëÇ((ùëÅ+ùëùlogùëù+ùëÄ)ùëü)=ùëÇ((ùëÅ+ùëÄlogùëÄ)(log(1/ùúñ))ùê∑),
hence the proof. ‚ñ°
3.3.2 Space Complexity. DFT is frequently required to be deployed
on devices with limited performance capabilities. Thus, it is es-
sential to consider memory constraints when implementing the
algorithm in real-world applications. In Theorem 7, we prove that
the space complexity of Auto-MPFT is asymptotically bounded
by the sum of the input and output sizes, ùëÅ+ùëÄ. This indicates
that Auto-MPFT is a space-optimal algorithm, requiring only the
minimum space necessary for input and output.
Theorem 7. Auto-MPFT is space-optimal, that is, the space com-
plexity of it has an asymptotic upper bound ùëÇ(ùëÅ+ùëÄ). ‚ñ°
Proof. In the configuration phase (Algorithm 1), Auto-MPFT
stores matrices of size ùëüùëë√óùëûùëë(ùëë=1,¬∑¬∑¬∑,ùê∑)for multivariate
polynomial approximation, which requires ùëÇ(√ç
ùëëùëüùëëùëûùëë)space cost.
In the computation phase (Algorithm 2), we need ùëÇ(ùëÅ)space to
read an input data array (line 1 in Algorithm 2), ùëÇ(ùëùùëü)space for
polynomial approximation results (line 2 in Algorithm 2), and ùëÇ(ùëÄ)
space to save an output (lines 4-6 in Algorithm 2), which sum up
toùëÇ(ùëÅ+ùëùùëü+ùëÄ). Typically, the number ùëüùëëis much smaller than
ùëùùëëandùëûùëëifùëÅùëë=ùëùùëëùëûùëëis sufficiently large, so we may assume
that (1)ùëÇ(√ç
ùëëùëüùëëùëûùëë)=ùëú(√ç
ùëëùëùùëëùëûùëë)=ùëú(√ç
ùëëùëÅùëë)=ùëú(ùëÅ)and (2)
ùëÇ(ùëùùëü)=ùëú(ùëùùëû)=ùëú(ùëÅ). These lead to a total of
ùëÇ(√ç
ùëëùëüùëëùëûùëë+ùëÅ+ùëùùëü+ùëÄ)=ùëÇ(ùëÅ+ùëÄ)
space complexity of Auto-MPFT. ‚ñ°
3.3.3 Approximation Bound. We present a theoretical bound for
the approximation of the polynomial P. The estimated Fourier
coefficient of ùíÇis denoted asE(ÀÜùíÇ). According to Theorem 8, the
approximation bound within the target range is contingent on the
data-specific total weight ‚à•ùíÇ‚à•1of the original array and the given
toleranceùúñ, where‚à•¬∑‚à• 1represents the ‚Ñì1norm. It is important to
note thatùúñinfluences the number ùëüof approximating terms (see
Lemma 4), consequently affecting the error bound ‚à•ÀÜùíÇ‚àíE( ÀÜùíÇ)‚à•BùùÅ,ùë¥.
This shows that, by adjusting ùúñaccordingly, Fourier coefficients can
be computed with arbitrary numerical precision using Auto-MPFT.
Theorem 8. Given a sufficiently small tolerance ùúñ>0, the esti-
mated Fourier coefficient E(ÀÜùíÇ)in (4) satisfies
‚à•ÀÜùíÇ‚àíE( ÀÜùíÇ)‚à•BùùÅ,ùë¥‚â§‚à•ùíÇ‚à•1¬∑(2ùê∑‚àí1)ùúñ,
where‚à•¬∑‚à•ùëÖdenotes the uniform norm restricted to set ùëÖ‚äÜRùê∑.‚ñ°
Proof. See Supplement A.3. ‚ñ°Table 1: Summary of datasets.
Dataset Type # of Images Size
{Sùëõ}15
ùëõ=8Synthetic 1K 2ùëõ√ó2ùëõ
Cityscapes1Real-world 5K 2048√ó1024
ADE20K2Real-world 20K 2048√ó2048
DF2K3Real-world 3K 2040√ó1536
RiceLeaf4Real-world 3.3K 3120√ó3120
Bird5Real-world 306 6000√ó4000
4 Experiments
Through experiments, we answer the following questions:
Q1Running time (Section 4.2). How rapidly does Auto-MPFT
compute a part of Fourier coefficients compared to baselines
without compromising accuracy?
Q2Automatic hyperparameter selection (Section 4.3). How
accurately and quickly does the optimization-based algorithm
find the optimal hyperparameter of Auto-MPFT?
Q3Impact of varying precision (Section 4.4). What impact does
varying precision settings have on the runtime of Auto-MPFT?
4.1 Experimental Setup
Machine. Our system utilizes an Intel Core i7-10700KF @ 3.80GHz
processor paired with 32GB of RAM.
Datasets. Although our proposed method can be applied to any
multidimensional data, we focus our experiments on two-dimensional
image datasets for clarity of presentation. Table 1 summarizes the
datasets used in our experiments. For ùëõ=8,¬∑¬∑¬∑,15,Sùëõcontains
1,000 matrices of size 2ùëõ√ó2ùëõwith elements being random real num-
bers ranging from 0to1. Cityscapes and ADE20K offer a wide range
of indoor and outdoor scene images with detailed scene segmenta-
tion labels, supporting semantic segmentation research. DF2K is
an image dataset for image super-resolution and restoration tasks
which is composed of around 3,000 2k resolution images. RiceLeaf
contains about 3,300 4k images of rice leaves for rice disease de-
tection. Bird is a dataset for bird species classification task and
contains 306 high-resolution images of birds. Note that the images
in each dataset were resized to the same resolution.
Baselines. We compare Auto-MPFT with PFT and Pruned FFT
as well as optimized FFT libraries, FFTW and Intel Math Kernel
Library. All of the methods are implemented using C++.
(1)FFTW: FFTW6[11,12] is among the fastest publicly available
FFT implementations with hardware-specific optimizations. We
employ the optimized version of FFTW 3.3.5, without including
the pre-processing for configuration as the run-time cost.
(2)MKL: Intel Math Kernel Library7(MKL), known for its opti-
mized mathematical functions such as FFT, often outperforms
FFTW in terms of running time. We conduct all the experiments
using an Intel processor to ensure optimal performance.
1https://www.cityscapes-dataset.com/
2https://groups.csail.mit.edu/vision/datasets/ADE20K/
3https://www.kaggle.com/datasets/thaihoa1476050/df2k-ost
4https://www.kaggle.com/datasets/shayanriyaz/riceleafs
5https://www.kaggle.com/datasets/akash2907/bird-species-classification
6http://www.fftw.org/index.html
7https://software.intel.com/mkl
 
2334KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain Yong-chan Park, Jongjin Kim, and U Kang
(3)Pruned FFT: Pruned FFT8[2,16,17,28,30] is a pruned variant
of FFT specialized for rapid computation of specific part of an
output, utilizing FFTW as a subroutine.
(4)PFT: PFT9[20] is the current state-of-the-art algorithm for one-
dimensional partial Fourier transform. For multidimensional
data, PFT is applied for each axis of the data.
Measure. We opt for single-precision floating-point format for all
experiments. The tolerance ùúñis adjusted to maintain a relative ‚Ñì2
error below 10‚àí6, thereby ensuring that the estimated coefficients
possess at least 6 significant figures across all methods. Explicitly,
Relative‚Ñì2Error=‚àöÔ∏Ñ√ç
ùëö‚ààB|ÀÜùëéùëö‚àíE( ÀÜùëé)ùëö|2
√ç
ùëö‚ààB|ÀÜùëéùëö|2<10‚àí6,
where ÀÜùíÇis the actual Fourier coefficient, E(ÀÜùíÇ)is the estimation of
ÀÜùíÇ, andBis the target range.
4.2 Running Time (Q1)
The running time of Auto-MPFT is measured across synthetic and
real-world datasets, with variations in input and output sizes.
4.2.1 Synthetic Datasets. We generate 1,000 random synthetic ma-
trices of size 2ùëõ√ó2ùëõfor eachùëõ=8,¬∑¬∑¬∑,15, and evaluate the average
running time of Auto-MPFT and competitors for all the matrices
with different settings.
Running time vs. input size. We fix the target range to be
26√ó26Fourier coefficients centered at the origin and evaluate the
average running time vs. input sizes 28√ó28,¬∑¬∑¬∑,215√ó215. In Figure
3(a), the running time of the five algorithms is illustrated concerning
varying input sizes. We observe that Auto-MPFT outperforms the
baselines in most cases where the output has a sufficiently smaller
size than the input. As a result, Auto-MPFT achieves a speedup of
up to 4.7√ócompared to the baselines. Note that when ùëÄis very
close toùëÅ, the time cost of Auto-MPFT tends to ùëÇ(ùëÅ+ùëÅlogùëÅ)
according to Theorem 6, thus it exhibits a slightly slower speed
than FFT that has an ùëÇ(ùëÅlogùëÅ)time complexity.
Running time vs. output size. In the next setting, we fix the
input size to ùëÅ=215√ó215and evaluate the average running time
vs. output sizes 25√ó25,¬∑¬∑¬∑,213√ó213. Figure 3(b) shows the results,
where Auto-MPFT consistently outperforms PFT and Pruned FFT,
achieving up to 3.3√óspeedup. We also observe that the running
times of the full FFT methods (MKL and FFTW) do not benefit from
the information of output size.
4.2.2 Real-World Datasets. We evaluate Auto-MPFT on the five
real-world datasets with output sizes 24√ó24,¬∑¬∑¬∑,28√ó28for
Cityscapes, ADE20K, and DF2K, and 24√ó24,¬∑¬∑¬∑,29√ó29for Rice-
Leaf and Bird. As illustrated in Figure 4, Auto-MPFT outperforms
the competitors across all datasets, delivering speedups of up to
7.6√ó. Notably, PFT shows low efficiency especially when the size
of the input is relatively small (Cityscapes, ADE20K, and DF2K),
which is not the case for Auto-MPFT. These results clearly show
the robustness of Auto-MPFT in diverse real-world settings.
8http://www.fftw.org/pruned.html
9https://github.com/snudatalab/PFT
2829210211212213214215
Data Points (log scale)101
100Performance (log scale)
Model Performance Comparison
Auto-MPFT (proposed) MKL FFTW PFT Pruned FFT
2829210211212213214215
Input size101
100101102103Running time (ms)
4.7x(
a) Running time vs. input size
2526272829210211212213
Output size272829210211212Running time (ms)
 3.3x (
b) Running time vs. output size
Figure 3: (a) Running time vs. input size for output size 26√ó26,
and (b) running time vs. output size for input size 215√ó215.
The x-axis is the length of one axis of data. To ensure the
same precision across all methods, we have standardized the
relative error to be strictly below 10‚àí6. Auto-MPFT consis-
tently outperforms the partial Fourier transform methods,
PFT and Pruned FFT. In addition, the smaller the output size
is, Auto-MPFT becomes more efficient than MKL and FFTW.
4.3 Automatic Hyperparameter Selection (Q2)
4.3.1 Accuracy of Optimization Algorithm. To evaluate the accu-
racy of our optimization algorithm for automatic hyperparameter
selection, we find the ground-truth optimal value of ùëùfor the syn-
thetic datasets{Sùëõ}15
ùëõ=8with varying ùëÄ, and compare it with the
estimated ÀÜùëùby our method. Table 2 shows that our algorithm accu-
rately finds the optimal value of ùëùin the majority of cases, and in
instances where it deviates, the margin of error remains minimal.
It is evident from these results that our optimization algorithm can
effectively replace manual processes with little sacrifice in accuracy.
4.3.2 Running Time of Optimization Algorithm. We further validate
the efficacy of our optimization algorithm by comparing its time
cost for selecting the optimal hyperparameter to that of the manual
search process. To this end, we fix the output size to 28√ó28and vary
the input size from 29√ó29to215√ó215. Table 3 demonstrates that
the automatic algorithm by Auto-MPFT achieves remarkably faster
processing times compared to the manual process. This discrep-
ancy arises because the manual process necessitates executing the
entire algorithm for each ùëùto determine its optimal value, whereas
Auto-MPFT simplifies the process by efficiently solving a convex op-
timization problem. It is also worth mentioning that the discrepancy
becomes more significant with larger input sizes.
4.4 Impact of Varying Precision (Q3)
Recall that Auto-MPFT offers the flexibility to set any numerical pre-
cision (Theorem 8). We investigate the trade-off between precision
and running time of Auto-MPFT by adjusting the tolerance ùúñ. For a
fixed input size 215√ó215, we vary the precision target from 10‚àí6to
10‚àí4or10‚àí2across various output sizes. Table 4 shows the results,
with the improvement of running times for each setting enclosed
in parentheses. The reduction reaches up to 21.2% or 49.8% when
the precision is relaxed to 10‚àí4or10‚àí2, respectively. This indicates
that one could gain advantages from the compromise, particularly
when speed is crucial despite a slight trade-off in precision.
 
2335Fast Multidimensional Partial Fourier Transform with Automatic Hyperparameter Selection KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain
2829210211212213214215
Data Points (log scale)101
100Performance (log scale)
Model Performance Comparison
Auto-MPFT (proposed) MKL FFTW PFT Pruned FFT
2425262728
Output size23
22
21
2021Running time (ms)
7.6x
(
a) Cityscapes
2425262728
Output size22
21
202122Running time (ms)
5.7x (
b) ADE20K
2425262728
Output size22
21
202122Running time (ms)
6.9x (
c) DF2K
242526272829
Output size20212223Running time (ms)
2.8x (
d) RiceLeaf
242526272829
Output size22232425Running time (ms)
2.6x (
e) Bird
Figure 4: Running time vs. output size for the real-world datasets, where the x-axis is the length of one axis of the target range.
We have standardized the relative error of all methods to be strictly below 10‚àí6. Our proposed Auto-MPFT exhibits superior
performance across all datasets, especially in cases where the output has a sufficiently smaller size than the input.
Table 2: Validation of our optimization algorithm for auto-
matic hyperparameter search. Entries without parentheses
denote that our estimate ÀÜùëùequals to the ground-truth ùëù, and
those with parentheses show both values in the form ÀÜùëù(ùëù).
Auto-MPFT successfully detects the optimal value in most
scenarios, with minor errors occurring infrequently.
Output
sizeInput
size
28√ó229√ó2210√ó2211√ó2212√ó2213√ó2214√ó2215√ó2
26√ó2624252526262728(27)29(28)
27√ó2725252626272728(27) 29
28√ó28- 26262627282829
29√ó29-
- 272727282929
210√ó210- - - 27(28) 28282929
211√ó211- - - - 28(29) 2929210
212√ó212- - - - - 29(210) 210210
213√ó213- - - - - - 210(211) 211
Table 3: Comparison of running time ( ùùÅs) for finding the
optimal hyperparameter ùëùusing our optimization algorithm
(Auto-MPFT) vs. manual search. Manual-best denotes finding
the optimal value in a single attempt, whereas Manual-worst
involves testing all divisors of 2ùëõexcept 1and 2ùëõ. Auto-MPFT
significantly outperforms the manual search process.
2ùëõ√ó2ùëõA
uto-MPFT Manual-best Manual-worst
29√ó293.596 63.30
860.9
210√ó2103.431 70.39 1273.3
211√ó2112.829 85.94 2083.7
212√ó2122.225 60.13 3638.6
213√ó2131.653 79.34 6707.4
214√ó2141.626 116.27 12508.7
215√ó2152.971 124.26 24113.0
5
Conclusions
We propose Auto-MPFT (Automatic Multidimensional Partial Fourier
Transform), an efficient and accurate method for computing a part
of Fourier coefficients with automatic hyperparameter selection.
Auto-MPFT decomposes the original DFT into small sub-blocks
and approximates some of trigonometric functions by ChebyshevTable 4: Average running time (ms) of Auto-MPFT with input
size 215√ó215and different precision settings. Notably, we ob-
serve up to 49.8% improvement in running time when preci-
sion requirements are relaxed, offering a beneficial trade-off,
particularly when prioritizing fast evaluations.
Output
sizePr
ecision
10‚àí610‚àí410‚àí2
25√ó25133.7
131.0 (2.0%) 126.7 (5.2%)
26√ó26135.1 132.3 (2.0%) 127.6 (5.6%)
27√ó27140.8 138.3 (1.8%) 133.5 (5.2%)
28√ó28142.3 139.6 (1.9%) 135.1 (5.1%)
29√ó29169.5 161.3 (4.9%) 148.1 (12.6%)
210√ó210208.3 188.1 (9.7%) 158.8 (23.8%)
211√ó211369.1 290.9 (21.2%) 201.1 (45.5%)
212√ó212905.9 732.5 (19.1%) 463.0 (48.9%)
213√ó2133012.5 2465.8 (18.1%) 1510.9 (49.8%)
polynomials, reducing the arithmetic cost. Furthermore, we present
an efficient optimization algorithm for finding the optimal hyperpa-
rameter of Auto-MPFT. Experiments demonstrate that Auto-MPFT
outperforms the state-of-the-art baseline models, delivering up to
7.6√óspeedup without compromising accuracy. We also illustrate
the efficacy of our convex optimization-based algorithm in select-
ing the optimal hyperparameter of Auto-MPFT, which leads to a
significant reduction in the additional cost attributed to hyperpa-
rameter search. Future tasks involve enhancing the execution of
Auto-MPFT through additional optimization.
Acknowledgments
This work was supported by the National Research Foundation
of Korea (NRF) funded by MSIT(2022R1A2C3007921), Institute of
Information & communications Technology Planning & Evaluation
(IITP) grant funded by the Korea government (MSIT) [No.2020-
0-00894, Flexible and Efficient Model Compression Method for
Various Applications and Environments], [No.RS-2021-II211343,
Artificial Intelligence Graduate School Program (Seoul National
University)], and [No.RS-2021-II212068, Artificial Intelligence Inno-
vation Hub (Artificial Intelligence Institute, Seoul National Univer-
sity)]. U Kang is the corresponding author.
 
2336KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain Yong-chan Park, Jongjin Kim, and U Kang
References
[1]Milton Abramowitz, Irene A Stegun, et al .1972. Handbook of mathematical
functions: with formulas, graphs, and mathematical tables. Vol. 55. National
bureau of standards Washington, DC.
[2]Nir Ailon and Edo Liberty. 2009. Fast dimension reduction using Rademacher
series on dual BCH codes. Discrete & Computational Geometry 42, 4 (2009), 615.
[3]Stefan Banach. 1922. Sur les op√©rations dans les ensembles abstraits et leur
application aux √©quations int√©grales. Fund. math 3, 1 (1922), 133‚Äì181.
[4]C Boncelet. 1986. A rearranged DFT algorithm requiring N 2/6 multiplications.
IEEE Trans. Acoust. Speech Signal Process. 34, 6 (1986).
[5]E Oran Brigham. 1988. The fast Fourier transform and its applications. Prentice-
Hall, Inc.
[6]C Sidney Burrus and TW Parks. 1985. DFT/FFT and Convolution Algorithms.
Citeseer.
[7] Neal L Carothers. 1998. A short course on approximation theory. (1998).
[8]Wen-Hsiung Chen, CH Smith, and Sam Fralick. 1977. A fast computational
algorithm for the discrete cosine transform. IEEE Transactions on communications
25, 9 (1977), 1004‚Äì1009.
[9]James W Cooley and John W Tukey. 1965. An algorithm for the machine calcula-
tion of complex Fourier series. Mathematics of computation 19, 90 (1965).
[10] W. Fraser. 1965. A Survey of Methods of Computing Minimax and Near-Minimax
Polynomial Approximations for Functions of a Single Independent Variable. J.
ACM 12, 3 (1965), 295‚Äì314.
[11] Matteo Frigo and Steven G Johnson. 1998. FFTW: An adaptive software archi-
tecture for the FFT. In Proceedings of the 1998 IEEE International Conference on
Acoustics, Speech and Signal Processing, ICASSP‚Äô98 (Cat. No. 98CH36181), Vol. 3.
IEEE, 1381‚Äì1384.
[12] M. Frigo and S. G. Johnson. 2005. The Design and Implementation of FFTW3.
Proc. IEEE 93, 2 (2005), 216‚Äì231.
[13] Gerald Goertzel. 1958. An algorithm for the evaluation of finite trigonometric
series. The American Mathematical Monthly 65, 1 (1958), 34‚Äì35.
[14] AN Hossen, Ulrich Heute, OV Shentov, and SK Mitra. 1995. Subband DFT Part II:
accuracy, complexity and applications. Signal Processing 41, 3 (1995), 279‚Äì294.
[15] Xiaodi Hou and Liqing Zhang. 2007. Saliency Detection: A Spectral Residual
Approach. In CVPR. IEEE Computer Society.
[16] J Markel. 1971. FFT pruning. IEEE transactions on Audio and Electroacoustics 19,
4 (1971), 305‚Äì311.
[17] K Nagai. 1986. Pruning the decimation-in-time FFT algorithm with frequency
shift. IEEE Trans. Acoust. Speech Signal Process. 34, 4 (1986), 1008‚Äì1010.
[18] Humberto Ochoa-Dominguez and Kamisetty Ramamohan Rao. 2019. Discrete
Cosine Transform. CRC Press.
[19] Alan V Oppenheim. 1999. Discrete-time signal processing. Pearson Education
India.
[20] Yong-chan Park, Jun-Gi Jang, and U Kang. 2021. Fast and accurate partial fourier
transform for time series data. In Proceedings of the 27th ACM SIGKDD Conference
on Knowledge Discovery & Data Mining. 1309‚Äì1318.
[21] Peng Qi, Juan Cao, Tianyun Yang, Junbo Guo, and Jintao Li. 2019. Exploiting
multi-domain visual information for fake news detection. In ICDM. IEEE.
[22] Faraz Rasheed, Peter Peng, Reda Alhajj, and Jon G. Rokne. 2009. Fourier Trans-
form Based Spatial Outlier Mining. In IDEAL, Vol. 5788. Springer, 317‚Äì324.
[23] Hansheng Ren, Bixiong Xu, Yujing Wang, Chao Yi, Congrui Huang, Xiaoyu Kou,
Tony Xing, Mao Yang, Jie Tong, and Qi Zhang. 2019. Time-Series Anomaly
Detection Service at Microsoft. In KDD. ACM, 3009‚Äì3017.
[24] Herbert Robbins. 1955. A remark on Stirling‚Äôs formula. The American mathemat-
ical monthly 62, 1 (1955), 26‚Äì29.
[25] Tim Schl√ºter and Stefan Conrad. 2010. An Approach for Automatic Sleep Stage
Scoring and Apnea-Hypopnea Detection. In ICDM. IEEE, 1007‚Äì1012.
[26] OV Shentov, SK Mitra, Ulrich Heute, and AN Hossen. 1995. Subband DFT Part I:
Definition, interpretation and extensions. Signal Processing 41, 3 (1995), 261‚Äì277.
[27] Sheng Shi, Runkai Yang, and Haihang You. 2017. A new two-dimensional Fourier
transform algorithm based on image sparsity. In ICASSP. IEEE, 1373‚Äì1377.
[28] D Skinner. 1976. Pruning the decimation in-time FFT algorithm. IEEE Trans.
Acoust. Speech Signal Process. 24, 2 (1976), 193‚Äì194.
[29] Georgey S Smirnov and Roman G Smirnov. 1999. Best uniform approximation of
complex-valued functions by generalized polynomials having restricted ranges.
Journal of approximation theory 100, 2 (1999), 284‚Äì303.
[30] Henrik V Sorensen and C Sidney Burrus. 1993. Efficient computation of the
DFT with only a subset of input or output points. IEEE transactions on signal
processing 41, 3 (1993), 1184‚Äì1200.
[31] Ting Hei Wan, Chi Wai Tsang, King Hui, and Edward Chung. 2023. Anomaly
detection of train wheels utilizing short-time Fourier transform and unsupervised
learning algorithms. Engineering Applications of Artificial Intelligence 122 (2023),
106037.
[32] George Neville Watson. 1922. A treatise on the theory of Bessel functions. Vol. 3.
The University Press.
[33] Liheng Zhang, Charu Aggarwal, and Guo-Jun Qi. 2017. Stock price prediction
via discovering multi-frequency trading patterns. In KDD. ACM, 2141‚Äì2149.A Supplement
A.1 Proof of Lemma 2
Proof. We first show that for ùëü‚â•2
ùúÇ(ùëü)‚â§‚àö
17
2‚àëÔ∏Å
ùëõ‚â•0ùêΩùëü+2ùëõ(ùëêùúã). (13)
For evenùëü, it is straightforward from (10) that
ùúÇ(ùëü)‚â§‚àëÔ∏Å
ùëõ‚â•0|2ùëñùëü+ùëõùêΩùëü+ùëõ(ùëêùúã)cos(ùúã(ùëü+ùëõ)/2)|
=2‚àëÔ∏Å
ùëõ‚â•0ùêΩùëü+2ùëõ(ùëêùúã)‚â§‚àö
17
2‚àëÔ∏Å
ùëõ‚â•0ùêΩùëü+2ùëõ(ùëêùúã).
For oddùëü, letùúÉùëü=ùúã(ùëü‚àí1)/2ùëü. Using the recurrence relation (9),
we have
ùúÇ(ùëü)
2=‚àëÔ∏Å
ùëõ‚â•ùëüùëñùëõùêΩùëõ(ùëêùúã)cosùëõùúÉùëü
=‚àëÔ∏Å
ùëõ‚â•0ùëñùëõùêΩùëü+ùëõ(ùëêùúã)cos(ùëü+ùëõ)ùúÉùëü
=‚àëÔ∏Å
ùëõ‚â•0ùëñ2ùëõùêΩùëü+2ùëõ(ùëêùúã)cos(ùëü+2ùëõ)ùúÉùëü
+ùëñ2ùëõ+1ùêΩùëü+2ùëõ+1(ùëêùúã)cos(ùëü+2ùëõ+1)ùúÉùëü
=‚àëÔ∏Å
ùëõ‚â•0ùëñ2ùëõùêΩùëü+2ùëõ(ùëêùúã)cos(ùëü+2ùëõ)ùúÉùëü
+ùëñ2ùëõ+1ùê∂ùêΩùëü+2ùëõ(ùëêùúã)+ùêΩùëü+2ùëõ+2(ùëêùúã)
ùëü+2ùëõ+1cos(ùëü+2ùëõ+1)ùúÉùëü.
We separate the ùêΩùëü(ùëêùúã)term from the summand as follows:
ùúÇ(ùëü)
2=
cosùëüùúÉùëü+ùëñùê∂cos(ùëü+1)ùúÉùëü
ùëü+1
ùêΩùëü(ùëêùúã)
+‚àëÔ∏Å
ùëõ‚â•1ùëñ2ùëõ
cos(ùëü+2ùëõ)ùúÉùëü+ùëñùê∂cos(ùëü+2ùëõ+1)ùúÉùëü
ùëü+2ùëõ+1
‚àícos(ùëü+2ùëõ‚àí1)ùúÉùëü
ùëü+2ùëõ‚àí1
ùêΩùëü+2ùëõ(ùëêùúã).
Becauseùëü‚â•2is odd andùê∂/(ùëü+1)‚â§1/2, the magnitude of the
first coefficient satisfiescosùëüùúÉùëü+ùëñùê∂cos(ùëü+1)ùúÉùëü
ùëü+1=1+ùëñùê∂
ùëü+1sinùúã
2ùëü
‚â§1+ùëñ
2sinùúã
6=1+ùëñ
4=‚àö
17
4.
For the magnitude of remainder coefficients, we use the trigono-
metric identity
cos(ùëü+2ùëõ¬±1)ùúÉùëü=cos(ùëü+2ùëõ)ùúÉùëücosùúÉùëü‚àìsin(ùëü+2ùëõ)ùúÉùëüsinùúÉùëü,
which yields
cos(ùëü+2ùëõ)ùúÉùëü+ùëñùê∂
ùëü+1
‚Ñé‚àí(ùëõ,ùëü)cos(ùëü+2ùëõ)ùúÉùëücosùúÉùëü
‚àí‚Ñé+(ùëõ,ùëü)sin(ùëü+2ùëõ)ùúÉùëüsinùúÉùëü,(14)
 
2337Fast Multidimensional Partial Fourier Transform with Automatic Hyperparameter Selection KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain
where‚Ñé¬±(ùëõ,ùëü)‚âîùëü+1
ùëü+2ùëõ+1¬±ùëü+1
ùëü+2ùëõ‚àí1. Since|ùëécosùúÉùëü+ùëèsinùúÉùëü| ‚â§‚àö
ùëé2+ùëè2forùëé,ùëè‚ààR, (14) becomes

cos2(ùëü+2ùëõ)ùúÉùëü+ùê∂2
(ùëü+1)2
‚Ñé‚àí(ùëõ,ùëü)cos(ùëü+2ùëõ)ùúÉùëücosùúÉùëü
‚àí‚Ñé+(ùëõ,ùëü)sin(ùëü+2ùëõ)ùúÉùëüsinùúÉùëü21/2
‚â§maxùëõ,ùëü
cos2(ùëü+2ùëõ)ùúÉùëü+ùê∂2
(ùëü+1)2
‚Ñé2
‚àí(ùëõ,ùëü)cos2(ùëü+2ùëõ)ùúÉùëü
+‚Ñé2
+(ùëõ,ùëü)sin2(ùëü+2ùëõ)ùúÉùëü1/2
.
Forùëõ‚â•1,
|‚Ñé+(ùëõ,ùëü)|‚â§ 1+1=2,|‚Ñé‚àí(ùëõ,ùëü)|=2(ùëü+1)
ùëü2+4ùëõùëü+4ùëõ2‚àí1‚â§2
ùëü+3‚â§1
2.
Thus, the magnitude of remainder coefficients is bounded by
maxùëõ,ùëü‚àöÔ∏Ñ
1+1
42
cos2(ùëü+2ùëõ)ùúÉùëü+sin2(ùëü+2ùëõ)ùúÉùëü
=maxùëõ,ùëü‚àöÔ∏Ç
1+1
42cos2(ùëü+2ùëõ)ùúÉùëü‚â§‚àö
17
4.
This implies that
ùúÇ(ùëü)
2‚â§‚àö
17
4ùêΩùëü(ùëêùúã)+‚àëÔ∏Å
ùëõ‚â•1‚àö
17
4ùêΩùëü+2ùëõ(ùëêùúã),
so the ineqaulity (13). We now use the following inequality [ 32] to
complete the proof:
ùêΩùëõ(2ùë§)‚â§ùë§ùëõ
ùëõ!ùëí‚àíùë§2
ùëõ+1
for a non-negative integer ùëõandùë§>0. From (13), we obtain
ùúÇ(ùëü)‚â§‚àö
17
2‚àëÔ∏Å
ùëõ‚â•0ùêΩùëü+2ùëõ(ùëêùúã)
‚â§‚àö
17
2‚àëÔ∏Å
ùëõ‚â•0ùê∂ùëü+2ùëõ
(ùëü+2ùëõ)!ùëí‚àíùê∂2
ùëü+2ùëõ+1
=‚àö
17
2ùê∂ùëü
ùëü!ùëí‚àíùê∂2
ùëü+1
1+ùê∂2
(ùëü+1)(ùëü+2)ùëí2ùê∂2
(ùëü+1)(ùëü+2)
+ùê∂4
(ùëü+1)(ùëü+2)(ùëü+3)(ùëü+4)ùëí4ùê∂2
(ùëü+1)(ùëü+5)+¬∑¬∑¬∑
‚â§‚àö
17
2ùê∂ùëü
ùëü!ùëí‚àíùê∂2
ùëü+1
1+ùê∂2
(ùëü+1)2ùëí2ùê∂2
(ùëü+1)2+ùê∂4
(ùëü+1)4ùëí4ùê∂2
(ùëü+1)2+¬∑¬∑¬∑
=‚àö
17
2ùê∂ùëü
ùëü!ùëí‚àíùê∂2
ùëü+1
1‚àíùê∂2
(ùëü+1)2ùëí2ùê∂2
(ùëü+1)2‚àí1
.
Thus, it follows from ùê∂2/(ùëü+1)2‚â§1/4that
ùúÇ(ùëü)‚â§‚àö
17
2ùê∂ùëü
ùëü!ùëí‚àíùê∂2
ùëü+1
1‚àí1
4ùëí2
4‚àí1
=2‚àö
17
4‚àí‚àöùëíùê∂ùëü
ùëü!ùëí‚àíùê∂2
ùëü+1,
hence the proof. ‚ñ°A.2 Proof of Theorem 3
Proof. Note that(ùëÅ+ùëùlogùëù+ùëÄ)ùëüis convex and non-decreasing
for eachùëù,ùëü‚â•1. Therefore, it is sufficient to show that ùëù(ùëü)is a
convex function with respect to ùëü. Indeed, we prove that ùëù(ùëü)is
logarithmically convex for ùëü‚â•1, from which the convexity follows.
We first show that
ùëü‚Ü¶‚Üílog(ùõºùúñùëü!)‚àí1
ùëü
is convex. It is easy to check that the function log(ùõºùúñ)‚àí1/ùëü=
‚àí(logùõºùúñ)/ùëüis convex for ùëü>0since 0<ùõº,ùúñ<1. We can also
show that logùëü!‚àí1/ùëü=‚àí(logùëü!)/ùëüis a convex function considering
its second derivative
ùëë2
ùëëùëü2
‚àílogùëü!
ùëü
=‚àí2 logùëü!+2ùëüùúì(ùëü+1)‚àíùëü2ùúì‚Ä≤(ùëü+1)
ùëü3, (15)
whereùúì(ùë•)=ùëë
ùëëùë•logŒì(ùë•)is the digamma function [ 1]. The follow-
ing property is often useful:
logùë•‚â§ùúì(ùë•+1)=‚àíùõæ+‚àëÔ∏Å
ùëò‚â•11
ùëò‚àí1
ùë•+ùëò
‚â§log(ùë•+1),‚àÄùë•>0,
whereùõæis the Euler-Mascheroni constant. We observe that the
numerator of (15) is non-negative on ùëü‚â•0because it attains its
minimum value 0atùëü=0due to the following inequality:
ùëë
ùëëùëü(‚àí2 logùëü!+2ùëüùúì(ùëü+1)‚àíùëü2ùúì‚Ä≤(ùëü+1))
=‚àíùëü2ùúì‚Ä≤‚Ä≤(ùëü+1)=‚àëÔ∏Å
ùëò‚â•12ùëü2
(ùëü+ùëò)3‚â•0
for allùëü‚â•0. Since the product of two logarithmically convex func-
tions is also logarithmically convex, we conclude that (ùõºùúñùëü!)‚àí1/ùëü=
(ùõºùúñ)‚àí1/ùëü√óùëü!‚àí1/ùëüis logarithmically convex for ùëü>0.
We use the above result to prove that ùëü‚Ü¶‚Üí(ùõºùúñùëü!)‚àí1
ùëüùëí‚àí1
ùëü(ùëü+1)(ùõºùúñùëü!)2/ùëü
is a convex function. Let ùë¢(ùëü)‚âî(ùõºùúñùëü!)‚àí1/ùëü. Our goal is to show
that the following function is convex:
ùëü‚Ü¶‚Üílogùë¢(ùëü)‚àí1
ùëü(ùëü+1)ùë¢(ùëü)2. (16)
A simple calculus shows that
ùëë2
ùëëùëü2logùë¢(ùëü)=2ùë£(ùëü)‚àíùëüùúì‚Ä≤(ùëü+1)
ùëü2,
ùëë2
ùëëùëü21
ùëü(ùëü+1)ùë¢(ùëü)2=2(3ùëü2+3ùëü+1)
ùëü2(ùëü+1)2+2ùúì‚Ä≤(ùëü+1)
ùëü
‚àí4(3ùëü+2)
ùëü2(ùëü+1)ùë£(ùëü)+4
ùëü2ùë£(ùëü)21
ùëü(ùëü+1)ùë¢(ùëü)2,
whereùë£(ùëü)‚âîlogùë¢(ùëü)+ùúì(ùëü+1). Since we have already shown that
ùëë2
ùëëùëü2logùë¢(ùëü)‚â•0, it is sufficient to consider only when ùëüsatisfies
ùëë2
ùëëùëü21
ùëü(ùëü+1)ùë¢(ùëü)2‚â•0, otherwise the function (16) trivially has a non-
nagative second derivative. For ùëü‚â•1, we have
ùëü(ùëü+1)ùë¢(ùëü)2‚â•1+log(ùëü(ùëü+1)ùë¢(ùëü)2)
‚â•log((ùëü+1)2ùë¢(ùëü)2)
=2(log(ùëü+1)+ logùë¢(ùëü))
‚â•2(ùúì(ùëü+1)+ logùë¢(ùëü))
=2ùë£(ùëü),
 
2338KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain Yong-chan Park, Jongjin Kim, and U Kang
so‚àí1
ùëü(ùëü+1)ùë¢(ùëü)2‚â•‚àí1
2ùë£(ùëü). Also,
ùúì‚Ä≤(ùëü+1)=‚àëÔ∏Å
ùëò‚â•11
(ùëü+ùëò)2‚â§‚à´‚àû
ùëüùëëùë•
ùë•2=1
ùëü.
These inequalities imply that
ùëë2
ùëëùëü2
logùë¢(ùëü)‚àí1
ùëü(ùëü+1)ùë¢(ùëü)2
‚â•2ùë£(ùëü)‚àíùëüùúì‚Ä≤(ùëü+1)
ùëü2‚àí2(3ùëü2+3ùëü+1)
ùëü2(ùëü+1)2+2ùúì‚Ä≤(ùëü+1)
ùëü
‚àí4(3ùëü+2)
ùëü2(ùëü+1)ùë£(ùëü)+4
ùëü2ùë£(ùëü)21
2ùë£(ùëü)
‚â•2ùë£(ùëü)‚àí1
ùëü2‚àí2(3ùëü2+3ùëü+1)
ùëü2(ùëü+1)2+2
ùëü2
‚àí4(3ùëü+2)
ùëü2(ùëü+1)ùë£(ùëü)+4
ùëü2ùë£(ùëü)21
2ùë£(ùëü)
=‚àí(4ùëü2+5ùëü+2)+ùë£(ùëü)(5ùëü2+8ùëü+3)
ùë£(ùëü)ùëü2(ùëü+1)2.
Thus, if we show that ùë£(ùëü)‚â•4/5, thenùë£(ùëü)ùëü2(ùëü+1)2>0, and
‚àí(4ùëü2+5ùëü+2)+ùë£(ùëü)(5ùëü2+8ùëü+3)
‚â•‚àí( 4ùëü2+5ùëü+2)+4
5(5ùëü2+8ùëü+3)=7ùëü+2
5‚â•0,
which proves that (16) is convex. Now, Stirling‚Äôs formula [ 24] im-
plies that
ùëü!‚â§‚àö
2ùúãùëüùëü
ùëíùëü
ùëí1
12ùëü
for allùëü‚â•1. Thus, it follows that
ùëü
ùë£(ùëü)‚àí4
5
=ùëü
‚àí1
ùëülog(ùõºùúñùëü!)+ùúì(ùëü+1)‚àí4
5
‚â•ùëü
‚àí1
ùëülog(ùõºùëü!)+logùëü‚àí4
5
=‚àílog(ùõºùëü!)+ùëülogùëü‚àí4
5ùëü
‚â•‚àílog
ùõº‚àö
2ùúãùëüùëü
ùëíùëü
ùëí1
12ùëü
+ùëülogùëü‚àí4
5ùëü
=‚àílogùõº‚àö
2ùúãùëü‚àíùëülogùëü+ùëü‚àí1
12ùëü+ùëülogùëü‚àí4
5ùëü
=‚àílogùõº‚àö
2ùúãùëü+1
5ùëü‚àí1
12ùëü
‚â•‚àílogùõº‚àö
2ùúãùëü+1
5ùëü‚àí1
12.
Since
ùëë
ùëëùëü
‚àílogùõº‚àö
2ùúãùëü+1
5ùëü‚àí1
12
=‚àí1
2ùëü+1
5,
the function attains its minimum at ùëü=5/2, so
ùëü
ùë£(ùëü)‚àí4
5
‚â•‚àílogùõº‚àö
5ùúã+5
12=0.294377¬∑¬∑¬∑‚â• 0,
orùë£(ùëü)‚â•4/5. This completes the proof. ‚ñ°A.3 Proof of Theorem 8
Proof. Letùë£ùëë=ùëôùëë‚àíùëûùëë/2andPùëë=Pùëüùëë,ùúâ(ùúñ,ùëüùëë)forùëë=1,2,¬∑¬∑¬∑,ùê∑,
andB=BùùÅ,ùë¥. Then, it follows that
‚à•ÀÜùíÇ‚àíE( ÀÜùíÇ)‚à•B
‚â§‚àëÔ∏Åùëé(ùíå)
ùíç√ñ
ùëëùúîùë£ùëëùëöùëë
ùëÅùëë‚àí√ñ
ùëëùúîùë£ùëëùúáùëë
ùëÅùëëPùëë(‚àí2ùë£ùëë(ùëöùëë‚àíùúáùëë)/ùëÅùëë)B
=‚àëÔ∏Å
|ùëé(ùíå)
ùíç|√ñ
ùëëùúîùë£ùëë(ùëöùëë‚àíùúáùëë)
ùëÅùëë‚àí√ñ
ùëëPùëë(‚àí2ùë£ùëë(ùëöùëë‚àíùúáùëë)/ùëÅùëë)B,
where the summations are over indices ùíå‚àà√é
ùëë[ùëùùëë]andùíç‚àà√é
ùëë[ùëüùëë]. Sinceùëôùëëranges from 0toùëûùëë‚àí1, we have|2ùë£ùëë/ùëÅùëë| ‚â§
2(ùëûùëë/2)/ùëÅùëë=1/ùëùùëë, and therefore ùëÄùëë|2ùë£ùëë/ùëÅùëë|‚â§ùëÄùëë/ùëùùëë‚â§ùúâ(ùúñ,ùëüùëë).
We replace‚àí2ùë£ùëë(ùë•ùëë‚àíùúáùëë)/ùëÅùëëwithùë•‚Ä≤
ùëë:
‚à•ÀÜùíÇ‚àíE( ÀÜùíÇ)‚à•B
‚â§‚àëÔ∏Å
|ùëé(ùíå)
ùíç|√ñ
ùëëùëíùúãùëñùë•‚Ä≤
ùëë‚àí√ñ
ùëëPùëë(ùë•‚Ä≤
ùëë)|ùë•‚Ä≤
ùëë|‚â§ùëÄùëë|2ùë£ùëë/ùëÅùëë|,‚àÄùëë
‚â§‚àëÔ∏Å
|ùëé(ùíå)
ùíç|√ñ
ùëëùëíùúãùëñùë•‚Ä≤
ùëë‚àí√ñ
ùëëPùëë(ùë•‚Ä≤
ùëë)|ùë•‚Ä≤
ùëë|‚â§ùúâ(ùúñ,ùëüùëë),‚àÄùëë.
Now
√ñ
ùëëùëíùúãùëñùë•‚Ä≤
ùëë‚àí√ñ
ùëëPùëë(ùë•‚Ä≤
ùëë)=√ñ
ùëë<ùê∑ùëíùúãùëñùë•‚Ä≤
ùëë
(ùëíùúãùëñùë•‚Ä≤
ùê∑‚àíPùê∑(ùë•‚Ä≤
ùê∑))
+√ñ
ùëë<ùê∑ùëíùúãùëñùë•‚Ä≤
ùëë‚àí√ñ
ùëë<ùê∑Pùëë(ùë•‚Ä≤
ùëë)
Pùê∑(ùë•‚Ä≤
ùê∑).
Using the above equation recursively, we obtain
√ñ
ùëëùëíùúãùëñùë•‚Ä≤
ùëë‚àí√ñ
ùëëPùëë(ùë•‚Ä≤
ùëë)
=ùê∑‚àëÔ∏Å
ùë†=1√ñ
ùëë<ùë†ùëíùúãùëñùë•‚Ä≤
ùëë
(ùëíùúãùëñùë•‚Ä≤
ùë†‚àíPùë†(ùë•‚Ä≤
ùë†))√ñ
ùë†<ùëëPùëë(ùë•‚Ä≤
ùëë)
.
Because|ùë•‚Ä≤
ùëë|‚â§ùúâ(ùúñ,ùëüùëë)for allùëë, we have the following inequality:
√ñ
ùëëùëíùúãùëñùë•‚Ä≤
ùëë‚àí√ñ
ùëëPùëë(ùë•‚Ä≤
ùëë)
‚â§ùê∑‚àëÔ∏Å
ùë†=1√ñ
ùëë<ùë†ùëíùúãùëñùë•‚Ä≤
ùëë¬∑|ùëíùúãùëñùë•‚Ä≤
ùë†‚àíPùë†(ùë•‚Ä≤
ùë†)|¬∑√ñ
ùë†<ùëëPùëë(ùë•‚Ä≤
ùëë)
‚â§ùê∑‚àëÔ∏Å
ùë†=11ùë†‚àí1¬∑ùúñ¬∑(ùúñ+1)ùê∑‚àíùë†=(ùúñ+1)ùê∑‚àí1,
where the second inequality holds since |ùëíùúãùëñùë•‚Ä≤
ùëë|=1and|Pùëë(ùë•‚Ä≤
ùëë)|‚â§
|Pùëë(ùë•‚Ä≤
ùëë)‚àíùëíùúãùëñùë•‚Ä≤
ùëë|+|ùëíùúãùëñùë•‚Ä≤
ùëë|‚â§ùúñ+1. We may assume that the tolerance
is sufficiently small so that ùúñ<2/ùê∑2. Then it is easy to see that
(ùúñ+1)ùê∑‚àí1=ùê∑‚àëÔ∏Å
ùëë=0ùê∑
ùëë
ùúñùëë‚àí1=ùê∑ùúñ+ùê∑‚àëÔ∏Å
ùëë=2ùê∑
ùëë
ùúñùëë
‚â§ùê∑ùúñ+ùê∑‚àëÔ∏Å
ùëë=2ùê∑2
2ùëë‚àí1
ùúñùëë
‚â§ùê∑ùúñ+ùê∑‚àëÔ∏Å
ùëë=21
ùúñùëë‚àí1
ùúñùëë=ùê∑ùúñ+ùê∑‚àëÔ∏Å
ùëë=2ùúñ=(2ùê∑‚àí1)ùúñ.
Thus, we obtain the desired approximation bound of Auto-MPFT:
‚à•ÀÜùíÇ‚àíE( ÀÜùíÇ)‚à•B‚â§√ç|ùëé(ùíå)
ùíç|¬∑(2ùê∑‚àí1)ùúñ=‚à•ùíÇ‚à•1¬∑(2ùê∑‚àí1)ùúñ. ‚ñ°
 
2339