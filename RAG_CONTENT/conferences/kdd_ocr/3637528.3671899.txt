FLea: Addressing Data Scarcity and Label Skew in Federated
Learning via Privacy-preserving Feature Augmentation
Tong Xia
tx229@cam.ac.uk
University of Cambridge
Cambridge, UKAbhirup Ghosh
University of Birmingham
University of Cambridge
Birmingham, UK
Xinchi Qiu
University of Cambridge
Cambridge, UKCecilia Mascolo
University of Cambridge
Cambridge, UK
Abstract
Federated Learning (FL) enables model development by leveraging
data distributed across numerous edge devices without transferring
local data to a central server. However, existing FL methods still face
challenges when dealing with scarce and label-skewed data across
devices, resulting in local model overfitting and drift, consequently
hindering the performance of the global model. In response to these
challenges, we propose a pioneering framework called FLea, incor-
porating the following key components: i)A global feature buffer
that stores activation-target pairs shared from multiple clients to
support local training. This design mitigates local model drift caused
by the absence of certain classes; ii)A feature augmentation ap-
proach based on local and global activation mix-ups for local train-
ing. This strategy enlarges the training samples, thereby reducing
the risk of local overfitting; iii)An obfuscation method to minimize
the correlation between intermediate activations and the source
data, enhancing the privacy of shared features. To verify the superi-
ority of FLea, we conduct extensive experiments using a wide range
of data modalities, simulating different levels of local data scarcity
and label skew. The results demonstrate that FLea consistently out-
performs state-of-the-art FL counterparts (among 13 of the experi-
mented 18 settings, the improvement is over 5%) while concurrently
mitigating the privacy vulnerabilities associated with shared fea-
tures. Code is available at https://github.com/XTxiatong/FLea.git.
CCS Concepts
•Computer methodologies →Machine learning; •Applied
computing→Computers in other domains .
Keywords
Federated learning, data scarcity, label skew, data privacy
ACM Reference Format:
Tong Xia, Abhirup Ghosh, Xinchi Qiu, and Cecilia Mascolo. 2024. FLea:
Addressing Data Scarcity and Label Skew in Federated Learning via Privacy-
preserving Feature Augmentation. In Proceedings of the 30th ACM SIGKDD
Conference on Knowledge Discovery and Data Mining (KDD ’24), August
This work is licensed under a Creative Commons Attribution
International 4.0 License.
KDD ’24, August 25–29, 2024, Barcelona, Spain
©2024 Copyright held by the owner/author(s).
ACM ISBN 979-8-4007-0490-1/24/08
https://doi.org/10.1145/3637528.367189925–29, 2024, Barcelona, Spain. ACM, New York, NY, USA, 11 pages. https:
//doi.org/10.1145/3637528.3671899
1 Introduction
Presently, there are billions of interconnected edge devices, includ-
ing smartphones, tablets, and wearables, generating a continuous
stream of data such as photos, videos, and audio [ 18]. Such data
presents numerous opportunities for meaningful research and ap-
plications. However, the conventional approach of aggregating this
data in a central server is no longer sustainable, as the data can
be sensitive to share and the communication cost associated with
transferring such vast amounts of information can be prohibitive.
Thanks to the advent of Federated Learning (FL), developing models
with data remaining at edge devices becomes feasible [19].
As illustrated in Figure 1, in FL, edge devices, usually referred
to as clients, train local models using their local data. These trained
models are then transmitted to the FL server and aggregated into a
global model for real-world applications [ 22]. However, the char-
acteristics of the data across edge devices can present significant
challenges to FL, mainly because of:
i) Data heterogeneity, specifically label-skewness. As shown in
Figure 1, edge devices may only possess a subset of the global
categories in their acquired datasets. For example, in terms of im-
ages, one mobile user may take photos of cats and indoor decora-
tions, while another user may have images of dogs and outdoor
views. Such label-skewness can result in local model drift: local
models are biased toward the local distribution and struggle to
generalize to the global distribution, leading to a sub-optimal global
model [10, 16, 21].
ii) Local data scarcity. Datasets collected by edge devices are also
limited in size, primarily due to limited data acquisition scenarios
and the difficulty in annotations. As shown in Figure 1, local data
could be much smaller than the desired data to optimize the local
models. In the prominent FL strategy FedAvg [22], lower aggrega-
tion weights are assigned to local models trained on smaller datasets,
indicating their relatively weaker performance and lesser contribu-
tion to the global model. However, in a situation where all clients
possess small-sized datasets, local models can be overfitted to the
training samples and thus struggle to generalize to unseen testing
data, even if from the same distribution. Consequently, aggregating
these models does not improve the global model’s generalization
ability. This, as a result, slows down convergence and negatively
3484
KDD ’24, August 25–29, 2024, Barcelona, Spain Tong Xia, Abhirup Ghosh, Xinchi Qiu, & Cecilia Mascolo
Figure 1: Edge devices as clients in federated learning, where
local data exhibits label skew (presented by different mark-
ers) and scarcity (usually very small in size).
impacts the performance of the global model (a detailed analysis of
the effect of data scarcity is presented in Sec. 2.3).
To fully harness the potential of FL for real-world edge applica-
tions, addressing the two challenges mentioned above is pivotal.
Despite numerous proposed approaches aimed at enhancing FL in
the presence of label skew, we find that the feasibility of these meth-
ods, when confronted with data scarcity, remains an under-explored
area. Methods that involve devising new learning objectives [ 17]
or aggregation strategies [ 36] falter when local data is extremely
scarce, as they struggle to find a balance between local optimiza-
tion and preserving global knowledge. On the other hand, certain
approaches leverage globally shareable information [ 39], such as a
proportion of raw data, which may be effective when the data across
edge devices are scarce and label-skewed. However, these strategies
often come at the cost of sacrificing privacy. In light of this, we
revisit the purpose of information sharing and pose a fundamental
question: Can we generate and share some privacy-preserving
information as a robust proxy for global data distribution to
aid local learning? This, in turn, could alleviate issues of local
overfitting and model drift caused by simultaneous challenges of
data scarcity and label skew.
The shared information, referred to as features in this study,
should satisfy the following critical criteria: (1) To alleviate local
drift caused by label skew, it should cover all categories. (2) To
prevent local overfitting due to data scarcity, it needs to be useful
in extending the local training data. (3) To mitigate privacy risks, it
requires to contain minimal information from the raw data. With
these considerations in mind, we introduce a novel method FLea (FL
with f eature sharing). In FLea, the shared features are activations
from an intermediate layer of the model and the associated labels.
Specifically, we maintain a global feature buffer that includes fea-
tures from multiple clients, ensuring coverage of all categories. The
shared features are integrated with local data through a mix-up aug-
mentation [ 37] to extend the training samples in the representation
space. Moreover, these activations undergo a level of “obfuscation”
by reducing their distance correlation with the source data [ 32],
while maintaining their classification characteristics through a cus-
tomized loss function during training.
Overall, this paper has the following contributions:
•The first in-depth study on a common but under-explored
scenario in FL, where all the clients possess extremely scarce
and label-skewed data. We find that model overfitting caused
by data scarcity is under-looked by existing methods.•A novel framework FLea to address both the data scarcity and
label skew challenges at the same time in FL. The key idea of
FLea is to share privacy-preserving features to augment local
data for model training.
•Extensive experiments with different levels of label skew and
data scarcity show that FLea consistently outperforms the
state-of-the-art baselines. We also empirically demonstrate
that FLea mitigates privacy risk measured by information
leakage from the shared features.
2 Background
2.1 Fundamentals of FL
This study focuses on learning a global model from a set of col-
laborating clients, 𝐾, with each client 𝑘containing a small and
label-skewed local dataset D𝑘. The FL system works in synchro-
nous rounds. At the start of each round 𝑡, the FL server broadcasts
the current global model parameters 𝜃(𝑡)to the randomly selected
subset of the clients K(𝑡)⊆𝐾. Each client 𝑘∈K(𝑡)takes a few
optimization steps (e.g., using stochastic gradient descend) starting
from𝜃(𝑡), resulting in an updated local model 𝜃(𝑡)
𝑘. The local opti-
mization aims to minimize the loss function Lon local dataD𝑘, i.e.,
𝜃𝑘=arg min𝜃L(𝜃,D𝑘|𝜃(𝑡))(Lis the learning objective which is
usually a cross-entropy loss for classification). Each round 𝑡ends
with model aggregation to derive the new global model 𝜃(𝑡+1). The
most basic and popular aggregation method, FedAvg [22] averages
the model parameters weighted by the fraction of local data size in
the clients,
𝜃(𝑡+1)=∑︁
𝑘∈K(𝑡)|D𝑘|Í
𝑘∈K(𝑡)|D𝑘|𝜃𝑘. (1)
2.2 Addressing Label Skew in FL
To mitigate the client drift caused by label skew, many methods
have been proposed to improve the learning objective L. In addi-
tion to classification loss, FedProx [16] also regulates the discrep-
ancy between the local and global model parameters. MOON [15]
leverages constructive learning to maximize the distance between
low-dimensional features and other classes, thereby improving fea-
ture learning. To compensate for missing categories in the local
data, FedDecorr [26] introduces regularization of the dimensional
collapse in FL models, while FedNTD [13] penalizes changes in the
non-ground-truth class logit distribution predicted by global and
local models. FedLC [38] directly re-scales the logits to derive a
calibrated loss. Similarly, FedRS restricts the Softmax to limit the
update of missing classes.
Data augmentations have been explored for label skewed FL.
[39] shows that sharing a small proportion of local data globally,
alongside the model parameters, can significantly enhance FedAvg
(in later sections, we name this method FedData ). Nevertheless,
collecting private data would compromise the privacy-preservation
benefits of FL. Therefore, other global proxies that are less privacy-
sensitive than raw data are explored. FedMix [35] and FedBR [7]
average data over mini-batches and share this aggregated data glob-
ally, while CCVR [21] shares low-dimensional features with the
server to calibrate the global model on the server side. These low-
dimensional features are also known as class prototypes, which are
3485FLea: Addressing Data Scarcity and Label Skew in Federated Learning via Privacy-preserving Feature Augmentation KDD ’24, August 25–29, 2024, Barcelona, Spain
Figure 2: Performance of FL methods with increasing data
scarcity levels (A smaller |D𝑘|indicates a heavier scarcity).
explored to mitigate local classifier bias [ 28].FedGen [20], VHL [ 29],
andFedFed [34] generate data samples through an additional gen-
erative model to aid local learning. Although no raw information
is shared by those two approaches, their performance highly de-
pends on the quantity and quality of synthetic data, usually yielding
marginal gains over FedAvg.
2.3 Data Scarcity in FL
Through the literature review, we have found few studies focusing
on the data scarcity problem in FL. As first observed by [ 14] (cf.
Finding 7), when developing the model with a fixed total number of
training samples, the accuracy of FedAvg andFedProx decreases as
the number of clients increases, leading to a reduction in local data
size per client. Despite the proliferation of FL methods, including
those mentioned earlier (cf. Sec. 2.2), most are evaluated on large
local datasets, each containing thousands of samples. For example,
the commonly used benchmark CIFAR10 contains 50,000training
samples, which are usually distributed among 10to100clients,
resulting in an average local data size of 500to5,000[7,13,17]. In
contrast, in a scarce setting, the average local data size could be
even much smaller, such as 50∼100. This leaves the effectiveness
of existing FL methods in handling data scarcity unclear. While
some studies have presented results in a scarce setting [ 2,40], they
fail to justify whether the performance gain is from alleviating bias
or overfitting caused by data scarcity, thus lacking in providing a
deep understanding.
FedScale introduced the first benchmark featuring thousands of
clients with limited training data [ 12]. However, FedScale primarily
focuses on system efficiency and offers limited insight into algo-
rithm effectiveness. On the contrary, in the following, we conduct
an empirical study and provide insightful observations on how data
scarcity can affect the performance of FL.
2.3.1 Performance decline caused by data scarcity. To directly ob-
serve how data scarcity affects FL, we conducted experiments
comparing several state-of-the-art FL algorithms at different data
scarcity levels. Specifically, we compared FedAvg with the best loss-
based methods FedDecorr and FedNTD, as well as the best data
augmentation-based methods FedMix andFedData. To avoid being
affected by label skew, we split the data in an IID (Independent
and Identically Distributed) manner. We distributed the training
set of CIFAR10 to 10,100, and 500clients, leading to a local data
size|D𝑘|of5000 (not scarce), 500(mildly scarce), and 100(scarce),
respectively, ensuring a uniform representation of all 10 classes.
More experimental details are presented in Appendix A.
The results are summarized in Figure 2, from which we draw
the following observations: 1)FedAvg degrades remarkably as
Figure 3: T-SNE for low-dimension features where the color
distinguishes classes and the class separation measurement
DB under different numbers of training samples.
Figure 4: Data augmentations. From (a) to (c), the privacy
vulnerability is reduced. (b) is the average of a batch of sam-
ples like (a), but if the local data contains individual context
information (e.g., (a*)), averaging over those samples cannot
protect such information (e.g., (b*)). (c) shows a feature of (a*)
and (c*) shows its reconstruction.
data scarcity becomes more severe: Its accuracy, which starts
at75% in (a) with sufficient data, decreases to 56% in (b) when
|D𝑘|is reduced to 500, and further drops to 37%in (c) when|D𝑘|
is reduced to 100.2) The compared loss-based methods also
decline as the data become scarce: From (a) to (c), although
FedDeccor andFedNTD outperform FedAvg, the gain is marginal,
and all their accuracy drops significantly. 3) The compared data
augmentation-based methods outperform other methods:
With internal data exchange, FedMix andFedData effectively im-
prove local models, leading to remarkable performance gains over
FedAvg. When data scarcity is significant ( |D𝑘|=100), they notably
outperform loss-based FL methods, as shown in (c).
2.3.2 Understanding the effect of data scarcity. From the above ob-
servation, we hypothesize that data scarcity can lead to local
model overfitting, and aggregating such models cannot continu-
ally improve the global model. In light of this, the data augmentation-
based methods can prevent the performance decline as more train-
ing samples are available to alleviate the local overfitting. To verify
this, we carried out controlled experiments on CIFAR10 to ana-
lyze the model update in one communication round with different
amounts of training samples.
Specifically, we examined a communication round where local
training begins with a global model possessing an accuracy of 40%.
Following the IID setting outlined in Sec. 2.3.1, we compare the
performance of local models trained with |D𝑘|=5000 and|D𝑘|=
100|samples. To assess the models, we scrutinized the quality of
learned activations across different classes. For visualization, we
adopted a commonly used tool that maps activations from the
penultimate layer of the model into a two-dimensional space [ 7,31].
Quantitatively, we employed the clustering score, specifically the
Davies-Bouldin Score (DB), to measure the separation of activations
3486KDD ’24, August 25–29, 2024, Barcelona, Spain Tong Xia, Abhirup Ghosh, Xinchi Qiu, & Cecilia Mascolo
among classes. A detailed formulation can be found in Appendix A.
As illustrated in Figure 3 (left), a smaller DB indicates less overlap
among activations. The DBs before and after local training are
summarized in the bar chart presented in Figure 3.
For local models, after training, the DB was reduced from 4.8
to 3.1 when|D𝑘|=5000 and to 0.8 when|D𝑘|=100on the
training set. However, a notable gap between DB values on the
training set and testing set can be observed, suggesting the
occurrence of overfitting. As the number of samples decreases
(|D𝑘|=100), the gap widens, indicating severe overfitting. Con-
sequently, after aggregation, the performance of the global model
varies, and training with only |D𝑘|=100fails to enhance the global
model, as evidenced by an increased DB. These results uncover the
negative impact of data scarcity on the generalization of local mod-
els, resulting in overlapped features and ultimately leading to an
under-performing global model.
Furthermore, in the fourth group ( |D𝑘|=100+1000) where
local data contain 100samples but a globally shared set with 1000
samples is also used for training, a smaller gap between the training
and testing sets is observed. This indicates that with more shared
data to aid local training, the generalization of the local model im-
proves. Consequently, the global model’s performance is enhanced,
as evidenced by a decreased DB. This observation supports the
feasibility of data augmentation-based methods for addressing data
scarcity in FL.
2.4 Privacy-preserving Feature Sharing
The above analysis highlights the challenge of overfitting caused
by data scarcity, and further suggests that globally sharing certain
information can help mitigate this problem. In Sec. 2.2, several
data augmentation-based FL methods are introduced; however,
it is crucial to note that these methods may introduce privacy
vulnerabilities.
As illustrated in Figure 4, FedData globally shares raw data and
labels, while FedMix shares aggregated data and labels globally.
Although the averaging of samples in FedMix hinders data recon-
struction, it remains privacy-vulnerable, as it releases contextual
information. To illustrate, consider a scenario where a client’s phone
camera has a sensor problem, resulting in a spot in each photo (see
Figure 4(a*)). Alternatively, imagine a client residing in a bustling
neighborhood, leading to a constant background score in all audio
clips. Averaging over a batch of samples fails to protect such spe-
cific context information, as depicted in Figure 4(b*). Unlike these
existing works, to improve the trade-offs between performance
and privacy protection, we propose to share the activations from
the intermediary layers (see Figure 4(c))). To enhance the privacy
measured by the information leakage from those activations, we
employ an obfuscation approach to reduce the distance correlation
between activations and the source data. One example of data re-
constructed from the activation of is shown in Figure 4(c*), where
sensitivity information like color and context are not recovered.
3 FLea
3.1 Overview
Building upon the insights gained from the preceding discussion
and analysis, we now formally introduce our method, FLea. It aims
Figure 5: Overview of FLea for𝑡-th communication round.
to address the challenges of data scarcity and label skew while
minimizing privacy risks associated with shared information.
At an abstract level, FLea maintains a feature buffer containing
activation-target pairs from multiple clients. This shared buffer en-
ables clients to have more training samples covering all classes for
local training. To safeguard the privacy of shared features, we obfus-
cate activations by minimizing the correlation between activations
and the source data when extracting these activations.
Examining the training process, FLea operates iteratively, akin
toFedAvg. Initially, the global model is randomly initialized, and
the buffer is empty. Then, for each round 𝑡, as illustrated in Figure 5,
FLea starts with synchronizing the global model parameters 𝜃(𝑡)
and feature buffer F(𝑡)to the selected clients K(𝑡). Once local
training usingD𝑘andF(𝑡)completes (the first round only uses
D𝑘since the feature buffer is empty), those clients send the updated
model parameters 𝜃𝑘to the server, to be aggregated into a new
global model parameterized by 𝜃(𝑡+1). Followed by that, FLea needs
another step to update the global feature buffer to F(𝑡+1). A detailed
training procedure is summarized in Algorithm 1. We elaborate on
the main components of the procedure in the following sections.
3.2 Formulation of Feature Buffer
The shared feature buffer contains activation-target pairs from
multiple clients. An activation is the intermediate-layer output of
a model. Let’s consider the model parameters 𝜃to be divided into
two parts at layer 𝑙:𝜃[:𝑙]and𝜃[𝑙:]. For client𝑘, the activation
extracted from data 𝑥𝑖∈D𝑘is𝜃[:𝑙](𝑥𝑖)=𝑓F
𝑖. The feature buffer
from this client is the set of pairs including activations and their
labels, termed as(𝑓F
𝑖,𝑦F
𝑖). Each client randomly selects a 𝛼fraction
of its local data to create its feature buffer to share with others. The
server gathers those local feature buffers and merges them into
the global oneF. Although data from a single client is skewed,
aggregating features from multiple clients can cover many classes
and thus alleviate the label-skew problem. Note that a client only
extracts and contributes to the global feature buffer at the round
when it participates in training and the global buffer resets at every
round. This reduces the exposure and mitigates the privacy risk.
3.3 Client Local Training
Suppose client 𝑘is selected in round 𝑡, i.e.,𝑘∈K(𝑡). As shown
in Figure 5, 𝑘receives the global model 𝜃𝑘=𝜃(𝑡)and the feature
bufferF(𝑡). The local dataD𝑘and the feature buffer F(𝑡)are
divided into equal-sized batches for model optimization, termed by
3487FLea: Addressing Data Scarcity and Label Skew in Federated Learning via Privacy-preserving Feature Augmentation KDD ’24, August 25–29, 2024, Barcelona, Spain
B={(𝑥𝑖,𝑦𝑖)∈D𝑘}andBF={(𝑓F
𝑖,𝑦F
𝑖)∈F(𝑡)}, respectively
(|B|=|BF|). The traditional method will feed Binto the model
directly to optimize the model, but to address the data scarcity
and label skew problem, we propose to augment the input in the
representation space.
3.3.1 Feature augmentation. We feedBinto the first 𝑙layers of the
model, extracting the intermediate output for each data point, and
then we generate the augmented inputs ˜B. Specifically, for each
data sample(𝑥𝑖,𝑦𝑖)inB, we extract its feature (𝑓𝑖=𝜃𝑘[:𝑙](𝑥𝑖),𝑦𝑖)
and mix the feature with a sample (𝑓F
𝑖,𝑦F
𝑖)from the feature buffer
batchBF. The generated augmentation (˜𝑓𝑖,˜𝑦𝑖)for𝑖-th sample is
formulated as (the new batch is termed as ˜B),
(˜𝑓𝑖=𝛽𝑖𝑓𝑖+(1−𝛽𝑖)𝑓F
𝑖,
˜𝑦𝑖=𝛽𝑖𝑦𝑖+(1−𝛽𝑖)𝑦F
𝑖,(2)
where𝛽𝑖is the weight balancing the strength of interpolation be-
tween the local and global features. Inspired by the data augmenta-
tion method in the centralized setting [ 37], we sample the weight
𝛽𝑖for each data point from a symmetrical Beta distribution [ 8]:
𝛽𝑖∼𝐵𝑒𝑡𝑎(𝑎,𝑎).𝛽𝑖∈[0,1]controls the strength of interpolation:
A smaller𝛽𝑖makes the generated sample closer to the local fea-
ture while a larger one pushes that to the global feature. 𝑎is a
hyper-parameter controlling the shape of the Beta distribution.
Since the data batch Band the feature batch BFare randomly
shuffled, and 𝛽𝑖is sampled from the Beta distribution for each pair,
the augmentation encounters an unlimited combination of local
and shared features, thereby significantly extending the classes and
the number of samples for model training.
3.3.2 Local training objective. As illustrated in Figure 5, the aug-
mented features in ˜Bare then inputted into the model starting from
layer𝑙. For ˜𝑓𝑖, let the output logit be denoted by 𝑧𝑙
𝑖:𝑧𝑙
𝑖=𝜃𝑘[𝑙:](˜𝑓𝑖),
and the probability for class 𝑐is𝑝𝑙
𝑖[𝑐]=exp(𝑧𝑙
𝑖[𝑐])Í
𝑐exp(𝑧𝑙
𝑖[𝑐]). Given this, we
devise a loss function comprising multiple components to optimize
the local model. The first term aims to minimize the classification
error, which is formulated as,
L𝑐𝑙𝑓(B,BF)=1
|B|∑︁
𝑖∑︁
𝑐−˜𝑦𝑖[𝑐]log𝑝𝑙
𝑖[𝑐]. (3)
It is equivalent to the cross-entropy loss. The second loss term is
used to distill the knowledge from the previous global model to
prevent local drift, and is derived by the KL-divergence between
the global probabilities and local probabilities as [9],
L𝑑𝑖𝑠(B,BF)=1
|B|∑︁
𝑖∑︁
𝑐−𝑝𝑙
𝑖[𝑐]log𝑝𝑔
𝑖[𝑐]
𝑝𝑙
𝑖[𝑐], (4)
where for ˜𝑓𝑖the global logit is 𝑧𝑔
𝑖=𝜃(𝑡)[𝑙:](˜𝑓𝑖)and the global
probability is 𝑝𝑔
𝑖[𝑐]=𝑒𝑥𝑝(𝑧𝑔
𝑖[𝑐])Í
𝑐𝑒𝑥𝑝(𝑧𝑔
𝑖[𝑐]). Mitigating this loss encourages
the local model to make similar predictions to the global model.
Besides, we aim to reduce the information leakage of the features
before they are shared with other clients. As such, we learn the
first𝑙layers while reducing the distance correlation between the
activations and the source data. Thus, the third term is formulatedAlgorithm 1: FLea
Input : Local datasetD𝑘, randomly initialized model 𝜃(1).
Output: Global model 𝜃(𝑇).
1foreach round𝑡= 1,2,...,T do
2 Server samples clients K(𝑡)and broadcasts 𝜃𝑘←𝜃(𝑡)
3 Server broadcastsF(𝑡)toK(𝑡)// Skip if𝑡=1.
4 foreach client𝑘∈K(𝑡)in parallel do
5 forlocal epoch𝑒=1,2,..,𝐸 do
6 forlocal batch𝑏=1,2,...do
7 Sample one data batch B, one feature batch BF,
and𝛽𝑖∼𝐵𝑒𝑡𝑎(𝑎,𝑎)
8 Generate augmentation and update local model:
𝜃𝑘←𝜃𝑘−𝜂∇L(𝜃𝑘)according to Eq. (6) //
Skip augmentation if 𝑡=1
9 end
10 end
11 Client𝑘sends𝜃𝑘to server
12 end
13 Server aggregates 𝜃𝑘to𝜃(𝑡+1)refer to Eq. (1)
14 foreach client𝑘∈K(𝑡)in parallel do
15 Client𝑘receives the new model 𝜃(𝑡+1)
16 Client𝑘extracts and sends F(𝑡+1)
𝑘to server
17 end
18 Server aggregatesF(𝑡+1)
𝑘and update the global buffer to F(𝑡+1)
19end
by distance correlation [32, 33],
L𝑑𝑒𝑐(B)=𝜈2(𝑥,𝑓)√︁
𝜈2(𝑥,𝑓)𝜈2(𝑓,𝑓), (5)
where𝜈2(,)denotes the squared distance. Specifically, 𝜈2(𝑥,𝑓)=
1
|B|2Í|B|
𝑖,𝑘ˆ𝐸𝑥[𝑖,𝑘]ˆ𝐸𝑓[𝑖,𝑘].𝐸𝑥is the Euclidean distance matrix for
𝑥∈B, i.e.,𝐸𝑥[𝑖,𝑘]=||𝑥𝑖−𝑥𝑘||2. Similarly,𝐸𝑓[𝑖,𝑘]=||𝑓𝑖−𝑓𝑘||2.
They are then double-centered to ˆ𝐸𝑋and ˆ𝐸𝐹, by making their row
and columns sum zeros (cf. Appendix B)). After normalization, the
distance correlation 𝑐=L𝑑𝑒𝑐has the following properties: (1)
𝑐satisfies the relation 0≤𝑐≤1, and a smaller 𝑐suggests less
mutual information between 𝑥and𝑓; (2)𝑐=1when𝑓is a linear
transformation from 𝑥[27]. In our case, the model contains 𝑙non-
linear layers and thus 𝑐<1; (3)𝑐=0when𝑥and𝑓are independent.
In other words, 𝑐=0if𝑓becomes random noise and this produces
perfect privacy but 𝑓is useless for classification. Overall, we aim
to reduce𝑐to project feature privacy. Our optimization function
therefore is,
L=L𝑐𝑙𝑓(B,BF)+𝜆1L𝑑𝑖𝑠(B,BF)+𝜆2L𝑑𝑒𝑐(B), (6)
where𝜆1and𝜆2are the weights to trade-off classification utility
and privacy preservation. The local update is then achieved by
𝜃𝑘←𝜃𝑘−𝜂𝜕L
𝜕𝜃𝑘, where𝜂controls the learning rate.
3.4 Model Aggregation and Buffer Updating
Once the local training completes, the updated model parameters
will be sent to the server for aggregation (lines 13 in Algorithm 1).
FLea utilizes the same aggregation strategy as FedAvg (Eq.(1)). The
new model will be synchronized to the clients, and the features
3488KDD ’24, August 25–29, 2024, Barcelona, Spain Tong Xia, Abhirup Ghosh, Xinchi Qiu, & Cecilia Mascolo
will be extracted and sent to the server to replace the old ones,
updating the feature buffer to F(𝑡+1)(lines 14-18 in Algorithm 1).
The iterations continue (restart from line 2) until the global model
converges.
4 Evaluation
In this section, we conduct extensive experiments using three
datasets to answer the following research questions:
•RQ1: How does FLea perform compared to the state-of-the-art
FL baselines for various levels of label skew and data scarcity?
•RQ2: How do the main components and key hyper-parameters
affect FLea’s performance?
•RQ3: Can FLea’s strategy mitigate the privacy vulnerability as-
sociated with feature sharing?
4.1 Experimental Setup
4.1.1 Datasets. We evaluate FLea on three data modalities. Im-
ages: CIFAR10 [11] is a commonly used FL benchmark contain-
ing 10 classes of objectives. To classify those images, we use Mo-
bileNet_V2 [ 25] with 18blocks consisting of multiple convolutional
and pooling layers. Audio: UrbanSound8K [ 24] is an audio classifi-
cation bookmark also containing 10 categories of sounds collected
in urban environments. Those audio samples are first transformed
into spectrograms and fed into a 4-layer CNN model called AudioNet
for classification [ 5].Sensory data: UCI-HAR [ 23] is a public hu-
man activity recognition database collected by a waist-mounted
smartphone with an embedded accelerometer. Six activities includ-
ing walking, walking upstairs, walking downstairs, sitting, standing,
and lying were recorded. We employ HARNet which comprises 4
convolutional layers to recognize those activitie [ 30]. A summarily
of those datasets can be found in Appendix C Table 2.
4.1.2 FL setup and baselines. To simulate label skew, we consider
quantity-based skew (Qua( 𝑞) with𝑞being the number of presented
classes) and distribution-based skew (Dir( 𝜇) with𝜇controlling the
class skewness) [ 38]. To mimic different levels of data scarcity, we
distribute the training data to |𝐾|clients, where|𝐾|is determined
by the average local data size ¯|D𝑘|, which is set to as small as 100
and50for experiments.
We compare FLea against FedAvg, and then loss-based methods:
𝑖)FedProx [16],𝑖𝑖)FedDecorr [26],𝑖𝑖𝑖)FedLC [38], and𝑖𝑣)Fed-
NTD [13], as well as data augmentation-based methods:𝑖)FedBR [7],
𝑖𝑖)CCVR [21],𝑖𝑖𝑖)FedGen [20], and𝑖𝑣)FedMix [35]. We also report
the results of FedData [39] for reference but it is not considered
as a baseline since raw data are exposed. All baselines are hyper-
parameter optimized to report their best performances. The specific
setting can be found in Appendix C.3.
For all methods, we use the Adam optimizer for local training
with an initial learning rate of 10−3and decay it by 2%per com-
munication round until 10−5. The size of the local batch is 32and
the number of local epochs is set to 5.10%of clients are randomly
sampled at each round. We run 100communications and report
the best accuracy as the final result. For all settings, we report the
mean and standard deviation of the accuracy from five runs with
different random seeds. For FLea, without particular mention, we
use𝛽∼𝐵𝑒𝑡𝑎(2,2)for Eq. (2), and 𝜆1=1,𝜆2=3for the loss in
Eq. (6), and extract the activations after several conventional layers
Figure 6: Comparison between FedMix and FLea using
UrbanSound8K with 𝑄𝑎𝑛(3),¯|D𝑘|=100.
of the model (as specified in Appendix C.2). We only share features
from𝛼=10%of the local data.
4.2 Performance Comparison (RQ1)
The overall accuracy achieved by FLea and baselines are compared
in Table 1. Across various model architectures (x3) and different
levels of local data skewness (x3) and scarcity (x2), FLea constantly
outperforms the state-of-the-art baselines and significantly reduces
the gap compared to FedData which shares the raw data. In 13out
of the studied 18scenarios, FLea presents an improvement of over
5%, and among those, in 5cases, the improvement is more than
10%. These demonstrate the superiority and generality of FLea in
addressing the challenges caused by label skew and data scarcity.
It can also be observed that the data-augmentation-based base-
lines, particularly FedMix, outperform the loss-based baselines in
most cases, which again supports FLea ’s use of some global in-
formation to aid local training in the presence of data scarcity. In
FedMix, sample aggregations are shared to protect data privacy, yet
this inevitably harms the utility of the shared augmentations for
the training of classification models. On the contrary, FLea shares
the intermediate layer activations, which are obfuscated to protect
privacy while retaining useful information for classification. This
explains why FLea can consistently outperform FedMix. FLea is also
more efficient than FedMix. As illustrated in Figure 6, FLea learns
faster than FedMix after the first 5rounds (cf. the left figure) and
requires a smaller proportion of augmentations to be shared to
achieve the same accuracy as FedMix (cf. the right figure).
4.3 Effects of Key Design Choices (RQ2)
4.3.1 The role of augmentation. The feature buffer is a key compo-
nent in FLea, designed to compensate for the missing classes in the
local dataset. Figure 7 displays an example of the class distribution
for the global feature buffer F(𝑡)and the local dataD𝑘at round𝑡.
F(𝑡)contains features from all six classes, while D𝑘only has data
from two classes. As introduced in Sec.3.3.1, a batch of features is
sampled fromF(𝑡)andD𝑘, respectively. These features are then
mixed up to create the augmented input ˜B, as shown in the red
bar plots in Figure 7: they also contain all six classes. This explains
how the feature buffer and mix-up augmentation help address the
local label skew.
Since we dynamically sample the weight 𝛽for the mix-up aug-
mentation, we can generate infinite combinations of global features
and local features. An example of 𝛽for one batch is given in Fig-
ure 8, and the corresponding class distribution for the augmented
batch in different epochs are shown in Figure 7. It is worth noting
that the two red bar plots in Figure 7 are different, although they are
generated using the same global and local features. Such diversity in
the training data can significantly enhance the generalization of the
local model, ultimately alleviating local overfitting as introduced
in Sec. 2.3.2 and improving the global model.
3489FLea: Addressing Data Scarcity and Label Skew in Federated Learning via Privacy-preserving Feature Augmentation KDD ’24, August 25–29, 2024, Barcelona, Spain
Table 1: Overall accuracy comparison. Accuracy is reported as 𝑚𝑒𝑎𝑛±𝑠𝑡𝑑across five runs. The best performance under each
setting is highlighted in red and the SOTA baseline (*excluding FedData ) is in grey.↑indicates a relative improvement of our
method compared to the SOTA over 5%and↑↑indicates a relative improvement over 10%.
CIF
AR10 UrbanSound8K UCI-HAR
A
ccuracy %𝑄
𝑢𝑎(3)𝐷𝑖𝑟(0.5)𝐷𝑖𝑟(0.1)𝑄
𝑢𝑎(3)𝐷𝑖𝑟(0.5)𝐷𝑖𝑟(0.1)𝑄
𝑢𝑎(2)𝐷𝑖𝑟(0.3)𝐷𝑖𝑟(0.1)¯|
D𝑘|=100Fe
dAvg 30.25±1.33
32.58±1.09 20.46±2.15 43.69±0.56
46.77±0.87 34.59±2.64 66.99±0.87
65.78±0.34 48.43±0.70
FedProx 31.92±1.45
32.01±1.25 20.86±1.97 38.45±0.48
39.58±1.02 34.81±0.46 68.32±0.50
67.75±0.41 58.35±0.52
FedDecorr 31.12±1.57
33.57±1.22 21.34±1.59 45.01±0.57
46.77±0.65 35.87±1.03 69.12±0.63
66.68±0.43 57.05±0.38
FedLC 32.05±1.60
30.17±1.18 18.82±2.01 50.98±0.49
50.11±0.83 37.05±0.87 71.69±0.52 70.57±0.38
62.57±0.42
FedNTD 39.98±0.97
39.82±0.86 26.78±2.34 49.80±0.45
51.09±0.97 36.53±0.99 68.33±0.72 70.32±0.49
60.13±0.51
Fe
dBR 31.66±1.07
33.08±1.12 20.98±2.54 44.05±0.63
47.58±0.90 36.15±1.17 67.54±0.68
69.15±0.40 59.87±0.46
CCVR 35.95±1.63
35.02±1.43 24.21±2.67 47.12±0.72
49.26±0.92 39.62±1.20 70.17±0.49
68.87±0.51 60.28±0.36
FedGen 32.32±1.21
34.27±1.56 22.56±2.89 45.20±0.89
48.33±1.12 38.27±1.44 70.58±0.61
69.32±0.60 60.07±0.63
FedMix 44.04±1.53 45.50±1.88 38.13±2.06 51.56±0.59 54.18±0.62 43.35±0.72 68.59±0.54
69.34±0.49 65.63±0.47
Fe
dData* 54.64±1.02
56.47±1.22 55.35±1.46 62.83±1.25
64.45±0.76 61.11±0.98 78.13±0.46
78.24±0.51 75.93±0.34
FLea 47.03±1.01↑48.86±1.43↑44.40±1.23↑
↑ 57.73±0.51↑
↑59.22±0.78↑45.94±0.77↑ 75.17±0.42 73.02±0.49 71.68±0.51↑¯|
D𝑘|=50Fe
dAvg 27.72±1.26
26.92±1.31 21.88±1.87 39.35±0.60
43.98±0.89 31.21±1.62 65.77±0.42
67.10±0.40 46.95±0.62
FedProx 22.88±2.54
24.47±2.17 21.01±2.46 39.05±0.56
42.21±0.76 32.85±1.22 69.18±0.41
68.28±0.45 59.97±0.46
FedDecorr 26.45±1.58
25.57±1.84 22.03±1.98 39.67±0.58
44.23±0.95 33.67±1.34 65.77±0.39
68.57±0.51 55.54±0.49
FedLC 28.64±1.52
26.36±1.47 20.24±1.68 44.33±0.79
45.15±0.80 39.87±1.04 70.63±0.49 71.34±0.45 63.67±0.52
Fe
dNTD 32.92±1.43
34.64±1.52 30.13±1.67 42.21±0.63
48.63±0.78 40.15±1.22 65.64±0.38
67.16±0.43 59.93±0.46
Fe
dBR 30.25±1.45
30.32±1.32 28.52±1.56 41.15±0.70
44.37±0.82 34.89±1.36 66.98±0.43
68.23±0.49 57.25±0.52
CCVR 34.01±1.89
35.12±1.34 33.26±1.56 44.05±0.87
46.68±0.83 36.80±1.37 65.24±0.50
70.15±0.46 60.26±0.57
FedGen 33.12±1.61
31.89±1.59 29.90±1.76 40.89±0.72
44.54±0.81 35.78±1.40 68.27±0.64
69.82±0.41 59.13±0.45
FedMix 38.14±1.12 39.87±1.55 36.87±1.38 46.55±0.81 50.00±0.92 42.27±1.15 68.06±0.44
70.80±0.45 61.39±0.46
FedData* 53.59±1.32
53.02±1.18 53.56±1.64 60.31±0.82
60.48±0.91 59.67±1.55 76.42±0.38
76.45±0.47 75.46±0.47
FLea 41.98±1.26↑
↑42.01±1.13↑ 37.69±1.65 54.35±0.80↑
↑55.68±0.87↑
↑45.05±1.32↑ 74.25±0.44↑73.98±0.46 66.57±0.45
4.3.2 Impact of hyper-parameters. We now analyze how the hyper-
parameters including the weight 𝛽in Eq. (2) and weights 𝜆in the
loss Eq. (6) affect the performance of FLea. We use UrbanSound8K
under the setting of 𝑄𝑢𝑎(3)and ¯|D𝑘|=100as an example for a
detailed analysis. We first look at the impact of 𝛽. In Figure 10, we
visualize the density function for 𝛽∼𝐵𝑒𝑡𝑎(𝑎,𝑎)in the left, and the
model performance with varying hyper-parameter 𝑎controlling
the shape of the distribution in the right. From the results, we can
observe that training with augmentation regardless of the viable of
𝛽outperforms training without mix-up (FedAvg ), while a choice of
𝑎ranging from 1.5to5yields the best performance. Thus we set
𝑎=2in our experiments.
Regarding the weights in the loss function, we first set 𝜆2=0
(without obfuscating the features) and search the value for 𝜆1. As
shown in Figure 11 (the left one), we found that 𝜆1>1can improve
the performance compared to that without the distilling loss ( 𝜆1=
0), but if the weight is too large ( 𝜆1>4) it harms the performance.
The pattern is similar with other 𝜆2, and thus we informally use
𝜆1=1for all experiments. With 𝜆1=1, we further study how 𝜆2
impacts the trade-off between privacy preservation (reflected by
the reduced correlation) and the feature utility (reflected by the
model accuracy), as shown in Figure 11 (the right one). Enlarging
𝜆2can significantly enhance privacy protection (referring to the
increasing 1−¯𝑐) but decreases the final performance. We finally
use𝜆2=3when the ¯𝑐reduces to about 0.72while maintaining a
strong accuracy of about 57%. We also suggest future applications
using 2∼6for the trade-off.
4.4 Privacy Analysis (RQ3)
Now, we show FLea can protect the privacy of the shared features
from the following aspects: i)reducing exposure by only sharing
Figure 7: Class distributions for the global feature buffer F(𝑡),
the local dataD𝑘, and augmented batch ˜Bin different epochs.
The example is from UCI-HAR with 𝑄𝑎𝑛(2),¯|D𝑘|=100.
Figure 8: Value of 𝛽for one batch (batch size =32).
features with a fraction of clients, ii)preventing data reconstruction,
andiii)impeding context information identification as introduced
in Sec. 2.4. We use CIFAR10 ( 𝑄𝑢𝑎(3),|¯D𝑘=100|) as the exam-
ple to demonstrate that FLea is more privacy-preserving than its
counterpart FedMix andFedData.
Reducing feature exposure. As described in Sec. 3.4, in FLea,
features from only a small fraction of local data are shared among
the selected 10%of the clients each round (clients in round 𝑡−1
share with clients in 𝑡). To quantify the feature exposure, we define
a feature exchange matrix 𝜉∈R|𝐾|×|𝐾|(|𝐾|is the number of total
clients).𝜉(𝑡)
𝑖,𝑗=1denotes client 𝑖and𝑗have exchanged features for
at least once until (including) 𝑡-th round, otherwise 𝜉(𝑡)
𝑖,𝑗=0. The
3490KDD ’24, August 25–29, 2024, Barcelona, Spain Tong Xia, Abhirup Ghosh, Xinchi Qiu, & Cecilia Mascolo
(a) Feature exposure.
 (b) Correlation.
 (c) Reconstruction training error.
 (d) Context detection accuracy.
Figure 9: The effectiveness of privacy protection. 𝑐is short for the expected correlation in (b). We show the reconstruction and
context detection performance for 𝑐=0.65(the 1𝑠𝑡round) and 𝑐=0.40(the 10𝑡ℎround).
Figure 10: Beta distribution 𝛽∼𝐵𝑒𝑡𝑎(𝑎,𝑎)and the model
performance with varying 𝑎.
Figure 11: Impact of 𝜆1and𝜆2.¯𝑐denotes the expectation of
the distance correlation between activations and source data.
feature exposure is measured by 𝜖(𝑡)=Í
𝑖,𝑗𝜉(𝑡)
𝑖,𝑗/|𝐾|2(0≤𝜖(𝑡)≤
1), and a smaller 𝜖(𝑡)is better. As FedData andFedMix gather data
or data averages and broadcast them to all clients before local model
training,𝜖(𝑡)=100% consistently. We illustrate 𝜖(𝑡)forFLea in
Figure 9(a): the exposure of FLea grows slowly. In our experiments,
the model converges within 50rounds (c.f. the learning curve in
Figure 6), by when 𝜖(𝑡)≤40%. Therefore, feature exposure is
reduced by FLea.
Moreover, feature exposure is not equivalent to privacy leakage.
Based on the reduction of distance correlation between raw data and
learned activations during training (as shown in Figure 9(b)), FLea
is resilient to data reconstruction and context identification attacks.
We construct test beds for a quantitative evaluation (detailed setup
can be found in Appendix D) and report the results below.
Preventing data reconstruction. We built an attacker model by
using the activations from the FL model with and without reducing
the distance correlation, respectively [ 32]. The reconstruction error
(MSE) for training the attacker is presented in Figure 9(c). It can
be observed withL𝑑𝑒𝑐, MSE can never be reduced to the value of
0.01achieved with normal training without L𝑑𝑒𝑐, which suggests
the data cannot be accurately reconstructed. To further illustrate
this, let’s look at an example: Assume one client is selected to share
the activation of an image, e.g., the dog image in Figure 4(a), in a
certain communication round (when 𝑐=0.4), the attacker tries to
reconstruct the image from the shared activation. Our experiment
shows the recovered image ends up with Figure 4(c*) (also shown inFigure 9(c)). The original attribute, i.e., the color distribution cannot
be recovered and thus privacy is preserved.
Impeding context identification. Our baseline FedMix also demon-
strates to be resilient to data reconstruction attacks because raw
data are aggregated before sharing [ 35]. However, FedMix can re-
lease context information, while FLea can increase the difficulty of
identifying the context. To quantify this, we constructed a context
identification attacker, assuming that the context targeted for at-
tack is represented by a colored square in the image (simulating a
malfunctioning camera, see Figure 4(a*))). We employed a binary
classifier to predict the presence of the context. Half of the CIFAR10
dataset was augmented with the marker for training and testing
the attacker. The identification accuracy achieved with varying
amounts of training samples is summarized in Figure 9(d). The
results indicate that FLea requires significantly more training data
(hundreds of times) than FedMix to achieve comparable identifica-
tion accuracy. For instance, to attain a 90%accuracy rate, FedMix
needs approximately 300training samples, whereas FLea (𝑐=0.4)
demands 10,000samples. It’s important to note that real-world sce-
narios pose greater challenges, as the context pattern may not be
explicit and the attacker might not have access to extensive training
data, resulting in reduced attacking accuracy. In such scenarios,
FLea can effectively safeguard context privacy.
5 Conclusions
We proposed FLea, a novel approach to tackle scarce and label-
skewed data in FL. Feature augmentation is employed to mitigate
over-fitting and local drift simultaneously. Extensive experiments
demonstrate that FLea remarkably outperforms the state-of-the-art
baselines while mitigating the privacy risk associated with feature
sharing. In practice, FLea can introduce some additional overheads,
such as increased communication and storage requirements, due to
feature sharing. We leave the task of improving efficiency for future
work. To enhance privacy, FLea can be combined with other meth-
ods like differential privacy [ 1] and homomorphic encryption [ 6].
For applications such as healthcare, protecting the label distribu-
tion may be necessary, which we did not address in this paper. We
anticipate that our work will inspire further investigations into
comprehensive studies on feature sharing in low data regimes.
Acknowledgment
This work was supported by European Research Council Project
833296 (EAR) and 805194 (REDIAL). We also thank Prof. Nicholas
Lane and Lorenzo Sani for their insightful discussions.
3491FLea: Addressing Data Scarcity and Label Skew in Federated Learning via Privacy-preserving Feature Augmentation KDD ’24, August 25–29, 2024, Barcelona, Spain
References
[1]Martin Abadi, Andy Chu, Ian Goodfellow, H Brendan McMahan, Ilya Mironov,
Kunal Talwar, and Li Zhang. 2016. Deep learning with differential privacy. In
Proceedings of the 2016 ACM SIGSAC conference on computer and communications
security. 308–318.
[2]Zachary Charles, Zachary Garrett, Zhouyuan Huo, Sergei Shmulyian, and Vir-
ginia Smith. 2021. On large-cohort training for federated learning. Advances in
neural information processing systems 34 (2021), 20461–20475.
[3]D Davies and D Bouldin. 1979. A cluster separation measure: IEEE transactions
on pattern analysis and machine intelligence. itpidj 0162-8828, pami-1, 2 224–227.
Crossref Web of Science (1979).
[4]Alexey Dosovitskiy and Thomas Brox. 2016. Inverting visual representations
with convolutional networks. In Proceedings of the IEEE conference on computer
vision and pattern recognition. 4829–4837.
[5]Long Pham Duc. 2023. Sound classification . Kaggle. https://www.kaggle.com/
code/longx99/sound-classification/notebook.
[6]Haokun Fang and Quan Qian. 2021. Privacy preserving machine learning with
homomorphic encryption and federated learning. Future Internet 13, 4 (2021), 94.
[7]Yongxin Guo, Xiaoying Tang, and Tao Lin. 2023. FedBR: Improving Federated
Learning on Heterogeneous Data via Local Learning Bias Reduction. (2023).
[8]Arjun K Gupta and Saralees Nadarajah. 2004. Handbook of beta distribution and
its applications. CRC press.
[9]Geoffrey Hinton, Oriol Vinyals, and Jeff Dean. 2015. Distilling the knowledge in
a neural network. arXiv preprint arXiv:1503.02531 (2015).
[10] Sai Praneeth Karimireddy, Satyen Kale, Mehryar Mohri, Sashank Reddi, Sebas-
tian Stich, and Ananda Theertha Suresh. 2020. Scaffold: Stochastic controlled
averaging for federated learning. In International Conference on Machine Learning.
PMLR, 5132–5143.
[11] Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton. 2009. Cifar-10 and cifar-100
datasets. URL: https://www.cs.toronto.edu/kriz/cifar.html (2009).
[12] Fan Lai, Yinwei Dai, Sanjay Singapuram, Jiachen Liu, Xiangfeng Zhu, Harsha
Madhyastha, and Mosharaf Chowdhury. 2022. Fedscale: Benchmarking model
and system performance of federated learning at scale. In International Conference
on Machine Learning. PMLR, 11814–11827.
[13] Gihun Lee, Minchan Jeong, Yongjin Shin, Sangmin Bae, and Se-Young Yun. 2022.
Preservation of the global knowledge by not-true distillation in federated learning.
InAdvances in Neural Information Processing Systems.
[14] Qinbin Li, Yiqun Diao, Quan Chen, and Bingsheng He. 2022. Federated learning
on non-iid data silos: An experimental study. In 2022 IEEE 38th International
Conference on Data Engineering (ICDE). IEEE, 965–978.
[15] Qinbin Li, Bingsheng He, and Dawn Song. 2021. Model-contrastive federated
learning. In Proceedings of the IEEE/CVF conference on computer vision and pattern
recognition. 10713–10722.
[16] Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar,
and Virginia Smith. 2020. Federated optimization in heterogeneous networks.
Proceedings of Machine learning and systems 2 (2020), 429–450.
[17] Xin-Chun Li and De-Chuan Zhan. 2021. Fedrs: Federated learning with restricted
softmax for label distribution non-iid data. In Proceedings of the 27th ACM SIGKDD
Conference on Knowledge Discovery & Data Mining. 995–1005.
[18] Wei Yang Bryan Lim, Nguyen Cong Luong, Dinh Thai Hoang, Yutao Jiao, Ying-
Chang Liang, Qiang Yang, Dusit Niyato, and Chunyan Miao. 2020. Federated
learning in mobile edge networks: A comprehensive survey. IEEE Communications
Surveys & Tutorials 22, 3 (2020), 2031–2063.
[19] Gaoyang Liu, Chen Wang, Xiaoqiang Ma, and Yang Yang. 2021. Keep your data
locally: Federated-learning-based data privacy preservation in edge computing.
IEEE Network 35, 2 (2021), 60–66.
[20] Shunjian Liu, Xinxin Feng, and Haifeng Zheng. 2022. Overcoming Forgetting
in Local Adaptation of Federated Learning Model. In Advances in Knowledge
Discovery and Data Mining: 26th Pacific-Asia Conference, PAKDD 2022, Chengdu,
China, May 16–19, 2022, Proceedings, Part I. Springer, 613–625.
[21] Mi Luo, Fei Chen, Dapeng Hu, Yifan Zhang, Jian Liang, and Jiashi Feng. 2021. No
fear of heterogeneity: Classifier calibration for federated learning with non-iid
data. Advances in Neural Information Processing Systems 34 (2021), 5972–5984.
[22] Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and
Blaise Aguera y Arcas. 2017. Communication-efficient learning of deep networks
from decentralized data. In Proc. Artificial Intelligence and Statistics. 1273–1282.
[23] Jorge Reyes-Ortiz, Davide Anguita, Alessandro Ghio, Luca Oneto, and Xavier
Parra. 2012. Human Activity Recognition Using Smartphones. UCI Machine
Learning Repository. DOI: https://doi.org/10.24432/C54S4K.
[24] Justin Salamon, Christopher Jacoby, and Juan Pablo Bello. 2014. A dataset and
taxonomy for urban sound research. In Proceedings of the 22nd ACM international
conference on Multimedia. 1041–1044.
[25] Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, and Liang-
Chieh Chen. 2018. Mobilenetv2: Inverted residuals and linear bottlenecks. In
Proceedings of the IEEE conference on computer vision and pattern recognition.
4510–4520.[26] Yujun Shi, Jian Liang, Wenqing Zhang, Vincent Tan, and Song Bai. 2022. Towards
Understanding and Mitigating Dimensional Collapse in Heterogeneous Federated
Learning. In The Eleventh International Conference on Learning Representations.
[27] Gábor J Székely, Maria L Rizzo, and Nail K Bakirov. 2007. Measuring and testing
dependence by correlation of distances. (2007).
[28] Yue Tan, Guodong Long, Lu Liu, Tianyi Zhou, Qinghua Lu, Jing Jiang, and
Chengqi Zhang. 2022. Fedproto: Federated prototype learning across hetero-
geneous clients. In Proceedings of the AAAI Conference on Artificial Intelligence,
Vol. 36. 8432–8440.
[29] Zhenheng Tang, Yonggang Zhang, Shaohuai Shi, Xin He, Bo Han, and Xiaowen
Chu. 2022. Virtual homogeneity learning: Defending against data heterogeneity
in federated learning. In International Conference on Machine Learning. PMLR,
21111–21132.
[30] Qi Teng, Kun Wang, Lei Zhang, and Jun He. 2020. The layer-wise training
convolutional neural networks using local loss for sensor-based human activity
recognition. IEEE Sensors Journal 20, 13 (2020), 7265–7274.
[31] Laurens Van der Maaten and Geoffrey Hinton. 2008. Visualizing data using t-SNE.
Journal of machine learning research 9, 11 (2008).
[32] Praneeth Vepakomma, Abhishek Singh, Otkrist Gupta, and Ramesh Raskar. 2020.
NoPeek: Information leakage reduction to share activations in distributed deep
learning. In 2020 International Conference on Data Mining Workshops (ICDMW).
IEEE, 933–942.
[33] Praneeth Vepakomma, Chetan Tonde, and Ahmed Elgammal. 2018. Supervised
dimensionality reduction via distance correlation maximization. (2018).
[34] Zhiqin Yang, Yonggang Zhang, Yu Zheng, Xinmei Tian, Hao Peng, Tongliang Liu,
and Bo Han. 2023. FedFed: Feature Distillation against Data Heterogeneity in
Federated Learning. In Thirty-seventh Conference on Neural Information Processing
Systems.
[35] Tehrim Yoon, Sumin Shin, Sung Ju Hwang, and Eunho Yang. 2020. FedMix:
Approximation of Mixup under Mean Augmented Federated Learning. In Inter-
national Conference on Learning Representations.
[36] Mikhail Yurochkin, Mayank Agarwal, Soumya Ghosh, Kristjan Greenewald,
Nghia Hoang, and Yasaman Khazaeni. 2019. Bayesian nonparametric federated
learning of neural networks. In International conference on machine learning.
PMLR, 7252–7261.
[37] Hongyi Zhang, Moustapha Cisse, Yann N Dauphin, and David Lopez-Paz. 2018.
Mixup: Beyond Empirical Risk Minimization. In International Conference on
Learning Representations.
[38] Jie Zhang, Zhiqi Li, Bo Li, Jianghe Xu, Shuang Wu, Shouhong Ding, and Chao
Wu. 2022. Federated learning with label distribution skew via logits calibration.
InInternational Conference on Machine Learning. PMLR, 26311–26329.
[39] Yue Zhao, Meng Li, Liangzhen Lai, Naveen Suda, Damon Civin, and Vikas Chan-
dra. 2018. Federated learning with non-iid data. arXiv preprint arXiv:1806.00582
(2018).
[40] Junyi Zhu, Xingchen Ma, and Matthew B Blaschko. 2023. Confidence-aware
personalized federated learning via variational expectation maximization. In
Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition .
24542–24551.
Appendix
A Experimental setup for Sec. 2.3
Federated Learning Setup. In Sec. 2.3, we employ CIFAR10 for an
empirical comparison. We conducted three groups of experiments
to simulate different levels of data scarcity, as introduced below.
•(a)The training set of CIFAR10 is uniformly distributed to 10
clients, resulting in each local dataset having a size of 5000
(|D𝑘|=5000) and 10classes (IID). More specifically, each
local dataset has 500samples per class.
•(b)CIFAR10 is uniformly distributed to 100clients. Thus
each local dataset has a size of 500(|D𝑘|=500), 10classes
(IID) with each class containing 50samples.
•(c)CIFAR10 is uniformly distributed to 500clients. Each local
dataset have a size of 100(|D𝑘|=100), 10classes (IID) with
each class containing 10samples.
For classification, we employ MobileNet_V2, which has 18blocks
consisting of multiple convolutional and pooling layers [ 25]. We use
the Adam optimizer for local training with an initial learning rate of
10−3and decay it by 2%per communication round until 10−5. For
3492KDD ’24, August 25–29, 2024, Barcelona, Spain Tong Xia, Abhirup Ghosh, Xinchi Qiu, & Cecilia Mascolo
(a), all clients will participate in the training in each round, while
for the other groups, we will randomly select 10%of the clients for
each round. The size of the local batch is 64, and we run 10local
epochs for each group. We run 100 communication rounds for all
groups to ensure global convergence.
Experimental setup for Figure 1: To compare the performance
of existing methods with , we use CIFAR10 dataset and report the
classification accuracy of the global model based on the global
testing set. We compare FedAvg with loss-based methods such as
FedDecorr andFedNTD, as well as data augmentation-based meth-
ods like FedMix and FedData. They are the most representative
methods in each category. FedMix is implemented by averaging
every 10samples and sharing the result globally. The shared av-
eraged data is then combined with local data according to a Beta
distribution (with the 𝑎=2) for local training. In the case of Fed-
Data, we collect 10%of the data (randomly chosen) from each client
and share it globally, in the first communication round. To simulate
varying scarcity levels, we split the CIFAR10 training set (compris-
ing50,000samples in total) into 5000, 500, and 100training samples
on average per client, which ends up with 10,100and500clients
finally. Other settings are the same with the main experiments as
introduced in Sec. 4.1.
Experimental setup for Figure 2: DB score [ 3] is defined as
the average similarity measuring each cluster with its most similar
cluster, where similarity is the ratio of within-cluster distances to
between-cluster distances. Thus, clusters which are farther apart
and less dispersed will result in a better score. The minimum score
is zero, with lower values indicating better clustering. To calculate
the score for features, we use the ground-true class labels as cluster
labels, and use Euclidean distance between features to measure the
similarity.
For a fair comparison, the local training for all clients starts
from a same global status with an accuracy of 40%. The features
of the testing set from the initial global model present a DB of
4.8. We run one communication round and report the performance
for the global model. In this round, for |D𝑘|=5000 we aggregate
10clients while for|D𝑘|=100we aggregate 50clients, so that
the total samples used for model training are kept unchanged. For
|D𝑘|=100+1000 group, we additionally give the selected 50clients
1000 samples (gathered in the first round) to aid local training. In
Figure 2, for local models, we report the averaged DB across clients.
B Notations
Beta Distribution. The probability density function (PDF) of the
Beta distribution is given by,
𝑝(𝛽;𝑎,𝑏)=𝛽𝑎−1(1−𝛽)(𝑏−1)
𝑁, (7)
where𝑁is the normalizing factor and 𝛽∈[0,1]. In our study, we
use a symmetrical distribution so that we choose 𝑎=𝑏and herein,
𝑝(𝛽)=1
𝑁(𝛽(1−𝛽))𝑎−1.
De-correlation Loss. We employ the following formulation to
quantify the correlation between the activation and the source data.
L𝑑𝑒𝑐(B)=𝜈2(𝑥,𝑓)√︁
𝜈2(𝑥,𝑥)𝜈2(𝑓,𝑓), (8)Table 2: Statistics of the used datasets.
Data Size #Class #T
raining #Testing Model
CIF
AR10 32×32×3
10 50,000 10,000 MobiNet_V2
UrbanSound8K 2×64×344
10 6,986 1,732 AudioNet
UCI-HAR 128×3 6
7,352 2,947 HARNet
Figure 12: Training data split for CIFAR10, |𝐾|=1000, Qua(3).
where𝜈2(,)denotes the squared distance. Specifically, 𝜈2(𝑥,𝑓)=
1
|
B|2Í|B|
𝑖,𝑘ˆ𝐸𝑥[𝑖,𝑘]ˆ𝐸𝑓[𝑖,𝑘], and𝜈2(𝑥,𝑥)=1
|
B|2Í|B|
𝑖,𝑘ˆ𝐸𝑥[𝑖,𝑘]ˆ𝐸𝑥[𝑖,𝑘].
𝐸𝑥is the Euclidean distance matrix for 𝑥∈ B , i.e.,𝐸𝑥[𝑖,𝑘]=
||𝑥𝑖−𝑥𝑘||2), and similarly 𝐸𝑓[𝑖,𝑘]=||𝑓𝑖−𝑓𝑘||2. They are then
double-centered to ˆ𝐸𝑋and ˆ𝐸𝐹. To do this, we leverage the center-
ing matrix of size 𝑛=|B|is defined as the 𝑛-by-𝑛matrix:𝐶=𝐼−1
𝑛𝐽,
𝐼is the identity matrix of size 𝑛and𝐽is an𝑛-by-𝑛matrix of all 1’s.
Given this, ˆ𝐸𝑥can be derived by, ˆ𝐸𝑥=𝐶×𝐸𝑥×𝐶.ˆ𝐸𝑓can be derived
by,ˆ𝐸𝑓=𝐶×𝐸𝑓×𝐶. Such double centralization can remove the
effects of row and column means in the Euclidean distance matrices,
making the distance more amenable to analyzing the correlation
between𝑥and𝑓.
C Details of Experiments
C.1 Data Distribution
An overview of the data we used is presented in Table 2. More
details are given below.
Image data: We test our algorithm on CIFAR 10[11]. We dis-
tribute CIFAR10 training images (containing 50,000samples for
10classes) to|𝐾|=500and|𝐾|=1000 clients and use the global
CIFAR10 test set (containing 1,000samples per class) to report the
accuracy of the global model. We show the data splits for the first
100clients when|𝐾|=5000 in Figure 12.
Audio data: We also test FLea using UrbanSound8K dataset [ 24].
This dataset contains 8,732labeled sound excerpts ( ≤4𝑠) of urban
sounds from 10 classes: air conditioner, car horn, children playing,
dog bark, drilling, engine idling, gunshot, jackhammer, siren, and
street music. For experiments, we randomly hold out 20%(about
1700 samples) for testing and distribute the rest (about 7000 samples)
to𝐾clients for training. We split the data into |𝐾|=70and|𝐾|=
140folds, leading to an average local data size of the order of 100
and50, respectively.
Sensory data: Sensory data is another modality we experiment
with for its popularity, which can collected by wearable and mobile
devices. UCI-HAR [ 23] is a commonly used human activity recogni-
tion benchmark. It was collected by a waist-mounted smartphone
with an embedded accelerometer. Six activities including walking,
walking upstairs, walking downstairs, sitting, standing, and lying
were recorded. We employ HARNet which comprises 4 convolu-
tional layers to recognize those activitie [ 30]. We split the data into
training and testing sets, then distributed the training set to 75and
150clients to simulate different levels of scarcity, respectively.
3493FLea: Addressing Data Scarcity and Label Skew in Federated Learning via Privacy-preserving Feature Augmentation KDD ’24, August 25–29, 2024, Barcelona, Spain
C.2 Model Architecture and Hyper-parameters
We classify images in CIFAR10 using MobileNet_V2 [ 25] that has
18blocks consisting of multiple convolutional and pooling layers.
For audio classification, the audio samples are first transformed
into spectrograms and fed into a CNN model, which we termed as
AudioNet. This model consists of four blocks, each comprising a
convolutional layer, a Relu activation layer, and a Batch Normaliza-
tion layer, followed by a fully connected layer1. For HAR data, we
use a 4-layer 1D CNN model.
We use the Adam optimizer for local training with an initial
learning rate of 10−3and decay it by 2%per communication round
until 10−5. The size of the local batch is 32, and we run 10local
epochs for 100clients setting and 15local epochs for the rest. For
feature augmentation, we use 𝐵𝑒𝑡𝑎(2,2). The weights in the loss
function are set to 𝜆1=1and𝜆2=3.10%of clients are randomly
sampled at each round. We run 100communications and take the
best accuracy as the final result. For all results, we report the mean
and standard deviation of the accuracy from five runs with different
random seeds.
C.3 Baseline Implementation
More details for baseline implementations are summarized as blew,
•FedProx : We adapt the implementation from [ 16]. We test the
weight for local model regularization in [0.1,0.01,0.001]and
report the best results.
•FedLC : it calibrates the logits before softmax cross-entropy
according to the probability of occurrence of each class [ 38].
We test the scaling factor in the calibration from 0.1 to 1 and
report the best performance.
•FedDecorr: This method applies a regularization term during
local training that encourages different dimensions of the low-
dimensional features to be uncorrelated [ 26]. We adapted the
official implementation2and suggested hyper-parameter in the
source paper. We found that this method can only outperform
FedAvg with fewer than 10clients for CIFAR10.
•FedNTD : It prevents the local model drift by distilling knowl-
edge from the global model [ 13]. We use the default distilling
weights from the original paper as the settings are similar3.
•FedBR [7]: this approach leverage 32mini-batch data aver-
ages without class labels as data augmentation. A min-max
algorithm is designed, where the max step aims to make lo-
cal features for all classes more distinguishable. In contrast,
the min step enforces the local classifier to predict uniform
probabilities for the global data averages. We adopt the official
implementation4in our framework.
•CCVR: It collects a global feature set before the final fully
connected linear of the converged global model, i.e., the model
trained via FedAvg, to calibrate the classifier on the server [ 21].
For a fair comparison, we use the same amount of features as
our method for this baseline, and we fit the model using the
features instead of distributions as used in [ 21]. This allows us
to report the optimal performance of CCVR.
1https://www.kaggle.com/code/longx99/sound-classification/notebook
2https://github.com/bytedance/FedDecorr
3https://github.com/Lee-Gihun/FedNTD.git
4https://github.com/lins-lab/fedbr•FedGen: It is a method that trains a data generator using the
global model as the discriminator to create synthetic data for
local training [ 20]. The generator outputs ˆ𝑥𝑖with input(𝑦𝑖,𝑧𝑖)
where𝑧𝑖is a sample for Normal distribution. The generator is
a convolutional neural network consisting of four ConvTrans-
pose2d layers to upsample feature maps. We train the first 30
rounds by normal FedAvg and after 30 rounds, we use the global
model as the discriminator to distinguish with the generated
data ˆ𝑥𝑖is real or not.
•FedData: In this baseline, we assume the server waits until all
the clients have shared 10%of their local data in the beginning
round. The gathered data will be sent to clients to mix with
local data for model training.
•FedMix: Similar to FedData, we assume the server waits until
all the clients have shared their data averages. we use a mini-
batch of 10to aggregate the samples. Different from FedBR The
gathered data will be sent to clients, combined with local data
based on the Beta distribution.
D Privacy study
Now we present the experimental setup for privacy attacks. We use
the Qua(3) data splits when |𝐾|=100as an example for studying,
as in other settings either the label is more skewed or the local data
is more scarce, privacy attack can hardly be more effective than
this setting. This is to present the attack defending for the most
vulnerable case. As the correlation between the features and the
data is continuously reduced (shown in Figure 9(b)), we report the
reconstruction and context detection performance for 𝑐=0.65(the
1𝑠𝑡round) and𝑐=0.40(the10𝑡ℎround) for reference.
Data reconstruction. We first implemented a data reconstruc-
tion attacker, following the approach described in [ 4], the attacker
constructed a decoder for reconstruction. Specifically, the attacker
targeted the converged global model, ensuring a fair comparison.
The decoder architecture, designed to match the MobileNet_V2 ar-
chitecture, comprised four conv2d layers to reconstruct the original
data from the provided features. For visualization purposes, the
CIFAR10 images were cropped to a size of 32×32pixels without
any normalization. The decoder took the features extracted from
the global model as input and generated a reconstructed image,
which served as the basis for calculating the mean squared error
(MSE).
To train the decoder, we utilized the entire CIFAR10 training
set, conducting training for 20epochs and employing a learning
rate of 0.001. This approach allowed us to evaluate the fidelity
of the reconstructed data and compare it with the original input,
providing insights into the effectiveness of our proposed feature
interpolation method. We use the testing set and the target global
model (𝑐=0.65and𝑐=0.40) to extract features for reconstruction.
Figure 9(b) shows the training MSE while the exampled images
are from the testing set. For 𝑐=0.65, i.e., after the first round, the
sensitive attributes are removed (e.g., the color of the dog). After
10rounds when 𝑐<0.4, information is further compressed and the
privacy protection is enhanced. Overall, with L𝑑𝑒𝑐, the correlation
between data and features is reduced, preventing the image from
being reconstructed.
3494