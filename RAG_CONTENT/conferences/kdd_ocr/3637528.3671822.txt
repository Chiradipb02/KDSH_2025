Fast Computation for the Forest Matrix of an Evolving Graph
Haoxin Sun
Fudan University
Shanghai, China
21210240097@m.fudan.edu.cnXiaotian Zhou
Fudan University
Shanghai, China
22110240080@m.fudan.edu.cnZhongzhi Zhang‚àó
Fudan University
Shanghai, China
zhangzz@fudan.edu.cn
ABSTRACT
The forest matrix plays a crucial role in network science, opinion
dynamics, and machine learning, offering deep insights into the
structure of and dynamics on networks. In this paper, we study
the problem of querying entries of the forest matrix in evolving
graphs, which more accurately represent the dynamic nature of
real-world networks compared to static graphs. To address the
unique challenges posed by evolving graphs, we first introduce two
approximation algorithms, SFQandSFQPlus, for static graphs. SFQ
employs a probabilistic interpretation of the forest matrix, while
SFQPlus incorporates a novel variance reduction technique and is
theoretically proven to offer enhanced accuracy. Based on these two
algorithms, we further devise two dynamic algorithms centered
around efficiently maintaining a list of spanning converging forests.
This approach ensures ùëÇ(1)runtime complexity for updates, in-
cluding edge additions and deletions, as well as for querying matrix
elements, and provides an unbiased estimation of forest matrix en-
tries. Finally, through extensive experiments on various real-world
networks, we demonstrate the efficiency and effectiveness of our
algorithms. Particularly, our algorithms are scalable to massive
graphs with more than forty million nodes.
CCS CONCEPTS
‚Ä¢Networks‚ÜíNetwork algorithms; ‚Ä¢Theory of computation
‚ÜíRandomness, geometry and discrete structures; ‚Ä¢Informa-
tion systems‚ÜíData mining.
KEYWORDS
Forest matrix, evolving graph, Wilson‚Äôs algorithm, spanning con-
verging forest, variance reduction
ACM Reference Format:
Haoxin Sun, Xiaotian Zhou, and Zhongzhi Zhang. 2024. Fast Computation
for the Forest Matrix of an Evolving Graph. In Proceedings of the 30th ACM
SIGKDD Conference on Knowledge Discovery and Data Mining (KDD ‚Äô24),
August 25‚Äì29, 2024, Barcelona, Spain. ACM, New York, NY, USA, 10 pages.
https://doi.org/10.1145/3637528.3671822
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain.
¬©2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 979-8-4007-0490-1/24/08. . . $15.00
https://doi.org/10.1145/3637528.36718221 INTRODUCTION
As a fundamental representation of a graph, the Laplacian matrix
Lencapsulates a wealth of structural and dynamical information
of the graph [ 34]. The forest matrix, denoted as ‚Ñ¶=(I+L)‚àí1, also
plays a pivotal role in the field of network science. This matrix,
along with its variants, is recognized as a foundational matrix in
numerous applications across various domains, such as Markov
processes [ 4,5], opinion dynamics [ 21,42,50], graph signal process-
ing [ 37,38], game theory [ 6,20], and multi-label classification [ 17].
The entries of the forest matrix notably reflect the structural prop-
erties of the graph due to their close relationship with the spanning
rooted forests within the graph [ 12,13]. In particular, the diagonal
entries of ‚Ñ¶are associated with the concept of forest closeness
centrality [ 26,46] in graph mining and determinantal point pro-
cesses [ 29] in machine learning, and find applications in electrical
interpretations for multi-agent and network-based challenges [ 40].
The off-diagonal elements, ùúîùëñ ùëó, serve as a measure of the proximity
of nodeùëñand nodeùëó, with a lower ùúîùëñ ùëóindicating a greater ‚Äúdistance‚Äù
between the two nodes [ 13]. These elements are also instrumental
in calculating the personalized PageRank centrality between two
nodes [25, 47].
Due to the broad applications of the forest matrix, querying
its elements is of significant importance. In order to query the
entries of ‚Ñ¶for a graph with ùëõnodes, a direct inversion of the
matrix I+LcostsùëÇ(ùëõ3)operations and ùëÇ(ùëõ2)memories and thus
is prohibitive for relatively large graphs. In previous work, some fast
Laplacian solver [ 16] based algorithms were proposed to compute
the diagonal of the forest matrix [ 26,46]. Besides, some forest
sampling algorithms were proposed to compute the trace of the
forest matrix [8, 39] and the column sum of the forest matrix [42].
A majority of existing algorithms are designed for static graphs,
despite the fact that many real-life networks typically evolve dy-
namically. To query the elements of the forest matrix in evolving
graphs, we need to repeatedly run these algorithms as the graph
structure changes, which is very inefficient. Recognizing this limi-
tation, there is a pressing need for a dynamic approach to querying
elements of the forest matrix in evolving graphs. Such a dynamic so-
lution should be able to be updated easily whenever edges are added
or removed from the network, offering query results significantly
faster than recalculating from the beginning. Furthermore, it is
equally crucial to ensure that the solution has guaranteed accuracy.
In this paper, we delve deep into the problem of efficiently com-
puting the entries of the forest matrix in an evolving digraph, in
order to overcome the challenges and limitations of existing algo-
rithms. The main contributions of this work are summarized as
follows:
*Corresponding author. Haoxin Sun, Xiaotian Zhou, and Zhongzhi Zhang are with
Shanghai Key Laboratory of Intelligent Information Processing, School of Computer
Science, Fudan University, Shanghai 200433, China.
 
2755
KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain. Haoxin Sun, Xiaotian Zhou, and Zhongzhi Zhang*
(i) For static graphs, we introduce an algorithm SFQ to query for-
est matrix entries through a probabilistic interpretation. To enhance
accuracy and reduce variance, we develop innovative variance-
reduction techniques and present an algorithm SFQPlus, alongside
a theoretical guarantee for its performance.
(ii) In the context of evolving graphs, we focus on two edge oper-
ations: edge insertions and deletions, by devising an update strategy
to maintain a list of spanning converging forests. We demonstrate
that our algorithm provides an unbiased estimate of the forest ma-
trix entries and maintains an ùëÇ(1)runtime complexity for both
querying and updating.
(iii) Comprehensive experiments on diverse real-world undi-
rected and directed networks show that SFQPlus consistently de-
livers superior estimation accuracy compared to SFQ, which returns
results close to the ground truth. Furthermore, our algorithms are
efficient and scalable, even on massive graphs with more than forty
million nodes.
2 RELATED WORK
In this section, we briefly review the existing work related to ours.
The investigation into forest matrix entries has garnered sig-
nificant attention in recent years, leading to the development of
two main categories of algorithms for addressing related problems:
solver-based algorithms and sampling-based algorithms. Solver-
based algorithms primarily operate on undirected graphs, lever-
aging the fast Laplacian solver [ 16]. In works such as [ 26,46], the
authors utilized the fast Laplacian solver for fast calculation of
the diagonal of forest matrix. In [ 50], the authors combined the
Johnson-Lindenstrauss lemma [ 2,27] with the fast Laplacian solver
to compute relevant quantities related to the forest matrix. Another
application in [ 51] utilizes a similar method for addressing opti-
mization issues in social dynamics, fundamentally relying on the
forest matrix.
In addition to solver-based algorithms, many algorithms are
sampling-based, inspired by the matrix-forest theorem that estab-
lishes a link between spanning forests and the forest matrix [ 12,13].
Wilson‚Äôs algorithm plays a pivotal role in these sampling-based
algorithms. Wilson‚Äôs algorithm and its variants have found applica-
tions across various domains, such as computing the trace of the
forest matrix [ 8,39], estimating the diagonal of forest matrix [ 43],
computing the column sum of the forest matrix to solve optimiza-
tion problems in opinion dynamics [ 42], and solving linear systems
in graph signal processing related to the forest matrix [37, 38].
For many realistic large graphs like social networks and the In-
ternet, their structures often change over time, posing challenges
in maintaining up-to-date information. For example, as the graph‚Äôs
structure evolves, it becomes necessary to repeatedly run previously
mentioned algorithms, whether solver-based or sampling-based, to
obtain newly queried forest matrix data. Researchers have devel-
oped many special tools called dynamic graph algorithms, which
help solve problems faster. These tools have been used for vari-
ous problems that involve edge sparsifiers [ 22,23,28,44], as well
important variants of edge sparsifiers themselves, including mini-
mum spanning trees [ 24,35,36,49], spanners [ 9], spectral sparsi-
fiers [ 1,18,45], and low-stretch spanning trees [ 19]. However, mostof these advancements have been more theoretical than practical
and may not be suitable for the forest matrix query problem.
Our work takes a step further by applying Wilson‚Äôs algorithm
and providing novel techniques to reduce variance, for quickly
updating and querying any entry in the forest matrix in a graph as
it changes.
3 PRELIMINARIES
In this section, we introduce some useful notations and tools for
the convenience of description and analysis.
3.1 Graph and Laplacian Matrix
LetG=(ùëâ,ùê∏)denote an unweighted simple directed graph (di-
graph), which consists of ùëõ=|ùëâ|nodes (vertices) and ùëö=|ùê∏|
directed edges (arcs). Here, ùëâ={ùë£1,ùë£2,...,ùë£ ùëõ}denotes the set of
nodes, andùê∏represents the set of directed edges. An directed edge
(ùë£ùëñ,ùë£ùëó)‚ààùê∏indicates an edge pointing from node ùë£ùëñto nodeùë£ùëó. In
what follows, ùë£ùëñandùëñare used interchangeably to represent node
ùë£ùëñif incurring no confusion.
The structure of digraph G=(ùëâ,ùê∏)is captured by its adjacency
matrix A=(ùëéùëñ ùëó)ùëõ√óùëõ, whereùëéùëñ ùëó=1if there is a directed edge from
nodeùë£ùëñto nodeùë£ùëóandùëéùëñ ùëó=0otherwise. The in-degree ùëë‚àí
ùëñand
out-degreeùëë+
ùëñof any node ùëñare defined by ùëë‚àí
ùëñ=√çùëõ
ùëó=1ùëéùëóùëñandùëë+
ùëñ=√çùëõ
ùëó=1ùëéùëñ ùëó, respectively. In the sequel, we use ùëëùëñto represent the out-
degreeùëë+
ùëñ. The diagonal degree matrix representing the out-degrees
of digraphGisD=diag(ùëë1,ùëë2,...,ùëë ùëõ), and the Laplacian matrix
isL=D‚àíA. For any given node ùëñ,ùëÅ+
ùëñandùëÅ‚àí
ùëñdenote the sets of
its out-neighbors and in-neighbors, meaning ùëÅ+
ùëñ={ùëó:(ùëñ,ùëó)‚ààùê∏}
andùëÅ‚àí
ùëñ={ùëó:(ùëó,ùëñ)‚ààùê∏}, respectively. Let Ibe theùëõ-dimensional
identity matrix, and eùëñbe theùëñ-th standard basis column vector,
withùëñ-th element being 1 and other elements being 0.
A pathùëÉfrom nodeùë£1toùë£ùëóis a sequence of alternating nodes
and arcsùë£1,(ùë£1,ùë£2),ùë£2,¬∑¬∑¬∑,ùë£ùëó‚àí1,(ùë£ùëó‚àí1,ùë£ùëó),ùë£ùëówhere each node is
unique and every arc connects ùë£ùëñdirectly toùë£ùëñ+1. A loop is a path
plus an arc from the ending node to the starting node. A digraph
is (strongly) connected if there exists a path from one node ùë£ùë•
to another node ùë£ùë¶, and vice versa. A digraph is called weakly
connected if it is connected when one replaces any directed edge
(ùëñ,ùëó)with two directed edges (ùëñ,ùëó)and(ùëó,ùëñ)in opposite directions.
A tree is a weakly connected graph with no loops, and an isolated
node is considered as a tree. A forest is a particular graph that is a
disjoint union of trees.
3.2 Spanning Converging Forests and Forest
Matrix
In a directed graph G=(ùëâ,ùê∏), a spanning subgraph contains all
the nodes from ùëâand a subset of edges from ùê∏. A rooted converging
tree is a weakly connected digraph, where one node, called the root
node, has an out-degree of 0, and all other nodes have an out-degree
of 1. An isolated node is considered as a converging tree with the
root being itself. A spanning converging forest of digraph Gthat
includes all nodes in ùëâand whose weakly connected components
are rooted converging trees. Such a forest aligns with the concept
of in-forest as described in [3, 11].
The forest matrix [ 13,14] is defined as ‚Ñ¶=(I+L)‚àí1=(ùúîùëñ ùëó)ùëõ√óùëõ.
In the context of digraphs, the forest matrix Œ©is row stochastic,
 
2756Fast Computation for the Forest Matrix of an Evolving Graph KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain.
with all its components in the interval [0,1]. Moreover, for each
column, the diagonal elements surpass the other elements, that is
0‚â§ùúîùëóùëñ<ùúîùëñùëñ‚â§1for any pair of different nodes ùëñandùëó, and the
diagonal element ùúîùëñùëñof matrix ‚Ñ¶satisfies1
1+ùëëùëñ‚â§ùúîùëñùëñ‚â§2
2+ùëëùëñ[42].
For an unweighted digraph G=(ùëâ,ùê∏), letFdenote the set of all
its spanning converging forests. For a given spanning converging
forestùúô‚ààF, define the root set R(ùúô)ofùúôas the collection of
roots from all converging trees that constitute ùúô, that is,R(ùúô)=
{ùëñ:(ùëñ,ùëó)‚àâùúô,‚àÄùëó‚ààùëâ}. Since each node ùëñinùúôis part of a specific
converging tree, we define a function ùëüùúô(ùëñ):ùëâ‚ÜíR(ùúô)mapping
nodeùëñto the root of its associated converging tree. Thus, if ùëüùúô(ùëñ)=ùëó,
it implies that ùëóis inR(ùúô), and both nodes ùëñandùëóare part of
the same converging tree in ùúô. DefineFùëñ ùëóas the set of spanning
converging forests in which nodes ùëñandùëóare within the same
converging tree, rooted at node ùëó. Formally,Fùëñ ùëó={ùúô:ùëüùúô(ùëñ)=
ùëó,ùúô‚ààF} . It follows thatFùëñùëñ={ùúô:ùëñ‚ààR(ùúô),ùúô‚ààF} . For two
nodesùëñandùëóand a spanning converging forest ùúô, define I{ùëüùúô(ùëñ)=ùëó}
as an indicator function, which is 1 if the input statement is true
and 0 otherwise. For example, if ùëüùúô(ùëñ)=ùëó,I{ùëüùúô(ùëñ)=ùëó}=1, and
I{ùëüùúô(ùëñ)=ùëó}=0otherwise.
4 FAST QUERY OF ENTRIES IN FOREST
MATRIX FOR DIGRAPHS
In this section, we propose sampling-based algorithms and novel
variance reduction techniques, designed to enable fast querying of
entries for the forest matrix.
4.1 Extension of Wilson‚Äôs Algorithm
As mentioned above, the entries of the forest matrix are closely
related to the spanning converging forests. In this subsection, we
briefly introduce the method for uniformly generating spanning
converging forest in graphs, utilizing an extension of Wilson‚Äôs
algorithm.
Wilson proposed an algorithm based on a loop-erased random
walk to get a spanning tree rooted at a given node [ 48]. The loop-
erasure technique, pivotal to this algorithm, is a process derived
from the random walk by performing an erasure operation on its
loops in chronological order [ 31,32]. For a digraphG=(ùëâ,ùê∏),
we can also apply an extension of Wilson‚Äôs algorithm to get a
spanning converging forest ùúô‚ààF, by using the method similar
to that in [ 5,38,42], which includes the following three steps: (i)
Construct an augmented digraph G‚Ä≤ofG, which is obtained from
Gby adding one new node ŒîtoG, and adding a new edge (ùëñ,Œî)for
each nodeùëñinG. (ii) Apply Wilson‚Äôs algorithm to G‚Ä≤, designating
Œîas the root, to produce a rooted spanning tree. (iii) Remove node
Œîand its connected edges, and define the root set Ras the nodes
with an out-degree of 0, thereby obtaining a spanning converging
forest inG.
Since Wilson‚Äôs algorithm returns a uniform rooted spanning
tree [ 48], the spanning converging forest obtained using the above
steps is also uniformly selected from F. According to [ 42], the
expected time complexity for generating a uniform spanning con-
verging forest in a digraph G=(ùëâ,ùê∏)isùëÇ(ùëõ), making this method
efficient and practical for large-scale graphs.4.2 Probabilistic Interpretation and Unbiased
Estimators of Entries in Forest Matrix
In this subsection, we present a probabilistic interpretation of the
entries in the forest matrix and propose unbiased estimators for
these entries.
Using the approach in [ 10,12,13], for any pair of nodes ùëñ,ùëó‚ààùëâ,
the entryùúîùëñ ùëóof the forest matrix ‚Ñ¶can be expressed as ùúîùëñ ùëó=
|Fùëñ ùëó|/|F| . This suggests a probabilistic interpretation of the entry
ùúîùëñ ùëóof the forest matrix which represents the probability of the root
of nodeùëñbeing nodeùëóin a uniformly sampled spanning converging
forestùúô‚ààF. For a spanning converging forest ùúô‚ààF, We define
an estimator bùúîùëñ ùëó(ùúô)forùúîùëñ ùëóasbùúîùëñ ùëó(ùúô)=I{ùëüùúô(ùëñ)=ùëó}. The estimator
bùúîùëñ ùëó(ùúô)takes the value 1if the root of ùëñisùëó, and 0otherwise. This
estimator is unbiased if ùúôis uniformly selected from F, satisfying
E(bùúîùëñ ùëó(ùúô))=P(ùëüùúô(ùëñ)=ùëó)=|Fùëñùëó|
|F|=ùúîùëñ ùëó. Moreover, the variance of
bùúîùëñ ùëóisVar(bùúîùëñ ùëó)=ùúîùëñ ùëó‚àíùúî2
ùëñ ùëó.
Algorithm 1: SFQ(G,F0,ùëô,ùëñ,ùëó)
Input : A digraphG, a list ofùëôuniformly sampled
spanning converging forest F0, a pair of querying
idùëñ,ùëó
Output : bùúîùëñ ùëó: an estimator of ùúîùëñ ùëó
1Initialize :bùúîùëñ ùëó‚Üê0
2forùúôinF0do
3ùëò‚Üêùëüùúô(ùëñ)
4 ifùëò=ùëóthen
5 bùúîùëñ ùëó‚Üêbùúîùëñ ùëó+1/ùëô
6return bùúîùëñ ùëó
As previously established, we employ the extension of Wilson‚Äôs
algorithm to generate ùëôspanning converging forests ùúô1,¬∑¬∑¬∑,ùúôùëô.
Then we can approximate ùúîùëñ ùëóusing the mean value1
ùëô√çùëô
ùëò=1bùúîùëñ ùëó(ùúôùëò).
We detailed this in Algorithm 1, named as Spanning Forest Query
(SFQ). The time complexity of Algorithm 1 is ùëÇ(ùëô), whereùëôis the
number of the pre-sampled spanning converging forests.
4.3 Enhanced Estimators with Reduced
Variance
In the preceding subsection, we defined an unbiased estimator
bùúîùëñ ùëó(ùúô)forùúîùëñ ùëó. In this subsection, we introduce enhanced estimators
that not only maintain the unbiased property, but also achieve
reduced variance, thus providing more accurate estimations.
We begin with the cases ùëñ‚â†ùëó. For a spanning converging forest
ùúô‚ààF, the initial estimator bùúîùëñ ùëó(ùúô)assigns a value of 1 if a path
exists from ùëñtoùëóinùúô, and 0 otherwise. However, this approach
overlooks the case where a node ùëò‚ààùëÅ‚àí
ùëó(indicating an edge (ùëò,ùëó)‚àà
ùê∏) is the root for node ùëñin the forest ùúô. This situation suggests that
nodeùëñmight be rooted at node ùëóin other forests due to the possible
existence of a path from ùëñtoùëó, which is a concatenation of a path
fromùëñtoùëòand an edge(ùëò,ùëó). Our new approach aims to incorporate
these overlooked instances by aggregating information from forests
where node ùëñis rooted in the in-neighbors of node ùëó.
Specifically, for nodes ùëò‚ààùëÅ‚àí(ùëó),ùúîùëñùëòdenotes the probability
of nodeùëñrooted atùëò. When performing the loop-erased random
 
2757KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain. Haoxin Sun, Xiaotian Zhou, and Zhongzhi Zhang*
walk in the extension of Wilson‚Äôs algorithm, if the walk is currently
at nodeùëñ, it has a probability of1
1+ùëëùëñmoving to a random out-
neighbor or becoming a root (moving to the extended node Œîin the
augmented graphG‚Ä≤). Let‚Äôs consider a loop-erased random walk
that starts at node ùëñand ends at node ùëò, creating a path ùëÉfromùëñto
ùëòand then terminating. Now, imagine a walking path ùëÉ‚Ä≤slightly
different from path ùëÉ, where the walker does not ending at ùëò, but
continues to jump to node ùëóand then terminates. The probability
of pathùëÉ‚Ä≤occurring is1
1+ùëëùëótimes that of ùëÉ. Since any path from
ùëñtoùëómust pass through a node ùëò‚ààùëÅ‚àí(ùëó)before reaching ùëó, we
define a new estimator eùúîùëñ ùëó(ùúô)for different nodes ùëñ,ùëó, and spanning
converging forest ùúô‚ààF aseùúîùëñ ùëó(ùúô)=1
1+ùëëùëó√ç
ùëò‚ààùëÅ‚àí(ùëó)bùúîùëñùëò(ùúô).
The following lemma shows that eùúîùëñ ùëóis an unbiased estimator of
ùúîùëñ ùëóand has a reduced variance compared to bùúîùëñ ùëó:
Lemma 4.1. For two different nodes ùëñandùëóin graphGand a
uniformly chosen spanning converging forest ùúô‚àà F ,eùúîùëñ ùëó(ùúô)=
1
1+ùëëùëó√ç
ùëò‚ààùëÅ‚àí(ùëó)bùúîùëñùëò(ùúô)is an unbiased estimator of ùúîùëñ ùëó. The vari-
ance of this estimator is given by Var(eùúîùëñ ùëó)=ùúîùëñùëó
1+ùëëùëó‚àíùúî2
ùëñ ùëó, which is
always less than or equal to the variance of the estimator bùúîùëñ ùëó.
Proof. Using the relationship ‚Ñ¶(I+L)=I, it follows that
e‚ä§
ùëñ‚Ñ¶(I+L)eùëó=0. This implies(1+ùëëùëó)ùúîùëñ ùëó‚àí√ç
ùëò‚ààùëÅ‚àí
ùëóùúîùëñùëò=0,
leading toùúîùëñ ùëó=1
1+ùëëùëó√ç
ùëò‚ààùëÅ‚àí
ùëóùúîùëñùëò.Since E(bùúîùëñùëò)=ùúîùëñùëò, we have
E(eùúîùëñ ùëó)=1
1+ùëëùëó√ç
ùëò‚ààùëÅ‚àí(ùëó)E(bùúîùëñùëò)=1
1+ùëëùëó√ç
ùëò‚ààùëÅ‚àí
ùëóùúîùëñùëò=ùúîùëñ ùëó,which
shows that eùúîùëñ ùëóis an unbiased estimator of ùúîùëñ ùëó.
Next, we calculate the variance of eùúîùëñ ùëó. Considering E(bùúî2
ùëñùëò)=
ùúîùëñùëòandE(bùúîùëñ ùëóbùúîùëñùëò)=0forùëó‚â†ùëò, we have Var(eùúîùëñ ùëó)=E(eùúî2
ùëñ ùëó)‚àí
(E(eùúîùëñ ùëó))2=E(1
(1+ùëëùëó)2(√ç
ùëò‚ààùëÅ‚àí(ùëó)bùúîùëñùëò)2)‚àíùúî2
ùëñ ùëó=√ç
ùëò‚ààùëÅ‚àí(ùëó)bùúîùëñùëò
(1+ùëëùëó)2‚àí
ùúî2
ùëñ ùëó=ùúîùëñùëó
1+ùëëùëó‚àíùúî2
ùëñ ùëó, which finishes the proof. ‚ñ°
Lemma 4.1 demonstrates that eùúîùëñ ùëóis an unbiased estimator with
a lower variance compared to bùúîùëñ ùëó. The reduction in variance is
attributed to eùúîùëñ ùëóaccounting for instances where node ùëñis rooted
at the in-neighbors of node ùëó, a scenario that bùúîùëñ ùëófails to consider.
Specifically, if ùúô‚ààFùëñùëòwithùëò‚ààùëÅ‚àí
ùëó, theneùúîùëñ ùëó(ùúô)equals1
1+ùëëùëñ, while
bùúîùëñ ùëó(ùúô)is 0. Conversely, for ùúô‚ààFùëñ ùëó,bùúîùëñ ùëó(ùúô)is 1, but eùúîùëñ ùëó(ùúô)is 0.
This indicates that eùúîùëñ ùëópartially disregards instances where ùëñis
directly rooted at ùëó.
To address this issue, we introduce an estimator ùúîùëñ ùëó(ùúô,ùõº), which
is a linear combination of eùúîùëñ ùëóandbùúîùëñ ùëó, defined as ùúîùëñ ùëó(ùúô,ùõº)=
ùõºbùúîùëñ ùëó(ùúô)+(1‚àíùõº)eùúîùëñ ùëó(ùúô). The parameter ùõºis chosen to minimize
the variance of the estimator, as explained in the following lemma:
Lemma 4.2. For two distinct nodes ùëñandùëóinùëâ, a parameter ùõº‚ààR,
and a uniformly chosen spanning converging forest ùúô‚ààF, the estima-
torùúîùëñ ùëó(ùúô,ùõº)=ùõºbùúîùëñ ùëó(ùúô)+(1‚àíùõº)eùúîùëñ ùëó(ùúô)is an unbiased estimator for
ùúîùëñ ùëó. The variance of estimator ùúîùëñ ùëó(ùúô,ùõº)is minimized when ùõº=1
2+ùëëùëó.
Definingùúîùëñ ùëó(ùúô)asùúîùëñ ùëó(ùúô,1
2+ùëëùëó)=1
2+ùëëùëó(bùúîùëñ ùëó(ùúô)+√ç
ùëò‚ààùëÅ‚àí
ùëóbùúîùëñùëò(ùúô)),
the variance of ùúîùëñ ùëó(ùúô)is given by Var(eùúîùëñ ùëó)=ùúîùëñùëó
2+ùëëùëó‚àíùúî2
ùëñ ùëó, which
is smaller than that of both bùúîùëñ ùëó(ùúô)andeùúîùëñ ùëó(ùúô). Moreover, the non-
negativity of variance implies ùúîùëñ ùëó‚â§1
2+ùëëùëó.
Proof. Since both bùúîùëñ ùëóandeùúîùëñ ùëóare unbiased estimators for ùúîùëñ ùëó,
it follows that E(ùúîùëñ ùëó(ùúô,ùõº))=ùõºE(bùúîùëñ ùëó(ùúô))+( 1‚àíùõº)E(eùúîùëñ ùëó(ùúô))=ùúîùëñ ùëó, indicating the estimator ùúîùëñ ùëó(ùúô,ùõº)is also unbiased for ùúîùëñ ùëó. We
proceed to calculate the variance of ùúîùëñ ùëó(ùúô,ùõº)as
Var(ùúîùëñ ùëó(ùúô,ùõº))=E(ùúî2
ùëñ ùëó(ùúô,ùõº))‚àí(E(ùúîùëñ ùëó(ùúô,ùõº))2
=ùúîùëñ ùëó(2+ùëëùëó)
1+ùëëùëó
ùõº‚àí1
2+ùëëùëó2
+ùúîùëñ ùëó
2+ùëëùëó‚àíùúî2
ùëñ ùëó.
The variance of the estimator ùúîùëñ ùëó(ùúô,ùõº)is minimized when ùõº=
1
2+ùëëùëó, resulting inùúîùëñùëó
2+ùëëùëó‚àíùúî2
ùëñ ùëó, which finishes the proof. ‚ñ°
Lemma 4.2 indicates that the newly formulated estimator ùúîùëñ ùëó(ùúô)=
1
2+ùëëùëó(bùúîùëñ ùëó(ùúô)+√ç
ùëò‚ààùëÅ‚àí
ùëóbùúîùëñùëò(ùúô))has a lower variance than the pre-
vious two estimators by incorporating their respective information.
Having established the improved estimator ùúîùëñ ùëófor the scenario
ùëñ‚â†ùëó, we next focus on the situation that ùëñis equal toùëó.
For the case ùëñ=ùëó, we consider a similar approach of aggregating
information from the in-neighbors of node ùëñ. This leads to a new
estimator with reduced variance compared to bùúîùëñùëñ. We define the new
estimatorùúîùëñùëñ(ùúô)asùúîùëñùëñ(ùúô)=1
1+ùëëùëñ(1+√ç
ùëò‚ààùëÅ‚àí
ùëñbùúîùëñùëò(ùúô)). Lemma 4.3
demonstrates that ùúîùëñùëñ(ùúô)is an unbiased estimator for ùúîùëñùëñwith
reduced variance.
Lemma 4.3. For nodeùëñ‚ààùëâand a uniformly chosen spanning con-
verging forest ùúô‚ààF,ùúîùëñùëñ(ùúô)=1
1+ùëëùëñ(1+√ç
ùëò‚ààùëÅ‚àí
ùëñbùúîùëñùëò(ùúô))is an unbi-
ased estimator for ùúîùëñùëñ. The variance of this estimator is Var(ùúîùëñùëñ)=
3ùúîùëñùëñ
1+ùëëùëñ‚àí2
(1+ùëëùëñ)2‚àíùúî2
ùëñùëñ, which is always less than or equal to the variance
of the estimator bùúîùëñùëñ.
Proof. Since ‚Ñ¶(I+L)=I, it follows that e‚ä§
ùëñ‚Ñ¶(I+L)eùëñ=1.
This implies(1+ùëëùëñ)ùúîùëñùëñ‚àí√ç
ùëò‚ààùëÅ‚àí
ùëñùúîùëñùëò=1, that is,ùúîùëñùëñ=1
1+ùëëùëñ(1+
√ç
ùëò‚ààùëÅ‚àí
ùëñùúîùëñùëò).Since E(bùúîùëñùëò)=ùúîùëñùëò, we have E(ùúîùëñùëñ)=1
1+ùëëùëñ(1+
√ç
ùëò‚ààùëÅ‚àí(ùëñ)E(bùúîùëñùëò))=1
1+ùëëùëñ(1+√ç
ùëò‚ààùëÅ‚àí
ùëñùúîùëñùëò)=ùúîùëñùëñ,which shows
thateùúîùëñ ùëóis an unbiased estimator for ùúîùëñ ùëó. The variance of ùúîùëñùëñcan be
derived as follows: Var(ùúîùëñùëñ)=E(ùúîùëñùëñ)2‚àí(E(ùúîùëñùëñ))2=1
(1+ùëëùëñ)2E((1+
√ç
ùëò‚ààùëÅ‚àí
ùëñbùúîùëñùëò)2)‚àíùúî2
ùëñùëñ=1
(1+ùëëùëñ)2E(1+2√ç
ùëò‚ààùëÅ‚àí
ùëñbùúîùëñùëò+(√ç
ùëò‚ààùëÅ‚àí
ùëñbùúîùëñùëò)2)‚àí
ùúî2
ùëñùëñ=1+3√ç
ùëò‚ààùëÅ‚àí
ùëñùúîùëñùëò
(1+ùëëùëñ)2‚àíùúî2
ùëñùëñ=1+3((1+ùëëùëñ)ùúîùëñùëñ‚àí1)
(1+ùëëùëñ)2‚àíùúî2
ùëñùëñ=3ùúîùëñùëñ
1+ùëëùëñ‚àí2
(1+ùëëùëñ)2‚àí
ùúî2
ùëñùëñ.Then we get the following relation Var{bùúîùëñùëñ}‚àíVar{ùúîùëñùëñ}=
2(1‚àíùúîùëñùëñ)
(1+ùëëùëñ)2+ùëëùëñ(ùëëùëñ‚àí1)ùúîùëñùëñ
(1+ùëëùëñ)2‚â•0.This inequality shows that the variance
ofùúîùëñùëñis no more than the variance of the estimator bùúîùëñùëñ, which
completes the proof. ‚ñ°
In the above, we have proposed enhanced estimators ùúîùëñùëñand
ùúîùëñ ùëófor the diagonal ùúîùëñùëñand non-diagonal entries ùúîùëñ ùëó. Suppose
that we already have used the extension of Wilson‚Äôs algorithm to
generateùëôspanning converging forests ùúô1,¬∑¬∑¬∑,ùúôùëô. Then we can
approximate ùúîùëñùëñandùúîùëñ ùëóusing1
ùëô√çùëô
ùëò=1ùúîùëñùëñ(ùúôùëò)and1
ùëô√çùëô
ùëò=1ùúîùëñ ùëó(ùúôùëò).
We detailed this in Algorithm 2, named as Spanning Forest Query
Plus (SFQPlus).
The time complexity of Algorithm 2 is ùëÇ(ùëô), whereùëôis the num-
ber of the pre-sampled spanning converging forests. As we increase
the number of pre-sampled forest ùëô, we observe a corresponding
decrease in the estimation error between ùúîùëñ ùëóand the actual value
ùúîùëñ ùëó. To quantify this relationship, we introduce Theorem 4.5, which
specifies the necessary size of ùëôto achieve a necessary error guaran-
tee with a high probability. Before giving Theorem 4.5, we introduce
the following lemma.
 
2758Fast Computation for the Forest Matrix of an Evolving Graph KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain.
Algorithm 2: SFQPlus(G,F0,ùëô,ùëñ,ùëó)
Input : A digraphG=(ùëâ,ùê∏), a list ofùëôuniformly
sampled spanning converging forest F0, a pair of
querying id ùëñ,ùëó
Output :ùúîùëñ ùëó: an estimator of ùúîùëñ ùëó
1ifùëñ=ùëóthen
2 Initialize :ùúîùëñ ùëó‚Üê1
1+ùëëùëñ
3else
4 Initialize :ùúîùëñ ùëó‚Üê0
5forùúôinF0do
6ùëò‚Üêùëüùúô(ùëñ)
7 ifùëò=ùëó&ùëñ‚â†ùëóthen
8ùúîùëñ ùëó‚Üêùúîùëñ ùëó+1
(2+ùëëùëó)ùëô
9 else if edge(ùëò,ùëó)‚ààùê∏then
10 ifùëñ=ùëóthen
11 ùúîùëñ ùëó‚Üêùúîùëñ ùëó+1
(1+ùëëùëó)ùëô
12 else
13 ùúîùëñ ùëó‚Üêùúîùëñ ùëó+1
(2+ùëëùëó)ùëô
14returnùúîùëñ ùëó
Lemma 4.4. (Chernoff bound [ 15]) Letùë•ùëñ(1‚â§ùëñ‚â§ùëô)be indepen-
dent random variables satisfying |ùë•ùëñ‚àíE{ùë•ùëñ}|‚â§ùëÄfor all 1‚â§ùëñ‚â§ùëô.
Letùë•=1
ùëô√çùëô
ùëñ=1ùë•ùëñ. Then we have
P(|ùë•‚àíE{ùë•}|‚â§ùúñ)‚â•1‚àí2 exp
‚àíùëôùúñ2
2(Var{ùë•}ùëô+ùëÄùúñ/3)
.(1)
Theorem 4.5. For any pair of nodes ùëñ‚â†ùëó, and parameters ùúñ,ùúé,ùõø‚àà
(0,1), ifùëôis chosen obeying ùëô=l
1
(2+ùëëùëó)2(1
2ùúñ2+2
3ùúñ)log(2
ùõø)m
, then
the approximation ùúîùëñ ùëóofùúîùëñ ùëóreturned by Algorithm 2 satisfies the
following relation with probability of at least 1‚àíùõø:
ùúîùëñ ùëó‚àíùúñ‚â§ùúîùëñ ùëó‚â§ùúîùëñ ùëó+ùúñ. (2)
For the case that ùëñ=ùëó, and for parameters ùúñ,ùõø‚àà(0,1), ifùëôis cho-
sen obeying ùëô=l
(2
3ùúñ+1
4ùúñ2)log(2
ùõø)m
, then the approximation ùúîùëñùëñ
ofùúîùëñùëñreturned by Algorithm 2 satisfies the following relation with
probability of at least 1‚àíùõø:
(1‚àíùúñ)ùúîùëñùëñ‚â§ùúîùëñùëñ‚â§(1+ùúñ)ùúîùëñùëñ. (3)
Proof. For the case that ùëñ‚â†ùëó, the output ùúîùëñ ùëóof Algorithm 2
isùúîùëñ ùëó=1
ùëô√çùëô
ùëò=1ùúîùëñ ùëó(ùúôùëò). Since the variance of ùúîùëñ ùëó(ùúôùëò)isùúîùëñùëó
2+ùëëùëó‚àí
ùúî2
ùëñ ùëóforùëò=1,¬∑¬∑¬∑,ùëô, and theùëôvariables are independent, we can
compute the variance of ùúîùëñ ùëóasVar(ùúîùëñ ùëó)=1
ùëô(ùúîùëñùëó
2+ùëëùëó‚àíùúî2
ùëñ ùëó). To obtain
the absolute error bound given by (2), ùúîùëñ ùëóneeds to satisfy
P(|ùúîùëñ ùëó‚àíùúîùëñ ùëó|‚â•ùúñ)‚â§ùõø.
We now show that the above relation holds true. To this end, we
designateùë•ùëó=ùúîùëñ ùëó(ùúôùëò)for1‚â§ùëò‚â§ùëôandùë•=ùúîùëñ ùëó, and invoke the
Chernoff bound in Lemma 4.4. Then, in order to prove (2), we only
need to show that the following inequality holds:
2 exp
‚àíùëôùúñ2
2(Var{ùúîùëñ ùëó}ùëô+ùëÄùúñùúî ùëñ ùëó/3)
‚â§ùõø,which leads to
ùëô‚â•log(2
ùõø)2Var{ùúîùëñ ùëó}ùëô
ùúñ2+2ùëÄùúîùëñ ùëó
3ùúñ
. (4)
Since|bùúîùëñ ùëó‚àíùúîùëñ ùëó|‚â§1
2+ùëëùëó, we can set ùëÄ=1
2+ùëëùëó. Considering that
Var{ùúîùëñ ùëó(ùúôùëó)}=1
ùëô(ùúîùëñùëó
2+ùëëùëó‚àíùúî2
ùëñ ùëó), inequality (4) is reduced to:
ùëô‚â•log(2
ùõø) 
2ùúîùëñ ùëó
ùúñ2(2+ùëëùëó)+2ùúîùëñ ùëó
3ùúñ(2+ùëëùëó)‚àí2ùúî2
ùëñ ùëó
ùúñ2!
. (5)
Thus, for any pair of nodes ùëñ‚â†ùëó, since 0‚â§ùúîùëñ ùëó‚â§1
2+ùëëùëó, selecting
ùëô=
1
2ùúñ2+2
3ùúñlog2
ùõø
(2+ùëëùëó)2
ensures the required inequality (4)always
holds. This completes the proof.
For the case that ùëñ=ùëó, the output ùúîùëñùëñof Algorithm 2 is ùúîùëñùëñ=
1
ùëô√çùëô
ùëò=1ùúîùëñùëñ(ùúôùëò). For a spanning converging forest ùúô‚ààF,ùúîùëñùëñ(ùúô)
is either1
1+ùëëùëñor2
1+ùëëùëñ. Considering1
1+ùëëùëñ‚â§ùúîùëñùëñ‚â§2
2+ùëëùëñ, it follows
that|ùúîùëñùëñ‚àíùúîùëñùëñ|‚â§1
1+ùëëùëñ. Then we can set the bound ùëÄasùëÄ=1
1+ùëëùëñ.
Employing a similar analytical approach as above, the number of ùëô
needs to satisfy the following inequality:
ùëô‚â•log(2
ùõø) 
2Var{ùúîùëñùëñ}ùëô
ùúñ2ùúî2
ùëñùëñ+2
3(1+ùëëùëñ)ùúñùúîùëñùëñ!
. (6)
Given thatùúîùëñùëñ=1
ùëô(3ùúîùëñùëñ
1+ùëëùëñ‚àí2
(1+ùëëùëñ)2‚àíùúî2
ùëñùëñ), we derive that
Var(ùúîùëñùëñ)ùëô
ùúî2
ùëñùëñ=3
(1+ùëëùëñ)ùúîùëñùëñ‚àí2
(1+ùëëùëñ)2ùúî2
ùëñùëñ‚àí1
=‚àí2
(1+ùëëùëñ)2(1
ùúîùëñùëñ‚àí3(1+ùëëùëñ)
4)2+1
8‚â§1
8(7)
Thus, withVar(ùúîùëñùëñ)ùëô
ùúî2
ùëñùëñ‚â§1
8and(1+ùëëùëñ)ùúîùëñùëñ‚â§1, choosing ùëô=
l
(2
3ùúñ+1
4ùúñ2)log
2
ùõøm
ensures that inequality (6)is always satisfied,
which completes the proof. ‚ñ°
Based on Theorem 4.5, when the parameters ùúñ,ùúé, andùõøare fixed
constants, the number of spanning converging forests ùëôrequired
by Algorithm 2 to achieve an ùúñabsolute error for non-diagonal
entries and relative error for diagonal entries does not increase
with the expansion of the graph. Therefore, the time complexity of
Algorithm 2 can be considered as ùëÇ(1)for achieving a satisfactory
error guarantee, regardless of the graph size.
5 FAST QUERY OF ENTRIES OF FOREST
MATRIX FOR EVOLVING GRAPHS
In the previous section, we developed estimators approximating
the entries of the forest matrix in static directed graphs. However,
real-world graphs often evolve dynamically. This section addresses
evolving graphs, focusing on two types of updates: edge insertion
and edge deletion.
5.1 Problem Statement
Consider an initial graph G0=(ùëâ0,ùê∏0)and a corresponding list
ùêø0ofùëô0spanning converging forests, which is uniformly sampled
using an extension of Wilson‚Äôs algorithm. In this dynamic context,
there are two possible requests: updates and queries. For the request
of updates, we restrict our focus to edge insertions and deletions.
 
2759KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain. Haoxin Sun, Xiaotian Zhou, and Zhongzhi Zhang*
Other updates such as nodes insertions/deletions can be easily
converted to a sequence of edges insertion/deletions. For the ùëò-
th edge update, let ùëíùëò=(ùë¢ùëò,ùë£ùëò)denote the edge being modified,
resulting in an updated graph Gùëò=(ùëâùëò,ùê∏ùëò). Specifically, for edge
insertions,ùê∏ùëò=ùê∏ùëò‚àí1‚à™{ùëíùëò}, and for deletions, ùê∏ùëò=ùê∏ùëò‚àí1\{ùëíùëò}.
Query requests involve asking for specific values of the forest
matrix entries ofGùëò, denoted by ‚Ñ¶ùëò. LetF(G ùëò)denote the set of
all spanning converging forests of graph Gùëò. Utilizing the methods
described earlier, if we have spanning converging forests uniformly
sampled fromF(G ùëò), Algorithm SFQPlus can provide an estima-
tion. However, resampling these forests after every update requires
time complexity of ùëÇ(ùëôùëõ)[42], which is inefficient. This naturally
leads to the following question. Suppose that ùêøùëò‚àí1is a spanning con-
verging forest list with ùëôùëò‚àí1spanning converging forests uniformly
sampled from the set F(G ùëò‚àí1). When an update ùëíùëò=(ùë¢ùëò,ùë£ùëò)oc-
curs, can we develop an efficient method to adapt the list ùêøùëò‚àí1into
ùêøùëò, ensuring that each spanning converging forest in set F(G ùëò)
has an equal probability appearing in the updated forest list ùêøùëò?
In the following, we address this challenge by proposing a method
with an expected cost of ùëÇ(1)for updating the forest list, while
preserving the uniform property of the sampling.
5.2 Edge Insertion
In this subsection, we delve into the edge insertion update. Consider
theùëò-th update involving the insertion of an edge ùëíùëò=(ùë¢ùëò,ùë£ùëò)
to the graphGùëò‚àí1. We start with a spanning converging forest
listùêøùëò‚àí1={ùúô1,¬∑¬∑¬∑,ùúôùëôùëò‚àí1}withùëôùëò‚àí1spanning converging forests.
Each forest from the set F(G ùëò‚àí1)is equally likely to be included in
listùêøùëò‚àí1. Our goal is to modify ùêøùëò‚àí1intoùêøùëòsuch that the forests
inùêøùëòare uniformly sampled from the updated set F(G ùëò).
Given thatùê∏ùëò=ùê∏ùëò‚àí1‚à™{ùëíùëò}, it follows thatF(G ùëò‚àí1)is a subset
ofF(G ùëò), indicating that all forests in F(G ùëò‚àí1)are also contained
inF(G ùëò). We now focus on those spanning converging forests that
are inF(G ùëò)but not inF(G ùëò‚àí1). Define ŒîFùëòasF(G ùëò)\F(G ùëò‚àí1).
It‚Äôs clear that ŒîFùëòis non-empty, and all its forests include the newly
added edgeùëíùëò=(ùë¢ùëò,ùë£ùëò). We define a subset F(G‚Ä≤
ùëò‚àí1)‚äÇF(G ùëò‚àí1),
whereF(G‚Ä≤
ùëò‚àí1)={ùúô:ùúô‚ààF(G ùëò‚àí1),ùëüùúô(ùë¢ùëò)=ùë¢ùëò,ùëüùúô(ùë£ùëò)‚â†ùë¢ùëò}.
Lemma 5.1 establishes a bijection between F(G‚Ä≤
ùëò‚àí1)andŒîFùëò.
Lemma 5.1. For any spanning converging forest ùúô‚ààŒîFùëò, the
forestùúô‚Ä≤=ùúô\{ùëíùëò}belongs toF(G‚Ä≤
ùëò‚àí1). This mapping constitutes a
bijection betweenF(G‚Ä≤
ùëò‚àí1)andŒîFùëò.
Proof. Consider a spanning converging forest ùúô‚ààŒîFùëò, which
includes the newly added edge ùëíùëò=(ùë¢ùëò,ùë£ùëò). By removing this
edge, we obtain the forest ùúô‚Ä≤=ùúô\{ùëíùëò}. Since all edges of ùúô‚Ä≤are
part of the graphGùëò‚àí1, it is evident that ùúô‚Ä≤belongs toF(G ùëò‚àí1).
Moreover, given that ùëüùúô‚Ä≤(ùë¢ùëò)=ùë¢ùëòandùëüùúô‚Ä≤(ùë£ùëò)‚â†ùë¢ùëò,ùúô‚Ä≤is also a
part ofF(G‚Ä≤
ùëò‚àí1).
Moreover, for any two distinct spanning converging forests
ùúô1,ùúô2‚ààŒîFùëò, their corresponding forests ùúô‚Ä≤
1andùúô‚Ä≤
2obtained by
deleting edge ùëíùëòare also distinct. Additionally, for any spanning
forestùúô‚Ä≤‚ààF(G‚Ä≤
ùëò‚àí1), we consider the forest ùúô=ùúô‚Ä≤‚à™{ùëíùëò}. The
conditionsùëüùúô‚Ä≤(ùë¢ùëò)=ùë¢ùëòandùëüùúô‚Ä≤(ùë£ùëò)‚â†ùë¢ùëòguarantee that ùúôis
well-defined and belongs to ùêøùëò, which finishes the proof. ‚ñ°
With Lemma 5.1, we propose the edge insertion update Algo-
rithm 3 to update the forest list ùêøùëò‚àí1toùêøùëò.Algorithm 3: Insert-Update(Gùëò‚àí1,ùêøùëò‚àí1,ùëôùëò‚àí1,ùëíùëò)
Input : A digraphGùëò‚àí1=(ùëâùëò‚àí1,ùê∏ùëò‚àí1), a list ofùëôùëò‚àí1
spanning converging forest ùêøùëò‚àí1uniformly
sampled fromF(G ùëò‚àí1), an edgeùëíùëò=(ùë¢ùëò,ùë£ùëò)to
be inserted
Output : An updated spanning converging forest list ùêøùëò
1Initialize :ùêøùëò‚Üêùêøùëò‚àí1
2forùúôinùêøùëò‚àí1do
3 ifùëüùúô(ùë¢ùëò)=ùë¢ùëò&ùëüùúô(ùë£ùëò)‚â†ùë¢ùëòthen
4 bùúô‚Üêùúô‚à™{ùëíùëò}
5 Addbùúôtoùêøùëò
6returnùêøùëò
Theorem 5.2. For a spanning converging forest list ùêøùëò‚àí1with
ùëôùëò‚àí1forests uniformly sampled from F(G ùëò‚àí1), and the insertion
edgeùëíùëò=(ùë¢ùëò,ùë£ùëò), all forests in the updated set F(G ùëò)have the
same probability to be included in the list returned by Algorithm 3.
Proof. We partitionF(G ùëò)into two disjoint subsets: F(G ùëò‚àí1)
andŒîFùëò, with ŒîFùëò=F(G ùëò)\F(G ùëò‚àí1). In order to prove the
theorem, we distinguish four cases: (i) ùúô1‚ààF(G ùëò‚àí1)andùúô2‚àà
F(G ùëò‚àí1), (ii)ùúô1‚ààŒîFùëòandùúô2‚ààŒîFùëò, (iii)ùúô1‚ààŒîF(G ùëò‚àí1)and
ùúô2‚ààŒîFùëò, and (iv)ùúô1‚ààŒîFùëòandùúô2‚ààŒîF(G ùëò‚àí1). Moreover, for
the convenience of description, let P(ùúô1‚ààùêøùëò)denote the proba-
bility that forest ùúô1is inùêøùëò. In a similar way, we can define other
probabilities. Note that all forests in ùêøùëò‚àí1are uniformly sampled
fromF(G ùëò‚àí1). Then, the theorem can be proved as follows.
For the first case that ùúô1‚ààF(G ùëò‚àí1)andùúô2‚ààF(G ùëò‚àí1), we
haveP(ùúô1‚ààùêøùëò)=P(ùúô1‚ààùêøùëò‚àí1)=P(ùúô2‚ààùêøùëò‚àí1)=P(ùúô2‚ààùêøùëò).
For the second case that ùúô1‚ààŒîFùëòandùúô2‚ààŒîFùëò, defineùúô‚Ä≤
1=
ùúô1\{ùëíùëò}andùúô‚Ä≤
2=ùúô2\{ùëíùëò}. Then we have that P(ùúô1‚ààùêøùëò)=
P(ùúô‚Ä≤
1‚ààùêøùëò‚àí1)=P(ùúô‚Ä≤
2‚ààùêøùëò‚àí1)=P(ùúô2‚ààùêøùëò).
For the third case that ùúô1‚ààŒîF(G ùëò‚àí1)andùúô2‚ààŒîFùëò, define
ùúô‚Ä≤
2=ùúô2\{ùëíùëò}. Then we have P(ùúô1‚ààùêøùëò)=P(ùúô1‚ààùêøùëò‚àí1)=P(ùúô‚Ä≤
2‚àà
ùêøùëò‚àí1)=P(ùúô2‚ààùêøùëò).
For the fourth case that ùúô1‚ààŒîFùëòandùúô2‚ààŒîF(G ùëò‚àí1), using
the same approach as the third case, we obtain P(ùúô1‚ààùêøùëò)=P(ùúô2‚àà
ùêøùëò).
Thus, for two distinct forests ùúô1,ùúô2‚ààF(G ùëò), they have equal
probability to appear in ùêøùëò. which finishes the proof. ‚ñ°
Theorem 5.2 demonstrates that the list ùêøùëò, generated by Algo-
rithm 3, achieves uniform sampling from the updated set F(G ùëò).
Additionally, the time complexity of Algorithm 3 is ùëÇ(ùëôùëò‚àí1), where
ùëôùëò‚àí1is the number of forests in the initial list ùêøùëò‚àí1.
Example 5.3. Consider a simple graph G0in Figure 1, which has
3nodes and 3edges. GraphG0comprises 7 spanning converging
forests, highlighted in the first row of Figure 1. After the inser-
tion of edge ùëí=(1,3), the graph updates to G1, which contains 9
spanning converging forests forming F(G 1), as demonstrated in
the second row of Figure 1. Suppose that we have a forest list ùêø0
uniformly sampled from F(G 0). A straightforward interpretation
of Algorithm 3 for updating the list ùêø0toùêø1involves two steps: first
creating a copy of ùêø0, and then attempting to add the new edge into
each forest in the list ùêø0. For the 7 forests in ùêø0, only two forests ùúô1
 
2760Fast Computation for the Forest Matrix of an Evolving Graph KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain.
andùúô2, distinguished by a yellow background, evolve into the valid
forests bùúô1andbùúô2with the incorporation of the edge ùëí=(1,3). The
addition of edge ùëíto other forests either generates a cycle or results
in a node with an out-degree of 2, both of which contradict the
definition of spanning converging forests. Lemma 5.1 theoretically
validates that there is a bijection between the sets {ùúô1,ùúô2}and
{bùúô1,bùúô2}, which validates that each forest in F(G 1)has the same
probability to appear in ùêø1.
1 23
1 23G0
G1œÜ1 œÜ2
/hatwideœÜ1/hatwideœÜ2
1
Figure 1: A toy digraph G0and updated graph G1with their
spanning converging forests. Blue nodes are roots.
5.3 Edge Deletion
In this subsection, we consider the edge deletion update. Specifi-
cally, we consider the deletion of an edge ùëíùëò=(ùë¢ùëò,ùë£ùëò)from the
graphGùëò‚àí1, resulting in the updated graph Gùëò=Gùëò‚àí1\{ùëíùëò}. Our
objective is to adapt the initial forest list ùêøùëò‚àí1intoùêøùëò, ensuring the
uniformity property of the sampling is preserved.
Given that the updated edge set ùê∏ùëòis defined as ùê∏ùëò=ùê∏ùëò‚àí1\{ùëíùëò},
it is evident thatF(G ùëò)is a subset ofF(G ùëò‚àí1). A straightforward
approach comes to our mind: for the forests in ùêøùëò‚àí1, we can define
the updated list ùêøùëò={ùúô:ùúô‚ààùêøùëò‚àí1,ùëíùëò‚àâùúô}. That is,ùêøùëòis the
subset ofùêøùëò‚àí1excluding any forests that contain the edge ùëíùëò. This
method ensures that all forests in F(G ùëò)are equally likely to be
included in ùêøùëò, under the assumption that all forests in ùêøùëò‚àí1are
uniformly sampled from F(G ùëò‚àí1).
However, this method poses a challenge. The number of forests
ùëôùëòin the updated list ùêøùëòwill always be less than or equal to ùëôùëò‚àí1.
Consequently, if all updates are edge deletions, the size of our
sampling forest lists will continually diminish. This reduction in
sampling size could result in decreased accuracy when responding
to query requests. Therefore, the challenge arises: can we devise an
alternative method that maintains the uniformity property without
leading to a reduction in the number of sampling forests?
To address the challenge, we define ŒîF(G ùëò)=F(G ùëò‚àí1)\
F(G ùëò). The solution lies in not merely discarding the forests in
ŒîF(G ùëò)but effectively utilizing them. Define F(G‚Ä≤
ùëò)={ùúô:ùúô‚àà
F(G ùëò),ùëüùúô(ùë¢ùëò)=ùë¢ùëò,ùëüùúô(ùë£ùëò)‚â†ùë¢ùëò}. Considering that edge inser-
tion and deletion are inverse operations, Lemma 5.1 establishes a
bijection between ŒîF(G ùëò)andF(G‚Ä≤
ùëò). Specifically, for a forest ùúô
inŒîF(G ùëò), the forestùúô\{ùëíùëò}is included inF(G‚Ä≤
ùëò). This insight
provides a method to utilize forests in ŒîF(G ùëò)without discard-
ing them. We then introduce an edge deletion update method, the
pseudocode of which is described in Algorithm 4.
Theorem 5.4. For a spanning converging forest list ùêøùëò‚àí1with
ùëôùëò‚àí1forests uniformly sampled from F(G ùëò‚àí1), and the deletion edge
ùëíùëò=(ùë¢ùëò,ùë£ùëò), all forests in the updated set F(G ùëò)have the same
probability to be included in the list returned by Algorithm 4.Algorithm 4: Delete-Update(Gùëò‚àí1,ùêøùëò‚àí1,ùëôùëò‚àí1,ùëíùëò)
Input : A digraphGùëò‚àí1=(ùëâùëò‚àí1,ùê∏ùëò‚àí1), a list ofùëôùëò‚àí1
spanning converging forest ùêøùëò‚àí1uniformly
sampled fromF(G ùëò‚àí1), an edgeùëíùëò=(ùë¢ùëò,ùë£ùëò)to
be deleted
Output : An updated spanning converging forest list ùêøùëò
1Initialize :ùêøùëò‚Üê‚àÖ
2forùúôinùêøùëò‚àí1do
3 ifùëíùëò‚ààùúôthen
4ùúô‚Üêùúô\{ùëíùëò}
5 Addùúôtoùêøùëò
6 else ifùëüùúô(ùë¢ùëò)=ùë¢ùëò&ùëüùúô(ùë£ùëò)‚â†ùë¢ùëòthen
7 Addùúôtoùêøùëò
8 else
9 Addùúôtoùêøùëòtwice
10returnùêøùëò
The proof of Theorem 5.4 is similar to that of Theorem 5.2. The-
orem 5.4 demonstrates that the list ùêøùëò, generated by Algorithm 4,
ensures uniform sampling from the updated set F(G ùëò).
Example 5.5. For a better understanding of Algorithm 4, we
present an example depicted in Figure 2. In this example, we re-
move the edge ùëí=(3,1)from graphG0, resulting in graph G1. Set
F(G 0)contains 7 spanning converging forests, shown in the first
row of Figure 2, while the set F(G 1)comprises 4 spanning con-
verging forests, illustrated in the second row of Figure 2. Assuming
a forest list ùêø0is uniformly sampled from F(G 0), a straightfor-
ward approach might suggest discarding the forests ùúô5,ùúô6,ùúô7inùêø0
to formùêø1. However, this strategy will unfortunately reduce the
sampling size, as mentioned earlier.
Algorithm 4 addresses this challenge by utilizing the forests
ùúô5,ùúô6,ùúô7. Lemma 5.1 suggests a bijection between {bùúô1,bùúô2,bùúô3}and
{ùúô5,ùúô6,ùúô7}. According to Algorithm 4, for a forest in ùêø0, if it belongs
to the set{ùúô1,ùúô2,ùúô3}, it is directly added to ùêø1. If a forest is part
of the set{ùúô4,ùúô5,ùúô6}, we first remove the edge ùëí=(3,1)and then
include the modified forest in ùêø1. This procedure ensures that bùúô1is
derived from ùúô1andùúô5,bùúô2fromùúô2andùúô6, andbùúô3fromùúô3andùúô7.
To maintain balanced probabilities, Algorithm 4 adds ùúô4toùêø1twice,
which is highlighted with a yellow background, thereby ensuring
uniformity in the sampling process from the updated forest set.
1 23
1 23G0
G1œÜ1 œÜ2 œÜ3 œÜ4 œÜ5 œÜ6 œÜ7 œÜ3
/hatwideœÜ1/hatwideœÜ2/hatwideœÜ3/hatwideœÜ4
1
Figure 2: A toy digraph G0and updated graph G1with their
spanning converging forests.
 
2761KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain. Haoxin Sun, Xiaotian Zhou, and Zhongzhi Zhang*
5.4 Prune Technique and Algorithm Details
In this subsection, we introduce the prune technique as well as
some details of our algorithms.
Prune Technique. The time complexity of Algorithm 3 and
Algorithm 4 is ùëÇ(ùëôùëò‚àí1), whereùëôùëò‚àí1is the number of spanning
converging forests in the input list ùêøùëò‚àí1. As illustrated previously,
the number ùëôùëòof spanning converging forests in the updated list
ùêøùëòeither equals or exceeds ùëôùëò‚àí1, irrespective of the update being
an edge insertion or deletion. Given ùëòupdates, with the number of
spanning converging forests incrementally rising as ùëô0‚â§ùëô1‚â§...‚â§
ùëôùëò, it becomes essential to mitigate the potential for exponential
growth. To this end, we introduce the pruning technique, which
involves setting a threshold ùëô‚Ä≤, for instance, ùëô‚Ä≤=5ùëô0. Ifùëôùëòsurpasses
ùëô‚Ä≤, a pruning action is undertaken to uniformly select ùëô‚Ä≤forests from
ùêøùëò, thereby constituting ùêø‚Ä≤
ùëò. This pruning strategy aims to ensure
that the time taken for updates and queries remains manageable,
avoiding significant increases as the number of updates grows.
Algorithm Details. For every spanning converging forest, our
algorithms retain information on the next node for each node in
the forest and its root node. This setup results in a space complexity
ofùëÇ(ùëôùëõ), withùëôrepresenting the required number of spanning
converging forests. Upon an update, when either Algorithm 3 or
Algorithm 4 is activated, we avoid directly replicating forests to
avoid theùëÇ(ùëõ)cost in copying a single forest. Instead, we only
record the updated edge (in the case of insertion) or the adjusted
weight (in the case of deletion). This method, combined with the
pruning approach, guarantees that our algorithms achieve an ùëÇ(1)
complexity for both query and update operations, enhancing its
efficiency and scalability for large-scale network analyses.
6 EXPERIMENTS
In this section, we conduct extensive experiments on various real-
life networks in order to evaluate the performance of our algorithms,
in terms of accuracy and efficiency.
6.1 Setup
Datasets and Equipment. The datasets of selected real networks
are publicly available in the KONECT [ 30] and SNAP [ 33]. Our
experiments are conducted on a diverse range of undirected and
directed networks. The details of these datasets are presented in
Table 1. All experiments are conducted using the Julia program-
ming language. We conduct all experiments in a computational
environment featuring a 2.5 GHz Intel E5-2682v4 CPU with 512GB
of primary memory.
Table 1: Datasets used in experiments.
Network Type Nodes Edges
Web-Stanford directed 281,903 2,312,497
Delicious undirected 536,108 1,375,961
Web-Google directed 875,713 5,105,039
Youtube undirected 1,134,890 2,987,624
Livejournal undirected 10,690,276 112,307,385
Twitter directed 41,652,230 1,468,365,182Algorithms and Parameters. In the evaluation of forest matrix
entry queries, we compare our two algorithms SFQ andSFQPlus
with the fast linear equation solvers, since direct matrix inversion
is computationally infeasible. For undirected graphs, we consider
the fast Laplacian solver [ 16], which is widely used in computation
and optimization problems [ 7,46,51]. For directed graphs, the fast
Laplacian solver no longer applies. Thus, we choose the GMRES
algorithm [ 41] to get the ground truth with a tolerance set to 10‚àí9.
According to Theorem 4.5, we set ùõø=0.01,ùúñ=0.03, and the num-
ber of spanning converging forest ùëôis given byùëô=l
(2
3ùúñ+1
4ùúñ2)log(2
ùõø)m
.
We set the prune threshold to be ùëô‚Ä≤=5ùëô. Given that Wilson‚Äôs algo-
rithm can be parallelized efficiently, we use 32 computing cores to
speed up the process.
6.2 Accuracy
In this subsection, we evaluate the accuracy of our algorithms SFQ
andSFQPlus with the ground truth. For both SFQ andSFQPlus,
we consider an undirected graph as a special directed graph, given
that an edge between two nodes in an undirected graph can be con-
sidered as two directed edges between the two nodes in a directed
graph setting.
Our initial evaluation focuses on the performance of our algo-
rithms in estimating the diagonal of the forest matrix, which has
broad applications. In our experiments, for a graph G=(ùëâ,ùê∏),
we randomly select a node ùëñ‚ààùëâ. We then obtain the ground
truth by employing the fast Laplacian solver for undirected graphs
and GMRES for directed graphs to solve the linear equation ùúîùëñùëñ=
e‚ä§
ùëñ(I+L)‚àí1eùëñ. Here we choose four graphs: web-Web-Stanford
(a), Delicious (b), web-Google (c), Youtube (d), since the solver was
unable to process the two large graphs, Livejournal and Twitter, con-
strained by time and memory. Then we apply algorithms SFQ and
SFQPlus to get the estimation values bùúîùëñùëñandùúîùëñùëñ, respectively. This
procedure is repeated 100 times to calculate the average relative er-
rors. In addition to the static graphs, we explore the scenarios where
the graph evolves with 50 edges inserted and 50 edges deleted. We
repeat the node selection procedure for these updated graphs and
calculate the average relative errors. The results for these settings
are reported in Figure 3.
(a) (b) (c) (d)Average Relative Errors0.000.050.100.15SFQ-D SFQ-S SFQPlus-D  SFQPlus-S 
Figure 3: Comparison of average relative errors of the diago-
nals for algorithms SFQ andSFQPlus on four graphs: web-
Web-Stanford (a), Delicious (b), web-Google (c), Youtube(d),
where suffix -S indicates the results on static graphs and -D
denotes results on the updated graphs.
 
2762Fast Computation for the Forest Matrix of an Evolving Graph KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain.
Figure 3 illustrates that, compared to static graphs, the accuracy
of both algorithms experiences varying degrees of decline on up-
dated graphs, confirming our earlier analysis. Specifically, SFQ‚Äôs
accuracy significantly decreases, rendering its results less reliable,
while SFQPlus consistently delivers satisfactory outcomes. This
highlights the effectiveness of our variance reduction technique in
enhancing accuracy.
We then conduct experiments to estimate the forest distance ùúåùëñ ùëó
between two distinct nodes ùëñandùëó. The forest distance ùúåùëñ ùëóis defined
asùúåùëñ ùëó=ùúîùëñùëñ+ùúîùëó ùëó‚àíùúîùëñ ùëó‚àíùúîùëóùëñ, which was applied in [ 26] to measure
the proximity between nodes ùëñandùëó. It has been shown that the
forest distance based node centrality measure is more discriminat-
ing than other frequently used metrics for node importance [ 7].
We obtain the ground truth of ùúåùëñ ùëóby solving the linear equations
ùúåùëñ ùëó=(e‚ä§
ùëñ‚àíe‚ä§
ùëó)(I+L)‚àí1eùëñ+(e‚ä§
ùëó‚àíe‚ä§
ùëñ)(I+L)‚àí1eùëó. We then derive
the estimations of ùúåùëñ ùëóby executing algorithms SFQ andSFQPlus
four times each. We randomly select 400 pairs of distinct nodes and
calculate their forest closeness centrality. The settings for these
experiments are consistent with those previously mentioned. The
results are displayed in Figure 4. From these results, it is evident
that the SFQPlus algorithm achieves better accuracy than SFQ in
both static and updated graphs.
(a) (b) (c) (d)Average Relative Errors0.000.050.100.15SFQ-D SFQ-S SFQPlus-D  SFQPlus-S
Figure 4: Comparison of average relative errors of the for-
est closeness centrality measures for algorithms SFQ and
SFQPlus on four graphs: web-Web-Stanford (a), Delicious (b),
web-Google (c), Livejournal(d), where suffix -S indicates the
results on static graphs and -D denotes results on the updated
graphs.
6.3 Efficiency and Scalability
As illustrated above, the SFQPlus algorithm achieves satisfactory
accuracy in comparison to the ground truth. In this subsection, we
show the efficiency and scalability of our query algorithms and
update strategies on various networks. The results, summarized
in Table 2, provide a clear indication of these findings. For each
network, the SFQ andSFQPlus algorithms are initially executed
100 times, yielding an average time denoted as SFQ-S andSFQPlus-
S, respectively, in the table. Subsequently, the graph undergoes
100 updates, comprising 50 random edge insertions and 50 random
edge deletions. The update time is calculated as the average of 100
executions, 50 executions of the Insert-Update algorithm and 50
executions of the Delete-Update algorithm. After the updates,
theSFQ andSFQPlus algorithms are run another 100 times on the
updated graph, with the average runtime recorded as SFQ-D andSFQPlus-D. To obtain the ground truth, a fast Laplacian solver for
undirected graphs and GMRES for directed graphs are used, with
the execution time noted in the Solver column of the table.
From these results, it is observable that under identical condi-
tions, the SFQPlus algorithm typically requires a slightly longer
time than SFQ. Moreover, the execution time for both algorithms
marginally increases after the updates. Importantly, the time for
queries and updates shows insensitivity to the size of the network.
This supports the prior analysis that the query and update times
areùëÇ(1), significantly less than the time required by the linear
solver to determine the ground truth. Remarkably, for two mas-
sive networks, Livejournal and Twitter, both of which contain over
10 million nodes, the solver fails to run due to time and memory
constraints, whereas our algorithms still perform effectively. Our
algorithms consistently return results for a single query operation
within one second, demonstrating their efficiency and scalability
for large-scale network analysis.
Table 2: The running time(seconds) of the linear solver and
SFQ andSFQPlus algorithms, as well as the update time,
where suffix -S indicates the results on static graphs and -D
denotes results on the updated graphs.
NetworkRunning Time(seconds)
SFQ-S SFQ-D SFQPlus-S SFQPlus-D Update Solver
Stanford 0.0008 0.027 0.0013 0.028 0.097 22.17
Delicious 0.0008 0.097 0.0012 0.098 0.429 50.06
Google 0.0007 0.153 0.0013 0.157 0.485 81.61
Youtube 0.0009 0.252 0.0014 0.256 0.885 255.64
Livejournal 0.0009 0.314 0.0014 0.362 1.121 -
Twitter 0.0011 0.421 0.0021 0.489 1.893 -
7 CONCLUSIONS
In this paper, we addressed the problem of efficiently querying
the entries of the forest matrix of a dynamically evolving graph.
Leveraging an extension of Wilson‚Äôs algorithm, we presented an
algorithm SFQ as our foundational approach. We further enhanced
this foundation and developed SFQPlus, an advanced algorithm
that incorporates an innovative variance reduction technique to
improve the accuracy of estimations for the entries of forest matrix.
Additionally, we proposed innovative forest updating techniques
to manage evolving graphs, including edge additions and deletions.
Our methods maintains ùëÇ(1)time complexity for both updates
and queries, while ensuring unbiased estimates of the entries of
the forest matrix entries. Extensive experimentation on various
real-world networks validates the effectiveness and efficiency of
our algorithms. Moreover, our algorithms are scalable to massive
graphs with over forty million nodes.
In future work, we plan to extend our algorithms to other prob-
lems on evolving graphs, such as dynamically solving linear sys-
tems associated with the forest matrix, thereby broadening their
applicability in network analysis.
ACKNOWLEDGEMENTS
This work was supported by the National Natural Science Founda-
tion of China (Nos. 62372112, U20B2051, and 61872093).
 
2763KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain. Haoxin Sun, Xiaotian Zhou, and Zhongzhi Zhang*
REFERENCES
[1]Ittai Abraham, David Durfee, Ioannis Koutis, Sebastian Krinninger, and Richard
Peng. 2016. On fully dynamic graph sparsifiers. In 2016 IEEE 57th Annual Sympo-
sium on Foundations of Computer Science. IEEE, 335‚Äì344.
[2]Dimitris Achlioptas. 2003. Database-friendly random projections: Johnson-
Lindenstrauss with binary coins. J. Comput. System Sci. 66, 4 (2003), 671‚Äì687.
[3]Rafig Pashaevich Agaev and P Yu Chebotarev. 2001. Spanning forests of a digraph
and their applications. Automation and Remote Control 62, 3 (2001), 443‚Äì466.
[4]Luca Avena, Fabienne Castell, Alexandre Gaudilli√®re, and Clothilde M√©lot. 2018.
Random forests and networks analysis. Journal of Statistical Physics 173 (2018),
985‚Äì1027.
[5]Luca Avena and Alexandre Gaudilli√®re. 2018. Two applications of random span-
ning forests. Journal of Theoretical Probability 31, 4 (2018), 1975‚Äì2004.
[6]Coralio Ballester, Antoni Calv√≥-Armengol, and Yves Zenou. 2006. Who‚Äôs who in
networks. Wanted: The key player. Econometrica 74, 5 (2006), 1403‚Äì1417.
[7]Qi Bao and Zhongzhi Zhang. 2022. Discriminating Power of centrality measures
in complex networks. IEEE Transactions on Cybernetics 52, 11 (2022), 12583‚Äì
12593.
[8]Simon Barthelm√©, Nicolas Tremblay, Alexandre Gaudilliere, Luca Avena, and
Pierre-Olivier Amblard. 2019. Estimating the inverse trace using random forests
on graphs. arXiv preprint arXiv:1905.02086 (2019).
[9]Surender Baswana, Sumeet Khurana, and Soumojit Sarkar. 2012. Fully dynamic
randomized algorithms for graph spanners. ACM Transactions on Algorithms 8, 4
(2012), 1‚Äì51.
[10] Seth Chaiken. 1982. A combinatorial proof of the all minors matrix tree theorem.
SIAM J. Alg. Disc. Meth. 3, 3 (Sep. 1982), 319‚Äì329.
[11] Pavel Chebotarev and Rafig Agaev. 2002. Forest matrices around the Laplacian
matrix. Linear Algebra Appl. 356, 1-3 (2002), 253‚Äì274.
[12] Pavel Yu. Chebotarev and Elena Shamis. 2006. Matrix-Forest Theorems. ArXiv
abs/math/0602575 (2006).
[13] P. Yu Chebotarev and E. V. Shamis. 1997. The matrix-forest theorem and measur-
ing relations in small social groups. Automation and Remote Control 58, 9 (1997),
1505‚Äì1514.
[14] P. Yu Chebotarev and E. V. Shamis. 1998. On proximity measures for graph
vertices. Automation and Remote Control 59, 10 (1998), 1443‚Äì1459.
[15] Fan Chung and Linyuan Lu. 2006. Concentration inequalities and martingale
inequalities: a survey. Internet mathematics 3, 1 (2006), 79‚Äì127.
[16] Michael B Cohen, Rasmus Kyng, Gary L Miller, Jakub W Pachocki, Richard Peng,
Anup B Rao, and Shen Chen Xu. 2014. Solving SDD linear systems in nearly
ùëölog1/2ùëõtime. In Proceedings of the Forty-Sixth Annual ACM Symposium on
Theory of Computing. ACM, 343‚Äì352.
[17] Jaydeep De, Xiaowei Zhang, Feng Lin, and Li Cheng. 2017. Transduction on di-
rected graphs via absorbing random walks. IEEE Transactions on Pattern Analysis
and Machine Intelligence 40, 7 (2017), 1770‚Äì1784.
[18] David Durfee, Yu Gao, Gramoz Goranci, and Richard Peng. 2019. Fully dynamic
spectral vertex sparsifiers and applications. In Proceedings of the 51st Annual ACM
SIGACT Symposium on Theory of Computing. 914‚Äì925.
[19] Sebastian Forster and Gramoz Goranci. 2019. Dynamic low-stretch trees via
dynamic low-diameter decompositions. In Proceedings of the 51st Annual ACM
SIGACT Symposium on Theory of Computing. 377‚Äì388.
[20] Andrea Galeotti, Benjamin Golub, and Sanjeev Goyal. 2020. Targeting interven-
tions in networks. Econometrica 88, 6 (2020), 2445‚Äì2471.
[21] Aristides Gionis, Evimaria Terzi, and Panayiotis Tsaparas. 2013. Opinion maxi-
mization in social networks. In Proceedings of the 2013 SIAM International Confer-
ence on Data Mining. SIAM, 387‚Äì395.
[22] Gramoz Goranci, Monika Henzinger, and Mikkel Thorup. 2018. Incremental
exact min-cut in polylogarithmic amortized update time. ACM Transactions on
Algorithms 14, 2 (2018), 1‚Äì21.
[23] Jacob Holm, Kristian De Lichtenberg, and Mikkel Thorup. 2001. Poly-logarithmic
deterministic fully-dynamic algorithms for connectivity, minimum spanning tree,
2-edge, and biconnectivity. J. ACM 48, 4 (2001), 723‚Äì760.
[24] Jacob Holm, Eva Rotenberg, and Christian Wulff-Nilsen. 2015. Faster fully-
dynamic minimum spanning forest. In Algorithms-ESA 2015: 23rd Annual Euro-
pean Symposium. Springer, 742‚Äì753.
[25] Glen Jeh and Jennifer Widom. 2003. Scaling personalized web search. In Proceed-
ings of the 12th International Conference on World Wide Web. 271‚Äì279.
[26] Yujia Jin, Qi Bao, and Zhongzhi Zhang. 2019. Forest distance closeness centrality
in disconnected graphs. In 2018 IEEE International Conference on Data Mining.
IEEE, 339‚Äì348.
[27] William B Johnson and Joram Lindenstrauss. 1984. Extensions of Lipschitz
mappings into a Hilbert space. Contemp. Math. 26 (1984), 189‚Äì206.[28] Bruce M Kapron, Valerie King, and Ben Mountjoy. 2013. Dynamic graph con-
nectivity in polylogarithmic worst case time. In Proceedings of the twenty-fourth
annual ACM-SIAM symposium on Discrete algorithms. SIAM, 1131‚Äì1142.
[29] Alex Kulesza, Ben Taskar, et al .2012. Determinantal point processes for machine
learning. Foundations and Trends¬Æ in Machine Learning 5, 2‚Äì3 (2012), 123‚Äì286.
[30] J√©r√¥me Kunegis. 2013. Konect: the koblenz network collection. In Proceedings of
the 22nd International World Wide Web Conference. ACM, 1343‚Äì1350.
[31] Lawler and F. Gregory. 1980. A self-avoiding random walk. Duke Mathematical
Journal 47, 3 (1980), 655‚Äì693.
[32] Gregory Francis Lawler. 1979. A self-avoiding random walk. Ph.D. Dissertation.
Princeton University.
[33] Jure Leskovec and Rok Sosiƒç. 2016. SNAP: A general-purpose network analysis
and graph-mining library. ACM Transactions on Intelligent Systems and Technology
8, 1 (2016), 1.
[34] Russell Merris. 1994. Laplacian matrices of graphs: A survey. Linear Algebra
Appl. 197 (1994), 143‚Äì176.
[35] Danupon Nanongkai and Thatchaphol Saranurak. 2017. Dynamic spanning
forest with worst-case update time: adaptive, las vegas, and o (n1/2- ùúÄ)-time. In
Proceedings of the 49th Annual ACM SIGACT Symposium on Theory of Computing.
1122‚Äì1129.
[36] Danupon Nanongkai, Thatchaphol Saranurak, and Christian Wulff-Nilsen. 2017.
Dynamic minimum spanning forest with subpolynomial worst-case update time.
In2017 IEEE 58th Annual Symposium on Foundations of Computer Science . IEEE,
950‚Äì961.
[37] Yusuf Y Pilavci, Pierre-Olivier Amblard, Simon Barthelme, and Nicolas Tremblay.
2020. Smoothing graph signals via random spanning forests. In Proceedings of
IEEE International Conference on Acoustics, Speech and Signal Processing. IEEE,
5630‚Äì5634.
[38] Yusuf Yiƒüit Pilavcƒ±, Pierre-Olivier Amblard, Simon Barthelme, and Nicolas Trem-
blay. 2021. Graph Tikhonov regularization and interpolation via random spanning
forests. IEEE Transactions on Signal and Information Processing over Networks 7
(2021), 359‚Äì374.
[39] Yusuf Yigit Pilavci, Pierre-Olivier Amblard, Simon Barthelme, and Nicolas Trem-
blay. 2022. Variance reduction for inverse trace estimation via random spanning
forests. arXiv preprint arXiv:2206.07421 (2022).
[40] Wilbert Samuel Rossi, Paolo Frasca, and Fabio Fagnani. 2017. Distributed estima-
tion from relative and absolute measurements. IEEE Trans. Automat. Control 62,
12 (2017), 6385‚Äì6391.
[41] Youcef Saad and Martin H Schultz. 1986. GMRES: A generalized minimal residual
algorithm for solving nonsymmetric linear systems. SIAM J. Sci. Statist. Comput.
7, 3 (1986), 856‚Äì869.
[42] Haoxin Sun and Zhongzhi Zhang. 2023. Opinion optimization in directed social
networks. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 37.
4623‚Äì4632.
[43] Haoxin Sun and Zhongzhi Zhang. 2024. Efficient computation for diagonal of
forest matrix via variance-reduced forest sampling. In Proceedings of the ACM
Web Conference 2024. 792‚Äì802.
[44] Mikkel Thorup. 2007. Fully-dynamic min-cut. Combinatorica 27, 1 (2007), 91‚Äì127.
[45] Jan van den Brand, Yu Gao, Arun Jambulapati, Yin Tat Lee, Yang P Liu, Richard
Peng, and Aaron Sidford. 2022. Faster maxflow via improved dynamic spectral
vertex sparsifiers. In Proceedings of the 54th Annual ACM SIGACT Symposium on
Theory of Computing. 543‚Äì556.
[46] Alexander van der Grinten, Eugenio Angriman, Maria Predari, and Henning Mey-
erhenke. 2021. New approximation algorithms for forest closeness centrality‚Äìfor
individual vertices and vertex groups. In Proceedings of the 2021 SIAM Interna-
tional Conference on Data Mining. SIAM, 136‚Äì144.
[47] Sibo Wang, Renchi Yang, Xiaokui Xiao, Zhewei Wei, and Yin Yang. 2017. FORA:
simple and effective approximate single-source personalized PageRank. In Pro-
ceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery
and Data Mining. 505‚Äì514.
[48] David Bruce Wilson. 1996. Generating random spanning trees more quickly than
the cover time. In Proceedings of the Twenty-Eighth Annual ACM Symposium on
Theory of Computing. 296‚Äì303.
[49] Christian Wulff-Nilsen. 2017. Fully-dynamic minimum spanning forest with
improved worst-case update time. In Proceedings of the 49th Annual ACM SIGACT
Symposium on Theory of Computing. 1130‚Äì1143.
[50] Wanyue Xu, Qi Bao, and Zhongzhi Zhang. 2021. Fast evaluation for relevant
quantities of opinion dynamics. In Proceedings of The Web Conference. ACM,
2037‚Äì2045.
[51] Liwang Zhu and Zhongzhi Zhang. 2022. A nearly-linear time algorithm for
minimizing risk of conflict in social networks. In Proceedings of the 28th ACM
SIGKDD Conference on Knowledge Discovery and Data Mining. 2648‚Äì2656.
 
2764