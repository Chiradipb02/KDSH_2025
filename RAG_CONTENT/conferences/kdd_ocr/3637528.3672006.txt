Spuriousness-Aware Meta-Learning for Learning Robust
Classifiers
Guangtao Zheng
University of Virginia
Charlottesville, VA, USA
gz5hp@virginia.eduWenqian Ye
University of Virginia
Charlottesville, VA, USA
wenqian@virginia.eduAidong Zhang
University of Virginia
Charlottesville, VA, USA
aidong@virginia.edu
ABSTRACT
Spurious correlations are brittle associations between certain at-
tributes of inputs and target variables, such as the correlation be-
tween an image background and an object class. Deep image classi-
fiers often leverage them for predictions, leading to poor generaliza-
tion on the data where the correlations do not hold. Mitigating the
impact of spurious correlations is crucial towards robust model gen-
eralization, but it often requires annotations of the spurious correla-
tions in data – a strong assumption in practice. In this paper, we pro-
pose a novel learning framework based on meta-learning, termed
SPUME – SPUriousness-aware MEta-learning, to train an image
classifier to be robust to spurious correlations. We design the frame-
work to iteratively detect and mitigate the spurious correlations
that the classifier excessively relies on for predictions. To achieve
this, we first propose to utilize a pre-trained vision-language model
to extract text-format attributes from images. These attributes en-
able us to curate data with various class-attribute correlations, and
we formulate a novel metric to measure the degree of these corre-
lations’ spuriousness. Then, to mitigate the reliance on spurious
correlations, we propose a meta-learning strategy in which the sup-
port (training) sets and query (test) sets in tasks are curated with
different spurious correlations that have high degrees of spurious-
ness. By meta-training the classifier on these spuriousness-aware
meta-learning tasks, our classifier can learn to be invariant to the
spurious correlations. We demonstrate that our method is robust to
spurious correlations without knowing them a priori and achieves
the best on five benchmark datasets with different robustness mea-
sures. Our code is available at https://github.com/gtzheng/SPUME.
CCS CONCEPTS
•Computing methodologies →Machine learning algorithms ;
Object recognition ;Learning under covariate shift ;Super-
vised learning by classification.
KEYWORDS
Spurious correlations, robustness, meta-learning, image classifica-
tion, vision-language models
ACM Reference Format:
Guangtao Zheng, Wenqian Ye, and Aidong Zhang. 2024. Spuriousness-
Aware Meta-Learning for Learning Robust Classifiers. In Proceedings of the
This work is licensed under a Creative Commons Attribution
International 4.0 License.
KDD ’24, August 25–29, 2024, Barcelona, Spain
©2024 Copyright held by the owner/author(s).
ACM ISBN 979-8-4007-0490-1/24/08
https://doi.org/10.1145/3637528.367200630th ACM SIGKDD Conference on Knowledge Discovery and Data Mining
(KDD ’24), August 25–29, 2024, Barcelona, Spain. ACM, New York, NY, USA,
12 pages. https://doi.org/10.1145/3637528.3672006
1 INTRODUCTION
Spurious correlations are prevalent in real-world datasets. They are
brittle associations between certain input attributes and the corre-
sponding target variables. For example, the class cowis correlated
with grassland when most training images show a cow on a grass-
land, but the correlation breaks when a cow is at a beach [ 5,15]. The
grassland feature is spurious as it does not always correlate with
the label cowand is not truly predictive for all cow images. Deep
image classifiers often use spurious correlations as their prediction
shortcuts [ 15], such as inferring an image as representing a cowby
focusing on the grassland background of the image. Although this
shortcut learning strategy can achieve high overall performance
when the majority of samples have spurious correlations, it gener-
alizes poorly on samples where spurious correlations do not hold.
Thus, mitigating the reliance on spurious correlations is crucial for
obtaining robust image classifiers.
Existing approaches require annotations of spurious correlations
or group labels, which separate data into multiple groups with
each containing samples of the same class and sharing the same
attribute. For example, a group label (cow, grass field) represents all
cow images with grass fields as the background. The group labels
are used to formulate new optimization objectives [ 42] or used for
model selection and/or model fine-tuning [ 22,24,31,32]. However,
knowing the group labels in data requires expert knowledge and
costly human annotations, which cannot scale to large datasets.
Completely removing the requirement for group labels while learn-
ing robust classifiers is also a challenging task since we have no
knowledge about what spurious correlations we need to mitigate.
In this paper, we propose a novel learning framework to train
an image classifier to be robust to spurious correlations without
the need of group labels. We design our framework to iteratively
detect and mitigate the spurious correlations that the classifier
heavily relies on for predictions. To achieve this, we first propose
an automatic spurious attribute detection method empowered by a
pre-trained vision-language model (VLM). The VLM enables us to
detect text-format attributes which represent many similar pixel-
level features and are interpretable to humans. These attributes
together with class labels can formulate various class-attribute
correlations which we may find to be spurious in data, and these
correlations can cover many potential scenarios where an image
classifier fails to generalize because of its reliance on one or multiple
of these spurious correlations. Therefore, to train a robust classifier
against spurious correlations in general without the guidance of
4524
KDD ’24, August 25–29, 2024, Barcelona, Spain Guangtao Zheng, Wenqian Ye, & Aidong Zhang
group labels, we focus on mitigating the classifier’s reliance on the
detected correlations.
However, it is not efficient to mitigate all of them with equal
importance, since among the detected correlations, some are trivial
for the classifier as the classifier is robust to them, while some
may pose a great risk to the robustness of the classifier. Thus, we
propose a novel spuriousness metric to quantify the spuriousness of
the correlation between a detected attribute and a class label, which
measures a classifier’s reliance on these class-attribute correlations
for predictions, with a larger value indicating a greater reliance
on the correlation. With the spuriousness metric, we can identify
harmful spurious correlations.
To train a robust classifier, we propose a SPUriousness-aware
MEta-learning (termed SPUME) strategy. Unlike the classical set-
tings where only a few spurious correlations are known and needed
to be mitigated, our setting has numerous correlations established
by the detected attributes and class labels, especially when the
dataset that we use has rich features. Using meta-learning, we can
distribute the detected spurious correlations with high spurious-
ness values into multiple meta-learning tasks by carefully curating
the data in those tasks. We exploit the support (training) and query
(test) sets in a meta-learning task so that samples in the support
and query sets have different spurious correlations. Such a task
simulates a challenging learning scenario where the classifier will
perform poorly on the query set when it has a high reliance on
the spurious correlations in the support set. By meta-training the
classifier on these spuriousness-aware meta-learning tasks, our
classifier can learn to be invariant to the spurious correlations.
Ourcontributions are as follows:
•We propose an automatic method to detect spurious correla-
tions in data, which exploits the prior knowledge contained
in a pre-trained VLM and extracts spurious attributes in
interpretable text format.
•We tackle the problem of mitigating the reliance on spurious
correlations with a novel meta-learning strategy.
•We propose a novel spuriousness metric to guide the con-
struction of meta-learning tasks with the detected spurious
attributes.
•We demonstrate that a classifier with high average accuracy
does not necessarily have high worst-group accuracy which
is commonly used for measuring the robustness to spurious
correlations. Our method, termed as SPUrious-aware MEta-
learning (SPUME), can train classifiers robust to spurious
correlations on five benchmark datasets without knowing
the spurious correlations a priori.
2 RELATED WORK
Detecting Spurious Attributes. Spurious attributes spuriously
correlate with class labels in data and tend to be exploited for
predictions, posing a great risk to the robustness of deep neural
classifiers. Detecting spurious attributes typically requires domain
knowledge [ 9,33] and human annotations [ 36,57]. For example,
researchers found that object backgrounds [ 52] and image tex-
ture [ 16] are spurious and can bias the predictions of deep learning
models. Recently, model explanation methods [ 1,38] are used to
detect spurious attributes. Neurons in the penultimate layer of arobust model assisted with limited human supervision are also uti-
lized for spurious attribute detection [ 34,43]. Pre-specifying a set
of candidate spurious attributes for spurious attribute detection is
also explored [ 51]. Our method of spurious attribute detection is
completely unsupervised. We exploit the prior knowledge in pre-
trained VLMs and extract spurious attributes in interpretable text
format without any human supervisions.
Mitigating Spurious Correlations. Spurious correlations tend to
bias a model’s predictions. There is a growing number of works on
mitigating the impact of spurious correlations. Methods that aim to
balance data distributions [ 6,11,18] or to perform distributionally
robust optimization [42] require knowing group labels which pro-
vide information about the spurious correlations in data. Recent
works aim to infer group labels to relax this requirement, such
as identifying misclassified samples [ 29], clustering hidden repre-
sentations [ 58], invariant learning [ 10], or training a group label
estimator using a small set of data with group labels [ 32]. Kirichenko
et al. [24] uses group-balanced validation data to retrain the last
layer of a model. All these methods still require group labels for the
validation data for model selection, which is a strong assumption
in practice. A recent work [ 2] uses masked data with interpretation
techniques to mitigate the impact of spurious correlations without
the need of group labels. Our method automatically detects spuri-
ous correlations and uses them to construct spuriousness-aware
learning tasks and to do model selection. Another line of works is
to use data augmentation, such as mixup [ 17,51,56] or selective
augmentation [ 53], to mitigate spurious bias in model training. Our
method is orthogonal to these approaches as we focus on learning
robust classifiers with existing data.
Meta-learning. Meta-learning [ 14,41,44,48] is a bi-level learning
paradigm and is popular in few-shot learning [ 8,37,45,54]. It
aims to learn from one set of data and to generalize on another set
of data. It has been found that the meta-learning can learn high-
quality representations [ 40], achieving good generalization across
different tasks. Utilizing the novel idea of meta-learning, in this
paper, we transform the problem of spurious correlation mitigation
into a novel meta-learning problem to facilitate learning feature
representations robust to spurious correlations.
3 PROBLEM FORMULATION
Consider a training dataset Dtr={(xn,yn)}N
n=1with xn∈ X,
yn∈Y, whereXdenotes the input space containing all possible
inputs,Ydenotes the set of Kclasses. In real-world scenarios, a
sample xninDtrtypically has spurious attributes and these at-
tributes have spurious correlations with the label yn. We describe
the two important concepts below.
•Spurious attributes: A spurious attribute a∈A describes some
common patterns in the input space Xand spuriously correlates
with some label y∈Y, whereAdenotes all possible spurious
attributes. In other words, acan be in samples of multiple classes
or only in some samples of a class, and therefore is not essential to
any of the classes. For example, the “land background" attribute can
exist in images of waterbird and landbird classes [ 42], and “land
background" is non-essential to either of the classes.
•Spurious correlations: A spurious correlation, denoted as ⟨y,a⟩,
describes the brittle association between the spurious attribute a
4525Spuriousness-Aware Meta-Learning for Learning Robust Classifiers KDD ’24, August 25–29, 2024, Barcelona, Spain
a green  vase 
sitting on top of a 
wooden  table
Vision-languageSpurious Attribute Detection (a)
(b)Add
Feature extractorSupport set Query set
Task t-1noun adjective
Step 1: Generate text descriptions Step 2: Extract informative words Step 3: Measure spuriousness (per class)Larger gap Larger value
Spuriousness green
vasegreen
\green
vase
\vase
Accuracy
Centroid-based 
classiﬁerAttribute set
Spuriousness-Aware Task Construction (c) Meta-Learning Robust Representations 
Sample......
......
Support 
set
Query 
setTask t+1
Generate
Loss
Task tBackward updateAttribute extractor
Map
Spuriousness scores
withmodel
Figure 1: Overview of SPUME. (a) Detect attributes from training data and measure their spuriousness in three steps. “\green"
denotes without the attribute “green". (b) Construct spuriousness-aware meta-learning tasks guided by the spuriousness scores
of the detected attributes. (c) Meta-train a robust feature extractor using the constructed tasks.
and the label y. The spurious correlation ⟨y,a⟩does not always
hold in the sense that acan be associated with multiple y’s ory
can correlate with other attributes in some samples. Knowing all
the spurious correlations in Dtr, we can divideDtrinto multiple
data groupsDд
tr,д∈G, whereд=(y,a)denotes the group label
for samples with the label yand having the spurious attribute a,
andG=Y×A denotes the set of all group labels.
Given a deep neural classifier fθwith parameters θ, we train it
with empirical risk minimization (ERM) on the training set Dtrand
obtain the optimized classifier fθ∗as follows:
θ∗=arg min
θE(x,y)∈D trℓ(fθ(x),y), (1)
where ℓ(·,·)is the cross-entropy loss function.
The problem occurs when data groups {Dд
tr|д∈G,Dд
tr⊂D tr}
inDtrare imbalanced in sizes or the inductive bias of the classifier
fθfavors particular data groups. For example, a majority group Dд
tr
with the group label д=(y,a)inDtr, which has significantly more
samples than other groups, may bias the optimization in Eq. (1)
towards favoring the data in Dд
trhaving the spurious correlation
⟨y,a⟩, i.e.,
θ∗≈arg min
θE(x,y)∈Dд
trℓ(fθ(x),y), (2)
with|Dд
tr|≫|Dд′
tr|, whereд,д′∈Gandд,д′, and|·|denotes the
size of a set. As a result, the classifier fθ∗, instead of utilizing the core
features in samples to predict y, may superficially learn the mapping
from atoy, which is non-robust when the correlation between a
andybreaks. More specifically, since ais a spurious attribute, there
may exist⟨y′,a⟩in samples from class y′withy,y′. Then, it is
very likely that fθ∗will wrongly predict these samples as yinstead
ofy′. For example, when fθ∗learns to use water backgrounds ( a)
to predict waterbirds ( y), it fails to recognize landbirds ( y′) with
water backgrounds. Similarly, when the inductive bias in fθ∗favorscertain spurious correlations, the classifier will encounter the same
generalization problem.
Spurious correlations pose a great challenge to the robustness
of machine learning models. To address this, typically, all or partial
group labels of the training data is required for various purposes,
such as formulating the group robustness objective [ 42], reweight-
ing the training data, or selecting models [ 29]. However, acquiring
group labels for a dataset typically involves human-guided annota-
tions, which is costly and not scalable, especially when the dataset
is large. In the following, without the need of group labels, we
propose a novel spuriousness-aware meta-learning framework to
train a classifier to be robust to spurious correlations.
4 SPURIOUSNESS-AWARE META-LEARNING
We give the overview of our framework in Fig. 1, where we first
detect spurious attributes with a pre-trained VLM (Fig. 1(a) and
Section 4.1). To effectively use the detected spurious attributes for
spurious correlation mitigation, we propose a novel meta-learning
strategy and provide details on how to construct spuriousness-
aware meta-training tasks (Fig. 1(b) and Section 4.2) and meta-learn
robust representations (Fig. 1(c) and Section 4.3).
4.1 Automatic Spurious Attribute Detection
To automatically detect spurious attributes in a target dataset with-
out human-guided annotations, we propose to exploit the prior
knowledge in a pre-trained VLM. Our method detects spurious
attributes in text format and consists of the following three steps.
Step 1: Generate Text Descriptions. We generate a text description
for each image using a pre-trained VLM ϕ, which is capable of
generating text descriptions of images at scale. Moreover, since the
model is trained on massive data and is not specifically fine-tuned
on the target dataset, it can discover general objects and patterns.
4526KDD ’24, August 25–29, 2024, Barcelona, Spain Guangtao Zheng, Wenqian Ye, & Aidong Zhang
For example, in Fig. 1(a), besides the class object vase , the VLM
also detects the vase’s color green and a background object table
with its material wooden.
Step 2: Extract Informative Words as Attributes. We extract in-
formative words from the text descriptions of images as attributes.
We select nouns, which describe objects, and adjectives, which de-
scribe certain properties of objects, as the informative words. For
example, we extract green ,vase ,top,wooden , and table from the
description in Fig. 1(a). We instantiate the attribute extractor ψ
with an automatic procedure (Section 5.2) to extract these infor-
mative words from the text descriptions obtained in the first step.
Then, these extracted words are added to the attribute set Aas the
possible spurious attributes.
Remark. VLMs can detect general objects and patterns. However,
due to the inductive bias learned during pre-training, VLMs may
generate text descriptions for some images that are not aligned
with human understandings, such as describing a red-and-green
background as a “Christmas tree". Although “Christmas tree" is not
self-explanatory in this case, it is still a valid and useful attribute,
representing samples having similar red-and-green backgrounds.
This also highlights the benefit of using VLMs: they can detect
patterns that are not easily perceived by humans. A limitation of
such a VLM-based detection approach is that VLMs may struggle on
describing images from domain-specific tasks where, for example,
slight changes in orientation of objects or variations in geographies
are important for robust predictions. Nevertheless, our proposed
spurious attribute detection approach is not restricted to a specific
VLM, and it can be improved if more capable VLMs are available.
Step 3: Measure Spuriousness. To know whether a detected at-
tribute a∈A is spurious, we need to consider it in the correlation
with a class label y, since among all the correlations between the
attributes inAand class labels, some of them may be vacuous —
they do not exist in the training data (e.g., aonly exists in images
of the class y′withy′,y), and some of them are not spurious (e.g.,
the attribute ais detected exclusively in all the images of the class
y). Moreover, we are interested in identifying spurious correlations
that are likely to be exploited by a classifier for predictions as these
correlations directly affect the robustness of the classifier.
To unify the above cases, we propose a metric to quantify the
likelihood of the correlation ⟨y,a⟩being spurious andused by a
classifier, i.e., spuriousness of the correlation. The metric γconsiders
y,a, the training data Dtr, and the classifier fθ, and maps them
to a finite value, which we call spuriousness score. We defines γas
follows.
Definition 1 (Spuriousness Metric) .Given a class label y∈Y, an
attribute a∈A, and a classifier fθtrained onDwithθ∈Θ, the
spuriousness metric for ⟨y,a⟩is a mapping γ:Y×A×D× Θ→
[α,β], whereDdenotes a set of sample-label pairs, Θdenotes the
set of all possible θ, and[α,β]denotes the output value range of
γ, withαbeing the lowest and βbeing the highest. When the
data group size|D(y,a)|=0or|D(y,ˆa)|=0, where ˆadenotes all
attributes inAother than a, the mapping γoutputsα.
Given the training set Dtr,|D(y,a)
tr|=0and|D(y,ˆa)
tr|=0cor-
respond to that⟨y,a⟩does not exist inDtrand that⟨y,a⟩existsexclusively in samples of class y, respectively. For both cases, the
spuriousness of⟨y,a⟩should be the smallest.
Then, we specifically design γbased on the performance of the
classifier fθ. The motivation is that the classifier fθwill gener-
alize poorly on samples of the class ywithout the attribute aif
fθexcessively relies on afor predicting the label y. Therefore, as
demonstrated in Fig. 1(a), the spuriousness will be higher if fθhas
a larger performance discrepancy on images with and without a
and be lower when the performance discrepancy is smaller. We
formally define our spuriousness metric for ⟨y,a⟩as follows,
γ(y,a;Dtr,fθ)=tanh
abs logJ(D(y,a)
tr;fθ)
J(D(y,ˆa)
tr;fθ)
, (3)
withγ(y,a;Dtr,fθ)=0whenD(y,ˆa)
tr=∅orD(y,a)
tr=∅, where
D(y,a)
tr⊂ D trdenotes the subset of all training data from the
class cwith the attribute a,D(y,ˆa)
tr⊂D trdenotes the subset of
all training data from the class cwithout the attribute a,J(·;fθ)
denotes the classification accuracy of fθon a given set of samples,
and abs(·) denotes taking the absolute value. The division in Eq. (3)
aims to produce larger values than the simple difference between
the two accuracies, making different correlations more distinctive.
Moreover, using log(·) avoids encountering extreme values from
the division, and tanh(abs(·)) bounds the score in the range from
0 to 1. Other designs of γare possible, and we have shown in our
experiments that our method proposed in the following is robust
to different choices of spuriousness metrics.
Discussion. With the detected attributes and our spuriousness
metric, we can identify spurious correlations that are likely to
be used for predictions by a classifier and thus pose a potential
risk to the robustness of the classifier. To improve the robustness
to spurious correlations, we need to mitigate the classifier’s re-
liance on those spurious correlations. Since there are multiple spu-
rious correlations, mitigating all of them at once is a challenging
task. To address this, we formulate the problem in a novel meta-
learning [8,14,44,48] setting, where we construct meta-learning
tasks with each task containing some potentially harmful spurious
correlations. Now, our goal is to learn a good classifier that performs
well across all these tasks with various spurious correlations.
In the following, we first introduce how to construct meta-
learning tasks with the identified spurious correlations. Then, we
give the details of using the constructed tasks for meta-learning.
4.2 Spuriousness-Aware Task Construction
To mitigate spurious correlations via meta-learning, we first cre-
ate meta-learning tasks which will be used in meta-training. A
meta-learning task typically consists of a support (training) set S
providing training samples for learning novel concepts and a query
(test) setQcontaining test samples for the evaluation of the learn-
ing outcome. We use the two sets to simulate spurious correlations
in meta-learning tasks so that these spurious correlations can be
effectively mitigated via meta-learning.
As illustrated in Fig. 1(b), for each classykwith k=1, . . . , K,
we first sample two attributes akanda′
kfromAbased on their
spuriousness scores, where ak,a′
k. Specifically, we normalize the
4527Spuriousness-Aware Meta-Learning for Learning Robust Classifiers KDD ’24, August 25–29, 2024, Barcelona, Spain
scores as probabilities, and an attribute with a higher spuriousness
score will be more likely to be selected than another attribute with
a lower spuriousness score. In this way, we target the spurious
correlations that pose a high risk to the robustness of the classifier.
Then, the two sampled attributes formulate two spurious cor-
relations with yk, i.e.,⟨yk,ak⟩and⟨yk,a′
k⟩, based on which, we
get two data groups, D(yk,ak)
trandD(yk,a′
k)
tr, from the training set
Dtr. These two groups of data together represent a shift in the
correlation between the two spurious attributes and the class label.
If the classifier learns to rely on the spurious correlation in one
group of data for predictions, then it will fail on the other group
of data with a different spurious correlation. Thus, crafting such a
shift facilitates learning a robust classifier.
Next, for efficient training, we randomly sample NSdata points
per class from the two data groups to construct the non-overlapping
support setSkand the query setQk, i.e.,
Sk=NSØ
i=1
(xi,yk)|(xi,yk)∈˜D(yk,ak)
tr	
, (4)
and
Qk=NSØ
i=1
(xi,yk)|(xi,yk)∈˜D(yk,a′
k)
tr	
, (5)
where ˜D(yk,ak)
tr=D(yk,ak)
tr−D(yk,a′
k)
trand ˜D(yk,a′
k)
tr=D(yk,a′
k)
tr−
D(yk,ak)
trare sets of elements unique to D(yk,ak)
trandD(yk,a′
k)
tr,
respectively. Taking the above set difference ensures that the two
spurious correlations won’t appear in the same set since some
samples may have both the attributes akanda′
k.
After constructing the two sets for each class, we obtain the con-
structed taskT={S,Q}withS=∪K
k=1SkandQ=∪K
k=1Qk. IfK
is large, we can randomly select a subset of Kclasses to construct T.
The constructed task Tdemonstrates to the classifier that the spu-
rious correlations in Tare highly risky for it, and that the classifier
should be invariant to them in order to perform well on this task.
Importantly, the construction of meta-learning tasks also ensures
that biases in VLMs won’t be passed down to the classifier as the
construction process effectively decorrelates biased attributes from
VLMs with prediction targets.
4.3 Meta-Learning Robust Representations
To train a robust classifier using the constructed tasks, we modify
fθso that it fits in with the meta-learning paradigm. Specifically,
we discard the last linear classification layer of fθand keep its
feature extractor hθ1:X→RD, whereθ1⊂θandDis the number
of dimensions in the feature extractor’s outputs. Thus, learning a
robust classifier is equivalent to learning robust representations.
As illustrated in Fig. 1(c), for the t’th task, we use the repre-
sentations of the samples in the support set Sprovided by hθ1to
generate (learn) a centroid-based classifier with Kclass-centroids
W={w1, . . . , wK}calculated as follows
wk=1
NSNSÕ
n=1hθ1(xn),(xn,yk)∈S . (6)Algorithm 1 SPUME
Input: A training datasetDtr, a feature extractor hθ1, a
pre-trained VLM ϕ, an attribute extractor ψ, a spuriousness metric
γ, the number of tasks per epoch NT, the number of classes K, and
the number of training epochs E.
Output: Learned weights θ∗
1
1:Build the attribute set A=∪(x,y)∈D trψ(ϕ(x))
2:fore=1, . . . , Edo
3: Generate class centroids using Eq. (6) with S=Dtr
4: Generate spuriousness scores using Eq. (3)
5: SetT(Dtr,A,γ,θ1)as an empty set
6: fort=1, . . . , NTdo
7: Sample Kpairs of attributes from Afor each class
8: Construct a spuriousness-aware meta-learning task T
using Eq. (4) and (5)
9: AddTtoT(Dtr,A,γ,θ1)
10: end for
11: Setθ1=θ∗
1using Eq. (9)
12:end for
13:returnθ∗
1
Next, we evaluate whether the classifier depends on the spurious
correlations inSby testing it on the query set Qwhere the spurious
correlations inSdo not hold. The output probability of the classifier
onykis calculated as follows
p(yk|xn,θ1,S)=exp(τd(wk,hθ1(xn)))
ÍK
k′=1exp(τd(wk′,hθ1(xn))), (7)
where d(·,·)denotes the cosine similarity between two embedding
vectors, and τdenotes a scaling hyperparameter. Then, the task
lossℓTonT={S,Q}is as follows
ℓT(θ1)= E
(xn,yn)∈Q−logp(yn|xn,θ1,S). (8)
A high loss indicates that the classifier, and in turn the feature
extractor hθ1, rely on the spurious correlations in the support set
and cannot generalize well on the query set.
Learning Objective. We minimize the loss in (8)over tasks con-
structed with various spurious correlations to find a feature extrac-
torhθ∗
1that is robust to multiple spurious correlations, i.e.,
θ∗
1=arg min
θ1ET∈T(Dtr,A,γ,θ1)ℓT(θ1), (9)
where T(Dtr,A,γ,θ1)denotes all possible meta-learning tasks con-
structed fromDtrbased on the detected attributes A, the spurious-
ness metric γ, and the feature extractor θ1.
To solve (9), we adopt an iterative optimization procedure. We
first fixθ1and construct a set of meta-training tasks based on A,θ1,
andγ. Then, we update θ1using the constructed tasks. The above
steps are iterated until some stop criterion is met. We name our
method as SPUriousness-aware MEta-Learning (SPUME) and give
the training details in Algorithm 1.
Complexity Analysis. VLMs do not incur training cost because
they are only used for data preparation. Extracting attributes (Line
1, Algorithm 1) is a onetime offline process, and empirically, its
time cost scales linearly with the dataset size. Spuriousness mea-
surement (Line 4, Algorithm 1) is performed periodically during
4528KDD ’24, August 25–29, 2024, Barcelona, Spain Guangtao Zheng, Wenqian Ye, & Aidong Zhang
training, and its time complexity grows linearly with the amount of
data it uses. The total training cost is O(E(Cm+Cs)), where Eis the
number of training epochs, CmandCsare the time cost of meta-
learning a classifier and obtaining spuriousness scores per epoch,
respectively, with Cm≫Cs, since the latter only requires for-
ward passes through the classifier. Moreover, using a metric-based
meta-learning technique (Eq. (6)) leads to Cmbeing comparable to
training a standard classifier. Therefore, our method does not incur
significant training cost compared with the ERM training.
Model Selection. We divide the validation data Dvalinto groups
based on the detected attributes Aand calculate the average accu-
racy over these groups as follows,
Accpu=1
|A|·|Y|Õ
a∈AÕ
y∈YJ D(y,a)
val;hθ1. (10)
We call this metric pseudo-unbiased accuracy, which fairly measures
the performance of the classifier on various groups inferred with
the detected attributes in A.
Inference. We first create a centroid-based classifier using Eq. (6)
with all the data in Dtr. Then, given a test sample x, the prediction
isˆy=arg maxy∈Yp(y|x,θ1,Dtr).
5 EXPERIMENT
5.1 Datasets
We tested our method on five image classification datasets with
various types of spurious correlations, which are introduced below.
Detailed dataset statistics are give in Table 8 in Appendix.
Waterbirds [42] contains waterbird and landbird classes. It is a
synthetic dataset generated by combining images of the two kinds
of birds from the CUB dataset [ 50] with water and land backgrounds
from the Places dataset [ 59], producing (landbird, land), (landbird,
water), (waterbird, land), and (waterbird, water) groups.
CelebA [30] is a large-scale image dataset of celebrity faces. It con-
tains images showing two hair colors, non-blond and blond, which
are spuriously correlated with gender. There are four groups in
the CelebA dataset: (non-blond, female), (non-blond, male), (blond,
female), and (blond, male).
ImageNet-9 [21] is a subset of ImageNet [ 12] and contains nine
super-classes. It is known to have correlations between object
classes and image textures. We followed the setting in [ 23] and
[3] to prepare training and validation data.
ImageNet-A [20] is a dataset of real-world images, adversarially
curated to test the limits of classifiers such as ResNet-50. While
these images are from standard ImageNet classes [ 12], they are
often misclassified in multiple models. We used this dataset to test
the robustness of a classifier after training it on ImageNet-9.
NICO [19] is designed for out-of-distribution image classification,
simulating real-world scenarios where testing distributions differ
from training ones. It labels images with both main concepts (e.g.,
cat) and contexts (e.g., at home). We used the Animal super-class
in NICO and followed the setting in [4, 46] for data preparation.
5.2 Experimental Setup
Spurious Attribute Detection. We used two pre-trained VLMs,
ViT-GPT2 [ 35] and BLIP [ 28] to generate text descriptions for im-
ages. ViT-GPT2 has an encoder-decoder structure with a visionDatasetNumber of
detected attributesAverage number of
attributes per image
BLIP ViT-GPT2 BLIP ViT-GPT2
Waterbirds 160 144 3.301 4.314
CelebA 683 345 3.913 4.291
NICO 239 199 3.104 3.995
ImageNet-9 540 442 3.276 4.311
Table 1: Statistics of the attributes detected from the Water-
birds, CelebA, NICO, and ImageNet-9 datasets.
transformer [ 13] as the encoder and the language model GPT-2
[39] as the decoder. BLIP has a multimodal mixture of encoder-
decoder architecture. After generating text descriptions, we used
Spacy (https://spacy.io/) to extract nouns and adjectives from the
descriptions automatically. We additionally filtered out words with
frequencies less than 10 to remove potential annotation noise and to
ensure that we have enough samples to construct a meta-learning
task with selected spurious attributes. We give the statistics of the
detected spurious attributes in the four datasets (ImageNet-A is
not included as it is only used for testing) in Table 1. BLIP detects
more attributes than ViT-GPT2 overall but less attributes for each
image. Based on the two VLMs, our method has two variations,
namely SPUME-BLIP andSPUME-ViT-GPT2 . In the following
experiments, we report the results of both methods.
Training Settings. We set NS=10for sampling each class of
images for both the support and query sets of a task. Following
existing settings [ 23,42,46], we used ResNet-50 as the feature ex-
tractor for the experiments on the Waterbirds and CelebA datasets,
and used ResNet-18 on the ImageNet-9 and NICO datasets. All mod-
els were initialized with weights pre-trained on ImageNet. We used
a stochastic gradient descent (SDG) optimizer with a momentum
of 0.9 and a weight decay of 10−4during meta-training. We trained
a model for 100 epochs and used the cosine annealing scheduler to
control the decay of learning rate. Without any group labels, our
method used the pseudo-unbiased accuracy on the validation set
defined in Eq. (10)for model selection, while other methods used
the average validation accuracy. We repeated each experiment three
times and calculated the averaged results with standard deviations.
We provide additional training details in Appendix. All experiments
were conducted on NVIDIA A100 GPUs.
Baselines. We compare our methods with state-of-the-art meth-
ods on mitigating spurious correlations and provide descriptions of
the baseline methods in Appendix. For fair comparison, the same
feature extractor was used for methods compared on each dataset.
Group labels were not used for model training and selection for
all the compared methods. Note that we did not include VLMs as
baselines, as they were exclusively used for extracting attributes
from training data in our method. Moreover, directly using VLMs
requires a completely different design, e.g., designing proper input
prompts for classification.
Evaluation Metrics. To evaluate the robustness to spurious cor-
relations on the Waterbirds and CelebA datasets, which provide
4529Spuriousness-Aware Meta-Learning for Learning Robust Classifiers KDD ’24, August 25–29, 2024, Barcelona, Spain
Class: landbird
Class: waterbirdSupport samples
Query samples
Support samples
Query samplesAttribute: horse
Attribute: ocean
Attribute: grass ﬁeld
Attribute:  group
Figure 2: A meta-learning task with NS=5constructed from
the Waterbirds dataset. Images in the support set differ sig-
nificantly from images in the query set in terms of their
backgrounds.
group labels, we adopted the widely accepted robustness metric,
worst-group accuracy , that gives the lower-bound performance
of a classifier on the test set with various dataset biases. We also
calculated the accuracy gap between the standard average accu-
racy and the worst-group accuracy as a measure of a classifier’s
reliance on spurious correlations. A high worst-group accuracy
with a low accuracy gap indicates that the classifier is robust to
spurious correlations and can fairly predict samples from different
groups. We adopted average accuracy for the evaluations on the
NICO, ImageNet-9, and ImageNet-A datasets as the these datasets
are specifically constructed to evaluate the robustness to distribu-
tional shifts.
5.3 Visualization of a Spuriousness-Aware Task
We show a spuriousness-aware meta-learning task constructed
from the Waterbirds dataset with NS=5in Fig. 2. For images in
the same class, their backgrounds differ significantly in the support
and query sets. Specifically, the landbird images selected based on
the attribute “horse" in the support set have land backgrounds, while
the same-class images selected based on the attribute “ocean" in
the query set mainly have water backgrounds. Similarly, the query
images of waterbird selected based on the attribute “group" have
backgrounds filled with a group of people, while the corresponding
support images selected based on the attribute “grass field" have
grass backgrounds without irrelevant objects.
The constructed task creates a challenging learning scenario for
classifiers that rely on spurious correlations for predictions. For
example, a classifier that learns to use the land backgrounds to
predict landbird from the support set will fail to predict landbird
images with water backgrounds in the query set. Optimizing a clas-
sifier’s performance on these spuriousness-aware tasks facilitates
the classifier to learn to be invariant to spurious correlations.
(a) landbird (before) (b) landbird (after) (c) waterbird (before) (d) waterbird (after)
(e) non-blond (before) (f) non-blond (after) (g) blond (before) (h) blond (after)
1 .0
0 .8
0 .6
0 .4
0 .2
0 .0
1 .0
0 .8
0 .6
0 .4
0 .2
0 .01 .0
0 .8
0 .6
0 .4
0 .2
0 .01 .0
0 .8
0 .6
0 .4
0 .2
0 .01 .0
0 .8
0 .6
0 .4
0 .2
0 .0040 80 1 201 60 040 80 1 201 60 040 80 1 201 60 040 80 1 201 601 .0
0 .8
0 .6
0 .4
0 .2
0 .01 .0
0 .8
0 .6
0 .4
0 .2
0 .01 .0
0 .8
0 .6
0 .4
0 .2
0 .0
0 200 400 600 0 200 400 600 0 200 400 600 0 200 400 600Figure 3: Spuriousness scores for all the class-attribute cor-
relations before and after applying SPUME-BLIP to a classi-
fier. The horizontal axes represent the indexes of detected
attributes or class-attribute correlations, and the vertical
axes represent the spuriousness scores. (a)-(d) Spuriousness
scores on the Waterbirds dataset with landbird and wa-
terbird classes. (e)-(h) Spuriousness scores on the CelebA
dataset with non-blond and blond classes.
5.4 SPUME Mitigates Reliance on Spurious
Correlations
We calculated the spuriousness scores for all the detected class-
attribute correlations before and after applying SPUME-BLIP to a
classifier with the ResNet-50 backbone initialized with ImageNet
pre-trained weights. We sorted the scores in the “before" scenarios
and kept the order in the corresponding “after" scenarios. From Fig.
3(a), (c), (e), and (g), we observe that the initial classifiers exhibit
high reliance on the detected class-attribute correlations which
have high spuriousness scores. After applying SPUME-BLIP to the
classifiers on the Waterbirds dataset, we observe from Fig. 3(b) and
(d) that the reliance on most of class-attribute correlations are miti-
gated and these correlations all have low spuriousness scores. On
the CelebA dataset, which has more class-attribute correlations than
the Waterbirds dataset, it becomes more challenging to mitigate the
reliance on all these correlations. As observed from Fig. 3 (f) and
(h), some correlations, which have low spuriousness scores initially,
become highly spurious. Nevertheless, SPUME-BLIP can still miti-
gate the reliance on most of the class-attribute correlations having
high spuriousness scores. Moreover, since spuriousness scores are
not directly incorporated into our optimization objective in (9), the
decrease in spuriousness scores demonstrates the effectiveness of
our spuriousness-aware meta-learning strategy in mitigating the
reliance on spurious correlations.
5.5 Quantitative Evaluation
We compared our methods with prior methods on mitigating spuri-
ous correlations on the five datasets. On each of the datasets, we
show the reported results of these methods when they are available
and give the details of these methods in Appendix.
For experiments on the Waterbirds and CelebA datasets, we
aimed to simulate a more realistic learning scenario and thus did
not provide group labels during model training, even though the
4530KDD ’24, August 25–29, 2024, Barcelona, Spain Guangtao Zheng, Wenqian Ye, & Aidong Zhang
Method Worst-group acc. ( ↑) Acc. gap (↓)
ERM 66.4 23.8
LfF [31] 44.1 47.1
CVaR DRO [27] 62.0 33.2
JTT [29] 62.5 30.8
DFR [24] 77.4 14.7
DivDis [26] 81.0 9.7
SPUME-ViT-GPT2 85.9±0.2 6.9±0.8
SPUME-BLIP 85.7±0.2 6.1±0.4
Table 2: Comparison of worst-group accuracy (%) and accu-
racy gap (%) on the Waterbirds dataset. All methods do not
have access to ground-truth group labels.
Method Worst-group acc. ( ↑) Acc. gap (↓)
ERM 45.7 49.8
LfF [31] 24.4 60.7
CVaR DRO [27] 36.1 46.4
JTT [29] 40.6 47.4
DFR [24] 46.0 49.8
DivDis [26] 55.0 35.8
MaskTune [2] 78.0 13.3
SPUME-ViT-GPT2 84.4±1.2 5.9±0.7
SPUME-BLIP 86.0±1.0 4.1±1.0
Table 3: Comparison of worst-group accuracy (%) and accu-
racy gap (%) on the CelebA dataset. All methods do not have
access to ground-truth group labels.
two datasets provide group labels. During testing, we used the
group labels to formulate the worst-group accuracy and calculated
theaccuracy gap as the standard average accuracy minus the worst-
group accuracy. The two metrics measure a classifier’s robustness
tospecific spurious correlations specified by the group labels, and
our goal is to train the classifier to be robust to these spurious
correlations without knowing them.
Our methods, SPUME-ViT-GPT2 and SPUME-BLIP achieve the
best worst-group accuracy and the best accuracy gap on the Wa-
terbirds and CelebA datasets (Tables 2 and 3), suggesting that our
trained classifiers have strong and balanced prediction capability
across different data groups. Note that the spurious attribute detec-
tion process proposed in Section 4.1 could introduce biases present
in VLMs into the detected spurious attributes. More specifically,
biases in different VLMs result in different sets of attributes. Conse-
quently, SPUME simulates different sets of spurious correlations
during meta-training. However, this wouldn’t be a significant con-
cern. Since our spurious attribute detection process can detect many
distinctive attributes with well-established VLMs, SPUME can miti-
gate many potential spurious correlations. Thus, biases in VLMs
won’t significantly affect the effectiveness of our framework. We
demonstrate this by showing that SPUME with two well-established
VLMs are effective and have comparable performance across dif-
ferent datasets (Tables 2 and 3). Moreover, SPUME-BLIP performsMethod Accuracy ( ↑)
ERM 75.9
REx [25] 74.3
Group DRO [42] 77.6
JiGen [7] 85.0
Mixup [55] 80.3
CNBB [19] 78.2
DecAug [4] 85.2
SIFER [47] 86.2±0.9
SPUME-ViT-GPT2 88.2±1.1
SPUME-BLIP 89.2±0.4
Table 4: Comparison of average accuracy (%) on the NICO
dataset. Most of the methods (DecAug, DRO, etc) use group
information for training, while we do not use it.
Metho
d ImageNet-9 (↑) ImageNet-A (↑) Acc. gap (↓)
ERM
90.8±0.6 24.9±1.1 65.9
ReBias [3] 91.9±1.7 29.6±1.6 62.3
LfF [31] 86.0 24.6 61.4
CaaM [49] 95.7 32.8 62.9
SSL+ERM [23] 94.2±0.1 34.2±0.5 60
LWBC[23] 94.0±0.2 36.0±0.5 58
SIFER [46] 97.8±0.1 40.0±0.8 57.8
SP
UME-ViT-GPT2 95.3±0.5 44.3±0.8 51.0±1.1
SPUME-BLIP 95.5±0.2 42.5±0.8 53.0±0.7
Table 5: Comparison of average accuracy (%) and accuracy
gap (%) on the ImageNet-9 and ImageNet-A datasets.
much better than SPUME-ViT-GPT2 on the CelebA dataset where
BLIP detects approximately twice as many attributes as ViT-GPT2
does (Table 1), suggesting that detecting more attributes benefits
SPUME in training more robust classifiers.
The NICO dataset provides object-context correlations and aims
to evaluate the out-of-distribution generalization capability of a
classifier by testing it in new contexts. We did not use the provided
correlations during training and calculated the standard average ac-
curacy on the test set with new object-context correlations. SPUME-
ViT-GPT2 and SPUME-BLIP outperform previous methods with
higher average accuracies (Table 4).
For the experiments on the ImageNet-9 which does not provide
information on spurious correlations, we trained and tested our
methods on the ImageNet-9 dataset. We also tested our methods on
the ImageNet-A dataset which contains images representing various
failure prediction modes in an ImageNet pre-trained classifier. The
accuracy gap is calculated as the average validation accuracy on the
ImageNet-9 dataset minus the average accuracy on the ImageNet-
A dataset. Our methods achieve the best on ImageNet-A while
well balancing between different prediction modes with the lowest
accuracy gaps (Table 5).
4531Spuriousness-Aware Meta-Learning for Learning Robust Classifiers KDD ’24, August 25–29, 2024, Barcelona, Spain
Method Worst-group acc ( ↑) Acc. gap (↓)
ERM 66.4 23.8
ERM-Cosine 75.5 17.5
SPUME-Random 78.7±0 .9 10.5±0 .8
SPUME-BLIP 85.7±0 .2 6.1±0.4
SPUME-ViT-GPT2 85.9±0.3 6.9±0.8
Table 6: Worst-group accuracy and accuracy gap com-
parisons between meta-learning based methods with
spuriousness-aware (SPUME-BLIP and SPUME-ViT-GPT2)
and random (SPUME-Random) task constructions, and
ERM-trained models on the Waterbirds dataset.
5.6 Ablation Study
Spuriousness-Aware Task Construction. To evaluate the effective-
ness of using VLMs to guide the construction of meta-learning
tasks, we compared SPUME with SPUME-Random which uses ran-
domly constructed tasks during training. We also included the
classical ERM model and the ERM-Cosine model that uses cosine
distance for predictions to compare with the meta-learning based
approaches. We observe from Table 6 that switching to the cosine-
distance-based classifier increases the robustness to spurious cor-
relations. Moreover, SPUME-Random outperforms ERM by 12.3%
in the worst-group accuracy and improves the accuracy gap by
13.3%, demonstrating that meta-learning is a promising approach
to improve the robustness to spurious correlations. Additionally,
using spuriousness-aware meta-learning tasks constructed with
the VLMs (BLIP and ViT-GPT2) can further improve robustness to
spurious correlations. Specifically, SPUME-BLIP achieves 7.0% and
4.4% increments over SPUME-Random in the worst-group accuracy
and accuracy gap, respectively, and SPUME-ViT-GPT2 achieves
7.2% and 3.6% increments in the two metrics.
Different Designs of the Spuriousness Metric. We have given our
design of spuriousness metric in Eq. (3). Here, we explore other pos-
sible design choices shown in Table 7, where δ=J(D(y,a)
tr;fθ)−
J(D(y,ˆa)
tr;fθ),η=J(D(y,a)
tr;fθ)/J(D(y,ˆa)
tr;fθ),J(·;·)is the accu-
racy measure used in Eq. (3), and “Constant" represents that we
assign the same score for all the detected attributes. Our method
SPUME-BLIP works well with different spuriousness metrics and
still outperforms the baselines we compared in Table 2. Moreover,
our method works well with non-negative spuriousness metrics as
SPUME with tanh(abs(log( η))) or abs(δ) performs better than with
the other two metrics.
Scaling Parameter of the Centroid-Based Classifier. We analyzed
how the scaling parameter τof the centroid-based classifier (Eq. (7))
affects the performance of SPUME. Fig. 4 shows the worst-group
accuracies and accuracy gaps of SPUME-BLIP with different τ’s
on the Waterbirds dataset. A very large or small τ, e.g.,τ=100or
τ=1, harms to robustness of the trained classifiers. In practice, we
setτto be in the range from 5 to 50.
Effects of Using VLMs. Although SPUME uses VLMs for data
preprocessing, the robustness does not directly come from theMetric Worst-group acc. ( ↑) Acc. gap (↓)
tanh(abs(log( η))) 85.7±0.2 6.1±0.4
abs(δ) 85.5±0.2 6.3±0.3
Constant 85.1±0.2 6.7±0.3
tanh(log(η)) 84.8±0.2 7.3±0.4
δ 84.5±0.5 7.4±0.9
Table 7: Analysis on different designs of spuriousness met-
rics. We tested SPUME-BLIP on the Waterbirds dataset.
Worst-group accuracy
Accuracy gapWorst-group accuracy (%)
Accuracy gap (%)85.5
85.0
84.5
84.06.6
6.4
6.2
6.0
5.8
15 20 100
Figure 4: Worst-group accuracy and accuracy gap compar-
isons between SPUME-BLIP with different τ’s on Water-
birds.
outputs of VLMs. To show this, we added an additional layer after
the backbone to predict detected attributes for each image, acting
as a regularization. We then fine-tuned the whole model on the
Waterbirds and CelebA datasets, respectively. The worst-group
accuracies on the two datasets are 71.7% and 47.2%, respectively,
which are close to ERM trained models. Therefore, the attributes
themselves do not provide useful regularization on the robustness
of the classifier. Moreover, directly using VLMs for predictions
requires a completely different inference pipeline and is not as
effective as our proposed SPUME. Details are provided in Appendix.
6 CONCLUSION
We proposed a novel framework to train a classifier to be robust
against spurious correlations in settings where spurious correla-
tions are not known or specified. We first adopted a pre-trained VLM
to automatically extract text-format attributes from a target dataset.
Then, we quantified the spuriousness of the correlations between
detected attributes and class labels using a spuriousness metric.
To effectively mitigate multiple detected spurious correlations, we
adopted a meta-learning strategy which iteratively meta-trains a
classifier on multiple meta-learning tasks constructed to represent
various class-attribute correlations with high spuriousness values.
Our framework, SPUME, mitigates many highly spurious corre-
lations in training samples and performs the best under different
robustness measures on five benchmark datasets. In the future, we
aim to explore more capable VLMs and combine other approaches,
e.g., customized data augmentations, for mitigating a model’s re-
liance on a wider range of spurious correlations.
ACKNOWLEDGMENTS
This work is supported in part by the US National Science Founda-
tion under grants 2217071, 2213700, 2106913, 2008208, 1955151.
4532KDD ’24, August 25–29, 2024, Barcelona, Spain Guangtao Zheng, Wenqian Ye, & Aidong Zhang
REFERENCES
[1]Abubakar Abid, Mert Yuksekgonul, and James Zou. 2022. Meaningfully debugging
model mistakes using conceptual counterfactual explanations. In International
Conference on Machine Learning. PMLR, 66–88.
[2]Saeid Asgari, Aliasghar Khani, Fereshte Khani, Ali Gholami, Linh Tran, Ali
Mahdavi Amiri, and Ghassan Hamarneh. 2022. Masktune: Mitigating spurious
correlations by forcing to explore. Advances in Neural Information Processing
Systems 35 (2022), 23284–23296.
[3]Hyojin Bahng, Sanghyuk Chun, Sangdoo Yun, Jaegul Choo, and Seong Joon
Oh. 2020. Learning de-biased representations with biased representations. In
International Conference on Machine Learning. PMLR, 528–539.
[4]Haoyue Bai, Rui Sun, Lanqing Hong, Fengwei Zhou, Nanyang Ye, Han-Jia Ye,
S-H Gary Chan, and Zhenguo Li. 2021. Decaug: Out-of-distribution general-
ization via decomposed feature representation and semantic augmentation. In
Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 35. 6705–6713.
[5]Sara Beery, Grant Van Horn, and Pietro Perona. 2018. Recognition in terra
incognita. In Proceedings of the European Conference on Computer Vision. 456–
473.
[6]Jonathon Byrd and Zachary Lipton. 2019. What is the effect of importance
weighting in deep learning?. In International Conference on Machine Learning.
PMLR, 872–881.
[7]Fabio M Carlucci, Antonio D’Innocente, Silvia Bucci, Barbara Caputo, and Tatiana
Tommasi. 2019. Domain generalization by solving jigsaw puzzles. In Proceedings
of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2229–
2238.
[8]Yinbo Chen, Xiaolong Wang, Zhuang Liu, Huijuan Xu, and Trevor Darrell. 2020.
A new meta-baseline for few-shot learning. arXiv preprint arXiv:2003.04390
(2020).
[9]Christopher Clark, Mark Yatskar, and Luke Zettlemoyer. 2019. Don’t Take the
Easy Way Out: Ensemble Based Methods for Avoiding Known Dataset Biases. In
Proceedings of the 2019 Conference on Empirical Methods in Natural Language Pro-
cessing and the 9th International Joint Conference on Natural Language Processing
(EMNLP-IJCNLP). 4069–4082.
[10] Elliot Creager, Jörn-Henrik Jacobsen, and Richard Zemel. 2021. Environment
inference for invariant learning. In International Conference on Machine Learning.
PMLR, 2189–2200.
[11] Yin Cui, Menglin Jia, Tsung-Yi Lin, Yang Song, and Serge Belongie. 2019. Class-
balanced loss based on effective number of samples. In Proceedings of the IEEE/CVF
Conference on Computer Vision and Pattern Recognition. 9268–9277.
[12] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. 2009. Im-
ageNet: A large-scale hierarchical image database. In 2009 IEEE Conference on
Computer Vision and Pattern Recognition. 248–255. https://doi.org/10.1109/CVPR.
2009.5206848
[13] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xi-
aohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg
Heigold, Sylvain Gelly, et al .2020. An Image is Worth 16x16 Words: Trans-
formers for Image Recognition at Scale. In International Conference on Learning
Representations.
[14] Chelsea Finn, Pieter Abbeel, and Sergey Levine. 2017. Model-agnostic meta-
learning for fast adaptation of deep networks. In International Conference on
Machine Learning, Vol. 70. 1126–1135.
[15] Robert Geirhos, Jörn-Henrik Jacobsen, Claudio Michaelis, Richard Zemel,
Wieland Brendel, Matthias Bethge, and Felix A Wichmann. 2020. Shortcut learn-
ing in deep neural networks. Nature Machine Intelligence 2, 11 (2020), 665–673.
[16] Robert Geirhos, Patricia Rubisch, Claudio Michaelis, Matthias Bethge, Felix A.
Wichmann, and Wieland Brendel. 2019. ImageNet-trained CNNs are biased
towards texture; increasing shape bias improves accuracy and robustness.. In
International Conference on Learning Representations.
[17] Zongbo Han, Zhipeng Liang, Fan Yang, Liu Liu, Lanqing Li, Yatao Bian, Peilin
Zhao, Bingzhe Wu, Changqing Zhang, and Jianhua Yao. 2022. Umix: Improving
importance weighting for subpopulation shift via uncertainty-aware mixup.
Advances in Neural Information Processing Systems 35 (2022), 37704–37718.
[18] Haibo He and Edwardo A Garcia. 2009. Learning from imbalanced data. IEEE
Transactions on knowledge and data engineering 21, 9 (2009), 1263–1284.
[19] Yue He, Zheyan Shen, and Peng Cui. 2021. Towards non-iid image classification:
A dataset and baselines. Pattern Recognition 110 (2021), 107383.
[20] Dan Hendrycks, Kevin Zhao, Steven Basart, Jacob Steinhardt, and Dawn Song.
2021. Natural adversarial examples. In Proceedings of the IEEE/CVF Conference on
Computer Vision and Pattern Recognition. 15262–15271.
[21] Andrew Ilyas, Shibani Santurkar, Dimitris Tsipras, Logan Engstrom, Brandon
Tran, and Aleksander Madry. 2019. Adversarial examples are not bugs, they are
features. Advances in Neural Information Processing Systems 32 (2019).
[22] Pavel Izmailov, Polina Kirichenko, Nate Gruver, and Andrew G Wilson. 2022. On
feature learning in the presence of spurious correlations. Advances in Neural
Information Processing Systems 35 (2022), 38516–38532.
[23] Nayeong Kim, Sehyun Hwang, Sungsoo Ahn, Jaesik Park, and Suha Kwak. 2022.
Learning debiased classifier with biased committee. Advances in Neural Informa-
tion Processing Systems 35 (2022), 18403–18415.[24] Polina Kirichenko, Pavel Izmailov, and Andrew Gordon Wilson. 2023. Last Layer
Re-Training is Sufficient for Robustness to Spurious Correlations. In International
Conference on Learning Representations.
[25] David Krueger, Ethan Caballero, Joern-Henrik Jacobsen, Amy Zhang, Jonathan
Binas, Dinghuai Zhang, Remi Le Priol, and Aaron Courville. 2021. Out-of-
distribution generalization via risk extrapolation (rex). In International Conference
on Machine Learning. PMLR, 5815–5826.
[26] Yoonho Lee, Huaxiu Yao, and Chelsea Finn. 2022. Diversify and disambiguate:
Out-of-distribution robustness via disagreement. In International Conference on
Learning Representations.
[27] Daniel Levy, Yair Carmon, John C Duchi, and Aaron Sidford. 2020. Large-scale
methods for distributionally robust optimization. Advances in Neural Information
Processing Systems 33 (2020), 8847–8860.
[28] Junnan Li, Dongxu Li, Caiming Xiong, and Steven Hoi. 2022. Blip: Bootstrapping
language-image pre-training for unified vision-language understanding and
generation. In International Conference on Machine Learning. PMLR, 12888–12900.
[29] Evan Z Liu, Behzad Haghgoo, Annie S Chen, Aditi Raghunathan, Pang Wei Koh,
Shiori Sagawa, Percy Liang, and Chelsea Finn. 2021. Just train twice: Improving
group robustness without training group information. In International Conference
on Machine Learning. PMLR, 6781–6792.
[30] Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang. 2015. Deep learning
face attributes in the wild. In Proceedings of the IEEE International Conference on
Computer Vision. 3730–3738.
[31] Junhyun Nam, Hyuntak Cha, Sungsoo Ahn, Jaeho Lee, and Jinwoo Shin. 2020.
Learning from failure: De-biasing classifier from biased classifier. Advances in
Neural Information Processing Systems 33 (2020), 20673–20684.
[32] Junhyun Nam, Jaehyung Kim, Jaeho Lee, and Jinwoo Shin. 2022. Spread Spurious
Attribute: Improving Worst-group Accuracy with Spurious Attribute Estimation.
InInternational Conference on Learning Representations.
[33] Meike Nauta, Ricky Walsh, Adam Dubowski, and Christin Seifert. 2021. Uncover-
ing and correcting shortcut learning in machine learning models for skin cancer
diagnosis. Diagnostics 12, 1 (2021), 40.
[34] Yannic Neuhaus, Maximilian Augustin, Valentyn Boreiko, and Matthias Hein.
2022. Spurious Features Everywhere–Large-Scale Detection of Harmful Spurious
Features in ImageNet. arXiv preprint arXiv:2212.04871 (2022).
[35] NLP Connect. 2022. vit-gpt2-image-captioning (Revision 0e334c7). https://
huggingface.co/nlpconnect/vit-gpt2-image-captioning.
[36] Besmira Nushi, Ece Kamar, and Eric Horvitz. 2018. Towards accountable ai:
Hybrid human-machine analyses for characterizing system failure. In Proceedings
of the AAAI Conference on Human Computation and Crowdsourcing, Vol. 6. 126–
135.
[37] Boris Oreshkin, Pau Rodríguez López, and Alexandre Lacoste. 2018. TADAM:
Task dependent adaptive metric for improved few-shot learning. In Advances in
Neural Information Processing Systems. 721–731.
[38] Gregory Plumb, Marco Tulio Ribeiro, and Ameet Talwalkar. 2022. Finding and
Fixing Spurious Patterns with Explanations. Transactions on Machine Learning
Research (2022). Expert Certification.
[39] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever,
et al.2019. Language models are unsupervised multitask learners. OpenAI blog
1, 8 (2019), 9.
[40] Aniruddh Raghu, Maithra Raghu, Samy Bengio, and Oriol Vinyals. 2020. Rapid
Learning or Feature Reuse? Towards Understanding the Effectiveness of MAML.
InInternational Conference on Learning Representations.
[41] Andrei A. Rusu, Dushyant Rao, Jakub Sygnowski, Oriol Vinyals, Razvan Pascanu,
Simon Osindero, and Raia Hadsell. 2019. Meta-Learning with Latent Embedding
Optimization. In International Conference on Learning Representations.
[42] Shiori Sagawa, Pang Wei Koh, Tatsunori B Hashimoto, and Percy Liang. 2019.
Distributionally Robust Neural Networks. In International Conference on Learning
Representations.
[43] Sahil Singla and Soheil Feizi. 2021. Salient ImageNet: How to discover spurious
features in Deep Learning?. In International Conference on Learning Representa-
tions.
[44] Jake Snell, Kevin Swersky, and Richard Zemel. 2017. Prototypical Networks
for Few-shot Learning. In Advances in Neural Information Processing Systems.
4077–4087.
[45] F. Sung, Y. Yang, L. Zhang, T. Xiang, P. H. S. Torr, and T. M. Hospedales. 2018.
Learning to Compare: Relation Network for Few-Shot Learning. In IEEE/CVF
Conference on Computer Vision and Pattern Recognition. 1199–1208.
[46] Rishabh Tiwari and Pradeep Shenoy. 2023. Overcoming Simplicity Bias in Deep
Networks using a Feature Sieve. In International Conference on Machine Learning
(Proceedings of Machine Learning Research, Vol. 202), Andreas Krause, Emma
Brunskill, Kyunghyun Cho, Barbara Engelhardt, Sivan Sabato, and Jonathan
Scarlett (Eds.). PMLR, 34330–34343.
[47] Rishabh Tiwari and Pradeep Shenoy. 2023. Overcoming simplicity bias in deep
networks using a feature sieve. In International Conference on Machine Learning.
PMLR, 34330–34343.
[48] Oriol Vinyals, Charles Blundell, Timothy Lillicrap, koray kavukcuoglu, and Daan
Wierstra. 2016. Matching Networks for One Shot Learning. In Advances in Neural
4533Spuriousness-Aware Meta-Learning for Learning Robust Classifiers KDD ’24, August 25–29, 2024, Barcelona, Spain
Information Processing Systems. 3630–3638.
[49] Tan Wang, Chang Zhou, Qianru Sun, and Hanwang Zhang. 2021. Causal attention
for unbiased visual recognition. In Proceedings of the IEEE/CVF International
Conference on Computer Vision. 3091–3100.
[50] P. Welinder, S. Branson, T. Mita, C. Wah, F. Schroff, S. Belongie, and P. Perona.
2010. Caltech-UCSD Birds 200. Technical Report CNS-TR-2010-001. California
Institute of Technology.
[51] Shirley Wu, Mert Yuksekgonul, Linjun Zhang, and James Zou. 2023. Discover
and Cure: Concept-aware Mitigation of Spurious Correlation. arXiv preprint
arXiv:2305.00650 (2023).
[52] Kai Yuanqing Xiao, Logan Engstrom, Andrew Ilyas, and Aleksander Madry.
2021. Noise or Signal: The Role of Image Backgrounds in Object Recognition. In
International Conference on Learning Representations.
[53] Huaxiu Yao, Yu Wang, Sai Li, Linjun Zhang, Weixin Liang, James Zou, and Chelsea
Finn. 2022. Improving out-of-distribution robustness via selective augmentation.
InInternational Conference on Machine Learning. PMLR, 25407–25437.
[54] Han-Jia Ye, Hexiang Hu, De-Chuan Zhan, and Fei Sha. 2020. Few-Shot Learning
via Embedding Adaptation with Set-to-Set Functions. In IEEE/CVF Conference on
Computer Vision and Pattern Recognition. 8808–8817.
[55] Hongyi Zhang, Moustapha Cisse, Yann N Dauphin, and David Lopez-Paz. 2017.
mixup: Beyond empirical risk minimization. arXiv preprint arXiv:1710.09412
(2017).
[56] Hongyi Zhang, Moustapha Cisse, Yann N Dauphin, and David Lopez-Paz. 2018.
mixup: Beyond Empirical Risk Minimization. In International Conference on Learn-
ing Representations.
[57] Jiawei Zhang, Yang Wang, Piero Molino, Lezhi Li, and David S Ebert. 2018. Man-
ifold: A model-agnostic framework for interpretation and diagnosis of machine
learning models. IEEE Transactions on Visualization and Computer Graphics 25, 1
(2018), 364–373.
[58] Michael Zhang, Nimit S Sohoni, Hongyang R Zhang, Chelsea Finn, and Christo-
pher Re. 2022. Correct-N-Contrast: a Contrastive Approach for Improving Robust-
ness to Spurious Correlations. In International Conference on Machine Learning
(Proceedings of Machine Learning Research, Vol. 162), Kamalika Chaudhuri, Ste-
fanie Jegelka, Le Song, Csaba Szepesvari, Gang Niu, and Sivan Sabato (Eds.).
PMLR, 26484–26516.
[59] Bolei Zhou, Agata Lapedriza, Aditya Khosla, Aude Oliva, and Antonio Torralba.
2017. Places: A 10 million image database for scene recognition. IEEE Transactions
on Pattern Analysis and Machine Intelligence 40, 6 (2017), 1452–1464.
A APPENDIX
A.1 Datasets
Table 8 depicts detailed statistics for all datasets. For Waterbirds
and CelebA datasets, we give the number of training, validation,
and test images in each group specified by classes and attributes.
For example, the group label (landbird, land) in the Waterbirds
dataset has 3498 training images which are all landbird and have
land backgrounds. NICO provides context labels as spurious at-
tributes. ImageNet-9 and ImageNet-A datasets do not have clear
group partitions specified by the class and attribute associations.
DatasetNumb
er of
classes⟨class, attribute⟩Number of images
T
rain Val Test
W
aterbirds 2⟨landbird, land⟩ 3,498 467 2,255
⟨landbird, water⟩ 184 466 2,255
⟨waterbird, land⟩ 56 133 642
⟨waterbird, water⟩ 1,057 133 642
Celeb
A 2⟨non-blond, female⟩ 71,629 8,535 9,767
⟨non-blond, male⟩ 66,874 8,276 7,535
⟨blond, female⟩ 22,880 2,874 2,480
⟨blond, male⟩ 1,387 182 180
NICO
10⟨object, context⟩ 10298 642 894
ImageNet-9
9 - 54,600 2,100 -
ImageNet-
A 9 - - - 1087
Table 8: Detailed statistics of the 5 datasets. ⟨class, attribute⟩
represents a spurious correlation between a class and a spu-
rious attribute. “-" denotes not applicable.ClassContexts
Validation Test
dog running in_street
cat on_tree in_street
bear on_tree white
bird on_shoulder in_hand
cow spotted standing
elephant in_circus in street
horse running in_street
monkey climbing sitting
rat running in_hole
sheep at_sunset on_road
Table 9: Classes and their associated contexts in the NICO
datasets. Contexts not shown in the table are used in the
training set.
NICO [ 19] is a real-world dataset for out-of-distribution robust-
ness. We used its Animal subset containing 10 object classes and 33
context labels. Following the setting in [ 4,47], we split the dataset
into training, validation, and test sets with each set having unique
contexts. Table 9 gives the allocation of the contexts for the 10
classes.
The ImageNet-9 dataset [ 3] is a subset of ImageNet. It has 9
super-classes, i.e., Dog, Cat, Frog, Turtle, Bird, Primate, Fish, Crab,
Insect, which are obtained by merging similar classes from Ima-
geNet. ImageNet-A contains real-world images that are challenging
to the image classifiers trained on standard ImageNet. We extract
images of the 9 super-classes from the ImageNet-A dataset and use
these images as the test data.
A.2 Experimental Details
VLM Settings. For both ViT-GPT2 and BLIP, we set the maximum
length of the sequence to be generated as 16 and the number of
beams for beam search to 4.
Training Details. We initialize ResNet-50 and ResNet-18 using
ImageNet pre-trained weights. Standard data augmentations, i.e.,
RandomResizedCrop andRandomHorizontalFlip are used during
model training. We use an SDG optimizer with a momentum of
0.9 and a weight decay of 10−4during meta-training. The detailed
training configurations are shown in Table 10.
A.3 Baselines
We briefly summarize and describe the baselines which are com-
pared in the experiments:
Group DRO [42] proposes to train the models on the worst-case
loss over a set of predefined groups.
ReBias [3] proposes a novel framework to train a de-biased rep-
resentation by encouraging it to be different from a set of biased
representations.
REx [25] proposes a min-max algorithm to optimize for the worst
linear combination of risks on different environments.
4534KDD ’24, August 25–29, 2024, Barcelona, Spain Guangtao Zheng, Wenqian Ye, & Aidong Zhang
Dataset Learning rateLearning rate
schedulerNumber of tasks
per epochTraining epochs τModel selection
metric
Waterbirds 1e-3 Cosine Annealing 80 100 5 Accpu
CelebA 1e-3 Cosine Annealing 80 100 5 Accpu
NICO 5e-3 Cosine Annealing 80 50 10 Validation accuracy
ImageNet-9 1e-3 Cosine Annealing 80 50 50 Validation accuracy
Table 10: Hyperparameter settings and model selection criteria for SPUME training on the Waterbirds, CelebA, NICO, and
ImageNet-9 datasets. Accpudenotes pseudo unbiased validation accuracy.
LfF [31] proposes a failure-based debiasing scheme by training a
pair of neural networks: the first network to be biased by repeatedly
amplifying its “prejudice" and debias the training of the second
network by focusing on samples that counter the first network.
CVaR DRO [27] is an algorithm for distributionally robust opti-
mization of convex losses with conditional value at risk (CVaR) and
χ2divergence uncertainty sets.
JTT [29] proposes a simple two-stage approach that first trains a
standard ERM model and then trains a second model by upweight-
ing the training examples misclassified by the first model.
DFR [24] retrains the last linear layer on a small held-out dataset
with balanced groups of data.
CaaM [49] learns causal features that are robust in any confound-
ing context and self-annotates the confounders in an unsupervised
fashion.
LWBC / SSL+ERM [23] employs a committee of classifiers as an
auxiliary module that identifies bias-conflicting data and assigns
large weights to them when training the main classifier. SSL+ERM
is another approach proposed in this paper that uses self-supervised
representation as the frozen backbone of the committee and the
main classifier.
MaskTune [2] employs an interpretation-based masking strat-
egy that mitigates over-reliance on spurious features. It forces the
trained model to explore new features during a single epoch fine-
tuning by masking previously discovered features.
DivDis [26] is a simple two-stage framework for identifying and
resolving ambiguity in data. It first learns a diverse set of hypotheses
and then disambiguates them by selecting one of the discovered
functions using additional information (e.g. target labels).
JiGen [7] jointly classifies objects and solves unsupervised jigsaw
tasks.
Mixup [55] trains a neural network on convex combinations of
pairs of examples and their labels to alleviate memorization and
sensitivity to adversarial examples in deep neural networks.
CNBB [19] is a non-independent and identically distributed (Non-
I.I.D) learning method that is based on batch balancing inspired by
causal inference.
DecAug [4] proposes a semantic augmentation and feature decom-
position approach to disentangle context features from category-
related features.
SIFER [46] automatically identifies and suppresses easily-computable
spurious features in lower layers of the network and allows thehigher layers of the network to extract and utilize more meaningful
representations.
A.4 Analyzing the Effects of Using VLMs
Using the Outputs of VLMs as Regularization. We added a linear
layer with weights WA∈R|A|× Dand bias bA∈R|A|after the
backbone to predict the detected attributes for each image, i.e.,
˜θ=arg min
θE(x,y)∈D trℓ(fθ(x),y)+Õ
a∈ψ(ϕ(x))ℓ′(f′
θ′(x),a)(11)
where f′
θ′(x)=WAhθ1(x)+bA, and ℓ′(·,·)is the binary entropy loss
function. We trained the whole model on the Waterbirds and CelebA
datasets, respectively. If the attributes contain information effective
in improving a classifier’s robustness to spurious correlations, we
will observe improved performance after training. However, the
worst-group accuracies on the Waterbirds and CelebA datasets are
71.7% and 47.2%, respectively, which are only slightly better than
those of ERM and fall far behind the results of SPUME. Therefore,
the detected attributes from the VLM alone do not contain infor-
mation effective for improving a classifier’s robustness to spurious
correlations.
Directly Using VLMs for Predictions. Although the goal of this
paper is to learn a classic and resource-light classifier that is robust
to spurious correlations, we explored the scenario when BLIP is
directly used for prediction with modifications on the inference par-
adigm. Specifically, we used text embeddings of the sentences with
the template “a photo of class_label " (“a person with hair_color
hair" for CelebA) from BLIP as the classifier weights and calcu-
lated the cosine similarity between an image embedding and these
weights in the shared embedding space of BLIP. We predicted the
label such that its corresponding sentence has the highest similar-
ity to the image embedding. The worst group accuracies on the
Waterbirds and CelebA datasets are 1.17% and 29.71% respectively.
The average accuracies on the NICO, ImageNet-9, and ImageNet-A
datasets are 14.30%, 13.43%, and 9.20%, respectively. Directly using
the VLM without carefully tuning the inference pipeline performs
much worse than our proposed method. In contrast, our proposed
method SPUME exploits the attributes provided by VLMs in a novel
way for significant improvement in the robustness of a classifier to
spurious correlations.
4535