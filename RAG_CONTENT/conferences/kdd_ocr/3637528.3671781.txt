Natural Language Explainable Recommendation
with Robustness Enhancement
Jingsen Zhang‚àó
Gaoling School of Artificial
Intelligence, Renmin
University of China
Beijing, China
zhangjingsen@ruc.edu.cnJiakai Tang‚àó
Gaoling School of Artificial
Intelligence, Renmin
University of China
Beijing, China
tangjiakai5704@gmail.comXu Chen‚àó‚Ä†
Gaoling School of Artificial
Intelligence, Renmin
University of China
Beijing, China
xu.chen@ruc.edu.cnWenhui Yu
Kuaishou Technology
Beijing, China
yuwenhui07@kuaishou.com
Lantao Hu
Kuaishou Technology
Beijing, China
hulantao@kuaishou.comPeng Jiang
Kuaishou Technology
Beijing, China
jiangpeng@kuaishou.comHan Li
Kuaishou Technology
Beijing, China
lihan08@kuaishou.com
Abstract
Natural language explainable recommendation has become a promis-
ing direction to facilitate more efficient and informed user decisions.
Previous models mostly focus on how to enhance the explana-
tion accuracy. However, the robustness problem has been largely
ignored, which requires the explanations generated for similar
user-item pairs should not be too much different. Different from
traditional classification problems, improving the robustness of nat-
ural languages has two unique characteristics: (1) Different token
importances, that is, different tokens play various roles in repre-
senting the complete sentence, and the robustness requirements for
predicting them should also be different. (2) Continuous token
semantics, that is, the similarity of the output should be judged
based on semantics, and the sequences without any token-level
overlap may also be highly similar. Based on these characteristics,
we formulate and solve a novel problem in the recommendation
domain, that is, robust natural language explainable recommen-
dation. To the best of our knowledge, it is the first time in this
field. Specifically, we base our modeling on adversarial robust opti-
mization and design four types of heuristic methods to modify the
adversarial outputs with weighted token probabilities and synonym
replacements. Furthermore, to consider the mutual influence be-
tween the above characteristics, we regard language generation as
a decision-making problem and design a dual-policy reinforcement
learning framework to improve the robustness of the generated
languages. We conduct extensive experiments to demonstrate the
effectiveness of our framework.
‚àóBeijing Key Laboratory of Big Data Management and Analysis Methods.
‚Ä†Corresponding author.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain
¬©2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 979-8-4007-0490-1/24/08
https://doi.org/10.1145/3637528.3671781CCS Concepts
‚Ä¢Information systems ‚ÜíRecommender systems.
Keywords
Explainable Recommendation, Natural Language Explanations, Ad-
versarial Learning
ACM Reference Format:
Jingsen Zhang, Jiakai Tang, Xu Chen, Wenhui Yu, Lantao Hu, Peng Jiang,
Han Li. 2024. Natural Language Explainable Recommendation with Ro-
bustness Enhancement. In Proceedings of the 30th ACM SIGKDD Conference
on Knowledge Discovery and Data Mining (KDD ‚Äô24), August 25‚Äì29, 2024,
Barcelona, Spain. ACM, New York, NY, USA, 10 pages. https://doi.org/10.
1145/3637528.3671781
1 Introduction
Explainable recommendation seeks to provide users with explana-
tions clarifying why a particular item is recommended to them [ 46].
With the capability to improve system transparency and user sat-
isfaction, generating reasonable explanations is recognized as a
promising direction in recommender systems (RecSys). Among var-
ious strategies, natural language explanations have emerged as a
pivotal approach, capable of offering more flexible and informative
explanations to facilitate user decision-making. Generally, these
approaches utilize user reviews as explanation labels for supervised
training and generate explanatory texts about recommended items
in the inference phase. In order to improve the accuracy of pre-
dicted explanations, NRT [ 21] integrates explanation generation
with rating prediction. NETE [ 18] incorporates specific features
into the decoding process. PETER [ 19] utilizes the Transformer to
learn better sequence representations for further improvement.
Although these methods have achieved impressive performance,
they mainly focus on designing advanced architectures to enhance
explanation accuracy while neglecting the aspect of robustness,
which can impair model‚Äôs generalization ability, resulting in poor
performance on unseen data [ 10,15,34]. The robustness in ex-
plainable recommendation requires the explanations generated for
similar user-item pairs should not be too much different. However,
existing methods often fail to satisfy this criterion. Figure 1 illus-
trates examples of recommendation explanations generated by the
PETER model on the real-world datasets. The first case presents the
4203
KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain Jingsen Zhang et al.
Thepizzatastedlikecardboard.Thepizzatastedgood.Thepillowisabithard.
ùëñ!ùë¢"ùë¢#ùë¢!ùëñ#ùëñ"
Thepillowwasverycomfortable.UsersItemsGeneratedExplanations
Figure 1: Examples illustrating the poor robustness in gener-
ating explanations, produced by the PETER model.
explanations generated for two similar users, ùë¢1andùë¢2, regarding
the same pizza. We observe that in the explanation for ùë¢1, the word
‚Äúcardboard‚Äù indicates poor taste, which conflicts to the term ‚Äúgood‚Äù
in the explanation for ùë¢2. The second case shows the explanations
forùë¢3about two similar pillows, ùëñ2andùëñ3, which possess same
features. Likewise, there is a contradiction where the word ‚Äúhard‚Äù
implies a negative opinion, conflicting with the term "comfortable"
mentioned in the first sentence. Considering these observations, if
we create a fabricated user (or item) by introducing minor perturba-
tions to the original user‚Äôs (or item‚Äôs) representation, the model may
generate explanations that differ significantly. This susceptibility
to minor perturbations indicates the poor robustness of models.
Moreover, such inconsistency in explanations can potentially cause
user confusion and undermine system‚Äôs credibility.
To address the aforementioned issue, we propose to enhance
robustness for natural language explainable recommendation. It is
an important yet unexplored problem, posing various challenges.
Existing studies on robust optimization [ 12,30] mainly focus on
classification tasks, such as image classification and click-through
rate prediction. The goal of robustness in these studies is to main-
tain consistent predictions when subjected to minor perturbations.
However, generating explanation involves sequence generation,
thus directly applying the prior methods is unfeasible. Specifically,
there are two unique characteristics that should be considered for
the robustness of sequence generation: different token importances
and continuous token semantics. The former refers that different
tokens play various roles in representing the complete sentence,
and the robustness requirements for predicting them should also
be different. The latter indicates that the similarity of the output
should be judged based on semantics, and the sequences without
any token-level overlap may also be highly similar. Moreover, it is
imperative to integrate these characteristics and capture the mutual
influence between them for comprehensive robustness. This paper
represents an significant extension of the traditional robust method
in sequence generation problem, which has not been explored.
To overcome these challenges, we propose to design a compre-
hensive robust framework for explainable recommendation based
on adversarial learning. We begin by defining the objective function
for adversarial robustness in the explanation generation task, which
differs significantly from that in the classification task and can be
easily extended to other sequence generation tasks. Additionally,
to model two unique characteristics of sequence generation, we
design both context-free and context-aware methods for token im-
portance estimation and synonym replacement. To consider the
mutual influence between these characteristics, we regard sequence
generation as a decision-making problem and develop a dual-policy
reinforcement learning framework, where each task is assigned toan agent and optimized through maximum likelihood estimation
with a shared reward mechanism. It enables us to obtain collabora-
tive strategies for constructing adversarial examples.
The main contributions of this paper can be summarized as
follows: (1) We formulate the robustness objective in sequence
generation, which differs from that in classification problem. And
we propose a Robustness-enhanced framework for natural language
explainable r ecommendation (called Rober for short). To the best
of our knowledge, it is the first time in recommendation domain.
(2) We analyze two key characteristics of sequence generation and
design a dual-policy reinforcement learning framework to capture
the mutual influence between them. (3) Extensive experiments on
real-world datasets demonstrate the improvements achieved by our
framework on the quality and robustness of explanations.
2 Preliminaries
2.1 Natural Language Explanations for RecSys
Natural language explainable recommendation aims to generate
textual explanations about the recommended items, offering users
informative and accessible insights. Generally, these approaches
utilize user reviews, which encompass user preferences, as sub-
stitutes for real explanations [ 9,11,18,19,21], and transform ex-
planation generation into review prediction task. Formally, given
a user setUand an item setI, the interactions are recorded in
D={(ùë¢,ùëñ,ùíÜùë¢ùëñ,ùëüùë¢ùëñ)|ùë¢‚ààU,ùëñ‚ààI} , whereùëüùë¢ùëñrepresents user‚Äôs
rating, ranging from 1 to 5, and ùíÜùë¢ùëñ={ùëí1
ùë¢ùëñ,ùëí2
ùë¢ùëñ,...,ùëíùëôùë¢ùëñ
ùë¢ùëñ}represents
userùë¢‚Äôs review on item ùëñ.ùëíùë°
ùë¢ùëñ, drawn from the vocabulary V, is the
ùë°-th word of the review and ùëôùë¢ùëñdenotes the review length.
The objective of natural language explainable recommenda-
tion is to accurately predict the review ÀÜùíÜùë¢ùëñand rating ÀÜùëüùë¢ùëñfor a
given user-item pair (ùë¢,ùëñ)as input. To achieve this, various ap-
proaches propose to integrate these two prediction tasks into a
unified architecture with parameters ùúΩ. Specifically, review pre-
diction is performed using sequence generation model ùëîùê∏, such
as GRU [ 18,21] and Transformer [ 19]. It is optimized by max-
imizing the likelihood of the observed review through the loss
functionùêøùê∏
ùë¢,ùëñ,ùúΩ=√çùëôùë¢ùëñ
ùë°=1‚àílogùëîùê∏(ùëí=ùëíùë°
ùë¢ùëñ|ùë¢,ùëñ,ùíÜ1:(ùë°‚àí1)
ùë¢ùëñ,ùúΩ), where
ùíÜ1:(ùë°‚àí1)
ùë¢ùëñrepresents the subsequence before the ùë°-th word. The
component for rating prediction ùëîùëÖ, is optimized by minimizing
the mean square error between the real and predicted ratings as
ùêøùëÖ
ùë¢,ùëñ,ùúΩ=(ùëüùë¢ùëñ‚àíùëîùëÖ(ùë¢,ùëñ,ùúΩ))2. These two parts are combined to form
the final objective function ùêø=ùêøùê∏
ùë¢,ùëñ,ùúΩ+ùõºùêøùëÖ
ùë¢,ùëñ,ùúΩ. Existing methods
often prioritize enhancing explanation accuracy while neglecting
robustness, which can adversely affect the generalization of models.
2.2 Adversarial Training for RecSys
Adversarial training [ 2] is a powerful approach for enhancing the
robustness of models against adversarial attacks [ 3,24,26]. Given a
general classification model ùúΩand a sample(ùë•,ùë¶)from datasetD,
ùë•is the input feature and ùë¶is the corresponding label. Adversarial
training aims to minimize the maximum of training loss over the
adversarial example (ùë•+ùúπ,ùë¶), which is formulated as:
min
ùúΩmax
ùúπ,‚à•ùúπ‚à•‚â§ùúñE(ùë•,ùë¶)‚ààDùêø(ùë•+ùúπ,ùë¶;ùúΩ),(1)
4204Natural Language Explainable Recommendation
with Robustness Enhancement KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain
where ùúπrepresents the input perturbation obtained by maximizing
the loss function and ùúñcontrols the magnitude of perturbations.
Various methods have been proposed [ 14,16,23,41] to estimate the
optimal perturbation ùúπùëéùëëùë£=arg max ùúπ,‚à•ùúπ‚à•‚â§ùúñùêø(ùë•+ùúπ,ùë¶,ÀÜùúΩ), such
as the Fast Gradient Sign Method (FGSM) [ 14]. It approximates
perturbation using the gradient descent of the loss function with
respect to ùúΩasùúπùëéùëëùë£=ùúñsign(‚àáùêø(ùë•+ùúπ,ùë¶,ùúΩ)).
In the field of recommender systems, given a user-item pair (ùë¢,ùëñ),
the task of predicting user‚Äôs preference ùë¶‚àà{0,1}on the item is
a typical classification problem. It is optimized by minimizing the
negative log-likelihood of the label ùë¶using the loss function ùêø=
‚àílogùëù(ùë¶|ùë¢,ùëñ,ùúΩ). Unlike the image domain where perturbations
are directly added to input data to obtain adversarial examples, most
recommender models introduce adversarial perturbations to the
underlying model parameters due to the discrete nature of input
(e.g., user/item IDs). Thus the objective function for adversarial
training in recommender systems can be expressed as:
min
ùúΩE(ùë¢,ùëñ,ùë¶)‚ààDùêø=‚àílogùëù(ùë¶|ùë¢,ùëñ,ùúΩ)‚àíùúÜlogùëù(ùë¶|ùë¢,ùëñ,ùúΩ+ùúπùëéùëëùë£),
where ùúπùëéùëëùë£=arg max
ùúπ,‚à•ùúπ‚à•‚â§ùúñ‚àílogùëù(ùë¶|ùë¢,ùëñ, ÀÜùúΩ+ùúπ),(2)
where ÀÜùúΩrepresents the parameters of the current model. Previous
studies [ 30] are mostly based on classification problems, with rare
research on the robustness of sequence generation tasks, which is
the focus of this paper.
3 The Robust Framework
In this section, we begin by defining the objective of robustness for
natural language explainable recommendation. Then, we analyze
two crucial characteristics that contribute to the robustness of se-
quence generation. Finally, we propose a dual-policy reinforcement
learning framework to capture the mutual influence between the
above characteristics.
3.1 Objective with Robustness Enhancement
In the task of explanation generation, the labels correspond to tex-
tual sequences, which differ from the labels used in traditional
classification tasks. When obtaining adversarial perturbations, in-
stead of directly minimizing the likelihood of the target category,
we aim to minimize the sum of the likelihood of the target word
(also called token) at each position in the sentence. For the model
optimization, it is achieved by maximizing the likelihood of the
target labels across both the original data and associated adversarial
examples. The robustness objective is defined as follows:
min
ùúΩE(ùë¢,ùëñ,ùíÜùë¢ùëñ,ùëüùë¢ùëñ)‚ààDùêø=ùêøùê∏
ùë¢,ùëñ,ùúΩ+ùõºùêøùëÖ
ùë¢,ùëñ,ùúΩ+ùúÜùêøùê∏
ùë¢,ùëñ,ùúΩ+ùúπùëéùëëùë£
=‚àíùëôùë¢ùëñ‚àëÔ∏Å
ùë°=1logùëîùê∏(ùëí=ùëíùë°
ùë¢ùëñ|ùë¢,ùëñ,ùíÜ1:(ùë°‚àí1)
ùë¢ùëñ,ùúΩ)+ùõº(ùëüùë¢ùëñ‚àíùëîùëÖ(ùë¢,ùëñ,ùúΩ))2
‚àíùúÜùëôùë¢ùëñ‚àëÔ∏Å
ùë°=1logùëîùê∏(ùëí=ùëíùë°
ùë¢ùëñ|ùë¢,ùëñ,ùíÜ1:(ùë°‚àí1)
ùë¢ùëñ,ùúΩ+ùúπùëéùëëùë£),
where ùúπùëéùëëùë£=arg max
ùúπ,‚à•ùúπ‚à•‚â§ùúñ‚àíùëôùë¢ùëñ‚àëÔ∏Å
ùë°=1logùëîùê∏(ùëí=ùëíùë°
ùë¢ùëñ|ùë¢,ùëñ,ùíÜ1:(ùë°‚àí1)
ùë¢ùëñ,ÀÜùúΩ+ùúπ).(3)
The third part ùêøùê∏
ùë¢,ùëñ,ùúΩ+ùúπùëéùëëùë£represents the prediction on adversarial
examples, which can be treated as a regularizer with the weight ùúÜ.
This objective function can be easily extended to other sequencegeneration tasks. To obtain adversarial perturbation ùúπùëéùëëùë£tailored
for sequence generation, we analyze two unique characteristics:
different token importances and continuous token semantics.
3.2 Modeling Token Importance
It is apparent that different tokens play various roles in representing
the complete sentence. For example, as illustrated in Figure 2(a), in
the sentence ‚Äúthe pizza tasted like cardboard‚Äù, the words ‚Äúpizza",
‚Äútasted" and ‚Äúcardboard" play crucial roles in describing the topic and
conveying the main meaning of the sentence. On the other hand, the
words ‚Äúthe" and ‚Äúlike" hold less importance in conveying sentence
meaning, which just complete the grammatical structure. Thus the
adversarial requirements for predicting different tokens should also
be various. It is expected that tokens with higher importance will
be predicted harder. We obtain the adversarial perturbations by
assigning corresponding importance to each token, denoted as:
ùúπùëéùëëùë£=arg max
ùúπ,‚à•ùúπ‚à•‚â§ùúñ‚àíùëôùë¢ùëñ‚àëÔ∏Å
ùë°=1ùêºùë°
ùë¢ùëñ¬∑logùëîùê∏(ùëí=ùëíùë°
ùë¢ùëñ|ùë¢,ùëñ,ùíÜ1:(ùë°‚àí1)
ùë¢ùëñ,ÀÜùúΩ+ùúπ),(4)
whereùêºùë°
ùë¢ùëñis the importance weight for the token ùëíùë°
ùë¢ùëñ. Unlike tradi-
tional methods that treat each token equally, we employ weighted
token probabilities, simple yet effective considering the importance
of various tokens.
To estimate the token importance, one straightforward approach
is to leverage token frequency. We employ TF-IDF (Term Frequency-
Inverse Document Frequency) [ 28] to measure token importance.
It is calculated as:
ùêºùë°
ùë¢ùëñ=ùëÄùë°
ùëôùë¢ùëñ¬∑log|D|
ùëÅùë°+1, (5)
whereùëÄùë°represents the frequency that ùëíùë°
ùë¢ùëñappears in ùíÜùë¢ùëñ, and
ùëÅùë°=|{ùíÜ:ùëíùë°
ùë¢ùëñ‚ààùíÜ}|is the number of reviews that contain ùëíùë°
ùë¢ùëñ.
Although above method can effectively estimate importance
from token-level, it overlooks a critical aspect: the importance of
a token can vary across different sentences. As mentioned before,
the word ‚Äúlike‚Äù holds less significance as a preposition in ‚Äúthe pizza
tasted like cardboard‚Äù. However, in the sentence ‚ÄúI like the taste of
this pizza‚Äù, ‚Äúlike‚Äù is vital for expressing preference. Therefore, we
propose to estimate token importance by considering its context,
which can be achieved through cosine similarity between the target
token and the sentence representations. We use the symbol ‚Äú Àú‚Äù to
denote context-awareness and the importance is calculated as:
Àúùêºùë°
ùë¢ùëñ=ùúé(cos(vùëíùë°
ùë¢ùëñ,vùíÜùë¢ùëñ))=ùúé(vùëíùë°
ùë¢ùëñ¬∑vùíÜùë¢ùëñ
‚à•vùëíùë°
ùë¢ùëñ‚à•‚à•vùíÜùë¢ùëñ‚à•), (6)
whereùúédenotes the Sigmoid function, mapping the results into
the interval of 0 to 1. vùëíùë°
ùë¢ùëñis the representation for the token ùëíùë°
ùë¢ùëñ
and the entire sentence ùíÜùë¢ùëñis represented as vùíÜùë¢ùëñ=1
ùëôùë¢ùëñ√çùëôùë¢ùëñ
ùë°=1vùëíùë°
ùë¢ùëñ,
which takes the mean of token vectors in the sentence.
3.3 Modeling Token Semantics
Another notable characteristic is that a token can be substituted
with its synonyms to convey the same meaning. As shown in Fig-
ure 2(b), in ‚Äúthe pillow is a bit hard‚Äù, the word ‚Äúhard‚Äù can be replaced
with ‚Äúsolid‚Äù to express dissatisfaction with the pillow. Thus the sim-
ilarity of the output should be judged based on semantics, and the
4205KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain Jingsen Zhang et al.
‚ë°I likethe taste of this pizza.Importance-aware&Context-awareSemantics-aware&Context-aware‚ë¢Thepillowisabithard. ‚ë£Itishardtofindthehotelquickly.soliddifficult
‚ë†Thepizzatastedlikecardboard.(a)(b)ThePizzaTastedLikeCardboard(c)
TokenImportanceSynonymSpace
Figure 2: (a) Examples of different token importances. The
highlighted shadings identify the key tokens in each sen-
tence. (b) Examples of continuous token semantics. (c) Illus-
tration of the mutual influence between token importance
and synonym space in ‚ÄúThe pizza tasted like cardboard‚Äù.
sequences with less token-level overlap may also be highly simi-
lar. To this end, we modify the targeted perturbation and further
minimize the likelihood of the target token‚Äôs synonyms:
ùúπùëéùëëùë£=arg max
ùúπ,‚à•ùúπ‚à•‚â§ùúñ‚àíùëôùë¢ùëñ‚àëÔ∏Å
ùë°=1‚àëÔ∏Å
ùë†‚ààùëÜùë°
ùë¢ùëñlogùëîùê∏(ùëí=ùë†|ùë¢,ùëñ,ùíÜ1:(ùë°‚àí1)
ùë¢ùëñ,ÀÜùúΩ+ùúπ),(7)
whereùëÜùë°
ùë¢ùëñdenotes the set of the most approximate synonyms of
the tokenùëíùë°
ùë¢ùëñ, including the token itself.
To determine the synonym set ùëÜùë°
ùë¢ùëñ, a sample yet powerful method
is to calculate the cosine similarity between the representation of
the target token and the other tokens in the vocabulary, and then
selectùëòtokens with the highest similarity scores:
ùëÜùë°
ùë¢ùëñ={ùë†|ùë†‚ààargùëòmax
ùë†‚ààV(cos(vùëíùë°
ùë¢ùëñ,vùë†))}, (8)
where the arg max function is used to retrieve the set of ùëòtokens
that exhibit the highest similarity to the target token ùëíùë°
ùë¢ùëñ.
While this method is effective, a limitation is that it fails to
consider context, which potentially leads to inappropriate synonym
replacements. For example, in Figure 2(b), although both ‚Äúsolid‚Äù
and ‚Äúdifficult‚Äù are two synonyms of the word ‚Äúhard‚Äù, ‚Äúsolid‚Äù usually
describes the attributes of a concrete object, while ‚Äúdifficult‚Äù is more
suitable for abstract concepts such as problems or tasks. Therefore,
it is inappropriate to use ‚Äúdifficult‚Äù to describe a pillow in the first
sentence and replace the word ‚Äúhard‚Äù with ‚Äúsolid‚Äù in the second
sentence. To address this concern, we propose a context-aware
approach for synonym replacement based on the above synonym
setùëÜùë°
ùë¢ùëñ. Specifically, we substitute the target token ùëíùë°
ùë¢ùëñwith each
synonymùë†‚ààùëÜùë°
ùë¢ùëñand assess the likelihood of the resulting sentence
ùíîùë¢ùëñ={ùëí1
ùë¢ùëñ,ùëí2
ùë¢ùëñ,...,ùë†,...,ùëíùëôùë¢ùëñ
ùë¢ùëñ}. We then select the top ùëò‚Ä≤tokens (ùëò‚Ä≤‚â§
ùëò) with the highest likelihood to form the context-aware synonym
setÀúùëÜùë°
ùë¢ùëñ, which can be expressed as:
ÀúùëÜùë°
ùë¢ùëñ={ùë†|ùë†‚ààargùëò‚Ä≤
max
ùë†‚ààùëÜùë°
ùë¢ùëñ(ùëôùë¢ùëñ‚àëÔ∏Å
ùë°=1logùëîùê∏(ùëí=ùë†ùë°
ùë¢ùëñ|ùë¢,ùëñ,ùíî1:(ùë°‚àí1)
ùë¢ùëñ,ùúΩ))}, (9)
whereùë†ùë°
ùë¢ùëñis theùë°-th token in ùíîùë¢ùëñafter replacing ùëíùë°
ùë¢ùëñwithùë†.
3.4 Dual-Policy Robust Framework
The first characteristic allows us to assign different weights to
tokens within sentences, promoting a better understanding of exist-
ing data. Meanwhile, the second characteristic performs synonym
replacements on the original data, serving as data augmentation.
These two characteristics enhance the effectiveness of adversarial
learning from different perspectives, while also complementingeach other. Thus, we integrate them into the perturbation acquisi-
tion process and obtain the targeted adversarial perturbation for
sequence generation tasks as follows:
ùúπùëéùëëùë£=arg max
ùúπ,‚à•ùúπ‚à•‚â§ùúñ‚àíùëôùë¢ùëñ‚àëÔ∏Å
ùë°=1ùêºùë°
ùë¢ùëñ¬∑‚àëÔ∏Å
ùë†‚ààùëÜùë°
ùë¢ùëñlogùëîùê∏(ùëí=ùë†|ùë¢,ùëñ,ùíÜ1:(ùë°‚àí1)
ùë¢ùëñ,ÀÜùúΩ+ùúπ).
(10)
Besides, in order to consider the context information, we can trans-
formùêºùë°
ùë¢ùëñtoÀúùêºùë°
ùë¢ùëñandùëÜùë°
ùë¢ùëñtoÀúùëÜùë°
ùë¢ùëñ, respectively.
To obtain the above perturbation, we can straightforwardly inte-
grate the methods of importance estimation in Section 3.2 and syn-
onym replacement in Section 3.3. However, these methods model
the characteristics independently and direct combinations may re-
sult in suboptimal perturbations and weaken the effectiveness of
adversarial learning. Specifically, when obtaining ùêºùë°
ùë¢ùëñandùëÜùë°
ùë¢ùëñ, it is
essential to consider the mutual influence between the importance
weight and the synonym space of tokens. Intuitively, tokens with
higher importance should have a smaller synonym space compared
to those with lower importance. This consideration is because if the
synonym space is too large, the higher importance weight could
amplify the inaccuracy resulting from substituting the target token
with a less similar synonym.
As illustrated in Figure 2(c), the selection of synonyms for the im-
portant tokens such as ‚Äúpizza‚Äù and ‚Äúcardboard‚Äù should be limited to
a narrow space around them to ensure the preservation of the sen-
tence‚Äôs intended meaning. Conversely, for the less important words
like ‚Äúthe‚Äù, a broader space is allowed since their replacement have
minimal impact on the overall meaning. Therefore, effective coordi-
nation between the two characteristics is imperative for achieving
optimal perturbations. However, there are several challenges to
overcome. On the one hand, since these tasks involve sequential
decision-making, it is crucial to model the cumulative effectiveness
of decisions. On the other hand, a common optimization objective
is necessary to establish collaboration between these tasks.
To address these challenges, we propose a dual-policy reinforce-
ment learning framework, where each task is assigned to a dedi-
cated agent. The agents are optimized using maximum likelihood
estimation (MLE) with a shared reward function that evaluates the
quality of adversarial examples. We use REINFORCE method [ 38]
with policy explorations. The basic elements of the framework are
formulated as follows:
‚Ä¢Action: The estimated importance weight ùêºùë°
ùë¢ùëñand selected syn-
onyms setùëÜùë°
ùë¢ùëñfor theùë°-th tokenùëíùë°
ùë¢ùëñin the sentence.
‚Ä¢State: The state at step ùë°isùíâùë°=(ùë¢,ùëñ,ùíÜùë¢ùëñ,ùë∞1:ùë°‚àí1
ùë¢ùëñ,ùë∫1:ùë°‚àí1
ùë¢ùëñ), where
ùë∞1:ùë°‚àí1
ùë¢ùëñ={ùêº1
ùë¢ùëñ,ùêº2
ùë¢ùëñ,...,ùêºùë°‚àí1
ùë¢ùëñ}andùë∫1:ùë°‚àí1
ùë¢ùëñ={ùëÜ1
ùë¢ùëñ,ùëÜ2
ùë¢ùëñ,...,ùëÜùë°‚àí1
ùë¢ùëñ}are the
importance and synonyms for the tokens in subsequence ùíÜ1:ùë°‚àí1
ùë¢ùëñ.
We denote the outcome set as:
ùúè1:ùë°‚àí1
ùë¢ùëñ={ùë∞1:ùë°‚àí1
ùë¢ùëñ,ùë∫1:ùë°‚àí1
ùë¢ùëñ}={(ùêº1
ùë¢ùëñ,ùëÜ1
ùë¢ùëñ),(ùêº2
ùë¢ùëñ,ùëÜ2
ùë¢ùëñ),...,(ùêºùë°‚àí1
ùë¢ùëñ,ùëÜùë°‚àí1
ùë¢ùëñ)}.
‚Ä¢Agent: Two agents, denoted as ùúãùêºandùúãùëÜ, are designed with re-
spective policy networks. The role of ùúãùêºis to estimate the token im-
portance within a continuous action space ranging from 0 to 1, while
ùúãùëÜis responsible for exploring synonyms from the given vocabulary
V. More specifically, ùúãùêºis implemented as ùúãùêº=ùúé(ùëä‚Ñé[vùëíùë°
ùë¢ùëñ,vùíÜùë¢ùëñ]),
which utilizes a multi-layer fully connected neural networks with
the Sigmoid function. The inputs are the concatenation of the rep-
resentations of the target token and the sentence. ùúãùëÜcan be defined
4206Natural Language Explainable Recommendation
with Robustness Enhancement KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain
asùúãùëÜ=softmax(ùë¨¬∑vùëíùë°
ùë¢ùëñ), where ùë¨‚ààRV√óùëërepresents the embed-
ding matrix for the tokens in V, and the output layer utilizes the
softmax function to produce the token similarities.
‚Ä¢Reward: With the ùë∞ùë¢ùëñandùë∫ùë¢ùëñobtained by agents, the reward
function is comprised of two components. Firstly, to encourage
smoothness and coherence, it evaluates the likelihood of the new
sentence ùíîùë¢ùëñ={ùë†1
ùë¢ùëñ,ùë†2
ùë¢ùëñ,...,ùë†ùëôùë¢ùëñ
ùë¢ùëñ}, which is formed by replacing each
tokenùëíùë°
ùë¢ùëñin the original sentence ùíÜùë¢ùëñ={ùëí1
ùë¢ùëñ,ùëí2
ùë¢ùëñ,...,ùëíùëôùë¢ùëñ
ùë¢ùëñ}with its
synonymùë†ùë°
ùë¢ùëñ‚ààùëÜùë°
ùë¢ùëñ. Secondly, we constrain the similarity between
the new sentence and the original review to maintain consistency in
sentence meaning. The reward is calculated after the entire process
ùúè={ùë∞ùë¢ùëñ,ùë∫ùë¢ùëñ}for the review ùíÜùë¢ùëñ, which is defined as:
ùëÖ(ùúè)=ùëôùë¢ùëñ‚àëÔ∏Å
ùë°=1ùêºùë°
ùë¢ùëñ¬∑logùëîùê∏(ùëí=ùë†ùë°
ùë¢ùëñ|ùë¢,ùëñ,ùíî1:(ùë°‚àí1)
ùë¢ùëñ,ùúΩ)+ùõΩ¬∑ùëêùëúùë†(vùíîùë¢ùëñ,vùíÜùë¢ùëñ),
where vùíîùë¢ùëñ=1
ùëôùë¢ùëñ√çùëôùë¢ùëñ
ùë°=1ùêºùë°
ùë¢ùëñvùë†ùë°
ùë¢ùëñis the representation of the new sen-
tence andùõΩcontrols the degree of encouraging similarity. To ensure
the correspondence between ùúèandùíîùë¢ùëñ, in practice, we limit the
number of synonyms selected at each iteration to one, i.e.,|ùëÜùë°
ùë¢ùëñ|=1.
During the optimization process, the parameters of two agents
(ùúΩùêºandùúΩùëÜ) are updated though a reward-enhanced MLE approach.
Specifically, for ùúãùêº, we formulate its objective function as ùêøùêº(ùúΩùêº)=√ç
ùë∞ùë¢ùëñ‚àºùúãùêºùëÖ(ùúè)ùëù(ùë∞ùë¢ùëñ). According to the ‚Äúlog derivative trick‚Äù [ 31], we
obtain gradients as ‚àáùúΩùêºùêøùêº(ùúΩùêº)=√ç
ùë∞ùë¢ùëñ‚àºùúãùêºùëÖ(ùúè)ùëù(ùë∞ùë¢ùëñ)‚àáùúΩùêºlogùëù(ùë∞ùë¢ùëñ).
This expression can be further derived as:
‚àáùúΩùêºùêøùêº(ùúΩùêº)=Eùë∞ùë¢ùëñ‚àºùúãùêº
ùëÖ(ùúè)‚àáùúΩùêºlogùëù(ùë∞ùë¢ùëñ|ùë¢,ùëñ,ùíÜùë¢ùëñ)
=Eùë∞ùë¢ùëñ‚àºùúãùêºh
ùëÖ(ùúè)‚àáùúΩùêºlogùëù(ùêº1
ùë¢ùëñ,ùêº2
ùë¢ùëñ,...,ùêºùëôùë¢ùëñ
ùë¢ùëñ|ùë¢,ùëñ,ùíÜùë¢ùëñ)i
=Eùë∞ùë¢ùëñ‚àºùúãùêº"
ùëÖ(ùúè)‚àáùúΩùêºlogùëôùë¢ùëñ√ñ
ùë°=1ùúãùêº(ùêºùë°
ùë¢ùëñ|ùë¢,ùëñ,ùíÜùë¢ùëñ)#
=Eùë∞ùë¢ùëñ‚àºùúãùêº"
ùëÖ(ùúè)ùëôùë¢ùëñ‚àëÔ∏Å
ùë°=1‚àáùúΩùêºlogùúãùêº ùêºùë°
ùë¢ùëñ|ùë¢,ùëñ,ùíÜùë¢ùëñ#
.(11)
Similarly, the gradients for ùúãùëÜwith respect to ùúΩùëÜcan be derived as:
‚àáùúΩùëÜùêøùëÜ(ùúΩùëÜ)=Eùë∫ùë¢ùëñ‚àºùúãùëÜ"
ùëÖ(ùúè)ùëôùë¢ùëñ‚àëÔ∏Å
ùë°=1‚àáùúΩùëÜlogùúãùëÜ ùëÜùë°
ùë¢ùëñ|ùë¢,ùëñ,ùíÜùë¢ùëñ#
.(12)
The parameters of recommender model are optimized using sto-
chastic gradient descent (SGD), ignoring the impact of two agents.
In summary, our dual-policy approach integrates importance
estimation and synonym replacement into a unified framework
to capture the mutual influence between two characteristics. It
effectively prompts the collaboration between two auxiliary tasks
for acquiring optimal targeted perturbation. The complete learning
procedure is presented in Algorithm 1.
4 Related Work
In this section, we briefly review the prior research in the related
fields and discuss their relations with our paper.
Explainable recommendation. Recent years have witnessed
significant advancements in explainable recommendation [ 8,33,46],
where various types of explanations are provided, such as user pre-
ferred features [ 6,7,44,47] and reasoning paths on knowledge
graph [ 1,36,39]. One notable strategy is generating natural lan-
guage explanations, which are flexible and informative. SeveralAlgorithm 1: Learning Algorithm of Rober
1Indicate the iteration parameters ùê∂,ùê∂ùúã,ùê∂ùê∫.
2Indicate the learning rate ùõæ1,ùõæ2.
3Initialize the parameters of two agents ùúΩùêº,ùúΩùëÜand the
explainable recommendation model ùúΩùê∫.
4Pre-train the model ùê∫using datasetD.
5fori in [0,ùê∂]do
6 Training the agents ùúãùêºandùúãùëÜ:
7 fori in [0,ùê∂ùúã]do
8 Select a sample(ùë¢,ùëñ,ùíÜùë¢ùëñ,ùëüùë¢ùëñ)from datasetD.
9 Estimate the token importance ùë∞ùë¢ùëñusingùúãùêº.
10 Acquire the synonyms set ùë∫ùë¢ùëñusingùúãùëÜ.
11 Calculate the reward ùëÖ(ùúè), whereùúè={ùë∞ùë¢ùëñ,ùë∫ùë¢ùëñ}.
12 Update ùúΩùêºby:ùúΩùêº‚ÜêùúΩùêº+ùõæ1‚àáùúΩùêºùêøùêº(ùúΩùêº)by Eq. (11).
13 Update ùúΩùëÜby:ùúΩùëÜ‚ÜêùúΩùëÜ+ùõæ1‚àáùúΩùëÜùêøùëÜ(ùúΩùëÜ)by Eq. (12).
14 end
15 Training the explainable recommendation model ùê∫:
16 fori in [0,ùê∂ùê∫]do
17 Obtain the adversarial perturbation ùúπùëéùëëùë£by Eq. (10).
18 Calculate the final loss ùêø(ùúΩùê∫)by Eq. (3).
19 Update ùúΩùê∫by:ùúΩùê∫‚ÜêùúΩùê∫‚àíùõæ2‚àáùúΩùê∫ùêø(ùúΩùê∫).
20 end
21end
22Generate explanations using the model ùê∫in inference phase.
methods integrate explanation generation with rating prediction in
a unified architecture and produce explanations utilizing sequential
models like LSTM [ 21], GRU [ 18], and Transformer [ 19]. Addition-
ally, many studies aim to improve the quality of explanations in
various aspects, including informativeness [ 13,17], personaliza-
tion [ 4,20,42,43] and coherence [ 40]. However, these methods pri-
marily focus on improving explanation accuracy while neglecting
the robustness of the generated explanations. Our study proposes
to enhance the robustness of existing explainable recommender
models, which differs from previous works.
Adversarial training. Another relevant aspect is adversarial
training [ 2]. It is originally proposed in the field of image classifi-
cation [ 14], where models are susceptible to producing incorrect
outputs under small adversarial perturbations. Subsequently, adver-
sarial training is explored in various fields, including recommender
systems [ 10,27,37]. For example, IRGAN [ 35] utilizes Generative
Adversarial Net (GAN) to obtain effective embeddings for Matrix
Factorization. APR [ 15] investigates the robustness of personal-
ized ranking by introducing perturbations to model parameters.
Additionally, researchers explore the utilization of adversarial train-
ing in various recommendation scenarios. For instance, improving
accuracy for multimedia recommendation [ 34], cascade-guided ad-
versarial training for sequential recommendation [ 32], and univer-
sal graph perturbations for GNN-based recommendation [ 5,29].
However, these studies focus on classification problem, our study
represents the first attempt to explore the employment of adver-
sarial learning in generating natural language explanations, which
involves sequence generation. We also provides inspiration for
improving the robustness of other text generation tasks.
4207KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain Jingsen Zhang et al.
Table 1: Statistics of the datasets.
Dataset
# User # Item # Interaction Sparsity Domain
YELP
27,147 20,266 1,293,247 99.76% Restaurant
TA-HK 9,765 6,280 320,023 99.48% Hotel
AZ-MT 7,506 7,360 441,783 99.20% E-commerce
5 Experiments
5.1 Experiment Setup
Datasets. To evaluate our framework comprehensively, we con-
duct experiments based on three real-world datasets from different
domains. Yelp Challenge 2019 (YELP) records user‚Äôs ratings and
reviews for various restaurants. TripAdvisor-HongKong (TA-
HK) includes user‚Äôs interactions with different hotels in Hong
Kong, which are crawled from TripAdvisor1, a popular travel web-
site.Amazon Movies&TV (AZ-MT) is collected from the Amazon
platform and reflects user preferences on movies and TV shows.
Table 1 provides detailed statistics of these datasets.
Baselines. In this study, we implement three representative nat-
ural language explainable models: NRT [21] is a typical review
generation model based on GRU that combines review generation
with rating prediction. NETE [18] utilizes a gated fusion recurrent
unit (GFRU) to incorporate features into the decoding process for
controllable explanations. PETER [19] employs the Transformer
architecture to generate personalized explanations by bridging IDs
and words. We apply our framework to these three models and
compare the performance with their original versions. Suppose the
original model is X, we can obtain X-Rober by applying the final
dual-policy framework introduced in Section 3.4 to X. Additionally,
we denote the context-free and context-aware methods for token
importance estimation in Section 3.2 as ùë∞andÀúùë∞, and the methods
for synonym replacement in Section 3.3 as ùë∫andÀúùë∫. The symbol ‚Äú
Àú‚Äù represents considering the context information. Therefore, the
combinations of these heuristic methods result in four additional
variants: X-ùë∞-ùë∫,X-Àúùë∞-ùë∫,X-ùë∞-Àúùë∫,X-Àúùë∞-Àúùë∫.
Evaluating Metrics. To measure the quality of generated expla-
nations, we employ two distinct types of metrics. BLEU-{1,4} [ 25]
and ROUGE-{1,2} [ 22] assess text similarity by comparing n-gram
matches between the generated explanations and the ground-truths.
On the other hand, BERTScore [ 45], a prevalent metric, utilizes
pre-trained language models such as BERT to capture semantic
information and achieve a deeper understanding of context. We
use the F1 score of ROUGE by default and the F1 score, Recall, Pre-
cision of BERTScore for comprehensive evaluation. Higher values
of these metrics indicate a higher quality of explanations. While
our focus is explanation generation, we also measure the accu-
racy of rating prediction to ensure a thorough evaluation. We use
MAE =1
ùëÅ√ç
ùë¢,ùëñ|ùëüùë¢,ùëñ‚àíÀÜùëüùë¢,ùëñ|to calculate the mean absolute error
between the real ratings ùëüùë¢,ùëñand the predicted ratings ÀÜùëüùë¢,ùëñ. A lower
value of MAE signifies better performance.
Implementation details. Each dataset is randomly divided into
three sets for training, validation and testing, with a ratio of 8:1:1.
Each user/item has at least one interaction in the training set. The
vocabularyVis formed by incorporating the 20,000 most frequent
words. The maximum length of generated explanations is limited
to 15, which corresponds to the average length of reviews in the
1https://www.tripadvisor.comdatasets. For all models, the embedding size and batch size are set
to 100 and 128, respectively. The learning rates of the base mod-
els are determined according to their original paper and are set
the same for all variants. Other hyper-parameters are tuned via
grid search. Specifically, the hidden size, number of layers, per-
turbation strength ùúñand regularizer weight ùúÜare tuned within
the range of{32,64,128,256},{1,2,3,4,5},{0.1,0.5,1,5,10}and
{0.01,0.1,1,10,100}, respectively. The baselines are implemented
based on the code released in NLG4RS2, and the parameters are
configured to optimal values as reported in the original papers or
tuned within the same ranges as our framework.
5.2 Overall Performance
The comprehensive performance are detailed in Table 2. It can be ob-
served that among the base models, NETE and PETER consistently
outperform NRT on all three datasets. This is expected as NETE
incorporates specific item features as auxiliary information for gen-
erating concise descriptions, while PETER utilizes a more advanced
architecture for personalized explanation generation. The winner
between NETE and PETER varies across different datasets, while
PETER usually achieves better performance. This demonstrates the
strength of the Transformer in sequence modeling tasks.
It is encouraging that the variants of our framework generally
improve the performance of the original model for explanation
generation. The improvements in BLEU and ROUGE metrics indi-
cate an enhanced capability to fit explanation ground truths, while
the improvements in BERTScore metric demonstrate the improved
ability in text expression based on semantics. These observations
verify the effectiveness of our framework and suggest that adversar-
ial training contributes to the overall generalization of the models.
Notably, the Rober framework achieves the best performance in
most cases, and the superiority is consistent across all datasets and
metrics. This highlights the significance of modeling the mutual
influence and bridging the collaboration between importance esti-
mation and synonym replacement. The Rober accomplishes that by
assigning two tasks to individual agents that work together towards
a shared reward. Furthermore, we observe that the second-best per-
formance is mostly achieved by the variants considering contextual
information. Among them, the variant Àúùë∞-Àúùë∫performs second-best
most frequently. This observation underscores the crucial role of
contextual information in determining the importance and seman-
tics of tokens in specific sentences and emphasizes that analyzing
a token without its surrounding context is inadequate.
Although rating prediction is not the primary focus of this study,
our framework exhibits comparable or superior performance to
the original models in most cases. We also observe some instances
where our framework does not perform well. This is not surprising,
as our strategies prioritize robustness enhancement in explana-
tion generation rather than rating prediction. The introduction of
adversarial perturbations guides the model parameters towards
improving the quality and robustness of generated explanations,
which may impact the accuracy of rating prediction.
5.3 Ablation Study
In this section, we examine the impact of various components
within our framework. In addition to evaluating the performance
2https://github.com/lileipisces/NLG4RS
4208Natural Language Explainable Recommendation
with Robustness Enhancement KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain
Table 2: Overall performance of different variants of our framework applied to baselines. For each dataset, we highlight the best and the
second-best performances using bold and underlined fonts, respectively. "R" represents the ROUGE metric. " ‚Üì": a lower value indicates better
performance. Our framework‚Äôs improvements exhibit statistical significant under a paired t-test with a significance level of ùëù<0.05.
Metho
dBLEU (%) ROUGE (%) BERTScore (%)MAE (‚Üì)BLEU-1 BLEU-4 R-1 R-2 F1 Recall Precision
YELP
dataset
NRTOriginal
11.619 0.696 13.782 1.433 86.214 85.372 87.120 0.777
ùêº-ùëÜ 11.713 0.724 13.880 1.468 86.297 85.502 87.157 0.786
Àúùêº-ùëÜ 11.805 0.711
13.954 1.457 86.295 85.456 87.197 0.777
ùêº-ÀúùëÜ 11.723
0.734 13.912
1.482 86.303 85.505 87.166 0.787
Àúùêº-ÀúùëÜ 11.623 0.708 14.033 1.486 86.313 85.515 87.176
0.785
Rober 11.966 0.744 14.181 1.547 86.374 85.573 87.240 0.778
NETEOriginal
21.226 3.038 27.238 7.139 87.964 87.079 88.925 0.797
ùêº-ùëÜ 21.342
3.084 27.413 7.149 87.998 87.153 88.916 0.818
Àúùêº-ùëÜ 21.404 3.078
27.380 7.144 88.024 87.177 88.945 0.817
ùêº-ÀúùëÜ 21.328 3.106 27.491 7.229 88.023 87.159 88.960 0.814
Àúùêº-ÀúùëÜ 21.318 3.137 27.584 7.307 88.055 87.179 89.006 0.814
Rob
er 21.665 3.196 27.681 7.351 88.120 87.184 89.129 0.794
PETEROriginal
17.236 2.570 25.736 6.951 87.721 86.733 88.801 0.809
ùêº-ùëÜ 17.434 2.563 26.706 7.047 88.289 87.076 89.595 0.805
Àúùêº-ùëÜ 17.676 2.585
26.532 7.021 88.281 87.041 89.606 0.790
ùêº-ÀúùëÜ 17.673 2.641 26.715 7.315 88.158
87.022 89.382 0.815
Àúùêº-ÀúùëÜ 17.453 2.667 26.935 7.293
88.349 87.142 89.648 0.819
Rob
er 19.029 2.827 27.453 7.489 88.425 87.217 89.723 0.793
T
A-HK dataset
NRTOriginal
13.074 0.703 15.259 2.064 86.418 85.885 86.985 0.692
ùêº-ùëÜ 15.016 0.848 16.485 2.015 87.096 86.628 87.605 0.756
Àúùêº-ùëÜ 15.232 0.828 16.330 1.972 86.937 86.365 87.551 0.786
ùêº-ÀúùëÜ 14.392 0.853 17.071 2.078
86.453 86.157 86.782 0.699
Àúùêº-ÀúùëÜ 15.976 0.938 15.670
2.079 87.478 86.640 88.368 0.604
Rob
er 17.064 1.006 17.645 2.170 87.540 86.684 88.449 0.680
NETEOriginal
25.355 4.326 30.308 8.725 88.930 88.022 89.902 0.621
ùêº-ùëÜ 25.487 4.414 30.455 8.744 88.950 88.047 89.917 0.624
Àúùêº-ùëÜ 25.455
4.419 30.570 8.857 89.000 88.061 90.003 0.643
ùêº-ÀúùëÜ 25.519
4.428 30.573
8.868 88.997 88.058 90.000 0.645
Àúùêº-ÀúùëÜ 25.543 4.419
30.610 8.904 88.984
88.054 89.977 0.643
Rober 25.629 4.529 30.649 8.984 89.003 88.118 89.952 0.656
PETEROriginal
25.600 3.787 30.059 7.905 88.360 87.841 88.934 0.619
ùêº-ùëÜ 25.201
4.200 29.635 8.364 88.796
87.997 89.658 0.615
Àúùêº-ùëÜ 24.482 3.966 29.017 8.099 88.642 87.887 89.458 0.615
ùêº-ÀúùëÜ 25.320 4.199 29.184 8.335 88.798 88.036 89.620
0.629
Àúùêº-ÀúùëÜ 25.810 4.233 30.285
8.556 88.783 87.936 89.690 0.622
Rob
er 25.982 4.269 30.228 8.334 89.077
88.151 90.066 0.672
AZ-MT
dataset
NRTOriginal
12.473 0.986 14.887 2.052 85.629 85.063 86.286 0.723
ùêº-ùëÜ 12.174 1.004 15.656 2.198
85.953 85.061 86.954 0.720
Àúùêº-ùëÜ 13.146 1.014
15.535 2.161 85.873 85.085 86.751 0.684
ùêº-ÀúùëÜ 12.563 1.089 15.617
2.240 86.022 85.079 87.066 0.704
Àúùêº-ÀúùëÜ 12.687
1.055 15.249 2.158 85.728 85.090 86.466
0.727
Rober 13.382 1.120 15.771 2.266 86.051 85.210 86.979 0.702
NETEOriginal
14.485 0.963 25.481 3.759 82.490 82.535 82.520 0.713
ùêº-ùëÜ 14.647 0.978 25.755 3.900 82.536 82.551 82.598 0.725
Àúùêº-ùëÜ 14.652 0.992
25.758 3.932 82.565 82.565 82.639 0.729
ùêº-ÀúùëÜ 14.619 0.982 25.771 3.917 82.590 82.567 82.689 0.727
Àúùêº-ÀúùëÜ 14.631 1.005 25.781 3.947 82.611 82.586 82.712 0.733
Rob
er 15.000 1.068 25.991 4.063 82.731 82.679 82.861 0.741
PETEROriginal
17.176 2.416 24.306 5.979 86.946 85.855 88.151 0.737
ùêº-ùëÜ 18.458 2.483
25.519 6.131 87.000 85.982 88.132 0.699
Àúùêº-ùëÜ 17.941 2.452 24.892 6.051 87.144 86.015 88.383 0.740
ùêº-ÀúùëÜ 17.769 2.585 25.942
6.308 87.256
85.945 88.689 0.710
Àúùêº-ÀúùëÜ 18.468 2.564
25.981 5.954
87.312 85.998 88.740 0.711
Rob
er 17.628 2.735 26.553 6.815 87.537 85.876 89.327 0.725
of the original models as well as their modified versions Àúùêº-ÀúùëÜand
Rober, we also examine the performance of four individual variants:
ùêº,Àúùêº,ùëÜand ÀúùëÜ. They consider only one characteristic when acquir-
ing perturbations. From the results shown in Table 3, we observe
that when modeling only one characteristic, the performance de-
clines compared to the performance of Rober and Àúùêº-ÀúùëÜ. Moreover,
the performance of ùêºandÀúùêºis comparable to that of ùëÜand ÀúùëÜ. Theseobservations indicate the contributions of both characteristics: as-
signing different importance weights to tokens helps emphasize the
main points of the sentence, while replacements with synonyms
enhances the expressiveness of the models. Therefore, disregarding
either characteristic leads to suboptimal performance. It is note-
worthy that the context-aware method Àúùêºgenerally outperforms the
context-free method ùêº, and similarly, ÀúùëÜoutperforms ùëÜin most cases.
4209KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain Jingsen Zhang et al.
1 2 3 4 5
||||
0.00.20.40.60.8ROUGE-2YELP
NRT-Rober
NRT
1 2 3 4 5
||||
84.084.585.085.586.0BERTScore-F1YELP
NRT-Rober
NRT
1 2 3 4 5
||||
0.00.81.62.43.2ROUGE-2YELP
PETER-Rober
PETER
1 2 3 4 5
||||
65.070.976.882.788.6BERTScore-F1YELP
PETER-Rober
PETER
1 2 3 4 5
||||
0.51.01.52.02.5ROUGE-2TA-HK
NRT-Rober
NRT
1 2 3 4 5
||||
83.084.485.887.288.6BERTScore-F1TA-HK
NRT-Rober
NRT
1 2 3 4 5
||||
0.02.24.46.68.8ROUGE-2TA-HK
PETER-Rober
PETER
1 2 3 4 5
||||
76.079.583.086.590.0BERTScore-F1TA-HK
PETER-Rober
PETER
Figure 3: The impact of applying adversarial perturbations ùúπon models in the testing phase.
Table 3: Performance comparison among various variants of
our framework, with "BS" indicating "BERTScore-F1".
Metho
dYELP TA-HK AZ-MT
R-2 BS R-2 BS R-2 BS
NRTOriginal 1.433 86.214 2.064 86.418 2.052 85.629
ùêº 1.461 86.305 2.059 87.161 2.156 85.671
Àúùêº 1.470 86.268 1.975 86.574 2.138 85.707
ùëÜ 1.465 86.299 2.069 86.755 2.143 85.693
ÀúùëÜ 1.474 86.303 2.009 87.223 2.145 85.701
Àúùêº-ÀúùëÜ 1.486 86.313 2.079 87.478 2.158 85.728
Rob
er 1.547 86.374 2.170 87.540 2.266 86.051
PETEROriginal 6.951 87.721 7.905 88.360 5.979 86.946
ùêº 6.985 87.940 8.033 88.539 6.060 87.122
Àúùêº 7.109 88.030 8.058 88.698 6.102 87.136
ùëÜ 7.024 87.887 8.113 88.579 6.106 87.157
ÀúùëÜ 7.126 88.108 8.247 88.580 6.173 87.170
Àúùêº-ÀúùëÜ 7.293 88.349 8.556 88.783 5.954
87.312
Rob
er 7.489 88.425 8.334 89.077 6.815 87.537
This further underscores the significance of analyzing the impor-
tance of words and their semantics within the surrounding context.
By jointly modeling these two characteristics based on context, our
comprehensive framework achieves superior performance.
5.4 Robustness Evaluation
To further evaluate our framework‚Äôs robustness, we conduct ex-
periments to simulate the perturbations of recommender models
on testing samples and examine their performance. Specifically,
adversarial perturbations of various intensities are generated by
adjusting the values of ùúñin Equation (10) and applied to model‚Äôs pa-
rameters for evaluation. Figure 3 presents the results of the original
NRT and PETER models, as well as our Rober framework, on the
TA-HK and YELP datasets. Due to space limitations, similar results
on other models and datasets are omitted. Comparing with the
results in Table 2, we observe that minor perturbations can result
in performance decline for both original models and our frame-
work. Furthermore, as the intensity of perturbation increases, the
performance further deteriorates. These observations demonstrate
the models‚Äô vulnerability. Encouragingly, our framework exhibits a
smaller degree of decline and consistently outperforms the origi-
nal models in all cases. For instance, as the perturbation intensityincreases from 1 to 5, the BERTScore of PETER and PETER-Rober
decreases by 11.65% and 5.12% respectively on the TA-HK dataset,
and on the YELP dataset, the decreases are 23.22% and 9.62%. These
findings reveal that the original models are more vulnerable to per-
turbations compared to our framework, which effectively enhances
the robustness of natural language explainable recommendation
through its elaborate adversarial learning mechanism.
Interestingly, PETER shows a greater decline compared to NRT.
We speculate that this may be due to PETER‚Äôs more complex Trans-
former architecture, which is prone to overfitting sparse training
data from recommender systems, leading to poorer performance on
poisoned data. Moreover, the dense interactions in the Transformer
make it highly sensitive to input noise, reducing its robustness.
Therefore, despite PETER‚Äôs advanced architecture, it does not guar-
antee superiority in all scenarios. Simpler models, like NRT, may
exhibit better robustness under noisy test conditions.
5.5 Parameters Analysis
Influence of the strength of perturbation ùúñ:ùúñcontrols the
scale of adversarial perturbations. We investigate its influence and
present the results of NRT-Rober and PETER-Rober models on the
TA-HK and YELP datasets in Figure 4. We can see that the best
performance is generally achieved at a moderate ùúñ, especially for
NRT-Rober. This observation aligns with expectations, since increas-
ingùúñinitially allows for stronger perturbations, which improves the
quality of adversarial examples and leads to gradual performance
improvements. However, too large perturbations can harm the pre-
trained model parameters and degrade the performance. Notably,
both models exhibit lower sensitivity to ùúñon YELP than on TA-HK.
We speculate that the smaller size of TA-HK dataset renders models
more susceptible to noise, while the larger YELP dataset contains
a wider diversity and richness of samples, helping models capture
more features and reduce sensitivity to perturbations.
Influence of the weight of adversarial regularizer ùúÜ:ùúÜin
Equation (3) determines the importance weight given to adversarial
examples. Results in Figure 5 show that increasing ùúÜ(whenùúÜ<1)
improves both models‚Äô performance, highlighting the effectiveness
of adversarial learning. Optimal performance is achieved when ùúÜ
is set to a moderate range (e.g., 1 ‚àº10), beyond which, the perfor-
mance gradually declines. We analyze that excessive emphasis on
4210Natural Language Explainable Recommendation
with Robustness Enhancement KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain
0.1 0.5 1 5 10
1.21.51.82.12.4ROUGE-2
NRT-Rober
TA-HK
YELP
0.1 0.5 1 5 10
85.686.487.288.088.8BERTScore-F1
NRT-Rober
TA-HK
YELP
0.1 0.5 1 5 10
7.27.68.08.48.8ROUGE-2
PETER-Rober
TA-HK
YELP
0.1 0.5 1 5 10
88.188.488.789.089.3BERTScore-F1
PETER-Rober
TA-HK
YELP
Figure 4: Influence of the perturbation strength ùúñ.
0.01 0.1 1 10 100
1.21.51.82.12.4ROUGE-2
NRT-Rober
TA-HK
YELP
0.01 0.1 1 10 100
85.586.286.987.688.3BERTScore-F1
NRT-Rober
TA-HK
YELP
0.01 0.1 1 10 100
6.67.27.88.49.0ROUGE-2
PETER-Rober
TA-HK
YELP
0.01 0.1 1 10 100
88.088.488.889.289.6BERTScore-F1
PETER-Rober
TA-HK
YELP
Figure 5: Influence of the adversarial regularizer weight ùúÜ.
Table 4: Qualitative studies. We use the bold fonts to label
the key words in each sentence.
Case Method Explanation
1Gr
ound TruthThe room is very very bigand
it has a lot of modes of transportation.
PETER
The room was nice andclean and comfortable.
PETER-Rob
er The room was spacious and the bathroom was large.
2Gr
ound Truth You can‚Äôt find better for the price.
PETER
I was given a good price.
PETER-Rob
er The price is reasonable.
3Gr
ound Truth The lounge is pretty nice.
PETER
The lounge is nice and the food is good.
PETER-Rob
erThe lounge is very nice and
the staff are friendly and helpful.
adversarial examples can cause models to disregard original data,
which is the primary training objective. Moreover, for NRT-Rober,
the optimal values of ùúÜon the BERTScore metric are larger. We
speculate that BERTScore focuses on the text semantics, which is
considered through synonym replacement in our framework, thus
emphasizing adversarial examples helps improve model‚Äôs ability in
semantics understanding. Thus, careful tuning of ùúÜis necessary to
balance the original and adversarial examples.
5.6 Qualitative studies
To understand our framework intuitively, Table 4 presents exam-
ples of explanations generated by PETER and PETER-Rober on
the TA-HK dataset, alongside the ground truth explanations (i.e.,
user reviews) for reference. In the first case, PETER-Rober gener-
ates the words ‚Äúspacious‚Äù and ‚Äúlarge‚Äù that align semantically with
‚Äúbig‚Äù in the review, whereas PETER uses words ‚Äúnice‚Äù and ‚Äúclean‚Äù
to express a general meaning. This demonstrates PETER-Rober‚Äôs
ability to capture semantics and utilize specific words that reflect
the key points. In the second case, while both models understand
the positive sentiment on price, PETER-Rober‚Äôs use of ‚Äúreasonable‚Äù
more appropriately conveys the intent of ‚Äúbetter‚Äù on price com-
pared to PETER‚Äôs use of ‚Äúgood‚Äù. In the third case, PETER-Robersuccessfully substitutes ‚Äúpretty‚Äù with the synonym ‚Äúvery‚Äù, showing
a more comprehensive understanding. These examples highlight
our framework‚Äôs capacity to identify essential words and emphasize
the significance of semantics in text analysis. By considering word
semantics and conducting synonym replacements during adver-
sarial learning process, our framework can generate explanations
that convey the same meaning as ground truths but with different
expressions. Such capability is challenging for original models.
6 Conclusions and Future Work
In this paper, we propose to enhance the robustness of natural
language explainable recommendation models for the first time. To
achieve this objective, we formulate the robustness objective for
sequence generation tasks based on adversarial robust optimization
and analyze two unique characteristics. Furthermore, we build a
dual-policy reinforcement learning framework to capture the mu-
tual influence between these characteristics. Extensive experiments
show the effectiveness of our framework in improving model‚Äôs ro-
bustness and generality. There is still room for improvement, such
as designing finer methods to measure token-sequence relation-
ships. This paper provides valuable insights for the robustness in
sequence generation tasks, with potential applications in machine
translation, text summarization, and other tasks.
Acknowledgments
This work is supported in part by National Key R&D Program of
China (2023YFF0905402), National Natural Science Foundation of
China (No.62102420), Beijing Outstanding Young Scientist Program
NO.BJJWZYJH012019100020098, Intelligent Social Governance Plat-
form, Major Innovation & Planning Interdisciplinary Platform for
the ‚ÄúDoubleFirst Class‚Äù Initiative, Renmin University of China, Pub-
lic Computing Cloud, Renmin University of China, fund for building
world-class universities (disciplines) of Renmin University of China,
Intelligent Social Governance Platform, and the Outstanding In-
novative Talents Cultivation Funded Programs 2023 of Renmin
University of China. This work is sponsored by KuaiShou Technol-
ogy Programs (No.2022020091).
4211KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain Jingsen Zhang et al.
References
[1]Qingyao Ai, Vahid Azizi, Xu Chen, and Yongfeng Zhang. 2018. Learning heteroge-
neous knowledge base embeddings for explainable recommendation. Algorithms
11, 9 (2018), 137.
[2]Tao Bai, Jinqi Luo, Jun Zhao, Bihan Wen, and Qian Wang. 2021. Recent advances
in adversarial training for adversarial robustness. arXiv preprint arXiv:2102.01356
(2021).
[3]Yang Bai, Xin Yan, Yong Jiang, Shu-Tao Xia, and Yisen Wang. 2021. Clustering
effect of adversarial robust models. Advances in Neural Information Processing
Systems 34 (2021), 29590‚Äì29601.
[4]Zefeng Cai and Zerui Cai. 2022. PEVAE: A Hierarchical VAE for Personalized
Explainable Recommendation.. In Proceedings of the 45th International ACM SIGIR
Conference on Research and Development in Information Retrieval. 692‚Äì702.
[5]Huiyuan Chen, Kaixiong Zhou, Kwei-Herng Lai, Xia Hu, Fei Wang, and Hao
Yang. 2022. Adversarial graph perturbations for recommendations at scale. In
Proceedings of the 45th International ACM SIGIR Conference on Research and
Development in Information Retrieval. 1854‚Äì1858.
[6]Jingwu Chen, Fuzhen Zhuang, Xin Hong, Xiang Ao, Xing Xie, and Qing He. 2018.
Attention-driven factor model for explainable personalized recommendation.
InThe 41st International ACM SIGIR Conference on Research & Development in
Information Retrieval. 909‚Äì912.
[7]Xu Chen, Zheng Qin, Yongfeng Zhang, and Tao Xu. 2016. Learning to rank
features for recommendation over multiple categories. In Proceedings of the 39th
International ACM SIGIR conference on Research and Development in Information
Retrieval. 305‚Äì314.
[8]Xu Chen, Jingsen Zhang, Lei Wang, Quanyu Dai, Zhenhua Dong, Ruiming Tang,
Rui Zhang, Li Chen, Xin Zhao, and Ji-Rong Wen. 2024. REASONER: An Explain-
able Recommendation Dataset with Comprehensive Labeling Ground Truths.
Advances in Neural Information Processing Systems 36 (2024).
[9]Felipe Costa, Sixun Ouyang, Peter Dolog, and Aonghus Lawlor. 2018. Auto-
matic generation of natural language explanations. In Proceedings of the 23rd
international conference on intelligent user interfaces companion. 1‚Äì2.
[10] Yashar Deldjoo, Tommaso Di Noia, and Felice Antonio Merra. 2021. A survey on
adversarial recommender systems: from attack/defense strategies to generative
adversarial networks. ACM Computing Surveys (CSUR) 54, 2 (2021), 1‚Äì38.
[11] Li Dong, Shaohan Huang, Furu Wei, Mirella Lapata, Ming Zhou, and Ke Xu.
2017. Learning to generate product reviews from attributes. In Proceedings of
the 15th Conference of the European Chapter of the Association for Computational
Linguistics: Volume 1, Long Papers. 623‚Äì632.
[12] Virginie Gabrel, C√©cile Murat, and Aur√©lie Thiele. 2014. Recent advances in
robust optimization: An overview. European journal of operational research 235, 3
(2014), 471‚Äì483.
[13] Shijie Geng, Zuohui Fu, Yingqiang Ge, Lei Li, Gerard De Melo, and Yongfeng
Zhang. 2022. Improving personalized explanation generation through visualiza-
tion. In Proceedings of the 60th Annual Meeting of the Association for Computational
Linguistics (Volume 1: Long Papers). 244‚Äì255.
[14] Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. 2014. Explaining and
harnessing adversarial examples. arXiv preprint arXiv:1412.6572 (2014).
[15] Xiangnan He, Zhankui He, Xiaoyu Du, and Tat-Seng Chua. 2018. Adversarial
personalized ranking for recommendation. In The 41st International ACM SIGIR
conference on research & development in information retrieval. 355‚Äì364.
[16] Alexey Kurakin, Ian Goodfellow, and Samy Bengio. 2016. Adversarial machine
learning at scale. arXiv preprint arXiv:1611.01236 (2016).
[17] Jiacheng Li, Zhankui He, Jingbo Shang, and Julian McAuley. 2023. UCEpic:
Unifying Aspect Planning and Lexical Constraints for Generating Explanations
in Recommendation. In Proceedings of the 29th ACM SIGKDD Conference on
Knowledge Discovery and Data Mining. 1248‚Äì1257.
[18] Lei Li, Yongfeng Zhang, and Li Chen. 2020. Generate neural template explanations
for recommendation. In Proceedings of the 29th ACM International Conference on
Information & Knowledge Management. 755‚Äì764.
[19] Lei Li, Yongfeng Zhang, and Li Chen. 2021. Personalized transformer for explain-
able recommendation. arXiv preprint arXiv:2105.11601 (2021).
[20] Lei Li, Yongfeng Zhang, and Li Chen. 2023. Personalized prompt learning for
explainable recommendation. ACM Transactions on Information Systems 41, 4
(2023), 1‚Äì26.
[21] Piji Li, Zihao Wang, Zhaochun Ren, Lidong Bing, and Wai Lam. 2017. Neural
rating regression with abstractive tips generation for recommendation. In Proceed-
ings of the 40th International ACM SIGIR conference on Research and Development
in Information Retrieval. 345‚Äì354.
[22] Chin-Yew Lin. 2004. Rouge: A package for automatic evaluation of summaries.
InText summarization branches out. 74‚Äì81.
[23] Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and
Adrian Vladu. 2017. Towards deep learning models resistant to adversarial attacks.
arXiv preprint arXiv:1706.06083 (2017).
[24] Muzammal Naseer, Salman Khan, Munawar Hayat, Fahad Shahbaz Khan, and
Fatih Porikli. 2020. A self-supervised approach for adversarial robustness. In
Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition .262‚Äì271.
[25] Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002. Bleu: a
method for automatic evaluation of machine translation. In Proceedings of the
40th annual meeting of the Association for Computational Linguistics. 311‚Äì318.
[26] Lerrel Pinto, James Davidson, Rahul Sukthankar, and Abhinav Gupta. 2017. Ro-
bust adversarial reinforcement learning. In International Conference on Machine
Learning. PMLR, 2817‚Äì2826.
[27] Xuhui Ren, Hongzhi Yin, Tong Chen, Hao Wang, Nguyen Quoc Viet Hung, Zi
Huang, and Xiangliang Zhang. 2020. Crsal: Conversational recommender systems
with adversarial learning. ACM Transactions on Information Systems (TOIS) 38, 4
(2020), 1‚Äì40.
[28] Gerard Salton, Anita Wong, and Chung-Shu Yang. 1975. A vector space model
for automatic indexing. Commun. ACM 18, 11 (1975), 613‚Äì620.
[29] Lei Sang, Min Xu, Shengsheng Qian, and Xindong Wu. 2023. Adversarial Hetero-
geneous Graph Neural Network for Robust Recommendation. IEEE Transactions
on Computational Social Systems (2023).
[30] Samuel Henrique Silva and Peyman Najafirad. 2020. Opportunities and challenges
in deep learning adversarial robustness: A survey. arXiv preprint arXiv:2007.00753
(2020).
[31] David Silver, Guy Lever, Nicolas Heess, Thomas Degris, Daan Wierstra, and
Martin Riedmiller. 2014. Deterministic policy gradient algorithms. In International
conference on machine learning. Pmlr, 387‚Äì395.
[32] Juntao Tan, Shelby Heinecke, Zhiwei Liu, Yongjun Chen, Yongfeng Zhang, and
Huan Wang. 2023. Towards More Robust and Accurate Sequential Recommenda-
tion with Cascade-guided Adversarial Training. arXiv preprint arXiv:2304.05492
(2023).
[33] Juntao Tan, Shuyuan Xu, Yingqiang Ge, Yunqi Li, Xu Chen, and Yongfeng Zhang.
2021. Counterfactual explainable recommendation. In Proceedings of the 30th ACM
International Conference on Information & Knowledge Management. 1784‚Äì1793.
[34] Jinhui Tang, Xiaoyu Du, Xiangnan He, Fajie Yuan, Qi Tian, and Tat-Seng Chua.
2019. Adversarial training towards robust multimedia recommender system.
IEEE Transactions on Knowledge and Data Engineering 32, 5 (2019), 855‚Äì867.
[35] Jun Wang, Lantao Yu, Weinan Zhang, Yu Gong, Yinghui Xu, Benyou Wang, Peng
Zhang, and Dell Zhang. 2017. Irgan: A minimax game for unifying generative
and discriminative information retrieval models. In Proceedings of the 40th In-
ternational ACM SIGIR conference on Research and Development in Information
Retrieval. 515‚Äì524.
[36] Xiang Wang, Dingxian Wang, Canran Xu, Xiangnan He, Yixin Cao, and Tat-Seng
Chua. 2019. Explainable reasoning over knowledge graphs for recommendation.
InProceedings of the AAAI conference on artificial intelligence, Vol. 33. 5329‚Äì5336.
[37] Zhenlei Wang, Jingsen Zhang, Hongteng Xu, Xu Chen, Yongfeng Zhang,
Wayne Xin Zhao, and Ji-Rong Wen. 2021. Counterfactual data-augmented se-
quential recommendation. In Proceedings of the 44th international ACM SIGIR
conference on research and development in information retrieval. 347‚Äì356.
[38] Ronald J Williams. 1992. Simple statistical gradient-following algorithms for
connectionist reinforcement learning. Machine learning 8 (1992), 229‚Äì256.
[39] Yikun Xian, Zuohui Fu, Shan Muthukrishnan, Gerard De Melo, and Yongfeng
Zhang. 2019. Reinforcement knowledge graph reasoning for explainable rec-
ommendation. In Proceedings of the 42nd international ACM SIGIR conference on
research and development in information retrieval. 285‚Äì294.
[40] Aobo Yang, Nan Wang, Hongbo Deng, and Hongning Wang. 2021. Explanation
as a Defense of Recommendation. In Proceedings of the 14th ACM International
Conference on Web Search and Data Mining. 1029‚Äì1037.
[41] Hongyang Zhang, Yaodong Yu, Jiantao Jiao, Eric Xing, Laurent El Ghaoui, and
Michael Jordan. 2019. Theoretically principled trade-off between robustness and
accuracy. In International conference on machine learning. PMLR, 7472‚Äì7482.
[42] Jingsen Zhang, Xiaohe Bo, Chenxi Wang, Quanyu Dai, Zhenhua Dong, Ruiming
Tang, and Xu Chen. 2024. Active Explainable Recommendation with Limited
Labeling Budgets. In ICASSP 2024-2024 IEEE International Conference on Acoustics,
Speech and Signal Processing (ICASSP). IEEE, 5375‚Äì5379.
[43] Jingsen Zhang, Xu Chen, Jiakai Tang, Weiqi Shao, Quanyu Dai, Zhenhua Dong,
and Rui Zhang. 2023. Recommendation with Causality enhanced Natural Lan-
guage Explanations. In Proceedings of the ACM Web Conference 2023. 876‚Äì886.
[44] Jingsen Zhang, Xu Chen, and Wayne Xin Zhao. 2021. Causally attentive col-
laborative filtering. In Proceedings of the 30th ACM International Conference on
Information & Knowledge Management. 3622‚Äì3626.
[45] Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q Weinberger, and Yoav
Artzi. 2019. Bertscore: Evaluating text generation with bert. arXiv preprint
arXiv:1904.09675 (2019).
[46] Yongfeng Zhang, Xu Chen, et al .2020. Explainable recommendation: A survey
and new perspectives. Foundations and Trends¬Æ in Information Retrieval 14, 1
(2020), 1‚Äì101.
[47] Yongfeng Zhang, Guokun Lai, Min Zhang, Yi Zhang, Yiqun Liu, and Shaoping
Ma. 2014. Explicit factor models for explainable recommendation based on
phrase-level sentiment analysis. In Proceedings of the 37th international ACM
SIGIR conference on Research & development in information retrieval. 83‚Äì92.
4212