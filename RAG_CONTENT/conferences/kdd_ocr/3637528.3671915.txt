Debiased Recommendation with Noisy Feedback
Haoxuan Li
Peking University
Beijing, China
hxli@stu.pku.edu.cnChunyuan Zheng
Peking University
Beijing, China
zhengchunyuan99@gmail.comWenjie Wang
National University of Singapore
Singapore, Singapore
wenjiewang96@gmail.com
Hao Wang
Zhejiang University
Hangzhou, China
haohaow@zju.edu.cnFuli Feng
University of Science and
Technology of China
fulifeng93@gmail.comXiao-Hua Zhou∗
Peking University
Beijing, China
azhou@math.pku.edu.cn
Abstract
Ratings of a user to most items in recommender systems are usually
missing not at random (MNAR), largely because users are free to
choose which items to rate. To achieve unbiased learning of the
prediction model under MNAR data, three typical solutions have
been proposed, including error-imputation-based (EIB), inverse-
propensity-scoring (IPS), and doubly robust (DR) methods. How-
ever, these methods ignore an alternative form of bias caused by
the inconsistency between the observed ratings and the users’ true
preferences, also known as noisy feedback or outcome measure-
ment errors (OME), e.g., due to public opinion or low-quality data
collection process. In this work, we study intersectional threats to
the unbiased learning of the prediction model from data MNAR and
OME in the collected data. First, we design OME-EIB, OME-IPS, and
OME-DR estimators, which largely extend the existing estimators
to combat OME in real-world recommendation scenarios. Next, we
theoretically prove the unbiasedness and generalization bound of
the proposed estimators. We further propose an alternate denoising
training approach to achieve unbiased learning of the prediction
model under MNAR data with OME. Extensive experiments are con-
ducted on three real-world datasets and one semi-synthetic dataset
to show the effectiveness of our proposed approaches. The code is
available at https://github.com/haoxuanli-pku/KDD24-OME-DR.
CCS Concepts
•Information systems →Recommender systems.
Keywords
Bias, Debias, Noisy Feedback, Recommender Systems
ACM Reference Format:
Haoxuan Li, Chunyuan Zheng, Wenjie Wang, Hao Wang, Fuli Feng, and Xiao-
Hua Zhou. 2024. Debiased Recommendation with Noisy Feedback. In Pro-
ceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and
∗Corresponding author
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
KDD ’24, August 25–29, 2024, Barcelona, Spain.
©2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 979-8-4007-0490-1/24/08
https://doi.org/10.1145/3637528.3671915Data Mining (KDD ’24), August 25–29, 2024, Barcelona, Spain. ACM, New
York, NY, USA, 11 pages. https://doi.org/10.1145/3637528.3671915
1 Introduction
Recommender systems (RS) are designed to generate meaningful
recommendations to a collection of users for items or products
that might interest them, which have made a number of significant
advancements in recent years [ 53,72,85,88]. Nevertheless, direct
use of these advanced models in real-world scenarios while ignoring
the presence of numerous biases in the collected data can lead to
sub-optimal performance of the rating prediction model [ 6,80,81].
Among these, the problem of missing data is particularly prevalent,
as users are free to choose items to rate and the ratings with a lower
value are more likely to be missing [ 12], leading to the collected
data in RS is always missing not at random (MNAR) [ 41]. MNAR
ratings pose a serious challenge to the unbiased evaluation and
learning of the prediction model because the observed data might
not faithfully represent the entirety of user-item pairs [59, 73].
To tackle this problem, previous studies evaluate the perfor-
mance of a prediction model by computing the prediction inaccuracy :
the average of the prediction errors (e.g., the squared difference be-
tween a predicted rating and the potentially observed rating) for all
ratings [ 54,56]. To unbiasedly estimate the prediction inaccuracy
when the ratings are partially observable, three typical approaches
have been proposed, including: (1) The error-imputation-based
(EIB) approaches [ 18,65], which compute an imputed error for
each missing rating. (2) The inverse-propensity-scoring (IPS) ap-
proaches [ 58,59], which inversely weight the prediction error for
each observed rating with the probability of observing that rating.
(3) The doubly robust (DR) approaches [ 28–30,64], which use both
the error imputation model and the propensity model to estimate
the prediction inaccuracy, and the estimation is unbiased when
either the imputed errors or the learned propensities are accurate.
Despite the widespread use of these methods, they ignore an
alternative form of bias caused by the inconsistency between the
observed ratings and the users’ true preferences, also known as
noisy feedback or outcome measurement errors (OME). Similar to
selection bias, OME also arises from systematic bias during the data
collection. For example, the collected user feedback may differ from
the true user preferences due to the influence of public opinions [ 89].
Meanwhile, low-quality data collection such as recommender at-
tacks [ 16] or carelessly filling out the after-sales assessment can
also result in noisy user feedback [ 71]. Therefore, to make current
debiased recommendation techniques more applicable to real-world
 
1576
KDD ’24, August 25–29, 2024, Barcelona, Spain. Haoxuan Li, Chunyuan Zheng, Wenjie Wang, Hao Wang, Fuli Feng, and Xiao-Hua Zhou
scenarios that may contain OME, it is worthwhile to develop new
model evaluation criteria and corresponding estimators to achieve
unbiased learning under OME.
In this work, we study intersectional threats to the unbiased
learning of the prediction model introduced by data MNAR and
OME from historical interactions, where the observed ratings are
not only MNAR but may differ from the true ratings due to the
presence of OME. In such a context, a natural evaluation criterion
for the prediction models is proposed, called true prediction inac-
curacy : the average of the trueprediction errors (e.g., the squared
difference between a predicted rating and the true rating) for all
ratings. Given the collected data with OME, the true prediction
errors are difficult to obtain even for the observed ratings, making
the previous debiasing estimators severely biased in estimating the
true prediction inaccuracy and training the rating prediction model.
To combat the influence of OME on the performance of the
prediction model, many data-driven error parameter estimation
methods are developed in recent machine learning literature [ 45,60,
61,79]. Meanwhile, given knowledge of measurement error parame-
ters, recent studies propose unbiased risk minimization approaches
for learning under noisy labels [ 9,44,49,67]. Despite the prevalence
of OME in real-world recommendation scenarios, there is still only
limited work focusing on denoising in RS [ 4,38,50,82]. For exam-
ple, [ 87] proposes to overcome noisy confounders by leveraging the
sensitivity analysis in the statistics literature. By noticing that noisy
feedback typically has large loss values in the early stages, [ 71]
proposes adaptive denoising training and [ 15] proposes self-guided
denoising learning for implicit feedback. However, most of these
methods are heuristic and lack theoretical guarantees of statistical
unbiasedness for estimating the true prediction inaccuracy.
To address the above problem, we extend the widely adopted
EIB, IPS, and DR estimators to achieve unbiased estimations with
the true prediction inaccuracy under OME, named OME-EIB, OME-
IPS, and OME-DR estimators, respectively. Our methods are built
upon the existing weak separability assumption [ 42], which states
that there exist "perfectly positive" and "perfectly negative" sam-
ples among the entire user-item pairs. Specifically, we discuss the
rationality of the weak separability assumption in real-world recom-
mendation scenarios and build up the linkage between the observed
and true outcome probabilities at specific instances, from which
we are able to obtain unbiased estimations of the measurement
error parameters. We also derive explicit forms of the biases and
the generalization bounds of the proposed OME-EIB, OME-IPS, and
OME-DR estimators under inaccurately estimated measurement
error parameters, from which we prove the double robustness of the
OME-DR estimator. We further propose an alternating denoise train-
ing approach to achieve unbiased learning of the prediction model,
which corrects for data MNAR and OME in parallel. In particular,
the imputation model learns to accurately estimate the prediction
errors made by the prediction model, while the prediction model
learns from the imputation model to reduce the prediction errors in
itself. In this way, the prediction and imputation models mutually
regularize each other to reduce both prediction and imputation
inaccuracies. The effectiveness of our proposed approaches is vali-
dated on three real-world datasets and one semi-synthetic dataset
with varying MNAR levels and OME rates. To the best of our knowl-
edge, our holistic evaluation is the first to examine how OME withits measurement error parameters’ estimation in the context of
selection bias interact to affect the debiased recommendations.
The contributions of this paper are summarized as follows.
•We formulate OME caused by the inconsistency between the
observed ratings and the users’ true preferences, and establish an
evaluation criterion for the unbiased learning of the prediction
model under OME, named true prediction inaccuracy.
•We develop OME-EIB, OME-IPS, and OME-DR estimators for
unbiasedly estimating the true prediction inaccuracy of the pre-
diction model under MNAR data with OME, and theoretically
analyze the biases and generalization bounds of the estimators.
•We further propose an alternating denoise training approach to
estimate the measurement error parameters and achieve unbiased
learning of the prediction model under MNAR data with OME,
which corrects for data MNAR and OME in parallel.
•We conduct extensive experiments on three real-world datasets
and one semi-synthetic dataset, and the results demonstrate the
superiority of our methods with varying MNAR and OME rates.
2 Preliminaries
2.1 Task Formulation without OME
LetU={𝑢1,...,𝑢𝑁}be a set of users,I={𝑖1,...,𝑖𝑀}a set of
items, andD=U×I the collection of all user-item pairs. The po-
tentially observed rating matrix R∈R𝑁×𝑀comprises potentially
observed ratings 𝑟𝑢,𝑖, which represents the observed rating if user
𝑢had rated the item 𝑖. In RS, given the user-item features 𝑥𝑢,𝑖, the
prediction model 𝑓𝜃(𝑥𝑢,𝑖)parameterized by 𝜃aims to accurately
predict the ratings of all users for all items, and then recommend to
the user the items with the highest predicted ratings, as described
in [51]. The prediction matrix ˆR∈R𝑁×𝑀comprises the predicted
ratings𝑓𝜃(𝑥𝑢,𝑖)obtained from this prediction model. If the rating
matrix Rhad been fully observed, then the prediction inaccuracy P
of the prediction model can be measured using
P=P(ˆR,R)=1
|D|∑︁
(𝑢,𝑖)∈D𝑒𝑢,𝑖,
where𝑒𝑢,𝑖=ℓ(𝑓𝜃(𝑥𝑢,𝑖),𝑟𝑢,𝑖)is the prediction error, and ℓ(·,·)
is a pre-defined loss, such as the mean square error (MSE), i.e.,
𝑒𝑢,𝑖=(𝑓𝜃(𝑥𝑢,𝑖)−𝑟𝑢,𝑖)2. LetO∈{0,1}𝑁×𝑀be an indicator matrix,
where each entry 𝑜𝑢,𝑖is an observation indicator: 𝑜𝑢,𝑖=1if the rat-
ing𝑟𝑢,𝑖is observed, and 𝑜𝑢,𝑖=0if the rating 𝑟𝑢,𝑖is missing. Given
R𝑜as the set of the observed entries in the rating matrix R, the
rating prediction model aims to train the prediction model that min-
imizes the prediction inaccuracy P. Nonetheless, as users are free
to choose items to rate, leading to the collection of observational
data that is always missing not at random (MNAR) [ 12,41,83],
e.g., the ratings with a lower value are more likely to be miss-
ing. LetO=
(𝑢,𝑖)|(𝑢,𝑖)∈D,𝑜𝑢,𝑖=1	be the set of user-item
pairs for the observed ratings, the direct use of the naive estima-
torEN=EN(ˆR,R𝑜)=1
|O|Í
(𝑢,𝑖)∈O𝑒𝑢,𝑖that computes on the
observed data would yield severely biased estimation [59, 73].
2.2 Existing Estimators
To unbiasedly estimate the prediction inaccuracy Pgiven the par-
tially observed ratings R𝑜, the error-imputation-based (EIB) ap-
proaches [ 18,65] compute an imputed error ˆ𝑒𝑢,𝑖for each missing
 
1577Debiased Recommendation with Noisy Feedback KDD ’24, August 25–29, 2024, Barcelona, Spain.
rating, and estimate the prediction inaccuracy with
EEIB(ˆR,R𝑜)=1
|D|∑︁
(𝑢,𝑖)∈D(𝑜𝑢,𝑖𝑒𝑢,𝑖+(1−𝑜𝑢,𝑖)ˆ𝑒𝑢,𝑖),
which is an unbiased estimator of the prediction inaccuracy when
the imputed errors are accurate, i.e.,ˆ𝑒𝑢,𝑖=𝑒𝑢,𝑖.
The inverse-propensity-scoring (IPS) approaches [ 58,59] first
learn ˆ𝑝𝑢,𝑖as the estimate of the propensity 𝑝𝑢,𝑖=P(𝑜𝑢,𝑖=1|𝑥𝑢,𝑖),
i.e., the probability of observing the rating, then inversely weight the
prediction error for each observed rating with the learned propen-
sity, and estimate the prediction inaccuracy with
EIPS(ˆR,R𝑜)=1
|D|∑︁
(𝑢,𝑖)∈D𝑜𝑢,𝑖𝑒𝑢,𝑖
ˆ𝑝𝑢,𝑖,
which is an unbiased estimator of the prediction inaccuracy when
the learned propensities are accurate, i.e.,ˆ𝑝𝑢,𝑖=𝑝𝑢,𝑖.
The doubly robust (DR) approaches [ 24–26,73] use both the
error imputation model and the propensity model to estimate the
prediction inaccuracy with
EDR(ˆR,R𝑜)=1
|D|∑︁
(𝑢,𝑖)∈D
ˆ𝑒𝑢,𝑖+𝑜𝑢,𝑖(𝑒𝑢,𝑖−ˆ𝑒𝑢,𝑖)
ˆ𝑝𝑢,𝑖
,
which is an unbiased estimator of the prediction inaccuracy when
either the imputed errors or the learned propensities are accurate,
i.e.,ˆ𝑒𝑢,𝑖=𝑒𝑢,𝑖orˆ𝑝𝑢,𝑖=𝑝𝑢,𝑖, this is also known as double robustness.
3 Methodology
3.1 Task Formulation under OME
Despite many methods have been proposed for achieving unbi-
ased learning to tackle the data MNAR problem [ 27,56,59,70,73],
they ignore an alternative form of bias caused by the inconsis-
tency between the observed ratings and the users’ true prefer-
ences, also known as noisy feedback or outcome measurement
errors (OME). Both data MNAR and OME arise from systematic
bias during the data collection. In RS, two common scenarios that
cause incorrect user feedback signals include the influence of public
opinions [ 89], and the low-quality data collection such as recom-
mender attacks [ 16] or carelessly filling out the after-sales assess-
ments [ 71]. Formally, we denote R∗as the user’s true preference
matrix, with 𝑟∗
𝑢,𝑖as its entries, which may deviate from the poten-
tially observed ratings 𝑟𝑢,𝑖. LetP(𝑟𝑢,𝑖=0|𝑟∗
𝑢,𝑖=1)=𝜌01and
P(𝑟𝑢,𝑖=1|𝑟∗
𝑢,𝑖=0)=𝜌10be the false negative rate and false
positive rate, respectively, where 𝜌01+𝜌10<1, then we have
P(𝑟𝑢,𝑖=1|𝑥𝑢,𝑖)=(1−𝜌01)·P(𝑟∗
𝑢,𝑖=1|𝑥𝑢,𝑖)+𝜌10·P(𝑟∗
𝑢,𝑖=0|𝑥𝑢,𝑖).
To make current debiased recommendation techniques more
applicable to real-world scenarios that may contain OME, we then
establish a new model evaluation criterion for the unbiased learning
under OME, named true prediction inaccuracy, formally defined as
P∗=P(ˆR,R∗)=1
|D|∑︁
(𝑢,𝑖)∈D𝑒∗
𝑢,𝑖,
where𝑒∗
𝑢,𝑖=ℓ(𝑓𝜃(𝑥𝑢,𝑖),𝑟∗
𝑢,𝑖)is called the true prediction error.3.2 Proposed OME-EIB, OME-IPS, and OME-DR
Estimators
To achieve unbiased learning of 𝑟∗
𝑢,𝑖using MNAR data with OME, a
typical class of methods [ 36,44] propose the use of a surrogate loss
˜ℓ(𝑓𝜃(𝑥𝑢,𝑖),𝑟𝑢,𝑖)based on the observed labels 𝑟𝑢,𝑖, which satisfies
E𝑟|𝑟∗[˜ℓ(𝑓𝜃(𝑥𝑢,𝑖),𝑟𝑢,𝑖)]=ℓ(𝑓𝜃(𝑥𝑢,𝑖),𝑟∗
𝑢,𝑖).
Considering the cases 𝑟∗
𝑢,𝑖=1and𝑟∗
𝑢,𝑖=0separately, we have
(1−𝜌01)·˜ℓ(𝑓𝜃(𝑥𝑢,𝑖),1)+𝜌01·˜ℓ(𝑓𝜃(𝑥𝑢,𝑖),0)=ℓ(𝑓𝜃(𝑥𝑢,𝑖),1),
(1−𝜌10)·˜ℓ(𝑓𝜃(𝑥𝑢,𝑖),0)+𝜌10·˜ℓ(𝑓𝜃(𝑥𝑢,𝑖),1)=ℓ(𝑓𝜃(𝑥𝑢,𝑖),0).
Solving these equations for ˜ℓ(𝑓𝜃(𝑥𝑢,𝑖),1)and ˜ℓ(𝑓𝜃(𝑥𝑢,𝑖),0)gives
˜ℓ(𝑓𝜃(𝑥𝑢,𝑖),1)=(1−𝜌10)ℓ(𝑓𝜃(𝑥𝑢,𝑖),1)−𝜌01ℓ(𝑓𝜃(𝑥𝑢,𝑖),0)
1−𝜌01−𝜌10,
˜ℓ(𝑓𝜃(𝑥𝑢,𝑖),0)=(1−𝜌01)ℓ(𝑓𝜃(𝑥𝑢,𝑖),0)−𝜌10ℓ(𝑓𝜃(𝑥𝑢,𝑖),1)
1−𝜌01−𝜌10.
However, the existing surrogate loss-based methods require fully
observed noisy labels 𝑟𝑢,𝑖, which prevents the direct use of such
methods for RS in the presence of missing data. To fill this gap,
motivated by the broad usage of EIB, IPS, and DR estimators in
the missing data literature [ 2,32], we extend the above surrogate
loss-based methods to address the data MNAR and OME in parallel.
Specifically, given knowledge of error parameters 𝜌01and𝜌10, let
˜𝑒𝑢,𝑖=𝑟𝑢,𝑖·˜ℓ(𝑓𝜃(𝑥𝑢,𝑖),1)+(1−𝑟𝑢,𝑖)·˜ℓ(𝑓𝜃(𝑥𝑢,𝑖),0)be the surrogate
loss with the rating 𝑟𝑢,𝑖, the OME-EIB estimator estimates the true
prediction inaccuracy P∗=P(ˆR,R∗)with
EOME−EIB(ˆR,R𝑜;𝜌01,𝜌10)=1
|D|∑︁
(𝑢,𝑖)∈D(1−𝑜𝑢,𝑖)¯𝑒𝑢,𝑖+
1
|D|∑︁
(𝑢,𝑖)∈D𝑜𝑢,𝑖𝑟𝑢,𝑖{(1−𝜌10)ℓ(𝑓𝜃(𝑥𝑢,𝑖),1)−𝜌01ℓ(𝑓𝜃(𝑥𝑢,𝑖),0)}
1−𝜌01−𝜌10+
1
|D|∑︁
(𝑢,𝑖)∈D𝑜𝑢,𝑖(1−𝑟𝑢,𝑖){(1−𝜌01)ℓ(𝑓𝜃(𝑥𝑢,𝑖),0)−𝜌10ℓ(𝑓𝜃(𝑥𝑢,𝑖),1)}
1−𝜌01−𝜌10,
where ¯𝑒𝑢,𝑖is the imputed error for estimating ˜𝑒𝑢,𝑖, and OME-EIB is
an unbiased estimator of the true prediction inaccuracy when the
imputed errors are accurate, i.e.,¯𝑒𝑢,𝑖=˜𝑒𝑢,𝑖. Since the proof is not
trivial, we postpone to show unbiasedness of OME-EIB estimator
and the following OME-IPS and OME-DR estimators in Sec. 3.4.
Similarly, the OME-IPS estimator estimates P∗=P(ˆR,R∗)with
EOME−IPS(ˆR,R𝑜;𝜌01,𝜌10)=
1
|D|∑︁
(𝑢,𝑖)∈D𝑜𝑢,𝑖𝑟𝑢,𝑖
ˆ𝑝𝑢,𝑖·(1−𝜌10)ℓ(𝑓𝜃(𝑥𝑢,𝑖),1)−𝜌01ℓ(𝑓𝜃(𝑥𝑢,𝑖),0)
1−𝜌01−𝜌10+
1
|D|∑︁
(𝑢,𝑖)∈D𝑜𝑢,𝑖(1−𝑟𝑢,𝑖)
ˆ𝑝𝑢,𝑖·(1−𝜌01)ℓ(𝑓𝜃(𝑥𝑢,𝑖),0)−𝜌10ℓ(𝑓𝜃(𝑥𝑢,𝑖),1)
1−𝜌01−𝜌10,
where ˆ𝑝𝑢,𝑖is the learned propensity for estimating 𝑝𝑢,𝑖, and OME-
IPS is an unbiased estimator of the true prediction inaccuracy when
the learned propensities are accurate, i.e.,ˆ𝑝𝑢,𝑖=𝑝𝑢,𝑖.
The OME-DR estimator estimates P∗=P(ˆR,R∗)with
 
1578KDD ’24, August 25–29, 2024, Barcelona, Spain. Haoxuan Li, Chunyuan Zheng, Wenjie Wang, Hao Wang, Fuli Feng, and Xiao-Hua Zhou
EOME−DR(ˆR,R𝑜;𝜌01,𝜌10)=1
|D|∑︁
(𝑢,𝑖)∈D
1−𝑜𝑢,𝑖
ˆ𝑝𝑢,𝑖
¯𝑒𝑢,𝑖+
1
|D|∑︁
(𝑢,𝑖)∈D𝑜𝑢,𝑖𝑟𝑢,𝑖
ˆ𝑝𝑢,𝑖·(1−𝜌10)ℓ(𝑓𝜃(𝑥𝑢,𝑖),1)−𝜌01ℓ(𝑓𝜃(𝑥𝑢,𝑖),0)
1−𝜌01−𝜌10+
1
|D|∑︁
(𝑢,𝑖)∈D𝑜𝑢,𝑖(1−𝑟𝑢,𝑖)
ˆ𝑝𝑢,𝑖·(1−𝜌01)ℓ(𝑓𝜃(𝑥𝑢,𝑖),0)−𝜌10ℓ(𝑓𝜃(𝑥𝑢,𝑖),1)
1−𝜌01−𝜌10,
which is an unbiased estimate of the true prediction inaccuracy
when either the imputed errors or the learned propensities are
accurate, i.e.,¯𝑒𝑢,𝑖=˜𝑒𝑢,𝑖orˆ𝑝𝑢,𝑖=𝑝𝑢,𝑖.
3.3 Identification and Estimation of 𝜌01and𝜌10
The proposed OME-EIB, OME-IPS, and OME-DR estimators require
knowledge of the known error parameters 𝜌01and𝜌10, which are
usually not directly available from the collected data. By building
upon the existing weak separability assumption [ 42], we present a
data-driven identification and estimation method of 𝜌01and𝜌10.
We impose the following weak separability assumption that
inf
(𝑢,𝑖)∈DP(𝑟∗
𝑢,𝑖=1|𝑥𝑢,𝑖)=0and sup
(𝑢,𝑖)∈DP(𝑟∗
𝑢,𝑖=1|𝑥𝑢,𝑖)=1,
which also known as mutual irreducibility [ 60,61] in the observa-
tional label noise literature. This does not require the true ratings
to be separable, i.e.,P(𝑟∗
𝑢,𝑖=1|𝑥𝑢,𝑖) ∈{ 0,1}for all user-item
pairs, but instead stipulates that there exist "perfectly positive"
and "perfectly negative" samples among the entire user-item pairs.
In real-world recommendation scenarios, the weak separability
assumption is easily satisfied, providing there exists at least one
"perfectly positive" feedback and one "perfectly negative" feedback
among the thousands of collected ratings. For example, in the movie
rating scenario, "perfectly positive" feedback refers to at least one of
the users who made a positive review of the movie is fully reliable,
and we do not need to know who that user exactly is.
By noting the linkage between the observed and the true ratings
P(𝑟𝑢,𝑖=1|𝑥𝑢,𝑖)=(1−𝜌01)P(𝑟∗
𝑢,𝑖=1|𝑥𝑢,𝑖)+𝜌10P(𝑟∗
𝑢,𝑖=0|𝑥𝑢,𝑖)
=(1−𝜌01−𝜌10)P(𝑟∗
𝑢,𝑖=1|𝑥𝑢,𝑖)+𝜌10,
which demonstrates the monotonicity between P(𝑟𝑢,𝑖=1|𝑥𝑢,𝑖)
andP(𝑟∗
𝑢,𝑖=1|𝑥𝑢,𝑖)under𝜌01+𝜌10<1, we have
(𝑢<,𝑖<)=arg min
(𝑢,𝑖)∈DP(𝑟𝑢,𝑖=1|𝑥𝑢,𝑖)=arg min
(𝑢,𝑖)∈DP(𝑟∗
𝑢,𝑖=1|𝑥𝑢,𝑖),
(𝑢>,𝑖>)=arg max
(𝑢,𝑖)∈DP(𝑟𝑢,𝑖=1|𝑥𝑢,𝑖)=arg max
(𝑢,𝑖)∈DP(𝑟∗
𝑢,𝑖=1|𝑥𝑢,𝑖).
Then, we can identify the error parameters 𝜌01and𝜌10via
𝜌01=1−P(𝑟𝑢>,𝑖>=1|𝑥𝑢>,𝑖>)and𝜌10=P(𝑟𝑢<,𝑖<=1|𝑥𝑢<,𝑖<),
where P(𝑟𝑢>,𝑖>=1|𝑥𝑢>,𝑖>)andP(𝑟𝑢<,𝑖<=1|𝑥𝑢<,𝑖<)can be
unbiasedly estimated from the existing EIB, IPS, or DR estimators
for estimating P(𝑟𝑢,𝑖=1|𝑥𝑢,𝑖)without considering the OME.
3.4 Theoretical Analyses
Since the OME-DR estimator degenerates to the OME-IPS estimator
when ¯𝑒𝑢,𝑖=0, and degenerates to the OME-EIB estimator when
ˆ𝑝𝑢,𝑖=1, without loss of generality, we only analyze the explicit biasform of the OME-DR estimator. Following existing literature [ 59,
73], we assume that the indicator matrix Ocontains independent
random variables and each 𝑜𝑢,𝑖follows a Bernoulli distribution with
probability𝑝𝑢,𝑖. In addition, due to the presence of OME, we also
consider the randomness of the potentially observed ratings 𝑟𝑢,𝑖
given the true ratings 𝑟∗
𝑢,𝑖,e.g.,𝑟𝑢,𝑖=1with probability 1−𝜌01
given𝑟∗
𝑢,𝑖=1, and𝑟𝑢,𝑖=0with probability 𝜌01given𝑟∗
𝑢,𝑖=1.
Theorem 3.1 (Bias of OME-DR Estimator). Given ˆ𝜌01and ˆ𝜌10
with ˆ𝜌01+ˆ𝜌10<1, imputed errors ¯Eand learned propensities ˆPwith
ˆ𝑝𝑢,𝑖>0for all user-item pairs, the bias of the OME-DR estimator is
Bias[EOME−DR(ˆR,R𝑜;ˆ𝜌01,ˆ𝜌10)]=1
|D|∑︁
(𝑢,𝑖)∈D
1−𝑜𝑢,𝑖
ˆ𝑝𝑢,𝑖
¯𝑒𝑢,𝑖+
∑︁
(𝑢,𝑖):𝑟∗
𝑢,𝑖=1𝑝𝑢,𝑖𝜔11−ˆ𝑝𝑢,𝑖
ˆ𝑝𝑢,𝑖ℓ(𝑓𝜃(𝑥𝑢,𝑖),1)+𝑝𝑢,𝑖𝜔01
ˆ𝑝𝑢,𝑖ℓ(𝑓𝜃(𝑥𝑢,𝑖),0)
+
∑︁
(𝑢,𝑖):𝑟∗
𝑢,𝑖=0𝑝𝑢,𝑖𝜔10
ˆ𝑝𝑢,𝑖ℓ(𝑓𝜃(𝑥𝑢,𝑖),1)+𝑝𝑢,𝑖𝜔00−ˆ𝑝𝑢,𝑖
ˆ𝑝𝑢,𝑖ℓ(𝑓𝜃(𝑥𝑢,𝑖),0),
where𝜔11,𝜔01,𝜔10, and𝜔00are given by
𝜔11=1−𝜌01−ˆ𝜌10
1−ˆ𝜌01−ˆ𝜌10, 𝜔 01=𝜌01−ˆ𝜌01
1−ˆ𝜌01−ˆ𝜌10,
𝜔10=𝜌10−ˆ𝜌10
1−ˆ𝜌01−ˆ𝜌10, 𝜔 00=1−ˆ𝜌01−𝜌10
1−ˆ𝜌01−ˆ𝜌10.
The bias of the OME-DR estimator includes the three terms: (1)
The first term shares a similar form to the bias of the previous IPS
estimator and leads to smaller bias when ˆ𝑝𝑢,𝑖≈𝑝𝑢,𝑖. (2) The second
term is novel for OME, specifically focusing on the estimated false
negative rate ˆ𝜌01that corresponds to the positive samples 𝑟∗
𝑢,𝑖=1.
Moreover, we find that 𝜔11=1and𝜔01=0when the the estimated
false negative rate ˆ𝜌01is accurate, i.e.,ˆ𝜌01=𝜌01, which results in
smaller bias when ¯𝑒𝑢,𝑖≈˜𝑒𝑢,𝑖. (3) The third term is similar to the
second term, but instead focuses on the estimated false positive
rate ˆ𝜌10that corresponds to the negative samples 𝑟∗
𝑢,𝑖=0, and also
results in smaller bias when ¯𝑒𝑢,𝑖≈˜𝑒𝑢,𝑖. Given the importance of
bias derivation for constructing estimators under OME, we provide
a proof sketch as below (see Appendix A for more details).
Proof Sketch. By definition, bias of the OME-DR estimator is
Bias[EOME−DR(ˆR,R𝑜;ˆ𝜌01,ˆ𝜌10)]=ER,O[EOME−DR]−P∗.
Then, we can derive the bias of the OME-DR estimator as follows
Bias[EOME−DR(ˆR,R𝑜;ˆ𝜌01,ˆ𝜌10)]=ER|O[EO[EOME−DR]]−P∗
=1
|D|∑︁
(𝑢,𝑖):𝑟∗
𝑢,𝑖=1ER|O
1−𝑝𝑢,𝑖
ˆ𝑝𝑢,𝑖
¯𝑒𝑢,𝑖+𝑝𝑢,𝑖˜𝑒𝑢,𝑖
ˆ𝑝𝑢,𝑖
−ℓ(𝑓𝜃(𝑥𝑢,𝑖),1)
+1
|D|∑︁
(𝑢,𝑖):𝑟∗
𝑢,𝑖=0ER|O
1−𝑝𝑢,𝑖
ˆ𝑝𝑢,𝑖
¯𝑒𝑢,𝑖+𝑝𝑢,𝑖˜𝑒𝑢,𝑖
ˆ𝑝𝑢,𝑖
−ℓ(𝑓𝜃(𝑥𝑢,𝑖),0).
 
1579Debiased Recommendation with Noisy Feedback KDD ’24, August 25–29, 2024, Barcelona, Spain.
For the user-item pairs with 𝑟∗
𝑢,𝑖=1, we have
ER|O˜𝑒𝑢,𝑖
=(1−𝜌01)·˜ℓ(𝑓𝜃(𝑥𝑢,𝑖),1;ˆ𝜌01,ˆ𝜌10)+𝜌01·˜ℓ(𝑓𝜃(𝑥𝑢,𝑖),0;ˆ𝜌01,ˆ𝜌10)
=(1−𝜌01)·(1−ˆ𝜌10)ℓ(𝑓𝜃(𝑥𝑢,𝑖),1)− ˆ𝜌01ℓ(𝑓𝜃(𝑥𝑢,𝑖),0)
1−ˆ𝜌01−ˆ𝜌10
+𝜌01·(1−ˆ𝜌01)ℓ(𝑓𝜃(𝑥𝑢,𝑖),0)− ˆ𝜌10ℓ(𝑓𝜃(𝑥𝑢,𝑖),1)
1−ˆ𝜌01−ˆ𝜌10
=1−𝜌01−ˆ𝜌10
1−ˆ𝜌01−ˆ𝜌10ℓ(𝑓𝜃(𝑥𝑢,𝑖),1)+𝜌01−ˆ𝜌01
1−ˆ𝜌01−ˆ𝜌10ℓ(𝑓𝜃(𝑥𝑢,𝑖),0)
:=𝜔11ℓ(𝑓𝜃(𝑥𝑢,𝑖),1)+𝜔01ℓ(𝑓𝜃(𝑥𝑢,𝑖),0),
where𝜔11and𝜔01are given by
𝜔11=1−𝜌01−ˆ𝜌10
1−ˆ𝜌01−ˆ𝜌10, 𝜔 01=𝜌01−ˆ𝜌01
1−ˆ𝜌01−ˆ𝜌10.
Similar results hold for the user-item pairs with 𝑟∗
𝑢,𝑖=0that
ER|O˜𝑒𝑢,𝑖
=𝜌10−ˆ𝜌10
1−ˆ𝜌01−ˆ𝜌10ℓ(𝑓𝜃(𝑥𝑢,𝑖),1)+1−ˆ𝜌01−𝜌10
1−ˆ𝜌01−ˆ𝜌10ℓ(𝑓𝜃(𝑥𝑢,𝑖),0)
:=𝜔10ℓ(𝑓𝜃(𝑥𝑢,𝑖),1)+𝜔00ℓ(𝑓𝜃(𝑥𝑢,𝑖),0),
where𝜔10and𝜔00are given by
𝜔10=𝜌10−ˆ𝜌10
1−ˆ𝜌01−ˆ𝜌10, 𝜔 00=1−ˆ𝜌01−𝜌10
1−ˆ𝜌01−ˆ𝜌10.
This completes the proof. □
We formally describe double robustness under OME as follows.
Corollary 3.2 (Double Robustness). Given ˆ𝜌01=𝜌01and
ˆ𝜌10=𝜌10, the OME-DR estimator is unbiased when either imputed
errors ¯Eor learned propensities ˆPare accurate for all user-item pairs.
The above result is obtained via substituting either ¯𝑒𝑢,𝑖=˜𝑒𝑢,𝑖or
ˆ𝑝𝑢,𝑖=𝑝𝑢,𝑖into the bias of the OME-DR estimator in Theorem 3.1.
Given the estimated error parameters ˆ𝜌01and ˆ𝜌01, we obtain the
optimal prediction model under OME by minimizing the OME-DR
estimator over a hypothesis space Fof the prediction models 𝑓𝜃
ˆR‡=arg min
𝑓𝜃∈F{EOME−DR(ˆR,R𝑜;ˆ𝜌01,ˆ𝜌10)}.
We next derive the generalization bound of the optimal prediction
model in terms of the empirical Rademacher complexity [ 62]. The
basic idea of proving the performance guarantee under OME is to
exploit the inheritance of the Lipschitz continuity from the ture
prediction loss ℓ(𝑓𝜃(𝑥𝑢,𝑖),𝑟∗
𝑢,𝑖)to the surrogate loss ˜ℓ(𝑓𝜃(𝑥𝑢,𝑖),𝑟𝑢,𝑖).
Lemma 3.3 (Lipschitz Continuity). Given ˆ𝜌01and ˆ𝜌10with
ˆ𝜌01+ˆ𝜌10<1, ifℓ(𝑓𝜃(𝑥𝑢,𝑖),𝑟∗
𝑢,𝑖)is𝐿-Lipschitz in 𝑓𝜃(𝑥𝑢,𝑖)for all𝑟∗
𝑢,𝑖,
then ˜ℓ(𝑓𝜃(𝑥𝑢,𝑖),𝑟𝑢,𝑖)is2𝐿
1−ˆ𝜌01−ˆ𝜌10-Lipschitz in 𝑓𝜃(𝑥𝑢,𝑖)for all𝑟𝑢,𝑖.
The above lemma immediately leads to a generalization bound
with respect to the true ratings by using the contraction principle
for Rademacher complexity (see Appendix A for proofs).
Theorem 3.4 (Generalization Bound). Given ˆ𝜌01andˆ𝜌10with
ˆ𝜌01+ˆ𝜌10<1, supposeℓ(𝑓𝜃(𝑥𝑢,𝑖),𝑟∗
𝑢,𝑖)is𝐿-Lipschitz in 𝑓𝜃(𝑥𝑢,𝑖)for
all𝑟∗
𝑢,𝑖, and ˆ𝑝𝑢,𝑖≥𝐶𝑝,|˜ℓ(𝑓𝜃(𝑥𝑢,𝑖),𝑟𝑢,𝑖)|≤𝐶𝑙for all𝑟𝑢,𝑖, then with
probability 1−𝜂, the true prediction inaccuracy P(ˆR‡,R∗)of theAlgorithm 1: Alternating Denoise Training with OME-DR.
Input: observed ratings R𝑜, learned propensities ˆ𝑝𝑢,𝑖, initial
estimates ˆ𝜌01and ˆ𝜌10, a pre-trained model ℎ𝜃′(𝑥𝑢,𝑖)
for estimating P(𝑟𝑢,𝑖=1|𝑥𝑢,𝑖)via existing method.
1while stopping criteria is not satisfied do
2 fornumber of steps for training the denoising prediction
model do
3 Sample a batch{(𝑢𝑗,𝑖𝑗)}𝐽
𝑗=1fromD;
4 Update𝜃by descending along the gradient
∇𝜃EOME−DR(𝜃,𝜙;ˆ𝜌01,ˆ𝜌10);
5(𝑢<,𝑖<)← arg min(𝑢,𝑖)∈D𝑓𝜃(𝑥𝑢,𝑖);
6(𝑢>,𝑖>)← arg max(𝑢,𝑖)∈D𝑓𝜃(𝑥𝑢,𝑖);
7 end
8 fornumber of steps for training the denoising imputation
model do
9 ˆ𝜌01←1−ℎ𝜃′(𝑥𝑢>,𝑖>)and ˆ𝜌10←ℎ𝜃′(𝑥𝑢<,𝑖<);
10 Sample a batch{(𝑢𝑘,𝑖𝑘)}𝐾
𝑘=1fromO;
11 Update𝜙by descending along the gradient
∇𝜙L¯𝑒(𝜃,𝜙;ˆ𝜌01,ˆ𝜌10);
12 end
13end
optimal prediction matrix using the OME-DR estimator with imputed
errors ¯Eand learned propensities ˆPhas the upper bound
EOME−DR(ˆR‡,R𝑜;ˆ𝜌01,ˆ𝜌10)+Bias[EOME−DR(ˆR‡,R𝑜;ˆ𝜌01,ˆ𝜌10)]+

1+2
𝐶𝑝4𝐿
1−ˆ𝜌01−ˆ𝜌10R(F)+
𝐶𝑙+4𝐿
1−ˆ𝜌01−ˆ𝜌10√︄
2 log(4/𝜂)
|D|,
whereR(F) is the empirical Rademacher complexity defined as
R(F) =E𝜎∼{− 1,+1}|D|sup
𝑓𝜃∈F1
|D|∑︁
(𝑢,𝑖)∈D𝜎𝑢,𝑖𝑓𝜃(𝑥𝑢,𝑖),
in which𝜎={𝜎𝑢,𝑖:(𝑢,𝑖)∈D} , and𝜎𝑢,𝑖are independent uniform
random variables taking values in {−1,+1}. The random variables
𝜎𝑢,𝑖are called Rademacher variables.
3.5 Alternating Denoise Training Approach
We further propose an alternating denoise training approach to
achieve unbiased learning of the prediction model, which corrects
for data MNAR and OME in parallel. Specifically, we first train a
propensity model using the observed MNAR data. Based on the
estimated propensities, the denoising prediction and imputation
models are alternately updated, which also facilitates the accurate
estimations ˆ𝜌01and ˆ𝜌10of the error parameters 𝜌01and𝜌10.
Propensity Estimation via Logistic Regression. Since unbiased
ratings are difficult to be collected in the real-world scenarios [ 57],
following previous studies [ 23,59], we adopt logistic regression
to train a propensity model ˆ𝑝𝑢,𝑖=𝜎(𝑤⊤𝑥𝑢,𝑖+𝛽𝑢+𝛾𝑖)parameter-
ized by𝜓=(𝑤,𝛽 1,...,𝛽𝑁,𝛾1,...,𝛾𝑀)using the observed MNAR
data, where 𝜎(·)is the sigmoid function, 𝑤∈R𝑁+𝑀is the weight
 
1580KDD ’24, August 25–29, 2024, Barcelona, Spain. Haoxuan Li, Chunyuan Zheng, Wenjie Wang, Hao Wang, Fuli Feng, and Xiao-Hua Zhou
Table 1: RE on ML-100K dataset with 𝜌01= 0.2 and𝜌10= 0.1. The best two results are bolded and the best baseline is underlined.
RO
TATE SKEW CRS ONE THREE FIVE
Naiv
e [20] 0.125±0.002
0.179±0.001 0.175±0.002 0.241±0.002 0.264±0.003 0.299±0.003
OME ( ˆ𝜌01,ˆ𝜌10) 0.087±0.006
0.163±0.002 0.104±0.014 0.161±0.013 0.179±0.014 0.213±0.014
OME (𝜌01,𝜌10) 0.024±0.003 0.136±0.002
0.105±0.004 0.067±0.004 0.076±0.004 0.100±0.004
MRDR
[17] 0.098±0.003
0.089±0.001 0.099±0.002 0.172±0.004
0.190±0.004 0.194±0.004
SDR [29] 0.097±0.002
0.089±0.001 0.102±0.002 0.172±0.003 0.191±0.003 0.194±0.003
TDR [23] 0.092±0.002
0.080±0.001 0.103±0.002
0.171±0.003 0.189±0.003 0.195±0.003
EIB
[65] 0.366±0.001
0.256±0.001 0.150±0.001 0.562±0.001 0.605±0.001 0.635±0.001
OME-EIB ( ˆ𝜌01,ˆ𝜌10) 0.362±0.001
0.255±0.001 0.144±0.001 0.554±0.001 0.598±0.001 0.627±0.001
OME-EIB (𝜌01,𝜌10) 0.357±0.001
0.253±0.001 0.144±0.001 0.546±0.001 0.589±0.001 0.618±0.001
IPS
[59] 0.110±0.002
0.116±0.002 0.134±0.003 0.212±0.004 0.231±0.004 0.254±0.004
OME-IPS ( ˆ𝜌01,ˆ𝜌10) 0.060±0.003
0.096±0.002 0.075±0.017 0.111±0.006 0.125±0.007 0.144±0.007
OME-IPS (𝜌01,𝜌10)0.013±0.003∗0.068±0.003∗0.052±0.004∗0.034±0.005∗0.038±0.006∗0.050±0.005∗
DR
[56] 0.106±0.002
0.087±0.001 0.104±0.002 0.190±0.003 0.209±0.003 0.216±0.003
OME-DR ( ˆ𝜌01,ˆ𝜌10) 0.056±0.004
0.067±0.001 0.045±0.018 0.090±0.006 0.102±0.006 0.106±0.007
OME-DR (𝜌01,𝜌10) 0.009±0.003∗0.039±0.002∗0.022±0.003∗0.013±0.004∗0.016±0.005∗0.012±0.004∗
Note: * means statistically significant results (p-value ≤0.05) using the paired-t-test compared with the best baseline.
vector,𝛽𝑢and𝛾𝑖are the user-specific and item-specific constants,
respectively. We train the propensity model by minimizing the loss
L𝑝(𝜓)=−1
|D|∑︁
(𝑢,𝑖)∈D𝑜𝑢,𝑖log(ˆ𝑝𝑢,𝑖)+(1−𝑜𝑢,𝑖)log(1−ˆ𝑝𝑢,𝑖).
Denoising Prediction Model Training. Based on the learned
propensities ˆ𝑝𝑢,𝑖, imputed errors ¯𝑒𝑢,𝑖(𝜙), and initial estimates ˆ𝜌01
and ˆ𝜌10, we train the denoising prediction model by minimizing
the estimated true prediction inaccuracy from the proposed OME-
DR estimatorEOME−DR(𝜃,𝜙;ˆ𝜌01,ˆ𝜌10). To obtain more accurate
estimates ˆ𝜌01and ˆ𝜌10from the training loop, we then compute the
minimum and maximum predicted ratings in the training batch
to update(𝑢<,𝑖<)and(𝑢>,𝑖>), respectively. The choice not to
employ a separate noisy rating prediction model for computing
(𝑢<,𝑖<)and(𝑢>,𝑖>)is guaranteed by the monotonicity between
P(𝑟𝑢,𝑖=1|𝑥𝑢,𝑖)andP(𝑟∗
𝑢,𝑖=1|𝑥𝑢,𝑖)(see Sec. 3.3 for proofs),
where the latter has a larger gap between the minimum and the
maximum, making it easier to distinguish (𝑢<,𝑖<)and(𝑢>,𝑖>).
Denoising Imputation Model Training. Given a pre-trained
modelℎ𝜃′(𝑥𝑢,𝑖)for estimating P(𝑟𝑢,𝑖=1|𝑥𝑢,𝑖)via existing meth-
ods [ 59,73], we update the estimates ˆ𝜌01and ˆ𝜌10by computing
1−ℎ𝜃′(𝑥𝑢>,𝑖>)andℎ𝜃′(𝑥𝑢<,𝑖<), respectively. We finally train the
denoising imputation model ¯𝑒𝑢,𝑖(𝜙)by minimizing the loss
L¯𝑒(𝜃,𝜙;ˆ𝜌01,ˆ𝜌10)=1
|D|∑︁
(𝑢,𝑖)∈D𝑜𝑢,𝑖(˜𝑒𝑢,𝑖−¯𝑒𝑢,𝑖)2
ˆ𝑝𝑢,𝑖.
The overall training process with OME-DR is summarized in Alg. 1.
4 Semi-Synthetic Experiments
To investigate if the proposed estimators are able to estimate the
true prediction inaccuracy accurately in the presence of OME and
MNAR effect, several semi-synthetic experiments are conducted on
a widely-used dataset MovieLens-100K (ML-100K). We first adopt
MF to complete the five-scaled rating matrix R. However, the com-
pleted matrix will have an unrealistic rating distribution, thus wesort the matrix entries in ascending order and assign a positive feed-
back probability of 0.1 for the lowest 𝑝1proportion, a positive feed-
back probability of 0.3 for the next 𝑝2proportion, and so on to obtain
a true positive feedback probability 𝛾𝑢,𝑖for each user-item pair. The
adjusted probability matrix contains 𝛾𝑢,𝑖∈{0.1,0.3,0.5,0.7,0.9}
with proportion[𝑝1,𝑝2,𝑝3,𝑝4,𝑝5], respectively.
Second, following the previous studies [ 17,59,73], we use six
matrices below as the prediction matrix ˆR:
•ROTATE: Set predicted ˆ𝑟𝑢,𝑖=𝛾𝑢,𝑖−0.2when𝛾𝑢,𝑖≥0.3, and
ˆ𝑟𝑢,𝑖=0.9when𝛾𝑢,𝑖=0.1.
•SKEW: Predicted ˆ𝑟𝑢,𝑖are sampled from the Gaussian distribution
N(𝜇=𝛾𝑢,𝑖,𝜎=(1−𝛾𝑢,𝑖)/2), and clipped to the interval [0.1,0.9].
•CRS: If the true 𝛾𝑢,𝑖≤0.6, then ˆ𝑟𝑢,𝑖=0.2. Otherwise, ˆ𝑟𝑢,𝑖=0.6.
•ONE: The predicted matrix ˆRis identical to the true positive
feedback probability matrix, except that randomly select 𝛾𝑢,𝑖=0.1
with total amount|{(𝑢,𝑖)|𝛾𝑢,𝑖=0.9}|are flipped to 0.9.
•THREE: Same as ONE, but flipping 𝛾𝑢,𝑖=0.3instead.
•FIVE: Same as ONE, but flipping 𝛾𝑢,𝑖=0.5instead.
Next, we assign the propensity 𝑝𝑢,𝑖=𝑝𝛼min(4,6−𝑟𝑢,𝑖)for each
user-item pair and obtain the estimate propensities
1
ˆ𝑝𝑢,𝑖=1−𝛽
𝑝𝑢,𝑖+𝛽
𝑝𝑒,
where𝑝𝑒=|D|−1Í
(𝑢,𝑖)∈D𝑜𝑢,𝑖,𝑝is set to 1 in our experiment
and𝛽is randomly sampled from a uniform distribution 𝑈(0,1)to
introduce noises. Then, we sample the binary true feedback matrix
R∗and binary observation matrix Oas follows:
𝑜𝑢,𝑖∼Bern(𝑝𝑢,𝑖),∀(𝑢,𝑖)∈D, 𝑟∗
𝑢,𝑖∼Bern(𝛾𝑢,𝑖),∀(𝑢,𝑖)∈D,
where Bern(·)denotes the Bernoulli distribution. Then we flip the
feedback matrix according to the 𝜌01and𝜌10to generate a binary
noise feedback matrix R. The absolute relative error (RE) is used for
evaluation, which is defined as RE(E𝑒𝑠𝑡)=|P∗−E𝑒𝑠𝑡(ˆR,R)|/P∗,
whereE𝑒𝑠𝑡denotes the estimate prediction inaccuracy. The smaller
the RE, the more accurate the estimation. In addition, we provide
both results for using estimated ˆ𝜌01and ˆ𝜌10to estimateP∗and
directly using true 𝜌01and𝜌10to estimateP∗.
 
1581Debiased Recommendation with Noisy Feedback KDD ’24, August 25–29, 2024, Barcelona, Spain.
(
a) Estimation error of ˆ𝜌01and ˆ𝜌10
 (
b) RE on EIB-based methods
 (
c) RE on IPS-based methods
 (
d) RE on DR-based methods
Figur
e 1: Estimation errors of ˆ𝜌01and ˆ𝜌10and RE with varying observed data ratios.
Table 2: Performance on AUC, NDCG@K, and Recall@K on the MAR test set of Coat, Music andKuaiRec with𝜌01= 0.2 and
𝜌10= 0.1. The best three results are bolded, and the best baseline is underlined.
Co
at Music K
uaiRec
Metho
d AUC
NDCG@5 Recall@5 AUC
NDCG@5 Recall@5 AUC
NDCG@50 Recall@50
MF
[20] 0.619±0.002 0.531±0.005 0.364±0.005 0.632±0.005 0.616±0.003 0.361±0.001 0.621±0.002 0.652±0.003 0.702±0.002
OME
[36] 0.621±0.003 0.543±0.006 0.371±0.007 0.650±0.005 0.615±0.004 0.373±0.004 0.645±0.002 0.660±0.002 0.722±0.002
T
-MF [71] 0.633±0.004 0.540±0.005 0.372±0.006 0.650±0.005 0.614±0.003 0.376±0.004 0.657±0.002 0.665±0.002 0.739±0.003
R-MF
[71] 0.641±0.004 0.544±0.005 0.376±0.009 0.657±0.005 0.614±0.006 0.371±0.004 0.645±0.002 0.661±0.001 0.720±0.003
LCD-MF
[11] 0.631±0.003 0.552±0.0070.381±0.006 0.659±0.005 0.617±0.005 0.374±0.004 0.664±0.003 0.677±0.003 0.738±0.003
EIB
[65] 0.621±0.003 0.547±0.006 0.368±0.008 0.648±0.003 0.620±0.002 0.371±0.002 0.641±0.001 0.653±0.001 0.713±0.002
IPS
[59] 0.625±0.002 0.534±0.009 0.360±0.008 0.648±0.001 0.615±0.001 0.369±0.001 0.636±0.001 0.642±0.002 0.714±0.001
SNIPS
[59] 0.631±0.004 0.544±0.008 0.369±0.007 0.659±0.005 0.617±0.005 0.375±0.004 0.657±0.002 0.670±0.001 0.735±0.001
CVIB
[75] 0.626±0.001 0.552±0.009 0.379±0.004 0.661±0.001 0.612±0.002 0.381±0.001 0.653±0.001 0.644±0.001 0.736±0.001
D
AMF [57] 0.631±0.004 0.548±0.006 0.367±0.006 0.640±0.0030.627±0.002 0.377±0.004 0.657±0.003 0.669±0.003 0.735±0.004
DR
[56] 0.633±0.009 0.548±0.015 0.360±0.011 0.654±0.009 0.613±0.007 0.372±0.005 0.643±0.002 0.650±0.001 0.721±0.001
DR-JL
[73] 0.633±0.005 0.546±0.006 0.366±0.007 0.650±0.002 0.617±0.001 0.382±0.001 0.644±0.001 0.669±0.002 0.725±0.002
MRDR-JL
[17] 0.634±0.005 0.538±0.010 0.373±0.008 0.659±0.002 0.624±0.007 0.376±0.006 0.658±0.003 0.670±0.002 0.741±0.003
DR-BIAS
[10] 0.632±0.004 0.549±0.009 0.369±0.008 0.660±0.001 0.619±0.003 0.378±0.0020.665±0.0040.679±0.004 0.737±0.002
DR-MSE
[10] 0.631±0.0030.557±0.008 0.374±0.008 0.662±0.002 0.623±0.004 0.374±0.002 0.653±0.002 0.660±0.002 0.732±0.002
DIB
[35] 0.626±0.003 0.550±0.009 0.376±0.006 0.647±0.0050.626±0.005 0.382±0.006 0.641±0.002 0.642±0.003 0.738±0.003
MR
[22] 0.630±0.005 0.546±0.009 0.376±0.007 0.656±0.005 0.623±0.004 0.380±0.004 0.637±0.002 0.644±0.004 0.723±0.002
SDR
[29] 0.635±0.005 0.543±0.005 0.368±0.006 0.660±0.006 0.618±0.006 0.376±0.005 0.661±0.003 0.675±0.001 0.739±0.002
TDR
[23] 0.638±0.007 0.556±0.014 0.370±0.013 0.657±0.004 0.616±0.002 0.371±0.003 0.650±0.002 0.670±0.001 0.723±0.003
IPS-
V2 [26] 0.631±0.005 0.549±0.008 0.373±0.008 0.648±0.005 0.615±0.005 0.373±0.004 0.658±0.002 0.675±0.003 0.734±0.002
DR-
V2 [26] 0.631±0.005 0.553±0.009 0.378±0.006 0.636±0.003 0.620±0.0020.392±0.004 0.658±0.001 0.671±0.001 0.734±0.002
OME-EIB
(ours) 0.627±0.0020.563∗
±0.0020.387∗
±0.0020.664±0.003 0.622±0.004 0.384±0.0050.667±0.0030.682∗
±0.0020.742±0.002
OME-IPS
(ours) 0.636±0.002 0.548±0.003 0.373±0.0040.664±0.003 0.625±0.0020.385±0.0020.671∗
±0.0020.693∗
±0.0040.763∗
±0.002
OME-DR
(ours) 0.651∗
±0.0060.561±0.0060.385∗
±0.0050.671∗
±0.0030.632∗
±0.0030.389±0.002 0.662±0.002 0.677±0.0040.743±0.002
Note: * means statistically significant results (p-value ≤0.05) using the paired-t-test compared with the best baseline.
Performance Comparison. We compare the proposed methods
with the Naive method [ 20], the EIB method [ 65], the IPS method [ 59],
and the DR-based methods [ 17,23,29,73]. The RE results are shown
in Table 1 with 𝜌01=0.2and𝜌10=0.1. First, most debiasing and
denoising methods have lower RE than the Naive method. In addi-
tion, our proposed methods stably and significantly outperform the
corresponding debiasing baseline methods. Meanwhile, the OME
methods are only able to denoising, thus they still have a large RE,
even the true 𝜌is used for estimation. This shows the effectiveness
of our method in the presence of both the OME and MNAR effects.
In Depth Analysis. We explore the effect of the proportion of
observed data on the estimation accuracy of ˆ𝜌01and ˆ𝜌10, and the
results when 𝜌01=0.2and𝜌10=0.1are shown in Figure 1. We take
ROTATE as an example, and the same phenomenon is observed forthe other five prediction matrices. First, our methods stably outper-
form the baseline methods in all scenarios. Second, the estimation
error decreases significantly as the proportion of observed data
increases. Moreover, even with the estimation error, our estimation
results are only slightly worse than using the real 𝜌. This further
validates the stability and practicality of our methods.
5 Real-World Experiments
Datasets and Experiment Details. We verify the effectiveness of
our methods on three real-world datasets: Coat [59],Music [59]
andKuaiRec [14].Coat includes 6,960 MNAR ratings and 4,640
missing-at-random (MAR) ratings from 290 users to 300 items. Mu-
sichas 311,704 MNAR ratings and 54,000 MAR ratings of 15,400
users to 1,000 items. For Coat andMusic, we binarize the ratings
 
1582KDD ’24, August 25–29, 2024, Barcelona, Spain. Haoxuan Li, Chunyuan Zheng, Wenjie Wang, Hao Wang, Fuli Feng, and Xiao-Hua Zhou
less than three to 0 and otherwise to 1. KuaiRec is a fully exposed
large-scale industrial dataset, which has 4,676,570 video watch-
ing ratio records from 1,411 users to 3,327 items. We binarize the
records less than one to 0 and otherwise to 1. We adopt three com-
mon metrics, i.e., AUC, NDCG@K, and Recall@K for performance
evaluation. For Coat andMusic, K is set to 5. For KuaiRec, K is
set to 50. All the experiments are implemented on PyTorch with
Adam as the optimizer. For all experiments, we use GeForce RTX
3090 as the computing resource. Logistic regression is used as the
propensity model for all the methods requiring propensity. The
learning rate is tuned in {0.001,0.005,0.01,0.05}and the batch size
is tuned in{64,128,256}forCoat and{2048,4096,8192}forMusic
andKuaiRec. We tune the embedding dimension in {4,8,16,32}
forCoat and{8,16,32,64}forMusic andKuaiRec. Moreover, we
tune the weight decay rate in [1𝑒−6,5𝑒−3].
Baselines. We use matrix factorization (MF) [ 20] as the base model
and compare our methods to the following debiasing methods:
EIB [ 65], IPS [ 59], SNIPS [ 59], CVIB [ 75], DAMF [ 57], DR [ 56],
DR-JL [ 73], MRDR-JL [ 17], DR-BIAS [ 10], DR-MSE [ 10], DIB [ 35],
MR [ 22], SDR [ 29], TDR [ 23], IPS-V2 [ 26] and DR-V2 [ 26]. We also
compare denoising methods including surrogate loss minimization
(OME) [36], T-MF [71], R-MF [71], and LCD-MF [11].
Performance Comparision. Table 2 shows the prediction perfor-
mance with varying baselines and our methods. First, most of the
debiasing and denoising methods have better performance com-
pared to the Naive method, which shows the necessity of debiasing
and denoising. Meanwhile, our methods exhibit the most competi-
tive performance in all three datasets, significantly outperforming
the baselines including debiasing methods and denoising methods.
6 Related Work
6.1 Debiased Recommendation
The data collected in recommender systems are often systematically
subject to varying types of bias, such as conformity bias [ 37], item
popularity bias [ 77,86], latent confounders [ 13,25], and position
bias [ 46,47]. In order to achieve unbiased learning of the predic-
tion model, three typical approaches have been proposed, includ-
ing: (1) The error-imputation-based (EIB) approaches [ 18,55,65],
which compute an imputed error for each missing rating. (2) The
inverse-propensity-scoring (IPS) approaches [ 54,58,59,66], which
inversely weight the prediction error for each observed rating with
the probability of observing that rating. (3) The doubly robust (DR)
approaches [ 21,56,73], which use both the error imputation model
and the propensity model, and the unbiased learning of the pre-
diction model can be achieved when either the error imputation
model or the propensity model is accurate. Based on the above
EIB, IPS, and DR estimators, in terms of learning paradigms, recent
studies have investigated flexible trade-offs between bias and vari-
ance [ 10,17], parameter sharing in multi-task learning [ 40,69,84],
and the use of a few unbiased ratings to improve the estimation of
the prediction inaccuracy [ 3,5,31,33,34,74]. In terms of statisti-
cal theory, recent studies have developed targeted DR (TDR) [ 23]
and conservative DR (CDR) [ 64] to combat the inaccurate imputed
errors, StableDR [ 29] to combat sparse data, and new propensity
estimation methods based on balancing metrics [ 26,39,80]. In
addition, [ 57] proposes to minimize the propensity-independentgeneralization error bound via adversarial learning. [ 22] extends DR
to multiple robust learning. These methods have also been applied
to sequential recommendation [ 76] and social recommendation [ 7].
Furthermore, methods based on information bottlenecks [ 35,75]
and representation learning [ 48,80] have also been proposed for
debiased recommendation. In this work, we extend the previous
debiasing methods to a more realistic RS scenario, in which the
observed ratings and the users’ true preferences may be different.
6.2 Outcome Measurement Error
Outcome measurement error (OME) refers to the inconsistency
between the observed outcomes and the true outcomes, also known
as noisy outcomes in social science [ 52], biostatistics [ 19], and
psychometrics [ 63]. The error models or transition matrices in
OME establish the relation between the true outcomes and the
observed outcomes, including uniform [ 1,68], class-conditional
[36,42,61], and instance-dependent [ 8,78] structures of outcome
misclassification. Many data-driven error parameter estimation
methods are developed in recent machine learning literature [ 45,
60,61,79]. Meanwhile, given knowledge of measurement error
parameters, recent studies propose unbiased risk minimization
approaches for learning under noisy labels [9, 44, 49, 67].
Despite the prevalence of OME in real-world recommendation
scenarios, there is still only limited work focusing on denoising in
RS [4,82,87]. Recently, by noticing that noisy feedback typically
has large loss values in the early stages, [ 71] proposes adaptive
denoising training and [ 15] proposes self-guided denoising learning
in implicit feedback. However, the existing methods are mostly
heuristic and require the fully observed noisy labels, which prevents
the direct use of such methods for RS in the presence of missing
data. To fill this gap, we extend the surrogate loss-based methods
to address the data MNAR and OME in parallel.
7 Conclusion
In this study, we explored the challenges characterized MNAR data
with noisy feedback encountered in real-world recommendation
scenarios. First, we introduced the concept of true prediction inaccu-
racy as a more comprehensive evaluation criterion that accounts for
OME, and proposed OME-EIB, OME-IPS, and OME-DR estimators
to provide unbiased estimations of the true prediction inaccuracy.
Next, we derived the explicit forms of the biases and the general-
ization bounds of the proposed estimators, and proved the double
robustness of our OME-DR estimator. We further proposed an al-
ternating denoise training approach that corrects for MNAR data
with OME. The effectiveness of our methods was validated on both
semi-synthetic and real-world datasets with varying MNAR and
OME rates. The potential limitations includes the usage of weak sep-
arability assumption, and accurate measurement error parameters’
estimation for ensuring unbiasedness. In future research, we aim
to develop unbiased learning methods applicable to more complex
OME forms, study alternative practical assumptions for identifying
and estimating the error parameters, and extend the applicability
of the proposed methods to a wider range of RS settings.
Acknowledgements
This work was supported in part by National Natural Science Foun-
dation of China (623B2002, 62272437).
 
1583Debiased Recommendation with Noisy Feedback KDD ’24, August 25–29, 2024, Barcelona, Spain.
References
[1]Dana Angluin and Philip Laird. 1988. Learning from noisy examples. Machine
learning (1988), 343–370.
[2]Heejung Bang and James M Robins. 2005. Doubly robust estimation in missing
data and causal inference models. Biometrics (2005), 962–973.
[3]Stephen Bonner and Flavian Vasile. 2018. Causal embeddings for recommendation.
InRecSys.
[4]Huiyuan Chen, Yusan Lin, Menghai Pan, Lan Wang, Chin-Chia Michael Yeh,
Xiaoting Li, Yan Zheng, Fei Wang, and Hao Yang. 2022. Denoising self-attentive
sequential recommendation. In RecSys.
[5]Jiawei Chen, Hande Dong, Yang Qiu, Xiangnan He, Xin Xin, Liang Chen, Guli Lin,
and Keping Yang. 2021. AutoDebias: Learning to Debias for Recommendation. In
SIGIR.
[6]Jiawei Chen, Hande Dong, Xiang Wang, Fuli Feng, Meng Wang, and Xiangnan
He. 2023. Bias and debias in recommender system: A survey and future directions.
ACM Transactions on Information Systems (2023), 1–39.
[7]Jiawei Chen, Can Wang, Martin Ester, Qihao Shi, Yan Feng, and Chun Chen. 2018.
Social recommendation with missing not at random data. In ICDM.
[8]Pengfei Chen, Junjie Ye, Guangyong Chen, Jingwei Zhao, and Pheng-Ann Heng.
2021. Beyond class-conditional assumption: A primary attempt to combat
instance-dependent label noise. In AAAI.
[9]Yu-Ting Chou, Gang Niu, Hsuan-Tien Lin, and Masashi Sugiyama. 2020. Unbiased
risk estimators can mislead: A case study of learning with complementary labels.
InICML.
[10] Quanyu Dai, Haoxuan Li, Peng Wu, Zhenhua Dong, Xiao-Hua Zhou, Rui Zhang,
Xiuqiang He, Rui Zhang, and Jie Sun. 2022. A Generalized Doubly Robust Learning
Framework for Debiasing Post-Click Conversion Rate Prediction. In KDD.
[11] Quanyu Dai, Yalei Lv, Jieming Zhu, Junjie Ye, Zhenhua Dong, Rui Zhang, Shu-Tao
Xia, and Ruiming Tang. 2022. LCD: Adaptive label correction for denoising music
recommendation. In CIKM.
[12] Arnaud De Myttenaere, Bénédicte Le Grand, Boris Golden, and Fabrice Rossi.
2014. Reducing offline evaluation bias in recommendation systems. arXiv preprint
arXiv:1407.0822 (2014).
[13] Sihao Ding, Peng Wu, Fuli Feng, Xiangnan He, Yitong Wang, Yong Liao, and Yong-
dong Zhang. 2022. Addressing Unmeasured Confounder for Recommendation
with Sensitivity Analysis. In KDD.
[14] Chongming Gao, Shijun Li, Wenqiang Lei, Jiawei Chen, Biao Li, Peng Jiang,
Xiangnan He, Jiaxin Mao, and Tat-Seng Chua. 2022. KuaiRec: A Fully-observed
Dataset and Insights for Evaluating Recommender Systems. In CIKM.
[15] Yunjun Gao, Yuntao Du, Yujia Hu, Lu Chen, Xinjun Zhu, Ziquan Fang, and Baihua
Zheng. 2022. Self-guided learning to denoise for robust recommendation. In
SIGIR.
[16] Ihsan Gunes, Cihan Kaleli, Alper Bilge, and Huseyin Polat. 2014. Shilling attacks
against recommender systems: a comprehensive survey. Artificial Intelligence
Review (2014), 767–799.
[17] Siyuan Guo, Lixin Zou, Yiding Liu, Wenwen Ye, Suqi Cheng, Shuaiqiang Wang,
Hechang Chen, Dawei Yin, and Yi Chang. 2021. Enhanced Doubly Robust Learn-
ing for Debiasing Post-Click Conversion Rate Estimation. In SIGIR.
[18] José Miguel Hernández-Lobato, Neil Houlsby, and Zoubin Ghahramani. 2014.
Probabilistic matrix factorization with non-random missing data. In ICML.
[19] Sui L Hui and Steven D Walter. 1980. Estimating the error rates of diagnostic
tests. Biometrics (1980), 167–171.
[20] Yehuda Koren, Robert Bell, and Chris Volinsky. 2009. Matrix factorization tech-
niques for recommender systems. Computer (2009), 30–37.
[21] Wonbin Kweon and Hwanjo Yu. 2024. Doubly Calibrated Estimator for Recom-
mendation on Data Missing Not At Random. In WWW.
[22] Haoxuan Li, Quanyu Dai, Yuru Li, Yan Lyu, Zhenhua Dong, Xiao-Hua Zhou, and
Peng Wu. 2023. Multiple Robust Learning for Recommendation. In AAAI.
[23] Haoxuan Li, Yan Lyu, Chunyuan Zheng, and Peng Wu. 2023. TDR-CL: Targeted
Doubly Robust Collaborative Learning for Debiased Recommendations. In ICLR.
[24] Haoxuan Li, Kunhan Wu, Chunyuan Zheng, Yanghao Xiao, Hao Wang, Zhi Geng,
Fuli Feng, Xiangnan He, and Peng Wu. 2023. Removing Hidden Confounding in
Recommendation: A Unified Multi-Task Learning Approach. In NeurIPS.
[25] Haoxuan Li, Yanghao Xiao, Chunyuan Zheng, and Peng Wu. 2023. Balancing un-
observed confounding with a few unbiased ratings in debiased recommendations.
InWWW.
[26] Haoxuan Li, Yanghao Xiao, Chunyuan Zheng, Peng Wu, and Peng Cui. 2023.
Propensity Matters: Measuring and Enhancing Balancing for Recommendation.
InICML.
[27] Haoxuan Li, Chunyuan Zheng, Sihao Ding, Peng Wu, Zhi Geng, Fuli Feng, and
Xiangnan He. 2024. Be Aware of the Neighborhood Effect: Modeling Selection
Bias under Interference for Recommendation. In ICLR.
[28] Haoxuan Li, Chunyuan Zheng, Shuyi Wang, Kunhan Wu, Hao Wang, peng Wu,
Zhi Geng, Xu Chen, and Xiao-Hua Zhou. 2024. Relaxing the Accurate Imputation
Assumption in Doubly Robust Learning for Debiased Collaborative Filtering. In
ICML.[29] Haoxuan Li, Chunyuan Zheng, and Peng Wu. 2023. StableDR: Stabilized Doubly
Robust Learning for Recommendation on Data Missing Not at Random. In ICLR.
[30] Haoxuan Li, Chunyuan Zheng, Yanghao Xiao, Peng Wu, Zhi Geng, Xu Chen,
and Peng Cui. 2024. Debiased Collaborative Filtering with Kernel-Based Causal
Balancing. In ICLR.
[31] Zinan Lin, Dugang Liu, Weike Pan, Qiang Yang, and Zhong Ming. 2023. Trans-
fer learning for collaborative recommendation with biased and unbiased data.
Artificial Intelligence (2023), 103992.
[32] Roderick JA Little and Donald B Rubin. 2019. Statistical analysis with missing
data. Vol. 793. John Wiley & Sons.
[33] Dugang Liu, Pengxiang Cheng, Zhenhua Dong, Xiuqiang He, Weike Pan, and
Zhong Ming. 2020. A general knowledge distillation framework for counterfactual
recommendation via uniform data. In SIGIR.
[34] Dugang Liu, Pengxiang Cheng, Zinan Lin, Jinwei Luo, Zhenhua Dong, Xiuqiang
He, Weike Pan, and Zhong Ming. 2022. KDCRec: Knowledge distillation for
counterfactual recommendation via uniform data. IEEE Transactions on Knowledge
and Data Engineering (2022).
[35] Dugang Liu, Pengxiang Cheng, Hong Zhu, Zhenhua Dong, Xiuqiang He, Weike
Pan, and Zhong Ming. 2021. Mitigating Confounding Bias in Recommendation
via Information Bottleneck. In RecSys.
[36] Tongliang Liu and Dacheng Tao. 2015. Classification with noisy labels by impor-
tance reweighting. IEEE Transactions on pattern analysis and machine intelligence
(2015), 447–461.
[37] Yiming Liu, Xuezhi Cao, and Yong Yu. 2016. Are You Influenced by Others When
Rating? Improve Rating Prediction by Conformity Modeling. In RecSys.
[38] Yiyu Liu, Qian Liu, Yu Tian, Changping Wang, Yanan Niu, Yang Song, and
Chenliang Li. 2021. Concept-aware denoising graph neural network for micro-
video recommendation. In CIKM.
[39] Jinwei Luo, Dugang Liu, Weike Pan, and Zhong Ming. 2021. Unbiased recom-
mendation model based on improved propensity score estimation. Journal of
Computer Applications (2021), 3508.
[40] Xiao Ma, Liqin Zhao, Guan Huang, Zhi Wang, Zelin Hu, Xiaoqiang Zhu, and Kun
Gai. 2018. Entire Space Multi-Task Model: An Effective Approach for Estimating
Post-Click Conversion Rate. In SIGIR.
[41] Benjamin M Marlin and Richard S Zemel. 2009. Collaborative prediction and
ranking with non-random missing data. In RecSys.
[42] Aditya Menon, Brendan Van Rooyen, Cheng Soon Ong, and Bob Williamson.
2015. Learning from corrupted binary labels via class-probability estimation. In
ICML.
[43] Mehryar Mohri, Afshin Rostamizadeh, and Ameet Talwalkar. 2018. Foundations
of machine learning. MIT press.
[44] Nagarajan Natarajan, Inderjit S Dhillon, Pradeep K Ravikumar, and Ambuj Tewari.
2013. Learning with noisy labels. In NeurIPS.
[45] Curtis Northcutt, Lu Jiang, and Isaac Chuang. 2021. Confident learning: Estimat-
ing uncertainty in dataset labels. Journal of Artificial Intelligence Research (2021),
1373–1411.
[46] Harrie Oosterhuis. 2022. Reaching the end of unbiasedness: Uncovering implicit
limitations of click-based learning to rank. In SIGIR.
[47] Harrie Oosterhuis. 2023. Doubly robust estimation for correcting position bias in
click feedback for unbiased learning to rank. ACM Transactions on Information
Systems (2023), 1–33.
[48] Hang Pan, Jiawei Chen, Fuli Feng, Wentao Shi, Junkang Wu, and Xiangnan He.
2023. Discriminative-Invariant Representation Learning for Unbiased Recom-
mendation. In IJCAI.
[49] Giorgio Patrini, Alessandro Rozza, Aditya Krishna Menon, Richard Nock, and
Lizhen Qu. 2017. Making deep neural networks robust to label noise: A loss
correction approach. In CVPR.
[50] Yuqi Qin, Pengfei Wang, and Chenliang Li. 2021. The world is binary: Contrastive
learning for denoising next basket recommendation. In SIGIR.
[51] Francesco Ricci, Lior Rokach, and Bracha Shapira. 2010. Introduction to rec-
ommender systems handbook. In Recommender systems handbook. Springer,
1–35.
[52] Fred S Roberts. 1985. Measurement theory. (1985).
[53] Yong Rui, Vicente Ivan Sanchez Carmona, Mohsen Pourvali, Yun Xing, Wei-Wen
Yi, Hui-Bin Ruan, and Yu Zhang. 2022. Knowledge mining: A cross-disciplinary
survey. Machine Intelligence Research (2022), 89–114.
[54] Yuta Saito. 2019. Unbiased Pairwise Learning from Implicit Feedback. In NeurIPS
Workshop.
[55] Yuta Saito. 2020. Asymmetric Tri-training for Debiasing Missing-Not-At-Random
Explicit Feedback. In SIGIR.
[56] Yuta Saito. 2020. Doubly robust estimator for ranking metrics with post-click
conversions. In RecSys.
[57] Yuta Saito and Masahiro Nomura. 2022. Towards Resolving Propensity Contra-
diction in Offline Recommender Learning. In IJCAI.
[58] Yuta Saito, Suguru Yaginuma, Yuta Nishino, Hayato Sakata, and Kazuhide Nakata.
2020. Unbiased recommender learning from missing-not-at-random implicit
feedback. In WSDM.
 
1584KDD ’24, August 25–29, 2024, Barcelona, Spain. Haoxuan Li, Chunyuan Zheng, Wenjie Wang, Hao Wang, Fuli Feng, and Xiao-Hua Zhou
[59] Tobias Schnabel, Adith Swaminathan, Ashudeep Singh, Navin Chandak, and
Thorsten Joachims. 2016. Recommendations as Treatments: Debiasing Learning
and Evaluation. In ICML.
[60] Clayton Scott. 2015. A rate of convergence for mixture proportion estimation,
with application to learning from noisy labels. In AISTATS.
[61] Clayton Scott, Gilles Blanchard, and Gregory Handy. 2013. Classification with
asymmetric label noise: Consistency and maximal denoising. In COLT.
[62] Shai Shalev-Shwartz and Shai Ben-David. 2014. Understanding machine learning:
From theory to algorithms. Cambridge university press.
[63] Patrick E Shrout and Sean P Lane. 2012. Psychometrics. (2012).
[64] Zijie Song, Jiawei Chen, Sheng Zhou, Qihao Shi, Yan Feng, Chun Chen, and Can
Wang. 2023. CDR: Conservative doubly robust learning for debiased recommen-
dation. In CIKM.
[65] Harald Steck. 2010. Training and testing of recommender systems on data missing
not at random. In KDD.
[66] Adith Swaminathan and Thorsten Joachims. 2015. The self-normalized estimator
for counterfactual learning. In NeurIPS.
[67] Brendan Van Rooyen et al. 2015. Machine learning via transitions. (2015).
[68] Brendan Van Rooyen, Aditya Menon, and Robert C Williamson. 2015. Learning
with symmetric label noise: The importance of being unhinged. In NeurIPS.
[69] Hao Wang, Tai-Wei Chang, Tianqiao Liu, Jianmin Huang, Zhichao Chen, Chao Yu,
Ruopeng Li, and Wei Chu. 2022. ESCM2: Entire space counterfactual multi-task
model for post-click conversion rate estimation. In SIGIR.
[70] Jun Wang, Haoxuan Li, Chi Zhang, Dongxu Liang, Enyun Yu, Wenwu Ou, and
Wenjia Wang. 2023. CounterCLR: Counterfactual contrastive learning with
non-random missing data in recommendation. In ICDM.
[71] Wenjie Wang, Fuli Feng, Xiangnan He, Liqiang Nie, and Tat-Seng Chua. 2021.
Denoising implicit feedback for recommendation. In WSDM.
[72] Wenjie Wang, Yang Zhang, Haoxuan Li, Peng Wu, Fuli Feng, and Xiangnan He.
2023. Causal Recommendation: Progresses and Future Directions. In SIGIR.
[73] Xiaojie Wang, Rui Zhang, Yu Sun, and Jianzhong Qi. 2019. Doubly Robust Joint
Learning for Recommendation on Data Missing Not at Random. In ICML.
[74] Xiaojie Wang, Rui Zhang, Yu Sun, and Jianzhong Qi. 2021. Combating Selection
Biases in Recommender Systems with A Few Unbiased Ratings. In WSDM.
[75] Zifeng Wang, Xi Chen, Shao-Lun Wen, Rui anFd Huang, Ercan E Kuruoglu,
and Yefeng Zheng. 2020. Information Theoretic Counterfactual Learning from
Missing-Not-At-Random Feedback. In NeurIPS.
[76] Zhenlei Wang, Shiqi Shen, Zhipeng Wang, Bo Chen, Xu Chen, and Ji-Rong Wen.
2022. Unbiased sequential recommendation with latent confounders. In WWW.
[77] Tianxin Wei, Fuli Feng, Jiawei Chen, Ziwei Wu, Jinfeng Yi, and Xiangnan He.
2021. Model-agnostic counterfactual reasoning for eliminating popularity bias in
recommender system. In KDD.
[78] Xiaobo Xia, Tongliang Liu, Bo Han, Nannan Wang, Mingming Gong, Haifeng
Liu, Gang Niu, Dacheng Tao, and Masashi Sugiyama. 2020. Part-dependent label
noise: Towards instance-dependent label noise. In NeurIPS.
[79] Xiaobo Xia, Tongliang Liu, Nannan Wang, Bo Han, Chen Gong, Gang Niu, and
Masashi Sugiyama. 2019. Are anchor points really indispensable in label-noise
learning?. In NeurIPS.
[80] Mengyue Yang, Guohao Cai, Furui Liu, Jiarui Jin, Zhenhua Dong, Xiuqiang He,
Jianye Hao, Weiqi Shao, Jun Wang, and Xu Chen. 2023. Debiased recommendation
with user feature balancing. ACM Transactions on Information Systems (2023).
[81] Mengyue Yang, Quanyu Dai, Zhenhua Dong, Xu Chen, Xiuqiang He, and Jun
Wang. 2021. Top-N recommendation with counterfactual user preference simula-
tion. In CIKM.
[82] Chi Zhang, Rui Chen, Xiangyu Zhao, Qilong Han, and Li Li. 2023. Denoising and
Prompt-Tuning for Multi-Behavior Recommendation. In WWW.
[83] Honglei Zhang, Shuyi Wang, Haoxuan Li, Chunyuan Zheng, Xu Chen, Li Liu,
Shanshan Luo, and Peng Wu. 2024. Uncovering the Propensity Identification
Problem in Debiased Recommendations. In ICDE.
[84] Wenhao Zhang, Wentian Bao, Xiao-Yang Liu, Keping Yang, Quan Lin, Hong
Wen, and Ramin Ramezani. 2020. Large-scale Causal Approaches to Debiasing
Post-click Conversion Rate Estimation with Multi-task Learning. In WWW.
[85] Yongfeng Zhang, Xu Chen, et al .2020. Explainable recommendation: A survey
and new perspectives. Foundations and Trends® in Information Retrieval (2020),
1–101.
[86] Yang Zhang, Fuli Feng, Xiangnan He, Tianxin Wei, Chonggang Song, Guohui
Ling, and Yongdong Zhang. 2021. Causal intervention for leveraging popularity
bias in recommendation. In SIGIR.
[87] Zhiheng Zhang, Quanyu Dai, Xu Chen, Zhenhua Dong, and Ruiming Tang. 2023.
Robust causal inference for recommender system to overcome noisy confounders.
InSIGIR.
[88] Xiangyu Zhao, Long Xia, Jiliang Tang, and Dawei Yin. 2019. Deep reinforcement
learning for search, recommendation, and online advertising: a survey. ACM
Sigweb Newsletter, 1–15.
[89] Yu Zheng, Chen Gao, Xiang Li, Xiangnan He, Depeng Jin, and Yong Li. 2021.
Disentangling User Interest and Conformity for Recommendation with Causal
Embedding. In WWW.A Proofs
Theorem 3.1 (Bias of OME-DR Estimator). Given ˆ𝜌01and ˆ𝜌10
with ˆ𝜌01+ˆ𝜌10<1, imputed errors ¯Eand learned propensities ˆPwith
ˆ𝑝𝑢,𝑖>0for all user-item pairs, the bias of the OME-DR estimator is
Bias[EOME−DR(ˆR,R𝑜;ˆ𝜌01,ˆ𝜌10)]=1
|D|∑︁
(𝑢,𝑖)∈D
1−𝑜𝑢,𝑖
ˆ𝑝𝑢,𝑖
¯𝑒𝑢,𝑖+
∑︁
(𝑢,𝑖):𝑟∗
𝑢,𝑖=1𝑝𝑢,𝑖𝜔11−ˆ𝑝𝑢,𝑖
ˆ𝑝𝑢,𝑖ℓ(𝑓𝜃(𝑥𝑢,𝑖),1)+𝑝𝑢,𝑖𝜔01
ˆ𝑝𝑢,𝑖ℓ(𝑓𝜃(𝑥𝑢,𝑖),0)
+
∑︁
(𝑢,𝑖):𝑟∗
𝑢,𝑖=0𝑝𝑢,𝑖𝜔10
ˆ𝑝𝑢,𝑖ℓ(𝑓𝜃(𝑥𝑢,𝑖),1)+𝑝𝑢,𝑖𝜔00−ˆ𝑝𝑢,𝑖
ˆ𝑝𝑢,𝑖ℓ(𝑓𝜃(𝑥𝑢,𝑖),0),
where𝜔11,𝜔01,𝜔10, and𝜔00are given by
𝜔11=1−𝜌01−ˆ𝜌10
1−ˆ𝜌01−ˆ𝜌10, 𝜔 01=𝜌01−ˆ𝜌01
1−ˆ𝜌01−ˆ𝜌10,
𝜔10=𝜌10−ˆ𝜌10
1−ˆ𝜌01−ˆ𝜌10, 𝜔 00=1−ˆ𝜌01−𝜌10
1−ˆ𝜌01−ˆ𝜌10.
Proof. By definition, the bias of the OME-DR estimator is
Bias[EOME−DR(ˆR,R𝑜;ˆ𝜌01,ˆ𝜌10)]=ER,O[EOME−DR]−P∗.
By double expectation formula, the first term is
ER,O
EOME−DR(ˆR,R𝑜;ˆ𝜌01,ˆ𝜌10)
=ER|O
EO
EOME−DR(ˆR,R𝑜;ˆ𝜌01,ˆ𝜌10)
=ER|O1
|D|∑︁
(𝑢,𝑖)∈D
1−𝑝𝑢,𝑖
ˆ𝑝𝑢,𝑖
¯𝑒𝑢,𝑖+𝑝𝑢,𝑖˜𝑒𝑢,𝑖
ˆ𝑝𝑢,𝑖
=1
|D|∑︁
(𝑢,𝑖):𝑟∗
𝑢,𝑖=1ER|O
1−𝑝𝑢,𝑖
ˆ𝑝𝑢,𝑖
¯𝑒𝑢,𝑖+𝑝𝑢,𝑖˜𝑒𝑢,𝑖
ˆ𝑝𝑢,𝑖
+1
|D|∑︁
(𝑢,𝑖):𝑟∗
𝑢,𝑖=0ER|O
1−𝑝𝑢,𝑖
ˆ𝑝𝑢,𝑖
¯𝑒𝑢,𝑖+𝑝𝑢,𝑖˜𝑒𝑢,𝑖
ˆ𝑝𝑢,𝑖
.
Then, we can derive the bias of the OME-DR estimator as follows
Bias[EOME−DR(ˆR,R𝑜;ˆ𝜌01,ˆ𝜌10)]=ER|O[EO[EOME−DR]]−P∗
=1
|D|∑︁
(𝑢,𝑖):𝑟∗
𝑢,𝑖=1ER|O
1−𝑝𝑢,𝑖
ˆ𝑝𝑢,𝑖
¯𝑒𝑢,𝑖+𝑝𝑢,𝑖˜𝑒𝑢,𝑖
ˆ𝑝𝑢,𝑖
−ℓ(𝑓𝜃(𝑥𝑢,𝑖),1)
+1
|D|∑︁
(𝑢,𝑖):𝑟∗
𝑢,𝑖=0ER|O
1−𝑝𝑢,𝑖
ˆ𝑝𝑢,𝑖
¯𝑒𝑢,𝑖+𝑝𝑢,𝑖˜𝑒𝑢,𝑖
ˆ𝑝𝑢,𝑖
−ℓ(𝑓𝜃(𝑥𝑢,𝑖),0)
=1
|D|∑︁
(𝑢,𝑖):𝑟∗
𝑢,𝑖=1
1−𝑝𝑢,𝑖
ˆ𝑝𝑢,𝑖
¯𝑒𝑢,𝑖+∑︁
(𝑢,𝑖):𝑟∗
𝑢,𝑖=0
1−𝑝𝑢,𝑖
ˆ𝑝𝑢,𝑖
¯𝑒𝑢,𝑖
+∑︁
(𝑢,𝑖):𝑟∗
𝑢,𝑖=1𝑝𝑢,𝑖
ˆ𝑝𝑢,𝑖·ER|O˜𝑒𝑢,𝑖
−ℓ(𝑓𝜃(𝑥𝑢,𝑖),1)
+∑︁
(𝑢,𝑖):𝑟∗
𝑢,𝑖=0𝑝𝑢,𝑖
ˆ𝑝𝑢,𝑖·ER|O˜𝑒𝑢,𝑖
−ℓ(𝑓𝜃(𝑥𝑢,𝑖),0).
 
1585Debiased Recommendation with Noisy Feedback KDD ’24, August 25–29, 2024, Barcelona, Spain.
On one hand, for the user-item pairs with 𝑟∗
𝑢,𝑖=1, we have
ER|O˜𝑒𝑢,𝑖
=(1−𝜌01)·˜ℓ(𝑓𝜃(𝑥𝑢,𝑖),1;ˆ𝜌01,ˆ𝜌10)+𝜌01·˜ℓ(𝑓𝜃(𝑥𝑢,𝑖),0;ˆ𝜌01,ˆ𝜌10)
=(1−𝜌01)·(1−ˆ𝜌10)ℓ(𝑓𝜃(𝑥𝑢,𝑖),1)− ˆ𝜌01ℓ(𝑓𝜃(𝑥𝑢,𝑖),0)
1−ˆ𝜌01−ˆ𝜌10
+𝜌01·(1−ˆ𝜌01)ℓ(𝑓𝜃(𝑥𝑢,𝑖),0)− ˆ𝜌10ℓ(𝑓𝜃(𝑥𝑢,𝑖),1)
1−ˆ𝜌01−ˆ𝜌10
=1−𝜌01−ˆ𝜌10
1−ˆ𝜌01−ˆ𝜌10ℓ(𝑓𝜃(𝑥𝑢,𝑖),1)+𝜌01−ˆ𝜌01
1−ˆ𝜌01−ˆ𝜌10ℓ(𝑓𝜃(𝑥𝑢,𝑖),0)
:=𝜔11ℓ(𝑓𝜃(𝑥𝑢,𝑖),1)+𝜔01ℓ(𝑓𝜃(𝑥𝑢,𝑖),0),
where𝜔11and𝜔01are given by
𝜔11=1−𝜌01−ˆ𝜌10
1−ˆ𝜌01−ˆ𝜌10, 𝜔 01=𝜌01−ˆ𝜌01
1−ˆ𝜌01−ˆ𝜌10.
On the other hand, for the user-item pairs with 𝑟∗
𝑢,𝑖=0, we have
ER|O˜𝑒𝑢,𝑖
=𝜌10·˜ℓ(𝑓𝜃(𝑥𝑢,𝑖),1;ˆ𝜌01,ˆ𝜌10)+(1−𝜌10)·˜ℓ(𝑓𝜃(𝑥𝑢,𝑖),0;ˆ𝜌01,ˆ𝜌10)
=𝜌10·(1−ˆ𝜌10)ℓ(𝑓𝜃(𝑥𝑢,𝑖),1)− ˆ𝜌01ℓ(𝑓𝜃(𝑥𝑢,𝑖),0)
1−ˆ𝜌01−ˆ𝜌10
+(1−𝜌10)·(1−ˆ𝜌01)ℓ(𝑓𝜃(𝑥𝑢,𝑖),0)− ˆ𝜌10ℓ(𝑓𝜃(𝑥𝑢,𝑖),1)
1−ˆ𝜌01−ˆ𝜌10
=𝜌10−ˆ𝜌10
1−ˆ𝜌01−ˆ𝜌10ℓ(𝑓𝜃(𝑥𝑢,𝑖),1)+1−ˆ𝜌01−𝜌10
1−ˆ𝜌01−ˆ𝜌10ℓ(𝑓𝜃(𝑥𝑢,𝑖),0)
:=𝜔10ℓ(𝑓𝜃(𝑥𝑢,𝑖),1)+𝜔00ℓ(𝑓𝜃(𝑥𝑢,𝑖),0),
where𝜔10and𝜔00are given by
𝜔10=𝜌10−ˆ𝜌10
1−ˆ𝜌01−ˆ𝜌10, 𝜔 00=1−ˆ𝜌01−𝜌10
1−ˆ𝜌01−ˆ𝜌10.
This completes the proof. □
Lemma 3.3 (Lipschitz Continuity). Given ˆ𝜌01and ˆ𝜌10with
ˆ𝜌01+ˆ𝜌10<1, ifℓ(𝑓𝜃(𝑥𝑢,𝑖),𝑟∗
𝑢,𝑖)is𝐿-Lipschitz in 𝑓𝜃(𝑥𝑢,𝑖)for all𝑟∗
𝑢,𝑖,
then ˜ℓ(𝑓𝜃(𝑥𝑢,𝑖),𝑟𝑢,𝑖)is2𝐿
1−ˆ𝜌01−ˆ𝜌10-Lipschitz in 𝑓𝜃(𝑥𝑢,𝑖)for all𝑟𝑢,𝑖.
Proof. The explicit form of ˜ℓ(𝑓𝜃(𝑥𝑢,𝑖),1)and ˜ℓ(𝑓𝜃(𝑥𝑢,𝑖),0)are
˜ℓ(𝑓𝜃(𝑥𝑢,𝑖),1)=(1−ˆ𝜌10)ℓ(𝑓𝜃(𝑥𝑢,𝑖),1)− ˆ𝜌01ℓ(𝑓𝜃(𝑥𝑢,𝑖),0)
1−ˆ𝜌01−ˆ𝜌10,
˜ℓ(𝑓𝜃(𝑥𝑢,𝑖),0)=(1−ˆ𝜌01)ℓ(𝑓𝜃(𝑥𝑢,𝑖),0)− ˆ𝜌10ℓ(𝑓𝜃(𝑥𝑢,𝑖),1)
1−ˆ𝜌01−ˆ𝜌10.
Then the conclusion can be dirived directly from ˆ𝜌01+ˆ𝜌10<1.□
Lemma A.1 (McDiarmid’s Ineqality). Let𝑉be some set and
let𝑓:𝑉𝑚→Rbe a function of 𝑚variables such that for some 𝑐>0,
for all𝑖∈[𝑚]and for all𝑥1,...,𝑥𝑚,𝑥′
𝑖∈𝑉we have
𝑓(𝑥1,...,𝑥𝑚)−𝑓 𝑥1,...,𝑥𝑖−1,𝑥′
𝑖,𝑥𝑖+1,...,𝑥𝑚≤𝑐
Let𝑋1,...,𝑋𝑚be𝑚independent random variables taking values in
𝑉. Then, with probability of at least 1−𝜂we have
|𝑓(𝑋1,...,𝑋𝑚)−E[𝑓(𝑋1,...,𝑋𝑚)]|≤𝑐√︄
log2
𝜂
𝑚/2.
Proof. The proof can be found in Lemma 26.4 of [62]. □Theorem 3.4 (Generalization Bound). Given ˆ𝜌01and ˆ𝜌10with
ˆ𝜌01+ˆ𝜌10<1, supposeℓ(𝑓𝜃(𝑥𝑢,𝑖),𝑟∗
𝑢,𝑖)is𝐿-Lipschitz in 𝑓𝜃(𝑥𝑢,𝑖)for
all𝑟∗
𝑢,𝑖, and ˆ𝑝𝑢,𝑖≥𝐶𝑝,|˜ℓ(𝑓𝜃(𝑥𝑢,𝑖),𝑟𝑢,𝑖)|≤𝐶𝑙for all𝑟𝑢,𝑖, then with
probability 1−𝜂, the true prediction inaccuracy P(ˆR‡,R∗)of the
optimal prediction matrix using the OME-DR estimator with imputed
errors ¯Eand learned propensities ˆPhas the upper bound
EOME−DR(ˆR‡,R𝑜;ˆ𝜌01,ˆ𝜌10)+Bias[EOME−DR(ˆR‡,R𝑜;ˆ𝜌01,ˆ𝜌10)]+

1+2
𝐶𝑝4𝐿
1−ˆ𝜌01−ˆ𝜌10R(F)+
𝐶𝑙+4𝐿
1−ˆ𝜌01−ˆ𝜌10√︄
2 log(4/𝜂)
|D|.
Proof. The true prediction inaccuracy can be decomposed as
P∗=EOME−DR+ P∗−E[EOME−DR]+(E[EOME−DR]−E OME−DR)
≤E OME−DR+Bias(EOME−DR)+(E[EOME−DR]−E OME−DR)
≤E OME−DR+Bias(EOME−DR)+sup
𝑓𝜃∈F(E[EOME−DR]−E OME−DR).
To simplify notation, let B(F) =sup𝑓𝜃∈F(E[EOME−DR]−E OME−DR),
which can be decomposed as
B(F) =E
𝑆∼P|D|[B(F)]+
B(F)− E
𝑆∼P|D|[B(F)]
.
For the first term E
𝑆∼P|D|[B(F)] , according to the Rademacher
Comparison Lemma [62] and Talagrand’s Lemma [43], we have
E
𝑆∼P|D|[B(F)]
≤2E
𝑆∼P|D|E𝜎sup
𝑓𝜃∈F1
|D|∑︁
(𝑢,𝑖)∈D𝜎𝑢,𝑖
1−𝑜𝑢,𝑖
ˆ𝑝𝑢,𝑖
¯𝑒𝑢,𝑖+𝑜𝑢,𝑖˜𝑒𝑢,𝑖
ˆ𝑝𝑢,𝑖
≤2
1+2
𝐶𝑝2𝐿
1−ˆ𝜌01−ˆ𝜌10·E
𝑆∼P|D|E𝜎sup
𝑓𝜃∈F1
|D|∑︁
(𝑢,𝑖)∈D𝜎𝑢,𝑖𝑓𝜃(𝑥𝑢,𝑖)
=2
1+2
𝐶𝑝2𝐿
1−ˆ𝜌01−ˆ𝜌10·E
𝑆∼P|D|{R(F)},
whereR(F) is the empirical Rademacher complexity of F
R(F) =E𝜎∼{− 1,+1}|D|sup
𝑓𝜃∈F1
|D|∑︁
(𝑢,𝑖)∈D𝜎𝑢,𝑖𝑓𝜃(𝑥𝑢,𝑖).
By applying McDiarmid’s inequality, and let 𝑐=2
|D|, with prob-
ability at least 1−𝜂
2,
R(F)− E
𝑆∼P|D|{R(F)}≤2√︄
log(4/𝜂)
2|D|=√︄
2 log(4/𝜂)
|D|.
For the rest term B(F)− E
𝑆∼P|D|[B(F)] , by applying McDi-
armid’s inequality, and let 𝑐=2
|D|𝐶𝑙
1+2
𝐶𝑝
, with probability at
least 1−𝜂
2,
B(F)− E
𝑆∼P|D|[B(F)]≤𝐶𝑙
1+2
𝐶𝑝√︄
2 log(4/𝜂)
|D|.
After adding the inequalities above, we can rearrange the terms to
obtain the stated results. □
 
1586