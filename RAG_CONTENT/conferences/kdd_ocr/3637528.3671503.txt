The First Workshop on AI Behavioral Science
Himabindu Lakkaraju
hlakkaraju@hbs.edu
Harvard University
Cambridge, Massachusetts, USAQiaozhu Mei∗
qmei@umich.edu
University of Michigan
Ann Arbor, Michigan, USAChenhao Tan
chenhao@uchicago.edu
University of Chicago
Chicago, Illinois, USA
Jie Tang
jietang@tsinghua.edu.cn
Tsinghua University
Beijing, ChinaYutong Xie
yutxie@umich.edu
University of Michigan
Ann Arbor, Michigan, USA
ABSTRACT
This workshop initiates a new study field which may be named
AI behavioral science. It discusses recent findings, methodologies,
applications, and potential societal impacts that are related to ana-
lyzing, understanding, and directing the behaviors of AI models,
especially those built upon large language models. This half-day
workshop includes several keynote and invited talks, a poster ses-
sion, and a panel discussion.
ACM Reference Format:
Himabindu Lakkaraju, Qiaozhu Mei, Chenhao Tan, Jie Tang, and Yutong
Xie. 2024. The First Workshop on AI Behavioral Science. In Proceedings of
the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining
(KDD ’24), August 25–29, 2024, Barcelona, Spain. ACM, New York, NY, USA,
2 pages. https://doi.org/10.1145/3637528.3671503
1 INTRODUCTION
Advancements in modern AIs, especially large language models
(LLMs), have stirred discussions about the potential of AI bots to
emulate, assist, or even outperform humans in various tasks such as
writing essays, taking the SAT, writing computer programs, solving
math problems, or developing ideas [ 2,3,5]. Debates arise about
their potential impact on labor markets [ 4] and broader societal
implications [7, 10]. Many of these present and future roles for AI
involve decision-making and strategic interactions with humans. It
is therefore critical to understand AI’s behavioral tendencies before
it can be trusted with pilot or co-pilot positions in societal contexts,
especially since the models and the training processes are complex
and not transparent [ 1]. Current evaluation and alignment of LLMs
are predominantly focused on their textual outputs rather than their
behaviors, which highlights a significant gap in understanding the
full capabilities and limitations of these AI systems. This focus on
"what they say" over "what they do" overlooks critical aspects of
AI behavior, such as the underlying decision-making mechanisms,
ethical considerations, and the potential for autonomous action
beyond content generation. To fully understand the preferences of
∗Primary contact: Qiaozhu Mei (qmei@umich.edu).
Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for third-party components of this work must be honored.
For all other uses, contact the owner/author(s).
KDD ’24, August 25–29, 2024, Barcelona, Spain
©2024 Copyright held by the owner/author(s).
ACM ISBN 979-8-4007-0490-1/24/08
https://doi.org/10.1145/3637528.3671503LLMs, align them with human values, and ensure they behave in
ways beneficial to the society, we need new methodologies that ac-
count for direct and comprehensive evaluation of LLM’s behaviors,
including how they interpret instructions, value choices, reason
through complex utilities, and how they behave in interactive or
dynamic environments where decision-making plays a crucial role.
Behavioral sciences [6] have long provided insights into human
behaviors through investigations in economics, psychology, educa-
tion, and other related disciplines. The methodologies employed
in behavioral sciences, including theories, observational studies,
and field experiments, have enabled researchers to predict behav-
iors, understand motivations, and identify patterns that underpin
human actions in different circumstances. Findings from behav-
ioral sciences have widely influenced the society, from individual
decision-making to public policies. These theories and methodolo-
gies originated in behavioral sciences provide a solid basis for in-
vestigating AI behaviors, while the fast development of AI presents
new opportunities and challenges for behavioral sciences [9].
In response to these evolving challenges and opportunities, this
workshop calls for broad discussions on the concept of AI behav-
ioral science [9], which represents an emerging field that seeks to
understand, model, and direct how AI behaves. Recent studies, such
as incorporating classic behavioral economic games into the Turing
test [ 8], highlight some initial steps in this new field. However,
plenty of critical questions remain unanswered: e.g., how to con-
ceal the objectives of AI (rather than generating the next words)
and align them with the distribution of human objectives? How to
model and optimize human-AI collaboration? What are the unique
challenges in AI behavioral studies? What is the key difference be-
tween AI behavioral science and human behavioral science? Do we
need to design new experiment methodologies and measurements
tailored for AI? What are the potential applications? This work-
shop aims to create a collaborative and interdisciplinary platform
that brings together researchers from different fields, especially
generative AI, data mining, and behavioral sciences to discuss these
questions. By fostering an open and forward-looking environment,
our ultimate goal is to facilitate discussions on the current land-
scape of AI behavioral science at large. This workshop provides an
opportunity for participants to share insights, exchange ideas, and
explore innovative approaches in the field.
The Call for Paper of the workshop includes the following topics:
•Insights from comparing AI behavior with human behavior.
•Game theoretical approaches to human-AI interaction.
6724
KDD ’24, August 25–29, 2024, Barcelona, Spain Himabindu Lakkaraju, Qiaozhu Mei, Chenhao Tan, Jie Tang, & Yutong Xie
•Empirical or theoretical analysis on the objectives, utilities,
and rationality of AI.
•New developments in aligning LLMs with diverse human
behaviors, preferences, and objectives.
•New experimental designs and measurements for AI behav-
ioral science research.
•Applications of AI to investigating human behaviors, in-
cluding but not limited to economics, psychology, sociology,
education, healthcare, and future of work.
•Ethics of AI behavioral science, including but not limited to
studies that promote fairness, diversity, and representation,
benefiting individuals, groups, and society at large.
A total of 12 submissions are received by the workshop. This
half-day workshop features a keynote speech, additional invited
talks, a poster session of all accepted papers, and a panel discussion
on open and forward-looking topics.
2 ORGANIZERS
Himabindu Lakkaraju, Harvard University. Himabindu (Hima)
Lakkaraju is an assistant professor at Harvard University focus-
ing on explainability, fairness, and robustness of machine learning
models. She has also been working with various domain experts
in policy and healthcare to understand the real-world implications
of explainable and fair ML. Hima has been named as one of the
world’s top innovators under 35 by both MIT Tech Review and Van-
ity Fair. Her research has also received best paper awards at SIAM
International Conference on Data Mining (SDM) and INFORMS,
and grants from NSF, Google, Amazon, and Bayer. Hima has given
keynote talks at various top ML conferences and workshops in-
cluding CIKM, ICML, NeurIPS, AAAI, and CVPR, and her research
has also been showcased by popular media outlets including the
New York Times, MIT Tech Review, TIME magazine, and Forbes.
More recently, she co-founded the Trustworthy ML Initiative to
enable easy access to resources on trustworthy ML and to build a
community of researchers/practitioners working on the topic.
Qiaozhu Mei, University of Michigan. qmei@umich.edu. Qiaozhu
is a professor in the School of Information and the Department of
EECS at the University of Michigan. His research focuses on large-
scale data mining, machine learning, information retrieval, and
natural language processing, with broad applications to networks,
Web, and healthcare. Qiaozhu is an ACM distinguished member
(2017) and a recipient of the NSF Career Award (2011). His work has
received multiple best paper awards at WWW, ICML, KDD, WSDM,
and other major conferences. He served as the founding director
of the master degree of applied data science at the University of
Michigan as well as the General Co-Chair of SIGIR 2018.
Chenhao Tan, University of Chicago. Chenhao Tan is an assis-
tant professor of computer science and data science at the University
of Chicago, and is also affiliated with the Harris School of Public
Policy. He obtained his PhD degree in the Department of Computer
Science at Cornell University and bachelor’s degrees in computer
science and in economics from Tsinghua University. Prior to join-
ing the University of Chicago, he was an assistant professor at the
University of Colorado Boulder and a postdoc at the University
of Washington. His research interests include human-centered AI,
natural language processing, and computational social science. Hiswork has been covered by many news media outlets, such as the
New York Times and the Washington Post. He also won a Sloan
research fellowship, an NSF CAREER award, an NSF CRII award, a
Google research scholar award, research awards from Amazon, IBM,
JP Morgan, and Salesforce, a Facebook fellowship, and a Yahoo!
Key Scientific Challenges award.
Jie Tang, Tsinghua University. Jie is a Professor of the Depart-
ment of Computer Science and Technology of Tsinghua University.
He is a Fellow of the ACM, a Fellow of AAAI, and a Fellow of
the IEEE. His research interests include artificial general intelli-
gence (AGI), data mining, social networks, machine learning and
knowledge graph, with an emphasis on designing new algorithms
for information and social network mining and designing new
paradigms for artificial general intelligence. Similar to Open AI’s
GPT serials, Jie, leading a big research team, have designed GLM-
130B, ChatGLM, CogView&CogVideo, CodeGeex, toward teaching
machines to think like humans. Jie also invented AMiner.org, which
has attracted over 30,000,000 users from 220 countries/regions in
the world. He has been honored with the SIGKDD Test-of-Time
Award for Applied Science (Ten-year Best Paper Award), the 2nd
National Award for Science&Technology, NSFC for Distinguished
Young Scholar, UK Royal Society-Newton Advanced Fellowship
Award, and SIGKDD Service Award. He served as PC Co-Chair of
CIKM’16, WSDM’15, Associate General Chair of KDD’18, and the
General Co-Chair of WWW’23.
Yutong Xie , University of Michigan. Yutong is a Ph.D. candi-
date in the School of Information at the University of Michigan.
She has a general research interest in AI for scientific innovation,
AI for creativity, and AI behavioral study. Yutong has published
research papers in major conferences and journals at PNAS, WWW,
ICLR, AAAI, etc. She co-organized the workshop on Graph Neural
Networks for Recommendation and Search at ACM RecSys ’21, and
regularly served as a reviewer in AI-related conferences.
REFERENCES
[1]Rishi Bommasani, Kevin Klyman, Shayne Longpre, Sayash Kapoor, Nestor Maslej,
Betty Xiong, Daniel Zhang, and Percy Liang. 2023. The Foundation Model
Transparency Index. arXiv preprint arXiv:2310.12941 (2023).
[2] Sébastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric
Horvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg, et al .2023.
Sparks of artificial general intelligence: Early experiments with gpt-4. arXiv
preprint arXiv:2303.12712 (2023).
[3]Yiting Chen, Tracy Xiao Liu, You Shan, and Songfa Zhong. 2023. The emergence
of economic rationality of GPT. Proceedings of the National Academy of Sciences
120, 51 (2023), e2316205120.
[4]Tyna Eloundou, Sam Manning, Pamela Mishkin, and Daniel Rock. 2023. Gpts
are gpts: An early look at the labor market impact potential of large language
models. arXiv preprint arXiv:2303.10130 (2023).
[5]Karan Girotra, Lennart Meincke, Christian Terwiesch, and Karl T Ulrich. 2023.
Ideas are dimes a dozen: Large language models for idea generation in innovation.
Available at SSRN 4526071 (2023).
[6]Michael Hallsworth. 2023. A manifesto for applying behavioural science. Nature
Human Behaviour 7, 3 (2023), 310–322.
[7]Peter Lee, Sebastien Bubeck, and Joseph Petro. 2023. Benefits, limits, and risks of
GPT-4 as an AI chatbot for medicine. New England Journal of Medicine 388, 13
(2023), 1233–1239.
[8]Qiaozhu Mei, Yutong Xie, Walter Yuan, and Matthew O. Jackson. 2024. A Turing
test of whether AI chatbots are behaviorally similar to humans. Proceedings of
the National Academy of Sciences 121, 9 (2024), e2313925121.
[9]Juanjuan Meng. 2024. AI emerges as the frontier in behavioral science. Proceedings
of the National Academy of Sciences 121, 10 (2024), e2401336121.
[10] Scott Shackelford, Lawrence J Trautman, and W Gregory Voss. 2023. How
We Learned to Stop Worrying and Love AI: Analyzing the Rapid Evolution of
Generative Pre-Trained Transformer (GPT) and its Impacts on Law, Business,
and Society. Business, and Society (July 20, 2023) (2023).
6725