DAG: Deep Adaptive and Generative 𝐾-Free Community
Detection on Attributed Graphs
Chang Liu∗
isonomialiu@sjtu.edu.cn
Shanghai Jiao Tong University
Shanghai, ChinaYuwen Yang
youngfish@sjtu.edu.cn
Shanghai Jiao Tong University
Shanghai, ChinaYue Ding†
dingyue@sjtu.edu.cn
Shanghai Jiao Tong University
Shanghai, China
Hongtao Lu
htlu@sjtu.edu.cn
Shanghai Jiao Tong University
Shanghai, ChinaWenqing Lin†
edwlin@tencent.com
Tencent, Shenzhen, ChinaZiming Wu
jimmyzmwu@tencent.com
Tencent, Shenzhen, China
Wendong Bi
wendongbi@tencent.com
Tencent, Shenzhen, China
ABSTRACT
Community detection on attributed graphs with rich semantic and
topological information offers great potential for real-world net-
work analysis, especially user matching in online games. Graph
Neural Networks (GNNs) have recently enabled Deep Graph Clus-
tering (DGC) methods to learn cluster assignments from semantic
andtopologicalinformation.However,theirsuccessdependsonthe
prior knowledge related to the number of communities 𝐾, which is
unrealisticduetothehighcostsandprivacyissuesofacquisition.In
this paper, weinvestigate the community detectionproblem with-
outprior 𝐾,referred toas 𝐾-FreeCommunity Detectionproblem.
To address this problem, we propose a novel Deep Adaptive and
Generative model (DAG) for community detection without specify-
ing the prior 𝐾. DAG consists of three key components, i.e.,an od e
representation learning module with masked attribute reconstruc-
tion, a community affiliation readout module, and a communitynumber search module with group sparsity. These components
enableDAGtoconverttheprocessofnon-differentiablegridsearch
for the community number, i.e.,a discrete hyperparameter in exist-
ing DGC methods, into a differentiable learning process. In such a
way,DAGcansimultaneouslyperformcommunitydetectionand
community number search end-to-end. To alleviate the cost of ac-
quiringcommunitylabelsinreal-worldapplications,wedesigna
newmetric,EDGE,toevaluatecommunitydetectionmethodseven
when thelabels are notfeasible. Extensive offlineexperiments on
five public datasets and a real-world online mobile game dataset
∗This work was done while Chang Liu was an intern at Tencent.
†Corresponding authors: Yue Ding and Wenqing Lin.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
onthe firstpage.Copyrights forcomponentsof thisworkowned byothersthan the
author(s)mustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,or
republish,topostonserversortoredistributetolists,requirespriorspecificpermission
and/or a fee. Request permissions from permissions@acm.org.
KDD ’24, August 25–29, 2024, Barcelona, Spain
© 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 979-8-4007-0490-1/24/08
https://doi.org/10.1145/3637528.3671615demonstrate the superiority of our DAG over the existing state-of-
the-art (SOTA) methods. DAG has a relative increase of 7.35% in
teamsinaTencentonlinegamecomparedwiththebestcompetitor.
CCS CONCEPTS
•Computing methodologies →Unsupervised learning.
KEYWORDS
Social network; Community detection; Graph neural networks;
Unsupervised learning
ACM Reference Format:
Chang Liu, Yuwen Yang, Yue Ding, Hongtao Lu, Wenqing Lin, Ziming
Wu,andWendongBi.2024.DAG:DeepAdaptiveandGenerative 𝐾-Free
CommunityDetectiononAttributedGraphs.In Proceedingsofthe30thACM
SIGKDD Conference on Knowledge Discovery and Data Mining (KDD ’24),
August25–29,2024,Barcelona,Spain. ACM,NewYork,NY,USA,12pages.
https://doi.org/10.1145/3637528.3671615
1 INTRODUCTION
Communitydetection,whichaimstopartitionnetworksintodensely
connectedsubstructuresandrevealslatentfunctions[ 12,24],isa
crucial unsupervised learning task in network analysis. It has been
extensively studied in various fields, such as recommendation sys-
tems[23,44,62],biochemistry[ 11,50,55],cybersecurity[ 54],and
business [ 2,3,25]. Among various networks, attributednetworks,
where nodes contain abundant semanticinformation, have gained
significantattentioninrecentyearssincenodeattributescanplaya
complementaryroleofthenetworktopology[ 35,40,53,57,61].Its
efficacyisevidentthatnodeswithsimilarattributestendtoform
cohesivecommunitiesinreal-worldsocialnetworks,assuggested
by the adage “birds of a feather flock together” [37].
Existingalgorithmsforcommunitydetectioninattributednet-
works suffer from two limitations in industrial applications: 1)
From a learning perspective, it is not feasible to concurrently ac-
quire representations from network topology and node semantics
whilealsosearchingfortheoptimalcommunitynumber,denoted
as𝐾. Specifically, conventional community detection algorithms
5454
KDD ’24, August 25–29, 2024, Barcelona, Spain Chang Liu et al.
 "%'" ( % " )+%'! + ) ))' *) %(  $ $" $ #"+%'" (% " $)+%'! +'
%##*$ ), $*#'  ( *$!$%+$
	




",' '( $)(#%##*$ ),






",'  '( '%((  '$)%##*$ ) (
	


$&*) ))' *) '& ' $ $ &'%*' (' $ (( $ $%( *)&*)$  " ) %$
' %##*$ ), )) %$ (( $ %(  $)% 
%##*$ ) (
(( $ $%(  $)%
	
%##*$ ) (
%))' *)(( $ $%(  $)%	
%##*$ ) (
 *)&*)
	

	
Figure1:Ourresearchproblem: 𝐾-Freecommunitydetection
for real-world social networks (node-attributed graphs).
struggle to strike a balance between learning the intricate network
topology and handling high-dimensional semantic attributes [ 49].
In comparison, advanced deep learning-based methods achieve
topology-semantictrade-off,buttheyrelyonpriorknowledgeof
𝐾, rendering their practical application challenging. 2) From the
evaluation perspective, the ground-truth community is a trade-off
between topology and semantics, making unsupervised metrics
deviate from the real-world communities. Meanwhile, the labels in
large-scalesocialnetworksareunavailableforuserprivacy,making
existing metrics infeasible in deployment.
Tosupportourinvestigation,weevaluatetraditionalmethods
on five well-known datasets with unsupervised metrics, i.e.,modu-
larity[7]andCalinskiHarabaszscore(dubbedas“Semantic”)[ 6]
tomeasurethenodeconnectiondensityandtheattributesimilar-
ity in the same community. As illustrated in Table 1, the ground
truth community is a trade-off between topology and semantics,
but existing methods overemphasize a specific metric, i.e.,Louvain
onlyfocusesonnetworkconnections,andattributeclusteringal-
gorithmslike 𝐾-means[14]solelyconcentrateonattributes.This
imbalance results in biased outcomes and deviates from the real-
world community structure. It should be noted that while Louvain
can adaptively search for the community number 𝐾(𝐾-means can-
not), its result is much greater than the ground truth across all
datasets. Thus, it falls short to discover a suitable 𝐾.
Deep Graph Clustering (DGC) [ 34] methods employ Graph Neu-
ral Networks (GNNs) and unify the learning from both topological
structure and node semantic attributes by learning “clustering-
friendly” node embeddings[38]. However, they fail toaddress the
dependency of knowing 𝐾, which precludes the applicability of
real-worldcommunitydetection.Onestraightforwardsolutionis
to estimate 𝐾by traditional methods, but it is often larger than the
groundtruth.Thus,naivelyestimating 𝐾viatraditionalmethods
andsubsequentlyapplyingDGCmayfallintosub-optimal.DGC
circumvents this problem by assuming 𝐾is already known, which
isunrealisticinpractice.AnexampleisillustratedinFig.1(a)for
usercommunitiesinonlinegames.Groundtruthlabelscanbesome
private user profiles, such as affiliation, job, location, etc., which
arenotavailabletotheplatform.Wecanonlyidentifyuserswith
frequent interactions and high attribute similarity. These users are
likelyto belongto thesamecommunity,and itisstill challenging
to determinethe numberof communitiesthey form. ThisexhibitsDataset Algorithm Modularity Semantic K
Cora [46]Ground Truth 0.6401 11.936 7
𝐾-means 0.1933 20.962 7
Louvain 0.8135 2.107 105
CiteSeer [46]Ground Truth 0.5470 11.646 6
𝐾-means 0.2970 19.349 6
Louvain 0.8919 1.615 469
PubMed [46]Ground Truth 0.4318 200.337 3
𝐾-means 0.3490 435.917 3
Louvain 0.7695 37.069 39
Wiki [56]Ground Truth 0.5420 11.368 17
𝐾-means 0.2061 24.986 17
Louvain 0.7112 3.530 64
CoraFull [47]Ground Truth 0.5417 10.468 70
𝐾-means 0.2462 22.371 70
Louvain 0.8126 2.344 404
Table 1: Traditional methods lead to biased results from
ground-truthcommunities.Modularitymeasuresthedensity
ofthecommunities.The“Semantic”metricistheCalinski
Harabasz score. 𝐾is the community number.
a“catch-22”dilemma:existingdeeplearningapproachesnecessi-
tatepriorknowledge,butitdoesnotexist.Consequently,thereis
anurgentneedtodetectcommunitieswithunknowncommunity
number issues in real-world attributed graphs [32].
In this paper, we aim to develop a systematic solution for the
𝐾-free community detection problem, as illustrated in Fig. 1 (b).
We design a novel learning framework named DeepAdaptive and
Generative (DAG) for community detection on node-attributed
graphs.Specifically,DAGfirstlearnsnodeembeddingswithboth
topologyandsemanticinformationwithmaskedattributerecon-
struction. Secondly, we design a community readout module based
on the community affiliation network [ 5,26] instead of clustering,
whichisthekeydifferencebetweenDAGandDGCmethods.The
readoutmoduleenablesourthirdstepfordifferentiablecommunity
selection.Weconvertthechallenginggridsearchof 𝐾forcluster-
ing into a differentiable community selection regularized by group
sparsity. In summary, DAG does not require specifying prior 𝐾
butsimultaneouslyperformscommunitydetectionandcommunity
number search in an end-to-end fashion. We additionally propose
a novel metric, EDGE, to address the high acquisition costs forevaluation. EDGE transforms the
𝐾class problem into a binary
one to replace the unavailable private profile with high-confidence
user interaction in deployment. Empirical experiments justify that
EDGE is more robust than existing metrics when the detected 𝐾
is not always equal to the ground truth in Sec.4.2.1 and can indi-
cate more meaningful communities where users are more likely to
interact with each other in Sec. 5.
Contributions. The contributions of our paper include:
•Weproposea 𝐾-freedeepcommunitydetectionframeworkon
attributedgraphscalledDAG,whichcanadaptivelysearchthe
numberofcommunitiesduringthetrainingprocessinanend-to-
end manner. DAG bridges the gap between traditional and deep
learning-based community detection methods.
•WedesignanewEDGEmetricfor 𝐾-freecommunitydetection
evaluation. EDGE offers two advantages: 1) For labeled data,
EDGEisrobustandobjectiveifdetected 𝐾variesfromground
5455DAG: Deep Adaptive and Generative 𝐾-Free Community Detection on Attributed Graphs KDD ’24, August 25–29, 2024, Barcelona, Spain
truth. 2) EDGE is also effective for real-world applications in
which we do not have actual ground truth communities because
EDGE reflects the intimacy between linked nodes.
•We conduct extensive experiments on five public benchmark
datasets in Sec. 4. Experimental results demonstrate that DAG
outperforms state-of-the-art (SOTA) methods. We further con-
duct an online A/B testing between our DAG and the best SOTA
againstthebaselineonafriendrecommendationtaskduringa
one-week event; the results show that DAG’s improvement out-
performsSOTAby7.35%,1.97%,and5.24%fortheoverallsuccess
rate, click rate, and team formation success rate, respectively.
The superior online performance further indicates that DAG can
detect more meaningfuluser communities, i.e.,users within the
same community have a higher tendency to interact.
2 PRELIMINARIES
In this section, we first formulate our research problem, i.e.,𝐾-free
community detection on attribute graphs. We then conduct an em-
piricalstudyonDGCmethods,demonstratingthattheycanneitherhandle
𝐾-freecommunitydetectiontaskswithtrivialmodifications
nor find a proper community number 𝐾with their methods.
2.1 Problem Formulation
In an undirected and unweighted attributed graph G={A,X},
letV={𝑣1,𝑣2,···,𝑣𝑁}be a set of 𝑁nodes and Ebe a set of edges.
X∈R𝑁×𝐷andA∈R𝑁×𝑁denote the node attribute matrix
and original adjacency matrix, respectively. We define community
affiliation as follows to represent node-to-community assignment.
Definition 1 (community affiliation). A community affilia-
tionC𝑖∈R𝐾
≥0of node𝑣𝑖is a stochastic vector that adds up to one,
wherethe 𝑘-thentryistheprobabilityofnode 𝑣belongingtothe
𝑘-th community.
BasedonDefinition1,wefocusonanon-overlappingcommunity
detectiontask, i.e.,eachnodebelongstoonlyonecommunity.How-
ever,unlikeexistingDGCmethods,wedonothavepriorknowledge
ofthetotalnumberofcommunities,denotedas 𝐾.Weformulate
the𝐾-free community detection problem as follows.
Problem1( 𝐾-FreeCommunityDetection). Thetaskof 𝐾-free
communitydetectioninvolvesdeterminingacommunitynumber
𝐾andacommunityaffiliationmatrix C∈R𝑁×𝐾
≥0forall𝑁nodesin
a given attributed graph G={A,X}.
Theobjectiveof 𝐾-freecommunitydetectionistoensurethat
nodes within a community exhibit stronger topological connec-
tionsandsharemorecommoncharacteristicscomparedtonodes
indifferentcommunities,suchasexternalgroundtruthlabels(if
available), connectivity patterns, and node features.
2.2 Empirical Investigations of DGC Methods
Weconductempiricalstudiestoinvestigatetheimpactoftheun-
known number of communities 𝐾for DGC methods.
Firstly,wechoosetheSOTAmodelCCGCasthebasemodel.We
thenreplaceCCGC’s 𝐾-meansclusteringbyDBSCAN[ 9],whichis
adensity-basedclusteringmethodthatdoesnotrelyontheprior
𝐾.Fig.2illustratestheresultsontheCoradataset.Weprojectnode(a)CCGC with 𝐾-means. (b)𝐾-free CCGC with DBSCAN.
Figure 2: T-SNE [ 51] visualization of Cora dataset’s node
representationsbydeepgraphclusteringmethodCCGC[ 57].
Figure3:Communitynumberwiththehighestmodularity
does not match the ground truth 𝐾on Cora.
embeddings on the two-dimensional space via T-SNE [ 51], and we
observe that the vanilla CCGC with 𝐾-means clustering groups
embeddingsinto 𝐾clusters.Atthesametime,CCGCwithDBSCAN
situates nodes on a manifold without distinguishable gaps. This
change poses challenges for DGC methods, as their training proce-
durereliesonclusteringresultsassoftorhardlabels.Consequently,
theoptimizationobjectiveofDGCmethodsvariesacrossepochs,
potentially leading to their collapse. Moreover, hyperparameter
tuning for DBSCAN becomes more challenging, as fine-tuning the
radiusparameterandtheminimumnumberofpointsinDBSCANisconsidereddifficult[
9,10,45].Additionally,eachepochrequiresad-
justingDBSCANsincenodeembeddingshavebeenmodifiedbased
on the previous epoch training. We conclude that in real-worldscenarios where
𝐾is unknown, clustering-based self-supervised
learningmethodsmaycollapseduetouncertaintrainingobjectives.
Existing DGC methods are unable to handle 𝐾-free community
detection tasks with trivial modifications.
Next, we traverse the prior 𝐾of the DGC methods and observe
thechangesintheunsupervisedmodularitymetric.Thisisasearch-
ing strategy mentioned by several DGC methods [ 13,28,41]t o
validatetheirperformanceongraphswithoutknown 𝐾.Ourgoalis
todetermineifthisstrategycaneffectivelycapturereal-worldcom-
munitystructures.WeimplementseveralDGCmethods,namely
DAEGC[ 53],CommDGI[ 61],VGAER[ 41],andCCGC[ 57]ase x-
amples. For the Cora dataset [ 46], we observe that their estimated
community number with the highest modularity does not align
with the ground truth 𝐾. This discrepancy persists even when con-
sidering a range of [2,2×𝐾GT], where𝐾GTis the ground truth
communitynumber.Furthermore,inreal-worldapplicationssuch
as online games, online tests are often employed to collect user
5456KDD ’24, August 25–29, 2024, Barcelona, Spain Chang Liu et al.
activity as the final metric. Online tests typically require days to
gatherreliableresults;real-worldgraphsarelarge-scale,anduser
communities may change over time, rendering grid search on 𝐾
impractical. Therefore, selecting the number 𝐾of communities
with the highest unsupervised modularity index through traversal
and repeated training is neither efficient nor effective. It becomes a
time-consuming process that does not guarantee optimal results.
From these observations, we conclude the findings that:
(1)In real-life scenarios where 𝐾is unknown, clustering-based
self-supervised learning methods can collapse due to uncertain
training objectives.
(2)It is neither efficient nor effective to select the number of com-
munities 𝐾with the highest unsupervised modularity through
traversal and repeated training.
In thefollowing sections, wepropose our DAG method to tackle
this challenging task and overcome the aforementioned issues.
3 DEEP ADAPTIVE AND GENERATIVE
COMMUNITY DETECTION
In this section, we aim to address two challenges of 𝐾-free com-
munitydetection, i.e.,howtodetectcommunitieswithout 𝐾,and
evaluatetheresultsinalow-costandrobustmanner.Wepropose
a general framework, named DAG, to jointly learn node embed-
ding H, community affiliation C, and community number 𝐾.A s
showninFig.4,thekeyinsightofDAGisintroducingaCommu-
nity Affiliation Network (CAN) based generative model instead of
clustering-basedDGC methods,convertingthe non-differentiable
𝐾searching problem to a differentiable one and solving it with
groupsparsity.WealsodesignanEDGEmetrictoconverta 𝐾class
problem into a binary edge classification problem.
3.1 Masked Attribute Reconstruction
In attributed graph community detection, obtaining node repre-
sentations that incorporate structural and semantic aspects is cru-
cial. To achieve this, inspired by recent progress in masked auto-
encoders for node classification [ 20,21], we introduce the Masked
Attribute Reconstruction module, which is trained with a task that
randomly masks attributes and reconstructs them. This process en-
courages the node representation to incorporate both its attributes
and the attributes of its topological neighbors.
For the graph G=(A,X)with node set V, we sample a set of
nodes /tildewideV⊂Vforeachepoch,andreplacetheirattributevectors
with a learnable [Mask] Token X[𝑀]∈R𝐷:
/tildewideX=MASK(X), where /tildewideX𝑖=/braceleftBigg
X[𝑀]𝑣𝑖∈/tildewideV
X𝑖𝑣𝑖∉/tildewideV.(1)
We use two layers of GAT [ 52] as the encoder to encode the
masked graph and generate the node representation matrix H∈
R𝑁×𝐷/prime, where𝐷/primeis the embedding length of each node:
H=Encoder(A,/tildewideX). (2)
Thisembedding Hwillsimultaneouslyperformtwotasks:attribute
reconstruction and community detection. The ReMask trick is em-
ployed to encourage the model’s embedding further to contain##!$#
"#!$#


 $#	! 
  
 
"



"#!$#
##!$# 
""

"" 







 !
 		
	 	

 !
 % $#"



	








	
 	
$#


$#& #


	!$  !"#&
		

	
!	
!

"

	
Figure 4: DAG framework.
  
  	


  	  
 
	 
	 
 	
Figure 5: The Community Affiliation Network.
semantic information about its topological neighborhood:
/tildewideH=MASK(H). (3)
We use two GAT layers as attribute Decoder to output the re-
stored feature matrix:
Z=Decoder(A,/tildewide𝑯). (4)
We introduce the Scaled Cosine Error (SCE) proposed by Graph-
MAE[21].Thisisbecausethefeaturevectorsofattributegraphs
areoftenverysparse,andtheMSElosseasilyconvergestoatrivial
solution of all zeros.
LSCE(X,Z,/tildewideV)=1
|/tildewideV|/summationdisplay.1
𝑣𝑖∈/tildewiderV/parenleftBigg
1−𝑥𝑇
𝑖𝑧𝑖
/bardbl𝑥𝑖/bardbl·/bardbl𝑧𝑖/bardbl/parenrightBigg3
.(5)
Insummary,MaskedAttributeReconstructionlearnsnoderepre-
sentationscombiningtopologicalandsemanticaspects,whichis
essential for the subsequent community affiliation readout.
3.2 Community Affiliation Readout
DAGsimultaneouslylearnsnoderepresentationsandcommunity
affiliationstoenablefurthersearching 𝐾end-to-end.Inspiredby
Community Affiliation Network (CAN), a classical social model
[5,26,64]explaininghowsocialnetworksaregenerated,wedesign
a readout module to model nodes’ affiliation explicitly.
5457DAG: Deep Adaptive and Generative 𝐾-Free Community Detection on Attributed Graphs KDD ’24, August 25–29, 2024, Barcelona, Spain
AsshowninFig.5,CANisaweightedbipartitegraphcontaining
all real nodes and unseen community nodes of a social network.
Eachrealnodeinthesocialnetworkisassociatedwithacommunity
affiliation vector C𝑖∈R𝐾, where𝐾is the number of communities,
and each entry C𝑖,𝑗represents the affiliation strength of node 𝑣𝑖
to the community 𝑗. The CAN model reconstructs the graph’s
adjacencymatrixbasedonthecommunityaffiliations,providing
a differentiable objective for learning the community structure.
When reconstructing the adjacency matrix, the similarity of the
communityaffiliationvectors (C𝑖,C𝑗)ofanodepair (𝑖,𝑗)indicates
the probability of generating an edge 𝑝(𝑖,𝑗)between them:
𝑝(𝑖,𝑗)=𝜎(C𝑖·C𝑇
𝑗), (6)
where𝜎is the sigmoid [36] function.
Theinputembeddingmatrix Hisaugmentedthroughouttraining
and can contain information about its neighbor nodes. Based on
this property, we use a two-layer GCN and a softmax [ 17] function
as the community affiliation readout to output the community
affiliation C∈R𝐾max
≥0of all nodes, where 𝐾maxis the maximum
possible community number.
C=Readout(A,H). (7)
Sincewedonothavetheactualcommunitynumber 𝐾inthe𝐾-free
community detection scenario, we set 𝐾maxto a relatively large
number. The 𝐾maxsetting can be found in Sec. 4.
ThecommunityID 𝐼𝑖ofnode𝑖isthenumberofdigitswherethe
maximumvalueoftheCommunitymatrixexists,whichissimilar
to node classification:
𝐼𝑖=argmax
𝑗C𝑖,𝑗. (8)
Generatingthewholeadjacencymatrixofthenetworkrequiresa
complexity of 𝑂(𝑛2), which is not realistic for large graphs. There-
fore, Bayesian Personalized Ranking (BPR) loss [ 43]i su s edt op r e -
dict each existing edge (𝑖,𝑗)by sampling a negative edge (𝑖,𝑢):
LBPR=−|E|/summationdisplay.1
𝑖=1ln𝜎(C𝑖·C𝑇
𝑗−C𝑖·C𝑇
𝑢), (9)
where|E|is the number of edges.
In summary, the Community Detection Readout module, which
is the main difference between DAG and DGC methods, simultane-
ously learns node representations and community affiliations in an
end-to-endmanner.Thisend-to-endreadoutenablesthedifferen-
tiable searching process, making it a crucial component for 𝐾-free
community detection in attributed graphs.
3.3 Community Number Search
In DGC methods, determining the optimal number of communities
𝐾posesasignificantchallenge,asitisoftenusedasahyperparam-
eter for𝐾-means-like clustering. This makes it difficult to optimize
within the DGC framework. Inspired by traditional community
detection methods such as Louvain [ 4], we propose a differentiable
Community Number Search method that adaptively finds the best
𝐾by gradually merging smaller communities. Our approach is per-
formed on the output layer of the Community Affiliation Readout
module during end-to-end training. This method employs groupsparsity constraints to gradually compress the number of commu-
nities, merging communities with close links and similar attributes.
As a result, our approach enables simultaneous learning of node
representations,communityaffiliations,andcommunitynumbers.
The input of the last layer of Community Readout is denoted as
HC, and the calculation of the Community Matrix Cis given by:
C=ReLU/parenleftBig
ˆAHCW/parenrightBig
, (10)
whereˆAis the normalized adjacency matrix obtained by adding
self-loops and row-normalizing the original adjacency matrix A.
Thematrix Whasdimensions 𝑑×𝑘max,where𝑑isthelengthofthe
input embedding, i.e.,column number of HC. The ReLU activation
functionisappliedelement-wisetothematrixproduct ˆAHCW.The
group sparsity constraint based on L2,1norm is defined as:
LGS=/bardblW𝑇/bardbl2,1=𝑘max/summationdisplay.1
𝑗=1||W:,𝑗||𝑝=2=𝑘max/summationdisplay.1
𝑗=1/parenleftBigg𝑑/summationdisplay.1
𝑖=1w2
𝑖,𝑗/parenrightBigg1/2
.(11)
Lemma 1 (group sparsity). The columns of Community Matrix
Care sparse, i.e., some of its column vectors should be zero vectors.
Fromthelemmaabove,weknowthat LGSconstrainthastwo
main benefits: (1) it makes Cmore sparse, improving the confi-
dence of community readout, and (2) it concentrates the output on
columns of C, allowing for an adaptive number of communities.
Additionally, this constraint only affects the parameters of the last
layer without influencing the generation of embeddings. The proof
of this lemma can be found in Appendix A.
For the community ID vector 𝐼∈Z𝑁for all𝑁nodes in the
graph,ourgroupsparsityensuresthattheoutputrangewillshrink
from[1,𝐾max]to a smaller range. In other words, the output is the
number of communities to which at least one node belongs:
𝐾=|{𝑖:∃𝑣∈V,𝐼(𝑣)=𝑖}|. (12)
Inconclusion,theproposedgroupsparsitymethodadaptsthe
numberofcommunitiesduringend-to-endtraining,addressingthe
challenge of searching 𝐾for𝐾-free community detection.
Optimization objective. The final total training loss is:
L=LSCE+𝛼LBPR+𝛽LGS, (13)
where the 𝛼and𝛽are manually set hyperparameters. Empirically,
we find that 𝛼and𝛽are stable across several public datasets. In
otherwords,wedon’tneedtofine-tunethemwhenitcomestoa
new dataset. Please refer to Appendix C for more details.
3.4 EDGE Metric
There are two-fold challenges when evaluating 𝐾-Free community
detection methods. First, accurate community labels for real-world
social networks are unavailable. Second, if the number of detected
communities 𝐾differsfromthegroundtruth 𝐾GT,manyexisting
metrics (e.g. F1 score and accuracy) are infeasible even if we know
the ground truth labels for public datasets. To address this, we
propose a supervised edge metric suitable for partially known real-
world networks and public datasets with ground truth labels. This
metric converts the community detection problem into a binary
classification problem of whether to cut an edge off.
5458KDD ’24, August 25–29, 2024, Barcelona, Spain Chang Liu et al.
Wetreattheedgesasinter-communityedgesandintra-community
edges.Let E∗
interdenotethesetofinter-communityedges,and E∗
intra
denotesthe setof intra-communityedges.Wecan obtainalledge
labels for public cases based on node community labels.
E∗
inter={(𝑖,𝑗)|A𝑖,𝑗=1,𝐼∗(𝑖)≠𝐼∗(𝑗)},
E∗
intra={(𝑖,𝑗)|A𝑖,𝑗=1,𝐼∗(𝑖)=𝐼∗(𝑗)},(14)
where𝐼∗(𝑖)denotes the ground truth label of 𝑖-th node. After com-
munity detection, we generate the set predicted EinterandEintra
withoutput 𝐼(𝑖)likeEq.(14).Tobalancethebinarytask,wecom-
putetheF1scorewhere E∗
intraisthepositiveset.Inotherwords,the
EDGE metric measures whether connected node pairs that belong
tothesamecommunitycanbeplacedinthesamedetectedcommu-
nity,whilenodepairsthatdonotbelongtothesamecommunity
can be placed in different detected communities:
EDGE=2·|E∗
intra∩Eintra|
|E∗
intra∩Eintra|+|E∗
inter∩Eintra|·|E∗
intra∩Eintra|
|E∗
intra∩Eintra|+|E∗
intra∩Einter|
|E∗
intra∩Eintra|
|E∗
intra∩Eintra|+|E∗
inter∩Eintra|+|E∗
intra∩Eintra|
|E∗
intra∩Eintra|+|E∗
intra∩Einter|.(15)
Inreal-worldscenarios,wecanconsidernodepairswithhigh-
confidence interaction (e.g., friends with the highest intimacy or
mentor-mentee relationships) as intra-community edges and no
historical interaction as inter-community edges.
The EDGE metric effectively evaluates community detection
methods on public datasets with known ground truth labels and
real-worldnetworkswithpartiallyknownedgeinformation.This
provides a practical approach to assess community detection al-
gorithmperformanceinreal-worldscenarioswheregroundtruth
community labels are difficult to obtain. Additionally, we find that
the widely used NMI is sensitive to the 𝐾detected and can overes-
timate the performance of trivial results; please refer to Sec. 4.2.1.
4 EXPERIMENTS ON PUBLIC DATASETS
4.1 Experimental Settings
Toensurethefairnessandvalidityofourexperimentalsetup,we
highlight several key aspects of our experiments.
Datasets. WeevaluateDAGonfivepublicdatasets(Cora[ 46],Cite-
Seer [46], PubMed [ 46], Wiki [56], and CoraFull [ 47]). The number
of nodes (#Node), edges (#Edge), feature dimensions (#Features),
communities (#Comm., if available), and inter-community edges
(#Cut) are shown in Table 2.
Compared methods. We compare our DAG with four traditional
algorithms, i.e.,Greedy Q [ 8], Louvain [ 4], LPA [42], and Hanp
[27]. We also implement five SOTA DGC methods, i.e.,DAEGC
[53], CommDGI [61], AGCN [40], HSAN [35], and CCGC [57].
Training procedure. For each epoch, we sample 50% (75% for
PubMed) of the nodes in the dataset for masking and recovering
themaskednodefeatures.Every50epochs,weevaluatethecom-
munities detected by DAG using unsupervised metrics. As we aim
to address the community detection in an unsupervised manner,
we select the checkpoint with the highest product of two unsuper-
visedmetrics, i.e.,modularityandCalinskiHarabaszscoreasthe
final result, and calculate its NMI and EDGE Metric. More detailed
settings can be found in Appendix B.#Nodes #Edges #Features #Comm. #Cuts
Cora 2,708 5,278 1,433 7 1,011
CiteSeer 3,327 4,552 3,703 6 1,212
PubMed 19,717 44,324 500 3 8,760
Wiki 2,405 8,261 4,973 17 2,590
CoraFull 19,793 63,421 8,710 70 28,023
GAME 209,794 2,874,396 85 Unknown Partially Known
Table 2: Dataset summary.
Fair comparison. One significant difference between DAG and
DGC methods is that DAG does not require specifying the number
ofcommunities 𝐾asapriori,whileDGCmethodsdo.Theresearch
questionweaimtoaddressishowtoperformcommunitydetection
without prior knowledge of 𝐾. Therefore, for a fair comparison,
weadoptthesamestrategyforfinding 𝐾forbothDAGandDGC
methods. Specifically, we choose the value of 𝐾that maximizes the
product of the unsupervised modularity and the Calinski Harabasz
score. This serves as a straightforward approach to balance the
topological and semantic similarity of the communities.
Furthermore, to ensure a fair comparison, we set the search
rangeforthenumberofcommunitiesto [2,2×𝐾GT]foralldeep
learning-based methods, where 𝐾GTis the ground truth number
of communities in each dataset, except for CoraFull. Althoughour DAG method can search within the range of
[2,2×𝐾GT]for
CoraFull,theDGCmethodsrequireiteratingoverallpossiblevaluesof
𝐾,makingitimpracticaltosearchoversuchalargerange( 𝐾GT=
70)forCoraFull.Therefore,forCoraFull,wesetthesearchrange
for both DAG and the DAG methods to [𝐾GT−10,𝐾GT+10].
Metric.Following the SOTA DGC methods [ 35,40,53,57,61],
we evaluate methods with Normalized Mutual Information (NMI)
[48] and our proposed EDGE metric. As mentioned earlier, prior
knowledgeofthenumberofcommunities 𝐾,whichisoftendiffi-
cult to obtain in real scenarios such as user communities in GAME,
is evaluated using the EDGE metric of DAG and the best SOTA
method. We perform an online test for recommendation tasks dur-ing a one-week game event. In the online test setting, we test how
the detected communities help to encourage user interactions.
4.2 Results in Public Datasets
4.2.1 Main Results. We analyze the performance of our proposed
DAG method in comparison with traditional community detection
algorithms and state-of-the-art DGC methods in Table 3. DAGoutperforms all DGC methods in terms of both NMI and EDGE
metricsacrossallpublicdatasets,demonstratingitseffectivenessin
handlingtheunknowncommunitydetectionproblem.CCGCisa
strong baseline for comparison in real-world scenario experiments.
Please refer to Appendix D for more detailed results, including
standard deviation and unsupervised metrics.
TheEDGEmetric,introducedinthispaper,provestobearobust
evaluation measure for varying community numbers. Note that
when the community number is set equal to the node number (the
trivialNULLcase),theexistingNMImetrictendstooverestimate
theperformance,evenachievingthebestNMIinCoraFull.However,theEDGEmetricdoesnotsufferfromthisissue,asitassignsavalue
of 0 to all trivial NULL cases, effectively differentiating between
meaningful community structures and trivial cases.
5459DAG: Deep Adaptive and Generative 𝐾-Free Community Detection on Attributed Graphs KDD ’24, August 25–29, 2024, Barcelona, Spain
Dataset Cora (K=7) CiteSeer (K=6) PubMed (K=3) Wiki (K=17) CoraFull (K=70)
Metric NMI EDGE K NMI EDGE K NMI EDGE K NMI EDGE K NMI EDGE K
Traditional
CDGreedy Q 0.4673 0.8864 106 0.3378 0.8395 488 0.2217 0.8584 114 0.4358 0.8478 90 0.4075 0.7290 499
Louvain 0.4468 0.8787 104 0.3243 0.8321 469 0.2062 0.8359 39 0.4559 0.8583 64 0.4792 0.7300 404
Hanp 0.4010 0.7508 553 0.3402 0.7393 508 0.1770 0.7126 2037 0.4995 0.7135 885 0.5560 0.6670 2113
LPA 0.4142 0.7871 481 0.3377 0.7530 959 0.1804 0.7329 1924 0.4858 0.8410 396 0.5664 0.6705 2328
Trivial NULL 0.3762 0 2708 0.3555 0 3327 0.1937 0 19717 0.4846 0 2405 0.5763 0 19793
DGCDAEGC 0.4587 0.8714 10.0 0.2907 0.8302 11.5 0.1784 0.8422 4.1 0.2200 0.7235 25.0 0.4503 0.6882 60.1
CommDGI 0.3192 0.8564 9.4 0.2911 0.8269 11.1 0.1892 0.8496 4.9 0.1839 0.7373 31.1 0.4467 0.6756 60.3
AGCN 0.2172 0.8297 10.6 0.3160 0.8316 8.2 0.2275 0.8504 3.8 0.1962 0.7431 22.6 0.4721 0.6955 74.2
HSAN 0.4497 0.8775 4.8 0.3128 0.8413 5.1 OOM OOM OOM 0.4131 0.8375 29.5 OOM OOM OOM
CCGC 0.5051 0.8887 8.5 0.4090 0.8447 11.9 0.1922 0.8520 4.1 0.4079 0.8467 21.8 0.4898 0.7047 73.6
Ours DAG 0.5171 0.9004 7.40.4118 0.8677 6.40.2828 0.8938 3.4 0.4320 0.8629 15.7 0.4932 0.7311 68.4
Table 3: Average result of supervised metrics and community number on public datasets. Trivial NULL is the case where
everysinglenodeistreatedasacommunity(i.e., 𝐾=𝑁).OOMmeansOut-of-Memoryerror. Underline showsthebestDGC
performance. Bold is the best performance for all methods.
Case Mask Sparsity Cora CiteSeer PubMed Wiki CoraFull
1 0.8649 0.8182 0.8092 0.8386 0.7002
2/enc-33 0.8966 0.8541 0.8735 0.8584 0.7193
3 /enc-330.8803 0.8374 0.8652 0.8468 0.7256
DAG /enc-33/enc-33 0.9004 0.8677 0.8938 0.8629 0.7311
Table4:AverageEDGEmetricofmaskattributegeneration
(Mask) and group sparsity (Sparsity) on public datasets as
ablation studies.
Methods EDGE Click Rate Team Rate Success Rate
Baseline N/A 2.59% 76.72% 2.00%
CCGC 0.82 2.66% (+2.93%) 76.08% (-0.83%) 2.03% (+2.08%)
Ours 0.88 2.72% (+4.90%) 80.10% (+4.41%) 2.18% (+9.44%)
Table 5: Resulton thereal-world GAMEgraph. Therelative
changes compared to the Baseline are in parentheses.
In summary, Table 3 shows that our proposed DAG method can
effectively handle the 𝐾-free community detection problem and
outperform SOTA DGC methods, with the EDGE metric serving as
a robust evaluation measure.
4.2.2 Ablation Study. We conduct an ablation study to investigate
theindividualcontributionsofthemaincomponentsintheDAG
model, focusing on the average EDGE metric across the five public
datasets. We consider four cases: Case 1: Neither mask attribute
generation (Mask) nor group sparsity (Sparsity) is applied. Case
2: Onlymask attributegeneration (Mask)is applied. Case 3: Only
group sparsity (Sparsity) is applied. DAG: Both mask attribute
generation (Mask) and group sparsity (Sparsity) are applied.
The results in Table 4 show that the DAG model’s performance
improves with each component. Introducing mask attribute gener-
ation(Case2)improvestheEDGEmetric,indicatingitsimportance
incapturing nodesemanticinformation. Applyinggroupsparsity
(Case 3) also results in better performance, highlighting its role in
adaptively searching for the optimal number of communities.
ThefullDAGmodelachievesthehighestEDGEmetricvalues
acrossalldatasets,demonstratingtheeffectivenessofcombining
thesecomponentsinaddressingthe 𝐾-freecommunitydetectionFigure 6: The convergence analysis across different datasets.
problem.Insummary,theablationstudyconfirmstheimportanceof
both mask attribute generation and group sparsity components in
theDAGmodel,astheircombinationleadstothebestperformance
in terms of the EDGE metric across all public datasets.
4.2.3 Convergence Analysis. We find that our DAG method con-
vergewellacrossdifferentdatasetsand hyper-parametersettings.
TofurthershowtheconvergenceofDAG,weconductthefollowing
experiments.
Convergence on different datasets. We have conducted addi-
tionalexperimentstoanalyzeconvergence.WerunourDAGonall
publicdatasetswith5trials.WetrainourDAGmodelswith1000
epochs for each trail and record the loss for each epoch without
cherry-picking. Finally, we compute the average value (mean) and
standard deviation (std) per epoch among the 5 trials. As shown
in Fig. 6, we plot the average loss in a line and fulfill the [mean
- std, mean + std] with shadow. To make the standard deviations
clear,wealsozoomedfigurethatonlyincludesthelossdistribution
for the last 600 epochs. The results demonstrates that DAG modelconverges well for different public datasets.
Convergenceondifferentdatasets. Tofurtherdrawtheconcern
about DAG’s convergence, we also provide the Cora dataset’s con-
vergencecurvefordifferentscalesofourproposedhyper-parameters,
i.e.,𝛼and𝛽.Fig.7showsthatwetunethetwohyper-parameters
5460KDD ’24, August 25–29, 2024, Barcelona, Spain Chang Liu et al.
Figure 7: The convergence analysis across different hyper-
parameter settings on Cora dataset.
inalogscale.ThefiguredemonstratesthatDAG’sconvergenceis
stable with different hyper-parameter settings.
4.2.4 Case Study. We provide a case study on the Cora dataset
toofferinsightintohowDAGsolvesthechallenging 𝐾-freecom-
munitydetectionproblem.Fig.8andFig.9showthecommunity
distribution of DAG before and after applying group sparsity. Both
models result in relatively uniformly sized communities. However,
group sparsity helps DAG merge the detected communities and
outputsomeemptycommunitiestosearch 𝐾inanend-to-endman-
ner.Fig.8alsoillustratesthatmostcommunitieshavehighpurity
withrespecttothegroundtruth; however, the largegroundtruth
communities are spliced into several detected communities. Forexample,thelabelid3isthedominantidincommunityid=7,11,
and 13. As shown in Fig. 9, with the help of group sparsity, the
communitiesaremergedintofewercommunities,andDAGmerges
communitieswithdenselyconnectedandsemanticallysimilarcom-
munities. As a result, most of the detected communities can better
fit the ground truth community.
However,aswecansee,thesmallgroundtruthcommunity(label
id=6)isnotdetectedbyDAGwithoutgroupsparsity.Consequently,
group sparsity fails to merge into a larger community. This alsoshows that DAG has the potential to improve with a deeper un-
derstanding of real-world communities. In summary, DAG demon-
stratesgoodperformanceinsolvingthe 𝐾-freecommunitydetec-
tionproblemandcanbefurtherenhancedwithdeeperinsightsinto
real-world community structures.
5 DEPLOYMENT
Dataset. Since we want to tackle the 𝐾-free community detection
problem in real-world applications, we evaluate DAG and the best
SOTAmethodonaTencentmobile massivelymultiplayeronlinerole-
playing game (MMORPG) dataset [22,29–31,58–60,62], referred
toasGAME.ThestatisticsofGAMEcanbefoundinTable2.We
construct the GAME dataset as follows: (i)eachdaily active user
(DAU)in the game is represented as a node, with the in-game
features as attributes, such as the preference for each gameplay
styleinthegame; (ii)anedgebetweentwonodesindicatesthatthe
twousershavefriendlyrelationships,suchasfriends,mentors,andmentees,amongothers.Wetransformthisgraphintoanundirected,
unweighted,andhomogeneousformtoenableafaircomparison
using the EDGE metric.
Competitors and parameter settings. We select CCGC as the
best SOTA DGC method for comparison with our DAG. For this
comparison, we directly use the searched 𝐾value of DAG to train
CCGC.Themaximumcommunitynumber 𝐾maxissetto256.We
providebothofflineandonlineexperimentalresults.Thebesthy-
perparameters of DAG and CCGC from the public CoraFull dataset
are used, as its scale is most similar to the GAME dataset. The
detailed parameters can be found in Appendix B.
Offline experiments. For offline experiments, we use mentor-
mentee relationships as positive examples in the friend network
and friends with no intimacy value ( i.e., no historical interactions)
as negative examples. A higher EDGE score in offline metrics indi-
cates that the algorithm assigns more intimate friends to the same
community and less intimate friends to different communities. It is
worthmentioningthatwedonotprovideanyinformationabout
intimacyormentor-menteerelationshipsduringtraining,ensuring
that the graph remains unweighted and homogeneous.
Online experiments. For online experiments, we collect a week’s
data from an in-game event where players invite friends to form
teamsbasedonsystemrecommendations.Theeventunlocksspecial
tasks for team members, offering rewards. We provide an in-game
module to recommend an ordered list of friends to each player.
When player 𝑢accesses the friend recommendation module in
GAME,𝑢sees six recommended friends each time. This generates
anexposurerecordintherecommendationlogs,and 𝑢candecide
toclickonafriendornot.If 𝑢isnotinterestedinthecurrentfriend
list,𝑢can switch to the next recommended result. User 𝑢can click
ononlyonefriendperday.Onceuser 𝑢clicksonarecommended
friend𝑣, it sends a team request and generates a clickrecord in the
recommendationlogs.Therequestrequiresapproval;theclicked
friend𝑣candecidetoacceptorrejectit.If 𝑢and𝑣successfullyform
a team, the recommendation module generates a successrecord.
We evaluate DAG, CCGC, and the baseline in the friend recom-
mendation task using three metrics: (i)Click Rate, which is the
proportion of clickfriends among exposurerecords;(ii)Team Rate,
the proportion of successteams among clickinvitations; and (iii)
overall Success Rate, the proportion of successteams among expo-
surerecords. The overall Success Rate is the product of the Click
RateandtheTeamRateafterinvitationsaresent, i.e.,SuccessRate =
Click Rate ×Team Rate. We compare the effects of three strategies:
•Baseline: Rank all friends based on their historical team count.
•DAG: First recall friends in the same community determined by
DAG, then rank by historical team formation count.
•CCGC: First recall friends in the same community determined
by CCGC, then rank by historical team formation count.
Duringtheweek-longevent,wetraincommunitydetectionmod-
els and output their friend ranking results every day. Each DAUis
randomlyassignedwithanalgorithmthatgeneratestherecommen-
dation results. We finally take the average metrics for one week to
ensureafaircomparison.Theresults,asshowninTable5,reveal
that DAG outperforms the best SOTA method by 7.35%, 1.97%, and
5.24%fortheoverallsuccessrate,clickrate,andteamformationsuc-
cessrate,respectively.Thissuperioronline performanceindicates
5461DAG: Deep Adaptive and Generative 𝐾-Free Community Detection on Attributed Graphs KDD ’24, August 25–29, 2024, Barcelona, Spain
Figure 8: The ground truth label distribution of detected
communities of DAG without group sparsity.
Figure 9: The ground truth label distribution of detected
communities of DAG with group sparsity.
that DAG can detect more meaningful user communities, i.e., users
within the same community have a higher tendency to interact.
Furthermore, it is observed that methods with higher EDGE
scoresalsoleadtoahigherinteractiontendencyamongusers.This
provides an intuition that the EDGE metric, introduced in this
paper, serves as a reliable indicator of the quality of community
detection in terms of promotinguser interactions. As a result, the
EDGE metric not only evaluates the performance of communitydetection methods but also captures the practical impact of the
detected communities on user interactions in real-world scenarios.
Insummary,theresultsoftheonlineexperimentdemonstrate
the effectiveness of the DAG method in detecting meaningful user
communitiesandpromotinguserinteractions.TheEDGEmetric
serves as a robust evaluation measure, highlighting the advantages
of the DAG method over existing SOTA in real-world applications,
i.e., friend recommendation tasks in online games.
6 RELATED WORK
This section briefly reviews related work in traditional community
detection methods, deep graph clustering, and masked attribute
reconstruction.
Traditionalcommunitydetectionmethods. Traditionalcom-
munitydetectionalgorithmsarebasedonoptimizingmodularity
and other quality metrics, such as the greedy method [ 8,18] and
Louvain [ 4]. Label Propagation Algorithm (LPA) based methods
[27,42] propagates community labels through the graph. These
traditionalmethodsinitiallyassumealargemaximumnumberofcommunities and then merge small communities to optimize unsu-
pervisedmetrics,findinganadaptivecommunitynumber 𝐾[24].
However, these methods do not take into account the node at-
tributes,whichareessentialforattributedgraphs[ 37],leadingto
sub-optimal results and biased community structures. Probabilistic
graphicalmodel-basedmethods,suchasSBM[ 19]andMMSB[ 1]
also can not automatically determine the number of communities.
Deep graph clustering (DGC). Deep Graph Clustering (DGC)
[13,16,24,34,41]methodsemployGraphNeuralNetworks(GNNs)
and unify the learning from both topological structure and node
semanticattributesbylearning“clustering-friendly”nodeembed-
dings[30,31,38],leadingtosuperiorperformanceincommunity
detection tasks. Among these methods, DAEGC [ 53] uses an atten-
tion network [ 52] and a self-training graph clustering process that
jointlyoptimizesgraphembeddingsandclustering.CommDGI[ 61]
focuses on community detection with a mutual information mech-
anismandaclusteringlayer.AGCN[ 40]employsfusionmodules
tofusenodeattributefeaturesandtopologicalgraphfeaturesdy-
namically.HSAN[ 35]isacontrastiveDGCmethodthatintroduces
a comprehensive similarity measure criterion and a sample weigh-
ing strategy. CCGC [ 57] mines intrinsic supervision information
from high-confidence clustering results and constructs positive
and negative samples. However, they need prior knowledge about
community number 𝐾, which precludes real-world application.
Maskedattributereconstruction. GraphMAEs[ 20,21]employ
masked attribute reconstruction to learn node embeddings, achiev-
ing the SOTA in downstream node classification tasks.
In this work, we propose DAG to bridge the gap between tra-
ditional and deep learning-based community detection methods.
OurapproachemploysadifferentiableCommunityNumberSearch
method, inspired by the traditional community detection methods,
toadaptivelyfindthebest 𝐾duringend-to-endtraining.Wealso
introduceaMaskedAttributeReconstructionmoduletolearnnode
representations. The proposed method effectively addresses the
challenges of 𝐾-free community detection in attributed graphs.
7 CONCLUSION
In this paper, we address 𝐾-free community detection in attributed
graphsbyproposinganoveldeeplearning-basedframework,Deep
AdaptiveandGenerative(DAG).DAGdetectsnetworkcommunities
and searches for the community number 𝐾end-to-end without
requiring prior 𝐾. We also introduced the EDGE metric, which
is low-cost and robust to varying 𝐾. Our experiments on public
datasetsandareal-worldsocialnetworkdemonstratedthatDAG
consistentlyoutperformsSOTADGCcompetitors.Inconclusion,
DAGoffersapromisingsolutionfor 𝐾-freecommunitydetection,
with the EDGE metric serving as a reliable evaluation measure.
ACKNOWLEDGEMENT
This work is supported by the National Nature Science Foundation
of China under Grant 62176155 and Shanghai Municipal Science
and Technology Major Project under Grant 2021SHZDZX0102.
5462KDD ’24, August 25–29, 2024, Barcelona, Spain Chang Liu et al.
REFERENCES
[1]EdoardoM.Airoldi,DavidM.Blei,StephenE.Fienberg,andEricP.Xing.2008.
Mixed Membership Stochastic Blockmodels. In NIPS. Curran Associates, Inc.,
33–40.
[2]Wendong Bi, Bingbing Xu, Xiaoqian Sun, Zidong Wang, Huawei Shen, and
Xueqi Cheng. 2022. Company-as-Tribe: Company Financial Risk Assessment
on Tribe-Style Graph with Hierarchical Graph Neural Networks. In KDD. ACM,
2712–2720.
[3]Wendong Bi, Bingbing Xu, Xiaoqian Sun, Easton Li Xu, Huawei Shen, and Xueqi
Cheng. 2023. Predicting the Silent Majority on Graphs: Knowledge Transferable
Graph Neural Network. In WWW. ACM, 274–285.
[4]Vincent D. Blondel, Jean-Loup Guillaume, Renaud Lambiotte, and Etienne Lefeb-
vre. 2008. Fast unfolding of communities in large networks. Journal of Statistical
Mechanics: Theory and Experiment 2008 (2008), 10008.
[5]Ronald L Breiger. 1974. The duality of persons and groups. Social forces 53, 2
(1974), 181–190.
[6]TadeuszCalińskiandJerzyHarabasz.1974.Adendritemethodforclusteranalysis.
Communications in Statistics-theory and Methods 3, 1 (1974), 1–27.
[7]Tanmoy Chakraborty, Ayushi Dalmia, Animesh Mukherjee, and Niloy Ganguly.
2017. Metrics for Community Analysis: A Survey. ACM Comput. Surv. 50, 4
(2017), 54:1–54:37.
[8]AaronClauset,MarkE.J.Newman,andCristopherMoore.2004. Findingcom-
munity structure in very large networks. Physical review. E, Statistical, nonlinear,
and soft matter physics 70 6 Pt 2 (2004), 066111.
[9]Martin Ester, Hans-Peter Kriegel, Jörg Sander, and Xiaowei Xu. 1996. A Density-
Based Algorithm for Discovering Clusters in Large Spatial Databases with Noise.
InKDD. AAAI Press, 226–231.
[10]AdilFahad,NajlaaAlshatri,ZahirTari,AbdullahAlamri,IbrahimKhalil,AlbertY.
Zomaya, Sebti Foufou, and Abdelaziz Bouras. 2014. A Survey of Clustering
Algorithms for Big Data: Taxonomy and Empirical Analysis. IEEE Trans. Emerg.
Top. Comput. 2, 3 (2014), 267–279.
[11]JavierO.Garcia,ArianAshourvan,SarahMuldoon,JeanM.Vettel,andDanielleS.
Bassett.2018. ApplicationsofCommunityDetectionTechniquestoBrainGraphs:
AlgorithmicConsiderationsandImplicationsforNeuralFunction. Proc.IEEE 106,
5 (2018), 846–867.
[12]MichelleGirvanandMarkE.J.Newman.2001. Communitystructureinsocial
andbiologicalnetworks. ProceedingsoftheNationalAcademyofSciencesofthe
United States of America 99 (2001), 7821 – 7826.
[13]Xiaotian Han, Zhimeng Jiang, Ninghao Liu, Qingquan Song, Jundong Li, and
XiaHu.2022. GeometricGraphRepresentationLearningviaMaximizingRate
Reduction. (2022), 1226–1237.
[14]JohnA.HartiganandM.Anthony.Wong.1979. Ak-meansclusteringalgorithm.
[15]TrevorHastie, RobertTibshirani, etal .2009.Theelements ofstatistical learning:
data mining, inference, and prediction.
[16]Dongxiao He, Yue Song, Di Jin, Zhiyong Feng, Binbin Zhang, Zhizhi Yu, and
Weixiong Zhang. 2020. Community-CentricGraph Convolutional Network for
Unsupervised Community Detection. In IJCAI. ijcai.org, 3515–3521.
[17]Geoffrey E. Hinton, Simon Osindero, and Yee Whye Teh. 2006. A Fast Learning
Algorithm for Deep Belief Nets. Neural Comput. 18, 7 (2006), 1527–1554.
[18]Qirong Ho, Wenqing Lin, Eran Shaham, Shonali Krishnaswamy, The Anh Dang,
Jingxuan Wang, Isabel Choo Zhongyan, and Amy She-Nash. 2016. A Distributed
GraphAlgorithmforDiscoveringUniqueBehavioralGroupsfromLarge-Scale
Telco Data. In CIKM. ACM, 1353–1362.
[19]PaulWHolland,KathrynBlackmondLaskey,andSamuelLeinhardt.1983. Sto-
chastic blockmodels: First steps. Social networks 5, 2 (1983), 109–137.
[20]ZhenyuHou, YufeiHe,Yukuo Cen,XiaoLiu, YuxiaoDong,Evgeny Kharlamov,
and Jie Tang. 2023. GraphMAE2: A Decoding-Enhanced Masked Self-Supervised
Graph Learner. In WWW. ACM, 737–746.
[21]Zhenyu Hou, Xiao Liu, Yukuo Cen, Yuxiao Dong, Hongxia Yang, Chunjie Wang,
andJieTang.2022. GraphMAE:Self-SupervisedMaskedGraphAutoencoders.In
KDD. ACM, 594–604.
[22]Shixun Huang, Wenqing Lin, Zhifeng Bao, and Jiachen Sun. 2022. Influence
MaximizationinReal-WorldClosedSocialNetworks. Proc.VLDBEndow. 16,2
(2022), 180–192.
[23]DiJin,MengGe,LiangYang,DongxiaoHe,LongbiaoWang,andWeixiongZhang.
2018. IntegrativeNetworkEmbeddingviaDeepJointReconstruction.In IJCAI.
ijcai.org, 3407–3413.
[24]Di Jin, Zhizhi Yu, Pengfei Jiao, Shirui Pan, et al .2021. A Survey of Commu-
nityDetectionApproaches:FromStatisticalModelingtoDeepLearning. IEEE
Transactions on Knowledge and Data Engineering 35 (2021), 1149–1170.
[25]MohammadRezaKeyvanpour,MehrnoushBaraniShirzad,andMaryamGhaderi.
2020. AD-C:anewnodeanomalydetectionbasedoncommunitydetectionin
social networks. Int. J. Electron. Bus. 15, 3 (2020), 199–222.
[26]Silvio Lattanzi and D. Sivakumar. 2009. Affiliation networks. In STOC. ACM,
427–434.
[27]Ian X. Y. Leung, Pan Hui, Pietro Lio’, and Jon A. Crowcroft. 2008. Towards
real-timecommunitydetectioninlargenetworks. Physicalreview.E,Statistical,
nonlinear, and soft matter physics 79 6 Pt 2 (2008), 066107.[28]Peiyan Li, Honglian Wang, Jianyun Lu, Qinli Yang, and Junming Shao. 2020.
Community Detection with Local Metric Learning. (2020), 312–321.
[29]Wenqing Lin. 2019. Distributed Algorithms for Fully Personalized PageRank on
Large Graphs. In WWW. ACM, 1084–1094.
[30]Wenqing Lin. 2021. Large-ScaleNetwork Embedding in Apache Spark.In KDD.
ACM, 3271–3279.
[31]Wenqing Lin, Feng He, Faqiang Zhang, Xu Cheng, and Hongyun Cai. 2020.
InitializationforNetworkEmbedding:AGraphPartitionApproach.In WSDM.
ACM, 367–374.
[32]Fanzhen Liu, Shan Xue, Jia Wu, Chuan Zhou, Wenbin Hu, Cécile Paris, Surya
Nepal,JianYang,andPhilipS.Yu.2020. DeepLearningforCommunityDetection:
Progress, Challenges and Opportunities. In IJCAI.
[33]Jun Liu, Shuiwang Ji, and Jieping Ye. 2009. Multi-Task Feature Learning Via
Efficient l2, 1-Norm Minimization. In UAI. 339–348.
[34]Yue Liu, Jun Xia, Sihang Zhou, Siwei Wang, Xifeng Guo, Xihong Yang, Ke Liang,
Wenxuan Tu, Stan Z. Li, and Xinwang Liu. 2022. A Survey of Deep Graph
Clustering: Taxonomy, Challenge, and Application. (2022).
[35]Yue Liu, Xihong Yang, Sihang Zhou, Xinwang Liu, Zhen Wang, Ke Liang, Wenx-
uan Tu, Liang Li, Jingcan Duan, and Cancan Chen. 2023. Hard Sample Aware
Network for Contrastive Deep Graph Clustering. In AAAI. AAAI Press, 8914–
8922.
[36]Warren S. McCulloch and Walter Pitts. 1990. A logical calculus of the ideas
immanent in nervousactivity. Bulletin ofMathematical Biology (1990), 99–115.
[37]Miller McPherson, Lynn Smith-Lovin, and James M. Cook. 2001. Birds of a
Feather: Homophily in Social Networks. Review of Sociology (2001), 415–444.
[38]Namyong Park, Ryan A. Rossi, Eunyee Koh, Iftikhar Ahamath Burhanuddin,
SungchulKim,FanDu,NesreenK.Ahmed,andChristosFaloutsos.2022. CGC:
Contrastive Graph Clustering for Community Detection and Tracking. CoRR
abs/2204.08504 (2022).
[39]Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang,
ZacharyDeVito,ZemingLin,AlbanDesmaison,LucaAntiga,andAdamLerer.
2017. Automatic differentiation in PyTorch. (2017).
[40]ZhihaoPeng,HuiLiu,YuhengJia,andJunhuiHou.2021. Attention-drivenGraph
Clustering Network. In ACM Multimedia. ACM, 935–943.
[41]Chenyang Qiu, Zhaoci Huang,Wenzhe Xu,and Huijia Li. 2022. VGAER: graph
neuralnetworkreconstructionbasedcommunitydetection. CoRRabs/2201.04066
(2022).
[42]Usha Nandini Raghavan, Réka Albert, et al .2007. Near linear time algorithm to
detectcommunitystructuresinlarge-scalenetworks. Physicalreview.E,Statistical,
nonlinear, and soft matter physics 76 3 Pt 2 (2007), 036106.
[43]SteffenRendle,ChristophFreudenthaler,ZenoGantner,andLarsSchmidt-Thieme.2009. BPR:BayesianPersonalizedRankingfromImplicitFeedback.In UAI,JeffA.
Bilmes and Andrew Y. Ng (Eds.).
[44]Venu Satuluri, Yao Wu, Xun Zheng, Yilei Qian, Brian Wichers, Qieyun Dai,
Gui Ming Tang, Jerry Jiang, and Jimmy Lin. 2020. SimClusters: Community-
Based Representations for Heterogeneous Recommendations at Twitter. In KDD.
ACM, 3183–3193.
[45]Erich Schubert, Jörg Sander, Martin Ester, Hans-Peter Kriegel, and Xiaowei
Xu. 2017. DBSCAN Revisited, Revisited:Why and HowYouShould (Still) Use
DBSCAN. ACM Trans. Database Syst. 42, 3 (2017), 19:1–19:21.
[46]PrithvirajSen,GalileoNamata,MustafaBilgic,LiseGetoor,etal .2008. Collective
Classification in Network Data. In The AI Magazine.
[47]Oleksandr Shchur, Maximilian Mumme, Aleksandar Bojchevski, and Stephan
Günnemann. 2018. Pitfalls of Graph Neural Network Evaluation. CoRR
abs/1811.05868 (2018).
[48]Alexander Strehl and Joydeep Ghosh. 2002. Cluster Ensembles — A Knowledge
ReuseFrameworkforCombiningMultiplePartitions. J.Mach.Learn.Res. (2002).
[49]XingSu,ShanXue,FanzhenLiu,JiaWu,JianYang,ChuanZhou,etal .2021. A
Comprehensive Survey on Community Detection with Deep Learning. IEEE
transactions on neural networks and learning systems PP (2021).
[50]FeiTian,BinGao,QingCui,EnhongChen,andTie-YanLiu.2014. LearningDeep
Representations for Graph Clustering. In AAAI. AAAI Press, 1293–1299.
[51]LaurensVanderMaatenandGeoffreyHinton.2008. Visualizingdatausingt-SNE.
Journal of machine learning research (2008).
[52]Petar Velickovic,Guillem Cucurull,Arantxa Casanova,Adriana Romero,Pietro
Liò, and Yoshua Bengio. 2017. Graph Attention Networks. CoRRabs/1710.10903
(2017).
[53]ChunWang,ShiruiPan,RuiqiHu,GuodongLong,JingJiang,andChengqiZhang.
2019. AttributedGraphClustering:ADeepAttentionalEmbeddingApproach.
InIJCAI. ijcai.org, 3670–3676.
[54]JingWangandIoannisCh.Paschalidis.2017. BotnetDetectionBasedonAnomaly
and Community Detection. IEEE Trans. Control. Netw. Syst. 4, 2 (2017), 392–404.
[55]XinXin,ChaokunWang,XiangYing,andBo-HungWang.2017.Deepcommunity
detection in topologically incomplete networks. Physica A-statistical Mechanics
and Its Applications 469 (2017), 342–352.
[56]Cheng Yang, Zhiyuan Liu, Deli Zhao, Maosong Sun, and Edward Y. Chang. 2015.
NetworkRepresentationLearningwithRichTextInformation.In IJCAI.AAAI
Press, 2111–2117.
5463DAG: Deep Adaptive and Generative 𝐾-Free Community Detection on Attributed Graphs KDD ’24, August 25–29, 2024, Barcelona, Spain
Metric Modularity Semantic NMI EDGE K
Ground Truth 0.6401 11.9360 N/A N/A 7
K-Means 0.1933 20.9624 0.1479 0.5622 7
Greedy Q 0.8069 2.0212 0.4673 0.8864 106
Louvain 0.8135 2.1077 0.4468 0.8787 104
Hanp 0.6263 1.5682 0.4010 0.7508 553
LPA 0.6605 1.5985 0.4142 0.7871 481
DAEGC 0.7545±0.0011 9.5154 ±0.4359 0.4587 ±0.0285 0.8714±0.0120 10.0±1.0
CommDGI 0.6266 ±0.0300 8.9907 ±2.2156 0.3192±0.0193 0.8564±0.0234 9.4 ±2.7
AGCN 0.4338 ±0.0009 20.6211±0.0414 0.2172±0.0044 0.8297±0.0011 10.6±1.2
HSAN 0.6862±0.0547 14.0055±1.6272 0.4497±0.0605 0.8775±0.0013 4.8 ±1.1
CCGC 0.6738 ±0.0690 11.8811±1.1215 0.5051±0.0546 0.8887±0.0141 8.5 ±0.5
DAG 0.6999±0.0125 9.8684 ±0.7115 0.5171 ±0.0053 0.9004±0.0037 7.4 ±1.2
Table 6: Cora
Metric Modularity Semantic NMI EDGE K
Ground Truth 0.5470 11.6463 N/A N/A 6
K-Means 0.2970 19.3495 0.2221 0.6554 6
Greedy Q 0.8736 1.6109 0.3378 0.8395 488
Louvain 0.8919 1.6155 0.3243 0.8321 469
Hanp 0.6019 1.4200 0.3402 0.7393 508
LPA 0.7177 1.6151 0.3377 0.7530 959
DAEGC 0.7676±0.0052 6.8796 ±1.0481 0.2907 ±0.0070 0.8302±0.0036 11.5±0.5
CommDGI 0.7285 ±0.0041 6.5277 ±0.8006 0.2911±0.0041 0.8269±0.0018 11.1±1.9
AGCN 0.7624 ±0.0064 7.2502 ±0.8901 0.3160±0.0039 0.8316±0.0053 8.2 ±1.1
HSAN 0.7041±0.0029 12.1715±0.0757 0.3128±0.0045 0.8413±0.0018 5.1 ±0.3
CCGC 0.7753 ±0.0021 8.4104 ±0.0852 0.4090±0.0050 0.8447±0.0037 11.9±0.3
DAG 0.7435±0.0194 9.1846 ±0.0730 0.4118 ±0.0022 0.8677±0.0041 6.4 ±0.5
Table 7: CiteSeer
Metric Modularity Semantic NMI EDGE K
Ground Truth 0.4318 200.3377 N/A N/A 3
K-Means 0.3490 435.9176 0.3111 0.8538 3
Greedy Q 0.7278 9.8667 0.2217 0.8584 114
Louvain 0.7695 37.0698 0.2062 0.8359 39
Hanp 0.3035 6.0354 0.1770 0.7126 2037
LPA 0.6159 2.8074 0.1804 0.7329 1924
DAEGC 0.4989 ±0.0788 170.8658±46.8934 0.1784±0.0601 0.8422±0.0183 4.1±1.1
CommDGI 0.5562 ±0.0697 161.2432±39.1524 0.1892±0.0595 0.8469±0.0086 4.9±0.7
AGCN 0.6409 ±0.0385 193.8005±23.4665 0.2275±0.0337 0.8504±0.0134 3.8±0.7
HSAN OOM OOM OOM OOM OOM
CCGC 0.5796 ±0.0712 220.9804±58.2542 0.1922±0.0035 0.8520±0.0172 4.1±1.2
DAG 0.5939±0.0507 189.2995±37.5518 0.2828±0.0143 0.8938±0.0057 3.4±0.5
Table 8: PubMed
Metric Modularity Semantic NMI EDGE K
Ground Truth 0.5420 11.3686 N/A N/A 17
K-Means 0.2061 24.9865 0.4281 0.7793 17
Greedy Q 0.6387 2.2243 0.4358 0.8478 90
Louvain 0.7112 3.5303 0.4559 0.8583 64
Hanp 0.2702 2.8806 0.4995 0.7135 885
LPA 0.6438 1.9228 0.4858 0.8410 396
DAEGC 0.4884±0.0115 6.1599 ±0.3052 0.2200 ±0.0082 0.7235±0.0310 25.0±2.5
CommDGI 0.3957 ±0.0021 6.4033 ±0.4709 0.1839±0.0245 0.7373±0.0393 31.1±1.3
AGCN 0.4344 ±0.0021 8.7744 ±1.1372 0.1962±0.0187 0.7431±0.0105 22.6±1.7
HSAN 0.6259±0.0100 7.1363 ±0.6481 0.4131±0.0049 0.8375±0.0141 29.5±0.5
CCGC 0.6166 ±0.0114 12.6023±1.0895 0.4079±0.0236 0.8467±0.0101 21.8±3.6
DAG 0.5981±0.0103 14.0695±1.3280 0.4320±0.0074 0.8629±0.0087 15.7±0.9
Table 9: Wiki
Metric Modularity Semantic NMI EDGE K
Ground Truth 0.5417 10.4687 N/A N/A 70
K-Means 0.2061 24.9865 0.4281 0.7793 70
Greedy Q 0.7270 1.9472 0.4075 0.7290 499
Louvain 0.8126 2.3447 0.4792 0.7300 404
Hanp 0.6670 1.9020 0.5560 0.6670 2113
LPA 0.6466 1.8934 0.5664 0.6705 2328
DAEGC 0.6818±0.0401 5.8318±0.3930 0.4503±0.0358 0.6882±0.0207 60.1±0.3
CommDGI 0.6875 ±0.0173 6.5136±1.2660 0.4467±0.0099 0.6756±0.0108 60.3±0.5
AGCN 0.6878±0.0147 5.7370±0.3423 0.4721±0.0108 0.6955±0.0065 74.2±1.9
HSAN OOM OOM OOM OOM OOM
CCGC 0.7176 ±0.0122 6.5657±0.5816 0.4898±0.0035 0.7047±0.0072 73.6±5.4
DAG 0.6602±0.0101 7.5734±0.2918 0.4932±0.0037 0.7311±0.0076 68.4±1.4
Table 10: CoraFull[57]Xihong Yang, Yue Liu, Sihang Zhou, Siwei Wang, Wenxuan Tu, Qun Zheng,
XinwangLiu,LimingFang,andEnZhu.2023. Cluster-GuidedContrastiveGraph
Clustering Network. In AAAI. AAAI Press, 10834–10842.
[58]Shiqi Zhang, Yiqian Huang, Jiachen Sun, Wenqing Lin, Xiaokui Xiao, and Bo
Tang.2023. CapacityConstrainedInfluenceMaximizationinSocialNetworks.In
KDD. ACM, 3376–3385.
[59]Shiqi Zhang, Jiachen Sun, Wenqing Lin, Xiaokui Xiao, Yiqian Huang, and Bo
Tang. 2024. Information Diffusion Meets Invitation Mechanism. In WWW. ACM,
383–392.
[60] Shiqi Zhang, Jiachen Sun, Wenqing Lin, Xiaokui Xiao, and Bo Tang. 2022. Mea-
suringFriendshipCloseness:APerspectiveofSocialIdentityTheory.In CIKM.
ACM, 3664–3673.
[61]TianqiZhang,YunXiong,JiaweiZhang,YaoZhang,YizhuJiao,andYangyong
Zhu. 2020. CommDGI: Community Detection Oriented Deep Graph Infomax. In
CIKM. ACM, 1843–1852.
[62]Xingyi Zhang, Shuliang Xu, Wenqing Lin, and Sibo Wang. 2023. Constrained
Social Community Recommendation. In KDD. ACM, 5586–5596.
[63]Zhao Zhang, Fanzhang Li, Mingbo Zhao, Li Zhang, and Shuicheng Yan. 2017.
Robustneighborhoodpreservingprojectionbynuclear/L2,1-normregularization
for image feature extraction. IEEE Trans. Image Process. 26, 4 (2017).
[64]ElenaZheleva,HossamSharara,andLiseGetoor.2009. Co-evolutionofsocial
and affiliation networks. In KDD. ACM, 1007–1016.
A PROOF OF GROUP SPARSITY LEMMA
Here, we provide the proof of Lemma 1 (group sparsity).
Proof.First,inEq. (11),weaddthe L2,1normconstrainton W𝑇,
whichmakes Whavecolumnsparsecharacteristics.Becausethe L2
norm is used for each column of the W, then the L1norm is used
forthatvector.The L1normisoftenusedtopromotesparsity[ 15],
whichmeansthatmanyelementsofavectorwillbezer o.However,
sincetheL2normiscalculatedfirstandthenthe L1norm,thiswill
ultimately encourage Wto be column-wise sparse. The L2,1norm
constraintisalsoacommonpracticeinmanyotherstudies[ 33,63].
Secondly,thecorrespondingcolumnofthematrixproduct ˆAHCW
willalsobeazerovectorlike W.InEq. (16),werepresentthematrix
W∈R𝑑×𝑘maxas a combination of column vectors and represent
any matrix S∈R𝑁×𝑑as a combination of row vectors. Then the
result of matrix product SW∈R𝑁×𝑘maxis as Eq. (17).
W=/bracketleftbig𝑤1𝑤2···𝑤𝑘max/bracketrightbig
,S=/bracketleftbig𝑠𝑇
1𝑠𝑇
2···𝑠𝑇
𝑁/bracketrightbig𝑇.(16)
SW=⎡⎢⎢⎢⎢⎢⎢⎢⎣𝑠𝑇
1𝑤1𝑠𝑇
1𝑤2···𝑠𝑇
1𝑤𝑘max
𝑠𝑇
2𝑤1𝑠𝑇
2𝑤2···𝑠𝑇
2𝑤𝑘max
............
𝑠
𝑇
𝑁𝑤1𝑠𝑇
𝑁𝑤2···𝑠𝑇
𝑁𝑤𝑘max⎤⎥⎥⎥⎥⎥⎥⎥⎦. (17)
Ifthe𝑗-thcolumnvector 𝑤𝑗ofWisazerovector,thenelementsof
𝑗-thcolumnof SW{𝑠𝑇
𝑖𝑤𝑗,𝑖∈[𝑁]}areallzeros.Itcanbeclearly
seenfromthevectorizedmultiplicationprocessthatnomatterwhat
the value of the left matrix Sis,SWmaintains the same column
sparsitypropertyas W.Taking S=ˆAHC,wegetsparsityof ˆAHCW.
Thirdly,forthe ReLUfunction𝑓(𝑥)=max(0,𝑥),because 𝑓(0)=
0, the value of the zero element will not be changed.
Following the above three steps, we can conclude that the C
matrix in Eq. (10) has the property of column sparseness. /square
B REPRODUCIBILITY DETAILS
B.1 Experimental environments.
The proposed DAG and the competitors are implemented with
PyTorch[ 39](2.0.1)andtheDGL(1.1.1+cu117).Eachexperiment
is implemented on an NVIDIA Tesla T4 GPU with 16 GB GPU
5464KDD ’24, August 25–29, 2024, Barcelona, Spain Chang Liu et al.
Figure 10: The Hyper-parameter search for the 𝛼and𝛽in
Cora. Thenumbersare shown inthe heatmap ofthe average
EDGE metric.
memory.Wetrainalldeeplearning-basedmethodswithtenruns
andreporttheaverageperformance.Weimportmodularityfrom
NetworkX(2.8.4),CalinskiHarabaszscore,andNMIfromthescikit-
learn library (1.2.2).
B.2 Hyper-parameter settings.
All DAG models share the following hyperparameters: GAT layers
are used as both the attribute encoder and decoder. The activation
functionisReLU.The Adamoptimizerisutilizedforoptimization
with a learning rate (lr) of 0.001. The input layer dropout rate
is set to 0.2. We set the 𝛼to 1e-2 and 𝛽to 5e-3 in Eq. (13) for
all datasets to ensure that our method can both efficiently and
effectivelyadaptivetotherealcommunitystructuresratherthan
DGC methods’ inevitable fine-tuning the community number 𝐾.
Dataset-Specific hyper-parameters. ForCora, we the length of
embedding(num_hidden)to512,thenumberofGAT’sattention
heads (num_heads) to 4, the number of layers for both attribute
encoder and attribute decoder (num_layers) to 2, the weight decay
of Adam (weight decay) to 1e-3, and the maximum number of
epochs(max_epoch)to1500.For Citeseer,wesetthenum_hidden
to 256, num_heads to 2, num_layers to 2, weight decay to 1e-4,
andthemax_epochto500.For Pubmed,wesetthenum_hidden
to 1024, num_heads to 4, num_layers to 2, weight decay to 1e-2,
andthemax_epochto1000.For Wiki,wesetthenum_hiddento
512,num_headsto2,num_layersto2, weightdecayto1e-5,and
the max_epoch to 1500. For CoraFull, we the num_hidden to 512,
num_heads to 4, num_layers to 2, weight decay to 1e-5, and the
max_epoch to 1000. The hyper-parameters of GAMEare the same
as CoraFull.C IMPACT OF HYPER-PARAMETER.
We adopt a two-step strategy for searching the hyperparameters 𝛼
and𝛽in Eq. (13). Firstly, we conduct a coarse search for 𝛼and𝛽in
alogscale(e.g.,[1,0.1,0.01,0.001,0.0001]).Secondly,weadjustthe
𝛽usingacombinationoflogscaleandgridsearchstrategies.For
instance, since the Cora dataset’s optimal 𝛽is around 1e-3 to 1e-2,
wesearchvaluesamong2e-3,3e-3,andupto9e-3.Finally,wefixthe
𝛼and𝛽forallcompareddatasets,includingtheGAMEgraph.Note
that as mentioned in Sec 4, we address the community detection inanunsupervisedmanner andsearchthe
𝛼and𝛽withthehighest
product of two unsupervised metrics, i.e.,modularity and Calinski
Harabaszscore.Thehyperparametersearchresultsforthe 𝛼and
𝛽in theCora dataset arevisualized inFig. 10 asa heatmap. Based
on the heatmap in Fig. 10, we can analyze the impact of varying
thehyperparameters 𝛼and𝛽ontheperformanceofourmethod,
as measured by the EDGE metric.
It can be observed that the best performance is achieved with
a value around 1e-3. This suggests that balancing the two hyper-
parameters yields the most effective community detection results.
We can also notice that the performance is relatively stable across
differentvaluesof 𝛼and𝛽inlongitudescales.Specifically,sincethe
bestSOTAmethod’sEDGEmetricis0.8887,thereare 60%ofcases
inthelongitudescalesoutperformtheSOTAmethods, indi-
cating that our method is robust to hyper-parameter variations. In
conclusion,thehyper-parametersearchresultsfortheCoradataset
demonstrate that our method achieves the best performance when
a balance between 𝛼and𝛽is maintained. The robustness of our
methodtohyperparametervariationsfurthervalidatesitseffective-
ness in community detection tasks.
DDETAILED RESULTS ON PUBLIC DATASETS
We provide detailed tables of experimental results for each dataset
from Tab.6 to Tab. 10, including modularity, Semantic (Calinski
Harabaszscore)asunsupervisedmetrics,aswellasNMIandEDGE
metrics as supervised metrics. For deep learning-based methods,including SOTA DGC methods and DAG, we provide the mean
and standard deviation ( i.e., mean ±std) of 10 runs. For traditional
methods,wereportsingle-runresults.The 𝐾-meansinthetables
already use ground truth as prior knowledge. Surprisingly, deep
learning-basedmethodscanfindmore“reasonable”communities
than ground truth labels. For example, as shown in Tab. 9, the com-
munitiesdetectedbytheCCGCandDAGhavebothhighermod-
ularity(tighterinternalconnections)andhighersemanticscores
(moreattributesimilarity)thanthegroundtruthintheWikidataset.Thisshowsthatinreal-lifescenarios,therearesomehiddenfactors
in the reasons for the generation of communities, which reveals
further research directions in community detection algorithms.
5465