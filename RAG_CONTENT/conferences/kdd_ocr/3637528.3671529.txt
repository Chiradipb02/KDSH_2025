Deep Ensemble Shape Calibration: Multi-Field Post-hoc
Calibration in Online Advertising
Shuai Yang
Shopee Discovery Ads
Beijing, China
lucas.yang@shopee.comHao Yang
Shopee Discovery Ads
Beijing, China
apple.yang@shopee.comZhuang Zou
Shopee Discovery Ads
Beijing, China
zhuang.zou@shopee.com
Linhe Xu
Shopee Discovery Ads
Beijing, China
linhe.xu@shopee.comShuo Yuan
Shopee Discovery Ads
Beijing, China
yuanshuo.ys@hotmail.comYifan Zeng
Shopee Discovery Ads
Beijing, China
alan.zeng@shopee.com
Abstract
In the e-commerce advertising scenario, estimating the true prob-
abilities (known as a calibrated estimate) on Click-Through Rate
(CTR) and Conversion Rate (CVR) is critical. Previous research has
introduced numerous solutions for addressing the calibration prob-
lem. These methods typically involve the training of calibrators
using a validation set and subsequently applying these calibrators
to correct the original estimated values during online inference.
However, what sets e-commerce advertising scenarios is the
challenge of multi-field calibration. Multi-field calibration requires
achieving calibration in each field. In order to achieve multi-field
calibration, it is necessary to have a strong data utilization ability.
Because the quantity of pCTR specified range for single field-value
(such as user ID and item ID) sample is relatively small, which makes
the calibrator more difficult to train. However, existing methods
have difficulty effectively addressing these issues.
To solve these problems, we propose a new method named Deep
Ensemble Shape Calibration (DESC). In terms of business under-
standing and interpretability, we decompose multi-field calibration
intovalue calibration and shape calibration. We introduce in-
novative basis calibration functions, which enhance both function
expression capabilities and data utilization by combining these basis
calibration functions. A significant advancement lies in the develop-
ment of an allocator capable of allocating the most suitable calibra-
tors to different estimation error distributions within diverse fields
and values. We achieve significant improvements in both public and
industrial datasets. In online experiments, we observe a +2.5% in-
crease in CVR and +4.0% in GMV. (Gross Merchandise Volume). Our
code is now available at: https://github.com/HaoYang0123/DESC.
CCS Concepts
•Computing methodologies →Machine learning.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
KDD ’24, August 25–29, 2024, Barcelona, Spain
©2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 979-8-4007-0490-1/24/08
https://doi.org/10.1145/3637528.3671529Keywords
Multi-Field Calibration, Basis Calibration Function, Field-aware
Attention
ACM Reference Format:
Shuai Yang, Hao Yang, Zhuang Zou, Linhe Xu, Shuo Yuan, and Yifan Zeng.
2024. Deep Ensemble Shape Calibration: Multi-Field Post-hoc Calibration
in Online Advertising. In Proceedings of the 30th ACM SIGKDD Conference
on Knowledge Discovery and Data Mining (KDD ’24), August 25–29, 2024,
Barcelona, Spain. ACM, New York, NY, USA, 10 pages. https://doi.org/10.
1145/3637528.3671529
1 INTRODUCTION
Estimating CTR and CVR is a crucial technology in e-commerce
advertising domains [ 2–6,10,14,22,26–28,30,33,35]. Accurate
prediction of CTR (pCTR) and CVR (pCVR) is essential, as it neces-
sitates precision not only in ranking but also in absolute values.
However, recent studies [ 1,7,9,16,23] have revealed that nu-
merous established machine learning techniques, particularly deep
learning methods extensively applied in the fields of e-commerce
advertising, often yield inadequately calibrated probability predic-
tions.
In previous research, there are many solutions to solve the cali-
bration problem. These methods learn calibrator through the vali-
dation set, and then use the calibrator to correct the original esti-
mated values in the online inference stage. These methods can be
categorized into parameter methods (including Platt Scaling [ 25],
Temperature scaling [9], Beta calibration [18], Gamma calibration
[20] and Dirichlet calibration [ 17]), non-parameter methods (such
as Histogram Binnning [ 31] and Isotonic Regression [ 32]) and hy-
brid methods. Hybrid methods encompass both non-field-aware
[15, 19, 34] and field-aware approaches [13, 24, 29].
In the advertising scenarios, there are multiple fields (such as
user group and item category), and if predictions of CTR (pCTR)
or CVR (pCVR) are not calibrated in certain fields, such as item
category, it can lead to a negative impact on the earnings of some
advertisers. Simultaneously, in the e-commerce scenario, there is a
particularly large number of fields to consider. This necessitates the
calibration of each field, referred to as multi-field calibration. To
achieve multi-field calibration, it is necessary to have a strong data
utilization ability. Because the samples of the specified pCTR range
for a single field value (such as user ID and item ID) are relatively
small, which makes the calibrator more difficult to train.
6117
KDD ’24, August 25–29, 2024, Barcelona, Spain Shuai Yang, Hao Yang, Zhuang Zou, Linhe Xu, Shuo Yuan, and Yifan Zeng
CTR
PCTR PCTR PCTRpCTR = CTRShape Miscalibrated Value  Miscalibrated Shape & Value Calibrated
Calibrated Calibrated Calibrated
Figure 1: Examples to show the shape miscalibration and
value miscalibration
012345678910111213141516171819202122231.01.52.0pCTR/CTRValuemiscalibration over 24 hours
cat_0 cat_1 cat_2 cat_3 cat_4 cat_50.60.81.01.21.4pCTR/CTRValuemiscalibration across Categories
Figure 2: Examples to show significant variations in value
miscalibration among different fields and values.
0.011 0.019 0.027 0.035 0.043
Un-calibrated pCTR0.20.40.60.81.01.21.4pCTR/CTR
Calibrated pCTR
value="Food",field="category"
0.011 0.019 0.027 0.035 0.043
Un-calibrated pCTR0.20.40.60.81.01.21.4
 Calibrated pCTR
value="Book",field="category"Shapemiscalibration across values
Figure 3: Examples to show significant variations in shape
miscalibration among different values within the same field.
In terms of business understanding and interpretability, we de-
compose multi-field calibration into value calibration and shape
calibration. Figure 1 shows shape miscalibration and value miscali-
bration. Value calibration is defined as no over- or under-estimation
each value under concerned fields (such as average of pCTR should
equal to the CTR for value "women’s shoes" in the field "category",
in the e-commerce advertising context, the number of fields can
range from dozens to even hundreds). From the advertising per-
spective, value calibration ensures that the ECPM (Effective Cost
Per Mille) and GMV (Gross Merchandise Value) of different items
are not over- or under estimated. Figure 2 illustrates the significant
inconsistency of over- and under-estimation across different values.
Shape calibration is defined as no over- or under-estimation for
each subset of the pCTR within the specified range. Explaining
from the advertising perspective, shape calibration ensures that
some already popular items are not excessively exposed or sup-
pressed. Take Figure 3 as an example, for the field "Category" with
values "Food" and "Book", the calibrated pCTR/CTR is 1 in anypCTR interval, whereas the distribution (shape) of the uncalibrated
pCTR/CTR will be different. However, the existing methods cannot
simultaneously fulfill both value calibration and shape calibration.
For parameter methods, non-parameter methods and non-field-
aware methods, they involve the training of a single calibration
function to address the issue of over- or under-estimation for each
subset of the pCTR globally but overlook the biases across different
fields.
For field-aware methods, they have different emphases, and can-
not simultaneously fulfill both value calibration and shape calibra-
tion. NeuralCalib/Field-aware Calibration (FAC) [ 24] places its focus
on modeling estimation value biases across various field values,
rather than addressing shape miscalibrations. Multiple Boosting
Calibration Tree (MBCT) [ 13] effectively enhances the binning of
field values, giving less emphasis to shape miscalibrations. AdaCalib
(Ada) [ 29] can only model shape calibration and value calibration
under the condition of a single field.
An analysis of the aforementioned field-aware methods reveals
several key observations. Firstly, within a single field, there exists
multiple values. In some cases, the allocation of samples to each
field value may be limited, particularly in scenarios involving user
ID, item ID and certain sparse cross-features. Consequently, train-
ing a calibrator under such limited samples can be challenging.
Additionally, field-aware methods often employ a binning strat-
egy, followed by the generation of calibration parameters based on
information from two adjacent bins. This approach can lead to a
sample isolation issue wherein the parameters of a bin are exclu-
sively influenced by the samples within that bin and its neighboring
bins, with no updates from samples in other bins. As a result, these
methods can result in suboptimal data utilization.
To solve these above problems, we propose a new method named
Deep Ensemble Shape Calibration (DESC). There are four contri-
butions in our work:
•We redefine the multi-field calibration: perform shape cali-
bration and value calibration at the same time.
•We propose the novel basis calibration functions, which can
simultaneously improve function expression ability and data
utilization through the combination of basis calibration func-
tions.
•We make a breakthrough in putting forward an allocator that
can allocate the most suitable shape calibrators for different
estimation error distributions on various fields and values.
•Our proposed DESC method outperforms other methods sig-
nificantly across both calibration and non-calibration met-
rics, as demonstrated on two public datasets and one indus-
trial dataset. Additionally, in online experiments, we observe
a notable increase of +2.5% in CVR and +4.0% in GMV.
2 RELATED WORKS
With the growing emphasis on improving the reliability and accu-
racy of machine learning models, several research approaches have
emerged. Numerous calibration methods focus on acquiring a map-
ping function to convert predicted probabilities into observed poste-
rior probabilities, referred to as post-hoc calibration. These studies
can be broadly classified into three categories: non-parameter, pa-
rameter, and hybrid methods.
6118Deep Ensemble Shape Calibration: Multi-Field Post-hoc Calibration in Online Advertising KDD ’24, August 25–29, 2024, Barcelona, Spain
2.1 Non-parametric Methods
Non-parametric methods do not rely on any assumptions regarding
the distribution of estimates. Examples of non-parametric methods
encompass Histogram Binning (HB)[ 31] and Isotonic Regression
(IR) [ 32]. HB involves sorting the estimated values and then dividing
them into bins of equal frequencies or intervals. Building upon this,
IR introduces the additional constraint of order preservation. These
approach can introduce instability in the bin boundary values.
2.2 Parametric Methods
Parameter methods often rely on specific probability distribution
assumptions for deriving mapping functions. Platt Scaling [ 25],
extensively employed in binary classification calibration, assumes
a Gaussian distribution with equal variances for both positive and
negative classes [ 20]. For multi-class tasks, Temperature Scaling [ 9]
extends this approach. Beta calibration [ 18], Gamma calibration [ 20]
and Dirichlet calibration [ 17] rely on their respective probability
distributions for calibration. Parameter methods are highly reliant
on the strong distribution assumption, which can lead to suboptimal
performance if the assumption does not hold in practical scenarios.
2.3 Hybrid Methods
Hybrid methods integrate non-parametric and parametric approaches.
Based on whether they are applied at the field-level, we further cat-
egorize hybrids into two groups: non-field-aware and field-aware
methods.
2.3.1 Non-field-aware Methods. Non-field-aware methods encom-
pass three notable approaches: Scaling-binning [ 19], Smooth Iso-
tonic Regression (SIR) [ 15], and Ensemble Temperature Scaling
(ETS) [ 34]. Scaling-binning combines the techniques of Platt Scal-
ing and Histogram Binning. SIR employs linear interpolation based
on isotonic regression, while ETS combines multiple temperature
scalings for calibration. Notably, all of these methods utilize raw
predicted scores as input without taking field information into
account.
2.3.2 Field-aware Methods. Field-aware methods integrate supple-
mentary features to formulate calibration functions. NeuralCalib
(FAC) [ 24] introduces an auxiliary module but it does not address
the challenge of shape miscalibration variance among different field
values. AdaCalib (Ada) [ 29] learns an isotonic function based on
posterior statistics and selects the most appropriate bin number
for a single field value. However, AdaCalib does not encompass all
fields. MBCT [ 13] employs trees to uncover more effective calibra-
tion across fields. However, calibration trees are unable to handle
sparse fields, such as user ID and item ID.
3 CALIBRATION PROBLEM FORMULATION
In online advertising systems, using CTR as an illustration (CVR
follows the same principles), we have trained a neural predictor,
denoted as𝑓𝑢𝑛𝑐𝑎𝑙𝑖𝑏 , on a training dataset D𝑡𝑟𝑎𝑖𝑛 . This dataset in-
cludes all field values as inputs ( 𝑥) and click responses ( 𝑦), where
𝑦=0represents non-click events and 𝑦=1signifies click events.
The neural predictor is capable of forecasting the likelihood of a
click using the following formula.
ˆ𝑝𝑢𝑛𝑐𝑎𝑙𝑖𝑏 =𝑓𝑢𝑛𝑐𝑎𝑙𝑖𝑏(𝑥) (1)
To address the under- and over-estimation issues associated
with the predicted scores generated by 𝑓𝑢𝑛𝑐𝑎𝑙𝑖𝑏 , we must train anadditional calibrator, denoted as 𝑓𝑐𝑎𝑙𝑖𝑏 , while considering 𝑛distinct
fields (𝑍1,𝑍2, ...,𝑍𝑛) in a validation dataset. Our objective is for
𝑓𝑐𝑎𝑙𝑖𝑏 to predict the conditional expectation E[𝑦|𝑥]. Subsequently,
the theoretical calibration error of 𝑓𝑐𝑎𝑙𝑖𝑏 with respect to the ground-
truth under the 𝑙𝑝-norm is defined as:
𝑇𝐶𝐸𝑝(𝑓𝑐𝑎𝑙𝑖𝑏)=(E𝑥[|E[𝑦|𝑥]−𝑓𝑐𝑎𝑙𝑖𝑏(𝑥)|𝑝])1
𝑝. (2)
The calibrator 𝑓𝑐𝑎𝑙𝑖𝑏 is considered to be perfectly calibrated when
the theoretical calibration error 𝑇𝐶𝐸𝑝(𝑓𝑐𝑎𝑙𝑖𝑏)is zero. However, in
fact perfect calibration is impossible in practice. Only approximate
and asymptotic grouped calibrations are possible for finite and
specific partitions of samples [ 11]. To test the performance of dif-
ferent calibrators, we will explain some related calibration metrics
in EXPERIMENTS section.
4 METHODS
Under the requirement of multi-field calibration, both shape cali-
bration and value calibration need to be performed simultaneously.
Therefore, within the entire DESC architecture, we have designed
separate modules, namely Shape Calibrator and Value Calibrator
(Figure 4), to achieve shape calibration and value calibration. The
final calibrated score is the product of these two parts:
ˆ𝑝𝑐𝑎𝑙𝑖𝑏 =S(𝑥)·V(𝑥), 𝑥={𝑍,ˆ𝑝𝑢𝑛𝑐𝑎𝑙𝑖𝑏} (3)
The input𝑥consists of all 𝑛field values 𝑍and non-calibrated
scores ˆ𝑝𝑢𝑛𝑐𝑎𝑙𝑖𝑏 .S(𝑥)andV(𝑥)refer to the shape calibrated score
(the output of Shape Calibrator) and value calibrated score (the
output of Value Calibrator), respectively. The training loss function
is the negative log-likelihood function.
L(𝑥, 𝑦)=−1
|D|(𝑦·𝑙𝑜𝑔ˆ𝑝𝑐𝑎𝑙𝑖𝑏+(1−𝑦)·𝑙𝑜𝑔(1−ˆ𝑝𝑐𝑎𝑙𝑖𝑏)) (4)
In Section 4.1, we present the Shape Calibrator module, which is
responsible for achieving shape calibration. In Section 4.2, we dis-
cuss the Value Calibrator module, which is designed to accomplish
value calibration. In Section 4.3, we elaborate on the deployment of
DESC in an online setting, outlining the necessary procedures and
considerations.
4.1 Shape Calibrator
For multi-field calibration, the goal of Shape Calibrator is to ensure
that: given input features 𝑥, we need to reduce the problems of
over- and under-estimation across all intervals of pCTR (shape
miscalibration).
In section 4.1.1, we pre-define a variety of basis functions to
accommodate different shape requirements. Section 4.1.2 deals with
the allocation of appropriate shape functions given specific field
conditions. This section offers separate discussions on how shape
allocation is managed for regular fields and sparse fields.
In section 4.1.3, when dealing with multiple fields, there may be
conflicts in terms of the influence of different fields on calibration.
Thus, we introduce a multi-field fusion mechanism named Multi-
Field Shape Ensemble.
Collectively, sections 4.1.1 and 4.1.2 are referred to as the Single
Field Shape Calibrator (SFSC), as depicted in Figure 4b.
4.1.1 Shape Pre-Define. In this section, we pre-define some basis
calibration functions. Then, we merge the basis calibration func-
tions into shape functions to enhance their expressive ability.
For the variable 𝑡,𝑡is between 0 and 1, basis calibration function
B(𝑡)satisfies the following conditions:
6119KDD ’24, August 25–29, 2024, Barcelona, Spain Shuai Yang, Hao Yang, Zhuang Zou, Linhe Xu, Shuo Yuan, and Yifan Zeng
(a) Overall Architecture
Value Calibrator Shape Calibrator
SFSC SFSC
0.10.7
0.2
pCTRlookup
table
bucketidMLP
fieldiemb (emb) emb(b) S ingle Field Shape Calibrator
Embedding
AugmentSoftmax
Softmax
Global
Shape
AttentionSFSC
pCTR fields value dot-pr oduct
inner -
productMulti-Field
Shape EnsembleShape
Pre-defineattention
scoressum sigmoid
inverse
sigmoid
Figure 4: (a) Overall architecture of DESC, its input includes the non-calibrated pCTR and the original fields, and the final
output is the calibrated pCTR. It is end-to-end trainable. (b) Single Field Shape Calibrator takes one field and the non-calibrated
pCTR as inputs and outputs the calibrated shape score for this field.
1.The function is monotonically non-decreasing and continuous
in range(0,1).
2.When𝑡approaches 0+, the limit ofB(𝑡)is 0, and when 𝑡
approaches 1−, the limit ofB(𝑡)is 1 (Equation 5).
lim
𝑡→0+B(𝑡)=0𝑎𝑛𝑑 lim
𝑥→1−B(𝑡)=1 (5)
We pre-define 𝑚basis functions consisting of 𝑝power functions,
𝑙logarithmic functions and 𝑠scaling functions (shown in Equa-
tion 6). These functions exhibit different shape characteristics,
and their shapes vary when the hyper-parameters (e.g. the coeffi-
cients in these basis calibration functions) are different. We choose
predefined functions over Multi-Layer Perceptron (MLP) because,
through data research, we have found that predefined functions
can address the issue of over- or underestimation for each subset of
pCTR within the specified range (shape calibration). Additionally,
predefined functions have a lower parameter count and superior
performance.
Compared to segmented linear functions in traditional calibra-
tion methods, including SIR, FAC, Ada, using basis calibration func-
tions doesn’t require data segmentation. In other words, shape
learning can utilize all samples for training, significantly enhancing
the data utilization. Basis calibration functions include, but are not
limited to𝑙𝑜𝑔,𝑒𝑥𝑝and𝑠𝑐𝑎𝑙𝑖𝑛𝑔 . By analyzing the data, we find that
the combination of 𝑙𝑜𝑔,𝑒𝑥𝑝and𝑠𝑐𝑎𝑙𝑖𝑛𝑔 functions can satisfactorily
fulfill our requirements with ease.
B(𝑡)={B𝑝𝑜𝑤𝑒𝑟
1,...,B𝑝𝑜𝑤𝑒𝑟
𝑝
|                     {z                     }
𝑝𝑝𝑜𝑤𝑒𝑟 𝑓𝑢𝑛𝑐𝑡𝑖𝑜𝑛𝑠,B𝑙𝑜𝑔
1,...,B𝑙𝑜𝑔
𝑙|            {z            }
𝑙𝑙𝑜𝑔 𝑓𝑢𝑛𝑐𝑡𝑖𝑜𝑛𝑠,B𝑠𝑐𝑎𝑙𝑖𝑛𝑔
1,...,B𝑠𝑐𝑎𝑙𝑖𝑛𝑔
𝑠|                       {z                       }
𝑠𝑠𝑐𝑎𝑙𝑖𝑛𝑔 𝑓𝑢𝑛𝑐𝑡𝑖𝑜𝑛𝑠}
(6)
B𝑝𝑜𝑤𝑒𝑟
𝑖(𝑡;ℎ𝑖)=𝑥ℎ𝑖 (7)
B𝑙𝑜𝑔
𝑖(𝑡;𝑣𝑖)=𝑙𝑜𝑔(1+𝑣𝑖·𝑡)
𝑙𝑜𝑔(1+𝑣𝑖)(8)
B𝑠𝑐𝑎𝑙𝑖𝑛𝑔
𝑖(𝑡;𝑎𝑖)=𝜎(𝜎−1(𝑡)·𝑎𝑖), (9)
𝑤ℎ𝑒𝑟𝑒𝜎(𝑡)=1
1+𝑒𝑥𝑝(−𝑡)𝑎𝑛𝑑𝜎−1(𝑡)=𝑙𝑜𝑔(𝑡
1−𝑡) (10)
0.0 0.5 1.00.00.51.0S(x)
0.0 0.5 1.00.00.51.0=  0.5 * scaling(x;0.5)
0.0 0.5 1.00.00.51.0+  0.5 * scaling(x;3.8)
Figure 5: Complex shape can be composed of simple shapes.
ℎ𝑖,𝑣𝑖and𝑎𝑖(ℎ𝑖,𝑣𝑖,𝑎𝑖∈R+) are parameters of basis calibration
functions. For each type of basic calibration function, we pre-define
these parameters using equally spaced floats (e.g., [0.1,0.3,0.5,0.7]),
which can be set as trainable.
However,B(𝑡)can only represent simple shapes, and complex
shapes can be composed of simple shapes, as shown in Figure 5.
Therefore, we need to combine these basis calibration functions
through weighted summation to create shape function S𝑖(𝑥)ca-
pable of representing complex shapes for 𝑖-th field, as shown in
Equation 11, where 𝛼𝑗
𝑖refers to the attention weight of 𝑗-th basis
function for 𝑖-th field, which will be explained in next section.
S𝑖(𝑥)=𝑚∑︁
𝑗=1𝛼𝑗
𝑖·B𝑗(𝑡),B𝑗(𝑡)∈B(𝑡) (11)
4.1.2 Shape Allocation. In shape allocation, we allocate suitable
shape functions based on feature values. These features include
two parts: pCTR bucket feature and original field features. PCTR
bucket feature categorizes pCTR into intervals. For example, 0 to
0.001 is bucket 1, and 0.001 to 0.003 is bucket 2. Introducing pCTR
bucket feature allows for better shape allocation within different
pCTR intervals. The specific steps are as follows:
Step1. We pre-define the embedding size for each feature. Each
one-hot feature (including pCTR bucket feature 𝑏𝑢𝑐𝑘𝑒𝑡 ˆ𝑝𝑢𝑛𝑐𝑎𝑙𝑖𝑏and
original field 𝑍𝑖) is projected into a fixed-size dense embedding,
such as bˆpuncalibandei. The bucket size of 𝑏𝑢𝑐𝑘𝑒𝑡 ˆ𝑝𝑢𝑛𝑐𝑎𝑙𝑖𝑏is assigned
as 100.
Step2. We concatenate embedding vectors into a Multi-Layer Per-
ceptron (MLP), followed by a softmax operation, the output 𝛼𝑖
6120Deep Ensemble Shape Calibration: Multi-Field Post-hoc Calibration in Online Advertising KDD ’24, August 25–29, 2024, Barcelona, Spain
size of softmax is 1×𝑚, with𝛼1
𝑖to𝛼𝑚
𝑖, same as the number of
pre-defined basis functions.
𝛼𝑖=𝑆𝑜𝑓𝑡𝑚𝑎𝑥(𝑀𝐿𝑃(bˆpuncalib,ei)) (12)
Step3. Finally, we obtain the output value of the Shape Calibrator
S𝑖(𝑥)for𝑍𝑖shown in the previous Equation 11.
In the shape allocation stage, the expressive ability of embed-
ding directly affects the ability of allocating shapes. For sparse
fields, we enhance the expressive ability of embeddings by using
self-attention. The specific formula is shown in following formula,
where𝑑is the dimension of eand𝑛is the number of fields.
X(ei)=𝑛∑︁
𝑗=1(𝑆𝑜𝑓𝑡𝑚𝑎𝑥(ei·ej𝑇
√
𝑑)·ej)1[𝑖≠𝑗] (13)
That means: for more similar fields, their miscalibration distri-
butions will be similar. If the semantics between two embeddings
eiandejis similar, then the corresponding weight is also relatively
large.
𝛼𝑖=𝑆𝑜𝑓𝑡𝑚𝑎𝑥(𝑀𝐿𝑃(bˆpuncalib,ei,X(ei))) (14)
Next, we concatenate the original embedding ei, the enhanced
output embedding X(ei), and the pCTR bucket embedding bˆpuncalib.
Then, following the same process as in the shape allocation stage,
we generate the attention for shape allocation 𝛼𝑖and perform the
final fusion.
4.1.3 Multi-Field Shape Ensemble. Different calibration values for
different fields can conflict with each other. For example, there
is a scenario where 19 to 26-year-old users demand for women’s
shoes. Under the item category field of "women’s shoes", the non-
calibrated model behaves 30% over-estimation of pCTR in the 0.01
to 0.03 range. However, under the user age field of "19 to 26", there’s
a 20% under-estimation of pCTR in the same 0.01 to 0.03 range.
Consequently, we not only need to perform shape calibration on
individual field but also need to globally harmonize the outputs of
shape calibrators for different fields. This helps reduce calibration
errors at a global level.
We use Global Shape Attention to combine the output results
obtained from different fields (Figure 4a). Global Shape Attention,
denoted as Ψ, is derived from the Global Shape Attention Generator
module (details will be elaborated in section 4.2.2). The size of Ψis
1×𝑛, with Ψ𝑖∈[0,1], andÍ𝑛
𝑖=1Ψ𝑖=1. The fusion formula is as
follows, where there are a total of 𝑛fields, and S𝑖(𝑥)represents the
output of the shape calibrator for 𝑖-th field.
S(𝑥)=𝑛∑︁
𝑖=1S𝑖(𝑥)·Ψ𝑖 (15)
We finally obtain the output of Global Shape Calibrator: S(𝑥).
4.2 Value Calibrator
The goal of the Value Calibrator is to ensure that, for each sample
𝑥, there is no overall over- or under-estimation (value calibration).
We use all fields for Value Calibrator to achieve the best overall
performance, as described in section 4.2.1. Considering all fields
allows for the excellent allocation of shapes for each field, we use
global shape attention depicted in section 4.2.2.
MatchingLogs
Ranking Model Plugin DESC
Rankingfeaturestraining 
Save checkpoint
ResultrequestFigure 6: Real-Time calibration system used DESC method for
CXR (CTR/CVR) task in our industrial advertising system.
4.2.1 Global Field Value Calibrator. Global Field Value Calibrator
encompasses all the necessary information of the fields concerned.
We train a neural network to fix the field-level miscalibration or
biases by utilizing all necessary features[ 24]. These input fields are
projected into fixed-size dense representations, which are fed into
a neural network (the form of the neural network is not restricted,
here we use MLP). Then we get the middle output ℎ𝑖𝑑𝑑𝑒𝑛𝐿𝑎𝑦𝑒𝑟 and
the final output V(𝑥)for the Global Field Value Calibrator. Finally,
by combining V(𝑥)andS(𝑥), we obtain the final calibrated output
ˆ𝑝𝑐𝑎𝑙𝑖𝑏=S(𝑥)·V(𝑥).
ℎ𝑖𝑑𝑑𝑒𝑛𝐿𝑎𝑦𝑒𝑟 =𝑀𝐿𝑃 1(𝐶𝑜𝑛𝑐𝑎𝑡(bˆpuncalib,e1,e2,...,e𝑛)) (16)
V(𝑥)=𝑀𝐿𝑃 2(ℎ𝑖𝑑𝑑𝑒𝑛𝐿𝑎𝑦𝑒𝑟) (17)
4.2.2 Global Shape Attention Generator. The Global Field Value
Calibrator not only produces the final output but also yields valuable
intermediate representation. In this context, we use the intermedi-
ate representation ℎ𝑖𝑑𝑑𝑒𝑛𝐿𝑎𝑦𝑒𝑟 as input of Equation 18, which can
effectively learn information from all fields. After passing through
a MLP and softmax layer, it produces Global Shape Attention Ψ
with a size equal to the number of fields 𝑛. In the Shape Calibra-
tion stage, the output produced by each field 𝑍𝑖is multiplied by
its corresponding score Ψ𝑖and summed to obtain the final Shape
Calibration Score.
Ψ=𝑆𝑜𝑓𝑡𝑚𝑎𝑥(𝑀𝐿𝑃 3(ℎ𝑖𝑑𝑑𝑒𝑛𝐿𝑎𝑦𝑒𝑟)) (18)
4.3 Online Deployment
The overall framework of the online service using the DESC cal-
ibration method in our industrial advertising system is shown in
Figure 6. When a real-time user request comes, all candidate items
are recalled and predicted with pCTRs by a non-calibration model
(ranking model). Then DESC model calibrates the pCTRs consider-
ing different field values, including user, item, and context features.
In detail, the input 𝑥of DESC has two parts: different field val-
ues and its non-calibrated score ˆ𝑝𝑢𝑛𝑐𝑎𝑙𝑖𝑏 . DESC uses a light neural
network to output the calibrated score ˆ𝑝𝑐𝑎𝑙𝑖𝑏, which is then used
to sort the final ranks for all candidate items. We have integrated
the DESC method as a plugin into the ranking model to reduce
maintenance costs while only adding a little more time (about 2ms
for one user’s request) for online inference.
5 EXPERIMENTS
5.1 Experimental Setup
5.1.1 Datasets. To validate the effectiveness of our proposed DESC
method, we conduct experiments on two public datasets (AliCCP
andCRITEO for CTR prediction tasks) and one industrial dataset
(Shopee for CVR prediction task). CRITEO display advertising
6121KDD ’24, August 25–29, 2024, Barcelona, Spain Shuai Yang, Hao Yang, Zhuang Zou, Linhe Xu, Shuo Yuan, and Yifan Zeng
data1, which consists of 46 million samples. We split the samples
into 28 million samples as training set ( D𝑡𝑟𝑎𝑖𝑛 ), 9 million samples
as validation set (D𝑑𝑒𝑣) and other 9 million samples as testing set
(D𝑡𝑒𝑠𝑡).AliCCP (Alibaba Click and Conversion Prediction) [ 21]
2contains 80 million samples. We split these samples with the
proportion 2:1:1 to D𝑡𝑟𝑎𝑖𝑛 ,D𝑑𝑒𝑣andD𝑡𝑒𝑠𝑡. To test DESC method
on CVR prediction task, we collect the conversion logs from the
Shopee’s online advertising system. It contains 100 million samples,
where the first 60 million for D𝑡𝑟𝑎𝑖𝑛 , the next 20 million for D𝑑𝑒𝑣
and the last 20 million for D𝑡𝑒𝑠𝑡.
5.1.2 Competing Methods. Several representative calibration meth-
ods are used as competitors. We tested several competitive methods,
including parametric methods, non-parametric methods, non-field-
aware hybrid methods and field-aware hybrid methods. Parametric
method contains Platt Scaling (PS) [ 25]. Non-parametric method
contains Histogram Binning (HB) [ 31] and Istonic Regression (IR)
[32]. Non-field-aware method contains Smooth Isotonic Regression
(SIR) [ 15] and Ensemble Temperature Scaling (ETS) [ 34]. Field-
aware method contains FAC [24], Ada [29] and MBCT [13].
We use DeepFM [ 10] to train the non-calibrated models with all
fields inD𝑡𝑟𝑎𝑖𝑛 , and predict the non-calibrated scores in D𝑑𝑒𝑣and
D𝑡𝑒𝑠𝑡. DeepFM consists of both the fully connected part and the FM
part. We utilized the open-source DeepFM "from deepctr.models
import DeepFM" and incorporated all features into DeepFM.
All calibration methods are trained using samples of D𝑑𝑒𝑣and
are tested using samples of D𝑡𝑒𝑠𝑡.
5.1.3 Parameter Configuration. For all neural calibrators, including
FAC, Ada and DESC, we use Adam as the optimizer with a learning
rate of 1e-3 and batch size of 16,384. For the embedding size of field
value𝑑, both FAC and Ada are set as 256 while for DESC, it is 128
because it obtains a better result. For FAC, we set the number of
bins to 100 while for Ada, the candidate set of bin numbers is set
{2, 4, 8} following in [ 29]. For DESC, the number of basis functions
𝑚is 48 (the numbers of the three types of basis functions are both
16), and the numbers of fields 𝑛are 26, 23 and 10 for Criteo, AliCCP
and Industrial dataset, respectively. For MBCT, we set the same
hyperparameters according to the paper.
5.1.4 Compared Metrics. Two commonly used metrics, F-RCE
(Field RCE) and F-ECE (Field ECE) for each field 𝑍𝑖are used. To
calculate the F-RCE of 𝑖-th field (shown in Equation 19), we use
the testing dataset D𝑡𝑒𝑠𝑡(for simplicity,Drefers toD𝑡𝑒𝑠𝑡here)
consisting of(𝑥𝑗,𝑦𝑗), where𝑥𝑗and𝑦𝑗mean the input features
with different fields and clicked label of 𝑗-th sample. The subset of
D𝑧has the samples with the same value 𝑧for𝑖-th field. F-RCE of
𝑖-th field evaluates the deviation level of each sample’s calibrated
probability ˆ𝑝𝑗
𝑐𝑎𝑙𝑖𝑏considering 𝑗-th field.
Another metric is the F-ECE of 𝑖-th field. As shown in Equation
20, it can be calculated for each subset 𝐷𝑧of samples with the same
value in𝑖-th field. We can calculate the subset of F-ECE (shown
in Equation 21) by partitioning predictions into 𝑀equally-spaced
bins and taking a weighted average of the difference between bins’
accuracy and confidence. In detail, firstly we sort the samples by
the non-calibrated scores ˆ𝑝𝑗
𝑢𝑛𝑐𝑎𝑙𝑖𝑏. Then all samples are grouped
into𝑀interval bins. For all samples ( 𝐵𝑚) in𝑚-th bin, we calculate
1https://www.kaggle.com/c/criteo-display-ad-challenge
2https://tianchi.aliyun.com/datalab/dataSet.html?dataId=408the accuracy and confidence, where the accuracy is the average of
labels and the confidence is the average of calibrated scores.
𝐹-𝑅𝐶𝐸𝑖=1
|D|∑︁
𝑧∈𝑍𝑖|Í
(𝑥𝑗,𝑦𝑗)∈D𝑧(𝑦𝑗−ˆ𝑝𝑗
𝑐𝑎𝑙𝑖𝑏)|
1
|D𝑧|Í
(𝑥𝑗,𝑦𝑗)∈D𝑧𝑦𝑗(19)
𝐹-𝐸𝐶𝐸𝑖@𝑀=1
|D|∑︁
𝑧∈𝑍𝑖|D𝑧|·(𝐹-𝐸𝐶𝐸D𝑧@𝑀) (20)
𝐹-𝐸𝐶𝐸D𝑧@𝑀=𝑀∑︁
𝑚=1|𝐵𝑚|
|D𝑧||𝑎𝑐𝑐(𝐵𝑚)−𝑐𝑜𝑛𝑓(𝐵𝑚)| (21)
𝑎𝑐𝑐(𝐵𝑚)=1
|𝐵𝑚|∑︁
𝑗∈𝐵𝑚𝑦𝑗, 𝑐𝑜𝑛𝑓(𝐵𝑚)=1
|𝐵𝑚|∑︁
𝑗∈𝐵𝑚ˆ𝑝𝑗
𝑐𝑎𝑙𝑖𝑏(22)
As explained that the traditional field-aware calibration methods,
such as FAC [ 24] and Ada [ 29], only consider one field to calibrate,
these methods do not take into account the influence of other fields
on the calibration results. We found that the calibration results from
these models only training on one field perform poorly on other
fields. So we use the Multi-Field RCE (MF-RCE) and Multi-Field
ECE (MF-ECE) on all fields to compare different methods as follows:
𝑀𝐹-𝑅𝐶𝐸=1
𝑛∑︁
𝑖𝐹-𝑅𝐶𝐸𝑖 (23)
𝑀𝐹-𝐸𝐶𝐸 @𝑀=1
𝑛∑︁
𝑖𝐹-𝐸𝐶𝐸𝑖@𝑀, (24)
where𝑛is the number of fields.
We use F-RCE and F-ECE as the primary empirical metrics to
compare the calibration errors of different calibration methods on
one field and MF-RCE and MF-ECE to test on all fields. Besides,
we also report the overall ranking performance by using AUC
and Log-loss metrics. Since PCOC (Predicted Click Over Click)
[8,12] and ECE (Expected Calibration Error) [ 13] indicators can be
achieved well for all competing methods, and F-ECE and MF-ECE,
as compared to the traditional ECE, can provide a finer-grained
representation of calibration error in the context of field-aware
problems, PCOC and ECE are not listed in the main results.
5.2 Main Results
5.2.1 Results on One Field. As other hybrid field-aware based meth-
ods only consider one field to calibrate, we compare our proposed
method in one field in the same way. We select the field of "C2" (577
unique values) in Criteo, "853" (39,979 unique values) in AliCCP
and "item ID" (5 million unique values) in Industrial data to perform
our experiments. As shown in Table 1, the AUCs of all calibrators
are higher than the uncalibrator while all other calibration-related
metrics (F-ECE, F-RCE) of calibrators are smaller than the uncali-
brator, which shows that the calibration methods can improve the
accuracy of pCTR while maintaining a certain increase in ranking
performance. Specially, by fusing multiple fields in shape allocation
and shape augmentation, our proposed DESC can achieve much
smaller calibration errors compared to other competitors even in
one field evaluation. It’s worth explaining that DESC performs
much better than other competitors in industrial data than public
data. The reason is that DESC behaves better in calibration per-
formance in this scene where the data sparsity is more serious in
practical industrial data.
6122Deep Ensemble Shape Calibration: Multi-Field Post-hoc Calibration in Online Advertising KDD ’24, August 25–29, 2024, Barcelona, Spain
Table 1: Results of different methods for calibrating CTR predictive models on public and industrial datasets for one field.
Type MethodCriteo AliCCP Industrial Data
AUC↑Log-loss↓F-RCE↓F-ECE@3↓AUC↑Log-loss↓F-RCE↓F-ECE@3↓AUC↑Log-loss↓F-RCE↓F-ECE@3↓
No Calib. N/A 0.7949 0.4559 0.0426 0.0119 0.6130 0.1611 0.0876 0.0135 0.8613 0.5212 0.0743 0.0253
Non-ParamHB 0.7944 0.4562 0.0328 0.0112 0.6128 0.1621 0.0852 0.0130 0.8610 0.5218 0.0669 0.0204
IR 0.7949 0.4559 0.0320 0.0110 0.6130 0.1611 0.0843 0.0132 0.8613 0.5212 0.0665 0.0202
Param PS 0.7949 0.4559 0.0301 0.0105 0.6130 0.1611 0.0841 0.0128 0.8613 0.5212 0.0660 0.0201
Non-Field-
AwareSIR 0.7949 0.4559 0.0300 0.0097 0.6130 0.1611 0.0836 0.0127 0.8613 0.5211 0.0660 0.0201
ETS 0.7949 0.4559 0.0293 0.0095 0.6130 0.1611 0.0837 0.0127 0.8613 0.5212 0.0661 0.0199
Field-
AwareFAC 0.7991 0.4523 0.0265 0.0087 0.6751 0.1571 0.0829 0.0123 0.8634 0.5203 0.0402 0.0163
Ada 0.7992 0.4521 0.0273 0.0089 0.6752 0.1568 0.0832 0.0125 0.8639 0.5201 0.0413 0.0170
MBCT 0.7951 0.4550 0.0248 0.0095 0.6742 0.1611 0.0828 0.0128 0.8621 0.5209 0.0409 0.0175
DESC 0.7992 0.4522 0.0203 0.0080 0.6774 0.1566 0.0821 0.0120 0.8641 0.5192 0.0307 0.0132
Table 2: Results of different methods for calibrating CTR predictive models on public and industrial datasets for all fields.
Type MethodCriteo AliCCP Industrial Data
MF-RCE↓MF-ECE@3↓MF-RCE↓MF-ECE@3↓MF-RCE↓MF-ECE@3↓
No Calib. N/A 0.0702 0.0142 0.1492 0.0143 0.0793 0.0370
Non-ParamHB 0.0692 0.0134 0.1430 0.0135 0.0779 0.0250
IR 0.0688 0.0131 0.1427 0.0131 0.0766 0.0249
Param PS 0.0685 0.0130 0.1420 0.0129 0.0765 0.0248
Non-Field-
AwareSIR 0.0686 0.0131 0.1422 0.0130 0.0764 0.0247
ETS 0.0683 0.0127 0.1470 0.0129 0.0761 0.0248
Field-
AwareFAC 0.0517 0.0101 0.1321 0.0120 0.0412 0.0183
Ada 0.0501 0.0102 0.1338 0.0122 0.0415 0.0180
MBCT 0.0660 0.0104 0.1357 0.0125 0.0430 0.0192
DESC 0.0489 0.0099 0.1264 0.0115 0.03606 0.0132
5.2.2 Results on All Fields. As DESC can consider the effects of
different fields on calibration, we need to evaluate its performance
on all fields. As shown in Table 2, the conclusion is consistent with
the smallest calibration errors on all three datasets.
5.3 In-Depth Analysis
5.3.1 Model Structure Ablation Experiment for DESC. We perform
some model structure ablation experiments to validate the signifi-
cance and effectiveness.
(1) Ablation Experiment of Shape Calibrator. To evaluate
the effectiveness of the Shape Calibrator and Value Calibrator, we
delete the corresponding module and left the other parts unchanged.
Firstly, we delete the Shape Calibrator sub-module, the AUC reduces
to 0.6602 while the metrics of MF-RCE and MF-ECE@3 on all fields
are slightly larger than DESC with 0.1434 and 0.0120 (first line on
Table. 3).
(2) Ablation Experiment of Value Calibrator. Secondly, we
delete another sub-module, the Value Calibrator. The phenomenon
is almost the same, with 0.6761 of AUC, and 0.1398 and 0.0119 of
MF-RCE and MF-ECE@3 on all fields (second line on Table. 3).
(3) Ablation Experiment of Multi-Field Shape Ensemble.
In METHODS section, we have emphasized that shape calibration
needs to consider multiple fields because different fields and values
can have numerous different shapes. Then, we only use mean-
pooling to compute the final predicted result considering different
fields ( Ψ𝑖is all the same with 1/𝑛in Equation 15). The results are
still inferior as shown in the third line in Table. 3.
(4) Ablation Experiment of pCTR Bucket Feature. The pCTR
bucket feature is concatenated with the field embedding to calculateTable 3: Ablation study of DESC on AliCCP.
Type AUC↑Log-loss↓MF-RCE↓MF-ECE@3↓
w/o Shape Calibrator 0.6602 0.1581 0.1434 0.0120
w/o Value Calibrator 0.6761 0.1567 0.1398 0.0119
w/o Multi-Field Shape Ensemble 0.6755 0.1568 0.1324 0.0116
w/o pCTR Bucket Feature 0.6764 0.1567 0.1391 0.0120
w/o Embedding Augment 0.6764 0.1567 0.1398 0.0119
DESC 0.6774 0.1566 0.1264 0.0115
the shape allocation weights in DESC (Equation 14). Then we delete
the pCTR bucket feature (fourth line on Table. 3) to verify that
different pCTR values can also have effects on the calibration shape.
(5) Ablation Experiment of Embedding Augmentation. To
enhance the expressive ability of embeddings, the self-attention
mechanism is used. Then we delete this part by using the original
Equation 12 rather than Equation 14. The fifth line on Table. 3
shows that the embedding augmentation mechanism can enhance
the representational power of embedding.
5.3.2 DESC exhibits a stronger data utilization capability. In this
part, we analyze the data utilization capabilities of different calibra-
tors from both a global perspective (overall down sampling) and an
individual perspective (field value sample quantity).
(1) Overall Down Sampling We further conducted experi-
ments to compare the calibration performance of four different
hybrid field-aware methods (FAC, Ada, MBCT and DESC) across
various sampling ratios. As shown in Figure 7, DESC exhibits a
distinct lower MF-ECE in the context of varying sampling ratios.
In a global perspective, this demonstrates that DESC exhibits a
stronger data utilization capability.
6123KDD ’24, August 25–29, 2024, Barcelona, Spain Shuai Yang, Hao Yang, Zhuang Zou, Linhe Xu, Shuo Yuan, and Yifan Zeng
0.2 0.4 0.6 0.8 1.0
Sampling Ratio0.01000.01050.01100.01150.01200.01250.0130MF-ECE@3
FAC
Ada
MBCT
DESC
Figure 7: Down sampling analysis in CRITEO.
Figure 8: Performance differences for the sample quantity
of the field value.
(2) Field Value Sample Quantity. We analysis the performance
differences among MBCT, FAC, Ada and DESC at sample quantity
aspect. We set the quantity of samples with a specific field value
(for the convenience of display, we use 𝑙𝑜𝑔10(𝑥)) as the x-axis and
𝐸𝐸𝑅𝐶𝑎𝑙𝑖𝑏 (Except Calibration Error Ratio) as the y-axis (the smaller
𝐸𝐸𝑅𝐶𝑎𝑙𝑖𝑏 is, the better DESC is compared with other calibrators),
as shown in Figure 8.
𝐸𝐸𝑅𝐶𝑎𝑙𝑖𝑏 =𝐸𝐶𝐸𝐷𝐸𝑆𝐶
𝐸𝐶𝐸𝐶𝑎𝑙𝑖𝑏,𝐶𝑎𝑙𝑖𝑏∈{𝑀𝐵𝐶𝑇,𝐹𝐴𝐶,𝐴𝑑𝑎} (25)
ECE (Expected Calibration Error) [ 13] is used as the calibration
error to explain the results. The ECE value ranges from (0,+∞].
The higher ECE value indicates higher calibration error and worse
performance. We can find that for the samples with small sized of
number,𝐸𝐸𝑅 is less than 1, which means, from an individual per-
spective, that DESC possesses a stronger data utilization capability.
Figure 9: Performance differences for miscalibration com-
plexity aspect.
5.3.3 DESC Can Adapt to Complex Miscalibration Shapes. We anal-
ysis the performance differences among MBCT, FAC, Ada and DESC
at shape complexity.
From the perspective of pCTR, we divide the estimated pCTR
values into bins either with equal frequency or equal interval, and
each bin can calculate the PCOC (Predicted Click Over Click) [ 8,12]
to describe the over- and under-estimation within that bin.
For some cases, the over- and under-estimation within each bin
are close, while in other cases, there is a significant difference in
over- and under-estimation for each bin. We define the "Miscalibra-
tion Complexity" metric to characterize the disparity in over- and
under-estimation across different pCTR bins. We selected all field
values for a subset of fields. For field 𝑧with a value 𝑣, the samples
are divided into 𝑄(𝑄>1) bins. The miscalibration complexity is
denoted as D𝑍,𝑣as follows:
D𝑍,𝑣=1
𝑄−1𝑄−1∑︁
𝑏𝑖𝑛=1|𝑃𝐶𝑂𝐶𝑏𝑖𝑛+1−𝑃𝐶𝑂𝐶𝑏𝑖𝑛|. (26)
In general, the higher the miscalibration complexity, the higher
the disparity in over- and under-estimation within the bins. For a
calibrator, a higher miscalibration complexity indicates a greater
calibration challenge. On one hand, it requires higher precision in
shaping the accuracy of the calibration, and on the other hand, an
excessive reliance on posterior data can compromise the general-
ization capability of the calibrator.
We still use the ECE metric to characterize the calibration error
of different calibrators under the specific field value. We compare
MBCT, FAC, Ada, and DESC and obtain the 𝐸𝐸𝑅𝐶𝑎𝑙𝑖𝑏 .
For each calibrator and each field value, there is a corresponding
D𝑍,𝑣value as the x-axis and 𝐸𝐸𝑅𝐶𝑎𝑙𝑖𝑏 as the y-axis. As shown in
Figure 9, we can observe that in the high D𝑍,𝑣range, all𝐸𝐸𝑅𝐶𝑎𝑙𝑖𝑏
6124Deep Ensemble Shape Calibration: Multi-Field Post-hoc Calibration in Online Advertising KDD ’24, August 25–29, 2024, Barcelona, Spain
values are less than 1, which indicates that DESC always performs
better in conditions of complex shapes compared to other methods.
5.4 Online Results
To prove the effectiveness of the proposed method, we further con-
duct real-world online experiments. We feed item ID with 5 million
unique values, category ID with 5,000 unique values, bidding type,
time, raw predict score and other features into DESC. Then the
model is deployed for online pCVR calibration on Shopee’s adver-
tising system. For the online A/B test, we build two experimental
buckets, each with ten percent of the traffic. One bucket was con-
figured with SIR [ 15] as the control group, while the other was
configured with DESC as the experimental group. We use the two
significant important business metrics CVR (Conversion Rate) and
GMV (Gross Merchandise Volume) to evaluate our calibration ef-
fectiveness. The online results over a 7-day period indicated that
DESC brings +2.5% on CVR and +4.0% on GMV compared to SIR.
These improvements verify the effectiveness and business values
of DESC in practical advertising system.
6 DISCUSSION
We propose a new calibration approach named DESC. Firstly, we put
forward multiple types of functions (e.g., power function, scaling
function, logarithmic function) as the basis functions. Secondly,
we allocate the appropriate basis functions to combine the shape
function given the specific field and specific value. Finally, all fields
are concatenated and used to calculate the weight for the calibration
value from each field, which can further improve the accuracy of
pCTR on multiple fields. Both offline and online experiments verify
that DESC achieves significant improvement. In future work, we
should explore the performance of our proposed method on other
machine learning tasks except CXR task. Also, we need to study
the reasons of miscalibration error in these machine learning tasks,
especially for CXR task, and find new technology ( e.g.data augment,
multi-tasking learning) to further improve the performance.
References
[1]Antonio Bella, Cèsar Ferri, José Hernández-Orallo, and María José Ramírez-
Quintana. 2010. Calibration of machine learning models. In Handbook of Research
on Machine Learning Applications and Trends: Algorithms, Methods, and Techniques .
IGI Global, 128–146.
[2]Weijie Bian, Kailun Wu, Lejian Ren, Qi Pi, Yujing Zhang, Can Xiao, Xiang-Rong
Sheng, Yong-Nan Zhu, Zhangming Chan, Na Mou, et al .2022. CAN: feature
co-action network for click-through rate prediction. In Proceedings of the fifteenth
ACM international conference on web search and data mining. 57–65.
[3]Heng-Tze Cheng, Levent Koc, Jeremiah Harmsen, Tal Shaked, Tushar Chandra,
Hrishi Aradhye, Glen Anderson, Greg Corrado, Wei Chai, Mustafa Ispir, et al .
2016. Wide & deep learning for recommender systems. In Proceedings of the 1st
workshop on deep learning for recommender systems. 7–10.
[4]James Davidson, Benjamin Liebald, Junning Liu, Palash Nandy, Taylor Van Vleet,
Ullas Gargi, Sujoy Gupta, Yu He, Mike Lambert, Blake Livingston, et al .2010.
The YouTube video recommendation system. In Proceedings of the fourth ACM
conference on Recommender systems. 293–296.
[5] Chao Deng, Hao Wang, Qing Tan, Jian Xu, and Kun Gai. 2021. Calibrating user
response predictions in online advertising. In Machine Learning and Knowledge
Discovery in Databases: Applied Data Science Track: European Conference, ECML
PKDD 2020, Ghent, Belgium, September 14–18, 2020, Proceedings, Part IV. Springer,
208–223.
[6]Chao Du, Zhifeng Gao, Shuo Yuan, Lining Gao, Ziyan Li, Yifan Zeng, Xiaoqiang
Zhu, Jian Xu, Kun Gai, and Kuang-Chih Lee. 2021. Exploration in online adver-
tising systems with deep uncertainty-aware learning. In Proceedings of the 27th
ACM SIGKDD Conference on Knowledge Discovery & Data Mining. 2792–2801.
[7]Shai Feldman, Stephen Bates, and Yaniv Romano. 2023. Calibrated multiple-
output quantile regression with representation learning. Journal of Machine
Learning Research 24, 24 (2023), 1–48.[8]Thore Graepel, Joaquin Quinonero Candela, Thomas Borchert, and Ralf Herbrich.
2010. Web-scale bayesian click-through rate prediction for sponsored search
advertising in microsoft’s bing search engine. Omnipress.
[9]Chuan Guo, Geoff Pleiss, Yu Sun, and Kilian Q Weinberger. 2017. On calibration of
modern neural networks. In International conference on machine learning. PMLR,
1321–1330.
[10] Huifeng Guo, Ruiming Tang, Yunming Ye, Zhenguo Li, and Xiuqiang He. 2017.
DeepFM: a factorization-machine based neural network for CTR prediction. arXiv
preprint arXiv:1703.04247 (2017).
[11] Chirag Gupta, Aleksandr Podkopaev, and Aaditya Ramdas. 2020. Distribution-
free binary classification: prediction sets, confidence intervals and calibration.
Advances in Neural Information Processing Systems 33 (2020), 3711–3723.
[12] Xinran He, Junfeng Pan, Ou Jin, Tianbing Xu, Bo Liu, Tao Xu, Yanxin Shi, Antoine
Atallah, Ralf Herbrich, Stuart Bowers, et al .2014. Practical lessons from predicting
clicks on ads at facebook. In Proceedings of the eighth international workshop on
data mining for online advertising. 1–9.
[13] Siguang Huang, Yunli Wang, Lili Mou, Huayue Zhang, Han Zhu, Chuan Yu,
and Bo Zheng. 2022. MBCT: Tree-Based Feature-Aware Binning for Individual
Uncertainty Calibration. In Proceedings of the ACM Web Conference 2022. 2236–
2246.
[14] Tongwen Huang, Zhiqi Zhang, and Junlin Zhang. 2019. FiBiNET: combining fea-
ture importance and bilinear feature interaction for click-through rate prediction.
InProceedings of the 13th ACM Conference on Recommender Systems. 169–177.
[15] Xiaoqian Jiang, Melanie Osl, Jihoon Kim, and Lucila Ohno-Machado. 2011.
Smooth isotonic regression: a new method to calibrate predictive models. AMIA
Summits on Translational Science Proceedings 2011 (2011), 16.
[16] Kevin B Korb. 1999. Calibration and the evaluation of predictive learners. In
Proceedings of the Sixteenth International Joint Conference on Artificial Intelligence .
Citeseer, 73–77.
[17] Meelis Kull, Miquel Perello Nieto, Markus Kängsepp, Telmo Silva Filho, Hao Song,
and Peter Flach. 2019. Beyond temperature scaling: Obtaining well-calibrated
multi-class probabilities with dirichlet calibration. Advances in neural information
processing systems 32 (2019).
[18] Meelis Kull, Telmo Silva Filho, and Peter Flach. 2017. Beta calibration: a well-
founded and easily implemented improvement on logistic calibration for binary
classifiers. In Artificial Intelligence and Statistics. PMLR, 623–631.
[19] Ananya Kumar, Percy S Liang, and Tengyu Ma. 2019. Verified uncertainty
calibration. Advances in Neural Information Processing Systems 32 (2019).
[20] Wonbin Kweon, SeongKu Kang, and Hwanjo Yu. 2022. Obtaining Calibrated
Probabilities with Personalized Ranking Models. In Proceedings of the AAAI
Conference on Artificial Intelligence, Vol. 36. 4083–4091.
[21] Xiao Ma, Liqin Zhao, Guan Huang, Zhi Wang, Zelin Hu, Xiaoqiang Zhu, and Kun
Gai. 2018. Entire space multi-task model: An effective approach for estimating
post-click conversion rate. In The 41st International ACM SIGIR Conference on
Research & Development in Information Retrieval. 1137–1140.
[22] Dang Minh Nguyen, Chenfei Wang, Yan Shen, and Yifan Zeng. 2023. LightSAGE:
Graph Neural Networks for Large Scale Item Retrieval in Shopee’s Advertisement
Recommendation. In Proceedings of the 17th ACM Conference on Recommender
Systems. 334–337.
[23] Yaniv Ovadia, Emily Fertig, Jie Ren, Zachary Nado, David Sculley, Sebastian
Nowozin, Joshua Dillon, Balaji Lakshminarayanan, and Jasper Snoek. 2019. Can
you trust your model’s uncertainty? evaluating predictive uncertainty under
dataset shift. Advances in neural information processing systems 32 (2019).
[24] Feiyang Pan, Xiang Ao, Pingzhong Tang, Min Lu, Dapeng Liu, Lei Xiao, and
Qing He. 2020. Field-aware calibration: a simple and empirically strong method
for reliable probabilistic predictions. In Proceedings of The Web Conference 2020.
729–739.
[25] John Platt et al .1999. Probabilistic outputs for support vector machines and com-
parisons to regularized likelihood methods. Advances in large margin classifiers
10, 3 (1999), 61–74.
[26] Ying Shan, T Ryan Hoens, Jian Jiao, Haijing Wang, Dong Yu, and JC Mao. 2016.
Deep crossing: Web-scale modeling without manually crafted combinatorial
features. In Proceedings of the 22nd ACM SIGKDD international conference on
knowledge discovery and data mining. 255–262.
[27] Jizhe Wang, Pipei Huang, Huan Zhao, Zhibo Zhang, Binqiang Zhao, and Dik Lun
Lee. 2018. Billion-scale commodity embedding for e-commerce recommendation
in alibaba. In Proceedings of the 24th ACM SIGKDD international conference on
knowledge discovery & data mining. 839–848.
[28] Zhiqiang Wang, Qingyun She, and Junlin Zhang. 2021. MaskNet: Introducing
feature-wise multiplication to CTR ranking models by instance-guided mask.
arXiv preprint arXiv:2102.07619 (2021).
[29] Penghui Wei, Weimin Zhang, Ruijie Hou, Jinquan Liu, Shaoguo Liu, Liang Wang,
and Bo Zheng. 2022. Posterior Probability Matters: Doubly-Adaptive Calibra-
tion for Neural Predictions in Online Advertising. In Proceedings of the 45th
International ACM SIGIR Conference on Research and Development in Information
Retrieval. 2645–2649.
[30] Hao Yang, Ziliang Wang, Weijie Bian, and Yifan Zeng. 2023. Practice on Effectively
Extracting NLP Features for Click-Through Rate Prediction. In Proceedings of the
6125KDD ’24, August 25–29, 2024, Barcelona, Spain Shuai Yang, Hao Yang, Zhuang Zou, Linhe Xu, Shuo Yuan, and Yifan Zeng
32nd ACM International Conference on Information and Knowledge Management .
4887–4893.
[31] Bianca Zadrozny and Charles Elkan. 2001. Obtaining calibrated probability
estimates from decision trees and naive bayesian classifiers. In Icml, Vol. 1. 609–
616.
[32] Bianca Zadrozny and Charles Elkan. 2002. Transforming classifier scores into ac-
curate multiclass probability estimates. In Proceedings of the eighth ACM SIGKDD
international conference on Knowledge discovery and data mining. 694–699.
[33] Shuangfei Zhai, Keng-hao Chang, Ruofei Zhang, and Zhongfei Mark Zhang. 2016.
Deepintent: Learning attentions for online advertising with recurrent neuralnetworks. In Proceedings of the 22nd ACM SIGKDD international conference on
knowledge discovery and data mining. 1295–1304.
[34] Jize Zhang, Bhavya Kailkhura, and T Yong-Jin Han. 2020. Mix-n-match: Ensem-
ble and compositional methods for uncertainty calibration in deep learning. In
International conference on machine learning. PMLR, 11117–11128.
[35] Han Zhu, Junqi Jin, Chang Tan, Fei Pan, Yifan Zeng, Han Li, and Kun Gai. 2017.
Optimized cost per click in taobao display advertising. In Proceedings of the 23rd
ACM SIGKDD international conference on knowledge discovery and data mining.
2191–2200.
6126