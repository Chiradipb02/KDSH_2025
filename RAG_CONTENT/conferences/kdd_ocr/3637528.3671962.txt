Self-Explainable Temporal Graph Networks based on
Graph Information Bottleneck
Sangwoo Seo
KAIST
Daejeon, Republic of Korea
sangwooseo@kaist.ac.krSungwon Kim
KAIST
Daejeon, Republic of Korea
swkim@kaist.ac.krJihyeong Jung
KAIST
Daejeon, Republic of Korea
mjajthh1@kaist.ac.kr
Yoonho Lee
KAIST
Daejeon, Republic of Korea
sml0399benbm@kaist.ac.krChanyoung Park‚àó
KAIST
Daejeon, Republic of Korea
cy.park@kaist.ac.kr
ABSTRACT
Temporal Graph Neural Networks (TGNN) have the ability to cap-
ture both the graph topology and dynamic dependencies of inter-
actions within a graph over time. There has been a growing need
to explain the predictions of TGNN models due to the difficulty
in identifying how past events influence their predictions. Since
the explanation model for a static graph cannot be readily applied
to temporal graphs due to its inability to capture temporal depen-
dencies, recent studies proposed explanation models for temporal
graphs. However, existing explanation models for temporal graphs
rely on post-hoc explanations, requiring separate models for predic-
tion and explanation, which is limited in two aspects: efficiency and
accuracy of explanation. In this work, we propose a novel built-in
explanation framework for temporal graphs, called Self-Explainable
Temporal Graph Networks based on Graph Information Bottleneck
(TGIB). TGIB provides explanations for event occurrences by in-
troducing stochasticity in each temporal event based on the Infor-
mation Bottleneck theory. Experimental results demonstrate the
superiority of TGIB in terms of both the link prediction performance
and explainability compared to state-of-the-art methods. This is the
first work that simultaneously performs prediction and explanation
for temporal graphs in an end-to-end manner. The source code of
TGIB is available at https://github.com/sang-woo-seo/TGIB.
CCS CONCEPTS
‚Ä¢Computing methodologies ‚ÜíMachine learning.
KEYWORDS
Graph Neural Network, Explainable AI, Temporal Graph
ACM Reference Format:
Sangwoo Seo, Sungwon Kim, Jihyeong Jung, Yoonho Lee, and Chanyoung
Park. 2024. Self-Explainable Temporal Graph Networks based on Graph
Information Bottleneck. In Proceedings of the 30th ACM SIGKDD Conference
‚àóCorresponding author.
This work is licensed under a Creative Commons Attribution
International 4.0 License.
KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain
¬©2024 Copyright held by the owner/author(s).
ACM ISBN 979-8-4007-0490-1/24/08
https://doi.org/10.1145/3637528.3671962on Knowledge Discovery and Data Mining (KDD ‚Äô24), August 25‚Äì29, 2024,
Barcelona, Spain. ACM, New York, NY, USA, 12 pages. https://doi.org/10.
1145/3637528.3671962
1 INTRODUCTION
Temporal Graph Neural Networks (TGNN) possess the capabil-
ity to capture interactions over time in graph-structured data and
demonstrate high utility in areas such as user-item interaction in
e-commerce [ 15] and friend relationships in social networks [ 6,21].
TGNNs incorporate both temporal dynamics and graph topology in
their approach and focus on learning time-dependent node repre-
sentation to predict future evolutions [ 3,24,40]. However, TGNN
models are considered as black boxes with limited transparency due
to the inability to discern how past events influence outcomes. Offer-
ing insights based on the logic of predictions in TGNN contributes
to an improved comprehension of the model‚Äôs decision-making
and provides rationality for predictions. Explainability for TGNN
can be applied in high-risk situations such as healthcare forecast-
ing [ 2,14] and fraud detection [ 23,29] to enhance the model‚Äôs
reliability, and assists in examining and mitigating issues related to
privacy, fairness, and safety in real-world applications [5].
Explainability aims to provide users with evidence within the
data that influenced a model prediction. With the emerging neces-
sity for explainability, explanation models for static graphs have
been actively studied in recent times [ 13,16,41]. These models
induce perturbations in the input of the model to detect the nodes
and edges, which significantly impact the final prediction. However,
these models cannot be easily generalized to temporal graphs due
to the high dynamicity of temporal graphs. Specifically, explanation
models for static graphs cannot capture the graph topology that is
dynamic in nature [ 40,42]. For example, in a temporal graph, multi-
ple events may occur over time between the same pair of nodes, and
these events may have different importance depending on when
the event occurred. In other words, events that occurred a long
time ago may have less influence on the current event compared to
events that occurred more recently.
Recently, T-GNNExplainer [ 39] attempted to explain the model
predictions on temporal graphs. Specifically, T-GNNExplainer con-
sists of a navigator that learns inductive relationships between
target events (those that are to be predicted) and candidate events
(those that may serve as reasons for the prediction), and an explorer
that explores the optimal combinations of candidate events for each
 
2572
KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain Sangwoo Seo, Sungwon Kim, Jihyeong Jung, Yoonho Lee, & Chanyoung Park
T-GNNExplainer
Our Self-Explainable TGIBTemporal GraphùúÉ!"##"ùëåStep1. Train a graph modelStep2. Find an explanationùúÉ$%&'()*)ùúÉ#+,-.+/()Temporal GraphùúÉ!"01"ùëå‚Ñõexplanationprediction
‚Ñõ‚Ä£Expensiveprocesses for retraining‚Ä£Built-in‚Ä£Post-hoc‚Ä£MCTSbased explanation‚Ä£Pretrainingrequired for the navigator
‚Ä£End-to-end‚Ä£Simultaneousprediction and explanation
Figure 1: Comparison between T-GNNexplainer and TGIB.
target event based on Monte Carlo Tree Search (MCTS) [ 28] (upper
part of Figure 1). T-GNNExplainer is a post-hoc explanation method
because explanations are generated based on a pretrained base
model (i.e., TGNN). Despite its effectiveness, T-GNNExplainer has
two major drawbacks that originate from its post-hoc manner of
generating explanations. First, since a temporal graph consistently
encounter changes in the topology due to its dynamic nature, the
base model needs to be consistently retrained. This results in the
repeated retraining of the explanation model (i.e., navigator and ex-
plorer) based on the retrained base model (i.e., TGNN), which makes
T-GNNExplainer inefficient especially when the base model is large.
The complexity issue aggravates as the explanations are generated
based on MCTS, which is a highly inefficient search algorithm.
Second, since post-hoc explanation methods provide explanations
by examining the behavior of an already trained base model, it
becomes challenging to fully comprehend the learning process of
the base model, and to provide accurate explanations [45].
As a solution to address the drawbacks of post-hoc explanation
methods when applied to temporal graphs, we propose to allow
the model to simultaneously perform both predictions and expla-
nations in temporal graphs by generating intrinsic explanations
within the model itself (i.e., built-in explanation method) (lower part
of Figure 1). Existing post-hoc explanation methods for temporal
graphs such as T-GNNExplainer focus on deriving subgraphs that
generate predictions as similar as possible to the predictions of the
base model for the target event. On the other hand, since our pro-
posed built-in explanation method does not have a base model, we
induce interactions between the target event representation at the
current timestamp and the candidate event representations at past
timestamps to extract the importance probability of each candidate
event. To consider the interaction of representations at different
timestamps, we generate time-aware representations by taking into
account the time spans between the target event and candidate
events. The time-aware representations facilitates our model to
identify important candidate events that are used as explanations
for the model predictions. Our goal is to detect significant past
events in temporal graphs based on the constructed time-aware
representations.
To this end, we propose a novel built-in explanation framework
for temporal graphs, called Self-Explainable Temporal Graph Net-
works based on Graph Information Bottleneck (TGIB). The mainidea is to build an end-to-end model that can simultaneously gener-
ate predictions for temporal graphs along with explanations based
on the Information Bottleneck (IB) approach, which enables the
model to detect important subgraphs by leveraging the time-aware
representations. Specifically, TGIB considers the interaction be-
tween the target event and candidate events to extract important
candidate events, eventually predicting the occurrence of the target
event. We formalize the prediction process for temporal graphs
with the IB to restrict the flow of information from candidate
events to predictions by injecting stochasticity into edges [ 26].
The stochasticity for label-relevant components decreases during
training, whereas the stochasticity for label-irrelevant components
is maintained. This difference in stochasticity eventually provides
explanations for the occurrence of the target events. We expect
improved generalization performance of TGIB by penalizing the
amount of information from input data.
We conducted extensive experiments to evaluate the prediction
performance and the explainability of TGIB in the event occurrence
prediction task. Our results show that TGIB outperforms existing
link prediction models in both transductive and inductive environ-
ments. We also evaluated the explainability of TGIB in capturing
the label information by evaluating its prediction performance with
only the detected explanation graphs. We also demonstrate that
explanation graphs with varying sparsities exhibit a higher expla-
nation performance than existing explanation models. Overall, our
results show that TGIB not only significantly improves the perfor-
mance of the event occurrence prediction, but also provides superior
performance in terms of explanations. To the best of our knowledge,
this is the first study to simultaneously perform predictions and
explanations in temporal graphs.
In summary, our main contributions are summarized as follows:
‚Ä¢We propose an explainable graph neural network model for
temporal graphs that can simultaneously perform prediction
and explanation.
‚Ä¢We provide a theoretical background of TGIB based on the IB
framework regarding the extraction of important past events
for predicting the occurrence of the target event.
‚Ä¢Extensive experiments demonstrate that TGIB outperforms
state-of-the-art methods in terms of both link prediction per-
formance and explainability.
2 RELATED WORK
2.1 Temporal Graph Neural Networks
Unlike ordinary Graph Neural Networks for a static graph, TGNNs
produce dynamic node embeddings from a temporal graph evolving
with a series of events. Early methods [ 4,11,32] used RNN-based
architectures to produce temporal node embeddings by only consid-
ering nodes involved in each of specific events. As these methods
merely use direct connectivity represented as a single event, the
Self-Attention Mechanism (SAM) [ 33] was adopted in recent meth-
ods for modeling more complex spatial and temporal relationships.
TGAT [ 40] applied SAM for simultaneous modeling of both spatial
and temporal relationships with functional time encodings based
on Bochner‚Äôs theorem. TGN [ 24] first updates the node memory for
temporal dependency by using an RNN-based model and computes
 
2573Self-Explainable Temporal Graph Networks based on
Graph Information Bottleneck KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain
node embeddings by a SAM-based model with spatial and temporal
information similar to [ 40]. TCL [ 36] also utilized the SAM-based
architecture considering both spatial and temporal dependencies
while using a contrastive learning scheme by regarding an inter-
acted node as a positive sample. On the other hand, GraphMixer [ 3]
showed effectiveness with a simple MLP-based architecture and
argued neither RNN nor SAM is mandatory for TGNNs.
2.2 Graph Information Bottleneck
As the Information Bottleneck (IB) principle enables a model to ex-
tract information within the input data that is relevant to the target
(i.e., label) information, it has been widely adopted in the various
fields of machine learning [ 1,7,19]. Inspired by their successes,
recent studies regarding the IB principle on graph-structured data
were proposed. GIB [ 38] extended the IB principle on GNNs by
extracting both minimal and sufficient information from both the
graph structure and node features. Extending this, GIB [ 44] uti-
lized the IB principle for recognizing an important subgraph (i.e.,
IB-Graph) within the input graph, and then applied the IB-Graph
for improving the graph classification performance. Additionally,
VGIB [ 43] utilized learnable random noise injection in the subgraph
recognition process to enable flexible subgraph compression. Mean-
while, CGIB [ 12] applied the graph information bottleneck in molec-
ular relational learning by finding a core subgraph of one molecule
based on the paired molecule and the target label. Furthermore,
PGIB [ 25] approached the information bottleneck principle from
a prototype perspective to provide prototypes with the subgraph
from the input graph which is important for model prediction.
2.3 GNN Explainability
Although Graph Neural Networks (GNNs) have been shown to be
effective on graph data [ 10,34], analyzing the reason of the predic-
tion and the decision-making process of these models has been a
long-standing challenge due to their complex architectures. For this
reason, approaches for explainable AI (XAI) have been recently pro-
posed to understand black-box GNNs [ 16,22,35,41]. Despite their
effectiveness, as these approaches are post-hoc methods, they are
both ineffective and inefficient when changes occur not only in the
training data but also the trained model to be explained. Therefore,
self-explainable (i.e., built-in ) [17,25,45] approaches have been re-
cently gained attention. They contain an explanatory module inside
the model to make predictions and explanations simultaneously,
addressing the limitations of post-hoc approaches. However, all the
aforementioned methods are designed for static graphs, and can-
not be readily applied to temporal graphs due to their dynamicity.
Recently, T-GNNExplainer [ 39] is proposed to give an explanation
on TGNNs trained on temporal graphs, which, however, has major
drawbacks due to its post-hoc manner as mentioned in Section 1. Ad-
ditionally, STExplainer [ 30] generates separate explanation graphs
for spatial and temporal graphs in traffic and crime prediction. How-
ever, to explain event occurrence predictions in a way that is easy
for humans to understand, it is necessary to generate a comprehen-
sive explanation graph as a set of temporal events. To this end, we
propose TGIB that can simultaneously generate predictions and
explanations in temporal graphs by detecting past events that are
important for the predictions based on the IB principle.3 PRELIMINARIES
3.1 Temporal Graph Model
A temporal graph contains a series of continuous events ùëÜ={ùëí1,ùëí2,¬∑¬∑¬∑}
with timestamps, where ùëíùëñ={ùë¢ùëñ,ùë£ùëñ,ùë°ùëñ,attùëñ}indicates an interaction
event between node ùë¢ùëñandùë£ùëñat timestamp ùë°ùëñwith edge attribute
attùëñ. The event set ùëÜcomposes a temporal graph G=(V,E), where
Eis regarded as edges with timestamps and Vrepresents the nodes
included in E. Since the definitions of VandEare interdependent,
we consider a temporal graph Gas a set of events. We define Gùëòas
the graph constructed immediately before the timestamp ùë°ùëòwhich
includes all events {ùëí1,ùëí2,¬∑¬∑¬∑,ùëíùëò‚àí1}excludingùëíùëò. Letùëìdenote a
self-explainable temporal graph model that we aim to learn. The
modelùëìsimultaneously predicts the occurrence of interactions
between two nodes at a certain timestamp, and explains the rea-
son for its prediction regarding the occurrence or absence of the
eventùëíùëò. The output of the model ùëì, i.e.,ùëì(Gùëò)[ùëíùëò], consists of two
components: the label prediction indicating whether the event ùëíùëò
is present or absent, i.e., ÀÜùëå, and an explanation for the presence or
absence ofùëíùëò, i.e.,Rùëò‚ààGùëò, whereGùëòis theùêø-hop computation
graph ofùëíùëò, andRùëòis a subgraph ofGùëòconsidered as important
events. Note thatGùëòofùëíùëò={ùë¢ùëò,ùë£ùëò,ùë°ùëò,attùëò}is a combination of
theùêø-hop computation graphs of node ùë¢ùëòand nodeùë£ùëò.
3.2 Graph Information Bottleneck
The mutual information denoted as ùêº(ùëã;ùëå)between two random
variablesùëãandùëåis formally defined as:
ùêº(ùëã;ùëå)=‚à´
ùëã‚à´
ùëåùëù(ùë•,ùë¶)logùëù(ùë•,ùë¶)
ùëù(ùë•)ùëù(ùë¶)dùë•dùë¶. (1)
Given an input denoted as ùëãand its corresponding label ùëå, the
Information Bottleneck (IB) [ 31] aims to optimize the following
objective function in order to derive a bottleneck variable ùëças:
min
ùëç‚àíùêº(ùëå;ùëç)+ùõΩùêº(ùëã;ùëç), (2)
whereùõΩenables the regulation of the balance between two terms
as the Lagrange multiplier. The IB principle has found recent appli-
cation in learning a bottleneck graph, referred to as the IB-Graph,
for a given graphG, which aims to preserve the minimal necessary
information concerning the properties of Gwhile capturing the
maximal information about the label ùëå. This approach compres-
sively identifies label-related information from the original graph
G, inspired by the Graph Information Bottleneck (GIB) principle
by optimizing the objective function as:
min
Gùë†ùë¢ùëè‚àíùêº(ùëå;Gùë†ùë¢ùëè)+ùõΩùêº(G;Gùë†ùë¢ùëè), (3)
whereGùë†ùë¢ùëèis the IB-Graph and ùëåis the label ofG. The first term
aims to maximize the mutual information between the graph label
and the subgraph to include as much graph label information ùëåas
possible in the subgraph Gùë†ùë¢ùëè. The second term aims to minimize
the mutual information between the original graph and the sub-
graph to include the original graph Gin the subgraphGùë†ùë¢ùëèto a
minimum extent.
4 METHODOLOGY
We present our proposed method, called TGIB. We introduce GIB-
based objective for a temporal graph (Section 4.1), time-aware event
 
2574KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain Sangwoo Seo, Sungwon Kim, Jihyeong Jung, Yoonho Lee, & Chanyoung Park
representation (Section 4.2), neural network parameterization for
each term of the objective function (Section 4.3 and 4.4) and spurious
correlation removal (Section 4.5). The entire process is presented
in Figure 2. We also include the pseudocode in Appendix D.
4.1 GIB-based Objective for Temporal Graph
We provide the objective of the Graph Information Bottleneck for
temporal graphs. TGIB extracts a bottleneck code Rùëòfor the target
edgeùëíùëòfrom itsùêø-hop neighborhood Gùëò. Specifically, the bottle-
neck codeRùëòis a subgraph of ùëíùëò‚Äôsùêø-hop computation graph. The
bottleneck mechanism on neighborhood information provides ex-
planations for the prediction of ùëíùëò. The objective function of the
graph information bottleneck is provided as follows:
min
Rùëò‚àíùêº
ùëåùëò;Rùëò
|        {z        }
Section 4.4+ùõΩùêº
Rùëò;ùëíùëò,Gùëò
|           {z           }
Section 4.3. (4)
whereùëåùëòis the label information regarding the occurrence of ùëíùëò.
The first term‚àíùêº
ùëåùëò;Rùëò
allowsRùëòto sufficiently learn label-
relevant information, while the second term ùêº
Rùëò;ùëíùëò,Gùëò
ensures
thatRùëòefficiently includes only important information related to
ùëíùëòandGùëòand removes unnecessary information. However, directly
optimizing Equation 4 is challenging because of the difficulty of
directly calculating the mutual information.
Inspired by [ 1], we obtain the upper bound of ‚àíùêº
ùëåùëò;Rùëò
in
Equation 4 as follows:
‚àíùêº(ùëåùëò;Rùëò)=Eùëåùëò,ùëíùëò,Rùëòh
‚àílogùëù
ùëåùëò|Rùëòi
‚àíùêª(ùëå)
‚â§Eùëåùëò,Rùëòh
‚àílogùëûùúÉ
ùëåùëò|Rùëòi
‚àíùêª(ùëå)
‚â§Eùëåùëò,Rùëòh
‚àílogùëûùúÉ
ùëåùëò|Rùëòi
BLcls,(5)
whereùëûùúÉ
ùëåùëò|Rùëò
is the variational approximation of ùëù
ùëåùëò|Rùëò
.
We modelùëûùúÉ
ùëåùëò|Rùëò
as a predictor which outputs predictions for
the occurrence of ùëíùëòbased on the subgraph Rùëò. We can maximize
ùêº(ùëåùëò;Rùëò)by minimizingLclsusing the predictor.
Moreover, we obtain the upper bound of ùêº
Rùëò;ùëíùëò,Gùëò
in Equa-
tion 4 as follows:
ùêº(Rùëò;ùëíùëò,Gùëò)=ERùëò,ùëíùëò,Gùëòh
logùëù
Rùëò|ùëíùëò,Gùëò
‚àílogùëù
Rùëòi
‚â§ERùëò,ùëíùëò,Gùëòh
logùëù
Rùëò|ùëíùëò,Gùëò
‚àílogùëû
Rùëòi
‚â§Eùëíùëò,Gùëòh
KLh
ùëù
Rùëò|ùëíùëò,Gùëò
‚à•ùëû
Rùëòii
BLMI,
(6)
whereùëû
Rùëò
is the variational approximation of ùëù
Rùëò
and KL
represents the Kullback-Leibler(KL) divergence. ùëû
Rùëò
can be flex-
ibly applied to various distributions, including normal distributions.
We can minimize the upper bound of ùêº(Rùëò;ùëíùëò,Gùëò)by minimizing
LMI.
Finally, we obtain the final loss function for the graph informa-
tion bottleneck as follows: Lùë°ùëúùë°ùëéùëô=Lcls+ùõΩLMI.4.2 Time-aware event representation
We generate time-aware event representations to capture the tem-
poral information of events. Inspired by [ 40], we obtain node rep-
resentations by performing self-attention based on temporal en-
coding. We consider the neighboring nodes for node ùëßat timeùë°as
N(ùëß;ùë°)={ùëß1,ùëß2,¬∑¬∑¬∑,ùëßùëõ}, whereùëõis the number of neighbors. The
interaction between ùëßand one of its neighbor ùëßùëñhas edge attribute
ùëéùë°ùë°ùëß,ùëñ‚ààRùëìedgeand occurs at time ùë°ùëß,ùëñ, which is earlier than ùë°. We use
the representations of neighbors, attributes of their interactions,
and their temporal information as the input to the self-attention
layer. We use ‚Ñé(ùëô)
ùëß(ùë°)‚ààRùëëto denote the representation of node ùëß
at timeùë°in theùëô-th layer, where ‚Ñé(0)
ùëß(ùë°)is the raw node feature of
nodeùëß, denoted as ùë•ùëß‚ààRùëìnode, that is invariant over time ùë°. For the
self-attention mechanism, we define the query, key and value as:
ùëÑ(ùëô)(ùë°)=h
‚Ñé(ùëô‚àí1)
ùëß(ùë°)‚à•ùëéùë°ùë°ùëß,0‚à•Œ¶ùëëùëá(0)i
,
ùêæ(ùëô)(ùë°)=Ô£ÆÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£∞ùêæ(ùëô)
1(ùë°)
...
ùêæ(ùëô)
ùëõ(ùë°)Ô£πÔ£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£ª=Ô£ÆÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£∞‚Ñé(ùëô‚àí1)
ùëß1(ùë°ùëß,1)‚à•ùëéùë°ùë°ùëß,1‚à•Œ¶ùëëùëá(ùë°‚àíùë°ùëß,1)
...
‚Ñé(ùëô‚àí1)
ùëßùëõ(ùë°ùëß,ùëõ)‚à•ùëéùë°ùë°ùëß,ùëõ‚à•Œ¶ùëëùëá(ùë°‚àíùë°ùëß,ùëõ)Ô£πÔ£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£ª,
ùëâ(ùëô)(ùë°)=Ô£ÆÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£∞ùëâ(ùëô)
1(ùë°)
...
ùëâ(ùëô)
ùëõ(ùë°)Ô£πÔ£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£ª=Ô£ÆÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£∞‚Ñé(ùëô‚àí1)
ùëß1(ùë°ùëß,1)‚à•ùëéùë°ùë°ùëß,1‚à•Œ¶ùëëùëá(ùë°‚àíùë°ùëß,1)
...
‚Ñé(ùëô‚àí1)
ùëßùëõ(ùë°ùëß,ùëõ)‚à•ùëéùë°ùë°ùëß,ùëõ‚à•Œ¶ùëëùëá(ùë°‚àíùë°ùëß,ùëõ)Ô£πÔ£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£ª,(7)
where Œ¶ùëëùëá:R‚ÜíRùëëùëáis time encoding that provides a continuous
functional mapping from the time domain to the vector space with
ùëëùëádimensions. According to the translation-invariant assumption
of time encoding, we use
ùë°‚àíùë°ùëß,1,ùë°‚àíùë°ùëß,2,¬∑¬∑¬∑,ùë°‚àíùë°ùëß,ùëõ	as the in-
teraction times. This means that we only consider the time span
since time encoding is designed to measure the temporal distance
between nodes, which is more important than the absolute value
of time.
Each node collects information from its neighboring nodes, and
in this process, the attention weightsn
ùõº(ùëô)
ùëñ(ùë°)oùëõ
ùëñ=1are defined as:
ùõº(ùëô)
ùëñ(ùë°)=softmax¬©¬≠¬≠
¬´ùëÑ(ùëô)(ùë°)ùêæ(ùëô)
ùëñ(ùë°)ùëá
‚àöÔ∏É
(ùëë+ùëìedge+ùëëùëá)¬™¬Æ¬Æ
¬¨‚ààRùëõ, (8)
whereùêæ(ùëô)
ùëñ(ùë°)is theùëñ-th row of ùêæ(ùëô)(ùë°). The attention weight
ùõº(ùëô)
ùëñ(ùë°)indicates the contribution of node ùëßùëñto the features of node
ùëßwithin the topological structure N(ùëß;ùë°), considering the interac-
tion timeùë°withùëßcomputed at layer ùëô. We utilize self-attention to
incorporate temporal interactions into node features and structural
information. The representation for a node ùëßùëñwithin the neighbor-
hoodN(ùëß;ùë°)is calculated as ùõº(ùëô)
ùëñ(ùë°)¬∑ùëâ(ùëô)
ùëñ(ùë°)based on the attention
weightùõº(ùëô)
ùëñ(ùë°). Finally, we obtain the hidden neighborhood repre-
sentations as follows1:
Àú‚Ñé(ùëô)
ùëß(ùë°)=Attn
ùëÑ(ùëô)(ùë°),ùêæ(ùëô)(ùë°),ùëâ(ùëô)(ùë°)
=softmax 
ùëÑ(ùëô)(ùë°)ùêæ(ùëô)(ùë°)ùëá
‚àöÔ∏Å(ùëë+ùëìedge+ùëëùëá)!
ùëâ(ùëô)(ùë°).(9)
1To remove clutter, we omit weights for query, key, and value, i.e., ùëäùëÑ,ùëäùêæùëäùëâ,
that exist for each layer ùëô.
 
2575Self-Explainable Temporal Graph Networks based on
Graph Information Bottleneck KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain
ùëí!ùëí!
Œ¶!!(0)ùëéùë°ùë°"‚Ñé#"ùë°"‚Ñé$"ùë°"‚®Å
Œ¶!!(ùë°"‚àíùë°%)ùëéùë°ùë°%‚Ñé##ùë°%‚Ñé$#ùë°%ùëã&"ùë°"ùëç&#ùë°"ùúéSamplingif ùõº$%= 1ùëí%‚ààùí¢"‚Ñõ!""ùëí!‚ë†Temporal graph ùêÜ"‚ë°Computational graph ùí¢"of ùëí"‚ë¢Explanation graph ‚Ñõ!"",‚Ñõ!"#$%"
‚®Å‚Ñí#$
‚Ñõ!"#$%"Œ¶!!(0)ùëéùë°ùë°"‚Ñé#"ùë°"‚Ñé("ùë°"‚®Åùëã&"&'(ùë°"ùëí%)*+
ùëí!&'(: Computational graph ùí¢": Explanation graph ‚Ñõ"for ùëí": Item node ùë£: User node ùë¢
: Explanation graph ‚Ñõ"for ùëí"&!': Target event ùëí"
ùë¢"ùë£"ùëí"
ùëí!&'(ùë¢"ùëõ"event representation
Readout‚ë£Predictionùõº~ùêµùëíùëüùëõ(ùëù): Negative sample node ùëõ"
:|ùí¢!||ùí¢!|ùúé: Negative sample event ùëí"&!'
ùëî+if ùõº$)= 1ùêª12#ùëåùëû(ùëå=1‚Ñí)*+ùêª32#ùëåùëû(ùëå=0ùëîSamplingùõº~ùêµùëíùëüùëõ(ùëù)‚Ñí)*+ùëí%)*+
{ùëù%"|ùëí%‚ààùí¢"}
{ùëù%(|ùëí%‚ààùí¢"}{ùõº%"|ùëí%‚ààùí¢"}
{ùõº%(|ùëí%‚ààùí¢"}
Figure 2: The architecture of our proposed TGIB.
We concatenate the neighborhood representation Àú‚Ñé(ùëô)
ùëß(ùë°)with the
feature of node ùëß, i.e.,ùë•ùëß, and use it as the input to a feed-forward
network as follows:
‚Ñé(ùëô)
ùëß(ùë°)=FFNh
Àú‚Ñé(ùëô)
ùëß(ùë°)‚à•ùë•ùëßi
=ReLUh
Àú‚Ñé(ùëô)
ùëß(ùë°)‚à•ùë•ùëßi
ùëä(ùëô)
0+ùëè(ùëô)
0
ùëä(ùëô)
1+ùëè(ùëô)
1,(10)
where‚Ñé(ùëô)
ùëß(ùë°)is the time-aware node embedding for node ùëßat time
ùë°as the output.
Finally, we construct the time-aware event representation for
the target event ùëíùëò={ùë¢ùëò,ùë£ùëò,ùë°ùëò,attùëò}with the representation of
the two nodes ùë¢ùëòandùë£ùëò, time encoding and edge attribute attùëòas
follows:
ùëãùëíùëò(ùë°ùëò)=
‚Ñéùë¢ùëò(ùë°ùëò)‚à•‚Ñéùë£ùëò(ùë°ùëò)‚à•Œ¶ùëëùëá(0)‚à• attùëò
, (11)
whereùëãùëíùëò(ùë°ùëò)denotes the time-aware representation for the target
eventùëíùëòat timeùë°ùëò. Additionally, we define the candidate event
representation, denoted as ùëçùëíùëó, which may potentially be included
within the explanation graph Rùëòas follows:
ùëçùëíùëó(ùë°ùëò)=
‚Ñéùë¢ùëó(ùë°ùëó)‚à•‚Ñéùë£ùëó(ùë°ùëó)‚à•Œ¶ùëëùëá(ùë°ùëò‚àíùë°ùëó)‚à•attùëó
, (12)
where allùëíùëósatisfy the following condition : ùëíùëó‚àà Gùëò, where
1‚â§ùëó‚â§ùëò‚àí1. In the time encoding Œ¶ùëëùëáof the above equations, sim-
ilar to node representation, we consider the time span to measure
the temporal distance between each interaction. It allows time-
aware explanations to sufficiently incorporate temporal distance
information and ensures that the importance scores of multiple
events occurring between the same pair of nodes over time are
dependent on the time span. Therefore, we regard the interaction
time asùë°ùëò‚àíùë°ùëó, whereùë°ùëòis the occurrence time of the target event
ùëíùëò, andùë°ùëóis the occurrence time of the candidate event ùëíùëó.4.3 Minimizing ùêº(Rùëò;ùëíùëò,Gùëò)in Equation 6
In this section, we propose a parameterized time-aware bottleneck
to modelùëù(Rùëò|ùëíùëò,Gùëò)given in Equation 6. To alleviate compu-
tational difficulty, we decompose (Rùëò|ùëíùëò,Gùëò)into a multivariate
Bernoulli distribution as follows:
ùëù(Rùëò|ùëíùëò,Gùëò)=√ñ
ùëíùëó‚ààRùëòùëùùëò
ùëó¬∑√ñ
ùëíùëó‚ààGùëò\Rùëò(1‚àíùëùùëò
ùëó), (13)
whereùëùùëò
ùëóis the probability of ùëíùëógivenùëíùëòandGùëò, i.e.,ùëù(ùëíùëó|ùëíùëò,Gùëò),
following Bernoulli distribution. We apply the Gumbel-Softmax
technique [ 9] for sampling in order to allow gradients to propa-
gate from the classifier to the time-aware bottleneck module in
optimization. Each ùëùùëò
ùëóis computed as the output of an MLP that
takes the target event representation ùëãùëíùëòand the candidate event
representation ùëçùëíùëóas input as follows:
ùëùùëò
ùëó=ùëù(ùëíùëó|ùëíùëò,Gùëò)=ùúé
ùëî
ùëãùëíùëò(ùë°ùëò), ùëçùëíùëó(ùë°ùëò)
(14)
whereùúé(¬∑)is the sigmoid function and ùëîis an MLP. A large ùëùùëò
ùëó
indicates that ùëíùëóis important for predicting ùëíùëòinGùëò.
Next, we define the variational approximation ùëû(Rùëò)of the mar-
ginal distribution ùëù(Rùëò). For every edge ùëíin the graphGùëò, we
sampleùõº‚Ä≤ùëí‚àºùêµùëíùëüùëõ(ùëü), whereùëü‚àà[0,1]is a predefined hyperparam-
eter. We eliminate all edges in Gùëòand reinstate all edges with ùõº‚Ä≤ùëí=1.
We assume that the graph obtained in this process is Rùëò. Conse-
quently, we use a multivariate Bernoulli distribution for ùëû(Rùëò)as
follows :
ùëû(Rùëò)=ùëü|Rùëò|(1‚àíùëü)|Gùëò|‚àí|Rùëò|. (15)
Finally, the mutual information loss LMIfor the time-aware
bottleneck in Equation 6 is calculated as follows:
 
2576KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain Sangwoo Seo, Sungwon Kim, Jihyeong Jung, Yoonho Lee, & Chanyoung Park
LMI=EGùëòh
ùêæùêøh
ùëù(Rùëò|ùëíùëò,Gùëò)‚à•ùëû(Rùëò)ii
=Eùëù(ùëíùëò,Gùëò)Ô£ÆÔ£ØÔ£ØÔ£ØÔ£ØÔ£∞‚àëÔ∏Å
ùëíùëó‚ààGùëòùëùùëò
ùëólogùëùùëò
ùëó
ùëü+(1‚àíùëùùëò
ùëó)log1‚àíùëùùëò
ùëó
1‚àíùëüÔ£πÔ£∫Ô£∫Ô£∫Ô£∫Ô£ª.(16)
4.4 Minimizing ‚àíùêº(ùëåùëò;Rùëò)in Equation 5
The predictor ùëûùúÉ
ùëåùëò|Rùëò
in Equation 5 provides predictions ùëåùëò
based on the bottleneck code Rùëò. We sample stochastic weights
from the Bernoulli distribution and obtain a valid event representa-
tion Àúùëçùëíùëó(ùë°ùëò)from the sampled ùõºùëò
ùëóas follows:
Àúùëçùëíùëó(ùë°ùëò)=ùõºùëò
ùëóùëçùëíùëó(ùë°ùëò), ùõºùëò
ùëó‚àºùêµùëíùëü(ùëùùëò
ùëó), (17)
whereùëçùëíùëó(ùë°ùëò)is the candidate event representation obtained from
Equation 12.
To ensure that gradients can be computed with respect to ùëùùëò
ùëó, we
use the Gumbel-Softmax reparameterization trick [ 9]. We obtain the
representation ofRùëò, denoted as ùêªùëò+, extracted from each Àúùëçùëíùëó(ùë°ùëò)
as follows:
ùêªùëò
+=Readouthn
Àúùëçùëíùëó(ùë°ùëò)|ùëíùëó‚ààGùëòoi
. (18)
Negative Sample. We utilize negative samples to effectively train
the predictor ùëûùúÉ
ùëåùëò|Rùëò
. To generate a negative sample of ùëíùëò=
{ùë¢ùëò,ùë£ùëò,ùë°ùëò,attùëò}, we fix the node ùë¢ùëòand replace ùë£ùëòby randomly
sampling a node from the entire graph G. We denote the randomly
sampled node as ùëõùëò, and the event representation ùëãùëíneg
ùëò(ùë°ùëò)corre-
sponding to the negative sample ùëõùëòis defined as follows:
ùëãùëíneg
ùëò(ùë°ùëò)=
‚Ñéùë¢ùëò(ùë°ùëò)‚à•‚Ñéùëõùëò(ùë°ùëò)‚à•Œ¶ùëëùëá(0)‚à•ùëéùë°ùë°ùëò
(19)
In the same manner as ùëãùëíùëò(ùë°ùëò), we extract the bottleneck code
based onùëãùëíneg
ùëò(ùë°ùëò)along with a candidate event ùëçùëíùëó(ùë°ùëò), and sample
stochastic weights from the Bernoulli distribution. Consequently,
using the Bernoulli variables derived based on ùëãùëíneg
ùëò(ùë°ùëò), we select
important events from candidate events and obtain the selected
candidate graph embedding ùêªùëò‚àíthrough a readout function.
Finally, we use the time-aware link prediction loss function as
follows:
Lcls=‚àëÔ∏Å
ùëíùëò‚ààùëÜ‚àílogh
ùúé
ùëûùúÉ(ùëãùëíùëò,ùêªùëò
+)i
‚àíùëÅ¬∑Eneg‚àºùëÉùëõlog
ùúé
ùëûùúÉ(ùëãùëíneg
ùëò,ùêªùëò
‚àí)
,
(20)
whereùëûùúÉis an MLP,ùëÅis the number of negative samples, and ùëÉùëõ
is a distribution from which negative samples are sampled.
Explanability. The explainability of TGIB is established by inject-
ing stochasticity into past candidate events. LMIin Equation 16
aims to assign high stochasticity to all candidate events, while Lcls
in Equation 20 simultaneously learns to reduce the stochasticity for
explanation graphs that are important for the occurrence of ùëíùëò. We
generate an importance score ùëùùëò
ùëóderived from the interactions of
events at different timestamps, i.e., ùëíùëòandùëíùëó, which allows the bot-
tleneck code to help generate a time-aware explanation. TGIB can
rank all candidate events according to ùëùùëò
ùëóand detect the top-ranked
candidate events as explanation graphs.4.5 Spurious Correlation Removal
ùëí!ùëå!
ùëí!ùí¢!‚Ñõ!ùëí"predictionSpurious Correlation
Figure 3: Spurious Correlation Removal of TGIB.
TGIB eliminates spurious correlations within the input data and
ensures interpretability. If there is a correspondence between the
explanation of event occurrence Rùëò‚àóand the label Y, we can prove
thatRùëò‚àóis the optimal solution for the objective function of TGIB
(i.e., Equation 4).
Proposition 1. Assume that eachGùëòcontainsRùëò‚àó, which deter-
minesùëåùëò. In other words, for some deterministic invertable func-
tionùëìwith randomness ùúñthat is independent of Gùëò, it satisfies
ùëå=ùëì(Rùëò‚àó)+ùúñ. Then, for any ùõΩ‚àà [0,1], the optimalRùëòthat
minimizes‚àíùêº(ùëåùëò;Rùëò)+ùõΩùêº(Rùëò;ùëíùëò,Gùëò)isRùëò‚àó.
Proof. We can obtain the following derivation:
min
Rùëò‚àíùêº(ùëåùëò;Rùëò)+ùõΩùêº(Rùëò;ùëíùëò,Gùëò)
=min
Rùëò‚àíùêº(ùëåùëò;Rùëò)‚àíùõΩùêº(ùëåùëò;ùëíùëò,Gùëò|Rùëò)+ùõΩùêº(ùëåùëò,Rùëò;ùëíùëò,Gùëò)
=min
Rùëò‚àíùêº(ùëåùëò;Rùëò)‚àíùõΩùêº(ùëåùëò;ùëíùëò|Gùëò,Rùëò)‚àíùõΩùêº(ùëåùëò;Gùëò|Rùëò)+ùõΩùêº(ùëåùëò,Rùëò;ùëíùëò,Gùëò)
=min
Rùëò‚àíùêº(ùëåùëò;Gùëò,Rùëò)+ùêº(ùëåùëò;Gùëò|Rùëò)‚àíùõΩùêº(ùëåùëò;Gùëò|Rùëò)+ùõΩùêº(ùëåùëò,Rùëò;ùëíùëò,Gùëò)
=min
Rùëòùêº(ùëåùëò;Gùëò|Rùëò)‚àíùõΩùêº(ùëåùëò;Gùëò|Rùëò)+ùõΩùêº(Rùëò;ùëíùëò,Gùëò|ùëåùëò)+ùõΩùêº(ùëåùëò;ùëíùëò,Gùëò)
=min
Rùëò(1‚àíùõΩ)ùêº(ùëåùëò;Gùëò|Rùëò)+ùõΩùêº(Rùëò;ùëíùëò,Gùëò|ùëåùëò),
where, sinceRùëòis a subgraph ofGùëò, implying(Gùëò,Rùëò)holds
no additional information over Gùëò, it follows‚àíùêº(ùëåùëò;ùëíùëò|Gùëò,Rùëò)=
‚àíùêº(ùëåùëò;ùëíùëò|Gùëò)in the third equation and ‚àíùêº(ùëåùëò;Gùëò,Rùëò)=‚àíùêº(ùëåùëò;Gùëò)
in the fourth equation. The derivation of the equations is based
on the chain rule of mutual information, and since the objective
is to find theRùëòthat optimizes the equation, the terms that are
irrelevant toRùëòhave been removed (detailed derivation is provided
in Appendix A).
The above derivation shows that Rùëòthat minimizes(1‚àíùõΩ)
ùêº(ùëåùëò;Gùëò|Rùëò)+ùõΩùêº(Rùëò;ùëíùëò,Gùëò|ùëåùëò)can also minimize‚àíùêº(ùëåùëò;Rùëò)+
ùõΩùêº(Rùëò;ùëíùëò,Gùëò). Since mutual information is always non-negative,
(1‚àíùõΩ)ùêº(ùëåùëò;Gùëò|Rùëò)+ùõΩùêº(Rùëò;ùëíùëò,Gùëò|ùëåùëò)reaches its minimum when
bothùêº(ùëåùëò;Gùëò|Rùëò)andùêº(Rùëò;ùëíùëò,Gùëò|ùëåùëò)are equal to 0.
ùëå=ùëì(Rùëò‚àó)+ùúñ, whereùúñis independent from Gùëò, implies that
ùêº(ùëåùëò;Gùëò|Rùëò‚àó)=0. Similarly,Rùëò‚àó=ùëì‚àí1(ùëå‚àíùúñ)whereùúñis inde-
pendent fromGùëòimplies that ùêº(Rùëò‚àó;ùëíùëò,Gùëò|ùëåùëò)=0. Therefore,
the following holds: (1‚àíùõΩ)ùêº(ùëåùëò;Gùëò|Rùëò‚àó)+ùõΩùêº(Rùëò‚àó;ùëíùëò,Gùëò|ùëåùëò)=
0. In other words, the optimal Rùëòthat minimizes‚àíùêº(ùëåùëò;Rùëò)+
ùõΩùêº(Rùëò;ùëíùëò,Gùëò)isRùëò‚àó. ‚ñ°
 
2577Self-Explainable Temporal Graph Networks based on
Graph Information Bottleneck KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain
As shown in the Figure 3, Gùëòandùëåmay have a spurious corre-
lation due to the factors excluding Rùëò‚àófromGùëò. In other words,
the correlation between Gùëò\Rùëò‚àóand the label ùëåis a spurious
correlation and not a real factor in determining the label. Predicting
ùëåbased onGùëòhas a risk of capturing spurious correlations, which
can lead to a decrease in the model‚Äôs generalization performance.
According to Proposition 1, this problem can be solved by optimiz-
ing the objective function of TGIB. It shows that event occurrence
can be predicted based on ùëÖùëò‚àówithout spurious correlations. As a
result, TGIB can improve the generalization performance of predic-
tions by removing spurious correlations for event occurrence.
5 EXPERIMENTS
In this section, we provide experimental setups (Sec 5.1), perfor-
mances of link prediction (Sec 5.2), explanation performances (Sec 5.3),
explanation visualization (Sec 5.4) and ablation study of TGIB
(Sec 5.5).
5.1 Experimental Setup
Datasets. We use six real-world temporal graph datasets to mea-
sure the performance of TGIB. The six datasets include various
applications and domains, such as social networks and communica-
tion networks. The following describes the details of the datasets
used for evaluation. Data statistics are provided in the Table 1.
Table 1: Statistics of datasets used for experiments.
Dataset Domain
#Nodes #Edges #Edge Features Duration
Wikip
edia So
cial 9,227 157,474 172 1 month
UCI So
cial 1,899 58,835 - 196 days
USLegis Politics
225 60,396 1 12 terms
CanParl Politics
734 74,478 1 14 years
Enron So
cial 184 125,235 - 3 years
Reddit So
cial 10,984 672,447 172 1 month
‚Ä¢Wikipedia [11] consists of 9,227 nodes representing editors and
Wiki pages, and 157,474 edges representing timestamped post
requests. Each edge has a Linguistic Inquiry and Word Count
(LIWC) feature vector of the requested text [ 20] with each vector
having a length of 172.
‚Ä¢UCI [18] is a social network within the online community of Uni-
versity of California, Irvine students spanning 196 days. Nodes
represent students, and edges denote messages exchanged be-
tween two students, each with a timestamp in seconds.
‚Ä¢USLegis [8] is a co-sponsorship network among U.S. senators.
Each node represents legislators, and two legislators are connected
if they have jointly sponsored a bill. The weight assigned to each
edge represents the number of times two legislators have jointly
sponsored bills over a period of 12 terms.
‚Ä¢CanParl [8] is a network capturing interactions among Canadian
Members of Parliament from 2006 to 2019. Nodes represent Mem-
bers of Parliament, and two members are connected if they both
vote in favor of a specific bill. The weight assigned to each edge
represents the number of times one member has voted in favor of
another member within one year.
‚Ä¢Enron [27] is an email network that includes communication
exchanged over a period of three years within the Enron energycompany. Nodes represent employees of the Enron company, and
edges represent the exchanged emails between two employees.
‚Ä¢Reddit [11] represents a network of posts created by users in
subreddits for one month. The nodes represent users and posts,
and the edges represent timestamped post requests. Similar to
Wikipedia, the features of the edges have LIWC feature vectors of
the requested text [20], with each vector having a length of 172.
Evalutation Protocol. We split the total time [0,ùëá]into[0,ùëátrain],
[ùëátrain,ùëával], and[ùëával,ùëátest]and use the events occurring within
each interval as the training set, validation set, and test set, respec-
tively. We set ùëátrain=0.7ùëáandùëával=0.85ùëá. We set the number of
layers to 2 and the dropout rate as 0.1 for the aggregation process
within the attention mechanism to obtain time-aware event repre-
sentations. Our model is trained for 10epochs using the Adam SGD
optimizer with a learning rate of 0.00001. We set the dimensions
of the node embeddings and time encodings to be identical to the
raw features of the events. For the ùêø-hop computational graph, we
setùêøas 2. We evaluate the performance, which is averaged over 5
independent runs with different random seeds.
5.2 Link Prediction
Baselines. We use seven TGNN methods, i.e., Jodie [11],DyRep
[32],TGAT [40],TGN [24],TCL [36],CAW-N [37],GraphMixer
[3] as baselines. Details on compared baselines can be found in
Appendix E.
Setup. To measure performance in various settings, we assess link
prediction performance in both transductive and inductive settings.
‚Ä¢Transductive Setting. We use all events occurring in the three
intervals (i.e.,[0,ùëátrain],[ùëátrain,ùëával], and[ùëával,ùëátest]) as the train-
ing set, validation set, and test set, respectively. This means that
during the training time, all events occurring before ùëátrain can
be observed.
‚Ä¢Inductive Setting. We predict the occurrence of events involv-
ing nodes not observed during the training time. Specifically, 1)
we split the training set, validation set, and test set as shown
in Section 5.1. 2)We randomly select 10% of nodes from the
training set, and remove all events containing these nodes from
the training set. 3)We include the events involving these nodes
only in the validation and test sets.
Experiment Results. The experimental results for link prediction
in the transductive setting and inductive setting are presented in Ta-
ble 2 and Table 3, respectively. We measured the mean and standard
deviation of Average Precision (AP) on the test set. We obtained
the following observations: 1)TGIB demonstrated the highest per-
formance on 5 out of 6 datasets compared to the baselines for the
temporal graphs in both transductive and inductive settings. The
remaining dataset (i.e., Enron) showed the second-highest perfor-
mance compared to the baselines. We attribute the superior per-
formance of TGIB to its capturing of important past events, which
eliminates spurious correlations for an event occurrence ùëíùëòby pre-
dictingùëåùëòbased onRùëòas stated in Proposition 1. 2)TGIB achieved
high prediction performance in politics networks such as USLegis
and CanParl compared to the baselines. Specifically, in the inductive
setting, USLegis achieved a 47.4%performance improvement over
 
2578KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain Sangwoo Seo, Sungwon Kim, Jihyeong Jung, Yoonho Lee, & Chanyoung Park
Table 2: AP on link prediction in a transductive setting for TGIB and 8 baseline methods over 6 datasets.
T
ransductiveMo
del Wikipedia UCI USLegis CanParl Enron Reddit
Jo
die 94.62 ¬±0.50 86.73 ¬±1.00 73.31 ¬±0.40 69.26 ¬±0.31 77.31 ¬±4.20 97.11 ¬±0.30
DyRep 92.43 ¬±0.37 53.67 ¬±2.10 57.28 ¬±0.71 54.02 ¬±0.76 74.55 ¬±3.95 96.09 ¬±0.11
TGAT 95.34 ¬±0.10 73.01 ¬±0.60 68.89 ¬±1.30 70.73 ¬±0.72 68.02 ¬±0.10 98.12 ¬±0.20
TGN 97.58 ¬±0.20 80.40 ¬±1.40 75.13 ¬±1.30 70.88 ¬±2.34
79.91 ¬±1.30 98.30 ¬±0.20
T
CL 96.47 ¬±0.16 89.57 ¬±1.63 69.59 ¬±0.48 68.67 ¬±2.67 79.70 ¬±0.71 97.53 ¬±0.02
CAW-N 98.28 ¬±0.20 90.03 ¬±0.40
69.94 ¬±0.40 69.82 ¬±2.34 89.56 ¬±0.09 97.95 ¬±0.20
GraphMixer 97.25 ¬±0.03 93.25 ¬±0.57 70.74 ¬±1.02
77.04 ¬±0.46 82.25 ¬±0.16
97.31 ¬±0.01
T
GIB 99.37 ¬±0.09 93.60 ¬±0.24 91.61 ¬±0.34 87.07 ¬±0.44 82.42 ¬±0.11 99.68 ¬±0.15
Table 3: AP on link prediction in an inductive setting for TGIB and 8 baseline methods over 6 datasets.
Inductiv
eMo
del Wikipedia UCI USLegis CanParl Enron Reddit
Jo
die 93.11 ¬±0.40 71.23 ¬±0.80 52.16 ¬±0.50 53.92 ¬±0.94 76.48 ¬±3.50 94.36 ¬±1.10
DyRep 92.05 ¬±0.30 50.43 ¬±1.20 56.26 ¬±2.00 54.02 ¬±0.76 66.97 ¬±3.80 95.68 ¬±0.20
TGAT 93.82 ¬±0.30 66.89 ¬±0.40 52.31 ¬±1.50 55.18 ¬±0.79 63.70 ¬±0.20 96.42 ¬±0.30
TGN 97.05 ¬±0.20 74.70 ¬±0.90 58.63 ¬±0.37 54.10 ¬±0.93
77.94 ¬±1.02 96.87 ¬±0.20
TCL 96.22 ¬±0.17 87.36 ¬±2.03 52.59 ¬±0.97 54.30 ¬±0.66 76.14 ¬±0.79 94.09 ¬±0.07
CAW-N 97.70 ¬±0.20 89.65 ¬±0.40
53.11 ¬±0.40 55.80 ¬±0.69 86.35 ¬±0.51 97.37 ¬±0.30
GraphMixer
96.65 ¬±0.02 91.19 ¬±0.42 50.71 ¬±0.76
55.91 ¬±0.82 75.88 ¬±0.48
95.26 ¬±0.02
T
GIB 99.28 ¬±0.11 91.26 ¬±0.16 86.42 ¬±0.16 79.56 ¬±0.79 80.64 ¬±0.59 99.54 ¬±0.02
the runner-up baseline, and CanParl achieved a 42.3%improvement
over the runner-up baseline. These findings suggest that in a po-
litical network, specific individuals or groups can have significant
influence, and the GIB method effectively identifies these important
people or groups and analyzes their roles and influence. 3)Addi-
tionally, TGIB achieved very high AP scores of 99.28%and99.68%
in the Wikipedia and Reddit datasets, respectively. Even though
Wikipedia and Reddit already have high baseline performances,
with runner-up performances of 98.28%and98.30%respectively,
TGIB achieves nearly perfect performance on both datasets. TGIB
is the only model that demonstrates performance exceeding 99%
on both datasets.
5.3 Explanation Performance
Baselines. We use six explanation methods, i.e. Random, ATTN
[34],Grad-CAM [22],GNNExplainer [41],PGExplainer [16],
T-GNNExplainer [39] as baselines. Random is the explanation
results obtained by randomly sampling a number of nodes that
satisfy sparsity. Details on baselines are presented in Appendix E.
Setup. We used TGAT [ 40] as the base model for all baselines that
generate explanations in a post-hoc manner. Since the overall range
of Fidelity used as an evaluation metric in TGNNExplainer has vari-
ability depending on the dataset or base model, calculating the area
of the graph related to Fidelity may not provide consistent results.
Therefore, to evaluate the performance of explanations, we mea-
sure the proportion of predictions that match the model‚Äôs original
predictions when the model performs predictions based on expla-
nations. In other words, predictions based on superior explanations
have the same prediction label as predictions from the original
graph. We also evaluate the explanation performance over vari-
ous sparsity levels [ 39], where the sparsity is defined as |Rùëò|/|Gùëò|.
Since higher levels of sparsity would always yield better explana-
tion performance, we evaluate explanation performance in varioussparsity environments. We divide the sparsity level from 0 to 0.3
with intervals of 0.002, measure the performance of the explanation
graphRùëò, and then calculate the area under the sparsity-accuracy
curve.
Experiment Results. We have presented the experimental results
for explanation performance in Table 4. We have the following ob-
servations: 1)TGIB outperforms all the baselines, indicating that it
provides a high quality of explanation for the predictions. 2)TGIB
achieved up to 27.5% improvement in performance on the UCI
dataset compared to the baselines. Moreover, 2 out of 5 baselines
(i.e., ATTN and Grad-CAM) show worse performance than random
explanations. 3)Some baselines, such as ATTN and Grad-CAM,
fail to provide explanation, performing even worse than random
explanations depending on the datasets, which significantly affect
the reliability of the explainable model. However, TGIB demon-
strates stable performance in explainablity, and its performance is
further supported by a theoretical background. Furthermore, we
present the inference time in Appendix C, demonstrating the effi-
ciency of our method‚Äôs evaluation while maintaining its superior
explanations.
5.4 Explanation Visualization
We compare the explanation visualizations for static graph expla-
nation models, GNNExplainer and PGExplainer, with the temporal
graph explanation model, TGIB, as shown in the Figure 4. In the
figure, the target events are depicted by red solid lines, and the
explanation events are depicted by blue solid lines. Additionally, we
marked the difference in occurrence timestamps between the target
event and each of the five explanation events. Then, the mean time
intervals are calculated as follows: (a) 1228523.4, (b) 1475006.2, and
(c) 612333.2. This shows that the time interval for (c) is smaller
than that for (a) and (b), and that the timestamps of the explanation
events in TGIB are closer to the timestamps of the target events
 
2579Self-Explainable Temporal Graph Networks based on
Graph Information Bottleneck KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain
Table 4: Explanation performance for TGIB and 6 baseline methods over 5 datasets.
Wikip
edia UCI USLegis CanParl Enron
Random
70.91 ¬±1.03 54.51 ¬±0.52 54.24 ¬±1.34 51.66 ¬±2.26 48.94 ¬±1.28
ATTN 77.31 ¬±0.01 27.25 ¬±0.01 62.24 ¬±0.00 79.92 ¬±0.01 68.28 ¬±0.01
Grad-CAM 83.11 ¬±0.01 26.06 ¬±0.01 78.98 ¬±0.01 50.42 ¬±0.01 19.93 ¬±0.01
GNNExplainer 84.34 ¬±0.16 62.38 ¬±0.46 89.42 ¬±0.50 80.59 ¬±0.58 77.82 ¬±0.88
PGExplainer 84.26 ¬±0.78 59.47 ¬±1.68 91.42 ¬±0.94 75.92 ¬±1.12
62.37 ¬±3.82
T-GNNExplainer 85.74 ¬±0.56 68.26 ¬±2.62 90.37 ¬±0.84
80.67 ¬±1.49 82.02 ¬±1.94
T
GIB 88.09 ¬±0.68 87.06 ¬±1.04 93.33 ¬±0.72 89.72 ¬±1.18 83.55 ¬±0.91
(a) GNNExplainer
(b) Target Event = 2218875
(b) P GExplainer (c) TGIB
Figur
e 4: Comparison of explanation visualization for explanation models for static graphs and TGIB.
than those in GNNExplainer and PGExplainer. In temporal graphs,
events that occurred recently should have a greater influence on
the target event compared to events that happened a long time ago;
however, GNNExplainer and PGExplainer fail to capture this. In
other words, it shows that GNNExplainer and PGExplainer cannot
be easily generalized to temporal graphs because they don‚Äôt capture
temporal dynamics. In contrast, TGIB considers the temporal infor-
mation of the target event to generate explanations for temporal
graphs. Therefore, we can observe that TGIB is capable of capturing
temporal dependencies along with graph topology.
5.5 Ablation Study
Table 5: Ablation study of the proposed components.
USLegis
UCI CanParl
w/oùëãùëíùëò(ùë°ùëò)andùëçùëíùëó(ùë°ùëò) 85.85 ¬±0.36
86.10 ¬±0.74 85.53 ¬±0.62
w/oùêº(ùëåùëò;Rùëò) 81.24 ¬±0.41 78.30 ¬±0.83 69.85 ¬±0.74
w/oùêº(Rùëò;ùëíùëò,Gùëò) 88.91 ¬±1.14 90.45 ¬±0.38 86.78 ¬±0.37
with
all(TGIB) 91.61 ¬±0.34 91.41 ¬±0.41 87.07 ¬±0.44
We conduct ablation studies to investigate the efficiency of the pro-
posed model (i.e., TGIB). Table 5 provides the ablation study of our
proposed method based on link prediction. The with all setting
indicates our final model including all components of TGIB. We
performed ablation studies on time-aware event representations
(i.e.,ùëãùëíùëò(ùë°ùëò)andùëçùëíùëó(ùë°ùëò)) and losses relevant to mutual informa-
tion (i.e.,ùêº(ùëåùëò;Rùëò)andùêº(Rùëò;ùëíùëò,Gùëò)). We obtain the following
observations: 1)Capturing temporal information from event repre-
sentations in the prediction based on the IB principle contributes
to performance improvement. 2)The model experiences declinesin performance when the terms relevant to mutual information,
ùêº(ùëåùëò;Rùëò)andùêº(Rùëò;ùëíùëò,Gùëò), are not considered. Specifically, the
removal ofùêº(ùëåùëò;Rùëò)results inRùëòcontaining a large amount of
label-irrelevant information, leading to difficulties in the final label
prediction. Moreover, when ùêº(Gùëò;ùëíùëò,Rùëò)is not considered, it leads
to a decrease in the generalization performance of the prediction
due to the portions of Gùëòthat have spurious correlations with ùëåùëò,
as mentioned in Section 4.5.
6 CONCLUSION
In this work, we propose TGIB, a more reliable and practical ex-
planation model for temporal graphs that can simultaneously per-
form prediction and explanation tasks. The main idea is to provide
time-aware explanations for the occurrence of the target events by
restricting the flow of information from candidate events to predic-
tions based on the IB theory. We demonstrate that TGIB exhibits
significant performance in both prediction and explanation across
various datasets, and its explanation visualizations show that it can
capture temporal relationships to extract important past events.
Consequently, TGIB represents a more adaptable explainable model
compared to existing models, capable of being efficiently trained
on dynamically evolving graph settings without the exhaustive
requirement for retraining from scratch, unlike other methods.
Acknowledgement. This work was supported by the National
Research Foundation of Korea(NRF) grant funded by the Korea
government(MSIT) (RS-2024-00335098), Institute of Information &
communications Technology Planning & Evaluation (IITP) grant
funded by the Korea government(MSIT) (No.2022-0-00157), and
National Research Foundation of Korea(NRF) funded by Ministry
of Science and ICT (NRF-2022M3J6A1063021).
 
2580KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain Sangwoo Seo, Sungwon Kim, Jihyeong Jung, Yoonho Lee, & Chanyoung Park
REFERENCES
[1]Alexander A Alemi, Ian Fischer, Joshua V Dillon, and Kevin Murphy. 2016. Deep
variational information bottleneck. arXiv preprint arXiv:1612.00410 (2016).
[2]Julia Amann, Alessandro Blasimme, Effy Vayena, Dietmar Frey, Vince I Madai,
and Precise4Q Consortium. 2020. Explainability for artificial intelligence in
healthcare: a multidisciplinary perspective. BMC medical informatics and decision
making 20 (2020), 1‚Äì9.
[3]Weilin Cong, Si Zhang, Jian Kang, Baichuan Yuan, Hao Wu, Xin Zhou, Hanghang
Tong, and Mehrdad Mahdavi. 2023. Do We Really Need Complicated Model
Architectures For Temporal Networks? arXiv preprint arXiv:2302.11636 (2023).
[4]Hanjun Dai, Yichen Wang, Rakshit Trivedi, and Le Song. 2016. Deep coevolu-
tionary network: Embedding user and item features for recommendation. arXiv
preprint arXiv:1609.03675 (2016).
[5]Finale Doshi-Velez and Been Kim. 2017. Towards a rigorous science of inter-
pretable machine learning. arXiv preprint arXiv:1702.08608 (2017).
[6]Valeria Gelardi, Didier Le Bail, Alain Barrat, and Nicolas Claidiere. 2021. From
temporal network data to the dynamics of social relationships. Proceedings of the
Royal Society B 288, 1959 (2021), 20211164.
[7]Irina Higgins, Loic Matthey, Arka Pal, Christopher Burgess, Xavier Glorot,
Matthew Botvinick, Shakir Mohamed, and Alexander Lerchner. 2016. beta-vae:
Learning basic visual concepts with a constrained variational framework. In
International conference on learning representations.
[8]Shenyang Huang, Yasmeen Hitti, Guillaume Rabusseau, and Reihaneh Rabbany.
2020. Laplacian change point detection for dynamic graphs. In Proceedings of
the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data
Mining. 349‚Äì358.
[9]Eric Jang, Shixiang Gu, and Ben Poole. 2017. Categorical reparameterization
with gumbel-softmax. In International Conference on Learning Representations.
[10] Thomas N Kipf and Max Welling. 2017. Semi-supervised classification with graph
convolutional networks. In International Conference on Learning Representations.
[11] Srijan Kumar, Xikun Zhang, and Jure Leskovec. 2019. Predicting dynamic em-
bedding trajectory in temporal interaction networks. In Proceedings of the 25th
ACM SIGKDD international conference on knowledge discovery & data mining.
1269‚Äì1278.
[12] Namkyeong Lee, Dongmin Hyun, Gyoung S Na, Sungwon Kim, Junseok Lee, and
Chanyoung Park. 2023. Conditional Graph Information Bottleneck for Molecular
Relational Learning. arXiv preprint arXiv:2305.01520 (2023).
[13] Namkyeong Lee, Kanghoon Yoon, Gyoung S Na, Sein Kim, and Chanyoung Park.
2023. Shift-robust molecular relational learning with causal substructure. In
Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and
Data Mining. 1200‚Äì1212.
[14] Shuang Li, Mingquan Feng, Lu Wang, Abdelmajid Essofi, Yufeng Cao, Junchi
Yan, and Le Song. 2021. Explaining point processes by learning interpretable
temporal logic rules. In International Conference on Learning Representations.
[15] Zhao Li, Pengrui Hui, Peng Zhang, Jiaming Huang, Biao Wang, Ling Tian, Ji
Zhang, Jianliang Gao, and Xing Tang. 2021. What happens behind the scene?
Towards fraud community detection in e-commerce from online to offline. In
Companion Proceedings of the Web Conference 2021. 105‚Äì113.
[16] Dongsheng Luo, Wei Cheng, Dongkuan Xu, Wenchao Yu, Bo Zong, Haifeng
Chen, and Xiang Zhang. 2020. Parameterized explainer for graph neural network.
Advances in neural information processing systems 33 (2020), 19620‚Äì19631.
[17] Siqi Miao, Mia Liu, and Pan Li. 2022. Interpretable and generalizable graph learn-
ing via stochastic attention mechanism. In International Conference on Machine
Learning. PMLR, 15524‚Äì15543.
[18] Pietro Panzarasa, Tore Opsahl, and Kathleen M Carley. 2009. Patterns and
dynamics of users‚Äô behavior and interaction: Network analysis of an online
community. Journal of the American Society for Information Science and Technology
60, 5 (2009), 911‚Äì932.
[19] Xue Bin Peng, Angjoo Kanazawa, Sam Toyer, Pieter Abbeel, and Sergey Levine.
2018. Variational discriminator bottleneck: Improving imitation learning, inverse
rl, and gans by constraining information flow. arXiv preprint arXiv:1810.00821
(2018).
[20] James W Pennebaker, Martha E Francis, and Roger J Booth. 2001. Linguistic
inquiry and word count: LIWC 2001. Mahway: Lawrence Erlbaum Associates 71,
2001 (2001), 2001.
[21] Fab√≠ola SF Pereira, Jo√£o Gama, Sandra de Amo, and Gina MB Oliveira. 2018. On
analyzing user preference dynamics with temporal social networks. Machine
Learning 107 (2018), 1745‚Äì1773.
[22] Phillip E Pope, Soheil Kolouri, Mohammad Rostami, Charles E Martin, and Heiko
Hoffmann. 2019. Explainability methods for graph convolutional neural net-
works. In Proceedings of the IEEE/CVF conference on computer vision and patternrecognition. 10772‚Äì10781.
[23] Ismini Psychoula, Andreas Gutmann, Pradip Mainali, Sharon H Lee, Paul Dunphy,
and Fabien Petitcolas. 2021. Explainable machine learning for fraud detection.
Computer 54, 10 (2021), 49‚Äì59.
[24] Emanuele Rossi, Ben Chamberlain, Fabrizio Frasca, Davide Eynard, Federico
Monti, and Michael Bronstein. 2020. Temporal graph networks for deep learning
on dynamic graphs. arXiv preprint arXiv:2006.10637 (2020).
[25] Sangwoo Seo, Sungwon Kim, and Chanyoung Park. 2023. Interpretable Prototype-
based Graph Information Bottleneck. arXiv preprint arXiv:2310.19906 (2023).
[26] Claude Elwood Shannon. 1948. A mathematical theory of communication. The
Bell system technical journal 27, 3 (1948), 379‚Äì423.
[27] Jitesh Shetty and Jafar Adibi. [n. d.]. The Enron Email Dataset Database
Schema and Brief Statistical Report (2004). Available on< http://www. isi. edu/Àú
adibi/Enron/Enron_Dataset_Report. pdf ([n. d.]).
[28] David Silver, Julian Schrittwieser, Karen Simonyan, Ioannis Antonoglou, Aja
Huang, Arthur Guez, Thomas Hubert, Lucas Baker, Matthew Lai, Adrian Bolton,
Yutian Chen, Timothy Lillicrap, Fan Hui, Laurent Sifre, George van den Driessche,
Thore Graepel, and Demis Hassabis. 2017. Mastering the game of Go without
human knowledge. Nature 550 (2017). http://dx.doi.org/10.1038/nature24270
[29] Duygu Sinanc, Umut Demirezen, ≈ûeref Saƒüƒ±roƒülu, et al .2021. Explainable credit
card fraud detection with image conversion. (2021).
[30] Jiabin Tang, Lianghao Xia, and Chao Huang. 2023. Explainable Spatio-Temporal
Graph Neural Networks. In Proceedings of the 32nd ACM International Conference
on Information and Knowledge Management. 2432‚Äì2441.
[31] Naftali Tishby, Fernando C Pereira, and William Bialek. 2000. The information
bottleneck method. arXiv preprint physics/0004057 (2000).
[32] Rakshit Trivedi, Mehrdad Farajtabar, Prasenjeet Biswal, and Hongyuan Zha. 2019.
Dyrep: Learning representations over dynamic graphs. In International conference
on learning representations.
[33] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
Aidan N Gomez, ≈Åukasz Kaiser, and Illia Polosukhin. 2017. Attention is all
you need. Advances in neural information processing systems 30 (2017).
[34] Petar Veliƒçkoviƒá, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro
Lio, and Yoshua Bengio. 2018. Graph attention networks. International Conference
on Learning Representations (2018).
[35] Minh Vu and My T Thai. 2020. Pgm-explainer: Probabilistic graphical model
explanations for graph neural networks. Advances in neural information processing
systems 33 (2020), 12225‚Äì12235.
[36] Lu Wang, Xiaofu Chang, Shuang Li, Yunfei Chu, Hui Li, Wei Zhang, Xiaofeng He,
Le Song, Jingren Zhou, and Hongxia Yang. 2021. Tcl: Transformer-based dynamic
graph modelling via contrastive learning. arXiv preprint arXiv:2105.07944 (2021).
[37] Yanbang Wang, Yen-Yu Chang, Yunyu Liu, Jure Leskovec, and Pan Li. 2021.
Inductive representation learning in temporal networks via causal anonymous
walks. arXiv preprint arXiv:2101.05974 (2021).
[38] Tailin Wu, Hongyu Ren, Pan Li, and Jure Leskovec. 2020. Graph information
bottleneck. Advances in Neural Information Processing Systems 33 (2020), 20437‚Äì
20448.
[39] Wenwen Xia, Mincai Lai, Caihua Shan, Yao Zhang, Xinnan Dai, Xiang Li, and
Dongsheng Li. 2022. Explaining temporal graph models through an explorer-
navigator framework. In The Eleventh International Conference on Learning Rep-
resentations.
[40] Da Xu, Chuanwei Ruan, Evren Korpeoglu, Sushant Kumar, and Kannan Achan.
2020. Inductive representation learning on temporal graphs. arXiv preprint
arXiv:2002.07962 (2020).
[41] Zhitao Ying, Dylan Bourgeois, Jiaxuan You, Marinka Zitnik, and Jure Leskovec.
2019. Gnnexplainer: Generating explanations for graph neural networks. Ad-
vances in neural information processing systems 32 (2019).
[42] Jiaxuan You, Tianyu Du, and Jure Leskovec. 2022. ROLAND: graph learning
framework for dynamic graphs. In Proceedings of the 28th ACM SIGKDD Confer-
ence on Knowledge Discovery and Data Mining. 2358‚Äì2366.
[43] Junchi Yu, Jie Cao, and Ran He. 2022. Improving subgraph recognition with vari-
ational graph information bottleneck. In Proceedings of the IEEE/CVF Conference
on Computer Vision and Pattern Recognition. 19396‚Äì19405.
[44] Junchi Yu, Tingyang Xu, Yu Rong, Yatao Bian, Junzhou Huang, and Ran He.
2020. Graph information bottleneck for subgraph recognition. arXiv preprint
arXiv:2010.05563 (2020).
[45] Zaixi Zhang, Qi Liu, Hao Wang, Chengqiang Lu, and Cheekong Lee. 2022. Prot-
gnn: Towards self-explaining graph neural networks. In Proceedings of the AAAI
Conference on Artificial Intelligence, Vol. 36. 9127‚Äì9135.
 
2581Self-Explainable Temporal Graph Networks based on
Graph Information Bottleneck KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain
A PROOF OF PROPOSITION 1
In this section, we provide a detailed derivation process of equations
corresponding to part of the proof of Proposition 1.
From Equation 4, the TGIB objective is
‚àíùêº(ùëåùëò;Rùëò)+ùõΩùêº(Rùëò;ùëíùëò,Gùëò). (21)
According to the chain rule of mutual information, we can decom-
pose the term ùõΩùêº(Rùëò;ùëíùëò,Gùëò)as follows:
‚àíùêº(ùëåùëò;Rùëò)‚àíùõΩùêº(ùëåùëò;ùëíùëò,Gùëò|Rùëò)+ùõΩùêº(ùëåùëò,Rùëò;ùëíùëò,Gùëò). (22)
Similarly, we decompose the term ‚àíùõΩùêº(ùëåùëò;ùëíùëò,Gùëò|Rùëò)from Equa-
tion 22 as follows:
‚àíùêº(ùëåùëò;Rùëò)‚àíùõΩùêº(ùëåùëò;ùëíùëò|Gùëò,Rùëò)‚àíùõΩùêº(ùëåùëò;Gùëò|Rùëò)+ùõΩùêº(ùëåùëò,Rùëò;ùëíùëò,Gùëò).
(23)
SinceRùëòis a subgraph ofGùëò,(Gùëò,Rùëò)holds no additional in-
formation overGùëò. Therefore, Equation 23 can be expressed as
follows:
‚àíùêº(ùëåùëò;Rùëò)‚àíùõΩùêº(ùëåùëò;ùëíùëò|Gùëò)‚àíùõΩùêº(ùëåùëò;Gùëò|Rùëò)+ùõΩùêº(ùëåùëò,Rùëò;ùëíùëò,Gùëò).
(24)
We also follow the same process for the term ‚àíùêº(ùëåùëò;Rùëò)as in
Equation 23 and 24, as follows:
‚àíùêº(ùëåùëò;Gùëò,Rùëò)+ùêº(ùëåùëò;Gùëò|Rùëò)‚àíùõΩùêº(ùëåùëò;ùëíùëò|Gùëò)
‚àíùõΩùêº(ùëåùëò;Gùëò|Rùëò)+ùõΩùêº(ùëåùëò,Rùëò;ùëíùëò,Gùëò)
=‚àíùêº(ùëåùëò;Gùëò)+ùêº(ùëåùëò;Gùëò|Rùëò)‚àíùõΩùêº(ùëåùëò;ùëíùëò|Gùëò)
‚àíùõΩùêº(ùëåùëò;Gùëò|Rùëò)+ùõΩùêº(ùëåùëò,Rùëò;ùëíùëò,Gùëò).
(25)
Additionally, we decompose the term ùêº(ùëåùëò,Rùëò;ùëíùëò,Gùëò)according
to the chain rule of mutual information as:
‚àíùêº(ùëåùëò;Gùëò)+ùêº(ùëåùëò;Gùëò|Rùëò)‚àíùõΩùêº(ùëåùëò;ùëíùëò|Gùëò)‚àíùõΩùêº(ùëåùëò;Gùëò|Rùëò)
+ùõΩùêº(Rùëò;ùëíùëò,Gùëò|ùëåùëò)+ùõΩùêº(ùëåùëò;ùëíùëò,Gùëò).
(26)
We separate the terms related to Rùëòfrom those unrelated to Rùëòas
follows:
(1‚àíùõΩ)ùêº(ùëåùëò;Gùëò|Rùëò)+ùõΩùêº(Rùëò;ùëíùëò,Gùëò|ùëåùëò)‚àíùêº(ùëåùëò;Gùëò)
+ùõΩùêº(ùëåùëò;ùëíùëò,Gùëò)‚àíùõΩùêº(ùëåùëò;ùëíùëò|Gùëò).
(27)
We can substitute the terms unrelated to Rùëòwith a constant ùê∂,
since they remain constant regardless of Rùëòas:
(1‚àíùõΩ)ùêº(ùëåùëò;Gùëò|Rùëò)+ùõΩùêº(Rùëò;ùëíùëò,Gùëò|ùëåùëò)+ùê∂. (28)
Therefore, we can utilize Equation 28 to find Rùëòthat minimizes
Equation 21 .
B NOTATIONS
In this section, we summarize the main notations used in this paper.
Table 6 provides the main notation and their descriptions.Table 6: Summary of the notations.
Notation
Description
ùëÜ={ùëí1,
ùëí2,¬∑¬∑¬∑} Series of continuous events
ùë° Timestamp
G=(V,E) Temporal graph with nodes Vand edges E
ùëì Self-explainable temporal graph model
ùë¢,ùë£ User and item node, respectively
ùëíùëñ=(ùë¢ùëñ,ùë£ùëñ,ùë°ùëñ,ùëéùë°ùë°ùëñ) Eventùëíùëñbetween node ùë¢ùëñandùë£ùëñat timeùë°ùëñwith attribute ùëéùë°ùë°ùëñ
GùëòGraph constructed immediately before the timestamp ùë°ùëò
GùëòL-hop computation graph of ùëíùëò
RùëòSubgraph ofGùëòconsidered as important events (i.e., explanation).
ùëå Ground truth label
ÀÜùëå Label prediction
ùêº(¬∑,¬∑) Mutual information function
N(ùëß;ùë°)={ùëß1,¬∑¬∑¬∑,ùëßùëõ}Neighboring nodes for node ùëßat timeùë°, whereùëõis # of neighbors
ùëéùë°ùë°ùëß,ùëñ Attribute of an interaction between ùëßandùëßùëñ
‚Ñé(ùëô)
ùëß(ùë°) Representation of node ùëßat timeùë°in theùëô-th layer
ùëë Dimension of the node representation
ùë•ùëß Raw feature of node ùëß
ùëìnode Dimension of the raw node feature
ùëìedge Dimension of the raw edge feature
Œ¶ùëëùëáTime encoding function
ùëëùëá Output dimension of a function Œ¶ùëëùëá
ùëíùëò Target event
ùëíùëó Candidate event
ùëíùëõùëíùëî
ùëòNegative sample event for ùëíùëò
ùëõùëò Negative sample node for ùëíùëò
ùëãùëí‚Ä≤(ùë°ùëò) Time-aware representation for the target event ùëí‚Ä≤at timeùë°ùëò
ùëçùëíùëó(ùë°ùëò) Time-aware representation for the candidate event ùëíùëóat timeùë°ùëò
Àúùëçùëíùëó(ùë°ùëò) Valid event representation for the candidate event ùëíùëóat timeùë°ùëò
ùëù‚Ä≤
ùëóProbability of ùëíùëógivenùëí‚Ä≤, respectively
ùëî MLP function calculating the probability ùëù‚Ä≤
ùëó
ùõº‚Ä≤ùëí‚àºùêµùëíùëüùëõ(ùëü) Mask forùëísampled from ùêµùëíùëüùëõùëúùë¢ùëôùëôùëñ(ùëü)
ùêªùëòRepresentation of the explanation graph Rùëò
ùëûùúÉ Link predictor
C EFFICIENCY EVALUATION
Table 7: Inference time of one explanation.
Wikipedia Reddit
TGAT + ATTN 0.02 0.04
TGAT + Grad-CAM 0.04 0.06
TGAT + GNNExplainer 8.52 11.03
TGAT + PGExplainer 0.10 0.11
TGAT + TGNNExplainer 25.36 81.57
TGIB 0.11 0.53
In this section, we measure the inference time to produce an expla-
nation to investigate the effectiveness of TGIB. Table 7 shows the
inference time for several explanation models on Wikipedia and
Reddit datasets. All baselines are models that generate explanations
in a post-hoc manner, and TGAT is used as their base model. The
inference time is calculated for all test events. We obtain the fol-
lowing observations: 1)TGNNexplainer is time-consuming due to
its reliance on the MCTS algorithm. On the other hand, TGIB effi-
ciently detects important candidate events based on the IB principle
by injecting stochasticity into past candidate events to generate
explanations. 2)Some explanation models for static graphs have
fast inference times, but according to Table 4, they exhibit low-
quality explanations for temporal graphs. However, although TGIB
is slower than them, it does not demonstrate a significant time
 
2582KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain Sangwoo Seo, Sungwon Kim, Jihyeong Jung, Yoonho Lee, & Chanyoung Park
difference with them and achieve notable explanation performance.
Therefore, considering both the quality of explanations and the
inference time, TGIB is regarded as a reasonable model.
D ALGORITHM
Algorithm 1: Overview of TGIB training
Input: Temporal graph ùëÜ={ùëí1,ùëí2,¬∑¬∑¬∑} where
ùëíùëñ={ùë¢ùëñ,ùë£ùëñ,ùë°ùëñ,ùëéùë°ùë°ùëñ}, The number of epochs ùëá
1Training set ùëÜùë°ùëüùëéùëñùëõ‚Üê{ùëíùëñ={ùë¢ùëñ,ùë£ùëñ,ùë°ùëñ,ùëéùë°ùë°ùëñ}|ùë°ùëñ<0.7ùëá}
2forepoch in1,2,¬∑¬∑¬∑,Tdo
3 forùëòin1,2,¬∑¬∑¬∑,|ùëÜùë°ùëüùëéùëñùëõ|do
/* Calculate an event representation */
4ùëãùëíùëò=[‚Ñéùë¢ùëò(ùë°ùëò)‚à•‚Ñéùë£ùëò(ùë°ùëò)‚à•Œ¶ùëëùëá(0)‚à•attùëò]
/* Calculate a negative event representation */
5ùëõùëò‚ÜêSample random ùë£ùëñfromùëÜùë°ùëüùëéùëñùëõ withùë£ùëñ‚â†ùë£ùëò
6ùëãùëíùëõùëíùëî
ùëò=[‚Ñéùë¢ùëò(ùë°ùëò)‚à•‚Ñéùëõùëò(ùë°ùëò)‚à•Œ¶ùëëùëá(0)‚à•attùëò]
/* Extract an L-hop computational graph */
7Gùëò‚Üê{ùëíùëó|ùëíùëóis L-hop from ùëíùëò}
8 forùëíùëóinGùëòdo
/* Calculate a candidate event representation */
9 ùëçùëíùëó(ùë°ùëò)=[‚Ñéùë¢ùëó(ùë°ùëó)‚à•‚Ñéùë£ùëó(ùë°ùëó)‚à•Œ¶ùëëùëá(ùë°ùëò‚àíùë°ùëó)‚à•attùëó]
/* Calculate a probability of ùëíùëógivenùëíùëò */
10 ùëùùëò
ùëó=ùëù(ùëíùëó|ùëíùëò,Gùëò)=ùúé(ùëî(ùëãùëíùëò(ùë°ùëò),ùëçùëíùëó(ùë°ùëò)))
/* Evaluate the mutual information loss */
11LMI=
Eùëù(ùëíùëò,Gùëò)[√ç
ùëíùëó‚ààGùëòùëùùëò
ùëólogùëùùëò
ùëó
ùëü+(1‚àíùëùùëò
ùëó)log1‚àíùëùùëò
ùëó
1‚àíùëü]
/* Extract a valid event representation and Rùëò*/
12 Àúùëçùëíùëó(ùë°ùëò)=ùõºùëò
ùëóùëçùëíùëó(ùë°ùëò), ùõºùëò
ùëó‚àºùêµùëíùëü(ùëùùëò
ùëó)
13Rùëò‚Üêùëíùëóifùõºùëò
ùëó=1
14 end
/* Calculate an representation of Rùëò*/
15ùêªùëò+=Readout[{Àúùëçùëíùëó(ùë°ùëò)|ùëíùëó‚ààGùëò}]
16 Deriveùêªùëò‚àíbased onùëãùëíùëõùëíùëî
ùëòin the same way as ùëãùëíùëò
/* Evaluate the link prediction loss */
17Lcls=√ç
ùëíùëò‚ààùëÜ‚àílog[ùúé(ùëûùúÉ(ùëãùëíùëò,ùêªùëò+))]‚àíùëÅ¬∑
Eneg‚àºùëÉùëõlog[ùúé(ùëûùúÉ(ùëãùëíneg
ùëò,ùêªùëò‚àí))]
/* Calculate a total loss and update the model */
18L=Lcls+L MI
19 Update model parameters by gradient descent
20 end
21end
E BASELINE DETAILS & SOURCE CODE
Details on compared baselines for each experiments are provided
below (Sec E.1, E.2). Official source codes for the baselines are also
provided in table 8.
E.1 Link Prediction
‚Ä¢Jodie [11] utilizes two coupled RNNs to produce temporal user
and item embeddings then projects temporal user embeddings
at a future time to predict the future user-item interaction.
‚Ä¢DyRep [32] is an RNN-based method that propagates messages
along the interaction, where messages are collected from neigh-
bors of nodes involved in the interaction.‚Ä¢TGAT [40] applies Self-Attention Mechanism (SAM) to model
both spatial and temporal relationships concurrently by using
features with functional time encodings.
‚Ä¢TGN [24] uses both RNN-based model and SAM-based model
architecture, where the former is used to update node memory
for modeling temporal dependencies and the latter is used to
compute node embeddings modeling both spatial and temporal
information similar to TGAT.
‚Ä¢TCL [36] is a SAM-based method for modeling both spatial and
temporal dependencies, where contrastive objective function is
used to optimize encoders.
‚Ä¢CAW-N [37] utilizes Causal Anonymous Walks (CAWs) ex-
tracted from temporal random walks to represent temporal
graph dynamics with anonymized node identities and the RNN
for encoding CAWs.
‚Ä¢GraphMixer [3] uses three modules, 1) MLP-based link encoder,
2) node encoder using neighbor mean-pooling and 3) MLP-based
link classifier without using commonly utilized RNN or SAM-
based architecture in temporal modeling.
E.2 Explanation Performance
‚Ä¢ATTN [34] utilizes learned attention weights of GAT as edge
importances to make explanations.
‚Ä¢Grad-CAM [22] provides post-hoc explanation for the GNN by
using importance score computed with gradients of the logit
value with respect to the node embeddings.
‚Ä¢GNNExplainer [41] is a post-hoc explanation model for provid-
ing explanations for GNN predictions. Specifically, this model
learns to mask the input graph while including label information
in the detected subgraphs.
‚Ä¢PGExplainer [16] uses parameterized edge distributions ob-
tained by explanation network to make explanation subgraph.
The explanation network is optimized by maximizing the mutual
information between the explanatory subgraph and predictions
of the GNN.
‚Ä¢T-GNNExplainer [39] aims to explain TGNNs post-hoc, em-
ploying both navigator and explorer components. The pretrained
navigator captures inductive relationships among events, and
the explorer seeks the optimal combination of candidates for
explanation.
Table 8: Source code links of the baseline methods
Metho
ds Sour
ce code
Jo
die [11] https://github
.com/claws-lab/jodie
D
yRep [32] https://github
.com/hunto/DyRep
T
GAT [40] https://github.com/StatsDLMathsRecomSys/Inductive-
representation-learning-on-temporal-graphs
T
GN [24] https://github
.com/twitter-research/tgn
CA
W-N [37] https://github
.com/snap-stanford/CAW
GraphMixer
[3] https://github
.com/CongWeilin/GraphMixer
Grad-CAM
[22] https://github
.com/ppope/explain_graphs
GNNExplainer
[41] https://github
.com/RexYing/gnn-model-explainer
PGExplainer
[16] https://github
.com/flyingdoog/PGExplainer
 
2583