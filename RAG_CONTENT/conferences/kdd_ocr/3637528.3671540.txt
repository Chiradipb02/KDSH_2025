Spending Programmed Bidding: Privacy-friendly Bid
Optimization with ROI Constraint in Online Advertising
Yumin Su∗
ByteDance Inc.
Beijing, China
suyumin@bytedance.comMin Xiang∗
ByteDance Inc.
Beijing, China
xiangmin@bytedance.comYifei Chen
ByteDance Inc.
Beijing, China
chenyifei.ward@bytedance.com
Yanbiao Li
ByteDance Inc.
Beijing, China
liyanbiao@bytedance.comTian Qin
ByteDance Inc.
San Jose, United States
tian.qin@bytedance.comHongyi Zhang
ByteDance Inc.
San Jose, United States
hongyi.zhang@bytedance.com
Yasong Li†
ByteDance Inc.
Beijing, China
liyasong@bytedance.comXiaobing Liu
ByteDance Inc.
Singapore
will.liu@bytedance.com
Abstract
Privacy policies have disrupted the multi-billion dollar online ad-
vertising market by making real-time and precise user data un-
traceable, which poses significant challenges to the optimization
of Return-On-Investment (ROI) constrained products in the on-
line advertising industry. Privacy protection strategies, including
event aggregation and reporting delays, hinder access to detailed
and instantaneous feedback data, thus incapacitating traditional
identity-revealing attribution techniques. In this paper, we intro-
duces a novel Spending Programmed Bidding (SPB) framework
to navigate these challenges. SPB is a two-stage framework that
separates long horizon delivery spend planning (the macro stage)
and short horizon bidding execution (the micro stage). The macro
stage models the target ROI to achieve maximum utility and de-
rives the expected spend, whereas the micro stage optimizes the
bid price given the expected spend. We further extend our frame-
work to the cross-channel scenario where the agent bids in both
privacy-constrained and identity-revealing attribution channels.
We find that when privacy-constrained channels are present, SPB is
superior to state-of-the-art bidding methods in both offline datasets
and online experiments on a large ad platform.
CCS Concepts
•Information systems →Computational advertising.
∗Both authors contributed equally to this research.
†Corresponding author
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
KDD ’24, August 25–29, 2024, Barcelona, Spain.
©2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 979-8-4007-0490-1/24/08
https://doi.org/10.1145/3637528.3671540Keywords
Real-Time Bidding; Bid Optimization; Privacy; ROI Constraint; Dis-
play Advertising
ACM Reference Format:
Yumin Su, Min Xiang, Yifei Chen, Yanbiao Li, Tian Qin, Hongyi Zhang,
Yasong Li, and Xiaobing Liu. 2024. Spending Programmed Bidding: Privacy-
friendly Bid Optimization with ROI Constraint in Online Advertising. In
Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery
and Data Mining (KDD ’24), August 25–29, 2024, Barcelona, Spain. ACM, New
York, NY, USA, 10 pages. https://doi.org/10.1145/3637528.3671540
1 Instruction
Advertisers search for potential consumers to promote their prod-
ucts with a clear Return-On-Investment (ROI) demand and a limited
spend. In the $350 billion online advertising market, Real-Time Bid-
ding (RTB) allows advertisers to bid on a display ad impression in
real time. To support advertisers in achieving their marketing ob-
jectives, a multitude of identity-revealing bidding algorithms have
been developed. Typically, these algorithms generate bids based on
real-time feedback gathered from user behavior event sequences,
such as impressions, clicks, and conversions.
However, the reliance of real-time and precise user data in e-
commerce has become increasingly controversial, triggering wide-
spread concerns about privacy [ 17]. In response to the rising con-
troversy, regulatory agencies (e.g. GDPR1) and key companies (e.g.
Apple2) have formulated a series of policies to protect user privacy
by making user data untraceable. Unfortunately, display advertising
becomes far less effective under privacy regulation and non-data-
driven performance optimization is particularly hard [ 13]. It is no
wonder that according to a research report from Interactive Ad-
vertising Bureau (IAB)[ 9], if tracking were to end, there would be
a shift of nearly $39 billion of advertising revenue away from the
open web by 2025.
1the European General Data Protection Regulation
2https://www.apple.com/legal/privacy/en-ww/
5731
KDD ’24, August 25–29, 2024, Barcelona, Spain. Yumin Su et al.
Striving to move toward a more privacy-sensitive equilibrium in
the advertising market, some companies have proposed correspond-
ing policies. Notably, Apple presented Private Click Measurement
(PCM)3and SKAdNetwork (SKAN)4to help advertisers measure
the success of ad campaigns while maintaining user privacy. How-
ever, these coping strategies still impact the online advertising in
two major aspects: Firstly, event aggregation makes it impossible to
attribute conversion event to a single user click, but only to a cohort
of users based on certain aggregation rules (PCM is based on prior-
ity, while SKAN is based on timing). Therefore, bidding algorithms
can no longer leverage fine-grained & real-time ROI data. Secondly,
reporting delay involves intentionally delaying conversion reports
by 24 to 48 hours. This delay can cause bidding strategies to respond
sluggishly. Moreover, random factors are typically introduced dur-
ing this delay period to mitigate privacy compromises from timing
attacks.
In this paper, a series of innovative methods are proposed to
tackle the ROI constrained spend planning and bidding problem
under privacy protection. Contributions can be summarized as,
(1) A Spending Programmed Bidding framework (SPB) is pro-
posed which innovatively decompose the bidding procedure into
macro and micro stages;(subsection 4.2)
(2) The functional relationship between Gross Merchandise Vol-
ume (GMV) and ROI is theoretically proved, and a stable, light-
weight, effective non-parametric regression model is proposed to
generate bids;(subsection 4.3 and subsection 4.4)
(3) The proposed SPB framework is theoretically extended to
mixed scenarios involving both privacy and non-privacy concerns.
(subsection 4.5)
2 Related Work
Existing research usually focuses on improving traditional identity-
revealing methods which only address a fraction of the problem
and are greatly affected by privacy constraints.
For the reporting delay challenge, most solutions are proposed in
the field of Conversion Rate (CVR) prediction model. [ 30] proposed
a non-parametric delayed feedback model to estimate the time
delay. [ 12] directly quantizes conversions into multiple windows
as a multi-head model. However, considering the tremendous and
stochastic delay of conversions caused by privacy policies, it is
difficult to ensure the estimated stability.
The application of the widely used Proportion Integration Dif-
ferentiation (PID) [ 7,29] in privacy scenarios is also extremely lim-
ited [ 2,5] due to its heavily rely on real-time conversion feedback.
Another type of classic method in the online advertising industry is
Model Predictive Control (MPC) which models the relation between
bid, spend and conversion with fine-grained auction replay data to
predict the optimal bid. Thus suffering from the conversion delay
and inaccuracy problems arising from strict privacy regulation.
Reinforced Learning-based (RL) solutions attempt to optimize
delivery performance by using bidding or spending control through
a learned policy or agent. However, considering the lack of real-
time and fine-grained interactive feedback with the environment,
applying these methods in privacy scenarios is almost ineffective.
3https://webkit.org/blog/8943/privacy-preserving-ad-click-attribution-for-the-web/
4https://developer.apple.com/documentation/storekit/skadnetworkTable 1: Notation Description
Notation Description
𝑥𝑖 A binary variable with a value of {0,1}, indicating
whether the ad campaign wins an 𝑎𝑢𝑐𝑡𝑖𝑜𝑛𝑖
𝑏𝑖 Bid price for the ad campaign in 𝑎𝑢𝑐𝑡𝑖𝑜𝑛𝑖
𝑤𝑝𝑖 Winning price for the ad campaign in 𝑎𝑢𝑐𝑡𝑖𝑜𝑛𝑖
𝑐𝑖 Conversion events obtained by the ad campaign after
winning𝑎𝑢𝑐𝑡𝑖𝑜𝑛𝑖
𝑆𝑐𝑎𝑝 Maximum spend within a spending period of the ad
campaign set by advertiser
𝑅𝑡𝑎𝑟𝑔𝑒𝑡 Target ROI of the ad campaign set by advertiser
3 Preliminary
3.1 Online Stochastic Knapsack Problem
Taking the ROI demand of advertisers and the platform ecology
comprehensively into account, the problem we define to solve is
to maximize GMV with the ROI and spend constraints. Here we
introduce relevant notations in table 1 and then derive the math-
ematical representation of this problem by analogy to the online
stochastic knapsack problem.
For a given advertiser’s ad campaign 𝑎, suppose there are 𝑁auc-
tion opportunities in a preset spending period (e.g. a day). We denote
these opportunities according to their generated order as 𝑎𝑢𝑐𝑡𝑖𝑜𝑛𝑖.
Based on the previously stated definitions, we recognize the cumula-
tive𝐺𝑀𝑉 and𝑆𝑃𝐸𝑁𝐷 for the𝑁auctions over the spending period
as𝑃𝐺and𝑃𝑆, respectively. This corresponds to 𝑃𝐺=Í𝑁
𝑖=1𝑥𝑖·𝑐𝑖·𝑣𝑎,
where𝑣𝑎represents the value derived from a conversion event for
the advertiser. Consequently, the expected ROI result (hereafter
abbreviated as 𝑅𝑟𝑒𝑠) can be obtained as follows:
𝑅𝑟𝑒𝑠=𝑃𝐺
𝑃𝑆=Í𝑁
𝑖=1𝑥𝑖·𝑐𝑖·𝑣𝑎
Í𝑁
𝑖=1𝑥𝑖·𝑤𝑝𝑖(1)
For the ad campaign 𝑎, our goal is to maximize 𝑃𝐺under𝑆𝑐𝑎𝑝
and𝑅𝑡𝑎𝑟𝑔𝑒𝑡 constraints which is formulated as:
𝑚𝑎𝑥𝑥𝑖𝑁∑︁
𝑖=1𝑥𝑖·𝑐𝑖·𝑣𝑎 (2)
s.t.
𝑁∑︁
𝑖=1𝑥𝑖·𝑤𝑝𝑖≤𝑆𝑐𝑎𝑝 (3)
Í𝑁
𝑖=1𝑥𝑖·𝑐𝑖·𝑣𝑎
Í𝑁
𝑖=1𝑥𝑖·𝑤𝑝𝑖≥𝑅𝑡𝑎𝑟𝑔𝑒𝑡 (4)
Referring to [ 34], we define the optimal bidding formula from
the perspective of a single 𝑎𝑢𝑐𝑡𝑖𝑜𝑛𝑖as
𝑏𝑖=𝑐𝑖·𝑣𝑎
𝑟𝑖(5)
Where𝑟𝑖can be regarded as the ROI of 𝑎𝑢𝑐𝑡𝑖𝑜𝑛𝑖. It is worth not-
ing that we can relate our problem to a variant of the well known
Knapsack Problem (KP), i.e., the online stochastic variant. We can
regard each auction opportunity as an item 𝑖with value𝑃𝑔𝑖(𝑔𝑚𝑣𝑖)
and weight𝑃𝑐𝑖(𝑤𝑝𝑖). Assuming we have a knapsack with a capacity
5732Spending Programmed Bidding: Privacy-friendly Bid Optimization with ROI Constraint in Online Advertising KDD ’24, August 25–29, 2024, Barcelona, Spain.
of𝑆𝑐𝑎𝑝, we aim to load the knapsack as much as possible to max-
imize its cumulative value while ensuring the expected ROI and
not exceeding the capacity. However, due to the fact that bidding,
winning, clicking, and conversion occur in chronological order, we
cannot obtain accurate value and weight information in advance,
i.e.𝑐𝑖and𝑤𝑝𝑖respectively. Therefore, in bidding strategy, only
historical conversion quantity or model estimates can be used to re-
place𝑐𝑖and𝑤𝑝𝑖, and a immediate decision has to be made whether
to pack the item or not.
3.2 Challenges in Privacy Scenarios
As delineated above, the problem represented by Eq. (2) we are
addressing becomes challenging under the constraints imposed by
privacy regulations for the subsequent reasons:
1)Coarse-Grained : The value of 𝑐𝑖in𝑎𝑢𝑐𝑡𝑖𝑜𝑛𝑖does not cor-
respond one-to-one, thereby complicating the optimization pro-
cess for fine-grained estimation methods such as model-based ap-
proaches.
2)Hysteresis : The reporting delay of 𝑐𝑖exceeds 24 hours, while
the frequently adopted spending period is a single day. This dis-
crepancy implies that the regulation of real-time bidding strategies
is executed without a ground truth label.
(3)Stochastic : i.e. random and unpredictable. The value of 𝑐𝑖is
not a stationary but a noisier feedback after aggregation, making it
almost impossible to estimate the distribution of 𝑐𝑖.
These privacy-related challenges induce considerable and irregu-
lar variance in the estimated deviation 𝑑(𝑡)of𝑐𝑖. Given the impact
of𝑑(𝑡), Eq. (5) transforms into
𝑏𝑖=𝑐𝑖·𝑑(𝑡)·𝑣𝑎
𝑟𝑖=𝑐𝑖·𝑣𝑎
𝑟𝑖
𝑑(𝑡)=𝑐𝑖·𝑣𝑎
𝑟′
𝑖(6)
Now, based on Eq. (6), we analyze the applicability of three state-
of-the-art methods in privacy scenarios.
Real-time Feedback Control 𝑐𝑖is the observed conversion
events while online bidding process usually requires to calculate the
bid price𝑏𝑖and return it within tens of milliseconds. This notion is
apparently contradictory to the hysteresis characteristic of privacy
scenarios.
Model Predictive Control (MPC) replaces ground truth values
with model-estimated click-through rates 𝑐𝑡𝑟𝑖and conversion rates
𝑐𝑣𝑟𝑖, i.e.,𝑐𝑖=𝑐𝑡𝑟𝑖∗𝑐𝑣𝑟𝑖. This reliance on model generalization can
partially address the hysteresis issue. Since the historical patterns
are not likely suitable for the future under the stochastic limitation
and conversions cannot be precisely applied back to every fine-
grained individual sample under the coarse-grained constraint, the
accuracy and stability of model estimation cannot be guaranteed.
Thus, the MPC based methods has low applicability in privacy
scenarios.
Reinforced Learning (RL) based methods demand real-time
feedback to adapt bidding policies and actions which are typically
model-based. As a consequence, they encounter similar obstacles
as MPC methods within privacy scenarios..4 Spending Programmed Bidding
4.1 THRESHOLD Algorithm
As analyzed above, the problem under review can be identified
as an online stochastic KP in privacy scenarios. The incomplete-
ness of𝑐𝑖and𝑤𝑝𝑖in online auctions indicates that conventional
optimization solutions (e.g., Dynamic Programming) aren’t appli-
cable. Fortunately, it has been asserted by [ 8] that the greedy al-
gorithm serves as a proximal optimal algorithm when the weight
of the item is significantly smaller than the knapsack’s capacity,
i.e.,𝑤𝑝𝑖≤(1−𝜆)𝑆𝑐𝑎𝑝,0≤𝜆≤1where𝜆signifies the degree of
resemblance to the optimal solution. As we will illustrate in the
experimental section, in the TikTok display advertising platform,
𝜆is generally sizable, thus, this validates the greedy algorithm as
suitable for approximately resolving our problem.
The THRESHOLD, a typical example of greedy algorithms, only
packages an item 𝑖when its efficiency 𝑣𝑎𝑙𝑢𝑒𝑖/𝑤𝑒𝑖𝑔ℎ𝑡𝑖(in this case
𝑐𝑖·𝑣𝑎/𝑤𝑝𝑖=𝑟𝑖) equals or surpasses a predefined threshold 𝑅𝑡ℎ𝑟,
until the knapsack is filled (spend reaches cap) or there are no
items (auction opportunities) left. Once 𝑅𝑡ℎ𝑟is determined, the
optimal bid can be inferred by substituting 𝑟𝑖in Eq. (5) with 𝑅𝑡ℎ𝑟.
Earlier researches [ 24] [15] identified the specific threshold 𝑅𝑡ℎ𝑟
through feedback mechanism or model learning, which is inherently
limited in privacy scenarios due to aggregation, hysteresis, and
stochastic attributes. Contrarily, our SPB algorithm proves resilient
to these impediments, thereby facilitating valuable results in privacy
situations. Now we introduce the SPB framework in Algorithm 1
and then elaborate in the following subsections.
Algorithm 1 SPB Framework
Input: target ROI𝑅𝑡𝑎𝑟𝑔𝑒𝑡 , spend cap𝑆𝑐𝑎𝑝set by advertiser
Output: optimal𝑏𝑙+1for next time control interval 𝑡𝑙+1
// Macro Spend Planning
1:Input the target ROI 𝑅𝑡𝑎𝑟𝑔𝑒𝑡 and spend cap 𝑆𝑐𝑎𝑝, work out at
the total optimal spend 𝑆(𝑜𝑝𝑡)for a spending period
2:Obtain the optimal spend 𝑆(𝑜𝑝𝑡)
𝑙+1for the next time interval 𝑡𝑙+1
// Micro Bidding Optimization
3:Construct an interpolation queue with the point pairs
(𝑆(𝑜𝑝𝑡)
𝑙,𝑏𝑙)and obtain𝑏𝑙+1through interpolation or extension
methods
The SPB algorithm introduced here offers several distinct advan-
tages:
1) Innovative Two-Stage Decomposition Framework for Online
Bidding: This approach effectively dampens the impact of model
estimation errors.
2) Applicability in Privacy Scenarios: The application of long-
term cumulated data allows for the effective management of the
three challenges involved in privacy scenarios: coarse-grained, hys-
teresis, and stochastic natures. This level of resolution isn’t achiev-
able with other non-decomposition methods.
3) Complexity Reduction: The original solution space of 𝜒=
[𝑥1,...,𝑥𝑖,...,𝑥𝑁]is reduced from 2𝑁to just a single dimension,
which only necessitates the determination of 𝑆(𝑜𝑝𝑡).
5733KDD ’24, August 25–29, 2024, Barcelona, Spain. Yumin Su et al.
Figure 1: THRESHOLD algorithm
4.2 SPB Two-Stage Decomposition
The SPB algorithm, as we have previously discussed, consists of
two stages: macro and micro. This section explains why we split
the algorithm in this way. Subsequent sections will provide further
details about each stage. First, we establish a theorem based on an
ideal scenario, not taking into account 𝑑(𝑡). Then, we extend it to a
more common scenario where 𝑑(𝑡)is considered. For a short time
period𝑡𝑙, the ROI of a single auction can be defined as 𝑟𝑖=𝑃𝑔𝑖/𝑃𝑠𝑖.
In this context, the THRESHOLD greedy algorithm in an ideal
scenario works as follows:
1) Sort all auction opportunities in a descending order according
to𝑟𝑖
2) Select auction opportunities from top to bottom until 𝑟𝑖meets
the optimal threshold 𝑅(𝑜𝑝𝑡)
𝑡ℎ𝑟, obtain corresponding bid by replacing
𝑟𝑖in Eq. (5) with 𝑅(𝑜𝑝𝑡)
𝑡ℎ𝑟.
A demonstration is visualized in Fig. 1. We win all auction oppor-
tunities where 𝑟𝑖is greater than or equal to 𝑅(𝑜𝑝𝑡)
𝑡ℎ𝑟(shadow region
𝑆1in Fig. 1) to achieve the maximization of 𝑃𝐺under the𝑅𝑡𝑎𝑟𝑔𝑒𝑡
and𝑆𝑐𝑎𝑝constraints.
Referring to Eq. (6), disregarding 𝑑(𝑡)means that the estimated
value of𝑐𝑖is equal to the ground-truth value. For each auction op-
portunity, it can be accurately placed in the corresponding position
in Fig. 1. then we provide a theorem,
Theorem 1. When the𝑅𝑡ℎ𝑟remains consistent across all auction
opportunities, the optimal solution is achieved.
Proof. We prove by contradiction. Considering the situation of
two different 𝑅𝑡ℎ𝑟1and𝑅𝑡ℎ𝑟2, assuming the overall 𝑃𝐺is maximum
with𝑅𝑡ℎ𝑟1>𝑅𝑡ℎ𝑟2, then we move 𝑅𝑡ℎ𝑟1down of a exiguity Δ𝑅−
𝑡ℎ𝑟1
and move𝑅𝑡ℎ𝑟2up of a exiguity Δ𝑅+
𝑡ℎ𝑟2withΔ𝑃+
𝑆𝑡ℎ𝑟1=Δ𝑃−
𝑆𝑡ℎ𝑟2.
since all auction opportunities are arranged in descending order
by roi, obviously, there is Δ𝑅−
𝑟𝑒𝑠1>Δ𝑅+
𝑟𝑒𝑠2. Given that Δ𝑃𝐺𝑡ℎ𝑟=
Δ𝑃𝑆𝑡ℎ𝑟·𝑅𝑟𝑒𝑠, it naturally follows that Δ𝑃+
𝐺𝑡ℎ𝑟1>Δ𝑃−
𝐺𝑡ℎ𝑟2, i.e., mov-
ing a portion of spend in 𝑅𝑡ℎ𝑟2to𝑅𝑡ℎ𝑟1can obtain a overall 𝑃′
𝐺that
𝑃′
𝐺>𝑃𝐺, which contradicts our initial assumption of 𝑃𝐺being
maximal. Proof completed.
Nevertheless, in privacy scenarios, the value of 𝑑(𝑡)cannot be
overlooked as it precludes the attainment of real-time 𝑐𝑖values in
short time intervals. As previously mentioned,
1) Privacy policies often impose a certain delay (e.g., SKAN
doesn’t surpass 48 hours). By aggregating data over multiple days,
we can get very close to the actual value of 𝑐𝑖.2)𝑑(𝑡)doesn’t highly fluctuate within a very short time interval.
Thus, if𝑟𝑖is order-preserving regardless of the value of 𝑑(𝑡)for
all auction opportunities, using THRESHOLD algorithm remains a
viable solution even in a short duration.
This insight motivates us to separate the online bidding pro-
cess into two stages: macro andmicro. The macro stage devises the
optimal spend 𝑆(𝑜𝑝𝑡), for a given spending period from archived
data over a long period, and then allocates 𝑆(𝑜𝑝𝑡)for a short time
interval𝑡𝑙following a budget allocation curve to get 𝑆(𝑜𝑝𝑡)
𝑙. Sub-
sequently, the micro stage generates the real-time bidding price
based on𝑆(𝑜𝑝𝑡)
𝑙. It is crucial to note that budget distribution curve
research, a field focused on optimizing budget allocation, ensures a
consistent𝑅𝑡ℎ𝑟once the allocated budget is fully spent. While this
study doesn’t focus on this, it leverages existing works like [ 36] to
potentially optimize budget allocation efficiency.
4.3 Macro Spend Planning
As previously stated, the macro stage devises the long-term optimal
spend𝑆(𝑜𝑝𝑡), ensuring this allocated spend aligns with the long-
term optimum in Eq. (2). This problem is modeled by exploring
the relationship between optimal GMV and optimal ROI, and we’ll
demonstrate this with an example. Initially, in the absence of 𝑑(𝑡)
considerations, we propose the following theorems under ideal
conditions.
Theorem 2. For an ad campaign with different 𝑅𝑡𝑎𝑟𝑔𝑒𝑡 and𝑆𝑐𝑎𝑝
constraints, the optimal result roi 𝑅(𝑜𝑝𝑡)
𝑟𝑒𝑠 is monotone increasing w.r.t.
𝑅(𝑜𝑝𝑡)
𝑡ℎ𝑟.
Proof. To verify the proof more clearly and more intuitive, an
illustration is shown in Fig. 1. Assuming we move 𝑅(𝑜𝑝𝑡)
𝑡ℎ𝑟between
𝑅′(𝑜𝑝𝑡)
𝑡ℎ𝑟and𝑅′′(𝑜𝑝𝑡)
𝑡ℎ𝑟under different 𝑅𝑡𝑎𝑟𝑔𝑒𝑡 and𝑆𝑐𝑎𝑝constraints,
we obtain more auction opportunities in the 𝑆2region. Since 𝑟𝑖is
arranged in descending order, any 𝑟𝑖in the𝑆1region is greater than
any𝑟𝑗in the𝑆2region, i.e.𝑟𝑖>𝑟𝑗, for∀𝑖∈𝑆1,𝑗∈𝑆2. So obvi-
ously the result ROI also follows the same inequality relationship
𝑅(𝑜𝑝𝑡)
𝑟𝑒𝑠𝑆1≥𝑅𝑟𝑒𝑠𝑆2, considering Eq. (1), we have
𝑃(𝑜𝑝𝑡)
𝐺𝑆1
𝑃𝑆(𝑜𝑝𝑡)
𝑆1≥𝑃𝐺𝑆2
𝑃𝑆𝑆2⇒𝑃(𝑜𝑝𝑡)
𝐺𝑆1·𝑃𝑆𝑆2−𝑃𝐺𝑆2·𝑃(𝑜𝑝𝑡)
𝑆𝑆1≥0 (7)
We denote the optimal result ROI of the new winning region
𝑆1+𝑆2as𝑅(𝑜𝑝𝑡)
𝑟𝑒𝑠(𝑆1+𝑆2), and we compare
𝑃(𝑜𝑝𝑡)
𝐺(𝑆1+𝑆2)
𝑃(𝑜𝑝𝑡)
𝑆(𝑆1+𝑆2)−𝑃(𝑜𝑝𝑡)
𝐺𝑆1
𝑃(𝑜𝑝𝑡)
𝑆𝑆1
=−𝑃(𝑜𝑝𝑡)
𝐺𝑆1·𝑃𝑆𝑆2−𝑃𝐺𝑆2·𝑃(𝑜𝑝𝑡)
𝑆𝑆1
(𝑃(𝑜𝑝𝑡)
𝑆𝑆1+𝑃𝑆𝑆2)·𝑃(𝑜𝑝𝑡)
𝑆𝑆1≤0(8)
Eq. (8) indicates that 𝑅(𝑜𝑝𝑡)
𝑟𝑒𝑠 decreases as 𝑅(𝑜𝑝𝑡)
𝑡ℎ𝑟decreases, thus
we have completed the proof.
5734Spending Programmed Bidding: Privacy-friendly Bid Optimization with ROI Constraint in Online Advertising KDD ’24, August 25–29, 2024, Barcelona, Spain.
Theorem 3. For an ad campaign with different 𝑅𝑡𝑎𝑟𝑔𝑒𝑡 and𝑆𝑐𝑎𝑝
constraints, the optimal gmv 𝑃(𝑜𝑝𝑡)
𝐺and spend𝑃(𝑜𝑝𝑡)
𝑆is monotone
decreasing w.r.t. 𝑅(𝑜𝑝𝑡)
𝑟𝑒𝑠 .
Proof. Same with proof of Theorem2, assuming we move 𝑅(𝑜𝑝𝑡)
𝑡ℎ𝑟
between𝑅′(𝑜𝑝𝑡)
𝑡ℎ𝑟and𝑅′′(𝑜𝑝𝑡)
𝑡ℎ𝑟under different 𝑅𝑡𝑎𝑟𝑔𝑒𝑡 and𝑆𝑐𝑎𝑝con-
straints, we win extra auction opportunities with Δ𝑃𝐺=𝑃𝐺𝑆2and
Δ𝑃𝑆=𝑃𝑆𝑆2, which are definitely greater than 0. Then we have
𝑃(𝑜𝑝𝑡)
𝐺(𝑆1+𝑆2)=𝑃(𝑜𝑝𝑡)
𝐺𝑆1+𝑃𝐺𝑆2≥𝑃(𝑜𝑝𝑡)
𝐺𝑆1and𝑃(𝑜𝑝𝑡)
(𝑆1+𝑆2)=𝑃(𝑜𝑝𝑡)
𝑆𝑆1+𝑃𝑆𝑆2≥
𝑃(𝑜𝑝𝑡)
𝑆𝑆1i.e. the gmv and spend of the new winning region 𝑆1+𝑆2
are greater than the origin winning region 𝑆1along with 𝑅(𝑜𝑝𝑡)
𝑡ℎ𝑟
less than𝑅′(𝑜𝑝𝑡)
𝑡ℎ𝑟. Noting that we have proved 𝑅(𝑜𝑝𝑡)
𝑟𝑒𝑠 is monotone
increasing w.r.t. 𝑅(𝑜𝑝𝑡)
𝑡ℎ𝑟in Theorem2, we attain 𝑃(𝑜𝑝𝑡)
𝐺and𝑃(𝑜𝑝𝑡)
𝑆
is monotone decreasing w.r.t. 𝑅(𝑜𝑝𝑡)
𝑟𝑒𝑠 , thus the proof of Theorem3
has been finished.
With consideration of 𝑑(𝑡), the value of 𝑅(𝑜𝑝𝑡)
𝑡ℎ𝑟in the THRESH-
OLD algorithm may exhibit variations. However, the final optimal
GMV and ROI still conform to Theorem 3. Thus, we can construct a
relation function between the optimal GMV 𝑃(𝑜𝑝𝑡)
𝐺and ROI𝑅(𝑜𝑝𝑡)
𝑟𝑒𝑠 .
Treat the𝑅𝑡𝑎𝑟𝑔𝑒𝑡 , as set by the advertiser, to be the optimal ROI (i.e.,
Eq. (4) is equivalent), allowing for the calculation of optimal GMV
𝑃(𝑜𝑝𝑡)
𝐺and thereby the optimal spend 𝑃(𝑜𝑝𝑡)
𝑆. We compute our func-
tion parameters based on GMV and ROI posterior data aggregated
over a long period (such as n days). Given the minor impact of 𝑑(𝑡)
on long-term posterior data :1) 𝑐𝑖can be fully restored within 48
hours, and only accumulated data is employed, thereby dodging the
coarse-grained and hysteresis challenges; 2)due to the large sample
size of the long-term results, the stochastic challenges impact is
considerably less than that of small samples in a short period. So
that the optimal functional relationship can be approximated. Let’s
further explain this through a detailed example.
As shown from Fig. 1, 𝑅𝑡ℎ𝑟indicates the reduction in 𝑅𝑟𝑒𝑠for
each additional auction opportunity, precisely representing the
concept of marginal ROI. Function 𝐹(𝑃(𝑜𝑝𝑡)
𝐺)=𝑅(𝑜𝑝𝑡)
𝑟𝑒𝑠 can take
various forms depending on the circumstances. For clarity, we’ll
provide an example in its simplest form, we simply infer that the
optimal marginal ROI 𝑅(𝑜𝑝𝑡)
𝑡ℎ𝑟and optimal GMV 𝑃(𝑜𝑝𝑡)
𝐺bear a linear
relationship according to Theorem2 and Theorem3.
𝑅(𝑜𝑝𝑡)
𝑡ℎ𝑟=𝐹′(𝑃(𝑜𝑝𝑡)
𝐺)=𝑎·𝑃(𝑜𝑝𝑡)
𝐺+𝑏 (9)
Where a and b are hyperparameters, then we get
𝑅(𝑜𝑝𝑡)
𝑟𝑒𝑠 =𝐹(𝑃(𝑜𝑝𝑡)
𝐺)=𝑎·𝑃2(𝑜𝑝𝑡)
𝐺
2+𝑏·𝑃(𝑜𝑝𝑡)
𝐺(10)
𝑃(𝑜𝑝𝑡)
𝐺=√︃
𝑏2+2𝑎·𝑅(𝑜𝑝𝑡)
𝑟𝑒𝑠−𝑏
𝑎(11)
According to Eq. (1), we further obtain
𝑃(𝑜𝑝𝑡)
𝑆=𝑃(𝑜𝑝𝑡)
𝐺
𝑅(𝑜𝑝𝑡)
𝑟𝑒𝑠=√︃
𝑏2+2𝑎·𝑅(𝑜𝑝𝑡)
𝑟𝑒𝑠−𝑏
𝑎·𝑅(𝑜𝑝𝑡)
𝑟𝑒𝑠(12)To figure out the parameters a and b, the cumulative GMV and
ROI over a defined spending period (such as one day) can be syn-
thesized to generate a single sample point. The data points over
multiple days then can be aggregated and derived parameters a and
b through multi-point fitting. Numerous existing methods can be
consulted for model parameter determination to achieve minimum
MSE across multiple sample points. Once parameters a and b are
determined, we can input the advertiser’s target ROI, 𝑅𝑡𝑎𝑟𝑔𝑒𝑡 , into
Eq. (12) to procure the optimal spending 𝑃(𝑜𝑝𝑡)
𝑆for a defined spend-
ing duration. Given the spend constraint Eq. (3), 𝑆(𝑜𝑝𝑡)is assessed
asmin(𝑃(𝑜𝑝𝑡)
𝑆,𝑆𝑐𝑎𝑝).
After finding the 𝑃(𝑜𝑝𝑡)
𝑆, it is distributed over a shorter period
through a budget allocation curve, obtaining the 𝑃(𝑜𝑝𝑡)
𝑆𝑙for a brief
time interval 𝑡𝑙. This can guide the optimal bid within 𝑡𝑙during the
micro stage.
4.4 Micro Bidding Optimization
As previously noted, we have determined the overall optimal spend
𝑃(𝑜𝑝𝑡)
𝑆in the macro satge. We then use a budget allocation method
to obtain the optimal 𝑃(𝑜𝑝𝑡)
𝑆𝑙for a brief time interval 𝑡𝑙. The micro
process’ objective is to spend exactly 𝑃(𝑜𝑝𝑡)
𝑆𝑙within𝑡𝑙. Ideally, the
THRESHOLD algorithm could be directly employed to compute
𝑅𝑡ℎ𝑟through Eq. (9), then calculate the optimal bid through Eq. (5).
Nevertheless, in privacy scenarios demanding the consideration
of𝑑(𝑡), short-term GMV and ROI are influenced by the aforemen-
tioned challenges, inhibiting the acquisition of suitable a and b
parameters for Eq. (9). As a result, we need to refine the THRESH-
OLD algorithm to find the specific 𝑅𝑡ℎ𝑟value without depending
on GMV and ROI, ensuring fulfilling the 𝑃(𝑜𝑝𝑡)
𝑆𝑙spend.
It’s worth acknowledging that in privacy scenarios, while 𝑐𝑖is
impacted by 𝑑(𝑡), its spend is unaffected. The spend can be imme-
diately collected as soon as the ad campaign has been displayed
via the widely accepted OCPM mechanism5(or any other pricing
method charging by display or click), indicating that the spend can
be gathered in real-time, undisturbed by hysteresis and stochastic
challenges.
Hence, we aim to build a model for 𝑅𝑡ℎ𝑟and spend𝑃𝑆. In accord
with Theorem2 and Theorem3, under ideal circumstances, 𝑅𝑡ℎ𝑟
and𝑃𝑆monotonically decrease. Assuming that 𝑑(𝑡)maintains the
𝑟𝑖order for all auction opportunities, Theorem2 and Theorem3
continues to hold in privacy scenarios featuring a different optimal
𝑅𝑡ℎ𝑟than the ideal, as exhibited in Eq. (6).
We propose the following algorithm to construct a linear interpo-
lation model for 𝑅𝑡ℎ𝑟and𝑃𝑆, termed the Interpolation-based MPC
method (IMPC). By utilizing spending data from a brief time slice
𝑡𝑙only, we can calculate the 𝑅𝑡ℎ𝑟and then𝑏𝑙+1for the subsequent
time interval 𝑡𝑙+1. The specific algorithm is delineated in Algorithm
2.
We can summarize that the IMPC, as described in Algorithm 2,
offers several key advantages:
5Advertisers bid for conversions while paying per mille display
5735KDD ’24, August 25–29, 2024, Barcelona, Spain. Yumin Su et al.
Algorithm 2 Interpolation-based MPC method
Input:(𝑃𝑆𝑙,𝑅𝑡ℎ𝑟𝑙)for time control interval 𝑡𝑙;
𝑄=𝑞𝑢𝑒𝑢𝑒(𝑃𝑆𝑖,𝑅𝑡ℎ𝑟𝑖),𝑖∈{1,...,𝐿}for last𝐿time control in-
tervals
𝑉=𝑣𝑒𝑐𝑡𝑜𝑟(𝑆𝑟𝑎𝑡𝑖𝑜𝑗)for remain time control intervals from
budget allocation methods
𝑆(𝑜𝑝𝑡)the expected spend in a spending period derived from
the macro stage
𝑆𝑐𝑎𝑝maximum spend in a spending period set by advertiser
𝑃𝑆cumulative spend in a spending period
Output:𝑏𝑙+1for next time control interval 𝑡𝑙+1
1:if𝑃𝑆>𝑆𝑐𝑎𝑝then
2:𝑏𝑙+1=0
3: return
4:else
5: if𝑙𝑒𝑛(𝑄)==0then
6:𝑏𝑙+1=𝑖𝑛𝑖𝑡(𝑐𝑜𝑛𝑠𝑡𝑎𝑛𝑡 _𝑏𝑖𝑑)
7: return
8: else
9:𝑙𝑎𝑠𝑡𝑅𝑡ℎ𝑟=𝑅𝑡ℎ𝑟𝑙
10: end if
//deal with new data
11: if𝑣𝑎𝑙𝑖𝑑(𝑃𝑆𝑙,𝑅𝑡ℎ𝑟𝑙)then
12:𝑄=𝑝𝑢𝑠ℎ(𝑄,(𝑃𝑆𝑙,𝑅𝑡ℎ𝑟𝑙))
13: else
14:𝑏𝑙+1=𝐹(𝑙𝑎𝑠𝑡𝑅𝑡ℎ𝑟)// using Eq. (6)
15: return
16: end if
17: if𝑙𝑒𝑛(𝑄)>𝐿then
18:𝑄=𝑝𝑜𝑝(𝑄)
19: end if
//calculate the expected spend for 𝑡𝑙+1
20:𝑆(𝑜𝑝𝑡)
𝑙+1=(𝑆(𝑜𝑝𝑡)−𝑃𝑆)·𝑆𝑟𝑎𝑡𝑖𝑜𝑙+1/Í
𝑗𝑆𝑟𝑎𝑡𝑖𝑜𝑗
//aggregate and average points with similar 𝑅𝑡ℎ𝑟values
21:𝐴𝑄=𝑎𝑔𝑔𝑟𝑒𝑔𝑎𝑡𝑖𝑜𝑛(𝑄)
//calculate new 𝑅𝑡ℎ𝑟with liner interpolation
22:𝐿𝐼𝑆𝑄 =𝐿𝑜𝑛𝑔𝑒𝑠𝑡𝐼𝑛𝑐𝑟𝑒𝑎𝑠𝑖𝑛𝑔𝑆𝑢𝑏𝑆𝑞𝑢𝑒𝑛𝑐𝑒 (𝐴𝑄)
23:(𝑃𝑆𝑥1,𝑅𝑡ℎ𝑟𝑥1),(𝑃𝑆𝑥2,𝑅𝑡ℎ𝑟𝑥2)=𝐶𝑙𝑜𝑠𝑒𝑠𝑡𝑃𝑜𝑖𝑛𝑡(𝐿𝐼𝑆𝑄,𝑆(𝑜𝑝𝑡)
𝑙+1)
24:𝑅𝑡ℎ𝑟𝑙+1=𝑅𝑡ℎ𝑟𝑥1+(𝑆(𝑜𝑝𝑡)
𝑙+1−𝑃𝑆𝑥1)·𝑅𝑡ℎ𝑟𝑥2−𝑅𝑡ℎ𝑟𝑥1
𝑃𝑆𝑥2−𝑃𝑆𝑥1
25:𝑏𝑙+1=𝐹(𝑅𝑡ℎ𝑟𝑙+1)// using Eq. (6)
26: return
27:end if
1) No Cumulative Error: For each 𝑡𝑙, the optimal bid 𝑏𝑙depends
only on a predetermined 𝑆(𝑜𝑝𝑡)
𝑙, and remains unaffected by previous
control effects, unlike feedback control methods.
2) No Prior Function Distribution Required: Essentially as a non-
parametric regression model, it ensures high accuracy.
3) Robustness and Portability: Relying only on real-time settle-
ment data, it proves to be stable and effective even in high-frequency
computations.4.5 Multi Channel Promotion
In practical, advertisers usually place ad campaigns on more than
one channel regardless of privacy constraints with spend sharing,
and each channel has its own 𝑅𝑡𝑎𝑟𝑔𝑒𝑡 constrain. Therefore, the
problem to be solved is extended to
𝑚𝑎𝑥𝑀∑︁
𝑗=1𝑐𝑐ℎ𝑎𝑛𝑛𝑒𝑙𝑗·𝑣𝑎𝑐ℎ𝑎𝑛𝑛𝑒𝑙𝑗(13)
s.t.
𝑀∑︁
𝑗=1𝑃𝑆𝑐ℎ𝑎𝑛𝑛𝑒𝑙𝑗≤𝑆𝑐𝑎𝑝 (14)
𝑆𝑓𝑙𝑜𝑜𝑟𝑐ℎ𝑎𝑛𝑛𝑒𝑙𝑗≤𝑃𝑆𝑐ℎ𝑎𝑛𝑛𝑒𝑙𝑗≤𝑆𝑐ℎ𝑎𝑛𝑛𝑒𝑙𝑗,∀𝑗∈{1,...,𝑀} (15)
𝑅𝑟𝑒𝑠𝑐ℎ𝑎𝑛𝑛𝑒𝑙𝑗≥𝑅𝑡𝑎𝑟𝑔𝑒𝑡𝑐ℎ𝑎𝑛𝑛𝑒𝑙𝑗,∀𝑗∈{1,...,𝑀} (16)
𝑅𝑟𝑒𝑠≥𝑅𝑡𝑎𝑟𝑔𝑒𝑡 (17)
Due to the differences in the estimated deviation 𝑑𝑙and tar-
get ROI𝑅𝑡𝑎𝑟𝑔𝑒𝑡 between different channels in mixed privacy and
non-privacy scenarios, the single channel SPB solution proposed
above cannot be directly used. We further expand SPB to multiple
channels, which macro part is jointly solved, while micro part is
separately solved. In the macro part, we need to simultaneously
produce the expected optimal spend 𝑆𝑐ℎ𝑎𝑛𝑛𝑒𝑙𝑗for each channel.
Before that, we provide Theorem 4 and prove it.
Theorem 4. When the overall 𝑃𝐺is maximum, there must be
equal𝑅𝑡ℎ𝑟for each channel.
Proof. We prove by contradiction. Considering the situation
of two channels 𝑐ℎ1and𝑐ℎ2, assuming the overall 𝑃𝐺is maxi-
mum with𝑅𝑡ℎ𝑟𝑐ℎ1>𝑅𝑡ℎ𝑟𝑐ℎ2, then we move 𝑅𝑡ℎ𝑟𝑐ℎ1down of a
exiguity Δ𝑅−
𝑡ℎ𝑟𝑐ℎ1and move𝑅𝑡ℎ𝑟𝑐ℎ2up of a exiguity Δ𝑅+
𝑡ℎ𝑟𝑐ℎ2with
Δ𝑃+
𝑆𝑐ℎ1=Δ𝑃−
𝑆𝑐ℎ2. Obviously, there is Δ𝑅−𝑟𝑒𝑠𝑐ℎ1>Δ𝑅+𝑟𝑒𝑠𝑐ℎ2and
Δ𝑃𝐺𝑐ℎ=Δ𝑃𝑆𝑐ℎ·𝑅𝑟𝑒𝑠𝑐ℎ, then we have Δ𝑃+
𝐺𝑐ℎ1>Δ𝑃−
𝐺𝑐ℎ2, i.e., mov-
ing a portion of spend in 𝑐ℎ2to𝑐ℎ1can obtain a overall 𝑃′
𝐺that
𝑃′
𝐺>𝑃𝐺, which contradicts our initial assumption of 𝑃𝐺being
maximal. Proof completed.
According to Theorem 4, we can determine the optimal spend
for each channel through a binary search method which detailed
in Algorithm 3.
Upon determining 𝑅𝑡ℎ𝑟, we can’t directly bid using Eq. (5) due to
the variance in 𝑑𝑙across different channels. We need to first com-
pute𝑆𝑐ℎ𝑎𝑛𝑛𝑒𝑙𝑗akin to the macro stage, constructing a functional
correlation between GMV and ROI for each channel. Subsequently,
the IMPC algorithm is independently applied to 𝑐ℎ𝑎𝑛𝑛𝑒𝑙𝑗to derive
the optimal bid 𝑏𝑐ℎ𝑎𝑛𝑛𝑒𝑙𝑗.
5 Experiments
In this section, we validate the performance of our proposed SPB
method through online and offline experiments. We first conduct
online experiments on an industrial dataset collected from the
TikTok display advertising platform6to compare the performance
of SPB with other advanced methods in real-world industrial appli-
cation circumstances. As the privacy constrained attribution issue
is recently raised, and due to the need to protect user privacy and
6https://ads.tiktok.com/i18n/dashboard
5736Spending Programmed Bidding: Privacy-friendly Bid Optimization with ROI Constraint in Online Advertising KDD ’24, August 25–29, 2024, Barcelona, Spain.
Algorithm 3 Multi Channel SPB - macro stage
Input:𝑅𝑡𝑎𝑟𝑔𝑒𝑡,𝑅𝑡𝑎𝑟𝑔𝑒𝑡𝑐ℎ𝑎𝑛𝑛𝑒𝑙𝑗,𝑆𝑐𝑎𝑝,𝑆𝑓𝑙𝑜𝑜𝑟𝑐ℎ𝑎𝑛𝑛𝑒𝑙𝑗
Output:𝑆𝑐ℎ𝑎𝑛𝑛𝑒𝑙𝑗
1:initialize:𝑆(𝑜𝑝𝑡)=0,𝑃𝐺=0,random(𝑅𝑡ℎ𝑟)
2:repeat
3: foreach channel 𝑗do
4:𝑆𝑐ℎ𝑎𝑛𝑛𝑒𝑙𝑗=max(𝐹𝑐ℎ𝑎𝑛𝑛𝑒𝑙𝑗(𝑅𝑡ℎ𝑟),𝑆𝑓𝑙𝑜𝑜𝑟𝑐ℎ𝑎𝑛𝑛𝑒𝑙𝑗)// using
Eq. 9 and Eq. 10 and Eq. 1
5:𝑅𝑟𝑒𝑠𝑐ℎ𝑎𝑛𝑛𝑒𝑙𝑗=𝐹(𝑆𝑐ℎ𝑎𝑛𝑛𝑒𝑙𝑗)// using Eq. 12
6:𝑃𝐺𝑐ℎ𝑎𝑛𝑛𝑒𝑙𝑗=𝐹(𝑅𝑟𝑒𝑠𝑐ℎ𝑎𝑛𝑛𝑒𝑙𝑗)// using Eq. 11
7:𝑆(𝑜𝑝𝑡)+=𝑆𝑐ℎ𝑎𝑛𝑛𝑒𝑙𝑗,𝑃𝐺+=𝑃𝐺𝑐ℎ𝑎𝑛𝑛𝑒𝑙𝑗
8: end for
9:𝑅𝑟𝑒𝑠=𝑃𝐺
𝑆(𝑜𝑝𝑡)
10: if𝑅𝑟𝑒𝑠<𝑅𝑡𝑎𝑟𝑔𝑒𝑡 or𝑆(𝑜𝑝𝑡)>𝑆𝑐𝑎𝑝or𝑅𝑟𝑒𝑠𝑐ℎ𝑎𝑛𝑛𝑒𝑙𝑗<
𝑅𝑡𝑎𝑟𝑔𝑒𝑡𝑐ℎ𝑎𝑛𝑛𝑒𝑙𝑗𝑓𝑜𝑟∀𝑗then
11: Explore up𝑅𝑡ℎ𝑟in (𝑅𝑡ℎ𝑟,+∞)
12: else
13: Explore down 𝑅𝑡ℎ𝑟in (0,𝑅𝑡ℎ𝑟)
14: end if
15:until𝑅𝑡ℎ𝑟convergence
16:𝑆𝑐ℎ𝑎𝑛𝑛𝑒𝑙𝑗=𝐹𝑐ℎ𝑎𝑛𝑛𝑒𝑙𝑗(𝑅𝑡ℎ𝑟)// using Eq. 9
commercial secrets, we are unable to disclose TikTok’s advertis-
ing data. To demonstrate the reproducibility of our work, and to
provide a validation dataset and template code for future users of
our method, we have built a simulated privacy dataset based on
AuctionGym[ 19], and then conduct offline experiments on the simu-
lated dataset. Our simulated dataset and code are publicly available
at https://github.com/cff29546/SpendingProgrammedBidding.
5.1 Experimental Settings
Datasets: Theindustrial dataset is collected from the Tiktok dis-
play advertising platform. As described in Table 2, we randomly
select three datasets for the experiment, one from campaigns using
SKAN attribution, one from campaigns using PCM attribution and
another from campaigns using non-privacy constrained. We evalu-
ated the average 𝑤𝑝/𝑠𝑝𝑒𝑛𝑑 ratio for each dataset during Aug 1st
to Aug 8th of 2023. As all datasets have small 𝑤𝑝/𝑠𝑝𝑒𝑛𝑑 ratio, thus
the greedy method in subsection 4.1 is applicable.
Thesimulated dataset is created based on the public simulated
dataset AuctionGym, which is a simulation environment that facili-
tates reproducible offline evaluations for ad allocation and bidding
in online advertising auctions without privacy constraints. We have
enhanced this dataset to meet the three characteristics previously
mentioned for privacy scenarios: coarse-grained, hysteresis, and
stochastic natures. In our enhanced dataset, the number of cam-
paigns and auction opportunities can be set, while still retaining
the attribute of a very small 𝑤𝑝/𝑠𝑝𝑒𝑛𝑑 proportion. The offline ex-
periment simulates each bidder with 500 random campaigns (runs)
under different postback delay settings of 0, 1, and 2 batches (simu-
lating online days).
Budget Splitting Experimental Mechanism: For the online ex-
periments on the industrial dataset, to split online traffic into testTable 2: summary of industrial datasets
Dataset # Campaigns Avg. 𝑤𝑝/𝑠𝑝𝑒𝑛𝑑 𝑔 𝑖
SKAN 455 2.82×10−77% each
PCM 4488 1.24×10−67% each
non-privacy 1290 6.28×10−77% each
and control groups, we define the split vector 𝐺=[𝑔1,...,𝑔𝑖,...,𝑔𝑁]
where𝑔𝑖∈(0,1]andÍ𝑁
𝑖=1𝑔𝑖=1. Then we split all online auction
opportunities into 𝑁groups by randomly assigning each auction
opportunity to group 𝑖with a chance of 𝑔𝑖. For each involved adver-
tising campaign, the original spend cap 𝑆𝑐𝑎𝑝given by the advertiser
is also split into 𝑁groups, with each group 𝑖having a spend cap
equal to𝑆𝑐𝑎𝑝·𝑔𝑖and can only participate in auction opportunities
assigned to that group.
SPB method settings: For each campaign, we learn 𝐹(𝑃𝐺)=𝑅𝑟𝑒𝑠
from its daily history using a 7-day time window. Each daily 𝑅𝑟𝑒𝑠
and𝑃𝐺pair within the history window that is no longer affected by
attribution delays is used as a sample. After learning 𝐹(𝑃𝐺)=𝑅𝑟𝑒𝑠,
𝑆(𝑜𝑝𝑡)is calculated by inserting 𝑅𝑡𝑎𝑟𝑔𝑒𝑡 .𝑆(𝑜𝑝𝑡)is then applied in
the micro stage of the following day, where 𝑡𝑙is set to 20 seconds.
5.2 Performance Measurement
The goal of ROI constrained advertising is to optimise a cam-
paign’s GMV while maintaining an acceptable ROI result. Therefore,
GMV and spending (platform revenue) are calculated for each cam-
paign during the experimental period. Subsequently, campaigns
are grouped based on their ROI and spend utilization performance.
Lastly, the GMV and spending accumulated for each campaign
performance group are used to assess the performance of bidding
methods. As shown in Fig. 2, we define the following campaign
performance groups:
(1) The Violation group includes campaigns whose 𝑅𝑟𝑒𝑠/𝑅𝑡𝑎𝑟𝑔𝑒𝑡 <
1−𝜖1, indicating a violation of the ROI constraint. The 𝜖1is the ROI
volatility tolerance parameter. We use 𝜖1=0.2in our overall per-
formance comparisons. The less GMV and spending in this group
indicate a better bidding method.
(2) The Under Performance group includes campaigns where
𝑅𝑟𝑒𝑠/𝑅𝑡𝑎𝑟𝑔𝑒𝑡 >1+𝜖2and𝑃𝑆/𝑆𝑐𝑎𝑝<1−𝜖3, suggesting campaigns
have a good ROI and potential to increase spending. The 𝜖2is the
good ROI discriminant parameter and 𝜖3is the spending capacity
discriminant parameter. We use 𝜖2=0.2and𝜖3=0.1in our overall
performance comparisons. Lower GMV and spending in this group
also indicate a better bidding method.
(3) The Accomplish group comprises all campaigns not included
in the Violation andUnder Performance groups. Higher GMV
and spending in this group would indicate a better bidding method.
Additionally, when ROI is the primary concern, we can combine
groups (2) and (3) to form the Non-Violation group.
5.3 Compared Bidding Methods
In our experiments, we compare the following bidding methods:
Bid Cap: This method attempts to smoothly spend the entire budget
𝑆𝑐𝑎𝑝, ensuring that 𝑅𝑡ℎ𝑟≥𝑅𝑡𝑎𝑟𝑔𝑒𝑡 . The smooth spending is similar
to using the micro stage for the entire budget 𝑆𝑐𝑎𝑝.
5737KDD ’24, August 25–29, 2024, Barcelona, Spain. Yumin Su et al.
Figure 2: campaign performance groups
Table 3: over all performance compare over SKAN campaigns
Violation Under Performance Accomplish
BidCap(base)
GMV 10.54 (27.24%) 3.58 (9.25%) 24.57 (63.51%)
Spending 19.47 (44.48%) 2.65 (6.06%) 21.65 (49.46%)
# Campaigns 36.53% 13.70% 49.77%
MPC
GMV 11.78 (29.35%) 1.43 (3.56%) 26.93 (67.09%)
Spending 16.99 (38.81%) 0.82 (1.87%) 25.97 (59.32%)
# Campaigns 38.57% 13.45% 47.98%
SPB
GMV 5.61 (11.92%) 4.44 (9.45%) 36.99 (78.63%)
Spending 9.74 (27.55%) 2.31 (6.55%) 23.29 (65.91%)
# Campaigns 40.66% 12.12% 47.19%
MPC: Real-time feedback control using ground truth data is unre-
alistic in scenarios with heavy delays. Therefore, we use true click
events with the model-predicted conversion rate for feedback where
𝑐𝑖=𝑐𝑙𝑖𝑐𝑘∗
𝑖·𝑐𝑣𝑟𝑖. We then employ a PID controller for real-time
feedback control, where the PID error is given by 𝑅𝑟𝑒𝑠/𝑅𝑡𝑎𝑟𝑔𝑒𝑡−1.
5.4 Online Experimental Performance
5.4.1 Overall Performance Comparisons. In this subsection, we
evaluate the overall performance of our proposed SPB framework
by comparing it comprehensively with various baselines.
Table.3 contains performance data from the online experiment
conducted from July 26, 2023 to August 1, 2023 on SKAN attribution
campaigns. The numbers, which have been desensitized to protect
commercial confidentiality, are collected from all campaigns with 5
or more average daily SKAN conversions. The results show that the
SPB bidding method can improve GMV and revenue in the Accom-
plish group while reducing GMV and revenue in the Violation
group, compared to other methods.
Fig.3 displays the Accomplish group’s GMV ratio across differ-
ent industrial datasets. Even though the SPB bidding method didn’t
outperform the MPC bidding method in non-privacy attribution
campaigns, it still surpasses the baseline (BidCap) bidding method.
Moreover, the SPB method demonstrates better performance in
privacy-constrained scenarios compared to other bidding methods,
especially in SKAN attribution campaigns.
Figure 3: Accomplish group GMV ratio across datasets
Figure 4: Violation group GMV ratio across different 𝜖1
Figure 5: GMV density over 𝑅𝑟𝑒𝑠/𝑅𝑡𝑎𝑟𝑔𝑒𝑡
5.4.2 In-Depth ROI Analysis. In this subsection, we compare the
performance of all bidding methods across different values of 𝜖1.
The data in Fig.4 is calculated from online experimental data
on SKAN attribution campaigns by varying the value of 𝜖1. As
mentioned in the Performance Measurement subsection, 𝜖1is the
ROI volatility tolerance parameter. According to Fig.4, the SPB bid-
ding method sees less increase in the violation group’s GMV ratio
compared to the other methods when reducing the ROI volatility
tolerance. Moreover, the SPB bidding method has the smallest vio-
lation group GMV ratio at 𝜖1=0, where the non-violation group
must strictly meet the ROI target.
To further analyze the ROI constrained optimization capability
of the SPB bidding method, we list the GMV distribution over
𝑅𝑟𝑒𝑠/𝑅𝑡𝑎𝑟𝑔𝑒𝑡 in Fig.5. We can see that the GMV distribution of SPB
is shifted towards 𝑅𝑟𝑒𝑠/𝑅𝑡𝑎𝑟𝑔𝑒𝑡 >1compared to other bidding
methods. Also, the SPB bidding method generates more GMV with
𝑅𝑟𝑒𝑠/𝑅𝑡𝑎𝑟𝑔𝑒𝑡≥1.0compared to other bidding methods.
5738Spending Programmed Bidding: Privacy-friendly Bid Optimization with ROI Constraint in Online Advertising KDD ’24, August 25–29, 2024, Barcelona, Spain.
Figure 6: Accomplish group GMV ratio across different delays
Figure 7: Violation group GMV ratio across different delays
5.5 Offline Experimental Performance
We are particularly interested in seeing our proposed method prac-
tically implemented in industrial scenarios, contributing a feasible
solution for computational advertising in privacy-constrained sce-
narios. Our approach is comprehensively applied to TikTok’s ad-
vertising under privacy constraints, exhibiting stable performance
online.
In adherence to user privacy and protection of commercial se-
crets, we cannot disclose TikTok’s advertising data. Hence, we pro-
vide an enhanced simulation environment based on AuctionGym
and establish offline experiments on it. Our main improvements
include:
1) Ensuring 𝑐𝑖differences with the original 𝑐𝑖values disrupted
by a monotonic disturbance.
2) Incorporating a delay in 𝑐𝑖feedback.
3) Aggregating 𝑐𝑖results into a single batch instead of instant
feedback after each auction opportunity.
Offline evaluation metrics align with those online, and we set
the advertiser-specified target ROI 𝑅𝑡𝑎𝑟𝑔𝑒𝑡 =1. Furthermore, in
our offline experiments, we have each method compete against the
same environment to obtain results for comparison. And our SPB
method outperforms compared to benchmark methods. Please refer
to the GitHub link provided in section 5 for details.
5.5.1 Overall Performance Comparisons. In alignment with online
experiment findings, the offline results further affirm that SPB
bidding method, relative to others, effectively enhances GMV in
the Accomplish group and decreases Value in the Violation group.
Fig.6 and Fig.7 present the GMV ratios for the Accomplish and
Violation groups over different delays. The SPB method shows
dominance in the Accomplish group with the highest proportion
Figure 8: Violation group GMV ratio across different 𝜖1
Figure 9: GMV density over 𝑅𝑟𝑒𝑠/𝑅𝑡𝑎𝑟𝑔𝑒𝑡
in the 0-3 batches delay period, and this lead intensifies as delays
increase. In contrast, the MPC method causes sharp ratio increases
in the Violation group as delays extend. However, the SPB method
increases at a much slower rate, showcasing its better effectiveness
against strict privacy policies.
5.5.2 In-Depth ROI Analysis. Here we compare the performance
of all bidding methods across different values of 𝜖1with a 1 batch
delay. As indicated in the paper, 𝜖1represents the ROI volatility
tolerance parameter. Fig.8 reveals that SPB bidding leads to smaller
increases in violation group’s GMV ratio compared to MPC when
reducing ROI volatility tolerance. The BidCap method, at the cost
of significantly less GMV compared to other methods, shows the
least violation group Value ratio in our offline experiment.
Further analysis of SPB’s ROI constrained optimization can be
seen in Fig.9, displaying Value distribution over 𝑅𝑟𝑒𝑠/𝑅𝑡𝑎𝑟𝑔𝑒𝑡 . SPB’s
Value distribution shifts towards 𝑅𝑟𝑒𝑠/𝑅𝑡𝑎𝑟𝑔𝑒𝑡 =1, significantly in
a uniform offline environment, compared to other methods. Consis-
tent with our findings in online experiments, SPB could yield more
Value for𝑅𝑟𝑒𝑠/𝑅𝑡𝑎𝑟𝑔𝑒𝑡≥1.0than other bidding methods.
6 Conclusions
In this paper, we introduce a novel Spending Programmed Bidding
framework (SPB) designed to address the issue of ROI-constrained
spending planning and bidding within privacy-protected environ-
ments, and extend it to mixed scenarios of privacy and non-privacy.
Through both offline and online experiments, we demonstrated that
our SPB method surpasses other state-of-the-art methods. The ex-
ploration of a more privacy-sensitive equilibrium would be studied
in the future work.
5739KDD ’24, August 25–29, 2024, Barcelona, Spain. Yumin Su et al.
References
[1]Deepak Agarwal, Souvik Ghosh, Kai Wei, and Siyu You. 2014. Budget pac-
ing for targeted online advertisements at LinkedIn. In The 20th ACM SIGKDD
International Conference on Knowledge Discovery and Data Mining, KDD ’14,
New York, NY, USA - August 24 - 27, 2014, Sofus A. Macskassy, Claudia Perlich,
Jure Leskovec, Wei Wang, and Rayid Ghani (Eds.). ACM, 1613–1619. https:
//doi.org/10.1145/2623330.2623366
[2]Karl Johan Astrom and Richard M. Murray. 2008. Feedback Systems: An Introduc-
tion for Scientists and Engineers. Princeton University Press, USA.
[3]Vashist Avadhanula, Riccardo Colini-Baldeschi, Stefano Leonardi, Karthik Abinav
Sankararaman, and Okke Schrijvers. 2021. Stochastic bandits for multi-platform
budget optimization in online advertising. In WWW ’21: The Web Conference
2021, Virtual Event / Ljubljana, Slovenia, April 19-23, 2021, Jure Leskovec, Marko
Grobelnik, Marc Najork, Jie Tang, and Leila Zia (Eds.). ACM / IW3C2, 2805–2817.
https://doi.org/10.1145/3442381.3450074
[4]Ashwinkumar Badanidiyuru, Andrew Evdokimov, Vinodh Krishnan, Pan Li,
Wynn Vonnegut, and Jayden Wang. 2021. Handling many conversions per click
in modeling delayed feedback. CoRR abs/2101.02284 (2021). arXiv:2101.02284
https://arxiv.org/abs/2101.02284
[5]Stuart Bennett. 1993. A History of Control Engineering 1930-1955 (1st ed.). Peter
Peregrinus, GBR.
[6]Olivier Chapelle. 2014. Modeling delayed feedback in display advertising. In
KDD. 1097–1105.
[7]Ye Chen, Pavel Berkhin, Bo Anderson, and Nikhil R Devanur. 2011. Real-time
bidding algorithms for performance-based display ad allocation. In Proceedings
of the 17th ACM SIGKDD international conference on Knowledge discovery and
data mining. 1307–1315.
[8]George B Dantzig. 1957. Discrete-variable extremum problems. Operations
research 5, 2 (1957), 266–288.
[9]John Deighton and Leora Kornfeld. 2020. The Socioeconomic Impact of Internet
Tracking. Interactive Advertising Bureau (2020).
[10] Simeon Duckworth, Mateusz Myśliwski, and Lars Nesheim. 2023. Taking the
biscuit: how Safari privacy policies affect online advertising. (2023).
[11] Rui Fan and Erick Delage. 2022. Risk-Aware Bid Optimization for Online
Display Advertisement. In Proceedings of the 31st ACM International Confer-
ence on Information & Knowledge Management, Atlanta, GA, USA, October 17-
21, 2022, Mohammad Al Hasan and Li Xiong (Eds.). ACM, 457–467. https:
//doi.org/10.1145/3511808.3557436
[12] Hui Gao and Yihan Yang. 2022. Multi-Head Online Learning for Delayed Feedback
Modeling. CoRR abs/2205.12406 (2022). https://doi.org/10.48550/arXiv.2205.12406
arXiv:2205.12406
[13] Avi Goldfarb and Catherine E Tucker. 2011. Privacy regulation and online
advertising. Management science 57, 1 (2011), 57–71.
[14] Liyi Guo, Junqi Jin, Haoqi Zhang, Zhenzhe Zheng, Zhiye Yang, Zhizhuang Xing,
Fei Pan, Lvyin Niu, Fan Wu, Haiyang Xu, Chuan Yu, Yuning Jiang, and Xiaoqiang
Zhu. 2021. We Know What You Want: An Advertising Strategy Recommender
System for Online Advertising. In KDD ’21: The 27th ACM SIGKDD Conference
on Knowledge Discovery and Data Mining, Virtual Event, Singapore, August 14-18,
2021, Feida Zhu, Beng Chin Ooi, and Chunyan Miao (Eds.). ACM, 2919–2927.
https://doi.org/10.1145/3447548.3467175
[15] Xiaotian Hao, Zhaoqing Peng, Yi Ma, Guan Wang, Junqi Jin, Jianye Hao, Shan
Chen, Rongquan Bai, Mingzhou Xie, Miao Xu, Zhenzhe Zheng, Chuan Yu, Han
Li, Jian Xu, and Kun Gai. 2020. Dynamic Knapsack Optimization Towards Ef-
ficient Multi-Channel Sequential Advertising. In Proceedings of the 37th Inter-
national Conference on Machine Learning, ICML 2020, 13-18 July 2020, Virtual
Event (Proceedings of Machine Learning Research, Vol. 119). PMLR, 4060–4070.
http://proceedings.mlr.press/v119/hao20b.html
[16] Yue He, Xiujun Chen, Di Wu, Junwei Pan, Qing Tan, Chuan Yu, Jian Xu, and
Xiaoqiang Zhu. 2021. A Unified Solution to Constrained Bidding in Online
Display Advertising. In KDD ’21: The 27th ACM SIGKDD Conference on Knowledge
Discovery and Data Mining, Virtual Event, Singapore, August 14-18, 2021, Feida
Zhu, Beng Chin Ooi, and Chunyan Miao (Eds.). ACM, 2993–3001. https://doi.
org/10.1145/3447548.3467199
[17] ICO. 2019. Update report into adtech and real time bidding. (2019).
[18] Kinshuk Jerath. 2022. Mobile Advertising and the Impact of Apple’s App Tracking
Transparency Policy.
[19] Olivier Jeunen, Sean Murphy, and Ben Allison. 2023. Off-Policy Learning-
to-Bid with AuctionGym. In Proceedings of the 29th ACM SIGKDD Confer-
ence on Knowledge Discovery and Data Mining (Long Beach, CA, USA) (KDD
’23). Association for Computing Machinery, New York, NY, USA, 4219–4228.
https://doi.org/10.1145/3580305.3599877
[20] Reinhold Kesler. 2022. The Impact of Apple’s App Tracking Transparency on
App Monetization. Available at SSRN 4090786 (2022).
[21] Konrad Kollnig, Anastasia Shuba, Max Van Kleek, Reuben Binns, and Nigel
Shadbolt. 2022. Goodbye tracking? Impact of iOS app tracking transparency
and privacy labels. In 2022 ACM Conference on Fairness, Accountability, andTransparency. 508–520.
[22] Kuang-Chih Lee, Ali Jalali, and Ali Dasdan. 2013. Real Time Bid Optimization
with Smooth Budget Delivery in Online Advertising. CoRR abs/1305.3011 (2013).
arXiv:1305.3011 http://arxiv.org/abs/1305.3011
[23] Xu Li, Michelle Ma Zhang, Zhenya Wang, and Youjun Tong. 2022. Arbitrary
Distribution Modeling with Censorship in Real-Time Bidding Advertising. In
KDD ’22: The 28th ACM SIGKDD Conference on Knowledge Discovery and Data
Mining, Washington, DC, USA, August 14 - 18, 2022, Aidong Zhang and Huzefa
Rangwala (Eds.). ACM, 3250–3258. https://doi.org/10.1145/3534678.3539048
[24] Chi-Chun Lin, Kun-Ta Chuang, Wush Chi-Hsuan Wu, and Ming-Syan Chen.
2016. Combining Powers of Two Predictors in Optimizing Real-Time Bidding
Strategy under Constrained Budget. In Proceedings of the 25th ACM International
Conference on Information and Knowledge Management, CIKM 2016, Indianapolis,
IN, USA, October 24-28, 2016, Snehasis Mukhopadhyay, ChengXiang Zhai, Elisa
Bertino, Fabio Crestani, Javed Mostafa, Jie Tang, Luo Si, Xiaofang Zhou, Yi Chang,
Yunyao Li, and Parikshit Sondhi (Eds.). ACM, 2143–2148. https://doi.org/10.1145/
2983323.2983656
[25] Pingzhong Tang, Xun Wang, Zihe Wang, Yadong Xu, and Xiwang Yang. 2020.
Optimized Cost per Mille in Feeds Advertising. In Proceedings of the 19th Interna-
tional Conference on Autonomous Agents and MultiAgent Systems. 1359–1367.
[26] Haozhe Wang, Chao Du, Panyan Fang, Li He, Liang Wang, and Bo Zheng.
2023. Adversarial Constrained Bidding via Minimax Regret Optimization with
Causality-Aware Reinforcement Learning. In Proceedings of the 29th ACM SIGKDD
Conference on Knowledge Discovery and Data Mining, KDD 2023, Long Beach, CA,
USA, August 6-10, 2023, Ambuj K. Singh, Yizhou Sun, Leman Akoglu, Dimitrios
Gunopulos, Xifeng Yan, Ravi Kumar, Fatma Ozcan, and Jieping Ye (Eds.). ACM,
2314–2325. https://doi.org/10.1145/3580305.3599254
[27] Haozhe Wang, Chao Du, Panyan Fang, Shuo Yuan, Xuming He, Liang Wang,
and Bo Zheng. 2022. ROI-Constrained Bidding via Curriculum-Guided Bayesian
Reinforcement Learning. In KDD ’22: The 28th ACM SIGKDD Conference on
Knowledge Discovery and Data Mining, Washington, DC, USA, August 14 - 18,
2022, Aidong Zhang and Huzefa Rangwala (Eds.). ACM, 4021–4031. https:
//doi.org/10.1145/3534678.3539211
[28] Chao Wen, Miao Xu, Zhilin Zhang, Zhenzhe Zheng, Yuhui Wang, Xiangyu Liu, Yu
Rong, Dong Xie, Xiaoyang Tan, Chuan Yu, Jian Xu, Fan Wu, Guihai Chen, and Xi-
aoqiang Zhu. 2021. A Cooperative-Competitive Multi-Agent Framework for Auto-
bidding in Online Advertising. CoRR abs/2106.06224 (2021). arXiv:2106.06224
https://arxiv.org/abs/2106.06224
[29] Xun Yang, Yasong Li, Hao Wang, Di Wu, Qing Tan, Jian Xu, and Kun Gai. 2019.
Bid optimization by multivariable control in display advertising. In Proceedings
of the 25th ACM SIGKDD international conference on knowledge discovery & data
mining. 1966–1974.
[30] Yuya Yoshikawa and Yusaku Imai. 2018. A Nonparametric Delayed Feedback
Model for Conversion Rate Prediction. Proc of Jsai 2018 (2018).
[31] Haoqi Zhang, Lvyin Niu, Zhenzhe Zheng, Zhilin Zhang, Shan Gu, Fan Wu, Chuan
Yu, Jian Xu, Guihai Chen, and Bo Zheng. 2023. A Personalized Automated Bidding
Framework for Fairness-aware Online Advertising. In Proceedings of the 29th
ACM SIGKDD Conference on Knowledge Discovery and Data Mining, KDD 2023,
Long Beach, CA, USA, August 6-10, 2023, Ambuj K. Singh, Yizhou Sun, Leman
Akoglu, Dimitrios Gunopulos, Xifeng Yan, Ravi Kumar, Fatma Ozcan, and Jieping
Ye (Eds.). ACM, 5544–5553. https://doi.org/10.1145/3580305.3599765
[32] Weinan Zhang, Kan Ren, and Jun Wang. 2016. Optimal Real-Time Bidding
Frameworks Discussion. CoRR abs/1602.01007 (2016). arXiv:1602.01007 http:
//arxiv.org/abs/1602.01007
[33] Weinan Zhang, Yifei Rong, Jun Wang, Tianchi Zhu, and Xiaofan Wang. 2016.
Feedback Control of Real-Time Display Advertising. In Proceedings of the Ninth
ACM International Conference on Web Search and Data Mining, San Francisco, CA,
USA, February 22-25, 2016, Paul N. Bennett, Vanja Josifovski, Jennifer Neville, and
Filip Radlinski (Eds.). ACM, 407–416. https://doi.org/10.1145/2835776.2835843
[34] Weinan Zhang, Shuai Yuan, and Jun Wang. 2014. Optimal real-time bidding
for display advertising. In The 20th ACM SIGKDD International Conference on
Knowledge Discovery and Data Mining, KDD ’14, New York, NY, USA - August 24
- 27, 2014, Sofus A. Macskassy, Claudia Perlich, Jure Leskovec, Wei Wang, and
Rayid Ghani (Eds.). ACM, 1077–1086. https://doi.org/10.1145/2623330.2623633
[35] Jun Zhao, Guang Qiu, Ziyu Guan, Wei Zhao, and Xiaofei He. 2018. Deep rein-
forcement learning for sponsored search real-time bidding. In Proceedings of the
24th ACM SIGKDD international conference on knowledge discovery & data mining .
1021–1030.
[36] Kui Zhao, Junhao Hua, Ling Yan, Qi Zhang, Huan Xu, and Cheng Yang. 2019. A
unified framework for marketing budget allocation. In Proceedings of the 25th
ACM SIGKDD International Conference on Knowledge Discovery & Data Mining.
1820–1830.
[37] Han Zhu, Junqi Jin, Chang Tan, Fei Pan, Yifan Zeng, Han Li, and Kun Gai. 2017.
Optimized Cost per Click in Taobao Display Advertising. In Proceedings of the
23rd ACM SIGKDD International Conference on Knowledge Discovery and Data
Mining, Halifax, NS, Canada, August 13 - 17, 2017. ACM, 2191–2200. https:
//doi.org/10.1145/3097983.3098134
5740