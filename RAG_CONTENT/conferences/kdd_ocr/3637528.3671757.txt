Max-Min Diversification with Asymmetric Distances
Iiro Kumpulainen
iiro.kumpulainen@helsinki.fi
University of Helsinki
Helsinki, FinlandFlorian Adriaens
florian.adriaens@helsinki.fi
University of Helsinki, HIIT
Helsinki, FinlandNikolaj Tatti
nikolaj.tatti@helsinki.fi
University of Helsinki, HIIT
Helsinki, Finland
ABSTRACT
One of the most well-known and simplest models for diversity max-
imization is the Max-Min Diversification (MMD) model, which has
been extensively studied in the data mining and database literature.
In this paper, we initiate the study of the Asymmetric Max-Min
Diversification (AMMD) problem. The input is a positive integer 𝑘
and a complete digraph over 𝑛vertices, together with a nonnega-
tive distance function over the edges obeying the directed triangle
inequality. The objective is to select a set of 𝑘vertices, which maxi-
mizes the smallest pairwise distance between them. AMMD reduces
to the well-studied MMD problem in case the distances are sym-
metric, and has natural applications to query result diversification,
web search, and facility location problems. Although the MMD
problem admits a simple1
2-approximation by greedily selecting the
next-furthest point, this strategy fails for AMMD and it remained
unclear how to design good approximation algorithms for AMMD.
We propose a combinatorial1
6𝑘-approximation algorithm for
AMMD by leveraging connections with the Maximum Antichain
problem. We discuss several ways of speeding up the algorithm and
compare its performance against heuristic baselines on real-life and
synthetic datasets.
CCS CONCEPTS
•Theory of computation →Approximation algorithms anal-
ysis; •Mathematics of computing →Graph theory.
KEYWORDS
Max-Min Diversification, Asymmetry, Maximum Antichain
ACM Reference Format:
Iiro Kumpulainen, Florian Adriaens, and Nikolaj Tatti. 2024. Max-Min Di-
versification with Asymmetric Distances. In Proceedings of the 30th ACM
SIGKDD Conference on Knowledge Discovery and Data Mining (KDD ’24),
August 25–29, 2024, Barcelona, Spain. ACM, New York, NY, USA, 11 pages.
https://doi.org/10.1145/3637528.3671757
1 INTRODUCTION
Diversity maximization is a fundamental problem with natural
applications to query result diversification [ 24,26], recommender
systems [ 1,15,35], information exposure in social networks [ 45],
web search [ 8,55,56,66], feature selection [ 67] and data summa-
rization [ 18,20,42,69]. In a typical diverse data selection problem,
one is interested in finding a diverse group of items within the data,
This work is licensed under a Creative Commons Attribution
International 4.0 License.
KDD ’24, August 25–29, 2024, Barcelona, Spain
©2024 Copyright held by the owner/author(s).
ACM ISBN 979-8-4007-0490-1/24/08
https://doi.org/10.1145/3637528.3671757Guam Int.MerceditaA
dak
Pago
PagoDel
Norte County
Figure 1: The result of our algorithm BCF for𝑘=5on the
Flights Delay dataset [51]. It shows 5 airports located in U.S.
territory which require a large flight time between any two
of them, averaged over all flights in 2015. The airports are all
spread out over different U.S. territories (Puerto Rico, Guam,
American Samoa) and/or states (Alaska, California).
meaning that the selected items should be highly dissimilar to each
other. Typically, one is interested in finding sets of fixed and small
sizes.
A simple and popular model for diversity maximization is the
Max-Min Diversification (MMD) model. In this model, the data is
represented as a universe of points 𝑈of size|𝑈|=𝑛, and we are
given a nonnegative distance function 𝑑:𝑈×𝑈→R≥0measuring
the dissimilarity between points. If 𝑑(𝑢,𝑣)is large, then 𝑢and𝑣are
highly dissimilar and vice versa. The space (𝑈,𝑑)is a pseudometric1,
implying that for all 𝑢,𝑣,𝑤∈𝑈:𝑑(𝑢,𝑢)=0,𝑑(𝑢,𝑣)=𝑑(𝑣,𝑢)
(symmetry), and 𝑑(𝑢,𝑣)≤𝑑(𝑢,𝑤)+𝑑(𝑤,𝑣)(triangle inequality).
Thediversity score div(𝑆)of a set of points 𝑆⊆𝑈is then defined as
the smallest distance between any two distinct points in 𝑆. Formally,
div(𝑆)=min
𝑢,𝑣∈𝑆
𝑢≠𝑣𝑑(𝑢,𝑣). (1)
The Max-Min Diversification (MMD) problem asks, given an inte-
ger𝑘, to find a set 𝑆⊆𝑈of size|𝑆|=𝑘which maximizes div(𝑆).
The MMD problem has originally been studied in the operations re-
search literature as the max-min dispersion problem or 𝑘-dispersion
problem [ 27,37,57,61]. The problem naturally describes a facility
location problem where the proximity of selected facilities is unde-
sirable. Facilities that are close to each other might be undesirable
due to economic or safety reasons. Examples include the placement
of store warehouses, nuclear power plants, or ammunition depot
storages.
This paper initiates the study of the asymmetric generalization
of the MMD problem, which will be referred to as the Asymmet-
ric Max-Min Diversification problem (AMMD). AMMD allows for
1Contrary to a metric, a pseudometric allows 𝑑(𝑢,𝑣)=0for distinct𝑢≠𝑣.
 
1440
KDD ’24, August 25–29, 2024, Barcelona, Spain Iiro Kumpulainen, Florian Adriaens, & Nikolaj Tatti
𝑢2
𝑢1
𝑢4𝑢5𝑢3
Figure 2: An input graph to AMMD on which the known1
2-
approximations for symmetric MMD perform poorly. A blue
directed edge(𝑢,𝑣)indicates that the distance 𝑑(𝑢,𝑣)is zero.
All other distances (edges not drawn) are equal to some 𝑅>0.
These distances satisfy the directed triangle inequality. For
𝑘=3the optimal solution is 𝑂={𝑢1,𝑢2,𝑢3}, with optimum
div(𝑂)=𝑅. The greedy algorithm from [ 61] picks an arbitrary
initial node. If 𝑢4or𝑢5are selected we get a solution value of
zero, regardless of how the remaining two nodes are selected.
Similarly, the algorithm of [ 57] initially selects a node pair
with maximum distance. This could be (𝑢4,𝑢5), since ties are
broken arbitrarily, again resulting in a zero-valued solution.
asymmetric distances 𝑑(𝑢,𝑣)≠𝑑(𝑣,𝑢)for𝑢≠𝑣∈𝑈, while retain-
ing all other properties of the MMD model such as the triangle
inequality. A formal problem statement is given by Problem 1.
There are two good reasons for studying AMMD. First, it can
be argued that many real-world similarity measures and distances
are in fact not symmetric. Straightforward examples are one-way
traffic roads, uphill/downhill traveling, one-sided friendships and
asymmetric flight times between airports, among others [ 40,41,58].
Hence, one should consider studying models incorporating this
property.
Secondly, for many optimization problems, the asymmetric gen-
eralization requires different, often more complicated, approxima-
tion algorithms than their symmetric restrictions. Additionally,
they might also be significantly harder to approximate. An exam-
ple is the Ω(log∗𝑛)-hardness result [ 22] for asymmetric 𝑘-center,2
and the corresponding O(log∗𝑛)-approximation algorithms [ 6,53].
Another example is the asymmetric traveling salesman problem,
for which only recently a constant-factor approximation has been
discovered [60].
Designing approximation algorithms for AMMD is seemingly
also more challenging than for MMD. While MMD admits a greedy
1
2-approximation by iteratively selecting the next-furthest point
until a set of size 𝑘is obtained [ 57,61], this greedy strategy can
perform arbitrarily bad on asymmetric instances. Figure 2 shows
such an example.
Results and techniques. Throughout the paper we let 𝜔<2.373
be the matrix multiplication exponent. We refer to [ 5] for the cur-
rent best bound.
Our main result is the following theorem.
Theorem 1. Our algorithms BAC ,BCR andBCF from Section 5.3
approximate AMMD within a factor of1
6𝑘. Their worst-case time
complexity is respectively O(𝑛2+𝜔log𝑘),O(𝑛2+𝜔log𝑘log𝑛)and
O(𝑛𝜔log𝑘log𝑛).
2The iterated logarithm log∗𝑛is defined as the number of times the logfunction can
be iteratively applied to 𝑛until the result is less than or equal to 1.To the best of our knowledge, these are the first approxima-
tion algorithms for AMMD with a non-trivial guarantee. BAC is
the vanilla algorithm. BCR is a refined variant looking to improve
solution quality, while BCF is a faster variant.
We also show that our practical implementation run fast on real-
world and synthetic data and produces solutions with high diversity
scores (see Section 6). Figure 1 shows the output of BCF for𝑘=5on
a real-world dataset consisting of U.S. domestic flight data by large
air carriers in 2015 [ 51]. Between the five airports, the shortest
average flight time is from Adak Airport to Del Norte Country
Airport. Flying from Mercedita Airport to Guam Int. Airport on
average took 10% longer than flying in the reverse direction. This
is the largest ratio of bidirectional flying times among all routes
between the five airports.
The high-level idea behind our algorithm is to create auxiliary
graphs based on the distances in the AMMD instance. In these
auxiliary graphs, an independent set of size 𝑘will lead to good
solutions. In order to efficiently extract the independent sets, we
need to equip the auxiliary graphs with certain properties. We
show that by first clustering the points in the AMMD instance, the
graphs must contain a subgraph of a certain type (antichain, a large
chordless cycle, or a long shortest path with no backward edges).
We can search for all 3 subgraphs in polynomial time, and we can
extract an independent set from them in polynomial time.
Roadmap. Section 2 discusses related work on diversity maximiza-
tion and the MMD problem in particular. Section 3 provides a formal
problem statement and the necessary background literature on max-
imum antichains. Section 4 briefly discusses the performance of
the greedy algorithm on instances that are nearly symmetric. Sec-
tion 5 details our algorithms for AMMD. We present experimental
evaluation in Section 6 and conclude the paper with remarks in
Section 7.
2 RELATED WORK
MMD. The MMD problem was shown to be NP-complete by Wang
and Kuo [62]. Both Tamir [61] and Ravi et al . [57] showed that the
greedy next-furthest point algorithms yield a1
2-approximation for
MMD. Moumoulidou et al . [47] noted that these greedy algorithms
are essentially identical to the well-known Gonzalez-heuristic [ 31]
which gives a 2-approximation for the 𝑘-center problem. By a re-
duction from max. clique, Ravi et al . [57] showed that for any 𝜖>0
MMD is NP-hard to approximate within a factor of1
2+𝜖, thereby
showing the optimality of the Gonzalez-heuristic in terms of worst-
case performance. Ravi et al . [57] also showed that MMD without
the triangle inequality constraints is NP-hard to approximate within
any multiplicative factor.
Akagi et al . [4] showed that MMD can be solved exactly by
solvingO(log𝑛)𝑘-clique problems, resulting in an exact algorithm
inO(𝑛𝜔𝑘/3log𝑛)time by using the 𝑘-clique algorithm from [49].
Fairness and matroid constraints. Fairness variants of the MMD
problem have recently gained a lot of research attention [ 2,18,
48,63–65]. A typical fair MMD problem statement assumes the
universe is partitioned into |𝐶|disjoint groups. Solutions are now
required to contain a certain amount of points from each group.
It is still undetermined whether constant-factor approximation
algorithms exist for arbitrary |𝐶|[2,65]. The fairness constraints are
 
1441Max-Min Diversification with Asymmetric Distances KDD ’24, August 25–29, 2024, Barcelona, Spain
a special case of diversity maximization under matroid constraints
[1, 12, 16, 17, 19].
Other objective functions. Chandra and Halldórsson [20] consid-
ered a range of diversity problems with different objective functions
besides MMD. Among them is the popular Max-Sum Diversifica-
tion (MSD) problem, which aims to maximize the sum of pairwise
distances instead of the minimum [ 1,3,7,8,11,32,34,37]. Cevallos
et al. [19] provided a local search (1−O( 1/𝑘))-approximation for
MSD for distances of negative type (which includes several non-
metric distances), subject to general matroid constraints. Zhang and
Gionis [68] consider a variant of MSD adapted to a clustered data
setting. Besides MSD there are numerous other objective functions
for diversity maximization, depending on the topic area. We refer
to [69] for a summary of results in query result diversification.
Nonetheless, all of these works consider symmetric distances
between points. We also note that the asymmetric generalization
of the MSD problem is trivially approximated by considering the
symmetric distance 𝑑′formed by𝑑′(𝑢,𝑣)=𝑑(𝑢,𝑣)+𝑑(𝑣,𝑢)and
applying any MSD approximation algorithm on 𝑑′. This strategy
does not lead to a guarantee for AMMD, as the distance in one
direction might be very small compared to the other direction.
3 NOTATION AND PRELIMINARIES
Graphs. Given a directed graph (digraph) 𝐺=(𝑉,𝐴), vertex𝑣
is reachable from vertex 𝑢if there exists a path from 𝑢to𝑣in𝐺.
Otherwise, 𝑣is called unreachable from 𝑢. The transitive closure
TC(𝐺)of a digraph 𝐺is a digraph with the same nodes as 𝐺, and
with edges(𝑢,𝑣)∈TC(𝐺)if𝑣is reachable from 𝑢in𝐺. We say a
digraph𝐺is transitively closed if 𝐺=TC(𝐺). A set𝑋⊆𝑉is called
independent if there are no edges in the induced subgraph 𝐺[𝑋].
An edge(𝑖,𝑗)∈𝐴is often abbreviated as 𝑖𝑗.
AMMD problem. As mentioned in the introduction, we will as-
sume a pseudometric space (𝑈,𝑑)without symmetry constraints
on the distance function 𝑑, thus satisfying 𝑑(𝑢,𝑢)=0, nonneg-
ativity𝑑(𝑢,𝑣)≥0and the directed triangle inequality 𝑑(𝑢,𝑣)≤
𝑑(𝑢,𝑤)+𝑑(𝑤,𝑣)for all𝑢,𝑣,𝑤∈𝑈. Instances of AMMD can be
viewed as complete digraphs or distance matrices representing the
distances between each pair of points. An example of an AMMD
instance space is the metric closure of a nonnegatively weighted
digraph, formed by defining distances as weighted shortest path
lengths between all the pairs of nodes in the graph.
We are interested in the following problem.
Problem 1 (AMMD). Given(𝑈,𝑑)and integer𝑘, find a set𝑂⊆𝑈
with|𝑂|=𝑘such that div(𝑂), as defined in Eq. 1, is maximized.
Throughout the paper, we let 𝑅∗=div(𝑂)be the optimal value
for an AMMD instance space (𝑈,𝑑)with parameter 𝑘, where𝑂is a
corresponding optimal set of 𝑘points. We assume 𝑅∗>0, as when
𝑅∗=0any set of𝑘points would be an optimal solution.
With𝑑we define two new functions 𝑑minand𝑑maxas𝑑min(𝑢,𝑣)=
min{𝑑(𝑢,𝑣),𝑑(𝑣,𝑢)}and𝑑max(𝑢,𝑣)=max{𝑑(𝑢,𝑣),𝑑(𝑣,𝑢)}for all
𝑢,𝑣∈𝑈. Both functions are clearly symmetric, and 𝑑maxsatisfies
the triangle inequality while 𝑑mindoes not. Finally, using the 𝑑min
and𝑑maxfunctions we quantify the asymmetry of a given pseudo-
metric space. A pseudometric space (𝑈,𝑑)is called𝜖-symmetric for
some𝜖≥0if for all𝑢,𝑣∈𝑈:(1+𝜖)𝑑min(𝑢,𝑣)≥𝑑max(𝑢,𝑣).Maximum antichains. We will see that there is a connection
between AMMD and the maximum independent set (MIS) problem.
Unfortunately, finding a MIS is not feasible. Instead, we will look for
a maximum antichain (MA). An antichain of a digraph 𝐺=(𝑉,𝐸)is
a set of vertices that are pairwise unreachable in 𝐺. In other words,
an antichain is an independent set in TC(𝐺), and therefore also in
𝐺. We have the following problem.
Problem 2 (MA). Given a digraph 𝐺and integer 𝑘, find an an-
tichain of size 𝑘or decide no such set exists.
Unlike finding a MIS, MA can be solved in polynomial time. A
common approach is to reduce the problem into a minimum flow
(with edge demands) problem [ 14,44,50,54]. Such reduction has
2|𝑉|+2vertices and 3|𝑉|+|𝐸|edges. The minimum flow problem
is then solved by reducing it to a maximum flow problem, we refer
to [14] for the explicit construction.
This reduction has been combined with the recent breakthrough
paper on maximum flows by Chen et al . [21] to obtain the following
result.
Proposition 1 (Corollary 2.1 [ 13]).Given a digraph 𝐺=(𝑉,𝐸)
with|𝑉|=𝑛and|𝐸|=𝑚, a maximum antichain of 𝐺can be com-
puted inO(𝑚1+𝑜(1)log𝑛)time with high probability.
There is a subtle complication in using the solver by Chen et al .
[21]. The algorithm solves the maximum flow problem with high
probability, that is, there is a small 𝑜(1)chance of failure.3The
issue is that in certain cases we need to solve MA several times,
say𝑠times, and allof them need to succeed. Here, the asymptotic
probability of failure depends on how quickly the failure rate goes
to 0 for a single MA as the instance size grows. However, if we
make the failure rate of a single instance 𝑜(𝑠−1), then the union
bound immediately shows that the probability of a single failure in
𝑠instances is then in 𝑜(1). The standard technique for guaranteeing
an𝑜(𝑠−1)failure bound is to run the solver O(log𝑠)times and select
the best result. To summarize, we have the following proposition.
Proposition 2. Given𝑠digraphs𝐺𝑖=(𝑉𝑖,𝐸𝑖)with|𝑉𝑖|≤𝑛and
|𝐸𝑖|≤𝑚, computing 𝑠maximum antichains of each 𝐺𝑖can be done
inO(𝑠𝑚1+𝑜(1)log𝑛log𝑠)time with high probability.
We should point out that in practice we do not use the solver
by Chen et al . [21] due to its high complexity and high constants.
Instead, we settle for a more practical algorithm by Goldberg [30]
that solves maximum flow instances in O(𝑛2√𝑚)time.
We conclude this section by discussing alternative techniques
for solving maximum antichains. The first approach requires the
computation of the transitive closure of the digraph. The idea is to
reduce the MA problem to finding a maximum cardinality matching
in a bipartite graph encoding the reachability relation between ver-
tices [ 25,28,29]. The downside of this approach is that computing
the transitive closure is expensive.
Moreover, there is a large body of work on width-parametrized4
algorithms for the MA problems [ 13,14,23,28,36,43]. These al-
gorithms are practical in a small-width regime [ 14]. However, we
opted to use the maximum flow approach as this was sufficiently
fast for us, while also being the asymptotically fastest algorithm.
3By definition, this probability goes to 0 as the instance size grows.
4The size of the maximum antichain is often called the width of the graph.
 
1442KDD ’24, August 25–29, 2024, Barcelona, Spain Iiro Kumpulainen, Florian Adriaens, & Nikolaj Tatti
Algorithm 1 Greedy with 𝑑min-distances.
Input: space(𝑈,𝑑)and integer parameter 𝑘≥2.
1:𝑣←arbitrary vertex from 𝑈.
2:𝑆←{𝑣}.
3:while|𝑆|<𝑘do
4:𝑣←argmax𝑢∈𝑈𝑑min(𝑢,𝑆).
5:𝑆←𝑆∪{𝑣}.
Output: the set𝑆.
Algorithm 2 Naive Maximum Antichain method.
Input: space(𝑈,𝑑)and integer parameter 𝑘≥2.
1:for all𝑅∈{𝑑(𝑖,𝑗)>0|𝑖,𝑗∈𝑈,𝑖≠𝑗}do
2: Create𝐺𝑅=(𝑈,𝐴), with𝑖𝑗∈𝐴⇔𝑑(𝑖,𝑗)<𝑅
𝑛−𝑘+1.
3:𝑀←Maximum antichain of 𝐺𝑅.
4: if|𝑀|≥𝑘,then𝑆𝑅←any𝑘points from 𝑀.
Output: the set𝑆𝑅with the largest div(𝑆𝑅)value.
4 NEARLY SYMMETRIC INSTANCES
Greedily selecting the next-furthest points until 𝑘points are se-
lected is a1
2-approximation for symmetric MMD [ 57,61], but can
perform arbitrarily badly on asymmetric instances as shown by the
example in Figure 2.
Theorem 2 generalizes this result to asymmetric instances. It
states that on asymmetric instances that are 𝜖-symmetric (see Sec-
tion 3), the greedy approach applied on the 𝑑mindistances yields a
1
2+𝜖-approximation, and this ratio is tight. The proof of Theorem 2
can be found in the Appendix.
Theorem 2. For any𝜖≥0, Algorithm 1 is a1
2+𝜖-approximation on
𝜖-symmetric instances and can be implemented to run in O(𝑘𝑛)time.
Additionally, there exist 𝜖-symmetric instances for which Algorithm 1
cannot achieve a performance ratio better than1
2+𝜖.
5 BALL-AND-ANTICHAIN METHOD
Section 5.1 details a straightforward approximation algorithm for
AMMD, exploiting the polynomial time complexity of the MA prob-
lem in digraphs, as discussed in the previous section. This algorithm
has an approximation guarantee of1
𝑛−𝑘+1, which is not very useful
in a typical regime of small 𝑘, but it gives insight into the use of
the MA problem for approximating AMMD.
In Section 5.2 we modify the algorithm from Section 5.1 by first
clustering the points based on the 𝑑maxdistances between them.
The subspace induced by the cluster centers has some very use-
ful properties, which leads to an approximation algorithm with a
multiplicative guarantee of1
6𝑘for AMMD.
Finally, in Section 5.3, we discuss improvements to look for
better solutions and speed up the algorithm while maintaining the
approximation guarantee.
5.1 Naive approach based on antichains
We begin by describing the naive approach for approximating
AMMD. Assume for the moment that we know 𝑅=𝑅∗, the op-
timal value for an AMMD instance. Consider a digraph 𝐺=(𝑈,𝐴),
where𝑖𝑗∈𝐴if and only if 𝑑(𝑖,𝑗)<𝑅. Then an independent set,say𝑂, in𝐺of size𝑘will have div(𝑂)=𝑅∗. Unfortunately, finding
a maximum independent set in a graph is an NP-hard problem with
a weak approximation guarantee [33].
Therefore, we lower the cutoff by setting it to𝑅
𝑛−𝑘+1. This makes
the underlying graph so sparse that we can guarantee that the
graph contains an antichain, say 𝑆, of size𝑘. Since an antichain is
also an independent set, we know that div(𝑆)≥𝑅
𝑛−𝑘+1. We can
find the antichain in polynomial time. Finally, we do not know
𝑅∗but we know that it is one of the distances. Therefore, we test
every distance; there are at most 𝑛(𝑛−1)of such distances. The
pseudo-code for the algorithm is given in Algorithm 2.
Theorem 3. Algorithm 2 is an1
𝑛−𝑘+1-approximation for AMMD
inO(𝑛4+𝑜(1)log𝑛)time with high probability.
The proof is given in Appendix.
We finalize this section by observing that we could binary search
for the largest 𝑅value for which 𝐺𝑅(defined in line 2 in Algorithm 2)
still has an antichain of size 𝑘. First, sort the unique distances in
timeO(𝑛2log𝑛), after which we need at most O(log𝑛)calls to
find this𝑅. Since for this 𝑅we have𝑅≥𝑅∗, we retain the same
approximation guarantee. The binary search performs O(log𝑛)MA
computations, and all of them need to succeed. Proposition 2 implies
that the algorithm solves the problem in O(𝑛2+𝑜(1)log2𝑛log log𝑛)
time with high probability.
5.2 Refined approach: clustering and antichains
The problem with Algorithm 2 is that it is using a very conservative
cutoff of𝑅
𝑛−𝑘+1, leading to a weak guarantee. We show that we can
relax this cutoff to𝑅
6𝑘, by first clustering the space (𝑈,𝑑)according
to the𝑑maxdistances. The discovered cluster centers will have the
property that two centers must have a large 𝑑maxdistance between
them. A consequence of this property is that the resulting graph
contains a large antichain, a large chordless cycle, or a large shortest
path with no backward edges. It turns out that we can search for
all 3 subgraphs in polynomial time, and using those we can extract
an independent set in polynomial time.
Clustering step. Next, we describe the clustering step, as given in
Algorithm 3. Here the algorithm greedily covers 𝑈with a family of
pairwise disjoint sets {𝐴𝑡}. Each𝐴𝑡is constructed by selecting an
unmarked point as a center 𝑐𝑡, and adding all unmarked points 𝑣
with𝑑max(𝑐𝑡,𝑣)<𝑅. Since all the vertices in 𝐴𝑡are marked at the
end of step𝑡(line 5), they cannot be selected by any 𝐴𝑡′for𝑡′>𝑡.
It follows that for every 𝑡≠𝑡′we have𝐴𝑡∩𝐴𝑡′=∅.
Algorithm 3 terminates in at most 𝑛steps, since every set 𝐴𝑡
contains at least one point, namely the center point 𝑐𝑡. Algorithm 3
runs inO(𝑛2)time.
Each𝐴𝑡is constructed by selecting vertices that have a small
𝑑maxdistance to their center 𝑐𝑡. Line 4 in Algorithm 3 ensures that
the𝑑maxdistances between two distinct centers are at least 𝑅.
To analyze this further, let us define 𝑅′as the smallest distance
that is at least one third of the optimum 𝑅∗,
𝑅′=min{𝑑(𝑢,𝑣)|𝑑(𝑢,𝑣)≥𝑅∗/3, 𝑢,𝑣∈𝑈, 𝑢≠𝑣}. (2)
If we then perform the clustering for any 𝑅≤𝑅′, there will be
𝑘centers that also have a pairwise 𝑑mindistance of at least 𝑅∗/3
between them. This is captured by Proposition 3 and Corollary 1.
 
1443Max-Min Diversification with Asymmetric Distances KDD ’24, August 25–29, 2024, Barcelona, Spain
Algorithm 3 Clust(𝑈,𝑑,𝑅), clusters𝑈according to 𝑑max.
Input: space(𝑈,𝑑)and parameter 𝑅>0.
1:Label all𝑢∈𝑈as unmarked, let 𝑈′←∅ and𝑡←1.
2:while there exists an unmarked point do
3:𝑐𝑡←any unmarked point.
4:𝐴𝑡←{unmarked𝑣∈𝑈|𝑑max(𝑐𝑡,𝑣)<𝑅}.
5: Mark all𝑣∈𝐴𝑡.
6:𝑈′←𝑈′∪{𝑐𝑡}and𝑡←𝑡+1.
Output:𝑈′.
Proposition 3. Let𝑂be an optimal solution to AMMD with
optimum𝑅∗and𝑅′as defined in Equation 2. If 𝑅≤𝑅′, then the
following two statements regarding Algorithm 3 are true.
•For all𝑡it holds that|𝐴𝑡∩𝑂|≤1.
•For any𝑡≠𝑡′for which|𝐴𝑡∩𝑂|=1and|𝐴𝑡′∩𝑂|=1, it
holds that𝑑min(𝑐𝑡,𝑐𝑡′)≥𝑅′≥𝑅∗/3.
Proof. For the first statement, suppose that 𝐴𝑡contains two
distinct𝑥,𝑦∈𝑂,𝑥≠𝑦. Then it holds that 𝑑(𝑥,𝑦) ≤𝑑(𝑥,𝑐𝑡)+
𝑑(𝑐𝑡,𝑦). Since𝑑(𝑥,𝑐𝑡)and𝑑(𝑐𝑡,𝑦)are strictly less than 𝑅≤𝑅′,
they must be less than 𝑅∗/3because𝑅′is defined as the smallest
distance greater or equal to 𝑅∗/3, so any distance strictly smaller
than𝑅′must be less than 𝑅∗/3. Thus,𝑑(𝑥,𝑦)<2𝑅∗/3<𝑅∗, a
contradiction since 𝑥,𝑦∈𝑂,𝑥≠𝑦implies that 𝑑(𝑥,𝑦)≥𝑅∗.
For the second statement, assume that 𝐴𝑡contains𝑥∈𝑂and𝐴𝑡′
contains𝑦∈𝑂. Since𝐴𝑡and𝐴𝑡′are disjoint, we have 𝑥≠𝑦. Note
that𝑑(𝑥,𝑦)≤𝑑(𝑥,𝑐𝑡)+𝑑(𝑐𝑡,𝑐𝑡′)+𝑑(𝑐𝑡′,𝑦), where𝑑(𝑥,𝑐𝑡)<𝑅≤𝑅′
and𝑑(𝑐𝑡′,𝑦)<𝑅≤𝑅′. This means 𝑑(𝑥,𝑐𝑡)and𝑑(𝑐𝑡′,𝑦)must be
less than𝑅∗/3by the definition of 𝑅′. So if𝑑(𝑐𝑡,𝑐𝑡′)<𝑅′, we
would have 𝑑(𝑥,𝑦)<3𝑅∗/3=𝑅∗, a contradiction. Similarly, we
cannot have 𝑑(𝑐𝑡′,𝑐𝑡)<𝑅′either, which means 𝑑min(𝑐𝑡,𝑐𝑡′) ≥
𝑅′≥𝑅∗/3. □
Corollary 1. Let𝑈′=Clust(𝑈,𝑑,𝑅). For every𝑢,𝑣∈𝑈′,𝑢≠𝑣
we have𝑑max(𝑢,𝑣)≥𝑅. Additionally, if 𝑅≤𝑅′, then𝑈′contains a
set𝑆, for which|𝑆|=𝑘and div(𝑆)≥𝑅′≥𝑅∗/3.
Corollary 1 states that as long as 𝑅≤𝑅′, from any instance
space(𝑈,𝑑)we can efficiently find a subset 𝑈′⊆𝑈such that𝑈′
still contains 𝑘points with a pairwise 𝑑mindistance of at least 𝑅∗/3
between them. This enables us to restrict ourselves to 𝑈′, at the
expense of a decrease in the optimal value by a factor of three.
TheBAC algorithm. We are ready to describe our algorithm which
we call BAC (shortened for ball-and-antichain). The pseudocode is
given in Algorithms 4–5. Similar to the naive approach we iterate
over all distances. For each candidate distance 𝑅, we cluster the
space to get the centers 𝑈′. We then construct a graph 𝐺with edges
corresponding to distances shorter than𝑅
2𝑘. We can guarantee that
there is (𝑖) a large chordless cycle, ( 𝑖𝑖) a long shortest path with
no backward edges, or ( 𝑖𝑖𝑖) a large antichain. In the first two cases,
we can obtain an independent set by selecting 𝑘vertices with odd
indices. In the last case, it is enough to select 𝑘vertices from the
found antichain.
Next, we will prove the approximation guarantee. First, we need
Lemma 1, which states that there cannot exist small cycles in 𝐺.Algorithm 4 BAC(𝑈,𝑑,𝑘), an1
6𝑘-approx. algorithm for AMMD.
Input: space(𝑈,𝑑)and integer parameter 𝑘≥2.
1:for all𝑅∈{𝑑(𝑖,𝑗)>0|𝑖,𝑗∈𝑈,𝑖≠𝑗}do
2:𝑈′←Clust(𝑈,𝑑,𝑅).
3: Extract(𝑈′,𝑑,𝑅/(2𝑘),𝑘).
Output: the set returned by Extract with the largest divvalue.
Algorithm 5 Extract(𝑈,𝑑,𝜎,𝑘), subroutine for extracting a can-
didate set.
Input: space(𝑈,𝑑), threshold𝜎, and integer parameter 𝑘≥2.
1:Create𝐺=(𝑈,𝐴), with𝑖𝑗∈𝐴⇔𝑑(𝑖,𝑗)<𝜎.
2:if𝐺contains a cycle then
3:𝐶←chordless cycle in 𝐺.
4:𝐺𝑐←the condensation of 𝐺.
5:𝑀←maximum antichain of 𝐺𝑐.
6:𝐿←shortest path of length 2𝑘−1in𝐺𝑐or longest found.
7:if𝐶exists and|𝐶|≥2|𝑀|−1and|𝐶|≥|𝐿|then
8:𝐼←points with odd indices from 𝐶.
9:else if 2|𝑀|−1≥|𝐿|then
10:𝐼←points in𝐺corresponding to points in 𝑀.
11:else
12:𝐼←points in𝐺corr. to points with odd indices in 𝐿.
Output: greedily selected 𝑘points from the set 𝐼, if found.
Lemma 1. For any𝑅>0, any cycle𝐶in the digraph 𝐺constructed
inExtract
𝑈′,𝑑,𝑅
2𝑘,𝑘
(see Alg. 5) has at least 2𝑘+2distinct vertices.
Proof. Suppose𝐺contains a cycle 𝐶=(𝑣1,...,𝑣ℓ,𝑣1)of length
ℓ. Since𝐶is a cycle in𝐺, it holds that 𝑑(𝑣ℓ,𝑣1)<𝑅
2𝑘, by definition of
𝐺. On the other hand, as 𝑈′is the output of Clust , Corollary 1 states
that𝑑max(𝑣1,𝑣ℓ) ≥𝑅. This implies that 𝑑(𝑣1,𝑣ℓ) ≥𝑅. Now the
triangle inequality for 𝑑(𝑣1,𝑣ℓ)along the edges of cycle 𝐶implies
𝑅≤𝑑(𝑣1,𝑣ℓ)≤ℓ−1∑︁
𝑖=1𝑑(𝑣𝑖,𝑣𝑖+1)<(ℓ−1)𝑅
2𝑘.
Solving forℓleads toℓ>2𝑘+1, which proves the claim. □
Theorem 4. BAC(𝑈,𝑑,𝑘)is an1
6𝑘-approximation to AMMD.
Proof. Line 1 in Algorithm 4 iterates over all unique distances,
and one of them is equal to 𝑅′as defined in Eq. 2. We will show that
for𝑅≤𝑅′, the digraph 𝐺, constructed in line 1 in Algorithm 5, has
an antichain 𝑀of size|𝑀|≥𝑘, or there exists either a shortest path
with no backward edges or a chordless cycle from which we can
select𝑘independent vertices. An independent set 𝐼of size|𝐼|≥𝑘in
graph𝐺then yields a solution with a diversity score of div(𝐼)≥𝑅
2𝑘,
which for𝑅=𝑅′isdiv(𝐼)≥𝑅′
2𝑘≥𝑅∗
6𝑘proving the theorem.
Note that since the nodes in an antichain have no paths connect-
ing them, it suffices to look for an antichain in the condensation
𝐺𝑐, whose vertices are the strongly connected components of 𝐺.
If there exists an antichain 𝑀of size|𝑀|≥𝑘, we are done as the
nodes in an antichain are independent.
 
1444KDD ’24, August 25–29, 2024, Barcelona, Spain Iiro Kumpulainen, Florian Adriaens, & Nikolaj Tatti
Consider the case where the maximum antichain 𝑀has size
|𝑀|<𝑘and assume 𝐺is a DAG. Note that when 𝐺is a DAG the
condensation 𝐺𝑐is equivalent to 𝐺.
Corollary 1 states that if 𝑅≤𝑅′then𝑈′contains a subset 𝑆⊆𝑈′
for which|𝑆|=𝑘and div(𝑆)≥𝑅′. Then there must be a path in
𝐺between some pair of distinct points in 𝑆. Otherwise, 𝑆is an
antichain of size 𝑘.
Let this pair of nodes be 𝑥,𝑦∈𝑆,𝑥≠𝑦, with a path(𝑥=
𝑣1,...,𝑣ℓ=𝑦)from𝑥to𝑦in𝐺. Then the triangle inequality implies
𝑅′≤div(𝑆)≤𝑑(𝑥,𝑦)≤ℓ−1∑︁
𝑖=1𝑑(𝑣𝑖,𝑣𝑖+1)<(ℓ−1)𝑅
2𝑘≤(ℓ−1)𝑅′
2𝑘.
Therefore,ℓmust be at least 2𝑘+2meaning any path between 𝑥
and𝑦must have at least 2𝑘+2vertices. Hence, there is a shortest
path of length 2𝑘+2while a shortest path 𝐿of length 2𝑘−1is
sufficient. There cannot be any shortcut edges in 𝐿, since𝐿is a
shortest path. Nor can there be any backward edges in 𝐿, since𝐺
is a DAG. Consequently, elements in 𝐿with odd indices form an
independent set 𝐼of size𝑘.
Finally, assume that 𝐺is not a DAG. Then there is a chordless
cycle𝐶. Lemma 1 guarantees that 𝐶has at least 2𝑘+2elements.
Then, elements in 𝐶with odd indices form an independent set 𝐼of
size|𝐼|≥𝑘+1>𝑘. □
Time complexity of Algorithm 4. The iteration in line 1 is over
at mostO(𝑛2)possible𝑅values. Both detecting a cycle in 𝐺and
extracting the chordless cycle from it (line 3 of Algorithm 5) take
O(𝑛2)time. Computing the maximum antichain can be done in
O(𝑛2+𝑜(1)log𝑛)time (Proposition 1).
To compute the shortest path we can use the following approach:
Let𝐷=𝐴+𝐼, where𝐴is the adjacency matrix of 𝐺, and𝐼is the
identity matrix. Then 𝐷ℓ
𝑖𝑗>0if and only if there is a path of at
most length ℓfrom𝑖to𝑗. Consequently, there is a shortest path
from𝑖to𝑗of length 2𝑘−1if and only if 𝐷2𝑘−1
𝑖𝑗>0and𝐷2𝑘−2
𝑖𝑗=0.
We can compute the necessary matrices in O(𝑛𝜔log𝑘)time, where
𝜔<2.373is the matrix multiplication exponent [ 5]. Once𝑖is found,
we use Dijkstra’s algorithm to recover the path in O(𝑛2)time.
Overall we have a worst-case time complexity of O(𝑛2+𝜔log𝑘).
Note that in practice, we do not use the matrix multiplication
method. Instead, we compute a shortest path tree from every node.
This leads to a slower theoretical time but the algorithms are still
practical as demonstrated in the experiments.
5.3 Practical improvements
We discuss several modifications, which speed up BAC , and/or
might improve the solution quality in practice.
Algorithm BCR .The first modification to BAC , given in Algo-
rithm 6, is aimed at improving solution quality, at the expense of a
slightly larger running time. We will call this modified algorithm
BCR. Note that the1
6𝑘-approximation guarantee comes from the
fact that we add an edge 𝑖𝑗to𝐺whenever𝑑(𝑖,𝑗)<𝑅
2𝑘. If we can
increase this cutoff to, say 𝑅×𝛼,andstill find a feasible set, then
the found set 𝑆is guaranteed to have div(𝑆)≥𝑅𝛼, that is we will
obtain an𝛼-approximation.
For every𝑅in the iteration of BCR that gives a feasible solution
for the threshold𝑅
2𝑘, we will try to improve the solution value byAlgorithm 6 BCR(𝑈,𝑑,𝑘), an1
6𝑘-approx. algorithm for AMMD.
Input: space(𝑈,𝑑)and integer parameter 𝑘≥2.
1:𝑅1<...<𝑅𝑚←all unique positive distances sorted.
2:forevery𝑖=1,...,𝑚 do
3:𝑈′←Clust(𝑈,𝑑,𝑅𝑖).
4: ifExtract(𝑈′,𝑑,𝑅𝑖/(2𝑘),𝑘)exists then
5:𝑎←min{𝑠|𝑅𝑖/(2𝑘)<𝑅𝑠},𝑏←𝑖.
6: while𝑎≤𝑏do
7: 𝑡←j
𝑎+𝑏
2k
.
8: ifExtract(𝑈′,𝑑,𝑅𝑡,𝑘)exists then𝑎←𝑡+1
9: else𝑏←𝑡−1
Output: the set returned by Extract with the largest divvalue.
Algorithm 7 BCF(𝑈,𝑑,𝑘), an1
6𝑘-approx. algorithm for AMMD.
Input: space(𝑈,𝑑)and integer parameter 𝑘≥2.
1:𝑅1<...<𝑅𝑚←all unique positive distances sorted.
2:𝑎←1,𝑏←𝑚
3:while𝑎≤𝑏do
4:𝑡←j
𝑎+𝑏
2k
.
5:𝑈′←Clust(𝑈,𝑑,𝑅𝑡).
6: ifExtract(𝑈′,𝑑,𝑅𝑡/(2𝑘),𝑘)exists then𝑎←𝑡+1
7: else𝑏←𝑡−1
8:𝑖←𝑎−1.
9:𝑈′←Clust(𝑈,𝑑,𝑅𝑖).
10:𝑎←min{𝑠|𝑅𝑖/(2𝑘)<𝑅𝑠},𝑏←𝑖.
11:while𝑎≤𝑏do
12:𝑡←j
𝑎+𝑏
2k
.
13: ifExtract(𝑈′,𝑑,𝑅𝑡,𝑘)exists then𝑎←𝑡+1
14: else𝑏←𝑡−1
Output: the set returned by Extract with the largest divvalue.
searching for a cutoff value larger than𝑅
2𝑘when constructing the
graph𝐺(line 1 of Algorithm 5). If BCR is unable to find a feasible
solution for a certain 𝑅, then we continue iterating to the next 𝑅.
To this end, if BCR has found a feasible set for some 𝑅, we use the
binary search to search for larger cutoffs in [𝑅
2𝑘,𝑅]. Note that only
when we use the cutoff𝑅
6𝑘are we theoretically guaranteed that we
can extract 𝑘independent points. Nonetheless, BCR will attempt
to do this for larger cutoffs as well. The binary search requires
O(log𝑛)tests for a single 𝑅since we can assume that the cutoff is
one of the distances. Hence, the computational complexity of BCR
is inO(𝑛2+𝜔log𝑘log𝑛).
Algorithm BCF.This algorithm speeds up BAC while at the same
time attempting to improve solution quality. Similarly to Section 5.1,
we can replace the loop of Algorithm 4 (line 1) with a binary search
in an attempt to find a maximal 𝑅for which we find a feasible
solution. This reduces the iterations from O(𝑛2)toO(log𝑛).
Note that unlike in Section 5.1, this binary search might not find
the globally largest 𝑅value for which we can extract a feasible
solution. This is because there may be distance values 𝑅𝑖>𝑅𝑗>𝑅′
such that𝑅𝑖yields a feasible solution while 𝑅𝑗does not.
 
1445Max-Min Diversification with Asymmetric Distances KDD ’24, August 25–29, 2024, Barcelona, Spain
Table 1: Characteristics of the datasets: size, smallest and
largest distances, and number of unique distances. The total
number of pairwise distances is |𝑈|(|𝑈|−1).
Data type |𝑈|min𝑑 max𝑑 dists
ft70[58] infra 70 331 2 588 1 441
kro124 [58] infra 100 81 4 309 3 297
celegans [40] bio 297 1 24 24
rbg323 [58] infra 323 0 21 23
wiki-vote [41] social 1 300 1 9 9
US airports [40, 52] flight 1 402 1 169 685 27 237
moreno [40, 46] social 2 155 1 52 52
openflights [40, 52] flight 2 868 1 17 17
cora [40, 59] citation 3 991 1 45 45
bitcoin [38, 39] trust 4 709 0 134 130
gnutella [41] P2P 5 153 1 21 21
However, we can still sort the unique distances and use binary
search to find 𝑅𝑗with a feasible solution, say 𝑆𝑗, such that the next
value𝑅𝑗+1>𝑅𝑗does not yield a feasible solution.
Moreover, any 𝑅≤𝑅′yields a feasible solution. This implies
𝑅𝑗≥𝑅′and we get the same guarantee as BAC, because
div 𝑆𝑗≥𝑅𝑗
2𝑘≥𝑅′
2𝑘≥𝑅∗
6𝑘.
Similarly to BCR,BCF then attempts to improve the cutoff value
for constructing 𝐺by again binary searching for an improved cutoff
in the interval[𝑅𝑗
2𝑘,𝑅𝑗]for which Extract still finds a feasible solu-
tion. In the worst case, this adds another O(log𝑛)iterations, which
does not change the asymptotic running time of the algorithm.
The running time for solving O(log𝑛)MA instances, as given by
Proposition 2, is dominated by the time needed to check for shortest
paths of length 2𝑘−1. In summary, the running time of BCF is
O(𝑛2log𝑛+2𝑛𝜔log𝑛log𝑘)=O(𝑛𝜔log𝑛log𝑘).
This is a considerable improvement over the running time of
BAC , making BCF orders of magnitude faster while retaining the
same theoretical guarantees.
Further improvements. As the graph 𝐺constructed in Algo-
rithm 5 may be split into multiple disconnected components, we
improve the search for independent sets by looking for the cycles,
antichains, and long shortest paths in each weakly connected com-
ponent of𝐺separately. We then take the union of the independent
sets for each component, aiming to have 𝑘points in total.
In addition, rather than choosing the centers arbitrarily in Al-
gorithm 3, we start by picking one of the vertices with the largest
𝑑mindistance. This heuristic is similar to the approach for solv-
ing MMD [ 57]. For the subsequent iterations, we choose the point
furthest from the current set of chosen centers, as in Algorithm 1.
Finally, in practice many of the unique distances 𝑅1,...,𝑅𝑚may
result in the same clustering 𝑈′in Algorithms 4 and 6. We avoid
these duplicate computations by grouping the 𝑅values that yield
the same clustering.Table 2: Performance comparison between our approxima-
tion algorithms ( BAC ,BCR , andBCF), the greedy algorithm
(Greedy), and the random baseline (Rand.), relative to the op-
timum solution value (Opt.) for fixed parameter value 𝑘=10.
Data BAC BCR BCF Greedy Rand. Opt.
ft70 95% 98% 95% 95% 63% 786
kro124p 88% 89% 88% 88% 45% 1 136
celegans 100% 100% 100% 100% 29% 7
rbg323 80% 100% 80% 80% 0% 15
wiki-vote 80% 80% 80% 80% 40% 5
US airports 100% 100% 100% 100% 0% 64036
moreno 100% 100% 100% 100% 27% 22
openflights 100% 100% 100% 100% 33% 9
cora 100% 100% 100% 100% 19% 27
bitcoin 100% 100% 100% 100% 29% 77
gnutella 85% 92% 85% 85% 38% 13
Average 93.4% 96.3% 93.4% 93.4% 29.3% 100%
6 EXPERIMENTS
Nextwedescrib eourexperiments. Allexperiments wereperforme d
onanIntel Corei5-8265U processor at1.6GHz with 16GBRAM.
Our metho dswereimplemente dinPython 3.8andarepublicly
available .5
6.1 Setup
Data. Fordata, weusedweighte ddigraphs thatweconv ertedinto
anasymmetric distance space bycomputing themetric closur e,
that is,wedefine thedistance𝑑(𝑢,𝑣)tobetheweighte dshortest
path length between𝑢and𝑣.Weonly usedthelargest strongly
conne ctedcomp onent. Table 1showsthedata andseveralstatistics
usedforevaluation. The column min𝑑(resp.max𝑑)denotes the
smallest (resp.largest) distance present. Thelastcolumn showsthe
numb erofunique distances, which heavily influences therunning
time ofouralgorithms fromSection 5.The datasets ft70, kro124
andrgb323 areasymmetric traveling salesman instances fromthe
public librar yTSPLIB [58].The bitcoin dataset originally hasedge
weights between[−10,10],which wehaverescale dtononnegativ e
weights between[0,20].
Baselines. Besides ourproposedalgorithms BAC,BCR,andBCF,
wehavealsoimplemente dandteste dthefollowing baselines:
Greedy.Iterativ elypick vertices maximizing the𝑑mindistance to-
wardsthealready chosen setofvertices asinAlgorithm 1.To
impr ovetheperformance ,westart with avertexofanedgewith
themaximum𝑑mindistance .
Random. Selectasubset𝑆⊆𝑈ofsize|𝑆|=𝑘uniformly atrandom.
Repeat10times andreturn thesetwith thehighest scorediv(𝑆).
Optimal. Computes anoptimal solution byreducing ittosolving
multiple𝑘-clique problems. First, sortalltheunique weights inthe
AMMD instance .The optimum𝑅∗isequal tooneoftheunique
5https://version.helsinki.fi/dacs/ammd
 
1446KDD ’24, August 25–29, 2024, Barcelona, Spain Iiro Kumpulainen, Florian Adriaens, & Nikolaj Tatti
4 8 16 32 644006008001
000OPT
BCF
RNDBCR
BA
C
GRD
r
equired size, 𝑘div(𝑆)
(
a)ft70dataset4 8 16 32 645001 0001 5002 000
OPTBA
C,BCF, GRD
RNDBCR
required size, 𝑘div(𝑆)
(
b)kro124 dataset4 8 16 32 64 128 25605101520
GRD
BA
COPT
,BCRBCF
RND
required size, 𝑘div(𝑆)
(
c)rbg323 dataset
Figure 3: The y-axis shows the diversity score of the solutions provided by the algorithms. The x-axis shows the parameter 𝑘,
which is the required solution size. All solutions converge to the same set as 𝑘approaches 𝑛.
weights. Let 𝑅be one of the unique weights. Create an undirected
graph𝐺𝑅=(𝑈,𝐸)with the same nodes as our AMMD instance,
and𝑖𝑗∈𝐸if and only if both 𝑑(𝑖,𝑗) ≥𝑅and𝑑(𝑗,𝑖) ≥𝑅. For
every𝑅≤𝑅∗the graph𝐺𝑅will have a clique of size 𝑘, and for
every𝑅>𝑅∗the graph𝐺𝑅does not contain a clique of size 𝑘, by
the optimality of 𝑅∗. A binary search on the sorted list of unique
weights finds the optimum 𝑅∗, by solving at most O(log𝑛)𝑘-clique
problems. Note that the 𝑘-clique problem can be solved optimally
inO(𝑛𝜔𝑘/3)time [ 49]. A similar idea has been used to optimally
solve symmetric MMD and related fairness variants [4, 65].
6.2 The diversity scores of the returned sets
Small𝑘regime. As mentioned in the introduction, in a typical
AMMD setting one is interested in finding solutions of small size.
We compare the performance of our algorithms BAC ,BCR andBCF
in Table 2 with the aforementioned baselines Greedy, Random, and
Optimal on all the datasets from Table 1, for the choice of 𝑘=10.
Observe that BCR achieves the highest score in every experi-
ment and finds the optimal value on seven datasets. In addition,
BCF achieves the same solution quality as BAC and Greedy while
being significantly faster than BAC and having the approximation
guarantee discussed in Section 5.3. We also note that Random often
performs very poorly, even with an increased number of repetitions.
BCF, Greedy, and Random were very fast and took less than three
seconds to run, whereas BCR took several minutes on some datasets.
Onwiki-vote andgnutella datasets, our baseline Optimal exceeded
a time limit of two hours, but we were able to find the optimal
values by manually checking that no cliques of size 𝑘exist when
only edges with higher weight are considered. The running times
on the real-world datasets are shown in Table 3 in the Appendix.
Performance for any 𝑘.We were able to run all the algorithms
for all values of 𝑘on the three small traveling salesman instances of
Table 1 within a reasonable time. Figure 3 shows the results, which
are consistent with our previous findings. BCR performs very well
also for larger values of 𝑘while BAC ,BCF, and Greedy are often
slightly worse. Note that as 𝑘increases, the output of all algorithms
converges to the same set, which is the entire universe of points.
6.3 Running times of the algorithms
In this section, we compare the running time of our algorithms
BAC, BCR, and BCF on synthetically generated graph instances.5002
0004
0006
0008
00010
00012
000020406080
BA
CBCR
BCFOPT
GRD
RND
graph
size,𝑛running
time (s)
(
a) Synthetic scale-free graphs5002
0004
0006
0008
00010
00012
00001020304050
BACBCR
BCF
distance
rangerunning
time (s)
(
b) Synthetic complete digraph
Figure 4: Running time of our algorithms as a function of
the generated graph size and the size of the interval from
which distances are sampled.
Increasing graph size. In the first experiment, we generated di-
rected (unweighted) scale-free networks of varying size 𝑛accord-
ing to the model by Bollobás et al . [9]. These synthetic graphs are
weakly connected, and we make them strongly connected by adding
directed edges in both directions. We set 𝑘=10, and defined dis-
tances as the shortest path distances between pairs of nodes (metric
closure). The diameter of scale-free networks typically scales about
logarithmically with graph size [ 10], so the number of unique dis-
tances in our AMMD instances does not change that drastically
when increasing the graph size 𝑛. For example, when generating
instances of size 𝑛=100and𝑛=3 200, the diameter roughly only
doubled from 5 to 10. Figure 4a shows the results of the average run-
ning time over several repeats. It shows that although the number
of unique distances is relatively low, the difference in speed be-
tween BCR andBCF is still substantial. For 𝑛=12 000 the running
time of BCR was about 49s while BCF required less than 14s. As
expected, the running time of Optimal scales exponentially while
Greedy and Random are very fast.
Unique distances. In a second timing experiment, we kept both
𝑛and𝑘fixed and increased the number of unique distances. We
generated complete weighted digraphs of size 𝑛=400, where the
weights are random positive integers below a variable upper bound.
To guarantee the triangle inequality, we again took the metric
closure. We set 𝑘=10. Figure 4b shows the results. The theoretical
speed-up of BCF when compared to BAC andBCR, as discussed in
Section 5.3, is clearly visible in our implementations on practical
 
1447Max-Min Diversification with Asymmetric Distances KDD ’24, August 25–29, 2024, Barcelona, Spain
data as well. Note that the running times of Greedy and Random
do not depend on the number of unique distances, while Optimal
takes prohibitively long for these instances.
7 CONCLUDING REMARKS
This paper initiated the study on the asymmetric generalization of
the Max-Min Diversification problem, denoted as AMMD, which
does not appear to have been studied before. We provided an ap-
proximation algorithm with an approximation factor of1
6𝑘and
running time equivalent to matrix multiplication with logarithmic
factors. In practice, BCR outperformed all the baselines, returning
optimal result in most of the cases, while having pratical running
times, and having theoretical guarantees.
Regarding the hardness of approximation, we leave it as an open
question whether one can improve the1
2+𝜖inapproximability result
that follows from MMD, which is the restriction of AMMD to sym-
metric distances. There is a large gap between our approximation
ratio and the inapproximability bound, and it would be interesting
for future work to narrow down the gap. For example, by designing
a constant-factor approximation algorithm for AMMD or showing
that no such algorithm exists under reasonable assumptions.
ACKNOWLEDGMENTS
This research is supported by the Academy of Finland project MAL-
SOME (343045) and by the Helsinki Institute for Information Tech-
nology (HIIT).
REFERENCES
[1]Zeinab Abbassi, Vahab S Mirrokni, and Mayur Thakur. 2013. Diversity max-
imization under matroid constraints. In Proceedings of the 19th ACM SIGKDD
international conference on Knowledge discovery and data mining. 32–40.
[2]Raghavendra Addanki, Andrew McGregor, Alexandra Meliou, and Zafeiria
Moumoulidou. 2022. Improved Approximation and Scalability for Fair Max-
Min Diversification. In 25th International Conference on Database Theory, ICDT
2022, March 29 to April 1, 2022, Edinburgh, UK (Virtual Conference) (LIPIcs, Vol. 220),
Dan Olteanu and Nils Vortmeier (Eds.). Schloss Dagstuhl - Leibniz-Zentrum für
Informatik, 7:1–7:21. https://doi.org/10.4230/LIPIcs.ICDT.2022.7
[3]Sepideh Aghamolaei, Majid Farhadi, and Hamid Zarrabi-Zadeh. 2015. Diversity
Maximization via Composable Coresets.. In CCCG. 38–48.
[4]Toshihiro Akagi, Tetsuya Araki, Takashi Horiyama, Shin-ichi Nakano, Yoshio
Okamoto, Yota Otachi, Toshiki Saitoh, Ryuhei Uehara, Takeaki Uno, and Kunihiro
Wasa. 2018. Exact algorithms for the max-min dispersion problem. In International
Workshop on Frontiers in Algorithmics. Springer, 263–272.
[5]Josh Alman and Virginia Vassilevska Williams. 2021. A refined laser method and
faster matrix multiplication. In Proceedings of the 2021 ACM-SIAM Symposium on
Discrete Algorithms (SODA). SIAM, 522–539.
[6]Aaron Archer. 2001. Two O (log* k)-approximation algorithms for the asymmet-
ric k-center problem. In International Conference on Integer Programming and
Combinatorial Optimization. Springer, 1–14.
[7]Christian Bauckhage, Rafet Sifa, and Stefan Wrobel. 2020. Adiabatic quantum
computing for max-sum diversification. In Proceedings of the 2020 SIAM Interna-
tional Conference on Data Mining. SIAM, 343–351.
[8]Sayan Bhattacharya, Sreenivas Gollapudi, and Kamesh Munagala. 2011. Consid-
eration set generation in commerce search. In Proceedings of the 20th international
conference on World wide web. 317–326.
[9]Béla Bollobás, Christian Borgs, Jennifer T Chayes, and Oliver Riordan. 2003.
Directed scale-free graphs.. In SODA, Vol. 3. 132–139.
[10] Béla Bollobás* and Oliver Riordan. 2004. The diameter of a scale-free random
graph. Combinatorica 24, 1 (2004), 5–34.
[11] Michele Borassi, Alessandro Epasto, Silvio Lattanzi, Sergei Vassilvitskii, and
Morteza Zadimoghaddam. 2019. Better sliding window algorithms to maximize
subadditive and diversity objectives. In Proceedings of the 38th ACM SIGMOD-
SIGACT-SIGAI Symposium on Principles of Database Systems. 254–268.
[12] Allan Borodin, Hyun Chul Lee, and Yuli Ye. 2012. Max-sum diversification,
monotone submodular functions and dynamic updates. In Proceedings of the
31st ACM SIGMOD-SIGACT-SIGAI symposium on Principles of Database Systems .
155–166.[13] Manuel Caceres, Massimo Cairo, Brendan Mumey, Romeo Rizzi, and Alexandru I
Tomescu. 2022. Minimum path cover in parameterized linear time. arXiv preprint
arXiv:2211.09659 (2022).
[14] Manuel Cáceres, Brendan Mumey, Santeri Toivonen, and Alexandru I Tomescu.
2023. Minimum Path Cover: The Power of Parameterization. arXiv preprint
arXiv:2308.08960 (2023).
[15] Pablo Castells, Neil Hurley, and Saul Vargas. 2021. Novelty and diversity in
recommender systems. In Recommender systems handbook. Springer, 603–646.
[16] Matteo Ceccarello, Andrea Pietracaprina, and Geppino Pucci. 2018. Fast coreset-
based diversity maximization under matroid constraints. In Proceedings of the
Eleventh ACM International Conference on Web Search and Data Mining. 81–89.
[17] Matteo Ceccarello, Andrea Pietracaprina, and Geppino Pucci. 2020. A general
coreset-based approach to diversity maximization under matroid constraints.
ACM Transactions on Knowledge Discovery from Data (TKDD) 14, 5 (2020), 1–27.
[18] Elisa Celis, Vijay Keswani, Damian Straszak, Amit Deshpande, Tarun Kathuria,
and Nisheeth Vishnoi. 2018. Fair and diverse DPP-based data summarization. In
International conference on machine learning. PMLR, 716–725.
[19] Alfonso Cevallos, Friedrich Eisenbrand, and Rico Zenklusen. 2017. Local search
for max-sum diversification. In Proceedings of the Twenty-Eighth Annual ACM-
SIAM Symposium on Discrete Algorithms. SIAM, 130–142.
[20] Barun Chandra and Magnús M Halldórsson. 2001. Approximation Algorithms
for Dispersion Problems. Journal of Algorithms 38, 2 (2001), 438–465. https:
//doi.org/10.1006/jagm.2000.1145
[21] Li Chen, Rasmus Kyng, Yang P Liu, Richard Peng, Maximilian Probst Gutenberg,
and Sushant Sachdeva. 2022. Maximum flow and minimum-cost flow in almost-
linear time. In 2022 IEEE 63rd Annual Symposium on Foundations of Computer
Science (FOCS). IEEE, 612–623.
[22] Julia Chuzhoy, Sudipto Guha, Eran Halperin, Sanjeev Khanna, Guy Kortsarz,
Robert Krauthgamer, and Joseph Naor. 2005. Asymmetric k-center is log* n-hard
to approximate. Journal of the ACM (JACM) 52, 4 (2005), 538–551.
[23] Manuel Cáceres, Massimo Cairo, Brendan Mumey, Romeo Rizzi, and Alexandru I.
Tomescu. [n. d.]. Sparsifying, Shrinking and Splicing for Minimum Path Cover in
Parameterized Linear Time. 359–376. https://doi.org/10.1137/1.9781611977073.18
[24] Ting Deng and Wenfei Fan. 2013. On the complexity of query result diversification.
Proceedings of the VLDB Endowment 6, 8 (2013), 577–588.
[25] Robert P Dilworth. 1987. A decomposition theorem for partially ordered sets.
Classic papers in combinatorics (1987), 139–144.
[26] Marina Drosou and Evaggelia Pitoura. 2012. Disc diversity: result diversification
based on dissimilarity and coverage. arXiv preprint arXiv:1208.3533 (2012).
[27] Erhan Erkut. 1990. The discrete p-dispersion problem. European Journal of
Operational Research 46, 1 (1990), 48–60.
[28] Stefan Felsner, Vijay Raghavan, and Jeremy Spinrad. 2003. Recognition algorithms
for orders of small width and graphs of small Dilworth number. Order 20 (2003),
351–364.
[29] Delbert R Fulkerson. 1956. Note on Dilworth’s decomposition theorem for
partially ordered sets. Proc. Amer. Math. Soc. 7, 4 (1956), 701–702.
[30] Andrew V Goldberg. 2008. The partial augment—relabel algorithm for the maxi-
mum flow problem. In European Symposium on Algorithms. Springer, 466–477.
[31] Teofilo F Gonzalez. 1985. Clustering to minimize the maximum intercluster
distance. Theoretical computer science 38 (1985), 293–306.
[32] Refael Hassin, Shlomi Rubinstein, and Arie Tamir. 1997. Approximation algo-
rithms for maximum dispersion. Operations research letters 21, 3 (1997), 133–137.
[33] Johan Hastad. 1996. Clique is hard to approximate within 𝑛1−𝜀. InProceedings of
37th Conference on Foundations of Computer Science. IEEE, 627–636.
[34] Piotr Indyk, Sepideh Mahabadi, Mohammad Mahdian, and Vahab S Mirrokni. 2014.
Composable core-sets for diversity and coverage maximization. In Proceedings
of the 33rd ACM SIGMOD-SIGACT-SIGART symposium on Principles of database
systems. 100–108.
[35] Marius Kaminskas and Derek Bridge. 2016. Diversity, serendipity, novelty, and
coverage: a survey and empirical analysis of beyond-accuracy objectives in
recommender systems. ACM Transactions on Interactive Intelligent Systems (TiiS)
7, 1 (2016), 1–42.
[36] Mirosław Kowaluk, Andrzej Lingas, and Johannes Nowak. 2008. A path cover
technique for LCAs in dags. In Scandinavian Workshop on Algorithm Theory.
Springer, 222–233.
[37] Michael J Kuby. 1987. Programming models for facility dispersion: The p-
dispersion and maxisum dispersion problems. Geographical Analysis 19, 4 (1987),
315–329.
[38] Srijan Kumar, Bryan Hooi, Disha Makhija, Mohit Kumar, Christos Faloutsos, and
VS Subrahmanian. 2018. Rev2: Fraudulent user prediction in rating platforms.
InProceedings of the Eleventh ACM International Conference on Web Search and
Data Mining. ACM, 333–341.
[39] Srijan Kumar, Francesca Spezzano, VS Subrahmanian, and Christos Faloutsos.
2016. Edge weight prediction in weighted signed networks. In Data Mining
(ICDM), 2016 IEEE 16th International Conference on. IEEE, 221–230.
[40] Jérôme Kunegis. 2013. Konect: the koblenz network collection. In Proceedings of
the 22nd international conference on world wide web. 1343–1350.
 
1448KDD ’24, August 25–29, 2024, Barcelona, Spain Iiro Kumpulainen, Florian Adriaens, & Nikolaj Tatti
[41] Jure Leskovec and Andrej Krevl. 2014. SNAP Datasets: Stanford Large Network
Dataset Collection. http://snap.stanford.edu/data.
[42] Sepideh Mahabadi and Shyam Narayanan. 2023. Improved Diversity Maximiza-
tion Algorithms for Matching and Pseudoforest. arXiv preprint arXiv:2307.04329
(2023).
[43] Veli Mäkinen, Alexandru I Tomescu, Anna Kuosmanen, Topi Paavilainen, Travis
Gagie, and Rayan Chikhi. 2019. Sparse dynamic programming on DAGs with
small width. ACM Transactions on Algorithms (TALG) 15, 2 (2019), 1–21.
[44] Loris Marchal, Hanna Nagy, Bertrand Simon, and Frédéric Vivien. 2018. Parallel
scheduling of dags under memory constraints. In 2018 IEEE International Parallel
and Distributed Processing Symposium (IPDPS). IEEE, 204–213.
[45] Antonis Matakos, Sijing Tu, and Aristides Gionis. 2020. Tell me something my
friends do not know: Diversity maximization in social networks. Knowledge and
Information Systems 62 (2020), 3697–3726.
[46] James Moody. 2001. Peer influence groups: identifying dense clusters in large
networks. Social networks 23, 4 (2001), 261–283.
[47] Zafeiria Moumoulidou, Andrew McGregor, and Alexandra Meliou. 2020. Diverse
data selection under fairness constraints. arXiv preprint arXiv:2010.09141 (2020).
[48] Zafeiria Moumoulidou, Andrew McGregor, and Alexandra Meliou. 2021. Diverse
Data Selection under Fairness Constraints. In 24th International Conference on
Database Theory, ICDT 2021, March 23-26, 2021, Nicosia, Cyprus (LIPIcs, Vol. 186),
Ke Yi and Zhewei Wei (Eds.). Schloss Dagstuhl - Leibniz-Zentrum für Informatik,
13:1–13:25. https://doi.org/10.4230/LIPIcs.ICDT.2021.13
[49] Jaroslav Nešetřil and Svatopluk Poljak. 1985. On the complexity of the subgraph
problem. Commentationes Mathematicae Universitatis Carolinae 26, 2 (1985),
415–419.
[50] Simeon C. Ntafos and S. Louis Hakimi. 1979. On path cover problems in digraphs
and applications to program testing. IEEE Transactions on Software Engineering 5
(1979), 520–529.
[51] U.S. Department of Transportation (DOT). 2015. 2015 Flights Delay. https:
//www.kaggle.com/datasets/usdot/flight-delays.
[52] Tore Opsahl. 2011. Why anchorage is not (that) important: Binary ties and sample
selection. In https://toreopsahl.com/datasets/#usairports .
[53] Rina Panigrahy and Sundar Vishwanathan. 1998. AnO (log* n) Approximation
Algorithm for the Asymmetricp-Center Problem. Journal of Algorithms 27, 2
(1998), 259–268.
[54] Wim Pijls and Rob Potharst. 2013. Another note on dilworth’s decomposition
theorem. Journal of Discrete Mathematics 2013 (2013).
[55] Lu Qin, Jeffrey Xu Yu, and Lijun Chang. 2012. Diversifying Top-k Results. Proc.
VLDB Endow. 5, 11 (jul 2012), 1124–1135. https://doi.org/10.14778/2350229.2350233
[56] Filip Radlinski and Susan Dumais. 2006. Improving personalized web search
using result diversification. In Proceedings of the 29th annual international ACM
SIGIR conference on Research and development in information retrieval. 691–692.
[57] Sekharipuram S Ravi, Daniel J Rosenkrantz, and Giri Kumar Tayi. 1994. Heuristic
and special case algorithms for dispersion problems. Operations Research 42, 2
(1994), 299–310.
[58] Gerhard Reinelt. 1991. TSPLIB, a Traveling Salesman Problem Library. ORSA
Journal on Computing 3, 4 (1991), 376–384.
[59] Lovro Šubelj and Marko Bajec. 2013. Model of complex networks based on
citation dynamics. In Proceedings of the 22nd international conference on World
Wide Web. 527–530.
[60] Ola Svensson, Jakub Tarnawski, and László A Végh. 2020. A constant-factor
approximation algorithm for the asymmetric traveling salesman problem. Journal
of the ACM (JACM) 67, 6 (2020), 1–53.
[61] Arie Tamir. 1991. Obnoxious facility location on graphs. SIAM Journal on Discrete
Mathematics 4, 4 (1991), 550–567.
[62] Da-Wei Wang and Yue-Sun Kuo. 1988. A study on two geometric location
problems. Information processing letters 28, 6 (1988), 281–286.
[63] Yanhao Wang, Francesco Fabbri, and Michael Mathioudakis. 2022. Streaming
algorithms for diversity maximization with fairness constraints. In 2022 IEEE
38th International Conference on Data Engineering (ICDE). IEEE, 41–53.
[64] Yanhao Wang, Francesco Fabbri, Michael Mathioudakis, and Jia Li. 2023. Fair
Max–Min Diversity Maximization in Streaming and Sliding-Window Models.
Entropy 25, 7 (2023), 1066.
[65] Yanhao Wang, Michael Mathioudakis, Jia Li, and Francesco Fabbri. 2023. Max-Min
Diversification with Fairness Constraints: Exact and Approximation Algorithms.
InProceedings of the 2023 SIAM International Conference on Data Mining (SDM).
SIAM, 91–99.
[66] Dong Xin, Hong Cheng, Xifeng Yan, and Jiawei Han. 2006. Extracting redundancy-
aware top-k patterns. In Proceedings of the 12th ACM SIGKDD international
conference on Knowledge discovery and data mining. 444–453.
[67] Sepehr Zadeh, Mehrdad Ghadiri, Vahab Mirrokni, and Morteza Zadimoghad-
dam. 2017. Scalable feature selection via distributed diversity maximization. In
Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 31.
[68] Guangyi Zhang and Aristides Gionis. 2020. Maximizing diversity over clustered
data. In Proceedings of the 2020 SIAM International Conference on Data Mining.
SIAM, 649–657.
[69] Kaiping Zheng, Hongzhi Wang, Zhixin Qi, Jianzhong Li, and Hong Gao. 2017.
A survey of query result diversification. Knowledge and Information Systems 51
(2017), 1–36.
 
1449Max-Min Diversification with Asymmetric Distances KDD ’24, August 25–29, 2024, Barcelona, Spain
A PROOFS
A.1 Proof of Theorem 2
We start by proving the approximation ratio of Algorithm 1. For a
point𝑢∈𝑈and𝑟>0, let𝐵(𝑢,𝑟)={𝑣∈𝑈|𝑑min(𝑣,𝑢)<𝑟}denote
the𝑑min-ball around 𝑢with radius 𝑟. We first prove the Property 4.
Proposition 4. If a pseudometric space (𝑈,𝑑)is𝜖-symmetric,
then for any 𝑥,𝑦∈𝐵(𝑧,𝑟)it holds that 𝑑min(𝑥,𝑦)<(2+𝜖)𝑟.
Proof. It holds that
𝑑min(𝑥,𝑦)=min{𝑑(𝑥,𝑦),𝑑(𝑦,𝑥)}
≤min{𝑑(𝑥,𝑧)+𝑑(𝑧,𝑦),𝑑(𝑦,𝑧)+𝑑(𝑧,𝑥)}.
If𝑑(𝑥,𝑧)≤𝑑(𝑧,𝑥), then
𝑑min(𝑥,𝑦)≤𝑑(𝑥,𝑧)+𝑑(𝑧,𝑦)<𝑟+(1+𝜖)𝑟=(2+𝜖)𝑟.
Otherwise𝑑(𝑥,𝑧)>𝑑(𝑧,𝑥), and then
𝑑min(𝑥,𝑦)≤𝑑(𝑦,𝑧)+𝑑(𝑧,𝑥)<(1+𝜖)𝑟+𝑟=(2+𝜖)𝑟,
and Property 4 follows. □
Now we continue with the proof of Theorem 2. Consider an
optimum solution 𝑂={𝑜1,...,𝑜𝑘}of𝑘distinct points, with op-
timal value div(𝑂)=𝑅∗. Property 4 implies that the 𝑘balls𝐵𝑖=
𝐵(𝑜𝑖,𝑅∗
2+𝜖)for each𝑖=1,...,𝑘 are pairwise disjoint. Indeed, assume
two balls𝐵𝑖and𝐵𝑗share a common point 𝑢, then because 𝑜𝑖∈
𝐵(𝑢,𝑅∗
2+𝜖)and𝑜𝑗∈𝐵(𝑢,𝑅∗
2+𝜖), Property 4 states that 𝑑min(𝑜𝑖,𝑜𝑗)<
𝑅∗, contradicting the optimality of 𝑂.
While|𝑆|<𝑘in Algorithm 1, there exists some ball 𝐵𝑖that does
not contain any point from 𝑆. Therefore,𝑜𝑖is available for selection
and𝑑min(𝑜𝑖,𝑆)≥𝑅∗
2+𝜖. As Algorithm 1 picks the vertex with the
maximum𝑑mindistance towards the 𝑆, it holds that div(𝑆)≥𝑅∗
2+𝜖
in each iteration. The performance guarantee follows.
To show that this ratio is tight, consider the following example of
a pseudometric on three points {𝑥,𝑦,𝑧}with𝑑(𝑥,𝑦)=𝑑(𝑦,𝑥)=1,
𝑑(𝑥,𝑧)=𝑑(𝑦,𝑧)=1
2+𝜖and𝑑(𝑧,𝑥)=𝑑(𝑧,𝑦)=1+𝜖
2+𝜖. This instance is
𝜖-symmetric and satisfies the directed triangle inequality. For 𝑘=2,
the optimum is 𝑂={𝑥,𝑦}with𝑅∗=1, but Algorithm 1 returns a
set with value1
2+𝜖if the first point chosen is 𝑧.
Algorithm 1 can be implemented to run in O(𝑘𝑛)time by main-
taining𝑑(𝑢,𝑆)for each𝑢∈𝑈in each iteration. If 𝑣is selected
in an iteration, then the distances are updated as 𝑑(𝑢,𝑆∪{𝑣})=
min{𝑑(𝑢,𝑆),𝑑(𝑢,𝑣)}. There are𝑘iterations and 𝑛updates in each
iteration, with each update requiring constant time.
A.2 Proof of Theorem 3
Recall that𝑅∗is the optimal value for an AMMD instance space
(𝑈,𝑑)with parameter 𝑘, and𝑂is a corresponding optimal set of 𝑘
points. There are at most 𝑛(𝑛−1)unique pairwise distances in 𝑑,and𝑅∗equals one of them. Algorithm 2 will iterate over all unique
distances𝑅and creates a digraph 𝐺𝑅=(𝑈,𝐴)with𝑖𝑗∈𝐸if and
only if𝑑(𝑖,𝑗)<𝑅
𝑛−𝑘+1.
Now we argue that for any 𝑅≤𝑅∗, and for any two 𝑥,𝑦∈𝑂,𝑥≠
𝑦, it must hold that 𝑦is unreachable from 𝑥in𝐺𝑅. Suppose that
𝑦is reachable from 𝑥. So there is a path 𝑝in𝐺𝑅from𝑥to𝑦. We
may assume that 𝑝only has vertices that are not in 𝑂, except for
the first vertex 𝑥and the last vertex 𝑦. Otherwise, we continue the
argument by shortening 𝑝to start at𝑥until encountering the first
point in𝑂. Using the triangle inequality along the edges in 𝑝, it
follows that
𝑑(𝑥,𝑦)<(𝑛−𝑘+1)𝑅
𝑛−𝑘+1=𝑅,
as there are at most 𝑛−𝑘+1edges in𝑝, and the distance between
consecutive points in 𝑝is strictly smaller than𝑅
𝑛−𝑘+1by definition
of𝐺𝑅. This contradicts with 𝑑(𝑥,𝑦)≥𝑅∗, by optimality of 𝑥,𝑦∈𝑂.
As the points in an optimal solution are pairwise unreachable in
𝐺𝑅for𝑅≤𝑅∗, it follows that the maximum antichain 𝑀in𝐺𝑅will
have at least 𝑘vertices, and we simply select 𝑘arbitrary vertices
from𝑀and return them as our final solution. As two distinct
vertices𝑖,𝑗∈𝑀,𝑖≠𝑗satisfy𝑑(𝑖,𝑗)≥𝑅
𝑛−𝑘+1, the approximation
guarantee follows by iterating over all unique distances so that for
one of the iterations we have 𝑅=𝑅∗. The running time follows
from Proposition 1, by using the maximum antichain algorithm
from [13].
A.3 Table of running times
Table 3: Running times for our approximation algorithms
(BAC,BCR , and BCF), the greedy algorithm (Greedy), and
the random baseline (Rand.) for fixed parameter value 𝑘=10
on the real-world datasets from Table 1.
Data BAC BCR BCF Greedy Rand.
ft70 1s 4s 0s 0s 0s
kro124p 1s 5s 0s 0s 0s
celegans 0s 0s 0s 0s 0s
rbg323 0s 1s 0s 0s 0s
wiki-vote 0s 1s 0s 0s 0s
US airports 1m 44s 7m 25s 0s 0s 0s
moreno 3s 15s 0s 0s 0s
openflights 2s 2s 1s 0s 0s
cora 9s 41s 1s 0s 0s
bitcoin 51s 5m 13s 2s 0s 0s
gnutella 11s 23s 2s 0s 0s
 
1450