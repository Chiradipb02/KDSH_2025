Relevance Meets Diversity: A User-Centric Framework for
Knowledge Exploration Through Recommendations
Erica Coppolillo∗
University of Calabria
Department of Computer Science
Rende, Italy
erica.coppolillo@unical.itGiuseppe Manco
ICAR-CNR
Rende, Italy
giuseppe.manco@icar.cnr.itAristides Gionis
KTH Royal Institute of Technology
Division of Theoretical Computer
Science
Stockholm, Sweden
argioni@kth.se
ABSTRACT
Providing recommendations that are both relevant anddiverse is a
key consideration of modern recommender systems. Optimizing
both of these measures presents a fundamental trade-off, as higher
diversity typically comes at the cost of relevance, resulting in lower
user engagement. Existing recommendation algorithms try to re-
solve this trade-off by combining the two measures, relevance and
diversity, into one aim and then seeking recommendations that
optimize the combined objective, for a given number of items. Tra-
ditional approaches, however, do not consider the user interaction
with the suggested items. In this paper, we put the userat the central
stage, and build on the interplay between relevance, diversity, and
user behavior. In contrast to applications where the goal is solely to
maximize engagement, we focus on scenarios aiming at maximizing
the total amount of knowledge encountered by the user. We use
diversity as a surrogate for the amount of knowledge obtained by
the user while interacting with the system, and we seek to maxi-
mize diversity. We propose a probabilistic user-behavior model in
which users keep interacting with the recommender system as long
as they receive relevant suggestions, but they may stop if the rele-
vance of the recommended items drops. Thus, for a recommender
system to achieve a high-diversity measure, it will need to produce
recommendations that are both relevant and diverse. Finally, we pro-
pose a novel recommendation strategy that combines relevance and
diversity by a copula function. We conduct an extensive evaluation
of the proposed methodology over multiple datasets, and we show
that our strategy outperforms several state-of-the-art competitors.
Our implementation is publicly available1.
CCS CONCEPTS
•Information systems →Personalization; Recommender
systems; •Computing methodologies →Modeling and simu-
lation.
KEYWORDS
User Modeling; Diversity; Recommender Systems
∗Also with ICAR-CNR.
1https://github.com/EricaCoppolillo/EXPLORE
This work is licensed under a Creative Commons Attribution
International 4.0 License.
KDD ’24, August 25–29, 2024, Barcelona, Spain
©2024 Copyright held by the owner/author(s).
ACM ISBN 979-8-4007-0490-1/24/08.
https://doi.org/10.1145/3637528.3671949ACM Reference Format:
Erica Coppolillo, Giuseppe Manco, and Aristides Gionis. 2024. Relevance
Meets Diversity: A User-Centric Framework for Knowledge Exploration
Through Recommendations. In Proceedings of the 30th ACM SIGKDD Con-
ference on Knowledge Discovery and Data Mining (KDD ’24), August 25–
29, 2024, Barcelona, Spain. ACM, New York, NY, USA, 12 pages. https:
//doi.org/10.1145/3637528.3671949
Iterative knowledge exploration via recommendationsKnowledge exploration 
continues as long as user 
receives relevant items
Set of information items accessed
Knowledge exploration 
terminates when user 
receives less relevant items
Large and 
diverse setSmall or 
non-diverse set
Low 
diversity
scoreHigh 
diversity
score
Figure 1: The knowledge-exploration process, illustrating
the interplay among relevance, diversity, and user behavior.
1 INTRODUCTION
Recommender systems play a significant role in helping users dis-
cover new information and expand their knowledge base. Notable
examples are the adoptions of recommendations for finding news ar-
ticles or books to read [ 46], listening to enjoyable music [ 14],visiting
interesting locations [ 47], and more. Recommender systems aim
to predict and leverage users’ interests to identify the portions of
the catalog that match them, thus enabling efficient exploration
of vast volumes of information and offering benefits ranging from
increased personalization and user satisfaction to improved engage-
ment and resource efficiency.
Recommenders are primarily focused on maximizing relevance.
However, from the standpoint of knowledge exploration, incor-
porating diversity into recommendations adds significant value,
as emphasized in earlier research [ 20,40]. Indeed, providing di-
verse recommendations can be critical in mitigating detrimental
consequences, such as being trapped in rabbit holes in platforms
like Youtube [ 16,35,43] or Reddit [ 32], where the algorithm may
lead the user to consume limited types of content. To achieve a
 
490
KDD ’24, August 25–29, 2024, Barcelona, Spain Erica Coppolillo, Giuseppe Manco, and Aristides Gionis
balance between relevance and diversity, current methods merge
these two metrics into a single objective for optimization. However,
they overlook user behavior and how users interact with the rec-
ommended list of items. For instance, typical approaches assume a
fixed number of interactions between the user and the algorithm,
disregarding any reactions or refusals from the user during the
exploration process. Indeed, users might reject recommended items
and quit the process.
In this paper, we propose a new framework for recommender
systems, where we place the user at the forefront. We consider
the interaction of the user with the algorithm to be a knowledge-
exploration task, where recommendations enable exploration. The
interaction of the user with the system is guided via a user-behavior
model, i.e., the propensity of a user to accept or reject recommenda-
tions according to their preferences and patience. As the objective
is to maximize the amount of knowledge that a user acquires during
exploration, we model the knowledge accrued by the user using
adiversity measure, which we consequently aim at maximizing.
Notably, although diversity is the sole optimization objective, the
coupling of the exploration task with the user-behavior model
implies that the recommendation system is required to produce rec-
ommendations that are both relevant and diverse. We illustrate the
proposed concept of “knowledge exploration via recommendations”
with the following example.
(a)
 (b)
 (c)
Figure 2: Illustration of the impact of different recommenda-
tion strategies. White points are recommended items, blue
circles indicate information coverage. (a) High relevance,
low diversity (e.g., all about ‘technology’); (b) High diversity,
likely non-relevant (e.g., ‘technology’, ‘religion’, ‘lifestyle’);
(c) Optimal balance: relevant and diverse, keeping user en-
gaged (e.g., ‘technology’, ‘science’, ‘engineering’).
Example. Alice interacts with a news recommender system for find-
ing interesting news articles to read. The knowledge-exploration
process is iterative, and is depicted in Figure 1. At each step, the
system recommends a set of news articles to Alice, and Alice clicks
on an article to read. At some point, Alice can decide to quit, either
because she received enough information, or because the recom-
mendations are not very interesting to her, or simply because she
got bored. Our goal is to design a recommender system that maxi-
mizes the amount of knowledge received by Alice. The challenge is
to strike a balance between diversity and relevance to keep Alice en-
gaged while exploring interesting topics, avoiding scenarios where
recommendations are either too focused (Figure 2(a)) or too diverse
and irrelevant (Figure 2(b)). Our aim is to create an ideal scenario
(Figure 2(c)) where Alice explores many relevant yet diverse topics,
enriching her knowledge.Motivated by the previous example, we propose a novel frame-
work where relevance governs the termination of exploration, while
the overall quality is measured by diversity. We instantiate our
model using two standard notions of diversity, one based on cover-
age and the other based on pair-wise distances [ 3,7,10]. Both diver-
sity notions, coverage and pairwise distances, can be defined using
an underlying space of user-to-item ratings or categories/topics.
Finally, we propose a novel recommendation strategy that com-
bines relevance and diversity by a copula function. We perform
an extensive evaluation of the proposed framework and strategy
using five benchmark datasets publicly available, and show that
our strategy outperforms several state-of-the-art competitors.
Our contributions are summarized as follows:
•We develop a user-centric model for knowledge exploration
via recommendations; our framework considers the interplay
among relevance, diversity, and user behavior.
•We instantiate our model with two diversity measures, de-
fined over user-to-item ratings or categories/topics.
•We propose a recommendation strategy that accounts for
both diversity and relevance when providing suggestions.
•We conduct an extensive analysis over multiple benchmark
datasets and several competitors to show the effectiveness
of our proposal in the suggested framework.
The rest of the paper is structured as follows. Section 2 presents
the related work in terms of user modeling and diversity in recom-
mendations. Section 3 presents our problem definition and method-
ology. In Section 4, we present our recommendation strategy. Ex-
perimental results are reported in Section 5, and finally Section 6
concludes the paper and provides pointers for future extensions.
2 RELATED WORK
User modeling in recommender systems. The effects of user
behavior in recommender systems, in terms of novelty and diver-
sity, have gained a lot of attention in recent years. Analysis can
be conducted by either running user studies [ 24,53], or by means
of simulation [ 18,49]. Analyzing the choices made by actual users
can yield more dependable outcomes; however, it also requires cre-
ating an effective recommendation system and engaging users for
conducting comprehensive studies. On the other hand, simulating
user choices is a more straightforward method, allowing for testing
several system configurations at no expense. However, it requires
a realistic model of user behavior.
To address this challenge, several user-behavior models have
been proposed in the literature. Hazrati and Ricci [19] model the
probability that a user picks a recommended item as being pro-
portional to its utility. Similarly, Bountouridis et al . [5] propose
a simulation framework in which users decide to interact with a
certain number of items per iteration, according to their given pref-
erences. Szlávik et al . [42] present three different user-behavior
models, where users either blindly follow recommendations and
choose the most popular items, or completely ignore suggestions
and pick items randomly.
The aforementioned models present certain limitations, namely
users necessarily have to pick an item, i.e., they cannot leave the
application, and second, the selection probability stays constant
over time. We overcome these limitations by modeling a quitting
 
491Relevance Meets Diversity: A User-Centric Framework for Knowledge Exploration Through Recommendations KDD ’24, August 25–29, 2024, Barcelona, Spain
probability, according to which users can interrupt their interac-
tion with the recommender system. We assume that the quitting
probability depends on the utility of the recommended items and
on the user patience, which degrades over time.
Notably, with our framework, we leverage the intrinsic inter-
play among relevance, diversity, and user behavior, since successful
recommendation strategies need to ensure that they provide rec-
ommendations that are both relevant and diverse.
Diversity in recommendation. Diversity in recommendations
has been acknowledged as a crucial issue [ 8,20,40], and over
the past decade, it has received considerable attention [ 1,2,44].
Several online and targeted user studies assessed the increase in
user satisfaction when diversity is incorporated into the list of
suggested items [ 8,21]. For example, Allison et al. [ 9] show that, if
diversity (besides other objectives) is not taken into account, the
interactions between users and recommender systems are prone to
homogenization and, consequently, low utility.
The challenge of striking a balance between diversity and rel-
evance has been explored both in the context of recommender
systems and in the broader domain of information retrieval. For
instance, one of the most popular methods in the literature of in-
formation retrieval is the maximal marginal relevance (MMR) [ 7].
It employs a weighted linear combination of scores that evaluate
both utility and diversity, offering a systematic way to address this
critical aspect. In the specific context of recommender systems,
Ziegler et al . [54] introduced one of the earliest methods for en-
hancing diversity. They use a greedy selection approach, where
they pick items that minimize the similarity within a recommended
list. Liu et al . [27] present a solution based on random walks for the
so-called accuracy-diversity dilemma, i.e., the challenge in finding
a profitable trade-off between the two measures. This concept is
also known as calibration, as mentioned by Steck [41], and refers
to the algorithm’s capability to produce suggestions that do not
under-represent (or ignore) the user’s secondary areas of interest.
Several re-ranking strategies have also been introduced: Ashkan
et al. [3] propose to greedily select items by maximizing the utility
of a submodular function; Sha et al . [39] suggest to optimize the
diversity loss of items using probabilistic matrix factorization; Chen
et al. [10] propose a determinantal point process (DPP) to re-rank
the recommended items so as to maximize the determinant on the
items’ similarity matrix. Hansen et al . [15] investigate the impact
of diversity on music consumption, and propose two innovative
models: a feed-forward neural ranker that produces dynamic user
embedding, and a reinforcement learning-based ranker optimized
on the track relevance. Reinforcement learning is indeed a suitable
solution for addressing the diversity problem. It plays a role in the
work by Parapar and Radlinski [29], where diversity is induced
by adopting multi-armed bandits in the elicitation phase; and in
the online learning framework proposed by Yue and Guestrin [50],
where diversification is obtained by carefully balancing the explo-
ration and exploitation of users’ preferences and interests. Notably,
these reinforcement learning-based approaches typically require a
lengthy training phase, which can often be prone to stability issues.
Several other neural-network models have been applied to address
the diversity problem. Gao et al . [13] adopt a variational autoencoder
to induce targeted (i.e., topical) diversity. Liang et al . [25] proposeabilateral branch network to achieve a good trade-off between rele-
vance and diversity, defined at either domain or user level. Zheng
et al. [52] present a graph neural network (GNN) for diversified
recommendations, where node neighbors are selected based on
inverse category frequency, together with negative sampling for
inducing diverse items in the embedding space. Yang et al . [48] pro-
pose an extension, optimizing a graph-based recommender system
to suggest items that maximize the number of covered categories.
In contrast to most of the approaches mentioned earlier, the rec-
ommendation strategy we introduce, explore, does not necessitate
any form of training or hyperparameter tuning, it is computation-
ally efficient, and is shown to provide both highly relevant and
diverse suggestions.
3 USER MODEL AND PROBLEM
FORMULATION
Algorithm 1 Simulation process for user 𝑢
Input:𝑢,I,S,R
Output:X
1:X←∅
2:𝑞𝑢𝑖𝑡←False
3:while not𝑞𝑢𝑖𝑡 do
4: L𝑡=[𝑖𝑖,𝑖2,...,𝑖𝑘]←S(R(𝑢,I\X),X)
5: examining L𝑡←Algorithm 2
6: if𝑢does not quit then
7:𝑖←picked item
8:X←X∪{𝑖}
9: else
10:𝑞𝑢𝑖𝑡←True
11: end if
12:end while
We consider a typical recommendation setting in which we have
a set of𝑚usersUand a set of𝑛itemsI. We also consider a function
R:U×I→ Rthat provides us with a relevance score R(𝑢,𝑖), for
each user𝑢∈U and item𝑖∈I. We assume that the function Rcan
be computed by a black-box method, and state-of-the-art relevance-
scoring functions can be employed, such as content similarity [ 30],
collaborative filtering [37], or a combination of both [6].
Our goal in this paper is to create lists of diverse recommenda-
tions using such relevance-scoring functions as a black box, rather
than devising a novel R.
Item-to-item distance function. We next discuss how to define
a distance function between pairs of items in I, which will be used
in one of our two diversity definitions.
Given an item 𝑖∈I, we denote by x𝑖the vector of users with
𝑥𝑖𝑢=(
1,if user𝑢interacted with item 𝑖,
0,otherwise.
The vectors{x𝑖}can be retrieved by user-log data. A more fine-
grained representation of vectors {x𝑖}beyond binary is also possi-
ble, for instance, using numerical values that represent the rating
of user𝑢for item𝑖, if such information is available.
An alternative approach is to use categories (or keywords, or
genres, depending on the application). In particular, we consider
 
492KDD ’24, August 25–29, 2024, Barcelona, Spain Erica Coppolillo, Giuseppe Manco, and Aristides Gionis
Algorithm 2 User behavior at step 𝑡
Input: L𝑡
Output:𝑖∈L𝑡orquits
1:interest←False
2:for𝑗=1,...,𝑘 do
3:𝑖←L𝑡[𝑗]
4: quitting←with probability 𝜂𝑡
5: if𝑢quits then
6: return
7: else
8: examining𝑖←with probability 𝑞𝑖
9: if𝑖is interesting then
10: interest←True
11: end if
12: end if
13:end for
14:ifnotinterest then
15: return
16:end if
17:for𝑗=1,...,𝑘 do
18:𝑖←L𝑡[𝑗]
19: consuming𝑖←with probability 𝑝𝑖
20: if𝑢consumes𝑖then
21: return𝑖
22: end if
23:end for
a set of categoriesC, and we define y𝑖to be a category vector, for
item𝑖∈I, where
𝑦𝑖𝑐=(
1,if category𝑐relates to item 𝑖,
0,otherwise.
Given two items 𝑖,𝑗∈I, we hence define their distance as the
weighted Jaccard distance
𝑑(𝑖,𝑗)=1−Í
𝑤∈Wmin{𝑧𝑖𝑤,𝑧𝑗𝑤}Í
𝑤∈Wmax{𝑧𝑖𝑤,𝑧𝑗𝑤}, (1)
whereWis either the set of users Uor the set of categories C, and
accordingly, z𝑖is the user vector or the category vector of item𝑖.
Finally, we note that other state-of-the-art distance functions
can also be used, such as Euclidean distance, cosine similarity, or
Minkowski distance. We do not investigate what is the best distance
function to be used, as this is orthogonal to our study and beyond
the scope of this paper.
Diversity. Given a set of items X⊆I , we define the diversity of
the setX. We explore two different definitions of diversity.
Our first definition is based on the concept of coverage. It assesses
the degree to which the items within Xadequately represent the
entire range of categories C. In particular, for a set of items X⊆I ,
we define its coverage-based diversity as
div𝐶(X)=1
|C|Ü
𝑖∈Xy𝑖0, (2)
where∥·∥ 0returns the number of non-zero entries of the binary
vectorÔ
𝑖∈Xy𝑖. Notice that the metric div𝐶is scaled to fall within
the range of 0 to 1, considering the total number of categories
inC. It is worth highlighting that div𝐶favours largerXsizes, asthey typically cover a wider range of categories. Additionally, div𝐶
naturally prefers items that individually provide extensive coverage.
Our second measure of diversity employs the distance function 𝑑
that we defined in the previous paragraph. In particular, for a set of
itemsX⊆I with|X|≥ 2, we define its distance-based diversity as
div𝐷(X)=1
|X|− 1∑︁
𝑖∈X∑︁
𝑗∈X𝑑(𝑖,𝑗), (3)
and we define div𝐷(X)=0, if|X|<2. Notice that the number of
terms in div𝐷is quadratic with respect to |X|. By normalizing with
(|X|− 1)the dependence becomes linear in |X|. As with div𝐶, the
div𝐷metric favors larger sets, in addition to favoring items whose
distance is large to each other.
User model. A central aspect of our approach is that we aim
to evaluate the quality of a recommendation algorithm Sin the
context of the user response to items recommended by S. We view
the user-algorithm interaction as a dynamic knowledge-exploration
process, in which the algorithm recommends items to the user, and
the user interacts with the recommended items. The knowledge-
exploration process continues as long as the recommended items are
of interest to the user. If the recommended items are not interesting
enough (meaning, if they have low relevance for the user) the user
may (stochastically) decide to quit.
To formalize the exploration process between the user and the
recommendation algorithm S, which is needed to evaluate the
quality ofS, we propose a user model. Our model is specified in
terms of a relevance-scoring function R, which guides the behavior
of the user, and in terms of a recommendation algorithm S, which
enacts the choices within S.
Our user model, which formalizes knowledge-exploration as an
iterative process, is described as follows.
(1)The set of items that the user interacts with during the ex-
ploration process is denoted by X. Initially,Xis empty.
(2)In the𝑡-th step, the recommendation algorithm Sgenerates
a list of items L𝑡to present to the user. The user examines
these items in a specified order.
(3)At any point in the current step, the user has the option
to quit. The likelihood of quitting (to be quantified later)
depends on two factors: the relevance of the recommended
items and the user’s patience. If the user fails to find inter-
esting items in list L𝑡or if they stochastically run out of
patience, they may opt to conclude the exploration process.
(4)If the user does not quit, with a certain probability that
depends on the relevance of the recommended items (and
which we quantify later), they select an item 𝑖from the list
L𝑡and interact with it. The item 𝑖is added to the setXand
the exploration process continues.
(5)Upon quitting, the total score achieved by the recommen-
dation algorithmSis determined to be div(X), where div
is one of our diversity functions, div𝐶ordiv𝐷. This score
reflects the diversity in the items the user has interacted
with throughout the exploration process. We denote the
final number of steps performed by the user as 𝜅.
Algorithm 1 depicts the overall exploration process.
To fully specify the user model we need to describe in more detail
the probability that the user selects an item to interact with, as well
 
493Relevance Meets Diversity: A User-Centric Framework for Knowledge Exploration Through Recommendations KDD ’24, August 25–29, 2024, Barcelona, Spain
as the probability of quitting the exploration. Before presenting
more details about these aspects of the model, we first formalize the
problem of designing a recommendation algorithm in the context
of our user model.
The recommendation task (problem statement). The algorith-
mic problem that we address in this paper is the following.
Problem 1. Given a set of items I, a set of usersU, a relevance-
scoring functionR:U×I→ R, a diversity function div: 2I→R,
and a user model for knowledge-exploration as the one described in the
previous paragraph, the goal is to design a recommendation algorithm
Sthat maximizes the diversity score div(X) for the set of items X
that a user𝑢∈U interacts with.
Item selection. We now discuss step (4) of the iterative knowledge-
exploration user model presented in the previous paragraph, that
is, we specify how we model the probability that a user selects an
item𝑖from the list L𝑡to interact with. We first assume that a user
does not quit the exploration, i.e., that they have enough patience
to explore the whole L𝑡and that they find at least a relevant item
within it (see next paragraph). In that case, the user selects an item 𝑖
from L𝑡with probability proportional to the relevance of 𝑖for that
user𝑢, that is,𝑝𝑖=R(𝑢,𝑖)Í
𝑗∈L𝑡R(𝑢,𝑗). As noted before, the selected item 𝑖
is added to the set of interacted items X.
Quitting exploration. Last, we discuss step (3) in our user model,
that is, how we model the probability that a user quits the ex-
ploration process. A sensible model for the quitting probability
is crucial in our knowledge-exploration model, since we want to
mimic user behavior as realistically as possible. In particular, we
take into consideration two aspects: ( 𝑖) users decide to interact with
the recommended items according to their relevance; and ( 𝑖𝑖) users’
desire for exploration degrades with time, i.e., users get bored.
In the model we propose, a user examines the items in the list L𝑡
sequentially. Upon examining an item 𝑖∈L𝑡, the user decides with
probability𝜂𝑡to quit the exploration due to worn out at step 𝑡. We
refer to this as the weariness probability. The weariness probabil-
ity𝜂𝑡, which is discussed in more detail below, models the user’s
decline of interest as a function of time, and depends on the current
step𝑡in the exploration process.
If the user does not quit, they decide whether item 𝑖is interesting
to explore. The latter is decided again stochastically with Bernoulli
probability𝑞𝑖, which is a function of the relevance score R(𝑢,𝑖)2.
Thus, the probability 𝑞𝑖models the user’s interest in an item ac-
cording to its relevance. The examination of the list L𝑡continues
until the user decides to quit or decides that there is at least one
item that is interesting to explore. Therefore, the probability that
the user quits examining the list L𝑡without identifying any item
to explore is
𝑄𝑡={pr. quitting after the first item} +...+
{pr. quitting after the last item}
=|L𝑡|∑︁
𝑗=1𝜂𝑡(1−𝜂𝑡)𝑗−1𝑗−1Ö
𝑖=1(1−𝑞𝑖).(4)
2In our experiments, 𝑞𝑖is obtained by normalizing R(𝑢,𝑖)into the[0,1]interval by
considering the maximum relevance range.The last ingredient in our model is to quantify the weariness prob-
ability𝜂𝑡at step𝑡. This probability models the user’s increasing
impatience or boredom as their interaction continues. To achieve
this, we employ the Weibull distribution [ 33], which has been pre-
viously used to model web page dwell times and session lengths in
web page navigation [26].
The Weibull distribution is described by two parameters, 𝜆and𝛾,
where𝜆>0is the scale parameter and 𝛾>0is the shape parameter
of the distribution. In particular, we set the weariness probability 𝜂𝑡
by resorting to the discrete version of the Weibull Distribution [ 36]:
𝜂𝑡=1−𝑞(𝑡+1)𝛾−𝑡𝛾, (5)
where𝑞=𝑒−1/𝜆𝛾,0≤𝑞≤1.
The shape parameter 𝛾controls the “aging” of the process. For
𝛾=1, the weariness probability remains constant, and the resulting
distribution becomes an exponential distribution, while for 𝛾>
1, the weariness probability increases over time — modeling the
tiredness of the user3.
We can use the analytical properties of the Weibull distribution
to obtain the expected number of steps in the exploration process,
for the case that all recommended items are maximally relevant, i.e.,
𝑞𝑖=1for all𝑖∈L𝑡. In this case, there will be exactly one coin-flip
for quitting exploration for each list L𝑡, and thus,𝑄𝑡=𝜂𝑡for all𝑡.
The overall quitting probability 𝑄𝑇is then
𝑄𝑇={pr. quitting at step 1} +...+
{pr. quitting at step 𝑡}+...
=∞∑︁
𝑡=1𝑄𝑡𝑡−1Ö
𝑗=0(1−𝑄𝑗)
=∞∑︁
𝑡=1
1−𝑞(𝑡+1)𝛾−𝑡𝛾𝑡−1Ö
𝑗=0𝑞(𝑗+1)𝛾−𝑗𝛾
=∞∑︁
𝑡=1
1−𝑞(𝑡+1)𝛾−𝑡𝛾
𝑞𝑡𝛾
=∞∑︁
𝑡=1𝑞𝑡𝛾−𝑞(𝑡+1)𝛾.(6)
The expected number of steps E[steps]examined by a user be-
fore quitting (or equivalently, the number of items in X) is hence
given by
E[steps]=∞∑︁
𝑡=1𝑡
𝑞𝑡𝛾−𝑞(𝑡+1)𝛾
. (7)
Although lacking closed-form analytical expressions, Khan et al .
[22] show that it is bounded by the expectation 𝜇=𝜆Γ(1+1/𝛾)of
the Weibull distribution in the continuous setting [33] as
𝜇<E[steps]<𝜇+1, (8)
which provides an algebraic relationship between the 𝜆parameter
of the Weibull distribution and the admissible range for the expected
number of steps. Note that, if the relevance of the recommended
items is less than 1, it is possible to get more than one coin-flip for
quitting exploration in each list L𝑡. In this case, the right-hand side
of Equation (7) provides an upper bound on the expected number
of steps during exploration.
3For𝛾<1, the weariness probability decreases over time.
 
494KDD ’24, August 25–29, 2024, Barcelona, Spain Erica Coppolillo, Giuseppe Manco, and Aristides Gionis
Remarks on the proposed model. We observe that, as intended,
our model captures both the relevance of the recommended items
and the natural tiredness of users with exploration over time. For
fixed values of the Weibull distribution parameters 𝜆and𝛾, which
control scaling and aging, the users’ time for exploration increases
with the relevance of the recommended items. Furthermore, the
ordering of the items in the list L𝑡is important, and thus, we are
viewing the recommendation list as a sequence, and not just as
a set. This aspect would have implications on how to pick the
appropriate recommendation strategy, but also on the objective
(diversity) function, since it can affect the choices of the user.
4 RECOMMENDATION STRATEGY
In this section, we present our recommendation strategy for the
proposed knowledge-exploration framework. Recall that the rec-
ommendation task is displayed as Problem 1.
The core of the problem is to construct a list of recommendations
L𝑡of size∥L𝑡∥=𝑘at the𝑡-th step of exploration, for a given user
𝑢∈U . We assume thatX𝑡is the set of items that the user has
interacted with at step 𝑡, whereX1=∅. We defineJ𝑡=I\X𝑡to
be set of items that are available for recommendation, that is, all
items except the ones that the user has already interacted with.
For a user𝑢and each item in the candidate set 𝑖∈J𝑡, we consider
its relevance score R𝑖=R(𝑢,𝑖)and its marginal diversity
T𝑖=div(X𝑡∪{𝑖})− div(X𝑡), (9)
with respect to the interaction set X𝑡, where div∈{div𝐷,div𝐶}. We
denoteT𝑖=D𝑖when the distance diversity function div𝐷is used,
andT𝑖=C𝑖when the coverage diversity function div𝐶is used.
Intuitively,D𝑖represents the distance of 𝑖from all the items in
the interaction setX𝑡, whileC𝑖represents the additional coverage
that𝑖provides4. GivenP𝑖∈{R𝑖,T𝑖}, we also denote the min-max
normalization of the score PasbP𝑖=(P𝑖−P min)/(P max−P min),
wherePmaxandPminare the maximum and minimum values of P,
respectively, over all items in X𝑡.
Our strategy for constructing the recommendation list L𝑡is to
combine relevance and diversity into one score. For each item 𝑖
with relevanceR𝑖and diversityT𝑖, we compute the combined score
Z𝑖by adopting the Clayton copula function [11]
Z𝑖=bR−𝛼
𝑖+bT−𝛼
𝑖−1−1/𝛼, (10)
where𝛼>0is a regularization parameter. The list L𝑡is then formed
by selecting the top- 𝑘items fromJ𝑡according toZ𝑖.
We refer to this strategy as explore. When the distance diversity
function is used we refer to it as explore- D, and when coverage
diversity is used we refer to it as explore- C. A final word on the
justification of using the copula function (10). Copulas are functions
able to model the cumulative joint distribution of uniform marginal
distributions. In general, they are used to represent correlation and
dependencies of high-dimensional random variables [ 28,31,45,51].
The Clayton copula function approaches 1 when both the input
variables𝑢,𝑣are maximized, and it is minimized when either of
them is 0. The 𝛼parameter governs the folding of the surface: the
higher the value of 𝛼, the more stooped the function is when 𝑢=𝑣.
4At the beginning of the exploration process (when X𝑡=∅), ifT𝑖=D𝑖, the strategy
samples a highly relevant item 𝑖𝑟so thatD𝑖=𝑑(𝑖,𝑖𝑟); ifT𝑖=C𝑖, thenC𝑖=y𝑖, thus
picking the item that individually provides the highest coverage.Table 1: Dataset statistics and mean Jaccard distances with
respect to users ( ˆ𝐷𝑈) and categories ( ˆ𝐷𝐶).
Dataset
|U| |I | #Ratings ˆ𝐷𝑈ˆ𝐷𝐶
Mo
vielens-1M 6 040 3 706 1 000 208 0.97 0.83
Coat 290 300 6 960 0.97 0.73
KuaiRec-2.0 1 411 3 327 4 676 570 0.35 0.91
Netflix-Prize 4 999 1 112 557 176 0.95 0.83
Yahoo-R2 21 181 3 000 963 296 0.99 0.26
Complexity. Besides the (black-box) recommender system, the
critical point of the algorithm is the generation of L𝑡to be presented
to users (Equations 9 and 10). Since X𝑡is computed incrementally,
the cost of computing T𝑖in Equation 9 is 𝑂(𝑡𝑑)when adopting
div𝐷, and𝑂(|C|) when adopting div𝐶. Here, dis the computational
cost associated with the Jaccard distance. In total, the worst-case
cost for generating a list of kelements by considering 𝑛items
is either𝑂(𝑛𝑑𝑘2)or𝑂(𝑛𝑘|C|). We can observe the following. (1)
The number 𝑛of items to consider could be large (in principle,
the entire item catalog). However, since T𝑖is combined withR𝑖
in Equation 10, we can filter out low-relevance items, as they will
affect the value ofZ𝑖due to the properties of the copula function.
Notice also that, in a practical implementation, sampling strategies
on portions of the catalog can also be devised. (2) The cost 𝑑for
computing𝑑(𝑖,𝑗), for two generic items, can be 𝑂(𝑚), where𝑚is
the total number of users. To relieve this cost, the scores for popular
items can be precomputed. Notice that the distribution of items
is typically heavy-tailed, thus we can expect that the number of
distance scores to precompute is not intractably large.
5 EXPERIMENTS
In this section, we assess the effectiveness of our strategy, either
explore- Dorexplore- C, in balancing accuracy and diversity. We
also evaluate it against several state-of-the-art competitors within
the proposed knowledge-exploration framework.
5.1 Datasets
We use five benchmark datasets, freely available online. We ensure
that all datasets have category information, which is used by our
diversity measures.
Movielens-1M5[17]: A popular dataset with movie ratings in the
range[1,5], and movie genres.
Coat6[38]: Ratings on coats in the range [1,5], and information
on coats’ properties.
KuaiRec-2.07[12]: A recommendation log from a video-sharing
mobile app. Context information is provided, such as play duration,
video duration, and watch ratio. We convert the watch ratios into
ratings by interpolating the values from [0,2]to[1,5], where 0
represents “never watched” and 2 represents “watched twice”. We
use the small version of the dataset.
Netflix-Prize8[4]: Movie ratings in the range [1,5]. We adopt a
smaller sample of the original dataset by randomly selecting 5 000
5https://grouplens.org/datasets/movielens/1m/
6https://www.cs.cornell.edu/~schnabts/mnar/
7https://kuairec.com/
8https://www.kaggle.com/datasets/rishitjavia/netflix-movie-rating-dataset
 
495Relevance Meets Diversity: A User-Centric Framework for Knowledge Exploration Through Recommendations KDD ’24, August 25–29, 2024, Barcelona, Spain
items and discard the users with less than 20 interactions. Movie
categories are acquired from a dataset using the IMDB database9.
Yahoo-R210: Song ratings in the range [1,5]. Each item is accompa-
nied by artist, album, and genre information. We randomly sample
3 000 items and discard users with less than 20 interactions.
Table 1 provides a summary of the dataset properties, which
include the number of users (| U|), the number of items (| I|), the
number of ratings (#Ratings), and the distribution of item distances,
calculated based on either users or categories. During our exper-
iments, we use Equation (1) with the distance that exhibits the
lowest mean for each dataset. This approach helps us avoid poten-
tial bias from large distance values, which could otherwise hinder
the effectiveness of the approaches.
5.2 Competing Recommendation Strategies
We evaluate our recommendation algorithm, explore, against the
following baseline and state-of-the-art strategies designed for the
task of increasing diversity in recommender systems.
Relevance: This approach recommends the 𝑘most relevant items,
making it a fundamental baseline. Since this strategy is solely fo-
cused on maximizing relevance, it represents the most straightfor-
ward and basic diversity method, and any other approach must
outperform it to be deemed effective.
Maximal marginal relevance (MMR) [7]: A classic method used
to balance relevance and diversity, performed by optimizing the
following marginal relevance:
MMR =argmax
𝑖∉𝐿
𝛽R(𝑢,𝑖)−( 1−𝛽)max
𝑗∈𝐿S𝑖,𝑗
,
where S𝑖,𝑗=1−𝑑(𝑖,𝑗). In our experiments, we set 𝛽=0.5to
achieve the best trade-off between relevance and diversity.
DUM [3]: This strategy aims at diversifying the suggestions by
performing the following diversity-weighted utility maximization:
DUM=argmax
𝐿∈Π𝑘∑︁
ℎ=1h
𝑓
𝐿[:ℎ]
−𝑓
𝐿[:ℎ−1]i
R(𝑢,𝑖ℎ),
where Πdenotes all possible permutations of 𝐿,𝐿[:ℎ]represents
the list up to the ℎ-th element 𝑖ℎ, and𝑓(𝑋)=Í
𝑐∈C 1{exists𝑖∈
𝑋:𝑖covers category 𝑐}is the number of categories in 𝑋. Hence,
the function maximizes the relevance of the recommended items
weighted by the increase in their coverage.
DPP [10]: This method utilizes determinantal point processes and
maximizes diversity by iteratively selecting the item 𝑖that maxi-
mizes the determinant of the item-item similarity matrix Sdefined
on a subset of items:
DPP=argmax
𝑖∉𝐿
log det(S𝐿∪{𝑖})−log det(S𝐿)	
.
DGREC [48]: A GNN-based recommender that aims at finding a
subset of diverse neighbors as well as maximizing the coverage of
categories, by optimizing the loss function:
LDGREC =∑︁
(𝑢,𝑖)∈𝐸𝑤y𝑖LBPR(𝑢,𝑖,𝑗)+𝜆||Θ||2
2,
9https://github.com/tommasocarraro/netflix-prize-with-genres
10https://webscope.sandbox.yahoo.com/catalog.php?datatype=i&did=67where𝑤y𝑖weights each sample based on its category, 𝜆is a reg-
ularization factor, and LBPRis the Bayesian personalized ranking
loss [34].
Notably, these competitors exhibit significant heterogeneity both
in terms of the approaches they employ as well as the specific
diversity functions they aim to optimize.
5.3 Experimental Setting
To evaluate the performance of the examined recommendation
strategies, we divide user interactions into a training and a test
set, following an 80-20% split ratio. When evaluating the accuracy,
we only focus on the recommendation list generated in the initial
exploration step. This is because evaluating the quality only for
the recommendation list generated in the first exploration step
represents a lower bound of the system’s overall accuracy. By con-
sidering multiple lists, the probability of achieving a hit increases,
thereby enhancing the overall metrics. Regarding diversity instead,
we consider the complete set of recommendation lists produced
across all exploration steps. Our approach also assumes that the
entire item catalog is accessible to every user during the simulation.
To calculate the relevance score R(𝑢,𝑖), we employ a black-box
model in the form of a neural network based on matrix factoriza-
tion [ 23]. We fine-tune the latent factors of this model for each
dataset. For explore, we use a value of 𝛼=0.5in the Clayton
copula. Additionally, we conduct hyperparameter tuning for this
parameter, and it appears that it has no significant impact on the
results (further details can be found in the Appendix).
We keep the length of the recommendation list, L, fixed at 10,
and vary the expected number of steps, E[steps], in the range
of [5, 10, 20]. This allows us to devise a suitable value for the
Weibull parameter 𝜆to be used in the simulation experiments, ac-
cording to Equation (7). In more detail, its value is computed so that
E[steps]∈[ 5,10,20]. ForE[steps] =5, we devise a value 𝜆=6.2;
similarly, E[steps] =10, devises𝜆=11.85andE[steps] =20de-
vises𝜆=23.21. Regarding 𝛾, we fixed𝛾=2, since a value >1
models a weariness probability which increases over time, as dis-
cussed in Section 3. To assess recommendation quality, we use
standard metrics: Hit-Ratio (HR),Precision, and Recall. Our experi-
mental results are the average of 20 independent trials, and we use
the ANOVA test to evaluate statistical significance. The code used
in these experiments is made publicly accessible11.
5.4 Results
Quality-diversity trade-off. We initiate our evaluation by assess-
ing the performance of all our strategies in terms of recommenda-
tion quality and diversity. Figure 3 displays the scores for Recall @10
(on the𝑥-axis) and diversity (on the 𝑦-axis) across all five datasets,
either in terms of coverage (top-row) or distance (bottom-row).
The Figure shows that on all datasets, MMR and DGREC exhibit
notably poor performance with respect to Recall @10. In contrast,
the other strategies achieve significantly higher scores, with the
Relevance baseline performing the best, which aligns with our ex-
pectations. In terms of diversity, our method, explore- C, clearly
outperforms the other strategies. It achieves a substantially higher
diversity score while still delivering relevant recommendations. In
11https://github.com/EricaCoppolillo/EXPLORE
 
496KDD ’24, August 25–29, 2024, Barcelona, Spain Erica Coppolillo, Giuseppe Manco, and Aristides Gionis
Relevance explore- D explore- C MMR DUM DPP DGREC
0.000.250.500.751.00
Recall @100.00.20.40.60.8divC
0.000.250.500.751.00
Recall @100.00.20.4divC
0.000.250.500.751.00
Recall @100.00.20.4divC
0.000.250.500.751.00
Recall @100.00.20.40.60.8divC
0.000.250.500.751.00
Recall @100.000.050.100.15divC
0.000.250.500.751.00
Recall @100.02.55.07.510.0divD
(
a) Movielens-1M
0.00 0.25 0.50 0.75 1.00
Recall @100246divD (
b) Coat
0.00 0.25 0.50 0.75 1.00
Recall @100123divD (
c) KuaiRec-2.0
0.00 0.25 0.50 0.75 1.00
Recall @1002468divD (
d) Netflix-Prize
0.00 0.25 0.50 0.75 1.00
Recall @1002468divD (
e) Yahoo-R2
Figure 3: Trade-off between div𝐶(top) and div𝐷(bottom), and Recall @10, respectively, across all the datasets considered. The 𝑥-axis
represents recommendation quality, while the 𝑦-axis indicates the diversity score.
fact, it strikes the best trade-off between diversity and relevance.
Similar considerations can be made for the distance-based variant,
explore-D . Other results can be found in the Appendix.
Best performing diversity strategy. Table 2 presents a compre-
hensive analysis of div𝐷,div𝐶and𝜅when E[steps]=5. Addition-
ally, we report the deviations from the maximum diversity scores
in terms of distance and coverage (in Table 3), denoted as Δ¯𝐷and
Δ¯𝐶, along with ΔE[steps].
We observe that our strategy, either explore- Dorexplore- C,
consistently outperforms the competitors in terms of both div𝐷and
div𝐶across all datasets. We also show how these values deviate
from the expected maximum values. Notably, on the Movielens-1M
dataset, their scores are very close to their maxima. Our strategy
achieves significantly higher scores than the competitors on all
datasets, especially in terms of coverage.
Regarding the number of steps, as mentioned in Section 3, the rel-
evance plays a fundamental role in our exploration process. There-
fore, it is expected that our strategy performs slightly worse than
other competitors, particularly the Relevance baseline. Nevertheless,
our primary objective is to maximize recommendation diversity
while maintaining relevance as high as possible. Additional results
are reported in the Appendix.
Ablation study. In our final investigation, we explore the advan-
tages of combining both relevance and diversity through the copula
function in Equation (10), in contrast to a simpler strategy that
neglects relevance and relies on Equation (9).
Table 4 presents a summary of the results obtained for E[steps]=
10. For each strategy, we provide the values for div𝐷,div𝐶, and
actual steps 𝜅. The scores are computed for two variants: one where
relevance is included through the copula function (w) and another
where it is ignored (w/o). The table also reports the differences in
scores ( Δw). We can observe that the combination has a positive
effect both in terms of diversity and number of steps.
Timing. Another crucial aspect to consider is the timing needed to
provide L𝑡, reported in Figure 4. As we can see, competitors such as
MMR and DPP require a considerable amount of time to computeTable 2: Diversity scores for E[steps]=5. Any best scores with
a statistical significance 𝑝<0.05are highlighted in bold.
Dataset
Strategy div𝐷div𝐶𝜅 Δ¯𝐷Δ¯𝐶ΔE[steps]Mo
vielens-1MRele
vance 3.67 0.22 5.0 0.27 0.73 0.0
explore-D 4.91 0.36
4.98 0.03 0.55 0.0
explore-C 4.43 0.71 4.71 0.12 0.11 0.06
MMR
3.96 0.29 4.57 0.22 0.64 0.09
DUM 4.4 0.33 4.98 0.13 0.59 0.0
DPP 4.59 0.31 4.99 0.09 0.61 0.0
DGREC 3.36 0.37 4.49 0.33 0.54 0.1CoatRele
vance 3.15 0.3 4.36 0.38 0.3 0.13
explore-D 3.48 0.34
4.16 0.31 0.2 0.17
explore-C 3.36 0.35 4.13 0.33 0.18 0.17
MMR
2.43 0.26 3.54 0.52 0.39 0.29
DUM 3.11 0.3 4.31 0.38 0.3 0.14
DPP 3.28 0.31 4.33 0.35 0.27 0.13
DGREC 2.2 0.24 3.2 0.56 0.44 0.36KuaiRe
c-2.0Rele
vance 0.76 0.13 4.81 0.81 0.74 0.04
explore-D 1.56 0.11
3.54 0.61 0.78 0.29
explore-C 1.08 0.34 4.09 0.73 0.32 0.18
MMR
1.25 0.12 3.89 0.68 0.76 0.22
DUM 0.83 0.17 4.8 0.79 0.66 0.04
DPP 1.38 0.09 4.75 0.65 0.82 0.05
DGREC 0.77 0.11 2.64 0.81 0.78 0.47NetflixRele
vance 4.04 0.32 4.86 0.2 0.59 0.03
explore-D 4.62 0.38
4.75 0.09 0.51 0.05
explore-C 3.97 0.6 4.43 0.21 0.22 0.11
MMR
3.56 0.3 4.19 0.3 0.61 0.16
DUM 4.16 0.36 4.89 0.18 0.53 0.02
DPP 4.38 0.34 4.88 0.13 0.56 0.02
DGREC 3.0 0.26 3.74 0.41 0.66 0.25Y
ahoo-R2Rele
vance 0.66 0.02 4.77 0.87 0.77 0.05
explore-D 4.4
0.08 4.49 0.13 0.1 0.1
explore-C 4.38 0.08 4.47 0.13 0.1 0.11
MMR
2.45 0.04 3.96 0.52 0.55 0.21
DUM 4.38 0.07 4.72 0.13 0.21 0.06
DPP 4.38 0.07 4.72 0.13 0.21 0.06
DGREC 1.02 0.02 3.68 0.8 0.77 0.26
 
497Relevance Meets Diversity: A User-Centric Framework for Knowledge Exploration Through Recommendations KDD ’24, August 25–29, 2024, Barcelona, Spain
Relevance explore-D
explore-C
MMR DUM DPP
DGREC100101102103104Time (s)
(a) Movielens-1M
Relevance explore-D
explore-C
MMR DUM DPP
DGREC100101102103104Time (s) (b) Coat
Relevance explore-D
explore-C
MMR DUM DPP
DGREC100101102103104Time (s) (c) KuaiRec-2.0
Relevance explore-D
explore-C
MMR DUM DPP
DGREC100101102103104Time (s) (d) Netflix-Prize
Relevance explore-D
explore-C
MMR DUM DPP
DGREC100101102103104Time (s) (e) Yahoo-R2
Figure 4: Timing for producing L𝑡. The𝑥-axis reports the strategies, while the 𝑦-axis the recommendation time (in seconds).
Table 3: Maximum scores in terms of diversity and coverage
per dataset, by varying the expected number of steps.
Dataset E[steps] ¯𝐷 ¯𝐶
Mo
vielens-1M5 5.05 0.80
10 10.05 0.93
20 20.03 0.98
Coat5
5.05 0.43
10 10.05 0.68
20 20.03 0.89
KuaiRe
c-2.05 3.97 0.50
10 7.87 0.73
20 15.63 0.91
Netflix-Prize5
5.05 0.77
10 10.05 0.87
20 20.03 0.91
Y
ahoo-r25 5.05 0.09
10 10.05 0.17
20 20.03 0.34
their recommended lists, in particular for the largest datasets. Our
algorithm explore, instead, proves to be much more efficient, and
its running time is basically constant over all the benchmarks.
6 CONCLUSION AND FUTURE WORK
In this study, we addressed recommendation diversity by introduc-
ing a user-behavior model where relevance drives engagement. We
developed a recommendation strategy that optimizes the delivery of
diverse knowledge based on user behavior. Our experimental anal-
ysis confirms the effectiveness of this approach, though it remains
open to further enhancements. First, the behavioral model can be
refined to include more sophisticated scenarios, such as refresh-
ing the list, guiding its composition, and incorporating dynamic
adjustments to the weariness probability beyond temporal decay.
Additionally, our model assumes the relevance score accurately
reflects a user’s interest in an item. However, since the relevance
score is algorithmically computed and may not be entirely accurate,
we can adapt the user behavior model by incorporating a random
discount factor for the relevance of each item. Finally, the proposed
strategy can be improved in several ways, such as integrating differ-
ent distance measures or extending it to include additional metrics
beyond diversity, like serendipity or fairness.Table 4: Results in terms of div𝐷,div𝐶and𝜅by including
(w) and excluding (w/o) relevance from our recommendation
strategies. Positive relative changes ( Δw) are reported in bold.
Strategy
Relevance div𝐷 div𝐶𝜅Mo
vielens-1Mexplore-Dw
9.77 0.63 9.85
w/o 6.66 0.53 6.73
Δw +0.32
+0.16 +0.32
explore-Cw
8.84 0.89 9.7
w/o 6.56 0.86 7.0
Δw +0.26
+0.03 +0.28Coatexplore-Dw
6.73 0.51 8.02
w/o 5.5 0.47 6.41
Δw +0.18
+0.08 +0.2
explore-Cw
6.31 0.55 7.81
w/o 5.18 0.49 6.34
Δw +0.18
+0.11 +0.19KuaiRe
c-2.0explore-Dw
3.06 0.17 6.86
w/o 2.38 0.13 4.47
Δw +0.22
+0.24 +0.35
explore-Cw
2.22 0.53 7.95
w/o 2.01 0.49 6.04
Δw +0.09
+0.08 +0.24Netflixexplore-Dw
9.03 0.59 9.24
w/o 7.42 0.54 7.52
Δw +0.18
+0.08 +0.19
explore-Cw
7.92 0.77 8.69
w/o 6.71 0.75 7.38
Δw +0.15
+0.03 +0.15Y
ahoo-R2explore-Dw
8.71 0.15 8.73
w/o 6.23 0.11 6.3
Δw +0.28
+0.27 +0.28
explore-Cw
8.67 0.15 8.7
w/o 6.25 0.11 6.31
Δw +0.28
+0.27 +0.27
ACKNOLWEDGEMENTS
This work has been partially funded by MUR on D.M. 351/2022,
PNRR Ricerca, CUP H23C22000440007, and supported by project
SERICS (PE00000014) under the MUR National Recovery and Re-
silience Plan funded by the European Union – NextGenerationEU.
Aristides Gionis is supported by the ERC Advanced Grant RE-
BOUND (834862), the EC H2020 RIA project SoBigData++ (871042),
and the Wallenberg AI, Autonomous Systems and Software Pro-
gram (WASP) funded by the Knut and Alice Wallenberg Foundation.
 
498KDD ’24, August 25–29, 2024, Barcelona, Spain Erica Coppolillo, Giuseppe Manco, and Aristides Gionis
REFERENCES
[1]Panagiotis Adamopoulos and Alexander Tuzhilin. 2014. On Unexpectedness in
Recommender Systems: Or How to Better Expect the Unexpected. ACM Trans.
Intell. Syst. Technol. 5, 4 (2014), 54:1–54:32.
[2]Gediminas Adomavicius and YoungOk Kwon. 2012. Improving Aggregate Rec-
ommendation Diversity Using Ranking-Based Techniques. IEEE Trans. Knowl.
Data Eng. 24, 5 (2012), 896–911.
[3]Azin Ashkan, Branislav Kveton, Shlomo Berkovsky, and Zheng Wen. 2015. Opti-
mal Greedy Diversity for Recommendation. In Procs. AAAI IJCAI. 1742–1748.
[4] James Bennett and Stan Lanning. 2007. The Netflix Prize.
[5]Dimitrios Bountouridis, Jaron Harambam, Mykola Makhortykh, Mónica Marrero,
Nava Tintarev, and Claudia Hauff. 2019. SIREN: A Simulation Framework for Un-
derstanding the Effects of Recommender Systems in Online News Environments.
InProcs. ACM FAT*. 150–159.
[6]Robin D. Burke. 2007. Hybrid Web Recommender Systems. In The Adaptive Web,
Methods and Strategies of Web Personalization, Vol. 4321. Springer, 377–408.
[7]Jaime Carbonell and Jade Goldstein. 1998. The Use of MMR, Diversity-Based
Reranking for Reordering Documents and Producing Summaries. In Procs. ACM
SIGIR. 335–336.
[8]Pablo Castells, Neil Hurley, and S. Vargas. 2022. Novelty and Diversity in Recom-
mender Systems. In Recommender Systems Handbook. Springer US, 603–646.
[9]Allison J. B. Chaney, Brandon M. Stewart, and Barbara E. Engelhardt. 2018. How
algorithmic confounding in recommendation systems increases homogeneity
and decreases utility. In Procs. ACM RecSys. 224–232.
[10] Laming Chen, Guoxin Zhang, and Hanning Zhou. 2018. Fast Greedy MAP
Inference for Determinantal Point Process to Improve Recommendation Diversity.
InProcs. NeurIPS. 5627–5638.
[11] David George Clayton. 1978. A model for association in bivariate life tables and
its application in epidemiological studies of familial tendency in chronic disease
incidence. Biometrika 65, 1 (1978), 141–151.
[12] Chongming Gao, Shijun Li, Wenqiang Lei, Jiawei Chen, Biao Li, Peng Jiang,
Xiangnan He, J. Mao, and T. Chua. 2022. KuaiRec: A Fully-observed Dataset and
Insights for Evaluating Recommender Systems. In Procs. ACM CIKM. 540–550.
[13] Zhaolin Gao, Tianshu Shen, Zheda Mai, Mohamed Reda Bouadjenek, Isaac Waller,
Ashton Anderson, Ron Bodkin, and Scott Sanner. 2022. Mitigating the Filter
Bubble While Maintaining Relevance: Targeted Diversification with VAE-based
Recommender Systems. In Procs. ACM SIGIR. 2524–2531.
[14] Casper Hansen, Christian Hansen, Lucas Maystre, Rishabh Mehrotra, Brian Brost,
Federico Tomasi, and Mounia Lalmas. 2020. Contextual and Sequential User
Embeddings for Large-Scale Music Recommendation. In ACM RecSys. 53–62.
[15] Christian Hansen, Rishabh Mehrotra, Casper Hansen, Brian Brost, Lucas Maystre,
and Mounia Lalmas. 2021. Shifting Consumption towards Diverse Content on
Music Streaming Platforms. In Procs. ACM WSDM. 238–246.
[16] Muhammad Haroon, Anshuman Chhabra, Xin Liu, Prasanta Mohapatra, Zubair
Shafiq, and Magdalena E. Wojcieszak. 2022. YouTube, The Great Radicalizer?
Auditing and Mitigating Ideological Biases in YouTube Recommendations. CoRR
abs/2203.10666 (2022).
[17] F. Maxwell Harper and Joseph A. Konstan. 2016. The MovieLens Datasets: History
and Context. ACM Trans. Interact. Intell. Syst. 5, 4 (2016), 19:1–19:19.
[18] Naieme Hazrati, Mehdi Elahi, and Francesco Ricci. 2020. Simulating the Impact
of Recommender Systems on the Evolution of Collective Users’ Choices. In Procs.
ACM HT. 207–212.
[19] Naieme Hazrati and Francesco Ricci. 2022. Recommender systems effect on the
evolution of users’ choices distribution. Inf. Process. Manag. 59, 1 (2022), 102766.
[20] Jonathan L. Herlocker, Joseph A. Konstan, Loren G. Terveen, and John T. Riedl.
2004. Evaluating collaborative filtering recommender systems. ACM Trans. Inf.
Syst. 22, 1 (2004), 5–53.
[21] Neil Hurley and Mi Zhang. 2011. Novelty and Diversity in Top-N Recommenda-
tion - Analysis and Evaluation. ACM Trans. Internet Techn. 10, 4 (2011), 14:1–14:30.
[22] M.S.A. Khan, Abdul Khalique, and A. M. Abouammoh. 1989. On estimating
parameters in a discrete Weibull distribution. IEEE Transactions on Reliability 38
(1989), 348–350.
[23] Yehuda Koren, Robert Bell, and Chris Volinsky. 2009. Matrix Factorization Tech-
niques for Recommender Systems. Computer 42, 8 (2009), 30–37.
[24] Dokyun Lee and Kartik Hosanagar. 2019. How Do Recommender Systems Affect
Sales Diversity? A Cross-Category Investigation via Randomized Field Experi-
ment. Inf. Syst. Res. 30, 1 (2019), 239–259.
[25] Yile Liang, Tieyun Qian, Qing Li, and Hongzhi Yin. 2021. Enhancing Domain-
Level and User-Level Adaptivity in Diversified Recommendation. In Procs. ACM
SIGIR. 747–756.
[26] Chao Liu, Ryen W. White, and Susan T. Dumais. 2010. Understanding web
browsing behaviors through Weibull analysis of dwell time. In Procs. ACM SIGIR.
379–386.
[27] Jian-Guo Liu, Kerui Shi, and Qiang Guo. 2012. Solving the accuracy-diversity
dilemma via directed random walks. CoRR abs/1201.6278 (2012).[28] P Novianti, S H Kartiko, and D Rosadi. 2021. Application of Clayton Copula to
identify dependency structure of Covid-19 outbreak and average temperature in
Jakarta Indonesia. Journal of Physics: Conference Series 1943 (2021), 012154.
[29] Javier Parapar and Filip Radlinski. 2021. Diverse User Preference Elicitation with
Multi-Armed Bandits. In Procs. ACM SIGIR. 130–138.
[30] Michael J. Pazzani and Daniel Billsus. 2007. Content-Based Recommendation
Systems. In The Adaptive Web, Methods and Strategies of Web Personalization,
Vol. 4321. Springer, 325–341.
[31] Hanyu Peng, Guanhua Fang, and Ping Li. 2023. Copula for Instance-wise Feature
Selection and Rank. In Procs. PMLR UAI, Vol. 216. 1651–1661.
[32] Shruti Phadke, Mattia Samory, and Tanushree Mitra. 2022. Pathways through
Conspiracy: The Evolution of Conspiracy Radicalization through Engagement in
Online Conspiracy Discussions. In Procs. AAAI ICWSM. 770–781.
[33] John G. Proakis. 1985. Probability, random variables and stochastic processes.
IEEE Trans. Acoust. Speech Signal Process. 33, 6 (1985), 1637.
[34] Steffen Rendle, Christoph Freudenthaler, Zeno Gantner, and Lars Schmidt-Thieme.
2009. BPR: Bayesian Personalized Ranking from Implicit Feedback. In Procs. AUAI
UAI. 452–461.
[35] Manoel H. Ribeiro, Raphael Ottoni, Robert West, Virgílio A. Almeida, and Wagner
Meira Jr. 2020. Auditing radicalization pathways on YouTube. In Procs. ACM
FAT*. 131–141.
[36] Horst Rinne. 2008. The Weibull Distribution: A Handbook (1st ed.). Chapman and
Hall/CRC.
[37] J. Ben Schafer, Dan Frankowski, Jon Herlocker, and Shilad Sen. 2007. Collaborative
Filtering Recommender Systems. In The Adaptive Web, Methods and Strategies of
Web Personalization, Vol. 4321. Springer, 291–324.
[38] Tobias Schnabel, Adith Swaminathan, Ashudeep Singh, Navin Chandak, and
Thorsten Joachims. 2016. Recommendations as Treatments: Debiasing Learning
and Evaluation. In Procs. JMLR ICML, Vol. 48. 1670–1679.
[39] Chaofeng Sha, Xiaowei Wu, and Junyu Niu. 2016. A Framework for Recommend-
ing Relevant and Diverse Items. In Procs. IJCAI/AAAI IJCAI. 3868–3874.
[40] Barry Smyth and Paul McClave. 2001. Similarity vs. Diversity. In Procs. Springer
ICCBR, Vol. 2080. 347–361.
[41] Harald Steck. 2018. Calibrated recommendations. In Procs. ACM RecSys. 154–162.
[42] Zoltán Szlávik, Wojtek Kowalczyk, and Martijn Schut. 2011. Diversity Measure-
ment of Recommender Systems under Different User Choice Models. In Procs.
AAAI . Conference on Weblogs and Social Media.
[43] Zeynep Tufekci. 2018. YouTube, the great radicalizer. The New York Times 10, 3
(2018), 2018.
[44] Saul Vargas and Pablo Castells. 2011. Rank and relevance in novelty and diversity
metrics for recommender systems. In Procs. ACM RecSys. 109–116.
[45] Prince Zizhuang Wang and William Yang Wang. 2019. Neural Gaussian Copula
for Variational Autoencoder. In Procs. EMNLP-IJCNLP. 4332–4342.
[46] Chuhan Wu, Fangzhao Wu, Yongfeng Huang, and Xing Xie. 2023. Personalized
News Recommendation: Methods and Challenges. ACM Trans. Inf. Syst. 41, 1
(2023), 24:1–24:50.
[47] Min Xie, Hongzhi Yin, Hao Wang, Fanjiang Xu, Weitong Chen, and Sen Wang.
2016. Learning Graph-based POI Embedding for Location-based Recommenda-
tion. In Procs. ACM CIKM. 15–24.
[48] Liangwei Yang, Shengjie Wang, Yunzhe Tao, Jiankai Sun, Xiaolong Liu, Philip S.
Yu, and Taiqing Wang. 2023. DGRec: Graph Neural Network for Recommendation
with Diversified Embedding Generation. In Procs. ACM WSDM. 661–669.
[49] Sirui Yao, Yoni Halpern, Nithum Thain, Xuezhi Wang, Kang Lee, Flavien Prost,
Ed H. Chi, Jilin Chen, and Alex Beutel. 2021. Measuring Recommender System
Effects with Simulated Users. CoRR abs/2101.04526 (2021).
[50] Yisong Yue and Carlos Guestrin. 2011. Linear Submodular Bandits and their
Application to Diversified Retrieval. In Procs. NeurIPS. 2483–2491.
[51] Zhi Zeng and Ting Wang. 2022. Neural Copula: A unified framework for estimat-
ing generic high-dimensional Copula functions. CoRR abs/2205.15031 (2022).
[52] Yu Zheng, Chen Gao, Liang Chen, Depeng Jin, and Yong Li. 2021. DGCN: Diversi-
fied Recommendation with Graph Convolutional Networks. In Procs. ACM/IW3C2
WWW. 401–412.
[53] Dong Hong Zhu, Yawei Wang, and Ya Ping Chang. 2018. The influence of
online cross-recommendation on consumers’ instant cross-buying intention: The
moderating role of decision-making difficulty. Internet Res. 28, 3 (2018), 604–622.
[54] C. Ziegler, Sean M. McNee, Joseph A. Konstan, and Georg Lausen. 2005. Improving
recommendation lists through topic diversification. In Procs. ACM WWW. 22–32.
A ADDITIONAL RESULTS
Figure 5 shows the trade-off between diversity and accuracy. Fig-
ure 6 depicts the effects of tuning the 𝛼parameter in the Clayton
copula function. Table 5 reports additional results for E[steps]∈
[10,20]across the considered datasets.
 
499Relevance Meets Diversity: A User-Centric Framework for Knowledge Exploration Through Recommendations KDD ’24, August 25–29, 2024, Barcelona, Spain
Relevance explore- D explore- C MMR DUM DPP DGREC
0.000.250.500.751.00
HR@100.00.20.40.60.8divC
0.000.250.500.751.00
HR@100.00.20.4divC
0.000.250.500.751.00
HR@100.00.20.4divC
0.000.250.500.751.00
HR@100.00.20.40.60.8divC
0.000.250.500.751.00
HR@100.000.050.100.15divC
0.000.250.500.751.00
HR@100.02.55.07.510.0divD
0.00 0.25 0.50 0.75 1.00
HR@100246divD
0.00 0.25 0.50 0.75 1.00
HR@100123divD
0.00 0.25 0.50 0.75 1.00
HR@1002468divD
0.00 0.25 0.50 0.75 1.00
HR@1002468divD
0.000.250.500.751.00
Precision @100.00.20.40.60.8divC
0.000.250.500.751.00
Precision @100.00.20.4divC
0.000.250.500.751.00
Precision @100.00.20.4divC
0.000.250.500.751.00
Precision @100.00.20.40.60.8divC
0.000.250.500.751.00
Precision @100.000.050.100.15divC
0.000.250.500.751.00
Precision @100.02.55.07.510.0divD
(
a) Movielens-1M
0.00 0.25 0.50 0.75 1.00
Precision @100246divD (
b) Coat
0.00 0.25 0.50 0.75 1.00
Precision @100123divD (
c) KuaiRec-2.0
0.00 0.25 0.50 0.75 1.00
Precision @1002468divD (
d) Netflix-Prize
0.00 0.25 0.50 0.75 1.00
Precision @1002468divD (
e) Yahoo-R2
Figure 5: Trade-off between either div𝐶ordiv𝐷and either HR@10 orPrecision @10 across all the datasets. The 𝑥-axis shows the
recommendation quality while the 𝑦-axis represents the diversity score.
explore- D explore- C
0.0001 0.001 0.01 0.1 0.5 1 2 3 4
α0.04.07.011.0divD
0.00.30.71.0
divC
(a) Movielens-1M
0.0001 0.001 0.01 0.1 0.5 1 2 3 4
α0.03.05.08.0divD
0.00.20.40.6
divC
 (b) Coat
0.0001 0.001 0.01 0.1 0.5 1 2 3 4
α0.01.02.03.0divD
0.00.20.40.6
divC
 (c) KuaiRec-2.0
0.0001 0.001 0.01 0.1 0.5 1 2 3 4
α0.03.07.010.0divD
0.00.30.60.8
divC
(d) Netflix-Prize
0.0001 0.001 0.01 0.1 0.5 1 2 3 4
α0.03.06.010.0divD
0.00.10.10.2
divC
 (e) Yahoo-R2
Figure 6: Effects of tuning the 𝛼parameter fixing E[steps]=10. The𝑥-axis represents different values of 𝛼, while the 𝑦-axis
report values of div𝐷(left) and of div𝐶(right).
 
500KDD ’24, August 25–29, 2024, Barcelona, Spain Erica Coppolillo, Giuseppe Manco, and Aristides Gionis
Table 5: Results with E[steps]∈[ 10,20]across all the datasets. Best scores with statistical significance 𝑝<0.05are in bold.
Dataset
Strategy div𝐷div𝐶𝜅 Δ¯𝐷Δ¯𝐶ΔE[steps]Mo
vielens-1MRele
vance 7.45 0.34 10.02 0.26 0.64 0.0
explore-D 9.77 0.63
9.85 0.03 0.32 0.02
explore-C 8.84 0.89 9.7 0.12 0.05 0.03
MMR
7.29 0.43 8.62 0.27 0.54 0.14
DUM 8.95 0.51 10.03 0.11 0.45 0.0
DPP 9.29 0.5 9.99 0.08 0.46 0.0
DGREC 6.89 0.49 8.92 0.31 0.47 0.11CoatRele
vance 6.38 0.44 8.64 0.36 0.35 0.14
explore-D 6.73
0.51 8.02 0.33 0.25 0.2
explore-C 6.31 0.55 7.81 0.37 0.19 0.22
MMR
4.63 0.38 6.75 0.54 0.44 0.32
DUM 6.44 0.46 8.65 0.36 0.32 0.13
DPP 6.64 0.45 8.61 0.34 0.34 0.14
DGREC 4.56 0.37 6.33 0.55 0.46 0.37KuaiRe
c-2.0Rele
vance 1.63 0.21 9.6 0.79 0.71 0.04
explore-D 3.06 0.17
6.86 0.61 0.77 0.31
explore-C 2.22 0.53 7.95 0.72 0.28 0.2
MMR
2.52 0.2 7.34 0.68 0.73 0.27
DUM 1.78 0.27 9.59 0.77 0.63 0.04
DPP 2.81 0.15 9.54 0.64 0.8 0.05
DGREC 1.71 0.19 5.45 0.78 0.74 0.45NetflixRele
vance 8.17 0.46 9.73 0.19 0.47 0.03
explore-D 9.03 0.59
9.24 0.1 0.32 0.08
explore-C 7.92 0.77 8.69 0.21 0.12 0.13
MMR
6.76 0.43 7.94 0.33 0.51 0.21
DUM 8.36 0.51 9.72 0.17 0.41 0.03
DPP 8.82 0.5 9.73 0.12 0.43 0.03
DGREC 6.15 0.39 7.44 0.39 0.55 0.26Y
ahoo-R2Rele
vance 1.39 0.03 9.49 0.86 0.83 0.05
explore-D 8.71 0.15 8.73
0.13 0.14 0.13
explore-C 8.67 0.15 8.7 0.14 0.14 0.13
MMR
3.86 0.05 7.36 0.62 0.71 0.26
DUM 8.86 0.12 9.43 0.12 0.31 0.06
DPP 8.84 0.12 9.41 0.12 0.31 0.06
DGREC 2.04 0.03 7.35 0.8 0.83 0.26
(a)E[steps]=10.Dataset
Strategy div𝐷 div𝐶𝜅 Δ¯𝐷Δ¯𝐶ΔE[steps]Mo
vielens-1MRele
vance 14.96 0.48 20.04 0.25 0.51 0.0
explore-D 18.96 0.86
19.4 0.05 0.12 0.03
explore-C 16.81 0.97 19.76 0.16 0.01 0.01
MMR
13.45 0.57 16.49 0.33 0.42 0.18
DUM 17.98 0.7 20.16 0.1 0.29 -0.01
DPP 18.6 0.71 20.02 0.07 0.28 0.0
DGREC 13.91 0.63 17.64 0.31 0.36 0.12CoatRele
vance 12.23 0.59 16.36 0.39 0.33 0.18
explore-D 12.85
0.7 15.48 0.36 0.21 0.23
explore-C 12.09 0.77 15.36 0.4 0.13 0.23
MMR
8.79 0.53 13.12 0.56 0.4 0.34
DUM 12.63 0.62 16.78 0.37 0.3 0.16
DPP 13.06 0.62 16.84 0.35 0.3 0.16
DGREC 9.31 0.53 12.84 0.54 0.4 0.36KuaiRe
c-2.0Rele
vance 3.62 0.32 19.02 0.77 0.65 0.05
explore-D 6.16 0.26
13.83 0.61 0.71 0.31
explore-C 4.55 0.76 15.09 0.71 0.16 0.25
MMR
4.79 0.3 13.91 0.69 0.67 0.3
DUM 3.86 0.39 19.09 0.75 0.57 0.05
DPP 5.56 0.24 18.99 0.64 0.73 0.05
DGREC 3.55 0.3 11.33 0.77 0.67 0.43NetflixRele
vance 16.19 0.6 19.29 0.19 0.34 0.04
explore-D 17.38
0.77 17.98 0.13 0.15 0.1
explore-C 15.6 0.87 17.53 0.22 0.04 0.12
MMR
12.79 0.56 15.34 0.36 0.38 0.23
DUM 16.59 0.65 19.33 0.17 0.29 0.03
DPP 17.49 0.66 19.36 0.13 0.27 0.03
DGREC 12.11 0.53 14.59 0.4 0.42 0.27Y
ahoo-R2Rele
vance 3.0 0.04 18.81 0.85 0.88 0.06
explore-D 16.48 0.28 16.5
0.18 0.17 0.18
explore-C 16.43 0.28 16.46 0.18 0.17 0.18
MMR
5.9 0.07 13.89 0.71 0.79 0.31
DUM 17.59 0.19 18.73 0.12 0.44 0.06
DPP 17.6 0.19 18.74 0.12 0.44 0.06
DGREC 3.92 0.04 14.56 0.8 0.88 0.27
(b)E[steps]=20.
 
501